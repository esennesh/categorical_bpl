{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/eli/AnacondaProjects/categorical_bpl\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import collections\n",
    "import pyro\n",
    "import torch\n",
    "import numpy as np\n",
    "import data_loader.data_loaders as module_data\n",
    "import model.model as module_arch\n",
    "from parse_config import ConfigParser\n",
    "from trainer import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyro.enable_validation(True)\n",
    "# torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seeds for reproducibility\n",
    "SEED = 123\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Args = collections.namedtuple('Args', 'config resume device')\n",
    "config = ConfigParser.from_args(Args(config='deepgen_mnist_config.json', resume=None, device=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = config.get_logger('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup data_loader instances\n",
    "data_loader = config.init_obj('data_loader', module_data)\n",
    "valid_data_loader = data_loader.split_validation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model architecture, then print to console\n",
    "model = config.init_obj('arch', module_arch,\n",
    "                        dataset_length=len(data_loader.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = pyro.optim.ReduceLROnPlateau({\n",
    "    'optimizer': torch.optim.Adam,\n",
    "    'optim_args': {\n",
    "        \"lr\": 1e-3,\n",
    "        \"weight_decay\": 0,\n",
    "        \"amsgrad\": True\n",
    "    },\n",
    "    \"patience\": 100,\n",
    "    \"cooldown\": 100,\n",
    "    \"factor\": 0.5,\n",
    "    \"verbose\": True,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model, [], optimizer, config=config,\n",
    "                  data_loader=data_loader,\n",
    "                  valid_data_loader=valid_data_loader,\n",
    "                  lr_scheduler=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [512/60000 (1%)] Loss: 1641.421143\n",
      "Train Epoch: 1 [11776/60000 (20%)] Loss: -12.925884\n",
      "Train Epoch: 1 [23040/60000 (38%)] Loss: 137.008682\n",
      "Train Epoch: 1 [34304/60000 (57%)] Loss: -165.080902\n",
      "Train Epoch: 1 [45568/60000 (76%)] Loss: -232.495605\n",
      "Train Epoch: 1 [56832/60000 (95%)] Loss: -317.463593\n",
      "    epoch          : 1\n",
      "    loss           : 18.38017420580158\n",
      "Warning: Metric 'val_loss' is not found. Model performance monitoring is disabled.\n",
      "Train Epoch: 2 [512/60000 (1%)] Loss: -240.714508\n",
      "Train Epoch: 2 [11776/60000 (20%)] Loss: -286.388733\n",
      "Train Epoch: 2 [23040/60000 (38%)] Loss: -277.965454\n",
      "Train Epoch: 2 [34304/60000 (57%)] Loss: -350.820099\n",
      "Train Epoch: 2 [45568/60000 (76%)] Loss: -473.049042\n",
      "Train Epoch: 2 [56832/60000 (95%)] Loss: -398.701294\n",
      "    epoch          : 2\n",
      "    loss           : -368.4804598705917\n",
      "Train Epoch: 3 [512/60000 (1%)] Loss: -485.121643\n",
      "Train Epoch: 3 [11776/60000 (20%)] Loss: -371.872955\n",
      "Train Epoch: 3 [23040/60000 (38%)] Loss: -408.211426\n",
      "Train Epoch: 3 [34304/60000 (57%)] Loss: -546.657471\n",
      "Train Epoch: 3 [45568/60000 (76%)] Loss: -546.552979\n",
      "Train Epoch: 3 [56832/60000 (95%)] Loss: -455.315491\n",
      "    epoch          : 3\n",
      "    loss           : -476.28746377546236\n",
      "Train Epoch: 4 [512/60000 (1%)] Loss: -444.390656\n",
      "Train Epoch: 4 [11776/60000 (20%)] Loss: -469.747559\n",
      "Train Epoch: 4 [23040/60000 (38%)] Loss: -446.681793\n",
      "Train Epoch: 4 [34304/60000 (57%)] Loss: -578.532959\n",
      "Train Epoch: 4 [45568/60000 (76%)] Loss: -477.813293\n",
      "Train Epoch: 4 [56832/60000 (95%)] Loss: -454.457611\n",
      "    epoch          : 4\n",
      "    loss           : -527.1697795458433\n",
      "Train Epoch: 5 [512/60000 (1%)] Loss: -598.352295\n",
      "Train Epoch: 5 [11776/60000 (20%)] Loss: -471.049316\n",
      "Train Epoch: 5 [23040/60000 (38%)] Loss: -610.801025\n",
      "Train Epoch: 5 [34304/60000 (57%)] Loss: -633.029175\n",
      "Train Epoch: 5 [45568/60000 (76%)] Loss: -784.283203\n",
      "Train Epoch: 5 [56832/60000 (95%)] Loss: -475.806702\n",
      "    epoch          : 5\n",
      "    loss           : -586.9978296312236\n",
      "Train Epoch: 6 [512/60000 (1%)] Loss: -808.149048\n",
      "Train Epoch: 6 [11776/60000 (20%)] Loss: -649.858704\n",
      "Train Epoch: 6 [23040/60000 (38%)] Loss: -687.033997\n",
      "Train Epoch: 6 [34304/60000 (57%)] Loss: -545.003296\n",
      "Train Epoch: 6 [45568/60000 (76%)] Loss: -551.854858\n",
      "Train Epoch: 6 [56832/60000 (95%)] Loss: -837.329102\n",
      "    epoch          : 6\n",
      "    loss           : -621.8566154005837\n",
      "Train Epoch: 7 [512/60000 (1%)] Loss: -667.193604\n",
      "Train Epoch: 7 [11776/60000 (20%)] Loss: -556.780518\n",
      "Train Epoch: 7 [23040/60000 (38%)] Loss: -533.709351\n",
      "Train Epoch: 7 [34304/60000 (57%)] Loss: -559.696289\n",
      "Train Epoch: 7 [45568/60000 (76%)] Loss: -858.392578\n",
      "Train Epoch: 7 [56832/60000 (95%)] Loss: -566.770813\n",
      "    epoch          : 7\n",
      "    loss           : -639.2384447000794\n",
      "Train Epoch: 8 [512/60000 (1%)] Loss: -562.126892\n",
      "Train Epoch: 8 [11776/60000 (20%)] Loss: -548.334045\n",
      "Train Epoch: 8 [23040/60000 (38%)] Loss: -597.046326\n",
      "Train Epoch: 8 [34304/60000 (57%)] Loss: -556.641602\n",
      "Train Epoch: 8 [45568/60000 (76%)] Loss: -608.944702\n",
      "Train Epoch: 8 [56832/60000 (95%)] Loss: -576.077698\n",
      "    epoch          : 8\n",
      "    loss           : -652.5002234507415\n",
      "Train Epoch: 9 [512/60000 (1%)] Loss: -735.023010\n",
      "Train Epoch: 9 [11776/60000 (20%)] Loss: -612.037842\n",
      "Train Epoch: 9 [23040/60000 (38%)] Loss: -624.928772\n",
      "Train Epoch: 9 [34304/60000 (57%)] Loss: -583.574036\n",
      "Train Epoch: 9 [45568/60000 (76%)] Loss: -755.802246\n",
      "Train Epoch: 9 [56832/60000 (95%)] Loss: -756.944214\n",
      "    epoch          : 9\n",
      "    loss           : -677.1746427891618\n",
      "Train Epoch: 10 [512/60000 (1%)] Loss: -610.135193\n",
      "Train Epoch: 10 [11776/60000 (20%)] Loss: -596.687500\n",
      "Train Epoch: 10 [23040/60000 (38%)] Loss: -593.077454\n",
      "Train Epoch: 10 [34304/60000 (57%)] Loss: -578.227539\n",
      "Train Epoch: 10 [45568/60000 (76%)] Loss: -793.958069\n",
      "Train Epoch: 10 [56832/60000 (95%)] Loss: -641.497681\n",
      "    epoch          : 10\n",
      "    loss           : -692.9036515230513\n",
      "Train Epoch: 11 [512/60000 (1%)] Loss: -599.290466\n",
      "Train Epoch: 11 [11776/60000 (20%)] Loss: -585.008789\n",
      "Train Epoch: 11 [23040/60000 (38%)] Loss: -747.289307\n",
      "Train Epoch: 11 [34304/60000 (57%)] Loss: -719.908325\n",
      "Train Epoch: 11 [45568/60000 (76%)] Loss: -788.933594\n",
      "Train Epoch: 11 [56832/60000 (95%)] Loss: -642.968506\n",
      "    epoch          : 11\n",
      "    loss           : -680.1370208222987\n",
      "Train Epoch: 12 [512/60000 (1%)] Loss: -871.077271\n",
      "Train Epoch: 12 [11776/60000 (20%)] Loss: -702.335693\n",
      "Train Epoch: 12 [23040/60000 (38%)] Loss: -623.074036\n",
      "Train Epoch: 12 [34304/60000 (57%)] Loss: -659.393433\n",
      "Train Epoch: 12 [45568/60000 (76%)] Loss: -672.267334\n",
      "Train Epoch: 12 [56832/60000 (95%)] Loss: -982.184204\n",
      "    epoch          : 12\n",
      "    loss           : -710.1277436509644\n",
      "Train Epoch: 13 [512/60000 (1%)] Loss: -795.454468\n",
      "Train Epoch: 13 [11776/60000 (20%)] Loss: -754.557251\n",
      "Train Epoch: 13 [23040/60000 (38%)] Loss: -800.843323\n",
      "Train Epoch: 13 [34304/60000 (57%)] Loss: -671.276367\n",
      "Train Epoch: 13 [45568/60000 (76%)] Loss: -618.473145\n",
      "Train Epoch: 13 [56832/60000 (95%)] Loss: -610.755066\n",
      "    epoch          : 13\n",
      "    loss           : -736.3180105780478\n",
      "Train Epoch: 14 [512/60000 (1%)] Loss: -792.682983\n",
      "Train Epoch: 14 [11776/60000 (20%)] Loss: -690.411987\n",
      "Train Epoch: 14 [23040/60000 (38%)] Loss: -1068.443359\n",
      "Train Epoch: 14 [34304/60000 (57%)] Loss: -817.449219\n",
      "Train Epoch: 14 [45568/60000 (76%)] Loss: -625.739990\n",
      "Train Epoch: 14 [56832/60000 (95%)] Loss: -769.765625\n",
      "    epoch          : 14\n",
      "    loss           : -749.5170953610523\n",
      "Train Epoch: 15 [512/60000 (1%)] Loss: -924.160706\n",
      "Train Epoch: 15 [11776/60000 (20%)] Loss: -666.988159\n",
      "Train Epoch: 15 [23040/60000 (38%)] Loss: -730.984802\n",
      "Train Epoch: 15 [34304/60000 (57%)] Loss: -626.453552\n",
      "Train Epoch: 15 [45568/60000 (76%)] Loss: -669.180786\n",
      "Train Epoch: 15 [56832/60000 (95%)] Loss: -870.916138\n",
      "    epoch          : 15\n",
      "    loss           : -758.2074491856462\n",
      "Train Epoch: 16 [512/60000 (1%)] Loss: -960.879639\n",
      "Train Epoch: 16 [11776/60000 (20%)] Loss: -682.052490\n",
      "Train Epoch: 16 [23040/60000 (38%)] Loss: -647.373413\n",
      "Train Epoch: 16 [34304/60000 (57%)] Loss: -846.868164\n",
      "Train Epoch: 16 [45568/60000 (76%)] Loss: -713.161255\n",
      "Train Epoch: 16 [56832/60000 (95%)] Loss: -770.608643\n",
      "    epoch          : 16\n",
      "    loss           : -774.325040138374\n",
      "Train Epoch: 17 [512/60000 (1%)] Loss: -800.608215\n",
      "Train Epoch: 17 [11776/60000 (20%)] Loss: -842.283142\n",
      "Train Epoch: 17 [23040/60000 (38%)] Loss: -737.429504\n",
      "Train Epoch: 17 [34304/60000 (57%)] Loss: -723.098511\n",
      "Train Epoch: 17 [45568/60000 (76%)] Loss: -674.121948\n",
      "Train Epoch: 17 [56832/60000 (95%)] Loss: -872.697754\n",
      "    epoch          : 17\n",
      "    loss           : -776.9727971136233\n",
      "Train Epoch: 18 [512/60000 (1%)] Loss: -771.244507\n",
      "Train Epoch: 18 [11776/60000 (20%)] Loss: -694.833862\n",
      "Train Epoch: 18 [23040/60000 (38%)] Loss: -698.788452\n",
      "Train Epoch: 18 [34304/60000 (57%)] Loss: -739.989624\n",
      "Train Epoch: 18 [45568/60000 (76%)] Loss: -919.590332\n",
      "Train Epoch: 18 [56832/60000 (95%)] Loss: -858.500305\n",
      "    epoch          : 18\n",
      "    loss           : -812.0361360883982\n",
      "Train Epoch: 19 [512/60000 (1%)] Loss: -755.721985\n",
      "Train Epoch: 19 [11776/60000 (20%)] Loss: -880.151367\n",
      "Train Epoch: 19 [23040/60000 (38%)] Loss: -894.887390\n",
      "Train Epoch: 19 [34304/60000 (57%)] Loss: -975.465454\n",
      "Train Epoch: 19 [45568/60000 (76%)] Loss: -903.326538\n",
      "Train Epoch: 19 [56832/60000 (95%)] Loss: -715.999939\n",
      "    epoch          : 19\n",
      "    loss           : -814.295213602357\n",
      "Train Epoch: 20 [512/60000 (1%)] Loss: -816.153748\n",
      "Train Epoch: 20 [11776/60000 (20%)] Loss: -866.685913\n",
      "Train Epoch: 20 [23040/60000 (38%)] Loss: -818.862000\n",
      "Train Epoch: 20 [34304/60000 (57%)] Loss: -890.822144\n",
      "Train Epoch: 20 [45568/60000 (76%)] Loss: -655.699402\n",
      "Train Epoch: 20 [56832/60000 (95%)] Loss: -763.252747\n",
      "    epoch          : 20\n",
      "    loss           : -778.0823265980866\n",
      "Train Epoch: 21 [512/60000 (1%)] Loss: -721.050293\n",
      "Train Epoch: 21 [11776/60000 (20%)] Loss: -670.699097\n",
      "Train Epoch: 21 [23040/60000 (38%)] Loss: -700.989990\n",
      "Train Epoch: 21 [34304/60000 (57%)] Loss: -654.157593\n",
      "Train Epoch: 21 [45568/60000 (76%)] Loss: -840.988525\n",
      "Train Epoch: 21 [56832/60000 (95%)] Loss: -977.875671\n",
      "    epoch          : 21\n",
      "    loss           : -810.8873094461732\n",
      "Train Epoch: 22 [512/60000 (1%)] Loss: -777.153442\n",
      "Train Epoch: 22 [11776/60000 (20%)] Loss: -791.794250\n",
      "Train Epoch: 22 [23040/60000 (38%)] Loss: -694.007446\n",
      "Train Epoch: 22 [34304/60000 (57%)] Loss: -738.237549\n",
      "Train Epoch: 22 [45568/60000 (76%)] Loss: -874.317627\n",
      "Train Epoch: 22 [56832/60000 (95%)] Loss: -833.847656\n",
      "    epoch          : 22\n",
      "    loss           : -807.7580700890493\n",
      "Train Epoch: 23 [512/60000 (1%)] Loss: -922.778931\n",
      "Train Epoch: 23 [11776/60000 (20%)] Loss: -761.153137\n",
      "Train Epoch: 23 [23040/60000 (38%)] Loss: -893.833252\n",
      "Train Epoch: 23 [34304/60000 (57%)] Loss: -671.587341\n",
      "Train Epoch: 23 [45568/60000 (76%)] Loss: -829.647217\n",
      "Train Epoch: 23 [56832/60000 (95%)] Loss: -885.995178\n",
      "    epoch          : 23\n",
      "    loss           : -836.1575970838298\n",
      "Train Epoch: 24 [512/60000 (1%)] Loss: -924.107666\n",
      "Train Epoch: 24 [11776/60000 (20%)] Loss: -780.520386\n",
      "Train Epoch: 24 [23040/60000 (38%)] Loss: -731.003296\n",
      "Train Epoch: 24 [34304/60000 (57%)] Loss: -689.810608\n",
      "Train Epoch: 24 [45568/60000 (76%)] Loss: -812.544800\n",
      "Train Epoch: 24 [56832/60000 (95%)] Loss: -965.184021\n",
      "    epoch          : 24\n",
      "    loss           : -844.7671081198137\n",
      "Train Epoch: 25 [512/60000 (1%)] Loss: -1068.756470\n",
      "Train Epoch: 25 [11776/60000 (20%)] Loss: -945.884766\n",
      "Train Epoch: 25 [23040/60000 (38%)] Loss: -712.503296\n",
      "Train Epoch: 25 [34304/60000 (57%)] Loss: -864.511353\n",
      "Train Epoch: 25 [45568/60000 (76%)] Loss: -986.440063\n",
      "Train Epoch: 25 [56832/60000 (95%)] Loss: -845.103760\n",
      "    epoch          : 25\n",
      "    loss           : -856.1073339429952\n",
      "Train Epoch: 26 [512/60000 (1%)] Loss: -733.008667\n",
      "Train Epoch: 26 [11776/60000 (20%)] Loss: -849.432251\n",
      "Train Epoch: 26 [23040/60000 (38%)] Loss: -809.371216\n",
      "Train Epoch: 26 [34304/60000 (57%)] Loss: -1055.401978\n",
      "Train Epoch: 26 [45568/60000 (76%)] Loss: -737.232544\n",
      "Train Epoch: 26 [56832/60000 (95%)] Loss: -1064.145996\n",
      "    epoch          : 26\n",
      "    loss           : -864.0982305666821\n",
      "Train Epoch: 27 [512/60000 (1%)] Loss: -803.887451\n",
      "Train Epoch: 27 [11776/60000 (20%)] Loss: -760.875427\n",
      "Train Epoch: 27 [23040/60000 (38%)] Loss: -909.497253\n",
      "Train Epoch: 27 [34304/60000 (57%)] Loss: -761.977722\n",
      "Train Epoch: 27 [45568/60000 (76%)] Loss: -1018.715088\n",
      "Train Epoch: 27 [56832/60000 (95%)] Loss: -1169.562378\n",
      "    epoch          : 27\n",
      "    loss           : -886.4405472750044\n",
      "Train Epoch: 28 [512/60000 (1%)] Loss: -1080.958984\n",
      "Train Epoch: 28 [11776/60000 (20%)] Loss: -946.432373\n",
      "Train Epoch: 28 [23040/60000 (38%)] Loss: -930.620361\n",
      "Train Epoch: 28 [34304/60000 (57%)] Loss: -817.358398\n",
      "Train Epoch: 28 [45568/60000 (76%)] Loss: -941.484619\n",
      "Train Epoch: 28 [56832/60000 (95%)] Loss: -818.221191\n",
      "    epoch          : 28\n",
      "    loss           : -905.958903339623\n",
      "Train Epoch: 29 [512/60000 (1%)] Loss: -1106.232422\n",
      "Train Epoch: 29 [11776/60000 (20%)] Loss: -838.413879\n",
      "Train Epoch: 29 [23040/60000 (38%)] Loss: -916.926392\n",
      "Train Epoch: 29 [34304/60000 (57%)] Loss: -951.059814\n",
      "Train Epoch: 29 [45568/60000 (76%)] Loss: -820.970459\n",
      "Train Epoch: 29 [56832/60000 (95%)] Loss: -993.395691\n",
      "    epoch          : 29\n",
      "    loss           : -897.398404051355\n",
      "Train Epoch: 30 [512/60000 (1%)] Loss: -800.390259\n",
      "Train Epoch: 30 [11776/60000 (20%)] Loss: -821.229614\n",
      "Train Epoch: 30 [23040/60000 (38%)] Loss: -942.522156\n",
      "Train Epoch: 30 [34304/60000 (57%)] Loss: -684.778015\n",
      "Train Epoch: 30 [45568/60000 (76%)] Loss: -924.625000\n",
      "Train Epoch: 30 [56832/60000 (95%)] Loss: -909.955444\n",
      "    epoch          : 30\n",
      "    loss           : -882.1219834149894\n",
      "Train Epoch: 31 [512/60000 (1%)] Loss: -880.960693\n",
      "Train Epoch: 31 [11776/60000 (20%)] Loss: -927.474854\n",
      "Train Epoch: 31 [23040/60000 (38%)] Loss: -781.101074\n",
      "Train Epoch: 31 [34304/60000 (57%)] Loss: -1025.731323\n",
      "Train Epoch: 31 [45568/60000 (76%)] Loss: -747.263672\n",
      "Train Epoch: 31 [56832/60000 (95%)] Loss: -900.676270\n",
      "    epoch          : 31\n",
      "    loss           : -910.6725603523901\n",
      "Train Epoch: 32 [512/60000 (1%)] Loss: -1009.091064\n",
      "Train Epoch: 32 [11776/60000 (20%)] Loss: -870.861877\n",
      "Train Epoch: 32 [23040/60000 (38%)] Loss: -757.907410\n",
      "Train Epoch: 32 [34304/60000 (57%)] Loss: -1020.205139\n",
      "Train Epoch: 32 [45568/60000 (76%)] Loss: -1031.474609\n",
      "Train Epoch: 32 [56832/60000 (95%)] Loss: -878.681152\n",
      "    epoch          : 32\n",
      "    loss           : -901.2160837636828\n",
      "Train Epoch: 33 [512/60000 (1%)] Loss: -958.897095\n",
      "Train Epoch: 33 [11776/60000 (20%)] Loss: -916.339355\n",
      "Train Epoch: 33 [23040/60000 (38%)] Loss: -1024.647827\n",
      "Train Epoch: 33 [34304/60000 (57%)] Loss: -772.877014\n",
      "Train Epoch: 33 [45568/60000 (76%)] Loss: -998.987061\n",
      "Train Epoch: 33 [56832/60000 (95%)] Loss: -929.586670\n",
      "    epoch          : 33\n",
      "    loss           : -910.9029206529175\n",
      "Train Epoch: 34 [512/60000 (1%)] Loss: -955.838074\n",
      "Train Epoch: 34 [11776/60000 (20%)] Loss: -777.220032\n",
      "Train Epoch: 34 [23040/60000 (38%)] Loss: -849.854126\n",
      "Train Epoch: 34 [34304/60000 (57%)] Loss: -862.670715\n",
      "Train Epoch: 34 [45568/60000 (76%)] Loss: -964.990601\n",
      "Train Epoch: 34 [56832/60000 (95%)] Loss: -965.614685\n",
      "    epoch          : 34\n",
      "    loss           : -908.887903763076\n",
      "Train Epoch: 35 [512/60000 (1%)] Loss: -971.002563\n",
      "Train Epoch: 35 [11776/60000 (20%)] Loss: -1055.791382\n",
      "Train Epoch: 35 [23040/60000 (38%)] Loss: -800.188354\n",
      "Train Epoch: 35 [34304/60000 (57%)] Loss: -892.910400\n",
      "Train Epoch: 35 [45568/60000 (76%)] Loss: -980.042480\n",
      "Train Epoch: 35 [56832/60000 (95%)] Loss: -962.112488\n",
      "    epoch          : 35\n",
      "    loss           : -937.5089426848848\n",
      "Train Epoch: 36 [512/60000 (1%)] Loss: -991.030334\n",
      "Train Epoch: 36 [11776/60000 (20%)] Loss: -762.234497\n",
      "Train Epoch: 36 [23040/60000 (38%)] Loss: -1104.696777\n",
      "Train Epoch: 36 [34304/60000 (57%)] Loss: -1112.695435\n",
      "Train Epoch: 36 [45568/60000 (76%)] Loss: -847.224609\n",
      "Train Epoch: 36 [56832/60000 (95%)] Loss: -1039.032593\n",
      "    epoch          : 36\n",
      "    loss           : -912.6214404779638\n",
      "Train Epoch: 37 [512/60000 (1%)] Loss: -948.465637\n",
      "Train Epoch: 37 [11776/60000 (20%)] Loss: -883.688232\n",
      "Train Epoch: 37 [23040/60000 (38%)] Loss: -784.700439\n",
      "Train Epoch: 37 [34304/60000 (57%)] Loss: -1026.267212\n",
      "Train Epoch: 37 [45568/60000 (76%)] Loss: -906.032349\n",
      "Train Epoch: 37 [56832/60000 (95%)] Loss: -898.981262\n",
      "    epoch          : 37\n",
      "    loss           : -923.8491090246514\n",
      "Train Epoch: 38 [512/60000 (1%)] Loss: -887.062744\n",
      "Train Epoch: 38 [11776/60000 (20%)] Loss: -976.914062\n",
      "Train Epoch: 38 [23040/60000 (38%)] Loss: -1048.554077\n",
      "Train Epoch: 38 [34304/60000 (57%)] Loss: -988.524414\n",
      "Train Epoch: 38 [45568/60000 (76%)] Loss: -800.637451\n",
      "Train Epoch: 38 [56832/60000 (95%)] Loss: -960.605164\n",
      "    epoch          : 38\n",
      "    loss           : -923.592989819198\n",
      "Train Epoch: 39 [512/60000 (1%)] Loss: -784.764526\n",
      "Train Epoch: 39 [11776/60000 (20%)] Loss: -952.076294\n",
      "Train Epoch: 39 [23040/60000 (38%)] Loss: -1050.140137\n",
      "Train Epoch: 39 [34304/60000 (57%)] Loss: -959.083801\n",
      "Train Epoch: 39 [45568/60000 (76%)] Loss: -1043.957153\n",
      "Train Epoch: 39 [56832/60000 (95%)] Loss: -887.171997\n",
      "    epoch          : 39\n",
      "    loss           : -940.1924902274784\n",
      "Train Epoch: 40 [512/60000 (1%)] Loss: -893.761292\n",
      "Train Epoch: 40 [11776/60000 (20%)] Loss: -977.097290\n",
      "Train Epoch: 40 [23040/60000 (38%)] Loss: -813.622925\n",
      "Train Epoch: 40 [34304/60000 (57%)] Loss: -912.405518\n",
      "Train Epoch: 40 [45568/60000 (76%)] Loss: -917.672791\n",
      "Train Epoch: 40 [56832/60000 (95%)] Loss: -1118.933228\n",
      "    epoch          : 40\n",
      "    loss           : -915.7654872398592\n",
      "Train Epoch: 41 [512/60000 (1%)] Loss: -769.153320\n",
      "Train Epoch: 41 [11776/60000 (20%)] Loss: -1071.867676\n",
      "Train Epoch: 41 [23040/60000 (38%)] Loss: -889.166504\n",
      "Train Epoch: 41 [34304/60000 (57%)] Loss: -799.369751\n",
      "Train Epoch: 41 [45568/60000 (76%)] Loss: -988.360718\n",
      "Train Epoch: 41 [56832/60000 (95%)] Loss: -957.040771\n",
      "    epoch          : 41\n",
      "    loss           : -934.2001966918256\n",
      "Train Epoch: 42 [512/60000 (1%)] Loss: -899.997559\n",
      "Train Epoch: 42 [11776/60000 (20%)] Loss: -885.477356\n",
      "Train Epoch: 42 [23040/60000 (38%)] Loss: -1042.241333\n",
      "Train Epoch: 42 [34304/60000 (57%)] Loss: -804.470886\n",
      "Train Epoch: 42 [45568/60000 (76%)] Loss: -948.110474\n",
      "Train Epoch: 42 [56832/60000 (95%)] Loss: -912.679321\n",
      "    epoch          : 42\n",
      "    loss           : -940.3751196564928\n",
      "Train Epoch: 43 [512/60000 (1%)] Loss: -807.221619\n",
      "Train Epoch: 43 [11776/60000 (20%)] Loss: -982.477783\n",
      "Train Epoch: 43 [23040/60000 (38%)] Loss: -1077.240479\n",
      "Train Epoch: 43 [34304/60000 (57%)] Loss: -987.993164\n",
      "Train Epoch: 43 [45568/60000 (76%)] Loss: -1022.156494\n",
      "Train Epoch: 43 [56832/60000 (95%)] Loss: -1011.967896\n",
      "    epoch          : 43\n",
      "    loss           : -974.5776586155433\n",
      "Train Epoch: 44 [512/60000 (1%)] Loss: -904.877991\n",
      "Train Epoch: 44 [11776/60000 (20%)] Loss: -1097.455566\n",
      "Train Epoch: 44 [23040/60000 (38%)] Loss: -1100.949341\n",
      "Train Epoch: 44 [34304/60000 (57%)] Loss: -1073.954346\n",
      "Train Epoch: 44 [45568/60000 (76%)] Loss: -1105.835083\n",
      "Train Epoch: 44 [56832/60000 (95%)] Loss: -1155.353271\n",
      "    epoch          : 44\n",
      "    loss           : -978.679886295297\n",
      "Train Epoch: 45 [512/60000 (1%)] Loss: -1031.095703\n",
      "Train Epoch: 45 [11776/60000 (20%)] Loss: -1020.826355\n",
      "Train Epoch: 45 [23040/60000 (38%)] Loss: -1035.228516\n",
      "Train Epoch: 45 [34304/60000 (57%)] Loss: -1082.880615\n",
      "Train Epoch: 45 [45568/60000 (76%)] Loss: -930.463013\n",
      "Train Epoch: 45 [56832/60000 (95%)] Loss: -1211.185791\n",
      "    epoch          : 45\n",
      "    loss           : -997.8510788739737\n",
      "Train Epoch: 46 [512/60000 (1%)] Loss: -814.665894\n",
      "Train Epoch: 46 [11776/60000 (20%)] Loss: -1030.429077\n",
      "Train Epoch: 46 [23040/60000 (38%)] Loss: -857.947388\n",
      "Train Epoch: 46 [34304/60000 (57%)] Loss: -945.261047\n",
      "Train Epoch: 46 [45568/60000 (76%)] Loss: -1018.487061\n",
      "Train Epoch: 46 [56832/60000 (95%)] Loss: -996.941833\n",
      "    epoch          : 46\n",
      "    loss           : -983.9803209897489\n",
      "Train Epoch: 47 [512/60000 (1%)] Loss: -837.261658\n",
      "Train Epoch: 47 [11776/60000 (20%)] Loss: -836.385620\n",
      "Train Epoch: 47 [23040/60000 (38%)] Loss: -999.915405\n",
      "Train Epoch: 47 [34304/60000 (57%)] Loss: -927.122681\n",
      "Train Epoch: 47 [45568/60000 (76%)] Loss: -765.073181\n",
      "Train Epoch: 47 [56832/60000 (95%)] Loss: -1040.873291\n",
      "    epoch          : 47\n",
      "    loss           : -974.5306851661811\n",
      "Train Epoch: 48 [512/60000 (1%)] Loss: -1014.530518\n",
      "Train Epoch: 48 [11776/60000 (20%)] Loss: -1017.334351\n",
      "Train Epoch: 48 [23040/60000 (38%)] Loss: -1014.181702\n",
      "Train Epoch: 48 [34304/60000 (57%)] Loss: -963.271606\n",
      "Train Epoch: 48 [45568/60000 (76%)] Loss: -1112.701904\n",
      "Train Epoch: 48 [56832/60000 (95%)] Loss: -902.935120\n",
      "    epoch          : 48\n",
      "    loss           : -989.4319168349443\n",
      "Train Epoch: 49 [512/60000 (1%)] Loss: -1050.994019\n",
      "Train Epoch: 49 [11776/60000 (20%)] Loss: -792.135986\n",
      "Train Epoch: 49 [23040/60000 (38%)] Loss: -1086.880127\n",
      "Train Epoch: 49 [34304/60000 (57%)] Loss: -929.179382\n",
      "Train Epoch: 49 [45568/60000 (76%)] Loss: -1055.694336\n",
      "Train Epoch: 49 [56832/60000 (95%)] Loss: -928.892700\n",
      "    epoch          : 49\n",
      "    loss           : -972.9521396442996\n",
      "Train Epoch: 50 [512/60000 (1%)] Loss: -874.113770\n",
      "Train Epoch: 50 [11776/60000 (20%)] Loss: -946.245117\n",
      "Train Epoch: 50 [23040/60000 (38%)] Loss: -940.397888\n",
      "Train Epoch: 50 [34304/60000 (57%)] Loss: -1131.264893\n",
      "Train Epoch: 50 [45568/60000 (76%)] Loss: -1063.314209\n",
      "Train Epoch: 50 [56832/60000 (95%)] Loss: -1107.444336\n",
      "    epoch          : 50\n",
      "    loss           : -986.2430035434874\n",
      "Train Epoch: 51 [512/60000 (1%)] Loss: -931.732178\n",
      "Train Epoch: 51 [11776/60000 (20%)] Loss: -1020.963989\n",
      "Train Epoch: 51 [23040/60000 (38%)] Loss: -1023.934692\n",
      "Train Epoch: 51 [34304/60000 (57%)] Loss: -983.241211\n",
      "Train Epoch: 51 [45568/60000 (76%)] Loss: -1016.655640\n",
      "Train Epoch: 51 [56832/60000 (95%)] Loss: -953.386902\n",
      "    epoch          : 51\n",
      "    loss           : -1012.089508401472\n",
      "Train Epoch: 52 [512/60000 (1%)] Loss: -660.102173\n",
      "Train Epoch: 52 [11776/60000 (20%)] Loss: -849.252319\n",
      "Train Epoch: 52 [23040/60000 (38%)] Loss: -1001.166992\n",
      "Train Epoch: 52 [34304/60000 (57%)] Loss: -964.730957\n",
      "Train Epoch: 52 [45568/60000 (76%)] Loss: -939.084229\n",
      "Train Epoch: 52 [56832/60000 (95%)] Loss: -1041.240967\n",
      "    epoch          : 52\n",
      "    loss           : -998.781541727357\n",
      "Train Epoch: 53 [512/60000 (1%)] Loss: -986.472900\n",
      "Train Epoch: 53 [11776/60000 (20%)] Loss: -1134.688477\n",
      "Train Epoch: 53 [23040/60000 (38%)] Loss: -943.639221\n",
      "Train Epoch: 53 [34304/60000 (57%)] Loss: -1112.796387\n",
      "Train Epoch: 53 [45568/60000 (76%)] Loss: -1033.150879\n",
      "Train Epoch: 53 [56832/60000 (95%)] Loss: -1022.611328\n",
      "    epoch          : 53\n",
      "    loss           : -1002.1892326053253\n",
      "Train Epoch: 54 [512/60000 (1%)] Loss: -1056.467773\n",
      "Train Epoch: 54 [11776/60000 (20%)] Loss: -786.314636\n",
      "Train Epoch: 54 [23040/60000 (38%)] Loss: -1115.692383\n",
      "Train Epoch: 54 [34304/60000 (57%)] Loss: -797.482422\n",
      "Train Epoch: 54 [45568/60000 (76%)] Loss: -1173.928345\n",
      "Train Epoch: 54 [56832/60000 (95%)] Loss: -1076.403076\n",
      "    epoch          : 54\n",
      "    loss           : -1000.1250698283567\n",
      "Train Epoch: 55 [512/60000 (1%)] Loss: -892.839050\n",
      "Train Epoch: 55 [11776/60000 (20%)] Loss: -899.824158\n",
      "Train Epoch: 55 [23040/60000 (38%)] Loss: -1122.684937\n",
      "Train Epoch: 55 [34304/60000 (57%)] Loss: -922.185425\n",
      "Train Epoch: 55 [45568/60000 (76%)] Loss: -796.073181\n",
      "Train Epoch: 55 [56832/60000 (95%)] Loss: -1117.787720\n",
      "    epoch          : 55\n",
      "    loss           : -1008.9904305840615\n",
      "Train Epoch: 56 [512/60000 (1%)] Loss: -980.322266\n",
      "Train Epoch: 56 [11776/60000 (20%)] Loss: -1103.279785\n",
      "Train Epoch: 56 [23040/60000 (38%)] Loss: -1002.931641\n",
      "Train Epoch: 56 [34304/60000 (57%)] Loss: -1062.390747\n",
      "Train Epoch: 56 [45568/60000 (76%)] Loss: -1101.500732\n",
      "Train Epoch: 56 [56832/60000 (95%)] Loss: -1122.791382\n",
      "    epoch          : 56\n",
      "    loss           : -1022.0081744005452\n",
      "Train Epoch: 57 [512/60000 (1%)] Loss: -1065.289795\n",
      "Train Epoch: 57 [11776/60000 (20%)] Loss: -910.033447\n",
      "Train Epoch: 57 [23040/60000 (38%)] Loss: -986.115234\n",
      "Train Epoch: 57 [34304/60000 (57%)] Loss: -1115.123291\n",
      "Train Epoch: 57 [45568/60000 (76%)] Loss: -1021.511414\n",
      "Train Epoch: 57 [56832/60000 (95%)] Loss: -1012.199097\n",
      "    epoch          : 57\n",
      "    loss           : -1028.2629066941429\n",
      "Train Epoch: 58 [512/60000 (1%)] Loss: -928.839600\n",
      "Train Epoch: 58 [11776/60000 (20%)] Loss: -1097.322021\n",
      "Train Epoch: 58 [23040/60000 (38%)] Loss: -1047.755737\n",
      "Train Epoch: 58 [34304/60000 (57%)] Loss: -997.365540\n",
      "Train Epoch: 58 [45568/60000 (76%)] Loss: -941.359558\n",
      "Train Epoch: 58 [56832/60000 (95%)] Loss: -1030.536377\n",
      "    epoch          : 58\n",
      "    loss           : -1012.1449376337946\n",
      "Train Epoch: 59 [512/60000 (1%)] Loss: -1040.980347\n",
      "Train Epoch: 59 [11776/60000 (20%)] Loss: -1076.791138\n",
      "Train Epoch: 59 [23040/60000 (38%)] Loss: -1006.764221\n",
      "Train Epoch: 59 [34304/60000 (57%)] Loss: -1137.094360\n",
      "Train Epoch: 59 [45568/60000 (76%)] Loss: -1066.459229\n",
      "Train Epoch: 59 [56832/60000 (95%)] Loss: -1035.705811\n",
      "    epoch          : 59\n",
      "    loss           : -1033.410612289515\n",
      "Train Epoch: 60 [512/60000 (1%)] Loss: -1157.898926\n",
      "Train Epoch: 60 [11776/60000 (20%)] Loss: -1004.547852\n",
      "Train Epoch: 60 [23040/60000 (38%)] Loss: -994.861206\n",
      "Train Epoch: 60 [34304/60000 (57%)] Loss: -970.271484\n",
      "Train Epoch: 60 [45568/60000 (76%)] Loss: -1047.382812\n",
      "Train Epoch: 60 [56832/60000 (95%)] Loss: -1071.605225\n",
      "    epoch          : 60\n",
      "    loss           : -1029.7013720496227\n",
      "Train Epoch: 61 [512/60000 (1%)] Loss: -1092.545898\n",
      "Train Epoch: 61 [11776/60000 (20%)] Loss: -1042.512451\n",
      "Train Epoch: 61 [23040/60000 (38%)] Loss: -921.649109\n",
      "Train Epoch: 61 [34304/60000 (57%)] Loss: -1056.079346\n",
      "Train Epoch: 61 [45568/60000 (76%)] Loss: -771.173096\n",
      "Train Epoch: 61 [56832/60000 (95%)] Loss: -1113.978271\n",
      "    epoch          : 61\n",
      "    loss           : -1025.2297037415585\n",
      "Train Epoch: 62 [512/60000 (1%)] Loss: -1136.450928\n",
      "Train Epoch: 62 [11776/60000 (20%)] Loss: -1060.400146\n",
      "Train Epoch: 62 [23040/60000 (38%)] Loss: -946.212036\n",
      "Train Epoch: 62 [34304/60000 (57%)] Loss: -961.642212\n",
      "Train Epoch: 62 [45568/60000 (76%)] Loss: -973.869263\n",
      "Train Epoch: 62 [56832/60000 (95%)] Loss: -985.185242\n",
      "    epoch          : 62\n",
      "    loss           : -1033.1053663350767\n",
      "Train Epoch: 63 [512/60000 (1%)] Loss: -1090.119873\n",
      "Train Epoch: 63 [11776/60000 (20%)] Loss: -1088.461792\n",
      "Train Epoch: 63 [23040/60000 (38%)] Loss: -985.119385\n",
      "Train Epoch: 63 [34304/60000 (57%)] Loss: -1086.366943\n",
      "Train Epoch: 63 [45568/60000 (76%)] Loss: -1128.252197\n",
      "Train Epoch: 63 [56832/60000 (95%)] Loss: -1207.264038\n",
      "    epoch          : 63\n",
      "    loss           : -1029.6206399518892\n",
      "Train Epoch: 64 [512/60000 (1%)] Loss: -811.368652\n",
      "Train Epoch: 64 [11776/60000 (20%)] Loss: -1064.122314\n",
      "Train Epoch: 64 [23040/60000 (38%)] Loss: -1019.765320\n",
      "Train Epoch: 64 [34304/60000 (57%)] Loss: -1122.706055\n",
      "Train Epoch: 64 [45568/60000 (76%)] Loss: -976.226135\n",
      "Train Epoch: 64 [56832/60000 (95%)] Loss: -1118.546021\n",
      "    epoch          : 64\n",
      "    loss           : -1048.614979372186\n",
      "Train Epoch: 65 [512/60000 (1%)] Loss: -1021.768066\n",
      "Train Epoch: 65 [11776/60000 (20%)] Loss: -1075.872192\n",
      "Train Epoch: 65 [23040/60000 (38%)] Loss: -1072.503906\n",
      "Train Epoch: 65 [34304/60000 (57%)] Loss: -1071.447998\n",
      "Train Epoch: 65 [45568/60000 (76%)] Loss: -885.984741\n",
      "Train Epoch: 65 [56832/60000 (95%)] Loss: -811.551270\n",
      "    epoch          : 65\n",
      "    loss           : -1040.2828017412605\n",
      "Train Epoch: 66 [512/60000 (1%)] Loss: -991.163330\n",
      "Train Epoch: 66 [11776/60000 (20%)] Loss: -1075.207275\n",
      "Train Epoch: 66 [23040/60000 (38%)] Loss: -1140.121582\n",
      "Train Epoch: 66 [34304/60000 (57%)] Loss: -937.732178\n",
      "Train Epoch: 66 [45568/60000 (76%)] Loss: -1063.281982\n",
      "Train Epoch: 66 [56832/60000 (95%)] Loss: -926.351440\n",
      "    epoch          : 66\n",
      "    loss           : -1038.4879355565304\n",
      "Train Epoch: 67 [512/60000 (1%)] Loss: -1124.091187\n",
      "Train Epoch: 67 [11776/60000 (20%)] Loss: -764.507446\n",
      "Train Epoch: 67 [23040/60000 (38%)] Loss: -1099.364868\n",
      "Train Epoch: 67 [34304/60000 (57%)] Loss: -943.987793\n",
      "Train Epoch: 67 [45568/60000 (76%)] Loss: -1085.948120\n",
      "Train Epoch: 67 [56832/60000 (95%)] Loss: -1030.520874\n",
      "    epoch          : 67\n",
      "    loss           : -1031.992646815413\n",
      "Train Epoch: 68 [512/60000 (1%)] Loss: -965.706848\n",
      "Train Epoch: 68 [11776/60000 (20%)] Loss: -1074.124512\n",
      "Train Epoch: 68 [23040/60000 (38%)] Loss: -1193.507202\n",
      "Train Epoch: 68 [34304/60000 (57%)] Loss: -1075.491699\n",
      "Train Epoch: 68 [45568/60000 (76%)] Loss: -1039.060059\n",
      "Train Epoch: 68 [56832/60000 (95%)] Loss: -1081.159790\n",
      "    epoch          : 68\n",
      "    loss           : -1035.4210532667946\n",
      "Train Epoch: 69 [512/60000 (1%)] Loss: -894.764954\n",
      "Train Epoch: 69 [11776/60000 (20%)] Loss: -954.235596\n",
      "Train Epoch: 69 [23040/60000 (38%)] Loss: -1116.865723\n",
      "Train Epoch: 69 [34304/60000 (57%)] Loss: -1017.830811\n",
      "Train Epoch: 69 [45568/60000 (76%)] Loss: -925.249817\n",
      "Train Epoch: 69 [56832/60000 (95%)] Loss: -907.450439\n",
      "    epoch          : 69\n",
      "    loss           : -1032.4941823495983\n",
      "Train Epoch: 70 [512/60000 (1%)] Loss: -1060.534424\n",
      "Train Epoch: 70 [11776/60000 (20%)] Loss: -1058.767822\n",
      "Train Epoch: 70 [23040/60000 (38%)] Loss: -1111.090210\n",
      "Train Epoch: 70 [34304/60000 (57%)] Loss: -970.107056\n",
      "Train Epoch: 70 [45568/60000 (76%)] Loss: -1153.177368\n",
      "Train Epoch: 70 [56832/60000 (95%)] Loss: -908.181335\n",
      "    epoch          : 70\n",
      "    loss           : -1022.7653044792218\n",
      "Train Epoch: 71 [512/60000 (1%)] Loss: -1006.904663\n",
      "Train Epoch: 71 [11776/60000 (20%)] Loss: -1149.544189\n",
      "Train Epoch: 71 [23040/60000 (38%)] Loss: -984.689148\n",
      "Train Epoch: 71 [34304/60000 (57%)] Loss: -1038.255493\n",
      "Train Epoch: 71 [45568/60000 (76%)] Loss: -1138.150146\n",
      "Train Epoch: 71 [56832/60000 (95%)] Loss: -1146.002441\n",
      "    epoch          : 71\n",
      "    loss           : -1044.1515980521165\n",
      "Train Epoch: 72 [512/60000 (1%)] Loss: -1147.664551\n",
      "Train Epoch: 72 [11776/60000 (20%)] Loss: -1014.353271\n",
      "Train Epoch: 72 [23040/60000 (38%)] Loss: -1146.681641\n",
      "Train Epoch: 72 [34304/60000 (57%)] Loss: -950.535522\n",
      "Train Epoch: 72 [45568/60000 (76%)] Loss: -1040.903076\n",
      "Train Epoch: 72 [56832/60000 (95%)] Loss: -998.075806\n",
      "    epoch          : 72\n",
      "    loss           : -1031.7112844003796\n",
      "Train Epoch: 73 [512/60000 (1%)] Loss: -1043.204346\n",
      "Train Epoch: 73 [11776/60000 (20%)] Loss: -1129.224854\n",
      "Train Epoch: 73 [23040/60000 (38%)] Loss: -1044.112183\n",
      "Train Epoch: 73 [34304/60000 (57%)] Loss: -1078.385742\n",
      "Train Epoch: 73 [45568/60000 (76%)] Loss: -997.721558\n",
      "Train Epoch: 73 [56832/60000 (95%)] Loss: -1042.175171\n",
      "    epoch          : 73\n",
      "    loss           : -1026.265690173133\n",
      "Train Epoch: 74 [512/60000 (1%)] Loss: -1041.480591\n",
      "Train Epoch: 74 [11776/60000 (20%)] Loss: -1072.659302\n",
      "Train Epoch: 74 [23040/60000 (38%)] Loss: -1142.848877\n",
      "Train Epoch: 74 [34304/60000 (57%)] Loss: -1241.254395\n",
      "Train Epoch: 74 [45568/60000 (76%)] Loss: -979.026794\n",
      "Train Epoch: 74 [56832/60000 (95%)] Loss: -1126.633301\n",
      "    epoch          : 74\n",
      "    loss           : -1045.7473610053628\n",
      "Train Epoch: 75 [512/60000 (1%)] Loss: -839.593201\n",
      "Train Epoch: 75 [11776/60000 (20%)] Loss: -1167.792114\n",
      "Train Epoch: 75 [23040/60000 (38%)] Loss: -832.274353\n",
      "Train Epoch: 75 [34304/60000 (57%)] Loss: -1190.147095\n",
      "Train Epoch: 75 [45568/60000 (76%)] Loss: -903.455872\n",
      "Train Epoch: 75 [56832/60000 (95%)] Loss: -1094.899658\n",
      "    epoch          : 75\n",
      "    loss           : -1044.3215985486736\n",
      "Train Epoch: 76 [512/60000 (1%)] Loss: -1168.401611\n",
      "Train Epoch: 76 [11776/60000 (20%)] Loss: -951.067078\n",
      "Train Epoch: 76 [23040/60000 (38%)] Loss: -946.118164\n",
      "Train Epoch: 76 [34304/60000 (57%)] Loss: -884.137695\n",
      "Train Epoch: 76 [45568/60000 (76%)] Loss: -881.615112\n",
      "Train Epoch: 76 [56832/60000 (95%)] Loss: -920.379395\n",
      "    epoch          : 76\n",
      "    loss           : -1045.0835933362023\n",
      "Train Epoch: 77 [512/60000 (1%)] Loss: -1102.491821\n",
      "Train Epoch: 77 [11776/60000 (20%)] Loss: -966.301270\n",
      "Train Epoch: 77 [23040/60000 (38%)] Loss: -936.854980\n",
      "Train Epoch: 77 [34304/60000 (57%)] Loss: -1064.737793\n",
      "Train Epoch: 77 [45568/60000 (76%)] Loss: -1052.310669\n",
      "Train Epoch: 77 [56832/60000 (95%)] Loss: -1152.794922\n",
      "    epoch          : 77\n",
      "    loss           : -1057.8260151491327\n",
      "Train Epoch: 78 [512/60000 (1%)] Loss: -996.635437\n",
      "Train Epoch: 78 [11776/60000 (20%)] Loss: -1026.698486\n",
      "Train Epoch: 78 [23040/60000 (38%)] Loss: -913.943420\n",
      "Train Epoch: 78 [34304/60000 (57%)] Loss: -1230.901855\n",
      "Train Epoch: 78 [45568/60000 (76%)] Loss: -1159.046509\n",
      "Train Epoch: 78 [56832/60000 (95%)] Loss: -1223.947266\n",
      "    epoch          : 78\n",
      "    loss           : -1074.430844236902\n",
      "Train Epoch: 79 [512/60000 (1%)] Loss: -931.173462\n",
      "Train Epoch: 79 [11776/60000 (20%)] Loss: -869.739502\n",
      "Train Epoch: 79 [23040/60000 (38%)] Loss: -895.328369\n",
      "Train Epoch: 79 [34304/60000 (57%)] Loss: -1063.698486\n",
      "Train Epoch: 79 [45568/60000 (76%)] Loss: -915.248413\n",
      "Train Epoch: 79 [56832/60000 (95%)] Loss: -1144.910034\n",
      "    epoch          : 79\n",
      "    loss           : -1056.1230775649938\n",
      "Train Epoch: 80 [512/60000 (1%)] Loss: -995.277649\n",
      "Train Epoch: 80 [11776/60000 (20%)] Loss: -1034.698975\n",
      "Train Epoch: 80 [23040/60000 (38%)] Loss: -1159.082031\n",
      "Train Epoch: 80 [34304/60000 (57%)] Loss: -1192.593628\n",
      "Train Epoch: 80 [45568/60000 (76%)] Loss: -1167.019775\n",
      "Train Epoch: 80 [56832/60000 (95%)] Loss: -1204.562256\n",
      "    epoch          : 80\n",
      "    loss           : -1059.711170778436\n",
      "Train Epoch: 81 [512/60000 (1%)] Loss: -1105.143433\n",
      "Train Epoch: 81 [11776/60000 (20%)] Loss: -1055.336060\n",
      "Train Epoch: 81 [23040/60000 (38%)] Loss: -991.073242\n",
      "Train Epoch: 81 [34304/60000 (57%)] Loss: -1016.743530\n",
      "Train Epoch: 81 [45568/60000 (76%)] Loss: -911.220825\n",
      "Train Epoch: 81 [56832/60000 (95%)] Loss: -1223.600830\n",
      "    epoch          : 81\n",
      "    loss           : -1058.2709374724136\n",
      "Train Epoch: 82 [512/60000 (1%)] Loss: -1108.627686\n",
      "Train Epoch: 82 [11776/60000 (20%)] Loss: -1085.005859\n",
      "Train Epoch: 82 [23040/60000 (38%)] Loss: -1115.264160\n",
      "Train Epoch: 82 [34304/60000 (57%)] Loss: -1124.171265\n",
      "Train Epoch: 82 [45568/60000 (76%)] Loss: -1114.490479\n",
      "Train Epoch: 82 [56832/60000 (95%)] Loss: -1186.781006\n",
      "    epoch          : 82\n",
      "    loss           : -1045.847700905665\n",
      "Train Epoch: 83 [512/60000 (1%)] Loss: -1142.014404\n",
      "Train Epoch: 83 [11776/60000 (20%)] Loss: -1070.460449\n",
      "Train Epoch: 83 [23040/60000 (38%)] Loss: -1119.155762\n",
      "Train Epoch: 83 [34304/60000 (57%)] Loss: -957.570496\n",
      "Train Epoch: 83 [45568/60000 (76%)] Loss: -1046.678223\n",
      "Train Epoch: 83 [56832/60000 (95%)] Loss: -1171.227295\n",
      "    epoch          : 83\n",
      "    loss           : -1064.9562783106571\n",
      "Train Epoch: 84 [512/60000 (1%)] Loss: -850.791016\n",
      "Train Epoch: 84 [11776/60000 (20%)] Loss: -1114.326050\n",
      "Train Epoch: 84 [23040/60000 (38%)] Loss: -1152.180420\n",
      "Train Epoch: 84 [34304/60000 (57%)] Loss: -841.305481\n",
      "Train Epoch: 84 [45568/60000 (76%)] Loss: -1030.145020\n",
      "Train Epoch: 84 [56832/60000 (95%)] Loss: -1031.603516\n",
      "    epoch          : 84\n",
      "    loss           : -1054.1697810113767\n",
      "Train Epoch: 85 [512/60000 (1%)] Loss: -1097.712158\n",
      "Train Epoch: 85 [11776/60000 (20%)] Loss: -1079.316895\n",
      "Train Epoch: 85 [23040/60000 (38%)] Loss: -1128.116211\n",
      "Train Epoch: 85 [34304/60000 (57%)] Loss: -1115.674316\n",
      "Train Epoch: 85 [45568/60000 (76%)] Loss: -1174.148071\n",
      "Train Epoch: 85 [56832/60000 (95%)] Loss: -1225.355469\n",
      "    epoch          : 85\n",
      "    loss           : -1049.7932039250088\n",
      "Train Epoch: 86 [512/60000 (1%)] Loss: -918.592346\n",
      "Train Epoch: 86 [11776/60000 (20%)] Loss: -1053.542969\n",
      "Train Epoch: 86 [23040/60000 (38%)] Loss: -943.976990\n",
      "Train Epoch: 86 [34304/60000 (57%)] Loss: -854.495483\n",
      "Train Epoch: 86 [45568/60000 (76%)] Loss: -1170.474121\n",
      "Train Epoch: 86 [56832/60000 (95%)] Loss: -925.124634\n",
      "    epoch          : 86\n",
      "    loss           : -1061.0821853896318\n",
      "Train Epoch: 87 [512/60000 (1%)] Loss: -1196.891235\n",
      "Train Epoch: 87 [11776/60000 (20%)] Loss: -1157.063843\n",
      "Train Epoch: 87 [23040/60000 (38%)] Loss: -1003.046875\n",
      "Train Epoch: 87 [34304/60000 (57%)] Loss: -1135.858887\n",
      "Train Epoch: 87 [45568/60000 (76%)] Loss: -1193.689453\n",
      "Train Epoch: 87 [56832/60000 (95%)] Loss: -949.376221\n",
      "    epoch          : 87\n",
      "    loss           : -1065.7106045652918\n",
      "Train Epoch: 88 [512/60000 (1%)] Loss: -1101.639160\n",
      "Train Epoch: 88 [11776/60000 (20%)] Loss: -1138.766724\n",
      "Train Epoch: 88 [23040/60000 (38%)] Loss: -1040.651001\n",
      "Train Epoch: 88 [34304/60000 (57%)] Loss: -1152.695801\n",
      "Train Epoch: 88 [45568/60000 (76%)] Loss: -1053.903687\n",
      "Train Epoch: 88 [56832/60000 (95%)] Loss: -950.991516\n",
      "    epoch          : 88\n",
      "    loss           : -1058.4700917389434\n",
      "Train Epoch: 89 [512/60000 (1%)] Loss: -998.335571\n",
      "Train Epoch: 89 [11776/60000 (20%)] Loss: -946.789062\n",
      "Train Epoch: 89 [23040/60000 (38%)] Loss: -1240.144897\n",
      "Train Epoch: 89 [34304/60000 (57%)] Loss: -1118.696777\n",
      "Train Epoch: 89 [45568/60000 (76%)] Loss: -865.595215\n",
      "Train Epoch: 89 [56832/60000 (95%)] Loss: -1067.906128\n",
      "    epoch          : 89\n",
      "    loss           : -1073.023438534494\n",
      "Train Epoch: 90 [512/60000 (1%)] Loss: -989.415222\n",
      "Train Epoch: 90 [11776/60000 (20%)] Loss: -927.080566\n",
      "Train Epoch: 90 [23040/60000 (38%)] Loss: -965.518005\n",
      "Train Epoch: 90 [34304/60000 (57%)] Loss: -811.809692\n",
      "Train Epoch: 90 [45568/60000 (76%)] Loss: -954.739624\n",
      "Train Epoch: 90 [56832/60000 (95%)] Loss: -867.981506\n",
      "    epoch          : 90\n",
      "    loss           : -1053.7350720766574\n",
      "Train Epoch: 91 [512/60000 (1%)] Loss: -1179.118408\n",
      "Train Epoch: 91 [11776/60000 (20%)] Loss: -1000.376953\n",
      "Train Epoch: 91 [23040/60000 (38%)] Loss: -979.654480\n",
      "Train Epoch: 91 [34304/60000 (57%)] Loss: -898.383972\n",
      "Train Epoch: 91 [45568/60000 (76%)] Loss: -1105.811890\n",
      "Train Epoch: 91 [56832/60000 (95%)] Loss: -1162.507080\n",
      "    epoch          : 91\n",
      "    loss           : -1086.8845138980844\n",
      "Train Epoch: 92 [512/60000 (1%)] Loss: -1197.269775\n",
      "Train Epoch: 92 [11776/60000 (20%)] Loss: -1026.964111\n",
      "Train Epoch: 92 [23040/60000 (38%)] Loss: -981.484253\n",
      "Train Epoch: 92 [34304/60000 (57%)] Loss: -1189.150391\n",
      "Train Epoch: 92 [45568/60000 (76%)] Loss: -972.918335\n",
      "Train Epoch: 92 [56832/60000 (95%)] Loss: -984.911133\n",
      "    epoch          : 92\n",
      "    loss           : -1056.5499545167395\n",
      "Train Epoch: 93 [512/60000 (1%)] Loss: -1192.007812\n",
      "Train Epoch: 93 [11776/60000 (20%)] Loss: -1230.255005\n",
      "Train Epoch: 93 [23040/60000 (38%)] Loss: -1053.557129\n",
      "Train Epoch: 93 [34304/60000 (57%)] Loss: -963.455017\n",
      "Train Epoch: 93 [45568/60000 (76%)] Loss: -1054.248413\n",
      "Train Epoch: 93 [56832/60000 (95%)] Loss: -1115.236450\n",
      "    epoch          : 93\n",
      "    loss           : -1059.1958430230954\n",
      "Train Epoch: 94 [512/60000 (1%)] Loss: -930.406250\n",
      "Train Epoch: 94 [11776/60000 (20%)] Loss: -929.479248\n",
      "Train Epoch: 94 [23040/60000 (38%)] Loss: -1118.999634\n",
      "Train Epoch: 94 [34304/60000 (57%)] Loss: -1108.421021\n",
      "Train Epoch: 94 [45568/60000 (76%)] Loss: -957.629333\n",
      "Train Epoch: 94 [56832/60000 (95%)] Loss: -1102.804199\n",
      "    epoch          : 94\n",
      "    loss           : -1062.8813231732213\n",
      "Train Epoch: 95 [512/60000 (1%)] Loss: -1148.288330\n",
      "Train Epoch: 95 [11776/60000 (20%)] Loss: -1132.351562\n",
      "Train Epoch: 95 [23040/60000 (38%)] Loss: -1051.685669\n",
      "Train Epoch: 95 [34304/60000 (57%)] Loss: -1060.690918\n",
      "Train Epoch: 95 [45568/60000 (76%)] Loss: -970.396057\n",
      "Train Epoch: 95 [56832/60000 (95%)] Loss: -937.573181\n",
      "    epoch          : 95\n",
      "    loss           : -1073.3575736008122\n",
      "Train Epoch: 96 [512/60000 (1%)] Loss: -1261.938721\n",
      "Train Epoch: 96 [11776/60000 (20%)] Loss: -1115.418213\n",
      "Train Epoch: 96 [23040/60000 (38%)] Loss: -994.468628\n",
      "Train Epoch: 96 [34304/60000 (57%)] Loss: -1173.760498\n",
      "Train Epoch: 96 [45568/60000 (76%)] Loss: -1086.581055\n",
      "Train Epoch: 96 [56832/60000 (95%)] Loss: -1187.023071\n",
      "    epoch          : 96\n",
      "    loss           : -1084.0326755329713\n",
      "Train Epoch: 97 [512/60000 (1%)] Loss: -1112.883789\n",
      "Train Epoch: 97 [11776/60000 (20%)] Loss: -1252.496826\n",
      "Train Epoch: 97 [23040/60000 (38%)] Loss: -1116.504272\n",
      "Train Epoch: 97 [34304/60000 (57%)] Loss: -804.433533\n",
      "Train Epoch: 97 [45568/60000 (76%)] Loss: -1118.416504\n",
      "Train Epoch: 97 [56832/60000 (95%)] Loss: -973.503662\n",
      "    epoch          : 97\n",
      "    loss           : -1065.9752869686838\n",
      "Train Epoch: 98 [512/60000 (1%)] Loss: -1187.592285\n",
      "Train Epoch: 98 [11776/60000 (20%)] Loss: -1132.427734\n",
      "Train Epoch: 98 [23040/60000 (38%)] Loss: -1127.902466\n",
      "Train Epoch: 98 [34304/60000 (57%)] Loss: -1234.060303\n",
      "Train Epoch: 98 [45568/60000 (76%)] Loss: -1049.360718\n",
      "Train Epoch: 98 [56832/60000 (95%)] Loss: -1008.529785\n",
      "    epoch          : 98\n",
      "    loss           : -1084.2855048745366\n",
      "Train Epoch: 99 [512/60000 (1%)] Loss: -1225.551514\n",
      "Train Epoch: 99 [11776/60000 (20%)] Loss: -1067.693359\n",
      "Train Epoch: 99 [23040/60000 (38%)] Loss: -977.401184\n",
      "Train Epoch: 99 [34304/60000 (57%)] Loss: -922.084961\n",
      "Train Epoch: 99 [45568/60000 (76%)] Loss: -1167.493286\n",
      "Train Epoch: 99 [56832/60000 (95%)] Loss: -806.684998\n",
      "    epoch          : 99\n",
      "    loss           : -1078.4685134456656\n",
      "Train Epoch: 100 [512/60000 (1%)] Loss: -1209.645752\n",
      "Train Epoch: 100 [11776/60000 (20%)] Loss: -1115.023438\n",
      "Train Epoch: 100 [23040/60000 (38%)] Loss: -945.818848\n",
      "Train Epoch: 100 [34304/60000 (57%)] Loss: -1091.472534\n",
      "Train Epoch: 100 [45568/60000 (76%)] Loss: -1120.022583\n",
      "Train Epoch: 100 [56832/60000 (95%)] Loss: -1209.908936\n",
      "    epoch          : 100\n",
      "    loss           : -1089.1611998822057\n",
      "Saving checkpoint: saved/models/Mnist_DeepGenerativeOperad/0127_111843/checkpoint-epoch100.pth ...\n",
      "Train Epoch: 101 [512/60000 (1%)] Loss: -1139.091553\n",
      "Train Epoch: 101 [11776/60000 (20%)] Loss: -1111.073120\n",
      "Train Epoch: 101 [23040/60000 (38%)] Loss: -1168.375610\n",
      "Train Epoch: 101 [34304/60000 (57%)] Loss: -1218.020508\n",
      "Train Epoch: 101 [45568/60000 (76%)] Loss: -1012.947510\n",
      "Train Epoch: 101 [56832/60000 (95%)] Loss: -1126.983887\n",
      "    epoch          : 101\n",
      "    loss           : -1078.3767739850923\n",
      "Train Epoch: 102 [512/60000 (1%)] Loss: -1112.084717\n",
      "Train Epoch: 102 [11776/60000 (20%)] Loss: -1021.445496\n",
      "Train Epoch: 102 [23040/60000 (38%)] Loss: -1041.643311\n",
      "Train Epoch: 102 [34304/60000 (57%)] Loss: -991.434998\n",
      "Train Epoch: 102 [45568/60000 (76%)] Loss: -1073.187134\n",
      "Train Epoch: 102 [56832/60000 (95%)] Loss: -1121.195190\n",
      "    epoch          : 102\n",
      "    loss           : -1087.256035583841\n",
      "Train Epoch: 103 [512/60000 (1%)] Loss: -1194.056885\n",
      "Train Epoch: 103 [11776/60000 (20%)] Loss: -1275.542603\n",
      "Train Epoch: 103 [23040/60000 (38%)] Loss: -1082.307495\n",
      "Train Epoch: 103 [34304/60000 (57%)] Loss: -1130.110107\n",
      "Train Epoch: 103 [45568/60000 (76%)] Loss: -1151.198975\n",
      "Train Epoch: 103 [56832/60000 (95%)] Loss: -1138.625610\n",
      "    epoch          : 103\n",
      "    loss           : -1084.627380888341\n",
      "Train Epoch: 104 [512/60000 (1%)] Loss: -1228.614868\n",
      "Train Epoch: 104 [11776/60000 (20%)] Loss: -1109.926758\n",
      "Train Epoch: 104 [23040/60000 (38%)] Loss: -1023.401611\n",
      "Train Epoch: 104 [34304/60000 (57%)] Loss: -760.308228\n",
      "Train Epoch: 104 [45568/60000 (76%)] Loss: -1097.047607\n",
      "Train Epoch: 104 [56832/60000 (95%)] Loss: -1114.081299\n",
      "    epoch          : 104\n",
      "    loss           : -1062.7779401358912\n",
      "Train Epoch: 105 [512/60000 (1%)] Loss: -982.579102\n",
      "Train Epoch: 105 [11776/60000 (20%)] Loss: -1105.772217\n",
      "Train Epoch: 105 [23040/60000 (38%)] Loss: -1211.806885\n",
      "Train Epoch: 105 [34304/60000 (57%)] Loss: -1236.903320\n",
      "Train Epoch: 105 [45568/60000 (76%)] Loss: -1247.936401\n",
      "Train Epoch: 105 [56832/60000 (95%)] Loss: -1155.501953\n",
      "    epoch          : 105\n",
      "    loss           : -1095.3418318753863\n",
      "Train Epoch: 106 [512/60000 (1%)] Loss: -1096.180176\n",
      "Train Epoch: 106 [11776/60000 (20%)] Loss: -1006.278992\n",
      "Train Epoch: 106 [23040/60000 (38%)] Loss: -1259.151611\n",
      "Train Epoch: 106 [34304/60000 (57%)] Loss: -1015.223572\n",
      "Train Epoch: 106 [45568/60000 (76%)] Loss: -1101.258789\n",
      "Train Epoch: 106 [56832/60000 (95%)] Loss: -1212.936035\n",
      "    epoch          : 106\n",
      "    loss           : -1099.5693959381622\n",
      "Train Epoch: 107 [512/60000 (1%)] Loss: -986.028259\n",
      "Train Epoch: 107 [11776/60000 (20%)] Loss: -928.874084\n",
      "Train Epoch: 107 [23040/60000 (38%)] Loss: -1093.556885\n",
      "Train Epoch: 107 [34304/60000 (57%)] Loss: -1075.033936\n",
      "Train Epoch: 107 [45568/60000 (76%)] Loss: -1082.245483\n",
      "Train Epoch: 107 [56832/60000 (95%)] Loss: -1149.517578\n",
      "    epoch          : 107\n",
      "    loss           : -1080.445666641839\n",
      "Train Epoch: 108 [512/60000 (1%)] Loss: -1148.638306\n",
      "Train Epoch: 108 [11776/60000 (20%)] Loss: -1159.936279\n",
      "Train Epoch: 108 [23040/60000 (38%)] Loss: -1080.051514\n",
      "Train Epoch: 108 [34304/60000 (57%)] Loss: -1201.256104\n",
      "Train Epoch: 108 [45568/60000 (76%)] Loss: -1010.530273\n",
      "Train Epoch: 108 [56832/60000 (95%)] Loss: -1218.630005\n",
      "    epoch          : 108\n",
      "    loss           : -1091.1577634649761\n",
      "Train Epoch: 109 [512/60000 (1%)] Loss: -966.932434\n",
      "Train Epoch: 109 [11776/60000 (20%)] Loss: -1175.275879\n",
      "Train Epoch: 109 [23040/60000 (38%)] Loss: -990.500305\n",
      "Train Epoch: 109 [34304/60000 (57%)] Loss: -836.027344\n",
      "Train Epoch: 109 [45568/60000 (76%)] Loss: -1116.538696\n",
      "Train Epoch: 109 [56832/60000 (95%)] Loss: -1165.725586\n",
      "    epoch          : 109\n",
      "    loss           : -1060.9668158407267\n",
      "Train Epoch: 110 [512/60000 (1%)] Loss: -1166.722778\n",
      "Train Epoch: 110 [11776/60000 (20%)] Loss: -1200.959473\n",
      "Train Epoch: 110 [23040/60000 (38%)] Loss: -1186.972046\n",
      "Train Epoch: 110 [34304/60000 (57%)] Loss: -1014.130859\n",
      "Train Epoch: 110 [45568/60000 (76%)] Loss: -842.386902\n",
      "Train Epoch: 110 [56832/60000 (95%)] Loss: -1137.591309\n",
      "    epoch          : 110\n",
      "    loss           : -1078.449316164868\n",
      "Train Epoch: 111 [512/60000 (1%)] Loss: -942.222534\n",
      "Train Epoch: 111 [11776/60000 (20%)] Loss: -1215.973145\n",
      "Train Epoch: 111 [23040/60000 (38%)] Loss: -1261.729614\n",
      "Train Epoch: 111 [34304/60000 (57%)] Loss: -1237.457153\n",
      "Train Epoch: 111 [45568/60000 (76%)] Loss: -1077.482910\n",
      "Train Epoch: 111 [56832/60000 (95%)] Loss: -1069.827515\n",
      "    epoch          : 111\n",
      "    loss           : -1086.6516720184497\n",
      "Train Epoch: 112 [512/60000 (1%)] Loss: -1108.158081\n",
      "Train Epoch: 112 [11776/60000 (20%)] Loss: -1212.773682\n",
      "Train Epoch: 112 [23040/60000 (38%)] Loss: -1118.904053\n",
      "Train Epoch: 112 [34304/60000 (57%)] Loss: -1152.042236\n",
      "Train Epoch: 112 [45568/60000 (76%)] Loss: -858.846924\n",
      "Train Epoch: 112 [56832/60000 (95%)] Loss: -1125.350952\n",
      "    epoch          : 112\n",
      "    loss           : -1084.3046606031514\n",
      "Train Epoch: 113 [512/60000 (1%)] Loss: -1254.146240\n",
      "Train Epoch: 113 [11776/60000 (20%)] Loss: -933.811768\n",
      "Train Epoch: 113 [23040/60000 (38%)] Loss: -1139.199829\n",
      "Train Epoch: 113 [34304/60000 (57%)] Loss: -1089.464600\n",
      "Train Epoch: 113 [45568/60000 (76%)] Loss: -1139.389526\n",
      "Train Epoch: 113 [56832/60000 (95%)] Loss: -1198.111938\n",
      "    epoch          : 113\n",
      "    loss           : -1083.6962854417704\n",
      "Train Epoch: 114 [512/60000 (1%)] Loss: -934.570190\n",
      "Train Epoch: 114 [11776/60000 (20%)] Loss: -931.679749\n",
      "Train Epoch: 114 [23040/60000 (38%)] Loss: -1191.579834\n",
      "Train Epoch: 114 [34304/60000 (57%)] Loss: -1097.409180\n",
      "Train Epoch: 114 [45568/60000 (76%)] Loss: -1059.319824\n",
      "Train Epoch: 114 [56832/60000 (95%)] Loss: -1098.772583\n",
      "    epoch          : 114\n",
      "    loss           : -1099.322036139709\n",
      "Train Epoch: 115 [512/60000 (1%)] Loss: -866.507935\n",
      "Train Epoch: 115 [11776/60000 (20%)] Loss: -1075.292236\n",
      "Train Epoch: 115 [23040/60000 (38%)] Loss: -1011.639954\n",
      "Train Epoch: 115 [34304/60000 (57%)] Loss: -938.513428\n",
      "Train Epoch: 115 [45568/60000 (76%)] Loss: -1214.090698\n",
      "Train Epoch: 115 [56832/60000 (95%)] Loss: -1219.726929\n",
      "    epoch          : 115\n",
      "    loss           : -1065.0866809564795\n",
      "Train Epoch: 116 [512/60000 (1%)] Loss: -982.845093\n",
      "Train Epoch: 116 [11776/60000 (20%)] Loss: -1075.684814\n",
      "Train Epoch: 116 [23040/60000 (38%)] Loss: -1033.698730\n",
      "Train Epoch: 116 [34304/60000 (57%)] Loss: -1130.820068\n",
      "Train Epoch: 116 [45568/60000 (76%)] Loss: -1214.321045\n",
      "Train Epoch: 116 [56832/60000 (95%)] Loss: -1282.325684\n",
      "    epoch          : 116\n",
      "    loss           : -1075.4937376895193\n",
      "Train Epoch: 117 [512/60000 (1%)] Loss: -1046.679932\n",
      "Train Epoch: 117 [11776/60000 (20%)] Loss: -991.854370\n",
      "Train Epoch: 117 [23040/60000 (38%)] Loss: -1012.746643\n",
      "Train Epoch: 117 [34304/60000 (57%)] Loss: -1167.193604\n",
      "Train Epoch: 117 [45568/60000 (76%)] Loss: -1231.586304\n",
      "Train Epoch: 117 [56832/60000 (95%)] Loss: -1090.821289\n",
      "    epoch          : 117\n",
      "    loss           : -1084.4146852654926\n",
      "Train Epoch: 118 [512/60000 (1%)] Loss: -979.558716\n",
      "Train Epoch: 118 [11776/60000 (20%)] Loss: -984.248779\n",
      "Train Epoch: 118 [23040/60000 (38%)] Loss: -1145.890381\n",
      "Train Epoch: 118 [34304/60000 (57%)] Loss: -1119.256714\n",
      "Train Epoch: 118 [45568/60000 (76%)] Loss: -1203.646240\n",
      "Train Epoch: 118 [56832/60000 (95%)] Loss: -935.843018\n",
      "    epoch          : 118\n",
      "    loss           : -1060.597804699914\n",
      "Train Epoch: 119 [512/60000 (1%)] Loss: -836.247437\n",
      "Train Epoch: 119 [11776/60000 (20%)] Loss: -1092.163208\n",
      "Train Epoch: 119 [23040/60000 (38%)] Loss: -984.739685\n",
      "Train Epoch: 119 [34304/60000 (57%)] Loss: -937.615967\n",
      "Train Epoch: 119 [45568/60000 (76%)] Loss: -933.112305\n",
      "Train Epoch: 119 [56832/60000 (95%)] Loss: -1118.165771\n",
      "    epoch          : 119\n",
      "    loss           : -1086.5791193213165\n",
      "Train Epoch: 120 [512/60000 (1%)] Loss: -1070.148682\n",
      "Train Epoch: 120 [11776/60000 (20%)] Loss: -1218.074463\n",
      "Train Epoch: 120 [23040/60000 (38%)] Loss: -1202.236450\n",
      "Train Epoch: 120 [34304/60000 (57%)] Loss: -1216.062256\n",
      "Train Epoch: 120 [45568/60000 (76%)] Loss: -994.591187\n",
      "Train Epoch: 120 [56832/60000 (95%)] Loss: -1063.909546\n",
      "    epoch          : 120\n",
      "    loss           : -1076.6856413588011\n",
      "Train Epoch: 121 [512/60000 (1%)] Loss: -1151.271729\n",
      "Train Epoch: 121 [11776/60000 (20%)] Loss: -1153.301636\n",
      "Train Epoch: 121 [23040/60000 (38%)] Loss: -1099.596680\n",
      "Train Epoch: 121 [34304/60000 (57%)] Loss: -1281.152832\n",
      "Train Epoch: 121 [45568/60000 (76%)] Loss: -1054.324463\n",
      "Train Epoch: 121 [56832/60000 (95%)] Loss: -941.031372\n",
      "    epoch          : 121\n",
      "    loss           : -1074.1368290960452\n",
      "Train Epoch: 122 [512/60000 (1%)] Loss: -1118.542725\n",
      "Train Epoch: 122 [11776/60000 (20%)] Loss: -994.118225\n",
      "Train Epoch: 122 [23040/60000 (38%)] Loss: -1204.019775\n",
      "Train Epoch: 122 [34304/60000 (57%)] Loss: -963.091309\n",
      "Train Epoch: 122 [45568/60000 (76%)] Loss: -974.540649\n",
      "Train Epoch: 122 [56832/60000 (95%)] Loss: -843.804626\n",
      "    epoch          : 122\n",
      "    loss           : -1060.677951963608\n",
      "Train Epoch: 123 [512/60000 (1%)] Loss: -1063.885010\n",
      "Train Epoch: 123 [11776/60000 (20%)] Loss: -1026.392822\n",
      "Train Epoch: 123 [23040/60000 (38%)] Loss: -1006.232056\n",
      "Train Epoch: 123 [34304/60000 (57%)] Loss: -1172.231567\n",
      "Train Epoch: 123 [45568/60000 (76%)] Loss: -1072.738281\n",
      "Train Epoch: 123 [56832/60000 (95%)] Loss: -1002.274719\n",
      "    epoch          : 123\n",
      "    loss           : -1089.3368021647136\n",
      "Train Epoch: 124 [512/60000 (1%)] Loss: -1124.922607\n",
      "Train Epoch: 124 [11776/60000 (20%)] Loss: -1225.552124\n",
      "Train Epoch: 124 [23040/60000 (38%)] Loss: -843.116089\n",
      "Train Epoch: 124 [34304/60000 (57%)] Loss: -1007.770874\n",
      "Train Epoch: 124 [45568/60000 (76%)] Loss: -956.816772\n",
      "Train Epoch: 124 [56832/60000 (95%)] Loss: -1150.223877\n",
      "    epoch          : 124\n",
      "    loss           : -1093.2238160903844\n",
      "Train Epoch: 125 [512/60000 (1%)] Loss: -1078.450928\n",
      "Train Epoch: 125 [11776/60000 (20%)] Loss: -1270.179932\n",
      "Train Epoch: 125 [23040/60000 (38%)] Loss: -1211.426392\n",
      "Train Epoch: 125 [34304/60000 (57%)] Loss: -1152.983643\n",
      "Train Epoch: 125 [45568/60000 (76%)] Loss: -995.026001\n",
      "Train Epoch: 125 [56832/60000 (95%)] Loss: -1137.141968\n",
      "    epoch          : 125\n",
      "    loss           : -1104.5233716372043\n",
      "Train Epoch: 126 [512/60000 (1%)] Loss: -910.139465\n",
      "Train Epoch: 126 [11776/60000 (20%)] Loss: -1011.330078\n",
      "Train Epoch: 126 [23040/60000 (38%)] Loss: -1141.533936\n",
      "Train Epoch: 126 [34304/60000 (57%)] Loss: -1117.975586\n",
      "Train Epoch: 126 [45568/60000 (76%)] Loss: -1015.706787\n",
      "Train Epoch: 126 [56832/60000 (95%)] Loss: -1176.477051\n",
      "    epoch          : 126\n",
      "    loss           : -1087.785556254414\n",
      "Train Epoch: 127 [512/60000 (1%)] Loss: -1269.080322\n",
      "Train Epoch: 127 [11776/60000 (20%)] Loss: -1217.081421\n",
      "Train Epoch: 127 [23040/60000 (38%)] Loss: -915.447632\n",
      "Train Epoch: 127 [34304/60000 (57%)] Loss: -879.439941\n",
      "Train Epoch: 127 [45568/60000 (76%)] Loss: -963.301575\n",
      "Train Epoch: 127 [56832/60000 (95%)] Loss: -1124.166748\n",
      "    epoch          : 127\n",
      "    loss           : -1105.2572133554577\n",
      "Train Epoch: 128 [512/60000 (1%)] Loss: -980.964722\n",
      "Train Epoch: 128 [11776/60000 (20%)] Loss: -1104.637451\n",
      "Train Epoch: 128 [23040/60000 (38%)] Loss: -1220.116455\n",
      "Train Epoch: 128 [34304/60000 (57%)] Loss: -1127.043945\n",
      "Train Epoch: 128 [45568/60000 (76%)] Loss: -1046.419189\n",
      "Train Epoch: 128 [56832/60000 (95%)] Loss: -1215.523804\n",
      "    epoch          : 128\n",
      "    loss           : -1082.365619034417\n",
      "Train Epoch: 129 [512/60000 (1%)] Loss: -1042.657471\n",
      "Train Epoch: 129 [11776/60000 (20%)] Loss: -1227.858154\n",
      "Train Epoch: 129 [23040/60000 (38%)] Loss: -1158.071533\n",
      "Train Epoch: 129 [34304/60000 (57%)] Loss: -1224.096436\n",
      "Train Epoch: 129 [45568/60000 (76%)] Loss: -874.299072\n",
      "Train Epoch: 129 [56832/60000 (95%)] Loss: -1206.716431\n",
      "    epoch          : 129\n",
      "    loss           : -1094.4264991889565\n",
      "Train Epoch: 130 [512/60000 (1%)] Loss: -916.523621\n",
      "Train Epoch: 130 [11776/60000 (20%)] Loss: -1145.259155\n",
      "Train Epoch: 130 [23040/60000 (38%)] Loss: -1135.331909\n",
      "Train Epoch: 130 [34304/60000 (57%)] Loss: -832.682068\n",
      "Train Epoch: 130 [45568/60000 (76%)] Loss: -991.557678\n",
      "Train Epoch: 130 [56832/60000 (95%)] Loss: -1082.614136\n",
      "    epoch          : 130\n",
      "    loss           : -1094.912870762712\n",
      "Train Epoch: 131 [512/60000 (1%)] Loss: -1043.786621\n",
      "Train Epoch: 131 [11776/60000 (20%)] Loss: -845.664734\n",
      "Train Epoch: 131 [23040/60000 (38%)] Loss: -1066.515625\n",
      "Train Epoch: 131 [34304/60000 (57%)] Loss: -1061.607422\n",
      "Train Epoch: 131 [45568/60000 (76%)] Loss: -1203.383423\n",
      "Train Epoch: 131 [56832/60000 (95%)] Loss: -1258.425781\n",
      "    epoch          : 131\n",
      "    loss           : -1077.8327886721509\n",
      "Train Epoch: 132 [512/60000 (1%)] Loss: -1252.335205\n",
      "Train Epoch: 132 [11776/60000 (20%)] Loss: -1142.063721\n",
      "Train Epoch: 132 [23040/60000 (38%)] Loss: -1271.803711\n",
      "Train Epoch: 132 [34304/60000 (57%)] Loss: -1301.653076\n",
      "Train Epoch: 132 [45568/60000 (76%)] Loss: -1112.412354\n",
      "Train Epoch: 132 [56832/60000 (95%)] Loss: -1069.139404\n",
      "    epoch          : 132\n",
      "    loss           : -1096.8632553876457\n",
      "Train Epoch: 133 [512/60000 (1%)] Loss: -931.292114\n",
      "Train Epoch: 133 [11776/60000 (20%)] Loss: -1099.202148\n",
      "Train Epoch: 133 [23040/60000 (38%)] Loss: -1123.532104\n",
      "Train Epoch: 133 [34304/60000 (57%)] Loss: -1174.630615\n",
      "Train Epoch: 133 [45568/60000 (76%)] Loss: -1198.431641\n",
      "Train Epoch: 133 [56832/60000 (95%)] Loss: -1059.021851\n",
      "    epoch          : 133\n",
      "    loss           : -1109.4598926608846\n",
      "Train Epoch: 134 [512/60000 (1%)] Loss: -1155.879150\n",
      "Train Epoch: 134 [11776/60000 (20%)] Loss: -1266.080200\n",
      "Train Epoch: 134 [23040/60000 (38%)] Loss: -915.959412\n",
      "Train Epoch: 134 [34304/60000 (57%)] Loss: -1052.405518\n",
      "Train Epoch: 134 [45568/60000 (76%)] Loss: -1214.534424\n",
      "Train Epoch: 134 [56832/60000 (95%)] Loss: -1003.821960\n",
      "    epoch          : 134\n",
      "    loss           : -1095.20922110175\n",
      "Train Epoch: 135 [512/60000 (1%)] Loss: -1123.835449\n",
      "Train Epoch: 135 [11776/60000 (20%)] Loss: -1065.238525\n",
      "Train Epoch: 135 [23040/60000 (38%)] Loss: -1174.932007\n",
      "Train Epoch: 135 [34304/60000 (57%)] Loss: -849.422119\n",
      "Train Epoch: 135 [45568/60000 (76%)] Loss: -1028.086792\n",
      "Train Epoch: 135 [56832/60000 (95%)] Loss: -995.466064\n",
      "    epoch          : 135\n",
      "    loss           : -1110.6040173546742\n",
      "Train Epoch: 136 [512/60000 (1%)] Loss: -1273.821777\n",
      "Train Epoch: 136 [11776/60000 (20%)] Loss: -1241.190674\n",
      "Train Epoch: 136 [23040/60000 (38%)] Loss: -1008.259705\n",
      "Train Epoch: 136 [34304/60000 (57%)] Loss: -1141.434326\n",
      "Train Epoch: 136 [45568/60000 (76%)] Loss: -1149.569702\n",
      "Train Epoch: 136 [56832/60000 (95%)] Loss: -1277.978027\n",
      "    epoch          : 136\n",
      "    loss           : -1093.5226742157154\n",
      "Train Epoch: 137 [512/60000 (1%)] Loss: -1216.575928\n",
      "Train Epoch: 137 [11776/60000 (20%)] Loss: -1019.161865\n",
      "Train Epoch: 137 [23040/60000 (38%)] Loss: -1031.115601\n",
      "Train Epoch: 137 [34304/60000 (57%)] Loss: -1016.685059\n",
      "Train Epoch: 137 [45568/60000 (76%)] Loss: -1061.242310\n",
      "Train Epoch: 137 [56832/60000 (95%)] Loss: -1149.243164\n",
      "    epoch          : 137\n",
      "    loss           : -1104.9572067691781\n",
      "Train Epoch: 138 [512/60000 (1%)] Loss: -1172.062744\n",
      "Train Epoch: 138 [11776/60000 (20%)] Loss: -1223.917236\n",
      "Train Epoch: 138 [23040/60000 (38%)] Loss: -1079.008789\n",
      "Train Epoch: 138 [34304/60000 (57%)] Loss: -1005.992432\n",
      "Train Epoch: 138 [45568/60000 (76%)] Loss: -1260.940796\n",
      "Train Epoch: 138 [56832/60000 (95%)] Loss: -1093.902588\n",
      "    epoch          : 138\n",
      "    loss           : -1087.7038532838983\n",
      "Train Epoch: 139 [512/60000 (1%)] Loss: -837.238403\n",
      "Train Epoch: 139 [11776/60000 (20%)] Loss: -1020.022034\n",
      "Train Epoch: 139 [23040/60000 (38%)] Loss: -1062.050049\n",
      "Train Epoch: 139 [34304/60000 (57%)] Loss: -1229.463257\n",
      "Train Epoch: 139 [45568/60000 (76%)] Loss: -1226.286255\n",
      "Train Epoch: 139 [56832/60000 (95%)] Loss: -1117.104736\n",
      "    epoch          : 139\n",
      "    loss           : -1092.0995455811926\n",
      "Train Epoch: 140 [512/60000 (1%)] Loss: -999.051208\n",
      "Train Epoch: 140 [11776/60000 (20%)] Loss: -1095.066650\n",
      "Train Epoch: 140 [23040/60000 (38%)] Loss: -991.108765\n",
      "Train Epoch: 140 [34304/60000 (57%)] Loss: -1131.487305\n",
      "Train Epoch: 140 [45568/60000 (76%)] Loss: -1126.715820\n",
      "Train Epoch: 140 [56832/60000 (95%)] Loss: -833.650940\n",
      "    epoch          : 140\n",
      "    loss           : -1112.9633006295242\n",
      "Train Epoch: 141 [512/60000 (1%)] Loss: -1008.648804\n",
      "Train Epoch: 141 [11776/60000 (20%)] Loss: -974.651550\n",
      "Train Epoch: 141 [23040/60000 (38%)] Loss: -1062.236694\n",
      "Train Epoch: 141 [34304/60000 (57%)] Loss: -993.421570\n",
      "Train Epoch: 141 [45568/60000 (76%)] Loss: -1068.125122\n",
      "Train Epoch: 141 [56832/60000 (95%)] Loss: -1168.025024\n",
      "    epoch          : 141\n",
      "    loss           : -1087.8203619833048\n",
      "Train Epoch: 142 [512/60000 (1%)] Loss: -866.526489\n",
      "Train Epoch: 142 [11776/60000 (20%)] Loss: -1161.215698\n",
      "Train Epoch: 142 [23040/60000 (38%)] Loss: -1157.935669\n",
      "Train Epoch: 142 [34304/60000 (57%)] Loss: -1064.199463\n",
      "Train Epoch: 142 [45568/60000 (76%)] Loss: -1024.248169\n",
      "Train Epoch: 142 [56832/60000 (95%)] Loss: -863.510742\n",
      "    epoch          : 142\n",
      "    loss           : -1070.892475537661\n",
      "Train Epoch: 143 [512/60000 (1%)] Loss: -1096.401367\n",
      "Train Epoch: 143 [11776/60000 (20%)] Loss: -1124.964233\n",
      "Train Epoch: 143 [23040/60000 (38%)] Loss: -1151.964722\n",
      "Train Epoch: 143 [34304/60000 (57%)] Loss: -1140.266602\n",
      "Train Epoch: 143 [45568/60000 (76%)] Loss: -1064.050171\n",
      "Train Epoch: 143 [56832/60000 (95%)] Loss: -1221.771973\n",
      "    epoch          : 143\n",
      "    loss           : -1111.5154517222259\n",
      "Train Epoch: 144 [512/60000 (1%)] Loss: -1216.616821\n",
      "Train Epoch: 144 [11776/60000 (20%)] Loss: -1097.452515\n",
      "Train Epoch: 144 [23040/60000 (38%)] Loss: -934.132568\n",
      "Train Epoch: 144 [34304/60000 (57%)] Loss: -1291.615356\n",
      "Train Epoch: 144 [45568/60000 (76%)] Loss: -1074.354492\n",
      "Train Epoch: 144 [56832/60000 (95%)] Loss: -1205.699829\n",
      "    epoch          : 144\n",
      "    loss           : -1086.0891639149122\n",
      "Train Epoch: 145 [512/60000 (1%)] Loss: -1234.824951\n",
      "Train Epoch: 145 [11776/60000 (20%)] Loss: -1242.446777\n",
      "Train Epoch: 145 [23040/60000 (38%)] Loss: -1032.051880\n",
      "Train Epoch: 145 [34304/60000 (57%)] Loss: -938.625854\n",
      "Train Epoch: 145 [45568/60000 (76%)] Loss: -994.100037\n",
      "Train Epoch: 145 [56832/60000 (95%)] Loss: -1092.268799\n",
      "    epoch          : 145\n",
      "    loss           : -1084.3955324679446\n",
      "Train Epoch: 146 [512/60000 (1%)] Loss: -1164.531860\n",
      "Train Epoch: 146 [11776/60000 (20%)] Loss: -1060.197266\n",
      "Train Epoch: 146 [23040/60000 (38%)] Loss: -1001.767090\n",
      "Train Epoch: 146 [34304/60000 (57%)] Loss: -1128.383789\n",
      "Train Epoch: 146 [45568/60000 (76%)] Loss: -887.469849\n",
      "Train Epoch: 146 [56832/60000 (95%)] Loss: -1134.106812\n",
      "    epoch          : 146\n",
      "    loss           : -1105.9943990761278\n",
      "Train Epoch: 147 [512/60000 (1%)] Loss: -1012.627258\n",
      "Train Epoch: 147 [11776/60000 (20%)] Loss: -861.625366\n",
      "Train Epoch: 147 [23040/60000 (38%)] Loss: -1172.181885\n",
      "Train Epoch: 147 [34304/60000 (57%)] Loss: -1136.495728\n",
      "Train Epoch: 147 [45568/60000 (76%)] Loss: -926.349609\n",
      "Train Epoch: 147 [56832/60000 (95%)] Loss: -1223.674194\n",
      "    epoch          : 147\n",
      "    loss           : -1111.1888343250682\n",
      "Train Epoch: 148 [512/60000 (1%)] Loss: -927.034302\n",
      "Train Epoch: 148 [11776/60000 (20%)] Loss: -1167.167236\n",
      "Train Epoch: 148 [23040/60000 (38%)] Loss: -1148.984741\n",
      "Train Epoch: 148 [34304/60000 (57%)] Loss: -1141.232178\n",
      "Train Epoch: 148 [45568/60000 (76%)] Loss: -1068.431152\n",
      "Train Epoch: 148 [56832/60000 (95%)] Loss: -1228.524658\n",
      "    epoch          : 148\n",
      "    loss           : -1107.6062211720957\n",
      "Train Epoch: 149 [512/60000 (1%)] Loss: -1020.620239\n",
      "Train Epoch: 149 [11776/60000 (20%)] Loss: -867.629883\n",
      "Train Epoch: 149 [23040/60000 (38%)] Loss: -1211.747314\n",
      "Train Epoch: 149 [34304/60000 (57%)] Loss: -1020.407043\n",
      "Train Epoch: 149 [45568/60000 (76%)] Loss: -1178.653320\n",
      "Train Epoch: 149 [56832/60000 (95%)] Loss: -996.724487\n",
      "    epoch          : 149\n",
      "    loss           : -1106.0691969704492\n",
      "Train Epoch: 150 [512/60000 (1%)] Loss: -1142.368408\n",
      "Train Epoch: 150 [11776/60000 (20%)] Loss: -1040.376099\n",
      "Train Epoch: 150 [23040/60000 (38%)] Loss: -1150.865845\n",
      "Train Epoch: 150 [34304/60000 (57%)] Loss: -1082.959961\n",
      "Train Epoch: 150 [45568/60000 (76%)] Loss: -1146.678223\n",
      "Train Epoch: 150 [56832/60000 (95%)] Loss: -1110.541626\n",
      "    epoch          : 150\n",
      "    loss           : -1079.0563183800648\n",
      "Train Epoch: 151 [512/60000 (1%)] Loss: -997.774597\n",
      "Train Epoch: 151 [11776/60000 (20%)] Loss: -1005.374878\n",
      "Train Epoch: 151 [23040/60000 (38%)] Loss: -1096.845215\n",
      "Train Epoch: 151 [34304/60000 (57%)] Loss: -1006.826355\n",
      "Train Epoch: 151 [45568/60000 (76%)] Loss: -998.096069\n",
      "Train Epoch: 151 [56832/60000 (95%)] Loss: -929.954590\n",
      "    epoch          : 151\n",
      "    loss           : -1104.103006309035\n",
      "Train Epoch: 152 [512/60000 (1%)] Loss: -1140.595337\n",
      "Train Epoch: 152 [11776/60000 (20%)] Loss: -1151.420288\n",
      "Train Epoch: 152 [23040/60000 (38%)] Loss: -1025.737793\n",
      "Train Epoch: 152 [34304/60000 (57%)] Loss: -1035.938843\n",
      "Train Epoch: 152 [45568/60000 (76%)] Loss: -1135.898926\n",
      "Train Epoch: 152 [56832/60000 (95%)] Loss: -1239.715942\n",
      "    epoch          : 152\n",
      "    loss           : -1111.4314913130077\n",
      "Train Epoch: 153 [512/60000 (1%)] Loss: -1168.244019\n",
      "Train Epoch: 153 [11776/60000 (20%)] Loss: -1234.244751\n",
      "Train Epoch: 153 [23040/60000 (38%)] Loss: -1217.446045\n",
      "Train Epoch: 153 [34304/60000 (57%)] Loss: -1052.048706\n",
      "Train Epoch: 153 [45568/60000 (76%)] Loss: -941.153442\n",
      "Train Epoch: 153 [56832/60000 (95%)] Loss: -1024.958862\n",
      "    epoch          : 153\n",
      "    loss           : -1105.2805891306386\n",
      "Train Epoch: 154 [512/60000 (1%)] Loss: -1272.255859\n",
      "Train Epoch: 154 [11776/60000 (20%)] Loss: -1178.762329\n",
      "Train Epoch: 154 [23040/60000 (38%)] Loss: -1163.064209\n",
      "Train Epoch: 154 [34304/60000 (57%)] Loss: -877.929260\n",
      "Train Epoch: 154 [45568/60000 (76%)] Loss: -1101.124756\n",
      "Train Epoch: 154 [56832/60000 (95%)] Loss: -1024.471313\n",
      "    epoch          : 154\n",
      "    loss           : -1106.3414639402918\n",
      "Train Epoch: 155 [512/60000 (1%)] Loss: -1280.383911\n",
      "Train Epoch: 155 [11776/60000 (20%)] Loss: -1303.785522\n",
      "Train Epoch: 155 [23040/60000 (38%)] Loss: -938.150635\n",
      "Train Epoch: 155 [34304/60000 (57%)] Loss: -1274.620728\n",
      "Train Epoch: 155 [45568/60000 (76%)] Loss: -1038.789062\n",
      "Train Epoch: 155 [56832/60000 (95%)] Loss: -988.886719\n",
      "    epoch          : 155\n",
      "    loss           : -1092.9491911634886\n",
      "Train Epoch: 156 [512/60000 (1%)] Loss: -1218.791260\n",
      "Train Epoch: 156 [11776/60000 (20%)] Loss: -1171.393188\n",
      "Train Epoch: 156 [23040/60000 (38%)] Loss: -1226.919189\n",
      "Train Epoch: 156 [34304/60000 (57%)] Loss: -1277.340332\n",
      "Train Epoch: 156 [45568/60000 (76%)] Loss: -1105.066406\n",
      "Train Epoch: 156 [56832/60000 (95%)] Loss: -1074.543579\n",
      "    epoch          : 156\n",
      "    loss           : -1093.5939050017105\n",
      "Train Epoch: 157 [512/60000 (1%)] Loss: -1051.579102\n",
      "Train Epoch: 157 [11776/60000 (20%)] Loss: -1267.785767\n",
      "Train Epoch: 157 [23040/60000 (38%)] Loss: -1239.347412\n",
      "Train Epoch: 157 [34304/60000 (57%)] Loss: -1016.352722\n",
      "Train Epoch: 157 [45568/60000 (76%)] Loss: -1178.034912\n",
      "Train Epoch: 157 [56832/60000 (95%)] Loss: -1087.898804\n",
      "    epoch          : 157\n",
      "    loss           : -1107.2041636321503\n",
      "Train Epoch: 158 [512/60000 (1%)] Loss: -1183.468994\n",
      "Train Epoch: 158 [11776/60000 (20%)] Loss: -994.902649\n",
      "Train Epoch: 158 [23040/60000 (38%)] Loss: -1012.882690\n",
      "Train Epoch: 158 [34304/60000 (57%)] Loss: -1273.729004\n",
      "Train Epoch: 158 [45568/60000 (76%)] Loss: -1241.829224\n",
      "Train Epoch: 158 [56832/60000 (95%)] Loss: -1046.722778\n",
      "    epoch          : 158\n",
      "    loss           : -1107.0685319631114\n",
      "Train Epoch: 159 [512/60000 (1%)] Loss: -1154.276367\n",
      "Train Epoch: 159 [11776/60000 (20%)] Loss: -1114.200439\n",
      "Train Epoch: 159 [23040/60000 (38%)] Loss: -1059.505737\n",
      "Train Epoch: 159 [34304/60000 (57%)] Loss: -1009.871033\n",
      "Train Epoch: 159 [45568/60000 (76%)] Loss: -1106.780640\n",
      "Train Epoch: 159 [56832/60000 (95%)] Loss: -1138.026367\n",
      "    epoch          : 159\n",
      "    loss           : -1109.6263350147312\n",
      "Train Epoch: 160 [512/60000 (1%)] Loss: -1090.309570\n",
      "Train Epoch: 160 [11776/60000 (20%)] Loss: -1128.118286\n",
      "Train Epoch: 160 [23040/60000 (38%)] Loss: -1170.765991\n",
      "Train Epoch: 160 [34304/60000 (57%)] Loss: -1075.162354\n",
      "Train Epoch: 160 [45568/60000 (76%)] Loss: -992.092773\n",
      "Train Epoch: 160 [56832/60000 (95%)] Loss: -1151.632080\n",
      "    epoch          : 160\n",
      "    loss           : -1114.4708176090219\n",
      "Train Epoch: 161 [512/60000 (1%)] Loss: -1249.326172\n",
      "Train Epoch: 161 [11776/60000 (20%)] Loss: -1011.291870\n",
      "Train Epoch: 161 [23040/60000 (38%)] Loss: -1090.808105\n",
      "Train Epoch: 161 [34304/60000 (57%)] Loss: -1139.605957\n",
      "Train Epoch: 161 [45568/60000 (76%)] Loss: -1142.001953\n",
      "Train Epoch: 161 [56832/60000 (95%)] Loss: -1280.855225\n",
      "    epoch          : 161\n",
      "    loss           : -1100.8138207042284\n",
      "Train Epoch: 162 [512/60000 (1%)] Loss: -1137.623657\n",
      "Train Epoch: 162 [11776/60000 (20%)] Loss: -944.167358\n",
      "Train Epoch: 162 [23040/60000 (38%)] Loss: -1089.965820\n",
      "Train Epoch: 162 [34304/60000 (57%)] Loss: -1220.569580\n",
      "Train Epoch: 162 [45568/60000 (76%)] Loss: -1280.208130\n",
      "Train Epoch: 162 [56832/60000 (95%)] Loss: -985.658325\n",
      "    epoch          : 162\n",
      "    loss           : -1102.868398720262\n",
      "Train Epoch: 163 [512/60000 (1%)] Loss: -1091.129639\n",
      "Train Epoch: 163 [11776/60000 (20%)] Loss: -999.682129\n",
      "Train Epoch: 163 [23040/60000 (38%)] Loss: -1273.939209\n",
      "Train Epoch: 163 [34304/60000 (57%)] Loss: -1037.660034\n",
      "Train Epoch: 163 [45568/60000 (76%)] Loss: -858.567749\n",
      "Train Epoch: 163 [56832/60000 (95%)] Loss: -1014.234375\n",
      "    epoch          : 163\n",
      "    loss           : -1094.9893216063074\n",
      "Train Epoch: 164 [512/60000 (1%)] Loss: -1019.005371\n",
      "Train Epoch: 164 [11776/60000 (20%)] Loss: -1088.415039\n",
      "Train Epoch: 164 [23040/60000 (38%)] Loss: -1023.991943\n",
      "Train Epoch: 164 [34304/60000 (57%)] Loss: -1136.133911\n",
      "Train Epoch: 164 [45568/60000 (76%)] Loss: -1073.872681\n",
      "Train Epoch: 164 [56832/60000 (95%)] Loss: -1270.799805\n",
      "    epoch          : 164\n",
      "    loss           : -1107.7760761498057\n",
      "Train Epoch: 165 [512/60000 (1%)] Loss: -996.414307\n",
      "Train Epoch: 165 [11776/60000 (20%)] Loss: -1173.621094\n",
      "Train Epoch: 165 [23040/60000 (38%)] Loss: -808.491333\n",
      "Train Epoch: 165 [34304/60000 (57%)] Loss: -1221.074463\n",
      "Train Epoch: 165 [45568/60000 (76%)] Loss: -1214.507690\n",
      "Train Epoch: 165 [56832/60000 (95%)] Loss: -1193.070068\n",
      "    epoch          : 165\n",
      "    loss           : -1104.5565447618733\n",
      "Train Epoch: 166 [512/60000 (1%)] Loss: -1097.904053\n",
      "Train Epoch: 166 [11776/60000 (20%)] Loss: -1301.154053\n",
      "Train Epoch: 166 [23040/60000 (38%)] Loss: -957.287781\n",
      "Train Epoch: 166 [34304/60000 (57%)] Loss: -1087.041016\n",
      "Train Epoch: 166 [45568/60000 (76%)] Loss: -1009.325195\n",
      "Train Epoch: 166 [56832/60000 (95%)] Loss: -1035.448853\n",
      "    epoch          : 166\n",
      "    loss           : -1095.1502749340682\n",
      "Train Epoch: 167 [512/60000 (1%)] Loss: -844.711731\n",
      "Train Epoch: 167 [11776/60000 (20%)] Loss: -1102.560425\n",
      "Train Epoch: 167 [23040/60000 (38%)] Loss: -1249.395020\n",
      "Train Epoch: 167 [34304/60000 (57%)] Loss: -1127.147705\n",
      "Train Epoch: 167 [45568/60000 (76%)] Loss: -1133.008301\n",
      "Train Epoch: 167 [56832/60000 (95%)] Loss: -892.321533\n",
      "    epoch          : 167\n",
      "    loss           : -1109.588833221608\n",
      "Train Epoch: 168 [512/60000 (1%)] Loss: -1233.441650\n",
      "Train Epoch: 168 [11776/60000 (20%)] Loss: -987.428406\n",
      "Train Epoch: 168 [23040/60000 (38%)] Loss: -1084.915527\n",
      "Train Epoch: 168 [34304/60000 (57%)] Loss: -1083.846191\n",
      "Train Epoch: 168 [45568/60000 (76%)] Loss: -1130.285522\n",
      "Train Epoch: 168 [56832/60000 (95%)] Loss: -1022.236145\n",
      "    epoch          : 168\n",
      "    loss           : -1102.0273909919006\n",
      "Train Epoch: 169 [512/60000 (1%)] Loss: -1217.886230\n",
      "Train Epoch: 169 [11776/60000 (20%)] Loss: -1227.518188\n",
      "Train Epoch: 169 [23040/60000 (38%)] Loss: -1285.532471\n",
      "Train Epoch: 169 [34304/60000 (57%)] Loss: -1149.726318\n",
      "Train Epoch: 169 [45568/60000 (76%)] Loss: -929.370728\n",
      "Train Epoch: 169 [56832/60000 (95%)] Loss: -952.456177\n",
      "    epoch          : 169\n",
      "    loss           : -1120.7431978559764\n",
      "Train Epoch: 170 [512/60000 (1%)] Loss: -1294.980957\n",
      "Train Epoch: 170 [11776/60000 (20%)] Loss: -1126.605591\n",
      "Train Epoch: 170 [23040/60000 (38%)] Loss: -1094.986572\n",
      "Train Epoch: 170 [34304/60000 (57%)] Loss: -1286.372559\n",
      "Train Epoch: 170 [45568/60000 (76%)] Loss: -1088.563843\n",
      "Train Epoch: 170 [56832/60000 (95%)] Loss: -1092.739624\n",
      "    epoch          : 170\n",
      "    loss           : -1113.9484446035267\n",
      "Train Epoch: 171 [512/60000 (1%)] Loss: -998.484131\n",
      "Train Epoch: 171 [11776/60000 (20%)] Loss: -1031.117065\n",
      "Train Epoch: 171 [23040/60000 (38%)] Loss: -1227.364502\n",
      "Train Epoch: 171 [34304/60000 (57%)] Loss: -1224.470947\n",
      "Train Epoch: 171 [45568/60000 (76%)] Loss: -1222.923462\n",
      "Train Epoch: 171 [56832/60000 (95%)] Loss: -1014.998535\n",
      "    epoch          : 171\n",
      "    loss           : -1088.9017428813006\n",
      "Train Epoch: 172 [512/60000 (1%)] Loss: -1140.940796\n",
      "Train Epoch: 172 [11776/60000 (20%)] Loss: -1230.414551\n",
      "Train Epoch: 172 [23040/60000 (38%)] Loss: -1077.441284\n",
      "Train Epoch: 172 [34304/60000 (57%)] Loss: -1088.025269\n",
      "Train Epoch: 172 [45568/60000 (76%)] Loss: -1159.153320\n",
      "Train Epoch: 172 [56832/60000 (95%)] Loss: -1091.093262\n",
      "    epoch          : 172\n",
      "    loss           : -1121.0037948694605\n",
      "Train Epoch: 173 [512/60000 (1%)] Loss: -1121.364258\n",
      "Train Epoch: 173 [11776/60000 (20%)] Loss: -1172.472900\n",
      "Train Epoch: 173 [23040/60000 (38%)] Loss: -1088.849854\n",
      "Train Epoch: 173 [34304/60000 (57%)] Loss: -1167.231689\n",
      "Train Epoch: 173 [45568/60000 (76%)] Loss: -1133.520142\n",
      "Train Epoch: 173 [56832/60000 (95%)] Loss: -1034.823486\n",
      "    epoch          : 173\n",
      "    loss           : -1114.5771568858693\n",
      "Train Epoch: 174 [512/60000 (1%)] Loss: -945.341919\n",
      "Train Epoch: 174 [11776/60000 (20%)] Loss: -850.612549\n",
      "Train Epoch: 174 [23040/60000 (38%)] Loss: -856.730835\n",
      "Train Epoch: 174 [34304/60000 (57%)] Loss: -1270.091553\n",
      "Train Epoch: 174 [45568/60000 (76%)] Loss: -1213.207764\n",
      "Train Epoch: 174 [56832/60000 (95%)] Loss: -1097.479736\n",
      "    epoch          : 174\n",
      "    loss           : -1105.2864340227202\n",
      "Train Epoch: 175 [512/60000 (1%)] Loss: -866.356140\n",
      "Train Epoch: 175 [11776/60000 (20%)] Loss: -1081.804932\n",
      "Train Epoch: 175 [23040/60000 (38%)] Loss: -1093.579346\n",
      "Train Epoch: 175 [34304/60000 (57%)] Loss: -1297.434570\n",
      "Train Epoch: 175 [45568/60000 (76%)] Loss: -1149.348877\n",
      "Train Epoch: 175 [56832/60000 (95%)] Loss: -1073.474365\n",
      "    epoch          : 175\n",
      "    loss           : -1115.6947428385415\n",
      "Train Epoch: 176 [512/60000 (1%)] Loss: -1184.703857\n",
      "Train Epoch: 176 [11776/60000 (20%)] Loss: -1222.268921\n",
      "Train Epoch: 176 [23040/60000 (38%)] Loss: -1203.956299\n",
      "Train Epoch: 176 [34304/60000 (57%)] Loss: -1241.540894\n",
      "Train Epoch: 176 [45568/60000 (76%)] Loss: -1189.583984\n",
      "Train Epoch: 176 [56832/60000 (95%)] Loss: -1252.993774\n",
      "    epoch          : 176\n",
      "    loss           : -1119.886071329063\n",
      "Train Epoch: 177 [512/60000 (1%)] Loss: -1180.370850\n",
      "Train Epoch: 177 [11776/60000 (20%)] Loss: -1162.632690\n",
      "Train Epoch: 177 [23040/60000 (38%)] Loss: -953.645630\n",
      "Train Epoch: 177 [34304/60000 (57%)] Loss: -1130.179443\n",
      "Train Epoch: 177 [45568/60000 (76%)] Loss: -1214.336914\n",
      "Train Epoch: 177 [56832/60000 (95%)] Loss: -821.053467\n",
      "    epoch          : 177\n",
      "    loss           : -1095.0838314422779\n",
      "Train Epoch: 178 [512/60000 (1%)] Loss: -1224.856689\n",
      "Train Epoch: 178 [11776/60000 (20%)] Loss: -1145.581055\n",
      "Train Epoch: 178 [23040/60000 (38%)] Loss: -953.559448\n",
      "Train Epoch: 178 [34304/60000 (57%)] Loss: -811.118469\n",
      "Train Epoch: 178 [45568/60000 (76%)] Loss: -1152.702148\n",
      "Train Epoch: 178 [56832/60000 (95%)] Loss: -1233.748535\n",
      "    epoch          : 178\n",
      "    loss           : -1102.192506262138\n",
      "Train Epoch: 179 [512/60000 (1%)] Loss: -1152.863770\n",
      "Train Epoch: 179 [11776/60000 (20%)] Loss: -1144.365112\n",
      "Train Epoch: 179 [23040/60000 (38%)] Loss: -1123.932251\n",
      "Train Epoch: 179 [34304/60000 (57%)] Loss: -1137.653442\n",
      "Train Epoch: 179 [45568/60000 (76%)] Loss: -945.921997\n",
      "Train Epoch: 179 [56832/60000 (95%)] Loss: -1231.059570\n",
      "    epoch          : 179\n",
      "    loss           : -1104.8814197260108\n",
      "Train Epoch: 180 [512/60000 (1%)] Loss: -1288.616211\n",
      "Train Epoch: 180 [11776/60000 (20%)] Loss: -1167.221802\n",
      "Train Epoch: 180 [23040/60000 (38%)] Loss: -1297.750488\n",
      "Train Epoch: 180 [34304/60000 (57%)] Loss: -826.600037\n",
      "Train Epoch: 180 [45568/60000 (76%)] Loss: -1095.441650\n",
      "Train Epoch: 180 [56832/60000 (95%)] Loss: -1090.499756\n",
      "    epoch          : 180\n",
      "    loss           : -1111.6429250253796\n",
      "Train Epoch: 181 [512/60000 (1%)] Loss: -1148.958740\n",
      "Train Epoch: 181 [11776/60000 (20%)] Loss: -1149.742554\n",
      "Train Epoch: 181 [23040/60000 (38%)] Loss: -1282.786499\n",
      "Train Epoch: 181 [34304/60000 (57%)] Loss: -1008.685608\n",
      "Train Epoch: 181 [45568/60000 (76%)] Loss: -1172.248657\n",
      "Train Epoch: 181 [56832/60000 (95%)] Loss: -1313.705688\n",
      "    epoch          : 181\n",
      "    loss           : -1111.7577288783878\n",
      "Train Epoch: 182 [512/60000 (1%)] Loss: -1218.755371\n",
      "Train Epoch: 182 [11776/60000 (20%)] Loss: -1288.111328\n",
      "Train Epoch: 182 [23040/60000 (38%)] Loss: -1088.542847\n",
      "Train Epoch: 182 [34304/60000 (57%)] Loss: -1095.378418\n",
      "Train Epoch: 182 [45568/60000 (76%)] Loss: -1163.013428\n",
      "Train Epoch: 182 [56832/60000 (95%)] Loss: -1028.664429\n",
      "    epoch          : 182\n",
      "    loss           : -1114.8485643634688\n",
      "Train Epoch: 183 [512/60000 (1%)] Loss: -1239.450928\n",
      "Train Epoch: 183 [11776/60000 (20%)] Loss: -1215.074219\n",
      "Train Epoch: 183 [23040/60000 (38%)] Loss: -822.850952\n",
      "Train Epoch: 183 [34304/60000 (57%)] Loss: -1023.971680\n",
      "Train Epoch: 183 [45568/60000 (76%)] Loss: -893.518921\n",
      "Train Epoch: 183 [56832/60000 (95%)] Loss: -868.382080\n",
      "    epoch          : 183\n",
      "    loss           : -1133.3090018579514\n",
      "Train Epoch: 184 [512/60000 (1%)] Loss: -1104.144409\n",
      "Train Epoch: 184 [11776/60000 (20%)] Loss: -1223.056641\n",
      "Train Epoch: 184 [23040/60000 (38%)] Loss: -921.982178\n",
      "Train Epoch: 184 [34304/60000 (57%)] Loss: -1232.448975\n",
      "Train Epoch: 184 [45568/60000 (76%)] Loss: -1320.081177\n",
      "Train Epoch: 184 [56832/60000 (95%)] Loss: -1027.080078\n",
      "    epoch          : 184\n",
      "    loss           : -1135.295220498985\n",
      "Train Epoch: 185 [512/60000 (1%)] Loss: -1228.645996\n",
      "Train Epoch: 185 [11776/60000 (20%)] Loss: -1087.800781\n",
      "Train Epoch: 185 [23040/60000 (38%)] Loss: -1241.880249\n",
      "Train Epoch: 185 [34304/60000 (57%)] Loss: -1224.808716\n",
      "Train Epoch: 185 [45568/60000 (76%)] Loss: -956.079712\n",
      "Train Epoch: 185 [56832/60000 (95%)] Loss: -884.925476\n",
      "    epoch          : 185\n",
      "    loss           : -1111.1147560938605\n",
      "Train Epoch: 186 [512/60000 (1%)] Loss: -1003.090576\n",
      "Train Epoch: 186 [11776/60000 (20%)] Loss: -775.327148\n",
      "Train Epoch: 186 [23040/60000 (38%)] Loss: -1097.157837\n",
      "Train Epoch: 186 [34304/60000 (57%)] Loss: -999.996521\n",
      "Train Epoch: 186 [45568/60000 (76%)] Loss: -1090.412231\n",
      "Train Epoch: 186 [56832/60000 (95%)] Loss: -1246.541260\n",
      "    epoch          : 186\n",
      "    loss           : -1114.3734542932887\n",
      "Train Epoch: 187 [512/60000 (1%)] Loss: -1177.936768\n",
      "Train Epoch: 187 [11776/60000 (20%)] Loss: -1149.826294\n",
      "Train Epoch: 187 [23040/60000 (38%)] Loss: -1026.254028\n",
      "Train Epoch: 187 [34304/60000 (57%)] Loss: -1150.362793\n",
      "Train Epoch: 187 [45568/60000 (76%)] Loss: -1170.940918\n",
      "Train Epoch: 187 [56832/60000 (95%)] Loss: -1286.948486\n",
      "    epoch          : 187\n",
      "    loss           : -1115.4256034894179\n",
      "Train Epoch: 188 [512/60000 (1%)] Loss: -1101.779053\n",
      "Train Epoch: 188 [11776/60000 (20%)] Loss: -1089.054688\n",
      "Train Epoch: 188 [23040/60000 (38%)] Loss: -1052.435791\n",
      "Train Epoch: 188 [34304/60000 (57%)] Loss: -1168.268799\n",
      "Train Epoch: 188 [45568/60000 (76%)] Loss: -1226.485107\n",
      "Train Epoch: 188 [56832/60000 (95%)] Loss: -1243.788940\n",
      "    epoch          : 188\n",
      "    loss           : -1109.4823020460915\n",
      "Train Epoch: 189 [512/60000 (1%)] Loss: -1175.861328\n",
      "Train Epoch: 189 [11776/60000 (20%)] Loss: -967.726074\n",
      "Train Epoch: 189 [23040/60000 (38%)] Loss: -1051.962402\n",
      "Train Epoch: 189 [34304/60000 (57%)] Loss: -1240.407715\n",
      "Train Epoch: 189 [45568/60000 (76%)] Loss: -1147.233887\n",
      "Train Epoch: 189 [56832/60000 (95%)] Loss: -1241.372070\n",
      "    epoch          : 189\n",
      "    loss           : -1131.5080028469279\n",
      "Train Epoch: 190 [512/60000 (1%)] Loss: -1093.493286\n",
      "Train Epoch: 190 [11776/60000 (20%)] Loss: -1043.570068\n",
      "Train Epoch: 190 [23040/60000 (38%)] Loss: -1166.120972\n",
      "Train Epoch: 190 [34304/60000 (57%)] Loss: -961.698792\n",
      "Train Epoch: 190 [45568/60000 (76%)] Loss: -1166.699707\n",
      "Train Epoch: 190 [56832/60000 (95%)] Loss: -1282.018921\n",
      "    epoch          : 190\n",
      "    loss           : -1129.866253351761\n",
      "Train Epoch: 191 [512/60000 (1%)] Loss: -955.410217\n",
      "Train Epoch: 191 [11776/60000 (20%)] Loss: -1280.089355\n",
      "Train Epoch: 191 [23040/60000 (38%)] Loss: -1159.140015\n",
      "Train Epoch: 191 [34304/60000 (57%)] Loss: -1103.762207\n",
      "Train Epoch: 191 [45568/60000 (76%)] Loss: -1001.558105\n",
      "Train Epoch: 191 [56832/60000 (95%)] Loss: -1029.703857\n",
      "    epoch          : 191\n",
      "    loss           : -1116.4156545865333\n",
      "Train Epoch: 192 [512/60000 (1%)] Loss: -1103.786743\n",
      "Train Epoch: 192 [11776/60000 (20%)] Loss: -1286.663574\n",
      "Train Epoch: 192 [23040/60000 (38%)] Loss: -1168.771362\n",
      "Train Epoch: 192 [34304/60000 (57%)] Loss: -1179.994507\n",
      "Train Epoch: 192 [45568/60000 (76%)] Loss: -1106.697876\n",
      "Train Epoch: 192 [56832/60000 (95%)] Loss: -967.505371\n",
      "    epoch          : 192\n",
      "    loss           : -1109.1535620393051\n",
      "Train Epoch: 193 [512/60000 (1%)] Loss: -1239.465820\n",
      "Train Epoch: 193 [11776/60000 (20%)] Loss: -1247.571411\n",
      "Train Epoch: 193 [23040/60000 (38%)] Loss: -1010.344360\n",
      "Train Epoch: 193 [34304/60000 (57%)] Loss: -1108.555908\n",
      "Train Epoch: 193 [45568/60000 (76%)] Loss: -1302.094116\n",
      "Train Epoch: 193 [56832/60000 (95%)] Loss: -1158.833374\n",
      "    epoch          : 193\n",
      "    loss           : -1122.0025684766176\n",
      "Train Epoch: 194 [512/60000 (1%)] Loss: -1041.321777\n",
      "Train Epoch: 194 [11776/60000 (20%)] Loss: -1036.394165\n",
      "Train Epoch: 194 [23040/60000 (38%)] Loss: -1007.814087\n",
      "Train Epoch: 194 [34304/60000 (57%)] Loss: -966.717712\n",
      "Train Epoch: 194 [45568/60000 (76%)] Loss: -1100.704468\n",
      "Train Epoch: 194 [56832/60000 (95%)] Loss: -979.010010\n",
      "    epoch          : 194\n",
      "    loss           : -1109.8616988187457\n",
      "Train Epoch: 195 [512/60000 (1%)] Loss: -1044.584839\n",
      "Train Epoch: 195 [11776/60000 (20%)] Loss: -963.233154\n",
      "Train Epoch: 195 [23040/60000 (38%)] Loss: -741.559631\n",
      "Train Epoch: 195 [34304/60000 (57%)] Loss: -1150.042480\n",
      "Train Epoch: 195 [45568/60000 (76%)] Loss: -1050.919800\n",
      "Train Epoch: 195 [56832/60000 (95%)] Loss: -1151.673340\n",
      "    epoch          : 195\n",
      "    loss           : -1108.265660172802\n",
      "Train Epoch: 196 [512/60000 (1%)] Loss: -1179.022095\n",
      "Train Epoch: 196 [11776/60000 (20%)] Loss: -971.866821\n",
      "Train Epoch: 196 [23040/60000 (38%)] Loss: -1108.987549\n",
      "Train Epoch: 196 [34304/60000 (57%)] Loss: -1167.631226\n",
      "Train Epoch: 196 [45568/60000 (76%)] Loss: -1321.921631\n",
      "Train Epoch: 196 [56832/60000 (95%)] Loss: -1124.244629\n",
      "    epoch          : 196\n",
      "    loss           : -1133.016011211158\n",
      "Train Epoch: 197 [512/60000 (1%)] Loss: -1226.846436\n",
      "Train Epoch: 197 [11776/60000 (20%)] Loss: -1009.181763\n",
      "Train Epoch: 197 [23040/60000 (38%)] Loss: -964.150818\n",
      "Train Epoch: 197 [34304/60000 (57%)] Loss: -996.456970\n",
      "Train Epoch: 197 [45568/60000 (76%)] Loss: -1044.525391\n",
      "Train Epoch: 197 [56832/60000 (95%)] Loss: -1093.431641\n",
      "    epoch          : 197\n",
      "    loss           : -1108.4237645036083\n",
      "Train Epoch: 198 [512/60000 (1%)] Loss: -1047.567871\n",
      "Train Epoch: 198 [11776/60000 (20%)] Loss: -1241.807983\n",
      "Train Epoch: 198 [23040/60000 (38%)] Loss: -980.508057\n",
      "Train Epoch: 198 [34304/60000 (57%)] Loss: -1095.585938\n",
      "Train Epoch: 198 [45568/60000 (76%)] Loss: -884.683960\n",
      "Train Epoch: 198 [56832/60000 (95%)] Loss: -1250.401367\n",
      "    epoch          : 198\n",
      "    loss           : -1119.3357683602026\n",
      "Train Epoch: 199 [512/60000 (1%)] Loss: -1237.700684\n",
      "Train Epoch: 199 [11776/60000 (20%)] Loss: -1197.710815\n",
      "Train Epoch: 199 [23040/60000 (38%)] Loss: -1121.519165\n",
      "Train Epoch: 199 [34304/60000 (57%)] Loss: -1038.831055\n",
      "Train Epoch: 199 [45568/60000 (76%)] Loss: -980.179382\n",
      "Train Epoch: 199 [56832/60000 (95%)] Loss: -1099.891357\n",
      "    epoch          : 199\n",
      "    loss           : -1136.675103139069\n",
      "Train Epoch: 200 [512/60000 (1%)] Loss: -1159.743408\n",
      "Train Epoch: 200 [11776/60000 (20%)] Loss: -1187.559814\n",
      "Train Epoch: 200 [23040/60000 (38%)] Loss: -1298.364624\n",
      "Train Epoch: 200 [34304/60000 (57%)] Loss: -1053.932373\n",
      "Train Epoch: 200 [45568/60000 (76%)] Loss: -1050.322754\n",
      "Train Epoch: 200 [56832/60000 (95%)] Loss: -1305.507690\n",
      "    epoch          : 200\n",
      "    loss           : -1140.5235635358733\n",
      "Saving checkpoint: saved/models/Mnist_DeepGenerativeOperad/0127_111843/checkpoint-epoch200.pth ...\n",
      "Train Epoch: 201 [512/60000 (1%)] Loss: -1108.224365\n",
      "Train Epoch: 201 [11776/60000 (20%)] Loss: -1160.662842\n",
      "Train Epoch: 201 [23040/60000 (38%)] Loss: -1115.214355\n",
      "Train Epoch: 201 [34304/60000 (57%)] Loss: -1245.519287\n",
      "Train Epoch: 201 [45568/60000 (76%)] Loss: -1031.687866\n",
      "Train Epoch: 201 [56832/60000 (95%)] Loss: -1310.161865\n",
      "    epoch          : 201\n",
      "    loss           : -1133.267530538268\n",
      "Train Epoch: 202 [512/60000 (1%)] Loss: -1112.829102\n",
      "Train Epoch: 202 [11776/60000 (20%)] Loss: -1168.041504\n",
      "Train Epoch: 202 [23040/60000 (38%)] Loss: -1254.886475\n",
      "Train Epoch: 202 [34304/60000 (57%)] Loss: -1180.423096\n",
      "Train Epoch: 202 [45568/60000 (76%)] Loss: -1183.234131\n",
      "Train Epoch: 202 [56832/60000 (95%)] Loss: -1040.801025\n",
      "    epoch          : 202\n",
      "    loss           : -1141.5637820831125\n",
      "Train Epoch: 203 [512/60000 (1%)] Loss: -1130.370361\n",
      "Train Epoch: 203 [11776/60000 (20%)] Loss: -728.540894\n",
      "Train Epoch: 203 [23040/60000 (38%)] Loss: -1035.258789\n",
      "Train Epoch: 203 [34304/60000 (57%)] Loss: -890.376221\n",
      "Train Epoch: 203 [45568/60000 (76%)] Loss: -1117.854492\n",
      "Train Epoch: 203 [56832/60000 (95%)] Loss: -1078.435181\n",
      "    epoch          : 203\n",
      "    loss           : -1118.8123177566097\n",
      "Train Epoch: 204 [512/60000 (1%)] Loss: -1296.239258\n",
      "Train Epoch: 204 [11776/60000 (20%)] Loss: -886.161560\n",
      "Train Epoch: 204 [23040/60000 (38%)] Loss: -972.434204\n",
      "Train Epoch: 204 [34304/60000 (57%)] Loss: -1242.957642\n",
      "Train Epoch: 204 [45568/60000 (76%)] Loss: -1313.585693\n",
      "Train Epoch: 204 [56832/60000 (95%)] Loss: -1258.439087\n",
      "    epoch          : 204\n",
      "    loss           : -1131.6243086130607\n",
      "Train Epoch: 205 [512/60000 (1%)] Loss: -1251.606079\n",
      "Train Epoch: 205 [11776/60000 (20%)] Loss: -1176.262939\n",
      "Train Epoch: 205 [23040/60000 (38%)] Loss: -1037.516357\n",
      "Train Epoch: 205 [34304/60000 (57%)] Loss: -1191.623901\n",
      "Train Epoch: 205 [45568/60000 (76%)] Loss: -980.234619\n",
      "Train Epoch: 205 [56832/60000 (95%)] Loss: -1111.417358\n",
      "    epoch          : 205\n",
      "    loss           : -1130.251429843364\n",
      "Train Epoch: 206 [512/60000 (1%)] Loss: -1314.540771\n",
      "Train Epoch: 206 [11776/60000 (20%)] Loss: -835.933594\n",
      "Train Epoch: 206 [23040/60000 (38%)] Loss: -1048.330688\n",
      "Train Epoch: 206 [34304/60000 (57%)] Loss: -1318.439331\n",
      "Train Epoch: 206 [45568/60000 (76%)] Loss: -1241.746338\n",
      "Train Epoch: 206 [56832/60000 (95%)] Loss: -1112.092529\n",
      "    epoch          : 206\n",
      "    loss           : -1118.6461917855647\n",
      "Train Epoch: 207 [512/60000 (1%)] Loss: -1150.984375\n",
      "Train Epoch: 207 [11776/60000 (20%)] Loss: -1178.053467\n",
      "Train Epoch: 207 [23040/60000 (38%)] Loss: -1040.335083\n",
      "Train Epoch: 207 [34304/60000 (57%)] Loss: -1101.697266\n",
      "Train Epoch: 207 [45568/60000 (76%)] Loss: -1150.633179\n",
      "Train Epoch: 207 [56832/60000 (95%)] Loss: -1188.341064\n",
      "    epoch          : 207\n",
      "    loss           : -1131.2702522924392\n",
      "Train Epoch: 208 [512/60000 (1%)] Loss: -1117.415039\n",
      "Train Epoch: 208 [11776/60000 (20%)] Loss: -1133.198120\n",
      "Train Epoch: 208 [23040/60000 (38%)] Loss: -894.648071\n",
      "Train Epoch: 208 [34304/60000 (57%)] Loss: -1125.960327\n",
      "Train Epoch: 208 [45568/60000 (76%)] Loss: -1137.839111\n",
      "Train Epoch: 208 [56832/60000 (95%)] Loss: -1160.090088\n",
      "    epoch          : 208\n",
      "    loss           : -1121.5057581669867\n",
      "Train Epoch: 209 [512/60000 (1%)] Loss: -973.374512\n",
      "Train Epoch: 209 [11776/60000 (20%)] Loss: -1164.077393\n",
      "Train Epoch: 209 [23040/60000 (38%)] Loss: -1118.219482\n",
      "Train Epoch: 209 [34304/60000 (57%)] Loss: -1259.251953\n",
      "Train Epoch: 209 [45568/60000 (76%)] Loss: -1242.848633\n",
      "Train Epoch: 209 [56832/60000 (95%)] Loss: -1315.150635\n",
      "    epoch          : 209\n",
      "    loss           : -1145.3478848732125\n",
      "Train Epoch: 210 [512/60000 (1%)] Loss: -1165.733398\n",
      "Train Epoch: 210 [11776/60000 (20%)] Loss: -1049.518188\n",
      "Train Epoch: 210 [23040/60000 (38%)] Loss: -1294.057495\n",
      "Train Epoch: 210 [34304/60000 (57%)] Loss: -1169.313965\n",
      "Train Epoch: 210 [45568/60000 (76%)] Loss: -1037.638916\n",
      "Train Epoch: 210 [56832/60000 (95%)] Loss: -1026.949097\n",
      "    epoch          : 210\n",
      "    loss           : -1127.7870238568148\n",
      "Train Epoch: 211 [512/60000 (1%)] Loss: -960.879883\n",
      "Train Epoch: 211 [11776/60000 (20%)] Loss: -1171.446899\n",
      "Train Epoch: 211 [23040/60000 (38%)] Loss: -1167.283691\n",
      "Train Epoch: 211 [34304/60000 (57%)] Loss: -1325.796997\n",
      "Train Epoch: 211 [45568/60000 (76%)] Loss: -1074.966187\n",
      "Train Epoch: 211 [56832/60000 (95%)] Loss: -989.332703\n",
      "    epoch          : 211\n",
      "    loss           : -1126.411392815369\n",
      "Train Epoch: 212 [512/60000 (1%)] Loss: -1242.558594\n",
      "Train Epoch: 212 [11776/60000 (20%)] Loss: -1121.415527\n",
      "Train Epoch: 212 [23040/60000 (38%)] Loss: -982.556641\n",
      "Train Epoch: 212 [34304/60000 (57%)] Loss: -1022.431763\n",
      "Train Epoch: 212 [45568/60000 (76%)] Loss: -1168.511597\n",
      "Train Epoch: 212 [56832/60000 (95%)] Loss: -1010.165161\n",
      "    epoch          : 212\n",
      "    loss           : -1137.6930762684276\n",
      "Train Epoch: 213 [512/60000 (1%)] Loss: -1238.111694\n",
      "Train Epoch: 213 [11776/60000 (20%)] Loss: -835.672363\n",
      "Train Epoch: 213 [23040/60000 (38%)] Loss: -1312.598145\n",
      "Train Epoch: 213 [34304/60000 (57%)] Loss: -1120.193848\n",
      "Train Epoch: 213 [45568/60000 (76%)] Loss: -1317.154907\n",
      "Train Epoch: 213 [56832/60000 (95%)] Loss: -1115.807861\n",
      "    epoch          : 213\n",
      "    loss           : -1151.9138935326184\n",
      "Train Epoch: 214 [512/60000 (1%)] Loss: -1088.194580\n",
      "Train Epoch: 214 [11776/60000 (20%)] Loss: -967.236755\n",
      "Train Epoch: 214 [23040/60000 (38%)] Loss: -1167.642212\n",
      "Train Epoch: 214 [34304/60000 (57%)] Loss: -1172.852417\n",
      "Train Epoch: 214 [45568/60000 (76%)] Loss: -1168.273926\n",
      "Train Epoch: 214 [56832/60000 (95%)] Loss: -1160.068970\n",
      "    epoch          : 214\n",
      "    loss           : -1134.0946505271781\n",
      "Train Epoch: 215 [512/60000 (1%)] Loss: -1218.034302\n",
      "Train Epoch: 215 [11776/60000 (20%)] Loss: -972.515869\n",
      "Train Epoch: 215 [23040/60000 (38%)] Loss: -1204.246216\n",
      "Train Epoch: 215 [34304/60000 (57%)] Loss: -1178.129395\n",
      "Train Epoch: 215 [45568/60000 (76%)] Loss: -1098.760986\n",
      "Train Epoch: 215 [56832/60000 (95%)] Loss: -1071.912964\n",
      "    epoch          : 215\n",
      "    loss           : -1140.0648210600946\n",
      "Train Epoch: 216 [512/60000 (1%)] Loss: -1074.265015\n",
      "Train Epoch: 216 [11776/60000 (20%)] Loss: -1039.449707\n",
      "Train Epoch: 216 [23040/60000 (38%)] Loss: -1165.112183\n",
      "Train Epoch: 216 [34304/60000 (57%)] Loss: -1199.181030\n",
      "Train Epoch: 216 [45568/60000 (76%)] Loss: -1305.984375\n",
      "Train Epoch: 216 [56832/60000 (95%)] Loss: -1112.091675\n",
      "    epoch          : 216\n",
      "    loss           : -1135.5083340574793\n",
      "Train Epoch: 217 [512/60000 (1%)] Loss: -1151.460327\n",
      "Train Epoch: 217 [11776/60000 (20%)] Loss: -1198.946045\n",
      "Train Epoch: 217 [23040/60000 (38%)] Loss: -1323.436768\n",
      "Train Epoch: 217 [34304/60000 (57%)] Loss: -1252.529053\n",
      "Train Epoch: 217 [45568/60000 (76%)] Loss: -1179.266602\n",
      "Train Epoch: 217 [56832/60000 (95%)] Loss: -1207.780029\n",
      "    epoch          : 217\n",
      "    loss           : -1128.228064757956\n",
      "Train Epoch: 218 [512/60000 (1%)] Loss: -1191.756226\n",
      "Train Epoch: 218 [11776/60000 (20%)] Loss: -1274.047607\n",
      "Train Epoch: 218 [23040/60000 (38%)] Loss: -1131.862793\n",
      "Train Epoch: 218 [34304/60000 (57%)] Loss: -1176.585205\n",
      "Train Epoch: 218 [45568/60000 (76%)] Loss: -1304.818726\n",
      "Train Epoch: 218 [56832/60000 (95%)] Loss: -1065.325439\n",
      "    epoch          : 218\n",
      "    loss           : -1144.5842771368511\n",
      "Train Epoch: 219 [512/60000 (1%)] Loss: -1256.942993\n",
      "Train Epoch: 219 [11776/60000 (20%)] Loss: -997.733765\n",
      "Train Epoch: 219 [23040/60000 (38%)] Loss: -1111.034302\n",
      "Train Epoch: 219 [34304/60000 (57%)] Loss: -1061.204834\n",
      "Train Epoch: 219 [45568/60000 (76%)] Loss: -1140.535400\n",
      "Train Epoch: 219 [56832/60000 (95%)] Loss: -1139.141357\n",
      "    epoch          : 219\n",
      "    loss           : -1131.766433284781\n",
      "Train Epoch: 220 [512/60000 (1%)] Loss: -975.403870\n",
      "Train Epoch: 220 [11776/60000 (20%)] Loss: -1258.363159\n",
      "Train Epoch: 220 [23040/60000 (38%)] Loss: -1080.602783\n",
      "Train Epoch: 220 [34304/60000 (57%)] Loss: -1120.834961\n",
      "Train Epoch: 220 [45568/60000 (76%)] Loss: -990.917908\n",
      "Train Epoch: 220 [56832/60000 (95%)] Loss: -1309.374756\n",
      "    epoch          : 220\n",
      "    loss           : -1133.9672748113082\n",
      "Train Epoch: 221 [512/60000 (1%)] Loss: -1052.458008\n",
      "Train Epoch: 221 [11776/60000 (20%)] Loss: -1172.153442\n",
      "Train Epoch: 221 [23040/60000 (38%)] Loss: -1216.846558\n",
      "Train Epoch: 221 [34304/60000 (57%)] Loss: -987.649109\n",
      "Train Epoch: 221 [45568/60000 (76%)] Loss: -1256.359253\n",
      "Train Epoch: 221 [56832/60000 (95%)] Loss: -1075.628418\n",
      "    epoch          : 221\n",
      "    loss           : -1157.809828073965\n",
      "Train Epoch: 222 [512/60000 (1%)] Loss: -863.634216\n",
      "Train Epoch: 222 [11776/60000 (20%)] Loss: -1154.690796\n",
      "Train Epoch: 222 [23040/60000 (38%)] Loss: -1303.820190\n",
      "Train Epoch: 222 [34304/60000 (57%)] Loss: -1183.651978\n",
      "Train Epoch: 222 [45568/60000 (76%)] Loss: -1199.083008\n",
      "Train Epoch: 222 [56832/60000 (95%)] Loss: -985.059387\n",
      "    epoch          : 222\n",
      "    loss           : -1142.016160350735\n",
      "Train Epoch: 223 [512/60000 (1%)] Loss: -1241.326904\n",
      "Train Epoch: 223 [11776/60000 (20%)] Loss: -1203.605225\n",
      "Train Epoch: 223 [23040/60000 (38%)] Loss: -1302.502930\n",
      "Train Epoch: 223 [34304/60000 (57%)] Loss: -1180.301147\n",
      "Train Epoch: 223 [45568/60000 (76%)] Loss: -989.110291\n",
      "Train Epoch: 223 [56832/60000 (95%)] Loss: -1139.458130\n",
      "    epoch          : 223\n",
      "    loss           : -1127.8825474970758\n",
      "Train Epoch: 224 [512/60000 (1%)] Loss: -1142.662842\n",
      "Train Epoch: 224 [11776/60000 (20%)] Loss: -1176.481812\n",
      "Train Epoch: 224 [23040/60000 (38%)] Loss: -1184.343506\n",
      "Train Epoch: 224 [34304/60000 (57%)] Loss: -1131.555420\n",
      "Train Epoch: 224 [45568/60000 (76%)] Loss: -1207.527344\n",
      "Train Epoch: 224 [56832/60000 (95%)] Loss: -1180.788696\n",
      "    epoch          : 224\n",
      "    loss           : -1139.3952838445114\n",
      "Train Epoch: 225 [512/60000 (1%)] Loss: -1109.640625\n",
      "Train Epoch: 225 [11776/60000 (20%)] Loss: -1051.270874\n",
      "Train Epoch: 225 [23040/60000 (38%)] Loss: -1197.808838\n",
      "Train Epoch: 225 [34304/60000 (57%)] Loss: -1168.164551\n",
      "Train Epoch: 225 [45568/60000 (76%)] Loss: -1045.288208\n",
      "Train Epoch: 225 [56832/60000 (95%)] Loss: -1119.764526\n",
      "    epoch          : 225\n",
      "    loss           : -1136.8556980628753\n",
      "Train Epoch: 226 [512/60000 (1%)] Loss: -834.966797\n",
      "Train Epoch: 226 [11776/60000 (20%)] Loss: -1095.562988\n",
      "Train Epoch: 226 [23040/60000 (38%)] Loss: -1079.345459\n",
      "Train Epoch: 226 [34304/60000 (57%)] Loss: -1257.734863\n",
      "Train Epoch: 226 [45568/60000 (76%)] Loss: -1195.206055\n",
      "Train Epoch: 226 [56832/60000 (95%)] Loss: -1035.239746\n",
      "    epoch          : 226\n",
      "    loss           : -1152.5615843002404\n",
      "Train Epoch: 227 [512/60000 (1%)] Loss: -1194.667114\n",
      "Train Epoch: 227 [11776/60000 (20%)] Loss: -1310.532227\n",
      "Train Epoch: 227 [23040/60000 (38%)] Loss: -1274.871338\n",
      "Train Epoch: 227 [34304/60000 (57%)] Loss: -914.659180\n",
      "Train Epoch: 227 [45568/60000 (76%)] Loss: -1258.681030\n",
      "Train Epoch: 227 [56832/60000 (95%)] Loss: -1047.540283\n",
      "    epoch          : 227\n",
      "    loss           : -1159.559535829361\n",
      "Train Epoch: 228 [512/60000 (1%)] Loss: -1042.908325\n",
      "Train Epoch: 228 [11776/60000 (20%)] Loss: -1062.415039\n",
      "Train Epoch: 228 [23040/60000 (38%)] Loss: -1133.011719\n",
      "Train Epoch: 228 [34304/60000 (57%)] Loss: -1031.125610\n",
      "Train Epoch: 228 [45568/60000 (76%)] Loss: -1162.130737\n",
      "Train Epoch: 228 [56832/60000 (95%)] Loss: -979.639526\n",
      "    epoch          : 228\n",
      "    loss           : -1149.129162287308\n",
      "Train Epoch: 229 [512/60000 (1%)] Loss: -930.802795\n",
      "Train Epoch: 229 [11776/60000 (20%)] Loss: -1041.903809\n",
      "Train Epoch: 229 [23040/60000 (38%)] Loss: -1261.975342\n",
      "Train Epoch: 229 [34304/60000 (57%)] Loss: -1141.474121\n",
      "Train Epoch: 229 [45568/60000 (76%)] Loss: -1116.820801\n",
      "Train Epoch: 229 [56832/60000 (95%)] Loss: -1128.468628\n",
      "    epoch          : 229\n",
      "    loss           : -1130.521840585827\n",
      "Train Epoch: 230 [512/60000 (1%)] Loss: -1041.605957\n",
      "Train Epoch: 230 [11776/60000 (20%)] Loss: -1008.228394\n",
      "Train Epoch: 230 [23040/60000 (38%)] Loss: -1128.997925\n",
      "Train Epoch: 230 [34304/60000 (57%)] Loss: -1285.026367\n",
      "Train Epoch: 230 [45568/60000 (76%)] Loss: -1266.531250\n",
      "Train Epoch: 230 [56832/60000 (95%)] Loss: -1017.571533\n",
      "    epoch          : 230\n",
      "    loss           : -1136.347984874316\n",
      "Train Epoch: 231 [512/60000 (1%)] Loss: -1268.401123\n",
      "Train Epoch: 231 [11776/60000 (20%)] Loss: -1274.196045\n",
      "Train Epoch: 231 [23040/60000 (38%)] Loss: -1004.974121\n",
      "Train Epoch: 231 [34304/60000 (57%)] Loss: -1143.427979\n",
      "Train Epoch: 231 [45568/60000 (76%)] Loss: -1125.242432\n",
      "Train Epoch: 231 [56832/60000 (95%)] Loss: -1028.608154\n",
      "    epoch          : 231\n",
      "    loss           : -1136.0557668222546\n",
      "Train Epoch: 232 [512/60000 (1%)] Loss: -1072.975098\n",
      "Train Epoch: 232 [11776/60000 (20%)] Loss: -916.012573\n",
      "Train Epoch: 232 [23040/60000 (38%)] Loss: -1068.598755\n",
      "Train Epoch: 232 [34304/60000 (57%)] Loss: -1216.615967\n",
      "Train Epoch: 232 [45568/60000 (76%)] Loss: -1270.287354\n",
      "Train Epoch: 232 [56832/60000 (95%)] Loss: -1040.459229\n",
      "    epoch          : 232\n",
      "    loss           : -1149.9336080605026\n",
      "Train Epoch: 233 [512/60000 (1%)] Loss: -1164.391724\n",
      "Train Epoch: 233 [11776/60000 (20%)] Loss: -1099.697266\n",
      "Train Epoch: 233 [23040/60000 (38%)] Loss: -1140.317627\n",
      "Train Epoch: 233 [34304/60000 (57%)] Loss: -1288.097900\n",
      "Train Epoch: 233 [45568/60000 (76%)] Loss: -1111.153198\n",
      "Train Epoch: 233 [56832/60000 (95%)] Loss: -1323.079102\n",
      "    epoch          : 233\n",
      "    loss           : -1134.346722101761\n",
      "Train Epoch: 234 [512/60000 (1%)] Loss: -1134.515015\n",
      "Train Epoch: 234 [11776/60000 (20%)] Loss: -894.177612\n",
      "Train Epoch: 234 [23040/60000 (38%)] Loss: -1259.712280\n",
      "Train Epoch: 234 [34304/60000 (57%)] Loss: -908.375732\n",
      "Train Epoch: 234 [45568/60000 (76%)] Loss: -1205.180786\n",
      "Train Epoch: 234 [56832/60000 (95%)] Loss: -1111.566040\n",
      "    epoch          : 234\n",
      "    loss           : -1151.7721192095914\n",
      "Train Epoch: 235 [512/60000 (1%)] Loss: -1089.925903\n",
      "Train Epoch: 235 [11776/60000 (20%)] Loss: -1262.698608\n",
      "Train Epoch: 235 [23040/60000 (38%)] Loss: -899.885864\n",
      "Train Epoch: 235 [34304/60000 (57%)] Loss: -1211.897705\n",
      "Train Epoch: 235 [45568/60000 (76%)] Loss: -1144.636719\n",
      "Train Epoch: 235 [56832/60000 (95%)] Loss: -1266.395752\n",
      "    epoch          : 235\n",
      "    loss           : -1149.67535865913\n",
      "Train Epoch: 236 [512/60000 (1%)] Loss: -1037.939209\n",
      "Train Epoch: 236 [11776/60000 (20%)] Loss: -995.796265\n",
      "Train Epoch: 236 [23040/60000 (38%)] Loss: -1322.353271\n",
      "Train Epoch: 236 [34304/60000 (57%)] Loss: -1318.192139\n",
      "Train Epoch: 236 [45568/60000 (76%)] Loss: -1139.189819\n",
      "Train Epoch: 236 [56832/60000 (95%)] Loss: -1066.097656\n",
      "    epoch          : 236\n",
      "    loss           : -1144.79973779021\n",
      "Train Epoch: 237 [512/60000 (1%)] Loss: -1225.936035\n",
      "Train Epoch: 237 [11776/60000 (20%)] Loss: -1181.903564\n",
      "Train Epoch: 237 [23040/60000 (38%)] Loss: -1167.792847\n",
      "Train Epoch: 237 [34304/60000 (57%)] Loss: -1069.243896\n",
      "Train Epoch: 237 [45568/60000 (76%)] Loss: -1141.870361\n",
      "Train Epoch: 237 [56832/60000 (95%)] Loss: -1072.092041\n",
      "    epoch          : 237\n",
      "    loss           : -1142.9699601857674\n",
      "Train Epoch: 238 [512/60000 (1%)] Loss: -1144.795288\n",
      "Train Epoch: 238 [11776/60000 (20%)] Loss: -1226.269775\n",
      "Train Epoch: 238 [23040/60000 (38%)] Loss: -1093.723877\n",
      "Train Epoch: 238 [34304/60000 (57%)] Loss: -1336.426392\n",
      "Train Epoch: 238 [45568/60000 (76%)] Loss: -1201.671387\n",
      "Train Epoch: 238 [56832/60000 (95%)] Loss: -874.052551\n",
      "    epoch          : 238\n",
      "    loss           : -1167.4792958060227\n",
      "Train Epoch: 239 [512/60000 (1%)] Loss: -1177.026489\n",
      "Train Epoch: 239 [11776/60000 (20%)] Loss: -1185.361328\n",
      "Train Epoch: 239 [23040/60000 (38%)] Loss: -1291.408936\n",
      "Train Epoch: 239 [34304/60000 (57%)] Loss: -1283.853271\n",
      "Train Epoch: 239 [45568/60000 (76%)] Loss: -1330.275635\n",
      "Train Epoch: 239 [56832/60000 (95%)] Loss: -1047.219727\n",
      "    epoch          : 239\n",
      "    loss           : -1155.303342140327\n",
      "Train Epoch: 240 [512/60000 (1%)] Loss: -1183.243652\n",
      "Train Epoch: 240 [11776/60000 (20%)] Loss: -1321.408569\n",
      "Train Epoch: 240 [23040/60000 (38%)] Loss: -904.742432\n",
      "Train Epoch: 240 [34304/60000 (57%)] Loss: -1232.381104\n",
      "Train Epoch: 240 [45568/60000 (76%)] Loss: -1227.669678\n",
      "Train Epoch: 240 [56832/60000 (95%)] Loss: -1053.149536\n",
      "    epoch          : 240\n",
      "    loss           : -1143.1936036880409\n",
      "Train Epoch: 241 [512/60000 (1%)] Loss: -1333.473511\n",
      "Train Epoch: 241 [11776/60000 (20%)] Loss: -1109.363281\n",
      "Train Epoch: 241 [23040/60000 (38%)] Loss: -1090.622559\n",
      "Train Epoch: 241 [34304/60000 (57%)] Loss: -1081.538452\n",
      "Train Epoch: 241 [45568/60000 (76%)] Loss: -1291.118164\n",
      "Train Epoch: 241 [56832/60000 (95%)] Loss: -1193.260864\n",
      "    epoch          : 241\n",
      "    loss           : -1172.7234971213475\n",
      "Train Epoch: 242 [512/60000 (1%)] Loss: -1134.622314\n",
      "Train Epoch: 242 [11776/60000 (20%)] Loss: -1188.655273\n",
      "Train Epoch: 242 [23040/60000 (38%)] Loss: -1202.337158\n",
      "Train Epoch: 242 [34304/60000 (57%)] Loss: -1174.075317\n",
      "Train Epoch: 242 [45568/60000 (76%)] Loss: -1233.144409\n",
      "Train Epoch: 242 [56832/60000 (95%)] Loss: -1288.404175\n",
      "    epoch          : 242\n",
      "    loss           : -1166.1552727478372\n",
      "Train Epoch: 243 [512/60000 (1%)] Loss: -1298.983154\n",
      "Train Epoch: 243 [11776/60000 (20%)] Loss: -1138.795654\n",
      "Train Epoch: 243 [23040/60000 (38%)] Loss: -1090.638428\n",
      "Train Epoch: 243 [34304/60000 (57%)] Loss: -1186.032959\n",
      "Train Epoch: 243 [45568/60000 (76%)] Loss: -1091.804443\n",
      "Train Epoch: 243 [56832/60000 (95%)] Loss: -990.221802\n",
      "    epoch          : 243\n",
      "    loss           : -1161.690437101375\n",
      "Train Epoch: 244 [512/60000 (1%)] Loss: -1145.060913\n",
      "Train Epoch: 244 [11776/60000 (20%)] Loss: -1152.922729\n",
      "Train Epoch: 244 [23040/60000 (38%)] Loss: -1185.965698\n",
      "Train Epoch: 244 [34304/60000 (57%)] Loss: -1109.565186\n",
      "Train Epoch: 244 [45568/60000 (76%)] Loss: -1052.447388\n",
      "Train Epoch: 244 [56832/60000 (95%)] Loss: -1046.503906\n",
      "    epoch          : 244\n",
      "    loss           : -1173.398919574285\n",
      "Train Epoch: 245 [512/60000 (1%)] Loss: -1228.959961\n",
      "Train Epoch: 245 [11776/60000 (20%)] Loss: -1311.860596\n",
      "Train Epoch: 245 [23040/60000 (38%)] Loss: -1149.234009\n",
      "Train Epoch: 245 [34304/60000 (57%)] Loss: -1203.336304\n",
      "Train Epoch: 245 [45568/60000 (76%)] Loss: -1315.001099\n",
      "Train Epoch: 245 [56832/60000 (95%)] Loss: -1181.510376\n",
      "    epoch          : 245\n",
      "    loss           : -1164.1632338701668\n",
      "Train Epoch: 246 [512/60000 (1%)] Loss: -1058.849121\n",
      "Train Epoch: 246 [11776/60000 (20%)] Loss: -1346.325684\n",
      "Train Epoch: 246 [23040/60000 (38%)] Loss: -1281.373535\n",
      "Train Epoch: 246 [34304/60000 (57%)] Loss: -908.081909\n",
      "Train Epoch: 246 [45568/60000 (76%)] Loss: -1188.982056\n",
      "Train Epoch: 246 [56832/60000 (95%)] Loss: -1047.715088\n",
      "    epoch          : 246\n",
      "    loss           : -1177.4559439966233\n",
      "Train Epoch: 247 [512/60000 (1%)] Loss: -1291.734741\n",
      "Train Epoch: 247 [11776/60000 (20%)] Loss: -1058.271729\n",
      "Train Epoch: 247 [23040/60000 (38%)] Loss: -1157.951904\n",
      "Train Epoch: 247 [34304/60000 (57%)] Loss: -1079.656494\n",
      "Train Epoch: 247 [45568/60000 (76%)] Loss: -1196.540527\n",
      "Train Epoch: 247 [56832/60000 (95%)] Loss: -1237.379028\n",
      "    epoch          : 247\n",
      "    loss           : -1151.405511888407\n",
      "Train Epoch: 248 [512/60000 (1%)] Loss: -1078.305908\n",
      "Train Epoch: 248 [11776/60000 (20%)] Loss: -1295.106812\n",
      "Train Epoch: 248 [23040/60000 (38%)] Loss: -1059.746338\n",
      "Train Epoch: 248 [34304/60000 (57%)] Loss: -1200.384033\n",
      "Train Epoch: 248 [45568/60000 (76%)] Loss: -1001.100342\n",
      "Train Epoch: 248 [56832/60000 (95%)] Loss: -1155.764160\n",
      "    epoch          : 248\n",
      "    loss           : -1163.5873194118003\n",
      "Train Epoch: 249 [512/60000 (1%)] Loss: -1195.714355\n",
      "Train Epoch: 249 [11776/60000 (20%)] Loss: -1325.577393\n",
      "Train Epoch: 249 [23040/60000 (38%)] Loss: -1323.307739\n",
      "Train Epoch: 249 [34304/60000 (57%)] Loss: -1245.505005\n",
      "Train Epoch: 249 [45568/60000 (76%)] Loss: -918.886475\n",
      "Train Epoch: 249 [56832/60000 (95%)] Loss: -1153.028809\n",
      "    epoch          : 249\n",
      "    loss           : -1167.2050926079185\n",
      "Train Epoch: 250 [512/60000 (1%)] Loss: -1162.096069\n",
      "Train Epoch: 250 [11776/60000 (20%)] Loss: -1210.253418\n",
      "Train Epoch: 250 [23040/60000 (38%)] Loss: -1284.322998\n",
      "Train Epoch: 250 [34304/60000 (57%)] Loss: -1018.812317\n",
      "Train Epoch: 250 [45568/60000 (76%)] Loss: -1141.158325\n",
      "Train Epoch: 250 [56832/60000 (95%)] Loss: -1158.914062\n",
      "    epoch          : 250\n",
      "    loss           : -1153.1513380492474\n",
      "Train Epoch: 251 [512/60000 (1%)] Loss: -1031.925537\n",
      "Train Epoch: 251 [11776/60000 (20%)] Loss: -1049.370361\n",
      "Train Epoch: 251 [23040/60000 (38%)] Loss: -1152.214478\n",
      "Train Epoch: 251 [34304/60000 (57%)] Loss: -1231.529053\n",
      "Train Epoch: 251 [45568/60000 (76%)] Loss: -1268.986572\n",
      "Train Epoch: 251 [56832/60000 (95%)] Loss: -1200.141968\n",
      "    epoch          : 251\n",
      "    loss           : -1163.425256761454\n",
      "Train Epoch: 252 [512/60000 (1%)] Loss: -1151.340942\n",
      "Train Epoch: 252 [11776/60000 (20%)] Loss: -1072.302734\n",
      "Train Epoch: 252 [23040/60000 (38%)] Loss: -1300.587036\n",
      "Train Epoch: 252 [34304/60000 (57%)] Loss: -1252.086304\n",
      "Train Epoch: 252 [45568/60000 (76%)] Loss: -1002.859741\n",
      "Train Epoch: 252 [56832/60000 (95%)] Loss: -948.700195\n",
      "    epoch          : 252\n",
      "    loss           : -1171.1967499296543\n",
      "Train Epoch: 253 [512/60000 (1%)] Loss: -1162.944336\n",
      "Train Epoch: 253 [11776/60000 (20%)] Loss: -1150.110229\n",
      "Train Epoch: 253 [23040/60000 (38%)] Loss: -1223.035645\n",
      "Train Epoch: 253 [34304/60000 (57%)] Loss: -1257.223999\n",
      "Train Epoch: 253 [45568/60000 (76%)] Loss: -1010.118591\n",
      "Train Epoch: 253 [56832/60000 (95%)] Loss: -1029.325439\n",
      "    epoch          : 253\n",
      "    loss           : -1161.397889735335\n",
      "Train Epoch: 254 [512/60000 (1%)] Loss: -1103.704102\n",
      "Train Epoch: 254 [11776/60000 (20%)] Loss: -1208.564087\n",
      "Train Epoch: 254 [23040/60000 (38%)] Loss: -1034.214111\n",
      "Train Epoch: 254 [34304/60000 (57%)] Loss: -1148.910400\n",
      "Train Epoch: 254 [45568/60000 (76%)] Loss: -1164.436035\n",
      "Train Epoch: 254 [56832/60000 (95%)] Loss: -1169.390137\n",
      "    epoch          : 254\n",
      "    loss           : -1177.770527123058\n",
      "Train Epoch: 255 [512/60000 (1%)] Loss: -1027.708618\n",
      "Train Epoch: 255 [11776/60000 (20%)] Loss: -1306.013672\n",
      "Train Epoch: 255 [23040/60000 (38%)] Loss: -1300.742554\n",
      "Train Epoch: 255 [34304/60000 (57%)] Loss: -932.760986\n",
      "Train Epoch: 255 [45568/60000 (76%)] Loss: -1156.855347\n",
      "Train Epoch: 255 [56832/60000 (95%)] Loss: -853.247070\n",
      "    epoch          : 255\n",
      "    loss           : -1153.7179556808903\n",
      "Train Epoch: 256 [512/60000 (1%)] Loss: -1010.234863\n",
      "Train Epoch: 256 [11776/60000 (20%)] Loss: -1195.551758\n",
      "Train Epoch: 256 [23040/60000 (38%)] Loss: -1247.300293\n",
      "Train Epoch: 256 [34304/60000 (57%)] Loss: -1190.502441\n",
      "Train Epoch: 256 [45568/60000 (76%)] Loss: -1117.667114\n",
      "Train Epoch: 256 [56832/60000 (95%)] Loss: -1291.051514\n",
      "    epoch          : 256\n",
      "    loss           : -1181.360315355204\n",
      "Train Epoch: 257 [512/60000 (1%)] Loss: -1136.420166\n",
      "Train Epoch: 257 [11776/60000 (20%)] Loss: -1205.710327\n",
      "Train Epoch: 257 [23040/60000 (38%)] Loss: -1326.727539\n",
      "Train Epoch: 257 [34304/60000 (57%)] Loss: -1008.563965\n",
      "Train Epoch: 257 [45568/60000 (76%)] Loss: -1065.783203\n",
      "Train Epoch: 257 [56832/60000 (95%)] Loss: -1224.107178\n",
      "    epoch          : 257\n",
      "    loss           : -1144.0930136125642\n",
      "Train Epoch: 258 [512/60000 (1%)] Loss: -1115.301025\n",
      "Train Epoch: 258 [11776/60000 (20%)] Loss: -1322.169189\n",
      "Train Epoch: 258 [23040/60000 (38%)] Loss: -1279.890869\n",
      "Train Epoch: 258 [34304/60000 (57%)] Loss: -1177.219482\n",
      "Train Epoch: 258 [45568/60000 (76%)] Loss: -1055.009277\n",
      "Train Epoch: 258 [56832/60000 (95%)] Loss: -1296.853760\n",
      "    epoch          : 258\n",
      "    loss           : -1173.2494030968617\n",
      "Train Epoch: 259 [512/60000 (1%)] Loss: -1216.253052\n",
      "Train Epoch: 259 [11776/60000 (20%)] Loss: -1177.707275\n",
      "Train Epoch: 259 [23040/60000 (38%)] Loss: -1335.467773\n",
      "Train Epoch: 259 [34304/60000 (57%)] Loss: -1302.912964\n",
      "Train Epoch: 259 [45568/60000 (76%)] Loss: -1208.734497\n",
      "Train Epoch: 259 [56832/60000 (95%)] Loss: -1211.569824\n",
      "    epoch          : 259\n",
      "    loss           : -1143.6268651929952\n",
      "Train Epoch: 260 [512/60000 (1%)] Loss: -1282.257812\n",
      "Train Epoch: 260 [11776/60000 (20%)] Loss: -1107.448242\n",
      "Train Epoch: 260 [23040/60000 (38%)] Loss: -1093.215576\n",
      "Train Epoch: 260 [34304/60000 (57%)] Loss: -1272.990479\n",
      "Train Epoch: 260 [45568/60000 (76%)] Loss: -1117.307129\n",
      "Train Epoch: 260 [56832/60000 (95%)] Loss: -1059.521973\n",
      "    epoch          : 260\n",
      "    loss           : -1170.4273890263617\n",
      "Train Epoch: 261 [512/60000 (1%)] Loss: -1059.767822\n",
      "Train Epoch: 261 [11776/60000 (20%)] Loss: -1096.237305\n",
      "Train Epoch: 261 [23040/60000 (38%)] Loss: -1236.526611\n",
      "Train Epoch: 261 [34304/60000 (57%)] Loss: -1001.396301\n",
      "Train Epoch: 261 [45568/60000 (76%)] Loss: -1085.146240\n",
      "Train Epoch: 261 [56832/60000 (95%)] Loss: -1284.844604\n",
      "    epoch          : 261\n",
      "    loss           : -1170.1788642150534\n",
      "Train Epoch: 262 [512/60000 (1%)] Loss: -1152.864258\n",
      "Train Epoch: 262 [11776/60000 (20%)] Loss: -1265.401367\n",
      "Train Epoch: 262 [23040/60000 (38%)] Loss: -1171.379761\n",
      "Train Epoch: 262 [34304/60000 (57%)] Loss: -1048.370361\n",
      "Train Epoch: 262 [45568/60000 (76%)] Loss: -1334.708008\n",
      "Train Epoch: 262 [56832/60000 (95%)] Loss: -1196.532959\n",
      "    epoch          : 262\n",
      "    loss           : -1176.084979041148\n",
      "Train Epoch: 263 [512/60000 (1%)] Loss: -1338.195068\n",
      "Train Epoch: 263 [11776/60000 (20%)] Loss: -1299.857788\n",
      "Train Epoch: 263 [23040/60000 (38%)] Loss: -1355.175049\n",
      "Train Epoch: 263 [34304/60000 (57%)] Loss: -1110.872192\n",
      "Train Epoch: 263 [45568/60000 (76%)] Loss: -1324.526855\n",
      "Train Epoch: 263 [56832/60000 (95%)] Loss: -905.697815\n",
      "    epoch          : 263\n",
      "    loss           : -1168.5888432217182\n",
      "Train Epoch: 264 [512/60000 (1%)] Loss: -1179.738403\n",
      "Train Epoch: 264 [11776/60000 (20%)] Loss: -1146.286011\n",
      "Train Epoch: 264 [23040/60000 (38%)] Loss: -1153.318115\n",
      "Train Epoch: 264 [34304/60000 (57%)] Loss: -1347.631470\n",
      "Train Epoch: 264 [45568/60000 (76%)] Loss: -1068.241211\n",
      "Train Epoch: 264 [56832/60000 (95%)] Loss: -1240.158325\n",
      "    epoch          : 264\n",
      "    loss           : -1176.9995980990136\n",
      "Train Epoch: 265 [512/60000 (1%)] Loss: -1083.394775\n",
      "Train Epoch: 265 [11776/60000 (20%)] Loss: -1270.355957\n",
      "Train Epoch: 265 [23040/60000 (38%)] Loss: -1083.326904\n",
      "Train Epoch: 265 [34304/60000 (57%)] Loss: -1056.952393\n",
      "Train Epoch: 265 [45568/60000 (76%)] Loss: -1074.395264\n",
      "Train Epoch: 265 [56832/60000 (95%)] Loss: -1304.868042\n",
      "    epoch          : 265\n",
      "    loss           : -1169.217028601695\n",
      "Train Epoch: 266 [512/60000 (1%)] Loss: -1204.477051\n",
      "Train Epoch: 266 [11776/60000 (20%)] Loss: -1351.088379\n",
      "Train Epoch: 266 [23040/60000 (38%)] Loss: -1277.626343\n",
      "Train Epoch: 266 [34304/60000 (57%)] Loss: -1090.832520\n",
      "Train Epoch: 266 [45568/60000 (76%)] Loss: -1351.697876\n",
      "Train Epoch: 266 [56832/60000 (95%)] Loss: -1037.160278\n",
      "    epoch          : 266\n",
      "    loss           : -1171.5230730132196\n",
      "Train Epoch: 267 [512/60000 (1%)] Loss: -910.981445\n",
      "Train Epoch: 267 [11776/60000 (20%)] Loss: -1022.281372\n",
      "Train Epoch: 267 [23040/60000 (38%)] Loss: -1286.661377\n",
      "Train Epoch: 267 [34304/60000 (57%)] Loss: -1068.671875\n",
      "Train Epoch: 267 [45568/60000 (76%)] Loss: -1044.588257\n",
      "Train Epoch: 267 [56832/60000 (95%)] Loss: -1214.819580\n",
      "    epoch          : 267\n",
      "    loss           : -1155.4973529018253\n",
      "Train Epoch: 268 [512/60000 (1%)] Loss: -1211.284180\n",
      "Train Epoch: 268 [11776/60000 (20%)] Loss: -1201.283691\n",
      "Train Epoch: 268 [23040/60000 (38%)] Loss: -1057.857910\n",
      "Train Epoch: 268 [34304/60000 (57%)] Loss: -1062.634277\n",
      "Train Epoch: 268 [45568/60000 (76%)] Loss: -1220.412109\n",
      "Train Epoch: 268 [56832/60000 (95%)] Loss: -1284.208740\n",
      "    epoch          : 268\n",
      "    loss           : -1166.5122225486625\n",
      "Train Epoch: 269 [512/60000 (1%)] Loss: -1149.513916\n",
      "Train Epoch: 269 [11776/60000 (20%)] Loss: -1164.103882\n",
      "Train Epoch: 269 [23040/60000 (38%)] Loss: -1241.988525\n",
      "Train Epoch: 269 [34304/60000 (57%)] Loss: -1244.184814\n",
      "Train Epoch: 269 [45568/60000 (76%)] Loss: -873.872559\n",
      "Train Epoch: 269 [56832/60000 (95%)] Loss: -1319.360107\n",
      "    epoch          : 269\n",
      "    loss           : -1136.5964977889412\n",
      "Train Epoch: 270 [512/60000 (1%)] Loss: -919.948364\n",
      "Train Epoch: 270 [11776/60000 (20%)] Loss: -1321.596802\n",
      "Train Epoch: 270 [23040/60000 (38%)] Loss: -1157.560547\n",
      "Train Epoch: 270 [34304/60000 (57%)] Loss: -1213.006836\n",
      "Train Epoch: 270 [45568/60000 (76%)] Loss: -864.218262\n",
      "Train Epoch: 270 [56832/60000 (95%)] Loss: -1093.238770\n",
      "    epoch          : 270\n",
      "    loss           : -1164.7241467836886\n",
      "Train Epoch: 271 [512/60000 (1%)] Loss: -1261.214111\n",
      "Train Epoch: 271 [11776/60000 (20%)] Loss: -1075.352173\n",
      "Train Epoch: 271 [23040/60000 (38%)] Loss: -1092.938843\n",
      "Train Epoch: 271 [34304/60000 (57%)] Loss: -1204.939941\n",
      "Train Epoch: 271 [45568/60000 (76%)] Loss: -1322.385254\n",
      "Train Epoch: 271 [56832/60000 (95%)] Loss: -1188.127441\n",
      "    epoch          : 271\n",
      "    loss           : -1156.1656980352886\n",
      "Train Epoch: 272 [512/60000 (1%)] Loss: -1199.437134\n",
      "Train Epoch: 272 [11776/60000 (20%)] Loss: -1170.064941\n",
      "Train Epoch: 272 [23040/60000 (38%)] Loss: -1316.216797\n",
      "Train Epoch: 272 [34304/60000 (57%)] Loss: -1059.569092\n",
      "Train Epoch: 272 [45568/60000 (76%)] Loss: -1114.471558\n",
      "Train Epoch: 272 [56832/60000 (95%)] Loss: -1136.198608\n",
      "    epoch          : 272\n",
      "    loss           : -1166.6780579992605\n",
      "Train Epoch: 273 [512/60000 (1%)] Loss: -1295.732422\n",
      "Train Epoch: 273 [11776/60000 (20%)] Loss: -1100.192505\n",
      "Train Epoch: 273 [23040/60000 (38%)] Loss: -1272.156982\n",
      "Train Epoch: 273 [34304/60000 (57%)] Loss: -1030.090088\n",
      "Train Epoch: 273 [45568/60000 (76%)] Loss: -1109.914551\n",
      "Train Epoch: 273 [56832/60000 (95%)] Loss: -1270.839355\n",
      "    epoch          : 273\n",
      "    loss           : -1170.2127802789548\n",
      "Train Epoch: 274 [512/60000 (1%)] Loss: -1338.877930\n",
      "Train Epoch: 274 [11776/60000 (20%)] Loss: -1148.138794\n",
      "Train Epoch: 274 [23040/60000 (38%)] Loss: -1185.086304\n",
      "Train Epoch: 274 [34304/60000 (57%)] Loss: -1150.776001\n",
      "Train Epoch: 274 [45568/60000 (76%)] Loss: -1280.285400\n",
      "Train Epoch: 274 [56832/60000 (95%)] Loss: -1305.122437\n",
      "    epoch          : 274\n",
      "    loss           : -1163.865507998709\n",
      "Train Epoch: 275 [512/60000 (1%)] Loss: -1072.512695\n",
      "Train Epoch: 275 [11776/60000 (20%)] Loss: -1197.684204\n",
      "Train Epoch: 275 [23040/60000 (38%)] Loss: -1346.947998\n",
      "Train Epoch: 275 [34304/60000 (57%)] Loss: -1099.852051\n",
      "Train Epoch: 275 [45568/60000 (76%)] Loss: -1359.365723\n",
      "Train Epoch: 275 [56832/60000 (95%)] Loss: -868.038940\n",
      "    epoch          : 275\n",
      "    loss           : -1151.453317588332\n",
      "Train Epoch: 276 [512/60000 (1%)] Loss: -1249.793457\n",
      "Train Epoch: 276 [11776/60000 (20%)] Loss: -993.946655\n",
      "Train Epoch: 276 [23040/60000 (38%)] Loss: -1146.198364\n",
      "Train Epoch: 276 [34304/60000 (57%)] Loss: -1090.425049\n",
      "Train Epoch: 276 [45568/60000 (76%)] Loss: -932.193726\n",
      "Train Epoch: 276 [56832/60000 (95%)] Loss: -1346.213501\n",
      "    epoch          : 276\n",
      "    loss           : -1165.3745244775114\n",
      "Train Epoch: 277 [512/60000 (1%)] Loss: -1219.760864\n",
      "Train Epoch: 277 [11776/60000 (20%)] Loss: -1232.720581\n",
      "Train Epoch: 277 [23040/60000 (38%)] Loss: -1046.473022\n",
      "Train Epoch: 277 [34304/60000 (57%)] Loss: -1211.280273\n",
      "Train Epoch: 277 [45568/60000 (76%)] Loss: -1114.206787\n",
      "Train Epoch: 277 [56832/60000 (95%)] Loss: -1013.262146\n",
      "    epoch          : 277\n",
      "    loss           : -1151.7758071813207\n",
      "Train Epoch: 278 [512/60000 (1%)] Loss: -1053.161865\n",
      "Train Epoch: 278 [11776/60000 (20%)] Loss: -1087.982056\n",
      "Train Epoch: 278 [23040/60000 (38%)] Loss: -1297.324707\n",
      "Train Epoch: 278 [34304/60000 (57%)] Loss: -1284.994995\n",
      "Train Epoch: 278 [45568/60000 (76%)] Loss: -938.570435\n",
      "Train Epoch: 278 [56832/60000 (95%)] Loss: -1355.235352\n",
      "    epoch          : 278\n",
      "    loss           : -1161.5626832778846\n",
      "Train Epoch: 279 [512/60000 (1%)] Loss: -1069.629639\n",
      "Train Epoch: 279 [11776/60000 (20%)] Loss: -1281.331543\n",
      "Train Epoch: 279 [23040/60000 (38%)] Loss: -1167.434937\n",
      "Train Epoch: 279 [34304/60000 (57%)] Loss: -1210.269287\n",
      "Train Epoch: 279 [45568/60000 (76%)] Loss: -1311.916504\n",
      "Train Epoch: 279 [56832/60000 (95%)] Loss: -1266.091919\n",
      "    epoch          : 279\n",
      "    loss           : -1161.6204987434344\n",
      "Train Epoch: 280 [512/60000 (1%)] Loss: -1206.836304\n",
      "Train Epoch: 280 [11776/60000 (20%)] Loss: -1022.981934\n",
      "Train Epoch: 280 [23040/60000 (38%)] Loss: -1225.484375\n",
      "Train Epoch: 280 [34304/60000 (57%)] Loss: -1224.443237\n",
      "Train Epoch: 280 [45568/60000 (76%)] Loss: -1190.884521\n",
      "Train Epoch: 280 [56832/60000 (95%)] Loss: -1190.082642\n",
      "    epoch          : 280\n",
      "    loss           : -1200.2545803953699\n",
      "Train Epoch: 281 [512/60000 (1%)] Loss: -1200.361938\n",
      "Train Epoch: 281 [11776/60000 (20%)] Loss: -1304.702393\n",
      "Train Epoch: 281 [23040/60000 (38%)] Loss: -1294.462402\n",
      "Train Epoch: 281 [34304/60000 (57%)] Loss: -1200.201904\n",
      "Train Epoch: 281 [45568/60000 (76%)] Loss: -1273.869873\n",
      "Train Epoch: 281 [56832/60000 (95%)] Loss: -1371.530273\n",
      "    epoch          : 281\n",
      "    loss           : -1190.750947769079\n",
      "Train Epoch: 282 [512/60000 (1%)] Loss: -972.608276\n",
      "Train Epoch: 282 [11776/60000 (20%)] Loss: -1162.253906\n",
      "Train Epoch: 282 [23040/60000 (38%)] Loss: -1198.433716\n",
      "Train Epoch: 282 [34304/60000 (57%)] Loss: -1213.809814\n",
      "Train Epoch: 282 [45568/60000 (76%)] Loss: -1161.186523\n",
      "Train Epoch: 282 [56832/60000 (95%)] Loss: -1082.324341\n",
      "    epoch          : 282\n",
      "    loss           : -1182.7514508780787\n",
      "Train Epoch: 283 [512/60000 (1%)] Loss: -1198.958862\n",
      "Train Epoch: 283 [11776/60000 (20%)] Loss: -804.620544\n",
      "Train Epoch: 283 [23040/60000 (38%)] Loss: -1249.232788\n",
      "Train Epoch: 283 [34304/60000 (57%)] Loss: -1159.977051\n",
      "Train Epoch: 283 [45568/60000 (76%)] Loss: -1067.004517\n",
      "Train Epoch: 283 [56832/60000 (95%)] Loss: -1239.726318\n",
      "    epoch          : 283\n",
      "    loss           : -1175.5416627011057\n",
      "Train Epoch: 284 [512/60000 (1%)] Loss: -1262.189697\n",
      "Train Epoch: 284 [11776/60000 (20%)] Loss: -1163.583496\n",
      "Train Epoch: 284 [23040/60000 (38%)] Loss: -963.700562\n",
      "Train Epoch: 284 [34304/60000 (57%)] Loss: -1202.701050\n",
      "Train Epoch: 284 [45568/60000 (76%)] Loss: -1273.422119\n",
      "Train Epoch: 284 [56832/60000 (95%)] Loss: -1154.080322\n",
      "    epoch          : 284\n",
      "    loss           : -1159.6956125033105\n",
      "Train Epoch: 285 [512/60000 (1%)] Loss: -1310.974365\n",
      "Train Epoch: 285 [11776/60000 (20%)] Loss: -1179.418213\n",
      "Train Epoch: 285 [23040/60000 (38%)] Loss: -1277.034180\n",
      "Train Epoch: 285 [34304/60000 (57%)] Loss: -1223.509888\n",
      "Train Epoch: 285 [45568/60000 (76%)] Loss: -1094.084717\n",
      "Train Epoch: 285 [56832/60000 (95%)] Loss: -1079.501343\n",
      "    epoch          : 285\n",
      "    loss           : -1178.6957426771605\n",
      "Train Epoch: 286 [512/60000 (1%)] Loss: -1029.994019\n",
      "Train Epoch: 286 [11776/60000 (20%)] Loss: -1219.421143\n",
      "Train Epoch: 286 [23040/60000 (38%)] Loss: -1148.409180\n",
      "Train Epoch: 286 [34304/60000 (57%)] Loss: -887.773926\n",
      "Train Epoch: 286 [45568/60000 (76%)] Loss: -1143.295166\n",
      "Train Epoch: 286 [56832/60000 (95%)] Loss: -1229.254272\n",
      "    epoch          : 286\n",
      "    loss           : -1188.9438230008057\n",
      "Train Epoch: 287 [512/60000 (1%)] Loss: -1236.133301\n",
      "Train Epoch: 287 [11776/60000 (20%)] Loss: -1071.679443\n",
      "Train Epoch: 287 [23040/60000 (38%)] Loss: -1300.680908\n",
      "Train Epoch: 287 [34304/60000 (57%)] Loss: -1207.268433\n",
      "Train Epoch: 287 [45568/60000 (76%)] Loss: -1012.562195\n",
      "Train Epoch: 287 [56832/60000 (95%)] Loss: -1207.462524\n",
      "    epoch          : 287\n",
      "    loss           : -1174.523645950576\n",
      "Train Epoch: 288 [512/60000 (1%)] Loss: -1218.260498\n",
      "Train Epoch: 288 [11776/60000 (20%)] Loss: -1084.005371\n",
      "Train Epoch: 288 [23040/60000 (38%)] Loss: -1235.330444\n",
      "Train Epoch: 288 [34304/60000 (57%)] Loss: -1159.944092\n",
      "Train Epoch: 288 [45568/60000 (76%)] Loss: -1336.107178\n",
      "Train Epoch: 288 [56832/60000 (95%)] Loss: -1196.174805\n",
      "    epoch          : 288\n",
      "    loss           : -1192.2951584293344\n",
      "Train Epoch: 289 [512/60000 (1%)] Loss: -1208.597168\n",
      "Train Epoch: 289 [11776/60000 (20%)] Loss: -1316.662476\n",
      "Train Epoch: 289 [23040/60000 (38%)] Loss: -1061.024170\n",
      "Train Epoch: 289 [34304/60000 (57%)] Loss: -1215.144897\n",
      "Train Epoch: 289 [45568/60000 (76%)] Loss: -1207.087402\n",
      "Train Epoch: 289 [56832/60000 (95%)] Loss: -1020.894653\n",
      "    epoch          : 289\n",
      "    loss           : -1165.9176902986515\n",
      "Train Epoch: 290 [512/60000 (1%)] Loss: -1382.766235\n",
      "Train Epoch: 290 [11776/60000 (20%)] Loss: -1226.640991\n",
      "Train Epoch: 290 [23040/60000 (38%)] Loss: -1291.839600\n",
      "Train Epoch: 290 [34304/60000 (57%)] Loss: -1169.988037\n",
      "Train Epoch: 290 [45568/60000 (76%)] Loss: -1237.231445\n",
      "Train Epoch: 290 [56832/60000 (95%)] Loss: -1357.513062\n",
      "    epoch          : 290\n",
      "    loss           : -1185.1188368285443\n",
      "Train Epoch: 291 [512/60000 (1%)] Loss: -1092.074829\n",
      "Train Epoch: 291 [11776/60000 (20%)] Loss: -1300.167969\n",
      "Train Epoch: 291 [23040/60000 (38%)] Loss: -1348.954468\n",
      "Train Epoch: 291 [34304/60000 (57%)] Loss: -913.020569\n",
      "Train Epoch: 291 [45568/60000 (76%)] Loss: -1190.400635\n",
      "Train Epoch: 291 [56832/60000 (95%)] Loss: -1198.555420\n",
      "    epoch          : 291\n",
      "    loss           : -1178.1778523073358\n",
      "Train Epoch: 292 [512/60000 (1%)] Loss: -1254.710938\n",
      "Train Epoch: 292 [11776/60000 (20%)] Loss: -1202.132812\n",
      "Train Epoch: 292 [23040/60000 (38%)] Loss: -1255.884277\n",
      "Train Epoch: 292 [34304/60000 (57%)] Loss: -1181.666016\n",
      "Train Epoch: 292 [45568/60000 (76%)] Loss: -1233.918457\n",
      "Train Epoch: 292 [56832/60000 (95%)] Loss: -1232.945312\n",
      "    epoch          : 292\n",
      "    loss           : -1186.2658562094477\n",
      "Train Epoch: 293 [512/60000 (1%)] Loss: -1382.487549\n",
      "Train Epoch: 293 [11776/60000 (20%)] Loss: -1032.372437\n",
      "Train Epoch: 293 [23040/60000 (38%)] Loss: -1091.728638\n",
      "Train Epoch: 293 [34304/60000 (57%)] Loss: -1073.538574\n",
      "Train Epoch: 293 [45568/60000 (76%)] Loss: -1042.164062\n",
      "Train Epoch: 293 [56832/60000 (95%)] Loss: -1236.842529\n",
      "    epoch          : 293\n",
      "    loss           : -1193.5999624823446\n",
      "Train Epoch: 294 [512/60000 (1%)] Loss: -1222.441406\n",
      "Train Epoch: 294 [11776/60000 (20%)] Loss: -946.144165\n",
      "Train Epoch: 294 [23040/60000 (38%)] Loss: -968.365356\n",
      "Train Epoch: 294 [34304/60000 (57%)] Loss: -1064.470093\n",
      "Train Epoch: 294 [45568/60000 (76%)] Loss: -1192.421997\n",
      "Train Epoch: 294 [56832/60000 (95%)] Loss: -1175.661255\n",
      "    epoch          : 294\n",
      "    loss           : -1170.1540499757239\n",
      "Train Epoch: 295 [512/60000 (1%)] Loss: -1228.174194\n",
      "Train Epoch: 295 [11776/60000 (20%)] Loss: -1311.999512\n",
      "Train Epoch: 295 [23040/60000 (38%)] Loss: -1225.845337\n",
      "Train Epoch: 295 [34304/60000 (57%)] Loss: -795.646240\n",
      "Train Epoch: 295 [45568/60000 (76%)] Loss: -1162.468506\n",
      "Train Epoch: 295 [56832/60000 (95%)] Loss: -1317.637695\n",
      "    epoch          : 295\n",
      "    loss           : -1154.2041403560315\n",
      "Train Epoch: 296 [512/60000 (1%)] Loss: -1308.843262\n",
      "Train Epoch: 296 [11776/60000 (20%)] Loss: -1177.396362\n",
      "Train Epoch: 296 [23040/60000 (38%)] Loss: -1236.072754\n",
      "Train Epoch: 296 [34304/60000 (57%)] Loss: -1265.752319\n",
      "Train Epoch: 296 [45568/60000 (76%)] Loss: -1317.255493\n",
      "Train Epoch: 296 [56832/60000 (95%)] Loss: -1217.315308\n",
      "    epoch          : 296\n",
      "    loss           : -1193.0977467682403\n",
      "Train Epoch: 297 [512/60000 (1%)] Loss: -1044.261230\n",
      "Train Epoch: 297 [11776/60000 (20%)] Loss: -1170.156006\n",
      "Train Epoch: 297 [23040/60000 (38%)] Loss: -1139.807495\n",
      "Train Epoch: 297 [34304/60000 (57%)] Loss: -1191.143921\n",
      "Train Epoch: 297 [45568/60000 (76%)] Loss: -1154.368164\n",
      "Train Epoch: 297 [56832/60000 (95%)] Loss: -1103.448120\n",
      "    epoch          : 297\n",
      "    loss           : -1198.7755585578875\n",
      "Train Epoch: 298 [512/60000 (1%)] Loss: -1356.153931\n",
      "Train Epoch: 298 [11776/60000 (20%)] Loss: -1290.062988\n",
      "Train Epoch: 298 [23040/60000 (38%)] Loss: -1307.947754\n",
      "Train Epoch: 298 [34304/60000 (57%)] Loss: -1252.468994\n",
      "Train Epoch: 298 [45568/60000 (76%)] Loss: -1156.493408\n",
      "Train Epoch: 298 [56832/60000 (95%)] Loss: -1202.767822\n",
      "    epoch          : 298\n",
      "    loss           : -1176.3490364376435\n",
      "Train Epoch: 299 [512/60000 (1%)] Loss: -1115.374390\n",
      "Train Epoch: 299 [11776/60000 (20%)] Loss: -1048.219238\n",
      "Train Epoch: 299 [23040/60000 (38%)] Loss: -1279.050049\n",
      "Train Epoch: 299 [34304/60000 (57%)] Loss: -960.963501\n",
      "Train Epoch: 299 [45568/60000 (76%)] Loss: -1321.244629\n",
      "Train Epoch: 299 [56832/60000 (95%)] Loss: -1037.507568\n",
      "    epoch          : 299\n",
      "    loss           : -1192.8668128406932\n",
      "Train Epoch: 300 [512/60000 (1%)] Loss: -1095.535034\n",
      "Train Epoch: 300 [11776/60000 (20%)] Loss: -1199.633789\n",
      "Train Epoch: 300 [23040/60000 (38%)] Loss: -1340.800781\n",
      "Train Epoch: 300 [34304/60000 (57%)] Loss: -1160.727173\n",
      "Train Epoch: 300 [45568/60000 (76%)] Loss: -1306.056396\n",
      "Train Epoch: 300 [56832/60000 (95%)] Loss: -1112.523071\n",
      "    epoch          : 300\n",
      "    loss           : -1188.798111565369\n",
      "Saving checkpoint: saved/models/Mnist_DeepGenerativeOperad/0127_111843/checkpoint-epoch300.pth ...\n",
      "Train Epoch: 301 [512/60000 (1%)] Loss: -1056.234863\n",
      "Train Epoch: 301 [11776/60000 (20%)] Loss: -1206.670654\n",
      "Train Epoch: 301 [23040/60000 (38%)] Loss: -1039.153931\n",
      "Train Epoch: 301 [34304/60000 (57%)] Loss: -1232.090820\n",
      "Train Epoch: 301 [45568/60000 (76%)] Loss: -1016.940552\n",
      "Train Epoch: 301 [56832/60000 (95%)] Loss: -1294.758179\n",
      "    epoch          : 301\n",
      "    loss           : -1179.7618204752603\n",
      "Train Epoch: 302 [512/60000 (1%)] Loss: -1185.330566\n",
      "Train Epoch: 302 [11776/60000 (20%)] Loss: -994.507568\n",
      "Train Epoch: 302 [23040/60000 (38%)] Loss: -1325.123535\n",
      "Train Epoch: 302 [34304/60000 (57%)] Loss: -1194.124268\n",
      "Train Epoch: 302 [45568/60000 (76%)] Loss: -1173.350098\n",
      "Train Epoch: 302 [56832/60000 (95%)] Loss: -1316.089966\n",
      "    epoch          : 302\n",
      "    loss           : -1184.0468922415696\n",
      "Train Epoch: 303 [512/60000 (1%)] Loss: -1221.786499\n",
      "Train Epoch: 303 [11776/60000 (20%)] Loss: -1310.593994\n",
      "Train Epoch: 303 [23040/60000 (38%)] Loss: -1178.242920\n",
      "Train Epoch: 303 [34304/60000 (57%)] Loss: -1315.525391\n",
      "Train Epoch: 303 [45568/60000 (76%)] Loss: -1359.166870\n",
      "Train Epoch: 303 [56832/60000 (95%)] Loss: -1105.235840\n",
      "    epoch          : 303\n",
      "    loss           : -1190.4142331915386\n",
      "Train Epoch: 304 [512/60000 (1%)] Loss: -1211.689087\n",
      "Train Epoch: 304 [11776/60000 (20%)] Loss: -985.479004\n",
      "Train Epoch: 304 [23040/60000 (38%)] Loss: -1121.197021\n",
      "Train Epoch: 304 [34304/60000 (57%)] Loss: -1233.861572\n",
      "Train Epoch: 304 [45568/60000 (76%)] Loss: -1122.936768\n",
      "Train Epoch: 304 [56832/60000 (95%)] Loss: -1096.002441\n",
      "    epoch          : 304\n",
      "    loss           : -1172.5315627620719\n",
      "Train Epoch: 305 [512/60000 (1%)] Loss: -1262.833862\n",
      "Train Epoch: 305 [11776/60000 (20%)] Loss: -1324.341431\n",
      "Train Epoch: 305 [23040/60000 (38%)] Loss: -1188.830078\n",
      "Train Epoch: 305 [34304/60000 (57%)] Loss: -1201.256104\n",
      "Train Epoch: 305 [45568/60000 (76%)] Loss: -1185.497437\n",
      "Train Epoch: 305 [56832/60000 (95%)] Loss: -1321.797607\n",
      "    epoch          : 305\n",
      "    loss           : -1183.7528258932514\n",
      "Train Epoch: 306 [512/60000 (1%)] Loss: -1362.725342\n",
      "Train Epoch: 306 [11776/60000 (20%)] Loss: -911.934082\n",
      "Train Epoch: 306 [23040/60000 (38%)] Loss: -1220.458740\n",
      "Train Epoch: 306 [34304/60000 (57%)] Loss: -1315.787964\n",
      "Train Epoch: 306 [45568/60000 (76%)] Loss: -1313.514648\n",
      "Train Epoch: 306 [56832/60000 (95%)] Loss: -1323.138672\n",
      "    epoch          : 306\n",
      "    loss           : -1195.3493391996049\n",
      "Train Epoch: 307 [512/60000 (1%)] Loss: -1078.758179\n",
      "Train Epoch: 307 [11776/60000 (20%)] Loss: -1269.640747\n",
      "Train Epoch: 307 [23040/60000 (38%)] Loss: -1248.492920\n",
      "Train Epoch: 307 [34304/60000 (57%)] Loss: -1192.173462\n",
      "Train Epoch: 307 [45568/60000 (76%)] Loss: -1035.288208\n",
      "Train Epoch: 307 [56832/60000 (95%)] Loss: -1181.544922\n",
      "    epoch          : 307\n",
      "    loss           : -1184.389150500971\n",
      "Train Epoch: 308 [512/60000 (1%)] Loss: -1241.083008\n",
      "Train Epoch: 308 [11776/60000 (20%)] Loss: -1100.854126\n",
      "Train Epoch: 308 [23040/60000 (38%)] Loss: -1160.537354\n",
      "Train Epoch: 308 [34304/60000 (57%)] Loss: -1283.763428\n",
      "Train Epoch: 308 [45568/60000 (76%)] Loss: -1074.876587\n",
      "Train Epoch: 308 [56832/60000 (95%)] Loss: -1044.720459\n",
      "    epoch          : 308\n",
      "    loss           : -1183.212784761763\n",
      "Train Epoch: 309 [512/60000 (1%)] Loss: -1182.562134\n",
      "Train Epoch: 309 [11776/60000 (20%)] Loss: -1374.861572\n",
      "Train Epoch: 309 [23040/60000 (38%)] Loss: -1169.069336\n",
      "Train Epoch: 309 [34304/60000 (57%)] Loss: -1154.762207\n",
      "Train Epoch: 309 [45568/60000 (76%)] Loss: -1036.091797\n",
      "Train Epoch: 309 [56832/60000 (95%)] Loss: -1059.435425\n",
      "    epoch          : 309\n",
      "    loss           : -1186.8975299037784\n",
      "Train Epoch: 310 [512/60000 (1%)] Loss: -1087.028076\n",
      "Train Epoch: 310 [11776/60000 (20%)] Loss: -1349.709473\n",
      "Train Epoch: 310 [23040/60000 (38%)] Loss: -914.361755\n",
      "Train Epoch: 310 [34304/60000 (57%)] Loss: -1081.746094\n",
      "Train Epoch: 310 [45568/60000 (76%)] Loss: -1250.508545\n",
      "Train Epoch: 310 [56832/60000 (95%)] Loss: -1080.073853\n",
      "    epoch          : 310\n",
      "    loss           : -1194.9079765707759\n",
      "Train Epoch: 311 [512/60000 (1%)] Loss: -1342.083740\n",
      "Train Epoch: 311 [11776/60000 (20%)] Loss: -1227.108398\n",
      "Train Epoch: 311 [23040/60000 (38%)] Loss: -1243.407715\n",
      "Train Epoch: 311 [34304/60000 (57%)] Loss: -1206.055908\n",
      "Train Epoch: 311 [45568/60000 (76%)] Loss: -1275.930420\n",
      "Train Epoch: 311 [56832/60000 (95%)] Loss: -1092.612183\n",
      "    epoch          : 311\n",
      "    loss           : -1186.4026158219676\n",
      "Train Epoch: 312 [512/60000 (1%)] Loss: -1388.256104\n",
      "Train Epoch: 312 [11776/60000 (20%)] Loss: -1202.709229\n",
      "Train Epoch: 312 [23040/60000 (38%)] Loss: -1275.183594\n",
      "Train Epoch: 312 [34304/60000 (57%)] Loss: -1084.862793\n",
      "Train Epoch: 312 [45568/60000 (76%)] Loss: -1349.290527\n",
      "Train Epoch: 312 [56832/60000 (95%)] Loss: -1259.737915\n",
      "    epoch          : 312\n",
      "    loss           : -1199.3424679168875\n",
      "Train Epoch: 313 [512/60000 (1%)] Loss: -1083.597778\n",
      "Train Epoch: 313 [11776/60000 (20%)] Loss: -1202.519653\n",
      "Train Epoch: 313 [23040/60000 (38%)] Loss: -1182.079712\n",
      "Train Epoch: 313 [34304/60000 (57%)] Loss: -1333.167114\n",
      "Train Epoch: 313 [45568/60000 (76%)] Loss: -1192.960449\n",
      "Train Epoch: 313 [56832/60000 (95%)] Loss: -1223.934082\n",
      "    epoch          : 313\n",
      "    loss           : -1186.0895340914108\n",
      "Train Epoch: 314 [512/60000 (1%)] Loss: -1027.480469\n",
      "Train Epoch: 314 [11776/60000 (20%)] Loss: -1302.624146\n",
      "Train Epoch: 314 [23040/60000 (38%)] Loss: -1251.027832\n",
      "Train Epoch: 314 [34304/60000 (57%)] Loss: -1191.289551\n",
      "Train Epoch: 314 [45568/60000 (76%)] Loss: -1372.441040\n",
      "Train Epoch: 314 [56832/60000 (95%)] Loss: -1101.458496\n",
      "    epoch          : 314\n",
      "    loss           : -1177.8107201527741\n",
      "Train Epoch: 315 [512/60000 (1%)] Loss: -1179.964966\n",
      "Train Epoch: 315 [11776/60000 (20%)] Loss: -812.032227\n",
      "Train Epoch: 315 [23040/60000 (38%)] Loss: -936.683472\n",
      "Train Epoch: 315 [34304/60000 (57%)] Loss: -1046.708496\n",
      "Train Epoch: 315 [45568/60000 (76%)] Loss: -899.857544\n",
      "Train Epoch: 315 [56832/60000 (95%)] Loss: -1352.490479\n",
      "    epoch          : 315\n",
      "    loss           : -1190.4168087372\n",
      "Train Epoch: 316 [512/60000 (1%)] Loss: -1297.089233\n",
      "Train Epoch: 316 [11776/60000 (20%)] Loss: -1030.279541\n",
      "Train Epoch: 316 [23040/60000 (38%)] Loss: -1116.558960\n",
      "Train Epoch: 316 [34304/60000 (57%)] Loss: -1388.090698\n",
      "Train Epoch: 316 [45568/60000 (76%)] Loss: -1137.634277\n",
      "Train Epoch: 316 [56832/60000 (95%)] Loss: -1239.121948\n",
      "    epoch          : 316\n",
      "    loss           : -1191.3653435141352\n",
      "Train Epoch: 317 [512/60000 (1%)] Loss: -1116.754150\n",
      "Train Epoch: 317 [11776/60000 (20%)] Loss: -1045.005615\n",
      "Train Epoch: 317 [23040/60000 (38%)] Loss: -1174.953491\n",
      "Train Epoch: 317 [34304/60000 (57%)] Loss: -1147.508545\n",
      "Train Epoch: 317 [45568/60000 (76%)] Loss: -1095.597168\n",
      "Train Epoch: 317 [56832/60000 (95%)] Loss: -1225.988159\n",
      "    epoch          : 317\n",
      "    loss           : -1183.1316671425338\n",
      "Train Epoch: 318 [512/60000 (1%)] Loss: -1170.101929\n",
      "Train Epoch: 318 [11776/60000 (20%)] Loss: -1038.881714\n",
      "Train Epoch: 318 [23040/60000 (38%)] Loss: -1269.354492\n",
      "Train Epoch: 318 [34304/60000 (57%)] Loss: -1165.624268\n",
      "Train Epoch: 318 [45568/60000 (76%)] Loss: -1088.878174\n",
      "Train Epoch: 318 [56832/60000 (95%)] Loss: -1293.201660\n",
      "    epoch          : 318\n",
      "    loss           : -1179.6218609998457\n",
      "Train Epoch: 319 [512/60000 (1%)] Loss: -1298.335693\n",
      "Train Epoch: 319 [11776/60000 (20%)] Loss: -1203.133789\n",
      "Train Epoch: 319 [23040/60000 (38%)] Loss: -1212.611328\n",
      "Train Epoch: 319 [34304/60000 (57%)] Loss: -1307.454468\n",
      "Train Epoch: 319 [45568/60000 (76%)] Loss: -1146.115234\n",
      "Train Epoch: 319 [56832/60000 (95%)] Loss: -1274.477661\n",
      "    epoch          : 319\n",
      "    loss           : -1211.0856033583818\n",
      "Train Epoch: 320 [512/60000 (1%)] Loss: -1325.729492\n",
      "Train Epoch: 320 [11776/60000 (20%)] Loss: -1251.151001\n",
      "Train Epoch: 320 [23040/60000 (38%)] Loss: -1103.619385\n",
      "Train Epoch: 320 [34304/60000 (57%)] Loss: -1028.057007\n",
      "Train Epoch: 320 [45568/60000 (76%)] Loss: -1221.916016\n",
      "Train Epoch: 320 [56832/60000 (95%)] Loss: -1124.384277\n",
      "    epoch          : 320\n",
      "    loss           : -1189.4619999255165\n",
      "Train Epoch: 321 [512/60000 (1%)] Loss: -1100.680420\n",
      "Train Epoch: 321 [11776/60000 (20%)] Loss: -1306.285156\n",
      "Train Epoch: 321 [23040/60000 (38%)] Loss: -1176.171631\n",
      "Train Epoch: 321 [34304/60000 (57%)] Loss: -1322.252930\n",
      "Train Epoch: 321 [45568/60000 (76%)] Loss: -1160.787598\n",
      "Train Epoch: 321 [56832/60000 (95%)] Loss: -1286.300049\n",
      "    epoch          : 321\n",
      "    loss           : -1172.5207467806542\n",
      "Train Epoch: 322 [512/60000 (1%)] Loss: -1370.530518\n",
      "Train Epoch: 322 [11776/60000 (20%)] Loss: -924.517883\n",
      "Train Epoch: 322 [23040/60000 (38%)] Loss: -1227.212646\n",
      "Train Epoch: 322 [34304/60000 (57%)] Loss: -1040.818848\n",
      "Train Epoch: 322 [45568/60000 (76%)] Loss: -1281.268066\n",
      "Train Epoch: 322 [56832/60000 (95%)] Loss: -1154.630371\n",
      "    epoch          : 322\n",
      "    loss           : -1172.4016325352557\n",
      "Train Epoch: 323 [512/60000 (1%)] Loss: -1170.211914\n",
      "Train Epoch: 323 [11776/60000 (20%)] Loss: -1138.762451\n",
      "Train Epoch: 323 [23040/60000 (38%)] Loss: -1235.353516\n",
      "Train Epoch: 323 [34304/60000 (57%)] Loss: -1166.876587\n",
      "Train Epoch: 323 [45568/60000 (76%)] Loss: -1323.656616\n",
      "Train Epoch: 323 [56832/60000 (95%)] Loss: -964.539429\n",
      "    epoch          : 323\n",
      "    loss           : -1179.8902682719258\n",
      "Train Epoch: 324 [512/60000 (1%)] Loss: -1079.111206\n",
      "Train Epoch: 324 [11776/60000 (20%)] Loss: -1167.281372\n",
      "Train Epoch: 324 [23040/60000 (38%)] Loss: -921.159119\n",
      "Train Epoch: 324 [34304/60000 (57%)] Loss: -1291.298462\n",
      "Train Epoch: 324 [45568/60000 (76%)] Loss: -1016.589478\n",
      "Train Epoch: 324 [56832/60000 (95%)] Loss: -1199.253784\n",
      "    epoch          : 324\n",
      "    loss           : -1183.7989970923816\n",
      "Train Epoch: 325 [512/60000 (1%)] Loss: -1263.917114\n",
      "Train Epoch: 325 [11776/60000 (20%)] Loss: -1128.670288\n",
      "Train Epoch: 325 [23040/60000 (38%)] Loss: -1192.952515\n",
      "Train Epoch: 325 [34304/60000 (57%)] Loss: -940.614014\n",
      "Train Epoch: 325 [45568/60000 (76%)] Loss: -1310.750244\n",
      "Train Epoch: 325 [56832/60000 (95%)] Loss: -1337.668457\n",
      "    epoch          : 325\n",
      "    loss           : -1182.6479109424656\n",
      "Train Epoch: 326 [512/60000 (1%)] Loss: -1094.874512\n",
      "Train Epoch: 326 [11776/60000 (20%)] Loss: -1397.053223\n",
      "Train Epoch: 326 [23040/60000 (38%)] Loss: -878.337280\n",
      "Train Epoch: 326 [34304/60000 (57%)] Loss: -1030.458618\n",
      "Train Epoch: 326 [45568/60000 (76%)] Loss: -1228.204956\n",
      "Train Epoch: 326 [56832/60000 (95%)] Loss: -1248.663208\n",
      "    epoch          : 326\n",
      "    loss           : -1181.3853425279176\n",
      "Train Epoch: 327 [512/60000 (1%)] Loss: -926.168945\n",
      "Train Epoch: 327 [11776/60000 (20%)] Loss: -1303.033081\n",
      "Train Epoch: 327 [23040/60000 (38%)] Loss: -1243.430542\n",
      "Train Epoch: 327 [34304/60000 (57%)] Loss: -1185.730713\n",
      "Train Epoch: 327 [45568/60000 (76%)] Loss: -1085.788086\n",
      "Train Epoch: 327 [56832/60000 (95%)] Loss: -1318.963013\n",
      "    epoch          : 327\n",
      "    loss           : -1170.2641617079912\n",
      "Train Epoch: 328 [512/60000 (1%)] Loss: -1233.972290\n",
      "Train Epoch: 328 [11776/60000 (20%)] Loss: -1234.574463\n",
      "Train Epoch: 328 [23040/60000 (38%)] Loss: -1091.215820\n",
      "Train Epoch: 328 [34304/60000 (57%)] Loss: -1171.160889\n",
      "Train Epoch: 328 [45568/60000 (76%)] Loss: -1119.834106\n",
      "Train Epoch: 328 [56832/60000 (95%)] Loss: -1179.219482\n",
      "    epoch          : 328\n",
      "    loss           : -1198.4505977307335\n",
      "Train Epoch: 329 [512/60000 (1%)] Loss: -1247.482056\n",
      "Train Epoch: 329 [11776/60000 (20%)] Loss: -1142.498047\n",
      "Train Epoch: 329 [23040/60000 (38%)] Loss: -1121.621216\n",
      "Train Epoch: 329 [34304/60000 (57%)] Loss: -1122.410278\n",
      "Train Epoch: 329 [45568/60000 (76%)] Loss: -1284.346191\n",
      "Train Epoch: 329 [56832/60000 (95%)] Loss: -1346.315674\n",
      "    epoch          : 329\n",
      "    loss           : -1199.6429965778932\n",
      "Train Epoch: 330 [512/60000 (1%)] Loss: -986.288574\n",
      "Train Epoch: 330 [11776/60000 (20%)] Loss: -1081.188965\n",
      "Train Epoch: 330 [23040/60000 (38%)] Loss: -1361.252319\n",
      "Train Epoch: 330 [34304/60000 (57%)] Loss: -1175.561890\n",
      "Train Epoch: 330 [45568/60000 (76%)] Loss: -1082.189453\n",
      "Train Epoch: 330 [56832/60000 (95%)] Loss: -1230.764771\n",
      "    epoch          : 330\n",
      "    loss           : -1184.4489449538753\n",
      "Train Epoch: 331 [512/60000 (1%)] Loss: -1166.844727\n",
      "Train Epoch: 331 [11776/60000 (20%)] Loss: -1262.269653\n",
      "Train Epoch: 331 [23040/60000 (38%)] Loss: -1222.879639\n",
      "Train Epoch: 331 [34304/60000 (57%)] Loss: -1035.648682\n",
      "Train Epoch: 331 [45568/60000 (76%)] Loss: -1237.742676\n",
      "Train Epoch: 331 [56832/60000 (95%)] Loss: -1020.506714\n",
      "    epoch          : 331\n",
      "    loss           : -1189.205556750971\n",
      "Train Epoch: 332 [512/60000 (1%)] Loss: -1199.364258\n",
      "Train Epoch: 332 [11776/60000 (20%)] Loss: -1239.442871\n",
      "Train Epoch: 332 [23040/60000 (38%)] Loss: -1351.747803\n",
      "Train Epoch: 332 [34304/60000 (57%)] Loss: -1282.591797\n",
      "Train Epoch: 332 [45568/60000 (76%)] Loss: -1066.350220\n",
      "Train Epoch: 332 [56832/60000 (95%)] Loss: -1256.341431\n",
      "    epoch          : 332\n",
      "    loss           : -1205.9481397725767\n",
      "Train Epoch: 333 [512/60000 (1%)] Loss: -1187.687988\n",
      "Train Epoch: 333 [11776/60000 (20%)] Loss: -1377.274414\n",
      "Train Epoch: 333 [23040/60000 (38%)] Loss: -1218.192627\n",
      "Train Epoch: 333 [34304/60000 (57%)] Loss: -1291.518921\n",
      "Train Epoch: 333 [45568/60000 (76%)] Loss: -1071.876465\n",
      "Train Epoch: 333 [56832/60000 (95%)] Loss: -1069.852051\n",
      "    epoch          : 333\n",
      "    loss           : -1196.3385582185733\n",
      "Train Epoch: 334 [512/60000 (1%)] Loss: -1242.633789\n",
      "Train Epoch: 334 [11776/60000 (20%)] Loss: -1251.824951\n",
      "Train Epoch: 334 [23040/60000 (38%)] Loss: -1292.956421\n",
      "Train Epoch: 334 [34304/60000 (57%)] Loss: -1151.205078\n",
      "Train Epoch: 334 [45568/60000 (76%)] Loss: -1168.305664\n",
      "Train Epoch: 334 [56832/60000 (95%)] Loss: -1123.955566\n",
      "    epoch          : 334\n",
      "    loss           : -1193.3273703365003\n",
      "Train Epoch: 335 [512/60000 (1%)] Loss: -1172.314453\n",
      "Train Epoch: 335 [11776/60000 (20%)] Loss: -1090.894043\n",
      "Train Epoch: 335 [23040/60000 (38%)] Loss: -1335.893799\n",
      "Train Epoch: 335 [34304/60000 (57%)] Loss: -1118.639893\n",
      "Train Epoch: 335 [45568/60000 (76%)] Loss: -1199.916626\n",
      "Train Epoch: 335 [56832/60000 (95%)] Loss: -1230.849121\n",
      "    epoch          : 335\n",
      "    loss           : -1204.8925531247241\n",
      "Train Epoch: 336 [512/60000 (1%)] Loss: -1255.332764\n",
      "Train Epoch: 336 [11776/60000 (20%)] Loss: -1298.755859\n",
      "Train Epoch: 336 [23040/60000 (38%)] Loss: -1031.532104\n",
      "Train Epoch: 336 [34304/60000 (57%)] Loss: -1164.933472\n",
      "Train Epoch: 336 [45568/60000 (76%)] Loss: -1095.185547\n",
      "Train Epoch: 336 [56832/60000 (95%)] Loss: -1397.943848\n",
      "    epoch          : 336\n",
      "    loss           : -1204.8653362726761\n",
      "Train Epoch: 337 [512/60000 (1%)] Loss: -1038.022949\n",
      "Train Epoch: 337 [11776/60000 (20%)] Loss: -1401.312012\n",
      "Train Epoch: 337 [23040/60000 (38%)] Loss: -1065.187988\n",
      "Train Epoch: 337 [34304/60000 (57%)] Loss: -1270.458130\n",
      "Train Epoch: 337 [45568/60000 (76%)] Loss: -978.211609\n",
      "Train Epoch: 337 [56832/60000 (95%)] Loss: -1186.084473\n",
      "    epoch          : 337\n",
      "    loss           : -1191.8321617686818\n",
      "Train Epoch: 338 [512/60000 (1%)] Loss: -1310.720581\n",
      "Train Epoch: 338 [11776/60000 (20%)] Loss: -1295.694092\n",
      "Train Epoch: 338 [23040/60000 (38%)] Loss: -1269.044678\n",
      "Train Epoch: 338 [34304/60000 (57%)] Loss: -1225.380249\n",
      "Train Epoch: 338 [45568/60000 (76%)] Loss: -1222.933594\n",
      "Train Epoch: 338 [56832/60000 (95%)] Loss: -1243.416504\n",
      "    epoch          : 338\n",
      "    loss           : -1199.707350219037\n",
      "Train Epoch: 339 [512/60000 (1%)] Loss: -1254.608887\n",
      "Train Epoch: 339 [11776/60000 (20%)] Loss: -1334.981201\n",
      "Train Epoch: 339 [23040/60000 (38%)] Loss: -1190.927002\n",
      "Train Epoch: 339 [34304/60000 (57%)] Loss: -1239.498169\n",
      "Train Epoch: 339 [45568/60000 (76%)] Loss: -1187.809326\n",
      "Train Epoch: 339 [56832/60000 (95%)] Loss: -1101.793945\n",
      "    epoch          : 339\n",
      "    loss           : -1204.4691472457628\n",
      "Train Epoch: 340 [512/60000 (1%)] Loss: -1185.904785\n",
      "Train Epoch: 340 [11776/60000 (20%)] Loss: -1219.028320\n",
      "Train Epoch: 340 [23040/60000 (38%)] Loss: -1083.906616\n",
      "Train Epoch: 340 [34304/60000 (57%)] Loss: -1319.892090\n",
      "Train Epoch: 340 [45568/60000 (76%)] Loss: -1177.603271\n",
      "Train Epoch: 340 [56832/60000 (95%)] Loss: -1195.441895\n",
      "    epoch          : 340\n",
      "    loss           : -1200.730326679467\n",
      "Train Epoch: 341 [512/60000 (1%)] Loss: -1219.889282\n",
      "Train Epoch: 341 [11776/60000 (20%)] Loss: -1087.400391\n",
      "Train Epoch: 341 [23040/60000 (38%)] Loss: -1188.213379\n",
      "Train Epoch: 341 [34304/60000 (57%)] Loss: -1096.305786\n",
      "Train Epoch: 341 [45568/60000 (76%)] Loss: -1194.851562\n",
      "Train Epoch: 341 [56832/60000 (95%)] Loss: -1020.071533\n",
      "    epoch          : 341\n",
      "    loss           : -1204.4979558395128\n",
      "Train Epoch: 342 [512/60000 (1%)] Loss: -1345.197998\n",
      "Train Epoch: 342 [11776/60000 (20%)] Loss: -1245.918335\n",
      "Train Epoch: 342 [23040/60000 (38%)] Loss: -1037.856079\n",
      "Train Epoch: 342 [34304/60000 (57%)] Loss: -1261.774780\n",
      "Train Epoch: 342 [45568/60000 (76%)] Loss: -1339.618896\n",
      "Train Epoch: 342 [56832/60000 (95%)] Loss: -1203.852783\n",
      "    epoch          : 342\n",
      "    loss           : -1211.042940991073\n",
      "Train Epoch: 343 [512/60000 (1%)] Loss: -1364.431396\n",
      "Train Epoch: 343 [11776/60000 (20%)] Loss: -936.006836\n",
      "Train Epoch: 343 [23040/60000 (38%)] Loss: -1337.758301\n",
      "Train Epoch: 343 [34304/60000 (57%)] Loss: -1244.976929\n",
      "Train Epoch: 343 [45568/60000 (76%)] Loss: -1092.938477\n",
      "Train Epoch: 343 [56832/60000 (95%)] Loss: -1272.655762\n",
      "    epoch          : 343\n",
      "    loss           : -1198.691233489473\n",
      "Train Epoch: 344 [512/60000 (1%)] Loss: -1091.639526\n",
      "Train Epoch: 344 [11776/60000 (20%)] Loss: -1400.847046\n",
      "Train Epoch: 344 [23040/60000 (38%)] Loss: -1238.204590\n",
      "Train Epoch: 344 [34304/60000 (57%)] Loss: -1246.119263\n",
      "Train Epoch: 344 [45568/60000 (76%)] Loss: -1224.177246\n",
      "Train Epoch: 344 [56832/60000 (95%)] Loss: -1087.811768\n",
      "    epoch          : 344\n",
      "    loss           : -1214.4565546930173\n",
      "Train Epoch: 345 [512/60000 (1%)] Loss: -1208.017700\n",
      "Train Epoch: 345 [11776/60000 (20%)] Loss: -1311.283569\n",
      "Train Epoch: 345 [23040/60000 (38%)] Loss: -1194.867554\n",
      "Train Epoch: 345 [34304/60000 (57%)] Loss: -1074.619873\n",
      "Train Epoch: 345 [45568/60000 (76%)] Loss: -1185.961670\n",
      "Train Epoch: 345 [56832/60000 (95%)] Loss: -1308.671631\n",
      "    epoch          : 345\n",
      "    loss           : -1212.861929166115\n",
      "Train Epoch: 346 [512/60000 (1%)] Loss: -905.934021\n",
      "Train Epoch: 346 [11776/60000 (20%)] Loss: -1210.148315\n",
      "Train Epoch: 346 [23040/60000 (38%)] Loss: -1342.291748\n",
      "Train Epoch: 346 [34304/60000 (57%)] Loss: -1364.291260\n",
      "Train Epoch: 346 [45568/60000 (76%)] Loss: -1325.484009\n",
      "Train Epoch: 346 [56832/60000 (95%)] Loss: -1205.949463\n",
      "    epoch          : 346\n",
      "    loss           : -1214.5996176509534\n",
      "Train Epoch: 347 [512/60000 (1%)] Loss: -1036.820801\n",
      "Train Epoch: 347 [11776/60000 (20%)] Loss: -1352.030273\n",
      "Train Epoch: 347 [23040/60000 (38%)] Loss: -1191.337280\n",
      "Train Epoch: 347 [34304/60000 (57%)] Loss: -1181.655273\n",
      "Train Epoch: 347 [45568/60000 (76%)] Loss: -1193.858521\n",
      "Train Epoch: 347 [56832/60000 (95%)] Loss: -1212.860107\n",
      "    epoch          : 347\n",
      "    loss           : -1222.187733968099\n",
      "Train Epoch: 348 [512/60000 (1%)] Loss: -1360.177490\n",
      "Train Epoch: 348 [11776/60000 (20%)] Loss: -1172.101807\n",
      "Train Epoch: 348 [23040/60000 (38%)] Loss: -1248.033569\n",
      "Train Epoch: 348 [34304/60000 (57%)] Loss: -1160.536499\n",
      "Train Epoch: 348 [45568/60000 (76%)] Loss: -1198.704834\n",
      "Train Epoch: 348 [56832/60000 (95%)] Loss: -1247.099609\n",
      "    epoch          : 348\n",
      "    loss           : -1221.1880198333222\n",
      "Train Epoch: 349 [512/60000 (1%)] Loss: -1193.172119\n",
      "Train Epoch: 349 [11776/60000 (20%)] Loss: -1321.146484\n",
      "Train Epoch: 349 [23040/60000 (38%)] Loss: -1083.134644\n",
      "Train Epoch: 349 [34304/60000 (57%)] Loss: -1192.802979\n",
      "Train Epoch: 349 [45568/60000 (76%)] Loss: -1343.119629\n",
      "Train Epoch: 349 [56832/60000 (95%)] Loss: -1219.636597\n",
      "    epoch          : 349\n",
      "    loss           : -1231.1519535732807\n",
      "Train Epoch: 350 [512/60000 (1%)] Loss: -1046.186035\n",
      "Train Epoch: 350 [11776/60000 (20%)] Loss: -1188.121948\n",
      "Train Epoch: 350 [23040/60000 (38%)] Loss: -1327.797363\n",
      "Train Epoch: 350 [34304/60000 (57%)] Loss: -1236.940308\n",
      "Train Epoch: 350 [45568/60000 (76%)] Loss: -1223.778931\n",
      "Train Epoch: 350 [56832/60000 (95%)] Loss: -1240.328857\n",
      "    epoch          : 350\n",
      "    loss           : -1211.2368326133255\n",
      "Train Epoch: 351 [512/60000 (1%)] Loss: -1176.403564\n",
      "Train Epoch: 351 [11776/60000 (20%)] Loss: -1325.519653\n",
      "Train Epoch: 351 [23040/60000 (38%)] Loss: -1235.379028\n",
      "Train Epoch: 351 [34304/60000 (57%)] Loss: -1246.294434\n",
      "Train Epoch: 351 [45568/60000 (76%)] Loss: -1176.829346\n",
      "Train Epoch: 351 [56832/60000 (95%)] Loss: -1372.829224\n",
      "    epoch          : 351\n",
      "    loss           : -1215.2208065744173\n",
      "Train Epoch: 352 [512/60000 (1%)] Loss: -1162.249512\n",
      "Train Epoch: 352 [11776/60000 (20%)] Loss: -1056.240234\n",
      "Train Epoch: 352 [23040/60000 (38%)] Loss: -1204.480469\n",
      "Train Epoch: 352 [34304/60000 (57%)] Loss: -1037.588989\n",
      "Train Epoch: 352 [45568/60000 (76%)] Loss: -1307.444946\n",
      "Train Epoch: 352 [56832/60000 (95%)] Loss: -1179.444092\n",
      "    epoch          : 352\n",
      "    loss           : -1208.3676749191716\n",
      "Train Epoch: 353 [512/60000 (1%)] Loss: -1290.517578\n",
      "Train Epoch: 353 [11776/60000 (20%)] Loss: -1213.221680\n",
      "Train Epoch: 353 [23040/60000 (38%)] Loss: -1352.275635\n",
      "Train Epoch: 353 [34304/60000 (57%)] Loss: -1365.665771\n",
      "Train Epoch: 353 [45568/60000 (76%)] Loss: -1247.270264\n",
      "Train Epoch: 353 [56832/60000 (95%)] Loss: -1254.357056\n",
      "    epoch          : 353\n",
      "    loss           : -1220.2523072668387\n",
      "Train Epoch: 354 [512/60000 (1%)] Loss: -1084.558105\n",
      "Train Epoch: 354 [11776/60000 (20%)] Loss: -1236.564697\n",
      "Train Epoch: 354 [23040/60000 (38%)] Loss: -1325.231934\n",
      "Train Epoch: 354 [34304/60000 (57%)] Loss: -1226.081055\n",
      "Train Epoch: 354 [45568/60000 (76%)] Loss: -1376.892578\n",
      "Train Epoch: 354 [56832/60000 (95%)] Loss: -1092.543701\n",
      "    epoch          : 354\n",
      "    loss           : -1218.871136336677\n",
      "Train Epoch: 355 [512/60000 (1%)] Loss: -1056.980713\n",
      "Train Epoch: 355 [11776/60000 (20%)] Loss: -1159.824341\n",
      "Train Epoch: 355 [23040/60000 (38%)] Loss: -1228.806152\n",
      "Train Epoch: 355 [34304/60000 (57%)] Loss: -1364.271973\n",
      "Train Epoch: 355 [45568/60000 (76%)] Loss: -1267.652832\n",
      "Train Epoch: 355 [56832/60000 (95%)] Loss: -1213.803223\n",
      "    epoch          : 355\n",
      "    loss           : -1219.8755531095517\n",
      "Train Epoch: 356 [512/60000 (1%)] Loss: -1220.309937\n",
      "Train Epoch: 356 [11776/60000 (20%)] Loss: -1205.257080\n",
      "Train Epoch: 356 [23040/60000 (38%)] Loss: -1370.931641\n",
      "Train Epoch: 356 [34304/60000 (57%)] Loss: -1203.344849\n",
      "Train Epoch: 356 [45568/60000 (76%)] Loss: -1108.862061\n",
      "Train Epoch: 356 [56832/60000 (95%)] Loss: -1337.876953\n",
      "    epoch          : 356\n",
      "    loss           : -1225.0658869339247\n",
      "Train Epoch: 357 [512/60000 (1%)] Loss: -1217.501465\n",
      "Train Epoch: 357 [11776/60000 (20%)] Loss: -1127.698120\n",
      "Train Epoch: 357 [23040/60000 (38%)] Loss: -1219.457764\n",
      "Train Epoch: 357 [34304/60000 (57%)] Loss: -1356.248413\n",
      "Train Epoch: 357 [45568/60000 (76%)] Loss: -1335.475830\n",
      "Train Epoch: 357 [56832/60000 (95%)] Loss: -1305.889282\n",
      "    epoch          : 357\n",
      "    loss           : -1220.3914643196063\n",
      "Train Epoch: 358 [512/60000 (1%)] Loss: -1224.769165\n",
      "Train Epoch: 358 [11776/60000 (20%)] Loss: -1182.248047\n",
      "Train Epoch: 358 [23040/60000 (38%)] Loss: -1210.098633\n",
      "Train Epoch: 358 [34304/60000 (57%)] Loss: -1076.950195\n",
      "Train Epoch: 358 [45568/60000 (76%)] Loss: -1383.303223\n",
      "Train Epoch: 358 [56832/60000 (95%)] Loss: -1344.506348\n",
      "    epoch          : 358\n",
      "    loss           : -1205.8380149367167\n",
      "Train Epoch: 359 [512/60000 (1%)] Loss: -1022.281616\n",
      "Train Epoch: 359 [11776/60000 (20%)] Loss: -1272.500732\n",
      "Train Epoch: 359 [23040/60000 (38%)] Loss: -1091.824585\n",
      "Train Epoch: 359 [34304/60000 (57%)] Loss: -1376.316406\n",
      "Train Epoch: 359 [45568/60000 (76%)] Loss: -1076.484741\n",
      "Train Epoch: 359 [56832/60000 (95%)] Loss: -1089.140381\n",
      "    epoch          : 359\n",
      "    loss           : -1197.418556687522\n",
      "Train Epoch: 360 [512/60000 (1%)] Loss: -1365.211060\n",
      "Train Epoch: 360 [11776/60000 (20%)] Loss: -1216.703369\n",
      "Train Epoch: 360 [23040/60000 (38%)] Loss: -1345.031494\n",
      "Train Epoch: 360 [34304/60000 (57%)] Loss: -1182.401611\n",
      "Train Epoch: 360 [45568/60000 (76%)] Loss: -915.307251\n",
      "Train Epoch: 360 [56832/60000 (95%)] Loss: -1211.994507\n",
      "    epoch          : 360\n",
      "    loss           : -1218.9337599587307\n",
      "Train Epoch: 361 [512/60000 (1%)] Loss: -1112.968018\n",
      "Train Epoch: 361 [11776/60000 (20%)] Loss: -1149.658813\n",
      "Train Epoch: 361 [23040/60000 (38%)] Loss: -1191.647217\n",
      "Train Epoch: 361 [34304/60000 (57%)] Loss: -1213.622681\n",
      "Train Epoch: 361 [45568/60000 (76%)] Loss: -1185.319824\n",
      "Train Epoch: 361 [56832/60000 (95%)] Loss: -1238.105835\n",
      "    epoch          : 361\n",
      "    loss           : -1224.1035223492122\n",
      "Train Epoch: 362 [512/60000 (1%)] Loss: -1052.355591\n",
      "Train Epoch: 362 [11776/60000 (20%)] Loss: -1301.593750\n",
      "Train Epoch: 362 [23040/60000 (38%)] Loss: -1230.350830\n",
      "Train Epoch: 362 [34304/60000 (57%)] Loss: -1243.919800\n",
      "Train Epoch: 362 [45568/60000 (76%)] Loss: -1365.171875\n",
      "Train Epoch: 362 [56832/60000 (95%)] Loss: -1325.697021\n",
      "    epoch          : 362\n",
      "    loss           : -1216.821477685271\n",
      "Train Epoch: 363 [512/60000 (1%)] Loss: -1362.835693\n",
      "Train Epoch: 363 [11776/60000 (20%)] Loss: -1209.379639\n",
      "Train Epoch: 363 [23040/60000 (38%)] Loss: -1396.570557\n",
      "Train Epoch: 363 [34304/60000 (57%)] Loss: -1381.840210\n",
      "Train Epoch: 363 [45568/60000 (76%)] Loss: -1215.020508\n",
      "Train Epoch: 363 [56832/60000 (95%)] Loss: -1258.034424\n",
      "    epoch          : 363\n",
      "    loss           : -1209.187415516309\n",
      "Train Epoch: 364 [512/60000 (1%)] Loss: -1137.427246\n",
      "Train Epoch: 364 [11776/60000 (20%)] Loss: -1372.172852\n",
      "Train Epoch: 364 [23040/60000 (38%)] Loss: -1216.147705\n",
      "Train Epoch: 364 [34304/60000 (57%)] Loss: -1088.784180\n",
      "Train Epoch: 364 [45568/60000 (76%)] Loss: -1375.463135\n",
      "Train Epoch: 364 [56832/60000 (95%)] Loss: -1361.569336\n",
      "    epoch          : 364\n",
      "    loss           : -1202.7383533197608\n",
      "Train Epoch: 365 [512/60000 (1%)] Loss: -1222.229126\n",
      "Train Epoch: 365 [11776/60000 (20%)] Loss: -1209.318115\n",
      "Train Epoch: 365 [23040/60000 (38%)] Loss: -942.477905\n",
      "Train Epoch: 365 [34304/60000 (57%)] Loss: -1410.123535\n",
      "Train Epoch: 365 [45568/60000 (76%)] Loss: -1341.627808\n",
      "Train Epoch: 365 [56832/60000 (95%)] Loss: -1342.822998\n",
      "    epoch          : 365\n",
      "    loss           : -1241.0619913736978\n",
      "Train Epoch: 366 [512/60000 (1%)] Loss: -1243.266479\n",
      "Train Epoch: 366 [11776/60000 (20%)] Loss: -1383.108765\n",
      "Train Epoch: 366 [23040/60000 (38%)] Loss: -1219.810547\n",
      "Train Epoch: 366 [34304/60000 (57%)] Loss: -1349.643555\n",
      "Train Epoch: 366 [45568/60000 (76%)] Loss: -1206.129517\n",
      "Train Epoch: 366 [56832/60000 (95%)] Loss: -1200.825684\n",
      "    epoch          : 366\n",
      "    loss           : -1240.3871882379392\n",
      "Train Epoch: 367 [512/60000 (1%)] Loss: -1360.836914\n",
      "Train Epoch: 367 [11776/60000 (20%)] Loss: -1392.150757\n",
      "Train Epoch: 367 [23040/60000 (38%)] Loss: -1213.926270\n",
      "Train Epoch: 367 [34304/60000 (57%)] Loss: -1207.370605\n",
      "Train Epoch: 367 [45568/60000 (76%)] Loss: -1194.929443\n",
      "Train Epoch: 367 [56832/60000 (95%)] Loss: -1270.666992\n",
      "    epoch          : 367\n",
      "    loss           : -1242.4452704305702\n",
      "Train Epoch: 368 [512/60000 (1%)] Loss: -1219.366211\n",
      "Train Epoch: 368 [11776/60000 (20%)] Loss: -1380.553223\n",
      "Train Epoch: 368 [23040/60000 (38%)] Loss: -1331.816406\n",
      "Train Epoch: 368 [34304/60000 (57%)] Loss: -1219.885864\n",
      "Train Epoch: 368 [45568/60000 (76%)] Loss: -1056.269409\n",
      "Train Epoch: 368 [56832/60000 (95%)] Loss: -1180.749878\n",
      "    epoch          : 368\n",
      "    loss           : -1235.4162785589358\n",
      "Train Epoch: 369 [512/60000 (1%)] Loss: -1082.912720\n",
      "Train Epoch: 369 [11776/60000 (20%)] Loss: -1359.154785\n",
      "Train Epoch: 369 [23040/60000 (38%)] Loss: -950.184509\n",
      "Train Epoch: 369 [34304/60000 (57%)] Loss: -1290.434326\n",
      "Train Epoch: 369 [45568/60000 (76%)] Loss: -1164.838623\n",
      "Train Epoch: 369 [56832/60000 (95%)] Loss: -1337.581177\n",
      "    epoch          : 369\n",
      "    loss           : -1218.7564662782486\n",
      "Train Epoch: 370 [512/60000 (1%)] Loss: -1245.656616\n",
      "Train Epoch: 370 [11776/60000 (20%)] Loss: -1303.243774\n",
      "Train Epoch: 370 [23040/60000 (38%)] Loss: -1328.567627\n",
      "Train Epoch: 370 [34304/60000 (57%)] Loss: -1205.268921\n",
      "Train Epoch: 370 [45568/60000 (76%)] Loss: -1214.004883\n",
      "Train Epoch: 370 [56832/60000 (95%)] Loss: -1224.862793\n",
      "    epoch          : 370\n",
      "    loss           : -1225.5261911510747\n",
      "Train Epoch: 371 [512/60000 (1%)] Loss: -1196.795654\n",
      "Train Epoch: 371 [11776/60000 (20%)] Loss: -1214.741577\n",
      "Train Epoch: 371 [23040/60000 (38%)] Loss: -1219.574585\n",
      "Train Epoch: 371 [34304/60000 (57%)] Loss: -1224.261963\n",
      "Train Epoch: 371 [45568/60000 (76%)] Loss: -1356.363159\n",
      "Train Epoch: 371 [56832/60000 (95%)] Loss: -1132.703125\n",
      "    epoch          : 371\n",
      "    loss           : -1239.5127306577176\n",
      "Train Epoch: 372 [512/60000 (1%)] Loss: -1323.505371\n",
      "Train Epoch: 372 [11776/60000 (20%)] Loss: -1290.819824\n",
      "Train Epoch: 372 [23040/60000 (38%)] Loss: -1415.316406\n",
      "Train Epoch: 372 [34304/60000 (57%)] Loss: -1419.777100\n",
      "Train Epoch: 372 [45568/60000 (76%)] Loss: -1224.615234\n",
      "Train Epoch: 372 [56832/60000 (95%)] Loss: -1221.257568\n",
      "    epoch          : 372\n",
      "    loss           : -1207.9683251677259\n",
      "Train Epoch: 373 [512/60000 (1%)] Loss: -1259.201660\n",
      "Train Epoch: 373 [11776/60000 (20%)] Loss: -1114.040405\n",
      "Train Epoch: 373 [23040/60000 (38%)] Loss: -1026.774902\n",
      "Train Epoch: 373 [34304/60000 (57%)] Loss: -1213.514404\n",
      "Train Epoch: 373 [45568/60000 (76%)] Loss: -1094.852417\n",
      "Train Epoch: 373 [56832/60000 (95%)] Loss: -1083.621338\n",
      "    epoch          : 373\n",
      "    loss           : -1223.5566559699969\n",
      "Train Epoch: 374 [512/60000 (1%)] Loss: -1382.130493\n",
      "Train Epoch: 374 [11776/60000 (20%)] Loss: -1184.196167\n",
      "Train Epoch: 374 [23040/60000 (38%)] Loss: -1259.922852\n",
      "Train Epoch: 374 [34304/60000 (57%)] Loss: -1388.902832\n",
      "Train Epoch: 374 [45568/60000 (76%)] Loss: -1322.495972\n",
      "Train Epoch: 374 [56832/60000 (95%)] Loss: -1224.643799\n",
      "    epoch          : 374\n",
      "    loss           : -1225.329052768858\n",
      "Train Epoch: 375 [512/60000 (1%)] Loss: -1254.980835\n",
      "Train Epoch: 375 [11776/60000 (20%)] Loss: -1216.958130\n",
      "Train Epoch: 375 [23040/60000 (38%)] Loss: -1385.578369\n",
      "Train Epoch: 375 [34304/60000 (57%)] Loss: -1383.238647\n",
      "Train Epoch: 375 [45568/60000 (76%)] Loss: -1339.459473\n",
      "Train Epoch: 375 [56832/60000 (95%)] Loss: -1337.043579\n",
      "    epoch          : 375\n",
      "    loss           : -1240.0689471401065\n",
      "Train Epoch: 376 [512/60000 (1%)] Loss: -1238.352173\n",
      "Train Epoch: 376 [11776/60000 (20%)] Loss: -1307.472534\n",
      "Train Epoch: 376 [23040/60000 (38%)] Loss: -904.048340\n",
      "Train Epoch: 376 [34304/60000 (57%)] Loss: -1263.642090\n",
      "Train Epoch: 376 [45568/60000 (76%)] Loss: -1173.881592\n",
      "Train Epoch: 376 [56832/60000 (95%)] Loss: -1394.797363\n",
      "    epoch          : 376\n",
      "    loss           : -1221.2514934647556\n",
      "Train Epoch: 377 [512/60000 (1%)] Loss: -1384.311646\n",
      "Train Epoch: 377 [11776/60000 (20%)] Loss: -1230.026733\n",
      "Train Epoch: 377 [23040/60000 (38%)] Loss: -1238.063110\n",
      "Train Epoch: 377 [34304/60000 (57%)] Loss: -1254.775269\n",
      "Train Epoch: 377 [45568/60000 (76%)] Loss: -1400.550537\n",
      "Train Epoch: 377 [56832/60000 (95%)] Loss: -1251.149536\n",
      "    epoch          : 377\n",
      "    loss           : -1238.4321211475437\n",
      "Train Epoch: 378 [512/60000 (1%)] Loss: -1197.890747\n",
      "Train Epoch: 378 [11776/60000 (20%)] Loss: -1420.806274\n",
      "Train Epoch: 378 [23040/60000 (38%)] Loss: -1163.870605\n",
      "Train Epoch: 378 [34304/60000 (57%)] Loss: -1381.043335\n",
      "Train Epoch: 378 [45568/60000 (76%)] Loss: -1334.080933\n",
      "Train Epoch: 378 [56832/60000 (95%)] Loss: -1110.496948\n",
      "    epoch          : 378\n",
      "    loss           : -1239.6717932749602\n",
      "Train Epoch: 379 [512/60000 (1%)] Loss: -1278.502441\n",
      "Train Epoch: 379 [11776/60000 (20%)] Loss: -1238.361084\n",
      "Train Epoch: 379 [23040/60000 (38%)] Loss: -953.423340\n",
      "Train Epoch: 379 [34304/60000 (57%)] Loss: -1388.952393\n",
      "Train Epoch: 379 [45568/60000 (76%)] Loss: -1195.220093\n",
      "Train Epoch: 379 [56832/60000 (95%)] Loss: -950.476135\n",
      "    epoch          : 379\n",
      "    loss           : -1230.6928191966256\n",
      "Train Epoch: 380 [512/60000 (1%)] Loss: -1339.285156\n",
      "Train Epoch: 380 [11776/60000 (20%)] Loss: -1351.097656\n",
      "Train Epoch: 380 [23040/60000 (38%)] Loss: -1122.291870\n",
      "Train Epoch: 380 [34304/60000 (57%)] Loss: -1387.984497\n",
      "Train Epoch: 380 [45568/60000 (76%)] Loss: -1236.914795\n",
      "Train Epoch: 380 [56832/60000 (95%)] Loss: -1400.422363\n",
      "    epoch          : 380\n",
      "    loss           : -1234.7569600768009\n",
      "Train Epoch: 381 [512/60000 (1%)] Loss: -1097.770874\n",
      "Train Epoch: 381 [11776/60000 (20%)] Loss: -1234.994263\n",
      "Train Epoch: 381 [23040/60000 (38%)] Loss: -1385.730957\n",
      "Train Epoch: 381 [34304/60000 (57%)] Loss: -1198.541748\n",
      "Train Epoch: 381 [45568/60000 (76%)] Loss: -1356.970947\n",
      "Train Epoch: 381 [56832/60000 (95%)] Loss: -1345.115479\n",
      "    epoch          : 381\n",
      "    loss           : -1234.1531206551244\n",
      "Train Epoch: 382 [512/60000 (1%)] Loss: -1252.872803\n",
      "Train Epoch: 382 [11776/60000 (20%)] Loss: -1359.524902\n",
      "Train Epoch: 382 [23040/60000 (38%)] Loss: -1211.450439\n",
      "Train Epoch: 382 [34304/60000 (57%)] Loss: -1334.611938\n",
      "Train Epoch: 382 [45568/60000 (76%)] Loss: -1265.433716\n",
      "Train Epoch: 382 [56832/60000 (95%)] Loss: -1053.289307\n",
      "    epoch          : 382\n",
      "    loss           : -1238.8513207731946\n",
      "Train Epoch: 383 [512/60000 (1%)] Loss: -1109.538086\n",
      "Train Epoch: 383 [11776/60000 (20%)] Loss: -1358.118896\n",
      "Train Epoch: 383 [23040/60000 (38%)] Loss: -1392.720947\n",
      "Train Epoch: 383 [34304/60000 (57%)] Loss: -1251.434204\n",
      "Train Epoch: 383 [45568/60000 (76%)] Loss: -956.544861\n",
      "Train Epoch: 383 [56832/60000 (95%)] Loss: -1351.936035\n",
      "    epoch          : 383\n",
      "    loss           : -1217.6924160887293\n",
      "Train Epoch: 384 [512/60000 (1%)] Loss: -1216.115356\n",
      "Train Epoch: 384 [11776/60000 (20%)] Loss: -1261.881348\n",
      "Train Epoch: 384 [23040/60000 (38%)] Loss: -1370.945435\n",
      "Train Epoch: 384 [34304/60000 (57%)] Loss: -1209.145142\n",
      "Train Epoch: 384 [45568/60000 (76%)] Loss: -1379.007080\n",
      "Train Epoch: 384 [56832/60000 (95%)] Loss: -1222.913818\n",
      "    epoch          : 384\n",
      "    loss           : -1234.760273734055\n",
      "Train Epoch: 385 [512/60000 (1%)] Loss: -1130.417603\n",
      "Train Epoch: 385 [11776/60000 (20%)] Loss: -1168.067017\n",
      "Train Epoch: 385 [23040/60000 (38%)] Loss: -1089.229736\n",
      "Train Epoch: 385 [34304/60000 (57%)] Loss: -1187.628906\n",
      "Train Epoch: 385 [45568/60000 (76%)] Loss: -1396.214355\n",
      "Train Epoch: 385 [56832/60000 (95%)] Loss: -1388.221436\n",
      "    epoch          : 385\n",
      "    loss           : -1225.6857118768207\n",
      "Train Epoch: 386 [512/60000 (1%)] Loss: -1365.703003\n",
      "Train Epoch: 386 [11776/60000 (20%)] Loss: -1225.718018\n",
      "Train Epoch: 386 [23040/60000 (38%)] Loss: -1369.320801\n",
      "Train Epoch: 386 [34304/60000 (57%)] Loss: -1382.142334\n",
      "Train Epoch: 386 [45568/60000 (76%)] Loss: -1187.702637\n",
      "Train Epoch: 386 [56832/60000 (95%)] Loss: -1061.398438\n",
      "    epoch          : 386\n",
      "    loss           : -1239.7183617198536\n",
      "Train Epoch: 387 [512/60000 (1%)] Loss: -989.411011\n",
      "Train Epoch: 387 [11776/60000 (20%)] Loss: -1072.826904\n",
      "Train Epoch: 387 [23040/60000 (38%)] Loss: -1352.774414\n",
      "Train Epoch: 387 [34304/60000 (57%)] Loss: -1354.616821\n",
      "Train Epoch: 387 [45568/60000 (76%)] Loss: -1361.279785\n",
      "Train Epoch: 387 [56832/60000 (95%)] Loss: -1242.337646\n",
      "    epoch          : 387\n",
      "    loss           : -1213.326218772069\n",
      "Train Epoch: 388 [512/60000 (1%)] Loss: -1159.337280\n",
      "Train Epoch: 388 [11776/60000 (20%)] Loss: -1065.069824\n",
      "Train Epoch: 388 [23040/60000 (38%)] Loss: -1248.515137\n",
      "Train Epoch: 388 [34304/60000 (57%)] Loss: -1221.905273\n",
      "Train Epoch: 388 [45568/60000 (76%)] Loss: -1276.594482\n",
      "Train Epoch: 388 [56832/60000 (95%)] Loss: -1279.973389\n",
      "    epoch          : 388\n",
      "    loss           : -1227.54110855706\n",
      "Train Epoch: 389 [512/60000 (1%)] Loss: -970.951294\n",
      "Train Epoch: 389 [11776/60000 (20%)] Loss: -1218.393921\n",
      "Train Epoch: 389 [23040/60000 (38%)] Loss: -1348.864502\n",
      "Train Epoch: 389 [34304/60000 (57%)] Loss: -1390.747803\n",
      "Train Epoch: 389 [45568/60000 (76%)] Loss: -1381.220947\n",
      "Train Epoch: 389 [56832/60000 (95%)] Loss: -1222.906860\n",
      "    epoch          : 389\n",
      "    loss           : -1248.5973693502826\n",
      "Train Epoch: 390 [512/60000 (1%)] Loss: -1396.457397\n",
      "Train Epoch: 390 [11776/60000 (20%)] Loss: -1329.510864\n",
      "Train Epoch: 390 [23040/60000 (38%)] Loss: -1315.475830\n",
      "Train Epoch: 390 [34304/60000 (57%)] Loss: -1378.157959\n",
      "Train Epoch: 390 [45568/60000 (76%)] Loss: -945.669983\n",
      "Train Epoch: 390 [56832/60000 (95%)] Loss: -1094.701172\n",
      "    epoch          : 390\n",
      "    loss           : -1238.1568700068415\n",
      "Train Epoch: 391 [512/60000 (1%)] Loss: -1328.647827\n",
      "Train Epoch: 391 [11776/60000 (20%)] Loss: -1289.182861\n",
      "Train Epoch: 391 [23040/60000 (38%)] Loss: -1049.498413\n",
      "Train Epoch: 391 [34304/60000 (57%)] Loss: -1157.232666\n",
      "Train Epoch: 391 [45568/60000 (76%)] Loss: -1295.904785\n",
      "Train Epoch: 391 [56832/60000 (95%)] Loss: -1379.160522\n",
      "    epoch          : 391\n",
      "    loss           : -1218.920518950554\n",
      "Train Epoch: 392 [512/60000 (1%)] Loss: -1249.382080\n",
      "Train Epoch: 392 [11776/60000 (20%)] Loss: -1141.894409\n",
      "Train Epoch: 392 [23040/60000 (38%)] Loss: -1223.973999\n",
      "Train Epoch: 392 [34304/60000 (57%)] Loss: -1232.833496\n",
      "Train Epoch: 392 [45568/60000 (76%)] Loss: -1398.385132\n",
      "Train Epoch: 392 [56832/60000 (95%)] Loss: -1122.547974\n",
      "    epoch          : 392\n",
      "    loss           : -1236.9736260882878\n",
      "Train Epoch: 393 [512/60000 (1%)] Loss: -1341.044678\n",
      "Train Epoch: 393 [11776/60000 (20%)] Loss: -1409.202393\n",
      "Train Epoch: 393 [23040/60000 (38%)] Loss: -1081.692871\n",
      "Train Epoch: 393 [34304/60000 (57%)] Loss: -951.471924\n",
      "Train Epoch: 393 [45568/60000 (76%)] Loss: -1372.913452\n",
      "Train Epoch: 393 [56832/60000 (95%)] Loss: -1361.460938\n",
      "    epoch          : 393\n",
      "    loss           : -1235.4235153629281\n",
      "Train Epoch: 394 [512/60000 (1%)] Loss: -1082.846558\n",
      "Train Epoch: 394 [11776/60000 (20%)] Loss: -1373.310547\n",
      "Train Epoch: 394 [23040/60000 (38%)] Loss: -1237.926392\n",
      "Train Epoch: 394 [34304/60000 (57%)] Loss: -1241.352051\n",
      "Train Epoch: 394 [45568/60000 (76%)] Loss: -1243.733643\n",
      "Train Epoch: 394 [56832/60000 (95%)] Loss: -1241.737427\n",
      "    epoch          : 394\n",
      "    loss           : -1256.7061693439375\n",
      "Train Epoch: 395 [512/60000 (1%)] Loss: -1260.452393\n",
      "Train Epoch: 395 [11776/60000 (20%)] Loss: -1211.284912\n",
      "Train Epoch: 395 [23040/60000 (38%)] Loss: -1221.837402\n",
      "Train Epoch: 395 [34304/60000 (57%)] Loss: -1100.966431\n",
      "Train Epoch: 395 [45568/60000 (76%)] Loss: -1174.897095\n",
      "Train Epoch: 395 [56832/60000 (95%)] Loss: -1361.869385\n",
      "    epoch          : 395\n",
      "    loss           : -1217.5953955353991\n",
      "Train Epoch: 396 [512/60000 (1%)] Loss: -1050.185669\n",
      "Train Epoch: 396 [11776/60000 (20%)] Loss: -1205.446045\n",
      "Train Epoch: 396 [23040/60000 (38%)] Loss: -1347.635498\n",
      "Train Epoch: 396 [34304/60000 (57%)] Loss: -1395.520264\n",
      "Train Epoch: 396 [45568/60000 (76%)] Loss: -1295.711792\n",
      "Train Epoch: 396 [56832/60000 (95%)] Loss: -1210.520264\n",
      "    epoch          : 396\n",
      "    loss           : -1215.1742536469367\n",
      "Train Epoch: 397 [512/60000 (1%)] Loss: -1363.981445\n",
      "Train Epoch: 397 [11776/60000 (20%)] Loss: -1366.526489\n",
      "Train Epoch: 397 [23040/60000 (38%)] Loss: -1234.103271\n",
      "Train Epoch: 397 [34304/60000 (57%)] Loss: -1260.204956\n",
      "Train Epoch: 397 [45568/60000 (76%)] Loss: -1223.269531\n",
      "Train Epoch: 397 [56832/60000 (95%)] Loss: -1206.930054\n",
      "    epoch          : 397\n",
      "    loss           : -1222.8739544712216\n",
      "Train Epoch: 398 [512/60000 (1%)] Loss: -1058.562744\n",
      "Train Epoch: 398 [11776/60000 (20%)] Loss: -1347.085693\n",
      "Train Epoch: 398 [23040/60000 (38%)] Loss: -1127.130249\n",
      "Train Epoch: 398 [34304/60000 (57%)] Loss: -1422.453735\n",
      "Train Epoch: 398 [45568/60000 (76%)] Loss: -1064.773193\n",
      "Train Epoch: 398 [56832/60000 (95%)] Loss: -1368.806396\n",
      "    epoch          : 398\n",
      "    loss           : -1220.4331146067818\n",
      "Train Epoch: 399 [512/60000 (1%)] Loss: -1319.854248\n",
      "Train Epoch: 399 [11776/60000 (20%)] Loss: -1149.105957\n",
      "Train Epoch: 399 [23040/60000 (38%)] Loss: -1309.514526\n",
      "Train Epoch: 399 [34304/60000 (57%)] Loss: -954.746277\n",
      "Train Epoch: 399 [45568/60000 (76%)] Loss: -1258.479370\n",
      "Train Epoch: 399 [56832/60000 (95%)] Loss: -1348.061523\n",
      "    epoch          : 399\n",
      "    loss           : -1227.419550836423\n",
      "Train Epoch: 400 [512/60000 (1%)] Loss: -1255.095825\n",
      "Train Epoch: 400 [11776/60000 (20%)] Loss: -1382.177490\n",
      "Train Epoch: 400 [23040/60000 (38%)] Loss: -1394.389282\n",
      "Train Epoch: 400 [34304/60000 (57%)] Loss: -1207.401245\n",
      "Train Epoch: 400 [45568/60000 (76%)] Loss: -1079.455933\n",
      "Train Epoch: 400 [56832/60000 (95%)] Loss: -1226.004150\n",
      "    epoch          : 400\n",
      "    loss           : -1228.71179388876\n",
      "Saving checkpoint: saved/models/Mnist_DeepGenerativeOperad/0127_111843/checkpoint-epoch400.pth ...\n",
      "Train Epoch: 401 [512/60000 (1%)] Loss: -1045.457397\n",
      "Train Epoch: 401 [11776/60000 (20%)] Loss: -1266.949097\n",
      "Train Epoch: 401 [23040/60000 (38%)] Loss: -1390.994873\n",
      "Train Epoch: 401 [34304/60000 (57%)] Loss: -1226.189209\n",
      "Train Epoch: 401 [45568/60000 (76%)] Loss: -1220.561523\n",
      "Train Epoch: 401 [56832/60000 (95%)] Loss: -1091.844360\n",
      "    epoch          : 401\n",
      "    loss           : -1241.0087785451424\n",
      "Train Epoch: 402 [512/60000 (1%)] Loss: -1355.897217\n",
      "Train Epoch: 402 [11776/60000 (20%)] Loss: -1242.828857\n",
      "Train Epoch: 402 [23040/60000 (38%)] Loss: -1353.730225\n",
      "Train Epoch: 402 [34304/60000 (57%)] Loss: -1202.610718\n",
      "Train Epoch: 402 [45568/60000 (76%)] Loss: -1281.952393\n",
      "Train Epoch: 402 [56832/60000 (95%)] Loss: -1352.196167\n",
      "    epoch          : 402\n",
      "    loss           : -1234.9306187171721\n",
      "Train Epoch: 403 [512/60000 (1%)] Loss: -1240.992432\n",
      "Train Epoch: 403 [11776/60000 (20%)] Loss: -1343.832642\n",
      "Train Epoch: 403 [23040/60000 (38%)] Loss: -1329.061035\n",
      "Train Epoch: 403 [34304/60000 (57%)] Loss: -1406.315918\n",
      "Train Epoch: 403 [45568/60000 (76%)] Loss: -1213.542969\n",
      "Train Epoch: 403 [56832/60000 (95%)] Loss: -1241.603271\n",
      "    epoch          : 403\n",
      "    loss           : -1246.7311092743093\n",
      "Train Epoch: 404 [512/60000 (1%)] Loss: -1243.993042\n",
      "Train Epoch: 404 [11776/60000 (20%)] Loss: -1238.246216\n",
      "Train Epoch: 404 [23040/60000 (38%)] Loss: -1218.002686\n",
      "Train Epoch: 404 [34304/60000 (57%)] Loss: -1224.422119\n",
      "Train Epoch: 404 [45568/60000 (76%)] Loss: -1246.922363\n",
      "Train Epoch: 404 [56832/60000 (95%)] Loss: -1337.092407\n",
      "    epoch          : 404\n",
      "    loss           : -1230.934580485026\n",
      "Train Epoch: 405 [512/60000 (1%)] Loss: -1396.723511\n",
      "Train Epoch: 405 [11776/60000 (20%)] Loss: -1175.894775\n",
      "Train Epoch: 405 [23040/60000 (38%)] Loss: -1428.411743\n",
      "Train Epoch: 405 [34304/60000 (57%)] Loss: -1229.286377\n",
      "Train Epoch: 405 [45568/60000 (76%)] Loss: -1277.614868\n",
      "Train Epoch: 405 [56832/60000 (95%)] Loss: -1251.516846\n",
      "    epoch          : 405\n",
      "    loss           : -1231.8988823324946\n",
      "Train Epoch: 406 [512/60000 (1%)] Loss: -1222.482910\n",
      "Train Epoch: 406 [11776/60000 (20%)] Loss: -1200.476318\n",
      "Train Epoch: 406 [23040/60000 (38%)] Loss: -1119.422119\n",
      "Train Epoch: 406 [34304/60000 (57%)] Loss: -1370.049194\n",
      "Train Epoch: 406 [45568/60000 (76%)] Loss: -1107.199341\n",
      "Train Epoch: 406 [56832/60000 (95%)] Loss: -1229.795166\n",
      "    epoch          : 406\n",
      "    loss           : -1239.7025553385415\n",
      "Train Epoch: 407 [512/60000 (1%)] Loss: -1195.517578\n",
      "Train Epoch: 407 [11776/60000 (20%)] Loss: -1408.152832\n",
      "Train Epoch: 407 [23040/60000 (38%)] Loss: -1189.913818\n",
      "Train Epoch: 407 [34304/60000 (57%)] Loss: -1203.233643\n",
      "Train Epoch: 407 [45568/60000 (76%)] Loss: -1101.843506\n",
      "Train Epoch: 407 [56832/60000 (95%)] Loss: -1350.309814\n",
      "    epoch          : 407\n",
      "    loss           : -1242.087241479906\n",
      "Train Epoch: 408 [512/60000 (1%)] Loss: -1166.527466\n",
      "Train Epoch: 408 [11776/60000 (20%)] Loss: -1387.278076\n",
      "Train Epoch: 408 [23040/60000 (38%)] Loss: -1357.957275\n",
      "Train Epoch: 408 [34304/60000 (57%)] Loss: -1128.742920\n",
      "Train Epoch: 408 [45568/60000 (76%)] Loss: -1331.727295\n",
      "Train Epoch: 408 [56832/60000 (95%)] Loss: -1247.857666\n",
      "    epoch          : 408\n",
      "    loss           : -1232.0723247635838\n",
      "Train Epoch: 409 [512/60000 (1%)] Loss: -1238.989990\n",
      "Train Epoch: 409 [11776/60000 (20%)] Loss: -1368.509033\n",
      "Train Epoch: 409 [23040/60000 (38%)] Loss: -1271.302002\n",
      "Train Epoch: 409 [34304/60000 (57%)] Loss: -1214.068848\n",
      "Train Epoch: 409 [45568/60000 (76%)] Loss: -1247.976440\n",
      "Train Epoch: 409 [56832/60000 (95%)] Loss: -1394.974854\n",
      "    epoch          : 409\n",
      "    loss           : -1237.5105613234355\n",
      "Train Epoch: 410 [512/60000 (1%)] Loss: -1366.859741\n",
      "Train Epoch: 410 [11776/60000 (20%)] Loss: -1227.772217\n",
      "Train Epoch: 410 [23040/60000 (38%)] Loss: -1372.953613\n",
      "Train Epoch: 410 [34304/60000 (57%)] Loss: -1097.297729\n",
      "Train Epoch: 410 [45568/60000 (76%)] Loss: -1092.960815\n",
      "Train Epoch: 410 [56832/60000 (95%)] Loss: -925.835632\n",
      "    epoch          : 410\n",
      "    loss           : -1236.8451291531494\n",
      "Train Epoch: 411 [512/60000 (1%)] Loss: -1284.657349\n",
      "Train Epoch: 411 [11776/60000 (20%)] Loss: -1091.650513\n",
      "Train Epoch: 411 [23040/60000 (38%)] Loss: -1210.457031\n",
      "Train Epoch: 411 [34304/60000 (57%)] Loss: -1400.957275\n",
      "Train Epoch: 411 [45568/60000 (76%)] Loss: -1100.164673\n",
      "Train Epoch: 411 [56832/60000 (95%)] Loss: -1399.017822\n",
      "    epoch          : 411\n",
      "    loss           : -1245.1660859706037\n",
      "Train Epoch: 412 [512/60000 (1%)] Loss: -1051.782471\n",
      "Train Epoch: 412 [11776/60000 (20%)] Loss: -1131.403198\n",
      "Train Epoch: 412 [23040/60000 (38%)] Loss: -982.827393\n",
      "Train Epoch: 412 [34304/60000 (57%)] Loss: -1369.585205\n",
      "Train Epoch: 412 [45568/60000 (76%)] Loss: -1118.141479\n",
      "Train Epoch: 412 [56832/60000 (95%)] Loss: -1305.470703\n",
      "    epoch          : 412\n",
      "    loss           : -1245.7577454302946\n",
      "Train Epoch: 413 [512/60000 (1%)] Loss: -1283.083618\n",
      "Train Epoch: 413 [11776/60000 (20%)] Loss: -1218.178833\n",
      "Train Epoch: 413 [23040/60000 (38%)] Loss: -1197.008789\n",
      "Train Epoch: 413 [34304/60000 (57%)] Loss: -1385.684814\n",
      "Train Epoch: 413 [45568/60000 (76%)] Loss: -1112.704468\n",
      "Train Epoch: 413 [56832/60000 (95%)] Loss: -1257.624390\n",
      "    epoch          : 413\n",
      "    loss           : -1225.2656058618577\n",
      "Train Epoch: 414 [512/60000 (1%)] Loss: -1363.796143\n",
      "Train Epoch: 414 [11776/60000 (20%)] Loss: -1233.526123\n",
      "Train Epoch: 414 [23040/60000 (38%)] Loss: -1235.998169\n",
      "Train Epoch: 414 [34304/60000 (57%)] Loss: -1382.299683\n",
      "Train Epoch: 414 [45568/60000 (76%)] Loss: -962.023010\n",
      "Train Epoch: 414 [56832/60000 (95%)] Loss: -1229.298218\n",
      "    epoch          : 414\n",
      "    loss           : -1236.3140970865884\n",
      "Train Epoch: 415 [512/60000 (1%)] Loss: -1329.101562\n",
      "Train Epoch: 415 [11776/60000 (20%)] Loss: -1350.947632\n",
      "Train Epoch: 415 [23040/60000 (38%)] Loss: -1011.528931\n",
      "Train Epoch: 415 [34304/60000 (57%)] Loss: -1386.320312\n",
      "Train Epoch: 415 [45568/60000 (76%)] Loss: -1188.513428\n",
      "Train Epoch: 415 [56832/60000 (95%)] Loss: -1343.468628\n",
      "    epoch          : 415\n",
      "    loss           : -1233.4598700744284\n",
      "Train Epoch: 416 [512/60000 (1%)] Loss: -1373.464355\n",
      "Train Epoch: 416 [11776/60000 (20%)] Loss: -1357.236938\n",
      "Train Epoch: 416 [23040/60000 (38%)] Loss: -930.686768\n",
      "Train Epoch: 416 [34304/60000 (57%)] Loss: -1310.703491\n",
      "Train Epoch: 416 [45568/60000 (76%)] Loss: -1194.266602\n",
      "Train Epoch: 416 [56832/60000 (95%)] Loss: -1075.878784\n",
      "    epoch          : 416\n",
      "    loss           : -1234.0794670837747\n",
      "Train Epoch: 417 [512/60000 (1%)] Loss: -1219.524414\n",
      "Train Epoch: 417 [11776/60000 (20%)] Loss: -964.238647\n",
      "Train Epoch: 417 [23040/60000 (38%)] Loss: -1215.243042\n",
      "Train Epoch: 417 [34304/60000 (57%)] Loss: -1133.273682\n",
      "Train Epoch: 417 [45568/60000 (76%)] Loss: -1248.892578\n",
      "Train Epoch: 417 [56832/60000 (95%)] Loss: -957.384705\n",
      "    epoch          : 417\n",
      "    loss           : -1227.0827483268781\n",
      "Train Epoch: 418 [512/60000 (1%)] Loss: -1376.629517\n",
      "Train Epoch: 418 [11776/60000 (20%)] Loss: -1409.069580\n",
      "Train Epoch: 418 [23040/60000 (38%)] Loss: -1354.934570\n",
      "Train Epoch: 418 [34304/60000 (57%)] Loss: -1246.074707\n",
      "Train Epoch: 418 [45568/60000 (76%)] Loss: -1208.144775\n",
      "Train Epoch: 418 [56832/60000 (95%)] Loss: -1226.232666\n",
      "    epoch          : 418\n",
      "    loss           : -1215.6306431657176\n",
      "Train Epoch: 419 [512/60000 (1%)] Loss: -1249.855103\n",
      "Train Epoch: 419 [11776/60000 (20%)] Loss: -1366.461426\n",
      "Train Epoch: 419 [23040/60000 (38%)] Loss: -1395.718750\n",
      "Train Epoch: 419 [34304/60000 (57%)] Loss: -1151.695557\n",
      "Train Epoch: 419 [45568/60000 (76%)] Loss: -1368.355835\n",
      "Train Epoch: 419 [56832/60000 (95%)] Loss: -1382.740967\n",
      "    epoch          : 419\n",
      "    loss           : -1228.4887798761918\n",
      "Train Epoch: 420 [512/60000 (1%)] Loss: -1436.880615\n",
      "Train Epoch: 420 [11776/60000 (20%)] Loss: -1393.930908\n",
      "Train Epoch: 420 [23040/60000 (38%)] Loss: -1405.097168\n",
      "Train Epoch: 420 [34304/60000 (57%)] Loss: -1211.395508\n",
      "Train Epoch: 420 [45568/60000 (76%)] Loss: -1261.064575\n",
      "Train Epoch: 420 [56832/60000 (95%)] Loss: -1063.784668\n",
      "    epoch          : 420\n",
      "    loss           : -1244.8629329702947\n",
      "Train Epoch: 421 [512/60000 (1%)] Loss: -1359.616821\n",
      "Train Epoch: 421 [11776/60000 (20%)] Loss: -1365.153564\n",
      "Train Epoch: 421 [23040/60000 (38%)] Loss: -1253.789185\n",
      "Train Epoch: 421 [34304/60000 (57%)] Loss: -1368.718628\n",
      "Train Epoch: 421 [45568/60000 (76%)] Loss: -1339.315674\n",
      "Train Epoch: 421 [56832/60000 (95%)] Loss: -1347.442627\n",
      "    epoch          : 421\n",
      "    loss           : -1237.8988052626787\n",
      "Train Epoch: 422 [512/60000 (1%)] Loss: -1192.104736\n",
      "Train Epoch: 422 [11776/60000 (20%)] Loss: -1276.437988\n",
      "Train Epoch: 422 [23040/60000 (38%)] Loss: -1386.516357\n",
      "Train Epoch: 422 [34304/60000 (57%)] Loss: -1272.890747\n",
      "Train Epoch: 422 [45568/60000 (76%)] Loss: -1345.976562\n",
      "Train Epoch: 422 [56832/60000 (95%)] Loss: -1360.300293\n",
      "    epoch          : 422\n",
      "    loss           : -1247.2882681808903\n",
      "Train Epoch: 423 [512/60000 (1%)] Loss: -982.585754\n",
      "Train Epoch: 423 [11776/60000 (20%)] Loss: -1265.086426\n",
      "Train Epoch: 423 [23040/60000 (38%)] Loss: -1405.252563\n",
      "Train Epoch: 423 [34304/60000 (57%)] Loss: -1203.428711\n",
      "Train Epoch: 423 [45568/60000 (76%)] Loss: -1236.072998\n",
      "Train Epoch: 423 [56832/60000 (95%)] Loss: -1051.667236\n",
      "    epoch          : 423\n",
      "    loss           : -1232.1753307277872\n",
      "Train Epoch: 424 [512/60000 (1%)] Loss: -1358.640137\n",
      "Train Epoch: 424 [11776/60000 (20%)] Loss: -1322.178955\n",
      "Train Epoch: 424 [23040/60000 (38%)] Loss: -1232.666870\n",
      "Train Epoch: 424 [34304/60000 (57%)] Loss: -1295.367920\n",
      "Train Epoch: 424 [45568/60000 (76%)] Loss: -1274.740601\n",
      "Train Epoch: 424 [56832/60000 (95%)] Loss: -1235.088501\n",
      "    epoch          : 424\n",
      "    loss           : -1241.6163138696702\n",
      "Train Epoch: 425 [512/60000 (1%)] Loss: -1083.437500\n",
      "Train Epoch: 425 [11776/60000 (20%)] Loss: -1369.549072\n",
      "Train Epoch: 425 [23040/60000 (38%)] Loss: -1408.862793\n",
      "Train Epoch: 425 [34304/60000 (57%)] Loss: -1051.474243\n",
      "Train Epoch: 425 [45568/60000 (76%)] Loss: -1350.551270\n",
      "Train Epoch: 425 [56832/60000 (95%)] Loss: -1222.780884\n",
      "    epoch          : 425\n",
      "    loss           : -1239.259510794602\n",
      "Train Epoch: 426 [512/60000 (1%)] Loss: -1046.126831\n",
      "Train Epoch: 426 [11776/60000 (20%)] Loss: -1362.137695\n",
      "Train Epoch: 426 [23040/60000 (38%)] Loss: -1114.632690\n",
      "Train Epoch: 426 [34304/60000 (57%)] Loss: -967.456360\n",
      "Train Epoch: 426 [45568/60000 (76%)] Loss: -1203.642090\n",
      "Train Epoch: 426 [56832/60000 (95%)] Loss: -1238.739746\n",
      "    epoch          : 426\n",
      "    loss           : -1245.5382143871934\n",
      "Train Epoch: 427 [512/60000 (1%)] Loss: -1089.437622\n",
      "Train Epoch: 427 [11776/60000 (20%)] Loss: -1209.658325\n",
      "Train Epoch: 427 [23040/60000 (38%)] Loss: -1258.784790\n",
      "Train Epoch: 427 [34304/60000 (57%)] Loss: -1370.998535\n",
      "Train Epoch: 427 [45568/60000 (76%)] Loss: -1217.953125\n",
      "Train Epoch: 427 [56832/60000 (95%)] Loss: -1299.233154\n",
      "    epoch          : 427\n",
      "    loss           : -1227.3897060243423\n",
      "Train Epoch: 428 [512/60000 (1%)] Loss: -1377.045532\n",
      "Train Epoch: 428 [11776/60000 (20%)] Loss: -1394.095703\n",
      "Train Epoch: 428 [23040/60000 (38%)] Loss: -1269.557617\n",
      "Train Epoch: 428 [34304/60000 (57%)] Loss: -1376.587036\n",
      "Train Epoch: 428 [45568/60000 (76%)] Loss: -1220.836426\n",
      "Train Epoch: 428 [56832/60000 (95%)] Loss: -1237.551758\n",
      "    epoch          : 428\n",
      "    loss           : -1245.6031978628728\n",
      "Train Epoch: 429 [512/60000 (1%)] Loss: -1126.553223\n",
      "Train Epoch: 429 [11776/60000 (20%)] Loss: -1265.006226\n",
      "Train Epoch: 429 [23040/60000 (38%)] Loss: -1214.837158\n",
      "Train Epoch: 429 [34304/60000 (57%)] Loss: -1256.665161\n",
      "Train Epoch: 429 [45568/60000 (76%)] Loss: -1145.764282\n",
      "Train Epoch: 429 [56832/60000 (95%)] Loss: -1250.556641\n",
      "    epoch          : 429\n",
      "    loss           : -1239.030310334459\n",
      "Train Epoch: 430 [512/60000 (1%)] Loss: -1160.032227\n",
      "Train Epoch: 430 [11776/60000 (20%)] Loss: -1422.425293\n",
      "Train Epoch: 430 [23040/60000 (38%)] Loss: -1379.876099\n",
      "Train Epoch: 430 [34304/60000 (57%)] Loss: -1207.930176\n",
      "Train Epoch: 430 [45568/60000 (76%)] Loss: -1232.293457\n",
      "Train Epoch: 430 [56832/60000 (95%)] Loss: -1240.044189\n",
      "    epoch          : 430\n",
      "    loss           : -1234.096335890603\n",
      "Train Epoch: 431 [512/60000 (1%)] Loss: -1232.802124\n",
      "Train Epoch: 431 [11776/60000 (20%)] Loss: -1104.972900\n",
      "Train Epoch: 431 [23040/60000 (38%)] Loss: -1194.217773\n",
      "Train Epoch: 431 [34304/60000 (57%)] Loss: -1236.287231\n",
      "Train Epoch: 431 [45568/60000 (76%)] Loss: -1380.461182\n",
      "Train Epoch: 431 [56832/60000 (95%)] Loss: -1269.253906\n",
      "    epoch          : 431\n",
      "    loss           : -1242.2137611518472\n",
      "Train Epoch: 432 [512/60000 (1%)] Loss: -1373.731689\n",
      "Train Epoch: 432 [11776/60000 (20%)] Loss: -1233.661133\n",
      "Train Epoch: 432 [23040/60000 (38%)] Loss: -1228.712646\n",
      "Train Epoch: 432 [34304/60000 (57%)] Loss: -1367.858643\n",
      "Train Epoch: 432 [45568/60000 (76%)] Loss: -1359.867676\n",
      "Train Epoch: 432 [56832/60000 (95%)] Loss: -1113.658203\n",
      "    epoch          : 432\n",
      "    loss           : -1235.6935435149628\n",
      "Train Epoch: 433 [512/60000 (1%)] Loss: -1398.375977\n",
      "Train Epoch: 433 [11776/60000 (20%)] Loss: -1242.500122\n",
      "Train Epoch: 433 [23040/60000 (38%)] Loss: -1233.866333\n",
      "Train Epoch: 433 [34304/60000 (57%)] Loss: -1249.742920\n",
      "Train Epoch: 433 [45568/60000 (76%)] Loss: -1246.736328\n",
      "Train Epoch: 433 [56832/60000 (95%)] Loss: -1248.210205\n",
      "    epoch          : 433\n",
      "    loss           : -1246.872722905908\n",
      "Train Epoch: 434 [512/60000 (1%)] Loss: -1263.134277\n",
      "Train Epoch: 434 [11776/60000 (20%)] Loss: -1427.552734\n",
      "Train Epoch: 434 [23040/60000 (38%)] Loss: -1148.037598\n",
      "Train Epoch: 434 [34304/60000 (57%)] Loss: -1353.051514\n",
      "Train Epoch: 434 [45568/60000 (76%)] Loss: -1386.285034\n",
      "Train Epoch: 434 [56832/60000 (95%)] Loss: -860.505371\n",
      "    epoch          : 434\n",
      "    loss           : -1231.923923815711\n",
      "Train Epoch: 435 [512/60000 (1%)] Loss: -1279.960449\n",
      "Train Epoch: 435 [11776/60000 (20%)] Loss: -1215.004028\n",
      "Train Epoch: 435 [23040/60000 (38%)] Loss: -1189.932495\n",
      "Train Epoch: 435 [34304/60000 (57%)] Loss: -1442.799561\n",
      "Train Epoch: 435 [45568/60000 (76%)] Loss: -1196.391602\n",
      "Train Epoch: 435 [56832/60000 (95%)] Loss: -1346.595947\n",
      "    epoch          : 435\n",
      "    loss           : -1248.0560499288267\n",
      "Train Epoch: 436 [512/60000 (1%)] Loss: -1275.308838\n",
      "Train Epoch: 436 [11776/60000 (20%)] Loss: -1377.939941\n",
      "Train Epoch: 436 [23040/60000 (38%)] Loss: -1398.882690\n",
      "Train Epoch: 436 [34304/60000 (57%)] Loss: -1223.500244\n",
      "Train Epoch: 436 [45568/60000 (76%)] Loss: -1117.641602\n",
      "Train Epoch: 436 [56832/60000 (95%)] Loss: -1371.526245\n",
      "    epoch          : 436\n",
      "    loss           : -1255.9715122718596\n",
      "Train Epoch: 437 [512/60000 (1%)] Loss: -1270.449097\n",
      "Train Epoch: 437 [11776/60000 (20%)] Loss: -1411.102905\n",
      "Train Epoch: 437 [23040/60000 (38%)] Loss: -1095.002930\n",
      "Train Epoch: 437 [34304/60000 (57%)] Loss: -1304.006958\n",
      "Train Epoch: 437 [45568/60000 (76%)] Loss: -1246.826660\n",
      "Train Epoch: 437 [56832/60000 (95%)] Loss: -1252.381348\n",
      "    epoch          : 437\n",
      "    loss           : -1232.5442580745719\n",
      "Train Epoch: 438 [512/60000 (1%)] Loss: -1393.941162\n",
      "Train Epoch: 438 [11776/60000 (20%)] Loss: -1242.212891\n",
      "Train Epoch: 438 [23040/60000 (38%)] Loss: -1114.808960\n",
      "Train Epoch: 438 [34304/60000 (57%)] Loss: -1267.964233\n",
      "Train Epoch: 438 [45568/60000 (76%)] Loss: -1060.849243\n",
      "Train Epoch: 438 [56832/60000 (95%)] Loss: -1260.515381\n",
      "    epoch          : 438\n",
      "    loss           : -1261.5170989817818\n",
      "Train Epoch: 439 [512/60000 (1%)] Loss: -1223.905762\n",
      "Train Epoch: 439 [11776/60000 (20%)] Loss: -1343.124512\n",
      "Train Epoch: 439 [23040/60000 (38%)] Loss: -1399.513794\n",
      "Train Epoch: 439 [34304/60000 (57%)] Loss: -1275.963501\n",
      "Train Epoch: 439 [45568/60000 (76%)] Loss: -1202.755493\n",
      "Train Epoch: 439 [56832/60000 (95%)] Loss: -1066.744873\n",
      "    epoch          : 439\n",
      "    loss           : -1253.1950102552855\n",
      "Train Epoch: 440 [512/60000 (1%)] Loss: -1229.119629\n",
      "Train Epoch: 440 [11776/60000 (20%)] Loss: -1337.704346\n",
      "Train Epoch: 440 [23040/60000 (38%)] Loss: -1371.859253\n",
      "Train Epoch: 440 [34304/60000 (57%)] Loss: -1345.853271\n",
      "Train Epoch: 440 [45568/60000 (76%)] Loss: -1093.179688\n",
      "Train Epoch: 440 [56832/60000 (95%)] Loss: -1357.724854\n",
      "    epoch          : 440\n",
      "    loss           : -1251.8216140660863\n",
      "Train Epoch: 441 [512/60000 (1%)] Loss: -1228.938721\n",
      "Train Epoch: 441 [11776/60000 (20%)] Loss: -1284.175537\n",
      "Train Epoch: 441 [23040/60000 (38%)] Loss: -1228.979980\n",
      "Train Epoch: 441 [34304/60000 (57%)] Loss: -1360.290283\n",
      "Train Epoch: 441 [45568/60000 (76%)] Loss: -1396.973389\n",
      "Train Epoch: 441 [56832/60000 (95%)] Loss: -1223.998169\n",
      "    epoch          : 441\n",
      "    loss           : -1224.763232387392\n",
      "Train Epoch: 442 [512/60000 (1%)] Loss: -1260.370728\n",
      "Train Epoch: 442 [11776/60000 (20%)] Loss: -1130.278198\n",
      "Train Epoch: 442 [23040/60000 (38%)] Loss: -1381.547119\n",
      "Train Epoch: 442 [34304/60000 (57%)] Loss: -1424.654541\n",
      "Train Epoch: 442 [45568/60000 (76%)] Loss: -1172.871216\n",
      "Train Epoch: 442 [56832/60000 (95%)] Loss: -1274.328979\n",
      "    epoch          : 442\n",
      "    loss           : -1247.9942876955884\n",
      "Train Epoch: 443 [512/60000 (1%)] Loss: -1399.465576\n",
      "Train Epoch: 443 [11776/60000 (20%)] Loss: -1314.055908\n",
      "Train Epoch: 443 [23040/60000 (38%)] Loss: -1086.965454\n",
      "Train Epoch: 443 [34304/60000 (57%)] Loss: -1071.958740\n",
      "Train Epoch: 443 [45568/60000 (76%)] Loss: -1240.097900\n",
      "Train Epoch: 443 [56832/60000 (95%)] Loss: -1411.379150\n",
      "    epoch          : 443\n",
      "    loss           : -1254.3022376453807\n",
      "Train Epoch: 444 [512/60000 (1%)] Loss: -1075.381958\n",
      "Train Epoch: 444 [11776/60000 (20%)] Loss: -1264.956787\n",
      "Train Epoch: 444 [23040/60000 (38%)] Loss: -1053.240967\n",
      "Train Epoch: 444 [34304/60000 (57%)] Loss: -1246.577515\n",
      "Train Epoch: 444 [45568/60000 (76%)] Loss: -1271.300049\n",
      "Train Epoch: 444 [56832/60000 (95%)] Loss: -1386.178467\n",
      "    epoch          : 444\n",
      "    loss           : -1231.8311233089469\n",
      "Train Epoch: 445 [512/60000 (1%)] Loss: -965.331543\n",
      "Train Epoch: 445 [11776/60000 (20%)] Loss: -1263.234131\n",
      "Train Epoch: 445 [23040/60000 (38%)] Loss: -1354.527100\n",
      "Train Epoch: 445 [34304/60000 (57%)] Loss: -1248.616699\n",
      "Train Epoch: 445 [45568/60000 (76%)] Loss: -1108.752686\n",
      "Train Epoch: 445 [56832/60000 (95%)] Loss: -1142.241943\n",
      "    epoch          : 445\n",
      "    loss           : -1237.4039410090043\n",
      "Train Epoch: 446 [512/60000 (1%)] Loss: -1104.647583\n",
      "Train Epoch: 446 [11776/60000 (20%)] Loss: -1398.370361\n",
      "Train Epoch: 446 [23040/60000 (38%)] Loss: -933.620239\n",
      "Train Epoch: 446 [34304/60000 (57%)] Loss: -1356.094727\n",
      "Train Epoch: 446 [45568/60000 (76%)] Loss: -1219.695801\n",
      "Train Epoch: 446 [56832/60000 (95%)] Loss: -1212.463989\n",
      "    epoch          : 446\n",
      "    loss           : -1240.2519736424676\n",
      "Train Epoch: 447 [512/60000 (1%)] Loss: -1368.704590\n",
      "Train Epoch: 447 [11776/60000 (20%)] Loss: -1389.320557\n",
      "Train Epoch: 447 [23040/60000 (38%)] Loss: -958.698303\n",
      "Train Epoch: 447 [34304/60000 (57%)] Loss: -1216.263184\n",
      "Train Epoch: 447 [45568/60000 (76%)] Loss: -1279.077637\n",
      "Train Epoch: 447 [56832/60000 (95%)] Loss: -1250.355957\n",
      "    epoch          : 447\n",
      "    loss           : -1225.6202280507923\n",
      "Train Epoch: 448 [512/60000 (1%)] Loss: -1256.455811\n",
      "Train Epoch: 448 [11776/60000 (20%)] Loss: -1063.974243\n",
      "Train Epoch: 448 [23040/60000 (38%)] Loss: -1384.241455\n",
      "Train Epoch: 448 [34304/60000 (57%)] Loss: -1105.373657\n",
      "Train Epoch: 448 [45568/60000 (76%)] Loss: -1229.909058\n",
      "Train Epoch: 448 [56832/60000 (95%)] Loss: -1038.082520\n",
      "    epoch          : 448\n",
      "    loss           : -1248.7025739594367\n",
      "Train Epoch: 449 [512/60000 (1%)] Loss: -1327.603760\n",
      "Train Epoch: 449 [11776/60000 (20%)] Loss: -1403.162476\n",
      "Train Epoch: 449 [23040/60000 (38%)] Loss: -1424.755859\n",
      "Train Epoch: 449 [34304/60000 (57%)] Loss: -1208.083008\n",
      "Train Epoch: 449 [45568/60000 (76%)] Loss: -1412.317871\n",
      "Train Epoch: 449 [56832/60000 (95%)] Loss: -1376.923462\n",
      "    epoch          : 449\n",
      "    loss           : -1249.1251084494725\n",
      "Train Epoch: 450 [512/60000 (1%)] Loss: -1388.418701\n",
      "Train Epoch: 450 [11776/60000 (20%)] Loss: -984.195679\n",
      "Train Epoch: 450 [23040/60000 (38%)] Loss: -1240.719604\n",
      "Train Epoch: 450 [34304/60000 (57%)] Loss: -1391.502808\n",
      "Train Epoch: 450 [45568/60000 (76%)] Loss: -962.877075\n",
      "Train Epoch: 450 [56832/60000 (95%)] Loss: -1202.282959\n",
      "    epoch          : 450\n",
      "    loss           : -1246.7422816389699\n",
      "Train Epoch: 451 [512/60000 (1%)] Loss: -1253.807495\n",
      "Train Epoch: 451 [11776/60000 (20%)] Loss: -1225.487793\n",
      "Train Epoch: 451 [23040/60000 (38%)] Loss: -1367.103882\n",
      "Train Epoch: 451 [34304/60000 (57%)] Loss: -1100.615967\n",
      "Train Epoch: 451 [45568/60000 (76%)] Loss: -1223.177979\n",
      "Train Epoch: 451 [56832/60000 (95%)] Loss: -1100.491455\n",
      "    epoch          : 451\n",
      "    loss           : -1245.635667359088\n",
      "Train Epoch: 452 [512/60000 (1%)] Loss: -1252.479004\n",
      "Train Epoch: 452 [11776/60000 (20%)] Loss: -1228.668213\n",
      "Train Epoch: 452 [23040/60000 (38%)] Loss: -1370.916382\n",
      "Train Epoch: 452 [34304/60000 (57%)] Loss: -1378.718994\n",
      "Train Epoch: 452 [45568/60000 (76%)] Loss: -1100.688110\n",
      "Train Epoch: 452 [56832/60000 (95%)] Loss: -1407.240479\n",
      "    epoch          : 452\n",
      "    loss           : -1263.6991566803497\n",
      "Train Epoch: 453 [512/60000 (1%)] Loss: -1109.443359\n",
      "Train Epoch: 453 [11776/60000 (20%)] Loss: -1410.411987\n",
      "Train Epoch: 453 [23040/60000 (38%)] Loss: -1396.753540\n",
      "Train Epoch: 453 [34304/60000 (57%)] Loss: -1216.697021\n",
      "Train Epoch: 453 [45568/60000 (76%)] Loss: -1094.401123\n",
      "Train Epoch: 453 [56832/60000 (95%)] Loss: -1252.966064\n",
      "    epoch          : 453\n",
      "    loss           : -1217.109804315082\n",
      "Train Epoch: 454 [512/60000 (1%)] Loss: -1275.625488\n",
      "Train Epoch: 454 [11776/60000 (20%)] Loss: -1412.211426\n",
      "Train Epoch: 454 [23040/60000 (38%)] Loss: -1097.478882\n",
      "Train Epoch: 454 [34304/60000 (57%)] Loss: -1381.562378\n",
      "Train Epoch: 454 [45568/60000 (76%)] Loss: -1266.720337\n",
      "Train Epoch: 454 [56832/60000 (95%)] Loss: -1262.791016\n",
      "    epoch          : 454\n",
      "    loss           : -1255.0706457795397\n",
      "Train Epoch: 455 [512/60000 (1%)] Loss: -1377.079834\n",
      "Train Epoch: 455 [11776/60000 (20%)] Loss: -1247.477417\n",
      "Train Epoch: 455 [23040/60000 (38%)] Loss: -1223.290039\n",
      "Train Epoch: 455 [34304/60000 (57%)] Loss: -1390.814575\n",
      "Train Epoch: 455 [45568/60000 (76%)] Loss: -1290.480957\n",
      "Train Epoch: 455 [56832/60000 (95%)] Loss: -1352.460815\n",
      "    epoch          : 455\n",
      "    loss           : -1255.660888671875\n",
      "Train Epoch: 456 [512/60000 (1%)] Loss: -1358.093506\n",
      "Train Epoch: 456 [11776/60000 (20%)] Loss: -1134.069092\n",
      "Train Epoch: 456 [23040/60000 (38%)] Loss: -1004.749451\n",
      "Train Epoch: 456 [34304/60000 (57%)] Loss: -1214.300781\n",
      "Train Epoch: 456 [45568/60000 (76%)] Loss: -1433.452637\n",
      "Train Epoch: 456 [56832/60000 (95%)] Loss: -1416.452393\n",
      "    epoch          : 456\n",
      "    loss           : -1241.4627375198622\n",
      "Train Epoch: 457 [512/60000 (1%)] Loss: -1373.297852\n",
      "Train Epoch: 457 [11776/60000 (20%)] Loss: -1352.809814\n",
      "Train Epoch: 457 [23040/60000 (38%)] Loss: -1097.724731\n",
      "Train Epoch: 457 [34304/60000 (57%)] Loss: -982.618774\n",
      "Train Epoch: 457 [45568/60000 (76%)] Loss: -1098.277344\n",
      "Train Epoch: 457 [56832/60000 (95%)] Loss: -1254.376221\n",
      "    epoch          : 457\n",
      "    loss           : -1241.0619480973583\n",
      "Train Epoch: 458 [512/60000 (1%)] Loss: -1394.458618\n",
      "Train Epoch: 458 [11776/60000 (20%)] Loss: -1361.742065\n",
      "Train Epoch: 458 [23040/60000 (38%)] Loss: -1410.117188\n",
      "Train Epoch: 458 [34304/60000 (57%)] Loss: -1207.718018\n",
      "Train Epoch: 458 [45568/60000 (76%)] Loss: -1358.801514\n",
      "Train Epoch: 458 [56832/60000 (95%)] Loss: -1371.742554\n",
      "    epoch          : 458\n",
      "    loss           : -1249.5095326913952\n",
      "Train Epoch: 459 [512/60000 (1%)] Loss: -1103.502686\n",
      "Train Epoch: 459 [11776/60000 (20%)] Loss: -1378.463623\n",
      "Train Epoch: 459 [23040/60000 (38%)] Loss: -1249.263672\n",
      "Train Epoch: 459 [34304/60000 (57%)] Loss: -1221.413574\n",
      "Train Epoch: 459 [45568/60000 (76%)] Loss: -1229.868774\n",
      "Train Epoch: 459 [56832/60000 (95%)] Loss: -1140.226929\n",
      "    epoch          : 459\n",
      "    loss           : -1240.6852741133694\n",
      "Train Epoch: 460 [512/60000 (1%)] Loss: -1233.285889\n",
      "Train Epoch: 460 [11776/60000 (20%)] Loss: -1115.858276\n",
      "Train Epoch: 460 [23040/60000 (38%)] Loss: -948.401733\n",
      "Train Epoch: 460 [34304/60000 (57%)] Loss: -1420.900635\n",
      "Train Epoch: 460 [45568/60000 (76%)] Loss: -1288.297119\n",
      "Train Epoch: 460 [56832/60000 (95%)] Loss: -1101.732422\n",
      "    epoch          : 460\n",
      "    loss           : -1248.5537742140605\n",
      "Train Epoch: 461 [512/60000 (1%)] Loss: -1234.082397\n",
      "Train Epoch: 461 [11776/60000 (20%)] Loss: -1093.042236\n",
      "Train Epoch: 461 [23040/60000 (38%)] Loss: -1047.678467\n",
      "Train Epoch: 461 [34304/60000 (57%)] Loss: -1376.010742\n",
      "Train Epoch: 461 [45568/60000 (76%)] Loss: -1229.084229\n",
      "Train Epoch: 461 [56832/60000 (95%)] Loss: -1334.275757\n",
      "    epoch          : 461\n",
      "    loss           : -1262.7587949246338\n",
      "Train Epoch: 462 [512/60000 (1%)] Loss: -1330.400757\n",
      "Train Epoch: 462 [11776/60000 (20%)] Loss: -1241.753784\n",
      "Train Epoch: 462 [23040/60000 (38%)] Loss: -1363.577393\n",
      "Train Epoch: 462 [34304/60000 (57%)] Loss: -1275.897827\n",
      "Train Epoch: 462 [45568/60000 (76%)] Loss: -1386.271362\n",
      "Train Epoch: 462 [56832/60000 (95%)] Loss: -1250.514160\n",
      "    epoch          : 462\n",
      "    loss           : -1256.6322405971378\n",
      "Train Epoch: 463 [512/60000 (1%)] Loss: -1210.961670\n",
      "Train Epoch: 463 [11776/60000 (20%)] Loss: -1294.943115\n",
      "Train Epoch: 463 [23040/60000 (38%)] Loss: -1271.213867\n",
      "Train Epoch: 463 [34304/60000 (57%)] Loss: -1218.872314\n",
      "Train Epoch: 463 [45568/60000 (76%)] Loss: -1276.071045\n",
      "Train Epoch: 463 [56832/60000 (95%)] Loss: -1266.487305\n",
      "    epoch          : 463\n",
      "    loss           : -1263.1402967205156\n",
      "Train Epoch: 464 [512/60000 (1%)] Loss: -1259.549561\n",
      "Train Epoch: 464 [11776/60000 (20%)] Loss: -1241.506470\n",
      "Train Epoch: 464 [23040/60000 (38%)] Loss: -1271.710449\n",
      "Train Epoch: 464 [34304/60000 (57%)] Loss: -1254.298584\n",
      "Train Epoch: 464 [45568/60000 (76%)] Loss: -1355.533569\n",
      "Train Epoch: 464 [56832/60000 (95%)] Loss: -1229.616455\n",
      "    epoch          : 464\n",
      "    loss           : -1255.372392040188\n",
      "Train Epoch: 465 [512/60000 (1%)] Loss: -1229.312134\n",
      "Train Epoch: 465 [11776/60000 (20%)] Loss: -1396.550293\n",
      "Train Epoch: 465 [23040/60000 (38%)] Loss: -1161.331299\n",
      "Train Epoch: 465 [34304/60000 (57%)] Loss: -1385.680786\n",
      "Train Epoch: 465 [45568/60000 (76%)] Loss: -1218.162109\n",
      "Train Epoch: 465 [56832/60000 (95%)] Loss: -1367.625610\n",
      "    epoch          : 465\n",
      "    loss           : -1253.1926352290784\n",
      "Train Epoch: 466 [512/60000 (1%)] Loss: -1209.615356\n",
      "Train Epoch: 466 [11776/60000 (20%)] Loss: -1228.476807\n",
      "Train Epoch: 466 [23040/60000 (38%)] Loss: -1243.977173\n",
      "Train Epoch: 466 [34304/60000 (57%)] Loss: -1279.765137\n",
      "Train Epoch: 466 [45568/60000 (76%)] Loss: -1244.369019\n",
      "Train Epoch: 466 [56832/60000 (95%)] Loss: -1195.266846\n",
      "    epoch          : 466\n",
      "    loss           : -1263.0283953133276\n",
      "Train Epoch: 467 [512/60000 (1%)] Loss: -1395.810547\n",
      "Train Epoch: 467 [11776/60000 (20%)] Loss: -1140.219482\n",
      "Train Epoch: 467 [23040/60000 (38%)] Loss: -1274.857300\n",
      "Train Epoch: 467 [34304/60000 (57%)] Loss: -1235.365723\n",
      "Train Epoch: 467 [45568/60000 (76%)] Loss: -1086.063110\n",
      "Train Epoch: 467 [56832/60000 (95%)] Loss: -1043.141357\n",
      "    epoch          : 467\n",
      "    loss           : -1252.4322723561088\n",
      "Train Epoch: 468 [512/60000 (1%)] Loss: -1396.596069\n",
      "Train Epoch: 468 [11776/60000 (20%)] Loss: -1154.860840\n",
      "Train Epoch: 468 [23040/60000 (38%)] Loss: -976.789673\n",
      "Train Epoch: 468 [34304/60000 (57%)] Loss: -1138.992432\n",
      "Train Epoch: 468 [45568/60000 (76%)] Loss: -1131.792236\n",
      "Train Epoch: 468 [56832/60000 (95%)] Loss: -1229.344360\n",
      "    epoch          : 468\n",
      "    loss           : -1242.7916344249318\n",
      "Train Epoch: 469 [512/60000 (1%)] Loss: -970.687744\n",
      "Train Epoch: 469 [11776/60000 (20%)] Loss: -1070.037476\n",
      "Train Epoch: 469 [23040/60000 (38%)] Loss: -1283.923340\n",
      "Train Epoch: 469 [34304/60000 (57%)] Loss: -1106.031250\n",
      "Train Epoch: 469 [45568/60000 (76%)] Loss: -1438.251465\n",
      "Train Epoch: 469 [56832/60000 (95%)] Loss: -1366.086426\n",
      "    epoch          : 469\n",
      "    loss           : -1254.0896640928452\n",
      "Train Epoch: 470 [512/60000 (1%)] Loss: -941.449280\n",
      "Train Epoch: 470 [11776/60000 (20%)] Loss: -1242.966064\n",
      "Train Epoch: 470 [23040/60000 (38%)] Loss: -1302.785522\n",
      "Train Epoch: 470 [34304/60000 (57%)] Loss: -1260.492920\n",
      "Train Epoch: 470 [45568/60000 (76%)] Loss: -1362.554688\n",
      "Train Epoch: 470 [56832/60000 (95%)] Loss: -1211.953003\n",
      "    epoch          : 470\n",
      "    loss           : -1253.6584786452815\n",
      "Train Epoch: 471 [512/60000 (1%)] Loss: -1296.898926\n",
      "Train Epoch: 471 [11776/60000 (20%)] Loss: -1388.782959\n",
      "Train Epoch: 471 [23040/60000 (38%)] Loss: -1240.242188\n",
      "Train Epoch: 471 [34304/60000 (57%)] Loss: -1280.195190\n",
      "Train Epoch: 471 [45568/60000 (76%)] Loss: -1362.042236\n",
      "Train Epoch: 471 [56832/60000 (95%)] Loss: -1242.136719\n",
      "    epoch          : 471\n",
      "    loss           : -1254.8963267870542\n",
      "Train Epoch: 472 [512/60000 (1%)] Loss: -1224.164307\n",
      "Train Epoch: 472 [11776/60000 (20%)] Loss: -1425.624146\n",
      "Train Epoch: 472 [23040/60000 (38%)] Loss: -1240.536499\n",
      "Train Epoch: 472 [34304/60000 (57%)] Loss: -1087.437378\n",
      "Train Epoch: 472 [45568/60000 (76%)] Loss: -1359.279053\n",
      "Train Epoch: 472 [56832/60000 (95%)] Loss: -1401.290894\n",
      "    epoch          : 472\n",
      "    loss           : -1256.2870524778205\n",
      "Train Epoch: 473 [512/60000 (1%)] Loss: -1325.976929\n",
      "Train Epoch: 473 [11776/60000 (20%)] Loss: -1093.719482\n",
      "Train Epoch: 473 [23040/60000 (38%)] Loss: -1201.009766\n",
      "Train Epoch: 473 [34304/60000 (57%)] Loss: -1242.837646\n",
      "Train Epoch: 473 [45568/60000 (76%)] Loss: -1249.157715\n",
      "Train Epoch: 473 [56832/60000 (95%)] Loss: -1416.537598\n",
      "    epoch          : 473\n",
      "    loss           : -1262.6958526783744\n",
      "Train Epoch: 474 [512/60000 (1%)] Loss: -1370.838867\n",
      "Train Epoch: 474 [11776/60000 (20%)] Loss: -1097.467285\n",
      "Train Epoch: 474 [23040/60000 (38%)] Loss: -1390.748901\n",
      "Train Epoch: 474 [34304/60000 (57%)] Loss: -1078.964111\n",
      "Train Epoch: 474 [45568/60000 (76%)] Loss: -1244.648438\n",
      "Train Epoch: 474 [56832/60000 (95%)] Loss: -1231.552612\n",
      "    epoch          : 474\n",
      "    loss           : -1247.555141298111\n",
      "Train Epoch: 475 [512/60000 (1%)] Loss: -1283.683960\n",
      "Train Epoch: 475 [11776/60000 (20%)] Loss: -1219.202759\n",
      "Train Epoch: 475 [23040/60000 (38%)] Loss: -1319.956055\n",
      "Train Epoch: 475 [34304/60000 (57%)] Loss: -1254.021118\n",
      "Train Epoch: 475 [45568/60000 (76%)] Loss: -1297.277100\n",
      "Train Epoch: 475 [56832/60000 (95%)] Loss: -1195.346924\n",
      "    epoch          : 475\n",
      "    loss           : -1249.9105921168784\n",
      "Train Epoch: 476 [512/60000 (1%)] Loss: -1386.150513\n",
      "Train Epoch: 476 [11776/60000 (20%)] Loss: -1160.528809\n",
      "Train Epoch: 476 [23040/60000 (38%)] Loss: -1271.124634\n",
      "Train Epoch: 476 [34304/60000 (57%)] Loss: -992.545044\n",
      "Train Epoch: 476 [45568/60000 (76%)] Loss: -1371.448975\n",
      "Train Epoch: 476 [56832/60000 (95%)] Loss: -1393.810791\n",
      "    epoch          : 476\n",
      "    loss           : -1257.2092569642148\n",
      "Train Epoch: 477 [512/60000 (1%)] Loss: -1245.989258\n",
      "Train Epoch: 477 [11776/60000 (20%)] Loss: -1209.239990\n",
      "Train Epoch: 477 [23040/60000 (38%)] Loss: -1381.219238\n",
      "Train Epoch: 477 [34304/60000 (57%)] Loss: -1251.415649\n",
      "Train Epoch: 477 [45568/60000 (76%)] Loss: -1411.895508\n",
      "Train Epoch: 477 [56832/60000 (95%)] Loss: -1305.693481\n",
      "    epoch          : 477\n",
      "    loss           : -1252.1464643747795\n",
      "Train Epoch: 478 [512/60000 (1%)] Loss: -1242.047974\n",
      "Train Epoch: 478 [11776/60000 (20%)] Loss: -1117.285767\n",
      "Train Epoch: 478 [23040/60000 (38%)] Loss: -1084.520752\n",
      "Train Epoch: 478 [34304/60000 (57%)] Loss: -1221.450439\n",
      "Train Epoch: 478 [45568/60000 (76%)] Loss: -1267.580811\n",
      "Train Epoch: 478 [56832/60000 (95%)] Loss: -1366.949707\n",
      "    epoch          : 478\n",
      "    loss           : -1223.4945354569431\n",
      "Train Epoch: 479 [512/60000 (1%)] Loss: -1100.434326\n",
      "Train Epoch: 479 [11776/60000 (20%)] Loss: -1213.242188\n",
      "Train Epoch: 479 [23040/60000 (38%)] Loss: -1253.923218\n",
      "Train Epoch: 479 [34304/60000 (57%)] Loss: -1252.199829\n",
      "Train Epoch: 479 [45568/60000 (76%)] Loss: -1394.890869\n",
      "Train Epoch: 479 [56832/60000 (95%)] Loss: -944.075806\n",
      "    epoch          : 479\n",
      "    loss           : -1262.1126455533301\n",
      "Train Epoch: 480 [512/60000 (1%)] Loss: -1383.410767\n",
      "Train Epoch: 480 [11776/60000 (20%)] Loss: -1346.751099\n",
      "Train Epoch: 480 [23040/60000 (38%)] Loss: -1382.610352\n",
      "Train Epoch: 480 [34304/60000 (57%)] Loss: -1260.268066\n",
      "Train Epoch: 480 [45568/60000 (76%)] Loss: -1219.535034\n",
      "Train Epoch: 480 [56832/60000 (95%)] Loss: -1141.409424\n",
      "    epoch          : 480\n",
      "    loss           : -1257.108914994924\n",
      "Train Epoch: 481 [512/60000 (1%)] Loss: -1417.421387\n",
      "Train Epoch: 481 [11776/60000 (20%)] Loss: -1416.593872\n",
      "Train Epoch: 481 [23040/60000 (38%)] Loss: -1289.147583\n",
      "Train Epoch: 481 [34304/60000 (57%)] Loss: -1284.452515\n",
      "Train Epoch: 481 [45568/60000 (76%)] Loss: -1228.526367\n",
      "Train Epoch: 481 [56832/60000 (95%)] Loss: -1180.220703\n",
      "    epoch          : 481\n",
      "    loss           : -1259.2883919753597\n",
      "Train Epoch: 482 [512/60000 (1%)] Loss: -1253.971191\n",
      "Train Epoch: 482 [11776/60000 (20%)] Loss: -1371.293213\n",
      "Train Epoch: 482 [23040/60000 (38%)] Loss: -1407.829590\n",
      "Train Epoch: 482 [34304/60000 (57%)] Loss: -1422.095093\n",
      "Train Epoch: 482 [45568/60000 (76%)] Loss: -1129.998291\n",
      "Train Epoch: 482 [56832/60000 (95%)] Loss: -1230.534424\n",
      "    epoch          : 482\n",
      "    loss           : -1248.2307427185403\n",
      "Train Epoch: 483 [512/60000 (1%)] Loss: -1039.024780\n",
      "Train Epoch: 483 [11776/60000 (20%)] Loss: -1353.173096\n",
      "Train Epoch: 483 [23040/60000 (38%)] Loss: -1410.980591\n",
      "Train Epoch: 483 [34304/60000 (57%)] Loss: -1260.408936\n",
      "Train Epoch: 483 [45568/60000 (76%)] Loss: -913.633667\n",
      "Train Epoch: 483 [56832/60000 (95%)] Loss: -926.447449\n",
      "    epoch          : 483\n",
      "    loss           : -1253.1325940493136\n",
      "Train Epoch: 484 [512/60000 (1%)] Loss: -1401.408936\n",
      "Train Epoch: 484 [11776/60000 (20%)] Loss: -1230.034302\n",
      "Train Epoch: 484 [23040/60000 (38%)] Loss: -1190.182983\n",
      "Train Epoch: 484 [34304/60000 (57%)] Loss: -1385.251099\n",
      "Train Epoch: 484 [45568/60000 (76%)] Loss: -1204.460083\n",
      "Train Epoch: 484 [56832/60000 (95%)] Loss: -1280.019775\n",
      "    epoch          : 484\n",
      "    loss           : -1253.4681925800562\n",
      "Train Epoch: 485 [512/60000 (1%)] Loss: -1113.037476\n",
      "Train Epoch: 485 [11776/60000 (20%)] Loss: -1145.702637\n",
      "Train Epoch: 485 [23040/60000 (38%)] Loss: -1142.394531\n",
      "Train Epoch: 485 [34304/60000 (57%)] Loss: -1223.548950\n",
      "Train Epoch: 485 [45568/60000 (76%)] Loss: -1113.334717\n",
      "Train Epoch: 485 [56832/60000 (95%)] Loss: -1376.149414\n",
      "    epoch          : 485\n",
      "    loss           : -1227.8236659852798\n",
      "Train Epoch: 486 [512/60000 (1%)] Loss: -1375.882568\n",
      "Train Epoch: 486 [11776/60000 (20%)] Loss: -1376.389160\n",
      "Train Epoch: 486 [23040/60000 (38%)] Loss: -1356.854858\n",
      "Train Epoch: 486 [34304/60000 (57%)] Loss: -1245.913086\n",
      "Train Epoch: 486 [45568/60000 (76%)] Loss: -1012.142517\n",
      "Train Epoch: 486 [56832/60000 (95%)] Loss: -1253.266968\n",
      "    epoch          : 486\n",
      "    loss           : -1260.9737855728065\n",
      "Train Epoch: 487 [512/60000 (1%)] Loss: -1232.193359\n",
      "Train Epoch: 487 [11776/60000 (20%)] Loss: -1382.505249\n",
      "Train Epoch: 487 [23040/60000 (38%)] Loss: -1257.580444\n",
      "Train Epoch: 487 [34304/60000 (57%)] Loss: -1387.365112\n",
      "Train Epoch: 487 [45568/60000 (76%)] Loss: -1253.701416\n",
      "Train Epoch: 487 [56832/60000 (95%)] Loss: -1071.477783\n",
      "    epoch          : 487\n",
      "    loss           : -1267.0673490190236\n",
      "Train Epoch: 488 [512/60000 (1%)] Loss: -960.180298\n",
      "Train Epoch: 488 [11776/60000 (20%)] Loss: -1089.935669\n",
      "Train Epoch: 488 [23040/60000 (38%)] Loss: -1044.670166\n",
      "Train Epoch: 488 [34304/60000 (57%)] Loss: -1250.895630\n",
      "Train Epoch: 488 [45568/60000 (76%)] Loss: -1346.535400\n",
      "Train Epoch: 488 [56832/60000 (95%)] Loss: -1372.993286\n",
      "    epoch          : 488\n",
      "    loss           : -1254.3935619289591\n",
      "Train Epoch: 489 [512/60000 (1%)] Loss: -1393.641846\n",
      "Train Epoch: 489 [11776/60000 (20%)] Loss: -1120.420776\n",
      "Train Epoch: 489 [23040/60000 (38%)] Loss: -1137.222412\n",
      "Train Epoch: 489 [34304/60000 (57%)] Loss: -1267.166992\n",
      "Train Epoch: 489 [45568/60000 (76%)] Loss: -1209.054688\n",
      "Train Epoch: 489 [56832/60000 (95%)] Loss: -1283.421021\n",
      "    epoch          : 489\n",
      "    loss           : -1243.225776801675\n",
      "Train Epoch: 490 [512/60000 (1%)] Loss: -1153.144043\n",
      "Train Epoch: 490 [11776/60000 (20%)] Loss: -1272.936523\n",
      "Train Epoch: 490 [23040/60000 (38%)] Loss: -1370.838379\n",
      "Train Epoch: 490 [34304/60000 (57%)] Loss: -1126.978638\n",
      "Train Epoch: 490 [45568/60000 (76%)] Loss: -1017.620667\n",
      "Train Epoch: 490 [56832/60000 (95%)] Loss: -1257.953125\n",
      "    epoch          : 490\n",
      "    loss           : -1266.0302177472304\n",
      "Train Epoch: 491 [512/60000 (1%)] Loss: -1237.318604\n",
      "Train Epoch: 491 [11776/60000 (20%)] Loss: -1218.428467\n",
      "Train Epoch: 491 [23040/60000 (38%)] Loss: -1085.067017\n",
      "Train Epoch: 491 [34304/60000 (57%)] Loss: -1256.962769\n",
      "Train Epoch: 491 [45568/60000 (76%)] Loss: -1172.792725\n",
      "Train Epoch: 491 [56832/60000 (95%)] Loss: -1233.033447\n",
      "    epoch          : 491\n",
      "    loss           : -1260.3313024488546\n",
      "Train Epoch: 492 [512/60000 (1%)] Loss: -1259.788940\n",
      "Train Epoch: 492 [11776/60000 (20%)] Loss: -1150.351196\n",
      "Train Epoch: 492 [23040/60000 (38%)] Loss: -1421.007935\n",
      "Train Epoch: 492 [34304/60000 (57%)] Loss: -1273.826782\n",
      "Train Epoch: 492 [45568/60000 (76%)] Loss: -1288.751465\n",
      "Train Epoch: 492 [56832/60000 (95%)] Loss: -1396.646973\n",
      "    epoch          : 492\n",
      "    loss           : -1277.1039740783347\n",
      "Train Epoch: 493 [512/60000 (1%)] Loss: -1079.453125\n",
      "Train Epoch: 493 [11776/60000 (20%)] Loss: -1036.653564\n",
      "Train Epoch: 493 [23040/60000 (38%)] Loss: -1222.927490\n",
      "Train Epoch: 493 [34304/60000 (57%)] Loss: -1355.740723\n",
      "Train Epoch: 493 [45568/60000 (76%)] Loss: -1413.021973\n",
      "Train Epoch: 493 [56832/60000 (95%)] Loss: -1142.629883\n",
      "    epoch          : 493\n",
      "    loss           : -1259.8244720286568\n",
      "Train Epoch: 494 [512/60000 (1%)] Loss: -1140.387207\n",
      "Train Epoch: 494 [11776/60000 (20%)] Loss: -1108.088867\n",
      "Train Epoch: 494 [23040/60000 (38%)] Loss: -996.340881\n",
      "Train Epoch: 494 [34304/60000 (57%)] Loss: -1391.917969\n",
      "Train Epoch: 494 [45568/60000 (76%)] Loss: -1368.560547\n",
      "Train Epoch: 494 [56832/60000 (95%)] Loss: -1384.017090\n",
      "    epoch          : 494\n",
      "    loss           : -1246.9366467147224\n",
      "Train Epoch: 495 [512/60000 (1%)] Loss: -1086.608643\n",
      "Train Epoch: 495 [11776/60000 (20%)] Loss: -1253.624756\n",
      "Train Epoch: 495 [23040/60000 (38%)] Loss: -1241.706421\n",
      "Train Epoch: 495 [34304/60000 (57%)] Loss: -1447.850586\n",
      "Train Epoch: 495 [45568/60000 (76%)] Loss: -961.390259\n",
      "Train Epoch: 495 [56832/60000 (95%)] Loss: -1159.284058\n",
      "    epoch          : 495\n",
      "    loss           : -1231.0752841065832\n",
      "Train Epoch: 496 [512/60000 (1%)] Loss: -1384.371094\n",
      "Train Epoch: 496 [11776/60000 (20%)] Loss: -1222.430664\n",
      "Train Epoch: 496 [23040/60000 (38%)] Loss: -1258.536499\n",
      "Train Epoch: 496 [34304/60000 (57%)] Loss: -1243.184204\n",
      "Train Epoch: 496 [45568/60000 (76%)] Loss: -1095.470825\n",
      "Train Epoch: 496 [56832/60000 (95%)] Loss: -1249.045044\n",
      "    epoch          : 496\n",
      "    loss           : -1246.0072781837594\n",
      "Train Epoch: 497 [512/60000 (1%)] Loss: -1254.544678\n",
      "Train Epoch: 497 [11776/60000 (20%)] Loss: -1419.755371\n",
      "Train Epoch: 497 [23040/60000 (38%)] Loss: -1221.697144\n",
      "Train Epoch: 497 [34304/60000 (57%)] Loss: -1314.480469\n",
      "Train Epoch: 497 [45568/60000 (76%)] Loss: -1230.416870\n",
      "Train Epoch: 497 [56832/60000 (95%)] Loss: -1407.906738\n",
      "    epoch          : 497\n",
      "    loss           : -1248.8474333165057\n",
      "Train Epoch: 498 [512/60000 (1%)] Loss: -1351.545654\n",
      "Train Epoch: 498 [11776/60000 (20%)] Loss: -1294.999268\n",
      "Train Epoch: 498 [23040/60000 (38%)] Loss: -1247.760254\n",
      "Train Epoch: 498 [34304/60000 (57%)] Loss: -1396.256104\n",
      "Train Epoch: 498 [45568/60000 (76%)] Loss: -1391.095459\n",
      "Train Epoch: 498 [56832/60000 (95%)] Loss: -1269.470093\n",
      "    epoch          : 498\n",
      "    loss           : -1256.5868275098208\n",
      "Train Epoch: 499 [512/60000 (1%)] Loss: -1270.770874\n",
      "Train Epoch: 499 [11776/60000 (20%)] Loss: -1370.097290\n",
      "Train Epoch: 499 [23040/60000 (38%)] Loss: -1395.283936\n",
      "Train Epoch: 499 [34304/60000 (57%)] Loss: -946.663208\n",
      "Train Epoch: 499 [45568/60000 (76%)] Loss: -1358.054443\n",
      "Train Epoch: 499 [56832/60000 (95%)] Loss: -1192.695312\n",
      "    epoch          : 499\n",
      "    loss           : -1251.8608260504943\n",
      "Train Epoch: 500 [512/60000 (1%)] Loss: -1212.894653\n",
      "Train Epoch: 500 [11776/60000 (20%)] Loss: -1109.579590\n",
      "Train Epoch: 500 [23040/60000 (38%)] Loss: -1183.725342\n",
      "Train Epoch: 500 [34304/60000 (57%)] Loss: -1266.298828\n",
      "Train Epoch: 500 [45568/60000 (76%)] Loss: -1249.491699\n",
      "Train Epoch: 500 [56832/60000 (95%)] Loss: -1390.369507\n",
      "    epoch          : 500\n",
      "    loss           : -1260.254928675075\n",
      "Saving checkpoint: saved/models/Mnist_DeepGenerativeOperad/0127_111843/checkpoint-epoch500.pth ...\n",
      "Train Epoch: 501 [512/60000 (1%)] Loss: -1265.974365\n",
      "Train Epoch: 501 [11776/60000 (20%)] Loss: -1416.819092\n",
      "Train Epoch: 501 [23040/60000 (38%)] Loss: -1399.638916\n",
      "Train Epoch: 501 [34304/60000 (57%)] Loss: -1427.711426\n",
      "Train Epoch: 501 [45568/60000 (76%)] Loss: -1222.506226\n",
      "Train Epoch: 501 [56832/60000 (95%)] Loss: -1181.328857\n",
      "    epoch          : 501\n",
      "    loss           : -1272.2084700589799\n",
      "Train Epoch: 502 [512/60000 (1%)] Loss: -1290.494141\n",
      "Train Epoch: 502 [11776/60000 (20%)] Loss: -1194.425171\n",
      "Train Epoch: 502 [23040/60000 (38%)] Loss: -1248.969238\n",
      "Train Epoch: 502 [34304/60000 (57%)] Loss: -1276.668945\n",
      "Train Epoch: 502 [45568/60000 (76%)] Loss: -1379.776855\n",
      "Train Epoch: 502 [56832/60000 (95%)] Loss: -1270.888672\n",
      "    epoch          : 502\n",
      "    loss           : -1268.8558654785156\n",
      "Train Epoch: 503 [512/60000 (1%)] Loss: -1305.491333\n",
      "Train Epoch: 503 [11776/60000 (20%)] Loss: -1375.835449\n",
      "Train Epoch: 503 [23040/60000 (38%)] Loss: -1256.973877\n",
      "Train Epoch: 503 [34304/60000 (57%)] Loss: -1165.028076\n",
      "Train Epoch: 503 [45568/60000 (76%)] Loss: -1094.766602\n",
      "Train Epoch: 503 [56832/60000 (95%)] Loss: -1410.401855\n",
      "    epoch          : 503\n",
      "    loss           : -1255.52131333863\n",
      "Train Epoch: 504 [512/60000 (1%)] Loss: -1089.058350\n",
      "Train Epoch: 504 [11776/60000 (20%)] Loss: -1223.950073\n",
      "Train Epoch: 504 [23040/60000 (38%)] Loss: -1271.234253\n",
      "Train Epoch: 504 [34304/60000 (57%)] Loss: -1095.642578\n",
      "Train Epoch: 504 [45568/60000 (76%)] Loss: -1253.141479\n",
      "Train Epoch: 504 [56832/60000 (95%)] Loss: -1241.558960\n",
      "    epoch          : 504\n",
      "    loss           : -1259.1454362599861\n",
      "Train Epoch: 505 [512/60000 (1%)] Loss: -1291.924927\n",
      "Train Epoch: 505 [11776/60000 (20%)] Loss: -1108.328491\n",
      "Train Epoch: 505 [23040/60000 (38%)] Loss: -1327.180176\n",
      "Train Epoch: 505 [34304/60000 (57%)] Loss: -1334.233765\n",
      "Train Epoch: 505 [45568/60000 (76%)] Loss: -1430.427490\n",
      "Train Epoch: 505 [56832/60000 (95%)] Loss: -1362.107422\n",
      "    epoch          : 505\n",
      "    loss           : -1268.6000342072741\n",
      "Train Epoch: 506 [512/60000 (1%)] Loss: -1417.158569\n",
      "Train Epoch: 506 [11776/60000 (20%)] Loss: -1433.374390\n",
      "Train Epoch: 506 [23040/60000 (38%)] Loss: -1392.190918\n",
      "Train Epoch: 506 [34304/60000 (57%)] Loss: -1449.573364\n",
      "Train Epoch: 506 [45568/60000 (76%)] Loss: -1291.614258\n",
      "Train Epoch: 506 [56832/60000 (95%)] Loss: -1396.066406\n",
      "    epoch          : 506\n",
      "    loss           : -1268.6770814367605\n",
      "Train Epoch: 507 [512/60000 (1%)] Loss: -1381.924805\n",
      "Train Epoch: 507 [11776/60000 (20%)] Loss: -1245.596436\n",
      "Train Epoch: 507 [23040/60000 (38%)] Loss: -1281.310303\n",
      "Train Epoch: 507 [34304/60000 (57%)] Loss: -1250.451294\n",
      "Train Epoch: 507 [45568/60000 (76%)] Loss: -1158.750122\n",
      "Train Epoch: 507 [56832/60000 (95%)] Loss: -1294.551758\n",
      "    epoch          : 507\n",
      "    loss           : -1265.5923539501125\n",
      "Train Epoch: 508 [512/60000 (1%)] Loss: -1376.664307\n",
      "Train Epoch: 508 [11776/60000 (20%)] Loss: -1368.923584\n",
      "Train Epoch: 508 [23040/60000 (38%)] Loss: -1170.696899\n",
      "Train Epoch: 508 [34304/60000 (57%)] Loss: -1451.360596\n",
      "Train Epoch: 508 [45568/60000 (76%)] Loss: -1091.222534\n",
      "Train Epoch: 508 [56832/60000 (95%)] Loss: -1266.346680\n",
      "    epoch          : 508\n",
      "    loss           : -1276.1172816389699\n",
      "Train Epoch: 509 [512/60000 (1%)] Loss: -1117.853149\n",
      "Train Epoch: 509 [11776/60000 (20%)] Loss: -1210.833374\n",
      "Train Epoch: 509 [23040/60000 (38%)] Loss: -1403.102539\n",
      "Train Epoch: 509 [34304/60000 (57%)] Loss: -1431.058472\n",
      "Train Epoch: 509 [45568/60000 (76%)] Loss: -1138.773804\n",
      "Train Epoch: 509 [56832/60000 (95%)] Loss: -1365.554077\n",
      "    epoch          : 509\n",
      "    loss           : -1255.924398476121\n",
      "Train Epoch: 510 [512/60000 (1%)] Loss: -1261.394775\n",
      "Train Epoch: 510 [11776/60000 (20%)] Loss: -1333.069824\n",
      "Train Epoch: 510 [23040/60000 (38%)] Loss: -1360.916992\n",
      "Train Epoch: 510 [34304/60000 (57%)] Loss: -1278.370850\n",
      "Train Epoch: 510 [45568/60000 (76%)] Loss: -1087.942871\n",
      "Train Epoch: 510 [56832/60000 (95%)] Loss: -1246.013550\n",
      "    epoch          : 510\n",
      "    loss           : -1245.9696582858846\n",
      "Train Epoch: 511 [512/60000 (1%)] Loss: -1400.090088\n",
      "Train Epoch: 511 [11776/60000 (20%)] Loss: -1458.227661\n",
      "Train Epoch: 511 [23040/60000 (38%)] Loss: -1397.986328\n",
      "Train Epoch: 511 [34304/60000 (57%)] Loss: -1383.761963\n",
      "Train Epoch: 511 [45568/60000 (76%)] Loss: -1364.180908\n",
      "Train Epoch: 511 [56832/60000 (95%)] Loss: -1292.176880\n",
      "    epoch          : 511\n",
      "    loss           : -1277.1610291906668\n",
      "Train Epoch: 512 [512/60000 (1%)] Loss: -1264.080566\n",
      "Train Epoch: 512 [11776/60000 (20%)] Loss: -992.508850\n",
      "Train Epoch: 512 [23040/60000 (38%)] Loss: -1272.696777\n",
      "Train Epoch: 512 [34304/60000 (57%)] Loss: -1114.538208\n",
      "Train Epoch: 512 [45568/60000 (76%)] Loss: -1268.417114\n",
      "Train Epoch: 512 [56832/60000 (95%)] Loss: -1386.059814\n",
      "    epoch          : 512\n",
      "    loss           : -1244.7587076822915\n",
      "Train Epoch: 513 [512/60000 (1%)] Loss: -920.171448\n",
      "Train Epoch: 513 [11776/60000 (20%)] Loss: -1402.549072\n",
      "Train Epoch: 513 [23040/60000 (38%)] Loss: -1234.967407\n",
      "Train Epoch: 513 [34304/60000 (57%)] Loss: -1226.303833\n",
      "Train Epoch: 513 [45568/60000 (76%)] Loss: -1202.880615\n",
      "Train Epoch: 513 [56832/60000 (95%)] Loss: -1294.238770\n",
      "    epoch          : 513\n",
      "    loss           : -1268.0332317460056\n",
      "Train Epoch: 514 [512/60000 (1%)] Loss: -1362.623657\n",
      "Train Epoch: 514 [11776/60000 (20%)] Loss: -1280.208740\n",
      "Train Epoch: 514 [23040/60000 (38%)] Loss: -1293.130493\n",
      "Train Epoch: 514 [34304/60000 (57%)] Loss: -1274.996826\n",
      "Train Epoch: 514 [45568/60000 (76%)] Loss: -1278.214966\n",
      "Train Epoch: 514 [56832/60000 (95%)] Loss: -1426.425415\n",
      "    epoch          : 514\n",
      "    loss           : -1268.229701155323\n",
      "Train Epoch: 515 [512/60000 (1%)] Loss: -1230.050537\n",
      "Train Epoch: 515 [11776/60000 (20%)] Loss: -1284.050415\n",
      "Train Epoch: 515 [23040/60000 (38%)] Loss: -1231.979004\n",
      "Train Epoch: 515 [34304/60000 (57%)] Loss: -1251.393677\n",
      "Train Epoch: 515 [45568/60000 (76%)] Loss: -1376.241943\n",
      "Train Epoch: 515 [56832/60000 (95%)] Loss: -1429.306030\n",
      "    epoch          : 515\n",
      "    loss           : -1276.3983095675537\n",
      "Train Epoch: 516 [512/60000 (1%)] Loss: -1418.751343\n",
      "Train Epoch: 516 [11776/60000 (20%)] Loss: -1440.824829\n",
      "Train Epoch: 516 [23040/60000 (38%)] Loss: -1262.562988\n",
      "Train Epoch: 516 [34304/60000 (57%)] Loss: -1227.070190\n",
      "Train Epoch: 516 [45568/60000 (76%)] Loss: -1273.900146\n",
      "Train Epoch: 516 [56832/60000 (95%)] Loss: -1355.927002\n",
      "    epoch          : 516\n",
      "    loss           : -1271.1162185237906\n",
      "Train Epoch: 517 [512/60000 (1%)] Loss: -1234.381592\n",
      "Train Epoch: 517 [11776/60000 (20%)] Loss: -1264.607544\n",
      "Train Epoch: 517 [23040/60000 (38%)] Loss: -1102.032471\n",
      "Train Epoch: 517 [34304/60000 (57%)] Loss: -1281.935425\n",
      "Train Epoch: 517 [45568/60000 (76%)] Loss: -1250.643799\n",
      "Train Epoch: 517 [56832/60000 (95%)] Loss: -1402.493652\n",
      "    epoch          : 517\n",
      "    loss           : -1259.5071243889588\n",
      "Train Epoch: 518 [512/60000 (1%)] Loss: -1295.761475\n",
      "Train Epoch: 518 [11776/60000 (20%)] Loss: -1246.481934\n",
      "Train Epoch: 518 [23040/60000 (38%)] Loss: -1291.550781\n",
      "Train Epoch: 518 [34304/60000 (57%)] Loss: -1289.193848\n",
      "Train Epoch: 518 [45568/60000 (76%)] Loss: -1295.858887\n",
      "Train Epoch: 518 [56832/60000 (95%)] Loss: -1403.959229\n",
      "    epoch          : 518\n",
      "    loss           : -1277.5327869135108\n",
      "Train Epoch: 519 [512/60000 (1%)] Loss: -1227.072754\n",
      "Train Epoch: 519 [11776/60000 (20%)] Loss: -1427.152344\n",
      "Train Epoch: 519 [23040/60000 (38%)] Loss: -1275.030029\n",
      "Train Epoch: 519 [34304/60000 (57%)] Loss: -1258.245483\n",
      "Train Epoch: 519 [45568/60000 (76%)] Loss: -1319.857666\n",
      "Train Epoch: 519 [56832/60000 (95%)] Loss: -1232.208252\n",
      "    epoch          : 519\n",
      "    loss           : -1289.0561547575696\n",
      "Train Epoch: 520 [512/60000 (1%)] Loss: -1201.414185\n",
      "Train Epoch: 520 [11776/60000 (20%)] Loss: -1192.119385\n",
      "Train Epoch: 520 [23040/60000 (38%)] Loss: -1064.074707\n",
      "Train Epoch: 520 [34304/60000 (57%)] Loss: -1233.392700\n",
      "Train Epoch: 520 [45568/60000 (76%)] Loss: -1391.786377\n",
      "Train Epoch: 520 [56832/60000 (95%)] Loss: -1211.679932\n",
      "    epoch          : 520\n",
      "    loss           : -1254.5795019117452\n",
      "Train Epoch: 521 [512/60000 (1%)] Loss: -1207.019653\n",
      "Train Epoch: 521 [11776/60000 (20%)] Loss: -1032.423584\n",
      "Train Epoch: 521 [23040/60000 (38%)] Loss: -1392.443115\n",
      "Train Epoch: 521 [34304/60000 (57%)] Loss: -1437.906738\n",
      "Train Epoch: 521 [45568/60000 (76%)] Loss: -1294.460205\n",
      "Train Epoch: 521 [56832/60000 (95%)] Loss: -1248.913818\n",
      "    epoch          : 521\n",
      "    loss           : -1270.9321616652323\n",
      "Train Epoch: 522 [512/60000 (1%)] Loss: -1216.959106\n",
      "Train Epoch: 522 [11776/60000 (20%)] Loss: -1403.005981\n",
      "Train Epoch: 522 [23040/60000 (38%)] Loss: -1133.741333\n",
      "Train Epoch: 522 [34304/60000 (57%)] Loss: -1191.191895\n",
      "Train Epoch: 522 [45568/60000 (76%)] Loss: -1431.696167\n",
      "Train Epoch: 522 [56832/60000 (95%)] Loss: -1272.699219\n",
      "    epoch          : 522\n",
      "    loss           : -1258.3589055120608\n",
      "Train Epoch: 523 [512/60000 (1%)] Loss: -1170.278442\n",
      "Train Epoch: 523 [11776/60000 (20%)] Loss: -1121.169556\n",
      "Train Epoch: 523 [23040/60000 (38%)] Loss: -1359.396362\n",
      "Train Epoch: 523 [34304/60000 (57%)] Loss: -1133.147705\n",
      "Train Epoch: 523 [45568/60000 (76%)] Loss: -1289.824951\n",
      "Train Epoch: 523 [56832/60000 (95%)] Loss: -1408.381226\n",
      "    epoch          : 523\n",
      "    loss           : -1271.1318580067089\n",
      "Train Epoch: 524 [512/60000 (1%)] Loss: -1268.850830\n",
      "Train Epoch: 524 [11776/60000 (20%)] Loss: -1108.319092\n",
      "Train Epoch: 524 [23040/60000 (38%)] Loss: -1421.710083\n",
      "Train Epoch: 524 [34304/60000 (57%)] Loss: -1249.025757\n",
      "Train Epoch: 524 [45568/60000 (76%)] Loss: -1399.838989\n",
      "Train Epoch: 524 [56832/60000 (95%)] Loss: -1388.399536\n",
      "    epoch          : 524\n",
      "    loss           : -1273.0123949643582\n",
      "Train Epoch: 525 [512/60000 (1%)] Loss: -1261.744873\n",
      "Train Epoch: 525 [11776/60000 (20%)] Loss: -967.043335\n",
      "Train Epoch: 525 [23040/60000 (38%)] Loss: -1422.228271\n",
      "Train Epoch: 525 [34304/60000 (57%)] Loss: -1230.940186\n",
      "Train Epoch: 525 [45568/60000 (76%)] Loss: -1464.600830\n",
      "Train Epoch: 525 [56832/60000 (95%)] Loss: -1257.983276\n",
      "    epoch          : 525\n",
      "    loss           : -1276.8893275718904\n",
      "Train Epoch: 526 [512/60000 (1%)] Loss: -1263.544312\n",
      "Train Epoch: 526 [11776/60000 (20%)] Loss: -851.743164\n",
      "Train Epoch: 526 [23040/60000 (38%)] Loss: -1401.080322\n",
      "Train Epoch: 526 [34304/60000 (57%)] Loss: -1459.112305\n",
      "Train Epoch: 526 [45568/60000 (76%)] Loss: -1116.774414\n",
      "Train Epoch: 526 [56832/60000 (95%)] Loss: -1371.273560\n",
      "    epoch          : 526\n",
      "    loss           : -1269.8180662683176\n",
      "Train Epoch: 527 [512/60000 (1%)] Loss: -1226.618652\n",
      "Train Epoch: 527 [11776/60000 (20%)] Loss: -1384.438721\n",
      "Train Epoch: 527 [23040/60000 (38%)] Loss: -1421.458008\n",
      "Train Epoch: 527 [34304/60000 (57%)] Loss: -1162.796143\n",
      "Train Epoch: 527 [45568/60000 (76%)] Loss: -1349.741821\n",
      "Train Epoch: 527 [56832/60000 (95%)] Loss: -1281.937500\n",
      "    epoch          : 527\n",
      "    loss           : -1258.9228405278955\n",
      "Train Epoch: 528 [512/60000 (1%)] Loss: -991.229004\n",
      "Train Epoch: 528 [11776/60000 (20%)] Loss: -1235.145020\n",
      "Train Epoch: 528 [23040/60000 (38%)] Loss: -1291.629150\n",
      "Train Epoch: 528 [34304/60000 (57%)] Loss: -1302.260986\n",
      "Train Epoch: 528 [45568/60000 (76%)] Loss: -1399.992920\n",
      "Train Epoch: 528 [56832/60000 (95%)] Loss: -1233.587524\n",
      "    epoch          : 528\n",
      "    loss           : -1252.461194226971\n",
      "Train Epoch: 529 [512/60000 (1%)] Loss: -1069.237427\n",
      "Train Epoch: 529 [11776/60000 (20%)] Loss: -1399.832886\n",
      "Train Epoch: 529 [23040/60000 (38%)] Loss: -1263.820312\n",
      "Train Epoch: 529 [34304/60000 (57%)] Loss: -1275.903320\n",
      "Train Epoch: 529 [45568/60000 (76%)] Loss: -1313.057495\n",
      "Train Epoch: 529 [56832/60000 (95%)] Loss: -1205.194092\n",
      "    epoch          : 529\n",
      "    loss           : -1265.81919214281\n",
      "Train Epoch: 530 [512/60000 (1%)] Loss: -1219.614380\n",
      "Train Epoch: 530 [11776/60000 (20%)] Loss: -1393.351562\n",
      "Train Epoch: 530 [23040/60000 (38%)] Loss: -1314.393066\n",
      "Train Epoch: 530 [34304/60000 (57%)] Loss: -1258.344971\n",
      "Train Epoch: 530 [45568/60000 (76%)] Loss: -1433.984253\n",
      "Train Epoch: 530 [56832/60000 (95%)] Loss: -1266.409912\n",
      "    epoch          : 530\n",
      "    loss           : -1264.7390795346707\n",
      "Train Epoch: 531 [512/60000 (1%)] Loss: -1318.928345\n",
      "Train Epoch: 531 [11776/60000 (20%)] Loss: -1233.338745\n",
      "Train Epoch: 531 [23040/60000 (38%)] Loss: -1251.571533\n",
      "Train Epoch: 531 [34304/60000 (57%)] Loss: -1078.437866\n",
      "Train Epoch: 531 [45568/60000 (76%)] Loss: -1279.529907\n",
      "Train Epoch: 531 [56832/60000 (95%)] Loss: -1417.220703\n",
      "    epoch          : 531\n",
      "    loss           : -1255.034722969357\n",
      "Train Epoch: 532 [512/60000 (1%)] Loss: -1287.327881\n",
      "Train Epoch: 532 [11776/60000 (20%)] Loss: -1109.559692\n",
      "Train Epoch: 532 [23040/60000 (38%)] Loss: -1342.044556\n",
      "Train Epoch: 532 [34304/60000 (57%)] Loss: -1379.362549\n",
      "Train Epoch: 532 [45568/60000 (76%)] Loss: -1150.146851\n",
      "Train Epoch: 532 [56832/60000 (95%)] Loss: -1287.197998\n",
      "    epoch          : 532\n",
      "    loss           : -1273.9447424937102\n",
      "Train Epoch: 533 [512/60000 (1%)] Loss: -1321.897827\n",
      "Train Epoch: 533 [11776/60000 (20%)] Loss: -1394.386230\n",
      "Train Epoch: 533 [23040/60000 (38%)] Loss: -1347.217651\n",
      "Train Epoch: 533 [34304/60000 (57%)] Loss: -1217.016602\n",
      "Train Epoch: 533 [45568/60000 (76%)] Loss: -1314.947266\n",
      "Train Epoch: 533 [56832/60000 (95%)] Loss: -1403.393066\n",
      "    epoch          : 533\n",
      "    loss           : -1278.0253778662386\n",
      "Train Epoch: 534 [512/60000 (1%)] Loss: -1280.723755\n",
      "Train Epoch: 534 [11776/60000 (20%)] Loss: -1098.577881\n",
      "Train Epoch: 534 [23040/60000 (38%)] Loss: -1396.688110\n",
      "Train Epoch: 534 [34304/60000 (57%)] Loss: -1228.786377\n",
      "Train Epoch: 534 [45568/60000 (76%)] Loss: -1275.693481\n",
      "Train Epoch: 534 [56832/60000 (95%)] Loss: -1290.430542\n",
      "    epoch          : 534\n",
      "    loss           : -1259.9020977128025\n",
      "Train Epoch: 535 [512/60000 (1%)] Loss: -1253.849731\n",
      "Train Epoch: 535 [11776/60000 (20%)] Loss: -1409.726685\n",
      "Train Epoch: 535 [23040/60000 (38%)] Loss: -1262.281738\n",
      "Train Epoch: 535 [34304/60000 (57%)] Loss: -1415.793823\n",
      "Train Epoch: 535 [45568/60000 (76%)] Loss: -1233.311157\n",
      "Train Epoch: 535 [56832/60000 (95%)] Loss: -1123.123291\n",
      "    epoch          : 535\n",
      "    loss           : -1269.3313672771562\n",
      "Train Epoch: 536 [512/60000 (1%)] Loss: -1346.930054\n",
      "Train Epoch: 536 [11776/60000 (20%)] Loss: -1259.905518\n",
      "Train Epoch: 536 [23040/60000 (38%)] Loss: -1120.997437\n",
      "Train Epoch: 536 [34304/60000 (57%)] Loss: -1242.923584\n",
      "Train Epoch: 536 [45568/60000 (76%)] Loss: -1269.468750\n",
      "Train Epoch: 536 [56832/60000 (95%)] Loss: -1397.322998\n",
      "    epoch          : 536\n",
      "    loss           : -1262.0901951331878\n",
      "Train Epoch: 537 [512/60000 (1%)] Loss: -1278.984131\n",
      "Train Epoch: 537 [11776/60000 (20%)] Loss: -1165.769165\n",
      "Train Epoch: 537 [23040/60000 (38%)] Loss: -1432.594727\n",
      "Train Epoch: 537 [34304/60000 (57%)] Loss: -1420.847168\n",
      "Train Epoch: 537 [45568/60000 (76%)] Loss: -1359.480591\n",
      "Train Epoch: 537 [56832/60000 (95%)] Loss: -1166.911499\n",
      "    epoch          : 537\n",
      "    loss           : -1252.8227371819276\n",
      "Train Epoch: 538 [512/60000 (1%)] Loss: -1299.599609\n",
      "Train Epoch: 538 [11776/60000 (20%)] Loss: -1282.423584\n",
      "Train Epoch: 538 [23040/60000 (38%)] Loss: -1409.330322\n",
      "Train Epoch: 538 [34304/60000 (57%)] Loss: -1274.068970\n",
      "Train Epoch: 538 [45568/60000 (76%)] Loss: -1233.848267\n",
      "Train Epoch: 538 [56832/60000 (95%)] Loss: -1256.485718\n",
      "    epoch          : 538\n",
      "    loss           : -1257.8462652001676\n",
      "Train Epoch: 539 [512/60000 (1%)] Loss: -1230.391724\n",
      "Train Epoch: 539 [11776/60000 (20%)] Loss: -1072.730713\n",
      "Train Epoch: 539 [23040/60000 (38%)] Loss: -1262.443604\n",
      "Train Epoch: 539 [34304/60000 (57%)] Loss: -1191.718750\n",
      "Train Epoch: 539 [45568/60000 (76%)] Loss: -1409.399414\n",
      "Train Epoch: 539 [56832/60000 (95%)] Loss: -1398.273071\n",
      "    epoch          : 539\n",
      "    loss           : -1280.8281868972347\n",
      "Train Epoch: 540 [512/60000 (1%)] Loss: -1381.529297\n",
      "Train Epoch: 540 [11776/60000 (20%)] Loss: -1256.679932\n",
      "Train Epoch: 540 [23040/60000 (38%)] Loss: -1250.346069\n",
      "Train Epoch: 540 [34304/60000 (57%)] Loss: -1402.718994\n",
      "Train Epoch: 540 [45568/60000 (76%)] Loss: -1160.253174\n",
      "Train Epoch: 540 [56832/60000 (95%)] Loss: -1273.109619\n",
      "    epoch          : 540\n",
      "    loss           : -1283.9714031327244\n",
      "Train Epoch: 541 [512/60000 (1%)] Loss: -1263.522583\n",
      "Train Epoch: 541 [11776/60000 (20%)] Loss: -1277.787598\n",
      "Train Epoch: 541 [23040/60000 (38%)] Loss: -1252.359741\n",
      "Train Epoch: 541 [34304/60000 (57%)] Loss: -1112.690796\n",
      "Train Epoch: 541 [45568/60000 (76%)] Loss: -1039.840210\n",
      "Train Epoch: 541 [56832/60000 (95%)] Loss: -1110.056885\n",
      "    epoch          : 541\n",
      "    loss           : -1277.065416583907\n",
      "Train Epoch: 542 [512/60000 (1%)] Loss: -1273.564331\n",
      "Train Epoch: 542 [11776/60000 (20%)] Loss: -966.925415\n",
      "Train Epoch: 542 [23040/60000 (38%)] Loss: -1437.787231\n",
      "Train Epoch: 542 [34304/60000 (57%)] Loss: -1194.542114\n",
      "Train Epoch: 542 [45568/60000 (76%)] Loss: -1180.268799\n",
      "Train Epoch: 542 [56832/60000 (95%)] Loss: -1414.533325\n",
      "    epoch          : 542\n",
      "    loss           : -1268.8354000802767\n",
      "Train Epoch: 543 [512/60000 (1%)] Loss: -1232.751953\n",
      "Train Epoch: 543 [11776/60000 (20%)] Loss: -1409.217407\n",
      "Train Epoch: 543 [23040/60000 (38%)] Loss: -1126.229736\n",
      "Train Epoch: 543 [34304/60000 (57%)] Loss: -1227.016235\n",
      "Train Epoch: 543 [45568/60000 (76%)] Loss: -1266.158447\n",
      "Train Epoch: 543 [56832/60000 (95%)] Loss: -1331.312256\n",
      "    epoch          : 543\n",
      "    loss           : -1245.2122182037872\n",
      "Train Epoch: 544 [512/60000 (1%)] Loss: -1131.283325\n",
      "Train Epoch: 544 [11776/60000 (20%)] Loss: -1289.070923\n",
      "Train Epoch: 544 [23040/60000 (38%)] Loss: -1296.541016\n",
      "Train Epoch: 544 [34304/60000 (57%)] Loss: -1241.275513\n",
      "Train Epoch: 544 [45568/60000 (76%)] Loss: -1335.623657\n",
      "Train Epoch: 544 [56832/60000 (95%)] Loss: -1283.279907\n",
      "    epoch          : 544\n",
      "    loss           : -1273.366530941031\n",
      "Train Epoch: 545 [512/60000 (1%)] Loss: -1180.593140\n",
      "Train Epoch: 545 [11776/60000 (20%)] Loss: -1315.347656\n",
      "Train Epoch: 545 [23040/60000 (38%)] Loss: -1272.878174\n",
      "Train Epoch: 545 [34304/60000 (57%)] Loss: -1375.234863\n",
      "Train Epoch: 545 [45568/60000 (76%)] Loss: -1225.653809\n",
      "Train Epoch: 545 [56832/60000 (95%)] Loss: -1307.670898\n",
      "    epoch          : 545\n",
      "    loss           : -1267.868495962714\n",
      "Train Epoch: 546 [512/60000 (1%)] Loss: -1467.917358\n",
      "Train Epoch: 546 [11776/60000 (20%)] Loss: -1278.938965\n",
      "Train Epoch: 546 [23040/60000 (38%)] Loss: -1094.716064\n",
      "Train Epoch: 546 [34304/60000 (57%)] Loss: -1170.934326\n",
      "Train Epoch: 546 [45568/60000 (76%)] Loss: -1215.645020\n",
      "Train Epoch: 546 [56832/60000 (95%)] Loss: -1158.756592\n",
      "    epoch          : 546\n",
      "    loss           : -1259.4131076618776\n",
      "Train Epoch: 547 [512/60000 (1%)] Loss: -1404.520020\n",
      "Train Epoch: 547 [11776/60000 (20%)] Loss: -1215.918701\n",
      "Train Epoch: 547 [23040/60000 (38%)] Loss: -1272.506104\n",
      "Train Epoch: 547 [34304/60000 (57%)] Loss: -1115.273560\n",
      "Train Epoch: 547 [45568/60000 (76%)] Loss: -1270.451660\n",
      "Train Epoch: 547 [56832/60000 (95%)] Loss: -1261.056885\n",
      "    epoch          : 547\n",
      "    loss           : -1271.415465618931\n",
      "Train Epoch: 548 [512/60000 (1%)] Loss: -1271.266846\n",
      "Train Epoch: 548 [11776/60000 (20%)] Loss: -1213.793457\n",
      "Train Epoch: 548 [23040/60000 (38%)] Loss: -1255.854980\n",
      "Train Epoch: 548 [34304/60000 (57%)] Loss: -1406.456421\n",
      "Train Epoch: 548 [45568/60000 (76%)] Loss: -1139.030762\n",
      "Train Epoch: 548 [56832/60000 (95%)] Loss: -1432.071045\n",
      "    epoch          : 548\n",
      "    loss           : -1269.5400223381776\n",
      "Train Epoch: 549 [512/60000 (1%)] Loss: -1132.598633\n",
      "Train Epoch: 549 [11776/60000 (20%)] Loss: -1396.484741\n",
      "Train Epoch: 549 [23040/60000 (38%)] Loss: -1408.898682\n",
      "Train Epoch: 549 [34304/60000 (57%)] Loss: -1280.948975\n",
      "Train Epoch: 549 [45568/60000 (76%)] Loss: -1259.719971\n",
      "Train Epoch: 549 [56832/60000 (95%)] Loss: -1253.240967\n",
      "    epoch          : 549\n",
      "    loss           : -1261.9402536510747\n",
      "Train Epoch: 550 [512/60000 (1%)] Loss: -1137.110229\n",
      "Train Epoch: 550 [11776/60000 (20%)] Loss: -1243.430420\n",
      "Train Epoch: 550 [23040/60000 (38%)] Loss: -1309.075195\n",
      "Train Epoch: 550 [34304/60000 (57%)] Loss: -1434.641113\n",
      "Train Epoch: 550 [45568/60000 (76%)] Loss: -1108.397461\n",
      "Train Epoch: 550 [56832/60000 (95%)] Loss: -1140.896484\n",
      "    epoch          : 550\n",
      "    loss           : -1275.9483627060713\n",
      "Train Epoch: 551 [512/60000 (1%)] Loss: -1290.835083\n",
      "Train Epoch: 551 [11776/60000 (20%)] Loss: -1373.096191\n",
      "Train Epoch: 551 [23040/60000 (38%)] Loss: -974.094299\n",
      "Train Epoch: 551 [34304/60000 (57%)] Loss: -1327.057983\n",
      "Train Epoch: 551 [45568/60000 (76%)] Loss: -1203.141357\n",
      "Train Epoch: 551 [56832/60000 (95%)] Loss: -1333.925781\n",
      "    epoch          : 551\n",
      "    loss           : -1269.8682137182204\n",
      "Train Epoch: 552 [512/60000 (1%)] Loss: -1364.100708\n",
      "Train Epoch: 552 [11776/60000 (20%)] Loss: -1273.241943\n",
      "Train Epoch: 552 [23040/60000 (38%)] Loss: -1284.473022\n",
      "Train Epoch: 552 [34304/60000 (57%)] Loss: -1293.553711\n",
      "Train Epoch: 552 [45568/60000 (76%)] Loss: -1369.539551\n",
      "Train Epoch: 552 [56832/60000 (95%)] Loss: -1440.398682\n",
      "    epoch          : 552\n",
      "    loss           : -1289.034451587052\n",
      "Train Epoch: 553 [512/60000 (1%)] Loss: -1011.946716\n",
      "Train Epoch: 553 [11776/60000 (20%)] Loss: -1257.510498\n",
      "Train Epoch: 553 [23040/60000 (38%)] Loss: -1468.070068\n",
      "Train Epoch: 553 [34304/60000 (57%)] Loss: -1098.767822\n",
      "Train Epoch: 553 [45568/60000 (76%)] Loss: -1273.085938\n",
      "Train Epoch: 553 [56832/60000 (95%)] Loss: -1106.158203\n",
      "    epoch          : 553\n",
      "    loss           : -1264.1119215798244\n",
      "Train Epoch: 554 [512/60000 (1%)] Loss: -1232.676147\n",
      "Train Epoch: 554 [11776/60000 (20%)] Loss: -1430.805908\n",
      "Train Epoch: 554 [23040/60000 (38%)] Loss: -1312.202271\n",
      "Train Epoch: 554 [34304/60000 (57%)] Loss: -1437.597656\n",
      "Train Epoch: 554 [45568/60000 (76%)] Loss: -1003.766968\n",
      "Train Epoch: 554 [56832/60000 (95%)] Loss: -1297.315796\n",
      "    epoch          : 554\n",
      "    loss           : -1271.0589834094721\n",
      "Train Epoch: 555 [512/60000 (1%)] Loss: -1229.586060\n",
      "Train Epoch: 555 [11776/60000 (20%)] Loss: -1416.962280\n",
      "Train Epoch: 555 [23040/60000 (38%)] Loss: -1353.620728\n",
      "Train Epoch: 555 [34304/60000 (57%)] Loss: -1378.923096\n",
      "Train Epoch: 555 [45568/60000 (76%)] Loss: -1267.443726\n",
      "Train Epoch: 555 [56832/60000 (95%)] Loss: -1438.973877\n",
      "    epoch          : 555\n",
      "    loss           : -1257.3776324428409\n",
      "Train Epoch: 556 [512/60000 (1%)] Loss: -1149.041992\n",
      "Train Epoch: 556 [11776/60000 (20%)] Loss: -1404.293945\n",
      "Train Epoch: 556 [23040/60000 (38%)] Loss: -1001.758118\n",
      "Train Epoch: 556 [34304/60000 (57%)] Loss: -1069.124634\n",
      "Train Epoch: 556 [45568/60000 (76%)] Loss: -1391.759277\n",
      "Train Epoch: 556 [56832/60000 (95%)] Loss: -1455.918457\n",
      "    epoch          : 556\n",
      "    loss           : -1286.7397541972875\n",
      "Train Epoch: 557 [512/60000 (1%)] Loss: -1190.910034\n",
      "Train Epoch: 557 [11776/60000 (20%)] Loss: -1084.871216\n",
      "Train Epoch: 557 [23040/60000 (38%)] Loss: -1130.951050\n",
      "Train Epoch: 557 [34304/60000 (57%)] Loss: -1129.581665\n",
      "Train Epoch: 557 [45568/60000 (76%)] Loss: -1435.387939\n",
      "Train Epoch: 557 [56832/60000 (95%)] Loss: -1400.398682\n",
      "    epoch          : 557\n",
      "    loss           : -1274.3009607347392\n",
      "Train Epoch: 558 [512/60000 (1%)] Loss: -1144.470825\n",
      "Train Epoch: 558 [11776/60000 (20%)] Loss: -1021.079834\n",
      "Train Epoch: 558 [23040/60000 (38%)] Loss: -1432.941406\n",
      "Train Epoch: 558 [34304/60000 (57%)] Loss: -1226.292725\n",
      "Train Epoch: 558 [45568/60000 (76%)] Loss: -1199.656494\n",
      "Train Epoch: 558 [56832/60000 (95%)] Loss: -1255.456055\n",
      "    epoch          : 558\n",
      "    loss           : -1271.8056087170617\n",
      "Train Epoch: 559 [512/60000 (1%)] Loss: -1086.518799\n",
      "Train Epoch: 559 [11776/60000 (20%)] Loss: -1421.858154\n",
      "Train Epoch: 559 [23040/60000 (38%)] Loss: -1389.369385\n",
      "Train Epoch: 559 [34304/60000 (57%)] Loss: -1381.252075\n",
      "Train Epoch: 559 [45568/60000 (76%)] Loss: -1234.575073\n",
      "Train Epoch: 559 [56832/60000 (95%)] Loss: -1234.835815\n",
      "    epoch          : 559\n",
      "    loss           : -1265.7754928675074\n",
      "Train Epoch: 560 [512/60000 (1%)] Loss: -1269.597412\n",
      "Train Epoch: 560 [11776/60000 (20%)] Loss: -951.255005\n",
      "Train Epoch: 560 [23040/60000 (38%)] Loss: -1208.867676\n",
      "Train Epoch: 560 [34304/60000 (57%)] Loss: -1270.739014\n",
      "Train Epoch: 560 [45568/60000 (76%)] Loss: -1250.292480\n",
      "Train Epoch: 560 [56832/60000 (95%)] Loss: -1431.591797\n",
      "    epoch          : 560\n",
      "    loss           : -1273.6915565964864\n",
      "Train Epoch: 561 [512/60000 (1%)] Loss: -1237.784180\n",
      "Train Epoch: 561 [11776/60000 (20%)] Loss: -1158.163330\n",
      "Train Epoch: 561 [23040/60000 (38%)] Loss: -1298.891479\n",
      "Train Epoch: 561 [34304/60000 (57%)] Loss: -1412.805420\n",
      "Train Epoch: 561 [45568/60000 (76%)] Loss: -1274.045044\n",
      "Train Epoch: 561 [56832/60000 (95%)] Loss: -1425.625488\n",
      "    epoch          : 561\n",
      "    loss           : -1283.6049801239187\n",
      "Train Epoch: 562 [512/60000 (1%)] Loss: -1273.527100\n",
      "Train Epoch: 562 [11776/60000 (20%)] Loss: -1038.999756\n",
      "Train Epoch: 562 [23040/60000 (38%)] Loss: -1139.065552\n",
      "Train Epoch: 562 [34304/60000 (57%)] Loss: -1425.145264\n",
      "Train Epoch: 562 [45568/60000 (76%)] Loss: -1159.446655\n",
      "Train Epoch: 562 [56832/60000 (95%)] Loss: -1189.582764\n",
      "    epoch          : 562\n",
      "    loss           : -1273.2835777843068\n",
      "Train Epoch: 563 [512/60000 (1%)] Loss: -1025.621582\n",
      "Train Epoch: 563 [11776/60000 (20%)] Loss: -1414.829468\n",
      "Train Epoch: 563 [23040/60000 (38%)] Loss: -1432.286743\n",
      "Train Epoch: 563 [34304/60000 (57%)] Loss: -1094.291138\n",
      "Train Epoch: 563 [45568/60000 (76%)] Loss: -1432.329346\n",
      "Train Epoch: 563 [56832/60000 (95%)] Loss: -1105.480225\n",
      "    epoch          : 563\n",
      "    loss           : -1271.366161626611\n",
      "Train Epoch: 564 [512/60000 (1%)] Loss: -1135.674316\n",
      "Train Epoch: 564 [11776/60000 (20%)] Loss: -1396.435669\n",
      "Train Epoch: 564 [23040/60000 (38%)] Loss: -1299.292236\n",
      "Train Epoch: 564 [34304/60000 (57%)] Loss: -1418.107910\n",
      "Train Epoch: 564 [45568/60000 (76%)] Loss: -1210.676514\n",
      "Train Epoch: 564 [56832/60000 (95%)] Loss: -1320.494141\n",
      "    epoch          : 564\n",
      "    loss           : -1276.7911944200762\n",
      "Train Epoch: 565 [512/60000 (1%)] Loss: -1430.207397\n",
      "Train Epoch: 565 [11776/60000 (20%)] Loss: -1314.447266\n",
      "Train Epoch: 565 [23040/60000 (38%)] Loss: -1381.032837\n",
      "Train Epoch: 565 [34304/60000 (57%)] Loss: -1229.117065\n",
      "Train Epoch: 565 [45568/60000 (76%)] Loss: -1168.547607\n",
      "Train Epoch: 565 [56832/60000 (95%)] Loss: -1263.839355\n",
      "    epoch          : 565\n",
      "    loss           : -1281.6545523950608\n",
      "Train Epoch: 566 [512/60000 (1%)] Loss: -1010.549377\n",
      "Train Epoch: 566 [11776/60000 (20%)] Loss: -1234.825317\n",
      "Train Epoch: 566 [23040/60000 (38%)] Loss: -1141.377197\n",
      "Train Epoch: 566 [34304/60000 (57%)] Loss: -1134.746094\n",
      "Train Epoch: 566 [45568/60000 (76%)] Loss: -1401.275513\n",
      "Train Epoch: 566 [56832/60000 (95%)] Loss: -989.931885\n",
      "    epoch          : 566\n",
      "    loss           : -1271.389849991448\n",
      "Train Epoch: 567 [512/60000 (1%)] Loss: -1425.383179\n",
      "Train Epoch: 567 [11776/60000 (20%)] Loss: -956.166870\n",
      "Train Epoch: 567 [23040/60000 (38%)] Loss: -1261.781982\n",
      "Train Epoch: 567 [34304/60000 (57%)] Loss: -1288.564331\n",
      "Train Epoch: 567 [45568/60000 (76%)] Loss: -1327.119507\n",
      "Train Epoch: 567 [56832/60000 (95%)] Loss: -1434.087524\n",
      "    epoch          : 567\n",
      "    loss           : -1276.150264244295\n",
      "Train Epoch: 568 [512/60000 (1%)] Loss: -1312.013550\n",
      "Train Epoch: 568 [11776/60000 (20%)] Loss: -957.401489\n",
      "Train Epoch: 568 [23040/60000 (38%)] Loss: -1074.818970\n",
      "Train Epoch: 568 [34304/60000 (57%)] Loss: -1391.751587\n",
      "Train Epoch: 568 [45568/60000 (76%)] Loss: -1410.726074\n",
      "Train Epoch: 568 [56832/60000 (95%)] Loss: -1264.180908\n",
      "    epoch          : 568\n",
      "    loss           : -1285.3461603714247\n",
      "Train Epoch: 569 [512/60000 (1%)] Loss: -1195.291870\n",
      "Train Epoch: 569 [11776/60000 (20%)] Loss: -1328.918457\n",
      "Train Epoch: 569 [23040/60000 (38%)] Loss: -1445.599243\n",
      "Train Epoch: 569 [34304/60000 (57%)] Loss: -1052.231934\n",
      "Train Epoch: 569 [45568/60000 (76%)] Loss: -1104.932861\n",
      "Train Epoch: 569 [56832/60000 (95%)] Loss: -979.843506\n",
      "    epoch          : 569\n",
      "    loss           : -1275.220666228041\n",
      "Train Epoch: 570 [512/60000 (1%)] Loss: -1096.505615\n",
      "Train Epoch: 570 [11776/60000 (20%)] Loss: -1241.683472\n",
      "Train Epoch: 570 [23040/60000 (38%)] Loss: -1303.471436\n",
      "Train Epoch: 570 [34304/60000 (57%)] Loss: -1402.396484\n",
      "Train Epoch: 570 [45568/60000 (76%)] Loss: -1172.248779\n",
      "Train Epoch: 570 [56832/60000 (95%)] Loss: -1194.976074\n",
      "    epoch          : 570\n",
      "    loss           : -1261.5461818889037\n",
      "Train Epoch: 571 [512/60000 (1%)] Loss: -1310.391113\n",
      "Train Epoch: 571 [11776/60000 (20%)] Loss: -1385.110352\n",
      "Train Epoch: 571 [23040/60000 (38%)] Loss: -1214.002686\n",
      "Train Epoch: 571 [34304/60000 (57%)] Loss: -1118.320068\n",
      "Train Epoch: 571 [45568/60000 (76%)] Loss: -1439.954956\n",
      "Train Epoch: 571 [56832/60000 (95%)] Loss: -1085.813110\n",
      "    epoch          : 571\n",
      "    loss           : -1279.7987150203037\n",
      "Train Epoch: 572 [512/60000 (1%)] Loss: -1069.083740\n",
      "Train Epoch: 572 [11776/60000 (20%)] Loss: -1178.252197\n",
      "Train Epoch: 572 [23040/60000 (38%)] Loss: -1251.724121\n",
      "Train Epoch: 572 [34304/60000 (57%)] Loss: -1303.510742\n",
      "Train Epoch: 572 [45568/60000 (76%)] Loss: -1114.926025\n",
      "Train Epoch: 572 [56832/60000 (95%)] Loss: -1244.839600\n",
      "    epoch          : 572\n",
      "    loss           : -1260.3893518825034\n",
      "Train Epoch: 573 [512/60000 (1%)] Loss: -1138.980347\n",
      "Train Epoch: 573 [11776/60000 (20%)] Loss: -1385.650879\n",
      "Train Epoch: 573 [23040/60000 (38%)] Loss: -1240.619263\n",
      "Train Epoch: 573 [34304/60000 (57%)] Loss: -1150.959961\n",
      "Train Epoch: 573 [45568/60000 (76%)] Loss: -1405.857788\n",
      "Train Epoch: 573 [56832/60000 (95%)] Loss: -1246.693604\n",
      "    epoch          : 573\n",
      "    loss           : -1289.6243046474995\n",
      "Train Epoch: 574 [512/60000 (1%)] Loss: -1103.596436\n",
      "Train Epoch: 574 [11776/60000 (20%)] Loss: -1271.969482\n",
      "Train Epoch: 574 [23040/60000 (38%)] Loss: -1218.966064\n",
      "Train Epoch: 574 [34304/60000 (57%)] Loss: -985.404846\n",
      "Train Epoch: 574 [45568/60000 (76%)] Loss: -1368.260376\n",
      "Train Epoch: 574 [56832/60000 (95%)] Loss: -1306.324097\n",
      "    epoch          : 574\n",
      "    loss           : -1276.1755548681917\n",
      "Train Epoch: 575 [512/60000 (1%)] Loss: -1443.762573\n",
      "Train Epoch: 575 [11776/60000 (20%)] Loss: -1239.856689\n",
      "Train Epoch: 575 [23040/60000 (38%)] Loss: -1394.137451\n",
      "Train Epoch: 575 [34304/60000 (57%)] Loss: -1431.661011\n",
      "Train Epoch: 575 [45568/60000 (76%)] Loss: -1246.816406\n",
      "Train Epoch: 575 [56832/60000 (95%)] Loss: -941.999268\n",
      "    epoch          : 575\n",
      "    loss           : -1270.2797179141287\n",
      "Train Epoch: 576 [512/60000 (1%)] Loss: -1249.290039\n",
      "Train Epoch: 576 [11776/60000 (20%)] Loss: -1168.864868\n",
      "Train Epoch: 576 [23040/60000 (38%)] Loss: -1046.830444\n",
      "Train Epoch: 576 [34304/60000 (57%)] Loss: -1146.275757\n",
      "Train Epoch: 576 [45568/60000 (76%)] Loss: -1125.179199\n",
      "Train Epoch: 576 [56832/60000 (95%)] Loss: -964.454346\n",
      "    epoch          : 576\n",
      "    loss           : -1281.6881360415011\n",
      "Train Epoch: 577 [512/60000 (1%)] Loss: -1154.240112\n",
      "Train Epoch: 577 [11776/60000 (20%)] Loss: -1442.798218\n",
      "Train Epoch: 577 [23040/60000 (38%)] Loss: -1439.573242\n",
      "Train Epoch: 577 [34304/60000 (57%)] Loss: -1136.354980\n",
      "Train Epoch: 577 [45568/60000 (76%)] Loss: -1276.894043\n",
      "Train Epoch: 577 [56832/60000 (95%)] Loss: -1334.370361\n",
      "    epoch          : 577\n",
      "    loss           : -1280.7180456818835\n",
      "Train Epoch: 578 [512/60000 (1%)] Loss: -1306.446167\n",
      "Train Epoch: 578 [11776/60000 (20%)] Loss: -1283.740723\n",
      "Train Epoch: 578 [23040/60000 (38%)] Loss: -1418.456787\n",
      "Train Epoch: 578 [34304/60000 (57%)] Loss: -1295.463745\n",
      "Train Epoch: 578 [45568/60000 (76%)] Loss: -1388.749878\n",
      "Train Epoch: 578 [56832/60000 (95%)] Loss: -1274.913086\n",
      "    epoch          : 578\n",
      "    loss           : -1287.776598224532\n",
      "Train Epoch: 579 [512/60000 (1%)] Loss: -1461.696045\n",
      "Train Epoch: 579 [11776/60000 (20%)] Loss: -1270.583618\n",
      "Train Epoch: 579 [23040/60000 (38%)] Loss: -1229.947998\n",
      "Train Epoch: 579 [34304/60000 (57%)] Loss: -1240.302856\n",
      "Train Epoch: 579 [45568/60000 (76%)] Loss: -1437.750000\n",
      "Train Epoch: 579 [56832/60000 (95%)] Loss: -1269.888916\n",
      "    epoch          : 579\n",
      "    loss           : -1299.1276288221113\n",
      "Train Epoch: 580 [512/60000 (1%)] Loss: -1273.821777\n",
      "Train Epoch: 580 [11776/60000 (20%)] Loss: -1271.302490\n",
      "Train Epoch: 580 [23040/60000 (38%)] Loss: -1417.894287\n",
      "Train Epoch: 580 [34304/60000 (57%)] Loss: -1440.438354\n",
      "Train Epoch: 580 [45568/60000 (76%)] Loss: -1284.467041\n",
      "Train Epoch: 580 [56832/60000 (95%)] Loss: -1416.635620\n",
      "    epoch          : 580\n",
      "    loss           : -1268.016843978968\n",
      "Train Epoch: 581 [512/60000 (1%)] Loss: -1237.180664\n",
      "Train Epoch: 581 [11776/60000 (20%)] Loss: -1039.037598\n",
      "Train Epoch: 581 [23040/60000 (38%)] Loss: -1262.091675\n",
      "Train Epoch: 581 [34304/60000 (57%)] Loss: -1388.323853\n",
      "Train Epoch: 581 [45568/60000 (76%)] Loss: -1466.533569\n",
      "Train Epoch: 581 [56832/60000 (95%)] Loss: -1415.545532\n",
      "    epoch          : 581\n",
      "    loss           : -1277.7885233561196\n",
      "Train Epoch: 582 [512/60000 (1%)] Loss: -1288.134766\n",
      "Train Epoch: 582 [11776/60000 (20%)] Loss: -1184.476440\n",
      "Train Epoch: 582 [23040/60000 (38%)] Loss: -997.628906\n",
      "Train Epoch: 582 [34304/60000 (57%)] Loss: -1420.465332\n",
      "Train Epoch: 582 [45568/60000 (76%)] Loss: -987.581665\n",
      "Train Epoch: 582 [56832/60000 (95%)] Loss: -1298.064087\n",
      "    epoch          : 582\n",
      "    loss           : -1265.7148678881972\n",
      "Train Epoch: 583 [512/60000 (1%)] Loss: -1302.681885\n",
      "Train Epoch: 583 [11776/60000 (20%)] Loss: -1282.545776\n",
      "Train Epoch: 583 [23040/60000 (38%)] Loss: -1122.531616\n",
      "Train Epoch: 583 [34304/60000 (57%)] Loss: -1258.240845\n",
      "Train Epoch: 583 [45568/60000 (76%)] Loss: -1164.095459\n",
      "Train Epoch: 583 [56832/60000 (95%)] Loss: -1126.846313\n",
      "    epoch          : 583\n",
      "    loss           : -1271.5721054508188\n",
      "Train Epoch: 584 [512/60000 (1%)] Loss: -1430.916138\n",
      "Train Epoch: 584 [11776/60000 (20%)] Loss: -1408.208130\n",
      "Train Epoch: 584 [23040/60000 (38%)] Loss: -1233.135132\n",
      "Train Epoch: 584 [34304/60000 (57%)] Loss: -1002.143860\n",
      "Train Epoch: 584 [45568/60000 (76%)] Loss: -1380.181885\n",
      "Train Epoch: 584 [56832/60000 (95%)] Loss: -1204.674683\n",
      "    epoch          : 584\n",
      "    loss           : -1292.1469045520503\n",
      "Train Epoch: 585 [512/60000 (1%)] Loss: -1206.715820\n",
      "Train Epoch: 585 [11776/60000 (20%)] Loss: -1282.019043\n",
      "Train Epoch: 585 [23040/60000 (38%)] Loss: -1170.690552\n",
      "Train Epoch: 585 [34304/60000 (57%)] Loss: -1232.972656\n",
      "Train Epoch: 585 [45568/60000 (76%)] Loss: -1453.017456\n",
      "Train Epoch: 585 [56832/60000 (95%)] Loss: -1119.883301\n",
      "    epoch          : 585\n",
      "    loss           : -1251.177715064442\n",
      "Train Epoch: 586 [512/60000 (1%)] Loss: -1415.413330\n",
      "Train Epoch: 586 [11776/60000 (20%)] Loss: -1384.931885\n",
      "Train Epoch: 586 [23040/60000 (38%)] Loss: -1258.413940\n",
      "Train Epoch: 586 [34304/60000 (57%)] Loss: -1448.153564\n",
      "Train Epoch: 586 [45568/60000 (76%)] Loss: -1271.618408\n",
      "Train Epoch: 586 [56832/60000 (95%)] Loss: -1255.997803\n",
      "    epoch          : 586\n",
      "    loss           : -1282.4679777500994\n",
      "Train Epoch: 587 [512/60000 (1%)] Loss: -1441.798096\n",
      "Train Epoch: 587 [11776/60000 (20%)] Loss: -1472.710693\n",
      "Train Epoch: 587 [23040/60000 (38%)] Loss: -1298.520264\n",
      "Train Epoch: 587 [34304/60000 (57%)] Loss: -1160.670532\n",
      "Train Epoch: 587 [45568/60000 (76%)] Loss: -1170.277100\n",
      "Train Epoch: 587 [56832/60000 (95%)] Loss: -1421.219727\n",
      "    epoch          : 587\n",
      "    loss           : -1281.217321363546\n",
      "Train Epoch: 588 [512/60000 (1%)] Loss: -988.281494\n",
      "Train Epoch: 588 [11776/60000 (20%)] Loss: -1409.381348\n",
      "Train Epoch: 588 [23040/60000 (38%)] Loss: -1259.979248\n",
      "Train Epoch: 588 [34304/60000 (57%)] Loss: -1247.778809\n",
      "Train Epoch: 588 [45568/60000 (76%)] Loss: -1384.325562\n",
      "Train Epoch: 588 [56832/60000 (95%)] Loss: -1418.512207\n",
      "    epoch          : 588\n",
      "    loss           : -1272.1933923063978\n",
      "Train Epoch: 589 [512/60000 (1%)] Loss: -1232.199097\n",
      "Train Epoch: 589 [11776/60000 (20%)] Loss: -1454.858643\n",
      "Train Epoch: 589 [23040/60000 (38%)] Loss: -1398.091309\n",
      "Train Epoch: 589 [34304/60000 (57%)] Loss: -1176.782104\n",
      "Train Epoch: 589 [45568/60000 (76%)] Loss: -1295.791992\n",
      "Train Epoch: 589 [56832/60000 (95%)] Loss: -977.192627\n",
      "    epoch          : 589\n",
      "    loss           : -1273.4253969354145\n",
      "Train Epoch: 590 [512/60000 (1%)] Loss: -1437.177856\n",
      "Train Epoch: 590 [11776/60000 (20%)] Loss: -1133.168335\n",
      "Train Epoch: 590 [23040/60000 (38%)] Loss: -1410.113037\n",
      "Train Epoch: 590 [34304/60000 (57%)] Loss: -1302.941650\n",
      "Train Epoch: 590 [45568/60000 (76%)] Loss: -1305.964111\n",
      "Train Epoch: 590 [56832/60000 (95%)] Loss: -1126.623291\n",
      "    epoch          : 590\n",
      "    loss           : -1286.3467503779352\n",
      "Train Epoch: 591 [512/60000 (1%)] Loss: -1426.691650\n",
      "Train Epoch: 591 [11776/60000 (20%)] Loss: -1230.868286\n",
      "Train Epoch: 591 [23040/60000 (38%)] Loss: -1426.676514\n",
      "Train Epoch: 591 [34304/60000 (57%)] Loss: -1340.657715\n",
      "Train Epoch: 591 [45568/60000 (76%)] Loss: -1280.881714\n",
      "Train Epoch: 591 [56832/60000 (95%)] Loss: -1281.380859\n",
      "    epoch          : 591\n",
      "    loss           : -1274.556704591223\n",
      "Train Epoch: 592 [512/60000 (1%)] Loss: -1126.595215\n",
      "Train Epoch: 592 [11776/60000 (20%)] Loss: -1089.431396\n",
      "Train Epoch: 592 [23040/60000 (38%)] Loss: -1357.258301\n",
      "Train Epoch: 592 [34304/60000 (57%)] Loss: -1467.192139\n",
      "Train Epoch: 592 [45568/60000 (76%)] Loss: -1097.997803\n",
      "Train Epoch: 592 [56832/60000 (95%)] Loss: -1296.086182\n",
      "    epoch          : 592\n",
      "    loss           : -1281.6966076867054\n",
      "Train Epoch: 593 [512/60000 (1%)] Loss: -1391.079834\n",
      "Train Epoch: 593 [11776/60000 (20%)] Loss: -1406.629761\n",
      "Train Epoch: 593 [23040/60000 (38%)] Loss: -1235.248657\n",
      "Train Epoch: 593 [34304/60000 (57%)] Loss: -1447.905029\n",
      "Train Epoch: 593 [45568/60000 (76%)] Loss: -1281.133301\n",
      "Train Epoch: 593 [56832/60000 (95%)] Loss: -1256.942383\n",
      "    epoch          : 593\n",
      "    loss           : -1282.9983291194937\n",
      "Train Epoch: 594 [512/60000 (1%)] Loss: -1301.406738\n",
      "Train Epoch: 594 [11776/60000 (20%)] Loss: -1271.595581\n",
      "Train Epoch: 594 [23040/60000 (38%)] Loss: -1314.847168\n",
      "Train Epoch: 594 [34304/60000 (57%)] Loss: -1330.737427\n",
      "Train Epoch: 594 [45568/60000 (76%)] Loss: -1137.684082\n",
      "Train Epoch: 594 [56832/60000 (95%)] Loss: -1096.116455\n",
      "    epoch          : 594\n",
      "    loss           : -1277.2438556218551\n",
      "Train Epoch: 595 [512/60000 (1%)] Loss: -1232.544434\n",
      "Train Epoch: 595 [11776/60000 (20%)] Loss: -1314.292969\n",
      "Train Epoch: 595 [23040/60000 (38%)] Loss: -1306.720337\n",
      "Train Epoch: 595 [34304/60000 (57%)] Loss: -1410.808838\n",
      "Train Epoch: 595 [45568/60000 (76%)] Loss: -1330.055176\n",
      "Train Epoch: 595 [56832/60000 (95%)] Loss: -1221.560303\n",
      "    epoch          : 595\n",
      "    loss           : -1299.5107985674324\n",
      "Train Epoch: 596 [512/60000 (1%)] Loss: -1302.870605\n",
      "Train Epoch: 596 [11776/60000 (20%)] Loss: -1282.751343\n",
      "Train Epoch: 596 [23040/60000 (38%)] Loss: -1380.901001\n",
      "Train Epoch: 596 [34304/60000 (57%)] Loss: -1257.017944\n",
      "Train Epoch: 596 [45568/60000 (76%)] Loss: -1441.910278\n",
      "Train Epoch: 596 [56832/60000 (95%)] Loss: -1280.595337\n",
      "    epoch          : 596\n",
      "    loss           : -1278.4192315225548\n",
      "Train Epoch: 597 [512/60000 (1%)] Loss: -1400.127197\n",
      "Train Epoch: 597 [11776/60000 (20%)] Loss: -1282.398438\n",
      "Train Epoch: 597 [23040/60000 (38%)] Loss: -1390.285889\n",
      "Train Epoch: 597 [34304/60000 (57%)] Loss: -1438.812744\n",
      "Train Epoch: 597 [45568/60000 (76%)] Loss: -1441.631470\n",
      "Train Epoch: 597 [56832/60000 (95%)] Loss: -1472.622803\n",
      "    epoch          : 597\n",
      "    loss           : -1280.2002346232787\n",
      "Train Epoch: 598 [512/60000 (1%)] Loss: -1136.377563\n",
      "Train Epoch: 598 [11776/60000 (20%)] Loss: -1440.786743\n",
      "Train Epoch: 598 [23040/60000 (38%)] Loss: -1274.719727\n",
      "Train Epoch: 598 [34304/60000 (57%)] Loss: -1393.026001\n",
      "Train Epoch: 598 [45568/60000 (76%)] Loss: -1432.775513\n",
      "Train Epoch: 598 [56832/60000 (95%)] Loss: -1100.350586\n",
      "    epoch          : 598\n",
      "    loss           : -1295.5635589772025\n",
      "Train Epoch: 599 [512/60000 (1%)] Loss: -1118.403809\n",
      "Train Epoch: 599 [11776/60000 (20%)] Loss: -1314.415039\n",
      "Train Epoch: 599 [23040/60000 (38%)] Loss: -1327.103760\n",
      "Train Epoch: 599 [34304/60000 (57%)] Loss: -1415.437012\n",
      "Train Epoch: 599 [45568/60000 (76%)] Loss: -1132.829102\n",
      "Train Epoch: 599 [56832/60000 (95%)] Loss: -1312.200439\n",
      "    epoch          : 599\n",
      "    loss           : -1302.267907266563\n",
      "Train Epoch: 600 [512/60000 (1%)] Loss: -1126.723389\n",
      "Train Epoch: 600 [11776/60000 (20%)] Loss: -1108.699951\n",
      "Train Epoch: 600 [23040/60000 (38%)] Loss: -1416.860962\n",
      "Train Epoch: 600 [34304/60000 (57%)] Loss: -1149.397095\n",
      "Train Epoch: 600 [45568/60000 (76%)] Loss: -1026.920410\n",
      "Train Epoch: 600 [56832/60000 (95%)] Loss: -996.731445\n",
      "    epoch          : 600\n",
      "    loss           : -1257.7990517481574\n",
      "Saving checkpoint: saved/models/Mnist_DeepGenerativeOperad/0127_111843/checkpoint-epoch600.pth ...\n",
      "Train Epoch: 601 [512/60000 (1%)] Loss: -1280.716919\n",
      "Train Epoch: 601 [11776/60000 (20%)] Loss: -1139.788940\n",
      "Train Epoch: 601 [23040/60000 (38%)] Loss: -1174.215332\n",
      "Train Epoch: 601 [34304/60000 (57%)] Loss: -1240.956543\n",
      "Train Epoch: 601 [45568/60000 (76%)] Loss: -1411.309570\n",
      "Train Epoch: 601 [56832/60000 (95%)] Loss: -1271.905029\n",
      "    epoch          : 601\n",
      "    loss           : -1280.8422718802415\n",
      "Train Epoch: 602 [512/60000 (1%)] Loss: -1292.162476\n",
      "Train Epoch: 602 [11776/60000 (20%)] Loss: -1305.949463\n",
      "Train Epoch: 602 [23040/60000 (38%)] Loss: -1422.682129\n",
      "Train Epoch: 602 [34304/60000 (57%)] Loss: -1268.997314\n",
      "Train Epoch: 602 [45568/60000 (76%)] Loss: -1249.428833\n",
      "Train Epoch: 602 [56832/60000 (95%)] Loss: -1292.699463\n",
      "    epoch          : 602\n",
      "    loss           : -1273.0093164821128\n",
      "Train Epoch: 603 [512/60000 (1%)] Loss: -1410.650879\n",
      "Train Epoch: 603 [11776/60000 (20%)] Loss: -1226.736572\n",
      "Train Epoch: 603 [23040/60000 (38%)] Loss: -1438.394287\n",
      "Train Epoch: 603 [34304/60000 (57%)] Loss: -1144.363403\n",
      "Train Epoch: 603 [45568/60000 (76%)] Loss: -1420.569824\n",
      "Train Epoch: 603 [56832/60000 (95%)] Loss: -1115.169800\n",
      "    epoch          : 603\n",
      "    loss           : -1283.4224496615136\n",
      "Train Epoch: 604 [512/60000 (1%)] Loss: -1054.470825\n",
      "Train Epoch: 604 [11776/60000 (20%)] Loss: -1302.647461\n",
      "Train Epoch: 604 [23040/60000 (38%)] Loss: -1098.655762\n",
      "Train Epoch: 604 [34304/60000 (57%)] Loss: -1143.622559\n",
      "Train Epoch: 604 [45568/60000 (76%)] Loss: -1287.378662\n",
      "Train Epoch: 604 [56832/60000 (95%)] Loss: -1221.215820\n",
      "    epoch          : 604\n",
      "    loss           : -1273.6214706507105\n",
      "Train Epoch: 605 [512/60000 (1%)] Loss: -1389.402466\n",
      "Train Epoch: 605 [11776/60000 (20%)] Loss: -1168.259155\n",
      "Train Epoch: 605 [23040/60000 (38%)] Loss: -1265.910645\n",
      "Train Epoch: 605 [34304/60000 (57%)] Loss: -974.485901\n",
      "Train Epoch: 605 [45568/60000 (76%)] Loss: -1408.644409\n",
      "Train Epoch: 605 [56832/60000 (95%)] Loss: -1161.987061\n",
      "    epoch          : 605\n",
      "    loss           : -1283.9217786196261\n",
      "Train Epoch: 606 [512/60000 (1%)] Loss: -1131.469116\n",
      "Train Epoch: 606 [11776/60000 (20%)] Loss: -1146.238281\n",
      "Train Epoch: 606 [23040/60000 (38%)] Loss: -1230.568604\n",
      "Train Epoch: 606 [34304/60000 (57%)] Loss: -1265.461182\n",
      "Train Epoch: 606 [45568/60000 (76%)] Loss: -1172.679443\n",
      "Train Epoch: 606 [56832/60000 (95%)] Loss: -1450.915283\n",
      "    epoch          : 606\n",
      "    loss           : -1280.947636663577\n",
      "Train Epoch: 607 [512/60000 (1%)] Loss: -1192.047119\n",
      "Train Epoch: 607 [11776/60000 (20%)] Loss: -1252.473511\n",
      "Train Epoch: 607 [23040/60000 (38%)] Loss: -1256.795898\n",
      "Train Epoch: 607 [34304/60000 (57%)] Loss: -1202.603516\n",
      "Train Epoch: 607 [45568/60000 (76%)] Loss: -1206.733887\n",
      "Train Epoch: 607 [56832/60000 (95%)] Loss: -1277.190430\n",
      "    epoch          : 607\n",
      "    loss           : -1284.4193063509667\n",
      "Train Epoch: 608 [512/60000 (1%)] Loss: -966.477844\n",
      "Train Epoch: 608 [11776/60000 (20%)] Loss: -1270.910400\n",
      "Train Epoch: 608 [23040/60000 (38%)] Loss: -1410.311768\n",
      "Train Epoch: 608 [34304/60000 (57%)] Loss: -1426.239746\n",
      "Train Epoch: 608 [45568/60000 (76%)] Loss: -1423.910156\n",
      "Train Epoch: 608 [56832/60000 (95%)] Loss: -1407.882935\n",
      "    epoch          : 608\n",
      "    loss           : -1270.114744369593\n",
      "Train Epoch: 609 [512/60000 (1%)] Loss: -1138.598877\n",
      "Train Epoch: 609 [11776/60000 (20%)] Loss: -1375.931396\n",
      "Train Epoch: 609 [23040/60000 (38%)] Loss: -1438.972168\n",
      "Train Epoch: 609 [34304/60000 (57%)] Loss: -1418.723877\n",
      "Train Epoch: 609 [45568/60000 (76%)] Loss: -1230.908447\n",
      "Train Epoch: 609 [56832/60000 (95%)] Loss: -1374.213623\n",
      "    epoch          : 609\n",
      "    loss           : -1262.9060425839182\n",
      "Train Epoch: 610 [512/60000 (1%)] Loss: -1421.572754\n",
      "Train Epoch: 610 [11776/60000 (20%)] Loss: -1408.555908\n",
      "Train Epoch: 610 [23040/60000 (38%)] Loss: -1112.479370\n",
      "Train Epoch: 610 [34304/60000 (57%)] Loss: -1272.635498\n",
      "Train Epoch: 610 [45568/60000 (76%)] Loss: -1317.117676\n",
      "Train Epoch: 610 [56832/60000 (95%)] Loss: -1398.695679\n",
      "    epoch          : 610\n",
      "    loss           : -1289.211507851121\n",
      "Train Epoch: 611 [512/60000 (1%)] Loss: -1303.568359\n",
      "Train Epoch: 611 [11776/60000 (20%)] Loss: -1313.738525\n",
      "Train Epoch: 611 [23040/60000 (38%)] Loss: -1319.562012\n",
      "Train Epoch: 611 [34304/60000 (57%)] Loss: -1146.253296\n",
      "Train Epoch: 611 [45568/60000 (76%)] Loss: -1419.719727\n",
      "Train Epoch: 611 [56832/60000 (95%)] Loss: -1440.933838\n",
      "    epoch          : 611\n",
      "    loss           : -1295.4554441635216\n",
      "Train Epoch: 612 [512/60000 (1%)] Loss: -1177.168701\n",
      "Train Epoch: 612 [11776/60000 (20%)] Loss: -1318.553223\n",
      "Train Epoch: 612 [23040/60000 (38%)] Loss: -1279.214355\n",
      "Train Epoch: 612 [34304/60000 (57%)] Loss: -1323.937378\n",
      "Train Epoch: 612 [45568/60000 (76%)] Loss: -1148.774170\n",
      "Train Epoch: 612 [56832/60000 (95%)] Loss: -1115.832031\n",
      "    epoch          : 612\n",
      "    loss           : -1271.3247530662406\n",
      "Train Epoch: 613 [512/60000 (1%)] Loss: -1446.988525\n",
      "Train Epoch: 613 [11776/60000 (20%)] Loss: -1146.113525\n",
      "Train Epoch: 613 [23040/60000 (38%)] Loss: -1086.367554\n",
      "Train Epoch: 613 [34304/60000 (57%)] Loss: -1316.491455\n",
      "Train Epoch: 613 [45568/60000 (76%)] Loss: -1437.616211\n",
      "Train Epoch: 613 [56832/60000 (95%)] Loss: -1174.619141\n",
      "    epoch          : 613\n",
      "    loss           : -1282.8621846861759\n",
      "Train Epoch: 614 [512/60000 (1%)] Loss: -1273.660889\n",
      "Train Epoch: 614 [11776/60000 (20%)] Loss: -1327.388916\n",
      "Train Epoch: 614 [23040/60000 (38%)] Loss: -1291.555908\n",
      "Train Epoch: 614 [34304/60000 (57%)] Loss: -1239.398682\n",
      "Train Epoch: 614 [45568/60000 (76%)] Loss: -1441.383301\n",
      "Train Epoch: 614 [56832/60000 (95%)] Loss: -985.599487\n",
      "    epoch          : 614\n",
      "    loss           : -1287.2733337057514\n",
      "Train Epoch: 615 [512/60000 (1%)] Loss: -1350.668213\n",
      "Train Epoch: 615 [11776/60000 (20%)] Loss: -1471.297119\n",
      "Train Epoch: 615 [23040/60000 (38%)] Loss: -1252.253418\n",
      "Train Epoch: 615 [34304/60000 (57%)] Loss: -1358.858765\n",
      "Train Epoch: 615 [45568/60000 (76%)] Loss: -1060.395996\n",
      "Train Epoch: 615 [56832/60000 (95%)] Loss: -1310.396973\n",
      "    epoch          : 615\n",
      "    loss           : -1294.781190516585\n",
      "Train Epoch: 616 [512/60000 (1%)] Loss: -1300.565796\n",
      "Train Epoch: 616 [11776/60000 (20%)] Loss: -1283.472534\n",
      "Train Epoch: 616 [23040/60000 (38%)] Loss: -1257.087158\n",
      "Train Epoch: 616 [34304/60000 (57%)] Loss: -1278.926025\n",
      "Train Epoch: 616 [45568/60000 (76%)] Loss: -1298.083740\n",
      "Train Epoch: 616 [56832/60000 (95%)] Loss: -1449.326904\n",
      "    epoch          : 616\n",
      "    loss           : -1286.1535723842471\n",
      "Train Epoch: 617 [512/60000 (1%)] Loss: -1411.541870\n",
      "Train Epoch: 617 [11776/60000 (20%)] Loss: -1115.751953\n",
      "Train Epoch: 617 [23040/60000 (38%)] Loss: -1424.615356\n",
      "Train Epoch: 617 [34304/60000 (57%)] Loss: -1414.334717\n",
      "Train Epoch: 617 [45568/60000 (76%)] Loss: -1109.797852\n",
      "Train Epoch: 617 [56832/60000 (95%)] Loss: -985.226318\n",
      "    epoch          : 617\n",
      "    loss           : -1289.0429656465176\n",
      "Train Epoch: 618 [512/60000 (1%)] Loss: -1271.455811\n",
      "Train Epoch: 618 [11776/60000 (20%)] Loss: -1251.427368\n",
      "Train Epoch: 618 [23040/60000 (38%)] Loss: -1307.112915\n",
      "Train Epoch: 618 [34304/60000 (57%)] Loss: -1384.001587\n",
      "Train Epoch: 618 [45568/60000 (76%)] Loss: -1427.459106\n",
      "Train Epoch: 618 [56832/60000 (95%)] Loss: -1422.766724\n",
      "    epoch          : 618\n",
      "    loss           : -1278.7388072902872\n",
      "Train Epoch: 619 [512/60000 (1%)] Loss: -1157.429199\n",
      "Train Epoch: 619 [11776/60000 (20%)] Loss: -1037.567993\n",
      "Train Epoch: 619 [23040/60000 (38%)] Loss: -1318.805664\n",
      "Train Epoch: 619 [34304/60000 (57%)] Loss: -1274.948730\n",
      "Train Epoch: 619 [45568/60000 (76%)] Loss: -1175.720947\n",
      "Train Epoch: 619 [56832/60000 (95%)] Loss: -1162.667847\n",
      "    epoch          : 619\n",
      "    loss           : -1271.2413830083642\n",
      "Train Epoch: 620 [512/60000 (1%)] Loss: -1285.439941\n",
      "Train Epoch: 620 [11776/60000 (20%)] Loss: -1134.673340\n",
      "Train Epoch: 620 [23040/60000 (38%)] Loss: -1253.140625\n",
      "Train Epoch: 620 [34304/60000 (57%)] Loss: -1285.592651\n",
      "Train Epoch: 620 [45568/60000 (76%)] Loss: -1233.628906\n",
      "Train Epoch: 620 [56832/60000 (95%)] Loss: -996.068359\n",
      "    epoch          : 620\n",
      "    loss           : -1275.3044724976276\n",
      "Train Epoch: 621 [512/60000 (1%)] Loss: -1266.020020\n",
      "Train Epoch: 621 [11776/60000 (20%)] Loss: -1370.924561\n",
      "Train Epoch: 621 [23040/60000 (38%)] Loss: -1359.487671\n",
      "Train Epoch: 621 [34304/60000 (57%)] Loss: -1398.734375\n",
      "Train Epoch: 621 [45568/60000 (76%)] Loss: -1276.926636\n",
      "Train Epoch: 621 [56832/60000 (95%)] Loss: -1347.265137\n",
      "    epoch          : 621\n",
      "    loss           : -1292.5490772656801\n",
      "Train Epoch: 622 [512/60000 (1%)] Loss: -1005.889343\n",
      "Train Epoch: 622 [11776/60000 (20%)] Loss: -1124.718506\n",
      "Train Epoch: 622 [23040/60000 (38%)] Loss: -1421.621826\n",
      "Train Epoch: 622 [34304/60000 (57%)] Loss: -1026.026733\n",
      "Train Epoch: 622 [45568/60000 (76%)] Loss: -1487.440552\n",
      "Train Epoch: 622 [56832/60000 (95%)] Loss: -1428.338989\n",
      "    epoch          : 622\n",
      "    loss           : -1277.8904875846906\n",
      "Train Epoch: 623 [512/60000 (1%)] Loss: -1315.036865\n",
      "Train Epoch: 623 [11776/60000 (20%)] Loss: -1408.420410\n",
      "Train Epoch: 623 [23040/60000 (38%)] Loss: -1412.577393\n",
      "Train Epoch: 623 [34304/60000 (57%)] Loss: -1440.313599\n",
      "Train Epoch: 623 [45568/60000 (76%)] Loss: -1421.165771\n",
      "Train Epoch: 623 [56832/60000 (95%)] Loss: -1318.416016\n",
      "    epoch          : 623\n",
      "    loss           : -1306.49284681762\n",
      "Train Epoch: 624 [512/60000 (1%)] Loss: -1222.199219\n",
      "Train Epoch: 624 [11776/60000 (20%)] Loss: -1384.906982\n",
      "Train Epoch: 624 [23040/60000 (38%)] Loss: -1404.368042\n",
      "Train Epoch: 624 [34304/60000 (57%)] Loss: -1208.482544\n",
      "Train Epoch: 624 [45568/60000 (76%)] Loss: -1278.379639\n",
      "Train Epoch: 624 [56832/60000 (95%)] Loss: -1360.667969\n",
      "    epoch          : 624\n",
      "    loss           : -1266.5772511972546\n",
      "Train Epoch: 625 [512/60000 (1%)] Loss: -1272.811157\n",
      "Train Epoch: 625 [11776/60000 (20%)] Loss: -1460.526611\n",
      "Train Epoch: 625 [23040/60000 (38%)] Loss: -1243.072998\n",
      "Train Epoch: 625 [34304/60000 (57%)] Loss: -1083.731934\n",
      "Train Epoch: 625 [45568/60000 (76%)] Loss: -1108.225342\n",
      "Train Epoch: 625 [56832/60000 (95%)] Loss: -1409.818115\n",
      "    epoch          : 625\n",
      "    loss           : -1284.1885058731682\n",
      "Train Epoch: 626 [512/60000 (1%)] Loss: -1304.721069\n",
      "Train Epoch: 626 [11776/60000 (20%)] Loss: -1412.766602\n",
      "Train Epoch: 626 [23040/60000 (38%)] Loss: -1303.437988\n",
      "Train Epoch: 626 [34304/60000 (57%)] Loss: -1244.965088\n",
      "Train Epoch: 626 [45568/60000 (76%)] Loss: -1144.562744\n",
      "Train Epoch: 626 [56832/60000 (95%)] Loss: -1369.492432\n",
      "    epoch          : 626\n",
      "    loss           : -1279.8285648324397\n",
      "Train Epoch: 627 [512/60000 (1%)] Loss: -1367.920898\n",
      "Train Epoch: 627 [11776/60000 (20%)] Loss: -1324.640381\n",
      "Train Epoch: 627 [23040/60000 (38%)] Loss: -1467.428833\n",
      "Train Epoch: 627 [34304/60000 (57%)] Loss: -1258.498779\n",
      "Train Epoch: 627 [45568/60000 (76%)] Loss: -1311.936279\n",
      "Train Epoch: 627 [56832/60000 (95%)] Loss: -1454.218140\n",
      "    epoch          : 627\n",
      "    loss           : -1295.7976888020835\n",
      "Train Epoch: 628 [512/60000 (1%)] Loss: -1215.126831\n",
      "Train Epoch: 628 [11776/60000 (20%)] Loss: -1322.989258\n",
      "Train Epoch: 628 [23040/60000 (38%)] Loss: -1002.076538\n",
      "Train Epoch: 628 [34304/60000 (57%)] Loss: -1216.980469\n",
      "Train Epoch: 628 [45568/60000 (76%)] Loss: -1396.785400\n",
      "Train Epoch: 628 [56832/60000 (95%)] Loss: -1263.669800\n",
      "    epoch          : 628\n",
      "    loss           : -1271.6102979412187\n",
      "Train Epoch: 629 [512/60000 (1%)] Loss: -1286.151123\n",
      "Train Epoch: 629 [11776/60000 (20%)] Loss: -1424.164062\n",
      "Train Epoch: 629 [23040/60000 (38%)] Loss: -926.663208\n",
      "Train Epoch: 629 [34304/60000 (57%)] Loss: -1423.725464\n",
      "Train Epoch: 629 [45568/60000 (76%)] Loss: -1052.314087\n",
      "Train Epoch: 629 [56832/60000 (95%)] Loss: -1267.515625\n",
      "    epoch          : 629\n",
      "    loss           : -1268.8970352431475\n",
      "Train Epoch: 630 [512/60000 (1%)] Loss: -1391.883301\n",
      "Train Epoch: 630 [11776/60000 (20%)] Loss: -1180.222656\n",
      "Train Epoch: 630 [23040/60000 (38%)] Loss: -1391.600708\n",
      "Train Epoch: 630 [34304/60000 (57%)] Loss: -1255.994019\n",
      "Train Epoch: 630 [45568/60000 (76%)] Loss: -1221.475952\n",
      "Train Epoch: 630 [56832/60000 (95%)] Loss: -1297.391357\n",
      "    epoch          : 630\n",
      "    loss           : -1318.5867561297227\n",
      "Train Epoch: 631 [512/60000 (1%)] Loss: -1034.813354\n",
      "Train Epoch: 631 [11776/60000 (20%)] Loss: -1389.098633\n",
      "Train Epoch: 631 [23040/60000 (38%)] Loss: -1111.582886\n",
      "Train Epoch: 631 [34304/60000 (57%)] Loss: -1403.355957\n",
      "Train Epoch: 631 [45568/60000 (76%)] Loss: -1047.355713\n",
      "Train Epoch: 631 [56832/60000 (95%)] Loss: -1249.476562\n",
      "    epoch          : 631\n",
      "    loss           : -1283.846473478328\n",
      "Train Epoch: 632 [512/60000 (1%)] Loss: -1415.553467\n",
      "Train Epoch: 632 [11776/60000 (20%)] Loss: -1397.907837\n",
      "Train Epoch: 632 [23040/60000 (38%)] Loss: -1239.362061\n",
      "Train Epoch: 632 [34304/60000 (57%)] Loss: -982.827209\n",
      "Train Epoch: 632 [45568/60000 (76%)] Loss: -1232.837769\n",
      "Train Epoch: 632 [56832/60000 (95%)] Loss: -1286.756104\n",
      "    epoch          : 632\n",
      "    loss           : -1301.0767161913511\n",
      "Train Epoch: 633 [512/60000 (1%)] Loss: -1393.260986\n",
      "Train Epoch: 633 [11776/60000 (20%)] Loss: -1440.323486\n",
      "Train Epoch: 633 [23040/60000 (38%)] Loss: -1291.732300\n",
      "Train Epoch: 633 [34304/60000 (57%)] Loss: -1403.577881\n",
      "Train Epoch: 633 [45568/60000 (76%)] Loss: -1321.439209\n",
      "Train Epoch: 633 [56832/60000 (95%)] Loss: -1403.434448\n",
      "    epoch          : 633\n",
      "    loss           : -1270.971540375618\n",
      "Train Epoch: 634 [512/60000 (1%)] Loss: -1275.154419\n",
      "Train Epoch: 634 [11776/60000 (20%)] Loss: -1169.272827\n",
      "Train Epoch: 634 [23040/60000 (38%)] Loss: -1089.018555\n",
      "Train Epoch: 634 [34304/60000 (57%)] Loss: -1283.409424\n",
      "Train Epoch: 634 [45568/60000 (76%)] Loss: -1336.739502\n",
      "Train Epoch: 634 [56832/60000 (95%)] Loss: -1430.729736\n",
      "    epoch          : 634\n",
      "    loss           : -1287.5198471155543\n",
      "Train Epoch: 635 [512/60000 (1%)] Loss: -1227.677490\n",
      "Train Epoch: 635 [11776/60000 (20%)] Loss: -1218.948853\n",
      "Train Epoch: 635 [23040/60000 (38%)] Loss: -1328.001465\n",
      "Train Epoch: 635 [34304/60000 (57%)] Loss: -1142.346436\n",
      "Train Epoch: 635 [45568/60000 (76%)] Loss: -1263.049927\n",
      "Train Epoch: 635 [56832/60000 (95%)] Loss: -1287.237183\n",
      "    epoch          : 635\n",
      "    loss           : -1295.1057523738193\n",
      "Train Epoch: 636 [512/60000 (1%)] Loss: -1160.854370\n",
      "Train Epoch: 636 [11776/60000 (20%)] Loss: -1400.432739\n",
      "Train Epoch: 636 [23040/60000 (38%)] Loss: -1408.120972\n",
      "Train Epoch: 636 [34304/60000 (57%)] Loss: -1264.326172\n",
      "Train Epoch: 636 [45568/60000 (76%)] Loss: -1090.541504\n",
      "Train Epoch: 636 [56832/60000 (95%)] Loss: -1366.125000\n",
      "    epoch          : 636\n",
      "    loss           : -1281.779683086158\n",
      "Train Epoch: 637 [512/60000 (1%)] Loss: -1474.849854\n",
      "Train Epoch: 637 [11776/60000 (20%)] Loss: -1135.842163\n",
      "Train Epoch: 637 [23040/60000 (38%)] Loss: -1295.104736\n",
      "Train Epoch: 637 [34304/60000 (57%)] Loss: -805.714233\n",
      "Train Epoch: 637 [45568/60000 (76%)] Loss: -1269.838135\n",
      "Train Epoch: 637 [56832/60000 (95%)] Loss: -1436.695557\n",
      "    epoch          : 637\n",
      "    loss           : -1289.982623601364\n",
      "Train Epoch: 638 [512/60000 (1%)] Loss: -1440.145020\n",
      "Train Epoch: 638 [11776/60000 (20%)] Loss: -1177.961792\n",
      "Train Epoch: 638 [23040/60000 (38%)] Loss: -1247.535400\n",
      "Train Epoch: 638 [34304/60000 (57%)] Loss: -1277.013916\n",
      "Train Epoch: 638 [45568/60000 (76%)] Loss: -1415.947021\n",
      "Train Epoch: 638 [56832/60000 (95%)] Loss: -1138.017334\n",
      "    epoch          : 638\n",
      "    loss           : -1295.260474253509\n",
      "Train Epoch: 639 [512/60000 (1%)] Loss: -1156.143188\n",
      "Train Epoch: 639 [11776/60000 (20%)] Loss: -1369.538574\n",
      "Train Epoch: 639 [23040/60000 (38%)] Loss: -1328.074951\n",
      "Train Epoch: 639 [34304/60000 (57%)] Loss: -1339.172852\n",
      "Train Epoch: 639 [45568/60000 (76%)] Loss: -1080.053711\n",
      "Train Epoch: 639 [56832/60000 (95%)] Loss: -1153.078125\n",
      "    epoch          : 639\n",
      "    loss           : -1287.7916073556673\n",
      "Train Epoch: 640 [512/60000 (1%)] Loss: -1372.888184\n",
      "Train Epoch: 640 [11776/60000 (20%)] Loss: -1170.084961\n",
      "Train Epoch: 640 [23040/60000 (38%)] Loss: -1344.723877\n",
      "Train Epoch: 640 [34304/60000 (57%)] Loss: -1373.770264\n",
      "Train Epoch: 640 [45568/60000 (76%)] Loss: -1238.192627\n",
      "Train Epoch: 640 [56832/60000 (95%)] Loss: -1285.394775\n",
      "    epoch          : 640\n",
      "    loss           : -1284.9848619019244\n",
      "Train Epoch: 641 [512/60000 (1%)] Loss: -1066.785034\n",
      "Train Epoch: 641 [11776/60000 (20%)] Loss: -1105.032227\n",
      "Train Epoch: 641 [23040/60000 (38%)] Loss: -1409.941895\n",
      "Train Epoch: 641 [34304/60000 (57%)] Loss: -1246.245850\n",
      "Train Epoch: 641 [45568/60000 (76%)] Loss: -1299.909912\n",
      "Train Epoch: 641 [56832/60000 (95%)] Loss: -1148.011963\n",
      "    epoch          : 641\n",
      "    loss           : -1287.7669739804026\n",
      "Train Epoch: 642 [512/60000 (1%)] Loss: -1247.202515\n",
      "Train Epoch: 642 [11776/60000 (20%)] Loss: -1256.356934\n",
      "Train Epoch: 642 [23040/60000 (38%)] Loss: -1121.233643\n",
      "Train Epoch: 642 [34304/60000 (57%)] Loss: -1458.759155\n",
      "Train Epoch: 642 [45568/60000 (76%)] Loss: -1166.609863\n",
      "Train Epoch: 642 [56832/60000 (95%)] Loss: -1435.861206\n",
      "    epoch          : 642\n",
      "    loss           : -1273.4265922934321\n",
      "Train Epoch: 643 [512/60000 (1%)] Loss: -1275.278320\n",
      "Train Epoch: 643 [11776/60000 (20%)] Loss: -1421.868652\n",
      "Train Epoch: 643 [23040/60000 (38%)] Loss: -1311.971924\n",
      "Train Epoch: 643 [34304/60000 (57%)] Loss: -1125.166992\n",
      "Train Epoch: 643 [45568/60000 (76%)] Loss: -1461.199707\n",
      "Train Epoch: 643 [56832/60000 (95%)] Loss: -1116.313965\n",
      "    epoch          : 643\n",
      "    loss           : -1283.5257578704316\n",
      "Train Epoch: 644 [512/60000 (1%)] Loss: -1203.632324\n",
      "Train Epoch: 644 [11776/60000 (20%)] Loss: -1209.645874\n",
      "Train Epoch: 644 [23040/60000 (38%)] Loss: -1403.817871\n",
      "Train Epoch: 644 [34304/60000 (57%)] Loss: -1207.657349\n",
      "Train Epoch: 644 [45568/60000 (76%)] Loss: -1157.111816\n",
      "Train Epoch: 644 [56832/60000 (95%)] Loss: -1330.679077\n",
      "    epoch          : 644\n",
      "    loss           : -1267.1897474385923\n",
      "Train Epoch: 645 [512/60000 (1%)] Loss: -1379.365356\n",
      "Train Epoch: 645 [11776/60000 (20%)] Loss: -1131.742920\n",
      "Train Epoch: 645 [23040/60000 (38%)] Loss: -1247.152344\n",
      "Train Epoch: 645 [34304/60000 (57%)] Loss: -1351.763428\n",
      "Train Epoch: 645 [45568/60000 (76%)] Loss: -1272.018677\n",
      "Train Epoch: 645 [56832/60000 (95%)] Loss: -1167.279785\n",
      "    epoch          : 645\n",
      "    loss           : -1277.3470764160156\n",
      "Train Epoch: 646 [512/60000 (1%)] Loss: -1280.456787\n",
      "Train Epoch: 646 [11776/60000 (20%)] Loss: -1466.199219\n",
      "Train Epoch: 646 [23040/60000 (38%)] Loss: -1168.175293\n",
      "Train Epoch: 646 [34304/60000 (57%)] Loss: -1279.282837\n",
      "Train Epoch: 646 [45568/60000 (76%)] Loss: -1176.332520\n",
      "Train Epoch: 646 [56832/60000 (95%)] Loss: -1432.717773\n",
      "    epoch          : 646\n",
      "    loss           : -1275.737597621767\n",
      "Train Epoch: 647 [512/60000 (1%)] Loss: -1302.914062\n",
      "Train Epoch: 647 [11776/60000 (20%)] Loss: -1030.133179\n",
      "Train Epoch: 647 [23040/60000 (38%)] Loss: -1385.811890\n",
      "Train Epoch: 647 [34304/60000 (57%)] Loss: -1123.775146\n",
      "Train Epoch: 647 [45568/60000 (76%)] Loss: -1427.754028\n",
      "Train Epoch: 647 [56832/60000 (95%)] Loss: -1225.917725\n",
      "    epoch          : 647\n",
      "    loss           : -1281.2871911000398\n",
      "Train Epoch: 648 [512/60000 (1%)] Loss: -1430.016846\n",
      "Train Epoch: 648 [11776/60000 (20%)] Loss: -1319.717529\n",
      "Train Epoch: 648 [23040/60000 (38%)] Loss: -1234.345703\n",
      "Train Epoch: 648 [34304/60000 (57%)] Loss: -1325.891602\n",
      "Train Epoch: 648 [45568/60000 (76%)] Loss: -1316.652344\n",
      "Train Epoch: 648 [56832/60000 (95%)] Loss: -1163.420410\n",
      "    epoch          : 648\n",
      "    loss           : -1278.7189174156404\n",
      "Train Epoch: 649 [512/60000 (1%)] Loss: -1379.982666\n",
      "Train Epoch: 649 [11776/60000 (20%)] Loss: -1384.771118\n",
      "Train Epoch: 649 [23040/60000 (38%)] Loss: -1253.464478\n",
      "Train Epoch: 649 [34304/60000 (57%)] Loss: -1172.217896\n",
      "Train Epoch: 649 [45568/60000 (76%)] Loss: -1319.320923\n",
      "Train Epoch: 649 [56832/60000 (95%)] Loss: -1282.695312\n",
      "    epoch          : 649\n",
      "    loss           : -1286.7518581239517\n",
      "Train Epoch: 650 [512/60000 (1%)] Loss: -1446.234131\n",
      "Train Epoch: 650 [11776/60000 (20%)] Loss: -1242.182861\n",
      "Train Epoch: 650 [23040/60000 (38%)] Loss: -1175.401367\n",
      "Train Epoch: 650 [34304/60000 (57%)] Loss: -1441.951660\n",
      "Train Epoch: 650 [45568/60000 (76%)] Loss: -1307.514771\n",
      "Train Epoch: 650 [56832/60000 (95%)] Loss: -1251.461792\n",
      "    epoch          : 650\n",
      "    loss           : -1276.8571937690347\n",
      "Train Epoch: 651 [512/60000 (1%)] Loss: -1072.074829\n",
      "Train Epoch: 651 [11776/60000 (20%)] Loss: -1421.936523\n",
      "Train Epoch: 651 [23040/60000 (38%)] Loss: -1301.867798\n",
      "Train Epoch: 651 [34304/60000 (57%)] Loss: -1242.916016\n",
      "Train Epoch: 651 [45568/60000 (76%)] Loss: -1127.723877\n",
      "Train Epoch: 651 [56832/60000 (95%)] Loss: -1186.167603\n",
      "    epoch          : 651\n",
      "    loss           : -1290.0348310739982\n",
      "Train Epoch: 652 [512/60000 (1%)] Loss: -1317.703247\n",
      "Train Epoch: 652 [11776/60000 (20%)] Loss: -1403.087769\n",
      "Train Epoch: 652 [23040/60000 (38%)] Loss: -1463.918945\n",
      "Train Epoch: 652 [34304/60000 (57%)] Loss: -1410.702148\n",
      "Train Epoch: 652 [45568/60000 (76%)] Loss: -1467.389648\n",
      "Train Epoch: 652 [56832/60000 (95%)] Loss: -1327.929810\n",
      "    epoch          : 652\n",
      "    loss           : -1286.3132496634446\n",
      "Train Epoch: 653 [512/60000 (1%)] Loss: -1276.378052\n",
      "Train Epoch: 653 [11776/60000 (20%)] Loss: -1436.753174\n",
      "Train Epoch: 653 [23040/60000 (38%)] Loss: -1298.943359\n",
      "Train Epoch: 653 [34304/60000 (57%)] Loss: -1383.114990\n",
      "Train Epoch: 653 [45568/60000 (76%)] Loss: -1307.865356\n",
      "Train Epoch: 653 [56832/60000 (95%)] Loss: -1337.946533\n",
      "    epoch          : 653\n",
      "    loss           : -1274.8731179102667\n",
      "Train Epoch: 654 [512/60000 (1%)] Loss: -1241.438354\n",
      "Train Epoch: 654 [11776/60000 (20%)] Loss: -1433.119263\n",
      "Train Epoch: 654 [23040/60000 (38%)] Loss: -1261.658936\n",
      "Train Epoch: 654 [34304/60000 (57%)] Loss: -1265.704346\n",
      "Train Epoch: 654 [45568/60000 (76%)] Loss: -1151.084595\n",
      "Train Epoch: 654 [56832/60000 (95%)] Loss: -1472.052368\n",
      "    epoch          : 654\n",
      "    loss           : -1269.0577606373588\n",
      "Train Epoch: 655 [512/60000 (1%)] Loss: -1275.103271\n",
      "Train Epoch: 655 [11776/60000 (20%)] Loss: -1453.744751\n",
      "Train Epoch: 655 [23040/60000 (38%)] Loss: -1190.818604\n",
      "Train Epoch: 655 [34304/60000 (57%)] Loss: -1172.723999\n",
      "Train Epoch: 655 [45568/60000 (76%)] Loss: -1340.581543\n",
      "Train Epoch: 655 [56832/60000 (95%)] Loss: -1119.084839\n",
      "    epoch          : 655\n",
      "    loss           : -1282.1257712154065\n",
      "Train Epoch: 656 [512/60000 (1%)] Loss: -1072.779541\n",
      "Train Epoch: 656 [11776/60000 (20%)] Loss: -1328.585449\n",
      "Train Epoch: 656 [23040/60000 (38%)] Loss: -1257.287231\n",
      "Train Epoch: 656 [34304/60000 (57%)] Loss: -1308.745972\n",
      "Train Epoch: 656 [45568/60000 (76%)] Loss: -1178.405518\n",
      "Train Epoch: 656 [56832/60000 (95%)] Loss: -1213.048584\n",
      "    epoch          : 656\n",
      "    loss           : -1285.1286636611162\n",
      "Train Epoch: 657 [512/60000 (1%)] Loss: -1395.566650\n",
      "Train Epoch: 657 [11776/60000 (20%)] Loss: -1095.651367\n",
      "Train Epoch: 657 [23040/60000 (38%)] Loss: -975.641113\n",
      "Train Epoch: 657 [34304/60000 (57%)] Loss: -1297.719971\n",
      "Train Epoch: 657 [45568/60000 (76%)] Loss: -1253.846924\n",
      "Train Epoch: 657 [56832/60000 (95%)] Loss: -1352.649292\n",
      "    epoch          : 657\n",
      "    loss           : -1276.3636779785156\n",
      "Train Epoch: 658 [512/60000 (1%)] Loss: -1358.596680\n",
      "Train Epoch: 658 [11776/60000 (20%)] Loss: -1119.730469\n",
      "Train Epoch: 658 [23040/60000 (38%)] Loss: -1286.069702\n",
      "Train Epoch: 658 [34304/60000 (57%)] Loss: -1395.260498\n",
      "Train Epoch: 658 [45568/60000 (76%)] Loss: -1312.085449\n",
      "Train Epoch: 658 [56832/60000 (95%)] Loss: -1413.668457\n",
      "    epoch          : 658\n",
      "    loss           : -1299.7281233792924\n",
      "Train Epoch: 659 [512/60000 (1%)] Loss: -1434.856445\n",
      "Train Epoch: 659 [11776/60000 (20%)] Loss: -1173.989380\n",
      "Train Epoch: 659 [23040/60000 (38%)] Loss: -1393.342041\n",
      "Train Epoch: 659 [34304/60000 (57%)] Loss: -1148.617920\n",
      "Train Epoch: 659 [45568/60000 (76%)] Loss: -1111.436401\n",
      "Train Epoch: 659 [56832/60000 (95%)] Loss: -1447.150146\n",
      "    epoch          : 659\n",
      "    loss           : -1289.5694957668497\n",
      "Train Epoch: 660 [512/60000 (1%)] Loss: -1215.058838\n",
      "Train Epoch: 660 [11776/60000 (20%)] Loss: -1247.020264\n",
      "Train Epoch: 660 [23040/60000 (38%)] Loss: -1479.072998\n",
      "Train Epoch: 660 [34304/60000 (57%)] Loss: -1414.543579\n",
      "Train Epoch: 660 [45568/60000 (76%)] Loss: -1422.876465\n",
      "Train Epoch: 660 [56832/60000 (95%)] Loss: -1285.441895\n",
      "    epoch          : 660\n",
      "    loss           : -1271.4402469268625\n",
      "Train Epoch: 661 [512/60000 (1%)] Loss: -1326.057739\n",
      "Train Epoch: 661 [11776/60000 (20%)] Loss: -1150.519531\n",
      "Train Epoch: 661 [23040/60000 (38%)] Loss: -1141.312744\n",
      "Train Epoch: 661 [34304/60000 (57%)] Loss: -1079.255859\n",
      "Train Epoch: 661 [45568/60000 (76%)] Loss: -1234.919556\n",
      "Train Epoch: 661 [56832/60000 (95%)] Loss: -1410.331299\n",
      "    epoch          : 661\n",
      "    loss           : -1276.936843441031\n",
      "Train Epoch: 662 [512/60000 (1%)] Loss: -1415.364258\n",
      "Train Epoch: 662 [11776/60000 (20%)] Loss: -1129.284546\n",
      "Train Epoch: 662 [23040/60000 (38%)] Loss: -1253.650513\n",
      "Train Epoch: 662 [34304/60000 (57%)] Loss: -1307.123901\n",
      "Train Epoch: 662 [45568/60000 (76%)] Loss: -1076.427490\n",
      "Train Epoch: 662 [56832/60000 (95%)] Loss: -1273.956909\n",
      "    epoch          : 662\n",
      "    loss           : -1284.615197995288\n",
      "Train Epoch: 663 [512/60000 (1%)] Loss: -1233.542236\n",
      "Train Epoch: 663 [11776/60000 (20%)] Loss: -1259.654053\n",
      "Train Epoch: 663 [23040/60000 (38%)] Loss: -1338.492432\n",
      "Train Epoch: 663 [34304/60000 (57%)] Loss: -1176.036987\n",
      "Train Epoch: 663 [45568/60000 (76%)] Loss: -1157.047363\n",
      "Train Epoch: 663 [56832/60000 (95%)] Loss: -1258.399780\n",
      "    epoch          : 663\n",
      "    loss           : -1293.143677619891\n",
      "Train Epoch: 664 [512/60000 (1%)] Loss: -1425.655273\n",
      "Train Epoch: 664 [11776/60000 (20%)] Loss: -1420.055420\n",
      "Train Epoch: 664 [23040/60000 (38%)] Loss: -1437.121338\n",
      "Train Epoch: 664 [34304/60000 (57%)] Loss: -1398.605835\n",
      "Train Epoch: 664 [45568/60000 (76%)] Loss: -1238.827637\n",
      "Train Epoch: 664 [56832/60000 (95%)] Loss: -1260.395996\n",
      "    epoch          : 664\n",
      "    loss           : -1271.3257216976187\n",
      "Train Epoch: 665 [512/60000 (1%)] Loss: -1162.864746\n",
      "Train Epoch: 665 [11776/60000 (20%)] Loss: -1296.183105\n",
      "Train Epoch: 665 [23040/60000 (38%)] Loss: -1376.235229\n",
      "Train Epoch: 665 [34304/60000 (57%)] Loss: -1147.213135\n",
      "Train Epoch: 665 [45568/60000 (76%)] Loss: -1144.840088\n",
      "Train Epoch: 665 [56832/60000 (95%)] Loss: -1455.776978\n",
      "    epoch          : 665\n",
      "    loss           : -1265.16301904021\n",
      "Train Epoch: 666 [512/60000 (1%)] Loss: -1445.411255\n",
      "Train Epoch: 666 [11776/60000 (20%)] Loss: -1263.890381\n",
      "Train Epoch: 666 [23040/60000 (38%)] Loss: -1070.227417\n",
      "Train Epoch: 666 [34304/60000 (57%)] Loss: -1316.701416\n",
      "Train Epoch: 666 [45568/60000 (76%)] Loss: -1425.894043\n",
      "Train Epoch: 666 [56832/60000 (95%)] Loss: -1133.960083\n",
      "    epoch          : 666\n",
      "    loss           : -1297.000322934598\n",
      "Train Epoch: 667 [512/60000 (1%)] Loss: -1131.923218\n",
      "Train Epoch: 667 [11776/60000 (20%)] Loss: -1284.208252\n",
      "Train Epoch: 667 [23040/60000 (38%)] Loss: -1452.146484\n",
      "Train Epoch: 667 [34304/60000 (57%)] Loss: -1234.183472\n",
      "Train Epoch: 667 [45568/60000 (76%)] Loss: -1414.285645\n",
      "Train Epoch: 667 [56832/60000 (95%)] Loss: -1310.162598\n",
      "    epoch          : 667\n",
      "    loss           : -1272.7756099377648\n",
      "Train Epoch: 668 [512/60000 (1%)] Loss: -1117.999268\n",
      "Train Epoch: 668 [11776/60000 (20%)] Loss: -1160.105225\n",
      "Train Epoch: 668 [23040/60000 (38%)] Loss: -1401.596436\n",
      "Train Epoch: 668 [34304/60000 (57%)] Loss: -1261.516235\n",
      "Train Epoch: 668 [45568/60000 (76%)] Loss: -1204.595947\n",
      "Train Epoch: 668 [56832/60000 (95%)] Loss: -1459.662720\n",
      "    epoch          : 668\n",
      "    loss           : -1293.4804151287187\n",
      "Train Epoch: 669 [512/60000 (1%)] Loss: -1179.836426\n",
      "Train Epoch: 669 [11776/60000 (20%)] Loss: -1264.035645\n",
      "Train Epoch: 669 [23040/60000 (38%)] Loss: -1260.271484\n",
      "Train Epoch: 669 [34304/60000 (57%)] Loss: -1251.930054\n",
      "Train Epoch: 669 [45568/60000 (76%)] Loss: -1032.807129\n",
      "Train Epoch: 669 [56832/60000 (95%)] Loss: -1132.214600\n",
      "    epoch          : 669\n",
      "    loss           : -1279.1296916034937\n",
      "Train Epoch: 670 [512/60000 (1%)] Loss: -1038.125854\n",
      "Train Epoch: 670 [11776/60000 (20%)] Loss: -1363.815674\n",
      "Train Epoch: 670 [23040/60000 (38%)] Loss: -1273.118164\n",
      "Train Epoch: 670 [34304/60000 (57%)] Loss: -1374.377686\n",
      "Train Epoch: 670 [45568/60000 (76%)] Loss: -1218.727051\n",
      "Train Epoch: 670 [56832/60000 (95%)] Loss: -1107.127686\n",
      "    epoch          : 670\n",
      "    loss           : -1297.0341196868378\n",
      "Train Epoch: 671 [512/60000 (1%)] Loss: -1442.081177\n",
      "Train Epoch: 671 [11776/60000 (20%)] Loss: -1029.504639\n",
      "Train Epoch: 671 [23040/60000 (38%)] Loss: -1428.411865\n",
      "Train Epoch: 671 [34304/60000 (57%)] Loss: -1119.190186\n",
      "Train Epoch: 671 [45568/60000 (76%)] Loss: -1106.942383\n",
      "Train Epoch: 671 [56832/60000 (95%)] Loss: -1137.458008\n",
      "    epoch          : 671\n",
      "    loss           : -1281.242349398338\n",
      "Train Epoch: 672 [512/60000 (1%)] Loss: -1371.518921\n",
      "Train Epoch: 672 [11776/60000 (20%)] Loss: -1285.530029\n",
      "Train Epoch: 672 [23040/60000 (38%)] Loss: -1450.533691\n",
      "Train Epoch: 672 [34304/60000 (57%)] Loss: -1409.590210\n",
      "Train Epoch: 672 [45568/60000 (76%)] Loss: -1301.212280\n",
      "Train Epoch: 672 [56832/60000 (95%)] Loss: -1401.494629\n",
      "    epoch          : 672\n",
      "    loss           : -1308.258948202187\n",
      "Train Epoch: 673 [512/60000 (1%)] Loss: -1254.999023\n",
      "Train Epoch: 673 [11776/60000 (20%)] Loss: -1396.042358\n",
      "Train Epoch: 673 [23040/60000 (38%)] Loss: -1453.708374\n",
      "Train Epoch: 673 [34304/60000 (57%)] Loss: -826.484619\n",
      "Train Epoch: 673 [45568/60000 (76%)] Loss: -1095.552734\n",
      "Train Epoch: 673 [56832/60000 (95%)] Loss: -1232.979736\n",
      "    epoch          : 673\n",
      "    loss           : -1277.2947891149145\n",
      "Train Epoch: 674 [512/60000 (1%)] Loss: -986.506531\n",
      "Train Epoch: 674 [11776/60000 (20%)] Loss: -1261.720459\n",
      "Train Epoch: 674 [23040/60000 (38%)] Loss: -1318.219849\n",
      "Train Epoch: 674 [34304/60000 (57%)] Loss: -1238.551270\n",
      "Train Epoch: 674 [45568/60000 (76%)] Loss: -1330.445312\n",
      "Train Epoch: 674 [56832/60000 (95%)] Loss: -1158.576660\n",
      "    epoch          : 674\n",
      "    loss           : -1279.6062159996247\n",
      "Train Epoch: 675 [512/60000 (1%)] Loss: -1289.816528\n",
      "Train Epoch: 675 [11776/60000 (20%)] Loss: -1119.792969\n",
      "Train Epoch: 675 [23040/60000 (38%)] Loss: -1310.576660\n",
      "Train Epoch: 675 [34304/60000 (57%)] Loss: -1283.705811\n",
      "Train Epoch: 675 [45568/60000 (76%)] Loss: -1478.223511\n",
      "Train Epoch: 675 [56832/60000 (95%)] Loss: -1266.200073\n",
      "    epoch          : 675\n",
      "    loss           : -1254.9780775167173\n",
      "Train Epoch: 676 [512/60000 (1%)] Loss: -1179.262451\n",
      "Train Epoch: 676 [11776/60000 (20%)] Loss: -1047.825562\n",
      "Train Epoch: 676 [23040/60000 (38%)] Loss: -1382.247925\n",
      "Train Epoch: 676 [34304/60000 (57%)] Loss: -1328.457275\n",
      "Train Epoch: 676 [45568/60000 (76%)] Loss: -1444.403198\n",
      "Train Epoch: 676 [56832/60000 (95%)] Loss: -1432.609863\n",
      "    epoch          : 676\n",
      "    loss           : -1282.5637850141795\n",
      "Train Epoch: 677 [512/60000 (1%)] Loss: -1295.939941\n",
      "Train Epoch: 677 [11776/60000 (20%)] Loss: -1113.065918\n",
      "Train Epoch: 677 [23040/60000 (38%)] Loss: -1364.341797\n",
      "Train Epoch: 677 [34304/60000 (57%)] Loss: -1245.691162\n",
      "Train Epoch: 677 [45568/60000 (76%)] Loss: -1259.625488\n",
      "Train Epoch: 677 [56832/60000 (95%)] Loss: -1456.438232\n",
      "    epoch          : 677\n",
      "    loss           : -1290.9710298527432\n",
      "Train Epoch: 678 [512/60000 (1%)] Loss: -1299.845215\n",
      "Train Epoch: 678 [11776/60000 (20%)] Loss: -1260.077026\n",
      "Train Epoch: 678 [23040/60000 (38%)] Loss: -1120.096313\n",
      "Train Epoch: 678 [34304/60000 (57%)] Loss: -1105.562378\n",
      "Train Epoch: 678 [45568/60000 (76%)] Loss: -1353.066895\n",
      "Train Epoch: 678 [56832/60000 (95%)] Loss: -1258.330322\n",
      "    epoch          : 678\n",
      "    loss           : -1293.0660698669778\n",
      "Train Epoch: 679 [512/60000 (1%)] Loss: -1155.434814\n",
      "Train Epoch: 679 [11776/60000 (20%)] Loss: -1394.618042\n",
      "Train Epoch: 679 [23040/60000 (38%)] Loss: -1173.881470\n",
      "Train Epoch: 679 [34304/60000 (57%)] Loss: -1281.712280\n",
      "Train Epoch: 679 [45568/60000 (76%)] Loss: -1080.884399\n",
      "Train Epoch: 679 [56832/60000 (95%)] Loss: -1401.709351\n",
      "    epoch          : 679\n",
      "    loss           : -1290.662097478317\n",
      "Train Epoch: 680 [512/60000 (1%)] Loss: -1272.483154\n",
      "Train Epoch: 680 [11776/60000 (20%)] Loss: -1132.182495\n",
      "Train Epoch: 680 [23040/60000 (38%)] Loss: -1253.005371\n",
      "Train Epoch: 680 [34304/60000 (57%)] Loss: -1416.805664\n",
      "Train Epoch: 680 [45568/60000 (76%)] Loss: -1398.123291\n",
      "Train Epoch: 680 [56832/60000 (95%)] Loss: -1446.871338\n",
      "    epoch          : 680\n",
      "    loss           : -1301.699160990742\n",
      "Train Epoch: 681 [512/60000 (1%)] Loss: -1150.676758\n",
      "Train Epoch: 681 [11776/60000 (20%)] Loss: -1404.391479\n",
      "Train Epoch: 681 [23040/60000 (38%)] Loss: -1283.091797\n",
      "Train Epoch: 681 [34304/60000 (57%)] Loss: -1357.993408\n",
      "Train Epoch: 681 [45568/60000 (76%)] Loss: -1293.646118\n",
      "Train Epoch: 681 [56832/60000 (95%)] Loss: -1436.564697\n",
      "    epoch          : 681\n",
      "    loss           : -1292.5380302472304\n",
      "Train Epoch: 682 [512/60000 (1%)] Loss: -1276.076294\n",
      "Train Epoch: 682 [11776/60000 (20%)] Loss: -1125.857056\n",
      "Train Epoch: 682 [23040/60000 (38%)] Loss: -1256.210938\n",
      "Train Epoch: 682 [34304/60000 (57%)] Loss: -1160.280884\n",
      "Train Epoch: 682 [45568/60000 (76%)] Loss: -1475.622070\n",
      "Train Epoch: 682 [56832/60000 (95%)] Loss: -1310.298706\n",
      "    epoch          : 682\n",
      "    loss           : -1283.5093630343506\n",
      "Train Epoch: 683 [512/60000 (1%)] Loss: -1396.814209\n",
      "Train Epoch: 683 [11776/60000 (20%)] Loss: -1446.575928\n",
      "Train Epoch: 683 [23040/60000 (38%)] Loss: -1434.572510\n",
      "Train Epoch: 683 [34304/60000 (57%)] Loss: -1424.561279\n",
      "Train Epoch: 683 [45568/60000 (76%)] Loss: -1401.797363\n",
      "Train Epoch: 683 [56832/60000 (95%)] Loss: -1078.700928\n",
      "    epoch          : 683\n",
      "    loss           : -1287.4977077333267\n",
      "Train Epoch: 684 [512/60000 (1%)] Loss: -1247.824097\n",
      "Train Epoch: 684 [11776/60000 (20%)] Loss: -1276.860352\n",
      "Train Epoch: 684 [23040/60000 (38%)] Loss: -1299.200317\n",
      "Train Epoch: 684 [34304/60000 (57%)] Loss: -1191.852417\n",
      "Train Epoch: 684 [45568/60000 (76%)] Loss: -1246.947876\n",
      "Train Epoch: 684 [56832/60000 (95%)] Loss: -944.229553\n",
      "    epoch          : 684\n",
      "    loss           : -1291.2132742499227\n",
      "Train Epoch: 685 [512/60000 (1%)] Loss: -1332.636230\n",
      "Train Epoch: 685 [11776/60000 (20%)] Loss: -1295.586792\n",
      "Train Epoch: 685 [23040/60000 (38%)] Loss: -1451.976929\n",
      "Train Epoch: 685 [34304/60000 (57%)] Loss: -1397.008179\n",
      "Train Epoch: 685 [45568/60000 (76%)] Loss: -1101.619629\n",
      "Train Epoch: 685 [56832/60000 (95%)] Loss: -1212.414307\n",
      "    epoch          : 685\n",
      "    loss           : -1291.6736781233449\n",
      "Train Epoch: 686 [512/60000 (1%)] Loss: -1118.390381\n",
      "Train Epoch: 686 [11776/60000 (20%)] Loss: -1280.882690\n",
      "Train Epoch: 686 [23040/60000 (38%)] Loss: -1436.262451\n",
      "Train Epoch: 686 [34304/60000 (57%)] Loss: -1437.489746\n",
      "Train Epoch: 686 [45568/60000 (76%)] Loss: -1424.646484\n",
      "Train Epoch: 686 [56832/60000 (95%)] Loss: -1171.454468\n",
      "    epoch          : 686\n",
      "    loss           : -1281.472852286646\n",
      "Train Epoch: 687 [512/60000 (1%)] Loss: -1242.645386\n",
      "Train Epoch: 687 [11776/60000 (20%)] Loss: -1448.934814\n",
      "Train Epoch: 687 [23040/60000 (38%)] Loss: -1267.867920\n",
      "Train Epoch: 687 [34304/60000 (57%)] Loss: -1443.607788\n",
      "Train Epoch: 687 [45568/60000 (76%)] Loss: -1295.440430\n",
      "Train Epoch: 687 [56832/60000 (95%)] Loss: -1436.662231\n",
      "    epoch          : 687\n",
      "    loss           : -1279.151886158744\n",
      "Train Epoch: 688 [512/60000 (1%)] Loss: -1417.850220\n",
      "Train Epoch: 688 [11776/60000 (20%)] Loss: -1394.077148\n",
      "Train Epoch: 688 [23040/60000 (38%)] Loss: -1255.616455\n",
      "Train Epoch: 688 [34304/60000 (57%)] Loss: -1145.755615\n",
      "Train Epoch: 688 [45568/60000 (76%)] Loss: -1457.599365\n",
      "Train Epoch: 688 [56832/60000 (95%)] Loss: -1302.776855\n",
      "    epoch          : 688\n",
      "    loss           : -1282.5995286844545\n",
      "Train Epoch: 689 [512/60000 (1%)] Loss: -1139.251709\n",
      "Train Epoch: 689 [11776/60000 (20%)] Loss: -1251.012695\n",
      "Train Epoch: 689 [23040/60000 (38%)] Loss: -1465.428833\n",
      "Train Epoch: 689 [34304/60000 (57%)] Loss: -1421.045898\n",
      "Train Epoch: 689 [45568/60000 (76%)] Loss: -1455.533569\n",
      "Train Epoch: 689 [56832/60000 (95%)] Loss: -1284.512817\n",
      "    epoch          : 689\n",
      "    loss           : -1276.452271887138\n",
      "Train Epoch: 690 [512/60000 (1%)] Loss: -1135.148193\n",
      "Train Epoch: 690 [11776/60000 (20%)] Loss: -1280.111450\n",
      "Train Epoch: 690 [23040/60000 (38%)] Loss: -1269.636719\n",
      "Train Epoch: 690 [34304/60000 (57%)] Loss: -1315.137451\n",
      "Train Epoch: 690 [45568/60000 (76%)] Loss: -1137.542236\n",
      "Train Epoch: 690 [56832/60000 (95%)] Loss: -1106.112305\n",
      "    epoch          : 690\n",
      "    loss           : -1294.5759439414505\n",
      "Train Epoch: 691 [512/60000 (1%)] Loss: -1494.447021\n",
      "Train Epoch: 691 [11776/60000 (20%)] Loss: -1431.172363\n",
      "Train Epoch: 691 [23040/60000 (38%)] Loss: -1269.074829\n",
      "Train Epoch: 691 [34304/60000 (57%)] Loss: -1462.899658\n",
      "Train Epoch: 691 [45568/60000 (76%)] Loss: -1260.188965\n",
      "Train Epoch: 691 [56832/60000 (95%)] Loss: -1057.080322\n",
      "    epoch          : 691\n",
      "    loss           : -1278.871991518527\n",
      "Train Epoch: 692 [512/60000 (1%)] Loss: -1405.829102\n",
      "Train Epoch: 692 [11776/60000 (20%)] Loss: -1125.604492\n",
      "Train Epoch: 692 [23040/60000 (38%)] Loss: -1101.334473\n",
      "Train Epoch: 692 [34304/60000 (57%)] Loss: -1394.528442\n",
      "Train Epoch: 692 [45568/60000 (76%)] Loss: -1367.556885\n",
      "Train Epoch: 692 [56832/60000 (95%)] Loss: -1233.685303\n",
      "    epoch          : 692\n",
      "    loss           : -1292.7098950747043\n",
      "Train Epoch: 693 [512/60000 (1%)] Loss: -1314.355591\n",
      "Train Epoch: 693 [11776/60000 (20%)] Loss: -1242.428223\n",
      "Train Epoch: 693 [23040/60000 (38%)] Loss: -1140.262939\n",
      "Train Epoch: 693 [34304/60000 (57%)] Loss: -1307.667358\n",
      "Train Epoch: 693 [45568/60000 (76%)] Loss: -1142.125244\n",
      "Train Epoch: 693 [56832/60000 (95%)] Loss: -1182.016724\n",
      "    epoch          : 693\n",
      "    loss           : -1291.1774407510704\n",
      "Train Epoch: 694 [512/60000 (1%)] Loss: -1484.033447\n",
      "Train Epoch: 694 [11776/60000 (20%)] Loss: -1260.465454\n",
      "Train Epoch: 694 [23040/60000 (38%)] Loss: -1422.752197\n",
      "Train Epoch: 694 [34304/60000 (57%)] Loss: -1124.018311\n",
      "Train Epoch: 694 [45568/60000 (76%)] Loss: -1201.340088\n",
      "Train Epoch: 694 [56832/60000 (95%)] Loss: -1244.232178\n",
      "    epoch          : 694\n",
      "    loss           : -1288.1363640909142\n",
      "Train Epoch: 695 [512/60000 (1%)] Loss: -1283.492554\n",
      "Train Epoch: 695 [11776/60000 (20%)] Loss: -1244.607910\n",
      "Train Epoch: 695 [23040/60000 (38%)] Loss: -1253.498901\n",
      "Train Epoch: 695 [34304/60000 (57%)] Loss: -1446.770996\n",
      "Train Epoch: 695 [45568/60000 (76%)] Loss: -1288.551758\n",
      "Train Epoch: 695 [56832/60000 (95%)] Loss: -1372.340332\n",
      "    epoch          : 695\n",
      "    loss           : -1294.120639951889\n",
      "Train Epoch: 696 [512/60000 (1%)] Loss: -1261.753906\n",
      "Train Epoch: 696 [11776/60000 (20%)] Loss: -1004.080627\n",
      "Train Epoch: 696 [23040/60000 (38%)] Loss: -1132.595337\n",
      "Train Epoch: 696 [34304/60000 (57%)] Loss: -1238.800415\n",
      "Train Epoch: 696 [45568/60000 (76%)] Loss: -1423.209229\n",
      "Train Epoch: 696 [56832/60000 (95%)] Loss: -986.415649\n",
      "    epoch          : 696\n",
      "    loss           : -1278.3585089559608\n",
      "Train Epoch: 697 [512/60000 (1%)] Loss: -1101.989014\n",
      "Train Epoch: 697 [11776/60000 (20%)] Loss: -1306.466064\n",
      "Train Epoch: 697 [23040/60000 (38%)] Loss: -1123.075073\n",
      "Train Epoch: 697 [34304/60000 (57%)] Loss: -1456.817871\n",
      "Train Epoch: 697 [45568/60000 (76%)] Loss: -1248.707153\n",
      "Train Epoch: 697 [56832/60000 (95%)] Loss: -1342.314453\n",
      "    epoch          : 697\n",
      "    loss           : -1277.1216523768537\n",
      "Train Epoch: 698 [512/60000 (1%)] Loss: -1360.518799\n",
      "Train Epoch: 698 [11776/60000 (20%)] Loss: -1278.853638\n",
      "Train Epoch: 698 [23040/60000 (38%)] Loss: -1165.454712\n",
      "Train Epoch: 698 [34304/60000 (57%)] Loss: -1432.246338\n",
      "Train Epoch: 698 [45568/60000 (76%)] Loss: -1458.636719\n",
      "Train Epoch: 698 [56832/60000 (95%)] Loss: -1395.185303\n",
      "    epoch          : 698\n",
      "    loss           : -1300.9508316988326\n",
      "Train Epoch: 699 [512/60000 (1%)] Loss: -1283.667236\n",
      "Train Epoch: 699 [11776/60000 (20%)] Loss: -1164.054932\n",
      "Train Epoch: 699 [23040/60000 (38%)] Loss: -1413.002930\n",
      "Train Epoch: 699 [34304/60000 (57%)] Loss: -1193.232788\n",
      "Train Epoch: 699 [45568/60000 (76%)] Loss: -1335.833496\n",
      "Train Epoch: 699 [56832/60000 (95%)] Loss: -1423.975342\n",
      "    epoch          : 699\n",
      "    loss           : -1277.5050650558903\n",
      "Train Epoch: 700 [512/60000 (1%)] Loss: -1389.726318\n",
      "Train Epoch: 700 [11776/60000 (20%)] Loss: -1070.699463\n",
      "Train Epoch: 700 [23040/60000 (38%)] Loss: -1410.855103\n",
      "Train Epoch: 700 [34304/60000 (57%)] Loss: -1456.714478\n",
      "Train Epoch: 700 [45568/60000 (76%)] Loss: -1430.237549\n",
      "Train Epoch: 700 [56832/60000 (95%)] Loss: -1241.857422\n",
      "    epoch          : 700\n",
      "    loss           : -1303.4238181248895\n",
      "Saving checkpoint: saved/models/Mnist_DeepGenerativeOperad/0127_111843/checkpoint-epoch700.pth ...\n",
      "Train Epoch: 701 [512/60000 (1%)] Loss: -1443.783203\n",
      "Train Epoch: 701 [11776/60000 (20%)] Loss: -1065.204590\n",
      "Train Epoch: 701 [23040/60000 (38%)] Loss: -1120.612793\n",
      "Train Epoch: 701 [34304/60000 (57%)] Loss: -1376.012085\n",
      "Train Epoch: 701 [45568/60000 (76%)] Loss: -1205.368164\n",
      "Train Epoch: 701 [56832/60000 (95%)] Loss: -1407.706665\n",
      "    epoch          : 701\n",
      "    loss           : -1289.4919204280875\n",
      "Train Epoch: 702 [512/60000 (1%)] Loss: -1453.462524\n",
      "Train Epoch: 702 [11776/60000 (20%)] Loss: -1041.964844\n",
      "Train Epoch: 702 [23040/60000 (38%)] Loss: -1423.265869\n",
      "Train Epoch: 702 [34304/60000 (57%)] Loss: -1464.354736\n",
      "Train Epoch: 702 [45568/60000 (76%)] Loss: -1150.607666\n",
      "Train Epoch: 702 [56832/60000 (95%)] Loss: -1272.074707\n",
      "    epoch          : 702\n",
      "    loss           : -1286.4610111215022\n",
      "Train Epoch: 703 [512/60000 (1%)] Loss: -1458.283569\n",
      "Train Epoch: 703 [11776/60000 (20%)] Loss: -1356.587769\n",
      "Train Epoch: 703 [23040/60000 (38%)] Loss: -1473.598877\n",
      "Train Epoch: 703 [34304/60000 (57%)] Loss: -1082.511230\n",
      "Train Epoch: 703 [45568/60000 (76%)] Loss: -1426.443848\n",
      "Train Epoch: 703 [56832/60000 (95%)] Loss: -1334.461914\n",
      "    epoch          : 703\n",
      "    loss           : -1308.1773798883298\n",
      "Train Epoch: 704 [512/60000 (1%)] Loss: -1130.852539\n",
      "Train Epoch: 704 [11776/60000 (20%)] Loss: -1457.643677\n",
      "Train Epoch: 704 [23040/60000 (38%)] Loss: -1270.081299\n",
      "Train Epoch: 704 [34304/60000 (57%)] Loss: -1040.151611\n",
      "Train Epoch: 704 [45568/60000 (76%)] Loss: -1163.052124\n",
      "Train Epoch: 704 [56832/60000 (95%)] Loss: -1291.814819\n",
      "    epoch          : 704\n",
      "    loss           : -1273.883338195456\n",
      "Train Epoch: 705 [512/60000 (1%)] Loss: -1430.590820\n",
      "Train Epoch: 705 [11776/60000 (20%)] Loss: -1332.400391\n",
      "Train Epoch: 705 [23040/60000 (38%)] Loss: -1253.847900\n",
      "Train Epoch: 705 [34304/60000 (57%)] Loss: -1149.180664\n",
      "Train Epoch: 705 [45568/60000 (76%)] Loss: -1251.508789\n",
      "Train Epoch: 705 [56832/60000 (95%)] Loss: -1423.770020\n",
      "    epoch          : 705\n",
      "    loss           : -1290.4528836180261\n",
      "Train Epoch: 706 [512/60000 (1%)] Loss: -1277.298218\n",
      "Train Epoch: 706 [11776/60000 (20%)] Loss: -1267.963867\n",
      "Train Epoch: 706 [23040/60000 (38%)] Loss: -1294.831543\n",
      "Train Epoch: 706 [34304/60000 (57%)] Loss: -1421.551514\n",
      "Train Epoch: 706 [45568/60000 (76%)] Loss: -1490.106445\n",
      "Train Epoch: 706 [56832/60000 (95%)] Loss: -1305.090088\n",
      "    epoch          : 706\n",
      "    loss           : -1309.5827962584415\n",
      "Train Epoch: 707 [512/60000 (1%)] Loss: -1139.748169\n",
      "Train Epoch: 707 [11776/60000 (20%)] Loss: -1281.891968\n",
      "Train Epoch: 707 [23040/60000 (38%)] Loss: -1276.561035\n",
      "Train Epoch: 707 [34304/60000 (57%)] Loss: -1262.615967\n",
      "Train Epoch: 707 [45568/60000 (76%)] Loss: -1302.599731\n",
      "Train Epoch: 707 [56832/60000 (95%)] Loss: -1009.264038\n",
      "    epoch          : 707\n",
      "    loss           : -1306.3517695712505\n",
      "Train Epoch: 708 [512/60000 (1%)] Loss: -1430.949951\n",
      "Train Epoch: 708 [11776/60000 (20%)] Loss: -1431.491089\n",
      "Train Epoch: 708 [23040/60000 (38%)] Loss: -1145.863281\n",
      "Train Epoch: 708 [34304/60000 (57%)] Loss: -1280.345825\n",
      "Train Epoch: 708 [45568/60000 (76%)] Loss: -1287.297119\n",
      "Train Epoch: 708 [56832/60000 (95%)] Loss: -1142.983032\n",
      "    epoch          : 708\n",
      "    loss           : -1292.1362896073338\n",
      "Train Epoch: 709 [512/60000 (1%)] Loss: -1417.456299\n",
      "Train Epoch: 709 [11776/60000 (20%)] Loss: -1337.054932\n",
      "Train Epoch: 709 [23040/60000 (38%)] Loss: -1291.548828\n",
      "Train Epoch: 709 [34304/60000 (57%)] Loss: -1446.968750\n",
      "Train Epoch: 709 [45568/60000 (76%)] Loss: -1261.470581\n",
      "Train Epoch: 709 [56832/60000 (95%)] Loss: -1172.427124\n",
      "    epoch          : 709\n",
      "    loss           : -1285.5102508027676\n",
      "Train Epoch: 710 [512/60000 (1%)] Loss: -1173.162964\n",
      "Train Epoch: 710 [11776/60000 (20%)] Loss: -1295.177246\n",
      "Train Epoch: 710 [23040/60000 (38%)] Loss: -1254.446289\n",
      "Train Epoch: 710 [34304/60000 (57%)] Loss: -1481.089111\n",
      "Train Epoch: 710 [45568/60000 (76%)] Loss: -1285.039429\n",
      "Train Epoch: 710 [56832/60000 (95%)] Loss: -1413.717773\n",
      "    epoch          : 710\n",
      "    loss           : -1296.2134204584327\n",
      "Train Epoch: 711 [512/60000 (1%)] Loss: -1273.572998\n",
      "Train Epoch: 711 [11776/60000 (20%)] Loss: -1307.401123\n",
      "Train Epoch: 711 [23040/60000 (38%)] Loss: -1307.643799\n",
      "Train Epoch: 711 [34304/60000 (57%)] Loss: -1458.203369\n",
      "Train Epoch: 711 [45568/60000 (76%)] Loss: -1436.540649\n",
      "Train Epoch: 711 [56832/60000 (95%)] Loss: -1441.017822\n",
      "    epoch          : 711\n",
      "    loss           : -1296.267363467459\n",
      "Train Epoch: 712 [512/60000 (1%)] Loss: -1240.784546\n",
      "Train Epoch: 712 [11776/60000 (20%)] Loss: -1459.720459\n",
      "Train Epoch: 712 [23040/60000 (38%)] Loss: -1417.189087\n",
      "Train Epoch: 712 [34304/60000 (57%)] Loss: -1323.969971\n",
      "Train Epoch: 712 [45568/60000 (76%)] Loss: -1143.813965\n",
      "Train Epoch: 712 [56832/60000 (95%)] Loss: -1336.333008\n",
      "    epoch          : 712\n",
      "    loss           : -1294.1839601333534\n",
      "Train Epoch: 713 [512/60000 (1%)] Loss: -1155.223877\n",
      "Train Epoch: 713 [11776/60000 (20%)] Loss: -1291.541626\n",
      "Train Epoch: 713 [23040/60000 (38%)] Loss: -1358.003418\n",
      "Train Epoch: 713 [34304/60000 (57%)] Loss: -1407.515869\n",
      "Train Epoch: 713 [45568/60000 (76%)] Loss: -1296.019775\n",
      "Train Epoch: 713 [56832/60000 (95%)] Loss: -1447.745972\n",
      "    epoch          : 713\n",
      "    loss           : -1282.3881732488082\n",
      "Train Epoch: 714 [512/60000 (1%)] Loss: -1453.972412\n",
      "Train Epoch: 714 [11776/60000 (20%)] Loss: -1124.144653\n",
      "Train Epoch: 714 [23040/60000 (38%)] Loss: -1254.395996\n",
      "Train Epoch: 714 [34304/60000 (57%)] Loss: -1282.768311\n",
      "Train Epoch: 714 [45568/60000 (76%)] Loss: -1313.140381\n",
      "Train Epoch: 714 [56832/60000 (95%)] Loss: -1341.282959\n",
      "    epoch          : 714\n",
      "    loss           : -1278.103880456612\n",
      "Train Epoch: 715 [512/60000 (1%)] Loss: -1449.492920\n",
      "Train Epoch: 715 [11776/60000 (20%)] Loss: -1293.770020\n",
      "Train Epoch: 715 [23040/60000 (38%)] Loss: -1279.578735\n",
      "Train Epoch: 715 [34304/60000 (57%)] Loss: -1069.406128\n",
      "Train Epoch: 715 [45568/60000 (76%)] Loss: -1489.233276\n",
      "Train Epoch: 715 [56832/60000 (95%)] Loss: -1253.331543\n",
      "    epoch          : 715\n",
      "    loss           : -1276.027830307093\n",
      "Train Epoch: 716 [512/60000 (1%)] Loss: -1466.677124\n",
      "Train Epoch: 716 [11776/60000 (20%)] Loss: -1329.999023\n",
      "Train Epoch: 716 [23040/60000 (38%)] Loss: -1413.190430\n",
      "Train Epoch: 716 [34304/60000 (57%)] Loss: -944.013977\n",
      "Train Epoch: 716 [45568/60000 (76%)] Loss: -1409.974609\n",
      "Train Epoch: 716 [56832/60000 (95%)] Loss: -1264.317383\n",
      "    epoch          : 716\n",
      "    loss           : -1300.3650867871645\n",
      "Train Epoch: 717 [512/60000 (1%)] Loss: -1317.796875\n",
      "Train Epoch: 717 [11776/60000 (20%)] Loss: -989.317688\n",
      "Train Epoch: 717 [23040/60000 (38%)] Loss: -1339.693726\n",
      "Train Epoch: 717 [34304/60000 (57%)] Loss: -1139.988525\n",
      "Train Epoch: 717 [45568/60000 (76%)] Loss: -1248.693115\n",
      "Train Epoch: 717 [56832/60000 (95%)] Loss: -1161.406494\n",
      "    epoch          : 717\n",
      "    loss           : -1303.5495414087327\n",
      "Train Epoch: 718 [512/60000 (1%)] Loss: -1244.964844\n",
      "Train Epoch: 718 [11776/60000 (20%)] Loss: -1133.626465\n",
      "Train Epoch: 718 [23040/60000 (38%)] Loss: -1432.572144\n",
      "Train Epoch: 718 [34304/60000 (57%)] Loss: -1251.203857\n",
      "Train Epoch: 718 [45568/60000 (76%)] Loss: -1122.515381\n",
      "Train Epoch: 718 [56832/60000 (95%)] Loss: -1236.082153\n",
      "    epoch          : 718\n",
      "    loss           : -1280.6819495939267\n",
      "Train Epoch: 719 [512/60000 (1%)] Loss: -1048.538086\n",
      "Train Epoch: 719 [11776/60000 (20%)] Loss: -1159.447632\n",
      "Train Epoch: 719 [23040/60000 (38%)] Loss: -1386.297119\n",
      "Train Epoch: 719 [34304/60000 (57%)] Loss: -1426.860474\n",
      "Train Epoch: 719 [45568/60000 (76%)] Loss: -1091.839111\n",
      "Train Epoch: 719 [56832/60000 (95%)] Loss: -1308.974731\n",
      "    epoch          : 719\n",
      "    loss           : -1281.1129172804667\n",
      "Train Epoch: 720 [512/60000 (1%)] Loss: -1056.855225\n",
      "Train Epoch: 720 [11776/60000 (20%)] Loss: -1439.894409\n",
      "Train Epoch: 720 [23040/60000 (38%)] Loss: -1318.270386\n",
      "Train Epoch: 720 [34304/60000 (57%)] Loss: -1348.454346\n",
      "Train Epoch: 720 [45568/60000 (76%)] Loss: -1116.838135\n",
      "Train Epoch: 720 [56832/60000 (95%)] Loss: -1126.237793\n",
      "    epoch          : 720\n",
      "    loss           : -1289.1608733268781\n",
      "Train Epoch: 721 [512/60000 (1%)] Loss: -1301.253784\n",
      "Train Epoch: 721 [11776/60000 (20%)] Loss: -1290.877808\n",
      "Train Epoch: 721 [23040/60000 (38%)] Loss: -1154.752319\n",
      "Train Epoch: 721 [34304/60000 (57%)] Loss: -1434.258301\n",
      "Train Epoch: 721 [45568/60000 (76%)] Loss: -1222.965820\n",
      "Train Epoch: 721 [56832/60000 (95%)] Loss: -1315.560059\n",
      "    epoch          : 721\n",
      "    loss           : -1300.54220287948\n",
      "Train Epoch: 722 [512/60000 (1%)] Loss: -962.356445\n",
      "Train Epoch: 722 [11776/60000 (20%)] Loss: -1246.638428\n",
      "Train Epoch: 722 [23040/60000 (38%)] Loss: -1456.149780\n",
      "Train Epoch: 722 [34304/60000 (57%)] Loss: -1278.962646\n",
      "Train Epoch: 722 [45568/60000 (76%)] Loss: -1183.266235\n",
      "Train Epoch: 722 [56832/60000 (95%)] Loss: -1427.386841\n",
      "    epoch          : 722\n",
      "    loss           : -1290.9250671041889\n",
      "Train Epoch: 723 [512/60000 (1%)] Loss: -1337.058960\n",
      "Train Epoch: 723 [11776/60000 (20%)] Loss: -1288.398438\n",
      "Train Epoch: 723 [23040/60000 (38%)] Loss: -1266.199097\n",
      "Train Epoch: 723 [34304/60000 (57%)] Loss: -1249.445312\n",
      "Train Epoch: 723 [45568/60000 (76%)] Loss: -1444.375488\n",
      "Train Epoch: 723 [56832/60000 (95%)] Loss: -1425.585449\n",
      "    epoch          : 723\n",
      "    loss           : -1272.0647917494261\n",
      "Train Epoch: 724 [512/60000 (1%)] Loss: -1085.421753\n",
      "Train Epoch: 724 [11776/60000 (20%)] Loss: -1436.052002\n",
      "Train Epoch: 724 [23040/60000 (38%)] Loss: -1462.631958\n",
      "Train Epoch: 724 [34304/60000 (57%)] Loss: -1258.029663\n",
      "Train Epoch: 724 [45568/60000 (76%)] Loss: -1420.631592\n",
      "Train Epoch: 724 [56832/60000 (95%)] Loss: -1108.586426\n",
      "    epoch          : 724\n",
      "    loss           : -1293.7167917025292\n",
      "Train Epoch: 725 [512/60000 (1%)] Loss: -1030.312622\n",
      "Train Epoch: 725 [11776/60000 (20%)] Loss: -1444.830933\n",
      "Train Epoch: 725 [23040/60000 (38%)] Loss: -1435.883179\n",
      "Train Epoch: 725 [34304/60000 (57%)] Loss: -1291.340332\n",
      "Train Epoch: 725 [45568/60000 (76%)] Loss: -1150.603760\n",
      "Train Epoch: 725 [56832/60000 (95%)] Loss: -1126.161133\n",
      "    epoch          : 725\n",
      "    loss           : -1290.8111465367895\n",
      "Train Epoch: 726 [512/60000 (1%)] Loss: -1271.901245\n",
      "Train Epoch: 726 [11776/60000 (20%)] Loss: -1426.580933\n",
      "Train Epoch: 726 [23040/60000 (38%)] Loss: -1137.953003\n",
      "Train Epoch: 726 [34304/60000 (57%)] Loss: -1320.197754\n",
      "Train Epoch: 726 [45568/60000 (76%)] Loss: -1219.363770\n",
      "Train Epoch: 726 [56832/60000 (95%)] Loss: -1326.660156\n",
      "    epoch          : 726\n",
      "    loss           : -1288.636766336732\n",
      "Train Epoch: 727 [512/60000 (1%)] Loss: -1452.715820\n",
      "Train Epoch: 727 [11776/60000 (20%)] Loss: -1190.396240\n",
      "Train Epoch: 727 [23040/60000 (38%)] Loss: -1206.352051\n",
      "Train Epoch: 727 [34304/60000 (57%)] Loss: -1239.020264\n",
      "Train Epoch: 727 [45568/60000 (76%)] Loss: -1268.677490\n",
      "Train Epoch: 727 [56832/60000 (95%)] Loss: -1447.781494\n",
      "    epoch          : 727\n",
      "    loss           : -1283.4010752877273\n",
      "Train Epoch: 728 [512/60000 (1%)] Loss: -1413.669556\n",
      "Train Epoch: 728 [11776/60000 (20%)] Loss: -1329.019897\n",
      "Train Epoch: 728 [23040/60000 (38%)] Loss: -1277.093994\n",
      "Train Epoch: 728 [34304/60000 (57%)] Loss: -1297.514160\n",
      "Train Epoch: 728 [45568/60000 (76%)] Loss: -1469.849731\n",
      "Train Epoch: 728 [56832/60000 (95%)] Loss: -1439.224854\n",
      "    epoch          : 728\n",
      "    loss           : -1284.5195003875906\n",
      "Train Epoch: 729 [512/60000 (1%)] Loss: -1417.159790\n",
      "Train Epoch: 729 [11776/60000 (20%)] Loss: -1316.892700\n",
      "Train Epoch: 729 [23040/60000 (38%)] Loss: -1072.130493\n",
      "Train Epoch: 729 [34304/60000 (57%)] Loss: -857.932495\n",
      "Train Epoch: 729 [45568/60000 (76%)] Loss: -1433.099609\n",
      "Train Epoch: 729 [56832/60000 (95%)] Loss: -1213.086304\n",
      "    epoch          : 729\n",
      "    loss           : -1289.4015168443239\n",
      "Train Epoch: 730 [512/60000 (1%)] Loss: -1170.677002\n",
      "Train Epoch: 730 [11776/60000 (20%)] Loss: -1043.631226\n",
      "Train Epoch: 730 [23040/60000 (38%)] Loss: -1327.280518\n",
      "Train Epoch: 730 [34304/60000 (57%)] Loss: -1144.267090\n",
      "Train Epoch: 730 [45568/60000 (76%)] Loss: -1327.434937\n",
      "Train Epoch: 730 [56832/60000 (95%)] Loss: -1193.462158\n",
      "    epoch          : 730\n",
      "    loss           : -1308.7893985381907\n",
      "Train Epoch: 731 [512/60000 (1%)] Loss: -1261.945801\n",
      "Train Epoch: 731 [11776/60000 (20%)] Loss: -1139.107422\n",
      "Train Epoch: 731 [23040/60000 (38%)] Loss: -963.053833\n",
      "Train Epoch: 731 [34304/60000 (57%)] Loss: -1292.757080\n",
      "Train Epoch: 731 [45568/60000 (76%)] Loss: -1438.556396\n",
      "Train Epoch: 731 [56832/60000 (95%)] Loss: -1263.749756\n",
      "    epoch          : 731\n",
      "    loss           : -1280.342238086765\n",
      "Train Epoch: 732 [512/60000 (1%)] Loss: -1249.718262\n",
      "Train Epoch: 732 [11776/60000 (20%)] Loss: -1444.550293\n",
      "Train Epoch: 732 [23040/60000 (38%)] Loss: -1196.090820\n",
      "Train Epoch: 732 [34304/60000 (57%)] Loss: -1443.996216\n",
      "Train Epoch: 732 [45568/60000 (76%)] Loss: -1443.433594\n",
      "Train Epoch: 732 [56832/60000 (95%)] Loss: -1430.293945\n",
      "    epoch          : 732\n",
      "    loss           : -1287.3646914379747\n",
      "Train Epoch: 733 [512/60000 (1%)] Loss: -1291.505005\n",
      "Train Epoch: 733 [11776/60000 (20%)] Loss: -1336.325195\n",
      "Train Epoch: 733 [23040/60000 (38%)] Loss: -1229.314087\n",
      "Train Epoch: 733 [34304/60000 (57%)] Loss: -1277.351685\n",
      "Train Epoch: 733 [45568/60000 (76%)] Loss: -1129.803833\n",
      "Train Epoch: 733 [56832/60000 (95%)] Loss: -1336.283936\n",
      "    epoch          : 733\n",
      "    loss           : -1299.1450522902323\n",
      "Train Epoch: 734 [512/60000 (1%)] Loss: -1316.630249\n",
      "Train Epoch: 734 [11776/60000 (20%)] Loss: -1250.507812\n",
      "Train Epoch: 734 [23040/60000 (38%)] Loss: -1470.748047\n",
      "Train Epoch: 734 [34304/60000 (57%)] Loss: -1220.145752\n",
      "Train Epoch: 734 [45568/60000 (76%)] Loss: -1251.100586\n",
      "Train Epoch: 734 [56832/60000 (95%)] Loss: -1284.936646\n",
      "    epoch          : 734\n",
      "    loss           : -1284.7000392762955\n",
      "Train Epoch: 735 [512/60000 (1%)] Loss: -1302.973145\n",
      "Train Epoch: 735 [11776/60000 (20%)] Loss: -996.353394\n",
      "Train Epoch: 735 [23040/60000 (38%)] Loss: -1094.766113\n",
      "Train Epoch: 735 [34304/60000 (57%)] Loss: -1267.520752\n",
      "Train Epoch: 735 [45568/60000 (76%)] Loss: -1114.907227\n",
      "Train Epoch: 735 [56832/60000 (95%)] Loss: -1235.182129\n",
      "    epoch          : 735\n",
      "    loss           : -1284.1046833965063\n",
      "Train Epoch: 736 [512/60000 (1%)] Loss: -1498.926758\n",
      "Train Epoch: 736 [11776/60000 (20%)] Loss: -1433.307617\n",
      "Train Epoch: 736 [23040/60000 (38%)] Loss: -1445.750244\n",
      "Train Epoch: 736 [34304/60000 (57%)] Loss: -1448.262207\n",
      "Train Epoch: 736 [45568/60000 (76%)] Loss: -960.081055\n",
      "Train Epoch: 736 [56832/60000 (95%)] Loss: -1299.154419\n",
      "    epoch          : 736\n",
      "    loss           : -1306.9995968921035\n",
      "Train Epoch: 737 [512/60000 (1%)] Loss: -1225.429077\n",
      "Train Epoch: 737 [11776/60000 (20%)] Loss: -1083.214355\n",
      "Train Epoch: 737 [23040/60000 (38%)] Loss: -1323.137451\n",
      "Train Epoch: 737 [34304/60000 (57%)] Loss: -1314.722656\n",
      "Train Epoch: 737 [45568/60000 (76%)] Loss: -1432.452271\n",
      "Train Epoch: 737 [56832/60000 (95%)] Loss: -1314.877808\n",
      "    epoch          : 737\n",
      "    loss           : -1295.1224704893295\n",
      "Train Epoch: 738 [512/60000 (1%)] Loss: -1260.335205\n",
      "Train Epoch: 738 [11776/60000 (20%)] Loss: -1269.062012\n",
      "Train Epoch: 738 [23040/60000 (38%)] Loss: -1123.075439\n",
      "Train Epoch: 738 [34304/60000 (57%)] Loss: -1396.023926\n",
      "Train Epoch: 738 [45568/60000 (76%)] Loss: -1272.100464\n",
      "Train Epoch: 738 [56832/60000 (95%)] Loss: -1319.349365\n",
      "    epoch          : 738\n",
      "    loss           : -1296.3237318480756\n",
      "Train Epoch: 739 [512/60000 (1%)] Loss: -1300.413208\n",
      "Train Epoch: 739 [11776/60000 (20%)] Loss: -1301.712524\n",
      "Train Epoch: 739 [23040/60000 (38%)] Loss: -1246.608154\n",
      "Train Epoch: 739 [34304/60000 (57%)] Loss: -1249.834839\n",
      "Train Epoch: 739 [45568/60000 (76%)] Loss: -1291.194458\n",
      "Train Epoch: 739 [56832/60000 (95%)] Loss: -1413.237549\n",
      "    epoch          : 739\n",
      "    loss           : -1294.7143296063957\n",
      "Train Epoch: 740 [512/60000 (1%)] Loss: -1426.101562\n",
      "Train Epoch: 740 [11776/60000 (20%)] Loss: -1254.717041\n",
      "Train Epoch: 740 [23040/60000 (38%)] Loss: -1151.051270\n",
      "Train Epoch: 740 [34304/60000 (57%)] Loss: -1230.469238\n",
      "Train Epoch: 740 [45568/60000 (76%)] Loss: -1298.277710\n",
      "Train Epoch: 740 [56832/60000 (95%)] Loss: -1412.688354\n",
      "    epoch          : 740\n",
      "    loss           : -1305.317930577165\n",
      "Train Epoch: 741 [512/60000 (1%)] Loss: -1329.437988\n",
      "Train Epoch: 741 [11776/60000 (20%)] Loss: -1295.598877\n",
      "Train Epoch: 741 [23040/60000 (38%)] Loss: -1118.926636\n",
      "Train Epoch: 741 [34304/60000 (57%)] Loss: -1274.347412\n",
      "Train Epoch: 741 [45568/60000 (76%)] Loss: -1228.149780\n",
      "Train Epoch: 741 [56832/60000 (95%)] Loss: -1405.557129\n",
      "    epoch          : 741\n",
      "    loss           : -1290.7772692664196\n",
      "Train Epoch: 742 [512/60000 (1%)] Loss: -1389.039062\n",
      "Train Epoch: 742 [11776/60000 (20%)] Loss: -1256.617310\n",
      "Train Epoch: 742 [23040/60000 (38%)] Loss: -1460.101318\n",
      "Train Epoch: 742 [34304/60000 (57%)] Loss: -1252.109375\n",
      "Train Epoch: 742 [45568/60000 (76%)] Loss: -1151.702271\n",
      "Train Epoch: 742 [56832/60000 (95%)] Loss: -1217.250732\n",
      "    epoch          : 742\n",
      "    loss           : -1296.1881382829051\n",
      "Train Epoch: 743 [512/60000 (1%)] Loss: -1433.718506\n",
      "Train Epoch: 743 [11776/60000 (20%)] Loss: -1227.625122\n",
      "Train Epoch: 743 [23040/60000 (38%)] Loss: -1277.911377\n",
      "Train Epoch: 743 [34304/60000 (57%)] Loss: -1463.655762\n",
      "Train Epoch: 743 [45568/60000 (76%)] Loss: -1266.313965\n",
      "Train Epoch: 743 [56832/60000 (95%)] Loss: -1092.721680\n",
      "    epoch          : 743\n",
      "    loss           : -1286.1163511114605\n",
      "Train Epoch: 744 [512/60000 (1%)] Loss: -1183.974243\n",
      "Train Epoch: 744 [11776/60000 (20%)] Loss: -1414.146606\n",
      "Train Epoch: 744 [23040/60000 (38%)] Loss: -1239.915283\n",
      "Train Epoch: 744 [34304/60000 (57%)] Loss: -1198.399292\n",
      "Train Epoch: 744 [45568/60000 (76%)] Loss: -1264.480225\n",
      "Train Epoch: 744 [56832/60000 (95%)] Loss: -1311.062988\n",
      "    epoch          : 744\n",
      "    loss           : -1305.2079321220097\n",
      "Train Epoch: 745 [512/60000 (1%)] Loss: -1270.846924\n",
      "Train Epoch: 745 [11776/60000 (20%)] Loss: -1124.435913\n",
      "Train Epoch: 745 [23040/60000 (38%)] Loss: -1328.350830\n",
      "Train Epoch: 745 [34304/60000 (57%)] Loss: -1312.706787\n",
      "Train Epoch: 745 [45568/60000 (76%)] Loss: -1265.424316\n",
      "Train Epoch: 745 [56832/60000 (95%)] Loss: -1433.349365\n",
      "    epoch          : 745\n",
      "    loss           : -1278.1630142125707\n",
      "Train Epoch: 746 [512/60000 (1%)] Loss: -1142.579468\n",
      "Train Epoch: 746 [11776/60000 (20%)] Loss: -1446.153076\n",
      "Train Epoch: 746 [23040/60000 (38%)] Loss: -1430.788086\n",
      "Train Epoch: 746 [34304/60000 (57%)] Loss: -1256.453247\n",
      "Train Epoch: 746 [45568/60000 (76%)] Loss: -1145.786865\n",
      "Train Epoch: 746 [56832/60000 (95%)] Loss: -1319.160278\n",
      "    epoch          : 746\n",
      "    loss           : -1282.8324819446284\n",
      "Train Epoch: 747 [512/60000 (1%)] Loss: -1490.830078\n",
      "Train Epoch: 747 [11776/60000 (20%)] Loss: -1310.268799\n",
      "Train Epoch: 747 [23040/60000 (38%)] Loss: -1077.587769\n",
      "Train Epoch: 747 [34304/60000 (57%)] Loss: -1291.354004\n",
      "Train Epoch: 747 [45568/60000 (76%)] Loss: -1291.384155\n",
      "Train Epoch: 747 [56832/60000 (95%)] Loss: -1120.429932\n",
      "    epoch          : 747\n",
      "    loss           : -1311.43194545595\n",
      "Train Epoch: 748 [512/60000 (1%)] Loss: -1325.461670\n",
      "Train Epoch: 748 [11776/60000 (20%)] Loss: -996.258179\n",
      "Train Epoch: 748 [23040/60000 (38%)] Loss: -1099.592529\n",
      "Train Epoch: 748 [34304/60000 (57%)] Loss: -1275.704834\n",
      "Train Epoch: 748 [45568/60000 (76%)] Loss: -1448.783447\n",
      "Train Epoch: 748 [56832/60000 (95%)] Loss: -1299.433838\n",
      "    epoch          : 748\n",
      "    loss           : -1279.7952910170043\n",
      "Train Epoch: 749 [512/60000 (1%)] Loss: -1473.000000\n",
      "Train Epoch: 749 [11776/60000 (20%)] Loss: -1112.928955\n",
      "Train Epoch: 749 [23040/60000 (38%)] Loss: -1327.633911\n",
      "Train Epoch: 749 [34304/60000 (57%)] Loss: -1440.166504\n",
      "Train Epoch: 749 [45568/60000 (76%)] Loss: -1469.251465\n",
      "Train Epoch: 749 [56832/60000 (95%)] Loss: -1413.861206\n",
      "    epoch          : 749\n",
      "    loss           : -1298.7486903303761\n",
      "Train Epoch: 750 [512/60000 (1%)] Loss: -1399.702393\n",
      "Train Epoch: 750 [11776/60000 (20%)] Loss: -1330.020020\n",
      "Train Epoch: 750 [23040/60000 (38%)] Loss: -1139.283203\n",
      "Train Epoch: 750 [34304/60000 (57%)] Loss: -1326.100220\n",
      "Train Epoch: 750 [45568/60000 (76%)] Loss: -1295.526978\n",
      "Train Epoch: 750 [56832/60000 (95%)] Loss: -1455.460815\n",
      "    epoch          : 750\n",
      "    loss           : -1306.9928018171233\n",
      "Train Epoch: 751 [512/60000 (1%)] Loss: -1317.708008\n",
      "Train Epoch: 751 [11776/60000 (20%)] Loss: -1023.113098\n",
      "Train Epoch: 751 [23040/60000 (38%)] Loss: -1017.358459\n",
      "Train Epoch: 751 [34304/60000 (57%)] Loss: -1439.610474\n",
      "Train Epoch: 751 [45568/60000 (76%)] Loss: -1143.735596\n",
      "Train Epoch: 751 [56832/60000 (95%)] Loss: -1301.991699\n",
      "    epoch          : 751\n",
      "    loss           : -1297.3645595399673\n",
      "Train Epoch: 752 [512/60000 (1%)] Loss: -1467.849121\n",
      "Train Epoch: 752 [11776/60000 (20%)] Loss: -1314.735107\n",
      "Train Epoch: 752 [23040/60000 (38%)] Loss: -1147.650269\n",
      "Train Epoch: 752 [34304/60000 (57%)] Loss: -1311.388794\n",
      "Train Epoch: 752 [45568/60000 (76%)] Loss: -1362.920898\n",
      "Train Epoch: 752 [56832/60000 (95%)] Loss: -1273.886108\n",
      "    epoch          : 752\n",
      "    loss           : -1269.9056679246114\n",
      "Train Epoch: 753 [512/60000 (1%)] Loss: -1479.420654\n",
      "Train Epoch: 753 [11776/60000 (20%)] Loss: -1336.840942\n",
      "Train Epoch: 753 [23040/60000 (38%)] Loss: -1324.758057\n",
      "Train Epoch: 753 [34304/60000 (57%)] Loss: -1281.857544\n",
      "Train Epoch: 753 [45568/60000 (76%)] Loss: -1454.237671\n",
      "Train Epoch: 753 [56832/60000 (95%)] Loss: -1453.493408\n",
      "    epoch          : 753\n",
      "    loss           : -1278.4128169690148\n",
      "Train Epoch: 754 [512/60000 (1%)] Loss: -1106.689819\n",
      "Train Epoch: 754 [11776/60000 (20%)] Loss: -1421.721436\n",
      "Train Epoch: 754 [23040/60000 (38%)] Loss: -1147.191040\n",
      "Train Epoch: 754 [34304/60000 (57%)] Loss: -1414.667480\n",
      "Train Epoch: 754 [45568/60000 (76%)] Loss: -1282.996582\n",
      "Train Epoch: 754 [56832/60000 (95%)] Loss: -1405.185791\n",
      "    epoch          : 754\n",
      "    loss           : -1276.527220817609\n",
      "Train Epoch: 755 [512/60000 (1%)] Loss: -952.187988\n",
      "Train Epoch: 755 [11776/60000 (20%)] Loss: -1462.163452\n",
      "Train Epoch: 755 [23040/60000 (38%)] Loss: -1282.701416\n",
      "Train Epoch: 755 [34304/60000 (57%)] Loss: -1260.650146\n",
      "Train Epoch: 755 [45568/60000 (76%)] Loss: -1253.089355\n",
      "Train Epoch: 755 [56832/60000 (95%)] Loss: -1131.414551\n",
      "    epoch          : 755\n",
      "    loss           : -1280.7074786687301\n",
      "Train Epoch: 756 [512/60000 (1%)] Loss: -1303.631470\n",
      "Train Epoch: 756 [11776/60000 (20%)] Loss: -1328.344482\n",
      "Train Epoch: 756 [23040/60000 (38%)] Loss: -1464.254395\n",
      "Train Epoch: 756 [34304/60000 (57%)] Loss: -1284.199219\n",
      "Train Epoch: 756 [45568/60000 (76%)] Loss: -1465.442383\n",
      "Train Epoch: 756 [56832/60000 (95%)] Loss: -1301.562744\n",
      "    epoch          : 756\n",
      "    loss           : -1308.5678352312852\n",
      "Train Epoch: 757 [512/60000 (1%)] Loss: -1269.550415\n",
      "Train Epoch: 757 [11776/60000 (20%)] Loss: -1454.874023\n",
      "Train Epoch: 757 [23040/60000 (38%)] Loss: -1120.735352\n",
      "Train Epoch: 757 [34304/60000 (57%)] Loss: -1234.213257\n",
      "Train Epoch: 757 [45568/60000 (76%)] Loss: -1287.705322\n",
      "Train Epoch: 757 [56832/60000 (95%)] Loss: -1252.756104\n",
      "    epoch          : 757\n",
      "    loss           : -1270.6831935731705\n",
      "Train Epoch: 758 [512/60000 (1%)] Loss: -1234.060669\n",
      "Train Epoch: 758 [11776/60000 (20%)] Loss: -1137.196533\n",
      "Train Epoch: 758 [23040/60000 (38%)] Loss: -1287.926025\n",
      "Train Epoch: 758 [34304/60000 (57%)] Loss: -1473.311401\n",
      "Train Epoch: 758 [45568/60000 (76%)] Loss: -1341.737793\n",
      "Train Epoch: 758 [56832/60000 (95%)] Loss: -1388.456909\n",
      "    epoch          : 758\n",
      "    loss           : -1298.9279533429335\n",
      "Train Epoch: 759 [512/60000 (1%)] Loss: -1359.306030\n",
      "Train Epoch: 759 [11776/60000 (20%)] Loss: -1189.394043\n",
      "Train Epoch: 759 [23040/60000 (38%)] Loss: -1174.704590\n",
      "Train Epoch: 759 [34304/60000 (57%)] Loss: -1489.683838\n",
      "Train Epoch: 759 [45568/60000 (76%)] Loss: -1305.505859\n",
      "Train Epoch: 759 [56832/60000 (95%)] Loss: -1293.914917\n",
      "    epoch          : 759\n",
      "    loss           : -1304.142388467735\n",
      "Train Epoch: 760 [512/60000 (1%)] Loss: -1152.336548\n",
      "Train Epoch: 760 [11776/60000 (20%)] Loss: -1464.707764\n",
      "Train Epoch: 760 [23040/60000 (38%)] Loss: -1296.202393\n",
      "Train Epoch: 760 [34304/60000 (57%)] Loss: -1129.402100\n",
      "Train Epoch: 760 [45568/60000 (76%)] Loss: -1124.694824\n",
      "Train Epoch: 760 [56832/60000 (95%)] Loss: -1301.315308\n",
      "    epoch          : 760\n",
      "    loss           : -1261.802145747815\n",
      "Train Epoch: 761 [512/60000 (1%)] Loss: -1294.014771\n",
      "Train Epoch: 761 [11776/60000 (20%)] Loss: -1259.523071\n",
      "Train Epoch: 761 [23040/60000 (38%)] Loss: -1331.715820\n",
      "Train Epoch: 761 [34304/60000 (57%)] Loss: -1192.651855\n",
      "Train Epoch: 761 [45568/60000 (76%)] Loss: -1322.215820\n",
      "Train Epoch: 761 [56832/60000 (95%)] Loss: -1207.689941\n",
      "    epoch          : 761\n",
      "    loss           : -1283.494770459536\n",
      "Train Epoch: 762 [512/60000 (1%)] Loss: -1297.936157\n",
      "Train Epoch: 762 [11776/60000 (20%)] Loss: -1335.876099\n",
      "Train Epoch: 762 [23040/60000 (38%)] Loss: -1285.350220\n",
      "Train Epoch: 762 [34304/60000 (57%)] Loss: -1418.199707\n",
      "Train Epoch: 762 [45568/60000 (76%)] Loss: -1318.619873\n",
      "Train Epoch: 762 [56832/60000 (95%)] Loss: -1453.582275\n",
      "    epoch          : 762\n",
      "    loss           : -1303.4898007495253\n",
      "Train Epoch: 763 [512/60000 (1%)] Loss: -1155.855957\n",
      "Train Epoch: 763 [11776/60000 (20%)] Loss: -1257.640747\n",
      "Train Epoch: 763 [23040/60000 (38%)] Loss: -962.537903\n",
      "Train Epoch: 763 [34304/60000 (57%)] Loss: -1416.470459\n",
      "Train Epoch: 763 [45568/60000 (76%)] Loss: -1172.216431\n",
      "Train Epoch: 763 [56832/60000 (95%)] Loss: -1347.773315\n",
      "    epoch          : 763\n",
      "    loss           : -1288.9448950816009\n",
      "Train Epoch: 764 [512/60000 (1%)] Loss: -1326.701660\n",
      "Train Epoch: 764 [11776/60000 (20%)] Loss: -1001.197144\n",
      "Train Epoch: 764 [23040/60000 (38%)] Loss: -1196.904053\n",
      "Train Epoch: 764 [34304/60000 (57%)] Loss: -986.363159\n",
      "Train Epoch: 764 [45568/60000 (76%)] Loss: -1328.493652\n",
      "Train Epoch: 764 [56832/60000 (95%)] Loss: -1321.769775\n",
      "    epoch          : 764\n",
      "    loss           : -1284.4325459798179\n",
      "Train Epoch: 765 [512/60000 (1%)] Loss: -1460.674072\n",
      "Train Epoch: 765 [11776/60000 (20%)] Loss: -1098.163330\n",
      "Train Epoch: 765 [23040/60000 (38%)] Loss: -1062.382568\n",
      "Train Epoch: 765 [34304/60000 (57%)] Loss: -1123.211548\n",
      "Train Epoch: 765 [45568/60000 (76%)] Loss: -1353.725464\n",
      "Train Epoch: 765 [56832/60000 (95%)] Loss: -1436.810791\n",
      "    epoch          : 765\n",
      "    loss           : -1296.6888977740446\n",
      "Train Epoch: 766 [512/60000 (1%)] Loss: -1236.800659\n",
      "Train Epoch: 766 [11776/60000 (20%)] Loss: -1293.979004\n",
      "Train Epoch: 766 [23040/60000 (38%)] Loss: -1475.001831\n",
      "Train Epoch: 766 [34304/60000 (57%)] Loss: -1295.263184\n",
      "Train Epoch: 766 [45568/60000 (76%)] Loss: -1352.229858\n",
      "Train Epoch: 766 [56832/60000 (95%)] Loss: -1433.553467\n",
      "    epoch          : 766\n",
      "    loss           : -1306.1388004971088\n",
      "Train Epoch: 767 [512/60000 (1%)] Loss: -1453.597656\n",
      "Train Epoch: 767 [11776/60000 (20%)] Loss: -1122.182129\n",
      "Train Epoch: 767 [23040/60000 (38%)] Loss: -1303.535278\n",
      "Train Epoch: 767 [34304/60000 (57%)] Loss: -1314.400635\n",
      "Train Epoch: 767 [45568/60000 (76%)] Loss: -1305.553345\n",
      "Train Epoch: 767 [56832/60000 (95%)] Loss: -1361.655396\n",
      "    epoch          : 767\n",
      "    loss           : -1281.402510820809\n",
      "Train Epoch: 768 [512/60000 (1%)] Loss: -1197.179443\n",
      "Train Epoch: 768 [11776/60000 (20%)] Loss: -1480.838257\n",
      "Train Epoch: 768 [23040/60000 (38%)] Loss: -1452.387695\n",
      "Train Epoch: 768 [34304/60000 (57%)] Loss: -1285.294067\n",
      "Train Epoch: 768 [45568/60000 (76%)] Loss: -1061.203613\n",
      "Train Epoch: 768 [56832/60000 (95%)] Loss: -1420.428711\n",
      "    epoch          : 768\n",
      "    loss           : -1313.069022140934\n",
      "Train Epoch: 769 [512/60000 (1%)] Loss: -1287.335815\n",
      "Train Epoch: 769 [11776/60000 (20%)] Loss: -1462.544312\n",
      "Train Epoch: 769 [23040/60000 (38%)] Loss: -1334.907715\n",
      "Train Epoch: 769 [34304/60000 (57%)] Loss: -1450.467773\n",
      "Train Epoch: 769 [45568/60000 (76%)] Loss: -1328.929199\n",
      "Train Epoch: 769 [56832/60000 (95%)] Loss: -1300.512695\n",
      "    epoch          : 769\n",
      "    loss           : -1270.0423044323247\n",
      "Train Epoch: 770 [512/60000 (1%)] Loss: -1451.362061\n",
      "Train Epoch: 770 [11776/60000 (20%)] Loss: -1258.745361\n",
      "Train Epoch: 770 [23040/60000 (38%)] Loss: -1335.408936\n",
      "Train Epoch: 770 [34304/60000 (57%)] Loss: -1211.426636\n",
      "Train Epoch: 770 [45568/60000 (76%)] Loss: -946.976257\n",
      "Train Epoch: 770 [56832/60000 (95%)] Loss: -1117.527588\n",
      "    epoch          : 770\n",
      "    loss           : -1298.5546340511344\n",
      "Train Epoch: 771 [512/60000 (1%)] Loss: -1283.211426\n",
      "Train Epoch: 771 [11776/60000 (20%)] Loss: -1464.894287\n",
      "Train Epoch: 771 [23040/60000 (38%)] Loss: -1318.485107\n",
      "Train Epoch: 771 [34304/60000 (57%)] Loss: -1263.991577\n",
      "Train Epoch: 771 [45568/60000 (76%)] Loss: -1153.943359\n",
      "Train Epoch: 771 [56832/60000 (95%)] Loss: -1130.825684\n",
      "    epoch          : 771\n",
      "    loss           : -1279.2586081984355\n",
      "Train Epoch: 772 [512/60000 (1%)] Loss: -1283.227295\n",
      "Train Epoch: 772 [11776/60000 (20%)] Loss: -1137.789062\n",
      "Train Epoch: 772 [23040/60000 (38%)] Loss: -1335.972900\n",
      "Train Epoch: 772 [34304/60000 (57%)] Loss: -1091.236450\n",
      "Train Epoch: 772 [45568/60000 (76%)] Loss: -1148.286987\n",
      "Train Epoch: 772 [56832/60000 (95%)] Loss: -1235.891235\n",
      "    epoch          : 772\n",
      "    loss           : -1289.5202250507593\n",
      "Train Epoch: 773 [512/60000 (1%)] Loss: -1280.836548\n",
      "Train Epoch: 773 [11776/60000 (20%)] Loss: -1130.306885\n",
      "Train Epoch: 773 [23040/60000 (38%)] Loss: -1119.814453\n",
      "Train Epoch: 773 [34304/60000 (57%)] Loss: -970.607483\n",
      "Train Epoch: 773 [45568/60000 (76%)] Loss: -1458.917114\n",
      "Train Epoch: 773 [56832/60000 (95%)] Loss: -1128.122559\n",
      "    epoch          : 773\n",
      "    loss           : -1302.3880389369815\n",
      "Train Epoch: 774 [512/60000 (1%)] Loss: -1171.274414\n",
      "Train Epoch: 774 [11776/60000 (20%)] Loss: -1298.974731\n",
      "Train Epoch: 774 [23040/60000 (38%)] Loss: -1282.538086\n",
      "Train Epoch: 774 [34304/60000 (57%)] Loss: -1327.508057\n",
      "Train Epoch: 774 [45568/60000 (76%)] Loss: -1438.599976\n",
      "Train Epoch: 774 [56832/60000 (95%)] Loss: -1440.770630\n",
      "    epoch          : 774\n",
      "    loss           : -1312.2557723050736\n",
      "Train Epoch: 775 [512/60000 (1%)] Loss: -1341.793579\n",
      "Train Epoch: 775 [11776/60000 (20%)] Loss: -1373.070312\n",
      "Train Epoch: 775 [23040/60000 (38%)] Loss: -1497.357056\n",
      "Train Epoch: 775 [34304/60000 (57%)] Loss: -1438.938232\n",
      "Train Epoch: 775 [45568/60000 (76%)] Loss: -1288.675415\n",
      "Train Epoch: 775 [56832/60000 (95%)] Loss: -1282.878662\n",
      "    epoch          : 775\n",
      "    loss           : -1305.4402833065744\n",
      "Train Epoch: 776 [512/60000 (1%)] Loss: -1309.417969\n",
      "Train Epoch: 776 [11776/60000 (20%)] Loss: -1151.015381\n",
      "Train Epoch: 776 [23040/60000 (38%)] Loss: -1424.305298\n",
      "Train Epoch: 776 [34304/60000 (57%)] Loss: -1220.052368\n",
      "Train Epoch: 776 [45568/60000 (76%)] Loss: -1427.598755\n",
      "Train Epoch: 776 [56832/60000 (95%)] Loss: -1031.728394\n",
      "    epoch          : 776\n",
      "    loss           : -1295.0268377099333\n",
      "Train Epoch: 777 [512/60000 (1%)] Loss: -1240.092773\n",
      "Train Epoch: 777 [11776/60000 (20%)] Loss: -1167.934326\n",
      "Train Epoch: 777 [23040/60000 (38%)] Loss: -1109.858887\n",
      "Train Epoch: 777 [34304/60000 (57%)] Loss: -1434.860107\n",
      "Train Epoch: 777 [45568/60000 (76%)] Loss: -1336.723877\n",
      "Train Epoch: 777 [56832/60000 (95%)] Loss: -1426.530762\n",
      "    epoch          : 777\n",
      "    loss           : -1302.431235620531\n",
      "Train Epoch: 778 [512/60000 (1%)] Loss: -1281.110840\n",
      "Train Epoch: 778 [11776/60000 (20%)] Loss: -1464.323730\n",
      "Train Epoch: 778 [23040/60000 (38%)] Loss: -1008.559570\n",
      "Train Epoch: 778 [34304/60000 (57%)] Loss: -1250.343750\n",
      "Train Epoch: 778 [45568/60000 (76%)] Loss: -1096.640503\n",
      "Train Epoch: 778 [56832/60000 (95%)] Loss: -1268.893555\n",
      "    epoch          : 778\n",
      "    loss           : -1300.2828341554114\n",
      "Train Epoch: 779 [512/60000 (1%)] Loss: -1121.716797\n",
      "Train Epoch: 779 [11776/60000 (20%)] Loss: -1107.832764\n",
      "Train Epoch: 779 [23040/60000 (38%)] Loss: -1184.020996\n",
      "Train Epoch: 779 [34304/60000 (57%)] Loss: -1441.756592\n",
      "Train Epoch: 779 [45568/60000 (76%)] Loss: -1173.677979\n",
      "Train Epoch: 779 [56832/60000 (95%)] Loss: -1343.365723\n",
      "    epoch          : 779\n",
      "    loss           : -1299.9059487897796\n",
      "Train Epoch: 780 [512/60000 (1%)] Loss: -1193.227783\n",
      "Train Epoch: 780 [11776/60000 (20%)] Loss: -1315.147339\n",
      "Train Epoch: 780 [23040/60000 (38%)] Loss: -1277.288818\n",
      "Train Epoch: 780 [34304/60000 (57%)] Loss: -1418.441895\n",
      "Train Epoch: 780 [45568/60000 (76%)] Loss: -1238.389404\n",
      "Train Epoch: 780 [56832/60000 (95%)] Loss: -1289.079102\n",
      "    epoch          : 780\n",
      "    loss           : -1300.6045133946307\n",
      "Train Epoch: 781 [512/60000 (1%)] Loss: -1454.585083\n",
      "Train Epoch: 781 [11776/60000 (20%)] Loss: -1257.917847\n",
      "Train Epoch: 781 [23040/60000 (38%)] Loss: -1426.553345\n",
      "Train Epoch: 781 [34304/60000 (57%)] Loss: -1159.367310\n",
      "Train Epoch: 781 [45568/60000 (76%)] Loss: -1323.897461\n",
      "Train Epoch: 781 [56832/60000 (95%)] Loss: -1414.487549\n",
      "    epoch          : 781\n",
      "    loss           : -1305.2758999409648\n",
      "Train Epoch: 782 [512/60000 (1%)] Loss: -1132.263550\n",
      "Train Epoch: 782 [11776/60000 (20%)] Loss: -1053.828125\n",
      "Train Epoch: 782 [23040/60000 (38%)] Loss: -1438.351318\n",
      "Train Epoch: 782 [34304/60000 (57%)] Loss: -1302.352539\n",
      "Train Epoch: 782 [45568/60000 (76%)] Loss: -1495.973511\n",
      "Train Epoch: 782 [56832/60000 (95%)] Loss: -1484.307373\n",
      "    epoch          : 782\n",
      "    loss           : -1294.2149190956588\n",
      "Train Epoch: 783 [512/60000 (1%)] Loss: -1114.007690\n",
      "Train Epoch: 783 [11776/60000 (20%)] Loss: -1422.412842\n",
      "Train Epoch: 783 [23040/60000 (38%)] Loss: -1233.101562\n",
      "Train Epoch: 783 [34304/60000 (57%)] Loss: -1435.478271\n",
      "Train Epoch: 783 [45568/60000 (76%)] Loss: -1334.912598\n",
      "Train Epoch: 783 [56832/60000 (95%)] Loss: -1427.282593\n",
      "    epoch          : 783\n",
      "    loss           : -1300.582859535002\n",
      "Train Epoch: 784 [512/60000 (1%)] Loss: -1436.606934\n",
      "Train Epoch: 784 [11776/60000 (20%)] Loss: -1091.598145\n",
      "Train Epoch: 784 [23040/60000 (38%)] Loss: -1489.997925\n",
      "Train Epoch: 784 [34304/60000 (57%)] Loss: -1101.938354\n",
      "Train Epoch: 784 [45568/60000 (76%)] Loss: -1468.387451\n",
      "Train Epoch: 784 [56832/60000 (95%)] Loss: -1482.394043\n",
      "    epoch          : 784\n",
      "    loss           : -1306.4751509327\n",
      "Train Epoch: 785 [512/60000 (1%)] Loss: -1441.875732\n",
      "Train Epoch: 785 [11776/60000 (20%)] Loss: -1477.580933\n",
      "Train Epoch: 785 [23040/60000 (38%)] Loss: -1444.134521\n",
      "Train Epoch: 785 [34304/60000 (57%)] Loss: -1452.091553\n",
      "Train Epoch: 785 [45568/60000 (76%)] Loss: -1448.303589\n",
      "Train Epoch: 785 [56832/60000 (95%)] Loss: -1178.338867\n",
      "    epoch          : 785\n",
      "    loss           : -1307.101720605193\n",
      "Train Epoch: 786 [512/60000 (1%)] Loss: -1420.320679\n",
      "Train Epoch: 786 [11776/60000 (20%)] Loss: -1349.847656\n",
      "Train Epoch: 786 [23040/60000 (38%)] Loss: -1294.690063\n",
      "Train Epoch: 786 [34304/60000 (57%)] Loss: -1280.188721\n",
      "Train Epoch: 786 [45568/60000 (76%)] Loss: -1170.941895\n",
      "Train Epoch: 786 [56832/60000 (95%)] Loss: -981.484985\n",
      "    epoch          : 786\n",
      "    loss           : -1315.2675579523636\n",
      "Train Epoch: 787 [512/60000 (1%)] Loss: -1335.985229\n",
      "Train Epoch: 787 [11776/60000 (20%)] Loss: -1456.846924\n",
      "Train Epoch: 787 [23040/60000 (38%)] Loss: -1460.000244\n",
      "Train Epoch: 787 [34304/60000 (57%)] Loss: -1338.549316\n",
      "Train Epoch: 787 [45568/60000 (76%)] Loss: -1317.909790\n",
      "Train Epoch: 787 [56832/60000 (95%)] Loss: -1161.176514\n",
      "    epoch          : 787\n",
      "    loss           : -1284.8158226228702\n",
      "Train Epoch: 788 [512/60000 (1%)] Loss: -1468.107422\n",
      "Train Epoch: 788 [11776/60000 (20%)] Loss: -1430.861328\n",
      "Train Epoch: 788 [23040/60000 (38%)] Loss: -990.819946\n",
      "Train Epoch: 788 [34304/60000 (57%)] Loss: -1458.995117\n",
      "Train Epoch: 788 [45568/60000 (76%)] Loss: -1432.646973\n",
      "Train Epoch: 788 [56832/60000 (95%)] Loss: -1455.183838\n",
      "    epoch          : 788\n",
      "    loss           : -1309.3814424848827\n",
      "Train Epoch: 789 [512/60000 (1%)] Loss: -958.146301\n",
      "Train Epoch: 789 [11776/60000 (20%)] Loss: -1265.904419\n",
      "Train Epoch: 789 [23040/60000 (38%)] Loss: -1412.412109\n",
      "Train Epoch: 789 [34304/60000 (57%)] Loss: -1281.019775\n",
      "Train Epoch: 789 [45568/60000 (76%)] Loss: -1437.708984\n",
      "Train Epoch: 789 [56832/60000 (95%)] Loss: -1462.135010\n",
      "    epoch          : 789\n",
      "    loss           : -1306.844983117055\n",
      "Train Epoch: 790 [512/60000 (1%)] Loss: -1320.022705\n",
      "Train Epoch: 790 [11776/60000 (20%)] Loss: -1272.471924\n",
      "Train Epoch: 790 [23040/60000 (38%)] Loss: -1456.179565\n",
      "Train Epoch: 790 [34304/60000 (57%)] Loss: -1436.016113\n",
      "Train Epoch: 790 [45568/60000 (76%)] Loss: -1269.290771\n",
      "Train Epoch: 790 [56832/60000 (95%)] Loss: -1437.821167\n",
      "    epoch          : 790\n",
      "    loss           : -1323.9644520215395\n",
      "Train Epoch: 791 [512/60000 (1%)] Loss: -1302.737183\n",
      "Train Epoch: 791 [11776/60000 (20%)] Loss: -1330.001465\n",
      "Train Epoch: 791 [23040/60000 (38%)] Loss: -1132.936035\n",
      "Train Epoch: 791 [34304/60000 (57%)] Loss: -1353.784912\n",
      "Train Epoch: 791 [45568/60000 (76%)] Loss: -1429.465088\n",
      "Train Epoch: 791 [56832/60000 (95%)] Loss: -1322.168091\n",
      "    epoch          : 791\n",
      "    loss           : -1292.256949214612\n",
      "Train Epoch: 792 [512/60000 (1%)] Loss: -1144.410889\n",
      "Train Epoch: 792 [11776/60000 (20%)] Loss: -1294.214233\n",
      "Train Epoch: 792 [23040/60000 (38%)] Loss: -1427.423340\n",
      "Train Epoch: 792 [34304/60000 (57%)] Loss: -1254.506104\n",
      "Train Epoch: 792 [45568/60000 (76%)] Loss: -1243.987305\n",
      "Train Epoch: 792 [56832/60000 (95%)] Loss: -1439.982910\n",
      "    epoch          : 792\n",
      "    loss           : -1295.6251203461554\n",
      "Train Epoch: 793 [512/60000 (1%)] Loss: -1155.163574\n",
      "Train Epoch: 793 [11776/60000 (20%)] Loss: -1299.098022\n",
      "Train Epoch: 793 [23040/60000 (38%)] Loss: -1485.447021\n",
      "Train Epoch: 793 [34304/60000 (57%)] Loss: -1447.239746\n",
      "Train Epoch: 793 [45568/60000 (76%)] Loss: -1155.345947\n",
      "Train Epoch: 793 [56832/60000 (95%)] Loss: -1114.417847\n",
      "    epoch          : 793\n",
      "    loss           : -1302.4699148404395\n",
      "Train Epoch: 794 [512/60000 (1%)] Loss: -920.007935\n",
      "Train Epoch: 794 [11776/60000 (20%)] Loss: -1403.008179\n",
      "Train Epoch: 794 [23040/60000 (38%)] Loss: -1454.300293\n",
      "Train Epoch: 794 [34304/60000 (57%)] Loss: -1279.771484\n",
      "Train Epoch: 794 [45568/60000 (76%)] Loss: -1127.320923\n",
      "Train Epoch: 794 [56832/60000 (95%)] Loss: -1290.817505\n",
      "    epoch          : 794\n",
      "    loss           : -1299.0399749238613\n",
      "Train Epoch: 795 [512/60000 (1%)] Loss: -1288.013794\n",
      "Train Epoch: 795 [11776/60000 (20%)] Loss: -1271.960205\n",
      "Train Epoch: 795 [23040/60000 (38%)] Loss: -1344.387207\n",
      "Train Epoch: 795 [34304/60000 (57%)] Loss: -1181.105591\n",
      "Train Epoch: 795 [45568/60000 (76%)] Loss: -1274.328979\n",
      "Train Epoch: 795 [56832/60000 (95%)] Loss: -1398.746216\n",
      "    epoch          : 795\n",
      "    loss           : -1303.7569818011784\n",
      "Train Epoch: 796 [512/60000 (1%)] Loss: -1458.929321\n",
      "Train Epoch: 796 [11776/60000 (20%)] Loss: -1244.031860\n",
      "Train Epoch: 796 [23040/60000 (38%)] Loss: -1392.523804\n",
      "Train Epoch: 796 [34304/60000 (57%)] Loss: -1338.028564\n",
      "Train Epoch: 796 [45568/60000 (76%)] Loss: -1465.077515\n",
      "Train Epoch: 796 [56832/60000 (95%)] Loss: -1444.115967\n",
      "    epoch          : 796\n",
      "    loss           : -1305.1296529823776\n",
      "Train Epoch: 797 [512/60000 (1%)] Loss: -1295.489014\n",
      "Train Epoch: 797 [11776/60000 (20%)] Loss: -1261.934814\n",
      "Train Epoch: 797 [23040/60000 (38%)] Loss: -1282.018066\n",
      "Train Epoch: 797 [34304/60000 (57%)] Loss: -1341.701050\n",
      "Train Epoch: 797 [45568/60000 (76%)] Loss: -1126.714844\n",
      "Train Epoch: 797 [56832/60000 (95%)] Loss: -1245.617554\n",
      "    epoch          : 797\n",
      "    loss           : -1320.5557945811818\n",
      "Train Epoch: 798 [512/60000 (1%)] Loss: -821.569824\n",
      "Train Epoch: 798 [11776/60000 (20%)] Loss: -1314.183716\n",
      "Train Epoch: 798 [23040/60000 (38%)] Loss: -1475.298828\n",
      "Train Epoch: 798 [34304/60000 (57%)] Loss: -1434.322021\n",
      "Train Epoch: 798 [45568/60000 (76%)] Loss: -1199.908203\n",
      "Train Epoch: 798 [56832/60000 (95%)] Loss: -1460.117676\n",
      "    epoch          : 798\n",
      "    loss           : -1299.5103995975128\n",
      "Train Epoch: 799 [512/60000 (1%)] Loss: -1474.553589\n",
      "Train Epoch: 799 [11776/60000 (20%)] Loss: -1205.041504\n",
      "Train Epoch: 799 [23040/60000 (38%)] Loss: -1047.282959\n",
      "Train Epoch: 799 [34304/60000 (57%)] Loss: -1465.854980\n",
      "Train Epoch: 799 [45568/60000 (76%)] Loss: -1109.939575\n",
      "Train Epoch: 799 [56832/60000 (95%)] Loss: -1100.764648\n",
      "    epoch          : 799\n",
      "    loss           : -1307.4027046160509\n",
      "Train Epoch: 800 [512/60000 (1%)] Loss: -1209.512573\n",
      "Train Epoch: 800 [11776/60000 (20%)] Loss: -1465.616577\n",
      "Train Epoch: 800 [23040/60000 (38%)] Loss: -1273.588135\n",
      "Train Epoch: 800 [34304/60000 (57%)] Loss: -1480.493164\n",
      "Train Epoch: 800 [45568/60000 (76%)] Loss: -1479.014160\n",
      "Train Epoch: 800 [56832/60000 (95%)] Loss: -1463.746704\n",
      "    epoch          : 800\n",
      "    loss           : -1304.7021522306454\n",
      "Saving checkpoint: saved/models/Mnist_DeepGenerativeOperad/0127_111843/checkpoint-epoch800.pth ...\n",
      "Train Epoch: 801 [512/60000 (1%)] Loss: -1266.039185\n",
      "Train Epoch: 801 [11776/60000 (20%)] Loss: -1243.784668\n",
      "Train Epoch: 801 [23040/60000 (38%)] Loss: -1285.441040\n",
      "Train Epoch: 801 [34304/60000 (57%)] Loss: -1279.513916\n",
      "Train Epoch: 801 [45568/60000 (76%)] Loss: -1276.592285\n",
      "Train Epoch: 801 [56832/60000 (95%)] Loss: -1410.790527\n",
      "    epoch          : 801\n",
      "    loss           : -1295.3505200747043\n",
      "Train Epoch: 802 [512/60000 (1%)] Loss: -1442.760742\n",
      "Train Epoch: 802 [11776/60000 (20%)] Loss: -1309.680298\n",
      "Train Epoch: 802 [23040/60000 (38%)] Loss: -1438.477173\n",
      "Train Epoch: 802 [34304/60000 (57%)] Loss: -1254.473877\n",
      "Train Epoch: 802 [45568/60000 (76%)] Loss: -1258.475830\n",
      "Train Epoch: 802 [56832/60000 (95%)] Loss: -1425.823486\n",
      "    epoch          : 802\n",
      "    loss           : -1315.6808904443083\n",
      "Train Epoch: 803 [512/60000 (1%)] Loss: -1264.920776\n",
      "Train Epoch: 803 [11776/60000 (20%)] Loss: -1119.421143\n",
      "Train Epoch: 803 [23040/60000 (38%)] Loss: -1154.185547\n",
      "Train Epoch: 803 [34304/60000 (57%)] Loss: -1144.097046\n",
      "Train Epoch: 803 [45568/60000 (76%)] Loss: -1438.192139\n",
      "Train Epoch: 803 [56832/60000 (95%)] Loss: -1301.251221\n",
      "    epoch          : 803\n",
      "    loss           : -1287.0860837085097\n",
      "Train Epoch: 804 [512/60000 (1%)] Loss: -1326.202026\n",
      "Train Epoch: 804 [11776/60000 (20%)] Loss: -1155.766357\n",
      "Train Epoch: 804 [23040/60000 (38%)] Loss: -1284.172241\n",
      "Train Epoch: 804 [34304/60000 (57%)] Loss: -1092.890259\n",
      "Train Epoch: 804 [45568/60000 (76%)] Loss: -1152.294067\n",
      "Train Epoch: 804 [56832/60000 (95%)] Loss: -1300.846191\n",
      "    epoch          : 804\n",
      "    loss           : -1283.8147829562256\n",
      "Train Epoch: 805 [512/60000 (1%)] Loss: -1165.398682\n",
      "Train Epoch: 805 [11776/60000 (20%)] Loss: -1445.877930\n",
      "Train Epoch: 805 [23040/60000 (38%)] Loss: -1329.079468\n",
      "Train Epoch: 805 [34304/60000 (57%)] Loss: -1259.000244\n",
      "Train Epoch: 805 [45568/60000 (76%)] Loss: -1423.709717\n",
      "Train Epoch: 805 [56832/60000 (95%)] Loss: -1332.473999\n",
      "    epoch          : 805\n",
      "    loss           : -1330.6673899505097\n",
      "Train Epoch: 806 [512/60000 (1%)] Loss: -1274.959717\n",
      "Train Epoch: 806 [11776/60000 (20%)] Loss: -1265.623657\n",
      "Train Epoch: 806 [23040/60000 (38%)] Loss: -1337.457764\n",
      "Train Epoch: 806 [34304/60000 (57%)] Loss: -1190.362427\n",
      "Train Epoch: 806 [45568/60000 (76%)] Loss: -1288.767090\n",
      "Train Epoch: 806 [56832/60000 (95%)] Loss: -1277.088745\n",
      "    epoch          : 806\n",
      "    loss           : -1299.219239315744\n",
      "Train Epoch: 807 [512/60000 (1%)] Loss: -1336.399780\n",
      "Train Epoch: 807 [11776/60000 (20%)] Loss: -1468.571777\n",
      "Train Epoch: 807 [23040/60000 (38%)] Loss: -1209.738525\n",
      "Train Epoch: 807 [34304/60000 (57%)] Loss: -1119.407959\n",
      "Train Epoch: 807 [45568/60000 (76%)] Loss: -1154.619385\n",
      "Train Epoch: 807 [56832/60000 (95%)] Loss: -1408.391357\n",
      "    epoch          : 807\n",
      "    loss           : -1290.9634289068017\n",
      "Train Epoch: 808 [512/60000 (1%)] Loss: -1283.270264\n",
      "Train Epoch: 808 [11776/60000 (20%)] Loss: -1295.869629\n",
      "Train Epoch: 808 [23040/60000 (38%)] Loss: -1153.976807\n",
      "Train Epoch: 808 [34304/60000 (57%)] Loss: -1284.918457\n",
      "Train Epoch: 808 [45568/60000 (76%)] Loss: -1108.171631\n",
      "Train Epoch: 808 [56832/60000 (95%)] Loss: -1145.382935\n",
      "    epoch          : 808\n",
      "    loss           : -1298.490107477048\n",
      "Train Epoch: 809 [512/60000 (1%)] Loss: -1439.453857\n",
      "Train Epoch: 809 [11776/60000 (20%)] Loss: -1148.293579\n",
      "Train Epoch: 809 [23040/60000 (38%)] Loss: -1332.731812\n",
      "Train Epoch: 809 [34304/60000 (57%)] Loss: -1431.648926\n",
      "Train Epoch: 809 [45568/60000 (76%)] Loss: -941.679871\n",
      "Train Epoch: 809 [56832/60000 (95%)] Loss: -1310.136475\n",
      "    epoch          : 809\n",
      "    loss           : -1297.4573815986935\n",
      "Train Epoch: 810 [512/60000 (1%)] Loss: -1143.834473\n",
      "Train Epoch: 810 [11776/60000 (20%)] Loss: -1107.686523\n",
      "Train Epoch: 810 [23040/60000 (38%)] Loss: -1190.296875\n",
      "Train Epoch: 810 [34304/60000 (57%)] Loss: -1435.194092\n",
      "Train Epoch: 810 [45568/60000 (76%)] Loss: -1334.350586\n",
      "Train Epoch: 810 [56832/60000 (95%)] Loss: -1294.784790\n",
      "    epoch          : 810\n",
      "    loss           : -1316.5658996926861\n",
      "Train Epoch: 811 [512/60000 (1%)] Loss: -1498.459229\n",
      "Train Epoch: 811 [11776/60000 (20%)] Loss: -1223.243408\n",
      "Train Epoch: 811 [23040/60000 (38%)] Loss: -1192.844971\n",
      "Train Epoch: 811 [34304/60000 (57%)] Loss: -1340.170654\n",
      "Train Epoch: 811 [45568/60000 (76%)] Loss: -1365.453857\n",
      "Train Epoch: 811 [56832/60000 (95%)] Loss: -1039.255005\n",
      "    epoch          : 811\n",
      "    loss           : -1303.7620266844324\n",
      "Train Epoch: 812 [512/60000 (1%)] Loss: -1412.044922\n",
      "Train Epoch: 812 [11776/60000 (20%)] Loss: -1306.100342\n",
      "Train Epoch: 812 [23040/60000 (38%)] Loss: -1313.216431\n",
      "Train Epoch: 812 [34304/60000 (57%)] Loss: -1163.367432\n",
      "Train Epoch: 812 [45568/60000 (76%)] Loss: -1321.208008\n",
      "Train Epoch: 812 [56832/60000 (95%)] Loss: -1092.179321\n",
      "    epoch          : 812\n",
      "    loss           : -1301.3554639223605\n",
      "Train Epoch: 813 [512/60000 (1%)] Loss: -1071.210938\n",
      "Train Epoch: 813 [11776/60000 (20%)] Loss: -1445.533447\n",
      "Train Epoch: 813 [23040/60000 (38%)] Loss: -1318.848633\n",
      "Train Epoch: 813 [34304/60000 (57%)] Loss: -971.343506\n",
      "Train Epoch: 813 [45568/60000 (76%)] Loss: -1472.985107\n",
      "Train Epoch: 813 [56832/60000 (95%)] Loss: -1331.693604\n",
      "    epoch          : 813\n",
      "    loss           : -1276.5931482692222\n",
      "Train Epoch: 814 [512/60000 (1%)] Loss: -1413.676025\n",
      "Train Epoch: 814 [11776/60000 (20%)] Loss: -1320.445435\n",
      "Train Epoch: 814 [23040/60000 (38%)] Loss: -963.833618\n",
      "Train Epoch: 814 [34304/60000 (57%)] Loss: -1114.217041\n",
      "Train Epoch: 814 [45568/60000 (76%)] Loss: -1440.719971\n",
      "Train Epoch: 814 [56832/60000 (95%)] Loss: -1453.914551\n",
      "    epoch          : 814\n",
      "    loss           : -1289.6764533263815\n",
      "Train Epoch: 815 [512/60000 (1%)] Loss: -952.993286\n",
      "Train Epoch: 815 [11776/60000 (20%)] Loss: -1417.988037\n",
      "Train Epoch: 815 [23040/60000 (38%)] Loss: -1411.111938\n",
      "Train Epoch: 815 [34304/60000 (57%)] Loss: -1304.782959\n",
      "Train Epoch: 815 [45568/60000 (76%)] Loss: -1442.620239\n",
      "Train Epoch: 815 [56832/60000 (95%)] Loss: -1346.288818\n",
      "    epoch          : 815\n",
      "    loss           : -1300.583468334823\n",
      "Train Epoch: 816 [512/60000 (1%)] Loss: -1442.121582\n",
      "Train Epoch: 816 [11776/60000 (20%)] Loss: -1126.379395\n",
      "Train Epoch: 816 [23040/60000 (38%)] Loss: -1423.738281\n",
      "Train Epoch: 816 [34304/60000 (57%)] Loss: -1467.421631\n",
      "Train Epoch: 816 [45568/60000 (76%)] Loss: -1432.935181\n",
      "Train Epoch: 816 [56832/60000 (95%)] Loss: -1372.301147\n",
      "    epoch          : 816\n",
      "    loss           : -1296.6166069763528\n",
      "Train Epoch: 817 [512/60000 (1%)] Loss: -1423.607666\n",
      "Train Epoch: 817 [11776/60000 (20%)] Loss: -1307.651001\n",
      "Train Epoch: 817 [23040/60000 (38%)] Loss: -1447.757812\n",
      "Train Epoch: 817 [34304/60000 (57%)] Loss: -987.553711\n",
      "Train Epoch: 817 [45568/60000 (76%)] Loss: -1321.050659\n",
      "Train Epoch: 817 [56832/60000 (95%)] Loss: -1307.557373\n",
      "    epoch          : 817\n",
      "    loss           : -1320.7888824980137\n",
      "Train Epoch: 818 [512/60000 (1%)] Loss: -1253.886719\n",
      "Train Epoch: 818 [11776/60000 (20%)] Loss: -1325.546265\n",
      "Train Epoch: 818 [23040/60000 (38%)] Loss: -1311.249390\n",
      "Train Epoch: 818 [34304/60000 (57%)] Loss: -1222.275269\n",
      "Train Epoch: 818 [45568/60000 (76%)] Loss: -1304.776001\n",
      "Train Epoch: 818 [56832/60000 (95%)] Loss: -1445.536865\n",
      "    epoch          : 818\n",
      "    loss           : -1301.7953249828965\n",
      "Train Epoch: 819 [512/60000 (1%)] Loss: -775.430664\n",
      "Train Epoch: 819 [11776/60000 (20%)] Loss: -1436.032959\n",
      "Train Epoch: 819 [23040/60000 (38%)] Loss: -1446.970093\n",
      "Train Epoch: 819 [34304/60000 (57%)] Loss: -1265.443115\n",
      "Train Epoch: 819 [45568/60000 (76%)] Loss: -1471.045166\n",
      "Train Epoch: 819 [56832/60000 (95%)] Loss: -1396.899048\n",
      "    epoch          : 819\n",
      "    loss           : -1286.02966618942\n",
      "Train Epoch: 820 [512/60000 (1%)] Loss: -1458.339966\n",
      "Train Epoch: 820 [11776/60000 (20%)] Loss: -1318.241943\n",
      "Train Epoch: 820 [23040/60000 (38%)] Loss: -1438.254395\n",
      "Train Epoch: 820 [34304/60000 (57%)] Loss: -1297.415527\n",
      "Train Epoch: 820 [45568/60000 (76%)] Loss: -1467.714111\n",
      "Train Epoch: 820 [56832/60000 (95%)] Loss: -1267.048340\n",
      "    epoch          : 820\n",
      "    loss           : -1307.8857213252008\n",
      "Train Epoch: 821 [512/60000 (1%)] Loss: -1112.259521\n",
      "Train Epoch: 821 [11776/60000 (20%)] Loss: -1246.913208\n",
      "Train Epoch: 821 [23040/60000 (38%)] Loss: -1413.883667\n",
      "Train Epoch: 821 [34304/60000 (57%)] Loss: -1298.653564\n",
      "Train Epoch: 821 [45568/60000 (76%)] Loss: -1141.392578\n",
      "Train Epoch: 821 [56832/60000 (95%)] Loss: -1318.299194\n",
      "    epoch          : 821\n",
      "    loss           : -1288.8693926967471\n",
      "Train Epoch: 822 [512/60000 (1%)] Loss: -1309.600220\n",
      "Train Epoch: 822 [11776/60000 (20%)] Loss: -1223.362183\n",
      "Train Epoch: 822 [23040/60000 (38%)] Loss: -1416.634399\n",
      "Train Epoch: 822 [34304/60000 (57%)] Loss: -1434.342285\n",
      "Train Epoch: 822 [45568/60000 (76%)] Loss: -1320.083008\n",
      "Train Epoch: 822 [56832/60000 (95%)] Loss: -1294.538452\n",
      "    epoch          : 822\n",
      "    loss           : -1302.3190473136256\n",
      "Train Epoch: 823 [512/60000 (1%)] Loss: -1141.491699\n",
      "Train Epoch: 823 [11776/60000 (20%)] Loss: -1430.252686\n",
      "Train Epoch: 823 [23040/60000 (38%)] Loss: -1456.297974\n",
      "Train Epoch: 823 [34304/60000 (57%)] Loss: -1255.499756\n",
      "Train Epoch: 823 [45568/60000 (76%)] Loss: -1024.510010\n",
      "Train Epoch: 823 [56832/60000 (95%)] Loss: -1335.574585\n",
      "    epoch          : 823\n",
      "    loss           : -1297.77825462212\n",
      "Train Epoch: 824 [512/60000 (1%)] Loss: -1274.724243\n",
      "Train Epoch: 824 [11776/60000 (20%)] Loss: -1338.755615\n",
      "Train Epoch: 824 [23040/60000 (38%)] Loss: -961.066528\n",
      "Train Epoch: 824 [34304/60000 (57%)] Loss: -1327.205200\n",
      "Train Epoch: 824 [45568/60000 (76%)] Loss: -1474.081665\n",
      "Train Epoch: 824 [56832/60000 (95%)] Loss: -1169.252197\n",
      "    epoch          : 824\n",
      "    loss           : -1323.3522859562588\n",
      "Train Epoch: 825 [512/60000 (1%)] Loss: -1291.313965\n",
      "Train Epoch: 825 [11776/60000 (20%)] Loss: -1475.945801\n",
      "Train Epoch: 825 [23040/60000 (38%)] Loss: -1342.982422\n",
      "Train Epoch: 825 [34304/60000 (57%)] Loss: -1009.890259\n",
      "Train Epoch: 825 [45568/60000 (76%)] Loss: -1071.128174\n",
      "Train Epoch: 825 [56832/60000 (95%)] Loss: -1418.561279\n",
      "    epoch          : 825\n",
      "    loss           : -1271.2354838053384\n",
      "Train Epoch: 826 [512/60000 (1%)] Loss: -1221.456177\n",
      "Train Epoch: 826 [11776/60000 (20%)] Loss: -1356.161377\n",
      "Train Epoch: 826 [23040/60000 (38%)] Loss: -1441.443970\n",
      "Train Epoch: 826 [34304/60000 (57%)] Loss: -1291.555176\n",
      "Train Epoch: 826 [45568/60000 (76%)] Loss: -1286.983398\n",
      "Train Epoch: 826 [56832/60000 (95%)] Loss: -1094.109619\n",
      "    epoch          : 826\n",
      "    loss           : -1297.6323945643537\n",
      "Train Epoch: 827 [512/60000 (1%)] Loss: -1268.518066\n",
      "Train Epoch: 827 [11776/60000 (20%)] Loss: -1154.255127\n",
      "Train Epoch: 827 [23040/60000 (38%)] Loss: -1444.066650\n",
      "Train Epoch: 827 [34304/60000 (57%)] Loss: -1140.787109\n",
      "Train Epoch: 827 [45568/60000 (76%)] Loss: -1296.266846\n",
      "Train Epoch: 827 [56832/60000 (95%)] Loss: -1181.712036\n",
      "    epoch          : 827\n",
      "    loss           : -1304.3769279523085\n",
      "Train Epoch: 828 [512/60000 (1%)] Loss: -1257.204834\n",
      "Train Epoch: 828 [11776/60000 (20%)] Loss: -1442.500610\n",
      "Train Epoch: 828 [23040/60000 (38%)] Loss: -1339.726196\n",
      "Train Epoch: 828 [34304/60000 (57%)] Loss: -1184.523438\n",
      "Train Epoch: 828 [45568/60000 (76%)] Loss: -1093.353516\n",
      "Train Epoch: 828 [56832/60000 (95%)] Loss: -1313.971436\n",
      "    epoch          : 828\n",
      "    loss           : -1288.9332937466895\n",
      "Train Epoch: 829 [512/60000 (1%)] Loss: -1427.561523\n",
      "Train Epoch: 829 [11776/60000 (20%)] Loss: -1435.371460\n",
      "Train Epoch: 829 [23040/60000 (38%)] Loss: -1430.974609\n",
      "Train Epoch: 829 [34304/60000 (57%)] Loss: -1259.456909\n",
      "Train Epoch: 829 [45568/60000 (76%)] Loss: -1270.576050\n",
      "Train Epoch: 829 [56832/60000 (95%)] Loss: -1206.063843\n",
      "    epoch          : 829\n",
      "    loss           : -1284.3239175397796\n",
      "Train Epoch: 830 [512/60000 (1%)] Loss: -1491.171021\n",
      "Train Epoch: 830 [11776/60000 (20%)] Loss: -1328.378174\n",
      "Train Epoch: 830 [23040/60000 (38%)] Loss: -1146.864746\n",
      "Train Epoch: 830 [34304/60000 (57%)] Loss: -1025.467041\n",
      "Train Epoch: 830 [45568/60000 (76%)] Loss: -1442.871460\n",
      "Train Epoch: 830 [56832/60000 (95%)] Loss: -1294.163086\n",
      "    epoch          : 830\n",
      "    loss           : -1292.1929978192863\n",
      "Train Epoch: 831 [512/60000 (1%)] Loss: -1098.221802\n",
      "Train Epoch: 831 [11776/60000 (20%)] Loss: -1306.657959\n",
      "Train Epoch: 831 [23040/60000 (38%)] Loss: -1195.103638\n",
      "Train Epoch: 831 [34304/60000 (57%)] Loss: -1117.008545\n",
      "Train Epoch: 831 [45568/60000 (76%)] Loss: -1256.489990\n",
      "Train Epoch: 831 [56832/60000 (95%)] Loss: -1296.604126\n",
      "    epoch          : 831\n",
      "    loss           : -1307.0491765771208\n",
      "Train Epoch: 832 [512/60000 (1%)] Loss: -1258.210693\n",
      "Train Epoch: 832 [11776/60000 (20%)] Loss: -1441.203491\n",
      "Train Epoch: 832 [23040/60000 (38%)] Loss: -1241.534790\n",
      "Train Epoch: 832 [34304/60000 (57%)] Loss: -1442.177124\n",
      "Train Epoch: 832 [45568/60000 (76%)] Loss: -1443.559570\n",
      "Train Epoch: 832 [56832/60000 (95%)] Loss: -1289.392334\n",
      "    epoch          : 832\n",
      "    loss           : -1288.92052791617\n",
      "Train Epoch: 833 [512/60000 (1%)] Loss: -1448.673950\n",
      "Train Epoch: 833 [11776/60000 (20%)] Loss: -1194.147827\n",
      "Train Epoch: 833 [23040/60000 (38%)] Loss: -1326.063843\n",
      "Train Epoch: 833 [34304/60000 (57%)] Loss: -1135.637695\n",
      "Train Epoch: 833 [45568/60000 (76%)] Loss: -1286.161377\n",
      "Train Epoch: 833 [56832/60000 (95%)] Loss: -1458.471313\n",
      "    epoch          : 833\n",
      "    loss           : -1301.6728594936221\n",
      "Train Epoch: 834 [512/60000 (1%)] Loss: -1156.570068\n",
      "Train Epoch: 834 [11776/60000 (20%)] Loss: -1468.417114\n",
      "Train Epoch: 834 [23040/60000 (38%)] Loss: -1289.583496\n",
      "Train Epoch: 834 [34304/60000 (57%)] Loss: -1304.373169\n",
      "Train Epoch: 834 [45568/60000 (76%)] Loss: -1265.203735\n",
      "Train Epoch: 834 [56832/60000 (95%)] Loss: -1118.040527\n",
      "    epoch          : 834\n",
      "    loss           : -1292.5325470832781\n",
      "Train Epoch: 835 [512/60000 (1%)] Loss: -1243.938965\n",
      "Train Epoch: 835 [11776/60000 (20%)] Loss: -1447.172974\n",
      "Train Epoch: 835 [23040/60000 (38%)] Loss: -1201.439087\n",
      "Train Epoch: 835 [34304/60000 (57%)] Loss: -1275.275024\n",
      "Train Epoch: 835 [45568/60000 (76%)] Loss: -1333.732910\n",
      "Train Epoch: 835 [56832/60000 (95%)] Loss: -1463.801147\n",
      "    epoch          : 835\n",
      "    loss           : -1314.2535522805767\n",
      "Train Epoch: 836 [512/60000 (1%)] Loss: -1481.336548\n",
      "Train Epoch: 836 [11776/60000 (20%)] Loss: -1257.860962\n",
      "Train Epoch: 836 [23040/60000 (38%)] Loss: -1448.702393\n",
      "Train Epoch: 836 [34304/60000 (57%)] Loss: -1446.220703\n",
      "Train Epoch: 836 [45568/60000 (76%)] Loss: -1338.559082\n",
      "Train Epoch: 836 [56832/60000 (95%)] Loss: -1491.753296\n",
      "    epoch          : 836\n",
      "    loss           : -1306.3040114580574\n",
      "Train Epoch: 837 [512/60000 (1%)] Loss: -1435.711182\n",
      "Train Epoch: 837 [11776/60000 (20%)] Loss: -1454.326172\n",
      "Train Epoch: 837 [23040/60000 (38%)] Loss: -1306.000488\n",
      "Train Epoch: 837 [34304/60000 (57%)] Loss: -1293.429810\n",
      "Train Epoch: 837 [45568/60000 (76%)] Loss: -1145.622681\n",
      "Train Epoch: 837 [56832/60000 (95%)] Loss: -1258.529053\n",
      "    epoch          : 837\n",
      "    loss           : -1301.8352714581679\n",
      "Train Epoch: 838 [512/60000 (1%)] Loss: -1152.695435\n",
      "Train Epoch: 838 [11776/60000 (20%)] Loss: -1329.402588\n",
      "Train Epoch: 838 [23040/60000 (38%)] Loss: -1109.927002\n",
      "Train Epoch: 838 [34304/60000 (57%)] Loss: -1154.343018\n",
      "Train Epoch: 838 [45568/60000 (76%)] Loss: -1400.449707\n",
      "Train Epoch: 838 [56832/60000 (95%)] Loss: -1313.205566\n",
      "    epoch          : 838\n",
      "    loss           : -1281.1168197373213\n",
      "Train Epoch: 839 [512/60000 (1%)] Loss: -1310.229126\n",
      "Train Epoch: 839 [11776/60000 (20%)] Loss: -1300.897583\n",
      "Train Epoch: 839 [23040/60000 (38%)] Loss: -1287.344849\n",
      "Train Epoch: 839 [34304/60000 (57%)] Loss: -1190.405029\n",
      "Train Epoch: 839 [45568/60000 (76%)] Loss: -1321.033081\n",
      "Train Epoch: 839 [56832/60000 (95%)] Loss: -1365.122314\n",
      "    epoch          : 839\n",
      "    loss           : -1307.0635420804642\n",
      "Train Epoch: 840 [512/60000 (1%)] Loss: -1435.503662\n",
      "Train Epoch: 840 [11776/60000 (20%)] Loss: -1479.436768\n",
      "Train Epoch: 840 [23040/60000 (38%)] Loss: -1290.382812\n",
      "Train Epoch: 840 [34304/60000 (57%)] Loss: -1290.129761\n",
      "Train Epoch: 840 [45568/60000 (76%)] Loss: -1463.675903\n",
      "Train Epoch: 840 [56832/60000 (95%)] Loss: -1460.784546\n",
      "    epoch          : 840\n",
      "    loss           : -1307.5745782367253\n",
      "Train Epoch: 841 [512/60000 (1%)] Loss: -1136.542603\n",
      "Train Epoch: 841 [11776/60000 (20%)] Loss: -1466.707275\n",
      "Train Epoch: 841 [23040/60000 (38%)] Loss: -1443.461182\n",
      "Train Epoch: 841 [34304/60000 (57%)] Loss: -1365.380615\n",
      "Train Epoch: 841 [45568/60000 (76%)] Loss: -1461.510742\n",
      "Train Epoch: 841 [56832/60000 (95%)] Loss: -1192.668457\n",
      "    epoch          : 841\n",
      "    loss           : -1304.1748724468684\n",
      "Train Epoch: 842 [512/60000 (1%)] Loss: -1158.725464\n",
      "Train Epoch: 842 [11776/60000 (20%)] Loss: -1502.198730\n",
      "Train Epoch: 842 [23040/60000 (38%)] Loss: -1451.571899\n",
      "Train Epoch: 842 [34304/60000 (57%)] Loss: -1154.811890\n",
      "Train Epoch: 842 [45568/60000 (76%)] Loss: -1341.782104\n",
      "Train Epoch: 842 [56832/60000 (95%)] Loss: -1485.656982\n",
      "    epoch          : 842\n",
      "    loss           : -1307.3113710220252\n",
      "Train Epoch: 843 [512/60000 (1%)] Loss: -1454.284302\n",
      "Train Epoch: 843 [11776/60000 (20%)] Loss: -1099.140503\n",
      "Train Epoch: 843 [23040/60000 (38%)] Loss: -1472.697021\n",
      "Train Epoch: 843 [34304/60000 (57%)] Loss: -1314.812012\n",
      "Train Epoch: 843 [45568/60000 (76%)] Loss: -1000.814941\n",
      "Train Epoch: 843 [56832/60000 (95%)] Loss: -1328.096436\n",
      "    epoch          : 843\n",
      "    loss           : -1306.614180225437\n",
      "Train Epoch: 844 [512/60000 (1%)] Loss: -1281.572388\n",
      "Train Epoch: 844 [11776/60000 (20%)] Loss: -1020.764404\n",
      "Train Epoch: 844 [23040/60000 (38%)] Loss: -870.614807\n",
      "Train Epoch: 844 [34304/60000 (57%)] Loss: -1491.020142\n",
      "Train Epoch: 844 [45568/60000 (76%)] Loss: -1297.082886\n",
      "Train Epoch: 844 [56832/60000 (95%)] Loss: -1296.583862\n",
      "    epoch          : 844\n",
      "    loss           : -1307.7018042957714\n",
      "Train Epoch: 845 [512/60000 (1%)] Loss: -1475.774292\n",
      "Train Epoch: 845 [11776/60000 (20%)] Loss: -1318.469604\n",
      "Train Epoch: 845 [23040/60000 (38%)] Loss: -1460.658691\n",
      "Train Epoch: 845 [34304/60000 (57%)] Loss: -1426.176636\n",
      "Train Epoch: 845 [45568/60000 (76%)] Loss: -1308.955322\n",
      "Train Epoch: 845 [56832/60000 (95%)] Loss: -1298.427368\n",
      "    epoch          : 845\n",
      "    loss           : -1322.7601442498676\n",
      "Train Epoch: 846 [512/60000 (1%)] Loss: -1429.072754\n",
      "Train Epoch: 846 [11776/60000 (20%)] Loss: -1484.544678\n",
      "Train Epoch: 846 [23040/60000 (38%)] Loss: -1316.165283\n",
      "Train Epoch: 846 [34304/60000 (57%)] Loss: -1472.411377\n",
      "Train Epoch: 846 [45568/60000 (76%)] Loss: -1335.047607\n",
      "Train Epoch: 846 [56832/60000 (95%)] Loss: -1351.277344\n",
      "    epoch          : 846\n",
      "    loss           : -1322.4062570690435\n",
      "Train Epoch: 847 [512/60000 (1%)] Loss: -1161.794189\n",
      "Train Epoch: 847 [11776/60000 (20%)] Loss: -1459.415161\n",
      "Train Epoch: 847 [23040/60000 (38%)] Loss: -1500.379639\n",
      "Train Epoch: 847 [34304/60000 (57%)] Loss: -1183.942261\n",
      "Train Epoch: 847 [45568/60000 (76%)] Loss: -1446.630859\n",
      "Train Epoch: 847 [56832/60000 (95%)] Loss: -1347.281860\n",
      "    epoch          : 847\n",
      "    loss           : -1300.4394915737003\n",
      "Train Epoch: 848 [512/60000 (1%)] Loss: -1344.072998\n",
      "Train Epoch: 848 [11776/60000 (20%)] Loss: -1328.621582\n",
      "Train Epoch: 848 [23040/60000 (38%)] Loss: -1079.336304\n",
      "Train Epoch: 848 [34304/60000 (57%)] Loss: -1162.389282\n",
      "Train Epoch: 848 [45568/60000 (76%)] Loss: -1272.700439\n",
      "Train Epoch: 848 [56832/60000 (95%)] Loss: -1284.816772\n",
      "    epoch          : 848\n",
      "    loss           : -1285.6404848260395\n",
      "Train Epoch: 849 [512/60000 (1%)] Loss: -1340.303711\n",
      "Train Epoch: 849 [11776/60000 (20%)] Loss: -1314.864502\n",
      "Train Epoch: 849 [23040/60000 (38%)] Loss: -1136.472534\n",
      "Train Epoch: 849 [34304/60000 (57%)] Loss: -1288.354126\n",
      "Train Epoch: 849 [45568/60000 (76%)] Loss: -1163.099121\n",
      "Train Epoch: 849 [56832/60000 (95%)] Loss: -1160.646240\n",
      "    epoch          : 849\n",
      "    loss           : -1318.752233472921\n",
      "Train Epoch: 850 [512/60000 (1%)] Loss: -1301.074951\n",
      "Train Epoch: 850 [11776/60000 (20%)] Loss: -1456.041626\n",
      "Train Epoch: 850 [23040/60000 (38%)] Loss: -1130.755371\n",
      "Train Epoch: 850 [34304/60000 (57%)] Loss: -1449.741577\n",
      "Train Epoch: 850 [45568/60000 (76%)] Loss: -1139.764404\n",
      "Train Epoch: 850 [56832/60000 (95%)] Loss: -1457.433594\n",
      "    epoch          : 850\n",
      "    loss           : -1318.0871538927324\n",
      "Train Epoch: 851 [512/60000 (1%)] Loss: -1307.312012\n",
      "Train Epoch: 851 [11776/60000 (20%)] Loss: -1175.747925\n",
      "Train Epoch: 851 [23040/60000 (38%)] Loss: -1290.252319\n",
      "Train Epoch: 851 [34304/60000 (57%)] Loss: -1346.359131\n",
      "Train Epoch: 851 [45568/60000 (76%)] Loss: -1489.085449\n",
      "Train Epoch: 851 [56832/60000 (95%)] Loss: -1146.573730\n",
      "    epoch          : 851\n",
      "    loss           : -1319.4520801608846\n",
      "Train Epoch: 852 [512/60000 (1%)] Loss: -1339.420776\n",
      "Train Epoch: 852 [11776/60000 (20%)] Loss: -1264.561646\n",
      "Train Epoch: 852 [23040/60000 (38%)] Loss: -1298.275757\n",
      "Train Epoch: 852 [34304/60000 (57%)] Loss: -1137.326294\n",
      "Train Epoch: 852 [45568/60000 (76%)] Loss: -1265.960938\n",
      "Train Epoch: 852 [56832/60000 (95%)] Loss: -1184.619629\n",
      "    epoch          : 852\n",
      "    loss           : -1312.4037744554423\n",
      "Train Epoch: 853 [512/60000 (1%)] Loss: -1448.187378\n",
      "Train Epoch: 853 [11776/60000 (20%)] Loss: -1348.404785\n",
      "Train Epoch: 853 [23040/60000 (38%)] Loss: -1182.939697\n",
      "Train Epoch: 853 [34304/60000 (57%)] Loss: -1490.466064\n",
      "Train Epoch: 853 [45568/60000 (76%)] Loss: -1274.552368\n",
      "Train Epoch: 853 [56832/60000 (95%)] Loss: -1176.451660\n",
      "    epoch          : 853\n",
      "    loss           : -1299.187912418344\n",
      "Train Epoch: 854 [512/60000 (1%)] Loss: -1442.808350\n",
      "Train Epoch: 854 [11776/60000 (20%)] Loss: -1098.147583\n",
      "Train Epoch: 854 [23040/60000 (38%)] Loss: -1343.729858\n",
      "Train Epoch: 854 [34304/60000 (57%)] Loss: -951.519775\n",
      "Train Epoch: 854 [45568/60000 (76%)] Loss: -1226.567627\n",
      "Train Epoch: 854 [56832/60000 (95%)] Loss: -1376.635742\n",
      "    epoch          : 854\n",
      "    loss           : -1287.7063769324352\n",
      "Train Epoch: 855 [512/60000 (1%)] Loss: -1308.270508\n",
      "Train Epoch: 855 [11776/60000 (20%)] Loss: -1316.976807\n",
      "Train Epoch: 855 [23040/60000 (38%)] Loss: -1133.139038\n",
      "Train Epoch: 855 [34304/60000 (57%)] Loss: -1342.132446\n",
      "Train Epoch: 855 [45568/60000 (76%)] Loss: -1263.062378\n",
      "Train Epoch: 855 [56832/60000 (95%)] Loss: -1339.954712\n",
      "    epoch          : 855\n",
      "    loss           : -1308.0634439759335\n",
      "Train Epoch: 856 [512/60000 (1%)] Loss: -1490.796997\n",
      "Train Epoch: 856 [11776/60000 (20%)] Loss: -1114.843506\n",
      "Train Epoch: 856 [23040/60000 (38%)] Loss: -1309.143311\n",
      "Train Epoch: 856 [34304/60000 (57%)] Loss: -1353.022339\n",
      "Train Epoch: 856 [45568/60000 (76%)] Loss: -1212.084717\n",
      "Train Epoch: 856 [56832/60000 (95%)] Loss: -1194.728271\n",
      "    epoch          : 856\n",
      "    loss           : -1312.281668625309\n",
      "Train Epoch: 857 [512/60000 (1%)] Loss: -1401.090942\n",
      "Train Epoch: 857 [11776/60000 (20%)] Loss: -1280.522095\n",
      "Train Epoch: 857 [23040/60000 (38%)] Loss: -1333.959229\n",
      "Train Epoch: 857 [34304/60000 (57%)] Loss: -1415.307129\n",
      "Train Epoch: 857 [45568/60000 (76%)] Loss: -1170.758911\n",
      "Train Epoch: 857 [56832/60000 (95%)] Loss: -1023.090027\n",
      "    epoch          : 857\n",
      "    loss           : -1326.6198092530676\n",
      "Train Epoch: 858 [512/60000 (1%)] Loss: -1175.488770\n",
      "Train Epoch: 858 [11776/60000 (20%)] Loss: -1079.912476\n",
      "Train Epoch: 858 [23040/60000 (38%)] Loss: -1299.325928\n",
      "Train Epoch: 858 [34304/60000 (57%)] Loss: -1472.139771\n",
      "Train Epoch: 858 [45568/60000 (76%)] Loss: -1281.215454\n",
      "Train Epoch: 858 [56832/60000 (95%)] Loss: -1121.776978\n",
      "    epoch          : 858\n",
      "    loss           : -1303.6956338828568\n",
      "Train Epoch: 859 [512/60000 (1%)] Loss: -1153.345581\n",
      "Train Epoch: 859 [11776/60000 (20%)] Loss: -1462.606934\n",
      "Train Epoch: 859 [23040/60000 (38%)] Loss: -1299.921631\n",
      "Train Epoch: 859 [34304/60000 (57%)] Loss: -1451.037720\n",
      "Train Epoch: 859 [45568/60000 (76%)] Loss: -1468.303711\n",
      "Train Epoch: 859 [56832/60000 (95%)] Loss: -1322.676758\n",
      "    epoch          : 859\n",
      "    loss           : -1297.8110082594014\n",
      "Train Epoch: 860 [512/60000 (1%)] Loss: -1478.671997\n",
      "Train Epoch: 860 [11776/60000 (20%)] Loss: -1068.392334\n",
      "Train Epoch: 860 [23040/60000 (38%)] Loss: -1311.598633\n",
      "Train Epoch: 860 [34304/60000 (57%)] Loss: -1483.475830\n",
      "Train Epoch: 860 [45568/60000 (76%)] Loss: -1187.780762\n",
      "Train Epoch: 860 [56832/60000 (95%)] Loss: -1285.778320\n",
      "    epoch          : 860\n",
      "    loss           : -1290.5150465453412\n",
      "Train Epoch: 861 [512/60000 (1%)] Loss: -1240.703857\n",
      "Train Epoch: 861 [11776/60000 (20%)] Loss: -1294.677002\n",
      "Train Epoch: 861 [23040/60000 (38%)] Loss: -1341.378540\n",
      "Train Epoch: 861 [34304/60000 (57%)] Loss: -1252.207153\n",
      "Train Epoch: 861 [45568/60000 (76%)] Loss: -1339.299561\n",
      "Train Epoch: 861 [56832/60000 (95%)] Loss: -1471.091797\n",
      "    epoch          : 861\n",
      "    loss           : -1295.1906408967272\n",
      "Train Epoch: 862 [512/60000 (1%)] Loss: -1285.280762\n",
      "Train Epoch: 862 [11776/60000 (20%)] Loss: -1313.964600\n",
      "Train Epoch: 862 [23040/60000 (38%)] Loss: -1082.138428\n",
      "Train Epoch: 862 [34304/60000 (57%)] Loss: -1208.035645\n",
      "Train Epoch: 862 [45568/60000 (76%)] Loss: -1150.874634\n",
      "Train Epoch: 862 [56832/60000 (95%)] Loss: -1131.352905\n",
      "    epoch          : 862\n",
      "    loss           : -1293.879835225768\n",
      "Train Epoch: 863 [512/60000 (1%)] Loss: -1241.146729\n",
      "Train Epoch: 863 [11776/60000 (20%)] Loss: -1341.629150\n",
      "Train Epoch: 863 [23040/60000 (38%)] Loss: -1321.924194\n",
      "Train Epoch: 863 [34304/60000 (57%)] Loss: -1499.878418\n",
      "Train Epoch: 863 [45568/60000 (76%)] Loss: -1365.435425\n",
      "Train Epoch: 863 [56832/60000 (95%)] Loss: -1280.433838\n",
      "    epoch          : 863\n",
      "    loss           : -1304.4836974063162\n",
      "Train Epoch: 864 [512/60000 (1%)] Loss: -1314.943359\n",
      "Train Epoch: 864 [11776/60000 (20%)] Loss: -1268.248657\n",
      "Train Epoch: 864 [23040/60000 (38%)] Loss: -1473.562622\n",
      "Train Epoch: 864 [34304/60000 (57%)] Loss: -1339.076660\n",
      "Train Epoch: 864 [45568/60000 (76%)] Loss: -1478.334229\n",
      "Train Epoch: 864 [56832/60000 (95%)] Loss: -1301.642700\n",
      "    epoch          : 864\n",
      "    loss           : -1306.1853387692554\n",
      "Train Epoch: 865 [512/60000 (1%)] Loss: -1265.164795\n",
      "Train Epoch: 865 [11776/60000 (20%)] Loss: -1454.963501\n",
      "Train Epoch: 865 [23040/60000 (38%)] Loss: -1428.379395\n",
      "Train Epoch: 865 [34304/60000 (57%)] Loss: -1478.756348\n",
      "Train Epoch: 865 [45568/60000 (76%)] Loss: -1421.167358\n",
      "Train Epoch: 865 [56832/60000 (95%)] Loss: -1321.821289\n",
      "    epoch          : 865\n",
      "    loss           : -1300.7732288770083\n",
      "Train Epoch: 866 [512/60000 (1%)] Loss: -1167.710327\n",
      "Train Epoch: 866 [11776/60000 (20%)] Loss: -1328.960815\n",
      "Train Epoch: 866 [23040/60000 (38%)] Loss: -1259.465454\n",
      "Train Epoch: 866 [34304/60000 (57%)] Loss: -1464.343750\n",
      "Train Epoch: 866 [45568/60000 (76%)] Loss: -1119.854126\n",
      "Train Epoch: 866 [56832/60000 (95%)] Loss: -1293.589600\n",
      "    epoch          : 866\n",
      "    loss           : -1301.2568735241216\n",
      "Train Epoch: 867 [512/60000 (1%)] Loss: -1268.737427\n",
      "Train Epoch: 867 [11776/60000 (20%)] Loss: -1329.483154\n",
      "Train Epoch: 867 [23040/60000 (38%)] Loss: -1340.294189\n",
      "Train Epoch: 867 [34304/60000 (57%)] Loss: -1471.195435\n",
      "Train Epoch: 867 [45568/60000 (76%)] Loss: -1306.746338\n",
      "Train Epoch: 867 [56832/60000 (95%)] Loss: -1437.702271\n",
      "    epoch          : 867\n",
      "    loss           : -1300.4896431615798\n",
      "Train Epoch: 868 [512/60000 (1%)] Loss: -1258.830078\n",
      "Train Epoch: 868 [11776/60000 (20%)] Loss: -1288.825806\n",
      "Train Epoch: 868 [23040/60000 (38%)] Loss: -1495.182251\n",
      "Train Epoch: 868 [34304/60000 (57%)] Loss: -1410.595459\n",
      "Train Epoch: 868 [45568/60000 (76%)] Loss: -1194.436157\n",
      "Train Epoch: 868 [56832/60000 (95%)] Loss: -1441.586914\n",
      "    epoch          : 868\n",
      "    loss           : -1294.724686962063\n",
      "Train Epoch: 869 [512/60000 (1%)] Loss: -1439.583984\n",
      "Train Epoch: 869 [11776/60000 (20%)] Loss: -1449.822266\n",
      "Train Epoch: 869 [23040/60000 (38%)] Loss: -1315.353027\n",
      "Train Epoch: 869 [34304/60000 (57%)] Loss: -1435.358521\n",
      "Train Epoch: 869 [45568/60000 (76%)] Loss: -1338.532227\n",
      "Train Epoch: 869 [56832/60000 (95%)] Loss: -1271.422852\n",
      "    epoch          : 869\n",
      "    loss           : -1304.4675279175494\n",
      "Train Epoch: 870 [512/60000 (1%)] Loss: -1229.937500\n",
      "Train Epoch: 870 [11776/60000 (20%)] Loss: -1101.659546\n",
      "Train Epoch: 870 [23040/60000 (38%)] Loss: -1308.911133\n",
      "Train Epoch: 870 [34304/60000 (57%)] Loss: -1335.820557\n",
      "Train Epoch: 870 [45568/60000 (76%)] Loss: -1175.763184\n",
      "Train Epoch: 870 [56832/60000 (95%)] Loss: -1314.377563\n",
      "    epoch          : 870\n",
      "    loss           : -1305.4088560632395\n",
      "Train Epoch: 871 [512/60000 (1%)] Loss: -1305.770874\n",
      "Train Epoch: 871 [11776/60000 (20%)] Loss: -1480.838501\n",
      "Train Epoch: 871 [23040/60000 (38%)] Loss: -1185.530518\n",
      "Train Epoch: 871 [34304/60000 (57%)] Loss: -1476.216553\n",
      "Train Epoch: 871 [45568/60000 (76%)] Loss: -796.304321\n",
      "Train Epoch: 871 [56832/60000 (95%)] Loss: -1138.891846\n",
      "    epoch          : 871\n",
      "    loss           : -1298.6355214954096\n",
      "Train Epoch: 872 [512/60000 (1%)] Loss: -975.017944\n",
      "Train Epoch: 872 [11776/60000 (20%)] Loss: -1277.082886\n",
      "Train Epoch: 872 [23040/60000 (38%)] Loss: -1171.243896\n",
      "Train Epoch: 872 [34304/60000 (57%)] Loss: -1327.738037\n",
      "Train Epoch: 872 [45568/60000 (76%)] Loss: -1338.423706\n",
      "Train Epoch: 872 [56832/60000 (95%)] Loss: -1308.898071\n",
      "    epoch          : 872\n",
      "    loss           : -1280.4979134252517\n",
      "Train Epoch: 873 [512/60000 (1%)] Loss: -1456.432251\n",
      "Train Epoch: 873 [11776/60000 (20%)] Loss: -1100.512329\n",
      "Train Epoch: 873 [23040/60000 (38%)] Loss: -1165.978027\n",
      "Train Epoch: 873 [34304/60000 (57%)] Loss: -1237.665527\n",
      "Train Epoch: 873 [45568/60000 (76%)] Loss: -1196.356201\n",
      "Train Epoch: 873 [56832/60000 (95%)] Loss: -1173.376953\n",
      "    epoch          : 873\n",
      "    loss           : -1310.4497537559037\n",
      "Train Epoch: 874 [512/60000 (1%)] Loss: -1458.603271\n",
      "Train Epoch: 874 [11776/60000 (20%)] Loss: -1034.471558\n",
      "Train Epoch: 874 [23040/60000 (38%)] Loss: -1360.095703\n",
      "Train Epoch: 874 [34304/60000 (57%)] Loss: -1223.733643\n",
      "Train Epoch: 874 [45568/60000 (76%)] Loss: -1269.682251\n",
      "Train Epoch: 874 [56832/60000 (95%)] Loss: -1183.526367\n",
      "    epoch          : 874\n",
      "    loss           : -1291.1707529186529\n",
      "Train Epoch: 875 [512/60000 (1%)] Loss: -1264.313843\n",
      "Train Epoch: 875 [11776/60000 (20%)] Loss: -1360.366211\n",
      "Train Epoch: 875 [23040/60000 (38%)] Loss: -1335.313477\n",
      "Train Epoch: 875 [34304/60000 (57%)] Loss: -1304.695068\n",
      "Train Epoch: 875 [45568/60000 (76%)] Loss: -1345.922852\n",
      "Train Epoch: 875 [56832/60000 (95%)] Loss: -1181.185059\n",
      "    epoch          : 875\n",
      "    loss           : -1298.8918496686858\n",
      "Train Epoch: 876 [512/60000 (1%)] Loss: -1285.715454\n",
      "Train Epoch: 876 [11776/60000 (20%)] Loss: -1286.851807\n",
      "Train Epoch: 876 [23040/60000 (38%)] Loss: -1154.441284\n",
      "Train Epoch: 876 [34304/60000 (57%)] Loss: -1254.494995\n",
      "Train Epoch: 876 [45568/60000 (76%)] Loss: -1496.333496\n",
      "Train Epoch: 876 [56832/60000 (95%)] Loss: -1184.936401\n",
      "    epoch          : 876\n",
      "    loss           : -1285.0916623907574\n",
      "Train Epoch: 877 [512/60000 (1%)] Loss: -1406.894043\n",
      "Train Epoch: 877 [11776/60000 (20%)] Loss: -1253.502319\n",
      "Train Epoch: 877 [23040/60000 (38%)] Loss: -1322.285034\n",
      "Train Epoch: 877 [34304/60000 (57%)] Loss: -1317.456055\n",
      "Train Epoch: 877 [45568/60000 (76%)] Loss: -1499.156860\n",
      "Train Epoch: 877 [56832/60000 (95%)] Loss: -1242.446167\n",
      "    epoch          : 877\n",
      "    loss           : -1311.1742760609773\n",
      "Train Epoch: 878 [512/60000 (1%)] Loss: -1158.449707\n",
      "Train Epoch: 878 [11776/60000 (20%)] Loss: -1034.948608\n",
      "Train Epoch: 878 [23040/60000 (38%)] Loss: -1430.098145\n",
      "Train Epoch: 878 [34304/60000 (57%)] Loss: -1447.863770\n",
      "Train Epoch: 878 [45568/60000 (76%)] Loss: -1128.184570\n",
      "Train Epoch: 878 [56832/60000 (95%)] Loss: -1176.606445\n",
      "    epoch          : 878\n",
      "    loss           : -1321.4102476303185\n",
      "Train Epoch: 879 [512/60000 (1%)] Loss: -1353.257568\n",
      "Train Epoch: 879 [11776/60000 (20%)] Loss: -1160.661743\n",
      "Train Epoch: 879 [23040/60000 (38%)] Loss: -1289.412354\n",
      "Train Epoch: 879 [34304/60000 (57%)] Loss: -1321.734131\n",
      "Train Epoch: 879 [45568/60000 (76%)] Loss: -1157.865479\n",
      "Train Epoch: 879 [56832/60000 (95%)] Loss: -1302.591431\n",
      "    epoch          : 879\n",
      "    loss           : -1301.6054371979278\n",
      "Train Epoch: 880 [512/60000 (1%)] Loss: -1292.403442\n",
      "Train Epoch: 880 [11776/60000 (20%)] Loss: -1484.223511\n",
      "Train Epoch: 880 [23040/60000 (38%)] Loss: -1263.083252\n",
      "Train Epoch: 880 [34304/60000 (57%)] Loss: -1294.781738\n",
      "Train Epoch: 880 [45568/60000 (76%)] Loss: -1444.569702\n",
      "Train Epoch: 880 [56832/60000 (95%)] Loss: -1351.664185\n",
      "    epoch          : 880\n",
      "    loss           : -1301.8687595863128\n",
      "Train Epoch: 881 [512/60000 (1%)] Loss: -1190.845215\n",
      "Train Epoch: 881 [11776/60000 (20%)] Loss: -1331.114990\n",
      "Train Epoch: 881 [23040/60000 (38%)] Loss: -1263.940308\n",
      "Train Epoch: 881 [34304/60000 (57%)] Loss: -1453.512695\n",
      "Train Epoch: 881 [45568/60000 (76%)] Loss: -1484.606445\n",
      "Train Epoch: 881 [56832/60000 (95%)] Loss: -1327.782227\n",
      "    epoch          : 881\n",
      "    loss           : -1297.5012107030145\n",
      "Train Epoch: 882 [512/60000 (1%)] Loss: -1173.364258\n",
      "Train Epoch: 882 [11776/60000 (20%)] Loss: -1008.194092\n",
      "Train Epoch: 882 [23040/60000 (38%)] Loss: -1290.101929\n",
      "Train Epoch: 882 [34304/60000 (57%)] Loss: -1346.313599\n",
      "Train Epoch: 882 [45568/60000 (76%)] Loss: -1300.828613\n",
      "Train Epoch: 882 [56832/60000 (95%)] Loss: -1299.592285\n",
      "    epoch          : 882\n",
      "    loss           : -1277.7670951886366\n",
      "Train Epoch: 883 [512/60000 (1%)] Loss: -987.604614\n",
      "Train Epoch: 883 [11776/60000 (20%)] Loss: -955.706909\n",
      "Train Epoch: 883 [23040/60000 (38%)] Loss: -1284.529297\n",
      "Train Epoch: 883 [34304/60000 (57%)] Loss: -1507.158203\n",
      "Train Epoch: 883 [45568/60000 (76%)] Loss: -1259.006836\n",
      "Train Epoch: 883 [56832/60000 (95%)] Loss: -1475.366943\n",
      "    epoch          : 883\n",
      "    loss           : -1296.3272241279903\n",
      "Train Epoch: 884 [512/60000 (1%)] Loss: -1124.427002\n",
      "Train Epoch: 884 [11776/60000 (20%)] Loss: -1110.612427\n",
      "Train Epoch: 884 [23040/60000 (38%)] Loss: -1283.808594\n",
      "Train Epoch: 884 [34304/60000 (57%)] Loss: -1273.789917\n",
      "Train Epoch: 884 [45568/60000 (76%)] Loss: -1207.517334\n",
      "Train Epoch: 884 [56832/60000 (95%)] Loss: -1319.742432\n",
      "    epoch          : 884\n",
      "    loss           : -1304.5745889264983\n",
      "Train Epoch: 885 [512/60000 (1%)] Loss: -1123.009399\n",
      "Train Epoch: 885 [11776/60000 (20%)] Loss: -1476.792847\n",
      "Train Epoch: 885 [23040/60000 (38%)] Loss: -1433.160400\n",
      "Train Epoch: 885 [34304/60000 (57%)] Loss: -1161.837402\n",
      "Train Epoch: 885 [45568/60000 (76%)] Loss: -1490.292603\n",
      "Train Epoch: 885 [56832/60000 (95%)] Loss: -1345.780518\n",
      "    epoch          : 885\n",
      "    loss           : -1316.2181318897312\n",
      "Train Epoch: 886 [512/60000 (1%)] Loss: -1477.194214\n",
      "Train Epoch: 886 [11776/60000 (20%)] Loss: -982.458069\n",
      "Train Epoch: 886 [23040/60000 (38%)] Loss: -1481.835205\n",
      "Train Epoch: 886 [34304/60000 (57%)] Loss: -1484.266357\n",
      "Train Epoch: 886 [45568/60000 (76%)] Loss: -1349.722290\n",
      "Train Epoch: 886 [56832/60000 (95%)] Loss: -1102.190674\n",
      "    epoch          : 886\n",
      "    loss           : -1304.370482019112\n",
      "Train Epoch: 887 [512/60000 (1%)] Loss: -1463.958496\n",
      "Train Epoch: 887 [11776/60000 (20%)] Loss: -1268.910645\n",
      "Train Epoch: 887 [23040/60000 (38%)] Loss: -1235.126221\n",
      "Train Epoch: 887 [34304/60000 (57%)] Loss: -1221.127197\n",
      "Train Epoch: 887 [45568/60000 (76%)] Loss: -1451.790283\n",
      "Train Epoch: 887 [56832/60000 (95%)] Loss: -1496.591919\n",
      "    epoch          : 887\n",
      "    loss           : -1322.561783440369\n",
      "Train Epoch: 888 [512/60000 (1%)] Loss: -1424.859497\n",
      "Train Epoch: 888 [11776/60000 (20%)] Loss: -1135.832520\n",
      "Train Epoch: 888 [23040/60000 (38%)] Loss: -1332.794556\n",
      "Train Epoch: 888 [34304/60000 (57%)] Loss: -844.387146\n",
      "Train Epoch: 888 [45568/60000 (76%)] Loss: -1475.224609\n",
      "Train Epoch: 888 [56832/60000 (95%)] Loss: -1270.635986\n",
      "    epoch          : 888\n",
      "    loss           : -1298.4113602288026\n",
      "Train Epoch: 889 [512/60000 (1%)] Loss: -1463.307861\n",
      "Train Epoch: 889 [11776/60000 (20%)] Loss: -1142.892578\n",
      "Train Epoch: 889 [23040/60000 (38%)] Loss: -1426.406616\n",
      "Train Epoch: 889 [34304/60000 (57%)] Loss: -1454.002075\n",
      "Train Epoch: 889 [45568/60000 (76%)] Loss: -1343.373779\n",
      "Train Epoch: 889 [56832/60000 (95%)] Loss: -1354.363525\n",
      "    epoch          : 889\n",
      "    loss           : -1324.0534609347412\n",
      "Train Epoch: 890 [512/60000 (1%)] Loss: -1430.762939\n",
      "Train Epoch: 890 [11776/60000 (20%)] Loss: -1279.006592\n",
      "Train Epoch: 890 [23040/60000 (38%)] Loss: -1321.454834\n",
      "Train Epoch: 890 [34304/60000 (57%)] Loss: -1215.674927\n",
      "Train Epoch: 890 [45568/60000 (76%)] Loss: -1451.006104\n",
      "Train Epoch: 890 [56832/60000 (95%)] Loss: -1339.906616\n",
      "    epoch          : 890\n",
      "    loss           : -1301.1540194581457\n",
      "Train Epoch: 891 [512/60000 (1%)] Loss: -1502.235962\n",
      "Train Epoch: 891 [11776/60000 (20%)] Loss: -1315.988892\n",
      "Train Epoch: 891 [23040/60000 (38%)] Loss: -1510.905762\n",
      "Train Epoch: 891 [34304/60000 (57%)] Loss: -1424.498047\n",
      "Train Epoch: 891 [45568/60000 (76%)] Loss: -1271.772217\n",
      "Train Epoch: 891 [56832/60000 (95%)] Loss: -1315.936768\n",
      "    epoch          : 891\n",
      "    loss           : -1294.7786639369815\n",
      "Train Epoch: 892 [512/60000 (1%)] Loss: -1265.023804\n",
      "Train Epoch: 892 [11776/60000 (20%)] Loss: -1285.191528\n",
      "Train Epoch: 892 [23040/60000 (38%)] Loss: -1333.109253\n",
      "Train Epoch: 892 [34304/60000 (57%)] Loss: -1471.667480\n",
      "Train Epoch: 892 [45568/60000 (76%)] Loss: -1463.727417\n",
      "Train Epoch: 892 [56832/60000 (95%)] Loss: -1264.072632\n",
      "    epoch          : 892\n",
      "    loss           : -1310.961486471575\n",
      "Train Epoch: 893 [512/60000 (1%)] Loss: -1225.843994\n",
      "Train Epoch: 893 [11776/60000 (20%)] Loss: -1304.223145\n",
      "Train Epoch: 893 [23040/60000 (38%)] Loss: -1306.887207\n",
      "Train Epoch: 893 [34304/60000 (57%)] Loss: -1150.797363\n",
      "Train Epoch: 893 [45568/60000 (76%)] Loss: -1129.536133\n",
      "Train Epoch: 893 [56832/60000 (95%)] Loss: -1248.826660\n",
      "    epoch          : 893\n",
      "    loss           : -1284.1233551542637\n",
      "Train Epoch: 894 [512/60000 (1%)] Loss: -1411.939087\n",
      "Train Epoch: 894 [11776/60000 (20%)] Loss: -1295.348511\n",
      "Train Epoch: 894 [23040/60000 (38%)] Loss: -1345.925171\n",
      "Train Epoch: 894 [34304/60000 (57%)] Loss: -1455.888672\n",
      "Train Epoch: 894 [45568/60000 (76%)] Loss: -1334.822510\n",
      "Train Epoch: 894 [56832/60000 (95%)] Loss: -1461.244019\n",
      "    epoch          : 894\n",
      "    loss           : -1334.08573922195\n",
      "Train Epoch: 895 [512/60000 (1%)] Loss: -1019.275635\n",
      "Train Epoch: 895 [11776/60000 (20%)] Loss: -1291.133667\n",
      "Train Epoch: 895 [23040/60000 (38%)] Loss: -1283.892090\n",
      "Train Epoch: 895 [34304/60000 (57%)] Loss: -1281.115967\n",
      "Train Epoch: 895 [45568/60000 (76%)] Loss: -1443.034668\n",
      "Train Epoch: 895 [56832/60000 (95%)] Loss: -1431.773071\n",
      "    epoch          : 895\n",
      "    loss           : -1298.1339044086003\n",
      "Train Epoch: 896 [512/60000 (1%)] Loss: -1139.446289\n",
      "Train Epoch: 896 [11776/60000 (20%)] Loss: -1455.891357\n",
      "Train Epoch: 896 [23040/60000 (38%)] Loss: -1260.837646\n",
      "Train Epoch: 896 [34304/60000 (57%)] Loss: -1087.864136\n",
      "Train Epoch: 896 [45568/60000 (76%)] Loss: -1163.497437\n",
      "Train Epoch: 896 [56832/60000 (95%)] Loss: -1372.318359\n",
      "    epoch          : 896\n",
      "    loss           : -1299.4939152776858\n",
      "Train Epoch: 897 [512/60000 (1%)] Loss: -1463.295288\n",
      "Train Epoch: 897 [11776/60000 (20%)] Loss: -1356.205322\n",
      "Train Epoch: 897 [23040/60000 (38%)] Loss: -1290.705322\n",
      "Train Epoch: 897 [34304/60000 (57%)] Loss: -1461.006958\n",
      "Train Epoch: 897 [45568/60000 (76%)] Loss: -1319.020386\n",
      "Train Epoch: 897 [56832/60000 (95%)] Loss: -1462.833496\n",
      "    epoch          : 897\n",
      "    loss           : -1305.8432303390935\n",
      "Train Epoch: 898 [512/60000 (1%)] Loss: -1175.416504\n",
      "Train Epoch: 898 [11776/60000 (20%)] Loss: -1330.121826\n",
      "Train Epoch: 898 [23040/60000 (38%)] Loss: -1245.930420\n",
      "Train Epoch: 898 [34304/60000 (57%)] Loss: -1094.041138\n",
      "Train Epoch: 898 [45568/60000 (76%)] Loss: -1480.889282\n",
      "Train Epoch: 898 [56832/60000 (95%)] Loss: -1282.683105\n",
      "    epoch          : 898\n",
      "    loss           : -1323.459734900523\n",
      "Train Epoch: 899 [512/60000 (1%)] Loss: -1415.928711\n",
      "Train Epoch: 899 [11776/60000 (20%)] Loss: -1451.179199\n",
      "Train Epoch: 899 [23040/60000 (38%)] Loss: -1301.497681\n",
      "Train Epoch: 899 [34304/60000 (57%)] Loss: -995.136475\n",
      "Train Epoch: 899 [45568/60000 (76%)] Loss: -1294.339966\n",
      "Train Epoch: 899 [56832/60000 (95%)] Loss: -1484.310913\n",
      "    epoch          : 899\n",
      "    loss           : -1309.2011989442642\n",
      "Train Epoch: 900 [512/60000 (1%)] Loss: -1093.525879\n",
      "Train Epoch: 900 [11776/60000 (20%)] Loss: -1317.725708\n",
      "Train Epoch: 900 [23040/60000 (38%)] Loss: -1281.631836\n",
      "Train Epoch: 900 [34304/60000 (57%)] Loss: -1203.249146\n",
      "Train Epoch: 900 [45568/60000 (76%)] Loss: -1336.001953\n",
      "Train Epoch: 900 [56832/60000 (95%)] Loss: -1470.544189\n",
      "    epoch          : 900\n",
      "    loss           : -1331.054246288235\n",
      "Saving checkpoint: saved/models/Mnist_DeepGenerativeOperad/0127_111843/checkpoint-epoch900.pth ...\n",
      "Train Epoch: 901 [512/60000 (1%)] Loss: -1320.354370\n",
      "Train Epoch: 901 [11776/60000 (20%)] Loss: -1346.656250\n",
      "Train Epoch: 901 [23040/60000 (38%)] Loss: -1170.762939\n",
      "Train Epoch: 901 [34304/60000 (57%)] Loss: -1345.592163\n",
      "Train Epoch: 901 [45568/60000 (76%)] Loss: -1333.344482\n",
      "Train Epoch: 901 [56832/60000 (95%)] Loss: -1280.775269\n",
      "    epoch          : 901\n",
      "    loss           : -1300.114507642843\n",
      "Train Epoch: 902 [512/60000 (1%)] Loss: -1313.887207\n",
      "Train Epoch: 902 [11776/60000 (20%)] Loss: -1307.524780\n",
      "Train Epoch: 902 [23040/60000 (38%)] Loss: -1271.287964\n",
      "Train Epoch: 902 [34304/60000 (57%)] Loss: -1298.127808\n",
      "Train Epoch: 902 [45568/60000 (76%)] Loss: -1459.010986\n",
      "Train Epoch: 902 [56832/60000 (95%)] Loss: -963.956665\n",
      "    epoch          : 902\n",
      "    loss           : -1313.1663630426267\n",
      "Train Epoch: 903 [512/60000 (1%)] Loss: -1443.215576\n",
      "Train Epoch: 903 [11776/60000 (20%)] Loss: -1230.807007\n",
      "Train Epoch: 903 [23040/60000 (38%)] Loss: -1330.556152\n",
      "Train Epoch: 903 [34304/60000 (57%)] Loss: -1152.890747\n",
      "Train Epoch: 903 [45568/60000 (76%)] Loss: -1330.274048\n",
      "Train Epoch: 903 [56832/60000 (95%)] Loss: -1348.312744\n",
      "    epoch          : 903\n",
      "    loss           : -1333.464461331987\n",
      "Train Epoch: 904 [512/60000 (1%)] Loss: -1475.665039\n",
      "Train Epoch: 904 [11776/60000 (20%)] Loss: -1322.759399\n",
      "Train Epoch: 904 [23040/60000 (38%)] Loss: -1284.031250\n",
      "Train Epoch: 904 [34304/60000 (57%)] Loss: -1454.200806\n",
      "Train Epoch: 904 [45568/60000 (76%)] Loss: -1122.990112\n",
      "Train Epoch: 904 [56832/60000 (95%)] Loss: -1352.476562\n",
      "    epoch          : 904\n",
      "    loss           : -1300.5117797851562\n",
      "Train Epoch: 905 [512/60000 (1%)] Loss: -1498.624390\n",
      "Train Epoch: 905 [11776/60000 (20%)] Loss: -1318.699585\n",
      "Train Epoch: 905 [23040/60000 (38%)] Loss: -1363.825317\n",
      "Train Epoch: 905 [34304/60000 (57%)] Loss: -1318.462524\n",
      "Train Epoch: 905 [45568/60000 (76%)] Loss: -1417.240479\n",
      "Train Epoch: 905 [56832/60000 (95%)] Loss: -1197.964111\n",
      "    epoch          : 905\n",
      "    loss           : -1310.2096067956613\n",
      "Train Epoch: 906 [512/60000 (1%)] Loss: -1330.205200\n",
      "Train Epoch: 906 [11776/60000 (20%)] Loss: -1253.697754\n",
      "Train Epoch: 906 [23040/60000 (38%)] Loss: -1333.551880\n",
      "Train Epoch: 906 [34304/60000 (57%)] Loss: -1160.054199\n",
      "Train Epoch: 906 [45568/60000 (76%)] Loss: -1461.113037\n",
      "Train Epoch: 906 [56832/60000 (95%)] Loss: -1450.822266\n",
      "    epoch          : 906\n",
      "    loss           : -1307.8759817349708\n",
      "Train Epoch: 907 [512/60000 (1%)] Loss: -1490.550781\n",
      "Train Epoch: 907 [11776/60000 (20%)] Loss: -1409.643066\n",
      "Train Epoch: 907 [23040/60000 (38%)] Loss: -1450.648193\n",
      "Train Epoch: 907 [34304/60000 (57%)] Loss: -1158.331299\n",
      "Train Epoch: 907 [45568/60000 (76%)] Loss: -1430.073364\n",
      "Train Epoch: 907 [56832/60000 (95%)] Loss: -1348.131348\n",
      "    epoch          : 907\n",
      "    loss           : -1321.0066873151702\n",
      "Train Epoch: 908 [512/60000 (1%)] Loss: -1308.813843\n",
      "Train Epoch: 908 [11776/60000 (20%)] Loss: -1308.354736\n",
      "Train Epoch: 908 [23040/60000 (38%)] Loss: -1296.026489\n",
      "Train Epoch: 908 [34304/60000 (57%)] Loss: -1418.610596\n",
      "Train Epoch: 908 [45568/60000 (76%)] Loss: -1338.325073\n",
      "Train Epoch: 908 [56832/60000 (95%)] Loss: -1411.497925\n",
      "    epoch          : 908\n",
      "    loss           : -1308.689332434013\n",
      "Train Epoch: 909 [512/60000 (1%)] Loss: -1462.833252\n",
      "Train Epoch: 909 [11776/60000 (20%)] Loss: -1310.957764\n",
      "Train Epoch: 909 [23040/60000 (38%)] Loss: -1296.753296\n",
      "Train Epoch: 909 [34304/60000 (57%)] Loss: -1166.837402\n",
      "Train Epoch: 909 [45568/60000 (76%)] Loss: -1330.338013\n",
      "Train Epoch: 909 [56832/60000 (95%)] Loss: -1194.903687\n",
      "    epoch          : 909\n",
      "    loss           : -1311.0032771051267\n",
      "Train Epoch: 910 [512/60000 (1%)] Loss: -1490.090088\n",
      "Train Epoch: 910 [11776/60000 (20%)] Loss: -1494.708984\n",
      "Train Epoch: 910 [23040/60000 (38%)] Loss: -1269.993164\n",
      "Train Epoch: 910 [34304/60000 (57%)] Loss: -1274.924561\n",
      "Train Epoch: 910 [45568/60000 (76%)] Loss: -1429.960693\n",
      "Train Epoch: 910 [56832/60000 (95%)] Loss: -1281.848389\n",
      "    epoch          : 910\n",
      "    loss           : -1337.583476783192\n",
      "Train Epoch: 911 [512/60000 (1%)] Loss: -1310.604248\n",
      "Train Epoch: 911 [11776/60000 (20%)] Loss: -1299.218140\n",
      "Train Epoch: 911 [23040/60000 (38%)] Loss: -1224.694092\n",
      "Train Epoch: 911 [34304/60000 (57%)] Loss: -1419.658203\n",
      "Train Epoch: 911 [45568/60000 (76%)] Loss: -1271.057739\n",
      "Train Epoch: 911 [56832/60000 (95%)] Loss: -1307.224731\n",
      "    epoch          : 911\n",
      "    loss           : -1319.8588080971929\n",
      "Train Epoch: 912 [512/60000 (1%)] Loss: -1377.162354\n",
      "Train Epoch: 912 [11776/60000 (20%)] Loss: -1491.666626\n",
      "Train Epoch: 912 [23040/60000 (38%)] Loss: -1170.924927\n",
      "Train Epoch: 912 [34304/60000 (57%)] Loss: -1264.990234\n",
      "Train Epoch: 912 [45568/60000 (76%)] Loss: -1468.732422\n",
      "Train Epoch: 912 [56832/60000 (95%)] Loss: -1165.263306\n",
      "    epoch          : 912\n",
      "    loss           : -1315.820015082925\n",
      "Train Epoch: 913 [512/60000 (1%)] Loss: -1316.702637\n",
      "Train Epoch: 913 [11776/60000 (20%)] Loss: -1198.426270\n",
      "Train Epoch: 913 [23040/60000 (38%)] Loss: -1260.231812\n",
      "Train Epoch: 913 [34304/60000 (57%)] Loss: -1208.662109\n",
      "Train Epoch: 913 [45568/60000 (76%)] Loss: -1290.357422\n",
      "Train Epoch: 913 [56832/60000 (95%)] Loss: -1360.426147\n",
      "    epoch          : 913\n",
      "    loss           : -1298.7345786229364\n",
      "Train Epoch: 914 [512/60000 (1%)] Loss: -1301.762451\n",
      "Train Epoch: 914 [11776/60000 (20%)] Loss: -1253.378174\n",
      "Train Epoch: 914 [23040/60000 (38%)] Loss: -1353.321411\n",
      "Train Epoch: 914 [34304/60000 (57%)] Loss: -1317.508667\n",
      "Train Epoch: 914 [45568/60000 (76%)] Loss: -1293.757568\n",
      "Train Epoch: 914 [56832/60000 (95%)] Loss: -1406.974976\n",
      "    epoch          : 914\n",
      "    loss           : -1307.7035082800915\n",
      "Train Epoch: 915 [512/60000 (1%)] Loss: -1116.580566\n",
      "Train Epoch: 915 [11776/60000 (20%)] Loss: -1275.108887\n",
      "Train Epoch: 915 [23040/60000 (38%)] Loss: -1203.654907\n",
      "Train Epoch: 915 [34304/60000 (57%)] Loss: -1313.266724\n",
      "Train Epoch: 915 [45568/60000 (76%)] Loss: -1150.632324\n",
      "Train Epoch: 915 [56832/60000 (95%)] Loss: -1502.576904\n",
      "    epoch          : 915\n",
      "    loss           : -1317.0296177406096\n",
      "Train Epoch: 916 [512/60000 (1%)] Loss: -1462.427490\n",
      "Train Epoch: 916 [11776/60000 (20%)] Loss: -1261.370361\n",
      "Train Epoch: 916 [23040/60000 (38%)] Loss: -1315.932373\n",
      "Train Epoch: 916 [34304/60000 (57%)] Loss: -1478.357788\n",
      "Train Epoch: 916 [45568/60000 (76%)] Loss: -802.729492\n",
      "Train Epoch: 916 [56832/60000 (95%)] Loss: -1315.638550\n",
      "    epoch          : 916\n",
      "    loss           : -1306.22302435751\n",
      "Train Epoch: 917 [512/60000 (1%)] Loss: -1502.057861\n",
      "Train Epoch: 917 [11776/60000 (20%)] Loss: -1349.325195\n",
      "Train Epoch: 917 [23040/60000 (38%)] Loss: -1321.870483\n",
      "Train Epoch: 917 [34304/60000 (57%)] Loss: -1316.645630\n",
      "Train Epoch: 917 [45568/60000 (76%)] Loss: -1484.555664\n",
      "Train Epoch: 917 [56832/60000 (95%)] Loss: -1432.162598\n",
      "    epoch          : 917\n",
      "    loss           : -1326.3383458024364\n",
      "Train Epoch: 918 [512/60000 (1%)] Loss: -1429.848633\n",
      "Train Epoch: 918 [11776/60000 (20%)] Loss: -975.300476\n",
      "Train Epoch: 918 [23040/60000 (38%)] Loss: -1024.535034\n",
      "Train Epoch: 918 [34304/60000 (57%)] Loss: -1401.404785\n",
      "Train Epoch: 918 [45568/60000 (76%)] Loss: -1274.223022\n",
      "Train Epoch: 918 [56832/60000 (95%)] Loss: -1464.802734\n",
      "    epoch          : 918\n",
      "    loss           : -1303.5617493020611\n",
      "Train Epoch: 919 [512/60000 (1%)] Loss: -1290.934570\n",
      "Train Epoch: 919 [11776/60000 (20%)] Loss: -1311.621338\n",
      "Train Epoch: 919 [23040/60000 (38%)] Loss: -1316.464355\n",
      "Train Epoch: 919 [34304/60000 (57%)] Loss: -1465.218994\n",
      "Train Epoch: 919 [45568/60000 (76%)] Loss: -1144.102173\n",
      "Train Epoch: 919 [56832/60000 (95%)] Loss: -1459.216309\n",
      "    epoch          : 919\n",
      "    loss           : -1307.7672391557423\n",
      "Train Epoch: 920 [512/60000 (1%)] Loss: -1252.885498\n",
      "Train Epoch: 920 [11776/60000 (20%)] Loss: -1476.288818\n",
      "Train Epoch: 920 [23040/60000 (38%)] Loss: -1339.695068\n",
      "Train Epoch: 920 [34304/60000 (57%)] Loss: -1297.595459\n",
      "Train Epoch: 920 [45568/60000 (76%)] Loss: -1005.541443\n",
      "Train Epoch: 920 [56832/60000 (95%)] Loss: -1274.060669\n",
      "    epoch          : 920\n",
      "    loss           : -1298.6165473205222\n",
      "Train Epoch: 921 [512/60000 (1%)] Loss: -1187.535889\n",
      "Train Epoch: 921 [11776/60000 (20%)] Loss: -1468.301025\n",
      "Train Epoch: 921 [23040/60000 (38%)] Loss: -1332.889160\n",
      "Train Epoch: 921 [34304/60000 (57%)] Loss: -1329.784912\n",
      "Train Epoch: 921 [45568/60000 (76%)] Loss: -1459.215698\n",
      "Train Epoch: 921 [56832/60000 (95%)] Loss: -1178.045166\n",
      "    epoch          : 921\n",
      "    loss           : -1315.0147336108535\n",
      "Train Epoch: 922 [512/60000 (1%)] Loss: -1459.678955\n",
      "Train Epoch: 922 [11776/60000 (20%)] Loss: -1276.244629\n",
      "Train Epoch: 922 [23040/60000 (38%)] Loss: -1289.654785\n",
      "Train Epoch: 922 [34304/60000 (57%)] Loss: -1348.432251\n",
      "Train Epoch: 922 [45568/60000 (76%)] Loss: -1442.702637\n",
      "Train Epoch: 922 [56832/60000 (95%)] Loss: -1067.034302\n",
      "    epoch          : 922\n",
      "    loss           : -1305.7854102183196\n",
      "Train Epoch: 923 [512/60000 (1%)] Loss: -1173.278442\n",
      "Train Epoch: 923 [11776/60000 (20%)] Loss: -1307.649292\n",
      "Train Epoch: 923 [23040/60000 (38%)] Loss: -1116.663086\n",
      "Train Epoch: 923 [34304/60000 (57%)] Loss: -1446.409302\n",
      "Train Epoch: 923 [45568/60000 (76%)] Loss: -1456.507935\n",
      "Train Epoch: 923 [56832/60000 (95%)] Loss: -1133.365234\n",
      "    epoch          : 923\n",
      "    loss           : -1317.1184006168344\n",
      "Train Epoch: 924 [512/60000 (1%)] Loss: -1300.199585\n",
      "Train Epoch: 924 [11776/60000 (20%)] Loss: -1469.911987\n",
      "Train Epoch: 924 [23040/60000 (38%)] Loss: -1321.942993\n",
      "Train Epoch: 924 [34304/60000 (57%)] Loss: -1126.881592\n",
      "Train Epoch: 924 [45568/60000 (76%)] Loss: -1431.974609\n",
      "Train Epoch: 924 [56832/60000 (95%)] Loss: -1042.989746\n",
      "    epoch          : 924\n",
      "    loss           : -1307.3430479232873\n",
      "Train Epoch: 925 [512/60000 (1%)] Loss: -1152.989258\n",
      "Train Epoch: 925 [11776/60000 (20%)] Loss: -1459.623291\n",
      "Train Epoch: 925 [23040/60000 (38%)] Loss: -1315.027344\n",
      "Train Epoch: 925 [34304/60000 (57%)] Loss: -1268.405762\n",
      "Train Epoch: 925 [45568/60000 (76%)] Loss: -1311.030762\n",
      "Train Epoch: 925 [56832/60000 (95%)] Loss: -1125.168945\n",
      "    epoch          : 925\n",
      "    loss           : -1289.2481332552636\n",
      "Train Epoch: 926 [512/60000 (1%)] Loss: -1173.909912\n",
      "Train Epoch: 926 [11776/60000 (20%)] Loss: -1170.536743\n",
      "Train Epoch: 926 [23040/60000 (38%)] Loss: -1478.271606\n",
      "Train Epoch: 926 [34304/60000 (57%)] Loss: -1477.207031\n",
      "Train Epoch: 926 [45568/60000 (76%)] Loss: -1439.011230\n",
      "Train Epoch: 926 [56832/60000 (95%)] Loss: -1406.889038\n",
      "    epoch          : 926\n",
      "    loss           : -1340.0872609628796\n",
      "Train Epoch: 927 [512/60000 (1%)] Loss: -1453.638062\n",
      "Train Epoch: 927 [11776/60000 (20%)] Loss: -1313.728760\n",
      "Train Epoch: 927 [23040/60000 (38%)] Loss: -1293.493408\n",
      "Train Epoch: 927 [34304/60000 (57%)] Loss: -1193.681152\n",
      "Train Epoch: 927 [45568/60000 (76%)] Loss: -1097.586182\n",
      "Train Epoch: 927 [56832/60000 (95%)] Loss: -1475.058594\n",
      "    epoch          : 927\n",
      "    loss           : -1319.219714665817\n",
      "Train Epoch: 928 [512/60000 (1%)] Loss: -1176.692993\n",
      "Train Epoch: 928 [11776/60000 (20%)] Loss: -1461.024170\n",
      "Train Epoch: 928 [23040/60000 (38%)] Loss: -1299.322388\n",
      "Train Epoch: 928 [34304/60000 (57%)] Loss: -1429.207886\n",
      "Train Epoch: 928 [45568/60000 (76%)] Loss: -1185.825195\n",
      "Train Epoch: 928 [56832/60000 (95%)] Loss: -1131.318359\n",
      "    epoch          : 928\n",
      "    loss           : -1330.427941618666\n",
      "Train Epoch: 929 [512/60000 (1%)] Loss: -1442.956055\n",
      "Train Epoch: 929 [11776/60000 (20%)] Loss: -1478.719971\n",
      "Train Epoch: 929 [23040/60000 (38%)] Loss: -1088.920288\n",
      "Train Epoch: 929 [34304/60000 (57%)] Loss: -1226.093750\n",
      "Train Epoch: 929 [45568/60000 (76%)] Loss: -1334.943237\n",
      "Train Epoch: 929 [56832/60000 (95%)] Loss: -1343.770020\n",
      "    epoch          : 929\n",
      "    loss           : -1310.3770360569497\n",
      "Train Epoch: 930 [512/60000 (1%)] Loss: -1462.539795\n",
      "Train Epoch: 930 [11776/60000 (20%)] Loss: -1282.562744\n",
      "Train Epoch: 930 [23040/60000 (38%)] Loss: -1109.528076\n",
      "Train Epoch: 930 [34304/60000 (57%)] Loss: -1345.716431\n",
      "Train Epoch: 930 [45568/60000 (76%)] Loss: -1334.377441\n",
      "Train Epoch: 930 [56832/60000 (95%)] Loss: -1315.768677\n",
      "    epoch          : 930\n",
      "    loss           : -1305.4650201312566\n",
      "Train Epoch: 931 [512/60000 (1%)] Loss: -1334.254639\n",
      "Train Epoch: 931 [11776/60000 (20%)] Loss: -1339.350830\n",
      "Train Epoch: 931 [23040/60000 (38%)] Loss: -1177.804688\n",
      "Train Epoch: 931 [34304/60000 (57%)] Loss: -1265.592285\n",
      "Train Epoch: 931 [45568/60000 (76%)] Loss: -1484.122559\n",
      "Train Epoch: 931 [56832/60000 (95%)] Loss: -1318.819702\n",
      "    epoch          : 931\n",
      "    loss           : -1340.5830364335056\n",
      "Train Epoch: 932 [512/60000 (1%)] Loss: -1282.248901\n",
      "Train Epoch: 932 [11776/60000 (20%)] Loss: -1430.843018\n",
      "Train Epoch: 932 [23040/60000 (38%)] Loss: -1360.820068\n",
      "Train Epoch: 932 [34304/60000 (57%)] Loss: -1474.973145\n",
      "Train Epoch: 932 [45568/60000 (76%)] Loss: -1339.401001\n",
      "Train Epoch: 932 [56832/60000 (95%)] Loss: -1322.460205\n",
      "    epoch          : 932\n",
      "    loss           : -1343.2026375808284\n",
      "Train Epoch: 933 [512/60000 (1%)] Loss: -1413.915527\n",
      "Train Epoch: 933 [11776/60000 (20%)] Loss: -1177.316040\n",
      "Train Epoch: 933 [23040/60000 (38%)] Loss: -1421.309082\n",
      "Train Epoch: 933 [34304/60000 (57%)] Loss: -1209.834717\n",
      "Train Epoch: 933 [45568/60000 (76%)] Loss: -1491.438965\n",
      "Train Epoch: 933 [56832/60000 (95%)] Loss: -1303.103149\n",
      "    epoch          : 933\n",
      "    loss           : -1312.834366275766\n",
      "Train Epoch: 934 [512/60000 (1%)] Loss: -1091.222412\n",
      "Train Epoch: 934 [11776/60000 (20%)] Loss: -1460.805908\n",
      "Train Epoch: 934 [23040/60000 (38%)] Loss: -1504.964355\n",
      "Train Epoch: 934 [34304/60000 (57%)] Loss: -1493.408447\n",
      "Train Epoch: 934 [45568/60000 (76%)] Loss: -1006.859253\n",
      "Train Epoch: 934 [56832/60000 (95%)] Loss: -1261.139282\n",
      "    epoch          : 934\n",
      "    loss           : -1312.1473993850966\n",
      "Train Epoch: 935 [512/60000 (1%)] Loss: -1304.748291\n",
      "Train Epoch: 935 [11776/60000 (20%)] Loss: -1382.312378\n",
      "Train Epoch: 935 [23040/60000 (38%)] Loss: -1255.514038\n",
      "Train Epoch: 935 [34304/60000 (57%)] Loss: -1169.977173\n",
      "Train Epoch: 935 [45568/60000 (76%)] Loss: -1475.978271\n",
      "Train Epoch: 935 [56832/60000 (95%)] Loss: -1496.729736\n",
      "    epoch          : 935\n",
      "    loss           : -1328.6543492893716\n",
      "Train Epoch: 936 [512/60000 (1%)] Loss: -1326.541748\n",
      "Train Epoch: 936 [11776/60000 (20%)] Loss: -1364.905640\n",
      "Train Epoch: 936 [23040/60000 (38%)] Loss: -1228.428345\n",
      "Train Epoch: 936 [34304/60000 (57%)] Loss: -1310.798096\n",
      "Train Epoch: 936 [45568/60000 (76%)] Loss: -1162.347412\n",
      "Train Epoch: 936 [56832/60000 (95%)] Loss: -1285.551880\n",
      "    epoch          : 936\n",
      "    loss           : -1318.3620176153668\n",
      "Train Epoch: 937 [512/60000 (1%)] Loss: -1126.448120\n",
      "Train Epoch: 937 [11776/60000 (20%)] Loss: -1432.912964\n",
      "Train Epoch: 937 [23040/60000 (38%)] Loss: -1431.130981\n",
      "Train Epoch: 937 [34304/60000 (57%)] Loss: -1349.438232\n",
      "Train Epoch: 937 [45568/60000 (76%)] Loss: -1293.496826\n",
      "Train Epoch: 937 [56832/60000 (95%)] Loss: -1475.773193\n",
      "    epoch          : 937\n",
      "    loss           : -1309.1493871656514\n",
      "Train Epoch: 938 [512/60000 (1%)] Loss: -1139.602905\n",
      "Train Epoch: 938 [11776/60000 (20%)] Loss: -1154.277710\n",
      "Train Epoch: 938 [23040/60000 (38%)] Loss: -1481.618042\n",
      "Train Epoch: 938 [34304/60000 (57%)] Loss: -1297.524902\n",
      "Train Epoch: 938 [45568/60000 (76%)] Loss: -1307.254761\n",
      "Train Epoch: 938 [56832/60000 (95%)] Loss: -1480.656128\n",
      "    epoch          : 938\n",
      "    loss           : -1322.7500003448313\n",
      "Train Epoch: 939 [512/60000 (1%)] Loss: -1447.690430\n",
      "Train Epoch: 939 [11776/60000 (20%)] Loss: -1268.164307\n",
      "Train Epoch: 939 [23040/60000 (38%)] Loss: -1478.374146\n",
      "Train Epoch: 939 [34304/60000 (57%)] Loss: -1001.847656\n",
      "Train Epoch: 939 [45568/60000 (76%)] Loss: -1314.475708\n",
      "Train Epoch: 939 [56832/60000 (95%)] Loss: -1018.612854\n",
      "    epoch          : 939\n",
      "    loss           : -1305.970910368666\n",
      "Train Epoch: 940 [512/60000 (1%)] Loss: -1343.599854\n",
      "Train Epoch: 940 [11776/60000 (20%)] Loss: -1466.686279\n",
      "Train Epoch: 940 [23040/60000 (38%)] Loss: -1293.208130\n",
      "Train Epoch: 940 [34304/60000 (57%)] Loss: -1301.207886\n",
      "Train Epoch: 940 [45568/60000 (76%)] Loss: -1043.757446\n",
      "Train Epoch: 940 [56832/60000 (95%)] Loss: -1447.492676\n",
      "    epoch          : 940\n",
      "    loss           : -1326.5816000383454\n",
      "Train Epoch: 941 [512/60000 (1%)] Loss: -1192.319824\n",
      "Train Epoch: 941 [11776/60000 (20%)] Loss: -1338.887207\n",
      "Train Epoch: 941 [23040/60000 (38%)] Loss: -1342.613281\n",
      "Train Epoch: 941 [34304/60000 (57%)] Loss: -1470.277222\n",
      "Train Epoch: 941 [45568/60000 (76%)] Loss: -1419.379272\n",
      "Train Epoch: 941 [56832/60000 (95%)] Loss: -1488.413086\n",
      "    epoch          : 941\n",
      "    loss           : -1317.4606893938142\n",
      "Train Epoch: 942 [512/60000 (1%)] Loss: -1250.733032\n",
      "Train Epoch: 942 [11776/60000 (20%)] Loss: -1303.287476\n",
      "Train Epoch: 942 [23040/60000 (38%)] Loss: -1322.535278\n",
      "Train Epoch: 942 [34304/60000 (57%)] Loss: -1004.271729\n",
      "Train Epoch: 942 [45568/60000 (76%)] Loss: -1486.810059\n",
      "Train Epoch: 942 [56832/60000 (95%)] Loss: -1464.553101\n",
      "    epoch          : 942\n",
      "    loss           : -1330.5181895110566\n",
      "Train Epoch: 943 [512/60000 (1%)] Loss: -1477.716553\n",
      "Train Epoch: 943 [11776/60000 (20%)] Loss: -1286.063354\n",
      "Train Epoch: 943 [23040/60000 (38%)] Loss: -1150.177002\n",
      "Train Epoch: 943 [34304/60000 (57%)] Loss: -1448.564209\n",
      "Train Epoch: 943 [45568/60000 (76%)] Loss: -1135.413208\n",
      "Train Epoch: 943 [56832/60000 (95%)] Loss: -1343.032227\n",
      "    epoch          : 943\n",
      "    loss           : -1318.7315366928185\n",
      "Train Epoch: 944 [512/60000 (1%)] Loss: -1308.253662\n",
      "Train Epoch: 944 [11776/60000 (20%)] Loss: -1310.697021\n",
      "Train Epoch: 944 [23040/60000 (38%)] Loss: -1006.154297\n",
      "Train Epoch: 944 [34304/60000 (57%)] Loss: -1514.646362\n",
      "Train Epoch: 944 [45568/60000 (76%)] Loss: -1179.786377\n",
      "Train Epoch: 944 [56832/60000 (95%)] Loss: -1287.556274\n",
      "    epoch          : 944\n",
      "    loss           : -1311.9162070064222\n",
      "Train Epoch: 945 [512/60000 (1%)] Loss: -1110.155029\n",
      "Train Epoch: 945 [11776/60000 (20%)] Loss: -1124.418945\n",
      "Train Epoch: 945 [23040/60000 (38%)] Loss: -1318.376709\n",
      "Train Epoch: 945 [34304/60000 (57%)] Loss: -936.890991\n",
      "Train Epoch: 945 [45568/60000 (76%)] Loss: -1485.080566\n",
      "Train Epoch: 945 [56832/60000 (95%)] Loss: -1424.500000\n",
      "    epoch          : 945\n",
      "    loss           : -1336.9414162501105\n",
      "Train Epoch: 946 [512/60000 (1%)] Loss: -1324.188477\n",
      "Train Epoch: 946 [11776/60000 (20%)] Loss: -1247.928345\n",
      "Train Epoch: 946 [23040/60000 (38%)] Loss: -1460.040527\n",
      "Train Epoch: 946 [34304/60000 (57%)] Loss: -1333.409424\n",
      "Train Epoch: 946 [45568/60000 (76%)] Loss: -1173.462891\n",
      "Train Epoch: 946 [56832/60000 (95%)] Loss: -1259.191528\n",
      "    epoch          : 946\n",
      "    loss           : -1306.4515104994261\n",
      "Train Epoch: 947 [512/60000 (1%)] Loss: -1135.088379\n",
      "Train Epoch: 947 [11776/60000 (20%)] Loss: -1169.120361\n",
      "Train Epoch: 947 [23040/60000 (38%)] Loss: -1461.380371\n",
      "Train Epoch: 947 [34304/60000 (57%)] Loss: -1251.203857\n",
      "Train Epoch: 947 [45568/60000 (76%)] Loss: -1469.435913\n",
      "Train Epoch: 947 [56832/60000 (95%)] Loss: -1298.793457\n",
      "    epoch          : 947\n",
      "    loss           : -1308.9602943894552\n",
      "Train Epoch: 948 [512/60000 (1%)] Loss: -1325.597168\n",
      "Train Epoch: 948 [11776/60000 (20%)] Loss: -1326.509277\n",
      "Train Epoch: 948 [23040/60000 (38%)] Loss: -1239.104248\n",
      "Train Epoch: 948 [34304/60000 (57%)] Loss: -1486.848999\n",
      "Train Epoch: 948 [45568/60000 (76%)] Loss: -1434.426025\n",
      "Train Epoch: 948 [56832/60000 (95%)] Loss: -1308.950928\n",
      "    epoch          : 948\n",
      "    loss           : -1320.9666111832958\n",
      "Train Epoch: 949 [512/60000 (1%)] Loss: -1475.155273\n",
      "Train Epoch: 949 [11776/60000 (20%)] Loss: -1452.330322\n",
      "Train Epoch: 949 [23040/60000 (38%)] Loss: -1373.487671\n",
      "Train Epoch: 949 [34304/60000 (57%)] Loss: -1296.608765\n",
      "Train Epoch: 949 [45568/60000 (76%)] Loss: -1270.078613\n",
      "Train Epoch: 949 [56832/60000 (95%)] Loss: -1516.907471\n",
      "    epoch          : 949\n",
      "    loss           : -1317.0675993666136\n",
      "Train Epoch: 950 [512/60000 (1%)] Loss: -1291.573486\n",
      "Train Epoch: 950 [11776/60000 (20%)] Loss: -1325.210205\n",
      "Train Epoch: 950 [23040/60000 (38%)] Loss: -1051.761719\n",
      "Train Epoch: 950 [34304/60000 (57%)] Loss: -1334.025024\n",
      "Train Epoch: 950 [45568/60000 (76%)] Loss: -1463.935059\n",
      "Train Epoch: 950 [56832/60000 (95%)] Loss: -1487.710205\n",
      "    epoch          : 950\n",
      "    loss           : -1327.6972499351716\n",
      "Train Epoch: 951 [512/60000 (1%)] Loss: -1198.625488\n",
      "Train Epoch: 951 [11776/60000 (20%)] Loss: -1309.974121\n",
      "Train Epoch: 951 [23040/60000 (38%)] Loss: -1298.691406\n",
      "Train Epoch: 951 [34304/60000 (57%)] Loss: -1305.562744\n",
      "Train Epoch: 951 [45568/60000 (76%)] Loss: -1161.887451\n",
      "Train Epoch: 951 [56832/60000 (95%)] Loss: -1193.644653\n",
      "    epoch          : 951\n",
      "    loss           : -1312.2649053368864\n",
      "Train Epoch: 952 [512/60000 (1%)] Loss: -1316.498901\n",
      "Train Epoch: 952 [11776/60000 (20%)] Loss: -1179.822998\n",
      "Train Epoch: 952 [23040/60000 (38%)] Loss: -1427.835938\n",
      "Train Epoch: 952 [34304/60000 (57%)] Loss: -1310.984985\n",
      "Train Epoch: 952 [45568/60000 (76%)] Loss: -999.532043\n",
      "Train Epoch: 952 [56832/60000 (95%)] Loss: -1270.694824\n",
      "    epoch          : 952\n",
      "    loss           : -1300.4726843537585\n",
      "Train Epoch: 953 [512/60000 (1%)] Loss: -1353.945801\n",
      "Train Epoch: 953 [11776/60000 (20%)] Loss: -1169.920776\n",
      "Train Epoch: 953 [23040/60000 (38%)] Loss: -1315.493286\n",
      "Train Epoch: 953 [34304/60000 (57%)] Loss: -1292.998657\n",
      "Train Epoch: 953 [45568/60000 (76%)] Loss: -1286.372192\n",
      "Train Epoch: 953 [56832/60000 (95%)] Loss: -1473.108032\n",
      "    epoch          : 953\n",
      "    loss           : -1330.515476550086\n",
      "Train Epoch: 954 [512/60000 (1%)] Loss: -1149.736206\n",
      "Train Epoch: 954 [11776/60000 (20%)] Loss: -1177.291748\n",
      "Train Epoch: 954 [23040/60000 (38%)] Loss: -1328.166748\n",
      "Train Epoch: 954 [34304/60000 (57%)] Loss: -1425.708252\n",
      "Train Epoch: 954 [45568/60000 (76%)] Loss: -1293.726685\n",
      "Train Epoch: 954 [56832/60000 (95%)] Loss: -1451.295898\n",
      "    epoch          : 954\n",
      "    loss           : -1331.6730569095935\n",
      "Train Epoch: 955 [512/60000 (1%)] Loss: -1294.980713\n",
      "Train Epoch: 955 [11776/60000 (20%)] Loss: -1353.291870\n",
      "Train Epoch: 955 [23040/60000 (38%)] Loss: -1492.598633\n",
      "Train Epoch: 955 [34304/60000 (57%)] Loss: -1330.895874\n",
      "Train Epoch: 955 [45568/60000 (76%)] Loss: -1477.826538\n",
      "Train Epoch: 955 [56832/60000 (95%)] Loss: -1185.696777\n",
      "    epoch          : 955\n",
      "    loss           : -1331.4630942479364\n",
      "Train Epoch: 956 [512/60000 (1%)] Loss: -1308.648926\n",
      "Train Epoch: 956 [11776/60000 (20%)] Loss: -1321.995850\n",
      "Train Epoch: 956 [23040/60000 (38%)] Loss: -1274.603516\n",
      "Train Epoch: 956 [34304/60000 (57%)] Loss: -1345.041748\n",
      "Train Epoch: 956 [45568/60000 (76%)] Loss: -1284.470703\n",
      "Train Epoch: 956 [56832/60000 (95%)] Loss: -1371.699097\n",
      "    epoch          : 956\n",
      "    loss           : -1323.557765637414\n",
      "Train Epoch: 957 [512/60000 (1%)] Loss: -1319.343506\n",
      "Train Epoch: 957 [11776/60000 (20%)] Loss: -1465.579956\n",
      "Train Epoch: 957 [23040/60000 (38%)] Loss: -940.291138\n",
      "Train Epoch: 957 [34304/60000 (57%)] Loss: -1314.072998\n",
      "Train Epoch: 957 [45568/60000 (76%)] Loss: -1317.555664\n",
      "Train Epoch: 957 [56832/60000 (95%)] Loss: -1290.196655\n",
      "    epoch          : 957\n",
      "    loss           : -1298.1582895052636\n",
      "Train Epoch: 958 [512/60000 (1%)] Loss: -1344.133789\n",
      "Train Epoch: 958 [11776/60000 (20%)] Loss: -1494.769775\n",
      "Train Epoch: 958 [23040/60000 (38%)] Loss: -1496.200073\n",
      "Train Epoch: 958 [34304/60000 (57%)] Loss: -1480.331421\n",
      "Train Epoch: 958 [45568/60000 (76%)] Loss: -1489.560547\n",
      "Train Epoch: 958 [56832/60000 (95%)] Loss: -1432.316528\n",
      "    epoch          : 958\n",
      "    loss           : -1339.959215412032\n",
      "Train Epoch: 959 [512/60000 (1%)] Loss: -1270.899170\n",
      "Train Epoch: 959 [11776/60000 (20%)] Loss: -1300.769653\n",
      "Train Epoch: 959 [23040/60000 (38%)] Loss: -1296.552612\n",
      "Train Epoch: 959 [34304/60000 (57%)] Loss: -1361.475952\n",
      "Train Epoch: 959 [45568/60000 (76%)] Loss: -1453.887207\n",
      "Train Epoch: 959 [56832/60000 (95%)] Loss: -1341.544800\n",
      "    epoch          : 959\n",
      "    loss           : -1317.1964532022423\n",
      "Train Epoch: 960 [512/60000 (1%)] Loss: -1224.397705\n",
      "Train Epoch: 960 [11776/60000 (20%)] Loss: -1474.579834\n",
      "Train Epoch: 960 [23040/60000 (38%)] Loss: -1276.614014\n",
      "Train Epoch: 960 [34304/60000 (57%)] Loss: -1031.734985\n",
      "Train Epoch: 960 [45568/60000 (76%)] Loss: -1187.485107\n",
      "Train Epoch: 960 [56832/60000 (95%)] Loss: -1421.347412\n",
      "    epoch          : 960\n",
      "    loss           : -1307.2114675058483\n",
      "Train Epoch: 961 [512/60000 (1%)] Loss: -1286.471924\n",
      "Train Epoch: 961 [11776/60000 (20%)] Loss: -1301.896973\n",
      "Train Epoch: 961 [23040/60000 (38%)] Loss: -1345.332397\n",
      "Train Epoch: 961 [34304/60000 (57%)] Loss: -1430.133911\n",
      "Train Epoch: 961 [45568/60000 (76%)] Loss: -1463.334961\n",
      "Train Epoch: 961 [56832/60000 (95%)] Loss: -1305.025635\n",
      "    epoch          : 961\n",
      "    loss           : -1332.119684424104\n",
      "Train Epoch: 962 [512/60000 (1%)] Loss: -1425.900024\n",
      "Train Epoch: 962 [11776/60000 (20%)] Loss: -1269.361572\n",
      "Train Epoch: 962 [23040/60000 (38%)] Loss: -1488.239746\n",
      "Train Epoch: 962 [34304/60000 (57%)] Loss: -1375.003662\n",
      "Train Epoch: 962 [45568/60000 (76%)] Loss: -1160.494507\n",
      "Train Epoch: 962 [56832/60000 (95%)] Loss: -1445.683960\n",
      "    epoch          : 962\n",
      "    loss           : -1321.0260218388617\n",
      "Train Epoch: 963 [512/60000 (1%)] Loss: -1500.041382\n",
      "Train Epoch: 963 [11776/60000 (20%)] Loss: -1232.301636\n",
      "Train Epoch: 963 [23040/60000 (38%)] Loss: -1369.119385\n",
      "Train Epoch: 963 [34304/60000 (57%)] Loss: -1360.651855\n",
      "Train Epoch: 963 [45568/60000 (76%)] Loss: -1279.132690\n",
      "Train Epoch: 963 [56832/60000 (95%)] Loss: -1061.116699\n",
      "    epoch          : 963\n",
      "    loss           : -1289.5155746546168\n",
      "Train Epoch: 964 [512/60000 (1%)] Loss: -1370.352539\n",
      "Train Epoch: 964 [11776/60000 (20%)] Loss: -1305.806396\n",
      "Train Epoch: 964 [23040/60000 (38%)] Loss: -1332.203003\n",
      "Train Epoch: 964 [34304/60000 (57%)] Loss: -1280.619751\n",
      "Train Epoch: 964 [45568/60000 (76%)] Loss: -1182.237549\n",
      "Train Epoch: 964 [56832/60000 (95%)] Loss: -1342.915771\n",
      "    epoch          : 964\n",
      "    loss           : -1311.8622896873344\n",
      "Train Epoch: 965 [512/60000 (1%)] Loss: -1179.228516\n",
      "Train Epoch: 965 [11776/60000 (20%)] Loss: -1128.992676\n",
      "Train Epoch: 965 [23040/60000 (38%)] Loss: -1287.938721\n",
      "Train Epoch: 965 [34304/60000 (57%)] Loss: -1286.617188\n",
      "Train Epoch: 965 [45568/60000 (76%)] Loss: -1462.714966\n",
      "Train Epoch: 965 [56832/60000 (95%)] Loss: -1129.034790\n",
      "    epoch          : 965\n",
      "    loss           : -1330.8509054237838\n",
      "Train Epoch: 966 [512/60000 (1%)] Loss: -1481.436035\n",
      "Train Epoch: 966 [11776/60000 (20%)] Loss: -1299.575439\n",
      "Train Epoch: 966 [23040/60000 (38%)] Loss: -1471.249023\n",
      "Train Epoch: 966 [34304/60000 (57%)] Loss: -1483.467285\n",
      "Train Epoch: 966 [45568/60000 (76%)] Loss: -1342.450928\n",
      "Train Epoch: 966 [56832/60000 (95%)] Loss: -1305.552124\n",
      "    epoch          : 966\n",
      "    loss           : -1319.9132518013992\n",
      "Train Epoch: 967 [512/60000 (1%)] Loss: -1283.832886\n",
      "Train Epoch: 967 [11776/60000 (20%)] Loss: -1282.979248\n",
      "Train Epoch: 967 [23040/60000 (38%)] Loss: -1290.943115\n",
      "Train Epoch: 967 [34304/60000 (57%)] Loss: -1014.188416\n",
      "Train Epoch: 967 [45568/60000 (76%)] Loss: -1332.026245\n",
      "Train Epoch: 967 [56832/60000 (95%)] Loss: -1441.599854\n",
      "    epoch          : 967\n",
      "    loss           : -1297.3063683806165\n",
      "Train Epoch: 968 [512/60000 (1%)] Loss: -1144.935547\n",
      "Train Epoch: 968 [11776/60000 (20%)] Loss: -1295.803955\n",
      "Train Epoch: 968 [23040/60000 (38%)] Loss: -1486.236816\n",
      "Train Epoch: 968 [34304/60000 (57%)] Loss: -1365.885864\n",
      "Train Epoch: 968 [45568/60000 (76%)] Loss: -1440.275757\n",
      "Train Epoch: 968 [56832/60000 (95%)] Loss: -1274.019287\n",
      "    epoch          : 968\n",
      "    loss           : -1334.922403454107\n",
      "Train Epoch: 969 [512/60000 (1%)] Loss: -1495.773926\n",
      "Train Epoch: 969 [11776/60000 (20%)] Loss: -1458.550659\n",
      "Train Epoch: 969 [23040/60000 (38%)] Loss: -1168.074585\n",
      "Train Epoch: 969 [34304/60000 (57%)] Loss: -1354.586304\n",
      "Train Epoch: 969 [45568/60000 (76%)] Loss: -1466.651978\n",
      "Train Epoch: 969 [56832/60000 (95%)] Loss: -1188.306641\n",
      "    epoch          : 969\n",
      "    loss           : -1338.1240089545815\n",
      "Train Epoch: 970 [512/60000 (1%)] Loss: -1299.369629\n",
      "Train Epoch: 970 [11776/60000 (20%)] Loss: -1263.131592\n",
      "Train Epoch: 970 [23040/60000 (38%)] Loss: -1263.668457\n",
      "Train Epoch: 970 [34304/60000 (57%)] Loss: -1497.071045\n",
      "Train Epoch: 970 [45568/60000 (76%)] Loss: -1322.929077\n",
      "Train Epoch: 970 [56832/60000 (95%)] Loss: -1016.146240\n",
      "    epoch          : 970\n",
      "    loss           : -1323.197207865742\n",
      "Train Epoch: 971 [512/60000 (1%)] Loss: -1337.029785\n",
      "Train Epoch: 971 [11776/60000 (20%)] Loss: -1487.130249\n",
      "Train Epoch: 971 [23040/60000 (38%)] Loss: -1437.885254\n",
      "Train Epoch: 971 [34304/60000 (57%)] Loss: -1499.632324\n",
      "Train Epoch: 971 [45568/60000 (76%)] Loss: -1366.250610\n",
      "Train Epoch: 971 [56832/60000 (95%)] Loss: -1473.796753\n",
      "    epoch          : 971\n",
      "    loss           : -1322.8092175499867\n",
      "Train Epoch: 972 [512/60000 (1%)] Loss: -1465.468628\n",
      "Train Epoch: 972 [11776/60000 (20%)] Loss: -1483.705933\n",
      "Train Epoch: 972 [23040/60000 (38%)] Loss: -1477.884155\n",
      "Train Epoch: 972 [34304/60000 (57%)] Loss: -1141.137451\n",
      "Train Epoch: 972 [45568/60000 (76%)] Loss: -1336.944946\n",
      "Train Epoch: 972 [56832/60000 (95%)] Loss: -1452.135498\n",
      "    epoch          : 972\n",
      "    loss           : -1342.9930461301642\n",
      "Train Epoch: 973 [512/60000 (1%)] Loss: -1320.708252\n",
      "Train Epoch: 973 [11776/60000 (20%)] Loss: -1327.008301\n",
      "Train Epoch: 973 [23040/60000 (38%)] Loss: -1362.230469\n",
      "Train Epoch: 973 [34304/60000 (57%)] Loss: -1493.259644\n",
      "Train Epoch: 973 [45568/60000 (76%)] Loss: -1459.433594\n",
      "Train Epoch: 973 [56832/60000 (95%)] Loss: -1142.239502\n",
      "    epoch          : 973\n",
      "    loss           : -1309.9179646120233\n",
      "Train Epoch: 974 [512/60000 (1%)] Loss: -1327.435547\n",
      "Train Epoch: 974 [11776/60000 (20%)] Loss: -1448.091919\n",
      "Train Epoch: 974 [23040/60000 (38%)] Loss: -1472.508057\n",
      "Train Epoch: 974 [34304/60000 (57%)] Loss: -1441.185059\n",
      "Train Epoch: 974 [45568/60000 (76%)] Loss: -1330.891724\n",
      "Train Epoch: 974 [56832/60000 (95%)] Loss: -1445.194336\n",
      "    epoch          : 974\n",
      "    loss           : -1327.5994736838475\n",
      "Train Epoch: 975 [512/60000 (1%)] Loss: -1199.700562\n",
      "Train Epoch: 975 [11776/60000 (20%)] Loss: -1271.987183\n",
      "Train Epoch: 975 [23040/60000 (38%)] Loss: -1457.118896\n",
      "Train Epoch: 975 [34304/60000 (57%)] Loss: -1204.483643\n",
      "Train Epoch: 975 [45568/60000 (76%)] Loss: -1326.261230\n",
      "Train Epoch: 975 [56832/60000 (95%)] Loss: -1283.842773\n",
      "    epoch          : 975\n",
      "    loss           : -1316.4996136164261\n",
      "Train Epoch: 976 [512/60000 (1%)] Loss: -1478.670166\n",
      "Train Epoch: 976 [11776/60000 (20%)] Loss: -1344.206665\n",
      "Train Epoch: 976 [23040/60000 (38%)] Loss: -1321.663818\n",
      "Train Epoch: 976 [34304/60000 (57%)] Loss: -1063.162842\n",
      "Train Epoch: 976 [45568/60000 (76%)] Loss: -1467.069458\n",
      "Train Epoch: 976 [56832/60000 (95%)] Loss: -1296.234985\n",
      "    epoch          : 976\n",
      "    loss           : -1307.0548275015447\n",
      "Train Epoch: 977 [512/60000 (1%)] Loss: -1322.030518\n",
      "Train Epoch: 977 [11776/60000 (20%)] Loss: -1365.433594\n",
      "Train Epoch: 977 [23040/60000 (38%)] Loss: -1492.321289\n",
      "Train Epoch: 977 [34304/60000 (57%)] Loss: -1473.248657\n",
      "Train Epoch: 977 [45568/60000 (76%)] Loss: -1463.919189\n",
      "Train Epoch: 977 [56832/60000 (95%)] Loss: -1347.208862\n",
      "    epoch          : 977\n",
      "    loss           : -1346.0678824731858\n",
      "Train Epoch: 978 [512/60000 (1%)] Loss: -1227.877197\n",
      "Train Epoch: 978 [11776/60000 (20%)] Loss: -1454.034912\n",
      "Train Epoch: 978 [23040/60000 (38%)] Loss: -1186.991943\n",
      "Train Epoch: 978 [34304/60000 (57%)] Loss: -1460.741455\n",
      "Train Epoch: 978 [45568/60000 (76%)] Loss: -1500.168701\n",
      "Train Epoch: 978 [56832/60000 (95%)] Loss: -1502.886719\n",
      "    epoch          : 978\n",
      "    loss           : -1335.159980041159\n",
      "Train Epoch: 979 [512/60000 (1%)] Loss: -1161.152954\n",
      "Train Epoch: 979 [11776/60000 (20%)] Loss: -1189.799438\n",
      "Train Epoch: 979 [23040/60000 (38%)] Loss: -1430.117188\n",
      "Train Epoch: 979 [34304/60000 (57%)] Loss: -1329.093628\n",
      "Train Epoch: 979 [45568/60000 (76%)] Loss: -1471.709229\n",
      "Train Epoch: 979 [56832/60000 (95%)] Loss: -1286.370117\n",
      "    epoch          : 979\n",
      "    loss           : -1312.142000187588\n",
      "Train Epoch: 980 [512/60000 (1%)] Loss: -1316.469971\n",
      "Train Epoch: 980 [11776/60000 (20%)] Loss: -1236.507080\n",
      "Train Epoch: 980 [23040/60000 (38%)] Loss: -1434.452026\n",
      "Train Epoch: 980 [34304/60000 (57%)] Loss: -1342.334961\n",
      "Train Epoch: 980 [45568/60000 (76%)] Loss: -1357.903564\n",
      "Train Epoch: 980 [56832/60000 (95%)] Loss: -1315.465332\n",
      "    epoch          : 980\n",
      "    loss           : -1325.3389196018716\n",
      "Train Epoch: 981 [512/60000 (1%)] Loss: -1218.535156\n",
      "Train Epoch: 981 [11776/60000 (20%)] Loss: -1486.238770\n",
      "Train Epoch: 981 [23040/60000 (38%)] Loss: -1195.361572\n",
      "Train Epoch: 981 [34304/60000 (57%)] Loss: -1494.028442\n",
      "Train Epoch: 981 [45568/60000 (76%)] Loss: -1300.003906\n",
      "Train Epoch: 981 [56832/60000 (95%)] Loss: -1498.258545\n",
      "    epoch          : 981\n",
      "    loss           : -1330.2581769867804\n",
      "Train Epoch: 982 [512/60000 (1%)] Loss: -1342.683105\n",
      "Train Epoch: 982 [11776/60000 (20%)] Loss: -1357.037109\n",
      "Train Epoch: 982 [23040/60000 (38%)] Loss: -1313.941406\n",
      "Train Epoch: 982 [34304/60000 (57%)] Loss: -1298.073730\n",
      "Train Epoch: 982 [45568/60000 (76%)] Loss: -1447.018188\n",
      "Train Epoch: 982 [56832/60000 (95%)] Loss: -1317.072144\n",
      "    epoch          : 982\n",
      "    loss           : -1325.4713707185733\n",
      "Train Epoch: 983 [512/60000 (1%)] Loss: -1346.587769\n",
      "Train Epoch: 983 [11776/60000 (20%)] Loss: -1454.812500\n",
      "Train Epoch: 983 [23040/60000 (38%)] Loss: -1346.916382\n",
      "Train Epoch: 983 [34304/60000 (57%)] Loss: -1223.394043\n",
      "Train Epoch: 983 [45568/60000 (76%)] Loss: -1172.377441\n",
      "Train Epoch: 983 [56832/60000 (95%)] Loss: -1285.472534\n",
      "    epoch          : 983\n",
      "    loss           : -1301.2842488261938\n",
      "Train Epoch: 984 [512/60000 (1%)] Loss: -1374.560303\n",
      "Train Epoch: 984 [11776/60000 (20%)] Loss: -1283.405029\n",
      "Train Epoch: 984 [23040/60000 (38%)] Loss: -1133.018066\n",
      "Train Epoch: 984 [34304/60000 (57%)] Loss: -1327.689453\n",
      "Train Epoch: 984 [45568/60000 (76%)] Loss: -1290.541870\n",
      "Train Epoch: 984 [56832/60000 (95%)] Loss: -1168.326660\n",
      "    epoch          : 984\n",
      "    loss           : -1326.7225672835011\n",
      "Train Epoch: 985 [512/60000 (1%)] Loss: -1232.237671\n",
      "Train Epoch: 985 [11776/60000 (20%)] Loss: -984.098755\n",
      "Train Epoch: 985 [23040/60000 (38%)] Loss: -1279.596436\n",
      "Train Epoch: 985 [34304/60000 (57%)] Loss: -1437.178955\n",
      "Train Epoch: 985 [45568/60000 (76%)] Loss: -1474.563232\n",
      "Train Epoch: 985 [56832/60000 (95%)] Loss: -1511.065430\n",
      "    epoch          : 985\n",
      "    loss           : -1333.106135481495\n",
      "Train Epoch: 986 [512/60000 (1%)] Loss: -1453.133057\n",
      "Train Epoch: 986 [11776/60000 (20%)] Loss: -1170.589111\n",
      "Train Epoch: 986 [23040/60000 (38%)] Loss: -1472.570801\n",
      "Train Epoch: 986 [34304/60000 (57%)] Loss: -1160.925049\n",
      "Train Epoch: 986 [45568/60000 (76%)] Loss: -1131.035889\n",
      "Train Epoch: 986 [56832/60000 (95%)] Loss: -1445.831909\n",
      "    epoch          : 986\n",
      "    loss           : -1330.7787504896605\n",
      "Train Epoch: 987 [512/60000 (1%)] Loss: -1354.914551\n",
      "Train Epoch: 987 [11776/60000 (20%)] Loss: -1178.341064\n",
      "Train Epoch: 987 [23040/60000 (38%)] Loss: -1523.702637\n",
      "Train Epoch: 987 [34304/60000 (57%)] Loss: -1484.845215\n",
      "Train Epoch: 987 [45568/60000 (76%)] Loss: -883.444519\n",
      "Train Epoch: 987 [56832/60000 (95%)] Loss: -1293.225220\n",
      "    epoch          : 987\n",
      "    loss           : -1318.567557297184\n",
      "Train Epoch: 988 [512/60000 (1%)] Loss: -1330.997559\n",
      "Train Epoch: 988 [11776/60000 (20%)] Loss: -1330.559570\n",
      "Train Epoch: 988 [23040/60000 (38%)] Loss: -1489.846191\n",
      "Train Epoch: 988 [34304/60000 (57%)] Loss: -1046.418091\n",
      "Train Epoch: 988 [45568/60000 (76%)] Loss: -1469.577393\n",
      "Train Epoch: 988 [56832/60000 (95%)] Loss: -1418.236206\n",
      "    epoch          : 988\n",
      "    loss           : -1321.680758029054\n",
      "Train Epoch: 989 [512/60000 (1%)] Loss: -1204.803955\n",
      "Train Epoch: 989 [11776/60000 (20%)] Loss: -1330.829468\n",
      "Train Epoch: 989 [23040/60000 (38%)] Loss: -1319.932373\n",
      "Train Epoch: 989 [34304/60000 (57%)] Loss: -1352.623413\n",
      "Train Epoch: 989 [45568/60000 (76%)] Loss: -1505.181885\n",
      "Train Epoch: 989 [56832/60000 (95%)] Loss: -1283.342529\n",
      "    epoch          : 989\n",
      "    loss           : -1338.6833090916864\n",
      "Train Epoch: 990 [512/60000 (1%)] Loss: -1180.812744\n",
      "Train Epoch: 990 [11776/60000 (20%)] Loss: -1310.492676\n",
      "Train Epoch: 990 [23040/60000 (38%)] Loss: -1306.905273\n",
      "Train Epoch: 990 [34304/60000 (57%)] Loss: -1248.328125\n",
      "Train Epoch: 990 [45568/60000 (76%)] Loss: -1164.775269\n",
      "Train Epoch: 990 [56832/60000 (95%)] Loss: -1304.349731\n",
      "    epoch          : 990\n",
      "    loss           : -1317.7792553228173\n",
      "Train Epoch: 991 [512/60000 (1%)] Loss: -1326.629883\n",
      "Train Epoch: 991 [11776/60000 (20%)] Loss: -1444.613892\n",
      "Train Epoch: 991 [23040/60000 (38%)] Loss: -1501.843018\n",
      "Train Epoch: 991 [34304/60000 (57%)] Loss: -1312.730103\n",
      "Train Epoch: 991 [45568/60000 (76%)] Loss: -1482.092407\n",
      "Train Epoch: 991 [56832/60000 (95%)] Loss: -1072.464966\n",
      "    epoch          : 991\n",
      "    loss           : -1318.4944608009469\n",
      "Train Epoch: 992 [512/60000 (1%)] Loss: -1337.960327\n",
      "Train Epoch: 992 [11776/60000 (20%)] Loss: -973.828369\n",
      "Train Epoch: 992 [23040/60000 (38%)] Loss: -1355.309204\n",
      "Train Epoch: 992 [34304/60000 (57%)] Loss: -1295.507080\n",
      "Train Epoch: 992 [45568/60000 (76%)] Loss: -1151.611816\n",
      "Train Epoch: 992 [56832/60000 (95%)] Loss: -1450.343872\n",
      "    epoch          : 992\n",
      "    loss           : -1335.7752873479983\n",
      "Train Epoch: 993 [512/60000 (1%)] Loss: -1459.354492\n",
      "Train Epoch: 993 [11776/60000 (20%)] Loss: -1323.241821\n",
      "Train Epoch: 993 [23040/60000 (38%)] Loss: -1327.760864\n",
      "Train Epoch: 993 [34304/60000 (57%)] Loss: -1155.141113\n",
      "Train Epoch: 993 [45568/60000 (76%)] Loss: -1197.774170\n",
      "Train Epoch: 993 [56832/60000 (95%)] Loss: -1113.659180\n",
      "    epoch          : 993\n",
      "    loss           : -1313.5755401438912\n",
      "Train Epoch: 994 [512/60000 (1%)] Loss: -1169.854370\n",
      "Train Epoch: 994 [11776/60000 (20%)] Loss: -1440.754639\n",
      "Train Epoch: 994 [23040/60000 (38%)] Loss: -1434.364746\n",
      "Train Epoch: 994 [34304/60000 (57%)] Loss: -1467.519043\n",
      "Train Epoch: 994 [45568/60000 (76%)] Loss: -1334.886230\n",
      "Train Epoch: 994 [56832/60000 (95%)] Loss: -1313.770020\n",
      "    epoch          : 994\n",
      "    loss           : -1326.8456357104628\n",
      "Train Epoch: 995 [512/60000 (1%)] Loss: -1286.836182\n",
      "Train Epoch: 995 [11776/60000 (20%)] Loss: -1301.041504\n",
      "Train Epoch: 995 [23040/60000 (38%)] Loss: -1159.218872\n",
      "Train Epoch: 995 [34304/60000 (57%)] Loss: -1331.912720\n",
      "Train Epoch: 995 [45568/60000 (76%)] Loss: -1303.742065\n",
      "Train Epoch: 995 [56832/60000 (95%)] Loss: -1469.059082\n",
      "    epoch          : 995\n",
      "    loss           : -1325.575629282806\n",
      "Train Epoch: 996 [512/60000 (1%)] Loss: -1247.629028\n",
      "Train Epoch: 996 [11776/60000 (20%)] Loss: -1469.246704\n",
      "Train Epoch: 996 [23040/60000 (38%)] Loss: -1332.786377\n",
      "Train Epoch: 996 [34304/60000 (57%)] Loss: -1317.535522\n",
      "Train Epoch: 996 [45568/60000 (76%)] Loss: -1183.419678\n",
      "Train Epoch: 996 [56832/60000 (95%)] Loss: -1438.636841\n",
      "    epoch          : 996\n",
      "    loss           : -1324.4182144423662\n",
      "Train Epoch: 997 [512/60000 (1%)] Loss: -1449.139771\n",
      "Train Epoch: 997 [11776/60000 (20%)] Loss: -1365.304688\n",
      "Train Epoch: 997 [23040/60000 (38%)] Loss: -1294.782959\n",
      "Train Epoch: 997 [34304/60000 (57%)] Loss: -1330.102295\n",
      "Train Epoch: 997 [45568/60000 (76%)] Loss: -1490.578613\n",
      "Train Epoch: 997 [56832/60000 (95%)] Loss: -1447.710327\n",
      "    epoch          : 997\n",
      "    loss           : -1317.8160715911347\n",
      "Train Epoch: 998 [512/60000 (1%)] Loss: -1345.920410\n",
      "Train Epoch: 998 [11776/60000 (20%)] Loss: -1340.469971\n",
      "Train Epoch: 998 [23040/60000 (38%)] Loss: -1514.484863\n",
      "Train Epoch: 998 [34304/60000 (57%)] Loss: -1439.420410\n",
      "Train Epoch: 998 [45568/60000 (76%)] Loss: -1245.494629\n",
      "Train Epoch: 998 [56832/60000 (95%)] Loss: -1497.853027\n",
      "    epoch          : 998\n",
      "    loss           : -1344.7083481610832\n",
      "Train Epoch: 999 [512/60000 (1%)] Loss: -1473.783691\n",
      "Train Epoch: 999 [11776/60000 (20%)] Loss: -1165.342163\n",
      "Train Epoch: 999 [23040/60000 (38%)] Loss: -1055.872803\n",
      "Train Epoch: 999 [34304/60000 (57%)] Loss: -1256.170410\n",
      "Train Epoch: 999 [45568/60000 (76%)] Loss: -1488.115112\n",
      "Train Epoch: 999 [56832/60000 (95%)] Loss: -1518.776611\n",
      "    epoch          : 999\n",
      "    loss           : -1313.155031021032\n",
      "Train Epoch: 1000 [512/60000 (1%)] Loss: -1015.493408\n",
      "Train Epoch: 1000 [11776/60000 (20%)] Loss: -1235.226562\n",
      "Train Epoch: 1000 [23040/60000 (38%)] Loss: -1201.875488\n",
      "Train Epoch: 1000 [34304/60000 (57%)] Loss: -1322.199707\n",
      "Train Epoch: 1000 [45568/60000 (76%)] Loss: -1309.821045\n",
      "Train Epoch: 1000 [56832/60000 (95%)] Loss: -1454.214478\n",
      "    epoch          : 1000\n",
      "    loss           : -1326.617859403966\n",
      "Saving checkpoint: saved/models/Mnist_DeepGenerativeOperad/0127_111843/checkpoint-epoch1000.pth ...\n",
      "Train Epoch: 1001 [512/60000 (1%)] Loss: -1097.723389\n",
      "Train Epoch: 1001 [11776/60000 (20%)] Loss: -1482.482910\n",
      "Train Epoch: 1001 [23040/60000 (38%)] Loss: -1461.076782\n",
      "Train Epoch: 1001 [34304/60000 (57%)] Loss: -1490.853516\n",
      "Train Epoch: 1001 [45568/60000 (76%)] Loss: -1178.022339\n",
      "Train Epoch: 1001 [56832/60000 (95%)] Loss: -1024.391846\n",
      "    epoch          : 1001\n",
      "    loss           : -1315.3319229729432\n",
      "Train Epoch: 1002 [512/60000 (1%)] Loss: -1287.601196\n",
      "Train Epoch: 1002 [11776/60000 (20%)] Loss: -1356.576416\n",
      "Train Epoch: 1002 [23040/60000 (38%)] Loss: -1170.484009\n",
      "Train Epoch: 1002 [34304/60000 (57%)] Loss: -1266.720215\n",
      "Train Epoch: 1002 [45568/60000 (76%)] Loss: -1290.539551\n",
      "Train Epoch: 1002 [56832/60000 (95%)] Loss: -1475.299072\n",
      "    epoch          : 1002\n",
      "    loss           : -1320.6020331948491\n",
      "Train Epoch: 1003 [512/60000 (1%)] Loss: -1174.619629\n",
      "Train Epoch: 1003 [11776/60000 (20%)] Loss: -1329.536133\n",
      "Train Epoch: 1003 [23040/60000 (38%)] Loss: -1035.248169\n",
      "Train Epoch: 1003 [34304/60000 (57%)] Loss: -1078.632324\n",
      "Train Epoch: 1003 [45568/60000 (76%)] Loss: -1469.011719\n",
      "Train Epoch: 1003 [56832/60000 (95%)] Loss: -1337.303589\n",
      "    epoch          : 1003\n",
      "    loss           : -1329.4904793777034\n",
      "Train Epoch: 1004 [512/60000 (1%)] Loss: -1479.923462\n",
      "Train Epoch: 1004 [11776/60000 (20%)] Loss: -1301.941284\n",
      "Train Epoch: 1004 [23040/60000 (38%)] Loss: -1313.348999\n",
      "Train Epoch: 1004 [34304/60000 (57%)] Loss: -1376.983887\n",
      "Train Epoch: 1004 [45568/60000 (76%)] Loss: -1373.487793\n",
      "Train Epoch: 1004 [56832/60000 (95%)] Loss: -1154.593384\n",
      "    epoch          : 1004\n",
      "    loss           : -1319.1628809352378\n",
      "Train Epoch: 1005 [512/60000 (1%)] Loss: -1466.693115\n",
      "Train Epoch: 1005 [11776/60000 (20%)] Loss: -1477.535156\n",
      "Train Epoch: 1005 [23040/60000 (38%)] Loss: -1135.776245\n",
      "Train Epoch: 1005 [34304/60000 (57%)] Loss: -1480.272949\n",
      "Train Epoch: 1005 [45568/60000 (76%)] Loss: -1350.183960\n",
      "Train Epoch: 1005 [56832/60000 (95%)] Loss: -1513.011475\n",
      "    epoch          : 1005\n",
      "    loss           : -1349.7005911789372\n",
      "Train Epoch: 1006 [512/60000 (1%)] Loss: -1154.511353\n",
      "Train Epoch: 1006 [11776/60000 (20%)] Loss: -1070.357544\n",
      "Train Epoch: 1006 [23040/60000 (38%)] Loss: -1294.227783\n",
      "Train Epoch: 1006 [34304/60000 (57%)] Loss: -1295.208252\n",
      "Train Epoch: 1006 [45568/60000 (76%)] Loss: -1458.487305\n",
      "Train Epoch: 1006 [56832/60000 (95%)] Loss: -1357.948853\n",
      "    epoch          : 1006\n",
      "    loss           : -1304.1555727511475\n",
      "Train Epoch: 1007 [512/60000 (1%)] Loss: -1150.144653\n",
      "Train Epoch: 1007 [11776/60000 (20%)] Loss: -1325.491821\n",
      "Train Epoch: 1007 [23040/60000 (38%)] Loss: -1504.395142\n",
      "Train Epoch: 1007 [34304/60000 (57%)] Loss: -1364.107544\n",
      "Train Epoch: 1007 [45568/60000 (76%)] Loss: -1360.085449\n",
      "Train Epoch: 1007 [56832/60000 (95%)] Loss: -1026.550293\n",
      "    epoch          : 1007\n",
      "    loss           : -1335.7457806430966\n",
      "Train Epoch: 1008 [512/60000 (1%)] Loss: -1333.877930\n",
      "Train Epoch: 1008 [11776/60000 (20%)] Loss: -1448.301147\n",
      "Train Epoch: 1008 [23040/60000 (38%)] Loss: -1321.314331\n",
      "Train Epoch: 1008 [34304/60000 (57%)] Loss: -1449.920410\n",
      "Train Epoch: 1008 [45568/60000 (76%)] Loss: -1315.588135\n",
      "Train Epoch: 1008 [56832/60000 (95%)] Loss: -1391.881958\n",
      "    epoch          : 1008\n",
      "    loss           : -1327.7807324080818\n",
      "Train Epoch: 1009 [512/60000 (1%)] Loss: -1342.267334\n",
      "Train Epoch: 1009 [11776/60000 (20%)] Loss: -1473.704590\n",
      "Train Epoch: 1009 [23040/60000 (38%)] Loss: -1279.810791\n",
      "Train Epoch: 1009 [34304/60000 (57%)] Loss: -1487.084473\n",
      "Train Epoch: 1009 [45568/60000 (76%)] Loss: -1354.014526\n",
      "Train Epoch: 1009 [56832/60000 (95%)] Loss: -1486.565430\n",
      "    epoch          : 1009\n",
      "    loss           : -1311.0836078191207\n",
      "Train Epoch: 1010 [512/60000 (1%)] Loss: -1494.622681\n",
      "Train Epoch: 1010 [11776/60000 (20%)] Loss: -1347.616943\n",
      "Train Epoch: 1010 [23040/60000 (38%)] Loss: -1490.032959\n",
      "Train Epoch: 1010 [34304/60000 (57%)] Loss: -1386.241577\n",
      "Train Epoch: 1010 [45568/60000 (76%)] Loss: -1496.456543\n",
      "Train Epoch: 1010 [56832/60000 (95%)] Loss: -1121.664062\n",
      "    epoch          : 1010\n",
      "    loss           : -1342.03260829085\n",
      "Train Epoch: 1011 [512/60000 (1%)] Loss: -1345.385254\n",
      "Train Epoch: 1011 [11776/60000 (20%)] Loss: -1340.741333\n",
      "Train Epoch: 1011 [23040/60000 (38%)] Loss: -1448.222656\n",
      "Train Epoch: 1011 [34304/60000 (57%)] Loss: -1164.166504\n",
      "Train Epoch: 1011 [45568/60000 (76%)] Loss: -1322.486816\n",
      "Train Epoch: 1011 [56832/60000 (95%)] Loss: -1472.914307\n",
      "    epoch          : 1011\n",
      "    loss           : -1328.1634669761872\n",
      "Train Epoch: 1012 [512/60000 (1%)] Loss: -1472.771240\n",
      "Train Epoch: 1012 [11776/60000 (20%)] Loss: -1310.944458\n",
      "Train Epoch: 1012 [23040/60000 (38%)] Loss: -1001.536011\n",
      "Train Epoch: 1012 [34304/60000 (57%)] Loss: -1204.706421\n",
      "Train Epoch: 1012 [45568/60000 (76%)] Loss: -1493.233032\n",
      "Train Epoch: 1012 [56832/60000 (95%)] Loss: -1338.587280\n",
      "    epoch          : 1012\n",
      "    loss           : -1326.3497648939574\n",
      "Train Epoch: 1013 [512/60000 (1%)] Loss: -1311.479126\n",
      "Train Epoch: 1013 [11776/60000 (20%)] Loss: -1117.890381\n",
      "Train Epoch: 1013 [23040/60000 (38%)] Loss: -1139.540649\n",
      "Train Epoch: 1013 [34304/60000 (57%)] Loss: -1459.979614\n",
      "Train Epoch: 1013 [45568/60000 (76%)] Loss: -1183.198853\n",
      "Train Epoch: 1013 [56832/60000 (95%)] Loss: -1350.994141\n",
      "    epoch          : 1013\n",
      "    loss           : -1329.943050233658\n",
      "Train Epoch: 1014 [512/60000 (1%)] Loss: -1297.943970\n",
      "Train Epoch: 1014 [11776/60000 (20%)] Loss: -1311.832397\n",
      "Train Epoch: 1014 [23040/60000 (38%)] Loss: -1315.413696\n",
      "Train Epoch: 1014 [34304/60000 (57%)] Loss: -1353.505005\n",
      "Train Epoch: 1014 [45568/60000 (76%)] Loss: -1287.565308\n",
      "Train Epoch: 1014 [56832/60000 (95%)] Loss: -1322.139404\n",
      "    epoch          : 1014\n",
      "    loss           : -1331.2816177626787\n",
      "Train Epoch: 1015 [512/60000 (1%)] Loss: -1482.546143\n",
      "Train Epoch: 1015 [11776/60000 (20%)] Loss: -1100.964355\n",
      "Train Epoch: 1015 [23040/60000 (38%)] Loss: -1157.767456\n",
      "Train Epoch: 1015 [34304/60000 (57%)] Loss: -1298.861084\n",
      "Train Epoch: 1015 [45568/60000 (76%)] Loss: -1209.505371\n",
      "Train Epoch: 1015 [56832/60000 (95%)] Loss: -1311.726929\n",
      "    epoch          : 1015\n",
      "    loss           : -1321.654330323645\n",
      "Train Epoch: 1016 [512/60000 (1%)] Loss: -1489.367188\n",
      "Train Epoch: 1016 [11776/60000 (20%)] Loss: -1440.717773\n",
      "Train Epoch: 1016 [23040/60000 (38%)] Loss: -1463.463623\n",
      "Train Epoch: 1016 [34304/60000 (57%)] Loss: -1158.977173\n",
      "Train Epoch: 1016 [45568/60000 (76%)] Loss: -1140.555786\n",
      "Train Epoch: 1016 [56832/60000 (95%)] Loss: -1302.789307\n",
      "    epoch          : 1016\n",
      "    loss           : -1292.0420252913136\n",
      "Train Epoch: 1017 [512/60000 (1%)] Loss: -1327.985107\n",
      "Train Epoch: 1017 [11776/60000 (20%)] Loss: -1472.189087\n",
      "Train Epoch: 1017 [23040/60000 (38%)] Loss: -1473.546875\n",
      "Train Epoch: 1017 [34304/60000 (57%)] Loss: -1294.305298\n",
      "Train Epoch: 1017 [45568/60000 (76%)] Loss: -1451.146240\n",
      "Train Epoch: 1017 [56832/60000 (95%)] Loss: -1434.432251\n",
      "    epoch          : 1017\n",
      "    loss           : -1332.673716054798\n",
      "Train Epoch: 1018 [512/60000 (1%)] Loss: -1334.650879\n",
      "Train Epoch: 1018 [11776/60000 (20%)] Loss: -1441.323486\n",
      "Train Epoch: 1018 [23040/60000 (38%)] Loss: -1500.940796\n",
      "Train Epoch: 1018 [34304/60000 (57%)] Loss: -1371.866821\n",
      "Train Epoch: 1018 [45568/60000 (76%)] Loss: -1288.470825\n",
      "Train Epoch: 1018 [56832/60000 (95%)] Loss: -1293.370605\n",
      "    epoch          : 1018\n",
      "    loss           : -1336.162301446085\n",
      "Train Epoch: 1019 [512/60000 (1%)] Loss: -1205.814941\n",
      "Train Epoch: 1019 [11776/60000 (20%)] Loss: -1385.998047\n",
      "Train Epoch: 1019 [23040/60000 (38%)] Loss: -1290.449097\n",
      "Train Epoch: 1019 [34304/60000 (57%)] Loss: -1197.376221\n",
      "Train Epoch: 1019 [45568/60000 (76%)] Loss: -1333.721313\n",
      "Train Epoch: 1019 [56832/60000 (95%)] Loss: -1478.141113\n",
      "    epoch          : 1019\n",
      "    loss           : -1327.0885999431719\n",
      "Train Epoch: 1020 [512/60000 (1%)] Loss: -985.072388\n",
      "Train Epoch: 1020 [11776/60000 (20%)] Loss: -1201.810913\n",
      "Train Epoch: 1020 [23040/60000 (38%)] Loss: -1465.273315\n",
      "Train Epoch: 1020 [34304/60000 (57%)] Loss: -1360.790039\n",
      "Train Epoch: 1020 [45568/60000 (76%)] Loss: -1339.968384\n",
      "Train Epoch: 1020 [56832/60000 (95%)] Loss: -1315.764038\n",
      "    epoch          : 1020\n",
      "    loss           : -1312.9125173105358\n",
      "Train Epoch: 1021 [512/60000 (1%)] Loss: -1323.627686\n",
      "Train Epoch: 1021 [11776/60000 (20%)] Loss: -1149.431885\n",
      "Train Epoch: 1021 [23040/60000 (38%)] Loss: -1489.064941\n",
      "Train Epoch: 1021 [34304/60000 (57%)] Loss: -1439.160156\n",
      "Train Epoch: 1021 [45568/60000 (76%)] Loss: -1113.532227\n",
      "Train Epoch: 1021 [56832/60000 (95%)] Loss: -1499.783447\n",
      "    epoch          : 1021\n",
      "    loss           : -1334.4757112837108\n",
      "Train Epoch: 1022 [512/60000 (1%)] Loss: -1244.125244\n",
      "Train Epoch: 1022 [11776/60000 (20%)] Loss: -1315.410645\n",
      "Train Epoch: 1022 [23040/60000 (38%)] Loss: -1343.056885\n",
      "Train Epoch: 1022 [34304/60000 (57%)] Loss: -1526.970093\n",
      "Train Epoch: 1022 [45568/60000 (76%)] Loss: -1330.827271\n",
      "Train Epoch: 1022 [56832/60000 (95%)] Loss: -1474.661011\n",
      "    epoch          : 1022\n",
      "    loss           : -1322.3429324047715\n",
      "Train Epoch: 1023 [512/60000 (1%)] Loss: -1318.131348\n",
      "Train Epoch: 1023 [11776/60000 (20%)] Loss: -1312.083862\n",
      "Train Epoch: 1023 [23040/60000 (38%)] Loss: -1233.714600\n",
      "Train Epoch: 1023 [34304/60000 (57%)] Loss: -1172.514282\n",
      "Train Epoch: 1023 [45568/60000 (76%)] Loss: -1472.704468\n",
      "Train Epoch: 1023 [56832/60000 (95%)] Loss: -1161.466431\n",
      "    epoch          : 1023\n",
      "    loss           : -1333.4200494626148\n",
      "Train Epoch: 1024 [512/60000 (1%)] Loss: -1433.536011\n",
      "Train Epoch: 1024 [11776/60000 (20%)] Loss: -1277.132202\n",
      "Train Epoch: 1024 [23040/60000 (38%)] Loss: -1472.016113\n",
      "Train Epoch: 1024 [34304/60000 (57%)] Loss: -1385.182129\n",
      "Train Epoch: 1024 [45568/60000 (76%)] Loss: -1453.495239\n",
      "Train Epoch: 1024 [56832/60000 (95%)] Loss: -1207.655273\n",
      "    epoch          : 1024\n",
      "    loss           : -1311.7751378635903\n",
      "Train Epoch: 1025 [512/60000 (1%)] Loss: -1294.173828\n",
      "Train Epoch: 1025 [11776/60000 (20%)] Loss: -1440.000854\n",
      "Train Epoch: 1025 [23040/60000 (38%)] Loss: -1508.856812\n",
      "Train Epoch: 1025 [34304/60000 (57%)] Loss: -1340.360107\n",
      "Train Epoch: 1025 [45568/60000 (76%)] Loss: -1468.387207\n",
      "Train Epoch: 1025 [56832/60000 (95%)] Loss: -1275.985596\n",
      "    epoch          : 1025\n",
      "    loss           : -1331.276091322387\n",
      "Train Epoch: 1026 [512/60000 (1%)] Loss: -1451.100342\n",
      "Train Epoch: 1026 [11776/60000 (20%)] Loss: -1314.831299\n",
      "Train Epoch: 1026 [23040/60000 (38%)] Loss: -1277.585815\n",
      "Train Epoch: 1026 [34304/60000 (57%)] Loss: -1473.310181\n",
      "Train Epoch: 1026 [45568/60000 (76%)] Loss: -1503.950562\n",
      "Train Epoch: 1026 [56832/60000 (95%)] Loss: -1469.696045\n",
      "    epoch          : 1026\n",
      "    loss           : -1331.76778881698\n",
      "Train Epoch: 1027 [512/60000 (1%)] Loss: -1037.143555\n",
      "Train Epoch: 1027 [11776/60000 (20%)] Loss: -1317.102539\n",
      "Train Epoch: 1027 [23040/60000 (38%)] Loss: -1466.612671\n",
      "Train Epoch: 1027 [34304/60000 (57%)] Loss: -916.476379\n",
      "Train Epoch: 1027 [45568/60000 (76%)] Loss: -1105.545776\n",
      "Train Epoch: 1027 [56832/60000 (95%)] Loss: -1285.022461\n",
      "    epoch          : 1027\n",
      "    loss           : -1297.4364048155014\n",
      "Train Epoch: 1028 [512/60000 (1%)] Loss: -1264.481689\n",
      "Train Epoch: 1028 [11776/60000 (20%)] Loss: -1457.875732\n",
      "Train Epoch: 1028 [23040/60000 (38%)] Loss: -1473.955933\n",
      "Train Epoch: 1028 [34304/60000 (57%)] Loss: -1340.046265\n",
      "Train Epoch: 1028 [45568/60000 (76%)] Loss: -1508.819458\n",
      "Train Epoch: 1028 [56832/60000 (95%)] Loss: -1493.957031\n",
      "    epoch          : 1028\n",
      "    loss           : -1323.9082643325721\n",
      "Train Epoch: 1029 [512/60000 (1%)] Loss: -1395.200195\n",
      "Train Epoch: 1029 [11776/60000 (20%)] Loss: -1164.692505\n",
      "Train Epoch: 1029 [23040/60000 (38%)] Loss: -1450.443359\n",
      "Train Epoch: 1029 [34304/60000 (57%)] Loss: -1309.971191\n",
      "Train Epoch: 1029 [45568/60000 (76%)] Loss: -1140.632080\n",
      "Train Epoch: 1029 [56832/60000 (95%)] Loss: -1289.439209\n",
      "    epoch          : 1029\n",
      "    loss           : -1315.9705222609355\n",
      "Train Epoch: 1030 [512/60000 (1%)] Loss: -1353.352539\n",
      "Train Epoch: 1030 [11776/60000 (20%)] Loss: -1154.474365\n",
      "Train Epoch: 1030 [23040/60000 (38%)] Loss: -1483.010010\n",
      "Train Epoch: 1030 [34304/60000 (57%)] Loss: -1433.157837\n",
      "Train Epoch: 1030 [45568/60000 (76%)] Loss: -1132.599243\n",
      "Train Epoch: 1030 [56832/60000 (95%)] Loss: -1122.612671\n",
      "    epoch          : 1030\n",
      "    loss           : -1327.1439167604608\n",
      "Train Epoch: 1031 [512/60000 (1%)] Loss: -1288.692993\n",
      "Train Epoch: 1031 [11776/60000 (20%)] Loss: -1139.246460\n",
      "Train Epoch: 1031 [23040/60000 (38%)] Loss: -1134.157104\n",
      "Train Epoch: 1031 [34304/60000 (57%)] Loss: -1510.055786\n",
      "Train Epoch: 1031 [45568/60000 (76%)] Loss: -1339.613037\n",
      "Train Epoch: 1031 [56832/60000 (95%)] Loss: -1514.649902\n",
      "    epoch          : 1031\n",
      "    loss           : -1323.4758883546301\n",
      "Train Epoch: 1032 [512/60000 (1%)] Loss: -1193.318237\n",
      "Train Epoch: 1032 [11776/60000 (20%)] Loss: -1272.704468\n",
      "Train Epoch: 1032 [23040/60000 (38%)] Loss: -1461.682861\n",
      "Train Epoch: 1032 [34304/60000 (57%)] Loss: -1347.576416\n",
      "Train Epoch: 1032 [45568/60000 (76%)] Loss: -1206.643555\n",
      "Train Epoch: 1032 [56832/60000 (95%)] Loss: -1297.265381\n",
      "    epoch          : 1032\n",
      "    loss           : -1332.8648574742895\n",
      "Train Epoch: 1033 [512/60000 (1%)] Loss: -1487.525879\n",
      "Train Epoch: 1033 [11776/60000 (20%)] Loss: -1309.315674\n",
      "Train Epoch: 1033 [23040/60000 (38%)] Loss: -1378.469849\n",
      "Train Epoch: 1033 [34304/60000 (57%)] Loss: -1360.383789\n",
      "Train Epoch: 1033 [45568/60000 (76%)] Loss: -1284.907959\n",
      "Train Epoch: 1033 [56832/60000 (95%)] Loss: -1363.654541\n",
      "    epoch          : 1033\n",
      "    loss           : -1349.2407686912406\n",
      "Train Epoch: 1034 [512/60000 (1%)] Loss: -1344.191406\n",
      "Train Epoch: 1034 [11776/60000 (20%)] Loss: -1326.927490\n",
      "Train Epoch: 1034 [23040/60000 (38%)] Loss: -1323.994019\n",
      "Train Epoch: 1034 [34304/60000 (57%)] Loss: -1184.644531\n",
      "Train Epoch: 1034 [45568/60000 (76%)] Loss: -1448.626221\n",
      "Train Epoch: 1034 [56832/60000 (95%)] Loss: -1494.639526\n",
      "    epoch          : 1034\n",
      "    loss           : -1325.9718289994923\n",
      "Train Epoch: 1035 [512/60000 (1%)] Loss: -1295.127197\n",
      "Train Epoch: 1035 [11776/60000 (20%)] Loss: -1332.299927\n",
      "Train Epoch: 1035 [23040/60000 (38%)] Loss: -1306.789429\n",
      "Train Epoch: 1035 [34304/60000 (57%)] Loss: -1290.438721\n",
      "Train Epoch: 1035 [45568/60000 (76%)] Loss: -1291.446777\n",
      "Train Epoch: 1035 [56832/60000 (95%)] Loss: -1328.709595\n",
      "    epoch          : 1035\n",
      "    loss           : -1311.8310136525643\n",
      "Train Epoch: 1036 [512/60000 (1%)] Loss: -1336.955200\n",
      "Train Epoch: 1036 [11776/60000 (20%)] Loss: -1184.163452\n",
      "Train Epoch: 1036 [23040/60000 (38%)] Loss: -1411.146606\n",
      "Train Epoch: 1036 [34304/60000 (57%)] Loss: -1489.128052\n",
      "Train Epoch: 1036 [45568/60000 (76%)] Loss: -1325.534424\n",
      "Train Epoch: 1036 [56832/60000 (95%)] Loss: -1159.652832\n",
      "    epoch          : 1036\n",
      "    loss           : -1310.2720597261764\n",
      "Train Epoch: 1037 [512/60000 (1%)] Loss: -1126.955688\n",
      "Train Epoch: 1037 [11776/60000 (20%)] Loss: -1494.035156\n",
      "Train Epoch: 1037 [23040/60000 (38%)] Loss: -1338.068359\n",
      "Train Epoch: 1037 [34304/60000 (57%)] Loss: -1143.021118\n",
      "Train Epoch: 1037 [45568/60000 (76%)] Loss: -1476.576172\n",
      "Train Epoch: 1037 [56832/60000 (95%)] Loss: -1332.665161\n",
      "    epoch          : 1037\n",
      "    loss           : -1327.4926735398458\n",
      "Train Epoch: 1038 [512/60000 (1%)] Loss: -1466.740479\n",
      "Train Epoch: 1038 [11776/60000 (20%)] Loss: -1451.796143\n",
      "Train Epoch: 1038 [23040/60000 (38%)] Loss: -1372.727051\n",
      "Train Epoch: 1038 [34304/60000 (57%)] Loss: -1274.871460\n",
      "Train Epoch: 1038 [45568/60000 (76%)] Loss: -1337.234985\n",
      "Train Epoch: 1038 [56832/60000 (95%)] Loss: -1197.460083\n",
      "    epoch          : 1038\n",
      "    loss           : -1325.1132215941693\n",
      "Train Epoch: 1039 [512/60000 (1%)] Loss: -1355.434326\n",
      "Train Epoch: 1039 [11776/60000 (20%)] Loss: -1465.909668\n",
      "Train Epoch: 1039 [23040/60000 (38%)] Loss: -1301.992920\n",
      "Train Epoch: 1039 [34304/60000 (57%)] Loss: -1336.510498\n",
      "Train Epoch: 1039 [45568/60000 (76%)] Loss: -1198.620239\n",
      "Train Epoch: 1039 [56832/60000 (95%)] Loss: -1296.818115\n",
      "    epoch          : 1039\n",
      "    loss           : -1324.493019578147\n",
      "Train Epoch: 1040 [512/60000 (1%)] Loss: -1299.830200\n",
      "Train Epoch: 1040 [11776/60000 (20%)] Loss: -1376.931152\n",
      "Train Epoch: 1040 [23040/60000 (38%)] Loss: -1498.716431\n",
      "Train Epoch: 1040 [34304/60000 (57%)] Loss: -1337.634277\n",
      "Train Epoch: 1040 [45568/60000 (76%)] Loss: -1236.809692\n",
      "Train Epoch: 1040 [56832/60000 (95%)] Loss: -1253.740723\n",
      "    epoch          : 1040\n",
      "    loss           : -1320.9761678404727\n",
      "Train Epoch: 1041 [512/60000 (1%)] Loss: -1337.348267\n",
      "Train Epoch: 1041 [11776/60000 (20%)] Loss: -1368.725220\n",
      "Train Epoch: 1041 [23040/60000 (38%)] Loss: -1294.990112\n",
      "Train Epoch: 1041 [34304/60000 (57%)] Loss: -1338.164551\n",
      "Train Epoch: 1041 [45568/60000 (76%)] Loss: -1451.088867\n",
      "Train Epoch: 1041 [56832/60000 (95%)] Loss: -1008.637146\n",
      "    epoch          : 1041\n",
      "    loss           : -1315.9395129532463\n",
      "Train Epoch: 1042 [512/60000 (1%)] Loss: -1480.817627\n",
      "Train Epoch: 1042 [11776/60000 (20%)] Loss: -1189.507080\n",
      "Train Epoch: 1042 [23040/60000 (38%)] Loss: -1330.190552\n",
      "Train Epoch: 1042 [34304/60000 (57%)] Loss: -1348.273926\n",
      "Train Epoch: 1042 [45568/60000 (76%)] Loss: -1490.539795\n",
      "Train Epoch: 1042 [56832/60000 (95%)] Loss: -1454.926514\n",
      "    epoch          : 1042\n",
      "    loss           : -1343.26134822867\n",
      "Train Epoch: 1043 [512/60000 (1%)] Loss: -1283.496094\n",
      "Train Epoch: 1043 [11776/60000 (20%)] Loss: -1331.822144\n",
      "Train Epoch: 1043 [23040/60000 (38%)] Loss: -1170.212524\n",
      "Train Epoch: 1043 [34304/60000 (57%)] Loss: -1361.613892\n",
      "Train Epoch: 1043 [45568/60000 (76%)] Loss: -1457.915527\n",
      "Train Epoch: 1043 [56832/60000 (95%)] Loss: -1453.662964\n",
      "    epoch          : 1043\n",
      "    loss           : -1305.7943784207275\n",
      "Train Epoch: 1044 [512/60000 (1%)] Loss: -1062.122925\n",
      "Train Epoch: 1044 [11776/60000 (20%)] Loss: -1483.015747\n",
      "Train Epoch: 1044 [23040/60000 (38%)] Loss: -1365.015259\n",
      "Train Epoch: 1044 [34304/60000 (57%)] Loss: -1466.272705\n",
      "Train Epoch: 1044 [45568/60000 (76%)] Loss: -1262.054810\n",
      "Train Epoch: 1044 [56832/60000 (95%)] Loss: -1475.818970\n",
      "    epoch          : 1044\n",
      "    loss           : -1327.1034301068148\n",
      "Train Epoch: 1045 [512/60000 (1%)] Loss: -1032.498413\n",
      "Train Epoch: 1045 [11776/60000 (20%)] Loss: -1451.035156\n",
      "Train Epoch: 1045 [23040/60000 (38%)] Loss: -1318.806396\n",
      "Train Epoch: 1045 [34304/60000 (57%)] Loss: -1460.736938\n",
      "Train Epoch: 1045 [45568/60000 (76%)] Loss: -1135.510498\n",
      "Train Epoch: 1045 [56832/60000 (95%)] Loss: -1481.124268\n",
      "    epoch          : 1045\n",
      "    loss           : -1327.5607194631111\n",
      "Train Epoch: 1046 [512/60000 (1%)] Loss: -1335.798828\n",
      "Train Epoch: 1046 [11776/60000 (20%)] Loss: -1513.819824\n",
      "Train Epoch: 1046 [23040/60000 (38%)] Loss: -1255.135376\n",
      "Train Epoch: 1046 [34304/60000 (57%)] Loss: -1318.045654\n",
      "Train Epoch: 1046 [45568/60000 (76%)] Loss: -1335.933228\n",
      "Train Epoch: 1046 [56832/60000 (95%)] Loss: -1189.608398\n",
      "    epoch          : 1046\n",
      "    loss           : -1323.0038284905213\n",
      "Train Epoch: 1047 [512/60000 (1%)] Loss: -1366.525879\n",
      "Train Epoch: 1047 [11776/60000 (20%)] Loss: -1279.549805\n",
      "Train Epoch: 1047 [23040/60000 (38%)] Loss: -1283.346680\n",
      "Train Epoch: 1047 [34304/60000 (57%)] Loss: -1457.942627\n",
      "Train Epoch: 1047 [45568/60000 (76%)] Loss: -1448.087158\n",
      "Train Epoch: 1047 [56832/60000 (95%)] Loss: -1485.619385\n",
      "    epoch          : 1047\n",
      "    loss           : -1332.4854024251304\n",
      "Train Epoch: 1048 [512/60000 (1%)] Loss: -1281.482178\n",
      "Train Epoch: 1048 [11776/60000 (20%)] Loss: -1466.359009\n",
      "Train Epoch: 1048 [23040/60000 (38%)] Loss: -1471.628418\n",
      "Train Epoch: 1048 [34304/60000 (57%)] Loss: -1196.571045\n",
      "Train Epoch: 1048 [45568/60000 (76%)] Loss: -1312.407227\n",
      "Train Epoch: 1048 [56832/60000 (95%)] Loss: -1156.259888\n",
      "    epoch          : 1048\n",
      "    loss           : -1304.079492946129\n",
      "Train Epoch: 1049 [512/60000 (1%)] Loss: -1384.788330\n",
      "Train Epoch: 1049 [11776/60000 (20%)] Loss: -1502.809326\n",
      "Train Epoch: 1049 [23040/60000 (38%)] Loss: -1529.241089\n",
      "Train Epoch: 1049 [34304/60000 (57%)] Loss: -1183.194580\n",
      "Train Epoch: 1049 [45568/60000 (76%)] Loss: -1349.252441\n",
      "Train Epoch: 1049 [56832/60000 (95%)] Loss: -1148.942627\n",
      "    epoch          : 1049\n",
      "    loss           : -1314.5959351965262\n",
      "Train Epoch: 1050 [512/60000 (1%)] Loss: -1454.390137\n",
      "Train Epoch: 1050 [11776/60000 (20%)] Loss: -998.152710\n",
      "Train Epoch: 1050 [23040/60000 (38%)] Loss: -1171.523682\n",
      "Train Epoch: 1050 [34304/60000 (57%)] Loss: -1352.854004\n",
      "Train Epoch: 1050 [45568/60000 (76%)] Loss: -1338.278564\n",
      "Train Epoch: 1050 [56832/60000 (95%)] Loss: -1498.349609\n",
      "    epoch          : 1050\n",
      "    loss           : -1321.2560464460296\n",
      "Train Epoch: 1051 [512/60000 (1%)] Loss: -1518.489990\n",
      "Train Epoch: 1051 [11776/60000 (20%)] Loss: -1348.944214\n",
      "Train Epoch: 1051 [23040/60000 (38%)] Loss: -1313.216797\n",
      "Train Epoch: 1051 [34304/60000 (57%)] Loss: -1302.206421\n",
      "Train Epoch: 1051 [45568/60000 (76%)] Loss: -1313.198486\n",
      "Train Epoch: 1051 [56832/60000 (95%)] Loss: -1215.206299\n",
      "    epoch          : 1051\n",
      "    loss           : -1311.9327647753355\n",
      "Train Epoch: 1052 [512/60000 (1%)] Loss: -1471.921143\n",
      "Train Epoch: 1052 [11776/60000 (20%)] Loss: -1362.577881\n",
      "Train Epoch: 1052 [23040/60000 (38%)] Loss: -994.074707\n",
      "Train Epoch: 1052 [34304/60000 (57%)] Loss: -1504.657959\n",
      "Train Epoch: 1052 [45568/60000 (76%)] Loss: -1304.349487\n",
      "Train Epoch: 1052 [56832/60000 (95%)] Loss: -1263.317505\n",
      "    epoch          : 1052\n",
      "    loss           : -1337.2148916815634\n",
      "Train Epoch: 1053 [512/60000 (1%)] Loss: -1478.625854\n",
      "Train Epoch: 1053 [11776/60000 (20%)] Loss: -1309.528564\n",
      "Train Epoch: 1053 [23040/60000 (38%)] Loss: -1466.536865\n",
      "Train Epoch: 1053 [34304/60000 (57%)] Loss: -1332.074707\n",
      "Train Epoch: 1053 [45568/60000 (76%)] Loss: -1298.256714\n",
      "Train Epoch: 1053 [56832/60000 (95%)] Loss: -1328.639404\n",
      "    epoch          : 1053\n",
      "    loss           : -1320.1787174892963\n",
      "Train Epoch: 1054 [512/60000 (1%)] Loss: -1142.368774\n",
      "Train Epoch: 1054 [11776/60000 (20%)] Loss: -1506.520996\n",
      "Train Epoch: 1054 [23040/60000 (38%)] Loss: -1488.352783\n",
      "Train Epoch: 1054 [34304/60000 (57%)] Loss: -1263.877808\n",
      "Train Epoch: 1054 [45568/60000 (76%)] Loss: -1213.615479\n",
      "Train Epoch: 1054 [56832/60000 (95%)] Loss: -1478.438721\n",
      "    epoch          : 1054\n",
      "    loss           : -1333.716578251898\n",
      "Train Epoch: 1055 [512/60000 (1%)] Loss: -1503.566528\n",
      "Train Epoch: 1055 [11776/60000 (20%)] Loss: -1316.098267\n",
      "Train Epoch: 1055 [23040/60000 (38%)] Loss: -1469.857422\n",
      "Train Epoch: 1055 [34304/60000 (57%)] Loss: -1294.535767\n",
      "Train Epoch: 1055 [45568/60000 (76%)] Loss: -1319.647461\n",
      "Train Epoch: 1055 [56832/60000 (95%)] Loss: -1373.606201\n",
      "    epoch          : 1055\n",
      "    loss           : -1322.7936544472213\n",
      "Train Epoch: 1056 [512/60000 (1%)] Loss: -1357.279785\n",
      "Train Epoch: 1056 [11776/60000 (20%)] Loss: -1098.164917\n",
      "Train Epoch: 1056 [23040/60000 (38%)] Loss: -1374.591309\n",
      "Train Epoch: 1056 [34304/60000 (57%)] Loss: -1336.231079\n",
      "Train Epoch: 1056 [45568/60000 (76%)] Loss: -1483.603516\n",
      "Train Epoch: 1056 [56832/60000 (95%)] Loss: -1312.595093\n",
      "    epoch          : 1056\n",
      "    loss           : -1329.5749632409738\n",
      "Train Epoch: 1057 [512/60000 (1%)] Loss: -1146.091797\n",
      "Train Epoch: 1057 [11776/60000 (20%)] Loss: -1358.944092\n",
      "Train Epoch: 1057 [23040/60000 (38%)] Loss: -1427.084351\n",
      "Train Epoch: 1057 [34304/60000 (57%)] Loss: -1477.727051\n",
      "Train Epoch: 1057 [45568/60000 (76%)] Loss: -1446.479004\n",
      "Train Epoch: 1057 [56832/60000 (95%)] Loss: -1362.201904\n",
      "    epoch          : 1057\n",
      "    loss           : -1333.6078379140736\n",
      "Train Epoch: 1058 [512/60000 (1%)] Loss: -1462.029541\n",
      "Train Epoch: 1058 [11776/60000 (20%)] Loss: -1291.568115\n",
      "Train Epoch: 1058 [23040/60000 (38%)] Loss: -1207.927979\n",
      "Train Epoch: 1058 [34304/60000 (57%)] Loss: -1374.901367\n",
      "Train Epoch: 1058 [45568/60000 (76%)] Loss: -1028.982910\n",
      "Train Epoch: 1058 [56832/60000 (95%)] Loss: -1304.164551\n",
      "    epoch          : 1058\n",
      "    loss           : -1328.5985933293057\n",
      "Train Epoch: 1059 [512/60000 (1%)] Loss: -1471.830688\n",
      "Train Epoch: 1059 [11776/60000 (20%)] Loss: -1494.999023\n",
      "Train Epoch: 1059 [23040/60000 (38%)] Loss: -1497.620483\n",
      "Train Epoch: 1059 [34304/60000 (57%)] Loss: -1200.820679\n",
      "Train Epoch: 1059 [45568/60000 (76%)] Loss: -1299.402344\n",
      "Train Epoch: 1059 [56832/60000 (95%)] Loss: -1289.155273\n",
      "    epoch          : 1059\n",
      "    loss           : -1311.3062342412054\n",
      "Train Epoch: 1060 [512/60000 (1%)] Loss: -1327.730347\n",
      "Train Epoch: 1060 [11776/60000 (20%)] Loss: -1156.305786\n",
      "Train Epoch: 1060 [23040/60000 (38%)] Loss: -1300.496094\n",
      "Train Epoch: 1060 [34304/60000 (57%)] Loss: -1329.086792\n",
      "Train Epoch: 1060 [45568/60000 (76%)] Loss: -1203.905762\n",
      "Train Epoch: 1060 [56832/60000 (95%)] Loss: -1111.182129\n",
      "    epoch          : 1060\n",
      "    loss           : -1330.836580265713\n",
      "Train Epoch: 1061 [512/60000 (1%)] Loss: -1176.118896\n",
      "Train Epoch: 1061 [11776/60000 (20%)] Loss: -1288.168945\n",
      "Train Epoch: 1061 [23040/60000 (38%)] Loss: -1226.058350\n",
      "Train Epoch: 1061 [34304/60000 (57%)] Loss: -1119.701050\n",
      "Train Epoch: 1061 [45568/60000 (76%)] Loss: -1129.909302\n",
      "Train Epoch: 1061 [56832/60000 (95%)] Loss: -1336.263916\n",
      "    epoch          : 1061\n",
      "    loss           : -1312.2634279067909\n",
      "Train Epoch: 1062 [512/60000 (1%)] Loss: -1482.656982\n",
      "Train Epoch: 1062 [11776/60000 (20%)] Loss: -1329.141113\n",
      "Train Epoch: 1062 [23040/60000 (38%)] Loss: -1181.970703\n",
      "Train Epoch: 1062 [34304/60000 (57%)] Loss: -1337.724487\n",
      "Train Epoch: 1062 [45568/60000 (76%)] Loss: -1187.782959\n",
      "Train Epoch: 1062 [56832/60000 (95%)] Loss: -1513.895020\n",
      "    epoch          : 1062\n",
      "    loss           : -1318.1118145096775\n",
      "Train Epoch: 1063 [512/60000 (1%)] Loss: -1325.461670\n",
      "Train Epoch: 1063 [11776/60000 (20%)] Loss: -1339.767334\n",
      "Train Epoch: 1063 [23040/60000 (38%)] Loss: -1353.383057\n",
      "Train Epoch: 1063 [34304/60000 (57%)] Loss: -1356.966919\n",
      "Train Epoch: 1063 [45568/60000 (76%)] Loss: -1317.704102\n",
      "Train Epoch: 1063 [56832/60000 (95%)] Loss: -1287.301392\n",
      "    epoch          : 1063\n",
      "    loss           : -1315.5782843121028\n",
      "Train Epoch: 1064 [512/60000 (1%)] Loss: -1127.419800\n",
      "Train Epoch: 1064 [11776/60000 (20%)] Loss: -1168.755493\n",
      "Train Epoch: 1064 [23040/60000 (38%)] Loss: -1461.655029\n",
      "Train Epoch: 1064 [34304/60000 (57%)] Loss: -1307.874146\n",
      "Train Epoch: 1064 [45568/60000 (76%)] Loss: -1176.738159\n",
      "Train Epoch: 1064 [56832/60000 (95%)] Loss: -1186.471436\n",
      "    epoch          : 1064\n",
      "    loss           : -1310.5461722336247\n",
      "Train Epoch: 1065 [512/60000 (1%)] Loss: -1237.773682\n",
      "Train Epoch: 1065 [11776/60000 (20%)] Loss: -1367.749512\n",
      "Train Epoch: 1065 [23040/60000 (38%)] Loss: -1444.479126\n",
      "Train Epoch: 1065 [34304/60000 (57%)] Loss: -1413.875977\n",
      "Train Epoch: 1065 [45568/60000 (76%)] Loss: -1131.278931\n",
      "Train Epoch: 1065 [56832/60000 (95%)] Loss: -1448.524902\n",
      "    epoch          : 1065\n",
      "    loss           : -1328.5076526706503\n",
      "Train Epoch: 1066 [512/60000 (1%)] Loss: -1163.284912\n",
      "Train Epoch: 1066 [11776/60000 (20%)] Loss: -1177.751831\n",
      "Train Epoch: 1066 [23040/60000 (38%)] Loss: -1517.682373\n",
      "Train Epoch: 1066 [34304/60000 (57%)] Loss: -1350.795166\n",
      "Train Epoch: 1066 [45568/60000 (76%)] Loss: -1046.232666\n",
      "Train Epoch: 1066 [56832/60000 (95%)] Loss: -1178.360718\n",
      "    epoch          : 1066\n",
      "    loss           : -1319.8421879137977\n",
      "Train Epoch: 1067 [512/60000 (1%)] Loss: -1199.776367\n",
      "Train Epoch: 1067 [11776/60000 (20%)] Loss: -1169.467773\n",
      "Train Epoch: 1067 [23040/60000 (38%)] Loss: -1320.681641\n",
      "Train Epoch: 1067 [34304/60000 (57%)] Loss: -1195.293091\n",
      "Train Epoch: 1067 [45568/60000 (76%)] Loss: -1179.461914\n",
      "Train Epoch: 1067 [56832/60000 (95%)] Loss: -1346.203369\n",
      "    epoch          : 1067\n",
      "    loss           : -1313.5321374235853\n",
      "Train Epoch: 1068 [512/60000 (1%)] Loss: -1487.994751\n",
      "Train Epoch: 1068 [11776/60000 (20%)] Loss: -1342.085938\n",
      "Train Epoch: 1068 [23040/60000 (38%)] Loss: -1161.067871\n",
      "Train Epoch: 1068 [34304/60000 (57%)] Loss: -1493.072754\n",
      "Train Epoch: 1068 [45568/60000 (76%)] Loss: -1139.223877\n",
      "Train Epoch: 1068 [56832/60000 (95%)] Loss: -1064.097168\n",
      "    epoch          : 1068\n",
      "    loss           : -1331.7503162103858\n",
      "Train Epoch: 1069 [512/60000 (1%)] Loss: -1187.048584\n",
      "Train Epoch: 1069 [11776/60000 (20%)] Loss: -1344.879028\n",
      "Train Epoch: 1069 [23040/60000 (38%)] Loss: -1284.651611\n",
      "Train Epoch: 1069 [34304/60000 (57%)] Loss: -1507.427368\n",
      "Train Epoch: 1069 [45568/60000 (76%)] Loss: -1174.578613\n",
      "Train Epoch: 1069 [56832/60000 (95%)] Loss: -1497.458252\n",
      "    epoch          : 1069\n",
      "    loss           : -1309.8030655855514\n",
      "Train Epoch: 1070 [512/60000 (1%)] Loss: -1343.107422\n",
      "Train Epoch: 1070 [11776/60000 (20%)] Loss: -1098.774292\n",
      "Train Epoch: 1070 [23040/60000 (38%)] Loss: -1428.269775\n",
      "Train Epoch: 1070 [34304/60000 (57%)] Loss: -1468.277222\n",
      "Train Epoch: 1070 [45568/60000 (76%)] Loss: -1483.109619\n",
      "Train Epoch: 1070 [56832/60000 (95%)] Loss: -1485.889893\n",
      "    epoch          : 1070\n",
      "    loss           : -1334.390089821681\n",
      "Train Epoch: 1071 [512/60000 (1%)] Loss: -1422.106934\n",
      "Train Epoch: 1071 [11776/60000 (20%)] Loss: -1314.247314\n",
      "Train Epoch: 1071 [23040/60000 (38%)] Loss: -1457.714111\n",
      "Train Epoch: 1071 [34304/60000 (57%)] Loss: -1445.514893\n",
      "Train Epoch: 1071 [45568/60000 (76%)] Loss: -1370.822021\n",
      "Train Epoch: 1071 [56832/60000 (95%)] Loss: -1476.478516\n",
      "    epoch          : 1071\n",
      "    loss           : -1316.3500354141838\n",
      "Train Epoch: 1072 [512/60000 (1%)] Loss: -1196.441162\n",
      "Train Epoch: 1072 [11776/60000 (20%)] Loss: -1349.274170\n",
      "Train Epoch: 1072 [23040/60000 (38%)] Loss: -1327.760010\n",
      "Train Epoch: 1072 [34304/60000 (57%)] Loss: -1437.476318\n",
      "Train Epoch: 1072 [45568/60000 (76%)] Loss: -1002.286987\n",
      "Train Epoch: 1072 [56832/60000 (95%)] Loss: -1174.167236\n",
      "    epoch          : 1072\n",
      "    loss           : -1319.053019895392\n",
      "Train Epoch: 1073 [512/60000 (1%)] Loss: -1356.734741\n",
      "Train Epoch: 1073 [11776/60000 (20%)] Loss: -974.986267\n",
      "Train Epoch: 1073 [23040/60000 (38%)] Loss: -1497.125244\n",
      "Train Epoch: 1073 [34304/60000 (57%)] Loss: -1486.348022\n",
      "Train Epoch: 1073 [45568/60000 (76%)] Loss: -1280.865967\n",
      "Train Epoch: 1073 [56832/60000 (95%)] Loss: -1291.540161\n",
      "    epoch          : 1073\n",
      "    loss           : -1303.0113934015824\n",
      "Train Epoch: 1074 [512/60000 (1%)] Loss: -1505.143799\n",
      "Train Epoch: 1074 [11776/60000 (20%)] Loss: -1429.081055\n",
      "Train Epoch: 1074 [23040/60000 (38%)] Loss: -1055.147583\n",
      "Train Epoch: 1074 [34304/60000 (57%)] Loss: -1287.683105\n",
      "Train Epoch: 1074 [45568/60000 (76%)] Loss: -1480.059204\n",
      "Train Epoch: 1074 [56832/60000 (95%)] Loss: -1152.306519\n",
      "    epoch          : 1074\n",
      "    loss           : -1321.8885367010946\n",
      "Train Epoch: 1075 [512/60000 (1%)] Loss: -1200.214844\n",
      "Train Epoch: 1075 [11776/60000 (20%)] Loss: -1195.399658\n",
      "Train Epoch: 1075 [23040/60000 (38%)] Loss: -1474.927368\n",
      "Train Epoch: 1075 [34304/60000 (57%)] Loss: -1351.599854\n",
      "Train Epoch: 1075 [45568/60000 (76%)] Loss: -1332.737183\n",
      "Train Epoch: 1075 [56832/60000 (95%)] Loss: -1034.293213\n",
      "    epoch          : 1075\n",
      "    loss           : -1327.6216901358912\n",
      "Train Epoch: 1076 [512/60000 (1%)] Loss: -1484.770142\n",
      "Train Epoch: 1076 [11776/60000 (20%)] Loss: -1207.967285\n",
      "Train Epoch: 1076 [23040/60000 (38%)] Loss: -1317.941895\n",
      "Train Epoch: 1076 [34304/60000 (57%)] Loss: -1209.491699\n",
      "Train Epoch: 1076 [45568/60000 (76%)] Loss: -1275.712158\n",
      "Train Epoch: 1076 [56832/60000 (95%)] Loss: -1309.785278\n",
      "    epoch          : 1076\n",
      "    loss           : -1309.5220885195974\n",
      "Train Epoch: 1077 [512/60000 (1%)] Loss: -1532.540894\n",
      "Train Epoch: 1077 [11776/60000 (20%)] Loss: -1156.334717\n",
      "Train Epoch: 1077 [23040/60000 (38%)] Loss: -950.862183\n",
      "Train Epoch: 1077 [34304/60000 (57%)] Loss: -1382.844849\n",
      "Train Epoch: 1077 [45568/60000 (76%)] Loss: -1485.897705\n",
      "Train Epoch: 1077 [56832/60000 (95%)] Loss: -1194.527832\n",
      "    epoch          : 1077\n",
      "    loss           : -1324.968587929246\n",
      "Train Epoch: 1078 [512/60000 (1%)] Loss: -1471.811279\n",
      "Train Epoch: 1078 [11776/60000 (20%)] Loss: -1346.095215\n",
      "Train Epoch: 1078 [23040/60000 (38%)] Loss: -1322.749512\n",
      "Train Epoch: 1078 [34304/60000 (57%)] Loss: -1055.510498\n",
      "Train Epoch: 1078 [45568/60000 (76%)] Loss: -1481.774658\n",
      "Train Epoch: 1078 [56832/60000 (95%)] Loss: -1180.055420\n",
      "    epoch          : 1078\n",
      "    loss           : -1326.3621246855137\n",
      "Train Epoch: 1079 [512/60000 (1%)] Loss: -1158.912598\n",
      "Train Epoch: 1079 [11776/60000 (20%)] Loss: -1480.816895\n",
      "Train Epoch: 1079 [23040/60000 (38%)] Loss: -1473.551758\n",
      "Train Epoch: 1079 [34304/60000 (57%)] Loss: -1154.218018\n",
      "Train Epoch: 1079 [45568/60000 (76%)] Loss: -1491.351807\n",
      "Train Epoch: 1079 [56832/60000 (95%)] Loss: -1480.471924\n",
      "    epoch          : 1079\n",
      "    loss           : -1322.0910980741855\n",
      "Train Epoch: 1080 [512/60000 (1%)] Loss: -1493.176514\n",
      "Train Epoch: 1080 [11776/60000 (20%)] Loss: -1532.755005\n",
      "Train Epoch: 1080 [23040/60000 (38%)] Loss: -1359.504395\n",
      "Train Epoch: 1080 [34304/60000 (57%)] Loss: -1236.105347\n",
      "Train Epoch: 1080 [45568/60000 (76%)] Loss: -1280.544189\n",
      "Train Epoch: 1080 [56832/60000 (95%)] Loss: -1377.526123\n",
      "    epoch          : 1080\n",
      "    loss           : -1331.4510346321063\n",
      "Train Epoch: 1081 [512/60000 (1%)] Loss: -1352.465698\n",
      "Train Epoch: 1081 [11776/60000 (20%)] Loss: -1295.813965\n",
      "Train Epoch: 1081 [23040/60000 (38%)] Loss: -1307.743408\n",
      "Train Epoch: 1081 [34304/60000 (57%)] Loss: -1335.669678\n",
      "Train Epoch: 1081 [45568/60000 (76%)] Loss: -1320.179077\n",
      "Train Epoch: 1081 [56832/60000 (95%)] Loss: -1178.839600\n",
      "    epoch          : 1081\n",
      "    loss           : -1332.3401678915077\n",
      "Train Epoch: 1082 [512/60000 (1%)] Loss: -1298.520996\n",
      "Train Epoch: 1082 [11776/60000 (20%)] Loss: -839.772095\n",
      "Train Epoch: 1082 [23040/60000 (38%)] Loss: -1334.977539\n",
      "Train Epoch: 1082 [34304/60000 (57%)] Loss: -1203.359009\n",
      "Train Epoch: 1082 [45568/60000 (76%)] Loss: -1466.248657\n",
      "Train Epoch: 1082 [56832/60000 (95%)] Loss: -1318.379272\n",
      "    epoch          : 1082\n",
      "    loss           : -1293.285001593121\n",
      "Train Epoch: 1083 [512/60000 (1%)] Loss: -1107.211182\n",
      "Train Epoch: 1083 [11776/60000 (20%)] Loss: -1481.520264\n",
      "Train Epoch: 1083 [23040/60000 (38%)] Loss: -1313.284058\n",
      "Train Epoch: 1083 [34304/60000 (57%)] Loss: -1155.971558\n",
      "Train Epoch: 1083 [45568/60000 (76%)] Loss: -1344.865479\n",
      "Train Epoch: 1083 [56832/60000 (95%)] Loss: -850.049072\n",
      "    epoch          : 1083\n",
      "    loss           : -1307.721079336048\n",
      "Train Epoch: 1084 [512/60000 (1%)] Loss: -1242.560181\n",
      "Train Epoch: 1084 [11776/60000 (20%)] Loss: -1312.187866\n",
      "Train Epoch: 1084 [23040/60000 (38%)] Loss: -1323.565674\n",
      "Train Epoch: 1084 [34304/60000 (57%)] Loss: -1190.568848\n",
      "Train Epoch: 1084 [45568/60000 (76%)] Loss: -986.354187\n",
      "Train Epoch: 1084 [56832/60000 (95%)] Loss: -1282.306152\n",
      "    epoch          : 1084\n",
      "    loss           : -1334.5994286833509\n",
      "Train Epoch: 1085 [512/60000 (1%)] Loss: -1488.094849\n",
      "Train Epoch: 1085 [11776/60000 (20%)] Loss: -978.465088\n",
      "Train Epoch: 1085 [23040/60000 (38%)] Loss: -1453.397949\n",
      "Train Epoch: 1085 [34304/60000 (57%)] Loss: -1378.202759\n",
      "Train Epoch: 1085 [45568/60000 (76%)] Loss: -1321.638550\n",
      "Train Epoch: 1085 [56832/60000 (95%)] Loss: -1368.715088\n",
      "    epoch          : 1085\n",
      "    loss           : -1320.843311029639\n",
      "Train Epoch: 1086 [512/60000 (1%)] Loss: -1213.686035\n",
      "Train Epoch: 1086 [11776/60000 (20%)] Loss: -1246.252930\n",
      "Train Epoch: 1086 [23040/60000 (38%)] Loss: -1356.396851\n",
      "Train Epoch: 1086 [34304/60000 (57%)] Loss: -1386.147949\n",
      "Train Epoch: 1086 [45568/60000 (76%)] Loss: -1313.867432\n",
      "Train Epoch: 1086 [56832/60000 (95%)] Loss: -1338.679565\n",
      "    epoch          : 1086\n",
      "    loss           : -1334.5579909847281\n",
      "Train Epoch: 1087 [512/60000 (1%)] Loss: -1456.412598\n",
      "Train Epoch: 1087 [11776/60000 (20%)] Loss: -1427.230225\n",
      "Train Epoch: 1087 [23040/60000 (38%)] Loss: -1466.507812\n",
      "Train Epoch: 1087 [34304/60000 (57%)] Loss: -1241.398804\n",
      "Train Epoch: 1087 [45568/60000 (76%)] Loss: -1159.517578\n",
      "Train Epoch: 1087 [56832/60000 (95%)] Loss: -1483.864746\n",
      "    epoch          : 1087\n",
      "    loss           : -1313.0419832218838\n",
      "Train Epoch: 1088 [512/60000 (1%)] Loss: -1350.546387\n",
      "Train Epoch: 1088 [11776/60000 (20%)] Loss: -1367.306641\n",
      "Train Epoch: 1088 [23040/60000 (38%)] Loss: -1133.950928\n",
      "Train Epoch: 1088 [34304/60000 (57%)] Loss: -1502.141968\n",
      "Train Epoch: 1088 [45568/60000 (76%)] Loss: -1330.226196\n",
      "Train Epoch: 1088 [56832/60000 (95%)] Loss: -1221.708984\n",
      "    epoch          : 1088\n",
      "    loss           : -1335.5990843692068\n",
      "Train Epoch: 1089 [512/60000 (1%)] Loss: -1230.728516\n",
      "Train Epoch: 1089 [11776/60000 (20%)] Loss: -1452.028076\n",
      "Train Epoch: 1089 [23040/60000 (38%)] Loss: -1320.065796\n",
      "Train Epoch: 1089 [34304/60000 (57%)] Loss: -1486.550415\n",
      "Train Epoch: 1089 [45568/60000 (76%)] Loss: -1196.566772\n",
      "Train Epoch: 1089 [56832/60000 (95%)] Loss: -1507.230225\n",
      "    epoch          : 1089\n",
      "    loss           : -1337.631491623356\n",
      "Train Epoch: 1090 [512/60000 (1%)] Loss: -1358.655640\n",
      "Train Epoch: 1090 [11776/60000 (20%)] Loss: -1480.583496\n",
      "Train Epoch: 1090 [23040/60000 (38%)] Loss: -1182.115356\n",
      "Train Epoch: 1090 [34304/60000 (57%)] Loss: -1458.873901\n",
      "Train Epoch: 1090 [45568/60000 (76%)] Loss: -1506.901245\n",
      "Train Epoch: 1090 [56832/60000 (95%)] Loss: -1130.703369\n",
      "    epoch          : 1090\n",
      "    loss           : -1319.4422160865222\n",
      "Train Epoch: 1091 [512/60000 (1%)] Loss: -1310.191406\n",
      "Train Epoch: 1091 [11776/60000 (20%)] Loss: -1309.722778\n",
      "Train Epoch: 1091 [23040/60000 (38%)] Loss: -1381.721069\n",
      "Train Epoch: 1091 [34304/60000 (57%)] Loss: -1345.830322\n",
      "Train Epoch: 1091 [45568/60000 (76%)] Loss: -1157.915161\n",
      "Train Epoch: 1091 [56832/60000 (95%)] Loss: -1510.757080\n",
      "    epoch          : 1091\n",
      "    loss           : -1303.1516301214358\n",
      "Train Epoch: 1092 [512/60000 (1%)] Loss: -1232.676880\n",
      "Train Epoch: 1092 [11776/60000 (20%)] Loss: -1343.372803\n",
      "Train Epoch: 1092 [23040/60000 (38%)] Loss: -1201.069092\n",
      "Train Epoch: 1092 [34304/60000 (57%)] Loss: -1477.090576\n",
      "Train Epoch: 1092 [45568/60000 (76%)] Loss: -1172.800537\n",
      "Train Epoch: 1092 [56832/60000 (95%)] Loss: -1513.965820\n",
      "    epoch          : 1092\n",
      "    loss           : -1313.7491030935514\n",
      "Train Epoch: 1093 [512/60000 (1%)] Loss: -1449.145142\n",
      "Train Epoch: 1093 [11776/60000 (20%)] Loss: -1135.570679\n",
      "Train Epoch: 1093 [23040/60000 (38%)] Loss: -1521.898438\n",
      "Train Epoch: 1093 [34304/60000 (57%)] Loss: -1463.700073\n",
      "Train Epoch: 1093 [45568/60000 (76%)] Loss: -1023.503418\n",
      "Train Epoch: 1093 [56832/60000 (95%)] Loss: -1496.393921\n",
      "    epoch          : 1093\n",
      "    loss           : -1315.9320525260969\n",
      "Train Epoch: 1094 [512/60000 (1%)] Loss: -1289.633911\n",
      "Train Epoch: 1094 [11776/60000 (20%)] Loss: -1499.138428\n",
      "Train Epoch: 1094 [23040/60000 (38%)] Loss: -1352.542969\n",
      "Train Epoch: 1094 [34304/60000 (57%)] Loss: -1338.827759\n",
      "Train Epoch: 1094 [45568/60000 (76%)] Loss: -1373.589478\n",
      "Train Epoch: 1094 [56832/60000 (95%)] Loss: -1502.427002\n",
      "    epoch          : 1094\n",
      "    loss           : -1337.2058145124358\n",
      "Train Epoch: 1095 [512/60000 (1%)] Loss: -1458.606201\n",
      "Train Epoch: 1095 [11776/60000 (20%)] Loss: -1367.188843\n",
      "Train Epoch: 1095 [23040/60000 (38%)] Loss: -1491.874268\n",
      "Train Epoch: 1095 [34304/60000 (57%)] Loss: -1323.026123\n",
      "Train Epoch: 1095 [45568/60000 (76%)] Loss: -1195.531860\n",
      "Train Epoch: 1095 [56832/60000 (95%)] Loss: -1184.209717\n",
      "    epoch          : 1095\n",
      "    loss           : -1343.2875350693525\n",
      "Train Epoch: 1096 [512/60000 (1%)] Loss: -1108.136963\n",
      "Train Epoch: 1096 [11776/60000 (20%)] Loss: -1480.233521\n",
      "Train Epoch: 1096 [23040/60000 (38%)] Loss: -1497.318604\n",
      "Train Epoch: 1096 [34304/60000 (57%)] Loss: -1255.487061\n",
      "Train Epoch: 1096 [45568/60000 (76%)] Loss: -1462.137207\n",
      "Train Epoch: 1096 [56832/60000 (95%)] Loss: -1469.451416\n",
      "    epoch          : 1096\n",
      "    loss           : -1316.4499830687787\n",
      "Train Epoch: 1097 [512/60000 (1%)] Loss: -1317.699463\n",
      "Train Epoch: 1097 [11776/60000 (20%)] Loss: -1445.470947\n",
      "Train Epoch: 1097 [23040/60000 (38%)] Loss: -1202.467285\n",
      "Train Epoch: 1097 [34304/60000 (57%)] Loss: -1462.472290\n",
      "Train Epoch: 1097 [45568/60000 (76%)] Loss: -1308.769775\n",
      "Train Epoch: 1097 [56832/60000 (95%)] Loss: -1296.237061\n",
      "    epoch          : 1097\n",
      "    loss           : -1318.405156194827\n",
      "Train Epoch: 1098 [512/60000 (1%)] Loss: -1476.993286\n",
      "Train Epoch: 1098 [11776/60000 (20%)] Loss: -1472.168213\n",
      "Train Epoch: 1098 [23040/60000 (38%)] Loss: -1295.316895\n",
      "Train Epoch: 1098 [34304/60000 (57%)] Loss: -1307.750244\n",
      "Train Epoch: 1098 [45568/60000 (76%)] Loss: -1481.041626\n",
      "Train Epoch: 1098 [56832/60000 (95%)] Loss: -1100.882324\n",
      "    epoch          : 1098\n",
      "    loss           : -1304.0659374517236\n",
      "Train Epoch: 1099 [512/60000 (1%)] Loss: -1286.609741\n",
      "Train Epoch: 1099 [11776/60000 (20%)] Loss: -1370.522827\n",
      "Train Epoch: 1099 [23040/60000 (38%)] Loss: -1341.861694\n",
      "Train Epoch: 1099 [34304/60000 (57%)] Loss: -1357.126953\n",
      "Train Epoch: 1099 [45568/60000 (76%)] Loss: -1204.860596\n",
      "Train Epoch: 1099 [56832/60000 (95%)] Loss: -1471.339355\n",
      "    epoch          : 1099\n",
      "    loss           : -1318.2778687557932\n",
      "Train Epoch: 1100 [512/60000 (1%)] Loss: -1310.242676\n",
      "Train Epoch: 1100 [11776/60000 (20%)] Loss: -1347.658936\n",
      "Train Epoch: 1100 [23040/60000 (38%)] Loss: -1366.425049\n",
      "Train Epoch: 1100 [34304/60000 (57%)] Loss: -1216.368530\n",
      "Train Epoch: 1100 [45568/60000 (76%)] Loss: -1491.850342\n",
      "Train Epoch: 1100 [56832/60000 (95%)] Loss: -1199.431396\n",
      "    epoch          : 1100\n",
      "    loss           : -1302.6582748499293\n",
      "Saving checkpoint: saved/models/Mnist_DeepGenerativeOperad/0127_111843/checkpoint-epoch1100.pth ...\n",
      "Train Epoch: 1101 [512/60000 (1%)] Loss: -1193.678467\n",
      "Train Epoch: 1101 [11776/60000 (20%)] Loss: -1484.150879\n",
      "Train Epoch: 1101 [23040/60000 (38%)] Loss: -1330.106323\n",
      "Train Epoch: 1101 [34304/60000 (57%)] Loss: -1309.307373\n",
      "Train Epoch: 1101 [45568/60000 (76%)] Loss: -1475.800537\n",
      "Train Epoch: 1101 [56832/60000 (95%)] Loss: -1177.123535\n",
      "    epoch          : 1101\n",
      "    loss           : -1327.4455064676577\n",
      "Train Epoch: 1102 [512/60000 (1%)] Loss: -1432.360352\n",
      "Train Epoch: 1102 [11776/60000 (20%)] Loss: -1349.815552\n",
      "Train Epoch: 1102 [23040/60000 (38%)] Loss: -1440.787476\n",
      "Train Epoch: 1102 [34304/60000 (57%)] Loss: -1286.776123\n",
      "Train Epoch: 1102 [45568/60000 (76%)] Loss: -1162.970093\n",
      "Train Epoch: 1102 [56832/60000 (95%)] Loss: -1289.289917\n",
      "    epoch          : 1102\n",
      "    loss           : -1332.616419388076\n",
      "Train Epoch: 1103 [512/60000 (1%)] Loss: -1322.504150\n",
      "Train Epoch: 1103 [11776/60000 (20%)] Loss: -1417.624023\n",
      "Train Epoch: 1103 [23040/60000 (38%)] Loss: -1327.393311\n",
      "Train Epoch: 1103 [34304/60000 (57%)] Loss: -1328.056519\n",
      "Train Epoch: 1103 [45568/60000 (76%)] Loss: -1309.645264\n",
      "Train Epoch: 1103 [56832/60000 (95%)] Loss: -1356.737915\n",
      "    epoch          : 1103\n",
      "    loss           : -1293.933754613844\n",
      "Train Epoch: 1104 [512/60000 (1%)] Loss: -1371.561035\n",
      "Train Epoch: 1104 [11776/60000 (20%)] Loss: -1335.517700\n",
      "Train Epoch: 1104 [23040/60000 (38%)] Loss: -1359.113525\n",
      "Train Epoch: 1104 [34304/60000 (57%)] Loss: -1303.939697\n",
      "Train Epoch: 1104 [45568/60000 (76%)] Loss: -1155.637817\n",
      "Train Epoch: 1104 [56832/60000 (95%)] Loss: -1322.096313\n",
      "    epoch          : 1104\n",
      "    loss           : -1311.357333425748\n",
      "Train Epoch: 1105 [512/60000 (1%)] Loss: -1472.422729\n",
      "Train Epoch: 1105 [11776/60000 (20%)] Loss: -1481.625244\n",
      "Train Epoch: 1105 [23040/60000 (38%)] Loss: -1177.617676\n",
      "Train Epoch: 1105 [34304/60000 (57%)] Loss: -1167.917969\n",
      "Train Epoch: 1105 [45568/60000 (76%)] Loss: -1237.550415\n",
      "Train Epoch: 1105 [56832/60000 (95%)] Loss: -1440.615356\n",
      "    epoch          : 1105\n",
      "    loss           : -1298.8983050847457\n",
      "Train Epoch: 1106 [512/60000 (1%)] Loss: -1164.278809\n",
      "Train Epoch: 1106 [11776/60000 (20%)] Loss: -1198.333496\n",
      "Train Epoch: 1106 [23040/60000 (38%)] Loss: -1358.367432\n",
      "Train Epoch: 1106 [34304/60000 (57%)] Loss: -1315.970459\n",
      "Train Epoch: 1106 [45568/60000 (76%)] Loss: -1225.783447\n",
      "Train Epoch: 1106 [56832/60000 (95%)] Loss: -1333.168213\n",
      "    epoch          : 1106\n",
      "    loss           : -1324.7722390384997\n",
      "Train Epoch: 1107 [512/60000 (1%)] Loss: -1321.836548\n",
      "Train Epoch: 1107 [11776/60000 (20%)] Loss: -1500.053101\n",
      "Train Epoch: 1107 [23040/60000 (38%)] Loss: -1464.572754\n",
      "Train Epoch: 1107 [34304/60000 (57%)] Loss: -1091.797119\n",
      "Train Epoch: 1107 [45568/60000 (76%)] Loss: -1294.743530\n",
      "Train Epoch: 1107 [56832/60000 (95%)] Loss: -1281.714844\n",
      "    epoch          : 1107\n",
      "    loss           : -1300.2473341085142\n",
      "Train Epoch: 1108 [512/60000 (1%)] Loss: -1472.776001\n",
      "Train Epoch: 1108 [11776/60000 (20%)] Loss: -1340.028320\n",
      "Train Epoch: 1108 [23040/60000 (38%)] Loss: -1159.039917\n",
      "Train Epoch: 1108 [34304/60000 (57%)] Loss: -1313.193848\n",
      "Train Epoch: 1108 [45568/60000 (76%)] Loss: -1316.510620\n",
      "Train Epoch: 1108 [56832/60000 (95%)] Loss: -1195.264648\n",
      "    epoch          : 1108\n",
      "    loss           : -1339.869759769763\n",
      "Train Epoch: 1109 [512/60000 (1%)] Loss: -1499.959229\n",
      "Train Epoch: 1109 [11776/60000 (20%)] Loss: -1440.091797\n",
      "Train Epoch: 1109 [23040/60000 (38%)] Loss: -1319.686890\n",
      "Train Epoch: 1109 [34304/60000 (57%)] Loss: -1469.045654\n",
      "Train Epoch: 1109 [45568/60000 (76%)] Loss: -1470.535034\n",
      "Train Epoch: 1109 [56832/60000 (95%)] Loss: -1489.834106\n",
      "    epoch          : 1109\n",
      "    loss           : -1320.259559415828\n",
      "Train Epoch: 1110 [512/60000 (1%)] Loss: -1227.467896\n",
      "Train Epoch: 1110 [11776/60000 (20%)] Loss: -1323.985840\n",
      "Train Epoch: 1110 [23040/60000 (38%)] Loss: -1134.188599\n",
      "Train Epoch: 1110 [34304/60000 (57%)] Loss: -1294.259399\n",
      "Train Epoch: 1110 [45568/60000 (76%)] Loss: -1187.121338\n",
      "Train Epoch: 1110 [56832/60000 (95%)] Loss: -1347.395386\n",
      "    epoch          : 1110\n",
      "    loss           : -1321.5469081038136\n",
      "Train Epoch: 1111 [512/60000 (1%)] Loss: -1282.962891\n",
      "Train Epoch: 1111 [11776/60000 (20%)] Loss: -1039.629883\n",
      "Train Epoch: 1111 [23040/60000 (38%)] Loss: -1333.757324\n",
      "Train Epoch: 1111 [34304/60000 (57%)] Loss: -1460.957031\n",
      "Train Epoch: 1111 [45568/60000 (76%)] Loss: -1514.323242\n",
      "Train Epoch: 1111 [56832/60000 (95%)] Loss: -1435.428711\n",
      "    epoch          : 1111\n",
      "    loss           : -1312.5567485572253\n",
      "Train Epoch: 1112 [512/60000 (1%)] Loss: -1326.553711\n",
      "Train Epoch: 1112 [11776/60000 (20%)] Loss: -1351.697388\n",
      "Train Epoch: 1112 [23040/60000 (38%)] Loss: -1184.874512\n",
      "Train Epoch: 1112 [34304/60000 (57%)] Loss: -1370.816162\n",
      "Train Epoch: 1112 [45568/60000 (76%)] Loss: -1326.896362\n",
      "Train Epoch: 1112 [56832/60000 (95%)] Loss: -1481.755615\n",
      "    epoch          : 1112\n",
      "    loss           : -1319.739835749912\n",
      "Train Epoch: 1113 [512/60000 (1%)] Loss: -1032.700928\n",
      "Train Epoch: 1113 [11776/60000 (20%)] Loss: -1286.090210\n",
      "Train Epoch: 1113 [23040/60000 (38%)] Loss: -1365.005615\n",
      "Train Epoch: 1113 [34304/60000 (57%)] Loss: -1166.422607\n",
      "Train Epoch: 1113 [45568/60000 (76%)] Loss: -1465.626343\n",
      "Train Epoch: 1113 [56832/60000 (95%)] Loss: -1463.863770\n",
      "    epoch          : 1113\n",
      "    loss           : -1317.774198715296\n",
      "Train Epoch: 1114 [512/60000 (1%)] Loss: -1501.875977\n",
      "Train Epoch: 1114 [11776/60000 (20%)] Loss: -1295.525269\n",
      "Train Epoch: 1114 [23040/60000 (38%)] Loss: -1334.892212\n",
      "Train Epoch: 1114 [34304/60000 (57%)] Loss: -1339.551758\n",
      "Train Epoch: 1114 [45568/60000 (76%)] Loss: -894.847168\n",
      "Train Epoch: 1114 [56832/60000 (95%)] Loss: -1306.963989\n",
      "    epoch          : 1114\n",
      "    loss           : -1325.539061465506\n",
      "Train Epoch: 1115 [512/60000 (1%)] Loss: -1448.571289\n",
      "Train Epoch: 1115 [11776/60000 (20%)] Loss: -1341.507202\n",
      "Train Epoch: 1115 [23040/60000 (38%)] Loss: -1342.054077\n",
      "Train Epoch: 1115 [34304/60000 (57%)] Loss: -1120.435303\n",
      "Train Epoch: 1115 [45568/60000 (76%)] Loss: -1425.755981\n",
      "Train Epoch: 1115 [56832/60000 (95%)] Loss: -1509.067383\n",
      "    epoch          : 1115\n",
      "    loss           : -1317.7071521134026\n",
      "Train Epoch: 1116 [512/60000 (1%)] Loss: -1496.954834\n",
      "Train Epoch: 1116 [11776/60000 (20%)] Loss: -1376.832275\n",
      "Train Epoch: 1116 [23040/60000 (38%)] Loss: -1362.602051\n",
      "Train Epoch: 1116 [34304/60000 (57%)] Loss: -1473.295654\n",
      "Train Epoch: 1116 [45568/60000 (76%)] Loss: -1328.374512\n",
      "Train Epoch: 1116 [56832/60000 (95%)] Loss: -1514.467041\n",
      "    epoch          : 1116\n",
      "    loss           : -1329.1208128848318\n",
      "Train Epoch: 1117 [512/60000 (1%)] Loss: -1191.451172\n",
      "Train Epoch: 1117 [11776/60000 (20%)] Loss: -1157.012207\n",
      "Train Epoch: 1117 [23040/60000 (38%)] Loss: -1321.313599\n",
      "Train Epoch: 1117 [34304/60000 (57%)] Loss: -1238.899780\n",
      "Train Epoch: 1117 [45568/60000 (76%)] Loss: -1177.711182\n",
      "Train Epoch: 1117 [56832/60000 (95%)] Loss: -1279.027100\n",
      "    epoch          : 1117\n",
      "    loss           : -1311.6029257909051\n",
      "Train Epoch: 1118 [512/60000 (1%)] Loss: -1360.939697\n",
      "Train Epoch: 1118 [11776/60000 (20%)] Loss: -1480.224854\n",
      "Train Epoch: 1118 [23040/60000 (38%)] Loss: -1361.393799\n",
      "Train Epoch: 1118 [34304/60000 (57%)] Loss: -1329.585449\n",
      "Train Epoch: 1118 [45568/60000 (76%)] Loss: -1501.614624\n",
      "Train Epoch: 1118 [56832/60000 (95%)] Loss: -1036.731201\n",
      "    epoch          : 1118\n",
      "    loss           : -1320.8645152291335\n",
      "Train Epoch: 1119 [512/60000 (1%)] Loss: -1503.879639\n",
      "Train Epoch: 1119 [11776/60000 (20%)] Loss: -1076.187500\n",
      "Train Epoch: 1119 [23040/60000 (38%)] Loss: -1347.531494\n",
      "Train Epoch: 1119 [34304/60000 (57%)] Loss: -1063.283447\n",
      "Train Epoch: 1119 [45568/60000 (76%)] Loss: -1364.461426\n",
      "Train Epoch: 1119 [56832/60000 (95%)] Loss: -1313.953613\n",
      "    epoch          : 1119\n",
      "    loss           : -1309.1746102025954\n",
      "Train Epoch: 1120 [512/60000 (1%)] Loss: -1209.188843\n",
      "Train Epoch: 1120 [11776/60000 (20%)] Loss: -1466.575928\n",
      "Train Epoch: 1120 [23040/60000 (38%)] Loss: -1379.055176\n",
      "Train Epoch: 1120 [34304/60000 (57%)] Loss: -1366.075806\n",
      "Train Epoch: 1120 [45568/60000 (76%)] Loss: -1168.822998\n",
      "Train Epoch: 1120 [56832/60000 (95%)] Loss: -1316.939087\n",
      "    epoch          : 1120\n",
      "    loss           : -1325.0164103534937\n",
      "Train Epoch: 1121 [512/60000 (1%)] Loss: -954.645691\n",
      "Train Epoch: 1121 [11776/60000 (20%)] Loss: -1290.780029\n",
      "Train Epoch: 1121 [23040/60000 (38%)] Loss: -1472.835449\n",
      "Train Epoch: 1121 [34304/60000 (57%)] Loss: -1304.014160\n",
      "Train Epoch: 1121 [45568/60000 (76%)] Loss: -1323.904053\n",
      "Train Epoch: 1121 [56832/60000 (95%)] Loss: -1476.326172\n",
      "    epoch          : 1121\n",
      "    loss           : -1345.9770968162406\n",
      "Train Epoch: 1122 [512/60000 (1%)] Loss: -1066.294922\n",
      "Train Epoch: 1122 [11776/60000 (20%)] Loss: -1299.457520\n",
      "Train Epoch: 1122 [23040/60000 (38%)] Loss: -1353.403809\n",
      "Train Epoch: 1122 [34304/60000 (57%)] Loss: -1333.095337\n",
      "Train Epoch: 1122 [45568/60000 (76%)] Loss: -1334.445435\n",
      "Train Epoch: 1122 [56832/60000 (95%)] Loss: -1336.103027\n",
      "    epoch          : 1122\n",
      "    loss           : -1322.8406251379324\n",
      "Train Epoch: 1123 [512/60000 (1%)] Loss: -1487.976685\n",
      "Train Epoch: 1123 [11776/60000 (20%)] Loss: -1364.312866\n",
      "Train Epoch: 1123 [23040/60000 (38%)] Loss: -1252.427734\n",
      "Train Epoch: 1123 [34304/60000 (57%)] Loss: -1488.940674\n",
      "Train Epoch: 1123 [45568/60000 (76%)] Loss: -1366.386230\n",
      "Train Epoch: 1123 [56832/60000 (95%)] Loss: -1201.779785\n",
      "    epoch          : 1123\n",
      "    loss           : -1299.020715745829\n",
      "Train Epoch: 1124 [512/60000 (1%)] Loss: -1306.286499\n",
      "Train Epoch: 1124 [11776/60000 (20%)] Loss: -1495.981323\n",
      "Train Epoch: 1124 [23040/60000 (38%)] Loss: -1351.559937\n",
      "Train Epoch: 1124 [34304/60000 (57%)] Loss: -1386.928711\n",
      "Train Epoch: 1124 [45568/60000 (76%)] Loss: -1346.423340\n",
      "Train Epoch: 1124 [56832/60000 (95%)] Loss: -1148.341675\n",
      "    epoch          : 1124\n",
      "    loss           : -1326.412310411701\n",
      "Train Epoch: 1125 [512/60000 (1%)] Loss: -1151.223633\n",
      "Train Epoch: 1125 [11776/60000 (20%)] Loss: -1205.094116\n",
      "Train Epoch: 1125 [23040/60000 (38%)] Loss: -1353.618408\n",
      "Train Epoch: 1125 [34304/60000 (57%)] Loss: -1356.420898\n",
      "Train Epoch: 1125 [45568/60000 (76%)] Loss: -1474.751465\n",
      "Train Epoch: 1125 [56832/60000 (95%)] Loss: -1088.257568\n",
      "    epoch          : 1125\n",
      "    loss           : -1331.2101602500443\n",
      "Train Epoch: 1126 [512/60000 (1%)] Loss: -975.319946\n",
      "Train Epoch: 1126 [11776/60000 (20%)] Loss: -1519.668701\n",
      "Train Epoch: 1126 [23040/60000 (38%)] Loss: -1281.113037\n",
      "Train Epoch: 1126 [34304/60000 (57%)] Loss: -1478.178467\n",
      "Train Epoch: 1126 [45568/60000 (76%)] Loss: -1326.658081\n",
      "Train Epoch: 1126 [56832/60000 (95%)] Loss: -1510.474731\n",
      "    epoch          : 1126\n",
      "    loss           : -1310.1666068384202\n",
      "Train Epoch: 1127 [512/60000 (1%)] Loss: -1475.329346\n",
      "Train Epoch: 1127 [11776/60000 (20%)] Loss: -1505.493408\n",
      "Train Epoch: 1127 [23040/60000 (38%)] Loss: -1329.068848\n",
      "Train Epoch: 1127 [34304/60000 (57%)] Loss: -1311.259521\n",
      "Train Epoch: 1127 [45568/60000 (76%)] Loss: -1512.285156\n",
      "Train Epoch: 1127 [56832/60000 (95%)] Loss: -1489.501709\n",
      "    epoch          : 1127\n",
      "    loss           : -1318.3138486355713\n",
      "Train Epoch: 1128 [512/60000 (1%)] Loss: -1340.502930\n",
      "Train Epoch: 1128 [11776/60000 (20%)] Loss: -1186.987061\n",
      "Train Epoch: 1128 [23040/60000 (38%)] Loss: -1359.065918\n",
      "Train Epoch: 1128 [34304/60000 (57%)] Loss: -1489.132568\n",
      "Train Epoch: 1128 [45568/60000 (76%)] Loss: -1464.489258\n",
      "Train Epoch: 1128 [56832/60000 (95%)] Loss: -1153.690674\n",
      "    epoch          : 1128\n",
      "    loss           : -1332.0835093697585\n",
      "Train Epoch: 1129 [512/60000 (1%)] Loss: -1315.830811\n",
      "Train Epoch: 1129 [11776/60000 (20%)] Loss: -1491.792114\n",
      "Train Epoch: 1129 [23040/60000 (38%)] Loss: -1499.900024\n",
      "Train Epoch: 1129 [34304/60000 (57%)] Loss: -1480.854248\n",
      "Train Epoch: 1129 [45568/60000 (76%)] Loss: -1467.873535\n",
      "Train Epoch: 1129 [56832/60000 (95%)] Loss: -1359.972290\n",
      "    epoch          : 1129\n",
      "    loss           : -1344.2537660760395\n",
      "Train Epoch: 1130 [512/60000 (1%)] Loss: -1207.260742\n",
      "Train Epoch: 1130 [11776/60000 (20%)] Loss: -1503.093506\n",
      "Train Epoch: 1130 [23040/60000 (38%)] Loss: -1098.169556\n",
      "Train Epoch: 1130 [34304/60000 (57%)] Loss: -1502.689941\n",
      "Train Epoch: 1130 [45568/60000 (76%)] Loss: -1502.853394\n",
      "Train Epoch: 1130 [56832/60000 (95%)] Loss: -1176.645508\n",
      "    epoch          : 1130\n",
      "    loss           : -1326.0757768706414\n",
      "Train Epoch: 1131 [512/60000 (1%)] Loss: -1480.860962\n",
      "Train Epoch: 1131 [11776/60000 (20%)] Loss: -992.184937\n",
      "Train Epoch: 1131 [23040/60000 (38%)] Loss: -1362.305420\n",
      "Train Epoch: 1131 [34304/60000 (57%)] Loss: -1497.016113\n",
      "Train Epoch: 1131 [45568/60000 (76%)] Loss: -1460.049316\n",
      "Train Epoch: 1131 [56832/60000 (95%)] Loss: -1344.353882\n",
      "    epoch          : 1131\n",
      "    loss           : -1317.283130710408\n",
      "Train Epoch: 1132 [512/60000 (1%)] Loss: -1356.080688\n",
      "Train Epoch: 1132 [11776/60000 (20%)] Loss: -1133.262817\n",
      "Train Epoch: 1132 [23040/60000 (38%)] Loss: -1219.412231\n",
      "Train Epoch: 1132 [34304/60000 (57%)] Loss: -1479.275024\n",
      "Train Epoch: 1132 [45568/60000 (76%)] Loss: -1360.008545\n",
      "Train Epoch: 1132 [56832/60000 (95%)] Loss: -1390.700439\n",
      "    epoch          : 1132\n",
      "    loss           : -1317.8711161640406\n",
      "Train Epoch: 1133 [512/60000 (1%)] Loss: -1205.802002\n",
      "Train Epoch: 1133 [11776/60000 (20%)] Loss: -1457.238403\n",
      "Train Epoch: 1133 [23040/60000 (38%)] Loss: -1134.395020\n",
      "Train Epoch: 1133 [34304/60000 (57%)] Loss: -1307.758057\n",
      "Train Epoch: 1133 [45568/60000 (76%)] Loss: -1355.562744\n",
      "Train Epoch: 1133 [56832/60000 (95%)] Loss: -1318.382690\n",
      "    epoch          : 1133\n",
      "    loss           : -1329.126373635847\n",
      "Train Epoch: 1134 [512/60000 (1%)] Loss: -1350.668823\n",
      "Train Epoch: 1134 [11776/60000 (20%)] Loss: -1313.633057\n",
      "Train Epoch: 1134 [23040/60000 (38%)] Loss: -1357.780762\n",
      "Train Epoch: 1134 [34304/60000 (57%)] Loss: -1063.558350\n",
      "Train Epoch: 1134 [45568/60000 (76%)] Loss: -1472.554688\n",
      "Train Epoch: 1134 [56832/60000 (95%)] Loss: -1335.652710\n",
      "    epoch          : 1134\n",
      "    loss           : -1328.9086389918784\n",
      "Train Epoch: 1135 [512/60000 (1%)] Loss: -1303.434082\n",
      "Train Epoch: 1135 [11776/60000 (20%)] Loss: -1148.682861\n",
      "Train Epoch: 1135 [23040/60000 (38%)] Loss: -1324.295166\n",
      "Train Epoch: 1135 [34304/60000 (57%)] Loss: -1201.994995\n",
      "Train Epoch: 1135 [45568/60000 (76%)] Loss: -1183.568359\n",
      "Train Epoch: 1135 [56832/60000 (95%)] Loss: -1451.534424\n",
      "    epoch          : 1135\n",
      "    loss           : -1326.9277457544358\n",
      "Train Epoch: 1136 [512/60000 (1%)] Loss: -1286.021606\n",
      "Train Epoch: 1136 [11776/60000 (20%)] Loss: -1182.228882\n",
      "Train Epoch: 1136 [23040/60000 (38%)] Loss: -1434.363525\n",
      "Train Epoch: 1136 [34304/60000 (57%)] Loss: -1296.651978\n",
      "Train Epoch: 1136 [45568/60000 (76%)] Loss: -1032.774658\n",
      "Train Epoch: 1136 [56832/60000 (95%)] Loss: -1068.254150\n",
      "    epoch          : 1136\n",
      "    loss           : -1315.3444612147443\n",
      "Train Epoch: 1137 [512/60000 (1%)] Loss: -1327.877319\n",
      "Train Epoch: 1137 [11776/60000 (20%)] Loss: -1472.726074\n",
      "Train Epoch: 1137 [23040/60000 (38%)] Loss: -1460.781006\n",
      "Train Epoch: 1137 [34304/60000 (57%)] Loss: -1361.177979\n",
      "Train Epoch: 1137 [45568/60000 (76%)] Loss: -1321.037964\n",
      "Train Epoch: 1137 [56832/60000 (95%)] Loss: -1192.439697\n",
      "    epoch          : 1137\n",
      "    loss           : -1321.7142913301113\n",
      "Train Epoch: 1138 [512/60000 (1%)] Loss: -1245.506592\n",
      "Train Epoch: 1138 [11776/60000 (20%)] Loss: -1305.108154\n",
      "Train Epoch: 1138 [23040/60000 (38%)] Loss: -1211.557983\n",
      "Train Epoch: 1138 [34304/60000 (57%)] Loss: -1310.608887\n",
      "Train Epoch: 1138 [45568/60000 (76%)] Loss: -1302.387451\n",
      "Train Epoch: 1138 [56832/60000 (95%)] Loss: -1443.910522\n",
      "    epoch          : 1138\n",
      "    loss           : -1323.7646775757526\n",
      "Train Epoch: 1139 [512/60000 (1%)] Loss: -1301.595947\n",
      "Train Epoch: 1139 [11776/60000 (20%)] Loss: -1223.980713\n",
      "Train Epoch: 1139 [23040/60000 (38%)] Loss: -1365.899658\n",
      "Train Epoch: 1139 [34304/60000 (57%)] Loss: -1340.125854\n",
      "Train Epoch: 1139 [45568/60000 (76%)] Loss: -1512.505981\n",
      "Train Epoch: 1139 [56832/60000 (95%)] Loss: -1480.498779\n",
      "    epoch          : 1139\n",
      "    loss           : -1344.0994221315545\n",
      "Train Epoch: 1140 [512/60000 (1%)] Loss: -1326.689087\n",
      "Train Epoch: 1140 [11776/60000 (20%)] Loss: -1384.511719\n",
      "Train Epoch: 1140 [23040/60000 (38%)] Loss: -1536.409912\n",
      "Train Epoch: 1140 [34304/60000 (57%)] Loss: -1428.039429\n",
      "Train Epoch: 1140 [45568/60000 (76%)] Loss: -1349.710449\n",
      "Train Epoch: 1140 [56832/60000 (95%)] Loss: -1478.248901\n",
      "    epoch          : 1140\n",
      "    loss           : -1320.8356147378179\n",
      "Train Epoch: 1141 [512/60000 (1%)] Loss: -1049.647949\n",
      "Train Epoch: 1141 [11776/60000 (20%)] Loss: -1499.623413\n",
      "Train Epoch: 1141 [23040/60000 (38%)] Loss: -1463.569092\n",
      "Train Epoch: 1141 [34304/60000 (57%)] Loss: -1307.482666\n",
      "Train Epoch: 1141 [45568/60000 (76%)] Loss: -1403.692383\n",
      "Train Epoch: 1141 [56832/60000 (95%)] Loss: -1218.968384\n",
      "    epoch          : 1141\n",
      "    loss           : -1334.3571049749514\n",
      "Train Epoch: 1142 [512/60000 (1%)] Loss: -1344.903320\n",
      "Train Epoch: 1142 [11776/60000 (20%)] Loss: -1330.615234\n",
      "Train Epoch: 1142 [23040/60000 (38%)] Loss: -1244.451416\n",
      "Train Epoch: 1142 [34304/60000 (57%)] Loss: -1152.241699\n",
      "Train Epoch: 1142 [45568/60000 (76%)] Loss: -1194.008911\n",
      "Train Epoch: 1142 [56832/60000 (95%)] Loss: -1227.488403\n",
      "    epoch          : 1142\n",
      "    loss           : -1321.2496330993997\n",
      "Train Epoch: 1143 [512/60000 (1%)] Loss: -1323.344727\n",
      "Train Epoch: 1143 [11776/60000 (20%)] Loss: -1340.034058\n",
      "Train Epoch: 1143 [23040/60000 (38%)] Loss: -1456.383057\n",
      "Train Epoch: 1143 [34304/60000 (57%)] Loss: -1291.751709\n",
      "Train Epoch: 1143 [45568/60000 (76%)] Loss: -1168.062134\n",
      "Train Epoch: 1143 [56832/60000 (95%)] Loss: -1167.485474\n",
      "    epoch          : 1143\n",
      "    loss           : -1317.248376016563\n",
      "Train Epoch: 1144 [512/60000 (1%)] Loss: -1335.014893\n",
      "Train Epoch: 1144 [11776/60000 (20%)] Loss: -1065.582886\n",
      "Train Epoch: 1144 [23040/60000 (38%)] Loss: -1457.276001\n",
      "Train Epoch: 1144 [34304/60000 (57%)] Loss: -1472.334595\n",
      "Train Epoch: 1144 [45568/60000 (76%)] Loss: -1357.607666\n",
      "Train Epoch: 1144 [56832/60000 (95%)] Loss: -1385.681885\n",
      "    epoch          : 1144\n",
      "    loss           : -1328.9548548466742\n",
      "Train Epoch: 1145 [512/60000 (1%)] Loss: -1370.696289\n",
      "Train Epoch: 1145 [11776/60000 (20%)] Loss: -1502.319702\n",
      "Train Epoch: 1145 [23040/60000 (38%)] Loss: -1285.459961\n",
      "Train Epoch: 1145 [34304/60000 (57%)] Loss: -1317.652832\n",
      "Train Epoch: 1145 [45568/60000 (76%)] Loss: -1357.007324\n",
      "Train Epoch: 1145 [56832/60000 (95%)] Loss: -1310.391602\n",
      "    epoch          : 1145\n",
      "    loss           : -1326.7389686713784\n",
      "Train Epoch: 1146 [512/60000 (1%)] Loss: -1356.361572\n",
      "Train Epoch: 1146 [11776/60000 (20%)] Loss: -1316.244385\n",
      "Train Epoch: 1146 [23040/60000 (38%)] Loss: -1359.769043\n",
      "Train Epoch: 1146 [34304/60000 (57%)] Loss: -1317.128906\n",
      "Train Epoch: 1146 [45568/60000 (76%)] Loss: -1227.090576\n",
      "Train Epoch: 1146 [56832/60000 (95%)] Loss: -1240.832764\n",
      "    epoch          : 1146\n",
      "    loss           : -1308.3103835973363\n",
      "Train Epoch: 1147 [512/60000 (1%)] Loss: -1379.916504\n",
      "Train Epoch: 1147 [11776/60000 (20%)] Loss: -1338.422363\n",
      "Train Epoch: 1147 [23040/60000 (38%)] Loss: -1196.705811\n",
      "Train Epoch: 1147 [34304/60000 (57%)] Loss: -1335.903076\n",
      "Train Epoch: 1147 [45568/60000 (76%)] Loss: -1491.660156\n",
      "Train Epoch: 1147 [56832/60000 (95%)] Loss: -1478.384155\n",
      "    epoch          : 1147\n",
      "    loss           : -1332.8630769374006\n",
      "Train Epoch: 1148 [512/60000 (1%)] Loss: -1315.811035\n",
      "Train Epoch: 1148 [11776/60000 (20%)] Loss: -1388.290527\n",
      "Train Epoch: 1148 [23040/60000 (38%)] Loss: -1480.408936\n",
      "Train Epoch: 1148 [34304/60000 (57%)] Loss: -1182.143311\n",
      "Train Epoch: 1148 [45568/60000 (76%)] Loss: -1304.866455\n",
      "Train Epoch: 1148 [56832/60000 (95%)] Loss: -1463.192749\n",
      "    epoch          : 1148\n",
      "    loss           : -1349.3704025354762\n",
      "Train Epoch: 1149 [512/60000 (1%)] Loss: -1130.858643\n",
      "Train Epoch: 1149 [11776/60000 (20%)] Loss: -1346.749268\n",
      "Train Epoch: 1149 [23040/60000 (38%)] Loss: -1470.086792\n",
      "Train Epoch: 1149 [34304/60000 (57%)] Loss: -986.323120\n",
      "Train Epoch: 1149 [45568/60000 (76%)] Loss: -1199.024902\n",
      "Train Epoch: 1149 [56832/60000 (95%)] Loss: -1301.886841\n",
      "    epoch          : 1149\n",
      "    loss           : -1320.9962540965969\n",
      "Train Epoch: 1150 [512/60000 (1%)] Loss: -1301.594482\n",
      "Train Epoch: 1150 [11776/60000 (20%)] Loss: -1458.163330\n",
      "Train Epoch: 1150 [23040/60000 (38%)] Loss: -1215.021240\n",
      "Train Epoch: 1150 [34304/60000 (57%)] Loss: -1497.544189\n",
      "Train Epoch: 1150 [45568/60000 (76%)] Loss: -1358.915283\n",
      "Train Epoch: 1150 [56832/60000 (95%)] Loss: -1137.803833\n",
      "    epoch          : 1150\n",
      "    loss           : -1317.9081650211313\n",
      "Train Epoch: 1151 [512/60000 (1%)] Loss: -1208.001465\n",
      "Train Epoch: 1151 [11776/60000 (20%)] Loss: -1178.962280\n",
      "Train Epoch: 1151 [23040/60000 (38%)] Loss: -1375.848145\n",
      "Train Epoch: 1151 [34304/60000 (57%)] Loss: -1472.003174\n",
      "Train Epoch: 1151 [45568/60000 (76%)] Loss: -1202.360474\n",
      "Train Epoch: 1151 [56832/60000 (95%)] Loss: -1479.286987\n",
      "    epoch          : 1151\n",
      "    loss           : -1325.9224143162958\n",
      "Train Epoch: 1152 [512/60000 (1%)] Loss: -1164.241821\n",
      "Train Epoch: 1152 [11776/60000 (20%)] Loss: -1192.008667\n",
      "Train Epoch: 1152 [23040/60000 (38%)] Loss: -1455.253662\n",
      "Train Epoch: 1152 [34304/60000 (57%)] Loss: -1284.572144\n",
      "Train Epoch: 1152 [45568/60000 (76%)] Loss: -1158.727783\n",
      "Train Epoch: 1152 [56832/60000 (95%)] Loss: -1291.619629\n",
      "    epoch          : 1152\n",
      "    loss           : -1317.5156453450522\n",
      "Train Epoch: 1153 [512/60000 (1%)] Loss: -1192.849243\n",
      "Train Epoch: 1153 [11776/60000 (20%)] Loss: -1186.949097\n",
      "Train Epoch: 1153 [23040/60000 (38%)] Loss: -1316.406738\n",
      "Train Epoch: 1153 [34304/60000 (57%)] Loss: -1302.297607\n",
      "Train Epoch: 1153 [45568/60000 (76%)] Loss: -1351.949951\n",
      "Train Epoch: 1153 [56832/60000 (95%)] Loss: -1178.807007\n",
      "    epoch          : 1153\n",
      "    loss           : -1307.6985627082781\n",
      "Train Epoch: 1154 [512/60000 (1%)] Loss: -1254.442627\n",
      "Train Epoch: 1154 [11776/60000 (20%)] Loss: -1335.910889\n",
      "Train Epoch: 1154 [23040/60000 (38%)] Loss: -1293.668457\n",
      "Train Epoch: 1154 [34304/60000 (57%)] Loss: -1207.865479\n",
      "Train Epoch: 1154 [45568/60000 (76%)] Loss: -1340.786255\n",
      "Train Epoch: 1154 [56832/60000 (95%)] Loss: -1286.375610\n",
      "    epoch          : 1154\n",
      "    loss           : -1321.97422643974\n",
      "Train Epoch: 1155 [512/60000 (1%)] Loss: -1309.437134\n",
      "Train Epoch: 1155 [11776/60000 (20%)] Loss: -1176.505249\n",
      "Train Epoch: 1155 [23040/60000 (38%)] Loss: -1254.782349\n",
      "Train Epoch: 1155 [34304/60000 (57%)] Loss: -1305.736084\n",
      "Train Epoch: 1155 [45568/60000 (76%)] Loss: -1468.280029\n",
      "Train Epoch: 1155 [56832/60000 (95%)] Loss: -1515.489746\n",
      "    epoch          : 1155\n",
      "    loss           : -1326.156446553893\n",
      "Train Epoch: 1156 [512/60000 (1%)] Loss: -1340.929077\n",
      "Train Epoch: 1156 [11776/60000 (20%)] Loss: -1154.655640\n",
      "Train Epoch: 1156 [23040/60000 (38%)] Loss: -1165.188599\n",
      "Train Epoch: 1156 [34304/60000 (57%)] Loss: -1183.691650\n",
      "Train Epoch: 1156 [45568/60000 (76%)] Loss: -1496.806396\n",
      "Train Epoch: 1156 [56832/60000 (95%)] Loss: -1501.298218\n",
      "    epoch          : 1156\n",
      "    loss           : -1304.6949580133298\n",
      "Train Epoch: 1157 [512/60000 (1%)] Loss: -1488.474609\n",
      "Train Epoch: 1157 [11776/60000 (20%)] Loss: -1229.394653\n",
      "Train Epoch: 1157 [23040/60000 (38%)] Loss: -1242.224854\n",
      "Train Epoch: 1157 [34304/60000 (57%)] Loss: -1200.567627\n",
      "Train Epoch: 1157 [45568/60000 (76%)] Loss: -1383.144775\n",
      "Train Epoch: 1157 [56832/60000 (95%)] Loss: -1024.569214\n",
      "    epoch          : 1157\n",
      "    loss           : -1343.21558237884\n",
      "Train Epoch: 1158 [512/60000 (1%)] Loss: -1475.885742\n",
      "Train Epoch: 1158 [11776/60000 (20%)] Loss: -945.044067\n",
      "Train Epoch: 1158 [23040/60000 (38%)] Loss: -1524.217773\n",
      "Train Epoch: 1158 [34304/60000 (57%)] Loss: -1397.026855\n",
      "Train Epoch: 1158 [45568/60000 (76%)] Loss: -1324.942871\n",
      "Train Epoch: 1158 [56832/60000 (95%)] Loss: -1312.384033\n",
      "    epoch          : 1158\n",
      "    loss           : -1335.2163818704205\n",
      "Train Epoch: 1159 [512/60000 (1%)] Loss: -1215.050415\n",
      "Train Epoch: 1159 [11776/60000 (20%)] Loss: -1303.503052\n",
      "Train Epoch: 1159 [23040/60000 (38%)] Loss: -1322.673584\n",
      "Train Epoch: 1159 [34304/60000 (57%)] Loss: -1198.609619\n",
      "Train Epoch: 1159 [45568/60000 (76%)] Loss: -1468.247803\n",
      "Train Epoch: 1159 [56832/60000 (95%)] Loss: -1223.075562\n",
      "    epoch          : 1159\n",
      "    loss           : -1321.2930999583443\n",
      "Train Epoch: 1160 [512/60000 (1%)] Loss: -1212.911621\n",
      "Train Epoch: 1160 [11776/60000 (20%)] Loss: -1229.701294\n",
      "Train Epoch: 1160 [23040/60000 (38%)] Loss: -1309.450806\n",
      "Train Epoch: 1160 [34304/60000 (57%)] Loss: -1302.449585\n",
      "Train Epoch: 1160 [45568/60000 (76%)] Loss: -1211.466553\n",
      "Train Epoch: 1160 [56832/60000 (95%)] Loss: -1137.681396\n",
      "    epoch          : 1160\n",
      "    loss           : -1316.894645216775\n",
      "Train Epoch: 1161 [512/60000 (1%)] Loss: -1316.172363\n",
      "Train Epoch: 1161 [11776/60000 (20%)] Loss: -1301.498535\n",
      "Train Epoch: 1161 [23040/60000 (38%)] Loss: -974.404480\n",
      "Train Epoch: 1161 [34304/60000 (57%)] Loss: -1375.399902\n",
      "Train Epoch: 1161 [45568/60000 (76%)] Loss: -1462.470337\n",
      "Train Epoch: 1161 [56832/60000 (95%)] Loss: -1351.854980\n",
      "    epoch          : 1161\n",
      "    loss           : -1308.535255389025\n",
      "Train Epoch: 1162 [512/60000 (1%)] Loss: -1458.567627\n",
      "Train Epoch: 1162 [11776/60000 (20%)] Loss: -868.881897\n",
      "Train Epoch: 1162 [23040/60000 (38%)] Loss: -1334.504883\n",
      "Train Epoch: 1162 [34304/60000 (57%)] Loss: -1514.328979\n",
      "Train Epoch: 1162 [45568/60000 (76%)] Loss: -1479.868652\n",
      "Train Epoch: 1162 [56832/60000 (95%)] Loss: -1077.481689\n",
      "    epoch          : 1162\n",
      "    loss           : -1308.3494142004324\n",
      "Train Epoch: 1163 [512/60000 (1%)] Loss: -1348.436401\n",
      "Train Epoch: 1163 [11776/60000 (20%)] Loss: -1498.516724\n",
      "Train Epoch: 1163 [23040/60000 (38%)] Loss: -1340.123535\n",
      "Train Epoch: 1163 [34304/60000 (57%)] Loss: -1485.310791\n",
      "Train Epoch: 1163 [45568/60000 (76%)] Loss: -1505.464722\n",
      "Train Epoch: 1163 [56832/60000 (95%)] Loss: -1308.652588\n",
      "    epoch          : 1163\n",
      "    loss           : -1331.221610031559\n",
      "Train Epoch: 1164 [512/60000 (1%)] Loss: -1287.693970\n",
      "Train Epoch: 1164 [11776/60000 (20%)] Loss: -1467.821655\n",
      "Train Epoch: 1164 [23040/60000 (38%)] Loss: -1466.589233\n",
      "Train Epoch: 1164 [34304/60000 (57%)] Loss: -1340.115845\n",
      "Train Epoch: 1164 [45568/60000 (76%)] Loss: -1321.385010\n",
      "Train Epoch: 1164 [56832/60000 (95%)] Loss: -1161.976685\n",
      "    epoch          : 1164\n",
      "    loss           : -1339.6489692300054\n",
      "Train Epoch: 1165 [512/60000 (1%)] Loss: -1302.088013\n",
      "Train Epoch: 1165 [11776/60000 (20%)] Loss: -1075.087036\n",
      "Train Epoch: 1165 [23040/60000 (38%)] Loss: -1470.339478\n",
      "Train Epoch: 1165 [34304/60000 (57%)] Loss: -1312.690308\n",
      "Train Epoch: 1165 [45568/60000 (76%)] Loss: -1173.374023\n",
      "Train Epoch: 1165 [56832/60000 (95%)] Loss: -1142.653320\n",
      "    epoch          : 1165\n",
      "    loss           : -1319.434233239815\n",
      "Train Epoch: 1166 [512/60000 (1%)] Loss: -1495.905151\n",
      "Train Epoch: 1166 [11776/60000 (20%)] Loss: -1276.453613\n",
      "Train Epoch: 1166 [23040/60000 (38%)] Loss: -1146.054688\n",
      "Train Epoch: 1166 [34304/60000 (57%)] Loss: -1537.671021\n",
      "Train Epoch: 1166 [45568/60000 (76%)] Loss: -1263.919678\n",
      "Train Epoch: 1166 [56832/60000 (95%)] Loss: -1288.093018\n",
      "    epoch          : 1166\n",
      "    loss           : -1315.517602435613\n",
      "Train Epoch: 1167 [512/60000 (1%)] Loss: -1434.939453\n",
      "Train Epoch: 1167 [11776/60000 (20%)] Loss: -1460.636475\n",
      "Train Epoch: 1167 [23040/60000 (38%)] Loss: -1295.737427\n",
      "Train Epoch: 1167 [34304/60000 (57%)] Loss: -1480.921753\n",
      "Train Epoch: 1167 [45568/60000 (76%)] Loss: -1291.984619\n",
      "Train Epoch: 1167 [56832/60000 (95%)] Loss: -1147.940918\n",
      "    epoch          : 1167\n",
      "    loss           : -1329.8937703795352\n",
      "Train Epoch: 1168 [512/60000 (1%)] Loss: -1298.539673\n",
      "Train Epoch: 1168 [11776/60000 (20%)] Loss: -1291.392334\n",
      "Train Epoch: 1168 [23040/60000 (38%)] Loss: -1455.903076\n",
      "Train Epoch: 1168 [34304/60000 (57%)] Loss: -1173.358643\n",
      "Train Epoch: 1168 [45568/60000 (76%)] Loss: -1481.967651\n",
      "Train Epoch: 1168 [56832/60000 (95%)] Loss: -1133.669922\n",
      "    epoch          : 1168\n",
      "    loss           : -1319.7660608668784\n",
      "Train Epoch: 1169 [512/60000 (1%)] Loss: -1188.651978\n",
      "Train Epoch: 1169 [11776/60000 (20%)] Loss: -1351.872803\n",
      "Train Epoch: 1169 [23040/60000 (38%)] Loss: -1181.076660\n",
      "Train Epoch: 1169 [34304/60000 (57%)] Loss: -1473.766235\n",
      "Train Epoch: 1169 [45568/60000 (76%)] Loss: -1196.363037\n",
      "Train Epoch: 1169 [56832/60000 (95%)] Loss: -1383.028076\n",
      "    epoch          : 1169\n",
      "    loss           : -1319.334718003785\n",
      "Train Epoch: 1170 [512/60000 (1%)] Loss: -1371.222778\n",
      "Train Epoch: 1170 [11776/60000 (20%)] Loss: -1163.335205\n",
      "Train Epoch: 1170 [23040/60000 (38%)] Loss: -1342.640015\n",
      "Train Epoch: 1170 [34304/60000 (57%)] Loss: -1502.536621\n",
      "Train Epoch: 1170 [45568/60000 (76%)] Loss: -1337.631714\n",
      "Train Epoch: 1170 [56832/60000 (95%)] Loss: -1453.793701\n",
      "    epoch          : 1170\n",
      "    loss           : -1320.4708031261036\n",
      "Train Epoch: 1171 [512/60000 (1%)] Loss: -1177.157471\n",
      "Train Epoch: 1171 [11776/60000 (20%)] Loss: -1125.157715\n",
      "Train Epoch: 1171 [23040/60000 (38%)] Loss: -1352.755737\n",
      "Train Epoch: 1171 [34304/60000 (57%)] Loss: -1295.748779\n",
      "Train Epoch: 1171 [45568/60000 (76%)] Loss: -1323.565308\n",
      "Train Epoch: 1171 [56832/60000 (95%)] Loss: -1354.734253\n",
      "    epoch          : 1171\n",
      "    loss           : -1308.5880109711554\n",
      "Train Epoch: 1172 [512/60000 (1%)] Loss: -1478.201538\n",
      "Train Epoch: 1172 [11776/60000 (20%)] Loss: -1348.477417\n",
      "Train Epoch: 1172 [23040/60000 (38%)] Loss: -1466.468140\n",
      "Train Epoch: 1172 [34304/60000 (57%)] Loss: -1495.377441\n",
      "Train Epoch: 1172 [45568/60000 (76%)] Loss: -1163.529663\n",
      "Train Epoch: 1172 [56832/60000 (95%)] Loss: -1325.747681\n",
      "    epoch          : 1172\n",
      "    loss           : -1322.4057093043784\n",
      "Train Epoch: 1173 [512/60000 (1%)] Loss: -1151.761963\n",
      "Train Epoch: 1173 [11776/60000 (20%)] Loss: -1261.955811\n",
      "Train Epoch: 1173 [23040/60000 (38%)] Loss: -1232.098755\n",
      "Train Epoch: 1173 [34304/60000 (57%)] Loss: -1346.401123\n",
      "Train Epoch: 1173 [45568/60000 (76%)] Loss: -1331.911377\n",
      "Train Epoch: 1173 [56832/60000 (95%)] Loss: -1337.967651\n",
      "    epoch          : 1173\n",
      "    loss           : -1330.0310791360455\n",
      "Train Epoch: 1174 [512/60000 (1%)] Loss: -1487.169434\n",
      "Train Epoch: 1174 [11776/60000 (20%)] Loss: -1339.532227\n",
      "Train Epoch: 1174 [23040/60000 (38%)] Loss: -1366.023682\n",
      "Train Epoch: 1174 [34304/60000 (57%)] Loss: -1456.166260\n",
      "Train Epoch: 1174 [45568/60000 (76%)] Loss: -1463.584229\n",
      "Train Epoch: 1174 [56832/60000 (95%)] Loss: -1481.182495\n",
      "    epoch          : 1174\n",
      "    loss           : -1295.7448106323932\n",
      "Train Epoch: 1175 [512/60000 (1%)] Loss: -1334.024414\n",
      "Train Epoch: 1175 [11776/60000 (20%)] Loss: -1331.371826\n",
      "Train Epoch: 1175 [23040/60000 (38%)] Loss: -1476.320312\n",
      "Train Epoch: 1175 [34304/60000 (57%)] Loss: -1290.199951\n",
      "Train Epoch: 1175 [45568/60000 (76%)] Loss: -1310.431763\n",
      "Train Epoch: 1175 [56832/60000 (95%)] Loss: -1197.163818\n",
      "    epoch          : 1175\n",
      "    loss           : -1331.281281724488\n",
      "Train Epoch: 1176 [512/60000 (1%)] Loss: -1445.223999\n",
      "Train Epoch: 1176 [11776/60000 (20%)] Loss: -1364.430786\n",
      "Train Epoch: 1176 [23040/60000 (38%)] Loss: -1344.790771\n",
      "Train Epoch: 1176 [34304/60000 (57%)] Loss: -1349.026123\n",
      "Train Epoch: 1176 [45568/60000 (76%)] Loss: -1395.506348\n",
      "Train Epoch: 1176 [56832/60000 (95%)] Loss: -1017.857056\n",
      "    epoch          : 1176\n",
      "    loss           : -1322.5574866688182\n",
      "Train Epoch: 1177 [512/60000 (1%)] Loss: -1202.806519\n",
      "Train Epoch: 1177 [11776/60000 (20%)] Loss: -1468.521118\n",
      "Train Epoch: 1177 [23040/60000 (38%)] Loss: -1484.774658\n",
      "Train Epoch: 1177 [34304/60000 (57%)] Loss: -1094.570557\n",
      "Train Epoch: 1177 [45568/60000 (76%)] Loss: -1294.865723\n",
      "Train Epoch: 1177 [56832/60000 (95%)] Loss: -1501.035889\n",
      "    epoch          : 1177\n",
      "    loss           : -1315.8625308968928\n",
      "Train Epoch: 1178 [512/60000 (1%)] Loss: -1309.522949\n",
      "Train Epoch: 1178 [11776/60000 (20%)] Loss: -1455.214355\n",
      "Train Epoch: 1178 [23040/60000 (38%)] Loss: -1362.612183\n",
      "Train Epoch: 1178 [34304/60000 (57%)] Loss: -1468.853149\n",
      "Train Epoch: 1178 [45568/60000 (76%)] Loss: -1305.639893\n",
      "Train Epoch: 1178 [56832/60000 (95%)] Loss: -1334.874023\n",
      "    epoch          : 1178\n",
      "    loss           : -1323.6035395907818\n",
      "Train Epoch: 1179 [512/60000 (1%)] Loss: -1215.693604\n",
      "Train Epoch: 1179 [11776/60000 (20%)] Loss: -1129.403809\n",
      "Train Epoch: 1179 [23040/60000 (38%)] Loss: -1138.187012\n",
      "Train Epoch: 1179 [34304/60000 (57%)] Loss: -1235.173950\n",
      "Train Epoch: 1179 [45568/60000 (76%)] Loss: -1495.311279\n",
      "Train Epoch: 1179 [56832/60000 (95%)] Loss: -1375.780151\n",
      "    epoch          : 1179\n",
      "    loss           : -1304.752141747771\n",
      "Train Epoch: 1180 [512/60000 (1%)] Loss: -1508.365601\n",
      "Train Epoch: 1180 [11776/60000 (20%)] Loss: -1146.069092\n",
      "Train Epoch: 1180 [23040/60000 (38%)] Loss: -1493.681152\n",
      "Train Epoch: 1180 [34304/60000 (57%)] Loss: -1125.880981\n",
      "Train Epoch: 1180 [45568/60000 (76%)] Loss: -1196.230957\n",
      "Train Epoch: 1180 [56832/60000 (95%)] Loss: -1331.132080\n",
      "    epoch          : 1180\n",
      "    loss           : -1311.484793625309\n",
      "Train Epoch: 1181 [512/60000 (1%)] Loss: -1310.053101\n",
      "Train Epoch: 1181 [11776/60000 (20%)] Loss: -1394.618164\n",
      "Train Epoch: 1181 [23040/60000 (38%)] Loss: -1166.224609\n",
      "Train Epoch: 1181 [34304/60000 (57%)] Loss: -1489.239502\n",
      "Train Epoch: 1181 [45568/60000 (76%)] Loss: -1449.142822\n",
      "Train Epoch: 1181 [56832/60000 (95%)] Loss: -1349.445312\n",
      "    epoch          : 1181\n",
      "    loss           : -1322.21157078285\n",
      "Train Epoch: 1182 [512/60000 (1%)] Loss: -1378.921021\n",
      "Train Epoch: 1182 [11776/60000 (20%)] Loss: -1303.634155\n",
      "Train Epoch: 1182 [23040/60000 (38%)] Loss: -1520.764282\n",
      "Train Epoch: 1182 [34304/60000 (57%)] Loss: -1478.725586\n",
      "Train Epoch: 1182 [45568/60000 (76%)] Loss: -1443.657593\n",
      "Train Epoch: 1182 [56832/60000 (95%)] Loss: -1495.446045\n",
      "    epoch          : 1182\n",
      "    loss           : -1332.4273979919778\n",
      "Train Epoch: 1183 [512/60000 (1%)] Loss: -1166.809692\n",
      "Train Epoch: 1183 [11776/60000 (20%)] Loss: -1199.094116\n",
      "Train Epoch: 1183 [23040/60000 (38%)] Loss: -1017.713074\n",
      "Train Epoch: 1183 [34304/60000 (57%)] Loss: -1183.638672\n",
      "Train Epoch: 1183 [45568/60000 (76%)] Loss: -1290.259033\n",
      "Train Epoch: 1183 [56832/60000 (95%)] Loss: -1054.337646\n",
      "    epoch          : 1183\n",
      "    loss           : -1309.5596244510284\n",
      "Train Epoch: 1184 [512/60000 (1%)] Loss: -1287.644531\n",
      "Train Epoch: 1184 [11776/60000 (20%)] Loss: -1345.393555\n",
      "Train Epoch: 1184 [23040/60000 (38%)] Loss: -1523.799316\n",
      "Train Epoch: 1184 [34304/60000 (57%)] Loss: -1490.133301\n",
      "Train Epoch: 1184 [45568/60000 (76%)] Loss: -1450.004395\n",
      "Train Epoch: 1184 [56832/60000 (95%)] Loss: -1322.811768\n",
      "    epoch          : 1184\n",
      "    loss           : -1307.5466437905523\n",
      "Train Epoch: 1185 [512/60000 (1%)] Loss: -1345.861938\n",
      "Train Epoch: 1185 [11776/60000 (20%)] Loss: -1486.502197\n",
      "Train Epoch: 1185 [23040/60000 (38%)] Loss: -1295.064575\n",
      "Train Epoch: 1185 [34304/60000 (57%)] Loss: -1367.231079\n",
      "Train Epoch: 1185 [45568/60000 (76%)] Loss: -1009.939514\n",
      "Train Epoch: 1185 [56832/60000 (95%)] Loss: -1147.924316\n",
      "    epoch          : 1185\n",
      "    loss           : -1310.5113408147952\n",
      "Train Epoch: 1186 [512/60000 (1%)] Loss: -1483.652344\n",
      "Train Epoch: 1186 [11776/60000 (20%)] Loss: -1459.208618\n",
      "Train Epoch: 1186 [23040/60000 (38%)] Loss: -1359.487183\n",
      "Train Epoch: 1186 [34304/60000 (57%)] Loss: -1456.264160\n",
      "Train Epoch: 1186 [45568/60000 (76%)] Loss: -1385.955566\n",
      "Train Epoch: 1186 [56832/60000 (95%)] Loss: -1070.458862\n",
      "    epoch          : 1186\n",
      "    loss           : -1327.623936712405\n",
      "Train Epoch: 1187 [512/60000 (1%)] Loss: -1296.541016\n",
      "Train Epoch: 1187 [11776/60000 (20%)] Loss: -1337.427734\n",
      "Train Epoch: 1187 [23040/60000 (38%)] Loss: -1144.412842\n",
      "Train Epoch: 1187 [34304/60000 (57%)] Loss: -1348.593018\n",
      "Train Epoch: 1187 [45568/60000 (76%)] Loss: -1172.903564\n",
      "Train Epoch: 1187 [56832/60000 (95%)] Loss: -1282.940430\n",
      "    epoch          : 1187\n",
      "    loss           : -1302.6310595496227\n",
      "Train Epoch: 1188 [512/60000 (1%)] Loss: -1438.481934\n",
      "Train Epoch: 1188 [11776/60000 (20%)] Loss: -1500.180054\n",
      "Train Epoch: 1188 [23040/60000 (38%)] Loss: -1194.306030\n",
      "Train Epoch: 1188 [34304/60000 (57%)] Loss: -1334.602295\n",
      "Train Epoch: 1188 [45568/60000 (76%)] Loss: -1312.465210\n",
      "Train Epoch: 1188 [56832/60000 (95%)] Loss: -1346.672729\n",
      "    epoch          : 1188\n",
      "    loss           : -1311.9701427739892\n",
      "Train Epoch: 1189 [512/60000 (1%)] Loss: -1483.039673\n",
      "Train Epoch: 1189 [11776/60000 (20%)] Loss: -1489.462036\n",
      "Train Epoch: 1189 [23040/60000 (38%)] Loss: -1470.577271\n",
      "Train Epoch: 1189 [34304/60000 (57%)] Loss: -1342.654053\n",
      "Train Epoch: 1189 [45568/60000 (76%)] Loss: -1475.437500\n",
      "Train Epoch: 1189 [56832/60000 (95%)] Loss: -1495.547119\n",
      "    epoch          : 1189\n",
      "    loss           : -1322.5850580075366\n",
      "Train Epoch: 1190 [512/60000 (1%)] Loss: -1496.523193\n",
      "Train Epoch: 1190 [11776/60000 (20%)] Loss: -1341.383301\n",
      "Train Epoch: 1190 [23040/60000 (38%)] Loss: -1487.043579\n",
      "Train Epoch: 1190 [34304/60000 (57%)] Loss: -1501.468872\n",
      "Train Epoch: 1190 [45568/60000 (76%)] Loss: -1288.708984\n",
      "Train Epoch: 1190 [56832/60000 (95%)] Loss: -1350.745605\n",
      "    epoch          : 1190\n",
      "    loss           : -1332.3085503012446\n",
      "Train Epoch: 1191 [512/60000 (1%)] Loss: -1187.722778\n",
      "Train Epoch: 1191 [11776/60000 (20%)] Loss: -1324.258057\n",
      "Train Epoch: 1191 [23040/60000 (38%)] Loss: -1349.903076\n",
      "Train Epoch: 1191 [34304/60000 (57%)] Loss: -1331.673218\n",
      "Train Epoch: 1191 [45568/60000 (76%)] Loss: -1291.742920\n",
      "Train Epoch: 1191 [56832/60000 (95%)] Loss: -1328.439697\n",
      "    epoch          : 1191\n",
      "    loss           : -1319.1158378299347\n",
      "Train Epoch: 1192 [512/60000 (1%)] Loss: -1161.502563\n",
      "Train Epoch: 1192 [11776/60000 (20%)] Loss: -1494.411499\n",
      "Train Epoch: 1192 [23040/60000 (38%)] Loss: -1170.001587\n",
      "Train Epoch: 1192 [34304/60000 (57%)] Loss: -1151.411743\n",
      "Train Epoch: 1192 [45568/60000 (76%)] Loss: -1494.521729\n",
      "Train Epoch: 1192 [56832/60000 (95%)] Loss: -1506.549683\n",
      "    epoch          : 1192\n",
      "    loss           : -1313.3345031738281\n",
      "Train Epoch: 1193 [512/60000 (1%)] Loss: -1491.146851\n",
      "Train Epoch: 1193 [11776/60000 (20%)] Loss: -1326.972900\n",
      "Train Epoch: 1193 [23040/60000 (38%)] Loss: -1329.900391\n",
      "Train Epoch: 1193 [34304/60000 (57%)] Loss: -1358.436401\n",
      "Train Epoch: 1193 [45568/60000 (76%)] Loss: -1020.268188\n",
      "Train Epoch: 1193 [56832/60000 (95%)] Loss: -1311.909668\n",
      "    epoch          : 1193\n",
      "    loss           : -1318.0000093104475\n",
      "Train Epoch: 1194 [512/60000 (1%)] Loss: -1032.480469\n",
      "Train Epoch: 1194 [11776/60000 (20%)] Loss: -1354.774170\n",
      "Train Epoch: 1194 [23040/60000 (38%)] Loss: -1337.635986\n",
      "Train Epoch: 1194 [34304/60000 (57%)] Loss: -1332.295288\n",
      "Train Epoch: 1194 [45568/60000 (76%)] Loss: -1344.942505\n",
      "Train Epoch: 1194 [56832/60000 (95%)] Loss: -1476.561035\n",
      "    epoch          : 1194\n",
      "    loss           : -1331.6642261224952\n",
      "Train Epoch: 1195 [512/60000 (1%)] Loss: -1339.729858\n",
      "Train Epoch: 1195 [11776/60000 (20%)] Loss: -1284.545776\n",
      "Train Epoch: 1195 [23040/60000 (38%)] Loss: -1375.755737\n",
      "Train Epoch: 1195 [34304/60000 (57%)] Loss: -1195.470337\n",
      "Train Epoch: 1195 [45568/60000 (76%)] Loss: -1300.887207\n",
      "Train Epoch: 1195 [56832/60000 (95%)] Loss: -947.079407\n",
      "    epoch          : 1195\n",
      "    loss           : -1305.2827070850437\n",
      "Train Epoch: 1196 [512/60000 (1%)] Loss: -1217.096436\n",
      "Train Epoch: 1196 [11776/60000 (20%)] Loss: -1301.411621\n",
      "Train Epoch: 1196 [23040/60000 (38%)] Loss: -1338.250244\n",
      "Train Epoch: 1196 [34304/60000 (57%)] Loss: -1487.758301\n",
      "Train Epoch: 1196 [45568/60000 (76%)] Loss: -1350.264893\n",
      "Train Epoch: 1196 [56832/60000 (95%)] Loss: -1364.192017\n",
      "    epoch          : 1196\n",
      "    loss           : -1310.6858917063912\n",
      "Train Epoch: 1197 [512/60000 (1%)] Loss: -1392.439941\n",
      "Train Epoch: 1197 [11776/60000 (20%)] Loss: -1493.712158\n",
      "Train Epoch: 1197 [23040/60000 (38%)] Loss: -1424.101074\n",
      "Train Epoch: 1197 [34304/60000 (57%)] Loss: -1215.561157\n",
      "Train Epoch: 1197 [45568/60000 (76%)] Loss: -1478.800293\n",
      "Train Epoch: 1197 [56832/60000 (95%)] Loss: -1046.013184\n",
      "    epoch          : 1197\n",
      "    loss           : -1318.0953617419227\n",
      "Train Epoch: 1198 [512/60000 (1%)] Loss: -1488.951782\n",
      "Train Epoch: 1198 [11776/60000 (20%)] Loss: -1486.581665\n",
      "Train Epoch: 1198 [23040/60000 (38%)] Loss: -1369.060303\n",
      "Train Epoch: 1198 [34304/60000 (57%)] Loss: -1492.742554\n",
      "Train Epoch: 1198 [45568/60000 (76%)] Loss: -1292.175293\n",
      "Train Epoch: 1198 [56832/60000 (95%)] Loss: -1355.698730\n",
      "    epoch          : 1198\n",
      "    loss           : -1346.415670103946\n",
      "Train Epoch: 1199 [512/60000 (1%)] Loss: -1302.094238\n",
      "Train Epoch: 1199 [11776/60000 (20%)] Loss: -1339.743164\n",
      "Train Epoch: 1199 [23040/60000 (38%)] Loss: -1331.911133\n",
      "Train Epoch: 1199 [34304/60000 (57%)] Loss: -1296.433594\n",
      "Train Epoch: 1199 [45568/60000 (76%)] Loss: -1052.032715\n",
      "Train Epoch: 1199 [56832/60000 (95%)] Loss: -1339.141846\n",
      "    epoch          : 1199\n",
      "    loss           : -1320.4134650796148\n",
      "Train Epoch: 1200 [512/60000 (1%)] Loss: -1330.250122\n",
      "Train Epoch: 1200 [11776/60000 (20%)] Loss: -1158.184692\n",
      "Train Epoch: 1200 [23040/60000 (38%)] Loss: -1491.071533\n",
      "Train Epoch: 1200 [34304/60000 (57%)] Loss: -1472.463867\n",
      "Train Epoch: 1200 [45568/60000 (76%)] Loss: -1313.193970\n",
      "Train Epoch: 1200 [56832/60000 (95%)] Loss: -1356.112549\n",
      "    epoch          : 1200\n",
      "    loss           : -1314.0323593225855\n",
      "Saving checkpoint: saved/models/Mnist_DeepGenerativeOperad/0127_111843/checkpoint-epoch1200.pth ...\n",
      "Train Epoch: 1201 [512/60000 (1%)] Loss: -1071.946533\n",
      "Train Epoch: 1201 [11776/60000 (20%)] Loss: -1445.749023\n",
      "Train Epoch: 1201 [23040/60000 (38%)] Loss: -1325.757324\n",
      "Train Epoch: 1201 [34304/60000 (57%)] Loss: -999.140076\n",
      "Train Epoch: 1201 [45568/60000 (76%)] Loss: -1200.565552\n",
      "Train Epoch: 1201 [56832/60000 (95%)] Loss: -1171.527344\n",
      "    epoch          : 1201\n",
      "    loss           : -1330.5826114288157\n",
      "Train Epoch: 1202 [512/60000 (1%)] Loss: -1326.429688\n",
      "Train Epoch: 1202 [11776/60000 (20%)] Loss: -1337.711182\n",
      "Train Epoch: 1202 [23040/60000 (38%)] Loss: -1283.780029\n",
      "Train Epoch: 1202 [34304/60000 (57%)] Loss: -1437.559448\n",
      "Train Epoch: 1202 [45568/60000 (76%)] Loss: -941.872742\n",
      "Train Epoch: 1202 [56832/60000 (95%)] Loss: -1201.710815\n",
      "    epoch          : 1202\n",
      "    loss           : -1331.3327741892326\n",
      "Train Epoch: 1203 [512/60000 (1%)] Loss: -1479.524414\n",
      "Train Epoch: 1203 [11776/60000 (20%)] Loss: -1151.065308\n",
      "Train Epoch: 1203 [23040/60000 (38%)] Loss: -1251.779785\n",
      "Train Epoch: 1203 [34304/60000 (57%)] Loss: -1208.414673\n",
      "Train Epoch: 1203 [45568/60000 (76%)] Loss: -1365.822388\n",
      "Train Epoch: 1203 [56832/60000 (95%)] Loss: -1331.433228\n",
      "    epoch          : 1203\n",
      "    loss           : -1306.3085120249602\n",
      "Train Epoch: 1204 [512/60000 (1%)] Loss: -1196.169922\n",
      "Train Epoch: 1204 [11776/60000 (20%)] Loss: -1501.206543\n",
      "Train Epoch: 1204 [23040/60000 (38%)] Loss: -1237.674316\n",
      "Train Epoch: 1204 [34304/60000 (57%)] Loss: -1221.412720\n",
      "Train Epoch: 1204 [45568/60000 (76%)] Loss: -1374.645752\n",
      "Train Epoch: 1204 [56832/60000 (95%)] Loss: -1324.036621\n",
      "    epoch          : 1204\n",
      "    loss           : -1324.13221645894\n",
      "Train Epoch: 1205 [512/60000 (1%)] Loss: -1160.468750\n",
      "Train Epoch: 1205 [11776/60000 (20%)] Loss: -1084.558350\n",
      "Train Epoch: 1205 [23040/60000 (38%)] Loss: -1199.159912\n",
      "Train Epoch: 1205 [34304/60000 (57%)] Loss: -1024.360352\n",
      "Train Epoch: 1205 [45568/60000 (76%)] Loss: -1194.916138\n",
      "Train Epoch: 1205 [56832/60000 (95%)] Loss: -1481.293091\n",
      "    epoch          : 1205\n",
      "    loss           : -1320.2742263018074\n",
      "Train Epoch: 1206 [512/60000 (1%)] Loss: -1103.162842\n",
      "Train Epoch: 1206 [11776/60000 (20%)] Loss: -1249.379761\n",
      "Train Epoch: 1206 [23040/60000 (38%)] Loss: -1222.703857\n",
      "Train Epoch: 1206 [34304/60000 (57%)] Loss: -1305.777466\n",
      "Train Epoch: 1206 [45568/60000 (76%)] Loss: -1469.400146\n",
      "Train Epoch: 1206 [56832/60000 (95%)] Loss: -1484.809937\n",
      "    epoch          : 1206\n",
      "    loss           : -1327.0527709271273\n",
      "Train Epoch: 1207 [512/60000 (1%)] Loss: -1338.657104\n",
      "Train Epoch: 1207 [11776/60000 (20%)] Loss: -1320.194092\n",
      "Train Epoch: 1207 [23040/60000 (38%)] Loss: -1358.082764\n",
      "Train Epoch: 1207 [34304/60000 (57%)] Loss: -1340.246338\n",
      "Train Epoch: 1207 [45568/60000 (76%)] Loss: -1373.526489\n",
      "Train Epoch: 1207 [56832/60000 (95%)] Loss: -1459.144531\n",
      "    epoch          : 1207\n",
      "    loss           : -1326.796208785752\n",
      "Train Epoch: 1208 [512/60000 (1%)] Loss: -1486.078369\n",
      "Train Epoch: 1208 [11776/60000 (20%)] Loss: -1165.658813\n",
      "Train Epoch: 1208 [23040/60000 (38%)] Loss: -1091.477295\n",
      "Train Epoch: 1208 [34304/60000 (57%)] Loss: -1317.051270\n",
      "Train Epoch: 1208 [45568/60000 (76%)] Loss: -1306.226685\n",
      "Train Epoch: 1208 [56832/60000 (95%)] Loss: -1322.966797\n",
      "    epoch          : 1208\n",
      "    loss           : -1306.8655264471884\n",
      "Train Epoch: 1209 [512/60000 (1%)] Loss: -1302.489746\n",
      "Train Epoch: 1209 [11776/60000 (20%)] Loss: -1330.404053\n",
      "Train Epoch: 1209 [23040/60000 (38%)] Loss: -1347.836060\n",
      "Train Epoch: 1209 [34304/60000 (57%)] Loss: -1435.055664\n",
      "Train Epoch: 1209 [45568/60000 (76%)] Loss: -1316.116699\n",
      "Train Epoch: 1209 [56832/60000 (95%)] Loss: -1370.558105\n",
      "    epoch          : 1209\n",
      "    loss           : -1318.3942022808528\n",
      "Train Epoch: 1210 [512/60000 (1%)] Loss: -1315.822388\n",
      "Train Epoch: 1210 [11776/60000 (20%)] Loss: -1200.150879\n",
      "Train Epoch: 1210 [23040/60000 (38%)] Loss: -1483.165039\n",
      "Train Epoch: 1210 [34304/60000 (57%)] Loss: -1456.765747\n",
      "Train Epoch: 1210 [45568/60000 (76%)] Loss: -1316.623169\n",
      "Train Epoch: 1210 [56832/60000 (95%)] Loss: -1344.116333\n",
      "    epoch          : 1210\n",
      "    loss           : -1331.9758369747528\n",
      "Train Epoch: 1211 [512/60000 (1%)] Loss: -1202.296387\n",
      "Train Epoch: 1211 [11776/60000 (20%)] Loss: -1490.453369\n",
      "Train Epoch: 1211 [23040/60000 (38%)] Loss: -1445.818237\n",
      "Train Epoch: 1211 [34304/60000 (57%)] Loss: -1301.721436\n",
      "Train Epoch: 1211 [45568/60000 (76%)] Loss: -1078.292480\n",
      "Train Epoch: 1211 [56832/60000 (95%)] Loss: -1212.897217\n",
      "    epoch          : 1211\n",
      "    loss           : -1318.2327627408301\n",
      "Train Epoch: 1212 [512/60000 (1%)] Loss: -1479.496460\n",
      "Train Epoch: 1212 [11776/60000 (20%)] Loss: -1374.407593\n",
      "Train Epoch: 1212 [23040/60000 (38%)] Loss: -1352.270020\n",
      "Train Epoch: 1212 [34304/60000 (57%)] Loss: -1224.955811\n",
      "Train Epoch: 1212 [45568/60000 (76%)] Loss: -996.342285\n",
      "Train Epoch: 1212 [56832/60000 (95%)] Loss: -1176.114380\n",
      "    epoch          : 1212\n",
      "    loss           : -1330.6773612674347\n",
      "Train Epoch: 1213 [512/60000 (1%)] Loss: -1259.739136\n",
      "Train Epoch: 1213 [11776/60000 (20%)] Loss: -1319.735840\n",
      "Train Epoch: 1213 [23040/60000 (38%)] Loss: -1521.497803\n",
      "Train Epoch: 1213 [34304/60000 (57%)] Loss: -1226.857788\n",
      "Train Epoch: 1213 [45568/60000 (76%)] Loss: -1482.161133\n",
      "Train Epoch: 1213 [56832/60000 (95%)] Loss: -1331.386230\n",
      "    epoch          : 1213\n",
      "    loss           : -1336.3837711312678\n",
      "Train Epoch: 1214 [512/60000 (1%)] Loss: -1527.666016\n",
      "Train Epoch: 1214 [11776/60000 (20%)] Loss: -1172.473389\n",
      "Train Epoch: 1214 [23040/60000 (38%)] Loss: -1324.022705\n",
      "Train Epoch: 1214 [34304/60000 (57%)] Loss: -1231.137695\n",
      "Train Epoch: 1214 [45568/60000 (76%)] Loss: -1490.328857\n",
      "Train Epoch: 1214 [56832/60000 (95%)] Loss: -1294.389771\n",
      "    epoch          : 1214\n",
      "    loss           : -1345.3174622961355\n",
      "Train Epoch: 1215 [512/60000 (1%)] Loss: -1347.920654\n",
      "Train Epoch: 1215 [11776/60000 (20%)] Loss: -1496.023193\n",
      "Train Epoch: 1215 [23040/60000 (38%)] Loss: -1347.225586\n",
      "Train Epoch: 1215 [34304/60000 (57%)] Loss: -1383.291992\n",
      "Train Epoch: 1215 [45568/60000 (76%)] Loss: -1352.696411\n",
      "Train Epoch: 1215 [56832/60000 (95%)] Loss: -1216.864624\n",
      "    epoch          : 1215\n",
      "    loss           : -1312.1214115121272\n",
      "Train Epoch: 1216 [512/60000 (1%)] Loss: -1293.779297\n",
      "Train Epoch: 1216 [11776/60000 (20%)] Loss: -1357.372925\n",
      "Train Epoch: 1216 [23040/60000 (38%)] Loss: -1185.088379\n",
      "Train Epoch: 1216 [34304/60000 (57%)] Loss: -1211.147339\n",
      "Train Epoch: 1216 [45568/60000 (76%)] Loss: -1460.343506\n",
      "Train Epoch: 1216 [56832/60000 (95%)] Loss: -1522.805908\n",
      "    epoch          : 1216\n",
      "    loss           : -1327.5934165480448\n",
      "Train Epoch: 1217 [512/60000 (1%)] Loss: -1027.592041\n",
      "Train Epoch: 1217 [11776/60000 (20%)] Loss: -1366.662964\n",
      "Train Epoch: 1217 [23040/60000 (38%)] Loss: -1392.866577\n",
      "Train Epoch: 1217 [34304/60000 (57%)] Loss: -1149.179565\n",
      "Train Epoch: 1217 [45568/60000 (76%)] Loss: -1494.941650\n",
      "Train Epoch: 1217 [56832/60000 (95%)] Loss: -1210.295654\n",
      "    epoch          : 1217\n",
      "    loss           : -1323.9694113866083\n",
      "Train Epoch: 1218 [512/60000 (1%)] Loss: -1224.940918\n",
      "Train Epoch: 1218 [11776/60000 (20%)] Loss: -1331.874878\n",
      "Train Epoch: 1218 [23040/60000 (38%)] Loss: -1496.062622\n",
      "Train Epoch: 1218 [34304/60000 (57%)] Loss: -1457.143677\n",
      "Train Epoch: 1218 [45568/60000 (76%)] Loss: -1225.002197\n",
      "Train Epoch: 1218 [56832/60000 (95%)] Loss: -1333.435303\n",
      "    epoch          : 1218\n",
      "    loss           : -1349.4427424716412\n",
      "Train Epoch: 1219 [512/60000 (1%)] Loss: -1361.915405\n",
      "Train Epoch: 1219 [11776/60000 (20%)] Loss: -1436.198242\n",
      "Train Epoch: 1219 [23040/60000 (38%)] Loss: -1334.681885\n",
      "Train Epoch: 1219 [34304/60000 (57%)] Loss: -1071.182495\n",
      "Train Epoch: 1219 [45568/60000 (76%)] Loss: -1357.377563\n",
      "Train Epoch: 1219 [56832/60000 (95%)] Loss: -1512.022461\n",
      "    epoch          : 1219\n",
      "    loss           : -1342.4446228372174\n",
      "Train Epoch: 1220 [512/60000 (1%)] Loss: -1162.482178\n",
      "Train Epoch: 1220 [11776/60000 (20%)] Loss: -1393.628296\n",
      "Train Epoch: 1220 [23040/60000 (38%)] Loss: -1352.351685\n",
      "Train Epoch: 1220 [34304/60000 (57%)] Loss: -1431.719971\n",
      "Train Epoch: 1220 [45568/60000 (76%)] Loss: -1331.614624\n",
      "Train Epoch: 1220 [56832/60000 (95%)] Loss: -1197.042969\n",
      "    epoch          : 1220\n",
      "    loss           : -1345.5139215329273\n",
      "Train Epoch: 1221 [512/60000 (1%)] Loss: -1482.855957\n",
      "Train Epoch: 1221 [11776/60000 (20%)] Loss: -1454.754028\n",
      "Train Epoch: 1221 [23040/60000 (38%)] Loss: -1436.300049\n",
      "Train Epoch: 1221 [34304/60000 (57%)] Loss: -1164.096313\n",
      "Train Epoch: 1221 [45568/60000 (76%)] Loss: -1343.479980\n",
      "Train Epoch: 1221 [56832/60000 (95%)] Loss: -1483.938843\n",
      "    epoch          : 1221\n",
      "    loss           : -1336.051143667792\n",
      "Train Epoch: 1222 [512/60000 (1%)] Loss: -1222.038330\n",
      "Train Epoch: 1222 [11776/60000 (20%)] Loss: -1516.097412\n",
      "Train Epoch: 1222 [23040/60000 (38%)] Loss: -1350.989502\n",
      "Train Epoch: 1222 [34304/60000 (57%)] Loss: -1204.699341\n",
      "Train Epoch: 1222 [45568/60000 (76%)] Loss: -1500.837036\n",
      "Train Epoch: 1222 [56832/60000 (95%)] Loss: -1456.111816\n",
      "    epoch          : 1222\n",
      "    loss           : -1314.706720901748\n",
      "Train Epoch: 1223 [512/60000 (1%)] Loss: -1337.824951\n",
      "Train Epoch: 1223 [11776/60000 (20%)] Loss: -1330.716187\n",
      "Train Epoch: 1223 [23040/60000 (38%)] Loss: -1207.659546\n",
      "Train Epoch: 1223 [34304/60000 (57%)] Loss: -1313.595703\n",
      "Train Epoch: 1223 [45568/60000 (76%)] Loss: -1377.824829\n",
      "Train Epoch: 1223 [56832/60000 (95%)] Loss: -1193.607544\n",
      "    epoch          : 1223\n",
      "    loss           : -1309.8979964606506\n",
      "Train Epoch: 1224 [512/60000 (1%)] Loss: -1347.562988\n",
      "Train Epoch: 1224 [11776/60000 (20%)] Loss: -1512.369995\n",
      "Train Epoch: 1224 [23040/60000 (38%)] Loss: -1361.135376\n",
      "Train Epoch: 1224 [34304/60000 (57%)] Loss: -1231.027100\n",
      "Train Epoch: 1224 [45568/60000 (76%)] Loss: -1472.571533\n",
      "Train Epoch: 1224 [56832/60000 (95%)] Loss: -1220.984619\n",
      "    epoch          : 1224\n",
      "    loss           : -1323.9632994226145\n",
      "Train Epoch: 1225 [512/60000 (1%)] Loss: -1301.796021\n",
      "Train Epoch: 1225 [11776/60000 (20%)] Loss: -1306.244629\n",
      "Train Epoch: 1225 [23040/60000 (38%)] Loss: -1364.965454\n",
      "Train Epoch: 1225 [34304/60000 (57%)] Loss: -1169.481079\n",
      "Train Epoch: 1225 [45568/60000 (76%)] Loss: -1351.803467\n",
      "Train Epoch: 1225 [56832/60000 (95%)] Loss: -1346.834717\n",
      "    epoch          : 1225\n",
      "    loss           : -1322.3401254772466\n",
      "Train Epoch: 1226 [512/60000 (1%)] Loss: -1497.979980\n",
      "Train Epoch: 1226 [11776/60000 (20%)] Loss: -1462.429077\n",
      "Train Epoch: 1226 [23040/60000 (38%)] Loss: -1397.228882\n",
      "Train Epoch: 1226 [34304/60000 (57%)] Loss: -1368.795044\n",
      "Train Epoch: 1226 [45568/60000 (76%)] Loss: -1323.019775\n",
      "Train Epoch: 1226 [56832/60000 (95%)] Loss: -1262.305176\n",
      "    epoch          : 1226\n",
      "    loss           : -1348.4591531699662\n",
      "Train Epoch: 1227 [512/60000 (1%)] Loss: -1479.935425\n",
      "Train Epoch: 1227 [11776/60000 (20%)] Loss: -1478.554932\n",
      "Train Epoch: 1227 [23040/60000 (38%)] Loss: -1360.627319\n",
      "Train Epoch: 1227 [34304/60000 (57%)] Loss: -1074.273071\n",
      "Train Epoch: 1227 [45568/60000 (76%)] Loss: -1159.752686\n",
      "Train Epoch: 1227 [56832/60000 (95%)] Loss: -1346.247314\n",
      "    epoch          : 1227\n",
      "    loss           : -1306.302305577165\n",
      "Train Epoch: 1228 [512/60000 (1%)] Loss: -1351.338623\n",
      "Train Epoch: 1228 [11776/60000 (20%)] Loss: -1055.031738\n",
      "Train Epoch: 1228 [23040/60000 (38%)] Loss: -1489.532837\n",
      "Train Epoch: 1228 [34304/60000 (57%)] Loss: -1302.340820\n",
      "Train Epoch: 1228 [45568/60000 (76%)] Loss: -1357.428711\n",
      "Train Epoch: 1228 [56832/60000 (95%)] Loss: -1350.577148\n",
      "    epoch          : 1228\n",
      "    loss           : -1334.518906415519\n",
      "Train Epoch: 1229 [512/60000 (1%)] Loss: -1364.349731\n",
      "Train Epoch: 1229 [11776/60000 (20%)] Loss: -1203.839355\n",
      "Train Epoch: 1229 [23040/60000 (38%)] Loss: -1241.789551\n",
      "Train Epoch: 1229 [34304/60000 (57%)] Loss: -1357.979614\n",
      "Train Epoch: 1229 [45568/60000 (76%)] Loss: -1537.687012\n",
      "Train Epoch: 1229 [56832/60000 (95%)] Loss: -1162.828613\n",
      "    epoch          : 1229\n",
      "    loss           : -1329.816640218099\n",
      "Train Epoch: 1230 [512/60000 (1%)] Loss: -1192.317383\n",
      "Train Epoch: 1230 [11776/60000 (20%)] Loss: -1184.420044\n",
      "Train Epoch: 1230 [23040/60000 (38%)] Loss: -1215.190063\n",
      "Train Epoch: 1230 [34304/60000 (57%)] Loss: -1237.935303\n",
      "Train Epoch: 1230 [45568/60000 (76%)] Loss: -1453.281616\n",
      "Train Epoch: 1230 [56832/60000 (95%)] Loss: -1338.893799\n",
      "    epoch          : 1230\n",
      "    loss           : -1346.4200591178937\n",
      "Train Epoch: 1231 [512/60000 (1%)] Loss: -1469.858154\n",
      "Train Epoch: 1231 [11776/60000 (20%)] Loss: -1452.861206\n",
      "Train Epoch: 1231 [23040/60000 (38%)] Loss: -1364.046753\n",
      "Train Epoch: 1231 [34304/60000 (57%)] Loss: -1184.771973\n",
      "Train Epoch: 1231 [45568/60000 (76%)] Loss: -1327.196167\n",
      "Train Epoch: 1231 [56832/60000 (95%)] Loss: -1467.141846\n",
      "    epoch          : 1231\n",
      "    loss           : -1327.4183570301464\n",
      "Train Epoch: 1232 [512/60000 (1%)] Loss: -1174.992188\n",
      "Train Epoch: 1232 [11776/60000 (20%)] Loss: -1512.594971\n",
      "Train Epoch: 1232 [23040/60000 (38%)] Loss: -1382.903687\n",
      "Train Epoch: 1232 [34304/60000 (57%)] Loss: -1365.214355\n",
      "Train Epoch: 1232 [45568/60000 (76%)] Loss: -1200.057129\n",
      "Train Epoch: 1232 [56832/60000 (95%)] Loss: -1359.059692\n",
      "    epoch          : 1232\n",
      "    loss           : -1324.781156033446\n",
      "Train Epoch: 1233 [512/60000 (1%)] Loss: -1245.946655\n",
      "Train Epoch: 1233 [11776/60000 (20%)] Loss: -1358.365112\n",
      "Train Epoch: 1233 [23040/60000 (38%)] Loss: -1373.196777\n",
      "Train Epoch: 1233 [34304/60000 (57%)] Loss: -1516.388428\n",
      "Train Epoch: 1233 [45568/60000 (76%)] Loss: -1315.024658\n",
      "Train Epoch: 1233 [56832/60000 (95%)] Loss: -1516.485962\n",
      "    epoch          : 1233\n",
      "    loss           : -1324.9989755059366\n",
      "Train Epoch: 1234 [512/60000 (1%)] Loss: -1168.169800\n",
      "Train Epoch: 1234 [11776/60000 (20%)] Loss: -1230.466675\n",
      "Train Epoch: 1234 [23040/60000 (38%)] Loss: -1052.851440\n",
      "Train Epoch: 1234 [34304/60000 (57%)] Loss: -1336.380859\n",
      "Train Epoch: 1234 [45568/60000 (76%)] Loss: -1084.205444\n",
      "Train Epoch: 1234 [56832/60000 (95%)] Loss: -1087.270264\n",
      "    epoch          : 1234\n",
      "    loss           : -1330.384152169955\n",
      "Train Epoch: 1235 [512/60000 (1%)] Loss: -1160.373047\n",
      "Train Epoch: 1235 [11776/60000 (20%)] Loss: -1316.470337\n",
      "Train Epoch: 1235 [23040/60000 (38%)] Loss: -1228.241699\n",
      "Train Epoch: 1235 [34304/60000 (57%)] Loss: -1339.640137\n",
      "Train Epoch: 1235 [45568/60000 (76%)] Loss: -1174.318237\n",
      "Train Epoch: 1235 [56832/60000 (95%)] Loss: -1326.135986\n",
      "    epoch          : 1235\n",
      "    loss           : -1316.3592825851872\n",
      "Train Epoch: 1236 [512/60000 (1%)] Loss: -1331.347778\n",
      "Train Epoch: 1236 [11776/60000 (20%)] Loss: -1357.101318\n",
      "Train Epoch: 1236 [23040/60000 (38%)] Loss: -1037.213867\n",
      "Train Epoch: 1236 [34304/60000 (57%)] Loss: -1343.130981\n",
      "Train Epoch: 1236 [45568/60000 (76%)] Loss: -1294.969971\n",
      "Train Epoch: 1236 [56832/60000 (95%)] Loss: -1394.708130\n",
      "    epoch          : 1236\n",
      "    loss           : -1305.3090261685645\n",
      "Train Epoch: 1237 [512/60000 (1%)] Loss: -1328.945557\n",
      "Train Epoch: 1237 [11776/60000 (20%)] Loss: -1439.608398\n",
      "Train Epoch: 1237 [23040/60000 (38%)] Loss: -1501.831055\n",
      "Train Epoch: 1237 [34304/60000 (57%)] Loss: -1343.286377\n",
      "Train Epoch: 1237 [45568/60000 (76%)] Loss: -1198.152710\n",
      "Train Epoch: 1237 [56832/60000 (95%)] Loss: -1385.876831\n",
      "    epoch          : 1237\n",
      "    loss           : -1318.773613708841\n",
      "Train Epoch: 1238 [512/60000 (1%)] Loss: -1162.961914\n",
      "Train Epoch: 1238 [11776/60000 (20%)] Loss: -1357.662354\n",
      "Train Epoch: 1238 [23040/60000 (38%)] Loss: -1458.562012\n",
      "Train Epoch: 1238 [34304/60000 (57%)] Loss: -1163.310547\n",
      "Train Epoch: 1238 [45568/60000 (76%)] Loss: -1418.256348\n",
      "Train Epoch: 1238 [56832/60000 (95%)] Loss: -1100.019043\n",
      "    epoch          : 1238\n",
      "    loss           : -1318.123875160002\n",
      "Train Epoch: 1239 [512/60000 (1%)] Loss: -1301.344727\n",
      "Train Epoch: 1239 [11776/60000 (20%)] Loss: -1295.886108\n",
      "Train Epoch: 1239 [23040/60000 (38%)] Loss: -1371.169678\n",
      "Train Epoch: 1239 [34304/60000 (57%)] Loss: -1365.860474\n",
      "Train Epoch: 1239 [45568/60000 (76%)] Loss: -1059.300049\n",
      "Train Epoch: 1239 [56832/60000 (95%)] Loss: -1522.455078\n",
      "    epoch          : 1239\n",
      "    loss           : -1332.5004527636167\n",
      "Train Epoch: 1240 [512/60000 (1%)] Loss: -1476.995117\n",
      "Train Epoch: 1240 [11776/60000 (20%)] Loss: -1370.961060\n",
      "Train Epoch: 1240 [23040/60000 (38%)] Loss: -1341.118530\n",
      "Train Epoch: 1240 [34304/60000 (57%)] Loss: -1178.361938\n",
      "Train Epoch: 1240 [45568/60000 (76%)] Loss: -1166.385864\n",
      "Train Epoch: 1240 [56832/60000 (95%)] Loss: -1313.585449\n",
      "    epoch          : 1240\n",
      "    loss           : -1328.1618805793719\n",
      "Train Epoch: 1241 [512/60000 (1%)] Loss: -1348.947266\n",
      "Train Epoch: 1241 [11776/60000 (20%)] Loss: -1202.414551\n",
      "Train Epoch: 1241 [23040/60000 (38%)] Loss: -1339.053955\n",
      "Train Epoch: 1241 [34304/60000 (57%)] Loss: -1478.597168\n",
      "Train Epoch: 1241 [45568/60000 (76%)] Loss: -1052.085449\n",
      "Train Epoch: 1241 [56832/60000 (95%)] Loss: -1373.496704\n",
      "    epoch          : 1241\n",
      "    loss           : -1315.7003554866812\n",
      "Train Epoch: 1242 [512/60000 (1%)] Loss: -1474.966309\n",
      "Train Epoch: 1242 [11776/60000 (20%)] Loss: -1490.327271\n",
      "Train Epoch: 1242 [23040/60000 (38%)] Loss: -1449.419678\n",
      "Train Epoch: 1242 [34304/60000 (57%)] Loss: -1325.324463\n",
      "Train Epoch: 1242 [45568/60000 (76%)] Loss: -1344.761963\n",
      "Train Epoch: 1242 [56832/60000 (95%)] Loss: -1379.376587\n",
      "    epoch          : 1242\n",
      "    loss           : -1338.7935011696682\n",
      "Train Epoch: 1243 [512/60000 (1%)] Loss: -1208.737793\n",
      "Train Epoch: 1243 [11776/60000 (20%)] Loss: -1185.742432\n",
      "Train Epoch: 1243 [23040/60000 (38%)] Loss: -1326.069092\n",
      "Train Epoch: 1243 [34304/60000 (57%)] Loss: -1528.939941\n",
      "Train Epoch: 1243 [45568/60000 (76%)] Loss: -1325.877075\n",
      "Train Epoch: 1243 [56832/60000 (95%)] Loss: -1499.119873\n",
      "    epoch          : 1243\n",
      "    loss           : -1325.4703713972015\n",
      "Train Epoch: 1244 [512/60000 (1%)] Loss: -1316.815796\n",
      "Train Epoch: 1244 [11776/60000 (20%)] Loss: -1394.268066\n",
      "Train Epoch: 1244 [23040/60000 (38%)] Loss: -1350.429443\n",
      "Train Epoch: 1244 [34304/60000 (57%)] Loss: -1200.999146\n",
      "Train Epoch: 1244 [45568/60000 (76%)] Loss: -1503.130371\n",
      "Train Epoch: 1244 [56832/60000 (95%)] Loss: -1226.654663\n",
      "    epoch          : 1244\n",
      "    loss           : -1336.6538172145347\n",
      "Train Epoch: 1245 [512/60000 (1%)] Loss: -1228.844360\n",
      "Train Epoch: 1245 [11776/60000 (20%)] Loss: -1376.965088\n",
      "Train Epoch: 1245 [23040/60000 (38%)] Loss: -1379.405029\n",
      "Train Epoch: 1245 [34304/60000 (57%)] Loss: -1216.106445\n",
      "Train Epoch: 1245 [45568/60000 (76%)] Loss: -1217.282227\n",
      "Train Epoch: 1245 [56832/60000 (95%)] Loss: -1334.657349\n",
      "    epoch          : 1245\n",
      "    loss           : -1310.6034956247795\n",
      "Train Epoch: 1246 [512/60000 (1%)] Loss: -1220.203247\n",
      "Train Epoch: 1246 [11776/60000 (20%)] Loss: -1062.534668\n",
      "Train Epoch: 1246 [23040/60000 (38%)] Loss: -1441.504395\n",
      "Train Epoch: 1246 [34304/60000 (57%)] Loss: -1455.200439\n",
      "Train Epoch: 1246 [45568/60000 (76%)] Loss: -1511.671387\n",
      "Train Epoch: 1246 [56832/60000 (95%)] Loss: -1342.978027\n",
      "    epoch          : 1246\n",
      "    loss           : -1320.11706853317\n",
      "Train Epoch: 1247 [512/60000 (1%)] Loss: -1362.602539\n",
      "Train Epoch: 1247 [11776/60000 (20%)] Loss: -1332.855469\n",
      "Train Epoch: 1247 [23040/60000 (38%)] Loss: -1219.627686\n",
      "Train Epoch: 1247 [34304/60000 (57%)] Loss: -1310.530640\n",
      "Train Epoch: 1247 [45568/60000 (76%)] Loss: -1232.138428\n",
      "Train Epoch: 1247 [56832/60000 (95%)] Loss: -1116.059082\n",
      "    epoch          : 1247\n",
      "    loss           : -1325.82329667086\n",
      "Train Epoch: 1248 [512/60000 (1%)] Loss: -1322.906738\n",
      "Train Epoch: 1248 [11776/60000 (20%)] Loss: -1223.143921\n",
      "Train Epoch: 1248 [23040/60000 (38%)] Loss: -1344.415649\n",
      "Train Epoch: 1248 [34304/60000 (57%)] Loss: -1490.426758\n",
      "Train Epoch: 1248 [45568/60000 (76%)] Loss: -1324.142456\n",
      "Train Epoch: 1248 [56832/60000 (95%)] Loss: -1482.329346\n",
      "    epoch          : 1248\n",
      "    loss           : -1339.6083655061022\n",
      "Train Epoch: 1249 [512/60000 (1%)] Loss: -1312.099121\n",
      "Train Epoch: 1249 [11776/60000 (20%)] Loss: -1194.131104\n",
      "Train Epoch: 1249 [23040/60000 (38%)] Loss: -1459.435181\n",
      "Train Epoch: 1249 [34304/60000 (57%)] Loss: -1329.285889\n",
      "Train Epoch: 1249 [45568/60000 (76%)] Loss: -1247.582397\n",
      "Train Epoch: 1249 [56832/60000 (95%)] Loss: -1340.519165\n",
      "    epoch          : 1249\n",
      "    loss           : -1331.899457166424\n",
      "Train Epoch: 1250 [512/60000 (1%)] Loss: -1198.945557\n",
      "Train Epoch: 1250 [11776/60000 (20%)] Loss: -1377.748779\n",
      "Train Epoch: 1250 [23040/60000 (38%)] Loss: -1339.993286\n",
      "Train Epoch: 1250 [34304/60000 (57%)] Loss: -1322.107788\n",
      "Train Epoch: 1250 [45568/60000 (76%)] Loss: -1345.010742\n",
      "Train Epoch: 1250 [56832/60000 (95%)] Loss: -1211.154907\n",
      "    epoch          : 1250\n",
      "    loss           : -1315.2457777120298\n",
      "Train Epoch: 1251 [512/60000 (1%)] Loss: -1341.640137\n",
      "Train Epoch: 1251 [11776/60000 (20%)] Loss: -1321.451660\n",
      "Train Epoch: 1251 [23040/60000 (38%)] Loss: -1507.538696\n",
      "Train Epoch: 1251 [34304/60000 (57%)] Loss: -1346.024902\n",
      "Train Epoch: 1251 [45568/60000 (76%)] Loss: -1388.564453\n",
      "Train Epoch: 1251 [56832/60000 (95%)] Loss: -1381.016479\n",
      "    epoch          : 1251\n",
      "    loss           : -1330.884693210408\n",
      "Train Epoch: 1252 [512/60000 (1%)] Loss: -1206.223267\n",
      "Train Epoch: 1252 [11776/60000 (20%)] Loss: -1499.731567\n",
      "Train Epoch: 1252 [23040/60000 (38%)] Loss: -1300.280518\n",
      "Train Epoch: 1252 [34304/60000 (57%)] Loss: -1475.491211\n",
      "Train Epoch: 1252 [45568/60000 (76%)] Loss: -1485.165894\n",
      "Train Epoch: 1252 [56832/60000 (95%)] Loss: -1321.611938\n",
      "    epoch          : 1252\n",
      "    loss           : -1330.886236675715\n",
      "Train Epoch: 1253 [512/60000 (1%)] Loss: -1329.360718\n",
      "Train Epoch: 1253 [11776/60000 (20%)] Loss: -1200.230469\n",
      "Train Epoch: 1253 [23040/60000 (38%)] Loss: -1497.006592\n",
      "Train Epoch: 1253 [34304/60000 (57%)] Loss: -1337.407349\n",
      "Train Epoch: 1253 [45568/60000 (76%)] Loss: -1329.608765\n",
      "Train Epoch: 1253 [56832/60000 (95%)] Loss: -1202.019409\n",
      "    epoch          : 1253\n",
      "    loss           : -1325.361995373742\n",
      "Train Epoch: 1254 [512/60000 (1%)] Loss: -1211.733887\n",
      "Train Epoch: 1254 [11776/60000 (20%)] Loss: -1331.633057\n",
      "Train Epoch: 1254 [23040/60000 (38%)] Loss: -1449.783691\n",
      "Train Epoch: 1254 [34304/60000 (57%)] Loss: -1226.665771\n",
      "Train Epoch: 1254 [45568/60000 (76%)] Loss: -1479.199707\n",
      "Train Epoch: 1254 [56832/60000 (95%)] Loss: -1511.961548\n",
      "    epoch          : 1254\n",
      "    loss           : -1339.0290789415606\n",
      "Train Epoch: 1255 [512/60000 (1%)] Loss: -1394.074219\n",
      "Train Epoch: 1255 [11776/60000 (20%)] Loss: -1197.334839\n",
      "Train Epoch: 1255 [23040/60000 (38%)] Loss: -1475.324951\n",
      "Train Epoch: 1255 [34304/60000 (57%)] Loss: -1244.890625\n",
      "Train Epoch: 1255 [45568/60000 (76%)] Loss: -1398.406250\n",
      "Train Epoch: 1255 [56832/60000 (95%)] Loss: -1199.028320\n",
      "    epoch          : 1255\n",
      "    loss           : -1318.0562502758653\n",
      "Train Epoch: 1256 [512/60000 (1%)] Loss: -1369.545532\n",
      "Train Epoch: 1256 [11776/60000 (20%)] Loss: -1364.458374\n",
      "Train Epoch: 1256 [23040/60000 (38%)] Loss: -1362.498779\n",
      "Train Epoch: 1256 [34304/60000 (57%)] Loss: -1342.814819\n",
      "Train Epoch: 1256 [45568/60000 (76%)] Loss: -1499.294922\n",
      "Train Epoch: 1256 [56832/60000 (95%)] Loss: -1321.015137\n",
      "    epoch          : 1256\n",
      "    loss           : -1323.9983420506708\n",
      "Train Epoch: 1257 [512/60000 (1%)] Loss: -1387.406128\n",
      "Train Epoch: 1257 [11776/60000 (20%)] Loss: -1538.954590\n",
      "Train Epoch: 1257 [23040/60000 (38%)] Loss: -1205.533081\n",
      "Train Epoch: 1257 [34304/60000 (57%)] Loss: -1211.180420\n",
      "Train Epoch: 1257 [45568/60000 (76%)] Loss: -1220.634277\n",
      "Train Epoch: 1257 [56832/60000 (95%)] Loss: -1186.148682\n",
      "    epoch          : 1257\n",
      "    loss           : -1338.5300137794625\n",
      "Train Epoch: 1258 [512/60000 (1%)] Loss: -1040.188721\n",
      "Train Epoch: 1258 [11776/60000 (20%)] Loss: -1235.462891\n",
      "Train Epoch: 1258 [23040/60000 (38%)] Loss: -1215.207886\n",
      "Train Epoch: 1258 [34304/60000 (57%)] Loss: -1392.230347\n",
      "Train Epoch: 1258 [45568/60000 (76%)] Loss: -1365.732300\n",
      "Train Epoch: 1258 [56832/60000 (95%)] Loss: -1200.431396\n",
      "    epoch          : 1258\n",
      "    loss           : -1322.6518613308838\n",
      "Train Epoch: 1259 [512/60000 (1%)] Loss: -1207.229004\n",
      "Train Epoch: 1259 [11776/60000 (20%)] Loss: -1470.155640\n",
      "Train Epoch: 1259 [23040/60000 (38%)] Loss: -1232.741943\n",
      "Train Epoch: 1259 [34304/60000 (57%)] Loss: -1370.759766\n",
      "Train Epoch: 1259 [45568/60000 (76%)] Loss: -1182.964600\n",
      "Train Epoch: 1259 [56832/60000 (95%)] Loss: -1357.665771\n",
      "    epoch          : 1259\n",
      "    loss           : -1326.2866566113833\n",
      "Train Epoch: 1260 [512/60000 (1%)] Loss: -1182.961426\n",
      "Train Epoch: 1260 [11776/60000 (20%)] Loss: -1194.336426\n",
      "Train Epoch: 1260 [23040/60000 (38%)] Loss: -1479.329834\n",
      "Train Epoch: 1260 [34304/60000 (57%)] Loss: -1535.263062\n",
      "Train Epoch: 1260 [45568/60000 (76%)] Loss: -1102.230713\n",
      "Train Epoch: 1260 [56832/60000 (95%)] Loss: -1185.239014\n",
      "    epoch          : 1260\n",
      "    loss           : -1335.9066937980006\n",
      "Train Epoch: 1261 [512/60000 (1%)] Loss: -1438.539307\n",
      "Train Epoch: 1261 [11776/60000 (20%)] Loss: -1333.686157\n",
      "Train Epoch: 1261 [23040/60000 (38%)] Loss: -1346.406494\n",
      "Train Epoch: 1261 [34304/60000 (57%)] Loss: -1216.511719\n",
      "Train Epoch: 1261 [45568/60000 (76%)] Loss: -1210.950684\n",
      "Train Epoch: 1261 [56832/60000 (95%)] Loss: -1493.827759\n",
      "    epoch          : 1261\n",
      "    loss           : -1334.0639579471222\n",
      "Train Epoch: 1262 [512/60000 (1%)] Loss: -889.851196\n",
      "Train Epoch: 1262 [11776/60000 (20%)] Loss: -1519.911621\n",
      "Train Epoch: 1262 [23040/60000 (38%)] Loss: -1351.512817\n",
      "Train Epoch: 1262 [34304/60000 (57%)] Loss: -1354.877563\n",
      "Train Epoch: 1262 [45568/60000 (76%)] Loss: -1213.534668\n",
      "Train Epoch: 1262 [56832/60000 (95%)] Loss: -1330.218750\n",
      "    epoch          : 1262\n",
      "    loss           : -1311.528851697674\n",
      "Train Epoch: 1263 [512/60000 (1%)] Loss: -1185.503784\n",
      "Train Epoch: 1263 [11776/60000 (20%)] Loss: -1187.833984\n",
      "Train Epoch: 1263 [23040/60000 (38%)] Loss: -1476.767456\n",
      "Train Epoch: 1263 [34304/60000 (57%)] Loss: -1479.993652\n",
      "Train Epoch: 1263 [45568/60000 (76%)] Loss: -1368.909058\n",
      "Train Epoch: 1263 [56832/60000 (95%)] Loss: -1335.269653\n",
      "    epoch          : 1263\n",
      "    loss           : -1342.2844638285665\n",
      "Train Epoch: 1264 [512/60000 (1%)] Loss: -1475.210693\n",
      "Train Epoch: 1264 [11776/60000 (20%)] Loss: -955.089172\n",
      "Train Epoch: 1264 [23040/60000 (38%)] Loss: -1233.868286\n",
      "Train Epoch: 1264 [34304/60000 (57%)] Loss: -1327.942627\n",
      "Train Epoch: 1264 [45568/60000 (76%)] Loss: -1378.302368\n",
      "Train Epoch: 1264 [56832/60000 (95%)] Loss: -1337.087280\n",
      "    epoch          : 1264\n",
      "    loss           : -1322.844978117\n",
      "Train Epoch: 1265 [512/60000 (1%)] Loss: -1205.600830\n",
      "Train Epoch: 1265 [11776/60000 (20%)] Loss: -1506.654907\n",
      "Train Epoch: 1265 [23040/60000 (38%)] Loss: -1358.790039\n",
      "Train Epoch: 1265 [34304/60000 (57%)] Loss: -1353.201538\n",
      "Train Epoch: 1265 [45568/60000 (76%)] Loss: -1488.942017\n",
      "Train Epoch: 1265 [56832/60000 (95%)] Loss: -1356.726685\n",
      "    epoch          : 1265\n",
      "    loss           : -1348.791156661039\n",
      "Train Epoch: 1266 [512/60000 (1%)] Loss: -1353.816528\n",
      "Train Epoch: 1266 [11776/60000 (20%)] Loss: -1199.814331\n",
      "Train Epoch: 1266 [23040/60000 (38%)] Loss: -1298.014282\n",
      "Train Epoch: 1266 [34304/60000 (57%)] Loss: -1201.520264\n",
      "Train Epoch: 1266 [45568/60000 (76%)] Loss: -1381.817383\n",
      "Train Epoch: 1266 [56832/60000 (95%)] Loss: -1352.391235\n",
      "    epoch          : 1266\n",
      "    loss           : -1336.3137951867054\n",
      "Train Epoch: 1267 [512/60000 (1%)] Loss: -1359.660645\n",
      "Train Epoch: 1267 [11776/60000 (20%)] Loss: -1506.349487\n",
      "Train Epoch: 1267 [23040/60000 (38%)] Loss: -1369.941406\n",
      "Train Epoch: 1267 [34304/60000 (57%)] Loss: -1373.161987\n",
      "Train Epoch: 1267 [45568/60000 (76%)] Loss: -1192.813354\n",
      "Train Epoch: 1267 [56832/60000 (95%)] Loss: -1375.092773\n",
      "    epoch          : 1267\n",
      "    loss           : -1325.862177789548\n",
      "Train Epoch: 1268 [512/60000 (1%)] Loss: -1387.451050\n",
      "Train Epoch: 1268 [11776/60000 (20%)] Loss: -1356.542114\n",
      "Train Epoch: 1268 [23040/60000 (38%)] Loss: -1073.890869\n",
      "Train Epoch: 1268 [34304/60000 (57%)] Loss: -1368.033691\n",
      "Train Epoch: 1268 [45568/60000 (76%)] Loss: -1217.787354\n",
      "Train Epoch: 1268 [56832/60000 (95%)] Loss: -1312.480591\n",
      "    epoch          : 1268\n",
      "    loss           : -1339.1669987392963\n",
      "Train Epoch: 1269 [512/60000 (1%)] Loss: -1256.423950\n",
      "Train Epoch: 1269 [11776/60000 (20%)] Loss: -1225.397949\n",
      "Train Epoch: 1269 [23040/60000 (38%)] Loss: -1393.742676\n",
      "Train Epoch: 1269 [34304/60000 (57%)] Loss: -1211.818359\n",
      "Train Epoch: 1269 [45568/60000 (76%)] Loss: -1047.760254\n",
      "Train Epoch: 1269 [56832/60000 (95%)] Loss: -1183.348633\n",
      "    epoch          : 1269\n",
      "    loss           : -1321.7820393190545\n",
      "Train Epoch: 1270 [512/60000 (1%)] Loss: -1342.528442\n",
      "Train Epoch: 1270 [11776/60000 (20%)] Loss: -1467.817505\n",
      "Train Epoch: 1270 [23040/60000 (38%)] Loss: -1489.110352\n",
      "Train Epoch: 1270 [34304/60000 (57%)] Loss: -1503.554443\n",
      "Train Epoch: 1270 [45568/60000 (76%)] Loss: -1056.506958\n",
      "Train Epoch: 1270 [56832/60000 (95%)] Loss: -1336.099365\n",
      "    epoch          : 1270\n",
      "    loss           : -1319.1286996959966\n",
      "Train Epoch: 1271 [512/60000 (1%)] Loss: -1224.334106\n",
      "Train Epoch: 1271 [11776/60000 (20%)] Loss: -1313.859009\n",
      "Train Epoch: 1271 [23040/60000 (38%)] Loss: -1184.112183\n",
      "Train Epoch: 1271 [34304/60000 (57%)] Loss: -1509.461670\n",
      "Train Epoch: 1271 [45568/60000 (76%)] Loss: -1347.084595\n",
      "Train Epoch: 1271 [56832/60000 (95%)] Loss: -1497.824951\n",
      "    epoch          : 1271\n",
      "    loss           : -1323.9145214705818\n",
      "Train Epoch: 1272 [512/60000 (1%)] Loss: -1498.542358\n",
      "Train Epoch: 1272 [11776/60000 (20%)] Loss: -1488.230957\n",
      "Train Epoch: 1272 [23040/60000 (38%)] Loss: -1396.716064\n",
      "Train Epoch: 1272 [34304/60000 (57%)] Loss: -1229.062988\n",
      "Train Epoch: 1272 [45568/60000 (76%)] Loss: -1360.200195\n",
      "Train Epoch: 1272 [56832/60000 (95%)] Loss: -1169.689697\n",
      "    epoch          : 1272\n",
      "    loss           : -1336.6295431535798\n",
      "Train Epoch: 1273 [512/60000 (1%)] Loss: -1213.198730\n",
      "Train Epoch: 1273 [11776/60000 (20%)] Loss: -1352.582764\n",
      "Train Epoch: 1273 [23040/60000 (38%)] Loss: -1067.916748\n",
      "Train Epoch: 1273 [34304/60000 (57%)] Loss: -1207.164307\n",
      "Train Epoch: 1273 [45568/60000 (76%)] Loss: -1522.718384\n",
      "Train Epoch: 1273 [56832/60000 (95%)] Loss: -1366.805298\n",
      "    epoch          : 1273\n",
      "    loss           : -1356.3188355871512\n",
      "Train Epoch: 1274 [512/60000 (1%)] Loss: -1180.372559\n",
      "Train Epoch: 1274 [11776/60000 (20%)] Loss: -1198.217041\n",
      "Train Epoch: 1274 [23040/60000 (38%)] Loss: -1208.103638\n",
      "Train Epoch: 1274 [34304/60000 (57%)] Loss: -1325.218262\n",
      "Train Epoch: 1274 [45568/60000 (76%)] Loss: -1359.760498\n",
      "Train Epoch: 1274 [56832/60000 (95%)] Loss: -1353.407227\n",
      "    epoch          : 1274\n",
      "    loss           : -1313.642489848164\n",
      "Train Epoch: 1275 [512/60000 (1%)] Loss: -1493.098389\n",
      "Train Epoch: 1275 [11776/60000 (20%)] Loss: -1364.908081\n",
      "Train Epoch: 1275 [23040/60000 (38%)] Loss: -1227.010376\n",
      "Train Epoch: 1275 [34304/60000 (57%)] Loss: -1354.850342\n",
      "Train Epoch: 1275 [45568/60000 (76%)] Loss: -1490.168579\n",
      "Train Epoch: 1275 [56832/60000 (95%)] Loss: -1502.213257\n",
      "    epoch          : 1275\n",
      "    loss           : -1319.8885135973915\n",
      "Train Epoch: 1276 [512/60000 (1%)] Loss: -1342.907104\n",
      "Train Epoch: 1276 [11776/60000 (20%)] Loss: -1322.464722\n",
      "Train Epoch: 1276 [23040/60000 (38%)] Loss: -1306.421997\n",
      "Train Epoch: 1276 [34304/60000 (57%)] Loss: -1347.365479\n",
      "Train Epoch: 1276 [45568/60000 (76%)] Loss: -1030.033691\n",
      "Train Epoch: 1276 [56832/60000 (95%)] Loss: -1306.575195\n",
      "    epoch          : 1276\n",
      "    loss           : -1338.6221430719236\n",
      "Train Epoch: 1277 [512/60000 (1%)] Loss: -1221.026489\n",
      "Train Epoch: 1277 [11776/60000 (20%)] Loss: -1185.158813\n",
      "Train Epoch: 1277 [23040/60000 (38%)] Loss: -1453.377563\n",
      "Train Epoch: 1277 [34304/60000 (57%)] Loss: -1376.227295\n",
      "Train Epoch: 1277 [45568/60000 (76%)] Loss: -1202.285889\n",
      "Train Epoch: 1277 [56832/60000 (95%)] Loss: -1353.226929\n",
      "    epoch          : 1277\n",
      "    loss           : -1329.3345605882548\n",
      "Train Epoch: 1278 [512/60000 (1%)] Loss: -1073.880615\n",
      "Train Epoch: 1278 [11776/60000 (20%)] Loss: -1367.108032\n",
      "Train Epoch: 1278 [23040/60000 (38%)] Loss: -1060.370605\n",
      "Train Epoch: 1278 [34304/60000 (57%)] Loss: -1389.077393\n",
      "Train Epoch: 1278 [45568/60000 (76%)] Loss: -1056.843018\n",
      "Train Epoch: 1278 [56832/60000 (95%)] Loss: -1317.658203\n",
      "    epoch          : 1278\n",
      "    loss           : -1314.7612087443724\n",
      "Train Epoch: 1279 [512/60000 (1%)] Loss: -1225.947510\n",
      "Train Epoch: 1279 [11776/60000 (20%)] Loss: -1345.414185\n",
      "Train Epoch: 1279 [23040/60000 (38%)] Loss: -1170.858887\n",
      "Train Epoch: 1279 [34304/60000 (57%)] Loss: -1475.260498\n",
      "Train Epoch: 1279 [45568/60000 (76%)] Loss: -1362.458496\n",
      "Train Epoch: 1279 [56832/60000 (95%)] Loss: -1342.611816\n",
      "    epoch          : 1279\n",
      "    loss           : -1353.7347998322741\n",
      "Train Epoch: 1280 [512/60000 (1%)] Loss: -1366.021484\n",
      "Train Epoch: 1280 [11776/60000 (20%)] Loss: -1359.697754\n",
      "Train Epoch: 1280 [23040/60000 (38%)] Loss: -1460.699829\n",
      "Train Epoch: 1280 [34304/60000 (57%)] Loss: -1218.977661\n",
      "Train Epoch: 1280 [45568/60000 (76%)] Loss: -1178.299805\n",
      "Train Epoch: 1280 [56832/60000 (95%)] Loss: -1355.597412\n",
      "    epoch          : 1280\n",
      "    loss           : -1330.5704293978417\n",
      "Train Epoch: 1281 [512/60000 (1%)] Loss: -1244.160645\n",
      "Train Epoch: 1281 [11776/60000 (20%)] Loss: -1091.443359\n",
      "Train Epoch: 1281 [23040/60000 (38%)] Loss: -1075.025146\n",
      "Train Epoch: 1281 [34304/60000 (57%)] Loss: -1357.817139\n",
      "Train Epoch: 1281 [45568/60000 (76%)] Loss: -1195.728394\n",
      "Train Epoch: 1281 [56832/60000 (95%)] Loss: -1312.885986\n",
      "    epoch          : 1281\n",
      "    loss           : -1340.1369018554688\n",
      "Train Epoch: 1282 [512/60000 (1%)] Loss: -1359.025269\n",
      "Train Epoch: 1282 [11776/60000 (20%)] Loss: -1218.156860\n",
      "Train Epoch: 1282 [23040/60000 (38%)] Loss: -1352.065796\n",
      "Train Epoch: 1282 [34304/60000 (57%)] Loss: -1225.134521\n",
      "Train Epoch: 1282 [45568/60000 (76%)] Loss: -1212.797241\n",
      "Train Epoch: 1282 [56832/60000 (95%)] Loss: -1361.594971\n",
      "    epoch          : 1282\n",
      "    loss           : -1338.1693516962946\n",
      "Train Epoch: 1283 [512/60000 (1%)] Loss: -1384.125244\n",
      "Train Epoch: 1283 [11776/60000 (20%)] Loss: -1062.126221\n",
      "Train Epoch: 1283 [23040/60000 (38%)] Loss: -1208.560669\n",
      "Train Epoch: 1283 [34304/60000 (57%)] Loss: -1376.022217\n",
      "Train Epoch: 1283 [45568/60000 (76%)] Loss: -1486.777466\n",
      "Train Epoch: 1283 [56832/60000 (95%)] Loss: -1543.166504\n",
      "    epoch          : 1283\n",
      "    loss           : -1335.000621386167\n",
      "Train Epoch: 1284 [512/60000 (1%)] Loss: -1493.741455\n",
      "Train Epoch: 1284 [11776/60000 (20%)] Loss: -1351.347412\n",
      "Train Epoch: 1284 [23040/60000 (38%)] Loss: -1348.483154\n",
      "Train Epoch: 1284 [34304/60000 (57%)] Loss: -1341.182251\n",
      "Train Epoch: 1284 [45568/60000 (76%)] Loss: -1087.653320\n",
      "Train Epoch: 1284 [56832/60000 (95%)] Loss: -1335.035522\n",
      "    epoch          : 1284\n",
      "    loss           : -1338.836694404904\n",
      "Train Epoch: 1285 [512/60000 (1%)] Loss: -1453.214844\n",
      "Train Epoch: 1285 [11776/60000 (20%)] Loss: -1342.384644\n",
      "Train Epoch: 1285 [23040/60000 (38%)] Loss: -1226.170166\n",
      "Train Epoch: 1285 [34304/60000 (57%)] Loss: -1499.708008\n",
      "Train Epoch: 1285 [45568/60000 (76%)] Loss: -1482.322144\n",
      "Train Epoch: 1285 [56832/60000 (95%)] Loss: -1500.719971\n",
      "    epoch          : 1285\n",
      "    loss           : -1348.700713594081\n",
      "Train Epoch: 1286 [512/60000 (1%)] Loss: -1482.837524\n",
      "Train Epoch: 1286 [11776/60000 (20%)] Loss: -1203.601440\n",
      "Train Epoch: 1286 [23040/60000 (38%)] Loss: -1330.947144\n",
      "Train Epoch: 1286 [34304/60000 (57%)] Loss: -1361.454102\n",
      "Train Epoch: 1286 [45568/60000 (76%)] Loss: -1207.834961\n",
      "Train Epoch: 1286 [56832/60000 (95%)] Loss: -1497.897461\n",
      "    epoch          : 1286\n",
      "    loss           : -1343.4043872208244\n",
      "Train Epoch: 1287 [512/60000 (1%)] Loss: -1329.526245\n",
      "Train Epoch: 1287 [11776/60000 (20%)] Loss: -1512.231079\n",
      "Train Epoch: 1287 [23040/60000 (38%)] Loss: -1482.522217\n",
      "Train Epoch: 1287 [34304/60000 (57%)] Loss: -1482.950684\n",
      "Train Epoch: 1287 [45568/60000 (76%)] Loss: -1183.724365\n",
      "Train Epoch: 1287 [56832/60000 (95%)] Loss: -1364.248901\n",
      "    epoch          : 1287\n",
      "    loss           : -1323.9156356208068\n",
      "Train Epoch: 1288 [512/60000 (1%)] Loss: -1154.853638\n",
      "Train Epoch: 1288 [11776/60000 (20%)] Loss: -1346.586426\n",
      "Train Epoch: 1288 [23040/60000 (38%)] Loss: -1474.904785\n",
      "Train Epoch: 1288 [34304/60000 (57%)] Loss: -1520.474609\n",
      "Train Epoch: 1288 [45568/60000 (76%)] Loss: -1228.281982\n",
      "Train Epoch: 1288 [56832/60000 (95%)] Loss: -1397.364624\n",
      "    epoch          : 1288\n",
      "    loss           : -1353.3319609043963\n",
      "Train Epoch: 1289 [512/60000 (1%)] Loss: -1208.319580\n",
      "Train Epoch: 1289 [11776/60000 (20%)] Loss: -1066.058594\n",
      "Train Epoch: 1289 [23040/60000 (38%)] Loss: -1357.510010\n",
      "Train Epoch: 1289 [34304/60000 (57%)] Loss: -1496.619629\n",
      "Train Epoch: 1289 [45568/60000 (76%)] Loss: -1200.558716\n",
      "Train Epoch: 1289 [56832/60000 (95%)] Loss: -1321.727173\n",
      "    epoch          : 1289\n",
      "    loss           : -1329.3542401157529\n",
      "Train Epoch: 1290 [512/60000 (1%)] Loss: -1529.849609\n",
      "Train Epoch: 1290 [11776/60000 (20%)] Loss: -1181.586914\n",
      "Train Epoch: 1290 [23040/60000 (38%)] Loss: -1352.251465\n",
      "Train Epoch: 1290 [34304/60000 (57%)] Loss: -1215.212036\n",
      "Train Epoch: 1290 [45568/60000 (76%)] Loss: -1502.223755\n",
      "Train Epoch: 1290 [56832/60000 (95%)] Loss: -1355.685059\n",
      "    epoch          : 1290\n",
      "    loss           : -1347.1581765729827\n",
      "Train Epoch: 1291 [512/60000 (1%)] Loss: -1334.019775\n",
      "Train Epoch: 1291 [11776/60000 (20%)] Loss: -1474.108154\n",
      "Train Epoch: 1291 [23040/60000 (38%)] Loss: -1363.161743\n",
      "Train Epoch: 1291 [34304/60000 (57%)] Loss: -1372.964600\n",
      "Train Epoch: 1291 [45568/60000 (76%)] Loss: -1325.392334\n",
      "Train Epoch: 1291 [56832/60000 (95%)] Loss: -1343.909302\n",
      "    epoch          : 1291\n",
      "    loss           : -1354.4088865808176\n",
      "Train Epoch: 1292 [512/60000 (1%)] Loss: -1336.629639\n",
      "Train Epoch: 1292 [11776/60000 (20%)] Loss: -1321.164062\n",
      "Train Epoch: 1292 [23040/60000 (38%)] Loss: -1478.838867\n",
      "Train Epoch: 1292 [34304/60000 (57%)] Loss: -1229.378418\n",
      "Train Epoch: 1292 [45568/60000 (76%)] Loss: -1328.461670\n",
      "Train Epoch: 1292 [56832/60000 (95%)] Loss: -1499.971802\n",
      "    epoch          : 1292\n",
      "    loss           : -1347.9263509114585\n",
      "Train Epoch: 1293 [512/60000 (1%)] Loss: -1342.303223\n",
      "Train Epoch: 1293 [11776/60000 (20%)] Loss: -1321.292358\n",
      "Train Epoch: 1293 [23040/60000 (38%)] Loss: -1220.794067\n",
      "Train Epoch: 1293 [34304/60000 (57%)] Loss: -1194.437134\n",
      "Train Epoch: 1293 [45568/60000 (76%)] Loss: -1489.761475\n",
      "Train Epoch: 1293 [56832/60000 (95%)] Loss: -1380.247192\n",
      "    epoch          : 1293\n",
      "    loss           : -1330.1884486311574\n",
      "Train Epoch: 1294 [512/60000 (1%)] Loss: -1327.926758\n",
      "Train Epoch: 1294 [11776/60000 (20%)] Loss: -1503.590454\n",
      "Train Epoch: 1294 [23040/60000 (38%)] Loss: -1223.064697\n",
      "Train Epoch: 1294 [34304/60000 (57%)] Loss: -1339.858032\n",
      "Train Epoch: 1294 [45568/60000 (76%)] Loss: -1041.052002\n",
      "Train Epoch: 1294 [56832/60000 (95%)] Loss: -1504.023926\n",
      "    epoch          : 1294\n",
      "    loss           : -1331.6190723483846\n",
      "Train Epoch: 1295 [512/60000 (1%)] Loss: -1486.892334\n",
      "Train Epoch: 1295 [11776/60000 (20%)] Loss: -1382.691162\n",
      "Train Epoch: 1295 [23040/60000 (38%)] Loss: -1338.854980\n",
      "Train Epoch: 1295 [34304/60000 (57%)] Loss: -1375.908813\n",
      "Train Epoch: 1295 [45568/60000 (76%)] Loss: -1339.574463\n",
      "Train Epoch: 1295 [56832/60000 (95%)] Loss: -1398.877441\n",
      "    epoch          : 1295\n",
      "    loss           : -1336.8831380208335\n",
      "Train Epoch: 1296 [512/60000 (1%)] Loss: -1362.434448\n",
      "Train Epoch: 1296 [11776/60000 (20%)] Loss: -1220.859985\n",
      "Train Epoch: 1296 [23040/60000 (38%)] Loss: -1336.625488\n",
      "Train Epoch: 1296 [34304/60000 (57%)] Loss: -1502.584106\n",
      "Train Epoch: 1296 [45568/60000 (76%)] Loss: -1500.215088\n",
      "Train Epoch: 1296 [56832/60000 (95%)] Loss: -1341.645264\n",
      "    epoch          : 1296\n",
      "    loss           : -1335.1825880492474\n",
      "Train Epoch: 1297 [512/60000 (1%)] Loss: -1348.042358\n",
      "Train Epoch: 1297 [11776/60000 (20%)] Loss: -1378.929932\n",
      "Train Epoch: 1297 [23040/60000 (38%)] Loss: -1204.605713\n",
      "Train Epoch: 1297 [34304/60000 (57%)] Loss: -1375.828857\n",
      "Train Epoch: 1297 [45568/60000 (76%)] Loss: -1181.703491\n",
      "Train Epoch: 1297 [56832/60000 (95%)] Loss: -1371.672241\n",
      "    epoch          : 1297\n",
      "    loss           : -1349.694908702441\n",
      "Train Epoch: 1298 [512/60000 (1%)] Loss: -1325.203491\n",
      "Train Epoch: 1298 [11776/60000 (20%)] Loss: -1513.647705\n",
      "Train Epoch: 1298 [23040/60000 (38%)] Loss: -1365.561279\n",
      "Train Epoch: 1298 [34304/60000 (57%)] Loss: -1345.136597\n",
      "Train Epoch: 1298 [45568/60000 (76%)] Loss: -1389.734863\n",
      "Train Epoch: 1298 [56832/60000 (95%)] Loss: -1350.386597\n",
      "    epoch          : 1298\n",
      "    loss           : -1337.6905500336554\n",
      "Train Epoch: 1299 [512/60000 (1%)] Loss: -1228.033081\n",
      "Train Epoch: 1299 [11776/60000 (20%)] Loss: -1391.679932\n",
      "Train Epoch: 1299 [23040/60000 (38%)] Loss: -1342.914795\n",
      "Train Epoch: 1299 [34304/60000 (57%)] Loss: -1227.707520\n",
      "Train Epoch: 1299 [45568/60000 (76%)] Loss: -1505.468872\n",
      "Train Epoch: 1299 [56832/60000 (95%)] Loss: -1210.751953\n",
      "    epoch          : 1299\n",
      "    loss           : -1335.0464253398657\n",
      "Train Epoch: 1300 [512/60000 (1%)] Loss: -1396.189331\n",
      "Train Epoch: 1300 [11776/60000 (20%)] Loss: -1356.052856\n",
      "Train Epoch: 1300 [23040/60000 (38%)] Loss: -1341.529907\n",
      "Train Epoch: 1300 [34304/60000 (57%)] Loss: -1221.813721\n",
      "Train Epoch: 1300 [45568/60000 (76%)] Loss: -1501.261353\n",
      "Train Epoch: 1300 [56832/60000 (95%)] Loss: -1239.814697\n",
      "    epoch          : 1300\n",
      "    loss           : -1322.502021056784\n",
      "Saving checkpoint: saved/models/Mnist_DeepGenerativeOperad/0127_111843/checkpoint-epoch1300.pth ...\n",
      "Train Epoch: 1301 [512/60000 (1%)] Loss: -1195.405273\n",
      "Train Epoch: 1301 [11776/60000 (20%)] Loss: -1342.395752\n",
      "Train Epoch: 1301 [23040/60000 (38%)] Loss: -1235.927490\n",
      "Train Epoch: 1301 [34304/60000 (57%)] Loss: -1315.599243\n",
      "Train Epoch: 1301 [45568/60000 (76%)] Loss: -1342.662109\n",
      "Train Epoch: 1301 [56832/60000 (95%)] Loss: -1362.830200\n",
      "    epoch          : 1301\n",
      "    loss           : -1369.0043148751986\n",
      "Train Epoch: 1302 [512/60000 (1%)] Loss: -1338.219727\n",
      "Train Epoch: 1302 [11776/60000 (20%)] Loss: -1341.586426\n",
      "Train Epoch: 1302 [23040/60000 (38%)] Loss: -1241.013550\n",
      "Train Epoch: 1302 [34304/60000 (57%)] Loss: -1464.810181\n",
      "Train Epoch: 1302 [45568/60000 (76%)] Loss: -1480.615845\n",
      "Train Epoch: 1302 [56832/60000 (95%)] Loss: -1383.653076\n",
      "    epoch          : 1302\n",
      "    loss           : -1326.6342107912915\n",
      "Train Epoch: 1303 [512/60000 (1%)] Loss: -1227.999268\n",
      "Train Epoch: 1303 [11776/60000 (20%)] Loss: -1224.210205\n",
      "Train Epoch: 1303 [23040/60000 (38%)] Loss: -1230.613037\n",
      "Train Epoch: 1303 [34304/60000 (57%)] Loss: -1333.250244\n",
      "Train Epoch: 1303 [45568/60000 (76%)] Loss: -1500.694458\n",
      "Train Epoch: 1303 [56832/60000 (95%)] Loss: -1372.870483\n",
      "    epoch          : 1303\n",
      "    loss           : -1311.8793603929423\n",
      "Train Epoch: 1304 [512/60000 (1%)] Loss: -1033.441528\n",
      "Train Epoch: 1304 [11776/60000 (20%)] Loss: -1356.252686\n",
      "Train Epoch: 1304 [23040/60000 (38%)] Loss: -1497.668945\n",
      "Train Epoch: 1304 [34304/60000 (57%)] Loss: -1070.005981\n",
      "Train Epoch: 1304 [45568/60000 (76%)] Loss: -1440.034180\n",
      "Train Epoch: 1304 [56832/60000 (95%)] Loss: -1198.903564\n",
      "    epoch          : 1304\n",
      "    loss           : -1332.5443829035355\n",
      "Train Epoch: 1305 [512/60000 (1%)] Loss: -1339.551270\n",
      "Train Epoch: 1305 [11776/60000 (20%)] Loss: -1210.250000\n",
      "Train Epoch: 1305 [23040/60000 (38%)] Loss: -1485.808960\n",
      "Train Epoch: 1305 [34304/60000 (57%)] Loss: -1470.212524\n",
      "Train Epoch: 1305 [45568/60000 (76%)] Loss: -1476.762085\n",
      "Train Epoch: 1305 [56832/60000 (95%)] Loss: -1486.067871\n",
      "    epoch          : 1305\n",
      "    loss           : -1324.1676978849423\n",
      "Train Epoch: 1306 [512/60000 (1%)] Loss: -1531.675903\n",
      "Train Epoch: 1306 [11776/60000 (20%)] Loss: -1356.338989\n",
      "Train Epoch: 1306 [23040/60000 (38%)] Loss: -1328.657471\n",
      "Train Epoch: 1306 [34304/60000 (57%)] Loss: -1175.853760\n",
      "Train Epoch: 1306 [45568/60000 (76%)] Loss: -1362.558350\n",
      "Train Epoch: 1306 [56832/60000 (95%)] Loss: -1323.722290\n",
      "    epoch          : 1306\n",
      "    loss           : -1338.369963737531\n",
      "Train Epoch: 1307 [512/60000 (1%)] Loss: -1532.264893\n",
      "Train Epoch: 1307 [11776/60000 (20%)] Loss: -1238.673584\n",
      "Train Epoch: 1307 [23040/60000 (38%)] Loss: -1375.491577\n",
      "Train Epoch: 1307 [34304/60000 (57%)] Loss: -1084.856079\n",
      "Train Epoch: 1307 [45568/60000 (76%)] Loss: -1333.152710\n",
      "Train Epoch: 1307 [56832/60000 (95%)] Loss: -1368.990234\n",
      "    epoch          : 1307\n",
      "    loss           : -1323.150719766563\n",
      "Train Epoch: 1308 [512/60000 (1%)] Loss: -1356.893311\n",
      "Train Epoch: 1308 [11776/60000 (20%)] Loss: -1342.778076\n",
      "Train Epoch: 1308 [23040/60000 (38%)] Loss: -1517.982422\n",
      "Train Epoch: 1308 [34304/60000 (57%)] Loss: -1198.298584\n",
      "Train Epoch: 1308 [45568/60000 (76%)] Loss: -1330.361938\n",
      "Train Epoch: 1308 [56832/60000 (95%)] Loss: -1366.723145\n",
      "    epoch          : 1308\n",
      "    loss           : -1340.9308597543147\n",
      "Train Epoch: 1309 [512/60000 (1%)] Loss: -1335.024536\n",
      "Train Epoch: 1309 [11776/60000 (20%)] Loss: -1393.201660\n",
      "Train Epoch: 1309 [23040/60000 (38%)] Loss: -1494.286865\n",
      "Train Epoch: 1309 [34304/60000 (57%)] Loss: -1475.966187\n",
      "Train Epoch: 1309 [45568/60000 (76%)] Loss: -1519.629761\n",
      "Train Epoch: 1309 [56832/60000 (95%)] Loss: -1348.813721\n",
      "    epoch          : 1309\n",
      "    loss           : -1336.6977095954162\n",
      "Train Epoch: 1310 [512/60000 (1%)] Loss: -1496.602783\n",
      "Train Epoch: 1310 [11776/60000 (20%)] Loss: -1370.656494\n",
      "Train Epoch: 1310 [23040/60000 (38%)] Loss: -1500.529785\n",
      "Train Epoch: 1310 [34304/60000 (57%)] Loss: -1361.427368\n",
      "Train Epoch: 1310 [45568/60000 (76%)] Loss: -1519.805298\n",
      "Train Epoch: 1310 [56832/60000 (95%)] Loss: -1208.656494\n",
      "    epoch          : 1310\n",
      "    loss           : -1338.964081327794\n",
      "Train Epoch: 1311 [512/60000 (1%)] Loss: -1188.451050\n",
      "Train Epoch: 1311 [11776/60000 (20%)] Loss: -1194.999023\n",
      "Train Epoch: 1311 [23040/60000 (38%)] Loss: -1190.803833\n",
      "Train Epoch: 1311 [34304/60000 (57%)] Loss: -1363.518311\n",
      "Train Epoch: 1311 [45568/60000 (76%)] Loss: -1185.427734\n",
      "Train Epoch: 1311 [56832/60000 (95%)] Loss: -1070.189087\n",
      "    epoch          : 1311\n",
      "    loss           : -1326.7805541302523\n",
      "Train Epoch: 1312 [512/60000 (1%)] Loss: -1473.454468\n",
      "Train Epoch: 1312 [11776/60000 (20%)] Loss: -1371.137573\n",
      "Train Epoch: 1312 [23040/60000 (38%)] Loss: -1506.113525\n",
      "Train Epoch: 1312 [34304/60000 (57%)] Loss: -1339.799316\n",
      "Train Epoch: 1312 [45568/60000 (76%)] Loss: -1332.686768\n",
      "Train Epoch: 1312 [56832/60000 (95%)] Loss: -1220.117310\n",
      "    epoch          : 1312\n",
      "    loss           : -1349.476115598517\n",
      "Train Epoch: 1313 [512/60000 (1%)] Loss: -1363.684082\n",
      "Train Epoch: 1313 [11776/60000 (20%)] Loss: -1396.558838\n",
      "Train Epoch: 1313 [23040/60000 (38%)] Loss: -1467.193115\n",
      "Train Epoch: 1313 [34304/60000 (57%)] Loss: -1174.160889\n",
      "Train Epoch: 1313 [45568/60000 (76%)] Loss: -1218.080811\n",
      "Train Epoch: 1313 [56832/60000 (95%)] Loss: -1195.435425\n",
      "    epoch          : 1313\n",
      "    loss           : -1330.3667016325696\n",
      "Train Epoch: 1314 [512/60000 (1%)] Loss: -1478.356201\n",
      "Train Epoch: 1314 [11776/60000 (20%)] Loss: -1348.572144\n",
      "Train Epoch: 1314 [23040/60000 (38%)] Loss: -1480.369873\n",
      "Train Epoch: 1314 [34304/60000 (57%)] Loss: -1512.041992\n",
      "Train Epoch: 1314 [45568/60000 (76%)] Loss: -1334.146484\n",
      "Train Epoch: 1314 [56832/60000 (95%)] Loss: -1230.034912\n",
      "    epoch          : 1314\n",
      "    loss           : -1325.7507882845605\n",
      "Train Epoch: 1315 [512/60000 (1%)] Loss: -1346.017090\n",
      "Train Epoch: 1315 [11776/60000 (20%)] Loss: -1376.483521\n",
      "Train Epoch: 1315 [23040/60000 (38%)] Loss: -1501.847290\n",
      "Train Epoch: 1315 [34304/60000 (57%)] Loss: -1380.184692\n",
      "Train Epoch: 1315 [45568/60000 (76%)] Loss: -1449.789673\n",
      "Train Epoch: 1315 [56832/60000 (95%)] Loss: -1208.336182\n",
      "    epoch          : 1315\n",
      "    loss           : -1345.4430709235412\n",
      "Train Epoch: 1316 [512/60000 (1%)] Loss: -1235.673340\n",
      "Train Epoch: 1316 [11776/60000 (20%)] Loss: -1354.098267\n",
      "Train Epoch: 1316 [23040/60000 (38%)] Loss: -1340.072021\n",
      "Train Epoch: 1316 [34304/60000 (57%)] Loss: -1493.350464\n",
      "Train Epoch: 1316 [45568/60000 (76%)] Loss: -1240.721436\n",
      "Train Epoch: 1316 [56832/60000 (95%)] Loss: -1331.829956\n",
      "    epoch          : 1316\n",
      "    loss           : -1337.9013499459304\n",
      "Train Epoch: 1317 [512/60000 (1%)] Loss: -1499.514893\n",
      "Train Epoch: 1317 [11776/60000 (20%)] Loss: -1193.313354\n",
      "Train Epoch: 1317 [23040/60000 (38%)] Loss: -1322.427246\n",
      "Train Epoch: 1317 [34304/60000 (57%)] Loss: -1349.228149\n",
      "Train Epoch: 1317 [45568/60000 (76%)] Loss: -908.851196\n",
      "Train Epoch: 1317 [56832/60000 (95%)] Loss: -1375.826660\n",
      "    epoch          : 1317\n",
      "    loss           : -1331.6407653463764\n",
      "Train Epoch: 1318 [512/60000 (1%)] Loss: -1371.291260\n",
      "Train Epoch: 1318 [11776/60000 (20%)] Loss: -1367.707642\n",
      "Train Epoch: 1318 [23040/60000 (38%)] Loss: -1355.193604\n",
      "Train Epoch: 1318 [34304/60000 (57%)] Loss: -1217.499512\n",
      "Train Epoch: 1318 [45568/60000 (76%)] Loss: -1509.781250\n",
      "Train Epoch: 1318 [56832/60000 (95%)] Loss: -1198.802979\n",
      "    epoch          : 1318\n",
      "    loss           : -1355.760270802988\n",
      "Train Epoch: 1319 [512/60000 (1%)] Loss: -1319.614258\n",
      "Train Epoch: 1319 [11776/60000 (20%)] Loss: -1239.467651\n",
      "Train Epoch: 1319 [23040/60000 (38%)] Loss: -1351.841919\n",
      "Train Epoch: 1319 [34304/60000 (57%)] Loss: -1332.260620\n",
      "Train Epoch: 1319 [45568/60000 (76%)] Loss: -1174.920654\n",
      "Train Epoch: 1319 [56832/60000 (95%)] Loss: -1404.066895\n",
      "    epoch          : 1319\n",
      "    loss           : -1336.6802147471974\n",
      "Train Epoch: 1320 [512/60000 (1%)] Loss: -1213.667236\n",
      "Train Epoch: 1320 [11776/60000 (20%)] Loss: -1182.678711\n",
      "Train Epoch: 1320 [23040/60000 (38%)] Loss: -1482.742676\n",
      "Train Epoch: 1320 [34304/60000 (57%)] Loss: -1357.291626\n",
      "Train Epoch: 1320 [45568/60000 (76%)] Loss: -1335.432495\n",
      "Train Epoch: 1320 [56832/60000 (95%)] Loss: -1204.104980\n",
      "    epoch          : 1320\n",
      "    loss           : -1336.5222823148392\n",
      "Train Epoch: 1321 [512/60000 (1%)] Loss: -1374.506836\n",
      "Train Epoch: 1321 [11776/60000 (20%)] Loss: -1385.893188\n",
      "Train Epoch: 1321 [23040/60000 (38%)] Loss: -1335.171753\n",
      "Train Epoch: 1321 [34304/60000 (57%)] Loss: -1346.215698\n",
      "Train Epoch: 1321 [45568/60000 (76%)] Loss: -1491.552734\n",
      "Train Epoch: 1321 [56832/60000 (95%)] Loss: -1203.931519\n",
      "    epoch          : 1321\n",
      "    loss           : -1331.6982304632327\n",
      "Train Epoch: 1322 [512/60000 (1%)] Loss: -1372.901367\n",
      "Train Epoch: 1322 [11776/60000 (20%)] Loss: -1490.735840\n",
      "Train Epoch: 1322 [23040/60000 (38%)] Loss: -1337.515137\n",
      "Train Epoch: 1322 [34304/60000 (57%)] Loss: -1220.632690\n",
      "Train Epoch: 1322 [45568/60000 (76%)] Loss: -1335.362061\n",
      "Train Epoch: 1322 [56832/60000 (95%)] Loss: -1216.119019\n",
      "    epoch          : 1322\n",
      "    loss           : -1354.675261244262\n",
      "Train Epoch: 1323 [512/60000 (1%)] Loss: -1232.287964\n",
      "Train Epoch: 1323 [11776/60000 (20%)] Loss: -1463.779907\n",
      "Train Epoch: 1323 [23040/60000 (38%)] Loss: -1457.353760\n",
      "Train Epoch: 1323 [34304/60000 (57%)] Loss: -1097.791992\n",
      "Train Epoch: 1323 [45568/60000 (76%)] Loss: -1483.787598\n",
      "Train Epoch: 1323 [56832/60000 (95%)] Loss: -1198.539917\n",
      "    epoch          : 1323\n",
      "    loss           : -1344.6384623899298\n",
      "Train Epoch: 1324 [512/60000 (1%)] Loss: -1358.884033\n",
      "Train Epoch: 1324 [11776/60000 (20%)] Loss: -1373.281860\n",
      "Train Epoch: 1324 [23040/60000 (38%)] Loss: -1350.557861\n",
      "Train Epoch: 1324 [34304/60000 (57%)] Loss: -1205.075928\n",
      "Train Epoch: 1324 [45568/60000 (76%)] Loss: -1480.043701\n",
      "Train Epoch: 1324 [56832/60000 (95%)] Loss: -1381.767944\n",
      "    epoch          : 1324\n",
      "    loss           : -1326.3660135215287\n",
      "Train Epoch: 1325 [512/60000 (1%)] Loss: -1491.802246\n",
      "Train Epoch: 1325 [11776/60000 (20%)] Loss: -1373.805420\n",
      "Train Epoch: 1325 [23040/60000 (38%)] Loss: -1486.640991\n",
      "Train Epoch: 1325 [34304/60000 (57%)] Loss: -1074.372681\n",
      "Train Epoch: 1325 [45568/60000 (76%)] Loss: -1506.238281\n",
      "Train Epoch: 1325 [56832/60000 (95%)] Loss: -1498.783447\n",
      "    epoch          : 1325\n",
      "    loss           : -1352.3375823457363\n",
      "Train Epoch: 1326 [512/60000 (1%)] Loss: -1364.724854\n",
      "Train Epoch: 1326 [11776/60000 (20%)] Loss: -1384.771484\n",
      "Train Epoch: 1326 [23040/60000 (38%)] Loss: -1211.526123\n",
      "Train Epoch: 1326 [34304/60000 (57%)] Loss: -1456.112793\n",
      "Train Epoch: 1326 [45568/60000 (76%)] Loss: -1239.122437\n",
      "Train Epoch: 1326 [56832/60000 (95%)] Loss: -1482.948730\n",
      "    epoch          : 1326\n",
      "    loss           : -1344.784208653337\n",
      "Train Epoch: 1327 [512/60000 (1%)] Loss: -1364.557739\n",
      "Train Epoch: 1327 [11776/60000 (20%)] Loss: -1222.572876\n",
      "Train Epoch: 1327 [23040/60000 (38%)] Loss: -1068.448975\n",
      "Train Epoch: 1327 [34304/60000 (57%)] Loss: -1331.641968\n",
      "Train Epoch: 1327 [45568/60000 (76%)] Loss: -1333.181030\n",
      "Train Epoch: 1327 [56832/60000 (95%)] Loss: -1482.328247\n",
      "    epoch          : 1327\n",
      "    loss           : -1337.3506274896827\n",
      "Train Epoch: 1328 [512/60000 (1%)] Loss: -1486.672363\n",
      "Train Epoch: 1328 [11776/60000 (20%)] Loss: -1098.520996\n",
      "Train Epoch: 1328 [23040/60000 (38%)] Loss: -1455.655884\n",
      "Train Epoch: 1328 [34304/60000 (57%)] Loss: -1082.705200\n",
      "Train Epoch: 1328 [45568/60000 (76%)] Loss: -1362.856812\n",
      "Train Epoch: 1328 [56832/60000 (95%)] Loss: -1358.469604\n",
      "    epoch          : 1328\n",
      "    loss           : -1324.4052713685116\n",
      "Train Epoch: 1329 [512/60000 (1%)] Loss: -1501.758301\n",
      "Train Epoch: 1329 [11776/60000 (20%)] Loss: -1351.930542\n",
      "Train Epoch: 1329 [23040/60000 (38%)] Loss: -1518.472046\n",
      "Train Epoch: 1329 [34304/60000 (57%)] Loss: -1467.460938\n",
      "Train Epoch: 1329 [45568/60000 (76%)] Loss: -1526.857666\n",
      "Train Epoch: 1329 [56832/60000 (95%)] Loss: -1076.286133\n",
      "    epoch          : 1329\n",
      "    loss           : -1366.0465784450034\n",
      "Train Epoch: 1330 [512/60000 (1%)] Loss: -1460.476562\n",
      "Train Epoch: 1330 [11776/60000 (20%)] Loss: -1326.320312\n",
      "Train Epoch: 1330 [23040/60000 (38%)] Loss: -1519.709229\n",
      "Train Epoch: 1330 [34304/60000 (57%)] Loss: -1393.648682\n",
      "Train Epoch: 1330 [45568/60000 (76%)] Loss: -1362.817871\n",
      "Train Epoch: 1330 [56832/60000 (95%)] Loss: -1044.682007\n",
      "    epoch          : 1330\n",
      "    loss           : -1339.6788505942134\n",
      "Train Epoch: 1331 [512/60000 (1%)] Loss: -1219.774414\n",
      "Train Epoch: 1331 [11776/60000 (20%)] Loss: -1496.049683\n",
      "Train Epoch: 1331 [23040/60000 (38%)] Loss: -1213.296387\n",
      "Train Epoch: 1331 [34304/60000 (57%)] Loss: -1112.601196\n",
      "Train Epoch: 1331 [45568/60000 (76%)] Loss: -1341.869019\n",
      "Train Epoch: 1331 [56832/60000 (95%)] Loss: -1373.253418\n",
      "    epoch          : 1331\n",
      "    loss           : -1331.6637245652364\n",
      "Train Epoch: 1332 [512/60000 (1%)] Loss: -1198.898682\n",
      "Train Epoch: 1332 [11776/60000 (20%)] Loss: -1467.489990\n",
      "Train Epoch: 1332 [23040/60000 (38%)] Loss: -1342.703979\n",
      "Train Epoch: 1332 [34304/60000 (57%)] Loss: -1509.193115\n",
      "Train Epoch: 1332 [45568/60000 (76%)] Loss: -1382.693970\n",
      "Train Epoch: 1332 [56832/60000 (95%)] Loss: -1234.430908\n",
      "    epoch          : 1332\n",
      "    loss           : -1334.645723676951\n",
      "Train Epoch: 1333 [512/60000 (1%)] Loss: -1501.309082\n",
      "Train Epoch: 1333 [11776/60000 (20%)] Loss: -1473.789673\n",
      "Train Epoch: 1333 [23040/60000 (38%)] Loss: -1350.532471\n",
      "Train Epoch: 1333 [34304/60000 (57%)] Loss: -1366.165283\n",
      "Train Epoch: 1333 [45568/60000 (76%)] Loss: -1232.630981\n",
      "Train Epoch: 1333 [56832/60000 (95%)] Loss: -1358.514038\n",
      "    epoch          : 1333\n",
      "    loss           : -1312.897051450223\n",
      "Train Epoch: 1334 [512/60000 (1%)] Loss: -1088.621094\n",
      "Train Epoch: 1334 [11776/60000 (20%)] Loss: -1464.252808\n",
      "Train Epoch: 1334 [23040/60000 (38%)] Loss: -1342.147461\n",
      "Train Epoch: 1334 [34304/60000 (57%)] Loss: -1229.687988\n",
      "Train Epoch: 1334 [45568/60000 (76%)] Loss: -944.450195\n",
      "Train Epoch: 1334 [56832/60000 (95%)] Loss: -1507.361328\n",
      "    epoch          : 1334\n",
      "    loss           : -1346.534251067598\n",
      "Train Epoch: 1335 [512/60000 (1%)] Loss: -922.955139\n",
      "Train Epoch: 1335 [11776/60000 (20%)] Loss: -1254.211792\n",
      "Train Epoch: 1335 [23040/60000 (38%)] Loss: -1357.148193\n",
      "Train Epoch: 1335 [34304/60000 (57%)] Loss: -1501.431763\n",
      "Train Epoch: 1335 [45568/60000 (76%)] Loss: -1474.412964\n",
      "Train Epoch: 1335 [56832/60000 (95%)] Loss: -1339.909912\n",
      "    epoch          : 1335\n",
      "    loss           : -1352.8427684374449\n",
      "Train Epoch: 1336 [512/60000 (1%)] Loss: -1383.880493\n",
      "Train Epoch: 1336 [11776/60000 (20%)] Loss: -1498.406494\n",
      "Train Epoch: 1336 [23040/60000 (38%)] Loss: -1217.359863\n",
      "Train Epoch: 1336 [34304/60000 (57%)] Loss: -1179.815796\n",
      "Train Epoch: 1336 [45568/60000 (76%)] Loss: -1209.364746\n",
      "Train Epoch: 1336 [56832/60000 (95%)] Loss: -1206.635132\n",
      "    epoch          : 1336\n",
      "    loss           : -1350.3773848539017\n",
      "Train Epoch: 1337 [512/60000 (1%)] Loss: -1341.826172\n",
      "Train Epoch: 1337 [11776/60000 (20%)] Loss: -1354.544922\n",
      "Train Epoch: 1337 [23040/60000 (38%)] Loss: -1517.270752\n",
      "Train Epoch: 1337 [34304/60000 (57%)] Loss: -1498.249268\n",
      "Train Epoch: 1337 [45568/60000 (76%)] Loss: -1353.742310\n",
      "Train Epoch: 1337 [56832/60000 (95%)] Loss: -1360.070312\n",
      "    epoch          : 1337\n",
      "    loss           : -1353.8736051570224\n",
      "Train Epoch: 1338 [512/60000 (1%)] Loss: -1348.286865\n",
      "Train Epoch: 1338 [11776/60000 (20%)] Loss: -1371.980103\n",
      "Train Epoch: 1338 [23040/60000 (38%)] Loss: -1355.183350\n",
      "Train Epoch: 1338 [34304/60000 (57%)] Loss: -1333.503906\n",
      "Train Epoch: 1338 [45568/60000 (76%)] Loss: -1214.062256\n",
      "Train Epoch: 1338 [56832/60000 (95%)] Loss: -1411.126587\n",
      "    epoch          : 1338\n",
      "    loss           : -1329.6533134158722\n",
      "Train Epoch: 1339 [512/60000 (1%)] Loss: -1338.100342\n",
      "Train Epoch: 1339 [11776/60000 (20%)] Loss: -1485.202026\n",
      "Train Epoch: 1339 [23040/60000 (38%)] Loss: -1484.864258\n",
      "Train Epoch: 1339 [34304/60000 (57%)] Loss: -1107.793213\n",
      "Train Epoch: 1339 [45568/60000 (76%)] Loss: -1493.479004\n",
      "Train Epoch: 1339 [56832/60000 (95%)] Loss: -1505.707520\n",
      "    epoch          : 1339\n",
      "    loss           : -1343.267310191009\n",
      "Train Epoch: 1340 [512/60000 (1%)] Loss: -1226.897949\n",
      "Train Epoch: 1340 [11776/60000 (20%)] Loss: -1226.322754\n",
      "Train Epoch: 1340 [23040/60000 (38%)] Loss: -1225.011963\n",
      "Train Epoch: 1340 [34304/60000 (57%)] Loss: -1462.975342\n",
      "Train Epoch: 1340 [45568/60000 (76%)] Loss: -1399.002197\n",
      "Train Epoch: 1340 [56832/60000 (95%)] Loss: -1551.994141\n",
      "    epoch          : 1340\n",
      "    loss           : -1346.3854032182423\n",
      "Train Epoch: 1341 [512/60000 (1%)] Loss: -1356.969604\n",
      "Train Epoch: 1341 [11776/60000 (20%)] Loss: -1487.185547\n",
      "Train Epoch: 1341 [23040/60000 (38%)] Loss: -1086.058228\n",
      "Train Epoch: 1341 [34304/60000 (57%)] Loss: -1493.049561\n",
      "Train Epoch: 1341 [45568/60000 (76%)] Loss: -1190.475342\n",
      "Train Epoch: 1341 [56832/60000 (95%)] Loss: -1485.106079\n",
      "    epoch          : 1341\n",
      "    loss           : -1339.9435217905852\n",
      "Train Epoch: 1342 [512/60000 (1%)] Loss: -1355.294067\n",
      "Train Epoch: 1342 [11776/60000 (20%)] Loss: -1383.073975\n",
      "Train Epoch: 1342 [23040/60000 (38%)] Loss: -1346.528320\n",
      "Train Epoch: 1342 [34304/60000 (57%)] Loss: -1339.034424\n",
      "Train Epoch: 1342 [45568/60000 (76%)] Loss: -1252.113037\n",
      "Train Epoch: 1342 [56832/60000 (95%)] Loss: -1209.869873\n",
      "    epoch          : 1342\n",
      "    loss           : -1350.0394471594168\n",
      "Train Epoch: 1343 [512/60000 (1%)] Loss: -1352.887573\n",
      "Train Epoch: 1343 [11776/60000 (20%)] Loss: -1326.434082\n",
      "Train Epoch: 1343 [23040/60000 (38%)] Loss: -1113.164307\n",
      "Train Epoch: 1343 [34304/60000 (57%)] Loss: -1056.752808\n",
      "Train Epoch: 1343 [45568/60000 (76%)] Loss: -1219.224243\n",
      "Train Epoch: 1343 [56832/60000 (95%)] Loss: -1486.484619\n",
      "    epoch          : 1343\n",
      "    loss           : -1344.101630431784\n",
      "Train Epoch: 1344 [512/60000 (1%)] Loss: -1398.393188\n",
      "Train Epoch: 1344 [11776/60000 (20%)] Loss: -1335.140869\n",
      "Train Epoch: 1344 [23040/60000 (38%)] Loss: -1357.134277\n",
      "Train Epoch: 1344 [34304/60000 (57%)] Loss: -1490.475342\n",
      "Train Epoch: 1344 [45568/60000 (76%)] Loss: -1392.052490\n",
      "Train Epoch: 1344 [56832/60000 (95%)] Loss: -1364.518799\n",
      "    epoch          : 1344\n",
      "    loss           : -1333.1433902029264\n",
      "Train Epoch: 1345 [512/60000 (1%)] Loss: -1306.288574\n",
      "Train Epoch: 1345 [11776/60000 (20%)] Loss: -1465.841919\n",
      "Train Epoch: 1345 [23040/60000 (38%)] Loss: -1208.250244\n",
      "Train Epoch: 1345 [34304/60000 (57%)] Loss: -1327.368164\n",
      "Train Epoch: 1345 [45568/60000 (76%)] Loss: -1450.179932\n",
      "Train Epoch: 1345 [56832/60000 (95%)] Loss: -1346.184326\n",
      "    epoch          : 1345\n",
      "    loss           : -1335.9603600798353\n",
      "Train Epoch: 1346 [512/60000 (1%)] Loss: -1377.036377\n",
      "Train Epoch: 1346 [11776/60000 (20%)] Loss: -1094.929932\n",
      "Train Epoch: 1346 [23040/60000 (38%)] Loss: -1338.802124\n",
      "Train Epoch: 1346 [34304/60000 (57%)] Loss: -1355.218994\n",
      "Train Epoch: 1346 [45568/60000 (76%)] Loss: -1481.326294\n",
      "Train Epoch: 1346 [56832/60000 (95%)] Loss: -1232.852905\n",
      "    epoch          : 1346\n",
      "    loss           : -1344.9932361322608\n",
      "Train Epoch: 1347 [512/60000 (1%)] Loss: -1392.645264\n",
      "Train Epoch: 1347 [11776/60000 (20%)] Loss: -1495.024048\n",
      "Train Epoch: 1347 [23040/60000 (38%)] Loss: -1362.981201\n",
      "Train Epoch: 1347 [34304/60000 (57%)] Loss: -1237.862671\n",
      "Train Epoch: 1347 [45568/60000 (76%)] Loss: -1247.102173\n",
      "Train Epoch: 1347 [56832/60000 (95%)] Loss: -1350.433716\n",
      "    epoch          : 1347\n",
      "    loss           : -1344.430284575554\n",
      "Train Epoch: 1348 [512/60000 (1%)] Loss: -1518.665527\n",
      "Train Epoch: 1348 [11776/60000 (20%)] Loss: -1485.925537\n",
      "Train Epoch: 1348 [23040/60000 (38%)] Loss: -1091.947510\n",
      "Train Epoch: 1348 [34304/60000 (57%)] Loss: -1198.042236\n",
      "Train Epoch: 1348 [45568/60000 (76%)] Loss: -1227.315918\n",
      "Train Epoch: 1348 [56832/60000 (95%)] Loss: -1544.312378\n",
      "    epoch          : 1348\n",
      "    loss           : -1342.6518994347523\n",
      "Train Epoch: 1349 [512/60000 (1%)] Loss: -1367.496338\n",
      "Train Epoch: 1349 [11776/60000 (20%)] Loss: -1512.401733\n",
      "Train Epoch: 1349 [23040/60000 (38%)] Loss: -1490.266846\n",
      "Train Epoch: 1349 [34304/60000 (57%)] Loss: -1375.986572\n",
      "Train Epoch: 1349 [45568/60000 (76%)] Loss: -1371.888672\n",
      "Train Epoch: 1349 [56832/60000 (95%)] Loss: -1078.460938\n",
      "    epoch          : 1349\n",
      "    loss           : -1355.748289291468\n",
      "Train Epoch: 1350 [512/60000 (1%)] Loss: -1347.658081\n",
      "Train Epoch: 1350 [11776/60000 (20%)] Loss: -1207.483398\n",
      "Train Epoch: 1350 [23040/60000 (38%)] Loss: -1473.894409\n",
      "Train Epoch: 1350 [34304/60000 (57%)] Loss: -1366.396606\n",
      "Train Epoch: 1350 [45568/60000 (76%)] Loss: -1057.939575\n",
      "Train Epoch: 1350 [56832/60000 (95%)] Loss: -1192.826294\n",
      "    epoch          : 1350\n",
      "    loss           : -1349.1740605413577\n",
      "Train Epoch: 1351 [512/60000 (1%)] Loss: -1352.813477\n",
      "Train Epoch: 1351 [11776/60000 (20%)] Loss: -1371.971436\n",
      "Train Epoch: 1351 [23040/60000 (38%)] Loss: -1516.110474\n",
      "Train Epoch: 1351 [34304/60000 (57%)] Loss: -1385.572021\n",
      "Train Epoch: 1351 [45568/60000 (76%)] Loss: -1364.905640\n",
      "Train Epoch: 1351 [56832/60000 (95%)] Loss: -1227.516357\n",
      "    epoch          : 1351\n",
      "    loss           : -1352.6675842629986\n",
      "Train Epoch: 1352 [512/60000 (1%)] Loss: -1230.410400\n",
      "Train Epoch: 1352 [11776/60000 (20%)] Loss: -1454.597900\n",
      "Train Epoch: 1352 [23040/60000 (38%)] Loss: -1487.654053\n",
      "Train Epoch: 1352 [34304/60000 (57%)] Loss: -1266.714355\n",
      "Train Epoch: 1352 [45568/60000 (76%)] Loss: -1293.183350\n",
      "Train Epoch: 1352 [56832/60000 (95%)] Loss: -1238.078003\n",
      "    epoch          : 1352\n",
      "    loss           : -1326.052420578434\n",
      "Train Epoch: 1353 [512/60000 (1%)] Loss: -1214.344727\n",
      "Train Epoch: 1353 [11776/60000 (20%)] Loss: -1240.008545\n",
      "Train Epoch: 1353 [23040/60000 (38%)] Loss: -1361.848022\n",
      "Train Epoch: 1353 [34304/60000 (57%)] Loss: -1341.061401\n",
      "Train Epoch: 1353 [45568/60000 (76%)] Loss: -1245.801147\n",
      "Train Epoch: 1353 [56832/60000 (95%)] Loss: -1397.722412\n",
      "    epoch          : 1353\n",
      "    loss           : -1330.0022193348339\n",
      "Train Epoch: 1354 [512/60000 (1%)] Loss: -1496.074219\n",
      "Train Epoch: 1354 [11776/60000 (20%)] Loss: -1538.467285\n",
      "Train Epoch: 1354 [23040/60000 (38%)] Loss: -1495.042236\n",
      "Train Epoch: 1354 [34304/60000 (57%)] Loss: -1483.402588\n",
      "Train Epoch: 1354 [45568/60000 (76%)] Loss: -1503.401733\n",
      "Train Epoch: 1354 [56832/60000 (95%)] Loss: -1500.006348\n",
      "    epoch          : 1354\n",
      "    loss           : -1362.347312453103\n",
      "Train Epoch: 1355 [512/60000 (1%)] Loss: -1245.983398\n",
      "Train Epoch: 1355 [11776/60000 (20%)] Loss: -1369.141724\n",
      "Train Epoch: 1355 [23040/60000 (38%)] Loss: -1234.189941\n",
      "Train Epoch: 1355 [34304/60000 (57%)] Loss: -1227.317993\n",
      "Train Epoch: 1355 [45568/60000 (76%)] Loss: -1335.480225\n",
      "Train Epoch: 1355 [56832/60000 (95%)] Loss: -1522.266479\n",
      "    epoch          : 1355\n",
      "    loss           : -1348.7633653198932\n",
      "Train Epoch: 1356 [512/60000 (1%)] Loss: -1113.181885\n",
      "Train Epoch: 1356 [11776/60000 (20%)] Loss: -1501.962402\n",
      "Train Epoch: 1356 [23040/60000 (38%)] Loss: -1386.531982\n",
      "Train Epoch: 1356 [34304/60000 (57%)] Loss: -1191.130981\n",
      "Train Epoch: 1356 [45568/60000 (76%)] Loss: -1218.310425\n",
      "Train Epoch: 1356 [56832/60000 (95%)] Loss: -1185.633423\n",
      "    epoch          : 1356\n",
      "    loss           : -1345.585240250927\n",
      "Train Epoch: 1357 [512/60000 (1%)] Loss: -1330.888062\n",
      "Train Epoch: 1357 [11776/60000 (20%)] Loss: -1321.691162\n",
      "Train Epoch: 1357 [23040/60000 (38%)] Loss: -1345.155029\n",
      "Train Epoch: 1357 [34304/60000 (57%)] Loss: -1355.326172\n",
      "Train Epoch: 1357 [45568/60000 (76%)] Loss: -1370.344971\n",
      "Train Epoch: 1357 [56832/60000 (95%)] Loss: -1347.501953\n",
      "    epoch          : 1357\n",
      "    loss           : -1325.8295532916227\n",
      "Train Epoch: 1358 [512/60000 (1%)] Loss: -1220.855225\n",
      "Train Epoch: 1358 [11776/60000 (20%)] Loss: -1384.509766\n",
      "Train Epoch: 1358 [23040/60000 (38%)] Loss: -1340.689453\n",
      "Train Epoch: 1358 [34304/60000 (57%)] Loss: -1244.037964\n",
      "Train Epoch: 1358 [45568/60000 (76%)] Loss: -1536.783569\n",
      "Train Epoch: 1358 [56832/60000 (95%)] Loss: -1494.738037\n",
      "    epoch          : 1358\n",
      "    loss           : -1335.6347606249449\n",
      "Train Epoch: 1359 [512/60000 (1%)] Loss: -1213.567505\n",
      "Train Epoch: 1359 [11776/60000 (20%)] Loss: -1320.040039\n",
      "Train Epoch: 1359 [23040/60000 (38%)] Loss: -1358.300415\n",
      "Train Epoch: 1359 [34304/60000 (57%)] Loss: -1355.265137\n",
      "Train Epoch: 1359 [45568/60000 (76%)] Loss: -1504.004883\n",
      "Train Epoch: 1359 [56832/60000 (95%)] Loss: -1467.500977\n",
      "    epoch          : 1359\n",
      "    loss           : -1328.8276867193017\n",
      "Train Epoch: 1360 [512/60000 (1%)] Loss: -1211.407959\n",
      "Train Epoch: 1360 [11776/60000 (20%)] Loss: -1249.932617\n",
      "Train Epoch: 1360 [23040/60000 (38%)] Loss: -1394.674683\n",
      "Train Epoch: 1360 [34304/60000 (57%)] Loss: -1337.686523\n",
      "Train Epoch: 1360 [45568/60000 (76%)] Loss: -1263.429688\n",
      "Train Epoch: 1360 [56832/60000 (95%)] Loss: -1334.427002\n",
      "    epoch          : 1360\n",
      "    loss           : -1330.6826532223804\n",
      "Train Epoch: 1361 [512/60000 (1%)] Loss: -1513.537231\n",
      "Train Epoch: 1361 [11776/60000 (20%)] Loss: -1050.253784\n",
      "Train Epoch: 1361 [23040/60000 (38%)] Loss: -1530.038086\n",
      "Train Epoch: 1361 [34304/60000 (57%)] Loss: -1509.189941\n",
      "Train Epoch: 1361 [45568/60000 (76%)] Loss: -1189.411743\n",
      "Train Epoch: 1361 [56832/60000 (95%)] Loss: -1376.276245\n",
      "    epoch          : 1361\n",
      "    loss           : -1326.0051798847437\n",
      "Train Epoch: 1362 [512/60000 (1%)] Loss: -1198.142944\n",
      "Train Epoch: 1362 [11776/60000 (20%)] Loss: -1212.368042\n",
      "Train Epoch: 1362 [23040/60000 (38%)] Loss: -1358.993164\n",
      "Train Epoch: 1362 [34304/60000 (57%)] Loss: -1374.910889\n",
      "Train Epoch: 1362 [45568/60000 (76%)] Loss: -1208.994019\n",
      "Train Epoch: 1362 [56832/60000 (95%)] Loss: -1348.282227\n",
      "    epoch          : 1362\n",
      "    loss           : -1328.2404805846134\n",
      "Train Epoch: 1363 [512/60000 (1%)] Loss: -1098.374756\n",
      "Train Epoch: 1363 [11776/60000 (20%)] Loss: -1511.065430\n",
      "Train Epoch: 1363 [23040/60000 (38%)] Loss: -1203.880371\n",
      "Train Epoch: 1363 [34304/60000 (57%)] Loss: -1366.206909\n",
      "Train Epoch: 1363 [45568/60000 (76%)] Loss: -1385.100952\n",
      "Train Epoch: 1363 [56832/60000 (95%)] Loss: -1381.903442\n",
      "    epoch          : 1363\n",
      "    loss           : -1344.3762851865952\n",
      "Train Epoch: 1364 [512/60000 (1%)] Loss: -1373.914062\n",
      "Train Epoch: 1364 [11776/60000 (20%)] Loss: -1241.202515\n",
      "Train Epoch: 1364 [23040/60000 (38%)] Loss: -1223.796875\n",
      "Train Epoch: 1364 [34304/60000 (57%)] Loss: -1479.672607\n",
      "Train Epoch: 1364 [45568/60000 (76%)] Loss: -1190.635498\n",
      "Train Epoch: 1364 [56832/60000 (95%)] Loss: -1220.054810\n",
      "    epoch          : 1364\n",
      "    loss           : -1353.6604614257812\n",
      "Train Epoch: 1365 [512/60000 (1%)] Loss: -1374.058838\n",
      "Train Epoch: 1365 [11776/60000 (20%)] Loss: -1353.451172\n",
      "Train Epoch: 1365 [23040/60000 (38%)] Loss: -1357.222168\n",
      "Train Epoch: 1365 [34304/60000 (57%)] Loss: -1480.390381\n",
      "Train Epoch: 1365 [45568/60000 (76%)] Loss: -1051.991943\n",
      "Train Epoch: 1365 [56832/60000 (95%)] Loss: -1479.261719\n",
      "    epoch          : 1365\n",
      "    loss           : -1346.1932469599665\n",
      "Train Epoch: 1366 [512/60000 (1%)] Loss: -1473.011353\n",
      "Train Epoch: 1366 [11776/60000 (20%)] Loss: -1489.969482\n",
      "Train Epoch: 1366 [23040/60000 (38%)] Loss: -1450.661011\n",
      "Train Epoch: 1366 [34304/60000 (57%)] Loss: -1217.796875\n",
      "Train Epoch: 1366 [45568/60000 (76%)] Loss: -1251.928467\n",
      "Train Epoch: 1366 [56832/60000 (95%)] Loss: -1223.970947\n",
      "    epoch          : 1366\n",
      "    loss           : -1346.758231125309\n",
      "Train Epoch: 1367 [512/60000 (1%)] Loss: -1493.311523\n",
      "Train Epoch: 1367 [11776/60000 (20%)] Loss: -1338.159668\n",
      "Train Epoch: 1367 [23040/60000 (38%)] Loss: -1502.253174\n",
      "Train Epoch: 1367 [34304/60000 (57%)] Loss: -1369.842285\n",
      "Train Epoch: 1367 [45568/60000 (76%)] Loss: -1493.159912\n",
      "Train Epoch: 1367 [56832/60000 (95%)] Loss: -1222.397217\n",
      "    epoch          : 1367\n",
      "    loss           : -1321.108105503233\n",
      "Train Epoch: 1368 [512/60000 (1%)] Loss: -1514.795532\n",
      "Train Epoch: 1368 [11776/60000 (20%)] Loss: -1364.800049\n",
      "Train Epoch: 1368 [23040/60000 (38%)] Loss: -1487.153809\n",
      "Train Epoch: 1368 [34304/60000 (57%)] Loss: -1370.122314\n",
      "Train Epoch: 1368 [45568/60000 (76%)] Loss: -1222.639893\n",
      "Train Epoch: 1368 [56832/60000 (95%)] Loss: -1395.055908\n",
      "    epoch          : 1368\n",
      "    loss           : -1333.5163672495696\n",
      "Train Epoch: 1369 [512/60000 (1%)] Loss: -1221.867920\n",
      "Train Epoch: 1369 [11776/60000 (20%)] Loss: -962.037354\n",
      "Train Epoch: 1369 [23040/60000 (38%)] Loss: -1357.440063\n",
      "Train Epoch: 1369 [34304/60000 (57%)] Loss: -1362.773682\n",
      "Train Epoch: 1369 [45568/60000 (76%)] Loss: -1352.067017\n",
      "Train Epoch: 1369 [56832/60000 (95%)] Loss: -1340.909668\n",
      "    epoch          : 1369\n",
      "    loss           : -1335.5046152233404\n",
      "Train Epoch: 1370 [512/60000 (1%)] Loss: -1240.704102\n",
      "Train Epoch: 1370 [11776/60000 (20%)] Loss: -1407.656982\n",
      "Train Epoch: 1370 [23040/60000 (38%)] Loss: -1390.153809\n",
      "Train Epoch: 1370 [34304/60000 (57%)] Loss: -1240.283691\n",
      "Train Epoch: 1370 [45568/60000 (76%)] Loss: -1490.539551\n",
      "Train Epoch: 1370 [56832/60000 (95%)] Loss: -1352.448608\n",
      "    epoch          : 1370\n",
      "    loss           : -1346.4504929019906\n",
      "Train Epoch: 1371 [512/60000 (1%)] Loss: -1248.764160\n",
      "Train Epoch: 1371 [11776/60000 (20%)] Loss: -1391.576782\n",
      "Train Epoch: 1371 [23040/60000 (38%)] Loss: -1358.421997\n",
      "Train Epoch: 1371 [34304/60000 (57%)] Loss: -1485.216064\n",
      "Train Epoch: 1371 [45568/60000 (76%)] Loss: -1385.462646\n",
      "Train Epoch: 1371 [56832/60000 (95%)] Loss: -1328.350098\n",
      "    epoch          : 1371\n",
      "    loss           : -1322.5298341223074\n",
      "Train Epoch: 1372 [512/60000 (1%)] Loss: -1483.169067\n",
      "Train Epoch: 1372 [11776/60000 (20%)] Loss: -1384.715576\n",
      "Train Epoch: 1372 [23040/60000 (38%)] Loss: -1518.004395\n",
      "Train Epoch: 1372 [34304/60000 (57%)] Loss: -1525.166504\n",
      "Train Epoch: 1372 [45568/60000 (76%)] Loss: -1202.902466\n",
      "Train Epoch: 1372 [56832/60000 (95%)] Loss: -1368.767944\n",
      "    epoch          : 1372\n",
      "    loss           : -1339.5630537992142\n",
      "Train Epoch: 1373 [512/60000 (1%)] Loss: -1204.765381\n",
      "Train Epoch: 1373 [11776/60000 (20%)] Loss: -1494.812500\n",
      "Train Epoch: 1373 [23040/60000 (38%)] Loss: -1222.476685\n",
      "Train Epoch: 1373 [34304/60000 (57%)] Loss: -1356.809082\n",
      "Train Epoch: 1373 [45568/60000 (76%)] Loss: -1367.583252\n",
      "Train Epoch: 1373 [56832/60000 (95%)] Loss: -1340.513184\n",
      "    epoch          : 1373\n",
      "    loss           : -1340.4957270218154\n",
      "Train Epoch: 1374 [512/60000 (1%)] Loss: -1073.630371\n",
      "Train Epoch: 1374 [11776/60000 (20%)] Loss: -1228.120972\n",
      "Train Epoch: 1374 [23040/60000 (38%)] Loss: -1212.263550\n",
      "Train Epoch: 1374 [34304/60000 (57%)] Loss: -1225.992920\n",
      "Train Epoch: 1374 [45568/60000 (76%)] Loss: -1177.544678\n",
      "Train Epoch: 1374 [56832/60000 (95%)] Loss: -1470.906860\n",
      "    epoch          : 1374\n",
      "    loss           : -1321.7341129281428\n",
      "Train Epoch: 1375 [512/60000 (1%)] Loss: -1214.454712\n",
      "Train Epoch: 1375 [11776/60000 (20%)] Loss: -1338.656006\n",
      "Train Epoch: 1375 [23040/60000 (38%)] Loss: -925.630005\n",
      "Train Epoch: 1375 [34304/60000 (57%)] Loss: -1205.612183\n",
      "Train Epoch: 1375 [45568/60000 (76%)] Loss: -1477.908691\n",
      "Train Epoch: 1375 [56832/60000 (95%)] Loss: -1501.006226\n",
      "    epoch          : 1375\n",
      "    loss           : -1325.793773586467\n",
      "Train Epoch: 1376 [512/60000 (1%)] Loss: -1475.946899\n",
      "Train Epoch: 1376 [11776/60000 (20%)] Loss: -1230.877808\n",
      "Train Epoch: 1376 [23040/60000 (38%)] Loss: -1203.834961\n",
      "Train Epoch: 1376 [34304/60000 (57%)] Loss: -1231.486816\n",
      "Train Epoch: 1376 [45568/60000 (76%)] Loss: -1345.335938\n",
      "Train Epoch: 1376 [56832/60000 (95%)] Loss: -1365.034180\n",
      "    epoch          : 1376\n",
      "    loss           : -1313.8678937146894\n",
      "Train Epoch: 1377 [512/60000 (1%)] Loss: -1353.805908\n",
      "Train Epoch: 1377 [11776/60000 (20%)] Loss: -1344.822388\n",
      "Train Epoch: 1377 [23040/60000 (38%)] Loss: -1512.733765\n",
      "Train Epoch: 1377 [34304/60000 (57%)] Loss: -1374.140869\n",
      "Train Epoch: 1377 [45568/60000 (76%)] Loss: -1217.427368\n",
      "Train Epoch: 1377 [56832/60000 (95%)] Loss: -1492.994629\n",
      "    epoch          : 1377\n",
      "    loss           : -1352.630390404308\n",
      "Train Epoch: 1378 [512/60000 (1%)] Loss: -1370.075317\n",
      "Train Epoch: 1378 [11776/60000 (20%)] Loss: -1303.344360\n",
      "Train Epoch: 1378 [23040/60000 (38%)] Loss: -1197.947388\n",
      "Train Epoch: 1378 [34304/60000 (57%)] Loss: -1379.894775\n",
      "Train Epoch: 1378 [45568/60000 (76%)] Loss: -1394.132324\n",
      "Train Epoch: 1378 [56832/60000 (95%)] Loss: -1336.455200\n",
      "    epoch          : 1378\n",
      "    loss           : -1343.1808885477358\n",
      "Train Epoch: 1379 [512/60000 (1%)] Loss: -1557.252441\n",
      "Train Epoch: 1379 [11776/60000 (20%)] Loss: -1380.069214\n",
      "Train Epoch: 1379 [23040/60000 (38%)] Loss: -1467.826172\n",
      "Train Epoch: 1379 [34304/60000 (57%)] Loss: -1366.888550\n",
      "Train Epoch: 1379 [45568/60000 (76%)] Loss: -1250.672119\n",
      "Train Epoch: 1379 [56832/60000 (95%)] Loss: -1203.096191\n",
      "    epoch          : 1379\n",
      "    loss           : -1332.7160616944739\n",
      "Train Epoch: 1380 [512/60000 (1%)] Loss: -1464.991211\n",
      "Train Epoch: 1380 [11776/60000 (20%)] Loss: -1510.168091\n",
      "Train Epoch: 1380 [23040/60000 (38%)] Loss: -1327.468872\n",
      "Train Epoch: 1380 [34304/60000 (57%)] Loss: -1336.085938\n",
      "Train Epoch: 1380 [45568/60000 (76%)] Loss: -1230.472412\n",
      "Train Epoch: 1380 [56832/60000 (95%)] Loss: -1243.111938\n",
      "    epoch          : 1380\n",
      "    loss           : -1337.6783948995298\n",
      "Train Epoch: 1381 [512/60000 (1%)] Loss: -1495.603149\n",
      "Train Epoch: 1381 [11776/60000 (20%)] Loss: -1500.479492\n",
      "Train Epoch: 1381 [23040/60000 (38%)] Loss: -1254.778320\n",
      "Train Epoch: 1381 [34304/60000 (57%)] Loss: -1250.097168\n",
      "Train Epoch: 1381 [45568/60000 (76%)] Loss: -1219.589478\n",
      "Train Epoch: 1381 [56832/60000 (95%)] Loss: -1190.385742\n",
      "    epoch          : 1381\n",
      "    loss           : -1340.2488496424787\n",
      "Train Epoch: 1382 [512/60000 (1%)] Loss: -1368.560547\n",
      "Train Epoch: 1382 [11776/60000 (20%)] Loss: -1226.187256\n",
      "Train Epoch: 1382 [23040/60000 (38%)] Loss: -1209.971680\n",
      "Train Epoch: 1382 [34304/60000 (57%)] Loss: -1226.121582\n",
      "Train Epoch: 1382 [45568/60000 (76%)] Loss: -1351.873779\n",
      "Train Epoch: 1382 [56832/60000 (95%)] Loss: -1473.798462\n",
      "    epoch          : 1382\n",
      "    loss           : -1336.773341636873\n",
      "Train Epoch: 1383 [512/60000 (1%)] Loss: -1540.984009\n",
      "Train Epoch: 1383 [11776/60000 (20%)] Loss: -1399.861206\n",
      "Train Epoch: 1383 [23040/60000 (38%)] Loss: -1224.880371\n",
      "Train Epoch: 1383 [34304/60000 (57%)] Loss: -1060.755127\n",
      "Train Epoch: 1383 [45568/60000 (76%)] Loss: -1394.986816\n",
      "Train Epoch: 1383 [56832/60000 (95%)] Loss: -1363.719482\n",
      "    epoch          : 1383\n",
      "    loss           : -1335.8394199522202\n",
      "Train Epoch: 1384 [512/60000 (1%)] Loss: -1353.083618\n",
      "Train Epoch: 1384 [11776/60000 (20%)] Loss: -1468.199097\n",
      "Train Epoch: 1384 [23040/60000 (38%)] Loss: -1372.748169\n",
      "Train Epoch: 1384 [34304/60000 (57%)] Loss: -1373.255127\n",
      "Train Epoch: 1384 [45568/60000 (76%)] Loss: -1376.169312\n",
      "Train Epoch: 1384 [56832/60000 (95%)] Loss: -1181.335327\n",
      "    epoch          : 1384\n",
      "    loss           : -1344.4107155665167\n",
      "Train Epoch: 1385 [512/60000 (1%)] Loss: -1236.887207\n",
      "Train Epoch: 1385 [11776/60000 (20%)] Loss: -1526.383057\n",
      "Train Epoch: 1385 [23040/60000 (38%)] Loss: -1243.969116\n",
      "Train Epoch: 1385 [34304/60000 (57%)] Loss: -1333.318604\n",
      "Train Epoch: 1385 [45568/60000 (76%)] Loss: -1348.087158\n",
      "Train Epoch: 1385 [56832/60000 (95%)] Loss: -1079.453125\n",
      "    epoch          : 1385\n",
      "    loss           : -1330.2142452951205\n",
      "Train Epoch: 1386 [512/60000 (1%)] Loss: -1397.373291\n",
      "Train Epoch: 1386 [11776/60000 (20%)] Loss: -1374.979614\n",
      "Train Epoch: 1386 [23040/60000 (38%)] Loss: -1387.666626\n",
      "Train Epoch: 1386 [34304/60000 (57%)] Loss: -1500.632568\n",
      "Train Epoch: 1386 [45568/60000 (76%)] Loss: -1057.154419\n",
      "Train Epoch: 1386 [56832/60000 (95%)] Loss: -1467.259888\n",
      "    epoch          : 1386\n",
      "    loss           : -1329.2342815506931\n",
      "Train Epoch: 1387 [512/60000 (1%)] Loss: -1226.693359\n",
      "Train Epoch: 1387 [11776/60000 (20%)] Loss: -1214.735840\n",
      "Train Epoch: 1387 [23040/60000 (38%)] Loss: -1472.876831\n",
      "Train Epoch: 1387 [34304/60000 (57%)] Loss: -1378.510132\n",
      "Train Epoch: 1387 [45568/60000 (76%)] Loss: -1452.345215\n",
      "Train Epoch: 1387 [56832/60000 (95%)] Loss: -1389.799072\n",
      "    epoch          : 1387\n",
      "    loss           : -1345.6053046102577\n",
      "Train Epoch: 1388 [512/60000 (1%)] Loss: -1360.470947\n",
      "Train Epoch: 1388 [11776/60000 (20%)] Loss: -1350.136108\n",
      "Train Epoch: 1388 [23040/60000 (38%)] Loss: -1223.743042\n",
      "Train Epoch: 1388 [34304/60000 (57%)] Loss: -1535.064941\n",
      "Train Epoch: 1388 [45568/60000 (76%)] Loss: -1334.416016\n",
      "Train Epoch: 1388 [56832/60000 (95%)] Loss: -1463.488159\n",
      "    epoch          : 1388\n",
      "    loss           : -1360.0936710336116\n",
      "Train Epoch: 1389 [512/60000 (1%)] Loss: -1203.742920\n",
      "Train Epoch: 1389 [11776/60000 (20%)] Loss: -1457.018555\n",
      "Train Epoch: 1389 [23040/60000 (38%)] Loss: -1241.489746\n",
      "Train Epoch: 1389 [34304/60000 (57%)] Loss: -1491.479248\n",
      "Train Epoch: 1389 [45568/60000 (76%)] Loss: -1479.356201\n",
      "Train Epoch: 1389 [56832/60000 (95%)] Loss: -1504.078979\n",
      "    epoch          : 1389\n",
      "    loss           : -1313.0568313167594\n",
      "Train Epoch: 1390 [512/60000 (1%)] Loss: -1367.215698\n",
      "Train Epoch: 1390 [11776/60000 (20%)] Loss: -1237.522949\n",
      "Train Epoch: 1390 [23040/60000 (38%)] Loss: -1363.472046\n",
      "Train Epoch: 1390 [34304/60000 (57%)] Loss: -1233.733765\n",
      "Train Epoch: 1390 [45568/60000 (76%)] Loss: -1228.027710\n",
      "Train Epoch: 1390 [56832/60000 (95%)] Loss: -1208.183594\n",
      "    epoch          : 1390\n",
      "    loss           : -1339.5021372649628\n",
      "Train Epoch: 1391 [512/60000 (1%)] Loss: -1493.577271\n",
      "Train Epoch: 1391 [11776/60000 (20%)] Loss: -1201.431763\n",
      "Train Epoch: 1391 [23040/60000 (38%)] Loss: -1075.782471\n",
      "Train Epoch: 1391 [34304/60000 (57%)] Loss: -1214.290894\n",
      "Train Epoch: 1391 [45568/60000 (76%)] Loss: -1472.250977\n",
      "Train Epoch: 1391 [56832/60000 (95%)] Loss: -1083.909668\n",
      "    epoch          : 1391\n",
      "    loss           : -1346.0569530422404\n",
      "Train Epoch: 1392 [512/60000 (1%)] Loss: -1498.546753\n",
      "Train Epoch: 1392 [11776/60000 (20%)] Loss: -1335.636719\n",
      "Train Epoch: 1392 [23040/60000 (38%)] Loss: -1223.841797\n",
      "Train Epoch: 1392 [34304/60000 (57%)] Loss: -1440.071533\n",
      "Train Epoch: 1392 [45568/60000 (76%)] Loss: -1248.845947\n",
      "Train Epoch: 1392 [56832/60000 (95%)] Loss: -1376.999268\n",
      "    epoch          : 1392\n",
      "    loss           : -1336.511953235346\n",
      "Train Epoch: 1393 [512/60000 (1%)] Loss: -1343.470459\n",
      "Train Epoch: 1393 [11776/60000 (20%)] Loss: -1490.022949\n",
      "Train Epoch: 1393 [23040/60000 (38%)] Loss: -1515.825195\n",
      "Train Epoch: 1393 [34304/60000 (57%)] Loss: -1487.550903\n",
      "Train Epoch: 1393 [45568/60000 (76%)] Loss: -1235.422852\n",
      "Train Epoch: 1393 [56832/60000 (95%)] Loss: -1488.221069\n",
      "    epoch          : 1393\n",
      "    loss           : -1345.7320522157486\n",
      "Train Epoch: 1394 [512/60000 (1%)] Loss: -1325.106079\n",
      "Train Epoch: 1394 [11776/60000 (20%)] Loss: -1538.824463\n",
      "Train Epoch: 1394 [23040/60000 (38%)] Loss: -1385.939209\n",
      "Train Epoch: 1394 [34304/60000 (57%)] Loss: -1370.275879\n",
      "Train Epoch: 1394 [45568/60000 (76%)] Loss: -1501.675049\n",
      "Train Epoch: 1394 [56832/60000 (95%)] Loss: -1398.000488\n",
      "    epoch          : 1394\n",
      "    loss           : -1359.5069321454582\n",
      "Train Epoch: 1395 [512/60000 (1%)] Loss: -1209.771973\n",
      "Train Epoch: 1395 [11776/60000 (20%)] Loss: -1398.781860\n",
      "Train Epoch: 1395 [23040/60000 (38%)] Loss: -1207.506226\n",
      "Train Epoch: 1395 [34304/60000 (57%)] Loss: -1469.598267\n",
      "Train Epoch: 1395 [45568/60000 (76%)] Loss: -1354.312988\n",
      "Train Epoch: 1395 [56832/60000 (95%)] Loss: -1116.087524\n",
      "    epoch          : 1395\n",
      "    loss           : -1327.5846780033435\n",
      "Train Epoch: 1396 [512/60000 (1%)] Loss: -1114.661865\n",
      "Train Epoch: 1396 [11776/60000 (20%)] Loss: -1532.111816\n",
      "Train Epoch: 1396 [23040/60000 (38%)] Loss: -1495.820557\n",
      "Train Epoch: 1396 [34304/60000 (57%)] Loss: -1208.702393\n",
      "Train Epoch: 1396 [45568/60000 (76%)] Loss: -1405.856812\n",
      "Train Epoch: 1396 [56832/60000 (95%)] Loss: -1241.493042\n",
      "    epoch          : 1396\n",
      "    loss           : -1356.308384782177\n",
      "Train Epoch: 1397 [512/60000 (1%)] Loss: -1179.199219\n",
      "Train Epoch: 1397 [11776/60000 (20%)] Loss: -1492.589355\n",
      "Train Epoch: 1397 [23040/60000 (38%)] Loss: -1082.208130\n",
      "Train Epoch: 1397 [34304/60000 (57%)] Loss: -1500.969482\n",
      "Train Epoch: 1397 [45568/60000 (76%)] Loss: -1357.745728\n",
      "Train Epoch: 1397 [56832/60000 (95%)] Loss: -1501.437866\n",
      "    epoch          : 1397\n",
      "    loss           : -1331.87027822376\n",
      "Train Epoch: 1398 [512/60000 (1%)] Loss: -1331.306396\n",
      "Train Epoch: 1398 [11776/60000 (20%)] Loss: -1210.505371\n",
      "Train Epoch: 1398 [23040/60000 (38%)] Loss: -1350.492188\n",
      "Train Epoch: 1398 [34304/60000 (57%)] Loss: -1099.458984\n",
      "Train Epoch: 1398 [45568/60000 (76%)] Loss: -1510.025635\n",
      "Train Epoch: 1398 [56832/60000 (95%)] Loss: -1369.864990\n",
      "    epoch          : 1398\n",
      "    loss           : -1337.379049010196\n",
      "Train Epoch: 1399 [512/60000 (1%)] Loss: -1376.119141\n",
      "Train Epoch: 1399 [11776/60000 (20%)] Loss: -1313.748047\n",
      "Train Epoch: 1399 [23040/60000 (38%)] Loss: -1231.545166\n",
      "Train Epoch: 1399 [34304/60000 (57%)] Loss: -1355.549561\n",
      "Train Epoch: 1399 [45568/60000 (76%)] Loss: -1502.864990\n",
      "Train Epoch: 1399 [56832/60000 (95%)] Loss: -1384.031616\n",
      "    epoch          : 1399\n",
      "    loss           : -1325.2426057804776\n",
      "Train Epoch: 1400 [512/60000 (1%)] Loss: -1218.914062\n",
      "Train Epoch: 1400 [11776/60000 (20%)] Loss: -1380.083252\n",
      "Train Epoch: 1400 [23040/60000 (38%)] Loss: -1067.980225\n",
      "Train Epoch: 1400 [34304/60000 (57%)] Loss: -1094.836182\n",
      "Train Epoch: 1400 [45568/60000 (76%)] Loss: -1231.026123\n",
      "Train Epoch: 1400 [56832/60000 (95%)] Loss: -1372.207031\n",
      "    epoch          : 1400\n",
      "    loss           : -1320.381536279021\n",
      "Saving checkpoint: saved/models/Mnist_DeepGenerativeOperad/0127_111843/checkpoint-epoch1400.pth ...\n",
      "Train Epoch: 1401 [512/60000 (1%)] Loss: -1512.091919\n",
      "Train Epoch: 1401 [11776/60000 (20%)] Loss: -1348.611816\n",
      "Train Epoch: 1401 [23040/60000 (38%)] Loss: -1065.685303\n",
      "Train Epoch: 1401 [34304/60000 (57%)] Loss: -1362.656372\n",
      "Train Epoch: 1401 [45568/60000 (76%)] Loss: -1387.281982\n",
      "Train Epoch: 1401 [56832/60000 (95%)] Loss: -1459.974243\n",
      "    epoch          : 1401\n",
      "    loss           : -1343.706082963674\n",
      "Train Epoch: 1402 [512/60000 (1%)] Loss: -1359.854980\n",
      "Train Epoch: 1402 [11776/60000 (20%)] Loss: -1234.848999\n",
      "Train Epoch: 1402 [23040/60000 (38%)] Loss: -1364.615356\n",
      "Train Epoch: 1402 [34304/60000 (57%)] Loss: -1356.910889\n",
      "Train Epoch: 1402 [45568/60000 (76%)] Loss: -1483.297241\n",
      "Train Epoch: 1402 [56832/60000 (95%)] Loss: -1334.674561\n",
      "    epoch          : 1402\n",
      "    loss           : -1347.6589279605844\n",
      "Train Epoch: 1403 [512/60000 (1%)] Loss: -1366.679199\n",
      "Train Epoch: 1403 [11776/60000 (20%)] Loss: -1494.999634\n",
      "Train Epoch: 1403 [23040/60000 (38%)] Loss: -1188.518066\n",
      "Train Epoch: 1403 [34304/60000 (57%)] Loss: -1231.085449\n",
      "Train Epoch: 1403 [45568/60000 (76%)] Loss: -1385.906494\n",
      "Train Epoch: 1403 [56832/60000 (95%)] Loss: -1469.371216\n",
      "    epoch          : 1403\n",
      "    loss           : -1353.2286699370477\n",
      "Train Epoch: 1404 [512/60000 (1%)] Loss: -1490.814453\n",
      "Train Epoch: 1404 [11776/60000 (20%)] Loss: -1336.033691\n",
      "Train Epoch: 1404 [23040/60000 (38%)] Loss: -1362.881104\n",
      "Train Epoch: 1404 [34304/60000 (57%)] Loss: -1382.886841\n",
      "Train Epoch: 1404 [45568/60000 (76%)] Loss: -1353.937988\n",
      "Train Epoch: 1404 [56832/60000 (95%)] Loss: -1336.754150\n",
      "    epoch          : 1404\n",
      "    loss           : -1331.454063631047\n",
      "Train Epoch: 1405 [512/60000 (1%)] Loss: -1350.074463\n",
      "Train Epoch: 1405 [11776/60000 (20%)] Loss: -1206.114258\n",
      "Train Epoch: 1405 [23040/60000 (38%)] Loss: -1222.408813\n",
      "Train Epoch: 1405 [34304/60000 (57%)] Loss: -1509.197632\n",
      "Train Epoch: 1405 [45568/60000 (76%)] Loss: -1354.118408\n",
      "Train Epoch: 1405 [56832/60000 (95%)] Loss: -1477.789795\n",
      "    epoch          : 1405\n",
      "    loss           : -1340.7256488692287\n",
      "Train Epoch: 1406 [512/60000 (1%)] Loss: -1494.031372\n",
      "Train Epoch: 1406 [11776/60000 (20%)] Loss: -1357.291382\n",
      "Train Epoch: 1406 [23040/60000 (38%)] Loss: -1228.527100\n",
      "Train Epoch: 1406 [34304/60000 (57%)] Loss: -1218.686279\n",
      "Train Epoch: 1406 [45568/60000 (76%)] Loss: -1494.515259\n",
      "Train Epoch: 1406 [56832/60000 (95%)] Loss: -1512.255615\n",
      "    epoch          : 1406\n",
      "    loss           : -1341.6344101038355\n",
      "Train Epoch: 1407 [512/60000 (1%)] Loss: -1366.876465\n",
      "Train Epoch: 1407 [11776/60000 (20%)] Loss: -1385.407715\n",
      "Train Epoch: 1407 [23040/60000 (38%)] Loss: -1343.387939\n",
      "Train Epoch: 1407 [34304/60000 (57%)] Loss: -1342.911377\n",
      "Train Epoch: 1407 [45568/60000 (76%)] Loss: -1354.278687\n",
      "Train Epoch: 1407 [56832/60000 (95%)] Loss: -1474.668213\n",
      "    epoch          : 1407\n",
      "    loss           : -1343.7396874724134\n",
      "Train Epoch: 1408 [512/60000 (1%)] Loss: -1505.237061\n",
      "Train Epoch: 1408 [11776/60000 (20%)] Loss: -1440.362061\n",
      "Train Epoch: 1408 [23040/60000 (38%)] Loss: -1192.103760\n",
      "Train Epoch: 1408 [34304/60000 (57%)] Loss: -1188.019409\n",
      "Train Epoch: 1408 [45568/60000 (76%)] Loss: -1323.654541\n",
      "Train Epoch: 1408 [56832/60000 (95%)] Loss: -1467.440674\n",
      "    epoch          : 1408\n",
      "    loss           : -1322.8946560789636\n",
      "Train Epoch: 1409 [512/60000 (1%)] Loss: -1341.694336\n",
      "Train Epoch: 1409 [11776/60000 (20%)] Loss: -1327.695190\n",
      "Train Epoch: 1409 [23040/60000 (38%)] Loss: -1367.440430\n",
      "Train Epoch: 1409 [34304/60000 (57%)] Loss: -1063.169678\n",
      "Train Epoch: 1409 [45568/60000 (76%)] Loss: -1205.388672\n",
      "Train Epoch: 1409 [56832/60000 (95%)] Loss: -1512.044922\n",
      "    epoch          : 1409\n",
      "    loss           : -1330.9157473461778\n",
      "Train Epoch: 1410 [512/60000 (1%)] Loss: -1250.304932\n",
      "Train Epoch: 1410 [11776/60000 (20%)] Loss: -1342.444946\n",
      "Train Epoch: 1410 [23040/60000 (38%)] Loss: -1489.380615\n",
      "Train Epoch: 1410 [34304/60000 (57%)] Loss: -1345.515137\n",
      "Train Epoch: 1410 [45568/60000 (76%)] Loss: -1343.689697\n",
      "Train Epoch: 1410 [56832/60000 (95%)] Loss: -1220.855347\n",
      "    epoch          : 1410\n",
      "    loss           : -1340.354259943558\n",
      "Train Epoch: 1411 [512/60000 (1%)] Loss: -1330.595093\n",
      "Train Epoch: 1411 [11776/60000 (20%)] Loss: -1212.193237\n",
      "Train Epoch: 1411 [23040/60000 (38%)] Loss: -1468.900146\n",
      "Train Epoch: 1411 [34304/60000 (57%)] Loss: -1222.881592\n",
      "Train Epoch: 1411 [45568/60000 (76%)] Loss: -1365.972778\n",
      "Train Epoch: 1411 [56832/60000 (95%)] Loss: -1468.174316\n",
      "    epoch          : 1411\n",
      "    loss           : -1339.5599985930878\n",
      "Train Epoch: 1412 [512/60000 (1%)] Loss: -1079.021362\n",
      "Train Epoch: 1412 [11776/60000 (20%)] Loss: -1341.077393\n",
      "Train Epoch: 1412 [23040/60000 (38%)] Loss: -1376.023438\n",
      "Train Epoch: 1412 [34304/60000 (57%)] Loss: -1409.296509\n",
      "Train Epoch: 1412 [45568/60000 (76%)] Loss: -1347.842041\n",
      "Train Epoch: 1412 [56832/60000 (95%)] Loss: -1368.868774\n",
      "    epoch          : 1412\n",
      "    loss           : -1352.4696974242474\n",
      "Train Epoch: 1413 [512/60000 (1%)] Loss: -929.034424\n",
      "Train Epoch: 1413 [11776/60000 (20%)] Loss: -1339.659790\n",
      "Train Epoch: 1413 [23040/60000 (38%)] Loss: -1330.267700\n",
      "Train Epoch: 1413 [34304/60000 (57%)] Loss: -1389.933350\n",
      "Train Epoch: 1413 [45568/60000 (76%)] Loss: -1521.721436\n",
      "Train Epoch: 1413 [56832/60000 (95%)] Loss: -1387.157104\n",
      "    epoch          : 1413\n",
      "    loss           : -1318.8668687033787\n",
      "Train Epoch: 1414 [512/60000 (1%)] Loss: -1218.358765\n",
      "Train Epoch: 1414 [11776/60000 (20%)] Loss: -1507.293945\n",
      "Train Epoch: 1414 [23040/60000 (38%)] Loss: -1358.054810\n",
      "Train Epoch: 1414 [34304/60000 (57%)] Loss: -1085.973267\n",
      "Train Epoch: 1414 [45568/60000 (76%)] Loss: -1073.933228\n",
      "Train Epoch: 1414 [56832/60000 (95%)] Loss: -1488.976074\n",
      "    epoch          : 1414\n",
      "    loss           : -1350.5483222573491\n",
      "Train Epoch: 1415 [512/60000 (1%)] Loss: -1540.270264\n",
      "Train Epoch: 1415 [11776/60000 (20%)] Loss: -1525.745239\n",
      "Train Epoch: 1415 [23040/60000 (38%)] Loss: -1348.477783\n",
      "Train Epoch: 1415 [34304/60000 (57%)] Loss: -1460.328857\n",
      "Train Epoch: 1415 [45568/60000 (76%)] Loss: -1502.507568\n",
      "Train Epoch: 1415 [56832/60000 (95%)] Loss: -1507.439575\n",
      "    epoch          : 1415\n",
      "    loss           : -1324.5336770957474\n",
      "Train Epoch: 1416 [512/60000 (1%)] Loss: -1519.598145\n",
      "Train Epoch: 1416 [11776/60000 (20%)] Loss: -1265.429932\n",
      "Train Epoch: 1416 [23040/60000 (38%)] Loss: -1489.848145\n",
      "Train Epoch: 1416 [34304/60000 (57%)] Loss: -1230.323242\n",
      "Train Epoch: 1416 [45568/60000 (76%)] Loss: -1367.307373\n",
      "Train Epoch: 1416 [56832/60000 (95%)] Loss: -1200.276611\n",
      "    epoch          : 1416\n",
      "    loss           : -1331.9337103030102\n",
      "Train Epoch: 1417 [512/60000 (1%)] Loss: -1261.146118\n",
      "Train Epoch: 1417 [11776/60000 (20%)] Loss: -1199.201416\n",
      "Train Epoch: 1417 [23040/60000 (38%)] Loss: -1192.651367\n",
      "Train Epoch: 1417 [34304/60000 (57%)] Loss: -1233.552979\n",
      "Train Epoch: 1417 [45568/60000 (76%)] Loss: -1348.034058\n",
      "Train Epoch: 1417 [56832/60000 (95%)] Loss: -1187.299805\n",
      "    epoch          : 1417\n",
      "    loss           : -1331.5926106770835\n",
      "Train Epoch: 1418 [512/60000 (1%)] Loss: -1221.279663\n",
      "Train Epoch: 1418 [11776/60000 (20%)] Loss: -1364.089844\n",
      "Train Epoch: 1418 [23040/60000 (38%)] Loss: -1365.008789\n",
      "Train Epoch: 1418 [34304/60000 (57%)] Loss: -1236.630127\n",
      "Train Epoch: 1418 [45568/60000 (76%)] Loss: -1221.059082\n",
      "Train Epoch: 1418 [56832/60000 (95%)] Loss: -1346.849976\n",
      "    epoch          : 1418\n",
      "    loss           : -1368.691239696438\n",
      "Train Epoch: 1419 [512/60000 (1%)] Loss: -1382.002441\n",
      "Train Epoch: 1419 [11776/60000 (20%)] Loss: -1517.526611\n",
      "Train Epoch: 1419 [23040/60000 (38%)] Loss: -1219.018188\n",
      "Train Epoch: 1419 [34304/60000 (57%)] Loss: -1507.421509\n",
      "Train Epoch: 1419 [45568/60000 (76%)] Loss: -1372.344238\n",
      "Train Epoch: 1419 [56832/60000 (95%)] Loss: -1521.963135\n",
      "    epoch          : 1419\n",
      "    loss           : -1343.5468377582097\n",
      "Train Epoch: 1420 [512/60000 (1%)] Loss: -1370.671387\n",
      "Train Epoch: 1420 [11776/60000 (20%)] Loss: -1366.529907\n",
      "Train Epoch: 1420 [23040/60000 (38%)] Loss: -1400.332153\n",
      "Train Epoch: 1420 [34304/60000 (57%)] Loss: -1370.411621\n",
      "Train Epoch: 1420 [45568/60000 (76%)] Loss: -1484.172485\n",
      "Train Epoch: 1420 [56832/60000 (95%)] Loss: -1112.625488\n",
      "    epoch          : 1420\n",
      "    loss           : -1355.1169292212878\n",
      "Train Epoch: 1421 [512/60000 (1%)] Loss: -1239.509644\n",
      "Train Epoch: 1421 [11776/60000 (20%)] Loss: -1342.578125\n",
      "Train Epoch: 1421 [23040/60000 (38%)] Loss: -1505.911865\n",
      "Train Epoch: 1421 [34304/60000 (57%)] Loss: -1488.568237\n",
      "Train Epoch: 1421 [45568/60000 (76%)] Loss: -1343.202881\n",
      "Train Epoch: 1421 [56832/60000 (95%)] Loss: -1517.949097\n",
      "    epoch          : 1421\n",
      "    loss           : -1361.43636602197\n",
      "Train Epoch: 1422 [512/60000 (1%)] Loss: -1510.712280\n",
      "Train Epoch: 1422 [11776/60000 (20%)] Loss: -1229.820068\n",
      "Train Epoch: 1422 [23040/60000 (38%)] Loss: -1320.045776\n",
      "Train Epoch: 1422 [34304/60000 (57%)] Loss: -1342.411011\n",
      "Train Epoch: 1422 [45568/60000 (76%)] Loss: -1197.610229\n",
      "Train Epoch: 1422 [56832/60000 (95%)] Loss: -1366.394287\n",
      "    epoch          : 1422\n",
      "    loss           : -1341.5187798623986\n",
      "Train Epoch: 1423 [512/60000 (1%)] Loss: -1486.656128\n",
      "Train Epoch: 1423 [11776/60000 (20%)] Loss: -1211.900146\n",
      "Train Epoch: 1423 [23040/60000 (38%)] Loss: -1361.272827\n",
      "Train Epoch: 1423 [34304/60000 (57%)] Loss: -1525.335938\n",
      "Train Epoch: 1423 [45568/60000 (76%)] Loss: -1379.450195\n",
      "Train Epoch: 1423 [56832/60000 (95%)] Loss: -1379.690918\n",
      "    epoch          : 1423\n",
      "    loss           : -1337.6133374575168\n",
      "Train Epoch: 1424 [512/60000 (1%)] Loss: -1112.046753\n",
      "Train Epoch: 1424 [11776/60000 (20%)] Loss: -1342.720337\n",
      "Train Epoch: 1424 [23040/60000 (38%)] Loss: -1357.106689\n",
      "Train Epoch: 1424 [34304/60000 (57%)] Loss: -1200.387085\n",
      "Train Epoch: 1424 [45568/60000 (76%)] Loss: -1348.983765\n",
      "Train Epoch: 1424 [56832/60000 (95%)] Loss: -1499.465698\n",
      "    epoch          : 1424\n",
      "    loss           : -1342.9096083129193\n",
      "Train Epoch: 1425 [512/60000 (1%)] Loss: -1378.180054\n",
      "Train Epoch: 1425 [11776/60000 (20%)] Loss: -1382.026123\n",
      "Train Epoch: 1425 [23040/60000 (38%)] Loss: -1246.242554\n",
      "Train Epoch: 1425 [34304/60000 (57%)] Loss: -1358.263184\n",
      "Train Epoch: 1425 [45568/60000 (76%)] Loss: -1220.191406\n",
      "Train Epoch: 1425 [56832/60000 (95%)] Loss: -1401.578735\n",
      "    epoch          : 1425\n",
      "    loss           : -1344.2250385176662\n",
      "Train Epoch: 1426 [512/60000 (1%)] Loss: -1246.505493\n",
      "Train Epoch: 1426 [11776/60000 (20%)] Loss: -1343.687744\n",
      "Train Epoch: 1426 [23040/60000 (38%)] Loss: -1481.512207\n",
      "Train Epoch: 1426 [34304/60000 (57%)] Loss: -1229.391846\n",
      "Train Epoch: 1426 [45568/60000 (76%)] Loss: -1396.680054\n",
      "Train Epoch: 1426 [56832/60000 (95%)] Loss: -1486.590454\n",
      "    epoch          : 1426\n",
      "    loss           : -1343.6598490052304\n",
      "Train Epoch: 1427 [512/60000 (1%)] Loss: -1235.516846\n",
      "Train Epoch: 1427 [11776/60000 (20%)] Loss: -1206.976074\n",
      "Train Epoch: 1427 [23040/60000 (38%)] Loss: -1468.576904\n",
      "Train Epoch: 1427 [34304/60000 (57%)] Loss: -1073.468506\n",
      "Train Epoch: 1427 [45568/60000 (76%)] Loss: -1227.875488\n",
      "Train Epoch: 1427 [56832/60000 (95%)] Loss: -1233.826416\n",
      "    epoch          : 1427\n",
      "    loss           : -1348.9685744808219\n",
      "Train Epoch: 1428 [512/60000 (1%)] Loss: -1370.504639\n",
      "Train Epoch: 1428 [11776/60000 (20%)] Loss: -1514.622803\n",
      "Train Epoch: 1428 [23040/60000 (38%)] Loss: -1361.229126\n",
      "Train Epoch: 1428 [34304/60000 (57%)] Loss: -1528.767212\n",
      "Train Epoch: 1428 [45568/60000 (76%)] Loss: -1510.435791\n",
      "Train Epoch: 1428 [56832/60000 (95%)] Loss: -1365.100586\n",
      "    epoch          : 1428\n",
      "    loss           : -1331.3684573415983\n",
      "Train Epoch: 1429 [512/60000 (1%)] Loss: -1494.402832\n",
      "Train Epoch: 1429 [11776/60000 (20%)] Loss: -1348.684204\n",
      "Train Epoch: 1429 [23040/60000 (38%)] Loss: -1369.931030\n",
      "Train Epoch: 1429 [34304/60000 (57%)] Loss: -1518.245850\n",
      "Train Epoch: 1429 [45568/60000 (76%)] Loss: -1342.415894\n",
      "Train Epoch: 1429 [56832/60000 (95%)] Loss: -1381.364502\n",
      "    epoch          : 1429\n",
      "    loss           : -1345.9511325642213\n",
      "Train Epoch: 1430 [512/60000 (1%)] Loss: -1196.044678\n",
      "Train Epoch: 1430 [11776/60000 (20%)] Loss: -1373.335693\n",
      "Train Epoch: 1430 [23040/60000 (38%)] Loss: -1221.023071\n",
      "Train Epoch: 1430 [34304/60000 (57%)] Loss: -1200.556030\n",
      "Train Epoch: 1430 [45568/60000 (76%)] Loss: -1352.709961\n",
      "Train Epoch: 1430 [56832/60000 (95%)] Loss: -1082.035522\n",
      "    epoch          : 1430\n",
      "    loss           : -1340.6972839010639\n",
      "Train Epoch: 1431 [512/60000 (1%)] Loss: -1341.639893\n",
      "Train Epoch: 1431 [11776/60000 (20%)] Loss: -1216.978882\n",
      "Train Epoch: 1431 [23040/60000 (38%)] Loss: -1481.925171\n",
      "Train Epoch: 1431 [34304/60000 (57%)] Loss: -1522.095947\n",
      "Train Epoch: 1431 [45568/60000 (76%)] Loss: -1321.232300\n",
      "Train Epoch: 1431 [56832/60000 (95%)] Loss: -1241.826172\n",
      "    epoch          : 1431\n",
      "    loss           : -1329.768888484287\n",
      "Train Epoch: 1432 [512/60000 (1%)] Loss: -1357.691162\n",
      "Train Epoch: 1432 [11776/60000 (20%)] Loss: -1373.396973\n",
      "Train Epoch: 1432 [23040/60000 (38%)] Loss: -1367.983887\n",
      "Train Epoch: 1432 [34304/60000 (57%)] Loss: -1227.457520\n",
      "Train Epoch: 1432 [45568/60000 (76%)] Loss: -1235.878662\n",
      "Train Epoch: 1432 [56832/60000 (95%)] Loss: -1376.892334\n",
      "    epoch          : 1432\n",
      "    loss           : -1337.8175700559455\n",
      "Train Epoch: 1433 [512/60000 (1%)] Loss: -1473.123779\n",
      "Train Epoch: 1433 [11776/60000 (20%)] Loss: -1375.314453\n",
      "Train Epoch: 1433 [23040/60000 (38%)] Loss: -1489.427734\n",
      "Train Epoch: 1433 [34304/60000 (57%)] Loss: -1209.387939\n",
      "Train Epoch: 1433 [45568/60000 (76%)] Loss: -1345.676514\n",
      "Train Epoch: 1433 [56832/60000 (95%)] Loss: -1528.533203\n",
      "    epoch          : 1433\n",
      "    loss           : -1348.2167196327682\n",
      "Train Epoch: 1434 [512/60000 (1%)] Loss: -1366.929688\n",
      "Train Epoch: 1434 [11776/60000 (20%)] Loss: -1229.004639\n",
      "Train Epoch: 1434 [23040/60000 (38%)] Loss: -1100.958862\n",
      "Train Epoch: 1434 [34304/60000 (57%)] Loss: -1084.890625\n",
      "Train Epoch: 1434 [45568/60000 (76%)] Loss: -1240.424805\n",
      "Train Epoch: 1434 [56832/60000 (95%)] Loss: -1374.100098\n",
      "    epoch          : 1434\n",
      "    loss           : -1350.7195210429907\n",
      "Train Epoch: 1435 [512/60000 (1%)] Loss: -1357.764648\n",
      "Train Epoch: 1435 [11776/60000 (20%)] Loss: -1512.527222\n",
      "Train Epoch: 1435 [23040/60000 (38%)] Loss: -1472.210327\n",
      "Train Epoch: 1435 [34304/60000 (57%)] Loss: -1524.615723\n",
      "Train Epoch: 1435 [45568/60000 (76%)] Loss: -1104.482544\n",
      "Train Epoch: 1435 [56832/60000 (95%)] Loss: -1217.836548\n",
      "    epoch          : 1435\n",
      "    loss           : -1348.8233990857832\n",
      "Train Epoch: 1436 [512/60000 (1%)] Loss: -1213.184570\n",
      "Train Epoch: 1436 [11776/60000 (20%)] Loss: -1208.268555\n",
      "Train Epoch: 1436 [23040/60000 (38%)] Loss: -1389.202393\n",
      "Train Epoch: 1436 [34304/60000 (57%)] Loss: -1373.088379\n",
      "Train Epoch: 1436 [45568/60000 (76%)] Loss: -1355.068115\n",
      "Train Epoch: 1436 [56832/60000 (95%)] Loss: -1516.419678\n",
      "    epoch          : 1436\n",
      "    loss           : -1332.1749798618466\n",
      "Train Epoch: 1437 [512/60000 (1%)] Loss: -1199.919922\n",
      "Train Epoch: 1437 [11776/60000 (20%)] Loss: -1199.885132\n",
      "Train Epoch: 1437 [23040/60000 (38%)] Loss: -1245.909912\n",
      "Train Epoch: 1437 [34304/60000 (57%)] Loss: -1207.759277\n",
      "Train Epoch: 1437 [45568/60000 (76%)] Loss: -1359.323242\n",
      "Train Epoch: 1437 [56832/60000 (95%)] Loss: -1233.870605\n",
      "    epoch          : 1437\n",
      "    loss           : -1341.348423844677\n",
      "Train Epoch: 1438 [512/60000 (1%)] Loss: -1190.129883\n",
      "Train Epoch: 1438 [11776/60000 (20%)] Loss: -1345.320557\n",
      "Train Epoch: 1438 [23040/60000 (38%)] Loss: -1339.425171\n",
      "Train Epoch: 1438 [34304/60000 (57%)] Loss: -1110.240723\n",
      "Train Epoch: 1438 [45568/60000 (76%)] Loss: -1226.272217\n",
      "Train Epoch: 1438 [56832/60000 (95%)] Loss: -1350.392212\n",
      "    epoch          : 1438\n",
      "    loss           : -1354.222820562158\n",
      "Train Epoch: 1439 [512/60000 (1%)] Loss: -1468.857178\n",
      "Train Epoch: 1439 [11776/60000 (20%)] Loss: -1208.453857\n",
      "Train Epoch: 1439 [23040/60000 (38%)] Loss: -1339.856567\n",
      "Train Epoch: 1439 [34304/60000 (57%)] Loss: -1339.254883\n",
      "Train Epoch: 1439 [45568/60000 (76%)] Loss: -1085.605713\n",
      "Train Epoch: 1439 [56832/60000 (95%)] Loss: -1472.643921\n",
      "    epoch          : 1439\n",
      "    loss           : -1328.24744083383\n",
      "Train Epoch: 1440 [512/60000 (1%)] Loss: -1370.633545\n",
      "Train Epoch: 1440 [11776/60000 (20%)] Loss: -1334.394531\n",
      "Train Epoch: 1440 [23040/60000 (38%)] Loss: -1223.738403\n",
      "Train Epoch: 1440 [34304/60000 (57%)] Loss: -1344.242920\n",
      "Train Epoch: 1440 [45568/60000 (76%)] Loss: -1223.373169\n",
      "Train Epoch: 1440 [56832/60000 (95%)] Loss: -1223.458130\n",
      "    epoch          : 1440\n",
      "    loss           : -1323.599677306784\n",
      "Train Epoch: 1441 [512/60000 (1%)] Loss: -1470.361938\n",
      "Train Epoch: 1441 [11776/60000 (20%)] Loss: -1358.253906\n",
      "Train Epoch: 1441 [23040/60000 (38%)] Loss: -1482.900879\n",
      "Train Epoch: 1441 [34304/60000 (57%)] Loss: -1344.177002\n",
      "Train Epoch: 1441 [45568/60000 (76%)] Loss: -954.734131\n",
      "Train Epoch: 1441 [56832/60000 (95%)] Loss: -1494.583374\n",
      "    epoch          : 1441\n",
      "    loss           : -1316.7213722703145\n",
      "Train Epoch: 1442 [512/60000 (1%)] Loss: -1397.314697\n",
      "Train Epoch: 1442 [11776/60000 (20%)] Loss: -1110.783813\n",
      "Train Epoch: 1442 [23040/60000 (38%)] Loss: -1464.633301\n",
      "Train Epoch: 1442 [34304/60000 (57%)] Loss: -1398.690552\n",
      "Train Epoch: 1442 [45568/60000 (76%)] Loss: -1322.455566\n",
      "Train Epoch: 1442 [56832/60000 (95%)] Loss: -1186.241943\n",
      "    epoch          : 1442\n",
      "    loss           : -1343.0917920473605\n",
      "Train Epoch: 1443 [512/60000 (1%)] Loss: -1370.032715\n",
      "Train Epoch: 1443 [11776/60000 (20%)] Loss: -1248.704102\n",
      "Train Epoch: 1443 [23040/60000 (38%)] Loss: -1452.467773\n",
      "Train Epoch: 1443 [34304/60000 (57%)] Loss: -1200.083984\n",
      "Train Epoch: 1443 [45568/60000 (76%)] Loss: -1359.853271\n",
      "Train Epoch: 1443 [56832/60000 (95%)] Loss: -1211.294067\n",
      "    epoch          : 1443\n",
      "    loss           : -1337.1246630997307\n",
      "Train Epoch: 1444 [512/60000 (1%)] Loss: -1487.698364\n",
      "Train Epoch: 1444 [11776/60000 (20%)] Loss: -1494.113647\n",
      "Train Epoch: 1444 [23040/60000 (38%)] Loss: -1084.415283\n",
      "Train Epoch: 1444 [34304/60000 (57%)] Loss: -1475.303467\n",
      "Train Epoch: 1444 [45568/60000 (76%)] Loss: -1102.237427\n",
      "Train Epoch: 1444 [56832/60000 (95%)] Loss: -1388.667236\n",
      "    epoch          : 1444\n",
      "    loss           : -1345.294820494571\n",
      "Train Epoch: 1445 [512/60000 (1%)] Loss: -1233.500977\n",
      "Train Epoch: 1445 [11776/60000 (20%)] Loss: -1396.529297\n",
      "Train Epoch: 1445 [23040/60000 (38%)] Loss: -1370.811646\n",
      "Train Epoch: 1445 [34304/60000 (57%)] Loss: -1342.928955\n",
      "Train Epoch: 1445 [45568/60000 (76%)] Loss: -1488.209717\n",
      "Train Epoch: 1445 [56832/60000 (95%)] Loss: -1074.380127\n",
      "    epoch          : 1445\n",
      "    loss           : -1349.4733302229542\n",
      "Train Epoch: 1446 [512/60000 (1%)] Loss: -1505.353516\n",
      "Train Epoch: 1446 [11776/60000 (20%)] Loss: -1465.870850\n",
      "Train Epoch: 1446 [23040/60000 (38%)] Loss: -1469.772461\n",
      "Train Epoch: 1446 [34304/60000 (57%)] Loss: -1493.805176\n",
      "Train Epoch: 1446 [45568/60000 (76%)] Loss: -1384.355957\n",
      "Train Epoch: 1446 [56832/60000 (95%)] Loss: -1482.413330\n",
      "    epoch          : 1446\n",
      "    loss           : -1351.0194433179952\n",
      "Train Epoch: 1447 [512/60000 (1%)] Loss: -1360.890869\n",
      "Train Epoch: 1447 [11776/60000 (20%)] Loss: -1542.166992\n",
      "Train Epoch: 1447 [23040/60000 (38%)] Loss: -1210.337402\n",
      "Train Epoch: 1447 [34304/60000 (57%)] Loss: -1471.027710\n",
      "Train Epoch: 1447 [45568/60000 (76%)] Loss: -1528.020142\n",
      "Train Epoch: 1447 [56832/60000 (95%)] Loss: -1228.093262\n",
      "    epoch          : 1447\n",
      "    loss           : -1316.4585383355954\n",
      "Train Epoch: 1448 [512/60000 (1%)] Loss: -1337.979980\n",
      "Train Epoch: 1448 [11776/60000 (20%)] Loss: -1404.463745\n",
      "Train Epoch: 1448 [23040/60000 (38%)] Loss: -1443.261963\n",
      "Train Epoch: 1448 [34304/60000 (57%)] Loss: -1062.728516\n",
      "Train Epoch: 1448 [45568/60000 (76%)] Loss: -1320.383301\n",
      "Train Epoch: 1448 [56832/60000 (95%)] Loss: -1210.549316\n",
      "    epoch          : 1448\n",
      "    loss           : -1339.3345319672492\n",
      "Train Epoch: 1449 [512/60000 (1%)] Loss: -1188.874146\n",
      "Train Epoch: 1449 [11776/60000 (20%)] Loss: -1077.902954\n",
      "Train Epoch: 1449 [23040/60000 (38%)] Loss: -1177.289062\n",
      "Train Epoch: 1449 [34304/60000 (57%)] Loss: -1510.361816\n",
      "Train Epoch: 1449 [45568/60000 (76%)] Loss: -1471.460693\n",
      "Train Epoch: 1449 [56832/60000 (95%)] Loss: -1363.715576\n",
      "    epoch          : 1449\n",
      "    loss           : -1327.7256231792903\n",
      "Train Epoch: 1450 [512/60000 (1%)] Loss: -1516.248169\n",
      "Train Epoch: 1450 [11776/60000 (20%)] Loss: -1395.757324\n",
      "Train Epoch: 1450 [23040/60000 (38%)] Loss: -1355.351562\n",
      "Train Epoch: 1450 [34304/60000 (57%)] Loss: -1347.357666\n",
      "Train Epoch: 1450 [45568/60000 (76%)] Loss: -1472.182983\n",
      "Train Epoch: 1450 [56832/60000 (95%)] Loss: -1499.809692\n",
      "    epoch          : 1450\n",
      "    loss           : -1326.2977822513903\n",
      "Train Epoch: 1451 [512/60000 (1%)] Loss: -1168.820312\n",
      "Train Epoch: 1451 [11776/60000 (20%)] Loss: -1357.442993\n",
      "Train Epoch: 1451 [23040/60000 (38%)] Loss: -1493.296143\n",
      "Train Epoch: 1451 [34304/60000 (57%)] Loss: -1230.824707\n",
      "Train Epoch: 1451 [45568/60000 (76%)] Loss: -1503.791138\n",
      "Train Epoch: 1451 [56832/60000 (95%)] Loss: -1350.062988\n",
      "    epoch          : 1451\n",
      "    loss           : -1356.3045299120542\n",
      "Train Epoch: 1452 [512/60000 (1%)] Loss: -1358.601562\n",
      "Train Epoch: 1452 [11776/60000 (20%)] Loss: -1380.383057\n",
      "Train Epoch: 1452 [23040/60000 (38%)] Loss: -1461.040283\n",
      "Train Epoch: 1452 [34304/60000 (57%)] Loss: -1078.419800\n",
      "Train Epoch: 1452 [45568/60000 (76%)] Loss: -1383.543945\n",
      "Train Epoch: 1452 [56832/60000 (95%)] Loss: -1240.888062\n",
      "    epoch          : 1452\n",
      "    loss           : -1334.0451863606772\n",
      "Train Epoch: 1453 [512/60000 (1%)] Loss: -1316.619751\n",
      "Train Epoch: 1453 [11776/60000 (20%)] Loss: -1244.276367\n",
      "Train Epoch: 1453 [23040/60000 (38%)] Loss: -1540.842407\n",
      "Train Epoch: 1453 [34304/60000 (57%)] Loss: -1191.177002\n",
      "Train Epoch: 1453 [45568/60000 (76%)] Loss: -1361.018433\n",
      "Train Epoch: 1453 [56832/60000 (95%)] Loss: -1352.063965\n",
      "    epoch          : 1453\n",
      "    loss           : -1341.6193561446194\n",
      "Train Epoch: 1454 [512/60000 (1%)] Loss: -1354.534912\n",
      "Train Epoch: 1454 [11776/60000 (20%)] Loss: -1182.278320\n",
      "Train Epoch: 1454 [23040/60000 (38%)] Loss: -1316.473755\n",
      "Train Epoch: 1454 [34304/60000 (57%)] Loss: -1111.430786\n",
      "Train Epoch: 1454 [45568/60000 (76%)] Loss: -1216.511963\n",
      "Train Epoch: 1454 [56832/60000 (95%)] Loss: -1356.105713\n",
      "    epoch          : 1454\n",
      "    loss           : -1331.077664477677\n",
      "Train Epoch: 1455 [512/60000 (1%)] Loss: -1333.526001\n",
      "Train Epoch: 1455 [11776/60000 (20%)] Loss: -1108.677490\n",
      "Train Epoch: 1455 [23040/60000 (38%)] Loss: -1339.165771\n",
      "Train Epoch: 1455 [34304/60000 (57%)] Loss: -1491.968506\n",
      "Train Epoch: 1455 [45568/60000 (76%)] Loss: -1349.738892\n",
      "Train Epoch: 1455 [56832/60000 (95%)] Loss: -1505.019043\n",
      "    epoch          : 1455\n",
      "    loss           : -1345.8158445196636\n",
      "Train Epoch: 1456 [512/60000 (1%)] Loss: -1359.402344\n",
      "Train Epoch: 1456 [11776/60000 (20%)] Loss: -1399.768433\n",
      "Train Epoch: 1456 [23040/60000 (38%)] Loss: -1336.223633\n",
      "Train Epoch: 1456 [34304/60000 (57%)] Loss: -1344.478638\n",
      "Train Epoch: 1456 [45568/60000 (76%)] Loss: -1274.239624\n",
      "Train Epoch: 1456 [56832/60000 (95%)] Loss: -1496.542603\n",
      "    epoch          : 1456\n",
      "    loss           : -1330.7153282381046\n",
      "Train Epoch: 1457 [512/60000 (1%)] Loss: -1388.734863\n",
      "Train Epoch: 1457 [11776/60000 (20%)] Loss: -1374.913086\n",
      "Train Epoch: 1457 [23040/60000 (38%)] Loss: -1409.913330\n",
      "Train Epoch: 1457 [34304/60000 (57%)] Loss: -1511.795166\n",
      "Train Epoch: 1457 [45568/60000 (76%)] Loss: -1558.675293\n",
      "Train Epoch: 1457 [56832/60000 (95%)] Loss: -1348.049438\n",
      "    epoch          : 1457\n",
      "    loss           : -1341.7023834400932\n",
      "Train Epoch: 1458 [512/60000 (1%)] Loss: -1468.195312\n",
      "Train Epoch: 1458 [11776/60000 (20%)] Loss: -1209.768066\n",
      "Train Epoch: 1458 [23040/60000 (38%)] Loss: -1247.407715\n",
      "Train Epoch: 1458 [34304/60000 (57%)] Loss: -1305.983643\n",
      "Train Epoch: 1458 [45568/60000 (76%)] Loss: -1468.065918\n",
      "Train Epoch: 1458 [56832/60000 (95%)] Loss: -1254.662598\n",
      "    epoch          : 1458\n",
      "    loss           : -1347.0570758022159\n",
      "Train Epoch: 1459 [512/60000 (1%)] Loss: -1505.875488\n",
      "Train Epoch: 1459 [11776/60000 (20%)] Loss: -1376.290283\n",
      "Train Epoch: 1459 [23040/60000 (38%)] Loss: -1380.648438\n",
      "Train Epoch: 1459 [34304/60000 (57%)] Loss: -1068.351929\n",
      "Train Epoch: 1459 [45568/60000 (76%)] Loss: -1358.776855\n",
      "Train Epoch: 1459 [56832/60000 (95%)] Loss: -1374.457764\n",
      "    epoch          : 1459\n",
      "    loss           : -1354.8087292687367\n",
      "Train Epoch: 1460 [512/60000 (1%)] Loss: -1226.812012\n",
      "Train Epoch: 1460 [11776/60000 (20%)] Loss: -1351.496826\n",
      "Train Epoch: 1460 [23040/60000 (38%)] Loss: -1333.260864\n",
      "Train Epoch: 1460 [34304/60000 (57%)] Loss: -1214.840576\n",
      "Train Epoch: 1460 [45568/60000 (76%)] Loss: -1364.072144\n",
      "Train Epoch: 1460 [56832/60000 (95%)] Loss: -1379.409546\n",
      "    epoch          : 1460\n",
      "    loss           : -1340.9118614412296\n",
      "Train Epoch: 1461 [512/60000 (1%)] Loss: -1256.482056\n",
      "Train Epoch: 1461 [11776/60000 (20%)] Loss: -1183.258057\n",
      "Train Epoch: 1461 [23040/60000 (38%)] Loss: -1264.904419\n",
      "Train Epoch: 1461 [34304/60000 (57%)] Loss: -1063.987915\n",
      "Train Epoch: 1461 [45568/60000 (76%)] Loss: -1376.239258\n",
      "Train Epoch: 1461 [56832/60000 (95%)] Loss: -1521.803833\n",
      "    epoch          : 1461\n",
      "    loss           : -1351.2517584676796\n",
      "Train Epoch: 1462 [512/60000 (1%)] Loss: -1374.309326\n",
      "Train Epoch: 1462 [11776/60000 (20%)] Loss: -941.655273\n",
      "Train Epoch: 1462 [23040/60000 (38%)] Loss: -1458.496338\n",
      "Train Epoch: 1462 [34304/60000 (57%)] Loss: -1179.293823\n",
      "Train Epoch: 1462 [45568/60000 (76%)] Loss: -1350.045410\n",
      "Train Epoch: 1462 [56832/60000 (95%)] Loss: -1490.710693\n",
      "    epoch          : 1462\n",
      "    loss           : -1346.134199756687\n",
      "Train Epoch: 1463 [512/60000 (1%)] Loss: -1359.859375\n",
      "Train Epoch: 1463 [11776/60000 (20%)] Loss: -1229.117310\n",
      "Train Epoch: 1463 [23040/60000 (38%)] Loss: -1223.739868\n",
      "Train Epoch: 1463 [34304/60000 (57%)] Loss: -1456.356812\n",
      "Train Epoch: 1463 [45568/60000 (76%)] Loss: -1360.863892\n",
      "Train Epoch: 1463 [56832/60000 (95%)] Loss: -1252.705688\n",
      "    epoch          : 1463\n",
      "    loss           : -1341.7627716926531\n",
      "Train Epoch: 1464 [512/60000 (1%)] Loss: -1496.442139\n",
      "Train Epoch: 1464 [11776/60000 (20%)] Loss: -1105.249512\n",
      "Train Epoch: 1464 [23040/60000 (38%)] Loss: -1375.006958\n",
      "Train Epoch: 1464 [34304/60000 (57%)] Loss: -1371.326782\n",
      "Train Epoch: 1464 [45568/60000 (76%)] Loss: -1181.375244\n",
      "Train Epoch: 1464 [56832/60000 (95%)] Loss: -1214.717896\n",
      "    epoch          : 1464\n",
      "    loss           : -1352.9552681270966\n",
      "Train Epoch: 1465 [512/60000 (1%)] Loss: -1351.099731\n",
      "Train Epoch: 1465 [11776/60000 (20%)] Loss: -1254.176392\n",
      "Train Epoch: 1465 [23040/60000 (38%)] Loss: -1343.324463\n",
      "Train Epoch: 1465 [34304/60000 (57%)] Loss: -1488.389771\n",
      "Train Epoch: 1465 [45568/60000 (76%)] Loss: -1248.392090\n",
      "Train Epoch: 1465 [56832/60000 (95%)] Loss: -1341.067871\n",
      "    epoch          : 1465\n",
      "    loss           : -1339.0352390095338\n",
      "Train Epoch: 1466 [512/60000 (1%)] Loss: -1235.101562\n",
      "Train Epoch: 1466 [11776/60000 (20%)] Loss: -1508.933960\n",
      "Train Epoch: 1466 [23040/60000 (38%)] Loss: -1354.279297\n",
      "Train Epoch: 1466 [34304/60000 (57%)] Loss: -1363.092163\n",
      "Train Epoch: 1466 [45568/60000 (76%)] Loss: -1394.160156\n",
      "Train Epoch: 1466 [56832/60000 (95%)] Loss: -1334.578125\n",
      "    epoch          : 1466\n",
      "    loss           : -1319.402583407817\n",
      "Train Epoch: 1467 [512/60000 (1%)] Loss: -1323.612793\n",
      "Train Epoch: 1467 [11776/60000 (20%)] Loss: -1360.617432\n",
      "Train Epoch: 1467 [23040/60000 (38%)] Loss: -1227.851074\n",
      "Train Epoch: 1467 [34304/60000 (57%)] Loss: -1188.908813\n",
      "Train Epoch: 1467 [45568/60000 (76%)] Loss: -1184.369751\n",
      "Train Epoch: 1467 [56832/60000 (95%)] Loss: -1227.613770\n",
      "    epoch          : 1467\n",
      "    loss           : -1335.7491782667948\n",
      "Train Epoch: 1468 [512/60000 (1%)] Loss: -1508.259399\n",
      "Train Epoch: 1468 [11776/60000 (20%)] Loss: -1364.220947\n",
      "Train Epoch: 1468 [23040/60000 (38%)] Loss: -1352.726440\n",
      "Train Epoch: 1468 [34304/60000 (57%)] Loss: -1193.056885\n",
      "Train Epoch: 1468 [45568/60000 (76%)] Loss: -1533.786255\n",
      "Train Epoch: 1468 [56832/60000 (95%)] Loss: -1541.379639\n",
      "    epoch          : 1468\n",
      "    loss           : -1338.0993157510704\n",
      "Train Epoch: 1469 [512/60000 (1%)] Loss: -1192.129150\n",
      "Train Epoch: 1469 [11776/60000 (20%)] Loss: -1398.498901\n",
      "Train Epoch: 1469 [23040/60000 (38%)] Loss: -1340.786621\n",
      "Train Epoch: 1469 [34304/60000 (57%)] Loss: -1455.387695\n",
      "Train Epoch: 1469 [45568/60000 (76%)] Loss: -1506.860596\n",
      "Train Epoch: 1469 [56832/60000 (95%)] Loss: -1388.428223\n",
      "    epoch          : 1469\n",
      "    loss           : -1351.282940880727\n",
      "Train Epoch: 1470 [512/60000 (1%)] Loss: -1467.099121\n",
      "Train Epoch: 1470 [11776/60000 (20%)] Loss: -1182.617188\n",
      "Train Epoch: 1470 [23040/60000 (38%)] Loss: -1353.131958\n",
      "Train Epoch: 1470 [34304/60000 (57%)] Loss: -1077.330444\n",
      "Train Epoch: 1470 [45568/60000 (76%)] Loss: -1313.727051\n",
      "Train Epoch: 1470 [56832/60000 (95%)] Loss: -1341.602417\n",
      "    epoch          : 1470\n",
      "    loss           : -1342.532887604277\n",
      "Train Epoch: 1471 [512/60000 (1%)] Loss: -1509.645264\n",
      "Train Epoch: 1471 [11776/60000 (20%)] Loss: -1343.708740\n",
      "Train Epoch: 1471 [23040/60000 (38%)] Loss: -1241.240234\n",
      "Train Epoch: 1471 [34304/60000 (57%)] Loss: -1361.830566\n",
      "Train Epoch: 1471 [45568/60000 (76%)] Loss: -1352.434937\n",
      "Train Epoch: 1471 [56832/60000 (95%)] Loss: -1461.853882\n",
      "    epoch          : 1471\n",
      "    loss           : -1332.715506515934\n",
      "Train Epoch: 1472 [512/60000 (1%)] Loss: -1375.355469\n",
      "Train Epoch: 1472 [11776/60000 (20%)] Loss: -1497.710083\n",
      "Train Epoch: 1472 [23040/60000 (38%)] Loss: -1389.867188\n",
      "Train Epoch: 1472 [34304/60000 (57%)] Loss: -1372.442627\n",
      "Train Epoch: 1472 [45568/60000 (76%)] Loss: -1322.052124\n",
      "Train Epoch: 1472 [56832/60000 (95%)] Loss: -1387.140381\n",
      "    epoch          : 1472\n",
      "    loss           : -1322.0934030996204\n",
      "Train Epoch: 1473 [512/60000 (1%)] Loss: -1223.670898\n",
      "Train Epoch: 1473 [11776/60000 (20%)] Loss: -1513.656982\n",
      "Train Epoch: 1473 [23040/60000 (38%)] Loss: -1380.995117\n",
      "Train Epoch: 1473 [34304/60000 (57%)] Loss: -1087.276855\n",
      "Train Epoch: 1473 [45568/60000 (76%)] Loss: -1402.829834\n",
      "Train Epoch: 1473 [56832/60000 (95%)] Loss: -1244.774658\n",
      "    epoch          : 1473\n",
      "    loss           : -1345.1398815435205\n",
      "Train Epoch: 1474 [512/60000 (1%)] Loss: -1352.189575\n",
      "Train Epoch: 1474 [11776/60000 (20%)] Loss: -1353.958984\n",
      "Train Epoch: 1474 [23040/60000 (38%)] Loss: -1530.681519\n",
      "Train Epoch: 1474 [34304/60000 (57%)] Loss: -1384.765137\n",
      "Train Epoch: 1474 [45568/60000 (76%)] Loss: -1513.058838\n",
      "Train Epoch: 1474 [56832/60000 (95%)] Loss: -1266.779785\n",
      "    epoch          : 1474\n",
      "    loss           : -1342.4314564850372\n",
      "Train Epoch: 1475 [512/60000 (1%)] Loss: -1203.179443\n",
      "Train Epoch: 1475 [11776/60000 (20%)] Loss: -1503.104614\n",
      "Train Epoch: 1475 [23040/60000 (38%)] Loss: -1506.895874\n",
      "Train Epoch: 1475 [34304/60000 (57%)] Loss: -1508.848389\n",
      "Train Epoch: 1475 [45568/60000 (76%)] Loss: -1351.279053\n",
      "Train Epoch: 1475 [56832/60000 (95%)] Loss: -1214.697510\n",
      "    epoch          : 1475\n",
      "    loss           : -1337.230193919381\n",
      "Train Epoch: 1476 [512/60000 (1%)] Loss: -1352.148926\n",
      "Train Epoch: 1476 [11776/60000 (20%)] Loss: -1388.453125\n",
      "Train Epoch: 1476 [23040/60000 (38%)] Loss: -1243.821899\n",
      "Train Epoch: 1476 [34304/60000 (57%)] Loss: -1479.446899\n",
      "Train Epoch: 1476 [45568/60000 (76%)] Loss: -1236.091064\n",
      "Train Epoch: 1476 [56832/60000 (95%)] Loss: -1335.292603\n",
      "    epoch          : 1476\n",
      "    loss           : -1347.8357081871247\n",
      "Train Epoch: 1477 [512/60000 (1%)] Loss: -1224.157349\n",
      "Train Epoch: 1477 [11776/60000 (20%)] Loss: -1351.978394\n",
      "Train Epoch: 1477 [23040/60000 (38%)] Loss: -1394.956299\n",
      "Train Epoch: 1477 [34304/60000 (57%)] Loss: -1237.195068\n",
      "Train Epoch: 1477 [45568/60000 (76%)] Loss: -1378.786987\n",
      "Train Epoch: 1477 [56832/60000 (95%)] Loss: -1319.099854\n",
      "    epoch          : 1477\n",
      "    loss           : -1341.871283407265\n",
      "Train Epoch: 1478 [512/60000 (1%)] Loss: -1346.838501\n",
      "Train Epoch: 1478 [11776/60000 (20%)] Loss: -1506.156982\n",
      "Train Epoch: 1478 [23040/60000 (38%)] Loss: -1503.458862\n",
      "Train Epoch: 1478 [34304/60000 (57%)] Loss: -1076.123291\n",
      "Train Epoch: 1478 [45568/60000 (76%)] Loss: -1383.776367\n",
      "Train Epoch: 1478 [56832/60000 (95%)] Loss: -1479.718384\n",
      "    epoch          : 1478\n",
      "    loss           : -1353.247944804908\n",
      "Train Epoch: 1479 [512/60000 (1%)] Loss: -1508.480835\n",
      "Train Epoch: 1479 [11776/60000 (20%)] Loss: -1180.060547\n",
      "Train Epoch: 1479 [23040/60000 (38%)] Loss: -1368.469849\n",
      "Train Epoch: 1479 [34304/60000 (57%)] Loss: -1549.851440\n",
      "Train Epoch: 1479 [45568/60000 (76%)] Loss: -1361.840088\n",
      "Train Epoch: 1479 [56832/60000 (95%)] Loss: -1347.950195\n",
      "    epoch          : 1479\n",
      "    loss           : -1344.215115649552\n",
      "Train Epoch: 1480 [512/60000 (1%)] Loss: -1227.881836\n",
      "Train Epoch: 1480 [11776/60000 (20%)] Loss: -1541.386963\n",
      "Train Epoch: 1480 [23040/60000 (38%)] Loss: -1357.963745\n",
      "Train Epoch: 1480 [34304/60000 (57%)] Loss: -1217.600708\n",
      "Train Epoch: 1480 [45568/60000 (76%)] Loss: -1384.946777\n",
      "Train Epoch: 1480 [56832/60000 (95%)] Loss: -1057.362793\n",
      "    epoch          : 1480\n",
      "    loss           : -1347.1278348588673\n",
      "Train Epoch: 1481 [512/60000 (1%)] Loss: -1494.521484\n",
      "Train Epoch: 1481 [11776/60000 (20%)] Loss: -1378.144165\n",
      "Train Epoch: 1481 [23040/60000 (38%)] Loss: -1390.008911\n",
      "Train Epoch: 1481 [34304/60000 (57%)] Loss: -1360.611694\n",
      "Train Epoch: 1481 [45568/60000 (76%)] Loss: -1490.603027\n",
      "Train Epoch: 1481 [56832/60000 (95%)] Loss: -1358.901611\n",
      "    epoch          : 1481\n",
      "    loss           : -1367.9247081347105\n",
      "Train Epoch: 1482 [512/60000 (1%)] Loss: -1368.078613\n",
      "Train Epoch: 1482 [11776/60000 (20%)] Loss: -1072.504883\n",
      "Train Epoch: 1482 [23040/60000 (38%)] Loss: -1356.637207\n",
      "Train Epoch: 1482 [34304/60000 (57%)] Loss: -1367.343262\n",
      "Train Epoch: 1482 [45568/60000 (76%)] Loss: -1368.309448\n",
      "Train Epoch: 1482 [56832/60000 (95%)] Loss: -1512.763184\n",
      "    epoch          : 1482\n",
      "    loss           : -1345.3766127764168\n",
      "Train Epoch: 1483 [512/60000 (1%)] Loss: -1225.200806\n",
      "Train Epoch: 1483 [11776/60000 (20%)] Loss: -1383.170410\n",
      "Train Epoch: 1483 [23040/60000 (38%)] Loss: -1391.665039\n",
      "Train Epoch: 1483 [34304/60000 (57%)] Loss: -1083.146484\n",
      "Train Epoch: 1483 [45568/60000 (76%)] Loss: -1208.292236\n",
      "Train Epoch: 1483 [56832/60000 (95%)] Loss: -1264.777466\n",
      "    epoch          : 1483\n",
      "    loss           : -1317.8402034091412\n",
      "Train Epoch: 1484 [512/60000 (1%)] Loss: -1058.606445\n",
      "Train Epoch: 1484 [11776/60000 (20%)] Loss: -1383.851929\n",
      "Train Epoch: 1484 [23040/60000 (38%)] Loss: -1347.929565\n",
      "Train Epoch: 1484 [34304/60000 (57%)] Loss: -1334.808960\n",
      "Train Epoch: 1484 [45568/60000 (76%)] Loss: -1093.517700\n",
      "Train Epoch: 1484 [56832/60000 (95%)] Loss: -1417.670166\n",
      "    epoch          : 1484\n",
      "    loss           : -1328.6120039945267\n",
      "Train Epoch: 1485 [512/60000 (1%)] Loss: -1219.238281\n",
      "Train Epoch: 1485 [11776/60000 (20%)] Loss: -1244.003296\n",
      "Train Epoch: 1485 [23040/60000 (38%)] Loss: -1237.802246\n",
      "Train Epoch: 1485 [34304/60000 (57%)] Loss: -1346.160645\n",
      "Train Epoch: 1485 [45568/60000 (76%)] Loss: -1073.236450\n",
      "Train Epoch: 1485 [56832/60000 (95%)] Loss: -1491.052246\n",
      "    epoch          : 1485\n",
      "    loss           : -1342.4546826033943\n",
      "Train Epoch: 1486 [512/60000 (1%)] Loss: -1484.174194\n",
      "Train Epoch: 1486 [11776/60000 (20%)] Loss: -1239.616699\n",
      "Train Epoch: 1486 [23040/60000 (38%)] Loss: -1431.613647\n",
      "Train Epoch: 1486 [34304/60000 (57%)] Loss: -1353.337891\n",
      "Train Epoch: 1486 [45568/60000 (76%)] Loss: -1382.094604\n",
      "Train Epoch: 1486 [56832/60000 (95%)] Loss: -1471.180908\n",
      "    epoch          : 1486\n",
      "    loss           : -1357.3252697960804\n",
      "Train Epoch: 1487 [512/60000 (1%)] Loss: -1468.715698\n",
      "Train Epoch: 1487 [11776/60000 (20%)] Loss: -1553.356567\n",
      "Train Epoch: 1487 [23040/60000 (38%)] Loss: -1399.173828\n",
      "Train Epoch: 1487 [34304/60000 (57%)] Loss: -1493.935303\n",
      "Train Epoch: 1487 [45568/60000 (76%)] Loss: -1064.859619\n",
      "Train Epoch: 1487 [56832/60000 (95%)] Loss: -1371.895630\n",
      "    epoch          : 1487\n",
      "    loss           : -1353.5392164672162\n",
      "Train Epoch: 1488 [512/60000 (1%)] Loss: -1304.017456\n",
      "Train Epoch: 1488 [11776/60000 (20%)] Loss: -1238.196899\n",
      "Train Epoch: 1488 [23040/60000 (38%)] Loss: -1071.108765\n",
      "Train Epoch: 1488 [34304/60000 (57%)] Loss: -1403.901367\n",
      "Train Epoch: 1488 [45568/60000 (76%)] Loss: -1205.352051\n",
      "Train Epoch: 1488 [56832/60000 (95%)] Loss: -1256.482178\n",
      "    epoch          : 1488\n",
      "    loss           : -1351.1492602676994\n",
      "Train Epoch: 1489 [512/60000 (1%)] Loss: -1244.137207\n",
      "Train Epoch: 1489 [11776/60000 (20%)] Loss: -1481.323242\n",
      "Train Epoch: 1489 [23040/60000 (38%)] Loss: -1339.139160\n",
      "Train Epoch: 1489 [34304/60000 (57%)] Loss: -1362.666504\n",
      "Train Epoch: 1489 [45568/60000 (76%)] Loss: -1487.400513\n",
      "Train Epoch: 1489 [56832/60000 (95%)] Loss: -1110.690552\n",
      "    epoch          : 1489\n",
      "    loss           : -1331.9922999150335\n",
      "Train Epoch: 1490 [512/60000 (1%)] Loss: -1352.644043\n",
      "Train Epoch: 1490 [11776/60000 (20%)] Loss: -1371.516846\n",
      "Train Epoch: 1490 [23040/60000 (38%)] Loss: -1359.305664\n",
      "Train Epoch: 1490 [34304/60000 (57%)] Loss: -1379.546143\n",
      "Train Epoch: 1490 [45568/60000 (76%)] Loss: -1520.934204\n",
      "Train Epoch: 1490 [56832/60000 (95%)] Loss: -1475.650635\n",
      "    epoch          : 1490\n",
      "    loss           : -1325.9186194468352\n",
      "Train Epoch: 1491 [512/60000 (1%)] Loss: -1536.090332\n",
      "Train Epoch: 1491 [11776/60000 (20%)] Loss: -1391.033691\n",
      "Train Epoch: 1491 [23040/60000 (38%)] Loss: -1477.149414\n",
      "Train Epoch: 1491 [34304/60000 (57%)] Loss: -1533.394165\n",
      "Train Epoch: 1491 [45568/60000 (76%)] Loss: -1390.780518\n",
      "Train Epoch: 1491 [56832/60000 (95%)] Loss: -1075.709595\n",
      "    epoch          : 1491\n",
      "    loss           : -1361.0606530830685\n",
      "Train Epoch: 1492 [512/60000 (1%)] Loss: -1506.384033\n",
      "Train Epoch: 1492 [11776/60000 (20%)] Loss: -1512.485840\n",
      "Train Epoch: 1492 [23040/60000 (38%)] Loss: -1515.997314\n",
      "Train Epoch: 1492 [34304/60000 (57%)] Loss: -1118.166138\n",
      "Train Epoch: 1492 [45568/60000 (76%)] Loss: -1362.273193\n",
      "Train Epoch: 1492 [56832/60000 (95%)] Loss: -1231.459961\n",
      "    epoch          : 1492\n",
      "    loss           : -1356.4601147323006\n",
      "Train Epoch: 1493 [512/60000 (1%)] Loss: -1247.270996\n",
      "Train Epoch: 1493 [11776/60000 (20%)] Loss: -1373.244385\n",
      "Train Epoch: 1493 [23040/60000 (38%)] Loss: -1373.649658\n",
      "Train Epoch: 1493 [34304/60000 (57%)] Loss: -1095.306030\n",
      "Train Epoch: 1493 [45568/60000 (76%)] Loss: -1192.628418\n",
      "Train Epoch: 1493 [56832/60000 (95%)] Loss: -1539.271973\n",
      "    epoch          : 1493\n",
      "    loss           : -1321.2322282521736\n",
      "Train Epoch: 1494 [512/60000 (1%)] Loss: -1058.367798\n",
      "Train Epoch: 1494 [11776/60000 (20%)] Loss: -1249.833496\n",
      "Train Epoch: 1494 [23040/60000 (38%)] Loss: -1338.174927\n",
      "Train Epoch: 1494 [34304/60000 (57%)] Loss: -1213.065186\n",
      "Train Epoch: 1494 [45568/60000 (76%)] Loss: -1352.590088\n",
      "Train Epoch: 1494 [56832/60000 (95%)] Loss: -1349.451782\n",
      "    epoch          : 1494\n",
      "    loss           : -1364.5689917957714\n",
      "Train Epoch: 1495 [512/60000 (1%)] Loss: -1370.978638\n",
      "Train Epoch: 1495 [11776/60000 (20%)] Loss: -1385.117798\n",
      "Train Epoch: 1495 [23040/60000 (38%)] Loss: -1507.626587\n",
      "Train Epoch: 1495 [34304/60000 (57%)] Loss: -1233.407959\n",
      "Train Epoch: 1495 [45568/60000 (76%)] Loss: -1510.156982\n",
      "Train Epoch: 1495 [56832/60000 (95%)] Loss: -1381.867920\n",
      "    epoch          : 1495\n",
      "    loss           : -1340.0967264121537\n",
      "Train Epoch: 1496 [512/60000 (1%)] Loss: -1467.771484\n",
      "Train Epoch: 1496 [11776/60000 (20%)] Loss: -1485.296021\n",
      "Train Epoch: 1496 [23040/60000 (38%)] Loss: -1366.943359\n",
      "Train Epoch: 1496 [34304/60000 (57%)] Loss: -1380.333008\n",
      "Train Epoch: 1496 [45568/60000 (76%)] Loss: -1245.135010\n",
      "Train Epoch: 1496 [56832/60000 (95%)] Loss: -1499.756958\n",
      "    epoch          : 1496\n",
      "    loss           : -1338.6258241470252\n",
      "Train Epoch: 1497 [512/60000 (1%)] Loss: -1349.298584\n",
      "Train Epoch: 1497 [11776/60000 (20%)] Loss: -1230.818604\n",
      "Train Epoch: 1497 [23040/60000 (38%)] Loss: -1485.003418\n",
      "Train Epoch: 1497 [34304/60000 (57%)] Loss: -1235.157471\n",
      "Train Epoch: 1497 [45568/60000 (76%)] Loss: -1229.122314\n",
      "Train Epoch: 1497 [56832/60000 (95%)] Loss: -1538.517822\n",
      "    epoch          : 1497\n",
      "    loss           : -1351.5405025158898\n",
      "Train Epoch: 1498 [512/60000 (1%)] Loss: -1497.143555\n",
      "Train Epoch: 1498 [11776/60000 (20%)] Loss: -1248.802490\n",
      "Train Epoch: 1498 [23040/60000 (38%)] Loss: -1374.041382\n",
      "Train Epoch: 1498 [34304/60000 (57%)] Loss: -1374.098877\n",
      "Train Epoch: 1498 [45568/60000 (76%)] Loss: -1377.289307\n",
      "Train Epoch: 1498 [56832/60000 (95%)] Loss: -1498.046143\n",
      "    epoch          : 1498\n",
      "    loss           : -1342.92900214761\n",
      "Train Epoch: 1499 [512/60000 (1%)] Loss: -1335.547363\n",
      "Train Epoch: 1499 [11776/60000 (20%)] Loss: -1351.373413\n",
      "Train Epoch: 1499 [23040/60000 (38%)] Loss: -1319.971191\n",
      "Train Epoch: 1499 [34304/60000 (57%)] Loss: -1189.772705\n",
      "Train Epoch: 1499 [45568/60000 (76%)] Loss: -1263.972900\n",
      "Train Epoch: 1499 [56832/60000 (95%)] Loss: -1387.827148\n",
      "    epoch          : 1499\n",
      "    loss           : -1323.388072558042\n",
      "Train Epoch: 1500 [512/60000 (1%)] Loss: -1565.661621\n",
      "Train Epoch: 1500 [11776/60000 (20%)] Loss: -1213.124146\n",
      "Train Epoch: 1500 [23040/60000 (38%)] Loss: -1342.330078\n",
      "Train Epoch: 1500 [34304/60000 (57%)] Loss: -1265.842896\n",
      "Train Epoch: 1500 [45568/60000 (76%)] Loss: -1354.755005\n",
      "Train Epoch: 1500 [56832/60000 (95%)] Loss: -1356.115723\n",
      "    epoch          : 1500\n",
      "    loss           : -1338.6307907535531\n",
      "Saving checkpoint: saved/models/Mnist_DeepGenerativeOperad/0127_111843/checkpoint-epoch1500.pth ...\n",
      "Train Epoch: 1501 [512/60000 (1%)] Loss: -1498.945923\n",
      "Train Epoch: 1501 [11776/60000 (20%)] Loss: -1378.874512\n",
      "Train Epoch: 1501 [23040/60000 (38%)] Loss: -1365.822754\n",
      "Train Epoch: 1501 [34304/60000 (57%)] Loss: -1223.275757\n",
      "Train Epoch: 1501 [45568/60000 (76%)] Loss: -1087.777100\n",
      "Train Epoch: 1501 [56832/60000 (95%)] Loss: -1505.737427\n",
      "    epoch          : 1501\n",
      "    loss           : -1336.061864475746\n",
      "Train Epoch: 1502 [512/60000 (1%)] Loss: -1526.342285\n",
      "Train Epoch: 1502 [11776/60000 (20%)] Loss: -1340.774902\n",
      "Train Epoch: 1502 [23040/60000 (38%)] Loss: -1214.614258\n",
      "Train Epoch: 1502 [34304/60000 (57%)] Loss: -1247.624268\n",
      "Train Epoch: 1502 [45568/60000 (76%)] Loss: -1378.448364\n",
      "Train Epoch: 1502 [56832/60000 (95%)] Loss: -1515.583618\n",
      "    epoch          : 1502\n",
      "    loss           : -1347.5134780797582\n",
      "Train Epoch: 1503 [512/60000 (1%)] Loss: -1481.962769\n",
      "Train Epoch: 1503 [11776/60000 (20%)] Loss: -1200.590576\n",
      "Train Epoch: 1503 [23040/60000 (38%)] Loss: -1508.005127\n",
      "Train Epoch: 1503 [34304/60000 (57%)] Loss: -1388.264648\n",
      "Train Epoch: 1503 [45568/60000 (76%)] Loss: -1390.099365\n",
      "Train Epoch: 1503 [56832/60000 (95%)] Loss: -1478.735962\n",
      "    epoch          : 1503\n",
      "    loss           : -1367.2426647466455\n",
      "Train Epoch: 1504 [512/60000 (1%)] Loss: -1512.527344\n",
      "Train Epoch: 1504 [11776/60000 (20%)] Loss: -1474.932373\n",
      "Train Epoch: 1504 [23040/60000 (38%)] Loss: -1521.135254\n",
      "Train Epoch: 1504 [34304/60000 (57%)] Loss: -1529.298584\n",
      "Train Epoch: 1504 [45568/60000 (76%)] Loss: -1349.120972\n",
      "Train Epoch: 1504 [56832/60000 (95%)] Loss: -1383.425537\n",
      "    epoch          : 1504\n",
      "    loss           : -1351.4681441312455\n",
      "Train Epoch: 1505 [512/60000 (1%)] Loss: -1450.576782\n",
      "Train Epoch: 1505 [11776/60000 (20%)] Loss: -1351.966431\n",
      "Train Epoch: 1505 [23040/60000 (38%)] Loss: -1337.339844\n",
      "Train Epoch: 1505 [34304/60000 (57%)] Loss: -1113.436279\n",
      "Train Epoch: 1505 [45568/60000 (76%)] Loss: -1231.709473\n",
      "Train Epoch: 1505 [56832/60000 (95%)] Loss: -1385.437744\n",
      "    epoch          : 1505\n",
      "    loss           : -1356.7828131206966\n",
      "Train Epoch: 1506 [512/60000 (1%)] Loss: -1234.978271\n",
      "Train Epoch: 1506 [11776/60000 (20%)] Loss: -1344.064941\n",
      "Train Epoch: 1506 [23040/60000 (38%)] Loss: -1247.684692\n",
      "Train Epoch: 1506 [34304/60000 (57%)] Loss: -1232.246338\n",
      "Train Epoch: 1506 [45568/60000 (76%)] Loss: -1406.245483\n",
      "Train Epoch: 1506 [56832/60000 (95%)] Loss: -1359.238159\n",
      "    epoch          : 1506\n",
      "    loss           : -1352.4380667303915\n",
      "Train Epoch: 1507 [512/60000 (1%)] Loss: -1357.469971\n",
      "Train Epoch: 1507 [11776/60000 (20%)] Loss: -1450.840576\n",
      "Train Epoch: 1507 [23040/60000 (38%)] Loss: -1261.209106\n",
      "Train Epoch: 1507 [34304/60000 (57%)] Loss: -1375.789307\n",
      "Train Epoch: 1507 [45568/60000 (76%)] Loss: -1250.114990\n",
      "Train Epoch: 1507 [56832/60000 (95%)] Loss: -1381.244141\n",
      "    epoch          : 1507\n",
      "    loss           : -1346.8162809037892\n",
      "Train Epoch: 1508 [512/60000 (1%)] Loss: -1504.889282\n",
      "Train Epoch: 1508 [11776/60000 (20%)] Loss: -1222.160522\n",
      "Train Epoch: 1508 [23040/60000 (38%)] Loss: -1540.774414\n",
      "Train Epoch: 1508 [34304/60000 (57%)] Loss: -1337.774048\n",
      "Train Epoch: 1508 [45568/60000 (76%)] Loss: -1377.905762\n",
      "Train Epoch: 1508 [56832/60000 (95%)] Loss: -908.311401\n",
      "    epoch          : 1508\n",
      "    loss           : -1341.9169501180702\n",
      "Train Epoch: 1509 [512/60000 (1%)] Loss: -1312.944336\n",
      "Train Epoch: 1509 [11776/60000 (20%)] Loss: -1472.292480\n",
      "Train Epoch: 1509 [23040/60000 (38%)] Loss: -1220.750488\n",
      "Train Epoch: 1509 [34304/60000 (57%)] Loss: -1335.471680\n",
      "Train Epoch: 1509 [45568/60000 (76%)] Loss: -1226.912720\n",
      "Train Epoch: 1509 [56832/60000 (95%)] Loss: -1238.907104\n",
      "    epoch          : 1509\n",
      "    loss           : -1337.897322660112\n",
      "Train Epoch: 1510 [512/60000 (1%)] Loss: -1421.497437\n",
      "Train Epoch: 1510 [11776/60000 (20%)] Loss: -1227.016968\n",
      "Train Epoch: 1510 [23040/60000 (38%)] Loss: -1188.520020\n",
      "Train Epoch: 1510 [34304/60000 (57%)] Loss: -1371.630249\n",
      "Train Epoch: 1510 [45568/60000 (76%)] Loss: -1511.528809\n",
      "Train Epoch: 1510 [56832/60000 (95%)] Loss: -1206.154297\n",
      "    epoch          : 1510\n",
      "    loss           : -1331.7257338701668\n",
      "Train Epoch: 1511 [512/60000 (1%)] Loss: -1230.028564\n",
      "Train Epoch: 1511 [11776/60000 (20%)] Loss: -1356.614136\n",
      "Train Epoch: 1511 [23040/60000 (38%)] Loss: -1513.229492\n",
      "Train Epoch: 1511 [34304/60000 (57%)] Loss: -1368.295654\n",
      "Train Epoch: 1511 [45568/60000 (76%)] Loss: -1225.334229\n",
      "Train Epoch: 1511 [56832/60000 (95%)] Loss: -1201.537476\n",
      "    epoch          : 1511\n",
      "    loss           : -1345.3352807686153\n",
      "Train Epoch: 1512 [512/60000 (1%)] Loss: -1521.569092\n",
      "Train Epoch: 1512 [11776/60000 (20%)] Loss: -1494.517334\n",
      "Train Epoch: 1512 [23040/60000 (38%)] Loss: -1548.360840\n",
      "Train Epoch: 1512 [34304/60000 (57%)] Loss: -1370.328979\n",
      "Train Epoch: 1512 [45568/60000 (76%)] Loss: -1470.971924\n",
      "Train Epoch: 1512 [56832/60000 (95%)] Loss: -1366.604370\n",
      "    epoch          : 1512\n",
      "    loss           : -1363.1125429659912\n",
      "Train Epoch: 1513 [512/60000 (1%)] Loss: -1231.795532\n",
      "Train Epoch: 1513 [11776/60000 (20%)] Loss: -1370.147827\n",
      "Train Epoch: 1513 [23040/60000 (38%)] Loss: -1501.334717\n",
      "Train Epoch: 1513 [34304/60000 (57%)] Loss: -1411.780518\n",
      "Train Epoch: 1513 [45568/60000 (76%)] Loss: -1098.957764\n",
      "Train Epoch: 1513 [56832/60000 (95%)] Loss: -1093.325317\n",
      "    epoch          : 1513\n",
      "    loss           : -1338.7467880680063\n",
      "Train Epoch: 1514 [512/60000 (1%)] Loss: -1474.348389\n",
      "Train Epoch: 1514 [11776/60000 (20%)] Loss: -1487.543945\n",
      "Train Epoch: 1514 [23040/60000 (38%)] Loss: -1333.777954\n",
      "Train Epoch: 1514 [34304/60000 (57%)] Loss: -1347.979736\n",
      "Train Epoch: 1514 [45568/60000 (76%)] Loss: -1335.871094\n",
      "Train Epoch: 1514 [56832/60000 (95%)] Loss: -1380.128418\n",
      "    epoch          : 1514\n",
      "    loss           : -1365.275290279065\n",
      "Train Epoch: 1515 [512/60000 (1%)] Loss: -1437.007324\n",
      "Train Epoch: 1515 [11776/60000 (20%)] Loss: -1207.173706\n",
      "Train Epoch: 1515 [23040/60000 (38%)] Loss: -1187.058105\n",
      "Train Epoch: 1515 [34304/60000 (57%)] Loss: -1253.803833\n",
      "Train Epoch: 1515 [45568/60000 (76%)] Loss: -1392.398560\n",
      "Train Epoch: 1515 [56832/60000 (95%)] Loss: -1384.661499\n",
      "    epoch          : 1515\n",
      "    loss           : -1369.4853715627205\n",
      "Train Epoch: 1516 [512/60000 (1%)] Loss: -1199.843506\n",
      "Train Epoch: 1516 [11776/60000 (20%)] Loss: -1390.636841\n",
      "Train Epoch: 1516 [23040/60000 (38%)] Loss: -1194.915649\n",
      "Train Epoch: 1516 [34304/60000 (57%)] Loss: -1239.298584\n",
      "Train Epoch: 1516 [45568/60000 (76%)] Loss: -1358.456787\n",
      "Train Epoch: 1516 [56832/60000 (95%)] Loss: -1398.299561\n",
      "    epoch          : 1516\n",
      "    loss           : -1360.1522558179952\n",
      "Train Epoch: 1517 [512/60000 (1%)] Loss: -1382.012939\n",
      "Train Epoch: 1517 [11776/60000 (20%)] Loss: -1489.984009\n",
      "Train Epoch: 1517 [23040/60000 (38%)] Loss: -1075.082886\n",
      "Train Epoch: 1517 [34304/60000 (57%)] Loss: -1086.488525\n",
      "Train Epoch: 1517 [45568/60000 (76%)] Loss: -1351.537354\n",
      "Train Epoch: 1517 [56832/60000 (95%)] Loss: -1082.725708\n",
      "    epoch          : 1517\n",
      "    loss           : -1349.3721180716477\n",
      "Train Epoch: 1518 [512/60000 (1%)] Loss: -1354.070557\n",
      "Train Epoch: 1518 [11776/60000 (20%)] Loss: -1374.205688\n",
      "Train Epoch: 1518 [23040/60000 (38%)] Loss: -1060.539062\n",
      "Train Epoch: 1518 [34304/60000 (57%)] Loss: -1551.758179\n",
      "Train Epoch: 1518 [45568/60000 (76%)] Loss: -1521.537598\n",
      "Train Epoch: 1518 [56832/60000 (95%)] Loss: -1225.117310\n",
      "    epoch          : 1518\n",
      "    loss           : -1350.9834322309764\n",
      "Train Epoch: 1519 [512/60000 (1%)] Loss: -1225.813965\n",
      "Train Epoch: 1519 [11776/60000 (20%)] Loss: -1371.725708\n",
      "Train Epoch: 1519 [23040/60000 (38%)] Loss: -1354.763916\n",
      "Train Epoch: 1519 [34304/60000 (57%)] Loss: -1206.959839\n",
      "Train Epoch: 1519 [45568/60000 (76%)] Loss: -1363.703857\n",
      "Train Epoch: 1519 [56832/60000 (95%)] Loss: -1084.203979\n",
      "    epoch          : 1519\n",
      "    loss           : -1336.3551973676952\n",
      "Train Epoch: 1520 [512/60000 (1%)] Loss: -1399.416992\n",
      "Train Epoch: 1520 [11776/60000 (20%)] Loss: -1519.426758\n",
      "Train Epoch: 1520 [23040/60000 (38%)] Loss: -1382.624756\n",
      "Train Epoch: 1520 [34304/60000 (57%)] Loss: -1402.745850\n",
      "Train Epoch: 1520 [45568/60000 (76%)] Loss: -1386.688721\n",
      "Train Epoch: 1520 [56832/60000 (95%)] Loss: -1545.687256\n",
      "    epoch          : 1520\n",
      "    loss           : -1355.2048258808375\n",
      "Train Epoch: 1521 [512/60000 (1%)] Loss: -1511.625244\n",
      "Train Epoch: 1521 [11776/60000 (20%)] Loss: -1366.841553\n",
      "Train Epoch: 1521 [23040/60000 (38%)] Loss: -1375.981445\n",
      "Train Epoch: 1521 [34304/60000 (57%)] Loss: -1237.012451\n",
      "Train Epoch: 1521 [45568/60000 (76%)] Loss: -1203.029175\n",
      "Train Epoch: 1521 [56832/60000 (95%)] Loss: -1515.219360\n",
      "    epoch          : 1521\n",
      "    loss           : -1353.9560531357588\n",
      "Train Epoch: 1522 [512/60000 (1%)] Loss: -1124.228027\n",
      "Train Epoch: 1522 [11776/60000 (20%)] Loss: -1499.629761\n",
      "Train Epoch: 1522 [23040/60000 (38%)] Loss: -1494.018066\n",
      "Train Epoch: 1522 [34304/60000 (57%)] Loss: -1401.503906\n",
      "Train Epoch: 1522 [45568/60000 (76%)] Loss: -1337.122681\n",
      "Train Epoch: 1522 [56832/60000 (95%)] Loss: -1369.391357\n",
      "    epoch          : 1522\n",
      "    loss           : -1339.7978970802437\n",
      "Train Epoch: 1523 [512/60000 (1%)] Loss: -1351.636963\n",
      "Train Epoch: 1523 [11776/60000 (20%)] Loss: -1405.339355\n",
      "Train Epoch: 1523 [23040/60000 (38%)] Loss: -1507.938477\n",
      "Train Epoch: 1523 [34304/60000 (57%)] Loss: -1244.629883\n",
      "Train Epoch: 1523 [45568/60000 (76%)] Loss: -1230.833130\n",
      "Train Epoch: 1523 [56832/60000 (95%)] Loss: -1253.488892\n",
      "    epoch          : 1523\n",
      "    loss           : -1340.5879830398128\n",
      "Train Epoch: 1524 [512/60000 (1%)] Loss: -1085.776001\n",
      "Train Epoch: 1524 [11776/60000 (20%)] Loss: -1374.777588\n",
      "Train Epoch: 1524 [23040/60000 (38%)] Loss: -1375.903198\n",
      "Train Epoch: 1524 [34304/60000 (57%)] Loss: -1240.858887\n",
      "Train Epoch: 1524 [45568/60000 (76%)] Loss: -1379.299561\n",
      "Train Epoch: 1524 [56832/60000 (95%)] Loss: -1362.708618\n",
      "    epoch          : 1524\n",
      "    loss           : -1341.3603262173926\n",
      "Train Epoch: 1525 [512/60000 (1%)] Loss: -1368.000977\n",
      "Train Epoch: 1525 [11776/60000 (20%)] Loss: -1387.080322\n",
      "Train Epoch: 1525 [23040/60000 (38%)] Loss: -1372.479004\n",
      "Train Epoch: 1525 [34304/60000 (57%)] Loss: -1367.550049\n",
      "Train Epoch: 1525 [45568/60000 (76%)] Loss: -1226.959717\n",
      "Train Epoch: 1525 [56832/60000 (95%)] Loss: -1215.344238\n",
      "    epoch          : 1525\n",
      "    loss           : -1340.1983621888241\n",
      "Train Epoch: 1526 [512/60000 (1%)] Loss: -1349.365234\n",
      "Train Epoch: 1526 [11776/60000 (20%)] Loss: -1398.080078\n",
      "Train Epoch: 1526 [23040/60000 (38%)] Loss: -1329.183960\n",
      "Train Epoch: 1526 [34304/60000 (57%)] Loss: -1447.528320\n",
      "Train Epoch: 1526 [45568/60000 (76%)] Loss: -1348.435913\n",
      "Train Epoch: 1526 [56832/60000 (95%)] Loss: -1375.624512\n",
      "    epoch          : 1526\n",
      "    loss           : -1346.8913579391221\n",
      "Train Epoch: 1527 [512/60000 (1%)] Loss: -1543.518677\n",
      "Train Epoch: 1527 [11776/60000 (20%)] Loss: -1253.606201\n",
      "Train Epoch: 1527 [23040/60000 (38%)] Loss: -1488.420410\n",
      "Train Epoch: 1527 [34304/60000 (57%)] Loss: -1516.430786\n",
      "Train Epoch: 1527 [45568/60000 (76%)] Loss: -1493.187744\n",
      "Train Epoch: 1527 [56832/60000 (95%)] Loss: -1392.101807\n",
      "    epoch          : 1527\n",
      "    loss           : -1344.0639896716102\n",
      "Train Epoch: 1528 [512/60000 (1%)] Loss: -1365.210327\n",
      "Train Epoch: 1528 [11776/60000 (20%)] Loss: -1377.324463\n",
      "Train Epoch: 1528 [23040/60000 (38%)] Loss: -1244.411133\n",
      "Train Epoch: 1528 [34304/60000 (57%)] Loss: -1342.281738\n",
      "Train Epoch: 1528 [45568/60000 (76%)] Loss: -1493.556763\n",
      "Train Epoch: 1528 [56832/60000 (95%)] Loss: -1522.943604\n",
      "    epoch          : 1528\n",
      "    loss           : -1364.157399323027\n",
      "Train Epoch: 1529 [512/60000 (1%)] Loss: -1354.119141\n",
      "Train Epoch: 1529 [11776/60000 (20%)] Loss: -1370.116455\n",
      "Train Epoch: 1529 [23040/60000 (38%)] Loss: -1365.084961\n",
      "Train Epoch: 1529 [34304/60000 (57%)] Loss: -1394.522217\n",
      "Train Epoch: 1529 [45568/60000 (76%)] Loss: -1206.857666\n",
      "Train Epoch: 1529 [56832/60000 (95%)] Loss: -1210.497559\n",
      "    epoch          : 1529\n",
      "    loss           : -1338.5706250896562\n",
      "Train Epoch: 1530 [512/60000 (1%)] Loss: -1366.705322\n",
      "Train Epoch: 1530 [11776/60000 (20%)] Loss: -1237.708252\n",
      "Train Epoch: 1530 [23040/60000 (38%)] Loss: -1363.480225\n",
      "Train Epoch: 1530 [34304/60000 (57%)] Loss: -1354.656738\n",
      "Train Epoch: 1530 [45568/60000 (76%)] Loss: -1519.211670\n",
      "Train Epoch: 1530 [56832/60000 (95%)] Loss: -1191.374512\n",
      "    epoch          : 1530\n",
      "    loss           : -1358.2477748030324\n",
      "Train Epoch: 1531 [512/60000 (1%)] Loss: -1476.018188\n",
      "Train Epoch: 1531 [11776/60000 (20%)] Loss: -1246.085083\n",
      "Train Epoch: 1531 [23040/60000 (38%)] Loss: -1108.135254\n",
      "Train Epoch: 1531 [34304/60000 (57%)] Loss: -1363.815186\n",
      "Train Epoch: 1531 [45568/60000 (76%)] Loss: -1357.177734\n",
      "Train Epoch: 1531 [56832/60000 (95%)] Loss: -1234.140625\n",
      "    epoch          : 1531\n",
      "    loss           : -1354.5426251255185\n",
      "Train Epoch: 1532 [512/60000 (1%)] Loss: -1351.749023\n",
      "Train Epoch: 1532 [11776/60000 (20%)] Loss: -1532.412231\n",
      "Train Epoch: 1532 [23040/60000 (38%)] Loss: -1346.835327\n",
      "Train Epoch: 1532 [34304/60000 (57%)] Loss: -1368.499512\n",
      "Train Epoch: 1532 [45568/60000 (76%)] Loss: -1338.261719\n",
      "Train Epoch: 1532 [56832/60000 (95%)] Loss: -1228.022949\n",
      "    epoch          : 1532\n",
      "    loss           : -1368.664188363458\n",
      "Train Epoch: 1533 [512/60000 (1%)] Loss: -1388.057861\n",
      "Train Epoch: 1533 [11776/60000 (20%)] Loss: -1506.008789\n",
      "Train Epoch: 1533 [23040/60000 (38%)] Loss: -1378.248291\n",
      "Train Epoch: 1533 [34304/60000 (57%)] Loss: -1460.995361\n",
      "Train Epoch: 1533 [45568/60000 (76%)] Loss: -1380.973633\n",
      "Train Epoch: 1533 [56832/60000 (95%)] Loss: -1488.480713\n",
      "    epoch          : 1533\n",
      "    loss           : -1353.8558427196438\n",
      "Train Epoch: 1534 [512/60000 (1%)] Loss: -1534.244019\n",
      "Train Epoch: 1534 [11776/60000 (20%)] Loss: -1371.352661\n",
      "Train Epoch: 1534 [23040/60000 (38%)] Loss: -1347.046021\n",
      "Train Epoch: 1534 [34304/60000 (57%)] Loss: -1384.791504\n",
      "Train Epoch: 1534 [45568/60000 (76%)] Loss: -1371.175049\n",
      "Train Epoch: 1534 [56832/60000 (95%)] Loss: -1244.599854\n",
      "    epoch          : 1534\n",
      "    loss           : -1352.035781601728\n",
      "Train Epoch: 1535 [512/60000 (1%)] Loss: -1381.816650\n",
      "Train Epoch: 1535 [11776/60000 (20%)] Loss: -1516.034912\n",
      "Train Epoch: 1535 [23040/60000 (38%)] Loss: -1369.651855\n",
      "Train Epoch: 1535 [34304/60000 (57%)] Loss: -1320.043335\n",
      "Train Epoch: 1535 [45568/60000 (76%)] Loss: -1331.969482\n",
      "Train Epoch: 1535 [56832/60000 (95%)] Loss: -1345.914062\n",
      "    epoch          : 1535\n",
      "    loss           : -1337.2724799032264\n",
      "Train Epoch: 1536 [512/60000 (1%)] Loss: -1506.021240\n",
      "Train Epoch: 1536 [11776/60000 (20%)] Loss: -1505.690063\n",
      "Train Epoch: 1536 [23040/60000 (38%)] Loss: -1395.676025\n",
      "Train Epoch: 1536 [34304/60000 (57%)] Loss: -1377.450928\n",
      "Train Epoch: 1536 [45568/60000 (76%)] Loss: -1087.141479\n",
      "Train Epoch: 1536 [56832/60000 (95%)] Loss: -1407.351318\n",
      "    epoch          : 1536\n",
      "    loss           : -1340.9481506347656\n",
      "Train Epoch: 1537 [512/60000 (1%)] Loss: -976.325806\n",
      "Train Epoch: 1537 [11776/60000 (20%)] Loss: -1324.381104\n",
      "Train Epoch: 1537 [23040/60000 (38%)] Loss: -1363.065674\n",
      "Train Epoch: 1537 [34304/60000 (57%)] Loss: -1400.792358\n",
      "Train Epoch: 1537 [45568/60000 (76%)] Loss: -1365.077271\n",
      "Train Epoch: 1537 [56832/60000 (95%)] Loss: -1229.679199\n",
      "    epoch          : 1537\n",
      "    loss           : -1352.1636855992895\n",
      "Train Epoch: 1538 [512/60000 (1%)] Loss: -1219.480469\n",
      "Train Epoch: 1538 [11776/60000 (20%)] Loss: -1235.222168\n",
      "Train Epoch: 1538 [23040/60000 (38%)] Loss: -1399.619629\n",
      "Train Epoch: 1538 [34304/60000 (57%)] Loss: -1357.050537\n",
      "Train Epoch: 1538 [45568/60000 (76%)] Loss: -1367.670654\n",
      "Train Epoch: 1538 [56832/60000 (95%)] Loss: -1232.683350\n",
      "    epoch          : 1538\n",
      "    loss           : -1352.932057526152\n",
      "Train Epoch: 1539 [512/60000 (1%)] Loss: -1076.569336\n",
      "Train Epoch: 1539 [11776/60000 (20%)] Loss: -1226.120972\n",
      "Train Epoch: 1539 [23040/60000 (38%)] Loss: -1507.345337\n",
      "Train Epoch: 1539 [34304/60000 (57%)] Loss: -1223.866089\n",
      "Train Epoch: 1539 [45568/60000 (76%)] Loss: -1515.911865\n",
      "Train Epoch: 1539 [56832/60000 (95%)] Loss: -1378.206421\n",
      "    epoch          : 1539\n",
      "    loss           : -1358.8346374856549\n",
      "Train Epoch: 1540 [512/60000 (1%)] Loss: -1347.042603\n",
      "Train Epoch: 1540 [11776/60000 (20%)] Loss: -1233.827759\n",
      "Train Epoch: 1540 [23040/60000 (38%)] Loss: -1356.281006\n",
      "Train Epoch: 1540 [34304/60000 (57%)] Loss: -1196.677490\n",
      "Train Epoch: 1540 [45568/60000 (76%)] Loss: -1407.359375\n",
      "Train Epoch: 1540 [56832/60000 (95%)] Loss: -1247.828979\n",
      "    epoch          : 1540\n",
      "    loss           : -1348.733684475139\n",
      "Train Epoch: 1541 [512/60000 (1%)] Loss: -1480.024658\n",
      "Train Epoch: 1541 [11776/60000 (20%)] Loss: -1224.626099\n",
      "Train Epoch: 1541 [23040/60000 (38%)] Loss: -1382.455933\n",
      "Train Epoch: 1541 [34304/60000 (57%)] Loss: -1363.820190\n",
      "Train Epoch: 1541 [45568/60000 (76%)] Loss: -1502.584473\n",
      "Train Epoch: 1541 [56832/60000 (95%)] Loss: -1372.670044\n",
      "    epoch          : 1541\n",
      "    loss           : -1365.3748248256534\n",
      "Train Epoch: 1542 [512/60000 (1%)] Loss: -1398.101318\n",
      "Train Epoch: 1542 [11776/60000 (20%)] Loss: -1254.302612\n",
      "Train Epoch: 1542 [23040/60000 (38%)] Loss: -1337.251953\n",
      "Train Epoch: 1542 [34304/60000 (57%)] Loss: -1528.312012\n",
      "Train Epoch: 1542 [45568/60000 (76%)] Loss: -1329.096680\n",
      "Train Epoch: 1542 [56832/60000 (95%)] Loss: -1336.495728\n",
      "    epoch          : 1542\n",
      "    loss           : -1359.1833309884798\n",
      "Train Epoch: 1543 [512/60000 (1%)] Loss: -1349.299683\n",
      "Train Epoch: 1543 [11776/60000 (20%)] Loss: -1449.934448\n",
      "Train Epoch: 1543 [23040/60000 (38%)] Loss: -1191.364624\n",
      "Train Epoch: 1543 [34304/60000 (57%)] Loss: -1480.285156\n",
      "Train Epoch: 1543 [45568/60000 (76%)] Loss: -1566.463623\n",
      "Train Epoch: 1543 [56832/60000 (95%)] Loss: -1379.234741\n",
      "    epoch          : 1543\n",
      "    loss           : -1349.0194546974312\n",
      "Train Epoch: 1544 [512/60000 (1%)] Loss: -1510.213379\n",
      "Train Epoch: 1544 [11776/60000 (20%)] Loss: -1351.064697\n",
      "Train Epoch: 1544 [23040/60000 (38%)] Loss: -1177.262451\n",
      "Train Epoch: 1544 [34304/60000 (57%)] Loss: -1518.241211\n",
      "Train Epoch: 1544 [45568/60000 (76%)] Loss: -1366.869385\n",
      "Train Epoch: 1544 [56832/60000 (95%)] Loss: -1186.350830\n",
      "    epoch          : 1544\n",
      "    loss           : -1357.0124328958111\n",
      "Train Epoch: 1545 [512/60000 (1%)] Loss: -1311.249023\n",
      "Train Epoch: 1545 [11776/60000 (20%)] Loss: -1348.068726\n",
      "Train Epoch: 1545 [23040/60000 (38%)] Loss: -1338.158936\n",
      "Train Epoch: 1545 [34304/60000 (57%)] Loss: -1246.162598\n",
      "Train Epoch: 1545 [45568/60000 (76%)] Loss: -1132.519043\n",
      "Train Epoch: 1545 [56832/60000 (95%)] Loss: -1366.613037\n",
      "    epoch          : 1545\n",
      "    loss           : -1359.6079717086534\n",
      "Train Epoch: 1546 [512/60000 (1%)] Loss: -1209.426758\n",
      "Train Epoch: 1546 [11776/60000 (20%)] Loss: -1386.080811\n",
      "Train Epoch: 1546 [23040/60000 (38%)] Loss: -1356.916504\n",
      "Train Epoch: 1546 [34304/60000 (57%)] Loss: -1347.916382\n",
      "Train Epoch: 1546 [45568/60000 (76%)] Loss: -1352.131104\n",
      "Train Epoch: 1546 [56832/60000 (95%)] Loss: -1373.609619\n",
      "    epoch          : 1546\n",
      "    loss           : -1349.3621315821417\n",
      "Train Epoch: 1547 [512/60000 (1%)] Loss: -1524.988281\n",
      "Train Epoch: 1547 [11776/60000 (20%)] Loss: -937.336426\n",
      "Train Epoch: 1547 [23040/60000 (38%)] Loss: -1263.257812\n",
      "Train Epoch: 1547 [34304/60000 (57%)] Loss: -1337.009033\n",
      "Train Epoch: 1547 [45568/60000 (76%)] Loss: -1497.766235\n",
      "Train Epoch: 1547 [56832/60000 (95%)] Loss: -1393.202881\n",
      "    epoch          : 1547\n",
      "    loss           : -1350.5292291156316\n",
      "Train Epoch: 1548 [512/60000 (1%)] Loss: -1076.034058\n",
      "Train Epoch: 1548 [11776/60000 (20%)] Loss: -1270.816162\n",
      "Train Epoch: 1548 [23040/60000 (38%)] Loss: -1505.096558\n",
      "Train Epoch: 1548 [34304/60000 (57%)] Loss: -1531.280884\n",
      "Train Epoch: 1548 [45568/60000 (76%)] Loss: -1479.276611\n",
      "Train Epoch: 1548 [56832/60000 (95%)] Loss: -1348.970093\n",
      "    epoch          : 1548\n",
      "    loss           : -1342.8556763384977\n",
      "Train Epoch: 1549 [512/60000 (1%)] Loss: -1375.810303\n",
      "Train Epoch: 1549 [11776/60000 (20%)] Loss: -1347.871704\n",
      "Train Epoch: 1549 [23040/60000 (38%)] Loss: -1107.187744\n",
      "Train Epoch: 1549 [34304/60000 (57%)] Loss: -1347.784790\n",
      "Train Epoch: 1549 [45568/60000 (76%)] Loss: -1252.734253\n",
      "Train Epoch: 1549 [56832/60000 (95%)] Loss: -1364.131470\n",
      "    epoch          : 1549\n",
      "    loss           : -1365.4161166605977\n",
      "Train Epoch: 1550 [512/60000 (1%)] Loss: -1343.753174\n",
      "Train Epoch: 1550 [11776/60000 (20%)] Loss: -1389.737793\n",
      "Train Epoch: 1550 [23040/60000 (38%)] Loss: -1519.546631\n",
      "Train Epoch: 1550 [34304/60000 (57%)] Loss: -1396.324951\n",
      "Train Epoch: 1550 [45568/60000 (76%)] Loss: -1244.064697\n",
      "Train Epoch: 1550 [56832/60000 (95%)] Loss: -1492.389893\n",
      "    epoch          : 1550\n",
      "    loss           : -1346.2901245806852\n",
      "Train Epoch: 1551 [512/60000 (1%)] Loss: -1324.336060\n",
      "Train Epoch: 1551 [11776/60000 (20%)] Loss: -1365.093750\n",
      "Train Epoch: 1551 [23040/60000 (38%)] Loss: -1229.953979\n",
      "Train Epoch: 1551 [34304/60000 (57%)] Loss: -1529.300659\n",
      "Train Epoch: 1551 [45568/60000 (76%)] Loss: -1517.182373\n",
      "Train Epoch: 1551 [56832/60000 (95%)] Loss: -1477.922119\n",
      "    epoch          : 1551\n",
      "    loss           : -1374.2262273238878\n",
      "Train Epoch: 1552 [512/60000 (1%)] Loss: -1354.242920\n",
      "Train Epoch: 1552 [11776/60000 (20%)] Loss: -1116.752441\n",
      "Train Epoch: 1552 [23040/60000 (38%)] Loss: -1383.399536\n",
      "Train Epoch: 1552 [34304/60000 (57%)] Loss: -1351.603516\n",
      "Train Epoch: 1552 [45568/60000 (76%)] Loss: -1375.449707\n",
      "Train Epoch: 1552 [56832/60000 (95%)] Loss: -1385.178101\n",
      "    epoch          : 1552\n",
      "    loss           : -1342.1270831264346\n",
      "Train Epoch: 1553 [512/60000 (1%)] Loss: -1382.279785\n",
      "Train Epoch: 1553 [11776/60000 (20%)] Loss: -1240.220703\n",
      "Train Epoch: 1553 [23040/60000 (38%)] Loss: -1381.452515\n",
      "Train Epoch: 1553 [34304/60000 (57%)] Loss: -1415.098145\n",
      "Train Epoch: 1553 [45568/60000 (76%)] Loss: -1525.839111\n",
      "Train Epoch: 1553 [56832/60000 (95%)] Loss: -1489.685059\n",
      "    epoch          : 1553\n",
      "    loss           : -1374.995671676377\n",
      "Train Epoch: 1554 [512/60000 (1%)] Loss: -1208.648438\n",
      "Train Epoch: 1554 [11776/60000 (20%)] Loss: -1498.710815\n",
      "Train Epoch: 1554 [23040/60000 (38%)] Loss: -1228.670166\n",
      "Train Epoch: 1554 [34304/60000 (57%)] Loss: -1410.136719\n",
      "Train Epoch: 1554 [45568/60000 (76%)] Loss: -1203.602905\n",
      "Train Epoch: 1554 [56832/60000 (95%)] Loss: -1379.462646\n",
      "    epoch          : 1554\n",
      "    loss           : -1341.489269709183\n",
      "Train Epoch: 1555 [512/60000 (1%)] Loss: -1350.157471\n",
      "Train Epoch: 1555 [11776/60000 (20%)] Loss: -1364.891113\n",
      "Train Epoch: 1555 [23040/60000 (38%)] Loss: -1242.175781\n",
      "Train Epoch: 1555 [34304/60000 (57%)] Loss: -1109.129517\n",
      "Train Epoch: 1555 [45568/60000 (76%)] Loss: -1368.418457\n",
      "Train Epoch: 1555 [56832/60000 (95%)] Loss: -1362.557129\n",
      "    epoch          : 1555\n",
      "    loss           : -1343.9383406989318\n",
      "Train Epoch: 1556 [512/60000 (1%)] Loss: -1219.113037\n",
      "Train Epoch: 1556 [11776/60000 (20%)] Loss: -1194.142944\n",
      "Train Epoch: 1556 [23040/60000 (38%)] Loss: -1502.217773\n",
      "Train Epoch: 1556 [34304/60000 (57%)] Loss: -1371.429321\n",
      "Train Epoch: 1556 [45568/60000 (76%)] Loss: -1084.892822\n",
      "Train Epoch: 1556 [56832/60000 (95%)] Loss: -1355.745117\n",
      "    epoch          : 1556\n",
      "    loss           : -1343.0514534987972\n",
      "Train Epoch: 1557 [512/60000 (1%)] Loss: -1372.986450\n",
      "Train Epoch: 1557 [11776/60000 (20%)] Loss: -1350.142578\n",
      "Train Epoch: 1557 [23040/60000 (38%)] Loss: -1125.779785\n",
      "Train Epoch: 1557 [34304/60000 (57%)] Loss: -1353.612549\n",
      "Train Epoch: 1557 [45568/60000 (76%)] Loss: -1323.819702\n",
      "Train Epoch: 1557 [56832/60000 (95%)] Loss: -1327.786011\n",
      "    epoch          : 1557\n",
      "    loss           : -1329.4256750419315\n",
      "Train Epoch: 1558 [512/60000 (1%)] Loss: -1407.727539\n",
      "Train Epoch: 1558 [11776/60000 (20%)] Loss: -1255.153687\n",
      "Train Epoch: 1558 [23040/60000 (38%)] Loss: -1340.083984\n",
      "Train Epoch: 1558 [34304/60000 (57%)] Loss: -1339.408447\n",
      "Train Epoch: 1558 [45568/60000 (76%)] Loss: -1508.056152\n",
      "Train Epoch: 1558 [56832/60000 (95%)] Loss: -1324.852783\n",
      "    epoch          : 1558\n",
      "    loss           : -1351.392493641309\n",
      "Train Epoch: 1559 [512/60000 (1%)] Loss: -1062.324097\n",
      "Train Epoch: 1559 [11776/60000 (20%)] Loss: -1374.339966\n",
      "Train Epoch: 1559 [23040/60000 (38%)] Loss: -1378.091675\n",
      "Train Epoch: 1559 [34304/60000 (57%)] Loss: -1401.107910\n",
      "Train Epoch: 1559 [45568/60000 (76%)] Loss: -1497.687744\n",
      "Train Epoch: 1559 [56832/60000 (95%)] Loss: -1553.260498\n",
      "    epoch          : 1559\n",
      "    loss           : -1333.2146444374557\n",
      "Train Epoch: 1560 [512/60000 (1%)] Loss: -1390.809937\n",
      "Train Epoch: 1560 [11776/60000 (20%)] Loss: -1067.234131\n",
      "Train Epoch: 1560 [23040/60000 (38%)] Loss: -1255.694458\n",
      "Train Epoch: 1560 [34304/60000 (57%)] Loss: -1398.296387\n",
      "Train Epoch: 1560 [45568/60000 (76%)] Loss: -1508.243042\n",
      "Train Epoch: 1560 [56832/60000 (95%)] Loss: -1539.333496\n",
      "    epoch          : 1560\n",
      "    loss           : -1344.4740550585386\n",
      "Train Epoch: 1561 [512/60000 (1%)] Loss: -1509.324219\n",
      "Train Epoch: 1561 [11776/60000 (20%)] Loss: -1183.803467\n",
      "Train Epoch: 1561 [23040/60000 (38%)] Loss: -1246.488770\n",
      "Train Epoch: 1561 [34304/60000 (57%)] Loss: -1267.513550\n",
      "Train Epoch: 1561 [45568/60000 (76%)] Loss: -1063.958008\n",
      "Train Epoch: 1561 [56832/60000 (95%)] Loss: -1221.103027\n",
      "    epoch          : 1561\n",
      "    loss           : -1344.2588583736097\n",
      "Train Epoch: 1562 [512/60000 (1%)] Loss: -1402.743652\n",
      "Train Epoch: 1562 [11776/60000 (20%)] Loss: -1204.915527\n",
      "Train Epoch: 1562 [23040/60000 (38%)] Loss: -1210.862549\n",
      "Train Epoch: 1562 [34304/60000 (57%)] Loss: -1205.364746\n",
      "Train Epoch: 1562 [45568/60000 (76%)] Loss: -1534.800781\n",
      "Train Epoch: 1562 [56832/60000 (95%)] Loss: -1401.431885\n",
      "    epoch          : 1562\n",
      "    loss           : -1343.380455577441\n",
      "Train Epoch: 1563 [512/60000 (1%)] Loss: -1338.890869\n",
      "Train Epoch: 1563 [11776/60000 (20%)] Loss: -1533.752319\n",
      "Train Epoch: 1563 [23040/60000 (38%)] Loss: -1391.320190\n",
      "Train Epoch: 1563 [34304/60000 (57%)] Loss: -1506.813477\n",
      "Train Epoch: 1563 [45568/60000 (76%)] Loss: -1369.946411\n",
      "Train Epoch: 1563 [56832/60000 (95%)] Loss: -1370.015137\n",
      "    epoch          : 1563\n",
      "    loss           : -1366.0296734308793\n",
      "Train Epoch: 1564 [512/60000 (1%)] Loss: -1505.544800\n",
      "Train Epoch: 1564 [11776/60000 (20%)] Loss: -1372.715088\n",
      "Train Epoch: 1564 [23040/60000 (38%)] Loss: -1368.672607\n",
      "Train Epoch: 1564 [34304/60000 (57%)] Loss: -1378.635132\n",
      "Train Epoch: 1564 [45568/60000 (76%)] Loss: -1230.117676\n",
      "Train Epoch: 1564 [56832/60000 (95%)] Loss: -1512.358521\n",
      "    epoch          : 1564\n",
      "    loss           : -1353.743870966852\n",
      "Train Epoch: 1565 [512/60000 (1%)] Loss: -1391.805420\n",
      "Train Epoch: 1565 [11776/60000 (20%)] Loss: -1395.937378\n",
      "Train Epoch: 1565 [23040/60000 (38%)] Loss: -1353.205322\n",
      "Train Epoch: 1565 [34304/60000 (57%)] Loss: -1244.317383\n",
      "Train Epoch: 1565 [45568/60000 (76%)] Loss: -1234.464844\n",
      "Train Epoch: 1565 [56832/60000 (95%)] Loss: -1342.487671\n",
      "    epoch          : 1565\n",
      "    loss           : -1353.664735955707\n",
      "Train Epoch: 1566 [512/60000 (1%)] Loss: -1236.577637\n",
      "Train Epoch: 1566 [11776/60000 (20%)] Loss: -1354.433105\n",
      "Train Epoch: 1566 [23040/60000 (38%)] Loss: -1202.977539\n",
      "Train Epoch: 1566 [34304/60000 (57%)] Loss: -1200.026489\n",
      "Train Epoch: 1566 [45568/60000 (76%)] Loss: -1225.775879\n",
      "Train Epoch: 1566 [56832/60000 (95%)] Loss: -1512.044434\n",
      "    epoch          : 1566\n",
      "    loss           : -1350.8723406603106\n",
      "Train Epoch: 1567 [512/60000 (1%)] Loss: -1517.912109\n",
      "Train Epoch: 1567 [11776/60000 (20%)] Loss: -1106.645752\n",
      "Train Epoch: 1567 [23040/60000 (38%)] Loss: -1394.536987\n",
      "Train Epoch: 1567 [34304/60000 (57%)] Loss: -1245.601074\n",
      "Train Epoch: 1567 [45568/60000 (76%)] Loss: -1236.681030\n",
      "Train Epoch: 1567 [56832/60000 (95%)] Loss: -1103.375488\n",
      "    epoch          : 1567\n",
      "    loss           : -1341.7605177022642\n",
      "Train Epoch: 1568 [512/60000 (1%)] Loss: -1355.667725\n",
      "Train Epoch: 1568 [11776/60000 (20%)] Loss: -1376.591919\n",
      "Train Epoch: 1568 [23040/60000 (38%)] Loss: -1539.767822\n",
      "Train Epoch: 1568 [34304/60000 (57%)] Loss: -1375.026733\n",
      "Train Epoch: 1568 [45568/60000 (76%)] Loss: -1349.899170\n",
      "Train Epoch: 1568 [56832/60000 (95%)] Loss: -982.040100\n",
      "    epoch          : 1568\n",
      "    loss           : -1349.0164520780918\n",
      "Train Epoch: 1569 [512/60000 (1%)] Loss: -1385.950439\n",
      "Train Epoch: 1569 [11776/60000 (20%)] Loss: -1387.227173\n",
      "Train Epoch: 1569 [23040/60000 (38%)] Loss: -1373.595825\n",
      "Train Epoch: 1569 [34304/60000 (57%)] Loss: -1262.213135\n",
      "Train Epoch: 1569 [45568/60000 (76%)] Loss: -1483.002930\n",
      "Train Epoch: 1569 [56832/60000 (95%)] Loss: -1125.082886\n",
      "    epoch          : 1569\n",
      "    loss           : -1357.551302979895\n",
      "Train Epoch: 1570 [512/60000 (1%)] Loss: -1339.966309\n",
      "Train Epoch: 1570 [11776/60000 (20%)] Loss: -1511.263428\n",
      "Train Epoch: 1570 [23040/60000 (38%)] Loss: -1518.493408\n",
      "Train Epoch: 1570 [34304/60000 (57%)] Loss: -1389.432617\n",
      "Train Epoch: 1570 [45568/60000 (76%)] Loss: -1503.641113\n",
      "Train Epoch: 1570 [56832/60000 (95%)] Loss: -1322.541504\n",
      "    epoch          : 1570\n",
      "    loss           : -1359.720333120917\n",
      "Train Epoch: 1571 [512/60000 (1%)] Loss: -1363.408081\n",
      "Train Epoch: 1571 [11776/60000 (20%)] Loss: -1334.321533\n",
      "Train Epoch: 1571 [23040/60000 (38%)] Loss: -1358.242676\n",
      "Train Epoch: 1571 [34304/60000 (57%)] Loss: -1521.882690\n",
      "Train Epoch: 1571 [45568/60000 (76%)] Loss: -1469.640869\n",
      "Train Epoch: 1571 [56832/60000 (95%)] Loss: -1523.718018\n",
      "    epoch          : 1571\n",
      "    loss           : -1363.7620594434145\n",
      "Train Epoch: 1572 [512/60000 (1%)] Loss: -1535.396484\n",
      "Train Epoch: 1572 [11776/60000 (20%)] Loss: -1194.018677\n",
      "Train Epoch: 1572 [23040/60000 (38%)] Loss: -1376.066650\n",
      "Train Epoch: 1572 [34304/60000 (57%)] Loss: -1504.233643\n",
      "Train Epoch: 1572 [45568/60000 (76%)] Loss: -1368.361084\n",
      "Train Epoch: 1572 [56832/60000 (95%)] Loss: -1359.926880\n",
      "    epoch          : 1572\n",
      "    loss           : -1356.979977020436\n",
      "Train Epoch: 1573 [512/60000 (1%)] Loss: -1527.346313\n",
      "Train Epoch: 1573 [11776/60000 (20%)] Loss: -1393.097290\n",
      "Train Epoch: 1573 [23040/60000 (38%)] Loss: -1214.859741\n",
      "Train Epoch: 1573 [34304/60000 (57%)] Loss: -1473.061890\n",
      "Train Epoch: 1573 [45568/60000 (76%)] Loss: -1350.549316\n",
      "Train Epoch: 1573 [56832/60000 (95%)] Loss: -1201.631226\n",
      "    epoch          : 1573\n",
      "    loss           : -1345.475192829714\n",
      "Train Epoch: 1574 [512/60000 (1%)] Loss: -1408.821289\n",
      "Train Epoch: 1574 [11776/60000 (20%)] Loss: -1398.514893\n",
      "Train Epoch: 1574 [23040/60000 (38%)] Loss: -1387.870361\n",
      "Train Epoch: 1574 [34304/60000 (57%)] Loss: -1281.021973\n",
      "Train Epoch: 1574 [45568/60000 (76%)] Loss: -1480.960205\n",
      "Train Epoch: 1574 [56832/60000 (95%)] Loss: -1390.702759\n",
      "    epoch          : 1574\n",
      "    loss           : -1357.9164259743557\n",
      "Train Epoch: 1575 [512/60000 (1%)] Loss: -1526.682007\n",
      "Train Epoch: 1575 [11776/60000 (20%)] Loss: -1236.263794\n",
      "Train Epoch: 1575 [23040/60000 (38%)] Loss: -1240.841919\n",
      "Train Epoch: 1575 [34304/60000 (57%)] Loss: -1267.998413\n",
      "Train Epoch: 1575 [45568/60000 (76%)] Loss: -1395.306152\n",
      "Train Epoch: 1575 [56832/60000 (95%)] Loss: -1256.817871\n",
      "    epoch          : 1575\n",
      "    loss           : -1355.3407330701582\n",
      "Train Epoch: 1576 [512/60000 (1%)] Loss: -1507.409546\n",
      "Train Epoch: 1576 [11776/60000 (20%)] Loss: -1490.240356\n",
      "Train Epoch: 1576 [23040/60000 (38%)] Loss: -1378.469238\n",
      "Train Epoch: 1576 [34304/60000 (57%)] Loss: -1506.674683\n",
      "Train Epoch: 1576 [45568/60000 (76%)] Loss: -1231.178101\n",
      "Train Epoch: 1576 [56832/60000 (95%)] Loss: -1395.958008\n",
      "    epoch          : 1576\n",
      "    loss           : -1374.394573147014\n",
      "Train Epoch: 1577 [512/60000 (1%)] Loss: -1379.536133\n",
      "Train Epoch: 1577 [11776/60000 (20%)] Loss: -1220.124023\n",
      "Train Epoch: 1577 [23040/60000 (38%)] Loss: -1334.773438\n",
      "Train Epoch: 1577 [34304/60000 (57%)] Loss: -1095.128418\n",
      "Train Epoch: 1577 [45568/60000 (76%)] Loss: -1401.343018\n",
      "Train Epoch: 1577 [56832/60000 (95%)] Loss: -1368.230591\n",
      "    epoch          : 1577\n",
      "    loss           : -1341.45757160079\n",
      "Train Epoch: 1578 [512/60000 (1%)] Loss: -1462.969727\n",
      "Train Epoch: 1578 [11776/60000 (20%)] Loss: -1401.684204\n",
      "Train Epoch: 1578 [23040/60000 (38%)] Loss: -1371.787231\n",
      "Train Epoch: 1578 [34304/60000 (57%)] Loss: -1382.020142\n",
      "Train Epoch: 1578 [45568/60000 (76%)] Loss: -1504.149170\n",
      "Train Epoch: 1578 [56832/60000 (95%)] Loss: -1554.474854\n",
      "    epoch          : 1578\n",
      "    loss           : -1365.1900238209525\n",
      "Train Epoch: 1579 [512/60000 (1%)] Loss: -1235.042358\n",
      "Train Epoch: 1579 [11776/60000 (20%)] Loss: -1377.436035\n",
      "Train Epoch: 1579 [23040/60000 (38%)] Loss: -1213.245972\n",
      "Train Epoch: 1579 [34304/60000 (57%)] Loss: -1066.926758\n",
      "Train Epoch: 1579 [45568/60000 (76%)] Loss: -1252.079834\n",
      "Train Epoch: 1579 [56832/60000 (95%)] Loss: -1521.384888\n",
      "    epoch          : 1579\n",
      "    loss           : -1341.2523629571085\n",
      "Train Epoch: 1580 [512/60000 (1%)] Loss: -1523.353027\n",
      "Train Epoch: 1580 [11776/60000 (20%)] Loss: -1534.114136\n",
      "Train Epoch: 1580 [23040/60000 (38%)] Loss: -1230.220093\n",
      "Train Epoch: 1580 [34304/60000 (57%)] Loss: -1501.224487\n",
      "Train Epoch: 1580 [45568/60000 (76%)] Loss: -1375.122925\n",
      "Train Epoch: 1580 [56832/60000 (95%)] Loss: -1260.120117\n",
      "    epoch          : 1580\n",
      "    loss           : -1369.3189714507196\n",
      "Train Epoch: 1581 [512/60000 (1%)] Loss: -1241.627930\n",
      "Train Epoch: 1581 [11776/60000 (20%)] Loss: -1362.268555\n",
      "Train Epoch: 1581 [23040/60000 (38%)] Loss: -1331.050781\n",
      "Train Epoch: 1581 [34304/60000 (57%)] Loss: -1505.462891\n",
      "Train Epoch: 1581 [45568/60000 (76%)] Loss: -1378.192749\n",
      "Train Epoch: 1581 [56832/60000 (95%)] Loss: -1359.271118\n",
      "    epoch          : 1581\n",
      "    loss           : -1354.2260324941517\n",
      "Train Epoch: 1582 [512/60000 (1%)] Loss: -1490.809814\n",
      "Train Epoch: 1582 [11776/60000 (20%)] Loss: -1364.075195\n",
      "Train Epoch: 1582 [23040/60000 (38%)] Loss: -1482.471069\n",
      "Train Epoch: 1582 [34304/60000 (57%)] Loss: -1107.753418\n",
      "Train Epoch: 1582 [45568/60000 (76%)] Loss: -1364.327393\n",
      "Train Epoch: 1582 [56832/60000 (95%)] Loss: -1194.156006\n",
      "    epoch          : 1582\n",
      "    loss           : -1363.4880429715088\n",
      "Train Epoch: 1583 [512/60000 (1%)] Loss: -1523.474609\n",
      "Train Epoch: 1583 [11776/60000 (20%)] Loss: -1349.392578\n",
      "Train Epoch: 1583 [23040/60000 (38%)] Loss: -1216.927856\n",
      "Train Epoch: 1583 [34304/60000 (57%)] Loss: -1539.300049\n",
      "Train Epoch: 1583 [45568/60000 (76%)] Loss: -1069.181152\n",
      "Train Epoch: 1583 [56832/60000 (95%)] Loss: -1409.529785\n",
      "    epoch          : 1583\n",
      "    loss           : -1370.0477822513903\n",
      "Train Epoch: 1584 [512/60000 (1%)] Loss: -1365.348389\n",
      "Train Epoch: 1584 [11776/60000 (20%)] Loss: -1387.314575\n",
      "Train Epoch: 1584 [23040/60000 (38%)] Loss: -1469.918457\n",
      "Train Epoch: 1584 [34304/60000 (57%)] Loss: -1504.359131\n",
      "Train Epoch: 1584 [45568/60000 (76%)] Loss: -1216.036377\n",
      "Train Epoch: 1584 [56832/60000 (95%)] Loss: -1381.768555\n",
      "    epoch          : 1584\n",
      "    loss           : -1364.940268823656\n",
      "Train Epoch: 1585 [512/60000 (1%)] Loss: -1512.716309\n",
      "Train Epoch: 1585 [11776/60000 (20%)] Loss: -1390.622314\n",
      "Train Epoch: 1585 [23040/60000 (38%)] Loss: -1347.479126\n",
      "Train Epoch: 1585 [34304/60000 (57%)] Loss: -1383.376587\n",
      "Train Epoch: 1585 [45568/60000 (76%)] Loss: -1369.251587\n",
      "Train Epoch: 1585 [56832/60000 (95%)] Loss: -1353.045044\n",
      "    epoch          : 1585\n",
      "    loss           : -1352.7446358028778\n",
      "Train Epoch: 1586 [512/60000 (1%)] Loss: -1205.212524\n",
      "Train Epoch: 1586 [11776/60000 (20%)] Loss: -1207.481445\n",
      "Train Epoch: 1586 [23040/60000 (38%)] Loss: -1343.088257\n",
      "Train Epoch: 1586 [34304/60000 (57%)] Loss: -1374.065308\n",
      "Train Epoch: 1586 [45568/60000 (76%)] Loss: -1214.568115\n",
      "Train Epoch: 1586 [56832/60000 (95%)] Loss: -1227.517822\n",
      "    epoch          : 1586\n",
      "    loss           : -1346.8796497064795\n",
      "Train Epoch: 1587 [512/60000 (1%)] Loss: -1401.014404\n",
      "Train Epoch: 1587 [11776/60000 (20%)] Loss: -1252.401367\n",
      "Train Epoch: 1587 [23040/60000 (38%)] Loss: -1347.035156\n",
      "Train Epoch: 1587 [34304/60000 (57%)] Loss: -1273.653809\n",
      "Train Epoch: 1587 [45568/60000 (76%)] Loss: -1338.882324\n",
      "Train Epoch: 1587 [56832/60000 (95%)] Loss: -1076.567017\n",
      "    epoch          : 1587\n",
      "    loss           : -1359.7394591940326\n",
      "Train Epoch: 1588 [512/60000 (1%)] Loss: -1395.829590\n",
      "Train Epoch: 1588 [11776/60000 (20%)] Loss: -1247.900879\n",
      "Train Epoch: 1588 [23040/60000 (38%)] Loss: -1358.780518\n",
      "Train Epoch: 1588 [34304/60000 (57%)] Loss: -1490.562012\n",
      "Train Epoch: 1588 [45568/60000 (76%)] Loss: -1371.239990\n",
      "Train Epoch: 1588 [56832/60000 (95%)] Loss: -1282.418213\n",
      "    epoch          : 1588\n",
      "    loss           : -1357.5674090196856\n",
      "Train Epoch: 1589 [512/60000 (1%)] Loss: -1333.252563\n",
      "Train Epoch: 1589 [11776/60000 (20%)] Loss: -1387.069824\n",
      "Train Epoch: 1589 [23040/60000 (38%)] Loss: -1422.366943\n",
      "Train Epoch: 1589 [34304/60000 (57%)] Loss: -1117.479370\n",
      "Train Epoch: 1589 [45568/60000 (76%)] Loss: -1369.479004\n",
      "Train Epoch: 1589 [56832/60000 (95%)] Loss: -1534.020264\n",
      "    epoch          : 1589\n",
      "    loss           : -1366.3815999004125\n",
      "Train Epoch: 1590 [512/60000 (1%)] Loss: -1423.472168\n",
      "Train Epoch: 1590 [11776/60000 (20%)] Loss: -1332.572144\n",
      "Train Epoch: 1590 [23040/60000 (38%)] Loss: -1230.265869\n",
      "Train Epoch: 1590 [34304/60000 (57%)] Loss: -1483.095459\n",
      "Train Epoch: 1590 [45568/60000 (76%)] Loss: -1228.576294\n",
      "Train Epoch: 1590 [56832/60000 (95%)] Loss: -1470.527100\n",
      "    epoch          : 1590\n",
      "    loss           : -1351.532607256356\n",
      "Train Epoch: 1591 [512/60000 (1%)] Loss: -1225.642944\n",
      "Train Epoch: 1591 [11776/60000 (20%)] Loss: -1376.271118\n",
      "Train Epoch: 1591 [23040/60000 (38%)] Loss: -1359.943359\n",
      "Train Epoch: 1591 [34304/60000 (57%)] Loss: -1370.594727\n",
      "Train Epoch: 1591 [45568/60000 (76%)] Loss: -1210.590698\n",
      "Train Epoch: 1591 [56832/60000 (95%)] Loss: -1370.105103\n",
      "    epoch          : 1591\n",
      "    loss           : -1360.374323095979\n",
      "Train Epoch: 1592 [512/60000 (1%)] Loss: -1251.162598\n",
      "Train Epoch: 1592 [11776/60000 (20%)] Loss: -1116.017822\n",
      "Train Epoch: 1592 [23040/60000 (38%)] Loss: -1093.135986\n",
      "Train Epoch: 1592 [34304/60000 (57%)] Loss: -1496.291992\n",
      "Train Epoch: 1592 [45568/60000 (76%)] Loss: -1375.712646\n",
      "Train Epoch: 1592 [56832/60000 (95%)] Loss: -1347.494629\n",
      "    epoch          : 1592\n",
      "    loss           : -1366.4170187395173\n",
      "Train Epoch: 1593 [512/60000 (1%)] Loss: -1341.954102\n",
      "Train Epoch: 1593 [11776/60000 (20%)] Loss: -1237.865479\n",
      "Train Epoch: 1593 [23040/60000 (38%)] Loss: -1376.328735\n",
      "Train Epoch: 1593 [34304/60000 (57%)] Loss: -1529.176636\n",
      "Train Epoch: 1593 [45568/60000 (76%)] Loss: -1312.131104\n",
      "Train Epoch: 1593 [56832/60000 (95%)] Loss: -1527.980591\n",
      "    epoch          : 1593\n",
      "    loss           : -1361.713820118015\n",
      "Train Epoch: 1594 [512/60000 (1%)] Loss: -1224.629028\n",
      "Train Epoch: 1594 [11776/60000 (20%)] Loss: -1566.489990\n",
      "Train Epoch: 1594 [23040/60000 (38%)] Loss: -1243.979980\n",
      "Train Epoch: 1594 [34304/60000 (57%)] Loss: -1236.677124\n",
      "Train Epoch: 1594 [45568/60000 (76%)] Loss: -1548.247925\n",
      "Train Epoch: 1594 [56832/60000 (95%)] Loss: -1242.644531\n",
      "    epoch          : 1594\n",
      "    loss           : -1348.253805904065\n",
      "Train Epoch: 1595 [512/60000 (1%)] Loss: -1374.031250\n",
      "Train Epoch: 1595 [11776/60000 (20%)] Loss: -1367.352539\n",
      "Train Epoch: 1595 [23040/60000 (38%)] Loss: -1394.285400\n",
      "Train Epoch: 1595 [34304/60000 (57%)] Loss: -1517.624878\n",
      "Train Epoch: 1595 [45568/60000 (76%)] Loss: -1362.793945\n",
      "Train Epoch: 1595 [56832/60000 (95%)] Loss: -1497.680176\n",
      "    epoch          : 1595\n",
      "    loss           : -1351.6126295186705\n",
      "Train Epoch: 1596 [512/60000 (1%)] Loss: -1396.339233\n",
      "Train Epoch: 1596 [11776/60000 (20%)] Loss: -1340.151733\n",
      "Train Epoch: 1596 [23040/60000 (38%)] Loss: -1229.592285\n",
      "Train Epoch: 1596 [34304/60000 (57%)] Loss: -1376.030518\n",
      "Train Epoch: 1596 [45568/60000 (76%)] Loss: -1223.469971\n",
      "Train Epoch: 1596 [56832/60000 (95%)] Loss: -1490.721436\n",
      "    epoch          : 1596\n",
      "    loss           : -1346.4814501401395\n",
      "Train Epoch: 1597 [512/60000 (1%)] Loss: -1348.040283\n",
      "Train Epoch: 1597 [11776/60000 (20%)] Loss: -1360.916748\n",
      "Train Epoch: 1597 [23040/60000 (38%)] Loss: -1325.715332\n",
      "Train Epoch: 1597 [34304/60000 (57%)] Loss: -1105.362305\n",
      "Train Epoch: 1597 [45568/60000 (76%)] Loss: -1350.258179\n",
      "Train Epoch: 1597 [56832/60000 (95%)] Loss: -1525.748779\n",
      "    epoch          : 1597\n",
      "    loss           : -1347.4457152630648\n",
      "Train Epoch: 1598 [512/60000 (1%)] Loss: -1081.782471\n",
      "Train Epoch: 1598 [11776/60000 (20%)] Loss: -1383.780396\n",
      "Train Epoch: 1598 [23040/60000 (38%)] Loss: -1497.957764\n",
      "Train Epoch: 1598 [34304/60000 (57%)] Loss: -1365.326294\n",
      "Train Epoch: 1598 [45568/60000 (76%)] Loss: -1224.765991\n",
      "Train Epoch: 1598 [56832/60000 (95%)] Loss: -1342.082275\n",
      "    epoch          : 1598\n",
      "    loss           : -1348.7364236432952\n",
      "Train Epoch: 1599 [512/60000 (1%)] Loss: -1236.579956\n",
      "Train Epoch: 1599 [11776/60000 (20%)] Loss: -1231.599365\n",
      "Train Epoch: 1599 [23040/60000 (38%)] Loss: -1363.629639\n",
      "Train Epoch: 1599 [34304/60000 (57%)] Loss: -1331.360718\n",
      "Train Epoch: 1599 [45568/60000 (76%)] Loss: -1223.593018\n",
      "Train Epoch: 1599 [56832/60000 (95%)] Loss: -1495.240479\n",
      "    epoch          : 1599\n",
      "    loss           : -1341.3549546063957\n",
      "Train Epoch: 1600 [512/60000 (1%)] Loss: -1488.159546\n",
      "Train Epoch: 1600 [11776/60000 (20%)] Loss: -1246.650513\n",
      "Train Epoch: 1600 [23040/60000 (38%)] Loss: -1213.849731\n",
      "Train Epoch: 1600 [34304/60000 (57%)] Loss: -1242.100708\n",
      "Train Epoch: 1600 [45568/60000 (76%)] Loss: -1221.770508\n",
      "Train Epoch: 1600 [56832/60000 (95%)] Loss: -1253.002197\n",
      "    epoch          : 1600\n",
      "    loss           : -1339.8030593785863\n",
      "Saving checkpoint: saved/models/Mnist_DeepGenerativeOperad/0127_111843/checkpoint-epoch1600.pth ...\n",
      "Train Epoch: 1601 [512/60000 (1%)] Loss: -1379.937744\n",
      "Train Epoch: 1601 [11776/60000 (20%)] Loss: -1199.726318\n",
      "Train Epoch: 1601 [23040/60000 (38%)] Loss: -1381.164795\n",
      "Train Epoch: 1601 [34304/60000 (57%)] Loss: -1503.385376\n",
      "Train Epoch: 1601 [45568/60000 (76%)] Loss: -1238.380371\n",
      "Train Epoch: 1601 [56832/60000 (95%)] Loss: -1412.595093\n",
      "    epoch          : 1601\n",
      "    loss           : -1349.3013026350636\n",
      "Train Epoch: 1602 [512/60000 (1%)] Loss: -1206.648071\n",
      "Train Epoch: 1602 [11776/60000 (20%)] Loss: -1231.688843\n",
      "Train Epoch: 1602 [23040/60000 (38%)] Loss: -1485.725342\n",
      "Train Epoch: 1602 [34304/60000 (57%)] Loss: -1363.584229\n",
      "Train Epoch: 1602 [45568/60000 (76%)] Loss: -1391.174683\n",
      "Train Epoch: 1602 [56832/60000 (95%)] Loss: -1517.079102\n",
      "    epoch          : 1602\n",
      "    loss           : -1333.3771034714864\n",
      "Train Epoch: 1603 [512/60000 (1%)] Loss: -1526.755371\n",
      "Train Epoch: 1603 [11776/60000 (20%)] Loss: -1254.447021\n",
      "Train Epoch: 1603 [23040/60000 (38%)] Loss: -1382.833618\n",
      "Train Epoch: 1603 [34304/60000 (57%)] Loss: -1494.521729\n",
      "Train Epoch: 1603 [45568/60000 (76%)] Loss: -1225.526123\n",
      "Train Epoch: 1603 [56832/60000 (95%)] Loss: -1374.667969\n",
      "    epoch          : 1603\n",
      "    loss           : -1375.5203552246094\n",
      "Train Epoch: 1604 [512/60000 (1%)] Loss: -1486.788574\n",
      "Train Epoch: 1604 [11776/60000 (20%)] Loss: -1047.253174\n",
      "Train Epoch: 1604 [23040/60000 (38%)] Loss: -1392.146606\n",
      "Train Epoch: 1604 [34304/60000 (57%)] Loss: -1257.260010\n",
      "Train Epoch: 1604 [45568/60000 (76%)] Loss: -1531.254395\n",
      "Train Epoch: 1604 [56832/60000 (95%)] Loss: -1111.178101\n",
      "    epoch          : 1604\n",
      "    loss           : -1355.3231604624602\n",
      "Train Epoch: 1605 [512/60000 (1%)] Loss: -1538.292725\n",
      "Train Epoch: 1605 [11776/60000 (20%)] Loss: -1376.968384\n",
      "Train Epoch: 1605 [23040/60000 (38%)] Loss: -1387.264893\n",
      "Train Epoch: 1605 [34304/60000 (57%)] Loss: -1380.687134\n",
      "Train Epoch: 1605 [45568/60000 (76%)] Loss: -1515.523438\n",
      "Train Epoch: 1605 [56832/60000 (95%)] Loss: -1515.157471\n",
      "    epoch          : 1605\n",
      "    loss           : -1347.117906818282\n",
      "Train Epoch: 1606 [512/60000 (1%)] Loss: -1488.242432\n",
      "Train Epoch: 1606 [11776/60000 (20%)] Loss: -1482.839966\n",
      "Train Epoch: 1606 [23040/60000 (38%)] Loss: -1205.325806\n",
      "Train Epoch: 1606 [34304/60000 (57%)] Loss: -1364.517212\n",
      "Train Epoch: 1606 [45568/60000 (76%)] Loss: -1476.924805\n",
      "Train Epoch: 1606 [56832/60000 (95%)] Loss: -1539.080688\n",
      "    epoch          : 1606\n",
      "    loss           : -1369.9028437555173\n",
      "Train Epoch: 1607 [512/60000 (1%)] Loss: -1391.838013\n",
      "Train Epoch: 1607 [11776/60000 (20%)] Loss: -1350.328369\n",
      "Train Epoch: 1607 [23040/60000 (38%)] Loss: -1495.107666\n",
      "Train Epoch: 1607 [34304/60000 (57%)] Loss: -1340.909912\n",
      "Train Epoch: 1607 [45568/60000 (76%)] Loss: -1373.021362\n",
      "Train Epoch: 1607 [56832/60000 (95%)] Loss: -1550.549805\n",
      "    epoch          : 1607\n",
      "    loss           : -1367.4552305404748\n",
      "Train Epoch: 1608 [512/60000 (1%)] Loss: -1226.170288\n",
      "Train Epoch: 1608 [11776/60000 (20%)] Loss: -1363.857422\n",
      "Train Epoch: 1608 [23040/60000 (38%)] Loss: -1252.125977\n",
      "Train Epoch: 1608 [34304/60000 (57%)] Loss: -1379.152100\n",
      "Train Epoch: 1608 [45568/60000 (76%)] Loss: -1493.302856\n",
      "Train Epoch: 1608 [56832/60000 (95%)] Loss: -1353.214966\n",
      "    epoch          : 1608\n",
      "    loss           : -1353.787363170904\n",
      "Train Epoch: 1609 [512/60000 (1%)] Loss: -1214.279785\n",
      "Train Epoch: 1609 [11776/60000 (20%)] Loss: -1358.789673\n",
      "Train Epoch: 1609 [23040/60000 (38%)] Loss: -1449.938110\n",
      "Train Epoch: 1609 [34304/60000 (57%)] Loss: -1354.673828\n",
      "Train Epoch: 1609 [45568/60000 (76%)] Loss: -1515.193848\n",
      "Train Epoch: 1609 [56832/60000 (95%)] Loss: -1212.999634\n",
      "    epoch          : 1609\n",
      "    loss           : -1352.510473563846\n",
      "Train Epoch: 1610 [512/60000 (1%)] Loss: -1312.570801\n",
      "Train Epoch: 1610 [11776/60000 (20%)] Loss: -1277.115967\n",
      "Train Epoch: 1610 [23040/60000 (38%)] Loss: -1346.615845\n",
      "Train Epoch: 1610 [34304/60000 (57%)] Loss: -1359.462891\n",
      "Train Epoch: 1610 [45568/60000 (76%)] Loss: -1375.729736\n",
      "Train Epoch: 1610 [56832/60000 (95%)] Loss: -1506.291992\n",
      "    epoch          : 1610\n",
      "    loss           : -1347.1557189596576\n",
      "Train Epoch: 1611 [512/60000 (1%)] Loss: -1079.128906\n",
      "Train Epoch: 1611 [11776/60000 (20%)] Loss: -1205.587769\n",
      "Train Epoch: 1611 [23040/60000 (38%)] Loss: -1480.616211\n",
      "Train Epoch: 1611 [34304/60000 (57%)] Loss: -1086.150635\n",
      "Train Epoch: 1611 [45568/60000 (76%)] Loss: -1096.529053\n",
      "Train Epoch: 1611 [56832/60000 (95%)] Loss: -1268.227295\n",
      "    epoch          : 1611\n",
      "    loss           : -1353.0437635863568\n",
      "Train Epoch: 1612 [512/60000 (1%)] Loss: -1219.791382\n",
      "Train Epoch: 1612 [11776/60000 (20%)] Loss: -1500.765381\n",
      "Train Epoch: 1612 [23040/60000 (38%)] Loss: -1401.273926\n",
      "Train Epoch: 1612 [34304/60000 (57%)] Loss: -1371.309448\n",
      "Train Epoch: 1612 [45568/60000 (76%)] Loss: -1520.418701\n",
      "Train Epoch: 1612 [56832/60000 (95%)] Loss: -1485.890137\n",
      "    epoch          : 1612\n",
      "    loss           : -1355.566882634567\n",
      "Train Epoch: 1613 [512/60000 (1%)] Loss: -1392.671631\n",
      "Train Epoch: 1613 [11776/60000 (20%)] Loss: -1350.545044\n",
      "Train Epoch: 1613 [23040/60000 (38%)] Loss: -1492.020752\n",
      "Train Epoch: 1613 [34304/60000 (57%)] Loss: -1212.756958\n",
      "Train Epoch: 1613 [45568/60000 (76%)] Loss: -1398.641602\n",
      "Train Epoch: 1613 [56832/60000 (95%)] Loss: -1075.295654\n",
      "    epoch          : 1613\n",
      "    loss           : -1342.4493925450213\n",
      "Train Epoch: 1614 [512/60000 (1%)] Loss: -1326.658569\n",
      "Train Epoch: 1614 [11776/60000 (20%)] Loss: -1258.784912\n",
      "Train Epoch: 1614 [23040/60000 (38%)] Loss: -1364.454712\n",
      "Train Epoch: 1614 [34304/60000 (57%)] Loss: -1218.148682\n",
      "Train Epoch: 1614 [45568/60000 (76%)] Loss: -1229.697876\n",
      "Train Epoch: 1614 [56832/60000 (95%)] Loss: -1414.118408\n",
      "    epoch          : 1614\n",
      "    loss           : -1348.6344983806719\n",
      "Train Epoch: 1615 [512/60000 (1%)] Loss: -1084.085327\n",
      "Train Epoch: 1615 [11776/60000 (20%)] Loss: -1238.793457\n",
      "Train Epoch: 1615 [23040/60000 (38%)] Loss: -1376.032349\n",
      "Train Epoch: 1615 [34304/60000 (57%)] Loss: -1356.376587\n",
      "Train Epoch: 1615 [45568/60000 (76%)] Loss: -1351.040283\n",
      "Train Epoch: 1615 [56832/60000 (95%)] Loss: -1346.234131\n",
      "    epoch          : 1615\n",
      "    loss           : -1357.6432270976782\n",
      "Train Epoch: 1616 [512/60000 (1%)] Loss: -1118.845459\n",
      "Train Epoch: 1616 [11776/60000 (20%)] Loss: -1502.028076\n",
      "Train Epoch: 1616 [23040/60000 (38%)] Loss: -1177.015503\n",
      "Train Epoch: 1616 [34304/60000 (57%)] Loss: -1207.438232\n",
      "Train Epoch: 1616 [45568/60000 (76%)] Loss: -1518.213501\n",
      "Train Epoch: 1616 [56832/60000 (95%)] Loss: -1495.130249\n",
      "    epoch          : 1616\n",
      "    loss           : -1349.2894842287915\n",
      "Train Epoch: 1617 [512/60000 (1%)] Loss: -1376.529663\n",
      "Train Epoch: 1617 [11776/60000 (20%)] Loss: -1466.901611\n",
      "Train Epoch: 1617 [23040/60000 (38%)] Loss: -1104.650024\n",
      "Train Epoch: 1617 [34304/60000 (57%)] Loss: -1318.007568\n",
      "Train Epoch: 1617 [45568/60000 (76%)] Loss: -1357.852905\n",
      "Train Epoch: 1617 [56832/60000 (95%)] Loss: -1228.077881\n",
      "    epoch          : 1617\n",
      "    loss           : -1371.8164310778602\n",
      "Train Epoch: 1618 [512/60000 (1%)] Loss: -1240.132080\n",
      "Train Epoch: 1618 [11776/60000 (20%)] Loss: -1500.632568\n",
      "Train Epoch: 1618 [23040/60000 (38%)] Loss: -1492.534302\n",
      "Train Epoch: 1618 [34304/60000 (57%)] Loss: -1539.319824\n",
      "Train Epoch: 1618 [45568/60000 (76%)] Loss: -1228.628540\n",
      "Train Epoch: 1618 [56832/60000 (95%)] Loss: -1477.367798\n",
      "    epoch          : 1618\n",
      "    loss           : -1340.7208712303031\n",
      "Train Epoch: 1619 [512/60000 (1%)] Loss: -1239.069092\n",
      "Train Epoch: 1619 [11776/60000 (20%)] Loss: -1352.981201\n",
      "Train Epoch: 1619 [23040/60000 (38%)] Loss: -1234.332153\n",
      "Train Epoch: 1619 [34304/60000 (57%)] Loss: -1362.856079\n",
      "Train Epoch: 1619 [45568/60000 (76%)] Loss: -1248.465698\n",
      "Train Epoch: 1619 [56832/60000 (95%)] Loss: -1247.405029\n",
      "    epoch          : 1619\n",
      "    loss           : -1371.1000204140182\n",
      "Train Epoch: 1620 [512/60000 (1%)] Loss: -1494.274658\n",
      "Train Epoch: 1620 [11776/60000 (20%)] Loss: -1351.994507\n",
      "Train Epoch: 1620 [23040/60000 (38%)] Loss: -1366.679077\n",
      "Train Epoch: 1620 [34304/60000 (57%)] Loss: -1392.738525\n",
      "Train Epoch: 1620 [45568/60000 (76%)] Loss: -1343.859619\n",
      "Train Epoch: 1620 [56832/60000 (95%)] Loss: -1373.971436\n",
      "    epoch          : 1620\n",
      "    loss           : -1349.8649854067355\n",
      "Train Epoch: 1621 [512/60000 (1%)] Loss: -1539.552734\n",
      "Train Epoch: 1621 [11776/60000 (20%)] Loss: -1254.625122\n",
      "Train Epoch: 1621 [23040/60000 (38%)] Loss: -1371.763306\n",
      "Train Epoch: 1621 [34304/60000 (57%)] Loss: -1099.885010\n",
      "Train Epoch: 1621 [45568/60000 (76%)] Loss: -1369.856201\n",
      "Train Epoch: 1621 [56832/60000 (95%)] Loss: -1396.840576\n",
      "    epoch          : 1621\n",
      "    loss           : -1343.081790557689\n",
      "Train Epoch: 1622 [512/60000 (1%)] Loss: -1510.531616\n",
      "Train Epoch: 1622 [11776/60000 (20%)] Loss: -1483.893433\n",
      "Train Epoch: 1622 [23040/60000 (38%)] Loss: -1252.019653\n",
      "Train Epoch: 1622 [34304/60000 (57%)] Loss: -1378.587402\n",
      "Train Epoch: 1622 [45568/60000 (76%)] Loss: -1207.879272\n",
      "Train Epoch: 1622 [56832/60000 (95%)] Loss: -1355.423462\n",
      "    epoch          : 1622\n",
      "    loss           : -1342.7878604177702\n",
      "Train Epoch: 1623 [512/60000 (1%)] Loss: -1086.139160\n",
      "Train Epoch: 1623 [11776/60000 (20%)] Loss: -1354.728760\n",
      "Train Epoch: 1623 [23040/60000 (38%)] Loss: -1368.955566\n",
      "Train Epoch: 1623 [34304/60000 (57%)] Loss: -1514.680420\n",
      "Train Epoch: 1623 [45568/60000 (76%)] Loss: -1507.013672\n",
      "Train Epoch: 1623 [56832/60000 (95%)] Loss: -1489.568115\n",
      "    epoch          : 1623\n",
      "    loss           : -1366.9929971641068\n",
      "Train Epoch: 1624 [512/60000 (1%)] Loss: -1394.974976\n",
      "Train Epoch: 1624 [11776/60000 (20%)] Loss: -1358.722656\n",
      "Train Epoch: 1624 [23040/60000 (38%)] Loss: -1344.603516\n",
      "Train Epoch: 1624 [34304/60000 (57%)] Loss: -1377.437744\n",
      "Train Epoch: 1624 [45568/60000 (76%)] Loss: -1514.668213\n",
      "Train Epoch: 1624 [56832/60000 (95%)] Loss: -1194.075562\n",
      "    epoch          : 1624\n",
      "    loss           : -1345.5563209663003\n",
      "Train Epoch: 1625 [512/60000 (1%)] Loss: -1364.096069\n",
      "Train Epoch: 1625 [11776/60000 (20%)] Loss: -1490.873779\n",
      "Train Epoch: 1625 [23040/60000 (38%)] Loss: -1394.432983\n",
      "Train Epoch: 1625 [34304/60000 (57%)] Loss: -1516.392822\n",
      "Train Epoch: 1625 [45568/60000 (76%)] Loss: -1523.774048\n",
      "Train Epoch: 1625 [56832/60000 (95%)] Loss: -1391.928589\n",
      "    epoch          : 1625\n",
      "    loss           : -1387.4734041892875\n",
      "Train Epoch: 1626 [512/60000 (1%)] Loss: -1275.758057\n",
      "Train Epoch: 1626 [11776/60000 (20%)] Loss: -1350.225586\n",
      "Train Epoch: 1626 [23040/60000 (38%)] Loss: -1509.884888\n",
      "Train Epoch: 1626 [34304/60000 (57%)] Loss: -1329.703369\n",
      "Train Epoch: 1626 [45568/60000 (76%)] Loss: -1220.148071\n",
      "Train Epoch: 1626 [56832/60000 (95%)] Loss: -1388.583374\n",
      "    epoch          : 1626\n",
      "    loss           : -1363.9796959828523\n",
      "Train Epoch: 1627 [512/60000 (1%)] Loss: -1516.312134\n",
      "Train Epoch: 1627 [11776/60000 (20%)] Loss: -1530.589355\n",
      "Train Epoch: 1627 [23040/60000 (38%)] Loss: -1356.335815\n",
      "Train Epoch: 1627 [34304/60000 (57%)] Loss: -1524.396729\n",
      "Train Epoch: 1627 [45568/60000 (76%)] Loss: -1481.687134\n",
      "Train Epoch: 1627 [56832/60000 (95%)] Loss: -1397.963989\n",
      "    epoch          : 1627\n",
      "    loss           : -1348.5272344384489\n",
      "Train Epoch: 1628 [512/60000 (1%)] Loss: -1515.698975\n",
      "Train Epoch: 1628 [11776/60000 (20%)] Loss: -1392.226196\n",
      "Train Epoch: 1628 [23040/60000 (38%)] Loss: -1345.609253\n",
      "Train Epoch: 1628 [34304/60000 (57%)] Loss: -1390.399780\n",
      "Train Epoch: 1628 [45568/60000 (76%)] Loss: -1223.868408\n",
      "Train Epoch: 1628 [56832/60000 (95%)] Loss: -1533.677490\n",
      "    epoch          : 1628\n",
      "    loss           : -1342.7404798949506\n",
      "Train Epoch: 1629 [512/60000 (1%)] Loss: -1384.565430\n",
      "Train Epoch: 1629 [11776/60000 (20%)] Loss: -1383.486084\n",
      "Train Epoch: 1629 [23040/60000 (38%)] Loss: -1482.891602\n",
      "Train Epoch: 1629 [34304/60000 (57%)] Loss: -1366.545532\n",
      "Train Epoch: 1629 [45568/60000 (76%)] Loss: -1397.689575\n",
      "Train Epoch: 1629 [56832/60000 (95%)] Loss: -1395.853027\n",
      "    epoch          : 1629\n",
      "    loss           : -1335.361294676355\n",
      "Train Epoch: 1630 [512/60000 (1%)] Loss: -1352.004150\n",
      "Train Epoch: 1630 [11776/60000 (20%)] Loss: -1344.859863\n",
      "Train Epoch: 1630 [23040/60000 (38%)] Loss: -1476.257446\n",
      "Train Epoch: 1630 [34304/60000 (57%)] Loss: -1219.952393\n",
      "Train Epoch: 1630 [45568/60000 (76%)] Loss: -1229.615479\n",
      "Train Epoch: 1630 [56832/60000 (95%)] Loss: -1229.837524\n",
      "    epoch          : 1630\n",
      "    loss           : -1343.7994043382548\n",
      "Train Epoch: 1631 [512/60000 (1%)] Loss: -1402.879639\n",
      "Train Epoch: 1631 [11776/60000 (20%)] Loss: -1227.392578\n",
      "Train Epoch: 1631 [23040/60000 (38%)] Loss: -1412.138428\n",
      "Train Epoch: 1631 [34304/60000 (57%)] Loss: -1487.122314\n",
      "Train Epoch: 1631 [45568/60000 (76%)] Loss: -1215.648682\n",
      "Train Epoch: 1631 [56832/60000 (95%)] Loss: -1523.819092\n",
      "    epoch          : 1631\n",
      "    loss           : -1369.6759933213057\n",
      "Train Epoch: 1632 [512/60000 (1%)] Loss: -1322.432617\n",
      "Train Epoch: 1632 [11776/60000 (20%)] Loss: -1504.932373\n",
      "Train Epoch: 1632 [23040/60000 (38%)] Loss: -1535.664062\n",
      "Train Epoch: 1632 [34304/60000 (57%)] Loss: -1365.603394\n",
      "Train Epoch: 1632 [45568/60000 (76%)] Loss: -1324.216797\n",
      "Train Epoch: 1632 [56832/60000 (95%)] Loss: -1528.541382\n",
      "    epoch          : 1632\n",
      "    loss           : -1347.7481561865511\n",
      "Train Epoch: 1633 [512/60000 (1%)] Loss: -1549.453247\n",
      "Train Epoch: 1633 [11776/60000 (20%)] Loss: -1469.499756\n",
      "Train Epoch: 1633 [23040/60000 (38%)] Loss: -1364.734863\n",
      "Train Epoch: 1633 [34304/60000 (57%)] Loss: -1360.987427\n",
      "Train Epoch: 1633 [45568/60000 (76%)] Loss: -1233.026611\n",
      "Train Epoch: 1633 [56832/60000 (95%)] Loss: -1363.849121\n",
      "    epoch          : 1633\n",
      "    loss           : -1345.5610717083773\n",
      "Train Epoch: 1634 [512/60000 (1%)] Loss: -1112.440918\n",
      "Train Epoch: 1634 [11776/60000 (20%)] Loss: -1070.247192\n",
      "Train Epoch: 1634 [23040/60000 (38%)] Loss: -1493.894897\n",
      "Train Epoch: 1634 [34304/60000 (57%)] Loss: -1385.740845\n",
      "Train Epoch: 1634 [45568/60000 (76%)] Loss: -1504.731812\n",
      "Train Epoch: 1634 [56832/60000 (95%)] Loss: -1350.389526\n",
      "    epoch          : 1634\n",
      "    loss           : -1382.8841404456878\n",
      "Train Epoch: 1635 [512/60000 (1%)] Loss: -1556.030029\n",
      "Train Epoch: 1635 [11776/60000 (20%)] Loss: -1464.166992\n",
      "Train Epoch: 1635 [23040/60000 (38%)] Loss: -1357.162720\n",
      "Train Epoch: 1635 [34304/60000 (57%)] Loss: -1361.592285\n",
      "Train Epoch: 1635 [45568/60000 (76%)] Loss: -1392.800781\n",
      "Train Epoch: 1635 [56832/60000 (95%)] Loss: -1516.429199\n",
      "    epoch          : 1635\n",
      "    loss           : -1381.7405054124736\n",
      "Train Epoch: 1636 [512/60000 (1%)] Loss: -1529.784302\n",
      "Train Epoch: 1636 [11776/60000 (20%)] Loss: -1206.245850\n",
      "Train Epoch: 1636 [23040/60000 (38%)] Loss: -1540.958618\n",
      "Train Epoch: 1636 [34304/60000 (57%)] Loss: -1364.294434\n",
      "Train Epoch: 1636 [45568/60000 (76%)] Loss: -1516.494873\n",
      "Train Epoch: 1636 [56832/60000 (95%)] Loss: -1396.412109\n",
      "    epoch          : 1636\n",
      "    loss           : -1356.1060959983006\n",
      "Train Epoch: 1637 [512/60000 (1%)] Loss: -1512.445557\n",
      "Train Epoch: 1637 [11776/60000 (20%)] Loss: -1373.941528\n",
      "Train Epoch: 1637 [23040/60000 (38%)] Loss: -1330.610596\n",
      "Train Epoch: 1637 [34304/60000 (57%)] Loss: -1341.793213\n",
      "Train Epoch: 1637 [45568/60000 (76%)] Loss: -1251.355957\n",
      "Train Epoch: 1637 [56832/60000 (95%)] Loss: -1093.999268\n",
      "    epoch          : 1637\n",
      "    loss           : -1345.4048423982608\n",
      "Train Epoch: 1638 [512/60000 (1%)] Loss: -1527.562744\n",
      "Train Epoch: 1638 [11776/60000 (20%)] Loss: -1391.202026\n",
      "Train Epoch: 1638 [23040/60000 (38%)] Loss: -1373.423828\n",
      "Train Epoch: 1638 [34304/60000 (57%)] Loss: -1501.197510\n",
      "Train Epoch: 1638 [45568/60000 (76%)] Loss: -1402.320679\n",
      "Train Epoch: 1638 [56832/60000 (95%)] Loss: -1360.219971\n",
      "    epoch          : 1638\n",
      "    loss           : -1362.1839547884667\n",
      "Train Epoch: 1639 [512/60000 (1%)] Loss: -1362.650146\n",
      "Train Epoch: 1639 [11776/60000 (20%)] Loss: -1224.559326\n",
      "Train Epoch: 1639 [23040/60000 (38%)] Loss: -1376.327759\n",
      "Train Epoch: 1639 [34304/60000 (57%)] Loss: -1343.561646\n",
      "Train Epoch: 1639 [45568/60000 (76%)] Loss: -1355.369385\n",
      "Train Epoch: 1639 [56832/60000 (95%)] Loss: -1387.514893\n",
      "    epoch          : 1639\n",
      "    loss           : -1374.341699977379\n",
      "Train Epoch: 1640 [512/60000 (1%)] Loss: -1237.369507\n",
      "Train Epoch: 1640 [11776/60000 (20%)] Loss: -1405.429443\n",
      "Train Epoch: 1640 [23040/60000 (38%)] Loss: -1123.792725\n",
      "Train Epoch: 1640 [34304/60000 (57%)] Loss: -1274.217407\n",
      "Train Epoch: 1640 [45568/60000 (76%)] Loss: -1388.155396\n",
      "Train Epoch: 1640 [56832/60000 (95%)] Loss: -1232.448730\n",
      "    epoch          : 1640\n",
      "    loss           : -1369.2623835849224\n",
      "Train Epoch: 1641 [512/60000 (1%)] Loss: -1357.220947\n",
      "Train Epoch: 1641 [11776/60000 (20%)] Loss: -1236.905762\n",
      "Train Epoch: 1641 [23040/60000 (38%)] Loss: -1374.841309\n",
      "Train Epoch: 1641 [34304/60000 (57%)] Loss: -1347.129883\n",
      "Train Epoch: 1641 [45568/60000 (76%)] Loss: -1236.383179\n",
      "Train Epoch: 1641 [56832/60000 (95%)] Loss: -1082.791870\n",
      "    epoch          : 1641\n",
      "    loss           : -1360.9280016193281\n",
      "Train Epoch: 1642 [512/60000 (1%)] Loss: -1482.374390\n",
      "Train Epoch: 1642 [11776/60000 (20%)] Loss: -1343.488647\n",
      "Train Epoch: 1642 [23040/60000 (38%)] Loss: -1397.976562\n",
      "Train Epoch: 1642 [34304/60000 (57%)] Loss: -1346.639893\n",
      "Train Epoch: 1642 [45568/60000 (76%)] Loss: -1222.962769\n",
      "Train Epoch: 1642 [56832/60000 (95%)] Loss: -1097.936279\n",
      "    epoch          : 1642\n",
      "    loss           : -1353.8854349427304\n",
      "Train Epoch: 1643 [512/60000 (1%)] Loss: -1475.760132\n",
      "Train Epoch: 1643 [11776/60000 (20%)] Loss: -1393.265015\n",
      "Train Epoch: 1643 [23040/60000 (38%)] Loss: -1216.806641\n",
      "Train Epoch: 1643 [34304/60000 (57%)] Loss: -1499.049316\n",
      "Train Epoch: 1643 [45568/60000 (76%)] Loss: -1415.668701\n",
      "Train Epoch: 1643 [56832/60000 (95%)] Loss: -1254.406372\n",
      "    epoch          : 1643\n",
      "    loss           : -1368.4374644823667\n",
      "Train Epoch: 1644 [512/60000 (1%)] Loss: -1354.848633\n",
      "Train Epoch: 1644 [11776/60000 (20%)] Loss: -1529.826904\n",
      "Train Epoch: 1644 [23040/60000 (38%)] Loss: -1528.077881\n",
      "Train Epoch: 1644 [34304/60000 (57%)] Loss: -1068.752441\n",
      "Train Epoch: 1644 [45568/60000 (76%)] Loss: -1494.047607\n",
      "Train Epoch: 1644 [56832/60000 (95%)] Loss: -1394.693848\n",
      "    epoch          : 1644\n",
      "    loss           : -1371.1113050212969\n",
      "Train Epoch: 1645 [512/60000 (1%)] Loss: -1546.691650\n",
      "Train Epoch: 1645 [11776/60000 (20%)] Loss: -1380.188232\n",
      "Train Epoch: 1645 [23040/60000 (38%)] Loss: -1401.001465\n",
      "Train Epoch: 1645 [34304/60000 (57%)] Loss: -1522.849976\n",
      "Train Epoch: 1645 [45568/60000 (76%)] Loss: -1364.276855\n",
      "Train Epoch: 1645 [56832/60000 (95%)] Loss: -1562.408569\n",
      "    epoch          : 1645\n",
      "    loss           : -1377.856303759214\n",
      "Train Epoch: 1646 [512/60000 (1%)] Loss: -1357.536377\n",
      "Train Epoch: 1646 [11776/60000 (20%)] Loss: -1516.045044\n",
      "Train Epoch: 1646 [23040/60000 (38%)] Loss: -1239.531494\n",
      "Train Epoch: 1646 [34304/60000 (57%)] Loss: -1553.994995\n",
      "Train Epoch: 1646 [45568/60000 (76%)] Loss: -1227.974487\n",
      "Train Epoch: 1646 [56832/60000 (95%)] Loss: -1533.132690\n",
      "    epoch          : 1646\n",
      "    loss           : -1367.6191730391506\n",
      "Train Epoch: 1647 [512/60000 (1%)] Loss: -1374.689575\n",
      "Train Epoch: 1647 [11776/60000 (20%)] Loss: -1412.184814\n",
      "Train Epoch: 1647 [23040/60000 (38%)] Loss: -1371.999268\n",
      "Train Epoch: 1647 [34304/60000 (57%)] Loss: -1527.856445\n",
      "Train Epoch: 1647 [45568/60000 (76%)] Loss: -1391.129395\n",
      "Train Epoch: 1647 [56832/60000 (95%)] Loss: -1487.186035\n",
      "    epoch          : 1647\n",
      "    loss           : -1365.499857239804\n",
      "Train Epoch: 1648 [512/60000 (1%)] Loss: -1389.742188\n",
      "Train Epoch: 1648 [11776/60000 (20%)] Loss: -1364.572998\n",
      "Train Epoch: 1648 [23040/60000 (38%)] Loss: -1357.299316\n",
      "Train Epoch: 1648 [34304/60000 (57%)] Loss: -1378.994873\n",
      "Train Epoch: 1648 [45568/60000 (76%)] Loss: -1543.332764\n",
      "Train Epoch: 1648 [56832/60000 (95%)] Loss: -1405.440674\n",
      "    epoch          : 1648\n",
      "    loss           : -1358.8583132641465\n",
      "Train Epoch: 1649 [512/60000 (1%)] Loss: -1489.025879\n",
      "Train Epoch: 1649 [11776/60000 (20%)] Loss: -1363.614380\n",
      "Train Epoch: 1649 [23040/60000 (38%)] Loss: -1211.098145\n",
      "Train Epoch: 1649 [34304/60000 (57%)] Loss: -1351.991943\n",
      "Train Epoch: 1649 [45568/60000 (76%)] Loss: -1366.662231\n",
      "Train Epoch: 1649 [56832/60000 (95%)] Loss: -1388.266235\n",
      "    epoch          : 1649\n",
      "    loss           : -1352.9674051575741\n",
      "Train Epoch: 1650 [512/60000 (1%)] Loss: -1520.486572\n",
      "Train Epoch: 1650 [11776/60000 (20%)] Loss: -1397.773682\n",
      "Train Epoch: 1650 [23040/60000 (38%)] Loss: -1346.224243\n",
      "Train Epoch: 1650 [34304/60000 (57%)] Loss: -1365.458252\n",
      "Train Epoch: 1650 [45568/60000 (76%)] Loss: -1340.379639\n",
      "Train Epoch: 1650 [56832/60000 (95%)] Loss: -1206.901733\n",
      "    epoch          : 1650\n",
      "    loss           : -1353.603038033523\n",
      "Train Epoch: 1651 [512/60000 (1%)] Loss: -1545.730591\n",
      "Train Epoch: 1651 [11776/60000 (20%)] Loss: -1451.297607\n",
      "Train Epoch: 1651 [23040/60000 (38%)] Loss: -964.396729\n",
      "Train Epoch: 1651 [34304/60000 (57%)] Loss: -1219.747192\n",
      "Train Epoch: 1651 [45568/60000 (76%)] Loss: -1227.293823\n",
      "Train Epoch: 1651 [56832/60000 (95%)] Loss: -1511.829346\n",
      "    epoch          : 1651\n",
      "    loss           : -1351.410368666137\n",
      "Train Epoch: 1652 [512/60000 (1%)] Loss: -1538.599854\n",
      "Train Epoch: 1652 [11776/60000 (20%)] Loss: -1549.784668\n",
      "Train Epoch: 1652 [23040/60000 (38%)] Loss: -1217.776367\n",
      "Train Epoch: 1652 [34304/60000 (57%)] Loss: -1188.945312\n",
      "Train Epoch: 1652 [45568/60000 (76%)] Loss: -1235.993530\n",
      "Train Epoch: 1652 [56832/60000 (95%)] Loss: -1368.163818\n",
      "    epoch          : 1652\n",
      "    loss           : -1366.1381522140935\n",
      "Train Epoch: 1653 [512/60000 (1%)] Loss: -1522.923340\n",
      "Train Epoch: 1653 [11776/60000 (20%)] Loss: -1383.472168\n",
      "Train Epoch: 1653 [23040/60000 (38%)] Loss: -1111.358765\n",
      "Train Epoch: 1653 [34304/60000 (57%)] Loss: -1522.387085\n",
      "Train Epoch: 1653 [45568/60000 (76%)] Loss: -1490.758301\n",
      "Train Epoch: 1653 [56832/60000 (95%)] Loss: -1229.258789\n",
      "    epoch          : 1653\n",
      "    loss           : -1338.4772838872705\n",
      "Train Epoch: 1654 [512/60000 (1%)] Loss: -1530.932739\n",
      "Train Epoch: 1654 [11776/60000 (20%)] Loss: -1211.806396\n",
      "Train Epoch: 1654 [23040/60000 (38%)] Loss: -1184.646484\n",
      "Train Epoch: 1654 [34304/60000 (57%)] Loss: -1083.652466\n",
      "Train Epoch: 1654 [45568/60000 (76%)] Loss: -1361.553955\n",
      "Train Epoch: 1654 [56832/60000 (95%)] Loss: -1235.639038\n",
      "    epoch          : 1654\n",
      "    loss           : -1357.9112507448358\n",
      "Train Epoch: 1655 [512/60000 (1%)] Loss: -1520.349731\n",
      "Train Epoch: 1655 [11776/60000 (20%)] Loss: -1515.673950\n",
      "Train Epoch: 1655 [23040/60000 (38%)] Loss: -1243.556152\n",
      "Train Epoch: 1655 [34304/60000 (57%)] Loss: -1519.748169\n",
      "Train Epoch: 1655 [45568/60000 (76%)] Loss: -1360.271973\n",
      "Train Epoch: 1655 [56832/60000 (95%)] Loss: -1503.030518\n",
      "    epoch          : 1655\n",
      "    loss           : -1351.7734224998344\n",
      "Train Epoch: 1656 [512/60000 (1%)] Loss: -1255.239502\n",
      "Train Epoch: 1656 [11776/60000 (20%)] Loss: -1500.010864\n",
      "Train Epoch: 1656 [23040/60000 (38%)] Loss: -1516.701416\n",
      "Train Epoch: 1656 [34304/60000 (57%)] Loss: -1385.893066\n",
      "Train Epoch: 1656 [45568/60000 (76%)] Loss: -1494.916626\n",
      "Train Epoch: 1656 [56832/60000 (95%)] Loss: -1508.733643\n",
      "    epoch          : 1656\n",
      "    loss           : -1373.4068075923597\n",
      "Train Epoch: 1657 [512/60000 (1%)] Loss: -1491.549805\n",
      "Train Epoch: 1657 [11776/60000 (20%)] Loss: -1371.034424\n",
      "Train Epoch: 1657 [23040/60000 (38%)] Loss: -1388.508057\n",
      "Train Epoch: 1657 [34304/60000 (57%)] Loss: -1525.418945\n",
      "Train Epoch: 1657 [45568/60000 (76%)] Loss: -1236.724609\n",
      "Train Epoch: 1657 [56832/60000 (95%)] Loss: -1273.132324\n",
      "    epoch          : 1657\n",
      "    loss           : -1379.3748396534031\n",
      "Train Epoch: 1658 [512/60000 (1%)] Loss: -967.814453\n",
      "Train Epoch: 1658 [11776/60000 (20%)] Loss: -1340.938354\n",
      "Train Epoch: 1658 [23040/60000 (38%)] Loss: -1342.256836\n",
      "Train Epoch: 1658 [34304/60000 (57%)] Loss: -1340.915283\n",
      "Train Epoch: 1658 [45568/60000 (76%)] Loss: -1377.821045\n",
      "Train Epoch: 1658 [56832/60000 (95%)] Loss: -1519.849487\n",
      "    epoch          : 1658\n",
      "    loss           : -1356.021872999978\n",
      "Train Epoch: 1659 [512/60000 (1%)] Loss: -1519.837036\n",
      "Train Epoch: 1659 [11776/60000 (20%)] Loss: -1090.384033\n",
      "Train Epoch: 1659 [23040/60000 (38%)] Loss: -1510.070557\n",
      "Train Epoch: 1659 [34304/60000 (57%)] Loss: -1529.403809\n",
      "Train Epoch: 1659 [45568/60000 (76%)] Loss: -1505.594482\n",
      "Train Epoch: 1659 [56832/60000 (95%)] Loss: -1501.606812\n",
      "    epoch          : 1659\n",
      "    loss           : -1370.5371797206037\n",
      "Train Epoch: 1660 [512/60000 (1%)] Loss: -1479.442139\n",
      "Train Epoch: 1660 [11776/60000 (20%)] Loss: -1497.096680\n",
      "Train Epoch: 1660 [23040/60000 (38%)] Loss: -1343.030884\n",
      "Train Epoch: 1660 [34304/60000 (57%)] Loss: -1343.817871\n",
      "Train Epoch: 1660 [45568/60000 (76%)] Loss: -1390.798340\n",
      "Train Epoch: 1660 [56832/60000 (95%)] Loss: -1492.585571\n",
      "    epoch          : 1660\n",
      "    loss           : -1357.2869276488568\n",
      "Train Epoch: 1661 [512/60000 (1%)] Loss: -1492.437744\n",
      "Train Epoch: 1661 [11776/60000 (20%)] Loss: -1232.372437\n",
      "Train Epoch: 1661 [23040/60000 (38%)] Loss: -1394.182007\n",
      "Train Epoch: 1661 [34304/60000 (57%)] Loss: -1245.074829\n",
      "Train Epoch: 1661 [45568/60000 (76%)] Loss: -1229.523193\n",
      "Train Epoch: 1661 [56832/60000 (95%)] Loss: -1391.936401\n",
      "    epoch          : 1661\n",
      "    loss           : -1355.8209807832363\n",
      "Train Epoch: 1662 [512/60000 (1%)] Loss: -1261.940552\n",
      "Train Epoch: 1662 [11776/60000 (20%)] Loss: -1382.289917\n",
      "Train Epoch: 1662 [23040/60000 (38%)] Loss: -1495.268677\n",
      "Train Epoch: 1662 [34304/60000 (57%)] Loss: -1511.028809\n",
      "Train Epoch: 1662 [45568/60000 (76%)] Loss: -1081.106079\n",
      "Train Epoch: 1662 [56832/60000 (95%)] Loss: -1395.973633\n",
      "    epoch          : 1662\n",
      "    loss           : -1364.1191782116216\n",
      "Train Epoch: 1663 [512/60000 (1%)] Loss: -1346.956909\n",
      "Train Epoch: 1663 [11776/60000 (20%)] Loss: -1231.146484\n",
      "Train Epoch: 1663 [23040/60000 (38%)] Loss: -1082.769165\n",
      "Train Epoch: 1663 [34304/60000 (57%)] Loss: -1125.724487\n",
      "Train Epoch: 1663 [45568/60000 (76%)] Loss: -1380.212402\n",
      "Train Epoch: 1663 [56832/60000 (95%)] Loss: -1236.061157\n",
      "    epoch          : 1663\n",
      "    loss           : -1347.3337867866128\n",
      "Train Epoch: 1664 [512/60000 (1%)] Loss: -1426.143677\n",
      "Train Epoch: 1664 [11776/60000 (20%)] Loss: -1259.749268\n",
      "Train Epoch: 1664 [23040/60000 (38%)] Loss: -1225.509521\n",
      "Train Epoch: 1664 [34304/60000 (57%)] Loss: -1097.063354\n",
      "Train Epoch: 1664 [45568/60000 (76%)] Loss: -1334.661743\n",
      "Train Epoch: 1664 [56832/60000 (95%)] Loss: -1500.401611\n",
      "    epoch          : 1664\n",
      "    loss           : -1356.939382951812\n",
      "Train Epoch: 1665 [512/60000 (1%)] Loss: -1234.590088\n",
      "Train Epoch: 1665 [11776/60000 (20%)] Loss: -1346.134399\n",
      "Train Epoch: 1665 [23040/60000 (38%)] Loss: -1495.522583\n",
      "Train Epoch: 1665 [34304/60000 (57%)] Loss: -1419.113037\n",
      "Train Epoch: 1665 [45568/60000 (76%)] Loss: -1365.093994\n",
      "Train Epoch: 1665 [56832/60000 (95%)] Loss: -1230.657227\n",
      "    epoch          : 1665\n",
      "    loss           : -1365.0562026891332\n",
      "Train Epoch: 1666 [512/60000 (1%)] Loss: -1536.425415\n",
      "Train Epoch: 1666 [11776/60000 (20%)] Loss: -1469.447998\n",
      "Train Epoch: 1666 [23040/60000 (38%)] Loss: -1510.043091\n",
      "Train Epoch: 1666 [34304/60000 (57%)] Loss: -1285.301758\n",
      "Train Epoch: 1666 [45568/60000 (76%)] Loss: -1367.410645\n",
      "Train Epoch: 1666 [56832/60000 (95%)] Loss: -1501.347046\n",
      "    epoch          : 1666\n",
      "    loss           : -1352.3623555501304\n",
      "Train Epoch: 1667 [512/60000 (1%)] Loss: -1390.299927\n",
      "Train Epoch: 1667 [11776/60000 (20%)] Loss: -1198.877319\n",
      "Train Epoch: 1667 [23040/60000 (38%)] Loss: -1373.334717\n",
      "Train Epoch: 1667 [34304/60000 (57%)] Loss: -1529.656250\n",
      "Train Epoch: 1667 [45568/60000 (76%)] Loss: -1043.875000\n",
      "Train Epoch: 1667 [56832/60000 (95%)] Loss: -1353.863647\n",
      "    epoch          : 1667\n",
      "    loss           : -1350.438588632702\n",
      "Train Epoch: 1668 [512/60000 (1%)] Loss: -1537.269409\n",
      "Train Epoch: 1668 [11776/60000 (20%)] Loss: -1529.551758\n",
      "Train Epoch: 1668 [23040/60000 (38%)] Loss: -1239.954590\n",
      "Train Epoch: 1668 [34304/60000 (57%)] Loss: -1359.323120\n",
      "Train Epoch: 1668 [45568/60000 (76%)] Loss: -1257.654785\n",
      "Train Epoch: 1668 [56832/60000 (95%)] Loss: -1517.109009\n",
      "    epoch          : 1668\n",
      "    loss           : -1363.9762621518582\n",
      "Train Epoch: 1669 [512/60000 (1%)] Loss: -1411.779053\n",
      "Train Epoch: 1669 [11776/60000 (20%)] Loss: -1515.185669\n",
      "Train Epoch: 1669 [23040/60000 (38%)] Loss: -1511.845825\n",
      "Train Epoch: 1669 [34304/60000 (57%)] Loss: -1103.502197\n",
      "Train Epoch: 1669 [45568/60000 (76%)] Loss: -1363.284790\n",
      "Train Epoch: 1669 [56832/60000 (95%)] Loss: -1513.072754\n",
      "    epoch          : 1669\n",
      "    loss           : -1383.6943786965924\n",
      "Train Epoch: 1670 [512/60000 (1%)] Loss: -1482.285767\n",
      "Train Epoch: 1670 [11776/60000 (20%)] Loss: -1530.580811\n",
      "Train Epoch: 1670 [23040/60000 (38%)] Loss: -1227.479126\n",
      "Train Epoch: 1670 [34304/60000 (57%)] Loss: -1330.489502\n",
      "Train Epoch: 1670 [45568/60000 (76%)] Loss: -1365.313110\n",
      "Train Epoch: 1670 [56832/60000 (95%)] Loss: -1093.442871\n",
      "    epoch          : 1670\n",
      "    loss           : -1354.2590959624383\n",
      "Train Epoch: 1671 [512/60000 (1%)] Loss: -1370.680908\n",
      "Train Epoch: 1671 [11776/60000 (20%)] Loss: -1371.724121\n",
      "Train Epoch: 1671 [23040/60000 (38%)] Loss: -1503.342896\n",
      "Train Epoch: 1671 [34304/60000 (57%)] Loss: -1362.486328\n",
      "Train Epoch: 1671 [45568/60000 (76%)] Loss: -1511.208740\n",
      "Train Epoch: 1671 [56832/60000 (95%)] Loss: -1458.799805\n",
      "    epoch          : 1671\n",
      "    loss           : -1366.043560135836\n",
      "Train Epoch: 1672 [512/60000 (1%)] Loss: -1344.068115\n",
      "Train Epoch: 1672 [11776/60000 (20%)] Loss: -1531.312378\n",
      "Train Epoch: 1672 [23040/60000 (38%)] Loss: -1248.545166\n",
      "Train Epoch: 1672 [34304/60000 (57%)] Loss: -1394.494141\n",
      "Train Epoch: 1672 [45568/60000 (76%)] Loss: -1332.889404\n",
      "Train Epoch: 1672 [56832/60000 (95%)] Loss: -1276.523804\n",
      "    epoch          : 1672\n",
      "    loss           : -1358.7183582715395\n",
      "Train Epoch: 1673 [512/60000 (1%)] Loss: -1223.496338\n",
      "Train Epoch: 1673 [11776/60000 (20%)] Loss: -1224.308716\n",
      "Train Epoch: 1673 [23040/60000 (38%)] Loss: -1362.618896\n",
      "Train Epoch: 1673 [34304/60000 (57%)] Loss: -1526.388306\n",
      "Train Epoch: 1673 [45568/60000 (76%)] Loss: -1401.370361\n",
      "Train Epoch: 1673 [56832/60000 (95%)] Loss: -953.650269\n",
      "    epoch          : 1673\n",
      "    loss           : -1370.867548883298\n",
      "Train Epoch: 1674 [512/60000 (1%)] Loss: -1400.681396\n",
      "Train Epoch: 1674 [11776/60000 (20%)] Loss: -1508.055176\n",
      "Train Epoch: 1674 [23040/60000 (38%)] Loss: -1260.706055\n",
      "Train Epoch: 1674 [34304/60000 (57%)] Loss: -1211.343506\n",
      "Train Epoch: 1674 [45568/60000 (76%)] Loss: -1227.502197\n",
      "Train Epoch: 1674 [56832/60000 (95%)] Loss: -1525.249268\n",
      "    epoch          : 1674\n",
      "    loss           : -1367.027455820202\n",
      "Train Epoch: 1675 [512/60000 (1%)] Loss: -1505.372559\n",
      "Train Epoch: 1675 [11776/60000 (20%)] Loss: -1232.664795\n",
      "Train Epoch: 1675 [23040/60000 (38%)] Loss: -1394.725220\n",
      "Train Epoch: 1675 [34304/60000 (57%)] Loss: -1397.166138\n",
      "Train Epoch: 1675 [45568/60000 (76%)] Loss: -1370.500122\n",
      "Train Epoch: 1675 [56832/60000 (95%)] Loss: -1354.866699\n",
      "    epoch          : 1675\n",
      "    loss           : -1338.4984061893097\n",
      "Train Epoch: 1676 [512/60000 (1%)] Loss: -1226.946289\n",
      "Train Epoch: 1676 [11776/60000 (20%)] Loss: -1219.890991\n",
      "Train Epoch: 1676 [23040/60000 (38%)] Loss: -1231.493286\n",
      "Train Epoch: 1676 [34304/60000 (57%)] Loss: -1128.063354\n",
      "Train Epoch: 1676 [45568/60000 (76%)] Loss: -1401.320068\n",
      "Train Epoch: 1676 [56832/60000 (95%)] Loss: -1223.660889\n",
      "    epoch          : 1676\n",
      "    loss           : -1354.665080442267\n",
      "Train Epoch: 1677 [512/60000 (1%)] Loss: -1380.320312\n",
      "Train Epoch: 1677 [11776/60000 (20%)] Loss: -1346.791992\n",
      "Train Epoch: 1677 [23040/60000 (38%)] Loss: -1477.448730\n",
      "Train Epoch: 1677 [34304/60000 (57%)] Loss: -1369.191040\n",
      "Train Epoch: 1677 [45568/60000 (76%)] Loss: -1216.485229\n",
      "Train Epoch: 1677 [56832/60000 (95%)] Loss: -1539.992920\n",
      "    epoch          : 1677\n",
      "    loss           : -1360.7377977963895\n",
      "Train Epoch: 1678 [512/60000 (1%)] Loss: -1542.503906\n",
      "Train Epoch: 1678 [11776/60000 (20%)] Loss: -1183.773804\n",
      "Train Epoch: 1678 [23040/60000 (38%)] Loss: -1243.135986\n",
      "Train Epoch: 1678 [34304/60000 (57%)] Loss: -1504.653809\n",
      "Train Epoch: 1678 [45568/60000 (76%)] Loss: -1383.614502\n",
      "Train Epoch: 1678 [56832/60000 (95%)] Loss: -1499.583984\n",
      "    epoch          : 1678\n",
      "    loss           : -1371.4849579374668\n",
      "Train Epoch: 1679 [512/60000 (1%)] Loss: -1500.571533\n",
      "Train Epoch: 1679 [11776/60000 (20%)] Loss: -1349.517456\n",
      "Train Epoch: 1679 [23040/60000 (38%)] Loss: -1376.858887\n",
      "Train Epoch: 1679 [34304/60000 (57%)] Loss: -1266.934937\n",
      "Train Epoch: 1679 [45568/60000 (76%)] Loss: -1531.837402\n",
      "Train Epoch: 1679 [56832/60000 (95%)] Loss: -1234.580566\n",
      "    epoch          : 1679\n",
      "    loss           : -1367.5852205955375\n",
      "Train Epoch: 1680 [512/60000 (1%)] Loss: -1367.442993\n",
      "Train Epoch: 1680 [11776/60000 (20%)] Loss: -1349.407104\n",
      "Train Epoch: 1680 [23040/60000 (38%)] Loss: -1519.710449\n",
      "Train Epoch: 1680 [34304/60000 (57%)] Loss: -1233.595703\n",
      "Train Epoch: 1680 [45568/60000 (76%)] Loss: -1514.496582\n",
      "Train Epoch: 1680 [56832/60000 (95%)] Loss: -1538.241211\n",
      "    epoch          : 1680\n",
      "    loss           : -1383.3632105595648\n",
      "Train Epoch: 1681 [512/60000 (1%)] Loss: -1340.819580\n",
      "Train Epoch: 1681 [11776/60000 (20%)] Loss: -1229.538818\n",
      "Train Epoch: 1681 [23040/60000 (38%)] Loss: -1347.879272\n",
      "Train Epoch: 1681 [34304/60000 (57%)] Loss: -1498.051025\n",
      "Train Epoch: 1681 [45568/60000 (76%)] Loss: -1476.712158\n",
      "Train Epoch: 1681 [56832/60000 (95%)] Loss: -1368.390381\n",
      "    epoch          : 1681\n",
      "    loss           : -1364.27251542086\n",
      "Train Epoch: 1682 [512/60000 (1%)] Loss: -1403.241333\n",
      "Train Epoch: 1682 [11776/60000 (20%)] Loss: -1120.019653\n",
      "Train Epoch: 1682 [23040/60000 (38%)] Loss: -1222.493774\n",
      "Train Epoch: 1682 [34304/60000 (57%)] Loss: -1372.130371\n",
      "Train Epoch: 1682 [45568/60000 (76%)] Loss: -1413.556885\n",
      "Train Epoch: 1682 [56832/60000 (95%)] Loss: -1288.368042\n",
      "    epoch          : 1682\n",
      "    loss           : -1367.2845379673154\n",
      "Train Epoch: 1683 [512/60000 (1%)] Loss: -1109.218994\n",
      "Train Epoch: 1683 [11776/60000 (20%)] Loss: -1257.793213\n",
      "Train Epoch: 1683 [23040/60000 (38%)] Loss: -1235.630371\n",
      "Train Epoch: 1683 [34304/60000 (57%)] Loss: -1402.328247\n",
      "Train Epoch: 1683 [45568/60000 (76%)] Loss: -1480.843994\n",
      "Train Epoch: 1683 [56832/60000 (95%)] Loss: -1482.985840\n",
      "    epoch          : 1683\n",
      "    loss           : -1361.975914561816\n",
      "Train Epoch: 1684 [512/60000 (1%)] Loss: -1073.618652\n",
      "Train Epoch: 1684 [11776/60000 (20%)] Loss: -1378.500366\n",
      "Train Epoch: 1684 [23040/60000 (38%)] Loss: -1545.733887\n",
      "Train Epoch: 1684 [34304/60000 (57%)] Loss: -1210.451172\n",
      "Train Epoch: 1684 [45568/60000 (76%)] Loss: -1402.356323\n",
      "Train Epoch: 1684 [56832/60000 (95%)] Loss: -1513.835449\n",
      "    epoch          : 1684\n",
      "    loss           : -1362.6857917052878\n",
      "Train Epoch: 1685 [512/60000 (1%)] Loss: -1240.735229\n",
      "Train Epoch: 1685 [11776/60000 (20%)] Loss: -1381.386719\n",
      "Train Epoch: 1685 [23040/60000 (38%)] Loss: -1361.690552\n",
      "Train Epoch: 1685 [34304/60000 (57%)] Loss: -1341.386475\n",
      "Train Epoch: 1685 [45568/60000 (76%)] Loss: -1271.626831\n",
      "Train Epoch: 1685 [56832/60000 (95%)] Loss: -1545.874023\n",
      "    epoch          : 1685\n",
      "    loss           : -1355.3687468275511\n",
      "Train Epoch: 1686 [512/60000 (1%)] Loss: -1237.305298\n",
      "Train Epoch: 1686 [11776/60000 (20%)] Loss: -1363.290283\n",
      "Train Epoch: 1686 [23040/60000 (38%)] Loss: -1380.695801\n",
      "Train Epoch: 1686 [34304/60000 (57%)] Loss: -1217.235962\n",
      "Train Epoch: 1686 [45568/60000 (76%)] Loss: -1364.782471\n",
      "Train Epoch: 1686 [56832/60000 (95%)] Loss: -1350.511353\n",
      "    epoch          : 1686\n",
      "    loss           : -1369.2614342641023\n",
      "Train Epoch: 1687 [512/60000 (1%)] Loss: -1200.449707\n",
      "Train Epoch: 1687 [11776/60000 (20%)] Loss: -1062.710571\n",
      "Train Epoch: 1687 [23040/60000 (38%)] Loss: -1192.287964\n",
      "Train Epoch: 1687 [34304/60000 (57%)] Loss: -1401.739502\n",
      "Train Epoch: 1687 [45568/60000 (76%)] Loss: -1229.982788\n",
      "Train Epoch: 1687 [56832/60000 (95%)] Loss: -1236.893555\n",
      "    epoch          : 1687\n",
      "    loss           : -1367.095381914559\n",
      "Train Epoch: 1688 [512/60000 (1%)] Loss: -1344.911499\n",
      "Train Epoch: 1688 [11776/60000 (20%)] Loss: -1346.556519\n",
      "Train Epoch: 1688 [23040/60000 (38%)] Loss: -1361.009521\n",
      "Train Epoch: 1688 [34304/60000 (57%)] Loss: -1234.898438\n",
      "Train Epoch: 1688 [45568/60000 (76%)] Loss: -1350.810181\n",
      "Train Epoch: 1688 [56832/60000 (95%)] Loss: -1362.828003\n",
      "    epoch          : 1688\n",
      "    loss           : -1361.2136568403514\n",
      "Train Epoch: 1689 [512/60000 (1%)] Loss: -1212.362183\n",
      "Train Epoch: 1689 [11776/60000 (20%)] Loss: -1394.770264\n",
      "Train Epoch: 1689 [23040/60000 (38%)] Loss: -1370.776489\n",
      "Train Epoch: 1689 [34304/60000 (57%)] Loss: -1222.528320\n",
      "Train Epoch: 1689 [45568/60000 (76%)] Loss: -1245.229126\n",
      "Train Epoch: 1689 [56832/60000 (95%)] Loss: -1390.284912\n",
      "    epoch          : 1689\n",
      "    loss           : -1378.9206153309276\n",
      "Train Epoch: 1690 [512/60000 (1%)] Loss: -1517.654297\n",
      "Train Epoch: 1690 [11776/60000 (20%)] Loss: -1515.346680\n",
      "Train Epoch: 1690 [23040/60000 (38%)] Loss: -1349.509033\n",
      "Train Epoch: 1690 [34304/60000 (57%)] Loss: -1414.356445\n",
      "Train Epoch: 1690 [45568/60000 (76%)] Loss: -1507.066650\n",
      "Train Epoch: 1690 [56832/60000 (95%)] Loss: -1235.558350\n",
      "    epoch          : 1690\n",
      "    loss           : -1353.912199031162\n",
      "Train Epoch: 1691 [512/60000 (1%)] Loss: -1503.147705\n",
      "Train Epoch: 1691 [11776/60000 (20%)] Loss: -1559.570557\n",
      "Train Epoch: 1691 [23040/60000 (38%)] Loss: -1366.889526\n",
      "Train Epoch: 1691 [34304/60000 (57%)] Loss: -1246.863892\n",
      "Train Epoch: 1691 [45568/60000 (76%)] Loss: -1560.649658\n",
      "Train Epoch: 1691 [56832/60000 (95%)] Loss: -1358.405640\n",
      "    epoch          : 1691\n",
      "    loss           : -1362.6006795592227\n",
      "Train Epoch: 1692 [512/60000 (1%)] Loss: -1514.034424\n",
      "Train Epoch: 1692 [11776/60000 (20%)] Loss: -1528.247559\n",
      "Train Epoch: 1692 [23040/60000 (38%)] Loss: -1360.291016\n",
      "Train Epoch: 1692 [34304/60000 (57%)] Loss: -1318.427368\n",
      "Train Epoch: 1692 [45568/60000 (76%)] Loss: -1481.314697\n",
      "Train Epoch: 1692 [56832/60000 (95%)] Loss: -1192.641602\n",
      "    epoch          : 1692\n",
      "    loss           : -1362.230607027388\n",
      "Train Epoch: 1693 [512/60000 (1%)] Loss: -1381.008789\n",
      "Train Epoch: 1693 [11776/60000 (20%)] Loss: -1542.554443\n",
      "Train Epoch: 1693 [23040/60000 (38%)] Loss: -1514.673706\n",
      "Train Epoch: 1693 [34304/60000 (57%)] Loss: -1409.639160\n",
      "Train Epoch: 1693 [45568/60000 (76%)] Loss: -1504.454590\n",
      "Train Epoch: 1693 [56832/60000 (95%)] Loss: -1355.165039\n",
      "    epoch          : 1693\n",
      "    loss           : -1359.7063971050716\n",
      "Train Epoch: 1694 [512/60000 (1%)] Loss: -1520.744507\n",
      "Train Epoch: 1694 [11776/60000 (20%)] Loss: -1248.226685\n",
      "Train Epoch: 1694 [23040/60000 (38%)] Loss: -1372.746216\n",
      "Train Epoch: 1694 [34304/60000 (57%)] Loss: -1363.866699\n",
      "Train Epoch: 1694 [45568/60000 (76%)] Loss: -1540.991699\n",
      "Train Epoch: 1694 [56832/60000 (95%)] Loss: -1369.718872\n",
      "    epoch          : 1694\n",
      "    loss           : -1368.7884624933793\n",
      "Train Epoch: 1695 [512/60000 (1%)] Loss: -1362.365723\n",
      "Train Epoch: 1695 [11776/60000 (20%)] Loss: -1216.725098\n",
      "Train Epoch: 1695 [23040/60000 (38%)] Loss: -1248.796509\n",
      "Train Epoch: 1695 [34304/60000 (57%)] Loss: -1489.031982\n",
      "Train Epoch: 1695 [45568/60000 (76%)] Loss: -1103.786743\n",
      "Train Epoch: 1695 [56832/60000 (95%)] Loss: -1390.088379\n",
      "    epoch          : 1695\n",
      "    loss           : -1357.244186487575\n",
      "Train Epoch: 1696 [512/60000 (1%)] Loss: -1366.968018\n",
      "Train Epoch: 1696 [11776/60000 (20%)] Loss: -1560.331055\n",
      "Train Epoch: 1696 [23040/60000 (38%)] Loss: -1141.699341\n",
      "Train Epoch: 1696 [34304/60000 (57%)] Loss: -1202.516357\n",
      "Train Epoch: 1696 [45568/60000 (76%)] Loss: -1365.469238\n",
      "Train Epoch: 1696 [56832/60000 (95%)] Loss: -1360.437378\n",
      "    epoch          : 1696\n",
      "    loss           : -1356.820384914592\n",
      "Train Epoch: 1697 [512/60000 (1%)] Loss: -1546.663696\n",
      "Train Epoch: 1697 [11776/60000 (20%)] Loss: -1357.983276\n",
      "Train Epoch: 1697 [23040/60000 (38%)] Loss: -1246.427734\n",
      "Train Epoch: 1697 [34304/60000 (57%)] Loss: -1398.420654\n",
      "Train Epoch: 1697 [45568/60000 (76%)] Loss: -1232.028076\n",
      "Train Epoch: 1697 [56832/60000 (95%)] Loss: -1087.395996\n",
      "    epoch          : 1697\n",
      "    loss           : -1378.5870164774233\n",
      "Train Epoch: 1698 [512/60000 (1%)] Loss: -1392.302856\n",
      "Train Epoch: 1698 [11776/60000 (20%)] Loss: -1336.169678\n",
      "Train Epoch: 1698 [23040/60000 (38%)] Loss: -1548.887939\n",
      "Train Epoch: 1698 [34304/60000 (57%)] Loss: -1248.468262\n",
      "Train Epoch: 1698 [45568/60000 (76%)] Loss: -1520.063110\n",
      "Train Epoch: 1698 [56832/60000 (95%)] Loss: -1376.243286\n",
      "    epoch          : 1698\n",
      "    loss           : -1352.8140148443017\n",
      "Train Epoch: 1699 [512/60000 (1%)] Loss: -1527.342407\n",
      "Train Epoch: 1699 [11776/60000 (20%)] Loss: -1250.381714\n",
      "Train Epoch: 1699 [23040/60000 (38%)] Loss: -1555.862671\n",
      "Train Epoch: 1699 [34304/60000 (57%)] Loss: -1533.487793\n",
      "Train Epoch: 1699 [45568/60000 (76%)] Loss: -1478.924561\n",
      "Train Epoch: 1699 [56832/60000 (95%)] Loss: -1572.200562\n",
      "    epoch          : 1699\n",
      "    loss           : -1365.3351064563471\n",
      "Train Epoch: 1700 [512/60000 (1%)] Loss: -1499.080688\n",
      "Train Epoch: 1700 [11776/60000 (20%)] Loss: -1517.934326\n",
      "Train Epoch: 1700 [23040/60000 (38%)] Loss: -1371.493774\n",
      "Train Epoch: 1700 [34304/60000 (57%)] Loss: -1325.305054\n",
      "Train Epoch: 1700 [45568/60000 (76%)] Loss: -1554.091553\n",
      "Train Epoch: 1700 [56832/60000 (95%)] Loss: -1493.870361\n",
      "    epoch          : 1700\n",
      "    loss           : -1369.175749525512\n",
      "Saving checkpoint: saved/models/Mnist_DeepGenerativeOperad/0127_111843/checkpoint-epoch1700.pth ...\n",
      "Train Epoch: 1701 [512/60000 (1%)] Loss: -1395.573486\n",
      "Train Epoch: 1701 [11776/60000 (20%)] Loss: -1503.961548\n",
      "Train Epoch: 1701 [23040/60000 (38%)] Loss: -1367.922607\n",
      "Train Epoch: 1701 [34304/60000 (57%)] Loss: -1254.569336\n",
      "Train Epoch: 1701 [45568/60000 (76%)] Loss: -1389.771973\n",
      "Train Epoch: 1701 [56832/60000 (95%)] Loss: -1489.438965\n",
      "    epoch          : 1701\n",
      "    loss           : -1346.125212416137\n",
      "Train Epoch: 1702 [512/60000 (1%)] Loss: -1483.908936\n",
      "Train Epoch: 1702 [11776/60000 (20%)] Loss: -1378.573486\n",
      "Train Epoch: 1702 [23040/60000 (38%)] Loss: -1253.927246\n",
      "Train Epoch: 1702 [34304/60000 (57%)] Loss: -1412.605225\n",
      "Train Epoch: 1702 [45568/60000 (76%)] Loss: -1541.306030\n",
      "Train Epoch: 1702 [56832/60000 (95%)] Loss: -1248.765015\n",
      "    epoch          : 1702\n",
      "    loss           : -1374.2455802960585\n",
      "Train Epoch: 1703 [512/60000 (1%)] Loss: -1520.527222\n",
      "Train Epoch: 1703 [11776/60000 (20%)] Loss: -1544.859863\n",
      "Train Epoch: 1703 [23040/60000 (38%)] Loss: -1215.743530\n",
      "Train Epoch: 1703 [34304/60000 (57%)] Loss: -1486.665527\n",
      "Train Epoch: 1703 [45568/60000 (76%)] Loss: -1215.153442\n",
      "Train Epoch: 1703 [56832/60000 (95%)] Loss: -1545.545532\n",
      "    epoch          : 1703\n",
      "    loss           : -1367.0290577344301\n",
      "Train Epoch: 1704 [512/60000 (1%)] Loss: -1395.502075\n",
      "Train Epoch: 1704 [11776/60000 (20%)] Loss: -1363.438843\n",
      "Train Epoch: 1704 [23040/60000 (38%)] Loss: -1364.490234\n",
      "Train Epoch: 1704 [34304/60000 (57%)] Loss: -1387.488281\n",
      "Train Epoch: 1704 [45568/60000 (76%)] Loss: -1249.475220\n",
      "Train Epoch: 1704 [56832/60000 (95%)] Loss: -1546.417725\n",
      "    epoch          : 1704\n",
      "    loss           : -1361.121360477081\n",
      "Train Epoch: 1705 [512/60000 (1%)] Loss: -1424.070190\n",
      "Train Epoch: 1705 [11776/60000 (20%)] Loss: -1382.861816\n",
      "Train Epoch: 1705 [23040/60000 (38%)] Loss: -1392.288452\n",
      "Train Epoch: 1705 [34304/60000 (57%)] Loss: -1368.232300\n",
      "Train Epoch: 1705 [45568/60000 (76%)] Loss: -1349.219849\n",
      "Train Epoch: 1705 [56832/60000 (95%)] Loss: -1279.359619\n",
      "    epoch          : 1705\n",
      "    loss           : -1370.1970547606043\n",
      "Train Epoch: 1706 [512/60000 (1%)] Loss: -1342.940674\n",
      "Train Epoch: 1706 [11776/60000 (20%)] Loss: -1326.458252\n",
      "Train Epoch: 1706 [23040/60000 (38%)] Loss: -1520.421143\n",
      "Train Epoch: 1706 [34304/60000 (57%)] Loss: -1515.841309\n",
      "Train Epoch: 1706 [45568/60000 (76%)] Loss: -1354.865479\n",
      "Train Epoch: 1706 [56832/60000 (95%)] Loss: -1087.907715\n",
      "    epoch          : 1706\n",
      "    loss           : -1364.7166437698622\n",
      "Train Epoch: 1707 [512/60000 (1%)] Loss: -1277.444824\n",
      "Train Epoch: 1707 [11776/60000 (20%)] Loss: -1228.781006\n",
      "Train Epoch: 1707 [23040/60000 (38%)] Loss: -1233.892578\n",
      "Train Epoch: 1707 [34304/60000 (57%)] Loss: -1355.991577\n",
      "Train Epoch: 1707 [45568/60000 (76%)] Loss: -1196.302734\n",
      "Train Epoch: 1707 [56832/60000 (95%)] Loss: -1451.506836\n",
      "    epoch          : 1707\n",
      "    loss           : -1357.5311162054202\n",
      "Train Epoch: 1708 [512/60000 (1%)] Loss: -1230.173340\n",
      "Train Epoch: 1708 [11776/60000 (20%)] Loss: -1377.432617\n",
      "Train Epoch: 1708 [23040/60000 (38%)] Loss: -1342.656250\n",
      "Train Epoch: 1708 [34304/60000 (57%)] Loss: -1202.099121\n",
      "Train Epoch: 1708 [45568/60000 (76%)] Loss: -1545.361328\n",
      "Train Epoch: 1708 [56832/60000 (95%)] Loss: -1546.159668\n",
      "    epoch          : 1708\n",
      "    loss           : -1363.259307344081\n",
      "Train Epoch: 1709 [512/60000 (1%)] Loss: -1364.349487\n",
      "Train Epoch: 1709 [11776/60000 (20%)] Loss: -1523.871094\n",
      "Train Epoch: 1709 [23040/60000 (38%)] Loss: -1523.303467\n",
      "Train Epoch: 1709 [34304/60000 (57%)] Loss: -1408.244995\n",
      "Train Epoch: 1709 [45568/60000 (76%)] Loss: -1356.810425\n",
      "Train Epoch: 1709 [56832/60000 (95%)] Loss: -1514.521973\n",
      "    epoch          : 1709\n",
      "    loss           : -1357.6516165005958\n",
      "Train Epoch: 1710 [512/60000 (1%)] Loss: -1413.727173\n",
      "Train Epoch: 1710 [11776/60000 (20%)] Loss: -1515.938721\n",
      "Train Epoch: 1710 [23040/60000 (38%)] Loss: -1396.611328\n",
      "Train Epoch: 1710 [34304/60000 (57%)] Loss: -1242.317017\n",
      "Train Epoch: 1710 [45568/60000 (76%)] Loss: -1371.085815\n",
      "Train Epoch: 1710 [56832/60000 (95%)] Loss: -1215.329346\n",
      "    epoch          : 1710\n",
      "    loss           : -1357.2476682501324\n",
      "Train Epoch: 1711 [512/60000 (1%)] Loss: -1413.894409\n",
      "Train Epoch: 1711 [11776/60000 (20%)] Loss: -1252.974854\n",
      "Train Epoch: 1711 [23040/60000 (38%)] Loss: -1555.236328\n",
      "Train Epoch: 1711 [34304/60000 (57%)] Loss: -1517.842285\n",
      "Train Epoch: 1711 [45568/60000 (76%)] Loss: -1510.041992\n",
      "Train Epoch: 1711 [56832/60000 (95%)] Loss: -1121.734131\n",
      "    epoch          : 1711\n",
      "    loss           : -1348.5069514560162\n",
      "Train Epoch: 1712 [512/60000 (1%)] Loss: -1467.991821\n",
      "Train Epoch: 1712 [11776/60000 (20%)] Loss: -1204.454590\n",
      "Train Epoch: 1712 [23040/60000 (38%)] Loss: -1202.090088\n",
      "Train Epoch: 1712 [34304/60000 (57%)] Loss: -1246.873779\n",
      "Train Epoch: 1712 [45568/60000 (76%)] Loss: -1200.751465\n",
      "Train Epoch: 1712 [56832/60000 (95%)] Loss: -1497.689697\n",
      "    epoch          : 1712\n",
      "    loss           : -1338.8205128470383\n",
      "Train Epoch: 1713 [512/60000 (1%)] Loss: -1365.198730\n",
      "Train Epoch: 1713 [11776/60000 (20%)] Loss: -1365.883545\n",
      "Train Epoch: 1713 [23040/60000 (38%)] Loss: -1343.254639\n",
      "Train Epoch: 1713 [34304/60000 (57%)] Loss: -1323.344727\n",
      "Train Epoch: 1713 [45568/60000 (76%)] Loss: -1408.488281\n",
      "Train Epoch: 1713 [56832/60000 (95%)] Loss: -1379.369385\n",
      "    epoch          : 1713\n",
      "    loss           : -1353.183431161999\n",
      "Train Epoch: 1714 [512/60000 (1%)] Loss: -1488.665039\n",
      "Train Epoch: 1714 [11776/60000 (20%)] Loss: -1546.562622\n",
      "Train Epoch: 1714 [23040/60000 (38%)] Loss: -1384.360840\n",
      "Train Epoch: 1714 [34304/60000 (57%)] Loss: -1554.645996\n",
      "Train Epoch: 1714 [45568/60000 (76%)] Loss: -1393.186890\n",
      "Train Epoch: 1714 [56832/60000 (95%)] Loss: -1233.070312\n",
      "    epoch          : 1714\n",
      "    loss           : -1374.8766007073182\n",
      "Train Epoch: 1715 [512/60000 (1%)] Loss: -1398.407715\n",
      "Train Epoch: 1715 [11776/60000 (20%)] Loss: -1513.504517\n",
      "Train Epoch: 1715 [23040/60000 (38%)] Loss: -1382.909790\n",
      "Train Epoch: 1715 [34304/60000 (57%)] Loss: -1480.740234\n",
      "Train Epoch: 1715 [45568/60000 (76%)] Loss: -1544.793945\n",
      "Train Epoch: 1715 [56832/60000 (95%)] Loss: -1245.155396\n",
      "    epoch          : 1715\n",
      "    loss           : -1367.0774889584989\n",
      "Train Epoch: 1716 [512/60000 (1%)] Loss: -1204.532104\n",
      "Train Epoch: 1716 [11776/60000 (20%)] Loss: -1388.388550\n",
      "Train Epoch: 1716 [23040/60000 (38%)] Loss: -1352.622559\n",
      "Train Epoch: 1716 [34304/60000 (57%)] Loss: -1259.862549\n",
      "Train Epoch: 1716 [45568/60000 (76%)] Loss: -1257.100830\n",
      "Train Epoch: 1716 [56832/60000 (95%)] Loss: -1552.601318\n",
      "    epoch          : 1716\n",
      "    loss           : -1366.0562640691207\n",
      "Train Epoch: 1717 [512/60000 (1%)] Loss: -1362.149780\n",
      "Train Epoch: 1717 [11776/60000 (20%)] Loss: -1508.286011\n",
      "Train Epoch: 1717 [23040/60000 (38%)] Loss: -1504.372559\n",
      "Train Epoch: 1717 [34304/60000 (57%)] Loss: -1561.407715\n",
      "Train Epoch: 1717 [45568/60000 (76%)] Loss: -1362.996582\n",
      "Train Epoch: 1717 [56832/60000 (95%)] Loss: -1231.520386\n",
      "    epoch          : 1717\n",
      "    loss           : -1369.9597295556364\n",
      "Train Epoch: 1718 [512/60000 (1%)] Loss: -1475.779907\n",
      "Train Epoch: 1718 [11776/60000 (20%)] Loss: -1484.381714\n",
      "Train Epoch: 1718 [23040/60000 (38%)] Loss: -1227.742188\n",
      "Train Epoch: 1718 [34304/60000 (57%)] Loss: -1340.689209\n",
      "Train Epoch: 1718 [45568/60000 (76%)] Loss: -1524.554321\n",
      "Train Epoch: 1718 [56832/60000 (95%)] Loss: -1372.993286\n",
      "    epoch          : 1718\n",
      "    loss           : -1351.106026687191\n",
      "Train Epoch: 1719 [512/60000 (1%)] Loss: -1339.962524\n",
      "Train Epoch: 1719 [11776/60000 (20%)] Loss: -1533.606689\n",
      "Train Epoch: 1719 [23040/60000 (38%)] Loss: -1372.966919\n",
      "Train Epoch: 1719 [34304/60000 (57%)] Loss: -1526.968384\n",
      "Train Epoch: 1719 [45568/60000 (76%)] Loss: -1502.806274\n",
      "Train Epoch: 1719 [56832/60000 (95%)] Loss: -1384.894409\n",
      "    epoch          : 1719\n",
      "    loss           : -1376.7116113005384\n",
      "Train Epoch: 1720 [512/60000 (1%)] Loss: -1233.306274\n",
      "Train Epoch: 1720 [11776/60000 (20%)] Loss: -1374.500732\n",
      "Train Epoch: 1720 [23040/60000 (38%)] Loss: -1091.326172\n",
      "Train Epoch: 1720 [34304/60000 (57%)] Loss: -1514.003906\n",
      "Train Epoch: 1720 [45568/60000 (76%)] Loss: -1227.560059\n",
      "Train Epoch: 1720 [56832/60000 (95%)] Loss: -1353.613037\n",
      "    epoch          : 1720\n",
      "    loss           : -1357.6952266369835\n",
      "Train Epoch: 1721 [512/60000 (1%)] Loss: -1229.262695\n",
      "Train Epoch: 1721 [11776/60000 (20%)] Loss: -1492.716797\n",
      "Train Epoch: 1721 [23040/60000 (38%)] Loss: -1341.875000\n",
      "Train Epoch: 1721 [34304/60000 (57%)] Loss: -1529.433838\n",
      "Train Epoch: 1721 [45568/60000 (76%)] Loss: -1227.323975\n",
      "Train Epoch: 1721 [56832/60000 (95%)] Loss: -1421.094360\n",
      "    epoch          : 1721\n",
      "    loss           : -1358.40272668526\n",
      "Train Epoch: 1722 [512/60000 (1%)] Loss: -1526.111084\n",
      "Train Epoch: 1722 [11776/60000 (20%)] Loss: -1480.475830\n",
      "Train Epoch: 1722 [23040/60000 (38%)] Loss: -1338.423462\n",
      "Train Epoch: 1722 [34304/60000 (57%)] Loss: -1464.743164\n",
      "Train Epoch: 1722 [45568/60000 (76%)] Loss: -1535.063110\n",
      "Train Epoch: 1722 [56832/60000 (95%)] Loss: -1210.813843\n",
      "    epoch          : 1722\n",
      "    loss           : -1364.2710347148657\n",
      "Train Epoch: 1723 [512/60000 (1%)] Loss: -1513.494385\n",
      "Train Epoch: 1723 [11776/60000 (20%)] Loss: -1380.208374\n",
      "Train Epoch: 1723 [23040/60000 (38%)] Loss: -1555.197876\n",
      "Train Epoch: 1723 [34304/60000 (57%)] Loss: -1511.367798\n",
      "Train Epoch: 1723 [45568/60000 (76%)] Loss: -1564.140625\n",
      "Train Epoch: 1723 [56832/60000 (95%)] Loss: -1354.180298\n",
      "    epoch          : 1723\n",
      "    loss           : -1357.9423038461116\n",
      "Train Epoch: 1724 [512/60000 (1%)] Loss: -1526.709839\n",
      "Train Epoch: 1724 [11776/60000 (20%)] Loss: -1472.142090\n",
      "Train Epoch: 1724 [23040/60000 (38%)] Loss: -1380.039551\n",
      "Train Epoch: 1724 [34304/60000 (57%)] Loss: -1361.599609\n",
      "Train Epoch: 1724 [45568/60000 (76%)] Loss: -1092.913086\n",
      "Train Epoch: 1724 [56832/60000 (95%)] Loss: -1446.910767\n",
      "    epoch          : 1724\n",
      "    loss           : -1363.5326965676861\n",
      "Train Epoch: 1725 [512/60000 (1%)] Loss: -1259.331543\n",
      "Train Epoch: 1725 [11776/60000 (20%)] Loss: -1495.749756\n",
      "Train Epoch: 1725 [23040/60000 (38%)] Loss: -1231.481201\n",
      "Train Epoch: 1725 [34304/60000 (57%)] Loss: -1360.362915\n",
      "Train Epoch: 1725 [45568/60000 (76%)] Loss: -1568.956177\n",
      "Train Epoch: 1725 [56832/60000 (95%)] Loss: -1507.178467\n",
      "    epoch          : 1725\n",
      "    loss           : -1375.0982472910046\n",
      "Train Epoch: 1726 [512/60000 (1%)] Loss: -1204.878662\n",
      "Train Epoch: 1726 [11776/60000 (20%)] Loss: -1425.208252\n",
      "Train Epoch: 1726 [23040/60000 (38%)] Loss: -1393.826172\n",
      "Train Epoch: 1726 [34304/60000 (57%)] Loss: -1366.976196\n",
      "Train Epoch: 1726 [45568/60000 (76%)] Loss: -1363.678223\n",
      "Train Epoch: 1726 [56832/60000 (95%)] Loss: -1372.493652\n",
      "    epoch          : 1726\n",
      "    loss           : -1366.6336594058969\n",
      "Train Epoch: 1727 [512/60000 (1%)] Loss: -1071.770264\n",
      "Train Epoch: 1727 [11776/60000 (20%)] Loss: -1336.841675\n",
      "Train Epoch: 1727 [23040/60000 (38%)] Loss: -1385.816895\n",
      "Train Epoch: 1727 [34304/60000 (57%)] Loss: -1369.564453\n",
      "Train Epoch: 1727 [45568/60000 (76%)] Loss: -1255.417603\n",
      "Train Epoch: 1727 [56832/60000 (95%)] Loss: -1218.597534\n",
      "    epoch          : 1727\n",
      "    loss           : -1341.3430524060957\n",
      "Train Epoch: 1728 [512/60000 (1%)] Loss: -1091.862793\n",
      "Train Epoch: 1728 [11776/60000 (20%)] Loss: -1241.908081\n",
      "Train Epoch: 1728 [23040/60000 (38%)] Loss: -1218.318481\n",
      "Train Epoch: 1728 [34304/60000 (57%)] Loss: -1243.830811\n",
      "Train Epoch: 1728 [45568/60000 (76%)] Loss: -1358.487793\n",
      "Train Epoch: 1728 [56832/60000 (95%)] Loss: -1517.259766\n",
      "    epoch          : 1728\n",
      "    loss           : -1348.360088111317\n",
      "Train Epoch: 1729 [512/60000 (1%)] Loss: -1363.397339\n",
      "Train Epoch: 1729 [11776/60000 (20%)] Loss: -1496.577515\n",
      "Train Epoch: 1729 [23040/60000 (38%)] Loss: -1382.058105\n",
      "Train Epoch: 1729 [34304/60000 (57%)] Loss: -1382.426147\n",
      "Train Epoch: 1729 [45568/60000 (76%)] Loss: -1372.054932\n",
      "Train Epoch: 1729 [56832/60000 (95%)] Loss: -1533.311768\n",
      "    epoch          : 1729\n",
      "    loss           : -1391.7229007354563\n",
      "Train Epoch: 1730 [512/60000 (1%)] Loss: -1506.581787\n",
      "Train Epoch: 1730 [11776/60000 (20%)] Loss: -1525.058350\n",
      "Train Epoch: 1730 [23040/60000 (38%)] Loss: -1363.467041\n",
      "Train Epoch: 1730 [34304/60000 (57%)] Loss: -1357.539429\n",
      "Train Epoch: 1730 [45568/60000 (76%)] Loss: -1400.571899\n",
      "Train Epoch: 1730 [56832/60000 (95%)] Loss: -1244.531616\n",
      "    epoch          : 1730\n",
      "    loss           : -1381.2068172821218\n",
      "Train Epoch: 1731 [512/60000 (1%)] Loss: -1361.245239\n",
      "Train Epoch: 1731 [11776/60000 (20%)] Loss: -1413.970215\n",
      "Train Epoch: 1731 [23040/60000 (38%)] Loss: -1395.175415\n",
      "Train Epoch: 1731 [34304/60000 (57%)] Loss: -1549.762939\n",
      "Train Epoch: 1731 [45568/60000 (76%)] Loss: -1345.347412\n",
      "Train Epoch: 1731 [56832/60000 (95%)] Loss: -1553.662842\n",
      "    epoch          : 1731\n",
      "    loss           : -1354.8692487296412\n",
      "Train Epoch: 1732 [512/60000 (1%)] Loss: -1519.685059\n",
      "Train Epoch: 1732 [11776/60000 (20%)] Loss: -1365.770630\n",
      "Train Epoch: 1732 [23040/60000 (38%)] Loss: -1370.063232\n",
      "Train Epoch: 1732 [34304/60000 (57%)] Loss: -1507.152100\n",
      "Train Epoch: 1732 [45568/60000 (76%)] Loss: -1393.170898\n",
      "Train Epoch: 1732 [56832/60000 (95%)] Loss: -1414.331909\n",
      "    epoch          : 1732\n",
      "    loss           : -1373.0578202931893\n",
      "Train Epoch: 1733 [512/60000 (1%)] Loss: -1536.032227\n",
      "Train Epoch: 1733 [11776/60000 (20%)] Loss: -1392.488159\n",
      "Train Epoch: 1733 [23040/60000 (38%)] Loss: -912.542114\n",
      "Train Epoch: 1733 [34304/60000 (57%)] Loss: -1494.535156\n",
      "Train Epoch: 1733 [45568/60000 (76%)] Loss: -1236.546021\n",
      "Train Epoch: 1733 [56832/60000 (95%)] Loss: -1525.754395\n",
      "    epoch          : 1733\n",
      "    loss           : -1342.998366878531\n",
      "Train Epoch: 1734 [512/60000 (1%)] Loss: -1230.675049\n",
      "Train Epoch: 1734 [11776/60000 (20%)] Loss: -1378.423584\n",
      "Train Epoch: 1734 [23040/60000 (38%)] Loss: -1379.410400\n",
      "Train Epoch: 1734 [34304/60000 (57%)] Loss: -1369.573730\n",
      "Train Epoch: 1734 [45568/60000 (76%)] Loss: -1374.281738\n",
      "Train Epoch: 1734 [56832/60000 (95%)] Loss: -1337.977539\n",
      "    epoch          : 1734\n",
      "    loss           : -1356.7422206038136\n",
      "Train Epoch: 1735 [512/60000 (1%)] Loss: -1514.849609\n",
      "Train Epoch: 1735 [11776/60000 (20%)] Loss: -1515.197388\n",
      "Train Epoch: 1735 [23040/60000 (38%)] Loss: -1403.746460\n",
      "Train Epoch: 1735 [34304/60000 (57%)] Loss: -1385.551025\n",
      "Train Epoch: 1735 [45568/60000 (76%)] Loss: -1201.806885\n",
      "Train Epoch: 1735 [56832/60000 (95%)] Loss: -1382.380859\n",
      "    epoch          : 1735\n",
      "    loss           : -1362.5184014099466\n",
      "Train Epoch: 1736 [512/60000 (1%)] Loss: -1379.849121\n",
      "Train Epoch: 1736 [11776/60000 (20%)] Loss: -1255.369385\n",
      "Train Epoch: 1736 [23040/60000 (38%)] Loss: -1223.605225\n",
      "Train Epoch: 1736 [34304/60000 (57%)] Loss: -1527.362793\n",
      "Train Epoch: 1736 [45568/60000 (76%)] Loss: -1514.607178\n",
      "Train Epoch: 1736 [56832/60000 (95%)] Loss: -1405.767822\n",
      "    epoch          : 1736\n",
      "    loss           : -1384.0859102583202\n",
      "Train Epoch: 1737 [512/60000 (1%)] Loss: -1383.026611\n",
      "Train Epoch: 1737 [11776/60000 (20%)] Loss: -1257.436157\n",
      "Train Epoch: 1737 [23040/60000 (38%)] Loss: -1476.500854\n",
      "Train Epoch: 1737 [34304/60000 (57%)] Loss: -1373.254028\n",
      "Train Epoch: 1737 [45568/60000 (76%)] Loss: -1379.320312\n",
      "Train Epoch: 1737 [56832/60000 (95%)] Loss: -1380.320801\n",
      "    epoch          : 1737\n",
      "    loss           : -1367.537792485986\n",
      "Train Epoch: 1738 [512/60000 (1%)] Loss: -1220.399170\n",
      "Train Epoch: 1738 [11776/60000 (20%)] Loss: -1372.316895\n",
      "Train Epoch: 1738 [23040/60000 (38%)] Loss: -1394.554199\n",
      "Train Epoch: 1738 [34304/60000 (57%)] Loss: -1206.487915\n",
      "Train Epoch: 1738 [45568/60000 (76%)] Loss: -1385.346069\n",
      "Train Epoch: 1738 [56832/60000 (95%)] Loss: -930.910645\n",
      "    epoch          : 1738\n",
      "    loss           : -1378.4512039443193\n",
      "Train Epoch: 1739 [512/60000 (1%)] Loss: -1393.544434\n",
      "Train Epoch: 1739 [11776/60000 (20%)] Loss: -1400.307861\n",
      "Train Epoch: 1739 [23040/60000 (38%)] Loss: -1420.551758\n",
      "Train Epoch: 1739 [34304/60000 (57%)] Loss: -1396.984863\n",
      "Train Epoch: 1739 [45568/60000 (76%)] Loss: -1255.541138\n",
      "Train Epoch: 1739 [56832/60000 (95%)] Loss: -1364.921509\n",
      "    epoch          : 1739\n",
      "    loss           : -1362.9924983654992\n",
      "Train Epoch: 1740 [512/60000 (1%)] Loss: -1544.431763\n",
      "Train Epoch: 1740 [11776/60000 (20%)] Loss: -1241.141724\n",
      "Train Epoch: 1740 [23040/60000 (38%)] Loss: -1066.922852\n",
      "Train Epoch: 1740 [34304/60000 (57%)] Loss: -1281.818970\n",
      "Train Epoch: 1740 [45568/60000 (76%)] Loss: -1227.577637\n",
      "Train Epoch: 1740 [56832/60000 (95%)] Loss: -1354.827393\n",
      "    epoch          : 1740\n",
      "    loss           : -1363.2424364682645\n",
      "Train Epoch: 1741 [512/60000 (1%)] Loss: -1513.965332\n",
      "Train Epoch: 1741 [11776/60000 (20%)] Loss: -1389.831299\n",
      "Train Epoch: 1741 [23040/60000 (38%)] Loss: -1236.021729\n",
      "Train Epoch: 1741 [34304/60000 (57%)] Loss: -1470.420776\n",
      "Train Epoch: 1741 [45568/60000 (76%)] Loss: -1365.150879\n",
      "Train Epoch: 1741 [56832/60000 (95%)] Loss: -1389.423828\n",
      "    epoch          : 1741\n",
      "    loss           : -1362.7042894956082\n",
      "Train Epoch: 1742 [512/60000 (1%)] Loss: -1525.857056\n",
      "Train Epoch: 1742 [11776/60000 (20%)] Loss: -1509.944336\n",
      "Train Epoch: 1742 [23040/60000 (38%)] Loss: -1371.705322\n",
      "Train Epoch: 1742 [34304/60000 (57%)] Loss: -1392.921143\n",
      "Train Epoch: 1742 [45568/60000 (76%)] Loss: -1537.050781\n",
      "Train Epoch: 1742 [56832/60000 (95%)] Loss: -1565.013550\n",
      "    epoch          : 1742\n",
      "    loss           : -1382.8958143676068\n",
      "Train Epoch: 1743 [512/60000 (1%)] Loss: -1390.198364\n",
      "Train Epoch: 1743 [11776/60000 (20%)] Loss: -1364.056152\n",
      "Train Epoch: 1743 [23040/60000 (38%)] Loss: -1366.306030\n",
      "Train Epoch: 1743 [34304/60000 (57%)] Loss: -1363.061279\n",
      "Train Epoch: 1743 [45568/60000 (76%)] Loss: -1532.017456\n",
      "Train Epoch: 1743 [56832/60000 (95%)] Loss: -1397.516357\n",
      "    epoch          : 1743\n",
      "    loss           : -1385.9282881742142\n",
      "Train Epoch: 1744 [512/60000 (1%)] Loss: -1360.641602\n",
      "Train Epoch: 1744 [11776/60000 (20%)] Loss: -1344.878662\n",
      "Train Epoch: 1744 [23040/60000 (38%)] Loss: -1205.777222\n",
      "Train Epoch: 1744 [34304/60000 (57%)] Loss: -1084.489380\n",
      "Train Epoch: 1744 [45568/60000 (76%)] Loss: -1372.261353\n",
      "Train Epoch: 1744 [56832/60000 (95%)] Loss: -1376.079590\n",
      "    epoch          : 1744\n",
      "    loss           : -1361.0038272836116\n",
      "Train Epoch: 1745 [512/60000 (1%)] Loss: -1254.791992\n",
      "Train Epoch: 1745 [11776/60000 (20%)] Loss: -1230.609741\n",
      "Train Epoch: 1745 [23040/60000 (38%)] Loss: -1344.305176\n",
      "Train Epoch: 1745 [34304/60000 (57%)] Loss: -1382.070068\n",
      "Train Epoch: 1745 [45568/60000 (76%)] Loss: -1370.412964\n",
      "Train Epoch: 1745 [56832/60000 (95%)] Loss: -1368.797119\n",
      "    epoch          : 1745\n",
      "    loss           : -1363.7367646815412\n",
      "Train Epoch: 1746 [512/60000 (1%)] Loss: -1359.296387\n",
      "Train Epoch: 1746 [11776/60000 (20%)] Loss: -1538.875732\n",
      "Train Epoch: 1746 [23040/60000 (38%)] Loss: -1367.208740\n",
      "Train Epoch: 1746 [34304/60000 (57%)] Loss: -1076.509399\n",
      "Train Epoch: 1746 [45568/60000 (76%)] Loss: -1231.140503\n",
      "Train Epoch: 1746 [56832/60000 (95%)] Loss: -1515.831177\n",
      "    epoch          : 1746\n",
      "    loss           : -1354.6504385565634\n",
      "Train Epoch: 1747 [512/60000 (1%)] Loss: -1363.987061\n",
      "Train Epoch: 1747 [11776/60000 (20%)] Loss: -1483.052246\n",
      "Train Epoch: 1747 [23040/60000 (38%)] Loss: -1385.444580\n",
      "Train Epoch: 1747 [34304/60000 (57%)] Loss: -1395.157837\n",
      "Train Epoch: 1747 [45568/60000 (76%)] Loss: -1562.529297\n",
      "Train Epoch: 1747 [56832/60000 (95%)] Loss: -1242.275146\n",
      "    epoch          : 1747\n",
      "    loss           : -1360.9953701213255\n",
      "Train Epoch: 1748 [512/60000 (1%)] Loss: -1342.595825\n",
      "Train Epoch: 1748 [11776/60000 (20%)] Loss: -1059.767578\n",
      "Train Epoch: 1748 [23040/60000 (38%)] Loss: -1537.261230\n",
      "Train Epoch: 1748 [34304/60000 (57%)] Loss: -1233.764160\n",
      "Train Epoch: 1748 [45568/60000 (76%)] Loss: -1371.972412\n",
      "Train Epoch: 1748 [56832/60000 (95%)] Loss: -1513.747925\n",
      "    epoch          : 1748\n",
      "    loss           : -1354.3037061098605\n",
      "Train Epoch: 1749 [512/60000 (1%)] Loss: -1364.254761\n",
      "Train Epoch: 1749 [11776/60000 (20%)] Loss: -1407.763428\n",
      "Train Epoch: 1749 [23040/60000 (38%)] Loss: -1382.605347\n",
      "Train Epoch: 1749 [34304/60000 (57%)] Loss: -1383.112549\n",
      "Train Epoch: 1749 [45568/60000 (76%)] Loss: -1498.900024\n",
      "Train Epoch: 1749 [56832/60000 (95%)] Loss: -1256.695557\n",
      "    epoch          : 1749\n",
      "    loss           : -1385.0124356544625\n",
      "Train Epoch: 1750 [512/60000 (1%)] Loss: -1380.355713\n",
      "Train Epoch: 1750 [11776/60000 (20%)] Loss: -1511.071289\n",
      "Train Epoch: 1750 [23040/60000 (38%)] Loss: -1190.404297\n",
      "Train Epoch: 1750 [34304/60000 (57%)] Loss: -1270.580933\n",
      "Train Epoch: 1750 [45568/60000 (76%)] Loss: -1217.083374\n",
      "Train Epoch: 1750 [56832/60000 (95%)] Loss: -1386.935547\n",
      "    epoch          : 1750\n",
      "    loss           : -1348.6307221321063\n",
      "Train Epoch: 1751 [512/60000 (1%)] Loss: -1392.627075\n",
      "Train Epoch: 1751 [11776/60000 (20%)] Loss: -1544.808594\n",
      "Train Epoch: 1751 [23040/60000 (38%)] Loss: -1464.441650\n",
      "Train Epoch: 1751 [34304/60000 (57%)] Loss: -1263.142578\n",
      "Train Epoch: 1751 [45568/60000 (76%)] Loss: -1350.242676\n",
      "Train Epoch: 1751 [56832/60000 (95%)] Loss: -1338.537842\n",
      "    epoch          : 1751\n",
      "    loss           : -1371.0882509738037\n",
      "Train Epoch: 1752 [512/60000 (1%)] Loss: -1406.714966\n",
      "Train Epoch: 1752 [11776/60000 (20%)] Loss: -1217.464355\n",
      "Train Epoch: 1752 [23040/60000 (38%)] Loss: -1354.534180\n",
      "Train Epoch: 1752 [34304/60000 (57%)] Loss: -1211.130005\n",
      "Train Epoch: 1752 [45568/60000 (76%)] Loss: -1549.480469\n",
      "Train Epoch: 1752 [56832/60000 (95%)] Loss: -1263.067383\n",
      "    epoch          : 1752\n",
      "    loss           : -1357.5253068309719\n",
      "Train Epoch: 1753 [512/60000 (1%)] Loss: -1489.642822\n",
      "Train Epoch: 1753 [11776/60000 (20%)] Loss: -1365.543213\n",
      "Train Epoch: 1753 [23040/60000 (38%)] Loss: -1381.800293\n",
      "Train Epoch: 1753 [34304/60000 (57%)] Loss: -1420.583740\n",
      "Train Epoch: 1753 [45568/60000 (76%)] Loss: -1513.546631\n",
      "Train Epoch: 1753 [56832/60000 (95%)] Loss: -1359.862305\n",
      "    epoch          : 1753\n",
      "    loss           : -1403.654183080641\n",
      "Train Epoch: 1754 [512/60000 (1%)] Loss: -1241.490845\n",
      "Train Epoch: 1754 [11776/60000 (20%)] Loss: -1521.482056\n",
      "Train Epoch: 1754 [23040/60000 (38%)] Loss: -1231.975830\n",
      "Train Epoch: 1754 [34304/60000 (57%)] Loss: -1239.953613\n",
      "Train Epoch: 1754 [45568/60000 (76%)] Loss: -1505.357422\n",
      "Train Epoch: 1754 [56832/60000 (95%)] Loss: -1556.122314\n",
      "    epoch          : 1754\n",
      "    loss           : -1344.637376343463\n",
      "Train Epoch: 1755 [512/60000 (1%)] Loss: -1378.198486\n",
      "Train Epoch: 1755 [11776/60000 (20%)] Loss: -1397.961914\n",
      "Train Epoch: 1755 [23040/60000 (38%)] Loss: -1376.122437\n",
      "Train Epoch: 1755 [34304/60000 (57%)] Loss: -1491.332520\n",
      "Train Epoch: 1755 [45568/60000 (76%)] Loss: -1507.000000\n",
      "Train Epoch: 1755 [56832/60000 (95%)] Loss: -1415.634399\n",
      "    epoch          : 1755\n",
      "    loss           : -1372.9714427883341\n",
      "Train Epoch: 1756 [512/60000 (1%)] Loss: -1411.309570\n",
      "Train Epoch: 1756 [11776/60000 (20%)] Loss: -1373.867920\n",
      "Train Epoch: 1756 [23040/60000 (38%)] Loss: -1409.898682\n",
      "Train Epoch: 1756 [34304/60000 (57%)] Loss: -1217.469727\n",
      "Train Epoch: 1756 [45568/60000 (76%)] Loss: -1384.450195\n",
      "Train Epoch: 1756 [56832/60000 (95%)] Loss: -941.762451\n",
      "    epoch          : 1756\n",
      "    loss           : -1356.3199483580509\n",
      "Train Epoch: 1757 [512/60000 (1%)] Loss: -1403.312256\n",
      "Train Epoch: 1757 [11776/60000 (20%)] Loss: -1394.149170\n",
      "Train Epoch: 1757 [23040/60000 (38%)] Loss: -1479.929199\n",
      "Train Epoch: 1757 [34304/60000 (57%)] Loss: -1359.113159\n",
      "Train Epoch: 1757 [45568/60000 (76%)] Loss: -1396.580322\n",
      "Train Epoch: 1757 [56832/60000 (95%)] Loss: -1523.168945\n",
      "    epoch          : 1757\n",
      "    loss           : -1353.0045814298642\n",
      "Train Epoch: 1758 [512/60000 (1%)] Loss: -1534.736450\n",
      "Train Epoch: 1758 [11776/60000 (20%)] Loss: -1125.408691\n",
      "Train Epoch: 1758 [23040/60000 (38%)] Loss: -1499.803101\n",
      "Train Epoch: 1758 [34304/60000 (57%)] Loss: -1320.510620\n",
      "Train Epoch: 1758 [45568/60000 (76%)] Loss: -1377.029053\n",
      "Train Epoch: 1758 [56832/60000 (95%)] Loss: -1255.881226\n",
      "    epoch          : 1758\n",
      "    loss           : -1360.5213626495188\n",
      "Train Epoch: 1759 [512/60000 (1%)] Loss: -1407.040527\n",
      "Train Epoch: 1759 [11776/60000 (20%)] Loss: -1275.807495\n",
      "Train Epoch: 1759 [23040/60000 (38%)] Loss: -1251.802856\n",
      "Train Epoch: 1759 [34304/60000 (57%)] Loss: -1399.780029\n",
      "Train Epoch: 1759 [45568/60000 (76%)] Loss: -1356.791382\n",
      "Train Epoch: 1759 [56832/60000 (95%)] Loss: -1372.321045\n",
      "    epoch          : 1759\n",
      "    loss           : -1375.7144658147952\n",
      "Train Epoch: 1760 [512/60000 (1%)] Loss: -1142.386719\n",
      "Train Epoch: 1760 [11776/60000 (20%)] Loss: -1232.273071\n",
      "Train Epoch: 1760 [23040/60000 (38%)] Loss: -1269.697632\n",
      "Train Epoch: 1760 [34304/60000 (57%)] Loss: -1529.832886\n",
      "Train Epoch: 1760 [45568/60000 (76%)] Loss: -1363.112427\n",
      "Train Epoch: 1760 [56832/60000 (95%)] Loss: -1511.488770\n",
      "    epoch          : 1760\n",
      "    loss           : -1351.4698303567486\n",
      "Train Epoch: 1761 [512/60000 (1%)] Loss: -1191.742310\n",
      "Train Epoch: 1761 [11776/60000 (20%)] Loss: -1529.064941\n",
      "Train Epoch: 1761 [23040/60000 (38%)] Loss: -1336.647461\n",
      "Train Epoch: 1761 [34304/60000 (57%)] Loss: -1356.208252\n",
      "Train Epoch: 1761 [45568/60000 (76%)] Loss: -1245.537354\n",
      "Train Epoch: 1761 [56832/60000 (95%)] Loss: -1397.853760\n",
      "    epoch          : 1761\n",
      "    loss           : -1377.135824257371\n",
      "Train Epoch: 1762 [512/60000 (1%)] Loss: -1355.412109\n",
      "Train Epoch: 1762 [11776/60000 (20%)] Loss: -1387.151367\n",
      "Train Epoch: 1762 [23040/60000 (38%)] Loss: -1507.949463\n",
      "Train Epoch: 1762 [34304/60000 (57%)] Loss: -1382.656006\n",
      "Train Epoch: 1762 [45568/60000 (76%)] Loss: -1233.539551\n",
      "Train Epoch: 1762 [56832/60000 (95%)] Loss: -1404.440430\n",
      "    epoch          : 1762\n",
      "    loss           : -1384.035679014389\n",
      "Train Epoch: 1763 [512/60000 (1%)] Loss: -1357.958740\n",
      "Train Epoch: 1763 [11776/60000 (20%)] Loss: -1363.149658\n",
      "Train Epoch: 1763 [23040/60000 (38%)] Loss: -1060.694702\n",
      "Train Epoch: 1763 [34304/60000 (57%)] Loss: -1129.047485\n",
      "Train Epoch: 1763 [45568/60000 (76%)] Loss: -1394.921997\n",
      "Train Epoch: 1763 [56832/60000 (95%)] Loss: -1349.514160\n",
      "    epoch          : 1763\n",
      "    loss           : -1356.615561792406\n",
      "Train Epoch: 1764 [512/60000 (1%)] Loss: -1549.952393\n",
      "Train Epoch: 1764 [11776/60000 (20%)] Loss: -1412.834229\n",
      "Train Epoch: 1764 [23040/60000 (38%)] Loss: -1233.755981\n",
      "Train Epoch: 1764 [34304/60000 (57%)] Loss: -1123.748413\n",
      "Train Epoch: 1764 [45568/60000 (76%)] Loss: -1494.503052\n",
      "Train Epoch: 1764 [56832/60000 (95%)] Loss: -1416.896362\n",
      "    epoch          : 1764\n",
      "    loss           : -1369.2713205800892\n",
      "Train Epoch: 1765 [512/60000 (1%)] Loss: -1370.770508\n",
      "Train Epoch: 1765 [11776/60000 (20%)] Loss: -1341.664185\n",
      "Train Epoch: 1765 [23040/60000 (38%)] Loss: -1337.539185\n",
      "Train Epoch: 1765 [34304/60000 (57%)] Loss: -1255.388550\n",
      "Train Epoch: 1765 [45568/60000 (76%)] Loss: -1517.730591\n",
      "Train Epoch: 1765 [56832/60000 (95%)] Loss: -1096.224854\n",
      "    epoch          : 1765\n",
      "    loss           : -1370.8944124555858\n",
      "Train Epoch: 1766 [512/60000 (1%)] Loss: -1537.097168\n",
      "Train Epoch: 1766 [11776/60000 (20%)] Loss: -1246.711914\n",
      "Train Epoch: 1766 [23040/60000 (38%)] Loss: -1387.081421\n",
      "Train Epoch: 1766 [34304/60000 (57%)] Loss: -1265.617432\n",
      "Train Epoch: 1766 [45568/60000 (76%)] Loss: -1535.111694\n",
      "Train Epoch: 1766 [56832/60000 (95%)] Loss: -1338.442505\n",
      "    epoch          : 1766\n",
      "    loss           : -1355.7601442498676\n",
      "Train Epoch: 1767 [512/60000 (1%)] Loss: -1374.803833\n",
      "Train Epoch: 1767 [11776/60000 (20%)] Loss: -1245.135864\n",
      "Train Epoch: 1767 [23040/60000 (38%)] Loss: -1541.845825\n",
      "Train Epoch: 1767 [34304/60000 (57%)] Loss: -1249.088135\n",
      "Train Epoch: 1767 [45568/60000 (76%)] Loss: -1517.998535\n",
      "Train Epoch: 1767 [56832/60000 (95%)] Loss: -1397.947510\n",
      "    epoch          : 1767\n",
      "    loss           : -1366.3568708344367\n",
      "Train Epoch: 1768 [512/60000 (1%)] Loss: -1411.704834\n",
      "Train Epoch: 1768 [11776/60000 (20%)] Loss: -1419.755615\n",
      "Train Epoch: 1768 [23040/60000 (38%)] Loss: -1242.372803\n",
      "Train Epoch: 1768 [34304/60000 (57%)] Loss: -1353.172119\n",
      "Train Epoch: 1768 [45568/60000 (76%)] Loss: -1269.948730\n",
      "Train Epoch: 1768 [56832/60000 (95%)] Loss: -1411.884277\n",
      "    epoch          : 1768\n",
      "    loss           : -1375.060331700212\n",
      "Train Epoch: 1769 [512/60000 (1%)] Loss: -1537.780884\n",
      "Train Epoch: 1769 [11776/60000 (20%)] Loss: -1218.019653\n",
      "Train Epoch: 1769 [23040/60000 (38%)] Loss: -1254.796997\n",
      "Train Epoch: 1769 [34304/60000 (57%)] Loss: -1390.232178\n",
      "Train Epoch: 1769 [45568/60000 (76%)] Loss: -1365.619995\n",
      "Train Epoch: 1769 [56832/60000 (95%)] Loss: -1358.482910\n",
      "    epoch          : 1769\n",
      "    loss           : -1359.2264280157574\n",
      "Train Epoch: 1770 [512/60000 (1%)] Loss: -1413.110107\n",
      "Train Epoch: 1770 [11776/60000 (20%)] Loss: -1474.365967\n",
      "Train Epoch: 1770 [23040/60000 (38%)] Loss: -1390.996338\n",
      "Train Epoch: 1770 [34304/60000 (57%)] Loss: -1390.419189\n",
      "Train Epoch: 1770 [45568/60000 (76%)] Loss: -1400.420898\n",
      "Train Epoch: 1770 [56832/60000 (95%)] Loss: -1396.539062\n",
      "    epoch          : 1770\n",
      "    loss           : -1383.049382613877\n",
      "Train Epoch: 1771 [512/60000 (1%)] Loss: -1380.462158\n",
      "Train Epoch: 1771 [11776/60000 (20%)] Loss: -1374.336792\n",
      "Train Epoch: 1771 [23040/60000 (38%)] Loss: -1506.754272\n",
      "Train Epoch: 1771 [34304/60000 (57%)] Loss: -1269.406250\n",
      "Train Epoch: 1771 [45568/60000 (76%)] Loss: -1511.395508\n",
      "Train Epoch: 1771 [56832/60000 (95%)] Loss: -1402.319336\n",
      "    epoch          : 1771\n",
      "    loss           : -1355.4251560706878\n",
      "Train Epoch: 1772 [512/60000 (1%)] Loss: -1372.499146\n",
      "Train Epoch: 1772 [11776/60000 (20%)] Loss: -1358.991211\n",
      "Train Epoch: 1772 [23040/60000 (38%)] Loss: -1217.603271\n",
      "Train Epoch: 1772 [34304/60000 (57%)] Loss: -1412.041382\n",
      "Train Epoch: 1772 [45568/60000 (76%)] Loss: -1353.324463\n",
      "Train Epoch: 1772 [56832/60000 (95%)] Loss: -1392.131470\n",
      "    epoch          : 1772\n",
      "    loss           : -1356.869594940358\n",
      "Train Epoch: 1773 [512/60000 (1%)] Loss: -1535.101685\n",
      "Train Epoch: 1773 [11776/60000 (20%)] Loss: -1377.594971\n",
      "Train Epoch: 1773 [23040/60000 (38%)] Loss: -1234.827759\n",
      "Train Epoch: 1773 [34304/60000 (57%)] Loss: -1249.149170\n",
      "Train Epoch: 1773 [45568/60000 (76%)] Loss: -1497.476807\n",
      "Train Epoch: 1773 [56832/60000 (95%)] Loss: -1240.120117\n",
      "    epoch          : 1773\n",
      "    loss           : -1356.9094750355866\n",
      "Train Epoch: 1774 [512/60000 (1%)] Loss: -1489.445801\n",
      "Train Epoch: 1774 [11776/60000 (20%)] Loss: -1084.466553\n",
      "Train Epoch: 1774 [23040/60000 (38%)] Loss: -1518.372192\n",
      "Train Epoch: 1774 [34304/60000 (57%)] Loss: -1391.566406\n",
      "Train Epoch: 1774 [45568/60000 (76%)] Loss: -1244.612671\n",
      "Train Epoch: 1774 [56832/60000 (95%)] Loss: -1508.973145\n",
      "    epoch          : 1774\n",
      "    loss           : -1356.931889248433\n",
      "Train Epoch: 1775 [512/60000 (1%)] Loss: -1381.704346\n",
      "Train Epoch: 1775 [11776/60000 (20%)] Loss: -1257.320557\n",
      "Train Epoch: 1775 [23040/60000 (38%)] Loss: -1393.354614\n",
      "Train Epoch: 1775 [34304/60000 (57%)] Loss: -1519.011108\n",
      "Train Epoch: 1775 [45568/60000 (76%)] Loss: -1217.327393\n",
      "Train Epoch: 1775 [56832/60000 (95%)] Loss: -1515.272095\n",
      "    epoch          : 1775\n",
      "    loss           : -1383.1536227296301\n",
      "Train Epoch: 1776 [512/60000 (1%)] Loss: -1384.942627\n",
      "Train Epoch: 1776 [11776/60000 (20%)] Loss: -1368.418335\n",
      "Train Epoch: 1776 [23040/60000 (38%)] Loss: -1324.567505\n",
      "Train Epoch: 1776 [34304/60000 (57%)] Loss: -1586.422974\n",
      "Train Epoch: 1776 [45568/60000 (76%)] Loss: -1415.388916\n",
      "Train Epoch: 1776 [56832/60000 (95%)] Loss: -1547.562744\n",
      "    epoch          : 1776\n",
      "    loss           : -1361.7061183088917\n",
      "Train Epoch: 1777 [512/60000 (1%)] Loss: -1268.854980\n",
      "Train Epoch: 1777 [11776/60000 (20%)] Loss: -1345.219604\n",
      "Train Epoch: 1777 [23040/60000 (38%)] Loss: -1505.005615\n",
      "Train Epoch: 1777 [34304/60000 (57%)] Loss: -1080.529785\n",
      "Train Epoch: 1777 [45568/60000 (76%)] Loss: -1508.771484\n",
      "Train Epoch: 1777 [56832/60000 (95%)] Loss: -1512.426636\n",
      "    epoch          : 1777\n",
      "    loss           : -1365.0081430208886\n",
      "Train Epoch: 1778 [512/60000 (1%)] Loss: -1181.490479\n",
      "Train Epoch: 1778 [11776/60000 (20%)] Loss: -1508.472168\n",
      "Train Epoch: 1778 [23040/60000 (38%)] Loss: -1222.005249\n",
      "Train Epoch: 1778 [34304/60000 (57%)] Loss: -1514.568726\n",
      "Train Epoch: 1778 [45568/60000 (76%)] Loss: -1215.969116\n",
      "Train Epoch: 1778 [56832/60000 (95%)] Loss: -1531.573975\n",
      "    epoch          : 1778\n",
      "    loss           : -1359.0417377019332\n",
      "Train Epoch: 1779 [512/60000 (1%)] Loss: -1496.485107\n",
      "Train Epoch: 1779 [11776/60000 (20%)] Loss: -1372.752441\n",
      "Train Epoch: 1779 [23040/60000 (38%)] Loss: -1388.359131\n",
      "Train Epoch: 1779 [34304/60000 (57%)] Loss: -1383.151245\n",
      "Train Epoch: 1779 [45568/60000 (76%)] Loss: -1265.055786\n",
      "Train Epoch: 1779 [56832/60000 (95%)] Loss: -1378.518677\n",
      "    epoch          : 1779\n",
      "    loss           : -1365.6964528574108\n",
      "Train Epoch: 1780 [512/60000 (1%)] Loss: -1514.168335\n",
      "Train Epoch: 1780 [11776/60000 (20%)] Loss: -1375.087158\n",
      "Train Epoch: 1780 [23040/60000 (38%)] Loss: -1390.705933\n",
      "Train Epoch: 1780 [34304/60000 (57%)] Loss: -1375.380981\n",
      "Train Epoch: 1780 [45568/60000 (76%)] Loss: -1403.309326\n",
      "Train Epoch: 1780 [56832/60000 (95%)] Loss: -1340.578857\n",
      "    epoch          : 1780\n",
      "    loss           : -1349.4647403005827\n",
      "Train Epoch: 1781 [512/60000 (1%)] Loss: -1357.081299\n",
      "Train Epoch: 1781 [11776/60000 (20%)] Loss: -1506.946655\n",
      "Train Epoch: 1781 [23040/60000 (38%)] Loss: -1381.841675\n",
      "Train Epoch: 1781 [34304/60000 (57%)] Loss: -1375.576172\n",
      "Train Epoch: 1781 [45568/60000 (76%)] Loss: -1499.900391\n",
      "Train Epoch: 1781 [56832/60000 (95%)] Loss: -1411.223755\n",
      "    epoch          : 1781\n",
      "    loss           : -1362.4534156928628\n",
      "Train Epoch: 1782 [512/60000 (1%)] Loss: -1538.627686\n",
      "Train Epoch: 1782 [11776/60000 (20%)] Loss: -1504.321289\n",
      "Train Epoch: 1782 [23040/60000 (38%)] Loss: -1436.481201\n",
      "Train Epoch: 1782 [34304/60000 (57%)] Loss: -1231.441528\n",
      "Train Epoch: 1782 [45568/60000 (76%)] Loss: -1062.382568\n",
      "Train Epoch: 1782 [56832/60000 (95%)] Loss: -1211.330444\n",
      "    epoch          : 1782\n",
      "    loss           : -1359.5335031283105\n",
      "Train Epoch: 1783 [512/60000 (1%)] Loss: -1398.966675\n",
      "Train Epoch: 1783 [11776/60000 (20%)] Loss: -1197.503540\n",
      "Train Epoch: 1783 [23040/60000 (38%)] Loss: -1516.643799\n",
      "Train Epoch: 1783 [34304/60000 (57%)] Loss: -1368.640259\n",
      "Train Epoch: 1783 [45568/60000 (76%)] Loss: -1381.865356\n",
      "Train Epoch: 1783 [56832/60000 (95%)] Loss: -1350.125488\n",
      "    epoch          : 1783\n",
      "    loss           : -1380.3435475839733\n",
      "Train Epoch: 1784 [512/60000 (1%)] Loss: -1126.337769\n",
      "Train Epoch: 1784 [11776/60000 (20%)] Loss: -1249.840332\n",
      "Train Epoch: 1784 [23040/60000 (38%)] Loss: -1218.112061\n",
      "Train Epoch: 1784 [34304/60000 (57%)] Loss: -1354.132690\n",
      "Train Epoch: 1784 [45568/60000 (76%)] Loss: -1498.456055\n",
      "Train Epoch: 1784 [56832/60000 (95%)] Loss: -1404.306885\n",
      "    epoch          : 1784\n",
      "    loss           : -1360.7374639996028\n",
      "Train Epoch: 1785 [512/60000 (1%)] Loss: -1527.477295\n",
      "Train Epoch: 1785 [11776/60000 (20%)] Loss: -1350.069336\n",
      "Train Epoch: 1785 [23040/60000 (38%)] Loss: -1243.580688\n",
      "Train Epoch: 1785 [34304/60000 (57%)] Loss: -1345.207031\n",
      "Train Epoch: 1785 [45568/60000 (76%)] Loss: -1369.125000\n",
      "Train Epoch: 1785 [56832/60000 (95%)] Loss: -1242.979004\n",
      "    epoch          : 1785\n",
      "    loss           : -1356.9570922851562\n",
      "Train Epoch: 1786 [512/60000 (1%)] Loss: -1356.999268\n",
      "Train Epoch: 1786 [11776/60000 (20%)] Loss: -1546.377441\n",
      "Train Epoch: 1786 [23040/60000 (38%)] Loss: -1383.854614\n",
      "Train Epoch: 1786 [34304/60000 (57%)] Loss: -1420.394409\n",
      "Train Epoch: 1786 [45568/60000 (76%)] Loss: -1548.453247\n",
      "Train Epoch: 1786 [56832/60000 (95%)] Loss: -1380.293213\n",
      "    epoch          : 1786\n",
      "    loss           : -1368.6962156134136\n",
      "Train Epoch: 1787 [512/60000 (1%)] Loss: -1490.677490\n",
      "Train Epoch: 1787 [11776/60000 (20%)] Loss: -1096.262695\n",
      "Train Epoch: 1787 [23040/60000 (38%)] Loss: -1378.809814\n",
      "Train Epoch: 1787 [34304/60000 (57%)] Loss: -1351.224609\n",
      "Train Epoch: 1787 [45568/60000 (76%)] Loss: -1503.639648\n",
      "Train Epoch: 1787 [56832/60000 (95%)] Loss: -1226.591797\n",
      "    epoch          : 1787\n",
      "    loss           : -1371.4870770987818\n",
      "Train Epoch: 1788 [512/60000 (1%)] Loss: -1382.509766\n",
      "Train Epoch: 1788 [11776/60000 (20%)] Loss: -1496.283203\n",
      "Train Epoch: 1788 [23040/60000 (38%)] Loss: -1234.973877\n",
      "Train Epoch: 1788 [34304/60000 (57%)] Loss: -1389.433105\n",
      "Train Epoch: 1788 [45568/60000 (76%)] Loss: -1102.986328\n",
      "Train Epoch: 1788 [56832/60000 (95%)] Loss: -1523.826294\n",
      "    epoch          : 1788\n",
      "    loss           : -1370.7414347330728\n",
      "Train Epoch: 1789 [512/60000 (1%)] Loss: -1263.916260\n",
      "Train Epoch: 1789 [11776/60000 (20%)] Loss: -1346.872559\n",
      "Train Epoch: 1789 [23040/60000 (38%)] Loss: -1324.659546\n",
      "Train Epoch: 1789 [34304/60000 (57%)] Loss: -1370.903320\n",
      "Train Epoch: 1789 [45568/60000 (76%)] Loss: -1502.417969\n",
      "Train Epoch: 1789 [56832/60000 (95%)] Loss: -1216.847656\n",
      "    epoch          : 1789\n",
      "    loss           : -1371.3071428719213\n",
      "Train Epoch: 1790 [512/60000 (1%)] Loss: -1340.939087\n",
      "Train Epoch: 1790 [11776/60000 (20%)] Loss: -1069.984863\n",
      "Train Epoch: 1790 [23040/60000 (38%)] Loss: -1533.069214\n",
      "Train Epoch: 1790 [34304/60000 (57%)] Loss: -1208.729492\n",
      "Train Epoch: 1790 [45568/60000 (76%)] Loss: -1561.255371\n",
      "Train Epoch: 1790 [56832/60000 (95%)] Loss: -1535.192383\n",
      "    epoch          : 1790\n",
      "    loss           : -1375.2856072894597\n",
      "Train Epoch: 1791 [512/60000 (1%)] Loss: -1337.672729\n",
      "Train Epoch: 1791 [11776/60000 (20%)] Loss: -1477.307129\n",
      "Train Epoch: 1791 [23040/60000 (38%)] Loss: -1394.961182\n",
      "Train Epoch: 1791 [34304/60000 (57%)] Loss: -1309.905762\n",
      "Train Epoch: 1791 [45568/60000 (76%)] Loss: -1194.479370\n",
      "Train Epoch: 1791 [56832/60000 (95%)] Loss: -1405.738159\n",
      "    epoch          : 1791\n",
      "    loss           : -1365.3086978890803\n",
      "Train Epoch: 1792 [512/60000 (1%)] Loss: -1525.373535\n",
      "Train Epoch: 1792 [11776/60000 (20%)] Loss: -1384.209961\n",
      "Train Epoch: 1792 [23040/60000 (38%)] Loss: -1496.735962\n",
      "Train Epoch: 1792 [34304/60000 (57%)] Loss: -1378.966187\n",
      "Train Epoch: 1792 [45568/60000 (76%)] Loss: -1320.809814\n",
      "Train Epoch: 1792 [56832/60000 (95%)] Loss: -1531.020874\n",
      "    epoch          : 1792\n",
      "    loss           : -1345.1665518378134\n",
      "Train Epoch: 1793 [512/60000 (1%)] Loss: -1380.548218\n",
      "Train Epoch: 1793 [11776/60000 (20%)] Loss: -1517.427368\n",
      "Train Epoch: 1793 [23040/60000 (38%)] Loss: -1365.089722\n",
      "Train Epoch: 1793 [34304/60000 (57%)] Loss: -1496.450439\n",
      "Train Epoch: 1793 [45568/60000 (76%)] Loss: -1408.478027\n",
      "Train Epoch: 1793 [56832/60000 (95%)] Loss: -1379.244873\n",
      "    epoch          : 1793\n",
      "    loss           : -1368.643762620829\n",
      "Train Epoch: 1794 [512/60000 (1%)] Loss: -1499.930908\n",
      "Train Epoch: 1794 [11776/60000 (20%)] Loss: -1260.046509\n",
      "Train Epoch: 1794 [23040/60000 (38%)] Loss: -1395.615479\n",
      "Train Epoch: 1794 [34304/60000 (57%)] Loss: -1392.542114\n",
      "Train Epoch: 1794 [45568/60000 (76%)] Loss: -1365.455322\n",
      "Train Epoch: 1794 [56832/60000 (95%)] Loss: -1540.093384\n",
      "    epoch          : 1794\n",
      "    loss           : -1347.1880044883255\n",
      "Train Epoch: 1795 [512/60000 (1%)] Loss: -1133.231567\n",
      "Train Epoch: 1795 [11776/60000 (20%)] Loss: -1512.593994\n",
      "Train Epoch: 1795 [23040/60000 (38%)] Loss: -1232.247925\n",
      "Train Epoch: 1795 [34304/60000 (57%)] Loss: -1547.192017\n",
      "Train Epoch: 1795 [45568/60000 (76%)] Loss: -1519.132568\n",
      "Train Epoch: 1795 [56832/60000 (95%)] Loss: -1373.292480\n",
      "    epoch          : 1795\n",
      "    loss           : -1362.0393838828568\n",
      "Train Epoch: 1796 [512/60000 (1%)] Loss: -1524.977539\n",
      "Train Epoch: 1796 [11776/60000 (20%)] Loss: -1370.178955\n",
      "Train Epoch: 1796 [23040/60000 (38%)] Loss: -1517.741943\n",
      "Train Epoch: 1796 [34304/60000 (57%)] Loss: -1074.520508\n",
      "Train Epoch: 1796 [45568/60000 (76%)] Loss: -1251.869141\n",
      "Train Epoch: 1796 [56832/60000 (95%)] Loss: -1475.850830\n",
      "    epoch          : 1796\n",
      "    loss           : -1372.3311558955133\n",
      "Train Epoch: 1797 [512/60000 (1%)] Loss: -1370.314453\n",
      "Train Epoch: 1797 [11776/60000 (20%)] Loss: -1416.066284\n",
      "Train Epoch: 1797 [23040/60000 (38%)] Loss: -1368.738037\n",
      "Train Epoch: 1797 [34304/60000 (57%)] Loss: -1359.836670\n",
      "Train Epoch: 1797 [45568/60000 (76%)] Loss: -1385.281006\n",
      "Train Epoch: 1797 [56832/60000 (95%)] Loss: -1395.051270\n",
      "    epoch          : 1797\n",
      "    loss           : -1370.9715817553847\n",
      "Train Epoch: 1798 [512/60000 (1%)] Loss: -1393.702271\n",
      "Train Epoch: 1798 [11776/60000 (20%)] Loss: -1498.939453\n",
      "Train Epoch: 1798 [23040/60000 (38%)] Loss: -1241.442017\n",
      "Train Epoch: 1798 [34304/60000 (57%)] Loss: -1518.600830\n",
      "Train Epoch: 1798 [45568/60000 (76%)] Loss: -1382.456787\n",
      "Train Epoch: 1798 [56832/60000 (95%)] Loss: -1232.905518\n",
      "    epoch          : 1798\n",
      "    loss           : -1358.04238753669\n",
      "Train Epoch: 1799 [512/60000 (1%)] Loss: -1376.574829\n",
      "Train Epoch: 1799 [11776/60000 (20%)] Loss: -1482.201538\n",
      "Train Epoch: 1799 [23040/60000 (38%)] Loss: -1226.167603\n",
      "Train Epoch: 1799 [34304/60000 (57%)] Loss: -1355.174805\n",
      "Train Epoch: 1799 [45568/60000 (76%)] Loss: -1390.301758\n",
      "Train Epoch: 1799 [56832/60000 (95%)] Loss: -1373.476685\n",
      "    epoch          : 1799\n",
      "    loss           : -1346.8800379866261\n",
      "Train Epoch: 1800 [512/60000 (1%)] Loss: -1254.674072\n",
      "Train Epoch: 1800 [11776/60000 (20%)] Loss: -1351.678833\n",
      "Train Epoch: 1800 [23040/60000 (38%)] Loss: -1368.902588\n",
      "Train Epoch: 1800 [34304/60000 (57%)] Loss: -1559.135498\n",
      "Train Epoch: 1800 [45568/60000 (76%)] Loss: -1408.813965\n",
      "Train Epoch: 1800 [56832/60000 (95%)] Loss: -1392.795410\n",
      "    epoch          : 1800\n",
      "    loss           : -1359.6171274993378\n",
      "Saving checkpoint: saved/models/Mnist_DeepGenerativeOperad/0127_111843/checkpoint-epoch1800.pth ...\n",
      "Train Epoch: 1801 [512/60000 (1%)] Loss: -1374.535522\n",
      "Train Epoch: 1801 [11776/60000 (20%)] Loss: -1106.421753\n",
      "Train Epoch: 1801 [23040/60000 (38%)] Loss: -1367.285278\n",
      "Train Epoch: 1801 [34304/60000 (57%)] Loss: -1242.495605\n",
      "Train Epoch: 1801 [45568/60000 (76%)] Loss: -1338.020020\n",
      "Train Epoch: 1801 [56832/60000 (95%)] Loss: -1403.424927\n",
      "    epoch          : 1801\n",
      "    loss           : -1367.9711458885063\n",
      "Train Epoch: 1802 [512/60000 (1%)] Loss: -1098.037109\n",
      "Train Epoch: 1802 [11776/60000 (20%)] Loss: -1384.913818\n",
      "Train Epoch: 1802 [23040/60000 (38%)] Loss: -1362.625122\n",
      "Train Epoch: 1802 [34304/60000 (57%)] Loss: -1387.531250\n",
      "Train Epoch: 1802 [45568/60000 (76%)] Loss: -1222.092773\n",
      "Train Epoch: 1802 [56832/60000 (95%)] Loss: -1086.257202\n",
      "    epoch          : 1802\n",
      "    loss           : -1360.8716168592207\n",
      "Train Epoch: 1803 [512/60000 (1%)] Loss: -1248.797363\n",
      "Train Epoch: 1803 [11776/60000 (20%)] Loss: -1526.488281\n",
      "Train Epoch: 1803 [23040/60000 (38%)] Loss: -1549.171143\n",
      "Train Epoch: 1803 [34304/60000 (57%)] Loss: -1275.956055\n",
      "Train Epoch: 1803 [45568/60000 (76%)] Loss: -1537.049927\n",
      "Train Epoch: 1803 [56832/60000 (95%)] Loss: -1410.258789\n",
      "    epoch          : 1803\n",
      "    loss           : -1356.1769395386432\n",
      "Train Epoch: 1804 [512/60000 (1%)] Loss: -1075.950562\n",
      "Train Epoch: 1804 [11776/60000 (20%)] Loss: -1368.329468\n",
      "Train Epoch: 1804 [23040/60000 (38%)] Loss: -1513.561523\n",
      "Train Epoch: 1804 [34304/60000 (57%)] Loss: -1489.282227\n",
      "Train Epoch: 1804 [45568/60000 (76%)] Loss: -1526.698242\n",
      "Train Epoch: 1804 [56832/60000 (95%)] Loss: -1502.376831\n",
      "    epoch          : 1804\n",
      "    loss           : -1372.026579603637\n",
      "Train Epoch: 1805 [512/60000 (1%)] Loss: -1411.489014\n",
      "Train Epoch: 1805 [11776/60000 (20%)] Loss: -1224.358276\n",
      "Train Epoch: 1805 [23040/60000 (38%)] Loss: -1181.120605\n",
      "Train Epoch: 1805 [34304/60000 (57%)] Loss: -1547.072144\n",
      "Train Epoch: 1805 [45568/60000 (76%)] Loss: -1408.251099\n",
      "Train Epoch: 1805 [56832/60000 (95%)] Loss: -1355.744751\n",
      "    epoch          : 1805\n",
      "    loss           : -1355.8779896881622\n",
      "Train Epoch: 1806 [512/60000 (1%)] Loss: -1393.703247\n",
      "Train Epoch: 1806 [11776/60000 (20%)] Loss: -1126.022583\n",
      "Train Epoch: 1806 [23040/60000 (38%)] Loss: -1554.422119\n",
      "Train Epoch: 1806 [34304/60000 (57%)] Loss: -1380.370605\n",
      "Train Epoch: 1806 [45568/60000 (76%)] Loss: -1380.146729\n",
      "Train Epoch: 1806 [56832/60000 (95%)] Loss: -1348.204468\n",
      "    epoch          : 1806\n",
      "    loss           : -1371.3210235423287\n",
      "Train Epoch: 1807 [512/60000 (1%)] Loss: -1243.095947\n",
      "Train Epoch: 1807 [11776/60000 (20%)] Loss: -1526.604248\n",
      "Train Epoch: 1807 [23040/60000 (38%)] Loss: -1509.938477\n",
      "Train Epoch: 1807 [34304/60000 (57%)] Loss: -1407.181519\n",
      "Train Epoch: 1807 [45568/60000 (76%)] Loss: -1559.984863\n",
      "Train Epoch: 1807 [56832/60000 (95%)] Loss: -1384.897217\n",
      "    epoch          : 1807\n",
      "    loss           : -1394.4320482157045\n",
      "Train Epoch: 1808 [512/60000 (1%)] Loss: -1255.189941\n",
      "Train Epoch: 1808 [11776/60000 (20%)] Loss: -1478.647949\n",
      "Train Epoch: 1808 [23040/60000 (38%)] Loss: -1409.478271\n",
      "Train Epoch: 1808 [34304/60000 (57%)] Loss: -1535.256348\n",
      "Train Epoch: 1808 [45568/60000 (76%)] Loss: -1540.269165\n",
      "Train Epoch: 1808 [56832/60000 (95%)] Loss: -1373.605103\n",
      "    epoch          : 1808\n",
      "    loss           : -1369.7783585887844\n",
      "Train Epoch: 1809 [512/60000 (1%)] Loss: -1497.571045\n",
      "Train Epoch: 1809 [11776/60000 (20%)] Loss: -1411.894775\n",
      "Train Epoch: 1809 [23040/60000 (38%)] Loss: -1372.145020\n",
      "Train Epoch: 1809 [34304/60000 (57%)] Loss: -1527.219238\n",
      "Train Epoch: 1809 [45568/60000 (76%)] Loss: -1518.972778\n",
      "Train Epoch: 1809 [56832/60000 (95%)] Loss: -1500.499756\n",
      "    epoch          : 1809\n",
      "    loss           : -1357.4154419979807\n",
      "Train Epoch: 1810 [512/60000 (1%)] Loss: -1228.412842\n",
      "Train Epoch: 1810 [11776/60000 (20%)] Loss: -1508.892090\n",
      "Train Epoch: 1810 [23040/60000 (38%)] Loss: -1519.392578\n",
      "Train Epoch: 1810 [34304/60000 (57%)] Loss: -1222.512085\n",
      "Train Epoch: 1810 [45568/60000 (76%)] Loss: -1564.248779\n",
      "Train Epoch: 1810 [56832/60000 (95%)] Loss: -1513.254150\n",
      "    epoch          : 1810\n",
      "    loss           : -1384.5803384727005\n",
      "Train Epoch: 1811 [512/60000 (1%)] Loss: -1511.315430\n",
      "Train Epoch: 1811 [11776/60000 (20%)] Loss: -1208.226562\n",
      "Train Epoch: 1811 [23040/60000 (38%)] Loss: -1517.038452\n",
      "Train Epoch: 1811 [34304/60000 (57%)] Loss: -1388.258545\n",
      "Train Epoch: 1811 [45568/60000 (76%)] Loss: -1506.412842\n",
      "Train Epoch: 1811 [56832/60000 (95%)] Loss: -1524.362061\n",
      "    epoch          : 1811\n",
      "    loss           : -1373.1927205748477\n",
      "Train Epoch: 1812 [512/60000 (1%)] Loss: -1117.158936\n",
      "Train Epoch: 1812 [11776/60000 (20%)] Loss: -1215.308838\n",
      "Train Epoch: 1812 [23040/60000 (38%)] Loss: -1397.134399\n",
      "Train Epoch: 1812 [34304/60000 (57%)] Loss: -1376.639282\n",
      "Train Epoch: 1812 [45568/60000 (76%)] Loss: -1240.457031\n",
      "Train Epoch: 1812 [56832/60000 (95%)] Loss: -1540.226562\n",
      "    epoch          : 1812\n",
      "    loss           : -1370.8360543978417\n",
      "Train Epoch: 1813 [512/60000 (1%)] Loss: -1223.628174\n",
      "Train Epoch: 1813 [11776/60000 (20%)] Loss: -1224.770630\n",
      "Train Epoch: 1813 [23040/60000 (38%)] Loss: -1542.172363\n",
      "Train Epoch: 1813 [34304/60000 (57%)] Loss: -1378.029297\n",
      "Train Epoch: 1813 [45568/60000 (76%)] Loss: -1344.740479\n",
      "Train Epoch: 1813 [56832/60000 (95%)] Loss: -1097.963867\n",
      "    epoch          : 1813\n",
      "    loss           : -1353.4808063399319\n",
      "Train Epoch: 1814 [512/60000 (1%)] Loss: -1373.214600\n",
      "Train Epoch: 1814 [11776/60000 (20%)] Loss: -1514.206055\n",
      "Train Epoch: 1814 [23040/60000 (38%)] Loss: -1084.988159\n",
      "Train Epoch: 1814 [34304/60000 (57%)] Loss: -1390.720581\n",
      "Train Epoch: 1814 [45568/60000 (76%)] Loss: -1111.654297\n",
      "Train Epoch: 1814 [56832/60000 (95%)] Loss: -1414.174316\n",
      "    epoch          : 1814\n",
      "    loss           : -1335.9556226137668\n",
      "Train Epoch: 1815 [512/60000 (1%)] Loss: -1368.438965\n",
      "Train Epoch: 1815 [11776/60000 (20%)] Loss: -1408.900879\n",
      "Train Epoch: 1815 [23040/60000 (38%)] Loss: -1387.162842\n",
      "Train Epoch: 1815 [34304/60000 (57%)] Loss: -1365.551636\n",
      "Train Epoch: 1815 [45568/60000 (76%)] Loss: -1349.916626\n",
      "Train Epoch: 1815 [56832/60000 (95%)] Loss: -1259.962036\n",
      "    epoch          : 1815\n",
      "    loss           : -1368.5882116630253\n",
      "Train Epoch: 1816 [512/60000 (1%)] Loss: -1512.720825\n",
      "Train Epoch: 1816 [11776/60000 (20%)] Loss: -1402.538208\n",
      "Train Epoch: 1816 [23040/60000 (38%)] Loss: -1227.626587\n",
      "Train Epoch: 1816 [34304/60000 (57%)] Loss: -1072.885986\n",
      "Train Epoch: 1816 [45568/60000 (76%)] Loss: -1258.487671\n",
      "Train Epoch: 1816 [56832/60000 (95%)] Loss: -1547.901123\n",
      "    epoch          : 1816\n",
      "    loss           : -1394.8870022014037\n",
      "Train Epoch: 1817 [512/60000 (1%)] Loss: -1334.953369\n",
      "Train Epoch: 1817 [11776/60000 (20%)] Loss: -1405.720459\n",
      "Train Epoch: 1817 [23040/60000 (38%)] Loss: -1240.706299\n",
      "Train Epoch: 1817 [34304/60000 (57%)] Loss: -1343.894653\n",
      "Train Epoch: 1817 [45568/60000 (76%)] Loss: -1388.656616\n",
      "Train Epoch: 1817 [56832/60000 (95%)] Loss: -1116.057983\n",
      "    epoch          : 1817\n",
      "    loss           : -1357.5219840356858\n",
      "Train Epoch: 1818 [512/60000 (1%)] Loss: -1253.643799\n",
      "Train Epoch: 1818 [11776/60000 (20%)] Loss: -1390.842041\n",
      "Train Epoch: 1818 [23040/60000 (38%)] Loss: -1356.942871\n",
      "Train Epoch: 1818 [34304/60000 (57%)] Loss: -1219.223999\n",
      "Train Epoch: 1818 [45568/60000 (76%)] Loss: -1125.559692\n",
      "Train Epoch: 1818 [56832/60000 (95%)] Loss: -1360.255127\n",
      "    epoch          : 1818\n",
      "    loss           : -1373.5352517682952\n",
      "Train Epoch: 1819 [512/60000 (1%)] Loss: -1236.470093\n",
      "Train Epoch: 1819 [11776/60000 (20%)] Loss: -1215.425293\n",
      "Train Epoch: 1819 [23040/60000 (38%)] Loss: -1243.787109\n",
      "Train Epoch: 1819 [34304/60000 (57%)] Loss: -1504.518921\n",
      "Train Epoch: 1819 [45568/60000 (76%)] Loss: -1357.744141\n",
      "Train Epoch: 1819 [56832/60000 (95%)] Loss: -1091.847656\n",
      "    epoch          : 1819\n",
      "    loss           : -1360.1085477494923\n",
      "Train Epoch: 1820 [512/60000 (1%)] Loss: -1400.997070\n",
      "Train Epoch: 1820 [11776/60000 (20%)] Loss: -1528.131592\n",
      "Train Epoch: 1820 [23040/60000 (38%)] Loss: -1371.918213\n",
      "Train Epoch: 1820 [34304/60000 (57%)] Loss: -1388.150635\n",
      "Train Epoch: 1820 [45568/60000 (76%)] Loss: -1515.304565\n",
      "Train Epoch: 1820 [56832/60000 (95%)] Loss: -1229.900635\n",
      "    epoch          : 1820\n",
      "    loss           : -1375.3213163041798\n",
      "Train Epoch: 1821 [512/60000 (1%)] Loss: -1225.904541\n",
      "Train Epoch: 1821 [11776/60000 (20%)] Loss: -1479.979736\n",
      "Train Epoch: 1821 [23040/60000 (38%)] Loss: -1058.084717\n",
      "Train Epoch: 1821 [34304/60000 (57%)] Loss: -1228.187988\n",
      "Train Epoch: 1821 [45568/60000 (76%)] Loss: -1501.265503\n",
      "Train Epoch: 1821 [56832/60000 (95%)] Loss: -1360.967163\n",
      "    epoch          : 1821\n",
      "    loss           : -1359.705411921787\n",
      "Train Epoch: 1822 [512/60000 (1%)] Loss: -1226.597778\n",
      "Train Epoch: 1822 [11776/60000 (20%)] Loss: -1497.546509\n",
      "Train Epoch: 1822 [23040/60000 (38%)] Loss: -1492.808960\n",
      "Train Epoch: 1822 [34304/60000 (57%)] Loss: -1231.214966\n",
      "Train Epoch: 1822 [45568/60000 (76%)] Loss: -1571.855225\n",
      "Train Epoch: 1822 [56832/60000 (95%)] Loss: -1224.195801\n",
      "    epoch          : 1822\n",
      "    loss           : -1380.2473992816472\n",
      "Train Epoch: 1823 [512/60000 (1%)] Loss: -1047.057373\n",
      "Train Epoch: 1823 [11776/60000 (20%)] Loss: -1228.848999\n",
      "Train Epoch: 1823 [23040/60000 (38%)] Loss: -1242.188232\n",
      "Train Epoch: 1823 [34304/60000 (57%)] Loss: -1218.802734\n",
      "Train Epoch: 1823 [45568/60000 (76%)] Loss: -1432.094849\n",
      "Train Epoch: 1823 [56832/60000 (95%)] Loss: -1411.964111\n",
      "    epoch          : 1823\n",
      "    loss           : -1374.1217096188648\n",
      "Train Epoch: 1824 [512/60000 (1%)] Loss: -1385.711548\n",
      "Train Epoch: 1824 [11776/60000 (20%)] Loss: -1391.281982\n",
      "Train Epoch: 1824 [23040/60000 (38%)] Loss: -1255.910278\n",
      "Train Epoch: 1824 [34304/60000 (57%)] Loss: -1388.824707\n",
      "Train Epoch: 1824 [45568/60000 (76%)] Loss: -1081.104004\n",
      "Train Epoch: 1824 [56832/60000 (95%)] Loss: -1392.845459\n",
      "    epoch          : 1824\n",
      "    loss           : -1371.0973207290565\n",
      "Train Epoch: 1825 [512/60000 (1%)] Loss: -1370.924194\n",
      "Train Epoch: 1825 [11776/60000 (20%)] Loss: -1368.148315\n",
      "Train Epoch: 1825 [23040/60000 (38%)] Loss: -1360.121460\n",
      "Train Epoch: 1825 [34304/60000 (57%)] Loss: -1419.280029\n",
      "Train Epoch: 1825 [45568/60000 (76%)] Loss: -1365.882812\n",
      "Train Epoch: 1825 [56832/60000 (95%)] Loss: -1095.990845\n",
      "    epoch          : 1825\n",
      "    loss           : -1351.2315887623588\n",
      "Train Epoch: 1826 [512/60000 (1%)] Loss: -1475.921387\n",
      "Train Epoch: 1826 [11776/60000 (20%)] Loss: -1361.488892\n",
      "Train Epoch: 1826 [23040/60000 (38%)] Loss: -1358.277466\n",
      "Train Epoch: 1826 [34304/60000 (57%)] Loss: -1390.848145\n",
      "Train Epoch: 1826 [45568/60000 (76%)] Loss: -1508.358154\n",
      "Train Epoch: 1826 [56832/60000 (95%)] Loss: -1407.476074\n",
      "    epoch          : 1826\n",
      "    loss           : -1381.9822125623457\n",
      "Train Epoch: 1827 [512/60000 (1%)] Loss: -1340.843506\n",
      "Train Epoch: 1827 [11776/60000 (20%)] Loss: -1365.818848\n",
      "Train Epoch: 1827 [23040/60000 (38%)] Loss: -1394.760254\n",
      "Train Epoch: 1827 [34304/60000 (57%)] Loss: -1565.737061\n",
      "Train Epoch: 1827 [45568/60000 (76%)] Loss: -1381.241455\n",
      "Train Epoch: 1827 [56832/60000 (95%)] Loss: -1248.866333\n",
      "    epoch          : 1827\n",
      "    loss           : -1362.3492666125971\n",
      "Train Epoch: 1828 [512/60000 (1%)] Loss: -1374.760498\n",
      "Train Epoch: 1828 [11776/60000 (20%)] Loss: -1525.948975\n",
      "Train Epoch: 1828 [23040/60000 (38%)] Loss: -1392.515747\n",
      "Train Epoch: 1828 [34304/60000 (57%)] Loss: -1252.390015\n",
      "Train Epoch: 1828 [45568/60000 (76%)] Loss: -1132.857178\n",
      "Train Epoch: 1828 [56832/60000 (95%)] Loss: -1371.674072\n",
      "    epoch          : 1828\n",
      "    loss           : -1375.3043581860215\n",
      "Train Epoch: 1829 [512/60000 (1%)] Loss: -1325.148682\n",
      "Train Epoch: 1829 [11776/60000 (20%)] Loss: -1220.586426\n",
      "Train Epoch: 1829 [23040/60000 (38%)] Loss: -1494.940186\n",
      "Train Epoch: 1829 [34304/60000 (57%)] Loss: -1378.458252\n",
      "Train Epoch: 1829 [45568/60000 (76%)] Loss: -1545.935303\n",
      "Train Epoch: 1829 [56832/60000 (95%)] Loss: -1423.906372\n",
      "    epoch          : 1829\n",
      "    loss           : -1382.0846107612222\n",
      "Train Epoch: 1830 [512/60000 (1%)] Loss: -1215.220947\n",
      "Train Epoch: 1830 [11776/60000 (20%)] Loss: -1368.687744\n",
      "Train Epoch: 1830 [23040/60000 (38%)] Loss: -1230.426758\n",
      "Train Epoch: 1830 [34304/60000 (57%)] Loss: -1247.739868\n",
      "Train Epoch: 1830 [45568/60000 (76%)] Loss: -1353.117188\n",
      "Train Epoch: 1830 [56832/60000 (95%)] Loss: -1365.399902\n",
      "    epoch          : 1830\n",
      "    loss           : -1375.03198862884\n",
      "Train Epoch: 1831 [512/60000 (1%)] Loss: -1361.054565\n",
      "Train Epoch: 1831 [11776/60000 (20%)] Loss: -1414.598267\n",
      "Train Epoch: 1831 [23040/60000 (38%)] Loss: -1379.712402\n",
      "Train Epoch: 1831 [34304/60000 (57%)] Loss: -1218.596436\n",
      "Train Epoch: 1831 [45568/60000 (76%)] Loss: -1364.986084\n",
      "Train Epoch: 1831 [56832/60000 (95%)] Loss: -1549.949463\n",
      "    epoch          : 1831\n",
      "    loss           : -1384.813017247087\n",
      "Train Epoch: 1832 [512/60000 (1%)] Loss: -1339.717285\n",
      "Train Epoch: 1832 [11776/60000 (20%)] Loss: -1240.842285\n",
      "Train Epoch: 1832 [23040/60000 (38%)] Loss: -1352.693359\n",
      "Train Epoch: 1832 [34304/60000 (57%)] Loss: -1358.655273\n",
      "Train Epoch: 1832 [45568/60000 (76%)] Loss: -1525.977783\n",
      "Train Epoch: 1832 [56832/60000 (95%)] Loss: -1387.076172\n",
      "    epoch          : 1832\n",
      "    loss           : -1367.0506598693503\n",
      "Train Epoch: 1833 [512/60000 (1%)] Loss: -1536.919678\n",
      "Train Epoch: 1833 [11776/60000 (20%)] Loss: -1413.212891\n",
      "Train Epoch: 1833 [23040/60000 (38%)] Loss: -1239.530029\n",
      "Train Epoch: 1833 [34304/60000 (57%)] Loss: -1389.844971\n",
      "Train Epoch: 1833 [45568/60000 (76%)] Loss: -1218.167969\n",
      "Train Epoch: 1833 [56832/60000 (95%)] Loss: -1384.647949\n",
      "    epoch          : 1833\n",
      "    loss           : -1349.7574664616989\n",
      "Train Epoch: 1834 [512/60000 (1%)] Loss: -1224.095093\n",
      "Train Epoch: 1834 [11776/60000 (20%)] Loss: -1423.500244\n",
      "Train Epoch: 1834 [23040/60000 (38%)] Loss: -1488.958862\n",
      "Train Epoch: 1834 [34304/60000 (57%)] Loss: -1259.975464\n",
      "Train Epoch: 1834 [45568/60000 (76%)] Loss: -1533.045654\n",
      "Train Epoch: 1834 [56832/60000 (95%)] Loss: -1233.376221\n",
      "    epoch          : 1834\n",
      "    loss           : -1345.98872987564\n",
      "Train Epoch: 1835 [512/60000 (1%)] Loss: -1558.054565\n",
      "Train Epoch: 1835 [11776/60000 (20%)] Loss: -1268.298950\n",
      "Train Epoch: 1835 [23040/60000 (38%)] Loss: -1533.875488\n",
      "Train Epoch: 1835 [34304/60000 (57%)] Loss: -1392.682739\n",
      "Train Epoch: 1835 [45568/60000 (76%)] Loss: -1530.547852\n",
      "Train Epoch: 1835 [56832/60000 (95%)] Loss: -1516.745605\n",
      "    epoch          : 1835\n",
      "    loss           : -1363.4874334820247\n",
      "Train Epoch: 1836 [512/60000 (1%)] Loss: -1410.995605\n",
      "Train Epoch: 1836 [11776/60000 (20%)] Loss: -1488.517822\n",
      "Train Epoch: 1836 [23040/60000 (38%)] Loss: -1372.410278\n",
      "Train Epoch: 1836 [34304/60000 (57%)] Loss: -1357.574219\n",
      "Train Epoch: 1836 [45568/60000 (76%)] Loss: -1389.893311\n",
      "Train Epoch: 1836 [56832/60000 (95%)] Loss: -1347.495361\n",
      "    epoch          : 1836\n",
      "    loss           : -1372.3578411899716\n",
      "Train Epoch: 1837 [512/60000 (1%)] Loss: -1573.188354\n",
      "Train Epoch: 1837 [11776/60000 (20%)] Loss: -1377.728882\n",
      "Train Epoch: 1837 [23040/60000 (38%)] Loss: -1557.174194\n",
      "Train Epoch: 1837 [34304/60000 (57%)] Loss: -1497.279541\n",
      "Train Epoch: 1837 [45568/60000 (76%)] Loss: -1383.301758\n",
      "Train Epoch: 1837 [56832/60000 (95%)] Loss: -1208.876709\n",
      "    epoch          : 1837\n",
      "    loss           : -1360.1325466349974\n",
      "Train Epoch: 1838 [512/60000 (1%)] Loss: -1357.132446\n",
      "Train Epoch: 1838 [11776/60000 (20%)] Loss: -1515.799683\n",
      "Train Epoch: 1838 [23040/60000 (38%)] Loss: -1227.055664\n",
      "Train Epoch: 1838 [34304/60000 (57%)] Loss: -1375.970947\n",
      "Train Epoch: 1838 [45568/60000 (76%)] Loss: -1521.846924\n",
      "Train Epoch: 1838 [56832/60000 (95%)] Loss: -1549.854614\n",
      "    epoch          : 1838\n",
      "    loss           : -1367.693858346023\n",
      "Train Epoch: 1839 [512/60000 (1%)] Loss: -1503.723267\n",
      "Train Epoch: 1839 [11776/60000 (20%)] Loss: -1535.032593\n",
      "Train Epoch: 1839 [23040/60000 (38%)] Loss: -1381.691895\n",
      "Train Epoch: 1839 [34304/60000 (57%)] Loss: -1361.583740\n",
      "Train Epoch: 1839 [45568/60000 (76%)] Loss: -1374.538452\n",
      "Train Epoch: 1839 [56832/60000 (95%)] Loss: -1513.451172\n",
      "    epoch          : 1839\n",
      "    loss           : -1375.215796001887\n",
      "Train Epoch: 1840 [512/60000 (1%)] Loss: -1382.047363\n",
      "Train Epoch: 1840 [11776/60000 (20%)] Loss: -1386.906006\n",
      "Train Epoch: 1840 [23040/60000 (38%)] Loss: -1207.102295\n",
      "Train Epoch: 1840 [34304/60000 (57%)] Loss: -1392.765015\n",
      "Train Epoch: 1840 [45568/60000 (76%)] Loss: -1482.326904\n",
      "Train Epoch: 1840 [56832/60000 (95%)] Loss: -1264.297119\n",
      "    epoch          : 1840\n",
      "    loss           : -1367.990205581579\n",
      "Train Epoch: 1841 [512/60000 (1%)] Loss: -1262.704834\n",
      "Train Epoch: 1841 [11776/60000 (20%)] Loss: -1540.562256\n",
      "Train Epoch: 1841 [23040/60000 (38%)] Loss: -1535.372070\n",
      "Train Epoch: 1841 [34304/60000 (57%)] Loss: -1377.205811\n",
      "Train Epoch: 1841 [45568/60000 (76%)] Loss: -1386.548096\n",
      "Train Epoch: 1841 [56832/60000 (95%)] Loss: -1363.007568\n",
      "    epoch          : 1841\n",
      "    loss           : -1370.2064112431585\n",
      "Train Epoch: 1842 [512/60000 (1%)] Loss: -1201.012695\n",
      "Train Epoch: 1842 [11776/60000 (20%)] Loss: -1102.548340\n",
      "Train Epoch: 1842 [23040/60000 (38%)] Loss: -1372.875122\n",
      "Train Epoch: 1842 [34304/60000 (57%)] Loss: -1532.715088\n",
      "Train Epoch: 1842 [45568/60000 (76%)] Loss: -1099.827515\n",
      "Train Epoch: 1842 [56832/60000 (95%)] Loss: -1374.124023\n",
      "    epoch          : 1842\n",
      "    loss           : -1368.2455802960585\n",
      "Train Epoch: 1843 [512/60000 (1%)] Loss: -1390.198242\n",
      "Train Epoch: 1843 [11776/60000 (20%)] Loss: -1501.169434\n",
      "Train Epoch: 1843 [23040/60000 (38%)] Loss: -1384.806885\n",
      "Train Epoch: 1843 [34304/60000 (57%)] Loss: -1373.409790\n",
      "Train Epoch: 1843 [45568/60000 (76%)] Loss: -1491.144409\n",
      "Train Epoch: 1843 [56832/60000 (95%)] Loss: -1231.387329\n",
      "    epoch          : 1843\n",
      "    loss           : -1367.3007953880872\n",
      "Train Epoch: 1844 [512/60000 (1%)] Loss: -1359.684814\n",
      "Train Epoch: 1844 [11776/60000 (20%)] Loss: -1403.279663\n",
      "Train Epoch: 1844 [23040/60000 (38%)] Loss: -1518.070923\n",
      "Train Epoch: 1844 [34304/60000 (57%)] Loss: -1425.321777\n",
      "Train Epoch: 1844 [45568/60000 (76%)] Loss: -1540.235596\n",
      "Train Epoch: 1844 [56832/60000 (95%)] Loss: -1222.141724\n",
      "    epoch          : 1844\n",
      "    loss           : -1366.0665465963764\n",
      "Train Epoch: 1845 [512/60000 (1%)] Loss: -1508.686890\n",
      "Train Epoch: 1845 [11776/60000 (20%)] Loss: -1520.983521\n",
      "Train Epoch: 1845 [23040/60000 (38%)] Loss: -1088.943970\n",
      "Train Epoch: 1845 [34304/60000 (57%)] Loss: -1381.194336\n",
      "Train Epoch: 1845 [45568/60000 (76%)] Loss: -1373.573730\n",
      "Train Epoch: 1845 [56832/60000 (95%)] Loss: -1322.091553\n",
      "    epoch          : 1845\n",
      "    loss           : -1377.1078894663665\n",
      "Train Epoch: 1846 [512/60000 (1%)] Loss: -1131.326538\n",
      "Train Epoch: 1846 [11776/60000 (20%)] Loss: -1234.543457\n",
      "Train Epoch: 1846 [23040/60000 (38%)] Loss: -1342.870361\n",
      "Train Epoch: 1846 [34304/60000 (57%)] Loss: -1516.962158\n",
      "Train Epoch: 1846 [45568/60000 (76%)] Loss: -1560.729980\n",
      "Train Epoch: 1846 [56832/60000 (95%)] Loss: -1085.243408\n",
      "    epoch          : 1846\n",
      "    loss           : -1369.5564099327992\n",
      "Train Epoch: 1847 [512/60000 (1%)] Loss: -1097.203857\n",
      "Train Epoch: 1847 [11776/60000 (20%)] Loss: -1242.445801\n",
      "Train Epoch: 1847 [23040/60000 (38%)] Loss: -1387.291504\n",
      "Train Epoch: 1847 [34304/60000 (57%)] Loss: -1504.257080\n",
      "Train Epoch: 1847 [45568/60000 (76%)] Loss: -1523.641724\n",
      "Train Epoch: 1847 [56832/60000 (95%)] Loss: -1415.881226\n",
      "    epoch          : 1847\n",
      "    loss           : -1381.993861311573\n",
      "Train Epoch: 1848 [512/60000 (1%)] Loss: -1371.414307\n",
      "Train Epoch: 1848 [11776/60000 (20%)] Loss: -1399.035400\n",
      "Train Epoch: 1848 [23040/60000 (38%)] Loss: -1463.908203\n",
      "Train Epoch: 1848 [34304/60000 (57%)] Loss: -1397.726685\n",
      "Train Epoch: 1848 [45568/60000 (76%)] Loss: -1381.074463\n",
      "Train Epoch: 1848 [56832/60000 (95%)] Loss: -1246.098389\n",
      "    epoch          : 1848\n",
      "    loss           : -1352.6586603714247\n",
      "Train Epoch: 1849 [512/60000 (1%)] Loss: -1373.930176\n",
      "Train Epoch: 1849 [11776/60000 (20%)] Loss: -1353.274292\n",
      "Train Epoch: 1849 [23040/60000 (38%)] Loss: -1244.050293\n",
      "Train Epoch: 1849 [34304/60000 (57%)] Loss: -1517.041504\n",
      "Train Epoch: 1849 [45568/60000 (76%)] Loss: -1215.620728\n",
      "Train Epoch: 1849 [56832/60000 (95%)] Loss: -1392.074219\n",
      "    epoch          : 1849\n",
      "    loss           : -1378.6346583824372\n",
      "Train Epoch: 1850 [512/60000 (1%)] Loss: -1408.370728\n",
      "Train Epoch: 1850 [11776/60000 (20%)] Loss: -1239.678589\n",
      "Train Epoch: 1850 [23040/60000 (38%)] Loss: -1388.532349\n",
      "Train Epoch: 1850 [34304/60000 (57%)] Loss: -1321.218872\n",
      "Train Epoch: 1850 [45568/60000 (76%)] Loss: -1517.700439\n",
      "Train Epoch: 1850 [56832/60000 (95%)] Loss: -1374.892578\n",
      "    epoch          : 1850\n",
      "    loss           : -1363.651383566991\n",
      "Train Epoch: 1851 [512/60000 (1%)] Loss: -1527.396606\n",
      "Train Epoch: 1851 [11776/60000 (20%)] Loss: -1410.819824\n",
      "Train Epoch: 1851 [23040/60000 (38%)] Loss: -1098.565796\n",
      "Train Epoch: 1851 [34304/60000 (57%)] Loss: -1259.201782\n",
      "Train Epoch: 1851 [45568/60000 (76%)] Loss: -1345.172363\n",
      "Train Epoch: 1851 [56832/60000 (95%)] Loss: -1280.133789\n",
      "    epoch          : 1851\n",
      "    loss           : -1369.879020044359\n",
      "Train Epoch: 1852 [512/60000 (1%)] Loss: -1253.600464\n",
      "Train Epoch: 1852 [11776/60000 (20%)] Loss: -1221.558594\n",
      "Train Epoch: 1852 [23040/60000 (38%)] Loss: -1373.929321\n",
      "Train Epoch: 1852 [34304/60000 (57%)] Loss: -1222.268066\n",
      "Train Epoch: 1852 [45568/60000 (76%)] Loss: -1379.404419\n",
      "Train Epoch: 1852 [56832/60000 (95%)] Loss: -1222.830322\n",
      "    epoch          : 1852\n",
      "    loss           : -1360.8086358194298\n",
      "Train Epoch: 1853 [512/60000 (1%)] Loss: -1339.208984\n",
      "Train Epoch: 1853 [11776/60000 (20%)] Loss: -1217.878662\n",
      "Train Epoch: 1853 [23040/60000 (38%)] Loss: -1425.396240\n",
      "Train Epoch: 1853 [34304/60000 (57%)] Loss: -1367.339722\n",
      "Train Epoch: 1853 [45568/60000 (76%)] Loss: -1409.498779\n",
      "Train Epoch: 1853 [56832/60000 (95%)] Loss: -1389.072998\n",
      "    epoch          : 1853\n",
      "    loss           : -1369.8447000104827\n",
      "Train Epoch: 1854 [512/60000 (1%)] Loss: -1224.983154\n",
      "Train Epoch: 1854 [11776/60000 (20%)] Loss: -1237.634277\n",
      "Train Epoch: 1854 [23040/60000 (38%)] Loss: -1364.001709\n",
      "Train Epoch: 1854 [34304/60000 (57%)] Loss: -1249.611328\n",
      "Train Epoch: 1854 [45568/60000 (76%)] Loss: -1242.009277\n",
      "Train Epoch: 1854 [56832/60000 (95%)] Loss: -1386.438232\n",
      "    epoch          : 1854\n",
      "    loss           : -1377.1291393560205\n",
      "Train Epoch: 1855 [512/60000 (1%)] Loss: -1247.184082\n",
      "Train Epoch: 1855 [11776/60000 (20%)] Loss: -1370.774292\n",
      "Train Epoch: 1855 [23040/60000 (38%)] Loss: -1088.429199\n",
      "Train Epoch: 1855 [34304/60000 (57%)] Loss: -1403.111572\n",
      "Train Epoch: 1855 [45568/60000 (76%)] Loss: -1235.931396\n",
      "Train Epoch: 1855 [56832/60000 (95%)] Loss: -1246.615356\n",
      "    epoch          : 1855\n",
      "    loss           : -1360.5249633789062\n",
      "Train Epoch: 1856 [512/60000 (1%)] Loss: -1490.976685\n",
      "Train Epoch: 1856 [11776/60000 (20%)] Loss: -1225.165894\n",
      "Train Epoch: 1856 [23040/60000 (38%)] Loss: -1228.037231\n",
      "Train Epoch: 1856 [34304/60000 (57%)] Loss: -1375.311768\n",
      "Train Epoch: 1856 [45568/60000 (76%)] Loss: -1527.516479\n",
      "Train Epoch: 1856 [56832/60000 (95%)] Loss: -1206.194702\n",
      "    epoch          : 1856\n",
      "    loss           : -1379.9917085291975\n",
      "Train Epoch: 1857 [512/60000 (1%)] Loss: -1389.745239\n",
      "Train Epoch: 1857 [11776/60000 (20%)] Loss: -1088.049683\n",
      "Train Epoch: 1857 [23040/60000 (38%)] Loss: -1369.920898\n",
      "Train Epoch: 1857 [34304/60000 (57%)] Loss: -1384.882568\n",
      "Train Epoch: 1857 [45568/60000 (76%)] Loss: -1346.330688\n",
      "Train Epoch: 1857 [56832/60000 (95%)] Loss: -1111.953491\n",
      "    epoch          : 1857\n",
      "    loss           : -1357.336650611317\n",
      "Train Epoch: 1858 [512/60000 (1%)] Loss: -1237.791870\n",
      "Train Epoch: 1858 [11776/60000 (20%)] Loss: -1363.048340\n",
      "Train Epoch: 1858 [23040/60000 (38%)] Loss: -1536.558960\n",
      "Train Epoch: 1858 [34304/60000 (57%)] Loss: -1520.477051\n",
      "Train Epoch: 1858 [45568/60000 (76%)] Loss: -1341.769409\n",
      "Train Epoch: 1858 [56832/60000 (95%)] Loss: -1397.058350\n",
      "    epoch          : 1858\n",
      "    loss           : -1363.249125507592\n",
      "Train Epoch: 1859 [512/60000 (1%)] Loss: -1338.242676\n",
      "Train Epoch: 1859 [11776/60000 (20%)] Loss: -1387.340088\n",
      "Train Epoch: 1859 [23040/60000 (38%)] Loss: -1492.136475\n",
      "Train Epoch: 1859 [34304/60000 (57%)] Loss: -1387.191406\n",
      "Train Epoch: 1859 [45568/60000 (76%)] Loss: -1240.202515\n",
      "Train Epoch: 1859 [56832/60000 (95%)] Loss: -1117.855469\n",
      "    epoch          : 1859\n",
      "    loss           : -1367.2535088318216\n",
      "Train Epoch: 1860 [512/60000 (1%)] Loss: -1217.541992\n",
      "Train Epoch: 1860 [11776/60000 (20%)] Loss: -1244.268066\n",
      "Train Epoch: 1860 [23040/60000 (38%)] Loss: -1267.677490\n",
      "Train Epoch: 1860 [34304/60000 (57%)] Loss: -1366.271851\n",
      "Train Epoch: 1860 [45568/60000 (76%)] Loss: -1509.495728\n",
      "Train Epoch: 1860 [56832/60000 (95%)] Loss: -1075.043335\n",
      "    epoch          : 1860\n",
      "    loss           : -1363.4441797288798\n",
      "Train Epoch: 1861 [512/60000 (1%)] Loss: -1416.482422\n",
      "Train Epoch: 1861 [11776/60000 (20%)] Loss: -1264.840576\n",
      "Train Epoch: 1861 [23040/60000 (38%)] Loss: -1354.896240\n",
      "Train Epoch: 1861 [34304/60000 (57%)] Loss: -1537.810547\n",
      "Train Epoch: 1861 [45568/60000 (76%)] Loss: -1373.263428\n",
      "Train Epoch: 1861 [56832/60000 (95%)] Loss: -1324.422607\n",
      "    epoch          : 1861\n",
      "    loss           : -1381.3025312693107\n",
      "Train Epoch: 1862 [512/60000 (1%)] Loss: -1377.525513\n",
      "Train Epoch: 1862 [11776/60000 (20%)] Loss: -1403.117554\n",
      "Train Epoch: 1862 [23040/60000 (38%)] Loss: -1411.834717\n",
      "Train Epoch: 1862 [34304/60000 (57%)] Loss: -1533.727783\n",
      "Train Epoch: 1862 [45568/60000 (76%)] Loss: -1262.543823\n",
      "Train Epoch: 1862 [56832/60000 (95%)] Loss: -1365.021729\n",
      "    epoch          : 1862\n",
      "    loss           : -1381.8458782993466\n",
      "Train Epoch: 1863 [512/60000 (1%)] Loss: -1493.270752\n",
      "Train Epoch: 1863 [11776/60000 (20%)] Loss: -1257.136841\n",
      "Train Epoch: 1863 [23040/60000 (38%)] Loss: -1546.289673\n",
      "Train Epoch: 1863 [34304/60000 (57%)] Loss: -1506.720581\n",
      "Train Epoch: 1863 [45568/60000 (76%)] Loss: -1492.360962\n",
      "Train Epoch: 1863 [56832/60000 (95%)] Loss: -987.161865\n",
      "    epoch          : 1863\n",
      "    loss           : -1368.6745057186838\n",
      "Train Epoch: 1864 [512/60000 (1%)] Loss: -1387.724731\n",
      "Train Epoch: 1864 [11776/60000 (20%)] Loss: -1276.696289\n",
      "Train Epoch: 1864 [23040/60000 (38%)] Loss: -1123.739990\n",
      "Train Epoch: 1864 [34304/60000 (57%)] Loss: -1229.976074\n",
      "Train Epoch: 1864 [45568/60000 (76%)] Loss: -1098.058716\n",
      "Train Epoch: 1864 [56832/60000 (95%)] Loss: -1510.021606\n",
      "    epoch          : 1864\n",
      "    loss           : -1354.4360503288312\n",
      "Train Epoch: 1865 [512/60000 (1%)] Loss: -1398.112549\n",
      "Train Epoch: 1865 [11776/60000 (20%)] Loss: -1357.500854\n",
      "Train Epoch: 1865 [23040/60000 (38%)] Loss: -1378.573364\n",
      "Train Epoch: 1865 [34304/60000 (57%)] Loss: -1262.684326\n",
      "Train Epoch: 1865 [45568/60000 (76%)] Loss: -1386.801025\n",
      "Train Epoch: 1865 [56832/60000 (95%)] Loss: -1368.260254\n",
      "    epoch          : 1865\n",
      "    loss           : -1363.9648389223605\n",
      "Train Epoch: 1866 [512/60000 (1%)] Loss: -1500.242554\n",
      "Train Epoch: 1866 [11776/60000 (20%)] Loss: -1443.229248\n",
      "Train Epoch: 1866 [23040/60000 (38%)] Loss: -1262.573364\n",
      "Train Epoch: 1866 [34304/60000 (57%)] Loss: -1396.349976\n",
      "Train Epoch: 1866 [45568/60000 (76%)] Loss: -1550.149536\n",
      "Train Epoch: 1866 [56832/60000 (95%)] Loss: -1516.378296\n",
      "    epoch          : 1866\n",
      "    loss           : -1390.4631906283105\n",
      "Train Epoch: 1867 [512/60000 (1%)] Loss: -1249.005127\n",
      "Train Epoch: 1867 [11776/60000 (20%)] Loss: -1250.411865\n",
      "Train Epoch: 1867 [23040/60000 (38%)] Loss: -1406.520752\n",
      "Train Epoch: 1867 [34304/60000 (57%)] Loss: -1531.565063\n",
      "Train Epoch: 1867 [45568/60000 (76%)] Loss: -1270.002075\n",
      "Train Epoch: 1867 [56832/60000 (95%)] Loss: -1396.410767\n",
      "    epoch          : 1867\n",
      "    loss           : -1382.2440473481086\n",
      "Train Epoch: 1868 [512/60000 (1%)] Loss: -1393.118896\n",
      "Train Epoch: 1868 [11776/60000 (20%)] Loss: -1525.628174\n",
      "Train Epoch: 1868 [23040/60000 (38%)] Loss: -1413.661011\n",
      "Train Epoch: 1868 [34304/60000 (57%)] Loss: -1406.907715\n",
      "Train Epoch: 1868 [45568/60000 (76%)] Loss: -1346.682983\n",
      "Train Epoch: 1868 [56832/60000 (95%)] Loss: -1370.787354\n",
      "    epoch          : 1868\n",
      "    loss           : -1365.8619770976782\n",
      "Train Epoch: 1869 [512/60000 (1%)] Loss: -1390.749023\n",
      "Train Epoch: 1869 [11776/60000 (20%)] Loss: -1524.170410\n",
      "Train Epoch: 1869 [23040/60000 (38%)] Loss: -1416.657227\n",
      "Train Epoch: 1869 [34304/60000 (57%)] Loss: -1405.062988\n",
      "Train Epoch: 1869 [45568/60000 (76%)] Loss: -1392.090454\n",
      "Train Epoch: 1869 [56832/60000 (95%)] Loss: -1365.367676\n",
      "    epoch          : 1869\n",
      "    loss           : -1375.364912647312\n",
      "Train Epoch: 1870 [512/60000 (1%)] Loss: -1352.422852\n",
      "Train Epoch: 1870 [11776/60000 (20%)] Loss: -1463.336670\n",
      "Train Epoch: 1870 [23040/60000 (38%)] Loss: -1415.575073\n",
      "Train Epoch: 1870 [34304/60000 (57%)] Loss: -1235.074707\n",
      "Train Epoch: 1870 [45568/60000 (76%)] Loss: -1505.749756\n",
      "Train Epoch: 1870 [56832/60000 (95%)] Loss: -1369.166260\n",
      "    epoch          : 1870\n",
      "    loss           : -1371.6637421516375\n",
      "Train Epoch: 1871 [512/60000 (1%)] Loss: -1394.335205\n",
      "Train Epoch: 1871 [11776/60000 (20%)] Loss: -1088.972778\n",
      "Train Epoch: 1871 [23040/60000 (38%)] Loss: -1430.177979\n",
      "Train Epoch: 1871 [34304/60000 (57%)] Loss: -1376.762573\n",
      "Train Epoch: 1871 [45568/60000 (76%)] Loss: -1378.054688\n",
      "Train Epoch: 1871 [56832/60000 (95%)] Loss: -1405.847656\n",
      "    epoch          : 1871\n",
      "    loss           : -1362.2596904517566\n",
      "Train Epoch: 1872 [512/60000 (1%)] Loss: -1245.113403\n",
      "Train Epoch: 1872 [11776/60000 (20%)] Loss: -1343.911865\n",
      "Train Epoch: 1872 [23040/60000 (38%)] Loss: -1265.556274\n",
      "Train Epoch: 1872 [34304/60000 (57%)] Loss: -1241.870850\n",
      "Train Epoch: 1872 [45568/60000 (76%)] Loss: -1366.373291\n",
      "Train Epoch: 1872 [56832/60000 (95%)] Loss: -1101.957764\n",
      "    epoch          : 1872\n",
      "    loss           : -1357.016353973561\n",
      "Train Epoch: 1873 [512/60000 (1%)] Loss: -1226.346680\n",
      "Train Epoch: 1873 [11776/60000 (20%)] Loss: -1340.822021\n",
      "Train Epoch: 1873 [23040/60000 (38%)] Loss: -1511.306885\n",
      "Train Epoch: 1873 [34304/60000 (57%)] Loss: -1536.096558\n",
      "Train Epoch: 1873 [45568/60000 (76%)] Loss: -1360.289673\n",
      "Train Epoch: 1873 [56832/60000 (95%)] Loss: -1506.641602\n",
      "    epoch          : 1873\n",
      "    loss           : -1362.214009947696\n",
      "Train Epoch: 1874 [512/60000 (1%)] Loss: -1369.791626\n",
      "Train Epoch: 1874 [11776/60000 (20%)] Loss: -1245.020874\n",
      "Train Epoch: 1874 [23040/60000 (38%)] Loss: -1367.455688\n",
      "Train Epoch: 1874 [34304/60000 (57%)] Loss: -1399.253906\n",
      "Train Epoch: 1874 [45568/60000 (76%)] Loss: -1358.666992\n",
      "Train Epoch: 1874 [56832/60000 (95%)] Loss: -1380.847046\n",
      "    epoch          : 1874\n",
      "    loss           : -1344.1200601179046\n",
      "Train Epoch: 1875 [512/60000 (1%)] Loss: -1383.113525\n",
      "Train Epoch: 1875 [11776/60000 (20%)] Loss: -1534.518921\n",
      "Train Epoch: 1875 [23040/60000 (38%)] Loss: -1398.009644\n",
      "Train Epoch: 1875 [34304/60000 (57%)] Loss: -1562.466797\n",
      "Train Epoch: 1875 [45568/60000 (76%)] Loss: -1536.130127\n",
      "Train Epoch: 1875 [56832/60000 (95%)] Loss: -1333.078369\n",
      "    epoch          : 1875\n",
      "    loss           : -1361.0608558439267\n",
      "Train Epoch: 1876 [512/60000 (1%)] Loss: -1253.857422\n",
      "Train Epoch: 1876 [11776/60000 (20%)] Loss: -1205.462524\n",
      "Train Epoch: 1876 [23040/60000 (38%)] Loss: -1382.110352\n",
      "Train Epoch: 1876 [34304/60000 (57%)] Loss: -1510.346436\n",
      "Train Epoch: 1876 [45568/60000 (76%)] Loss: -1249.395630\n",
      "Train Epoch: 1876 [56832/60000 (95%)] Loss: -1521.669189\n",
      "    epoch          : 1876\n",
      "    loss           : -1360.3971864517127\n",
      "Train Epoch: 1877 [512/60000 (1%)] Loss: -1245.555664\n",
      "Train Epoch: 1877 [11776/60000 (20%)] Loss: -1383.167969\n",
      "Train Epoch: 1877 [23040/60000 (38%)] Loss: -1412.438965\n",
      "Train Epoch: 1877 [34304/60000 (57%)] Loss: -1402.496338\n",
      "Train Epoch: 1877 [45568/60000 (76%)] Loss: -1214.526611\n",
      "Train Epoch: 1877 [56832/60000 (95%)] Loss: -1381.337158\n",
      "    epoch          : 1877\n",
      "    loss           : -1368.4132630084196\n",
      "Train Epoch: 1878 [512/60000 (1%)] Loss: -1389.240723\n",
      "Train Epoch: 1878 [11776/60000 (20%)] Loss: -1254.935669\n",
      "Train Epoch: 1878 [23040/60000 (38%)] Loss: -1373.711792\n",
      "Train Epoch: 1878 [34304/60000 (57%)] Loss: -1243.289185\n",
      "Train Epoch: 1878 [45568/60000 (76%)] Loss: -1363.196411\n",
      "Train Epoch: 1878 [56832/60000 (95%)] Loss: -1383.044922\n",
      "    epoch          : 1878\n",
      "    loss           : -1354.0726295945333\n",
      "Train Epoch: 1879 [512/60000 (1%)] Loss: -1363.713501\n",
      "Train Epoch: 1879 [11776/60000 (20%)] Loss: -1550.772705\n",
      "Train Epoch: 1879 [23040/60000 (38%)] Loss: -1521.549072\n",
      "Train Epoch: 1879 [34304/60000 (57%)] Loss: -1372.010010\n",
      "Train Epoch: 1879 [45568/60000 (76%)] Loss: -1361.108521\n",
      "Train Epoch: 1879 [56832/60000 (95%)] Loss: -1257.729004\n",
      "    epoch          : 1879\n",
      "    loss           : -1388.3935298596398\n",
      "Train Epoch: 1880 [512/60000 (1%)] Loss: -1395.033081\n",
      "Train Epoch: 1880 [11776/60000 (20%)] Loss: -1389.717651\n",
      "Train Epoch: 1880 [23040/60000 (38%)] Loss: -1537.392700\n",
      "Train Epoch: 1880 [34304/60000 (57%)] Loss: -1375.656616\n",
      "Train Epoch: 1880 [45568/60000 (76%)] Loss: -1366.060913\n",
      "Train Epoch: 1880 [56832/60000 (95%)] Loss: -1403.216187\n",
      "    epoch          : 1880\n",
      "    loss           : -1354.988377113127\n",
      "Train Epoch: 1881 [512/60000 (1%)] Loss: -1250.463745\n",
      "Train Epoch: 1881 [11776/60000 (20%)] Loss: -1224.873291\n",
      "Train Epoch: 1881 [23040/60000 (38%)] Loss: -922.671143\n",
      "Train Epoch: 1881 [34304/60000 (57%)] Loss: -1381.494019\n",
      "Train Epoch: 1881 [45568/60000 (76%)] Loss: -1382.919312\n",
      "Train Epoch: 1881 [56832/60000 (95%)] Loss: -1280.919434\n",
      "    epoch          : 1881\n",
      "    loss           : -1335.4213412010063\n",
      "Train Epoch: 1882 [512/60000 (1%)] Loss: -1257.188599\n",
      "Train Epoch: 1882 [11776/60000 (20%)] Loss: -1264.923096\n",
      "Train Epoch: 1882 [23040/60000 (38%)] Loss: -1076.902466\n",
      "Train Epoch: 1882 [34304/60000 (57%)] Loss: -1262.614624\n",
      "Train Epoch: 1882 [45568/60000 (76%)] Loss: -959.877136\n",
      "Train Epoch: 1882 [56832/60000 (95%)] Loss: -1553.824463\n",
      "    epoch          : 1882\n",
      "    loss           : -1336.6444746976517\n",
      "Train Epoch: 1883 [512/60000 (1%)] Loss: -1057.509888\n",
      "Train Epoch: 1883 [11776/60000 (20%)] Loss: -1370.023804\n",
      "Train Epoch: 1883 [23040/60000 (38%)] Loss: -1359.317383\n",
      "Train Epoch: 1883 [34304/60000 (57%)] Loss: -1380.843506\n",
      "Train Epoch: 1883 [45568/60000 (76%)] Loss: -1555.629150\n",
      "Train Epoch: 1883 [56832/60000 (95%)] Loss: -1407.615723\n",
      "    epoch          : 1883\n",
      "    loss           : -1362.6618157510704\n",
      "Train Epoch: 1884 [512/60000 (1%)] Loss: -1405.882812\n",
      "Train Epoch: 1884 [11776/60000 (20%)] Loss: -1384.034912\n",
      "Train Epoch: 1884 [23040/60000 (38%)] Loss: -1214.335571\n",
      "Train Epoch: 1884 [34304/60000 (57%)] Loss: -1507.130371\n",
      "Train Epoch: 1884 [45568/60000 (76%)] Loss: -1510.174805\n",
      "Train Epoch: 1884 [56832/60000 (95%)] Loss: -1405.358398\n",
      "    epoch          : 1884\n",
      "    loss           : -1349.006048515018\n",
      "Train Epoch: 1885 [512/60000 (1%)] Loss: -1223.666992\n",
      "Train Epoch: 1885 [11776/60000 (20%)] Loss: -1255.978882\n",
      "Train Epoch: 1885 [23040/60000 (38%)] Loss: -1484.765869\n",
      "Train Epoch: 1885 [34304/60000 (57%)] Loss: -1197.730469\n",
      "Train Epoch: 1885 [45568/60000 (76%)] Loss: -1402.266113\n",
      "Train Epoch: 1885 [56832/60000 (95%)] Loss: -1457.015015\n",
      "    epoch          : 1885\n",
      "    loss           : -1377.4260143560205\n",
      "Train Epoch: 1886 [512/60000 (1%)] Loss: -1237.215332\n",
      "Train Epoch: 1886 [11776/60000 (20%)] Loss: -1390.237061\n",
      "Train Epoch: 1886 [23040/60000 (38%)] Loss: -1395.272827\n",
      "Train Epoch: 1886 [34304/60000 (57%)] Loss: -1384.913208\n",
      "Train Epoch: 1886 [45568/60000 (76%)] Loss: -1400.515625\n",
      "Train Epoch: 1886 [56832/60000 (95%)] Loss: -1254.312988\n",
      "    epoch          : 1886\n",
      "    loss           : -1352.2251131736625\n",
      "Train Epoch: 1887 [512/60000 (1%)] Loss: -1401.289307\n",
      "Train Epoch: 1887 [11776/60000 (20%)] Loss: -1560.126221\n",
      "Train Epoch: 1887 [23040/60000 (38%)] Loss: -1106.295410\n",
      "Train Epoch: 1887 [34304/60000 (57%)] Loss: -1389.269287\n",
      "Train Epoch: 1887 [45568/60000 (76%)] Loss: -1335.961670\n",
      "Train Epoch: 1887 [56832/60000 (95%)] Loss: -1562.042969\n",
      "    epoch          : 1887\n",
      "    loss           : -1364.5290554930261\n",
      "Train Epoch: 1888 [512/60000 (1%)] Loss: -1519.384766\n",
      "Train Epoch: 1888 [11776/60000 (20%)] Loss: -1228.946167\n",
      "Train Epoch: 1888 [23040/60000 (38%)] Loss: -1482.396973\n",
      "Train Epoch: 1888 [34304/60000 (57%)] Loss: -1388.969604\n",
      "Train Epoch: 1888 [45568/60000 (76%)] Loss: -1376.664673\n",
      "Train Epoch: 1888 [56832/60000 (95%)] Loss: -1235.126953\n",
      "    epoch          : 1888\n",
      "    loss           : -1364.0438697944253\n",
      "Train Epoch: 1889 [512/60000 (1%)] Loss: -1231.290649\n",
      "Train Epoch: 1889 [11776/60000 (20%)] Loss: -1212.623413\n",
      "Train Epoch: 1889 [23040/60000 (38%)] Loss: -1384.614624\n",
      "Train Epoch: 1889 [34304/60000 (57%)] Loss: -1521.661499\n",
      "Train Epoch: 1889 [45568/60000 (76%)] Loss: -1513.322021\n",
      "Train Epoch: 1889 [56832/60000 (95%)] Loss: -1523.595947\n",
      "    epoch          : 1889\n",
      "    loss           : -1351.3594629320048\n",
      "Train Epoch: 1890 [512/60000 (1%)] Loss: -1229.315674\n",
      "Train Epoch: 1890 [11776/60000 (20%)] Loss: -1508.572388\n",
      "Train Epoch: 1890 [23040/60000 (38%)] Loss: -1139.788452\n",
      "Train Epoch: 1890 [34304/60000 (57%)] Loss: -1373.883911\n",
      "Train Epoch: 1890 [45568/60000 (76%)] Loss: -1390.335449\n",
      "Train Epoch: 1890 [56832/60000 (95%)] Loss: -1245.640625\n",
      "    epoch          : 1890\n",
      "    loss           : -1369.3874677237818\n",
      "Train Epoch: 1891 [512/60000 (1%)] Loss: -1365.279053\n",
      "Train Epoch: 1891 [11776/60000 (20%)] Loss: -1220.406006\n",
      "Train Epoch: 1891 [23040/60000 (38%)] Loss: -1352.770508\n",
      "Train Epoch: 1891 [34304/60000 (57%)] Loss: -1236.677490\n",
      "Train Epoch: 1891 [45568/60000 (76%)] Loss: -1401.089600\n",
      "Train Epoch: 1891 [56832/60000 (95%)] Loss: -1402.052734\n",
      "    epoch          : 1891\n",
      "    loss           : -1355.4615161270744\n",
      "Train Epoch: 1892 [512/60000 (1%)] Loss: -1390.844971\n",
      "Train Epoch: 1892 [11776/60000 (20%)] Loss: -1373.242676\n",
      "Train Epoch: 1892 [23040/60000 (38%)] Loss: -1345.750366\n",
      "Train Epoch: 1892 [34304/60000 (57%)] Loss: -1070.339844\n",
      "Train Epoch: 1892 [45568/60000 (76%)] Loss: -1212.945679\n",
      "Train Epoch: 1892 [56832/60000 (95%)] Loss: -1218.469238\n",
      "    epoch          : 1892\n",
      "    loss           : -1349.2698157358977\n",
      "Train Epoch: 1893 [512/60000 (1%)] Loss: -1395.988037\n",
      "Train Epoch: 1893 [11776/60000 (20%)] Loss: -1383.012939\n",
      "Train Epoch: 1893 [23040/60000 (38%)] Loss: -1498.994385\n",
      "Train Epoch: 1893 [34304/60000 (57%)] Loss: -1240.693726\n",
      "Train Epoch: 1893 [45568/60000 (76%)] Loss: -1341.709961\n",
      "Train Epoch: 1893 [56832/60000 (95%)] Loss: -1397.218506\n",
      "    epoch          : 1893\n",
      "    loss           : -1362.3334302309543\n",
      "Train Epoch: 1894 [512/60000 (1%)] Loss: -1246.379028\n",
      "Train Epoch: 1894 [11776/60000 (20%)] Loss: -1192.628540\n",
      "Train Epoch: 1894 [23040/60000 (38%)] Loss: -1243.385254\n",
      "Train Epoch: 1894 [34304/60000 (57%)] Loss: -1523.192139\n",
      "Train Epoch: 1894 [45568/60000 (76%)] Loss: -1221.336060\n",
      "Train Epoch: 1894 [56832/60000 (95%)] Loss: -1138.414062\n",
      "    epoch          : 1894\n",
      "    loss           : -1346.5271730584614\n",
      "Train Epoch: 1895 [512/60000 (1%)] Loss: -1231.288330\n",
      "Train Epoch: 1895 [11776/60000 (20%)] Loss: -1532.235352\n",
      "Train Epoch: 1895 [23040/60000 (38%)] Loss: -1380.495728\n",
      "Train Epoch: 1895 [34304/60000 (57%)] Loss: -1360.731812\n",
      "Train Epoch: 1895 [45568/60000 (76%)] Loss: -1221.180908\n",
      "Train Epoch: 1895 [56832/60000 (95%)] Loss: -1096.653076\n",
      "    epoch          : 1895\n",
      "    loss           : -1365.6664966647909\n",
      "Train Epoch: 1896 [512/60000 (1%)] Loss: -1370.596191\n",
      "Train Epoch: 1896 [11776/60000 (20%)] Loss: -1515.018799\n",
      "Train Epoch: 1896 [23040/60000 (38%)] Loss: -1533.903931\n",
      "Train Epoch: 1896 [34304/60000 (57%)] Loss: -1242.690796\n",
      "Train Epoch: 1896 [45568/60000 (76%)] Loss: -1372.960938\n",
      "Train Epoch: 1896 [56832/60000 (95%)] Loss: -1221.727295\n",
      "    epoch          : 1896\n",
      "    loss           : -1344.5697276659605\n",
      "Train Epoch: 1897 [512/60000 (1%)] Loss: -1250.125732\n",
      "Train Epoch: 1897 [11776/60000 (20%)] Loss: -1525.574219\n",
      "Train Epoch: 1897 [23040/60000 (38%)] Loss: -1512.275879\n",
      "Train Epoch: 1897 [34304/60000 (57%)] Loss: -1083.043823\n",
      "Train Epoch: 1897 [45568/60000 (76%)] Loss: -1384.374023\n",
      "Train Epoch: 1897 [56832/60000 (95%)] Loss: -1215.312134\n",
      "    epoch          : 1897\n",
      "    loss           : -1382.2726730088057\n",
      "Train Epoch: 1898 [512/60000 (1%)] Loss: -1541.849121\n",
      "Train Epoch: 1898 [11776/60000 (20%)] Loss: -1364.853394\n",
      "Train Epoch: 1898 [23040/60000 (38%)] Loss: -1286.574463\n",
      "Train Epoch: 1898 [34304/60000 (57%)] Loss: -1377.782104\n",
      "Train Epoch: 1898 [45568/60000 (76%)] Loss: -1512.238647\n",
      "Train Epoch: 1898 [56832/60000 (95%)] Loss: -1253.199951\n",
      "    epoch          : 1898\n",
      "    loss           : -1380.8153641695358\n",
      "Train Epoch: 1899 [512/60000 (1%)] Loss: -1206.377197\n",
      "Train Epoch: 1899 [11776/60000 (20%)] Loss: -1493.260498\n",
      "Train Epoch: 1899 [23040/60000 (38%)] Loss: -1252.545410\n",
      "Train Epoch: 1899 [34304/60000 (57%)] Loss: -1238.059204\n",
      "Train Epoch: 1899 [45568/60000 (76%)] Loss: -1352.539673\n",
      "Train Epoch: 1899 [56832/60000 (95%)] Loss: -1241.916504\n",
      "    epoch          : 1899\n",
      "    loss           : -1347.5816195213188\n",
      "Train Epoch: 1900 [512/60000 (1%)] Loss: -1384.395752\n",
      "Train Epoch: 1900 [11776/60000 (20%)] Loss: -1414.111328\n",
      "Train Epoch: 1900 [23040/60000 (38%)] Loss: -966.456726\n",
      "Train Epoch: 1900 [34304/60000 (57%)] Loss: -1379.711914\n",
      "Train Epoch: 1900 [45568/60000 (76%)] Loss: -1395.908691\n",
      "Train Epoch: 1900 [56832/60000 (95%)] Loss: -1365.614990\n",
      "    epoch          : 1900\n",
      "    loss           : -1358.9227541476318\n",
      "Saving checkpoint: saved/models/Mnist_DeepGenerativeOperad/0127_111843/checkpoint-epoch1900.pth ...\n",
      "Train Epoch: 1901 [512/60000 (1%)] Loss: -1413.086426\n",
      "Train Epoch: 1901 [11776/60000 (20%)] Loss: -1350.999512\n",
      "Train Epoch: 1901 [23040/60000 (38%)] Loss: -1388.672974\n",
      "Train Epoch: 1901 [34304/60000 (57%)] Loss: -1245.127075\n",
      "Train Epoch: 1901 [45568/60000 (76%)] Loss: -1370.683594\n",
      "Train Epoch: 1901 [56832/60000 (95%)] Loss: -1381.119995\n",
      "    epoch          : 1901\n",
      "    loss           : -1349.4024384062168\n",
      "Train Epoch: 1902 [512/60000 (1%)] Loss: -1371.519775\n",
      "Train Epoch: 1902 [11776/60000 (20%)] Loss: -1507.756226\n",
      "Train Epoch: 1902 [23040/60000 (38%)] Loss: -1506.304077\n",
      "Train Epoch: 1902 [34304/60000 (57%)] Loss: -1384.856567\n",
      "Train Epoch: 1902 [45568/60000 (76%)] Loss: -1360.356812\n",
      "Train Epoch: 1902 [56832/60000 (95%)] Loss: -1359.964966\n",
      "    epoch          : 1902\n",
      "    loss           : -1363.5785794877736\n",
      "Train Epoch: 1903 [512/60000 (1%)] Loss: -1230.090088\n",
      "Train Epoch: 1903 [11776/60000 (20%)] Loss: -1392.228027\n",
      "Train Epoch: 1903 [23040/60000 (38%)] Loss: -1264.955688\n",
      "Train Epoch: 1903 [34304/60000 (57%)] Loss: -1369.049438\n",
      "Train Epoch: 1903 [45568/60000 (76%)] Loss: -1393.154785\n",
      "Train Epoch: 1903 [56832/60000 (95%)] Loss: -1231.900635\n",
      "    epoch          : 1903\n",
      "    loss           : -1369.5700545661193\n",
      "Train Epoch: 1904 [512/60000 (1%)] Loss: -1269.152954\n",
      "Train Epoch: 1904 [11776/60000 (20%)] Loss: -1266.218628\n",
      "Train Epoch: 1904 [23040/60000 (38%)] Loss: -1257.434570\n",
      "Train Epoch: 1904 [34304/60000 (57%)] Loss: -1269.447998\n",
      "Train Epoch: 1904 [45568/60000 (76%)] Loss: -1377.340576\n",
      "Train Epoch: 1904 [56832/60000 (95%)] Loss: -1378.355591\n",
      "    epoch          : 1904\n",
      "    loss           : -1378.3190342100327\n",
      "Train Epoch: 1905 [512/60000 (1%)] Loss: -1405.768311\n",
      "Train Epoch: 1905 [11776/60000 (20%)] Loss: -1408.437622\n",
      "Train Epoch: 1905 [23040/60000 (38%)] Loss: -1203.484741\n",
      "Train Epoch: 1905 [34304/60000 (57%)] Loss: -1199.803711\n",
      "Train Epoch: 1905 [45568/60000 (76%)] Loss: -1258.189331\n",
      "Train Epoch: 1905 [56832/60000 (95%)] Loss: -1488.731445\n",
      "    epoch          : 1905\n",
      "    loss           : -1363.8220159670727\n",
      "Train Epoch: 1906 [512/60000 (1%)] Loss: -1390.984863\n",
      "Train Epoch: 1906 [11776/60000 (20%)] Loss: -1489.282227\n",
      "Train Epoch: 1906 [23040/60000 (38%)] Loss: -1388.654297\n",
      "Train Epoch: 1906 [34304/60000 (57%)] Loss: -1413.173584\n",
      "Train Epoch: 1906 [45568/60000 (76%)] Loss: -1112.337769\n",
      "Train Epoch: 1906 [56832/60000 (95%)] Loss: -1380.110352\n",
      "    epoch          : 1906\n",
      "    loss           : -1345.2077236714335\n",
      "Train Epoch: 1907 [512/60000 (1%)] Loss: -1392.693726\n",
      "Train Epoch: 1907 [11776/60000 (20%)] Loss: -1232.441895\n",
      "Train Epoch: 1907 [23040/60000 (38%)] Loss: -1243.151367\n",
      "Train Epoch: 1907 [34304/60000 (57%)] Loss: -1343.402954\n",
      "Train Epoch: 1907 [45568/60000 (76%)] Loss: -1409.618164\n",
      "Train Epoch: 1907 [56832/60000 (95%)] Loss: -1384.024414\n",
      "    epoch          : 1907\n",
      "    loss           : -1380.5988231594279\n",
      "Train Epoch: 1908 [512/60000 (1%)] Loss: -1514.952148\n",
      "Train Epoch: 1908 [11776/60000 (20%)] Loss: -1533.399902\n",
      "Train Epoch: 1908 [23040/60000 (38%)] Loss: -1365.614990\n",
      "Train Epoch: 1908 [34304/60000 (57%)] Loss: -1548.463135\n",
      "Train Epoch: 1908 [45568/60000 (76%)] Loss: -1375.824829\n",
      "Train Epoch: 1908 [56832/60000 (95%)] Loss: -1351.072754\n",
      "    epoch          : 1908\n",
      "    loss           : -1352.8703213276835\n",
      "Train Epoch: 1909 [512/60000 (1%)] Loss: -1220.672119\n",
      "Train Epoch: 1909 [11776/60000 (20%)] Loss: -1273.160522\n",
      "Train Epoch: 1909 [23040/60000 (38%)] Loss: -1097.043213\n",
      "Train Epoch: 1909 [34304/60000 (57%)] Loss: -1243.721558\n",
      "Train Epoch: 1909 [45568/60000 (76%)] Loss: -1366.391479\n",
      "Train Epoch: 1909 [56832/60000 (95%)] Loss: -1386.471069\n",
      "    epoch          : 1909\n",
      "    loss           : -1364.3187223100392\n",
      "Train Epoch: 1910 [512/60000 (1%)] Loss: -1244.617432\n",
      "Train Epoch: 1910 [11776/60000 (20%)] Loss: -1116.145752\n",
      "Train Epoch: 1910 [23040/60000 (38%)] Loss: -1403.722412\n",
      "Train Epoch: 1910 [34304/60000 (57%)] Loss: -1236.656250\n",
      "Train Epoch: 1910 [45568/60000 (76%)] Loss: -1403.735840\n",
      "Train Epoch: 1910 [56832/60000 (95%)] Loss: -1382.447998\n",
      "    epoch          : 1910\n",
      "    loss           : -1363.6827568442134\n",
      "Train Epoch: 1911 [512/60000 (1%)] Loss: -1410.125977\n",
      "Train Epoch: 1911 [11776/60000 (20%)] Loss: -1359.088745\n",
      "Train Epoch: 1911 [23040/60000 (38%)] Loss: -1552.287598\n",
      "Train Epoch: 1911 [34304/60000 (57%)] Loss: -1280.498779\n",
      "Train Epoch: 1911 [45568/60000 (76%)] Loss: -1273.075684\n",
      "Train Epoch: 1911 [56832/60000 (95%)] Loss: -1205.674438\n",
      "    epoch          : 1911\n",
      "    loss           : -1356.9977113540565\n",
      "Train Epoch: 1912 [512/60000 (1%)] Loss: -1361.270630\n",
      "Train Epoch: 1912 [11776/60000 (20%)] Loss: -1250.353760\n",
      "Train Epoch: 1912 [23040/60000 (38%)] Loss: -1538.785400\n",
      "Train Epoch: 1912 [34304/60000 (57%)] Loss: -1362.027954\n",
      "Train Epoch: 1912 [45568/60000 (76%)] Loss: -1378.985596\n",
      "Train Epoch: 1912 [56832/60000 (95%)] Loss: -1256.571777\n",
      "    epoch          : 1912\n",
      "    loss           : -1367.4523187842074\n",
      "Train Epoch: 1913 [512/60000 (1%)] Loss: -1377.614014\n",
      "Train Epoch: 1913 [11776/60000 (20%)] Loss: -1370.173584\n",
      "Train Epoch: 1913 [23040/60000 (38%)] Loss: -1431.464111\n",
      "Train Epoch: 1913 [34304/60000 (57%)] Loss: -1409.488037\n",
      "Train Epoch: 1913 [45568/60000 (76%)] Loss: -1394.220215\n",
      "Train Epoch: 1913 [56832/60000 (95%)] Loss: -1372.430542\n",
      "    epoch          : 1913\n",
      "    loss           : -1350.5389149121645\n",
      "Train Epoch: 1914 [512/60000 (1%)] Loss: -1397.048706\n",
      "Train Epoch: 1914 [11776/60000 (20%)] Loss: -1558.067505\n",
      "Train Epoch: 1914 [23040/60000 (38%)] Loss: -1248.237793\n",
      "Train Epoch: 1914 [34304/60000 (57%)] Loss: -1406.197144\n",
      "Train Epoch: 1914 [45568/60000 (76%)] Loss: -1325.534180\n",
      "Train Epoch: 1914 [56832/60000 (95%)] Loss: -1365.887939\n",
      "    epoch          : 1914\n",
      "    loss           : -1372.8798931574418\n",
      "Train Epoch: 1915 [512/60000 (1%)] Loss: -1274.196777\n",
      "Train Epoch: 1915 [11776/60000 (20%)] Loss: -1374.898438\n",
      "Train Epoch: 1915 [23040/60000 (38%)] Loss: -1240.945312\n",
      "Train Epoch: 1915 [34304/60000 (57%)] Loss: -1281.931152\n",
      "Train Epoch: 1915 [45568/60000 (76%)] Loss: -1355.911865\n",
      "Train Epoch: 1915 [56832/60000 (95%)] Loss: -1552.181885\n",
      "    epoch          : 1915\n",
      "    loss           : -1378.4107769465043\n",
      "Train Epoch: 1916 [512/60000 (1%)] Loss: -1373.101562\n",
      "Train Epoch: 1916 [11776/60000 (20%)] Loss: -1416.426392\n",
      "Train Epoch: 1916 [23040/60000 (38%)] Loss: -1360.221436\n",
      "Train Epoch: 1916 [34304/60000 (57%)] Loss: -1490.241211\n",
      "Train Epoch: 1916 [45568/60000 (76%)] Loss: -1270.809448\n",
      "Train Epoch: 1916 [56832/60000 (95%)] Loss: -1238.881470\n",
      "    epoch          : 1916\n",
      "    loss           : -1369.1096884517347\n",
      "Train Epoch: 1917 [512/60000 (1%)] Loss: -1403.311035\n",
      "Train Epoch: 1917 [11776/60000 (20%)] Loss: -1360.547852\n",
      "Train Epoch: 1917 [23040/60000 (38%)] Loss: -1246.877075\n",
      "Train Epoch: 1917 [34304/60000 (57%)] Loss: -1506.414062\n",
      "Train Epoch: 1917 [45568/60000 (76%)] Loss: -1131.968018\n",
      "Train Epoch: 1917 [56832/60000 (95%)] Loss: -1253.206665\n",
      "    epoch          : 1917\n",
      "    loss           : -1352.6229242874404\n",
      "Train Epoch: 1918 [512/60000 (1%)] Loss: -1250.061157\n",
      "Train Epoch: 1918 [11776/60000 (20%)] Loss: -1389.740967\n",
      "Train Epoch: 1918 [23040/60000 (38%)] Loss: -1237.431885\n",
      "Train Epoch: 1918 [34304/60000 (57%)] Loss: -1274.155884\n",
      "Train Epoch: 1918 [45568/60000 (76%)] Loss: -1551.563965\n",
      "Train Epoch: 1918 [56832/60000 (95%)] Loss: -1262.220215\n",
      "    epoch          : 1918\n",
      "    loss           : -1357.760580289162\n",
      "Train Epoch: 1919 [512/60000 (1%)] Loss: -1521.503418\n",
      "Train Epoch: 1919 [11776/60000 (20%)] Loss: -1511.129395\n",
      "Train Epoch: 1919 [23040/60000 (38%)] Loss: -1572.403931\n",
      "Train Epoch: 1919 [34304/60000 (57%)] Loss: -1242.528076\n",
      "Train Epoch: 1919 [45568/60000 (76%)] Loss: -1232.553101\n",
      "Train Epoch: 1919 [56832/60000 (95%)] Loss: -1365.812012\n",
      "    epoch          : 1919\n",
      "    loss           : -1392.9687405171367\n",
      "Train Epoch: 1920 [512/60000 (1%)] Loss: -1405.527222\n",
      "Train Epoch: 1920 [11776/60000 (20%)] Loss: -1231.330811\n",
      "Train Epoch: 1920 [23040/60000 (38%)] Loss: -1521.267822\n",
      "Train Epoch: 1920 [34304/60000 (57%)] Loss: -1271.833496\n",
      "Train Epoch: 1920 [45568/60000 (76%)] Loss: -1247.658813\n",
      "Train Epoch: 1920 [56832/60000 (95%)] Loss: -1400.214844\n",
      "    epoch          : 1920\n",
      "    loss           : -1376.5819546974312\n",
      "Train Epoch: 1921 [512/60000 (1%)] Loss: -1407.151855\n",
      "Train Epoch: 1921 [11776/60000 (20%)] Loss: -1488.020752\n",
      "Train Epoch: 1921 [23040/60000 (38%)] Loss: -1274.757080\n",
      "Train Epoch: 1921 [34304/60000 (57%)] Loss: -1531.339600\n",
      "Train Epoch: 1921 [45568/60000 (76%)] Loss: -1514.576416\n",
      "Train Epoch: 1921 [56832/60000 (95%)] Loss: -1213.867188\n",
      "    epoch          : 1921\n",
      "    loss           : -1375.1376756571108\n",
      "Train Epoch: 1922 [512/60000 (1%)] Loss: -1229.667725\n",
      "Train Epoch: 1922 [11776/60000 (20%)] Loss: -1571.525513\n",
      "Train Epoch: 1922 [23040/60000 (38%)] Loss: -1379.266113\n",
      "Train Epoch: 1922 [34304/60000 (57%)] Loss: -1502.102173\n",
      "Train Epoch: 1922 [45568/60000 (76%)] Loss: -1216.256470\n",
      "Train Epoch: 1922 [56832/60000 (95%)] Loss: -1475.220337\n",
      "    epoch          : 1922\n",
      "    loss           : -1361.0968698620122\n",
      "Train Epoch: 1923 [512/60000 (1%)] Loss: -1256.660156\n",
      "Train Epoch: 1923 [11776/60000 (20%)] Loss: -1392.854248\n",
      "Train Epoch: 1923 [23040/60000 (38%)] Loss: -1274.482788\n",
      "Train Epoch: 1923 [34304/60000 (57%)] Loss: -1517.198120\n",
      "Train Epoch: 1923 [45568/60000 (76%)] Loss: -1223.623413\n",
      "Train Epoch: 1923 [56832/60000 (95%)] Loss: -1412.279541\n",
      "    epoch          : 1923\n",
      "    loss           : -1349.8797510869085\n",
      "Train Epoch: 1924 [512/60000 (1%)] Loss: -1523.859497\n",
      "Train Epoch: 1924 [11776/60000 (20%)] Loss: -1403.036011\n",
      "Train Epoch: 1924 [23040/60000 (38%)] Loss: -1381.703613\n",
      "Train Epoch: 1924 [34304/60000 (57%)] Loss: -1339.546875\n",
      "Train Epoch: 1924 [45568/60000 (76%)] Loss: -1527.916260\n",
      "Train Epoch: 1924 [56832/60000 (95%)] Loss: -1519.267578\n",
      "    epoch          : 1924\n",
      "    loss           : -1364.1746236510196\n",
      "Train Epoch: 1925 [512/60000 (1%)] Loss: -1420.949707\n",
      "Train Epoch: 1925 [11776/60000 (20%)] Loss: -1349.297363\n",
      "Train Epoch: 1925 [23040/60000 (38%)] Loss: -1546.846680\n",
      "Train Epoch: 1925 [34304/60000 (57%)] Loss: -1362.775879\n",
      "Train Epoch: 1925 [45568/60000 (76%)] Loss: -1535.275269\n",
      "Train Epoch: 1925 [56832/60000 (95%)] Loss: -1537.897461\n",
      "    epoch          : 1925\n",
      "    loss           : -1366.4712138202906\n",
      "Train Epoch: 1926 [512/60000 (1%)] Loss: -1538.808105\n",
      "Train Epoch: 1926 [11776/60000 (20%)] Loss: -1518.437500\n",
      "Train Epoch: 1926 [23040/60000 (38%)] Loss: -1262.183105\n",
      "Train Epoch: 1926 [34304/60000 (57%)] Loss: -1379.314697\n",
      "Train Epoch: 1926 [45568/60000 (76%)] Loss: -1370.999878\n",
      "Train Epoch: 1926 [56832/60000 (95%)] Loss: -1498.120117\n",
      "    epoch          : 1926\n",
      "    loss           : -1369.1005936962063\n",
      "Train Epoch: 1927 [512/60000 (1%)] Loss: -1399.259033\n",
      "Train Epoch: 1927 [11776/60000 (20%)] Loss: -1419.944336\n",
      "Train Epoch: 1927 [23040/60000 (38%)] Loss: -1521.292969\n",
      "Train Epoch: 1927 [34304/60000 (57%)] Loss: -1408.465576\n",
      "Train Epoch: 1927 [45568/60000 (76%)] Loss: -1217.155640\n",
      "Train Epoch: 1927 [56832/60000 (95%)] Loss: -1380.095947\n",
      "    epoch          : 1927\n",
      "    loss           : -1347.9889478090793\n",
      "Train Epoch: 1928 [512/60000 (1%)] Loss: -1382.799194\n",
      "Train Epoch: 1928 [11776/60000 (20%)] Loss: -1243.085449\n",
      "Train Epoch: 1928 [23040/60000 (38%)] Loss: -1246.806152\n",
      "Train Epoch: 1928 [34304/60000 (57%)] Loss: -1566.183594\n",
      "Train Epoch: 1928 [45568/60000 (76%)] Loss: -1383.852539\n",
      "Train Epoch: 1928 [56832/60000 (95%)] Loss: -1377.188232\n",
      "    epoch          : 1928\n",
      "    loss           : -1360.8003755558682\n",
      "Train Epoch: 1929 [512/60000 (1%)] Loss: -1366.850342\n",
      "Train Epoch: 1929 [11776/60000 (20%)] Loss: -1409.621826\n",
      "Train Epoch: 1929 [23040/60000 (38%)] Loss: -1379.764282\n",
      "Train Epoch: 1929 [34304/60000 (57%)] Loss: -1239.449341\n",
      "Train Epoch: 1929 [45568/60000 (76%)] Loss: -1422.106445\n",
      "Train Epoch: 1929 [56832/60000 (95%)] Loss: -1257.348633\n",
      "    epoch          : 1929\n",
      "    loss           : -1361.8253356588764\n",
      "Train Epoch: 1930 [512/60000 (1%)] Loss: -1263.061646\n",
      "Train Epoch: 1930 [11776/60000 (20%)] Loss: -1260.082886\n",
      "Train Epoch: 1930 [23040/60000 (38%)] Loss: -1253.351562\n",
      "Train Epoch: 1930 [34304/60000 (57%)] Loss: -1232.693481\n",
      "Train Epoch: 1930 [45568/60000 (76%)] Loss: -1233.886841\n",
      "Train Epoch: 1930 [56832/60000 (95%)] Loss: -1541.532104\n",
      "    epoch          : 1930\n",
      "    loss           : -1370.4490009889764\n",
      "Train Epoch: 1931 [512/60000 (1%)] Loss: -1482.673584\n",
      "Train Epoch: 1931 [11776/60000 (20%)] Loss: -1231.829712\n",
      "Train Epoch: 1931 [23040/60000 (38%)] Loss: -1221.709839\n",
      "Train Epoch: 1931 [34304/60000 (57%)] Loss: -1266.685303\n",
      "Train Epoch: 1931 [45568/60000 (76%)] Loss: -1490.306396\n",
      "Train Epoch: 1931 [56832/60000 (95%)] Loss: -1243.537842\n",
      "    epoch          : 1931\n",
      "    loss           : -1373.2006722143142\n",
      "Train Epoch: 1932 [512/60000 (1%)] Loss: -1374.394409\n",
      "Train Epoch: 1932 [11776/60000 (20%)] Loss: -1271.157837\n",
      "Train Epoch: 1932 [23040/60000 (38%)] Loss: -1248.892090\n",
      "Train Epoch: 1932 [34304/60000 (57%)] Loss: -1388.705933\n",
      "Train Epoch: 1932 [45568/60000 (76%)] Loss: -1491.723022\n",
      "Train Epoch: 1932 [56832/60000 (95%)] Loss: -1256.007446\n",
      "    epoch          : 1932\n",
      "    loss           : -1363.4294312902762\n",
      "Train Epoch: 1933 [512/60000 (1%)] Loss: -1264.477783\n",
      "Train Epoch: 1933 [11776/60000 (20%)] Loss: -1522.259399\n",
      "Train Epoch: 1933 [23040/60000 (38%)] Loss: -1512.834595\n",
      "Train Epoch: 1933 [34304/60000 (57%)] Loss: -969.078918\n",
      "Train Epoch: 1933 [45568/60000 (76%)] Loss: -1388.700562\n",
      "Train Epoch: 1933 [56832/60000 (95%)] Loss: -1288.187256\n",
      "    epoch          : 1933\n",
      "    loss           : -1373.9628032102423\n",
      "Train Epoch: 1934 [512/60000 (1%)] Loss: -1344.704834\n",
      "Train Epoch: 1934 [11776/60000 (20%)] Loss: -1402.919067\n",
      "Train Epoch: 1934 [23040/60000 (38%)] Loss: -1106.364014\n",
      "Train Epoch: 1934 [34304/60000 (57%)] Loss: -1545.562988\n",
      "Train Epoch: 1934 [45568/60000 (76%)] Loss: -1401.174194\n",
      "Train Epoch: 1934 [56832/60000 (95%)] Loss: -1566.017578\n",
      "    epoch          : 1934\n",
      "    loss           : -1361.1852885962878\n",
      "Train Epoch: 1935 [512/60000 (1%)] Loss: -1104.761108\n",
      "Train Epoch: 1935 [11776/60000 (20%)] Loss: -1273.567749\n",
      "Train Epoch: 1935 [23040/60000 (38%)] Loss: -1528.771484\n",
      "Train Epoch: 1935 [34304/60000 (57%)] Loss: -1216.354858\n",
      "Train Epoch: 1935 [45568/60000 (76%)] Loss: -1086.544067\n",
      "Train Epoch: 1935 [56832/60000 (95%)] Loss: -1510.960449\n",
      "    epoch          : 1935\n",
      "    loss           : -1361.4567433157883\n",
      "Train Epoch: 1936 [512/60000 (1%)] Loss: -1383.353271\n",
      "Train Epoch: 1936 [11776/60000 (20%)] Loss: -1542.400146\n",
      "Train Epoch: 1936 [23040/60000 (38%)] Loss: -1213.173340\n",
      "Train Epoch: 1936 [34304/60000 (57%)] Loss: -1407.686279\n",
      "Train Epoch: 1936 [45568/60000 (76%)] Loss: -1112.244751\n",
      "Train Epoch: 1936 [56832/60000 (95%)] Loss: -1407.595947\n",
      "    epoch          : 1936\n",
      "    loss           : -1358.608486197089\n",
      "Train Epoch: 1937 [512/60000 (1%)] Loss: -1362.973633\n",
      "Train Epoch: 1937 [11776/60000 (20%)] Loss: -1136.508301\n",
      "Train Epoch: 1937 [23040/60000 (38%)] Loss: -1371.474731\n",
      "Train Epoch: 1937 [34304/60000 (57%)] Loss: -1132.122559\n",
      "Train Epoch: 1937 [45568/60000 (76%)] Loss: -1502.916260\n",
      "Train Epoch: 1937 [56832/60000 (95%)] Loss: -1409.471558\n",
      "    epoch          : 1937\n",
      "    loss           : -1357.5934675830906\n",
      "Train Epoch: 1938 [512/60000 (1%)] Loss: -1283.216064\n",
      "Train Epoch: 1938 [11776/60000 (20%)] Loss: -1406.325317\n",
      "Train Epoch: 1938 [23040/60000 (38%)] Loss: -1501.148071\n",
      "Train Epoch: 1938 [34304/60000 (57%)] Loss: -1427.560303\n",
      "Train Epoch: 1938 [45568/60000 (76%)] Loss: -1392.215454\n",
      "Train Epoch: 1938 [56832/60000 (95%)] Loss: -1507.687012\n",
      "    epoch          : 1938\n",
      "    loss           : -1353.3251677259886\n",
      "Train Epoch: 1939 [512/60000 (1%)] Loss: -1490.210205\n",
      "Train Epoch: 1939 [11776/60000 (20%)] Loss: -1538.517822\n",
      "Train Epoch: 1939 [23040/60000 (38%)] Loss: -1507.705322\n",
      "Train Epoch: 1939 [34304/60000 (57%)] Loss: -1392.904053\n",
      "Train Epoch: 1939 [45568/60000 (76%)] Loss: -1524.906250\n",
      "Train Epoch: 1939 [56832/60000 (95%)] Loss: -1385.289429\n",
      "    epoch          : 1939\n",
      "    loss           : -1387.8935869292352\n",
      "Train Epoch: 1940 [512/60000 (1%)] Loss: -1551.050049\n",
      "Train Epoch: 1940 [11776/60000 (20%)] Loss: -1229.173218\n",
      "Train Epoch: 1940 [23040/60000 (38%)] Loss: -1268.370361\n",
      "Train Epoch: 1940 [34304/60000 (57%)] Loss: -1541.163330\n",
      "Train Epoch: 1940 [45568/60000 (76%)] Loss: -1517.219238\n",
      "Train Epoch: 1940 [56832/60000 (95%)] Loss: -1278.220947\n",
      "    epoch          : 1940\n",
      "    loss           : -1340.3179948882196\n",
      "Train Epoch: 1941 [512/60000 (1%)] Loss: -1367.632690\n",
      "Train Epoch: 1941 [11776/60000 (20%)] Loss: -1412.442505\n",
      "Train Epoch: 1941 [23040/60000 (38%)] Loss: -1408.271240\n",
      "Train Epoch: 1941 [34304/60000 (57%)] Loss: -1386.546509\n",
      "Train Epoch: 1941 [45568/60000 (76%)] Loss: -1232.918213\n",
      "Train Epoch: 1941 [56832/60000 (95%)] Loss: -1508.092285\n",
      "    epoch          : 1941\n",
      "    loss           : -1344.8335841981705\n",
      "Train Epoch: 1942 [512/60000 (1%)] Loss: -1553.753784\n",
      "Train Epoch: 1942 [11776/60000 (20%)] Loss: -1227.432983\n",
      "Train Epoch: 1942 [23040/60000 (38%)] Loss: -1112.752930\n",
      "Train Epoch: 1942 [34304/60000 (57%)] Loss: -1227.104980\n",
      "Train Epoch: 1942 [45568/60000 (76%)] Loss: -1238.655518\n",
      "Train Epoch: 1942 [56832/60000 (95%)] Loss: -1299.577026\n",
      "    epoch          : 1942\n",
      "    loss           : -1348.0273297843287\n",
      "Train Epoch: 1943 [512/60000 (1%)] Loss: -1267.494385\n",
      "Train Epoch: 1943 [11776/60000 (20%)] Loss: -1283.500366\n",
      "Train Epoch: 1943 [23040/60000 (38%)] Loss: -1253.236572\n",
      "Train Epoch: 1943 [34304/60000 (57%)] Loss: -1367.975098\n",
      "Train Epoch: 1943 [45568/60000 (76%)] Loss: -1392.025757\n",
      "Train Epoch: 1943 [56832/60000 (95%)] Loss: -1404.366089\n",
      "    epoch          : 1943\n",
      "    loss           : -1348.874064127604\n",
      "Train Epoch: 1944 [512/60000 (1%)] Loss: -1523.461914\n",
      "Train Epoch: 1944 [11776/60000 (20%)] Loss: -1495.203125\n",
      "Train Epoch: 1944 [23040/60000 (38%)] Loss: -1350.223755\n",
      "Train Epoch: 1944 [34304/60000 (57%)] Loss: -1387.785767\n",
      "Train Epoch: 1944 [45568/60000 (76%)] Loss: -1432.202515\n",
      "Train Epoch: 1944 [56832/60000 (95%)] Loss: -1402.387939\n",
      "    epoch          : 1944\n",
      "    loss           : -1367.1477019746426\n",
      "Train Epoch: 1945 [512/60000 (1%)] Loss: -968.185120\n",
      "Train Epoch: 1945 [11776/60000 (20%)] Loss: -1391.352539\n",
      "Train Epoch: 1945 [23040/60000 (38%)] Loss: -1358.836182\n",
      "Train Epoch: 1945 [34304/60000 (57%)] Loss: -1414.156006\n",
      "Train Epoch: 1945 [45568/60000 (76%)] Loss: -1256.606934\n",
      "Train Epoch: 1945 [56832/60000 (95%)] Loss: -1262.199585\n",
      "    epoch          : 1945\n",
      "    loss           : -1338.5427530579648\n",
      "Train Epoch: 1946 [512/60000 (1%)] Loss: -1380.007568\n",
      "Train Epoch: 1946 [11776/60000 (20%)] Loss: -1391.583130\n",
      "Train Epoch: 1946 [23040/60000 (38%)] Loss: -1397.329712\n",
      "Train Epoch: 1946 [34304/60000 (57%)] Loss: -1502.710938\n",
      "Train Epoch: 1946 [45568/60000 (76%)] Loss: -1362.270020\n",
      "Train Epoch: 1946 [56832/60000 (95%)] Loss: -1226.261230\n",
      "    epoch          : 1946\n",
      "    loss           : -1358.9786076949815\n",
      "Train Epoch: 1947 [512/60000 (1%)] Loss: -1253.972534\n",
      "Train Epoch: 1947 [11776/60000 (20%)] Loss: -1206.713379\n",
      "Train Epoch: 1947 [23040/60000 (38%)] Loss: -1394.823853\n",
      "Train Epoch: 1947 [34304/60000 (57%)] Loss: -1387.998779\n",
      "Train Epoch: 1947 [45568/60000 (76%)] Loss: -1389.357300\n",
      "Train Epoch: 1947 [56832/60000 (95%)] Loss: -1515.826416\n",
      "    epoch          : 1947\n",
      "    loss           : -1372.6239975751457\n",
      "Train Epoch: 1948 [512/60000 (1%)] Loss: -1540.769287\n",
      "Train Epoch: 1948 [11776/60000 (20%)] Loss: -1243.907471\n",
      "Train Epoch: 1948 [23040/60000 (38%)] Loss: -1089.397827\n",
      "Train Epoch: 1948 [34304/60000 (57%)] Loss: -1415.846924\n",
      "Train Epoch: 1948 [45568/60000 (76%)] Loss: -1267.410156\n",
      "Train Epoch: 1948 [56832/60000 (95%)] Loss: -1348.769531\n",
      "    epoch          : 1948\n",
      "    loss           : -1347.8801717812057\n",
      "Train Epoch: 1949 [512/60000 (1%)] Loss: -1394.355713\n",
      "Train Epoch: 1949 [11776/60000 (20%)] Loss: -1381.198120\n",
      "Train Epoch: 1949 [23040/60000 (38%)] Loss: -960.112305\n",
      "Train Epoch: 1949 [34304/60000 (57%)] Loss: -1546.924561\n",
      "Train Epoch: 1949 [45568/60000 (76%)] Loss: -1240.296509\n",
      "Train Epoch: 1949 [56832/60000 (95%)] Loss: -1366.684692\n",
      "    epoch          : 1949\n",
      "    loss           : -1337.2194582836778\n",
      "Train Epoch: 1950 [512/60000 (1%)] Loss: -1508.120117\n",
      "Train Epoch: 1950 [11776/60000 (20%)] Loss: -1553.951172\n",
      "Train Epoch: 1950 [23040/60000 (38%)] Loss: -1107.925903\n",
      "Train Epoch: 1950 [34304/60000 (57%)] Loss: -1263.105957\n",
      "Train Epoch: 1950 [45568/60000 (76%)] Loss: -1128.778564\n",
      "Train Epoch: 1950 [56832/60000 (95%)] Loss: -1415.825195\n",
      "    epoch          : 1950\n",
      "    loss           : -1350.1188518287097\n",
      "Train Epoch: 1951 [512/60000 (1%)] Loss: -1519.876953\n",
      "Train Epoch: 1951 [11776/60000 (20%)] Loss: -1427.969727\n",
      "Train Epoch: 1951 [23040/60000 (38%)] Loss: -1552.100952\n",
      "Train Epoch: 1951 [34304/60000 (57%)] Loss: -1399.963867\n",
      "Train Epoch: 1951 [45568/60000 (76%)] Loss: -1369.327515\n",
      "Train Epoch: 1951 [56832/60000 (95%)] Loss: -1526.941406\n",
      "    epoch          : 1951\n",
      "    loss           : -1361.301799192267\n",
      "Train Epoch: 1952 [512/60000 (1%)] Loss: -1500.726074\n",
      "Train Epoch: 1952 [11776/60000 (20%)] Loss: -1372.841309\n",
      "Train Epoch: 1952 [23040/60000 (38%)] Loss: -1524.337402\n",
      "Train Epoch: 1952 [34304/60000 (57%)] Loss: -1535.304077\n",
      "Train Epoch: 1952 [45568/60000 (76%)] Loss: -1389.812866\n",
      "Train Epoch: 1952 [56832/60000 (95%)] Loss: -1413.958496\n",
      "    epoch          : 1952\n",
      "    loss           : -1364.1569072486316\n",
      "Train Epoch: 1953 [512/60000 (1%)] Loss: -1361.177979\n",
      "Train Epoch: 1953 [11776/60000 (20%)] Loss: -1127.923706\n",
      "Train Epoch: 1953 [23040/60000 (38%)] Loss: -1400.809082\n",
      "Train Epoch: 1953 [34304/60000 (57%)] Loss: -1415.138672\n",
      "Train Epoch: 1953 [45568/60000 (76%)] Loss: -1210.725586\n",
      "Train Epoch: 1953 [56832/60000 (95%)] Loss: -1222.680054\n",
      "    epoch          : 1953\n",
      "    loss           : -1355.0127668650139\n",
      "Train Epoch: 1954 [512/60000 (1%)] Loss: -1281.007080\n",
      "Train Epoch: 1954 [11776/60000 (20%)] Loss: -1401.541626\n",
      "Train Epoch: 1954 [23040/60000 (38%)] Loss: -1281.755127\n",
      "Train Epoch: 1954 [34304/60000 (57%)] Loss: -1385.894531\n",
      "Train Epoch: 1954 [45568/60000 (76%)] Loss: -1389.026978\n",
      "Train Epoch: 1954 [56832/60000 (95%)] Loss: -1359.119873\n",
      "    epoch          : 1954\n",
      "    loss           : -1364.6439396917483\n",
      "Train Epoch: 1955 [512/60000 (1%)] Loss: -1523.972900\n",
      "Train Epoch: 1955 [11776/60000 (20%)] Loss: -1365.649536\n",
      "Train Epoch: 1955 [23040/60000 (38%)] Loss: -1381.958618\n",
      "Train Epoch: 1955 [34304/60000 (57%)] Loss: -1266.334717\n",
      "Train Epoch: 1955 [45568/60000 (76%)] Loss: -1510.813721\n",
      "Train Epoch: 1955 [56832/60000 (95%)] Loss: -1105.508545\n",
      "    epoch          : 1955\n",
      "    loss           : -1377.692050395039\n",
      "Train Epoch: 1956 [512/60000 (1%)] Loss: -1391.666260\n",
      "Train Epoch: 1956 [11776/60000 (20%)] Loss: -1381.198242\n",
      "Train Epoch: 1956 [23040/60000 (38%)] Loss: -1535.211914\n",
      "Train Epoch: 1956 [34304/60000 (57%)] Loss: -1513.973755\n",
      "Train Epoch: 1956 [45568/60000 (76%)] Loss: -1392.918213\n",
      "Train Epoch: 1956 [56832/60000 (95%)] Loss: -1505.461304\n",
      "    epoch          : 1956\n",
      "    loss           : -1376.7610187422756\n",
      "Train Epoch: 1957 [512/60000 (1%)] Loss: -1269.761475\n",
      "Train Epoch: 1957 [11776/60000 (20%)] Loss: -1538.838745\n",
      "Train Epoch: 1957 [23040/60000 (38%)] Loss: -1383.651245\n",
      "Train Epoch: 1957 [34304/60000 (57%)] Loss: -1124.426514\n",
      "Train Epoch: 1957 [45568/60000 (76%)] Loss: -1369.520142\n",
      "Train Epoch: 1957 [56832/60000 (95%)] Loss: -1500.552979\n",
      "    epoch          : 1957\n",
      "    loss           : -1365.5383976650776\n",
      "Train Epoch: 1958 [512/60000 (1%)] Loss: -1353.992798\n",
      "Train Epoch: 1958 [11776/60000 (20%)] Loss: -1237.599976\n",
      "Train Epoch: 1958 [23040/60000 (38%)] Loss: -1238.000000\n",
      "Train Epoch: 1958 [34304/60000 (57%)] Loss: -1547.750732\n",
      "Train Epoch: 1958 [45568/60000 (76%)] Loss: -1552.922363\n",
      "Train Epoch: 1958 [56832/60000 (95%)] Loss: -1133.456421\n",
      "    epoch          : 1958\n",
      "    loss           : -1353.892585538875\n",
      "Train Epoch: 1959 [512/60000 (1%)] Loss: -1475.864502\n",
      "Train Epoch: 1959 [11776/60000 (20%)] Loss: -1540.394653\n",
      "Train Epoch: 1959 [23040/60000 (38%)] Loss: -1249.062744\n",
      "Train Epoch: 1959 [34304/60000 (57%)] Loss: -1417.973633\n",
      "Train Epoch: 1959 [45568/60000 (76%)] Loss: -1412.470703\n",
      "Train Epoch: 1959 [56832/60000 (95%)] Loss: -1515.527832\n",
      "    epoch          : 1959\n",
      "    loss           : -1363.1810728601145\n",
      "Train Epoch: 1960 [512/60000 (1%)] Loss: -1257.567383\n",
      "Train Epoch: 1960 [11776/60000 (20%)] Loss: -1394.993774\n",
      "Train Epoch: 1960 [23040/60000 (38%)] Loss: -1383.292358\n",
      "Train Epoch: 1960 [34304/60000 (57%)] Loss: -1240.985962\n",
      "Train Epoch: 1960 [45568/60000 (76%)] Loss: -1240.866943\n",
      "Train Epoch: 1960 [56832/60000 (95%)] Loss: -1551.990723\n",
      "    epoch          : 1960\n",
      "    loss           : -1347.2397926459878\n",
      "Train Epoch: 1961 [512/60000 (1%)] Loss: -1378.518311\n",
      "Train Epoch: 1961 [11776/60000 (20%)] Loss: -1390.157959\n",
      "Train Epoch: 1961 [23040/60000 (38%)] Loss: -1353.551392\n",
      "Train Epoch: 1961 [34304/60000 (57%)] Loss: -1404.592529\n",
      "Train Epoch: 1961 [45568/60000 (76%)] Loss: -1256.069702\n",
      "Train Epoch: 1961 [56832/60000 (95%)] Loss: -1240.306763\n",
      "    epoch          : 1961\n",
      "    loss           : -1361.276377877273\n",
      "Train Epoch: 1962 [512/60000 (1%)] Loss: -1272.412720\n",
      "Train Epoch: 1962 [11776/60000 (20%)] Loss: -1382.183594\n",
      "Train Epoch: 1962 [23040/60000 (38%)] Loss: -1257.210449\n",
      "Train Epoch: 1962 [34304/60000 (57%)] Loss: -1366.029053\n",
      "Train Epoch: 1962 [45568/60000 (76%)] Loss: -1501.697266\n",
      "Train Epoch: 1962 [56832/60000 (95%)] Loss: -1255.552856\n",
      "    epoch          : 1962\n",
      "    loss           : -1367.5847092105844\n",
      "Train Epoch: 1963 [512/60000 (1%)] Loss: -1369.709961\n",
      "Train Epoch: 1963 [11776/60000 (20%)] Loss: -1493.766846\n",
      "Train Epoch: 1963 [23040/60000 (38%)] Loss: -1407.827881\n",
      "Train Epoch: 1963 [34304/60000 (57%)] Loss: -1388.233643\n",
      "Train Epoch: 1963 [45568/60000 (76%)] Loss: -1476.017944\n",
      "Train Epoch: 1963 [56832/60000 (95%)] Loss: -1399.873413\n",
      "    epoch          : 1963\n",
      "    loss           : -1379.539275950631\n",
      "Train Epoch: 1964 [512/60000 (1%)] Loss: -1366.347290\n",
      "Train Epoch: 1964 [11776/60000 (20%)] Loss: -1376.115479\n",
      "Train Epoch: 1964 [23040/60000 (38%)] Loss: -1272.738770\n",
      "Train Epoch: 1964 [34304/60000 (57%)] Loss: -1394.330078\n",
      "Train Epoch: 1964 [45568/60000 (76%)] Loss: -1406.019531\n",
      "Train Epoch: 1964 [56832/60000 (95%)] Loss: -1371.978638\n",
      "    epoch          : 1964\n",
      "    loss           : -1370.3439137949108\n",
      "Train Epoch: 1965 [512/60000 (1%)] Loss: -1259.967285\n",
      "Train Epoch: 1965 [11776/60000 (20%)] Loss: -1533.758545\n",
      "Train Epoch: 1965 [23040/60000 (38%)] Loss: -1500.370483\n",
      "Train Epoch: 1965 [34304/60000 (57%)] Loss: -1419.913086\n",
      "Train Epoch: 1965 [45568/60000 (76%)] Loss: -1404.731323\n",
      "Train Epoch: 1965 [56832/60000 (95%)] Loss: -1495.349854\n",
      "    epoch          : 1965\n",
      "    loss           : -1375.2761120122705\n",
      "Train Epoch: 1966 [512/60000 (1%)] Loss: -1233.938721\n",
      "Train Epoch: 1966 [11776/60000 (20%)] Loss: -1404.644775\n",
      "Train Epoch: 1966 [23040/60000 (38%)] Loss: -1247.430786\n",
      "Train Epoch: 1966 [34304/60000 (57%)] Loss: -1540.130127\n",
      "Train Epoch: 1966 [45568/60000 (76%)] Loss: -1211.208740\n",
      "Train Epoch: 1966 [56832/60000 (95%)] Loss: -1257.492676\n",
      "    epoch          : 1966\n",
      "    loss           : -1345.9225994907529\n",
      "Train Epoch: 1967 [512/60000 (1%)] Loss: -1490.009521\n",
      "Train Epoch: 1967 [11776/60000 (20%)] Loss: -1222.686523\n",
      "Train Epoch: 1967 [23040/60000 (38%)] Loss: -1541.039307\n",
      "Train Epoch: 1967 [34304/60000 (57%)] Loss: -1265.113403\n",
      "Train Epoch: 1967 [45568/60000 (76%)] Loss: -1257.883911\n",
      "Train Epoch: 1967 [56832/60000 (95%)] Loss: -1523.137085\n",
      "    epoch          : 1967\n",
      "    loss           : -1367.84418379789\n",
      "Train Epoch: 1968 [512/60000 (1%)] Loss: -1507.401733\n",
      "Train Epoch: 1968 [11776/60000 (20%)] Loss: -1373.480225\n",
      "Train Epoch: 1968 [23040/60000 (38%)] Loss: -1506.749268\n",
      "Train Epoch: 1968 [34304/60000 (57%)] Loss: -1585.213135\n",
      "Train Epoch: 1968 [45568/60000 (76%)] Loss: -1392.701538\n",
      "Train Epoch: 1968 [56832/60000 (95%)] Loss: -1211.366699\n",
      "    epoch          : 1968\n",
      "    loss           : -1370.2669208763684\n",
      "Train Epoch: 1969 [512/60000 (1%)] Loss: -1260.403809\n",
      "Train Epoch: 1969 [11776/60000 (20%)] Loss: -971.828857\n",
      "Train Epoch: 1969 [23040/60000 (38%)] Loss: -1235.488892\n",
      "Train Epoch: 1969 [34304/60000 (57%)] Loss: -1407.977417\n",
      "Train Epoch: 1969 [45568/60000 (76%)] Loss: -1514.810303\n",
      "Train Epoch: 1969 [56832/60000 (95%)] Loss: -1364.738037\n",
      "    epoch          : 1969\n",
      "    loss           : -1358.0279306530279\n",
      "Train Epoch: 1970 [512/60000 (1%)] Loss: -1234.562744\n",
      "Train Epoch: 1970 [11776/60000 (20%)] Loss: -1397.345459\n",
      "Train Epoch: 1970 [23040/60000 (38%)] Loss: -1247.441895\n",
      "Train Epoch: 1970 [34304/60000 (57%)] Loss: -1491.097412\n",
      "Train Epoch: 1970 [45568/60000 (76%)] Loss: -1389.488647\n",
      "Train Epoch: 1970 [56832/60000 (95%)] Loss: -1533.282227\n",
      "    epoch          : 1970\n",
      "    loss           : -1351.556872351695\n",
      "Train Epoch: 1971 [512/60000 (1%)] Loss: -1391.521973\n",
      "Train Epoch: 1971 [11776/60000 (20%)] Loss: -1216.899292\n",
      "Train Epoch: 1971 [23040/60000 (38%)] Loss: -1401.542358\n",
      "Train Epoch: 1971 [34304/60000 (57%)] Loss: -1371.340088\n",
      "Train Epoch: 1971 [45568/60000 (76%)] Loss: -1401.390137\n",
      "Train Epoch: 1971 [56832/60000 (95%)] Loss: -1220.342407\n",
      "    epoch          : 1971\n",
      "    loss           : -1344.96942173155\n",
      "Train Epoch: 1972 [512/60000 (1%)] Loss: -1398.004395\n",
      "Train Epoch: 1972 [11776/60000 (20%)] Loss: -1138.654419\n",
      "Train Epoch: 1972 [23040/60000 (38%)] Loss: -1251.499512\n",
      "Train Epoch: 1972 [34304/60000 (57%)] Loss: -1367.656006\n",
      "Train Epoch: 1972 [45568/60000 (76%)] Loss: -1371.108032\n",
      "Train Epoch: 1972 [56832/60000 (95%)] Loss: -1275.804443\n",
      "    epoch          : 1972\n",
      "    loss           : -1352.0972741768185\n",
      "Train Epoch: 1973 [512/60000 (1%)] Loss: -1252.086060\n",
      "Train Epoch: 1973 [11776/60000 (20%)] Loss: -1228.469849\n",
      "Train Epoch: 1973 [23040/60000 (38%)] Loss: -1519.210327\n",
      "Train Epoch: 1973 [34304/60000 (57%)] Loss: -1250.242554\n",
      "Train Epoch: 1973 [45568/60000 (76%)] Loss: -1536.336792\n",
      "Train Epoch: 1973 [56832/60000 (95%)] Loss: -1094.403687\n",
      "    epoch          : 1973\n",
      "    loss           : -1343.7678122655145\n",
      "Train Epoch: 1974 [512/60000 (1%)] Loss: -1398.334229\n",
      "Train Epoch: 1974 [11776/60000 (20%)] Loss: -1403.858765\n",
      "Train Epoch: 1974 [23040/60000 (38%)] Loss: -1084.614014\n",
      "Train Epoch: 1974 [34304/60000 (57%)] Loss: -1403.287842\n",
      "Train Epoch: 1974 [45568/60000 (76%)] Loss: -1101.937256\n",
      "Train Epoch: 1974 [56832/60000 (95%)] Loss: -1403.943848\n",
      "    epoch          : 1974\n",
      "    loss           : -1362.5582251252429\n",
      "Train Epoch: 1975 [512/60000 (1%)] Loss: -1225.568115\n",
      "Train Epoch: 1975 [11776/60000 (20%)] Loss: -1413.515503\n",
      "Train Epoch: 1975 [23040/60000 (38%)] Loss: -1358.285522\n",
      "Train Epoch: 1975 [34304/60000 (57%)] Loss: -1246.186768\n",
      "Train Epoch: 1975 [45568/60000 (76%)] Loss: -1275.286377\n",
      "Train Epoch: 1975 [56832/60000 (95%)] Loss: -1254.515747\n",
      "    epoch          : 1975\n",
      "    loss           : -1348.9900716145835\n",
      "Train Epoch: 1976 [512/60000 (1%)] Loss: -1405.271729\n",
      "Train Epoch: 1976 [11776/60000 (20%)] Loss: -1240.268921\n",
      "Train Epoch: 1976 [23040/60000 (38%)] Loss: -1366.519775\n",
      "Train Epoch: 1976 [34304/60000 (57%)] Loss: -1234.134033\n",
      "Train Epoch: 1976 [45568/60000 (76%)] Loss: -1276.930786\n",
      "Train Epoch: 1976 [56832/60000 (95%)] Loss: -1402.863159\n",
      "    epoch          : 1976\n",
      "    loss           : -1356.410369700631\n",
      "Train Epoch: 1977 [512/60000 (1%)] Loss: -1126.086304\n",
      "Train Epoch: 1977 [11776/60000 (20%)] Loss: -1399.138184\n",
      "Train Epoch: 1977 [23040/60000 (38%)] Loss: -1387.210327\n",
      "Train Epoch: 1977 [34304/60000 (57%)] Loss: -1388.939453\n",
      "Train Epoch: 1977 [45568/60000 (76%)] Loss: -1114.457275\n",
      "Train Epoch: 1977 [56832/60000 (95%)] Loss: -1525.961792\n",
      "    epoch          : 1977\n",
      "    loss           : -1343.8576289462505\n",
      "Train Epoch: 1978 [512/60000 (1%)] Loss: -1541.487915\n",
      "Train Epoch: 1978 [11776/60000 (20%)] Loss: -1238.709351\n",
      "Train Epoch: 1978 [23040/60000 (38%)] Loss: -1528.379272\n",
      "Train Epoch: 1978 [34304/60000 (57%)] Loss: -1241.153809\n",
      "Train Epoch: 1978 [45568/60000 (76%)] Loss: -1375.135132\n",
      "Train Epoch: 1978 [56832/60000 (95%)] Loss: -1251.229126\n",
      "    epoch          : 1978\n",
      "    loss           : -1335.522699388407\n",
      "Train Epoch: 1979 [512/60000 (1%)] Loss: -1352.070923\n",
      "Train Epoch: 1979 [11776/60000 (20%)] Loss: -1394.157959\n",
      "Train Epoch: 1979 [23040/60000 (38%)] Loss: -1426.039795\n",
      "Train Epoch: 1979 [34304/60000 (57%)] Loss: -1400.396118\n",
      "Train Epoch: 1979 [45568/60000 (76%)] Loss: -1515.660156\n",
      "Train Epoch: 1979 [56832/60000 (95%)] Loss: -1411.278442\n",
      "    epoch          : 1979\n",
      "    loss           : -1366.926989539195\n",
      "Train Epoch: 1980 [512/60000 (1%)] Loss: -1355.803345\n",
      "Train Epoch: 1980 [11776/60000 (20%)] Loss: -1132.397583\n",
      "Train Epoch: 1980 [23040/60000 (38%)] Loss: -1531.302246\n",
      "Train Epoch: 1980 [34304/60000 (57%)] Loss: -1515.919800\n",
      "Train Epoch: 1980 [45568/60000 (76%)] Loss: -1380.705933\n",
      "Train Epoch: 1980 [56832/60000 (95%)] Loss: -1250.224121\n",
      "    epoch          : 1980\n",
      "    loss           : -1355.860725876975\n",
      "Train Epoch: 1981 [512/60000 (1%)] Loss: -1113.907837\n",
      "Train Epoch: 1981 [11776/60000 (20%)] Loss: -1393.913208\n",
      "Train Epoch: 1981 [23040/60000 (38%)] Loss: -1279.239624\n",
      "Train Epoch: 1981 [34304/60000 (57%)] Loss: -1369.779785\n",
      "Train Epoch: 1981 [45568/60000 (76%)] Loss: -1399.916260\n",
      "Train Epoch: 1981 [56832/60000 (95%)] Loss: -1245.447510\n",
      "    epoch          : 1981\n",
      "    loss           : -1372.7547438454494\n",
      "Train Epoch: 1982 [512/60000 (1%)] Loss: -1263.776855\n",
      "Train Epoch: 1982 [11776/60000 (20%)] Loss: -1397.367310\n",
      "Train Epoch: 1982 [23040/60000 (38%)] Loss: -1279.193115\n",
      "Train Epoch: 1982 [34304/60000 (57%)] Loss: -1509.602173\n",
      "Train Epoch: 1982 [45568/60000 (76%)] Loss: -1399.226807\n",
      "Train Epoch: 1982 [56832/60000 (95%)] Loss: -1394.242432\n",
      "    epoch          : 1982\n",
      "    loss           : -1352.465718242408\n",
      "Train Epoch: 1983 [512/60000 (1%)] Loss: -1546.186035\n",
      "Train Epoch: 1983 [11776/60000 (20%)] Loss: -1264.481689\n",
      "Train Epoch: 1983 [23040/60000 (38%)] Loss: -1368.525757\n",
      "Train Epoch: 1983 [34304/60000 (57%)] Loss: -1387.826416\n",
      "Train Epoch: 1983 [45568/60000 (76%)] Loss: -1389.721436\n",
      "Train Epoch: 1983 [56832/60000 (95%)] Loss: -1104.787720\n",
      "    epoch          : 1983\n",
      "    loss           : -1360.2614359882593\n",
      "Train Epoch: 1984 [512/60000 (1%)] Loss: -1517.029785\n",
      "Train Epoch: 1984 [11776/60000 (20%)] Loss: -1372.472900\n",
      "Train Epoch: 1984 [23040/60000 (38%)] Loss: -1405.457764\n",
      "Train Epoch: 1984 [34304/60000 (57%)] Loss: -1246.857910\n",
      "Train Epoch: 1984 [45568/60000 (76%)] Loss: -1274.939575\n",
      "Train Epoch: 1984 [56832/60000 (95%)] Loss: -1515.212646\n",
      "    epoch          : 1984\n",
      "    loss           : -1358.1596712446483\n",
      "Train Epoch: 1985 [512/60000 (1%)] Loss: -1371.916382\n",
      "Train Epoch: 1985 [11776/60000 (20%)] Loss: -1279.272583\n",
      "Train Epoch: 1985 [23040/60000 (38%)] Loss: -1235.124634\n",
      "Train Epoch: 1985 [34304/60000 (57%)] Loss: -1342.353516\n",
      "Train Epoch: 1985 [45568/60000 (76%)] Loss: -1552.988770\n",
      "Train Epoch: 1985 [56832/60000 (95%)] Loss: -1229.921875\n",
      "    epoch          : 1985\n",
      "    loss           : -1334.0356955662958\n",
      "Train Epoch: 1986 [512/60000 (1%)] Loss: -1549.930908\n",
      "Train Epoch: 1986 [11776/60000 (20%)] Loss: -1244.026367\n",
      "Train Epoch: 1986 [23040/60000 (38%)] Loss: -1369.090088\n",
      "Train Epoch: 1986 [34304/60000 (57%)] Loss: -1544.414307\n",
      "Train Epoch: 1986 [45568/60000 (76%)] Loss: -1409.271484\n",
      "Train Epoch: 1986 [56832/60000 (95%)] Loss: -1541.073975\n",
      "    epoch          : 1986\n",
      "    loss           : -1360.0878652798926\n",
      "Train Epoch: 1987 [512/60000 (1%)] Loss: -1216.267334\n",
      "Train Epoch: 1987 [11776/60000 (20%)] Loss: -1262.388794\n",
      "Train Epoch: 1987 [23040/60000 (38%)] Loss: -1530.482056\n",
      "Train Epoch: 1987 [34304/60000 (57%)] Loss: -1369.571533\n",
      "Train Epoch: 1987 [45568/60000 (76%)] Loss: -1400.871216\n",
      "Train Epoch: 1987 [56832/60000 (95%)] Loss: -1371.264893\n",
      "    epoch          : 1987\n",
      "    loss           : -1372.6129271081613\n",
      "Train Epoch: 1988 [512/60000 (1%)] Loss: -1255.713257\n",
      "Train Epoch: 1988 [11776/60000 (20%)] Loss: -1403.550293\n",
      "Train Epoch: 1988 [23040/60000 (38%)] Loss: -1393.146484\n",
      "Train Epoch: 1988 [34304/60000 (57%)] Loss: -1483.808838\n",
      "Train Epoch: 1988 [45568/60000 (76%)] Loss: -1418.874268\n",
      "Train Epoch: 1988 [56832/60000 (95%)] Loss: -1126.997681\n",
      "    epoch          : 1988\n",
      "    loss           : -1354.8341609286724\n",
      "Train Epoch: 1989 [512/60000 (1%)] Loss: -1420.870483\n",
      "Train Epoch: 1989 [11776/60000 (20%)] Loss: -1227.397339\n",
      "Train Epoch: 1989 [23040/60000 (38%)] Loss: -1288.230835\n",
      "Train Epoch: 1989 [34304/60000 (57%)] Loss: -1095.007080\n",
      "Train Epoch: 1989 [45568/60000 (76%)] Loss: -1389.776611\n",
      "Train Epoch: 1989 [56832/60000 (95%)] Loss: -1139.745117\n",
      "    epoch          : 1989\n",
      "    loss           : -1351.9562546897068\n",
      "Train Epoch: 1990 [512/60000 (1%)] Loss: -1397.590820\n",
      "Train Epoch: 1990 [11776/60000 (20%)] Loss: -1247.708618\n",
      "Train Epoch: 1990 [23040/60000 (38%)] Loss: -1114.917236\n",
      "Train Epoch: 1990 [34304/60000 (57%)] Loss: -1386.847168\n",
      "Train Epoch: 1990 [45568/60000 (76%)] Loss: -1240.161499\n",
      "Train Epoch: 1990 [56832/60000 (95%)] Loss: -1358.285767\n",
      "    epoch          : 1990\n",
      "    loss           : -1383.1711287848693\n",
      "Train Epoch: 1991 [512/60000 (1%)] Loss: -1386.835205\n",
      "Train Epoch: 1991 [11776/60000 (20%)] Loss: -1114.561035\n",
      "Train Epoch: 1991 [23040/60000 (38%)] Loss: -1118.701294\n",
      "Train Epoch: 1991 [34304/60000 (57%)] Loss: -1543.030273\n",
      "Train Epoch: 1991 [45568/60000 (76%)] Loss: -1101.585449\n",
      "Train Epoch: 1991 [56832/60000 (95%)] Loss: -1508.182495\n",
      "    epoch          : 1991\n",
      "    loss           : -1343.2170220498986\n",
      "Train Epoch: 1992 [512/60000 (1%)] Loss: -1404.227051\n",
      "Train Epoch: 1992 [11776/60000 (20%)] Loss: -1403.736206\n",
      "Train Epoch: 1992 [23040/60000 (38%)] Loss: -1381.237549\n",
      "Train Epoch: 1992 [34304/60000 (57%)] Loss: -1080.239380\n",
      "Train Epoch: 1992 [45568/60000 (76%)] Loss: -1379.877319\n",
      "Train Epoch: 1992 [56832/60000 (95%)] Loss: -1416.153076\n",
      "    epoch          : 1992\n",
      "    loss           : -1370.8591905152057\n",
      "Train Epoch: 1993 [512/60000 (1%)] Loss: -1545.377197\n",
      "Train Epoch: 1993 [11776/60000 (20%)] Loss: -1123.932251\n",
      "Train Epoch: 1993 [23040/60000 (38%)] Loss: -1424.283691\n",
      "Train Epoch: 1993 [34304/60000 (57%)] Loss: -1549.336914\n",
      "Train Epoch: 1993 [45568/60000 (76%)] Loss: -1275.142822\n",
      "Train Epoch: 1993 [56832/60000 (95%)] Loss: -1392.561768\n",
      "    epoch          : 1993\n",
      "    loss           : -1377.2568583515406\n",
      "Train Epoch: 1994 [512/60000 (1%)] Loss: -1547.336182\n",
      "Train Epoch: 1994 [11776/60000 (20%)] Loss: -1369.119873\n",
      "Train Epoch: 1994 [23040/60000 (38%)] Loss: -1350.176636\n",
      "Train Epoch: 1994 [34304/60000 (57%)] Loss: -1232.552002\n",
      "Train Epoch: 1994 [45568/60000 (76%)] Loss: -1353.468140\n",
      "Train Epoch: 1994 [56832/60000 (95%)] Loss: -1549.827026\n",
      "    epoch          : 1994\n",
      "    loss           : -1350.7392422950875\n",
      "Train Epoch: 1995 [512/60000 (1%)] Loss: -1549.974365\n",
      "Train Epoch: 1995 [11776/60000 (20%)] Loss: -1237.626099\n",
      "Train Epoch: 1995 [23040/60000 (38%)] Loss: -1227.202637\n",
      "Train Epoch: 1995 [34304/60000 (57%)] Loss: -1324.077637\n",
      "Train Epoch: 1995 [45568/60000 (76%)] Loss: -1393.216919\n",
      "Train Epoch: 1995 [56832/60000 (95%)] Loss: -1280.596436\n",
      "    epoch          : 1995\n",
      "    loss           : -1361.1239110224665\n",
      "Train Epoch: 1996 [512/60000 (1%)] Loss: -1254.781006\n",
      "Train Epoch: 1996 [11776/60000 (20%)] Loss: -1149.666260\n",
      "Train Epoch: 1996 [23040/60000 (38%)] Loss: -1375.315674\n",
      "Train Epoch: 1996 [34304/60000 (57%)] Loss: -1248.405029\n",
      "Train Epoch: 1996 [45568/60000 (76%)] Loss: -1244.574463\n",
      "Train Epoch: 1996 [56832/60000 (95%)] Loss: -1405.294189\n",
      "    epoch          : 1996\n",
      "    loss           : -1354.3047502593133\n",
      "Train Epoch: 1997 [512/60000 (1%)] Loss: -1384.030029\n",
      "Train Epoch: 1997 [11776/60000 (20%)] Loss: -1522.020508\n",
      "Train Epoch: 1997 [23040/60000 (38%)] Loss: -1236.390259\n",
      "Train Epoch: 1997 [34304/60000 (57%)] Loss: -1252.956543\n",
      "Train Epoch: 1997 [45568/60000 (76%)] Loss: -1535.389038\n",
      "Train Epoch: 1997 [56832/60000 (95%)] Loss: -1256.926025\n",
      "    epoch          : 1997\n",
      "    loss           : -1388.306010273217\n",
      "Train Epoch: 1998 [512/60000 (1%)] Loss: -1392.630005\n",
      "Train Epoch: 1998 [11776/60000 (20%)] Loss: -1382.310059\n",
      "Train Epoch: 1998 [23040/60000 (38%)] Loss: -1404.536987\n",
      "Train Epoch: 1998 [34304/60000 (57%)] Loss: -1393.456543\n",
      "Train Epoch: 1998 [45568/60000 (76%)] Loss: -1508.867310\n",
      "Train Epoch: 1998 [56832/60000 (95%)] Loss: -1409.216064\n",
      "    epoch          : 1998\n",
      "    loss           : -1365.0543388754634\n",
      "Train Epoch: 1999 [512/60000 (1%)] Loss: -1239.165649\n",
      "Train Epoch: 1999 [11776/60000 (20%)] Loss: -1540.614136\n",
      "Train Epoch: 1999 [23040/60000 (38%)] Loss: -1415.127441\n",
      "Train Epoch: 1999 [34304/60000 (57%)] Loss: -1542.186768\n",
      "Train Epoch: 1999 [45568/60000 (76%)] Loss: -1390.651245\n",
      "Train Epoch: 1999 [56832/60000 (95%)] Loss: -1510.740967\n",
      "    epoch          : 1999\n",
      "    loss           : -1354.806517175362\n",
      "Train Epoch: 2000 [512/60000 (1%)] Loss: -1374.314331\n",
      "Train Epoch: 2000 [11776/60000 (20%)] Loss: -1368.664429\n",
      "Train Epoch: 2000 [23040/60000 (38%)] Loss: -1243.395020\n",
      "Train Epoch: 2000 [34304/60000 (57%)] Loss: -1264.754028\n",
      "Train Epoch: 2000 [45568/60000 (76%)] Loss: -1528.938477\n",
      "Train Epoch: 2000 [56832/60000 (95%)] Loss: -1412.772217\n",
      "    epoch          : 2000\n",
      "    loss           : -1369.5652514096707\n",
      "Saving checkpoint: saved/models/Mnist_DeepGenerativeOperad/0127_111843/checkpoint-epoch2000.pth ...\n",
      "Train Epoch: 2001 [512/60000 (1%)] Loss: -1248.829346\n",
      "Train Epoch: 2001 [11776/60000 (20%)] Loss: -1257.146851\n",
      "Train Epoch: 2001 [23040/60000 (38%)] Loss: -1357.733154\n",
      "Train Epoch: 2001 [34304/60000 (57%)] Loss: -1372.926514\n",
      "Train Epoch: 2001 [45568/60000 (76%)] Loss: -1167.240967\n",
      "Train Epoch: 2001 [56832/60000 (95%)] Loss: -1387.173584\n",
      "    epoch          : 2001\n",
      "    loss           : -1349.3175486763992\n",
      "Train Epoch: 2002 [512/60000 (1%)] Loss: -1394.364990\n",
      "Train Epoch: 2002 [11776/60000 (20%)] Loss: -1258.969238\n",
      "Train Epoch: 2002 [23040/60000 (38%)] Loss: -1249.070068\n",
      "Train Epoch: 2002 [34304/60000 (57%)] Loss: -1263.011719\n",
      "Train Epoch: 2002 [45568/60000 (76%)] Loss: -1416.670532\n",
      "Train Epoch: 2002 [56832/60000 (95%)] Loss: -1388.228027\n",
      "    epoch          : 2002\n",
      "    loss           : -1345.4279243770966\n",
      "Train Epoch: 2003 [512/60000 (1%)] Loss: -1296.143311\n",
      "Train Epoch: 2003 [11776/60000 (20%)] Loss: -1382.970215\n",
      "Train Epoch: 2003 [23040/60000 (38%)] Loss: -1408.664429\n",
      "Train Epoch: 2003 [34304/60000 (57%)] Loss: -1370.334595\n",
      "Train Epoch: 2003 [45568/60000 (76%)] Loss: -1095.255005\n",
      "Train Epoch: 2003 [56832/60000 (95%)] Loss: -1383.241211\n",
      "    epoch          : 2003\n",
      "    loss           : -1355.136998063427\n",
      "Train Epoch: 2004 [512/60000 (1%)] Loss: -1234.364258\n",
      "Train Epoch: 2004 [11776/60000 (20%)] Loss: -1397.118408\n",
      "Train Epoch: 2004 [23040/60000 (38%)] Loss: -1387.817871\n",
      "Train Epoch: 2004 [34304/60000 (57%)] Loss: -1419.335327\n",
      "Train Epoch: 2004 [45568/60000 (76%)] Loss: -1228.931030\n",
      "Train Epoch: 2004 [56832/60000 (95%)] Loss: -1494.050049\n",
      "    epoch          : 2004\n",
      "    loss           : -1369.760359769487\n",
      "Train Epoch: 2005 [512/60000 (1%)] Loss: -1400.952271\n",
      "Train Epoch: 2005 [11776/60000 (20%)] Loss: -1259.759888\n",
      "Train Epoch: 2005 [23040/60000 (38%)] Loss: -1468.291870\n",
      "Train Epoch: 2005 [34304/60000 (57%)] Loss: -1362.491089\n",
      "Train Epoch: 2005 [45568/60000 (76%)] Loss: -1362.433228\n",
      "Train Epoch: 2005 [56832/60000 (95%)] Loss: -1431.394043\n",
      "    epoch          : 2005\n",
      "    loss           : -1356.4173639157398\n",
      "Train Epoch: 2006 [512/60000 (1%)] Loss: -1280.639404\n",
      "Train Epoch: 2006 [11776/60000 (20%)] Loss: -1216.216919\n",
      "Train Epoch: 2006 [23040/60000 (38%)] Loss: -1392.760132\n",
      "Train Epoch: 2006 [34304/60000 (57%)] Loss: -1539.274902\n",
      "Train Epoch: 2006 [45568/60000 (76%)] Loss: -1408.538940\n",
      "Train Epoch: 2006 [56832/60000 (95%)] Loss: -1543.832275\n",
      "    epoch          : 2006\n",
      "    loss           : -1356.6755567647642\n",
      "Train Epoch: 2007 [512/60000 (1%)] Loss: -1373.117310\n",
      "Train Epoch: 2007 [11776/60000 (20%)] Loss: -1549.077271\n",
      "Train Epoch: 2007 [23040/60000 (38%)] Loss: -1473.332642\n",
      "Train Epoch: 2007 [34304/60000 (57%)] Loss: -1419.715210\n",
      "Train Epoch: 2007 [45568/60000 (76%)] Loss: -1272.305054\n",
      "Train Epoch: 2007 [56832/60000 (95%)] Loss: -1424.114014\n",
      "    epoch          : 2007\n",
      "    loss           : -1365.8406603107344\n",
      "Train Epoch: 2008 [512/60000 (1%)] Loss: -1099.595459\n",
      "Train Epoch: 2008 [11776/60000 (20%)] Loss: -1132.180420\n",
      "Train Epoch: 2008 [23040/60000 (38%)] Loss: -1503.486572\n",
      "Train Epoch: 2008 [34304/60000 (57%)] Loss: -1393.732910\n",
      "Train Epoch: 2008 [45568/60000 (76%)] Loss: -1104.802612\n",
      "Train Epoch: 2008 [56832/60000 (95%)] Loss: -1351.159180\n",
      "    epoch          : 2008\n",
      "    loss           : -1364.7336898200256\n",
      "Train Epoch: 2009 [512/60000 (1%)] Loss: -1428.261475\n",
      "Train Epoch: 2009 [11776/60000 (20%)] Loss: -1384.041626\n",
      "Train Epoch: 2009 [23040/60000 (38%)] Loss: -1246.259766\n",
      "Train Epoch: 2009 [34304/60000 (57%)] Loss: -1374.976074\n",
      "Train Epoch: 2009 [45568/60000 (76%)] Loss: -1408.002808\n",
      "Train Epoch: 2009 [56832/60000 (95%)] Loss: -1264.988281\n",
      "    epoch          : 2009\n",
      "    loss           : -1361.075825147036\n",
      "Train Epoch: 2010 [512/60000 (1%)] Loss: -1546.494873\n",
      "Train Epoch: 2010 [11776/60000 (20%)] Loss: -1221.489014\n",
      "Train Epoch: 2010 [23040/60000 (38%)] Loss: -1393.055176\n",
      "Train Epoch: 2010 [34304/60000 (57%)] Loss: -1482.544312\n",
      "Train Epoch: 2010 [45568/60000 (76%)] Loss: -1094.791382\n",
      "Train Epoch: 2010 [56832/60000 (95%)] Loss: -1251.651123\n",
      "    epoch          : 2010\n",
      "    loss           : -1363.7488044695665\n",
      "Train Epoch: 2011 [512/60000 (1%)] Loss: -1416.379639\n",
      "Train Epoch: 2011 [11776/60000 (20%)] Loss: -1257.017334\n",
      "Train Epoch: 2011 [23040/60000 (38%)] Loss: -1253.939087\n",
      "Train Epoch: 2011 [34304/60000 (57%)] Loss: -1251.476807\n",
      "Train Epoch: 2011 [45568/60000 (76%)] Loss: -1270.893311\n",
      "Train Epoch: 2011 [56832/60000 (95%)] Loss: -1525.988892\n",
      "    epoch          : 2011\n",
      "    loss           : -1360.5001265531205\n",
      "Train Epoch: 2012 [512/60000 (1%)] Loss: -1367.800659\n",
      "Train Epoch: 2012 [11776/60000 (20%)] Loss: -1536.877197\n",
      "Train Epoch: 2012 [23040/60000 (38%)] Loss: -1393.546753\n",
      "Train Epoch: 2012 [34304/60000 (57%)] Loss: -1394.627075\n",
      "Train Epoch: 2012 [45568/60000 (76%)] Loss: -1399.714478\n",
      "Train Epoch: 2012 [56832/60000 (95%)] Loss: -1408.738770\n",
      "    epoch          : 2012\n",
      "    loss           : -1363.4502261749094\n",
      "Train Epoch: 2013 [512/60000 (1%)] Loss: -1354.258789\n",
      "Train Epoch: 2013 [11776/60000 (20%)] Loss: -1260.294067\n",
      "Train Epoch: 2013 [23040/60000 (38%)] Loss: -1522.318604\n",
      "Train Epoch: 2013 [34304/60000 (57%)] Loss: -1383.686401\n",
      "Train Epoch: 2013 [45568/60000 (76%)] Loss: -1290.480713\n",
      "Train Epoch: 2013 [56832/60000 (95%)] Loss: -1533.879883\n",
      "    epoch          : 2013\n",
      "    loss           : -1339.9985905016883\n",
      "Train Epoch: 2014 [512/60000 (1%)] Loss: -1380.591919\n",
      "Train Epoch: 2014 [11776/60000 (20%)] Loss: -1264.388184\n",
      "Train Epoch: 2014 [23040/60000 (38%)] Loss: -1260.201172\n",
      "Train Epoch: 2014 [34304/60000 (57%)] Loss: -1101.452271\n",
      "Train Epoch: 2014 [45568/60000 (76%)] Loss: -1545.274414\n",
      "Train Epoch: 2014 [56832/60000 (95%)] Loss: -1493.495850\n",
      "    epoch          : 2014\n",
      "    loss           : -1361.831644349179\n",
      "Train Epoch: 2015 [512/60000 (1%)] Loss: -1244.307861\n",
      "Train Epoch: 2015 [11776/60000 (20%)] Loss: -1386.769775\n",
      "Train Epoch: 2015 [23040/60000 (38%)] Loss: -1362.640137\n",
      "Train Epoch: 2015 [34304/60000 (57%)] Loss: -1251.813477\n",
      "Train Epoch: 2015 [45568/60000 (76%)] Loss: -1137.413330\n",
      "Train Epoch: 2015 [56832/60000 (95%)] Loss: -1381.112061\n",
      "    epoch          : 2015\n",
      "    loss           : -1363.1128852111472\n",
      "Train Epoch: 2016 [512/60000 (1%)] Loss: -1401.745361\n",
      "Train Epoch: 2016 [11776/60000 (20%)] Loss: -1513.815308\n",
      "Train Epoch: 2016 [23040/60000 (38%)] Loss: -1388.652832\n",
      "Train Epoch: 2016 [34304/60000 (57%)] Loss: -1412.849731\n",
      "Train Epoch: 2016 [45568/60000 (76%)] Loss: -1533.644897\n",
      "Train Epoch: 2016 [56832/60000 (95%)] Loss: -1402.024170\n",
      "    epoch          : 2016\n",
      "    loss           : -1371.449687720692\n",
      "Train Epoch: 2017 [512/60000 (1%)] Loss: -1410.080200\n",
      "Train Epoch: 2017 [11776/60000 (20%)] Loss: -1224.633789\n",
      "Train Epoch: 2017 [23040/60000 (38%)] Loss: -1124.725098\n",
      "Train Epoch: 2017 [34304/60000 (57%)] Loss: -1523.046753\n",
      "Train Epoch: 2017 [45568/60000 (76%)] Loss: -1417.350830\n",
      "Train Epoch: 2017 [56832/60000 (95%)] Loss: -1140.794678\n",
      "    epoch          : 2017\n",
      "    loss           : -1370.7533972788665\n",
      "Train Epoch: 2018 [512/60000 (1%)] Loss: -1354.127930\n",
      "Train Epoch: 2018 [11776/60000 (20%)] Loss: -1504.204102\n",
      "Train Epoch: 2018 [23040/60000 (38%)] Loss: -1227.432373\n",
      "Train Epoch: 2018 [34304/60000 (57%)] Loss: -1532.380005\n",
      "Train Epoch: 2018 [45568/60000 (76%)] Loss: -1401.538818\n",
      "Train Epoch: 2018 [56832/60000 (95%)] Loss: -1386.488647\n",
      "    epoch          : 2018\n",
      "    loss           : -1360.0822350453523\n",
      "Train Epoch: 2019 [512/60000 (1%)] Loss: -1499.304321\n",
      "Train Epoch: 2019 [11776/60000 (20%)] Loss: -1253.041504\n",
      "Train Epoch: 2019 [23040/60000 (38%)] Loss: -1371.900879\n",
      "Train Epoch: 2019 [34304/60000 (57%)] Loss: -1353.053955\n",
      "Train Epoch: 2019 [45568/60000 (76%)] Loss: -1237.061035\n",
      "Train Epoch: 2019 [56832/60000 (95%)] Loss: -1245.957031\n",
      "    epoch          : 2019\n",
      "    loss           : -1337.58287643174\n",
      "Train Epoch: 2020 [512/60000 (1%)] Loss: -1537.711792\n",
      "Train Epoch: 2020 [11776/60000 (20%)] Loss: -1229.025146\n",
      "Train Epoch: 2020 [23040/60000 (38%)] Loss: -1354.800537\n",
      "Train Epoch: 2020 [34304/60000 (57%)] Loss: -1408.901367\n",
      "Train Epoch: 2020 [45568/60000 (76%)] Loss: -1108.417480\n",
      "Train Epoch: 2020 [56832/60000 (95%)] Loss: -1411.752686\n",
      "    epoch          : 2020\n",
      "    loss           : -1353.9728876318636\n",
      "Train Epoch: 2021 [512/60000 (1%)] Loss: -1248.721069\n",
      "Train Epoch: 2021 [11776/60000 (20%)] Loss: -1234.345947\n",
      "Train Epoch: 2021 [23040/60000 (38%)] Loss: -1406.207886\n",
      "Train Epoch: 2021 [34304/60000 (57%)] Loss: -1494.576660\n",
      "Train Epoch: 2021 [45568/60000 (76%)] Loss: -1509.728516\n",
      "Train Epoch: 2021 [56832/60000 (95%)] Loss: -1528.971313\n",
      "    epoch          : 2021\n",
      "    loss           : -1362.0173896746446\n",
      "Train Epoch: 2022 [512/60000 (1%)] Loss: -1386.527954\n",
      "Train Epoch: 2022 [11776/60000 (20%)] Loss: -1392.416992\n",
      "Train Epoch: 2022 [23040/60000 (38%)] Loss: -1363.282837\n",
      "Train Epoch: 2022 [34304/60000 (57%)] Loss: -1386.902832\n",
      "Train Epoch: 2022 [45568/60000 (76%)] Loss: -1249.762329\n",
      "Train Epoch: 2022 [56832/60000 (95%)] Loss: -1509.074707\n",
      "    epoch          : 2022\n",
      "    loss           : -1376.221752791755\n",
      "Train Epoch: 2023 [512/60000 (1%)] Loss: -1112.287842\n",
      "Train Epoch: 2023 [11776/60000 (20%)] Loss: -1368.566772\n",
      "Train Epoch: 2023 [23040/60000 (38%)] Loss: -1415.533936\n",
      "Train Epoch: 2023 [34304/60000 (57%)] Loss: -1335.670898\n",
      "Train Epoch: 2023 [45568/60000 (76%)] Loss: -1483.235229\n",
      "Train Epoch: 2023 [56832/60000 (95%)] Loss: -1390.145020\n",
      "    epoch          : 2023\n",
      "    loss           : -1347.2777099609375\n",
      "Train Epoch: 2024 [512/60000 (1%)] Loss: -1417.983643\n",
      "Train Epoch: 2024 [11776/60000 (20%)] Loss: -1235.843872\n",
      "Train Epoch: 2024 [23040/60000 (38%)] Loss: -1380.018066\n",
      "Train Epoch: 2024 [34304/60000 (57%)] Loss: -1375.179810\n",
      "Train Epoch: 2024 [45568/60000 (76%)] Loss: -1536.400391\n",
      "Train Epoch: 2024 [56832/60000 (95%)] Loss: -1253.908447\n",
      "    epoch          : 2024\n",
      "    loss           : -1384.3242446123543\n",
      "Train Epoch: 2025 [512/60000 (1%)] Loss: -1284.640503\n",
      "Train Epoch: 2025 [11776/60000 (20%)] Loss: -1414.479980\n",
      "Train Epoch: 2025 [23040/60000 (38%)] Loss: -1513.215820\n",
      "Train Epoch: 2025 [34304/60000 (57%)] Loss: -1523.318359\n",
      "Train Epoch: 2025 [45568/60000 (76%)] Loss: -1503.625000\n",
      "Train Epoch: 2025 [56832/60000 (95%)] Loss: -1551.300659\n",
      "    epoch          : 2025\n",
      "    loss           : -1375.5714673403293\n",
      "Train Epoch: 2026 [512/60000 (1%)] Loss: -1239.255859\n",
      "Train Epoch: 2026 [11776/60000 (20%)] Loss: -1512.862793\n",
      "Train Epoch: 2026 [23040/60000 (38%)] Loss: -1246.242432\n",
      "Train Epoch: 2026 [34304/60000 (57%)] Loss: -1145.054932\n",
      "Train Epoch: 2026 [45568/60000 (76%)] Loss: -1544.140381\n",
      "Train Epoch: 2026 [56832/60000 (95%)] Loss: -1409.851929\n",
      "    epoch          : 2026\n",
      "    loss           : -1383.142904335496\n",
      "Train Epoch: 2027 [512/60000 (1%)] Loss: -1496.403076\n",
      "Train Epoch: 2027 [11776/60000 (20%)] Loss: -1511.121704\n",
      "Train Epoch: 2027 [23040/60000 (38%)] Loss: -1365.739502\n",
      "Train Epoch: 2027 [34304/60000 (57%)] Loss: -1115.223511\n",
      "Train Epoch: 2027 [45568/60000 (76%)] Loss: -1530.345459\n",
      "Train Epoch: 2027 [56832/60000 (95%)] Loss: -1386.816895\n",
      "    epoch          : 2027\n",
      "    loss           : -1375.5666283214161\n",
      "Train Epoch: 2028 [512/60000 (1%)] Loss: -1517.103271\n",
      "Train Epoch: 2028 [11776/60000 (20%)] Loss: -1251.000732\n",
      "Train Epoch: 2028 [23040/60000 (38%)] Loss: -1431.196411\n",
      "Train Epoch: 2028 [34304/60000 (57%)] Loss: -1231.344971\n",
      "Train Epoch: 2028 [45568/60000 (76%)] Loss: -1383.669922\n",
      "Train Epoch: 2028 [56832/60000 (95%)] Loss: -1482.562012\n",
      "    epoch          : 2028\n",
      "    loss           : -1354.6753114172293\n",
      "Train Epoch: 2029 [512/60000 (1%)] Loss: -1500.753174\n",
      "Train Epoch: 2029 [11776/60000 (20%)] Loss: -1518.933350\n",
      "Train Epoch: 2029 [23040/60000 (38%)] Loss: -1373.474121\n",
      "Train Epoch: 2029 [34304/60000 (57%)] Loss: -1502.210449\n",
      "Train Epoch: 2029 [45568/60000 (76%)] Loss: -1221.427979\n",
      "Train Epoch: 2029 [56832/60000 (95%)] Loss: -1373.962036\n",
      "    epoch          : 2029\n",
      "    loss           : -1376.2347758664923\n",
      "Train Epoch: 2030 [512/60000 (1%)] Loss: -1250.566895\n",
      "Train Epoch: 2030 [11776/60000 (20%)] Loss: -1396.252930\n",
      "Train Epoch: 2030 [23040/60000 (38%)] Loss: -1386.743408\n",
      "Train Epoch: 2030 [34304/60000 (57%)] Loss: -1496.914062\n",
      "Train Epoch: 2030 [45568/60000 (76%)] Loss: -1230.899780\n",
      "Train Epoch: 2030 [56832/60000 (95%)] Loss: -1251.651367\n",
      "    epoch          : 2030\n",
      "    loss           : -1361.9365741277145\n",
      "Train Epoch: 2031 [512/60000 (1%)] Loss: -1400.512085\n",
      "Train Epoch: 2031 [11776/60000 (20%)] Loss: -1406.804810\n",
      "Train Epoch: 2031 [23040/60000 (38%)] Loss: -1253.133057\n",
      "Train Epoch: 2031 [34304/60000 (57%)] Loss: -1543.519287\n",
      "Train Epoch: 2031 [45568/60000 (76%)] Loss: -1216.967163\n",
      "Train Epoch: 2031 [56832/60000 (95%)] Loss: -1393.422607\n",
      "    epoch          : 2031\n",
      "    loss           : -1362.1731557037872\n",
      "Train Epoch: 2032 [512/60000 (1%)] Loss: -1271.049316\n",
      "Train Epoch: 2032 [11776/60000 (20%)] Loss: -1125.286865\n",
      "Train Epoch: 2032 [23040/60000 (38%)] Loss: -1267.056396\n",
      "Train Epoch: 2032 [34304/60000 (57%)] Loss: -1251.359009\n",
      "Train Epoch: 2032 [45568/60000 (76%)] Loss: -1278.654297\n",
      "Train Epoch: 2032 [56832/60000 (95%)] Loss: -1385.937500\n",
      "    epoch          : 2032\n",
      "    loss           : -1363.6782612773657\n",
      "Train Epoch: 2033 [512/60000 (1%)] Loss: -1153.758545\n",
      "Train Epoch: 2033 [11776/60000 (20%)] Loss: -1363.810547\n",
      "Train Epoch: 2033 [23040/60000 (38%)] Loss: -1384.724365\n",
      "Train Epoch: 2033 [34304/60000 (57%)] Loss: -1356.258423\n",
      "Train Epoch: 2033 [45568/60000 (76%)] Loss: -1550.064209\n",
      "Train Epoch: 2033 [56832/60000 (95%)] Loss: -1365.875366\n",
      "    epoch          : 2033\n",
      "    loss           : -1357.2931390967074\n",
      "Train Epoch: 2034 [512/60000 (1%)] Loss: -1363.998169\n",
      "Train Epoch: 2034 [11776/60000 (20%)] Loss: -1257.912109\n",
      "Train Epoch: 2034 [23040/60000 (38%)] Loss: -1379.908447\n",
      "Train Epoch: 2034 [34304/60000 (57%)] Loss: -1402.255859\n",
      "Train Epoch: 2034 [45568/60000 (76%)] Loss: -1389.773071\n",
      "Train Epoch: 2034 [56832/60000 (95%)] Loss: -1417.367798\n",
      "    epoch          : 2034\n",
      "    loss           : -1343.4960690945557\n",
      "Train Epoch: 2035 [512/60000 (1%)] Loss: -1290.931641\n",
      "Train Epoch: 2035 [11776/60000 (20%)] Loss: -1387.611938\n",
      "Train Epoch: 2035 [23040/60000 (38%)] Loss: -1267.373291\n",
      "Train Epoch: 2035 [34304/60000 (57%)] Loss: -1382.923706\n",
      "Train Epoch: 2035 [45568/60000 (76%)] Loss: -1507.482178\n",
      "Train Epoch: 2035 [56832/60000 (95%)] Loss: -1237.041138\n",
      "    epoch          : 2035\n",
      "    loss           : -1361.6196530444472\n",
      "Train Epoch: 2036 [512/60000 (1%)] Loss: -1381.607666\n",
      "Train Epoch: 2036 [11776/60000 (20%)] Loss: -1392.518188\n",
      "Train Epoch: 2036 [23040/60000 (38%)] Loss: -1255.139648\n",
      "Train Epoch: 2036 [34304/60000 (57%)] Loss: -1399.006592\n",
      "Train Epoch: 2036 [45568/60000 (76%)] Loss: -1274.875977\n",
      "Train Epoch: 2036 [56832/60000 (95%)] Loss: -1528.352539\n",
      "    epoch          : 2036\n",
      "    loss           : -1361.5431456485037\n",
      "Train Epoch: 2037 [512/60000 (1%)] Loss: -1425.823975\n",
      "Train Epoch: 2037 [11776/60000 (20%)] Loss: -1371.239380\n",
      "Train Epoch: 2037 [23040/60000 (38%)] Loss: -1115.974365\n",
      "Train Epoch: 2037 [34304/60000 (57%)] Loss: -1551.069092\n",
      "Train Epoch: 2037 [45568/60000 (76%)] Loss: -1109.252563\n",
      "Train Epoch: 2037 [56832/60000 (95%)] Loss: -1123.165405\n",
      "    epoch          : 2037\n",
      "    loss           : -1353.9969844494835\n",
      "Train Epoch: 2038 [512/60000 (1%)] Loss: -1387.881836\n",
      "Train Epoch: 2038 [11776/60000 (20%)] Loss: -1260.594727\n",
      "Train Epoch: 2038 [23040/60000 (38%)] Loss: -1505.196411\n",
      "Train Epoch: 2038 [34304/60000 (57%)] Loss: -1382.755127\n",
      "Train Epoch: 2038 [45568/60000 (76%)] Loss: -1516.657471\n",
      "Train Epoch: 2038 [56832/60000 (95%)] Loss: -1356.197998\n",
      "    epoch          : 2038\n",
      "    loss           : -1347.3563285870741\n",
      "Train Epoch: 2039 [512/60000 (1%)] Loss: -1360.205078\n",
      "Train Epoch: 2039 [11776/60000 (20%)] Loss: -1529.113403\n",
      "Train Epoch: 2039 [23040/60000 (38%)] Loss: -1516.043701\n",
      "Train Epoch: 2039 [34304/60000 (57%)] Loss: -1256.008789\n",
      "Train Epoch: 2039 [45568/60000 (76%)] Loss: -1134.851807\n",
      "Train Epoch: 2039 [56832/60000 (95%)] Loss: -1401.014648\n",
      "    epoch          : 2039\n",
      "    loss           : -1375.0995497191693\n",
      "Train Epoch: 2040 [512/60000 (1%)] Loss: -1527.691162\n",
      "Train Epoch: 2040 [11776/60000 (20%)] Loss: -1261.762451\n",
      "Train Epoch: 2040 [23040/60000 (38%)] Loss: -1222.268555\n",
      "Train Epoch: 2040 [34304/60000 (57%)] Loss: -1241.544678\n",
      "Train Epoch: 2040 [45568/60000 (76%)] Loss: -1497.999268\n",
      "Train Epoch: 2040 [56832/60000 (95%)] Loss: -1403.866333\n",
      "    epoch          : 2040\n",
      "    loss           : -1369.1355313231043\n",
      "Train Epoch: 2041 [512/60000 (1%)] Loss: -1243.147827\n",
      "Train Epoch: 2041 [11776/60000 (20%)] Loss: -1148.860962\n",
      "Train Epoch: 2041 [23040/60000 (38%)] Loss: -1281.050537\n",
      "Train Epoch: 2041 [34304/60000 (57%)] Loss: -1416.718994\n",
      "Train Epoch: 2041 [45568/60000 (76%)] Loss: -1369.277588\n",
      "Train Epoch: 2041 [56832/60000 (95%)] Loss: -1214.574463\n",
      "    epoch          : 2041\n",
      "    loss           : -1380.5959648520259\n",
      "Train Epoch: 2042 [512/60000 (1%)] Loss: -1402.386719\n",
      "Train Epoch: 2042 [11776/60000 (20%)] Loss: -1252.413940\n",
      "Train Epoch: 2042 [23040/60000 (38%)] Loss: -1366.484131\n",
      "Train Epoch: 2042 [34304/60000 (57%)] Loss: -1400.320068\n",
      "Train Epoch: 2042 [45568/60000 (76%)] Loss: -1240.895264\n",
      "Train Epoch: 2042 [56832/60000 (95%)] Loss: -1237.552002\n",
      "    epoch          : 2042\n",
      "    loss           : -1358.7239045396364\n",
      "Train Epoch: 2043 [512/60000 (1%)] Loss: -1497.651001\n",
      "Train Epoch: 2043 [11776/60000 (20%)] Loss: -1290.739990\n",
      "Train Epoch: 2043 [23040/60000 (38%)] Loss: -1270.507812\n",
      "Train Epoch: 2043 [34304/60000 (57%)] Loss: -1423.487549\n",
      "Train Epoch: 2043 [45568/60000 (76%)] Loss: -1114.420044\n",
      "Train Epoch: 2043 [56832/60000 (95%)] Loss: -1523.885010\n",
      "    epoch          : 2043\n",
      "    loss           : -1351.7742471641068\n",
      "Train Epoch: 2044 [512/60000 (1%)] Loss: -1420.513794\n",
      "Train Epoch: 2044 [11776/60000 (20%)] Loss: -1540.150757\n",
      "Train Epoch: 2044 [23040/60000 (38%)] Loss: -1274.455200\n",
      "Train Epoch: 2044 [34304/60000 (57%)] Loss: -1536.767700\n",
      "Train Epoch: 2044 [45568/60000 (76%)] Loss: -1384.757812\n",
      "Train Epoch: 2044 [56832/60000 (95%)] Loss: -1233.743896\n",
      "    epoch          : 2044\n",
      "    loss           : -1365.233554301289\n",
      "Train Epoch: 2045 [512/60000 (1%)] Loss: -1382.209229\n",
      "Train Epoch: 2045 [11776/60000 (20%)] Loss: -1391.043335\n",
      "Train Epoch: 2045 [23040/60000 (38%)] Loss: -1389.829346\n",
      "Train Epoch: 2045 [34304/60000 (57%)] Loss: -1106.576172\n",
      "Train Epoch: 2045 [45568/60000 (76%)] Loss: -1377.741211\n",
      "Train Epoch: 2045 [56832/60000 (95%)] Loss: -1150.930176\n",
      "    epoch          : 2045\n",
      "    loss           : -1360.5081842282398\n",
      "Train Epoch: 2046 [512/60000 (1%)] Loss: -1385.846558\n",
      "Train Epoch: 2046 [11776/60000 (20%)] Loss: -1424.161255\n",
      "Train Epoch: 2046 [23040/60000 (38%)] Loss: -1220.107788\n",
      "Train Epoch: 2046 [34304/60000 (57%)] Loss: -1516.813843\n",
      "Train Epoch: 2046 [45568/60000 (76%)] Loss: -1254.315186\n",
      "Train Epoch: 2046 [56832/60000 (95%)] Loss: -1225.582275\n",
      "    epoch          : 2046\n",
      "    loss           : -1359.7946846310028\n",
      "Train Epoch: 2047 [512/60000 (1%)] Loss: -1131.807251\n",
      "Train Epoch: 2047 [11776/60000 (20%)] Loss: -1518.461426\n",
      "Train Epoch: 2047 [23040/60000 (38%)] Loss: -1271.188110\n",
      "Train Epoch: 2047 [34304/60000 (57%)] Loss: -1400.245850\n",
      "Train Epoch: 2047 [45568/60000 (76%)] Loss: -1395.599854\n",
      "Train Epoch: 2047 [56832/60000 (95%)] Loss: -1275.320312\n",
      "    epoch          : 2047\n",
      "    loss           : -1357.445693193856\n",
      "Train Epoch: 2048 [512/60000 (1%)] Loss: -1394.757568\n",
      "Train Epoch: 2048 [11776/60000 (20%)] Loss: -1419.582764\n",
      "Train Epoch: 2048 [23040/60000 (38%)] Loss: -1527.459839\n",
      "Train Epoch: 2048 [34304/60000 (57%)] Loss: -1364.042358\n",
      "Train Epoch: 2048 [45568/60000 (76%)] Loss: -1385.138306\n",
      "Train Epoch: 2048 [56832/60000 (95%)] Loss: -1400.069214\n",
      "    epoch          : 2048\n",
      "    loss           : -1389.7748078599489\n",
      "Train Epoch: 2049 [512/60000 (1%)] Loss: -1558.580566\n",
      "Train Epoch: 2049 [11776/60000 (20%)] Loss: -1367.117188\n",
      "Train Epoch: 2049 [23040/60000 (38%)] Loss: -1358.919189\n",
      "Train Epoch: 2049 [34304/60000 (57%)] Loss: -1413.914307\n",
      "Train Epoch: 2049 [45568/60000 (76%)] Loss: -1266.111694\n",
      "Train Epoch: 2049 [56832/60000 (95%)] Loss: -1388.568604\n",
      "    epoch          : 2049\n",
      "    loss           : -1357.7994126142082\n",
      "Train Epoch: 2050 [512/60000 (1%)] Loss: -1273.518311\n",
      "Train Epoch: 2050 [11776/60000 (20%)] Loss: -1366.596191\n",
      "Train Epoch: 2050 [23040/60000 (38%)] Loss: -1368.487183\n",
      "Train Epoch: 2050 [34304/60000 (57%)] Loss: -1226.212524\n",
      "Train Epoch: 2050 [45568/60000 (76%)] Loss: -1375.411621\n",
      "Train Epoch: 2050 [56832/60000 (95%)] Loss: -1141.459106\n",
      "    epoch          : 2050\n",
      "    loss           : -1343.4866684735832\n",
      "Train Epoch: 2051 [512/60000 (1%)] Loss: -1228.078247\n",
      "Train Epoch: 2051 [11776/60000 (20%)] Loss: -1245.110107\n",
      "Train Epoch: 2051 [23040/60000 (38%)] Loss: -1549.943115\n",
      "Train Epoch: 2051 [34304/60000 (57%)] Loss: -1503.089355\n",
      "Train Epoch: 2051 [45568/60000 (76%)] Loss: -1245.871704\n",
      "Train Epoch: 2051 [56832/60000 (95%)] Loss: -1413.503174\n",
      "    epoch          : 2051\n",
      "    loss           : -1360.9389770852642\n",
      "Train Epoch: 2052 [512/60000 (1%)] Loss: -1135.372070\n",
      "Train Epoch: 2052 [11776/60000 (20%)] Loss: -1385.173584\n",
      "Train Epoch: 2052 [23040/60000 (38%)] Loss: -1210.660400\n",
      "Train Epoch: 2052 [34304/60000 (57%)] Loss: -1374.929565\n",
      "Train Epoch: 2052 [45568/60000 (76%)] Loss: -1367.190674\n",
      "Train Epoch: 2052 [56832/60000 (95%)] Loss: -1257.366089\n",
      "    epoch          : 2052\n",
      "    loss           : -1357.5414192501435\n",
      "Train Epoch: 2053 [512/60000 (1%)] Loss: -1540.226807\n",
      "Train Epoch: 2053 [11776/60000 (20%)] Loss: -1289.220093\n",
      "Train Epoch: 2053 [23040/60000 (38%)] Loss: -1257.840088\n",
      "Train Epoch: 2053 [34304/60000 (57%)] Loss: -1519.037598\n",
      "Train Epoch: 2053 [45568/60000 (76%)] Loss: -1397.815430\n",
      "Train Epoch: 2053 [56832/60000 (95%)] Loss: -1356.536133\n",
      "    epoch          : 2053\n",
      "    loss           : -1365.6782388633255\n",
      "Train Epoch: 2054 [512/60000 (1%)] Loss: -1244.696777\n",
      "Train Epoch: 2054 [11776/60000 (20%)] Loss: -1413.037109\n",
      "Train Epoch: 2054 [23040/60000 (38%)] Loss: -1395.222046\n",
      "Train Epoch: 2054 [34304/60000 (57%)] Loss: -1481.741211\n",
      "Train Epoch: 2054 [45568/60000 (76%)] Loss: -1389.630371\n",
      "Train Epoch: 2054 [56832/60000 (95%)] Loss: -1411.727295\n",
      "    epoch          : 2054\n",
      "    loss           : -1350.1978044240486\n",
      "Train Epoch: 2055 [512/60000 (1%)] Loss: -1259.320068\n",
      "Train Epoch: 2055 [11776/60000 (20%)] Loss: -1266.559570\n",
      "Train Epoch: 2055 [23040/60000 (38%)] Loss: -1534.490356\n",
      "Train Epoch: 2055 [34304/60000 (57%)] Loss: -1386.990112\n",
      "Train Epoch: 2055 [45568/60000 (76%)] Loss: -1363.005615\n",
      "Train Epoch: 2055 [56832/60000 (95%)] Loss: -1434.779297\n",
      "    epoch          : 2055\n",
      "    loss           : -1374.9331582279528\n",
      "Train Epoch: 2056 [512/60000 (1%)] Loss: -1374.134399\n",
      "Train Epoch: 2056 [11776/60000 (20%)] Loss: -1112.029541\n",
      "Train Epoch: 2056 [23040/60000 (38%)] Loss: -1250.363525\n",
      "Train Epoch: 2056 [34304/60000 (57%)] Loss: -1343.116699\n",
      "Train Epoch: 2056 [45568/60000 (76%)] Loss: -1409.563965\n",
      "Train Epoch: 2056 [56832/60000 (95%)] Loss: -1116.015259\n",
      "    epoch          : 2056\n",
      "    loss           : -1353.8663255939375\n",
      "Train Epoch: 2057 [512/60000 (1%)] Loss: -1267.171875\n",
      "Train Epoch: 2057 [11776/60000 (20%)] Loss: -1518.254883\n",
      "Train Epoch: 2057 [23040/60000 (38%)] Loss: -1356.197021\n",
      "Train Epoch: 2057 [34304/60000 (57%)] Loss: -1505.632812\n",
      "Train Epoch: 2057 [45568/60000 (76%)] Loss: -1376.156128\n",
      "Train Epoch: 2057 [56832/60000 (95%)] Loss: -1272.125244\n",
      "    epoch          : 2057\n",
      "    loss           : -1360.3682495806852\n",
      "Train Epoch: 2058 [512/60000 (1%)] Loss: -1551.844971\n",
      "Train Epoch: 2058 [11776/60000 (20%)] Loss: -984.018677\n",
      "Train Epoch: 2058 [23040/60000 (38%)] Loss: -1231.469971\n",
      "Train Epoch: 2058 [34304/60000 (57%)] Loss: -1252.176392\n",
      "Train Epoch: 2058 [45568/60000 (76%)] Loss: -1271.165283\n",
      "Train Epoch: 2058 [56832/60000 (95%)] Loss: -1390.876099\n",
      "    epoch          : 2058\n",
      "    loss           : -1371.189205536061\n",
      "Train Epoch: 2059 [512/60000 (1%)] Loss: -1254.054932\n",
      "Train Epoch: 2059 [11776/60000 (20%)] Loss: -1283.723389\n",
      "Train Epoch: 2059 [23040/60000 (38%)] Loss: -1269.436646\n",
      "Train Epoch: 2059 [34304/60000 (57%)] Loss: -1235.767822\n",
      "Train Epoch: 2059 [45568/60000 (76%)] Loss: -1512.544434\n",
      "Train Epoch: 2059 [56832/60000 (95%)] Loss: -1247.101318\n",
      "    epoch          : 2059\n",
      "    loss           : -1353.9759474932137\n",
      "Train Epoch: 2060 [512/60000 (1%)] Loss: -1396.392456\n",
      "Train Epoch: 2060 [11776/60000 (20%)] Loss: -1482.468872\n",
      "Train Epoch: 2060 [23040/60000 (38%)] Loss: -1538.112793\n",
      "Train Epoch: 2060 [34304/60000 (57%)] Loss: -1387.031006\n",
      "Train Epoch: 2060 [45568/60000 (76%)] Loss: -1285.805908\n",
      "Train Epoch: 2060 [56832/60000 (95%)] Loss: -1549.535645\n",
      "    epoch          : 2060\n",
      "    loss           : -1370.9430390266375\n",
      "Train Epoch: 2061 [512/60000 (1%)] Loss: -1235.234131\n",
      "Train Epoch: 2061 [11776/60000 (20%)] Loss: -1554.805908\n",
      "Train Epoch: 2061 [23040/60000 (38%)] Loss: -1373.863403\n",
      "Train Epoch: 2061 [34304/60000 (57%)] Loss: -1258.008789\n",
      "Train Epoch: 2061 [45568/60000 (76%)] Loss: -1245.418701\n",
      "Train Epoch: 2061 [56832/60000 (95%)] Loss: -1387.350098\n",
      "    epoch          : 2061\n",
      "    loss           : -1371.464559953765\n",
      "Train Epoch: 2062 [512/60000 (1%)] Loss: -1394.938232\n",
      "Train Epoch: 2062 [11776/60000 (20%)] Loss: -1409.254395\n",
      "Train Epoch: 2062 [23040/60000 (38%)] Loss: -1561.113281\n",
      "Train Epoch: 2062 [34304/60000 (57%)] Loss: -1246.550293\n",
      "Train Epoch: 2062 [45568/60000 (76%)] Loss: -1395.776367\n",
      "Train Epoch: 2062 [56832/60000 (95%)] Loss: -1380.774170\n",
      "    epoch          : 2062\n",
      "    loss           : -1358.565990383342\n",
      "Train Epoch: 2063 [512/60000 (1%)] Loss: -1249.461914\n",
      "Train Epoch: 2063 [11776/60000 (20%)] Loss: -1382.296875\n",
      "Train Epoch: 2063 [23040/60000 (38%)] Loss: -1397.706055\n",
      "Train Epoch: 2063 [34304/60000 (57%)] Loss: -1259.463867\n",
      "Train Epoch: 2063 [45568/60000 (76%)] Loss: -1382.872437\n",
      "Train Epoch: 2063 [56832/60000 (95%)] Loss: -1371.629517\n",
      "    epoch          : 2063\n",
      "    loss           : -1353.559018065027\n",
      "Train Epoch: 2064 [512/60000 (1%)] Loss: -1510.975342\n",
      "Train Epoch: 2064 [11776/60000 (20%)] Loss: -1414.504883\n",
      "Train Epoch: 2064 [23040/60000 (38%)] Loss: -1249.251953\n",
      "Train Epoch: 2064 [34304/60000 (57%)] Loss: -1133.038696\n",
      "Train Epoch: 2064 [45568/60000 (76%)] Loss: -1394.224609\n",
      "Train Epoch: 2064 [56832/60000 (95%)] Loss: -1397.923096\n",
      "    epoch          : 2064\n",
      "    loss           : -1365.5435866878531\n",
      "Train Epoch: 2065 [512/60000 (1%)] Loss: -1259.030029\n",
      "Train Epoch: 2065 [11776/60000 (20%)] Loss: -1406.710449\n",
      "Train Epoch: 2065 [23040/60000 (38%)] Loss: -1222.677612\n",
      "Train Epoch: 2065 [34304/60000 (57%)] Loss: -1273.743896\n",
      "Train Epoch: 2065 [45568/60000 (76%)] Loss: -1380.135010\n",
      "Train Epoch: 2065 [56832/60000 (95%)] Loss: -1243.310059\n",
      "    epoch          : 2065\n",
      "    loss           : -1344.095282775534\n",
      "Train Epoch: 2066 [512/60000 (1%)] Loss: -1249.648193\n",
      "Train Epoch: 2066 [11776/60000 (20%)] Loss: -1116.137939\n",
      "Train Epoch: 2066 [23040/60000 (38%)] Loss: -1516.632446\n",
      "Train Epoch: 2066 [34304/60000 (57%)] Loss: -1237.632080\n",
      "Train Epoch: 2066 [45568/60000 (76%)] Loss: -1394.217651\n",
      "Train Epoch: 2066 [56832/60000 (95%)] Loss: -1548.909058\n",
      "    epoch          : 2066\n",
      "    loss           : -1348.0860437080685\n",
      "Train Epoch: 2067 [512/60000 (1%)] Loss: -1112.205444\n",
      "Train Epoch: 2067 [11776/60000 (20%)] Loss: -1541.390869\n",
      "Train Epoch: 2067 [23040/60000 (38%)] Loss: -1232.173340\n",
      "Train Epoch: 2067 [34304/60000 (57%)] Loss: -1104.680420\n",
      "Train Epoch: 2067 [45568/60000 (76%)] Loss: -1380.485962\n",
      "Train Epoch: 2067 [56832/60000 (95%)] Loss: -1526.439331\n",
      "    epoch          : 2067\n",
      "    loss           : -1369.682195113877\n",
      "Train Epoch: 2068 [512/60000 (1%)] Loss: -1125.379639\n",
      "Train Epoch: 2068 [11776/60000 (20%)] Loss: -1571.949707\n",
      "Train Epoch: 2068 [23040/60000 (38%)] Loss: -1525.036621\n",
      "Train Epoch: 2068 [34304/60000 (57%)] Loss: -1269.360474\n",
      "Train Epoch: 2068 [45568/60000 (76%)] Loss: -1397.471191\n",
      "Train Epoch: 2068 [56832/60000 (95%)] Loss: -1264.025513\n",
      "    epoch          : 2068\n",
      "    loss           : -1382.4380151780986\n",
      "Train Epoch: 2069 [512/60000 (1%)] Loss: -1391.243774\n",
      "Train Epoch: 2069 [11776/60000 (20%)] Loss: -1284.084839\n",
      "Train Epoch: 2069 [23040/60000 (38%)] Loss: -1392.507935\n",
      "Train Epoch: 2069 [34304/60000 (57%)] Loss: -1363.626709\n",
      "Train Epoch: 2069 [45568/60000 (76%)] Loss: -1269.436279\n",
      "Train Epoch: 2069 [56832/60000 (95%)] Loss: -1490.543945\n",
      "    epoch          : 2069\n",
      "    loss           : -1360.3376807950985\n",
      "Train Epoch: 2070 [512/60000 (1%)] Loss: -1389.319580\n",
      "Train Epoch: 2070 [11776/60000 (20%)] Loss: -1401.900879\n",
      "Train Epoch: 2070 [23040/60000 (38%)] Loss: -1118.573853\n",
      "Train Epoch: 2070 [34304/60000 (57%)] Loss: -1379.476929\n",
      "Train Epoch: 2070 [45568/60000 (76%)] Loss: -1257.214844\n",
      "Train Epoch: 2070 [56832/60000 (95%)] Loss: -1257.950195\n",
      "    epoch          : 2070\n",
      "    loss           : -1344.0062736899165\n",
      "Train Epoch: 2071 [512/60000 (1%)] Loss: -1400.117188\n",
      "Train Epoch: 2071 [11776/60000 (20%)] Loss: -1374.329834\n",
      "Train Epoch: 2071 [23040/60000 (38%)] Loss: -1512.249756\n",
      "Train Epoch: 2071 [34304/60000 (57%)] Loss: -1152.561768\n",
      "Train Epoch: 2071 [45568/60000 (76%)] Loss: -1404.770996\n",
      "Train Epoch: 2071 [56832/60000 (95%)] Loss: -1396.481445\n",
      "    epoch          : 2071\n",
      "    loss           : -1379.7671088094764\n",
      "Train Epoch: 2072 [512/60000 (1%)] Loss: -1114.964966\n",
      "Train Epoch: 2072 [11776/60000 (20%)] Loss: -1551.345337\n",
      "Train Epoch: 2072 [23040/60000 (38%)] Loss: -1247.438232\n",
      "Train Epoch: 2072 [34304/60000 (57%)] Loss: -1490.549316\n",
      "Train Epoch: 2072 [45568/60000 (76%)] Loss: -1415.620850\n",
      "Train Epoch: 2072 [56832/60000 (95%)] Loss: -1407.765625\n",
      "    epoch          : 2072\n",
      "    loss           : -1362.9738069523526\n",
      "Train Epoch: 2073 [512/60000 (1%)] Loss: -1360.028320\n",
      "Train Epoch: 2073 [11776/60000 (20%)] Loss: -1235.902100\n",
      "Train Epoch: 2073 [23040/60000 (38%)] Loss: -1268.752319\n",
      "Train Epoch: 2073 [34304/60000 (57%)] Loss: -1520.813965\n",
      "Train Epoch: 2073 [45568/60000 (76%)] Loss: -1138.898560\n",
      "Train Epoch: 2073 [56832/60000 (95%)] Loss: -1367.147705\n",
      "    epoch          : 2073\n",
      "    loss           : -1367.9762590483758\n",
      "Train Epoch: 2074 [512/60000 (1%)] Loss: -1269.745728\n",
      "Train Epoch: 2074 [11776/60000 (20%)] Loss: -1371.704590\n",
      "Train Epoch: 2074 [23040/60000 (38%)] Loss: -1274.955566\n",
      "Train Epoch: 2074 [34304/60000 (57%)] Loss: -1520.827393\n",
      "Train Epoch: 2074 [45568/60000 (76%)] Loss: -1261.428711\n",
      "Train Epoch: 2074 [56832/60000 (95%)] Loss: -1259.543701\n",
      "    epoch          : 2074\n",
      "    loss           : -1348.9651889262227\n",
      "Train Epoch: 2075 [512/60000 (1%)] Loss: -1433.224731\n",
      "Train Epoch: 2075 [11776/60000 (20%)] Loss: -1359.864746\n",
      "Train Epoch: 2075 [23040/60000 (38%)] Loss: -1387.768311\n",
      "Train Epoch: 2075 [34304/60000 (57%)] Loss: -1372.521118\n",
      "Train Epoch: 2075 [45568/60000 (76%)] Loss: -1524.508179\n",
      "Train Epoch: 2075 [56832/60000 (95%)] Loss: -1555.531982\n",
      "    epoch          : 2075\n",
      "    loss           : -1380.3963771324372\n",
      "Train Epoch: 2076 [512/60000 (1%)] Loss: -1512.661865\n",
      "Train Epoch: 2076 [11776/60000 (20%)] Loss: -1349.899902\n",
      "Train Epoch: 2076 [23040/60000 (38%)] Loss: -1268.231812\n",
      "Train Epoch: 2076 [34304/60000 (57%)] Loss: -1266.479980\n",
      "Train Epoch: 2076 [45568/60000 (76%)] Loss: -1374.496216\n",
      "Train Epoch: 2076 [56832/60000 (95%)] Loss: -1246.931519\n",
      "    epoch          : 2076\n",
      "    loss           : -1380.3735755015227\n",
      "Train Epoch: 2077 [512/60000 (1%)] Loss: -1270.552368\n",
      "Train Epoch: 2077 [11776/60000 (20%)] Loss: -1274.843506\n",
      "Train Epoch: 2077 [23040/60000 (38%)] Loss: -1520.856567\n",
      "Train Epoch: 2077 [34304/60000 (57%)] Loss: -1510.358643\n",
      "Train Epoch: 2077 [45568/60000 (76%)] Loss: -1561.764648\n",
      "Train Epoch: 2077 [56832/60000 (95%)] Loss: -1221.116211\n",
      "    epoch          : 2077\n",
      "    loss           : -1370.8477129747637\n",
      "Train Epoch: 2078 [512/60000 (1%)] Loss: -1403.790771\n",
      "Train Epoch: 2078 [11776/60000 (20%)] Loss: -1546.600708\n",
      "Train Epoch: 2078 [23040/60000 (38%)] Loss: -1252.296021\n",
      "Train Epoch: 2078 [34304/60000 (57%)] Loss: -1264.095459\n",
      "Train Epoch: 2078 [45568/60000 (76%)] Loss: -1390.613281\n",
      "Train Epoch: 2078 [56832/60000 (95%)] Loss: -1417.433594\n",
      "    epoch          : 2078\n",
      "    loss           : -1372.482387909108\n",
      "Train Epoch: 2079 [512/60000 (1%)] Loss: -1123.720825\n",
      "Train Epoch: 2079 [11776/60000 (20%)] Loss: -1249.265869\n",
      "Train Epoch: 2079 [23040/60000 (38%)] Loss: -1391.408691\n",
      "Train Epoch: 2079 [34304/60000 (57%)] Loss: -1382.140747\n",
      "Train Epoch: 2079 [45568/60000 (76%)] Loss: -1557.080322\n",
      "Train Epoch: 2079 [56832/60000 (95%)] Loss: -1393.232422\n",
      "    epoch          : 2079\n",
      "    loss           : -1357.3891063625529\n",
      "Train Epoch: 2080 [512/60000 (1%)] Loss: -1144.628052\n",
      "Train Epoch: 2080 [11776/60000 (20%)] Loss: -1292.498901\n",
      "Train Epoch: 2080 [23040/60000 (38%)] Loss: -1248.614014\n",
      "Train Epoch: 2080 [34304/60000 (57%)] Loss: -1407.126099\n",
      "Train Epoch: 2080 [45568/60000 (76%)] Loss: -1421.693359\n",
      "Train Epoch: 2080 [56832/60000 (95%)] Loss: -1351.627930\n",
      "    epoch          : 2080\n",
      "    loss           : -1358.9930740615068\n",
      "Train Epoch: 2081 [512/60000 (1%)] Loss: -1392.673950\n",
      "Train Epoch: 2081 [11776/60000 (20%)] Loss: -1272.359253\n",
      "Train Epoch: 2081 [23040/60000 (38%)] Loss: -1273.314941\n",
      "Train Epoch: 2081 [34304/60000 (57%)] Loss: -1365.017578\n",
      "Train Epoch: 2081 [45568/60000 (76%)] Loss: -1537.395996\n",
      "Train Epoch: 2081 [56832/60000 (95%)] Loss: -1491.504272\n",
      "    epoch          : 2081\n",
      "    loss           : -1365.0081362966764\n",
      "Train Epoch: 2082 [512/60000 (1%)] Loss: -1501.291748\n",
      "Train Epoch: 2082 [11776/60000 (20%)] Loss: -1341.572021\n",
      "Train Epoch: 2082 [23040/60000 (38%)] Loss: -1400.936768\n",
      "Train Epoch: 2082 [34304/60000 (57%)] Loss: -1523.948608\n",
      "Train Epoch: 2082 [45568/60000 (76%)] Loss: -1257.782471\n",
      "Train Epoch: 2082 [56832/60000 (95%)] Loss: -1425.346313\n",
      "    epoch          : 2082\n",
      "    loss           : -1365.914259053893\n",
      "Train Epoch: 2083 [512/60000 (1%)] Loss: -1242.292358\n",
      "Train Epoch: 2083 [11776/60000 (20%)] Loss: -1403.953369\n",
      "Train Epoch: 2083 [23040/60000 (38%)] Loss: -1372.640381\n",
      "Train Epoch: 2083 [34304/60000 (57%)] Loss: -1403.404785\n",
      "Train Epoch: 2083 [45568/60000 (76%)] Loss: -1238.066650\n",
      "Train Epoch: 2083 [56832/60000 (95%)] Loss: -1223.515259\n",
      "    epoch          : 2083\n",
      "    loss           : -1371.5375311037915\n",
      "Train Epoch: 2084 [512/60000 (1%)] Loss: -1268.086060\n",
      "Train Epoch: 2084 [11776/60000 (20%)] Loss: -1584.657959\n",
      "Train Epoch: 2084 [23040/60000 (38%)] Loss: -1117.727783\n",
      "Train Epoch: 2084 [34304/60000 (57%)] Loss: -1525.591919\n",
      "Train Epoch: 2084 [45568/60000 (76%)] Loss: -1358.214355\n",
      "Train Epoch: 2084 [56832/60000 (95%)] Loss: -1414.699341\n",
      "    epoch          : 2084\n",
      "    loss           : -1373.2330205022952\n",
      "Train Epoch: 2085 [512/60000 (1%)] Loss: -1237.980713\n",
      "Train Epoch: 2085 [11776/60000 (20%)] Loss: -1270.098755\n",
      "Train Epoch: 2085 [23040/60000 (38%)] Loss: -1387.054810\n",
      "Train Epoch: 2085 [34304/60000 (57%)] Loss: -1226.879761\n",
      "Train Epoch: 2085 [45568/60000 (76%)] Loss: -1375.698242\n",
      "Train Epoch: 2085 [56832/60000 (95%)] Loss: -1533.204468\n",
      "    epoch          : 2085\n",
      "    loss           : -1387.941035211423\n",
      "Train Epoch: 2086 [512/60000 (1%)] Loss: -1274.605713\n",
      "Train Epoch: 2086 [11776/60000 (20%)] Loss: -1521.755005\n",
      "Train Epoch: 2086 [23040/60000 (38%)] Loss: -1393.193115\n",
      "Train Epoch: 2086 [34304/60000 (57%)] Loss: -1422.389771\n",
      "Train Epoch: 2086 [45568/60000 (76%)] Loss: -1255.352661\n",
      "Train Epoch: 2086 [56832/60000 (95%)] Loss: -1233.967407\n",
      "    epoch          : 2086\n",
      "    loss           : -1354.7269935392392\n",
      "Train Epoch: 2087 [512/60000 (1%)] Loss: -1374.347534\n",
      "Train Epoch: 2087 [11776/60000 (20%)] Loss: -1364.926392\n",
      "Train Epoch: 2087 [23040/60000 (38%)] Loss: -1560.400879\n",
      "Train Epoch: 2087 [34304/60000 (57%)] Loss: -1276.240234\n",
      "Train Epoch: 2087 [45568/60000 (76%)] Loss: -1361.033081\n",
      "Train Epoch: 2087 [56832/60000 (95%)] Loss: -1414.459106\n",
      "    epoch          : 2087\n",
      "    loss           : -1366.5917720471398\n",
      "Train Epoch: 2088 [512/60000 (1%)] Loss: -1358.786987\n",
      "Train Epoch: 2088 [11776/60000 (20%)] Loss: -1556.207153\n",
      "Train Epoch: 2088 [23040/60000 (38%)] Loss: -1576.761230\n",
      "Train Epoch: 2088 [34304/60000 (57%)] Loss: -1528.837280\n",
      "Train Epoch: 2088 [45568/60000 (76%)] Loss: -1377.855225\n",
      "Train Epoch: 2088 [56832/60000 (95%)] Loss: -1399.533203\n",
      "    epoch          : 2088\n",
      "    loss           : -1355.8034661072122\n",
      "Train Epoch: 2089 [512/60000 (1%)] Loss: -1279.859375\n",
      "Train Epoch: 2089 [11776/60000 (20%)] Loss: -1239.066284\n",
      "Train Epoch: 2089 [23040/60000 (38%)] Loss: -1250.390869\n",
      "Train Epoch: 2089 [34304/60000 (57%)] Loss: -1534.312866\n",
      "Train Epoch: 2089 [45568/60000 (76%)] Loss: -1398.648438\n",
      "Train Epoch: 2089 [56832/60000 (95%)] Loss: -1397.666748\n",
      "    epoch          : 2089\n",
      "    loss           : -1353.271937483448\n",
      "Train Epoch: 2090 [512/60000 (1%)] Loss: -1286.676758\n",
      "Train Epoch: 2090 [11776/60000 (20%)] Loss: -1518.470947\n",
      "Train Epoch: 2090 [23040/60000 (38%)] Loss: -1255.207764\n",
      "Train Epoch: 2090 [34304/60000 (57%)] Loss: -1391.565063\n",
      "Train Epoch: 2090 [45568/60000 (76%)] Loss: -1514.667725\n",
      "Train Epoch: 2090 [56832/60000 (95%)] Loss: -1573.303711\n",
      "    epoch          : 2090\n",
      "    loss           : -1354.3329478118378\n",
      "Train Epoch: 2091 [512/60000 (1%)] Loss: -1429.525146\n",
      "Train Epoch: 2091 [11776/60000 (20%)] Loss: -1552.665894\n",
      "Train Epoch: 2091 [23040/60000 (38%)] Loss: -1549.565430\n",
      "Train Epoch: 2091 [34304/60000 (57%)] Loss: -1561.247559\n",
      "Train Epoch: 2091 [45568/60000 (76%)] Loss: -1545.453125\n",
      "Train Epoch: 2091 [56832/60000 (95%)] Loss: -1364.881226\n",
      "    epoch          : 2091\n",
      "    loss           : -1366.8787407309321\n",
      "Train Epoch: 2092 [512/60000 (1%)] Loss: -1147.211914\n",
      "Train Epoch: 2092 [11776/60000 (20%)] Loss: -1384.698730\n",
      "Train Epoch: 2092 [23040/60000 (38%)] Loss: -1512.042480\n",
      "Train Epoch: 2092 [34304/60000 (57%)] Loss: -1384.637451\n",
      "Train Epoch: 2092 [45568/60000 (76%)] Loss: -1259.662842\n",
      "Train Epoch: 2092 [56832/60000 (95%)] Loss: -1405.856201\n",
      "    epoch          : 2092\n",
      "    loss           : -1368.231343242408\n",
      "Train Epoch: 2093 [512/60000 (1%)] Loss: -1389.228027\n",
      "Train Epoch: 2093 [11776/60000 (20%)] Loss: -1400.192505\n",
      "Train Epoch: 2093 [23040/60000 (38%)] Loss: -1550.493652\n",
      "Train Epoch: 2093 [34304/60000 (57%)] Loss: -1411.207153\n",
      "Train Epoch: 2093 [45568/60000 (76%)] Loss: -1561.507568\n",
      "Train Epoch: 2093 [56832/60000 (95%)] Loss: -1406.558838\n",
      "    epoch          : 2093\n",
      "    loss           : -1374.3890348100392\n",
      "Train Epoch: 2094 [512/60000 (1%)] Loss: -1409.150635\n",
      "Train Epoch: 2094 [11776/60000 (20%)] Loss: -1416.232910\n",
      "Train Epoch: 2094 [23040/60000 (38%)] Loss: -1405.231689\n",
      "Train Epoch: 2094 [34304/60000 (57%)] Loss: -1437.293457\n",
      "Train Epoch: 2094 [45568/60000 (76%)] Loss: -1401.021973\n",
      "Train Epoch: 2094 [56832/60000 (95%)] Loss: -1418.967651\n",
      "    epoch          : 2094\n",
      "    loss           : -1382.3443893173994\n",
      "Train Epoch: 2095 [512/60000 (1%)] Loss: -1405.108276\n",
      "Train Epoch: 2095 [11776/60000 (20%)] Loss: -1494.847900\n",
      "Train Epoch: 2095 [23040/60000 (38%)] Loss: -1510.450684\n",
      "Train Epoch: 2095 [34304/60000 (57%)] Loss: -1278.303955\n",
      "Train Epoch: 2095 [45568/60000 (76%)] Loss: -1255.246704\n",
      "Train Epoch: 2095 [56832/60000 (95%)] Loss: -1427.729614\n",
      "    epoch          : 2095\n",
      "    loss           : -1385.8561032397597\n",
      "Train Epoch: 2096 [512/60000 (1%)] Loss: -1373.245117\n",
      "Train Epoch: 2096 [11776/60000 (20%)] Loss: -1473.792969\n",
      "Train Epoch: 2096 [23040/60000 (38%)] Loss: -1483.906372\n",
      "Train Epoch: 2096 [34304/60000 (57%)] Loss: -1376.972046\n",
      "Train Epoch: 2096 [45568/60000 (76%)] Loss: -1505.420044\n",
      "Train Epoch: 2096 [56832/60000 (95%)] Loss: -1520.875854\n",
      "    epoch          : 2096\n",
      "    loss           : -1376.7870883402852\n",
      "Train Epoch: 2097 [512/60000 (1%)] Loss: -1104.046387\n",
      "Train Epoch: 2097 [11776/60000 (20%)] Loss: -1529.355225\n",
      "Train Epoch: 2097 [23040/60000 (38%)] Loss: -1575.465332\n",
      "Train Epoch: 2097 [34304/60000 (57%)] Loss: -1249.290161\n",
      "Train Epoch: 2097 [45568/60000 (76%)] Loss: -1260.076782\n",
      "Train Epoch: 2097 [56832/60000 (95%)] Loss: -1388.532715\n",
      "    epoch          : 2097\n",
      "    loss           : -1347.912104892192\n",
      "Train Epoch: 2098 [512/60000 (1%)] Loss: -1542.152100\n",
      "Train Epoch: 2098 [11776/60000 (20%)] Loss: -1394.017700\n",
      "Train Epoch: 2098 [23040/60000 (38%)] Loss: -1523.633545\n",
      "Train Epoch: 2098 [34304/60000 (57%)] Loss: -1397.003296\n",
      "Train Epoch: 2098 [45568/60000 (76%)] Loss: -1226.016357\n",
      "Train Epoch: 2098 [56832/60000 (95%)] Loss: -1149.872314\n",
      "    epoch          : 2098\n",
      "    loss           : -1362.4249245164083\n",
      "Train Epoch: 2099 [512/60000 (1%)] Loss: -1369.545654\n",
      "Train Epoch: 2099 [11776/60000 (20%)] Loss: -1530.637695\n",
      "Train Epoch: 2099 [23040/60000 (38%)] Loss: -1263.279053\n",
      "Train Epoch: 2099 [34304/60000 (57%)] Loss: -990.296143\n",
      "Train Epoch: 2099 [45568/60000 (76%)] Loss: -1243.363037\n",
      "Train Epoch: 2099 [56832/60000 (95%)] Loss: -1399.697510\n",
      "    epoch          : 2099\n",
      "    loss           : -1366.299972965219\n",
      "Train Epoch: 2100 [512/60000 (1%)] Loss: -1529.549805\n",
      "Train Epoch: 2100 [11776/60000 (20%)] Loss: -1236.203979\n",
      "Train Epoch: 2100 [23040/60000 (38%)] Loss: -1410.859131\n",
      "Train Epoch: 2100 [34304/60000 (57%)] Loss: -1270.929810\n",
      "Train Epoch: 2100 [45568/60000 (76%)] Loss: -1415.252197\n",
      "Train Epoch: 2100 [56832/60000 (95%)] Loss: -1380.124023\n",
      "    epoch          : 2100\n",
      "    loss           : -1369.0542785299701\n",
      "Saving checkpoint: saved/models/Mnist_DeepGenerativeOperad/0127_111843/checkpoint-epoch2100.pth ...\n",
      "Train Epoch: 2101 [512/60000 (1%)] Loss: -1137.578979\n",
      "Train Epoch: 2101 [11776/60000 (20%)] Loss: -983.307922\n",
      "Train Epoch: 2101 [23040/60000 (38%)] Loss: -1426.080566\n",
      "Train Epoch: 2101 [34304/60000 (57%)] Loss: -1423.574341\n",
      "Train Epoch: 2101 [45568/60000 (76%)] Loss: -1253.035156\n",
      "Train Epoch: 2101 [56832/60000 (95%)] Loss: -1395.015015\n",
      "    epoch          : 2101\n",
      "    loss           : -1372.6428989906096\n",
      "Train Epoch: 2102 [512/60000 (1%)] Loss: -1395.811035\n",
      "Train Epoch: 2102 [11776/60000 (20%)] Loss: -1417.983521\n",
      "Train Epoch: 2102 [23040/60000 (38%)] Loss: -1360.149902\n",
      "Train Epoch: 2102 [34304/60000 (57%)] Loss: -1568.211914\n",
      "Train Epoch: 2102 [45568/60000 (76%)] Loss: -1538.396484\n",
      "Train Epoch: 2102 [56832/60000 (95%)] Loss: -1402.021729\n",
      "    epoch          : 2102\n",
      "    loss           : -1380.8532242424744\n",
      "Train Epoch: 2103 [512/60000 (1%)] Loss: -1380.524780\n",
      "Train Epoch: 2103 [11776/60000 (20%)] Loss: -1543.180664\n",
      "Train Epoch: 2103 [23040/60000 (38%)] Loss: -1360.756104\n",
      "Train Epoch: 2103 [34304/60000 (57%)] Loss: -1361.471680\n",
      "Train Epoch: 2103 [45568/60000 (76%)] Loss: -1256.805176\n",
      "Train Epoch: 2103 [56832/60000 (95%)] Loss: -1579.883179\n",
      "    epoch          : 2103\n",
      "    loss           : -1388.867706471244\n",
      "Train Epoch: 2104 [512/60000 (1%)] Loss: -1542.519897\n",
      "Train Epoch: 2104 [11776/60000 (20%)] Loss: -1513.885498\n",
      "Train Epoch: 2104 [23040/60000 (38%)] Loss: -1531.886230\n",
      "Train Epoch: 2104 [34304/60000 (57%)] Loss: -1533.419678\n",
      "Train Epoch: 2104 [45568/60000 (76%)] Loss: -1255.979858\n",
      "Train Epoch: 2104 [56832/60000 (95%)] Loss: -1389.973999\n",
      "    epoch          : 2104\n",
      "    loss           : -1390.9477466647909\n",
      "Train Epoch: 2105 [512/60000 (1%)] Loss: -1547.627075\n",
      "Train Epoch: 2105 [11776/60000 (20%)] Loss: -1514.205444\n",
      "Train Epoch: 2105 [23040/60000 (38%)] Loss: -1161.906494\n",
      "Train Epoch: 2105 [34304/60000 (57%)] Loss: -1377.835327\n",
      "Train Epoch: 2105 [45568/60000 (76%)] Loss: -1365.322754\n",
      "Train Epoch: 2105 [56832/60000 (95%)] Loss: -1563.659912\n",
      "    epoch          : 2105\n",
      "    loss           : -1371.2378140034648\n",
      "Train Epoch: 2106 [512/60000 (1%)] Loss: -1296.986206\n",
      "Train Epoch: 2106 [11776/60000 (20%)] Loss: -1407.710083\n",
      "Train Epoch: 2106 [23040/60000 (38%)] Loss: -1397.467651\n",
      "Train Epoch: 2106 [34304/60000 (57%)] Loss: -1571.785278\n",
      "Train Epoch: 2106 [45568/60000 (76%)] Loss: -1274.163208\n",
      "Train Epoch: 2106 [56832/60000 (95%)] Loss: -1413.132446\n",
      "    epoch          : 2106\n",
      "    loss           : -1373.5019760562875\n",
      "Train Epoch: 2107 [512/60000 (1%)] Loss: -1276.675903\n",
      "Train Epoch: 2107 [11776/60000 (20%)] Loss: -1550.890625\n",
      "Train Epoch: 2107 [23040/60000 (38%)] Loss: -1287.110840\n",
      "Train Epoch: 2107 [34304/60000 (57%)] Loss: -1420.272949\n",
      "Train Epoch: 2107 [45568/60000 (76%)] Loss: -1293.587402\n",
      "Train Epoch: 2107 [56832/60000 (95%)] Loss: -1529.879639\n",
      "    epoch          : 2107\n",
      "    loss           : -1381.8162265928452\n",
      "Train Epoch: 2108 [512/60000 (1%)] Loss: -1425.191406\n",
      "Train Epoch: 2108 [11776/60000 (20%)] Loss: -1353.658203\n",
      "Train Epoch: 2108 [23040/60000 (38%)] Loss: -1279.524902\n",
      "Train Epoch: 2108 [34304/60000 (57%)] Loss: -1403.861938\n",
      "Train Epoch: 2108 [45568/60000 (76%)] Loss: -1527.811035\n",
      "Train Epoch: 2108 [56832/60000 (95%)] Loss: -1248.950684\n",
      "    epoch          : 2108\n",
      "    loss           : -1370.4202806720625\n",
      "Train Epoch: 2109 [512/60000 (1%)] Loss: -1267.242432\n",
      "Train Epoch: 2109 [11776/60000 (20%)] Loss: -1568.691650\n",
      "Train Epoch: 2109 [23040/60000 (38%)] Loss: -1500.140991\n",
      "Train Epoch: 2109 [34304/60000 (57%)] Loss: -1394.847778\n",
      "Train Epoch: 2109 [45568/60000 (76%)] Loss: -1512.122070\n",
      "Train Epoch: 2109 [56832/60000 (95%)] Loss: -1506.554443\n",
      "    epoch          : 2109\n",
      "    loss           : -1379.3047926735744\n",
      "Train Epoch: 2110 [512/60000 (1%)] Loss: -1549.814575\n",
      "Train Epoch: 2110 [11776/60000 (20%)] Loss: -1295.232910\n",
      "Train Epoch: 2110 [23040/60000 (38%)] Loss: -1251.940552\n",
      "Train Epoch: 2110 [34304/60000 (57%)] Loss: -1164.973999\n",
      "Train Epoch: 2110 [45568/60000 (76%)] Loss: -1559.610596\n",
      "Train Epoch: 2110 [56832/60000 (95%)] Loss: -1541.429932\n",
      "    epoch          : 2110\n",
      "    loss           : -1385.067966956877\n",
      "Train Epoch: 2111 [512/60000 (1%)] Loss: -1516.928955\n",
      "Train Epoch: 2111 [11776/60000 (20%)] Loss: -1531.351440\n",
      "Train Epoch: 2111 [23040/60000 (38%)] Loss: -1418.993408\n",
      "Train Epoch: 2111 [34304/60000 (57%)] Loss: -1381.579102\n",
      "Train Epoch: 2111 [45568/60000 (76%)] Loss: -1300.642456\n",
      "Train Epoch: 2111 [56832/60000 (95%)] Loss: -1413.919189\n",
      "    epoch          : 2111\n",
      "    loss           : -1393.5019289868028\n",
      "Train Epoch: 2112 [512/60000 (1%)] Loss: -1550.023193\n",
      "Train Epoch: 2112 [11776/60000 (20%)] Loss: -1305.360596\n",
      "Train Epoch: 2112 [23040/60000 (38%)] Loss: -1276.801758\n",
      "Train Epoch: 2112 [34304/60000 (57%)] Loss: -1517.768555\n",
      "Train Epoch: 2112 [45568/60000 (76%)] Loss: -1403.260010\n",
      "Train Epoch: 2112 [56832/60000 (95%)] Loss: -1550.102051\n",
      "    epoch          : 2112\n",
      "    loss           : -1376.0458339540298\n",
      "Train Epoch: 2113 [512/60000 (1%)] Loss: -1244.578125\n",
      "Train Epoch: 2113 [11776/60000 (20%)] Loss: -1419.655396\n",
      "Train Epoch: 2113 [23040/60000 (38%)] Loss: -1550.683350\n",
      "Train Epoch: 2113 [34304/60000 (57%)] Loss: -1253.232178\n",
      "Train Epoch: 2113 [45568/60000 (76%)] Loss: -1417.269287\n",
      "Train Epoch: 2113 [56832/60000 (95%)] Loss: -1563.179321\n",
      "    epoch          : 2113\n",
      "    loss           : -1386.8659176584017\n",
      "Train Epoch: 2114 [512/60000 (1%)] Loss: -1231.627930\n",
      "Train Epoch: 2114 [11776/60000 (20%)] Loss: -1413.541748\n",
      "Train Epoch: 2114 [23040/60000 (38%)] Loss: -1504.208496\n",
      "Train Epoch: 2114 [34304/60000 (57%)] Loss: -1390.105469\n",
      "Train Epoch: 2114 [45568/60000 (76%)] Loss: -1273.481689\n",
      "Train Epoch: 2114 [56832/60000 (95%)] Loss: -1259.756714\n",
      "    epoch          : 2114\n",
      "    loss           : -1380.9334558174435\n",
      "Train Epoch: 2115 [512/60000 (1%)] Loss: -1243.008545\n",
      "Train Epoch: 2115 [11776/60000 (20%)] Loss: -1377.984985\n",
      "Train Epoch: 2115 [23040/60000 (38%)] Loss: -1271.182861\n",
      "Train Epoch: 2115 [34304/60000 (57%)] Loss: -1388.071533\n",
      "Train Epoch: 2115 [45568/60000 (76%)] Loss: -1293.081055\n",
      "Train Epoch: 2115 [56832/60000 (95%)] Loss: -1403.220215\n",
      "    epoch          : 2115\n",
      "    loss           : -1361.2678917491505\n",
      "Train Epoch: 2116 [512/60000 (1%)] Loss: -1404.128418\n",
      "Train Epoch: 2116 [11776/60000 (20%)] Loss: -1373.690796\n",
      "Train Epoch: 2116 [23040/60000 (38%)] Loss: -1410.094482\n",
      "Train Epoch: 2116 [34304/60000 (57%)] Loss: -1291.029663\n",
      "Train Epoch: 2116 [45568/60000 (76%)] Loss: -1382.348755\n",
      "Train Epoch: 2116 [56832/60000 (95%)] Loss: -1566.065308\n",
      "    epoch          : 2116\n",
      "    loss           : -1365.6673618467514\n",
      "Train Epoch: 2117 [512/60000 (1%)] Loss: -1401.806519\n",
      "Train Epoch: 2117 [11776/60000 (20%)] Loss: -1411.672852\n",
      "Train Epoch: 2117 [23040/60000 (38%)] Loss: -1273.757690\n",
      "Train Epoch: 2117 [34304/60000 (57%)] Loss: -1373.600586\n",
      "Train Epoch: 2117 [45568/60000 (76%)] Loss: -1525.586670\n",
      "Train Epoch: 2117 [56832/60000 (95%)] Loss: -1386.281738\n",
      "    epoch          : 2117\n",
      "    loss           : -1393.694675768836\n",
      "Train Epoch: 2118 [512/60000 (1%)] Loss: -1514.539551\n",
      "Train Epoch: 2118 [11776/60000 (20%)] Loss: -1284.624878\n",
      "Train Epoch: 2118 [23040/60000 (38%)] Loss: -1408.934570\n",
      "Train Epoch: 2118 [34304/60000 (57%)] Loss: -1422.124023\n",
      "Train Epoch: 2118 [45568/60000 (76%)] Loss: -1525.908813\n",
      "Train Epoch: 2118 [56832/60000 (95%)] Loss: -1518.280273\n",
      "    epoch          : 2118\n",
      "    loss           : -1381.0461622335142\n",
      "Train Epoch: 2119 [512/60000 (1%)] Loss: -1390.415405\n",
      "Train Epoch: 2119 [11776/60000 (20%)] Loss: -1372.211060\n",
      "Train Epoch: 2119 [23040/60000 (38%)] Loss: -1527.909302\n",
      "Train Epoch: 2119 [34304/60000 (57%)] Loss: -1268.147949\n",
      "Train Epoch: 2119 [45568/60000 (76%)] Loss: -1246.696899\n",
      "Train Epoch: 2119 [56832/60000 (95%)] Loss: -1282.319458\n",
      "    epoch          : 2119\n",
      "    loss           : -1382.9081517451227\n",
      "Train Epoch: 2120 [512/60000 (1%)] Loss: -1398.776855\n",
      "Train Epoch: 2120 [11776/60000 (20%)] Loss: -1380.873047\n",
      "Train Epoch: 2120 [23040/60000 (38%)] Loss: -1534.331055\n",
      "Train Epoch: 2120 [34304/60000 (57%)] Loss: -1380.948242\n",
      "Train Epoch: 2120 [45568/60000 (76%)] Loss: -1419.145752\n",
      "Train Epoch: 2120 [56832/60000 (95%)] Loss: -1272.410400\n",
      "    epoch          : 2120\n",
      "    loss           : -1365.9352937687588\n",
      "Train Epoch: 2121 [512/60000 (1%)] Loss: -1146.498291\n",
      "Train Epoch: 2121 [11776/60000 (20%)] Loss: -1411.848999\n",
      "Train Epoch: 2121 [23040/60000 (38%)] Loss: -1416.026001\n",
      "Train Epoch: 2121 [34304/60000 (57%)] Loss: -1435.914062\n",
      "Train Epoch: 2121 [45568/60000 (76%)] Loss: -1223.042114\n",
      "Train Epoch: 2121 [56832/60000 (95%)] Loss: -1141.917603\n",
      "    epoch          : 2121\n",
      "    loss           : -1363.5560106180483\n",
      "Train Epoch: 2122 [512/60000 (1%)] Loss: -1525.026001\n",
      "Train Epoch: 2122 [11776/60000 (20%)] Loss: -1265.788818\n",
      "Train Epoch: 2122 [23040/60000 (38%)] Loss: -1290.296753\n",
      "Train Epoch: 2122 [34304/60000 (57%)] Loss: -1390.151611\n",
      "Train Epoch: 2122 [45568/60000 (76%)] Loss: -1366.979980\n",
      "Train Epoch: 2122 [56832/60000 (95%)] Loss: -1250.659546\n",
      "    epoch          : 2122\n",
      "    loss           : -1379.531915524585\n",
      "Train Epoch: 2123 [512/60000 (1%)] Loss: -1567.483643\n",
      "Train Epoch: 2123 [11776/60000 (20%)] Loss: -1352.056030\n",
      "Train Epoch: 2123 [23040/60000 (38%)] Loss: -1278.346924\n",
      "Train Epoch: 2123 [34304/60000 (57%)] Loss: -1420.203857\n",
      "Train Epoch: 2123 [45568/60000 (76%)] Loss: -1530.307739\n",
      "Train Epoch: 2123 [56832/60000 (95%)] Loss: -1524.682617\n",
      "    epoch          : 2123\n",
      "    loss           : -1369.9528824111162\n",
      "Train Epoch: 2124 [512/60000 (1%)] Loss: -1415.879761\n",
      "Train Epoch: 2124 [11776/60000 (20%)] Loss: -1146.310303\n",
      "Train Epoch: 2124 [23040/60000 (38%)] Loss: -1520.571167\n",
      "Train Epoch: 2124 [34304/60000 (57%)] Loss: -1529.297729\n",
      "Train Epoch: 2124 [45568/60000 (76%)] Loss: -1379.135742\n",
      "Train Epoch: 2124 [56832/60000 (95%)] Loss: -1254.242554\n",
      "    epoch          : 2124\n",
      "    loss           : -1384.4809030651372\n",
      "Train Epoch: 2125 [512/60000 (1%)] Loss: -1542.148926\n",
      "Train Epoch: 2125 [11776/60000 (20%)] Loss: -1416.135010\n",
      "Train Epoch: 2125 [23040/60000 (38%)] Loss: -1364.403076\n",
      "Train Epoch: 2125 [34304/60000 (57%)] Loss: -1128.867432\n",
      "Train Epoch: 2125 [45568/60000 (76%)] Loss: -1415.250977\n",
      "Train Epoch: 2125 [56832/60000 (95%)] Loss: -1409.965088\n",
      "    epoch          : 2125\n",
      "    loss           : -1367.69854701845\n",
      "Train Epoch: 2126 [512/60000 (1%)] Loss: -1389.617920\n",
      "Train Epoch: 2126 [11776/60000 (20%)] Loss: -1136.828369\n",
      "Train Epoch: 2126 [23040/60000 (38%)] Loss: -1289.385010\n",
      "Train Epoch: 2126 [34304/60000 (57%)] Loss: -1289.384521\n",
      "Train Epoch: 2126 [45568/60000 (76%)] Loss: -1285.868408\n",
      "Train Epoch: 2126 [56832/60000 (95%)] Loss: -1378.705078\n",
      "    epoch          : 2126\n",
      "    loss           : -1390.2872567904199\n",
      "Train Epoch: 2127 [512/60000 (1%)] Loss: -1390.293945\n",
      "Train Epoch: 2127 [11776/60000 (20%)] Loss: -1146.930176\n",
      "Train Epoch: 2127 [23040/60000 (38%)] Loss: -1518.688599\n",
      "Train Epoch: 2127 [34304/60000 (57%)] Loss: -1406.927734\n",
      "Train Epoch: 2127 [45568/60000 (76%)] Loss: -1165.705933\n",
      "Train Epoch: 2127 [56832/60000 (95%)] Loss: -1533.450073\n",
      "    epoch          : 2127\n",
      "    loss           : -1396.7858131538003\n",
      "Train Epoch: 2128 [512/60000 (1%)] Loss: -1385.390869\n",
      "Train Epoch: 2128 [11776/60000 (20%)] Loss: -1516.098267\n",
      "Train Epoch: 2128 [23040/60000 (38%)] Loss: -1392.118286\n",
      "Train Epoch: 2128 [34304/60000 (57%)] Loss: -1367.901611\n",
      "Train Epoch: 2128 [45568/60000 (76%)] Loss: -1023.935730\n",
      "Train Epoch: 2128 [56832/60000 (95%)] Loss: -1427.409424\n",
      "    epoch          : 2128\n",
      "    loss           : -1380.5223204187082\n",
      "Train Epoch: 2129 [512/60000 (1%)] Loss: -1389.840576\n",
      "Train Epoch: 2129 [11776/60000 (20%)] Loss: -1529.722412\n",
      "Train Epoch: 2129 [23040/60000 (38%)] Loss: -1390.952637\n",
      "Train Epoch: 2129 [34304/60000 (57%)] Loss: -1554.415771\n",
      "Train Epoch: 2129 [45568/60000 (76%)] Loss: -1434.859741\n",
      "Train Epoch: 2129 [56832/60000 (95%)] Loss: -1410.497070\n",
      "    epoch          : 2129\n",
      "    loss           : -1397.274222508662\n",
      "Train Epoch: 2130 [512/60000 (1%)] Loss: -1272.130981\n",
      "Train Epoch: 2130 [11776/60000 (20%)] Loss: -1422.708984\n",
      "Train Epoch: 2130 [23040/60000 (38%)] Loss: -1306.552246\n",
      "Train Epoch: 2130 [34304/60000 (57%)] Loss: -1261.706421\n",
      "Train Epoch: 2130 [45568/60000 (76%)] Loss: -1510.715332\n",
      "Train Epoch: 2130 [56832/60000 (95%)] Loss: -1481.928223\n",
      "    epoch          : 2130\n",
      "    loss           : -1378.125945872506\n",
      "Train Epoch: 2131 [512/60000 (1%)] Loss: -1012.286621\n",
      "Train Epoch: 2131 [11776/60000 (20%)] Loss: -1542.127441\n",
      "Train Epoch: 2131 [23040/60000 (38%)] Loss: -1239.051758\n",
      "Train Epoch: 2131 [34304/60000 (57%)] Loss: -1259.552612\n",
      "Train Epoch: 2131 [45568/60000 (76%)] Loss: -1411.191406\n",
      "Train Epoch: 2131 [56832/60000 (95%)] Loss: -1408.467529\n",
      "    epoch          : 2131\n",
      "    loss           : -1373.6574924275026\n",
      "Train Epoch: 2132 [512/60000 (1%)] Loss: -1409.711914\n",
      "Train Epoch: 2132 [11776/60000 (20%)] Loss: -1419.069824\n",
      "Train Epoch: 2132 [23040/60000 (38%)] Loss: -1436.513184\n",
      "Train Epoch: 2132 [34304/60000 (57%)] Loss: -1385.433594\n",
      "Train Epoch: 2132 [45568/60000 (76%)] Loss: -1147.744263\n",
      "Train Epoch: 2132 [56832/60000 (95%)] Loss: -1161.712036\n",
      "    epoch          : 2132\n",
      "    loss           : -1372.7761223572122\n",
      "Train Epoch: 2133 [512/60000 (1%)] Loss: -1374.391968\n",
      "Train Epoch: 2133 [11776/60000 (20%)] Loss: -1525.821777\n",
      "Train Epoch: 2133 [23040/60000 (38%)] Loss: -1408.903687\n",
      "Train Epoch: 2133 [34304/60000 (57%)] Loss: -1419.413208\n",
      "Train Epoch: 2133 [45568/60000 (76%)] Loss: -1273.429932\n",
      "Train Epoch: 2133 [56832/60000 (95%)] Loss: -1547.546631\n",
      "    epoch          : 2133\n",
      "    loss           : -1384.7288318353858\n",
      "Train Epoch: 2134 [512/60000 (1%)] Loss: -1284.182495\n",
      "Train Epoch: 2134 [11776/60000 (20%)] Loss: -1575.280762\n",
      "Train Epoch: 2134 [23040/60000 (38%)] Loss: -1483.532104\n",
      "Train Epoch: 2134 [34304/60000 (57%)] Loss: -1362.917480\n",
      "Train Epoch: 2134 [45568/60000 (76%)] Loss: -1304.922852\n",
      "Train Epoch: 2134 [56832/60000 (95%)] Loss: -1539.779297\n",
      "    epoch          : 2134\n",
      "    loss           : -1392.3217801024011\n",
      "Train Epoch: 2135 [512/60000 (1%)] Loss: -1516.984497\n",
      "Train Epoch: 2135 [11776/60000 (20%)] Loss: -1263.198853\n",
      "Train Epoch: 2135 [23040/60000 (38%)] Loss: -1423.003174\n",
      "Train Epoch: 2135 [34304/60000 (57%)] Loss: -1525.381714\n",
      "Train Epoch: 2135 [45568/60000 (76%)] Loss: -1391.531006\n",
      "Train Epoch: 2135 [56832/60000 (95%)] Loss: -1310.876221\n",
      "    epoch          : 2135\n",
      "    loss           : -1369.5622293073577\n",
      "Train Epoch: 2136 [512/60000 (1%)] Loss: -1530.257324\n",
      "Train Epoch: 2136 [11776/60000 (20%)] Loss: -1291.723633\n",
      "Train Epoch: 2136 [23040/60000 (38%)] Loss: -1553.337524\n",
      "Train Epoch: 2136 [34304/60000 (57%)] Loss: -1542.354980\n",
      "Train Epoch: 2136 [45568/60000 (76%)] Loss: -1446.354614\n",
      "Train Epoch: 2136 [56832/60000 (95%)] Loss: -1380.580078\n",
      "    epoch          : 2136\n",
      "    loss           : -1395.777624097921\n",
      "Train Epoch: 2137 [512/60000 (1%)] Loss: -1391.756348\n",
      "Train Epoch: 2137 [11776/60000 (20%)] Loss: -1390.659424\n",
      "Train Epoch: 2137 [23040/60000 (38%)] Loss: -1276.778198\n",
      "Train Epoch: 2137 [34304/60000 (57%)] Loss: -1438.117432\n",
      "Train Epoch: 2137 [45568/60000 (76%)] Loss: -1426.395386\n",
      "Train Epoch: 2137 [56832/60000 (95%)] Loss: -1381.053711\n",
      "    epoch          : 2137\n",
      "    loss           : -1377.8760551840571\n",
      "Train Epoch: 2138 [512/60000 (1%)] Loss: -1416.676025\n",
      "Train Epoch: 2138 [11776/60000 (20%)] Loss: -1284.047241\n",
      "Train Epoch: 2138 [23040/60000 (38%)] Loss: -1547.160034\n",
      "Train Epoch: 2138 [34304/60000 (57%)] Loss: -1400.380127\n",
      "Train Epoch: 2138 [45568/60000 (76%)] Loss: -1406.737305\n",
      "Train Epoch: 2138 [56832/60000 (95%)] Loss: -1412.281006\n",
      "    epoch          : 2138\n",
      "    loss           : -1375.2482737740554\n",
      "Train Epoch: 2139 [512/60000 (1%)] Loss: -1424.510986\n",
      "Train Epoch: 2139 [11776/60000 (20%)] Loss: -1431.259521\n",
      "Train Epoch: 2139 [23040/60000 (38%)] Loss: -1380.699585\n",
      "Train Epoch: 2139 [34304/60000 (57%)] Loss: -1370.148926\n",
      "Train Epoch: 2139 [45568/60000 (76%)] Loss: -1363.328247\n",
      "Train Epoch: 2139 [56832/60000 (95%)] Loss: -1389.132935\n",
      "    epoch          : 2139\n",
      "    loss           : -1376.1742539917682\n",
      "Train Epoch: 2140 [512/60000 (1%)] Loss: -1438.199707\n",
      "Train Epoch: 2140 [11776/60000 (20%)] Loss: -1287.626343\n",
      "Train Epoch: 2140 [23040/60000 (38%)] Loss: -1403.458008\n",
      "Train Epoch: 2140 [34304/60000 (57%)] Loss: -1550.180176\n",
      "Train Epoch: 2140 [45568/60000 (76%)] Loss: -1548.075195\n",
      "Train Epoch: 2140 [56832/60000 (95%)] Loss: -1246.647461\n",
      "    epoch          : 2140\n",
      "    loss           : -1395.8960667841852\n",
      "Train Epoch: 2141 [512/60000 (1%)] Loss: -1414.615479\n",
      "Train Epoch: 2141 [11776/60000 (20%)] Loss: -1189.536133\n",
      "Train Epoch: 2141 [23040/60000 (38%)] Loss: -1311.073242\n",
      "Train Epoch: 2141 [34304/60000 (57%)] Loss: -1418.958984\n",
      "Train Epoch: 2141 [45568/60000 (76%)] Loss: -1431.390747\n",
      "Train Epoch: 2141 [56832/60000 (95%)] Loss: -1582.742188\n",
      "    epoch          : 2141\n",
      "    loss           : -1389.4975006620762\n",
      "Train Epoch: 2142 [512/60000 (1%)] Loss: -1273.811035\n",
      "Train Epoch: 2142 [11776/60000 (20%)] Loss: -1184.695679\n",
      "Train Epoch: 2142 [23040/60000 (38%)] Loss: -1303.785645\n",
      "Train Epoch: 2142 [34304/60000 (57%)] Loss: -1307.279419\n",
      "Train Epoch: 2142 [45568/60000 (76%)] Loss: -1399.984375\n",
      "Train Epoch: 2142 [56832/60000 (95%)] Loss: -1547.675537\n",
      "    epoch          : 2142\n",
      "    loss           : -1373.967849300406\n",
      "Train Epoch: 2143 [512/60000 (1%)] Loss: -1399.436401\n",
      "Train Epoch: 2143 [11776/60000 (20%)] Loss: -1389.009888\n",
      "Train Epoch: 2143 [23040/60000 (38%)] Loss: -1171.989014\n",
      "Train Epoch: 2143 [34304/60000 (57%)] Loss: -1387.842285\n",
      "Train Epoch: 2143 [45568/60000 (76%)] Loss: -1396.340088\n",
      "Train Epoch: 2143 [56832/60000 (95%)] Loss: -1399.528809\n",
      "    epoch          : 2143\n",
      "    loss           : -1378.6179150942355\n",
      "Train Epoch: 2144 [512/60000 (1%)] Loss: -1266.181763\n",
      "Train Epoch: 2144 [11776/60000 (20%)] Loss: -1307.603271\n",
      "Train Epoch: 2144 [23040/60000 (38%)] Loss: -1515.391846\n",
      "Train Epoch: 2144 [34304/60000 (57%)] Loss: -1413.985352\n",
      "Train Epoch: 2144 [45568/60000 (76%)] Loss: -1504.898926\n",
      "Train Epoch: 2144 [56832/60000 (95%)] Loss: -1263.002686\n",
      "    epoch          : 2144\n",
      "    loss           : -1393.287252135196\n",
      "Train Epoch: 2145 [512/60000 (1%)] Loss: -1525.308960\n",
      "Train Epoch: 2145 [11776/60000 (20%)] Loss: -1526.536621\n",
      "Train Epoch: 2145 [23040/60000 (38%)] Loss: -1481.907715\n",
      "Train Epoch: 2145 [34304/60000 (57%)] Loss: -1289.503784\n",
      "Train Epoch: 2145 [45568/60000 (76%)] Loss: -1482.267578\n",
      "Train Epoch: 2145 [56832/60000 (95%)] Loss: -1546.728760\n",
      "    epoch          : 2145\n",
      "    loss           : -1391.5402614787474\n",
      "Train Epoch: 2146 [512/60000 (1%)] Loss: -1384.901855\n",
      "Train Epoch: 2146 [11776/60000 (20%)] Loss: -1164.239258\n",
      "Train Epoch: 2146 [23040/60000 (38%)] Loss: -1167.564575\n",
      "Train Epoch: 2146 [34304/60000 (57%)] Loss: -1187.892700\n",
      "Train Epoch: 2146 [45568/60000 (76%)] Loss: -1252.275757\n",
      "Train Epoch: 2146 [56832/60000 (95%)] Loss: -1510.513916\n",
      "    epoch          : 2146\n",
      "    loss           : -1384.8988795738435\n",
      "Train Epoch: 2147 [512/60000 (1%)] Loss: -1339.795532\n",
      "Train Epoch: 2147 [11776/60000 (20%)] Loss: -1401.669678\n",
      "Train Epoch: 2147 [23040/60000 (38%)] Loss: -1327.374512\n",
      "Train Epoch: 2147 [34304/60000 (57%)] Loss: -1394.076782\n",
      "Train Epoch: 2147 [45568/60000 (76%)] Loss: -1500.231323\n",
      "Train Epoch: 2147 [56832/60000 (95%)] Loss: -1393.969482\n",
      "    epoch          : 2147\n",
      "    loss           : -1400.1033414851474\n",
      "Train Epoch: 2148 [512/60000 (1%)] Loss: -1530.458008\n",
      "Train Epoch: 2148 [11776/60000 (20%)] Loss: -1524.732178\n",
      "Train Epoch: 2148 [23040/60000 (38%)] Loss: -1284.891846\n",
      "Train Epoch: 2148 [34304/60000 (57%)] Loss: -1542.487061\n",
      "Train Epoch: 2148 [45568/60000 (76%)] Loss: -1210.280884\n",
      "Train Epoch: 2148 [56832/60000 (95%)] Loss: -1019.679810\n",
      "    epoch          : 2148\n",
      "    loss           : -1405.1627173127429\n",
      "Train Epoch: 2149 [512/60000 (1%)] Loss: -1302.744141\n",
      "Train Epoch: 2149 [11776/60000 (20%)] Loss: -1558.101807\n",
      "Train Epoch: 2149 [23040/60000 (38%)] Loss: -1410.070068\n",
      "Train Epoch: 2149 [34304/60000 (57%)] Loss: -1282.449829\n",
      "Train Epoch: 2149 [45568/60000 (76%)] Loss: -1385.095581\n",
      "Train Epoch: 2149 [56832/60000 (95%)] Loss: -1386.764771\n",
      "    epoch          : 2149\n",
      "    loss           : -1385.1670356362554\n",
      "Train Epoch: 2150 [512/60000 (1%)] Loss: -1530.621948\n",
      "Train Epoch: 2150 [11776/60000 (20%)] Loss: -1278.298340\n",
      "Train Epoch: 2150 [23040/60000 (38%)] Loss: -1365.404663\n",
      "Train Epoch: 2150 [34304/60000 (57%)] Loss: -1555.428467\n",
      "Train Epoch: 2150 [45568/60000 (76%)] Loss: -1190.617920\n",
      "Train Epoch: 2150 [56832/60000 (95%)] Loss: -1298.447266\n",
      "    epoch          : 2150\n",
      "    loss           : -1377.7278832042286\n",
      "Train Epoch: 2151 [512/60000 (1%)] Loss: -1423.471313\n",
      "Train Epoch: 2151 [11776/60000 (20%)] Loss: -1131.448242\n",
      "Train Epoch: 2151 [23040/60000 (38%)] Loss: -1418.326538\n",
      "Train Epoch: 2151 [34304/60000 (57%)] Loss: -1170.258789\n",
      "Train Epoch: 2151 [45568/60000 (76%)] Loss: -1243.023438\n",
      "Train Epoch: 2151 [56832/60000 (95%)] Loss: -1235.380981\n",
      "    epoch          : 2151\n",
      "    loss           : -1389.7110199147025\n",
      "Train Epoch: 2152 [512/60000 (1%)] Loss: -1561.490723\n",
      "Train Epoch: 2152 [11776/60000 (20%)] Loss: -1432.082031\n",
      "Train Epoch: 2152 [23040/60000 (38%)] Loss: -1429.204346\n",
      "Train Epoch: 2152 [34304/60000 (57%)] Loss: -1531.726929\n",
      "Train Epoch: 2152 [45568/60000 (76%)] Loss: -1423.107300\n",
      "Train Epoch: 2152 [56832/60000 (95%)] Loss: -1286.244873\n",
      "    epoch          : 2152\n",
      "    loss           : -1387.9518268822278\n",
      "Train Epoch: 2153 [512/60000 (1%)] Loss: -1550.992432\n",
      "Train Epoch: 2153 [11776/60000 (20%)] Loss: -1426.179565\n",
      "Train Epoch: 2153 [23040/60000 (38%)] Loss: -1564.767456\n",
      "Train Epoch: 2153 [34304/60000 (57%)] Loss: -1442.111938\n",
      "Train Epoch: 2153 [45568/60000 (76%)] Loss: -1559.240601\n",
      "Train Epoch: 2153 [56832/60000 (95%)] Loss: -1392.651367\n",
      "    epoch          : 2153\n",
      "    loss           : -1401.8031809316517\n",
      "Train Epoch: 2154 [512/60000 (1%)] Loss: -1251.029663\n",
      "Train Epoch: 2154 [11776/60000 (20%)] Loss: -1275.049683\n",
      "Train Epoch: 2154 [23040/60000 (38%)] Loss: -1277.257935\n",
      "Train Epoch: 2154 [34304/60000 (57%)] Loss: -1445.744141\n",
      "Train Epoch: 2154 [45568/60000 (76%)] Loss: -1258.763916\n",
      "Train Epoch: 2154 [56832/60000 (95%)] Loss: -1419.062256\n",
      "    epoch          : 2154\n",
      "    loss           : -1380.661091432733\n",
      "Train Epoch: 2155 [512/60000 (1%)] Loss: -1396.231689\n",
      "Train Epoch: 2155 [11776/60000 (20%)] Loss: -1451.180664\n",
      "Train Epoch: 2155 [23040/60000 (38%)] Loss: -1387.859253\n",
      "Train Epoch: 2155 [34304/60000 (57%)] Loss: -1304.302734\n",
      "Train Epoch: 2155 [45568/60000 (76%)] Loss: -1417.484497\n",
      "Train Epoch: 2155 [56832/60000 (95%)] Loss: -1291.570801\n",
      "    epoch          : 2155\n",
      "    loss           : -1388.5247382040077\n",
      "Train Epoch: 2156 [512/60000 (1%)] Loss: -1411.157227\n",
      "Train Epoch: 2156 [11776/60000 (20%)] Loss: -1455.186157\n",
      "Train Epoch: 2156 [23040/60000 (38%)] Loss: -1386.057617\n",
      "Train Epoch: 2156 [34304/60000 (57%)] Loss: -1241.808960\n",
      "Train Epoch: 2156 [45568/60000 (76%)] Loss: -1121.496094\n",
      "Train Epoch: 2156 [56832/60000 (95%)] Loss: -1535.899536\n",
      "    epoch          : 2156\n",
      "    loss           : -1384.2235435011698\n",
      "Train Epoch: 2157 [512/60000 (1%)] Loss: -1498.177490\n",
      "Train Epoch: 2157 [11776/60000 (20%)] Loss: -1543.129150\n",
      "Train Epoch: 2157 [23040/60000 (38%)] Loss: -1143.588989\n",
      "Train Epoch: 2157 [34304/60000 (57%)] Loss: -1160.342163\n",
      "Train Epoch: 2157 [45568/60000 (76%)] Loss: -1556.396484\n",
      "Train Epoch: 2157 [56832/60000 (95%)] Loss: -1514.483032\n",
      "    epoch          : 2157\n",
      "    loss           : -1384.3585132663534\n",
      "Train Epoch: 2158 [512/60000 (1%)] Loss: -1431.626099\n",
      "Train Epoch: 2158 [11776/60000 (20%)] Loss: -1394.508057\n",
      "Train Epoch: 2158 [23040/60000 (38%)] Loss: -1133.656494\n",
      "Train Epoch: 2158 [34304/60000 (57%)] Loss: -1445.306152\n",
      "Train Epoch: 2158 [45568/60000 (76%)] Loss: -1412.094116\n",
      "Train Epoch: 2158 [56832/60000 (95%)] Loss: -1319.937256\n",
      "    epoch          : 2158\n",
      "    loss           : -1386.2550610903293\n",
      "Train Epoch: 2159 [512/60000 (1%)] Loss: -980.092712\n",
      "Train Epoch: 2159 [11776/60000 (20%)] Loss: -1432.661377\n",
      "Train Epoch: 2159 [23040/60000 (38%)] Loss: -1128.689819\n",
      "Train Epoch: 2159 [34304/60000 (57%)] Loss: -1428.935547\n",
      "Train Epoch: 2159 [45568/60000 (76%)] Loss: -1472.167969\n",
      "Train Epoch: 2159 [56832/60000 (95%)] Loss: -1402.990356\n",
      "    epoch          : 2159\n",
      "    loss           : -1383.3626969332076\n",
      "Train Epoch: 2160 [512/60000 (1%)] Loss: -1433.010864\n",
      "Train Epoch: 2160 [11776/60000 (20%)] Loss: -1425.203613\n",
      "Train Epoch: 2160 [23040/60000 (38%)] Loss: -1425.448242\n",
      "Train Epoch: 2160 [34304/60000 (57%)] Loss: -1521.099121\n",
      "Train Epoch: 2160 [45568/60000 (76%)] Loss: -1359.720459\n",
      "Train Epoch: 2160 [56832/60000 (95%)] Loss: -1319.203491\n",
      "    epoch          : 2160\n",
      "    loss           : -1392.3632340080994\n",
      "Train Epoch: 2161 [512/60000 (1%)] Loss: -1500.421875\n",
      "Train Epoch: 2161 [11776/60000 (20%)] Loss: -1382.255249\n",
      "Train Epoch: 2161 [23040/60000 (38%)] Loss: -1397.903564\n",
      "Train Epoch: 2161 [34304/60000 (57%)] Loss: -1395.004028\n",
      "Train Epoch: 2161 [45568/60000 (76%)] Loss: -1376.325684\n",
      "Train Epoch: 2161 [56832/60000 (95%)] Loss: -1255.272339\n",
      "    epoch          : 2161\n",
      "    loss           : -1402.6969397593352\n",
      "Train Epoch: 2162 [512/60000 (1%)] Loss: -1556.276489\n",
      "Train Epoch: 2162 [11776/60000 (20%)] Loss: -1398.108521\n",
      "Train Epoch: 2162 [23040/60000 (38%)] Loss: -1329.432129\n",
      "Train Epoch: 2162 [34304/60000 (57%)] Loss: -1560.898926\n",
      "Train Epoch: 2162 [45568/60000 (76%)] Loss: -1434.659546\n",
      "Train Epoch: 2162 [56832/60000 (95%)] Loss: -1397.064575\n",
      "    epoch          : 2162\n",
      "    loss           : -1381.4075662214202\n",
      "Train Epoch: 2163 [512/60000 (1%)] Loss: -1499.802734\n",
      "Train Epoch: 2163 [11776/60000 (20%)] Loss: -1429.004639\n",
      "Train Epoch: 2163 [23040/60000 (38%)] Loss: -1528.690308\n",
      "Train Epoch: 2163 [34304/60000 (57%)] Loss: -1418.042969\n",
      "Train Epoch: 2163 [45568/60000 (76%)] Loss: -1384.677612\n",
      "Train Epoch: 2163 [56832/60000 (95%)] Loss: -1189.803223\n",
      "    epoch          : 2163\n",
      "    loss           : -1401.0346296924656\n",
      "Train Epoch: 2164 [512/60000 (1%)] Loss: -1398.208984\n",
      "Train Epoch: 2164 [11776/60000 (20%)] Loss: -1287.988525\n",
      "Train Epoch: 2164 [23040/60000 (38%)] Loss: -1294.633301\n",
      "Train Epoch: 2164 [34304/60000 (57%)] Loss: -1270.488525\n",
      "Train Epoch: 2164 [45568/60000 (76%)] Loss: -1321.931030\n",
      "Train Epoch: 2164 [56832/60000 (95%)] Loss: -1377.669189\n",
      "    epoch          : 2164\n",
      "    loss           : -1374.21797171555\n",
      "Train Epoch: 2165 [512/60000 (1%)] Loss: -1461.991699\n",
      "Train Epoch: 2165 [11776/60000 (20%)] Loss: -1474.027344\n",
      "Train Epoch: 2165 [23040/60000 (38%)] Loss: -1172.765869\n",
      "Train Epoch: 2165 [34304/60000 (57%)] Loss: -1444.599243\n",
      "Train Epoch: 2165 [45568/60000 (76%)] Loss: -1556.342529\n",
      "Train Epoch: 2165 [56832/60000 (95%)] Loss: -1511.209106\n",
      "    epoch          : 2165\n",
      "    loss           : -1390.6760653910665\n",
      "Train Epoch: 2166 [512/60000 (1%)] Loss: -1553.185181\n",
      "Train Epoch: 2166 [11776/60000 (20%)] Loss: -1322.414551\n",
      "Train Epoch: 2166 [23040/60000 (38%)] Loss: -1251.122803\n",
      "Train Epoch: 2166 [34304/60000 (57%)] Loss: -1412.503784\n",
      "Train Epoch: 2166 [45568/60000 (76%)] Loss: -1438.158447\n",
      "Train Epoch: 2166 [56832/60000 (95%)] Loss: -1525.592041\n",
      "    epoch          : 2166\n",
      "    loss           : -1383.2748375154483\n",
      "Train Epoch: 2167 [512/60000 (1%)] Loss: -1225.251709\n",
      "Train Epoch: 2167 [11776/60000 (20%)] Loss: -1561.860107\n",
      "Train Epoch: 2167 [23040/60000 (38%)] Loss: -1341.658447\n",
      "Train Epoch: 2167 [34304/60000 (57%)] Loss: -1414.408569\n",
      "Train Epoch: 2167 [45568/60000 (76%)] Loss: -1551.697144\n",
      "Train Epoch: 2167 [56832/60000 (95%)] Loss: -1383.778931\n",
      "    epoch          : 2167\n",
      "    loss           : -1384.8902603408037\n",
      "Train Epoch: 2168 [512/60000 (1%)] Loss: -1418.894531\n",
      "Train Epoch: 2168 [11776/60000 (20%)] Loss: -1519.550537\n",
      "Train Epoch: 2168 [23040/60000 (38%)] Loss: -1570.317261\n",
      "Train Epoch: 2168 [34304/60000 (57%)] Loss: -1285.766113\n",
      "Train Epoch: 2168 [45568/60000 (76%)] Loss: -1407.875366\n",
      "Train Epoch: 2168 [56832/60000 (95%)] Loss: -1551.584595\n",
      "    epoch          : 2168\n",
      "    loss           : -1397.2498779296875\n",
      "Train Epoch: 2169 [512/60000 (1%)] Loss: -1521.143311\n",
      "Train Epoch: 2169 [11776/60000 (20%)] Loss: -1513.906616\n",
      "Train Epoch: 2169 [23040/60000 (38%)] Loss: -1401.131104\n",
      "Train Epoch: 2169 [34304/60000 (57%)] Loss: -1406.513916\n",
      "Train Epoch: 2169 [45568/60000 (76%)] Loss: -1280.193237\n",
      "Train Epoch: 2169 [56832/60000 (95%)] Loss: -1261.656616\n",
      "    epoch          : 2169\n",
      "    loss           : -1403.7508044916358\n",
      "Train Epoch: 2170 [512/60000 (1%)] Loss: -1270.899048\n",
      "Train Epoch: 2170 [11776/60000 (20%)] Loss: -1418.580811\n",
      "Train Epoch: 2170 [23040/60000 (38%)] Loss: -1448.252930\n",
      "Train Epoch: 2170 [34304/60000 (57%)] Loss: -1279.193481\n",
      "Train Epoch: 2170 [45568/60000 (76%)] Loss: -1283.191162\n",
      "Train Epoch: 2170 [56832/60000 (95%)] Loss: -1262.607056\n",
      "    epoch          : 2170\n",
      "    loss           : -1371.3452931204758\n",
      "Train Epoch: 2171 [512/60000 (1%)] Loss: -1250.277222\n",
      "Train Epoch: 2171 [11776/60000 (20%)] Loss: -1020.433838\n",
      "Train Epoch: 2171 [23040/60000 (38%)] Loss: -1423.727295\n",
      "Train Epoch: 2171 [34304/60000 (57%)] Loss: -1434.291626\n",
      "Train Epoch: 2171 [45568/60000 (76%)] Loss: -1397.506226\n",
      "Train Epoch: 2171 [56832/60000 (95%)] Loss: -1405.673218\n",
      "    epoch          : 2171\n",
      "    loss           : -1397.3345581744352\n",
      "Train Epoch: 2172 [512/60000 (1%)] Loss: -1278.192627\n",
      "Train Epoch: 2172 [11776/60000 (20%)] Loss: -1421.098389\n",
      "Train Epoch: 2172 [23040/60000 (38%)] Loss: -1428.231445\n",
      "Train Epoch: 2172 [34304/60000 (57%)] Loss: -1431.579468\n",
      "Train Epoch: 2172 [45568/60000 (76%)] Loss: -1268.235107\n",
      "Train Epoch: 2172 [56832/60000 (95%)] Loss: -1516.190063\n",
      "    epoch          : 2172\n",
      "    loss           : -1394.6781774833378\n",
      "Train Epoch: 2173 [512/60000 (1%)] Loss: -1411.621338\n",
      "Train Epoch: 2173 [11776/60000 (20%)] Loss: -1358.522827\n",
      "Train Epoch: 2173 [23040/60000 (38%)] Loss: -1558.477295\n",
      "Train Epoch: 2173 [34304/60000 (57%)] Loss: -1200.126343\n",
      "Train Epoch: 2173 [45568/60000 (76%)] Loss: -1299.438843\n",
      "Train Epoch: 2173 [56832/60000 (95%)] Loss: -1514.555664\n",
      "    epoch          : 2173\n",
      "    loss           : -1386.5321527685824\n",
      "Train Epoch: 2174 [512/60000 (1%)] Loss: -1370.882324\n",
      "Train Epoch: 2174 [11776/60000 (20%)] Loss: -1200.103760\n",
      "Train Epoch: 2174 [23040/60000 (38%)] Loss: -1287.852905\n",
      "Train Epoch: 2174 [34304/60000 (57%)] Loss: -1276.888916\n",
      "Train Epoch: 2174 [45568/60000 (76%)] Loss: -1407.098389\n",
      "Train Epoch: 2174 [56832/60000 (95%)] Loss: -1306.801270\n",
      "    epoch          : 2174\n",
      "    loss           : -1388.8350157656912\n",
      "Train Epoch: 2175 [512/60000 (1%)] Loss: -1501.710083\n",
      "Train Epoch: 2175 [11776/60000 (20%)] Loss: -1517.120117\n",
      "Train Epoch: 2175 [23040/60000 (38%)] Loss: -1338.210205\n",
      "Train Epoch: 2175 [34304/60000 (57%)] Loss: -1074.022583\n",
      "Train Epoch: 2175 [45568/60000 (76%)] Loss: -1441.640625\n",
      "Train Epoch: 2175 [56832/60000 (95%)] Loss: -1438.678223\n",
      "    epoch          : 2175\n",
      "    loss           : -1404.2608356368069\n",
      "Train Epoch: 2176 [512/60000 (1%)] Loss: -1304.270386\n",
      "Train Epoch: 2176 [11776/60000 (20%)] Loss: -1534.294556\n",
      "Train Epoch: 2176 [23040/60000 (38%)] Loss: -1428.347656\n",
      "Train Epoch: 2176 [34304/60000 (57%)] Loss: -1542.096191\n",
      "Train Epoch: 2176 [45568/60000 (76%)] Loss: -1431.811890\n",
      "Train Epoch: 2176 [56832/60000 (95%)] Loss: -1151.186890\n",
      "    epoch          : 2176\n",
      "    loss           : -1370.0285546254304\n",
      "Train Epoch: 2177 [512/60000 (1%)] Loss: -1516.684692\n",
      "Train Epoch: 2177 [11776/60000 (20%)] Loss: -1320.399170\n",
      "Train Epoch: 2177 [23040/60000 (38%)] Loss: -1396.296875\n",
      "Train Epoch: 2177 [34304/60000 (57%)] Loss: -1305.834595\n",
      "Train Epoch: 2177 [45568/60000 (76%)] Loss: -1281.229858\n",
      "Train Epoch: 2177 [56832/60000 (95%)] Loss: -1171.850342\n",
      "    epoch          : 2177\n",
      "    loss           : -1384.4477721823139\n",
      "Train Epoch: 2178 [512/60000 (1%)] Loss: -1234.250854\n",
      "Train Epoch: 2178 [11776/60000 (20%)] Loss: -1335.141846\n",
      "Train Epoch: 2178 [23040/60000 (38%)] Loss: -1504.237061\n",
      "Train Epoch: 2178 [34304/60000 (57%)] Loss: -1377.362915\n",
      "Train Epoch: 2178 [45568/60000 (76%)] Loss: -1311.593384\n",
      "Train Epoch: 2178 [56832/60000 (95%)] Loss: -1425.811646\n",
      "    epoch          : 2178\n",
      "    loss           : -1379.556430967514\n",
      "Train Epoch: 2179 [512/60000 (1%)] Loss: -1325.402344\n",
      "Train Epoch: 2179 [11776/60000 (20%)] Loss: -1271.167725\n",
      "Train Epoch: 2179 [23040/60000 (38%)] Loss: -1494.288818\n",
      "Train Epoch: 2179 [34304/60000 (57%)] Loss: -1277.587769\n",
      "Train Epoch: 2179 [45568/60000 (76%)] Loss: -1200.816895\n",
      "Train Epoch: 2179 [56832/60000 (95%)] Loss: -1415.224243\n",
      "    epoch          : 2179\n",
      "    loss           : -1390.3798266049832\n",
      "Train Epoch: 2180 [512/60000 (1%)] Loss: -1442.040527\n",
      "Train Epoch: 2180 [11776/60000 (20%)] Loss: -1468.958496\n",
      "Train Epoch: 2180 [23040/60000 (38%)] Loss: -1165.290894\n",
      "Train Epoch: 2180 [34304/60000 (57%)] Loss: -1041.386108\n",
      "Train Epoch: 2180 [45568/60000 (76%)] Loss: -1365.275146\n",
      "Train Epoch: 2180 [56832/60000 (95%)] Loss: -1556.085938\n",
      "    epoch          : 2180\n",
      "    loss           : -1407.6990232306011\n",
      "Train Epoch: 2181 [512/60000 (1%)] Loss: -1528.029297\n",
      "Train Epoch: 2181 [11776/60000 (20%)] Loss: -1421.115967\n",
      "Train Epoch: 2181 [23040/60000 (38%)] Loss: -1561.729492\n",
      "Train Epoch: 2181 [34304/60000 (57%)] Loss: -1578.006836\n",
      "Train Epoch: 2181 [45568/60000 (76%)] Loss: -1364.018799\n",
      "Train Epoch: 2181 [56832/60000 (95%)] Loss: -1303.450684\n",
      "    epoch          : 2181\n",
      "    loss           : -1391.9653389278778\n",
      "Train Epoch: 2182 [512/60000 (1%)] Loss: -1443.450439\n",
      "Train Epoch: 2182 [11776/60000 (20%)] Loss: -1284.940674\n",
      "Train Epoch: 2182 [23040/60000 (38%)] Loss: -1300.703613\n",
      "Train Epoch: 2182 [34304/60000 (57%)] Loss: -1414.860107\n",
      "Train Epoch: 2182 [45568/60000 (76%)] Loss: -1285.841675\n",
      "Train Epoch: 2182 [56832/60000 (95%)] Loss: -1383.380615\n",
      "    epoch          : 2182\n",
      "    loss           : -1388.5146442995233\n",
      "Train Epoch: 2183 [512/60000 (1%)] Loss: -1294.229248\n",
      "Train Epoch: 2183 [11776/60000 (20%)] Loss: -1223.312134\n",
      "Train Epoch: 2183 [23040/60000 (38%)] Loss: -1536.080078\n",
      "Train Epoch: 2183 [34304/60000 (57%)] Loss: -1380.561646\n",
      "Train Epoch: 2183 [45568/60000 (76%)] Loss: -1546.121704\n",
      "Train Epoch: 2183 [56832/60000 (95%)] Loss: -1342.406860\n",
      "    epoch          : 2183\n",
      "    loss           : -1368.0340334789903\n",
      "Train Epoch: 2184 [512/60000 (1%)] Loss: -1548.196045\n",
      "Train Epoch: 2184 [11776/60000 (20%)] Loss: -1436.248169\n",
      "Train Epoch: 2184 [23040/60000 (38%)] Loss: -1405.614258\n",
      "Train Epoch: 2184 [34304/60000 (57%)] Loss: -1316.032471\n",
      "Train Epoch: 2184 [45568/60000 (76%)] Loss: -1263.798096\n",
      "Train Epoch: 2184 [56832/60000 (95%)] Loss: -1245.744385\n",
      "    epoch          : 2184\n",
      "    loss           : -1401.1784202446372\n",
      "Train Epoch: 2185 [512/60000 (1%)] Loss: -1296.896606\n",
      "Train Epoch: 2185 [11776/60000 (20%)] Loss: -1254.257324\n",
      "Train Epoch: 2185 [23040/60000 (38%)] Loss: -1556.042236\n",
      "Train Epoch: 2185 [34304/60000 (57%)] Loss: -1405.677734\n",
      "Train Epoch: 2185 [45568/60000 (76%)] Loss: -1421.927734\n",
      "Train Epoch: 2185 [56832/60000 (95%)] Loss: -1458.633301\n",
      "    epoch          : 2185\n",
      "    loss           : -1390.7949601512844\n",
      "Train Epoch: 2186 [512/60000 (1%)] Loss: -1259.353516\n",
      "Train Epoch: 2186 [11776/60000 (20%)] Loss: -1414.370728\n",
      "Train Epoch: 2186 [23040/60000 (38%)] Loss: -1424.802612\n",
      "Train Epoch: 2186 [34304/60000 (57%)] Loss: -1401.718506\n",
      "Train Epoch: 2186 [45568/60000 (76%)] Loss: -1321.101807\n",
      "Train Epoch: 2186 [56832/60000 (95%)] Loss: -1530.331421\n",
      "    epoch          : 2186\n",
      "    loss           : -1381.636325642214\n",
      "Train Epoch: 2187 [512/60000 (1%)] Loss: -1295.244385\n",
      "Train Epoch: 2187 [11776/60000 (20%)] Loss: -1431.951904\n",
      "Train Epoch: 2187 [23040/60000 (38%)] Loss: -1404.243042\n",
      "Train Epoch: 2187 [34304/60000 (57%)] Loss: -1404.874390\n",
      "Train Epoch: 2187 [45568/60000 (76%)] Loss: -1492.843262\n",
      "Train Epoch: 2187 [56832/60000 (95%)] Loss: -1413.170166\n",
      "    epoch          : 2187\n",
      "    loss           : -1388.5956365725415\n",
      "Train Epoch: 2188 [512/60000 (1%)] Loss: -1384.281128\n",
      "Train Epoch: 2188 [11776/60000 (20%)] Loss: -1205.614502\n",
      "Train Epoch: 2188 [23040/60000 (38%)] Loss: -1524.566650\n",
      "Train Epoch: 2188 [34304/60000 (57%)] Loss: -1409.055786\n",
      "Train Epoch: 2188 [45568/60000 (76%)] Loss: -1351.674316\n",
      "Train Epoch: 2188 [56832/60000 (95%)] Loss: -1321.945435\n",
      "    epoch          : 2188\n",
      "    loss           : -1408.3185642048463\n",
      "Train Epoch: 2189 [512/60000 (1%)] Loss: -1523.425049\n",
      "Train Epoch: 2189 [11776/60000 (20%)] Loss: -1379.720947\n",
      "Train Epoch: 2189 [23040/60000 (38%)] Loss: -1411.831543\n",
      "Train Epoch: 2189 [34304/60000 (57%)] Loss: -1415.865356\n",
      "Train Epoch: 2189 [45568/60000 (76%)] Loss: -1412.835449\n",
      "Train Epoch: 2189 [56832/60000 (95%)] Loss: -1408.776733\n",
      "    epoch          : 2189\n",
      "    loss           : -1396.8087796141199\n",
      "Train Epoch: 2190 [512/60000 (1%)] Loss: -1410.837036\n",
      "Train Epoch: 2190 [11776/60000 (20%)] Loss: -1443.982300\n",
      "Train Epoch: 2190 [23040/60000 (38%)] Loss: -1406.727661\n",
      "Train Epoch: 2190 [34304/60000 (57%)] Loss: -1561.624146\n",
      "Train Epoch: 2190 [45568/60000 (76%)] Loss: -1569.851196\n",
      "Train Epoch: 2190 [56832/60000 (95%)] Loss: -1438.195679\n",
      "    epoch          : 2190\n",
      "    loss           : -1379.5495598572122\n",
      "Train Epoch: 2191 [512/60000 (1%)] Loss: -1238.451660\n",
      "Train Epoch: 2191 [11776/60000 (20%)] Loss: -1273.146729\n",
      "Train Epoch: 2191 [23040/60000 (38%)] Loss: -1538.615479\n",
      "Train Epoch: 2191 [34304/60000 (57%)] Loss: -1386.879150\n",
      "Train Epoch: 2191 [45568/60000 (76%)] Loss: -1269.061401\n",
      "Train Epoch: 2191 [56832/60000 (95%)] Loss: -1053.312744\n",
      "    epoch          : 2191\n",
      "    loss           : -1374.210241285421\n",
      "Train Epoch: 2192 [512/60000 (1%)] Loss: -1326.941162\n",
      "Train Epoch: 2192 [11776/60000 (20%)] Loss: -1186.972534\n",
      "Train Epoch: 2192 [23040/60000 (38%)] Loss: -1403.523193\n",
      "Train Epoch: 2192 [34304/60000 (57%)] Loss: -1553.513550\n",
      "Train Epoch: 2192 [45568/60000 (76%)] Loss: -1511.442871\n",
      "Train Epoch: 2192 [56832/60000 (95%)] Loss: -1503.785767\n",
      "    epoch          : 2192\n",
      "    loss           : -1392.9804197839426\n",
      "Train Epoch: 2193 [512/60000 (1%)] Loss: -1383.924805\n",
      "Train Epoch: 2193 [11776/60000 (20%)] Loss: -1434.467773\n",
      "Train Epoch: 2193 [23040/60000 (38%)] Loss: -1318.555786\n",
      "Train Epoch: 2193 [34304/60000 (57%)] Loss: -1253.325562\n",
      "Train Epoch: 2193 [45568/60000 (76%)] Loss: -1282.452637\n",
      "Train Epoch: 2193 [56832/60000 (95%)] Loss: -1546.019775\n",
      "    epoch          : 2193\n",
      "    loss           : -1392.914782507945\n",
      "Train Epoch: 2194 [512/60000 (1%)] Loss: -1285.661865\n",
      "Train Epoch: 2194 [11776/60000 (20%)] Loss: -1396.855957\n",
      "Train Epoch: 2194 [23040/60000 (38%)] Loss: -1153.553711\n",
      "Train Epoch: 2194 [34304/60000 (57%)] Loss: -1383.371216\n",
      "Train Epoch: 2194 [45568/60000 (76%)] Loss: -1396.373291\n",
      "Train Epoch: 2194 [56832/60000 (95%)] Loss: -1431.671753\n",
      "    epoch          : 2194\n",
      "    loss           : -1407.5745163394906\n",
      "Train Epoch: 2195 [512/60000 (1%)] Loss: -1418.026367\n",
      "Train Epoch: 2195 [11776/60000 (20%)] Loss: -1399.185181\n",
      "Train Epoch: 2195 [23040/60000 (38%)] Loss: -1420.578613\n",
      "Train Epoch: 2195 [34304/60000 (57%)] Loss: -1434.603882\n",
      "Train Epoch: 2195 [45568/60000 (76%)] Loss: -1351.582397\n",
      "Train Epoch: 2195 [56832/60000 (95%)] Loss: -1299.746704\n",
      "    epoch          : 2195\n",
      "    loss           : -1390.9800759870452\n",
      "Train Epoch: 2196 [512/60000 (1%)] Loss: -1293.406250\n",
      "Train Epoch: 2196 [11776/60000 (20%)] Loss: -1290.781250\n",
      "Train Epoch: 2196 [23040/60000 (38%)] Loss: -1406.289429\n",
      "Train Epoch: 2196 [34304/60000 (57%)] Loss: -1287.444702\n",
      "Train Epoch: 2196 [45568/60000 (76%)] Loss: -1457.253052\n",
      "Train Epoch: 2196 [56832/60000 (95%)] Loss: -1281.378906\n",
      "    epoch          : 2196\n",
      "    loss           : -1389.412730761167\n",
      "Train Epoch: 2197 [512/60000 (1%)] Loss: -1426.318237\n",
      "Train Epoch: 2197 [11776/60000 (20%)] Loss: -1438.822510\n",
      "Train Epoch: 2197 [23040/60000 (38%)] Loss: -1412.431763\n",
      "Train Epoch: 2197 [34304/60000 (57%)] Loss: -1243.502808\n",
      "Train Epoch: 2197 [45568/60000 (76%)] Loss: -1408.929810\n",
      "Train Epoch: 2197 [56832/60000 (95%)] Loss: -1418.125366\n",
      "    epoch          : 2197\n",
      "    loss           : -1380.9038851463188\n",
      "Train Epoch: 2198 [512/60000 (1%)] Loss: -1519.655029\n",
      "Train Epoch: 2198 [11776/60000 (20%)] Loss: -1383.959351\n",
      "Train Epoch: 2198 [23040/60000 (38%)] Loss: -1420.254639\n",
      "Train Epoch: 2198 [34304/60000 (57%)] Loss: -1279.847168\n",
      "Train Epoch: 2198 [45568/60000 (76%)] Loss: -1524.541138\n",
      "Train Epoch: 2198 [56832/60000 (95%)] Loss: -1291.849609\n",
      "    epoch          : 2198\n",
      "    loss           : -1386.2598039012844\n",
      "Train Epoch: 2199 [512/60000 (1%)] Loss: -1533.251221\n",
      "Train Epoch: 2199 [11776/60000 (20%)] Loss: -1401.709351\n",
      "Train Epoch: 2199 [23040/60000 (38%)] Loss: -1213.632812\n",
      "Train Epoch: 2199 [34304/60000 (57%)] Loss: -1265.216431\n",
      "Train Epoch: 2199 [45568/60000 (76%)] Loss: -1158.131470\n",
      "Train Epoch: 2199 [56832/60000 (95%)] Loss: -1409.052246\n",
      "    epoch          : 2199\n",
      "    loss           : -1401.9225181105448\n",
      "Train Epoch: 2200 [512/60000 (1%)] Loss: -1441.536743\n",
      "Train Epoch: 2200 [11776/60000 (20%)] Loss: -1340.971436\n",
      "Train Epoch: 2200 [23040/60000 (38%)] Loss: -1287.616821\n",
      "Train Epoch: 2200 [34304/60000 (57%)] Loss: -1442.091919\n",
      "Train Epoch: 2200 [45568/60000 (76%)] Loss: -1417.188232\n",
      "Train Epoch: 2200 [56832/60000 (95%)] Loss: -1386.016113\n",
      "    epoch          : 2200\n",
      "    loss           : -1371.4154456187102\n",
      "Saving checkpoint: saved/models/Mnist_DeepGenerativeOperad/0127_111843/checkpoint-epoch2200.pth ...\n",
      "Train Epoch: 2201 [512/60000 (1%)] Loss: -1408.760620\n",
      "Train Epoch: 2201 [11776/60000 (20%)] Loss: -1574.697998\n",
      "Train Epoch: 2201 [23040/60000 (38%)] Loss: -1447.434937\n",
      "Train Epoch: 2201 [34304/60000 (57%)] Loss: -1522.342285\n",
      "Train Epoch: 2201 [45568/60000 (76%)] Loss: -1526.720947\n",
      "Train Epoch: 2201 [56832/60000 (95%)] Loss: -1525.226074\n",
      "    epoch          : 2201\n",
      "    loss           : -1401.5048707434012\n",
      "Train Epoch: 2202 [512/60000 (1%)] Loss: -1411.225708\n",
      "Train Epoch: 2202 [11776/60000 (20%)] Loss: -1431.533325\n",
      "Train Epoch: 2202 [23040/60000 (38%)] Loss: -1294.132935\n",
      "Train Epoch: 2202 [34304/60000 (57%)] Loss: -1257.233154\n",
      "Train Epoch: 2202 [45568/60000 (76%)] Loss: -1324.982178\n",
      "Train Epoch: 2202 [56832/60000 (95%)] Loss: -1394.293457\n",
      "    epoch          : 2202\n",
      "    loss           : -1390.1060491012315\n",
      "Train Epoch: 2203 [512/60000 (1%)] Loss: -1398.789551\n",
      "Train Epoch: 2203 [11776/60000 (20%)] Loss: -1577.211182\n",
      "Train Epoch: 2203 [23040/60000 (38%)] Loss: -1224.773804\n",
      "Train Epoch: 2203 [34304/60000 (57%)] Loss: -1545.018799\n",
      "Train Epoch: 2203 [45568/60000 (76%)] Loss: -1312.928101\n",
      "Train Epoch: 2203 [56832/60000 (95%)] Loss: -1461.150391\n",
      "    epoch          : 2203\n",
      "    loss           : -1413.797399488546\n",
      "Train Epoch: 2204 [512/60000 (1%)] Loss: -1397.078247\n",
      "Train Epoch: 2204 [11776/60000 (20%)] Loss: -1524.260254\n",
      "Train Epoch: 2204 [23040/60000 (38%)] Loss: -1501.581299\n",
      "Train Epoch: 2204 [34304/60000 (57%)] Loss: -1401.613892\n",
      "Train Epoch: 2204 [45568/60000 (76%)] Loss: -1342.732910\n",
      "Train Epoch: 2204 [56832/60000 (95%)] Loss: -1427.868286\n",
      "    epoch          : 2204\n",
      "    loss           : -1384.4998737917108\n",
      "Train Epoch: 2205 [512/60000 (1%)] Loss: -1309.140747\n",
      "Train Epoch: 2205 [11776/60000 (20%)] Loss: -1327.207520\n",
      "Train Epoch: 2205 [23040/60000 (38%)] Loss: -1261.507446\n",
      "Train Epoch: 2205 [34304/60000 (57%)] Loss: -1449.258911\n",
      "Train Epoch: 2205 [45568/60000 (76%)] Loss: -1562.892578\n",
      "Train Epoch: 2205 [56832/60000 (95%)] Loss: -1398.431274\n",
      "    epoch          : 2205\n",
      "    loss           : -1390.2120030289989\n",
      "Train Epoch: 2206 [512/60000 (1%)] Loss: -1282.568359\n",
      "Train Epoch: 2206 [11776/60000 (20%)] Loss: -1513.814941\n",
      "Train Epoch: 2206 [23040/60000 (38%)] Loss: -1543.472046\n",
      "Train Epoch: 2206 [34304/60000 (57%)] Loss: -1357.940186\n",
      "Train Epoch: 2206 [45568/60000 (76%)] Loss: -1303.179443\n",
      "Train Epoch: 2206 [56832/60000 (95%)] Loss: -1425.933594\n",
      "    epoch          : 2206\n",
      "    loss           : -1392.8420792919094\n",
      "Train Epoch: 2207 [512/60000 (1%)] Loss: -1520.389648\n",
      "Train Epoch: 2207 [11776/60000 (20%)] Loss: -1218.707031\n",
      "Train Epoch: 2207 [23040/60000 (38%)] Loss: -1401.299683\n",
      "Train Epoch: 2207 [34304/60000 (57%)] Loss: -1337.465332\n",
      "Train Epoch: 2207 [45568/60000 (76%)] Loss: -1406.790649\n",
      "Train Epoch: 2207 [56832/60000 (95%)] Loss: -1423.739746\n",
      "    epoch          : 2207\n",
      "    loss           : -1398.372104795639\n",
      "Train Epoch: 2208 [512/60000 (1%)] Loss: -1538.696167\n",
      "Train Epoch: 2208 [11776/60000 (20%)] Loss: -1317.893799\n",
      "Train Epoch: 2208 [23040/60000 (38%)] Loss: -1291.914795\n",
      "Train Epoch: 2208 [34304/60000 (57%)] Loss: -1422.756104\n",
      "Train Epoch: 2208 [45568/60000 (76%)] Loss: -1178.088745\n",
      "Train Epoch: 2208 [56832/60000 (95%)] Loss: -1164.902100\n",
      "    epoch          : 2208\n",
      "    loss           : -1387.1593810690326\n",
      "Train Epoch: 2209 [512/60000 (1%)] Loss: -1412.923828\n",
      "Train Epoch: 2209 [11776/60000 (20%)] Loss: -1273.336060\n",
      "Train Epoch: 2209 [23040/60000 (38%)] Loss: -1154.294678\n",
      "Train Epoch: 2209 [34304/60000 (57%)] Loss: -1308.010010\n",
      "Train Epoch: 2209 [45568/60000 (76%)] Loss: -1440.284668\n",
      "Train Epoch: 2209 [56832/60000 (95%)] Loss: -1435.411865\n",
      "    epoch          : 2209\n",
      "    loss           : -1384.4575381521452\n",
      "Train Epoch: 2210 [512/60000 (1%)] Loss: -1442.468994\n",
      "Train Epoch: 2210 [11776/60000 (20%)] Loss: -1529.581543\n",
      "Train Epoch: 2210 [23040/60000 (38%)] Loss: -1556.627930\n",
      "Train Epoch: 2210 [34304/60000 (57%)] Loss: -1544.555176\n",
      "Train Epoch: 2210 [45568/60000 (76%)] Loss: -1537.566650\n",
      "Train Epoch: 2210 [56832/60000 (95%)] Loss: -1406.767822\n",
      "    epoch          : 2210\n",
      "    loss           : -1381.227174230888\n",
      "Train Epoch: 2211 [512/60000 (1%)] Loss: -1387.302002\n",
      "Train Epoch: 2211 [11776/60000 (20%)] Loss: -1249.872681\n",
      "Train Epoch: 2211 [23040/60000 (38%)] Loss: -1197.725830\n",
      "Train Epoch: 2211 [34304/60000 (57%)] Loss: -1317.525513\n",
      "Train Epoch: 2211 [45568/60000 (76%)] Loss: -1491.975708\n",
      "Train Epoch: 2211 [56832/60000 (95%)] Loss: -1515.127075\n",
      "    epoch          : 2211\n",
      "    loss           : -1382.2323894608494\n",
      "Train Epoch: 2212 [512/60000 (1%)] Loss: -1418.104736\n",
      "Train Epoch: 2212 [11776/60000 (20%)] Loss: -1548.971436\n",
      "Train Epoch: 2212 [23040/60000 (38%)] Loss: -1254.604004\n",
      "Train Epoch: 2212 [34304/60000 (57%)] Loss: -1434.358521\n",
      "Train Epoch: 2212 [45568/60000 (76%)] Loss: -1367.875488\n",
      "Train Epoch: 2212 [56832/60000 (95%)] Loss: -1277.437500\n",
      "    epoch          : 2212\n",
      "    loss           : -1416.9085286458335\n",
      "Train Epoch: 2213 [512/60000 (1%)] Loss: -1403.856689\n",
      "Train Epoch: 2213 [11776/60000 (20%)] Loss: -1427.802979\n",
      "Train Epoch: 2213 [23040/60000 (38%)] Loss: -1491.411865\n",
      "Train Epoch: 2213 [34304/60000 (57%)] Loss: -1438.825806\n",
      "Train Epoch: 2213 [45568/60000 (76%)] Loss: -1313.925537\n",
      "Train Epoch: 2213 [56832/60000 (95%)] Loss: -1473.811157\n",
      "    epoch          : 2213\n",
      "    loss           : -1390.1584703693281\n",
      "Train Epoch: 2214 [512/60000 (1%)] Loss: -1289.753906\n",
      "Train Epoch: 2214 [11776/60000 (20%)] Loss: -1291.307373\n",
      "Train Epoch: 2214 [23040/60000 (38%)] Loss: -1537.815796\n",
      "Train Epoch: 2214 [34304/60000 (57%)] Loss: -1529.966064\n",
      "Train Epoch: 2214 [45568/60000 (76%)] Loss: -1569.884644\n",
      "Train Epoch: 2214 [56832/60000 (95%)] Loss: -1395.639893\n",
      "    epoch          : 2214\n",
      "    loss           : -1388.4094186556542\n",
      "Train Epoch: 2215 [512/60000 (1%)] Loss: -1400.803589\n",
      "Train Epoch: 2215 [11776/60000 (20%)] Loss: -1394.723267\n",
      "Train Epoch: 2215 [23040/60000 (38%)] Loss: -1397.955566\n",
      "Train Epoch: 2215 [34304/60000 (57%)] Loss: -1399.170044\n",
      "Train Epoch: 2215 [45568/60000 (76%)] Loss: -1275.453125\n",
      "Train Epoch: 2215 [56832/60000 (95%)] Loss: -1277.567017\n",
      "    epoch          : 2215\n",
      "    loss           : -1407.050990217823\n",
      "Train Epoch: 2216 [512/60000 (1%)] Loss: -1297.989990\n",
      "Train Epoch: 2216 [11776/60000 (20%)] Loss: -1439.412964\n",
      "Train Epoch: 2216 [23040/60000 (38%)] Loss: -1277.066650\n",
      "Train Epoch: 2216 [34304/60000 (57%)] Loss: -1544.608643\n",
      "Train Epoch: 2216 [45568/60000 (76%)] Loss: -1542.478394\n",
      "Train Epoch: 2216 [56832/60000 (95%)] Loss: -1517.260010\n",
      "    epoch          : 2216\n",
      "    loss           : -1408.2343867242673\n",
      "Train Epoch: 2217 [512/60000 (1%)] Loss: -1281.157837\n",
      "Train Epoch: 2217 [11776/60000 (20%)] Loss: -1246.004883\n",
      "Train Epoch: 2217 [23040/60000 (38%)] Loss: -1428.149658\n",
      "Train Epoch: 2217 [34304/60000 (57%)] Loss: -1555.198853\n",
      "Train Epoch: 2217 [45568/60000 (76%)] Loss: -1400.973999\n",
      "Train Epoch: 2217 [56832/60000 (95%)] Loss: -1431.190430\n",
      "    epoch          : 2217\n",
      "    loss           : -1404.6344580353991\n",
      "Train Epoch: 2218 [512/60000 (1%)] Loss: -1565.854492\n",
      "Train Epoch: 2218 [11776/60000 (20%)] Loss: -1452.518066\n",
      "Train Epoch: 2218 [23040/60000 (38%)] Loss: -1555.866821\n",
      "Train Epoch: 2218 [34304/60000 (57%)] Loss: -1441.596680\n",
      "Train Epoch: 2218 [45568/60000 (76%)] Loss: -1085.903320\n",
      "Train Epoch: 2218 [56832/60000 (95%)] Loss: -1466.784424\n",
      "    epoch          : 2218\n",
      "    loss           : -1402.887836348539\n",
      "Train Epoch: 2219 [512/60000 (1%)] Loss: -1407.674683\n",
      "Train Epoch: 2219 [11776/60000 (20%)] Loss: -1584.758545\n",
      "Train Epoch: 2219 [23040/60000 (38%)] Loss: -1396.674927\n",
      "Train Epoch: 2219 [34304/60000 (57%)] Loss: -1402.206909\n",
      "Train Epoch: 2219 [45568/60000 (76%)] Loss: -1583.892212\n",
      "Train Epoch: 2219 [56832/60000 (95%)] Loss: -1502.037109\n",
      "    epoch          : 2219\n",
      "    loss           : -1392.6917003911767\n",
      "Train Epoch: 2220 [512/60000 (1%)] Loss: -1529.106079\n",
      "Train Epoch: 2220 [11776/60000 (20%)] Loss: -1160.956543\n",
      "Train Epoch: 2220 [23040/60000 (38%)] Loss: -1426.230713\n",
      "Train Epoch: 2220 [34304/60000 (57%)] Loss: -1537.248291\n",
      "Train Epoch: 2220 [45568/60000 (76%)] Loss: -1145.360840\n",
      "Train Epoch: 2220 [56832/60000 (95%)] Loss: -1346.662842\n",
      "    epoch          : 2220\n",
      "    loss           : -1386.2693933174435\n",
      "Train Epoch: 2221 [512/60000 (1%)] Loss: -1302.756836\n",
      "Train Epoch: 2221 [11776/60000 (20%)] Loss: -1250.799805\n",
      "Train Epoch: 2221 [23040/60000 (38%)] Loss: -1511.312744\n",
      "Train Epoch: 2221 [34304/60000 (57%)] Loss: -1549.562988\n",
      "Train Epoch: 2221 [45568/60000 (76%)] Loss: -1520.092773\n",
      "Train Epoch: 2221 [56832/60000 (95%)] Loss: -1307.102173\n",
      "    epoch          : 2221\n",
      "    loss           : -1404.3959164376986\n",
      "Train Epoch: 2222 [512/60000 (1%)] Loss: -1208.301514\n",
      "Train Epoch: 2222 [11776/60000 (20%)] Loss: -1540.716553\n",
      "Train Epoch: 2222 [23040/60000 (38%)] Loss: -1447.515137\n",
      "Train Epoch: 2222 [34304/60000 (57%)] Loss: -1529.935425\n",
      "Train Epoch: 2222 [45568/60000 (76%)] Loss: -1443.800171\n",
      "Train Epoch: 2222 [56832/60000 (95%)] Loss: -1290.619263\n",
      "    epoch          : 2222\n",
      "    loss           : -1393.1254789708025\n",
      "Train Epoch: 2223 [512/60000 (1%)] Loss: -1433.133301\n",
      "Train Epoch: 2223 [11776/60000 (20%)] Loss: -1427.548218\n",
      "Train Epoch: 2223 [23040/60000 (38%)] Loss: -1316.903564\n",
      "Train Epoch: 2223 [34304/60000 (57%)] Loss: -1238.309570\n",
      "Train Epoch: 2223 [45568/60000 (76%)] Loss: -1317.451538\n",
      "Train Epoch: 2223 [56832/60000 (95%)] Loss: -1417.437500\n",
      "    epoch          : 2223\n",
      "    loss           : -1401.3093172062588\n",
      "Train Epoch: 2224 [512/60000 (1%)] Loss: -1428.518066\n",
      "Train Epoch: 2224 [11776/60000 (20%)] Loss: -1377.755005\n",
      "Train Epoch: 2224 [23040/60000 (38%)] Loss: -1387.217163\n",
      "Train Epoch: 2224 [34304/60000 (57%)] Loss: -1458.446533\n",
      "Train Epoch: 2224 [45568/60000 (76%)] Loss: -1424.157104\n",
      "Train Epoch: 2224 [56832/60000 (95%)] Loss: -1465.592773\n",
      "    epoch          : 2224\n",
      "    loss           : -1402.7881624900688\n",
      "Train Epoch: 2225 [512/60000 (1%)] Loss: -1519.545898\n",
      "Train Epoch: 2225 [11776/60000 (20%)] Loss: -1552.638794\n",
      "Train Epoch: 2225 [23040/60000 (38%)] Loss: -1428.344849\n",
      "Train Epoch: 2225 [34304/60000 (57%)] Loss: -1440.577637\n",
      "Train Epoch: 2225 [45568/60000 (76%)] Loss: -1458.423828\n",
      "Train Epoch: 2225 [56832/60000 (95%)] Loss: -1302.005493\n",
      "    epoch          : 2225\n",
      "    loss           : -1406.3817631780764\n",
      "Train Epoch: 2226 [512/60000 (1%)] Loss: -1562.017578\n",
      "Train Epoch: 2226 [11776/60000 (20%)] Loss: -1450.143555\n",
      "Train Epoch: 2226 [23040/60000 (38%)] Loss: -1542.223267\n",
      "Train Epoch: 2226 [34304/60000 (57%)] Loss: -1356.168213\n",
      "Train Epoch: 2226 [45568/60000 (76%)] Loss: -1454.791016\n",
      "Train Epoch: 2226 [56832/60000 (95%)] Loss: -1482.074951\n",
      "    epoch          : 2226\n",
      "    loss           : -1417.6011983580509\n",
      "Train Epoch: 2227 [512/60000 (1%)] Loss: -1281.418457\n",
      "Train Epoch: 2227 [11776/60000 (20%)] Loss: -1544.856689\n",
      "Train Epoch: 2227 [23040/60000 (38%)] Loss: -1329.027832\n",
      "Train Epoch: 2227 [34304/60000 (57%)] Loss: -1517.796875\n",
      "Train Epoch: 2227 [45568/60000 (76%)] Loss: -1300.448486\n",
      "Train Epoch: 2227 [56832/60000 (95%)] Loss: -1536.440308\n",
      "    epoch          : 2227\n",
      "    loss           : -1397.283976926642\n",
      "Train Epoch: 2228 [512/60000 (1%)] Loss: -1395.721558\n",
      "Train Epoch: 2228 [11776/60000 (20%)] Loss: -1474.496582\n",
      "Train Epoch: 2228 [23040/60000 (38%)] Loss: -1280.214355\n",
      "Train Epoch: 2228 [34304/60000 (57%)] Loss: -1311.590698\n",
      "Train Epoch: 2228 [45568/60000 (76%)] Loss: -1411.498535\n",
      "Train Epoch: 2228 [56832/60000 (95%)] Loss: -1189.806519\n",
      "    epoch          : 2228\n",
      "    loss           : -1407.3288894911943\n",
      "Train Epoch: 2229 [512/60000 (1%)] Loss: -1282.292603\n",
      "Train Epoch: 2229 [11776/60000 (20%)] Loss: -1513.042725\n",
      "Train Epoch: 2229 [23040/60000 (38%)] Loss: -1490.378052\n",
      "Train Epoch: 2229 [34304/60000 (57%)] Loss: -1521.174683\n",
      "Train Epoch: 2229 [45568/60000 (76%)] Loss: -1256.727783\n",
      "Train Epoch: 2229 [56832/60000 (95%)] Loss: -1187.076416\n",
      "    epoch          : 2229\n",
      "    loss           : -1388.3852932170287\n",
      "Train Epoch: 2230 [512/60000 (1%)] Loss: -1188.720703\n",
      "Train Epoch: 2230 [11776/60000 (20%)] Loss: -1399.999756\n",
      "Train Epoch: 2230 [23040/60000 (38%)] Loss: -1326.427856\n",
      "Train Epoch: 2230 [34304/60000 (57%)] Loss: -1263.429565\n",
      "Train Epoch: 2230 [45568/60000 (76%)] Loss: -1381.978027\n",
      "Train Epoch: 2230 [56832/60000 (95%)] Loss: -1413.940186\n",
      "    epoch          : 2230\n",
      "    loss           : -1412.4608016364318\n",
      "Train Epoch: 2231 [512/60000 (1%)] Loss: -1529.691406\n",
      "Train Epoch: 2231 [11776/60000 (20%)] Loss: -1415.647339\n",
      "Train Epoch: 2231 [23040/60000 (38%)] Loss: -1426.534546\n",
      "Train Epoch: 2231 [34304/60000 (57%)] Loss: -1316.738525\n",
      "Train Epoch: 2231 [45568/60000 (76%)] Loss: -1317.792480\n",
      "Train Epoch: 2231 [56832/60000 (95%)] Loss: -1407.199219\n",
      "    epoch          : 2231\n",
      "    loss           : -1402.6030718269994\n",
      "Train Epoch: 2232 [512/60000 (1%)] Loss: -1398.596924\n",
      "Train Epoch: 2232 [11776/60000 (20%)] Loss: -1349.406738\n",
      "Train Epoch: 2232 [23040/60000 (38%)] Loss: -1291.263794\n",
      "Train Epoch: 2232 [34304/60000 (57%)] Loss: -1270.147095\n",
      "Train Epoch: 2232 [45568/60000 (76%)] Loss: -1449.397705\n",
      "Train Epoch: 2232 [56832/60000 (95%)] Loss: -1426.982666\n",
      "    epoch          : 2232\n",
      "    loss           : -1401.2709250584833\n",
      "Train Epoch: 2233 [512/60000 (1%)] Loss: -1315.271729\n",
      "Train Epoch: 2233 [11776/60000 (20%)] Loss: -1334.693115\n",
      "Train Epoch: 2233 [23040/60000 (38%)] Loss: -1452.125732\n",
      "Train Epoch: 2233 [34304/60000 (57%)] Loss: -1545.970093\n",
      "Train Epoch: 2233 [45568/60000 (76%)] Loss: -1402.705200\n",
      "Train Epoch: 2233 [56832/60000 (95%)] Loss: -1162.360596\n",
      "    epoch          : 2233\n",
      "    loss           : -1409.008175607455\n",
      "Train Epoch: 2234 [512/60000 (1%)] Loss: -1420.067261\n",
      "Train Epoch: 2234 [11776/60000 (20%)] Loss: -1381.281616\n",
      "Train Epoch: 2234 [23040/60000 (38%)] Loss: -1263.033447\n",
      "Train Epoch: 2234 [34304/60000 (57%)] Loss: -1281.726807\n",
      "Train Epoch: 2234 [45568/60000 (76%)] Loss: -1556.452759\n",
      "Train Epoch: 2234 [56832/60000 (95%)] Loss: -1321.876709\n",
      "    epoch          : 2234\n",
      "    loss           : -1394.2134385620807\n",
      "Train Epoch: 2235 [512/60000 (1%)] Loss: -1316.793945\n",
      "Train Epoch: 2235 [11776/60000 (20%)] Loss: -1048.487793\n",
      "Train Epoch: 2235 [23040/60000 (38%)] Loss: -1528.000732\n",
      "Train Epoch: 2235 [34304/60000 (57%)] Loss: -1325.535645\n",
      "Train Epoch: 2235 [45568/60000 (76%)] Loss: -1322.017822\n",
      "Train Epoch: 2235 [56832/60000 (95%)] Loss: -1518.351929\n",
      "    epoch          : 2235\n",
      "    loss           : -1403.4903688592426\n",
      "Train Epoch: 2236 [512/60000 (1%)] Loss: -1339.370117\n",
      "Train Epoch: 2236 [11776/60000 (20%)] Loss: -1198.304932\n",
      "Train Epoch: 2236 [23040/60000 (38%)] Loss: -1379.846436\n",
      "Train Epoch: 2236 [34304/60000 (57%)] Loss: -1483.509521\n",
      "Train Epoch: 2236 [45568/60000 (76%)] Loss: -1397.500488\n",
      "Train Epoch: 2236 [56832/60000 (95%)] Loss: -1261.349243\n",
      "    epoch          : 2236\n",
      "    loss           : -1391.6190795898438\n",
      "Train Epoch: 2237 [512/60000 (1%)] Loss: -1546.790405\n",
      "Train Epoch: 2237 [11776/60000 (20%)] Loss: -1162.679810\n",
      "Train Epoch: 2237 [23040/60000 (38%)] Loss: -1332.732544\n",
      "Train Epoch: 2237 [34304/60000 (57%)] Loss: -1416.038208\n",
      "Train Epoch: 2237 [45568/60000 (76%)] Loss: -1469.106201\n",
      "Train Epoch: 2237 [56832/60000 (95%)] Loss: -1358.497559\n",
      "    epoch          : 2237\n",
      "    loss           : -1392.958609888109\n",
      "Train Epoch: 2238 [512/60000 (1%)] Loss: -1452.107910\n",
      "Train Epoch: 2238 [11776/60000 (20%)] Loss: -1380.490601\n",
      "Train Epoch: 2238 [23040/60000 (38%)] Loss: -1380.521973\n",
      "Train Epoch: 2238 [34304/60000 (57%)] Loss: -1519.827393\n",
      "Train Epoch: 2238 [45568/60000 (76%)] Loss: -1297.516602\n",
      "Train Epoch: 2238 [56832/60000 (95%)] Loss: -1410.239258\n",
      "    epoch          : 2238\n",
      "    loss           : -1387.8592901714778\n",
      "Train Epoch: 2239 [512/60000 (1%)] Loss: -1548.631348\n",
      "Train Epoch: 2239 [11776/60000 (20%)] Loss: -1206.390747\n",
      "Train Epoch: 2239 [23040/60000 (38%)] Loss: -1278.607910\n",
      "Train Epoch: 2239 [34304/60000 (57%)] Loss: -1525.186646\n",
      "Train Epoch: 2239 [45568/60000 (76%)] Loss: -1265.603638\n",
      "Train Epoch: 2239 [56832/60000 (95%)] Loss: -1538.440186\n",
      "    epoch          : 2239\n",
      "    loss           : -1411.2980263920153\n",
      "Train Epoch: 2240 [512/60000 (1%)] Loss: -1403.497559\n",
      "Train Epoch: 2240 [11776/60000 (20%)] Loss: -1426.724609\n",
      "Train Epoch: 2240 [23040/60000 (38%)] Loss: -1327.585815\n",
      "Train Epoch: 2240 [34304/60000 (57%)] Loss: -1552.408813\n",
      "Train Epoch: 2240 [45568/60000 (76%)] Loss: -1437.679199\n",
      "Train Epoch: 2240 [56832/60000 (95%)] Loss: -1444.849854\n",
      "    epoch          : 2240\n",
      "    loss           : -1377.8300850216278\n",
      "Train Epoch: 2241 [512/60000 (1%)] Loss: -1288.426758\n",
      "Train Epoch: 2241 [11776/60000 (20%)] Loss: -1332.777344\n",
      "Train Epoch: 2241 [23040/60000 (38%)] Loss: -1299.235107\n",
      "Train Epoch: 2241 [34304/60000 (57%)] Loss: -1553.490234\n",
      "Train Epoch: 2241 [45568/60000 (76%)] Loss: -1214.422119\n",
      "Train Epoch: 2241 [56832/60000 (95%)] Loss: -1436.874756\n",
      "    epoch          : 2241\n",
      "    loss           : -1393.038674564685\n",
      "Train Epoch: 2242 [512/60000 (1%)] Loss: -1262.625854\n",
      "Train Epoch: 2242 [11776/60000 (20%)] Loss: -1479.652832\n",
      "Train Epoch: 2242 [23040/60000 (38%)] Loss: -1414.116211\n",
      "Train Epoch: 2242 [34304/60000 (57%)] Loss: -1412.295166\n",
      "Train Epoch: 2242 [45568/60000 (76%)] Loss: -1158.906006\n",
      "Train Epoch: 2242 [56832/60000 (95%)] Loss: -1427.883789\n",
      "    epoch          : 2242\n",
      "    loss           : -1407.063537252825\n",
      "Train Epoch: 2243 [512/60000 (1%)] Loss: -1396.883667\n",
      "Train Epoch: 2243 [11776/60000 (20%)] Loss: -1429.424194\n",
      "Train Epoch: 2243 [23040/60000 (38%)] Loss: -1458.750977\n",
      "Train Epoch: 2243 [34304/60000 (57%)] Loss: -1408.875366\n",
      "Train Epoch: 2243 [45568/60000 (76%)] Loss: -1303.516846\n",
      "Train Epoch: 2243 [56832/60000 (95%)] Loss: -1327.844849\n",
      "    epoch          : 2243\n",
      "    loss           : -1381.8736392953303\n",
      "Train Epoch: 2244 [512/60000 (1%)] Loss: -1075.335449\n",
      "Train Epoch: 2244 [11776/60000 (20%)] Loss: -1316.465698\n",
      "Train Epoch: 2244 [23040/60000 (38%)] Loss: -1563.793701\n",
      "Train Epoch: 2244 [34304/60000 (57%)] Loss: -1538.468994\n",
      "Train Epoch: 2244 [45568/60000 (76%)] Loss: -1528.079712\n",
      "Train Epoch: 2244 [56832/60000 (95%)] Loss: -1407.878906\n",
      "    epoch          : 2244\n",
      "    loss           : -1385.4528074102886\n",
      "Train Epoch: 2245 [512/60000 (1%)] Loss: -1335.323975\n",
      "Train Epoch: 2245 [11776/60000 (20%)] Loss: -1438.643799\n",
      "Train Epoch: 2245 [23040/60000 (38%)] Loss: -1294.697510\n",
      "Train Epoch: 2245 [34304/60000 (57%)] Loss: -1307.030518\n",
      "Train Epoch: 2245 [45568/60000 (76%)] Loss: -1216.127197\n",
      "Train Epoch: 2245 [56832/60000 (95%)] Loss: -1514.170288\n",
      "    epoch          : 2245\n",
      "    loss           : -1395.857008422162\n",
      "Train Epoch: 2246 [512/60000 (1%)] Loss: -1267.439941\n",
      "Train Epoch: 2246 [11776/60000 (20%)] Loss: -1407.433716\n",
      "Train Epoch: 2246 [23040/60000 (38%)] Loss: -1558.628784\n",
      "Train Epoch: 2246 [34304/60000 (57%)] Loss: -1535.254395\n",
      "Train Epoch: 2246 [45568/60000 (76%)] Loss: -1193.486084\n",
      "Train Epoch: 2246 [56832/60000 (95%)] Loss: -1180.423218\n",
      "    epoch          : 2246\n",
      "    loss           : -1408.3558718578965\n",
      "Train Epoch: 2247 [512/60000 (1%)] Loss: -1439.605347\n",
      "Train Epoch: 2247 [11776/60000 (20%)] Loss: -1404.974976\n",
      "Train Epoch: 2247 [23040/60000 (38%)] Loss: -1323.470947\n",
      "Train Epoch: 2247 [34304/60000 (57%)] Loss: -1403.950684\n",
      "Train Epoch: 2247 [45568/60000 (76%)] Loss: -1313.277832\n",
      "Train Epoch: 2247 [56832/60000 (95%)] Loss: -1416.992310\n",
      "    epoch          : 2247\n",
      "    loss           : -1405.5332051939884\n",
      "Train Epoch: 2248 [512/60000 (1%)] Loss: -1563.374268\n",
      "Train Epoch: 2248 [11776/60000 (20%)] Loss: -1322.597656\n",
      "Train Epoch: 2248 [23040/60000 (38%)] Loss: -1326.414551\n",
      "Train Epoch: 2248 [34304/60000 (57%)] Loss: -1560.317871\n",
      "Train Epoch: 2248 [45568/60000 (76%)] Loss: -1315.222290\n",
      "Train Epoch: 2248 [56832/60000 (95%)] Loss: -1444.160522\n",
      "    epoch          : 2248\n",
      "    loss           : -1400.8453507073182\n",
      "Train Epoch: 2249 [512/60000 (1%)] Loss: -1275.382568\n",
      "Train Epoch: 2249 [11776/60000 (20%)] Loss: -1549.288818\n",
      "Train Epoch: 2249 [23040/60000 (38%)] Loss: -1422.031372\n",
      "Train Epoch: 2249 [34304/60000 (57%)] Loss: -1410.533447\n",
      "Train Epoch: 2249 [45568/60000 (76%)] Loss: -1389.570801\n",
      "Train Epoch: 2249 [56832/60000 (95%)] Loss: -1416.603394\n",
      "    epoch          : 2249\n",
      "    loss           : -1408.391005693856\n",
      "Train Epoch: 2250 [512/60000 (1%)] Loss: -1550.279907\n",
      "Train Epoch: 2250 [11776/60000 (20%)] Loss: -1256.705811\n",
      "Train Epoch: 2250 [23040/60000 (38%)] Loss: -1500.987427\n",
      "Train Epoch: 2250 [34304/60000 (57%)] Loss: -1414.413940\n",
      "Train Epoch: 2250 [45568/60000 (76%)] Loss: -1548.170898\n",
      "Train Epoch: 2250 [56832/60000 (95%)] Loss: -1526.107544\n",
      "    epoch          : 2250\n",
      "    loss           : -1412.8327722926597\n",
      "Train Epoch: 2251 [512/60000 (1%)] Loss: -1539.023804\n",
      "Train Epoch: 2251 [11776/60000 (20%)] Loss: -1274.227295\n",
      "Train Epoch: 2251 [23040/60000 (38%)] Loss: -1449.109863\n",
      "Train Epoch: 2251 [34304/60000 (57%)] Loss: -1315.501953\n",
      "Train Epoch: 2251 [45568/60000 (76%)] Loss: -1568.235229\n",
      "Train Epoch: 2251 [56832/60000 (95%)] Loss: -1464.196045\n",
      "    epoch          : 2251\n",
      "    loss           : -1391.4258971133474\n",
      "Train Epoch: 2252 [512/60000 (1%)] Loss: -1418.066772\n",
      "Train Epoch: 2252 [11776/60000 (20%)] Loss: -1412.688354\n",
      "Train Epoch: 2252 [23040/60000 (38%)] Loss: -1516.829834\n",
      "Train Epoch: 2252 [34304/60000 (57%)] Loss: -1436.337891\n",
      "Train Epoch: 2252 [45568/60000 (76%)] Loss: -1315.341187\n",
      "Train Epoch: 2252 [56832/60000 (95%)] Loss: -1405.945557\n",
      "    epoch          : 2252\n",
      "    loss           : -1399.9467721712792\n",
      "Train Epoch: 2253 [512/60000 (1%)] Loss: -1493.966675\n",
      "Train Epoch: 2253 [11776/60000 (20%)] Loss: -1429.194824\n",
      "Train Epoch: 2253 [23040/60000 (38%)] Loss: -1311.627441\n",
      "Train Epoch: 2253 [34304/60000 (57%)] Loss: -1418.763184\n",
      "Train Epoch: 2253 [45568/60000 (76%)] Loss: -1432.925781\n",
      "Train Epoch: 2253 [56832/60000 (95%)] Loss: -1547.790649\n",
      "    epoch          : 2253\n",
      "    loss           : -1400.4494904771364\n",
      "Train Epoch: 2254 [512/60000 (1%)] Loss: -1537.740723\n",
      "Train Epoch: 2254 [11776/60000 (20%)] Loss: -1318.679321\n",
      "Train Epoch: 2254 [23040/60000 (38%)] Loss: -1530.669678\n",
      "Train Epoch: 2254 [34304/60000 (57%)] Loss: -1535.898193\n",
      "Train Epoch: 2254 [45568/60000 (76%)] Loss: -1249.623047\n",
      "Train Epoch: 2254 [56832/60000 (95%)] Loss: -1426.053711\n",
      "    epoch          : 2254\n",
      "    loss           : -1398.1950473246602\n",
      "Train Epoch: 2255 [512/60000 (1%)] Loss: -1353.140503\n",
      "Train Epoch: 2255 [11776/60000 (20%)] Loss: -1410.359619\n",
      "Train Epoch: 2255 [23040/60000 (38%)] Loss: -1404.202393\n",
      "Train Epoch: 2255 [34304/60000 (57%)] Loss: -1417.008179\n",
      "Train Epoch: 2255 [45568/60000 (76%)] Loss: -1216.927124\n",
      "Train Epoch: 2255 [56832/60000 (95%)] Loss: -1315.488892\n",
      "    epoch          : 2255\n",
      "    loss           : -1389.1760564254503\n",
      "Train Epoch: 2256 [512/60000 (1%)] Loss: -1410.504639\n",
      "Train Epoch: 2256 [11776/60000 (20%)] Loss: -1400.188843\n",
      "Train Epoch: 2256 [23040/60000 (38%)] Loss: -1536.375732\n",
      "Train Epoch: 2256 [34304/60000 (57%)] Loss: -1567.179443\n",
      "Train Epoch: 2256 [45568/60000 (76%)] Loss: -1512.336182\n",
      "Train Epoch: 2256 [56832/60000 (95%)] Loss: -1283.848145\n",
      "    epoch          : 2256\n",
      "    loss           : -1398.4887257376633\n",
      "Train Epoch: 2257 [512/60000 (1%)] Loss: -1392.533569\n",
      "Train Epoch: 2257 [11776/60000 (20%)] Loss: -1184.025269\n",
      "Train Epoch: 2257 [23040/60000 (38%)] Loss: -1534.876221\n",
      "Train Epoch: 2257 [34304/60000 (57%)] Loss: -1547.264404\n",
      "Train Epoch: 2257 [45568/60000 (76%)] Loss: -1552.744263\n",
      "Train Epoch: 2257 [56832/60000 (95%)] Loss: -1401.039062\n",
      "    epoch          : 2257\n",
      "    loss           : -1408.4747293763241\n",
      "Train Epoch: 2258 [512/60000 (1%)] Loss: -1329.616211\n",
      "Train Epoch: 2258 [11776/60000 (20%)] Loss: -1269.766357\n",
      "Train Epoch: 2258 [23040/60000 (38%)] Loss: -1403.694580\n",
      "Train Epoch: 2258 [34304/60000 (57%)] Loss: -1539.088501\n",
      "Train Epoch: 2258 [45568/60000 (76%)] Loss: -1478.031494\n",
      "Train Epoch: 2258 [56832/60000 (95%)] Loss: -1268.380005\n",
      "    epoch          : 2258\n",
      "    loss           : -1387.7311256538003\n",
      "Train Epoch: 2259 [512/60000 (1%)] Loss: -1420.729736\n",
      "Train Epoch: 2259 [11776/60000 (20%)] Loss: -1383.639526\n",
      "Train Epoch: 2259 [23040/60000 (38%)] Loss: -1443.371948\n",
      "Train Epoch: 2259 [34304/60000 (57%)] Loss: -1389.525879\n",
      "Train Epoch: 2259 [45568/60000 (76%)] Loss: -1173.450317\n",
      "Train Epoch: 2259 [56832/60000 (95%)] Loss: -1289.056396\n",
      "    epoch          : 2259\n",
      "    loss           : -1389.7455302955066\n",
      "Train Epoch: 2260 [512/60000 (1%)] Loss: -1448.253174\n",
      "Train Epoch: 2260 [11776/60000 (20%)] Loss: -1436.516479\n",
      "Train Epoch: 2260 [23040/60000 (38%)] Loss: -1289.410156\n",
      "Train Epoch: 2260 [34304/60000 (57%)] Loss: -1332.894775\n",
      "Train Epoch: 2260 [45568/60000 (76%)] Loss: -1432.544312\n",
      "Train Epoch: 2260 [56832/60000 (95%)] Loss: -1409.225952\n",
      "    epoch          : 2260\n",
      "    loss           : -1387.4939799335718\n",
      "Train Epoch: 2261 [512/60000 (1%)] Loss: -1455.333008\n",
      "Train Epoch: 2261 [11776/60000 (20%)] Loss: -1440.204834\n",
      "Train Epoch: 2261 [23040/60000 (38%)] Loss: -1307.807251\n",
      "Train Epoch: 2261 [34304/60000 (57%)] Loss: -1528.482422\n",
      "Train Epoch: 2261 [45568/60000 (76%)] Loss: -1334.932251\n",
      "Train Epoch: 2261 [56832/60000 (95%)] Loss: -1538.596069\n",
      "    epoch          : 2261\n",
      "    loss           : -1412.1167626677259\n",
      "Train Epoch: 2262 [512/60000 (1%)] Loss: -1505.995239\n",
      "Train Epoch: 2262 [11776/60000 (20%)] Loss: -1332.265747\n",
      "Train Epoch: 2262 [23040/60000 (38%)] Loss: -1295.229492\n",
      "Train Epoch: 2262 [34304/60000 (57%)] Loss: -1397.903320\n",
      "Train Epoch: 2262 [45568/60000 (76%)] Loss: -1192.319824\n",
      "Train Epoch: 2262 [56832/60000 (95%)] Loss: -1174.546875\n",
      "    epoch          : 2262\n",
      "    loss           : -1390.486151916159\n",
      "Train Epoch: 2263 [512/60000 (1%)] Loss: -1558.939453\n",
      "Train Epoch: 2263 [11776/60000 (20%)] Loss: -1384.868164\n",
      "Train Epoch: 2263 [23040/60000 (38%)] Loss: -1439.070801\n",
      "Train Epoch: 2263 [34304/60000 (57%)] Loss: -1578.114014\n",
      "Train Epoch: 2263 [45568/60000 (76%)] Loss: -1198.110596\n",
      "Train Epoch: 2263 [56832/60000 (95%)] Loss: -1385.298340\n",
      "    epoch          : 2263\n",
      "    loss           : -1407.94673768814\n",
      "Train Epoch: 2264 [512/60000 (1%)] Loss: -1310.702881\n",
      "Train Epoch: 2264 [11776/60000 (20%)] Loss: -1449.536377\n",
      "Train Epoch: 2264 [23040/60000 (38%)] Loss: -1292.315063\n",
      "Train Epoch: 2264 [34304/60000 (57%)] Loss: -1502.473511\n",
      "Train Epoch: 2264 [45568/60000 (76%)] Loss: -1526.132690\n",
      "Train Epoch: 2264 [56832/60000 (95%)] Loss: -1422.327881\n",
      "    epoch          : 2264\n",
      "    loss           : -1404.2576328428452\n",
      "Train Epoch: 2265 [512/60000 (1%)] Loss: -1264.752686\n",
      "Train Epoch: 2265 [11776/60000 (20%)] Loss: -1145.064941\n",
      "Train Epoch: 2265 [23040/60000 (38%)] Loss: -1508.419434\n",
      "Train Epoch: 2265 [34304/60000 (57%)] Loss: -1329.789551\n",
      "Train Epoch: 2265 [45568/60000 (76%)] Loss: -1353.820068\n",
      "Train Epoch: 2265 [56832/60000 (95%)] Loss: -1368.044312\n",
      "    epoch          : 2265\n",
      "    loss           : -1395.2841217558262\n",
      "Train Epoch: 2266 [512/60000 (1%)] Loss: -1189.681030\n",
      "Train Epoch: 2266 [11776/60000 (20%)] Loss: -1386.267090\n",
      "Train Epoch: 2266 [23040/60000 (38%)] Loss: -1406.564453\n",
      "Train Epoch: 2266 [34304/60000 (57%)] Loss: -1214.805420\n",
      "Train Epoch: 2266 [45568/60000 (76%)] Loss: -1502.805298\n",
      "Train Epoch: 2266 [56832/60000 (95%)] Loss: -1302.642578\n",
      "    epoch          : 2266\n",
      "    loss           : -1381.6753719351384\n",
      "Train Epoch: 2267 [512/60000 (1%)] Loss: -1430.615479\n",
      "Train Epoch: 2267 [11776/60000 (20%)] Loss: -1544.510010\n",
      "Train Epoch: 2267 [23040/60000 (38%)] Loss: -1300.835571\n",
      "Train Epoch: 2267 [34304/60000 (57%)] Loss: -1545.769653\n",
      "Train Epoch: 2267 [45568/60000 (76%)] Loss: -1449.870850\n",
      "Train Epoch: 2267 [56832/60000 (95%)] Loss: -1232.338135\n",
      "    epoch          : 2267\n",
      "    loss           : -1387.2027846514168\n",
      "Train Epoch: 2268 [512/60000 (1%)] Loss: -1546.736328\n",
      "Train Epoch: 2268 [11776/60000 (20%)] Loss: -1463.262207\n",
      "Train Epoch: 2268 [23040/60000 (38%)] Loss: -1480.651245\n",
      "Train Epoch: 2268 [34304/60000 (57%)] Loss: -1424.756470\n",
      "Train Epoch: 2268 [45568/60000 (76%)] Loss: -1328.328613\n",
      "Train Epoch: 2268 [56832/60000 (95%)] Loss: -1321.109497\n",
      "    epoch          : 2268\n",
      "    loss           : -1399.7633991133694\n",
      "Train Epoch: 2269 [512/60000 (1%)] Loss: -1282.193237\n",
      "Train Epoch: 2269 [11776/60000 (20%)] Loss: -1396.756958\n",
      "Train Epoch: 2269 [23040/60000 (38%)] Loss: -1456.406616\n",
      "Train Epoch: 2269 [34304/60000 (57%)] Loss: -1320.054199\n",
      "Train Epoch: 2269 [45568/60000 (76%)] Loss: -1292.433472\n",
      "Train Epoch: 2269 [56832/60000 (95%)] Loss: -1486.816406\n",
      "    epoch          : 2269\n",
      "    loss           : -1405.9727755616614\n",
      "Train Epoch: 2270 [512/60000 (1%)] Loss: -1473.549316\n",
      "Train Epoch: 2270 [11776/60000 (20%)] Loss: -1412.660767\n",
      "Train Epoch: 2270 [23040/60000 (38%)] Loss: -1247.503662\n",
      "Train Epoch: 2270 [34304/60000 (57%)] Loss: -1409.797363\n",
      "Train Epoch: 2270 [45568/60000 (76%)] Loss: -1533.734619\n",
      "Train Epoch: 2270 [56832/60000 (95%)] Loss: -1420.282715\n",
      "    epoch          : 2270\n",
      "    loss           : -1418.76421222579\n",
      "Train Epoch: 2271 [512/60000 (1%)] Loss: -1558.734375\n",
      "Train Epoch: 2271 [11776/60000 (20%)] Loss: -1423.521729\n",
      "Train Epoch: 2271 [23040/60000 (38%)] Loss: -1568.389893\n",
      "Train Epoch: 2271 [34304/60000 (57%)] Loss: -1287.022217\n",
      "Train Epoch: 2271 [45568/60000 (76%)] Loss: -1426.438477\n",
      "Train Epoch: 2271 [56832/60000 (95%)] Loss: -1560.990234\n",
      "    epoch          : 2271\n",
      "    loss           : -1407.6796309476517\n",
      "Train Epoch: 2272 [512/60000 (1%)] Loss: -1212.683594\n",
      "Train Epoch: 2272 [11776/60000 (20%)] Loss: -1434.832764\n",
      "Train Epoch: 2272 [23040/60000 (38%)] Loss: -1550.663208\n",
      "Train Epoch: 2272 [34304/60000 (57%)] Loss: -1503.919312\n",
      "Train Epoch: 2272 [45568/60000 (76%)] Loss: -1399.589355\n",
      "Train Epoch: 2272 [56832/60000 (95%)] Loss: -1428.365112\n",
      "    epoch          : 2272\n",
      "    loss           : -1424.3299857101872\n",
      "Train Epoch: 2273 [512/60000 (1%)] Loss: -1322.436768\n",
      "Train Epoch: 2273 [11776/60000 (20%)] Loss: -1459.451294\n",
      "Train Epoch: 2273 [23040/60000 (38%)] Loss: -1550.020020\n",
      "Train Epoch: 2273 [34304/60000 (57%)] Loss: -1411.220581\n",
      "Train Epoch: 2273 [45568/60000 (76%)] Loss: -1552.945312\n",
      "Train Epoch: 2273 [56832/60000 (95%)] Loss: -1441.499023\n",
      "    epoch          : 2273\n",
      "    loss           : -1437.2236214330642\n",
      "Train Epoch: 2274 [512/60000 (1%)] Loss: -1323.058472\n",
      "Train Epoch: 2274 [11776/60000 (20%)] Loss: -1431.639526\n",
      "Train Epoch: 2274 [23040/60000 (38%)] Loss: -1450.911255\n",
      "Train Epoch: 2274 [34304/60000 (57%)] Loss: -1515.510498\n",
      "Train Epoch: 2274 [45568/60000 (76%)] Loss: -1284.808960\n",
      "Train Epoch: 2274 [56832/60000 (95%)] Loss: -1289.611572\n",
      "    epoch          : 2274\n",
      "    loss           : -1413.4343854828742\n",
      "Train Epoch: 2275 [512/60000 (1%)] Loss: -1434.077393\n",
      "Train Epoch: 2275 [11776/60000 (20%)] Loss: -1375.766846\n",
      "Train Epoch: 2275 [23040/60000 (38%)] Loss: -1433.167603\n",
      "Train Epoch: 2275 [34304/60000 (57%)] Loss: -1536.982666\n",
      "Train Epoch: 2275 [45568/60000 (76%)] Loss: -1441.203735\n",
      "Train Epoch: 2275 [56832/60000 (95%)] Loss: -1193.923096\n",
      "    epoch          : 2275\n",
      "    loss           : -1406.9805135780807\n",
      "Train Epoch: 2276 [512/60000 (1%)] Loss: -1353.392456\n",
      "Train Epoch: 2276 [11776/60000 (20%)] Loss: -1551.922241\n",
      "Train Epoch: 2276 [23040/60000 (38%)] Loss: -1335.526123\n",
      "Train Epoch: 2276 [34304/60000 (57%)] Loss: -1438.268433\n",
      "Train Epoch: 2276 [45568/60000 (76%)] Loss: -1550.819824\n",
      "Train Epoch: 2276 [56832/60000 (95%)] Loss: -1425.598389\n",
      "    epoch          : 2276\n",
      "    loss           : -1414.7507865604034\n",
      "Train Epoch: 2277 [512/60000 (1%)] Loss: -1471.401978\n",
      "Train Epoch: 2277 [11776/60000 (20%)] Loss: -1433.522705\n",
      "Train Epoch: 2277 [23040/60000 (38%)] Loss: -1418.752441\n",
      "Train Epoch: 2277 [34304/60000 (57%)] Loss: -1449.965332\n",
      "Train Epoch: 2277 [45568/60000 (76%)] Loss: -1431.384399\n",
      "Train Epoch: 2277 [56832/60000 (95%)] Loss: -1401.361572\n",
      "    epoch          : 2277\n",
      "    loss           : -1422.4541788047318\n",
      "Train Epoch: 2278 [512/60000 (1%)] Loss: -1474.795654\n",
      "Train Epoch: 2278 [11776/60000 (20%)] Loss: -1219.568604\n",
      "Train Epoch: 2278 [23040/60000 (38%)] Loss: -1311.760498\n",
      "Train Epoch: 2278 [34304/60000 (57%)] Loss: -1524.484985\n",
      "Train Epoch: 2278 [45568/60000 (76%)] Loss: -1544.776489\n",
      "Train Epoch: 2278 [56832/60000 (95%)] Loss: -1520.134766\n",
      "    epoch          : 2278\n",
      "    loss           : -1421.5849750755872\n",
      "Train Epoch: 2279 [512/60000 (1%)] Loss: -1545.203613\n",
      "Train Epoch: 2279 [11776/60000 (20%)] Loss: -1280.539795\n",
      "Train Epoch: 2279 [23040/60000 (38%)] Loss: -1307.043335\n",
      "Train Epoch: 2279 [34304/60000 (57%)] Loss: -1445.542847\n",
      "Train Epoch: 2279 [45568/60000 (76%)] Loss: -1449.224854\n",
      "Train Epoch: 2279 [56832/60000 (95%)] Loss: -1224.384521\n",
      "    epoch          : 2279\n",
      "    loss           : -1429.8283653474796\n",
      "Train Epoch: 2280 [512/60000 (1%)] Loss: -1491.731201\n",
      "Train Epoch: 2280 [11776/60000 (20%)] Loss: -1556.342529\n",
      "Train Epoch: 2280 [23040/60000 (38%)] Loss: -1266.539307\n",
      "Train Epoch: 2280 [34304/60000 (57%)] Loss: -1347.276733\n",
      "Train Epoch: 2280 [45568/60000 (76%)] Loss: -1393.245605\n",
      "Train Epoch: 2280 [56832/60000 (95%)] Loss: -1531.335449\n",
      "    epoch          : 2280\n",
      "    loss           : -1428.971952793962\n",
      "Train Epoch: 2281 [512/60000 (1%)] Loss: -1393.146484\n",
      "Train Epoch: 2281 [11776/60000 (20%)] Loss: -1472.017334\n",
      "Train Epoch: 2281 [23040/60000 (38%)] Loss: -1229.635986\n",
      "Train Epoch: 2281 [34304/60000 (57%)] Loss: -1555.565796\n",
      "Train Epoch: 2281 [45568/60000 (76%)] Loss: -1445.098633\n",
      "Train Epoch: 2281 [56832/60000 (95%)] Loss: -1389.497803\n",
      "    epoch          : 2281\n",
      "    loss           : -1406.4797277073403\n",
      "Train Epoch: 2282 [512/60000 (1%)] Loss: -1341.107788\n",
      "Train Epoch: 2282 [11776/60000 (20%)] Loss: -1204.034424\n",
      "Train Epoch: 2282 [23040/60000 (38%)] Loss: -1465.075806\n",
      "Train Epoch: 2282 [34304/60000 (57%)] Loss: -1337.222900\n",
      "Train Epoch: 2282 [45568/60000 (76%)] Loss: -1318.149902\n",
      "Train Epoch: 2282 [56832/60000 (95%)] Loss: -1291.999390\n",
      "    epoch          : 2282\n",
      "    loss           : -1402.2101264565679\n",
      "Train Epoch: 2283 [512/60000 (1%)] Loss: -1367.388672\n",
      "Train Epoch: 2283 [11776/60000 (20%)] Loss: -1298.034180\n",
      "Train Epoch: 2283 [23040/60000 (38%)] Loss: -1309.992188\n",
      "Train Epoch: 2283 [34304/60000 (57%)] Loss: -1445.747192\n",
      "Train Epoch: 2283 [45568/60000 (76%)] Loss: -1423.168213\n",
      "Train Epoch: 2283 [56832/60000 (95%)] Loss: -1435.933838\n",
      "    epoch          : 2283\n",
      "    loss           : -1419.7548910884534\n",
      "Train Epoch: 2284 [512/60000 (1%)] Loss: -1418.393311\n",
      "Train Epoch: 2284 [11776/60000 (20%)] Loss: -1453.749268\n",
      "Train Epoch: 2284 [23040/60000 (38%)] Loss: -1531.594238\n",
      "Train Epoch: 2284 [34304/60000 (57%)] Loss: -1517.297729\n",
      "Train Epoch: 2284 [45568/60000 (76%)] Loss: -1314.073730\n",
      "Train Epoch: 2284 [56832/60000 (95%)] Loss: -1424.351562\n",
      "    epoch          : 2284\n",
      "    loss           : -1408.6843541032176\n",
      "Train Epoch: 2285 [512/60000 (1%)] Loss: -1510.643066\n",
      "Train Epoch: 2285 [11776/60000 (20%)] Loss: -1558.207764\n",
      "Train Epoch: 2285 [23040/60000 (38%)] Loss: -1495.348389\n",
      "Train Epoch: 2285 [34304/60000 (57%)] Loss: -1360.000244\n",
      "Train Epoch: 2285 [45568/60000 (76%)] Loss: -1159.745605\n",
      "Train Epoch: 2285 [56832/60000 (95%)] Loss: -1260.877930\n",
      "    epoch          : 2285\n",
      "    loss           : -1420.635057352357\n",
      "Train Epoch: 2286 [512/60000 (1%)] Loss: -1464.992920\n",
      "Train Epoch: 2286 [11776/60000 (20%)] Loss: -1429.635132\n",
      "Train Epoch: 2286 [23040/60000 (38%)] Loss: -1450.057617\n",
      "Train Epoch: 2286 [34304/60000 (57%)] Loss: -1314.737793\n",
      "Train Epoch: 2286 [45568/60000 (76%)] Loss: -1516.414307\n",
      "Train Epoch: 2286 [56832/60000 (95%)] Loss: -1462.589233\n",
      "    epoch          : 2286\n",
      "    loss           : -1420.179484049479\n",
      "Train Epoch: 2287 [512/60000 (1%)] Loss: -1452.415894\n",
      "Train Epoch: 2287 [11776/60000 (20%)] Loss: -1481.391724\n",
      "Train Epoch: 2287 [23040/60000 (38%)] Loss: -1312.441406\n",
      "Train Epoch: 2287 [34304/60000 (57%)] Loss: -1444.293091\n",
      "Train Epoch: 2287 [45568/60000 (76%)] Loss: -1318.691650\n",
      "Train Epoch: 2287 [56832/60000 (95%)] Loss: -1581.965332\n",
      "    epoch          : 2287\n",
      "    loss           : -1426.0017834679554\n",
      "Train Epoch: 2288 [512/60000 (1%)] Loss: -1420.559814\n",
      "Train Epoch: 2288 [11776/60000 (20%)] Loss: -1439.577148\n",
      "Train Epoch: 2288 [23040/60000 (38%)] Loss: -1545.084473\n",
      "Train Epoch: 2288 [34304/60000 (57%)] Loss: -1553.316895\n",
      "Train Epoch: 2288 [45568/60000 (76%)] Loss: -1441.622192\n",
      "Train Epoch: 2288 [56832/60000 (95%)] Loss: -1426.444092\n",
      "    epoch          : 2288\n",
      "    loss           : -1413.6882600083864\n",
      "Train Epoch: 2289 [512/60000 (1%)] Loss: -1412.914673\n",
      "Train Epoch: 2289 [11776/60000 (20%)] Loss: -1370.122559\n",
      "Train Epoch: 2289 [23040/60000 (38%)] Loss: -1518.380737\n",
      "Train Epoch: 2289 [34304/60000 (57%)] Loss: -1583.614380\n",
      "Train Epoch: 2289 [45568/60000 (76%)] Loss: -1337.104858\n",
      "Train Epoch: 2289 [56832/60000 (95%)] Loss: -1461.384155\n",
      "    epoch          : 2289\n",
      "    loss           : -1417.5778015481549\n",
      "Train Epoch: 2290 [512/60000 (1%)] Loss: -1445.737793\n",
      "Train Epoch: 2290 [11776/60000 (20%)] Loss: -1475.804077\n",
      "Train Epoch: 2290 [23040/60000 (38%)] Loss: -1527.442871\n",
      "Train Epoch: 2290 [34304/60000 (57%)] Loss: -1531.093262\n",
      "Train Epoch: 2290 [45568/60000 (76%)] Loss: -1151.854370\n",
      "Train Epoch: 2290 [56832/60000 (95%)] Loss: -1546.012695\n",
      "    epoch          : 2290\n",
      "    loss           : -1418.0642765713276\n",
      "Train Epoch: 2291 [512/60000 (1%)] Loss: -1455.937012\n",
      "Train Epoch: 2291 [11776/60000 (20%)] Loss: -1554.524780\n",
      "Train Epoch: 2291 [23040/60000 (38%)] Loss: -1367.620361\n",
      "Train Epoch: 2291 [34304/60000 (57%)] Loss: -1440.391357\n",
      "Train Epoch: 2291 [45568/60000 (76%)] Loss: -1467.612671\n",
      "Train Epoch: 2291 [56832/60000 (95%)] Loss: -1533.944702\n",
      "    epoch          : 2291\n",
      "    loss           : -1429.431014756025\n",
      "Train Epoch: 2292 [512/60000 (1%)] Loss: -1341.131226\n",
      "Train Epoch: 2292 [11776/60000 (20%)] Loss: -1543.750488\n",
      "Train Epoch: 2292 [23040/60000 (38%)] Loss: -1512.885498\n",
      "Train Epoch: 2292 [34304/60000 (57%)] Loss: -1475.443604\n",
      "Train Epoch: 2292 [45568/60000 (76%)] Loss: -1462.226685\n",
      "Train Epoch: 2292 [56832/60000 (95%)] Loss: -1097.270508\n",
      "    epoch          : 2292\n",
      "    loss           : -1410.0479501842779\n",
      "Train Epoch: 2293 [512/60000 (1%)] Loss: -1565.468018\n",
      "Train Epoch: 2293 [11776/60000 (20%)] Loss: -1184.582031\n",
      "Train Epoch: 2293 [23040/60000 (38%)] Loss: -1517.319824\n",
      "Train Epoch: 2293 [34304/60000 (57%)] Loss: -1389.036011\n",
      "Train Epoch: 2293 [45568/60000 (76%)] Loss: -1221.962280\n",
      "Train Epoch: 2293 [56832/60000 (95%)] Loss: -1296.853027\n",
      "    epoch          : 2293\n",
      "    loss           : -1405.968274822343\n",
      "Train Epoch: 2294 [512/60000 (1%)] Loss: -1408.561523\n",
      "Train Epoch: 2294 [11776/60000 (20%)] Loss: -1544.371826\n",
      "Train Epoch: 2294 [23040/60000 (38%)] Loss: -1180.975098\n",
      "Train Epoch: 2294 [34304/60000 (57%)] Loss: -1391.927002\n",
      "Train Epoch: 2294 [45568/60000 (76%)] Loss: -1404.632812\n",
      "Train Epoch: 2294 [56832/60000 (95%)] Loss: -1345.000244\n",
      "    epoch          : 2294\n",
      "    loss           : -1412.1862927452992\n",
      "Train Epoch: 2295 [512/60000 (1%)] Loss: -1429.860962\n",
      "Train Epoch: 2295 [11776/60000 (20%)] Loss: -1340.015991\n",
      "Train Epoch: 2295 [23040/60000 (38%)] Loss: -1326.088867\n",
      "Train Epoch: 2295 [34304/60000 (57%)] Loss: -1154.288452\n",
      "Train Epoch: 2295 [45568/60000 (76%)] Loss: -1382.016602\n",
      "Train Epoch: 2295 [56832/60000 (95%)] Loss: -1437.296875\n",
      "    epoch          : 2295\n",
      "    loss           : -1409.3501607603946\n",
      "Train Epoch: 2296 [512/60000 (1%)] Loss: -1385.956787\n",
      "Train Epoch: 2296 [11776/60000 (20%)] Loss: -1316.205444\n",
      "Train Epoch: 2296 [23040/60000 (38%)] Loss: -1361.655029\n",
      "Train Epoch: 2296 [34304/60000 (57%)] Loss: -1460.654663\n",
      "Train Epoch: 2296 [45568/60000 (76%)] Loss: -1388.573853\n",
      "Train Epoch: 2296 [56832/60000 (95%)] Loss: -1293.135742\n",
      "    epoch          : 2296\n",
      "    loss           : -1420.4584733348781\n",
      "Train Epoch: 2297 [512/60000 (1%)] Loss: -1353.936523\n",
      "Train Epoch: 2297 [11776/60000 (20%)] Loss: -1436.002686\n",
      "Train Epoch: 2297 [23040/60000 (38%)] Loss: -1357.362305\n",
      "Train Epoch: 2297 [34304/60000 (57%)] Loss: -1538.009888\n",
      "Train Epoch: 2297 [45568/60000 (76%)] Loss: -1466.056396\n",
      "Train Epoch: 2297 [56832/60000 (95%)] Loss: -1441.904175\n",
      "    epoch          : 2297\n",
      "    loss           : -1432.4506687660003\n",
      "Train Epoch: 2298 [512/60000 (1%)] Loss: -1344.503906\n",
      "Train Epoch: 2298 [11776/60000 (20%)] Loss: -1535.695679\n",
      "Train Epoch: 2298 [23040/60000 (38%)] Loss: -1319.403320\n",
      "Train Epoch: 2298 [34304/60000 (57%)] Loss: -1328.144775\n",
      "Train Epoch: 2298 [45568/60000 (76%)] Loss: -1551.075684\n",
      "Train Epoch: 2298 [56832/60000 (95%)] Loss: -1478.217285\n",
      "    epoch          : 2298\n",
      "    loss           : -1438.2958091261698\n",
      "Train Epoch: 2299 [512/60000 (1%)] Loss: -1132.555298\n",
      "Train Epoch: 2299 [11776/60000 (20%)] Loss: -1427.225464\n",
      "Train Epoch: 2299 [23040/60000 (38%)] Loss: -1448.467651\n",
      "Train Epoch: 2299 [34304/60000 (57%)] Loss: -1451.259521\n",
      "Train Epoch: 2299 [45568/60000 (76%)] Loss: -1558.804810\n",
      "Train Epoch: 2299 [56832/60000 (95%)] Loss: -1423.501953\n",
      "    epoch          : 2299\n",
      "    loss           : -1417.9033751406912\n",
      "Train Epoch: 2300 [512/60000 (1%)] Loss: -1538.266113\n",
      "Train Epoch: 2300 [11776/60000 (20%)] Loss: -1460.985107\n",
      "Train Epoch: 2300 [23040/60000 (38%)] Loss: -1421.884888\n",
      "Train Epoch: 2300 [34304/60000 (57%)] Loss: -1438.371094\n",
      "Train Epoch: 2300 [45568/60000 (76%)] Loss: -1546.242676\n",
      "Train Epoch: 2300 [56832/60000 (95%)] Loss: -1400.847290\n",
      "    epoch          : 2300\n",
      "    loss           : -1424.0474319026969\n",
      "Saving checkpoint: saved/models/Mnist_DeepGenerativeOperad/0127_111843/checkpoint-epoch2300.pth ...\n",
      "Train Epoch: 2301 [512/60000 (1%)] Loss: -1366.895996\n",
      "Train Epoch: 2301 [11776/60000 (20%)] Loss: -1293.311646\n",
      "Train Epoch: 2301 [23040/60000 (38%)] Loss: -1346.146606\n",
      "Train Epoch: 2301 [34304/60000 (57%)] Loss: -1349.481201\n",
      "Train Epoch: 2301 [45568/60000 (76%)] Loss: -1422.314575\n",
      "Train Epoch: 2301 [56832/60000 (95%)] Loss: -1522.135742\n",
      "    epoch          : 2301\n",
      "    loss           : -1415.5213916153557\n",
      "Train Epoch: 2302 [512/60000 (1%)] Loss: -1387.922607\n",
      "Train Epoch: 2302 [11776/60000 (20%)] Loss: -1481.656006\n",
      "Train Epoch: 2302 [23040/60000 (38%)] Loss: -1418.469727\n",
      "Train Epoch: 2302 [34304/60000 (57%)] Loss: -1348.449341\n",
      "Train Epoch: 2302 [45568/60000 (76%)] Loss: -1444.096191\n",
      "Train Epoch: 2302 [56832/60000 (95%)] Loss: -1416.800903\n",
      "    epoch          : 2302\n",
      "    loss           : -1421.0902858238435\n",
      "Train Epoch: 2303 [512/60000 (1%)] Loss: -1379.985107\n",
      "Train Epoch: 2303 [11776/60000 (20%)] Loss: -1413.473755\n",
      "Train Epoch: 2303 [23040/60000 (38%)] Loss: -1413.033691\n",
      "Train Epoch: 2303 [34304/60000 (57%)] Loss: -1537.031494\n",
      "Train Epoch: 2303 [45568/60000 (76%)] Loss: -1471.158813\n",
      "Train Epoch: 2303 [56832/60000 (95%)] Loss: -1352.722656\n",
      "    epoch          : 2303\n",
      "    loss           : -1429.3457579531912\n",
      "Train Epoch: 2304 [512/60000 (1%)] Loss: -1536.313110\n",
      "Train Epoch: 2304 [11776/60000 (20%)] Loss: -1493.949341\n",
      "Train Epoch: 2304 [23040/60000 (38%)] Loss: -1508.297363\n",
      "Train Epoch: 2304 [34304/60000 (57%)] Loss: -1374.071899\n",
      "Train Epoch: 2304 [45568/60000 (76%)] Loss: -1336.978516\n",
      "Train Epoch: 2304 [56832/60000 (95%)] Loss: -1319.043701\n",
      "    epoch          : 2304\n",
      "    loss           : -1433.5750253106241\n",
      "Train Epoch: 2305 [512/60000 (1%)] Loss: -1513.340088\n",
      "Train Epoch: 2305 [11776/60000 (20%)] Loss: -1291.079590\n",
      "Train Epoch: 2305 [23040/60000 (38%)] Loss: -1512.249512\n",
      "Train Epoch: 2305 [34304/60000 (57%)] Loss: -1267.842773\n",
      "Train Epoch: 2305 [45568/60000 (76%)] Loss: -1392.347168\n",
      "Train Epoch: 2305 [56832/60000 (95%)] Loss: -1466.401245\n",
      "    epoch          : 2305\n",
      "    loss           : -1428.0540685276528\n",
      "Train Epoch: 2306 [512/60000 (1%)] Loss: -1287.662720\n",
      "Train Epoch: 2306 [11776/60000 (20%)] Loss: -1486.191040\n",
      "Train Epoch: 2306 [23040/60000 (38%)] Loss: -1444.956299\n",
      "Train Epoch: 2306 [34304/60000 (57%)] Loss: -1378.173584\n",
      "Train Epoch: 2306 [45568/60000 (76%)] Loss: -1325.531738\n",
      "Train Epoch: 2306 [56832/60000 (95%)] Loss: -1481.287598\n",
      "    epoch          : 2306\n",
      "    loss           : -1411.7710050593662\n",
      "Train Epoch: 2307 [512/60000 (1%)] Loss: -1440.370361\n",
      "Train Epoch: 2307 [11776/60000 (20%)] Loss: -1429.548340\n",
      "Train Epoch: 2307 [23040/60000 (38%)] Loss: -1439.340088\n",
      "Train Epoch: 2307 [34304/60000 (57%)] Loss: -1316.410522\n",
      "Train Epoch: 2307 [45568/60000 (76%)] Loss: -1301.218506\n",
      "Train Epoch: 2307 [56832/60000 (95%)] Loss: -1558.399902\n",
      "    epoch          : 2307\n",
      "    loss           : -1418.4348358326713\n",
      "Train Epoch: 2308 [512/60000 (1%)] Loss: -1467.039551\n",
      "Train Epoch: 2308 [11776/60000 (20%)] Loss: -1329.015137\n",
      "Train Epoch: 2308 [23040/60000 (38%)] Loss: -1414.920654\n",
      "Train Epoch: 2308 [34304/60000 (57%)] Loss: -1319.009399\n",
      "Train Epoch: 2308 [45568/60000 (76%)] Loss: -1370.250488\n",
      "Train Epoch: 2308 [56832/60000 (95%)] Loss: -1513.841309\n",
      "    epoch          : 2308\n",
      "    loss           : -1417.5488867463366\n",
      "Train Epoch: 2309 [512/60000 (1%)] Loss: -1498.912598\n",
      "Train Epoch: 2309 [11776/60000 (20%)] Loss: -1434.856567\n",
      "Train Epoch: 2309 [23040/60000 (38%)] Loss: -1441.428711\n",
      "Train Epoch: 2309 [34304/60000 (57%)] Loss: -1152.654297\n",
      "Train Epoch: 2309 [45568/60000 (76%)] Loss: -1409.815918\n",
      "Train Epoch: 2309 [56832/60000 (95%)] Loss: -1455.164795\n",
      "    epoch          : 2309\n",
      "    loss           : -1429.2505348334878\n",
      "Train Epoch: 2310 [512/60000 (1%)] Loss: -1542.336548\n",
      "Train Epoch: 2310 [11776/60000 (20%)] Loss: -1361.418335\n",
      "Train Epoch: 2310 [23040/60000 (38%)] Loss: -1475.231079\n",
      "Train Epoch: 2310 [34304/60000 (57%)] Loss: -1550.135986\n",
      "Train Epoch: 2310 [45568/60000 (76%)] Loss: -1545.287231\n",
      "Train Epoch: 2310 [56832/60000 (95%)] Loss: -1472.250610\n",
      "    epoch          : 2310\n",
      "    loss           : -1428.781442071085\n",
      "Train Epoch: 2311 [512/60000 (1%)] Loss: -1469.667358\n",
      "Train Epoch: 2311 [11776/60000 (20%)] Loss: -1188.183472\n",
      "Train Epoch: 2311 [23040/60000 (38%)] Loss: -1548.903320\n",
      "Train Epoch: 2311 [34304/60000 (57%)] Loss: -1363.343262\n",
      "Train Epoch: 2311 [45568/60000 (76%)] Loss: -1541.882080\n",
      "Train Epoch: 2311 [56832/60000 (95%)] Loss: -1525.997925\n",
      "    epoch          : 2311\n",
      "    loss           : -1439.4198291153557\n",
      "Train Epoch: 2312 [512/60000 (1%)] Loss: -1418.394653\n",
      "Train Epoch: 2312 [11776/60000 (20%)] Loss: -1440.557983\n",
      "Train Epoch: 2312 [23040/60000 (38%)] Loss: -1428.296631\n",
      "Train Epoch: 2312 [34304/60000 (57%)] Loss: -1525.575439\n",
      "Train Epoch: 2312 [45568/60000 (76%)] Loss: -1410.673706\n",
      "Train Epoch: 2312 [56832/60000 (95%)] Loss: -1458.385864\n",
      "    epoch          : 2312\n",
      "    loss           : -1423.5466305145437\n",
      "Train Epoch: 2313 [512/60000 (1%)] Loss: -1437.234619\n",
      "Train Epoch: 2313 [11776/60000 (20%)] Loss: -1418.039795\n",
      "Train Epoch: 2313 [23040/60000 (38%)] Loss: -1230.136475\n",
      "Train Epoch: 2313 [34304/60000 (57%)] Loss: -1547.365845\n",
      "Train Epoch: 2313 [45568/60000 (76%)] Loss: -1388.032593\n",
      "Train Epoch: 2313 [56832/60000 (95%)] Loss: -1292.484619\n",
      "    epoch          : 2313\n",
      "    loss           : -1426.6884820798023\n",
      "Train Epoch: 2314 [512/60000 (1%)] Loss: -1433.164062\n",
      "Train Epoch: 2314 [11776/60000 (20%)] Loss: -1542.061768\n",
      "Train Epoch: 2314 [23040/60000 (38%)] Loss: -1533.125854\n",
      "Train Epoch: 2314 [34304/60000 (57%)] Loss: -1331.360596\n",
      "Train Epoch: 2314 [45568/60000 (76%)] Loss: -1527.857178\n",
      "Train Epoch: 2314 [56832/60000 (95%)] Loss: -1396.870850\n",
      "    epoch          : 2314\n",
      "    loss           : -1418.9244491663355\n",
      "Train Epoch: 2315 [512/60000 (1%)] Loss: -1510.843018\n",
      "Train Epoch: 2315 [11776/60000 (20%)] Loss: -1322.425537\n",
      "Train Epoch: 2315 [23040/60000 (38%)] Loss: -1326.211182\n",
      "Train Epoch: 2315 [34304/60000 (57%)] Loss: -1316.466064\n",
      "Train Epoch: 2315 [45568/60000 (76%)] Loss: -1564.847290\n",
      "Train Epoch: 2315 [56832/60000 (95%)] Loss: -1442.853027\n",
      "    epoch          : 2315\n",
      "    loss           : -1416.9741845427259\n",
      "Train Epoch: 2316 [512/60000 (1%)] Loss: -1430.838989\n",
      "Train Epoch: 2316 [11776/60000 (20%)] Loss: -1311.908447\n",
      "Train Epoch: 2316 [23040/60000 (38%)] Loss: -1339.079102\n",
      "Train Epoch: 2316 [34304/60000 (57%)] Loss: -1545.647095\n",
      "Train Epoch: 2316 [45568/60000 (76%)] Loss: -1460.333130\n",
      "Train Epoch: 2316 [56832/60000 (95%)] Loss: -1402.960449\n",
      "    epoch          : 2316\n",
      "    loss           : -1435.615711966477\n",
      "Train Epoch: 2317 [512/60000 (1%)] Loss: -1386.789307\n",
      "Train Epoch: 2317 [11776/60000 (20%)] Loss: -1446.996826\n",
      "Train Epoch: 2317 [23040/60000 (38%)] Loss: -1422.964111\n",
      "Train Epoch: 2317 [34304/60000 (57%)] Loss: -1430.921997\n",
      "Train Epoch: 2317 [45568/60000 (76%)] Loss: -1450.455811\n",
      "Train Epoch: 2317 [56832/60000 (95%)] Loss: -1529.736572\n",
      "    epoch          : 2317\n",
      "    loss           : -1418.3856059791003\n",
      "Train Epoch: 2318 [512/60000 (1%)] Loss: -1443.555908\n",
      "Train Epoch: 2318 [11776/60000 (20%)] Loss: -1413.391235\n",
      "Train Epoch: 2318 [23040/60000 (38%)] Loss: -1191.543457\n",
      "Train Epoch: 2318 [34304/60000 (57%)] Loss: -1486.712036\n",
      "Train Epoch: 2318 [45568/60000 (76%)] Loss: -1337.328979\n",
      "Train Epoch: 2318 [56832/60000 (95%)] Loss: -1523.239990\n",
      "    epoch          : 2318\n",
      "    loss           : -1421.5196246993069\n",
      "Train Epoch: 2319 [512/60000 (1%)] Loss: -1538.829834\n",
      "Train Epoch: 2319 [11776/60000 (20%)] Loss: -1317.358032\n",
      "Train Epoch: 2319 [23040/60000 (38%)] Loss: -1433.690186\n",
      "Train Epoch: 2319 [34304/60000 (57%)] Loss: -1374.350586\n",
      "Train Epoch: 2319 [45568/60000 (76%)] Loss: -1418.491821\n",
      "Train Epoch: 2319 [56832/60000 (95%)] Loss: -1461.650391\n",
      "    epoch          : 2319\n",
      "    loss           : -1427.8242690953832\n",
      "Train Epoch: 2320 [512/60000 (1%)] Loss: -1409.797363\n",
      "Train Epoch: 2320 [11776/60000 (20%)] Loss: -1331.598389\n",
      "Train Epoch: 2320 [23040/60000 (38%)] Loss: -1374.787109\n",
      "Train Epoch: 2320 [34304/60000 (57%)] Loss: -1150.242432\n",
      "Train Epoch: 2320 [45568/60000 (76%)] Loss: -1359.800903\n",
      "Train Epoch: 2320 [56832/60000 (95%)] Loss: -1540.661865\n",
      "    epoch          : 2320\n",
      "    loss           : -1414.3949947033898\n",
      "Train Epoch: 2321 [512/60000 (1%)] Loss: -1402.545898\n",
      "Train Epoch: 2321 [11776/60000 (20%)] Loss: -1463.426758\n",
      "Train Epoch: 2321 [23040/60000 (38%)] Loss: -1268.234619\n",
      "Train Epoch: 2321 [34304/60000 (57%)] Loss: -1468.488770\n",
      "Train Epoch: 2321 [45568/60000 (76%)] Loss: -1492.068848\n",
      "Train Epoch: 2321 [56832/60000 (95%)] Loss: -1444.142700\n",
      "    epoch          : 2321\n",
      "    loss           : -1425.2528331347105\n",
      "Train Epoch: 2322 [512/60000 (1%)] Loss: -1308.896606\n",
      "Train Epoch: 2322 [11776/60000 (20%)] Loss: -1318.993286\n",
      "Train Epoch: 2322 [23040/60000 (38%)] Loss: -1491.793091\n",
      "Train Epoch: 2322 [34304/60000 (57%)] Loss: -1337.647217\n",
      "Train Epoch: 2322 [45568/60000 (76%)] Loss: -1342.010742\n",
      "Train Epoch: 2322 [56832/60000 (95%)] Loss: -1331.771118\n",
      "    epoch          : 2322\n",
      "    loss           : -1422.6929635085628\n",
      "Train Epoch: 2323 [512/60000 (1%)] Loss: -1423.540771\n",
      "Train Epoch: 2323 [11776/60000 (20%)] Loss: -1419.754639\n",
      "Train Epoch: 2323 [23040/60000 (38%)] Loss: -1441.267334\n",
      "Train Epoch: 2323 [34304/60000 (57%)] Loss: -1460.575317\n",
      "Train Epoch: 2323 [45568/60000 (76%)] Loss: -1183.849854\n",
      "Train Epoch: 2323 [56832/60000 (95%)] Loss: -1530.861450\n",
      "    epoch          : 2323\n",
      "    loss           : -1417.9024978896318\n",
      "Train Epoch: 2324 [512/60000 (1%)] Loss: -1245.121948\n",
      "Train Epoch: 2324 [11776/60000 (20%)] Loss: -1312.224854\n",
      "Train Epoch: 2324 [23040/60000 (38%)] Loss: -1569.241333\n",
      "Train Epoch: 2324 [34304/60000 (57%)] Loss: -1530.600830\n",
      "Train Epoch: 2324 [45568/60000 (76%)] Loss: -1372.456055\n",
      "Train Epoch: 2324 [56832/60000 (95%)] Loss: -1420.471924\n",
      "    epoch          : 2324\n",
      "    loss           : -1440.5549202611892\n",
      "Train Epoch: 2325 [512/60000 (1%)] Loss: -1517.478760\n",
      "Train Epoch: 2325 [11776/60000 (20%)] Loss: -1325.758789\n",
      "Train Epoch: 2325 [23040/60000 (38%)] Loss: -1491.864258\n",
      "Train Epoch: 2325 [34304/60000 (57%)] Loss: -1333.020386\n",
      "Train Epoch: 2325 [45568/60000 (76%)] Loss: -1530.262817\n",
      "Train Epoch: 2325 [56832/60000 (95%)] Loss: -1458.092651\n",
      "    epoch          : 2325\n",
      "    loss           : -1417.312293790828\n",
      "Train Epoch: 2326 [512/60000 (1%)] Loss: -1430.910645\n",
      "Train Epoch: 2326 [11776/60000 (20%)] Loss: -1541.242188\n",
      "Train Epoch: 2326 [23040/60000 (38%)] Loss: -1458.864136\n",
      "Train Epoch: 2326 [34304/60000 (57%)] Loss: -1332.994507\n",
      "Train Epoch: 2326 [45568/60000 (76%)] Loss: -1444.253784\n",
      "Train Epoch: 2326 [56832/60000 (95%)] Loss: -1403.329590\n",
      "    epoch          : 2326\n",
      "    loss           : -1426.7821324235301\n",
      "Train Epoch: 2327 [512/60000 (1%)] Loss: -1452.964233\n",
      "Train Epoch: 2327 [11776/60000 (20%)] Loss: -1440.380981\n",
      "Train Epoch: 2327 [23040/60000 (38%)] Loss: -1269.428833\n",
      "Train Epoch: 2327 [34304/60000 (57%)] Loss: -1300.827881\n",
      "Train Epoch: 2327 [45568/60000 (76%)] Loss: -1390.223389\n",
      "Train Epoch: 2327 [56832/60000 (95%)] Loss: -1371.865479\n",
      "    epoch          : 2327\n",
      "    loss           : -1411.386224261785\n",
      "Train Epoch: 2328 [512/60000 (1%)] Loss: -1251.515869\n",
      "Train Epoch: 2328 [11776/60000 (20%)] Loss: -1366.712769\n",
      "Train Epoch: 2328 [23040/60000 (38%)] Loss: -1391.652588\n",
      "Train Epoch: 2328 [34304/60000 (57%)] Loss: -1311.910034\n",
      "Train Epoch: 2328 [45568/60000 (76%)] Loss: -1393.544922\n",
      "Train Epoch: 2328 [56832/60000 (95%)] Loss: -1422.718018\n",
      "    epoch          : 2328\n",
      "    loss           : -1422.1398598191427\n",
      "Train Epoch: 2329 [512/60000 (1%)] Loss: -1475.582886\n",
      "Train Epoch: 2329 [11776/60000 (20%)] Loss: -1437.966797\n",
      "Train Epoch: 2329 [23040/60000 (38%)] Loss: -1438.000488\n",
      "Train Epoch: 2329 [34304/60000 (57%)] Loss: -1532.192871\n",
      "Train Epoch: 2329 [45568/60000 (76%)] Loss: -1241.991821\n",
      "Train Epoch: 2329 [56832/60000 (95%)] Loss: -1440.172729\n",
      "    epoch          : 2329\n",
      "    loss           : -1419.066377973826\n",
      "Train Epoch: 2330 [512/60000 (1%)] Loss: -1500.814697\n",
      "Train Epoch: 2330 [11776/60000 (20%)] Loss: -1518.404053\n",
      "Train Epoch: 2330 [23040/60000 (38%)] Loss: -1227.212646\n",
      "Train Epoch: 2330 [34304/60000 (57%)] Loss: -1431.704834\n",
      "Train Epoch: 2330 [45568/60000 (76%)] Loss: -1375.912598\n",
      "Train Epoch: 2330 [56832/60000 (95%)] Loss: -1540.931396\n",
      "    epoch          : 2330\n",
      "    loss           : -1433.5782936225503\n",
      "Train Epoch: 2331 [512/60000 (1%)] Loss: -1358.359619\n",
      "Train Epoch: 2331 [11776/60000 (20%)] Loss: -1511.354492\n",
      "Train Epoch: 2331 [23040/60000 (38%)] Loss: -1553.960571\n",
      "Train Epoch: 2331 [34304/60000 (57%)] Loss: -1435.218506\n",
      "Train Epoch: 2331 [45568/60000 (76%)] Loss: -1354.218018\n",
      "Train Epoch: 2331 [56832/60000 (95%)] Loss: -1516.846680\n",
      "    epoch          : 2331\n",
      "    loss           : -1412.0953879491083\n",
      "Train Epoch: 2332 [512/60000 (1%)] Loss: -1327.983765\n",
      "Train Epoch: 2332 [11776/60000 (20%)] Loss: -1402.038574\n",
      "Train Epoch: 2332 [23040/60000 (38%)] Loss: -1526.383057\n",
      "Train Epoch: 2332 [34304/60000 (57%)] Loss: -1551.218994\n",
      "Train Epoch: 2332 [45568/60000 (76%)] Loss: -1464.618164\n",
      "Train Epoch: 2332 [56832/60000 (95%)] Loss: -1443.098389\n",
      "    epoch          : 2332\n",
      "    loss           : -1419.0183391678806\n",
      "Train Epoch: 2333 [512/60000 (1%)] Loss: -1324.445679\n",
      "Train Epoch: 2333 [11776/60000 (20%)] Loss: -1371.790527\n",
      "Train Epoch: 2333 [23040/60000 (38%)] Loss: -1328.429932\n",
      "Train Epoch: 2333 [34304/60000 (57%)] Loss: -1352.253296\n",
      "Train Epoch: 2333 [45568/60000 (76%)] Loss: -1425.004639\n",
      "Train Epoch: 2333 [56832/60000 (95%)] Loss: -1409.521851\n",
      "    epoch          : 2333\n",
      "    loss           : -1416.7767354674259\n",
      "Train Epoch: 2334 [512/60000 (1%)] Loss: -1470.496826\n",
      "Train Epoch: 2334 [11776/60000 (20%)] Loss: -1419.461182\n",
      "Train Epoch: 2334 [23040/60000 (38%)] Loss: -1337.919312\n",
      "Train Epoch: 2334 [34304/60000 (57%)] Loss: -1415.710938\n",
      "Train Epoch: 2334 [45568/60000 (76%)] Loss: -1378.067627\n",
      "Train Epoch: 2334 [56832/60000 (95%)] Loss: -1447.914307\n",
      "    epoch          : 2334\n",
      "    loss           : -1423.2215207202285\n",
      "Train Epoch: 2335 [512/60000 (1%)] Loss: -1408.203979\n",
      "Train Epoch: 2335 [11776/60000 (20%)] Loss: -1443.188110\n",
      "Train Epoch: 2335 [23040/60000 (38%)] Loss: -1556.890869\n",
      "Train Epoch: 2335 [34304/60000 (57%)] Loss: -1298.403687\n",
      "Train Epoch: 2335 [45568/60000 (76%)] Loss: -1519.948242\n",
      "Train Epoch: 2335 [56832/60000 (95%)] Loss: -1427.154907\n",
      "    epoch          : 2335\n",
      "    loss           : -1420.7995419259798\n",
      "Train Epoch: 2336 [512/60000 (1%)] Loss: -1184.428955\n",
      "Train Epoch: 2336 [11776/60000 (20%)] Loss: -1394.705444\n",
      "Train Epoch: 2336 [23040/60000 (38%)] Loss: -1461.025024\n",
      "Train Epoch: 2336 [34304/60000 (57%)] Loss: -1471.372437\n",
      "Train Epoch: 2336 [45568/60000 (76%)] Loss: -1453.983521\n",
      "Train Epoch: 2336 [56832/60000 (95%)] Loss: -1420.422363\n",
      "    epoch          : 2336\n",
      "    loss           : -1428.8120562019994\n",
      "Train Epoch: 2337 [512/60000 (1%)] Loss: -1446.251465\n",
      "Train Epoch: 2337 [11776/60000 (20%)] Loss: -1414.470459\n",
      "Train Epoch: 2337 [23040/60000 (38%)] Loss: -1447.400146\n",
      "Train Epoch: 2337 [34304/60000 (57%)] Loss: -1316.362793\n",
      "Train Epoch: 2337 [45568/60000 (76%)] Loss: -1408.575195\n",
      "Train Epoch: 2337 [56832/60000 (95%)] Loss: -1368.839355\n",
      "    epoch          : 2337\n",
      "    loss           : -1430.1573210463011\n",
      "Train Epoch: 2338 [512/60000 (1%)] Loss: -1451.210571\n",
      "Train Epoch: 2338 [11776/60000 (20%)] Loss: -1299.281738\n",
      "Train Epoch: 2338 [23040/60000 (38%)] Loss: -1448.779541\n",
      "Train Epoch: 2338 [34304/60000 (57%)] Loss: -1428.672485\n",
      "Train Epoch: 2338 [45568/60000 (76%)] Loss: -1521.701050\n",
      "Train Epoch: 2338 [56832/60000 (95%)] Loss: -1429.452759\n",
      "    epoch          : 2338\n",
      "    loss           : -1428.7889273260946\n",
      "Train Epoch: 2339 [512/60000 (1%)] Loss: -1237.485229\n",
      "Train Epoch: 2339 [11776/60000 (20%)] Loss: -1531.904663\n",
      "Train Epoch: 2339 [23040/60000 (38%)] Loss: -1408.147949\n",
      "Train Epoch: 2339 [34304/60000 (57%)] Loss: -1586.125610\n",
      "Train Epoch: 2339 [45568/60000 (76%)] Loss: -1428.666260\n",
      "Train Epoch: 2339 [56832/60000 (95%)] Loss: -1466.915161\n",
      "    epoch          : 2339\n",
      "    loss           : -1420.8041978394244\n",
      "Train Epoch: 2340 [512/60000 (1%)] Loss: -1345.865356\n",
      "Train Epoch: 2340 [11776/60000 (20%)] Loss: -1434.427246\n",
      "Train Epoch: 2340 [23040/60000 (38%)] Loss: -1449.588135\n",
      "Train Epoch: 2340 [34304/60000 (57%)] Loss: -1543.148926\n",
      "Train Epoch: 2340 [45568/60000 (76%)] Loss: -1176.527222\n",
      "Train Epoch: 2340 [56832/60000 (95%)] Loss: -1365.697144\n",
      "    epoch          : 2340\n",
      "    loss           : -1415.8823459431276\n",
      "Train Epoch: 2341 [512/60000 (1%)] Loss: -1566.819092\n",
      "Train Epoch: 2341 [11776/60000 (20%)] Loss: -1542.187500\n",
      "Train Epoch: 2341 [23040/60000 (38%)] Loss: -1417.120605\n",
      "Train Epoch: 2341 [34304/60000 (57%)] Loss: -1418.231445\n",
      "Train Epoch: 2341 [45568/60000 (76%)] Loss: -1477.664062\n",
      "Train Epoch: 2341 [56832/60000 (95%)] Loss: -1482.500366\n",
      "    epoch          : 2341\n",
      "    loss           : -1428.8330233299125\n",
      "Train Epoch: 2342 [512/60000 (1%)] Loss: -1451.805664\n",
      "Train Epoch: 2342 [11776/60000 (20%)] Loss: -1564.098633\n",
      "Train Epoch: 2342 [23040/60000 (38%)] Loss: -1465.328125\n",
      "Train Epoch: 2342 [34304/60000 (57%)] Loss: -1465.725830\n",
      "Train Epoch: 2342 [45568/60000 (76%)] Loss: -1474.172974\n",
      "Train Epoch: 2342 [56832/60000 (95%)] Loss: -1506.484009\n",
      "    epoch          : 2342\n",
      "    loss           : -1434.491572320798\n",
      "Train Epoch: 2343 [512/60000 (1%)] Loss: -1483.885376\n",
      "Train Epoch: 2343 [11776/60000 (20%)] Loss: -1345.647705\n",
      "Train Epoch: 2343 [23040/60000 (38%)] Loss: -1495.632324\n",
      "Train Epoch: 2343 [34304/60000 (57%)] Loss: -1440.894653\n",
      "Train Epoch: 2343 [45568/60000 (76%)] Loss: -1502.593506\n",
      "Train Epoch: 2343 [56832/60000 (95%)] Loss: -1350.982056\n",
      "    epoch          : 2343\n",
      "    loss           : -1423.3345436915167\n",
      "Train Epoch: 2344 [512/60000 (1%)] Loss: -1521.435913\n",
      "Train Epoch: 2344 [11776/60000 (20%)] Loss: -1243.026123\n",
      "Train Epoch: 2344 [23040/60000 (38%)] Loss: -1531.917603\n",
      "Train Epoch: 2344 [34304/60000 (57%)] Loss: -1331.746948\n",
      "Train Epoch: 2344 [45568/60000 (76%)] Loss: -1449.572754\n",
      "Train Epoch: 2344 [56832/60000 (95%)] Loss: -1556.066772\n",
      "    epoch          : 2344\n",
      "    loss           : -1409.7267756057997\n",
      "Train Epoch: 2345 [512/60000 (1%)] Loss: -1470.635620\n",
      "Train Epoch: 2345 [11776/60000 (20%)] Loss: -1448.835327\n",
      "Train Epoch: 2345 [23040/60000 (38%)] Loss: -1414.506226\n",
      "Train Epoch: 2345 [34304/60000 (57%)] Loss: -1467.772583\n",
      "Train Epoch: 2345 [45568/60000 (76%)] Loss: -1425.022461\n",
      "Train Epoch: 2345 [56832/60000 (95%)] Loss: -1415.134033\n",
      "    epoch          : 2345\n",
      "    loss           : -1399.4167266673287\n",
      "Train Epoch: 2346 [512/60000 (1%)] Loss: -1415.794678\n",
      "Train Epoch: 2346 [11776/60000 (20%)] Loss: -1437.490601\n",
      "Train Epoch: 2346 [23040/60000 (38%)] Loss: -1453.194336\n",
      "Train Epoch: 2346 [34304/60000 (57%)] Loss: -1354.166016\n",
      "Train Epoch: 2346 [45568/60000 (76%)] Loss: -1457.656860\n",
      "Train Epoch: 2346 [56832/60000 (95%)] Loss: -1526.923462\n",
      "    epoch          : 2346\n",
      "    loss           : -1408.6841506526969\n",
      "Train Epoch: 2347 [512/60000 (1%)] Loss: -1559.825562\n",
      "Train Epoch: 2347 [11776/60000 (20%)] Loss: -1514.050903\n",
      "Train Epoch: 2347 [23040/60000 (38%)] Loss: -1447.395630\n",
      "Train Epoch: 2347 [34304/60000 (57%)] Loss: -1389.649658\n",
      "Train Epoch: 2347 [45568/60000 (76%)] Loss: -1329.331787\n",
      "Train Epoch: 2347 [56832/60000 (95%)] Loss: -1325.589600\n",
      "    epoch          : 2347\n",
      "    loss           : -1412.7196317338673\n",
      "Train Epoch: 2348 [512/60000 (1%)] Loss: -1516.328857\n",
      "Train Epoch: 2348 [11776/60000 (20%)] Loss: -1295.156128\n",
      "Train Epoch: 2348 [23040/60000 (38%)] Loss: -1441.510986\n",
      "Train Epoch: 2348 [34304/60000 (57%)] Loss: -1523.336060\n",
      "Train Epoch: 2348 [45568/60000 (76%)] Loss: -1539.846680\n",
      "Train Epoch: 2348 [56832/60000 (95%)] Loss: -1417.179688\n",
      "    epoch          : 2348\n",
      "    loss           : -1425.4969272074727\n",
      "Train Epoch: 2349 [512/60000 (1%)] Loss: -1425.475952\n",
      "Train Epoch: 2349 [11776/60000 (20%)] Loss: -1561.629395\n",
      "Train Epoch: 2349 [23040/60000 (38%)] Loss: -1404.136475\n",
      "Train Epoch: 2349 [34304/60000 (57%)] Loss: -1460.900757\n",
      "Train Epoch: 2349 [45568/60000 (76%)] Loss: -1364.367920\n",
      "Train Epoch: 2349 [56832/60000 (95%)] Loss: -1372.799805\n",
      "    epoch          : 2349\n",
      "    loss           : -1441.8517893990554\n",
      "Train Epoch: 2350 [512/60000 (1%)] Loss: -1318.886475\n",
      "Train Epoch: 2350 [11776/60000 (20%)] Loss: -1564.777466\n",
      "Train Epoch: 2350 [23040/60000 (38%)] Loss: -1444.289307\n",
      "Train Epoch: 2350 [34304/60000 (57%)] Loss: -1561.859863\n",
      "Train Epoch: 2350 [45568/60000 (76%)] Loss: -1402.777100\n",
      "Train Epoch: 2350 [56832/60000 (95%)] Loss: -1423.650879\n",
      "    epoch          : 2350\n",
      "    loss           : -1430.4551791605977\n",
      "Train Epoch: 2351 [512/60000 (1%)] Loss: -1450.885742\n",
      "Train Epoch: 2351 [11776/60000 (20%)] Loss: -1215.384277\n",
      "Train Epoch: 2351 [23040/60000 (38%)] Loss: -1333.116821\n",
      "Train Epoch: 2351 [34304/60000 (57%)] Loss: -1411.228027\n",
      "Train Epoch: 2351 [45568/60000 (76%)] Loss: -1259.319214\n",
      "Train Epoch: 2351 [56832/60000 (95%)] Loss: -1379.989746\n",
      "    epoch          : 2351\n",
      "    loss           : -1422.9668465307204\n",
      "Train Epoch: 2352 [512/60000 (1%)] Loss: -1329.672852\n",
      "Train Epoch: 2352 [11776/60000 (20%)] Loss: -1490.841064\n",
      "Train Epoch: 2352 [23040/60000 (38%)] Loss: -1490.600830\n",
      "Train Epoch: 2352 [34304/60000 (57%)] Loss: -1463.664185\n",
      "Train Epoch: 2352 [45568/60000 (76%)] Loss: -1451.146606\n",
      "Train Epoch: 2352 [56832/60000 (95%)] Loss: -1422.640015\n",
      "    epoch          : 2352\n",
      "    loss           : -1430.7968539652852\n",
      "Train Epoch: 2353 [512/60000 (1%)] Loss: -1521.076904\n",
      "Train Epoch: 2353 [11776/60000 (20%)] Loss: -1501.198975\n",
      "Train Epoch: 2353 [23040/60000 (38%)] Loss: -1566.188599\n",
      "Train Epoch: 2353 [34304/60000 (57%)] Loss: -1417.348267\n",
      "Train Epoch: 2353 [45568/60000 (76%)] Loss: -1537.668823\n",
      "Train Epoch: 2353 [56832/60000 (95%)] Loss: -1362.675293\n",
      "    epoch          : 2353\n",
      "    loss           : -1434.973639019465\n",
      "Train Epoch: 2354 [512/60000 (1%)] Loss: -1431.403198\n",
      "Train Epoch: 2354 [11776/60000 (20%)] Loss: -1456.362305\n",
      "Train Epoch: 2354 [23040/60000 (38%)] Loss: -1463.636719\n",
      "Train Epoch: 2354 [34304/60000 (57%)] Loss: -1374.687256\n",
      "Train Epoch: 2354 [45568/60000 (76%)] Loss: -1539.701782\n",
      "Train Epoch: 2354 [56832/60000 (95%)] Loss: -1523.271362\n",
      "    epoch          : 2354\n",
      "    loss           : -1423.6867837852005\n",
      "Train Epoch: 2355 [512/60000 (1%)] Loss: -1535.247070\n",
      "Train Epoch: 2355 [11776/60000 (20%)] Loss: -1331.240356\n",
      "Train Epoch: 2355 [23040/60000 (38%)] Loss: -1409.489258\n",
      "Train Epoch: 2355 [34304/60000 (57%)] Loss: -1325.307007\n",
      "Train Epoch: 2355 [45568/60000 (76%)] Loss: -1385.100464\n",
      "Train Epoch: 2355 [56832/60000 (95%)] Loss: -1459.887817\n",
      "    epoch          : 2355\n",
      "    loss           : -1430.6175685386872\n",
      "Train Epoch: 2356 [512/60000 (1%)] Loss: -1299.090332\n",
      "Train Epoch: 2356 [11776/60000 (20%)] Loss: -1221.019043\n",
      "Train Epoch: 2356 [23040/60000 (38%)] Loss: -1379.180298\n",
      "Train Epoch: 2356 [34304/60000 (57%)] Loss: -1370.711670\n",
      "Train Epoch: 2356 [45568/60000 (76%)] Loss: -1418.436646\n",
      "Train Epoch: 2356 [56832/60000 (95%)] Loss: -1452.648438\n",
      "    epoch          : 2356\n",
      "    loss           : -1408.7581938835187\n",
      "Train Epoch: 2357 [512/60000 (1%)] Loss: -1497.661621\n",
      "Train Epoch: 2357 [11776/60000 (20%)] Loss: -1322.852295\n",
      "Train Epoch: 2357 [23040/60000 (38%)] Loss: -1429.035767\n",
      "Train Epoch: 2357 [34304/60000 (57%)] Loss: -1536.301514\n",
      "Train Epoch: 2357 [45568/60000 (76%)] Loss: -1381.797363\n",
      "Train Epoch: 2357 [56832/60000 (95%)] Loss: -1242.071533\n",
      "    epoch          : 2357\n",
      "    loss           : -1405.1905924479165\n",
      "Train Epoch: 2358 [512/60000 (1%)] Loss: -1554.916870\n",
      "Train Epoch: 2358 [11776/60000 (20%)] Loss: -1413.844238\n",
      "Train Epoch: 2358 [23040/60000 (38%)] Loss: -1356.221313\n",
      "Train Epoch: 2358 [34304/60000 (57%)] Loss: -1526.258301\n",
      "Train Epoch: 2358 [45568/60000 (76%)] Loss: -1446.510010\n",
      "Train Epoch: 2358 [56832/60000 (95%)] Loss: -1451.294189\n",
      "    epoch          : 2358\n",
      "    loss           : -1433.8086547851562\n",
      "Train Epoch: 2359 [512/60000 (1%)] Loss: -1382.045898\n",
      "Train Epoch: 2359 [11776/60000 (20%)] Loss: -1334.289307\n",
      "Train Epoch: 2359 [23040/60000 (38%)] Loss: -1454.631592\n",
      "Train Epoch: 2359 [34304/60000 (57%)] Loss: -1427.996094\n",
      "Train Epoch: 2359 [45568/60000 (76%)] Loss: -1461.638184\n",
      "Train Epoch: 2359 [56832/60000 (95%)] Loss: -1545.442261\n",
      "    epoch          : 2359\n",
      "    loss           : -1418.947089416159\n",
      "Train Epoch: 2360 [512/60000 (1%)] Loss: -1397.773682\n",
      "Train Epoch: 2360 [11776/60000 (20%)] Loss: -1547.820435\n",
      "Train Epoch: 2360 [23040/60000 (38%)] Loss: -1521.187744\n",
      "Train Epoch: 2360 [34304/60000 (57%)] Loss: -1528.815430\n",
      "Train Epoch: 2360 [45568/60000 (76%)] Loss: -1354.667969\n",
      "Train Epoch: 2360 [56832/60000 (95%)] Loss: -1526.848389\n",
      "    epoch          : 2360\n",
      "    loss           : -1424.3852259749074\n",
      "Train Epoch: 2361 [512/60000 (1%)] Loss: -1541.346924\n",
      "Train Epoch: 2361 [11776/60000 (20%)] Loss: -1327.507812\n",
      "Train Epoch: 2361 [23040/60000 (38%)] Loss: -1229.242554\n",
      "Train Epoch: 2361 [34304/60000 (57%)] Loss: -1224.991089\n",
      "Train Epoch: 2361 [45568/60000 (76%)] Loss: -1357.375854\n",
      "Train Epoch: 2361 [56832/60000 (95%)] Loss: -1163.644043\n",
      "    epoch          : 2361\n",
      "    loss           : -1404.7982343253443\n",
      "Train Epoch: 2362 [512/60000 (1%)] Loss: -1550.502930\n",
      "Train Epoch: 2362 [11776/60000 (20%)] Loss: -1500.841797\n",
      "Train Epoch: 2362 [23040/60000 (38%)] Loss: -1522.079590\n",
      "Train Epoch: 2362 [34304/60000 (57%)] Loss: -1520.297607\n",
      "Train Epoch: 2362 [45568/60000 (76%)] Loss: -1580.258667\n",
      "Train Epoch: 2362 [56832/60000 (95%)] Loss: -1426.464844\n",
      "    epoch          : 2362\n",
      "    loss           : -1433.086689232433\n",
      "Train Epoch: 2363 [512/60000 (1%)] Loss: -1419.862793\n",
      "Train Epoch: 2363 [11776/60000 (20%)] Loss: -1441.611572\n",
      "Train Epoch: 2363 [23040/60000 (38%)] Loss: -1252.986450\n",
      "Train Epoch: 2363 [34304/60000 (57%)] Loss: -1293.535645\n",
      "Train Epoch: 2363 [45568/60000 (76%)] Loss: -1445.115967\n",
      "Train Epoch: 2363 [56832/60000 (95%)] Loss: -1407.768799\n",
      "    epoch          : 2363\n",
      "    loss           : -1424.3546352925273\n",
      "Train Epoch: 2364 [512/60000 (1%)] Loss: -1541.286621\n",
      "Train Epoch: 2364 [11776/60000 (20%)] Loss: -1554.574951\n",
      "Train Epoch: 2364 [23040/60000 (38%)] Loss: -1410.878174\n",
      "Train Epoch: 2364 [34304/60000 (57%)] Loss: -1470.032593\n",
      "Train Epoch: 2364 [45568/60000 (76%)] Loss: -1458.769775\n",
      "Train Epoch: 2364 [56832/60000 (95%)] Loss: -1318.799805\n",
      "    epoch          : 2364\n",
      "    loss           : -1424.1093091372043\n",
      "Train Epoch: 2365 [512/60000 (1%)] Loss: -1390.146973\n",
      "Train Epoch: 2365 [11776/60000 (20%)] Loss: -1490.890381\n",
      "Train Epoch: 2365 [23040/60000 (38%)] Loss: -1533.879150\n",
      "Train Epoch: 2365 [34304/60000 (57%)] Loss: -1478.365601\n",
      "Train Epoch: 2365 [45568/60000 (76%)] Loss: -1528.255859\n",
      "Train Epoch: 2365 [56832/60000 (95%)] Loss: -1408.260620\n",
      "    epoch          : 2365\n",
      "    loss           : -1437.1945066290386\n",
      "Train Epoch: 2366 [512/60000 (1%)] Loss: -1440.250244\n",
      "Train Epoch: 2366 [11776/60000 (20%)] Loss: -1306.900146\n",
      "Train Epoch: 2366 [23040/60000 (38%)] Loss: -1328.509766\n",
      "Train Epoch: 2366 [34304/60000 (57%)] Loss: -1541.091064\n",
      "Train Epoch: 2366 [45568/60000 (76%)] Loss: -1481.961182\n",
      "Train Epoch: 2366 [56832/60000 (95%)] Loss: -1538.642456\n",
      "    epoch          : 2366\n",
      "    loss           : -1430.5701904296875\n",
      "Train Epoch: 2367 [512/60000 (1%)] Loss: -1478.446777\n",
      "Train Epoch: 2367 [11776/60000 (20%)] Loss: -1521.551025\n",
      "Train Epoch: 2367 [23040/60000 (38%)] Loss: -1545.036865\n",
      "Train Epoch: 2367 [34304/60000 (57%)] Loss: -1250.293335\n",
      "Train Epoch: 2367 [45568/60000 (76%)] Loss: -1455.077148\n",
      "Train Epoch: 2367 [56832/60000 (95%)] Loss: -1373.006226\n",
      "    epoch          : 2367\n",
      "    loss           : -1436.1016845703125\n",
      "Train Epoch: 2368 [512/60000 (1%)] Loss: -1415.351562\n",
      "Train Epoch: 2368 [11776/60000 (20%)] Loss: -1273.381104\n",
      "Train Epoch: 2368 [23040/60000 (38%)] Loss: -1556.778809\n",
      "Train Epoch: 2368 [34304/60000 (57%)] Loss: -1441.149292\n",
      "Train Epoch: 2368 [45568/60000 (76%)] Loss: -1484.086670\n",
      "Train Epoch: 2368 [56832/60000 (95%)] Loss: -1503.387817\n",
      "    epoch          : 2368\n",
      "    loss           : -1419.8968781724489\n",
      "Train Epoch: 2369 [512/60000 (1%)] Loss: -1569.539795\n",
      "Train Epoch: 2369 [11776/60000 (20%)] Loss: -1442.316406\n",
      "Train Epoch: 2369 [23040/60000 (38%)] Loss: -1442.435669\n",
      "Train Epoch: 2369 [34304/60000 (57%)] Loss: -1436.370117\n",
      "Train Epoch: 2369 [45568/60000 (76%)] Loss: -1399.042480\n",
      "Train Epoch: 2369 [56832/60000 (95%)] Loss: -1447.566650\n",
      "    epoch          : 2369\n",
      "    loss           : -1430.8167352191472\n",
      "Train Epoch: 2370 [512/60000 (1%)] Loss: -1580.992065\n",
      "Train Epoch: 2370 [11776/60000 (20%)] Loss: -1472.156738\n",
      "Train Epoch: 2370 [23040/60000 (38%)] Loss: -1446.765747\n",
      "Train Epoch: 2370 [34304/60000 (57%)] Loss: -1533.500244\n",
      "Train Epoch: 2370 [45568/60000 (76%)] Loss: -1320.146118\n",
      "Train Epoch: 2370 [56832/60000 (95%)] Loss: -1453.341797\n",
      "    epoch          : 2370\n",
      "    loss           : -1431.0407435530324\n",
      "Train Epoch: 2371 [512/60000 (1%)] Loss: -1384.606934\n",
      "Train Epoch: 2371 [11776/60000 (20%)] Loss: -1569.459717\n",
      "Train Epoch: 2371 [23040/60000 (38%)] Loss: -1300.355713\n",
      "Train Epoch: 2371 [34304/60000 (57%)] Loss: -1501.216431\n",
      "Train Epoch: 2371 [45568/60000 (76%)] Loss: -1511.689941\n",
      "Train Epoch: 2371 [56832/60000 (95%)] Loss: -1372.647827\n",
      "    epoch          : 2371\n",
      "    loss           : -1431.435708945754\n",
      "Train Epoch: 2372 [512/60000 (1%)] Loss: -1335.198608\n",
      "Train Epoch: 2372 [11776/60000 (20%)] Loss: -1427.098389\n",
      "Train Epoch: 2372 [23040/60000 (38%)] Loss: -1461.010132\n",
      "Train Epoch: 2372 [34304/60000 (57%)] Loss: -1323.048218\n",
      "Train Epoch: 2372 [45568/60000 (76%)] Loss: -1525.152832\n",
      "Train Epoch: 2372 [56832/60000 (95%)] Loss: -1528.551514\n",
      "    epoch          : 2372\n",
      "    loss           : -1408.8629533153469\n",
      "Train Epoch: 2373 [512/60000 (1%)] Loss: -1506.394531\n",
      "Train Epoch: 2373 [11776/60000 (20%)] Loss: -1552.289917\n",
      "Train Epoch: 2373 [23040/60000 (38%)] Loss: -1407.266968\n",
      "Train Epoch: 2373 [34304/60000 (57%)] Loss: -1540.321045\n",
      "Train Epoch: 2373 [45568/60000 (76%)] Loss: -1435.427124\n",
      "Train Epoch: 2373 [56832/60000 (95%)] Loss: -1421.135254\n",
      "    epoch          : 2373\n",
      "    loss           : -1427.229049768825\n",
      "Train Epoch: 2374 [512/60000 (1%)] Loss: -1571.882568\n",
      "Train Epoch: 2374 [11776/60000 (20%)] Loss: -1425.641968\n",
      "Train Epoch: 2374 [23040/60000 (38%)] Loss: -1532.065063\n",
      "Train Epoch: 2374 [34304/60000 (57%)] Loss: -1339.099365\n",
      "Train Epoch: 2374 [45568/60000 (76%)] Loss: -1372.795898\n",
      "Train Epoch: 2374 [56832/60000 (95%)] Loss: -1440.323853\n",
      "    epoch          : 2374\n",
      "    loss           : -1430.695159050031\n",
      "Train Epoch: 2375 [512/60000 (1%)] Loss: -1512.861084\n",
      "Train Epoch: 2375 [11776/60000 (20%)] Loss: -1439.133301\n",
      "Train Epoch: 2375 [23040/60000 (38%)] Loss: -1465.111938\n",
      "Train Epoch: 2375 [34304/60000 (57%)] Loss: -1481.094727\n",
      "Train Epoch: 2375 [45568/60000 (76%)] Loss: -1390.410034\n",
      "Train Epoch: 2375 [56832/60000 (95%)] Loss: -1531.027100\n",
      "    epoch          : 2375\n",
      "    loss           : -1428.1154619637182\n",
      "Train Epoch: 2376 [512/60000 (1%)] Loss: -1200.459839\n",
      "Train Epoch: 2376 [11776/60000 (20%)] Loss: -1447.509399\n",
      "Train Epoch: 2376 [23040/60000 (38%)] Loss: -1341.685547\n",
      "Train Epoch: 2376 [34304/60000 (57%)] Loss: -1405.152222\n",
      "Train Epoch: 2376 [45568/60000 (76%)] Loss: -1335.204468\n",
      "Train Epoch: 2376 [56832/60000 (95%)] Loss: -1548.404785\n",
      "    epoch          : 2376\n",
      "    loss           : -1420.3866118522687\n",
      "Train Epoch: 2377 [512/60000 (1%)] Loss: -1463.117188\n",
      "Train Epoch: 2377 [11776/60000 (20%)] Loss: -1539.312134\n",
      "Train Epoch: 2377 [23040/60000 (38%)] Loss: -1400.134521\n",
      "Train Epoch: 2377 [34304/60000 (57%)] Loss: -1247.760132\n",
      "Train Epoch: 2377 [45568/60000 (76%)] Loss: -1546.072998\n",
      "Train Epoch: 2377 [56832/60000 (95%)] Loss: -1499.830444\n",
      "    epoch          : 2377\n",
      "    loss           : -1433.413396285752\n",
      "Train Epoch: 2378 [512/60000 (1%)] Loss: -1399.181396\n",
      "Train Epoch: 2378 [11776/60000 (20%)] Loss: -1385.084961\n",
      "Train Epoch: 2378 [23040/60000 (38%)] Loss: -1448.126465\n",
      "Train Epoch: 2378 [34304/60000 (57%)] Loss: -1396.100098\n",
      "Train Epoch: 2378 [45568/60000 (76%)] Loss: -1325.387939\n",
      "Train Epoch: 2378 [56832/60000 (95%)] Loss: -1382.710938\n",
      "    epoch          : 2378\n",
      "    loss           : -1415.6564617264744\n",
      "Train Epoch: 2379 [512/60000 (1%)] Loss: -1315.780029\n",
      "Train Epoch: 2379 [11776/60000 (20%)] Loss: -1139.405396\n",
      "Train Epoch: 2379 [23040/60000 (38%)] Loss: -1526.345459\n",
      "Train Epoch: 2379 [34304/60000 (57%)] Loss: -1439.444092\n",
      "Train Epoch: 2379 [45568/60000 (76%)] Loss: -1298.787842\n",
      "Train Epoch: 2379 [56832/60000 (95%)] Loss: -1402.550049\n",
      "    epoch          : 2379\n",
      "    loss           : -1420.3924560546875\n",
      "Train Epoch: 2380 [512/60000 (1%)] Loss: -1388.961792\n",
      "Train Epoch: 2380 [11776/60000 (20%)] Loss: -1509.452881\n",
      "Train Epoch: 2380 [23040/60000 (38%)] Loss: -1413.709106\n",
      "Train Epoch: 2380 [34304/60000 (57%)] Loss: -1478.771729\n",
      "Train Epoch: 2380 [45568/60000 (76%)] Loss: -1343.401611\n",
      "Train Epoch: 2380 [56832/60000 (95%)] Loss: -1455.027954\n",
      "    epoch          : 2380\n",
      "    loss           : -1426.9841222385903\n",
      "Train Epoch: 2381 [512/60000 (1%)] Loss: -1436.688843\n",
      "Train Epoch: 2381 [11776/60000 (20%)] Loss: -1391.227661\n",
      "Train Epoch: 2381 [23040/60000 (38%)] Loss: -1454.113892\n",
      "Train Epoch: 2381 [34304/60000 (57%)] Loss: -1346.003052\n",
      "Train Epoch: 2381 [45568/60000 (76%)] Loss: -1247.269653\n",
      "Train Epoch: 2381 [56832/60000 (95%)] Loss: -1478.381348\n",
      "    epoch          : 2381\n",
      "    loss           : -1431.5230861168122\n",
      "Train Epoch: 2382 [512/60000 (1%)] Loss: -1443.394409\n",
      "Train Epoch: 2382 [11776/60000 (20%)] Loss: -1488.403809\n",
      "Train Epoch: 2382 [23040/60000 (38%)] Loss: -1518.817383\n",
      "Train Epoch: 2382 [34304/60000 (57%)] Loss: -1537.901123\n",
      "Train Epoch: 2382 [45568/60000 (76%)] Loss: -1430.927002\n",
      "Train Epoch: 2382 [56832/60000 (95%)] Loss: -1390.327637\n",
      "    epoch          : 2382\n",
      "    loss           : -1423.648951298773\n",
      "Train Epoch: 2383 [512/60000 (1%)] Loss: -1077.838379\n",
      "Train Epoch: 2383 [11776/60000 (20%)] Loss: -1287.819092\n",
      "Train Epoch: 2383 [23040/60000 (38%)] Loss: -1413.539795\n",
      "Train Epoch: 2383 [34304/60000 (57%)] Loss: -1486.872559\n",
      "Train Epoch: 2383 [45568/60000 (76%)] Loss: -1538.886353\n",
      "Train Epoch: 2383 [56832/60000 (95%)] Loss: -1539.971802\n",
      "    epoch          : 2383\n",
      "    loss           : -1426.961429229564\n",
      "Train Epoch: 2384 [512/60000 (1%)] Loss: -1530.952881\n",
      "Train Epoch: 2384 [11776/60000 (20%)] Loss: -1214.894897\n",
      "Train Epoch: 2384 [23040/60000 (38%)] Loss: -1396.038086\n",
      "Train Epoch: 2384 [34304/60000 (57%)] Loss: -1532.731812\n",
      "Train Epoch: 2384 [45568/60000 (76%)] Loss: -1397.435425\n",
      "Train Epoch: 2384 [56832/60000 (95%)] Loss: -1345.752197\n",
      "    epoch          : 2384\n",
      "    loss           : -1426.7445071807688\n",
      "Train Epoch: 2385 [512/60000 (1%)] Loss: -1401.746460\n",
      "Train Epoch: 2385 [11776/60000 (20%)] Loss: -1411.393066\n",
      "Train Epoch: 2385 [23040/60000 (38%)] Loss: -1393.272217\n",
      "Train Epoch: 2385 [34304/60000 (57%)] Loss: -1522.670898\n",
      "Train Epoch: 2385 [45568/60000 (76%)] Loss: -1495.950439\n",
      "Train Epoch: 2385 [56832/60000 (95%)] Loss: -1357.830811\n",
      "    epoch          : 2385\n",
      "    loss           : -1434.2927990929554\n",
      "Train Epoch: 2386 [512/60000 (1%)] Loss: -1462.923584\n",
      "Train Epoch: 2386 [11776/60000 (20%)] Loss: -1509.055908\n",
      "Train Epoch: 2386 [23040/60000 (38%)] Loss: -1294.933594\n",
      "Train Epoch: 2386 [34304/60000 (57%)] Loss: -1356.285400\n",
      "Train Epoch: 2386 [45568/60000 (76%)] Loss: -1393.032837\n",
      "Train Epoch: 2386 [56832/60000 (95%)] Loss: -1341.123291\n",
      "    epoch          : 2386\n",
      "    loss           : -1407.8864608161193\n",
      "Train Epoch: 2387 [512/60000 (1%)] Loss: -1403.948853\n",
      "Train Epoch: 2387 [11776/60000 (20%)] Loss: -1445.568604\n",
      "Train Epoch: 2387 [23040/60000 (38%)] Loss: -1193.178589\n",
      "Train Epoch: 2387 [34304/60000 (57%)] Loss: -1417.716797\n",
      "Train Epoch: 2387 [45568/60000 (76%)] Loss: -1466.424316\n",
      "Train Epoch: 2387 [56832/60000 (95%)] Loss: -1569.270386\n",
      "    epoch          : 2387\n",
      "    loss           : -1426.129059699969\n",
      "Train Epoch: 2388 [512/60000 (1%)] Loss: -1501.626465\n",
      "Train Epoch: 2388 [11776/60000 (20%)] Loss: -1492.627197\n",
      "Train Epoch: 2388 [23040/60000 (38%)] Loss: -1461.890259\n",
      "Train Epoch: 2388 [34304/60000 (57%)] Loss: -1550.343262\n",
      "Train Epoch: 2388 [45568/60000 (76%)] Loss: -1483.415649\n",
      "Train Epoch: 2388 [56832/60000 (95%)] Loss: -1321.384155\n",
      "    epoch          : 2388\n",
      "    loss           : -1435.4316002797273\n",
      "Train Epoch: 2389 [512/60000 (1%)] Loss: -1217.222168\n",
      "Train Epoch: 2389 [11776/60000 (20%)] Loss: -1331.585938\n",
      "Train Epoch: 2389 [23040/60000 (38%)] Loss: -1529.904785\n",
      "Train Epoch: 2389 [34304/60000 (57%)] Loss: -1556.847900\n",
      "Train Epoch: 2389 [45568/60000 (76%)] Loss: -1540.344727\n",
      "Train Epoch: 2389 [56832/60000 (95%)] Loss: -1457.752075\n",
      "    epoch          : 2389\n",
      "    loss           : -1431.4840025820974\n",
      "Train Epoch: 2390 [512/60000 (1%)] Loss: -1488.339111\n",
      "Train Epoch: 2390 [11776/60000 (20%)] Loss: -1529.194824\n",
      "Train Epoch: 2390 [23040/60000 (38%)] Loss: -1491.626831\n",
      "Train Epoch: 2390 [34304/60000 (57%)] Loss: -1458.440796\n",
      "Train Epoch: 2390 [45568/60000 (76%)] Loss: -1502.551025\n",
      "Train Epoch: 2390 [56832/60000 (95%)] Loss: -1412.156250\n",
      "    epoch          : 2390\n",
      "    loss           : -1422.7801286083156\n",
      "Train Epoch: 2391 [512/60000 (1%)] Loss: -1328.828125\n",
      "Train Epoch: 2391 [11776/60000 (20%)] Loss: -1360.894287\n",
      "Train Epoch: 2391 [23040/60000 (38%)] Loss: -1537.398315\n",
      "Train Epoch: 2391 [34304/60000 (57%)] Loss: -1467.970703\n",
      "Train Epoch: 2391 [45568/60000 (76%)] Loss: -1247.500366\n",
      "Train Epoch: 2391 [56832/60000 (95%)] Loss: -1461.982422\n",
      "    epoch          : 2391\n",
      "    loss           : -1430.9508470438295\n",
      "Train Epoch: 2392 [512/60000 (1%)] Loss: -1264.324951\n",
      "Train Epoch: 2392 [11776/60000 (20%)] Loss: -1433.198853\n",
      "Train Epoch: 2392 [23040/60000 (38%)] Loss: -1460.756836\n",
      "Train Epoch: 2392 [34304/60000 (57%)] Loss: -1533.731201\n",
      "Train Epoch: 2392 [45568/60000 (76%)] Loss: -1482.019653\n",
      "Train Epoch: 2392 [56832/60000 (95%)] Loss: -1464.051636\n",
      "    epoch          : 2392\n",
      "    loss           : -1435.3720406570003\n",
      "Train Epoch: 2393 [512/60000 (1%)] Loss: -1430.019897\n",
      "Train Epoch: 2393 [11776/60000 (20%)] Loss: -1429.827148\n",
      "Train Epoch: 2393 [23040/60000 (38%)] Loss: -1356.164307\n",
      "Train Epoch: 2393 [34304/60000 (57%)] Loss: -1405.658691\n",
      "Train Epoch: 2393 [45568/60000 (76%)] Loss: -1366.086060\n",
      "Train Epoch: 2393 [56832/60000 (95%)] Loss: -1551.091064\n",
      "    epoch          : 2393\n",
      "    loss           : -1412.7309073755296\n",
      "Train Epoch: 2394 [512/60000 (1%)] Loss: -1252.684692\n",
      "Train Epoch: 2394 [11776/60000 (20%)] Loss: -1506.331421\n",
      "Train Epoch: 2394 [23040/60000 (38%)] Loss: -1526.817383\n",
      "Train Epoch: 2394 [34304/60000 (57%)] Loss: -1382.039673\n",
      "Train Epoch: 2394 [45568/60000 (76%)] Loss: -1503.922729\n",
      "Train Epoch: 2394 [56832/60000 (95%)] Loss: -1477.458496\n",
      "    epoch          : 2394\n",
      "    loss           : -1425.7736668128753\n",
      "Train Epoch: 2395 [512/60000 (1%)] Loss: -1534.010986\n",
      "Train Epoch: 2395 [11776/60000 (20%)] Loss: -1459.870728\n",
      "Train Epoch: 2395 [23040/60000 (38%)] Loss: -1531.293213\n",
      "Train Epoch: 2395 [34304/60000 (57%)] Loss: -1557.101562\n",
      "Train Epoch: 2395 [45568/60000 (76%)] Loss: -1321.231445\n",
      "Train Epoch: 2395 [56832/60000 (95%)] Loss: -1402.690186\n",
      "    epoch          : 2395\n",
      "    loss           : -1414.744356489451\n",
      "Train Epoch: 2396 [512/60000 (1%)] Loss: -1402.798218\n",
      "Train Epoch: 2396 [11776/60000 (20%)] Loss: -1524.510742\n",
      "Train Epoch: 2396 [23040/60000 (38%)] Loss: -1358.139771\n",
      "Train Epoch: 2396 [34304/60000 (57%)] Loss: -1576.289062\n",
      "Train Epoch: 2396 [45568/60000 (76%)] Loss: -1356.067505\n",
      "Train Epoch: 2396 [56832/60000 (95%)] Loss: -1333.007568\n",
      "    epoch          : 2396\n",
      "    loss           : -1417.9119393731241\n",
      "Train Epoch: 2397 [512/60000 (1%)] Loss: -1273.840454\n",
      "Train Epoch: 2397 [11776/60000 (20%)] Loss: -1530.416626\n",
      "Train Epoch: 2397 [23040/60000 (38%)] Loss: -1498.957153\n",
      "Train Epoch: 2397 [34304/60000 (57%)] Loss: -1564.988647\n",
      "Train Epoch: 2397 [45568/60000 (76%)] Loss: -1479.536987\n",
      "Train Epoch: 2397 [56832/60000 (95%)] Loss: -1458.529785\n",
      "    epoch          : 2397\n",
      "    loss           : -1422.7634625623457\n",
      "Train Epoch: 2398 [512/60000 (1%)] Loss: -1309.764282\n",
      "Train Epoch: 2398 [11776/60000 (20%)] Loss: -1382.646362\n",
      "Train Epoch: 2398 [23040/60000 (38%)] Loss: -1294.347046\n",
      "Train Epoch: 2398 [34304/60000 (57%)] Loss: -1161.293213\n",
      "Train Epoch: 2398 [45568/60000 (76%)] Loss: -1507.352539\n",
      "Train Epoch: 2398 [56832/60000 (95%)] Loss: -1536.458496\n",
      "    epoch          : 2398\n",
      "    loss           : -1419.2853948733227\n",
      "Train Epoch: 2399 [512/60000 (1%)] Loss: -1525.224731\n",
      "Train Epoch: 2399 [11776/60000 (20%)] Loss: -1539.972900\n",
      "Train Epoch: 2399 [23040/60000 (38%)] Loss: -1528.536865\n",
      "Train Epoch: 2399 [34304/60000 (57%)] Loss: -1520.968872\n",
      "Train Epoch: 2399 [45568/60000 (76%)] Loss: -1466.507568\n",
      "Train Epoch: 2399 [56832/60000 (95%)] Loss: -1415.984863\n",
      "    epoch          : 2399\n",
      "    loss           : -1427.2747557904086\n",
      "Train Epoch: 2400 [512/60000 (1%)] Loss: -1397.096802\n",
      "Train Epoch: 2400 [11776/60000 (20%)] Loss: -1556.596680\n",
      "Train Epoch: 2400 [23040/60000 (38%)] Loss: -1559.733765\n",
      "Train Epoch: 2400 [34304/60000 (57%)] Loss: -1306.226318\n",
      "Train Epoch: 2400 [45568/60000 (76%)] Loss: -1289.037231\n",
      "Train Epoch: 2400 [56832/60000 (95%)] Loss: -1516.971313\n",
      "    epoch          : 2400\n",
      "    loss           : -1433.1770702297404\n",
      "Saving checkpoint: saved/models/Mnist_DeepGenerativeOperad/0127_111843/checkpoint-epoch2400.pth ...\n",
      "Train Epoch: 2401 [512/60000 (1%)] Loss: -1544.575439\n",
      "Train Epoch: 2401 [11776/60000 (20%)] Loss: -1420.784180\n",
      "Train Epoch: 2401 [23040/60000 (38%)] Loss: -1398.346924\n",
      "Train Epoch: 2401 [34304/60000 (57%)] Loss: -1291.273804\n",
      "Train Epoch: 2401 [45568/60000 (76%)] Loss: -1569.588623\n",
      "Train Epoch: 2401 [56832/60000 (95%)] Loss: -1438.056885\n",
      "    epoch          : 2401\n",
      "    loss           : -1412.9660372114452\n",
      "Train Epoch: 2402 [512/60000 (1%)] Loss: -1219.360352\n",
      "Train Epoch: 2402 [11776/60000 (20%)] Loss: -1536.573242\n",
      "Train Epoch: 2402 [23040/60000 (38%)] Loss: -1458.588501\n",
      "Train Epoch: 2402 [34304/60000 (57%)] Loss: -1392.030762\n",
      "Train Epoch: 2402 [45568/60000 (76%)] Loss: -1388.422119\n",
      "Train Epoch: 2402 [56832/60000 (95%)] Loss: -1310.315063\n",
      "    epoch          : 2402\n",
      "    loss           : -1421.558452713961\n",
      "Train Epoch: 2403 [512/60000 (1%)] Loss: -1496.837891\n",
      "Train Epoch: 2403 [11776/60000 (20%)] Loss: -1413.893799\n",
      "Train Epoch: 2403 [23040/60000 (38%)] Loss: -1488.038574\n",
      "Train Epoch: 2403 [34304/60000 (57%)] Loss: -1475.466187\n",
      "Train Epoch: 2403 [45568/60000 (76%)] Loss: -1501.432129\n",
      "Train Epoch: 2403 [56832/60000 (95%)] Loss: -1452.870605\n",
      "    epoch          : 2403\n",
      "    loss           : -1427.2464599609375\n",
      "Train Epoch: 2404 [512/60000 (1%)] Loss: -1500.424438\n",
      "Train Epoch: 2404 [11776/60000 (20%)] Loss: -1255.050293\n",
      "Train Epoch: 2404 [23040/60000 (38%)] Loss: -1461.502441\n",
      "Train Epoch: 2404 [34304/60000 (57%)] Loss: -1525.727173\n",
      "Train Epoch: 2404 [45568/60000 (76%)] Loss: -1383.135864\n",
      "Train Epoch: 2404 [56832/60000 (95%)] Loss: -1382.884644\n",
      "    epoch          : 2404\n",
      "    loss           : -1420.5779381013858\n",
      "Train Epoch: 2405 [512/60000 (1%)] Loss: -1537.621094\n",
      "Train Epoch: 2405 [11776/60000 (20%)] Loss: -1460.260498\n",
      "Train Epoch: 2405 [23040/60000 (38%)] Loss: -1417.671631\n",
      "Train Epoch: 2405 [34304/60000 (57%)] Loss: -1273.599976\n",
      "Train Epoch: 2405 [45568/60000 (76%)] Loss: -1554.366943\n",
      "Train Epoch: 2405 [56832/60000 (95%)] Loss: -1311.548096\n",
      "    epoch          : 2405\n",
      "    loss           : -1433.6318669723253\n",
      "Train Epoch: 2406 [512/60000 (1%)] Loss: -1446.838745\n",
      "Train Epoch: 2406 [11776/60000 (20%)] Loss: -1416.089722\n",
      "Train Epoch: 2406 [23040/60000 (38%)] Loss: -1573.570068\n",
      "Train Epoch: 2406 [34304/60000 (57%)] Loss: -1399.439453\n",
      "Train Epoch: 2406 [45568/60000 (76%)] Loss: -1269.223267\n",
      "Train Epoch: 2406 [56832/60000 (95%)] Loss: -1530.739502\n",
      "    epoch          : 2406\n",
      "    loss           : -1434.95910334183\n",
      "Train Epoch: 2407 [512/60000 (1%)] Loss: -1420.808594\n",
      "Train Epoch: 2407 [11776/60000 (20%)] Loss: -1562.459229\n",
      "Train Epoch: 2407 [23040/60000 (38%)] Loss: -1566.482788\n",
      "Train Epoch: 2407 [34304/60000 (57%)] Loss: -1564.343506\n",
      "Train Epoch: 2407 [45568/60000 (76%)] Loss: -1466.784302\n",
      "Train Epoch: 2407 [56832/60000 (95%)] Loss: -1334.630615\n",
      "    epoch          : 2407\n",
      "    loss           : -1433.9179284047273\n",
      "Train Epoch: 2408 [512/60000 (1%)] Loss: -1354.646240\n",
      "Train Epoch: 2408 [11776/60000 (20%)] Loss: -1457.421631\n",
      "Train Epoch: 2408 [23040/60000 (38%)] Loss: -1473.054321\n",
      "Train Epoch: 2408 [34304/60000 (57%)] Loss: -1503.108887\n",
      "Train Epoch: 2408 [45568/60000 (76%)] Loss: -1517.494629\n",
      "Train Epoch: 2408 [56832/60000 (95%)] Loss: -1488.225098\n",
      "    epoch          : 2408\n",
      "    loss           : -1422.973299015713\n",
      "Train Epoch: 2409 [512/60000 (1%)] Loss: -1496.543701\n",
      "Train Epoch: 2409 [11776/60000 (20%)] Loss: -1464.935303\n",
      "Train Epoch: 2409 [23040/60000 (38%)] Loss: -1310.313232\n",
      "Train Epoch: 2409 [34304/60000 (57%)] Loss: -1294.276855\n",
      "Train Epoch: 2409 [45568/60000 (76%)] Loss: -1347.698486\n",
      "Train Epoch: 2409 [56832/60000 (95%)] Loss: -1469.051392\n",
      "    epoch          : 2409\n",
      "    loss           : -1421.8546028783767\n",
      "Train Epoch: 2410 [512/60000 (1%)] Loss: -1476.441650\n",
      "Train Epoch: 2410 [11776/60000 (20%)] Loss: -1316.137573\n",
      "Train Epoch: 2410 [23040/60000 (38%)] Loss: -1277.281860\n",
      "Train Epoch: 2410 [34304/60000 (57%)] Loss: -1543.535034\n",
      "Train Epoch: 2410 [45568/60000 (76%)] Loss: -1447.191162\n",
      "Train Epoch: 2410 [56832/60000 (95%)] Loss: -1328.185547\n",
      "    epoch          : 2410\n",
      "    loss           : -1423.0004272460938\n",
      "Train Epoch: 2411 [512/60000 (1%)] Loss: -1541.644531\n",
      "Train Epoch: 2411 [11776/60000 (20%)] Loss: -1391.072632\n",
      "Train Epoch: 2411 [23040/60000 (38%)] Loss: -1543.146729\n",
      "Train Epoch: 2411 [34304/60000 (57%)] Loss: -1242.463257\n",
      "Train Epoch: 2411 [45568/60000 (76%)] Loss: -1390.696533\n",
      "Train Epoch: 2411 [56832/60000 (95%)] Loss: -1560.005371\n",
      "    epoch          : 2411\n",
      "    loss           : -1431.850806284759\n",
      "Train Epoch: 2412 [512/60000 (1%)] Loss: -1401.041626\n",
      "Train Epoch: 2412 [11776/60000 (20%)] Loss: -1434.977539\n",
      "Train Epoch: 2412 [23040/60000 (38%)] Loss: -1401.398804\n",
      "Train Epoch: 2412 [34304/60000 (57%)] Loss: -1527.424927\n",
      "Train Epoch: 2412 [45568/60000 (76%)] Loss: -1477.919189\n",
      "Train Epoch: 2412 [56832/60000 (95%)] Loss: -1268.356445\n",
      "    epoch          : 2412\n",
      "    loss           : -1434.3378451072563\n",
      "Train Epoch: 2413 [512/60000 (1%)] Loss: -1314.546143\n",
      "Train Epoch: 2413 [11776/60000 (20%)] Loss: -1400.092529\n",
      "Train Epoch: 2413 [23040/60000 (38%)] Loss: -1538.724365\n",
      "Train Epoch: 2413 [34304/60000 (57%)] Loss: -1535.042480\n",
      "Train Epoch: 2413 [45568/60000 (76%)] Loss: -1359.313232\n",
      "Train Epoch: 2413 [56832/60000 (95%)] Loss: -1433.678467\n",
      "    epoch          : 2413\n",
      "    loss           : -1440.0068690413136\n",
      "Train Epoch: 2414 [512/60000 (1%)] Loss: -1562.472656\n",
      "Train Epoch: 2414 [11776/60000 (20%)] Loss: -1397.498047\n",
      "Train Epoch: 2414 [23040/60000 (38%)] Loss: -1537.862061\n",
      "Train Epoch: 2414 [34304/60000 (57%)] Loss: -1465.855225\n",
      "Train Epoch: 2414 [45568/60000 (76%)] Loss: -1496.684448\n",
      "Train Epoch: 2414 [56832/60000 (95%)] Loss: -1300.608765\n",
      "    epoch          : 2414\n",
      "    loss           : -1419.4829325702906\n",
      "Train Epoch: 2415 [512/60000 (1%)] Loss: -1389.730957\n",
      "Train Epoch: 2415 [11776/60000 (20%)] Loss: -1420.147705\n",
      "Train Epoch: 2415 [23040/60000 (38%)] Loss: -1341.586426\n",
      "Train Epoch: 2415 [34304/60000 (57%)] Loss: -1414.850098\n",
      "Train Epoch: 2415 [45568/60000 (76%)] Loss: -1267.687744\n",
      "Train Epoch: 2415 [56832/60000 (95%)] Loss: -1563.079102\n",
      "    epoch          : 2415\n",
      "    loss           : -1430.8072868390273\n",
      "Train Epoch: 2416 [512/60000 (1%)] Loss: -1568.791748\n",
      "Train Epoch: 2416 [11776/60000 (20%)] Loss: -1436.307617\n",
      "Train Epoch: 2416 [23040/60000 (38%)] Loss: -1384.608398\n",
      "Train Epoch: 2416 [34304/60000 (57%)] Loss: -1544.699219\n",
      "Train Epoch: 2416 [45568/60000 (76%)] Loss: -1536.958984\n",
      "Train Epoch: 2416 [56832/60000 (95%)] Loss: -1436.876709\n",
      "    epoch          : 2416\n",
      "    loss           : -1427.3145472639699\n",
      "Train Epoch: 2417 [512/60000 (1%)] Loss: -1402.475220\n",
      "Train Epoch: 2417 [11776/60000 (20%)] Loss: -1391.084473\n",
      "Train Epoch: 2417 [23040/60000 (38%)] Loss: -1413.917969\n",
      "Train Epoch: 2417 [34304/60000 (57%)] Loss: -1296.080811\n",
      "Train Epoch: 2417 [45568/60000 (76%)] Loss: -1284.688599\n",
      "Train Epoch: 2417 [56832/60000 (95%)] Loss: -1482.600830\n",
      "    epoch          : 2417\n",
      "    loss           : -1437.6253248311705\n",
      "Train Epoch: 2418 [512/60000 (1%)] Loss: -1449.397949\n",
      "Train Epoch: 2418 [11776/60000 (20%)] Loss: -1403.315430\n",
      "Train Epoch: 2418 [23040/60000 (38%)] Loss: -1435.633179\n",
      "Train Epoch: 2418 [34304/60000 (57%)] Loss: -1470.051880\n",
      "Train Epoch: 2418 [45568/60000 (76%)] Loss: -1422.781006\n",
      "Train Epoch: 2418 [56832/60000 (95%)] Loss: -1332.593750\n",
      "    epoch          : 2418\n",
      "    loss           : -1434.7213500286898\n",
      "Train Epoch: 2419 [512/60000 (1%)] Loss: -1409.546631\n",
      "Train Epoch: 2419 [11776/60000 (20%)] Loss: -1339.455322\n",
      "Train Epoch: 2419 [23040/60000 (38%)] Loss: -1397.096191\n",
      "Train Epoch: 2419 [34304/60000 (57%)] Loss: -1404.700928\n",
      "Train Epoch: 2419 [45568/60000 (76%)] Loss: -1428.917480\n",
      "Train Epoch: 2419 [56832/60000 (95%)] Loss: -1421.130249\n",
      "    epoch          : 2419\n",
      "    loss           : -1414.6937538621114\n",
      "Train Epoch: 2420 [512/60000 (1%)] Loss: -1454.856934\n",
      "Train Epoch: 2420 [11776/60000 (20%)] Loss: -1376.859131\n",
      "Train Epoch: 2420 [23040/60000 (38%)] Loss: -1473.724854\n",
      "Train Epoch: 2420 [34304/60000 (57%)] Loss: -1419.380371\n",
      "Train Epoch: 2420 [45568/60000 (76%)] Loss: -1429.675903\n",
      "Train Epoch: 2420 [56832/60000 (95%)] Loss: -1528.409668\n",
      "    epoch          : 2420\n",
      "    loss           : -1411.9108917753574\n",
      "Train Epoch: 2421 [512/60000 (1%)] Loss: -1517.491943\n",
      "Train Epoch: 2421 [11776/60000 (20%)] Loss: -1417.702637\n",
      "Train Epoch: 2421 [23040/60000 (38%)] Loss: -1155.163208\n",
      "Train Epoch: 2421 [34304/60000 (57%)] Loss: -1361.260010\n",
      "Train Epoch: 2421 [45568/60000 (76%)] Loss: -1526.284180\n",
      "Train Epoch: 2421 [56832/60000 (95%)] Loss: -1392.687988\n",
      "    epoch          : 2421\n",
      "    loss           : -1437.824553581281\n",
      "Train Epoch: 2422 [512/60000 (1%)] Loss: -1401.427734\n",
      "Train Epoch: 2422 [11776/60000 (20%)] Loss: -1236.662354\n",
      "Train Epoch: 2422 [23040/60000 (38%)] Loss: -1473.768433\n",
      "Train Epoch: 2422 [34304/60000 (57%)] Loss: -1531.281982\n",
      "Train Epoch: 2422 [45568/60000 (76%)] Loss: -1420.572876\n",
      "Train Epoch: 2422 [56832/60000 (95%)] Loss: -1397.852295\n",
      "    epoch          : 2422\n",
      "    loss           : -1424.6880872478594\n",
      "Train Epoch: 2423 [512/60000 (1%)] Loss: -1544.339355\n",
      "Train Epoch: 2423 [11776/60000 (20%)] Loss: -1425.512207\n",
      "Train Epoch: 2423 [23040/60000 (38%)] Loss: -1407.726929\n",
      "Train Epoch: 2423 [34304/60000 (57%)] Loss: -1295.152100\n",
      "Train Epoch: 2423 [45568/60000 (76%)] Loss: -1560.092163\n",
      "Train Epoch: 2423 [56832/60000 (95%)] Loss: -1346.080444\n",
      "    epoch          : 2423\n",
      "    loss           : -1445.776680984066\n",
      "Train Epoch: 2424 [512/60000 (1%)] Loss: -1464.708618\n",
      "Train Epoch: 2424 [11776/60000 (20%)] Loss: -1340.963867\n",
      "Train Epoch: 2424 [23040/60000 (38%)] Loss: -1521.593750\n",
      "Train Epoch: 2424 [34304/60000 (57%)] Loss: -1417.266602\n",
      "Train Epoch: 2424 [45568/60000 (76%)] Loss: -1402.267212\n",
      "Train Epoch: 2424 [56832/60000 (95%)] Loss: -1481.115967\n",
      "    epoch          : 2424\n",
      "    loss           : -1440.9084179549568\n",
      "Train Epoch: 2425 [512/60000 (1%)] Loss: -1420.099609\n",
      "Train Epoch: 2425 [11776/60000 (20%)] Loss: -1551.869385\n",
      "Train Epoch: 2425 [23040/60000 (38%)] Loss: -1338.354248\n",
      "Train Epoch: 2425 [34304/60000 (57%)] Loss: -1408.258667\n",
      "Train Epoch: 2425 [45568/60000 (76%)] Loss: -1384.376099\n",
      "Train Epoch: 2425 [56832/60000 (95%)] Loss: -1488.831421\n",
      "    epoch          : 2425\n",
      "    loss           : -1430.4589078224312\n",
      "Train Epoch: 2426 [512/60000 (1%)] Loss: -1484.450684\n",
      "Train Epoch: 2426 [11776/60000 (20%)] Loss: -1255.366333\n",
      "Train Epoch: 2426 [23040/60000 (38%)] Loss: -1565.879150\n",
      "Train Epoch: 2426 [34304/60000 (57%)] Loss: -1448.684326\n",
      "Train Epoch: 2426 [45568/60000 (76%)] Loss: -1437.068481\n",
      "Train Epoch: 2426 [56832/60000 (95%)] Loss: -1271.573730\n",
      "    epoch          : 2426\n",
      "    loss           : -1428.478969423111\n",
      "Train Epoch: 2427 [512/60000 (1%)] Loss: -1397.869751\n",
      "Train Epoch: 2427 [11776/60000 (20%)] Loss: -1442.524170\n",
      "Train Epoch: 2427 [23040/60000 (38%)] Loss: -1421.430786\n",
      "Train Epoch: 2427 [34304/60000 (57%)] Loss: -1292.263428\n",
      "Train Epoch: 2427 [45568/60000 (76%)] Loss: -1274.592041\n",
      "Train Epoch: 2427 [56832/60000 (95%)] Loss: -1462.795410\n",
      "    epoch          : 2427\n",
      "    loss           : -1426.7797803286105\n",
      "Train Epoch: 2428 [512/60000 (1%)] Loss: -1408.394775\n",
      "Train Epoch: 2428 [11776/60000 (20%)] Loss: -1358.058350\n",
      "Train Epoch: 2428 [23040/60000 (38%)] Loss: -1517.428345\n",
      "Train Epoch: 2428 [34304/60000 (57%)] Loss: -1337.512329\n",
      "Train Epoch: 2428 [45568/60000 (76%)] Loss: -1286.315674\n",
      "Train Epoch: 2428 [56832/60000 (95%)] Loss: -1497.517456\n",
      "    epoch          : 2428\n",
      "    loss           : -1426.2749113093662\n",
      "Train Epoch: 2429 [512/60000 (1%)] Loss: -1322.693359\n",
      "Train Epoch: 2429 [11776/60000 (20%)] Loss: -1479.958862\n",
      "Train Epoch: 2429 [23040/60000 (38%)] Loss: -1414.477295\n",
      "Train Epoch: 2429 [34304/60000 (57%)] Loss: -1239.374268\n",
      "Train Epoch: 2429 [45568/60000 (76%)] Loss: -1228.235474\n",
      "Train Epoch: 2429 [56832/60000 (95%)] Loss: -1468.908081\n",
      "    epoch          : 2429\n",
      "    loss           : -1439.121434788246\n",
      "Train Epoch: 2430 [512/60000 (1%)] Loss: -1433.235229\n",
      "Train Epoch: 2430 [11776/60000 (20%)] Loss: -1491.438843\n",
      "Train Epoch: 2430 [23040/60000 (38%)] Loss: -1404.903076\n",
      "Train Epoch: 2430 [34304/60000 (57%)] Loss: -1414.077881\n",
      "Train Epoch: 2430 [45568/60000 (76%)] Loss: -1272.069214\n",
      "Train Epoch: 2430 [56832/60000 (95%)] Loss: -1276.061768\n",
      "    epoch          : 2430\n",
      "    loss           : -1429.8158910719014\n",
      "Train Epoch: 2431 [512/60000 (1%)] Loss: -1184.624146\n",
      "Train Epoch: 2431 [11776/60000 (20%)] Loss: -1482.539307\n",
      "Train Epoch: 2431 [23040/60000 (38%)] Loss: -1426.495117\n",
      "Train Epoch: 2431 [34304/60000 (57%)] Loss: -1168.231445\n",
      "Train Epoch: 2431 [45568/60000 (76%)] Loss: -1538.103882\n",
      "Train Epoch: 2431 [56832/60000 (95%)] Loss: -1302.839111\n",
      "    epoch          : 2431\n",
      "    loss           : -1431.75013138076\n",
      "Train Epoch: 2432 [512/60000 (1%)] Loss: -1534.793823\n",
      "Train Epoch: 2432 [11776/60000 (20%)] Loss: -1402.661499\n",
      "Train Epoch: 2432 [23040/60000 (38%)] Loss: -1563.163086\n",
      "Train Epoch: 2432 [34304/60000 (57%)] Loss: -1285.619019\n",
      "Train Epoch: 2432 [45568/60000 (76%)] Loss: -1442.998535\n",
      "Train Epoch: 2432 [56832/60000 (95%)] Loss: -1429.845459\n",
      "    epoch          : 2432\n",
      "    loss           : -1413.000123449638\n",
      "Train Epoch: 2433 [512/60000 (1%)] Loss: -1394.069336\n",
      "Train Epoch: 2433 [11776/60000 (20%)] Loss: -1356.122803\n",
      "Train Epoch: 2433 [23040/60000 (38%)] Loss: -1513.397949\n",
      "Train Epoch: 2433 [34304/60000 (57%)] Loss: -1514.608398\n",
      "Train Epoch: 2433 [45568/60000 (76%)] Loss: -1365.248779\n",
      "Train Epoch: 2433 [56832/60000 (95%)] Loss: -1404.581177\n",
      "    epoch          : 2433\n",
      "    loss           : -1410.679617844059\n",
      "Train Epoch: 2434 [512/60000 (1%)] Loss: -1577.682007\n",
      "Train Epoch: 2434 [11776/60000 (20%)] Loss: -1375.234253\n",
      "Train Epoch: 2434 [23040/60000 (38%)] Loss: -1369.532959\n",
      "Train Epoch: 2434 [34304/60000 (57%)] Loss: -1489.487793\n",
      "Train Epoch: 2434 [45568/60000 (76%)] Loss: -1507.547119\n",
      "Train Epoch: 2434 [56832/60000 (95%)] Loss: -1581.841064\n",
      "    epoch          : 2434\n",
      "    loss           : -1448.3181155792063\n",
      "Train Epoch: 2435 [512/60000 (1%)] Loss: -1221.666016\n",
      "Train Epoch: 2435 [11776/60000 (20%)] Loss: -1433.253296\n",
      "Train Epoch: 2435 [23040/60000 (38%)] Loss: -1516.738770\n",
      "Train Epoch: 2435 [34304/60000 (57%)] Loss: -1461.659180\n",
      "Train Epoch: 2435 [45568/60000 (76%)] Loss: -1248.440674\n",
      "Train Epoch: 2435 [56832/60000 (95%)] Loss: -1426.345337\n",
      "    epoch          : 2435\n",
      "    loss           : -1423.654921709481\n",
      "Train Epoch: 2436 [512/60000 (1%)] Loss: -1546.928223\n",
      "Train Epoch: 2436 [11776/60000 (20%)] Loss: -1557.895264\n",
      "Train Epoch: 2436 [23040/60000 (38%)] Loss: -1569.995605\n",
      "Train Epoch: 2436 [34304/60000 (57%)] Loss: -1449.214600\n",
      "Train Epoch: 2436 [45568/60000 (76%)] Loss: -1459.356934\n",
      "Train Epoch: 2436 [56832/60000 (95%)] Loss: -1484.418579\n",
      "    epoch          : 2436\n",
      "    loss           : -1452.924660203147\n",
      "Train Epoch: 2437 [512/60000 (1%)] Loss: -1278.671753\n",
      "Train Epoch: 2437 [11776/60000 (20%)] Loss: -1476.009155\n",
      "Train Epoch: 2437 [23040/60000 (38%)] Loss: -1584.915283\n",
      "Train Epoch: 2437 [34304/60000 (57%)] Loss: -1450.356934\n",
      "Train Epoch: 2437 [45568/60000 (76%)] Loss: -1539.687256\n",
      "Train Epoch: 2437 [56832/60000 (95%)] Loss: -1502.794678\n",
      "    epoch          : 2437\n",
      "    loss           : -1435.5733625336554\n",
      "Train Epoch: 2438 [512/60000 (1%)] Loss: -1480.961548\n",
      "Train Epoch: 2438 [11776/60000 (20%)] Loss: -1483.154541\n",
      "Train Epoch: 2438 [23040/60000 (38%)] Loss: -1291.403809\n",
      "Train Epoch: 2438 [34304/60000 (57%)] Loss: -1425.976318\n",
      "Train Epoch: 2438 [45568/60000 (76%)] Loss: -1479.139648\n",
      "Train Epoch: 2438 [56832/60000 (95%)] Loss: -1510.638550\n",
      "    epoch          : 2438\n",
      "    loss           : -1432.8250804836466\n",
      "Train Epoch: 2439 [512/60000 (1%)] Loss: -1294.607422\n",
      "Train Epoch: 2439 [11776/60000 (20%)] Loss: -1487.586914\n",
      "Train Epoch: 2439 [23040/60000 (38%)] Loss: -1555.479004\n",
      "Train Epoch: 2439 [34304/60000 (57%)] Loss: -1496.443359\n",
      "Train Epoch: 2439 [45568/60000 (76%)] Loss: -1356.340332\n",
      "Train Epoch: 2439 [56832/60000 (95%)] Loss: -1307.592407\n",
      "    epoch          : 2439\n",
      "    loss           : -1432.9825770491261\n",
      "Train Epoch: 2440 [512/60000 (1%)] Loss: -1421.649902\n",
      "Train Epoch: 2440 [11776/60000 (20%)] Loss: -1326.098511\n",
      "Train Epoch: 2440 [23040/60000 (38%)] Loss: -1455.409912\n",
      "Train Epoch: 2440 [34304/60000 (57%)] Loss: -1511.332520\n",
      "Train Epoch: 2440 [45568/60000 (76%)] Loss: -1495.465088\n",
      "Train Epoch: 2440 [56832/60000 (95%)] Loss: -1465.963867\n",
      "    epoch          : 2440\n",
      "    loss           : -1441.5720897609904\n",
      "Train Epoch: 2441 [512/60000 (1%)] Loss: -1240.504028\n",
      "Train Epoch: 2441 [11776/60000 (20%)] Loss: -1488.506348\n",
      "Train Epoch: 2441 [23040/60000 (38%)] Loss: -1556.086304\n",
      "Train Epoch: 2441 [34304/60000 (57%)] Loss: -1428.499268\n",
      "Train Epoch: 2441 [45568/60000 (76%)] Loss: -1364.030762\n",
      "Train Epoch: 2441 [56832/60000 (95%)] Loss: -1427.107788\n",
      "    epoch          : 2441\n",
      "    loss           : -1433.756460416115\n",
      "Train Epoch: 2442 [512/60000 (1%)] Loss: -1556.810913\n",
      "Train Epoch: 2442 [11776/60000 (20%)] Loss: -1376.115967\n",
      "Train Epoch: 2442 [23040/60000 (38%)] Loss: -1460.598145\n",
      "Train Epoch: 2442 [34304/60000 (57%)] Loss: -1429.356567\n",
      "Train Epoch: 2442 [45568/60000 (76%)] Loss: -1378.582031\n",
      "Train Epoch: 2442 [56832/60000 (95%)] Loss: -1373.481812\n",
      "    epoch          : 2442\n",
      "    loss           : -1431.5194719390008\n",
      "Train Epoch: 2443 [512/60000 (1%)] Loss: -1380.625610\n",
      "Train Epoch: 2443 [11776/60000 (20%)] Loss: -1544.417847\n",
      "Train Epoch: 2443 [23040/60000 (38%)] Loss: -1400.412964\n",
      "Train Epoch: 2443 [34304/60000 (57%)] Loss: -1434.801758\n",
      "Train Epoch: 2443 [45568/60000 (76%)] Loss: -1392.501709\n",
      "Train Epoch: 2443 [56832/60000 (95%)] Loss: -1407.368530\n",
      "    epoch          : 2443\n",
      "    loss           : -1445.4108303953699\n",
      "Train Epoch: 2444 [512/60000 (1%)] Loss: -1547.274536\n",
      "Train Epoch: 2444 [11776/60000 (20%)] Loss: -1531.036865\n",
      "Train Epoch: 2444 [23040/60000 (38%)] Loss: -1539.621094\n",
      "Train Epoch: 2444 [34304/60000 (57%)] Loss: -1578.866089\n",
      "Train Epoch: 2444 [45568/60000 (76%)] Loss: -1511.841309\n",
      "Train Epoch: 2444 [56832/60000 (95%)] Loss: -1418.979248\n",
      "    epoch          : 2444\n",
      "    loss           : -1435.0147525765803\n",
      "Train Epoch: 2445 [512/60000 (1%)] Loss: -1276.935059\n",
      "Train Epoch: 2445 [11776/60000 (20%)] Loss: -1445.351807\n",
      "Train Epoch: 2445 [23040/60000 (38%)] Loss: -1234.758301\n",
      "Train Epoch: 2445 [34304/60000 (57%)] Loss: -1494.405151\n",
      "Train Epoch: 2445 [45568/60000 (76%)] Loss: -1402.170898\n",
      "Train Epoch: 2445 [56832/60000 (95%)] Loss: -1596.893311\n",
      "    epoch          : 2445\n",
      "    loss           : -1451.041212178893\n",
      "Train Epoch: 2446 [512/60000 (1%)] Loss: -1299.890991\n",
      "Train Epoch: 2446 [11776/60000 (20%)] Loss: -1445.288330\n",
      "Train Epoch: 2446 [23040/60000 (38%)] Loss: -1333.032837\n",
      "Train Epoch: 2446 [34304/60000 (57%)] Loss: -1262.779297\n",
      "Train Epoch: 2446 [45568/60000 (76%)] Loss: -1450.289551\n",
      "Train Epoch: 2446 [56832/60000 (95%)] Loss: -1230.277466\n",
      "    epoch          : 2446\n",
      "    loss           : -1412.9129949020128\n",
      "Train Epoch: 2447 [512/60000 (1%)] Loss: -1439.941528\n",
      "Train Epoch: 2447 [11776/60000 (20%)] Loss: -1492.309448\n",
      "Train Epoch: 2447 [23040/60000 (38%)] Loss: -1550.786743\n",
      "Train Epoch: 2447 [34304/60000 (57%)] Loss: -1557.741211\n",
      "Train Epoch: 2447 [45568/60000 (76%)] Loss: -1520.291016\n",
      "Train Epoch: 2447 [56832/60000 (95%)] Loss: -1362.700928\n",
      "    epoch          : 2447\n",
      "    loss           : -1444.026159943834\n",
      "Train Epoch: 2448 [512/60000 (1%)] Loss: -1567.325684\n",
      "Train Epoch: 2448 [11776/60000 (20%)] Loss: -1541.313965\n",
      "Train Epoch: 2448 [23040/60000 (38%)] Loss: -1523.408691\n",
      "Train Epoch: 2448 [34304/60000 (57%)] Loss: -1324.343140\n",
      "Train Epoch: 2448 [45568/60000 (76%)] Loss: -1306.287354\n",
      "Train Epoch: 2448 [56832/60000 (95%)] Loss: -1405.881226\n",
      "    epoch          : 2448\n",
      "    loss           : -1437.9445314568989\n",
      "Train Epoch: 2449 [512/60000 (1%)] Loss: -1122.332031\n",
      "Train Epoch: 2449 [11776/60000 (20%)] Loss: -1585.614624\n",
      "Train Epoch: 2449 [23040/60000 (38%)] Loss: -1309.358398\n",
      "Train Epoch: 2449 [34304/60000 (57%)] Loss: -1303.462646\n",
      "Train Epoch: 2449 [45568/60000 (76%)] Loss: -1561.567627\n",
      "Train Epoch: 2449 [56832/60000 (95%)] Loss: -1388.881470\n",
      "    epoch          : 2449\n",
      "    loss           : -1435.0597027277543\n",
      "Train Epoch: 2450 [512/60000 (1%)] Loss: -1408.965332\n",
      "Train Epoch: 2450 [11776/60000 (20%)] Loss: -1506.614380\n",
      "Train Epoch: 2450 [23040/60000 (38%)] Loss: -1562.811523\n",
      "Train Epoch: 2450 [34304/60000 (57%)] Loss: -1427.270508\n",
      "Train Epoch: 2450 [45568/60000 (76%)] Loss: -1240.345093\n",
      "Train Epoch: 2450 [56832/60000 (95%)] Loss: -1575.031738\n",
      "    epoch          : 2450\n",
      "    loss           : -1439.0688266215352\n",
      "Train Epoch: 2451 [512/60000 (1%)] Loss: -1299.424805\n",
      "Train Epoch: 2451 [11776/60000 (20%)] Loss: -1438.279053\n",
      "Train Epoch: 2451 [23040/60000 (38%)] Loss: -1437.376221\n",
      "Train Epoch: 2451 [34304/60000 (57%)] Loss: -1408.126953\n",
      "Train Epoch: 2451 [45568/60000 (76%)] Loss: -1439.632202\n",
      "Train Epoch: 2451 [56832/60000 (95%)] Loss: -1293.251587\n",
      "    epoch          : 2451\n",
      "    loss           : -1435.554801294359\n",
      "Train Epoch: 2452 [512/60000 (1%)] Loss: -1439.204590\n",
      "Train Epoch: 2452 [11776/60000 (20%)] Loss: -1399.294922\n",
      "Train Epoch: 2452 [23040/60000 (38%)] Loss: -1560.928223\n",
      "Train Epoch: 2452 [34304/60000 (57%)] Loss: -1493.740234\n",
      "Train Epoch: 2452 [45568/60000 (76%)] Loss: -1565.414062\n",
      "Train Epoch: 2452 [56832/60000 (95%)] Loss: -1412.034180\n",
      "    epoch          : 2452\n",
      "    loss           : -1426.5779105148747\n",
      "Train Epoch: 2453 [512/60000 (1%)] Loss: -1321.079956\n",
      "Train Epoch: 2453 [11776/60000 (20%)] Loss: -1516.408325\n",
      "Train Epoch: 2453 [23040/60000 (38%)] Loss: -1311.500610\n",
      "Train Epoch: 2453 [34304/60000 (57%)] Loss: -1286.235107\n",
      "Train Epoch: 2453 [45568/60000 (76%)] Loss: -1454.333008\n",
      "Train Epoch: 2453 [56832/60000 (95%)] Loss: -1373.789062\n",
      "    epoch          : 2453\n",
      "    loss           : -1445.3591822392523\n",
      "Train Epoch: 2454 [512/60000 (1%)] Loss: -1601.268677\n",
      "Train Epoch: 2454 [11776/60000 (20%)] Loss: -1565.421265\n",
      "Train Epoch: 2454 [23040/60000 (38%)] Loss: -1502.164795\n",
      "Train Epoch: 2454 [34304/60000 (57%)] Loss: -1405.982788\n",
      "Train Epoch: 2454 [45568/60000 (76%)] Loss: -1454.318481\n",
      "Train Epoch: 2454 [56832/60000 (95%)] Loss: -1464.968628\n",
      "    epoch          : 2454\n",
      "    loss           : -1443.4680779236185\n",
      "Train Epoch: 2455 [512/60000 (1%)] Loss: -1475.604492\n",
      "Train Epoch: 2455 [11776/60000 (20%)] Loss: -1422.791748\n",
      "Train Epoch: 2455 [23040/60000 (38%)] Loss: -1186.095215\n",
      "Train Epoch: 2455 [34304/60000 (57%)] Loss: -1322.404297\n",
      "Train Epoch: 2455 [45568/60000 (76%)] Loss: -1528.557861\n",
      "Train Epoch: 2455 [56832/60000 (95%)] Loss: -1523.018677\n",
      "    epoch          : 2455\n",
      "    loss           : -1436.889085327838\n",
      "Train Epoch: 2456 [512/60000 (1%)] Loss: -1482.891113\n",
      "Train Epoch: 2456 [11776/60000 (20%)] Loss: -1451.794189\n",
      "Train Epoch: 2456 [23040/60000 (38%)] Loss: -1470.888306\n",
      "Train Epoch: 2456 [34304/60000 (57%)] Loss: -1424.337769\n",
      "Train Epoch: 2456 [45568/60000 (76%)] Loss: -1159.479004\n",
      "Train Epoch: 2456 [56832/60000 (95%)] Loss: -1481.919067\n",
      "    epoch          : 2456\n",
      "    loss           : -1433.6938076558085\n",
      "Train Epoch: 2457 [512/60000 (1%)] Loss: -1348.217896\n",
      "Train Epoch: 2457 [11776/60000 (20%)] Loss: -1389.553589\n",
      "Train Epoch: 2457 [23040/60000 (38%)] Loss: -1334.433594\n",
      "Train Epoch: 2457 [34304/60000 (57%)] Loss: -1432.046387\n",
      "Train Epoch: 2457 [45568/60000 (76%)] Loss: -1498.953979\n",
      "Train Epoch: 2457 [56832/60000 (95%)] Loss: -1420.174561\n",
      "    epoch          : 2457\n",
      "    loss           : -1441.7892780196194\n",
      "Train Epoch: 2458 [512/60000 (1%)] Loss: -1507.763306\n",
      "Train Epoch: 2458 [11776/60000 (20%)] Loss: -1545.256592\n",
      "Train Epoch: 2458 [23040/60000 (38%)] Loss: -1385.272583\n",
      "Train Epoch: 2458 [34304/60000 (57%)] Loss: -1306.872314\n",
      "Train Epoch: 2458 [45568/60000 (76%)] Loss: -1509.698730\n",
      "Train Epoch: 2458 [56832/60000 (95%)] Loss: -1341.183472\n",
      "    epoch          : 2458\n",
      "    loss           : -1427.8903994802702\n",
      "Train Epoch: 2459 [512/60000 (1%)] Loss: -1470.455566\n",
      "Train Epoch: 2459 [11776/60000 (20%)] Loss: -1450.973022\n",
      "Train Epoch: 2459 [23040/60000 (38%)] Loss: -1379.568848\n",
      "Train Epoch: 2459 [34304/60000 (57%)] Loss: -1413.501709\n",
      "Train Epoch: 2459 [45568/60000 (76%)] Loss: -1356.001709\n",
      "Train Epoch: 2459 [56832/60000 (95%)] Loss: -1550.338745\n",
      "    epoch          : 2459\n",
      "    loss           : -1433.6725277658236\n",
      "Train Epoch: 2460 [512/60000 (1%)] Loss: -1297.350952\n",
      "Train Epoch: 2460 [11776/60000 (20%)] Loss: -1434.777832\n",
      "Train Epoch: 2460 [23040/60000 (38%)] Loss: -1563.157715\n",
      "Train Epoch: 2460 [34304/60000 (57%)] Loss: -1522.280640\n",
      "Train Epoch: 2460 [45568/60000 (76%)] Loss: -1367.226807\n",
      "Train Epoch: 2460 [56832/60000 (95%)] Loss: -1384.653564\n",
      "    epoch          : 2460\n",
      "    loss           : -1438.0411832130562\n",
      "Train Epoch: 2461 [512/60000 (1%)] Loss: -1433.526489\n",
      "Train Epoch: 2461 [11776/60000 (20%)] Loss: -1398.175293\n",
      "Train Epoch: 2461 [23040/60000 (38%)] Loss: -1574.119629\n",
      "Train Epoch: 2461 [34304/60000 (57%)] Loss: -1321.813477\n",
      "Train Epoch: 2461 [45568/60000 (76%)] Loss: -1251.994995\n",
      "Train Epoch: 2461 [56832/60000 (95%)] Loss: -1381.055664\n",
      "    epoch          : 2461\n",
      "    loss           : -1443.204564326227\n",
      "Train Epoch: 2462 [512/60000 (1%)] Loss: -1293.094482\n",
      "Train Epoch: 2462 [11776/60000 (20%)] Loss: -1329.648804\n",
      "Train Epoch: 2462 [23040/60000 (38%)] Loss: -1453.142334\n",
      "Train Epoch: 2462 [34304/60000 (57%)] Loss: -1424.376099\n",
      "Train Epoch: 2462 [45568/60000 (76%)] Loss: -1472.860474\n",
      "Train Epoch: 2462 [56832/60000 (95%)] Loss: -1530.455811\n",
      "    epoch          : 2462\n",
      "    loss           : -1430.9219374144818\n",
      "Train Epoch: 2463 [512/60000 (1%)] Loss: -1389.894775\n",
      "Train Epoch: 2463 [11776/60000 (20%)] Loss: -1532.535889\n",
      "Train Epoch: 2463 [23040/60000 (38%)] Loss: -1501.845093\n",
      "Train Epoch: 2463 [34304/60000 (57%)] Loss: -1460.856201\n",
      "Train Epoch: 2463 [45568/60000 (76%)] Loss: -1429.319458\n",
      "Train Epoch: 2463 [56832/60000 (95%)] Loss: -1444.115723\n",
      "    epoch          : 2463\n",
      "    loss           : -1449.766227075609\n",
      "Train Epoch: 2464 [512/60000 (1%)] Loss: -1455.891479\n",
      "Train Epoch: 2464 [11776/60000 (20%)] Loss: -1268.299072\n",
      "Train Epoch: 2464 [23040/60000 (38%)] Loss: -1357.598877\n",
      "Train Epoch: 2464 [34304/60000 (57%)] Loss: -1253.213379\n",
      "Train Epoch: 2464 [45568/60000 (76%)] Loss: -1483.413086\n",
      "Train Epoch: 2464 [56832/60000 (95%)] Loss: -1395.087036\n",
      "    epoch          : 2464\n",
      "    loss           : -1429.2042663919049\n",
      "Train Epoch: 2465 [512/60000 (1%)] Loss: -1404.095825\n",
      "Train Epoch: 2465 [11776/60000 (20%)] Loss: -1423.887085\n",
      "Train Epoch: 2465 [23040/60000 (38%)] Loss: -1466.511108\n",
      "Train Epoch: 2465 [34304/60000 (57%)] Loss: -1303.685669\n",
      "Train Epoch: 2465 [45568/60000 (76%)] Loss: -1407.241211\n",
      "Train Epoch: 2465 [56832/60000 (95%)] Loss: -1568.015991\n",
      "    epoch          : 2465\n",
      "    loss           : -1443.8605184608932\n",
      "Train Epoch: 2466 [512/60000 (1%)] Loss: -1527.802246\n",
      "Train Epoch: 2466 [11776/60000 (20%)] Loss: -1395.328125\n",
      "Train Epoch: 2466 [23040/60000 (38%)] Loss: -1417.926147\n",
      "Train Epoch: 2466 [34304/60000 (57%)] Loss: -1424.414062\n",
      "Train Epoch: 2466 [45568/60000 (76%)] Loss: -1364.257690\n",
      "Train Epoch: 2466 [56832/60000 (95%)] Loss: -1411.827515\n",
      "    epoch          : 2466\n",
      "    loss           : -1439.9382120768228\n",
      "Train Epoch: 2467 [512/60000 (1%)] Loss: -1217.570923\n",
      "Train Epoch: 2467 [11776/60000 (20%)] Loss: -1489.340820\n",
      "Train Epoch: 2467 [23040/60000 (38%)] Loss: -1501.342041\n",
      "Train Epoch: 2467 [34304/60000 (57%)] Loss: -1425.800293\n",
      "Train Epoch: 2467 [45568/60000 (76%)] Loss: -1506.364990\n",
      "Train Epoch: 2467 [56832/60000 (95%)] Loss: -1491.285645\n",
      "    epoch          : 2467\n",
      "    loss           : -1443.959084031272\n",
      "Train Epoch: 2468 [512/60000 (1%)] Loss: -1310.575195\n",
      "Train Epoch: 2468 [11776/60000 (20%)] Loss: -1314.015137\n",
      "Train Epoch: 2468 [23040/60000 (38%)] Loss: -1295.568115\n",
      "Train Epoch: 2468 [34304/60000 (57%)] Loss: -1337.563354\n",
      "Train Epoch: 2468 [45568/60000 (76%)] Loss: -1449.917725\n",
      "Train Epoch: 2468 [56832/60000 (95%)] Loss: -1488.610229\n",
      "    epoch          : 2468\n",
      "    loss           : -1422.471752791755\n",
      "Train Epoch: 2469 [512/60000 (1%)] Loss: -1511.857666\n",
      "Train Epoch: 2469 [11776/60000 (20%)] Loss: -1419.691528\n",
      "Train Epoch: 2469 [23040/60000 (38%)] Loss: -1576.389160\n",
      "Train Epoch: 2469 [34304/60000 (57%)] Loss: -1502.744629\n",
      "Train Epoch: 2469 [45568/60000 (76%)] Loss: -1544.684937\n",
      "Train Epoch: 2469 [56832/60000 (95%)] Loss: -1469.304199\n",
      "    epoch          : 2469\n",
      "    loss           : -1443.3431199930483\n",
      "Train Epoch: 2470 [512/60000 (1%)] Loss: -1500.773682\n",
      "Train Epoch: 2470 [11776/60000 (20%)] Loss: -1401.574341\n",
      "Train Epoch: 2470 [23040/60000 (38%)] Loss: -1408.330322\n",
      "Train Epoch: 2470 [34304/60000 (57%)] Loss: -1306.334961\n",
      "Train Epoch: 2470 [45568/60000 (76%)] Loss: -1471.156860\n",
      "Train Epoch: 2470 [56832/60000 (95%)] Loss: -1431.961792\n",
      "    epoch          : 2470\n",
      "    loss           : -1435.2393840207892\n",
      "Train Epoch: 2471 [512/60000 (1%)] Loss: -1193.887695\n",
      "Train Epoch: 2471 [11776/60000 (20%)] Loss: -1407.830688\n",
      "Train Epoch: 2471 [23040/60000 (38%)] Loss: -1414.587158\n",
      "Train Epoch: 2471 [34304/60000 (57%)] Loss: -1409.918701\n",
      "Train Epoch: 2471 [45568/60000 (76%)] Loss: -1444.174072\n",
      "Train Epoch: 2471 [56832/60000 (95%)] Loss: -1413.772217\n",
      "    epoch          : 2471\n",
      "    loss           : -1436.4359641209833\n",
      "Train Epoch: 2472 [512/60000 (1%)] Loss: -1486.173828\n",
      "Train Epoch: 2472 [11776/60000 (20%)] Loss: -1510.065674\n",
      "Train Epoch: 2472 [23040/60000 (38%)] Loss: -1375.009644\n",
      "Train Epoch: 2472 [34304/60000 (57%)] Loss: -1512.868774\n",
      "Train Epoch: 2472 [45568/60000 (76%)] Loss: -1327.906006\n",
      "Train Epoch: 2472 [56832/60000 (95%)] Loss: -1571.691528\n",
      "    epoch          : 2472\n",
      "    loss           : -1449.4990061959304\n",
      "Train Epoch: 2473 [512/60000 (1%)] Loss: -1379.914307\n",
      "Train Epoch: 2473 [11776/60000 (20%)] Loss: -1412.798706\n",
      "Train Epoch: 2473 [23040/60000 (38%)] Loss: -1491.818481\n",
      "Train Epoch: 2473 [34304/60000 (57%)] Loss: -1587.232910\n",
      "Train Epoch: 2473 [45568/60000 (76%)] Loss: -1488.160278\n",
      "Train Epoch: 2473 [56832/60000 (95%)] Loss: -1428.425537\n",
      "    epoch          : 2473\n",
      "    loss           : -1432.728062516552\n",
      "Train Epoch: 2474 [512/60000 (1%)] Loss: -1378.237305\n",
      "Train Epoch: 2474 [11776/60000 (20%)] Loss: -1387.603516\n",
      "Train Epoch: 2474 [23040/60000 (38%)] Loss: -1404.008789\n",
      "Train Epoch: 2474 [34304/60000 (57%)] Loss: -1309.107788\n",
      "Train Epoch: 2474 [45568/60000 (76%)] Loss: -1438.891724\n",
      "Train Epoch: 2474 [56832/60000 (95%)] Loss: -1539.614990\n",
      "    epoch          : 2474\n",
      "    loss           : -1434.35367666126\n",
      "Train Epoch: 2475 [512/60000 (1%)] Loss: -1472.170288\n",
      "Train Epoch: 2475 [11776/60000 (20%)] Loss: -1384.341309\n",
      "Train Epoch: 2475 [23040/60000 (38%)] Loss: -1489.306641\n",
      "Train Epoch: 2475 [34304/60000 (57%)] Loss: -1505.201904\n",
      "Train Epoch: 2475 [45568/60000 (76%)] Loss: -1535.454834\n",
      "Train Epoch: 2475 [56832/60000 (95%)] Loss: -1529.776855\n",
      "    epoch          : 2475\n",
      "    loss           : -1434.1236792957714\n",
      "Train Epoch: 2476 [512/60000 (1%)] Loss: -1552.697021\n",
      "Train Epoch: 2476 [11776/60000 (20%)] Loss: -1435.401001\n",
      "Train Epoch: 2476 [23040/60000 (38%)] Loss: -1493.808472\n",
      "Train Epoch: 2476 [34304/60000 (57%)] Loss: -1484.782959\n",
      "Train Epoch: 2476 [45568/60000 (76%)] Loss: -1274.350586\n",
      "Train Epoch: 2476 [56832/60000 (95%)] Loss: -1475.352905\n",
      "    epoch          : 2476\n",
      "    loss           : -1437.6375725525247\n",
      "Train Epoch: 2477 [512/60000 (1%)] Loss: -1384.193237\n",
      "Train Epoch: 2477 [11776/60000 (20%)] Loss: -1531.485840\n",
      "Train Epoch: 2477 [23040/60000 (38%)] Loss: -1425.729736\n",
      "Train Epoch: 2477 [34304/60000 (57%)] Loss: -1405.861206\n",
      "Train Epoch: 2477 [45568/60000 (76%)] Loss: -1271.867554\n",
      "Train Epoch: 2477 [56832/60000 (95%)] Loss: -1438.808105\n",
      "    epoch          : 2477\n",
      "    loss           : -1418.5094990703344\n",
      "Train Epoch: 2478 [512/60000 (1%)] Loss: -1405.069092\n",
      "Train Epoch: 2478 [11776/60000 (20%)] Loss: -1358.300659\n",
      "Train Epoch: 2478 [23040/60000 (38%)] Loss: -1404.420410\n",
      "Train Epoch: 2478 [34304/60000 (57%)] Loss: -1311.624878\n",
      "Train Epoch: 2478 [45568/60000 (76%)] Loss: -1549.349854\n",
      "Train Epoch: 2478 [56832/60000 (95%)] Loss: -1507.340576\n",
      "    epoch          : 2478\n",
      "    loss           : -1425.2770551261256\n",
      "Train Epoch: 2479 [512/60000 (1%)] Loss: -1447.630005\n",
      "Train Epoch: 2479 [11776/60000 (20%)] Loss: -1520.796631\n",
      "Train Epoch: 2479 [23040/60000 (38%)] Loss: -1376.115845\n",
      "Train Epoch: 2479 [34304/60000 (57%)] Loss: -1410.348633\n",
      "Train Epoch: 2479 [45568/60000 (76%)] Loss: -1276.948608\n",
      "Train Epoch: 2479 [56832/60000 (95%)] Loss: -1472.295532\n",
      "    epoch          : 2479\n",
      "    loss           : -1438.9106962559588\n",
      "Train Epoch: 2480 [512/60000 (1%)] Loss: -1540.492676\n",
      "Train Epoch: 2480 [11776/60000 (20%)] Loss: -1285.197998\n",
      "Train Epoch: 2480 [23040/60000 (38%)] Loss: -1419.708984\n",
      "Train Epoch: 2480 [34304/60000 (57%)] Loss: -1412.470093\n",
      "Train Epoch: 2480 [45568/60000 (76%)] Loss: -1402.340332\n",
      "Train Epoch: 2480 [56832/60000 (95%)] Loss: -1349.380859\n",
      "    epoch          : 2480\n",
      "    loss           : -1429.0897899563029\n",
      "Train Epoch: 2481 [512/60000 (1%)] Loss: -1490.147705\n",
      "Train Epoch: 2481 [11776/60000 (20%)] Loss: -1526.762573\n",
      "Train Epoch: 2481 [23040/60000 (38%)] Loss: -1287.794312\n",
      "Train Epoch: 2481 [34304/60000 (57%)] Loss: -1574.265625\n",
      "Train Epoch: 2481 [45568/60000 (76%)] Loss: -1425.415405\n",
      "Train Epoch: 2481 [56832/60000 (95%)] Loss: -1426.413940\n",
      "    epoch          : 2481\n",
      "    loss           : -1426.0249451028424\n",
      "Train Epoch: 2482 [512/60000 (1%)] Loss: -1510.538818\n",
      "Train Epoch: 2482 [11776/60000 (20%)] Loss: -1484.734375\n",
      "Train Epoch: 2482 [23040/60000 (38%)] Loss: -1518.737061\n",
      "Train Epoch: 2482 [34304/60000 (57%)] Loss: -1331.224121\n",
      "Train Epoch: 2482 [45568/60000 (76%)] Loss: -1468.206055\n",
      "Train Epoch: 2482 [56832/60000 (95%)] Loss: -1388.750610\n",
      "    epoch          : 2482\n",
      "    loss           : -1433.8661767991923\n",
      "Train Epoch: 2483 [512/60000 (1%)] Loss: -1556.715332\n",
      "Train Epoch: 2483 [11776/60000 (20%)] Loss: -1438.759521\n",
      "Train Epoch: 2483 [23040/60000 (38%)] Loss: -1532.566528\n",
      "Train Epoch: 2483 [34304/60000 (57%)] Loss: -1277.173340\n",
      "Train Epoch: 2483 [45568/60000 (76%)] Loss: -1379.874756\n",
      "Train Epoch: 2483 [56832/60000 (95%)] Loss: -1451.210571\n",
      "    epoch          : 2483\n",
      "    loss           : -1434.7689957268494\n",
      "Train Epoch: 2484 [512/60000 (1%)] Loss: -1329.342529\n",
      "Train Epoch: 2484 [11776/60000 (20%)] Loss: -1396.985107\n",
      "Train Epoch: 2484 [23040/60000 (38%)] Loss: -1322.340454\n",
      "Train Epoch: 2484 [34304/60000 (57%)] Loss: -1493.859253\n",
      "Train Epoch: 2484 [45568/60000 (76%)] Loss: -1440.952637\n",
      "Train Epoch: 2484 [56832/60000 (95%)] Loss: -1419.188354\n",
      "    epoch          : 2484\n",
      "    loss           : -1424.3165810795153\n",
      "Train Epoch: 2485 [512/60000 (1%)] Loss: -1381.360229\n",
      "Train Epoch: 2485 [11776/60000 (20%)] Loss: -1395.523071\n",
      "Train Epoch: 2485 [23040/60000 (38%)] Loss: -1229.074341\n",
      "Train Epoch: 2485 [34304/60000 (57%)] Loss: -1416.955444\n",
      "Train Epoch: 2485 [45568/60000 (76%)] Loss: -1405.490234\n",
      "Train Epoch: 2485 [56832/60000 (95%)] Loss: -1366.189331\n",
      "    epoch          : 2485\n",
      "    loss           : -1442.9400769249867\n",
      "Train Epoch: 2486 [512/60000 (1%)] Loss: -1564.688232\n",
      "Train Epoch: 2486 [11776/60000 (20%)] Loss: -1127.927856\n",
      "Train Epoch: 2486 [23040/60000 (38%)] Loss: -1324.434082\n",
      "Train Epoch: 2486 [34304/60000 (57%)] Loss: -1493.706299\n",
      "Train Epoch: 2486 [45568/60000 (76%)] Loss: -1503.114258\n",
      "Train Epoch: 2486 [56832/60000 (95%)] Loss: -1560.550293\n",
      "    epoch          : 2486\n",
      "    loss           : -1436.093792414261\n",
      "Train Epoch: 2487 [512/60000 (1%)] Loss: -1428.916626\n",
      "Train Epoch: 2487 [11776/60000 (20%)] Loss: -1538.866577\n",
      "Train Epoch: 2487 [23040/60000 (38%)] Loss: -1506.593384\n",
      "Train Epoch: 2487 [34304/60000 (57%)] Loss: -1375.217651\n",
      "Train Epoch: 2487 [45568/60000 (76%)] Loss: -1378.456299\n",
      "Train Epoch: 2487 [56832/60000 (95%)] Loss: -1451.121216\n",
      "    epoch          : 2487\n",
      "    loss           : -1432.1953621557204\n",
      "Train Epoch: 2488 [512/60000 (1%)] Loss: -1294.600708\n",
      "Train Epoch: 2488 [11776/60000 (20%)] Loss: -1233.903320\n",
      "Train Epoch: 2488 [23040/60000 (38%)] Loss: -1507.772949\n",
      "Train Epoch: 2488 [34304/60000 (57%)] Loss: -1346.793213\n",
      "Train Epoch: 2488 [45568/60000 (76%)] Loss: -1552.391602\n",
      "Train Epoch: 2488 [56832/60000 (95%)] Loss: -1483.342041\n",
      "    epoch          : 2488\n",
      "    loss           : -1437.4943068337307\n",
      "Train Epoch: 2489 [512/60000 (1%)] Loss: -1361.050049\n",
      "Train Epoch: 2489 [11776/60000 (20%)] Loss: -1363.947998\n",
      "Train Epoch: 2489 [23040/60000 (38%)] Loss: -1450.144165\n",
      "Train Epoch: 2489 [34304/60000 (57%)] Loss: -1546.748535\n",
      "Train Epoch: 2489 [45568/60000 (76%)] Loss: -1441.916260\n",
      "Train Epoch: 2489 [56832/60000 (95%)] Loss: -1576.784424\n",
      "    epoch          : 2489\n",
      "    loss           : -1440.189601402498\n",
      "Train Epoch: 2490 [512/60000 (1%)] Loss: -1353.248413\n",
      "Train Epoch: 2490 [11776/60000 (20%)] Loss: -1576.239990\n",
      "Train Epoch: 2490 [23040/60000 (38%)] Loss: -1536.534668\n",
      "Train Epoch: 2490 [34304/60000 (57%)] Loss: -1470.159058\n",
      "Train Epoch: 2490 [45568/60000 (76%)] Loss: -1429.464600\n",
      "Train Epoch: 2490 [56832/60000 (95%)] Loss: -1545.083008\n",
      "    epoch          : 2490\n",
      "    loss           : -1434.0816060728946\n",
      "Train Epoch: 2491 [512/60000 (1%)] Loss: -1522.358765\n",
      "Train Epoch: 2491 [11776/60000 (20%)] Loss: -1455.812744\n",
      "Train Epoch: 2491 [23040/60000 (38%)] Loss: -1559.715942\n",
      "Train Epoch: 2491 [34304/60000 (57%)] Loss: -1445.671753\n",
      "Train Epoch: 2491 [45568/60000 (76%)] Loss: -1550.679321\n",
      "Train Epoch: 2491 [56832/60000 (95%)] Loss: -1406.883667\n",
      "    epoch          : 2491\n",
      "    loss           : -1441.2363901946503\n",
      "Train Epoch: 2492 [512/60000 (1%)] Loss: -1528.542358\n",
      "Train Epoch: 2492 [11776/60000 (20%)] Loss: -1402.770142\n",
      "Train Epoch: 2492 [23040/60000 (38%)] Loss: -1238.439453\n",
      "Train Epoch: 2492 [34304/60000 (57%)] Loss: -1521.465332\n",
      "Train Epoch: 2492 [45568/60000 (76%)] Loss: -1382.802856\n",
      "Train Epoch: 2492 [56832/60000 (95%)] Loss: -1448.918945\n",
      "    epoch          : 2492\n",
      "    loss           : -1435.3152176161943\n",
      "Train Epoch: 2493 [512/60000 (1%)] Loss: -1385.971191\n",
      "Train Epoch: 2493 [11776/60000 (20%)] Loss: -1243.842285\n",
      "Train Epoch: 2493 [23040/60000 (38%)] Loss: -1491.225952\n",
      "Train Epoch: 2493 [34304/60000 (57%)] Loss: -1406.518555\n",
      "Train Epoch: 2493 [45568/60000 (76%)] Loss: -1472.221680\n",
      "Train Epoch: 2493 [56832/60000 (95%)] Loss: -1512.788086\n",
      "    epoch          : 2493\n",
      "    loss           : -1443.7245028221\n",
      "Train Epoch: 2494 [512/60000 (1%)] Loss: -1444.954346\n",
      "Train Epoch: 2494 [11776/60000 (20%)] Loss: -1488.883911\n",
      "Train Epoch: 2494 [23040/60000 (38%)] Loss: -1437.515137\n",
      "Train Epoch: 2494 [34304/60000 (57%)] Loss: -1315.018311\n",
      "Train Epoch: 2494 [45568/60000 (76%)] Loss: -1349.582275\n",
      "Train Epoch: 2494 [56832/60000 (95%)] Loss: -1451.753662\n",
      "    epoch          : 2494\n",
      "    loss           : -1437.117174396407\n",
      "Train Epoch: 2495 [512/60000 (1%)] Loss: -1237.790283\n",
      "Train Epoch: 2495 [11776/60000 (20%)] Loss: -1377.675659\n",
      "Train Epoch: 2495 [23040/60000 (38%)] Loss: -1373.233154\n",
      "Train Epoch: 2495 [34304/60000 (57%)] Loss: -1291.051880\n",
      "Train Epoch: 2495 [45568/60000 (76%)] Loss: -1565.394043\n",
      "Train Epoch: 2495 [56832/60000 (95%)] Loss: -1412.831299\n",
      "    epoch          : 2495\n",
      "    loss           : -1451.7438823462878\n",
      "Train Epoch: 2496 [512/60000 (1%)] Loss: -1523.568604\n",
      "Train Epoch: 2496 [11776/60000 (20%)] Loss: -1303.569336\n",
      "Train Epoch: 2496 [23040/60000 (38%)] Loss: -1546.162109\n",
      "Train Epoch: 2496 [34304/60000 (57%)] Loss: -1437.651611\n",
      "Train Epoch: 2496 [45568/60000 (76%)] Loss: -1522.176147\n",
      "Train Epoch: 2496 [56832/60000 (95%)] Loss: -1276.683838\n",
      "    epoch          : 2496\n",
      "    loss           : -1443.777676167461\n",
      "Train Epoch: 2497 [512/60000 (1%)] Loss: -1382.006104\n",
      "Train Epoch: 2497 [11776/60000 (20%)] Loss: -1412.085815\n",
      "Train Epoch: 2497 [23040/60000 (38%)] Loss: -1506.115356\n",
      "Train Epoch: 2497 [34304/60000 (57%)] Loss: -1572.415527\n",
      "Train Epoch: 2497 [45568/60000 (76%)] Loss: -1352.231689\n",
      "Train Epoch: 2497 [56832/60000 (95%)] Loss: -1414.252563\n",
      "    epoch          : 2497\n",
      "    loss           : -1454.8312902073403\n",
      "Train Epoch: 2498 [512/60000 (1%)] Loss: -1381.041138\n",
      "Train Epoch: 2498 [11776/60000 (20%)] Loss: -1422.483643\n",
      "Train Epoch: 2498 [23040/60000 (38%)] Loss: -1408.252563\n",
      "Train Epoch: 2498 [34304/60000 (57%)] Loss: -1540.474487\n",
      "Train Epoch: 2498 [45568/60000 (76%)] Loss: -1489.539307\n",
      "Train Epoch: 2498 [56832/60000 (95%)] Loss: -1255.846558\n",
      "    epoch          : 2498\n",
      "    loss           : -1442.7990126097943\n",
      "Train Epoch: 2499 [512/60000 (1%)] Loss: -1540.983154\n",
      "Train Epoch: 2499 [11776/60000 (20%)] Loss: -1405.475586\n",
      "Train Epoch: 2499 [23040/60000 (38%)] Loss: -1478.502686\n",
      "Train Epoch: 2499 [34304/60000 (57%)] Loss: -1527.281738\n",
      "Train Epoch: 2499 [45568/60000 (76%)] Loss: -1417.837158\n",
      "Train Epoch: 2499 [56832/60000 (95%)] Loss: -1526.710083\n",
      "    epoch          : 2499\n",
      "    loss           : -1425.588011315987\n",
      "Train Epoch: 2500 [512/60000 (1%)] Loss: -1446.016846\n",
      "Train Epoch: 2500 [11776/60000 (20%)] Loss: -1569.288818\n",
      "Train Epoch: 2500 [23040/60000 (38%)] Loss: -1381.252686\n",
      "Train Epoch: 2500 [34304/60000 (57%)] Loss: -1555.297241\n",
      "Train Epoch: 2500 [45568/60000 (76%)] Loss: -1333.558594\n",
      "Train Epoch: 2500 [56832/60000 (95%)] Loss: -1282.496582\n",
      "    epoch          : 2500\n",
      "    loss           : -1430.6950787043168\n",
      "Saving checkpoint: saved/models/Mnist_DeepGenerativeOperad/0127_111843/checkpoint-epoch2500.pth ...\n",
      "Train Epoch: 2501 [512/60000 (1%)] Loss: -1492.105469\n",
      "Train Epoch: 2501 [11776/60000 (20%)] Loss: -1453.174561\n",
      "Train Epoch: 2501 [23040/60000 (38%)] Loss: -1401.113647\n",
      "Train Epoch: 2501 [34304/60000 (57%)] Loss: -1446.907593\n",
      "Train Epoch: 2501 [45568/60000 (76%)] Loss: -1461.335815\n",
      "Train Epoch: 2501 [56832/60000 (95%)] Loss: -1577.440918\n",
      "    epoch          : 2501\n",
      "    loss           : -1426.4262698760813\n",
      "Train Epoch: 2502 [512/60000 (1%)] Loss: -1457.822998\n",
      "Train Epoch: 2502 [11776/60000 (20%)] Loss: -1447.446533\n",
      "Train Epoch: 2502 [23040/60000 (38%)] Loss: -1503.724976\n",
      "Train Epoch: 2502 [34304/60000 (57%)] Loss: -1372.755859\n",
      "Train Epoch: 2502 [45568/60000 (76%)] Loss: -1428.983398\n",
      "Train Epoch: 2502 [56832/60000 (95%)] Loss: -1545.566284\n",
      "    epoch          : 2502\n",
      "    loss           : -1443.189417952198\n",
      "Train Epoch: 2503 [512/60000 (1%)] Loss: -1455.151489\n",
      "Train Epoch: 2503 [11776/60000 (20%)] Loss: -1284.904053\n",
      "Train Epoch: 2503 [23040/60000 (38%)] Loss: -1537.862427\n",
      "Train Epoch: 2503 [34304/60000 (57%)] Loss: -1581.060425\n",
      "Train Epoch: 2503 [45568/60000 (76%)] Loss: -1478.026611\n",
      "Train Epoch: 2503 [56832/60000 (95%)] Loss: -1385.974854\n",
      "    epoch          : 2503\n",
      "    loss           : -1444.9469811391023\n",
      "Train Epoch: 2504 [512/60000 (1%)] Loss: -1377.892578\n",
      "Train Epoch: 2504 [11776/60000 (20%)] Loss: -1329.763184\n",
      "Train Epoch: 2504 [23040/60000 (38%)] Loss: -1363.830811\n",
      "Train Epoch: 2504 [34304/60000 (57%)] Loss: -1203.591064\n",
      "Train Epoch: 2504 [45568/60000 (76%)] Loss: -1487.709961\n",
      "Train Epoch: 2504 [56832/60000 (95%)] Loss: -1382.457520\n",
      "    epoch          : 2504\n",
      "    loss           : -1434.2722833493335\n",
      "Train Epoch: 2505 [512/60000 (1%)] Loss: -1322.461060\n",
      "Train Epoch: 2505 [11776/60000 (20%)] Loss: -1243.554321\n",
      "Train Epoch: 2505 [23040/60000 (38%)] Loss: -1532.030884\n",
      "Train Epoch: 2505 [34304/60000 (57%)] Loss: -1513.887329\n",
      "Train Epoch: 2505 [45568/60000 (76%)] Loss: -1418.264648\n",
      "Train Epoch: 2505 [56832/60000 (95%)] Loss: -1261.771240\n",
      "    epoch          : 2505\n",
      "    loss           : -1448.3358795683262\n",
      "Train Epoch: 2506 [512/60000 (1%)] Loss: -1476.497070\n",
      "Train Epoch: 2506 [11776/60000 (20%)] Loss: -1529.705200\n",
      "Train Epoch: 2506 [23040/60000 (38%)] Loss: -1524.920288\n",
      "Train Epoch: 2506 [34304/60000 (57%)] Loss: -1500.631958\n",
      "Train Epoch: 2506 [45568/60000 (76%)] Loss: -1386.428955\n",
      "Train Epoch: 2506 [56832/60000 (95%)] Loss: -1493.573730\n",
      "    epoch          : 2506\n",
      "    loss           : -1449.277906859662\n",
      "Train Epoch: 2507 [512/60000 (1%)] Loss: -1559.248169\n",
      "Train Epoch: 2507 [11776/60000 (20%)] Loss: -1442.463745\n",
      "Train Epoch: 2507 [23040/60000 (38%)] Loss: -1390.884033\n",
      "Train Epoch: 2507 [34304/60000 (57%)] Loss: -1502.827393\n",
      "Train Epoch: 2507 [45568/60000 (76%)] Loss: -1299.447876\n",
      "Train Epoch: 2507 [56832/60000 (95%)] Loss: -1563.342407\n",
      "    epoch          : 2507\n",
      "    loss           : -1451.7721036921787\n",
      "Train Epoch: 2508 [512/60000 (1%)] Loss: -1410.461792\n",
      "Train Epoch: 2508 [11776/60000 (20%)] Loss: -1375.827515\n",
      "Train Epoch: 2508 [23040/60000 (38%)] Loss: -1243.138062\n",
      "Train Epoch: 2508 [34304/60000 (57%)] Loss: -1497.249878\n",
      "Train Epoch: 2508 [45568/60000 (76%)] Loss: -1445.255127\n",
      "Train Epoch: 2508 [56832/60000 (95%)] Loss: -1457.635742\n",
      "    epoch          : 2508\n",
      "    loss           : -1441.1841882393185\n",
      "Train Epoch: 2509 [512/60000 (1%)] Loss: -1533.965820\n",
      "Train Epoch: 2509 [11776/60000 (20%)] Loss: -1460.003418\n",
      "Train Epoch: 2509 [23040/60000 (38%)] Loss: -1540.311768\n",
      "Train Epoch: 2509 [34304/60000 (57%)] Loss: -1352.873535\n",
      "Train Epoch: 2509 [45568/60000 (76%)] Loss: -1438.441528\n",
      "Train Epoch: 2509 [56832/60000 (95%)] Loss: -1521.138550\n",
      "    epoch          : 2509\n",
      "    loss           : -1448.6194195935957\n",
      "Train Epoch: 2510 [512/60000 (1%)] Loss: -1391.871826\n",
      "Train Epoch: 2510 [11776/60000 (20%)] Loss: -1417.341064\n",
      "Train Epoch: 2510 [23040/60000 (38%)] Loss: -1328.405762\n",
      "Train Epoch: 2510 [34304/60000 (57%)] Loss: -1431.770630\n",
      "Train Epoch: 2510 [45568/60000 (76%)] Loss: -1260.165527\n",
      "Train Epoch: 2510 [56832/60000 (95%)] Loss: -1340.851562\n",
      "    epoch          : 2510\n",
      "    loss           : -1455.411408677613\n",
      "Train Epoch: 2511 [512/60000 (1%)] Loss: -1288.771362\n",
      "Train Epoch: 2511 [11776/60000 (20%)] Loss: -1447.501343\n",
      "Train Epoch: 2511 [23040/60000 (38%)] Loss: -1425.365234\n",
      "Train Epoch: 2511 [34304/60000 (57%)] Loss: -1455.281860\n",
      "Train Epoch: 2511 [45568/60000 (76%)] Loss: -1414.521729\n",
      "Train Epoch: 2511 [56832/60000 (95%)] Loss: -1393.054321\n",
      "    epoch          : 2511\n",
      "    loss           : -1446.6452460854741\n",
      "Train Epoch: 2512 [512/60000 (1%)] Loss: -1367.715698\n",
      "Train Epoch: 2512 [11776/60000 (20%)] Loss: -1368.889404\n",
      "Train Epoch: 2512 [23040/60000 (38%)] Loss: -1430.429565\n",
      "Train Epoch: 2512 [34304/60000 (57%)] Loss: -1525.165283\n",
      "Train Epoch: 2512 [45568/60000 (76%)] Loss: -1560.899170\n",
      "Train Epoch: 2512 [56832/60000 (95%)] Loss: -1474.996460\n",
      "    epoch          : 2512\n",
      "    loss           : -1428.2553486797094\n",
      "Train Epoch: 2513 [512/60000 (1%)] Loss: -1530.227539\n",
      "Train Epoch: 2513 [11776/60000 (20%)] Loss: -1257.587891\n",
      "Train Epoch: 2513 [23040/60000 (38%)] Loss: -1478.712524\n",
      "Train Epoch: 2513 [34304/60000 (57%)] Loss: -1435.987061\n",
      "Train Epoch: 2513 [45568/60000 (76%)] Loss: -1500.318848\n",
      "Train Epoch: 2513 [56832/60000 (95%)] Loss: -1434.805176\n",
      "    epoch          : 2513\n",
      "    loss           : -1429.0303627488302\n",
      "Train Epoch: 2514 [512/60000 (1%)] Loss: -1572.135132\n",
      "Train Epoch: 2514 [11776/60000 (20%)] Loss: -1550.574829\n",
      "Train Epoch: 2514 [23040/60000 (38%)] Loss: -1491.049316\n",
      "Train Epoch: 2514 [34304/60000 (57%)] Loss: -1408.004761\n",
      "Train Epoch: 2514 [45568/60000 (76%)] Loss: -1534.442627\n",
      "Train Epoch: 2514 [56832/60000 (95%)] Loss: -1419.932129\n",
      "    epoch          : 2514\n",
      "    loss           : -1452.885094249316\n",
      "Train Epoch: 2515 [512/60000 (1%)] Loss: -1511.658691\n",
      "Train Epoch: 2515 [11776/60000 (20%)] Loss: -1433.799805\n",
      "Train Epoch: 2515 [23040/60000 (38%)] Loss: -1399.224976\n",
      "Train Epoch: 2515 [34304/60000 (57%)] Loss: -1333.810059\n",
      "Train Epoch: 2515 [45568/60000 (76%)] Loss: -1519.957153\n",
      "Train Epoch: 2515 [56832/60000 (95%)] Loss: -1500.240112\n",
      "    epoch          : 2515\n",
      "    loss           : -1445.516584665762\n",
      "Train Epoch: 2516 [512/60000 (1%)] Loss: -1161.687622\n",
      "Train Epoch: 2516 [11776/60000 (20%)] Loss: -1254.657104\n",
      "Train Epoch: 2516 [23040/60000 (38%)] Loss: -1540.609619\n",
      "Train Epoch: 2516 [34304/60000 (57%)] Loss: -1456.781494\n",
      "Train Epoch: 2516 [45568/60000 (76%)] Loss: -1460.730957\n",
      "Train Epoch: 2516 [56832/60000 (95%)] Loss: -1507.508301\n",
      "    epoch          : 2516\n",
      "    loss           : -1440.6709425759182\n",
      "Train Epoch: 2517 [512/60000 (1%)] Loss: -1313.178955\n",
      "Train Epoch: 2517 [11776/60000 (20%)] Loss: -1477.952637\n",
      "Train Epoch: 2517 [23040/60000 (38%)] Loss: -1362.418213\n",
      "Train Epoch: 2517 [34304/60000 (57%)] Loss: -1325.140869\n",
      "Train Epoch: 2517 [45568/60000 (76%)] Loss: -1504.113647\n",
      "Train Epoch: 2517 [56832/60000 (95%)] Loss: -1465.756836\n",
      "    epoch          : 2517\n",
      "    loss           : -1442.3206304345426\n",
      "Train Epoch: 2518 [512/60000 (1%)] Loss: -1331.310181\n",
      "Train Epoch: 2518 [11776/60000 (20%)] Loss: -1460.234131\n",
      "Train Epoch: 2518 [23040/60000 (38%)] Loss: -1322.378662\n",
      "Train Epoch: 2518 [34304/60000 (57%)] Loss: -1384.788452\n",
      "Train Epoch: 2518 [45568/60000 (76%)] Loss: -1479.786011\n",
      "Train Epoch: 2518 [56832/60000 (95%)] Loss: -1513.296021\n",
      "    epoch          : 2518\n",
      "    loss           : -1439.101640087063\n",
      "Train Epoch: 2519 [512/60000 (1%)] Loss: -1376.271729\n",
      "Train Epoch: 2519 [11776/60000 (20%)] Loss: -1382.907227\n",
      "Train Epoch: 2519 [23040/60000 (38%)] Loss: -1555.746948\n",
      "Train Epoch: 2519 [34304/60000 (57%)] Loss: -1313.509399\n",
      "Train Epoch: 2519 [45568/60000 (76%)] Loss: -1424.714111\n",
      "Train Epoch: 2519 [56832/60000 (95%)] Loss: -1492.179199\n",
      "    epoch          : 2519\n",
      "    loss           : -1437.5585361631577\n",
      "Train Epoch: 2520 [512/60000 (1%)] Loss: -1407.855957\n",
      "Train Epoch: 2520 [11776/60000 (20%)] Loss: -1360.440674\n",
      "Train Epoch: 2520 [23040/60000 (38%)] Loss: -1515.898804\n",
      "Train Epoch: 2520 [34304/60000 (57%)] Loss: -1425.044800\n",
      "Train Epoch: 2520 [45568/60000 (76%)] Loss: -1325.165771\n",
      "Train Epoch: 2520 [56832/60000 (95%)] Loss: -1562.206543\n",
      "    epoch          : 2520\n",
      "    loss           : -1427.3507459392656\n",
      "Train Epoch: 2521 [512/60000 (1%)] Loss: -1469.296631\n",
      "Train Epoch: 2521 [11776/60000 (20%)] Loss: -1340.969238\n",
      "Train Epoch: 2521 [23040/60000 (38%)] Loss: -1420.680908\n",
      "Train Epoch: 2521 [34304/60000 (57%)] Loss: -1516.294434\n",
      "Train Epoch: 2521 [45568/60000 (76%)] Loss: -1450.167480\n",
      "Train Epoch: 2521 [56832/60000 (95%)] Loss: -1543.233643\n",
      "    epoch          : 2521\n",
      "    loss           : -1442.7713267870542\n",
      "Train Epoch: 2522 [512/60000 (1%)] Loss: -1532.044189\n",
      "Train Epoch: 2522 [11776/60000 (20%)] Loss: -1417.494385\n",
      "Train Epoch: 2522 [23040/60000 (38%)] Loss: -1458.567139\n",
      "Train Epoch: 2522 [34304/60000 (57%)] Loss: -1355.354980\n",
      "Train Epoch: 2522 [45568/60000 (76%)] Loss: -1512.119629\n",
      "Train Epoch: 2522 [56832/60000 (95%)] Loss: -1370.776855\n",
      "    epoch          : 2522\n",
      "    loss           : -1429.8640826381534\n",
      "Train Epoch: 2523 [512/60000 (1%)] Loss: -1305.204834\n",
      "Train Epoch: 2523 [11776/60000 (20%)] Loss: -1291.740967\n",
      "Train Epoch: 2523 [23040/60000 (38%)] Loss: -1517.928833\n",
      "Train Epoch: 2523 [34304/60000 (57%)] Loss: -1304.857056\n",
      "Train Epoch: 2523 [45568/60000 (76%)] Loss: -1456.822510\n",
      "Train Epoch: 2523 [56832/60000 (95%)] Loss: -1384.843384\n",
      "    epoch          : 2523\n",
      "    loss           : -1434.8416865289548\n",
      "Train Epoch: 2524 [512/60000 (1%)] Loss: -1582.073730\n",
      "Train Epoch: 2524 [11776/60000 (20%)] Loss: -1408.803223\n",
      "Train Epoch: 2524 [23040/60000 (38%)] Loss: -1483.060669\n",
      "Train Epoch: 2524 [34304/60000 (57%)] Loss: -1449.871582\n",
      "Train Epoch: 2524 [45568/60000 (76%)] Loss: -1190.460693\n",
      "Train Epoch: 2524 [56832/60000 (95%)] Loss: -1505.934326\n",
      "    epoch          : 2524\n",
      "    loss           : -1439.5696614583335\n",
      "Train Epoch: 2525 [512/60000 (1%)] Loss: -1401.633301\n",
      "Train Epoch: 2525 [11776/60000 (20%)] Loss: -1503.568115\n",
      "Train Epoch: 2525 [23040/60000 (38%)] Loss: -1356.400757\n",
      "Train Epoch: 2525 [34304/60000 (57%)] Loss: -1496.451782\n",
      "Train Epoch: 2525 [45568/60000 (76%)] Loss: -1492.134155\n",
      "Train Epoch: 2525 [56832/60000 (95%)] Loss: -1368.671509\n",
      "    epoch          : 2525\n",
      "    loss           : -1441.1014314640713\n",
      "Train Epoch: 2526 [512/60000 (1%)] Loss: -1535.133667\n",
      "Train Epoch: 2526 [11776/60000 (20%)] Loss: -1514.398438\n",
      "Train Epoch: 2526 [23040/60000 (38%)] Loss: -1395.643311\n",
      "Train Epoch: 2526 [34304/60000 (57%)] Loss: -1541.074951\n",
      "Train Epoch: 2526 [45568/60000 (76%)] Loss: -1574.972168\n",
      "Train Epoch: 2526 [56832/60000 (95%)] Loss: -1359.140625\n",
      "    epoch          : 2526\n",
      "    loss           : -1435.9974385924259\n",
      "Train Epoch: 2527 [512/60000 (1%)] Loss: -1474.227539\n",
      "Train Epoch: 2527 [11776/60000 (20%)] Loss: -1481.962769\n",
      "Train Epoch: 2527 [23040/60000 (38%)] Loss: -1585.733887\n",
      "Train Epoch: 2527 [34304/60000 (57%)] Loss: -1543.263184\n",
      "Train Epoch: 2527 [45568/60000 (76%)] Loss: -1474.227295\n",
      "Train Epoch: 2527 [56832/60000 (95%)] Loss: -1559.752930\n",
      "    epoch          : 2527\n",
      "    loss           : -1449.876001045529\n",
      "Train Epoch: 2528 [512/60000 (1%)] Loss: -1401.749512\n",
      "Train Epoch: 2528 [11776/60000 (20%)] Loss: -1447.075684\n",
      "Train Epoch: 2528 [23040/60000 (38%)] Loss: -1524.336914\n",
      "Train Epoch: 2528 [34304/60000 (57%)] Loss: -1384.458740\n",
      "Train Epoch: 2528 [45568/60000 (76%)] Loss: -1517.714478\n",
      "Train Epoch: 2528 [56832/60000 (95%)] Loss: -1523.106934\n",
      "    epoch          : 2528\n",
      "    loss           : -1443.2914863198491\n",
      "Train Epoch: 2529 [512/60000 (1%)] Loss: -1510.272949\n",
      "Train Epoch: 2529 [11776/60000 (20%)] Loss: -1559.680542\n",
      "Train Epoch: 2529 [23040/60000 (38%)] Loss: -1364.002319\n",
      "Train Epoch: 2529 [34304/60000 (57%)] Loss: -1523.930420\n",
      "Train Epoch: 2529 [45568/60000 (76%)] Loss: -1373.074341\n",
      "Train Epoch: 2529 [56832/60000 (95%)] Loss: -1541.681152\n",
      "    epoch          : 2529\n",
      "    loss           : -1453.9941954531912\n",
      "Train Epoch: 2530 [512/60000 (1%)] Loss: -1476.220337\n",
      "Train Epoch: 2530 [11776/60000 (20%)] Loss: -1427.703979\n",
      "Train Epoch: 2530 [23040/60000 (38%)] Loss: -1306.240601\n",
      "Train Epoch: 2530 [34304/60000 (57%)] Loss: -1539.408936\n",
      "Train Epoch: 2530 [45568/60000 (76%)] Loss: -1437.149414\n",
      "Train Epoch: 2530 [56832/60000 (95%)] Loss: -1426.885620\n",
      "    epoch          : 2530\n",
      "    loss           : -1443.6921010852534\n",
      "Train Epoch: 2531 [512/60000 (1%)] Loss: -1421.740479\n",
      "Train Epoch: 2531 [11776/60000 (20%)] Loss: -1500.519043\n",
      "Train Epoch: 2531 [23040/60000 (38%)] Loss: -1511.893555\n",
      "Train Epoch: 2531 [34304/60000 (57%)] Loss: -1527.199829\n",
      "Train Epoch: 2531 [45568/60000 (76%)] Loss: -1575.600586\n",
      "Train Epoch: 2531 [56832/60000 (95%)] Loss: -1533.215088\n",
      "    epoch          : 2531\n",
      "    loss           : -1459.6518030543784\n",
      "Train Epoch: 2532 [512/60000 (1%)] Loss: -1320.061035\n",
      "Train Epoch: 2532 [11776/60000 (20%)] Loss: -1427.930542\n",
      "Train Epoch: 2532 [23040/60000 (38%)] Loss: -1566.756592\n",
      "Train Epoch: 2532 [34304/60000 (57%)] Loss: -1148.602783\n",
      "Train Epoch: 2532 [45568/60000 (76%)] Loss: -1505.072266\n",
      "Train Epoch: 2532 [56832/60000 (95%)] Loss: -1441.891846\n",
      "    epoch          : 2532\n",
      "    loss           : -1454.6409625899319\n",
      "Train Epoch: 2533 [512/60000 (1%)] Loss: -1528.360840\n",
      "Train Epoch: 2533 [11776/60000 (20%)] Loss: -1459.175171\n",
      "Train Epoch: 2533 [23040/60000 (38%)] Loss: -1497.995850\n",
      "Train Epoch: 2533 [34304/60000 (57%)] Loss: -1440.850098\n",
      "Train Epoch: 2533 [45568/60000 (76%)] Loss: -1546.977905\n",
      "Train Epoch: 2533 [56832/60000 (95%)] Loss: -1541.875977\n",
      "    epoch          : 2533\n",
      "    loss           : -1453.518447100106\n",
      "Train Epoch: 2534 [512/60000 (1%)] Loss: -1487.035400\n",
      "Train Epoch: 2534 [11776/60000 (20%)] Loss: -1386.659302\n",
      "Train Epoch: 2534 [23040/60000 (38%)] Loss: -1399.164917\n",
      "Train Epoch: 2534 [34304/60000 (57%)] Loss: -1467.383179\n",
      "Train Epoch: 2534 [45568/60000 (76%)] Loss: -1316.856323\n",
      "Train Epoch: 2534 [56832/60000 (95%)] Loss: -1481.792603\n",
      "    epoch          : 2534\n",
      "    loss           : -1447.102281818282\n",
      "Train Epoch: 2535 [512/60000 (1%)] Loss: -1501.301758\n",
      "Train Epoch: 2535 [11776/60000 (20%)] Loss: -1425.270874\n",
      "Train Epoch: 2535 [23040/60000 (38%)] Loss: -1484.115723\n",
      "Train Epoch: 2535 [34304/60000 (57%)] Loss: -1231.463867\n",
      "Train Epoch: 2535 [45568/60000 (76%)] Loss: -1443.007812\n",
      "Train Epoch: 2535 [56832/60000 (95%)] Loss: -1448.487793\n",
      "    epoch          : 2535\n",
      "    loss           : -1445.9553581280898\n",
      "Train Epoch: 2536 [512/60000 (1%)] Loss: -1545.776978\n",
      "Train Epoch: 2536 [11776/60000 (20%)] Loss: -1291.287842\n",
      "Train Epoch: 2536 [23040/60000 (38%)] Loss: -1390.855469\n",
      "Train Epoch: 2536 [34304/60000 (57%)] Loss: -1393.176147\n",
      "Train Epoch: 2536 [45568/60000 (76%)] Loss: -1582.344971\n",
      "Train Epoch: 2536 [56832/60000 (95%)] Loss: -1516.993164\n",
      "    epoch          : 2536\n",
      "    loss           : -1444.3872535834878\n",
      "Train Epoch: 2537 [512/60000 (1%)] Loss: -1411.031616\n",
      "Train Epoch: 2537 [11776/60000 (20%)] Loss: -1431.124390\n",
      "Train Epoch: 2537 [23040/60000 (38%)] Loss: -1361.595947\n",
      "Train Epoch: 2537 [34304/60000 (57%)] Loss: -1275.696289\n",
      "Train Epoch: 2537 [45568/60000 (76%)] Loss: -1395.703857\n",
      "Train Epoch: 2537 [56832/60000 (95%)] Loss: -1380.993164\n",
      "    epoch          : 2537\n",
      "    loss           : -1448.7651080977444\n",
      "Train Epoch: 2538 [512/60000 (1%)] Loss: -1528.525146\n",
      "Train Epoch: 2538 [11776/60000 (20%)] Loss: -1340.634766\n",
      "Train Epoch: 2538 [23040/60000 (38%)] Loss: -1382.018799\n",
      "Train Epoch: 2538 [34304/60000 (57%)] Loss: -1458.661255\n",
      "Train Epoch: 2538 [45568/60000 (76%)] Loss: -1535.465210\n",
      "Train Epoch: 2538 [56832/60000 (95%)] Loss: -1474.831177\n",
      "    epoch          : 2538\n",
      "    loss           : -1447.8865963348562\n",
      "Train Epoch: 2539 [512/60000 (1%)] Loss: -1556.460083\n",
      "Train Epoch: 2539 [11776/60000 (20%)] Loss: -1294.397705\n",
      "Train Epoch: 2539 [23040/60000 (38%)] Loss: -1371.951538\n",
      "Train Epoch: 2539 [34304/60000 (57%)] Loss: -1327.774902\n",
      "Train Epoch: 2539 [45568/60000 (76%)] Loss: -1364.438110\n",
      "Train Epoch: 2539 [56832/60000 (95%)] Loss: -1295.215332\n",
      "    epoch          : 2539\n",
      "    loss           : -1441.7537038339733\n",
      "Train Epoch: 2540 [512/60000 (1%)] Loss: -1513.665649\n",
      "Train Epoch: 2540 [11776/60000 (20%)] Loss: -1310.245605\n",
      "Train Epoch: 2540 [23040/60000 (38%)] Loss: -1559.172852\n",
      "Train Epoch: 2540 [34304/60000 (57%)] Loss: -1490.834473\n",
      "Train Epoch: 2540 [45568/60000 (76%)] Loss: -1559.864014\n",
      "Train Epoch: 2540 [56832/60000 (95%)] Loss: -1443.743164\n",
      "    epoch          : 2540\n",
      "    loss           : -1452.3572453213276\n",
      "Train Epoch: 2541 [512/60000 (1%)] Loss: -1376.492920\n",
      "Train Epoch: 2541 [11776/60000 (20%)] Loss: -1557.991943\n",
      "Train Epoch: 2541 [23040/60000 (38%)] Loss: -1402.270020\n",
      "Train Epoch: 2541 [34304/60000 (57%)] Loss: -1439.247314\n",
      "Train Epoch: 2541 [45568/60000 (76%)] Loss: -1579.865479\n",
      "Train Epoch: 2541 [56832/60000 (95%)] Loss: -1499.492188\n",
      "    epoch          : 2541\n",
      "    loss           : -1453.4777973412122\n",
      "Train Epoch: 2542 [512/60000 (1%)] Loss: -1259.149902\n",
      "Train Epoch: 2542 [11776/60000 (20%)] Loss: -1377.493896\n",
      "Train Epoch: 2542 [23040/60000 (38%)] Loss: -1445.110352\n",
      "Train Epoch: 2542 [34304/60000 (57%)] Loss: -1517.495239\n",
      "Train Epoch: 2542 [45568/60000 (76%)] Loss: -1407.249634\n",
      "Train Epoch: 2542 [56832/60000 (95%)] Loss: -1341.516846\n",
      "    epoch          : 2542\n",
      "    loss           : -1441.752251748985\n",
      "Train Epoch: 2543 [512/60000 (1%)] Loss: -1505.264893\n",
      "Train Epoch: 2543 [11776/60000 (20%)] Loss: -1417.087036\n",
      "Train Epoch: 2543 [23040/60000 (38%)] Loss: -1322.136475\n",
      "Train Epoch: 2543 [34304/60000 (57%)] Loss: -1494.135498\n",
      "Train Epoch: 2543 [45568/60000 (76%)] Loss: -1503.342285\n",
      "Train Epoch: 2543 [56832/60000 (95%)] Loss: -1475.824341\n",
      "    epoch          : 2543\n",
      "    loss           : -1450.5867071636653\n",
      "Train Epoch: 2544 [512/60000 (1%)] Loss: -1480.399170\n",
      "Train Epoch: 2544 [11776/60000 (20%)] Loss: -1500.687378\n",
      "Train Epoch: 2544 [23040/60000 (38%)] Loss: -1568.367798\n",
      "Train Epoch: 2544 [34304/60000 (57%)] Loss: -1378.962646\n",
      "Train Epoch: 2544 [45568/60000 (76%)] Loss: -1233.570312\n",
      "Train Epoch: 2544 [56832/60000 (95%)] Loss: -1409.098755\n",
      "    epoch          : 2544\n",
      "    loss           : -1433.7591032038974\n",
      "Train Epoch: 2545 [512/60000 (1%)] Loss: -1489.278564\n",
      "Train Epoch: 2545 [11776/60000 (20%)] Loss: -1458.565063\n",
      "Train Epoch: 2545 [23040/60000 (38%)] Loss: -1444.117188\n",
      "Train Epoch: 2545 [34304/60000 (57%)] Loss: -1518.522217\n",
      "Train Epoch: 2545 [45568/60000 (76%)] Loss: -1375.521240\n",
      "Train Epoch: 2545 [56832/60000 (95%)] Loss: -1455.144409\n",
      "    epoch          : 2545\n",
      "    loss           : -1452.747490661966\n",
      "Train Epoch: 2546 [512/60000 (1%)] Loss: -1494.531616\n",
      "Train Epoch: 2546 [11776/60000 (20%)] Loss: -1572.114014\n",
      "Train Epoch: 2546 [23040/60000 (38%)] Loss: -1436.005859\n",
      "Train Epoch: 2546 [34304/60000 (57%)] Loss: -1443.916504\n",
      "Train Epoch: 2546 [45568/60000 (76%)] Loss: -1446.179443\n",
      "Train Epoch: 2546 [56832/60000 (95%)] Loss: -1447.551025\n",
      "    epoch          : 2546\n",
      "    loss           : -1456.1197509765625\n",
      "Train Epoch: 2547 [512/60000 (1%)] Loss: -1573.404053\n",
      "Train Epoch: 2547 [11776/60000 (20%)] Loss: -1414.550537\n",
      "Train Epoch: 2547 [23040/60000 (38%)] Loss: -1473.287598\n",
      "Train Epoch: 2547 [34304/60000 (57%)] Loss: -1567.356812\n",
      "Train Epoch: 2547 [45568/60000 (76%)] Loss: -1452.224121\n",
      "Train Epoch: 2547 [56832/60000 (95%)] Loss: -1405.286743\n",
      "    epoch          : 2547\n",
      "    loss           : -1450.0411387298066\n",
      "Train Epoch: 2548 [512/60000 (1%)] Loss: -1518.782349\n",
      "Train Epoch: 2548 [11776/60000 (20%)] Loss: -1485.274414\n",
      "Train Epoch: 2548 [23040/60000 (38%)] Loss: -1552.496338\n",
      "Train Epoch: 2548 [34304/60000 (57%)] Loss: -1483.861328\n",
      "Train Epoch: 2548 [45568/60000 (76%)] Loss: -1538.412109\n",
      "Train Epoch: 2548 [56832/60000 (95%)] Loss: -1432.434204\n",
      "    epoch          : 2548\n",
      "    loss           : -1450.735630875927\n",
      "Train Epoch: 2549 [512/60000 (1%)] Loss: -1418.926514\n",
      "Train Epoch: 2549 [11776/60000 (20%)] Loss: -1445.002808\n",
      "Train Epoch: 2549 [23040/60000 (38%)] Loss: -1477.712402\n",
      "Train Epoch: 2549 [34304/60000 (57%)] Loss: -1452.248779\n",
      "Train Epoch: 2549 [45568/60000 (76%)] Loss: -1566.877930\n",
      "Train Epoch: 2549 [56832/60000 (95%)] Loss: -1550.929077\n",
      "    epoch          : 2549\n",
      "    loss           : -1440.2659815556585\n",
      "Train Epoch: 2550 [512/60000 (1%)] Loss: -1482.207520\n",
      "Train Epoch: 2550 [11776/60000 (20%)] Loss: -1356.929810\n",
      "Train Epoch: 2550 [23040/60000 (38%)] Loss: -1512.322876\n",
      "Train Epoch: 2550 [34304/60000 (57%)] Loss: -1477.624756\n",
      "Train Epoch: 2550 [45568/60000 (76%)] Loss: -1504.497681\n",
      "Train Epoch: 2550 [56832/60000 (95%)] Loss: -1496.279053\n",
      "    epoch          : 2550\n",
      "    loss           : -1449.478325967735\n",
      "Train Epoch: 2551 [512/60000 (1%)] Loss: -1376.187744\n",
      "Train Epoch: 2551 [11776/60000 (20%)] Loss: -1265.221558\n",
      "Train Epoch: 2551 [23040/60000 (38%)] Loss: -1547.602173\n",
      "Train Epoch: 2551 [34304/60000 (57%)] Loss: -1487.554199\n",
      "Train Epoch: 2551 [45568/60000 (76%)] Loss: -1511.856689\n",
      "Train Epoch: 2551 [56832/60000 (95%)] Loss: -1440.141113\n",
      "    epoch          : 2551\n",
      "    loss           : -1443.0149318889037\n",
      "Train Epoch: 2552 [512/60000 (1%)] Loss: -1362.777344\n",
      "Train Epoch: 2552 [11776/60000 (20%)] Loss: -1466.270142\n",
      "Train Epoch: 2552 [23040/60000 (38%)] Loss: -1482.266602\n",
      "Train Epoch: 2552 [34304/60000 (57%)] Loss: -1426.568481\n",
      "Train Epoch: 2552 [45568/60000 (76%)] Loss: -1446.340820\n",
      "Train Epoch: 2552 [56832/60000 (95%)] Loss: -1301.047485\n",
      "    epoch          : 2552\n",
      "    loss           : -1431.0103828731903\n",
      "Train Epoch: 2553 [512/60000 (1%)] Loss: -1525.273682\n",
      "Train Epoch: 2553 [11776/60000 (20%)] Loss: -1484.230957\n",
      "Train Epoch: 2553 [23040/60000 (38%)] Loss: -1425.715942\n",
      "Train Epoch: 2553 [34304/60000 (57%)] Loss: -1372.577026\n",
      "Train Epoch: 2553 [45568/60000 (76%)] Loss: -1477.764648\n",
      "Train Epoch: 2553 [56832/60000 (95%)] Loss: -1399.450439\n",
      "    epoch          : 2553\n",
      "    loss           : -1444.9761714612023\n",
      "Train Epoch: 2554 [512/60000 (1%)] Loss: -1556.601685\n",
      "Train Epoch: 2554 [11776/60000 (20%)] Loss: -1429.770752\n",
      "Train Epoch: 2554 [23040/60000 (38%)] Loss: -1448.586670\n",
      "Train Epoch: 2554 [34304/60000 (57%)] Loss: -1396.158447\n",
      "Train Epoch: 2554 [45568/60000 (76%)] Loss: -1582.569214\n",
      "Train Epoch: 2554 [56832/60000 (95%)] Loss: -1562.984741\n",
      "    epoch          : 2554\n",
      "    loss           : -1450.8436937924832\n",
      "Train Epoch: 2555 [512/60000 (1%)] Loss: -1377.569824\n",
      "Train Epoch: 2555 [11776/60000 (20%)] Loss: -1486.302246\n",
      "Train Epoch: 2555 [23040/60000 (38%)] Loss: -1275.003906\n",
      "Train Epoch: 2555 [34304/60000 (57%)] Loss: -1517.239502\n",
      "Train Epoch: 2555 [45568/60000 (76%)] Loss: -1490.773682\n",
      "Train Epoch: 2555 [56832/60000 (95%)] Loss: -1365.940186\n",
      "    epoch          : 2555\n",
      "    loss           : -1446.188549666755\n",
      "Train Epoch: 2556 [512/60000 (1%)] Loss: -1382.887695\n",
      "Train Epoch: 2556 [11776/60000 (20%)] Loss: -1445.066040\n",
      "Train Epoch: 2556 [23040/60000 (38%)] Loss: -1447.648926\n",
      "Train Epoch: 2556 [34304/60000 (57%)] Loss: -1558.754395\n",
      "Train Epoch: 2556 [45568/60000 (76%)] Loss: -1428.522461\n",
      "Train Epoch: 2556 [56832/60000 (95%)] Loss: -1563.464844\n",
      "    epoch          : 2556\n",
      "    loss           : -1437.9283816235215\n",
      "Train Epoch: 2557 [512/60000 (1%)] Loss: -1214.065186\n",
      "Train Epoch: 2557 [11776/60000 (20%)] Loss: -1461.129028\n",
      "Train Epoch: 2557 [23040/60000 (38%)] Loss: -1535.136963\n",
      "Train Epoch: 2557 [34304/60000 (57%)] Loss: -1419.992188\n",
      "Train Epoch: 2557 [45568/60000 (76%)] Loss: -1427.524048\n",
      "Train Epoch: 2557 [56832/60000 (95%)] Loss: -1389.393555\n",
      "    epoch          : 2557\n",
      "    loss           : -1459.1640159477622\n",
      "Train Epoch: 2558 [512/60000 (1%)] Loss: -1443.280273\n",
      "Train Epoch: 2558 [11776/60000 (20%)] Loss: -1484.549316\n",
      "Train Epoch: 2558 [23040/60000 (38%)] Loss: -1413.026733\n",
      "Train Epoch: 2558 [34304/60000 (57%)] Loss: -1403.741455\n",
      "Train Epoch: 2558 [45568/60000 (76%)] Loss: -1549.979492\n",
      "Train Epoch: 2558 [56832/60000 (95%)] Loss: -1328.181885\n",
      "    epoch          : 2558\n",
      "    loss           : -1452.6516885703568\n",
      "Train Epoch: 2559 [512/60000 (1%)] Loss: -1395.121338\n",
      "Train Epoch: 2559 [11776/60000 (20%)] Loss: -1430.916992\n",
      "Train Epoch: 2559 [23040/60000 (38%)] Loss: -1402.704102\n",
      "Train Epoch: 2559 [34304/60000 (57%)] Loss: -1442.202637\n",
      "Train Epoch: 2559 [45568/60000 (76%)] Loss: -1412.444092\n",
      "Train Epoch: 2559 [56832/60000 (95%)] Loss: -1323.164062\n",
      "    epoch          : 2559\n",
      "    loss           : -1437.7257714567884\n",
      "Train Epoch: 2560 [512/60000 (1%)] Loss: -1533.931396\n",
      "Train Epoch: 2560 [11776/60000 (20%)] Loss: -1404.844849\n",
      "Train Epoch: 2560 [23040/60000 (38%)] Loss: -1297.391113\n",
      "Train Epoch: 2560 [34304/60000 (57%)] Loss: -1429.741211\n",
      "Train Epoch: 2560 [45568/60000 (76%)] Loss: -1445.716797\n",
      "Train Epoch: 2560 [56832/60000 (95%)] Loss: -1424.999023\n",
      "    epoch          : 2560\n",
      "    loss           : -1447.2105088745807\n",
      "Train Epoch: 2561 [512/60000 (1%)] Loss: -1504.644897\n",
      "Train Epoch: 2561 [11776/60000 (20%)] Loss: -1459.667969\n",
      "Train Epoch: 2561 [23040/60000 (38%)] Loss: -1546.769043\n",
      "Train Epoch: 2561 [34304/60000 (57%)] Loss: -1447.530273\n",
      "Train Epoch: 2561 [45568/60000 (76%)] Loss: -1513.640747\n",
      "Train Epoch: 2561 [56832/60000 (95%)] Loss: -1322.533691\n",
      "    epoch          : 2561\n",
      "    loss           : -1443.9583774717514\n",
      "Train Epoch: 2562 [512/60000 (1%)] Loss: -1410.640137\n",
      "Train Epoch: 2562 [11776/60000 (20%)] Loss: -1507.272217\n",
      "Train Epoch: 2562 [23040/60000 (38%)] Loss: -1444.065918\n",
      "Train Epoch: 2562 [34304/60000 (57%)] Loss: -1450.791138\n",
      "Train Epoch: 2562 [45568/60000 (76%)] Loss: -1377.140503\n",
      "Train Epoch: 2562 [56832/60000 (95%)] Loss: -1325.757568\n",
      "    epoch          : 2562\n",
      "    loss           : -1432.3791048728813\n",
      "Train Epoch: 2563 [512/60000 (1%)] Loss: -1426.925049\n",
      "Train Epoch: 2563 [11776/60000 (20%)] Loss: -1543.894287\n",
      "Train Epoch: 2563 [23040/60000 (38%)] Loss: -1564.233521\n",
      "Train Epoch: 2563 [34304/60000 (57%)] Loss: -1522.949707\n",
      "Train Epoch: 2563 [45568/60000 (76%)] Loss: -1466.444824\n",
      "Train Epoch: 2563 [56832/60000 (95%)] Loss: -1562.383911\n",
      "    epoch          : 2563\n",
      "    loss           : -1449.8529221701756\n",
      "Train Epoch: 2564 [512/60000 (1%)] Loss: -1469.439941\n",
      "Train Epoch: 2564 [11776/60000 (20%)] Loss: -1414.958740\n",
      "Train Epoch: 2564 [23040/60000 (38%)] Loss: -1513.089722\n",
      "Train Epoch: 2564 [34304/60000 (57%)] Loss: -1433.444092\n",
      "Train Epoch: 2564 [45568/60000 (76%)] Loss: -1432.887573\n",
      "Train Epoch: 2564 [56832/60000 (95%)] Loss: -1243.510864\n",
      "    epoch          : 2564\n",
      "    loss           : -1450.7562893797449\n",
      "Train Epoch: 2565 [512/60000 (1%)] Loss: -1448.009277\n",
      "Train Epoch: 2565 [11776/60000 (20%)] Loss: -1378.272705\n",
      "Train Epoch: 2565 [23040/60000 (38%)] Loss: -1455.230957\n",
      "Train Epoch: 2565 [34304/60000 (57%)] Loss: -1372.119141\n",
      "Train Epoch: 2565 [45568/60000 (76%)] Loss: -1429.933838\n",
      "Train Epoch: 2565 [56832/60000 (95%)] Loss: -1552.466309\n",
      "    epoch          : 2565\n",
      "    loss           : -1441.9927609546035\n",
      "Train Epoch: 2566 [512/60000 (1%)] Loss: -1301.465820\n",
      "Train Epoch: 2566 [11776/60000 (20%)] Loss: -1310.357300\n",
      "Train Epoch: 2566 [23040/60000 (38%)] Loss: -1500.972168\n",
      "Train Epoch: 2566 [34304/60000 (57%)] Loss: -1432.795410\n",
      "Train Epoch: 2566 [45568/60000 (76%)] Loss: -1503.787964\n",
      "Train Epoch: 2566 [56832/60000 (95%)] Loss: -1528.546509\n",
      "    epoch          : 2566\n",
      "    loss           : -1448.1551079184321\n",
      "Train Epoch: 2567 [512/60000 (1%)] Loss: -1502.921631\n",
      "Train Epoch: 2567 [11776/60000 (20%)] Loss: -1469.872681\n",
      "Train Epoch: 2567 [23040/60000 (38%)] Loss: -1434.737427\n",
      "Train Epoch: 2567 [34304/60000 (57%)] Loss: -1428.821167\n",
      "Train Epoch: 2567 [45568/60000 (76%)] Loss: -1451.002808\n",
      "Train Epoch: 2567 [56832/60000 (95%)] Loss: -1409.938721\n",
      "    epoch          : 2567\n",
      "    loss           : -1455.642546400512\n",
      "Train Epoch: 2568 [512/60000 (1%)] Loss: -1555.047363\n",
      "Train Epoch: 2568 [11776/60000 (20%)] Loss: -1521.295898\n",
      "Train Epoch: 2568 [23040/60000 (38%)] Loss: -1414.571167\n",
      "Train Epoch: 2568 [34304/60000 (57%)] Loss: -1482.037354\n",
      "Train Epoch: 2568 [45568/60000 (76%)] Loss: -1566.814453\n",
      "Train Epoch: 2568 [56832/60000 (95%)] Loss: -1408.050049\n",
      "    epoch          : 2568\n",
      "    loss           : -1451.296589479608\n",
      "Train Epoch: 2569 [512/60000 (1%)] Loss: -1446.055664\n",
      "Train Epoch: 2569 [11776/60000 (20%)] Loss: -1489.282959\n",
      "Train Epoch: 2569 [23040/60000 (38%)] Loss: -1556.046631\n",
      "Train Epoch: 2569 [34304/60000 (57%)] Loss: -1438.131104\n",
      "Train Epoch: 2569 [45568/60000 (76%)] Loss: -1428.990723\n",
      "Train Epoch: 2569 [56832/60000 (95%)] Loss: -1278.851685\n",
      "    epoch          : 2569\n",
      "    loss           : -1440.3730313575875\n",
      "Train Epoch: 2570 [512/60000 (1%)] Loss: -1394.994385\n",
      "Train Epoch: 2570 [11776/60000 (20%)] Loss: -1399.053467\n",
      "Train Epoch: 2570 [23040/60000 (38%)] Loss: -1434.580688\n",
      "Train Epoch: 2570 [34304/60000 (57%)] Loss: -1526.341187\n",
      "Train Epoch: 2570 [45568/60000 (76%)] Loss: -1359.512939\n",
      "Train Epoch: 2570 [56832/60000 (95%)] Loss: -1359.031860\n",
      "    epoch          : 2570\n",
      "    loss           : -1439.1206061584128\n",
      "Train Epoch: 2571 [512/60000 (1%)] Loss: -1522.963623\n",
      "Train Epoch: 2571 [11776/60000 (20%)] Loss: -1435.306885\n",
      "Train Epoch: 2571 [23040/60000 (38%)] Loss: -1519.453491\n",
      "Train Epoch: 2571 [34304/60000 (57%)] Loss: -1390.598999\n",
      "Train Epoch: 2571 [45568/60000 (76%)] Loss: -1548.850220\n",
      "Train Epoch: 2571 [56832/60000 (95%)] Loss: -1439.222412\n",
      "    epoch          : 2571\n",
      "    loss           : -1443.662033512094\n",
      "Train Epoch: 2572 [512/60000 (1%)] Loss: -1474.562256\n",
      "Train Epoch: 2572 [11776/60000 (20%)] Loss: -1472.252930\n",
      "Train Epoch: 2572 [23040/60000 (38%)] Loss: -1476.757812\n",
      "Train Epoch: 2572 [34304/60000 (57%)] Loss: -1429.155762\n",
      "Train Epoch: 2572 [45568/60000 (76%)] Loss: -1303.983154\n",
      "Train Epoch: 2572 [56832/60000 (95%)] Loss: -1483.198242\n",
      "    epoch          : 2572\n",
      "    loss           : -1431.6039063189664\n",
      "Train Epoch: 2573 [512/60000 (1%)] Loss: -1424.842896\n",
      "Train Epoch: 2573 [11776/60000 (20%)] Loss: -1350.135742\n",
      "Train Epoch: 2573 [23040/60000 (38%)] Loss: -1580.506348\n",
      "Train Epoch: 2573 [34304/60000 (57%)] Loss: -1559.965576\n",
      "Train Epoch: 2573 [45568/60000 (76%)] Loss: -1497.259277\n",
      "Train Epoch: 2573 [56832/60000 (95%)] Loss: -1301.691284\n",
      "    epoch          : 2573\n",
      "    loss           : -1442.9228846663136\n",
      "Train Epoch: 2574 [512/60000 (1%)] Loss: -1522.916748\n",
      "Train Epoch: 2574 [11776/60000 (20%)] Loss: -1300.704346\n",
      "Train Epoch: 2574 [23040/60000 (38%)] Loss: -1498.933838\n",
      "Train Epoch: 2574 [34304/60000 (57%)] Loss: -1547.338745\n",
      "Train Epoch: 2574 [45568/60000 (76%)] Loss: -1436.003418\n",
      "Train Epoch: 2574 [56832/60000 (95%)] Loss: -1410.631348\n",
      "    epoch          : 2574\n",
      "    loss           : -1439.1820740780588\n",
      "Train Epoch: 2575 [512/60000 (1%)] Loss: -1496.699463\n",
      "Train Epoch: 2575 [11776/60000 (20%)] Loss: -1434.122925\n",
      "Train Epoch: 2575 [23040/60000 (38%)] Loss: -1542.034546\n",
      "Train Epoch: 2575 [34304/60000 (57%)] Loss: -1435.430420\n",
      "Train Epoch: 2575 [45568/60000 (76%)] Loss: -1552.872070\n",
      "Train Epoch: 2575 [56832/60000 (95%)] Loss: -1435.461060\n",
      "    epoch          : 2575\n",
      "    loss           : -1447.919832218838\n",
      "Train Epoch: 2576 [512/60000 (1%)] Loss: -1501.098877\n",
      "Train Epoch: 2576 [11776/60000 (20%)] Loss: -1422.467285\n",
      "Train Epoch: 2576 [23040/60000 (38%)] Loss: -1269.860718\n",
      "Train Epoch: 2576 [34304/60000 (57%)] Loss: -1545.431396\n",
      "Train Epoch: 2576 [45568/60000 (76%)] Loss: -1473.695557\n",
      "Train Epoch: 2576 [56832/60000 (95%)] Loss: -1451.180420\n",
      "    epoch          : 2576\n",
      "    loss           : -1462.0488422630872\n",
      "Train Epoch: 2577 [512/60000 (1%)] Loss: -1446.293945\n",
      "Train Epoch: 2577 [11776/60000 (20%)] Loss: -1517.844727\n",
      "Train Epoch: 2577 [23040/60000 (38%)] Loss: -1354.512329\n",
      "Train Epoch: 2577 [34304/60000 (57%)] Loss: -1252.872559\n",
      "Train Epoch: 2577 [45568/60000 (76%)] Loss: -1342.082520\n",
      "Train Epoch: 2577 [56832/60000 (95%)] Loss: -1348.922363\n",
      "    epoch          : 2577\n",
      "    loss           : -1455.0734008099398\n",
      "Train Epoch: 2578 [512/60000 (1%)] Loss: -1518.929688\n",
      "Train Epoch: 2578 [11776/60000 (20%)] Loss: -1468.737183\n",
      "Train Epoch: 2578 [23040/60000 (38%)] Loss: -1489.547363\n",
      "Train Epoch: 2578 [34304/60000 (57%)] Loss: -1455.539551\n",
      "Train Epoch: 2578 [45568/60000 (76%)] Loss: -1435.469482\n",
      "Train Epoch: 2578 [56832/60000 (95%)] Loss: -1354.025513\n",
      "    epoch          : 2578\n",
      "    loss           : -1439.9124500684145\n",
      "Train Epoch: 2579 [512/60000 (1%)] Loss: -1206.426880\n",
      "Train Epoch: 2579 [11776/60000 (20%)] Loss: -1466.917725\n",
      "Train Epoch: 2579 [23040/60000 (38%)] Loss: -1320.764160\n",
      "Train Epoch: 2579 [34304/60000 (57%)] Loss: -1525.740967\n",
      "Train Epoch: 2579 [45568/60000 (76%)] Loss: -1200.556396\n",
      "Train Epoch: 2579 [56832/60000 (95%)] Loss: -1573.374512\n",
      "    epoch          : 2579\n",
      "    loss           : -1459.2205362266068\n",
      "Train Epoch: 2580 [512/60000 (1%)] Loss: -1535.028076\n",
      "Train Epoch: 2580 [11776/60000 (20%)] Loss: -1442.074829\n",
      "Train Epoch: 2580 [23040/60000 (38%)] Loss: -1440.604004\n",
      "Train Epoch: 2580 [34304/60000 (57%)] Loss: -1436.457031\n",
      "Train Epoch: 2580 [45568/60000 (76%)] Loss: -1480.797852\n",
      "Train Epoch: 2580 [56832/60000 (95%)] Loss: -1286.221313\n",
      "    epoch          : 2580\n",
      "    loss           : -1449.4706179516465\n",
      "Train Epoch: 2581 [512/60000 (1%)] Loss: -1445.896484\n",
      "Train Epoch: 2581 [11776/60000 (20%)] Loss: -1355.806030\n",
      "Train Epoch: 2581 [23040/60000 (38%)] Loss: -1417.511841\n",
      "Train Epoch: 2581 [34304/60000 (57%)] Loss: -1378.902466\n",
      "Train Epoch: 2581 [45568/60000 (76%)] Loss: -1467.677490\n",
      "Train Epoch: 2581 [56832/60000 (95%)] Loss: -1460.568970\n",
      "    epoch          : 2581\n",
      "    loss           : -1447.9954261564267\n",
      "Train Epoch: 2582 [512/60000 (1%)] Loss: -1479.247192\n",
      "Train Epoch: 2582 [11776/60000 (20%)] Loss: -1388.887207\n",
      "Train Epoch: 2582 [23040/60000 (38%)] Loss: -1421.890869\n",
      "Train Epoch: 2582 [34304/60000 (57%)] Loss: -1303.581787\n",
      "Train Epoch: 2582 [45568/60000 (76%)] Loss: -1250.151611\n",
      "Train Epoch: 2582 [56832/60000 (95%)] Loss: -1442.952515\n",
      "    epoch          : 2582\n",
      "    loss           : -1462.0871182026835\n",
      "Train Epoch: 2583 [512/60000 (1%)] Loss: -1338.455078\n",
      "Train Epoch: 2583 [11776/60000 (20%)] Loss: -1541.879272\n",
      "Train Epoch: 2583 [23040/60000 (38%)] Loss: -1343.355713\n",
      "Train Epoch: 2583 [34304/60000 (57%)] Loss: -1305.269043\n",
      "Train Epoch: 2583 [45568/60000 (76%)] Loss: -1387.665771\n",
      "Train Epoch: 2583 [56832/60000 (95%)] Loss: -1417.517822\n",
      "    epoch          : 2583\n",
      "    loss           : -1439.3558404782398\n",
      "Train Epoch: 2584 [512/60000 (1%)] Loss: -1437.205933\n",
      "Train Epoch: 2584 [11776/60000 (20%)] Loss: -1356.495483\n",
      "Train Epoch: 2584 [23040/60000 (38%)] Loss: -1525.523438\n",
      "Train Epoch: 2584 [34304/60000 (57%)] Loss: -1550.608887\n",
      "Train Epoch: 2584 [45568/60000 (76%)] Loss: -1324.550781\n",
      "Train Epoch: 2584 [56832/60000 (95%)] Loss: -1484.311279\n",
      "    epoch          : 2584\n",
      "    loss           : -1450.3019788494219\n",
      "Train Epoch: 2585 [512/60000 (1%)] Loss: -1520.926514\n",
      "Train Epoch: 2585 [11776/60000 (20%)] Loss: -1384.464844\n",
      "Train Epoch: 2585 [23040/60000 (38%)] Loss: -1366.226807\n",
      "Train Epoch: 2585 [34304/60000 (57%)] Loss: -1349.850464\n",
      "Train Epoch: 2585 [45568/60000 (76%)] Loss: -1351.146606\n",
      "Train Epoch: 2585 [56832/60000 (95%)] Loss: -1514.588135\n",
      "    epoch          : 2585\n",
      "    loss           : -1445.3804845432778\n",
      "Train Epoch: 2586 [512/60000 (1%)] Loss: -1454.217163\n",
      "Train Epoch: 2586 [11776/60000 (20%)] Loss: -1455.418091\n",
      "Train Epoch: 2586 [23040/60000 (38%)] Loss: -1538.666138\n",
      "Train Epoch: 2586 [34304/60000 (57%)] Loss: -1470.800659\n",
      "Train Epoch: 2586 [45568/60000 (76%)] Loss: -1368.299805\n",
      "Train Epoch: 2586 [56832/60000 (95%)] Loss: -1540.289795\n",
      "    epoch          : 2586\n",
      "    loss           : -1438.6892789851474\n",
      "Train Epoch: 2587 [512/60000 (1%)] Loss: -1548.402466\n",
      "Train Epoch: 2587 [11776/60000 (20%)] Loss: -1447.003906\n",
      "Train Epoch: 2587 [23040/60000 (38%)] Loss: -1484.239868\n",
      "Train Epoch: 2587 [34304/60000 (57%)] Loss: -1454.203369\n",
      "Train Epoch: 2587 [45568/60000 (76%)] Loss: -1466.738281\n",
      "Train Epoch: 2587 [56832/60000 (95%)] Loss: -1448.933350\n",
      "    epoch          : 2587\n",
      "    loss           : -1445.2186355159781\n",
      "Train Epoch: 2588 [512/60000 (1%)] Loss: -1375.733398\n",
      "Train Epoch: 2588 [11776/60000 (20%)] Loss: -1429.799805\n",
      "Train Epoch: 2588 [23040/60000 (38%)] Loss: -1514.891968\n",
      "Train Epoch: 2588 [34304/60000 (57%)] Loss: -1452.109863\n",
      "Train Epoch: 2588 [45568/60000 (76%)] Loss: -1520.937988\n",
      "Train Epoch: 2588 [56832/60000 (95%)] Loss: -1318.267334\n",
      "    epoch          : 2588\n",
      "    loss           : -1449.017132947674\n",
      "Train Epoch: 2589 [512/60000 (1%)] Loss: -1339.302246\n",
      "Train Epoch: 2589 [11776/60000 (20%)] Loss: -1523.970581\n",
      "Train Epoch: 2589 [23040/60000 (38%)] Loss: -1429.617920\n",
      "Train Epoch: 2589 [34304/60000 (57%)] Loss: -1393.411865\n",
      "Train Epoch: 2589 [45568/60000 (76%)] Loss: -1386.196655\n",
      "Train Epoch: 2589 [56832/60000 (95%)] Loss: -1313.420410\n",
      "    epoch          : 2589\n",
      "    loss           : -1439.3387696002164\n",
      "Train Epoch: 2590 [512/60000 (1%)] Loss: -1363.410156\n",
      "Train Epoch: 2590 [11776/60000 (20%)] Loss: -1549.186279\n",
      "Train Epoch: 2590 [23040/60000 (38%)] Loss: -1508.748291\n",
      "Train Epoch: 2590 [34304/60000 (57%)] Loss: -1507.224609\n",
      "Train Epoch: 2590 [45568/60000 (76%)] Loss: -1486.373779\n",
      "Train Epoch: 2590 [56832/60000 (95%)] Loss: -1319.673950\n",
      "    epoch          : 2590\n",
      "    loss           : -1453.021042990819\n",
      "Train Epoch: 2591 [512/60000 (1%)] Loss: -1491.473389\n",
      "Train Epoch: 2591 [11776/60000 (20%)] Loss: -1411.680664\n",
      "Train Epoch: 2591 [23040/60000 (38%)] Loss: -1482.027954\n",
      "Train Epoch: 2591 [34304/60000 (57%)] Loss: -1545.828857\n",
      "Train Epoch: 2591 [45568/60000 (76%)] Loss: -1543.567383\n",
      "Train Epoch: 2591 [56832/60000 (95%)] Loss: -1371.724609\n",
      "    epoch          : 2591\n",
      "    loss           : -1453.207525738215\n",
      "Train Epoch: 2592 [512/60000 (1%)] Loss: -1512.099487\n",
      "Train Epoch: 2592 [11776/60000 (20%)] Loss: -1443.594971\n",
      "Train Epoch: 2592 [23040/60000 (38%)] Loss: -1354.569580\n",
      "Train Epoch: 2592 [34304/60000 (57%)] Loss: -1154.022217\n",
      "Train Epoch: 2592 [45568/60000 (76%)] Loss: -1532.983887\n",
      "Train Epoch: 2592 [56832/60000 (95%)] Loss: -1453.595703\n",
      "    epoch          : 2592\n",
      "    loss           : -1441.892781575521\n",
      "Train Epoch: 2593 [512/60000 (1%)] Loss: -1392.974976\n",
      "Train Epoch: 2593 [11776/60000 (20%)] Loss: -1390.122681\n",
      "Train Epoch: 2593 [23040/60000 (38%)] Loss: -1254.652100\n",
      "Train Epoch: 2593 [34304/60000 (57%)] Loss: -1498.674316\n",
      "Train Epoch: 2593 [45568/60000 (76%)] Loss: -1466.841919\n",
      "Train Epoch: 2593 [56832/60000 (95%)] Loss: -1492.685425\n",
      "    epoch          : 2593\n",
      "    loss           : -1456.2426750915872\n",
      "Train Epoch: 2594 [512/60000 (1%)] Loss: -1449.082642\n",
      "Train Epoch: 2594 [11776/60000 (20%)] Loss: -1540.884766\n",
      "Train Epoch: 2594 [23040/60000 (38%)] Loss: -1451.623047\n",
      "Train Epoch: 2594 [34304/60000 (57%)] Loss: -1419.941162\n",
      "Train Epoch: 2594 [45568/60000 (76%)] Loss: -1534.725830\n",
      "Train Epoch: 2594 [56832/60000 (95%)] Loss: -1441.484985\n",
      "    epoch          : 2594\n",
      "    loss           : -1436.9311502747616\n",
      "Train Epoch: 2595 [512/60000 (1%)] Loss: -1385.791992\n",
      "Train Epoch: 2595 [11776/60000 (20%)] Loss: -1248.560181\n",
      "Train Epoch: 2595 [23040/60000 (38%)] Loss: -1431.008301\n",
      "Train Epoch: 2595 [34304/60000 (57%)] Loss: -1184.443115\n",
      "Train Epoch: 2595 [45568/60000 (76%)] Loss: -1399.947388\n",
      "Train Epoch: 2595 [56832/60000 (95%)] Loss: -1563.885620\n",
      "    epoch          : 2595\n",
      "    loss           : -1435.374058610302\n",
      "Train Epoch: 2596 [512/60000 (1%)] Loss: -1522.961060\n",
      "Train Epoch: 2596 [11776/60000 (20%)] Loss: -1395.545044\n",
      "Train Epoch: 2596 [23040/60000 (38%)] Loss: -1497.596680\n",
      "Train Epoch: 2596 [34304/60000 (57%)] Loss: -1421.023560\n",
      "Train Epoch: 2596 [45568/60000 (76%)] Loss: -1311.372070\n",
      "Train Epoch: 2596 [56832/60000 (95%)] Loss: -1394.029297\n",
      "    epoch          : 2596\n",
      "    loss           : -1438.744065796588\n",
      "Train Epoch: 2597 [512/60000 (1%)] Loss: -1554.086426\n",
      "Train Epoch: 2597 [11776/60000 (20%)] Loss: -1442.270264\n",
      "Train Epoch: 2597 [23040/60000 (38%)] Loss: -1563.953369\n",
      "Train Epoch: 2597 [34304/60000 (57%)] Loss: -1404.288818\n",
      "Train Epoch: 2597 [45568/60000 (76%)] Loss: -1534.549438\n",
      "Train Epoch: 2597 [56832/60000 (95%)] Loss: -1431.356934\n",
      "    epoch          : 2597\n",
      "    loss           : -1449.1480833581613\n",
      "Train Epoch: 2598 [512/60000 (1%)] Loss: -1123.685669\n",
      "Train Epoch: 2598 [11776/60000 (20%)] Loss: -1374.021362\n",
      "Train Epoch: 2598 [23040/60000 (38%)] Loss: -1487.912231\n",
      "Train Epoch: 2598 [34304/60000 (57%)] Loss: -1380.047974\n",
      "Train Epoch: 2598 [45568/60000 (76%)] Loss: -1273.221924\n",
      "Train Epoch: 2598 [56832/60000 (95%)] Loss: -1406.889404\n",
      "    epoch          : 2598\n",
      "    loss           : -1424.4158214849267\n",
      "Train Epoch: 2599 [512/60000 (1%)] Loss: -1307.133789\n",
      "Train Epoch: 2599 [11776/60000 (20%)] Loss: -1531.650757\n",
      "Train Epoch: 2599 [23040/60000 (38%)] Loss: -1359.489258\n",
      "Train Epoch: 2599 [34304/60000 (57%)] Loss: -1392.045654\n",
      "Train Epoch: 2599 [45568/60000 (76%)] Loss: -1530.892822\n",
      "Train Epoch: 2599 [56832/60000 (95%)] Loss: -1417.643677\n",
      "    epoch          : 2599\n",
      "    loss           : -1440.1711649921656\n",
      "Train Epoch: 2600 [512/60000 (1%)] Loss: -1435.277588\n",
      "Train Epoch: 2600 [11776/60000 (20%)] Loss: -1547.784790\n",
      "Train Epoch: 2600 [23040/60000 (38%)] Loss: -1548.268799\n",
      "Train Epoch: 2600 [34304/60000 (57%)] Loss: -1381.726685\n",
      "Train Epoch: 2600 [45568/60000 (76%)] Loss: -1462.221924\n",
      "Train Epoch: 2600 [56832/60000 (95%)] Loss: -1343.930542\n",
      "    epoch          : 2600\n",
      "    loss           : -1448.6375094483801\n",
      "Saving checkpoint: saved/models/Mnist_DeepGenerativeOperad/0127_111843/checkpoint-epoch2600.pth ...\n",
      "Train Epoch: 2601 [512/60000 (1%)] Loss: -1539.682861\n",
      "Train Epoch: 2601 [11776/60000 (20%)] Loss: -1315.244629\n",
      "Train Epoch: 2601 [23040/60000 (38%)] Loss: -1285.614990\n",
      "Train Epoch: 2601 [34304/60000 (57%)] Loss: -1530.896973\n",
      "Train Epoch: 2601 [45568/60000 (76%)] Loss: -1380.446411\n",
      "Train Epoch: 2601 [56832/60000 (95%)] Loss: -1333.747314\n",
      "    epoch          : 2601\n",
      "    loss           : -1444.488469872771\n",
      "Train Epoch: 2602 [512/60000 (1%)] Loss: -1442.312988\n",
      "Train Epoch: 2602 [11776/60000 (20%)] Loss: -1587.501831\n",
      "Train Epoch: 2602 [23040/60000 (38%)] Loss: -1500.177612\n",
      "Train Epoch: 2602 [34304/60000 (57%)] Loss: -1488.632935\n",
      "Train Epoch: 2602 [45568/60000 (76%)] Loss: -1464.125000\n",
      "Train Epoch: 2602 [56832/60000 (95%)] Loss: -1323.525513\n",
      "    epoch          : 2602\n",
      "    loss           : -1461.1634214584435\n",
      "Train Epoch: 2603 [512/60000 (1%)] Loss: -1436.430664\n",
      "Train Epoch: 2603 [11776/60000 (20%)] Loss: -1497.697144\n",
      "Train Epoch: 2603 [23040/60000 (38%)] Loss: -1455.206909\n",
      "Train Epoch: 2603 [34304/60000 (57%)] Loss: -1378.303589\n",
      "Train Epoch: 2603 [45568/60000 (76%)] Loss: -1405.370361\n",
      "Train Epoch: 2603 [56832/60000 (95%)] Loss: -1259.052490\n",
      "    epoch          : 2603\n",
      "    loss           : -1449.8027481682557\n",
      "Train Epoch: 2604 [512/60000 (1%)] Loss: -1375.876221\n",
      "Train Epoch: 2604 [11776/60000 (20%)] Loss: -1419.049072\n",
      "Train Epoch: 2604 [23040/60000 (38%)] Loss: -1462.311401\n",
      "Train Epoch: 2604 [34304/60000 (57%)] Loss: -1408.695679\n",
      "Train Epoch: 2604 [45568/60000 (76%)] Loss: -1456.108398\n",
      "Train Epoch: 2604 [56832/60000 (95%)] Loss: -1511.789795\n",
      "    epoch          : 2604\n",
      "    loss           : -1451.1351935607565\n",
      "Train Epoch: 2605 [512/60000 (1%)] Loss: -1575.113647\n",
      "Train Epoch: 2605 [11776/60000 (20%)] Loss: -1420.354004\n",
      "Train Epoch: 2605 [23040/60000 (38%)] Loss: -1420.541260\n",
      "Train Epoch: 2605 [34304/60000 (57%)] Loss: -1353.558350\n",
      "Train Epoch: 2605 [45568/60000 (76%)] Loss: -1332.565063\n",
      "Train Epoch: 2605 [56832/60000 (95%)] Loss: -1501.974731\n",
      "    epoch          : 2605\n",
      "    loss           : -1445.6571938035177\n",
      "Train Epoch: 2606 [512/60000 (1%)] Loss: -1533.976807\n",
      "Train Epoch: 2606 [11776/60000 (20%)] Loss: -1560.443359\n",
      "Train Epoch: 2606 [23040/60000 (38%)] Loss: -1547.871094\n",
      "Train Epoch: 2606 [34304/60000 (57%)] Loss: -1474.039185\n",
      "Train Epoch: 2606 [45568/60000 (76%)] Loss: -1493.175171\n",
      "Train Epoch: 2606 [56832/60000 (95%)] Loss: -1340.257568\n",
      "    epoch          : 2606\n",
      "    loss           : -1448.819654906537\n",
      "Train Epoch: 2607 [512/60000 (1%)] Loss: -1280.591797\n",
      "Train Epoch: 2607 [11776/60000 (20%)] Loss: -1538.775513\n",
      "Train Epoch: 2607 [23040/60000 (38%)] Loss: -1534.019409\n",
      "Train Epoch: 2607 [34304/60000 (57%)] Loss: -1522.708984\n",
      "Train Epoch: 2607 [45568/60000 (76%)] Loss: -1416.668335\n",
      "Train Epoch: 2607 [56832/60000 (95%)] Loss: -1561.785400\n",
      "    epoch          : 2607\n",
      "    loss           : -1450.8875977252164\n",
      "Train Epoch: 2608 [512/60000 (1%)] Loss: -1376.390381\n",
      "Train Epoch: 2608 [11776/60000 (20%)] Loss: -1504.820557\n",
      "Train Epoch: 2608 [23040/60000 (38%)] Loss: -1408.174438\n",
      "Train Epoch: 2608 [34304/60000 (57%)] Loss: -1232.127686\n",
      "Train Epoch: 2608 [45568/60000 (76%)] Loss: -1505.337646\n",
      "Train Epoch: 2608 [56832/60000 (95%)] Loss: -1407.571289\n",
      "    epoch          : 2608\n",
      "    loss           : -1444.2658094847943\n",
      "Train Epoch: 2609 [512/60000 (1%)] Loss: -1410.394531\n",
      "Train Epoch: 2609 [11776/60000 (20%)] Loss: -1575.839233\n",
      "Train Epoch: 2609 [23040/60000 (38%)] Loss: -1569.757812\n",
      "Train Epoch: 2609 [34304/60000 (57%)] Loss: -1501.606689\n",
      "Train Epoch: 2609 [45568/60000 (76%)] Loss: -1477.621338\n",
      "Train Epoch: 2609 [56832/60000 (95%)] Loss: -1499.889771\n",
      "    epoch          : 2609\n",
      "    loss           : -1449.5981041859773\n",
      "Train Epoch: 2610 [512/60000 (1%)] Loss: -1498.772949\n",
      "Train Epoch: 2610 [11776/60000 (20%)] Loss: -1401.812744\n",
      "Train Epoch: 2610 [23040/60000 (38%)] Loss: -1447.488525\n",
      "Train Epoch: 2610 [34304/60000 (57%)] Loss: -1444.989868\n",
      "Train Epoch: 2610 [45568/60000 (76%)] Loss: -1396.335449\n",
      "Train Epoch: 2610 [56832/60000 (95%)] Loss: -1536.764648\n",
      "    epoch          : 2610\n",
      "    loss           : -1447.949610133629\n",
      "Train Epoch: 2611 [512/60000 (1%)] Loss: -1436.862793\n",
      "Train Epoch: 2611 [11776/60000 (20%)] Loss: -1546.025635\n",
      "Train Epoch: 2611 [23040/60000 (38%)] Loss: -1542.070557\n",
      "Train Epoch: 2611 [34304/60000 (57%)] Loss: -1533.831055\n",
      "Train Epoch: 2611 [45568/60000 (76%)] Loss: -1457.214478\n",
      "Train Epoch: 2611 [56832/60000 (95%)] Loss: -1540.794678\n",
      "    epoch          : 2611\n",
      "    loss           : -1460.9963127179335\n",
      "Train Epoch: 2612 [512/60000 (1%)] Loss: -1406.374146\n",
      "Train Epoch: 2612 [11776/60000 (20%)] Loss: -1433.491943\n",
      "Train Epoch: 2612 [23040/60000 (38%)] Loss: -1235.285156\n",
      "Train Epoch: 2612 [34304/60000 (57%)] Loss: -1458.069824\n",
      "Train Epoch: 2612 [45568/60000 (76%)] Loss: -1414.425781\n",
      "Train Epoch: 2612 [56832/60000 (95%)] Loss: -1437.583496\n",
      "    epoch          : 2612\n",
      "    loss           : -1435.1673201221531\n",
      "Train Epoch: 2613 [512/60000 (1%)] Loss: -1431.723999\n",
      "Train Epoch: 2613 [11776/60000 (20%)] Loss: -1534.253174\n",
      "Train Epoch: 2613 [23040/60000 (38%)] Loss: -1430.134033\n",
      "Train Epoch: 2613 [34304/60000 (57%)] Loss: -1513.570679\n",
      "Train Epoch: 2613 [45568/60000 (76%)] Loss: -1436.457886\n",
      "Train Epoch: 2613 [56832/60000 (95%)] Loss: -1469.967773\n",
      "    epoch          : 2613\n",
      "    loss           : -1457.816030728615\n",
      "Train Epoch: 2614 [512/60000 (1%)] Loss: -1395.661133\n",
      "Train Epoch: 2614 [11776/60000 (20%)] Loss: -1582.673462\n",
      "Train Epoch: 2614 [23040/60000 (38%)] Loss: -1567.899536\n",
      "Train Epoch: 2614 [34304/60000 (57%)] Loss: -1444.230225\n",
      "Train Epoch: 2614 [45568/60000 (76%)] Loss: -1469.064697\n",
      "Train Epoch: 2614 [56832/60000 (95%)] Loss: -1484.156738\n",
      "    epoch          : 2614\n",
      "    loss           : -1444.9950002896583\n",
      "Train Epoch: 2615 [512/60000 (1%)] Loss: -1531.818115\n",
      "Train Epoch: 2615 [11776/60000 (20%)] Loss: -1477.126709\n",
      "Train Epoch: 2615 [23040/60000 (38%)] Loss: -1514.103638\n",
      "Train Epoch: 2615 [34304/60000 (57%)] Loss: -1540.328369\n",
      "Train Epoch: 2615 [45568/60000 (76%)] Loss: -1565.230713\n",
      "Train Epoch: 2615 [56832/60000 (95%)] Loss: -1552.905029\n",
      "    epoch          : 2615\n",
      "    loss           : -1439.4094279661017\n",
      "Train Epoch: 2616 [512/60000 (1%)] Loss: -1512.987061\n",
      "Train Epoch: 2616 [11776/60000 (20%)] Loss: -1320.542480\n",
      "Train Epoch: 2616 [23040/60000 (38%)] Loss: -1389.130371\n",
      "Train Epoch: 2616 [34304/60000 (57%)] Loss: -1439.818604\n",
      "Train Epoch: 2616 [45568/60000 (76%)] Loss: -1326.727295\n",
      "Train Epoch: 2616 [56832/60000 (95%)] Loss: -1487.507690\n",
      "    epoch          : 2616\n",
      "    loss           : -1438.846252096575\n",
      "Train Epoch: 2617 [512/60000 (1%)] Loss: -1443.064941\n",
      "Train Epoch: 2617 [11776/60000 (20%)] Loss: -1463.846313\n",
      "Train Epoch: 2617 [23040/60000 (38%)] Loss: -1405.598999\n",
      "Train Epoch: 2617 [34304/60000 (57%)] Loss: -1568.908813\n",
      "Train Epoch: 2617 [45568/60000 (76%)] Loss: -1395.567871\n",
      "Train Epoch: 2617 [56832/60000 (95%)] Loss: -1543.151611\n",
      "    epoch          : 2617\n",
      "    loss           : -1451.4718614136432\n",
      "Train Epoch: 2618 [512/60000 (1%)] Loss: -1568.331909\n",
      "Train Epoch: 2618 [11776/60000 (20%)] Loss: -1433.998779\n",
      "Train Epoch: 2618 [23040/60000 (38%)] Loss: -1411.769043\n",
      "Train Epoch: 2618 [34304/60000 (57%)] Loss: -1520.323730\n",
      "Train Epoch: 2618 [45568/60000 (76%)] Loss: -1543.054443\n",
      "Train Epoch: 2618 [56832/60000 (95%)] Loss: -1372.952393\n",
      "    epoch          : 2618\n",
      "    loss           : -1446.9166014935336\n",
      "Train Epoch: 2619 [512/60000 (1%)] Loss: -1397.549072\n",
      "Train Epoch: 2619 [11776/60000 (20%)] Loss: -1407.608154\n",
      "Train Epoch: 2619 [23040/60000 (38%)] Loss: -1398.762085\n",
      "Train Epoch: 2619 [34304/60000 (57%)] Loss: -1512.217285\n",
      "Train Epoch: 2619 [45568/60000 (76%)] Loss: -1521.980347\n",
      "Train Epoch: 2619 [56832/60000 (95%)] Loss: -1356.044434\n",
      "    epoch          : 2619\n",
      "    loss           : -1443.9770369879943\n",
      "Train Epoch: 2620 [512/60000 (1%)] Loss: -1318.616699\n",
      "Train Epoch: 2620 [11776/60000 (20%)] Loss: -1312.246826\n",
      "Train Epoch: 2620 [23040/60000 (38%)] Loss: -1330.536621\n",
      "Train Epoch: 2620 [34304/60000 (57%)] Loss: -1478.445801\n",
      "Train Epoch: 2620 [45568/60000 (76%)] Loss: -1419.691406\n",
      "Train Epoch: 2620 [56832/60000 (95%)] Loss: -1558.672485\n",
      "    epoch          : 2620\n",
      "    loss           : -1437.8085627151747\n",
      "Train Epoch: 2621 [512/60000 (1%)] Loss: -1346.390503\n",
      "Train Epoch: 2621 [11776/60000 (20%)] Loss: -1466.761230\n",
      "Train Epoch: 2621 [23040/60000 (38%)] Loss: -1552.487427\n",
      "Train Epoch: 2621 [34304/60000 (57%)] Loss: -1486.049805\n",
      "Train Epoch: 2621 [45568/60000 (76%)] Loss: -1532.481689\n",
      "Train Epoch: 2621 [56832/60000 (95%)] Loss: -1436.113770\n",
      "    epoch          : 2621\n",
      "    loss           : -1446.5670445329051\n",
      "Train Epoch: 2622 [512/60000 (1%)] Loss: -1435.728027\n",
      "Train Epoch: 2622 [11776/60000 (20%)] Loss: -1505.200806\n",
      "Train Epoch: 2622 [23040/60000 (38%)] Loss: -1473.453857\n",
      "Train Epoch: 2622 [34304/60000 (57%)] Loss: -1500.769653\n",
      "Train Epoch: 2622 [45568/60000 (76%)] Loss: -1367.935303\n",
      "Train Epoch: 2622 [56832/60000 (95%)] Loss: -1339.127930\n",
      "    epoch          : 2622\n",
      "    loss           : -1447.297947425627\n",
      "Train Epoch: 2623 [512/60000 (1%)] Loss: -1446.523560\n",
      "Train Epoch: 2623 [11776/60000 (20%)] Loss: -1426.746094\n",
      "Train Epoch: 2623 [23040/60000 (38%)] Loss: -1380.708008\n",
      "Train Epoch: 2623 [34304/60000 (57%)] Loss: -1539.605225\n",
      "Train Epoch: 2623 [45568/60000 (76%)] Loss: -1373.948608\n",
      "Train Epoch: 2623 [56832/60000 (95%)] Loss: -1551.484253\n",
      "    epoch          : 2623\n",
      "    loss           : -1454.758675268141\n",
      "Train Epoch: 2624 [512/60000 (1%)] Loss: -1385.980103\n",
      "Train Epoch: 2624 [11776/60000 (20%)] Loss: -1494.177246\n",
      "Train Epoch: 2624 [23040/60000 (38%)] Loss: -1386.584717\n",
      "Train Epoch: 2624 [34304/60000 (57%)] Loss: -1325.669434\n",
      "Train Epoch: 2624 [45568/60000 (76%)] Loss: -1246.353516\n",
      "Train Epoch: 2624 [56832/60000 (95%)] Loss: -1387.435059\n",
      "    epoch          : 2624\n",
      "    loss           : -1449.0679100596974\n",
      "Train Epoch: 2625 [512/60000 (1%)] Loss: -1481.118164\n",
      "Train Epoch: 2625 [11776/60000 (20%)] Loss: -1577.234985\n",
      "Train Epoch: 2625 [23040/60000 (38%)] Loss: -1463.806519\n",
      "Train Epoch: 2625 [34304/60000 (57%)] Loss: -1560.865234\n",
      "Train Epoch: 2625 [45568/60000 (76%)] Loss: -1542.006592\n",
      "Train Epoch: 2625 [56832/60000 (95%)] Loss: -1476.542603\n",
      "    epoch          : 2625\n",
      "    loss           : -1453.5432839258917\n",
      "Train Epoch: 2626 [512/60000 (1%)] Loss: -1297.729614\n",
      "Train Epoch: 2626 [11776/60000 (20%)] Loss: -1485.152344\n",
      "Train Epoch: 2626 [23040/60000 (38%)] Loss: -1373.060791\n",
      "Train Epoch: 2626 [34304/60000 (57%)] Loss: -1512.530396\n",
      "Train Epoch: 2626 [45568/60000 (76%)] Loss: -1549.396484\n",
      "Train Epoch: 2626 [56832/60000 (95%)] Loss: -1487.461914\n",
      "    epoch          : 2626\n",
      "    loss           : -1457.0878451072563\n",
      "Train Epoch: 2627 [512/60000 (1%)] Loss: -1512.717896\n",
      "Train Epoch: 2627 [11776/60000 (20%)] Loss: -1567.433594\n",
      "Train Epoch: 2627 [23040/60000 (38%)] Loss: -1455.618896\n",
      "Train Epoch: 2627 [34304/60000 (57%)] Loss: -1390.621826\n",
      "Train Epoch: 2627 [45568/60000 (76%)] Loss: -1424.084961\n",
      "Train Epoch: 2627 [56832/60000 (95%)] Loss: -1543.558105\n",
      "    epoch          : 2627\n",
      "    loss           : -1454.4784970041048\n",
      "Train Epoch: 2628 [512/60000 (1%)] Loss: -1503.507202\n",
      "Train Epoch: 2628 [11776/60000 (20%)] Loss: -1273.889893\n",
      "Train Epoch: 2628 [23040/60000 (38%)] Loss: -1453.504883\n",
      "Train Epoch: 2628 [34304/60000 (57%)] Loss: -1361.878418\n",
      "Train Epoch: 2628 [45568/60000 (76%)] Loss: -1538.652100\n",
      "Train Epoch: 2628 [56832/60000 (95%)] Loss: -1312.843994\n",
      "    epoch          : 2628\n",
      "    loss           : -1459.6740301961952\n",
      "Train Epoch: 2629 [512/60000 (1%)] Loss: -1453.554688\n",
      "Train Epoch: 2629 [11776/60000 (20%)] Loss: -1432.577148\n",
      "Train Epoch: 2629 [23040/60000 (38%)] Loss: -1305.713379\n",
      "Train Epoch: 2629 [34304/60000 (57%)] Loss: -1422.509399\n",
      "Train Epoch: 2629 [45568/60000 (76%)] Loss: -1551.257568\n",
      "Train Epoch: 2629 [56832/60000 (95%)] Loss: -1450.954468\n",
      "    epoch          : 2629\n",
      "    loss           : -1437.2847407281736\n",
      "Train Epoch: 2630 [512/60000 (1%)] Loss: -1494.481934\n",
      "Train Epoch: 2630 [11776/60000 (20%)] Loss: -1399.247925\n",
      "Train Epoch: 2630 [23040/60000 (38%)] Loss: -1267.174683\n",
      "Train Epoch: 2630 [34304/60000 (57%)] Loss: -1453.751465\n",
      "Train Epoch: 2630 [45568/60000 (76%)] Loss: -1335.568359\n",
      "Train Epoch: 2630 [56832/60000 (95%)] Loss: -1382.966797\n",
      "    epoch          : 2630\n",
      "    loss           : -1452.351133184918\n",
      "Train Epoch: 2631 [512/60000 (1%)] Loss: -1309.536621\n",
      "Train Epoch: 2631 [11776/60000 (20%)] Loss: -1429.043213\n",
      "Train Epoch: 2631 [23040/60000 (38%)] Loss: -1338.987427\n",
      "Train Epoch: 2631 [34304/60000 (57%)] Loss: -1289.266113\n",
      "Train Epoch: 2631 [45568/60000 (76%)] Loss: -1445.127686\n",
      "Train Epoch: 2631 [56832/60000 (95%)] Loss: -1474.901001\n",
      "    epoch          : 2631\n",
      "    loss           : -1440.2575604282529\n",
      "Train Epoch: 2632 [512/60000 (1%)] Loss: -1410.451050\n",
      "Train Epoch: 2632 [11776/60000 (20%)] Loss: -1416.563599\n",
      "Train Epoch: 2632 [23040/60000 (38%)] Loss: -1478.182861\n",
      "Train Epoch: 2632 [34304/60000 (57%)] Loss: -1423.297363\n",
      "Train Epoch: 2632 [45568/60000 (76%)] Loss: -1470.340820\n",
      "Train Epoch: 2632 [56832/60000 (95%)] Loss: -1465.496826\n",
      "    epoch          : 2632\n",
      "    loss           : -1426.2935315148304\n",
      "Train Epoch: 2633 [512/60000 (1%)] Loss: -1242.527344\n",
      "Train Epoch: 2633 [11776/60000 (20%)] Loss: -1419.658691\n",
      "Train Epoch: 2633 [23040/60000 (38%)] Loss: -1478.248779\n",
      "Train Epoch: 2633 [34304/60000 (57%)] Loss: -1365.920776\n",
      "Train Epoch: 2633 [45568/60000 (76%)] Loss: -1312.962646\n",
      "Train Epoch: 2633 [56832/60000 (95%)] Loss: -1506.254272\n",
      "    epoch          : 2633\n",
      "    loss           : -1438.355849443856\n",
      "Train Epoch: 2634 [512/60000 (1%)] Loss: -1444.542358\n",
      "Train Epoch: 2634 [11776/60000 (20%)] Loss: -1521.855957\n",
      "Train Epoch: 2634 [23040/60000 (38%)] Loss: -1333.971558\n",
      "Train Epoch: 2634 [34304/60000 (57%)] Loss: -1509.296021\n",
      "Train Epoch: 2634 [45568/60000 (76%)] Loss: -1376.833496\n",
      "Train Epoch: 2634 [56832/60000 (95%)] Loss: -1557.437256\n",
      "    epoch          : 2634\n",
      "    loss           : -1444.5592534124514\n",
      "Train Epoch: 2635 [512/60000 (1%)] Loss: -1423.659302\n",
      "Train Epoch: 2635 [11776/60000 (20%)] Loss: -1459.440796\n",
      "Train Epoch: 2635 [23040/60000 (38%)] Loss: -1439.715698\n",
      "Train Epoch: 2635 [34304/60000 (57%)] Loss: -1462.726562\n",
      "Train Epoch: 2635 [45568/60000 (76%)] Loss: -1527.636475\n",
      "Train Epoch: 2635 [56832/60000 (95%)] Loss: -1538.215576\n",
      "    epoch          : 2635\n",
      "    loss           : -1464.3822480110125\n",
      "Train Epoch: 2636 [512/60000 (1%)] Loss: -1478.651123\n",
      "Train Epoch: 2636 [11776/60000 (20%)] Loss: -1509.580444\n",
      "Train Epoch: 2636 [23040/60000 (38%)] Loss: -1484.746216\n",
      "Train Epoch: 2636 [34304/60000 (57%)] Loss: -1138.109131\n",
      "Train Epoch: 2636 [45568/60000 (76%)] Loss: -1432.469971\n",
      "Train Epoch: 2636 [56832/60000 (95%)] Loss: -1415.266113\n",
      "    epoch          : 2636\n",
      "    loss           : -1452.706812626898\n",
      "Train Epoch: 2637 [512/60000 (1%)] Loss: -1322.350098\n",
      "Train Epoch: 2637 [11776/60000 (20%)] Loss: -1490.780762\n",
      "Train Epoch: 2637 [23040/60000 (38%)] Loss: -1503.013550\n",
      "Train Epoch: 2637 [34304/60000 (57%)] Loss: -1482.886475\n",
      "Train Epoch: 2637 [45568/60000 (76%)] Loss: -1539.675781\n",
      "Train Epoch: 2637 [56832/60000 (95%)] Loss: -1541.814697\n",
      "    epoch          : 2637\n",
      "    loss           : -1451.402095126567\n",
      "Train Epoch: 2638 [512/60000 (1%)] Loss: -1434.664917\n",
      "Train Epoch: 2638 [11776/60000 (20%)] Loss: -1368.393311\n",
      "Train Epoch: 2638 [23040/60000 (38%)] Loss: -1548.048218\n",
      "Train Epoch: 2638 [34304/60000 (57%)] Loss: -1405.198853\n",
      "Train Epoch: 2638 [45568/60000 (76%)] Loss: -1532.955078\n",
      "Train Epoch: 2638 [56832/60000 (95%)] Loss: -1415.266113\n",
      "    epoch          : 2638\n",
      "    loss           : -1446.5944910426597\n",
      "Train Epoch: 2639 [512/60000 (1%)] Loss: -1476.196411\n",
      "Train Epoch: 2639 [11776/60000 (20%)] Loss: -1248.111450\n",
      "Train Epoch: 2639 [23040/60000 (38%)] Loss: -1523.994629\n",
      "Train Epoch: 2639 [34304/60000 (57%)] Loss: -1424.548828\n",
      "Train Epoch: 2639 [45568/60000 (76%)] Loss: -1330.083252\n",
      "Train Epoch: 2639 [56832/60000 (95%)] Loss: -1505.922363\n",
      "    epoch          : 2639\n",
      "    loss           : -1450.3942033153469\n",
      "Train Epoch: 2640 [512/60000 (1%)] Loss: -1558.843140\n",
      "Train Epoch: 2640 [11776/60000 (20%)] Loss: -1316.657959\n",
      "Train Epoch: 2640 [23040/60000 (38%)] Loss: -1400.682617\n",
      "Train Epoch: 2640 [34304/60000 (57%)] Loss: -1378.115112\n",
      "Train Epoch: 2640 [45568/60000 (76%)] Loss: -1505.299561\n",
      "Train Epoch: 2640 [56832/60000 (95%)] Loss: -1250.067993\n",
      "    epoch          : 2640\n",
      "    loss           : -1435.1661607990156\n",
      "Train Epoch: 2641 [512/60000 (1%)] Loss: -1334.122437\n",
      "Train Epoch: 2641 [11776/60000 (20%)] Loss: -1351.603760\n",
      "Train Epoch: 2641 [23040/60000 (38%)] Loss: -1490.168213\n",
      "Train Epoch: 2641 [34304/60000 (57%)] Loss: -1444.225220\n",
      "Train Epoch: 2641 [45568/60000 (76%)] Loss: -1522.027710\n",
      "Train Epoch: 2641 [56832/60000 (95%)] Loss: -1215.723145\n",
      "    epoch          : 2641\n",
      "    loss           : -1441.6295966024452\n",
      "Train Epoch: 2642 [512/60000 (1%)] Loss: -1287.367920\n",
      "Train Epoch: 2642 [11776/60000 (20%)] Loss: -1341.634033\n",
      "Train Epoch: 2642 [23040/60000 (38%)] Loss: -1375.025635\n",
      "Train Epoch: 2642 [34304/60000 (57%)] Loss: -1521.870728\n",
      "Train Epoch: 2642 [45568/60000 (76%)] Loss: -1479.859985\n",
      "Train Epoch: 2642 [56832/60000 (95%)] Loss: -1386.136841\n",
      "    epoch          : 2642\n",
      "    loss           : -1440.5323165634932\n",
      "Train Epoch: 2643 [512/60000 (1%)] Loss: -1555.943359\n",
      "Train Epoch: 2643 [11776/60000 (20%)] Loss: -1445.546875\n",
      "Train Epoch: 2643 [23040/60000 (38%)] Loss: -1541.061279\n",
      "Train Epoch: 2643 [34304/60000 (57%)] Loss: -1459.014282\n",
      "Train Epoch: 2643 [45568/60000 (76%)] Loss: -1226.230347\n",
      "Train Epoch: 2643 [56832/60000 (95%)] Loss: -1434.272705\n",
      "    epoch          : 2643\n",
      "    loss           : -1451.2623677226782\n",
      "Train Epoch: 2644 [512/60000 (1%)] Loss: -1290.662354\n",
      "Train Epoch: 2644 [11776/60000 (20%)] Loss: -1368.956177\n",
      "Train Epoch: 2644 [23040/60000 (38%)] Loss: -1469.697998\n",
      "Train Epoch: 2644 [34304/60000 (57%)] Loss: -1550.192871\n",
      "Train Epoch: 2644 [45568/60000 (76%)] Loss: -1371.690186\n",
      "Train Epoch: 2644 [56832/60000 (95%)] Loss: -1481.135498\n",
      "    epoch          : 2644\n",
      "    loss           : -1445.0781850006622\n",
      "Train Epoch: 2645 [512/60000 (1%)] Loss: -1298.166626\n",
      "Train Epoch: 2645 [11776/60000 (20%)] Loss: -1389.163696\n",
      "Train Epoch: 2645 [23040/60000 (38%)] Loss: -1385.673462\n",
      "Train Epoch: 2645 [34304/60000 (57%)] Loss: -1371.586914\n",
      "Train Epoch: 2645 [45568/60000 (76%)] Loss: -1339.069824\n",
      "Train Epoch: 2645 [56832/60000 (95%)] Loss: -1443.807129\n",
      "    epoch          : 2645\n",
      "    loss           : -1454.9113004005562\n",
      "Train Epoch: 2646 [512/60000 (1%)] Loss: -1388.184692\n",
      "Train Epoch: 2646 [11776/60000 (20%)] Loss: -1423.090088\n",
      "Train Epoch: 2646 [23040/60000 (38%)] Loss: -1419.202393\n",
      "Train Epoch: 2646 [34304/60000 (57%)] Loss: -1375.923218\n",
      "Train Epoch: 2646 [45568/60000 (76%)] Loss: -1564.333008\n",
      "Train Epoch: 2646 [56832/60000 (95%)] Loss: -1542.005127\n",
      "    epoch          : 2646\n",
      "    loss           : -1437.5997069622836\n",
      "Train Epoch: 2647 [512/60000 (1%)] Loss: -1530.508667\n",
      "Train Epoch: 2647 [11776/60000 (20%)] Loss: -1476.433716\n",
      "Train Epoch: 2647 [23040/60000 (38%)] Loss: -1389.177979\n",
      "Train Epoch: 2647 [34304/60000 (57%)] Loss: -1443.666626\n",
      "Train Epoch: 2647 [45568/60000 (76%)] Loss: -1323.601318\n",
      "Train Epoch: 2647 [56832/60000 (95%)] Loss: -1460.961182\n",
      "    epoch          : 2647\n",
      "    loss           : -1446.0165474239716\n",
      "Train Epoch: 2648 [512/60000 (1%)] Loss: -1297.428467\n",
      "Train Epoch: 2648 [11776/60000 (20%)] Loss: -1317.822998\n",
      "Train Epoch: 2648 [23040/60000 (38%)] Loss: -1467.532837\n",
      "Train Epoch: 2648 [34304/60000 (57%)] Loss: -1397.431152\n",
      "Train Epoch: 2648 [45568/60000 (76%)] Loss: -1515.265503\n",
      "Train Epoch: 2648 [56832/60000 (95%)] Loss: -1460.142822\n",
      "    epoch          : 2648\n",
      "    loss           : -1452.3087882349046\n",
      "Train Epoch: 2649 [512/60000 (1%)] Loss: -1554.017090\n",
      "Train Epoch: 2649 [11776/60000 (20%)] Loss: -1254.876099\n",
      "Train Epoch: 2649 [23040/60000 (38%)] Loss: -1388.307861\n",
      "Train Epoch: 2649 [34304/60000 (57%)] Loss: -1485.884521\n",
      "Train Epoch: 2649 [45568/60000 (76%)] Loss: -1415.402100\n",
      "Train Epoch: 2649 [56832/60000 (95%)] Loss: -1460.595703\n",
      "    epoch          : 2649\n",
      "    loss           : -1462.8046809482037\n",
      "Train Epoch: 2650 [512/60000 (1%)] Loss: -1504.272461\n",
      "Train Epoch: 2650 [11776/60000 (20%)] Loss: -1466.152100\n",
      "Train Epoch: 2650 [23040/60000 (38%)] Loss: -1519.212891\n",
      "Train Epoch: 2650 [34304/60000 (57%)] Loss: -1554.383911\n",
      "Train Epoch: 2650 [45568/60000 (76%)] Loss: -1533.022461\n",
      "Train Epoch: 2650 [56832/60000 (95%)] Loss: -1595.858154\n",
      "    epoch          : 2650\n",
      "    loss           : -1451.9139724990068\n",
      "Train Epoch: 2651 [512/60000 (1%)] Loss: -1445.767334\n",
      "Train Epoch: 2651 [11776/60000 (20%)] Loss: -1492.365723\n",
      "Train Epoch: 2651 [23040/60000 (38%)] Loss: -1376.200562\n",
      "Train Epoch: 2651 [34304/60000 (57%)] Loss: -1568.434326\n",
      "Train Epoch: 2651 [45568/60000 (76%)] Loss: -1377.876953\n",
      "Train Epoch: 2651 [56832/60000 (95%)] Loss: -1500.113403\n",
      "    epoch          : 2651\n",
      "    loss           : -1451.4400179588188\n",
      "Train Epoch: 2652 [512/60000 (1%)] Loss: -1552.284058\n",
      "Train Epoch: 2652 [11776/60000 (20%)] Loss: -1481.136597\n",
      "Train Epoch: 2652 [23040/60000 (38%)] Loss: -1561.276733\n",
      "Train Epoch: 2652 [34304/60000 (57%)] Loss: -1286.520996\n",
      "Train Epoch: 2652 [45568/60000 (76%)] Loss: -1589.875732\n",
      "Train Epoch: 2652 [56832/60000 (95%)] Loss: -1400.253418\n",
      "    epoch          : 2652\n",
      "    loss           : -1458.0196884931145\n",
      "Train Epoch: 2653 [512/60000 (1%)] Loss: -1209.151855\n",
      "Train Epoch: 2653 [11776/60000 (20%)] Loss: -1444.749756\n",
      "Train Epoch: 2653 [23040/60000 (38%)] Loss: -1532.093506\n",
      "Train Epoch: 2653 [34304/60000 (57%)] Loss: -1250.397339\n",
      "Train Epoch: 2653 [45568/60000 (76%)] Loss: -1567.259277\n",
      "Train Epoch: 2653 [56832/60000 (95%)] Loss: -1559.181152\n",
      "    epoch          : 2653\n",
      "    loss           : -1455.8960498874471\n",
      "Train Epoch: 2654 [512/60000 (1%)] Loss: -1385.633301\n",
      "Train Epoch: 2654 [11776/60000 (20%)] Loss: -1471.794434\n",
      "Train Epoch: 2654 [23040/60000 (38%)] Loss: -1539.451904\n",
      "Train Epoch: 2654 [34304/60000 (57%)] Loss: -1505.692871\n",
      "Train Epoch: 2654 [45568/60000 (76%)] Loss: -1541.661011\n",
      "Train Epoch: 2654 [56832/60000 (95%)] Loss: -1510.521484\n",
      "    epoch          : 2654\n",
      "    loss           : -1461.0966162385241\n",
      "Train Epoch: 2655 [512/60000 (1%)] Loss: -1490.462646\n",
      "Train Epoch: 2655 [11776/60000 (20%)] Loss: -1532.703613\n",
      "Train Epoch: 2655 [23040/60000 (38%)] Loss: -1587.960083\n",
      "Train Epoch: 2655 [34304/60000 (57%)] Loss: -1362.039551\n",
      "Train Epoch: 2655 [45568/60000 (76%)] Loss: -1354.371094\n",
      "Train Epoch: 2655 [56832/60000 (95%)] Loss: -1324.647583\n",
      "    epoch          : 2655\n",
      "    loss           : -1447.2201824295994\n",
      "Train Epoch: 2656 [512/60000 (1%)] Loss: -1436.899780\n",
      "Train Epoch: 2656 [11776/60000 (20%)] Loss: -1464.513306\n",
      "Train Epoch: 2656 [23040/60000 (38%)] Loss: -1488.314209\n",
      "Train Epoch: 2656 [34304/60000 (57%)] Loss: -1281.957031\n",
      "Train Epoch: 2656 [45568/60000 (76%)] Loss: -1474.052612\n",
      "Train Epoch: 2656 [56832/60000 (95%)] Loss: -1357.661621\n",
      "    epoch          : 2656\n",
      "    loss           : -1446.1878589694784\n",
      "Train Epoch: 2657 [512/60000 (1%)] Loss: -1554.929199\n",
      "Train Epoch: 2657 [11776/60000 (20%)] Loss: -1414.824463\n",
      "Train Epoch: 2657 [23040/60000 (38%)] Loss: -1261.340088\n",
      "Train Epoch: 2657 [34304/60000 (57%)] Loss: -1347.639404\n",
      "Train Epoch: 2657 [45568/60000 (76%)] Loss: -1409.791748\n",
      "Train Epoch: 2657 [56832/60000 (95%)] Loss: -1302.138672\n",
      "    epoch          : 2657\n",
      "    loss           : -1454.987163651461\n",
      "Train Epoch: 2658 [512/60000 (1%)] Loss: -1519.563477\n",
      "Train Epoch: 2658 [11776/60000 (20%)] Loss: -1549.069458\n",
      "Train Epoch: 2658 [23040/60000 (38%)] Loss: -1480.627319\n",
      "Train Epoch: 2658 [34304/60000 (57%)] Loss: -1262.717407\n",
      "Train Epoch: 2658 [45568/60000 (76%)] Loss: -1534.831787\n",
      "Train Epoch: 2658 [56832/60000 (95%)] Loss: -1461.511597\n",
      "    epoch          : 2658\n",
      "    loss           : -1448.4702189817267\n",
      "Train Epoch: 2659 [512/60000 (1%)] Loss: -1553.123779\n",
      "Train Epoch: 2659 [11776/60000 (20%)] Loss: -1488.726929\n",
      "Train Epoch: 2659 [23040/60000 (38%)] Loss: -1561.224121\n",
      "Train Epoch: 2659 [34304/60000 (57%)] Loss: -1530.395508\n",
      "Train Epoch: 2659 [45568/60000 (76%)] Loss: -1367.153442\n",
      "Train Epoch: 2659 [56832/60000 (95%)] Loss: -1291.378906\n",
      "    epoch          : 2659\n",
      "    loss           : -1455.3295577744307\n",
      "Train Epoch: 2660 [512/60000 (1%)] Loss: -1226.857178\n",
      "Train Epoch: 2660 [11776/60000 (20%)] Loss: -1374.022217\n",
      "Train Epoch: 2660 [23040/60000 (38%)] Loss: -1448.920776\n",
      "Train Epoch: 2660 [34304/60000 (57%)] Loss: -1325.780273\n",
      "Train Epoch: 2660 [45568/60000 (76%)] Loss: -1439.663086\n",
      "Train Epoch: 2660 [56832/60000 (95%)] Loss: -1308.355713\n",
      "    epoch          : 2660\n",
      "    loss           : -1460.4227832858846\n",
      "Train Epoch: 2661 [512/60000 (1%)] Loss: -1392.897461\n",
      "Train Epoch: 2661 [11776/60000 (20%)] Loss: -1498.693237\n",
      "Train Epoch: 2661 [23040/60000 (38%)] Loss: -1509.166748\n",
      "Train Epoch: 2661 [34304/60000 (57%)] Loss: -1486.343750\n",
      "Train Epoch: 2661 [45568/60000 (76%)] Loss: -1550.880493\n",
      "Train Epoch: 2661 [56832/60000 (95%)] Loss: -1450.158936\n",
      "    epoch          : 2661\n",
      "    loss           : -1450.2688660702463\n",
      "Train Epoch: 2662 [512/60000 (1%)] Loss: -1549.340332\n",
      "Train Epoch: 2662 [11776/60000 (20%)] Loss: -1468.981812\n",
      "Train Epoch: 2662 [23040/60000 (38%)] Loss: -1510.366211\n",
      "Train Epoch: 2662 [34304/60000 (57%)] Loss: -1415.759399\n",
      "Train Epoch: 2662 [45568/60000 (76%)] Loss: -1303.383423\n",
      "Train Epoch: 2662 [56832/60000 (95%)] Loss: -1415.403320\n",
      "    epoch          : 2662\n",
      "    loss           : -1449.5666410801775\n",
      "Train Epoch: 2663 [512/60000 (1%)] Loss: -1308.444336\n",
      "Train Epoch: 2663 [11776/60000 (20%)] Loss: -1539.055664\n",
      "Train Epoch: 2663 [23040/60000 (38%)] Loss: -1554.448486\n",
      "Train Epoch: 2663 [34304/60000 (57%)] Loss: -1426.345337\n",
      "Train Epoch: 2663 [45568/60000 (76%)] Loss: -1397.261963\n",
      "Train Epoch: 2663 [56832/60000 (95%)] Loss: -1550.157104\n",
      "    epoch          : 2663\n",
      "    loss           : -1460.420869471663\n",
      "Train Epoch: 2664 [512/60000 (1%)] Loss: -1530.789185\n",
      "Train Epoch: 2664 [11776/60000 (20%)] Loss: -1386.019409\n",
      "Train Epoch: 2664 [23040/60000 (38%)] Loss: -1289.253784\n",
      "Train Epoch: 2664 [34304/60000 (57%)] Loss: -1541.598999\n",
      "Train Epoch: 2664 [45568/60000 (76%)] Loss: -1428.329102\n",
      "Train Epoch: 2664 [56832/60000 (95%)] Loss: -1305.641113\n",
      "    epoch          : 2664\n",
      "    loss           : -1445.5914892853991\n",
      "Train Epoch: 2665 [512/60000 (1%)] Loss: -1529.741943\n",
      "Train Epoch: 2665 [11776/60000 (20%)] Loss: -1338.920776\n",
      "Train Epoch: 2665 [23040/60000 (38%)] Loss: -1374.718140\n",
      "Train Epoch: 2665 [34304/60000 (57%)] Loss: -1350.705566\n",
      "Train Epoch: 2665 [45568/60000 (76%)] Loss: -1450.631470\n",
      "Train Epoch: 2665 [56832/60000 (95%)] Loss: -1547.760986\n",
      "    epoch          : 2665\n",
      "    loss           : -1460.1892596745895\n",
      "Train Epoch: 2666 [512/60000 (1%)] Loss: -1316.550781\n",
      "Train Epoch: 2666 [11776/60000 (20%)] Loss: -1366.195068\n",
      "Train Epoch: 2666 [23040/60000 (38%)] Loss: -1429.483154\n",
      "Train Epoch: 2666 [34304/60000 (57%)] Loss: -1475.756348\n",
      "Train Epoch: 2666 [45568/60000 (76%)] Loss: -1362.303833\n",
      "Train Epoch: 2666 [56832/60000 (95%)] Loss: -1444.341064\n",
      "    epoch          : 2666\n",
      "    loss           : -1451.4324602892168\n",
      "Train Epoch: 2667 [512/60000 (1%)] Loss: -1462.067139\n",
      "Train Epoch: 2667 [11776/60000 (20%)] Loss: -1499.946167\n",
      "Train Epoch: 2667 [23040/60000 (38%)] Loss: -1551.475586\n",
      "Train Epoch: 2667 [34304/60000 (57%)] Loss: -1405.133179\n",
      "Train Epoch: 2667 [45568/60000 (76%)] Loss: -1434.769043\n",
      "Train Epoch: 2667 [56832/60000 (95%)] Loss: -1337.972412\n",
      "    epoch          : 2667\n",
      "    loss           : -1459.7128523487156\n",
      "Train Epoch: 2668 [512/60000 (1%)] Loss: -1397.028442\n",
      "Train Epoch: 2668 [11776/60000 (20%)] Loss: -1446.305176\n",
      "Train Epoch: 2668 [23040/60000 (38%)] Loss: -1522.343506\n",
      "Train Epoch: 2668 [34304/60000 (57%)] Loss: -1568.590698\n",
      "Train Epoch: 2668 [45568/60000 (76%)] Loss: -1438.150146\n",
      "Train Epoch: 2668 [56832/60000 (95%)] Loss: -1369.324463\n",
      "    epoch          : 2668\n",
      "    loss           : -1452.2737171582583\n",
      "Train Epoch: 2669 [512/60000 (1%)] Loss: -1482.757812\n",
      "Train Epoch: 2669 [11776/60000 (20%)] Loss: -1408.041260\n",
      "Train Epoch: 2669 [23040/60000 (38%)] Loss: -1494.539429\n",
      "Train Epoch: 2669 [34304/60000 (57%)] Loss: -1540.284546\n",
      "Train Epoch: 2669 [45568/60000 (76%)] Loss: -1568.836304\n",
      "Train Epoch: 2669 [56832/60000 (95%)] Loss: -1453.534912\n",
      "    epoch          : 2669\n",
      "    loss           : -1462.403759282861\n",
      "Train Epoch: 2670 [512/60000 (1%)] Loss: -1448.900269\n",
      "Train Epoch: 2670 [11776/60000 (20%)] Loss: -1530.133301\n",
      "Train Epoch: 2670 [23040/60000 (38%)] Loss: -1406.474365\n",
      "Train Epoch: 2670 [34304/60000 (57%)] Loss: -1446.057495\n",
      "Train Epoch: 2670 [45568/60000 (76%)] Loss: -1314.062744\n",
      "Train Epoch: 2670 [56832/60000 (95%)] Loss: -1540.313232\n",
      "    epoch          : 2670\n",
      "    loss           : -1449.144537456965\n",
      "Train Epoch: 2671 [512/60000 (1%)] Loss: -1317.140137\n",
      "Train Epoch: 2671 [11776/60000 (20%)] Loss: -1354.578369\n",
      "Train Epoch: 2671 [23040/60000 (38%)] Loss: -1414.167236\n",
      "Train Epoch: 2671 [34304/60000 (57%)] Loss: -1463.862549\n",
      "Train Epoch: 2671 [45568/60000 (76%)] Loss: -1387.272827\n",
      "Train Epoch: 2671 [56832/60000 (95%)] Loss: -1439.518066\n",
      "    epoch          : 2671\n",
      "    loss           : -1454.3509159411415\n",
      "Train Epoch: 2672 [512/60000 (1%)] Loss: -1323.149780\n",
      "Train Epoch: 2672 [11776/60000 (20%)] Loss: -1395.096436\n",
      "Train Epoch: 2672 [23040/60000 (38%)] Loss: -1271.657349\n",
      "Train Epoch: 2672 [34304/60000 (57%)] Loss: -1426.661011\n",
      "Train Epoch: 2672 [45568/60000 (76%)] Loss: -1538.939575\n",
      "Train Epoch: 2672 [56832/60000 (95%)] Loss: -1566.140625\n",
      "    epoch          : 2672\n",
      "    loss           : -1444.453575349797\n",
      "Train Epoch: 2673 [512/60000 (1%)] Loss: -1456.089966\n",
      "Train Epoch: 2673 [11776/60000 (20%)] Loss: -1554.401855\n",
      "Train Epoch: 2673 [23040/60000 (38%)] Loss: -1427.204346\n",
      "Train Epoch: 2673 [34304/60000 (57%)] Loss: -1525.393311\n",
      "Train Epoch: 2673 [45568/60000 (76%)] Loss: -1574.962646\n",
      "Train Epoch: 2673 [56832/60000 (95%)] Loss: -1421.319092\n",
      "    epoch          : 2673\n",
      "    loss           : -1459.7561400677523\n",
      "Train Epoch: 2674 [512/60000 (1%)] Loss: -1306.758301\n",
      "Train Epoch: 2674 [11776/60000 (20%)] Loss: -1448.997192\n",
      "Train Epoch: 2674 [23040/60000 (38%)] Loss: -1354.257568\n",
      "Train Epoch: 2674 [34304/60000 (57%)] Loss: -1530.411255\n",
      "Train Epoch: 2674 [45568/60000 (76%)] Loss: -1491.641968\n",
      "Train Epoch: 2674 [56832/60000 (95%)] Loss: -1482.959229\n",
      "    epoch          : 2674\n",
      "    loss           : -1457.223360395701\n",
      "Train Epoch: 2675 [512/60000 (1%)] Loss: -1438.810791\n",
      "Train Epoch: 2675 [11776/60000 (20%)] Loss: -1447.788574\n",
      "Train Epoch: 2675 [23040/60000 (38%)] Loss: -1401.138184\n",
      "Train Epoch: 2675 [34304/60000 (57%)] Loss: -1465.885986\n",
      "Train Epoch: 2675 [45568/60000 (76%)] Loss: -1569.117676\n",
      "Train Epoch: 2675 [56832/60000 (95%)] Loss: -1425.678223\n",
      "    epoch          : 2675\n",
      "    loss           : -1449.1543958416094\n",
      "Train Epoch: 2676 [512/60000 (1%)] Loss: -1544.493530\n",
      "Train Epoch: 2676 [11776/60000 (20%)] Loss: -1466.334473\n",
      "Train Epoch: 2676 [23040/60000 (38%)] Loss: -1557.807861\n",
      "Train Epoch: 2676 [34304/60000 (57%)] Loss: -1515.199463\n",
      "Train Epoch: 2676 [45568/60000 (76%)] Loss: -1555.462769\n",
      "Train Epoch: 2676 [56832/60000 (95%)] Loss: -1393.156250\n",
      "    epoch          : 2676\n",
      "    loss           : -1455.4047679146804\n",
      "Train Epoch: 2677 [512/60000 (1%)] Loss: -1493.081543\n",
      "Train Epoch: 2677 [11776/60000 (20%)] Loss: -1505.492798\n",
      "Train Epoch: 2677 [23040/60000 (38%)] Loss: -1446.043335\n",
      "Train Epoch: 2677 [34304/60000 (57%)] Loss: -1504.974609\n",
      "Train Epoch: 2677 [45568/60000 (76%)] Loss: -1553.427856\n",
      "Train Epoch: 2677 [56832/60000 (95%)] Loss: -1357.036377\n",
      "    epoch          : 2677\n",
      "    loss           : -1446.4015554654395\n",
      "Train Epoch: 2678 [512/60000 (1%)] Loss: -1359.205078\n",
      "Train Epoch: 2678 [11776/60000 (20%)] Loss: -1550.673340\n",
      "Train Epoch: 2678 [23040/60000 (38%)] Loss: -1339.725098\n",
      "Train Epoch: 2678 [34304/60000 (57%)] Loss: -1550.743896\n",
      "Train Epoch: 2678 [45568/60000 (76%)] Loss: -1449.799072\n",
      "Train Epoch: 2678 [56832/60000 (95%)] Loss: -1556.838257\n",
      "    epoch          : 2678\n",
      "    loss           : -1451.9319706286415\n",
      "Train Epoch: 2679 [512/60000 (1%)] Loss: -1497.984253\n",
      "Train Epoch: 2679 [11776/60000 (20%)] Loss: -1359.801392\n",
      "Train Epoch: 2679 [23040/60000 (38%)] Loss: -1414.193115\n",
      "Train Epoch: 2679 [34304/60000 (57%)] Loss: -1348.065796\n",
      "Train Epoch: 2679 [45568/60000 (76%)] Loss: -1577.256104\n",
      "Train Epoch: 2679 [56832/60000 (95%)] Loss: -1541.303711\n",
      "    epoch          : 2679\n",
      "    loss           : -1469.8963564425537\n",
      "Train Epoch: 2680 [512/60000 (1%)] Loss: -1561.311279\n",
      "Train Epoch: 2680 [11776/60000 (20%)] Loss: -1544.199951\n",
      "Train Epoch: 2680 [23040/60000 (38%)] Loss: -1420.710205\n",
      "Train Epoch: 2680 [34304/60000 (57%)] Loss: -1533.457886\n",
      "Train Epoch: 2680 [45568/60000 (76%)] Loss: -1486.980469\n",
      "Train Epoch: 2680 [56832/60000 (95%)] Loss: -1526.479004\n",
      "    epoch          : 2680\n",
      "    loss           : -1462.6062528965838\n",
      "Train Epoch: 2681 [512/60000 (1%)] Loss: -1567.881348\n",
      "Train Epoch: 2681 [11776/60000 (20%)] Loss: -1418.112793\n",
      "Train Epoch: 2681 [23040/60000 (38%)] Loss: -1334.915894\n",
      "Train Epoch: 2681 [34304/60000 (57%)] Loss: -1459.355591\n",
      "Train Epoch: 2681 [45568/60000 (76%)] Loss: -1371.598389\n",
      "Train Epoch: 2681 [56832/60000 (95%)] Loss: -1558.410034\n",
      "    epoch          : 2681\n",
      "    loss           : -1451.420156360346\n",
      "Train Epoch: 2682 [512/60000 (1%)] Loss: -1534.415527\n",
      "Train Epoch: 2682 [11776/60000 (20%)] Loss: -1546.355591\n",
      "Train Epoch: 2682 [23040/60000 (38%)] Loss: -1385.613770\n",
      "Train Epoch: 2682 [34304/60000 (57%)] Loss: -1420.076416\n",
      "Train Epoch: 2682 [45568/60000 (76%)] Loss: -1434.740967\n",
      "Train Epoch: 2682 [56832/60000 (95%)] Loss: -1508.972290\n",
      "    epoch          : 2682\n",
      "    loss           : -1456.4461511299435\n",
      "Train Epoch: 2683 [512/60000 (1%)] Loss: -1559.466797\n",
      "Train Epoch: 2683 [11776/60000 (20%)] Loss: -1319.024658\n",
      "Train Epoch: 2683 [23040/60000 (38%)] Loss: -1516.793701\n",
      "Train Epoch: 2683 [34304/60000 (57%)] Loss: -1405.062256\n",
      "Train Epoch: 2683 [45568/60000 (76%)] Loss: -1408.382690\n",
      "Train Epoch: 2683 [56832/60000 (95%)] Loss: -1292.429443\n",
      "    epoch          : 2683\n",
      "    loss           : -1452.7799541236316\n",
      "Train Epoch: 2684 [512/60000 (1%)] Loss: -1556.102539\n",
      "Train Epoch: 2684 [11776/60000 (20%)] Loss: -1519.442261\n",
      "Train Epoch: 2684 [23040/60000 (38%)] Loss: -1334.048096\n",
      "Train Epoch: 2684 [34304/60000 (57%)] Loss: -1380.454346\n",
      "Train Epoch: 2684 [45568/60000 (76%)] Loss: -1518.438232\n",
      "Train Epoch: 2684 [56832/60000 (95%)] Loss: -1547.903564\n",
      "    epoch          : 2684\n",
      "    loss           : -1456.2001766916048\n",
      "Train Epoch: 2685 [512/60000 (1%)] Loss: -1437.298584\n",
      "Train Epoch: 2685 [11776/60000 (20%)] Loss: -1410.587769\n",
      "Train Epoch: 2685 [23040/60000 (38%)] Loss: -1387.020996\n",
      "Train Epoch: 2685 [34304/60000 (57%)] Loss: -1448.629883\n",
      "Train Epoch: 2685 [45568/60000 (76%)] Loss: -1450.374268\n",
      "Train Epoch: 2685 [56832/60000 (95%)] Loss: -1332.917358\n",
      "    epoch          : 2685\n",
      "    loss           : -1458.0684928247483\n",
      "Train Epoch: 2686 [512/60000 (1%)] Loss: -1444.240967\n",
      "Train Epoch: 2686 [11776/60000 (20%)] Loss: -1445.081543\n",
      "Train Epoch: 2686 [23040/60000 (38%)] Loss: -1555.496338\n",
      "Train Epoch: 2686 [34304/60000 (57%)] Loss: -1407.583740\n",
      "Train Epoch: 2686 [45568/60000 (76%)] Loss: -1443.200439\n",
      "Train Epoch: 2686 [56832/60000 (95%)] Loss: -1489.977417\n",
      "    epoch          : 2686\n",
      "    loss           : -1457.015276030632\n",
      "Train Epoch: 2687 [512/60000 (1%)] Loss: -1385.714844\n",
      "Train Epoch: 2687 [11776/60000 (20%)] Loss: -1351.660034\n",
      "Train Epoch: 2687 [23040/60000 (38%)] Loss: -1532.236206\n",
      "Train Epoch: 2687 [34304/60000 (57%)] Loss: -1277.639038\n",
      "Train Epoch: 2687 [45568/60000 (76%)] Loss: -1458.481934\n",
      "Train Epoch: 2687 [56832/60000 (95%)] Loss: -1550.121216\n",
      "    epoch          : 2687\n",
      "    loss           : -1460.1960625082759\n",
      "Train Epoch: 2688 [512/60000 (1%)] Loss: -1396.064209\n",
      "Train Epoch: 2688 [11776/60000 (20%)] Loss: -1445.531250\n",
      "Train Epoch: 2688 [23040/60000 (38%)] Loss: -1544.461182\n",
      "Train Epoch: 2688 [34304/60000 (57%)] Loss: -1440.946045\n",
      "Train Epoch: 2688 [45568/60000 (76%)] Loss: -1446.369019\n",
      "Train Epoch: 2688 [56832/60000 (95%)] Loss: -1560.379883\n",
      "    epoch          : 2688\n",
      "    loss           : -1453.561275848561\n",
      "Train Epoch: 2689 [512/60000 (1%)] Loss: -1344.558594\n",
      "Train Epoch: 2689 [11776/60000 (20%)] Loss: -1491.821899\n",
      "Train Epoch: 2689 [23040/60000 (38%)] Loss: -1382.303467\n",
      "Train Epoch: 2689 [34304/60000 (57%)] Loss: -1385.930542\n",
      "Train Epoch: 2689 [45568/60000 (76%)] Loss: -1489.623047\n",
      "Train Epoch: 2689 [56832/60000 (95%)] Loss: -1547.916260\n",
      "    epoch          : 2689\n",
      "    loss           : -1445.1455988479872\n",
      "Train Epoch: 2690 [512/60000 (1%)] Loss: -1410.951172\n",
      "Train Epoch: 2690 [11776/60000 (20%)] Loss: -1542.661987\n",
      "Train Epoch: 2690 [23040/60000 (38%)] Loss: -1411.614624\n",
      "Train Epoch: 2690 [34304/60000 (57%)] Loss: -1376.792358\n",
      "Train Epoch: 2690 [45568/60000 (76%)] Loss: -1544.130615\n",
      "Train Epoch: 2690 [56832/60000 (95%)] Loss: -1505.747192\n",
      "    epoch          : 2690\n",
      "    loss           : -1459.0746297890182\n",
      "Train Epoch: 2691 [512/60000 (1%)] Loss: -1391.071533\n",
      "Train Epoch: 2691 [11776/60000 (20%)] Loss: -1508.065796\n",
      "Train Epoch: 2691 [23040/60000 (38%)] Loss: -1450.562744\n",
      "Train Epoch: 2691 [34304/60000 (57%)] Loss: -1414.782593\n",
      "Train Epoch: 2691 [45568/60000 (76%)] Loss: -1382.043823\n",
      "Train Epoch: 2691 [56832/60000 (95%)] Loss: -1559.274170\n",
      "    epoch          : 2691\n",
      "    loss           : -1457.3300243313029\n",
      "Train Epoch: 2692 [512/60000 (1%)] Loss: -1556.855957\n",
      "Train Epoch: 2692 [11776/60000 (20%)] Loss: -1498.440186\n",
      "Train Epoch: 2692 [23040/60000 (38%)] Loss: -1540.297852\n",
      "Train Epoch: 2692 [34304/60000 (57%)] Loss: -1161.677124\n",
      "Train Epoch: 2692 [45568/60000 (76%)] Loss: -1521.861084\n",
      "Train Epoch: 2692 [56832/60000 (95%)] Loss: -1495.508057\n",
      "    epoch          : 2692\n",
      "    loss           : -1458.8039257674568\n",
      "Train Epoch: 2693 [512/60000 (1%)] Loss: -1522.028076\n",
      "Train Epoch: 2693 [11776/60000 (20%)] Loss: -1525.791260\n",
      "Train Epoch: 2693 [23040/60000 (38%)] Loss: -1283.950928\n",
      "Train Epoch: 2693 [34304/60000 (57%)] Loss: -1540.753418\n",
      "Train Epoch: 2693 [45568/60000 (76%)] Loss: -1497.708740\n",
      "Train Epoch: 2693 [56832/60000 (95%)] Loss: -1449.462158\n",
      "    epoch          : 2693\n",
      "    loss           : -1456.1633114572298\n",
      "Train Epoch: 2694 [512/60000 (1%)] Loss: -1387.934204\n",
      "Train Epoch: 2694 [11776/60000 (20%)] Loss: -1370.956055\n",
      "Train Epoch: 2694 [23040/60000 (38%)] Loss: -1565.874878\n",
      "Train Epoch: 2694 [34304/60000 (57%)] Loss: -1528.868408\n",
      "Train Epoch: 2694 [45568/60000 (76%)] Loss: -1351.054077\n",
      "Train Epoch: 2694 [56832/60000 (95%)] Loss: -1469.728271\n",
      "    epoch          : 2694\n",
      "    loss           : -1454.978308381334\n",
      "Train Epoch: 2695 [512/60000 (1%)] Loss: -1316.195068\n",
      "Train Epoch: 2695 [11776/60000 (20%)] Loss: -1423.466797\n",
      "Train Epoch: 2695 [23040/60000 (38%)] Loss: -1512.195312\n",
      "Train Epoch: 2695 [34304/60000 (57%)] Loss: -1530.106812\n",
      "Train Epoch: 2695 [45568/60000 (76%)] Loss: -1276.427979\n",
      "Train Epoch: 2695 [56832/60000 (95%)] Loss: -1435.911133\n",
      "    epoch          : 2695\n",
      "    loss           : -1462.4803377140713\n",
      "Train Epoch: 2696 [512/60000 (1%)] Loss: -1433.179688\n",
      "Train Epoch: 2696 [11776/60000 (20%)] Loss: -1484.031860\n",
      "Train Epoch: 2696 [23040/60000 (38%)] Loss: -1415.721558\n",
      "Train Epoch: 2696 [34304/60000 (57%)] Loss: -1433.343140\n",
      "Train Epoch: 2696 [45568/60000 (76%)] Loss: -1519.479492\n",
      "Train Epoch: 2696 [56832/60000 (95%)] Loss: -1436.843872\n",
      "    epoch          : 2696\n",
      "    loss           : -1451.415755622131\n",
      "Train Epoch: 2697 [512/60000 (1%)] Loss: -1348.457520\n",
      "Train Epoch: 2697 [11776/60000 (20%)] Loss: -1281.453369\n",
      "Train Epoch: 2697 [23040/60000 (38%)] Loss: -1487.219360\n",
      "Train Epoch: 2697 [34304/60000 (57%)] Loss: -1456.129028\n",
      "Train Epoch: 2697 [45568/60000 (76%)] Loss: -1464.870605\n",
      "Train Epoch: 2697 [56832/60000 (95%)] Loss: -1551.936890\n",
      "    epoch          : 2697\n",
      "    loss           : -1459.1332697464247\n",
      "Train Epoch: 2698 [512/60000 (1%)] Loss: -1479.065918\n",
      "Train Epoch: 2698 [11776/60000 (20%)] Loss: -1438.281616\n",
      "Train Epoch: 2698 [23040/60000 (38%)] Loss: -1554.148926\n",
      "Train Epoch: 2698 [34304/60000 (57%)] Loss: -1326.293213\n",
      "Train Epoch: 2698 [45568/60000 (76%)] Loss: -1350.168945\n",
      "Train Epoch: 2698 [56832/60000 (95%)] Loss: -1423.740723\n",
      "    epoch          : 2698\n",
      "    loss           : -1457.7724609375\n",
      "Train Epoch: 2699 [512/60000 (1%)] Loss: -1491.025635\n",
      "Train Epoch: 2699 [11776/60000 (20%)] Loss: -1419.510742\n",
      "Train Epoch: 2699 [23040/60000 (38%)] Loss: -1514.808350\n",
      "Train Epoch: 2699 [34304/60000 (57%)] Loss: -1480.446777\n",
      "Train Epoch: 2699 [45568/60000 (76%)] Loss: -1570.712036\n",
      "Train Epoch: 2699 [56832/60000 (95%)] Loss: -1564.362305\n",
      "    epoch          : 2699\n",
      "    loss           : -1454.934681348208\n",
      "Train Epoch: 2700 [512/60000 (1%)] Loss: -1518.064087\n",
      "Train Epoch: 2700 [11776/60000 (20%)] Loss: -1476.485962\n",
      "Train Epoch: 2700 [23040/60000 (38%)] Loss: -1232.081787\n",
      "Train Epoch: 2700 [34304/60000 (57%)] Loss: -1448.374023\n",
      "Train Epoch: 2700 [45568/60000 (76%)] Loss: -1565.700195\n",
      "Train Epoch: 2700 [56832/60000 (95%)] Loss: -1378.611450\n",
      "    epoch          : 2700\n",
      "    loss           : -1459.2561500678628\n",
      "Saving checkpoint: saved/models/Mnist_DeepGenerativeOperad/0127_111843/checkpoint-epoch2700.pth ...\n",
      "Train Epoch: 2701 [512/60000 (1%)] Loss: -1554.344727\n",
      "Train Epoch: 2701 [11776/60000 (20%)] Loss: -1524.757935\n",
      "Train Epoch: 2701 [23040/60000 (38%)] Loss: -1553.691528\n",
      "Train Epoch: 2701 [34304/60000 (57%)] Loss: -1381.390991\n",
      "Train Epoch: 2701 [45568/60000 (76%)] Loss: -1565.761963\n",
      "Train Epoch: 2701 [56832/60000 (95%)] Loss: -1567.276123\n",
      "    epoch          : 2701\n",
      "    loss           : -1464.930120263396\n",
      "Train Epoch: 2702 [512/60000 (1%)] Loss: -1542.697021\n",
      "Train Epoch: 2702 [11776/60000 (20%)] Loss: -1528.470825\n",
      "Train Epoch: 2702 [23040/60000 (38%)] Loss: -1565.571411\n",
      "Train Epoch: 2702 [34304/60000 (57%)] Loss: -1533.879272\n",
      "Train Epoch: 2702 [45568/60000 (76%)] Loss: -1306.632446\n",
      "Train Epoch: 2702 [56832/60000 (95%)] Loss: -1464.210815\n",
      "    epoch          : 2702\n",
      "    loss           : -1455.1428095068636\n",
      "Train Epoch: 2703 [512/60000 (1%)] Loss: -1396.100220\n",
      "Train Epoch: 2703 [11776/60000 (20%)] Loss: -1421.332275\n",
      "Train Epoch: 2703 [23040/60000 (38%)] Loss: -1515.103760\n",
      "Train Epoch: 2703 [34304/60000 (57%)] Loss: -1414.338745\n",
      "Train Epoch: 2703 [45568/60000 (76%)] Loss: -1458.005981\n",
      "Train Epoch: 2703 [56832/60000 (95%)] Loss: -1435.696899\n",
      "    epoch          : 2703\n",
      "    loss           : -1443.477013884291\n",
      "Train Epoch: 2704 [512/60000 (1%)] Loss: -1434.800049\n",
      "Train Epoch: 2704 [11776/60000 (20%)] Loss: -1518.997681\n",
      "Train Epoch: 2704 [23040/60000 (38%)] Loss: -1456.992798\n",
      "Train Epoch: 2704 [34304/60000 (57%)] Loss: -1418.306885\n",
      "Train Epoch: 2704 [45568/60000 (76%)] Loss: -1540.568481\n",
      "Train Epoch: 2704 [56832/60000 (95%)] Loss: -1568.435547\n",
      "    epoch          : 2704\n",
      "    loss           : -1466.612633311816\n",
      "Train Epoch: 2705 [512/60000 (1%)] Loss: -1268.400024\n",
      "Train Epoch: 2705 [11776/60000 (20%)] Loss: -1455.020020\n",
      "Train Epoch: 2705 [23040/60000 (38%)] Loss: -1476.539307\n",
      "Train Epoch: 2705 [34304/60000 (57%)] Loss: -1287.038330\n",
      "Train Epoch: 2705 [45568/60000 (76%)] Loss: -1091.892334\n",
      "Train Epoch: 2705 [56832/60000 (95%)] Loss: -1389.224365\n",
      "    epoch          : 2705\n",
      "    loss           : -1433.253573832539\n",
      "Train Epoch: 2706 [512/60000 (1%)] Loss: -1532.252197\n",
      "Train Epoch: 2706 [11776/60000 (20%)] Loss: -1512.307251\n",
      "Train Epoch: 2706 [23040/60000 (38%)] Loss: -1436.726807\n",
      "Train Epoch: 2706 [34304/60000 (57%)] Loss: -1543.898804\n",
      "Train Epoch: 2706 [45568/60000 (76%)] Loss: -1567.276367\n",
      "Train Epoch: 2706 [56832/60000 (95%)] Loss: -1542.387695\n",
      "    epoch          : 2706\n",
      "    loss           : -1455.9695372500662\n",
      "Train Epoch: 2707 [512/60000 (1%)] Loss: -1399.774048\n",
      "Train Epoch: 2707 [11776/60000 (20%)] Loss: -1552.718506\n",
      "Train Epoch: 2707 [23040/60000 (38%)] Loss: -1487.544312\n",
      "Train Epoch: 2707 [34304/60000 (57%)] Loss: -1469.056152\n",
      "Train Epoch: 2707 [45568/60000 (76%)] Loss: -1310.769531\n",
      "Train Epoch: 2707 [56832/60000 (95%)] Loss: -1432.316406\n",
      "    epoch          : 2707\n",
      "    loss           : -1442.127466923773\n",
      "Train Epoch: 2708 [512/60000 (1%)] Loss: -1390.840698\n",
      "Train Epoch: 2708 [11776/60000 (20%)] Loss: -1466.775024\n",
      "Train Epoch: 2708 [23040/60000 (38%)] Loss: -1319.911377\n",
      "Train Epoch: 2708 [34304/60000 (57%)] Loss: -1542.736084\n",
      "Train Epoch: 2708 [45568/60000 (76%)] Loss: -1434.598389\n",
      "Train Epoch: 2708 [56832/60000 (95%)] Loss: -1509.027100\n",
      "    epoch          : 2708\n",
      "    loss           : -1445.1726560431011\n",
      "Train Epoch: 2709 [512/60000 (1%)] Loss: -1462.872314\n",
      "Train Epoch: 2709 [11776/60000 (20%)] Loss: -1512.999023\n",
      "Train Epoch: 2709 [23040/60000 (38%)] Loss: -1371.732422\n",
      "Train Epoch: 2709 [34304/60000 (57%)] Loss: -1515.704834\n",
      "Train Epoch: 2709 [45568/60000 (76%)] Loss: -1434.635986\n",
      "Train Epoch: 2709 [56832/60000 (95%)] Loss: -1459.315430\n",
      "    epoch          : 2709\n",
      "    loss           : -1459.7415154236185\n",
      "Train Epoch: 2710 [512/60000 (1%)] Loss: -1498.282715\n",
      "Train Epoch: 2710 [11776/60000 (20%)] Loss: -1405.072876\n",
      "Train Epoch: 2710 [23040/60000 (38%)] Loss: -1319.142212\n",
      "Train Epoch: 2710 [34304/60000 (57%)] Loss: -1370.648193\n",
      "Train Epoch: 2710 [45568/60000 (76%)] Loss: -1382.385620\n",
      "Train Epoch: 2710 [56832/60000 (95%)] Loss: -1498.673096\n",
      "    epoch          : 2710\n",
      "    loss           : -1438.4573084944386\n",
      "Train Epoch: 2711 [512/60000 (1%)] Loss: -1550.084106\n",
      "Train Epoch: 2711 [11776/60000 (20%)] Loss: -1555.634888\n",
      "Train Epoch: 2711 [23040/60000 (38%)] Loss: -1396.477539\n",
      "Train Epoch: 2711 [34304/60000 (57%)] Loss: -1380.891846\n",
      "Train Epoch: 2711 [45568/60000 (76%)] Loss: -1331.176514\n",
      "Train Epoch: 2711 [56832/60000 (95%)] Loss: -1499.599487\n",
      "    epoch          : 2711\n",
      "    loss           : -1463.2030956893318\n",
      "Train Epoch: 2712 [512/60000 (1%)] Loss: -1402.265259\n",
      "Train Epoch: 2712 [11776/60000 (20%)] Loss: -1497.143066\n",
      "Train Epoch: 2712 [23040/60000 (38%)] Loss: -1493.346802\n",
      "Train Epoch: 2712 [34304/60000 (57%)] Loss: -1481.281860\n",
      "Train Epoch: 2712 [45568/60000 (76%)] Loss: -1529.383789\n",
      "Train Epoch: 2712 [56832/60000 (95%)] Loss: -1508.432495\n",
      "    epoch          : 2712\n",
      "    loss           : -1471.9654909985215\n",
      "Train Epoch: 2713 [512/60000 (1%)] Loss: -1435.844971\n",
      "Train Epoch: 2713 [11776/60000 (20%)] Loss: -1512.266602\n",
      "Train Epoch: 2713 [23040/60000 (38%)] Loss: -1570.698242\n",
      "Train Epoch: 2713 [34304/60000 (57%)] Loss: -1497.133545\n",
      "Train Epoch: 2713 [45568/60000 (76%)] Loss: -1588.098389\n",
      "Train Epoch: 2713 [56832/60000 (95%)] Loss: -1572.537109\n",
      "    epoch          : 2713\n",
      "    loss           : -1459.8375564833818\n",
      "Train Epoch: 2714 [512/60000 (1%)] Loss: -1396.557983\n",
      "Train Epoch: 2714 [11776/60000 (20%)] Loss: -1540.477539\n",
      "Train Epoch: 2714 [23040/60000 (38%)] Loss: -1478.013184\n",
      "Train Epoch: 2714 [34304/60000 (57%)] Loss: -1540.535400\n",
      "Train Epoch: 2714 [45568/60000 (76%)] Loss: -1524.880249\n",
      "Train Epoch: 2714 [56832/60000 (95%)] Loss: -1426.892334\n",
      "    epoch          : 2714\n",
      "    loss           : -1456.324810135836\n",
      "Train Epoch: 2715 [512/60000 (1%)] Loss: -1360.500977\n",
      "Train Epoch: 2715 [11776/60000 (20%)] Loss: -1581.793945\n",
      "Train Epoch: 2715 [23040/60000 (38%)] Loss: -1501.137207\n",
      "Train Epoch: 2715 [34304/60000 (57%)] Loss: -1490.758179\n",
      "Train Epoch: 2715 [45568/60000 (76%)] Loss: -1523.556763\n",
      "Train Epoch: 2715 [56832/60000 (95%)] Loss: -1348.535156\n",
      "    epoch          : 2715\n",
      "    loss           : -1449.1371349614892\n",
      "Train Epoch: 2716 [512/60000 (1%)] Loss: -1267.097168\n",
      "Train Epoch: 2716 [11776/60000 (20%)] Loss: -1561.273438\n",
      "Train Epoch: 2716 [23040/60000 (38%)] Loss: -1386.670044\n",
      "Train Epoch: 2716 [34304/60000 (57%)] Loss: -1472.146240\n",
      "Train Epoch: 2716 [45568/60000 (76%)] Loss: -1507.291748\n",
      "Train Epoch: 2716 [56832/60000 (95%)] Loss: -1349.256104\n",
      "    epoch          : 2716\n",
      "    loss           : -1463.204035354873\n",
      "Train Epoch: 2717 [512/60000 (1%)] Loss: -1429.032715\n",
      "Train Epoch: 2717 [11776/60000 (20%)] Loss: -1308.089966\n",
      "Train Epoch: 2717 [23040/60000 (38%)] Loss: -1548.775146\n",
      "Train Epoch: 2717 [34304/60000 (57%)] Loss: -1510.960571\n",
      "Train Epoch: 2717 [45568/60000 (76%)] Loss: -1523.324219\n",
      "Train Epoch: 2717 [56832/60000 (95%)] Loss: -1390.951538\n",
      "    epoch          : 2717\n",
      "    loss           : -1448.2291752874514\n",
      "Train Epoch: 2718 [512/60000 (1%)] Loss: -1484.987061\n",
      "Train Epoch: 2718 [11776/60000 (20%)] Loss: -1442.876221\n",
      "Train Epoch: 2718 [23040/60000 (38%)] Loss: -1452.183594\n",
      "Train Epoch: 2718 [34304/60000 (57%)] Loss: -1548.233032\n",
      "Train Epoch: 2718 [45568/60000 (76%)] Loss: -1510.320557\n",
      "Train Epoch: 2718 [56832/60000 (95%)] Loss: -1432.548584\n",
      "    epoch          : 2718\n",
      "    loss           : -1453.6778002377957\n",
      "Train Epoch: 2719 [512/60000 (1%)] Loss: -1443.532593\n",
      "Train Epoch: 2719 [11776/60000 (20%)] Loss: -1207.785278\n",
      "Train Epoch: 2719 [23040/60000 (38%)] Loss: -1586.457520\n",
      "Train Epoch: 2719 [34304/60000 (57%)] Loss: -1351.596313\n",
      "Train Epoch: 2719 [45568/60000 (76%)] Loss: -1314.985840\n",
      "Train Epoch: 2719 [56832/60000 (95%)] Loss: -1588.443359\n",
      "    epoch          : 2719\n",
      "    loss           : -1456.8591729288048\n",
      "Train Epoch: 2720 [512/60000 (1%)] Loss: -1353.367554\n",
      "Train Epoch: 2720 [11776/60000 (20%)] Loss: -1367.532227\n",
      "Train Epoch: 2720 [23040/60000 (38%)] Loss: -1499.681152\n",
      "Train Epoch: 2720 [34304/60000 (57%)] Loss: -1444.691528\n",
      "Train Epoch: 2720 [45568/60000 (76%)] Loss: -1412.509521\n",
      "Train Epoch: 2720 [56832/60000 (95%)] Loss: -1381.720581\n",
      "    epoch          : 2720\n",
      "    loss           : -1464.3059185480668\n",
      "Train Epoch: 2721 [512/60000 (1%)] Loss: -1507.574341\n",
      "Train Epoch: 2721 [11776/60000 (20%)] Loss: -1531.653076\n",
      "Train Epoch: 2721 [23040/60000 (38%)] Loss: -1446.855225\n",
      "Train Epoch: 2721 [34304/60000 (57%)] Loss: -1569.047485\n",
      "Train Epoch: 2721 [45568/60000 (76%)] Loss: -1392.400391\n",
      "Train Epoch: 2721 [56832/60000 (95%)] Loss: -1578.697754\n",
      "    epoch          : 2721\n",
      "    loss           : -1455.836305090263\n",
      "Train Epoch: 2722 [512/60000 (1%)] Loss: -1389.991089\n",
      "Train Epoch: 2722 [11776/60000 (20%)] Loss: -1501.246338\n",
      "Train Epoch: 2722 [23040/60000 (38%)] Loss: -1438.186035\n",
      "Train Epoch: 2722 [34304/60000 (57%)] Loss: -1536.708618\n",
      "Train Epoch: 2722 [45568/60000 (76%)] Loss: -1406.334106\n",
      "Train Epoch: 2722 [56832/60000 (95%)] Loss: -1423.555664\n",
      "    epoch          : 2722\n",
      "    loss           : -1468.1918234959833\n",
      "Train Epoch: 2723 [512/60000 (1%)] Loss: -1523.932861\n",
      "Train Epoch: 2723 [11776/60000 (20%)] Loss: -1463.150757\n",
      "Train Epoch: 2723 [23040/60000 (38%)] Loss: -1559.316406\n",
      "Train Epoch: 2723 [34304/60000 (57%)] Loss: -1398.452637\n",
      "Train Epoch: 2723 [45568/60000 (76%)] Loss: -1456.389282\n",
      "Train Epoch: 2723 [56832/60000 (95%)] Loss: -1593.461060\n",
      "    epoch          : 2723\n",
      "    loss           : -1451.3963888567048\n",
      "Train Epoch: 2724 [512/60000 (1%)] Loss: -1599.627930\n",
      "Train Epoch: 2724 [11776/60000 (20%)] Loss: -1462.297363\n",
      "Train Epoch: 2724 [23040/60000 (38%)] Loss: -1426.350952\n",
      "Train Epoch: 2724 [34304/60000 (57%)] Loss: -1498.879517\n",
      "Train Epoch: 2724 [45568/60000 (76%)] Loss: -1392.233887\n",
      "Train Epoch: 2724 [56832/60000 (95%)] Loss: -1413.915527\n",
      "    epoch          : 2724\n",
      "    loss           : -1469.5975048690193\n",
      "Train Epoch: 2725 [512/60000 (1%)] Loss: -1531.094849\n",
      "Train Epoch: 2725 [11776/60000 (20%)] Loss: -1474.514526\n",
      "Train Epoch: 2725 [23040/60000 (38%)] Loss: -1499.571777\n",
      "Train Epoch: 2725 [34304/60000 (57%)] Loss: -1310.247314\n",
      "Train Epoch: 2725 [45568/60000 (76%)] Loss: -1594.014893\n",
      "Train Epoch: 2725 [56832/60000 (95%)] Loss: -1294.964722\n",
      "    epoch          : 2725\n",
      "    loss           : -1459.1238303319208\n",
      "Train Epoch: 2726 [512/60000 (1%)] Loss: -1378.749146\n",
      "Train Epoch: 2726 [11776/60000 (20%)] Loss: -1547.266357\n",
      "Train Epoch: 2726 [23040/60000 (38%)] Loss: -1538.780273\n",
      "Train Epoch: 2726 [34304/60000 (57%)] Loss: -1516.339111\n",
      "Train Epoch: 2726 [45568/60000 (76%)] Loss: -1574.412109\n",
      "Train Epoch: 2726 [56832/60000 (95%)] Loss: -1268.540527\n",
      "    epoch          : 2726\n",
      "    loss           : -1467.8394137452551\n",
      "Train Epoch: 2727 [512/60000 (1%)] Loss: -1563.757080\n",
      "Train Epoch: 2727 [11776/60000 (20%)] Loss: -1258.519775\n",
      "Train Epoch: 2727 [23040/60000 (38%)] Loss: -1485.808838\n",
      "Train Epoch: 2727 [34304/60000 (57%)] Loss: -1425.424072\n",
      "Train Epoch: 2727 [45568/60000 (76%)] Loss: -1587.335205\n",
      "Train Epoch: 2727 [56832/60000 (95%)] Loss: -1561.195068\n",
      "    epoch          : 2727\n",
      "    loss           : -1451.7789013533943\n",
      "Train Epoch: 2728 [512/60000 (1%)] Loss: -1550.735229\n",
      "Train Epoch: 2728 [11776/60000 (20%)] Loss: -1500.426514\n",
      "Train Epoch: 2728 [23040/60000 (38%)] Loss: -1507.343994\n",
      "Train Epoch: 2728 [34304/60000 (57%)] Loss: -1445.279175\n",
      "Train Epoch: 2728 [45568/60000 (76%)] Loss: -1472.039551\n",
      "Train Epoch: 2728 [56832/60000 (95%)] Loss: -1464.596313\n",
      "    epoch          : 2728\n",
      "    loss           : -1466.9081820902852\n",
      "Train Epoch: 2729 [512/60000 (1%)] Loss: -1573.878052\n",
      "Train Epoch: 2729 [11776/60000 (20%)] Loss: -1528.247559\n",
      "Train Epoch: 2729 [23040/60000 (38%)] Loss: -1423.548706\n",
      "Train Epoch: 2729 [34304/60000 (57%)] Loss: -1540.200439\n",
      "Train Epoch: 2729 [45568/60000 (76%)] Loss: -1555.712158\n",
      "Train Epoch: 2729 [56832/60000 (95%)] Loss: -1475.643188\n",
      "    epoch          : 2729\n",
      "    loss           : -1467.5139173949506\n",
      "Train Epoch: 2730 [512/60000 (1%)] Loss: -1472.175903\n",
      "Train Epoch: 2730 [11776/60000 (20%)] Loss: -1461.811768\n",
      "Train Epoch: 2730 [23040/60000 (38%)] Loss: -1410.244995\n",
      "Train Epoch: 2730 [34304/60000 (57%)] Loss: -1497.022949\n",
      "Train Epoch: 2730 [45568/60000 (76%)] Loss: -1470.538818\n",
      "Train Epoch: 2730 [56832/60000 (95%)] Loss: -1391.012085\n",
      "    epoch          : 2730\n",
      "    loss           : -1449.1024473373498\n",
      "Train Epoch: 2731 [512/60000 (1%)] Loss: -1485.376831\n",
      "Train Epoch: 2731 [11776/60000 (20%)] Loss: -1546.697754\n",
      "Train Epoch: 2731 [23040/60000 (38%)] Loss: -1299.814209\n",
      "Train Epoch: 2731 [34304/60000 (57%)] Loss: -1575.903198\n",
      "Train Epoch: 2731 [45568/60000 (76%)] Loss: -1505.667847\n",
      "Train Epoch: 2731 [56832/60000 (95%)] Loss: -1493.057129\n",
      "    epoch          : 2731\n",
      "    loss           : -1463.209270929886\n",
      "Train Epoch: 2732 [512/60000 (1%)] Loss: -1549.913086\n",
      "Train Epoch: 2732 [11776/60000 (20%)] Loss: -1397.217773\n",
      "Train Epoch: 2732 [23040/60000 (38%)] Loss: -1505.676270\n",
      "Train Epoch: 2732 [34304/60000 (57%)] Loss: -1393.653198\n",
      "Train Epoch: 2732 [45568/60000 (76%)] Loss: -1481.997070\n",
      "Train Epoch: 2732 [56832/60000 (95%)] Loss: -1538.528809\n",
      "    epoch          : 2732\n",
      "    loss           : -1462.6300741939222\n",
      "Train Epoch: 2733 [512/60000 (1%)] Loss: -1483.205200\n",
      "Train Epoch: 2733 [11776/60000 (20%)] Loss: -1528.171021\n",
      "Train Epoch: 2733 [23040/60000 (38%)] Loss: -1216.333496\n",
      "Train Epoch: 2733 [34304/60000 (57%)] Loss: -1494.614746\n",
      "Train Epoch: 2733 [45568/60000 (76%)] Loss: -1471.648071\n",
      "Train Epoch: 2733 [56832/60000 (95%)] Loss: -1464.982788\n",
      "    epoch          : 2733\n",
      "    loss           : -1451.282016905014\n",
      "Train Epoch: 2734 [512/60000 (1%)] Loss: -1396.157227\n",
      "Train Epoch: 2734 [11776/60000 (20%)] Loss: -1533.243530\n",
      "Train Epoch: 2734 [23040/60000 (38%)] Loss: -1437.696289\n",
      "Train Epoch: 2734 [34304/60000 (57%)] Loss: -1486.291382\n",
      "Train Epoch: 2734 [45568/60000 (76%)] Loss: -1495.678467\n",
      "Train Epoch: 2734 [56832/60000 (95%)] Loss: -1465.100586\n",
      "    epoch          : 2734\n",
      "    loss           : -1458.38415837692\n",
      "Train Epoch: 2735 [512/60000 (1%)] Loss: -1563.137207\n",
      "Train Epoch: 2735 [11776/60000 (20%)] Loss: -1396.519775\n",
      "Train Epoch: 2735 [23040/60000 (38%)] Loss: -1504.783569\n",
      "Train Epoch: 2735 [34304/60000 (57%)] Loss: -1386.315430\n",
      "Train Epoch: 2735 [45568/60000 (76%)] Loss: -1475.523438\n",
      "Train Epoch: 2735 [56832/60000 (95%)] Loss: -1149.168945\n",
      "    epoch          : 2735\n",
      "    loss           : -1458.1947011139434\n",
      "Train Epoch: 2736 [512/60000 (1%)] Loss: -1294.757324\n",
      "Train Epoch: 2736 [11776/60000 (20%)] Loss: -1374.468262\n",
      "Train Epoch: 2736 [23040/60000 (38%)] Loss: -1559.399170\n",
      "Train Epoch: 2736 [34304/60000 (57%)] Loss: -1517.813232\n",
      "Train Epoch: 2736 [45568/60000 (76%)] Loss: -1391.332764\n",
      "Train Epoch: 2736 [56832/60000 (95%)] Loss: -1489.010132\n",
      "    epoch          : 2736\n",
      "    loss           : -1455.125561385505\n",
      "Train Epoch: 2737 [512/60000 (1%)] Loss: -1355.523315\n",
      "Train Epoch: 2737 [11776/60000 (20%)] Loss: -1420.488037\n",
      "Train Epoch: 2737 [23040/60000 (38%)] Loss: -1598.309326\n",
      "Train Epoch: 2737 [34304/60000 (57%)] Loss: -1519.716797\n",
      "Train Epoch: 2737 [45568/60000 (76%)] Loss: -1480.144531\n",
      "Train Epoch: 2737 [56832/60000 (95%)] Loss: -1481.777832\n",
      "    epoch          : 2737\n",
      "    loss           : -1477.6024407855534\n",
      "Train Epoch: 2738 [512/60000 (1%)] Loss: -1503.917725\n",
      "Train Epoch: 2738 [11776/60000 (20%)] Loss: -1515.129272\n",
      "Train Epoch: 2738 [23040/60000 (38%)] Loss: -1428.428955\n",
      "Train Epoch: 2738 [34304/60000 (57%)] Loss: -1403.089355\n",
      "Train Epoch: 2738 [45568/60000 (76%)] Loss: -1549.282227\n",
      "Train Epoch: 2738 [56832/60000 (95%)] Loss: -1436.879639\n",
      "    epoch          : 2738\n",
      "    loss           : -1459.7873207566427\n",
      "Train Epoch: 2739 [512/60000 (1%)] Loss: -1550.818115\n",
      "Train Epoch: 2739 [11776/60000 (20%)] Loss: -1469.368530\n",
      "Train Epoch: 2739 [23040/60000 (38%)] Loss: -1414.377930\n",
      "Train Epoch: 2739 [34304/60000 (57%)] Loss: -1277.921631\n",
      "Train Epoch: 2739 [45568/60000 (76%)] Loss: -1434.803711\n",
      "Train Epoch: 2739 [56832/60000 (95%)] Loss: -1394.716309\n",
      "    epoch          : 2739\n",
      "    loss           : -1442.177282990709\n",
      "Train Epoch: 2740 [512/60000 (1%)] Loss: -1259.272461\n",
      "Train Epoch: 2740 [11776/60000 (20%)] Loss: -1530.843750\n",
      "Train Epoch: 2740 [23040/60000 (38%)] Loss: -1399.835815\n",
      "Train Epoch: 2740 [34304/60000 (57%)] Loss: -1431.761719\n",
      "Train Epoch: 2740 [45568/60000 (76%)] Loss: -1519.462891\n",
      "Train Epoch: 2740 [56832/60000 (95%)] Loss: -1430.723267\n",
      "    epoch          : 2740\n",
      "    loss           : -1465.7864566091764\n",
      "Train Epoch: 2741 [512/60000 (1%)] Loss: -1569.587402\n",
      "Train Epoch: 2741 [11776/60000 (20%)] Loss: -1435.054199\n",
      "Train Epoch: 2741 [23040/60000 (38%)] Loss: -1305.556274\n",
      "Train Epoch: 2741 [34304/60000 (57%)] Loss: -1534.384155\n",
      "Train Epoch: 2741 [45568/60000 (76%)] Loss: -1424.541992\n",
      "Train Epoch: 2741 [56832/60000 (95%)] Loss: -1591.402832\n",
      "    epoch          : 2741\n",
      "    loss           : -1467.214187191031\n",
      "Train Epoch: 2742 [512/60000 (1%)] Loss: -1496.943604\n",
      "Train Epoch: 2742 [11776/60000 (20%)] Loss: -1395.717529\n",
      "Train Epoch: 2742 [23040/60000 (38%)] Loss: -1446.444336\n",
      "Train Epoch: 2742 [34304/60000 (57%)] Loss: -1455.931274\n",
      "Train Epoch: 2742 [45568/60000 (76%)] Loss: -1561.517822\n",
      "Train Epoch: 2742 [56832/60000 (95%)] Loss: -1528.667480\n",
      "    epoch          : 2742\n",
      "    loss           : -1452.698420120498\n",
      "Train Epoch: 2743 [512/60000 (1%)] Loss: -1447.580322\n",
      "Train Epoch: 2743 [11776/60000 (20%)] Loss: -1508.760254\n",
      "Train Epoch: 2743 [23040/60000 (38%)] Loss: -1574.276245\n",
      "Train Epoch: 2743 [34304/60000 (57%)] Loss: -1215.742554\n",
      "Train Epoch: 2743 [45568/60000 (76%)] Loss: -1459.925781\n",
      "Train Epoch: 2743 [56832/60000 (95%)] Loss: -1402.808472\n",
      "    epoch          : 2743\n",
      "    loss           : -1458.347517972612\n",
      "Train Epoch: 2744 [512/60000 (1%)] Loss: -1295.440186\n",
      "Train Epoch: 2744 [11776/60000 (20%)] Loss: -1388.628174\n",
      "Train Epoch: 2744 [23040/60000 (38%)] Loss: -1425.362793\n",
      "Train Epoch: 2744 [34304/60000 (57%)] Loss: -1579.348877\n",
      "Train Epoch: 2744 [45568/60000 (76%)] Loss: -1406.712646\n",
      "Train Epoch: 2744 [56832/60000 (95%)] Loss: -1390.683838\n",
      "    epoch          : 2744\n",
      "    loss           : -1430.9709786452815\n",
      "Train Epoch: 2745 [512/60000 (1%)] Loss: -1421.009766\n",
      "Train Epoch: 2745 [11776/60000 (20%)] Loss: -1440.113403\n",
      "Train Epoch: 2745 [23040/60000 (38%)] Loss: -1299.274414\n",
      "Train Epoch: 2745 [34304/60000 (57%)] Loss: -1385.365234\n",
      "Train Epoch: 2745 [45568/60000 (76%)] Loss: -1497.516113\n",
      "Train Epoch: 2745 [56832/60000 (95%)] Loss: -1504.796021\n",
      "    epoch          : 2745\n",
      "    loss           : -1461.4691206937455\n",
      "Train Epoch: 2746 [512/60000 (1%)] Loss: -1557.190796\n",
      "Train Epoch: 2746 [11776/60000 (20%)] Loss: -1320.232910\n",
      "Train Epoch: 2746 [23040/60000 (38%)] Loss: -1528.823242\n",
      "Train Epoch: 2746 [34304/60000 (57%)] Loss: -1466.352783\n",
      "Train Epoch: 2746 [45568/60000 (76%)] Loss: -1498.772949\n",
      "Train Epoch: 2746 [56832/60000 (95%)] Loss: -1399.096924\n",
      "    epoch          : 2746\n",
      "    loss           : -1457.608043261167\n",
      "Train Epoch: 2747 [512/60000 (1%)] Loss: -1416.201416\n",
      "Train Epoch: 2747 [11776/60000 (20%)] Loss: -1486.569702\n",
      "Train Epoch: 2747 [23040/60000 (38%)] Loss: -1467.523438\n",
      "Train Epoch: 2747 [34304/60000 (57%)] Loss: -1440.347412\n",
      "Train Epoch: 2747 [45568/60000 (76%)] Loss: -1456.022827\n",
      "Train Epoch: 2747 [56832/60000 (95%)] Loss: -1518.379395\n",
      "    epoch          : 2747\n",
      "    loss           : -1456.8339495470293\n",
      "Train Epoch: 2748 [512/60000 (1%)] Loss: -1427.150879\n",
      "Train Epoch: 2748 [11776/60000 (20%)] Loss: -1419.230591\n",
      "Train Epoch: 2748 [23040/60000 (38%)] Loss: -1586.208008\n",
      "Train Epoch: 2748 [34304/60000 (57%)] Loss: -1584.266113\n",
      "Train Epoch: 2748 [45568/60000 (76%)] Loss: -1473.274048\n",
      "Train Epoch: 2748 [56832/60000 (95%)] Loss: -1587.544800\n",
      "    epoch          : 2748\n",
      "    loss           : -1455.3260918741173\n",
      "Train Epoch: 2749 [512/60000 (1%)] Loss: -1568.105957\n",
      "Train Epoch: 2749 [11776/60000 (20%)] Loss: -1378.165649\n",
      "Train Epoch: 2749 [23040/60000 (38%)] Loss: -1399.168091\n",
      "Train Epoch: 2749 [34304/60000 (57%)] Loss: -1526.210449\n",
      "Train Epoch: 2749 [45568/60000 (76%)] Loss: -1457.299683\n",
      "Train Epoch: 2749 [56832/60000 (95%)] Loss: -1547.811890\n",
      "    epoch          : 2749\n",
      "    loss           : -1466.465921692929\n",
      "Train Epoch: 2750 [512/60000 (1%)] Loss: -1542.438477\n",
      "Train Epoch: 2750 [11776/60000 (20%)] Loss: -1465.083862\n",
      "Train Epoch: 2750 [23040/60000 (38%)] Loss: -1431.801025\n",
      "Train Epoch: 2750 [34304/60000 (57%)] Loss: -1469.551270\n",
      "Train Epoch: 2750 [45568/60000 (76%)] Loss: -1544.771973\n",
      "Train Epoch: 2750 [56832/60000 (95%)] Loss: -1434.793335\n",
      "    epoch          : 2750\n",
      "    loss           : -1445.865608861891\n",
      "Train Epoch: 2751 [512/60000 (1%)] Loss: -1529.608521\n",
      "Train Epoch: 2751 [11776/60000 (20%)] Loss: -1439.730835\n",
      "Train Epoch: 2751 [23040/60000 (38%)] Loss: -1424.220459\n",
      "Train Epoch: 2751 [34304/60000 (57%)] Loss: -1551.605469\n",
      "Train Epoch: 2751 [45568/60000 (76%)] Loss: -1455.253662\n",
      "Train Epoch: 2751 [56832/60000 (95%)] Loss: -1539.760376\n",
      "    epoch          : 2751\n",
      "    loss           : -1459.8887942901438\n",
      "Train Epoch: 2752 [512/60000 (1%)] Loss: -1514.422119\n",
      "Train Epoch: 2752 [11776/60000 (20%)] Loss: -1360.749756\n",
      "Train Epoch: 2752 [23040/60000 (38%)] Loss: -1485.079224\n",
      "Train Epoch: 2752 [34304/60000 (57%)] Loss: -1376.802246\n",
      "Train Epoch: 2752 [45568/60000 (76%)] Loss: -1338.509644\n",
      "Train Epoch: 2752 [56832/60000 (95%)] Loss: -1455.040039\n",
      "    epoch          : 2752\n",
      "    loss           : -1463.83653233415\n",
      "Train Epoch: 2753 [512/60000 (1%)] Loss: -1392.314575\n",
      "Train Epoch: 2753 [11776/60000 (20%)] Loss: -1440.529785\n",
      "Train Epoch: 2753 [23040/60000 (38%)] Loss: -1330.268066\n",
      "Train Epoch: 2753 [34304/60000 (57%)] Loss: -1187.901733\n",
      "Train Epoch: 2753 [45568/60000 (76%)] Loss: -1396.238159\n",
      "Train Epoch: 2753 [56832/60000 (95%)] Loss: -1586.235840\n",
      "    epoch          : 2753\n",
      "    loss           : -1461.655405507923\n",
      "Train Epoch: 2754 [512/60000 (1%)] Loss: -1551.010010\n",
      "Train Epoch: 2754 [11776/60000 (20%)] Loss: -1553.353638\n",
      "Train Epoch: 2754 [23040/60000 (38%)] Loss: -1546.024170\n",
      "Train Epoch: 2754 [34304/60000 (57%)] Loss: -1546.066162\n",
      "Train Epoch: 2754 [45568/60000 (76%)] Loss: -1495.072754\n",
      "Train Epoch: 2754 [56832/60000 (95%)] Loss: -1442.311768\n",
      "    epoch          : 2754\n",
      "    loss           : -1455.935342389985\n",
      "Train Epoch: 2755 [512/60000 (1%)] Loss: -1367.431274\n",
      "Train Epoch: 2755 [11776/60000 (20%)] Loss: -1519.632690\n",
      "Train Epoch: 2755 [23040/60000 (38%)] Loss: -1528.963013\n",
      "Train Epoch: 2755 [34304/60000 (57%)] Loss: -1473.219849\n",
      "Train Epoch: 2755 [45568/60000 (76%)] Loss: -1512.020386\n",
      "Train Epoch: 2755 [56832/60000 (95%)] Loss: -1354.577271\n",
      "    epoch          : 2755\n",
      "    loss           : -1456.1328007757327\n",
      "Train Epoch: 2756 [512/60000 (1%)] Loss: -1440.013184\n",
      "Train Epoch: 2756 [11776/60000 (20%)] Loss: -1306.154785\n",
      "Train Epoch: 2756 [23040/60000 (38%)] Loss: -1487.370972\n",
      "Train Epoch: 2756 [34304/60000 (57%)] Loss: -1538.042480\n",
      "Train Epoch: 2756 [45568/60000 (76%)] Loss: -1560.453125\n",
      "Train Epoch: 2756 [56832/60000 (95%)] Loss: -1502.414795\n",
      "    epoch          : 2756\n",
      "    loss           : -1454.7143789172846\n",
      "Train Epoch: 2757 [512/60000 (1%)] Loss: -1528.873413\n",
      "Train Epoch: 2757 [11776/60000 (20%)] Loss: -1520.378662\n",
      "Train Epoch: 2757 [23040/60000 (38%)] Loss: -1500.948486\n",
      "Train Epoch: 2757 [34304/60000 (57%)] Loss: -1415.054321\n",
      "Train Epoch: 2757 [45568/60000 (76%)] Loss: -1261.160645\n",
      "Train Epoch: 2757 [56832/60000 (95%)] Loss: -1442.877930\n",
      "    epoch          : 2757\n",
      "    loss           : -1459.7481644625045\n",
      "Train Epoch: 2758 [512/60000 (1%)] Loss: -1385.081909\n",
      "Train Epoch: 2758 [11776/60000 (20%)] Loss: -1408.501953\n",
      "Train Epoch: 2758 [23040/60000 (38%)] Loss: -1395.538574\n",
      "Train Epoch: 2758 [34304/60000 (57%)] Loss: -1392.933105\n",
      "Train Epoch: 2758 [45568/60000 (76%)] Loss: -1415.139160\n",
      "Train Epoch: 2758 [56832/60000 (95%)] Loss: -1495.776489\n",
      "    epoch          : 2758\n",
      "    loss           : -1460.8172241900602\n",
      "Train Epoch: 2759 [512/60000 (1%)] Loss: -1418.844849\n",
      "Train Epoch: 2759 [11776/60000 (20%)] Loss: -1530.948242\n",
      "Train Epoch: 2759 [23040/60000 (38%)] Loss: -1545.006714\n",
      "Train Epoch: 2759 [34304/60000 (57%)] Loss: -1508.092285\n",
      "Train Epoch: 2759 [45568/60000 (76%)] Loss: -1397.865234\n",
      "Train Epoch: 2759 [56832/60000 (95%)] Loss: -1454.324463\n",
      "    epoch          : 2759\n",
      "    loss           : -1469.1846903138241\n",
      "Train Epoch: 2760 [512/60000 (1%)] Loss: -1523.258789\n",
      "Train Epoch: 2760 [11776/60000 (20%)] Loss: -1351.443970\n",
      "Train Epoch: 2760 [23040/60000 (38%)] Loss: -1534.385986\n",
      "Train Epoch: 2760 [34304/60000 (57%)] Loss: -1542.775146\n",
      "Train Epoch: 2760 [45568/60000 (76%)] Loss: -1529.128784\n",
      "Train Epoch: 2760 [56832/60000 (95%)] Loss: -1552.468506\n",
      "    epoch          : 2760\n",
      "    loss           : -1455.474354544602\n",
      "Train Epoch: 2761 [512/60000 (1%)] Loss: -1461.583130\n",
      "Train Epoch: 2761 [11776/60000 (20%)] Loss: -1445.148682\n",
      "Train Epoch: 2761 [23040/60000 (38%)] Loss: -1524.041260\n",
      "Train Epoch: 2761 [34304/60000 (57%)] Loss: -1512.996582\n",
      "Train Epoch: 2761 [45568/60000 (76%)] Loss: -1393.976074\n",
      "Train Epoch: 2761 [56832/60000 (95%)] Loss: -1407.167725\n",
      "    epoch          : 2761\n",
      "    loss           : -1464.0409163135594\n",
      "Train Epoch: 2762 [512/60000 (1%)] Loss: -1369.315552\n",
      "Train Epoch: 2762 [11776/60000 (20%)] Loss: -1468.061523\n",
      "Train Epoch: 2762 [23040/60000 (38%)] Loss: -1467.200928\n",
      "Train Epoch: 2762 [34304/60000 (57%)] Loss: -1530.974976\n",
      "Train Epoch: 2762 [45568/60000 (76%)] Loss: -1496.739990\n",
      "Train Epoch: 2762 [56832/60000 (95%)] Loss: -1518.449219\n",
      "    epoch          : 2762\n",
      "    loss           : -1467.742298535708\n",
      "Train Epoch: 2763 [512/60000 (1%)] Loss: -1468.415039\n",
      "Train Epoch: 2763 [11776/60000 (20%)] Loss: -1516.740112\n",
      "Train Epoch: 2763 [23040/60000 (38%)] Loss: -1287.084717\n",
      "Train Epoch: 2763 [34304/60000 (57%)] Loss: -1388.529175\n",
      "Train Epoch: 2763 [45568/60000 (76%)] Loss: -1423.475342\n",
      "Train Epoch: 2763 [56832/60000 (95%)] Loss: -1577.505737\n",
      "    epoch          : 2763\n",
      "    loss           : -1460.647465420308\n",
      "Train Epoch: 2764 [512/60000 (1%)] Loss: -1538.956299\n",
      "Train Epoch: 2764 [11776/60000 (20%)] Loss: -1426.080566\n",
      "Train Epoch: 2764 [23040/60000 (38%)] Loss: -1311.557007\n",
      "Train Epoch: 2764 [34304/60000 (57%)] Loss: -1297.384277\n",
      "Train Epoch: 2764 [45568/60000 (76%)] Loss: -1513.451416\n",
      "Train Epoch: 2764 [56832/60000 (95%)] Loss: -1462.377930\n",
      "    epoch          : 2764\n",
      "    loss           : -1462.8512700829801\n",
      "Train Epoch: 2765 [512/60000 (1%)] Loss: -1582.638428\n",
      "Train Epoch: 2765 [11776/60000 (20%)] Loss: -1370.807983\n",
      "Train Epoch: 2765 [23040/60000 (38%)] Loss: -1417.130615\n",
      "Train Epoch: 2765 [34304/60000 (57%)] Loss: -1504.493042\n",
      "Train Epoch: 2765 [45568/60000 (76%)] Loss: -1541.038086\n",
      "Train Epoch: 2765 [56832/60000 (95%)] Loss: -1583.655518\n",
      "    epoch          : 2765\n",
      "    loss           : -1452.105645993335\n",
      "Train Epoch: 2766 [512/60000 (1%)] Loss: -1449.898682\n",
      "Train Epoch: 2766 [11776/60000 (20%)] Loss: -1498.659180\n",
      "Train Epoch: 2766 [23040/60000 (38%)] Loss: -1403.699219\n",
      "Train Epoch: 2766 [34304/60000 (57%)] Loss: -1552.134644\n",
      "Train Epoch: 2766 [45568/60000 (76%)] Loss: -1461.144775\n",
      "Train Epoch: 2766 [56832/60000 (95%)] Loss: -1425.719238\n",
      "    epoch          : 2766\n",
      "    loss           : -1458.314250364142\n",
      "Train Epoch: 2767 [512/60000 (1%)] Loss: -1562.412354\n",
      "Train Epoch: 2767 [11776/60000 (20%)] Loss: -1479.056396\n",
      "Train Epoch: 2767 [23040/60000 (38%)] Loss: -1547.329346\n",
      "Train Epoch: 2767 [34304/60000 (57%)] Loss: -1541.963013\n",
      "Train Epoch: 2767 [45568/60000 (76%)] Loss: -1538.791016\n",
      "Train Epoch: 2767 [56832/60000 (95%)] Loss: -1447.328125\n",
      "    epoch          : 2767\n",
      "    loss           : -1477.7075778077551\n",
      "Train Epoch: 2768 [512/60000 (1%)] Loss: -1592.702881\n",
      "Train Epoch: 2768 [11776/60000 (20%)] Loss: -1521.568115\n",
      "Train Epoch: 2768 [23040/60000 (38%)] Loss: -1331.775757\n",
      "Train Epoch: 2768 [34304/60000 (57%)] Loss: -1553.343506\n",
      "Train Epoch: 2768 [45568/60000 (76%)] Loss: -1364.451294\n",
      "Train Epoch: 2768 [56832/60000 (95%)] Loss: -1413.458984\n",
      "    epoch          : 2768\n",
      "    loss           : -1458.2882821465616\n",
      "Train Epoch: 2769 [512/60000 (1%)] Loss: -1476.543701\n",
      "Train Epoch: 2769 [11776/60000 (20%)] Loss: -1386.433105\n",
      "Train Epoch: 2769 [23040/60000 (38%)] Loss: -1409.830811\n",
      "Train Epoch: 2769 [34304/60000 (57%)] Loss: -1371.187500\n",
      "Train Epoch: 2769 [45568/60000 (76%)] Loss: -1416.354126\n",
      "Train Epoch: 2769 [56832/60000 (95%)] Loss: -1404.536011\n",
      "    epoch          : 2769\n",
      "    loss           : -1454.969191384181\n",
      "Train Epoch: 2770 [512/60000 (1%)] Loss: -1393.850586\n",
      "Train Epoch: 2770 [11776/60000 (20%)] Loss: -1568.389648\n",
      "Train Epoch: 2770 [23040/60000 (38%)] Loss: -1464.730347\n",
      "Train Epoch: 2770 [34304/60000 (57%)] Loss: -1289.031250\n",
      "Train Epoch: 2770 [45568/60000 (76%)] Loss: -1339.621460\n",
      "Train Epoch: 2770 [56832/60000 (95%)] Loss: -1465.312256\n",
      "    epoch          : 2770\n",
      "    loss           : -1445.7736106053583\n",
      "Train Epoch: 2771 [512/60000 (1%)] Loss: -1416.087769\n",
      "Train Epoch: 2771 [11776/60000 (20%)] Loss: -1449.368896\n",
      "Train Epoch: 2771 [23040/60000 (38%)] Loss: -1431.841553\n",
      "Train Epoch: 2771 [34304/60000 (57%)] Loss: -1471.854126\n",
      "Train Epoch: 2771 [45568/60000 (76%)] Loss: -1537.526855\n",
      "Train Epoch: 2771 [56832/60000 (95%)] Loss: -1537.285034\n",
      "    epoch          : 2771\n",
      "    loss           : -1464.7243559239275\n",
      "Train Epoch: 2772 [512/60000 (1%)] Loss: -1534.459717\n",
      "Train Epoch: 2772 [11776/60000 (20%)] Loss: -1482.113892\n",
      "Train Epoch: 2772 [23040/60000 (38%)] Loss: -1421.792725\n",
      "Train Epoch: 2772 [34304/60000 (57%)] Loss: -1473.185547\n",
      "Train Epoch: 2772 [45568/60000 (76%)] Loss: -1442.580933\n",
      "Train Epoch: 2772 [56832/60000 (95%)] Loss: -1453.914062\n",
      "    epoch          : 2772\n",
      "    loss           : -1452.685191698667\n",
      "Train Epoch: 2773 [512/60000 (1%)] Loss: -1424.162964\n",
      "Train Epoch: 2773 [11776/60000 (20%)] Loss: -1467.561157\n",
      "Train Epoch: 2773 [23040/60000 (38%)] Loss: -1533.940430\n",
      "Train Epoch: 2773 [34304/60000 (57%)] Loss: -1484.921631\n",
      "Train Epoch: 2773 [45568/60000 (76%)] Loss: -1276.687134\n",
      "Train Epoch: 2773 [56832/60000 (95%)] Loss: -1341.770996\n",
      "    epoch          : 2773\n",
      "    loss           : -1461.5724625237244\n",
      "Train Epoch: 2774 [512/60000 (1%)] Loss: -1492.404663\n",
      "Train Epoch: 2774 [11776/60000 (20%)] Loss: -1484.001099\n",
      "Train Epoch: 2774 [23040/60000 (38%)] Loss: -1367.660645\n",
      "Train Epoch: 2774 [34304/60000 (57%)] Loss: -1491.458374\n",
      "Train Epoch: 2774 [45568/60000 (76%)] Loss: -1506.618042\n",
      "Train Epoch: 2774 [56832/60000 (95%)] Loss: -1359.861938\n",
      "    epoch          : 2774\n",
      "    loss           : -1462.872761354608\n",
      "Train Epoch: 2775 [512/60000 (1%)] Loss: -1581.354004\n",
      "Train Epoch: 2775 [11776/60000 (20%)] Loss: -1456.414062\n",
      "Train Epoch: 2775 [23040/60000 (38%)] Loss: -1396.768311\n",
      "Train Epoch: 2775 [34304/60000 (57%)] Loss: -1456.754272\n",
      "Train Epoch: 2775 [45568/60000 (76%)] Loss: -1188.798584\n",
      "Train Epoch: 2775 [56832/60000 (95%)] Loss: -1531.020508\n",
      "    epoch          : 2775\n",
      "    loss           : -1458.0674638478768\n",
      "Train Epoch: 2776 [512/60000 (1%)] Loss: -1464.420898\n",
      "Train Epoch: 2776 [11776/60000 (20%)] Loss: -1518.720215\n",
      "Train Epoch: 2776 [23040/60000 (38%)] Loss: -1373.997192\n",
      "Train Epoch: 2776 [34304/60000 (57%)] Loss: -1332.651367\n",
      "Train Epoch: 2776 [45568/60000 (76%)] Loss: -1369.832886\n",
      "Train Epoch: 2776 [56832/60000 (95%)] Loss: -1429.183350\n",
      "    epoch          : 2776\n",
      "    loss           : -1462.7000432418565\n",
      "Train Epoch: 2777 [512/60000 (1%)] Loss: -1563.875000\n",
      "Train Epoch: 2777 [11776/60000 (20%)] Loss: -1442.064453\n",
      "Train Epoch: 2777 [23040/60000 (38%)] Loss: -1436.977051\n",
      "Train Epoch: 2777 [34304/60000 (57%)] Loss: -1489.340454\n",
      "Train Epoch: 2777 [45568/60000 (76%)] Loss: -1530.184814\n",
      "Train Epoch: 2777 [56832/60000 (95%)] Loss: -1510.748535\n",
      "    epoch          : 2777\n",
      "    loss           : -1476.89899267854\n",
      "Train Epoch: 2778 [512/60000 (1%)] Loss: -1420.582397\n",
      "Train Epoch: 2778 [11776/60000 (20%)] Loss: -1512.447021\n",
      "Train Epoch: 2778 [23040/60000 (38%)] Loss: -1448.281616\n",
      "Train Epoch: 2778 [34304/60000 (57%)] Loss: -1412.997070\n",
      "Train Epoch: 2778 [45568/60000 (76%)] Loss: -1466.030762\n",
      "Train Epoch: 2778 [56832/60000 (95%)] Loss: -1544.566406\n",
      "    epoch          : 2778\n",
      "    loss           : -1449.4953827076713\n",
      "Train Epoch: 2779 [512/60000 (1%)] Loss: -1473.667480\n",
      "Train Epoch: 2779 [11776/60000 (20%)] Loss: -1403.561035\n",
      "Train Epoch: 2779 [23040/60000 (38%)] Loss: -1462.952148\n",
      "Train Epoch: 2779 [34304/60000 (57%)] Loss: -1403.179810\n",
      "Train Epoch: 2779 [45568/60000 (76%)] Loss: -1518.245605\n",
      "Train Epoch: 2779 [56832/60000 (95%)] Loss: -1539.766602\n",
      "    epoch          : 2779\n",
      "    loss           : -1459.7629942813162\n",
      "Train Epoch: 2780 [512/60000 (1%)] Loss: -1262.175659\n",
      "Train Epoch: 2780 [11776/60000 (20%)] Loss: -1507.808350\n",
      "Train Epoch: 2780 [23040/60000 (38%)] Loss: -1383.200317\n",
      "Train Epoch: 2780 [34304/60000 (57%)] Loss: -1475.669434\n",
      "Train Epoch: 2780 [45568/60000 (76%)] Loss: -1459.854370\n",
      "Train Epoch: 2780 [56832/60000 (95%)] Loss: -1423.251221\n",
      "    epoch          : 2780\n",
      "    loss           : -1464.943619377869\n",
      "Train Epoch: 2781 [512/60000 (1%)] Loss: -1528.614014\n",
      "Train Epoch: 2781 [11776/60000 (20%)] Loss: -1569.690796\n",
      "Train Epoch: 2781 [23040/60000 (38%)] Loss: -1505.038696\n",
      "Train Epoch: 2781 [34304/60000 (57%)] Loss: -1537.507812\n",
      "Train Epoch: 2781 [45568/60000 (76%)] Loss: -1535.430176\n",
      "Train Epoch: 2781 [56832/60000 (95%)] Loss: -1409.317627\n",
      "    epoch          : 2781\n",
      "    loss           : -1458.4500377245542\n",
      "Train Epoch: 2782 [512/60000 (1%)] Loss: -1511.563965\n",
      "Train Epoch: 2782 [11776/60000 (20%)] Loss: -1570.733521\n",
      "Train Epoch: 2782 [23040/60000 (38%)] Loss: -1499.535156\n",
      "Train Epoch: 2782 [34304/60000 (57%)] Loss: -1522.245850\n",
      "Train Epoch: 2782 [45568/60000 (76%)] Loss: -1476.833008\n",
      "Train Epoch: 2782 [56832/60000 (95%)] Loss: -1400.531128\n",
      "    epoch          : 2782\n",
      "    loss           : -1450.133167676333\n",
      "Train Epoch: 2783 [512/60000 (1%)] Loss: -1381.564087\n",
      "Train Epoch: 2783 [11776/60000 (20%)] Loss: -1570.993530\n",
      "Train Epoch: 2783 [23040/60000 (38%)] Loss: -1330.482178\n",
      "Train Epoch: 2783 [34304/60000 (57%)] Loss: -1534.101440\n",
      "Train Epoch: 2783 [45568/60000 (76%)] Loss: -1507.750977\n",
      "Train Epoch: 2783 [56832/60000 (95%)] Loss: -1427.248779\n",
      "    epoch          : 2783\n",
      "    loss           : -1472.3036302469545\n",
      "Train Epoch: 2784 [512/60000 (1%)] Loss: -1542.627319\n",
      "Train Epoch: 2784 [11776/60000 (20%)] Loss: -1461.149414\n",
      "Train Epoch: 2784 [23040/60000 (38%)] Loss: -1589.571899\n",
      "Train Epoch: 2784 [34304/60000 (57%)] Loss: -1535.304565\n",
      "Train Epoch: 2784 [45568/60000 (76%)] Loss: -1463.255493\n",
      "Train Epoch: 2784 [56832/60000 (95%)] Loss: -1287.707275\n",
      "    epoch          : 2784\n",
      "    loss           : -1472.7657525876148\n",
      "Train Epoch: 2785 [512/60000 (1%)] Loss: -1420.230713\n",
      "Train Epoch: 2785 [11776/60000 (20%)] Loss: -1413.046631\n",
      "Train Epoch: 2785 [23040/60000 (38%)] Loss: -1285.111084\n",
      "Train Epoch: 2785 [34304/60000 (57%)] Loss: -1437.406372\n",
      "Train Epoch: 2785 [45568/60000 (76%)] Loss: -1478.564087\n",
      "Train Epoch: 2785 [56832/60000 (95%)] Loss: -1387.610352\n",
      "    epoch          : 2785\n",
      "    loss           : -1468.4444269729872\n",
      "Train Epoch: 2786 [512/60000 (1%)] Loss: -1565.504150\n",
      "Train Epoch: 2786 [11776/60000 (20%)] Loss: -1436.100342\n",
      "Train Epoch: 2786 [23040/60000 (38%)] Loss: -1474.739380\n",
      "Train Epoch: 2786 [34304/60000 (57%)] Loss: -1499.753662\n",
      "Train Epoch: 2786 [45568/60000 (76%)] Loss: -1367.217407\n",
      "Train Epoch: 2786 [56832/60000 (95%)] Loss: -1493.349731\n",
      "    epoch          : 2786\n",
      "    loss           : -1467.7956977456304\n",
      "Train Epoch: 2787 [512/60000 (1%)] Loss: -1501.654785\n",
      "Train Epoch: 2787 [11776/60000 (20%)] Loss: -1397.993652\n",
      "Train Epoch: 2787 [23040/60000 (38%)] Loss: -1463.199951\n",
      "Train Epoch: 2787 [34304/60000 (57%)] Loss: -1248.438721\n",
      "Train Epoch: 2787 [45568/60000 (76%)] Loss: -1433.884399\n",
      "Train Epoch: 2787 [56832/60000 (95%)] Loss: -1338.515991\n",
      "    epoch          : 2787\n",
      "    loss           : -1454.3950991873014\n",
      "Train Epoch: 2788 [512/60000 (1%)] Loss: -1530.296021\n",
      "Train Epoch: 2788 [11776/60000 (20%)] Loss: -1546.253174\n",
      "Train Epoch: 2788 [23040/60000 (38%)] Loss: -1495.989258\n",
      "Train Epoch: 2788 [34304/60000 (57%)] Loss: -1517.517700\n",
      "Train Epoch: 2788 [45568/60000 (76%)] Loss: -1426.401611\n",
      "Train Epoch: 2788 [56832/60000 (95%)] Loss: -1415.229248\n",
      "    epoch          : 2788\n",
      "    loss           : -1465.7668891518804\n",
      "Train Epoch: 2789 [512/60000 (1%)] Loss: -1483.965088\n",
      "Train Epoch: 2789 [11776/60000 (20%)] Loss: -1530.338257\n",
      "Train Epoch: 2789 [23040/60000 (38%)] Loss: -1580.403076\n",
      "Train Epoch: 2789 [34304/60000 (57%)] Loss: -1404.788330\n",
      "Train Epoch: 2789 [45568/60000 (76%)] Loss: -1498.402954\n",
      "Train Epoch: 2789 [56832/60000 (95%)] Loss: -1426.755737\n",
      "    epoch          : 2789\n",
      "    loss           : -1459.7619632354563\n",
      "Train Epoch: 2790 [512/60000 (1%)] Loss: -1446.609985\n",
      "Train Epoch: 2790 [11776/60000 (20%)] Loss: -1448.324585\n",
      "Train Epoch: 2790 [23040/60000 (38%)] Loss: -1489.680176\n",
      "Train Epoch: 2790 [34304/60000 (57%)] Loss: -1518.031372\n",
      "Train Epoch: 2790 [45568/60000 (76%)] Loss: -1427.972412\n",
      "Train Epoch: 2790 [56832/60000 (95%)] Loss: -1319.624146\n",
      "    epoch          : 2790\n",
      "    loss           : -1458.6810999293784\n",
      "Train Epoch: 2791 [512/60000 (1%)] Loss: -1442.279297\n",
      "Train Epoch: 2791 [11776/60000 (20%)] Loss: -1483.057129\n",
      "Train Epoch: 2791 [23040/60000 (38%)] Loss: -1394.931152\n",
      "Train Epoch: 2791 [34304/60000 (57%)] Loss: -1341.617188\n",
      "Train Epoch: 2791 [45568/60000 (76%)] Loss: -1368.528076\n",
      "Train Epoch: 2791 [56832/60000 (95%)] Loss: -1457.950195\n",
      "    epoch          : 2791\n",
      "    loss           : -1451.8794145314705\n",
      "Train Epoch: 2792 [512/60000 (1%)] Loss: -1458.151733\n",
      "Train Epoch: 2792 [11776/60000 (20%)] Loss: -1556.352539\n",
      "Train Epoch: 2792 [23040/60000 (38%)] Loss: -1448.690796\n",
      "Train Epoch: 2792 [34304/60000 (57%)] Loss: -1538.799683\n",
      "Train Epoch: 2792 [45568/60000 (76%)] Loss: -1489.389160\n",
      "Train Epoch: 2792 [56832/60000 (95%)] Loss: -1447.280640\n",
      "    epoch          : 2792\n",
      "    loss           : -1470.2148678881972\n",
      "Train Epoch: 2793 [512/60000 (1%)] Loss: -1521.037964\n",
      "Train Epoch: 2793 [11776/60000 (20%)] Loss: -1412.716309\n",
      "Train Epoch: 2793 [23040/60000 (38%)] Loss: -1365.843018\n",
      "Train Epoch: 2793 [34304/60000 (57%)] Loss: -1471.327026\n",
      "Train Epoch: 2793 [45568/60000 (76%)] Loss: -1511.284058\n",
      "Train Epoch: 2793 [56832/60000 (95%)] Loss: -1329.448730\n",
      "    epoch          : 2793\n",
      "    loss           : -1467.4381758695267\n",
      "Train Epoch: 2794 [512/60000 (1%)] Loss: -1540.118774\n",
      "Train Epoch: 2794 [11776/60000 (20%)] Loss: -1396.880859\n",
      "Train Epoch: 2794 [23040/60000 (38%)] Loss: -1541.979614\n",
      "Train Epoch: 2794 [34304/60000 (57%)] Loss: -1472.492676\n",
      "Train Epoch: 2794 [45568/60000 (76%)] Loss: -1385.695435\n",
      "Train Epoch: 2794 [56832/60000 (95%)] Loss: -1410.075562\n",
      "    epoch          : 2794\n",
      "    loss           : -1467.8428282656912\n",
      "Train Epoch: 2795 [512/60000 (1%)] Loss: -1518.260132\n",
      "Train Epoch: 2795 [11776/60000 (20%)] Loss: -1417.096924\n",
      "Train Epoch: 2795 [23040/60000 (38%)] Loss: -1575.377075\n",
      "Train Epoch: 2795 [34304/60000 (57%)] Loss: -1466.089111\n",
      "Train Epoch: 2795 [45568/60000 (76%)] Loss: -1405.143677\n",
      "Train Epoch: 2795 [56832/60000 (95%)] Loss: -1425.130737\n",
      "    epoch          : 2795\n",
      "    loss           : -1467.1071846310028\n",
      "Train Epoch: 2796 [512/60000 (1%)] Loss: -1406.003418\n",
      "Train Epoch: 2796 [11776/60000 (20%)] Loss: -1374.414917\n",
      "Train Epoch: 2796 [23040/60000 (38%)] Loss: -1492.578125\n",
      "Train Epoch: 2796 [34304/60000 (57%)] Loss: -1553.180054\n",
      "Train Epoch: 2796 [45568/60000 (76%)] Loss: -1407.206665\n",
      "Train Epoch: 2796 [56832/60000 (95%)] Loss: -1543.190186\n",
      "    epoch          : 2796\n",
      "    loss           : -1465.226478016309\n",
      "Train Epoch: 2797 [512/60000 (1%)] Loss: -1465.068726\n",
      "Train Epoch: 2797 [11776/60000 (20%)] Loss: -1566.232422\n",
      "Train Epoch: 2797 [23040/60000 (38%)] Loss: -1304.039307\n",
      "Train Epoch: 2797 [34304/60000 (57%)] Loss: -1514.116943\n",
      "Train Epoch: 2797 [45568/60000 (76%)] Loss: -1477.379272\n",
      "Train Epoch: 2797 [56832/60000 (95%)] Loss: -1544.794189\n",
      "    epoch          : 2797\n",
      "    loss           : -1478.4840570654574\n",
      "Train Epoch: 2798 [512/60000 (1%)] Loss: -1544.133057\n",
      "Train Epoch: 2798 [11776/60000 (20%)] Loss: -1337.242065\n",
      "Train Epoch: 2798 [23040/60000 (38%)] Loss: -1477.421387\n",
      "Train Epoch: 2798 [34304/60000 (57%)] Loss: -1472.124756\n",
      "Train Epoch: 2798 [45568/60000 (76%)] Loss: -1503.233154\n",
      "Train Epoch: 2798 [56832/60000 (95%)] Loss: -1520.448486\n",
      "    epoch          : 2798\n",
      "    loss           : -1466.8574735997088\n",
      "Train Epoch: 2799 [512/60000 (1%)] Loss: -1419.015869\n",
      "Train Epoch: 2799 [11776/60000 (20%)] Loss: -1458.688599\n",
      "Train Epoch: 2799 [23040/60000 (38%)] Loss: -1579.086914\n",
      "Train Epoch: 2799 [34304/60000 (57%)] Loss: -1348.063110\n",
      "Train Epoch: 2799 [45568/60000 (76%)] Loss: -1491.526855\n",
      "Train Epoch: 2799 [56832/60000 (95%)] Loss: -1513.356079\n",
      "    epoch          : 2799\n",
      "    loss           : -1468.0207491944739\n",
      "Train Epoch: 2800 [512/60000 (1%)] Loss: -1473.300903\n",
      "Train Epoch: 2800 [11776/60000 (20%)] Loss: -1510.498535\n",
      "Train Epoch: 2800 [23040/60000 (38%)] Loss: -1523.551880\n",
      "Train Epoch: 2800 [34304/60000 (57%)] Loss: -1469.571167\n",
      "Train Epoch: 2800 [45568/60000 (76%)] Loss: -1576.049561\n",
      "Train Epoch: 2800 [56832/60000 (95%)] Loss: -1306.025146\n",
      "    epoch          : 2800\n",
      "    loss           : -1474.541819426973\n",
      "Saving checkpoint: saved/models/Mnist_DeepGenerativeOperad/0127_111843/checkpoint-epoch2800.pth ...\n",
      "Train Epoch: 2801 [512/60000 (1%)] Loss: -1502.086426\n",
      "Train Epoch: 2801 [11776/60000 (20%)] Loss: -1389.223633\n",
      "Train Epoch: 2801 [23040/60000 (38%)] Loss: -1521.106934\n",
      "Train Epoch: 2801 [34304/60000 (57%)] Loss: -1513.310913\n",
      "Train Epoch: 2801 [45568/60000 (76%)] Loss: -1531.114868\n",
      "Train Epoch: 2801 [56832/60000 (95%)] Loss: -1419.301636\n",
      "    epoch          : 2801\n",
      "    loss           : -1469.1870044772909\n",
      "Train Epoch: 2802 [512/60000 (1%)] Loss: -1571.685669\n",
      "Train Epoch: 2802 [11776/60000 (20%)] Loss: -1483.406616\n",
      "Train Epoch: 2802 [23040/60000 (38%)] Loss: -1466.136963\n",
      "Train Epoch: 2802 [34304/60000 (57%)] Loss: -1541.724854\n",
      "Train Epoch: 2802 [45568/60000 (76%)] Loss: -1438.585205\n",
      "Train Epoch: 2802 [56832/60000 (95%)] Loss: -1474.421631\n",
      "    epoch          : 2802\n",
      "    loss           : -1462.9498342740333\n",
      "Train Epoch: 2803 [512/60000 (1%)] Loss: -1502.934204\n",
      "Train Epoch: 2803 [11776/60000 (20%)] Loss: -1481.400391\n",
      "Train Epoch: 2803 [23040/60000 (38%)] Loss: -1591.527222\n",
      "Train Epoch: 2803 [34304/60000 (57%)] Loss: -1365.061279\n",
      "Train Epoch: 2803 [45568/60000 (76%)] Loss: -1465.652344\n",
      "Train Epoch: 2803 [56832/60000 (95%)] Loss: -1423.686523\n",
      "    epoch          : 2803\n",
      "    loss           : -1465.0095483812236\n",
      "Train Epoch: 2804 [512/60000 (1%)] Loss: -1500.461670\n",
      "Train Epoch: 2804 [11776/60000 (20%)] Loss: -1531.991333\n",
      "Train Epoch: 2804 [23040/60000 (38%)] Loss: -1546.766357\n",
      "Train Epoch: 2804 [34304/60000 (57%)] Loss: -1499.260742\n",
      "Train Epoch: 2804 [45568/60000 (76%)] Loss: -1395.901245\n",
      "Train Epoch: 2804 [56832/60000 (95%)] Loss: -1480.041626\n",
      "    epoch          : 2804\n",
      "    loss           : -1466.50395831954\n",
      "Train Epoch: 2805 [512/60000 (1%)] Loss: -1604.119141\n",
      "Train Epoch: 2805 [11776/60000 (20%)] Loss: -1522.328125\n",
      "Train Epoch: 2805 [23040/60000 (38%)] Loss: -1398.163086\n",
      "Train Epoch: 2805 [34304/60000 (57%)] Loss: -1565.500244\n",
      "Train Epoch: 2805 [45568/60000 (76%)] Loss: -1474.080444\n",
      "Train Epoch: 2805 [56832/60000 (95%)] Loss: -1462.353760\n",
      "    epoch          : 2805\n",
      "    loss           : -1468.0979317702815\n",
      "Train Epoch: 2806 [512/60000 (1%)] Loss: -1522.067505\n",
      "Train Epoch: 2806 [11776/60000 (20%)] Loss: -1491.749023\n",
      "Train Epoch: 2806 [23040/60000 (38%)] Loss: -1536.524658\n",
      "Train Epoch: 2806 [34304/60000 (57%)] Loss: -1475.364136\n",
      "Train Epoch: 2806 [45568/60000 (76%)] Loss: -1486.263428\n",
      "Train Epoch: 2806 [56832/60000 (95%)] Loss: -1583.899536\n",
      "    epoch          : 2806\n",
      "    loss           : -1475.1612028132724\n",
      "Train Epoch: 2807 [512/60000 (1%)] Loss: -1406.781982\n",
      "Train Epoch: 2807 [11776/60000 (20%)] Loss: -1520.015625\n",
      "Train Epoch: 2807 [23040/60000 (38%)] Loss: -1423.360474\n",
      "Train Epoch: 2807 [34304/60000 (57%)] Loss: -1414.899658\n",
      "Train Epoch: 2807 [45568/60000 (76%)] Loss: -1497.782227\n",
      "Train Epoch: 2807 [56832/60000 (95%)] Loss: -1441.484375\n",
      "    epoch          : 2807\n",
      "    loss           : -1475.8334764383608\n",
      "Train Epoch: 2808 [512/60000 (1%)] Loss: -1492.293091\n",
      "Train Epoch: 2808 [11776/60000 (20%)] Loss: -1284.196167\n",
      "Train Epoch: 2808 [23040/60000 (38%)] Loss: -1472.978394\n",
      "Train Epoch: 2808 [34304/60000 (57%)] Loss: -1443.268921\n",
      "Train Epoch: 2808 [45568/60000 (76%)] Loss: -1489.509277\n",
      "Train Epoch: 2808 [56832/60000 (95%)] Loss: -1497.692139\n",
      "    epoch          : 2808\n",
      "    loss           : -1469.9815128994526\n",
      "Train Epoch: 2809 [512/60000 (1%)] Loss: -1430.743286\n",
      "Train Epoch: 2809 [11776/60000 (20%)] Loss: -1562.366821\n",
      "Train Epoch: 2809 [23040/60000 (38%)] Loss: -1521.525269\n",
      "Train Epoch: 2809 [34304/60000 (57%)] Loss: -1545.959106\n",
      "Train Epoch: 2809 [45568/60000 (76%)] Loss: -1446.505981\n",
      "Train Epoch: 2809 [56832/60000 (95%)] Loss: -1357.629028\n",
      "    epoch          : 2809\n",
      "    loss           : -1478.8690213133386\n",
      "Train Epoch: 2810 [512/60000 (1%)] Loss: -1532.390381\n",
      "Train Epoch: 2810 [11776/60000 (20%)] Loss: -1416.117798\n",
      "Train Epoch: 2810 [23040/60000 (38%)] Loss: -1558.240234\n",
      "Train Epoch: 2810 [34304/60000 (57%)] Loss: -1522.731201\n",
      "Train Epoch: 2810 [45568/60000 (76%)] Loss: -1478.106079\n",
      "Train Epoch: 2810 [56832/60000 (95%)] Loss: -1486.502441\n",
      "    epoch          : 2810\n",
      "    loss           : -1470.1748677916446\n",
      "Train Epoch: 2811 [512/60000 (1%)] Loss: -1570.275513\n",
      "Train Epoch: 2811 [11776/60000 (20%)] Loss: -1547.873291\n",
      "Train Epoch: 2811 [23040/60000 (38%)] Loss: -1474.970337\n",
      "Train Epoch: 2811 [34304/60000 (57%)] Loss: -1501.737305\n",
      "Train Epoch: 2811 [45568/60000 (76%)] Loss: -1450.997070\n",
      "Train Epoch: 2811 [56832/60000 (95%)] Loss: -1334.174805\n",
      "    epoch          : 2811\n",
      "    loss           : -1466.463510976673\n",
      "Train Epoch: 2812 [512/60000 (1%)] Loss: -1415.978271\n",
      "Train Epoch: 2812 [11776/60000 (20%)] Loss: -1347.846680\n",
      "Train Epoch: 2812 [23040/60000 (38%)] Loss: -1454.283936\n",
      "Train Epoch: 2812 [34304/60000 (57%)] Loss: -1446.613525\n",
      "Train Epoch: 2812 [45568/60000 (76%)] Loss: -1378.353516\n",
      "Train Epoch: 2812 [56832/60000 (95%)] Loss: -1488.948975\n",
      "    epoch          : 2812\n",
      "    loss           : -1468.3365133684235\n",
      "Train Epoch: 2813 [512/60000 (1%)] Loss: -1443.443848\n",
      "Train Epoch: 2813 [11776/60000 (20%)] Loss: -1483.926636\n",
      "Train Epoch: 2813 [23040/60000 (38%)] Loss: -1564.935181\n",
      "Train Epoch: 2813 [34304/60000 (57%)] Loss: -1457.821899\n",
      "Train Epoch: 2813 [45568/60000 (76%)] Loss: -1361.549316\n",
      "Train Epoch: 2813 [56832/60000 (95%)] Loss: -1410.425781\n",
      "    epoch          : 2813\n",
      "    loss           : -1480.378229345979\n",
      "Train Epoch: 2814 [512/60000 (1%)] Loss: -1592.351318\n",
      "Train Epoch: 2814 [11776/60000 (20%)] Loss: -1454.377563\n",
      "Train Epoch: 2814 [23040/60000 (38%)] Loss: -1518.154175\n",
      "Train Epoch: 2814 [34304/60000 (57%)] Loss: -1572.106445\n",
      "Train Epoch: 2814 [45568/60000 (76%)] Loss: -1482.420410\n",
      "Train Epoch: 2814 [56832/60000 (95%)] Loss: -1508.340820\n",
      "    epoch          : 2814\n",
      "    loss           : -1480.9430293713585\n",
      "Train Epoch: 2815 [512/60000 (1%)] Loss: -1470.324951\n",
      "Train Epoch: 2815 [11776/60000 (20%)] Loss: -1507.783691\n",
      "Train Epoch: 2815 [23040/60000 (38%)] Loss: -1415.081909\n",
      "Train Epoch: 2815 [34304/60000 (57%)] Loss: -1341.987305\n",
      "Train Epoch: 2815 [45568/60000 (76%)] Loss: -1398.427856\n",
      "Train Epoch: 2815 [56832/60000 (95%)] Loss: -1476.830078\n",
      "    epoch          : 2815\n",
      "    loss           : -1457.1584751969676\n",
      "Train Epoch: 2816 [512/60000 (1%)] Loss: -1461.271118\n",
      "Train Epoch: 2816 [11776/60000 (20%)] Loss: -1559.121460\n",
      "Train Epoch: 2816 [23040/60000 (38%)] Loss: -1580.114990\n",
      "Train Epoch: 2816 [34304/60000 (57%)] Loss: -1350.081177\n",
      "Train Epoch: 2816 [45568/60000 (76%)] Loss: -1467.821899\n",
      "Train Epoch: 2816 [56832/60000 (95%)] Loss: -1539.924683\n",
      "    epoch          : 2816\n",
      "    loss           : -1470.0459846453477\n",
      "Train Epoch: 2817 [512/60000 (1%)] Loss: -1321.568604\n",
      "Train Epoch: 2817 [11776/60000 (20%)] Loss: -1452.996948\n",
      "Train Epoch: 2817 [23040/60000 (38%)] Loss: -1570.125732\n",
      "Train Epoch: 2817 [34304/60000 (57%)] Loss: -1394.410889\n",
      "Train Epoch: 2817 [45568/60000 (76%)] Loss: -1437.617188\n",
      "Train Epoch: 2817 [56832/60000 (95%)] Loss: -1589.511719\n",
      "    epoch          : 2817\n",
      "    loss           : -1469.2274490615068\n",
      "Train Epoch: 2818 [512/60000 (1%)] Loss: -1447.266602\n",
      "Train Epoch: 2818 [11776/60000 (20%)] Loss: -1356.597900\n",
      "Train Epoch: 2818 [23040/60000 (38%)] Loss: -1414.932129\n",
      "Train Epoch: 2818 [34304/60000 (57%)] Loss: -1317.948486\n",
      "Train Epoch: 2818 [45568/60000 (76%)] Loss: -1361.664062\n",
      "Train Epoch: 2818 [56832/60000 (95%)] Loss: -1543.144531\n",
      "    epoch          : 2818\n",
      "    loss           : -1465.4774873377912\n",
      "Train Epoch: 2819 [512/60000 (1%)] Loss: -1510.463745\n",
      "Train Epoch: 2819 [11776/60000 (20%)] Loss: -1518.651855\n",
      "Train Epoch: 2819 [23040/60000 (38%)] Loss: -1470.054565\n",
      "Train Epoch: 2819 [34304/60000 (57%)] Loss: -1560.631592\n",
      "Train Epoch: 2819 [45568/60000 (76%)] Loss: -1418.713257\n",
      "Train Epoch: 2819 [56832/60000 (95%)] Loss: -1492.211914\n",
      "    epoch          : 2819\n",
      "    loss           : -1468.1797857769466\n",
      "Train Epoch: 2820 [512/60000 (1%)] Loss: -1403.011719\n",
      "Train Epoch: 2820 [11776/60000 (20%)] Loss: -1520.593262\n",
      "Train Epoch: 2820 [23040/60000 (38%)] Loss: -1534.242188\n",
      "Train Epoch: 2820 [34304/60000 (57%)] Loss: -1533.091309\n",
      "Train Epoch: 2820 [45568/60000 (76%)] Loss: -1549.888672\n",
      "Train Epoch: 2820 [56832/60000 (95%)] Loss: -1474.619385\n",
      "    epoch          : 2820\n",
      "    loss           : -1484.77211645094\n",
      "Train Epoch: 2821 [512/60000 (1%)] Loss: -1541.104004\n",
      "Train Epoch: 2821 [11776/60000 (20%)] Loss: -1526.142334\n",
      "Train Epoch: 2821 [23040/60000 (38%)] Loss: -1547.984009\n",
      "Train Epoch: 2821 [34304/60000 (57%)] Loss: -1386.981323\n",
      "Train Epoch: 2821 [45568/60000 (76%)] Loss: -1565.347412\n",
      "Train Epoch: 2821 [56832/60000 (95%)] Loss: -1570.523315\n",
      "    epoch          : 2821\n",
      "    loss           : -1484.09752486924\n",
      "Train Epoch: 2822 [512/60000 (1%)] Loss: -1425.056641\n",
      "Train Epoch: 2822 [11776/60000 (20%)] Loss: -1255.629395\n",
      "Train Epoch: 2822 [23040/60000 (38%)] Loss: -1450.735840\n",
      "Train Epoch: 2822 [34304/60000 (57%)] Loss: -1499.146240\n",
      "Train Epoch: 2822 [45568/60000 (76%)] Loss: -1351.507935\n",
      "Train Epoch: 2822 [56832/60000 (95%)] Loss: -1456.609497\n",
      "    epoch          : 2822\n",
      "    loss           : -1464.754496601342\n",
      "Train Epoch: 2823 [512/60000 (1%)] Loss: -1567.862061\n",
      "Train Epoch: 2823 [11776/60000 (20%)] Loss: -1506.646729\n",
      "Train Epoch: 2823 [23040/60000 (38%)] Loss: -1572.746826\n",
      "Train Epoch: 2823 [34304/60000 (57%)] Loss: -1512.214844\n",
      "Train Epoch: 2823 [45568/60000 (76%)] Loss: -1379.758789\n",
      "Train Epoch: 2823 [56832/60000 (95%)] Loss: -1495.597656\n",
      "    epoch          : 2823\n",
      "    loss           : -1461.6974356268759\n",
      "Train Epoch: 2824 [512/60000 (1%)] Loss: -1525.862061\n",
      "Train Epoch: 2824 [11776/60000 (20%)] Loss: -1582.511475\n",
      "Train Epoch: 2824 [23040/60000 (38%)] Loss: -1318.928955\n",
      "Train Epoch: 2824 [34304/60000 (57%)] Loss: -1361.238647\n",
      "Train Epoch: 2824 [45568/60000 (76%)] Loss: -1519.480225\n",
      "Train Epoch: 2824 [56832/60000 (95%)] Loss: -1514.129395\n",
      "    epoch          : 2824\n",
      "    loss           : -1472.4128559349622\n",
      "Train Epoch: 2825 [512/60000 (1%)] Loss: -1349.181763\n",
      "Train Epoch: 2825 [11776/60000 (20%)] Loss: -1570.019165\n",
      "Train Epoch: 2825 [23040/60000 (38%)] Loss: -1521.963623\n",
      "Train Epoch: 2825 [34304/60000 (57%)] Loss: -1499.774658\n",
      "Train Epoch: 2825 [45568/60000 (76%)] Loss: -1566.946533\n",
      "Train Epoch: 2825 [56832/60000 (95%)] Loss: -1447.839355\n",
      "    epoch          : 2825\n",
      "    loss           : -1475.559142721575\n",
      "Train Epoch: 2826 [512/60000 (1%)] Loss: -1536.506714\n",
      "Train Epoch: 2826 [11776/60000 (20%)] Loss: -1530.781982\n",
      "Train Epoch: 2826 [23040/60000 (38%)] Loss: -1355.410767\n",
      "Train Epoch: 2826 [34304/60000 (57%)] Loss: -1499.266602\n",
      "Train Epoch: 2826 [45568/60000 (76%)] Loss: -1549.540771\n",
      "Train Epoch: 2826 [56832/60000 (95%)] Loss: -1489.535156\n",
      "    epoch          : 2826\n",
      "    loss           : -1489.048466741702\n",
      "Train Epoch: 2827 [512/60000 (1%)] Loss: -1533.035034\n",
      "Train Epoch: 2827 [11776/60000 (20%)] Loss: -1465.024170\n",
      "Train Epoch: 2827 [23040/60000 (38%)] Loss: -1570.183716\n",
      "Train Epoch: 2827 [34304/60000 (57%)] Loss: -1431.620117\n",
      "Train Epoch: 2827 [45568/60000 (76%)] Loss: -1450.104004\n",
      "Train Epoch: 2827 [56832/60000 (95%)] Loss: -1366.953369\n",
      "    epoch          : 2827\n",
      "    loss           : -1465.025230968066\n",
      "Train Epoch: 2828 [512/60000 (1%)] Loss: -1530.195557\n",
      "Train Epoch: 2828 [11776/60000 (20%)] Loss: -1380.265869\n",
      "Train Epoch: 2828 [23040/60000 (38%)] Loss: -1449.478760\n",
      "Train Epoch: 2828 [34304/60000 (57%)] Loss: -1374.228149\n",
      "Train Epoch: 2828 [45568/60000 (76%)] Loss: -1505.886719\n",
      "Train Epoch: 2828 [56832/60000 (95%)] Loss: -1361.675537\n",
      "    epoch          : 2828\n",
      "    loss           : -1471.3768024336819\n",
      "Train Epoch: 2829 [512/60000 (1%)] Loss: -1524.962036\n",
      "Train Epoch: 2829 [11776/60000 (20%)] Loss: -1396.115723\n",
      "Train Epoch: 2829 [23040/60000 (38%)] Loss: -1413.286987\n",
      "Train Epoch: 2829 [34304/60000 (57%)] Loss: -1456.945557\n",
      "Train Epoch: 2829 [45568/60000 (76%)] Loss: -1496.291016\n",
      "Train Epoch: 2829 [56832/60000 (95%)] Loss: -1450.688965\n",
      "    epoch          : 2829\n",
      "    loss           : -1468.634462518207\n",
      "Train Epoch: 2830 [512/60000 (1%)] Loss: -1579.595825\n",
      "Train Epoch: 2830 [11776/60000 (20%)] Loss: -1578.933960\n",
      "Train Epoch: 2830 [23040/60000 (38%)] Loss: -1558.406372\n",
      "Train Epoch: 2830 [34304/60000 (57%)] Loss: -1552.247314\n",
      "Train Epoch: 2830 [45568/60000 (76%)] Loss: -1466.663452\n",
      "Train Epoch: 2830 [56832/60000 (95%)] Loss: -1577.086670\n",
      "    epoch          : 2830\n",
      "    loss           : -1476.2584518173994\n",
      "Train Epoch: 2831 [512/60000 (1%)] Loss: -1349.990601\n",
      "Train Epoch: 2831 [11776/60000 (20%)] Loss: -1536.060303\n",
      "Train Epoch: 2831 [23040/60000 (38%)] Loss: -1397.135986\n",
      "Train Epoch: 2831 [34304/60000 (57%)] Loss: -1460.995483\n",
      "Train Epoch: 2831 [45568/60000 (76%)] Loss: -1524.763428\n",
      "Train Epoch: 2831 [56832/60000 (95%)] Loss: -1454.567627\n",
      "    epoch          : 2831\n",
      "    loss           : -1464.0699869791665\n",
      "Train Epoch: 2832 [512/60000 (1%)] Loss: -1549.603516\n",
      "Train Epoch: 2832 [11776/60000 (20%)] Loss: -1510.202393\n",
      "Train Epoch: 2832 [23040/60000 (38%)] Loss: -1499.095215\n",
      "Train Epoch: 2832 [34304/60000 (57%)] Loss: -1570.212646\n",
      "Train Epoch: 2832 [45568/60000 (76%)] Loss: -1367.992188\n",
      "Train Epoch: 2832 [56832/60000 (95%)] Loss: -1344.943848\n",
      "    epoch          : 2832\n",
      "    loss           : -1470.2216565837969\n",
      "Train Epoch: 2833 [512/60000 (1%)] Loss: -1416.263794\n",
      "Train Epoch: 2833 [11776/60000 (20%)] Loss: -1494.433350\n",
      "Train Epoch: 2833 [23040/60000 (38%)] Loss: -1399.284302\n",
      "Train Epoch: 2833 [34304/60000 (57%)] Loss: -1480.917969\n",
      "Train Epoch: 2833 [45568/60000 (76%)] Loss: -1416.303345\n",
      "Train Epoch: 2833 [56832/60000 (95%)] Loss: -1443.999756\n",
      "    epoch          : 2833\n",
      "    loss           : -1459.0694273178185\n",
      "Train Epoch: 2834 [512/60000 (1%)] Loss: -1564.408569\n",
      "Train Epoch: 2834 [11776/60000 (20%)] Loss: -1592.609375\n",
      "Train Epoch: 2834 [23040/60000 (38%)] Loss: -1354.110352\n",
      "Train Epoch: 2834 [34304/60000 (57%)] Loss: -1413.687378\n",
      "Train Epoch: 2834 [45568/60000 (76%)] Loss: -1369.085449\n",
      "Train Epoch: 2834 [56832/60000 (95%)] Loss: -1412.786743\n",
      "    epoch          : 2834\n",
      "    loss           : -1466.096982794293\n",
      "Train Epoch: 2835 [512/60000 (1%)] Loss: -1348.563721\n",
      "Train Epoch: 2835 [11776/60000 (20%)] Loss: -1433.736938\n",
      "Train Epoch: 2835 [23040/60000 (38%)] Loss: -1403.895996\n",
      "Train Epoch: 2835 [34304/60000 (57%)] Loss: -1475.748169\n",
      "Train Epoch: 2835 [45568/60000 (76%)] Loss: -1475.835938\n",
      "Train Epoch: 2835 [56832/60000 (95%)] Loss: -1508.460205\n",
      "    epoch          : 2835\n",
      "    loss           : -1466.2970850023173\n",
      "Train Epoch: 2836 [512/60000 (1%)] Loss: -1451.393799\n",
      "Train Epoch: 2836 [11776/60000 (20%)] Loss: -1423.394165\n",
      "Train Epoch: 2836 [23040/60000 (38%)] Loss: -1543.182251\n",
      "Train Epoch: 2836 [34304/60000 (57%)] Loss: -1590.617432\n",
      "Train Epoch: 2836 [45568/60000 (76%)] Loss: -1288.089233\n",
      "Train Epoch: 2836 [56832/60000 (95%)] Loss: -1392.790039\n",
      "    epoch          : 2836\n",
      "    loss           : -1445.6869472352798\n",
      "Train Epoch: 2837 [512/60000 (1%)] Loss: -1564.387939\n",
      "Train Epoch: 2837 [11776/60000 (20%)] Loss: -1464.853516\n",
      "Train Epoch: 2837 [23040/60000 (38%)] Loss: -1368.080811\n",
      "Train Epoch: 2837 [34304/60000 (57%)] Loss: -1468.037842\n",
      "Train Epoch: 2837 [45568/60000 (76%)] Loss: -1376.545532\n",
      "Train Epoch: 2837 [56832/60000 (95%)] Loss: -1516.402222\n",
      "    epoch          : 2837\n",
      "    loss           : -1478.0260402873412\n",
      "Train Epoch: 2838 [512/60000 (1%)] Loss: -1484.988159\n",
      "Train Epoch: 2838 [11776/60000 (20%)] Loss: -1446.174927\n",
      "Train Epoch: 2838 [23040/60000 (38%)] Loss: -1422.855835\n",
      "Train Epoch: 2838 [34304/60000 (57%)] Loss: -1454.099121\n",
      "Train Epoch: 2838 [45568/60000 (76%)] Loss: -1470.383301\n",
      "Train Epoch: 2838 [56832/60000 (95%)] Loss: -1381.245850\n",
      "    epoch          : 2838\n",
      "    loss           : -1481.429957158148\n",
      "Train Epoch: 2839 [512/60000 (1%)] Loss: -1343.177368\n",
      "Train Epoch: 2839 [11776/60000 (20%)] Loss: -1475.212891\n",
      "Train Epoch: 2839 [23040/60000 (38%)] Loss: -1570.179932\n",
      "Train Epoch: 2839 [34304/60000 (57%)] Loss: -1586.144775\n",
      "Train Epoch: 2839 [45568/60000 (76%)] Loss: -1461.198730\n",
      "Train Epoch: 2839 [56832/60000 (95%)] Loss: -1443.054443\n",
      "    epoch          : 2839\n",
      "    loss           : -1478.5744208211952\n",
      "Train Epoch: 2840 [512/60000 (1%)] Loss: -1448.291748\n",
      "Train Epoch: 2840 [11776/60000 (20%)] Loss: -1477.786743\n",
      "Train Epoch: 2840 [23040/60000 (38%)] Loss: -1353.070801\n",
      "Train Epoch: 2840 [34304/60000 (57%)] Loss: -1436.458252\n",
      "Train Epoch: 2840 [45568/60000 (76%)] Loss: -1346.646973\n",
      "Train Epoch: 2840 [56832/60000 (95%)] Loss: -1489.881104\n",
      "    epoch          : 2840\n",
      "    loss           : -1461.8104792880474\n",
      "Train Epoch: 2841 [512/60000 (1%)] Loss: -1573.789062\n",
      "Train Epoch: 2841 [11776/60000 (20%)] Loss: -1392.957153\n",
      "Train Epoch: 2841 [23040/60000 (38%)] Loss: -1516.909668\n",
      "Train Epoch: 2841 [34304/60000 (57%)] Loss: -1451.887085\n",
      "Train Epoch: 2841 [45568/60000 (76%)] Loss: -1487.128418\n",
      "Train Epoch: 2841 [56832/60000 (95%)] Loss: -1422.065796\n",
      "    epoch          : 2841\n",
      "    loss           : -1469.9512577380165\n",
      "Train Epoch: 2842 [512/60000 (1%)] Loss: -1578.028687\n",
      "Train Epoch: 2842 [11776/60000 (20%)] Loss: -1530.958862\n",
      "Train Epoch: 2842 [23040/60000 (38%)] Loss: -1527.852661\n",
      "Train Epoch: 2842 [34304/60000 (57%)] Loss: -1360.766357\n",
      "Train Epoch: 2842 [45568/60000 (76%)] Loss: -1542.836914\n",
      "Train Epoch: 2842 [56832/60000 (95%)] Loss: -1365.454834\n",
      "    epoch          : 2842\n",
      "    loss           : -1474.5203150517523\n",
      "Train Epoch: 2843 [512/60000 (1%)] Loss: -1239.996460\n",
      "Train Epoch: 2843 [11776/60000 (20%)] Loss: -1488.459961\n",
      "Train Epoch: 2843 [23040/60000 (38%)] Loss: -1553.496582\n",
      "Train Epoch: 2843 [34304/60000 (57%)] Loss: -1575.983032\n",
      "Train Epoch: 2843 [45568/60000 (76%)] Loss: -1435.356934\n",
      "Train Epoch: 2843 [56832/60000 (95%)] Loss: -1472.365479\n",
      "    epoch          : 2843\n",
      "    loss           : -1466.3051219875529\n",
      "Train Epoch: 2844 [512/60000 (1%)] Loss: -1447.928833\n",
      "Train Epoch: 2844 [11776/60000 (20%)] Loss: -1528.864258\n",
      "Train Epoch: 2844 [23040/60000 (38%)] Loss: -1571.294922\n",
      "Train Epoch: 2844 [34304/60000 (57%)] Loss: -1477.797363\n",
      "Train Epoch: 2844 [45568/60000 (76%)] Loss: -1565.410645\n",
      "Train Epoch: 2844 [56832/60000 (95%)] Loss: -1387.659668\n",
      "    epoch          : 2844\n",
      "    loss           : -1472.7806610279838\n",
      "Train Epoch: 2845 [512/60000 (1%)] Loss: -1378.082520\n",
      "Train Epoch: 2845 [11776/60000 (20%)] Loss: -1377.960449\n",
      "Train Epoch: 2845 [23040/60000 (38%)] Loss: -1557.987671\n",
      "Train Epoch: 2845 [34304/60000 (57%)] Loss: -1468.496460\n",
      "Train Epoch: 2845 [45568/60000 (76%)] Loss: -1500.322510\n",
      "Train Epoch: 2845 [56832/60000 (95%)] Loss: -1404.145020\n",
      "    epoch          : 2845\n",
      "    loss           : -1479.671108094986\n",
      "Train Epoch: 2846 [512/60000 (1%)] Loss: -1465.013428\n",
      "Train Epoch: 2846 [11776/60000 (20%)] Loss: -1390.965820\n",
      "Train Epoch: 2846 [23040/60000 (38%)] Loss: -1471.000244\n",
      "Train Epoch: 2846 [34304/60000 (57%)] Loss: -1532.404785\n",
      "Train Epoch: 2846 [45568/60000 (76%)] Loss: -1403.917114\n",
      "Train Epoch: 2846 [56832/60000 (95%)] Loss: -1570.564209\n",
      "    epoch          : 2846\n",
      "    loss           : -1462.705068469721\n",
      "Train Epoch: 2847 [512/60000 (1%)] Loss: -1299.300537\n",
      "Train Epoch: 2847 [11776/60000 (20%)] Loss: -1533.698486\n",
      "Train Epoch: 2847 [23040/60000 (38%)] Loss: -1406.311646\n",
      "Train Epoch: 2847 [34304/60000 (57%)] Loss: -1576.872437\n",
      "Train Epoch: 2847 [45568/60000 (76%)] Loss: -1583.244141\n",
      "Train Epoch: 2847 [56832/60000 (95%)] Loss: -1439.879883\n",
      "    epoch          : 2847\n",
      "    loss           : -1463.0416232179114\n",
      "Train Epoch: 2848 [512/60000 (1%)] Loss: -1493.491943\n",
      "Train Epoch: 2848 [11776/60000 (20%)] Loss: -1517.484863\n",
      "Train Epoch: 2848 [23040/60000 (38%)] Loss: -1412.436157\n",
      "Train Epoch: 2848 [34304/60000 (57%)] Loss: -1327.395874\n",
      "Train Epoch: 2848 [45568/60000 (76%)] Loss: -1452.843506\n",
      "Train Epoch: 2848 [56832/60000 (95%)] Loss: -1448.689941\n",
      "    epoch          : 2848\n",
      "    loss           : -1472.146346097612\n",
      "Train Epoch: 2849 [512/60000 (1%)] Loss: -1452.214966\n",
      "Train Epoch: 2849 [11776/60000 (20%)] Loss: -1486.397583\n",
      "Train Epoch: 2849 [23040/60000 (38%)] Loss: -1431.449707\n",
      "Train Epoch: 2849 [34304/60000 (57%)] Loss: -1489.653687\n",
      "Train Epoch: 2849 [45568/60000 (76%)] Loss: -1542.385864\n",
      "Train Epoch: 2849 [56832/60000 (95%)] Loss: -1517.780396\n",
      "    epoch          : 2849\n",
      "    loss           : -1479.432164079052\n",
      "Train Epoch: 2850 [512/60000 (1%)] Loss: -1476.672607\n",
      "Train Epoch: 2850 [11776/60000 (20%)] Loss: -1513.882690\n",
      "Train Epoch: 2850 [23040/60000 (38%)] Loss: -1572.065430\n",
      "Train Epoch: 2850 [34304/60000 (57%)] Loss: -1516.395874\n",
      "Train Epoch: 2850 [45568/60000 (76%)] Loss: -1476.274414\n",
      "Train Epoch: 2850 [56832/60000 (95%)] Loss: -1395.091797\n",
      "    epoch          : 2850\n",
      "    loss           : -1473.3047137071856\n",
      "Train Epoch: 2851 [512/60000 (1%)] Loss: -1446.617065\n",
      "Train Epoch: 2851 [11776/60000 (20%)] Loss: -1511.466187\n",
      "Train Epoch: 2851 [23040/60000 (38%)] Loss: -1502.484375\n",
      "Train Epoch: 2851 [34304/60000 (57%)] Loss: -1454.884399\n",
      "Train Epoch: 2851 [45568/60000 (76%)] Loss: -1471.261475\n",
      "Train Epoch: 2851 [56832/60000 (95%)] Loss: -1467.543579\n",
      "    epoch          : 2851\n",
      "    loss           : -1475.4031685866878\n",
      "Train Epoch: 2852 [512/60000 (1%)] Loss: -1414.587280\n",
      "Train Epoch: 2852 [11776/60000 (20%)] Loss: -1504.599609\n",
      "Train Epoch: 2852 [23040/60000 (38%)] Loss: -1490.432129\n",
      "Train Epoch: 2852 [34304/60000 (57%)] Loss: -1347.180908\n",
      "Train Epoch: 2852 [45568/60000 (76%)] Loss: -1548.066650\n",
      "Train Epoch: 2852 [56832/60000 (95%)] Loss: -1470.630127\n",
      "    epoch          : 2852\n",
      "    loss           : -1462.3622474454892\n",
      "Train Epoch: 2853 [512/60000 (1%)] Loss: -1292.109863\n",
      "Train Epoch: 2853 [11776/60000 (20%)] Loss: -1502.875244\n",
      "Train Epoch: 2853 [23040/60000 (38%)] Loss: -1430.568848\n",
      "Train Epoch: 2853 [34304/60000 (57%)] Loss: -1436.794434\n",
      "Train Epoch: 2853 [45568/60000 (76%)] Loss: -1383.802979\n",
      "Train Epoch: 2853 [56832/60000 (95%)] Loss: -1321.022583\n",
      "    epoch          : 2853\n",
      "    loss           : -1473.6664059741347\n",
      "Train Epoch: 2854 [512/60000 (1%)] Loss: -1538.448853\n",
      "Train Epoch: 2854 [11776/60000 (20%)] Loss: -1435.388062\n",
      "Train Epoch: 2854 [23040/60000 (38%)] Loss: -1525.804199\n",
      "Train Epoch: 2854 [34304/60000 (57%)] Loss: -1536.279419\n",
      "Train Epoch: 2854 [45568/60000 (76%)] Loss: -1403.978760\n",
      "Train Epoch: 2854 [56832/60000 (95%)] Loss: -1546.709961\n",
      "    epoch          : 2854\n",
      "    loss           : -1480.325026000287\n",
      "Train Epoch: 2855 [512/60000 (1%)] Loss: -1474.599609\n",
      "Train Epoch: 2855 [11776/60000 (20%)] Loss: -1482.268555\n",
      "Train Epoch: 2855 [23040/60000 (38%)] Loss: -1605.985596\n",
      "Train Epoch: 2855 [34304/60000 (57%)] Loss: -1464.424438\n",
      "Train Epoch: 2855 [45568/60000 (76%)] Loss: -1443.342651\n",
      "Train Epoch: 2855 [56832/60000 (95%)] Loss: -1510.511353\n",
      "    epoch          : 2855\n",
      "    loss           : -1478.8770041600458\n",
      "Train Epoch: 2856 [512/60000 (1%)] Loss: -1415.362793\n",
      "Train Epoch: 2856 [11776/60000 (20%)] Loss: -1434.319092\n",
      "Train Epoch: 2856 [23040/60000 (38%)] Loss: -1496.326782\n",
      "Train Epoch: 2856 [34304/60000 (57%)] Loss: -1509.097168\n",
      "Train Epoch: 2856 [45568/60000 (76%)] Loss: -1487.079834\n",
      "Train Epoch: 2856 [56832/60000 (95%)] Loss: -1326.338013\n",
      "    epoch          : 2856\n",
      "    loss           : -1470.5583675406072\n",
      "Train Epoch: 2857 [512/60000 (1%)] Loss: -1436.511841\n",
      "Train Epoch: 2857 [11776/60000 (20%)] Loss: -1463.061890\n",
      "Train Epoch: 2857 [23040/60000 (38%)] Loss: -1530.977905\n",
      "Train Epoch: 2857 [34304/60000 (57%)] Loss: -1527.983398\n",
      "Train Epoch: 2857 [45568/60000 (76%)] Loss: -1380.170044\n",
      "Train Epoch: 2857 [56832/60000 (95%)] Loss: -1445.621094\n",
      "    epoch          : 2857\n",
      "    loss           : -1465.2907287252826\n",
      "Train Epoch: 2858 [512/60000 (1%)] Loss: -1581.867798\n",
      "Train Epoch: 2858 [11776/60000 (20%)] Loss: -1428.864990\n",
      "Train Epoch: 2858 [23040/60000 (38%)] Loss: -1460.717651\n",
      "Train Epoch: 2858 [34304/60000 (57%)] Loss: -1426.529541\n",
      "Train Epoch: 2858 [45568/60000 (76%)] Loss: -1438.537109\n",
      "Train Epoch: 2858 [56832/60000 (95%)] Loss: -1367.253540\n",
      "    epoch          : 2858\n",
      "    loss           : -1468.9361106743247\n",
      "Train Epoch: 2859 [512/60000 (1%)] Loss: -1399.182617\n",
      "Train Epoch: 2859 [11776/60000 (20%)] Loss: -1413.901367\n",
      "Train Epoch: 2859 [23040/60000 (38%)] Loss: -1481.009888\n",
      "Train Epoch: 2859 [34304/60000 (57%)] Loss: -1449.337891\n",
      "Train Epoch: 2859 [45568/60000 (76%)] Loss: -1534.138184\n",
      "Train Epoch: 2859 [56832/60000 (95%)] Loss: -1356.498779\n",
      "    epoch          : 2859\n",
      "    loss           : -1464.711711301642\n",
      "Train Epoch: 2860 [512/60000 (1%)] Loss: -1535.132568\n",
      "Train Epoch: 2860 [11776/60000 (20%)] Loss: -1559.121460\n",
      "Train Epoch: 2860 [23040/60000 (38%)] Loss: -1548.023682\n",
      "Train Epoch: 2860 [34304/60000 (57%)] Loss: -1398.551392\n",
      "Train Epoch: 2860 [45568/60000 (76%)] Loss: -1562.022461\n",
      "Train Epoch: 2860 [56832/60000 (95%)] Loss: -1394.986084\n",
      "    epoch          : 2860\n",
      "    loss           : -1477.3818445582847\n",
      "Train Epoch: 2861 [512/60000 (1%)] Loss: -1500.627197\n",
      "Train Epoch: 2861 [11776/60000 (20%)] Loss: -1392.174683\n",
      "Train Epoch: 2861 [23040/60000 (38%)] Loss: -1391.524902\n",
      "Train Epoch: 2861 [34304/60000 (57%)] Loss: -1557.005005\n",
      "Train Epoch: 2861 [45568/60000 (76%)] Loss: -1430.647095\n",
      "Train Epoch: 2861 [56832/60000 (95%)] Loss: -1467.262207\n",
      "    epoch          : 2861\n",
      "    loss           : -1470.2493551652985\n",
      "Train Epoch: 2862 [512/60000 (1%)] Loss: -1526.417969\n",
      "Train Epoch: 2862 [11776/60000 (20%)] Loss: -1386.151611\n",
      "Train Epoch: 2862 [23040/60000 (38%)] Loss: -1574.714844\n",
      "Train Epoch: 2862 [34304/60000 (57%)] Loss: -1570.081909\n",
      "Train Epoch: 2862 [45568/60000 (76%)] Loss: -1559.514648\n",
      "Train Epoch: 2862 [56832/60000 (95%)] Loss: -1551.150269\n",
      "    epoch          : 2862\n",
      "    loss           : -1472.7896656101034\n",
      "Train Epoch: 2863 [512/60000 (1%)] Loss: -1508.228149\n",
      "Train Epoch: 2863 [11776/60000 (20%)] Loss: -1372.743286\n",
      "Train Epoch: 2863 [23040/60000 (38%)] Loss: -1558.971436\n",
      "Train Epoch: 2863 [34304/60000 (57%)] Loss: -1253.614624\n",
      "Train Epoch: 2863 [45568/60000 (76%)] Loss: -1528.968750\n",
      "Train Epoch: 2863 [56832/60000 (95%)] Loss: -1559.607910\n",
      "    epoch          : 2863\n",
      "    loss           : -1469.9141366387491\n",
      "Train Epoch: 2864 [512/60000 (1%)] Loss: -1388.866455\n",
      "Train Epoch: 2864 [11776/60000 (20%)] Loss: -1414.053467\n",
      "Train Epoch: 2864 [23040/60000 (38%)] Loss: -1488.294678\n",
      "Train Epoch: 2864 [34304/60000 (57%)] Loss: -1426.307861\n",
      "Train Epoch: 2864 [45568/60000 (76%)] Loss: -1466.056763\n",
      "Train Epoch: 2864 [56832/60000 (95%)] Loss: -1379.675171\n",
      "    epoch          : 2864\n",
      "    loss           : -1468.183311677922\n",
      "Train Epoch: 2865 [512/60000 (1%)] Loss: -1361.099609\n",
      "Train Epoch: 2865 [11776/60000 (20%)] Loss: -1443.845215\n",
      "Train Epoch: 2865 [23040/60000 (38%)] Loss: -1484.807251\n",
      "Train Epoch: 2865 [34304/60000 (57%)] Loss: -1417.443604\n",
      "Train Epoch: 2865 [45568/60000 (76%)] Loss: -1575.136108\n",
      "Train Epoch: 2865 [56832/60000 (95%)] Loss: -1447.346436\n",
      "    epoch          : 2865\n",
      "    loss           : -1463.2195741470252\n",
      "Train Epoch: 2866 [512/60000 (1%)] Loss: -1544.491821\n",
      "Train Epoch: 2866 [11776/60000 (20%)] Loss: -1386.258911\n",
      "Train Epoch: 2866 [23040/60000 (38%)] Loss: -1507.156006\n",
      "Train Epoch: 2866 [34304/60000 (57%)] Loss: -1466.758423\n",
      "Train Epoch: 2866 [45568/60000 (76%)] Loss: -1439.469727\n",
      "Train Epoch: 2866 [56832/60000 (95%)] Loss: -1473.362427\n",
      "    epoch          : 2866\n",
      "    loss           : -1472.5757235941915\n",
      "Train Epoch: 2867 [512/60000 (1%)] Loss: -1419.141968\n",
      "Train Epoch: 2867 [11776/60000 (20%)] Loss: -1426.019531\n",
      "Train Epoch: 2867 [23040/60000 (38%)] Loss: -1521.019531\n",
      "Train Epoch: 2867 [34304/60000 (57%)] Loss: -1521.935059\n",
      "Train Epoch: 2867 [45568/60000 (76%)] Loss: -1379.092407\n",
      "Train Epoch: 2867 [56832/60000 (95%)] Loss: -1364.576172\n",
      "    epoch          : 2867\n",
      "    loss           : -1461.901809606175\n",
      "Train Epoch: 2868 [512/60000 (1%)] Loss: -1455.437988\n",
      "Train Epoch: 2868 [11776/60000 (20%)] Loss: -1459.157471\n",
      "Train Epoch: 2868 [23040/60000 (38%)] Loss: -1433.333252\n",
      "Train Epoch: 2868 [34304/60000 (57%)] Loss: -1510.049805\n",
      "Train Epoch: 2868 [45568/60000 (76%)] Loss: -1441.834961\n",
      "Train Epoch: 2868 [56832/60000 (95%)] Loss: -1471.750977\n",
      "    epoch          : 2868\n",
      "    loss           : -1465.564973130738\n",
      "Train Epoch: 2869 [512/60000 (1%)] Loss: -1407.668457\n",
      "Train Epoch: 2869 [11776/60000 (20%)] Loss: -1296.253784\n",
      "Train Epoch: 2869 [23040/60000 (38%)] Loss: -1374.523926\n",
      "Train Epoch: 2869 [34304/60000 (57%)] Loss: -1499.355469\n",
      "Train Epoch: 2869 [45568/60000 (76%)] Loss: -1381.038086\n",
      "Train Epoch: 2869 [56832/60000 (95%)] Loss: -1460.020996\n",
      "    epoch          : 2869\n",
      "    loss           : -1472.009211136123\n",
      "Train Epoch: 2870 [512/60000 (1%)] Loss: -1271.010620\n",
      "Train Epoch: 2870 [11776/60000 (20%)] Loss: -1422.513916\n",
      "Train Epoch: 2870 [23040/60000 (38%)] Loss: -1586.866211\n",
      "Train Epoch: 2870 [34304/60000 (57%)] Loss: -1431.280884\n",
      "Train Epoch: 2870 [45568/60000 (76%)] Loss: -1465.661255\n",
      "Train Epoch: 2870 [56832/60000 (95%)] Loss: -1577.496338\n",
      "    epoch          : 2870\n",
      "    loss           : -1482.0526454085011\n",
      "Train Epoch: 2871 [512/60000 (1%)] Loss: -1459.110962\n",
      "Train Epoch: 2871 [11776/60000 (20%)] Loss: -1451.782715\n",
      "Train Epoch: 2871 [23040/60000 (38%)] Loss: -1369.811035\n",
      "Train Epoch: 2871 [34304/60000 (57%)] Loss: -1525.425659\n",
      "Train Epoch: 2871 [45568/60000 (76%)] Loss: -1404.102783\n",
      "Train Epoch: 2871 [56832/60000 (95%)] Loss: -1483.001099\n",
      "    epoch          : 2871\n",
      "    loss           : -1464.6320497329627\n",
      "Train Epoch: 2872 [512/60000 (1%)] Loss: -1319.908936\n",
      "Train Epoch: 2872 [11776/60000 (20%)] Loss: -1575.862915\n",
      "Train Epoch: 2872 [23040/60000 (38%)] Loss: -1429.645874\n",
      "Train Epoch: 2872 [34304/60000 (57%)] Loss: -1475.690674\n",
      "Train Epoch: 2872 [45568/60000 (76%)] Loss: -1468.234375\n",
      "Train Epoch: 2872 [56832/60000 (95%)] Loss: -1541.788208\n",
      "    epoch          : 2872\n",
      "    loss           : -1477.3865546102577\n",
      "Train Epoch: 2873 [512/60000 (1%)] Loss: -1359.972900\n",
      "Train Epoch: 2873 [11776/60000 (20%)] Loss: -1304.292236\n",
      "Train Epoch: 2873 [23040/60000 (38%)] Loss: -1466.621826\n",
      "Train Epoch: 2873 [34304/60000 (57%)] Loss: -1466.301636\n",
      "Train Epoch: 2873 [45568/60000 (76%)] Loss: -1461.658569\n",
      "Train Epoch: 2873 [56832/60000 (95%)] Loss: -1484.822510\n",
      "    epoch          : 2873\n",
      "    loss           : -1474.9897516110523\n",
      "Train Epoch: 2874 [512/60000 (1%)] Loss: -1577.669556\n",
      "Train Epoch: 2874 [11776/60000 (20%)] Loss: -1547.016235\n",
      "Train Epoch: 2874 [23040/60000 (38%)] Loss: -1546.372803\n",
      "Train Epoch: 2874 [34304/60000 (57%)] Loss: -1382.833984\n",
      "Train Epoch: 2874 [45568/60000 (76%)] Loss: -1416.387329\n",
      "Train Epoch: 2874 [56832/60000 (95%)] Loss: -1583.842407\n",
      "    epoch          : 2874\n",
      "    loss           : -1481.059702382923\n",
      "Train Epoch: 2875 [512/60000 (1%)] Loss: -1417.068970\n",
      "Train Epoch: 2875 [11776/60000 (20%)] Loss: -1565.255249\n",
      "Train Epoch: 2875 [23040/60000 (38%)] Loss: -1568.687378\n",
      "Train Epoch: 2875 [34304/60000 (57%)] Loss: -1421.740845\n",
      "Train Epoch: 2875 [45568/60000 (76%)] Loss: -1584.150635\n",
      "Train Epoch: 2875 [56832/60000 (95%)] Loss: -1571.146362\n",
      "    epoch          : 2875\n",
      "    loss           : -1470.2521103681145\n",
      "Train Epoch: 2876 [512/60000 (1%)] Loss: -1400.623901\n",
      "Train Epoch: 2876 [11776/60000 (20%)] Loss: -1532.671021\n",
      "Train Epoch: 2876 [23040/60000 (38%)] Loss: -1369.277588\n",
      "Train Epoch: 2876 [34304/60000 (57%)] Loss: -1412.699829\n",
      "Train Epoch: 2876 [45568/60000 (76%)] Loss: -1563.020752\n",
      "Train Epoch: 2876 [56832/60000 (95%)] Loss: -1361.274048\n",
      "    epoch          : 2876\n",
      "    loss           : -1465.6123305498543\n",
      "Train Epoch: 2877 [512/60000 (1%)] Loss: -1388.663208\n",
      "Train Epoch: 2877 [11776/60000 (20%)] Loss: -1464.792114\n",
      "Train Epoch: 2877 [23040/60000 (38%)] Loss: -1430.473145\n",
      "Train Epoch: 2877 [34304/60000 (57%)] Loss: -1535.994141\n",
      "Train Epoch: 2877 [45568/60000 (76%)] Loss: -1567.167969\n",
      "Train Epoch: 2877 [56832/60000 (95%)] Loss: -1544.974976\n",
      "    epoch          : 2877\n",
      "    loss           : -1472.4144411248676\n",
      "Train Epoch: 2878 [512/60000 (1%)] Loss: -1506.376343\n",
      "Train Epoch: 2878 [11776/60000 (20%)] Loss: -1457.386230\n",
      "Train Epoch: 2878 [23040/60000 (38%)] Loss: -1346.545532\n",
      "Train Epoch: 2878 [34304/60000 (57%)] Loss: -1468.156738\n",
      "Train Epoch: 2878 [45568/60000 (76%)] Loss: -1562.914551\n",
      "Train Epoch: 2878 [56832/60000 (95%)] Loss: -1438.480469\n",
      "    epoch          : 2878\n",
      "    loss           : -1461.7276714777543\n",
      "Train Epoch: 2879 [512/60000 (1%)] Loss: -1453.746582\n",
      "Train Epoch: 2879 [11776/60000 (20%)] Loss: -1495.762695\n",
      "Train Epoch: 2879 [23040/60000 (38%)] Loss: -1437.151245\n",
      "Train Epoch: 2879 [34304/60000 (57%)] Loss: -1555.066650\n",
      "Train Epoch: 2879 [45568/60000 (76%)] Loss: -1448.362061\n",
      "Train Epoch: 2879 [56832/60000 (95%)] Loss: -1561.779053\n",
      "    epoch          : 2879\n",
      "    loss           : -1469.0073193911105\n",
      "Train Epoch: 2880 [512/60000 (1%)] Loss: -1548.496338\n",
      "Train Epoch: 2880 [11776/60000 (20%)] Loss: -1452.174072\n",
      "Train Epoch: 2880 [23040/60000 (38%)] Loss: -1397.932251\n",
      "Train Epoch: 2880 [34304/60000 (57%)] Loss: -1521.680542\n",
      "Train Epoch: 2880 [45568/60000 (76%)] Loss: -1445.007568\n",
      "Train Epoch: 2880 [56832/60000 (95%)] Loss: -1581.660278\n",
      "    epoch          : 2880\n",
      "    loss           : -1479.2051408843133\n",
      "Train Epoch: 2881 [512/60000 (1%)] Loss: -1515.954590\n",
      "Train Epoch: 2881 [11776/60000 (20%)] Loss: -1362.041748\n",
      "Train Epoch: 2881 [23040/60000 (38%)] Loss: -1532.133545\n",
      "Train Epoch: 2881 [34304/60000 (57%)] Loss: -1419.790527\n",
      "Train Epoch: 2881 [45568/60000 (76%)] Loss: -1465.167725\n",
      "Train Epoch: 2881 [56832/60000 (95%)] Loss: -1489.907349\n",
      "    epoch          : 2881\n",
      "    loss           : -1469.0708004364187\n",
      "Train Epoch: 2882 [512/60000 (1%)] Loss: -1522.580811\n",
      "Train Epoch: 2882 [11776/60000 (20%)] Loss: -1406.305420\n",
      "Train Epoch: 2882 [23040/60000 (38%)] Loss: -1540.978394\n",
      "Train Epoch: 2882 [34304/60000 (57%)] Loss: -1502.442505\n",
      "Train Epoch: 2882 [45568/60000 (76%)] Loss: -1536.797607\n",
      "Train Epoch: 2882 [56832/60000 (95%)] Loss: -1527.255859\n",
      "    epoch          : 2882\n",
      "    loss           : -1477.1733784648657\n",
      "Train Epoch: 2883 [512/60000 (1%)] Loss: -1563.609985\n",
      "Train Epoch: 2883 [11776/60000 (20%)] Loss: -1571.456787\n",
      "Train Epoch: 2883 [23040/60000 (38%)] Loss: -1465.314697\n",
      "Train Epoch: 2883 [34304/60000 (57%)] Loss: -1437.749756\n",
      "Train Epoch: 2883 [45568/60000 (76%)] Loss: -1439.204346\n",
      "Train Epoch: 2883 [56832/60000 (95%)] Loss: -1369.847168\n",
      "    epoch          : 2883\n",
      "    loss           : -1479.5830364335056\n",
      "Train Epoch: 2884 [512/60000 (1%)] Loss: -1432.398193\n",
      "Train Epoch: 2884 [11776/60000 (20%)] Loss: -1562.368652\n",
      "Train Epoch: 2884 [23040/60000 (38%)] Loss: -1372.894043\n",
      "Train Epoch: 2884 [34304/60000 (57%)] Loss: -1467.507812\n",
      "Train Epoch: 2884 [45568/60000 (76%)] Loss: -1562.321899\n",
      "Train Epoch: 2884 [56832/60000 (95%)] Loss: -1419.209839\n",
      "    epoch          : 2884\n",
      "    loss           : -1479.4153763076006\n",
      "Train Epoch: 2885 [512/60000 (1%)] Loss: -1472.133789\n",
      "Train Epoch: 2885 [11776/60000 (20%)] Loss: -1404.143311\n",
      "Train Epoch: 2885 [23040/60000 (38%)] Loss: -1537.782715\n",
      "Train Epoch: 2885 [34304/60000 (57%)] Loss: -1532.340576\n",
      "Train Epoch: 2885 [45568/60000 (76%)] Loss: -1575.474487\n",
      "Train Epoch: 2885 [56832/60000 (95%)] Loss: -1443.064697\n",
      "    epoch          : 2885\n",
      "    loss           : -1476.336010604255\n",
      "Train Epoch: 2886 [512/60000 (1%)] Loss: -1524.650879\n",
      "Train Epoch: 2886 [11776/60000 (20%)] Loss: -1427.002686\n",
      "Train Epoch: 2886 [23040/60000 (38%)] Loss: -1454.448975\n",
      "Train Epoch: 2886 [34304/60000 (57%)] Loss: -1445.967773\n",
      "Train Epoch: 2886 [45568/60000 (76%)] Loss: -1523.615234\n",
      "Train Epoch: 2886 [56832/60000 (95%)] Loss: -1376.000000\n",
      "    epoch          : 2886\n",
      "    loss           : -1470.2689922785355\n",
      "Train Epoch: 2887 [512/60000 (1%)] Loss: -1421.431396\n",
      "Train Epoch: 2887 [11776/60000 (20%)] Loss: -1389.186523\n",
      "Train Epoch: 2887 [23040/60000 (38%)] Loss: -1419.537842\n",
      "Train Epoch: 2887 [34304/60000 (57%)] Loss: -1514.684570\n",
      "Train Epoch: 2887 [45568/60000 (76%)] Loss: -1510.081055\n",
      "Train Epoch: 2887 [56832/60000 (95%)] Loss: -1571.925781\n",
      "    epoch          : 2887\n",
      "    loss           : -1472.146109888109\n",
      "Train Epoch: 2888 [512/60000 (1%)] Loss: -1496.588379\n",
      "Train Epoch: 2888 [11776/60000 (20%)] Loss: -1404.883667\n",
      "Train Epoch: 2888 [23040/60000 (38%)] Loss: -1387.841064\n",
      "Train Epoch: 2888 [34304/60000 (57%)] Loss: -1433.744751\n",
      "Train Epoch: 2888 [45568/60000 (76%)] Loss: -1543.633667\n",
      "Train Epoch: 2888 [56832/60000 (95%)] Loss: -1430.006226\n",
      "    epoch          : 2888\n",
      "    loss           : -1474.880282816914\n",
      "Train Epoch: 2889 [512/60000 (1%)] Loss: -1531.611572\n",
      "Train Epoch: 2889 [11776/60000 (20%)] Loss: -1473.927124\n",
      "Train Epoch: 2889 [23040/60000 (38%)] Loss: -1306.694824\n",
      "Train Epoch: 2889 [34304/60000 (57%)] Loss: -1467.303833\n",
      "Train Epoch: 2889 [45568/60000 (76%)] Loss: -1483.160400\n",
      "Train Epoch: 2889 [56832/60000 (95%)] Loss: -1503.737549\n",
      "    epoch          : 2889\n",
      "    loss           : -1473.2407674843307\n",
      "Train Epoch: 2890 [512/60000 (1%)] Loss: -1435.015747\n",
      "Train Epoch: 2890 [11776/60000 (20%)] Loss: -1476.251221\n",
      "Train Epoch: 2890 [23040/60000 (38%)] Loss: -1573.290161\n",
      "Train Epoch: 2890 [34304/60000 (57%)] Loss: -1432.573608\n",
      "Train Epoch: 2890 [45568/60000 (76%)] Loss: -1573.412109\n",
      "Train Epoch: 2890 [56832/60000 (95%)] Loss: -1384.528198\n",
      "    epoch          : 2890\n",
      "    loss           : -1469.5170098428673\n",
      "Train Epoch: 2891 [512/60000 (1%)] Loss: -1570.221069\n",
      "Train Epoch: 2891 [11776/60000 (20%)] Loss: -1568.476196\n",
      "Train Epoch: 2891 [23040/60000 (38%)] Loss: -1519.367676\n",
      "Train Epoch: 2891 [34304/60000 (57%)] Loss: -1466.226807\n",
      "Train Epoch: 2891 [45568/60000 (76%)] Loss: -1371.374023\n",
      "Train Epoch: 2891 [56832/60000 (95%)] Loss: -1483.111450\n",
      "    epoch          : 2891\n",
      "    loss           : -1469.238050212968\n",
      "Train Epoch: 2892 [512/60000 (1%)] Loss: -1361.800781\n",
      "Train Epoch: 2892 [11776/60000 (20%)] Loss: -1506.829834\n",
      "Train Epoch: 2892 [23040/60000 (38%)] Loss: -1440.576538\n",
      "Train Epoch: 2892 [34304/60000 (57%)] Loss: -1578.791382\n",
      "Train Epoch: 2892 [45568/60000 (76%)] Loss: -1419.206543\n",
      "Train Epoch: 2892 [56832/60000 (95%)] Loss: -1519.798218\n",
      "    epoch          : 2892\n",
      "    loss           : -1476.5125146208509\n",
      "Train Epoch: 2893 [512/60000 (1%)] Loss: -1421.680908\n",
      "Train Epoch: 2893 [11776/60000 (20%)] Loss: -1416.068848\n",
      "Train Epoch: 2893 [23040/60000 (38%)] Loss: -1484.256104\n",
      "Train Epoch: 2893 [34304/60000 (57%)] Loss: -1510.044556\n",
      "Train Epoch: 2893 [45568/60000 (76%)] Loss: -1545.377441\n",
      "Train Epoch: 2893 [56832/60000 (95%)] Loss: -1398.712158\n",
      "    epoch          : 2893\n",
      "    loss           : -1475.6928507486978\n",
      "Train Epoch: 2894 [512/60000 (1%)] Loss: -1451.084839\n",
      "Train Epoch: 2894 [11776/60000 (20%)] Loss: -1521.837158\n",
      "Train Epoch: 2894 [23040/60000 (38%)] Loss: -1589.613281\n",
      "Train Epoch: 2894 [34304/60000 (57%)] Loss: -1518.805054\n",
      "Train Epoch: 2894 [45568/60000 (76%)] Loss: -1536.626343\n",
      "Train Epoch: 2894 [56832/60000 (95%)] Loss: -1515.351685\n",
      "    epoch          : 2894\n",
      "    loss           : -1476.2781589314088\n",
      "Train Epoch: 2895 [512/60000 (1%)] Loss: -1549.783936\n",
      "Train Epoch: 2895 [11776/60000 (20%)] Loss: -1436.480957\n",
      "Train Epoch: 2895 [23040/60000 (38%)] Loss: -1522.601440\n",
      "Train Epoch: 2895 [34304/60000 (57%)] Loss: -1433.881470\n",
      "Train Epoch: 2895 [45568/60000 (76%)] Loss: -1476.872681\n",
      "Train Epoch: 2895 [56832/60000 (95%)] Loss: -1473.142578\n",
      "    epoch          : 2895\n",
      "    loss           : -1472.9108707406428\n",
      "Train Epoch: 2896 [512/60000 (1%)] Loss: -1407.555420\n",
      "Train Epoch: 2896 [11776/60000 (20%)] Loss: -1532.408081\n",
      "Train Epoch: 2896 [23040/60000 (38%)] Loss: -1410.722290\n",
      "Train Epoch: 2896 [34304/60000 (57%)] Loss: -1530.476318\n",
      "Train Epoch: 2896 [45568/60000 (76%)] Loss: -1463.272583\n",
      "Train Epoch: 2896 [56832/60000 (95%)] Loss: -1409.559570\n",
      "    epoch          : 2896\n",
      "    loss           : -1475.1105508750443\n",
      "Train Epoch: 2897 [512/60000 (1%)] Loss: -1329.568726\n",
      "Train Epoch: 2897 [11776/60000 (20%)] Loss: -1341.377563\n",
      "Train Epoch: 2897 [23040/60000 (38%)] Loss: -1476.731812\n",
      "Train Epoch: 2897 [34304/60000 (57%)] Loss: -1432.737549\n",
      "Train Epoch: 2897 [45568/60000 (76%)] Loss: -1568.517822\n",
      "Train Epoch: 2897 [56832/60000 (95%)] Loss: -1429.323242\n",
      "    epoch          : 2897\n",
      "    loss           : -1470.4946726998367\n",
      "Train Epoch: 2898 [512/60000 (1%)] Loss: -1550.078369\n",
      "Train Epoch: 2898 [11776/60000 (20%)] Loss: -1455.849121\n",
      "Train Epoch: 2898 [23040/60000 (38%)] Loss: -1418.101440\n",
      "Train Epoch: 2898 [34304/60000 (57%)] Loss: -1554.752441\n",
      "Train Epoch: 2898 [45568/60000 (76%)] Loss: -1520.984619\n",
      "Train Epoch: 2898 [56832/60000 (95%)] Loss: -1474.203003\n",
      "    epoch          : 2898\n",
      "    loss           : -1476.0665565964864\n",
      "Train Epoch: 2899 [512/60000 (1%)] Loss: -1416.972534\n",
      "Train Epoch: 2899 [11776/60000 (20%)] Loss: -1488.321289\n",
      "Train Epoch: 2899 [23040/60000 (38%)] Loss: -1461.631836\n",
      "Train Epoch: 2899 [34304/60000 (57%)] Loss: -1339.435547\n",
      "Train Epoch: 2899 [45568/60000 (76%)] Loss: -1448.400757\n",
      "Train Epoch: 2899 [56832/60000 (95%)] Loss: -1466.188477\n",
      "    epoch          : 2899\n",
      "    loss           : -1472.8135807015803\n",
      "Train Epoch: 2900 [512/60000 (1%)] Loss: -1534.216064\n",
      "Train Epoch: 2900 [11776/60000 (20%)] Loss: -1552.616821\n",
      "Train Epoch: 2900 [23040/60000 (38%)] Loss: -1442.908569\n",
      "Train Epoch: 2900 [34304/60000 (57%)] Loss: -1307.254761\n",
      "Train Epoch: 2900 [45568/60000 (76%)] Loss: -1458.363770\n",
      "Train Epoch: 2900 [56832/60000 (95%)] Loss: -1473.030518\n",
      "    epoch          : 2900\n",
      "    loss           : -1472.1572138037386\n",
      "Saving checkpoint: saved/models/Mnist_DeepGenerativeOperad/0127_111843/checkpoint-epoch2900.pth ...\n",
      "Train Epoch: 2901 [512/60000 (1%)] Loss: -1369.596436\n",
      "Train Epoch: 2901 [11776/60000 (20%)] Loss: -1551.270874\n",
      "Train Epoch: 2901 [23040/60000 (38%)] Loss: -1478.354980\n",
      "Train Epoch: 2901 [34304/60000 (57%)] Loss: -1488.974121\n",
      "Train Epoch: 2901 [45568/60000 (76%)] Loss: -1573.740967\n",
      "Train Epoch: 2901 [56832/60000 (95%)] Loss: -1504.557983\n",
      "    epoch          : 2901\n",
      "    loss           : -1465.0570599399716\n",
      "Train Epoch: 2902 [512/60000 (1%)] Loss: -1480.958984\n",
      "Train Epoch: 2902 [11776/60000 (20%)] Loss: -1567.109985\n",
      "Train Epoch: 2902 [23040/60000 (38%)] Loss: -1480.613647\n",
      "Train Epoch: 2902 [34304/60000 (57%)] Loss: -1462.907593\n",
      "Train Epoch: 2902 [45568/60000 (76%)] Loss: -1469.697021\n",
      "Train Epoch: 2902 [56832/60000 (95%)] Loss: -1434.565674\n",
      "    epoch          : 2902\n",
      "    loss           : -1474.7531752074506\n",
      "Train Epoch: 2903 [512/60000 (1%)] Loss: -1496.635010\n",
      "Train Epoch: 2903 [11776/60000 (20%)] Loss: -1514.297607\n",
      "Train Epoch: 2903 [23040/60000 (38%)] Loss: -1435.947510\n",
      "Train Epoch: 2903 [34304/60000 (57%)] Loss: -1475.674805\n",
      "Train Epoch: 2903 [45568/60000 (76%)] Loss: -1411.361206\n",
      "Train Epoch: 2903 [56832/60000 (95%)] Loss: -1459.355225\n",
      "    epoch          : 2903\n",
      "    loss           : -1477.68763138076\n",
      "Train Epoch: 2904 [512/60000 (1%)] Loss: -1511.619141\n",
      "Train Epoch: 2904 [11776/60000 (20%)] Loss: -1453.783936\n",
      "Train Epoch: 2904 [23040/60000 (38%)] Loss: -1549.156006\n",
      "Train Epoch: 2904 [34304/60000 (57%)] Loss: -1573.306152\n",
      "Train Epoch: 2904 [45568/60000 (76%)] Loss: -1414.244873\n",
      "Train Epoch: 2904 [56832/60000 (95%)] Loss: -1514.422241\n",
      "    epoch          : 2904\n",
      "    loss           : -1482.9867060602048\n",
      "Train Epoch: 2905 [512/60000 (1%)] Loss: -1463.834961\n",
      "Train Epoch: 2905 [11776/60000 (20%)] Loss: -1491.609741\n",
      "Train Epoch: 2905 [23040/60000 (38%)] Loss: -1583.181519\n",
      "Train Epoch: 2905 [34304/60000 (57%)] Loss: -1505.753906\n",
      "Train Epoch: 2905 [45568/60000 (76%)] Loss: -1484.693237\n",
      "Train Epoch: 2905 [56832/60000 (95%)] Loss: -1415.276855\n",
      "    epoch          : 2905\n",
      "    loss           : -1472.7500503453832\n",
      "Train Epoch: 2906 [512/60000 (1%)] Loss: -1515.181885\n",
      "Train Epoch: 2906 [11776/60000 (20%)] Loss: -1434.603394\n",
      "Train Epoch: 2906 [23040/60000 (38%)] Loss: -1411.629028\n",
      "Train Epoch: 2906 [34304/60000 (57%)] Loss: -1469.392090\n",
      "Train Epoch: 2906 [45568/60000 (76%)] Loss: -1482.190186\n",
      "Train Epoch: 2906 [56832/60000 (95%)] Loss: -1441.357422\n",
      "    epoch          : 2906\n",
      "    loss           : -1471.6823364947477\n",
      "Train Epoch: 2907 [512/60000 (1%)] Loss: -1530.659302\n",
      "Train Epoch: 2907 [11776/60000 (20%)] Loss: -1575.857056\n",
      "Train Epoch: 2907 [23040/60000 (38%)] Loss: -1569.524170\n",
      "Train Epoch: 2907 [34304/60000 (57%)] Loss: -1578.299072\n",
      "Train Epoch: 2907 [45568/60000 (76%)] Loss: -1370.468872\n",
      "Train Epoch: 2907 [56832/60000 (95%)] Loss: -1385.120605\n",
      "    epoch          : 2907\n",
      "    loss           : -1484.6581658832097\n",
      "Train Epoch: 2908 [512/60000 (1%)] Loss: -1480.163696\n",
      "Train Epoch: 2908 [11776/60000 (20%)] Loss: -1389.601196\n",
      "Train Epoch: 2908 [23040/60000 (38%)] Loss: -1441.564819\n",
      "Train Epoch: 2908 [34304/60000 (57%)] Loss: -1352.949585\n",
      "Train Epoch: 2908 [45568/60000 (76%)] Loss: -1426.507935\n",
      "Train Epoch: 2908 [56832/60000 (95%)] Loss: -1427.338623\n",
      "    epoch          : 2908\n",
      "    loss           : -1469.2011253227622\n",
      "Train Epoch: 2909 [512/60000 (1%)] Loss: -1463.771729\n",
      "Train Epoch: 2909 [11776/60000 (20%)] Loss: -1601.528564\n",
      "Train Epoch: 2909 [23040/60000 (38%)] Loss: -1464.034424\n",
      "Train Epoch: 2909 [34304/60000 (57%)] Loss: -1467.675049\n",
      "Train Epoch: 2909 [45568/60000 (76%)] Loss: -1556.433838\n",
      "Train Epoch: 2909 [56832/60000 (95%)] Loss: -1575.607910\n",
      "    epoch          : 2909\n",
      "    loss           : -1482.2959618864759\n",
      "Train Epoch: 2910 [512/60000 (1%)] Loss: -1503.632568\n",
      "Train Epoch: 2910 [11776/60000 (20%)] Loss: -1451.536133\n",
      "Train Epoch: 2910 [23040/60000 (38%)] Loss: -1557.839111\n",
      "Train Epoch: 2910 [34304/60000 (57%)] Loss: -1459.304565\n",
      "Train Epoch: 2910 [45568/60000 (76%)] Loss: -1509.458862\n",
      "Train Epoch: 2910 [56832/60000 (95%)] Loss: -1508.452393\n",
      "    epoch          : 2910\n",
      "    loss           : -1467.4063493114406\n",
      "Train Epoch: 2911 [512/60000 (1%)] Loss: -1531.130371\n",
      "Train Epoch: 2911 [11776/60000 (20%)] Loss: -1517.144043\n",
      "Train Epoch: 2911 [23040/60000 (38%)] Loss: -1463.855835\n",
      "Train Epoch: 2911 [34304/60000 (57%)] Loss: -1389.270264\n",
      "Train Epoch: 2911 [45568/60000 (76%)] Loss: -1422.828125\n",
      "Train Epoch: 2911 [56832/60000 (95%)] Loss: -1470.120117\n",
      "    epoch          : 2911\n",
      "    loss           : -1466.2741861289505\n",
      "Train Epoch: 2912 [512/60000 (1%)] Loss: -1511.555542\n",
      "Train Epoch: 2912 [11776/60000 (20%)] Loss: -1524.268433\n",
      "Train Epoch: 2912 [23040/60000 (38%)] Loss: -1495.143555\n",
      "Train Epoch: 2912 [34304/60000 (57%)] Loss: -1462.897217\n",
      "Train Epoch: 2912 [45568/60000 (76%)] Loss: -1574.601196\n",
      "Train Epoch: 2912 [56832/60000 (95%)] Loss: -1397.802490\n",
      "    epoch          : 2912\n",
      "    loss           : -1467.5673869504767\n",
      "Train Epoch: 2913 [512/60000 (1%)] Loss: -1566.517822\n",
      "Train Epoch: 2913 [11776/60000 (20%)] Loss: -1516.778687\n",
      "Train Epoch: 2913 [23040/60000 (38%)] Loss: -1462.238647\n",
      "Train Epoch: 2913 [34304/60000 (57%)] Loss: -1442.346069\n",
      "Train Epoch: 2913 [45568/60000 (76%)] Loss: -1464.349609\n",
      "Train Epoch: 2913 [56832/60000 (95%)] Loss: -1448.791992\n",
      "    epoch          : 2913\n",
      "    loss           : -1469.8779683086157\n",
      "Train Epoch: 2914 [512/60000 (1%)] Loss: -1549.416260\n",
      "Train Epoch: 2914 [11776/60000 (20%)] Loss: -1500.760986\n",
      "Train Epoch: 2914 [23040/60000 (38%)] Loss: -1480.060303\n",
      "Train Epoch: 2914 [34304/60000 (57%)] Loss: -1416.333008\n",
      "Train Epoch: 2914 [45568/60000 (76%)] Loss: -1522.041138\n",
      "Train Epoch: 2914 [56832/60000 (95%)] Loss: -1441.079224\n",
      "    epoch          : 2914\n",
      "    loss           : -1468.4046172233625\n",
      "Train Epoch: 2915 [512/60000 (1%)] Loss: -1468.635986\n",
      "Train Epoch: 2915 [11776/60000 (20%)] Loss: -1537.175415\n",
      "Train Epoch: 2915 [23040/60000 (38%)] Loss: -1463.681641\n",
      "Train Epoch: 2915 [34304/60000 (57%)] Loss: -1423.380005\n",
      "Train Epoch: 2915 [45568/60000 (76%)] Loss: -1532.627319\n",
      "Train Epoch: 2915 [56832/60000 (95%)] Loss: -1508.510132\n",
      "    epoch          : 2915\n",
      "    loss           : -1478.3758386299435\n",
      "Train Epoch: 2916 [512/60000 (1%)] Loss: -1536.134644\n",
      "Train Epoch: 2916 [11776/60000 (20%)] Loss: -1503.677246\n",
      "Train Epoch: 2916 [23040/60000 (38%)] Loss: -1450.382568\n",
      "Train Epoch: 2916 [34304/60000 (57%)] Loss: -1385.681396\n",
      "Train Epoch: 2916 [45568/60000 (76%)] Loss: -1513.664795\n",
      "Train Epoch: 2916 [56832/60000 (95%)] Loss: -1452.054688\n",
      "    epoch          : 2916\n",
      "    loss           : -1477.757421116371\n",
      "Train Epoch: 2917 [512/60000 (1%)] Loss: -1399.636719\n",
      "Train Epoch: 2917 [11776/60000 (20%)] Loss: -1567.674805\n",
      "Train Epoch: 2917 [23040/60000 (38%)] Loss: -1446.355469\n",
      "Train Epoch: 2917 [34304/60000 (57%)] Loss: -1534.152832\n",
      "Train Epoch: 2917 [45568/60000 (76%)] Loss: -1435.554565\n",
      "Train Epoch: 2917 [56832/60000 (95%)] Loss: -1550.407349\n",
      "    epoch          : 2917\n",
      "    loss           : -1491.115928865422\n",
      "Train Epoch: 2918 [512/60000 (1%)] Loss: -1428.682739\n",
      "Train Epoch: 2918 [11776/60000 (20%)] Loss: -1409.654907\n",
      "Train Epoch: 2918 [23040/60000 (38%)] Loss: -1455.792725\n",
      "Train Epoch: 2918 [34304/60000 (57%)] Loss: -1514.402832\n",
      "Train Epoch: 2918 [45568/60000 (76%)] Loss: -1406.555786\n",
      "Train Epoch: 2918 [56832/60000 (95%)] Loss: -1526.073853\n",
      "    epoch          : 2918\n",
      "    loss           : -1471.66138316009\n",
      "Train Epoch: 2919 [512/60000 (1%)] Loss: -1565.483398\n",
      "Train Epoch: 2919 [11776/60000 (20%)] Loss: -1526.203125\n",
      "Train Epoch: 2919 [23040/60000 (38%)] Loss: -1435.577881\n",
      "Train Epoch: 2919 [34304/60000 (57%)] Loss: -1532.817871\n",
      "Train Epoch: 2919 [45568/60000 (76%)] Loss: -1516.090332\n",
      "Train Epoch: 2919 [56832/60000 (95%)] Loss: -1470.997803\n",
      "    epoch          : 2919\n",
      "    loss           : -1481.728402865135\n",
      "Train Epoch: 2920 [512/60000 (1%)] Loss: -1494.794067\n",
      "Train Epoch: 2920 [11776/60000 (20%)] Loss: -1566.812012\n",
      "Train Epoch: 2920 [23040/60000 (38%)] Loss: -1497.232422\n",
      "Train Epoch: 2920 [34304/60000 (57%)] Loss: -1520.286743\n",
      "Train Epoch: 2920 [45568/60000 (76%)] Loss: -1584.917725\n",
      "Train Epoch: 2920 [56832/60000 (95%)] Loss: -1478.044434\n",
      "    epoch          : 2920\n",
      "    loss           : -1481.960525081656\n",
      "Train Epoch: 2921 [512/60000 (1%)] Loss: -1539.875122\n",
      "Train Epoch: 2921 [11776/60000 (20%)] Loss: -1355.083008\n",
      "Train Epoch: 2921 [23040/60000 (38%)] Loss: -1517.650757\n",
      "Train Epoch: 2921 [34304/60000 (57%)] Loss: -1569.905640\n",
      "Train Epoch: 2921 [45568/60000 (76%)] Loss: -1473.840820\n",
      "Train Epoch: 2921 [56832/60000 (95%)] Loss: -1350.936157\n",
      "    epoch          : 2921\n",
      "    loss           : -1470.6779129976608\n",
      "Train Epoch: 2922 [512/60000 (1%)] Loss: -1478.625488\n",
      "Train Epoch: 2922 [11776/60000 (20%)] Loss: -1498.653320\n",
      "Train Epoch: 2922 [23040/60000 (38%)] Loss: -1582.271240\n",
      "Train Epoch: 2922 [34304/60000 (57%)] Loss: -1572.880493\n",
      "Train Epoch: 2922 [45568/60000 (76%)] Loss: -1491.215576\n",
      "Train Epoch: 2922 [56832/60000 (95%)] Loss: -1504.964722\n",
      "    epoch          : 2922\n",
      "    loss           : -1471.498660330045\n",
      "Train Epoch: 2923 [512/60000 (1%)] Loss: -1346.427979\n",
      "Train Epoch: 2923 [11776/60000 (20%)] Loss: -1516.773804\n",
      "Train Epoch: 2923 [23040/60000 (38%)] Loss: -1439.109863\n",
      "Train Epoch: 2923 [34304/60000 (57%)] Loss: -1551.605713\n",
      "Train Epoch: 2923 [45568/60000 (76%)] Loss: -1488.802979\n",
      "Train Epoch: 2923 [56832/60000 (95%)] Loss: -1478.315552\n",
      "    epoch          : 2923\n",
      "    loss           : -1474.2319922150866\n",
      "Train Epoch: 2924 [512/60000 (1%)] Loss: -1542.882935\n",
      "Train Epoch: 2924 [11776/60000 (20%)] Loss: -1570.446655\n",
      "Train Epoch: 2924 [23040/60000 (38%)] Loss: -1495.077393\n",
      "Train Epoch: 2924 [34304/60000 (57%)] Loss: -1466.100830\n",
      "Train Epoch: 2924 [45568/60000 (76%)] Loss: -1523.870361\n",
      "Train Epoch: 2924 [56832/60000 (95%)] Loss: -1485.580078\n",
      "    epoch          : 2924\n",
      "    loss           : -1473.4555574406338\n",
      "Train Epoch: 2925 [512/60000 (1%)] Loss: -1300.529053\n",
      "Train Epoch: 2925 [11776/60000 (20%)] Loss: -1516.385010\n",
      "Train Epoch: 2925 [23040/60000 (38%)] Loss: -1492.252441\n",
      "Train Epoch: 2925 [34304/60000 (57%)] Loss: -1457.394775\n",
      "Train Epoch: 2925 [45568/60000 (76%)] Loss: -1486.424438\n",
      "Train Epoch: 2925 [56832/60000 (95%)] Loss: -1571.651611\n",
      "    epoch          : 2925\n",
      "    loss           : -1478.5909344516904\n",
      "Train Epoch: 2926 [512/60000 (1%)] Loss: -1536.716431\n",
      "Train Epoch: 2926 [11776/60000 (20%)] Loss: -1522.182373\n",
      "Train Epoch: 2926 [23040/60000 (38%)] Loss: -1403.505859\n",
      "Train Epoch: 2926 [34304/60000 (57%)] Loss: -1527.520752\n",
      "Train Epoch: 2926 [45568/60000 (76%)] Loss: -1395.937256\n",
      "Train Epoch: 2926 [56832/60000 (95%)] Loss: -1524.068604\n",
      "    epoch          : 2926\n",
      "    loss           : -1478.6262848417637\n",
      "Train Epoch: 2927 [512/60000 (1%)] Loss: -1398.942871\n",
      "Train Epoch: 2927 [11776/60000 (20%)] Loss: -1539.741455\n",
      "Train Epoch: 2927 [23040/60000 (38%)] Loss: -1452.330322\n",
      "Train Epoch: 2927 [34304/60000 (57%)] Loss: -1444.334595\n",
      "Train Epoch: 2927 [45568/60000 (76%)] Loss: -1561.514526\n",
      "Train Epoch: 2927 [56832/60000 (95%)] Loss: -1327.767944\n",
      "    epoch          : 2927\n",
      "    loss           : -1475.4050748146187\n",
      "Train Epoch: 2928 [512/60000 (1%)] Loss: -1455.260132\n",
      "Train Epoch: 2928 [11776/60000 (20%)] Loss: -1515.985474\n",
      "Train Epoch: 2928 [23040/60000 (38%)] Loss: -1417.752686\n",
      "Train Epoch: 2928 [34304/60000 (57%)] Loss: -1558.400879\n",
      "Train Epoch: 2928 [45568/60000 (76%)] Loss: -1548.430908\n",
      "Train Epoch: 2928 [56832/60000 (95%)] Loss: -1427.631592\n",
      "    epoch          : 2928\n",
      "    loss           : -1466.803668523239\n",
      "Train Epoch: 2929 [512/60000 (1%)] Loss: -1552.404419\n",
      "Train Epoch: 2929 [11776/60000 (20%)] Loss: -1439.294189\n",
      "Train Epoch: 2929 [23040/60000 (38%)] Loss: -1461.429810\n",
      "Train Epoch: 2929 [34304/60000 (57%)] Loss: -1374.701660\n",
      "Train Epoch: 2929 [45568/60000 (76%)] Loss: -1502.485840\n",
      "Train Epoch: 2929 [56832/60000 (95%)] Loss: -1388.498413\n",
      "    epoch          : 2929\n",
      "    loss           : -1484.2813437941386\n",
      "Train Epoch: 2930 [512/60000 (1%)] Loss: -1388.130859\n",
      "Train Epoch: 2930 [11776/60000 (20%)] Loss: -1476.457275\n",
      "Train Epoch: 2930 [23040/60000 (38%)] Loss: -1439.915527\n",
      "Train Epoch: 2930 [34304/60000 (57%)] Loss: -1549.725952\n",
      "Train Epoch: 2930 [45568/60000 (76%)] Loss: -1543.963623\n",
      "Train Epoch: 2930 [56832/60000 (95%)] Loss: -1533.505371\n",
      "    epoch          : 2930\n",
      "    loss           : -1471.350128346244\n",
      "Train Epoch: 2931 [512/60000 (1%)] Loss: -1431.322632\n",
      "Train Epoch: 2931 [11776/60000 (20%)] Loss: -1402.275391\n",
      "Train Epoch: 2931 [23040/60000 (38%)] Loss: -1541.259399\n",
      "Train Epoch: 2931 [34304/60000 (57%)] Loss: -1586.042114\n",
      "Train Epoch: 2931 [45568/60000 (76%)] Loss: -1380.258057\n",
      "Train Epoch: 2931 [56832/60000 (95%)] Loss: -1512.519775\n",
      "    epoch          : 2931\n",
      "    loss           : -1468.5723304533017\n",
      "Train Epoch: 2932 [512/60000 (1%)] Loss: -1473.396606\n",
      "Train Epoch: 2932 [11776/60000 (20%)] Loss: -1462.138672\n",
      "Train Epoch: 2932 [23040/60000 (38%)] Loss: -1446.489380\n",
      "Train Epoch: 2932 [34304/60000 (57%)] Loss: -1511.702393\n",
      "Train Epoch: 2932 [45568/60000 (76%)] Loss: -1523.591064\n",
      "Train Epoch: 2932 [56832/60000 (95%)] Loss: -1527.065063\n",
      "    epoch          : 2932\n",
      "    loss           : -1464.9648592674125\n",
      "Train Epoch: 2933 [512/60000 (1%)] Loss: -1497.860840\n",
      "Train Epoch: 2933 [11776/60000 (20%)] Loss: -1452.910034\n",
      "Train Epoch: 2933 [23040/60000 (38%)] Loss: -1364.155762\n",
      "Train Epoch: 2933 [34304/60000 (57%)] Loss: -1451.185303\n",
      "Train Epoch: 2933 [45568/60000 (76%)] Loss: -1398.111694\n",
      "Train Epoch: 2933 [56832/60000 (95%)] Loss: -1569.625000\n",
      "    epoch          : 2933\n",
      "    loss           : -1485.455114332296\n",
      "Train Epoch: 2934 [512/60000 (1%)] Loss: -1445.843262\n",
      "Train Epoch: 2934 [11776/60000 (20%)] Loss: -1522.747925\n",
      "Train Epoch: 2934 [23040/60000 (38%)] Loss: -1467.712524\n",
      "Train Epoch: 2934 [34304/60000 (57%)] Loss: -1468.700928\n",
      "Train Epoch: 2934 [45568/60000 (76%)] Loss: -1397.141113\n",
      "Train Epoch: 2934 [56832/60000 (95%)] Loss: -1508.310547\n",
      "    epoch          : 2934\n",
      "    loss           : -1473.4126748984818\n",
      "Train Epoch: 2935 [512/60000 (1%)] Loss: -1412.334351\n",
      "Train Epoch: 2935 [11776/60000 (20%)] Loss: -1454.179321\n",
      "Train Epoch: 2935 [23040/60000 (38%)] Loss: -1485.355469\n",
      "Train Epoch: 2935 [34304/60000 (57%)] Loss: -1514.832886\n",
      "Train Epoch: 2935 [45568/60000 (76%)] Loss: -1448.390503\n",
      "Train Epoch: 2935 [56832/60000 (95%)] Loss: -1538.351562\n",
      "    epoch          : 2935\n",
      "    loss           : -1477.6838347871426\n",
      "Train Epoch: 2936 [512/60000 (1%)] Loss: -1424.867920\n",
      "Train Epoch: 2936 [11776/60000 (20%)] Loss: -1379.998779\n",
      "Train Epoch: 2936 [23040/60000 (38%)] Loss: -1472.580566\n",
      "Train Epoch: 2936 [34304/60000 (57%)] Loss: -1532.671387\n",
      "Train Epoch: 2936 [45568/60000 (76%)] Loss: -1442.240845\n",
      "Train Epoch: 2936 [56832/60000 (95%)] Loss: -1455.071777\n",
      "    epoch          : 2936\n",
      "    loss           : -1471.7698281498278\n",
      "Train Epoch: 2937 [512/60000 (1%)] Loss: -1416.355957\n",
      "Train Epoch: 2937 [11776/60000 (20%)] Loss: -1501.365356\n",
      "Train Epoch: 2937 [23040/60000 (38%)] Loss: -1419.206787\n",
      "Train Epoch: 2937 [34304/60000 (57%)] Loss: -1574.954834\n",
      "Train Epoch: 2937 [45568/60000 (76%)] Loss: -1437.694946\n",
      "Train Epoch: 2937 [56832/60000 (95%)] Loss: -1487.260010\n",
      "    epoch          : 2937\n",
      "    loss           : -1478.6236837785798\n",
      "Train Epoch: 2938 [512/60000 (1%)] Loss: -1479.373413\n",
      "Train Epoch: 2938 [11776/60000 (20%)] Loss: -1527.053955\n",
      "Train Epoch: 2938 [23040/60000 (38%)] Loss: -1467.698120\n",
      "Train Epoch: 2938 [34304/60000 (57%)] Loss: -1518.438843\n",
      "Train Epoch: 2938 [45568/60000 (76%)] Loss: -1602.035156\n",
      "Train Epoch: 2938 [56832/60000 (95%)] Loss: -1370.662476\n",
      "    epoch          : 2938\n",
      "    loss           : -1475.9788080420199\n",
      "Train Epoch: 2939 [512/60000 (1%)] Loss: -1430.611572\n",
      "Train Epoch: 2939 [11776/60000 (20%)] Loss: -1548.228394\n",
      "Train Epoch: 2939 [23040/60000 (38%)] Loss: -1465.672729\n",
      "Train Epoch: 2939 [34304/60000 (57%)] Loss: -1487.999390\n",
      "Train Epoch: 2939 [45568/60000 (76%)] Loss: -1597.619385\n",
      "Train Epoch: 2939 [56832/60000 (95%)] Loss: -1398.503418\n",
      "    epoch          : 2939\n",
      "    loss           : -1479.036537989385\n",
      "Train Epoch: 2940 [512/60000 (1%)] Loss: -1405.718140\n",
      "Train Epoch: 2940 [11776/60000 (20%)] Loss: -1517.961182\n",
      "Train Epoch: 2940 [23040/60000 (38%)] Loss: -1535.021729\n",
      "Train Epoch: 2940 [34304/60000 (57%)] Loss: -1409.361572\n",
      "Train Epoch: 2940 [45568/60000 (76%)] Loss: -1543.334717\n",
      "Train Epoch: 2940 [56832/60000 (95%)] Loss: -1510.754150\n",
      "    epoch          : 2940\n",
      "    loss           : -1478.0980886685645\n",
      "Train Epoch: 2941 [512/60000 (1%)] Loss: -1474.526245\n",
      "Train Epoch: 2941 [11776/60000 (20%)] Loss: -1475.555420\n",
      "Train Epoch: 2941 [23040/60000 (38%)] Loss: -1517.068115\n",
      "Train Epoch: 2941 [34304/60000 (57%)] Loss: -1588.219116\n",
      "Train Epoch: 2941 [45568/60000 (76%)] Loss: -1425.527344\n",
      "Train Epoch: 2941 [56832/60000 (95%)] Loss: -1468.381104\n",
      "    epoch          : 2941\n",
      "    loss           : -1472.0037031443107\n",
      "Train Epoch: 2942 [512/60000 (1%)] Loss: -1446.917725\n",
      "Train Epoch: 2942 [11776/60000 (20%)] Loss: -1333.723999\n",
      "Train Epoch: 2942 [23040/60000 (38%)] Loss: -1567.925049\n",
      "Train Epoch: 2942 [34304/60000 (57%)] Loss: -1384.484253\n",
      "Train Epoch: 2942 [45568/60000 (76%)] Loss: -1384.200073\n",
      "Train Epoch: 2942 [56832/60000 (95%)] Loss: -1484.583374\n",
      "    epoch          : 2942\n",
      "    loss           : -1481.8458331264346\n",
      "Train Epoch: 2943 [512/60000 (1%)] Loss: -1448.396973\n",
      "Train Epoch: 2943 [11776/60000 (20%)] Loss: -1430.533691\n",
      "Train Epoch: 2943 [23040/60000 (38%)] Loss: -1577.690186\n",
      "Train Epoch: 2943 [34304/60000 (57%)] Loss: -1522.592041\n",
      "Train Epoch: 2943 [45568/60000 (76%)] Loss: -1425.511719\n",
      "Train Epoch: 2943 [56832/60000 (95%)] Loss: -1504.688354\n",
      "    epoch          : 2943\n",
      "    loss           : -1472.2852090092028\n",
      "Train Epoch: 2944 [512/60000 (1%)] Loss: -1381.074707\n",
      "Train Epoch: 2944 [11776/60000 (20%)] Loss: -1457.132080\n",
      "Train Epoch: 2944 [23040/60000 (38%)] Loss: -1455.631104\n",
      "Train Epoch: 2944 [34304/60000 (57%)] Loss: -1578.657471\n",
      "Train Epoch: 2944 [45568/60000 (76%)] Loss: -1543.807007\n",
      "Train Epoch: 2944 [56832/60000 (95%)] Loss: -1420.197266\n",
      "    epoch          : 2944\n",
      "    loss           : -1475.6424046748102\n",
      "Train Epoch: 2945 [512/60000 (1%)] Loss: -1397.011475\n",
      "Train Epoch: 2945 [11776/60000 (20%)] Loss: -1427.066650\n",
      "Train Epoch: 2945 [23040/60000 (38%)] Loss: -1394.783447\n",
      "Train Epoch: 2945 [34304/60000 (57%)] Loss: -1472.180664\n",
      "Train Epoch: 2945 [45568/60000 (76%)] Loss: -1482.426880\n",
      "Train Epoch: 2945 [56832/60000 (95%)] Loss: -1317.969482\n",
      "    epoch          : 2945\n",
      "    loss           : -1469.3295326017392\n",
      "Train Epoch: 2946 [512/60000 (1%)] Loss: -1547.248535\n",
      "Train Epoch: 2946 [11776/60000 (20%)] Loss: -1599.361938\n",
      "Train Epoch: 2946 [23040/60000 (38%)] Loss: -1578.268555\n",
      "Train Epoch: 2946 [34304/60000 (57%)] Loss: -1443.934814\n",
      "Train Epoch: 2946 [45568/60000 (76%)] Loss: -1510.778198\n",
      "Train Epoch: 2946 [56832/60000 (95%)] Loss: -1405.490723\n",
      "    epoch          : 2946\n",
      "    loss           : -1479.5891154661017\n",
      "Train Epoch: 2947 [512/60000 (1%)] Loss: -1453.506592\n",
      "Train Epoch: 2947 [11776/60000 (20%)] Loss: -1512.657959\n",
      "Train Epoch: 2947 [23040/60000 (38%)] Loss: -1573.280273\n",
      "Train Epoch: 2947 [34304/60000 (57%)] Loss: -1488.516357\n",
      "Train Epoch: 2947 [45568/60000 (76%)] Loss: -1467.251343\n",
      "Train Epoch: 2947 [56832/60000 (95%)] Loss: -1285.888672\n",
      "    epoch          : 2947\n",
      "    loss           : -1474.4296685342736\n",
      "Train Epoch: 2948 [512/60000 (1%)] Loss: -1268.444336\n",
      "Train Epoch: 2948 [11776/60000 (20%)] Loss: -1589.950195\n",
      "Train Epoch: 2948 [23040/60000 (38%)] Loss: -1525.447998\n",
      "Train Epoch: 2948 [34304/60000 (57%)] Loss: -1567.061646\n",
      "Train Epoch: 2948 [45568/60000 (76%)] Loss: -1542.177246\n",
      "Train Epoch: 2948 [56832/60000 (95%)] Loss: -1382.212646\n",
      "    epoch          : 2948\n",
      "    loss           : -1475.8828280174125\n",
      "Train Epoch: 2949 [512/60000 (1%)] Loss: -1474.863159\n",
      "Train Epoch: 2949 [11776/60000 (20%)] Loss: -1585.222046\n",
      "Train Epoch: 2949 [23040/60000 (38%)] Loss: -1548.244019\n",
      "Train Epoch: 2949 [34304/60000 (57%)] Loss: -1379.887817\n",
      "Train Epoch: 2949 [45568/60000 (76%)] Loss: -1491.083496\n",
      "Train Epoch: 2949 [56832/60000 (95%)] Loss: -1518.227173\n",
      "    epoch          : 2949\n",
      "    loss           : -1496.2360026041665\n",
      "Train Epoch: 2950 [512/60000 (1%)] Loss: -1507.808105\n",
      "Train Epoch: 2950 [11776/60000 (20%)] Loss: -1514.160278\n",
      "Train Epoch: 2950 [23040/60000 (38%)] Loss: -1428.473877\n",
      "Train Epoch: 2950 [34304/60000 (57%)] Loss: -1518.334351\n",
      "Train Epoch: 2950 [45568/60000 (76%)] Loss: -1542.276611\n",
      "Train Epoch: 2950 [56832/60000 (95%)] Loss: -1392.311523\n",
      "    epoch          : 2950\n",
      "    loss           : -1483.8506721453477\n",
      "Train Epoch: 2951 [512/60000 (1%)] Loss: -1463.291748\n",
      "Train Epoch: 2951 [11776/60000 (20%)] Loss: -1483.351807\n",
      "Train Epoch: 2951 [23040/60000 (38%)] Loss: -1478.798218\n",
      "Train Epoch: 2951 [34304/60000 (57%)] Loss: -1481.059814\n",
      "Train Epoch: 2951 [45568/60000 (76%)] Loss: -1297.975220\n",
      "Train Epoch: 2951 [56832/60000 (95%)] Loss: -1585.369873\n",
      "    epoch          : 2951\n",
      "    loss           : -1474.015958796787\n",
      "Train Epoch: 2952 [512/60000 (1%)] Loss: -1556.264893\n",
      "Train Epoch: 2952 [11776/60000 (20%)] Loss: -1383.360107\n",
      "Train Epoch: 2952 [23040/60000 (38%)] Loss: -1418.924683\n",
      "Train Epoch: 2952 [34304/60000 (57%)] Loss: -1499.756348\n",
      "Train Epoch: 2952 [45568/60000 (76%)] Loss: -1458.586914\n",
      "Train Epoch: 2952 [56832/60000 (95%)] Loss: -1514.377319\n",
      "    epoch          : 2952\n",
      "    loss           : -1461.5133939408986\n",
      "Train Epoch: 2953 [512/60000 (1%)] Loss: -1464.583008\n",
      "Train Epoch: 2953 [11776/60000 (20%)] Loss: -1402.363403\n",
      "Train Epoch: 2953 [23040/60000 (38%)] Loss: -1421.613159\n",
      "Train Epoch: 2953 [34304/60000 (57%)] Loss: -1556.102783\n",
      "Train Epoch: 2953 [45568/60000 (76%)] Loss: -1531.945190\n",
      "Train Epoch: 2953 [56832/60000 (95%)] Loss: -1338.032471\n",
      "    epoch          : 2953\n",
      "    loss           : -1471.1714067189705\n",
      "Train Epoch: 2954 [512/60000 (1%)] Loss: -1420.625244\n",
      "Train Epoch: 2954 [11776/60000 (20%)] Loss: -1411.027832\n",
      "Train Epoch: 2954 [23040/60000 (38%)] Loss: -1566.725586\n",
      "Train Epoch: 2954 [34304/60000 (57%)] Loss: -1435.039795\n",
      "Train Epoch: 2954 [45568/60000 (76%)] Loss: -1560.946533\n",
      "Train Epoch: 2954 [56832/60000 (95%)] Loss: -1448.834229\n",
      "    epoch          : 2954\n",
      "    loss           : -1478.6762098754193\n",
      "Train Epoch: 2955 [512/60000 (1%)] Loss: -1370.277344\n",
      "Train Epoch: 2955 [11776/60000 (20%)] Loss: -1483.378174\n",
      "Train Epoch: 2955 [23040/60000 (38%)] Loss: -1412.254883\n",
      "Train Epoch: 2955 [34304/60000 (57%)] Loss: -1464.981934\n",
      "Train Epoch: 2955 [45568/60000 (76%)] Loss: -1507.599854\n",
      "Train Epoch: 2955 [56832/60000 (95%)] Loss: -1533.312012\n",
      "    epoch          : 2955\n",
      "    loss           : -1472.7663184559276\n",
      "Train Epoch: 2956 [512/60000 (1%)] Loss: -1472.351562\n",
      "Train Epoch: 2956 [11776/60000 (20%)] Loss: -1592.046143\n",
      "Train Epoch: 2956 [23040/60000 (38%)] Loss: -1527.307861\n",
      "Train Epoch: 2956 [34304/60000 (57%)] Loss: -1556.466553\n",
      "Train Epoch: 2956 [45568/60000 (76%)] Loss: -1468.968750\n",
      "Train Epoch: 2956 [56832/60000 (95%)] Loss: -1527.837646\n",
      "    epoch          : 2956\n",
      "    loss           : -1482.0290723897642\n",
      "Train Epoch: 2957 [512/60000 (1%)] Loss: -1575.325317\n",
      "Train Epoch: 2957 [11776/60000 (20%)] Loss: -1594.396729\n",
      "Train Epoch: 2957 [23040/60000 (38%)] Loss: -1502.192627\n",
      "Train Epoch: 2957 [34304/60000 (57%)] Loss: -1455.984375\n",
      "Train Epoch: 2957 [45568/60000 (76%)] Loss: -1480.745728\n",
      "Train Epoch: 2957 [56832/60000 (95%)] Loss: -1517.110596\n",
      "    epoch          : 2957\n",
      "    loss           : -1479.0580813305528\n",
      "Train Epoch: 2958 [512/60000 (1%)] Loss: -1472.635742\n",
      "Train Epoch: 2958 [11776/60000 (20%)] Loss: -1442.807373\n",
      "Train Epoch: 2958 [23040/60000 (38%)] Loss: -1449.171875\n",
      "Train Epoch: 2958 [34304/60000 (57%)] Loss: -1565.435181\n",
      "Train Epoch: 2958 [45568/60000 (76%)] Loss: -1469.097778\n",
      "Train Epoch: 2958 [56832/60000 (95%)] Loss: -1539.236084\n",
      "    epoch          : 2958\n",
      "    loss           : -1483.3032423116392\n",
      "Train Epoch: 2959 [512/60000 (1%)] Loss: -1514.213013\n",
      "Train Epoch: 2959 [11776/60000 (20%)] Loss: -1496.923218\n",
      "Train Epoch: 2959 [23040/60000 (38%)] Loss: -1489.060059\n",
      "Train Epoch: 2959 [34304/60000 (57%)] Loss: -1495.246094\n",
      "Train Epoch: 2959 [45568/60000 (76%)] Loss: -1496.069946\n",
      "Train Epoch: 2959 [56832/60000 (95%)] Loss: -1543.568359\n",
      "    epoch          : 2959\n",
      "    loss           : -1482.9693365581966\n",
      "Train Epoch: 2960 [512/60000 (1%)] Loss: -1563.871826\n",
      "Train Epoch: 2960 [11776/60000 (20%)] Loss: -1520.907471\n",
      "Train Epoch: 2960 [23040/60000 (38%)] Loss: -1461.593750\n",
      "Train Epoch: 2960 [34304/60000 (57%)] Loss: -1445.065308\n",
      "Train Epoch: 2960 [45568/60000 (76%)] Loss: -1542.098389\n",
      "Train Epoch: 2960 [56832/60000 (95%)] Loss: -1507.347656\n",
      "    epoch          : 2960\n",
      "    loss           : -1475.7063688288974\n",
      "Train Epoch: 2961 [512/60000 (1%)] Loss: -1400.426880\n",
      "Train Epoch: 2961 [11776/60000 (20%)] Loss: -1492.406860\n",
      "Train Epoch: 2961 [23040/60000 (38%)] Loss: -1591.736084\n",
      "Train Epoch: 2961 [34304/60000 (57%)] Loss: -1376.859863\n",
      "Train Epoch: 2961 [45568/60000 (76%)] Loss: -1486.125244\n",
      "Train Epoch: 2961 [56832/60000 (95%)] Loss: -1398.648682\n",
      "    epoch          : 2961\n",
      "    loss           : -1479.9743114406779\n",
      "Train Epoch: 2962 [512/60000 (1%)] Loss: -1464.970703\n",
      "Train Epoch: 2962 [11776/60000 (20%)] Loss: -1576.870483\n",
      "Train Epoch: 2962 [23040/60000 (38%)] Loss: -1418.987671\n",
      "Train Epoch: 2962 [34304/60000 (57%)] Loss: -1454.912354\n",
      "Train Epoch: 2962 [45568/60000 (76%)] Loss: -1569.342163\n",
      "Train Epoch: 2962 [56832/60000 (95%)] Loss: -1495.838867\n",
      "    epoch          : 2962\n",
      "    loss           : -1478.4597561076537\n",
      "Train Epoch: 2963 [512/60000 (1%)] Loss: -1541.309448\n",
      "Train Epoch: 2963 [11776/60000 (20%)] Loss: -1312.452881\n",
      "Train Epoch: 2963 [23040/60000 (38%)] Loss: -1535.610352\n",
      "Train Epoch: 2963 [34304/60000 (57%)] Loss: -1521.597900\n",
      "Train Epoch: 2963 [45568/60000 (76%)] Loss: -1564.759888\n",
      "Train Epoch: 2963 [56832/60000 (95%)] Loss: -1533.366699\n",
      "    epoch          : 2963\n",
      "    loss           : -1477.4320720090705\n",
      "Train Epoch: 2964 [512/60000 (1%)] Loss: -1362.435547\n",
      "Train Epoch: 2964 [11776/60000 (20%)] Loss: -1390.214844\n",
      "Train Epoch: 2964 [23040/60000 (38%)] Loss: -1477.642944\n",
      "Train Epoch: 2964 [34304/60000 (57%)] Loss: -1538.080688\n",
      "Train Epoch: 2964 [45568/60000 (76%)] Loss: -1346.622559\n",
      "Train Epoch: 2964 [56832/60000 (95%)] Loss: -1419.554932\n",
      "    epoch          : 2964\n",
      "    loss           : -1459.3107896362994\n",
      "Train Epoch: 2965 [512/60000 (1%)] Loss: -1489.193115\n",
      "Train Epoch: 2965 [11776/60000 (20%)] Loss: -1516.758911\n",
      "Train Epoch: 2965 [23040/60000 (38%)] Loss: -1485.099121\n",
      "Train Epoch: 2965 [34304/60000 (57%)] Loss: -1405.553223\n",
      "Train Epoch: 2965 [45568/60000 (76%)] Loss: -1535.023926\n",
      "Train Epoch: 2965 [56832/60000 (95%)] Loss: -1598.075439\n",
      "    epoch          : 2965\n",
      "    loss           : -1468.6083911960409\n",
      "Train Epoch: 2966 [512/60000 (1%)] Loss: -1545.556030\n",
      "Train Epoch: 2966 [11776/60000 (20%)] Loss: -1464.463257\n",
      "Train Epoch: 2966 [23040/60000 (38%)] Loss: -1455.936523\n",
      "Train Epoch: 2966 [34304/60000 (57%)] Loss: -1503.986450\n",
      "Train Epoch: 2966 [45568/60000 (76%)] Loss: -1574.206543\n",
      "Train Epoch: 2966 [56832/60000 (95%)] Loss: -1544.626709\n",
      "    epoch          : 2966\n",
      "    loss           : -1475.3296415684588\n",
      "Train Epoch: 2967 [512/60000 (1%)] Loss: -1533.996826\n",
      "Train Epoch: 2967 [11776/60000 (20%)] Loss: -1398.726074\n",
      "Train Epoch: 2967 [23040/60000 (38%)] Loss: -1516.978516\n",
      "Train Epoch: 2967 [34304/60000 (57%)] Loss: -1488.923096\n",
      "Train Epoch: 2967 [45568/60000 (76%)] Loss: -1522.906982\n",
      "Train Epoch: 2967 [56832/60000 (95%)] Loss: -1473.549561\n",
      "    epoch          : 2967\n",
      "    loss           : -1491.866609562588\n",
      "Train Epoch: 2968 [512/60000 (1%)] Loss: -1578.399658\n",
      "Train Epoch: 2968 [11776/60000 (20%)] Loss: -1553.535400\n",
      "Train Epoch: 2968 [23040/60000 (38%)] Loss: -1418.108398\n",
      "Train Epoch: 2968 [34304/60000 (57%)] Loss: -1435.927002\n",
      "Train Epoch: 2968 [45568/60000 (76%)] Loss: -1472.367798\n",
      "Train Epoch: 2968 [56832/60000 (95%)] Loss: -1466.893066\n",
      "    epoch          : 2968\n",
      "    loss           : -1483.889112569518\n",
      "Train Epoch: 2969 [512/60000 (1%)] Loss: -1518.148193\n",
      "Train Epoch: 2969 [11776/60000 (20%)] Loss: -1543.195435\n",
      "Train Epoch: 2969 [23040/60000 (38%)] Loss: -1491.278076\n",
      "Train Epoch: 2969 [34304/60000 (57%)] Loss: -1538.982666\n",
      "Train Epoch: 2969 [45568/60000 (76%)] Loss: -1420.483154\n",
      "Train Epoch: 2969 [56832/60000 (95%)] Loss: -1433.211426\n",
      "    epoch          : 2969\n",
      "    loss           : -1483.2403064447608\n",
      "Train Epoch: 2970 [512/60000 (1%)] Loss: -1601.473633\n",
      "Train Epoch: 2970 [11776/60000 (20%)] Loss: -1394.135864\n",
      "Train Epoch: 2970 [23040/60000 (38%)] Loss: -1513.600220\n",
      "Train Epoch: 2970 [34304/60000 (57%)] Loss: -1471.904907\n",
      "Train Epoch: 2970 [45568/60000 (76%)] Loss: -1467.688843\n",
      "Train Epoch: 2970 [56832/60000 (95%)] Loss: -1320.458252\n",
      "    epoch          : 2970\n",
      "    loss           : -1480.2891852599753\n",
      "Train Epoch: 2971 [512/60000 (1%)] Loss: -1340.383667\n",
      "Train Epoch: 2971 [11776/60000 (20%)] Loss: -1424.054688\n",
      "Train Epoch: 2971 [23040/60000 (38%)] Loss: -1550.977051\n",
      "Train Epoch: 2971 [34304/60000 (57%)] Loss: -1405.544434\n",
      "Train Epoch: 2971 [45568/60000 (76%)] Loss: -1558.441406\n",
      "Train Epoch: 2971 [56832/60000 (95%)] Loss: -1564.839111\n",
      "    epoch          : 2971\n",
      "    loss           : -1476.8832069871114\n",
      "Train Epoch: 2972 [512/60000 (1%)] Loss: -1498.684326\n",
      "Train Epoch: 2972 [11776/60000 (20%)] Loss: -1480.093628\n",
      "Train Epoch: 2972 [23040/60000 (38%)] Loss: -1553.199097\n",
      "Train Epoch: 2972 [34304/60000 (57%)] Loss: -1583.898193\n",
      "Train Epoch: 2972 [45568/60000 (76%)] Loss: -1494.014038\n",
      "Train Epoch: 2972 [56832/60000 (95%)] Loss: -1376.689941\n",
      "    epoch          : 2972\n",
      "    loss           : -1479.0136991166798\n",
      "Train Epoch: 2973 [512/60000 (1%)] Loss: -1564.727905\n",
      "Train Epoch: 2973 [11776/60000 (20%)] Loss: -1456.167236\n",
      "Train Epoch: 2973 [23040/60000 (38%)] Loss: -1563.648804\n",
      "Train Epoch: 2973 [34304/60000 (57%)] Loss: -1514.483643\n",
      "Train Epoch: 2973 [45568/60000 (76%)] Loss: -1392.603027\n",
      "Train Epoch: 2973 [56832/60000 (95%)] Loss: -1549.300171\n",
      "    epoch          : 2973\n",
      "    loss           : -1483.3712489241261\n",
      "Train Epoch: 2974 [512/60000 (1%)] Loss: -1323.033203\n",
      "Train Epoch: 2974 [11776/60000 (20%)] Loss: -1451.325439\n",
      "Train Epoch: 2974 [23040/60000 (38%)] Loss: -1558.057983\n",
      "Train Epoch: 2974 [34304/60000 (57%)] Loss: -1432.680054\n",
      "Train Epoch: 2974 [45568/60000 (76%)] Loss: -1522.444092\n",
      "Train Epoch: 2974 [56832/60000 (95%)] Loss: -1377.147461\n",
      "    epoch          : 2974\n",
      "    loss           : -1480.3392309846179\n",
      "Train Epoch: 2975 [512/60000 (1%)] Loss: -1335.802002\n",
      "Train Epoch: 2975 [11776/60000 (20%)] Loss: -1472.049561\n",
      "Train Epoch: 2975 [23040/60000 (38%)] Loss: -1518.036499\n",
      "Train Epoch: 2975 [34304/60000 (57%)] Loss: -1546.701904\n",
      "Train Epoch: 2975 [45568/60000 (76%)] Loss: -1545.674561\n",
      "Train Epoch: 2975 [56832/60000 (95%)] Loss: -1450.405151\n",
      "    epoch          : 2975\n",
      "    loss           : -1484.9904567912474\n",
      "Train Epoch: 2976 [512/60000 (1%)] Loss: -1509.281250\n",
      "Train Epoch: 2976 [11776/60000 (20%)] Loss: -1526.448120\n",
      "Train Epoch: 2976 [23040/60000 (38%)] Loss: -1563.630371\n",
      "Train Epoch: 2976 [34304/60000 (57%)] Loss: -1544.990967\n",
      "Train Epoch: 2976 [45568/60000 (76%)] Loss: -1462.015991\n",
      "Train Epoch: 2976 [56832/60000 (95%)] Loss: -1446.237671\n",
      "    epoch          : 2976\n",
      "    loss           : -1474.672043277719\n",
      "Train Epoch: 2977 [512/60000 (1%)] Loss: -1535.693970\n",
      "Train Epoch: 2977 [11776/60000 (20%)] Loss: -1510.726318\n",
      "Train Epoch: 2977 [23040/60000 (38%)] Loss: -1486.386108\n",
      "Train Epoch: 2977 [34304/60000 (57%)] Loss: -1418.637451\n",
      "Train Epoch: 2977 [45568/60000 (76%)] Loss: -1335.940063\n",
      "Train Epoch: 2977 [56832/60000 (95%)] Loss: -1460.537109\n",
      "    epoch          : 2977\n",
      "    loss           : -1487.9127683477886\n",
      "Train Epoch: 2978 [512/60000 (1%)] Loss: -1521.139893\n",
      "Train Epoch: 2978 [11776/60000 (20%)] Loss: -1540.080200\n",
      "Train Epoch: 2978 [23040/60000 (38%)] Loss: -1391.210327\n",
      "Train Epoch: 2978 [34304/60000 (57%)] Loss: -1546.097168\n",
      "Train Epoch: 2978 [45568/60000 (76%)] Loss: -1432.849365\n",
      "Train Epoch: 2978 [56832/60000 (95%)] Loss: -1432.435547\n",
      "    epoch          : 2978\n",
      "    loss           : -1474.6282110699153\n",
      "Train Epoch: 2979 [512/60000 (1%)] Loss: -1480.377441\n",
      "Train Epoch: 2979 [11776/60000 (20%)] Loss: -1502.669434\n",
      "Train Epoch: 2979 [23040/60000 (38%)] Loss: -1548.458130\n",
      "Train Epoch: 2979 [34304/60000 (57%)] Loss: -1374.275879\n",
      "Train Epoch: 2979 [45568/60000 (76%)] Loss: -1387.533081\n",
      "Train Epoch: 2979 [56832/60000 (95%)] Loss: -1500.190796\n",
      "    epoch          : 2979\n",
      "    loss           : -1474.2028653419625\n",
      "Train Epoch: 2980 [512/60000 (1%)] Loss: -1521.113281\n",
      "Train Epoch: 2980 [11776/60000 (20%)] Loss: -1539.799561\n",
      "Train Epoch: 2980 [23040/60000 (38%)] Loss: -1587.860840\n",
      "Train Epoch: 2980 [34304/60000 (57%)] Loss: -1447.623657\n",
      "Train Epoch: 2980 [45568/60000 (76%)] Loss: -1553.149170\n",
      "Train Epoch: 2980 [56832/60000 (95%)] Loss: -1432.318359\n",
      "    epoch          : 2980\n",
      "    loss           : -1482.6898127841412\n",
      "Train Epoch: 2981 [512/60000 (1%)] Loss: -1291.771240\n",
      "Train Epoch: 2981 [11776/60000 (20%)] Loss: -1458.633423\n",
      "Train Epoch: 2981 [23040/60000 (38%)] Loss: -1444.760132\n",
      "Train Epoch: 2981 [34304/60000 (57%)] Loss: -1493.646729\n",
      "Train Epoch: 2981 [45568/60000 (76%)] Loss: -1419.761719\n",
      "Train Epoch: 2981 [56832/60000 (95%)] Loss: -1536.085938\n",
      "    epoch          : 2981\n",
      "    loss           : -1475.407363115731\n",
      "Train Epoch: 2982 [512/60000 (1%)] Loss: -1478.980103\n",
      "Train Epoch: 2982 [11776/60000 (20%)] Loss: -1389.440063\n",
      "Train Epoch: 2982 [23040/60000 (38%)] Loss: -1541.890625\n",
      "Train Epoch: 2982 [34304/60000 (57%)] Loss: -1541.817627\n",
      "Train Epoch: 2982 [45568/60000 (76%)] Loss: -1413.007202\n",
      "Train Epoch: 2982 [56832/60000 (95%)] Loss: -1512.600342\n",
      "    epoch          : 2982\n",
      "    loss           : -1481.6048966747219\n",
      "Train Epoch: 2983 [512/60000 (1%)] Loss: -1562.045410\n",
      "Train Epoch: 2983 [11776/60000 (20%)] Loss: -1481.603271\n",
      "Train Epoch: 2983 [23040/60000 (38%)] Loss: -1463.530273\n",
      "Train Epoch: 2983 [34304/60000 (57%)] Loss: -1573.263672\n",
      "Train Epoch: 2983 [45568/60000 (76%)] Loss: -1452.485474\n",
      "Train Epoch: 2983 [56832/60000 (95%)] Loss: -1418.232422\n",
      "    epoch          : 2983\n",
      "    loss           : -1488.432033043123\n",
      "Train Epoch: 2984 [512/60000 (1%)] Loss: -1378.142822\n",
      "Train Epoch: 2984 [11776/60000 (20%)] Loss: -1527.475098\n",
      "Train Epoch: 2984 [23040/60000 (38%)] Loss: -1513.107422\n",
      "Train Epoch: 2984 [34304/60000 (57%)] Loss: -1536.419800\n",
      "Train Epoch: 2984 [45568/60000 (76%)] Loss: -1518.970093\n",
      "Train Epoch: 2984 [56832/60000 (95%)] Loss: -1515.318604\n",
      "    epoch          : 2984\n",
      "    loss           : -1488.8658026571327\n",
      "Train Epoch: 2985 [512/60000 (1%)] Loss: -1397.499512\n",
      "Train Epoch: 2985 [11776/60000 (20%)] Loss: -1438.015747\n",
      "Train Epoch: 2985 [23040/60000 (38%)] Loss: -1460.355103\n",
      "Train Epoch: 2985 [34304/60000 (57%)] Loss: -1425.576172\n",
      "Train Epoch: 2985 [45568/60000 (76%)] Loss: -1541.814819\n",
      "Train Epoch: 2985 [56832/60000 (95%)] Loss: -1409.477417\n",
      "    epoch          : 2985\n",
      "    loss           : -1486.0652748582052\n",
      "Train Epoch: 2986 [512/60000 (1%)] Loss: -1525.292236\n",
      "Train Epoch: 2986 [11776/60000 (20%)] Loss: -1601.103516\n",
      "Train Epoch: 2986 [23040/60000 (38%)] Loss: -1436.841309\n",
      "Train Epoch: 2986 [34304/60000 (57%)] Loss: -1430.289062\n",
      "Train Epoch: 2986 [45568/60000 (76%)] Loss: -1467.665527\n",
      "Train Epoch: 2986 [56832/60000 (95%)] Loss: -1423.223389\n",
      "    epoch          : 2986\n",
      "    loss           : -1480.4138124972412\n",
      "Train Epoch: 2987 [512/60000 (1%)] Loss: -1514.796631\n",
      "Train Epoch: 2987 [11776/60000 (20%)] Loss: -1514.764526\n",
      "Train Epoch: 2987 [23040/60000 (38%)] Loss: -1509.119995\n",
      "Train Epoch: 2987 [34304/60000 (57%)] Loss: -1477.203613\n",
      "Train Epoch: 2987 [45568/60000 (76%)] Loss: -1424.067139\n",
      "Train Epoch: 2987 [56832/60000 (95%)] Loss: -1467.580933\n",
      "    epoch          : 2987\n",
      "    loss           : -1484.1213161662474\n",
      "Train Epoch: 2988 [512/60000 (1%)] Loss: -1536.551270\n",
      "Train Epoch: 2988 [11776/60000 (20%)] Loss: -1439.558228\n",
      "Train Epoch: 2988 [23040/60000 (38%)] Loss: -1500.804321\n",
      "Train Epoch: 2988 [34304/60000 (57%)] Loss: -1480.196045\n",
      "Train Epoch: 2988 [45568/60000 (76%)] Loss: -1465.953003\n",
      "Train Epoch: 2988 [56832/60000 (95%)] Loss: -1504.462280\n",
      "    epoch          : 2988\n",
      "    loss           : -1478.900098897643\n",
      "Train Epoch: 2989 [512/60000 (1%)] Loss: -1543.692017\n",
      "Train Epoch: 2989 [11776/60000 (20%)] Loss: -1444.629028\n",
      "Train Epoch: 2989 [23040/60000 (38%)] Loss: -1382.847046\n",
      "Train Epoch: 2989 [34304/60000 (57%)] Loss: -1556.473633\n",
      "Train Epoch: 2989 [45568/60000 (76%)] Loss: -1542.475464\n",
      "Train Epoch: 2989 [56832/60000 (95%)] Loss: -1492.226562\n",
      "    epoch          : 2989\n",
      "    loss           : -1476.290706311242\n",
      "Train Epoch: 2990 [512/60000 (1%)] Loss: -1475.318848\n",
      "Train Epoch: 2990 [11776/60000 (20%)] Loss: -1416.976074\n",
      "Train Epoch: 2990 [23040/60000 (38%)] Loss: -1452.756104\n",
      "Train Epoch: 2990 [34304/60000 (57%)] Loss: -1545.008423\n",
      "Train Epoch: 2990 [45568/60000 (76%)] Loss: -1394.037109\n",
      "Train Epoch: 2990 [56832/60000 (95%)] Loss: -1449.674194\n",
      "    epoch          : 2990\n",
      "    loss           : -1486.3921926035046\n",
      "Train Epoch: 2991 [512/60000 (1%)] Loss: -1463.985596\n",
      "Train Epoch: 2991 [11776/60000 (20%)] Loss: -1493.797119\n",
      "Train Epoch: 2991 [23040/60000 (38%)] Loss: -1433.439819\n",
      "Train Epoch: 2991 [34304/60000 (57%)] Loss: -1516.237915\n",
      "Train Epoch: 2991 [45568/60000 (76%)] Loss: -1521.774170\n",
      "Train Epoch: 2991 [56832/60000 (95%)] Loss: -1372.985718\n",
      "    epoch          : 2991\n",
      "    loss           : -1477.4021082301597\n",
      "Train Epoch: 2992 [512/60000 (1%)] Loss: -1456.841675\n",
      "Train Epoch: 2992 [11776/60000 (20%)] Loss: -1555.651123\n",
      "Train Epoch: 2992 [23040/60000 (38%)] Loss: -1497.922119\n",
      "Train Epoch: 2992 [34304/60000 (57%)] Loss: -1450.748779\n",
      "Train Epoch: 2992 [45568/60000 (76%)] Loss: -1571.128418\n",
      "Train Epoch: 2992 [56832/60000 (95%)] Loss: -1586.872559\n",
      "    epoch          : 2992\n",
      "    loss           : -1486.5923368809588\n",
      "Train Epoch: 2993 [512/60000 (1%)] Loss: -1511.903809\n",
      "Train Epoch: 2993 [11776/60000 (20%)] Loss: -1352.435425\n",
      "Train Epoch: 2993 [23040/60000 (38%)] Loss: -1570.557617\n",
      "Train Epoch: 2993 [34304/60000 (57%)] Loss: -1503.809814\n",
      "Train Epoch: 2993 [45568/60000 (76%)] Loss: -1430.699463\n",
      "Train Epoch: 2993 [56832/60000 (95%)] Loss: -1436.417358\n",
      "    epoch          : 2993\n",
      "    loss           : -1479.6974476959747\n",
      "Train Epoch: 2994 [512/60000 (1%)] Loss: -1456.867554\n",
      "Train Epoch: 2994 [11776/60000 (20%)] Loss: -1409.096191\n",
      "Train Epoch: 2994 [23040/60000 (38%)] Loss: -1480.994873\n",
      "Train Epoch: 2994 [34304/60000 (57%)] Loss: -1498.265869\n",
      "Train Epoch: 2994 [45568/60000 (76%)] Loss: -1527.733398\n",
      "Train Epoch: 2994 [56832/60000 (95%)] Loss: -1536.386841\n",
      "    epoch          : 2994\n",
      "    loss           : -1479.4972947977358\n",
      "Train Epoch: 2995 [512/60000 (1%)] Loss: -1349.864014\n",
      "Train Epoch: 2995 [11776/60000 (20%)] Loss: -1469.214233\n",
      "Train Epoch: 2995 [23040/60000 (38%)] Loss: -1491.204834\n",
      "Train Epoch: 2995 [34304/60000 (57%)] Loss: -1397.654297\n",
      "Train Epoch: 2995 [45568/60000 (76%)] Loss: -1418.005127\n",
      "Train Epoch: 2995 [56832/60000 (95%)] Loss: -1468.597168\n",
      "    epoch          : 2995\n",
      "    loss           : -1489.054513015316\n",
      "Train Epoch: 2996 [512/60000 (1%)] Loss: -1507.427002\n",
      "Train Epoch: 2996 [11776/60000 (20%)] Loss: -1431.185669\n",
      "Train Epoch: 2996 [23040/60000 (38%)] Loss: -1497.680176\n",
      "Train Epoch: 2996 [34304/60000 (57%)] Loss: -1525.379395\n",
      "Train Epoch: 2996 [45568/60000 (76%)] Loss: -1451.834961\n",
      "Train Epoch: 2996 [56832/60000 (95%)] Loss: -1452.162354\n",
      "    epoch          : 2996\n",
      "    loss           : -1475.2440854519775\n",
      "Train Epoch: 2997 [512/60000 (1%)] Loss: -1448.052490\n",
      "Train Epoch: 2997 [11776/60000 (20%)] Loss: -1367.560913\n",
      "Train Epoch: 2997 [23040/60000 (38%)] Loss: -1592.003906\n",
      "Train Epoch: 2997 [34304/60000 (57%)] Loss: -1500.681641\n",
      "Train Epoch: 2997 [45568/60000 (76%)] Loss: -1449.970703\n",
      "Train Epoch: 2997 [56832/60000 (95%)] Loss: -1517.015869\n",
      "    epoch          : 2997\n",
      "    loss           : -1487.8432289597677\n",
      "Train Epoch: 2998 [512/60000 (1%)] Loss: -1388.012817\n",
      "Train Epoch: 2998 [11776/60000 (20%)] Loss: -1368.475952\n",
      "Train Epoch: 2998 [23040/60000 (38%)] Loss: -1477.764648\n",
      "Train Epoch: 2998 [34304/60000 (57%)] Loss: -1498.423706\n",
      "Train Epoch: 2998 [45568/60000 (76%)] Loss: -1439.007812\n",
      "Train Epoch: 2998 [56832/60000 (95%)] Loss: -1519.353882\n",
      "    epoch          : 2998\n",
      "    loss           : -1481.0344703803628\n",
      "Train Epoch: 2999 [512/60000 (1%)] Loss: -1537.496704\n",
      "Train Epoch: 2999 [11776/60000 (20%)] Loss: -1479.410889\n",
      "Train Epoch: 2999 [23040/60000 (38%)] Loss: -1392.910889\n",
      "Train Epoch: 2999 [34304/60000 (57%)] Loss: -1466.625977\n",
      "Train Epoch: 2999 [45568/60000 (76%)] Loss: -1502.202637\n",
      "Train Epoch: 2999 [56832/60000 (95%)] Loss: -1464.092041\n",
      "    epoch          : 2999\n",
      "    loss           : -1478.665484929489\n",
      "Train Epoch: 3000 [512/60000 (1%)] Loss: -1426.447021\n",
      "Train Epoch: 3000 [11776/60000 (20%)] Loss: -1540.789551\n",
      "Train Epoch: 3000 [23040/60000 (38%)] Loss: -1536.140137\n",
      "Train Epoch: 3000 [34304/60000 (57%)] Loss: -1399.455322\n",
      "Train Epoch: 3000 [45568/60000 (76%)] Loss: -1510.096680\n",
      "Train Epoch: 3000 [56832/60000 (95%)] Loss: -1504.240356\n",
      "    epoch          : 3000\n",
      "    loss           : -1478.7926325393935\n",
      "Saving checkpoint: saved/models/Mnist_DeepGenerativeOperad/0127_111843/checkpoint-epoch3000.pth ...\n",
      "Train Epoch: 3001 [512/60000 (1%)] Loss: -1466.191162\n",
      "Train Epoch: 3001 [11776/60000 (20%)] Loss: -1575.329346\n",
      "Train Epoch: 3001 [23040/60000 (38%)] Loss: -1547.253662\n",
      "Train Epoch: 3001 [34304/60000 (57%)] Loss: -1493.964355\n",
      "Train Epoch: 3001 [45568/60000 (76%)] Loss: -1455.313965\n",
      "Train Epoch: 3001 [56832/60000 (95%)] Loss: -1455.069702\n",
      "    epoch          : 3001\n",
      "    loss           : -1482.1389139466366\n",
      "Train Epoch: 3002 [512/60000 (1%)] Loss: -1576.025391\n",
      "Train Epoch: 3002 [11776/60000 (20%)] Loss: -1492.970215\n",
      "Train Epoch: 3002 [23040/60000 (38%)] Loss: -1556.089844\n",
      "Train Epoch: 3002 [34304/60000 (57%)] Loss: -1590.858398\n",
      "Train Epoch: 3002 [45568/60000 (76%)] Loss: -1479.567139\n",
      "Train Epoch: 3002 [56832/60000 (95%)] Loss: -1347.610962\n",
      "    epoch          : 3002\n",
      "    loss           : -1477.5433632371114\n",
      "Train Epoch: 3003 [512/60000 (1%)] Loss: -1457.462769\n",
      "Train Epoch: 3003 [11776/60000 (20%)] Loss: -1513.564697\n",
      "Train Epoch: 3003 [23040/60000 (38%)] Loss: -1537.326172\n",
      "Train Epoch: 3003 [34304/60000 (57%)] Loss: -1567.383301\n",
      "Train Epoch: 3003 [45568/60000 (76%)] Loss: -1473.697266\n",
      "Train Epoch: 3003 [56832/60000 (95%)] Loss: -1497.323975\n",
      "    epoch          : 3003\n",
      "    loss           : -1486.6805368197167\n",
      "Train Epoch: 3004 [512/60000 (1%)] Loss: -1462.438599\n",
      "Train Epoch: 3004 [11776/60000 (20%)] Loss: -1504.723755\n",
      "Train Epoch: 3004 [23040/60000 (38%)] Loss: -1431.605225\n",
      "Train Epoch: 3004 [34304/60000 (57%)] Loss: -1567.273438\n",
      "Train Epoch: 3004 [45568/60000 (76%)] Loss: -1554.163696\n",
      "Train Epoch: 3004 [56832/60000 (95%)] Loss: -1533.026733\n",
      "    epoch          : 3004\n",
      "    loss           : -1479.0292482537739\n",
      "Train Epoch: 3005 [512/60000 (1%)] Loss: -1459.184448\n",
      "Train Epoch: 3005 [11776/60000 (20%)] Loss: -1479.432861\n",
      "Train Epoch: 3005 [23040/60000 (38%)] Loss: -1522.241577\n",
      "Train Epoch: 3005 [34304/60000 (57%)] Loss: -1466.949219\n",
      "Train Epoch: 3005 [45568/60000 (76%)] Loss: -1520.635132\n",
      "Train Epoch: 3005 [56832/60000 (95%)] Loss: -1555.752319\n",
      "    epoch          : 3005\n",
      "    loss           : -1470.057660291424\n",
      "Train Epoch: 3006 [512/60000 (1%)] Loss: -1578.778687\n",
      "Train Epoch: 3006 [11776/60000 (20%)] Loss: -1457.204346\n",
      "Train Epoch: 3006 [23040/60000 (38%)] Loss: -1490.984497\n",
      "Train Epoch: 3006 [34304/60000 (57%)] Loss: -1508.193481\n",
      "Train Epoch: 3006 [45568/60000 (76%)] Loss: -1545.330322\n",
      "Train Epoch: 3006 [56832/60000 (95%)] Loss: -1590.316650\n",
      "    epoch          : 3006\n",
      "    loss           : -1496.7426692294537\n",
      "Train Epoch: 3007 [512/60000 (1%)] Loss: -1535.475342\n",
      "Train Epoch: 3007 [11776/60000 (20%)] Loss: -1452.024292\n",
      "Train Epoch: 3007 [23040/60000 (38%)] Loss: -1204.052490\n",
      "Train Epoch: 3007 [34304/60000 (57%)] Loss: -1428.098267\n",
      "Train Epoch: 3007 [45568/60000 (76%)] Loss: -1533.551147\n",
      "Train Epoch: 3007 [56832/60000 (95%)] Loss: -1483.068604\n",
      "    epoch          : 3007\n",
      "    loss           : -1467.7046401891332\n",
      "Train Epoch: 3008 [512/60000 (1%)] Loss: -1413.443604\n",
      "Train Epoch: 3008 [11776/60000 (20%)] Loss: -1567.796997\n",
      "Train Epoch: 3008 [23040/60000 (38%)] Loss: -1518.963745\n",
      "Train Epoch: 3008 [34304/60000 (57%)] Loss: -1498.059204\n",
      "Train Epoch: 3008 [45568/60000 (76%)] Loss: -1497.520874\n",
      "Train Epoch: 3008 [56832/60000 (95%)] Loss: -1505.993408\n",
      "    epoch          : 3008\n",
      "    loss           : -1469.0307837879589\n",
      "Train Epoch: 3009 [512/60000 (1%)] Loss: -1472.308228\n",
      "Train Epoch: 3009 [11776/60000 (20%)] Loss: -1567.877563\n",
      "Train Epoch: 3009 [23040/60000 (38%)] Loss: -1548.255371\n",
      "Train Epoch: 3009 [34304/60000 (57%)] Loss: -1545.310669\n",
      "Train Epoch: 3009 [45568/60000 (76%)] Loss: -1547.730225\n",
      "Train Epoch: 3009 [56832/60000 (95%)] Loss: -1322.569580\n",
      "    epoch          : 3009\n",
      "    loss           : -1471.044011520127\n",
      "Train Epoch: 3010 [512/60000 (1%)] Loss: -1584.414917\n",
      "Train Epoch: 3010 [11776/60000 (20%)] Loss: -1417.582764\n",
      "Train Epoch: 3010 [23040/60000 (38%)] Loss: -1349.605835\n",
      "Train Epoch: 3010 [34304/60000 (57%)] Loss: -1517.795410\n",
      "Train Epoch: 3010 [45568/60000 (76%)] Loss: -1395.966553\n",
      "Train Epoch: 3010 [56832/60000 (95%)] Loss: -1418.630859\n",
      "    epoch          : 3010\n",
      "    loss           : -1477.4815294513594\n",
      "Train Epoch: 3011 [512/60000 (1%)] Loss: -1428.931641\n",
      "Train Epoch: 3011 [11776/60000 (20%)] Loss: -1273.008179\n",
      "Train Epoch: 3011 [23040/60000 (38%)] Loss: -1451.000977\n",
      "Train Epoch: 3011 [34304/60000 (57%)] Loss: -1536.057495\n",
      "Train Epoch: 3011 [45568/60000 (76%)] Loss: -1492.607666\n",
      "Train Epoch: 3011 [56832/60000 (95%)] Loss: -1522.669678\n",
      "    epoch          : 3011\n",
      "    loss           : -1469.3251973814884\n",
      "Train Epoch: 3012 [512/60000 (1%)] Loss: -1272.637207\n",
      "Train Epoch: 3012 [11776/60000 (20%)] Loss: -1533.250000\n",
      "Train Epoch: 3012 [23040/60000 (38%)] Loss: -1472.471558\n",
      "Train Epoch: 3012 [34304/60000 (57%)] Loss: -1544.764404\n",
      "Train Epoch: 3012 [45568/60000 (76%)] Loss: -1407.458252\n",
      "Train Epoch: 3012 [56832/60000 (95%)] Loss: -1454.968506\n",
      "    epoch          : 3012\n",
      "    loss           : -1473.3134569071108\n",
      "Train Epoch: 3013 [512/60000 (1%)] Loss: -1582.453247\n",
      "Train Epoch: 3013 [11776/60000 (20%)] Loss: -1400.906860\n",
      "Train Epoch: 3013 [23040/60000 (38%)] Loss: -1516.625610\n",
      "Train Epoch: 3013 [34304/60000 (57%)] Loss: -1459.556396\n",
      "Train Epoch: 3013 [45568/60000 (76%)] Loss: -1418.554688\n",
      "Train Epoch: 3013 [56832/60000 (95%)] Loss: -1516.807617\n",
      "    epoch          : 3013\n",
      "    loss           : -1482.729457014698\n",
      "Train Epoch: 3014 [512/60000 (1%)] Loss: -1499.670166\n",
      "Train Epoch: 3014 [11776/60000 (20%)] Loss: -1550.319458\n",
      "Train Epoch: 3014 [23040/60000 (38%)] Loss: -1446.765991\n",
      "Train Epoch: 3014 [34304/60000 (57%)] Loss: -1482.467529\n",
      "Train Epoch: 3014 [45568/60000 (76%)] Loss: -1524.441528\n",
      "Train Epoch: 3014 [56832/60000 (95%)] Loss: -1494.718384\n",
      "    epoch          : 3014\n",
      "    loss           : -1484.6719201729122\n",
      "Train Epoch: 3015 [512/60000 (1%)] Loss: -1466.794556\n",
      "Train Epoch: 3015 [11776/60000 (20%)] Loss: -1328.410156\n",
      "Train Epoch: 3015 [23040/60000 (38%)] Loss: -1453.521973\n",
      "Train Epoch: 3015 [34304/60000 (57%)] Loss: -1527.130615\n",
      "Train Epoch: 3015 [45568/60000 (76%)] Loss: -1487.501221\n",
      "Train Epoch: 3015 [56832/60000 (95%)] Loss: -1511.724854\n",
      "    epoch          : 3015\n",
      "    loss           : -1487.1813871739275\n",
      "Train Epoch: 3016 [512/60000 (1%)] Loss: -1498.086182\n",
      "Train Epoch: 3016 [11776/60000 (20%)] Loss: -1579.048340\n",
      "Train Epoch: 3016 [23040/60000 (38%)] Loss: -1569.930298\n",
      "Train Epoch: 3016 [34304/60000 (57%)] Loss: -1440.231812\n",
      "Train Epoch: 3016 [45568/60000 (76%)] Loss: -1553.115356\n",
      "Train Epoch: 3016 [56832/60000 (95%)] Loss: -1403.595581\n",
      "    epoch          : 3016\n",
      "    loss           : -1473.160691428319\n",
      "Train Epoch: 3017 [512/60000 (1%)] Loss: -1384.926514\n",
      "Train Epoch: 3017 [11776/60000 (20%)] Loss: -1317.929810\n",
      "Train Epoch: 3017 [23040/60000 (38%)] Loss: -1430.397217\n",
      "Train Epoch: 3017 [34304/60000 (57%)] Loss: -1426.516357\n",
      "Train Epoch: 3017 [45568/60000 (76%)] Loss: -1495.122803\n",
      "Train Epoch: 3017 [56832/60000 (95%)] Loss: -1449.118896\n",
      "    epoch          : 3017\n",
      "    loss           : -1481.8249922068107\n",
      "Train Epoch: 3018 [512/60000 (1%)] Loss: -1460.443604\n",
      "Train Epoch: 3018 [11776/60000 (20%)] Loss: -1378.695801\n",
      "Train Epoch: 3018 [23040/60000 (38%)] Loss: -1365.551758\n",
      "Train Epoch: 3018 [34304/60000 (57%)] Loss: -1456.431030\n",
      "Train Epoch: 3018 [45568/60000 (76%)] Loss: -1396.901733\n",
      "Train Epoch: 3018 [56832/60000 (95%)] Loss: -1285.626587\n",
      "    epoch          : 3018\n",
      "    loss           : -1480.4842512055304\n",
      "Train Epoch: 3019 [512/60000 (1%)] Loss: -1438.493286\n",
      "Train Epoch: 3019 [11776/60000 (20%)] Loss: -1449.130859\n",
      "Train Epoch: 3019 [23040/60000 (38%)] Loss: -1562.669312\n",
      "Train Epoch: 3019 [34304/60000 (57%)] Loss: -1430.028809\n",
      "Train Epoch: 3019 [45568/60000 (76%)] Loss: -1259.027100\n",
      "Train Epoch: 3019 [56832/60000 (95%)] Loss: -1590.007446\n",
      "    epoch          : 3019\n",
      "    loss           : -1476.3662430068193\n",
      "Train Epoch: 3020 [512/60000 (1%)] Loss: -1551.438965\n",
      "Train Epoch: 3020 [11776/60000 (20%)] Loss: -1524.138916\n",
      "Train Epoch: 3020 [23040/60000 (38%)] Loss: -1535.104980\n",
      "Train Epoch: 3020 [34304/60000 (57%)] Loss: -1493.566162\n",
      "Train Epoch: 3020 [45568/60000 (76%)] Loss: -1418.735718\n",
      "Train Epoch: 3020 [56832/60000 (95%)] Loss: -1457.410034\n",
      "    epoch          : 3020\n",
      "    loss           : -1487.2846610721222\n",
      "Train Epoch: 3021 [512/60000 (1%)] Loss: -1467.398193\n",
      "Train Epoch: 3021 [11776/60000 (20%)] Loss: -1447.320557\n",
      "Train Epoch: 3021 [23040/60000 (38%)] Loss: -1566.134644\n",
      "Train Epoch: 3021 [34304/60000 (57%)] Loss: -1442.984375\n",
      "Train Epoch: 3021 [45568/60000 (76%)] Loss: -1462.523071\n",
      "Train Epoch: 3021 [56832/60000 (95%)] Loss: -1445.968750\n",
      "    epoch          : 3021\n",
      "    loss           : -1480.6804813018625\n",
      "Train Epoch: 3022 [512/60000 (1%)] Loss: -1489.914062\n",
      "Train Epoch: 3022 [11776/60000 (20%)] Loss: -1538.882202\n",
      "Train Epoch: 3022 [23040/60000 (38%)] Loss: -1593.273315\n",
      "Train Epoch: 3022 [34304/60000 (57%)] Loss: -1587.343872\n",
      "Train Epoch: 3022 [45568/60000 (76%)] Loss: -1460.497681\n",
      "Train Epoch: 3022 [56832/60000 (95%)] Loss: -1485.724854\n",
      "    epoch          : 3022\n",
      "    loss           : -1486.151523051289\n",
      "Train Epoch: 3023 [512/60000 (1%)] Loss: -1516.120850\n",
      "Train Epoch: 3023 [11776/60000 (20%)] Loss: -1579.948120\n",
      "Train Epoch: 3023 [23040/60000 (38%)] Loss: -1511.190918\n",
      "Train Epoch: 3023 [34304/60000 (57%)] Loss: -1496.929932\n",
      "Train Epoch: 3023 [45568/60000 (76%)] Loss: -1548.435425\n",
      "Train Epoch: 3023 [56832/60000 (95%)] Loss: -1519.421143\n",
      "    epoch          : 3023\n",
      "    loss           : -1494.9281716212042\n",
      "Train Epoch: 3024 [512/60000 (1%)] Loss: -1540.837402\n",
      "Train Epoch: 3024 [11776/60000 (20%)] Loss: -1427.909180\n",
      "Train Epoch: 3024 [23040/60000 (38%)] Loss: -1377.359009\n",
      "Train Epoch: 3024 [34304/60000 (57%)] Loss: -1540.521484\n",
      "Train Epoch: 3024 [45568/60000 (76%)] Loss: -1579.389038\n",
      "Train Epoch: 3024 [56832/60000 (95%)] Loss: -1483.519653\n",
      "    epoch          : 3024\n",
      "    loss           : -1480.6205444335938\n",
      "Train Epoch: 3025 [512/60000 (1%)] Loss: -1532.822998\n",
      "Train Epoch: 3025 [11776/60000 (20%)] Loss: -1408.928223\n",
      "Train Epoch: 3025 [23040/60000 (38%)] Loss: -1482.176270\n",
      "Train Epoch: 3025 [34304/60000 (57%)] Loss: -1547.146240\n",
      "Train Epoch: 3025 [45568/60000 (76%)] Loss: -1415.964600\n",
      "Train Epoch: 3025 [56832/60000 (95%)] Loss: -1440.191650\n",
      "    epoch          : 3025\n",
      "    loss           : -1472.6088767186395\n",
      "Train Epoch: 3026 [512/60000 (1%)] Loss: -1527.888062\n",
      "Train Epoch: 3026 [11776/60000 (20%)] Loss: -1493.198486\n",
      "Train Epoch: 3026 [23040/60000 (38%)] Loss: -1504.598999\n",
      "Train Epoch: 3026 [34304/60000 (57%)] Loss: -1535.812866\n",
      "Train Epoch: 3026 [45568/60000 (76%)] Loss: -1575.207275\n",
      "Train Epoch: 3026 [56832/60000 (95%)] Loss: -1466.784912\n",
      "    epoch          : 3026\n",
      "    loss           : -1477.5504512463585\n",
      "Train Epoch: 3027 [512/60000 (1%)] Loss: -1342.015625\n",
      "Train Epoch: 3027 [11776/60000 (20%)] Loss: -1461.496216\n",
      "Train Epoch: 3027 [23040/60000 (38%)] Loss: -1480.216553\n",
      "Train Epoch: 3027 [34304/60000 (57%)] Loss: -1405.115723\n",
      "Train Epoch: 3027 [45568/60000 (76%)] Loss: -1575.667969\n",
      "Train Epoch: 3027 [56832/60000 (95%)] Loss: -1524.075195\n",
      "    epoch          : 3027\n",
      "    loss           : -1477.6729160459702\n",
      "Train Epoch: 3028 [512/60000 (1%)] Loss: -1513.020508\n",
      "Train Epoch: 3028 [11776/60000 (20%)] Loss: -1523.220825\n",
      "Train Epoch: 3028 [23040/60000 (38%)] Loss: -1392.400269\n",
      "Train Epoch: 3028 [34304/60000 (57%)] Loss: -1501.429810\n",
      "Train Epoch: 3028 [45568/60000 (76%)] Loss: -1562.875488\n",
      "Train Epoch: 3028 [56832/60000 (95%)] Loss: -1437.415161\n",
      "    epoch          : 3028\n",
      "    loss           : -1481.7341394801597\n",
      "Train Epoch: 3029 [512/60000 (1%)] Loss: -1567.202881\n",
      "Train Epoch: 3029 [11776/60000 (20%)] Loss: -1532.356201\n",
      "Train Epoch: 3029 [23040/60000 (38%)] Loss: -1447.263916\n",
      "Train Epoch: 3029 [34304/60000 (57%)] Loss: -1369.345947\n",
      "Train Epoch: 3029 [45568/60000 (76%)] Loss: -1483.699707\n",
      "Train Epoch: 3029 [56832/60000 (95%)] Loss: -1453.451660\n",
      "    epoch          : 3029\n",
      "    loss           : -1487.591278593419\n",
      "Train Epoch: 3030 [512/60000 (1%)] Loss: -1573.987793\n",
      "Train Epoch: 3030 [11776/60000 (20%)] Loss: -1520.271973\n",
      "Train Epoch: 3030 [23040/60000 (38%)] Loss: -1321.929199\n",
      "Train Epoch: 3030 [34304/60000 (57%)] Loss: -1301.578735\n",
      "Train Epoch: 3030 [45568/60000 (76%)] Loss: -1564.123779\n",
      "Train Epoch: 3030 [56832/60000 (95%)] Loss: -1330.346558\n",
      "    epoch          : 3030\n",
      "    loss           : -1473.5193498686883\n",
      "Train Epoch: 3031 [512/60000 (1%)] Loss: -1506.309937\n",
      "Train Epoch: 3031 [11776/60000 (20%)] Loss: -1482.433594\n",
      "Train Epoch: 3031 [23040/60000 (38%)] Loss: -1299.823486\n",
      "Train Epoch: 3031 [34304/60000 (57%)] Loss: -1464.042358\n",
      "Train Epoch: 3031 [45568/60000 (76%)] Loss: -1570.462036\n",
      "Train Epoch: 3031 [56832/60000 (95%)] Loss: -1581.027344\n",
      "    epoch          : 3031\n",
      "    loss           : -1479.2970639676025\n",
      "Train Epoch: 3032 [512/60000 (1%)] Loss: -1408.454346\n",
      "Train Epoch: 3032 [11776/60000 (20%)] Loss: -1398.981201\n",
      "Train Epoch: 3032 [23040/60000 (38%)] Loss: -1571.553833\n",
      "Train Epoch: 3032 [34304/60000 (57%)] Loss: -1397.620605\n",
      "Train Epoch: 3032 [45568/60000 (76%)] Loss: -1454.966919\n",
      "Train Epoch: 3032 [56832/60000 (95%)] Loss: -1538.368164\n",
      "    epoch          : 3032\n",
      "    loss           : -1489.193735586048\n",
      "Train Epoch: 3033 [512/60000 (1%)] Loss: -1493.326172\n",
      "Train Epoch: 3033 [11776/60000 (20%)] Loss: -1404.323364\n",
      "Train Epoch: 3033 [23040/60000 (38%)] Loss: -1467.572144\n",
      "Train Epoch: 3033 [34304/60000 (57%)] Loss: -1489.288330\n",
      "Train Epoch: 3033 [45568/60000 (76%)] Loss: -1486.859497\n",
      "Train Epoch: 3033 [56832/60000 (95%)] Loss: -1481.203735\n",
      "    epoch          : 3033\n",
      "    loss           : -1483.511742543366\n",
      "Train Epoch: 3034 [512/60000 (1%)] Loss: -1558.575195\n",
      "Train Epoch: 3034 [11776/60000 (20%)] Loss: -1448.342529\n",
      "Train Epoch: 3034 [23040/60000 (38%)] Loss: -1523.023071\n",
      "Train Epoch: 3034 [34304/60000 (57%)] Loss: -1512.013916\n",
      "Train Epoch: 3034 [45568/60000 (76%)] Loss: -1453.009521\n",
      "Train Epoch: 3034 [56832/60000 (95%)] Loss: -1396.343018\n",
      "    epoch          : 3034\n",
      "    loss           : -1486.0315375893804\n",
      "Train Epoch: 3035 [512/60000 (1%)] Loss: -1586.641846\n",
      "Train Epoch: 3035 [11776/60000 (20%)] Loss: -1575.820557\n",
      "Train Epoch: 3035 [23040/60000 (38%)] Loss: -1446.384644\n",
      "Train Epoch: 3035 [34304/60000 (57%)] Loss: -1577.306641\n",
      "Train Epoch: 3035 [45568/60000 (76%)] Loss: -1486.065674\n",
      "Train Epoch: 3035 [56832/60000 (95%)] Loss: -1434.337646\n",
      "    epoch          : 3035\n",
      "    loss           : -1481.0524464407883\n",
      "Train Epoch: 3036 [512/60000 (1%)] Loss: -1430.048584\n",
      "Train Epoch: 3036 [11776/60000 (20%)] Loss: -1460.103760\n",
      "Train Epoch: 3036 [23040/60000 (38%)] Loss: -1554.681396\n",
      "Train Epoch: 3036 [34304/60000 (57%)] Loss: -1550.725342\n",
      "Train Epoch: 3036 [45568/60000 (76%)] Loss: -1528.895508\n",
      "Train Epoch: 3036 [56832/60000 (95%)] Loss: -1423.323120\n",
      "    epoch          : 3036\n",
      "    loss           : -1477.1217606539108\n",
      "Train Epoch: 3037 [512/60000 (1%)] Loss: -1563.491455\n",
      "Train Epoch: 3037 [11776/60000 (20%)] Loss: -1466.067017\n",
      "Train Epoch: 3037 [23040/60000 (38%)] Loss: -1562.062988\n",
      "Train Epoch: 3037 [34304/60000 (57%)] Loss: -1546.965820\n",
      "Train Epoch: 3037 [45568/60000 (76%)] Loss: -1273.917480\n",
      "Train Epoch: 3037 [56832/60000 (95%)] Loss: -1434.844604\n",
      "    epoch          : 3037\n",
      "    loss           : -1483.129370048221\n",
      "Train Epoch: 3038 [512/60000 (1%)] Loss: -1553.035767\n",
      "Train Epoch: 3038 [11776/60000 (20%)] Loss: -1469.684204\n",
      "Train Epoch: 3038 [23040/60000 (38%)] Loss: -1442.395264\n",
      "Train Epoch: 3038 [34304/60000 (57%)] Loss: -1453.993774\n",
      "Train Epoch: 3038 [45568/60000 (76%)] Loss: -1457.619141\n",
      "Train Epoch: 3038 [56832/60000 (95%)] Loss: -1519.231567\n",
      "    epoch          : 3038\n",
      "    loss           : -1487.4293099096267\n",
      "Train Epoch: 3039 [512/60000 (1%)] Loss: -1475.166016\n",
      "Train Epoch: 3039 [11776/60000 (20%)] Loss: -1615.736816\n",
      "Train Epoch: 3039 [23040/60000 (38%)] Loss: -1485.226807\n",
      "Train Epoch: 3039 [34304/60000 (57%)] Loss: -1502.679688\n",
      "Train Epoch: 3039 [45568/60000 (76%)] Loss: -1503.105713\n",
      "Train Epoch: 3039 [56832/60000 (95%)] Loss: -1488.086182\n",
      "    epoch          : 3039\n",
      "    loss           : -1496.3137748416534\n",
      "Train Epoch: 3040 [512/60000 (1%)] Loss: -1511.070557\n",
      "Train Epoch: 3040 [11776/60000 (20%)] Loss: -1515.272339\n",
      "Train Epoch: 3040 [23040/60000 (38%)] Loss: -1532.029297\n",
      "Train Epoch: 3040 [34304/60000 (57%)] Loss: -1441.309570\n",
      "Train Epoch: 3040 [45568/60000 (76%)] Loss: -1398.583130\n",
      "Train Epoch: 3040 [56832/60000 (95%)] Loss: -1551.497070\n",
      "    epoch          : 3040\n",
      "    loss           : -1486.226769743666\n",
      "Train Epoch: 3041 [512/60000 (1%)] Loss: -1481.704224\n",
      "Train Epoch: 3041 [11776/60000 (20%)] Loss: -1372.935303\n",
      "Train Epoch: 3041 [23040/60000 (38%)] Loss: -1354.522827\n",
      "Train Epoch: 3041 [34304/60000 (57%)] Loss: -1503.103638\n",
      "Train Epoch: 3041 [45568/60000 (76%)] Loss: -1474.946533\n",
      "Train Epoch: 3041 [56832/60000 (95%)] Loss: -1422.657471\n",
      "    epoch          : 3041\n",
      "    loss           : -1494.0874478614937\n",
      "Train Epoch: 3042 [512/60000 (1%)] Loss: -1505.514282\n",
      "Train Epoch: 3042 [11776/60000 (20%)] Loss: -1536.812378\n",
      "Train Epoch: 3042 [23040/60000 (38%)] Loss: -1412.679810\n",
      "Train Epoch: 3042 [34304/60000 (57%)] Loss: -1433.287842\n",
      "Train Epoch: 3042 [45568/60000 (76%)] Loss: -1459.020752\n",
      "Train Epoch: 3042 [56832/60000 (95%)] Loss: -1498.886230\n",
      "    epoch          : 3042\n",
      "    loss           : -1484.569668354961\n",
      "Train Epoch: 3043 [512/60000 (1%)] Loss: -1450.297607\n",
      "Train Epoch: 3043 [11776/60000 (20%)] Loss: -1494.818848\n",
      "Train Epoch: 3043 [23040/60000 (38%)] Loss: -1565.989746\n",
      "Train Epoch: 3043 [34304/60000 (57%)] Loss: -1517.026367\n",
      "Train Epoch: 3043 [45568/60000 (76%)] Loss: -1441.327637\n",
      "Train Epoch: 3043 [56832/60000 (95%)] Loss: -1491.274658\n",
      "    epoch          : 3043\n",
      "    loss           : -1487.0822026312014\n",
      "Train Epoch: 3044 [512/60000 (1%)] Loss: -1516.068115\n",
      "Train Epoch: 3044 [11776/60000 (20%)] Loss: -1511.923584\n",
      "Train Epoch: 3044 [23040/60000 (38%)] Loss: -1445.572266\n",
      "Train Epoch: 3044 [34304/60000 (57%)] Loss: -1476.020142\n",
      "Train Epoch: 3044 [45568/60000 (76%)] Loss: -1552.020996\n",
      "Train Epoch: 3044 [56832/60000 (95%)] Loss: -1589.227783\n",
      "    epoch          : 3044\n",
      "    loss           : -1485.0302827479475\n",
      "Train Epoch: 3045 [512/60000 (1%)] Loss: -1562.614868\n",
      "Train Epoch: 3045 [11776/60000 (20%)] Loss: -1418.277222\n",
      "Train Epoch: 3045 [23040/60000 (38%)] Loss: -1515.267212\n",
      "Train Epoch: 3045 [34304/60000 (57%)] Loss: -1468.023926\n",
      "Train Epoch: 3045 [45568/60000 (76%)] Loss: -1400.634399\n",
      "Train Epoch: 3045 [56832/60000 (95%)] Loss: -1551.902832\n",
      "    epoch          : 3045\n",
      "    loss           : -1482.413577667064\n",
      "Train Epoch: 3046 [512/60000 (1%)] Loss: -1549.805298\n",
      "Train Epoch: 3046 [11776/60000 (20%)] Loss: -1451.646118\n",
      "Train Epoch: 3046 [23040/60000 (38%)] Loss: -1548.116821\n",
      "Train Epoch: 3046 [34304/60000 (57%)] Loss: -1544.689697\n",
      "Train Epoch: 3046 [45568/60000 (76%)] Loss: -1446.791870\n",
      "Train Epoch: 3046 [56832/60000 (95%)] Loss: -1552.411377\n",
      "    epoch          : 3046\n",
      "    loss           : -1490.3906522416798\n",
      "Train Epoch: 3047 [512/60000 (1%)] Loss: -1524.163330\n",
      "Train Epoch: 3047 [11776/60000 (20%)] Loss: -1568.097778\n",
      "Train Epoch: 3047 [23040/60000 (38%)] Loss: -1490.700928\n",
      "Train Epoch: 3047 [34304/60000 (57%)] Loss: -1519.073975\n",
      "Train Epoch: 3047 [45568/60000 (76%)] Loss: -1530.715942\n",
      "Train Epoch: 3047 [56832/60000 (95%)] Loss: -1451.242432\n",
      "    epoch          : 3047\n",
      "    loss           : -1493.8966354111494\n",
      "Train Epoch: 3048 [512/60000 (1%)] Loss: -1429.077881\n",
      "Train Epoch: 3048 [11776/60000 (20%)] Loss: -1564.762695\n",
      "Train Epoch: 3048 [23040/60000 (38%)] Loss: -1553.331665\n",
      "Train Epoch: 3048 [34304/60000 (57%)] Loss: -1526.263428\n",
      "Train Epoch: 3048 [45568/60000 (76%)] Loss: -1463.899414\n",
      "Train Epoch: 3048 [56832/60000 (95%)] Loss: -1385.871338\n",
      "    epoch          : 3048\n",
      "    loss           : -1488.9191329007767\n",
      "Train Epoch: 3049 [512/60000 (1%)] Loss: -1396.251709\n",
      "Train Epoch: 3049 [11776/60000 (20%)] Loss: -1362.268066\n",
      "Train Epoch: 3049 [23040/60000 (38%)] Loss: -1545.116455\n",
      "Train Epoch: 3049 [34304/60000 (57%)] Loss: -1530.177246\n",
      "Train Epoch: 3049 [45568/60000 (76%)] Loss: -1413.605225\n",
      "Train Epoch: 3049 [56832/60000 (95%)] Loss: -1529.163574\n",
      "    epoch          : 3049\n",
      "    loss           : -1481.3758379402807\n",
      "Train Epoch: 3050 [512/60000 (1%)] Loss: -1475.972290\n",
      "Train Epoch: 3050 [11776/60000 (20%)] Loss: -1442.152466\n",
      "Train Epoch: 3050 [23040/60000 (38%)] Loss: -1489.662109\n",
      "Train Epoch: 3050 [34304/60000 (57%)] Loss: -1450.393799\n",
      "Train Epoch: 3050 [45568/60000 (76%)] Loss: -1552.060791\n",
      "Train Epoch: 3050 [56832/60000 (95%)] Loss: -1389.570190\n",
      "    epoch          : 3050\n",
      "    loss           : -1493.403565487619\n",
      "Train Epoch: 3051 [512/60000 (1%)] Loss: -1469.821167\n",
      "Train Epoch: 3051 [11776/60000 (20%)] Loss: -1457.896729\n",
      "Train Epoch: 3051 [23040/60000 (38%)] Loss: -1518.203857\n",
      "Train Epoch: 3051 [34304/60000 (57%)] Loss: -1385.410034\n",
      "Train Epoch: 3051 [45568/60000 (76%)] Loss: -1547.290283\n",
      "Train Epoch: 3051 [56832/60000 (95%)] Loss: -1462.629761\n",
      "    epoch          : 3051\n",
      "    loss           : -1492.445134567002\n",
      "Train Epoch: 3052 [512/60000 (1%)] Loss: -1584.269531\n",
      "Train Epoch: 3052 [11776/60000 (20%)] Loss: -1504.649902\n",
      "Train Epoch: 3052 [23040/60000 (38%)] Loss: -1472.507568\n",
      "Train Epoch: 3052 [34304/60000 (57%)] Loss: -1537.999146\n",
      "Train Epoch: 3052 [45568/60000 (76%)] Loss: -1511.571289\n",
      "Train Epoch: 3052 [56832/60000 (95%)] Loss: -1549.997437\n",
      "    epoch          : 3052\n",
      "    loss           : -1487.8034899005781\n",
      "Train Epoch: 3053 [512/60000 (1%)] Loss: -1579.948486\n",
      "Train Epoch: 3053 [11776/60000 (20%)] Loss: -1351.166138\n",
      "Train Epoch: 3053 [23040/60000 (38%)] Loss: -1565.762695\n",
      "Train Epoch: 3053 [34304/60000 (57%)] Loss: -1429.406738\n",
      "Train Epoch: 3053 [45568/60000 (76%)] Loss: -1461.431152\n",
      "Train Epoch: 3053 [56832/60000 (95%)] Loss: -1455.185303\n",
      "    epoch          : 3053\n",
      "    loss           : -1490.9888860842602\n",
      "Train Epoch: 3054 [512/60000 (1%)] Loss: -1570.043701\n",
      "Train Epoch: 3054 [11776/60000 (20%)] Loss: -1402.158813\n",
      "Train Epoch: 3054 [23040/60000 (38%)] Loss: -1428.914429\n",
      "Train Epoch: 3054 [34304/60000 (57%)] Loss: -1566.167725\n",
      "Train Epoch: 3054 [45568/60000 (76%)] Loss: -1459.620972\n",
      "Train Epoch: 3054 [56832/60000 (95%)] Loss: -1442.044678\n",
      "    epoch          : 3054\n",
      "    loss           : -1485.7916063211733\n",
      "Train Epoch: 3055 [512/60000 (1%)] Loss: -1348.901611\n",
      "Train Epoch: 3055 [11776/60000 (20%)] Loss: -1358.343506\n",
      "Train Epoch: 3055 [23040/60000 (38%)] Loss: -1576.825195\n",
      "Train Epoch: 3055 [34304/60000 (57%)] Loss: -1458.575073\n",
      "Train Epoch: 3055 [45568/60000 (76%)] Loss: -1391.918457\n",
      "Train Epoch: 3055 [56832/60000 (95%)] Loss: -1384.545532\n",
      "    epoch          : 3055\n",
      "    loss           : -1482.2958363678497\n",
      "Train Epoch: 3056 [512/60000 (1%)] Loss: -1523.909424\n",
      "Train Epoch: 3056 [11776/60000 (20%)] Loss: -1438.854248\n",
      "Train Epoch: 3056 [23040/60000 (38%)] Loss: -1539.630737\n",
      "Train Epoch: 3056 [34304/60000 (57%)] Loss: -1520.984131\n",
      "Train Epoch: 3056 [45568/60000 (76%)] Loss: -1434.790527\n",
      "Train Epoch: 3056 [56832/60000 (95%)] Loss: -1449.586792\n",
      "    epoch          : 3056\n",
      "    loss           : -1495.191431767523\n",
      "Train Epoch: 3057 [512/60000 (1%)] Loss: -1571.637939\n",
      "Train Epoch: 3057 [11776/60000 (20%)] Loss: -1505.225342\n",
      "Train Epoch: 3057 [23040/60000 (38%)] Loss: -1560.376099\n",
      "Train Epoch: 3057 [34304/60000 (57%)] Loss: -1465.511719\n",
      "Train Epoch: 3057 [45568/60000 (76%)] Loss: -1431.900635\n",
      "Train Epoch: 3057 [56832/60000 (95%)] Loss: -1457.125977\n",
      "    epoch          : 3057\n",
      "    loss           : -1488.9907554152323\n",
      "Train Epoch: 3058 [512/60000 (1%)] Loss: -1424.700928\n",
      "Train Epoch: 3058 [11776/60000 (20%)] Loss: -1353.593994\n",
      "Train Epoch: 3058 [23040/60000 (38%)] Loss: -1447.625977\n",
      "Train Epoch: 3058 [34304/60000 (57%)] Loss: -1575.075439\n",
      "Train Epoch: 3058 [45568/60000 (76%)] Loss: -1554.026855\n",
      "Train Epoch: 3058 [56832/60000 (95%)] Loss: -1550.061279\n",
      "    epoch          : 3058\n",
      "    loss           : -1486.4729883226298\n",
      "Train Epoch: 3059 [512/60000 (1%)] Loss: -1494.819702\n",
      "Train Epoch: 3059 [11776/60000 (20%)] Loss: -1478.168701\n",
      "Train Epoch: 3059 [23040/60000 (38%)] Loss: -1593.814087\n",
      "Train Epoch: 3059 [34304/60000 (57%)] Loss: -1554.085449\n",
      "Train Epoch: 3059 [45568/60000 (76%)] Loss: -1383.353516\n",
      "Train Epoch: 3059 [56832/60000 (95%)] Loss: -1391.213745\n",
      "    epoch          : 3059\n",
      "    loss           : -1490.585109214998\n",
      "Train Epoch: 3060 [512/60000 (1%)] Loss: -1481.438232\n",
      "Train Epoch: 3060 [11776/60000 (20%)] Loss: -1388.045288\n",
      "Train Epoch: 3060 [23040/60000 (38%)] Loss: -1505.651855\n",
      "Train Epoch: 3060 [34304/60000 (57%)] Loss: -1563.235596\n",
      "Train Epoch: 3060 [45568/60000 (76%)] Loss: -1559.970337\n",
      "Train Epoch: 3060 [56832/60000 (95%)] Loss: -1486.914185\n",
      "    epoch          : 3060\n",
      "    loss           : -1479.8795614296432\n",
      "Train Epoch: 3061 [512/60000 (1%)] Loss: -1421.801880\n",
      "Train Epoch: 3061 [11776/60000 (20%)] Loss: -1496.278687\n",
      "Train Epoch: 3061 [23040/60000 (38%)] Loss: -1539.842529\n",
      "Train Epoch: 3061 [34304/60000 (57%)] Loss: -1373.141846\n",
      "Train Epoch: 3061 [45568/60000 (76%)] Loss: -1388.601196\n",
      "Train Epoch: 3061 [56832/60000 (95%)] Loss: -1540.936768\n",
      "    epoch          : 3061\n",
      "    loss           : -1474.3969526560295\n",
      "Train Epoch: 3062 [512/60000 (1%)] Loss: -1607.686035\n",
      "Train Epoch: 3062 [11776/60000 (20%)] Loss: -1401.558594\n",
      "Train Epoch: 3062 [23040/60000 (38%)] Loss: -1507.723145\n",
      "Train Epoch: 3062 [34304/60000 (57%)] Loss: -1463.825439\n",
      "Train Epoch: 3062 [45568/60000 (76%)] Loss: -1435.985840\n",
      "Train Epoch: 3062 [56832/60000 (95%)] Loss: -1418.789917\n",
      "    epoch          : 3062\n",
      "    loss           : -1489.1263417389434\n",
      "Train Epoch: 3063 [512/60000 (1%)] Loss: -1489.756958\n",
      "Train Epoch: 3063 [11776/60000 (20%)] Loss: -1441.025879\n",
      "Train Epoch: 3063 [23040/60000 (38%)] Loss: -1525.662354\n",
      "Train Epoch: 3063 [34304/60000 (57%)] Loss: -1430.366699\n",
      "Train Epoch: 3063 [45568/60000 (76%)] Loss: -1571.889038\n",
      "Train Epoch: 3063 [56832/60000 (95%)] Loss: -1512.046875\n",
      "    epoch          : 3063\n",
      "    loss           : -1481.6937359308793\n",
      "Train Epoch: 3064 [512/60000 (1%)] Loss: -1560.068726\n",
      "Train Epoch: 3064 [11776/60000 (20%)] Loss: -1451.208252\n",
      "Train Epoch: 3064 [23040/60000 (38%)] Loss: -1486.238403\n",
      "Train Epoch: 3064 [34304/60000 (57%)] Loss: -1541.064941\n",
      "Train Epoch: 3064 [45568/60000 (76%)] Loss: -1382.300415\n",
      "Train Epoch: 3064 [56832/60000 (95%)] Loss: -1414.966309\n",
      "    epoch          : 3064\n",
      "    loss           : -1487.0052869548906\n",
      "Train Epoch: 3065 [512/60000 (1%)] Loss: -1558.133789\n",
      "Train Epoch: 3065 [11776/60000 (20%)] Loss: -1468.856934\n",
      "Train Epoch: 3065 [23040/60000 (38%)] Loss: -1577.782715\n",
      "Train Epoch: 3065 [34304/60000 (57%)] Loss: -1540.719849\n",
      "Train Epoch: 3065 [45568/60000 (76%)] Loss: -1580.609619\n",
      "Train Epoch: 3065 [56832/60000 (95%)] Loss: -1527.409668\n",
      "    epoch          : 3065\n",
      "    loss           : -1490.402862031581\n",
      "Train Epoch: 3066 [512/60000 (1%)] Loss: -1426.935669\n",
      "Train Epoch: 3066 [11776/60000 (20%)] Loss: -1396.122192\n",
      "Train Epoch: 3066 [23040/60000 (38%)] Loss: -1482.367065\n",
      "Train Epoch: 3066 [34304/60000 (57%)] Loss: -1561.862915\n",
      "Train Epoch: 3066 [45568/60000 (76%)] Loss: -1530.792847\n",
      "Train Epoch: 3066 [56832/60000 (95%)] Loss: -1584.859131\n",
      "    epoch          : 3066\n",
      "    loss           : -1477.9824546339823\n",
      "Train Epoch: 3067 [512/60000 (1%)] Loss: -1473.763672\n",
      "Train Epoch: 3067 [11776/60000 (20%)] Loss: -1463.165283\n",
      "Train Epoch: 3067 [23040/60000 (38%)] Loss: -1443.322510\n",
      "Train Epoch: 3067 [34304/60000 (57%)] Loss: -1554.348022\n",
      "Train Epoch: 3067 [45568/60000 (76%)] Loss: -1572.675903\n",
      "Train Epoch: 3067 [56832/60000 (95%)] Loss: -1531.491699\n",
      "    epoch          : 3067\n",
      "    loss           : -1490.541963911326\n",
      "Train Epoch: 3068 [512/60000 (1%)] Loss: -1453.588135\n",
      "Train Epoch: 3068 [11776/60000 (20%)] Loss: -1379.445923\n",
      "Train Epoch: 3068 [23040/60000 (38%)] Loss: -1585.425781\n",
      "Train Epoch: 3068 [34304/60000 (57%)] Loss: -1547.611206\n",
      "Train Epoch: 3068 [45568/60000 (76%)] Loss: -1539.277222\n",
      "Train Epoch: 3068 [56832/60000 (95%)] Loss: -1586.535278\n",
      "    epoch          : 3068\n",
      "    loss           : -1482.9574657375529\n",
      "Train Epoch: 3069 [512/60000 (1%)] Loss: -1573.126465\n",
      "Train Epoch: 3069 [11776/60000 (20%)] Loss: -1425.047607\n",
      "Train Epoch: 3069 [23040/60000 (38%)] Loss: -1534.930542\n",
      "Train Epoch: 3069 [34304/60000 (57%)] Loss: -1570.419678\n",
      "Train Epoch: 3069 [45568/60000 (76%)] Loss: -1475.019897\n",
      "Train Epoch: 3069 [56832/60000 (95%)] Loss: -1443.734253\n",
      "    epoch          : 3069\n",
      "    loss           : -1487.9298261222193\n",
      "Train Epoch: 3070 [512/60000 (1%)] Loss: -1565.886475\n",
      "Train Epoch: 3070 [11776/60000 (20%)] Loss: -1449.517578\n",
      "Train Epoch: 3070 [23040/60000 (38%)] Loss: -1563.509033\n",
      "Train Epoch: 3070 [34304/60000 (57%)] Loss: -1568.263794\n",
      "Train Epoch: 3070 [45568/60000 (76%)] Loss: -1499.581055\n",
      "Train Epoch: 3070 [56832/60000 (95%)] Loss: -1505.667236\n",
      "    epoch          : 3070\n",
      "    loss           : -1500.6461223020392\n",
      "Train Epoch: 3071 [512/60000 (1%)] Loss: -1457.660889\n",
      "Train Epoch: 3071 [11776/60000 (20%)] Loss: -1432.729980\n",
      "Train Epoch: 3071 [23040/60000 (38%)] Loss: -1455.186035\n",
      "Train Epoch: 3071 [34304/60000 (57%)] Loss: -1440.266602\n",
      "Train Epoch: 3071 [45568/60000 (76%)] Loss: -1455.228027\n",
      "Train Epoch: 3071 [56832/60000 (95%)] Loss: -1458.935059\n",
      "    epoch          : 3071\n",
      "    loss           : -1481.5253637281514\n",
      "Train Epoch: 3072 [512/60000 (1%)] Loss: -1589.949951\n",
      "Train Epoch: 3072 [11776/60000 (20%)] Loss: -1427.245605\n",
      "Train Epoch: 3072 [23040/60000 (38%)] Loss: -1507.782227\n",
      "Train Epoch: 3072 [34304/60000 (57%)] Loss: -1295.007324\n",
      "Train Epoch: 3072 [45568/60000 (76%)] Loss: -1595.865723\n",
      "Train Epoch: 3072 [56832/60000 (95%)] Loss: -1405.665649\n",
      "    epoch          : 3072\n",
      "    loss           : -1474.8065747622043\n",
      "Train Epoch: 3073 [512/60000 (1%)] Loss: -1556.005859\n",
      "Train Epoch: 3073 [11776/60000 (20%)] Loss: -1348.593872\n",
      "Train Epoch: 3073 [23040/60000 (38%)] Loss: -1547.142944\n",
      "Train Epoch: 3073 [34304/60000 (57%)] Loss: -1526.446533\n",
      "Train Epoch: 3073 [45568/60000 (76%)] Loss: -1539.627197\n",
      "Train Epoch: 3073 [56832/60000 (95%)] Loss: -1558.837524\n",
      "    epoch          : 3073\n",
      "    loss           : -1494.135051145392\n",
      "Train Epoch: 3074 [512/60000 (1%)] Loss: -1589.407715\n",
      "Train Epoch: 3074 [11776/60000 (20%)] Loss: -1502.170410\n",
      "Train Epoch: 3074 [23040/60000 (38%)] Loss: -1457.957397\n",
      "Train Epoch: 3074 [34304/60000 (57%)] Loss: -1588.550415\n",
      "Train Epoch: 3074 [45568/60000 (76%)] Loss: -1516.195557\n",
      "Train Epoch: 3074 [56832/60000 (95%)] Loss: -1429.590698\n",
      "    epoch          : 3074\n",
      "    loss           : -1482.6970149325787\n",
      "Train Epoch: 3075 [512/60000 (1%)] Loss: -1585.438721\n",
      "Train Epoch: 3075 [11776/60000 (20%)] Loss: -1441.955566\n",
      "Train Epoch: 3075 [23040/60000 (38%)] Loss: -1411.353027\n",
      "Train Epoch: 3075 [34304/60000 (57%)] Loss: -1392.069824\n",
      "Train Epoch: 3075 [45568/60000 (76%)] Loss: -1542.817505\n",
      "Train Epoch: 3075 [56832/60000 (95%)] Loss: -1560.036133\n",
      "    epoch          : 3075\n",
      "    loss           : -1488.1893965726517\n",
      "Train Epoch: 3076 [512/60000 (1%)] Loss: -1492.480103\n",
      "Train Epoch: 3076 [11776/60000 (20%)] Loss: -1556.344849\n",
      "Train Epoch: 3076 [23040/60000 (38%)] Loss: -1459.001465\n",
      "Train Epoch: 3076 [34304/60000 (57%)] Loss: -1451.491943\n",
      "Train Epoch: 3076 [45568/60000 (76%)] Loss: -1539.121094\n",
      "Train Epoch: 3076 [56832/60000 (95%)] Loss: -1417.635620\n",
      "    epoch          : 3076\n",
      "    loss           : -1488.5402473406602\n",
      "Train Epoch: 3077 [512/60000 (1%)] Loss: -1470.121338\n",
      "Train Epoch: 3077 [11776/60000 (20%)] Loss: -1562.481567\n",
      "Train Epoch: 3077 [23040/60000 (38%)] Loss: -1564.136963\n",
      "Train Epoch: 3077 [34304/60000 (57%)] Loss: -1585.212891\n",
      "Train Epoch: 3077 [45568/60000 (76%)] Loss: -1444.926025\n",
      "Train Epoch: 3077 [56832/60000 (95%)] Loss: -1508.594116\n",
      "    epoch          : 3077\n",
      "    loss           : -1490.943375237244\n",
      "Train Epoch: 3078 [512/60000 (1%)] Loss: -1393.241455\n",
      "Train Epoch: 3078 [11776/60000 (20%)] Loss: -1565.282349\n",
      "Train Epoch: 3078 [23040/60000 (38%)] Loss: -1504.433838\n",
      "Train Epoch: 3078 [34304/60000 (57%)] Loss: -1457.948730\n",
      "Train Epoch: 3078 [45568/60000 (76%)] Loss: -1476.920898\n",
      "Train Epoch: 3078 [56832/60000 (95%)] Loss: -1564.846924\n",
      "    epoch          : 3078\n",
      "    loss           : -1481.534913833532\n",
      "Train Epoch: 3079 [512/60000 (1%)] Loss: -1538.738525\n",
      "Train Epoch: 3079 [11776/60000 (20%)] Loss: -1521.375977\n",
      "Train Epoch: 3079 [23040/60000 (38%)] Loss: -1470.189697\n",
      "Train Epoch: 3079 [34304/60000 (57%)] Loss: -1432.196289\n",
      "Train Epoch: 3079 [45568/60000 (76%)] Loss: -1446.057007\n",
      "Train Epoch: 3079 [56832/60000 (95%)] Loss: -1450.885620\n",
      "    epoch          : 3079\n",
      "    loss           : -1477.9070110428806\n",
      "Train Epoch: 3080 [512/60000 (1%)] Loss: -1490.511475\n",
      "Train Epoch: 3080 [11776/60000 (20%)] Loss: -1453.155273\n",
      "Train Epoch: 3080 [23040/60000 (38%)] Loss: -1380.097534\n",
      "Train Epoch: 3080 [34304/60000 (57%)] Loss: -1544.552612\n",
      "Train Epoch: 3080 [45568/60000 (76%)] Loss: -1508.906250\n",
      "Train Epoch: 3080 [56832/60000 (95%)] Loss: -1400.218140\n",
      "    epoch          : 3080\n",
      "    loss           : -1485.1297097071417\n",
      "Train Epoch: 3081 [512/60000 (1%)] Loss: -1454.535522\n",
      "Train Epoch: 3081 [11776/60000 (20%)] Loss: -1549.579590\n",
      "Train Epoch: 3081 [23040/60000 (38%)] Loss: -1586.726807\n",
      "Train Epoch: 3081 [34304/60000 (57%)] Loss: -1442.969849\n",
      "Train Epoch: 3081 [45568/60000 (76%)] Loss: -1491.617432\n",
      "Train Epoch: 3081 [56832/60000 (95%)] Loss: -1512.808838\n",
      "    epoch          : 3081\n",
      "    loss           : -1486.0233526714778\n",
      "Train Epoch: 3082 [512/60000 (1%)] Loss: -1449.295410\n",
      "Train Epoch: 3082 [11776/60000 (20%)] Loss: -1427.434082\n",
      "Train Epoch: 3082 [23040/60000 (38%)] Loss: -1576.312744\n",
      "Train Epoch: 3082 [34304/60000 (57%)] Loss: -1566.314087\n",
      "Train Epoch: 3082 [45568/60000 (76%)] Loss: -1415.786133\n",
      "Train Epoch: 3082 [56832/60000 (95%)] Loss: -1520.667480\n",
      "    epoch          : 3082\n",
      "    loss           : -1489.3898343016199\n",
      "Train Epoch: 3083 [512/60000 (1%)] Loss: -1458.866455\n",
      "Train Epoch: 3083 [11776/60000 (20%)] Loss: -1540.523438\n",
      "Train Epoch: 3083 [23040/60000 (38%)] Loss: -1464.027954\n",
      "Train Epoch: 3083 [34304/60000 (57%)] Loss: -1540.980835\n",
      "Train Epoch: 3083 [45568/60000 (76%)] Loss: -1566.736084\n",
      "Train Epoch: 3083 [56832/60000 (95%)] Loss: -1524.691528\n",
      "    epoch          : 3083\n",
      "    loss           : -1487.3248611708818\n",
      "Train Epoch: 3084 [512/60000 (1%)] Loss: -1389.709229\n",
      "Train Epoch: 3084 [11776/60000 (20%)] Loss: -1571.240967\n",
      "Train Epoch: 3084 [23040/60000 (38%)] Loss: -1472.389160\n",
      "Train Epoch: 3084 [34304/60000 (57%)] Loss: -1447.734131\n",
      "Train Epoch: 3084 [45568/60000 (76%)] Loss: -1443.260742\n",
      "Train Epoch: 3084 [56832/60000 (95%)] Loss: -1502.782349\n",
      "    epoch          : 3084\n",
      "    loss           : -1484.8462893383653\n",
      "Train Epoch: 3085 [512/60000 (1%)] Loss: -1555.776123\n",
      "Train Epoch: 3085 [11776/60000 (20%)] Loss: -1515.958740\n",
      "Train Epoch: 3085 [23040/60000 (38%)] Loss: -1350.643066\n",
      "Train Epoch: 3085 [34304/60000 (57%)] Loss: -1549.961670\n",
      "Train Epoch: 3085 [45568/60000 (76%)] Loss: -1563.662842\n",
      "Train Epoch: 3085 [56832/60000 (95%)] Loss: -1461.616455\n",
      "    epoch          : 3085\n",
      "    loss           : -1474.3511559437898\n",
      "Train Epoch: 3086 [512/60000 (1%)] Loss: -1490.596680\n",
      "Train Epoch: 3086 [11776/60000 (20%)] Loss: -1539.924927\n",
      "Train Epoch: 3086 [23040/60000 (38%)] Loss: -1387.739868\n",
      "Train Epoch: 3086 [34304/60000 (57%)] Loss: -1462.094971\n",
      "Train Epoch: 3086 [45568/60000 (76%)] Loss: -1553.520142\n",
      "Train Epoch: 3086 [56832/60000 (95%)] Loss: -1411.358032\n",
      "    epoch          : 3086\n",
      "    loss           : -1499.3457169182557\n",
      "Train Epoch: 3087 [512/60000 (1%)] Loss: -1417.668945\n",
      "Train Epoch: 3087 [11776/60000 (20%)] Loss: -1477.399414\n",
      "Train Epoch: 3087 [23040/60000 (38%)] Loss: -1443.105591\n",
      "Train Epoch: 3087 [34304/60000 (57%)] Loss: -1461.326538\n",
      "Train Epoch: 3087 [45568/60000 (76%)] Loss: -1496.823242\n",
      "Train Epoch: 3087 [56832/60000 (95%)] Loss: -1463.526001\n",
      "    epoch          : 3087\n",
      "    loss           : -1488.5684493759932\n",
      "Train Epoch: 3088 [512/60000 (1%)] Loss: -1569.104736\n",
      "Train Epoch: 3088 [11776/60000 (20%)] Loss: -1518.942871\n",
      "Train Epoch: 3088 [23040/60000 (38%)] Loss: -1449.674316\n",
      "Train Epoch: 3088 [34304/60000 (57%)] Loss: -1417.862427\n",
      "Train Epoch: 3088 [45568/60000 (76%)] Loss: -1507.600342\n",
      "Train Epoch: 3088 [56832/60000 (95%)] Loss: -1527.398682\n",
      "    epoch          : 3088\n",
      "    loss           : -1489.9577516027762\n",
      "Train Epoch: 3089 [512/60000 (1%)] Loss: -1465.755615\n",
      "Train Epoch: 3089 [11776/60000 (20%)] Loss: -1473.112427\n",
      "Train Epoch: 3089 [23040/60000 (38%)] Loss: -1438.729004\n",
      "Train Epoch: 3089 [34304/60000 (57%)] Loss: -1457.304077\n",
      "Train Epoch: 3089 [45568/60000 (76%)] Loss: -1472.191895\n",
      "Train Epoch: 3089 [56832/60000 (95%)] Loss: -1497.135986\n",
      "    epoch          : 3089\n",
      "    loss           : -1479.2514417400469\n",
      "Train Epoch: 3090 [512/60000 (1%)] Loss: -1472.236816\n",
      "Train Epoch: 3090 [11776/60000 (20%)] Loss: -1466.541504\n",
      "Train Epoch: 3090 [23040/60000 (38%)] Loss: -1413.424561\n",
      "Train Epoch: 3090 [34304/60000 (57%)] Loss: -1449.420166\n",
      "Train Epoch: 3090 [45568/60000 (76%)] Loss: -1506.787354\n",
      "Train Epoch: 3090 [56832/60000 (95%)] Loss: -1482.531616\n",
      "    epoch          : 3090\n",
      "    loss           : -1478.0924648134048\n",
      "Train Epoch: 3091 [512/60000 (1%)] Loss: -1333.900513\n",
      "Train Epoch: 3091 [11776/60000 (20%)] Loss: -1475.338501\n",
      "Train Epoch: 3091 [23040/60000 (38%)] Loss: -1419.702271\n",
      "Train Epoch: 3091 [34304/60000 (57%)] Loss: -1442.699463\n",
      "Train Epoch: 3091 [45568/60000 (76%)] Loss: -1489.668579\n",
      "Train Epoch: 3091 [56832/60000 (95%)] Loss: -1574.124756\n",
      "    epoch          : 3091\n",
      "    loss           : -1481.256282483117\n",
      "Train Epoch: 3092 [512/60000 (1%)] Loss: -1394.818604\n",
      "Train Epoch: 3092 [11776/60000 (20%)] Loss: -1490.622803\n",
      "Train Epoch: 3092 [23040/60000 (38%)] Loss: -1451.542969\n",
      "Train Epoch: 3092 [34304/60000 (57%)] Loss: -1523.420898\n",
      "Train Epoch: 3092 [45568/60000 (76%)] Loss: -1501.624146\n",
      "Train Epoch: 3092 [56832/60000 (95%)] Loss: -1409.140259\n",
      "    epoch          : 3092\n",
      "    loss           : -1486.9200080828477\n",
      "Train Epoch: 3093 [512/60000 (1%)] Loss: -1576.680786\n",
      "Train Epoch: 3093 [11776/60000 (20%)] Loss: -1446.765381\n",
      "Train Epoch: 3093 [23040/60000 (38%)] Loss: -1492.059082\n",
      "Train Epoch: 3093 [34304/60000 (57%)] Loss: -1537.705200\n",
      "Train Epoch: 3093 [45568/60000 (76%)] Loss: -1492.508301\n",
      "Train Epoch: 3093 [56832/60000 (95%)] Loss: -1500.805542\n",
      "    epoch          : 3093\n",
      "    loss           : -1481.097424523305\n",
      "Train Epoch: 3094 [512/60000 (1%)] Loss: -1386.275757\n",
      "Train Epoch: 3094 [11776/60000 (20%)] Loss: -1584.850464\n",
      "Train Epoch: 3094 [23040/60000 (38%)] Loss: -1487.539062\n",
      "Train Epoch: 3094 [34304/60000 (57%)] Loss: -1494.958740\n",
      "Train Epoch: 3094 [45568/60000 (76%)] Loss: -1468.494507\n",
      "Train Epoch: 3094 [56832/60000 (95%)] Loss: -1524.710449\n",
      "    epoch          : 3094\n",
      "    loss           : -1486.4922692250398\n",
      "Train Epoch: 3095 [512/60000 (1%)] Loss: -1531.357056\n",
      "Train Epoch: 3095 [11776/60000 (20%)] Loss: -1393.318115\n",
      "Train Epoch: 3095 [23040/60000 (38%)] Loss: -1456.971680\n",
      "Train Epoch: 3095 [34304/60000 (57%)] Loss: -1568.334473\n",
      "Train Epoch: 3095 [45568/60000 (76%)] Loss: -1530.153442\n",
      "Train Epoch: 3095 [56832/60000 (95%)] Loss: -1578.173096\n",
      "    epoch          : 3095\n",
      "    loss           : -1492.4070755263506\n",
      "Train Epoch: 3096 [512/60000 (1%)] Loss: -1578.216553\n",
      "Train Epoch: 3096 [11776/60000 (20%)] Loss: -1455.497559\n",
      "Train Epoch: 3096 [23040/60000 (38%)] Loss: -1492.932983\n",
      "Train Epoch: 3096 [34304/60000 (57%)] Loss: -1416.944824\n",
      "Train Epoch: 3096 [45568/60000 (76%)] Loss: -1467.103027\n",
      "Train Epoch: 3096 [56832/60000 (95%)] Loss: -1511.382568\n",
      "    epoch          : 3096\n",
      "    loss           : -1492.9178346105887\n",
      "Train Epoch: 3097 [512/60000 (1%)] Loss: -1487.322510\n",
      "Train Epoch: 3097 [11776/60000 (20%)] Loss: -1545.241577\n",
      "Train Epoch: 3097 [23040/60000 (38%)] Loss: -1593.351562\n",
      "Train Epoch: 3097 [34304/60000 (57%)] Loss: -1464.486328\n",
      "Train Epoch: 3097 [45568/60000 (76%)] Loss: -1534.792969\n",
      "Train Epoch: 3097 [56832/60000 (95%)] Loss: -1530.510254\n",
      "    epoch          : 3097\n",
      "    loss           : -1487.0815912451449\n",
      "Train Epoch: 3098 [512/60000 (1%)] Loss: -1441.256470\n",
      "Train Epoch: 3098 [11776/60000 (20%)] Loss: -1397.801514\n",
      "Train Epoch: 3098 [23040/60000 (38%)] Loss: -1573.221069\n",
      "Train Epoch: 3098 [34304/60000 (57%)] Loss: -1369.895874\n",
      "Train Epoch: 3098 [45568/60000 (76%)] Loss: -1458.977173\n",
      "Train Epoch: 3098 [56832/60000 (95%)] Loss: -1538.751953\n",
      "    epoch          : 3098\n",
      "    loss           : -1480.5656458967824\n",
      "Train Epoch: 3099 [512/60000 (1%)] Loss: -1414.545898\n",
      "Train Epoch: 3099 [11776/60000 (20%)] Loss: -1511.218384\n",
      "Train Epoch: 3099 [23040/60000 (38%)] Loss: -1430.332520\n",
      "Train Epoch: 3099 [34304/60000 (57%)] Loss: -1484.757568\n",
      "Train Epoch: 3099 [45568/60000 (76%)] Loss: -1553.893188\n",
      "Train Epoch: 3099 [56832/60000 (95%)] Loss: -1485.886353\n",
      "    epoch          : 3099\n",
      "    loss           : -1495.68913588012\n",
      "Train Epoch: 3100 [512/60000 (1%)] Loss: -1545.028076\n",
      "Train Epoch: 3100 [11776/60000 (20%)] Loss: -1330.527344\n",
      "Train Epoch: 3100 [23040/60000 (38%)] Loss: -1566.237305\n",
      "Train Epoch: 3100 [34304/60000 (57%)] Loss: -1601.214478\n",
      "Train Epoch: 3100 [45568/60000 (76%)] Loss: -1448.551025\n",
      "Train Epoch: 3100 [56832/60000 (95%)] Loss: -1560.906738\n",
      "    epoch          : 3100\n",
      "    loss           : -1485.8657988639875\n",
      "Saving checkpoint: saved/models/Mnist_DeepGenerativeOperad/0127_111843/checkpoint-epoch3100.pth ...\n",
      "Train Epoch: 3101 [512/60000 (1%)] Loss: -1394.279541\n",
      "Train Epoch: 3101 [11776/60000 (20%)] Loss: -1459.950439\n",
      "Train Epoch: 3101 [23040/60000 (38%)] Loss: -1424.482178\n",
      "Train Epoch: 3101 [34304/60000 (57%)] Loss: -1582.895752\n",
      "Train Epoch: 3101 [45568/60000 (76%)] Loss: -1542.323486\n",
      "Train Epoch: 3101 [56832/60000 (95%)] Loss: -1440.127075\n",
      "    epoch          : 3101\n",
      "    loss           : -1483.3435006869042\n",
      "Train Epoch: 3102 [512/60000 (1%)] Loss: -1389.639282\n",
      "Train Epoch: 3102 [11776/60000 (20%)] Loss: -1486.083374\n",
      "Train Epoch: 3102 [23040/60000 (38%)] Loss: -1482.292480\n",
      "Train Epoch: 3102 [34304/60000 (57%)] Loss: -1495.083252\n",
      "Train Epoch: 3102 [45568/60000 (76%)] Loss: -1574.365234\n",
      "Train Epoch: 3102 [56832/60000 (95%)] Loss: -1536.565186\n",
      "    epoch          : 3102\n",
      "    loss           : -1493.775432004767\n",
      "Train Epoch: 3103 [512/60000 (1%)] Loss: -1450.335571\n",
      "Train Epoch: 3103 [11776/60000 (20%)] Loss: -1573.936279\n",
      "Train Epoch: 3103 [23040/60000 (38%)] Loss: -1530.844971\n",
      "Train Epoch: 3103 [34304/60000 (57%)] Loss: -1475.323975\n",
      "Train Epoch: 3103 [45568/60000 (76%)] Loss: -1531.258545\n",
      "Train Epoch: 3103 [56832/60000 (95%)] Loss: -1415.916504\n",
      "    epoch          : 3103\n",
      "    loss           : -1494.9546581203654\n",
      "Train Epoch: 3104 [512/60000 (1%)] Loss: -1418.505371\n",
      "Train Epoch: 3104 [11776/60000 (20%)] Loss: -1507.768066\n",
      "Train Epoch: 3104 [23040/60000 (38%)] Loss: -1565.197388\n",
      "Train Epoch: 3104 [34304/60000 (57%)] Loss: -1555.631348\n",
      "Train Epoch: 3104 [45568/60000 (76%)] Loss: -1456.543213\n",
      "Train Epoch: 3104 [56832/60000 (95%)] Loss: -1371.023193\n",
      "    epoch          : 3104\n",
      "    loss           : -1491.6084694727667\n",
      "Train Epoch: 3105 [512/60000 (1%)] Loss: -1496.200928\n",
      "Train Epoch: 3105 [11776/60000 (20%)] Loss: -1593.580566\n",
      "Train Epoch: 3105 [23040/60000 (38%)] Loss: -1549.883179\n",
      "Train Epoch: 3105 [34304/60000 (57%)] Loss: -1512.187256\n",
      "Train Epoch: 3105 [45568/60000 (76%)] Loss: -1368.892822\n",
      "Train Epoch: 3105 [56832/60000 (95%)] Loss: -1554.134888\n",
      "    epoch          : 3105\n",
      "    loss           : -1488.9061475850767\n",
      "Train Epoch: 3106 [512/60000 (1%)] Loss: -1442.618896\n",
      "Train Epoch: 3106 [11776/60000 (20%)] Loss: -1489.696289\n",
      "Train Epoch: 3106 [23040/60000 (38%)] Loss: -1494.390259\n",
      "Train Epoch: 3106 [34304/60000 (57%)] Loss: -1488.455078\n",
      "Train Epoch: 3106 [45568/60000 (76%)] Loss: -1469.389038\n",
      "Train Epoch: 3106 [56832/60000 (95%)] Loss: -1499.144897\n",
      "    epoch          : 3106\n",
      "    loss           : -1484.6292803920596\n",
      "Train Epoch: 3107 [512/60000 (1%)] Loss: -1379.498779\n",
      "Train Epoch: 3107 [11776/60000 (20%)] Loss: -1498.949707\n",
      "Train Epoch: 3107 [23040/60000 (38%)] Loss: -1493.541992\n",
      "Train Epoch: 3107 [34304/60000 (57%)] Loss: -1520.160156\n",
      "Train Epoch: 3107 [45568/60000 (76%)] Loss: -1571.966553\n",
      "Train Epoch: 3107 [56832/60000 (95%)] Loss: -1388.351440\n",
      "    epoch          : 3107\n",
      "    loss           : -1503.9991941290386\n",
      "Train Epoch: 3108 [512/60000 (1%)] Loss: -1559.943604\n",
      "Train Epoch: 3108 [11776/60000 (20%)] Loss: -1495.089355\n",
      "Train Epoch: 3108 [23040/60000 (38%)] Loss: -1468.817383\n",
      "Train Epoch: 3108 [34304/60000 (57%)] Loss: -1534.868408\n",
      "Train Epoch: 3108 [45568/60000 (76%)] Loss: -1480.543213\n",
      "Train Epoch: 3108 [56832/60000 (95%)] Loss: -1479.968384\n",
      "    epoch          : 3108\n",
      "    loss           : -1491.4949316682116\n",
      "Train Epoch: 3109 [512/60000 (1%)] Loss: -1518.230835\n",
      "Train Epoch: 3109 [11776/60000 (20%)] Loss: -1525.889160\n",
      "Train Epoch: 3109 [23040/60000 (38%)] Loss: -1531.433838\n",
      "Train Epoch: 3109 [34304/60000 (57%)] Loss: -1415.154175\n",
      "Train Epoch: 3109 [45568/60000 (76%)] Loss: -1440.342896\n",
      "Train Epoch: 3109 [56832/60000 (95%)] Loss: -1506.084839\n",
      "    epoch          : 3109\n",
      "    loss           : -1485.0039252157264\n",
      "Train Epoch: 3110 [512/60000 (1%)] Loss: -1498.589233\n",
      "Train Epoch: 3110 [11776/60000 (20%)] Loss: -1334.354980\n",
      "Train Epoch: 3110 [23040/60000 (38%)] Loss: -1535.948486\n",
      "Train Epoch: 3110 [34304/60000 (57%)] Loss: -1420.006348\n",
      "Train Epoch: 3110 [45568/60000 (76%)] Loss: -1549.072998\n",
      "Train Epoch: 3110 [56832/60000 (95%)] Loss: -1521.244141\n",
      "    epoch          : 3110\n",
      "    loss           : -1491.306253724179\n",
      "Train Epoch: 3111 [512/60000 (1%)] Loss: -1590.360596\n",
      "Train Epoch: 3111 [11776/60000 (20%)] Loss: -1533.654541\n",
      "Train Epoch: 3111 [23040/60000 (38%)] Loss: -1475.415527\n",
      "Train Epoch: 3111 [34304/60000 (57%)] Loss: -1470.952148\n",
      "Train Epoch: 3111 [45568/60000 (76%)] Loss: -1565.514648\n",
      "Train Epoch: 3111 [56832/60000 (95%)] Loss: -1417.134033\n",
      "    epoch          : 3111\n",
      "    loss           : -1489.1997618594412\n",
      "Train Epoch: 3112 [512/60000 (1%)] Loss: -1364.548340\n",
      "Train Epoch: 3112 [11776/60000 (20%)] Loss: -1598.423218\n",
      "Train Epoch: 3112 [23040/60000 (38%)] Loss: -1573.573120\n",
      "Train Epoch: 3112 [34304/60000 (57%)] Loss: -1513.891846\n",
      "Train Epoch: 3112 [45568/60000 (76%)] Loss: -1582.227051\n",
      "Train Epoch: 3112 [56832/60000 (95%)] Loss: -1528.537354\n",
      "    epoch          : 3112\n",
      "    loss           : -1496.7769989186088\n",
      "Train Epoch: 3113 [512/60000 (1%)] Loss: -1426.853760\n",
      "Train Epoch: 3113 [11776/60000 (20%)] Loss: -1515.944702\n",
      "Train Epoch: 3113 [23040/60000 (38%)] Loss: -1413.152344\n",
      "Train Epoch: 3113 [34304/60000 (57%)] Loss: -1480.800781\n",
      "Train Epoch: 3113 [45568/60000 (76%)] Loss: -1516.034912\n",
      "Train Epoch: 3113 [56832/60000 (95%)] Loss: -1446.305420\n",
      "    epoch          : 3113\n",
      "    loss           : -1494.4184973765227\n",
      "Train Epoch: 3114 [512/60000 (1%)] Loss: -1409.666992\n",
      "Train Epoch: 3114 [11776/60000 (20%)] Loss: -1571.502563\n",
      "Train Epoch: 3114 [23040/60000 (38%)] Loss: -1478.273438\n",
      "Train Epoch: 3114 [34304/60000 (57%)] Loss: -1577.887207\n",
      "Train Epoch: 3114 [45568/60000 (76%)] Loss: -1524.031250\n",
      "Train Epoch: 3114 [56832/60000 (95%)] Loss: -1470.197510\n",
      "    epoch          : 3114\n",
      "    loss           : -1493.4212370619261\n",
      "Train Epoch: 3115 [512/60000 (1%)] Loss: -1548.906616\n",
      "Train Epoch: 3115 [11776/60000 (20%)] Loss: -1460.361450\n",
      "Train Epoch: 3115 [23040/60000 (38%)] Loss: -1529.562012\n",
      "Train Epoch: 3115 [34304/60000 (57%)] Loss: -1486.635010\n",
      "Train Epoch: 3115 [45568/60000 (76%)] Loss: -1369.953369\n",
      "Train Epoch: 3115 [56832/60000 (95%)] Loss: -1508.805054\n",
      "    epoch          : 3115\n",
      "    loss           : -1492.3661667990818\n",
      "Train Epoch: 3116 [512/60000 (1%)] Loss: -1493.575928\n",
      "Train Epoch: 3116 [11776/60000 (20%)] Loss: -1510.108398\n",
      "Train Epoch: 3116 [23040/60000 (38%)] Loss: -1510.993896\n",
      "Train Epoch: 3116 [34304/60000 (57%)] Loss: -1370.460083\n",
      "Train Epoch: 3116 [45568/60000 (76%)] Loss: -1502.085327\n",
      "Train Epoch: 3116 [56832/60000 (95%)] Loss: -1429.442871\n",
      "    epoch          : 3116\n",
      "    loss           : -1487.8863918498412\n",
      "Train Epoch: 3117 [512/60000 (1%)] Loss: -1496.947510\n",
      "Train Epoch: 3117 [11776/60000 (20%)] Loss: -1518.248047\n",
      "Train Epoch: 3117 [23040/60000 (38%)] Loss: -1482.317871\n",
      "Train Epoch: 3117 [34304/60000 (57%)] Loss: -1497.122925\n",
      "Train Epoch: 3117 [45568/60000 (76%)] Loss: -1543.689697\n",
      "Train Epoch: 3117 [56832/60000 (95%)] Loss: -1452.788330\n",
      "    epoch          : 3117\n",
      "    loss           : -1498.5282799672273\n",
      "Train Epoch: 3118 [512/60000 (1%)] Loss: -1505.799316\n",
      "Train Epoch: 3118 [11776/60000 (20%)] Loss: -1543.129761\n",
      "Train Epoch: 3118 [23040/60000 (38%)] Loss: -1504.053223\n",
      "Train Epoch: 3118 [34304/60000 (57%)] Loss: -1445.356445\n",
      "Train Epoch: 3118 [45568/60000 (76%)] Loss: -1372.357788\n",
      "Train Epoch: 3118 [56832/60000 (95%)] Loss: -1571.625366\n",
      "    epoch          : 3118\n",
      "    loss           : -1498.5123984126722\n",
      "Train Epoch: 3119 [512/60000 (1%)] Loss: -1394.539307\n",
      "Train Epoch: 3119 [11776/60000 (20%)] Loss: -1534.610352\n",
      "Train Epoch: 3119 [23040/60000 (38%)] Loss: -1440.272705\n",
      "Train Epoch: 3119 [34304/60000 (57%)] Loss: -1472.430420\n",
      "Train Epoch: 3119 [45568/60000 (76%)] Loss: -1457.108643\n",
      "Train Epoch: 3119 [56832/60000 (95%)] Loss: -1401.646240\n",
      "    epoch          : 3119\n",
      "    loss           : -1486.1223720399673\n",
      "Train Epoch: 3120 [512/60000 (1%)] Loss: -1500.054565\n",
      "Train Epoch: 3120 [11776/60000 (20%)] Loss: -1509.861328\n",
      "Train Epoch: 3120 [23040/60000 (38%)] Loss: -1589.284912\n",
      "Train Epoch: 3120 [34304/60000 (57%)] Loss: -1516.916260\n",
      "Train Epoch: 3120 [45568/60000 (76%)] Loss: -1593.282471\n",
      "Train Epoch: 3120 [56832/60000 (95%)] Loss: -1489.337036\n",
      "    epoch          : 3120\n",
      "    loss           : -1506.2113333664372\n",
      "Train Epoch: 3121 [512/60000 (1%)] Loss: -1475.281128\n",
      "Train Epoch: 3121 [11776/60000 (20%)] Loss: -1548.689575\n",
      "Train Epoch: 3121 [23040/60000 (38%)] Loss: -1463.775146\n",
      "Train Epoch: 3121 [34304/60000 (57%)] Loss: -1520.900146\n",
      "Train Epoch: 3121 [45568/60000 (76%)] Loss: -1546.781006\n",
      "Train Epoch: 3121 [56832/60000 (95%)] Loss: -1416.349121\n",
      "    epoch          : 3121\n",
      "    loss           : -1496.1101246634446\n",
      "Train Epoch: 3122 [512/60000 (1%)] Loss: -1490.967163\n",
      "Train Epoch: 3122 [11776/60000 (20%)] Loss: -1455.835083\n",
      "Train Epoch: 3122 [23040/60000 (38%)] Loss: -1596.592651\n",
      "Train Epoch: 3122 [34304/60000 (57%)] Loss: -1460.639404\n",
      "Train Epoch: 3122 [45568/60000 (76%)] Loss: -1474.760010\n",
      "Train Epoch: 3122 [56832/60000 (95%)] Loss: -1491.710205\n",
      "    epoch          : 3122\n",
      "    loss           : -1491.1922672939838\n",
      "Train Epoch: 3123 [512/60000 (1%)] Loss: -1535.844727\n",
      "Train Epoch: 3123 [11776/60000 (20%)] Loss: -1520.505249\n",
      "Train Epoch: 3123 [23040/60000 (38%)] Loss: -1389.485352\n",
      "Train Epoch: 3123 [34304/60000 (57%)] Loss: -1542.245605\n",
      "Train Epoch: 3123 [45568/60000 (76%)] Loss: -1570.769775\n",
      "Train Epoch: 3123 [56832/60000 (95%)] Loss: -1391.288940\n",
      "    epoch          : 3123\n",
      "    loss           : -1496.2792348053497\n",
      "Train Epoch: 3124 [512/60000 (1%)] Loss: -1403.093750\n",
      "Train Epoch: 3124 [11776/60000 (20%)] Loss: -1517.323975\n",
      "Train Epoch: 3124 [23040/60000 (38%)] Loss: -1529.846558\n",
      "Train Epoch: 3124 [34304/60000 (57%)] Loss: -1491.654541\n",
      "Train Epoch: 3124 [45568/60000 (76%)] Loss: -1452.022095\n",
      "Train Epoch: 3124 [56832/60000 (95%)] Loss: -1480.342529\n",
      "    epoch          : 3124\n",
      "    loss           : -1491.3197473213497\n",
      "Train Epoch: 3125 [512/60000 (1%)] Loss: -1487.912109\n",
      "Train Epoch: 3125 [11776/60000 (20%)] Loss: -1585.056641\n",
      "Train Epoch: 3125 [23040/60000 (38%)] Loss: -1540.077637\n",
      "Train Epoch: 3125 [34304/60000 (57%)] Loss: -1465.191895\n",
      "Train Epoch: 3125 [45568/60000 (76%)] Loss: -1489.926025\n",
      "Train Epoch: 3125 [56832/60000 (95%)] Loss: -1563.403442\n",
      "    epoch          : 3125\n",
      "    loss           : -1501.5624889653955\n",
      "Train Epoch: 3126 [512/60000 (1%)] Loss: -1542.662354\n",
      "Train Epoch: 3126 [11776/60000 (20%)] Loss: -1461.826660\n",
      "Train Epoch: 3126 [23040/60000 (38%)] Loss: -1546.894409\n",
      "Train Epoch: 3126 [34304/60000 (57%)] Loss: -1507.635254\n",
      "Train Epoch: 3126 [45568/60000 (76%)] Loss: -1478.650635\n",
      "Train Epoch: 3126 [56832/60000 (95%)] Loss: -1489.533813\n",
      "    epoch          : 3126\n",
      "    loss           : -1504.1009290447344\n",
      "Train Epoch: 3127 [512/60000 (1%)] Loss: -1544.739624\n",
      "Train Epoch: 3127 [11776/60000 (20%)] Loss: -1458.374146\n",
      "Train Epoch: 3127 [23040/60000 (38%)] Loss: -1564.715820\n",
      "Train Epoch: 3127 [34304/60000 (57%)] Loss: -1442.700806\n",
      "Train Epoch: 3127 [45568/60000 (76%)] Loss: -1475.126099\n",
      "Train Epoch: 3127 [56832/60000 (95%)] Loss: -1425.681396\n",
      "    epoch          : 3127\n",
      "    loss           : -1491.9808453058793\n",
      "Train Epoch: 3128 [512/60000 (1%)] Loss: -1471.046021\n",
      "Train Epoch: 3128 [11776/60000 (20%)] Loss: -1489.944946\n",
      "Train Epoch: 3128 [23040/60000 (38%)] Loss: -1537.171021\n",
      "Train Epoch: 3128 [34304/60000 (57%)] Loss: -1450.570557\n",
      "Train Epoch: 3128 [45568/60000 (76%)] Loss: -1590.599731\n",
      "Train Epoch: 3128 [56832/60000 (95%)] Loss: -1488.906738\n",
      "    epoch          : 3128\n",
      "    loss           : -1506.9452600856284\n",
      "Train Epoch: 3129 [512/60000 (1%)] Loss: -1510.722534\n",
      "Train Epoch: 3129 [11776/60000 (20%)] Loss: -1572.283203\n",
      "Train Epoch: 3129 [23040/60000 (38%)] Loss: -1563.505249\n",
      "Train Epoch: 3129 [34304/60000 (57%)] Loss: -1500.846802\n",
      "Train Epoch: 3129 [45568/60000 (76%)] Loss: -1437.024048\n",
      "Train Epoch: 3129 [56832/60000 (95%)] Loss: -1591.591309\n",
      "    epoch          : 3129\n",
      "    loss           : -1492.6985670186705\n",
      "Train Epoch: 3130 [512/60000 (1%)] Loss: -1562.443604\n",
      "Train Epoch: 3130 [11776/60000 (20%)] Loss: -1375.429810\n",
      "Train Epoch: 3130 [23040/60000 (38%)] Loss: -1522.667969\n",
      "Train Epoch: 3130 [34304/60000 (57%)] Loss: -1496.564697\n",
      "Train Epoch: 3130 [45568/60000 (76%)] Loss: -1523.144043\n",
      "Train Epoch: 3130 [56832/60000 (95%)] Loss: -1476.326416\n",
      "    epoch          : 3130\n",
      "    loss           : -1501.7557000628972\n",
      "Train Epoch: 3131 [512/60000 (1%)] Loss: -1383.489868\n",
      "Train Epoch: 3131 [11776/60000 (20%)] Loss: -1502.856689\n",
      "Train Epoch: 3131 [23040/60000 (38%)] Loss: -1453.751465\n",
      "Train Epoch: 3131 [34304/60000 (57%)] Loss: -1532.191284\n",
      "Train Epoch: 3131 [45568/60000 (76%)] Loss: -1400.456787\n",
      "Train Epoch: 3131 [56832/60000 (95%)] Loss: -1476.529297\n",
      "    epoch          : 3131\n",
      "    loss           : -1492.9178463348562\n",
      "Train Epoch: 3132 [512/60000 (1%)] Loss: -1591.244751\n",
      "Train Epoch: 3132 [11776/60000 (20%)] Loss: -1547.424316\n",
      "Train Epoch: 3132 [23040/60000 (38%)] Loss: -1397.596680\n",
      "Train Epoch: 3132 [34304/60000 (57%)] Loss: -1458.166992\n",
      "Train Epoch: 3132 [45568/60000 (76%)] Loss: -1550.153442\n",
      "Train Epoch: 3132 [56832/60000 (95%)] Loss: -1528.085449\n",
      "    epoch          : 3132\n",
      "    loss           : -1501.923092254811\n",
      "Train Epoch: 3133 [512/60000 (1%)] Loss: -1408.782959\n",
      "Train Epoch: 3133 [11776/60000 (20%)] Loss: -1447.445679\n",
      "Train Epoch: 3133 [23040/60000 (38%)] Loss: -1571.939819\n",
      "Train Epoch: 3133 [34304/60000 (57%)] Loss: -1530.380127\n",
      "Train Epoch: 3133 [45568/60000 (76%)] Loss: -1544.897217\n",
      "Train Epoch: 3133 [56832/60000 (95%)] Loss: -1576.523315\n",
      "    epoch          : 3133\n",
      "    loss           : -1497.9342251362773\n",
      "Train Epoch: 3134 [512/60000 (1%)] Loss: -1507.302124\n",
      "Train Epoch: 3134 [11776/60000 (20%)] Loss: -1554.831299\n",
      "Train Epoch: 3134 [23040/60000 (38%)] Loss: -1535.903931\n",
      "Train Epoch: 3134 [34304/60000 (57%)] Loss: -1581.190674\n",
      "Train Epoch: 3134 [45568/60000 (76%)] Loss: -1477.661133\n",
      "Train Epoch: 3134 [56832/60000 (95%)] Loss: -1538.449219\n",
      "    epoch          : 3134\n",
      "    loss           : -1502.7029084458864\n",
      "Train Epoch: 3135 [512/60000 (1%)] Loss: -1494.666992\n",
      "Train Epoch: 3135 [11776/60000 (20%)] Loss: -1380.858765\n",
      "Train Epoch: 3135 [23040/60000 (38%)] Loss: -1600.651855\n",
      "Train Epoch: 3135 [34304/60000 (57%)] Loss: -1526.442383\n",
      "Train Epoch: 3135 [45568/60000 (76%)] Loss: -1494.712891\n",
      "Train Epoch: 3135 [56832/60000 (95%)] Loss: -1450.131714\n",
      "    epoch          : 3135\n",
      "    loss           : -1499.6011073225636\n",
      "Train Epoch: 3136 [512/60000 (1%)] Loss: -1426.178955\n",
      "Train Epoch: 3136 [11776/60000 (20%)] Loss: -1473.527832\n",
      "Train Epoch: 3136 [23040/60000 (38%)] Loss: -1571.946045\n",
      "Train Epoch: 3136 [34304/60000 (57%)] Loss: -1513.079956\n",
      "Train Epoch: 3136 [45568/60000 (76%)] Loss: -1476.533569\n",
      "Train Epoch: 3136 [56832/60000 (95%)] Loss: -1483.722412\n",
      "    epoch          : 3136\n",
      "    loss           : -1491.771941966256\n",
      "Train Epoch: 3137 [512/60000 (1%)] Loss: -1584.138672\n",
      "Train Epoch: 3137 [11776/60000 (20%)] Loss: -1481.317261\n",
      "Train Epoch: 3137 [23040/60000 (38%)] Loss: -1482.498291\n",
      "Train Epoch: 3137 [34304/60000 (57%)] Loss: -1422.443848\n",
      "Train Epoch: 3137 [45568/60000 (76%)] Loss: -1480.451050\n",
      "Train Epoch: 3137 [56832/60000 (95%)] Loss: -1551.844116\n",
      "    epoch          : 3137\n",
      "    loss           : -1499.6148019564355\n",
      "Train Epoch: 3138 [512/60000 (1%)] Loss: -1561.197510\n",
      "Train Epoch: 3138 [11776/60000 (20%)] Loss: -1572.224854\n",
      "Train Epoch: 3138 [23040/60000 (38%)] Loss: -1563.140137\n",
      "Train Epoch: 3138 [34304/60000 (57%)] Loss: -1568.318848\n",
      "Train Epoch: 3138 [45568/60000 (76%)] Loss: -1471.291992\n",
      "Train Epoch: 3138 [56832/60000 (95%)] Loss: -1517.784790\n",
      "    epoch          : 3138\n",
      "    loss           : -1504.0270137463585\n",
      "Train Epoch: 3139 [512/60000 (1%)] Loss: -1558.285034\n",
      "Train Epoch: 3139 [11776/60000 (20%)] Loss: -1528.772949\n",
      "Train Epoch: 3139 [23040/60000 (38%)] Loss: -1579.127930\n",
      "Train Epoch: 3139 [34304/60000 (57%)] Loss: -1531.550781\n",
      "Train Epoch: 3139 [45568/60000 (76%)] Loss: -1419.672852\n",
      "Train Epoch: 3139 [56832/60000 (95%)] Loss: -1518.082642\n",
      "    epoch          : 3139\n",
      "    loss           : -1504.8962133375264\n",
      "Train Epoch: 3140 [512/60000 (1%)] Loss: -1489.958252\n",
      "Train Epoch: 3140 [11776/60000 (20%)] Loss: -1559.639893\n",
      "Train Epoch: 3140 [23040/60000 (38%)] Loss: -1432.618896\n",
      "Train Epoch: 3140 [34304/60000 (57%)] Loss: -1504.577393\n",
      "Train Epoch: 3140 [45568/60000 (76%)] Loss: -1610.360840\n",
      "Train Epoch: 3140 [56832/60000 (95%)] Loss: -1557.547607\n",
      "    epoch          : 3140\n",
      "    loss           : -1500.5626686225503\n",
      "Train Epoch: 3141 [512/60000 (1%)] Loss: -1552.841064\n",
      "Train Epoch: 3141 [11776/60000 (20%)] Loss: -1455.992432\n",
      "Train Epoch: 3141 [23040/60000 (38%)] Loss: -1437.474854\n",
      "Train Epoch: 3141 [34304/60000 (57%)] Loss: -1504.861938\n",
      "Train Epoch: 3141 [45568/60000 (76%)] Loss: -1512.676270\n",
      "Train Epoch: 3141 [56832/60000 (95%)] Loss: -1518.707031\n",
      "    epoch          : 3141\n",
      "    loss           : -1508.380735925362\n",
      "Train Epoch: 3142 [512/60000 (1%)] Loss: -1535.312134\n",
      "Train Epoch: 3142 [11776/60000 (20%)] Loss: -1587.279419\n",
      "Train Epoch: 3142 [23040/60000 (38%)] Loss: -1509.343750\n",
      "Train Epoch: 3142 [34304/60000 (57%)] Loss: -1437.110718\n",
      "Train Epoch: 3142 [45568/60000 (76%)] Loss: -1487.821899\n",
      "Train Epoch: 3142 [56832/60000 (95%)] Loss: -1437.749512\n",
      "    epoch          : 3142\n",
      "    loss           : -1499.8842142396054\n",
      "Train Epoch: 3143 [512/60000 (1%)] Loss: -1516.989990\n",
      "Train Epoch: 3143 [11776/60000 (20%)] Loss: -1532.315308\n",
      "Train Epoch: 3143 [23040/60000 (38%)] Loss: -1510.130127\n",
      "Train Epoch: 3143 [34304/60000 (57%)] Loss: -1512.295654\n",
      "Train Epoch: 3143 [45568/60000 (76%)] Loss: -1405.465576\n",
      "Train Epoch: 3143 [56832/60000 (95%)] Loss: -1493.781982\n",
      "    epoch          : 3143\n",
      "    loss           : -1500.5623075840838\n",
      "Train Epoch: 3144 [512/60000 (1%)] Loss: -1515.573486\n",
      "Train Epoch: 3144 [11776/60000 (20%)] Loss: -1569.843262\n",
      "Train Epoch: 3144 [23040/60000 (38%)] Loss: -1480.982788\n",
      "Train Epoch: 3144 [34304/60000 (57%)] Loss: -1409.560791\n",
      "Train Epoch: 3144 [45568/60000 (76%)] Loss: -1511.610229\n",
      "Train Epoch: 3144 [56832/60000 (95%)] Loss: -1521.510376\n",
      "    epoch          : 3144\n",
      "    loss           : -1495.9920274982344\n",
      "Train Epoch: 3145 [512/60000 (1%)] Loss: -1549.917969\n",
      "Train Epoch: 3145 [11776/60000 (20%)] Loss: -1496.117676\n",
      "Train Epoch: 3145 [23040/60000 (38%)] Loss: -1397.486816\n",
      "Train Epoch: 3145 [34304/60000 (57%)] Loss: -1583.210938\n",
      "Train Epoch: 3145 [45568/60000 (76%)] Loss: -1453.190430\n",
      "Train Epoch: 3145 [56832/60000 (95%)] Loss: -1439.986084\n",
      "    epoch          : 3145\n",
      "    loss           : -1485.7169899805792\n",
      "Train Epoch: 3146 [512/60000 (1%)] Loss: -1525.369385\n",
      "Train Epoch: 3146 [11776/60000 (20%)] Loss: -1603.220947\n",
      "Train Epoch: 3146 [23040/60000 (38%)] Loss: -1522.144897\n",
      "Train Epoch: 3146 [34304/60000 (57%)] Loss: -1424.207886\n",
      "Train Epoch: 3146 [45568/60000 (76%)] Loss: -1530.094482\n",
      "Train Epoch: 3146 [56832/60000 (95%)] Loss: -1461.248779\n",
      "    epoch          : 3146\n",
      "    loss           : -1505.4566777978239\n",
      "Train Epoch: 3147 [512/60000 (1%)] Loss: -1534.331299\n",
      "Train Epoch: 3147 [11776/60000 (20%)] Loss: -1512.926270\n",
      "Train Epoch: 3147 [23040/60000 (38%)] Loss: -1443.237793\n",
      "Train Epoch: 3147 [34304/60000 (57%)] Loss: -1543.898193\n",
      "Train Epoch: 3147 [45568/60000 (76%)] Loss: -1435.029297\n",
      "Train Epoch: 3147 [56832/60000 (95%)] Loss: -1545.486450\n",
      "    epoch          : 3147\n",
      "    loss           : -1498.1237806762006\n",
      "Train Epoch: 3148 [512/60000 (1%)] Loss: -1559.924805\n",
      "Train Epoch: 3148 [11776/60000 (20%)] Loss: -1515.930298\n",
      "Train Epoch: 3148 [23040/60000 (38%)] Loss: -1418.967041\n",
      "Train Epoch: 3148 [34304/60000 (57%)] Loss: -1454.821167\n",
      "Train Epoch: 3148 [45568/60000 (76%)] Loss: -1519.047119\n",
      "Train Epoch: 3148 [56832/60000 (95%)] Loss: -1554.504150\n",
      "    epoch          : 3148\n",
      "    loss           : -1489.1959025065103\n",
      "Train Epoch: 3149 [512/60000 (1%)] Loss: -1575.553345\n",
      "Train Epoch: 3149 [11776/60000 (20%)] Loss: -1543.795410\n",
      "Train Epoch: 3149 [23040/60000 (38%)] Loss: -1572.694702\n",
      "Train Epoch: 3149 [34304/60000 (57%)] Loss: -1508.305908\n",
      "Train Epoch: 3149 [45568/60000 (76%)] Loss: -1453.911377\n",
      "Train Epoch: 3149 [56832/60000 (95%)] Loss: -1455.436523\n",
      "    epoch          : 3149\n",
      "    loss           : -1495.9580205712614\n",
      "Train Epoch: 3150 [512/60000 (1%)] Loss: -1487.858398\n",
      "Train Epoch: 3150 [11776/60000 (20%)] Loss: -1461.646606\n",
      "Train Epoch: 3150 [23040/60000 (38%)] Loss: -1505.267090\n",
      "Train Epoch: 3150 [34304/60000 (57%)] Loss: -1510.604004\n",
      "Train Epoch: 3150 [45568/60000 (76%)] Loss: -1527.240112\n",
      "Train Epoch: 3150 [56832/60000 (95%)] Loss: -1569.754272\n",
      "    epoch          : 3150\n",
      "    loss           : -1502.504852812169\n",
      "Train Epoch: 3151 [512/60000 (1%)] Loss: -1488.659058\n",
      "Train Epoch: 3151 [11776/60000 (20%)] Loss: -1525.835083\n",
      "Train Epoch: 3151 [23040/60000 (38%)] Loss: -1586.081177\n",
      "Train Epoch: 3151 [34304/60000 (57%)] Loss: -1467.553467\n",
      "Train Epoch: 3151 [45568/60000 (76%)] Loss: -1472.425781\n",
      "Train Epoch: 3151 [56832/60000 (95%)] Loss: -1502.338745\n",
      "    epoch          : 3151\n",
      "    loss           : -1503.5018789862509\n",
      "Train Epoch: 3152 [512/60000 (1%)] Loss: -1471.367920\n",
      "Train Epoch: 3152 [11776/60000 (20%)] Loss: -1507.307129\n",
      "Train Epoch: 3152 [23040/60000 (38%)] Loss: -1524.675903\n",
      "Train Epoch: 3152 [34304/60000 (57%)] Loss: -1474.638062\n",
      "Train Epoch: 3152 [45568/60000 (76%)] Loss: -1519.443115\n",
      "Train Epoch: 3152 [56832/60000 (95%)] Loss: -1533.663086\n",
      "    epoch          : 3152\n",
      "    loss           : -1505.3669406007239\n",
      "Train Epoch: 3153 [512/60000 (1%)] Loss: -1438.902466\n",
      "Train Epoch: 3153 [11776/60000 (20%)] Loss: -1568.403198\n",
      "Train Epoch: 3153 [23040/60000 (38%)] Loss: -1472.806641\n",
      "Train Epoch: 3153 [34304/60000 (57%)] Loss: -1503.968872\n",
      "Train Epoch: 3153 [45568/60000 (76%)] Loss: -1538.478882\n",
      "Train Epoch: 3153 [56832/60000 (95%)] Loss: -1560.328369\n",
      "    epoch          : 3153\n",
      "    loss           : -1500.0585016800185\n",
      "Train Epoch: 3154 [512/60000 (1%)] Loss: -1465.206787\n",
      "Train Epoch: 3154 [11776/60000 (20%)] Loss: -1541.139893\n",
      "Train Epoch: 3154 [23040/60000 (38%)] Loss: -1592.279297\n",
      "Train Epoch: 3154 [34304/60000 (57%)] Loss: -1445.954102\n",
      "Train Epoch: 3154 [45568/60000 (76%)] Loss: -1598.302246\n",
      "Train Epoch: 3154 [56832/60000 (95%)] Loss: -1512.008789\n",
      "    epoch          : 3154\n",
      "    loss           : -1503.344156211379\n",
      "Train Epoch: 3155 [512/60000 (1%)] Loss: -1355.653320\n",
      "Train Epoch: 3155 [11776/60000 (20%)] Loss: -1532.425049\n",
      "Train Epoch: 3155 [23040/60000 (38%)] Loss: -1417.496826\n",
      "Train Epoch: 3155 [34304/60000 (57%)] Loss: -1545.240723\n",
      "Train Epoch: 3155 [45568/60000 (76%)] Loss: -1511.253662\n",
      "Train Epoch: 3155 [56832/60000 (95%)] Loss: -1561.911621\n",
      "    epoch          : 3155\n",
      "    loss           : -1496.3711265089823\n",
      "Train Epoch: 3156 [512/60000 (1%)] Loss: -1381.739502\n",
      "Train Epoch: 3156 [11776/60000 (20%)] Loss: -1565.898560\n",
      "Train Epoch: 3156 [23040/60000 (38%)] Loss: -1570.191650\n",
      "Train Epoch: 3156 [34304/60000 (57%)] Loss: -1519.653564\n",
      "Train Epoch: 3156 [45568/60000 (76%)] Loss: -1400.537842\n",
      "Train Epoch: 3156 [56832/60000 (95%)] Loss: -1509.573608\n",
      "    epoch          : 3156\n",
      "    loss           : -1504.385482184631\n",
      "Train Epoch: 3157 [512/60000 (1%)] Loss: -1465.185303\n",
      "Train Epoch: 3157 [11776/60000 (20%)] Loss: -1454.156372\n",
      "Train Epoch: 3157 [23040/60000 (38%)] Loss: -1492.753418\n",
      "Train Epoch: 3157 [34304/60000 (57%)] Loss: -1555.818359\n",
      "Train Epoch: 3157 [45568/60000 (76%)] Loss: -1505.520874\n",
      "Train Epoch: 3157 [56832/60000 (95%)] Loss: -1517.684570\n",
      "    epoch          : 3157\n",
      "    loss           : -1497.1561158605887\n",
      "Train Epoch: 3158 [512/60000 (1%)] Loss: -1469.295044\n",
      "Train Epoch: 3158 [11776/60000 (20%)] Loss: -1508.477051\n",
      "Train Epoch: 3158 [23040/60000 (38%)] Loss: -1568.039795\n",
      "Train Epoch: 3158 [34304/60000 (57%)] Loss: -1503.046143\n",
      "Train Epoch: 3158 [45568/60000 (76%)] Loss: -1512.254883\n",
      "Train Epoch: 3158 [56832/60000 (95%)] Loss: -1485.060791\n",
      "    epoch          : 3158\n",
      "    loss           : -1505.47884286999\n",
      "Train Epoch: 3159 [512/60000 (1%)] Loss: -1399.046021\n",
      "Train Epoch: 3159 [11776/60000 (20%)] Loss: -1465.743164\n",
      "Train Epoch: 3159 [23040/60000 (38%)] Loss: -1521.439697\n",
      "Train Epoch: 3159 [34304/60000 (57%)] Loss: -1506.457153\n",
      "Train Epoch: 3159 [45568/60000 (76%)] Loss: -1548.046143\n",
      "Train Epoch: 3159 [56832/60000 (95%)] Loss: -1390.993774\n",
      "    epoch          : 3159\n",
      "    loss           : -1504.3224866619219\n",
      "Train Epoch: 3160 [512/60000 (1%)] Loss: -1585.816650\n",
      "Train Epoch: 3160 [11776/60000 (20%)] Loss: -1557.337402\n",
      "Train Epoch: 3160 [23040/60000 (38%)] Loss: -1516.692749\n",
      "Train Epoch: 3160 [34304/60000 (57%)] Loss: -1569.215820\n",
      "Train Epoch: 3160 [45568/60000 (76%)] Loss: -1523.370605\n",
      "Train Epoch: 3160 [56832/60000 (95%)] Loss: -1480.907715\n",
      "    epoch          : 3160\n",
      "    loss           : -1505.997024449925\n",
      "Train Epoch: 3161 [512/60000 (1%)] Loss: -1570.676392\n",
      "Train Epoch: 3161 [11776/60000 (20%)] Loss: -1521.385254\n",
      "Train Epoch: 3161 [23040/60000 (38%)] Loss: -1472.522095\n",
      "Train Epoch: 3161 [34304/60000 (57%)] Loss: -1456.692871\n",
      "Train Epoch: 3161 [45568/60000 (76%)] Loss: -1447.255615\n",
      "Train Epoch: 3161 [56832/60000 (95%)] Loss: -1423.602295\n",
      "    epoch          : 3161\n",
      "    loss           : -1507.2960725773526\n",
      "Train Epoch: 3162 [512/60000 (1%)] Loss: -1552.243408\n",
      "Train Epoch: 3162 [11776/60000 (20%)] Loss: -1494.588867\n",
      "Train Epoch: 3162 [23040/60000 (38%)] Loss: -1458.044800\n",
      "Train Epoch: 3162 [34304/60000 (57%)] Loss: -1412.383423\n",
      "Train Epoch: 3162 [45568/60000 (76%)] Loss: -1448.299072\n",
      "Train Epoch: 3162 [56832/60000 (95%)] Loss: -1553.733765\n",
      "    epoch          : 3162\n",
      "    loss           : -1497.1940459343\n",
      "Train Epoch: 3163 [512/60000 (1%)] Loss: -1415.482422\n",
      "Train Epoch: 3163 [11776/60000 (20%)] Loss: -1514.575439\n",
      "Train Epoch: 3163 [23040/60000 (38%)] Loss: -1528.029785\n",
      "Train Epoch: 3163 [34304/60000 (57%)] Loss: -1550.016357\n",
      "Train Epoch: 3163 [45568/60000 (76%)] Loss: -1529.345337\n",
      "Train Epoch: 3163 [56832/60000 (95%)] Loss: -1532.452148\n",
      "    epoch          : 3163\n",
      "    loss           : -1503.5910527288577\n",
      "Train Epoch: 3164 [512/60000 (1%)] Loss: -1485.083496\n",
      "Train Epoch: 3164 [11776/60000 (20%)] Loss: -1452.313721\n",
      "Train Epoch: 3164 [23040/60000 (38%)] Loss: -1585.752197\n",
      "Train Epoch: 3164 [34304/60000 (57%)] Loss: -1526.741943\n",
      "Train Epoch: 3164 [45568/60000 (76%)] Loss: -1519.706909\n",
      "Train Epoch: 3164 [56832/60000 (95%)] Loss: -1502.855225\n",
      "    epoch          : 3164\n",
      "    loss           : -1501.994121314442\n",
      "Train Epoch: 3165 [512/60000 (1%)] Loss: -1503.513428\n",
      "Train Epoch: 3165 [11776/60000 (20%)] Loss: -1429.351318\n",
      "Train Epoch: 3165 [23040/60000 (38%)] Loss: -1446.119141\n",
      "Train Epoch: 3165 [34304/60000 (57%)] Loss: -1452.060059\n",
      "Train Epoch: 3165 [45568/60000 (76%)] Loss: -1532.678467\n",
      "Train Epoch: 3165 [56832/60000 (95%)] Loss: -1450.366577\n",
      "    epoch          : 3165\n",
      "    loss           : -1508.914549746756\n",
      "Train Epoch: 3166 [512/60000 (1%)] Loss: -1526.344482\n",
      "Train Epoch: 3166 [11776/60000 (20%)] Loss: -1518.714478\n",
      "Train Epoch: 3166 [23040/60000 (38%)] Loss: -1578.074463\n",
      "Train Epoch: 3166 [34304/60000 (57%)] Loss: -1488.854980\n",
      "Train Epoch: 3166 [45568/60000 (76%)] Loss: -1480.294312\n",
      "Train Epoch: 3166 [56832/60000 (95%)] Loss: -1466.646240\n",
      "    epoch          : 3166\n",
      "    loss           : -1510.8951457395392\n",
      "Train Epoch: 3167 [512/60000 (1%)] Loss: -1527.714600\n",
      "Train Epoch: 3167 [11776/60000 (20%)] Loss: -1472.200195\n",
      "Train Epoch: 3167 [23040/60000 (38%)] Loss: -1561.235840\n",
      "Train Epoch: 3167 [34304/60000 (57%)] Loss: -1572.100586\n",
      "Train Epoch: 3167 [45568/60000 (76%)] Loss: -1599.898193\n",
      "Train Epoch: 3167 [56832/60000 (95%)] Loss: -1497.805542\n",
      "    epoch          : 3167\n",
      "    loss           : -1497.78341381698\n",
      "Train Epoch: 3168 [512/60000 (1%)] Loss: -1572.637207\n",
      "Train Epoch: 3168 [11776/60000 (20%)] Loss: -1440.295776\n",
      "Train Epoch: 3168 [23040/60000 (38%)] Loss: -1429.963867\n",
      "Train Epoch: 3168 [34304/60000 (57%)] Loss: -1382.517334\n",
      "Train Epoch: 3168 [45568/60000 (76%)] Loss: -1558.697754\n",
      "Train Epoch: 3168 [56832/60000 (95%)] Loss: -1549.264771\n",
      "    epoch          : 3168\n",
      "    loss           : -1499.9782266562943\n",
      "Train Epoch: 3169 [512/60000 (1%)] Loss: -1565.456543\n",
      "Train Epoch: 3169 [11776/60000 (20%)] Loss: -1502.409546\n",
      "Train Epoch: 3169 [23040/60000 (38%)] Loss: -1590.710449\n",
      "Train Epoch: 3169 [34304/60000 (57%)] Loss: -1562.606445\n",
      "Train Epoch: 3169 [45568/60000 (76%)] Loss: -1508.630981\n",
      "Train Epoch: 3169 [56832/60000 (95%)] Loss: -1548.476562\n",
      "    epoch          : 3169\n",
      "    loss           : -1512.5823860815017\n",
      "Train Epoch: 3170 [512/60000 (1%)] Loss: -1502.439087\n",
      "Train Epoch: 3170 [11776/60000 (20%)] Loss: -1557.340698\n",
      "Train Epoch: 3170 [23040/60000 (38%)] Loss: -1419.150513\n",
      "Train Epoch: 3170 [34304/60000 (57%)] Loss: -1541.991821\n",
      "Train Epoch: 3170 [45568/60000 (76%)] Loss: -1511.808838\n",
      "Train Epoch: 3170 [56832/60000 (95%)] Loss: -1585.154541\n",
      "    epoch          : 3170\n",
      "    loss           : -1511.4932633739406\n",
      "Train Epoch: 3171 [512/60000 (1%)] Loss: -1571.746948\n",
      "Train Epoch: 3171 [11776/60000 (20%)] Loss: -1553.441650\n",
      "Train Epoch: 3171 [23040/60000 (38%)] Loss: -1471.886475\n",
      "Train Epoch: 3171 [34304/60000 (57%)] Loss: -1375.501709\n",
      "Train Epoch: 3171 [45568/60000 (76%)] Loss: -1477.859009\n",
      "Train Epoch: 3171 [56832/60000 (95%)] Loss: -1595.008057\n",
      "    epoch          : 3171\n",
      "    loss           : -1506.2674922619835\n",
      "Train Epoch: 3172 [512/60000 (1%)] Loss: -1456.253296\n",
      "Train Epoch: 3172 [11776/60000 (20%)] Loss: -1495.033447\n",
      "Train Epoch: 3172 [23040/60000 (38%)] Loss: -1512.848389\n",
      "Train Epoch: 3172 [34304/60000 (57%)] Loss: -1507.458496\n",
      "Train Epoch: 3172 [45568/60000 (76%)] Loss: -1562.379517\n",
      "Train Epoch: 3172 [56832/60000 (95%)] Loss: -1538.586426\n",
      "    epoch          : 3172\n",
      "    loss           : -1510.0337386481506\n",
      "Train Epoch: 3173 [512/60000 (1%)] Loss: -1432.736450\n",
      "Train Epoch: 3173 [11776/60000 (20%)] Loss: -1389.319946\n",
      "Train Epoch: 3173 [23040/60000 (38%)] Loss: -1562.991455\n",
      "Train Epoch: 3173 [34304/60000 (57%)] Loss: -1506.972168\n",
      "Train Epoch: 3173 [45568/60000 (76%)] Loss: -1520.637939\n",
      "Train Epoch: 3173 [56832/60000 (95%)] Loss: -1591.627930\n",
      "    epoch          : 3173\n",
      "    loss           : -1507.268830552613\n",
      "Train Epoch: 3174 [512/60000 (1%)] Loss: -1441.689209\n",
      "Train Epoch: 3174 [11776/60000 (20%)] Loss: -1488.383911\n",
      "Train Epoch: 3174 [23040/60000 (38%)] Loss: -1594.478394\n",
      "Train Epoch: 3174 [34304/60000 (57%)] Loss: -1528.088623\n",
      "Train Epoch: 3174 [45568/60000 (76%)] Loss: -1532.972656\n",
      "Train Epoch: 3174 [56832/60000 (95%)] Loss: -1553.730469\n",
      "    epoch          : 3174\n",
      "    loss           : -1507.9558533059674\n",
      "Train Epoch: 3175 [512/60000 (1%)] Loss: -1533.448242\n",
      "Train Epoch: 3175 [11776/60000 (20%)] Loss: -1412.001709\n",
      "Train Epoch: 3175 [23040/60000 (38%)] Loss: -1507.412720\n",
      "Train Epoch: 3175 [34304/60000 (57%)] Loss: -1545.319336\n",
      "Train Epoch: 3175 [45568/60000 (76%)] Loss: -1518.632446\n",
      "Train Epoch: 3175 [56832/60000 (95%)] Loss: -1511.928467\n",
      "    epoch          : 3175\n",
      "    loss           : -1500.1276500292417\n",
      "Train Epoch: 3176 [512/60000 (1%)] Loss: -1534.687744\n",
      "Train Epoch: 3176 [11776/60000 (20%)] Loss: -1520.341064\n",
      "Train Epoch: 3176 [23040/60000 (38%)] Loss: -1380.984131\n",
      "Train Epoch: 3176 [34304/60000 (57%)] Loss: -1575.319946\n",
      "Train Epoch: 3176 [45568/60000 (76%)] Loss: -1496.380127\n",
      "Train Epoch: 3176 [56832/60000 (95%)] Loss: -1580.745972\n",
      "    epoch          : 3176\n",
      "    loss           : -1503.3921036370057\n",
      "Train Epoch: 3177 [512/60000 (1%)] Loss: -1426.553345\n",
      "Train Epoch: 3177 [11776/60000 (20%)] Loss: -1385.384766\n",
      "Train Epoch: 3177 [23040/60000 (38%)] Loss: -1494.626465\n",
      "Train Epoch: 3177 [34304/60000 (57%)] Loss: -1405.136963\n",
      "Train Epoch: 3177 [45568/60000 (76%)] Loss: -1508.690308\n",
      "Train Epoch: 3177 [56832/60000 (95%)] Loss: -1476.130005\n",
      "    epoch          : 3177\n",
      "    loss           : -1507.4775528557557\n",
      "Train Epoch: 3178 [512/60000 (1%)] Loss: -1555.016357\n",
      "Train Epoch: 3178 [11776/60000 (20%)] Loss: -1488.232422\n",
      "Train Epoch: 3178 [23040/60000 (38%)] Loss: -1573.051636\n",
      "Train Epoch: 3178 [34304/60000 (57%)] Loss: -1483.336304\n",
      "Train Epoch: 3178 [45568/60000 (76%)] Loss: -1386.765625\n",
      "Train Epoch: 3178 [56832/60000 (95%)] Loss: -1556.973511\n",
      "    epoch          : 3178\n",
      "    loss           : -1499.9560964120983\n",
      "Train Epoch: 3179 [512/60000 (1%)] Loss: -1522.691650\n",
      "Train Epoch: 3179 [11776/60000 (20%)] Loss: -1582.081543\n",
      "Train Epoch: 3179 [23040/60000 (38%)] Loss: -1477.472656\n",
      "Train Epoch: 3179 [34304/60000 (57%)] Loss: -1526.869141\n",
      "Train Epoch: 3179 [45568/60000 (76%)] Loss: -1489.164429\n",
      "Train Epoch: 3179 [56832/60000 (95%)] Loss: -1379.968994\n",
      "    epoch          : 3179\n",
      "    loss           : -1500.6704194666975\n",
      "Train Epoch: 3180 [512/60000 (1%)] Loss: -1457.752808\n",
      "Train Epoch: 3180 [11776/60000 (20%)] Loss: -1540.553589\n",
      "Train Epoch: 3180 [23040/60000 (38%)] Loss: -1487.354736\n",
      "Train Epoch: 3180 [34304/60000 (57%)] Loss: -1487.215088\n",
      "Train Epoch: 3180 [45568/60000 (76%)] Loss: -1452.578613\n",
      "Train Epoch: 3180 [56832/60000 (95%)] Loss: -1424.754395\n",
      "    epoch          : 3180\n",
      "    loss           : -1497.7917090809276\n",
      "Train Epoch: 3181 [512/60000 (1%)] Loss: -1581.395264\n",
      "Train Epoch: 3181 [11776/60000 (20%)] Loss: -1575.311279\n",
      "Train Epoch: 3181 [23040/60000 (38%)] Loss: -1489.936523\n",
      "Train Epoch: 3181 [34304/60000 (57%)] Loss: -1495.214478\n",
      "Train Epoch: 3181 [45568/60000 (76%)] Loss: -1397.374756\n",
      "Train Epoch: 3181 [56832/60000 (95%)] Loss: -1433.881592\n",
      "    epoch          : 3181\n",
      "    loss           : -1498.1340687207583\n",
      "Train Epoch: 3182 [512/60000 (1%)] Loss: -1519.939087\n",
      "Train Epoch: 3182 [11776/60000 (20%)] Loss: -1532.297363\n",
      "Train Epoch: 3182 [23040/60000 (38%)] Loss: -1456.365112\n",
      "Train Epoch: 3182 [34304/60000 (57%)] Loss: -1516.377197\n",
      "Train Epoch: 3182 [45568/60000 (76%)] Loss: -1463.768921\n",
      "Train Epoch: 3182 [56832/60000 (95%)] Loss: -1538.517334\n",
      "    epoch          : 3182\n",
      "    loss           : -1510.8579711914062\n",
      "Train Epoch: 3183 [512/60000 (1%)] Loss: -1596.869995\n",
      "Train Epoch: 3183 [11776/60000 (20%)] Loss: -1545.116943\n",
      "Train Epoch: 3183 [23040/60000 (38%)] Loss: -1534.183838\n",
      "Train Epoch: 3183 [34304/60000 (57%)] Loss: -1461.851929\n",
      "Train Epoch: 3183 [45568/60000 (76%)] Loss: -1418.052734\n",
      "Train Epoch: 3183 [56832/60000 (95%)] Loss: -1524.339600\n",
      "    epoch          : 3183\n",
      "    loss           : -1502.1807202700168\n",
      "Train Epoch: 3184 [512/60000 (1%)] Loss: -1468.694824\n",
      "Train Epoch: 3184 [11776/60000 (20%)] Loss: -1499.403076\n",
      "Train Epoch: 3184 [23040/60000 (38%)] Loss: -1509.402222\n",
      "Train Epoch: 3184 [34304/60000 (57%)] Loss: -1550.059326\n",
      "Train Epoch: 3184 [45568/60000 (76%)] Loss: -1498.796143\n",
      "Train Epoch: 3184 [56832/60000 (95%)] Loss: -1467.665649\n",
      "    epoch          : 3184\n",
      "    loss           : -1509.276218220339\n",
      "Train Epoch: 3185 [512/60000 (1%)] Loss: -1460.816528\n",
      "Train Epoch: 3185 [11776/60000 (20%)] Loss: -1564.700439\n",
      "Train Epoch: 3185 [23040/60000 (38%)] Loss: -1533.791260\n",
      "Train Epoch: 3185 [34304/60000 (57%)] Loss: -1480.336426\n",
      "Train Epoch: 3185 [45568/60000 (76%)] Loss: -1437.963989\n",
      "Train Epoch: 3185 [56832/60000 (95%)] Loss: -1569.251465\n",
      "    epoch          : 3185\n",
      "    loss           : -1504.44586767854\n",
      "Train Epoch: 3186 [512/60000 (1%)] Loss: -1489.255737\n",
      "Train Epoch: 3186 [11776/60000 (20%)] Loss: -1586.717529\n",
      "Train Epoch: 3186 [23040/60000 (38%)] Loss: -1470.265991\n",
      "Train Epoch: 3186 [34304/60000 (57%)] Loss: -1440.439819\n",
      "Train Epoch: 3186 [45568/60000 (76%)] Loss: -1471.640991\n",
      "Train Epoch: 3186 [56832/60000 (95%)] Loss: -1533.565918\n",
      "    epoch          : 3186\n",
      "    loss           : -1504.4135304251633\n",
      "Train Epoch: 3187 [512/60000 (1%)] Loss: -1580.116577\n",
      "Train Epoch: 3187 [11776/60000 (20%)] Loss: -1518.376221\n",
      "Train Epoch: 3187 [23040/60000 (38%)] Loss: -1497.636963\n",
      "Train Epoch: 3187 [34304/60000 (57%)] Loss: -1501.480835\n",
      "Train Epoch: 3187 [45568/60000 (76%)] Loss: -1517.476562\n",
      "Train Epoch: 3187 [56832/60000 (95%)] Loss: -1564.466187\n",
      "    epoch          : 3187\n",
      "    loss           : -1515.4983568784207\n",
      "Train Epoch: 3188 [512/60000 (1%)] Loss: -1483.195557\n",
      "Train Epoch: 3188 [11776/60000 (20%)] Loss: -1457.249023\n",
      "Train Epoch: 3188 [23040/60000 (38%)] Loss: -1540.287964\n",
      "Train Epoch: 3188 [34304/60000 (57%)] Loss: -1546.626587\n",
      "Train Epoch: 3188 [45568/60000 (76%)] Loss: -1485.437622\n",
      "Train Epoch: 3188 [56832/60000 (95%)] Loss: -1556.125000\n",
      "    epoch          : 3188\n",
      "    loss           : -1507.429533015537\n",
      "Train Epoch: 3189 [512/60000 (1%)] Loss: -1592.037598\n",
      "Train Epoch: 3189 [11776/60000 (20%)] Loss: -1440.970093\n",
      "Train Epoch: 3189 [23040/60000 (38%)] Loss: -1493.977661\n",
      "Train Epoch: 3189 [34304/60000 (57%)] Loss: -1561.467285\n",
      "Train Epoch: 3189 [45568/60000 (76%)] Loss: -1569.695679\n",
      "Train Epoch: 3189 [56832/60000 (95%)] Loss: -1475.696777\n",
      "    epoch          : 3189\n",
      "    loss           : -1505.8355571509753\n",
      "Train Epoch: 3190 [512/60000 (1%)] Loss: -1568.466797\n",
      "Train Epoch: 3190 [11776/60000 (20%)] Loss: -1543.985962\n",
      "Train Epoch: 3190 [23040/60000 (38%)] Loss: -1484.219727\n",
      "Train Epoch: 3190 [34304/60000 (57%)] Loss: -1508.833496\n",
      "Train Epoch: 3190 [45568/60000 (76%)] Loss: -1524.694336\n",
      "Train Epoch: 3190 [56832/60000 (95%)] Loss: -1524.726318\n",
      "    epoch          : 3190\n",
      "    loss           : -1502.3379599361097\n",
      "Train Epoch: 3191 [512/60000 (1%)] Loss: -1561.411377\n",
      "Train Epoch: 3191 [11776/60000 (20%)] Loss: -1528.878174\n",
      "Train Epoch: 3191 [23040/60000 (38%)] Loss: -1545.782227\n",
      "Train Epoch: 3191 [34304/60000 (57%)] Loss: -1432.694336\n",
      "Train Epoch: 3191 [45568/60000 (76%)] Loss: -1499.966797\n",
      "Train Epoch: 3191 [56832/60000 (95%)] Loss: -1569.534058\n",
      "    epoch          : 3191\n",
      "    loss           : -1506.3334871281338\n",
      "Train Epoch: 3192 [512/60000 (1%)] Loss: -1556.280640\n",
      "Train Epoch: 3192 [11776/60000 (20%)] Loss: -1596.217041\n",
      "Train Epoch: 3192 [23040/60000 (38%)] Loss: -1464.385742\n",
      "Train Epoch: 3192 [34304/60000 (57%)] Loss: -1562.541260\n",
      "Train Epoch: 3192 [45568/60000 (76%)] Loss: -1464.404053\n",
      "Train Epoch: 3192 [56832/60000 (95%)] Loss: -1508.391113\n",
      "    epoch          : 3192\n",
      "    loss           : -1512.7372964115466\n",
      "Train Epoch: 3193 [512/60000 (1%)] Loss: -1480.446411\n",
      "Train Epoch: 3193 [11776/60000 (20%)] Loss: -1451.986328\n",
      "Train Epoch: 3193 [23040/60000 (38%)] Loss: -1542.269897\n",
      "Train Epoch: 3193 [34304/60000 (57%)] Loss: -1509.223877\n",
      "Train Epoch: 3193 [45568/60000 (76%)] Loss: -1448.186157\n",
      "Train Epoch: 3193 [56832/60000 (95%)] Loss: -1503.248535\n",
      "    epoch          : 3193\n",
      "    loss           : -1510.3848852814929\n",
      "Train Epoch: 3194 [512/60000 (1%)] Loss: -1491.481934\n",
      "Train Epoch: 3194 [11776/60000 (20%)] Loss: -1600.030884\n",
      "Train Epoch: 3194 [23040/60000 (38%)] Loss: -1477.808105\n",
      "Train Epoch: 3194 [34304/60000 (57%)] Loss: -1419.149658\n",
      "Train Epoch: 3194 [45568/60000 (76%)] Loss: -1577.481201\n",
      "Train Epoch: 3194 [56832/60000 (95%)] Loss: -1399.740723\n",
      "    epoch          : 3194\n",
      "    loss           : -1502.5180298541227\n",
      "Train Epoch: 3195 [512/60000 (1%)] Loss: -1451.128662\n",
      "Train Epoch: 3195 [11776/60000 (20%)] Loss: -1480.289917\n",
      "Train Epoch: 3195 [23040/60000 (38%)] Loss: -1529.159790\n",
      "Train Epoch: 3195 [34304/60000 (57%)] Loss: -1525.443481\n",
      "Train Epoch: 3195 [45568/60000 (76%)] Loss: -1541.958008\n",
      "Train Epoch: 3195 [56832/60000 (95%)] Loss: -1421.605713\n",
      "    epoch          : 3195\n",
      "    loss           : -1498.6396029197563\n",
      "Train Epoch: 3196 [512/60000 (1%)] Loss: -1494.574463\n",
      "Train Epoch: 3196 [11776/60000 (20%)] Loss: -1510.383911\n",
      "Train Epoch: 3196 [23040/60000 (38%)] Loss: -1439.996582\n",
      "Train Epoch: 3196 [34304/60000 (57%)] Loss: -1442.972534\n",
      "Train Epoch: 3196 [45568/60000 (76%)] Loss: -1503.072998\n",
      "Train Epoch: 3196 [56832/60000 (95%)] Loss: -1463.001099\n",
      "    epoch          : 3196\n",
      "    loss           : -1500.3692637298066\n",
      "Train Epoch: 3197 [512/60000 (1%)] Loss: -1482.300537\n",
      "Train Epoch: 3197 [11776/60000 (20%)] Loss: -1539.920410\n",
      "Train Epoch: 3197 [23040/60000 (38%)] Loss: -1603.390991\n",
      "Train Epoch: 3197 [34304/60000 (57%)] Loss: -1469.333618\n",
      "Train Epoch: 3197 [45568/60000 (76%)] Loss: -1568.190918\n",
      "Train Epoch: 3197 [56832/60000 (95%)] Loss: -1481.545166\n",
      "    epoch          : 3197\n",
      "    loss           : -1506.207947122175\n",
      "Train Epoch: 3198 [512/60000 (1%)] Loss: -1461.703491\n",
      "Train Epoch: 3198 [11776/60000 (20%)] Loss: -1481.058105\n",
      "Train Epoch: 3198 [23040/60000 (38%)] Loss: -1563.268311\n",
      "Train Epoch: 3198 [34304/60000 (57%)] Loss: -1520.313354\n",
      "Train Epoch: 3198 [45568/60000 (76%)] Loss: -1529.919189\n",
      "Train Epoch: 3198 [56832/60000 (95%)] Loss: -1486.818115\n",
      "    epoch          : 3198\n",
      "    loss           : -1513.2629918674966\n",
      "Train Epoch: 3199 [512/60000 (1%)] Loss: -1501.486206\n",
      "Train Epoch: 3199 [11776/60000 (20%)] Loss: -1460.970581\n",
      "Train Epoch: 3199 [23040/60000 (38%)] Loss: -1555.757324\n",
      "Train Epoch: 3199 [34304/60000 (57%)] Loss: -1517.339844\n",
      "Train Epoch: 3199 [45568/60000 (76%)] Loss: -1535.009766\n",
      "Train Epoch: 3199 [56832/60000 (95%)] Loss: -1585.991943\n",
      "    epoch          : 3199\n",
      "    loss           : -1501.0209216101696\n",
      "Train Epoch: 3200 [512/60000 (1%)] Loss: -1548.459717\n",
      "Train Epoch: 3200 [11776/60000 (20%)] Loss: -1478.687134\n",
      "Train Epoch: 3200 [23040/60000 (38%)] Loss: -1516.821777\n",
      "Train Epoch: 3200 [34304/60000 (57%)] Loss: -1561.016724\n",
      "Train Epoch: 3200 [45568/60000 (76%)] Loss: -1511.652954\n",
      "Train Epoch: 3200 [56832/60000 (95%)] Loss: -1525.827881\n",
      "    epoch          : 3200\n",
      "    loss           : -1505.3944195246293\n",
      "Saving checkpoint: saved/models/Mnist_DeepGenerativeOperad/0127_111843/checkpoint-epoch3200.pth ...\n",
      "Train Epoch: 3201 [512/60000 (1%)] Loss: -1575.026611\n",
      "Train Epoch: 3201 [11776/60000 (20%)] Loss: -1419.308472\n",
      "Train Epoch: 3201 [23040/60000 (38%)] Loss: -1416.011597\n",
      "Train Epoch: 3201 [34304/60000 (57%)] Loss: -1554.448242\n",
      "Train Epoch: 3201 [45568/60000 (76%)] Loss: -1560.436523\n",
      "Train Epoch: 3201 [56832/60000 (95%)] Loss: -1495.229370\n",
      "    epoch          : 3201\n",
      "    loss           : -1501.8278836180261\n",
      "Train Epoch: 3202 [512/60000 (1%)] Loss: -1549.861206\n",
      "Train Epoch: 3202 [11776/60000 (20%)] Loss: -1564.556641\n",
      "Train Epoch: 3202 [23040/60000 (38%)] Loss: -1535.539062\n",
      "Train Epoch: 3202 [34304/60000 (57%)] Loss: -1424.018555\n",
      "Train Epoch: 3202 [45568/60000 (76%)] Loss: -1556.605713\n",
      "Train Epoch: 3202 [56832/60000 (95%)] Loss: -1514.398926\n",
      "    epoch          : 3202\n",
      "    loss           : -1502.1696708377472\n",
      "Train Epoch: 3203 [512/60000 (1%)] Loss: -1502.306152\n",
      "Train Epoch: 3203 [11776/60000 (20%)] Loss: -1444.599976\n",
      "Train Epoch: 3203 [23040/60000 (38%)] Loss: -1488.569946\n",
      "Train Epoch: 3203 [34304/60000 (57%)] Loss: -1522.759766\n",
      "Train Epoch: 3203 [45568/60000 (76%)] Loss: -1444.150024\n",
      "Train Epoch: 3203 [56832/60000 (95%)] Loss: -1563.473877\n",
      "    epoch          : 3203\n",
      "    loss           : -1509.5027055470955\n",
      "Train Epoch: 3204 [512/60000 (1%)] Loss: -1498.904785\n",
      "Train Epoch: 3204 [11776/60000 (20%)] Loss: -1573.590210\n",
      "Train Epoch: 3204 [23040/60000 (38%)] Loss: -1586.111328\n",
      "Train Epoch: 3204 [34304/60000 (57%)] Loss: -1591.711426\n",
      "Train Epoch: 3204 [45568/60000 (76%)] Loss: -1491.623535\n",
      "Train Epoch: 3204 [56832/60000 (95%)] Loss: -1490.195190\n",
      "    epoch          : 3204\n",
      "    loss           : -1514.431872351695\n",
      "Train Epoch: 3205 [512/60000 (1%)] Loss: -1510.149170\n",
      "Train Epoch: 3205 [11776/60000 (20%)] Loss: -1531.834229\n",
      "Train Epoch: 3205 [23040/60000 (38%)] Loss: -1526.249756\n",
      "Train Epoch: 3205 [34304/60000 (57%)] Loss: -1399.708130\n",
      "Train Epoch: 3205 [45568/60000 (76%)] Loss: -1582.919434\n",
      "Train Epoch: 3205 [56832/60000 (95%)] Loss: -1496.456787\n",
      "    epoch          : 3205\n",
      "    loss           : -1504.454791570114\n",
      "Train Epoch: 3206 [512/60000 (1%)] Loss: -1542.022705\n",
      "Train Epoch: 3206 [11776/60000 (20%)] Loss: -1508.333496\n",
      "Train Epoch: 3206 [23040/60000 (38%)] Loss: -1547.516602\n",
      "Train Epoch: 3206 [34304/60000 (57%)] Loss: -1358.805908\n",
      "Train Epoch: 3206 [45568/60000 (76%)] Loss: -1561.584961\n",
      "Train Epoch: 3206 [56832/60000 (95%)] Loss: -1486.841553\n",
      "    epoch          : 3206\n",
      "    loss           : -1509.1024663030764\n",
      "Train Epoch: 3207 [512/60000 (1%)] Loss: -1489.373901\n",
      "Train Epoch: 3207 [11776/60000 (20%)] Loss: -1438.522095\n",
      "Train Epoch: 3207 [23040/60000 (38%)] Loss: -1523.617920\n",
      "Train Epoch: 3207 [34304/60000 (57%)] Loss: -1488.376831\n",
      "Train Epoch: 3207 [45568/60000 (76%)] Loss: -1555.691162\n",
      "Train Epoch: 3207 [56832/60000 (95%)] Loss: -1537.142944\n",
      "    epoch          : 3207\n",
      "    loss           : -1504.45750711732\n",
      "Train Epoch: 3208 [512/60000 (1%)] Loss: -1440.194458\n",
      "Train Epoch: 3208 [11776/60000 (20%)] Loss: -1400.478516\n",
      "Train Epoch: 3208 [23040/60000 (38%)] Loss: -1524.424316\n",
      "Train Epoch: 3208 [34304/60000 (57%)] Loss: -1596.444336\n",
      "Train Epoch: 3208 [45568/60000 (76%)] Loss: -1498.553955\n",
      "Train Epoch: 3208 [56832/60000 (95%)] Loss: -1465.866211\n",
      "    epoch          : 3208\n",
      "    loss           : -1500.6355232195665\n",
      "Train Epoch: 3209 [512/60000 (1%)] Loss: -1504.241211\n",
      "Train Epoch: 3209 [11776/60000 (20%)] Loss: -1532.971069\n",
      "Train Epoch: 3209 [23040/60000 (38%)] Loss: -1529.884766\n",
      "Train Epoch: 3209 [34304/60000 (57%)] Loss: -1403.039917\n",
      "Train Epoch: 3209 [45568/60000 (76%)] Loss: -1445.255005\n",
      "Train Epoch: 3209 [56832/60000 (95%)] Loss: -1538.890137\n",
      "    epoch          : 3209\n",
      "    loss           : -1499.0383797338454\n",
      "Train Epoch: 3210 [512/60000 (1%)] Loss: -1533.989990\n",
      "Train Epoch: 3210 [11776/60000 (20%)] Loss: -1511.750610\n",
      "Train Epoch: 3210 [23040/60000 (38%)] Loss: -1556.369019\n",
      "Train Epoch: 3210 [34304/60000 (57%)] Loss: -1473.921753\n",
      "Train Epoch: 3210 [45568/60000 (76%)] Loss: -1511.707642\n",
      "Train Epoch: 3210 [56832/60000 (95%)] Loss: -1504.679932\n",
      "    epoch          : 3210\n",
      "    loss           : -1509.793880139367\n",
      "Train Epoch: 3211 [512/60000 (1%)] Loss: -1457.096436\n",
      "Train Epoch: 3211 [11776/60000 (20%)] Loss: -1483.111084\n",
      "Train Epoch: 3211 [23040/60000 (38%)] Loss: -1521.281250\n",
      "Train Epoch: 3211 [34304/60000 (57%)] Loss: -1487.322998\n",
      "Train Epoch: 3211 [45568/60000 (76%)] Loss: -1517.466309\n",
      "Train Epoch: 3211 [56832/60000 (95%)] Loss: -1508.617676\n",
      "    epoch          : 3211\n",
      "    loss           : -1507.7345750022068\n",
      "Train Epoch: 3212 [512/60000 (1%)] Loss: -1452.823242\n",
      "Train Epoch: 3212 [11776/60000 (20%)] Loss: -1578.175049\n",
      "Train Epoch: 3212 [23040/60000 (38%)] Loss: -1536.609009\n",
      "Train Epoch: 3212 [34304/60000 (57%)] Loss: -1494.334351\n",
      "Train Epoch: 3212 [45568/60000 (76%)] Loss: -1546.259399\n",
      "Train Epoch: 3212 [56832/60000 (95%)] Loss: -1532.581055\n",
      "    epoch          : 3212\n",
      "    loss           : -1509.650926492982\n",
      "Train Epoch: 3213 [512/60000 (1%)] Loss: -1533.373169\n",
      "Train Epoch: 3213 [11776/60000 (20%)] Loss: -1473.558716\n",
      "Train Epoch: 3213 [23040/60000 (38%)] Loss: -1458.077515\n",
      "Train Epoch: 3213 [34304/60000 (57%)] Loss: -1487.753418\n",
      "Train Epoch: 3213 [45568/60000 (76%)] Loss: -1468.753662\n",
      "Train Epoch: 3213 [56832/60000 (95%)] Loss: -1471.060791\n",
      "    epoch          : 3213\n",
      "    loss           : -1505.105663579736\n",
      "Train Epoch: 3214 [512/60000 (1%)] Loss: -1456.569092\n",
      "Train Epoch: 3214 [11776/60000 (20%)] Loss: -1473.695435\n",
      "Train Epoch: 3214 [23040/60000 (38%)] Loss: -1539.289551\n",
      "Train Epoch: 3214 [34304/60000 (57%)] Loss: -1490.564209\n",
      "Train Epoch: 3214 [45568/60000 (76%)] Loss: -1369.241089\n",
      "Train Epoch: 3214 [56832/60000 (95%)] Loss: -1511.295776\n",
      "    epoch          : 3214\n",
      "    loss           : -1507.1599083162296\n",
      "Train Epoch: 3215 [512/60000 (1%)] Loss: -1499.489746\n",
      "Train Epoch: 3215 [11776/60000 (20%)] Loss: -1501.898438\n",
      "Train Epoch: 3215 [23040/60000 (38%)] Loss: -1488.602539\n",
      "Train Epoch: 3215 [34304/60000 (57%)] Loss: -1401.928467\n",
      "Train Epoch: 3215 [45568/60000 (76%)] Loss: -1520.125732\n",
      "Train Epoch: 3215 [56832/60000 (95%)] Loss: -1532.805054\n",
      "    epoch          : 3215\n",
      "    loss           : -1500.428561970339\n",
      "Train Epoch: 3216 [512/60000 (1%)] Loss: -1486.460571\n",
      "Train Epoch: 3216 [11776/60000 (20%)] Loss: -1539.361938\n",
      "Train Epoch: 3216 [23040/60000 (38%)] Loss: -1487.765259\n",
      "Train Epoch: 3216 [34304/60000 (57%)] Loss: -1515.187012\n",
      "Train Epoch: 3216 [45568/60000 (76%)] Loss: -1513.854248\n",
      "Train Epoch: 3216 [56832/60000 (95%)] Loss: -1498.722656\n",
      "    epoch          : 3216\n",
      "    loss           : -1510.6168171510858\n",
      "Train Epoch: 3217 [512/60000 (1%)] Loss: -1440.124756\n",
      "Train Epoch: 3217 [11776/60000 (20%)] Loss: -1569.982910\n",
      "Train Epoch: 3217 [23040/60000 (38%)] Loss: -1457.189697\n",
      "Train Epoch: 3217 [34304/60000 (57%)] Loss: -1397.646484\n",
      "Train Epoch: 3217 [45568/60000 (76%)] Loss: -1432.551270\n",
      "Train Epoch: 3217 [56832/60000 (95%)] Loss: -1456.993286\n",
      "    epoch          : 3217\n",
      "    loss           : -1511.0735404666534\n",
      "Train Epoch: 3218 [512/60000 (1%)] Loss: -1424.918945\n",
      "Train Epoch: 3218 [11776/60000 (20%)] Loss: -1548.734375\n",
      "Train Epoch: 3218 [23040/60000 (38%)] Loss: -1455.499634\n",
      "Train Epoch: 3218 [34304/60000 (57%)] Loss: -1457.572266\n",
      "Train Epoch: 3218 [45568/60000 (76%)] Loss: -1586.615723\n",
      "Train Epoch: 3218 [56832/60000 (95%)] Loss: -1580.833740\n",
      "    epoch          : 3218\n",
      "    loss           : -1509.8350526626502\n",
      "Train Epoch: 3219 [512/60000 (1%)] Loss: -1478.405029\n",
      "Train Epoch: 3219 [11776/60000 (20%)] Loss: -1446.532471\n",
      "Train Epoch: 3219 [23040/60000 (38%)] Loss: -1550.037598\n",
      "Train Epoch: 3219 [34304/60000 (57%)] Loss: -1552.916992\n",
      "Train Epoch: 3219 [45568/60000 (76%)] Loss: -1483.739990\n",
      "Train Epoch: 3219 [56832/60000 (95%)] Loss: -1450.055908\n",
      "    epoch          : 3219\n",
      "    loss           : -1504.9394810563426\n",
      "Train Epoch: 3220 [512/60000 (1%)] Loss: -1528.494629\n",
      "Train Epoch: 3220 [11776/60000 (20%)] Loss: -1499.466309\n",
      "Train Epoch: 3220 [23040/60000 (38%)] Loss: -1503.269653\n",
      "Train Epoch: 3220 [34304/60000 (57%)] Loss: -1530.378784\n",
      "Train Epoch: 3220 [45568/60000 (76%)] Loss: -1406.123779\n",
      "Train Epoch: 3220 [56832/60000 (95%)] Loss: -1529.071533\n",
      "    epoch          : 3220\n",
      "    loss           : -1500.4834843005165\n",
      "Train Epoch: 3221 [512/60000 (1%)] Loss: -1455.449463\n",
      "Train Epoch: 3221 [11776/60000 (20%)] Loss: -1592.134155\n",
      "Train Epoch: 3221 [23040/60000 (38%)] Loss: -1461.141724\n",
      "Train Epoch: 3221 [34304/60000 (57%)] Loss: -1548.438843\n",
      "Train Epoch: 3221 [45568/60000 (76%)] Loss: -1498.553467\n",
      "Train Epoch: 3221 [56832/60000 (95%)] Loss: -1510.028687\n",
      "    epoch          : 3221\n",
      "    loss           : -1499.362024339579\n",
      "Train Epoch: 3222 [512/60000 (1%)] Loss: -1515.588135\n",
      "Train Epoch: 3222 [11776/60000 (20%)] Loss: -1375.438599\n",
      "Train Epoch: 3222 [23040/60000 (38%)] Loss: -1518.840820\n",
      "Train Epoch: 3222 [34304/60000 (57%)] Loss: -1427.814331\n",
      "Train Epoch: 3222 [45568/60000 (76%)] Loss: -1490.021240\n",
      "Train Epoch: 3222 [56832/60000 (95%)] Loss: -1492.366333\n",
      "    epoch          : 3222\n",
      "    loss           : -1507.4052820582847\n",
      "Train Epoch: 3223 [512/60000 (1%)] Loss: -1562.417358\n",
      "Train Epoch: 3223 [11776/60000 (20%)] Loss: -1516.869629\n",
      "Train Epoch: 3223 [23040/60000 (38%)] Loss: -1551.790039\n",
      "Train Epoch: 3223 [34304/60000 (57%)] Loss: -1586.149414\n",
      "Train Epoch: 3223 [45568/60000 (76%)] Loss: -1562.353882\n",
      "Train Epoch: 3223 [56832/60000 (95%)] Loss: -1545.234497\n",
      "    epoch          : 3223\n",
      "    loss           : -1514.4859905350681\n",
      "Train Epoch: 3224 [512/60000 (1%)] Loss: -1529.260986\n",
      "Train Epoch: 3224 [11776/60000 (20%)] Loss: -1550.462524\n",
      "Train Epoch: 3224 [23040/60000 (38%)] Loss: -1523.544800\n",
      "Train Epoch: 3224 [34304/60000 (57%)] Loss: -1475.785400\n",
      "Train Epoch: 3224 [45568/60000 (76%)] Loss: -1471.068848\n",
      "Train Epoch: 3224 [56832/60000 (95%)] Loss: -1473.841797\n",
      "    epoch          : 3224\n",
      "    loss           : -1511.620259947696\n",
      "Train Epoch: 3225 [512/60000 (1%)] Loss: -1418.508057\n",
      "Train Epoch: 3225 [11776/60000 (20%)] Loss: -1502.639526\n",
      "Train Epoch: 3225 [23040/60000 (38%)] Loss: -1522.206421\n",
      "Train Epoch: 3225 [34304/60000 (57%)] Loss: -1584.784912\n",
      "Train Epoch: 3225 [45568/60000 (76%)] Loss: -1536.476685\n",
      "Train Epoch: 3225 [56832/60000 (95%)] Loss: -1391.061768\n",
      "    epoch          : 3225\n",
      "    loss           : -1499.9687865521273\n",
      "Train Epoch: 3226 [512/60000 (1%)] Loss: -1510.043701\n",
      "Train Epoch: 3226 [11776/60000 (20%)] Loss: -1461.846313\n",
      "Train Epoch: 3226 [23040/60000 (38%)] Loss: -1533.073242\n",
      "Train Epoch: 3226 [34304/60000 (57%)] Loss: -1461.213867\n",
      "Train Epoch: 3226 [45568/60000 (76%)] Loss: -1588.557983\n",
      "Train Epoch: 3226 [56832/60000 (95%)] Loss: -1585.891846\n",
      "    epoch          : 3226\n",
      "    loss           : -1506.5840395480225\n",
      "Train Epoch: 3227 [512/60000 (1%)] Loss: -1460.404053\n",
      "Train Epoch: 3227 [11776/60000 (20%)] Loss: -1501.010010\n",
      "Train Epoch: 3227 [23040/60000 (38%)] Loss: -1557.375366\n",
      "Train Epoch: 3227 [34304/60000 (57%)] Loss: -1550.968750\n",
      "Train Epoch: 3227 [45568/60000 (76%)] Loss: -1515.643799\n",
      "Train Epoch: 3227 [56832/60000 (95%)] Loss: -1425.857300\n",
      "    epoch          : 3227\n",
      "    loss           : -1500.9086327849134\n",
      "Train Epoch: 3228 [512/60000 (1%)] Loss: -1505.447754\n",
      "Train Epoch: 3228 [11776/60000 (20%)] Loss: -1511.962402\n",
      "Train Epoch: 3228 [23040/60000 (38%)] Loss: -1478.169556\n",
      "Train Epoch: 3228 [34304/60000 (57%)] Loss: -1374.026123\n",
      "Train Epoch: 3228 [45568/60000 (76%)] Loss: -1531.308105\n",
      "Train Epoch: 3228 [56832/60000 (95%)] Loss: -1488.407593\n",
      "    epoch          : 3228\n",
      "    loss           : -1497.8682092354122\n",
      "Train Epoch: 3229 [512/60000 (1%)] Loss: -1534.069702\n",
      "Train Epoch: 3229 [11776/60000 (20%)] Loss: -1555.350220\n",
      "Train Epoch: 3229 [23040/60000 (38%)] Loss: -1546.675903\n",
      "Train Epoch: 3229 [34304/60000 (57%)] Loss: -1579.240479\n",
      "Train Epoch: 3229 [45568/60000 (76%)] Loss: -1543.462402\n",
      "Train Epoch: 3229 [56832/60000 (95%)] Loss: -1519.343140\n",
      "    epoch          : 3229\n",
      "    loss           : -1503.5411614886784\n",
      "Train Epoch: 3230 [512/60000 (1%)] Loss: -1514.885986\n",
      "Train Epoch: 3230 [11776/60000 (20%)] Loss: -1463.959717\n",
      "Train Epoch: 3230 [23040/60000 (38%)] Loss: -1453.826172\n",
      "Train Epoch: 3230 [34304/60000 (57%)] Loss: -1536.017212\n",
      "Train Epoch: 3230 [45568/60000 (76%)] Loss: -1466.059082\n",
      "Train Epoch: 3230 [56832/60000 (95%)] Loss: -1496.948975\n",
      "    epoch          : 3230\n",
      "    loss           : -1512.0914906647247\n",
      "Train Epoch: 3231 [512/60000 (1%)] Loss: -1429.504150\n",
      "Train Epoch: 3231 [11776/60000 (20%)] Loss: -1555.544434\n",
      "Train Epoch: 3231 [23040/60000 (38%)] Loss: -1447.299805\n",
      "Train Epoch: 3231 [34304/60000 (57%)] Loss: -1606.065186\n",
      "Train Epoch: 3231 [45568/60000 (76%)] Loss: -1530.690063\n",
      "Train Epoch: 3231 [56832/60000 (95%)] Loss: -1484.351440\n",
      "    epoch          : 3231\n",
      "    loss           : -1497.572442868335\n",
      "Train Epoch: 3232 [512/60000 (1%)] Loss: -1468.839233\n",
      "Train Epoch: 3232 [11776/60000 (20%)] Loss: -1546.118408\n",
      "Train Epoch: 3232 [23040/60000 (38%)] Loss: -1493.885010\n",
      "Train Epoch: 3232 [34304/60000 (57%)] Loss: -1509.747803\n",
      "Train Epoch: 3232 [45568/60000 (76%)] Loss: -1573.241821\n",
      "Train Epoch: 3232 [56832/60000 (95%)] Loss: -1450.884155\n",
      "    epoch          : 3232\n",
      "    loss           : -1504.3106044618423\n",
      "Train Epoch: 3233 [512/60000 (1%)] Loss: -1561.561401\n",
      "Train Epoch: 3233 [11776/60000 (20%)] Loss: -1458.109253\n",
      "Train Epoch: 3233 [23040/60000 (38%)] Loss: -1527.423218\n",
      "Train Epoch: 3233 [34304/60000 (57%)] Loss: -1445.429443\n",
      "Train Epoch: 3233 [45568/60000 (76%)] Loss: -1555.219482\n",
      "Train Epoch: 3233 [56832/60000 (95%)] Loss: -1484.243530\n",
      "    epoch          : 3233\n",
      "    loss           : -1505.9415307341321\n",
      "Train Epoch: 3234 [512/60000 (1%)] Loss: -1452.054443\n",
      "Train Epoch: 3234 [11776/60000 (20%)] Loss: -1512.102661\n",
      "Train Epoch: 3234 [23040/60000 (38%)] Loss: -1453.573486\n",
      "Train Epoch: 3234 [34304/60000 (57%)] Loss: -1486.363525\n",
      "Train Epoch: 3234 [45568/60000 (76%)] Loss: -1587.951050\n",
      "Train Epoch: 3234 [56832/60000 (95%)] Loss: -1478.228149\n",
      "    epoch          : 3234\n",
      "    loss           : -1500.9892040188029\n",
      "Train Epoch: 3235 [512/60000 (1%)] Loss: -1493.213989\n",
      "Train Epoch: 3235 [11776/60000 (20%)] Loss: -1423.729736\n",
      "Train Epoch: 3235 [23040/60000 (38%)] Loss: -1550.733276\n",
      "Train Epoch: 3235 [34304/60000 (57%)] Loss: -1506.814697\n",
      "Train Epoch: 3235 [45568/60000 (76%)] Loss: -1517.768799\n",
      "Train Epoch: 3235 [56832/60000 (95%)] Loss: -1558.964844\n",
      "    epoch          : 3235\n",
      "    loss           : -1516.2189603471486\n",
      "Train Epoch: 3236 [512/60000 (1%)] Loss: -1382.235352\n",
      "Train Epoch: 3236 [11776/60000 (20%)] Loss: -1456.896729\n",
      "Train Epoch: 3236 [23040/60000 (38%)] Loss: -1571.639404\n",
      "Train Epoch: 3236 [34304/60000 (57%)] Loss: -1433.871826\n",
      "Train Epoch: 3236 [45568/60000 (76%)] Loss: -1469.030640\n",
      "Train Epoch: 3236 [56832/60000 (95%)] Loss: -1540.326416\n",
      "    epoch          : 3236\n",
      "    loss           : -1513.946305959238\n",
      "Train Epoch: 3237 [512/60000 (1%)] Loss: -1514.717041\n",
      "Train Epoch: 3237 [11776/60000 (20%)] Loss: -1500.733643\n",
      "Train Epoch: 3237 [23040/60000 (38%)] Loss: -1450.979858\n",
      "Train Epoch: 3237 [34304/60000 (57%)] Loss: -1547.981079\n",
      "Train Epoch: 3237 [45568/60000 (76%)] Loss: -1505.753296\n",
      "Train Epoch: 3237 [56832/60000 (95%)] Loss: -1571.778564\n",
      "    epoch          : 3237\n",
      "    loss           : -1506.4541650114759\n",
      "Train Epoch: 3238 [512/60000 (1%)] Loss: -1465.170410\n",
      "Train Epoch: 3238 [11776/60000 (20%)] Loss: -1535.258545\n",
      "Train Epoch: 3238 [23040/60000 (38%)] Loss: -1606.081055\n",
      "Train Epoch: 3238 [34304/60000 (57%)] Loss: -1482.682129\n",
      "Train Epoch: 3238 [45568/60000 (76%)] Loss: -1536.203613\n",
      "Train Epoch: 3238 [56832/60000 (95%)] Loss: -1508.950317\n",
      "    epoch          : 3238\n",
      "    loss           : -1515.4571046990864\n",
      "Train Epoch: 3239 [512/60000 (1%)] Loss: -1417.811401\n",
      "Train Epoch: 3239 [11776/60000 (20%)] Loss: -1380.026855\n",
      "Train Epoch: 3239 [23040/60000 (38%)] Loss: -1363.364136\n",
      "Train Epoch: 3239 [34304/60000 (57%)] Loss: -1389.566406\n",
      "Train Epoch: 3239 [45568/60000 (76%)] Loss: -1577.552368\n",
      "Train Epoch: 3239 [56832/60000 (95%)] Loss: -1502.114746\n",
      "    epoch          : 3239\n",
      "    loss           : -1510.0249582064355\n",
      "Train Epoch: 3240 [512/60000 (1%)] Loss: -1593.365234\n",
      "Train Epoch: 3240 [11776/60000 (20%)] Loss: -1549.441162\n",
      "Train Epoch: 3240 [23040/60000 (38%)] Loss: -1551.296753\n",
      "Train Epoch: 3240 [34304/60000 (57%)] Loss: -1494.619507\n",
      "Train Epoch: 3240 [45568/60000 (76%)] Loss: -1498.585083\n",
      "Train Epoch: 3240 [56832/60000 (95%)] Loss: -1541.907227\n",
      "    epoch          : 3240\n",
      "    loss           : -1514.3246211682335\n",
      "Train Epoch: 3241 [512/60000 (1%)] Loss: -1467.992920\n",
      "Train Epoch: 3241 [11776/60000 (20%)] Loss: -1478.651489\n",
      "Train Epoch: 3241 [23040/60000 (38%)] Loss: -1502.107910\n",
      "Train Epoch: 3241 [34304/60000 (57%)] Loss: -1440.511719\n",
      "Train Epoch: 3241 [45568/60000 (76%)] Loss: -1410.160645\n",
      "Train Epoch: 3241 [56832/60000 (95%)] Loss: -1469.461182\n",
      "    epoch          : 3241\n",
      "    loss           : -1502.7143071923551\n",
      "Train Epoch: 3242 [512/60000 (1%)] Loss: -1520.520386\n",
      "Train Epoch: 3242 [11776/60000 (20%)] Loss: -1554.300537\n",
      "Train Epoch: 3242 [23040/60000 (38%)] Loss: -1396.623047\n",
      "Train Epoch: 3242 [34304/60000 (57%)] Loss: -1493.784058\n",
      "Train Epoch: 3242 [45568/60000 (76%)] Loss: -1443.554932\n",
      "Train Epoch: 3242 [56832/60000 (95%)] Loss: -1488.619873\n",
      "    epoch          : 3242\n",
      "    loss           : -1503.9647020242983\n",
      "Train Epoch: 3243 [512/60000 (1%)] Loss: -1449.717285\n",
      "Train Epoch: 3243 [11776/60000 (20%)] Loss: -1446.295898\n",
      "Train Epoch: 3243 [23040/60000 (38%)] Loss: -1526.191650\n",
      "Train Epoch: 3243 [34304/60000 (57%)] Loss: -1499.119141\n",
      "Train Epoch: 3243 [45568/60000 (76%)] Loss: -1449.315186\n",
      "Train Epoch: 3243 [56832/60000 (95%)] Loss: -1512.575439\n",
      "    epoch          : 3243\n",
      "    loss           : -1507.1723187980006\n",
      "Train Epoch: 3244 [512/60000 (1%)] Loss: -1484.046631\n",
      "Train Epoch: 3244 [11776/60000 (20%)] Loss: -1567.635010\n",
      "Train Epoch: 3244 [23040/60000 (38%)] Loss: -1527.745117\n",
      "Train Epoch: 3244 [34304/60000 (57%)] Loss: -1485.616699\n",
      "Train Epoch: 3244 [45568/60000 (76%)] Loss: -1517.510010\n",
      "Train Epoch: 3244 [56832/60000 (95%)] Loss: -1535.749512\n",
      "    epoch          : 3244\n",
      "    loss           : -1494.2372584800935\n",
      "Train Epoch: 3245 [512/60000 (1%)] Loss: -1466.100342\n",
      "Train Epoch: 3245 [11776/60000 (20%)] Loss: -1438.330322\n",
      "Train Epoch: 3245 [23040/60000 (38%)] Loss: -1479.668945\n",
      "Train Epoch: 3245 [34304/60000 (57%)] Loss: -1472.225586\n",
      "Train Epoch: 3245 [45568/60000 (76%)] Loss: -1370.178955\n",
      "Train Epoch: 3245 [56832/60000 (95%)] Loss: -1438.944458\n",
      "    epoch          : 3245\n",
      "    loss           : -1502.4204929157838\n",
      "Train Epoch: 3246 [512/60000 (1%)] Loss: -1546.462280\n",
      "Train Epoch: 3246 [11776/60000 (20%)] Loss: -1506.703613\n",
      "Train Epoch: 3246 [23040/60000 (38%)] Loss: -1518.076660\n",
      "Train Epoch: 3246 [34304/60000 (57%)] Loss: -1491.447876\n",
      "Train Epoch: 3246 [45568/60000 (76%)] Loss: -1486.921875\n",
      "Train Epoch: 3246 [56832/60000 (95%)] Loss: -1581.580811\n",
      "    epoch          : 3246\n",
      "    loss           : -1506.1582396771273\n",
      "Train Epoch: 3247 [512/60000 (1%)] Loss: -1458.240967\n",
      "Train Epoch: 3247 [11776/60000 (20%)] Loss: -1425.384521\n",
      "Train Epoch: 3247 [23040/60000 (38%)] Loss: -1491.773926\n",
      "Train Epoch: 3247 [34304/60000 (57%)] Loss: -1530.131348\n",
      "Train Epoch: 3247 [45568/60000 (76%)] Loss: -1550.010742\n",
      "Train Epoch: 3247 [56832/60000 (95%)] Loss: -1604.220459\n",
      "    epoch          : 3247\n",
      "    loss           : -1504.382435254458\n",
      "Train Epoch: 3248 [512/60000 (1%)] Loss: -1513.985718\n",
      "Train Epoch: 3248 [11776/60000 (20%)] Loss: -1495.396118\n",
      "Train Epoch: 3248 [23040/60000 (38%)] Loss: -1599.927002\n",
      "Train Epoch: 3248 [34304/60000 (57%)] Loss: -1454.107788\n",
      "Train Epoch: 3248 [45568/60000 (76%)] Loss: -1499.836426\n",
      "Train Epoch: 3248 [56832/60000 (95%)] Loss: -1539.109009\n",
      "    epoch          : 3248\n",
      "    loss           : -1499.515702587063\n",
      "Train Epoch: 3249 [512/60000 (1%)] Loss: -1412.367432\n",
      "Train Epoch: 3249 [11776/60000 (20%)] Loss: -1587.213135\n",
      "Train Epoch: 3249 [23040/60000 (38%)] Loss: -1521.804077\n",
      "Train Epoch: 3249 [34304/60000 (57%)] Loss: -1584.112427\n",
      "Train Epoch: 3249 [45568/60000 (76%)] Loss: -1495.006592\n",
      "Train Epoch: 3249 [56832/60000 (95%)] Loss: -1561.698242\n",
      "    epoch          : 3249\n",
      "    loss           : -1506.048005012469\n",
      "Train Epoch: 3250 [512/60000 (1%)] Loss: -1572.846924\n",
      "Train Epoch: 3250 [11776/60000 (20%)] Loss: -1546.562500\n",
      "Train Epoch: 3250 [23040/60000 (38%)] Loss: -1509.486084\n",
      "Train Epoch: 3250 [34304/60000 (57%)] Loss: -1586.144409\n",
      "Train Epoch: 3250 [45568/60000 (76%)] Loss: -1538.439087\n",
      "Train Epoch: 3250 [56832/60000 (95%)] Loss: -1470.290283\n",
      "    epoch          : 3250\n",
      "    loss           : -1514.8170903954801\n",
      "Train Epoch: 3251 [512/60000 (1%)] Loss: -1495.573242\n",
      "Train Epoch: 3251 [11776/60000 (20%)] Loss: -1589.718994\n",
      "Train Epoch: 3251 [23040/60000 (38%)] Loss: -1407.734863\n",
      "Train Epoch: 3251 [34304/60000 (57%)] Loss: -1590.210938\n",
      "Train Epoch: 3251 [45568/60000 (76%)] Loss: -1508.502441\n",
      "Train Epoch: 3251 [56832/60000 (95%)] Loss: -1446.524170\n",
      "    epoch          : 3251\n",
      "    loss           : -1508.286503851077\n",
      "Train Epoch: 3252 [512/60000 (1%)] Loss: -1543.741333\n",
      "Train Epoch: 3252 [11776/60000 (20%)] Loss: -1502.633057\n",
      "Train Epoch: 3252 [23040/60000 (38%)] Loss: -1559.238892\n",
      "Train Epoch: 3252 [34304/60000 (57%)] Loss: -1556.747925\n",
      "Train Epoch: 3252 [45568/60000 (76%)] Loss: -1473.210449\n",
      "Train Epoch: 3252 [56832/60000 (95%)] Loss: -1466.578125\n",
      "    epoch          : 3252\n",
      "    loss           : -1498.221266234662\n",
      "Train Epoch: 3253 [512/60000 (1%)] Loss: -1457.140869\n",
      "Train Epoch: 3253 [11776/60000 (20%)] Loss: -1570.851807\n",
      "Train Epoch: 3253 [23040/60000 (38%)] Loss: -1508.389404\n",
      "Train Epoch: 3253 [34304/60000 (57%)] Loss: -1429.649414\n",
      "Train Epoch: 3253 [45568/60000 (76%)] Loss: -1457.498535\n",
      "Train Epoch: 3253 [56832/60000 (95%)] Loss: -1394.322876\n",
      "    epoch          : 3253\n",
      "    loss           : -1508.278986526748\n",
      "Train Epoch: 3254 [512/60000 (1%)] Loss: -1468.988281\n",
      "Train Epoch: 3254 [11776/60000 (20%)] Loss: -1488.210693\n",
      "Train Epoch: 3254 [23040/60000 (38%)] Loss: -1468.490967\n",
      "Train Epoch: 3254 [34304/60000 (57%)] Loss: -1550.117188\n",
      "Train Epoch: 3254 [45568/60000 (76%)] Loss: -1513.289307\n",
      "Train Epoch: 3254 [56832/60000 (95%)] Loss: -1479.636353\n",
      "    epoch          : 3254\n",
      "    loss           : -1499.2124240681276\n",
      "Train Epoch: 3255 [512/60000 (1%)] Loss: -1472.128296\n",
      "Train Epoch: 3255 [11776/60000 (20%)] Loss: -1453.411499\n",
      "Train Epoch: 3255 [23040/60000 (38%)] Loss: -1532.987305\n",
      "Train Epoch: 3255 [34304/60000 (57%)] Loss: -1522.821899\n",
      "Train Epoch: 3255 [45568/60000 (76%)] Loss: -1505.632690\n",
      "Train Epoch: 3255 [56832/60000 (95%)] Loss: -1524.715576\n",
      "    epoch          : 3255\n",
      "    loss           : -1513.8932557186838\n",
      "Train Epoch: 3256 [512/60000 (1%)] Loss: -1492.377197\n",
      "Train Epoch: 3256 [11776/60000 (20%)] Loss: -1578.495361\n",
      "Train Epoch: 3256 [23040/60000 (38%)] Loss: -1594.568115\n",
      "Train Epoch: 3256 [34304/60000 (57%)] Loss: -1536.014526\n",
      "Train Epoch: 3256 [45568/60000 (76%)] Loss: -1437.935913\n",
      "Train Epoch: 3256 [56832/60000 (95%)] Loss: -1452.209961\n",
      "    epoch          : 3256\n",
      "    loss           : -1504.9094010692531\n",
      "Train Epoch: 3257 [512/60000 (1%)] Loss: -1542.128906\n",
      "Train Epoch: 3257 [11776/60000 (20%)] Loss: -1583.372192\n",
      "Train Epoch: 3257 [23040/60000 (38%)] Loss: -1517.030762\n",
      "Train Epoch: 3257 [34304/60000 (57%)] Loss: -1570.895020\n",
      "Train Epoch: 3257 [45568/60000 (76%)] Loss: -1486.462524\n",
      "Train Epoch: 3257 [56832/60000 (95%)] Loss: -1442.659424\n",
      "    epoch          : 3257\n",
      "    loss           : -1507.429078527763\n",
      "Train Epoch: 3258 [512/60000 (1%)] Loss: -1526.325684\n",
      "Train Epoch: 3258 [11776/60000 (20%)] Loss: -1495.162354\n",
      "Train Epoch: 3258 [23040/60000 (38%)] Loss: -1454.930908\n",
      "Train Epoch: 3258 [34304/60000 (57%)] Loss: -1516.125977\n",
      "Train Epoch: 3258 [45568/60000 (76%)] Loss: -1562.128296\n",
      "Train Epoch: 3258 [56832/60000 (95%)] Loss: -1608.819336\n",
      "    epoch          : 3258\n",
      "    loss           : -1506.461707853328\n",
      "Train Epoch: 3259 [512/60000 (1%)] Loss: -1522.581665\n",
      "Train Epoch: 3259 [11776/60000 (20%)] Loss: -1586.651611\n",
      "Train Epoch: 3259 [23040/60000 (38%)] Loss: -1481.285034\n",
      "Train Epoch: 3259 [34304/60000 (57%)] Loss: -1557.731201\n",
      "Train Epoch: 3259 [45568/60000 (76%)] Loss: -1373.732788\n",
      "Train Epoch: 3259 [56832/60000 (95%)] Loss: -1493.938599\n",
      "    epoch          : 3259\n",
      "    loss           : -1499.5040821140096\n",
      "Train Epoch: 3260 [512/60000 (1%)] Loss: -1586.276367\n",
      "Train Epoch: 3260 [11776/60000 (20%)] Loss: -1412.836426\n",
      "Train Epoch: 3260 [23040/60000 (38%)] Loss: -1553.183838\n",
      "Train Epoch: 3260 [34304/60000 (57%)] Loss: -1391.987305\n",
      "Train Epoch: 3260 [45568/60000 (76%)] Loss: -1558.765503\n",
      "Train Epoch: 3260 [56832/60000 (95%)] Loss: -1603.240112\n",
      "    epoch          : 3260\n",
      "    loss           : -1504.2692164189398\n",
      "Train Epoch: 3261 [512/60000 (1%)] Loss: -1548.742554\n",
      "Train Epoch: 3261 [11776/60000 (20%)] Loss: -1454.050293\n",
      "Train Epoch: 3261 [23040/60000 (38%)] Loss: -1540.981445\n",
      "Train Epoch: 3261 [34304/60000 (57%)] Loss: -1494.973877\n",
      "Train Epoch: 3261 [45568/60000 (76%)] Loss: -1528.167236\n",
      "Train Epoch: 3261 [56832/60000 (95%)] Loss: -1461.117188\n",
      "    epoch          : 3261\n",
      "    loss           : -1507.4373965505827\n",
      "Train Epoch: 3262 [512/60000 (1%)] Loss: -1519.117188\n",
      "Train Epoch: 3262 [11776/60000 (20%)] Loss: -1492.995605\n",
      "Train Epoch: 3262 [23040/60000 (38%)] Loss: -1488.428345\n",
      "Train Epoch: 3262 [34304/60000 (57%)] Loss: -1530.971313\n",
      "Train Epoch: 3262 [45568/60000 (76%)] Loss: -1492.286255\n",
      "Train Epoch: 3262 [56832/60000 (95%)] Loss: -1454.639771\n",
      "    epoch          : 3262\n",
      "    loss           : -1498.1102808720648\n",
      "Train Epoch: 3263 [512/60000 (1%)] Loss: -1522.582397\n",
      "Train Epoch: 3263 [11776/60000 (20%)] Loss: -1428.916504\n",
      "Train Epoch: 3263 [23040/60000 (38%)] Loss: -1589.338623\n",
      "Train Epoch: 3263 [34304/60000 (57%)] Loss: -1561.770630\n",
      "Train Epoch: 3263 [45568/60000 (76%)] Loss: -1446.393921\n",
      "Train Epoch: 3263 [56832/60000 (95%)] Loss: -1470.208496\n",
      "    epoch          : 3263\n",
      "    loss           : -1503.554831984353\n",
      "Train Epoch: 3264 [512/60000 (1%)] Loss: -1505.718018\n",
      "Train Epoch: 3264 [11776/60000 (20%)] Loss: -1573.996582\n",
      "Train Epoch: 3264 [23040/60000 (38%)] Loss: -1512.432129\n",
      "Train Epoch: 3264 [34304/60000 (57%)] Loss: -1459.183350\n",
      "Train Epoch: 3264 [45568/60000 (76%)] Loss: -1478.271240\n",
      "Train Epoch: 3264 [56832/60000 (95%)] Loss: -1451.711670\n",
      "    epoch          : 3264\n",
      "    loss           : -1512.0360845361051\n",
      "Train Epoch: 3265 [512/60000 (1%)] Loss: -1558.261719\n",
      "Train Epoch: 3265 [11776/60000 (20%)] Loss: -1545.383057\n",
      "Train Epoch: 3265 [23040/60000 (38%)] Loss: -1454.592651\n",
      "Train Epoch: 3265 [34304/60000 (57%)] Loss: -1559.514160\n",
      "Train Epoch: 3265 [45568/60000 (76%)] Loss: -1415.938477\n",
      "Train Epoch: 3265 [56832/60000 (95%)] Loss: -1426.138306\n",
      "    epoch          : 3265\n",
      "    loss           : -1499.9972072105622\n",
      "Train Epoch: 3266 [512/60000 (1%)] Loss: -1422.486694\n",
      "Train Epoch: 3266 [11776/60000 (20%)] Loss: -1515.428589\n",
      "Train Epoch: 3266 [23040/60000 (38%)] Loss: -1477.052246\n",
      "Train Epoch: 3266 [34304/60000 (57%)] Loss: -1571.800293\n",
      "Train Epoch: 3266 [45568/60000 (76%)] Loss: -1435.432617\n",
      "Train Epoch: 3266 [56832/60000 (95%)] Loss: -1477.809326\n",
      "    epoch          : 3266\n",
      "    loss           : -1510.4586967856196\n",
      "Train Epoch: 3267 [512/60000 (1%)] Loss: -1517.090576\n",
      "Train Epoch: 3267 [11776/60000 (20%)] Loss: -1352.132690\n",
      "Train Epoch: 3267 [23040/60000 (38%)] Loss: -1541.573242\n",
      "Train Epoch: 3267 [34304/60000 (57%)] Loss: -1544.004150\n",
      "Train Epoch: 3267 [45568/60000 (76%)] Loss: -1468.230591\n",
      "Train Epoch: 3267 [56832/60000 (95%)] Loss: -1498.973022\n",
      "    epoch          : 3267\n",
      "    loss           : -1509.642708471266\n",
      "Train Epoch: 3268 [512/60000 (1%)] Loss: -1494.783569\n",
      "Train Epoch: 3268 [11776/60000 (20%)] Loss: -1533.079224\n",
      "Train Epoch: 3268 [23040/60000 (38%)] Loss: -1557.910156\n",
      "Train Epoch: 3268 [34304/60000 (57%)] Loss: -1554.783447\n",
      "Train Epoch: 3268 [45568/60000 (76%)] Loss: -1439.554932\n",
      "Train Epoch: 3268 [56832/60000 (95%)] Loss: -1410.243530\n",
      "    epoch          : 3268\n",
      "    loss           : -1498.5719856219102\n",
      "Train Epoch: 3269 [512/60000 (1%)] Loss: -1579.709229\n",
      "Train Epoch: 3269 [11776/60000 (20%)] Loss: -1510.541016\n",
      "Train Epoch: 3269 [23040/60000 (38%)] Loss: -1510.329102\n",
      "Train Epoch: 3269 [34304/60000 (57%)] Loss: -1415.400146\n",
      "Train Epoch: 3269 [45568/60000 (76%)] Loss: -1476.731812\n",
      "Train Epoch: 3269 [56832/60000 (95%)] Loss: -1576.508057\n",
      "    epoch          : 3269\n",
      "    loss           : -1511.423948815987\n",
      "Train Epoch: 3270 [512/60000 (1%)] Loss: -1478.714478\n",
      "Train Epoch: 3270 [11776/60000 (20%)] Loss: -1534.264404\n",
      "Train Epoch: 3270 [23040/60000 (38%)] Loss: -1487.055420\n",
      "Train Epoch: 3270 [34304/60000 (57%)] Loss: -1416.990601\n",
      "Train Epoch: 3270 [45568/60000 (76%)] Loss: -1592.709106\n",
      "Train Epoch: 3270 [56832/60000 (95%)] Loss: -1563.886230\n",
      "    epoch          : 3270\n",
      "    loss           : -1513.2563993809588\n",
      "Train Epoch: 3271 [512/60000 (1%)] Loss: -1561.778320\n",
      "Train Epoch: 3271 [11776/60000 (20%)] Loss: -1566.247070\n",
      "Train Epoch: 3271 [23040/60000 (38%)] Loss: -1529.568848\n",
      "Train Epoch: 3271 [34304/60000 (57%)] Loss: -1542.612671\n",
      "Train Epoch: 3271 [45568/60000 (76%)] Loss: -1511.549927\n",
      "Train Epoch: 3271 [56832/60000 (95%)] Loss: -1493.735229\n",
      "    epoch          : 3271\n",
      "    loss           : -1512.5425380555923\n",
      "Train Epoch: 3272 [512/60000 (1%)] Loss: -1530.448730\n",
      "Train Epoch: 3272 [11776/60000 (20%)] Loss: -1526.904785\n",
      "Train Epoch: 3272 [23040/60000 (38%)] Loss: -1578.295410\n",
      "Train Epoch: 3272 [34304/60000 (57%)] Loss: -1524.702515\n",
      "Train Epoch: 3272 [45568/60000 (76%)] Loss: -1423.706787\n",
      "Train Epoch: 3272 [56832/60000 (95%)] Loss: -1536.568848\n",
      "    epoch          : 3272\n",
      "    loss           : -1513.633019743666\n",
      "Train Epoch: 3273 [512/60000 (1%)] Loss: -1461.649780\n",
      "Train Epoch: 3273 [11776/60000 (20%)] Loss: -1419.285889\n",
      "Train Epoch: 3273 [23040/60000 (38%)] Loss: -1522.343506\n",
      "Train Epoch: 3273 [34304/60000 (57%)] Loss: -1538.486328\n",
      "Train Epoch: 3273 [45568/60000 (76%)] Loss: -1468.510986\n",
      "Train Epoch: 3273 [56832/60000 (95%)] Loss: -1364.852783\n",
      "    epoch          : 3273\n",
      "    loss           : -1512.4790983900511\n",
      "Train Epoch: 3274 [512/60000 (1%)] Loss: -1568.623047\n",
      "Train Epoch: 3274 [11776/60000 (20%)] Loss: -1586.330444\n",
      "Train Epoch: 3274 [23040/60000 (38%)] Loss: -1446.052124\n",
      "Train Epoch: 3274 [34304/60000 (57%)] Loss: -1484.987183\n",
      "Train Epoch: 3274 [45568/60000 (76%)] Loss: -1512.579346\n",
      "Train Epoch: 3274 [56832/60000 (95%)] Loss: -1601.745483\n",
      "    epoch          : 3274\n",
      "    loss           : -1510.0722804527497\n",
      "Train Epoch: 3275 [512/60000 (1%)] Loss: -1564.408569\n",
      "Train Epoch: 3275 [11776/60000 (20%)] Loss: -1540.679810\n",
      "Train Epoch: 3275 [23040/60000 (38%)] Loss: -1496.575439\n",
      "Train Epoch: 3275 [34304/60000 (57%)] Loss: -1530.216553\n",
      "Train Epoch: 3275 [45568/60000 (76%)] Loss: -1458.766235\n",
      "Train Epoch: 3275 [56832/60000 (95%)] Loss: -1590.355957\n",
      "    epoch          : 3275\n",
      "    loss           : -1508.6078049826756\n",
      "Train Epoch: 3276 [512/60000 (1%)] Loss: -1462.662598\n",
      "Train Epoch: 3276 [11776/60000 (20%)] Loss: -1511.344482\n",
      "Train Epoch: 3276 [23040/60000 (38%)] Loss: -1466.794312\n",
      "Train Epoch: 3276 [34304/60000 (57%)] Loss: -1530.584961\n",
      "Train Epoch: 3276 [45568/60000 (76%)] Loss: -1531.157349\n",
      "Train Epoch: 3276 [56832/60000 (95%)] Loss: -1496.064209\n",
      "    epoch          : 3276\n",
      "    loss           : -1508.7888273249912\n",
      "Train Epoch: 3277 [512/60000 (1%)] Loss: -1508.148682\n",
      "Train Epoch: 3277 [11776/60000 (20%)] Loss: -1532.802002\n",
      "Train Epoch: 3277 [23040/60000 (38%)] Loss: -1488.630249\n",
      "Train Epoch: 3277 [34304/60000 (57%)] Loss: -1554.707764\n",
      "Train Epoch: 3277 [45568/60000 (76%)] Loss: -1518.151978\n",
      "Train Epoch: 3277 [56832/60000 (95%)] Loss: -1376.118652\n",
      "    epoch          : 3277\n",
      "    loss           : -1520.318935933086\n",
      "Train Epoch: 3278 [512/60000 (1%)] Loss: -1554.076904\n",
      "Train Epoch: 3278 [11776/60000 (20%)] Loss: -1523.395874\n",
      "Train Epoch: 3278 [23040/60000 (38%)] Loss: -1535.310547\n",
      "Train Epoch: 3278 [34304/60000 (57%)] Loss: -1523.464600\n",
      "Train Epoch: 3278 [45568/60000 (76%)] Loss: -1464.750732\n",
      "Train Epoch: 3278 [56832/60000 (95%)] Loss: -1465.328857\n",
      "    epoch          : 3278\n",
      "    loss           : -1518.4247781354827\n",
      "Train Epoch: 3279 [512/60000 (1%)] Loss: -1471.948364\n",
      "Train Epoch: 3279 [11776/60000 (20%)] Loss: -1464.631348\n",
      "Train Epoch: 3279 [23040/60000 (38%)] Loss: -1443.450195\n",
      "Train Epoch: 3279 [34304/60000 (57%)] Loss: -1546.410889\n",
      "Train Epoch: 3279 [45568/60000 (76%)] Loss: -1517.299805\n",
      "Train Epoch: 3279 [56832/60000 (95%)] Loss: -1429.506836\n",
      "    epoch          : 3279\n",
      "    loss           : -1508.5663079730534\n",
      "Train Epoch: 3280 [512/60000 (1%)] Loss: -1432.612793\n",
      "Train Epoch: 3280 [11776/60000 (20%)] Loss: -1518.183350\n",
      "Train Epoch: 3280 [23040/60000 (38%)] Loss: -1564.677002\n",
      "Train Epoch: 3280 [34304/60000 (57%)] Loss: -1498.552856\n",
      "Train Epoch: 3280 [45568/60000 (76%)] Loss: -1472.300781\n",
      "Train Epoch: 3280 [56832/60000 (95%)] Loss: -1527.858887\n",
      "    epoch          : 3280\n",
      "    loss           : -1513.1533282436221\n",
      "Train Epoch: 3281 [512/60000 (1%)] Loss: -1458.016602\n",
      "Train Epoch: 3281 [11776/60000 (20%)] Loss: -1498.840942\n",
      "Train Epoch: 3281 [23040/60000 (38%)] Loss: -1372.837524\n",
      "Train Epoch: 3281 [34304/60000 (57%)] Loss: -1484.298462\n",
      "Train Epoch: 3281 [45568/60000 (76%)] Loss: -1502.352539\n",
      "Train Epoch: 3281 [56832/60000 (95%)] Loss: -1588.732788\n",
      "    epoch          : 3281\n",
      "    loss           : -1506.0720025186486\n",
      "Train Epoch: 3282 [512/60000 (1%)] Loss: -1541.776001\n",
      "Train Epoch: 3282 [11776/60000 (20%)] Loss: -1564.019775\n",
      "Train Epoch: 3282 [23040/60000 (38%)] Loss: -1475.297729\n",
      "Train Epoch: 3282 [34304/60000 (57%)] Loss: -1565.988525\n",
      "Train Epoch: 3282 [45568/60000 (76%)] Loss: -1507.843628\n",
      "Train Epoch: 3282 [56832/60000 (95%)] Loss: -1562.348877\n",
      "    epoch          : 3282\n",
      "    loss           : -1516.2322101485256\n",
      "Train Epoch: 3283 [512/60000 (1%)] Loss: -1539.765015\n",
      "Train Epoch: 3283 [11776/60000 (20%)] Loss: -1540.162354\n",
      "Train Epoch: 3283 [23040/60000 (38%)] Loss: -1560.380127\n",
      "Train Epoch: 3283 [34304/60000 (57%)] Loss: -1495.282593\n",
      "Train Epoch: 3283 [45568/60000 (76%)] Loss: -1536.810425\n",
      "Train Epoch: 3283 [56832/60000 (95%)] Loss: -1544.170044\n",
      "    epoch          : 3283\n",
      "    loss           : -1515.5670645331259\n",
      "Train Epoch: 3284 [512/60000 (1%)] Loss: -1562.061279\n",
      "Train Epoch: 3284 [11776/60000 (20%)] Loss: -1476.353760\n",
      "Train Epoch: 3284 [23040/60000 (38%)] Loss: -1543.841553\n",
      "Train Epoch: 3284 [34304/60000 (57%)] Loss: -1505.577026\n",
      "Train Epoch: 3284 [45568/60000 (76%)] Loss: -1534.419556\n",
      "Train Epoch: 3284 [56832/60000 (95%)] Loss: -1534.755981\n",
      "    epoch          : 3284\n",
      "    loss           : -1512.1070846298994\n",
      "Train Epoch: 3285 [512/60000 (1%)] Loss: -1578.603271\n",
      "Train Epoch: 3285 [11776/60000 (20%)] Loss: -1434.864990\n",
      "Train Epoch: 3285 [23040/60000 (38%)] Loss: -1383.374756\n",
      "Train Epoch: 3285 [34304/60000 (57%)] Loss: -1431.323975\n",
      "Train Epoch: 3285 [45568/60000 (76%)] Loss: -1491.709106\n",
      "Train Epoch: 3285 [56832/60000 (95%)] Loss: -1494.728760\n",
      "    epoch          : 3285\n",
      "    loss           : -1509.1827823617366\n",
      "Train Epoch: 3286 [512/60000 (1%)] Loss: -1571.939819\n",
      "Train Epoch: 3286 [11776/60000 (20%)] Loss: -1588.907227\n",
      "Train Epoch: 3286 [23040/60000 (38%)] Loss: -1536.473877\n",
      "Train Epoch: 3286 [34304/60000 (57%)] Loss: -1538.611328\n",
      "Train Epoch: 3286 [45568/60000 (76%)] Loss: -1583.087280\n",
      "Train Epoch: 3286 [56832/60000 (95%)] Loss: -1519.950317\n",
      "    epoch          : 3286\n",
      "    loss           : -1518.4466232041182\n",
      "Train Epoch: 3287 [512/60000 (1%)] Loss: -1560.074707\n",
      "Train Epoch: 3287 [11776/60000 (20%)] Loss: -1506.817993\n",
      "Train Epoch: 3287 [23040/60000 (38%)] Loss: -1497.080322\n",
      "Train Epoch: 3287 [34304/60000 (57%)] Loss: -1541.014893\n",
      "Train Epoch: 3287 [45568/60000 (76%)] Loss: -1503.032349\n",
      "Train Epoch: 3287 [56832/60000 (95%)] Loss: -1571.803955\n",
      "    epoch          : 3287\n",
      "    loss           : -1518.3852983894994\n",
      "Train Epoch: 3288 [512/60000 (1%)] Loss: -1532.197021\n",
      "Train Epoch: 3288 [11776/60000 (20%)] Loss: -1426.235840\n",
      "Train Epoch: 3288 [23040/60000 (38%)] Loss: -1480.610718\n",
      "Train Epoch: 3288 [34304/60000 (57%)] Loss: -1516.911377\n",
      "Train Epoch: 3288 [45568/60000 (76%)] Loss: -1594.796387\n",
      "Train Epoch: 3288 [56832/60000 (95%)] Loss: -1544.124023\n",
      "    epoch          : 3288\n",
      "    loss           : -1517.8321781481727\n",
      "Train Epoch: 3289 [512/60000 (1%)] Loss: -1519.074463\n",
      "Train Epoch: 3289 [11776/60000 (20%)] Loss: -1496.321167\n",
      "Train Epoch: 3289 [23040/60000 (38%)] Loss: -1500.480713\n",
      "Train Epoch: 3289 [34304/60000 (57%)] Loss: -1488.637451\n",
      "Train Epoch: 3289 [45568/60000 (76%)] Loss: -1498.031372\n",
      "Train Epoch: 3289 [56832/60000 (95%)] Loss: -1492.441895\n",
      "    epoch          : 3289\n",
      "    loss           : -1512.1484371551687\n",
      "Train Epoch: 3290 [512/60000 (1%)] Loss: -1493.670532\n",
      "Train Epoch: 3290 [11776/60000 (20%)] Loss: -1506.129883\n",
      "Train Epoch: 3290 [23040/60000 (38%)] Loss: -1515.698486\n",
      "Train Epoch: 3290 [34304/60000 (57%)] Loss: -1454.313965\n",
      "Train Epoch: 3290 [45568/60000 (76%)] Loss: -1539.796265\n",
      "Train Epoch: 3290 [56832/60000 (95%)] Loss: -1552.486084\n",
      "    epoch          : 3290\n",
      "    loss           : -1517.353990802657\n",
      "Train Epoch: 3291 [512/60000 (1%)] Loss: -1544.718384\n",
      "Train Epoch: 3291 [11776/60000 (20%)] Loss: -1498.051147\n",
      "Train Epoch: 3291 [23040/60000 (38%)] Loss: -1562.576294\n",
      "Train Epoch: 3291 [34304/60000 (57%)] Loss: -1406.383301\n",
      "Train Epoch: 3291 [45568/60000 (76%)] Loss: -1528.790039\n",
      "Train Epoch: 3291 [56832/60000 (95%)] Loss: -1517.894897\n",
      "    epoch          : 3291\n",
      "    loss           : -1508.4542536331435\n",
      "Train Epoch: 3292 [512/60000 (1%)] Loss: -1418.138184\n",
      "Train Epoch: 3292 [11776/60000 (20%)] Loss: -1513.428955\n",
      "Train Epoch: 3292 [23040/60000 (38%)] Loss: -1566.118042\n",
      "Train Epoch: 3292 [34304/60000 (57%)] Loss: -1583.136475\n",
      "Train Epoch: 3292 [45568/60000 (76%)] Loss: -1619.713501\n",
      "Train Epoch: 3292 [56832/60000 (95%)] Loss: -1536.847412\n",
      "    epoch          : 3292\n",
      "    loss           : -1509.7617821989759\n",
      "Train Epoch: 3293 [512/60000 (1%)] Loss: -1471.805176\n",
      "Train Epoch: 3293 [11776/60000 (20%)] Loss: -1420.712646\n",
      "Train Epoch: 3293 [23040/60000 (38%)] Loss: -1458.841675\n",
      "Train Epoch: 3293 [34304/60000 (57%)] Loss: -1615.787598\n",
      "Train Epoch: 3293 [45568/60000 (76%)] Loss: -1574.377441\n",
      "Train Epoch: 3293 [56832/60000 (95%)] Loss: -1532.397217\n",
      "    epoch          : 3293\n",
      "    loss           : -1505.5342869300628\n",
      "Train Epoch: 3294 [512/60000 (1%)] Loss: -1445.937134\n",
      "Train Epoch: 3294 [11776/60000 (20%)] Loss: -1496.769775\n",
      "Train Epoch: 3294 [23040/60000 (38%)] Loss: -1482.460693\n",
      "Train Epoch: 3294 [34304/60000 (57%)] Loss: -1484.659668\n",
      "Train Epoch: 3294 [45568/60000 (76%)] Loss: -1493.576660\n",
      "Train Epoch: 3294 [56832/60000 (95%)] Loss: -1498.590210\n",
      "    epoch          : 3294\n",
      "    loss           : -1507.9768521583687\n",
      "Train Epoch: 3295 [512/60000 (1%)] Loss: -1559.302734\n",
      "Train Epoch: 3295 [11776/60000 (20%)] Loss: -1529.537842\n",
      "Train Epoch: 3295 [23040/60000 (38%)] Loss: -1424.256348\n",
      "Train Epoch: 3295 [34304/60000 (57%)] Loss: -1491.226440\n",
      "Train Epoch: 3295 [45568/60000 (76%)] Loss: -1565.937256\n",
      "Train Epoch: 3295 [56832/60000 (95%)] Loss: -1560.014526\n",
      "    epoch          : 3295\n",
      "    loss           : -1518.1911379711778\n",
      "Train Epoch: 3296 [512/60000 (1%)] Loss: -1558.981934\n",
      "Train Epoch: 3296 [11776/60000 (20%)] Loss: -1388.815796\n",
      "Train Epoch: 3296 [23040/60000 (38%)] Loss: -1489.624512\n",
      "Train Epoch: 3296 [34304/60000 (57%)] Loss: -1477.915894\n",
      "Train Epoch: 3296 [45568/60000 (76%)] Loss: -1506.800781\n",
      "Train Epoch: 3296 [56832/60000 (95%)] Loss: -1407.072388\n",
      "    epoch          : 3296\n",
      "    loss           : -1511.2569366282662\n",
      "Train Epoch: 3297 [512/60000 (1%)] Loss: -1477.122803\n",
      "Train Epoch: 3297 [11776/60000 (20%)] Loss: -1492.658203\n",
      "Train Epoch: 3297 [23040/60000 (38%)] Loss: -1493.177734\n",
      "Train Epoch: 3297 [34304/60000 (57%)] Loss: -1477.994385\n",
      "Train Epoch: 3297 [45568/60000 (76%)] Loss: -1407.674194\n",
      "Train Epoch: 3297 [56832/60000 (95%)] Loss: -1499.875000\n",
      "    epoch          : 3297\n",
      "    loss           : -1507.1567827644994\n",
      "Train Epoch: 3298 [512/60000 (1%)] Loss: -1559.733643\n",
      "Train Epoch: 3298 [11776/60000 (20%)] Loss: -1508.452637\n",
      "Train Epoch: 3298 [23040/60000 (38%)] Loss: -1531.416870\n",
      "Train Epoch: 3298 [34304/60000 (57%)] Loss: -1522.076416\n",
      "Train Epoch: 3298 [45568/60000 (76%)] Loss: -1441.295288\n",
      "Train Epoch: 3298 [56832/60000 (95%)] Loss: -1529.481323\n",
      "    epoch          : 3298\n",
      "    loss           : -1504.646096439685\n",
      "Train Epoch: 3299 [512/60000 (1%)] Loss: -1531.605225\n",
      "Train Epoch: 3299 [11776/60000 (20%)] Loss: -1499.088379\n",
      "Train Epoch: 3299 [23040/60000 (38%)] Loss: -1488.010376\n",
      "Train Epoch: 3299 [34304/60000 (57%)] Loss: -1427.861084\n",
      "Train Epoch: 3299 [45568/60000 (76%)] Loss: -1433.255371\n",
      "Train Epoch: 3299 [56832/60000 (95%)] Loss: -1493.878662\n",
      "    epoch          : 3299\n",
      "    loss           : -1510.5830660890051\n",
      "Train Epoch: 3300 [512/60000 (1%)] Loss: -1524.336060\n",
      "Train Epoch: 3300 [11776/60000 (20%)] Loss: -1560.800171\n",
      "Train Epoch: 3300 [23040/60000 (38%)] Loss: -1570.884277\n",
      "Train Epoch: 3300 [34304/60000 (57%)] Loss: -1419.252930\n",
      "Train Epoch: 3300 [45568/60000 (76%)] Loss: -1500.614502\n",
      "Train Epoch: 3300 [56832/60000 (95%)] Loss: -1440.353760\n",
      "    epoch          : 3300\n",
      "    loss           : -1514.935771705067\n",
      "Saving checkpoint: saved/models/Mnist_DeepGenerativeOperad/0127_111843/checkpoint-epoch3300.pth ...\n",
      "Train Epoch: 3301 [512/60000 (1%)] Loss: -1554.998291\n",
      "Train Epoch: 3301 [11776/60000 (20%)] Loss: -1518.509521\n",
      "Train Epoch: 3301 [23040/60000 (38%)] Loss: -1510.049316\n",
      "Train Epoch: 3301 [34304/60000 (57%)] Loss: -1494.873657\n",
      "Train Epoch: 3301 [45568/60000 (76%)] Loss: -1483.688965\n",
      "Train Epoch: 3301 [56832/60000 (95%)] Loss: -1453.541504\n",
      "    epoch          : 3301\n",
      "    loss           : -1512.1335628531072\n",
      "Train Epoch: 3302 [512/60000 (1%)] Loss: -1581.752930\n",
      "Train Epoch: 3302 [11776/60000 (20%)] Loss: -1484.027832\n",
      "Train Epoch: 3302 [23040/60000 (38%)] Loss: -1418.804688\n",
      "Train Epoch: 3302 [34304/60000 (57%)] Loss: -1538.847900\n",
      "Train Epoch: 3302 [45568/60000 (76%)] Loss: -1513.283936\n",
      "Train Epoch: 3302 [56832/60000 (95%)] Loss: -1512.067871\n",
      "    epoch          : 3302\n",
      "    loss           : -1510.6437940004855\n",
      "Train Epoch: 3303 [512/60000 (1%)] Loss: -1443.639160\n",
      "Train Epoch: 3303 [11776/60000 (20%)] Loss: -1466.787842\n",
      "Train Epoch: 3303 [23040/60000 (38%)] Loss: -1363.561035\n",
      "Train Epoch: 3303 [34304/60000 (57%)] Loss: -1535.319458\n",
      "Train Epoch: 3303 [45568/60000 (76%)] Loss: -1521.799438\n",
      "Train Epoch: 3303 [56832/60000 (95%)] Loss: -1471.063110\n",
      "    epoch          : 3303\n",
      "    loss           : -1510.3016053970252\n",
      "Train Epoch: 3304 [512/60000 (1%)] Loss: -1517.707031\n",
      "Train Epoch: 3304 [11776/60000 (20%)] Loss: -1503.385986\n",
      "Train Epoch: 3304 [23040/60000 (38%)] Loss: -1498.659302\n",
      "Train Epoch: 3304 [34304/60000 (57%)] Loss: -1598.458252\n",
      "Train Epoch: 3304 [45568/60000 (76%)] Loss: -1501.927856\n",
      "Train Epoch: 3304 [56832/60000 (95%)] Loss: -1522.000977\n",
      "    epoch          : 3304\n",
      "    loss           : -1513.1969656216895\n",
      "Train Epoch: 3305 [512/60000 (1%)] Loss: -1456.979492\n",
      "Train Epoch: 3305 [11776/60000 (20%)] Loss: -1546.109619\n",
      "Train Epoch: 3305 [23040/60000 (38%)] Loss: -1480.572266\n",
      "Train Epoch: 3305 [34304/60000 (57%)] Loss: -1525.404541\n",
      "Train Epoch: 3305 [45568/60000 (76%)] Loss: -1570.308472\n",
      "Train Epoch: 3305 [56832/60000 (95%)] Loss: -1563.277344\n",
      "    epoch          : 3305\n",
      "    loss           : -1528.613449527719\n",
      "Train Epoch: 3306 [512/60000 (1%)] Loss: -1429.505371\n",
      "Train Epoch: 3306 [11776/60000 (20%)] Loss: -1474.817261\n",
      "Train Epoch: 3306 [23040/60000 (38%)] Loss: -1486.701294\n",
      "Train Epoch: 3306 [34304/60000 (57%)] Loss: -1415.157959\n",
      "Train Epoch: 3306 [45568/60000 (76%)] Loss: -1562.037109\n",
      "Train Epoch: 3306 [56832/60000 (95%)] Loss: -1502.080322\n",
      "    epoch          : 3306\n",
      "    loss           : -1511.9289736990202\n",
      "Train Epoch: 3307 [512/60000 (1%)] Loss: -1505.760620\n",
      "Train Epoch: 3307 [11776/60000 (20%)] Loss: -1446.103760\n",
      "Train Epoch: 3307 [23040/60000 (38%)] Loss: -1500.403076\n",
      "Train Epoch: 3307 [34304/60000 (57%)] Loss: -1452.195801\n",
      "Train Epoch: 3307 [45568/60000 (76%)] Loss: -1520.212158\n",
      "Train Epoch: 3307 [56832/60000 (95%)] Loss: -1516.475464\n",
      "    epoch          : 3307\n",
      "    loss           : -1507.9698972540386\n",
      "Train Epoch: 3308 [512/60000 (1%)] Loss: -1510.527344\n",
      "Train Epoch: 3308 [11776/60000 (20%)] Loss: -1468.368042\n",
      "Train Epoch: 3308 [23040/60000 (38%)] Loss: -1560.807129\n",
      "Train Epoch: 3308 [34304/60000 (57%)] Loss: -1535.100220\n",
      "Train Epoch: 3308 [45568/60000 (76%)] Loss: -1520.837036\n",
      "Train Epoch: 3308 [56832/60000 (95%)] Loss: -1511.768433\n",
      "    epoch          : 3308\n",
      "    loss           : -1518.4028803076449\n",
      "Train Epoch: 3309 [512/60000 (1%)] Loss: -1532.028076\n",
      "Train Epoch: 3309 [11776/60000 (20%)] Loss: -1474.623291\n",
      "Train Epoch: 3309 [23040/60000 (38%)] Loss: -1496.541016\n",
      "Train Epoch: 3309 [34304/60000 (57%)] Loss: -1564.303223\n",
      "Train Epoch: 3309 [45568/60000 (76%)] Loss: -1440.414429\n",
      "Train Epoch: 3309 [56832/60000 (95%)] Loss: -1405.716797\n",
      "    epoch          : 3309\n",
      "    loss           : -1511.1424867446815\n",
      "Train Epoch: 3310 [512/60000 (1%)] Loss: -1455.721436\n",
      "Train Epoch: 3310 [11776/60000 (20%)] Loss: -1452.391724\n",
      "Train Epoch: 3310 [23040/60000 (38%)] Loss: -1384.204712\n",
      "Train Epoch: 3310 [34304/60000 (57%)] Loss: -1536.212280\n",
      "Train Epoch: 3310 [45568/60000 (76%)] Loss: -1454.863525\n",
      "Train Epoch: 3310 [56832/60000 (95%)] Loss: -1477.699463\n",
      "    epoch          : 3310\n",
      "    loss           : -1508.9931892351915\n",
      "Train Epoch: 3311 [512/60000 (1%)] Loss: -1550.776367\n",
      "Train Epoch: 3311 [11776/60000 (20%)] Loss: -1517.289795\n",
      "Train Epoch: 3311 [23040/60000 (38%)] Loss: -1537.637085\n",
      "Train Epoch: 3311 [34304/60000 (57%)] Loss: -1476.880615\n",
      "Train Epoch: 3311 [45568/60000 (76%)] Loss: -1452.323730\n",
      "Train Epoch: 3311 [56832/60000 (95%)] Loss: -1538.829468\n",
      "    epoch          : 3311\n",
      "    loss           : -1510.3172141899497\n",
      "Train Epoch: 3312 [512/60000 (1%)] Loss: -1567.010010\n",
      "Train Epoch: 3312 [11776/60000 (20%)] Loss: -1522.377441\n",
      "Train Epoch: 3312 [23040/60000 (38%)] Loss: -1550.914307\n",
      "Train Epoch: 3312 [34304/60000 (57%)] Loss: -1531.639648\n",
      "Train Epoch: 3312 [45568/60000 (76%)] Loss: -1475.969727\n",
      "Train Epoch: 3312 [56832/60000 (95%)] Loss: -1476.206177\n",
      "    epoch          : 3312\n",
      "    loss           : -1509.460680255782\n",
      "Train Epoch: 3313 [512/60000 (1%)] Loss: -1426.166016\n",
      "Train Epoch: 3313 [11776/60000 (20%)] Loss: -1544.184570\n",
      "Train Epoch: 3313 [23040/60000 (38%)] Loss: -1503.426270\n",
      "Train Epoch: 3313 [34304/60000 (57%)] Loss: -1518.082520\n",
      "Train Epoch: 3313 [45568/60000 (76%)] Loss: -1547.075439\n",
      "Train Epoch: 3313 [56832/60000 (95%)] Loss: -1522.651367\n",
      "    epoch          : 3313\n",
      "    loss           : -1513.5911210054733\n",
      "Train Epoch: 3314 [512/60000 (1%)] Loss: -1511.066162\n",
      "Train Epoch: 3314 [11776/60000 (20%)] Loss: -1536.161621\n",
      "Train Epoch: 3314 [23040/60000 (38%)] Loss: -1492.959595\n",
      "Train Epoch: 3314 [34304/60000 (57%)] Loss: -1512.805420\n",
      "Train Epoch: 3314 [45568/60000 (76%)] Loss: -1500.227417\n",
      "Train Epoch: 3314 [56832/60000 (95%)] Loss: -1497.024170\n",
      "    epoch          : 3314\n",
      "    loss           : -1509.7612697795287\n",
      "Train Epoch: 3315 [512/60000 (1%)] Loss: -1542.510986\n",
      "Train Epoch: 3315 [11776/60000 (20%)] Loss: -1572.183105\n",
      "Train Epoch: 3315 [23040/60000 (38%)] Loss: -1504.791260\n",
      "Train Epoch: 3315 [34304/60000 (57%)] Loss: -1449.125000\n",
      "Train Epoch: 3315 [45568/60000 (76%)] Loss: -1480.566162\n",
      "Train Epoch: 3315 [56832/60000 (95%)] Loss: -1449.453369\n",
      "    epoch          : 3315\n",
      "    loss           : -1522.283626233117\n",
      "Train Epoch: 3316 [512/60000 (1%)] Loss: -1489.342896\n",
      "Train Epoch: 3316 [11776/60000 (20%)] Loss: -1490.771240\n",
      "Train Epoch: 3316 [23040/60000 (38%)] Loss: -1380.586670\n",
      "Train Epoch: 3316 [34304/60000 (57%)] Loss: -1569.525879\n",
      "Train Epoch: 3316 [45568/60000 (76%)] Loss: -1451.367920\n",
      "Train Epoch: 3316 [56832/60000 (95%)] Loss: -1550.932007\n",
      "    epoch          : 3316\n",
      "    loss           : -1508.628414520436\n",
      "Train Epoch: 3317 [512/60000 (1%)] Loss: -1501.190552\n",
      "Train Epoch: 3317 [11776/60000 (20%)] Loss: -1576.558105\n",
      "Train Epoch: 3317 [23040/60000 (38%)] Loss: -1453.418701\n",
      "Train Epoch: 3317 [34304/60000 (57%)] Loss: -1589.549316\n",
      "Train Epoch: 3317 [45568/60000 (76%)] Loss: -1447.420410\n",
      "Train Epoch: 3317 [56832/60000 (95%)] Loss: -1460.854614\n",
      "    epoch          : 3317\n",
      "    loss           : -1515.4385155284474\n",
      "Train Epoch: 3318 [512/60000 (1%)] Loss: -1491.166626\n",
      "Train Epoch: 3318 [11776/60000 (20%)] Loss: -1436.529419\n",
      "Train Epoch: 3318 [23040/60000 (38%)] Loss: -1440.413696\n",
      "Train Epoch: 3318 [34304/60000 (57%)] Loss: -1541.574585\n",
      "Train Epoch: 3318 [45568/60000 (76%)] Loss: -1501.703613\n",
      "Train Epoch: 3318 [56832/60000 (95%)] Loss: -1440.255493\n",
      "    epoch          : 3318\n",
      "    loss           : -1516.0984700520835\n",
      "Train Epoch: 3319 [512/60000 (1%)] Loss: -1584.691528\n",
      "Train Epoch: 3319 [11776/60000 (20%)] Loss: -1456.504395\n",
      "Train Epoch: 3319 [23040/60000 (38%)] Loss: -1416.307983\n",
      "Train Epoch: 3319 [34304/60000 (57%)] Loss: -1474.265137\n",
      "Train Epoch: 3319 [45568/60000 (76%)] Loss: -1469.973145\n",
      "Train Epoch: 3319 [56832/60000 (95%)] Loss: -1467.885376\n",
      "    epoch          : 3319\n",
      "    loss           : -1518.2326515327065\n",
      "Train Epoch: 3320 [512/60000 (1%)] Loss: -1545.575928\n",
      "Train Epoch: 3320 [11776/60000 (20%)] Loss: -1516.147461\n",
      "Train Epoch: 3320 [23040/60000 (38%)] Loss: -1572.830322\n",
      "Train Epoch: 3320 [34304/60000 (57%)] Loss: -1566.278320\n",
      "Train Epoch: 3320 [45568/60000 (76%)] Loss: -1497.869385\n",
      "Train Epoch: 3320 [56832/60000 (95%)] Loss: -1518.068359\n",
      "    epoch          : 3320\n",
      "    loss           : -1519.0406328621557\n",
      "Train Epoch: 3321 [512/60000 (1%)] Loss: -1451.370117\n",
      "Train Epoch: 3321 [11776/60000 (20%)] Loss: -1496.186401\n",
      "Train Epoch: 3321 [23040/60000 (38%)] Loss: -1508.102783\n",
      "Train Epoch: 3321 [34304/60000 (57%)] Loss: -1561.413818\n",
      "Train Epoch: 3321 [45568/60000 (76%)] Loss: -1534.306396\n",
      "Train Epoch: 3321 [56832/60000 (95%)] Loss: -1522.913452\n",
      "    epoch          : 3321\n",
      "    loss           : -1516.972023484397\n",
      "Train Epoch: 3322 [512/60000 (1%)] Loss: -1464.817871\n",
      "Train Epoch: 3322 [11776/60000 (20%)] Loss: -1529.094360\n",
      "Train Epoch: 3322 [23040/60000 (38%)] Loss: -1534.682129\n",
      "Train Epoch: 3322 [34304/60000 (57%)] Loss: -1467.571777\n",
      "Train Epoch: 3322 [45568/60000 (76%)] Loss: -1510.623779\n",
      "Train Epoch: 3322 [56832/60000 (95%)] Loss: -1463.083252\n",
      "    epoch          : 3322\n",
      "    loss           : -1513.4352441130384\n",
      "Train Epoch: 3323 [512/60000 (1%)] Loss: -1539.816895\n",
      "Train Epoch: 3323 [11776/60000 (20%)] Loss: -1560.717773\n",
      "Train Epoch: 3323 [23040/60000 (38%)] Loss: -1518.636230\n",
      "Train Epoch: 3323 [34304/60000 (57%)] Loss: -1374.805176\n",
      "Train Epoch: 3323 [45568/60000 (76%)] Loss: -1500.404297\n",
      "Train Epoch: 3323 [56832/60000 (95%)] Loss: -1502.049683\n",
      "    epoch          : 3323\n",
      "    loss           : -1511.6406053446108\n",
      "Train Epoch: 3324 [512/60000 (1%)] Loss: -1506.183105\n",
      "Train Epoch: 3324 [11776/60000 (20%)] Loss: -1478.677124\n",
      "Train Epoch: 3324 [23040/60000 (38%)] Loss: -1478.579590\n",
      "Train Epoch: 3324 [34304/60000 (57%)] Loss: -1512.108643\n",
      "Train Epoch: 3324 [45568/60000 (76%)] Loss: -1488.806885\n",
      "Train Epoch: 3324 [56832/60000 (95%)] Loss: -1560.949219\n",
      "    epoch          : 3324\n",
      "    loss           : -1512.0967821024233\n",
      "Train Epoch: 3325 [512/60000 (1%)] Loss: -1493.590454\n",
      "Train Epoch: 3325 [11776/60000 (20%)] Loss: -1514.948730\n",
      "Train Epoch: 3325 [23040/60000 (38%)] Loss: -1514.814331\n",
      "Train Epoch: 3325 [34304/60000 (57%)] Loss: -1445.068359\n",
      "Train Epoch: 3325 [45568/60000 (76%)] Loss: -1485.971924\n",
      "Train Epoch: 3325 [56832/60000 (95%)] Loss: -1550.660645\n",
      "    epoch          : 3325\n",
      "    loss           : -1507.0485950189795\n",
      "Train Epoch: 3326 [512/60000 (1%)] Loss: -1503.509521\n",
      "Train Epoch: 3326 [11776/60000 (20%)] Loss: -1545.531128\n",
      "Train Epoch: 3326 [23040/60000 (38%)] Loss: -1508.993164\n",
      "Train Epoch: 3326 [34304/60000 (57%)] Loss: -1518.049561\n",
      "Train Epoch: 3326 [45568/60000 (76%)] Loss: -1497.264893\n",
      "Train Epoch: 3326 [56832/60000 (95%)] Loss: -1482.630127\n",
      "    epoch          : 3326\n",
      "    loss           : -1517.9629326944298\n",
      "Train Epoch: 3327 [512/60000 (1%)] Loss: -1434.716553\n",
      "Train Epoch: 3327 [11776/60000 (20%)] Loss: -1526.249634\n",
      "Train Epoch: 3327 [23040/60000 (38%)] Loss: -1444.190430\n",
      "Train Epoch: 3327 [34304/60000 (57%)] Loss: -1561.239868\n",
      "Train Epoch: 3327 [45568/60000 (76%)] Loss: -1596.123291\n",
      "Train Epoch: 3327 [56832/60000 (95%)] Loss: -1607.536255\n",
      "    epoch          : 3327\n",
      "    loss           : -1514.3342950680835\n",
      "Train Epoch: 3328 [512/60000 (1%)] Loss: -1504.920044\n",
      "Train Epoch: 3328 [11776/60000 (20%)] Loss: -1516.860962\n",
      "Train Epoch: 3328 [23040/60000 (38%)] Loss: -1550.709473\n",
      "Train Epoch: 3328 [34304/60000 (57%)] Loss: -1498.139648\n",
      "Train Epoch: 3328 [45568/60000 (76%)] Loss: -1442.141846\n",
      "Train Epoch: 3328 [56832/60000 (95%)] Loss: -1489.434814\n",
      "    epoch          : 3328\n",
      "    loss           : -1501.6971345890713\n",
      "Train Epoch: 3329 [512/60000 (1%)] Loss: -1514.470703\n",
      "Train Epoch: 3329 [11776/60000 (20%)] Loss: -1554.516479\n",
      "Train Epoch: 3329 [23040/60000 (38%)] Loss: -1474.014526\n",
      "Train Epoch: 3329 [34304/60000 (57%)] Loss: -1455.857300\n",
      "Train Epoch: 3329 [45568/60000 (76%)] Loss: -1491.862427\n",
      "Train Epoch: 3329 [56832/60000 (95%)] Loss: -1604.284546\n",
      "    epoch          : 3329\n",
      "    loss           : -1508.213653047206\n",
      "Train Epoch: 3330 [512/60000 (1%)] Loss: -1496.359741\n",
      "Train Epoch: 3330 [11776/60000 (20%)] Loss: -1502.583130\n",
      "Train Epoch: 3330 [23040/60000 (38%)] Loss: -1504.528076\n",
      "Train Epoch: 3330 [34304/60000 (57%)] Loss: -1568.612305\n",
      "Train Epoch: 3330 [45568/60000 (76%)] Loss: -1416.445312\n",
      "Train Epoch: 3330 [56832/60000 (95%)] Loss: -1552.655884\n",
      "    epoch          : 3330\n",
      "    loss           : -1520.0997159279\n",
      "Train Epoch: 3331 [512/60000 (1%)] Loss: -1459.254150\n",
      "Train Epoch: 3331 [11776/60000 (20%)] Loss: -1509.867920\n",
      "Train Epoch: 3331 [23040/60000 (38%)] Loss: -1367.139160\n",
      "Train Epoch: 3331 [34304/60000 (57%)] Loss: -1524.537231\n",
      "Train Epoch: 3331 [45568/60000 (76%)] Loss: -1540.317383\n",
      "Train Epoch: 3331 [56832/60000 (95%)] Loss: -1592.077393\n",
      "    epoch          : 3331\n",
      "    loss           : -1511.6293203925009\n",
      "Train Epoch: 3332 [512/60000 (1%)] Loss: -1529.300293\n",
      "Train Epoch: 3332 [11776/60000 (20%)] Loss: -1554.013550\n",
      "Train Epoch: 3332 [23040/60000 (38%)] Loss: -1439.269897\n",
      "Train Epoch: 3332 [34304/60000 (57%)] Loss: -1444.568481\n",
      "Train Epoch: 3332 [45568/60000 (76%)] Loss: -1520.711670\n",
      "Train Epoch: 3332 [56832/60000 (95%)] Loss: -1556.312256\n",
      "    epoch          : 3332\n",
      "    loss           : -1509.746118233029\n",
      "Train Epoch: 3333 [512/60000 (1%)] Loss: -1516.130493\n",
      "Train Epoch: 3333 [11776/60000 (20%)] Loss: -1466.737793\n",
      "Train Epoch: 3333 [23040/60000 (38%)] Loss: -1533.434814\n",
      "Train Epoch: 3333 [34304/60000 (57%)] Loss: -1494.566406\n",
      "Train Epoch: 3333 [45568/60000 (76%)] Loss: -1499.133057\n",
      "Train Epoch: 3333 [56832/60000 (95%)] Loss: -1541.359497\n",
      "    epoch          : 3333\n",
      "    loss           : -1512.7165568723517\n",
      "Train Epoch: 3334 [512/60000 (1%)] Loss: -1439.731812\n",
      "Train Epoch: 3334 [11776/60000 (20%)] Loss: -1536.324341\n",
      "Train Epoch: 3334 [23040/60000 (38%)] Loss: -1454.410522\n",
      "Train Epoch: 3334 [34304/60000 (57%)] Loss: -1534.059082\n",
      "Train Epoch: 3334 [45568/60000 (76%)] Loss: -1476.281006\n",
      "Train Epoch: 3334 [56832/60000 (95%)] Loss: -1461.812500\n",
      "    epoch          : 3334\n",
      "    loss           : -1508.4936044121866\n",
      "Train Epoch: 3335 [512/60000 (1%)] Loss: -1521.479248\n",
      "Train Epoch: 3335 [11776/60000 (20%)] Loss: -1533.879883\n",
      "Train Epoch: 3335 [23040/60000 (38%)] Loss: -1498.044067\n",
      "Train Epoch: 3335 [34304/60000 (57%)] Loss: -1564.170532\n",
      "Train Epoch: 3335 [45568/60000 (76%)] Loss: -1452.190186\n",
      "Train Epoch: 3335 [56832/60000 (95%)] Loss: -1557.389893\n",
      "    epoch          : 3335\n",
      "    loss           : -1523.3233573611847\n",
      "Train Epoch: 3336 [512/60000 (1%)] Loss: -1515.563354\n",
      "Train Epoch: 3336 [11776/60000 (20%)] Loss: -1539.634155\n",
      "Train Epoch: 3336 [23040/60000 (38%)] Loss: -1412.137329\n",
      "Train Epoch: 3336 [34304/60000 (57%)] Loss: -1520.082764\n",
      "Train Epoch: 3336 [45568/60000 (76%)] Loss: -1505.341064\n",
      "Train Epoch: 3336 [56832/60000 (95%)] Loss: -1536.088989\n",
      "    epoch          : 3336\n",
      "    loss           : -1510.8376282083111\n",
      "Train Epoch: 3337 [512/60000 (1%)] Loss: -1471.695557\n",
      "Train Epoch: 3337 [11776/60000 (20%)] Loss: -1608.475830\n",
      "Train Epoch: 3337 [23040/60000 (38%)] Loss: -1573.992554\n",
      "Train Epoch: 3337 [34304/60000 (57%)] Loss: -1497.162109\n",
      "Train Epoch: 3337 [45568/60000 (76%)] Loss: -1500.790039\n",
      "Train Epoch: 3337 [56832/60000 (95%)] Loss: -1464.442383\n",
      "    epoch          : 3337\n",
      "    loss           : -1515.2415030096884\n",
      "Train Epoch: 3338 [512/60000 (1%)] Loss: -1514.178345\n",
      "Train Epoch: 3338 [11776/60000 (20%)] Loss: -1426.869629\n",
      "Train Epoch: 3338 [23040/60000 (38%)] Loss: -1547.446167\n",
      "Train Epoch: 3338 [34304/60000 (57%)] Loss: -1518.893555\n",
      "Train Epoch: 3338 [45568/60000 (76%)] Loss: -1559.891602\n",
      "Train Epoch: 3338 [56832/60000 (95%)] Loss: -1491.059326\n",
      "    epoch          : 3338\n",
      "    loss           : -1507.549829170529\n",
      "Train Epoch: 3339 [512/60000 (1%)] Loss: -1561.003540\n",
      "Train Epoch: 3339 [11776/60000 (20%)] Loss: -1567.367188\n",
      "Train Epoch: 3339 [23040/60000 (38%)] Loss: -1474.916992\n",
      "Train Epoch: 3339 [34304/60000 (57%)] Loss: -1558.644775\n",
      "Train Epoch: 3339 [45568/60000 (76%)] Loss: -1551.304321\n",
      "Train Epoch: 3339 [56832/60000 (95%)] Loss: -1490.407227\n",
      "    epoch          : 3339\n",
      "    loss           : -1520.3371068232477\n",
      "Train Epoch: 3340 [512/60000 (1%)] Loss: -1535.357788\n",
      "Train Epoch: 3340 [11776/60000 (20%)] Loss: -1494.466553\n",
      "Train Epoch: 3340 [23040/60000 (38%)] Loss: -1539.603027\n",
      "Train Epoch: 3340 [34304/60000 (57%)] Loss: -1595.690674\n",
      "Train Epoch: 3340 [45568/60000 (76%)] Loss: -1521.887329\n",
      "Train Epoch: 3340 [56832/60000 (95%)] Loss: -1601.145508\n",
      "    epoch          : 3340\n",
      "    loss           : -1521.0965020993335\n",
      "Train Epoch: 3341 [512/60000 (1%)] Loss: -1415.132446\n",
      "Train Epoch: 3341 [11776/60000 (20%)] Loss: -1484.629883\n",
      "Train Epoch: 3341 [23040/60000 (38%)] Loss: -1500.360840\n",
      "Train Epoch: 3341 [34304/60000 (57%)] Loss: -1551.439453\n",
      "Train Epoch: 3341 [45568/60000 (76%)] Loss: -1485.104370\n",
      "Train Epoch: 3341 [56832/60000 (95%)] Loss: -1526.662354\n",
      "    epoch          : 3341\n",
      "    loss           : -1509.2693384892523\n",
      "Train Epoch: 3342 [512/60000 (1%)] Loss: -1392.811768\n",
      "Train Epoch: 3342 [11776/60000 (20%)] Loss: -1514.209961\n",
      "Train Epoch: 3342 [23040/60000 (38%)] Loss: -1435.475586\n",
      "Train Epoch: 3342 [34304/60000 (57%)] Loss: -1460.036133\n",
      "Train Epoch: 3342 [45568/60000 (76%)] Loss: -1538.218262\n",
      "Train Epoch: 3342 [56832/60000 (95%)] Loss: -1446.624268\n",
      "    epoch          : 3342\n",
      "    loss           : -1510.7141882255253\n",
      "Train Epoch: 3343 [512/60000 (1%)] Loss: -1467.998291\n",
      "Train Epoch: 3343 [11776/60000 (20%)] Loss: -1615.291626\n",
      "Train Epoch: 3343 [23040/60000 (38%)] Loss: -1520.420532\n",
      "Train Epoch: 3343 [34304/60000 (57%)] Loss: -1448.975464\n",
      "Train Epoch: 3343 [45568/60000 (76%)] Loss: -1417.789307\n",
      "Train Epoch: 3343 [56832/60000 (95%)] Loss: -1510.526123\n",
      "    epoch          : 3343\n",
      "    loss           : -1507.4222891425009\n",
      "Train Epoch: 3344 [512/60000 (1%)] Loss: -1566.723022\n",
      "Train Epoch: 3344 [11776/60000 (20%)] Loss: -1523.167603\n",
      "Train Epoch: 3344 [23040/60000 (38%)] Loss: -1535.710327\n",
      "Train Epoch: 3344 [34304/60000 (57%)] Loss: -1553.828979\n",
      "Train Epoch: 3344 [45568/60000 (76%)] Loss: -1536.667114\n",
      "Train Epoch: 3344 [56832/60000 (95%)] Loss: -1487.859009\n",
      "    epoch          : 3344\n",
      "    loss           : -1518.306650280279\n",
      "Train Epoch: 3345 [512/60000 (1%)] Loss: -1452.746094\n",
      "Train Epoch: 3345 [11776/60000 (20%)] Loss: -1562.350952\n",
      "Train Epoch: 3345 [23040/60000 (38%)] Loss: -1542.528687\n",
      "Train Epoch: 3345 [34304/60000 (57%)] Loss: -1449.800537\n",
      "Train Epoch: 3345 [45568/60000 (76%)] Loss: -1420.091187\n",
      "Train Epoch: 3345 [56832/60000 (95%)] Loss: -1541.133057\n",
      "    epoch          : 3345\n",
      "    loss           : -1508.608921891552\n",
      "Train Epoch: 3346 [512/60000 (1%)] Loss: -1563.229736\n",
      "Train Epoch: 3346 [11776/60000 (20%)] Loss: -1580.542236\n",
      "Train Epoch: 3346 [23040/60000 (38%)] Loss: -1469.799805\n",
      "Train Epoch: 3346 [34304/60000 (57%)] Loss: -1536.880371\n",
      "Train Epoch: 3346 [45568/60000 (76%)] Loss: -1446.967896\n",
      "Train Epoch: 3346 [56832/60000 (95%)] Loss: -1483.316284\n",
      "    epoch          : 3346\n",
      "    loss           : -1511.270780229299\n",
      "Train Epoch: 3347 [512/60000 (1%)] Loss: -1559.479248\n",
      "Train Epoch: 3347 [11776/60000 (20%)] Loss: -1544.663818\n",
      "Train Epoch: 3347 [23040/60000 (38%)] Loss: -1453.105347\n",
      "Train Epoch: 3347 [34304/60000 (57%)] Loss: -1452.038574\n",
      "Train Epoch: 3347 [45568/60000 (76%)] Loss: -1486.940063\n",
      "Train Epoch: 3347 [56832/60000 (95%)] Loss: -1518.195068\n",
      "    epoch          : 3347\n",
      "    loss           : -1513.4414162501105\n",
      "Train Epoch: 3348 [512/60000 (1%)] Loss: -1465.012939\n",
      "Train Epoch: 3348 [11776/60000 (20%)] Loss: -1493.948730\n",
      "Train Epoch: 3348 [23040/60000 (38%)] Loss: -1531.240234\n",
      "Train Epoch: 3348 [34304/60000 (57%)] Loss: -1543.314331\n",
      "Train Epoch: 3348 [45568/60000 (76%)] Loss: -1510.962524\n",
      "Train Epoch: 3348 [56832/60000 (95%)] Loss: -1557.304443\n",
      "    epoch          : 3348\n",
      "    loss           : -1516.979954951227\n",
      "Train Epoch: 3349 [512/60000 (1%)] Loss: -1523.568970\n",
      "Train Epoch: 3349 [11776/60000 (20%)] Loss: -1608.240234\n",
      "Train Epoch: 3349 [23040/60000 (38%)] Loss: -1517.519287\n",
      "Train Epoch: 3349 [34304/60000 (57%)] Loss: -1507.280762\n",
      "Train Epoch: 3349 [45568/60000 (76%)] Loss: -1538.930908\n",
      "Train Epoch: 3349 [56832/60000 (95%)] Loss: -1504.044189\n",
      "    epoch          : 3349\n",
      "    loss           : -1514.5103401140977\n",
      "Train Epoch: 3350 [512/60000 (1%)] Loss: -1456.720581\n",
      "Train Epoch: 3350 [11776/60000 (20%)] Loss: -1467.860596\n",
      "Train Epoch: 3350 [23040/60000 (38%)] Loss: -1534.065308\n",
      "Train Epoch: 3350 [34304/60000 (57%)] Loss: -1440.937866\n",
      "Train Epoch: 3350 [45568/60000 (76%)] Loss: -1532.465332\n",
      "Train Epoch: 3350 [56832/60000 (95%)] Loss: -1433.010010\n",
      "    epoch          : 3350\n",
      "    loss           : -1501.8819459387137\n",
      "Train Epoch: 3351 [512/60000 (1%)] Loss: -1487.015381\n",
      "Train Epoch: 3351 [11776/60000 (20%)] Loss: -1584.982544\n",
      "Train Epoch: 3351 [23040/60000 (38%)] Loss: -1509.638916\n",
      "Train Epoch: 3351 [34304/60000 (57%)] Loss: -1528.582031\n",
      "Train Epoch: 3351 [45568/60000 (76%)] Loss: -1452.840454\n",
      "Train Epoch: 3351 [56832/60000 (95%)] Loss: -1560.320801\n",
      "    epoch          : 3351\n",
      "    loss           : -1512.001507947674\n",
      "Train Epoch: 3352 [512/60000 (1%)] Loss: -1525.656250\n",
      "Train Epoch: 3352 [11776/60000 (20%)] Loss: -1512.810059\n",
      "Train Epoch: 3352 [23040/60000 (38%)] Loss: -1507.687134\n",
      "Train Epoch: 3352 [34304/60000 (57%)] Loss: -1431.111206\n",
      "Train Epoch: 3352 [45568/60000 (76%)] Loss: -1557.668579\n",
      "Train Epoch: 3352 [56832/60000 (95%)] Loss: -1536.674805\n",
      "    epoch          : 3352\n",
      "    loss           : -1509.1232492910267\n",
      "Train Epoch: 3353 [512/60000 (1%)] Loss: -1598.496094\n",
      "Train Epoch: 3353 [11776/60000 (20%)] Loss: -1567.142578\n",
      "Train Epoch: 3353 [23040/60000 (38%)] Loss: -1457.856812\n",
      "Train Epoch: 3353 [34304/60000 (57%)] Loss: -1580.564941\n",
      "Train Epoch: 3353 [45568/60000 (76%)] Loss: -1540.793213\n",
      "Train Epoch: 3353 [56832/60000 (95%)] Loss: -1529.901855\n",
      "    epoch          : 3353\n",
      "    loss           : -1514.3334360930878\n",
      "Train Epoch: 3354 [512/60000 (1%)] Loss: -1456.113159\n",
      "Train Epoch: 3354 [11776/60000 (20%)] Loss: -1513.318848\n",
      "Train Epoch: 3354 [23040/60000 (38%)] Loss: -1552.870239\n",
      "Train Epoch: 3354 [34304/60000 (57%)] Loss: -1535.299683\n",
      "Train Epoch: 3354 [45568/60000 (76%)] Loss: -1500.155518\n",
      "Train Epoch: 3354 [56832/60000 (95%)] Loss: -1540.807495\n",
      "    epoch          : 3354\n",
      "    loss           : -1511.6935993776483\n",
      "Train Epoch: 3355 [512/60000 (1%)] Loss: -1582.237061\n",
      "Train Epoch: 3355 [11776/60000 (20%)] Loss: -1474.030396\n",
      "Train Epoch: 3355 [23040/60000 (38%)] Loss: -1472.516113\n",
      "Train Epoch: 3355 [34304/60000 (57%)] Loss: -1485.172729\n",
      "Train Epoch: 3355 [45568/60000 (76%)] Loss: -1556.965454\n",
      "Train Epoch: 3355 [56832/60000 (95%)] Loss: -1484.592651\n",
      "    epoch          : 3355\n",
      "    loss           : -1519.765409135549\n",
      "Train Epoch: 3356 [512/60000 (1%)] Loss: -1550.047729\n",
      "Train Epoch: 3356 [11776/60000 (20%)] Loss: -1479.292847\n",
      "Train Epoch: 3356 [23040/60000 (38%)] Loss: -1443.111938\n",
      "Train Epoch: 3356 [34304/60000 (57%)] Loss: -1505.697144\n",
      "Train Epoch: 3356 [45568/60000 (76%)] Loss: -1548.757324\n",
      "Train Epoch: 3356 [56832/60000 (95%)] Loss: -1610.577515\n",
      "    epoch          : 3356\n",
      "    loss           : -1517.260152525821\n",
      "Train Epoch: 3357 [512/60000 (1%)] Loss: -1512.718262\n",
      "Train Epoch: 3357 [11776/60000 (20%)] Loss: -1483.751221\n",
      "Train Epoch: 3357 [23040/60000 (38%)] Loss: -1482.460815\n",
      "Train Epoch: 3357 [34304/60000 (57%)] Loss: -1512.918091\n",
      "Train Epoch: 3357 [45568/60000 (76%)] Loss: -1516.605225\n",
      "Train Epoch: 3357 [56832/60000 (95%)] Loss: -1565.382324\n",
      "    epoch          : 3357\n",
      "    loss           : -1515.0764932578568\n",
      "Train Epoch: 3358 [512/60000 (1%)] Loss: -1505.937500\n",
      "Train Epoch: 3358 [11776/60000 (20%)] Loss: -1526.609497\n",
      "Train Epoch: 3358 [23040/60000 (38%)] Loss: -1538.742310\n",
      "Train Epoch: 3358 [34304/60000 (57%)] Loss: -1542.524902\n",
      "Train Epoch: 3358 [45568/60000 (76%)] Loss: -1514.363525\n",
      "Train Epoch: 3358 [56832/60000 (95%)] Loss: -1577.149170\n",
      "    epoch          : 3358\n",
      "    loss           : -1514.4849032816915\n",
      "Train Epoch: 3359 [512/60000 (1%)] Loss: -1542.889648\n",
      "Train Epoch: 3359 [11776/60000 (20%)] Loss: -1469.989868\n",
      "Train Epoch: 3359 [23040/60000 (38%)] Loss: -1535.535522\n",
      "Train Epoch: 3359 [34304/60000 (57%)] Loss: -1464.605469\n",
      "Train Epoch: 3359 [45568/60000 (76%)] Loss: -1560.190063\n",
      "Train Epoch: 3359 [56832/60000 (95%)] Loss: -1512.864258\n",
      "    epoch          : 3359\n",
      "    loss           : -1508.355400818216\n",
      "Train Epoch: 3360 [512/60000 (1%)] Loss: -1435.176514\n",
      "Train Epoch: 3360 [11776/60000 (20%)] Loss: -1580.893311\n",
      "Train Epoch: 3360 [23040/60000 (38%)] Loss: -1564.778564\n",
      "Train Epoch: 3360 [34304/60000 (57%)] Loss: -1498.365356\n",
      "Train Epoch: 3360 [45568/60000 (76%)] Loss: -1579.957397\n",
      "Train Epoch: 3360 [56832/60000 (95%)] Loss: -1488.172119\n",
      "    epoch          : 3360\n",
      "    loss           : -1513.5836895441605\n",
      "Train Epoch: 3361 [512/60000 (1%)] Loss: -1499.511963\n",
      "Train Epoch: 3361 [11776/60000 (20%)] Loss: -1555.741577\n",
      "Train Epoch: 3361 [23040/60000 (38%)] Loss: -1541.874756\n",
      "Train Epoch: 3361 [34304/60000 (57%)] Loss: -1442.909424\n",
      "Train Epoch: 3361 [45568/60000 (76%)] Loss: -1520.292236\n",
      "Train Epoch: 3361 [56832/60000 (95%)] Loss: -1506.094360\n",
      "    epoch          : 3361\n",
      "    loss           : -1520.3766424319165\n",
      "Train Epoch: 3362 [512/60000 (1%)] Loss: -1429.004883\n",
      "Train Epoch: 3362 [11776/60000 (20%)] Loss: -1541.945801\n",
      "Train Epoch: 3362 [23040/60000 (38%)] Loss: -1446.459106\n",
      "Train Epoch: 3362 [34304/60000 (57%)] Loss: -1542.603638\n",
      "Train Epoch: 3362 [45568/60000 (76%)] Loss: -1539.600098\n",
      "Train Epoch: 3362 [56832/60000 (95%)] Loss: -1525.127686\n",
      "    epoch          : 3362\n",
      "    loss           : -1515.8926843330685\n",
      "Train Epoch: 3363 [512/60000 (1%)] Loss: -1467.445068\n",
      "Train Epoch: 3363 [11776/60000 (20%)] Loss: -1537.528076\n",
      "Train Epoch: 3363 [23040/60000 (38%)] Loss: -1451.568115\n",
      "Train Epoch: 3363 [34304/60000 (57%)] Loss: -1440.343628\n",
      "Train Epoch: 3363 [45568/60000 (76%)] Loss: -1586.056396\n",
      "Train Epoch: 3363 [56832/60000 (95%)] Loss: -1520.874512\n",
      "    epoch          : 3363\n",
      "    loss           : -1509.7310722049347\n",
      "Train Epoch: 3364 [512/60000 (1%)] Loss: -1586.857910\n",
      "Train Epoch: 3364 [11776/60000 (20%)] Loss: -1531.534424\n",
      "Train Epoch: 3364 [23040/60000 (38%)] Loss: -1562.706177\n",
      "Train Epoch: 3364 [34304/60000 (57%)] Loss: -1456.388550\n",
      "Train Epoch: 3364 [45568/60000 (76%)] Loss: -1535.676270\n",
      "Train Epoch: 3364 [56832/60000 (95%)] Loss: -1503.795654\n",
      "    epoch          : 3364\n",
      "    loss           : -1522.8811683439267\n",
      "Train Epoch: 3365 [512/60000 (1%)] Loss: -1482.314575\n",
      "Train Epoch: 3365 [11776/60000 (20%)] Loss: -1537.671875\n",
      "Train Epoch: 3365 [23040/60000 (38%)] Loss: -1494.163574\n",
      "Train Epoch: 3365 [34304/60000 (57%)] Loss: -1552.456665\n",
      "Train Epoch: 3365 [45568/60000 (76%)] Loss: -1567.074341\n",
      "Train Epoch: 3365 [56832/60000 (95%)] Loss: -1539.322754\n",
      "    epoch          : 3365\n",
      "    loss           : -1513.6617283363128\n",
      "Train Epoch: 3366 [512/60000 (1%)] Loss: -1553.114014\n",
      "Train Epoch: 3366 [11776/60000 (20%)] Loss: -1551.732178\n",
      "Train Epoch: 3366 [23040/60000 (38%)] Loss: -1503.650269\n",
      "Train Epoch: 3366 [34304/60000 (57%)] Loss: -1548.832886\n",
      "Train Epoch: 3366 [45568/60000 (76%)] Loss: -1462.108643\n",
      "Train Epoch: 3366 [56832/60000 (95%)] Loss: -1452.982300\n",
      "    epoch          : 3366\n",
      "    loss           : -1516.2303828869835\n",
      "Train Epoch: 3367 [512/60000 (1%)] Loss: -1529.809814\n",
      "Train Epoch: 3367 [11776/60000 (20%)] Loss: -1513.557251\n",
      "Train Epoch: 3367 [23040/60000 (38%)] Loss: -1574.829102\n",
      "Train Epoch: 3367 [34304/60000 (57%)] Loss: -1576.077271\n",
      "Train Epoch: 3367 [45568/60000 (76%)] Loss: -1572.600952\n",
      "Train Epoch: 3367 [56832/60000 (95%)] Loss: -1504.783569\n",
      "    epoch          : 3367\n",
      "    loss           : -1512.2677684719279\n",
      "Train Epoch: 3368 [512/60000 (1%)] Loss: -1433.365845\n",
      "Train Epoch: 3368 [11776/60000 (20%)] Loss: -1555.809692\n",
      "Train Epoch: 3368 [23040/60000 (38%)] Loss: -1517.702148\n",
      "Train Epoch: 3368 [34304/60000 (57%)] Loss: -1538.612549\n",
      "Train Epoch: 3368 [45568/60000 (76%)] Loss: -1498.200317\n",
      "Train Epoch: 3368 [56832/60000 (95%)] Loss: -1403.066650\n",
      "    epoch          : 3368\n",
      "    loss           : -1504.83922408799\n",
      "Train Epoch: 3369 [512/60000 (1%)] Loss: -1517.965454\n",
      "Train Epoch: 3369 [11776/60000 (20%)] Loss: -1458.088623\n",
      "Train Epoch: 3369 [23040/60000 (38%)] Loss: -1532.478882\n",
      "Train Epoch: 3369 [34304/60000 (57%)] Loss: -1518.867798\n",
      "Train Epoch: 3369 [45568/60000 (76%)] Loss: -1559.012817\n",
      "Train Epoch: 3369 [56832/60000 (95%)] Loss: -1478.374268\n",
      "    epoch          : 3369\n",
      "    loss           : -1507.252237955729\n",
      "Train Epoch: 3370 [512/60000 (1%)] Loss: -1562.796387\n",
      "Train Epoch: 3370 [11776/60000 (20%)] Loss: -1458.357178\n",
      "Train Epoch: 3370 [23040/60000 (38%)] Loss: -1558.708252\n",
      "Train Epoch: 3370 [34304/60000 (57%)] Loss: -1544.678345\n",
      "Train Epoch: 3370 [45568/60000 (76%)] Loss: -1545.210815\n",
      "Train Epoch: 3370 [56832/60000 (95%)] Loss: -1441.530151\n",
      "    epoch          : 3370\n",
      "    loss           : -1506.283326574638\n",
      "Train Epoch: 3371 [512/60000 (1%)] Loss: -1596.846313\n",
      "Train Epoch: 3371 [11776/60000 (20%)] Loss: -1476.751465\n",
      "Train Epoch: 3371 [23040/60000 (38%)] Loss: -1444.007690\n",
      "Train Epoch: 3371 [34304/60000 (57%)] Loss: -1456.990234\n",
      "Train Epoch: 3371 [45568/60000 (76%)] Loss: -1537.585449\n",
      "Train Epoch: 3371 [56832/60000 (95%)] Loss: -1501.304688\n",
      "    epoch          : 3371\n",
      "    loss           : -1512.9585443701449\n",
      "Train Epoch: 3372 [512/60000 (1%)] Loss: -1441.110352\n",
      "Train Epoch: 3372 [11776/60000 (20%)] Loss: -1567.453491\n",
      "Train Epoch: 3372 [23040/60000 (38%)] Loss: -1546.230469\n",
      "Train Epoch: 3372 [34304/60000 (57%)] Loss: -1570.928711\n",
      "Train Epoch: 3372 [45568/60000 (76%)] Loss: -1554.432983\n",
      "Train Epoch: 3372 [56832/60000 (95%)] Loss: -1538.856689\n",
      "    epoch          : 3372\n",
      "    loss           : -1518.5800701938779\n",
      "Train Epoch: 3373 [512/60000 (1%)] Loss: -1580.401123\n",
      "Train Epoch: 3373 [11776/60000 (20%)] Loss: -1601.710938\n",
      "Train Epoch: 3373 [23040/60000 (38%)] Loss: -1450.424316\n",
      "Train Epoch: 3373 [34304/60000 (57%)] Loss: -1549.508789\n",
      "Train Epoch: 3373 [45568/60000 (76%)] Loss: -1589.635620\n",
      "Train Epoch: 3373 [56832/60000 (95%)] Loss: -1554.341919\n",
      "    epoch          : 3373\n",
      "    loss           : -1520.4846087956832\n",
      "Train Epoch: 3374 [512/60000 (1%)] Loss: -1570.208984\n",
      "Train Epoch: 3374 [11776/60000 (20%)] Loss: -1594.761108\n",
      "Train Epoch: 3374 [23040/60000 (38%)] Loss: -1548.475098\n",
      "Train Epoch: 3374 [34304/60000 (57%)] Loss: -1579.472656\n",
      "Train Epoch: 3374 [45568/60000 (76%)] Loss: -1523.881714\n",
      "Train Epoch: 3374 [56832/60000 (95%)] Loss: -1525.061768\n",
      "    epoch          : 3374\n",
      "    loss           : -1508.6103350105932\n",
      "Train Epoch: 3375 [512/60000 (1%)] Loss: -1522.180908\n",
      "Train Epoch: 3375 [11776/60000 (20%)] Loss: -1496.339111\n",
      "Train Epoch: 3375 [23040/60000 (38%)] Loss: -1461.586670\n",
      "Train Epoch: 3375 [34304/60000 (57%)] Loss: -1571.361816\n",
      "Train Epoch: 3375 [45568/60000 (76%)] Loss: -1549.442139\n",
      "Train Epoch: 3375 [56832/60000 (95%)] Loss: -1507.841919\n",
      "    epoch          : 3375\n",
      "    loss           : -1511.331192275225\n",
      "Train Epoch: 3376 [512/60000 (1%)] Loss: -1590.868164\n",
      "Train Epoch: 3376 [11776/60000 (20%)] Loss: -1540.597168\n",
      "Train Epoch: 3376 [23040/60000 (38%)] Loss: -1447.233887\n",
      "Train Epoch: 3376 [34304/60000 (57%)] Loss: -1551.334473\n",
      "Train Epoch: 3376 [45568/60000 (76%)] Loss: -1383.126709\n",
      "Train Epoch: 3376 [56832/60000 (95%)] Loss: -1474.839233\n",
      "    epoch          : 3376\n",
      "    loss           : -1515.6290576309807\n",
      "Train Epoch: 3377 [512/60000 (1%)] Loss: -1440.323730\n",
      "Train Epoch: 3377 [11776/60000 (20%)] Loss: -1561.800659\n",
      "Train Epoch: 3377 [23040/60000 (38%)] Loss: -1515.595459\n",
      "Train Epoch: 3377 [34304/60000 (57%)] Loss: -1578.800293\n",
      "Train Epoch: 3377 [45568/60000 (76%)] Loss: -1570.885742\n",
      "Train Epoch: 3377 [56832/60000 (95%)] Loss: -1522.487061\n",
      "    epoch          : 3377\n",
      "    loss           : -1518.296900517523\n",
      "Train Epoch: 3378 [512/60000 (1%)] Loss: -1499.223633\n",
      "Train Epoch: 3378 [11776/60000 (20%)] Loss: -1537.379639\n",
      "Train Epoch: 3378 [23040/60000 (38%)] Loss: -1582.179077\n",
      "Train Epoch: 3378 [34304/60000 (57%)] Loss: -1561.270020\n",
      "Train Epoch: 3378 [45568/60000 (76%)] Loss: -1511.908936\n",
      "Train Epoch: 3378 [56832/60000 (95%)] Loss: -1419.641479\n",
      "    epoch          : 3378\n",
      "    loss           : -1520.8538411458335\n",
      "Train Epoch: 3379 [512/60000 (1%)] Loss: -1546.159912\n",
      "Train Epoch: 3379 [11776/60000 (20%)] Loss: -1459.859375\n",
      "Train Epoch: 3379 [23040/60000 (38%)] Loss: -1528.738159\n",
      "Train Epoch: 3379 [34304/60000 (57%)] Loss: -1588.634888\n",
      "Train Epoch: 3379 [45568/60000 (76%)] Loss: -1539.979614\n",
      "Train Epoch: 3379 [56832/60000 (95%)] Loss: -1559.997437\n",
      "    epoch          : 3379\n",
      "    loss           : -1515.6025656145173\n",
      "Train Epoch: 3380 [512/60000 (1%)] Loss: -1488.752563\n",
      "Train Epoch: 3380 [11776/60000 (20%)] Loss: -1440.037598\n",
      "Train Epoch: 3380 [23040/60000 (38%)] Loss: -1508.640137\n",
      "Train Epoch: 3380 [34304/60000 (57%)] Loss: -1489.310791\n",
      "Train Epoch: 3380 [45568/60000 (76%)] Loss: -1534.046387\n",
      "Train Epoch: 3380 [56832/60000 (95%)] Loss: -1569.694458\n",
      "    epoch          : 3380\n",
      "    loss           : -1518.4561464126502\n",
      "Train Epoch: 3381 [512/60000 (1%)] Loss: -1499.709351\n",
      "Train Epoch: 3381 [11776/60000 (20%)] Loss: -1470.727417\n",
      "Train Epoch: 3381 [23040/60000 (38%)] Loss: -1503.609619\n",
      "Train Epoch: 3381 [34304/60000 (57%)] Loss: -1556.279297\n",
      "Train Epoch: 3381 [45568/60000 (76%)] Loss: -1491.789673\n",
      "Train Epoch: 3381 [56832/60000 (95%)] Loss: -1604.580078\n",
      "    epoch          : 3381\n",
      "    loss           : -1516.7615708173332\n",
      "Train Epoch: 3382 [512/60000 (1%)] Loss: -1545.181519\n",
      "Train Epoch: 3382 [11776/60000 (20%)] Loss: -1507.944092\n",
      "Train Epoch: 3382 [23040/60000 (38%)] Loss: -1531.574951\n",
      "Train Epoch: 3382 [34304/60000 (57%)] Loss: -1605.742920\n",
      "Train Epoch: 3382 [45568/60000 (76%)] Loss: -1466.329590\n",
      "Train Epoch: 3382 [56832/60000 (95%)] Loss: -1503.438477\n",
      "    epoch          : 3382\n",
      "    loss           : -1520.9846005197298\n",
      "Train Epoch: 3383 [512/60000 (1%)] Loss: -1454.780518\n",
      "Train Epoch: 3383 [11776/60000 (20%)] Loss: -1546.354004\n",
      "Train Epoch: 3383 [23040/60000 (38%)] Loss: -1469.319092\n",
      "Train Epoch: 3383 [34304/60000 (57%)] Loss: -1479.758179\n",
      "Train Epoch: 3383 [45568/60000 (76%)] Loss: -1533.603882\n",
      "Train Epoch: 3383 [56832/60000 (95%)] Loss: -1550.565430\n",
      "    epoch          : 3383\n",
      "    loss           : -1513.1503926939884\n",
      "Train Epoch: 3384 [512/60000 (1%)] Loss: -1595.950317\n",
      "Train Epoch: 3384 [11776/60000 (20%)] Loss: -1538.593018\n",
      "Train Epoch: 3384 [23040/60000 (38%)] Loss: -1521.008301\n",
      "Train Epoch: 3384 [34304/60000 (57%)] Loss: -1534.041870\n",
      "Train Epoch: 3384 [45568/60000 (76%)] Loss: -1463.826904\n",
      "Train Epoch: 3384 [56832/60000 (95%)] Loss: -1548.250732\n",
      "    epoch          : 3384\n",
      "    loss           : -1515.2230859099134\n",
      "Train Epoch: 3385 [512/60000 (1%)] Loss: -1482.068848\n",
      "Train Epoch: 3385 [11776/60000 (20%)] Loss: -1504.600586\n",
      "Train Epoch: 3385 [23040/60000 (38%)] Loss: -1492.958252\n",
      "Train Epoch: 3385 [34304/60000 (57%)] Loss: -1517.455322\n",
      "Train Epoch: 3385 [45568/60000 (76%)] Loss: -1576.968018\n",
      "Train Epoch: 3385 [56832/60000 (95%)] Loss: -1463.190186\n",
      "    epoch          : 3385\n",
      "    loss           : -1518.1428508866306\n",
      "Train Epoch: 3386 [512/60000 (1%)] Loss: -1470.168701\n",
      "Train Epoch: 3386 [11776/60000 (20%)] Loss: -1520.806274\n",
      "Train Epoch: 3386 [23040/60000 (38%)] Loss: -1507.019043\n",
      "Train Epoch: 3386 [34304/60000 (57%)] Loss: -1510.371826\n",
      "Train Epoch: 3386 [45568/60000 (76%)] Loss: -1471.885132\n",
      "Train Epoch: 3386 [56832/60000 (95%)] Loss: -1557.616699\n",
      "    epoch          : 3386\n",
      "    loss           : -1514.0703228449418\n",
      "Train Epoch: 3387 [512/60000 (1%)] Loss: -1482.054199\n",
      "Train Epoch: 3387 [11776/60000 (20%)] Loss: -1535.209229\n",
      "Train Epoch: 3387 [23040/60000 (38%)] Loss: -1469.336426\n",
      "Train Epoch: 3387 [34304/60000 (57%)] Loss: -1468.395264\n",
      "Train Epoch: 3387 [45568/60000 (76%)] Loss: -1514.818848\n",
      "Train Epoch: 3387 [56832/60000 (95%)] Loss: -1466.972412\n",
      "    epoch          : 3387\n",
      "    loss           : -1507.965761346332\n",
      "Train Epoch: 3388 [512/60000 (1%)] Loss: -1401.241943\n",
      "Train Epoch: 3388 [11776/60000 (20%)] Loss: -1476.126343\n",
      "Train Epoch: 3388 [23040/60000 (38%)] Loss: -1588.854126\n",
      "Train Epoch: 3388 [34304/60000 (57%)] Loss: -1465.322144\n",
      "Train Epoch: 3388 [45568/60000 (76%)] Loss: -1578.256226\n",
      "Train Epoch: 3388 [56832/60000 (95%)] Loss: -1541.695312\n",
      "    epoch          : 3388\n",
      "    loss           : -1514.2323263567048\n",
      "Train Epoch: 3389 [512/60000 (1%)] Loss: -1452.742432\n",
      "Train Epoch: 3389 [11776/60000 (20%)] Loss: -1548.699341\n",
      "Train Epoch: 3389 [23040/60000 (38%)] Loss: -1479.194336\n",
      "Train Epoch: 3389 [34304/60000 (57%)] Loss: -1465.812256\n",
      "Train Epoch: 3389 [45568/60000 (76%)] Loss: -1563.147583\n",
      "Train Epoch: 3389 [56832/60000 (95%)] Loss: -1541.844604\n",
      "    epoch          : 3389\n",
      "    loss           : -1516.5055390266375\n",
      "Train Epoch: 3390 [512/60000 (1%)] Loss: -1535.675781\n",
      "Train Epoch: 3390 [11776/60000 (20%)] Loss: -1535.599121\n",
      "Train Epoch: 3390 [23040/60000 (38%)] Loss: -1544.857178\n",
      "Train Epoch: 3390 [34304/60000 (57%)] Loss: -1533.381104\n",
      "Train Epoch: 3390 [45568/60000 (76%)] Loss: -1504.530762\n",
      "Train Epoch: 3390 [56832/60000 (95%)] Loss: -1531.350464\n",
      "    epoch          : 3390\n",
      "    loss           : -1518.3446769067796\n",
      "Train Epoch: 3391 [512/60000 (1%)] Loss: -1525.492310\n",
      "Train Epoch: 3391 [11776/60000 (20%)] Loss: -1494.620117\n",
      "Train Epoch: 3391 [23040/60000 (38%)] Loss: -1559.567139\n",
      "Train Epoch: 3391 [34304/60000 (57%)] Loss: -1558.561768\n",
      "Train Epoch: 3391 [45568/60000 (76%)] Loss: -1444.382080\n",
      "Train Epoch: 3391 [56832/60000 (95%)] Loss: -1551.701172\n",
      "    epoch          : 3391\n",
      "    loss           : -1511.0407904501014\n",
      "Train Epoch: 3392 [512/60000 (1%)] Loss: -1505.010010\n",
      "Train Epoch: 3392 [11776/60000 (20%)] Loss: -1441.698242\n",
      "Train Epoch: 3392 [23040/60000 (38%)] Loss: -1577.674561\n",
      "Train Epoch: 3392 [34304/60000 (57%)] Loss: -1556.749023\n",
      "Train Epoch: 3392 [45568/60000 (76%)] Loss: -1514.827026\n",
      "Train Epoch: 3392 [56832/60000 (95%)] Loss: -1571.181396\n",
      "    epoch          : 3392\n",
      "    loss           : -1520.8249118610963\n",
      "Train Epoch: 3393 [512/60000 (1%)] Loss: -1529.005005\n",
      "Train Epoch: 3393 [11776/60000 (20%)] Loss: -1399.318604\n",
      "Train Epoch: 3393 [23040/60000 (38%)] Loss: -1484.155640\n",
      "Train Epoch: 3393 [34304/60000 (57%)] Loss: -1510.195068\n",
      "Train Epoch: 3393 [45568/60000 (76%)] Loss: -1574.346436\n",
      "Train Epoch: 3393 [56832/60000 (95%)] Loss: -1576.360718\n",
      "    epoch          : 3393\n",
      "    loss           : -1510.288135248389\n",
      "Train Epoch: 3394 [512/60000 (1%)] Loss: -1579.551392\n",
      "Train Epoch: 3394 [11776/60000 (20%)] Loss: -1516.690674\n",
      "Train Epoch: 3394 [23040/60000 (38%)] Loss: -1421.234131\n",
      "Train Epoch: 3394 [34304/60000 (57%)] Loss: -1560.275146\n",
      "Train Epoch: 3394 [45568/60000 (76%)] Loss: -1568.752930\n",
      "Train Epoch: 3394 [56832/60000 (95%)] Loss: -1517.521851\n",
      "    epoch          : 3394\n",
      "    loss           : -1513.4523560259977\n",
      "Train Epoch: 3395 [512/60000 (1%)] Loss: -1383.705811\n",
      "Train Epoch: 3395 [11776/60000 (20%)] Loss: -1532.625366\n",
      "Train Epoch: 3395 [23040/60000 (38%)] Loss: -1568.902466\n",
      "Train Epoch: 3395 [34304/60000 (57%)] Loss: -1491.434692\n",
      "Train Epoch: 3395 [45568/60000 (76%)] Loss: -1448.789185\n",
      "Train Epoch: 3395 [56832/60000 (95%)] Loss: -1522.677246\n",
      "    epoch          : 3395\n",
      "    loss           : -1514.2981743246821\n",
      "Train Epoch: 3396 [512/60000 (1%)] Loss: -1500.959106\n",
      "Train Epoch: 3396 [11776/60000 (20%)] Loss: -1526.361084\n",
      "Train Epoch: 3396 [23040/60000 (38%)] Loss: -1591.827026\n",
      "Train Epoch: 3396 [34304/60000 (57%)] Loss: -1567.308105\n",
      "Train Epoch: 3396 [45568/60000 (76%)] Loss: -1502.277832\n",
      "Train Epoch: 3396 [56832/60000 (95%)] Loss: -1485.525269\n",
      "    epoch          : 3396\n",
      "    loss           : -1524.185992741989\n",
      "Train Epoch: 3397 [512/60000 (1%)] Loss: -1492.770996\n",
      "Train Epoch: 3397 [11776/60000 (20%)] Loss: -1490.314941\n",
      "Train Epoch: 3397 [23040/60000 (38%)] Loss: -1591.105103\n",
      "Train Epoch: 3397 [34304/60000 (57%)] Loss: -1574.962402\n",
      "Train Epoch: 3397 [45568/60000 (76%)] Loss: -1471.142334\n",
      "Train Epoch: 3397 [56832/60000 (95%)] Loss: -1511.840088\n",
      "    epoch          : 3397\n",
      "    loss           : -1520.130631096619\n",
      "Train Epoch: 3398 [512/60000 (1%)] Loss: -1526.276123\n",
      "Train Epoch: 3398 [11776/60000 (20%)] Loss: -1473.658203\n",
      "Train Epoch: 3398 [23040/60000 (38%)] Loss: -1583.213623\n",
      "Train Epoch: 3398 [34304/60000 (57%)] Loss: -1518.282959\n",
      "Train Epoch: 3398 [45568/60000 (76%)] Loss: -1440.373779\n",
      "Train Epoch: 3398 [56832/60000 (95%)] Loss: -1522.698975\n",
      "    epoch          : 3398\n",
      "    loss           : -1520.487058822718\n",
      "Train Epoch: 3399 [512/60000 (1%)] Loss: -1546.007812\n",
      "Train Epoch: 3399 [11776/60000 (20%)] Loss: -1534.622070\n",
      "Train Epoch: 3399 [23040/60000 (38%)] Loss: -1514.871094\n",
      "Train Epoch: 3399 [34304/60000 (57%)] Loss: -1474.531006\n",
      "Train Epoch: 3399 [45568/60000 (76%)] Loss: -1559.783691\n",
      "Train Epoch: 3399 [56832/60000 (95%)] Loss: -1519.525635\n",
      "    epoch          : 3399\n",
      "    loss           : -1517.608422230866\n",
      "Train Epoch: 3400 [512/60000 (1%)] Loss: -1564.618530\n",
      "Train Epoch: 3400 [11776/60000 (20%)] Loss: -1612.472900\n",
      "Train Epoch: 3400 [23040/60000 (38%)] Loss: -1468.883301\n",
      "Train Epoch: 3400 [34304/60000 (57%)] Loss: -1463.941406\n",
      "Train Epoch: 3400 [45568/60000 (76%)] Loss: -1481.804077\n",
      "Train Epoch: 3400 [56832/60000 (95%)] Loss: -1582.268188\n",
      "    epoch          : 3400\n",
      "    loss           : -1520.6102974239716\n",
      "Saving checkpoint: saved/models/Mnist_DeepGenerativeOperad/0127_111843/checkpoint-epoch3400.pth ...\n",
      "Train Epoch: 3401 [512/60000 (1%)] Loss: -1499.044434\n",
      "Train Epoch: 3401 [11776/60000 (20%)] Loss: -1530.399414\n",
      "Train Epoch: 3401 [23040/60000 (38%)] Loss: -1525.732178\n",
      "Train Epoch: 3401 [34304/60000 (57%)] Loss: -1575.272217\n",
      "Train Epoch: 3401 [45568/60000 (76%)] Loss: -1539.938965\n",
      "Train Epoch: 3401 [56832/60000 (95%)] Loss: -1564.675049\n",
      "    epoch          : 3401\n",
      "    loss           : -1521.0684079962261\n",
      "Train Epoch: 3402 [512/60000 (1%)] Loss: -1553.548096\n",
      "Train Epoch: 3402 [11776/60000 (20%)] Loss: -1534.005005\n",
      "Train Epoch: 3402 [23040/60000 (38%)] Loss: -1569.345703\n",
      "Train Epoch: 3402 [34304/60000 (57%)] Loss: -1482.651123\n",
      "Train Epoch: 3402 [45568/60000 (76%)] Loss: -1524.505371\n",
      "Train Epoch: 3402 [56832/60000 (95%)] Loss: -1613.778076\n",
      "    epoch          : 3402\n",
      "    loss           : -1520.998051357808\n",
      "Train Epoch: 3403 [512/60000 (1%)] Loss: -1449.873047\n",
      "Train Epoch: 3403 [11776/60000 (20%)] Loss: -1485.299438\n",
      "Train Epoch: 3403 [23040/60000 (38%)] Loss: -1447.393799\n",
      "Train Epoch: 3403 [34304/60000 (57%)] Loss: -1556.052246\n",
      "Train Epoch: 3403 [45568/60000 (76%)] Loss: -1453.834717\n",
      "Train Epoch: 3403 [56832/60000 (95%)] Loss: -1584.549194\n",
      "    epoch          : 3403\n",
      "    loss           : -1515.62164892854\n",
      "Train Epoch: 3404 [512/60000 (1%)] Loss: -1521.559937\n",
      "Train Epoch: 3404 [11776/60000 (20%)] Loss: -1586.963745\n",
      "Train Epoch: 3404 [23040/60000 (38%)] Loss: -1512.600342\n",
      "Train Epoch: 3404 [34304/60000 (57%)] Loss: -1408.334473\n",
      "Train Epoch: 3404 [45568/60000 (76%)] Loss: -1496.070801\n",
      "Train Epoch: 3404 [56832/60000 (95%)] Loss: -1543.723022\n",
      "    epoch          : 3404\n",
      "    loss           : -1512.8980454267082\n",
      "Train Epoch: 3405 [512/60000 (1%)] Loss: -1494.330566\n",
      "Train Epoch: 3405 [11776/60000 (20%)] Loss: -1510.865479\n",
      "Train Epoch: 3405 [23040/60000 (38%)] Loss: -1448.484863\n",
      "Train Epoch: 3405 [34304/60000 (57%)] Loss: -1581.902588\n",
      "Train Epoch: 3405 [45568/60000 (76%)] Loss: -1521.027588\n",
      "Train Epoch: 3405 [56832/60000 (95%)] Loss: -1534.561035\n",
      "    epoch          : 3405\n",
      "    loss           : -1512.6028497555835\n",
      "Train Epoch: 3406 [512/60000 (1%)] Loss: -1426.221191\n",
      "Train Epoch: 3406 [11776/60000 (20%)] Loss: -1497.104736\n",
      "Train Epoch: 3406 [23040/60000 (38%)] Loss: -1580.970825\n",
      "Train Epoch: 3406 [34304/60000 (57%)] Loss: -1576.131348\n",
      "Train Epoch: 3406 [45568/60000 (76%)] Loss: -1503.252563\n",
      "Train Epoch: 3406 [56832/60000 (95%)] Loss: -1509.254395\n",
      "    epoch          : 3406\n",
      "    loss           : -1518.7712416137006\n",
      "Train Epoch: 3407 [512/60000 (1%)] Loss: -1464.789185\n",
      "Train Epoch: 3407 [11776/60000 (20%)] Loss: -1591.919189\n",
      "Train Epoch: 3407 [23040/60000 (38%)] Loss: -1565.864990\n",
      "Train Epoch: 3407 [34304/60000 (57%)] Loss: -1421.981445\n",
      "Train Epoch: 3407 [45568/60000 (76%)] Loss: -1453.242188\n",
      "Train Epoch: 3407 [56832/60000 (95%)] Loss: -1532.650635\n",
      "    epoch          : 3407\n",
      "    loss           : -1511.266022590594\n",
      "Train Epoch: 3408 [512/60000 (1%)] Loss: -1473.983887\n",
      "Train Epoch: 3408 [11776/60000 (20%)] Loss: -1438.488037\n",
      "Train Epoch: 3408 [23040/60000 (38%)] Loss: -1529.219971\n",
      "Train Epoch: 3408 [34304/60000 (57%)] Loss: -1486.432373\n",
      "Train Epoch: 3408 [45568/60000 (76%)] Loss: -1565.526245\n",
      "Train Epoch: 3408 [56832/60000 (95%)] Loss: -1506.083496\n",
      "    epoch          : 3408\n",
      "    loss           : -1514.9666758391816\n",
      "Train Epoch: 3409 [512/60000 (1%)] Loss: -1556.946777\n",
      "Train Epoch: 3409 [11776/60000 (20%)] Loss: -1535.955933\n",
      "Train Epoch: 3409 [23040/60000 (38%)] Loss: -1541.091431\n",
      "Train Epoch: 3409 [34304/60000 (57%)] Loss: -1440.525757\n",
      "Train Epoch: 3409 [45568/60000 (76%)] Loss: -1480.037109\n",
      "Train Epoch: 3409 [56832/60000 (95%)] Loss: -1443.023926\n",
      "    epoch          : 3409\n",
      "    loss           : -1519.3472248659295\n",
      "Train Epoch: 3410 [512/60000 (1%)] Loss: -1518.057251\n",
      "Train Epoch: 3410 [11776/60000 (20%)] Loss: -1502.695679\n",
      "Train Epoch: 3410 [23040/60000 (38%)] Loss: -1434.852661\n",
      "Train Epoch: 3410 [34304/60000 (57%)] Loss: -1576.377197\n",
      "Train Epoch: 3410 [45568/60000 (76%)] Loss: -1545.582275\n",
      "Train Epoch: 3410 [56832/60000 (95%)] Loss: -1557.121338\n",
      "    epoch          : 3410\n",
      "    loss           : -1520.0114604712878\n",
      "Train Epoch: 3411 [512/60000 (1%)] Loss: -1562.837891\n",
      "Train Epoch: 3411 [11776/60000 (20%)] Loss: -1548.163940\n",
      "Train Epoch: 3411 [23040/60000 (38%)] Loss: -1483.558350\n",
      "Train Epoch: 3411 [34304/60000 (57%)] Loss: -1475.728760\n",
      "Train Epoch: 3411 [45568/60000 (76%)] Loss: -1520.546997\n",
      "Train Epoch: 3411 [56832/60000 (95%)] Loss: -1563.074951\n",
      "    epoch          : 3411\n",
      "    loss           : -1510.7340429273702\n",
      "Train Epoch: 3412 [512/60000 (1%)] Loss: -1587.172485\n",
      "Train Epoch: 3412 [11776/60000 (20%)] Loss: -1554.286621\n",
      "Train Epoch: 3412 [23040/60000 (38%)] Loss: -1511.145508\n",
      "Train Epoch: 3412 [34304/60000 (57%)] Loss: -1572.352051\n",
      "Train Epoch: 3412 [45568/60000 (76%)] Loss: -1383.982056\n",
      "Train Epoch: 3412 [56832/60000 (95%)] Loss: -1440.995728\n",
      "    epoch          : 3412\n",
      "    loss           : -1519.6043342547227\n",
      "Train Epoch: 3413 [512/60000 (1%)] Loss: -1520.178223\n",
      "Train Epoch: 3413 [11776/60000 (20%)] Loss: -1535.127441\n",
      "Train Epoch: 3413 [23040/60000 (38%)] Loss: -1478.861572\n",
      "Train Epoch: 3413 [34304/60000 (57%)] Loss: -1580.303223\n",
      "Train Epoch: 3413 [45568/60000 (76%)] Loss: -1516.235596\n",
      "Train Epoch: 3413 [56832/60000 (95%)] Loss: -1549.612305\n",
      "    epoch          : 3413\n",
      "    loss           : -1520.9354010113216\n",
      "Train Epoch: 3414 [512/60000 (1%)] Loss: -1577.720703\n",
      "Train Epoch: 3414 [11776/60000 (20%)] Loss: -1551.595825\n",
      "Train Epoch: 3414 [23040/60000 (38%)] Loss: -1545.698975\n",
      "Train Epoch: 3414 [34304/60000 (57%)] Loss: -1507.884644\n",
      "Train Epoch: 3414 [45568/60000 (76%)] Loss: -1431.640381\n",
      "Train Epoch: 3414 [56832/60000 (95%)] Loss: -1535.318848\n",
      "    epoch          : 3414\n",
      "    loss           : -1522.369105452198\n",
      "Train Epoch: 3415 [512/60000 (1%)] Loss: -1479.127563\n",
      "Train Epoch: 3415 [11776/60000 (20%)] Loss: -1505.896973\n",
      "Train Epoch: 3415 [23040/60000 (38%)] Loss: -1545.221191\n",
      "Train Epoch: 3415 [34304/60000 (57%)] Loss: -1378.489746\n",
      "Train Epoch: 3415 [45568/60000 (76%)] Loss: -1533.145752\n",
      "Train Epoch: 3415 [56832/60000 (95%)] Loss: -1564.009277\n",
      "    epoch          : 3415\n",
      "    loss           : -1523.0402987205375\n",
      "Train Epoch: 3416 [512/60000 (1%)] Loss: -1506.532837\n",
      "Train Epoch: 3416 [11776/60000 (20%)] Loss: -1456.165527\n",
      "Train Epoch: 3416 [23040/60000 (38%)] Loss: -1495.015503\n",
      "Train Epoch: 3416 [34304/60000 (57%)] Loss: -1540.073975\n",
      "Train Epoch: 3416 [45568/60000 (76%)] Loss: -1403.782227\n",
      "Train Epoch: 3416 [56832/60000 (95%)] Loss: -1556.514160\n",
      "    epoch          : 3416\n",
      "    loss           : -1512.002959687831\n",
      "Train Epoch: 3417 [512/60000 (1%)] Loss: -1412.730347\n",
      "Train Epoch: 3417 [11776/60000 (20%)] Loss: -1538.627930\n",
      "Train Epoch: 3417 [23040/60000 (38%)] Loss: -1511.194092\n",
      "Train Epoch: 3417 [34304/60000 (57%)] Loss: -1548.231934\n",
      "Train Epoch: 3417 [45568/60000 (76%)] Loss: -1520.207031\n",
      "Train Epoch: 3417 [56832/60000 (95%)] Loss: -1577.231689\n",
      "    epoch          : 3417\n",
      "    loss           : -1516.5213157524497\n",
      "Train Epoch: 3418 [512/60000 (1%)] Loss: -1514.682251\n",
      "Train Epoch: 3418 [11776/60000 (20%)] Loss: -1433.298096\n",
      "Train Epoch: 3418 [23040/60000 (38%)] Loss: -1500.020630\n",
      "Train Epoch: 3418 [34304/60000 (57%)] Loss: -1609.562256\n",
      "Train Epoch: 3418 [45568/60000 (76%)] Loss: -1477.139160\n",
      "Train Epoch: 3418 [56832/60000 (95%)] Loss: -1535.586914\n",
      "    epoch          : 3418\n",
      "    loss           : -1511.8603732868776\n",
      "Train Epoch: 3419 [512/60000 (1%)] Loss: -1504.543945\n",
      "Train Epoch: 3419 [11776/60000 (20%)] Loss: -1520.113037\n",
      "Train Epoch: 3419 [23040/60000 (38%)] Loss: -1466.897583\n",
      "Train Epoch: 3419 [34304/60000 (57%)] Loss: -1496.153809\n",
      "Train Epoch: 3419 [45568/60000 (76%)] Loss: -1515.913208\n",
      "Train Epoch: 3419 [56832/60000 (95%)] Loss: -1538.135986\n",
      "    epoch          : 3419\n",
      "    loss           : -1513.682112009512\n",
      "Train Epoch: 3420 [512/60000 (1%)] Loss: -1580.850098\n",
      "Train Epoch: 3420 [11776/60000 (20%)] Loss: -1547.721558\n",
      "Train Epoch: 3420 [23040/60000 (38%)] Loss: -1557.840942\n",
      "Train Epoch: 3420 [34304/60000 (57%)] Loss: -1557.375610\n",
      "Train Epoch: 3420 [45568/60000 (76%)] Loss: -1583.622681\n",
      "Train Epoch: 3420 [56832/60000 (95%)] Loss: -1552.946045\n",
      "    epoch          : 3420\n",
      "    loss           : -1514.6103381140758\n",
      "Train Epoch: 3421 [512/60000 (1%)] Loss: -1594.957031\n",
      "Train Epoch: 3421 [11776/60000 (20%)] Loss: -1531.097168\n",
      "Train Epoch: 3421 [23040/60000 (38%)] Loss: -1462.647461\n",
      "Train Epoch: 3421 [34304/60000 (57%)] Loss: -1497.894775\n",
      "Train Epoch: 3421 [45568/60000 (76%)] Loss: -1537.451050\n",
      "Train Epoch: 3421 [56832/60000 (95%)] Loss: -1539.777588\n",
      "    epoch          : 3421\n",
      "    loss           : -1517.7646570582847\n",
      "Train Epoch: 3422 [512/60000 (1%)] Loss: -1453.079102\n",
      "Train Epoch: 3422 [11776/60000 (20%)] Loss: -1555.934082\n",
      "Train Epoch: 3422 [23040/60000 (38%)] Loss: -1511.508179\n",
      "Train Epoch: 3422 [34304/60000 (57%)] Loss: -1451.775391\n",
      "Train Epoch: 3422 [45568/60000 (76%)] Loss: -1525.381836\n",
      "Train Epoch: 3422 [56832/60000 (95%)] Loss: -1451.444702\n",
      "    epoch          : 3422\n",
      "    loss           : -1523.424392269156\n",
      "Train Epoch: 3423 [512/60000 (1%)] Loss: -1441.904785\n",
      "Train Epoch: 3423 [11776/60000 (20%)] Loss: -1538.270142\n",
      "Train Epoch: 3423 [23040/60000 (38%)] Loss: -1505.278198\n",
      "Train Epoch: 3423 [34304/60000 (57%)] Loss: -1548.130493\n",
      "Train Epoch: 3423 [45568/60000 (76%)] Loss: -1586.841797\n",
      "Train Epoch: 3423 [56832/60000 (95%)] Loss: -1508.262329\n",
      "    epoch          : 3423\n",
      "    loss           : -1523.7700260830463\n",
      "Train Epoch: 3424 [512/60000 (1%)] Loss: -1505.547363\n",
      "Train Epoch: 3424 [11776/60000 (20%)] Loss: -1546.222290\n",
      "Train Epoch: 3424 [23040/60000 (38%)] Loss: -1491.256714\n",
      "Train Epoch: 3424 [34304/60000 (57%)] Loss: -1421.834106\n",
      "Train Epoch: 3424 [45568/60000 (76%)] Loss: -1584.812744\n",
      "Train Epoch: 3424 [56832/60000 (95%)] Loss: -1424.491943\n",
      "    epoch          : 3424\n",
      "    loss           : -1521.5634400103727\n",
      "Train Epoch: 3425 [512/60000 (1%)] Loss: -1464.273560\n",
      "Train Epoch: 3425 [11776/60000 (20%)] Loss: -1575.801880\n",
      "Train Epoch: 3425 [23040/60000 (38%)] Loss: -1439.290283\n",
      "Train Epoch: 3425 [34304/60000 (57%)] Loss: -1442.471191\n",
      "Train Epoch: 3425 [45568/60000 (76%)] Loss: -1499.523560\n",
      "Train Epoch: 3425 [56832/60000 (95%)] Loss: -1498.567627\n",
      "    epoch          : 3425\n",
      "    loss           : -1520.5149443028338\n",
      "Train Epoch: 3426 [512/60000 (1%)] Loss: -1446.817139\n",
      "Train Epoch: 3426 [11776/60000 (20%)] Loss: -1489.006714\n",
      "Train Epoch: 3426 [23040/60000 (38%)] Loss: -1508.011597\n",
      "Train Epoch: 3426 [34304/60000 (57%)] Loss: -1583.262207\n",
      "Train Epoch: 3426 [45568/60000 (76%)] Loss: -1511.267456\n",
      "Train Epoch: 3426 [56832/60000 (95%)] Loss: -1465.414795\n",
      "    epoch          : 3426\n",
      "    loss           : -1519.2278769972636\n",
      "Train Epoch: 3427 [512/60000 (1%)] Loss: -1498.407593\n",
      "Train Epoch: 3427 [11776/60000 (20%)] Loss: -1521.942383\n",
      "Train Epoch: 3427 [23040/60000 (38%)] Loss: -1447.251221\n",
      "Train Epoch: 3427 [34304/60000 (57%)] Loss: -1470.547363\n",
      "Train Epoch: 3427 [45568/60000 (76%)] Loss: -1507.477539\n",
      "Train Epoch: 3427 [56832/60000 (95%)] Loss: -1451.201904\n",
      "    epoch          : 3427\n",
      "    loss           : -1509.0575664972855\n",
      "Train Epoch: 3428 [512/60000 (1%)] Loss: -1558.908325\n",
      "Train Epoch: 3428 [11776/60000 (20%)] Loss: -1452.216675\n",
      "Train Epoch: 3428 [23040/60000 (38%)] Loss: -1585.457520\n",
      "Train Epoch: 3428 [34304/60000 (57%)] Loss: -1442.731689\n",
      "Train Epoch: 3428 [45568/60000 (76%)] Loss: -1542.748291\n",
      "Train Epoch: 3428 [56832/60000 (95%)] Loss: -1483.060547\n",
      "    epoch          : 3428\n",
      "    loss           : -1521.7654101700432\n",
      "Train Epoch: 3429 [512/60000 (1%)] Loss: -1543.535767\n",
      "Train Epoch: 3429 [11776/60000 (20%)] Loss: -1423.029419\n",
      "Train Epoch: 3429 [23040/60000 (38%)] Loss: -1580.870361\n",
      "Train Epoch: 3429 [34304/60000 (57%)] Loss: -1560.395630\n",
      "Train Epoch: 3429 [45568/60000 (76%)] Loss: -1522.133545\n",
      "Train Epoch: 3429 [56832/60000 (95%)] Loss: -1568.903564\n",
      "    epoch          : 3429\n",
      "    loss           : -1528.6342514813957\n",
      "Train Epoch: 3430 [512/60000 (1%)] Loss: -1578.733887\n",
      "Train Epoch: 3430 [11776/60000 (20%)] Loss: -1522.579834\n",
      "Train Epoch: 3430 [23040/60000 (38%)] Loss: -1568.121338\n",
      "Train Epoch: 3430 [34304/60000 (57%)] Loss: -1559.258911\n",
      "Train Epoch: 3430 [45568/60000 (76%)] Loss: -1519.658447\n",
      "Train Epoch: 3430 [56832/60000 (95%)] Loss: -1523.542236\n",
      "    epoch          : 3430\n",
      "    loss           : -1520.1722712112685\n",
      "Train Epoch: 3431 [512/60000 (1%)] Loss: -1571.150391\n",
      "Train Epoch: 3431 [11776/60000 (20%)] Loss: -1509.195557\n",
      "Train Epoch: 3431 [23040/60000 (38%)] Loss: -1402.768433\n",
      "Train Epoch: 3431 [34304/60000 (57%)] Loss: -1473.352905\n",
      "Train Epoch: 3431 [45568/60000 (76%)] Loss: -1541.291260\n",
      "Train Epoch: 3431 [56832/60000 (95%)] Loss: -1596.213257\n",
      "    epoch          : 3431\n",
      "    loss           : -1514.6664301123324\n",
      "Train Epoch: 3432 [512/60000 (1%)] Loss: -1539.366211\n",
      "Train Epoch: 3432 [11776/60000 (20%)] Loss: -1460.555664\n",
      "Train Epoch: 3432 [23040/60000 (38%)] Loss: -1490.477051\n",
      "Train Epoch: 3432 [34304/60000 (57%)] Loss: -1539.723022\n",
      "Train Epoch: 3432 [45568/60000 (76%)] Loss: -1527.737305\n",
      "Train Epoch: 3432 [56832/60000 (95%)] Loss: -1480.097656\n",
      "    epoch          : 3432\n",
      "    loss           : -1522.7028832731946\n",
      "Train Epoch: 3433 [512/60000 (1%)] Loss: -1545.798950\n",
      "Train Epoch: 3433 [11776/60000 (20%)] Loss: -1558.712891\n",
      "Train Epoch: 3433 [23040/60000 (38%)] Loss: -1419.391357\n",
      "Train Epoch: 3433 [34304/60000 (57%)] Loss: -1557.065430\n",
      "Train Epoch: 3433 [45568/60000 (76%)] Loss: -1503.506348\n",
      "Train Epoch: 3433 [56832/60000 (95%)] Loss: -1533.760620\n",
      "    epoch          : 3433\n",
      "    loss           : -1519.1775419590838\n",
      "Train Epoch: 3434 [512/60000 (1%)] Loss: -1538.970703\n",
      "Train Epoch: 3434 [11776/60000 (20%)] Loss: -1549.948853\n",
      "Train Epoch: 3434 [23040/60000 (38%)] Loss: -1462.046021\n",
      "Train Epoch: 3434 [34304/60000 (57%)] Loss: -1445.374268\n",
      "Train Epoch: 3434 [45568/60000 (76%)] Loss: -1557.773682\n",
      "Train Epoch: 3434 [56832/60000 (95%)] Loss: -1455.848999\n",
      "    epoch          : 3434\n",
      "    loss           : -1519.162490068856\n",
      "Train Epoch: 3435 [512/60000 (1%)] Loss: -1450.796143\n",
      "Train Epoch: 3435 [11776/60000 (20%)] Loss: -1531.631470\n",
      "Train Epoch: 3435 [23040/60000 (38%)] Loss: -1603.808350\n",
      "Train Epoch: 3435 [34304/60000 (57%)] Loss: -1486.808716\n",
      "Train Epoch: 3435 [45568/60000 (76%)] Loss: -1520.511475\n",
      "Train Epoch: 3435 [56832/60000 (95%)] Loss: -1491.730469\n",
      "    epoch          : 3435\n",
      "    loss           : -1518.471936242055\n",
      "Train Epoch: 3436 [512/60000 (1%)] Loss: -1455.888794\n",
      "Train Epoch: 3436 [11776/60000 (20%)] Loss: -1442.081665\n",
      "Train Epoch: 3436 [23040/60000 (38%)] Loss: -1516.316040\n",
      "Train Epoch: 3436 [34304/60000 (57%)] Loss: -1565.053711\n",
      "Train Epoch: 3436 [45568/60000 (76%)] Loss: -1527.001709\n",
      "Train Epoch: 3436 [56832/60000 (95%)] Loss: -1450.700317\n",
      "    epoch          : 3436\n",
      "    loss           : -1521.3455455370542\n",
      "Train Epoch: 3437 [512/60000 (1%)] Loss: -1448.136963\n",
      "Train Epoch: 3437 [11776/60000 (20%)] Loss: -1504.069214\n",
      "Train Epoch: 3437 [23040/60000 (38%)] Loss: -1523.384766\n",
      "Train Epoch: 3437 [34304/60000 (57%)] Loss: -1516.420044\n",
      "Train Epoch: 3437 [45568/60000 (76%)] Loss: -1496.604736\n",
      "Train Epoch: 3437 [56832/60000 (95%)] Loss: -1431.989868\n",
      "    epoch          : 3437\n",
      "    loss           : -1519.9967199638065\n",
      "Train Epoch: 3438 [512/60000 (1%)] Loss: -1508.769531\n",
      "Train Epoch: 3438 [11776/60000 (20%)] Loss: -1529.172241\n",
      "Train Epoch: 3438 [23040/60000 (38%)] Loss: -1529.743042\n",
      "Train Epoch: 3438 [34304/60000 (57%)] Loss: -1533.560059\n",
      "Train Epoch: 3438 [45568/60000 (76%)] Loss: -1602.533813\n",
      "Train Epoch: 3438 [56832/60000 (95%)] Loss: -1445.652832\n",
      "    epoch          : 3438\n",
      "    loss           : -1513.878197621491\n",
      "Train Epoch: 3439 [512/60000 (1%)] Loss: -1532.442993\n",
      "Train Epoch: 3439 [11776/60000 (20%)] Loss: -1496.814697\n",
      "Train Epoch: 3439 [23040/60000 (38%)] Loss: -1490.530151\n",
      "Train Epoch: 3439 [34304/60000 (57%)] Loss: -1505.907227\n",
      "Train Epoch: 3439 [45568/60000 (76%)] Loss: -1524.224121\n",
      "Train Epoch: 3439 [56832/60000 (95%)] Loss: -1479.484863\n",
      "    epoch          : 3439\n",
      "    loss           : -1522.0289123879986\n",
      "Train Epoch: 3440 [512/60000 (1%)] Loss: -1501.248779\n",
      "Train Epoch: 3440 [11776/60000 (20%)] Loss: -1597.192627\n",
      "Train Epoch: 3440 [23040/60000 (38%)] Loss: -1450.325928\n",
      "Train Epoch: 3440 [34304/60000 (57%)] Loss: -1546.660278\n",
      "Train Epoch: 3440 [45568/60000 (76%)] Loss: -1472.176025\n",
      "Train Epoch: 3440 [56832/60000 (95%)] Loss: -1615.317627\n",
      "    epoch          : 3440\n",
      "    loss           : -1520.2491958531957\n",
      "Train Epoch: 3441 [512/60000 (1%)] Loss: -1607.590698\n",
      "Train Epoch: 3441 [11776/60000 (20%)] Loss: -1540.423950\n",
      "Train Epoch: 3441 [23040/60000 (38%)] Loss: -1607.658447\n",
      "Train Epoch: 3441 [34304/60000 (57%)] Loss: -1521.935547\n",
      "Train Epoch: 3441 [45568/60000 (76%)] Loss: -1555.347656\n",
      "Train Epoch: 3441 [56832/60000 (95%)] Loss: -1541.601929\n",
      "    epoch          : 3441\n",
      "    loss           : -1524.6051694363525\n",
      "Train Epoch: 3442 [512/60000 (1%)] Loss: -1554.755005\n",
      "Train Epoch: 3442 [11776/60000 (20%)] Loss: -1487.555908\n",
      "Train Epoch: 3442 [23040/60000 (38%)] Loss: -1502.562866\n",
      "Train Epoch: 3442 [34304/60000 (57%)] Loss: -1494.358154\n",
      "Train Epoch: 3442 [45568/60000 (76%)] Loss: -1454.333862\n",
      "Train Epoch: 3442 [56832/60000 (95%)] Loss: -1454.042969\n",
      "    epoch          : 3442\n",
      "    loss           : -1517.816941428319\n",
      "Train Epoch: 3443 [512/60000 (1%)] Loss: -1524.765625\n",
      "Train Epoch: 3443 [11776/60000 (20%)] Loss: -1511.876465\n",
      "Train Epoch: 3443 [23040/60000 (38%)] Loss: -1442.541016\n",
      "Train Epoch: 3443 [34304/60000 (57%)] Loss: -1508.584595\n",
      "Train Epoch: 3443 [45568/60000 (76%)] Loss: -1499.497070\n",
      "Train Epoch: 3443 [56832/60000 (95%)] Loss: -1503.813965\n",
      "    epoch          : 3443\n",
      "    loss           : -1512.9914954233977\n",
      "Train Epoch: 3444 [512/60000 (1%)] Loss: -1467.373657\n",
      "Train Epoch: 3444 [11776/60000 (20%)] Loss: -1554.057861\n",
      "Train Epoch: 3444 [23040/60000 (38%)] Loss: -1579.661377\n",
      "Train Epoch: 3444 [34304/60000 (57%)] Loss: -1516.714233\n",
      "Train Epoch: 3444 [45568/60000 (76%)] Loss: -1543.092773\n",
      "Train Epoch: 3444 [56832/60000 (95%)] Loss: -1560.584961\n",
      "    epoch          : 3444\n",
      "    loss           : -1518.6756526278912\n",
      "Train Epoch: 3445 [512/60000 (1%)] Loss: -1555.736938\n",
      "Train Epoch: 3445 [11776/60000 (20%)] Loss: -1591.276855\n",
      "Train Epoch: 3445 [23040/60000 (38%)] Loss: -1487.217041\n",
      "Train Epoch: 3445 [34304/60000 (57%)] Loss: -1505.748291\n",
      "Train Epoch: 3445 [45568/60000 (76%)] Loss: -1452.852295\n",
      "Train Epoch: 3445 [56832/60000 (95%)] Loss: -1399.883057\n",
      "    epoch          : 3445\n",
      "    loss           : -1514.3185783429335\n",
      "Train Epoch: 3446 [512/60000 (1%)] Loss: -1515.494019\n",
      "Train Epoch: 3446 [11776/60000 (20%)] Loss: -1500.365234\n",
      "Train Epoch: 3446 [23040/60000 (38%)] Loss: -1553.909424\n",
      "Train Epoch: 3446 [34304/60000 (57%)] Loss: -1527.947998\n",
      "Train Epoch: 3446 [45568/60000 (76%)] Loss: -1561.737793\n",
      "Train Epoch: 3446 [56832/60000 (95%)] Loss: -1472.113892\n",
      "    epoch          : 3446\n",
      "    loss           : -1521.0979217701713\n",
      "Train Epoch: 3447 [512/60000 (1%)] Loss: -1536.227295\n",
      "Train Epoch: 3447 [11776/60000 (20%)] Loss: -1496.812988\n",
      "Train Epoch: 3447 [23040/60000 (38%)] Loss: -1414.693726\n",
      "Train Epoch: 3447 [34304/60000 (57%)] Loss: -1506.611572\n",
      "Train Epoch: 3447 [45568/60000 (76%)] Loss: -1509.737305\n",
      "Train Epoch: 3447 [56832/60000 (95%)] Loss: -1571.992554\n",
      "    epoch          : 3447\n",
      "    loss           : -1518.763606701867\n",
      "Train Epoch: 3448 [512/60000 (1%)] Loss: -1522.110840\n",
      "Train Epoch: 3448 [11776/60000 (20%)] Loss: -1445.469971\n",
      "Train Epoch: 3448 [23040/60000 (38%)] Loss: -1482.558594\n",
      "Train Epoch: 3448 [34304/60000 (57%)] Loss: -1518.856079\n",
      "Train Epoch: 3448 [45568/60000 (76%)] Loss: -1465.682861\n",
      "Train Epoch: 3448 [56832/60000 (95%)] Loss: -1530.765381\n",
      "    epoch          : 3448\n",
      "    loss           : -1522.1388287732832\n",
      "Train Epoch: 3449 [512/60000 (1%)] Loss: -1564.603882\n",
      "Train Epoch: 3449 [11776/60000 (20%)] Loss: -1458.356689\n",
      "Train Epoch: 3449 [23040/60000 (38%)] Loss: -1568.887939\n",
      "Train Epoch: 3449 [34304/60000 (57%)] Loss: -1500.071899\n",
      "Train Epoch: 3449 [45568/60000 (76%)] Loss: -1451.915527\n",
      "Train Epoch: 3449 [56832/60000 (95%)] Loss: -1573.340698\n",
      "    epoch          : 3449\n",
      "    loss           : -1518.089421676377\n",
      "Train Epoch: 3450 [512/60000 (1%)] Loss: -1482.254395\n",
      "Train Epoch: 3450 [11776/60000 (20%)] Loss: -1514.917358\n",
      "Train Epoch: 3450 [23040/60000 (38%)] Loss: -1581.586182\n",
      "Train Epoch: 3450 [34304/60000 (57%)] Loss: -1479.871094\n",
      "Train Epoch: 3450 [45568/60000 (76%)] Loss: -1591.784912\n",
      "Train Epoch: 3450 [56832/60000 (95%)] Loss: -1528.148438\n",
      "    epoch          : 3450\n",
      "    loss           : -1514.3683630302128\n",
      "Train Epoch: 3451 [512/60000 (1%)] Loss: -1540.581055\n",
      "Train Epoch: 3451 [11776/60000 (20%)] Loss: -1572.853271\n",
      "Train Epoch: 3451 [23040/60000 (38%)] Loss: -1532.364990\n",
      "Train Epoch: 3451 [34304/60000 (57%)] Loss: -1522.648682\n",
      "Train Epoch: 3451 [45568/60000 (76%)] Loss: -1531.318115\n",
      "Train Epoch: 3451 [56832/60000 (95%)] Loss: -1481.299561\n",
      "    epoch          : 3451\n",
      "    loss           : -1519.1812351032838\n",
      "Train Epoch: 3452 [512/60000 (1%)] Loss: -1520.401611\n",
      "Train Epoch: 3452 [11776/60000 (20%)] Loss: -1512.862427\n",
      "Train Epoch: 3452 [23040/60000 (38%)] Loss: -1547.948242\n",
      "Train Epoch: 3452 [34304/60000 (57%)] Loss: -1565.030762\n",
      "Train Epoch: 3452 [45568/60000 (76%)] Loss: -1562.389282\n",
      "Train Epoch: 3452 [56832/60000 (95%)] Loss: -1529.276367\n",
      "    epoch          : 3452\n",
      "    loss           : -1521.640184305482\n",
      "Train Epoch: 3453 [512/60000 (1%)] Loss: -1554.590942\n",
      "Train Epoch: 3453 [11776/60000 (20%)] Loss: -1512.889893\n",
      "Train Epoch: 3453 [23040/60000 (38%)] Loss: -1516.789307\n",
      "Train Epoch: 3453 [34304/60000 (57%)] Loss: -1559.729980\n",
      "Train Epoch: 3453 [45568/60000 (76%)] Loss: -1498.744385\n",
      "Train Epoch: 3453 [56832/60000 (95%)] Loss: -1475.267334\n",
      "    epoch          : 3453\n",
      "    loss           : -1516.969827942929\n",
      "Train Epoch: 3454 [512/60000 (1%)] Loss: -1542.617432\n",
      "Train Epoch: 3454 [11776/60000 (20%)] Loss: -1455.639771\n",
      "Train Epoch: 3454 [23040/60000 (38%)] Loss: -1622.964844\n",
      "Train Epoch: 3454 [34304/60000 (57%)] Loss: -1571.242554\n",
      "Train Epoch: 3454 [45568/60000 (76%)] Loss: -1506.116089\n",
      "Train Epoch: 3454 [56832/60000 (95%)] Loss: -1516.226440\n",
      "    epoch          : 3454\n",
      "    loss           : -1520.1898976126633\n",
      "Train Epoch: 3455 [512/60000 (1%)] Loss: -1478.137207\n",
      "Train Epoch: 3455 [11776/60000 (20%)] Loss: -1534.595581\n",
      "Train Epoch: 3455 [23040/60000 (38%)] Loss: -1531.651123\n",
      "Train Epoch: 3455 [34304/60000 (57%)] Loss: -1497.194580\n",
      "Train Epoch: 3455 [45568/60000 (76%)] Loss: -1521.446411\n",
      "Train Epoch: 3455 [56832/60000 (95%)] Loss: -1565.787964\n",
      "    epoch          : 3455\n",
      "    loss           : -1520.4957402978239\n",
      "Train Epoch: 3456 [512/60000 (1%)] Loss: -1525.456177\n",
      "Train Epoch: 3456 [11776/60000 (20%)] Loss: -1501.401489\n",
      "Train Epoch: 3456 [23040/60000 (38%)] Loss: -1455.807861\n",
      "Train Epoch: 3456 [34304/60000 (57%)] Loss: -1487.556030\n",
      "Train Epoch: 3456 [45568/60000 (76%)] Loss: -1541.566650\n",
      "Train Epoch: 3456 [56832/60000 (95%)] Loss: -1486.683105\n",
      "    epoch          : 3456\n",
      "    loss           : -1518.5763601529395\n",
      "Train Epoch: 3457 [512/60000 (1%)] Loss: -1510.606689\n",
      "Train Epoch: 3457 [11776/60000 (20%)] Loss: -1531.182129\n",
      "Train Epoch: 3457 [23040/60000 (38%)] Loss: -1585.530151\n",
      "Train Epoch: 3457 [34304/60000 (57%)] Loss: -1524.000122\n",
      "Train Epoch: 3457 [45568/60000 (76%)] Loss: -1540.690063\n",
      "Train Epoch: 3457 [56832/60000 (95%)] Loss: -1588.391113\n",
      "    epoch          : 3457\n",
      "    loss           : -1520.5083028502384\n",
      "Train Epoch: 3458 [512/60000 (1%)] Loss: -1517.028564\n",
      "Train Epoch: 3458 [11776/60000 (20%)] Loss: -1433.127319\n",
      "Train Epoch: 3458 [23040/60000 (38%)] Loss: -1485.417725\n",
      "Train Epoch: 3458 [34304/60000 (57%)] Loss: -1545.984253\n",
      "Train Epoch: 3458 [45568/60000 (76%)] Loss: -1538.545166\n",
      "Train Epoch: 3458 [56832/60000 (95%)] Loss: -1532.916260\n",
      "    epoch          : 3458\n",
      "    loss           : -1525.1395949886344\n",
      "Train Epoch: 3459 [512/60000 (1%)] Loss: -1604.841064\n",
      "Train Epoch: 3459 [11776/60000 (20%)] Loss: -1541.150391\n",
      "Train Epoch: 3459 [23040/60000 (38%)] Loss: -1523.044556\n",
      "Train Epoch: 3459 [34304/60000 (57%)] Loss: -1453.618408\n",
      "Train Epoch: 3459 [45568/60000 (76%)] Loss: -1504.699829\n",
      "Train Epoch: 3459 [56832/60000 (95%)] Loss: -1439.770508\n",
      "    epoch          : 3459\n",
      "    loss           : -1519.9176763329801\n",
      "Train Epoch: 3460 [512/60000 (1%)] Loss: -1521.765381\n",
      "Train Epoch: 3460 [11776/60000 (20%)] Loss: -1499.447021\n",
      "Train Epoch: 3460 [23040/60000 (38%)] Loss: -1530.043701\n",
      "Train Epoch: 3460 [34304/60000 (57%)] Loss: -1576.027100\n",
      "Train Epoch: 3460 [45568/60000 (76%)] Loss: -1540.068848\n",
      "Train Epoch: 3460 [56832/60000 (95%)] Loss: -1544.481689\n",
      "    epoch          : 3460\n",
      "    loss           : -1511.5964438228284\n",
      "Train Epoch: 3461 [512/60000 (1%)] Loss: -1566.365601\n",
      "Train Epoch: 3461 [11776/60000 (20%)] Loss: -1587.645996\n",
      "Train Epoch: 3461 [23040/60000 (38%)] Loss: -1411.088623\n",
      "Train Epoch: 3461 [34304/60000 (57%)] Loss: -1572.611084\n",
      "Train Epoch: 3461 [45568/60000 (76%)] Loss: -1546.355103\n",
      "Train Epoch: 3461 [56832/60000 (95%)] Loss: -1518.757080\n",
      "    epoch          : 3461\n",
      "    loss           : -1514.2255976617673\n",
      "Train Epoch: 3462 [512/60000 (1%)] Loss: -1546.724365\n",
      "Train Epoch: 3462 [11776/60000 (20%)] Loss: -1617.248901\n",
      "Train Epoch: 3462 [23040/60000 (38%)] Loss: -1588.494873\n",
      "Train Epoch: 3462 [34304/60000 (57%)] Loss: -1481.196777\n",
      "Train Epoch: 3462 [45568/60000 (76%)] Loss: -1489.992432\n",
      "Train Epoch: 3462 [56832/60000 (95%)] Loss: -1495.681152\n",
      "    epoch          : 3462\n",
      "    loss           : -1520.544750148967\n",
      "Train Epoch: 3463 [512/60000 (1%)] Loss: -1463.281250\n",
      "Train Epoch: 3463 [11776/60000 (20%)] Loss: -1532.620361\n",
      "Train Epoch: 3463 [23040/60000 (38%)] Loss: -1547.987793\n",
      "Train Epoch: 3463 [34304/60000 (57%)] Loss: -1534.057373\n",
      "Train Epoch: 3463 [45568/60000 (76%)] Loss: -1503.159424\n",
      "Train Epoch: 3463 [56832/60000 (95%)] Loss: -1558.475830\n",
      "    epoch          : 3463\n",
      "    loss           : -1523.5082987122616\n",
      "Train Epoch: 3464 [512/60000 (1%)] Loss: -1599.251465\n",
      "Train Epoch: 3464 [11776/60000 (20%)] Loss: -1508.582520\n",
      "Train Epoch: 3464 [23040/60000 (38%)] Loss: -1575.273193\n",
      "Train Epoch: 3464 [34304/60000 (57%)] Loss: -1524.070190\n",
      "Train Epoch: 3464 [45568/60000 (76%)] Loss: -1588.644409\n",
      "Train Epoch: 3464 [56832/60000 (95%)] Loss: -1529.123169\n",
      "    epoch          : 3464\n",
      "    loss           : -1510.2116757840088\n",
      "Train Epoch: 3465 [512/60000 (1%)] Loss: -1516.824585\n",
      "Train Epoch: 3465 [11776/60000 (20%)] Loss: -1437.505127\n",
      "Train Epoch: 3465 [23040/60000 (38%)] Loss: -1530.011719\n",
      "Train Epoch: 3465 [34304/60000 (57%)] Loss: -1469.901245\n",
      "Train Epoch: 3465 [45568/60000 (76%)] Loss: -1563.976074\n",
      "Train Epoch: 3465 [56832/60000 (95%)] Loss: -1515.324585\n",
      "    epoch          : 3465\n",
      "    loss           : -1518.7921946035267\n",
      "Train Epoch: 3466 [512/60000 (1%)] Loss: -1498.567505\n",
      "Train Epoch: 3466 [11776/60000 (20%)] Loss: -1570.452148\n",
      "Train Epoch: 3466 [23040/60000 (38%)] Loss: -1556.086670\n",
      "Train Epoch: 3466 [34304/60000 (57%)] Loss: -1484.537109\n",
      "Train Epoch: 3466 [45568/60000 (76%)] Loss: -1552.596680\n",
      "Train Epoch: 3466 [56832/60000 (95%)] Loss: -1532.828247\n",
      "    epoch          : 3466\n",
      "    loss           : -1518.108552921963\n",
      "Train Epoch: 3467 [512/60000 (1%)] Loss: -1474.827148\n",
      "Train Epoch: 3467 [11776/60000 (20%)] Loss: -1514.394287\n",
      "Train Epoch: 3467 [23040/60000 (38%)] Loss: -1524.860107\n",
      "Train Epoch: 3467 [34304/60000 (57%)] Loss: -1468.990967\n",
      "Train Epoch: 3467 [45568/60000 (76%)] Loss: -1525.128906\n",
      "Train Epoch: 3467 [56832/60000 (95%)] Loss: -1508.360107\n",
      "    epoch          : 3467\n",
      "    loss           : -1521.9077793272202\n",
      "Train Epoch: 3468 [512/60000 (1%)] Loss: -1451.706543\n",
      "Train Epoch: 3468 [11776/60000 (20%)] Loss: -1537.810425\n",
      "Train Epoch: 3468 [23040/60000 (38%)] Loss: -1581.347046\n",
      "Train Epoch: 3468 [34304/60000 (57%)] Loss: -1508.793213\n",
      "Train Epoch: 3468 [45568/60000 (76%)] Loss: -1502.170776\n",
      "Train Epoch: 3468 [56832/60000 (95%)] Loss: -1551.217285\n",
      "    epoch          : 3468\n",
      "    loss           : -1521.313684495829\n",
      "Train Epoch: 3469 [512/60000 (1%)] Loss: -1518.716309\n",
      "Train Epoch: 3469 [11776/60000 (20%)] Loss: -1567.340088\n",
      "Train Epoch: 3469 [23040/60000 (38%)] Loss: -1481.873779\n",
      "Train Epoch: 3469 [34304/60000 (57%)] Loss: -1542.686157\n",
      "Train Epoch: 3469 [45568/60000 (76%)] Loss: -1501.180908\n",
      "Train Epoch: 3469 [56832/60000 (95%)] Loss: -1456.880371\n",
      "    epoch          : 3469\n",
      "    loss           : -1514.7251366221974\n",
      "Train Epoch: 3470 [512/60000 (1%)] Loss: -1565.560547\n",
      "Train Epoch: 3470 [11776/60000 (20%)] Loss: -1536.240967\n",
      "Train Epoch: 3470 [23040/60000 (38%)] Loss: -1531.597046\n",
      "Train Epoch: 3470 [34304/60000 (57%)] Loss: -1517.954834\n",
      "Train Epoch: 3470 [45568/60000 (76%)] Loss: -1526.352539\n",
      "Train Epoch: 3470 [56832/60000 (95%)] Loss: -1539.671143\n",
      "    epoch          : 3470\n",
      "    loss           : -1521.4971520375398\n",
      "Train Epoch: 3471 [512/60000 (1%)] Loss: -1480.870850\n",
      "Train Epoch: 3471 [11776/60000 (20%)] Loss: -1538.195557\n",
      "Train Epoch: 3471 [23040/60000 (38%)] Loss: -1482.077148\n",
      "Train Epoch: 3471 [34304/60000 (57%)] Loss: -1502.236084\n",
      "Train Epoch: 3471 [45568/60000 (76%)] Loss: -1459.799927\n",
      "Train Epoch: 3471 [56832/60000 (95%)] Loss: -1443.357056\n",
      "    epoch          : 3471\n",
      "    loss           : -1527.2296439133122\n",
      "Train Epoch: 3472 [512/60000 (1%)] Loss: -1564.623535\n",
      "Train Epoch: 3472 [11776/60000 (20%)] Loss: -1440.434814\n",
      "Train Epoch: 3472 [23040/60000 (38%)] Loss: -1547.418335\n",
      "Train Epoch: 3472 [34304/60000 (57%)] Loss: -1590.953979\n",
      "Train Epoch: 3472 [45568/60000 (76%)] Loss: -1569.447144\n",
      "Train Epoch: 3472 [56832/60000 (95%)] Loss: -1630.686157\n",
      "    epoch          : 3472\n",
      "    loss           : -1524.3719141038798\n",
      "Train Epoch: 3473 [512/60000 (1%)] Loss: -1521.074463\n",
      "Train Epoch: 3473 [11776/60000 (20%)] Loss: -1521.858643\n",
      "Train Epoch: 3473 [23040/60000 (38%)] Loss: -1503.951660\n",
      "Train Epoch: 3473 [34304/60000 (57%)] Loss: -1593.378296\n",
      "Train Epoch: 3473 [45568/60000 (76%)] Loss: -1405.785889\n",
      "Train Epoch: 3473 [56832/60000 (95%)] Loss: -1581.100830\n",
      "    epoch          : 3473\n",
      "    loss           : -1520.7180468887932\n",
      "Train Epoch: 3474 [512/60000 (1%)] Loss: -1610.861328\n",
      "Train Epoch: 3474 [11776/60000 (20%)] Loss: -1578.000244\n",
      "Train Epoch: 3474 [23040/60000 (38%)] Loss: -1513.076538\n",
      "Train Epoch: 3474 [34304/60000 (57%)] Loss: -1484.489502\n",
      "Train Epoch: 3474 [45568/60000 (76%)] Loss: -1567.598145\n",
      "Train Epoch: 3474 [56832/60000 (95%)] Loss: -1491.537720\n",
      "    epoch          : 3474\n",
      "    loss           : -1521.1395253326934\n",
      "Train Epoch: 3475 [512/60000 (1%)] Loss: -1546.642212\n",
      "Train Epoch: 3475 [11776/60000 (20%)] Loss: -1439.932739\n",
      "Train Epoch: 3475 [23040/60000 (38%)] Loss: -1585.589233\n",
      "Train Epoch: 3475 [34304/60000 (57%)] Loss: -1543.287354\n",
      "Train Epoch: 3475 [45568/60000 (76%)] Loss: -1566.037842\n",
      "Train Epoch: 3475 [56832/60000 (95%)] Loss: -1576.301025\n",
      "    epoch          : 3475\n",
      "    loss           : -1525.8269577457406\n",
      "Train Epoch: 3476 [512/60000 (1%)] Loss: -1524.374878\n",
      "Train Epoch: 3476 [11776/60000 (20%)] Loss: -1495.493042\n",
      "Train Epoch: 3476 [23040/60000 (38%)] Loss: -1483.922119\n",
      "Train Epoch: 3476 [34304/60000 (57%)] Loss: -1560.569458\n",
      "Train Epoch: 3476 [45568/60000 (76%)] Loss: -1521.409302\n",
      "Train Epoch: 3476 [56832/60000 (95%)] Loss: -1501.033081\n",
      "    epoch          : 3476\n",
      "    loss           : -1514.419956358139\n",
      "Train Epoch: 3477 [512/60000 (1%)] Loss: -1564.809448\n",
      "Train Epoch: 3477 [11776/60000 (20%)] Loss: -1534.270996\n",
      "Train Epoch: 3477 [23040/60000 (38%)] Loss: -1473.063354\n",
      "Train Epoch: 3477 [34304/60000 (57%)] Loss: -1452.291382\n",
      "Train Epoch: 3477 [45568/60000 (76%)] Loss: -1561.625000\n",
      "Train Epoch: 3477 [56832/60000 (95%)] Loss: -1564.621826\n",
      "    epoch          : 3477\n",
      "    loss           : -1524.8443665585276\n",
      "Train Epoch: 3478 [512/60000 (1%)] Loss: -1432.165649\n",
      "Train Epoch: 3478 [11776/60000 (20%)] Loss: -1495.676514\n",
      "Train Epoch: 3478 [23040/60000 (38%)] Loss: -1500.958862\n",
      "Train Epoch: 3478 [34304/60000 (57%)] Loss: -1462.741699\n",
      "Train Epoch: 3478 [45568/60000 (76%)] Loss: -1543.663940\n",
      "Train Epoch: 3478 [56832/60000 (95%)] Loss: -1482.073486\n",
      "    epoch          : 3478\n",
      "    loss           : -1514.2149337509932\n",
      "Train Epoch: 3479 [512/60000 (1%)] Loss: -1416.878662\n",
      "Train Epoch: 3479 [11776/60000 (20%)] Loss: -1511.304321\n",
      "Train Epoch: 3479 [23040/60000 (38%)] Loss: -1437.223999\n",
      "Train Epoch: 3479 [34304/60000 (57%)] Loss: -1532.511108\n",
      "Train Epoch: 3479 [45568/60000 (76%)] Loss: -1497.710693\n",
      "Train Epoch: 3479 [56832/60000 (95%)] Loss: -1366.416504\n",
      "    epoch          : 3479\n",
      "    loss           : -1522.4615995762713\n",
      "Train Epoch: 3480 [512/60000 (1%)] Loss: -1548.709106\n",
      "Train Epoch: 3480 [11776/60000 (20%)] Loss: -1563.142090\n",
      "Train Epoch: 3480 [23040/60000 (38%)] Loss: -1561.617188\n",
      "Train Epoch: 3480 [34304/60000 (57%)] Loss: -1559.477417\n",
      "Train Epoch: 3480 [45568/60000 (76%)] Loss: -1522.754639\n",
      "Train Epoch: 3480 [56832/60000 (95%)] Loss: -1496.288452\n",
      "    epoch          : 3480\n",
      "    loss           : -1523.5552464716852\n",
      "Train Epoch: 3481 [512/60000 (1%)] Loss: -1539.731689\n",
      "Train Epoch: 3481 [11776/60000 (20%)] Loss: -1583.220825\n",
      "Train Epoch: 3481 [23040/60000 (38%)] Loss: -1496.137207\n",
      "Train Epoch: 3481 [34304/60000 (57%)] Loss: -1551.819702\n",
      "Train Epoch: 3481 [45568/60000 (76%)] Loss: -1472.054199\n",
      "Train Epoch: 3481 [56832/60000 (95%)] Loss: -1517.479370\n",
      "    epoch          : 3481\n",
      "    loss           : -1526.3352212852005\n",
      "Train Epoch: 3482 [512/60000 (1%)] Loss: -1509.227539\n",
      "Train Epoch: 3482 [11776/60000 (20%)] Loss: -1606.042236\n",
      "Train Epoch: 3482 [23040/60000 (38%)] Loss: -1424.502197\n",
      "Train Epoch: 3482 [34304/60000 (57%)] Loss: -1522.817993\n",
      "Train Epoch: 3482 [45568/60000 (76%)] Loss: -1518.698486\n",
      "Train Epoch: 3482 [56832/60000 (95%)] Loss: -1592.554688\n",
      "    epoch          : 3482\n",
      "    loss           : -1529.2659870729608\n",
      "Train Epoch: 3483 [512/60000 (1%)] Loss: -1486.251465\n",
      "Train Epoch: 3483 [11776/60000 (20%)] Loss: -1595.775879\n",
      "Train Epoch: 3483 [23040/60000 (38%)] Loss: -1537.562500\n",
      "Train Epoch: 3483 [34304/60000 (57%)] Loss: -1509.281738\n",
      "Train Epoch: 3483 [45568/60000 (76%)] Loss: -1580.322266\n",
      "Train Epoch: 3483 [56832/60000 (95%)] Loss: -1559.467163\n",
      "    epoch          : 3483\n",
      "    loss           : -1518.7387916004589\n",
      "Train Epoch: 3484 [512/60000 (1%)] Loss: -1519.959717\n",
      "Train Epoch: 3484 [11776/60000 (20%)] Loss: -1538.660889\n",
      "Train Epoch: 3484 [23040/60000 (38%)] Loss: -1590.100098\n",
      "Train Epoch: 3484 [34304/60000 (57%)] Loss: -1519.544678\n",
      "Train Epoch: 3484 [45568/60000 (76%)] Loss: -1459.261108\n",
      "Train Epoch: 3484 [56832/60000 (95%)] Loss: -1511.975342\n",
      "    epoch          : 3484\n",
      "    loss           : -1526.4731572900114\n",
      "Train Epoch: 3485 [512/60000 (1%)] Loss: -1566.484375\n",
      "Train Epoch: 3485 [11776/60000 (20%)] Loss: -1467.039062\n",
      "Train Epoch: 3485 [23040/60000 (38%)] Loss: -1577.686279\n",
      "Train Epoch: 3485 [34304/60000 (57%)] Loss: -1527.576660\n",
      "Train Epoch: 3485 [45568/60000 (76%)] Loss: -1560.721436\n",
      "Train Epoch: 3485 [56832/60000 (95%)] Loss: -1513.593262\n",
      "    epoch          : 3485\n",
      "    loss           : -1519.6486412953523\n",
      "Train Epoch: 3486 [512/60000 (1%)] Loss: -1488.461304\n",
      "Train Epoch: 3486 [11776/60000 (20%)] Loss: -1515.897217\n",
      "Train Epoch: 3486 [23040/60000 (38%)] Loss: -1489.104248\n",
      "Train Epoch: 3486 [34304/60000 (57%)] Loss: -1559.793457\n",
      "Train Epoch: 3486 [45568/60000 (76%)] Loss: -1584.894531\n",
      "Train Epoch: 3486 [56832/60000 (95%)] Loss: -1482.206543\n",
      "    epoch          : 3486\n",
      "    loss           : -1517.7058639957406\n",
      "Train Epoch: 3487 [512/60000 (1%)] Loss: -1558.964966\n",
      "Train Epoch: 3487 [11776/60000 (20%)] Loss: -1610.112305\n",
      "Train Epoch: 3487 [23040/60000 (38%)] Loss: -1542.337769\n",
      "Train Epoch: 3487 [34304/60000 (57%)] Loss: -1589.013306\n",
      "Train Epoch: 3487 [45568/60000 (76%)] Loss: -1463.557129\n",
      "Train Epoch: 3487 [56832/60000 (95%)] Loss: -1462.668335\n",
      "    epoch          : 3487\n",
      "    loss           : -1522.0725563178628\n",
      "Train Epoch: 3488 [512/60000 (1%)] Loss: -1566.698608\n",
      "Train Epoch: 3488 [11776/60000 (20%)] Loss: -1535.817139\n",
      "Train Epoch: 3488 [23040/60000 (38%)] Loss: -1403.950806\n",
      "Train Epoch: 3488 [34304/60000 (57%)] Loss: -1527.907227\n",
      "Train Epoch: 3488 [45568/60000 (76%)] Loss: -1541.751709\n",
      "Train Epoch: 3488 [56832/60000 (95%)] Loss: -1540.470459\n",
      "    epoch          : 3488\n",
      "    loss           : -1523.8403437555173\n",
      "Train Epoch: 3489 [512/60000 (1%)] Loss: -1446.638062\n",
      "Train Epoch: 3489 [11776/60000 (20%)] Loss: -1581.989746\n",
      "Train Epoch: 3489 [23040/60000 (38%)] Loss: -1577.834717\n",
      "Train Epoch: 3489 [34304/60000 (57%)] Loss: -1525.090576\n",
      "Train Epoch: 3489 [45568/60000 (76%)] Loss: -1477.985840\n",
      "Train Epoch: 3489 [56832/60000 (95%)] Loss: -1570.211182\n",
      "    epoch          : 3489\n",
      "    loss           : -1525.4535560392392\n",
      "Train Epoch: 3490 [512/60000 (1%)] Loss: -1466.676270\n",
      "Train Epoch: 3490 [11776/60000 (20%)] Loss: -1509.988892\n",
      "Train Epoch: 3490 [23040/60000 (38%)] Loss: -1599.677734\n",
      "Train Epoch: 3490 [34304/60000 (57%)] Loss: -1473.449829\n",
      "Train Epoch: 3490 [45568/60000 (76%)] Loss: -1486.729736\n",
      "Train Epoch: 3490 [56832/60000 (95%)] Loss: -1500.879150\n",
      "    epoch          : 3490\n",
      "    loss           : -1526.1603631488347\n",
      "Train Epoch: 3491 [512/60000 (1%)] Loss: -1609.725464\n",
      "Train Epoch: 3491 [11776/60000 (20%)] Loss: -1569.689453\n",
      "Train Epoch: 3491 [23040/60000 (38%)] Loss: -1558.721558\n",
      "Train Epoch: 3491 [34304/60000 (57%)] Loss: -1567.447388\n",
      "Train Epoch: 3491 [45568/60000 (76%)] Loss: -1491.423340\n",
      "Train Epoch: 3491 [56832/60000 (95%)] Loss: -1457.526123\n",
      "    epoch          : 3491\n",
      "    loss           : -1522.0183570991128\n",
      "Train Epoch: 3492 [512/60000 (1%)] Loss: -1564.108154\n",
      "Train Epoch: 3492 [11776/60000 (20%)] Loss: -1575.925781\n",
      "Train Epoch: 3492 [23040/60000 (38%)] Loss: -1544.800537\n",
      "Train Epoch: 3492 [34304/60000 (57%)] Loss: -1545.937134\n",
      "Train Epoch: 3492 [45568/60000 (76%)] Loss: -1500.623047\n",
      "Train Epoch: 3492 [56832/60000 (95%)] Loss: -1416.267822\n",
      "    epoch          : 3492\n",
      "    loss           : -1516.47693181442\n",
      "Train Epoch: 3493 [512/60000 (1%)] Loss: -1513.344727\n",
      "Train Epoch: 3493 [11776/60000 (20%)] Loss: -1569.622681\n",
      "Train Epoch: 3493 [23040/60000 (38%)] Loss: -1549.602539\n",
      "Train Epoch: 3493 [34304/60000 (57%)] Loss: -1520.174316\n",
      "Train Epoch: 3493 [45568/60000 (76%)] Loss: -1442.266357\n",
      "Train Epoch: 3493 [56832/60000 (95%)] Loss: -1434.394653\n",
      "    epoch          : 3493\n",
      "    loss           : -1525.9828884318724\n",
      "Train Epoch: 3494 [512/60000 (1%)] Loss: -1475.715332\n",
      "Train Epoch: 3494 [11776/60000 (20%)] Loss: -1410.193237\n",
      "Train Epoch: 3494 [23040/60000 (38%)] Loss: -1530.657227\n",
      "Train Epoch: 3494 [34304/60000 (57%)] Loss: -1472.572510\n",
      "Train Epoch: 3494 [45568/60000 (76%)] Loss: -1535.455200\n",
      "Train Epoch: 3494 [56832/60000 (95%)] Loss: -1576.418701\n",
      "    epoch          : 3494\n",
      "    loss           : -1520.0636093225855\n",
      "Train Epoch: 3495 [512/60000 (1%)] Loss: -1376.189697\n",
      "Train Epoch: 3495 [11776/60000 (20%)] Loss: -1574.568604\n",
      "Train Epoch: 3495 [23040/60000 (38%)] Loss: -1565.619385\n",
      "Train Epoch: 3495 [34304/60000 (57%)] Loss: -1538.177856\n",
      "Train Epoch: 3495 [45568/60000 (76%)] Loss: -1526.699219\n",
      "Train Epoch: 3495 [56832/60000 (95%)] Loss: -1484.715942\n",
      "    epoch          : 3495\n",
      "    loss           : -1515.8312415861142\n",
      "Train Epoch: 3496 [512/60000 (1%)] Loss: -1560.246582\n",
      "Train Epoch: 3496 [11776/60000 (20%)] Loss: -1527.283081\n",
      "Train Epoch: 3496 [23040/60000 (38%)] Loss: -1465.944702\n",
      "Train Epoch: 3496 [34304/60000 (57%)] Loss: -1491.421265\n",
      "Train Epoch: 3496 [45568/60000 (76%)] Loss: -1457.136597\n",
      "Train Epoch: 3496 [56832/60000 (95%)] Loss: -1508.391357\n",
      "    epoch          : 3496\n",
      "    loss           : -1523.9660651427878\n",
      "Train Epoch: 3497 [512/60000 (1%)] Loss: -1510.008301\n",
      "Train Epoch: 3497 [11776/60000 (20%)] Loss: -1520.944458\n",
      "Train Epoch: 3497 [23040/60000 (38%)] Loss: -1503.550049\n",
      "Train Epoch: 3497 [34304/60000 (57%)] Loss: -1525.107666\n",
      "Train Epoch: 3497 [45568/60000 (76%)] Loss: -1542.299194\n",
      "Train Epoch: 3497 [56832/60000 (95%)] Loss: -1518.431152\n",
      "    epoch          : 3497\n",
      "    loss           : -1520.6440677966102\n",
      "Train Epoch: 3498 [512/60000 (1%)] Loss: -1500.666870\n",
      "Train Epoch: 3498 [11776/60000 (20%)] Loss: -1493.797363\n",
      "Train Epoch: 3498 [23040/60000 (38%)] Loss: -1469.196411\n",
      "Train Epoch: 3498 [34304/60000 (57%)] Loss: -1574.586914\n",
      "Train Epoch: 3498 [45568/60000 (76%)] Loss: -1441.000732\n",
      "Train Epoch: 3498 [56832/60000 (95%)] Loss: -1522.848389\n",
      "    epoch          : 3498\n",
      "    loss           : -1525.926447464248\n",
      "Train Epoch: 3499 [512/60000 (1%)] Loss: -1509.815186\n",
      "Train Epoch: 3499 [11776/60000 (20%)] Loss: -1521.320068\n",
      "Train Epoch: 3499 [23040/60000 (38%)] Loss: -1577.066040\n",
      "Train Epoch: 3499 [34304/60000 (57%)] Loss: -1461.236572\n",
      "Train Epoch: 3499 [45568/60000 (76%)] Loss: -1528.265137\n",
      "Train Epoch: 3499 [56832/60000 (95%)] Loss: -1538.929199\n",
      "    epoch          : 3499\n",
      "    loss           : -1526.3323491845426\n",
      "Train Epoch: 3500 [512/60000 (1%)] Loss: -1450.955688\n",
      "Train Epoch: 3500 [11776/60000 (20%)] Loss: -1548.275635\n",
      "Train Epoch: 3500 [23040/60000 (38%)] Loss: -1560.628906\n",
      "Train Epoch: 3500 [34304/60000 (57%)] Loss: -1541.987793\n",
      "Train Epoch: 3500 [45568/60000 (76%)] Loss: -1530.190430\n",
      "Train Epoch: 3500 [56832/60000 (95%)] Loss: -1492.741943\n",
      "    epoch          : 3500\n",
      "    loss           : -1521.510112870211\n",
      "Saving checkpoint: saved/models/Mnist_DeepGenerativeOperad/0127_111843/checkpoint-epoch3500.pth ...\n",
      "Train Epoch: 3501 [512/60000 (1%)] Loss: -1522.218018\n",
      "Train Epoch: 3501 [11776/60000 (20%)] Loss: -1470.050293\n",
      "Train Epoch: 3501 [23040/60000 (38%)] Loss: -1516.411621\n",
      "Train Epoch: 3501 [34304/60000 (57%)] Loss: -1598.333374\n",
      "Train Epoch: 3501 [45568/60000 (76%)] Loss: -1524.173950\n",
      "Train Epoch: 3501 [56832/60000 (95%)] Loss: -1585.833984\n",
      "    epoch          : 3501\n",
      "    loss           : -1527.9749059299966\n",
      "Train Epoch: 3502 [512/60000 (1%)] Loss: -1453.012085\n",
      "Train Epoch: 3502 [11776/60000 (20%)] Loss: -1575.177246\n",
      "Train Epoch: 3502 [23040/60000 (38%)] Loss: -1504.676025\n",
      "Train Epoch: 3502 [34304/60000 (57%)] Loss: -1525.937378\n",
      "Train Epoch: 3502 [45568/60000 (76%)] Loss: -1484.775879\n",
      "Train Epoch: 3502 [56832/60000 (95%)] Loss: -1610.972656\n",
      "    epoch          : 3502\n",
      "    loss           : -1525.5760646324372\n",
      "Train Epoch: 3503 [512/60000 (1%)] Loss: -1502.628540\n",
      "Train Epoch: 3503 [11776/60000 (20%)] Loss: -1522.632812\n",
      "Train Epoch: 3503 [23040/60000 (38%)] Loss: -1529.742065\n",
      "Train Epoch: 3503 [34304/60000 (57%)] Loss: -1546.514893\n",
      "Train Epoch: 3503 [45568/60000 (76%)] Loss: -1551.836304\n",
      "Train Epoch: 3503 [56832/60000 (95%)] Loss: -1478.780518\n",
      "    epoch          : 3503\n",
      "    loss           : -1516.110571220096\n",
      "Train Epoch: 3504 [512/60000 (1%)] Loss: -1493.055542\n",
      "Train Epoch: 3504 [11776/60000 (20%)] Loss: -1526.034668\n",
      "Train Epoch: 3504 [23040/60000 (38%)] Loss: -1524.660400\n",
      "Train Epoch: 3504 [34304/60000 (57%)] Loss: -1555.420410\n",
      "Train Epoch: 3504 [45568/60000 (76%)] Loss: -1577.203979\n",
      "Train Epoch: 3504 [56832/60000 (95%)] Loss: -1559.405396\n",
      "    epoch          : 3504\n",
      "    loss           : -1518.574171163268\n",
      "Train Epoch: 3505 [512/60000 (1%)] Loss: -1549.695312\n",
      "Train Epoch: 3505 [11776/60000 (20%)] Loss: -1546.995361\n",
      "Train Epoch: 3505 [23040/60000 (38%)] Loss: -1460.686279\n",
      "Train Epoch: 3505 [34304/60000 (57%)] Loss: -1554.612305\n",
      "Train Epoch: 3505 [45568/60000 (76%)] Loss: -1512.547119\n",
      "Train Epoch: 3505 [56832/60000 (95%)] Loss: -1504.054077\n",
      "    epoch          : 3505\n",
      "    loss           : -1506.904715500309\n",
      "Train Epoch: 3506 [512/60000 (1%)] Loss: -1508.356812\n",
      "Train Epoch: 3506 [11776/60000 (20%)] Loss: -1529.348267\n",
      "Train Epoch: 3506 [23040/60000 (38%)] Loss: -1588.287598\n",
      "Train Epoch: 3506 [34304/60000 (57%)] Loss: -1589.113525\n",
      "Train Epoch: 3506 [45568/60000 (76%)] Loss: -1546.930298\n",
      "Train Epoch: 3506 [56832/60000 (95%)] Loss: -1540.979736\n",
      "    epoch          : 3506\n",
      "    loss           : -1520.7999929654395\n",
      "Train Epoch: 3507 [512/60000 (1%)] Loss: -1511.592163\n",
      "Train Epoch: 3507 [11776/60000 (20%)] Loss: -1549.074219\n",
      "Train Epoch: 3507 [23040/60000 (38%)] Loss: -1490.826782\n",
      "Train Epoch: 3507 [34304/60000 (57%)] Loss: -1556.234375\n",
      "Train Epoch: 3507 [45568/60000 (76%)] Loss: -1521.143555\n",
      "Train Epoch: 3507 [56832/60000 (95%)] Loss: -1527.839478\n",
      "    epoch          : 3507\n",
      "    loss           : -1518.2356032894156\n",
      "Train Epoch: 3508 [512/60000 (1%)] Loss: -1580.815918\n",
      "Train Epoch: 3508 [11776/60000 (20%)] Loss: -1548.758667\n",
      "Train Epoch: 3508 [23040/60000 (38%)] Loss: -1464.134277\n",
      "Train Epoch: 3508 [34304/60000 (57%)] Loss: -1557.629150\n",
      "Train Epoch: 3508 [45568/60000 (76%)] Loss: -1547.252930\n",
      "Train Epoch: 3508 [56832/60000 (95%)] Loss: -1573.620117\n",
      "    epoch          : 3508\n",
      "    loss           : -1521.6809026858227\n",
      "Train Epoch: 3509 [512/60000 (1%)] Loss: -1511.685913\n",
      "Train Epoch: 3509 [11776/60000 (20%)] Loss: -1542.736206\n",
      "Train Epoch: 3509 [23040/60000 (38%)] Loss: -1549.455078\n",
      "Train Epoch: 3509 [34304/60000 (57%)] Loss: -1545.713745\n",
      "Train Epoch: 3509 [45568/60000 (76%)] Loss: -1456.967407\n",
      "Train Epoch: 3509 [56832/60000 (95%)] Loss: -1536.949707\n",
      "    epoch          : 3509\n",
      "    loss           : -1524.2422223279707\n",
      "Train Epoch: 3510 [512/60000 (1%)] Loss: -1543.512207\n",
      "Train Epoch: 3510 [11776/60000 (20%)] Loss: -1596.871338\n",
      "Train Epoch: 3510 [23040/60000 (38%)] Loss: -1557.932739\n",
      "Train Epoch: 3510 [34304/60000 (57%)] Loss: -1522.837402\n",
      "Train Epoch: 3510 [45568/60000 (76%)] Loss: -1530.653442\n",
      "Train Epoch: 3510 [56832/60000 (95%)] Loss: -1569.349243\n",
      "    epoch          : 3510\n",
      "    loss           : -1523.2048950195312\n",
      "Train Epoch: 3511 [512/60000 (1%)] Loss: -1478.364502\n",
      "Train Epoch: 3511 [11776/60000 (20%)] Loss: -1533.890259\n",
      "Train Epoch: 3511 [23040/60000 (38%)] Loss: -1476.171387\n",
      "Train Epoch: 3511 [34304/60000 (57%)] Loss: -1494.495239\n",
      "Train Epoch: 3511 [45568/60000 (76%)] Loss: -1523.349609\n",
      "Train Epoch: 3511 [56832/60000 (95%)] Loss: -1512.886963\n",
      "    epoch          : 3511\n",
      "    loss           : -1520.241805081987\n",
      "Train Epoch: 3512 [512/60000 (1%)] Loss: -1594.439209\n",
      "Train Epoch: 3512 [11776/60000 (20%)] Loss: -1480.601196\n",
      "Train Epoch: 3512 [23040/60000 (38%)] Loss: -1534.348877\n",
      "Train Epoch: 3512 [34304/60000 (57%)] Loss: -1530.196777\n",
      "Train Epoch: 3512 [45568/60000 (76%)] Loss: -1543.493164\n",
      "Train Epoch: 3512 [56832/60000 (95%)] Loss: -1576.343018\n",
      "    epoch          : 3512\n",
      "    loss           : -1523.8040743897864\n",
      "Train Epoch: 3513 [512/60000 (1%)] Loss: -1488.332275\n",
      "Train Epoch: 3513 [11776/60000 (20%)] Loss: -1404.951660\n",
      "Train Epoch: 3513 [23040/60000 (38%)] Loss: -1453.751953\n",
      "Train Epoch: 3513 [34304/60000 (57%)] Loss: -1530.134521\n",
      "Train Epoch: 3513 [45568/60000 (76%)] Loss: -1582.358887\n",
      "Train Epoch: 3513 [56832/60000 (95%)] Loss: -1464.183594\n",
      "    epoch          : 3513\n",
      "    loss           : -1517.2213420975681\n",
      "Train Epoch: 3514 [512/60000 (1%)] Loss: -1564.905151\n",
      "Train Epoch: 3514 [11776/60000 (20%)] Loss: -1441.730103\n",
      "Train Epoch: 3514 [23040/60000 (38%)] Loss: -1516.982666\n",
      "Train Epoch: 3514 [34304/60000 (57%)] Loss: -1508.420654\n",
      "Train Epoch: 3514 [45568/60000 (76%)] Loss: -1476.717163\n",
      "Train Epoch: 3514 [56832/60000 (95%)] Loss: -1567.532349\n",
      "    epoch          : 3514\n",
      "    loss           : -1522.4157242424744\n",
      "Train Epoch: 3515 [512/60000 (1%)] Loss: -1455.901611\n",
      "Train Epoch: 3515 [11776/60000 (20%)] Loss: -1552.178467\n",
      "Train Epoch: 3515 [23040/60000 (38%)] Loss: -1485.673340\n",
      "Train Epoch: 3515 [34304/60000 (57%)] Loss: -1539.625244\n",
      "Train Epoch: 3515 [45568/60000 (76%)] Loss: -1570.567261\n",
      "Train Epoch: 3515 [56832/60000 (95%)] Loss: -1542.993896\n",
      "    epoch          : 3515\n",
      "    loss           : -1524.0838964429952\n",
      "Train Epoch: 3516 [512/60000 (1%)] Loss: -1507.597290\n",
      "Train Epoch: 3516 [11776/60000 (20%)] Loss: -1529.161499\n",
      "Train Epoch: 3516 [23040/60000 (38%)] Loss: -1479.489990\n",
      "Train Epoch: 3516 [34304/60000 (57%)] Loss: -1436.130249\n",
      "Train Epoch: 3516 [45568/60000 (76%)] Loss: -1514.688965\n",
      "Train Epoch: 3516 [56832/60000 (95%)] Loss: -1470.475586\n",
      "    epoch          : 3516\n",
      "    loss           : -1532.0725518350548\n",
      "Train Epoch: 3517 [512/60000 (1%)] Loss: -1529.625000\n",
      "Train Epoch: 3517 [11776/60000 (20%)] Loss: -1514.439331\n",
      "Train Epoch: 3517 [23040/60000 (38%)] Loss: -1491.887817\n",
      "Train Epoch: 3517 [34304/60000 (57%)] Loss: -1522.348267\n",
      "Train Epoch: 3517 [45568/60000 (76%)] Loss: -1504.216797\n",
      "Train Epoch: 3517 [56832/60000 (95%)] Loss: -1549.164429\n",
      "    epoch          : 3517\n",
      "    loss           : -1522.2744664768716\n",
      "Train Epoch: 3518 [512/60000 (1%)] Loss: -1573.253174\n",
      "Train Epoch: 3518 [11776/60000 (20%)] Loss: -1531.693970\n",
      "Train Epoch: 3518 [23040/60000 (38%)] Loss: -1597.316040\n",
      "Train Epoch: 3518 [34304/60000 (57%)] Loss: -1609.968750\n",
      "Train Epoch: 3518 [45568/60000 (76%)] Loss: -1504.075684\n",
      "Train Epoch: 3518 [56832/60000 (95%)] Loss: -1454.517334\n",
      "    epoch          : 3518\n",
      "    loss           : -1529.1441926255739\n",
      "Train Epoch: 3519 [512/60000 (1%)] Loss: -1479.005615\n",
      "Train Epoch: 3519 [11776/60000 (20%)] Loss: -1600.770996\n",
      "Train Epoch: 3519 [23040/60000 (38%)] Loss: -1505.788574\n",
      "Train Epoch: 3519 [34304/60000 (57%)] Loss: -1457.879639\n",
      "Train Epoch: 3519 [45568/60000 (76%)] Loss: -1520.350708\n",
      "Train Epoch: 3519 [56832/60000 (95%)] Loss: -1497.781006\n",
      "    epoch          : 3519\n",
      "    loss           : -1527.5026745122705\n",
      "Train Epoch: 3520 [512/60000 (1%)] Loss: -1508.041748\n",
      "Train Epoch: 3520 [11776/60000 (20%)] Loss: -1582.919678\n",
      "Train Epoch: 3520 [23040/60000 (38%)] Loss: -1576.033691\n",
      "Train Epoch: 3520 [34304/60000 (57%)] Loss: -1486.674194\n",
      "Train Epoch: 3520 [45568/60000 (76%)] Loss: -1485.465088\n",
      "Train Epoch: 3520 [56832/60000 (95%)] Loss: -1565.109497\n",
      "    epoch          : 3520\n",
      "    loss           : -1531.0183367540606\n",
      "Train Epoch: 3521 [512/60000 (1%)] Loss: -1476.456055\n",
      "Train Epoch: 3521 [11776/60000 (20%)] Loss: -1541.688721\n",
      "Train Epoch: 3521 [23040/60000 (38%)] Loss: -1512.014404\n",
      "Train Epoch: 3521 [34304/60000 (57%)] Loss: -1480.856323\n",
      "Train Epoch: 3521 [45568/60000 (76%)] Loss: -1535.481934\n",
      "Train Epoch: 3521 [56832/60000 (95%)] Loss: -1414.975098\n",
      "    epoch          : 3521\n",
      "    loss           : -1523.1252913825256\n",
      "Train Epoch: 3522 [512/60000 (1%)] Loss: -1572.787109\n",
      "Train Epoch: 3522 [11776/60000 (20%)] Loss: -1555.163330\n",
      "Train Epoch: 3522 [23040/60000 (38%)] Loss: -1548.149658\n",
      "Train Epoch: 3522 [34304/60000 (57%)] Loss: -1471.325195\n",
      "Train Epoch: 3522 [45568/60000 (76%)] Loss: -1525.116821\n",
      "Train Epoch: 3522 [56832/60000 (95%)] Loss: -1517.944824\n",
      "    epoch          : 3522\n",
      "    loss           : -1522.4407096905898\n",
      "Train Epoch: 3523 [512/60000 (1%)] Loss: -1483.462036\n",
      "Train Epoch: 3523 [11776/60000 (20%)] Loss: -1485.995361\n",
      "Train Epoch: 3523 [23040/60000 (38%)] Loss: -1534.240356\n",
      "Train Epoch: 3523 [34304/60000 (57%)] Loss: -1581.917725\n",
      "Train Epoch: 3523 [45568/60000 (76%)] Loss: -1400.715820\n",
      "Train Epoch: 3523 [56832/60000 (95%)] Loss: -1513.191162\n",
      "    epoch          : 3523\n",
      "    loss           : -1520.4042103223208\n",
      "Train Epoch: 3524 [512/60000 (1%)] Loss: -1553.703125\n",
      "Train Epoch: 3524 [11776/60000 (20%)] Loss: -1517.515015\n",
      "Train Epoch: 3524 [23040/60000 (38%)] Loss: -1562.126343\n",
      "Train Epoch: 3524 [34304/60000 (57%)] Loss: -1547.548340\n",
      "Train Epoch: 3524 [45568/60000 (76%)] Loss: -1558.746826\n",
      "Train Epoch: 3524 [56832/60000 (95%)] Loss: -1385.836060\n",
      "    epoch          : 3524\n",
      "    loss           : -1523.4671213613392\n",
      "Train Epoch: 3525 [512/60000 (1%)] Loss: -1515.588745\n",
      "Train Epoch: 3525 [11776/60000 (20%)] Loss: -1535.705322\n",
      "Train Epoch: 3525 [23040/60000 (38%)] Loss: -1420.671265\n",
      "Train Epoch: 3525 [34304/60000 (57%)] Loss: -1571.377808\n",
      "Train Epoch: 3525 [45568/60000 (76%)] Loss: -1520.124512\n",
      "Train Epoch: 3525 [56832/60000 (95%)] Loss: -1604.837402\n",
      "    epoch          : 3525\n",
      "    loss           : -1521.7274987172273\n",
      "Train Epoch: 3526 [512/60000 (1%)] Loss: -1509.603394\n",
      "Train Epoch: 3526 [11776/60000 (20%)] Loss: -1518.982178\n",
      "Train Epoch: 3526 [23040/60000 (38%)] Loss: -1496.155884\n",
      "Train Epoch: 3526 [34304/60000 (57%)] Loss: -1532.724487\n",
      "Train Epoch: 3526 [45568/60000 (76%)] Loss: -1471.562012\n",
      "Train Epoch: 3526 [56832/60000 (95%)] Loss: -1477.382568\n",
      "    epoch          : 3526\n",
      "    loss           : -1520.2479444600767\n",
      "Train Epoch: 3527 [512/60000 (1%)] Loss: -1541.613159\n",
      "Train Epoch: 3527 [11776/60000 (20%)] Loss: -1439.106079\n",
      "Train Epoch: 3527 [23040/60000 (38%)] Loss: -1530.188721\n",
      "Train Epoch: 3527 [34304/60000 (57%)] Loss: -1565.776001\n",
      "Train Epoch: 3527 [45568/60000 (76%)] Loss: -1543.486938\n",
      "Train Epoch: 3527 [56832/60000 (95%)] Loss: -1475.354736\n",
      "    epoch          : 3527\n",
      "    loss           : -1515.6233630853858\n",
      "Train Epoch: 3528 [512/60000 (1%)] Loss: -1587.500977\n",
      "Train Epoch: 3528 [11776/60000 (20%)] Loss: -1469.290527\n",
      "Train Epoch: 3528 [23040/60000 (38%)] Loss: -1532.843994\n",
      "Train Epoch: 3528 [34304/60000 (57%)] Loss: -1588.414062\n",
      "Train Epoch: 3528 [45568/60000 (76%)] Loss: -1531.411987\n",
      "Train Epoch: 3528 [56832/60000 (95%)] Loss: -1540.881104\n",
      "    epoch          : 3528\n",
      "    loss           : -1524.6354183908236\n",
      "Train Epoch: 3529 [512/60000 (1%)] Loss: -1513.291504\n",
      "Train Epoch: 3529 [11776/60000 (20%)] Loss: -1569.964600\n",
      "Train Epoch: 3529 [23040/60000 (38%)] Loss: -1530.009155\n",
      "Train Epoch: 3529 [34304/60000 (57%)] Loss: -1484.995483\n",
      "Train Epoch: 3529 [45568/60000 (76%)] Loss: -1518.859375\n",
      "Train Epoch: 3529 [56832/60000 (95%)] Loss: -1513.634155\n",
      "    epoch          : 3529\n",
      "    loss           : -1522.667601159737\n",
      "Train Epoch: 3530 [512/60000 (1%)] Loss: -1501.681152\n",
      "Train Epoch: 3530 [11776/60000 (20%)] Loss: -1542.694214\n",
      "Train Epoch: 3530 [23040/60000 (38%)] Loss: -1559.355957\n",
      "Train Epoch: 3530 [34304/60000 (57%)] Loss: -1514.627808\n",
      "Train Epoch: 3530 [45568/60000 (76%)] Loss: -1539.531738\n",
      "Train Epoch: 3530 [56832/60000 (95%)] Loss: -1469.117065\n",
      "    epoch          : 3530\n",
      "    loss           : -1528.5604006664903\n",
      "Train Epoch: 3531 [512/60000 (1%)] Loss: -1511.207886\n",
      "Train Epoch: 3531 [11776/60000 (20%)] Loss: -1536.410522\n",
      "Train Epoch: 3531 [23040/60000 (38%)] Loss: -1510.098267\n",
      "Train Epoch: 3531 [34304/60000 (57%)] Loss: -1569.879761\n",
      "Train Epoch: 3531 [45568/60000 (76%)] Loss: -1570.350586\n",
      "Train Epoch: 3531 [56832/60000 (95%)] Loss: -1538.398926\n",
      "    epoch          : 3531\n",
      "    loss           : -1526.1985752946239\n",
      "Train Epoch: 3532 [512/60000 (1%)] Loss: -1573.906372\n",
      "Train Epoch: 3532 [11776/60000 (20%)] Loss: -1578.699951\n",
      "Train Epoch: 3532 [23040/60000 (38%)] Loss: -1479.851318\n",
      "Train Epoch: 3532 [34304/60000 (57%)] Loss: -1500.384033\n",
      "Train Epoch: 3532 [45568/60000 (76%)] Loss: -1464.287109\n",
      "Train Epoch: 3532 [56832/60000 (95%)] Loss: -1539.019409\n",
      "    epoch          : 3532\n",
      "    loss           : -1518.303533004502\n",
      "Train Epoch: 3533 [512/60000 (1%)] Loss: -1527.236328\n",
      "Train Epoch: 3533 [11776/60000 (20%)] Loss: -1513.672363\n",
      "Train Epoch: 3533 [23040/60000 (38%)] Loss: -1454.627441\n",
      "Train Epoch: 3533 [34304/60000 (57%)] Loss: -1518.385254\n",
      "Train Epoch: 3533 [45568/60000 (76%)] Loss: -1579.233643\n",
      "Train Epoch: 3533 [56832/60000 (95%)] Loss: -1535.033447\n",
      "    epoch          : 3533\n",
      "    loss           : -1527.3047057760639\n",
      "Train Epoch: 3534 [512/60000 (1%)] Loss: -1468.691162\n",
      "Train Epoch: 3534 [11776/60000 (20%)] Loss: -1557.476196\n",
      "Train Epoch: 3534 [23040/60000 (38%)] Loss: -1472.864014\n",
      "Train Epoch: 3534 [34304/60000 (57%)] Loss: -1573.058838\n",
      "Train Epoch: 3534 [45568/60000 (76%)] Loss: -1584.230225\n",
      "Train Epoch: 3534 [56832/60000 (95%)] Loss: -1498.102417\n",
      "    epoch          : 3534\n",
      "    loss           : -1517.9467080326403\n",
      "Train Epoch: 3535 [512/60000 (1%)] Loss: -1502.651367\n",
      "Train Epoch: 3535 [11776/60000 (20%)] Loss: -1502.812744\n",
      "Train Epoch: 3535 [23040/60000 (38%)] Loss: -1504.168701\n",
      "Train Epoch: 3535 [34304/60000 (57%)] Loss: -1565.273438\n",
      "Train Epoch: 3535 [45568/60000 (76%)] Loss: -1577.351440\n",
      "Train Epoch: 3535 [56832/60000 (95%)] Loss: -1542.788574\n",
      "    epoch          : 3535\n",
      "    loss           : -1518.7874562753796\n",
      "Train Epoch: 3536 [512/60000 (1%)] Loss: -1579.454102\n",
      "Train Epoch: 3536 [11776/60000 (20%)] Loss: -1615.588867\n",
      "Train Epoch: 3536 [23040/60000 (38%)] Loss: -1524.305664\n",
      "Train Epoch: 3536 [34304/60000 (57%)] Loss: -1549.807373\n",
      "Train Epoch: 3536 [45568/60000 (76%)] Loss: -1493.270874\n",
      "Train Epoch: 3536 [56832/60000 (95%)] Loss: -1493.969116\n",
      "    epoch          : 3536\n",
      "    loss           : -1525.7042853576315\n",
      "Train Epoch: 3537 [512/60000 (1%)] Loss: -1605.439453\n",
      "Train Epoch: 3537 [11776/60000 (20%)] Loss: -1516.038086\n",
      "Train Epoch: 3537 [23040/60000 (38%)] Loss: -1495.336426\n",
      "Train Epoch: 3537 [34304/60000 (57%)] Loss: -1524.420898\n",
      "Train Epoch: 3537 [45568/60000 (76%)] Loss: -1457.140747\n",
      "Train Epoch: 3537 [56832/60000 (95%)] Loss: -1504.768311\n",
      "    epoch          : 3537\n",
      "    loss           : -1511.266798116393\n",
      "Train Epoch: 3538 [512/60000 (1%)] Loss: -1434.107788\n",
      "Train Epoch: 3538 [11776/60000 (20%)] Loss: -1499.682617\n",
      "Train Epoch: 3538 [23040/60000 (38%)] Loss: -1560.514648\n",
      "Train Epoch: 3538 [34304/60000 (57%)] Loss: -1532.989258\n",
      "Train Epoch: 3538 [45568/60000 (76%)] Loss: -1492.796143\n",
      "Train Epoch: 3538 [56832/60000 (95%)] Loss: -1511.669678\n",
      "    epoch          : 3538\n",
      "    loss           : -1517.7038384561486\n",
      "Train Epoch: 3539 [512/60000 (1%)] Loss: -1563.507080\n",
      "Train Epoch: 3539 [11776/60000 (20%)] Loss: -1467.298462\n",
      "Train Epoch: 3539 [23040/60000 (38%)] Loss: -1454.160767\n",
      "Train Epoch: 3539 [34304/60000 (57%)] Loss: -1499.895996\n",
      "Train Epoch: 3539 [45568/60000 (76%)] Loss: -1545.986206\n",
      "Train Epoch: 3539 [56832/60000 (95%)] Loss: -1517.986450\n",
      "    epoch          : 3539\n",
      "    loss           : -1521.9946923552259\n",
      "Train Epoch: 3540 [512/60000 (1%)] Loss: -1513.275879\n",
      "Train Epoch: 3540 [11776/60000 (20%)] Loss: -1546.627808\n",
      "Train Epoch: 3540 [23040/60000 (38%)] Loss: -1439.230957\n",
      "Train Epoch: 3540 [34304/60000 (57%)] Loss: -1443.458740\n",
      "Train Epoch: 3540 [45568/60000 (76%)] Loss: -1495.015991\n",
      "Train Epoch: 3540 [56832/60000 (95%)] Loss: -1580.145996\n",
      "    epoch          : 3540\n",
      "    loss           : -1514.8890508446989\n",
      "Train Epoch: 3541 [512/60000 (1%)] Loss: -1586.700684\n",
      "Train Epoch: 3541 [11776/60000 (20%)] Loss: -1468.681763\n",
      "Train Epoch: 3541 [23040/60000 (38%)] Loss: -1448.221924\n",
      "Train Epoch: 3541 [34304/60000 (57%)] Loss: -1575.924316\n",
      "Train Epoch: 3541 [45568/60000 (76%)] Loss: -1525.152832\n",
      "Train Epoch: 3541 [56832/60000 (95%)] Loss: -1508.421509\n",
      "    epoch          : 3541\n",
      "    loss           : -1526.2946694584216\n",
      "Train Epoch: 3542 [512/60000 (1%)] Loss: -1596.964600\n",
      "Train Epoch: 3542 [11776/60000 (20%)] Loss: -1516.208862\n",
      "Train Epoch: 3542 [23040/60000 (38%)] Loss: -1482.542480\n",
      "Train Epoch: 3542 [34304/60000 (57%)] Loss: -1502.555176\n",
      "Train Epoch: 3542 [45568/60000 (76%)] Loss: -1589.365967\n",
      "Train Epoch: 3542 [56832/60000 (95%)] Loss: -1586.660645\n",
      "    epoch          : 3542\n",
      "    loss           : -1527.3074464959614\n",
      "Train Epoch: 3543 [512/60000 (1%)] Loss: -1460.996338\n",
      "Train Epoch: 3543 [11776/60000 (20%)] Loss: -1565.455444\n",
      "Train Epoch: 3543 [23040/60000 (38%)] Loss: -1420.340454\n",
      "Train Epoch: 3543 [34304/60000 (57%)] Loss: -1445.664917\n",
      "Train Epoch: 3543 [45568/60000 (76%)] Loss: -1582.789062\n",
      "Train Epoch: 3543 [56832/60000 (95%)] Loss: -1618.193115\n",
      "    epoch          : 3543\n",
      "    loss           : -1527.106158757614\n",
      "Train Epoch: 3544 [512/60000 (1%)] Loss: -1604.448730\n",
      "Train Epoch: 3544 [11776/60000 (20%)] Loss: -1514.371704\n",
      "Train Epoch: 3544 [23040/60000 (38%)] Loss: -1543.617920\n",
      "Train Epoch: 3544 [34304/60000 (57%)] Loss: -1571.391357\n",
      "Train Epoch: 3544 [45568/60000 (76%)] Loss: -1512.743896\n",
      "Train Epoch: 3544 [56832/60000 (95%)] Loss: -1478.070312\n",
      "    epoch          : 3544\n",
      "    loss           : -1523.280796201889\n",
      "Train Epoch: 3545 [512/60000 (1%)] Loss: -1539.900146\n",
      "Train Epoch: 3545 [11776/60000 (20%)] Loss: -1537.490356\n",
      "Train Epoch: 3545 [23040/60000 (38%)] Loss: -1617.911743\n",
      "Train Epoch: 3545 [34304/60000 (57%)] Loss: -1510.909180\n",
      "Train Epoch: 3545 [45568/60000 (76%)] Loss: -1559.722656\n",
      "Train Epoch: 3545 [56832/60000 (95%)] Loss: -1461.626953\n",
      "    epoch          : 3545\n",
      "    loss           : -1524.1613617805438\n",
      "Train Epoch: 3546 [512/60000 (1%)] Loss: -1540.750488\n",
      "Train Epoch: 3546 [11776/60000 (20%)] Loss: -1516.165283\n",
      "Train Epoch: 3546 [23040/60000 (38%)] Loss: -1451.324463\n",
      "Train Epoch: 3546 [34304/60000 (57%)] Loss: -1478.153564\n",
      "Train Epoch: 3546 [45568/60000 (76%)] Loss: -1501.885376\n",
      "Train Epoch: 3546 [56832/60000 (95%)] Loss: -1504.086914\n",
      "    epoch          : 3546\n",
      "    loss           : -1517.2643846414858\n",
      "Train Epoch: 3547 [512/60000 (1%)] Loss: -1455.536133\n",
      "Train Epoch: 3547 [11776/60000 (20%)] Loss: -1518.054810\n",
      "Train Epoch: 3547 [23040/60000 (38%)] Loss: -1585.466309\n",
      "Train Epoch: 3547 [34304/60000 (57%)] Loss: -1507.315552\n",
      "Train Epoch: 3547 [45568/60000 (76%)] Loss: -1523.658691\n",
      "Train Epoch: 3547 [56832/60000 (95%)] Loss: -1460.175293\n",
      "    epoch          : 3547\n",
      "    loss           : -1524.9972306590969\n",
      "Train Epoch: 3548 [512/60000 (1%)] Loss: -1462.210815\n",
      "Train Epoch: 3548 [11776/60000 (20%)] Loss: -1539.243530\n",
      "Train Epoch: 3548 [23040/60000 (38%)] Loss: -1515.266113\n",
      "Train Epoch: 3548 [34304/60000 (57%)] Loss: -1507.889526\n",
      "Train Epoch: 3548 [45568/60000 (76%)] Loss: -1465.055298\n",
      "Train Epoch: 3548 [56832/60000 (95%)] Loss: -1573.285645\n",
      "    epoch          : 3548\n",
      "    loss           : -1519.16238696427\n",
      "Train Epoch: 3549 [512/60000 (1%)] Loss: -1543.008057\n",
      "Train Epoch: 3549 [11776/60000 (20%)] Loss: -1496.549805\n",
      "Train Epoch: 3549 [23040/60000 (38%)] Loss: -1493.762939\n",
      "Train Epoch: 3549 [34304/60000 (57%)] Loss: -1508.671875\n",
      "Train Epoch: 3549 [45568/60000 (76%)] Loss: -1517.484497\n",
      "Train Epoch: 3549 [56832/60000 (95%)] Loss: -1436.658447\n",
      "    epoch          : 3549\n",
      "    loss           : -1519.4884595278293\n",
      "Train Epoch: 3550 [512/60000 (1%)] Loss: -1588.608643\n",
      "Train Epoch: 3550 [11776/60000 (20%)] Loss: -1567.732178\n",
      "Train Epoch: 3550 [23040/60000 (38%)] Loss: -1580.114746\n",
      "Train Epoch: 3550 [34304/60000 (57%)] Loss: -1470.981201\n",
      "Train Epoch: 3550 [45568/60000 (76%)] Loss: -1490.940063\n",
      "Train Epoch: 3550 [56832/60000 (95%)] Loss: -1548.858887\n",
      "    epoch          : 3550\n",
      "    loss           : -1526.2625328969148\n",
      "Train Epoch: 3551 [512/60000 (1%)] Loss: -1527.569946\n",
      "Train Epoch: 3551 [11776/60000 (20%)] Loss: -1523.576660\n",
      "Train Epoch: 3551 [23040/60000 (38%)] Loss: -1618.089966\n",
      "Train Epoch: 3551 [34304/60000 (57%)] Loss: -1521.441528\n",
      "Train Epoch: 3551 [45568/60000 (76%)] Loss: -1421.352417\n",
      "Train Epoch: 3551 [56832/60000 (95%)] Loss: -1579.956787\n",
      "    epoch          : 3551\n",
      "    loss           : -1526.957991950256\n",
      "Train Epoch: 3552 [512/60000 (1%)] Loss: -1465.364990\n",
      "Train Epoch: 3552 [11776/60000 (20%)] Loss: -1505.192139\n",
      "Train Epoch: 3552 [23040/60000 (38%)] Loss: -1554.229248\n",
      "Train Epoch: 3552 [34304/60000 (57%)] Loss: -1484.125610\n",
      "Train Epoch: 3552 [45568/60000 (76%)] Loss: -1490.212646\n",
      "Train Epoch: 3552 [56832/60000 (95%)] Loss: -1469.499634\n",
      "    epoch          : 3552\n",
      "    loss           : -1524.4546063956568\n",
      "Train Epoch: 3553 [512/60000 (1%)] Loss: -1503.769043\n",
      "Train Epoch: 3553 [11776/60000 (20%)] Loss: -1416.053589\n",
      "Train Epoch: 3553 [23040/60000 (38%)] Loss: -1469.369019\n",
      "Train Epoch: 3553 [34304/60000 (57%)] Loss: -1508.645508\n",
      "Train Epoch: 3553 [45568/60000 (76%)] Loss: -1505.729004\n",
      "Train Epoch: 3553 [56832/60000 (95%)] Loss: -1483.772339\n",
      "    epoch          : 3553\n",
      "    loss           : -1524.8488241939222\n",
      "Train Epoch: 3554 [512/60000 (1%)] Loss: -1402.262207\n",
      "Train Epoch: 3554 [11776/60000 (20%)] Loss: -1597.251831\n",
      "Train Epoch: 3554 [23040/60000 (38%)] Loss: -1528.851074\n",
      "Train Epoch: 3554 [34304/60000 (57%)] Loss: -1621.764404\n",
      "Train Epoch: 3554 [45568/60000 (76%)] Loss: -1614.619019\n",
      "Train Epoch: 3554 [56832/60000 (95%)] Loss: -1504.785400\n",
      "    epoch          : 3554\n",
      "    loss           : -1530.350187312412\n",
      "Train Epoch: 3555 [512/60000 (1%)] Loss: -1500.056396\n",
      "Train Epoch: 3555 [11776/60000 (20%)] Loss: -1552.143311\n",
      "Train Epoch: 3555 [23040/60000 (38%)] Loss: -1453.384033\n",
      "Train Epoch: 3555 [34304/60000 (57%)] Loss: -1432.013916\n",
      "Train Epoch: 3555 [45568/60000 (76%)] Loss: -1559.283447\n",
      "Train Epoch: 3555 [56832/60000 (95%)] Loss: -1537.833130\n",
      "    epoch          : 3555\n",
      "    loss           : -1516.6365890933969\n",
      "Train Epoch: 3556 [512/60000 (1%)] Loss: -1579.604370\n",
      "Train Epoch: 3556 [11776/60000 (20%)] Loss: -1496.297241\n",
      "Train Epoch: 3556 [23040/60000 (38%)] Loss: -1525.025879\n",
      "Train Epoch: 3556 [34304/60000 (57%)] Loss: -1559.635864\n",
      "Train Epoch: 3556 [45568/60000 (76%)] Loss: -1430.371338\n",
      "Train Epoch: 3556 [56832/60000 (95%)] Loss: -1447.596924\n",
      "    epoch          : 3556\n",
      "    loss           : -1519.4349068679378\n",
      "Train Epoch: 3557 [512/60000 (1%)] Loss: -1437.049072\n",
      "Train Epoch: 3557 [11776/60000 (20%)] Loss: -1432.996338\n",
      "Train Epoch: 3557 [23040/60000 (38%)] Loss: -1516.080566\n",
      "Train Epoch: 3557 [34304/60000 (57%)] Loss: -1602.248535\n",
      "Train Epoch: 3557 [45568/60000 (76%)] Loss: -1459.703369\n",
      "Train Epoch: 3557 [56832/60000 (95%)] Loss: -1378.029663\n",
      "    epoch          : 3557\n",
      "    loss           : -1517.5938834497483\n",
      "Train Epoch: 3558 [512/60000 (1%)] Loss: -1606.249390\n",
      "Train Epoch: 3558 [11776/60000 (20%)] Loss: -1576.800049\n",
      "Train Epoch: 3558 [23040/60000 (38%)] Loss: -1453.888428\n",
      "Train Epoch: 3558 [34304/60000 (57%)] Loss: -1456.112305\n",
      "Train Epoch: 3558 [45568/60000 (76%)] Loss: -1504.746582\n",
      "Train Epoch: 3558 [56832/60000 (95%)] Loss: -1516.251465\n",
      "    epoch          : 3558\n",
      "    loss           : -1518.4900836836819\n",
      "Train Epoch: 3559 [512/60000 (1%)] Loss: -1506.916138\n",
      "Train Epoch: 3559 [11776/60000 (20%)] Loss: -1545.029907\n",
      "Train Epoch: 3559 [23040/60000 (38%)] Loss: -1556.654419\n",
      "Train Epoch: 3559 [34304/60000 (57%)] Loss: -1459.649048\n",
      "Train Epoch: 3559 [45568/60000 (76%)] Loss: -1525.939819\n",
      "Train Epoch: 3559 [56832/60000 (95%)] Loss: -1514.222656\n",
      "    epoch          : 3559\n",
      "    loss           : -1528.309286516265\n",
      "Train Epoch: 3560 [512/60000 (1%)] Loss: -1568.799072\n",
      "Train Epoch: 3560 [11776/60000 (20%)] Loss: -1551.223877\n",
      "Train Epoch: 3560 [23040/60000 (38%)] Loss: -1552.941650\n",
      "Train Epoch: 3560 [34304/60000 (57%)] Loss: -1502.745605\n",
      "Train Epoch: 3560 [45568/60000 (76%)] Loss: -1588.542969\n",
      "Train Epoch: 3560 [56832/60000 (95%)] Loss: -1523.120850\n",
      "    epoch          : 3560\n",
      "    loss           : -1530.294020140912\n",
      "Train Epoch: 3561 [512/60000 (1%)] Loss: -1546.492676\n",
      "Train Epoch: 3561 [11776/60000 (20%)] Loss: -1499.697266\n",
      "Train Epoch: 3561 [23040/60000 (38%)] Loss: -1538.648438\n",
      "Train Epoch: 3561 [34304/60000 (57%)] Loss: -1410.795654\n",
      "Train Epoch: 3561 [45568/60000 (76%)] Loss: -1544.520508\n",
      "Train Epoch: 3561 [56832/60000 (95%)] Loss: -1566.460327\n",
      "    epoch          : 3561\n",
      "    loss           : -1521.7245528226517\n",
      "Train Epoch: 3562 [512/60000 (1%)] Loss: -1484.812012\n",
      "Train Epoch: 3562 [11776/60000 (20%)] Loss: -1573.479980\n",
      "Train Epoch: 3562 [23040/60000 (38%)] Loss: -1548.783691\n",
      "Train Epoch: 3562 [34304/60000 (57%)] Loss: -1594.220215\n",
      "Train Epoch: 3562 [45568/60000 (76%)] Loss: -1542.015991\n",
      "Train Epoch: 3562 [56832/60000 (95%)] Loss: -1584.837646\n",
      "    epoch          : 3562\n",
      "    loss           : -1528.3408241056454\n",
      "Train Epoch: 3563 [512/60000 (1%)] Loss: -1539.509644\n",
      "Train Epoch: 3563 [11776/60000 (20%)] Loss: -1516.889893\n",
      "Train Epoch: 3563 [23040/60000 (38%)] Loss: -1613.912720\n",
      "Train Epoch: 3563 [34304/60000 (57%)] Loss: -1553.137207\n",
      "Train Epoch: 3563 [45568/60000 (76%)] Loss: -1463.868286\n",
      "Train Epoch: 3563 [56832/60000 (95%)] Loss: -1578.531372\n",
      "    epoch          : 3563\n",
      "    loss           : -1515.002841410664\n",
      "Train Epoch: 3564 [512/60000 (1%)] Loss: -1525.028076\n",
      "Train Epoch: 3564 [11776/60000 (20%)] Loss: -1579.566650\n",
      "Train Epoch: 3564 [23040/60000 (38%)] Loss: -1570.761475\n",
      "Train Epoch: 3564 [34304/60000 (57%)] Loss: -1411.000977\n",
      "Train Epoch: 3564 [45568/60000 (76%)] Loss: -1530.478027\n",
      "Train Epoch: 3564 [56832/60000 (95%)] Loss: -1566.513184\n",
      "    epoch          : 3564\n",
      "    loss           : -1521.9981361863302\n",
      "Train Epoch: 3565 [512/60000 (1%)] Loss: -1531.208984\n",
      "Train Epoch: 3565 [11776/60000 (20%)] Loss: -1525.952393\n",
      "Train Epoch: 3565 [23040/60000 (38%)] Loss: -1579.433838\n",
      "Train Epoch: 3565 [34304/60000 (57%)] Loss: -1552.855591\n",
      "Train Epoch: 3565 [45568/60000 (76%)] Loss: -1552.562012\n",
      "Train Epoch: 3565 [56832/60000 (95%)] Loss: -1506.722900\n",
      "    epoch          : 3565\n",
      "    loss           : -1528.9230677717824\n",
      "Train Epoch: 3566 [512/60000 (1%)] Loss: -1536.911987\n",
      "Train Epoch: 3566 [11776/60000 (20%)] Loss: -1564.884766\n",
      "Train Epoch: 3566 [23040/60000 (38%)] Loss: -1526.697754\n",
      "Train Epoch: 3566 [34304/60000 (57%)] Loss: -1568.093506\n",
      "Train Epoch: 3566 [45568/60000 (76%)] Loss: -1560.790405\n",
      "Train Epoch: 3566 [56832/60000 (95%)] Loss: -1536.740967\n",
      "    epoch          : 3566\n",
      "    loss           : -1527.0038738358494\n",
      "Train Epoch: 3567 [512/60000 (1%)] Loss: -1524.845947\n",
      "Train Epoch: 3567 [11776/60000 (20%)] Loss: -1554.191040\n",
      "Train Epoch: 3567 [23040/60000 (38%)] Loss: -1454.153687\n",
      "Train Epoch: 3567 [34304/60000 (57%)] Loss: -1536.048462\n",
      "Train Epoch: 3567 [45568/60000 (76%)] Loss: -1459.962158\n",
      "Train Epoch: 3567 [56832/60000 (95%)] Loss: -1465.104614\n",
      "    epoch          : 3567\n",
      "    loss           : -1523.0469894840219\n",
      "Train Epoch: 3568 [512/60000 (1%)] Loss: -1518.625732\n",
      "Train Epoch: 3568 [11776/60000 (20%)] Loss: -1536.559204\n",
      "Train Epoch: 3568 [23040/60000 (38%)] Loss: -1524.891479\n",
      "Train Epoch: 3568 [34304/60000 (57%)] Loss: -1490.247192\n",
      "Train Epoch: 3568 [45568/60000 (76%)] Loss: -1547.688599\n",
      "Train Epoch: 3568 [56832/60000 (95%)] Loss: -1436.048218\n",
      "    epoch          : 3568\n",
      "    loss           : -1523.547076036701\n",
      "Train Epoch: 3569 [512/60000 (1%)] Loss: -1479.235352\n",
      "Train Epoch: 3569 [11776/60000 (20%)] Loss: -1489.656006\n",
      "Train Epoch: 3569 [23040/60000 (38%)] Loss: -1547.239014\n",
      "Train Epoch: 3569 [34304/60000 (57%)] Loss: -1563.336304\n",
      "Train Epoch: 3569 [45568/60000 (76%)] Loss: -1553.163574\n",
      "Train Epoch: 3569 [56832/60000 (95%)] Loss: -1528.956787\n",
      "    epoch          : 3569\n",
      "    loss           : -1522.0367279914813\n",
      "Train Epoch: 3570 [512/60000 (1%)] Loss: -1508.320679\n",
      "Train Epoch: 3570 [11776/60000 (20%)] Loss: -1543.042480\n",
      "Train Epoch: 3570 [23040/60000 (38%)] Loss: -1607.719238\n",
      "Train Epoch: 3570 [34304/60000 (57%)] Loss: -1410.208252\n",
      "Train Epoch: 3570 [45568/60000 (76%)] Loss: -1554.131958\n",
      "Train Epoch: 3570 [56832/60000 (95%)] Loss: -1584.525513\n",
      "    epoch          : 3570\n",
      "    loss           : -1524.5142149844412\n",
      "Train Epoch: 3571 [512/60000 (1%)] Loss: -1510.156128\n",
      "Train Epoch: 3571 [11776/60000 (20%)] Loss: -1522.130737\n",
      "Train Epoch: 3571 [23040/60000 (38%)] Loss: -1475.651855\n",
      "Train Epoch: 3571 [34304/60000 (57%)] Loss: -1542.037964\n",
      "Train Epoch: 3571 [45568/60000 (76%)] Loss: -1539.068604\n",
      "Train Epoch: 3571 [56832/60000 (95%)] Loss: -1525.611938\n",
      "    epoch          : 3571\n",
      "    loss           : -1528.3649695444915\n",
      "Train Epoch: 3572 [512/60000 (1%)] Loss: -1467.083984\n",
      "Train Epoch: 3572 [11776/60000 (20%)] Loss: -1598.506958\n",
      "Train Epoch: 3572 [23040/60000 (38%)] Loss: -1523.688721\n",
      "Train Epoch: 3572 [34304/60000 (57%)] Loss: -1576.223633\n",
      "Train Epoch: 3572 [45568/60000 (76%)] Loss: -1559.955688\n",
      "Train Epoch: 3572 [56832/60000 (95%)] Loss: -1534.258179\n",
      "    epoch          : 3572\n",
      "    loss           : -1525.8232866707494\n",
      "Train Epoch: 3573 [512/60000 (1%)] Loss: -1522.180298\n",
      "Train Epoch: 3573 [11776/60000 (20%)] Loss: -1605.403076\n",
      "Train Epoch: 3573 [23040/60000 (38%)] Loss: -1471.930664\n",
      "Train Epoch: 3573 [34304/60000 (57%)] Loss: -1441.614502\n",
      "Train Epoch: 3573 [45568/60000 (76%)] Loss: -1480.136475\n",
      "Train Epoch: 3573 [56832/60000 (95%)] Loss: -1481.554443\n",
      "    epoch          : 3573\n",
      "    loss           : -1519.077487751589\n",
      "Train Epoch: 3574 [512/60000 (1%)] Loss: -1564.153320\n",
      "Train Epoch: 3574 [11776/60000 (20%)] Loss: -1529.062500\n",
      "Train Epoch: 3574 [23040/60000 (38%)] Loss: -1498.227905\n",
      "Train Epoch: 3574 [34304/60000 (57%)] Loss: -1550.447021\n",
      "Train Epoch: 3574 [45568/60000 (76%)] Loss: -1558.806885\n",
      "Train Epoch: 3574 [56832/60000 (95%)] Loss: -1511.313965\n",
      "    epoch          : 3574\n",
      "    loss           : -1521.0012500137932\n",
      "Train Epoch: 3575 [512/60000 (1%)] Loss: -1602.909912\n",
      "Train Epoch: 3575 [11776/60000 (20%)] Loss: -1550.478149\n",
      "Train Epoch: 3575 [23040/60000 (38%)] Loss: -1415.755981\n",
      "Train Epoch: 3575 [34304/60000 (57%)] Loss: -1570.983276\n",
      "Train Epoch: 3575 [45568/60000 (76%)] Loss: -1552.362061\n",
      "Train Epoch: 3575 [56832/60000 (95%)] Loss: -1511.571533\n",
      "    epoch          : 3575\n",
      "    loss           : -1529.1884486311574\n",
      "Train Epoch: 3576 [512/60000 (1%)] Loss: -1434.420410\n",
      "Train Epoch: 3576 [11776/60000 (20%)] Loss: -1444.414795\n",
      "Train Epoch: 3576 [23040/60000 (38%)] Loss: -1573.294800\n",
      "Train Epoch: 3576 [34304/60000 (57%)] Loss: -1413.598022\n",
      "Train Epoch: 3576 [45568/60000 (76%)] Loss: -1499.600098\n",
      "Train Epoch: 3576 [56832/60000 (95%)] Loss: -1592.425537\n",
      "    epoch          : 3576\n",
      "    loss           : -1514.9301978504589\n",
      "Train Epoch: 3577 [512/60000 (1%)] Loss: -1498.090088\n",
      "Train Epoch: 3577 [11776/60000 (20%)] Loss: -1467.234009\n",
      "Train Epoch: 3577 [23040/60000 (38%)] Loss: -1465.797119\n",
      "Train Epoch: 3577 [34304/60000 (57%)] Loss: -1426.260742\n",
      "Train Epoch: 3577 [45568/60000 (76%)] Loss: -1512.738159\n",
      "Train Epoch: 3577 [56832/60000 (95%)] Loss: -1476.858643\n",
      "    epoch          : 3577\n",
      "    loss           : -1514.9544746700653\n",
      "Train Epoch: 3578 [512/60000 (1%)] Loss: -1579.124512\n",
      "Train Epoch: 3578 [11776/60000 (20%)] Loss: -1470.095703\n",
      "Train Epoch: 3578 [23040/60000 (38%)] Loss: -1588.156982\n",
      "Train Epoch: 3578 [34304/60000 (57%)] Loss: -1488.648926\n",
      "Train Epoch: 3578 [45568/60000 (76%)] Loss: -1492.938843\n",
      "Train Epoch: 3578 [56832/60000 (95%)] Loss: -1576.991455\n",
      "    epoch          : 3578\n",
      "    loss           : -1517.2854531498278\n",
      "Train Epoch: 3579 [512/60000 (1%)] Loss: -1595.217529\n",
      "Train Epoch: 3579 [11776/60000 (20%)] Loss: -1492.439941\n",
      "Train Epoch: 3579 [23040/60000 (38%)] Loss: -1544.396973\n",
      "Train Epoch: 3579 [34304/60000 (57%)] Loss: -1493.245483\n",
      "Train Epoch: 3579 [45568/60000 (76%)] Loss: -1488.936523\n",
      "Train Epoch: 3579 [56832/60000 (95%)] Loss: -1510.784424\n",
      "    epoch          : 3579\n",
      "    loss           : -1519.1534185894466\n",
      "Train Epoch: 3580 [512/60000 (1%)] Loss: -1576.266602\n",
      "Train Epoch: 3580 [11776/60000 (20%)] Loss: -1584.822510\n",
      "Train Epoch: 3580 [23040/60000 (38%)] Loss: -1510.381104\n",
      "Train Epoch: 3580 [34304/60000 (57%)] Loss: -1546.875732\n",
      "Train Epoch: 3580 [45568/60000 (76%)] Loss: -1488.223755\n",
      "Train Epoch: 3580 [56832/60000 (95%)] Loss: -1529.176758\n",
      "    epoch          : 3580\n",
      "    loss           : -1527.9963958222988\n",
      "Train Epoch: 3581 [512/60000 (1%)] Loss: -1434.140625\n",
      "Train Epoch: 3581 [11776/60000 (20%)] Loss: -1445.129150\n",
      "Train Epoch: 3581 [23040/60000 (38%)] Loss: -1538.120850\n",
      "Train Epoch: 3581 [34304/60000 (57%)] Loss: -1575.649658\n",
      "Train Epoch: 3581 [45568/60000 (76%)] Loss: -1501.340942\n",
      "Train Epoch: 3581 [56832/60000 (95%)] Loss: -1554.098877\n",
      "    epoch          : 3581\n",
      "    loss           : -1527.9800666765977\n",
      "Train Epoch: 3582 [512/60000 (1%)] Loss: -1502.005859\n",
      "Train Epoch: 3582 [11776/60000 (20%)] Loss: -1555.979370\n",
      "Train Epoch: 3582 [23040/60000 (38%)] Loss: -1562.805908\n",
      "Train Epoch: 3582 [34304/60000 (57%)] Loss: -1491.079956\n",
      "Train Epoch: 3582 [45568/60000 (76%)] Loss: -1479.796753\n",
      "Train Epoch: 3582 [56832/60000 (95%)] Loss: -1518.263672\n",
      "    epoch          : 3582\n",
      "    loss           : -1518.5816319352489\n",
      "Train Epoch: 3583 [512/60000 (1%)] Loss: -1550.319580\n",
      "Train Epoch: 3583 [11776/60000 (20%)] Loss: -1546.618164\n",
      "Train Epoch: 3583 [23040/60000 (38%)] Loss: -1577.449463\n",
      "Train Epoch: 3583 [34304/60000 (57%)] Loss: -1506.061523\n",
      "Train Epoch: 3583 [45568/60000 (76%)] Loss: -1522.156250\n",
      "Train Epoch: 3583 [56832/60000 (95%)] Loss: -1581.490601\n",
      "    epoch          : 3583\n",
      "    loss           : -1517.805725787319\n",
      "Train Epoch: 3584 [512/60000 (1%)] Loss: -1613.451660\n",
      "Train Epoch: 3584 [11776/60000 (20%)] Loss: -1522.673584\n",
      "Train Epoch: 3584 [23040/60000 (38%)] Loss: -1561.587280\n",
      "Train Epoch: 3584 [34304/60000 (57%)] Loss: -1436.615723\n",
      "Train Epoch: 3584 [45568/60000 (76%)] Loss: -1457.388794\n",
      "Train Epoch: 3584 [56832/60000 (95%)] Loss: -1613.007080\n",
      "    epoch          : 3584\n",
      "    loss           : -1525.4025503040034\n",
      "Train Epoch: 3585 [512/60000 (1%)] Loss: -1583.004517\n",
      "Train Epoch: 3585 [11776/60000 (20%)] Loss: -1440.651978\n",
      "Train Epoch: 3585 [23040/60000 (38%)] Loss: -1512.475586\n",
      "Train Epoch: 3585 [34304/60000 (57%)] Loss: -1506.185425\n",
      "Train Epoch: 3585 [45568/60000 (76%)] Loss: -1563.709473\n",
      "Train Epoch: 3585 [56832/60000 (95%)] Loss: -1508.255127\n",
      "    epoch          : 3585\n",
      "    loss           : -1525.4308488921258\n",
      "Train Epoch: 3586 [512/60000 (1%)] Loss: -1526.255981\n",
      "Train Epoch: 3586 [11776/60000 (20%)] Loss: -1468.072998\n",
      "Train Epoch: 3586 [23040/60000 (38%)] Loss: -1548.758057\n",
      "Train Epoch: 3586 [34304/60000 (57%)] Loss: -1533.966064\n",
      "Train Epoch: 3586 [45568/60000 (76%)] Loss: -1510.397461\n",
      "Train Epoch: 3586 [56832/60000 (95%)] Loss: -1557.138550\n",
      "    epoch          : 3586\n",
      "    loss           : -1523.6010652531338\n",
      "Train Epoch: 3587 [512/60000 (1%)] Loss: -1546.800293\n",
      "Train Epoch: 3587 [11776/60000 (20%)] Loss: -1571.052002\n",
      "Train Epoch: 3587 [23040/60000 (38%)] Loss: -1544.405762\n",
      "Train Epoch: 3587 [34304/60000 (57%)] Loss: -1579.386475\n",
      "Train Epoch: 3587 [45568/60000 (76%)] Loss: -1524.754761\n",
      "Train Epoch: 3587 [56832/60000 (95%)] Loss: -1555.315918\n",
      "    epoch          : 3587\n",
      "    loss           : -1527.4910602461819\n",
      "Train Epoch: 3588 [512/60000 (1%)] Loss: -1471.177612\n",
      "Train Epoch: 3588 [11776/60000 (20%)] Loss: -1491.188110\n",
      "Train Epoch: 3588 [23040/60000 (38%)] Loss: -1554.953247\n",
      "Train Epoch: 3588 [34304/60000 (57%)] Loss: -1501.955566\n",
      "Train Epoch: 3588 [45568/60000 (76%)] Loss: -1528.533081\n",
      "Train Epoch: 3588 [56832/60000 (95%)] Loss: -1449.363770\n",
      "    epoch          : 3588\n",
      "    loss           : -1516.1015718104475\n",
      "Train Epoch: 3589 [512/60000 (1%)] Loss: -1460.068481\n",
      "Train Epoch: 3589 [11776/60000 (20%)] Loss: -1492.378784\n",
      "Train Epoch: 3589 [23040/60000 (38%)] Loss: -1552.559814\n",
      "Train Epoch: 3589 [34304/60000 (57%)] Loss: -1502.638672\n",
      "Train Epoch: 3589 [45568/60000 (76%)] Loss: -1580.495728\n",
      "Train Epoch: 3589 [56832/60000 (95%)] Loss: -1505.799438\n",
      "    epoch          : 3589\n",
      "    loss           : -1511.9196994587526\n",
      "Train Epoch: 3590 [512/60000 (1%)] Loss: -1440.806885\n",
      "Train Epoch: 3590 [11776/60000 (20%)] Loss: -1464.053711\n",
      "Train Epoch: 3590 [23040/60000 (38%)] Loss: -1523.548828\n",
      "Train Epoch: 3590 [34304/60000 (57%)] Loss: -1571.602295\n",
      "Train Epoch: 3590 [45568/60000 (76%)] Loss: -1507.514160\n",
      "Train Epoch: 3590 [56832/60000 (95%)] Loss: -1534.288452\n",
      "    epoch          : 3590\n",
      "    loss           : -1527.2765633965616\n",
      "Train Epoch: 3591 [512/60000 (1%)] Loss: -1596.765137\n",
      "Train Epoch: 3591 [11776/60000 (20%)] Loss: -1546.145142\n",
      "Train Epoch: 3591 [23040/60000 (38%)] Loss: -1511.643799\n",
      "Train Epoch: 3591 [34304/60000 (57%)] Loss: -1578.109253\n",
      "Train Epoch: 3591 [45568/60000 (76%)] Loss: -1557.680664\n",
      "Train Epoch: 3591 [56832/60000 (95%)] Loss: -1491.651611\n",
      "    epoch          : 3591\n",
      "    loss           : -1522.0797446730448\n",
      "Train Epoch: 3592 [512/60000 (1%)] Loss: -1512.569336\n",
      "Train Epoch: 3592 [11776/60000 (20%)] Loss: -1589.326660\n",
      "Train Epoch: 3592 [23040/60000 (38%)] Loss: -1563.330811\n",
      "Train Epoch: 3592 [34304/60000 (57%)] Loss: -1442.444336\n",
      "Train Epoch: 3592 [45568/60000 (76%)] Loss: -1587.077393\n",
      "Train Epoch: 3592 [56832/60000 (95%)] Loss: -1485.442993\n",
      "    epoch          : 3592\n",
      "    loss           : -1520.4089148569915\n",
      "Train Epoch: 3593 [512/60000 (1%)] Loss: -1486.441162\n",
      "Train Epoch: 3593 [11776/60000 (20%)] Loss: -1570.496094\n",
      "Train Epoch: 3593 [23040/60000 (38%)] Loss: -1431.320068\n",
      "Train Epoch: 3593 [34304/60000 (57%)] Loss: -1454.477783\n",
      "Train Epoch: 3593 [45568/60000 (76%)] Loss: -1499.422119\n",
      "Train Epoch: 3593 [56832/60000 (95%)] Loss: -1585.686035\n",
      "    epoch          : 3593\n",
      "    loss           : -1528.6872079278116\n",
      "Train Epoch: 3594 [512/60000 (1%)] Loss: -1545.546143\n",
      "Train Epoch: 3594 [11776/60000 (20%)] Loss: -1525.698975\n",
      "Train Epoch: 3594 [23040/60000 (38%)] Loss: -1552.392944\n",
      "Train Epoch: 3594 [34304/60000 (57%)] Loss: -1574.787842\n",
      "Train Epoch: 3594 [45568/60000 (76%)] Loss: -1552.443115\n",
      "Train Epoch: 3594 [56832/60000 (95%)] Loss: -1571.284058\n",
      "    epoch          : 3594\n",
      "    loss           : -1526.657011387712\n",
      "Train Epoch: 3595 [512/60000 (1%)] Loss: -1529.724365\n",
      "Train Epoch: 3595 [11776/60000 (20%)] Loss: -1516.084717\n",
      "Train Epoch: 3595 [23040/60000 (38%)] Loss: -1523.698975\n",
      "Train Epoch: 3595 [34304/60000 (57%)] Loss: -1452.263306\n",
      "Train Epoch: 3595 [45568/60000 (76%)] Loss: -1459.783936\n",
      "Train Epoch: 3595 [56832/60000 (95%)] Loss: -1524.046997\n",
      "    epoch          : 3595\n",
      "    loss           : -1519.0598168669446\n",
      "Train Epoch: 3596 [512/60000 (1%)] Loss: -1501.069702\n",
      "Train Epoch: 3596 [11776/60000 (20%)] Loss: -1616.051025\n",
      "Train Epoch: 3596 [23040/60000 (38%)] Loss: -1580.849121\n",
      "Train Epoch: 3596 [34304/60000 (57%)] Loss: -1563.522949\n",
      "Train Epoch: 3596 [45568/60000 (76%)] Loss: -1565.686523\n",
      "Train Epoch: 3596 [56832/60000 (95%)] Loss: -1570.540405\n",
      "    epoch          : 3596\n",
      "    loss           : -1524.4815970383122\n",
      "Train Epoch: 3597 [512/60000 (1%)] Loss: -1484.058716\n",
      "Train Epoch: 3597 [11776/60000 (20%)] Loss: -1577.982910\n",
      "Train Epoch: 3597 [23040/60000 (38%)] Loss: -1534.587891\n",
      "Train Epoch: 3597 [34304/60000 (57%)] Loss: -1446.770752\n",
      "Train Epoch: 3597 [45568/60000 (76%)] Loss: -1514.708374\n",
      "Train Epoch: 3597 [56832/60000 (95%)] Loss: -1537.202637\n",
      "    epoch          : 3597\n",
      "    loss           : -1524.06866420595\n",
      "Train Epoch: 3598 [512/60000 (1%)] Loss: -1439.366333\n",
      "Train Epoch: 3598 [11776/60000 (20%)] Loss: -1542.989136\n",
      "Train Epoch: 3598 [23040/60000 (38%)] Loss: -1557.744263\n",
      "Train Epoch: 3598 [34304/60000 (57%)] Loss: -1495.315674\n",
      "Train Epoch: 3598 [45568/60000 (76%)] Loss: -1557.939697\n",
      "Train Epoch: 3598 [56832/60000 (95%)] Loss: -1589.832275\n",
      "    epoch          : 3598\n",
      "    loss           : -1527.295126360015\n",
      "Train Epoch: 3599 [512/60000 (1%)] Loss: -1528.152832\n",
      "Train Epoch: 3599 [11776/60000 (20%)] Loss: -1519.798096\n",
      "Train Epoch: 3599 [23040/60000 (38%)] Loss: -1604.621460\n",
      "Train Epoch: 3599 [34304/60000 (57%)] Loss: -1539.540527\n",
      "Train Epoch: 3599 [45568/60000 (76%)] Loss: -1542.329834\n",
      "Train Epoch: 3599 [56832/60000 (95%)] Loss: -1578.389404\n",
      "    epoch          : 3599\n",
      "    loss           : -1523.0237012960142\n",
      "Train Epoch: 3600 [512/60000 (1%)] Loss: -1530.000610\n",
      "Train Epoch: 3600 [11776/60000 (20%)] Loss: -1475.815186\n",
      "Train Epoch: 3600 [23040/60000 (38%)] Loss: -1470.335205\n",
      "Train Epoch: 3600 [34304/60000 (57%)] Loss: -1588.719116\n",
      "Train Epoch: 3600 [45568/60000 (76%)] Loss: -1558.065918\n",
      "Train Epoch: 3600 [56832/60000 (95%)] Loss: -1590.114746\n",
      "    epoch          : 3600\n",
      "    loss           : -1522.671559479277\n",
      "Saving checkpoint: saved/models/Mnist_DeepGenerativeOperad/0127_111843/checkpoint-epoch3600.pth ...\n",
      "Train Epoch: 3601 [512/60000 (1%)] Loss: -1484.246704\n",
      "Train Epoch: 3601 [11776/60000 (20%)] Loss: -1520.757324\n",
      "Train Epoch: 3601 [23040/60000 (38%)] Loss: -1490.249878\n",
      "Train Epoch: 3601 [34304/60000 (57%)] Loss: -1535.328857\n",
      "Train Epoch: 3601 [45568/60000 (76%)] Loss: -1542.289062\n",
      "Train Epoch: 3601 [56832/60000 (95%)] Loss: -1544.226440\n",
      "    epoch          : 3601\n",
      "    loss           : -1525.9967034118997\n",
      "Train Epoch: 3602 [512/60000 (1%)] Loss: -1549.314941\n",
      "Train Epoch: 3602 [11776/60000 (20%)] Loss: -1530.995483\n",
      "Train Epoch: 3602 [23040/60000 (38%)] Loss: -1533.064209\n",
      "Train Epoch: 3602 [34304/60000 (57%)] Loss: -1535.711792\n",
      "Train Epoch: 3602 [45568/60000 (76%)] Loss: -1518.003662\n",
      "Train Epoch: 3602 [56832/60000 (95%)] Loss: -1582.901733\n",
      "    epoch          : 3602\n",
      "    loss           : -1523.3520897471974\n",
      "Train Epoch: 3603 [512/60000 (1%)] Loss: -1511.463623\n",
      "Train Epoch: 3603 [11776/60000 (20%)] Loss: -1534.001953\n",
      "Train Epoch: 3603 [23040/60000 (38%)] Loss: -1486.270386\n",
      "Train Epoch: 3603 [34304/60000 (57%)] Loss: -1473.304688\n",
      "Train Epoch: 3603 [45568/60000 (76%)] Loss: -1538.094727\n",
      "Train Epoch: 3603 [56832/60000 (95%)] Loss: -1503.724854\n",
      "    epoch          : 3603\n",
      "    loss           : -1522.6294690148304\n",
      "Train Epoch: 3604 [512/60000 (1%)] Loss: -1486.475708\n",
      "Train Epoch: 3604 [11776/60000 (20%)] Loss: -1594.188721\n",
      "Train Epoch: 3604 [23040/60000 (38%)] Loss: -1526.544800\n",
      "Train Epoch: 3604 [34304/60000 (57%)] Loss: -1488.192749\n",
      "Train Epoch: 3604 [45568/60000 (76%)] Loss: -1562.752808\n",
      "Train Epoch: 3604 [56832/60000 (95%)] Loss: -1448.529297\n",
      "    epoch          : 3604\n",
      "    loss           : -1528.0778070654574\n",
      "Train Epoch: 3605 [512/60000 (1%)] Loss: -1530.859131\n",
      "Train Epoch: 3605 [11776/60000 (20%)] Loss: -1484.088379\n",
      "Train Epoch: 3605 [23040/60000 (38%)] Loss: -1572.021606\n",
      "Train Epoch: 3605 [34304/60000 (57%)] Loss: -1556.114014\n",
      "Train Epoch: 3605 [45568/60000 (76%)] Loss: -1576.426392\n",
      "Train Epoch: 3605 [56832/60000 (95%)] Loss: -1547.243042\n",
      "    epoch          : 3605\n",
      "    loss           : -1525.223375568282\n",
      "Train Epoch: 3606 [512/60000 (1%)] Loss: -1420.187012\n",
      "Train Epoch: 3606 [11776/60000 (20%)] Loss: -1496.188110\n",
      "Train Epoch: 3606 [23040/60000 (38%)] Loss: -1444.733032\n",
      "Train Epoch: 3606 [34304/60000 (57%)] Loss: -1586.343628\n",
      "Train Epoch: 3606 [45568/60000 (76%)] Loss: -1488.190674\n",
      "Train Epoch: 3606 [56832/60000 (95%)] Loss: -1496.422852\n",
      "    epoch          : 3606\n",
      "    loss           : -1520.4717169292903\n",
      "Train Epoch: 3607 [512/60000 (1%)] Loss: -1474.378418\n",
      "Train Epoch: 3607 [11776/60000 (20%)] Loss: -1511.954834\n",
      "Train Epoch: 3607 [23040/60000 (38%)] Loss: -1458.066895\n",
      "Train Epoch: 3607 [34304/60000 (57%)] Loss: -1604.705322\n",
      "Train Epoch: 3607 [45568/60000 (76%)] Loss: -1576.708984\n",
      "Train Epoch: 3607 [56832/60000 (95%)] Loss: -1492.403687\n",
      "    epoch          : 3607\n",
      "    loss           : -1524.8685399287165\n",
      "Train Epoch: 3608 [512/60000 (1%)] Loss: -1565.709595\n",
      "Train Epoch: 3608 [11776/60000 (20%)] Loss: -1425.948975\n",
      "Train Epoch: 3608 [23040/60000 (38%)] Loss: -1505.154785\n",
      "Train Epoch: 3608 [34304/60000 (57%)] Loss: -1499.044800\n",
      "Train Epoch: 3608 [45568/60000 (76%)] Loss: -1496.713379\n",
      "Train Epoch: 3608 [56832/60000 (95%)] Loss: -1525.367920\n",
      "    epoch          : 3608\n",
      "    loss           : -1509.8145882989054\n",
      "Train Epoch: 3609 [512/60000 (1%)] Loss: -1546.903564\n",
      "Train Epoch: 3609 [11776/60000 (20%)] Loss: -1474.025879\n",
      "Train Epoch: 3609 [23040/60000 (38%)] Loss: -1513.209473\n",
      "Train Epoch: 3609 [34304/60000 (57%)] Loss: -1505.654053\n",
      "Train Epoch: 3609 [45568/60000 (76%)] Loss: -1582.281006\n",
      "Train Epoch: 3609 [56832/60000 (95%)] Loss: -1610.116455\n",
      "    epoch          : 3609\n",
      "    loss           : -1529.927000228968\n",
      "Train Epoch: 3610 [512/60000 (1%)] Loss: -1583.249268\n",
      "Train Epoch: 3610 [11776/60000 (20%)] Loss: -1555.986328\n",
      "Train Epoch: 3610 [23040/60000 (38%)] Loss: -1583.772705\n",
      "Train Epoch: 3610 [34304/60000 (57%)] Loss: -1500.228271\n",
      "Train Epoch: 3610 [45568/60000 (76%)] Loss: -1608.260986\n",
      "Train Epoch: 3610 [56832/60000 (95%)] Loss: -1584.128784\n",
      "    epoch          : 3610\n",
      "    loss           : -1525.9846387960142\n",
      "Train Epoch: 3611 [512/60000 (1%)] Loss: -1531.661377\n",
      "Train Epoch: 3611 [11776/60000 (20%)] Loss: -1518.523682\n",
      "Train Epoch: 3611 [23040/60000 (38%)] Loss: -1521.469116\n",
      "Train Epoch: 3611 [34304/60000 (57%)] Loss: -1484.016357\n",
      "Train Epoch: 3611 [45568/60000 (76%)] Loss: -1492.390503\n",
      "Train Epoch: 3611 [56832/60000 (95%)] Loss: -1508.525879\n",
      "    epoch          : 3611\n",
      "    loss           : -1523.4988596425892\n",
      "Train Epoch: 3612 [512/60000 (1%)] Loss: -1606.301392\n",
      "Train Epoch: 3612 [11776/60000 (20%)] Loss: -1504.373657\n",
      "Train Epoch: 3612 [23040/60000 (38%)] Loss: -1599.717773\n",
      "Train Epoch: 3612 [34304/60000 (57%)] Loss: -1409.302612\n",
      "Train Epoch: 3612 [45568/60000 (76%)] Loss: -1468.998413\n",
      "Train Epoch: 3612 [56832/60000 (95%)] Loss: -1492.780884\n",
      "    epoch          : 3612\n",
      "    loss           : -1523.9212674070886\n",
      "Train Epoch: 3613 [512/60000 (1%)] Loss: -1578.070068\n",
      "Train Epoch: 3613 [11776/60000 (20%)] Loss: -1551.193604\n",
      "Train Epoch: 3613 [23040/60000 (38%)] Loss: -1510.523193\n",
      "Train Epoch: 3613 [34304/60000 (57%)] Loss: -1573.307251\n",
      "Train Epoch: 3613 [45568/60000 (76%)] Loss: -1480.605957\n",
      "Train Epoch: 3613 [56832/60000 (95%)] Loss: -1481.884766\n",
      "    epoch          : 3613\n",
      "    loss           : -1524.099905585165\n",
      "Train Epoch: 3614 [512/60000 (1%)] Loss: -1550.741699\n",
      "Train Epoch: 3614 [11776/60000 (20%)] Loss: -1576.891357\n",
      "Train Epoch: 3614 [23040/60000 (38%)] Loss: -1463.821411\n",
      "Train Epoch: 3614 [34304/60000 (57%)] Loss: -1488.413574\n",
      "Train Epoch: 3614 [45568/60000 (76%)] Loss: -1430.897461\n",
      "Train Epoch: 3614 [56832/60000 (95%)] Loss: -1552.988159\n",
      "    epoch          : 3614\n",
      "    loss           : -1524.8633919408767\n",
      "Train Epoch: 3615 [512/60000 (1%)] Loss: -1474.503784\n",
      "Train Epoch: 3615 [11776/60000 (20%)] Loss: -1592.600952\n",
      "Train Epoch: 3615 [23040/60000 (38%)] Loss: -1460.172485\n",
      "Train Epoch: 3615 [34304/60000 (57%)] Loss: -1493.866943\n",
      "Train Epoch: 3615 [45568/60000 (76%)] Loss: -1412.103760\n",
      "Train Epoch: 3615 [56832/60000 (95%)] Loss: -1513.040527\n",
      "    epoch          : 3615\n",
      "    loss           : -1520.8107317046258\n",
      "Train Epoch: 3616 [512/60000 (1%)] Loss: -1562.959351\n",
      "Train Epoch: 3616 [11776/60000 (20%)] Loss: -1565.923096\n",
      "Train Epoch: 3616 [23040/60000 (38%)] Loss: -1485.991455\n",
      "Train Epoch: 3616 [34304/60000 (57%)] Loss: -1583.923828\n",
      "Train Epoch: 3616 [45568/60000 (76%)] Loss: -1565.276001\n",
      "Train Epoch: 3616 [56832/60000 (95%)] Loss: -1607.026123\n",
      "    epoch          : 3616\n",
      "    loss           : -1528.1262148409912\n",
      "Train Epoch: 3617 [512/60000 (1%)] Loss: -1564.039185\n",
      "Train Epoch: 3617 [11776/60000 (20%)] Loss: -1573.525635\n",
      "Train Epoch: 3617 [23040/60000 (38%)] Loss: -1440.817749\n",
      "Train Epoch: 3617 [34304/60000 (57%)] Loss: -1546.739746\n",
      "Train Epoch: 3617 [45568/60000 (76%)] Loss: -1553.750244\n",
      "Train Epoch: 3617 [56832/60000 (95%)] Loss: -1505.965088\n",
      "    epoch          : 3617\n",
      "    loss           : -1524.6553955078125\n",
      "Train Epoch: 3618 [512/60000 (1%)] Loss: -1529.342163\n",
      "Train Epoch: 3618 [11776/60000 (20%)] Loss: -1523.406982\n",
      "Train Epoch: 3618 [23040/60000 (38%)] Loss: -1440.063354\n",
      "Train Epoch: 3618 [34304/60000 (57%)] Loss: -1541.235474\n",
      "Train Epoch: 3618 [45568/60000 (76%)] Loss: -1511.050781\n",
      "Train Epoch: 3618 [56832/60000 (95%)] Loss: -1482.042236\n",
      "    epoch          : 3618\n",
      "    loss           : -1524.096052094368\n",
      "Train Epoch: 3619 [512/60000 (1%)] Loss: -1553.737549\n",
      "Train Epoch: 3619 [11776/60000 (20%)] Loss: -1615.061279\n",
      "Train Epoch: 3619 [23040/60000 (38%)] Loss: -1531.593872\n",
      "Train Epoch: 3619 [34304/60000 (57%)] Loss: -1571.442383\n",
      "Train Epoch: 3619 [45568/60000 (76%)] Loss: -1544.033447\n",
      "Train Epoch: 3619 [56832/60000 (95%)] Loss: -1551.214966\n",
      "    epoch          : 3619\n",
      "    loss           : -1526.3410179008872\n",
      "Train Epoch: 3620 [512/60000 (1%)] Loss: -1416.355957\n",
      "Train Epoch: 3620 [11776/60000 (20%)] Loss: -1461.208984\n",
      "Train Epoch: 3620 [23040/60000 (38%)] Loss: -1482.762695\n",
      "Train Epoch: 3620 [34304/60000 (57%)] Loss: -1520.000366\n",
      "Train Epoch: 3620 [45568/60000 (76%)] Loss: -1602.859863\n",
      "Train Epoch: 3620 [56832/60000 (95%)] Loss: -1491.011719\n",
      "    epoch          : 3620\n",
      "    loss           : -1515.9666158385196\n",
      "Train Epoch: 3621 [512/60000 (1%)] Loss: -1478.495483\n",
      "Train Epoch: 3621 [11776/60000 (20%)] Loss: -1458.819092\n",
      "Train Epoch: 3621 [23040/60000 (38%)] Loss: -1573.656250\n",
      "Train Epoch: 3621 [34304/60000 (57%)] Loss: -1439.480469\n",
      "Train Epoch: 3621 [45568/60000 (76%)] Loss: -1570.093140\n",
      "Train Epoch: 3621 [56832/60000 (95%)] Loss: -1604.551270\n",
      "    epoch          : 3621\n",
      "    loss           : -1528.3337350619042\n",
      "Train Epoch: 3622 [512/60000 (1%)] Loss: -1520.194946\n",
      "Train Epoch: 3622 [11776/60000 (20%)] Loss: -1540.911377\n",
      "Train Epoch: 3622 [23040/60000 (38%)] Loss: -1547.149902\n",
      "Train Epoch: 3622 [34304/60000 (57%)] Loss: -1519.848755\n",
      "Train Epoch: 3622 [45568/60000 (76%)] Loss: -1565.865723\n",
      "Train Epoch: 3622 [56832/60000 (95%)] Loss: -1549.595093\n",
      "    epoch          : 3622\n",
      "    loss           : -1529.6037242479917\n",
      "Train Epoch: 3623 [512/60000 (1%)] Loss: -1542.613892\n",
      "Train Epoch: 3623 [11776/60000 (20%)] Loss: -1432.657227\n",
      "Train Epoch: 3623 [23040/60000 (38%)] Loss: -1613.046875\n",
      "Train Epoch: 3623 [34304/60000 (57%)] Loss: -1582.067261\n",
      "Train Epoch: 3623 [45568/60000 (76%)] Loss: -1479.353760\n",
      "Train Epoch: 3623 [56832/60000 (95%)] Loss: -1594.973389\n",
      "    epoch          : 3623\n",
      "    loss           : -1522.360136387712\n",
      "Train Epoch: 3624 [512/60000 (1%)] Loss: -1523.529541\n",
      "Train Epoch: 3624 [11776/60000 (20%)] Loss: -1406.591675\n",
      "Train Epoch: 3624 [23040/60000 (38%)] Loss: -1519.802368\n",
      "Train Epoch: 3624 [34304/60000 (57%)] Loss: -1500.145630\n",
      "Train Epoch: 3624 [45568/60000 (76%)] Loss: -1521.039551\n",
      "Train Epoch: 3624 [56832/60000 (95%)] Loss: -1541.272217\n",
      "    epoch          : 3624\n",
      "    loss           : -1524.346954518119\n",
      "Train Epoch: 3625 [512/60000 (1%)] Loss: -1477.013062\n",
      "Train Epoch: 3625 [11776/60000 (20%)] Loss: -1500.655762\n",
      "Train Epoch: 3625 [23040/60000 (38%)] Loss: -1603.686523\n",
      "Train Epoch: 3625 [34304/60000 (57%)] Loss: -1550.318848\n",
      "Train Epoch: 3625 [45568/60000 (76%)] Loss: -1512.149780\n",
      "Train Epoch: 3625 [56832/60000 (95%)] Loss: -1526.684326\n",
      "    epoch          : 3625\n",
      "    loss           : -1524.2235652255474\n",
      "Train Epoch: 3626 [512/60000 (1%)] Loss: -1517.084473\n",
      "Train Epoch: 3626 [11776/60000 (20%)] Loss: -1528.442627\n",
      "Train Epoch: 3626 [23040/60000 (38%)] Loss: -1573.999023\n",
      "Train Epoch: 3626 [34304/60000 (57%)] Loss: -1551.045166\n",
      "Train Epoch: 3626 [45568/60000 (76%)] Loss: -1497.473022\n",
      "Train Epoch: 3626 [56832/60000 (95%)] Loss: -1492.078613\n",
      "    epoch          : 3626\n",
      "    loss           : -1524.2720902437545\n",
      "Train Epoch: 3627 [512/60000 (1%)] Loss: -1473.726318\n",
      "Train Epoch: 3627 [11776/60000 (20%)] Loss: -1473.049561\n",
      "Train Epoch: 3627 [23040/60000 (38%)] Loss: -1531.274414\n",
      "Train Epoch: 3627 [34304/60000 (57%)] Loss: -1529.668945\n",
      "Train Epoch: 3627 [45568/60000 (76%)] Loss: -1488.685547\n",
      "Train Epoch: 3627 [56832/60000 (95%)] Loss: -1420.822266\n",
      "    epoch          : 3627\n",
      "    loss           : -1526.2825189795199\n",
      "Train Epoch: 3628 [512/60000 (1%)] Loss: -1478.171631\n",
      "Train Epoch: 3628 [11776/60000 (20%)] Loss: -1529.940063\n",
      "Train Epoch: 3628 [23040/60000 (38%)] Loss: -1576.900146\n",
      "Train Epoch: 3628 [34304/60000 (57%)] Loss: -1591.765015\n",
      "Train Epoch: 3628 [45568/60000 (76%)] Loss: -1558.874023\n",
      "Train Epoch: 3628 [56832/60000 (95%)] Loss: -1556.390991\n",
      "    epoch          : 3628\n",
      "    loss           : -1523.5434090996866\n",
      "Train Epoch: 3629 [512/60000 (1%)] Loss: -1550.109985\n",
      "Train Epoch: 3629 [11776/60000 (20%)] Loss: -1612.704834\n",
      "Train Epoch: 3629 [23040/60000 (38%)] Loss: -1441.483887\n",
      "Train Epoch: 3629 [34304/60000 (57%)] Loss: -1535.748413\n",
      "Train Epoch: 3629 [45568/60000 (76%)] Loss: -1519.648193\n",
      "Train Epoch: 3629 [56832/60000 (95%)] Loss: -1602.535156\n",
      "    epoch          : 3629\n",
      "    loss           : -1524.6705929168875\n",
      "Train Epoch: 3630 [512/60000 (1%)] Loss: -1551.948853\n",
      "Train Epoch: 3630 [11776/60000 (20%)] Loss: -1566.825317\n",
      "Train Epoch: 3630 [23040/60000 (38%)] Loss: -1457.175293\n",
      "Train Epoch: 3630 [34304/60000 (57%)] Loss: -1581.292236\n",
      "Train Epoch: 3630 [45568/60000 (76%)] Loss: -1447.228149\n",
      "Train Epoch: 3630 [56832/60000 (95%)] Loss: -1528.312744\n",
      "    epoch          : 3630\n",
      "    loss           : -1531.2323684261344\n",
      "Train Epoch: 3631 [512/60000 (1%)] Loss: -1431.426514\n",
      "Train Epoch: 3631 [11776/60000 (20%)] Loss: -1532.897217\n",
      "Train Epoch: 3631 [23040/60000 (38%)] Loss: -1508.841553\n",
      "Train Epoch: 3631 [34304/60000 (57%)] Loss: -1555.385620\n",
      "Train Epoch: 3631 [45568/60000 (76%)] Loss: -1540.622803\n",
      "Train Epoch: 3631 [56832/60000 (95%)] Loss: -1458.154297\n",
      "    epoch          : 3631\n",
      "    loss           : -1530.4454431910972\n",
      "Train Epoch: 3632 [512/60000 (1%)] Loss: -1511.728760\n",
      "Train Epoch: 3632 [11776/60000 (20%)] Loss: -1573.812256\n",
      "Train Epoch: 3632 [23040/60000 (38%)] Loss: -1515.639526\n",
      "Train Epoch: 3632 [34304/60000 (57%)] Loss: -1501.152588\n",
      "Train Epoch: 3632 [45568/60000 (76%)] Loss: -1555.604492\n",
      "Train Epoch: 3632 [56832/60000 (95%)] Loss: -1579.920288\n",
      "    epoch          : 3632\n",
      "    loss           : -1523.0256023514744\n",
      "Train Epoch: 3633 [512/60000 (1%)] Loss: -1540.313477\n",
      "Train Epoch: 3633 [11776/60000 (20%)] Loss: -1554.617554\n",
      "Train Epoch: 3633 [23040/60000 (38%)] Loss: -1503.052246\n",
      "Train Epoch: 3633 [34304/60000 (57%)] Loss: -1550.232666\n",
      "Train Epoch: 3633 [45568/60000 (76%)] Loss: -1541.180664\n",
      "Train Epoch: 3633 [56832/60000 (95%)] Loss: -1535.220093\n",
      "    epoch          : 3633\n",
      "    loss           : -1525.7264407745188\n",
      "Train Epoch: 3634 [512/60000 (1%)] Loss: -1492.189575\n",
      "Train Epoch: 3634 [11776/60000 (20%)] Loss: -1598.742065\n",
      "Train Epoch: 3634 [23040/60000 (38%)] Loss: -1527.852539\n",
      "Train Epoch: 3634 [34304/60000 (57%)] Loss: -1465.246460\n",
      "Train Epoch: 3634 [45568/60000 (76%)] Loss: -1525.630249\n",
      "Train Epoch: 3634 [56832/60000 (95%)] Loss: -1593.171265\n",
      "    epoch          : 3634\n",
      "    loss           : -1519.251713467183\n",
      "Train Epoch: 3635 [512/60000 (1%)] Loss: -1575.306763\n",
      "Train Epoch: 3635 [11776/60000 (20%)] Loss: -1552.599365\n",
      "Train Epoch: 3635 [23040/60000 (38%)] Loss: -1448.982910\n",
      "Train Epoch: 3635 [34304/60000 (57%)] Loss: -1529.774780\n",
      "Train Epoch: 3635 [45568/60000 (76%)] Loss: -1564.496704\n",
      "Train Epoch: 3635 [56832/60000 (95%)] Loss: -1535.290894\n",
      "    epoch          : 3635\n",
      "    loss           : -1526.7983105330818\n",
      "Train Epoch: 3636 [512/60000 (1%)] Loss: -1545.151855\n",
      "Train Epoch: 3636 [11776/60000 (20%)] Loss: -1495.483887\n",
      "Train Epoch: 3636 [23040/60000 (38%)] Loss: -1532.114258\n",
      "Train Epoch: 3636 [34304/60000 (57%)] Loss: -1565.977051\n",
      "Train Epoch: 3636 [45568/60000 (76%)] Loss: -1432.073975\n",
      "Train Epoch: 3636 [56832/60000 (95%)] Loss: -1548.209595\n",
      "    epoch          : 3636\n",
      "    loss           : -1530.452523958885\n",
      "Train Epoch: 3637 [512/60000 (1%)] Loss: -1552.356201\n",
      "Train Epoch: 3637 [11776/60000 (20%)] Loss: -1465.401855\n",
      "Train Epoch: 3637 [23040/60000 (38%)] Loss: -1463.602661\n",
      "Train Epoch: 3637 [34304/60000 (57%)] Loss: -1617.022217\n",
      "Train Epoch: 3637 [45568/60000 (76%)] Loss: -1522.076660\n",
      "Train Epoch: 3637 [56832/60000 (95%)] Loss: -1567.417969\n",
      "    epoch          : 3637\n",
      "    loss           : -1523.2366143350548\n",
      "Train Epoch: 3638 [512/60000 (1%)] Loss: -1517.927246\n",
      "Train Epoch: 3638 [11776/60000 (20%)] Loss: -1587.359131\n",
      "Train Epoch: 3638 [23040/60000 (38%)] Loss: -1531.734985\n",
      "Train Epoch: 3638 [34304/60000 (57%)] Loss: -1545.267578\n",
      "Train Epoch: 3638 [45568/60000 (76%)] Loss: -1552.750488\n",
      "Train Epoch: 3638 [56832/60000 (95%)] Loss: -1545.893311\n",
      "    epoch          : 3638\n",
      "    loss           : -1532.3773431293034\n",
      "Train Epoch: 3639 [512/60000 (1%)] Loss: -1537.151978\n",
      "Train Epoch: 3639 [11776/60000 (20%)] Loss: -1561.579468\n",
      "Train Epoch: 3639 [23040/60000 (38%)] Loss: -1568.644287\n",
      "Train Epoch: 3639 [34304/60000 (57%)] Loss: -1584.305420\n",
      "Train Epoch: 3639 [45568/60000 (76%)] Loss: -1503.577515\n",
      "Train Epoch: 3639 [56832/60000 (95%)] Loss: -1576.114380\n",
      "    epoch          : 3639\n",
      "    loss           : -1525.1137340136167\n",
      "Train Epoch: 3640 [512/60000 (1%)] Loss: -1535.311401\n",
      "Train Epoch: 3640 [11776/60000 (20%)] Loss: -1473.730469\n",
      "Train Epoch: 3640 [23040/60000 (38%)] Loss: -1569.352783\n",
      "Train Epoch: 3640 [34304/60000 (57%)] Loss: -1557.318359\n",
      "Train Epoch: 3640 [45568/60000 (76%)] Loss: -1474.351807\n",
      "Train Epoch: 3640 [56832/60000 (95%)] Loss: -1504.785278\n",
      "    epoch          : 3640\n",
      "    loss           : -1527.5303524038884\n",
      "Train Epoch: 3641 [512/60000 (1%)] Loss: -1551.117798\n",
      "Train Epoch: 3641 [11776/60000 (20%)] Loss: -1466.140015\n",
      "Train Epoch: 3641 [23040/60000 (38%)] Loss: -1542.592041\n",
      "Train Epoch: 3641 [34304/60000 (57%)] Loss: -1515.638916\n",
      "Train Epoch: 3641 [45568/60000 (76%)] Loss: -1495.910645\n",
      "Train Epoch: 3641 [56832/60000 (95%)] Loss: -1533.894043\n",
      "    epoch          : 3641\n",
      "    loss           : -1519.4646702998102\n",
      "Train Epoch: 3642 [512/60000 (1%)] Loss: -1564.908081\n",
      "Train Epoch: 3642 [11776/60000 (20%)] Loss: -1522.515625\n",
      "Train Epoch: 3642 [23040/60000 (38%)] Loss: -1537.648438\n",
      "Train Epoch: 3642 [34304/60000 (57%)] Loss: -1544.914307\n",
      "Train Epoch: 3642 [45568/60000 (76%)] Loss: -1548.075195\n",
      "Train Epoch: 3642 [56832/60000 (95%)] Loss: -1599.563599\n",
      "    epoch          : 3642\n",
      "    loss           : -1526.3345223119704\n",
      "Train Epoch: 3643 [512/60000 (1%)] Loss: -1450.810303\n",
      "Train Epoch: 3643 [11776/60000 (20%)] Loss: -1520.072510\n",
      "Train Epoch: 3643 [23040/60000 (38%)] Loss: -1539.886230\n",
      "Train Epoch: 3643 [34304/60000 (57%)] Loss: -1609.929077\n",
      "Train Epoch: 3643 [45568/60000 (76%)] Loss: -1561.975586\n",
      "Train Epoch: 3643 [56832/60000 (95%)] Loss: -1563.329956\n",
      "    epoch          : 3643\n",
      "    loss           : -1533.0744597871426\n",
      "Train Epoch: 3644 [512/60000 (1%)] Loss: -1599.019043\n",
      "Train Epoch: 3644 [11776/60000 (20%)] Loss: -1570.007935\n",
      "Train Epoch: 3644 [23040/60000 (38%)] Loss: -1497.258301\n",
      "Train Epoch: 3644 [34304/60000 (57%)] Loss: -1561.423584\n",
      "Train Epoch: 3644 [45568/60000 (76%)] Loss: -1549.140015\n",
      "Train Epoch: 3644 [56832/60000 (95%)] Loss: -1527.399536\n",
      "    epoch          : 3644\n",
      "    loss           : -1525.5405725166622\n",
      "Train Epoch: 3645 [512/60000 (1%)] Loss: -1516.433105\n",
      "Train Epoch: 3645 [11776/60000 (20%)] Loss: -1511.569214\n",
      "Train Epoch: 3645 [23040/60000 (38%)] Loss: -1498.697754\n",
      "Train Epoch: 3645 [34304/60000 (57%)] Loss: -1528.745117\n",
      "Train Epoch: 3645 [45568/60000 (76%)] Loss: -1498.501221\n",
      "Train Epoch: 3645 [56832/60000 (95%)] Loss: -1529.527100\n",
      "    epoch          : 3645\n",
      "    loss           : -1522.2323501500707\n",
      "Train Epoch: 3646 [512/60000 (1%)] Loss: -1432.627319\n",
      "Train Epoch: 3646 [11776/60000 (20%)] Loss: -1577.071655\n",
      "Train Epoch: 3646 [23040/60000 (38%)] Loss: -1486.033691\n",
      "Train Epoch: 3646 [34304/60000 (57%)] Loss: -1604.001099\n",
      "Train Epoch: 3646 [45568/60000 (76%)] Loss: -1521.632324\n",
      "Train Epoch: 3646 [56832/60000 (95%)] Loss: -1517.746094\n",
      "    epoch          : 3646\n",
      "    loss           : -1520.9828046378443\n",
      "Train Epoch: 3647 [512/60000 (1%)] Loss: -1545.168823\n",
      "Train Epoch: 3647 [11776/60000 (20%)] Loss: -1570.140991\n",
      "Train Epoch: 3647 [23040/60000 (38%)] Loss: -1527.530762\n",
      "Train Epoch: 3647 [34304/60000 (57%)] Loss: -1508.843018\n",
      "Train Epoch: 3647 [45568/60000 (76%)] Loss: -1601.776855\n",
      "Train Epoch: 3647 [56832/60000 (95%)] Loss: -1455.184082\n",
      "    epoch          : 3647\n",
      "    loss           : -1520.2239628161415\n",
      "Train Epoch: 3648 [512/60000 (1%)] Loss: -1526.997437\n",
      "Train Epoch: 3648 [11776/60000 (20%)] Loss: -1523.630981\n",
      "Train Epoch: 3648 [23040/60000 (38%)] Loss: -1506.460205\n",
      "Train Epoch: 3648 [34304/60000 (57%)] Loss: -1553.430908\n",
      "Train Epoch: 3648 [45568/60000 (76%)] Loss: -1500.954834\n",
      "Train Epoch: 3648 [56832/60000 (95%)] Loss: -1503.759521\n",
      "    epoch          : 3648\n",
      "    loss           : -1516.5624565512446\n",
      "Train Epoch: 3649 [512/60000 (1%)] Loss: -1451.455200\n",
      "Train Epoch: 3649 [11776/60000 (20%)] Loss: -1580.851807\n",
      "Train Epoch: 3649 [23040/60000 (38%)] Loss: -1592.607544\n",
      "Train Epoch: 3649 [34304/60000 (57%)] Loss: -1522.341064\n",
      "Train Epoch: 3649 [45568/60000 (76%)] Loss: -1530.300049\n",
      "Train Epoch: 3649 [56832/60000 (95%)] Loss: -1537.597778\n",
      "    epoch          : 3649\n",
      "    loss           : -1530.8611453643625\n",
      "Train Epoch: 3650 [512/60000 (1%)] Loss: -1500.208374\n",
      "Train Epoch: 3650 [11776/60000 (20%)] Loss: -1546.243408\n",
      "Train Epoch: 3650 [23040/60000 (38%)] Loss: -1595.749146\n",
      "Train Epoch: 3650 [34304/60000 (57%)] Loss: -1540.966797\n",
      "Train Epoch: 3650 [45568/60000 (76%)] Loss: -1578.190918\n",
      "Train Epoch: 3650 [56832/60000 (95%)] Loss: -1476.536865\n",
      "    epoch          : 3650\n",
      "    loss           : -1523.9976523878886\n",
      "Train Epoch: 3651 [512/60000 (1%)] Loss: -1616.650879\n",
      "Train Epoch: 3651 [11776/60000 (20%)] Loss: -1600.281860\n",
      "Train Epoch: 3651 [23040/60000 (38%)] Loss: -1471.158813\n",
      "Train Epoch: 3651 [34304/60000 (57%)] Loss: -1557.209595\n",
      "Train Epoch: 3651 [45568/60000 (76%)] Loss: -1593.920898\n",
      "Train Epoch: 3651 [56832/60000 (95%)] Loss: -1494.596191\n",
      "    epoch          : 3651\n",
      "    loss           : -1526.9431300621247\n",
      "Train Epoch: 3652 [512/60000 (1%)] Loss: -1580.287109\n",
      "Train Epoch: 3652 [11776/60000 (20%)] Loss: -1500.882812\n",
      "Train Epoch: 3652 [23040/60000 (38%)] Loss: -1623.987549\n",
      "Train Epoch: 3652 [34304/60000 (57%)] Loss: -1554.673828\n",
      "Train Epoch: 3652 [45568/60000 (76%)] Loss: -1559.357666\n",
      "Train Epoch: 3652 [56832/60000 (95%)] Loss: -1540.966431\n",
      "    epoch          : 3652\n",
      "    loss           : -1522.5968383099398\n",
      "Train Epoch: 3653 [512/60000 (1%)] Loss: -1605.885132\n",
      "Train Epoch: 3653 [11776/60000 (20%)] Loss: -1505.195679\n",
      "Train Epoch: 3653 [23040/60000 (38%)] Loss: -1553.993286\n",
      "Train Epoch: 3653 [34304/60000 (57%)] Loss: -1468.367432\n",
      "Train Epoch: 3653 [45568/60000 (76%)] Loss: -1503.229980\n",
      "Train Epoch: 3653 [56832/60000 (95%)] Loss: -1469.797607\n",
      "    epoch          : 3653\n",
      "    loss           : -1526.8180038538355\n",
      "Train Epoch: 3654 [512/60000 (1%)] Loss: -1513.781738\n",
      "Train Epoch: 3654 [11776/60000 (20%)] Loss: -1585.244385\n",
      "Train Epoch: 3654 [23040/60000 (38%)] Loss: -1523.971191\n",
      "Train Epoch: 3654 [34304/60000 (57%)] Loss: -1493.861084\n",
      "Train Epoch: 3654 [45568/60000 (76%)] Loss: -1514.883911\n",
      "Train Epoch: 3654 [56832/60000 (95%)] Loss: -1520.463745\n",
      "    epoch          : 3654\n",
      "    loss           : -1521.7713043730137\n",
      "Train Epoch: 3655 [512/60000 (1%)] Loss: -1537.110107\n",
      "Train Epoch: 3655 [11776/60000 (20%)] Loss: -1476.414795\n",
      "Train Epoch: 3655 [23040/60000 (38%)] Loss: -1519.432495\n",
      "Train Epoch: 3655 [34304/60000 (57%)] Loss: -1557.756348\n",
      "Train Epoch: 3655 [45568/60000 (76%)] Loss: -1460.755005\n",
      "Train Epoch: 3655 [56832/60000 (95%)] Loss: -1548.154785\n",
      "    epoch          : 3655\n",
      "    loss           : -1522.4521905069298\n",
      "Train Epoch: 3656 [512/60000 (1%)] Loss: -1526.206665\n",
      "Train Epoch: 3656 [11776/60000 (20%)] Loss: -1494.221802\n",
      "Train Epoch: 3656 [23040/60000 (38%)] Loss: -1578.926270\n",
      "Train Epoch: 3656 [34304/60000 (57%)] Loss: -1520.313232\n",
      "Train Epoch: 3656 [45568/60000 (76%)] Loss: -1475.444336\n",
      "Train Epoch: 3656 [56832/60000 (95%)] Loss: -1526.424561\n",
      "    epoch          : 3656\n",
      "    loss           : -1523.7713043730137\n",
      "Train Epoch: 3657 [512/60000 (1%)] Loss: -1563.939575\n",
      "Train Epoch: 3657 [11776/60000 (20%)] Loss: -1431.325928\n",
      "Train Epoch: 3657 [23040/60000 (38%)] Loss: -1588.048462\n",
      "Train Epoch: 3657 [34304/60000 (57%)] Loss: -1480.361938\n",
      "Train Epoch: 3657 [45568/60000 (76%)] Loss: -1563.490479\n",
      "Train Epoch: 3657 [56832/60000 (95%)] Loss: -1486.154297\n",
      "    epoch          : 3657\n",
      "    loss           : -1516.410619013727\n",
      "Train Epoch: 3658 [512/60000 (1%)] Loss: -1457.548828\n",
      "Train Epoch: 3658 [11776/60000 (20%)] Loss: -1581.997925\n",
      "Train Epoch: 3658 [23040/60000 (38%)] Loss: -1528.660522\n",
      "Train Epoch: 3658 [34304/60000 (57%)] Loss: -1587.277466\n",
      "Train Epoch: 3658 [45568/60000 (76%)] Loss: -1469.698120\n",
      "Train Epoch: 3658 [56832/60000 (95%)] Loss: -1539.936646\n",
      "    epoch          : 3658\n",
      "    loss           : -1526.5433501335187\n",
      "Train Epoch: 3659 [512/60000 (1%)] Loss: -1432.480469\n",
      "Train Epoch: 3659 [11776/60000 (20%)] Loss: -1525.088745\n",
      "Train Epoch: 3659 [23040/60000 (38%)] Loss: -1559.591675\n",
      "Train Epoch: 3659 [34304/60000 (57%)] Loss: -1515.624023\n",
      "Train Epoch: 3659 [45568/60000 (76%)] Loss: -1475.529663\n",
      "Train Epoch: 3659 [56832/60000 (95%)] Loss: -1459.011475\n",
      "    epoch          : 3659\n",
      "    loss           : -1523.953615005407\n",
      "Train Epoch: 3660 [512/60000 (1%)] Loss: -1587.036133\n",
      "Train Epoch: 3660 [11776/60000 (20%)] Loss: -1561.669678\n",
      "Train Epoch: 3660 [23040/60000 (38%)] Loss: -1566.897949\n",
      "Train Epoch: 3660 [34304/60000 (57%)] Loss: -1496.072266\n",
      "Train Epoch: 3660 [45568/60000 (76%)] Loss: -1585.859619\n",
      "Train Epoch: 3660 [56832/60000 (95%)] Loss: -1521.911499\n",
      "    epoch          : 3660\n",
      "    loss           : -1528.2668074268406\n",
      "Train Epoch: 3661 [512/60000 (1%)] Loss: -1537.695923\n",
      "Train Epoch: 3661 [11776/60000 (20%)] Loss: -1572.133911\n",
      "Train Epoch: 3661 [23040/60000 (38%)] Loss: -1479.689941\n",
      "Train Epoch: 3661 [34304/60000 (57%)] Loss: -1475.256592\n",
      "Train Epoch: 3661 [45568/60000 (76%)] Loss: -1586.952393\n",
      "Train Epoch: 3661 [56832/60000 (95%)] Loss: -1527.669434\n",
      "    epoch          : 3661\n",
      "    loss           : -1532.7660456942974\n",
      "Train Epoch: 3662 [512/60000 (1%)] Loss: -1467.264160\n",
      "Train Epoch: 3662 [11776/60000 (20%)] Loss: -1463.130127\n",
      "Train Epoch: 3662 [23040/60000 (38%)] Loss: -1522.751465\n",
      "Train Epoch: 3662 [34304/60000 (57%)] Loss: -1490.810059\n",
      "Train Epoch: 3662 [45568/60000 (76%)] Loss: -1578.347900\n",
      "Train Epoch: 3662 [56832/60000 (95%)] Loss: -1574.413452\n",
      "    epoch          : 3662\n",
      "    loss           : -1533.2598049357787\n",
      "Train Epoch: 3663 [512/60000 (1%)] Loss: -1579.828491\n",
      "Train Epoch: 3663 [11776/60000 (20%)] Loss: -1608.307129\n",
      "Train Epoch: 3663 [23040/60000 (38%)] Loss: -1572.269897\n",
      "Train Epoch: 3663 [34304/60000 (57%)] Loss: -1532.172974\n",
      "Train Epoch: 3663 [45568/60000 (76%)] Loss: -1545.960205\n",
      "Train Epoch: 3663 [56832/60000 (95%)] Loss: -1473.493896\n",
      "    epoch          : 3663\n",
      "    loss           : -1534.0004569015935\n",
      "Train Epoch: 3664 [512/60000 (1%)] Loss: -1444.551514\n",
      "Train Epoch: 3664 [11776/60000 (20%)] Loss: -1496.487061\n",
      "Train Epoch: 3664 [23040/60000 (38%)] Loss: -1502.964600\n",
      "Train Epoch: 3664 [34304/60000 (57%)] Loss: -1536.727051\n",
      "Train Epoch: 3664 [45568/60000 (76%)] Loss: -1594.323975\n",
      "Train Epoch: 3664 [56832/60000 (95%)] Loss: -1606.754883\n",
      "    epoch          : 3664\n",
      "    loss           : -1523.3249215163753\n",
      "Train Epoch: 3665 [512/60000 (1%)] Loss: -1583.611938\n",
      "Train Epoch: 3665 [11776/60000 (20%)] Loss: -1426.920532\n",
      "Train Epoch: 3665 [23040/60000 (38%)] Loss: -1542.543091\n",
      "Train Epoch: 3665 [34304/60000 (57%)] Loss: -1498.429565\n",
      "Train Epoch: 3665 [45568/60000 (76%)] Loss: -1556.857422\n",
      "Train Epoch: 3665 [56832/60000 (95%)] Loss: -1468.005005\n",
      "    epoch          : 3665\n",
      "    loss           : -1527.1669049451582\n",
      "Train Epoch: 3666 [512/60000 (1%)] Loss: -1601.163086\n",
      "Train Epoch: 3666 [11776/60000 (20%)] Loss: -1558.956787\n",
      "Train Epoch: 3666 [23040/60000 (38%)] Loss: -1492.353271\n",
      "Train Epoch: 3666 [34304/60000 (57%)] Loss: -1531.597168\n",
      "Train Epoch: 3666 [45568/60000 (76%)] Loss: -1510.235718\n",
      "Train Epoch: 3666 [56832/60000 (95%)] Loss: -1545.104736\n",
      "    epoch          : 3666\n",
      "    loss           : -1523.4136462885108\n",
      "Train Epoch: 3667 [512/60000 (1%)] Loss: -1515.166992\n",
      "Train Epoch: 3667 [11776/60000 (20%)] Loss: -1452.637817\n",
      "Train Epoch: 3667 [23040/60000 (38%)] Loss: -1539.930908\n",
      "Train Epoch: 3667 [34304/60000 (57%)] Loss: -1599.191772\n",
      "Train Epoch: 3667 [45568/60000 (76%)] Loss: -1507.828491\n",
      "Train Epoch: 3667 [56832/60000 (95%)] Loss: -1549.660156\n",
      "    epoch          : 3667\n",
      "    loss           : -1523.2248590329273\n",
      "Train Epoch: 3668 [512/60000 (1%)] Loss: -1513.966797\n",
      "Train Epoch: 3668 [11776/60000 (20%)] Loss: -1499.333740\n",
      "Train Epoch: 3668 [23040/60000 (38%)] Loss: -1493.099365\n",
      "Train Epoch: 3668 [34304/60000 (57%)] Loss: -1556.428223\n",
      "Train Epoch: 3668 [45568/60000 (76%)] Loss: -1540.233887\n",
      "Train Epoch: 3668 [56832/60000 (95%)] Loss: -1519.187012\n",
      "    epoch          : 3668\n",
      "    loss           : -1525.3703496038577\n",
      "Train Epoch: 3669 [512/60000 (1%)] Loss: -1591.316528\n",
      "Train Epoch: 3669 [11776/60000 (20%)] Loss: -1532.108154\n",
      "Train Epoch: 3669 [23040/60000 (38%)] Loss: -1527.054932\n",
      "Train Epoch: 3669 [34304/60000 (57%)] Loss: -1469.302979\n",
      "Train Epoch: 3669 [45568/60000 (76%)] Loss: -1549.309448\n",
      "Train Epoch: 3669 [56832/60000 (95%)] Loss: -1582.287720\n",
      "    epoch          : 3669\n",
      "    loss           : -1521.7714557539944\n",
      "Train Epoch: 3670 [512/60000 (1%)] Loss: -1471.065552\n",
      "Train Epoch: 3670 [11776/60000 (20%)] Loss: -1487.615723\n",
      "Train Epoch: 3670 [23040/60000 (38%)] Loss: -1589.507812\n",
      "Train Epoch: 3670 [34304/60000 (57%)] Loss: -1596.194580\n",
      "Train Epoch: 3670 [45568/60000 (76%)] Loss: -1594.050049\n",
      "Train Epoch: 3670 [56832/60000 (95%)] Loss: -1585.395020\n",
      "    epoch          : 3670\n",
      "    loss           : -1536.06690694518\n",
      "Train Epoch: 3671 [512/60000 (1%)] Loss: -1496.631836\n",
      "Train Epoch: 3671 [11776/60000 (20%)] Loss: -1561.099976\n",
      "Train Epoch: 3671 [23040/60000 (38%)] Loss: -1536.041260\n",
      "Train Epoch: 3671 [34304/60000 (57%)] Loss: -1522.550049\n",
      "Train Epoch: 3671 [45568/60000 (76%)] Loss: -1542.367920\n",
      "Train Epoch: 3671 [56832/60000 (95%)] Loss: -1596.214844\n",
      "    epoch          : 3671\n",
      "    loss           : -1528.3895380914548\n",
      "Train Epoch: 3672 [512/60000 (1%)] Loss: -1543.583008\n",
      "Train Epoch: 3672 [11776/60000 (20%)] Loss: -1548.348145\n",
      "Train Epoch: 3672 [23040/60000 (38%)] Loss: -1569.154419\n",
      "Train Epoch: 3672 [34304/60000 (57%)] Loss: -1485.676025\n",
      "Train Epoch: 3672 [45568/60000 (76%)] Loss: -1592.887939\n",
      "Train Epoch: 3672 [56832/60000 (95%)] Loss: -1560.901855\n",
      "    epoch          : 3672\n",
      "    loss           : -1525.162593173442\n",
      "Train Epoch: 3673 [512/60000 (1%)] Loss: -1527.301147\n",
      "Train Epoch: 3673 [11776/60000 (20%)] Loss: -1522.796387\n",
      "Train Epoch: 3673 [23040/60000 (38%)] Loss: -1418.347656\n",
      "Train Epoch: 3673 [34304/60000 (57%)] Loss: -1535.947510\n",
      "Train Epoch: 3673 [45568/60000 (76%)] Loss: -1445.469727\n",
      "Train Epoch: 3673 [56832/60000 (95%)] Loss: -1607.427490\n",
      "    epoch          : 3673\n",
      "    loss           : -1524.2165930796477\n",
      "Train Epoch: 3674 [512/60000 (1%)] Loss: -1465.680908\n",
      "Train Epoch: 3674 [11776/60000 (20%)] Loss: -1531.190186\n",
      "Train Epoch: 3674 [23040/60000 (38%)] Loss: -1522.431396\n",
      "Train Epoch: 3674 [34304/60000 (57%)] Loss: -1585.036377\n",
      "Train Epoch: 3674 [45568/60000 (76%)] Loss: -1527.457764\n",
      "Train Epoch: 3674 [56832/60000 (95%)] Loss: -1396.720825\n",
      "    epoch          : 3674\n",
      "    loss           : -1528.870616158523\n",
      "Train Epoch: 3675 [512/60000 (1%)] Loss: -1513.637939\n",
      "Train Epoch: 3675 [11776/60000 (20%)] Loss: -1567.884521\n",
      "Train Epoch: 3675 [23040/60000 (38%)] Loss: -1489.390137\n",
      "Train Epoch: 3675 [34304/60000 (57%)] Loss: -1530.383301\n",
      "Train Epoch: 3675 [45568/60000 (76%)] Loss: -1532.369263\n",
      "Train Epoch: 3675 [56832/60000 (95%)] Loss: -1563.255615\n",
      "    epoch          : 3675\n",
      "    loss           : -1530.7544621182026\n",
      "Train Epoch: 3676 [512/60000 (1%)] Loss: -1515.666260\n",
      "Train Epoch: 3676 [11776/60000 (20%)] Loss: -1521.038330\n",
      "Train Epoch: 3676 [23040/60000 (38%)] Loss: -1514.993652\n",
      "Train Epoch: 3676 [34304/60000 (57%)] Loss: -1472.677246\n",
      "Train Epoch: 3676 [45568/60000 (76%)] Loss: -1570.654785\n",
      "Train Epoch: 3676 [56832/60000 (95%)] Loss: -1573.036865\n",
      "    epoch          : 3676\n",
      "    loss           : -1516.694090072718\n",
      "Train Epoch: 3677 [512/60000 (1%)] Loss: -1446.323242\n",
      "Train Epoch: 3677 [11776/60000 (20%)] Loss: -1509.923340\n",
      "Train Epoch: 3677 [23040/60000 (38%)] Loss: -1425.872803\n",
      "Train Epoch: 3677 [34304/60000 (57%)] Loss: -1511.168823\n",
      "Train Epoch: 3677 [45568/60000 (76%)] Loss: -1581.962891\n",
      "Train Epoch: 3677 [56832/60000 (95%)] Loss: -1593.118774\n",
      "    epoch          : 3677\n",
      "    loss           : -1516.8830835374736\n",
      "Train Epoch: 3678 [512/60000 (1%)] Loss: -1532.430420\n",
      "Train Epoch: 3678 [11776/60000 (20%)] Loss: -1509.128052\n",
      "Train Epoch: 3678 [23040/60000 (38%)] Loss: -1508.672485\n",
      "Train Epoch: 3678 [34304/60000 (57%)] Loss: -1474.048340\n",
      "Train Epoch: 3678 [45568/60000 (76%)] Loss: -1528.764404\n",
      "Train Epoch: 3678 [56832/60000 (95%)] Loss: -1535.033447\n",
      "    epoch          : 3678\n",
      "    loss           : -1527.882706636763\n",
      "Train Epoch: 3679 [512/60000 (1%)] Loss: -1566.503418\n",
      "Train Epoch: 3679 [11776/60000 (20%)] Loss: -1588.323975\n",
      "Train Epoch: 3679 [23040/60000 (38%)] Loss: -1544.640625\n",
      "Train Epoch: 3679 [34304/60000 (57%)] Loss: -1504.912354\n",
      "Train Epoch: 3679 [45568/60000 (76%)] Loss: -1514.219482\n",
      "Train Epoch: 3679 [56832/60000 (95%)] Loss: -1539.436279\n",
      "    epoch          : 3679\n",
      "    loss           : -1518.6314135190457\n",
      "Train Epoch: 3680 [512/60000 (1%)] Loss: -1430.562378\n",
      "Train Epoch: 3680 [11776/60000 (20%)] Loss: -1558.508789\n",
      "Train Epoch: 3680 [23040/60000 (38%)] Loss: -1525.477783\n",
      "Train Epoch: 3680 [34304/60000 (57%)] Loss: -1541.253052\n",
      "Train Epoch: 3680 [45568/60000 (76%)] Loss: -1543.088867\n",
      "Train Epoch: 3680 [56832/60000 (95%)] Loss: -1590.835083\n",
      "    epoch          : 3680\n",
      "    loss           : -1523.6259579416048\n",
      "Train Epoch: 3681 [512/60000 (1%)] Loss: -1456.006104\n",
      "Train Epoch: 3681 [11776/60000 (20%)] Loss: -1589.282471\n",
      "Train Epoch: 3681 [23040/60000 (38%)] Loss: -1447.347412\n",
      "Train Epoch: 3681 [34304/60000 (57%)] Loss: -1541.025635\n",
      "Train Epoch: 3681 [45568/60000 (76%)] Loss: -1509.763062\n",
      "Train Epoch: 3681 [56832/60000 (95%)] Loss: -1504.815430\n",
      "    epoch          : 3681\n",
      "    loss           : -1520.890683966168\n",
      "Train Epoch: 3682 [512/60000 (1%)] Loss: -1545.672119\n",
      "Train Epoch: 3682 [11776/60000 (20%)] Loss: -1448.913086\n",
      "Train Epoch: 3682 [23040/60000 (38%)] Loss: -1583.170288\n",
      "Train Epoch: 3682 [34304/60000 (57%)] Loss: -1468.823730\n",
      "Train Epoch: 3682 [45568/60000 (76%)] Loss: -1553.152588\n",
      "Train Epoch: 3682 [56832/60000 (95%)] Loss: -1492.020996\n",
      "    epoch          : 3682\n",
      "    loss           : -1521.4314382089733\n",
      "Train Epoch: 3683 [512/60000 (1%)] Loss: -1580.086914\n",
      "Train Epoch: 3683 [11776/60000 (20%)] Loss: -1489.702148\n",
      "Train Epoch: 3683 [23040/60000 (38%)] Loss: -1489.074341\n",
      "Train Epoch: 3683 [34304/60000 (57%)] Loss: -1534.040894\n",
      "Train Epoch: 3683 [45568/60000 (76%)] Loss: -1555.133789\n",
      "Train Epoch: 3683 [56832/60000 (95%)] Loss: -1492.866821\n",
      "    epoch          : 3683\n",
      "    loss           : -1526.1945318017301\n",
      "Train Epoch: 3684 [512/60000 (1%)] Loss: -1492.188965\n",
      "Train Epoch: 3684 [11776/60000 (20%)] Loss: -1536.488525\n",
      "Train Epoch: 3684 [23040/60000 (38%)] Loss: -1490.100098\n",
      "Train Epoch: 3684 [34304/60000 (57%)] Loss: -1456.735840\n",
      "Train Epoch: 3684 [45568/60000 (76%)] Loss: -1573.693237\n",
      "Train Epoch: 3684 [56832/60000 (95%)] Loss: -1567.233398\n",
      "    epoch          : 3684\n",
      "    loss           : -1528.3395309879281\n",
      "Train Epoch: 3685 [512/60000 (1%)] Loss: -1522.302490\n",
      "Train Epoch: 3685 [11776/60000 (20%)] Loss: -1579.919189\n",
      "Train Epoch: 3685 [23040/60000 (38%)] Loss: -1559.992188\n",
      "Train Epoch: 3685 [34304/60000 (57%)] Loss: -1529.753540\n",
      "Train Epoch: 3685 [45568/60000 (76%)] Loss: -1591.475830\n",
      "Train Epoch: 3685 [56832/60000 (95%)] Loss: -1560.165771\n",
      "    epoch          : 3685\n",
      "    loss           : -1521.0845278292725\n",
      "Train Epoch: 3686 [512/60000 (1%)] Loss: -1452.354614\n",
      "Train Epoch: 3686 [11776/60000 (20%)] Loss: -1532.266602\n",
      "Train Epoch: 3686 [23040/60000 (38%)] Loss: -1615.864014\n",
      "Train Epoch: 3686 [34304/60000 (57%)] Loss: -1582.593750\n",
      "Train Epoch: 3686 [45568/60000 (76%)] Loss: -1526.904541\n",
      "Train Epoch: 3686 [56832/60000 (95%)] Loss: -1576.353638\n",
      "    epoch          : 3686\n",
      "    loss           : -1517.7944991117142\n",
      "Train Epoch: 3687 [512/60000 (1%)] Loss: -1568.386108\n",
      "Train Epoch: 3687 [11776/60000 (20%)] Loss: -1523.010254\n",
      "Train Epoch: 3687 [23040/60000 (38%)] Loss: -1562.305054\n",
      "Train Epoch: 3687 [34304/60000 (57%)] Loss: -1522.145386\n",
      "Train Epoch: 3687 [45568/60000 (76%)] Loss: -1533.131958\n",
      "Train Epoch: 3687 [56832/60000 (95%)] Loss: -1519.582886\n",
      "    epoch          : 3687\n",
      "    loss           : -1530.418969795529\n",
      "Train Epoch: 3688 [512/60000 (1%)] Loss: -1445.206543\n",
      "Train Epoch: 3688 [11776/60000 (20%)] Loss: -1456.682129\n",
      "Train Epoch: 3688 [23040/60000 (38%)] Loss: -1472.459229\n",
      "Train Epoch: 3688 [34304/60000 (57%)] Loss: -1513.680542\n",
      "Train Epoch: 3688 [45568/60000 (76%)] Loss: -1520.155029\n",
      "Train Epoch: 3688 [56832/60000 (95%)] Loss: -1551.061279\n",
      "    epoch          : 3688\n",
      "    loss           : -1519.520091945842\n",
      "Train Epoch: 3689 [512/60000 (1%)] Loss: -1490.382080\n",
      "Train Epoch: 3689 [11776/60000 (20%)] Loss: -1589.377197\n",
      "Train Epoch: 3689 [23040/60000 (38%)] Loss: -1560.496338\n",
      "Train Epoch: 3689 [34304/60000 (57%)] Loss: -1551.675293\n",
      "Train Epoch: 3689 [45568/60000 (76%)] Loss: -1498.020264\n",
      "Train Epoch: 3689 [56832/60000 (95%)] Loss: -1538.216553\n",
      "    epoch          : 3689\n",
      "    loss           : -1523.1828878801423\n",
      "Train Epoch: 3690 [512/60000 (1%)] Loss: -1475.756714\n",
      "Train Epoch: 3690 [11776/60000 (20%)] Loss: -1510.691284\n",
      "Train Epoch: 3690 [23040/60000 (38%)] Loss: -1579.147705\n",
      "Train Epoch: 3690 [34304/60000 (57%)] Loss: -1554.643311\n",
      "Train Epoch: 3690 [45568/60000 (76%)] Loss: -1524.558838\n",
      "Train Epoch: 3690 [56832/60000 (95%)] Loss: -1566.019287\n",
      "    epoch          : 3690\n",
      "    loss           : -1514.9775004413843\n",
      "Train Epoch: 3691 [512/60000 (1%)] Loss: -1555.970947\n",
      "Train Epoch: 3691 [11776/60000 (20%)] Loss: -1605.421631\n",
      "Train Epoch: 3691 [23040/60000 (38%)] Loss: -1454.291626\n",
      "Train Epoch: 3691 [34304/60000 (57%)] Loss: -1475.861938\n",
      "Train Epoch: 3691 [45568/60000 (76%)] Loss: -1554.098999\n",
      "Train Epoch: 3691 [56832/60000 (95%)] Loss: -1488.245239\n",
      "    epoch          : 3691\n",
      "    loss           : -1522.6980828753972\n",
      "Train Epoch: 3692 [512/60000 (1%)] Loss: -1587.969482\n",
      "Train Epoch: 3692 [11776/60000 (20%)] Loss: -1488.299927\n",
      "Train Epoch: 3692 [23040/60000 (38%)] Loss: -1434.784912\n",
      "Train Epoch: 3692 [34304/60000 (57%)] Loss: -1533.701904\n",
      "Train Epoch: 3692 [45568/60000 (76%)] Loss: -1477.023560\n",
      "Train Epoch: 3692 [56832/60000 (95%)] Loss: -1597.980225\n",
      "    epoch          : 3692\n",
      "    loss           : -1525.0472905218264\n",
      "Train Epoch: 3693 [512/60000 (1%)] Loss: -1594.544800\n",
      "Train Epoch: 3693 [11776/60000 (20%)] Loss: -1568.839722\n",
      "Train Epoch: 3693 [23040/60000 (38%)] Loss: -1555.332153\n",
      "Train Epoch: 3693 [34304/60000 (57%)] Loss: -1550.719604\n",
      "Train Epoch: 3693 [45568/60000 (76%)] Loss: -1550.922119\n",
      "Train Epoch: 3693 [56832/60000 (95%)] Loss: -1451.370239\n",
      "    epoch          : 3693\n",
      "    loss           : -1526.9675558488923\n",
      "Train Epoch: 3694 [512/60000 (1%)] Loss: -1472.769775\n",
      "Train Epoch: 3694 [11776/60000 (20%)] Loss: -1521.748169\n",
      "Train Epoch: 3694 [23040/60000 (38%)] Loss: -1519.406494\n",
      "Train Epoch: 3694 [34304/60000 (57%)] Loss: -1488.373291\n",
      "Train Epoch: 3694 [45568/60000 (76%)] Loss: -1509.081055\n",
      "Train Epoch: 3694 [56832/60000 (95%)] Loss: -1528.361694\n",
      "    epoch          : 3694\n",
      "    loss           : -1526.1109591554114\n",
      "Train Epoch: 3695 [512/60000 (1%)] Loss: -1511.990356\n",
      "Train Epoch: 3695 [11776/60000 (20%)] Loss: -1520.513916\n",
      "Train Epoch: 3695 [23040/60000 (38%)] Loss: -1572.738403\n",
      "Train Epoch: 3695 [34304/60000 (57%)] Loss: -1522.236572\n",
      "Train Epoch: 3695 [45568/60000 (76%)] Loss: -1518.291260\n",
      "Train Epoch: 3695 [56832/60000 (95%)] Loss: -1469.236816\n",
      "    epoch          : 3695\n",
      "    loss           : -1517.6901858917063\n",
      "Train Epoch: 3696 [512/60000 (1%)] Loss: -1456.337402\n",
      "Train Epoch: 3696 [11776/60000 (20%)] Loss: -1584.371826\n",
      "Train Epoch: 3696 [23040/60000 (38%)] Loss: -1534.351318\n",
      "Train Epoch: 3696 [34304/60000 (57%)] Loss: -1513.669678\n",
      "Train Epoch: 3696 [45568/60000 (76%)] Loss: -1522.958618\n",
      "Train Epoch: 3696 [56832/60000 (95%)] Loss: -1495.677490\n",
      "    epoch          : 3696\n",
      "    loss           : -1522.3630533164505\n",
      "Train Epoch: 3697 [512/60000 (1%)] Loss: -1500.239136\n",
      "Train Epoch: 3697 [11776/60000 (20%)] Loss: -1489.234131\n",
      "Train Epoch: 3697 [23040/60000 (38%)] Loss: -1482.080566\n",
      "Train Epoch: 3697 [34304/60000 (57%)] Loss: -1584.413330\n",
      "Train Epoch: 3697 [45568/60000 (76%)] Loss: -1565.930176\n",
      "Train Epoch: 3697 [56832/60000 (95%)] Loss: -1568.951660\n",
      "    epoch          : 3697\n",
      "    loss           : -1533.005649717514\n",
      "Train Epoch: 3698 [512/60000 (1%)] Loss: -1579.251465\n",
      "Train Epoch: 3698 [11776/60000 (20%)] Loss: -1500.295044\n",
      "Train Epoch: 3698 [23040/60000 (38%)] Loss: -1548.005737\n",
      "Train Epoch: 3698 [34304/60000 (57%)] Loss: -1507.713257\n",
      "Train Epoch: 3698 [45568/60000 (76%)] Loss: -1441.158813\n",
      "Train Epoch: 3698 [56832/60000 (95%)] Loss: -1545.049805\n",
      "    epoch          : 3698\n",
      "    loss           : -1521.8535990741968\n",
      "Train Epoch: 3699 [512/60000 (1%)] Loss: -1467.326294\n",
      "Train Epoch: 3699 [11776/60000 (20%)] Loss: -1520.856079\n",
      "Train Epoch: 3699 [23040/60000 (38%)] Loss: -1539.358398\n",
      "Train Epoch: 3699 [34304/60000 (57%)] Loss: -1574.601196\n",
      "Train Epoch: 3699 [45568/60000 (76%)] Loss: -1487.345093\n",
      "Train Epoch: 3699 [56832/60000 (95%)] Loss: -1503.984375\n",
      "    epoch          : 3699\n",
      "    loss           : -1519.7391840185824\n",
      "Train Epoch: 3700 [512/60000 (1%)] Loss: -1470.042725\n",
      "Train Epoch: 3700 [11776/60000 (20%)] Loss: -1574.610352\n",
      "Train Epoch: 3700 [23040/60000 (38%)] Loss: -1505.160767\n",
      "Train Epoch: 3700 [34304/60000 (57%)] Loss: -1509.678833\n",
      "Train Epoch: 3700 [45568/60000 (76%)] Loss: -1555.117676\n",
      "Train Epoch: 3700 [56832/60000 (95%)] Loss: -1527.260742\n",
      "    epoch          : 3700\n",
      "    loss           : -1518.9041879082804\n",
      "Saving checkpoint: saved/models/Mnist_DeepGenerativeOperad/0127_111843/checkpoint-epoch3700.pth ...\n",
      "Train Epoch: 3701 [512/60000 (1%)] Loss: -1502.345581\n",
      "Train Epoch: 3701 [11776/60000 (20%)] Loss: -1492.079834\n",
      "Train Epoch: 3701 [23040/60000 (38%)] Loss: -1450.685669\n",
      "Train Epoch: 3701 [34304/60000 (57%)] Loss: -1510.383179\n",
      "Train Epoch: 3701 [45568/60000 (76%)] Loss: -1560.708618\n",
      "Train Epoch: 3701 [56832/60000 (95%)] Loss: -1543.734375\n",
      "    epoch          : 3701\n",
      "    loss           : -1529.1132809051687\n",
      "Train Epoch: 3702 [512/60000 (1%)] Loss: -1577.099854\n",
      "Train Epoch: 3702 [11776/60000 (20%)] Loss: -1516.721802\n",
      "Train Epoch: 3702 [23040/60000 (38%)] Loss: -1441.807617\n",
      "Train Epoch: 3702 [34304/60000 (57%)] Loss: -1463.973022\n",
      "Train Epoch: 3702 [45568/60000 (76%)] Loss: -1552.162231\n",
      "Train Epoch: 3702 [56832/60000 (95%)] Loss: -1554.237305\n",
      "    epoch          : 3702\n",
      "    loss           : -1520.9751459326449\n",
      "Train Epoch: 3703 [512/60000 (1%)] Loss: -1521.941406\n",
      "Train Epoch: 3703 [11776/60000 (20%)] Loss: -1508.058716\n",
      "Train Epoch: 3703 [23040/60000 (38%)] Loss: -1554.566284\n",
      "Train Epoch: 3703 [34304/60000 (57%)] Loss: -1591.412720\n",
      "Train Epoch: 3703 [45568/60000 (76%)] Loss: -1548.234619\n",
      "Train Epoch: 3703 [56832/60000 (95%)] Loss: -1481.252441\n",
      "    epoch          : 3703\n",
      "    loss           : -1522.144654699638\n",
      "Train Epoch: 3704 [512/60000 (1%)] Loss: -1508.019043\n",
      "Train Epoch: 3704 [11776/60000 (20%)] Loss: -1487.100952\n",
      "Train Epoch: 3704 [23040/60000 (38%)] Loss: -1546.858643\n",
      "Train Epoch: 3704 [34304/60000 (57%)] Loss: -1615.407471\n",
      "Train Epoch: 3704 [45568/60000 (76%)] Loss: -1517.578857\n",
      "Train Epoch: 3704 [56832/60000 (95%)] Loss: -1501.492798\n",
      "    epoch          : 3704\n",
      "    loss           : -1525.4515370514434\n",
      "Train Epoch: 3705 [512/60000 (1%)] Loss: -1489.270020\n",
      "Train Epoch: 3705 [11776/60000 (20%)] Loss: -1456.941650\n",
      "Train Epoch: 3705 [23040/60000 (38%)] Loss: -1589.164429\n",
      "Train Epoch: 3705 [34304/60000 (57%)] Loss: -1519.350464\n",
      "Train Epoch: 3705 [45568/60000 (76%)] Loss: -1587.872437\n",
      "Train Epoch: 3705 [56832/60000 (95%)] Loss: -1512.424927\n",
      "    epoch          : 3705\n",
      "    loss           : -1519.764163604564\n",
      "Train Epoch: 3706 [512/60000 (1%)] Loss: -1481.914917\n",
      "Train Epoch: 3706 [11776/60000 (20%)] Loss: -1506.466919\n",
      "Train Epoch: 3706 [23040/60000 (38%)] Loss: -1548.344482\n",
      "Train Epoch: 3706 [34304/60000 (57%)] Loss: -1486.049927\n",
      "Train Epoch: 3706 [45568/60000 (76%)] Loss: -1617.030640\n",
      "Train Epoch: 3706 [56832/60000 (95%)] Loss: -1502.369263\n",
      "    epoch          : 3706\n",
      "    loss           : -1524.2080840202375\n",
      "Train Epoch: 3707 [512/60000 (1%)] Loss: -1557.889038\n",
      "Train Epoch: 3707 [11776/60000 (20%)] Loss: -1501.155029\n",
      "Train Epoch: 3707 [23040/60000 (38%)] Loss: -1567.668579\n",
      "Train Epoch: 3707 [34304/60000 (57%)] Loss: -1535.971069\n",
      "Train Epoch: 3707 [45568/60000 (76%)] Loss: -1516.276855\n",
      "Train Epoch: 3707 [56832/60000 (95%)] Loss: -1500.903564\n",
      "    epoch          : 3707\n",
      "    loss           : -1522.719228625971\n",
      "Train Epoch: 3708 [512/60000 (1%)] Loss: -1435.559326\n",
      "Train Epoch: 3708 [11776/60000 (20%)] Loss: -1534.774414\n",
      "Train Epoch: 3708 [23040/60000 (38%)] Loss: -1567.542236\n",
      "Train Epoch: 3708 [34304/60000 (57%)] Loss: -1587.633545\n",
      "Train Epoch: 3708 [45568/60000 (76%)] Loss: -1520.366455\n",
      "Train Epoch: 3708 [56832/60000 (95%)] Loss: -1587.272461\n",
      "    epoch          : 3708\n",
      "    loss           : -1524.7833800235037\n",
      "Train Epoch: 3709 [512/60000 (1%)] Loss: -1514.834351\n",
      "Train Epoch: 3709 [11776/60000 (20%)] Loss: -1487.620972\n",
      "Train Epoch: 3709 [23040/60000 (38%)] Loss: -1522.511841\n",
      "Train Epoch: 3709 [34304/60000 (57%)] Loss: -1551.481201\n",
      "Train Epoch: 3709 [45568/60000 (76%)] Loss: -1447.877686\n",
      "Train Epoch: 3709 [56832/60000 (95%)] Loss: -1481.663818\n",
      "    epoch          : 3709\n",
      "    loss           : -1524.0303655074815\n",
      "Train Epoch: 3710 [512/60000 (1%)] Loss: -1477.147949\n",
      "Train Epoch: 3710 [11776/60000 (20%)] Loss: -1571.400391\n",
      "Train Epoch: 3710 [23040/60000 (38%)] Loss: -1592.425781\n",
      "Train Epoch: 3710 [34304/60000 (57%)] Loss: -1553.126099\n",
      "Train Epoch: 3710 [45568/60000 (76%)] Loss: -1536.845947\n",
      "Train Epoch: 3710 [56832/60000 (95%)] Loss: -1550.038574\n",
      "    epoch          : 3710\n",
      "    loss           : -1530.0872830320886\n",
      "Train Epoch: 3711 [512/60000 (1%)] Loss: -1591.391602\n",
      "Train Epoch: 3711 [11776/60000 (20%)] Loss: -1480.709106\n",
      "Train Epoch: 3711 [23040/60000 (38%)] Loss: -1562.195679\n",
      "Train Epoch: 3711 [34304/60000 (57%)] Loss: -1556.881104\n",
      "Train Epoch: 3711 [45568/60000 (76%)] Loss: -1489.303711\n",
      "Train Epoch: 3711 [56832/60000 (95%)] Loss: -1515.794189\n",
      "    epoch          : 3711\n",
      "    loss           : -1522.0775853388727\n",
      "Train Epoch: 3712 [512/60000 (1%)] Loss: -1500.019775\n",
      "Train Epoch: 3712 [11776/60000 (20%)] Loss: -1542.418213\n",
      "Train Epoch: 3712 [23040/60000 (38%)] Loss: -1540.124390\n",
      "Train Epoch: 3712 [34304/60000 (57%)] Loss: -1498.053345\n",
      "Train Epoch: 3712 [45568/60000 (76%)] Loss: -1560.944946\n",
      "Train Epoch: 3712 [56832/60000 (95%)] Loss: -1587.378418\n",
      "    epoch          : 3712\n",
      "    loss           : -1530.7363322629767\n",
      "Train Epoch: 3713 [512/60000 (1%)] Loss: -1529.334473\n",
      "Train Epoch: 3713 [11776/60000 (20%)] Loss: -1436.613770\n",
      "Train Epoch: 3713 [23040/60000 (38%)] Loss: -1524.755127\n",
      "Train Epoch: 3713 [34304/60000 (57%)] Loss: -1586.151855\n",
      "Train Epoch: 3713 [45568/60000 (76%)] Loss: -1564.751709\n",
      "Train Epoch: 3713 [56832/60000 (95%)] Loss: -1538.293457\n",
      "    epoch          : 3713\n",
      "    loss           : -1514.7468489307469\n",
      "Train Epoch: 3714 [512/60000 (1%)] Loss: -1518.809570\n",
      "Train Epoch: 3714 [11776/60000 (20%)] Loss: -1519.345459\n",
      "Train Epoch: 3714 [23040/60000 (38%)] Loss: -1559.450073\n",
      "Train Epoch: 3714 [34304/60000 (57%)] Loss: -1569.260498\n",
      "Train Epoch: 3714 [45568/60000 (76%)] Loss: -1447.296387\n",
      "Train Epoch: 3714 [56832/60000 (95%)] Loss: -1561.274414\n",
      "    epoch          : 3714\n",
      "    loss           : -1519.3248932402012\n",
      "Train Epoch: 3715 [512/60000 (1%)] Loss: -1563.618164\n",
      "Train Epoch: 3715 [11776/60000 (20%)] Loss: -1527.911621\n",
      "Train Epoch: 3715 [23040/60000 (38%)] Loss: -1470.239746\n",
      "Train Epoch: 3715 [34304/60000 (57%)] Loss: -1483.122314\n",
      "Train Epoch: 3715 [45568/60000 (76%)] Loss: -1579.091553\n",
      "Train Epoch: 3715 [56832/60000 (95%)] Loss: -1489.543945\n",
      "    epoch          : 3715\n",
      "    loss           : -1525.674386062191\n",
      "Train Epoch: 3716 [512/60000 (1%)] Loss: -1531.662354\n",
      "Train Epoch: 3716 [11776/60000 (20%)] Loss: -1494.839355\n",
      "Train Epoch: 3716 [23040/60000 (38%)] Loss: -1554.655762\n",
      "Train Epoch: 3716 [34304/60000 (57%)] Loss: -1555.979492\n",
      "Train Epoch: 3716 [45568/60000 (76%)] Loss: -1600.156738\n",
      "Train Epoch: 3716 [56832/60000 (95%)] Loss: -1456.383789\n",
      "    epoch          : 3716\n",
      "    loss           : -1535.771769895392\n",
      "Train Epoch: 3717 [512/60000 (1%)] Loss: -1480.604126\n",
      "Train Epoch: 3717 [11776/60000 (20%)] Loss: -1527.746094\n",
      "Train Epoch: 3717 [23040/60000 (38%)] Loss: -1476.893066\n",
      "Train Epoch: 3717 [34304/60000 (57%)] Loss: -1434.448730\n",
      "Train Epoch: 3717 [45568/60000 (76%)] Loss: -1572.550171\n",
      "Train Epoch: 3717 [56832/60000 (95%)] Loss: -1513.160400\n",
      "    epoch          : 3717\n",
      "    loss           : -1521.5000137932557\n",
      "Train Epoch: 3718 [512/60000 (1%)] Loss: -1540.472656\n",
      "Train Epoch: 3718 [11776/60000 (20%)] Loss: -1561.829102\n",
      "Train Epoch: 3718 [23040/60000 (38%)] Loss: -1420.046387\n",
      "Train Epoch: 3718 [34304/60000 (57%)] Loss: -1500.659668\n",
      "Train Epoch: 3718 [45568/60000 (76%)] Loss: -1526.710327\n",
      "Train Epoch: 3718 [56832/60000 (95%)] Loss: -1437.588379\n",
      "    epoch          : 3718\n",
      "    loss           : -1529.265308444783\n",
      "Train Epoch: 3719 [512/60000 (1%)] Loss: -1508.525635\n",
      "Train Epoch: 3719 [11776/60000 (20%)] Loss: -1570.493530\n",
      "Train Epoch: 3719 [23040/60000 (38%)] Loss: -1535.828979\n",
      "Train Epoch: 3719 [34304/60000 (57%)] Loss: -1441.441895\n",
      "Train Epoch: 3719 [45568/60000 (76%)] Loss: -1556.819580\n",
      "Train Epoch: 3719 [56832/60000 (95%)] Loss: -1535.917236\n",
      "    epoch          : 3719\n",
      "    loss           : -1525.3538790772864\n",
      "Train Epoch: 3720 [512/60000 (1%)] Loss: -1490.979980\n",
      "Train Epoch: 3720 [11776/60000 (20%)] Loss: -1590.042603\n",
      "Train Epoch: 3720 [23040/60000 (38%)] Loss: -1489.334717\n",
      "Train Epoch: 3720 [34304/60000 (57%)] Loss: -1535.573120\n",
      "Train Epoch: 3720 [45568/60000 (76%)] Loss: -1450.537598\n",
      "Train Epoch: 3720 [56832/60000 (95%)] Loss: -1446.942627\n",
      "    epoch          : 3720\n",
      "    loss           : -1521.6455660890051\n",
      "Train Epoch: 3721 [512/60000 (1%)] Loss: -1477.951904\n",
      "Train Epoch: 3721 [11776/60000 (20%)] Loss: -1557.105957\n",
      "Train Epoch: 3721 [23040/60000 (38%)] Loss: -1477.623535\n",
      "Train Epoch: 3721 [34304/60000 (57%)] Loss: -1532.905518\n",
      "Train Epoch: 3721 [45568/60000 (76%)] Loss: -1541.516479\n",
      "Train Epoch: 3721 [56832/60000 (95%)] Loss: -1472.311890\n",
      "    epoch          : 3721\n",
      "    loss           : -1520.6548434327551\n",
      "Train Epoch: 3722 [512/60000 (1%)] Loss: -1472.504272\n",
      "Train Epoch: 3722 [11776/60000 (20%)] Loss: -1584.600708\n",
      "Train Epoch: 3722 [23040/60000 (38%)] Loss: -1558.160156\n",
      "Train Epoch: 3722 [34304/60000 (57%)] Loss: -1517.478271\n",
      "Train Epoch: 3722 [45568/60000 (76%)] Loss: -1592.312256\n",
      "Train Epoch: 3722 [56832/60000 (95%)] Loss: -1564.418945\n",
      "    epoch          : 3722\n",
      "    loss           : -1526.128872801355\n",
      "Train Epoch: 3723 [512/60000 (1%)] Loss: -1548.613770\n",
      "Train Epoch: 3723 [11776/60000 (20%)] Loss: -1472.245850\n",
      "Train Epoch: 3723 [23040/60000 (38%)] Loss: -1623.294800\n",
      "Train Epoch: 3723 [34304/60000 (57%)] Loss: -1462.885254\n",
      "Train Epoch: 3723 [45568/60000 (76%)] Loss: -1497.965942\n",
      "Train Epoch: 3723 [56832/60000 (95%)] Loss: -1487.638550\n",
      "    epoch          : 3723\n",
      "    loss           : -1529.8061744129589\n",
      "Train Epoch: 3724 [512/60000 (1%)] Loss: -1616.651733\n",
      "Train Epoch: 3724 [11776/60000 (20%)] Loss: -1487.456177\n",
      "Train Epoch: 3724 [23040/60000 (38%)] Loss: -1589.694214\n",
      "Train Epoch: 3724 [34304/60000 (57%)] Loss: -1532.587646\n",
      "Train Epoch: 3724 [45568/60000 (76%)] Loss: -1519.099243\n",
      "Train Epoch: 3724 [56832/60000 (95%)] Loss: -1549.304932\n",
      "    epoch          : 3724\n",
      "    loss           : -1521.0322848390051\n",
      "Train Epoch: 3725 [512/60000 (1%)] Loss: -1558.915283\n",
      "Train Epoch: 3725 [11776/60000 (20%)] Loss: -1547.033691\n",
      "Train Epoch: 3725 [23040/60000 (38%)] Loss: -1526.895874\n",
      "Train Epoch: 3725 [34304/60000 (57%)] Loss: -1567.284180\n",
      "Train Epoch: 3725 [45568/60000 (76%)] Loss: -1537.856689\n",
      "Train Epoch: 3725 [56832/60000 (95%)] Loss: -1517.696533\n",
      "    epoch          : 3725\n",
      "    loss           : -1521.9772838872705\n",
      "Train Epoch: 3726 [512/60000 (1%)] Loss: -1595.316406\n",
      "Train Epoch: 3726 [11776/60000 (20%)] Loss: -1575.654785\n",
      "Train Epoch: 3726 [23040/60000 (38%)] Loss: -1500.349854\n",
      "Train Epoch: 3726 [34304/60000 (57%)] Loss: -1532.655273\n",
      "Train Epoch: 3726 [45568/60000 (76%)] Loss: -1515.971191\n",
      "Train Epoch: 3726 [56832/60000 (95%)] Loss: -1449.587524\n",
      "    epoch          : 3726\n",
      "    loss           : -1523.9426579879503\n",
      "Train Epoch: 3727 [512/60000 (1%)] Loss: -1503.509277\n",
      "Train Epoch: 3727 [11776/60000 (20%)] Loss: -1545.444092\n",
      "Train Epoch: 3727 [23040/60000 (38%)] Loss: -1493.810791\n",
      "Train Epoch: 3727 [34304/60000 (57%)] Loss: -1515.413086\n",
      "Train Epoch: 3727 [45568/60000 (76%)] Loss: -1518.629883\n",
      "Train Epoch: 3727 [56832/60000 (95%)] Loss: -1576.745605\n",
      "    epoch          : 3727\n",
      "    loss           : -1526.1743867518537\n",
      "Train Epoch: 3728 [512/60000 (1%)] Loss: -1505.286011\n",
      "Train Epoch: 3728 [11776/60000 (20%)] Loss: -1509.644653\n",
      "Train Epoch: 3728 [23040/60000 (38%)] Loss: -1605.983643\n",
      "Train Epoch: 3728 [34304/60000 (57%)] Loss: -1538.989258\n",
      "Train Epoch: 3728 [45568/60000 (76%)] Loss: -1559.539917\n",
      "Train Epoch: 3728 [56832/60000 (95%)] Loss: -1550.293213\n",
      "    epoch          : 3728\n",
      "    loss           : -1522.1749508960097\n",
      "Train Epoch: 3729 [512/60000 (1%)] Loss: -1546.850464\n",
      "Train Epoch: 3729 [11776/60000 (20%)] Loss: -1498.493896\n",
      "Train Epoch: 3729 [23040/60000 (38%)] Loss: -1522.271606\n",
      "Train Epoch: 3729 [34304/60000 (57%)] Loss: -1449.602539\n",
      "Train Epoch: 3729 [45568/60000 (76%)] Loss: -1498.303101\n",
      "Train Epoch: 3729 [56832/60000 (95%)] Loss: -1528.982788\n",
      "    epoch          : 3729\n",
      "    loss           : -1524.713922705354\n",
      "Train Epoch: 3730 [512/60000 (1%)] Loss: -1486.675781\n",
      "Train Epoch: 3730 [11776/60000 (20%)] Loss: -1520.624023\n",
      "Train Epoch: 3730 [23040/60000 (38%)] Loss: -1465.112671\n",
      "Train Epoch: 3730 [34304/60000 (57%)] Loss: -1474.118652\n",
      "Train Epoch: 3730 [45568/60000 (76%)] Loss: -1499.822632\n",
      "Train Epoch: 3730 [56832/60000 (95%)] Loss: -1498.205688\n",
      "    epoch          : 3730\n",
      "    loss           : -1524.7513758772511\n",
      "Train Epoch: 3731 [512/60000 (1%)] Loss: -1551.927612\n",
      "Train Epoch: 3731 [11776/60000 (20%)] Loss: -1550.723145\n",
      "Train Epoch: 3731 [23040/60000 (38%)] Loss: -1544.883545\n",
      "Train Epoch: 3731 [34304/60000 (57%)] Loss: -1548.664307\n",
      "Train Epoch: 3731 [45568/60000 (76%)] Loss: -1585.440796\n",
      "Train Epoch: 3731 [56832/60000 (95%)] Loss: -1590.741821\n",
      "    epoch          : 3731\n",
      "    loss           : -1527.5103114930923\n",
      "Train Epoch: 3732 [512/60000 (1%)] Loss: -1546.407715\n",
      "Train Epoch: 3732 [11776/60000 (20%)] Loss: -1468.678589\n",
      "Train Epoch: 3732 [23040/60000 (38%)] Loss: -1539.249756\n",
      "Train Epoch: 3732 [34304/60000 (57%)] Loss: -1564.668701\n",
      "Train Epoch: 3732 [45568/60000 (76%)] Loss: -1446.885620\n",
      "Train Epoch: 3732 [56832/60000 (95%)] Loss: -1536.602051\n",
      "    epoch          : 3732\n",
      "    loss           : -1526.5010620806852\n",
      "Train Epoch: 3733 [512/60000 (1%)] Loss: -1557.819702\n",
      "Train Epoch: 3733 [11776/60000 (20%)] Loss: -1478.655518\n",
      "Train Epoch: 3733 [23040/60000 (38%)] Loss: -1602.367554\n",
      "Train Epoch: 3733 [34304/60000 (57%)] Loss: -1523.925049\n",
      "Train Epoch: 3733 [45568/60000 (76%)] Loss: -1591.219604\n",
      "Train Epoch: 3733 [56832/60000 (95%)] Loss: -1477.116699\n",
      "    epoch          : 3733\n",
      "    loss           : -1522.1219613457804\n",
      "Train Epoch: 3734 [512/60000 (1%)] Loss: -1538.740723\n",
      "Train Epoch: 3734 [11776/60000 (20%)] Loss: -1547.916748\n",
      "Train Epoch: 3734 [23040/60000 (38%)] Loss: -1573.683838\n",
      "Train Epoch: 3734 [34304/60000 (57%)] Loss: -1540.483154\n",
      "Train Epoch: 3734 [45568/60000 (76%)] Loss: -1547.647949\n",
      "Train Epoch: 3734 [56832/60000 (95%)] Loss: -1570.572388\n",
      "    epoch          : 3734\n",
      "    loss           : -1526.6913738358494\n",
      "Train Epoch: 3735 [512/60000 (1%)] Loss: -1531.916138\n",
      "Train Epoch: 3735 [11776/60000 (20%)] Loss: -1441.592896\n",
      "Train Epoch: 3735 [23040/60000 (38%)] Loss: -1466.881714\n",
      "Train Epoch: 3735 [34304/60000 (57%)] Loss: -1525.708496\n",
      "Train Epoch: 3735 [45568/60000 (76%)] Loss: -1618.950684\n",
      "Train Epoch: 3735 [56832/60000 (95%)] Loss: -1513.899536\n",
      "    epoch          : 3735\n",
      "    loss           : -1526.3847880390406\n",
      "Train Epoch: 3736 [512/60000 (1%)] Loss: -1527.789307\n",
      "Train Epoch: 3736 [11776/60000 (20%)] Loss: -1589.063965\n",
      "Train Epoch: 3736 [23040/60000 (38%)] Loss: -1511.429199\n",
      "Train Epoch: 3736 [34304/60000 (57%)] Loss: -1509.994629\n",
      "Train Epoch: 3736 [45568/60000 (76%)] Loss: -1493.127197\n",
      "Train Epoch: 3736 [56832/60000 (95%)] Loss: -1584.724854\n",
      "    epoch          : 3736\n",
      "    loss           : -1522.4888702220162\n",
      "Train Epoch: 3737 [512/60000 (1%)] Loss: -1516.591797\n",
      "Train Epoch: 3737 [11776/60000 (20%)] Loss: -1568.970093\n",
      "Train Epoch: 3737 [23040/60000 (38%)] Loss: -1519.246582\n",
      "Train Epoch: 3737 [34304/60000 (57%)] Loss: -1566.754883\n",
      "Train Epoch: 3737 [45568/60000 (76%)] Loss: -1531.994385\n",
      "Train Epoch: 3737 [56832/60000 (95%)] Loss: -1455.526978\n",
      "    epoch          : 3737\n",
      "    loss           : -1532.8115775760284\n",
      "Train Epoch: 3738 [512/60000 (1%)] Loss: -1574.451294\n",
      "Train Epoch: 3738 [11776/60000 (20%)] Loss: -1591.352783\n",
      "Train Epoch: 3738 [23040/60000 (38%)] Loss: -1585.693604\n",
      "Train Epoch: 3738 [34304/60000 (57%)] Loss: -1570.723633\n",
      "Train Epoch: 3738 [45568/60000 (76%)] Loss: -1499.104614\n",
      "Train Epoch: 3738 [56832/60000 (95%)] Loss: -1563.776367\n",
      "    epoch          : 3738\n",
      "    loss           : -1531.7048891573975\n",
      "Train Epoch: 3739 [512/60000 (1%)] Loss: -1486.316162\n",
      "Train Epoch: 3739 [11776/60000 (20%)] Loss: -1513.539795\n",
      "Train Epoch: 3739 [23040/60000 (38%)] Loss: -1568.038818\n",
      "Train Epoch: 3739 [34304/60000 (57%)] Loss: -1533.997192\n",
      "Train Epoch: 3739 [45568/60000 (76%)] Loss: -1518.035156\n",
      "Train Epoch: 3739 [56832/60000 (95%)] Loss: -1501.985229\n",
      "    epoch          : 3739\n",
      "    loss           : -1523.066544527388\n",
      "Train Epoch: 3740 [512/60000 (1%)] Loss: -1594.535400\n",
      "Train Epoch: 3740 [11776/60000 (20%)] Loss: -1540.975586\n",
      "Train Epoch: 3740 [23040/60000 (38%)] Loss: -1477.219971\n",
      "Train Epoch: 3740 [34304/60000 (57%)] Loss: -1478.289551\n",
      "Train Epoch: 3740 [45568/60000 (76%)] Loss: -1595.874756\n",
      "Train Epoch: 3740 [56832/60000 (95%)] Loss: -1589.599731\n",
      "    epoch          : 3740\n",
      "    loss           : -1526.178592660333\n",
      "Train Epoch: 3741 [512/60000 (1%)] Loss: -1538.221680\n",
      "Train Epoch: 3741 [11776/60000 (20%)] Loss: -1480.577881\n",
      "Train Epoch: 3741 [23040/60000 (38%)] Loss: -1543.235229\n",
      "Train Epoch: 3741 [34304/60000 (57%)] Loss: -1540.561768\n",
      "Train Epoch: 3741 [45568/60000 (76%)] Loss: -1594.032959\n",
      "Train Epoch: 3741 [56832/60000 (95%)] Loss: -1512.309326\n",
      "    epoch          : 3741\n",
      "    loss           : -1529.1637973246602\n",
      "Train Epoch: 3742 [512/60000 (1%)] Loss: -1576.543579\n",
      "Train Epoch: 3742 [11776/60000 (20%)] Loss: -1545.950439\n",
      "Train Epoch: 3742 [23040/60000 (38%)] Loss: -1575.731567\n",
      "Train Epoch: 3742 [34304/60000 (57%)] Loss: -1532.829224\n",
      "Train Epoch: 3742 [45568/60000 (76%)] Loss: -1412.605835\n",
      "Train Epoch: 3742 [56832/60000 (95%)] Loss: -1593.558594\n",
      "    epoch          : 3742\n",
      "    loss           : -1522.4589733403955\n",
      "Train Epoch: 3743 [512/60000 (1%)] Loss: -1577.700317\n",
      "Train Epoch: 3743 [11776/60000 (20%)] Loss: -1496.479858\n",
      "Train Epoch: 3743 [23040/60000 (38%)] Loss: -1541.020752\n",
      "Train Epoch: 3743 [34304/60000 (57%)] Loss: -1540.651855\n",
      "Train Epoch: 3743 [45568/60000 (76%)] Loss: -1457.876709\n",
      "Train Epoch: 3743 [56832/60000 (95%)] Loss: -1558.737671\n",
      "    epoch          : 3743\n",
      "    loss           : -1529.1048866746114\n",
      "Train Epoch: 3744 [512/60000 (1%)] Loss: -1516.084473\n",
      "Train Epoch: 3744 [11776/60000 (20%)] Loss: -1541.791748\n",
      "Train Epoch: 3744 [23040/60000 (38%)] Loss: -1476.213379\n",
      "Train Epoch: 3744 [34304/60000 (57%)] Loss: -1444.074951\n",
      "Train Epoch: 3744 [45568/60000 (76%)] Loss: -1542.384277\n",
      "Train Epoch: 3744 [56832/60000 (95%)] Loss: -1512.452148\n",
      "    epoch          : 3744\n",
      "    loss           : -1535.5255047641904\n",
      "Train Epoch: 3745 [512/60000 (1%)] Loss: -1540.407227\n",
      "Train Epoch: 3745 [11776/60000 (20%)] Loss: -1507.789185\n",
      "Train Epoch: 3745 [23040/60000 (38%)] Loss: -1474.898804\n",
      "Train Epoch: 3745 [34304/60000 (57%)] Loss: -1543.773560\n",
      "Train Epoch: 3745 [45568/60000 (76%)] Loss: -1527.645142\n",
      "Train Epoch: 3745 [56832/60000 (95%)] Loss: -1535.884766\n",
      "    epoch          : 3745\n",
      "    loss           : -1521.9387044960495\n",
      "Train Epoch: 3746 [512/60000 (1%)] Loss: -1547.797485\n",
      "Train Epoch: 3746 [11776/60000 (20%)] Loss: -1552.121582\n",
      "Train Epoch: 3746 [23040/60000 (38%)] Loss: -1593.578735\n",
      "Train Epoch: 3746 [34304/60000 (57%)] Loss: -1504.728271\n",
      "Train Epoch: 3746 [45568/60000 (76%)] Loss: -1563.269165\n",
      "Train Epoch: 3746 [56832/60000 (95%)] Loss: -1523.318848\n",
      "    epoch          : 3746\n",
      "    loss           : -1527.0572282176906\n",
      "Train Epoch: 3747 [512/60000 (1%)] Loss: -1508.593262\n",
      "Train Epoch: 3747 [11776/60000 (20%)] Loss: -1476.156250\n",
      "Train Epoch: 3747 [23040/60000 (38%)] Loss: -1528.407959\n",
      "Train Epoch: 3747 [34304/60000 (57%)] Loss: -1519.449707\n",
      "Train Epoch: 3747 [45568/60000 (76%)] Loss: -1552.001831\n",
      "Train Epoch: 3747 [56832/60000 (95%)] Loss: -1503.523560\n",
      "    epoch          : 3747\n",
      "    loss           : -1527.6050332279528\n",
      "Train Epoch: 3748 [512/60000 (1%)] Loss: -1497.296265\n",
      "Train Epoch: 3748 [11776/60000 (20%)] Loss: -1515.125977\n",
      "Train Epoch: 3748 [23040/60000 (38%)] Loss: -1548.640869\n",
      "Train Epoch: 3748 [34304/60000 (57%)] Loss: -1516.400024\n",
      "Train Epoch: 3748 [45568/60000 (76%)] Loss: -1552.389404\n",
      "Train Epoch: 3748 [56832/60000 (95%)] Loss: -1401.539551\n",
      "    epoch          : 3748\n",
      "    loss           : -1525.8549480545994\n",
      "Train Epoch: 3749 [512/60000 (1%)] Loss: -1539.815552\n",
      "Train Epoch: 3749 [11776/60000 (20%)] Loss: -1542.265259\n",
      "Train Epoch: 3749 [23040/60000 (38%)] Loss: -1564.137451\n",
      "Train Epoch: 3749 [34304/60000 (57%)] Loss: -1534.607300\n",
      "Train Epoch: 3749 [45568/60000 (76%)] Loss: -1539.617432\n",
      "Train Epoch: 3749 [56832/60000 (95%)] Loss: -1460.317871\n",
      "    epoch          : 3749\n",
      "    loss           : -1520.9217601711466\n",
      "Train Epoch: 3750 [512/60000 (1%)] Loss: -1589.923584\n",
      "Train Epoch: 3750 [11776/60000 (20%)] Loss: -1565.380127\n",
      "Train Epoch: 3750 [23040/60000 (38%)] Loss: -1569.864502\n",
      "Train Epoch: 3750 [34304/60000 (57%)] Loss: -1606.958984\n",
      "Train Epoch: 3750 [45568/60000 (76%)] Loss: -1499.553589\n",
      "Train Epoch: 3750 [56832/60000 (95%)] Loss: -1566.015625\n",
      "    epoch          : 3750\n",
      "    loss           : -1524.9901881675935\n",
      "Train Epoch: 3751 [512/60000 (1%)] Loss: -1494.073608\n",
      "Train Epoch: 3751 [11776/60000 (20%)] Loss: -1557.250366\n",
      "Train Epoch: 3751 [23040/60000 (38%)] Loss: -1524.498291\n",
      "Train Epoch: 3751 [34304/60000 (57%)] Loss: -1572.838379\n",
      "Train Epoch: 3751 [45568/60000 (76%)] Loss: -1527.355347\n",
      "Train Epoch: 3751 [56832/60000 (95%)] Loss: -1519.182373\n",
      "    epoch          : 3751\n",
      "    loss           : -1527.3477617684057\n",
      "Train Epoch: 3752 [512/60000 (1%)] Loss: -1520.470581\n",
      "Train Epoch: 3752 [11776/60000 (20%)] Loss: -1468.710571\n",
      "Train Epoch: 3752 [23040/60000 (38%)] Loss: -1582.464478\n",
      "Train Epoch: 3752 [34304/60000 (57%)] Loss: -1522.731934\n",
      "Train Epoch: 3752 [45568/60000 (76%)] Loss: -1542.535889\n",
      "Train Epoch: 3752 [56832/60000 (95%)] Loss: -1510.184448\n",
      "    epoch          : 3752\n",
      "    loss           : -1519.5914816991083\n",
      "Train Epoch: 3753 [512/60000 (1%)] Loss: -1516.797363\n",
      "Train Epoch: 3753 [11776/60000 (20%)] Loss: -1542.734375\n",
      "Train Epoch: 3753 [23040/60000 (38%)] Loss: -1564.038818\n",
      "Train Epoch: 3753 [34304/60000 (57%)] Loss: -1486.740845\n",
      "Train Epoch: 3753 [45568/60000 (76%)] Loss: -1536.092041\n",
      "Train Epoch: 3753 [56832/60000 (95%)] Loss: -1549.744995\n",
      "    epoch          : 3753\n",
      "    loss           : -1525.5596520375398\n",
      "Train Epoch: 3754 [512/60000 (1%)] Loss: -1489.617310\n",
      "Train Epoch: 3754 [11776/60000 (20%)] Loss: -1472.410034\n",
      "Train Epoch: 3754 [23040/60000 (38%)] Loss: -1498.113525\n",
      "Train Epoch: 3754 [34304/60000 (57%)] Loss: -1538.232422\n",
      "Train Epoch: 3754 [45568/60000 (76%)] Loss: -1530.876709\n",
      "Train Epoch: 3754 [56832/60000 (95%)] Loss: -1520.193604\n",
      "    epoch          : 3754\n",
      "    loss           : -1517.8824890481549\n",
      "Train Epoch: 3755 [512/60000 (1%)] Loss: -1598.295410\n",
      "Train Epoch: 3755 [11776/60000 (20%)] Loss: -1544.259888\n",
      "Train Epoch: 3755 [23040/60000 (38%)] Loss: -1474.054688\n",
      "Train Epoch: 3755 [34304/60000 (57%)] Loss: -1598.411499\n",
      "Train Epoch: 3755 [45568/60000 (76%)] Loss: -1519.419800\n",
      "Train Epoch: 3755 [56832/60000 (95%)] Loss: -1491.094727\n",
      "    epoch          : 3755\n",
      "    loss           : -1519.5187395171258\n",
      "Train Epoch: 3756 [512/60000 (1%)] Loss: -1552.521729\n",
      "Train Epoch: 3756 [11776/60000 (20%)] Loss: -1492.394531\n",
      "Train Epoch: 3756 [23040/60000 (38%)] Loss: -1498.333252\n",
      "Train Epoch: 3756 [34304/60000 (57%)] Loss: -1559.451782\n",
      "Train Epoch: 3756 [45568/60000 (76%)] Loss: -1545.032593\n",
      "Train Epoch: 3756 [56832/60000 (95%)] Loss: -1552.738525\n",
      "    epoch          : 3756\n",
      "    loss           : -1523.3673412948006\n",
      "Train Epoch: 3757 [512/60000 (1%)] Loss: -1508.492188\n",
      "Train Epoch: 3757 [11776/60000 (20%)] Loss: -1528.405029\n",
      "Train Epoch: 3757 [23040/60000 (38%)] Loss: -1512.339600\n",
      "Train Epoch: 3757 [34304/60000 (57%)] Loss: -1386.519409\n",
      "Train Epoch: 3757 [45568/60000 (76%)] Loss: -1567.965454\n",
      "Train Epoch: 3757 [56832/60000 (95%)] Loss: -1541.788086\n",
      "    epoch          : 3757\n",
      "    loss           : -1521.1255096607963\n",
      "Train Epoch: 3758 [512/60000 (1%)] Loss: -1511.438232\n",
      "Train Epoch: 3758 [11776/60000 (20%)] Loss: -1469.052734\n",
      "Train Epoch: 3758 [23040/60000 (38%)] Loss: -1507.097046\n",
      "Train Epoch: 3758 [34304/60000 (57%)] Loss: -1521.264282\n",
      "Train Epoch: 3758 [45568/60000 (76%)] Loss: -1528.266479\n",
      "Train Epoch: 3758 [56832/60000 (95%)] Loss: -1571.522339\n",
      "    epoch          : 3758\n",
      "    loss           : -1522.8087568552482\n",
      "Train Epoch: 3759 [512/60000 (1%)] Loss: -1475.238770\n",
      "Train Epoch: 3759 [11776/60000 (20%)] Loss: -1510.354126\n",
      "Train Epoch: 3759 [23040/60000 (38%)] Loss: -1483.436401\n",
      "Train Epoch: 3759 [34304/60000 (57%)] Loss: -1476.012207\n",
      "Train Epoch: 3759 [45568/60000 (76%)] Loss: -1590.712402\n",
      "Train Epoch: 3759 [56832/60000 (95%)] Loss: -1503.281128\n",
      "    epoch          : 3759\n",
      "    loss           : -1518.8490962658898\n",
      "Train Epoch: 3760 [512/60000 (1%)] Loss: -1502.113037\n",
      "Train Epoch: 3760 [11776/60000 (20%)] Loss: -1537.245117\n",
      "Train Epoch: 3760 [23040/60000 (38%)] Loss: -1544.677124\n",
      "Train Epoch: 3760 [34304/60000 (57%)] Loss: -1539.829346\n",
      "Train Epoch: 3760 [45568/60000 (76%)] Loss: -1473.935425\n",
      "Train Epoch: 3760 [56832/60000 (95%)] Loss: -1559.313965\n",
      "    epoch          : 3760\n",
      "    loss           : -1526.7001535879017\n",
      "Train Epoch: 3761 [512/60000 (1%)] Loss: -1499.313354\n",
      "Train Epoch: 3761 [11776/60000 (20%)] Loss: -1552.821533\n",
      "Train Epoch: 3761 [23040/60000 (38%)] Loss: -1497.172119\n",
      "Train Epoch: 3761 [34304/60000 (57%)] Loss: -1460.359253\n",
      "Train Epoch: 3761 [45568/60000 (76%)] Loss: -1581.183105\n",
      "Train Epoch: 3761 [56832/60000 (95%)] Loss: -1525.363647\n",
      "    epoch          : 3761\n",
      "    loss           : -1521.9211174054335\n",
      "Train Epoch: 3762 [512/60000 (1%)] Loss: -1530.638428\n",
      "Train Epoch: 3762 [11776/60000 (20%)] Loss: -1525.357056\n",
      "Train Epoch: 3762 [23040/60000 (38%)] Loss: -1508.908936\n",
      "Train Epoch: 3762 [34304/60000 (57%)] Loss: -1498.297485\n",
      "Train Epoch: 3762 [45568/60000 (76%)] Loss: -1557.275024\n",
      "Train Epoch: 3762 [56832/60000 (95%)] Loss: -1500.445190\n",
      "    epoch          : 3762\n",
      "    loss           : -1518.4064648299568\n",
      "Train Epoch: 3763 [512/60000 (1%)] Loss: -1539.444580\n",
      "Train Epoch: 3763 [11776/60000 (20%)] Loss: -1521.833130\n",
      "Train Epoch: 3763 [23040/60000 (38%)] Loss: -1516.923462\n",
      "Train Epoch: 3763 [34304/60000 (57%)] Loss: -1475.639160\n",
      "Train Epoch: 3763 [45568/60000 (76%)] Loss: -1558.587524\n",
      "Train Epoch: 3763 [56832/60000 (95%)] Loss: -1561.874023\n",
      "    epoch          : 3763\n",
      "    loss           : -1519.026595465881\n",
      "Train Epoch: 3764 [512/60000 (1%)] Loss: -1471.502930\n",
      "Train Epoch: 3764 [11776/60000 (20%)] Loss: -1515.980957\n",
      "Train Epoch: 3764 [23040/60000 (38%)] Loss: -1497.660156\n",
      "Train Epoch: 3764 [34304/60000 (57%)] Loss: -1528.492920\n",
      "Train Epoch: 3764 [45568/60000 (76%)] Loss: -1497.945801\n",
      "Train Epoch: 3764 [56832/60000 (95%)] Loss: -1529.087646\n",
      "    epoch          : 3764\n",
      "    loss           : -1518.7429478532176\n",
      "Train Epoch: 3765 [512/60000 (1%)] Loss: -1491.762817\n",
      "Train Epoch: 3765 [11776/60000 (20%)] Loss: -1518.803711\n",
      "Train Epoch: 3765 [23040/60000 (38%)] Loss: -1479.150879\n",
      "Train Epoch: 3765 [34304/60000 (57%)] Loss: -1520.061157\n",
      "Train Epoch: 3765 [45568/60000 (76%)] Loss: -1442.411377\n",
      "Train Epoch: 3765 [56832/60000 (95%)] Loss: -1548.034912\n",
      "    epoch          : 3765\n",
      "    loss           : -1514.9919385317355\n",
      "Train Epoch: 3766 [512/60000 (1%)] Loss: -1550.546143\n",
      "Train Epoch: 3766 [11776/60000 (20%)] Loss: -1537.622925\n",
      "Train Epoch: 3766 [23040/60000 (38%)] Loss: -1527.195679\n",
      "Train Epoch: 3766 [34304/60000 (57%)] Loss: -1588.410767\n",
      "Train Epoch: 3766 [45568/60000 (76%)] Loss: -1499.002930\n",
      "Train Epoch: 3766 [56832/60000 (95%)] Loss: -1535.134277\n",
      "    epoch          : 3766\n",
      "    loss           : -1520.530766201558\n",
      "Train Epoch: 3767 [512/60000 (1%)] Loss: -1563.246582\n",
      "Train Epoch: 3767 [11776/60000 (20%)] Loss: -1461.131104\n",
      "Train Epoch: 3767 [23040/60000 (38%)] Loss: -1461.795654\n",
      "Train Epoch: 3767 [34304/60000 (57%)] Loss: -1533.095215\n",
      "Train Epoch: 3767 [45568/60000 (76%)] Loss: -1451.790039\n",
      "Train Epoch: 3767 [56832/60000 (95%)] Loss: -1427.167603\n",
      "    epoch          : 3767\n",
      "    loss           : -1522.5287816969014\n",
      "Train Epoch: 3768 [512/60000 (1%)] Loss: -1439.823486\n",
      "Train Epoch: 3768 [11776/60000 (20%)] Loss: -1440.654541\n",
      "Train Epoch: 3768 [23040/60000 (38%)] Loss: -1516.465454\n",
      "Train Epoch: 3768 [34304/60000 (57%)] Loss: -1564.512451\n",
      "Train Epoch: 3768 [45568/60000 (76%)] Loss: -1549.362549\n",
      "Train Epoch: 3768 [56832/60000 (95%)] Loss: -1584.466187\n",
      "    epoch          : 3768\n",
      "    loss           : -1525.9236653645835\n",
      "Train Epoch: 3769 [512/60000 (1%)] Loss: -1565.625732\n",
      "Train Epoch: 3769 [11776/60000 (20%)] Loss: -1536.511475\n",
      "Train Epoch: 3769 [23040/60000 (38%)] Loss: -1439.848633\n",
      "Train Epoch: 3769 [34304/60000 (57%)] Loss: -1514.678345\n",
      "Train Epoch: 3769 [45568/60000 (76%)] Loss: -1536.783447\n",
      "Train Epoch: 3769 [56832/60000 (95%)] Loss: -1593.750488\n",
      "    epoch          : 3769\n",
      "    loss           : -1525.2001170357742\n",
      "Train Epoch: 3770 [512/60000 (1%)] Loss: -1513.066895\n",
      "Train Epoch: 3770 [11776/60000 (20%)] Loss: -1564.211548\n",
      "Train Epoch: 3770 [23040/60000 (38%)] Loss: -1581.721313\n",
      "Train Epoch: 3770 [34304/60000 (57%)] Loss: -1514.436035\n",
      "Train Epoch: 3770 [45568/60000 (76%)] Loss: -1507.921753\n",
      "Train Epoch: 3770 [56832/60000 (95%)] Loss: -1561.427856\n",
      "    epoch          : 3770\n",
      "    loss           : -1529.3080627096576\n",
      "Train Epoch: 3771 [512/60000 (1%)] Loss: -1439.666748\n",
      "Train Epoch: 3771 [11776/60000 (20%)] Loss: -1514.979492\n",
      "Train Epoch: 3771 [23040/60000 (38%)] Loss: -1548.800537\n",
      "Train Epoch: 3771 [34304/60000 (57%)] Loss: -1622.848389\n",
      "Train Epoch: 3771 [45568/60000 (76%)] Loss: -1480.185303\n",
      "Train Epoch: 3771 [56832/60000 (95%)] Loss: -1527.916016\n",
      "    epoch          : 3771\n",
      "    loss           : -1525.5672441902807\n",
      "Train Epoch: 3772 [512/60000 (1%)] Loss: -1494.579590\n",
      "Train Epoch: 3772 [11776/60000 (20%)] Loss: -1540.310425\n",
      "Train Epoch: 3772 [23040/60000 (38%)] Loss: -1469.820679\n",
      "Train Epoch: 3772 [34304/60000 (57%)] Loss: -1522.089478\n",
      "Train Epoch: 3772 [45568/60000 (76%)] Loss: -1519.146606\n",
      "Train Epoch: 3772 [56832/60000 (95%)] Loss: -1530.195068\n",
      "    epoch          : 3772\n",
      "    loss           : -1525.0469105176333\n",
      "Train Epoch: 3773 [512/60000 (1%)] Loss: -1593.462158\n",
      "Train Epoch: 3773 [11776/60000 (20%)] Loss: -1445.466797\n",
      "Train Epoch: 3773 [23040/60000 (38%)] Loss: -1516.865234\n",
      "Train Epoch: 3773 [34304/60000 (57%)] Loss: -1415.740234\n",
      "Train Epoch: 3773 [45568/60000 (76%)] Loss: -1477.866821\n",
      "Train Epoch: 3773 [56832/60000 (95%)] Loss: -1547.541748\n",
      "    epoch          : 3773\n",
      "    loss           : -1520.8697868390273\n",
      "Train Epoch: 3774 [512/60000 (1%)] Loss: -1532.186035\n",
      "Train Epoch: 3774 [11776/60000 (20%)] Loss: -1544.786377\n",
      "Train Epoch: 3774 [23040/60000 (38%)] Loss: -1512.284180\n",
      "Train Epoch: 3774 [34304/60000 (57%)] Loss: -1580.126221\n",
      "Train Epoch: 3774 [45568/60000 (76%)] Loss: -1547.369507\n",
      "Train Epoch: 3774 [56832/60000 (95%)] Loss: -1575.234375\n",
      "    epoch          : 3774\n",
      "    loss           : -1525.3093396202992\n",
      "Train Epoch: 3775 [512/60000 (1%)] Loss: -1514.729492\n",
      "Train Epoch: 3775 [11776/60000 (20%)] Loss: -1533.945068\n",
      "Train Epoch: 3775 [23040/60000 (38%)] Loss: -1478.765869\n",
      "Train Epoch: 3775 [34304/60000 (57%)] Loss: -1508.667358\n",
      "Train Epoch: 3775 [45568/60000 (76%)] Loss: -1486.928223\n",
      "Train Epoch: 3775 [56832/60000 (95%)] Loss: -1499.701416\n",
      "    epoch          : 3775\n",
      "    loss           : -1520.4508584232653\n",
      "Train Epoch: 3776 [512/60000 (1%)] Loss: -1511.092041\n",
      "Train Epoch: 3776 [11776/60000 (20%)] Loss: -1532.790039\n",
      "Train Epoch: 3776 [23040/60000 (38%)] Loss: -1477.071777\n",
      "Train Epoch: 3776 [34304/60000 (57%)] Loss: -1554.628540\n",
      "Train Epoch: 3776 [45568/60000 (76%)] Loss: -1614.430908\n",
      "Train Epoch: 3776 [56832/60000 (95%)] Loss: -1485.050415\n",
      "    epoch          : 3776\n",
      "    loss           : -1523.9547346729344\n",
      "Train Epoch: 3777 [512/60000 (1%)] Loss: -1513.840210\n",
      "Train Epoch: 3777 [11776/60000 (20%)] Loss: -1610.978516\n",
      "Train Epoch: 3777 [23040/60000 (38%)] Loss: -1499.310059\n",
      "Train Epoch: 3777 [34304/60000 (57%)] Loss: -1489.127197\n",
      "Train Epoch: 3777 [45568/60000 (76%)] Loss: -1520.609619\n",
      "Train Epoch: 3777 [56832/60000 (95%)] Loss: -1521.178467\n",
      "    epoch          : 3777\n",
      "    loss           : -1532.1350325244969\n",
      "Train Epoch: 3778 [512/60000 (1%)] Loss: -1482.158325\n",
      "Train Epoch: 3778 [11776/60000 (20%)] Loss: -1582.786499\n",
      "Train Epoch: 3778 [23040/60000 (38%)] Loss: -1508.452881\n",
      "Train Epoch: 3778 [34304/60000 (57%)] Loss: -1516.786987\n",
      "Train Epoch: 3778 [45568/60000 (76%)] Loss: -1457.249268\n",
      "Train Epoch: 3778 [56832/60000 (95%)] Loss: -1540.111084\n",
      "    epoch          : 3778\n",
      "    loss           : -1524.8639619471662\n",
      "Train Epoch: 3779 [512/60000 (1%)] Loss: -1531.402832\n",
      "Train Epoch: 3779 [11776/60000 (20%)] Loss: -1453.874268\n",
      "Train Epoch: 3779 [23040/60000 (38%)] Loss: -1544.553955\n",
      "Train Epoch: 3779 [34304/60000 (57%)] Loss: -1568.869873\n",
      "Train Epoch: 3779 [45568/60000 (76%)] Loss: -1559.798828\n",
      "Train Epoch: 3779 [56832/60000 (95%)] Loss: -1570.567383\n",
      "    epoch          : 3779\n",
      "    loss           : -1537.5009734590176\n",
      "Train Epoch: 3780 [512/60000 (1%)] Loss: -1586.502441\n",
      "Train Epoch: 3780 [11776/60000 (20%)] Loss: -1606.879517\n",
      "Train Epoch: 3780 [23040/60000 (38%)] Loss: -1512.731323\n",
      "Train Epoch: 3780 [34304/60000 (57%)] Loss: -1561.172852\n",
      "Train Epoch: 3780 [45568/60000 (76%)] Loss: -1517.204712\n",
      "Train Epoch: 3780 [56832/60000 (95%)] Loss: -1546.738892\n",
      "    epoch          : 3780\n",
      "    loss           : -1519.559118238546\n",
      "Train Epoch: 3781 [512/60000 (1%)] Loss: -1435.159912\n",
      "Train Epoch: 3781 [11776/60000 (20%)] Loss: -1592.956299\n",
      "Train Epoch: 3781 [23040/60000 (38%)] Loss: -1487.889893\n",
      "Train Epoch: 3781 [34304/60000 (57%)] Loss: -1427.778931\n",
      "Train Epoch: 3781 [45568/60000 (76%)] Loss: -1551.515015\n",
      "Train Epoch: 3781 [56832/60000 (95%)] Loss: -1558.507080\n",
      "    epoch          : 3781\n",
      "    loss           : -1527.2306580624338\n",
      "Train Epoch: 3782 [512/60000 (1%)] Loss: -1553.260376\n",
      "Train Epoch: 3782 [11776/60000 (20%)] Loss: -1493.065674\n",
      "Train Epoch: 3782 [23040/60000 (38%)] Loss: -1535.685547\n",
      "Train Epoch: 3782 [34304/60000 (57%)] Loss: -1517.824951\n",
      "Train Epoch: 3782 [45568/60000 (76%)] Loss: -1527.389404\n",
      "Train Epoch: 3782 [56832/60000 (95%)] Loss: -1502.834473\n",
      "    epoch          : 3782\n",
      "    loss           : -1526.0270365052304\n",
      "Train Epoch: 3783 [512/60000 (1%)] Loss: -1494.206543\n",
      "Train Epoch: 3783 [11776/60000 (20%)] Loss: -1590.948486\n",
      "Train Epoch: 3783 [23040/60000 (38%)] Loss: -1554.772217\n",
      "Train Epoch: 3783 [34304/60000 (57%)] Loss: -1515.875000\n",
      "Train Epoch: 3783 [45568/60000 (76%)] Loss: -1504.633057\n",
      "Train Epoch: 3783 [56832/60000 (95%)] Loss: -1495.852661\n",
      "    epoch          : 3783\n",
      "    loss           : -1517.944662147996\n",
      "Train Epoch: 3784 [512/60000 (1%)] Loss: -1449.217773\n",
      "Train Epoch: 3784 [11776/60000 (20%)] Loss: -1568.160400\n",
      "Train Epoch: 3784 [23040/60000 (38%)] Loss: -1462.107910\n",
      "Train Epoch: 3784 [34304/60000 (57%)] Loss: -1537.357666\n",
      "Train Epoch: 3784 [45568/60000 (76%)] Loss: -1563.191040\n",
      "Train Epoch: 3784 [56832/60000 (95%)] Loss: -1525.679688\n",
      "    epoch          : 3784\n",
      "    loss           : -1522.4002751064838\n",
      "Train Epoch: 3785 [512/60000 (1%)] Loss: -1426.480469\n",
      "Train Epoch: 3785 [11776/60000 (20%)] Loss: -1550.675903\n",
      "Train Epoch: 3785 [23040/60000 (38%)] Loss: -1579.392334\n",
      "Train Epoch: 3785 [34304/60000 (57%)] Loss: -1529.902344\n",
      "Train Epoch: 3785 [45568/60000 (76%)] Loss: -1444.881836\n",
      "Train Epoch: 3785 [56832/60000 (95%)] Loss: -1513.636230\n",
      "    epoch          : 3785\n",
      "    loss           : -1524.0895816781428\n",
      "Train Epoch: 3786 [512/60000 (1%)] Loss: -1505.911133\n",
      "Train Epoch: 3786 [11776/60000 (20%)] Loss: -1498.678467\n",
      "Train Epoch: 3786 [23040/60000 (38%)] Loss: -1614.770020\n",
      "Train Epoch: 3786 [34304/60000 (57%)] Loss: -1550.315674\n",
      "Train Epoch: 3786 [45568/60000 (76%)] Loss: -1510.057007\n",
      "Train Epoch: 3786 [56832/60000 (95%)] Loss: -1537.094482\n",
      "    epoch          : 3786\n",
      "    loss           : -1525.996693066958\n",
      "Train Epoch: 3787 [512/60000 (1%)] Loss: -1469.275513\n",
      "Train Epoch: 3787 [11776/60000 (20%)] Loss: -1554.469238\n",
      "Train Epoch: 3787 [23040/60000 (38%)] Loss: -1509.896240\n",
      "Train Epoch: 3787 [34304/60000 (57%)] Loss: -1574.774780\n",
      "Train Epoch: 3787 [45568/60000 (76%)] Loss: -1563.514160\n",
      "Train Epoch: 3787 [56832/60000 (95%)] Loss: -1543.088379\n",
      "    epoch          : 3787\n",
      "    loss           : -1529.2945280775511\n",
      "Train Epoch: 3788 [512/60000 (1%)] Loss: -1559.199097\n",
      "Train Epoch: 3788 [11776/60000 (20%)] Loss: -1526.828003\n",
      "Train Epoch: 3788 [23040/60000 (38%)] Loss: -1487.266846\n",
      "Train Epoch: 3788 [34304/60000 (57%)] Loss: -1565.769043\n",
      "Train Epoch: 3788 [45568/60000 (76%)] Loss: -1531.734009\n",
      "Train Epoch: 3788 [56832/60000 (95%)] Loss: -1508.031006\n",
      "    epoch          : 3788\n",
      "    loss           : -1515.971769343662\n",
      "Train Epoch: 3789 [512/60000 (1%)] Loss: -1514.352295\n",
      "Train Epoch: 3789 [11776/60000 (20%)] Loss: -1572.569824\n",
      "Train Epoch: 3789 [23040/60000 (38%)] Loss: -1489.185425\n",
      "Train Epoch: 3789 [34304/60000 (57%)] Loss: -1596.477783\n",
      "Train Epoch: 3789 [45568/60000 (76%)] Loss: -1497.755127\n",
      "Train Epoch: 3789 [56832/60000 (95%)] Loss: -1443.590332\n",
      "    epoch          : 3789\n",
      "    loss           : -1520.1657011387713\n",
      "Train Epoch: 3790 [512/60000 (1%)] Loss: -1523.983154\n",
      "Train Epoch: 3790 [11776/60000 (20%)] Loss: -1503.639648\n",
      "Train Epoch: 3790 [23040/60000 (38%)] Loss: -1425.964600\n",
      "Train Epoch: 3790 [34304/60000 (57%)] Loss: -1506.131226\n",
      "Train Epoch: 3790 [45568/60000 (76%)] Loss: -1438.809082\n",
      "Train Epoch: 3790 [56832/60000 (95%)] Loss: -1553.921997\n",
      "    epoch          : 3790\n",
      "    loss           : -1516.1336097501767\n",
      "Train Epoch: 3791 [512/60000 (1%)] Loss: -1525.051758\n",
      "Train Epoch: 3791 [11776/60000 (20%)] Loss: -1561.965332\n",
      "Train Epoch: 3791 [23040/60000 (38%)] Loss: -1548.766846\n",
      "Train Epoch: 3791 [34304/60000 (57%)] Loss: -1575.288452\n",
      "Train Epoch: 3791 [45568/60000 (76%)] Loss: -1550.664917\n",
      "Train Epoch: 3791 [56832/60000 (95%)] Loss: -1577.566772\n",
      "    epoch          : 3791\n",
      "    loss           : -1524.4453131896628\n",
      "Train Epoch: 3792 [512/60000 (1%)] Loss: -1444.127197\n",
      "Train Epoch: 3792 [11776/60000 (20%)] Loss: -1468.614624\n",
      "Train Epoch: 3792 [23040/60000 (38%)] Loss: -1486.083496\n",
      "Train Epoch: 3792 [34304/60000 (57%)] Loss: -1573.340820\n",
      "Train Epoch: 3792 [45568/60000 (76%)] Loss: -1412.048584\n",
      "Train Epoch: 3792 [56832/60000 (95%)] Loss: -1486.161133\n",
      "    epoch          : 3792\n",
      "    loss           : -1527.3288815600722\n",
      "Train Epoch: 3793 [512/60000 (1%)] Loss: -1419.254639\n",
      "Train Epoch: 3793 [11776/60000 (20%)] Loss: -1530.470703\n",
      "Train Epoch: 3793 [23040/60000 (38%)] Loss: -1542.120239\n",
      "Train Epoch: 3793 [34304/60000 (57%)] Loss: -1527.841553\n",
      "Train Epoch: 3793 [45568/60000 (76%)] Loss: -1523.292358\n",
      "Train Epoch: 3793 [56832/60000 (95%)] Loss: -1537.208496\n",
      "    epoch          : 3793\n",
      "    loss           : -1517.5701752571063\n",
      "Train Epoch: 3794 [512/60000 (1%)] Loss: -1557.116943\n",
      "Train Epoch: 3794 [11776/60000 (20%)] Loss: -1603.593994\n",
      "Train Epoch: 3794 [23040/60000 (38%)] Loss: -1442.302124\n",
      "Train Epoch: 3794 [34304/60000 (57%)] Loss: -1554.619385\n",
      "Train Epoch: 3794 [45568/60000 (76%)] Loss: -1563.361450\n",
      "Train Epoch: 3794 [56832/60000 (95%)] Loss: -1521.078247\n",
      "    epoch          : 3794\n",
      "    loss           : -1523.386118398548\n",
      "Train Epoch: 3795 [512/60000 (1%)] Loss: -1522.058472\n",
      "Train Epoch: 3795 [11776/60000 (20%)] Loss: -1544.217285\n",
      "Train Epoch: 3795 [23040/60000 (38%)] Loss: -1577.490234\n",
      "Train Epoch: 3795 [34304/60000 (57%)] Loss: -1538.541260\n",
      "Train Epoch: 3795 [45568/60000 (76%)] Loss: -1552.074463\n",
      "Train Epoch: 3795 [56832/60000 (95%)] Loss: -1514.600586\n",
      "    epoch          : 3795\n",
      "    loss           : -1532.6371615135063\n",
      "Train Epoch: 3796 [512/60000 (1%)] Loss: -1602.635010\n",
      "Train Epoch: 3796 [11776/60000 (20%)] Loss: -1484.300293\n",
      "Train Epoch: 3796 [23040/60000 (38%)] Loss: -1559.792480\n",
      "Train Epoch: 3796 [34304/60000 (57%)] Loss: -1481.224854\n",
      "Train Epoch: 3796 [45568/60000 (76%)] Loss: -1574.706543\n",
      "Train Epoch: 3796 [56832/60000 (95%)] Loss: -1521.032471\n",
      "    epoch          : 3796\n",
      "    loss           : -1525.6172685353768\n",
      "Train Epoch: 3797 [512/60000 (1%)] Loss: -1558.631958\n",
      "Train Epoch: 3797 [11776/60000 (20%)] Loss: -1484.630127\n",
      "Train Epoch: 3797 [23040/60000 (38%)] Loss: -1520.422607\n",
      "Train Epoch: 3797 [34304/60000 (57%)] Loss: -1556.885620\n",
      "Train Epoch: 3797 [45568/60000 (76%)] Loss: -1464.112061\n",
      "Train Epoch: 3797 [56832/60000 (95%)] Loss: -1607.548828\n",
      "    epoch          : 3797\n",
      "    loss           : -1523.7418633584923\n",
      "Train Epoch: 3798 [512/60000 (1%)] Loss: -1513.734863\n",
      "Train Epoch: 3798 [11776/60000 (20%)] Loss: -1571.581421\n",
      "Train Epoch: 3798 [23040/60000 (38%)] Loss: -1571.146606\n",
      "Train Epoch: 3798 [34304/60000 (57%)] Loss: -1567.819336\n",
      "Train Epoch: 3798 [45568/60000 (76%)] Loss: -1502.727539\n",
      "Train Epoch: 3798 [56832/60000 (95%)] Loss: -1540.393311\n",
      "    epoch          : 3798\n",
      "    loss           : -1526.7136333918168\n",
      "Train Epoch: 3799 [512/60000 (1%)] Loss: -1551.642822\n",
      "Train Epoch: 3799 [11776/60000 (20%)] Loss: -1594.288574\n",
      "Train Epoch: 3799 [23040/60000 (38%)] Loss: -1534.225708\n",
      "Train Epoch: 3799 [34304/60000 (57%)] Loss: -1525.071777\n",
      "Train Epoch: 3799 [45568/60000 (76%)] Loss: -1471.492065\n",
      "Train Epoch: 3799 [56832/60000 (95%)] Loss: -1574.259033\n",
      "    epoch          : 3799\n",
      "    loss           : -1523.5161391436043\n",
      "Train Epoch: 3800 [512/60000 (1%)] Loss: -1537.057129\n",
      "Train Epoch: 3800 [11776/60000 (20%)] Loss: -1535.851685\n",
      "Train Epoch: 3800 [23040/60000 (38%)] Loss: -1468.511719\n",
      "Train Epoch: 3800 [34304/60000 (57%)] Loss: -1570.907471\n",
      "Train Epoch: 3800 [45568/60000 (76%)] Loss: -1602.474609\n",
      "Train Epoch: 3800 [56832/60000 (95%)] Loss: -1499.419067\n",
      "    epoch          : 3800\n",
      "    loss           : -1528.2937860003972\n",
      "Saving checkpoint: saved/models/Mnist_DeepGenerativeOperad/0127_111843/checkpoint-epoch3800.pth ...\n",
      "Train Epoch: 3801 [512/60000 (1%)] Loss: -1572.992188\n",
      "Train Epoch: 3801 [11776/60000 (20%)] Loss: -1538.327148\n",
      "Train Epoch: 3801 [23040/60000 (38%)] Loss: -1526.076294\n",
      "Train Epoch: 3801 [34304/60000 (57%)] Loss: -1555.145508\n",
      "Train Epoch: 3801 [45568/60000 (76%)] Loss: -1520.452148\n",
      "Train Epoch: 3801 [56832/60000 (95%)] Loss: -1572.027100\n",
      "    epoch          : 3801\n",
      "    loss           : -1531.5086942338673\n",
      "Train Epoch: 3802 [512/60000 (1%)] Loss: -1503.526367\n",
      "Train Epoch: 3802 [11776/60000 (20%)] Loss: -1505.975464\n",
      "Train Epoch: 3802 [23040/60000 (38%)] Loss: -1434.630615\n",
      "Train Epoch: 3802 [34304/60000 (57%)] Loss: -1422.931274\n",
      "Train Epoch: 3802 [45568/60000 (76%)] Loss: -1509.789307\n",
      "Train Epoch: 3802 [56832/60000 (95%)] Loss: -1543.294312\n",
      "    epoch          : 3802\n",
      "    loss           : -1518.6861723991437\n",
      "Train Epoch: 3803 [512/60000 (1%)] Loss: -1528.734619\n",
      "Train Epoch: 3803 [11776/60000 (20%)] Loss: -1500.217407\n",
      "Train Epoch: 3803 [23040/60000 (38%)] Loss: -1475.696777\n",
      "Train Epoch: 3803 [34304/60000 (57%)] Loss: -1547.195312\n",
      "Train Epoch: 3803 [45568/60000 (76%)] Loss: -1470.572876\n",
      "Train Epoch: 3803 [56832/60000 (95%)] Loss: -1537.902222\n",
      "    epoch          : 3803\n",
      "    loss           : -1526.1000542074946\n",
      "Train Epoch: 3804 [512/60000 (1%)] Loss: -1560.482178\n",
      "Train Epoch: 3804 [11776/60000 (20%)] Loss: -1411.199707\n",
      "Train Epoch: 3804 [23040/60000 (38%)] Loss: -1441.559082\n",
      "Train Epoch: 3804 [34304/60000 (57%)] Loss: -1575.128296\n",
      "Train Epoch: 3804 [45568/60000 (76%)] Loss: -1474.085693\n",
      "Train Epoch: 3804 [56832/60000 (95%)] Loss: -1582.872314\n",
      "    epoch          : 3804\n",
      "    loss           : -1526.5871575134622\n",
      "Train Epoch: 3805 [512/60000 (1%)] Loss: -1553.703979\n",
      "Train Epoch: 3805 [11776/60000 (20%)] Loss: -1510.914062\n",
      "Train Epoch: 3805 [23040/60000 (38%)] Loss: -1457.610229\n",
      "Train Epoch: 3805 [34304/60000 (57%)] Loss: -1427.127441\n",
      "Train Epoch: 3805 [45568/60000 (76%)] Loss: -1487.790527\n",
      "Train Epoch: 3805 [56832/60000 (95%)] Loss: -1533.489136\n",
      "    epoch          : 3805\n",
      "    loss           : -1516.61060191009\n",
      "Train Epoch: 3806 [512/60000 (1%)] Loss: -1572.269897\n",
      "Train Epoch: 3806 [11776/60000 (20%)] Loss: -1524.807739\n",
      "Train Epoch: 3806 [23040/60000 (38%)] Loss: -1509.444458\n",
      "Train Epoch: 3806 [34304/60000 (57%)] Loss: -1524.539062\n",
      "Train Epoch: 3806 [45568/60000 (76%)] Loss: -1538.532593\n",
      "Train Epoch: 3806 [56832/60000 (95%)] Loss: -1483.992798\n",
      "    epoch          : 3806\n",
      "    loss           : -1517.4069072486316\n",
      "Train Epoch: 3807 [512/60000 (1%)] Loss: -1581.579590\n",
      "Train Epoch: 3807 [11776/60000 (20%)] Loss: -1486.776978\n",
      "Train Epoch: 3807 [23040/60000 (38%)] Loss: -1496.384888\n",
      "Train Epoch: 3807 [34304/60000 (57%)] Loss: -1442.297974\n",
      "Train Epoch: 3807 [45568/60000 (76%)] Loss: -1489.710815\n",
      "Train Epoch: 3807 [56832/60000 (95%)] Loss: -1530.242554\n",
      "    epoch          : 3807\n",
      "    loss           : -1527.8055285437633\n",
      "Train Epoch: 3808 [512/60000 (1%)] Loss: -1530.751587\n",
      "Train Epoch: 3808 [11776/60000 (20%)] Loss: -1500.027100\n",
      "Train Epoch: 3808 [23040/60000 (38%)] Loss: -1551.255859\n",
      "Train Epoch: 3808 [34304/60000 (57%)] Loss: -1545.588379\n",
      "Train Epoch: 3808 [45568/60000 (76%)] Loss: -1579.619385\n",
      "Train Epoch: 3808 [56832/60000 (95%)] Loss: -1613.848389\n",
      "    epoch          : 3808\n",
      "    loss           : -1525.6173719847943\n",
      "Train Epoch: 3809 [512/60000 (1%)] Loss: -1561.257568\n",
      "Train Epoch: 3809 [11776/60000 (20%)] Loss: -1523.651611\n",
      "Train Epoch: 3809 [23040/60000 (38%)] Loss: -1593.149414\n",
      "Train Epoch: 3809 [34304/60000 (57%)] Loss: -1569.533081\n",
      "Train Epoch: 3809 [45568/60000 (76%)] Loss: -1526.996582\n",
      "Train Epoch: 3809 [56832/60000 (95%)] Loss: -1485.401001\n",
      "    epoch          : 3809\n",
      "    loss           : -1525.3939877957275\n",
      "Train Epoch: 3810 [512/60000 (1%)] Loss: -1501.765991\n",
      "Train Epoch: 3810 [11776/60000 (20%)] Loss: -1486.756348\n",
      "Train Epoch: 3810 [23040/60000 (38%)] Loss: -1587.825439\n",
      "Train Epoch: 3810 [34304/60000 (57%)] Loss: -1528.047607\n",
      "Train Epoch: 3810 [45568/60000 (76%)] Loss: -1539.446045\n",
      "Train Epoch: 3810 [56832/60000 (95%)] Loss: -1504.804932\n",
      "    epoch          : 3810\n",
      "    loss           : -1521.3798083289196\n",
      "Train Epoch: 3811 [512/60000 (1%)] Loss: -1503.529541\n",
      "Train Epoch: 3811 [11776/60000 (20%)] Loss: -1498.255127\n",
      "Train Epoch: 3811 [23040/60000 (38%)] Loss: -1492.558350\n",
      "Train Epoch: 3811 [34304/60000 (57%)] Loss: -1473.217285\n",
      "Train Epoch: 3811 [45568/60000 (76%)] Loss: -1514.328369\n",
      "Train Epoch: 3811 [56832/60000 (95%)] Loss: -1473.793945\n",
      "    epoch          : 3811\n",
      "    loss           : -1526.7328708454713\n",
      "Train Epoch: 3812 [512/60000 (1%)] Loss: -1477.704712\n",
      "Train Epoch: 3812 [11776/60000 (20%)] Loss: -1510.010986\n",
      "Train Epoch: 3812 [23040/60000 (38%)] Loss: -1502.484985\n",
      "Train Epoch: 3812 [34304/60000 (57%)] Loss: -1546.118408\n",
      "Train Epoch: 3812 [45568/60000 (76%)] Loss: -1518.391479\n",
      "Train Epoch: 3812 [56832/60000 (95%)] Loss: -1599.901001\n",
      "    epoch          : 3812\n",
      "    loss           : -1520.3282550014346\n",
      "Train Epoch: 3813 [512/60000 (1%)] Loss: -1581.688477\n",
      "Train Epoch: 3813 [11776/60000 (20%)] Loss: -1580.266724\n",
      "Train Epoch: 3813 [23040/60000 (38%)] Loss: -1577.368286\n",
      "Train Epoch: 3813 [34304/60000 (57%)] Loss: -1503.956787\n",
      "Train Epoch: 3813 [45568/60000 (76%)] Loss: -1544.781006\n",
      "Train Epoch: 3813 [56832/60000 (95%)] Loss: -1584.533936\n",
      "    epoch          : 3813\n",
      "    loss           : -1530.920882575256\n",
      "Train Epoch: 3814 [512/60000 (1%)] Loss: -1537.703125\n",
      "Train Epoch: 3814 [11776/60000 (20%)] Loss: -1431.473877\n",
      "Train Epoch: 3814 [23040/60000 (38%)] Loss: -1524.624268\n",
      "Train Epoch: 3814 [34304/60000 (57%)] Loss: -1496.886963\n",
      "Train Epoch: 3814 [45568/60000 (76%)] Loss: -1552.986694\n",
      "Train Epoch: 3814 [56832/60000 (95%)] Loss: -1529.898560\n",
      "    epoch          : 3814\n",
      "    loss           : -1519.9808508231815\n",
      "Train Epoch: 3815 [512/60000 (1%)] Loss: -1497.475708\n",
      "Train Epoch: 3815 [11776/60000 (20%)] Loss: -1555.727783\n",
      "Train Epoch: 3815 [23040/60000 (38%)] Loss: -1499.432373\n",
      "Train Epoch: 3815 [34304/60000 (57%)] Loss: -1549.999390\n",
      "Train Epoch: 3815 [45568/60000 (76%)] Loss: -1548.788208\n",
      "Train Epoch: 3815 [56832/60000 (95%)] Loss: -1428.631348\n",
      "    epoch          : 3815\n",
      "    loss           : -1523.067441778668\n",
      "Train Epoch: 3816 [512/60000 (1%)] Loss: -1483.056763\n",
      "Train Epoch: 3816 [11776/60000 (20%)] Loss: -1546.113037\n",
      "Train Epoch: 3816 [23040/60000 (38%)] Loss: -1478.350830\n",
      "Train Epoch: 3816 [34304/60000 (57%)] Loss: -1578.486816\n",
      "Train Epoch: 3816 [45568/60000 (76%)] Loss: -1508.011963\n",
      "Train Epoch: 3816 [56832/60000 (95%)] Loss: -1521.248413\n",
      "    epoch          : 3816\n",
      "    loss           : -1523.4965782381046\n",
      "Train Epoch: 3817 [512/60000 (1%)] Loss: -1545.673096\n",
      "Train Epoch: 3817 [11776/60000 (20%)] Loss: -1496.645142\n",
      "Train Epoch: 3817 [23040/60000 (38%)] Loss: -1457.953003\n",
      "Train Epoch: 3817 [34304/60000 (57%)] Loss: -1553.370605\n",
      "Train Epoch: 3817 [45568/60000 (76%)] Loss: -1480.406494\n",
      "Train Epoch: 3817 [56832/60000 (95%)] Loss: -1521.900513\n",
      "    epoch          : 3817\n",
      "    loss           : -1525.2445175257105\n",
      "Train Epoch: 3818 [512/60000 (1%)] Loss: -1545.113525\n",
      "Train Epoch: 3818 [11776/60000 (20%)] Loss: -1544.879517\n",
      "Train Epoch: 3818 [23040/60000 (38%)] Loss: -1579.980225\n",
      "Train Epoch: 3818 [34304/60000 (57%)] Loss: -1507.083496\n",
      "Train Epoch: 3818 [45568/60000 (76%)] Loss: -1551.698853\n",
      "Train Epoch: 3818 [56832/60000 (95%)] Loss: -1470.258667\n",
      "    epoch          : 3818\n",
      "    loss           : -1531.8680478543213\n",
      "Train Epoch: 3819 [512/60000 (1%)] Loss: -1523.967041\n",
      "Train Epoch: 3819 [11776/60000 (20%)] Loss: -1552.093506\n",
      "Train Epoch: 3819 [23040/60000 (38%)] Loss: -1498.742065\n",
      "Train Epoch: 3819 [34304/60000 (57%)] Loss: -1537.457642\n",
      "Train Epoch: 3819 [45568/60000 (76%)] Loss: -1519.852783\n",
      "Train Epoch: 3819 [56832/60000 (95%)] Loss: -1480.356323\n",
      "    epoch          : 3819\n",
      "    loss           : -1528.724194198005\n",
      "Train Epoch: 3820 [512/60000 (1%)] Loss: -1542.671753\n",
      "Train Epoch: 3820 [11776/60000 (20%)] Loss: -1533.008667\n",
      "Train Epoch: 3820 [23040/60000 (38%)] Loss: -1601.535278\n",
      "Train Epoch: 3820 [34304/60000 (57%)] Loss: -1518.874268\n",
      "Train Epoch: 3820 [45568/60000 (76%)] Loss: -1593.157959\n",
      "Train Epoch: 3820 [56832/60000 (95%)] Loss: -1498.421387\n",
      "    epoch          : 3820\n",
      "    loss           : -1518.6546448098736\n",
      "Train Epoch: 3821 [512/60000 (1%)] Loss: -1528.416016\n",
      "Train Epoch: 3821 [11776/60000 (20%)] Loss: -1469.084717\n",
      "Train Epoch: 3821 [23040/60000 (38%)] Loss: -1512.927002\n",
      "Train Epoch: 3821 [34304/60000 (57%)] Loss: -1487.553711\n",
      "Train Epoch: 3821 [45568/60000 (76%)] Loss: -1578.553467\n",
      "Train Epoch: 3821 [56832/60000 (95%)] Loss: -1541.234619\n",
      "    epoch          : 3821\n",
      "    loss           : -1525.6950231864628\n",
      "Train Epoch: 3822 [512/60000 (1%)] Loss: -1575.873779\n",
      "Train Epoch: 3822 [11776/60000 (20%)] Loss: -1547.924683\n",
      "Train Epoch: 3822 [23040/60000 (38%)] Loss: -1498.463867\n",
      "Train Epoch: 3822 [34304/60000 (57%)] Loss: -1556.869751\n",
      "Train Epoch: 3822 [45568/60000 (76%)] Loss: -1477.051270\n",
      "Train Epoch: 3822 [56832/60000 (95%)] Loss: -1550.460449\n",
      "    epoch          : 3822\n",
      "    loss           : -1528.7404157563117\n",
      "Train Epoch: 3823 [512/60000 (1%)] Loss: -1535.268921\n",
      "Train Epoch: 3823 [11776/60000 (20%)] Loss: -1570.853760\n",
      "Train Epoch: 3823 [23040/60000 (38%)] Loss: -1495.136841\n",
      "Train Epoch: 3823 [34304/60000 (57%)] Loss: -1446.858887\n",
      "Train Epoch: 3823 [45568/60000 (76%)] Loss: -1564.641724\n",
      "Train Epoch: 3823 [56832/60000 (95%)] Loss: -1583.304199\n",
      "    epoch          : 3823\n",
      "    loss           : -1524.9897536800406\n",
      "Train Epoch: 3824 [512/60000 (1%)] Loss: -1546.561157\n",
      "Train Epoch: 3824 [11776/60000 (20%)] Loss: -1591.920654\n",
      "Train Epoch: 3824 [23040/60000 (38%)] Loss: -1492.736450\n",
      "Train Epoch: 3824 [34304/60000 (57%)] Loss: -1497.800659\n",
      "Train Epoch: 3824 [45568/60000 (76%)] Loss: -1519.840454\n",
      "Train Epoch: 3824 [56832/60000 (95%)] Loss: -1547.037231\n",
      "    epoch          : 3824\n",
      "    loss           : -1536.0879992468883\n",
      "Train Epoch: 3825 [512/60000 (1%)] Loss: -1471.678467\n",
      "Train Epoch: 3825 [11776/60000 (20%)] Loss: -1527.803223\n",
      "Train Epoch: 3825 [23040/60000 (38%)] Loss: -1587.894775\n",
      "Train Epoch: 3825 [34304/60000 (57%)] Loss: -1439.623291\n",
      "Train Epoch: 3825 [45568/60000 (76%)] Loss: -1581.239380\n",
      "Train Epoch: 3825 [56832/60000 (95%)] Loss: -1567.079956\n",
      "    epoch          : 3825\n",
      "    loss           : -1533.4148325084966\n",
      "Train Epoch: 3826 [512/60000 (1%)] Loss: -1473.338135\n",
      "Train Epoch: 3826 [11776/60000 (20%)] Loss: -1474.259521\n",
      "Train Epoch: 3826 [23040/60000 (38%)] Loss: -1563.641724\n",
      "Train Epoch: 3826 [34304/60000 (57%)] Loss: -1566.204712\n",
      "Train Epoch: 3826 [45568/60000 (76%)] Loss: -1543.433228\n",
      "Train Epoch: 3826 [56832/60000 (95%)] Loss: -1472.332764\n",
      "    epoch          : 3826\n",
      "    loss           : -1524.2775061655852\n",
      "Train Epoch: 3827 [512/60000 (1%)] Loss: -1508.908691\n",
      "Train Epoch: 3827 [11776/60000 (20%)] Loss: -1506.135254\n",
      "Train Epoch: 3827 [23040/60000 (38%)] Loss: -1537.928955\n",
      "Train Epoch: 3827 [34304/60000 (57%)] Loss: -1577.172363\n",
      "Train Epoch: 3827 [45568/60000 (76%)] Loss: -1528.601929\n",
      "Train Epoch: 3827 [56832/60000 (95%)] Loss: -1588.320801\n",
      "    epoch          : 3827\n",
      "    loss           : -1524.0939927612994\n",
      "Train Epoch: 3828 [512/60000 (1%)] Loss: -1461.297852\n",
      "Train Epoch: 3828 [11776/60000 (20%)] Loss: -1469.810059\n",
      "Train Epoch: 3828 [23040/60000 (38%)] Loss: -1582.900879\n",
      "Train Epoch: 3828 [34304/60000 (57%)] Loss: -1432.211182\n",
      "Train Epoch: 3828 [45568/60000 (76%)] Loss: -1544.378052\n",
      "Train Epoch: 3828 [56832/60000 (95%)] Loss: -1537.744385\n",
      "    epoch          : 3828\n",
      "    loss           : -1520.4386796681893\n",
      "Train Epoch: 3829 [512/60000 (1%)] Loss: -1523.854736\n",
      "Train Epoch: 3829 [11776/60000 (20%)] Loss: -1532.041992\n",
      "Train Epoch: 3829 [23040/60000 (38%)] Loss: -1526.814453\n",
      "Train Epoch: 3829 [34304/60000 (57%)] Loss: -1596.942505\n",
      "Train Epoch: 3829 [45568/60000 (76%)] Loss: -1493.465088\n",
      "Train Epoch: 3829 [56832/60000 (95%)] Loss: -1493.816895\n",
      "    epoch          : 3829\n",
      "    loss           : -1531.6345163119042\n",
      "Train Epoch: 3830 [512/60000 (1%)] Loss: -1479.399048\n",
      "Train Epoch: 3830 [11776/60000 (20%)] Loss: -1552.831909\n",
      "Train Epoch: 3830 [23040/60000 (38%)] Loss: -1502.154541\n",
      "Train Epoch: 3830 [34304/60000 (57%)] Loss: -1539.801758\n",
      "Train Epoch: 3830 [45568/60000 (76%)] Loss: -1600.788330\n",
      "Train Epoch: 3830 [56832/60000 (95%)] Loss: -1590.033447\n",
      "    epoch          : 3830\n",
      "    loss           : -1529.0530995514434\n",
      "Train Epoch: 3831 [512/60000 (1%)] Loss: -1533.549927\n",
      "Train Epoch: 3831 [11776/60000 (20%)] Loss: -1529.842407\n",
      "Train Epoch: 3831 [23040/60000 (38%)] Loss: -1565.520386\n",
      "Train Epoch: 3831 [34304/60000 (57%)] Loss: -1562.252441\n",
      "Train Epoch: 3831 [45568/60000 (76%)] Loss: -1601.724487\n",
      "Train Epoch: 3831 [56832/60000 (95%)] Loss: -1450.213623\n",
      "    epoch          : 3831\n",
      "    loss           : -1518.700107035664\n",
      "Train Epoch: 3832 [512/60000 (1%)] Loss: -1554.255371\n",
      "Train Epoch: 3832 [11776/60000 (20%)] Loss: -1519.238281\n",
      "Train Epoch: 3832 [23040/60000 (38%)] Loss: -1536.030640\n",
      "Train Epoch: 3832 [34304/60000 (57%)] Loss: -1554.040283\n",
      "Train Epoch: 3832 [45568/60000 (76%)] Loss: -1518.432373\n",
      "Train Epoch: 3832 [56832/60000 (95%)] Loss: -1545.942261\n",
      "    epoch          : 3832\n",
      "    loss           : -1528.0516074660136\n",
      "Train Epoch: 3833 [512/60000 (1%)] Loss: -1523.717773\n",
      "Train Epoch: 3833 [11776/60000 (20%)] Loss: -1460.436523\n",
      "Train Epoch: 3833 [23040/60000 (38%)] Loss: -1567.862305\n",
      "Train Epoch: 3833 [34304/60000 (57%)] Loss: -1537.201416\n",
      "Train Epoch: 3833 [45568/60000 (76%)] Loss: -1521.100464\n",
      "Train Epoch: 3833 [56832/60000 (95%)] Loss: -1542.034424\n",
      "    epoch          : 3833\n",
      "    loss           : -1527.455048124669\n",
      "Train Epoch: 3834 [512/60000 (1%)] Loss: -1578.427368\n",
      "Train Epoch: 3834 [11776/60000 (20%)] Loss: -1499.343506\n",
      "Train Epoch: 3834 [23040/60000 (38%)] Loss: -1517.687012\n",
      "Train Epoch: 3834 [34304/60000 (57%)] Loss: -1544.520142\n",
      "Train Epoch: 3834 [45568/60000 (76%)] Loss: -1421.758423\n",
      "Train Epoch: 3834 [56832/60000 (95%)] Loss: -1445.919189\n",
      "    epoch          : 3834\n",
      "    loss           : -1517.8150079587085\n",
      "Train Epoch: 3835 [512/60000 (1%)] Loss: -1535.917114\n",
      "Train Epoch: 3835 [11776/60000 (20%)] Loss: -1471.834595\n",
      "Train Epoch: 3835 [23040/60000 (38%)] Loss: -1564.967773\n",
      "Train Epoch: 3835 [34304/60000 (57%)] Loss: -1524.166016\n",
      "Train Epoch: 3835 [45568/60000 (76%)] Loss: -1540.588257\n",
      "Train Epoch: 3835 [56832/60000 (95%)] Loss: -1553.124023\n",
      "    epoch          : 3835\n",
      "    loss           : -1520.4117007498014\n",
      "Train Epoch: 3836 [512/60000 (1%)] Loss: -1565.685181\n",
      "Train Epoch: 3836 [11776/60000 (20%)] Loss: -1465.205811\n",
      "Train Epoch: 3836 [23040/60000 (38%)] Loss: -1531.707764\n",
      "Train Epoch: 3836 [34304/60000 (57%)] Loss: -1521.554688\n",
      "Train Epoch: 3836 [45568/60000 (76%)] Loss: -1557.975342\n",
      "Train Epoch: 3836 [56832/60000 (95%)] Loss: -1555.835938\n",
      "    epoch          : 3836\n",
      "    loss           : -1528.3869784080375\n",
      "Train Epoch: 3837 [512/60000 (1%)] Loss: -1500.589355\n",
      "Train Epoch: 3837 [11776/60000 (20%)] Loss: -1519.919556\n",
      "Train Epoch: 3837 [23040/60000 (38%)] Loss: -1527.711304\n",
      "Train Epoch: 3837 [34304/60000 (57%)] Loss: -1490.930298\n",
      "Train Epoch: 3837 [45568/60000 (76%)] Loss: -1592.562500\n",
      "Train Epoch: 3837 [56832/60000 (95%)] Loss: -1572.112915\n",
      "    epoch          : 3837\n",
      "    loss           : -1524.1301197116659\n",
      "Train Epoch: 3838 [512/60000 (1%)] Loss: -1515.852051\n",
      "Train Epoch: 3838 [11776/60000 (20%)] Loss: -1472.152710\n",
      "Train Epoch: 3838 [23040/60000 (38%)] Loss: -1539.588013\n",
      "Train Epoch: 3838 [34304/60000 (57%)] Loss: -1610.963379\n",
      "Train Epoch: 3838 [45568/60000 (76%)] Loss: -1561.763184\n",
      "Train Epoch: 3838 [56832/60000 (95%)] Loss: -1532.078857\n",
      "    epoch          : 3838\n",
      "    loss           : -1525.9662527310645\n",
      "Train Epoch: 3839 [512/60000 (1%)] Loss: -1526.559326\n",
      "Train Epoch: 3839 [11776/60000 (20%)] Loss: -1541.018066\n",
      "Train Epoch: 3839 [23040/60000 (38%)] Loss: -1570.247803\n",
      "Train Epoch: 3839 [34304/60000 (57%)] Loss: -1479.503174\n",
      "Train Epoch: 3839 [45568/60000 (76%)] Loss: -1520.979370\n",
      "Train Epoch: 3839 [56832/60000 (95%)] Loss: -1497.554932\n",
      "    epoch          : 3839\n",
      "    loss           : -1525.650224071438\n",
      "Train Epoch: 3840 [512/60000 (1%)] Loss: -1452.457031\n",
      "Train Epoch: 3840 [11776/60000 (20%)] Loss: -1480.178833\n",
      "Train Epoch: 3840 [23040/60000 (38%)] Loss: -1565.919922\n",
      "Train Epoch: 3840 [34304/60000 (57%)] Loss: -1542.163086\n",
      "Train Epoch: 3840 [45568/60000 (76%)] Loss: -1565.397705\n",
      "Train Epoch: 3840 [56832/60000 (95%)] Loss: -1499.408203\n",
      "    epoch          : 3840\n",
      "    loss           : -1522.5717814817267\n",
      "Train Epoch: 3841 [512/60000 (1%)] Loss: -1531.686768\n",
      "Train Epoch: 3841 [11776/60000 (20%)] Loss: -1559.421143\n",
      "Train Epoch: 3841 [23040/60000 (38%)] Loss: -1568.051270\n",
      "Train Epoch: 3841 [34304/60000 (57%)] Loss: -1504.582153\n",
      "Train Epoch: 3841 [45568/60000 (76%)] Loss: -1576.851807\n",
      "Train Epoch: 3841 [56832/60000 (95%)] Loss: -1505.757568\n",
      "    epoch          : 3841\n",
      "    loss           : -1522.388892222259\n",
      "Train Epoch: 3842 [512/60000 (1%)] Loss: -1506.449097\n",
      "Train Epoch: 3842 [11776/60000 (20%)] Loss: -1534.802856\n",
      "Train Epoch: 3842 [23040/60000 (38%)] Loss: -1544.220947\n",
      "Train Epoch: 3842 [34304/60000 (57%)] Loss: -1476.098877\n",
      "Train Epoch: 3842 [45568/60000 (76%)] Loss: -1524.028198\n",
      "Train Epoch: 3842 [56832/60000 (95%)] Loss: -1547.980957\n",
      "    epoch          : 3842\n",
      "    loss           : -1527.1039401124426\n",
      "Train Epoch: 3843 [512/60000 (1%)] Loss: -1538.621582\n",
      "Train Epoch: 3843 [11776/60000 (20%)] Loss: -1535.105469\n",
      "Train Epoch: 3843 [23040/60000 (38%)] Loss: -1490.097290\n",
      "Train Epoch: 3843 [34304/60000 (57%)] Loss: -1559.177490\n",
      "Train Epoch: 3843 [45568/60000 (76%)] Loss: -1535.343750\n",
      "Train Epoch: 3843 [56832/60000 (95%)] Loss: -1513.455933\n",
      "    epoch          : 3843\n",
      "    loss           : -1528.7996895138153\n",
      "Train Epoch: 3844 [512/60000 (1%)] Loss: -1588.765137\n",
      "Train Epoch: 3844 [11776/60000 (20%)] Loss: -1554.269653\n",
      "Train Epoch: 3844 [23040/60000 (38%)] Loss: -1411.759521\n",
      "Train Epoch: 3844 [34304/60000 (57%)] Loss: -1511.079956\n",
      "Train Epoch: 3844 [45568/60000 (76%)] Loss: -1546.792114\n",
      "Train Epoch: 3844 [56832/60000 (95%)] Loss: -1495.074463\n",
      "    epoch          : 3844\n",
      "    loss           : -1525.614471952794\n",
      "Train Epoch: 3845 [512/60000 (1%)] Loss: -1525.054810\n",
      "Train Epoch: 3845 [11776/60000 (20%)] Loss: -1511.503418\n",
      "Train Epoch: 3845 [23040/60000 (38%)] Loss: -1503.674927\n",
      "Train Epoch: 3845 [34304/60000 (57%)] Loss: -1551.801270\n",
      "Train Epoch: 3845 [45568/60000 (76%)] Loss: -1585.946533\n",
      "Train Epoch: 3845 [56832/60000 (95%)] Loss: -1555.484253\n",
      "    epoch          : 3845\n",
      "    loss           : -1523.662223169359\n",
      "Train Epoch: 3846 [512/60000 (1%)] Loss: -1558.162842\n",
      "Train Epoch: 3846 [11776/60000 (20%)] Loss: -1525.033813\n",
      "Train Epoch: 3846 [23040/60000 (38%)] Loss: -1441.474365\n",
      "Train Epoch: 3846 [34304/60000 (57%)] Loss: -1572.408203\n",
      "Train Epoch: 3846 [45568/60000 (76%)] Loss: -1495.441406\n",
      "Train Epoch: 3846 [56832/60000 (95%)] Loss: -1557.236694\n",
      "    epoch          : 3846\n",
      "    loss           : -1521.1363728841147\n",
      "Train Epoch: 3847 [512/60000 (1%)] Loss: -1530.637695\n",
      "Train Epoch: 3847 [11776/60000 (20%)] Loss: -1543.157227\n",
      "Train Epoch: 3847 [23040/60000 (38%)] Loss: -1444.539673\n",
      "Train Epoch: 3847 [34304/60000 (57%)] Loss: -1518.212524\n",
      "Train Epoch: 3847 [45568/60000 (76%)] Loss: -1546.186768\n",
      "Train Epoch: 3847 [56832/60000 (95%)] Loss: -1537.840454\n",
      "    epoch          : 3847\n",
      "    loss           : -1532.4889650506489\n",
      "Train Epoch: 3848 [512/60000 (1%)] Loss: -1534.205566\n",
      "Train Epoch: 3848 [11776/60000 (20%)] Loss: -1577.305664\n",
      "Train Epoch: 3848 [23040/60000 (38%)] Loss: -1533.307373\n",
      "Train Epoch: 3848 [34304/60000 (57%)] Loss: -1479.837646\n",
      "Train Epoch: 3848 [45568/60000 (76%)] Loss: -1432.433472\n",
      "Train Epoch: 3848 [56832/60000 (95%)] Loss: -1596.678101\n",
      "    epoch          : 3848\n",
      "    loss           : -1524.7616321973208\n",
      "Train Epoch: 3849 [512/60000 (1%)] Loss: -1497.837891\n",
      "Train Epoch: 3849 [11776/60000 (20%)] Loss: -1508.286621\n",
      "Train Epoch: 3849 [23040/60000 (38%)] Loss: -1566.551880\n",
      "Train Epoch: 3849 [34304/60000 (57%)] Loss: -1533.044678\n",
      "Train Epoch: 3849 [45568/60000 (76%)] Loss: -1477.949951\n",
      "Train Epoch: 3849 [56832/60000 (95%)] Loss: -1454.319824\n",
      "    epoch          : 3849\n",
      "    loss           : -1526.5000586213366\n",
      "Train Epoch: 3850 [512/60000 (1%)] Loss: -1518.243896\n",
      "Train Epoch: 3850 [11776/60000 (20%)] Loss: -1485.184204\n",
      "Train Epoch: 3850 [23040/60000 (38%)] Loss: -1521.725220\n",
      "Train Epoch: 3850 [34304/60000 (57%)] Loss: -1602.969238\n",
      "Train Epoch: 3850 [45568/60000 (76%)] Loss: -1560.362915\n",
      "Train Epoch: 3850 [56832/60000 (95%)] Loss: -1583.388672\n",
      "    epoch          : 3850\n",
      "    loss           : -1532.271316097281\n",
      "Train Epoch: 3851 [512/60000 (1%)] Loss: -1516.132446\n",
      "Train Epoch: 3851 [11776/60000 (20%)] Loss: -1541.834839\n",
      "Train Epoch: 3851 [23040/60000 (38%)] Loss: -1571.564941\n",
      "Train Epoch: 3851 [34304/60000 (57%)] Loss: -1559.978394\n",
      "Train Epoch: 3851 [45568/60000 (76%)] Loss: -1497.751343\n",
      "Train Epoch: 3851 [56832/60000 (95%)] Loss: -1605.343262\n",
      "    epoch          : 3851\n",
      "    loss           : -1526.2487365377826\n",
      "Train Epoch: 3852 [512/60000 (1%)] Loss: -1607.028687\n",
      "Train Epoch: 3852 [11776/60000 (20%)] Loss: -1603.288330\n",
      "Train Epoch: 3852 [23040/60000 (38%)] Loss: -1515.063354\n",
      "Train Epoch: 3852 [34304/60000 (57%)] Loss: -1492.842163\n",
      "Train Epoch: 3852 [45568/60000 (76%)] Loss: -1557.753906\n",
      "Train Epoch: 3852 [56832/60000 (95%)] Loss: -1607.636719\n",
      "    epoch          : 3852\n",
      "    loss           : -1524.312179996469\n",
      "Train Epoch: 3853 [512/60000 (1%)] Loss: -1546.686279\n",
      "Train Epoch: 3853 [11776/60000 (20%)] Loss: -1492.242676\n",
      "Train Epoch: 3853 [23040/60000 (38%)] Loss: -1558.672363\n",
      "Train Epoch: 3853 [34304/60000 (57%)] Loss: -1473.484985\n",
      "Train Epoch: 3853 [45568/60000 (76%)] Loss: -1546.128418\n",
      "Train Epoch: 3853 [56832/60000 (95%)] Loss: -1588.379517\n",
      "    epoch          : 3853\n",
      "    loss           : -1525.2672253624867\n",
      "Train Epoch: 3854 [512/60000 (1%)] Loss: -1598.037842\n",
      "Train Epoch: 3854 [11776/60000 (20%)] Loss: -1501.980347\n",
      "Train Epoch: 3854 [23040/60000 (38%)] Loss: -1537.219238\n",
      "Train Epoch: 3854 [34304/60000 (57%)] Loss: -1487.327026\n",
      "Train Epoch: 3854 [45568/60000 (76%)] Loss: -1561.225586\n",
      "Train Epoch: 3854 [56832/60000 (95%)] Loss: -1491.221924\n",
      "    epoch          : 3854\n",
      "    loss           : -1526.1279900329935\n",
      "Train Epoch: 3855 [512/60000 (1%)] Loss: -1592.977783\n",
      "Train Epoch: 3855 [11776/60000 (20%)] Loss: -1539.177734\n",
      "Train Epoch: 3855 [23040/60000 (38%)] Loss: -1579.218872\n",
      "Train Epoch: 3855 [34304/60000 (57%)] Loss: -1415.129150\n",
      "Train Epoch: 3855 [45568/60000 (76%)] Loss: -1554.799072\n",
      "Train Epoch: 3855 [56832/60000 (95%)] Loss: -1431.568115\n",
      "    epoch          : 3855\n",
      "    loss           : -1526.4685851705951\n",
      "Train Epoch: 3856 [512/60000 (1%)] Loss: -1536.355103\n",
      "Train Epoch: 3856 [11776/60000 (20%)] Loss: -1554.767822\n",
      "Train Epoch: 3856 [23040/60000 (38%)] Loss: -1580.522705\n",
      "Train Epoch: 3856 [34304/60000 (57%)] Loss: -1583.833130\n",
      "Train Epoch: 3856 [45568/60000 (76%)] Loss: -1605.653320\n",
      "Train Epoch: 3856 [56832/60000 (95%)] Loss: -1470.587402\n",
      "    epoch          : 3856\n",
      "    loss           : -1525.1725074207714\n",
      "Train Epoch: 3857 [512/60000 (1%)] Loss: -1582.207031\n",
      "Train Epoch: 3857 [11776/60000 (20%)] Loss: -1585.502686\n",
      "Train Epoch: 3857 [23040/60000 (38%)] Loss: -1553.073486\n",
      "Train Epoch: 3857 [34304/60000 (57%)] Loss: -1537.659912\n",
      "Train Epoch: 3857 [45568/60000 (76%)] Loss: -1481.919922\n",
      "Train Epoch: 3857 [56832/60000 (95%)] Loss: -1586.156372\n",
      "    epoch          : 3857\n",
      "    loss           : -1529.2662812141375\n",
      "Train Epoch: 3858 [512/60000 (1%)] Loss: -1510.580444\n",
      "Train Epoch: 3858 [11776/60000 (20%)] Loss: -1484.014893\n",
      "Train Epoch: 3858 [23040/60000 (38%)] Loss: -1569.052612\n",
      "Train Epoch: 3858 [34304/60000 (57%)] Loss: -1538.653931\n",
      "Train Epoch: 3858 [45568/60000 (76%)] Loss: -1485.193848\n",
      "Train Epoch: 3858 [56832/60000 (95%)] Loss: -1512.420532\n",
      "    epoch          : 3858\n",
      "    loss           : -1528.6687573793918\n",
      "Train Epoch: 3859 [512/60000 (1%)] Loss: -1546.250000\n",
      "Train Epoch: 3859 [11776/60000 (20%)] Loss: -1588.890747\n",
      "Train Epoch: 3859 [23040/60000 (38%)] Loss: -1537.622437\n",
      "Train Epoch: 3859 [34304/60000 (57%)] Loss: -1555.977051\n",
      "Train Epoch: 3859 [45568/60000 (76%)] Loss: -1506.961060\n",
      "Train Epoch: 3859 [56832/60000 (95%)] Loss: -1485.647461\n",
      "    epoch          : 3859\n",
      "    loss           : -1537.216333076779\n",
      "Train Epoch: 3860 [512/60000 (1%)] Loss: -1552.996460\n",
      "Train Epoch: 3860 [11776/60000 (20%)] Loss: -1534.307861\n",
      "Train Epoch: 3860 [23040/60000 (38%)] Loss: -1548.656372\n",
      "Train Epoch: 3860 [34304/60000 (57%)] Loss: -1569.148926\n",
      "Train Epoch: 3860 [45568/60000 (76%)] Loss: -1522.714478\n",
      "Train Epoch: 3860 [56832/60000 (95%)] Loss: -1578.982788\n",
      "    epoch          : 3860\n",
      "    loss           : -1531.9154735500529\n",
      "Train Epoch: 3861 [512/60000 (1%)] Loss: -1538.318848\n",
      "Train Epoch: 3861 [11776/60000 (20%)] Loss: -1617.088623\n",
      "Train Epoch: 3861 [23040/60000 (38%)] Loss: -1563.575195\n",
      "Train Epoch: 3861 [34304/60000 (57%)] Loss: -1536.775391\n",
      "Train Epoch: 3861 [45568/60000 (76%)] Loss: -1530.050415\n",
      "Train Epoch: 3861 [56832/60000 (95%)] Loss: -1487.720337\n",
      "    epoch          : 3861\n",
      "    loss           : -1523.5147139554642\n",
      "Train Epoch: 3862 [512/60000 (1%)] Loss: -1472.903076\n",
      "Train Epoch: 3862 [11776/60000 (20%)] Loss: -1534.243896\n",
      "Train Epoch: 3862 [23040/60000 (38%)] Loss: -1423.109131\n",
      "Train Epoch: 3862 [34304/60000 (57%)] Loss: -1480.941040\n",
      "Train Epoch: 3862 [45568/60000 (76%)] Loss: -1587.624023\n",
      "Train Epoch: 3862 [56832/60000 (95%)] Loss: -1458.075806\n",
      "    epoch          : 3862\n",
      "    loss           : -1525.4099286612818\n",
      "Train Epoch: 3863 [512/60000 (1%)] Loss: -1551.504150\n",
      "Train Epoch: 3863 [11776/60000 (20%)] Loss: -1523.843506\n",
      "Train Epoch: 3863 [23040/60000 (38%)] Loss: -1486.523438\n",
      "Train Epoch: 3863 [34304/60000 (57%)] Loss: -1485.202637\n",
      "Train Epoch: 3863 [45568/60000 (76%)] Loss: -1570.146606\n",
      "Train Epoch: 3863 [56832/60000 (95%)] Loss: -1524.924072\n",
      "    epoch          : 3863\n",
      "    loss           : -1525.7433116503355\n",
      "Train Epoch: 3864 [512/60000 (1%)] Loss: -1577.240845\n",
      "Train Epoch: 3864 [11776/60000 (20%)] Loss: -1598.819946\n",
      "Train Epoch: 3864 [23040/60000 (38%)] Loss: -1512.964111\n",
      "Train Epoch: 3864 [34304/60000 (57%)] Loss: -1498.616455\n",
      "Train Epoch: 3864 [45568/60000 (76%)] Loss: -1450.024902\n",
      "Train Epoch: 3864 [56832/60000 (95%)] Loss: -1498.530762\n",
      "    epoch          : 3864\n",
      "    loss           : -1530.8268167097015\n",
      "Train Epoch: 3865 [512/60000 (1%)] Loss: -1608.733765\n",
      "Train Epoch: 3865 [11776/60000 (20%)] Loss: -1560.876343\n",
      "Train Epoch: 3865 [23040/60000 (38%)] Loss: -1458.104492\n",
      "Train Epoch: 3865 [34304/60000 (57%)] Loss: -1541.010010\n",
      "Train Epoch: 3865 [45568/60000 (76%)] Loss: -1556.185547\n",
      "Train Epoch: 3865 [56832/60000 (95%)] Loss: -1556.960938\n",
      "    epoch          : 3865\n",
      "    loss           : -1531.248922057071\n",
      "Train Epoch: 3866 [512/60000 (1%)] Loss: -1519.635498\n",
      "Train Epoch: 3866 [11776/60000 (20%)] Loss: -1602.322998\n",
      "Train Epoch: 3866 [23040/60000 (38%)] Loss: -1508.467773\n",
      "Train Epoch: 3866 [34304/60000 (57%)] Loss: -1586.091187\n",
      "Train Epoch: 3866 [45568/60000 (76%)] Loss: -1584.343750\n",
      "Train Epoch: 3866 [56832/60000 (95%)] Loss: -1538.162964\n",
      "    epoch          : 3866\n",
      "    loss           : -1527.2168944622836\n",
      "Train Epoch: 3867 [512/60000 (1%)] Loss: -1482.372192\n",
      "Train Epoch: 3867 [11776/60000 (20%)] Loss: -1533.141968\n",
      "Train Epoch: 3867 [23040/60000 (38%)] Loss: -1482.037231\n",
      "Train Epoch: 3867 [34304/60000 (57%)] Loss: -1561.043579\n",
      "Train Epoch: 3867 [45568/60000 (76%)] Loss: -1573.013184\n",
      "Train Epoch: 3867 [56832/60000 (95%)] Loss: -1512.771484\n",
      "    epoch          : 3867\n",
      "    loss           : -1525.900676145392\n",
      "Train Epoch: 3868 [512/60000 (1%)] Loss: -1487.591553\n",
      "Train Epoch: 3868 [11776/60000 (20%)] Loss: -1458.921143\n",
      "Train Epoch: 3868 [23040/60000 (38%)] Loss: -1447.596924\n",
      "Train Epoch: 3868 [34304/60000 (57%)] Loss: -1470.217651\n",
      "Train Epoch: 3868 [45568/60000 (76%)] Loss: -1549.364258\n",
      "Train Epoch: 3868 [56832/60000 (95%)] Loss: -1556.743530\n",
      "    epoch          : 3868\n",
      "    loss           : -1527.385337010615\n",
      "Train Epoch: 3869 [512/60000 (1%)] Loss: -1558.475098\n",
      "Train Epoch: 3869 [11776/60000 (20%)] Loss: -1513.213257\n",
      "Train Epoch: 3869 [23040/60000 (38%)] Loss: -1527.701416\n",
      "Train Epoch: 3869 [34304/60000 (57%)] Loss: -1483.840698\n",
      "Train Epoch: 3869 [45568/60000 (76%)] Loss: -1506.876221\n",
      "Train Epoch: 3869 [56832/60000 (95%)] Loss: -1450.189331\n",
      "    epoch          : 3869\n",
      "    loss           : -1530.661947304246\n",
      "Train Epoch: 3870 [512/60000 (1%)] Loss: -1577.615112\n",
      "Train Epoch: 3870 [11776/60000 (20%)] Loss: -1597.814331\n",
      "Train Epoch: 3870 [23040/60000 (38%)] Loss: -1483.571289\n",
      "Train Epoch: 3870 [34304/60000 (57%)] Loss: -1607.843628\n",
      "Train Epoch: 3870 [45568/60000 (76%)] Loss: -1496.665039\n",
      "Train Epoch: 3870 [56832/60000 (95%)] Loss: -1601.331787\n",
      "    epoch          : 3870\n",
      "    loss           : -1529.6742798541227\n",
      "Train Epoch: 3871 [512/60000 (1%)] Loss: -1605.266846\n",
      "Train Epoch: 3871 [11776/60000 (20%)] Loss: -1565.388672\n",
      "Train Epoch: 3871 [23040/60000 (38%)] Loss: -1606.905518\n",
      "Train Epoch: 3871 [34304/60000 (57%)] Loss: -1435.877197\n",
      "Train Epoch: 3871 [45568/60000 (76%)] Loss: -1482.491211\n",
      "Train Epoch: 3871 [56832/60000 (95%)] Loss: -1555.782227\n",
      "    epoch          : 3871\n",
      "    loss           : -1536.4314764852577\n",
      "Train Epoch: 3872 [512/60000 (1%)] Loss: -1540.449463\n",
      "Train Epoch: 3872 [11776/60000 (20%)] Loss: -1603.754395\n",
      "Train Epoch: 3872 [23040/60000 (38%)] Loss: -1512.731689\n",
      "Train Epoch: 3872 [34304/60000 (57%)] Loss: -1538.597412\n",
      "Train Epoch: 3872 [45568/60000 (76%)] Loss: -1447.179688\n",
      "Train Epoch: 3872 [56832/60000 (95%)] Loss: -1552.209717\n",
      "    epoch          : 3872\n",
      "    loss           : -1532.7585997500662\n",
      "Train Epoch: 3873 [512/60000 (1%)] Loss: -1567.828125\n",
      "Train Epoch: 3873 [11776/60000 (20%)] Loss: -1542.422363\n",
      "Train Epoch: 3873 [23040/60000 (38%)] Loss: -1574.097778\n",
      "Train Epoch: 3873 [34304/60000 (57%)] Loss: -1573.413208\n",
      "Train Epoch: 3873 [45568/60000 (76%)] Loss: -1541.727173\n",
      "Train Epoch: 3873 [56832/60000 (95%)] Loss: -1448.638672\n",
      "    epoch          : 3873\n",
      "    loss           : -1532.5126028976872\n",
      "Train Epoch: 3874 [512/60000 (1%)] Loss: -1532.552368\n",
      "Train Epoch: 3874 [11776/60000 (20%)] Loss: -1532.997070\n",
      "Train Epoch: 3874 [23040/60000 (38%)] Loss: -1476.546875\n",
      "Train Epoch: 3874 [34304/60000 (57%)] Loss: -1495.031982\n",
      "Train Epoch: 3874 [45568/60000 (76%)] Loss: -1488.401001\n",
      "Train Epoch: 3874 [56832/60000 (95%)] Loss: -1596.109619\n",
      "    epoch          : 3874\n",
      "    loss           : -1520.3562525517523\n",
      "Train Epoch: 3875 [512/60000 (1%)] Loss: -1460.247559\n",
      "Train Epoch: 3875 [11776/60000 (20%)] Loss: -1595.066772\n",
      "Train Epoch: 3875 [23040/60000 (38%)] Loss: -1576.405273\n",
      "Train Epoch: 3875 [34304/60000 (57%)] Loss: -1509.901855\n",
      "Train Epoch: 3875 [45568/60000 (76%)] Loss: -1557.768555\n",
      "Train Epoch: 3875 [56832/60000 (95%)] Loss: -1548.467896\n",
      "    epoch          : 3875\n",
      "    loss           : -1528.202159127273\n",
      "Train Epoch: 3876 [512/60000 (1%)] Loss: -1493.807495\n",
      "Train Epoch: 3876 [11776/60000 (20%)] Loss: -1562.787109\n",
      "Train Epoch: 3876 [23040/60000 (38%)] Loss: -1597.995605\n",
      "Train Epoch: 3876 [34304/60000 (57%)] Loss: -1576.363037\n",
      "Train Epoch: 3876 [45568/60000 (76%)] Loss: -1484.728271\n",
      "Train Epoch: 3876 [56832/60000 (95%)] Loss: -1473.901123\n",
      "    epoch          : 3876\n",
      "    loss           : -1526.4094776218221\n",
      "Train Epoch: 3877 [512/60000 (1%)] Loss: -1472.097168\n",
      "Train Epoch: 3877 [11776/60000 (20%)] Loss: -1531.684082\n",
      "Train Epoch: 3877 [23040/60000 (38%)] Loss: -1436.032715\n",
      "Train Epoch: 3877 [34304/60000 (57%)] Loss: -1547.220215\n",
      "Train Epoch: 3877 [45568/60000 (76%)] Loss: -1514.452148\n",
      "Train Epoch: 3877 [56832/60000 (95%)] Loss: -1510.244385\n",
      "    epoch          : 3877\n",
      "    loss           : -1527.4063648288534\n",
      "Train Epoch: 3878 [512/60000 (1%)] Loss: -1500.130127\n",
      "Train Epoch: 3878 [11776/60000 (20%)] Loss: -1556.356201\n",
      "Train Epoch: 3878 [23040/60000 (38%)] Loss: -1537.119263\n",
      "Train Epoch: 3878 [34304/60000 (57%)] Loss: -1521.538818\n",
      "Train Epoch: 3878 [45568/60000 (76%)] Loss: -1473.882568\n",
      "Train Epoch: 3878 [56832/60000 (95%)] Loss: -1566.192261\n",
      "    epoch          : 3878\n",
      "    loss           : -1526.1566872462042\n",
      "Train Epoch: 3879 [512/60000 (1%)] Loss: -1483.112671\n",
      "Train Epoch: 3879 [11776/60000 (20%)] Loss: -1544.921265\n",
      "Train Epoch: 3879 [23040/60000 (38%)] Loss: -1477.549072\n",
      "Train Epoch: 3879 [34304/60000 (57%)] Loss: -1586.517334\n",
      "Train Epoch: 3879 [45568/60000 (76%)] Loss: -1495.827759\n",
      "Train Epoch: 3879 [56832/60000 (95%)] Loss: -1548.487061\n",
      "    epoch          : 3879\n",
      "    loss           : -1528.9822049760548\n",
      "Train Epoch: 3880 [512/60000 (1%)] Loss: -1470.211426\n",
      "Train Epoch: 3880 [11776/60000 (20%)] Loss: -1498.882812\n",
      "Train Epoch: 3880 [23040/60000 (38%)] Loss: -1507.296509\n",
      "Train Epoch: 3880 [34304/60000 (57%)] Loss: -1470.438110\n",
      "Train Epoch: 3880 [45568/60000 (76%)] Loss: -1528.279541\n",
      "Train Epoch: 3880 [56832/60000 (95%)] Loss: -1511.522461\n",
      "    epoch          : 3880\n",
      "    loss           : -1519.4264150500971\n",
      "Train Epoch: 3881 [512/60000 (1%)] Loss: -1476.957520\n",
      "Train Epoch: 3881 [11776/60000 (20%)] Loss: -1542.593994\n",
      "Train Epoch: 3881 [23040/60000 (38%)] Loss: -1567.122803\n",
      "Train Epoch: 3881 [34304/60000 (57%)] Loss: -1578.502441\n",
      "Train Epoch: 3881 [45568/60000 (76%)] Loss: -1517.951416\n",
      "Train Epoch: 3881 [56832/60000 (95%)] Loss: -1489.647339\n",
      "    epoch          : 3881\n",
      "    loss           : -1522.3257280769994\n",
      "Train Epoch: 3882 [512/60000 (1%)] Loss: -1540.282593\n",
      "Train Epoch: 3882 [11776/60000 (20%)] Loss: -1490.155273\n",
      "Train Epoch: 3882 [23040/60000 (38%)] Loss: -1586.032349\n",
      "Train Epoch: 3882 [34304/60000 (57%)] Loss: -1566.923096\n",
      "Train Epoch: 3882 [45568/60000 (76%)] Loss: -1492.589355\n",
      "Train Epoch: 3882 [56832/60000 (95%)] Loss: -1486.939575\n",
      "    epoch          : 3882\n",
      "    loss           : -1531.5019017451227\n",
      "Train Epoch: 3883 [512/60000 (1%)] Loss: -1501.313721\n",
      "Train Epoch: 3883 [11776/60000 (20%)] Loss: -1506.187866\n",
      "Train Epoch: 3883 [23040/60000 (38%)] Loss: -1593.319214\n",
      "Train Epoch: 3883 [34304/60000 (57%)] Loss: -1551.875732\n",
      "Train Epoch: 3883 [45568/60000 (76%)] Loss: -1568.526489\n",
      "Train Epoch: 3883 [56832/60000 (95%)] Loss: -1534.453979\n",
      "    epoch          : 3883\n",
      "    loss           : -1531.5382531807247\n",
      "Train Epoch: 3884 [512/60000 (1%)] Loss: -1494.857910\n",
      "Train Epoch: 3884 [11776/60000 (20%)] Loss: -1609.787842\n",
      "Train Epoch: 3884 [23040/60000 (38%)] Loss: -1515.090332\n",
      "Train Epoch: 3884 [34304/60000 (57%)] Loss: -1548.276367\n",
      "Train Epoch: 3884 [45568/60000 (76%)] Loss: -1537.230225\n",
      "Train Epoch: 3884 [56832/60000 (95%)] Loss: -1469.692017\n",
      "    epoch          : 3884\n",
      "    loss           : -1525.5432556497174\n",
      "Train Epoch: 3885 [512/60000 (1%)] Loss: -1537.950928\n",
      "Train Epoch: 3885 [11776/60000 (20%)] Loss: -1483.772949\n",
      "Train Epoch: 3885 [23040/60000 (38%)] Loss: -1524.148315\n",
      "Train Epoch: 3885 [34304/60000 (57%)] Loss: -1615.494873\n",
      "Train Epoch: 3885 [45568/60000 (76%)] Loss: -1554.623901\n",
      "Train Epoch: 3885 [56832/60000 (95%)] Loss: -1555.893433\n",
      "    epoch          : 3885\n",
      "    loss           : -1532.2004197977358\n",
      "Train Epoch: 3886 [512/60000 (1%)] Loss: -1540.892700\n",
      "Train Epoch: 3886 [11776/60000 (20%)] Loss: -1508.689697\n",
      "Train Epoch: 3886 [23040/60000 (38%)] Loss: -1549.996582\n",
      "Train Epoch: 3886 [34304/60000 (57%)] Loss: -1583.520996\n",
      "Train Epoch: 3886 [45568/60000 (76%)] Loss: -1510.442383\n",
      "Train Epoch: 3886 [56832/60000 (95%)] Loss: -1540.786621\n",
      "    epoch          : 3886\n",
      "    loss           : -1526.680525785112\n",
      "Train Epoch: 3887 [512/60000 (1%)] Loss: -1562.022705\n",
      "Train Epoch: 3887 [11776/60000 (20%)] Loss: -1577.075073\n",
      "Train Epoch: 3887 [23040/60000 (38%)] Loss: -1523.865479\n",
      "Train Epoch: 3887 [34304/60000 (57%)] Loss: -1522.694702\n",
      "Train Epoch: 3887 [45568/60000 (76%)] Loss: -1599.634399\n",
      "Train Epoch: 3887 [56832/60000 (95%)] Loss: -1557.243652\n",
      "    epoch          : 3887\n",
      "    loss           : -1527.6531772074727\n",
      "Train Epoch: 3888 [512/60000 (1%)] Loss: -1533.829102\n",
      "Train Epoch: 3888 [11776/60000 (20%)] Loss: -1480.521240\n",
      "Train Epoch: 3888 [23040/60000 (38%)] Loss: -1497.860596\n",
      "Train Epoch: 3888 [34304/60000 (57%)] Loss: -1562.805176\n",
      "Train Epoch: 3888 [45568/60000 (76%)] Loss: -1544.637939\n",
      "Train Epoch: 3888 [56832/60000 (95%)] Loss: -1495.602539\n",
      "    epoch          : 3888\n",
      "    loss           : -1520.1615504033148\n",
      "Train Epoch: 3889 [512/60000 (1%)] Loss: -1557.297119\n",
      "Train Epoch: 3889 [11776/60000 (20%)] Loss: -1453.845093\n",
      "Train Epoch: 3889 [23040/60000 (38%)] Loss: -1474.498413\n",
      "Train Epoch: 3889 [34304/60000 (57%)] Loss: -1480.706543\n",
      "Train Epoch: 3889 [45568/60000 (76%)] Loss: -1485.374512\n",
      "Train Epoch: 3889 [56832/60000 (95%)] Loss: -1552.442139\n",
      "    epoch          : 3889\n",
      "    loss           : -1527.722729354255\n",
      "Train Epoch: 3890 [512/60000 (1%)] Loss: -1525.460571\n",
      "Train Epoch: 3890 [11776/60000 (20%)] Loss: -1490.104004\n",
      "Train Epoch: 3890 [23040/60000 (38%)] Loss: -1499.854370\n",
      "Train Epoch: 3890 [34304/60000 (57%)] Loss: -1515.079224\n",
      "Train Epoch: 3890 [45568/60000 (76%)] Loss: -1556.145996\n",
      "Train Epoch: 3890 [56832/60000 (95%)] Loss: -1606.756348\n",
      "    epoch          : 3890\n",
      "    loss           : -1525.5773146462307\n",
      "Train Epoch: 3891 [512/60000 (1%)] Loss: -1563.511841\n",
      "Train Epoch: 3891 [11776/60000 (20%)] Loss: -1531.796631\n",
      "Train Epoch: 3891 [23040/60000 (38%)] Loss: -1533.743652\n",
      "Train Epoch: 3891 [34304/60000 (57%)] Loss: -1590.050293\n",
      "Train Epoch: 3891 [45568/60000 (76%)] Loss: -1593.602661\n",
      "Train Epoch: 3891 [56832/60000 (95%)] Loss: -1475.152832\n",
      "    epoch          : 3891\n",
      "    loss           : -1531.3787586621645\n",
      "Train Epoch: 3892 [512/60000 (1%)] Loss: -1519.261719\n",
      "Train Epoch: 3892 [11776/60000 (20%)] Loss: -1600.256104\n",
      "Train Epoch: 3892 [23040/60000 (38%)] Loss: -1468.612183\n",
      "Train Epoch: 3892 [34304/60000 (57%)] Loss: -1584.496582\n",
      "Train Epoch: 3892 [45568/60000 (76%)] Loss: -1528.470215\n",
      "Train Epoch: 3892 [56832/60000 (95%)] Loss: -1523.669312\n",
      "    epoch          : 3892\n",
      "    loss           : -1527.5288885946327\n",
      "Train Epoch: 3893 [512/60000 (1%)] Loss: -1506.180542\n",
      "Train Epoch: 3893 [11776/60000 (20%)] Loss: -1583.102295\n",
      "Train Epoch: 3893 [23040/60000 (38%)] Loss: -1565.692627\n",
      "Train Epoch: 3893 [34304/60000 (57%)] Loss: -1571.992798\n",
      "Train Epoch: 3893 [45568/60000 (76%)] Loss: -1555.776367\n",
      "Train Epoch: 3893 [56832/60000 (95%)] Loss: -1457.277344\n",
      "    epoch          : 3893\n",
      "    loss           : -1530.7824196680792\n",
      "Train Epoch: 3894 [512/60000 (1%)] Loss: -1526.042236\n",
      "Train Epoch: 3894 [11776/60000 (20%)] Loss: -1498.064087\n",
      "Train Epoch: 3894 [23040/60000 (38%)] Loss: -1489.210205\n",
      "Train Epoch: 3894 [34304/60000 (57%)] Loss: -1460.125488\n",
      "Train Epoch: 3894 [45568/60000 (76%)] Loss: -1490.352539\n",
      "Train Epoch: 3894 [56832/60000 (95%)] Loss: -1543.814941\n",
      "    epoch          : 3894\n",
      "    loss           : -1531.9127990377826\n",
      "Train Epoch: 3895 [512/60000 (1%)] Loss: -1519.622559\n",
      "Train Epoch: 3895 [11776/60000 (20%)] Loss: -1588.851807\n",
      "Train Epoch: 3895 [23040/60000 (38%)] Loss: -1512.348755\n",
      "Train Epoch: 3895 [34304/60000 (57%)] Loss: -1521.282227\n",
      "Train Epoch: 3895 [45568/60000 (76%)] Loss: -1405.772949\n",
      "Train Epoch: 3895 [56832/60000 (95%)] Loss: -1550.777588\n",
      "    epoch          : 3895\n",
      "    loss           : -1529.624208611957\n",
      "Train Epoch: 3896 [512/60000 (1%)] Loss: -1506.657593\n",
      "Train Epoch: 3896 [11776/60000 (20%)] Loss: -1547.423584\n",
      "Train Epoch: 3896 [23040/60000 (38%)] Loss: -1528.914429\n",
      "Train Epoch: 3896 [34304/60000 (57%)] Loss: -1540.181152\n",
      "Train Epoch: 3896 [45568/60000 (76%)] Loss: -1590.322510\n",
      "Train Epoch: 3896 [56832/60000 (95%)] Loss: -1576.251709\n",
      "    epoch          : 3896\n",
      "    loss           : -1523.8251980711511\n",
      "Train Epoch: 3897 [512/60000 (1%)] Loss: -1582.317871\n",
      "Train Epoch: 3897 [11776/60000 (20%)] Loss: -1490.684692\n",
      "Train Epoch: 3897 [23040/60000 (38%)] Loss: -1523.271851\n",
      "Train Epoch: 3897 [34304/60000 (57%)] Loss: -1476.914062\n",
      "Train Epoch: 3897 [45568/60000 (76%)] Loss: -1579.243774\n",
      "Train Epoch: 3897 [56832/60000 (95%)] Loss: -1593.354126\n",
      "    epoch          : 3897\n",
      "    loss           : -1523.8126158633474\n",
      "Train Epoch: 3898 [512/60000 (1%)] Loss: -1473.220459\n",
      "Train Epoch: 3898 [11776/60000 (20%)] Loss: -1517.805054\n",
      "Train Epoch: 3898 [23040/60000 (38%)] Loss: -1536.614502\n",
      "Train Epoch: 3898 [34304/60000 (57%)] Loss: -1545.715454\n",
      "Train Epoch: 3898 [45568/60000 (76%)] Loss: -1525.006836\n",
      "Train Epoch: 3898 [56832/60000 (95%)] Loss: -1535.374634\n",
      "    epoch          : 3898\n",
      "    loss           : -1524.3225201105668\n",
      "Train Epoch: 3899 [512/60000 (1%)] Loss: -1573.986450\n",
      "Train Epoch: 3899 [11776/60000 (20%)] Loss: -1483.233643\n",
      "Train Epoch: 3899 [23040/60000 (38%)] Loss: -1488.773438\n",
      "Train Epoch: 3899 [34304/60000 (57%)] Loss: -1472.897339\n",
      "Train Epoch: 3899 [45568/60000 (76%)] Loss: -1502.961426\n",
      "Train Epoch: 3899 [56832/60000 (95%)] Loss: -1516.368896\n",
      "    epoch          : 3899\n",
      "    loss           : -1526.3540097683838\n",
      "Train Epoch: 3900 [512/60000 (1%)] Loss: -1593.799438\n",
      "Train Epoch: 3900 [11776/60000 (20%)] Loss: -1521.073486\n",
      "Train Epoch: 3900 [23040/60000 (38%)] Loss: -1506.879639\n",
      "Train Epoch: 3900 [34304/60000 (57%)] Loss: -1549.778076\n",
      "Train Epoch: 3900 [45568/60000 (76%)] Loss: -1563.065430\n",
      "Train Epoch: 3900 [56832/60000 (95%)] Loss: -1533.833618\n",
      "    epoch          : 3900\n",
      "    loss           : -1532.5519443662827\n",
      "Saving checkpoint: saved/models/Mnist_DeepGenerativeOperad/0127_111843/checkpoint-epoch3900.pth ...\n",
      "Train Epoch: 3901 [512/60000 (1%)] Loss: -1495.368530\n",
      "Train Epoch: 3901 [11776/60000 (20%)] Loss: -1547.362549\n",
      "Train Epoch: 3901 [23040/60000 (38%)] Loss: -1443.521973\n",
      "Train Epoch: 3901 [34304/60000 (57%)] Loss: -1522.491211\n",
      "Train Epoch: 3901 [45568/60000 (76%)] Loss: -1540.514648\n",
      "Train Epoch: 3901 [56832/60000 (95%)] Loss: -1525.708496\n",
      "    epoch          : 3901\n",
      "    loss           : -1526.9268871242716\n",
      "Train Epoch: 3902 [512/60000 (1%)] Loss: -1571.143433\n",
      "Train Epoch: 3902 [11776/60000 (20%)] Loss: -1522.067505\n",
      "Train Epoch: 3902 [23040/60000 (38%)] Loss: -1392.445068\n",
      "Train Epoch: 3902 [34304/60000 (57%)] Loss: -1513.518555\n",
      "Train Epoch: 3902 [45568/60000 (76%)] Loss: -1458.589844\n",
      "Train Epoch: 3902 [56832/60000 (95%)] Loss: -1530.328491\n",
      "    epoch          : 3902\n",
      "    loss           : -1524.5818636619438\n",
      "Train Epoch: 3903 [512/60000 (1%)] Loss: -1489.902466\n",
      "Train Epoch: 3903 [11776/60000 (20%)] Loss: -1535.082397\n",
      "Train Epoch: 3903 [23040/60000 (38%)] Loss: -1569.955811\n",
      "Train Epoch: 3903 [34304/60000 (57%)] Loss: -1511.702393\n",
      "Train Epoch: 3903 [45568/60000 (76%)] Loss: -1525.378540\n",
      "Train Epoch: 3903 [56832/60000 (95%)] Loss: -1454.549316\n",
      "    epoch          : 3903\n",
      "    loss           : -1524.3955519509182\n",
      "Train Epoch: 3904 [512/60000 (1%)] Loss: -1552.418701\n",
      "Train Epoch: 3904 [11776/60000 (20%)] Loss: -1536.470581\n",
      "Train Epoch: 3904 [23040/60000 (38%)] Loss: -1514.755615\n",
      "Train Epoch: 3904 [34304/60000 (57%)] Loss: -1522.560303\n",
      "Train Epoch: 3904 [45568/60000 (76%)] Loss: -1535.148682\n",
      "Train Epoch: 3904 [56832/60000 (95%)] Loss: -1495.753418\n",
      "    epoch          : 3904\n",
      "    loss           : -1533.0935213767875\n",
      "Train Epoch: 3905 [512/60000 (1%)] Loss: -1470.460205\n",
      "Train Epoch: 3905 [11776/60000 (20%)] Loss: -1550.962402\n",
      "Train Epoch: 3905 [23040/60000 (38%)] Loss: -1585.853271\n",
      "Train Epoch: 3905 [34304/60000 (57%)] Loss: -1527.667236\n",
      "Train Epoch: 3905 [45568/60000 (76%)] Loss: -1589.127197\n",
      "Train Epoch: 3905 [56832/60000 (95%)] Loss: -1570.820679\n",
      "    epoch          : 3905\n",
      "    loss           : -1535.8371016507767\n",
      "Train Epoch: 3906 [512/60000 (1%)] Loss: -1582.995850\n",
      "Train Epoch: 3906 [11776/60000 (20%)] Loss: -1540.322998\n",
      "Train Epoch: 3906 [23040/60000 (38%)] Loss: -1524.109863\n",
      "Train Epoch: 3906 [34304/60000 (57%)] Loss: -1544.782227\n",
      "Train Epoch: 3906 [45568/60000 (76%)] Loss: -1555.116577\n",
      "Train Epoch: 3906 [56832/60000 (95%)] Loss: -1529.548218\n",
      "    epoch          : 3906\n",
      "    loss           : -1532.7868286822477\n",
      "Train Epoch: 3907 [512/60000 (1%)] Loss: -1530.533813\n",
      "Train Epoch: 3907 [11776/60000 (20%)] Loss: -1583.304321\n",
      "Train Epoch: 3907 [23040/60000 (38%)] Loss: -1540.955811\n",
      "Train Epoch: 3907 [34304/60000 (57%)] Loss: -1516.476440\n",
      "Train Epoch: 3907 [45568/60000 (76%)] Loss: -1451.849243\n",
      "Train Epoch: 3907 [56832/60000 (95%)] Loss: -1513.287842\n",
      "    epoch          : 3907\n",
      "    loss           : -1525.5429759914591\n",
      "Train Epoch: 3908 [512/60000 (1%)] Loss: -1523.767578\n",
      "Train Epoch: 3908 [11776/60000 (20%)] Loss: -1549.814453\n",
      "Train Epoch: 3908 [23040/60000 (38%)] Loss: -1547.622681\n",
      "Train Epoch: 3908 [34304/60000 (57%)] Loss: -1566.754883\n",
      "Train Epoch: 3908 [45568/60000 (76%)] Loss: -1526.912231\n",
      "Train Epoch: 3908 [56832/60000 (95%)] Loss: -1505.282349\n",
      "    epoch          : 3908\n",
      "    loss           : -1532.5880675235037\n",
      "Train Epoch: 3909 [512/60000 (1%)] Loss: -1441.798096\n",
      "Train Epoch: 3909 [11776/60000 (20%)] Loss: -1510.860107\n",
      "Train Epoch: 3909 [23040/60000 (38%)] Loss: -1500.659546\n",
      "Train Epoch: 3909 [34304/60000 (57%)] Loss: -1479.251221\n",
      "Train Epoch: 3909 [45568/60000 (76%)] Loss: -1509.539551\n",
      "Train Epoch: 3909 [56832/60000 (95%)] Loss: -1596.919922\n",
      "    epoch          : 3909\n",
      "    loss           : -1530.8312012408414\n",
      "Train Epoch: 3910 [512/60000 (1%)] Loss: -1478.324097\n",
      "Train Epoch: 3910 [11776/60000 (20%)] Loss: -1557.998535\n",
      "Train Epoch: 3910 [23040/60000 (38%)] Loss: -1559.043701\n",
      "Train Epoch: 3910 [34304/60000 (57%)] Loss: -1573.789307\n",
      "Train Epoch: 3910 [45568/60000 (76%)] Loss: -1573.314697\n",
      "Train Epoch: 3910 [56832/60000 (95%)] Loss: -1490.297363\n",
      "    epoch          : 3910\n",
      "    loss           : -1524.8128555211645\n",
      "Train Epoch: 3911 [512/60000 (1%)] Loss: -1449.775879\n",
      "Train Epoch: 3911 [11776/60000 (20%)] Loss: -1489.615967\n",
      "Train Epoch: 3911 [23040/60000 (38%)] Loss: -1536.421509\n",
      "Train Epoch: 3911 [34304/60000 (57%)] Loss: -1541.967896\n",
      "Train Epoch: 3911 [45568/60000 (76%)] Loss: -1506.155029\n",
      "Train Epoch: 3911 [56832/60000 (95%)] Loss: -1545.776855\n",
      "    epoch          : 3911\n",
      "    loss           : -1526.7805479232873\n",
      "Train Epoch: 3912 [512/60000 (1%)] Loss: -1450.718018\n",
      "Train Epoch: 3912 [11776/60000 (20%)] Loss: -1566.938477\n",
      "Train Epoch: 3912 [23040/60000 (38%)] Loss: -1547.336060\n",
      "Train Epoch: 3912 [34304/60000 (57%)] Loss: -1505.503662\n",
      "Train Epoch: 3912 [45568/60000 (76%)] Loss: -1510.270996\n",
      "Train Epoch: 3912 [56832/60000 (95%)] Loss: -1472.987305\n",
      "    epoch          : 3912\n",
      "    loss           : -1520.906630693856\n",
      "Train Epoch: 3913 [512/60000 (1%)] Loss: -1487.220703\n",
      "Train Epoch: 3913 [11776/60000 (20%)] Loss: -1506.861694\n",
      "Train Epoch: 3913 [23040/60000 (38%)] Loss: -1521.314575\n",
      "Train Epoch: 3913 [34304/60000 (57%)] Loss: -1452.701660\n",
      "Train Epoch: 3913 [45568/60000 (76%)] Loss: -1542.701172\n",
      "Train Epoch: 3913 [56832/60000 (95%)] Loss: -1481.291992\n",
      "    epoch          : 3913\n",
      "    loss           : -1520.996314097259\n",
      "Train Epoch: 3914 [512/60000 (1%)] Loss: -1531.161621\n",
      "Train Epoch: 3914 [11776/60000 (20%)] Loss: -1472.864868\n",
      "Train Epoch: 3914 [23040/60000 (38%)] Loss: -1498.865479\n",
      "Train Epoch: 3914 [34304/60000 (57%)] Loss: -1479.476929\n",
      "Train Epoch: 3914 [45568/60000 (76%)] Loss: -1585.461670\n",
      "Train Epoch: 3914 [56832/60000 (95%)] Loss: -1540.063965\n",
      "    epoch          : 3914\n",
      "    loss           : -1525.6859323964954\n",
      "Train Epoch: 3915 [512/60000 (1%)] Loss: -1567.613403\n",
      "Train Epoch: 3915 [11776/60000 (20%)] Loss: -1604.712280\n",
      "Train Epoch: 3915 [23040/60000 (38%)] Loss: -1540.270264\n",
      "Train Epoch: 3915 [34304/60000 (57%)] Loss: -1529.575195\n",
      "Train Epoch: 3915 [45568/60000 (76%)] Loss: -1484.565674\n",
      "Train Epoch: 3915 [56832/60000 (95%)] Loss: -1558.139404\n",
      "    epoch          : 3915\n",
      "    loss           : -1534.4810404804468\n",
      "Train Epoch: 3916 [512/60000 (1%)] Loss: -1526.728027\n",
      "Train Epoch: 3916 [11776/60000 (20%)] Loss: -1551.627563\n",
      "Train Epoch: 3916 [23040/60000 (38%)] Loss: -1518.744629\n",
      "Train Epoch: 3916 [34304/60000 (57%)] Loss: -1560.349731\n",
      "Train Epoch: 3916 [45568/60000 (76%)] Loss: -1572.522705\n",
      "Train Epoch: 3916 [56832/60000 (95%)] Loss: -1512.039062\n",
      "    epoch          : 3916\n",
      "    loss           : -1525.936326193944\n",
      "Train Epoch: 3917 [512/60000 (1%)] Loss: -1551.772217\n",
      "Train Epoch: 3917 [11776/60000 (20%)] Loss: -1590.771729\n",
      "Train Epoch: 3917 [23040/60000 (38%)] Loss: -1511.234985\n",
      "Train Epoch: 3917 [34304/60000 (57%)] Loss: -1540.426147\n",
      "Train Epoch: 3917 [45568/60000 (76%)] Loss: -1478.585327\n",
      "Train Epoch: 3917 [56832/60000 (95%)] Loss: -1498.811890\n",
      "    epoch          : 3917\n",
      "    loss           : -1525.9035789360435\n",
      "Train Epoch: 3918 [512/60000 (1%)] Loss: -1562.048096\n",
      "Train Epoch: 3918 [11776/60000 (20%)] Loss: -1522.493652\n",
      "Train Epoch: 3918 [23040/60000 (38%)] Loss: -1518.567017\n",
      "Train Epoch: 3918 [34304/60000 (57%)] Loss: -1541.823364\n",
      "Train Epoch: 3918 [45568/60000 (76%)] Loss: -1577.907471\n",
      "Train Epoch: 3918 [56832/60000 (95%)] Loss: -1498.753662\n",
      "    epoch          : 3918\n",
      "    loss           : -1525.7199382889744\n",
      "Train Epoch: 3919 [512/60000 (1%)] Loss: -1511.358765\n",
      "Train Epoch: 3919 [11776/60000 (20%)] Loss: -1482.395508\n",
      "Train Epoch: 3919 [23040/60000 (38%)] Loss: -1556.812500\n",
      "Train Epoch: 3919 [34304/60000 (57%)] Loss: -1473.325684\n",
      "Train Epoch: 3919 [45568/60000 (76%)] Loss: -1517.010986\n",
      "Train Epoch: 3919 [56832/60000 (95%)] Loss: -1560.021484\n",
      "    epoch          : 3919\n",
      "    loss           : -1525.9133280091366\n",
      "Train Epoch: 3920 [512/60000 (1%)] Loss: -1462.203369\n",
      "Train Epoch: 3920 [11776/60000 (20%)] Loss: -1505.932983\n",
      "Train Epoch: 3920 [23040/60000 (38%)] Loss: -1519.770508\n",
      "Train Epoch: 3920 [34304/60000 (57%)] Loss: -1593.836914\n",
      "Train Epoch: 3920 [45568/60000 (76%)] Loss: -1508.683228\n",
      "Train Epoch: 3920 [56832/60000 (95%)] Loss: -1494.959473\n",
      "    epoch          : 3920\n",
      "    loss           : -1526.136547023967\n",
      "Train Epoch: 3921 [512/60000 (1%)] Loss: -1493.777832\n",
      "Train Epoch: 3921 [11776/60000 (20%)] Loss: -1554.696533\n",
      "Train Epoch: 3921 [23040/60000 (38%)] Loss: -1549.669922\n",
      "Train Epoch: 3921 [34304/60000 (57%)] Loss: -1498.552124\n",
      "Train Epoch: 3921 [45568/60000 (76%)] Loss: -1573.749756\n",
      "Train Epoch: 3921 [56832/60000 (95%)] Loss: -1516.971924\n",
      "    epoch          : 3921\n",
      "    loss           : -1524.796367408192\n",
      "Train Epoch: 3922 [512/60000 (1%)] Loss: -1524.824463\n",
      "Train Epoch: 3922 [11776/60000 (20%)] Loss: -1587.034180\n",
      "Train Epoch: 3922 [23040/60000 (38%)] Loss: -1558.898071\n",
      "Train Epoch: 3922 [34304/60000 (57%)] Loss: -1575.775024\n",
      "Train Epoch: 3922 [45568/60000 (76%)] Loss: -1506.181519\n",
      "Train Epoch: 3922 [56832/60000 (95%)] Loss: -1548.081299\n",
      "    epoch          : 3922\n",
      "    loss           : -1529.559553415762\n",
      "Train Epoch: 3923 [512/60000 (1%)] Loss: -1519.941162\n",
      "Train Epoch: 3923 [11776/60000 (20%)] Loss: -1601.767578\n",
      "Train Epoch: 3923 [23040/60000 (38%)] Loss: -1544.136108\n",
      "Train Epoch: 3923 [34304/60000 (57%)] Loss: -1478.906860\n",
      "Train Epoch: 3923 [45568/60000 (76%)] Loss: -1472.963135\n",
      "Train Epoch: 3923 [56832/60000 (95%)] Loss: -1534.698242\n",
      "    epoch          : 3923\n",
      "    loss           : -1531.5406514830509\n",
      "Train Epoch: 3924 [512/60000 (1%)] Loss: -1515.856445\n",
      "Train Epoch: 3924 [11776/60000 (20%)] Loss: -1575.125732\n",
      "Train Epoch: 3924 [23040/60000 (38%)] Loss: -1525.179565\n",
      "Train Epoch: 3924 [34304/60000 (57%)] Loss: -1476.880859\n",
      "Train Epoch: 3924 [45568/60000 (76%)] Loss: -1517.648560\n",
      "Train Epoch: 3924 [56832/60000 (95%)] Loss: -1565.359863\n",
      "    epoch          : 3924\n",
      "    loss           : -1534.2991315766242\n",
      "Train Epoch: 3925 [512/60000 (1%)] Loss: -1496.409424\n",
      "Train Epoch: 3925 [11776/60000 (20%)] Loss: -1502.868042\n",
      "Train Epoch: 3925 [23040/60000 (38%)] Loss: -1541.335693\n",
      "Train Epoch: 3925 [34304/60000 (57%)] Loss: -1553.767334\n",
      "Train Epoch: 3925 [45568/60000 (76%)] Loss: -1577.151489\n",
      "Train Epoch: 3925 [56832/60000 (95%)] Loss: -1535.717651\n",
      "    epoch          : 3925\n",
      "    loss           : -1521.5055986824682\n",
      "Train Epoch: 3926 [512/60000 (1%)] Loss: -1542.643311\n",
      "Train Epoch: 3926 [11776/60000 (20%)] Loss: -1628.050781\n",
      "Train Epoch: 3926 [23040/60000 (38%)] Loss: -1456.605469\n",
      "Train Epoch: 3926 [34304/60000 (57%)] Loss: -1538.382324\n",
      "Train Epoch: 3926 [45568/60000 (76%)] Loss: -1531.790039\n",
      "Train Epoch: 3926 [56832/60000 (95%)] Loss: -1470.361084\n",
      "    epoch          : 3926\n",
      "    loss           : -1524.1913152145128\n",
      "Train Epoch: 3927 [512/60000 (1%)] Loss: -1546.778687\n",
      "Train Epoch: 3927 [11776/60000 (20%)] Loss: -1577.221436\n",
      "Train Epoch: 3927 [23040/60000 (38%)] Loss: -1572.608887\n",
      "Train Epoch: 3927 [34304/60000 (57%)] Loss: -1541.195312\n",
      "Train Epoch: 3927 [45568/60000 (76%)] Loss: -1562.696777\n",
      "Train Epoch: 3927 [56832/60000 (95%)] Loss: -1479.545410\n",
      "    epoch          : 3927\n",
      "    loss           : -1526.1435474460409\n",
      "Train Epoch: 3928 [512/60000 (1%)] Loss: -1523.250610\n",
      "Train Epoch: 3928 [11776/60000 (20%)] Loss: -1579.194580\n",
      "Train Epoch: 3928 [23040/60000 (38%)] Loss: -1561.336426\n",
      "Train Epoch: 3928 [34304/60000 (57%)] Loss: -1412.343750\n",
      "Train Epoch: 3928 [45568/60000 (76%)] Loss: -1506.075684\n",
      "Train Epoch: 3928 [56832/60000 (95%)] Loss: -1517.161987\n",
      "    epoch          : 3928\n",
      "    loss           : -1533.219507939398\n",
      "Train Epoch: 3929 [512/60000 (1%)] Loss: -1557.911011\n",
      "Train Epoch: 3929 [11776/60000 (20%)] Loss: -1547.597168\n",
      "Train Epoch: 3929 [23040/60000 (38%)] Loss: -1513.368042\n",
      "Train Epoch: 3929 [34304/60000 (57%)] Loss: -1478.241089\n",
      "Train Epoch: 3929 [45568/60000 (76%)] Loss: -1513.916870\n",
      "Train Epoch: 3929 [56832/60000 (95%)] Loss: -1473.148926\n",
      "    epoch          : 3929\n",
      "    loss           : -1532.372002380716\n",
      "Train Epoch: 3930 [512/60000 (1%)] Loss: -1585.536987\n",
      "Train Epoch: 3930 [11776/60000 (20%)] Loss: -1454.942627\n",
      "Train Epoch: 3930 [23040/60000 (38%)] Loss: -1527.100586\n",
      "Train Epoch: 3930 [34304/60000 (57%)] Loss: -1505.447632\n",
      "Train Epoch: 3930 [45568/60000 (76%)] Loss: -1565.453125\n",
      "Train Epoch: 3930 [56832/60000 (95%)] Loss: -1533.063477\n",
      "    epoch          : 3930\n",
      "    loss           : -1526.300250554489\n",
      "Train Epoch: 3931 [512/60000 (1%)] Loss: -1398.882202\n",
      "Train Epoch: 3931 [11776/60000 (20%)] Loss: -1487.450562\n",
      "Train Epoch: 3931 [23040/60000 (38%)] Loss: -1567.240967\n",
      "Train Epoch: 3931 [34304/60000 (57%)] Loss: -1539.813965\n",
      "Train Epoch: 3931 [45568/60000 (76%)] Loss: -1548.327637\n",
      "Train Epoch: 3931 [56832/60000 (95%)] Loss: -1447.752686\n",
      "    epoch          : 3931\n",
      "    loss           : -1521.8389575333244\n",
      "Train Epoch: 3932 [512/60000 (1%)] Loss: -1566.236206\n",
      "Train Epoch: 3932 [11776/60000 (20%)] Loss: -1497.742676\n",
      "Train Epoch: 3932 [23040/60000 (38%)] Loss: -1493.860840\n",
      "Train Epoch: 3932 [34304/60000 (57%)] Loss: -1489.656494\n",
      "Train Epoch: 3932 [45568/60000 (76%)] Loss: -1441.601074\n",
      "Train Epoch: 3932 [56832/60000 (95%)] Loss: -1496.075317\n",
      "    epoch          : 3932\n",
      "    loss           : -1531.302686788268\n",
      "Train Epoch: 3933 [512/60000 (1%)] Loss: -1559.849243\n",
      "Train Epoch: 3933 [11776/60000 (20%)] Loss: -1556.999878\n",
      "Train Epoch: 3933 [23040/60000 (38%)] Loss: -1450.601807\n",
      "Train Epoch: 3933 [34304/60000 (57%)] Loss: -1503.075073\n",
      "Train Epoch: 3933 [45568/60000 (76%)] Loss: -1569.436035\n",
      "Train Epoch: 3933 [56832/60000 (95%)] Loss: -1500.508789\n",
      "    epoch          : 3933\n",
      "    loss           : -1532.0360731566693\n",
      "Train Epoch: 3934 [512/60000 (1%)] Loss: -1443.858643\n",
      "Train Epoch: 3934 [11776/60000 (20%)] Loss: -1495.951416\n",
      "Train Epoch: 3934 [23040/60000 (38%)] Loss: -1428.953735\n",
      "Train Epoch: 3934 [34304/60000 (57%)] Loss: -1594.767822\n",
      "Train Epoch: 3934 [45568/60000 (76%)] Loss: -1566.186035\n",
      "Train Epoch: 3934 [56832/60000 (95%)] Loss: -1437.217163\n",
      "    epoch          : 3934\n",
      "    loss           : -1524.9707941604872\n",
      "Train Epoch: 3935 [512/60000 (1%)] Loss: -1577.078125\n",
      "Train Epoch: 3935 [11776/60000 (20%)] Loss: -1448.219360\n",
      "Train Epoch: 3935 [23040/60000 (38%)] Loss: -1592.723877\n",
      "Train Epoch: 3935 [34304/60000 (57%)] Loss: -1481.088501\n",
      "Train Epoch: 3935 [45568/60000 (76%)] Loss: -1565.757446\n",
      "Train Epoch: 3935 [56832/60000 (95%)] Loss: -1559.737793\n",
      "    epoch          : 3935\n",
      "    loss           : -1521.3519031934145\n",
      "Train Epoch: 3936 [512/60000 (1%)] Loss: -1555.236572\n",
      "Train Epoch: 3936 [11776/60000 (20%)] Loss: -1555.317261\n",
      "Train Epoch: 3936 [23040/60000 (38%)] Loss: -1519.899780\n",
      "Train Epoch: 3936 [34304/60000 (57%)] Loss: -1519.481567\n",
      "Train Epoch: 3936 [45568/60000 (76%)] Loss: -1553.797607\n",
      "Train Epoch: 3936 [56832/60000 (95%)] Loss: -1441.005493\n",
      "    epoch          : 3936\n",
      "    loss           : -1531.6329349151438\n",
      "Train Epoch: 3937 [512/60000 (1%)] Loss: -1455.561035\n",
      "Train Epoch: 3937 [11776/60000 (20%)] Loss: -1508.341919\n",
      "Train Epoch: 3937 [23040/60000 (38%)] Loss: -1486.020264\n",
      "Train Epoch: 3937 [34304/60000 (57%)] Loss: -1542.373779\n",
      "Train Epoch: 3937 [45568/60000 (76%)] Loss: -1606.215088\n",
      "Train Epoch: 3937 [56832/60000 (95%)] Loss: -1559.511230\n",
      "    epoch          : 3937\n",
      "    loss           : -1529.3301767467779\n",
      "Train Epoch: 3938 [512/60000 (1%)] Loss: -1603.291748\n",
      "Train Epoch: 3938 [11776/60000 (20%)] Loss: -1522.566406\n",
      "Train Epoch: 3938 [23040/60000 (38%)] Loss: -1557.810669\n",
      "Train Epoch: 3938 [34304/60000 (57%)] Loss: -1540.539185\n",
      "Train Epoch: 3938 [45568/60000 (76%)] Loss: -1528.478027\n",
      "Train Epoch: 3938 [56832/60000 (95%)] Loss: -1528.047241\n",
      "    epoch          : 3938\n",
      "    loss           : -1535.374814825543\n",
      "Train Epoch: 3939 [512/60000 (1%)] Loss: -1472.709839\n",
      "Train Epoch: 3939 [11776/60000 (20%)] Loss: -1445.277832\n",
      "Train Epoch: 3939 [23040/60000 (38%)] Loss: -1614.900635\n",
      "Train Epoch: 3939 [34304/60000 (57%)] Loss: -1525.376221\n",
      "Train Epoch: 3939 [45568/60000 (76%)] Loss: -1446.744873\n",
      "Train Epoch: 3939 [56832/60000 (95%)] Loss: -1521.839966\n",
      "    epoch          : 3939\n",
      "    loss           : -1526.6977673546742\n",
      "Train Epoch: 3940 [512/60000 (1%)] Loss: -1548.687134\n",
      "Train Epoch: 3940 [11776/60000 (20%)] Loss: -1525.592529\n",
      "Train Epoch: 3940 [23040/60000 (38%)] Loss: -1556.885864\n",
      "Train Epoch: 3940 [34304/60000 (57%)] Loss: -1496.690796\n",
      "Train Epoch: 3940 [45568/60000 (76%)] Loss: -1536.423828\n",
      "Train Epoch: 3940 [56832/60000 (95%)] Loss: -1478.768188\n",
      "    epoch          : 3940\n",
      "    loss           : -1532.4957268493997\n",
      "Train Epoch: 3941 [512/60000 (1%)] Loss: -1577.378906\n",
      "Train Epoch: 3941 [11776/60000 (20%)] Loss: -1544.434082\n",
      "Train Epoch: 3941 [23040/60000 (38%)] Loss: -1581.332764\n",
      "Train Epoch: 3941 [34304/60000 (57%)] Loss: -1516.031494\n",
      "Train Epoch: 3941 [45568/60000 (76%)] Loss: -1445.366821\n",
      "Train Epoch: 3941 [56832/60000 (95%)] Loss: -1593.521729\n",
      "    epoch          : 3941\n",
      "    loss           : -1528.2527655477577\n",
      "Train Epoch: 3942 [512/60000 (1%)] Loss: -1582.363647\n",
      "Train Epoch: 3942 [11776/60000 (20%)] Loss: -1423.594238\n",
      "Train Epoch: 3942 [23040/60000 (38%)] Loss: -1512.989258\n",
      "Train Epoch: 3942 [34304/60000 (57%)] Loss: -1591.790039\n",
      "Train Epoch: 3942 [45568/60000 (76%)] Loss: -1603.087280\n",
      "Train Epoch: 3942 [56832/60000 (95%)] Loss: -1615.352295\n",
      "    epoch          : 3942\n",
      "    loss           : -1530.0648862332275\n",
      "Train Epoch: 3943 [512/60000 (1%)] Loss: -1552.832153\n",
      "Train Epoch: 3943 [11776/60000 (20%)] Loss: -1460.188721\n",
      "Train Epoch: 3943 [23040/60000 (38%)] Loss: -1559.017212\n",
      "Train Epoch: 3943 [34304/60000 (57%)] Loss: -1558.576904\n",
      "Train Epoch: 3943 [45568/60000 (76%)] Loss: -1556.350708\n",
      "Train Epoch: 3943 [56832/60000 (95%)] Loss: -1496.267700\n",
      "    epoch          : 3943\n",
      "    loss           : -1535.4264436711026\n",
      "Train Epoch: 3944 [512/60000 (1%)] Loss: -1584.654053\n",
      "Train Epoch: 3944 [11776/60000 (20%)] Loss: -1539.911377\n",
      "Train Epoch: 3944 [23040/60000 (38%)] Loss: -1501.513306\n",
      "Train Epoch: 3944 [34304/60000 (57%)] Loss: -1470.149658\n",
      "Train Epoch: 3944 [45568/60000 (76%)] Loss: -1422.412109\n",
      "Train Epoch: 3944 [56832/60000 (95%)] Loss: -1503.802856\n",
      "    epoch          : 3944\n",
      "    loss           : -1523.1029969985877\n",
      "Train Epoch: 3945 [512/60000 (1%)] Loss: -1490.491455\n",
      "Train Epoch: 3945 [11776/60000 (20%)] Loss: -1507.561890\n",
      "Train Epoch: 3945 [23040/60000 (38%)] Loss: -1567.678223\n",
      "Train Epoch: 3945 [34304/60000 (57%)] Loss: -1555.314209\n",
      "Train Epoch: 3945 [45568/60000 (76%)] Loss: -1564.913574\n",
      "Train Epoch: 3945 [56832/60000 (95%)] Loss: -1540.885010\n",
      "    epoch          : 3945\n",
      "    loss           : -1530.8444924219855\n",
      "Train Epoch: 3946 [512/60000 (1%)] Loss: -1590.481689\n",
      "Train Epoch: 3946 [11776/60000 (20%)] Loss: -1523.794678\n",
      "Train Epoch: 3946 [23040/60000 (38%)] Loss: -1543.046143\n",
      "Train Epoch: 3946 [34304/60000 (57%)] Loss: -1465.303955\n",
      "Train Epoch: 3946 [45568/60000 (76%)] Loss: -1589.900879\n",
      "Train Epoch: 3946 [56832/60000 (95%)] Loss: -1594.684692\n",
      "    epoch          : 3946\n",
      "    loss           : -1527.8196780102403\n",
      "Train Epoch: 3947 [512/60000 (1%)] Loss: -1515.464111\n",
      "Train Epoch: 3947 [11776/60000 (20%)] Loss: -1565.176758\n",
      "Train Epoch: 3947 [23040/60000 (38%)] Loss: -1596.978149\n",
      "Train Epoch: 3947 [34304/60000 (57%)] Loss: -1508.809937\n",
      "Train Epoch: 3947 [45568/60000 (76%)] Loss: -1500.099854\n",
      "Train Epoch: 3947 [56832/60000 (95%)] Loss: -1582.396729\n",
      "    epoch          : 3947\n",
      "    loss           : -1529.5902440992452\n",
      "Train Epoch: 3948 [512/60000 (1%)] Loss: -1496.011841\n",
      "Train Epoch: 3948 [11776/60000 (20%)] Loss: -1565.744873\n",
      "Train Epoch: 3948 [23040/60000 (38%)] Loss: -1614.944824\n",
      "Train Epoch: 3948 [34304/60000 (57%)] Loss: -1506.807495\n",
      "Train Epoch: 3948 [45568/60000 (76%)] Loss: -1488.005005\n",
      "Train Epoch: 3948 [56832/60000 (95%)] Loss: -1486.541260\n",
      "    epoch          : 3948\n",
      "    loss           : -1533.4006758005607\n",
      "Train Epoch: 3949 [512/60000 (1%)] Loss: -1573.251709\n",
      "Train Epoch: 3949 [11776/60000 (20%)] Loss: -1584.175537\n",
      "Train Epoch: 3949 [23040/60000 (38%)] Loss: -1561.162842\n",
      "Train Epoch: 3949 [34304/60000 (57%)] Loss: -1590.572754\n",
      "Train Epoch: 3949 [45568/60000 (76%)] Loss: -1429.913330\n",
      "Train Epoch: 3949 [56832/60000 (95%)] Loss: -1596.093750\n",
      "    epoch          : 3949\n",
      "    loss           : -1528.7521131267656\n",
      "Train Epoch: 3950 [512/60000 (1%)] Loss: -1579.361694\n",
      "Train Epoch: 3950 [11776/60000 (20%)] Loss: -1512.500854\n",
      "Train Epoch: 3950 [23040/60000 (38%)] Loss: -1555.393799\n",
      "Train Epoch: 3950 [34304/60000 (57%)] Loss: -1573.546875\n",
      "Train Epoch: 3950 [45568/60000 (76%)] Loss: -1561.855469\n",
      "Train Epoch: 3950 [56832/60000 (95%)] Loss: -1524.371948\n",
      "    epoch          : 3950\n",
      "    loss           : -1523.902856514279\n",
      "Train Epoch: 3951 [512/60000 (1%)] Loss: -1498.090088\n",
      "Train Epoch: 3951 [11776/60000 (20%)] Loss: -1553.798828\n",
      "Train Epoch: 3951 [23040/60000 (38%)] Loss: -1612.886841\n",
      "Train Epoch: 3951 [34304/60000 (57%)] Loss: -1496.444336\n",
      "Train Epoch: 3951 [45568/60000 (76%)] Loss: -1531.140747\n",
      "Train Epoch: 3951 [56832/60000 (95%)] Loss: -1534.272095\n",
      "    epoch          : 3951\n",
      "    loss           : -1527.7985760532529\n",
      "Train Epoch: 3952 [512/60000 (1%)] Loss: -1580.036865\n",
      "Train Epoch: 3952 [11776/60000 (20%)] Loss: -1571.842285\n",
      "Train Epoch: 3952 [23040/60000 (38%)] Loss: -1506.328491\n",
      "Train Epoch: 3952 [34304/60000 (57%)] Loss: -1446.424194\n",
      "Train Epoch: 3952 [45568/60000 (76%)] Loss: -1555.277344\n",
      "Train Epoch: 3952 [56832/60000 (95%)] Loss: -1575.122925\n",
      "    epoch          : 3952\n",
      "    loss           : -1528.8326764295332\n",
      "Train Epoch: 3953 [512/60000 (1%)] Loss: -1497.026855\n",
      "Train Epoch: 3953 [11776/60000 (20%)] Loss: -1492.445435\n",
      "Train Epoch: 3953 [23040/60000 (38%)] Loss: -1577.609619\n",
      "Train Epoch: 3953 [34304/60000 (57%)] Loss: -1439.698486\n",
      "Train Epoch: 3953 [45568/60000 (76%)] Loss: -1554.032593\n",
      "Train Epoch: 3953 [56832/60000 (95%)] Loss: -1567.542725\n",
      "    epoch          : 3953\n",
      "    loss           : -1525.1897145071946\n",
      "Train Epoch: 3954 [512/60000 (1%)] Loss: -1523.777466\n",
      "Train Epoch: 3954 [11776/60000 (20%)] Loss: -1533.521484\n",
      "Train Epoch: 3954 [23040/60000 (38%)] Loss: -1495.467163\n",
      "Train Epoch: 3954 [34304/60000 (57%)] Loss: -1581.225464\n",
      "Train Epoch: 3954 [45568/60000 (76%)] Loss: -1514.857300\n",
      "Train Epoch: 3954 [56832/60000 (95%)] Loss: -1588.287598\n",
      "    epoch          : 3954\n",
      "    loss           : -1526.0728804593705\n",
      "Train Epoch: 3955 [512/60000 (1%)] Loss: -1518.030762\n",
      "Train Epoch: 3955 [11776/60000 (20%)] Loss: -1556.228882\n",
      "Train Epoch: 3955 [23040/60000 (38%)] Loss: -1518.159546\n",
      "Train Epoch: 3955 [34304/60000 (57%)] Loss: -1534.221802\n",
      "Train Epoch: 3955 [45568/60000 (76%)] Loss: -1543.648071\n",
      "Train Epoch: 3955 [56832/60000 (95%)] Loss: -1538.897217\n",
      "    epoch          : 3955\n",
      "    loss           : -1535.9245791677702\n",
      "Train Epoch: 3956 [512/60000 (1%)] Loss: -1556.317993\n",
      "Train Epoch: 3956 [11776/60000 (20%)] Loss: -1537.145386\n",
      "Train Epoch: 3956 [23040/60000 (38%)] Loss: -1454.563477\n",
      "Train Epoch: 3956 [34304/60000 (57%)] Loss: -1595.446655\n",
      "Train Epoch: 3956 [45568/60000 (76%)] Loss: -1576.754517\n",
      "Train Epoch: 3956 [56832/60000 (95%)] Loss: -1581.897705\n",
      "    epoch          : 3956\n",
      "    loss           : -1525.5687148961645\n",
      "Train Epoch: 3957 [512/60000 (1%)] Loss: -1479.937256\n",
      "Train Epoch: 3957 [11776/60000 (20%)] Loss: -1522.760498\n",
      "Train Epoch: 3957 [23040/60000 (38%)] Loss: -1516.894043\n",
      "Train Epoch: 3957 [34304/60000 (57%)] Loss: -1541.154907\n",
      "Train Epoch: 3957 [45568/60000 (76%)] Loss: -1576.481689\n",
      "Train Epoch: 3957 [56832/60000 (95%)] Loss: -1498.023315\n",
      "    epoch          : 3957\n",
      "    loss           : -1518.2512203582937\n",
      "Train Epoch: 3958 [512/60000 (1%)] Loss: -1503.649658\n",
      "Train Epoch: 3958 [11776/60000 (20%)] Loss: -1517.351929\n",
      "Train Epoch: 3958 [23040/60000 (38%)] Loss: -1581.005127\n",
      "Train Epoch: 3958 [34304/60000 (57%)] Loss: -1499.503662\n",
      "Train Epoch: 3958 [45568/60000 (76%)] Loss: -1410.437744\n",
      "Train Epoch: 3958 [56832/60000 (95%)] Loss: -1569.058228\n",
      "    epoch          : 3958\n",
      "    loss           : -1537.010300803319\n",
      "Train Epoch: 3959 [512/60000 (1%)] Loss: -1594.601074\n",
      "Train Epoch: 3959 [11776/60000 (20%)] Loss: -1542.356689\n",
      "Train Epoch: 3959 [23040/60000 (38%)] Loss: -1433.477051\n",
      "Train Epoch: 3959 [34304/60000 (57%)] Loss: -1541.117188\n",
      "Train Epoch: 3959 [45568/60000 (76%)] Loss: -1567.854980\n",
      "Train Epoch: 3959 [56832/60000 (95%)] Loss: -1452.851440\n",
      "    epoch          : 3959\n",
      "    loss           : -1534.9066717287915\n",
      "Train Epoch: 3960 [512/60000 (1%)] Loss: -1557.078003\n",
      "Train Epoch: 3960 [11776/60000 (20%)] Loss: -1476.999023\n",
      "Train Epoch: 3960 [23040/60000 (38%)] Loss: -1553.446045\n",
      "Train Epoch: 3960 [34304/60000 (57%)] Loss: -1564.109375\n",
      "Train Epoch: 3960 [45568/60000 (76%)] Loss: -1620.745605\n",
      "Train Epoch: 3960 [56832/60000 (95%)] Loss: -1572.852295\n",
      "    epoch          : 3960\n",
      "    loss           : -1535.524037851452\n",
      "Train Epoch: 3961 [512/60000 (1%)] Loss: -1464.223633\n",
      "Train Epoch: 3961 [11776/60000 (20%)] Loss: -1434.369385\n",
      "Train Epoch: 3961 [23040/60000 (38%)] Loss: -1506.767090\n",
      "Train Epoch: 3961 [34304/60000 (57%)] Loss: -1500.640503\n",
      "Train Epoch: 3961 [45568/60000 (76%)] Loss: -1521.904785\n",
      "Train Epoch: 3961 [56832/60000 (95%)] Loss: -1535.046753\n",
      "    epoch          : 3961\n",
      "    loss           : -1537.860608806718\n",
      "Train Epoch: 3962 [512/60000 (1%)] Loss: -1578.408813\n",
      "Train Epoch: 3962 [11776/60000 (20%)] Loss: -1481.421021\n",
      "Train Epoch: 3962 [23040/60000 (38%)] Loss: -1497.474609\n",
      "Train Epoch: 3962 [34304/60000 (57%)] Loss: -1507.745483\n",
      "Train Epoch: 3962 [45568/60000 (76%)] Loss: -1548.818115\n",
      "Train Epoch: 3962 [56832/60000 (95%)] Loss: -1502.779297\n",
      "    epoch          : 3962\n",
      "    loss           : -1531.4900674766068\n",
      "Train Epoch: 3963 [512/60000 (1%)] Loss: -1498.813599\n",
      "Train Epoch: 3963 [11776/60000 (20%)] Loss: -1549.425415\n",
      "Train Epoch: 3963 [23040/60000 (38%)] Loss: -1567.188843\n",
      "Train Epoch: 3963 [34304/60000 (57%)] Loss: -1507.749023\n",
      "Train Epoch: 3963 [45568/60000 (76%)] Loss: -1549.195312\n",
      "Train Epoch: 3963 [56832/60000 (95%)] Loss: -1455.101074\n",
      "    epoch          : 3963\n",
      "    loss           : -1537.095858988789\n",
      "Train Epoch: 3964 [512/60000 (1%)] Loss: -1524.038086\n",
      "Train Epoch: 3964 [11776/60000 (20%)] Loss: -1537.796753\n",
      "Train Epoch: 3964 [23040/60000 (38%)] Loss: -1529.706787\n",
      "Train Epoch: 3964 [34304/60000 (57%)] Loss: -1482.013916\n",
      "Train Epoch: 3964 [45568/60000 (76%)] Loss: -1548.323120\n",
      "Train Epoch: 3964 [56832/60000 (95%)] Loss: -1550.913574\n",
      "    epoch          : 3964\n",
      "    loss           : -1529.5738180559235\n",
      "Train Epoch: 3965 [512/60000 (1%)] Loss: -1481.121094\n",
      "Train Epoch: 3965 [11776/60000 (20%)] Loss: -1517.099365\n",
      "Train Epoch: 3965 [23040/60000 (38%)] Loss: -1586.727905\n",
      "Train Epoch: 3965 [34304/60000 (57%)] Loss: -1492.131714\n",
      "Train Epoch: 3965 [45568/60000 (76%)] Loss: -1502.655273\n",
      "Train Epoch: 3965 [56832/60000 (95%)] Loss: -1549.371948\n",
      "    epoch          : 3965\n",
      "    loss           : -1529.5186915855622\n",
      "Train Epoch: 3966 [512/60000 (1%)] Loss: -1597.339233\n",
      "Train Epoch: 3966 [11776/60000 (20%)] Loss: -1558.209839\n",
      "Train Epoch: 3966 [23040/60000 (38%)] Loss: -1525.517700\n",
      "Train Epoch: 3966 [34304/60000 (57%)] Loss: -1619.163696\n",
      "Train Epoch: 3966 [45568/60000 (76%)] Loss: -1477.291016\n",
      "Train Epoch: 3966 [56832/60000 (95%)] Loss: -1529.642578\n",
      "    epoch          : 3966\n",
      "    loss           : -1532.7343153441693\n",
      "Train Epoch: 3967 [512/60000 (1%)] Loss: -1567.271362\n",
      "Train Epoch: 3967 [11776/60000 (20%)] Loss: -1547.517456\n",
      "Train Epoch: 3967 [23040/60000 (38%)] Loss: -1515.651978\n",
      "Train Epoch: 3967 [34304/60000 (57%)] Loss: -1485.025879\n",
      "Train Epoch: 3967 [45568/60000 (76%)] Loss: -1533.303101\n",
      "Train Epoch: 3967 [56832/60000 (95%)] Loss: -1579.621948\n",
      "    epoch          : 3967\n",
      "    loss           : -1534.157338632702\n",
      "Train Epoch: 3968 [512/60000 (1%)] Loss: -1557.702881\n",
      "Train Epoch: 3968 [11776/60000 (20%)] Loss: -1559.148804\n",
      "Train Epoch: 3968 [23040/60000 (38%)] Loss: -1553.091553\n",
      "Train Epoch: 3968 [34304/60000 (57%)] Loss: -1581.355103\n",
      "Train Epoch: 3968 [45568/60000 (76%)] Loss: -1550.984009\n",
      "Train Epoch: 3968 [56832/60000 (95%)] Loss: -1425.455200\n",
      "    epoch          : 3968\n",
      "    loss           : -1530.2907070009048\n",
      "Train Epoch: 3969 [512/60000 (1%)] Loss: -1562.990967\n",
      "Train Epoch: 3969 [11776/60000 (20%)] Loss: -1557.050781\n",
      "Train Epoch: 3969 [23040/60000 (38%)] Loss: -1510.651978\n",
      "Train Epoch: 3969 [34304/60000 (57%)] Loss: -1508.628662\n",
      "Train Epoch: 3969 [45568/60000 (76%)] Loss: -1501.613770\n",
      "Train Epoch: 3969 [56832/60000 (95%)] Loss: -1452.831543\n",
      "    epoch          : 3969\n",
      "    loss           : -1518.1591914117673\n",
      "Train Epoch: 3970 [512/60000 (1%)] Loss: -1487.960693\n",
      "Train Epoch: 3970 [11776/60000 (20%)] Loss: -1549.354248\n",
      "Train Epoch: 3970 [23040/60000 (38%)] Loss: -1488.575684\n",
      "Train Epoch: 3970 [34304/60000 (57%)] Loss: -1504.734985\n",
      "Train Epoch: 3970 [45568/60000 (76%)] Loss: -1495.265991\n",
      "Train Epoch: 3970 [56832/60000 (95%)] Loss: -1497.615967\n",
      "    epoch          : 3970\n",
      "    loss           : -1535.397319901461\n",
      "Train Epoch: 3971 [512/60000 (1%)] Loss: -1490.567627\n",
      "Train Epoch: 3971 [11776/60000 (20%)] Loss: -1546.792725\n",
      "Train Epoch: 3971 [23040/60000 (38%)] Loss: -1487.220459\n",
      "Train Epoch: 3971 [34304/60000 (57%)] Loss: -1479.628662\n",
      "Train Epoch: 3971 [45568/60000 (76%)] Loss: -1500.451416\n",
      "Train Epoch: 3971 [56832/60000 (95%)] Loss: -1592.841309\n",
      "    epoch          : 3971\n",
      "    loss           : -1527.912550759181\n",
      "Train Epoch: 3972 [512/60000 (1%)] Loss: -1561.027588\n",
      "Train Epoch: 3972 [11776/60000 (20%)] Loss: -1521.521362\n",
      "Train Epoch: 3972 [23040/60000 (38%)] Loss: -1501.512329\n",
      "Train Epoch: 3972 [34304/60000 (57%)] Loss: -1527.406494\n",
      "Train Epoch: 3972 [45568/60000 (76%)] Loss: -1514.850098\n",
      "Train Epoch: 3972 [56832/60000 (95%)] Loss: -1545.099854\n",
      "    epoch          : 3972\n",
      "    loss           : -1532.8085289216983\n",
      "Train Epoch: 3973 [512/60000 (1%)] Loss: -1543.394775\n",
      "Train Epoch: 3973 [11776/60000 (20%)] Loss: -1575.299316\n",
      "Train Epoch: 3973 [23040/60000 (38%)] Loss: -1531.717773\n",
      "Train Epoch: 3973 [34304/60000 (57%)] Loss: -1562.181885\n",
      "Train Epoch: 3973 [45568/60000 (76%)] Loss: -1559.297119\n",
      "Train Epoch: 3973 [56832/60000 (95%)] Loss: -1541.922607\n",
      "    epoch          : 3973\n",
      "    loss           : -1527.9313247594457\n",
      "Train Epoch: 3974 [512/60000 (1%)] Loss: -1531.549438\n",
      "Train Epoch: 3974 [11776/60000 (20%)] Loss: -1548.745239\n",
      "Train Epoch: 3974 [23040/60000 (38%)] Loss: -1512.599854\n",
      "Train Epoch: 3974 [34304/60000 (57%)] Loss: -1579.483398\n",
      "Train Epoch: 3974 [45568/60000 (76%)] Loss: -1516.450806\n",
      "Train Epoch: 3974 [56832/60000 (95%)] Loss: -1528.930176\n",
      "    epoch          : 3974\n",
      "    loss           : -1529.9633247677216\n",
      "Train Epoch: 3975 [512/60000 (1%)] Loss: -1563.834473\n",
      "Train Epoch: 3975 [11776/60000 (20%)] Loss: -1539.387939\n",
      "Train Epoch: 3975 [23040/60000 (38%)] Loss: -1487.635132\n",
      "Train Epoch: 3975 [34304/60000 (57%)] Loss: -1494.219727\n",
      "Train Epoch: 3975 [45568/60000 (76%)] Loss: -1493.993164\n",
      "Train Epoch: 3975 [56832/60000 (95%)] Loss: -1547.645386\n",
      "    epoch          : 3975\n",
      "    loss           : -1524.9913561115156\n",
      "Train Epoch: 3976 [512/60000 (1%)] Loss: -1553.065308\n",
      "Train Epoch: 3976 [11776/60000 (20%)] Loss: -1591.168335\n",
      "Train Epoch: 3976 [23040/60000 (38%)] Loss: -1577.611084\n",
      "Train Epoch: 3976 [34304/60000 (57%)] Loss: -1600.177734\n",
      "Train Epoch: 3976 [45568/60000 (76%)] Loss: -1620.584229\n",
      "Train Epoch: 3976 [56832/60000 (95%)] Loss: -1489.046997\n",
      "    epoch          : 3976\n",
      "    loss           : -1532.7944491111625\n",
      "Train Epoch: 3977 [512/60000 (1%)] Loss: -1499.965942\n",
      "Train Epoch: 3977 [11776/60000 (20%)] Loss: -1543.027466\n",
      "Train Epoch: 3977 [23040/60000 (38%)] Loss: -1483.751953\n",
      "Train Epoch: 3977 [34304/60000 (57%)] Loss: -1536.276489\n",
      "Train Epoch: 3977 [45568/60000 (76%)] Loss: -1565.528076\n",
      "Train Epoch: 3977 [56832/60000 (95%)] Loss: -1556.958374\n",
      "    epoch          : 3977\n",
      "    loss           : -1526.2914811473781\n",
      "Train Epoch: 3978 [512/60000 (1%)] Loss: -1595.549438\n",
      "Train Epoch: 3978 [11776/60000 (20%)] Loss: -1561.901855\n",
      "Train Epoch: 3978 [23040/60000 (38%)] Loss: -1546.506958\n",
      "Train Epoch: 3978 [34304/60000 (57%)] Loss: -1502.186035\n",
      "Train Epoch: 3978 [45568/60000 (76%)] Loss: -1516.033936\n",
      "Train Epoch: 3978 [56832/60000 (95%)] Loss: -1502.444214\n",
      "    epoch          : 3978\n",
      "    loss           : -1532.1089884440103\n",
      "Train Epoch: 3979 [512/60000 (1%)] Loss: -1450.305176\n",
      "Train Epoch: 3979 [11776/60000 (20%)] Loss: -1525.689697\n",
      "Train Epoch: 3979 [23040/60000 (38%)] Loss: -1519.925171\n",
      "Train Epoch: 3979 [34304/60000 (57%)] Loss: -1515.712158\n",
      "Train Epoch: 3979 [45568/60000 (76%)] Loss: -1505.133667\n",
      "Train Epoch: 3979 [56832/60000 (95%)] Loss: -1500.930176\n",
      "    epoch          : 3979\n",
      "    loss           : -1530.5069169728768\n",
      "Train Epoch: 3980 [512/60000 (1%)] Loss: -1578.119141\n",
      "Train Epoch: 3980 [11776/60000 (20%)] Loss: -1492.111938\n",
      "Train Epoch: 3980 [23040/60000 (38%)] Loss: -1453.292480\n",
      "Train Epoch: 3980 [34304/60000 (57%)] Loss: -1522.723877\n",
      "Train Epoch: 3980 [45568/60000 (76%)] Loss: -1551.858765\n",
      "Train Epoch: 3980 [56832/60000 (95%)] Loss: -1521.261230\n",
      "    epoch          : 3980\n",
      "    loss           : -1530.859684313758\n",
      "Train Epoch: 3981 [512/60000 (1%)] Loss: -1496.566406\n",
      "Train Epoch: 3981 [11776/60000 (20%)] Loss: -1475.824097\n",
      "Train Epoch: 3981 [23040/60000 (38%)] Loss: -1503.574341\n",
      "Train Epoch: 3981 [34304/60000 (57%)] Loss: -1522.050903\n",
      "Train Epoch: 3981 [45568/60000 (76%)] Loss: -1564.497681\n",
      "Train Epoch: 3981 [56832/60000 (95%)] Loss: -1564.482056\n",
      "    epoch          : 3981\n",
      "    loss           : -1542.9546753619352\n",
      "Train Epoch: 3982 [512/60000 (1%)] Loss: -1561.913452\n",
      "Train Epoch: 3982 [11776/60000 (20%)] Loss: -1571.624634\n",
      "Train Epoch: 3982 [23040/60000 (38%)] Loss: -1503.860718\n",
      "Train Epoch: 3982 [34304/60000 (57%)] Loss: -1442.848511\n",
      "Train Epoch: 3982 [45568/60000 (76%)] Loss: -1566.688721\n",
      "Train Epoch: 3982 [56832/60000 (95%)] Loss: -1476.957520\n",
      "    epoch          : 3982\n",
      "    loss           : -1525.6826258082847\n",
      "Train Epoch: 3983 [512/60000 (1%)] Loss: -1572.291016\n",
      "Train Epoch: 3983 [11776/60000 (20%)] Loss: -1556.032837\n",
      "Train Epoch: 3983 [23040/60000 (38%)] Loss: -1547.869751\n",
      "Train Epoch: 3983 [34304/60000 (57%)] Loss: -1451.489746\n",
      "Train Epoch: 3983 [45568/60000 (76%)] Loss: -1518.619507\n",
      "Train Epoch: 3983 [56832/60000 (95%)] Loss: -1524.001953\n",
      "    epoch          : 3983\n",
      "    loss           : -1531.0998893780898\n",
      "Train Epoch: 3984 [512/60000 (1%)] Loss: -1515.603516\n",
      "Train Epoch: 3984 [11776/60000 (20%)] Loss: -1564.105957\n",
      "Train Epoch: 3984 [23040/60000 (38%)] Loss: -1519.865479\n",
      "Train Epoch: 3984 [34304/60000 (57%)] Loss: -1524.142944\n",
      "Train Epoch: 3984 [45568/60000 (76%)] Loss: -1570.967529\n",
      "Train Epoch: 3984 [56832/60000 (95%)] Loss: -1599.997314\n",
      "    epoch          : 3984\n",
      "    loss           : -1535.5365459205066\n",
      "Train Epoch: 3985 [512/60000 (1%)] Loss: -1541.063110\n",
      "Train Epoch: 3985 [11776/60000 (20%)] Loss: -1552.426392\n",
      "Train Epoch: 3985 [23040/60000 (38%)] Loss: -1590.742432\n",
      "Train Epoch: 3985 [34304/60000 (57%)] Loss: -1566.269287\n",
      "Train Epoch: 3985 [45568/60000 (76%)] Loss: -1521.701416\n",
      "Train Epoch: 3985 [56832/60000 (95%)] Loss: -1599.334473\n",
      "    epoch          : 3985\n",
      "    loss           : -1530.427974032817\n",
      "Train Epoch: 3986 [512/60000 (1%)] Loss: -1586.049683\n",
      "Train Epoch: 3986 [11776/60000 (20%)] Loss: -1530.298584\n",
      "Train Epoch: 3986 [23040/60000 (38%)] Loss: -1574.036011\n",
      "Train Epoch: 3986 [34304/60000 (57%)] Loss: -1492.016602\n",
      "Train Epoch: 3986 [45568/60000 (76%)] Loss: -1489.671509\n",
      "Train Epoch: 3986 [56832/60000 (95%)] Loss: -1529.996826\n",
      "    epoch          : 3986\n",
      "    loss           : -1530.5688569666975\n",
      "Train Epoch: 3987 [512/60000 (1%)] Loss: -1538.041748\n",
      "Train Epoch: 3987 [11776/60000 (20%)] Loss: -1557.783447\n",
      "Train Epoch: 3987 [23040/60000 (38%)] Loss: -1516.314087\n",
      "Train Epoch: 3987 [34304/60000 (57%)] Loss: -1489.755737\n",
      "Train Epoch: 3987 [45568/60000 (76%)] Loss: -1559.483398\n",
      "Train Epoch: 3987 [56832/60000 (95%)] Loss: -1533.450928\n",
      "    epoch          : 3987\n",
      "    loss           : -1534.24980172195\n",
      "Train Epoch: 3988 [512/60000 (1%)] Loss: -1524.856567\n",
      "Train Epoch: 3988 [11776/60000 (20%)] Loss: -1566.941650\n",
      "Train Epoch: 3988 [23040/60000 (38%)] Loss: -1521.265991\n",
      "Train Epoch: 3988 [34304/60000 (57%)] Loss: -1477.139526\n",
      "Train Epoch: 3988 [45568/60000 (76%)] Loss: -1567.940430\n",
      "Train Epoch: 3988 [56832/60000 (95%)] Loss: -1415.743896\n",
      "    epoch          : 3988\n",
      "    loss           : -1536.0820753884182\n",
      "Train Epoch: 3989 [512/60000 (1%)] Loss: -1563.467529\n",
      "Train Epoch: 3989 [11776/60000 (20%)] Loss: -1595.181763\n",
      "Train Epoch: 3989 [23040/60000 (38%)] Loss: -1519.592651\n",
      "Train Epoch: 3989 [34304/60000 (57%)] Loss: -1471.025635\n",
      "Train Epoch: 3989 [45568/60000 (76%)] Loss: -1511.869873\n",
      "Train Epoch: 3989 [56832/60000 (95%)] Loss: -1488.541504\n",
      "    epoch          : 3989\n",
      "    loss           : -1524.7807103388727\n",
      "Train Epoch: 3990 [512/60000 (1%)] Loss: -1519.928467\n",
      "Train Epoch: 3990 [11776/60000 (20%)] Loss: -1587.852905\n",
      "Train Epoch: 3990 [23040/60000 (38%)] Loss: -1585.631226\n",
      "Train Epoch: 3990 [34304/60000 (57%)] Loss: -1490.946899\n",
      "Train Epoch: 3990 [45568/60000 (76%)] Loss: -1610.324219\n",
      "Train Epoch: 3990 [56832/60000 (95%)] Loss: -1515.197021\n",
      "    epoch          : 3990\n",
      "    loss           : -1542.5296875689664\n",
      "Train Epoch: 3991 [512/60000 (1%)] Loss: -1595.943481\n",
      "Train Epoch: 3991 [11776/60000 (20%)] Loss: -1600.815918\n",
      "Train Epoch: 3991 [23040/60000 (38%)] Loss: -1520.959717\n",
      "Train Epoch: 3991 [34304/60000 (57%)] Loss: -1481.536743\n",
      "Train Epoch: 3991 [45568/60000 (76%)] Loss: -1594.793945\n",
      "Train Epoch: 3991 [56832/60000 (95%)] Loss: -1451.100586\n",
      "    epoch          : 3991\n",
      "    loss           : -1539.5437697933219\n",
      "Train Epoch: 3992 [512/60000 (1%)] Loss: -1587.145020\n",
      "Train Epoch: 3992 [11776/60000 (20%)] Loss: -1422.710083\n",
      "Train Epoch: 3992 [23040/60000 (38%)] Loss: -1557.279297\n",
      "Train Epoch: 3992 [34304/60000 (57%)] Loss: -1453.967529\n",
      "Train Epoch: 3992 [45568/60000 (76%)] Loss: -1556.718750\n",
      "Train Epoch: 3992 [56832/60000 (95%)] Loss: -1603.560547\n",
      "    epoch          : 3992\n",
      "    loss           : -1529.5555902685824\n",
      "Train Epoch: 3993 [512/60000 (1%)] Loss: -1521.166138\n",
      "Train Epoch: 3993 [11776/60000 (20%)] Loss: -1557.036987\n",
      "Train Epoch: 3993 [23040/60000 (38%)] Loss: -1491.683228\n",
      "Train Epoch: 3993 [34304/60000 (57%)] Loss: -1569.128662\n",
      "Train Epoch: 3993 [45568/60000 (76%)] Loss: -1510.376099\n",
      "Train Epoch: 3993 [56832/60000 (95%)] Loss: -1480.764771\n",
      "    epoch          : 3993\n",
      "    loss           : -1541.220137256687\n",
      "Train Epoch: 3994 [512/60000 (1%)] Loss: -1539.061523\n",
      "Train Epoch: 3994 [11776/60000 (20%)] Loss: -1596.516113\n",
      "Train Epoch: 3994 [23040/60000 (38%)] Loss: -1530.394165\n",
      "Train Epoch: 3994 [34304/60000 (57%)] Loss: -1519.259521\n",
      "Train Epoch: 3994 [45568/60000 (76%)] Loss: -1515.562378\n",
      "Train Epoch: 3994 [56832/60000 (95%)] Loss: -1552.620361\n",
      "    epoch          : 3994\n",
      "    loss           : -1534.4300812974489\n",
      "Train Epoch: 3995 [512/60000 (1%)] Loss: -1527.353760\n",
      "Train Epoch: 3995 [11776/60000 (20%)] Loss: -1508.264771\n",
      "Train Epoch: 3995 [23040/60000 (38%)] Loss: -1470.131836\n",
      "Train Epoch: 3995 [34304/60000 (57%)] Loss: -1561.079590\n",
      "Train Epoch: 3995 [45568/60000 (76%)] Loss: -1559.106445\n",
      "Train Epoch: 3995 [56832/60000 (95%)] Loss: -1578.634155\n",
      "    epoch          : 3995\n",
      "    loss           : -1527.7466865151616\n",
      "Train Epoch: 3996 [512/60000 (1%)] Loss: -1554.306885\n",
      "Train Epoch: 3996 [11776/60000 (20%)] Loss: -1507.221069\n",
      "Train Epoch: 3996 [23040/60000 (38%)] Loss: -1545.640137\n",
      "Train Epoch: 3996 [34304/60000 (57%)] Loss: -1468.456177\n",
      "Train Epoch: 3996 [45568/60000 (76%)] Loss: -1546.571533\n",
      "Train Epoch: 3996 [56832/60000 (95%)] Loss: -1560.958984\n",
      "    epoch          : 3996\n",
      "    loss           : -1523.0925227450787\n",
      "Train Epoch: 3997 [512/60000 (1%)] Loss: -1575.555420\n",
      "Train Epoch: 3997 [11776/60000 (20%)] Loss: -1544.418945\n",
      "Train Epoch: 3997 [23040/60000 (38%)] Loss: -1535.440430\n",
      "Train Epoch: 3997 [34304/60000 (57%)] Loss: -1560.136719\n",
      "Train Epoch: 3997 [45568/60000 (76%)] Loss: -1497.566040\n",
      "Train Epoch: 3997 [56832/60000 (95%)] Loss: -1538.804077\n",
      "    epoch          : 3997\n",
      "    loss           : -1532.6454147080244\n",
      "Train Epoch: 3998 [512/60000 (1%)] Loss: -1551.380493\n",
      "Train Epoch: 3998 [11776/60000 (20%)] Loss: -1487.518066\n",
      "Train Epoch: 3998 [23040/60000 (38%)] Loss: -1546.896362\n",
      "Train Epoch: 3998 [34304/60000 (57%)] Loss: -1575.299927\n",
      "Train Epoch: 3998 [45568/60000 (76%)] Loss: -1511.795166\n",
      "Train Epoch: 3998 [56832/60000 (95%)] Loss: -1585.984985\n",
      "    epoch          : 3998\n",
      "    loss           : -1539.357560152388\n",
      "Train Epoch: 3999 [512/60000 (1%)] Loss: -1631.361328\n",
      "Train Epoch: 3999 [11776/60000 (20%)] Loss: -1557.131836\n",
      "Train Epoch: 3999 [23040/60000 (38%)] Loss: -1588.586792\n",
      "Train Epoch: 3999 [34304/60000 (57%)] Loss: -1549.363892\n",
      "Train Epoch: 3999 [45568/60000 (76%)] Loss: -1503.862427\n",
      "Train Epoch: 3999 [56832/60000 (95%)] Loss: -1567.493164\n",
      "    epoch          : 3999\n",
      "    loss           : -1541.3730027365818\n",
      "Train Epoch: 4000 [512/60000 (1%)] Loss: -1465.102783\n",
      "Train Epoch: 4000 [11776/60000 (20%)] Loss: -1438.061523\n",
      "Train Epoch: 4000 [23040/60000 (38%)] Loss: -1591.404785\n",
      "Train Epoch: 4000 [34304/60000 (57%)] Loss: -1575.422363\n",
      "Train Epoch: 4000 [45568/60000 (76%)] Loss: -1593.092163\n",
      "Train Epoch: 4000 [56832/60000 (95%)] Loss: -1555.709839\n",
      "    epoch          : 4000\n",
      "    loss           : -1535.748040668035\n",
      "Saving checkpoint: saved/models/Mnist_DeepGenerativeOperad/0127_111843/checkpoint-epoch4000.pth ...\n",
      "Train Epoch: 4001 [512/60000 (1%)] Loss: -1560.740234\n",
      "Train Epoch: 4001 [11776/60000 (20%)] Loss: -1475.513916\n",
      "Train Epoch: 4001 [23040/60000 (38%)] Loss: -1569.425537\n",
      "Train Epoch: 4001 [34304/60000 (57%)] Loss: -1491.452271\n",
      "Train Epoch: 4001 [45568/60000 (76%)] Loss: -1598.549927\n",
      "Train Epoch: 4001 [56832/60000 (95%)] Loss: -1533.108643\n",
      "    epoch          : 4001\n",
      "    loss           : -1529.3697920114982\n",
      "Train Epoch: 4002 [512/60000 (1%)] Loss: -1518.718018\n",
      "Train Epoch: 4002 [11776/60000 (20%)] Loss: -1525.638672\n",
      "Train Epoch: 4002 [23040/60000 (38%)] Loss: -1572.990845\n",
      "Train Epoch: 4002 [34304/60000 (57%)] Loss: -1541.125854\n",
      "Train Epoch: 4002 [45568/60000 (76%)] Loss: -1558.686157\n",
      "Train Epoch: 4002 [56832/60000 (95%)] Loss: -1609.736450\n",
      "    epoch          : 4002\n",
      "    loss           : -1534.8866946118028\n",
      "Train Epoch: 4003 [512/60000 (1%)] Loss: -1588.588623\n",
      "Train Epoch: 4003 [11776/60000 (20%)] Loss: -1541.580322\n",
      "Train Epoch: 4003 [23040/60000 (38%)] Loss: -1516.722290\n",
      "Train Epoch: 4003 [34304/60000 (57%)] Loss: -1516.604614\n",
      "Train Epoch: 4003 [45568/60000 (76%)] Loss: -1539.960938\n",
      "Train Epoch: 4003 [56832/60000 (95%)] Loss: -1602.508057\n",
      "    epoch          : 4003\n",
      "    loss           : -1526.6951783605887\n",
      "Train Epoch: 4004 [512/60000 (1%)] Loss: -1592.023438\n",
      "Train Epoch: 4004 [11776/60000 (20%)] Loss: -1525.429443\n",
      "Train Epoch: 4004 [23040/60000 (38%)] Loss: -1481.421143\n",
      "Train Epoch: 4004 [34304/60000 (57%)] Loss: -1482.364746\n",
      "Train Epoch: 4004 [45568/60000 (76%)] Loss: -1547.989868\n",
      "Train Epoch: 4004 [56832/60000 (95%)] Loss: -1446.203735\n",
      "    epoch          : 4004\n",
      "    loss           : -1529.8107586014744\n",
      "Train Epoch: 4005 [512/60000 (1%)] Loss: -1517.295166\n",
      "Train Epoch: 4005 [11776/60000 (20%)] Loss: -1527.394531\n",
      "Train Epoch: 4005 [23040/60000 (38%)] Loss: -1479.201416\n",
      "Train Epoch: 4005 [34304/60000 (57%)] Loss: -1560.648193\n",
      "Train Epoch: 4005 [45568/60000 (76%)] Loss: -1485.336792\n",
      "Train Epoch: 4005 [56832/60000 (95%)] Loss: -1535.214600\n",
      "    epoch          : 4005\n",
      "    loss           : -1538.6454967778955\n",
      "Train Epoch: 4006 [512/60000 (1%)] Loss: -1507.090332\n",
      "Train Epoch: 4006 [11776/60000 (20%)] Loss: -1526.272095\n",
      "Train Epoch: 4006 [23040/60000 (38%)] Loss: -1609.821655\n",
      "Train Epoch: 4006 [34304/60000 (57%)] Loss: -1460.161621\n",
      "Train Epoch: 4006 [45568/60000 (76%)] Loss: -1567.728149\n",
      "Train Epoch: 4006 [56832/60000 (95%)] Loss: -1550.223511\n",
      "    epoch          : 4006\n",
      "    loss           : -1530.551744708907\n",
      "Train Epoch: 4007 [512/60000 (1%)] Loss: -1513.463501\n",
      "Train Epoch: 4007 [11776/60000 (20%)] Loss: -1604.002930\n",
      "Train Epoch: 4007 [23040/60000 (38%)] Loss: -1545.043457\n",
      "Train Epoch: 4007 [34304/60000 (57%)] Loss: -1479.312500\n",
      "Train Epoch: 4007 [45568/60000 (76%)] Loss: -1449.819458\n",
      "Train Epoch: 4007 [56832/60000 (95%)] Loss: -1520.317383\n",
      "    epoch          : 4007\n",
      "    loss           : -1534.0171726032838\n",
      "Train Epoch: 4008 [512/60000 (1%)] Loss: -1554.739868\n",
      "Train Epoch: 4008 [11776/60000 (20%)] Loss: -1567.132935\n",
      "Train Epoch: 4008 [23040/60000 (38%)] Loss: -1600.309326\n",
      "Train Epoch: 4008 [34304/60000 (57%)] Loss: -1496.643921\n",
      "Train Epoch: 4008 [45568/60000 (76%)] Loss: -1538.157227\n",
      "Train Epoch: 4008 [56832/60000 (95%)] Loss: -1424.704102\n",
      "    epoch          : 4008\n",
      "    loss           : -1535.3086196123543\n",
      "Train Epoch: 4009 [512/60000 (1%)] Loss: -1520.333008\n",
      "Train Epoch: 4009 [11776/60000 (20%)] Loss: -1552.183350\n",
      "Train Epoch: 4009 [23040/60000 (38%)] Loss: -1552.385986\n",
      "Train Epoch: 4009 [34304/60000 (57%)] Loss: -1545.339233\n",
      "Train Epoch: 4009 [45568/60000 (76%)] Loss: -1582.687256\n",
      "Train Epoch: 4009 [56832/60000 (95%)] Loss: -1559.766724\n",
      "    epoch          : 4009\n",
      "    loss           : -1531.7641394663665\n",
      "Train Epoch: 4010 [512/60000 (1%)] Loss: -1396.176025\n",
      "Train Epoch: 4010 [11776/60000 (20%)] Loss: -1590.307495\n",
      "Train Epoch: 4010 [23040/60000 (38%)] Loss: -1516.044678\n",
      "Train Epoch: 4010 [34304/60000 (57%)] Loss: -1567.465454\n",
      "Train Epoch: 4010 [45568/60000 (76%)] Loss: -1571.936768\n",
      "Train Epoch: 4010 [56832/60000 (95%)] Loss: -1562.529053\n",
      "    epoch          : 4010\n",
      "    loss           : -1544.6794181866835\n",
      "Train Epoch: 4011 [512/60000 (1%)] Loss: -1556.958374\n",
      "Train Epoch: 4011 [11776/60000 (20%)] Loss: -1481.236572\n",
      "Train Epoch: 4011 [23040/60000 (38%)] Loss: -1465.767700\n",
      "Train Epoch: 4011 [34304/60000 (57%)] Loss: -1565.725464\n",
      "Train Epoch: 4011 [45568/60000 (76%)] Loss: -1579.029785\n",
      "Train Epoch: 4011 [56832/60000 (95%)] Loss: -1530.171631\n",
      "    epoch          : 4011\n",
      "    loss           : -1540.3255060055835\n",
      "Train Epoch: 4012 [512/60000 (1%)] Loss: -1585.198730\n",
      "Train Epoch: 4012 [11776/60000 (20%)] Loss: -1618.474487\n",
      "Train Epoch: 4012 [23040/60000 (38%)] Loss: -1535.151489\n",
      "Train Epoch: 4012 [34304/60000 (57%)] Loss: -1504.275146\n",
      "Train Epoch: 4012 [45568/60000 (76%)] Loss: -1588.148438\n",
      "Train Epoch: 4012 [56832/60000 (95%)] Loss: -1465.590210\n",
      "    epoch          : 4012\n",
      "    loss           : -1532.4874891722943\n",
      "Train Epoch: 4013 [512/60000 (1%)] Loss: -1588.963867\n",
      "Train Epoch: 4013 [11776/60000 (20%)] Loss: -1546.838135\n",
      "Train Epoch: 4013 [23040/60000 (38%)] Loss: -1571.753296\n",
      "Train Epoch: 4013 [34304/60000 (57%)] Loss: -1571.756958\n",
      "Train Epoch: 4013 [45568/60000 (76%)] Loss: -1555.555908\n",
      "Train Epoch: 4013 [56832/60000 (95%)] Loss: -1576.220459\n",
      "    epoch          : 4013\n",
      "    loss           : -1532.4906040342514\n",
      "Train Epoch: 4014 [512/60000 (1%)] Loss: -1591.388550\n",
      "Train Epoch: 4014 [11776/60000 (20%)] Loss: -1536.517822\n",
      "Train Epoch: 4014 [23040/60000 (38%)] Loss: -1572.837036\n",
      "Train Epoch: 4014 [34304/60000 (57%)] Loss: -1502.209839\n",
      "Train Epoch: 4014 [45568/60000 (76%)] Loss: -1483.229858\n",
      "Train Epoch: 4014 [56832/60000 (95%)] Loss: -1507.820312\n",
      "    epoch          : 4014\n",
      "    loss           : -1530.433379609706\n",
      "Train Epoch: 4015 [512/60000 (1%)] Loss: -1555.488037\n",
      "Train Epoch: 4015 [11776/60000 (20%)] Loss: -1539.791748\n",
      "Train Epoch: 4015 [23040/60000 (38%)] Loss: -1551.193726\n",
      "Train Epoch: 4015 [34304/60000 (57%)] Loss: -1562.777710\n",
      "Train Epoch: 4015 [45568/60000 (76%)] Loss: -1507.382080\n",
      "Train Epoch: 4015 [56832/60000 (95%)] Loss: -1598.737061\n",
      "    epoch          : 4015\n",
      "    loss           : -1537.5372245486847\n",
      "Train Epoch: 4016 [512/60000 (1%)] Loss: -1471.706299\n",
      "Train Epoch: 4016 [11776/60000 (20%)] Loss: -1552.454590\n",
      "Train Epoch: 4016 [23040/60000 (38%)] Loss: -1542.059937\n",
      "Train Epoch: 4016 [34304/60000 (57%)] Loss: -1550.259033\n",
      "Train Epoch: 4016 [45568/60000 (76%)] Loss: -1515.094849\n",
      "Train Epoch: 4016 [56832/60000 (95%)] Loss: -1558.672974\n",
      "    epoch          : 4016\n",
      "    loss           : -1538.0787481103239\n",
      "Train Epoch: 4017 [512/60000 (1%)] Loss: -1563.841919\n",
      "Train Epoch: 4017 [11776/60000 (20%)] Loss: -1474.143555\n",
      "Train Epoch: 4017 [23040/60000 (38%)] Loss: -1549.944092\n",
      "Train Epoch: 4017 [34304/60000 (57%)] Loss: -1545.972412\n",
      "Train Epoch: 4017 [45568/60000 (76%)] Loss: -1563.468018\n",
      "Train Epoch: 4017 [56832/60000 (95%)] Loss: -1580.499878\n",
      "    epoch          : 4017\n",
      "    loss           : -1534.6790240444034\n",
      "Train Epoch: 4018 [512/60000 (1%)] Loss: -1576.874634\n",
      "Train Epoch: 4018 [11776/60000 (20%)] Loss: -1553.031006\n",
      "Train Epoch: 4018 [23040/60000 (38%)] Loss: -1568.189819\n",
      "Train Epoch: 4018 [34304/60000 (57%)] Loss: -1427.491211\n",
      "Train Epoch: 4018 [45568/60000 (76%)] Loss: -1470.801758\n",
      "Train Epoch: 4018 [56832/60000 (95%)] Loss: -1496.009766\n",
      "    epoch          : 4018\n",
      "    loss           : -1526.1483016364318\n",
      "Train Epoch: 4019 [512/60000 (1%)] Loss: -1516.854614\n",
      "Train Epoch: 4019 [11776/60000 (20%)] Loss: -1423.371582\n",
      "Train Epoch: 4019 [23040/60000 (38%)] Loss: -1490.561035\n",
      "Train Epoch: 4019 [34304/60000 (57%)] Loss: -1457.348999\n",
      "Train Epoch: 4019 [45568/60000 (76%)] Loss: -1453.152344\n",
      "Train Epoch: 4019 [56832/60000 (95%)] Loss: -1496.005737\n",
      "    epoch          : 4019\n",
      "    loss           : -1519.6852213541665\n",
      "Train Epoch: 4020 [512/60000 (1%)] Loss: -1455.468262\n",
      "Train Epoch: 4020 [11776/60000 (20%)] Loss: -1529.363770\n",
      "Train Epoch: 4020 [23040/60000 (38%)] Loss: -1598.779663\n",
      "Train Epoch: 4020 [34304/60000 (57%)] Loss: -1468.674438\n",
      "Train Epoch: 4020 [45568/60000 (76%)] Loss: -1538.151123\n",
      "Train Epoch: 4020 [56832/60000 (95%)] Loss: -1621.013672\n",
      "    epoch          : 4020\n",
      "    loss           : -1535.296591203765\n",
      "Train Epoch: 4021 [512/60000 (1%)] Loss: -1463.580566\n",
      "Train Epoch: 4021 [11776/60000 (20%)] Loss: -1490.848999\n",
      "Train Epoch: 4021 [23040/60000 (38%)] Loss: -1492.190674\n",
      "Train Epoch: 4021 [34304/60000 (57%)] Loss: -1559.301270\n",
      "Train Epoch: 4021 [45568/60000 (76%)] Loss: -1472.999268\n",
      "Train Epoch: 4021 [56832/60000 (95%)] Loss: -1536.354858\n",
      "    epoch          : 4021\n",
      "    loss           : -1525.7450247726872\n",
      "Train Epoch: 4022 [512/60000 (1%)] Loss: -1574.153564\n",
      "Train Epoch: 4022 [11776/60000 (20%)] Loss: -1558.958740\n",
      "Train Epoch: 4022 [23040/60000 (38%)] Loss: -1549.366699\n",
      "Train Epoch: 4022 [34304/60000 (57%)] Loss: -1546.479004\n",
      "Train Epoch: 4022 [45568/60000 (76%)] Loss: -1602.307983\n",
      "Train Epoch: 4022 [56832/60000 (95%)] Loss: -1593.160889\n",
      "    epoch          : 4022\n",
      "    loss           : -1536.6867555090262\n",
      "Train Epoch: 4023 [512/60000 (1%)] Loss: -1579.908569\n",
      "Train Epoch: 4023 [11776/60000 (20%)] Loss: -1466.615967\n",
      "Train Epoch: 4023 [23040/60000 (38%)] Loss: -1529.745361\n",
      "Train Epoch: 4023 [34304/60000 (57%)] Loss: -1523.248901\n",
      "Train Epoch: 4023 [45568/60000 (76%)] Loss: -1506.409302\n",
      "Train Epoch: 4023 [56832/60000 (95%)] Loss: -1497.574463\n",
      "    epoch          : 4023\n",
      "    loss           : -1534.8657761051156\n",
      "Train Epoch: 4024 [512/60000 (1%)] Loss: -1478.671387\n",
      "Train Epoch: 4024 [11776/60000 (20%)] Loss: -1498.418945\n",
      "Train Epoch: 4024 [23040/60000 (38%)] Loss: -1414.865845\n",
      "Train Epoch: 4024 [34304/60000 (57%)] Loss: -1576.169312\n",
      "Train Epoch: 4024 [45568/60000 (76%)] Loss: -1579.194336\n",
      "Train Epoch: 4024 [56832/60000 (95%)] Loss: -1524.209229\n",
      "    epoch          : 4024\n",
      "    loss           : -1526.648349223164\n",
      "Train Epoch: 4025 [512/60000 (1%)] Loss: -1586.193848\n",
      "Train Epoch: 4025 [11776/60000 (20%)] Loss: -1609.602173\n",
      "Train Epoch: 4025 [23040/60000 (38%)] Loss: -1589.539062\n",
      "Train Epoch: 4025 [34304/60000 (57%)] Loss: -1593.008301\n",
      "Train Epoch: 4025 [45568/60000 (76%)] Loss: -1518.750488\n",
      "Train Epoch: 4025 [56832/60000 (95%)] Loss: -1530.454834\n",
      "    epoch          : 4025\n",
      "    loss           : -1536.1184782038974\n",
      "Train Epoch: 4026 [512/60000 (1%)] Loss: -1464.866577\n",
      "Train Epoch: 4026 [11776/60000 (20%)] Loss: -1568.719360\n",
      "Train Epoch: 4026 [23040/60000 (38%)] Loss: -1467.917725\n",
      "Train Epoch: 4026 [34304/60000 (57%)] Loss: -1625.783936\n",
      "Train Epoch: 4026 [45568/60000 (76%)] Loss: -1570.684814\n",
      "Train Epoch: 4026 [56832/60000 (95%)] Loss: -1564.141235\n",
      "    epoch          : 4026\n",
      "    loss           : -1539.580769167108\n",
      "Train Epoch: 4027 [512/60000 (1%)] Loss: -1506.053711\n",
      "Train Epoch: 4027 [11776/60000 (20%)] Loss: -1492.983032\n",
      "Train Epoch: 4027 [23040/60000 (38%)] Loss: -1551.333740\n",
      "Train Epoch: 4027 [34304/60000 (57%)] Loss: -1479.987793\n",
      "Train Epoch: 4027 [45568/60000 (76%)] Loss: -1561.292480\n",
      "Train Epoch: 4027 [56832/60000 (95%)] Loss: -1521.605957\n",
      "    epoch          : 4027\n",
      "    loss           : -1530.2381043514963\n",
      "Train Epoch: 4028 [512/60000 (1%)] Loss: -1587.007690\n",
      "Train Epoch: 4028 [11776/60000 (20%)] Loss: -1520.481445\n",
      "Train Epoch: 4028 [23040/60000 (38%)] Loss: -1528.856689\n",
      "Train Epoch: 4028 [34304/60000 (57%)] Loss: -1458.120972\n",
      "Train Epoch: 4028 [45568/60000 (76%)] Loss: -1523.012207\n",
      "Train Epoch: 4028 [56832/60000 (95%)] Loss: -1543.965942\n",
      "    epoch          : 4028\n",
      "    loss           : -1541.9514722231418\n",
      "Train Epoch: 4029 [512/60000 (1%)] Loss: -1535.269775\n",
      "Train Epoch: 4029 [11776/60000 (20%)] Loss: -1500.328735\n",
      "Train Epoch: 4029 [23040/60000 (38%)] Loss: -1491.060791\n",
      "Train Epoch: 4029 [34304/60000 (57%)] Loss: -1527.210449\n",
      "Train Epoch: 4029 [45568/60000 (76%)] Loss: -1562.663574\n",
      "Train Epoch: 4029 [56832/60000 (95%)] Loss: -1544.203979\n",
      "    epoch          : 4029\n",
      "    loss           : -1533.9763573253224\n",
      "Train Epoch: 4030 [512/60000 (1%)] Loss: -1547.449097\n",
      "Train Epoch: 4030 [11776/60000 (20%)] Loss: -1495.251343\n",
      "Train Epoch: 4030 [23040/60000 (38%)] Loss: -1506.490356\n",
      "Train Epoch: 4030 [34304/60000 (57%)] Loss: -1578.971436\n",
      "Train Epoch: 4030 [45568/60000 (76%)] Loss: -1473.603760\n",
      "Train Epoch: 4030 [56832/60000 (95%)] Loss: -1596.745850\n",
      "    epoch          : 4030\n",
      "    loss           : -1533.4294474973517\n",
      "Train Epoch: 4031 [512/60000 (1%)] Loss: -1488.466187\n",
      "Train Epoch: 4031 [11776/60000 (20%)] Loss: -1549.837158\n",
      "Train Epoch: 4031 [23040/60000 (38%)] Loss: -1471.829712\n",
      "Train Epoch: 4031 [34304/60000 (57%)] Loss: -1570.747314\n",
      "Train Epoch: 4031 [45568/60000 (76%)] Loss: -1571.767212\n",
      "Train Epoch: 4031 [56832/60000 (95%)] Loss: -1520.303955\n",
      "    epoch          : 4031\n",
      "    loss           : -1542.2712116133694\n",
      "Train Epoch: 4032 [512/60000 (1%)] Loss: -1500.921631\n",
      "Train Epoch: 4032 [11776/60000 (20%)] Loss: -1540.381714\n",
      "Train Epoch: 4032 [23040/60000 (38%)] Loss: -1490.466553\n",
      "Train Epoch: 4032 [34304/60000 (57%)] Loss: -1612.795288\n",
      "Train Epoch: 4032 [45568/60000 (76%)] Loss: -1624.383667\n",
      "Train Epoch: 4032 [56832/60000 (95%)] Loss: -1457.636963\n",
      "    epoch          : 4032\n",
      "    loss           : -1537.2524231301861\n",
      "Train Epoch: 4033 [512/60000 (1%)] Loss: -1543.227051\n",
      "Train Epoch: 4033 [11776/60000 (20%)] Loss: -1485.087402\n",
      "Train Epoch: 4033 [23040/60000 (38%)] Loss: -1483.692627\n",
      "Train Epoch: 4033 [34304/60000 (57%)] Loss: -1624.425049\n",
      "Train Epoch: 4033 [45568/60000 (76%)] Loss: -1525.148315\n",
      "Train Epoch: 4033 [56832/60000 (95%)] Loss: -1559.832764\n",
      "    epoch          : 4033\n",
      "    loss           : -1541.231630486957\n",
      "Train Epoch: 4034 [512/60000 (1%)] Loss: -1500.705078\n",
      "Train Epoch: 4034 [11776/60000 (20%)] Loss: -1563.008057\n",
      "Train Epoch: 4034 [23040/60000 (38%)] Loss: -1507.761230\n",
      "Train Epoch: 4034 [34304/60000 (57%)] Loss: -1600.211182\n",
      "Train Epoch: 4034 [45568/60000 (76%)] Loss: -1543.502686\n",
      "Train Epoch: 4034 [56832/60000 (95%)] Loss: -1484.885010\n",
      "    epoch          : 4034\n",
      "    loss           : -1529.0919913599046\n",
      "Train Epoch: 4035 [512/60000 (1%)] Loss: -1532.078857\n",
      "Train Epoch: 4035 [11776/60000 (20%)] Loss: -1398.148804\n",
      "Train Epoch: 4035 [23040/60000 (38%)] Loss: -1530.022583\n",
      "Train Epoch: 4035 [34304/60000 (57%)] Loss: -1531.692505\n",
      "Train Epoch: 4035 [45568/60000 (76%)] Loss: -1497.447388\n",
      "Train Epoch: 4035 [56832/60000 (95%)] Loss: -1461.989746\n",
      "    epoch          : 4035\n",
      "    loss           : -1528.083928857146\n",
      "Train Epoch: 4036 [512/60000 (1%)] Loss: -1455.891113\n",
      "Train Epoch: 4036 [11776/60000 (20%)] Loss: -1470.866089\n",
      "Train Epoch: 4036 [23040/60000 (38%)] Loss: -1561.328125\n",
      "Train Epoch: 4036 [34304/60000 (57%)] Loss: -1545.656250\n",
      "Train Epoch: 4036 [45568/60000 (76%)] Loss: -1555.983032\n",
      "Train Epoch: 4036 [56832/60000 (95%)] Loss: -1464.830078\n",
      "    epoch          : 4036\n",
      "    loss           : -1535.4249277923066\n",
      "Train Epoch: 4037 [512/60000 (1%)] Loss: -1504.921509\n",
      "Train Epoch: 4037 [11776/60000 (20%)] Loss: -1527.291260\n",
      "Train Epoch: 4037 [23040/60000 (38%)] Loss: -1557.177368\n",
      "Train Epoch: 4037 [34304/60000 (57%)] Loss: -1577.136841\n",
      "Train Epoch: 4037 [45568/60000 (76%)] Loss: -1515.912354\n",
      "Train Epoch: 4037 [56832/60000 (95%)] Loss: -1596.913574\n",
      "    epoch          : 4037\n",
      "    loss           : -1538.976551810227\n",
      "Train Epoch: 4038 [512/60000 (1%)] Loss: -1578.648926\n",
      "Train Epoch: 4038 [11776/60000 (20%)] Loss: -1491.280029\n",
      "Train Epoch: 4038 [23040/60000 (38%)] Loss: -1503.239990\n",
      "Train Epoch: 4038 [34304/60000 (57%)] Loss: -1563.116333\n",
      "Train Epoch: 4038 [45568/60000 (76%)] Loss: -1502.021484\n",
      "Train Epoch: 4038 [56832/60000 (95%)] Loss: -1589.421143\n",
      "    epoch          : 4038\n",
      "    loss           : -1532.5844412765935\n",
      "Train Epoch: 4039 [512/60000 (1%)] Loss: -1499.833374\n",
      "Train Epoch: 4039 [11776/60000 (20%)] Loss: -1575.591431\n",
      "Train Epoch: 4039 [23040/60000 (38%)] Loss: -1489.520020\n",
      "Train Epoch: 4039 [34304/60000 (57%)] Loss: -1504.498291\n",
      "Train Epoch: 4039 [45568/60000 (76%)] Loss: -1623.475342\n",
      "Train Epoch: 4039 [56832/60000 (95%)] Loss: -1437.491577\n",
      "    epoch          : 4039\n",
      "    loss           : -1540.1924003989009\n",
      "Train Epoch: 4040 [512/60000 (1%)] Loss: -1545.427490\n",
      "Train Epoch: 4040 [11776/60000 (20%)] Loss: -1549.638184\n",
      "Train Epoch: 4040 [23040/60000 (38%)] Loss: -1494.869141\n",
      "Train Epoch: 4040 [34304/60000 (57%)] Loss: -1495.564941\n",
      "Train Epoch: 4040 [45568/60000 (76%)] Loss: -1542.588623\n",
      "Train Epoch: 4040 [56832/60000 (95%)] Loss: -1551.922363\n",
      "    epoch          : 4040\n",
      "    loss           : -1530.056413381113\n",
      "Train Epoch: 4041 [512/60000 (1%)] Loss: -1485.233643\n",
      "Train Epoch: 4041 [11776/60000 (20%)] Loss: -1569.939209\n",
      "Train Epoch: 4041 [23040/60000 (38%)] Loss: -1543.120850\n",
      "Train Epoch: 4041 [34304/60000 (57%)] Loss: -1587.799927\n",
      "Train Epoch: 4041 [45568/60000 (76%)] Loss: -1537.490601\n",
      "Train Epoch: 4041 [56832/60000 (95%)] Loss: -1496.094482\n",
      "    epoch          : 4041\n",
      "    loss           : -1532.5355279782398\n",
      "Train Epoch: 4042 [512/60000 (1%)] Loss: -1495.739014\n",
      "Train Epoch: 4042 [11776/60000 (20%)] Loss: -1500.407837\n",
      "Train Epoch: 4042 [23040/60000 (38%)] Loss: -1505.812866\n",
      "Train Epoch: 4042 [34304/60000 (57%)] Loss: -1513.903809\n",
      "Train Epoch: 4042 [45568/60000 (76%)] Loss: -1524.108765\n",
      "Train Epoch: 4042 [56832/60000 (95%)] Loss: -1455.887451\n",
      "    epoch          : 4042\n",
      "    loss           : -1530.3172469489318\n",
      "Train Epoch: 4043 [512/60000 (1%)] Loss: -1548.949219\n",
      "Train Epoch: 4043 [11776/60000 (20%)] Loss: -1504.663086\n",
      "Train Epoch: 4043 [23040/60000 (38%)] Loss: -1535.814209\n",
      "Train Epoch: 4043 [34304/60000 (57%)] Loss: -1529.421387\n",
      "Train Epoch: 4043 [45568/60000 (76%)] Loss: -1497.453247\n",
      "Train Epoch: 4043 [56832/60000 (95%)] Loss: -1517.935181\n",
      "    epoch          : 4043\n",
      "    loss           : -1528.8642391916048\n",
      "Train Epoch: 4044 [512/60000 (1%)] Loss: -1579.222412\n",
      "Train Epoch: 4044 [11776/60000 (20%)] Loss: -1529.652100\n",
      "Train Epoch: 4044 [23040/60000 (38%)] Loss: -1597.723999\n",
      "Train Epoch: 4044 [34304/60000 (57%)] Loss: -1573.850098\n",
      "Train Epoch: 4044 [45568/60000 (76%)] Loss: -1571.971191\n",
      "Train Epoch: 4044 [56832/60000 (95%)] Loss: -1554.297852\n",
      "    epoch          : 4044\n",
      "    loss           : -1537.2323508397333\n",
      "Train Epoch: 4045 [512/60000 (1%)] Loss: -1588.574951\n",
      "Train Epoch: 4045 [11776/60000 (20%)] Loss: -1507.267212\n",
      "Train Epoch: 4045 [23040/60000 (38%)] Loss: -1558.670532\n",
      "Train Epoch: 4045 [34304/60000 (57%)] Loss: -1577.006348\n",
      "Train Epoch: 4045 [45568/60000 (76%)] Loss: -1512.567261\n",
      "Train Epoch: 4045 [56832/60000 (95%)] Loss: -1543.187744\n",
      "    epoch          : 4045\n",
      "    loss           : -1534.7349712134753\n",
      "Train Epoch: 4046 [512/60000 (1%)] Loss: -1592.026245\n",
      "Train Epoch: 4046 [11776/60000 (20%)] Loss: -1587.903198\n",
      "Train Epoch: 4046 [23040/60000 (38%)] Loss: -1549.584106\n",
      "Train Epoch: 4046 [34304/60000 (57%)] Loss: -1556.157715\n",
      "Train Epoch: 4046 [45568/60000 (76%)] Loss: -1595.432373\n",
      "Train Epoch: 4046 [56832/60000 (95%)] Loss: -1401.447021\n",
      "    epoch          : 4046\n",
      "    loss           : -1534.2585442322122\n",
      "Train Epoch: 4047 [512/60000 (1%)] Loss: -1558.040894\n",
      "Train Epoch: 4047 [11776/60000 (20%)] Loss: -1564.534546\n",
      "Train Epoch: 4047 [23040/60000 (38%)] Loss: -1567.419189\n",
      "Train Epoch: 4047 [34304/60000 (57%)] Loss: -1591.337158\n",
      "Train Epoch: 4047 [45568/60000 (76%)] Loss: -1516.304565\n",
      "Train Epoch: 4047 [56832/60000 (95%)] Loss: -1452.936401\n",
      "    epoch          : 4047\n",
      "    loss           : -1535.3985016386387\n",
      "Train Epoch: 4048 [512/60000 (1%)] Loss: -1549.872314\n",
      "Train Epoch: 4048 [11776/60000 (20%)] Loss: -1563.278809\n",
      "Train Epoch: 4048 [23040/60000 (38%)] Loss: -1494.560547\n",
      "Train Epoch: 4048 [34304/60000 (57%)] Loss: -1546.984131\n",
      "Train Epoch: 4048 [45568/60000 (76%)] Loss: -1420.220459\n",
      "Train Epoch: 4048 [56832/60000 (95%)] Loss: -1554.344971\n",
      "    epoch          : 4048\n",
      "    loss           : -1529.3479307357873\n",
      "Train Epoch: 4049 [512/60000 (1%)] Loss: -1508.750000\n",
      "Train Epoch: 4049 [11776/60000 (20%)] Loss: -1561.079224\n",
      "Train Epoch: 4049 [23040/60000 (38%)] Loss: -1539.569702\n",
      "Train Epoch: 4049 [34304/60000 (57%)] Loss: -1523.716064\n",
      "Train Epoch: 4049 [45568/60000 (76%)] Loss: -1498.806152\n",
      "Train Epoch: 4049 [56832/60000 (95%)] Loss: -1519.070068\n",
      "    epoch          : 4049\n",
      "    loss           : -1540.4972875562764\n",
      "Train Epoch: 4050 [512/60000 (1%)] Loss: -1428.373047\n",
      "Train Epoch: 4050 [11776/60000 (20%)] Loss: -1480.590820\n",
      "Train Epoch: 4050 [23040/60000 (38%)] Loss: -1471.252808\n",
      "Train Epoch: 4050 [34304/60000 (57%)] Loss: -1503.623535\n",
      "Train Epoch: 4050 [45568/60000 (76%)] Loss: -1566.347900\n",
      "Train Epoch: 4050 [56832/60000 (95%)] Loss: -1544.526611\n",
      "    epoch          : 4050\n",
      "    loss           : -1535.3815438653116\n",
      "Train Epoch: 4051 [512/60000 (1%)] Loss: -1530.673706\n",
      "Train Epoch: 4051 [11776/60000 (20%)] Loss: -1563.173584\n",
      "Train Epoch: 4051 [23040/60000 (38%)] Loss: -1544.121094\n",
      "Train Epoch: 4051 [34304/60000 (57%)] Loss: -1491.886353\n",
      "Train Epoch: 4051 [45568/60000 (76%)] Loss: -1533.787964\n",
      "Train Epoch: 4051 [56832/60000 (95%)] Loss: -1542.812378\n",
      "    epoch          : 4051\n",
      "    loss           : -1530.722756595935\n",
      "Train Epoch: 4052 [512/60000 (1%)] Loss: -1492.550537\n",
      "Train Epoch: 4052 [11776/60000 (20%)] Loss: -1600.119873\n",
      "Train Epoch: 4052 [23040/60000 (38%)] Loss: -1465.340210\n",
      "Train Epoch: 4052 [34304/60000 (57%)] Loss: -1467.582642\n",
      "Train Epoch: 4052 [45568/60000 (76%)] Loss: -1521.913330\n",
      "Train Epoch: 4052 [56832/60000 (95%)] Loss: -1552.473389\n",
      "    epoch          : 4052\n",
      "    loss           : -1529.8873466879634\n",
      "Train Epoch: 4053 [512/60000 (1%)] Loss: -1538.184326\n",
      "Train Epoch: 4053 [11776/60000 (20%)] Loss: -1477.165527\n",
      "Train Epoch: 4053 [23040/60000 (38%)] Loss: -1542.233276\n",
      "Train Epoch: 4053 [34304/60000 (57%)] Loss: -1612.360962\n",
      "Train Epoch: 4053 [45568/60000 (76%)] Loss: -1575.456421\n",
      "Train Epoch: 4053 [56832/60000 (95%)] Loss: -1460.147217\n",
      "    epoch          : 4053\n",
      "    loss           : -1532.7660925913665\n",
      "Train Epoch: 4054 [512/60000 (1%)] Loss: -1502.180054\n",
      "Train Epoch: 4054 [11776/60000 (20%)] Loss: -1597.013916\n",
      "Train Epoch: 4054 [23040/60000 (38%)] Loss: -1533.352051\n",
      "Train Epoch: 4054 [34304/60000 (57%)] Loss: -1537.525879\n",
      "Train Epoch: 4054 [45568/60000 (76%)] Loss: -1526.142578\n",
      "Train Epoch: 4054 [56832/60000 (95%)] Loss: -1583.792114\n",
      "    epoch          : 4054\n",
      "    loss           : -1537.5844767942267\n",
      "Train Epoch: 4055 [512/60000 (1%)] Loss: -1484.990601\n",
      "Train Epoch: 4055 [11776/60000 (20%)] Loss: -1610.303101\n",
      "Train Epoch: 4055 [23040/60000 (38%)] Loss: -1589.938721\n",
      "Train Epoch: 4055 [34304/60000 (57%)] Loss: -1559.876953\n",
      "Train Epoch: 4055 [45568/60000 (76%)] Loss: -1513.774414\n",
      "Train Epoch: 4055 [56832/60000 (95%)] Loss: -1581.619019\n",
      "    epoch          : 4055\n",
      "    loss           : -1541.724019023658\n",
      "Train Epoch: 4056 [512/60000 (1%)] Loss: -1532.777344\n",
      "Train Epoch: 4056 [11776/60000 (20%)] Loss: -1555.030396\n",
      "Train Epoch: 4056 [23040/60000 (38%)] Loss: -1553.067749\n",
      "Train Epoch: 4056 [34304/60000 (57%)] Loss: -1483.192627\n",
      "Train Epoch: 4056 [45568/60000 (76%)] Loss: -1433.851074\n",
      "Train Epoch: 4056 [56832/60000 (95%)] Loss: -1588.502441\n",
      "    epoch          : 4056\n",
      "    loss           : -1537.3888363595736\n",
      "Train Epoch: 4057 [512/60000 (1%)] Loss: -1585.176758\n",
      "Train Epoch: 4057 [11776/60000 (20%)] Loss: -1516.094482\n",
      "Train Epoch: 4057 [23040/60000 (38%)] Loss: -1534.134399\n",
      "Train Epoch: 4057 [34304/60000 (57%)] Loss: -1588.467529\n",
      "Train Epoch: 4057 [45568/60000 (76%)] Loss: -1429.825684\n",
      "Train Epoch: 4057 [56832/60000 (95%)] Loss: -1518.741699\n",
      "    epoch          : 4057\n",
      "    loss           : -1534.4916126660708\n",
      "Train Epoch: 4058 [512/60000 (1%)] Loss: -1618.037476\n",
      "Train Epoch: 4058 [11776/60000 (20%)] Loss: -1531.660156\n",
      "Train Epoch: 4058 [23040/60000 (38%)] Loss: -1568.397827\n",
      "Train Epoch: 4058 [34304/60000 (57%)] Loss: -1536.258911\n",
      "Train Epoch: 4058 [45568/60000 (76%)] Loss: -1470.214355\n",
      "Train Epoch: 4058 [56832/60000 (95%)] Loss: -1583.151978\n",
      "    epoch          : 4058\n",
      "    loss           : -1542.8272449902895\n",
      "Train Epoch: 4059 [512/60000 (1%)] Loss: -1480.748779\n",
      "Train Epoch: 4059 [11776/60000 (20%)] Loss: -1548.790161\n",
      "Train Epoch: 4059 [23040/60000 (38%)] Loss: -1496.109985\n",
      "Train Epoch: 4059 [34304/60000 (57%)] Loss: -1578.221924\n",
      "Train Epoch: 4059 [45568/60000 (76%)] Loss: -1602.799561\n",
      "Train Epoch: 4059 [56832/60000 (95%)] Loss: -1590.136108\n",
      "    epoch          : 4059\n",
      "    loss           : -1528.8670602572167\n",
      "Train Epoch: 4060 [512/60000 (1%)] Loss: -1528.036987\n",
      "Train Epoch: 4060 [11776/60000 (20%)] Loss: -1416.195312\n",
      "Train Epoch: 4060 [23040/60000 (38%)] Loss: -1519.407959\n",
      "Train Epoch: 4060 [34304/60000 (57%)] Loss: -1559.346924\n",
      "Train Epoch: 4060 [45568/60000 (76%)] Loss: -1512.064209\n",
      "Train Epoch: 4060 [56832/60000 (95%)] Loss: -1527.156738\n",
      "    epoch          : 4060\n",
      "    loss           : -1537.42864404021\n",
      "Train Epoch: 4061 [512/60000 (1%)] Loss: -1501.093262\n",
      "Train Epoch: 4061 [11776/60000 (20%)] Loss: -1498.152954\n",
      "Train Epoch: 4061 [23040/60000 (38%)] Loss: -1575.957764\n",
      "Train Epoch: 4061 [34304/60000 (57%)] Loss: -1497.717041\n",
      "Train Epoch: 4061 [45568/60000 (76%)] Loss: -1580.142090\n",
      "Train Epoch: 4061 [56832/60000 (95%)] Loss: -1548.570801\n",
      "    epoch          : 4061\n",
      "    loss           : -1528.4453614660574\n",
      "Train Epoch: 4062 [512/60000 (1%)] Loss: -1513.323486\n",
      "Train Epoch: 4062 [11776/60000 (20%)] Loss: -1498.865845\n",
      "Train Epoch: 4062 [23040/60000 (38%)] Loss: -1558.270630\n",
      "Train Epoch: 4062 [34304/60000 (57%)] Loss: -1593.354492\n",
      "Train Epoch: 4062 [45568/60000 (76%)] Loss: -1518.132812\n",
      "Train Epoch: 4062 [56832/60000 (95%)] Loss: -1504.696167\n",
      "    epoch          : 4062\n",
      "    loss           : -1532.7656122412386\n",
      "Train Epoch: 4063 [512/60000 (1%)] Loss: -1580.446045\n",
      "Train Epoch: 4063 [11776/60000 (20%)] Loss: -1554.255371\n",
      "Train Epoch: 4063 [23040/60000 (38%)] Loss: -1458.684204\n",
      "Train Epoch: 4063 [34304/60000 (57%)] Loss: -1459.486328\n",
      "Train Epoch: 4063 [45568/60000 (76%)] Loss: -1541.237061\n",
      "Train Epoch: 4063 [56832/60000 (95%)] Loss: -1590.966797\n",
      "    epoch          : 4063\n",
      "    loss           : -1526.7962111995719\n",
      "Train Epoch: 4064 [512/60000 (1%)] Loss: -1590.606445\n",
      "Train Epoch: 4064 [11776/60000 (20%)] Loss: -1513.036377\n",
      "Train Epoch: 4064 [23040/60000 (38%)] Loss: -1493.997070\n",
      "Train Epoch: 4064 [34304/60000 (57%)] Loss: -1522.198242\n",
      "Train Epoch: 4064 [45568/60000 (76%)] Loss: -1539.721313\n",
      "Train Epoch: 4064 [56832/60000 (95%)] Loss: -1453.192627\n",
      "    epoch          : 4064\n",
      "    loss           : -1540.5268585722324\n",
      "Train Epoch: 4065 [512/60000 (1%)] Loss: -1490.632446\n",
      "Train Epoch: 4065 [11776/60000 (20%)] Loss: -1546.622803\n",
      "Train Epoch: 4065 [23040/60000 (38%)] Loss: -1479.972656\n",
      "Train Epoch: 4065 [34304/60000 (57%)] Loss: -1515.438965\n",
      "Train Epoch: 4065 [45568/60000 (76%)] Loss: -1608.116577\n",
      "Train Epoch: 4065 [56832/60000 (95%)] Loss: -1490.983643\n",
      "    epoch          : 4065\n",
      "    loss           : -1534.6943873173773\n",
      "Train Epoch: 4066 [512/60000 (1%)] Loss: -1460.151855\n",
      "Train Epoch: 4066 [11776/60000 (20%)] Loss: -1548.198242\n",
      "Train Epoch: 4066 [23040/60000 (38%)] Loss: -1572.674561\n",
      "Train Epoch: 4066 [34304/60000 (57%)] Loss: -1469.988525\n",
      "Train Epoch: 4066 [45568/60000 (76%)] Loss: -1530.004150\n",
      "Train Epoch: 4066 [56832/60000 (95%)] Loss: -1627.924194\n",
      "    epoch          : 4066\n",
      "    loss           : -1534.773991988877\n",
      "Train Epoch: 4067 [512/60000 (1%)] Loss: -1523.436401\n",
      "Train Epoch: 4067 [11776/60000 (20%)] Loss: -1623.518433\n",
      "Train Epoch: 4067 [23040/60000 (38%)] Loss: -1517.889526\n",
      "Train Epoch: 4067 [34304/60000 (57%)] Loss: -1446.074463\n",
      "Train Epoch: 4067 [45568/60000 (76%)] Loss: -1614.775269\n",
      "Train Epoch: 4067 [56832/60000 (95%)] Loss: -1585.611938\n",
      "    epoch          : 4067\n",
      "    loss           : -1538.230966686529\n",
      "Train Epoch: 4068 [512/60000 (1%)] Loss: -1537.640503\n",
      "Train Epoch: 4068 [11776/60000 (20%)] Loss: -1480.980225\n",
      "Train Epoch: 4068 [23040/60000 (38%)] Loss: -1604.156006\n",
      "Train Epoch: 4068 [34304/60000 (57%)] Loss: -1555.498047\n",
      "Train Epoch: 4068 [45568/60000 (76%)] Loss: -1527.663940\n",
      "Train Epoch: 4068 [56832/60000 (95%)] Loss: -1480.042847\n",
      "    epoch          : 4068\n",
      "    loss           : -1533.8056378553144\n",
      "Train Epoch: 4069 [512/60000 (1%)] Loss: -1563.053345\n",
      "Train Epoch: 4069 [11776/60000 (20%)] Loss: -1484.791504\n",
      "Train Epoch: 4069 [23040/60000 (38%)] Loss: -1552.596436\n",
      "Train Epoch: 4069 [34304/60000 (57%)] Loss: -1577.156982\n",
      "Train Epoch: 4069 [45568/60000 (76%)] Loss: -1546.447754\n",
      "Train Epoch: 4069 [56832/60000 (95%)] Loss: -1475.982666\n",
      "    epoch          : 4069\n",
      "    loss           : -1534.0753587625795\n",
      "Train Epoch: 4070 [512/60000 (1%)] Loss: -1558.266479\n",
      "Train Epoch: 4070 [11776/60000 (20%)] Loss: -1596.223633\n",
      "Train Epoch: 4070 [23040/60000 (38%)] Loss: -1541.175049\n",
      "Train Epoch: 4070 [34304/60000 (57%)] Loss: -1589.596436\n",
      "Train Epoch: 4070 [45568/60000 (76%)] Loss: -1592.687500\n",
      "Train Epoch: 4070 [56832/60000 (95%)] Loss: -1538.205078\n",
      "    epoch          : 4070\n",
      "    loss           : -1539.7780775512006\n",
      "Train Epoch: 4071 [512/60000 (1%)] Loss: -1562.506348\n",
      "Train Epoch: 4071 [11776/60000 (20%)] Loss: -1531.461792\n",
      "Train Epoch: 4071 [23040/60000 (38%)] Loss: -1536.175415\n",
      "Train Epoch: 4071 [34304/60000 (57%)] Loss: -1470.143188\n",
      "Train Epoch: 4071 [45568/60000 (76%)] Loss: -1581.472290\n",
      "Train Epoch: 4071 [56832/60000 (95%)] Loss: -1489.935303\n",
      "    epoch          : 4071\n",
      "    loss           : -1539.5129625568281\n",
      "Train Epoch: 4072 [512/60000 (1%)] Loss: -1571.638672\n",
      "Train Epoch: 4072 [11776/60000 (20%)] Loss: -1510.358643\n",
      "Train Epoch: 4072 [23040/60000 (38%)] Loss: -1505.924072\n",
      "Train Epoch: 4072 [34304/60000 (57%)] Loss: -1553.473145\n",
      "Train Epoch: 4072 [45568/60000 (76%)] Loss: -1497.484985\n",
      "Train Epoch: 4072 [56832/60000 (95%)] Loss: -1467.214111\n",
      "    epoch          : 4072\n",
      "    loss           : -1540.8089589264434\n",
      "Train Epoch: 4073 [512/60000 (1%)] Loss: -1509.277344\n",
      "Train Epoch: 4073 [11776/60000 (20%)] Loss: -1591.881592\n",
      "Train Epoch: 4073 [23040/60000 (38%)] Loss: -1546.303223\n",
      "Train Epoch: 4073 [34304/60000 (57%)] Loss: -1536.165405\n",
      "Train Epoch: 4073 [45568/60000 (76%)] Loss: -1552.185303\n",
      "Train Epoch: 4073 [56832/60000 (95%)] Loss: -1533.388672\n",
      "    epoch          : 4073\n",
      "    loss           : -1537.7663694909738\n",
      "Train Epoch: 4074 [512/60000 (1%)] Loss: -1533.962646\n",
      "Train Epoch: 4074 [11776/60000 (20%)] Loss: -1509.343140\n",
      "Train Epoch: 4074 [23040/60000 (38%)] Loss: -1505.623535\n",
      "Train Epoch: 4074 [34304/60000 (57%)] Loss: -1590.445312\n",
      "Train Epoch: 4074 [45568/60000 (76%)] Loss: -1492.761230\n",
      "Train Epoch: 4074 [56832/60000 (95%)] Loss: -1553.558716\n",
      "    epoch          : 4074\n",
      "    loss           : -1539.631878351761\n",
      "Train Epoch: 4075 [512/60000 (1%)] Loss: -1530.021118\n",
      "Train Epoch: 4075 [11776/60000 (20%)] Loss: -1522.639160\n",
      "Train Epoch: 4075 [23040/60000 (38%)] Loss: -1600.171631\n",
      "Train Epoch: 4075 [34304/60000 (57%)] Loss: -1517.883667\n",
      "Train Epoch: 4075 [45568/60000 (76%)] Loss: -1506.264160\n",
      "Train Epoch: 4075 [56832/60000 (95%)] Loss: -1563.078613\n",
      "    epoch          : 4075\n",
      "    loss           : -1533.2458623681364\n",
      "Train Epoch: 4076 [512/60000 (1%)] Loss: -1576.537842\n",
      "Train Epoch: 4076 [11776/60000 (20%)] Loss: -1508.874878\n",
      "Train Epoch: 4076 [23040/60000 (38%)] Loss: -1549.016724\n",
      "Train Epoch: 4076 [34304/60000 (57%)] Loss: -1460.549072\n",
      "Train Epoch: 4076 [45568/60000 (76%)] Loss: -1484.657227\n",
      "Train Epoch: 4076 [56832/60000 (95%)] Loss: -1534.137573\n",
      "    epoch          : 4076\n",
      "    loss           : -1534.7573318050406\n",
      "Train Epoch: 4077 [512/60000 (1%)] Loss: -1510.610840\n",
      "Train Epoch: 4077 [11776/60000 (20%)] Loss: -1544.807129\n",
      "Train Epoch: 4077 [23040/60000 (38%)] Loss: -1462.329834\n",
      "Train Epoch: 4077 [34304/60000 (57%)] Loss: -1472.504150\n",
      "Train Epoch: 4077 [45568/60000 (76%)] Loss: -1536.758667\n",
      "Train Epoch: 4077 [56832/60000 (95%)] Loss: -1481.318237\n",
      "    epoch          : 4077\n",
      "    loss           : -1534.9977537683176\n",
      "Train Epoch: 4078 [512/60000 (1%)] Loss: -1627.636719\n",
      "Train Epoch: 4078 [11776/60000 (20%)] Loss: -1544.316406\n",
      "Train Epoch: 4078 [23040/60000 (38%)] Loss: -1443.122314\n",
      "Train Epoch: 4078 [34304/60000 (57%)] Loss: -1533.054443\n",
      "Train Epoch: 4078 [45568/60000 (76%)] Loss: -1530.536865\n",
      "Train Epoch: 4078 [56832/60000 (95%)] Loss: -1536.294434\n",
      "    epoch          : 4078\n",
      "    loss           : -1537.9793625308969\n",
      "Train Epoch: 4079 [512/60000 (1%)] Loss: -1559.404541\n",
      "Train Epoch: 4079 [11776/60000 (20%)] Loss: -1587.987671\n",
      "Train Epoch: 4079 [23040/60000 (38%)] Loss: -1506.648926\n",
      "Train Epoch: 4079 [34304/60000 (57%)] Loss: -1501.805542\n",
      "Train Epoch: 4079 [45568/60000 (76%)] Loss: -1460.518311\n",
      "Train Epoch: 4079 [56832/60000 (95%)] Loss: -1494.747925\n",
      "    epoch          : 4079\n",
      "    loss           : -1531.5970838298906\n",
      "Train Epoch: 4080 [512/60000 (1%)] Loss: -1616.757690\n",
      "Train Epoch: 4080 [11776/60000 (20%)] Loss: -1541.466919\n",
      "Train Epoch: 4080 [23040/60000 (38%)] Loss: -1526.916016\n",
      "Train Epoch: 4080 [34304/60000 (57%)] Loss: -1540.626221\n",
      "Train Epoch: 4080 [45568/60000 (76%)] Loss: -1574.879639\n",
      "Train Epoch: 4080 [56832/60000 (95%)] Loss: -1426.914185\n",
      "    epoch          : 4080\n",
      "    loss           : -1537.6502992446815\n",
      "Train Epoch: 4081 [512/60000 (1%)] Loss: -1547.152588\n",
      "Train Epoch: 4081 [11776/60000 (20%)] Loss: -1517.044434\n",
      "Train Epoch: 4081 [23040/60000 (38%)] Loss: -1546.158081\n",
      "Train Epoch: 4081 [34304/60000 (57%)] Loss: -1523.448242\n",
      "Train Epoch: 4081 [45568/60000 (76%)] Loss: -1549.371582\n",
      "Train Epoch: 4081 [56832/60000 (95%)] Loss: -1500.161133\n",
      "    epoch          : 4081\n",
      "    loss           : -1538.061755164195\n",
      "Train Epoch: 4082 [512/60000 (1%)] Loss: -1596.553223\n",
      "Train Epoch: 4082 [11776/60000 (20%)] Loss: -1457.540283\n",
      "Train Epoch: 4082 [23040/60000 (38%)] Loss: -1528.823486\n",
      "Train Epoch: 4082 [34304/60000 (57%)] Loss: -1545.931519\n",
      "Train Epoch: 4082 [45568/60000 (76%)] Loss: -1572.146729\n",
      "Train Epoch: 4082 [56832/60000 (95%)] Loss: -1505.634155\n",
      "    epoch          : 4082\n",
      "    loss           : -1533.0880147643009\n",
      "Train Epoch: 4083 [512/60000 (1%)] Loss: -1535.141602\n",
      "Train Epoch: 4083 [11776/60000 (20%)] Loss: -1451.147461\n",
      "Train Epoch: 4083 [23040/60000 (38%)] Loss: -1489.918945\n",
      "Train Epoch: 4083 [34304/60000 (57%)] Loss: -1594.294800\n",
      "Train Epoch: 4083 [45568/60000 (76%)] Loss: -1604.714722\n",
      "Train Epoch: 4083 [56832/60000 (95%)] Loss: -1605.620483\n",
      "    epoch          : 4083\n",
      "    loss           : -1533.559373758607\n",
      "Train Epoch: 4084 [512/60000 (1%)] Loss: -1540.807617\n",
      "Train Epoch: 4084 [11776/60000 (20%)] Loss: -1521.082397\n",
      "Train Epoch: 4084 [23040/60000 (38%)] Loss: -1570.170166\n",
      "Train Epoch: 4084 [34304/60000 (57%)] Loss: -1449.829590\n",
      "Train Epoch: 4084 [45568/60000 (76%)] Loss: -1583.662231\n",
      "Train Epoch: 4084 [56832/60000 (95%)] Loss: -1608.973267\n",
      "    epoch          : 4084\n",
      "    loss           : -1529.7982543255648\n",
      "Train Epoch: 4085 [512/60000 (1%)] Loss: -1566.236572\n",
      "Train Epoch: 4085 [11776/60000 (20%)] Loss: -1574.370117\n",
      "Train Epoch: 4085 [23040/60000 (38%)] Loss: -1514.800903\n",
      "Train Epoch: 4085 [34304/60000 (57%)] Loss: -1413.611572\n",
      "Train Epoch: 4085 [45568/60000 (76%)] Loss: -1543.981079\n",
      "Train Epoch: 4085 [56832/60000 (95%)] Loss: -1491.684814\n",
      "    epoch          : 4085\n",
      "    loss           : -1534.527275818216\n",
      "Train Epoch: 4086 [512/60000 (1%)] Loss: -1573.395264\n",
      "Train Epoch: 4086 [11776/60000 (20%)] Loss: -1543.410767\n",
      "Train Epoch: 4086 [23040/60000 (38%)] Loss: -1561.749634\n",
      "Train Epoch: 4086 [34304/60000 (57%)] Loss: -1502.501831\n",
      "Train Epoch: 4086 [45568/60000 (76%)] Loss: -1574.782959\n",
      "Train Epoch: 4086 [56832/60000 (95%)] Loss: -1547.725098\n",
      "    epoch          : 4086\n",
      "    loss           : -1536.9233419127384\n",
      "Train Epoch: 4087 [512/60000 (1%)] Loss: -1514.638306\n",
      "Train Epoch: 4087 [11776/60000 (20%)] Loss: -1515.162842\n",
      "Train Epoch: 4087 [23040/60000 (38%)] Loss: -1540.468872\n",
      "Train Epoch: 4087 [34304/60000 (57%)] Loss: -1479.829102\n",
      "Train Epoch: 4087 [45568/60000 (76%)] Loss: -1545.615234\n",
      "Train Epoch: 4087 [56832/60000 (95%)] Loss: -1483.973511\n",
      "    epoch          : 4087\n",
      "    loss           : -1531.1713925808838\n",
      "Train Epoch: 4088 [512/60000 (1%)] Loss: -1588.167603\n",
      "Train Epoch: 4088 [11776/60000 (20%)] Loss: -1521.385986\n",
      "Train Epoch: 4088 [23040/60000 (38%)] Loss: -1544.630127\n",
      "Train Epoch: 4088 [34304/60000 (57%)] Loss: -1503.108887\n",
      "Train Epoch: 4088 [45568/60000 (76%)] Loss: -1581.804810\n",
      "Train Epoch: 4088 [56832/60000 (95%)] Loss: -1522.778564\n",
      "    epoch          : 4088\n",
      "    loss           : -1539.1829296047404\n",
      "Train Epoch: 4089 [512/60000 (1%)] Loss: -1538.344727\n",
      "Train Epoch: 4089 [11776/60000 (20%)] Loss: -1553.247070\n",
      "Train Epoch: 4089 [23040/60000 (38%)] Loss: -1561.630493\n",
      "Train Epoch: 4089 [34304/60000 (57%)] Loss: -1544.860474\n",
      "Train Epoch: 4089 [45568/60000 (76%)] Loss: -1596.156128\n",
      "Train Epoch: 4089 [56832/60000 (95%)] Loss: -1551.703247\n",
      "    epoch          : 4089\n",
      "    loss           : -1541.318394547802\n",
      "Train Epoch: 4090 [512/60000 (1%)] Loss: -1472.817505\n",
      "Train Epoch: 4090 [11776/60000 (20%)] Loss: -1516.968506\n",
      "Train Epoch: 4090 [23040/60000 (38%)] Loss: -1491.620850\n",
      "Train Epoch: 4090 [34304/60000 (57%)] Loss: -1563.457642\n",
      "Train Epoch: 4090 [45568/60000 (76%)] Loss: -1466.212524\n",
      "Train Epoch: 4090 [56832/60000 (95%)] Loss: -1490.748779\n",
      "    epoch          : 4090\n",
      "    loss           : -1528.2859828108449\n",
      "Train Epoch: 4091 [512/60000 (1%)] Loss: -1482.065430\n",
      "Train Epoch: 4091 [11776/60000 (20%)] Loss: -1431.704590\n",
      "Train Epoch: 4091 [23040/60000 (38%)] Loss: -1544.591064\n",
      "Train Epoch: 4091 [34304/60000 (57%)] Loss: -1489.872070\n",
      "Train Epoch: 4091 [45568/60000 (76%)] Loss: -1550.459229\n",
      "Train Epoch: 4091 [56832/60000 (95%)] Loss: -1453.654785\n",
      "    epoch          : 4091\n",
      "    loss           : -1534.0642896749205\n",
      "Train Epoch: 4092 [512/60000 (1%)] Loss: -1493.007568\n",
      "Train Epoch: 4092 [11776/60000 (20%)] Loss: -1555.092163\n",
      "Train Epoch: 4092 [23040/60000 (38%)] Loss: -1456.788330\n",
      "Train Epoch: 4092 [34304/60000 (57%)] Loss: -1544.335815\n",
      "Train Epoch: 4092 [45568/60000 (76%)] Loss: -1468.501587\n",
      "Train Epoch: 4092 [56832/60000 (95%)] Loss: -1590.715088\n",
      "    epoch          : 4092\n",
      "    loss           : -1536.038472148658\n",
      "Train Epoch: 4093 [512/60000 (1%)] Loss: -1547.937622\n",
      "Train Epoch: 4093 [11776/60000 (20%)] Loss: -1522.346436\n",
      "Train Epoch: 4093 [23040/60000 (38%)] Loss: -1534.951904\n",
      "Train Epoch: 4093 [34304/60000 (57%)] Loss: -1535.679077\n",
      "Train Epoch: 4093 [45568/60000 (76%)] Loss: -1532.919189\n",
      "Train Epoch: 4093 [56832/60000 (95%)] Loss: -1453.733154\n",
      "    epoch          : 4093\n",
      "    loss           : -1533.1739136431852\n",
      "Train Epoch: 4094 [512/60000 (1%)] Loss: -1577.209473\n",
      "Train Epoch: 4094 [11776/60000 (20%)] Loss: -1513.247192\n",
      "Train Epoch: 4094 [23040/60000 (38%)] Loss: -1557.430786\n",
      "Train Epoch: 4094 [34304/60000 (57%)] Loss: -1572.096802\n",
      "Train Epoch: 4094 [45568/60000 (76%)] Loss: -1444.456055\n",
      "Train Epoch: 4094 [56832/60000 (95%)] Loss: -1616.903809\n",
      "    epoch          : 4094\n",
      "    loss           : -1529.2677777823756\n",
      "Train Epoch: 4095 [512/60000 (1%)] Loss: -1518.145874\n",
      "Train Epoch: 4095 [11776/60000 (20%)] Loss: -1472.884399\n",
      "Train Epoch: 4095 [23040/60000 (38%)] Loss: -1551.563477\n",
      "Train Epoch: 4095 [34304/60000 (57%)] Loss: -1560.619507\n",
      "Train Epoch: 4095 [45568/60000 (76%)] Loss: -1539.904175\n",
      "Train Epoch: 4095 [56832/60000 (95%)] Loss: -1491.896240\n",
      "    epoch          : 4095\n",
      "    loss           : -1533.4039289399054\n",
      "Train Epoch: 4096 [512/60000 (1%)] Loss: -1401.933350\n",
      "Train Epoch: 4096 [11776/60000 (20%)] Loss: -1514.489014\n",
      "Train Epoch: 4096 [23040/60000 (38%)] Loss: -1535.557861\n",
      "Train Epoch: 4096 [34304/60000 (57%)] Loss: -1519.798462\n",
      "Train Epoch: 4096 [45568/60000 (76%)] Loss: -1579.918091\n",
      "Train Epoch: 4096 [56832/60000 (95%)] Loss: -1593.553833\n",
      "    epoch          : 4096\n",
      "    loss           : -1531.719577595339\n",
      "Train Epoch: 4097 [512/60000 (1%)] Loss: -1506.683716\n",
      "Train Epoch: 4097 [11776/60000 (20%)] Loss: -1494.459106\n",
      "Train Epoch: 4097 [23040/60000 (38%)] Loss: -1462.171753\n",
      "Train Epoch: 4097 [34304/60000 (57%)] Loss: -1578.802612\n",
      "Train Epoch: 4097 [45568/60000 (76%)] Loss: -1478.003906\n",
      "Train Epoch: 4097 [56832/60000 (95%)] Loss: -1516.040283\n",
      "    epoch          : 4097\n",
      "    loss           : -1533.7945098014875\n",
      "Train Epoch: 4098 [512/60000 (1%)] Loss: -1498.995117\n",
      "Train Epoch: 4098 [11776/60000 (20%)] Loss: -1566.979248\n",
      "Train Epoch: 4098 [23040/60000 (38%)] Loss: -1570.210693\n",
      "Train Epoch: 4098 [34304/60000 (57%)] Loss: -1562.786743\n",
      "Train Epoch: 4098 [45568/60000 (76%)] Loss: -1549.052002\n",
      "Train Epoch: 4098 [56832/60000 (95%)] Loss: -1564.159546\n",
      "    epoch          : 4098\n",
      "    loss           : -1541.5844661044537\n",
      "Train Epoch: 4099 [512/60000 (1%)] Loss: -1520.358887\n",
      "Train Epoch: 4099 [11776/60000 (20%)] Loss: -1561.375732\n",
      "Train Epoch: 4099 [23040/60000 (38%)] Loss: -1553.047974\n",
      "Train Epoch: 4099 [34304/60000 (57%)] Loss: -1543.510376\n",
      "Train Epoch: 4099 [45568/60000 (76%)] Loss: -1535.075439\n",
      "Train Epoch: 4099 [56832/60000 (95%)] Loss: -1615.072998\n",
      "    epoch          : 4099\n",
      "    loss           : -1532.1980266678806\n",
      "Train Epoch: 4100 [512/60000 (1%)] Loss: -1510.381470\n",
      "Train Epoch: 4100 [11776/60000 (20%)] Loss: -1566.559448\n",
      "Train Epoch: 4100 [23040/60000 (38%)] Loss: -1511.787598\n",
      "Train Epoch: 4100 [34304/60000 (57%)] Loss: -1441.248657\n",
      "Train Epoch: 4100 [45568/60000 (76%)] Loss: -1517.291992\n",
      "Train Epoch: 4100 [56832/60000 (95%)] Loss: -1559.790283\n",
      "    epoch          : 4100\n",
      "    loss           : -1530.7538531459659\n",
      "Saving checkpoint: saved/models/Mnist_DeepGenerativeOperad/0127_111843/checkpoint-epoch4100.pth ...\n",
      "Train Epoch: 4101 [512/60000 (1%)] Loss: -1513.982666\n",
      "Train Epoch: 4101 [11776/60000 (20%)] Loss: -1523.451782\n",
      "Train Epoch: 4101 [23040/60000 (38%)] Loss: -1464.739014\n",
      "Train Epoch: 4101 [34304/60000 (57%)] Loss: -1596.567871\n",
      "Train Epoch: 4101 [45568/60000 (76%)] Loss: -1559.655273\n",
      "Train Epoch: 4101 [56832/60000 (95%)] Loss: -1599.616455\n",
      "    epoch          : 4101\n",
      "    loss           : -1541.9773235428806\n",
      "Train Epoch: 4102 [512/60000 (1%)] Loss: -1568.363159\n",
      "Train Epoch: 4102 [11776/60000 (20%)] Loss: -1572.856079\n",
      "Train Epoch: 4102 [23040/60000 (38%)] Loss: -1516.968750\n",
      "Train Epoch: 4102 [34304/60000 (57%)] Loss: -1504.297363\n",
      "Train Epoch: 4102 [45568/60000 (76%)] Loss: -1510.006836\n",
      "Train Epoch: 4102 [56832/60000 (95%)] Loss: -1502.201538\n",
      "    epoch          : 4102\n",
      "    loss           : -1534.869585802326\n",
      "Train Epoch: 4103 [512/60000 (1%)] Loss: -1457.335938\n",
      "Train Epoch: 4103 [11776/60000 (20%)] Loss: -1528.192871\n",
      "Train Epoch: 4103 [23040/60000 (38%)] Loss: -1549.884766\n",
      "Train Epoch: 4103 [34304/60000 (57%)] Loss: -1485.256104\n",
      "Train Epoch: 4103 [45568/60000 (76%)] Loss: -1482.622925\n",
      "Train Epoch: 4103 [56832/60000 (95%)] Loss: -1565.348511\n",
      "    epoch          : 4103\n",
      "    loss           : -1529.1868182683395\n",
      "Train Epoch: 4104 [512/60000 (1%)] Loss: -1466.666992\n",
      "Train Epoch: 4104 [11776/60000 (20%)] Loss: -1555.194580\n",
      "Train Epoch: 4104 [23040/60000 (38%)] Loss: -1500.013794\n",
      "Train Epoch: 4104 [34304/60000 (57%)] Loss: -1488.935059\n",
      "Train Epoch: 4104 [45568/60000 (76%)] Loss: -1502.100830\n",
      "Train Epoch: 4104 [56832/60000 (95%)] Loss: -1592.642090\n",
      "    epoch          : 4104\n",
      "    loss           : -1530.6123112392963\n",
      "Train Epoch: 4105 [512/60000 (1%)] Loss: -1478.224243\n",
      "Train Epoch: 4105 [11776/60000 (20%)] Loss: -1544.655273\n",
      "Train Epoch: 4105 [23040/60000 (38%)] Loss: -1516.464111\n",
      "Train Epoch: 4105 [34304/60000 (57%)] Loss: -1468.697998\n",
      "Train Epoch: 4105 [45568/60000 (76%)] Loss: -1574.956543\n",
      "Train Epoch: 4105 [56832/60000 (95%)] Loss: -1482.795532\n",
      "    epoch          : 4105\n",
      "    loss           : -1530.9005040745278\n",
      "Train Epoch: 4106 [512/60000 (1%)] Loss: -1473.418213\n",
      "Train Epoch: 4106 [11776/60000 (20%)] Loss: -1554.224976\n",
      "Train Epoch: 4106 [23040/60000 (38%)] Loss: -1594.761108\n",
      "Train Epoch: 4106 [34304/60000 (57%)] Loss: -1454.715698\n",
      "Train Epoch: 4106 [45568/60000 (76%)] Loss: -1543.286011\n",
      "Train Epoch: 4106 [56832/60000 (95%)] Loss: -1643.336670\n",
      "    epoch          : 4106\n",
      "    loss           : -1542.7433540645966\n",
      "Train Epoch: 4107 [512/60000 (1%)] Loss: -1473.375854\n",
      "Train Epoch: 4107 [11776/60000 (20%)] Loss: -1590.368164\n",
      "Train Epoch: 4107 [23040/60000 (38%)] Loss: -1548.584961\n",
      "Train Epoch: 4107 [34304/60000 (57%)] Loss: -1582.463135\n",
      "Train Epoch: 4107 [45568/60000 (76%)] Loss: -1548.976562\n",
      "Train Epoch: 4107 [56832/60000 (95%)] Loss: -1537.984741\n",
      "    epoch          : 4107\n",
      "    loss           : -1540.16960463012\n",
      "Train Epoch: 4108 [512/60000 (1%)] Loss: -1503.483521\n",
      "Train Epoch: 4108 [11776/60000 (20%)] Loss: -1575.178589\n",
      "Train Epoch: 4108 [23040/60000 (38%)] Loss: -1572.424683\n",
      "Train Epoch: 4108 [34304/60000 (57%)] Loss: -1496.264404\n",
      "Train Epoch: 4108 [45568/60000 (76%)] Loss: -1538.636841\n",
      "Train Epoch: 4108 [56832/60000 (95%)] Loss: -1584.389648\n",
      "    epoch          : 4108\n",
      "    loss           : -1530.2157503117276\n",
      "Train Epoch: 4109 [512/60000 (1%)] Loss: -1600.895142\n",
      "Train Epoch: 4109 [11776/60000 (20%)] Loss: -1536.667725\n",
      "Train Epoch: 4109 [23040/60000 (38%)] Loss: -1531.232544\n",
      "Train Epoch: 4109 [34304/60000 (57%)] Loss: -1591.118652\n",
      "Train Epoch: 4109 [45568/60000 (76%)] Loss: -1539.032227\n",
      "Train Epoch: 4109 [56832/60000 (95%)] Loss: -1553.593872\n",
      "    epoch          : 4109\n",
      "    loss           : -1534.807484082583\n",
      "Train Epoch: 4110 [512/60000 (1%)] Loss: -1519.530273\n",
      "Train Epoch: 4110 [11776/60000 (20%)] Loss: -1527.121704\n",
      "Train Epoch: 4110 [23040/60000 (38%)] Loss: -1558.147949\n",
      "Train Epoch: 4110 [34304/60000 (57%)] Loss: -1538.252075\n",
      "Train Epoch: 4110 [45568/60000 (76%)] Loss: -1607.574341\n",
      "Train Epoch: 4110 [56832/60000 (95%)] Loss: -1511.089722\n",
      "    epoch          : 4110\n",
      "    loss           : -1541.7293642550537\n",
      "Train Epoch: 4111 [512/60000 (1%)] Loss: -1565.579346\n",
      "Train Epoch: 4111 [11776/60000 (20%)] Loss: -1522.618652\n",
      "Train Epoch: 4111 [23040/60000 (38%)] Loss: -1496.369751\n",
      "Train Epoch: 4111 [34304/60000 (57%)] Loss: -1559.341064\n",
      "Train Epoch: 4111 [45568/60000 (76%)] Loss: -1572.484253\n",
      "Train Epoch: 4111 [56832/60000 (95%)] Loss: -1545.132080\n",
      "    epoch          : 4111\n",
      "    loss           : -1541.4029544463938\n",
      "Train Epoch: 4112 [512/60000 (1%)] Loss: -1520.207520\n",
      "Train Epoch: 4112 [11776/60000 (20%)] Loss: -1550.141113\n",
      "Train Epoch: 4112 [23040/60000 (38%)] Loss: -1566.925171\n",
      "Train Epoch: 4112 [34304/60000 (57%)] Loss: -1483.446777\n",
      "Train Epoch: 4112 [45568/60000 (76%)] Loss: -1594.217773\n",
      "Train Epoch: 4112 [56832/60000 (95%)] Loss: -1573.352051\n",
      "    epoch          : 4112\n",
      "    loss           : -1539.578933284781\n",
      "Train Epoch: 4113 [512/60000 (1%)] Loss: -1586.599365\n",
      "Train Epoch: 4113 [11776/60000 (20%)] Loss: -1544.073364\n",
      "Train Epoch: 4113 [23040/60000 (38%)] Loss: -1575.727295\n",
      "Train Epoch: 4113 [34304/60000 (57%)] Loss: -1550.355957\n",
      "Train Epoch: 4113 [45568/60000 (76%)] Loss: -1604.210815\n",
      "Train Epoch: 4113 [56832/60000 (95%)] Loss: -1515.497314\n",
      "    epoch          : 4113\n",
      "    loss           : -1532.7547955701582\n",
      "Train Epoch: 4114 [512/60000 (1%)] Loss: -1532.635742\n",
      "Train Epoch: 4114 [11776/60000 (20%)] Loss: -1485.335693\n",
      "Train Epoch: 4114 [23040/60000 (38%)] Loss: -1607.786255\n",
      "Train Epoch: 4114 [34304/60000 (57%)] Loss: -1364.368896\n",
      "Train Epoch: 4114 [45568/60000 (76%)] Loss: -1496.908203\n",
      "Train Epoch: 4114 [56832/60000 (95%)] Loss: -1521.821411\n",
      "    epoch          : 4114\n",
      "    loss           : -1531.8830207781602\n",
      "Train Epoch: 4115 [512/60000 (1%)] Loss: -1525.677368\n",
      "Train Epoch: 4115 [11776/60000 (20%)] Loss: -1472.285889\n",
      "Train Epoch: 4115 [23040/60000 (38%)] Loss: -1508.036621\n",
      "Train Epoch: 4115 [34304/60000 (57%)] Loss: -1553.864746\n",
      "Train Epoch: 4115 [45568/60000 (76%)] Loss: -1466.895996\n",
      "Train Epoch: 4115 [56832/60000 (95%)] Loss: -1586.568115\n",
      "    epoch          : 4115\n",
      "    loss           : -1532.3569215246512\n",
      "Train Epoch: 4116 [512/60000 (1%)] Loss: -1552.083130\n",
      "Train Epoch: 4116 [11776/60000 (20%)] Loss: -1604.069458\n",
      "Train Epoch: 4116 [23040/60000 (38%)] Loss: -1482.177368\n",
      "Train Epoch: 4116 [34304/60000 (57%)] Loss: -1557.890747\n",
      "Train Epoch: 4116 [45568/60000 (76%)] Loss: -1605.401855\n",
      "Train Epoch: 4116 [56832/60000 (95%)] Loss: -1532.108276\n",
      "    epoch          : 4116\n",
      "    loss           : -1532.0989841956878\n",
      "Train Epoch: 4117 [512/60000 (1%)] Loss: -1569.433594\n",
      "Train Epoch: 4117 [11776/60000 (20%)] Loss: -1588.051514\n",
      "Train Epoch: 4117 [23040/60000 (38%)] Loss: -1564.395508\n",
      "Train Epoch: 4117 [34304/60000 (57%)] Loss: -1562.380737\n",
      "Train Epoch: 4117 [45568/60000 (76%)] Loss: -1549.628906\n",
      "Train Epoch: 4117 [56832/60000 (95%)] Loss: -1490.491577\n",
      "    epoch          : 4117\n",
      "    loss           : -1534.794747390316\n",
      "Train Epoch: 4118 [512/60000 (1%)] Loss: -1560.091797\n",
      "Train Epoch: 4118 [11776/60000 (20%)] Loss: -1593.401611\n",
      "Train Epoch: 4118 [23040/60000 (38%)] Loss: -1534.320312\n",
      "Train Epoch: 4118 [34304/60000 (57%)] Loss: -1585.395996\n",
      "Train Epoch: 4118 [45568/60000 (76%)] Loss: -1554.619507\n",
      "Train Epoch: 4118 [56832/60000 (95%)] Loss: -1584.492432\n",
      "    epoch          : 4118\n",
      "    loss           : -1532.5706487106065\n",
      "Train Epoch: 4119 [512/60000 (1%)] Loss: -1558.041016\n",
      "Train Epoch: 4119 [11776/60000 (20%)] Loss: -1578.496094\n",
      "Train Epoch: 4119 [23040/60000 (38%)] Loss: -1535.015869\n",
      "Train Epoch: 4119 [34304/60000 (57%)] Loss: -1522.189575\n",
      "Train Epoch: 4119 [45568/60000 (76%)] Loss: -1548.767334\n",
      "Train Epoch: 4119 [56832/60000 (95%)] Loss: -1442.422607\n",
      "    epoch          : 4119\n",
      "    loss           : -1529.7867841989982\n",
      "Train Epoch: 4120 [512/60000 (1%)] Loss: -1505.208008\n",
      "Train Epoch: 4120 [11776/60000 (20%)] Loss: -1433.462158\n",
      "Train Epoch: 4120 [23040/60000 (38%)] Loss: -1578.320801\n",
      "Train Epoch: 4120 [34304/60000 (57%)] Loss: -1544.976929\n",
      "Train Epoch: 4120 [45568/60000 (76%)] Loss: -1425.678101\n",
      "Train Epoch: 4120 [56832/60000 (95%)] Loss: -1485.792603\n",
      "    epoch          : 4120\n",
      "    loss           : -1531.1045790850105\n",
      "Train Epoch: 4121 [512/60000 (1%)] Loss: -1516.980469\n",
      "Train Epoch: 4121 [11776/60000 (20%)] Loss: -1577.486572\n",
      "Train Epoch: 4121 [23040/60000 (38%)] Loss: -1570.202148\n",
      "Train Epoch: 4121 [34304/60000 (57%)] Loss: -1504.106201\n",
      "Train Epoch: 4121 [45568/60000 (76%)] Loss: -1536.803833\n",
      "Train Epoch: 4121 [56832/60000 (95%)] Loss: -1593.123779\n",
      "    epoch          : 4121\n",
      "    loss           : -1532.8193611101915\n",
      "Train Epoch: 4122 [512/60000 (1%)] Loss: -1466.911011\n",
      "Train Epoch: 4122 [11776/60000 (20%)] Loss: -1521.679199\n",
      "Train Epoch: 4122 [23040/60000 (38%)] Loss: -1475.601196\n",
      "Train Epoch: 4122 [34304/60000 (57%)] Loss: -1618.229736\n",
      "Train Epoch: 4122 [45568/60000 (76%)] Loss: -1588.411377\n",
      "Train Epoch: 4122 [56832/60000 (95%)] Loss: -1475.921021\n",
      "    epoch          : 4122\n",
      "    loss           : -1535.0830398818193\n",
      "Train Epoch: 4123 [512/60000 (1%)] Loss: -1530.786865\n",
      "Train Epoch: 4123 [11776/60000 (20%)] Loss: -1625.897095\n",
      "Train Epoch: 4123 [23040/60000 (38%)] Loss: -1492.081543\n",
      "Train Epoch: 4123 [34304/60000 (57%)] Loss: -1602.204834\n",
      "Train Epoch: 4123 [45568/60000 (76%)] Loss: -1546.213013\n",
      "Train Epoch: 4123 [56832/60000 (95%)] Loss: -1511.820557\n",
      "    epoch          : 4123\n",
      "    loss           : -1532.9026916848736\n",
      "Train Epoch: 4124 [512/60000 (1%)] Loss: -1569.979492\n",
      "Train Epoch: 4124 [11776/60000 (20%)] Loss: -1569.355591\n",
      "Train Epoch: 4124 [23040/60000 (38%)] Loss: -1533.250977\n",
      "Train Epoch: 4124 [34304/60000 (57%)] Loss: -1506.054077\n",
      "Train Epoch: 4124 [45568/60000 (76%)] Loss: -1452.354492\n",
      "Train Epoch: 4124 [56832/60000 (95%)] Loss: -1555.156738\n",
      "    epoch          : 4124\n",
      "    loss           : -1532.7324480821856\n",
      "Train Epoch: 4125 [512/60000 (1%)] Loss: -1589.397949\n",
      "Train Epoch: 4125 [11776/60000 (20%)] Loss: -1556.513672\n",
      "Train Epoch: 4125 [23040/60000 (38%)] Loss: -1549.065552\n",
      "Train Epoch: 4125 [34304/60000 (57%)] Loss: -1526.096313\n",
      "Train Epoch: 4125 [45568/60000 (76%)] Loss: -1494.597168\n",
      "Train Epoch: 4125 [56832/60000 (95%)] Loss: -1564.824829\n",
      "    epoch          : 4125\n",
      "    loss           : -1540.4108679819915\n",
      "Train Epoch: 4126 [512/60000 (1%)] Loss: -1574.007324\n",
      "Train Epoch: 4126 [11776/60000 (20%)] Loss: -1503.083496\n",
      "Train Epoch: 4126 [23040/60000 (38%)] Loss: -1509.230591\n",
      "Train Epoch: 4126 [34304/60000 (57%)] Loss: -1504.266968\n",
      "Train Epoch: 4126 [45568/60000 (76%)] Loss: -1504.958496\n",
      "Train Epoch: 4126 [56832/60000 (95%)] Loss: -1548.430908\n",
      "    epoch          : 4126\n",
      "    loss           : -1534.2579618119923\n",
      "Train Epoch: 4127 [512/60000 (1%)] Loss: -1559.208862\n",
      "Train Epoch: 4127 [11776/60000 (20%)] Loss: -1576.778564\n",
      "Train Epoch: 4127 [23040/60000 (38%)] Loss: -1563.187256\n",
      "Train Epoch: 4127 [34304/60000 (57%)] Loss: -1569.748413\n",
      "Train Epoch: 4127 [45568/60000 (76%)] Loss: -1606.298096\n",
      "Train Epoch: 4127 [56832/60000 (95%)] Loss: -1555.442383\n",
      "    epoch          : 4127\n",
      "    loss           : -1534.1951549120542\n",
      "Train Epoch: 4128 [512/60000 (1%)] Loss: -1558.538330\n",
      "Train Epoch: 4128 [11776/60000 (20%)] Loss: -1473.784302\n",
      "Train Epoch: 4128 [23040/60000 (38%)] Loss: -1523.628418\n",
      "Train Epoch: 4128 [34304/60000 (57%)] Loss: -1532.079834\n",
      "Train Epoch: 4128 [45568/60000 (76%)] Loss: -1554.226318\n",
      "Train Epoch: 4128 [56832/60000 (95%)] Loss: -1530.241455\n",
      "    epoch          : 4128\n",
      "    loss           : -1533.6392798127429\n",
      "Train Epoch: 4129 [512/60000 (1%)] Loss: -1545.339844\n",
      "Train Epoch: 4129 [11776/60000 (20%)] Loss: -1543.430908\n",
      "Train Epoch: 4129 [23040/60000 (38%)] Loss: -1569.210449\n",
      "Train Epoch: 4129 [34304/60000 (57%)] Loss: -1580.427124\n",
      "Train Epoch: 4129 [45568/60000 (76%)] Loss: -1526.690186\n",
      "Train Epoch: 4129 [56832/60000 (95%)] Loss: -1564.088257\n",
      "    epoch          : 4129\n",
      "    loss           : -1531.9467925163312\n",
      "Train Epoch: 4130 [512/60000 (1%)] Loss: -1479.857544\n",
      "Train Epoch: 4130 [11776/60000 (20%)] Loss: -1532.696533\n",
      "Train Epoch: 4130 [23040/60000 (38%)] Loss: -1515.380859\n",
      "Train Epoch: 4130 [34304/60000 (57%)] Loss: -1457.012085\n",
      "Train Epoch: 4130 [45568/60000 (76%)] Loss: -1499.779175\n",
      "Train Epoch: 4130 [56832/60000 (95%)] Loss: -1539.516113\n",
      "    epoch          : 4130\n",
      "    loss           : -1536.5308248228946\n",
      "Train Epoch: 4131 [512/60000 (1%)] Loss: -1458.049194\n",
      "Train Epoch: 4131 [11776/60000 (20%)] Loss: -1570.354858\n",
      "Train Epoch: 4131 [23040/60000 (38%)] Loss: -1608.078613\n",
      "Train Epoch: 4131 [34304/60000 (57%)] Loss: -1549.244751\n",
      "Train Epoch: 4131 [45568/60000 (76%)] Loss: -1588.833862\n",
      "Train Epoch: 4131 [56832/60000 (95%)] Loss: -1542.406372\n",
      "    epoch          : 4131\n",
      "    loss           : -1536.4088393389168\n",
      "Train Epoch: 4132 [512/60000 (1%)] Loss: -1464.079834\n",
      "Train Epoch: 4132 [11776/60000 (20%)] Loss: -1529.983276\n",
      "Train Epoch: 4132 [23040/60000 (38%)] Loss: -1553.483276\n",
      "Train Epoch: 4132 [34304/60000 (57%)] Loss: -1584.666382\n",
      "Train Epoch: 4132 [45568/60000 (76%)] Loss: -1504.842407\n",
      "Train Epoch: 4132 [56832/60000 (95%)] Loss: -1504.119263\n",
      "    epoch          : 4132\n",
      "    loss           : -1530.0326944986978\n",
      "Train Epoch: 4133 [512/60000 (1%)] Loss: -1513.112061\n",
      "Train Epoch: 4133 [11776/60000 (20%)] Loss: -1522.651611\n",
      "Train Epoch: 4133 [23040/60000 (38%)] Loss: -1528.774658\n",
      "Train Epoch: 4133 [34304/60000 (57%)] Loss: -1534.346680\n",
      "Train Epoch: 4133 [45568/60000 (76%)] Loss: -1566.381592\n",
      "Train Epoch: 4133 [56832/60000 (95%)] Loss: -1533.498047\n",
      "    epoch          : 4133\n",
      "    loss           : -1538.930897513352\n",
      "Train Epoch: 4134 [512/60000 (1%)] Loss: -1604.368408\n",
      "Train Epoch: 4134 [11776/60000 (20%)] Loss: -1515.405640\n",
      "Train Epoch: 4134 [23040/60000 (38%)] Loss: -1490.562500\n",
      "Train Epoch: 4134 [34304/60000 (57%)] Loss: -1609.341675\n",
      "Train Epoch: 4134 [45568/60000 (76%)] Loss: -1493.105957\n",
      "Train Epoch: 4134 [56832/60000 (95%)] Loss: -1531.188843\n",
      "    epoch          : 4134\n",
      "    loss           : -1525.9598061082052\n",
      "Train Epoch: 4135 [512/60000 (1%)] Loss: -1545.832031\n",
      "Train Epoch: 4135 [11776/60000 (20%)] Loss: -1426.087891\n",
      "Train Epoch: 4135 [23040/60000 (38%)] Loss: -1604.952148\n",
      "Train Epoch: 4135 [34304/60000 (57%)] Loss: -1485.042480\n",
      "Train Epoch: 4135 [45568/60000 (76%)] Loss: -1482.368042\n",
      "Train Epoch: 4135 [56832/60000 (95%)] Loss: -1558.675415\n",
      "    epoch          : 4135\n",
      "    loss           : -1536.1389070500088\n",
      "Train Epoch: 4136 [512/60000 (1%)] Loss: -1595.166748\n",
      "Train Epoch: 4136 [11776/60000 (20%)] Loss: -1556.883179\n",
      "Train Epoch: 4136 [23040/60000 (38%)] Loss: -1496.763550\n",
      "Train Epoch: 4136 [34304/60000 (57%)] Loss: -1538.596924\n",
      "Train Epoch: 4136 [45568/60000 (76%)] Loss: -1502.937012\n",
      "Train Epoch: 4136 [56832/60000 (95%)] Loss: -1562.277222\n",
      "    epoch          : 4136\n",
      "    loss           : -1531.3814448987023\n",
      "Train Epoch: 4137 [512/60000 (1%)] Loss: -1472.209473\n",
      "Train Epoch: 4137 [11776/60000 (20%)] Loss: -1546.839478\n",
      "Train Epoch: 4137 [23040/60000 (38%)] Loss: -1574.712646\n",
      "Train Epoch: 4137 [34304/60000 (57%)] Loss: -1448.354736\n",
      "Train Epoch: 4137 [45568/60000 (76%)] Loss: -1568.486694\n",
      "Train Epoch: 4137 [56832/60000 (95%)] Loss: -1537.022827\n",
      "    epoch          : 4137\n",
      "    loss           : -1533.0886340814795\n",
      "Train Epoch: 4138 [512/60000 (1%)] Loss: -1509.296265\n",
      "Train Epoch: 4138 [11776/60000 (20%)] Loss: -1633.507812\n",
      "Train Epoch: 4138 [23040/60000 (38%)] Loss: -1561.597900\n",
      "Train Epoch: 4138 [34304/60000 (57%)] Loss: -1568.940308\n",
      "Train Epoch: 4138 [45568/60000 (76%)] Loss: -1529.800415\n",
      "Train Epoch: 4138 [56832/60000 (95%)] Loss: -1606.773438\n",
      "    epoch          : 4138\n",
      "    loss           : -1538.7130116608184\n",
      "Train Epoch: 4139 [512/60000 (1%)] Loss: -1477.793823\n",
      "Train Epoch: 4139 [11776/60000 (20%)] Loss: -1453.996460\n",
      "Train Epoch: 4139 [23040/60000 (38%)] Loss: -1535.526733\n",
      "Train Epoch: 4139 [34304/60000 (57%)] Loss: -1537.061768\n",
      "Train Epoch: 4139 [45568/60000 (76%)] Loss: -1553.261475\n",
      "Train Epoch: 4139 [56832/60000 (95%)] Loss: -1515.758545\n",
      "    epoch          : 4139\n",
      "    loss           : -1538.1824951171875\n",
      "Train Epoch: 4140 [512/60000 (1%)] Loss: -1509.850342\n",
      "Train Epoch: 4140 [11776/60000 (20%)] Loss: -1578.986572\n",
      "Train Epoch: 4140 [23040/60000 (38%)] Loss: -1546.937256\n",
      "Train Epoch: 4140 [34304/60000 (57%)] Loss: -1546.249023\n",
      "Train Epoch: 4140 [45568/60000 (76%)] Loss: -1528.394043\n",
      "Train Epoch: 4140 [56832/60000 (95%)] Loss: -1474.798218\n",
      "    epoch          : 4140\n",
      "    loss           : -1534.0806436484818\n",
      "Train Epoch: 4141 [512/60000 (1%)] Loss: -1580.156616\n",
      "Train Epoch: 4141 [11776/60000 (20%)] Loss: -1507.923950\n",
      "Train Epoch: 4141 [23040/60000 (38%)] Loss: -1584.692627\n",
      "Train Epoch: 4141 [34304/60000 (57%)] Loss: -1555.002686\n",
      "Train Epoch: 4141 [45568/60000 (76%)] Loss: -1626.571167\n",
      "Train Epoch: 4141 [56832/60000 (95%)] Loss: -1533.533936\n",
      "    epoch          : 4141\n",
      "    loss           : -1539.0961462333378\n",
      "Train Epoch: 4142 [512/60000 (1%)] Loss: -1498.675903\n",
      "Train Epoch: 4142 [11776/60000 (20%)] Loss: -1544.692627\n",
      "Train Epoch: 4142 [23040/60000 (38%)] Loss: -1587.424316\n",
      "Train Epoch: 4142 [34304/60000 (57%)] Loss: -1556.020752\n",
      "Train Epoch: 4142 [45568/60000 (76%)] Loss: -1490.386719\n",
      "Train Epoch: 4142 [56832/60000 (95%)] Loss: -1555.596558\n",
      "    epoch          : 4142\n",
      "    loss           : -1538.4212674070886\n",
      "Train Epoch: 4143 [512/60000 (1%)] Loss: -1483.069336\n",
      "Train Epoch: 4143 [11776/60000 (20%)] Loss: -1584.644409\n",
      "Train Epoch: 4143 [23040/60000 (38%)] Loss: -1550.410400\n",
      "Train Epoch: 4143 [34304/60000 (57%)] Loss: -1546.607788\n",
      "Train Epoch: 4143 [45568/60000 (76%)] Loss: -1620.695190\n",
      "Train Epoch: 4143 [56832/60000 (95%)] Loss: -1567.704224\n",
      "    epoch          : 4143\n",
      "    loss           : -1533.4686879303497\n",
      "Train Epoch: 4144 [512/60000 (1%)] Loss: -1522.278198\n",
      "Train Epoch: 4144 [11776/60000 (20%)] Loss: -1522.124634\n",
      "Train Epoch: 4144 [23040/60000 (38%)] Loss: -1507.500000\n",
      "Train Epoch: 4144 [34304/60000 (57%)] Loss: -1584.514038\n",
      "Train Epoch: 4144 [45568/60000 (76%)] Loss: -1577.153809\n",
      "Train Epoch: 4144 [56832/60000 (95%)] Loss: -1544.454956\n",
      "    epoch          : 4144\n",
      "    loss           : -1536.8053119896497\n",
      "Train Epoch: 4145 [512/60000 (1%)] Loss: -1621.163574\n",
      "Train Epoch: 4145 [11776/60000 (20%)] Loss: -1522.015381\n",
      "Train Epoch: 4145 [23040/60000 (38%)] Loss: -1561.166016\n",
      "Train Epoch: 4145 [34304/60000 (57%)] Loss: -1528.690552\n",
      "Train Epoch: 4145 [45568/60000 (76%)] Loss: -1576.152100\n",
      "Train Epoch: 4145 [56832/60000 (95%)] Loss: -1516.355957\n",
      "    epoch          : 4145\n",
      "    loss           : -1539.3302453682247\n",
      "Train Epoch: 4146 [512/60000 (1%)] Loss: -1513.576416\n",
      "Train Epoch: 4146 [11776/60000 (20%)] Loss: -1560.988159\n",
      "Train Epoch: 4146 [23040/60000 (38%)] Loss: -1478.388306\n",
      "Train Epoch: 4146 [34304/60000 (57%)] Loss: -1513.914185\n",
      "Train Epoch: 4146 [45568/60000 (76%)] Loss: -1469.463867\n",
      "Train Epoch: 4146 [56832/60000 (95%)] Loss: -1559.150635\n",
      "    epoch          : 4146\n",
      "    loss           : -1536.7683419265315\n",
      "Train Epoch: 4147 [512/60000 (1%)] Loss: -1507.556641\n",
      "Train Epoch: 4147 [11776/60000 (20%)] Loss: -1570.834595\n",
      "Train Epoch: 4147 [23040/60000 (38%)] Loss: -1511.141113\n",
      "Train Epoch: 4147 [34304/60000 (57%)] Loss: -1487.562500\n",
      "Train Epoch: 4147 [45568/60000 (76%)] Loss: -1508.299683\n",
      "Train Epoch: 4147 [56832/60000 (95%)] Loss: -1516.031738\n",
      "    epoch          : 4147\n",
      "    loss           : -1537.2537055581304\n",
      "Train Epoch: 4148 [512/60000 (1%)] Loss: -1581.812988\n",
      "Train Epoch: 4148 [11776/60000 (20%)] Loss: -1580.357178\n",
      "Train Epoch: 4148 [23040/60000 (38%)] Loss: -1524.439697\n",
      "Train Epoch: 4148 [34304/60000 (57%)] Loss: -1467.663208\n",
      "Train Epoch: 4148 [45568/60000 (76%)] Loss: -1629.248169\n",
      "Train Epoch: 4148 [56832/60000 (95%)] Loss: -1537.266846\n",
      "    epoch          : 4148\n",
      "    loss           : -1529.5546902586511\n",
      "Train Epoch: 4149 [512/60000 (1%)] Loss: -1578.709106\n",
      "Train Epoch: 4149 [11776/60000 (20%)] Loss: -1556.667969\n",
      "Train Epoch: 4149 [23040/60000 (38%)] Loss: -1474.249756\n",
      "Train Epoch: 4149 [34304/60000 (57%)] Loss: -1565.105103\n",
      "Train Epoch: 4149 [45568/60000 (76%)] Loss: -1518.352661\n",
      "Train Epoch: 4149 [56832/60000 (95%)] Loss: -1555.059326\n",
      "    epoch          : 4149\n",
      "    loss           : -1535.4135314596576\n",
      "Train Epoch: 4150 [512/60000 (1%)] Loss: -1518.743408\n",
      "Train Epoch: 4150 [11776/60000 (20%)] Loss: -1481.913330\n",
      "Train Epoch: 4150 [23040/60000 (38%)] Loss: -1575.009766\n",
      "Train Epoch: 4150 [34304/60000 (57%)] Loss: -1420.458130\n",
      "Train Epoch: 4150 [45568/60000 (76%)] Loss: -1560.783691\n",
      "Train Epoch: 4150 [56832/60000 (95%)] Loss: -1565.392944\n",
      "    epoch          : 4150\n",
      "    loss           : -1537.5833781614142\n",
      "Train Epoch: 4151 [512/60000 (1%)] Loss: -1464.514404\n",
      "Train Epoch: 4151 [11776/60000 (20%)] Loss: -1567.179443\n",
      "Train Epoch: 4151 [23040/60000 (38%)] Loss: -1554.478149\n",
      "Train Epoch: 4151 [34304/60000 (57%)] Loss: -1551.726318\n",
      "Train Epoch: 4151 [45568/60000 (76%)] Loss: -1518.489258\n",
      "Train Epoch: 4151 [56832/60000 (95%)] Loss: -1501.265869\n",
      "    epoch          : 4151\n",
      "    loss           : -1537.1496954449153\n",
      "Train Epoch: 4152 [512/60000 (1%)] Loss: -1454.155029\n",
      "Train Epoch: 4152 [11776/60000 (20%)] Loss: -1445.409058\n",
      "Train Epoch: 4152 [23040/60000 (38%)] Loss: -1559.230347\n",
      "Train Epoch: 4152 [34304/60000 (57%)] Loss: -1513.225952\n",
      "Train Epoch: 4152 [45568/60000 (76%)] Loss: -1576.832520\n",
      "Train Epoch: 4152 [56832/60000 (95%)] Loss: -1523.726196\n",
      "    epoch          : 4152\n",
      "    loss           : -1535.8024764411193\n",
      "Train Epoch: 4153 [512/60000 (1%)] Loss: -1490.268433\n",
      "Train Epoch: 4153 [11776/60000 (20%)] Loss: -1579.550781\n",
      "Train Epoch: 4153 [23040/60000 (38%)] Loss: -1560.446167\n",
      "Train Epoch: 4153 [34304/60000 (57%)] Loss: -1427.230835\n",
      "Train Epoch: 4153 [45568/60000 (76%)] Loss: -1563.210571\n",
      "Train Epoch: 4153 [56832/60000 (95%)] Loss: -1525.566528\n",
      "    epoch          : 4153\n",
      "    loss           : -1543.043898415431\n",
      "Train Epoch: 4154 [512/60000 (1%)] Loss: -1540.772461\n",
      "Train Epoch: 4154 [11776/60000 (20%)] Loss: -1514.416260\n",
      "Train Epoch: 4154 [23040/60000 (38%)] Loss: -1569.131592\n",
      "Train Epoch: 4154 [34304/60000 (57%)] Loss: -1485.818359\n",
      "Train Epoch: 4154 [45568/60000 (76%)] Loss: -1574.449219\n",
      "Train Epoch: 4154 [56832/60000 (95%)] Loss: -1530.407593\n",
      "    epoch          : 4154\n",
      "    loss           : -1533.6831989180569\n",
      "Train Epoch: 4155 [512/60000 (1%)] Loss: -1513.643677\n",
      "Train Epoch: 4155 [11776/60000 (20%)] Loss: -1560.391602\n",
      "Train Epoch: 4155 [23040/60000 (38%)] Loss: -1541.648193\n",
      "Train Epoch: 4155 [34304/60000 (57%)] Loss: -1557.449341\n",
      "Train Epoch: 4155 [45568/60000 (76%)] Loss: -1549.594116\n",
      "Train Epoch: 4155 [56832/60000 (95%)] Loss: -1580.948364\n",
      "    epoch          : 4155\n",
      "    loss           : -1540.9791004590395\n",
      "Train Epoch: 4156 [512/60000 (1%)] Loss: -1499.421753\n",
      "Train Epoch: 4156 [11776/60000 (20%)] Loss: -1556.769043\n",
      "Train Epoch: 4156 [23040/60000 (38%)] Loss: -1470.715454\n",
      "Train Epoch: 4156 [34304/60000 (57%)] Loss: -1488.587036\n",
      "Train Epoch: 4156 [45568/60000 (76%)] Loss: -1601.741455\n",
      "Train Epoch: 4156 [56832/60000 (95%)] Loss: -1524.890137\n",
      "    epoch          : 4156\n",
      "    loss           : -1538.418354961158\n",
      "Train Epoch: 4157 [512/60000 (1%)] Loss: -1632.032593\n",
      "Train Epoch: 4157 [11776/60000 (20%)] Loss: -1518.466797\n",
      "Train Epoch: 4157 [23040/60000 (38%)] Loss: -1533.125610\n",
      "Train Epoch: 4157 [34304/60000 (57%)] Loss: -1507.673462\n",
      "Train Epoch: 4157 [45568/60000 (76%)] Loss: -1540.482422\n",
      "Train Epoch: 4157 [56832/60000 (95%)] Loss: -1557.487793\n",
      "    epoch          : 4157\n",
      "    loss           : -1536.101844572078\n",
      "Train Epoch: 4158 [512/60000 (1%)] Loss: -1514.019043\n",
      "Train Epoch: 4158 [11776/60000 (20%)] Loss: -1569.149414\n",
      "Train Epoch: 4158 [23040/60000 (38%)] Loss: -1472.754639\n",
      "Train Epoch: 4158 [34304/60000 (57%)] Loss: -1623.861572\n",
      "Train Epoch: 4158 [45568/60000 (76%)] Loss: -1512.237671\n",
      "Train Epoch: 4158 [56832/60000 (95%)] Loss: -1553.635254\n",
      "    epoch          : 4158\n",
      "    loss           : -1535.9906933455818\n",
      "Train Epoch: 4159 [512/60000 (1%)] Loss: -1511.225952\n",
      "Train Epoch: 4159 [11776/60000 (20%)] Loss: -1509.748413\n",
      "Train Epoch: 4159 [23040/60000 (38%)] Loss: -1482.330078\n",
      "Train Epoch: 4159 [34304/60000 (57%)] Loss: -1521.616089\n",
      "Train Epoch: 4159 [45568/60000 (76%)] Loss: -1607.038818\n",
      "Train Epoch: 4159 [56832/60000 (95%)] Loss: -1589.756958\n",
      "    epoch          : 4159\n",
      "    loss           : -1539.08793028061\n",
      "Train Epoch: 4160 [512/60000 (1%)] Loss: -1587.539551\n",
      "Train Epoch: 4160 [11776/60000 (20%)] Loss: -1532.803955\n",
      "Train Epoch: 4160 [23040/60000 (38%)] Loss: -1561.360596\n",
      "Train Epoch: 4160 [34304/60000 (57%)] Loss: -1562.791504\n",
      "Train Epoch: 4160 [45568/60000 (76%)] Loss: -1459.934204\n",
      "Train Epoch: 4160 [56832/60000 (95%)] Loss: -1494.990234\n",
      "    epoch          : 4160\n",
      "    loss           : -1535.7712578207759\n",
      "Train Epoch: 4161 [512/60000 (1%)] Loss: -1548.271362\n",
      "Train Epoch: 4161 [11776/60000 (20%)] Loss: -1486.473389\n",
      "Train Epoch: 4161 [23040/60000 (38%)] Loss: -1499.573364\n",
      "Train Epoch: 4161 [34304/60000 (57%)] Loss: -1522.386597\n",
      "Train Epoch: 4161 [45568/60000 (76%)] Loss: -1583.510864\n",
      "Train Epoch: 4161 [56832/60000 (95%)] Loss: -1514.684570\n",
      "    epoch          : 4161\n",
      "    loss           : -1535.565716932049\n",
      "Train Epoch: 4162 [512/60000 (1%)] Loss: -1546.610596\n",
      "Train Epoch: 4162 [11776/60000 (20%)] Loss: -1565.633301\n",
      "Train Epoch: 4162 [23040/60000 (38%)] Loss: -1448.129028\n",
      "Train Epoch: 4162 [34304/60000 (57%)] Loss: -1552.003540\n",
      "Train Epoch: 4162 [45568/60000 (76%)] Loss: -1472.420410\n",
      "Train Epoch: 4162 [56832/60000 (95%)] Loss: -1486.679077\n",
      "    epoch          : 4162\n",
      "    loss           : -1533.5234585347148\n",
      "Train Epoch: 4163 [512/60000 (1%)] Loss: -1538.646484\n",
      "Train Epoch: 4163 [11776/60000 (20%)] Loss: -1493.344727\n",
      "Train Epoch: 4163 [23040/60000 (38%)] Loss: -1550.480591\n",
      "Train Epoch: 4163 [34304/60000 (57%)] Loss: -1575.961792\n",
      "Train Epoch: 4163 [45568/60000 (76%)] Loss: -1579.988647\n",
      "Train Epoch: 4163 [56832/60000 (95%)] Loss: -1457.501099\n",
      "    epoch          : 4163\n",
      "    loss           : -1536.5337355446682\n",
      "Train Epoch: 4164 [512/60000 (1%)] Loss: -1433.835083\n",
      "Train Epoch: 4164 [11776/60000 (20%)] Loss: -1521.261841\n",
      "Train Epoch: 4164 [23040/60000 (38%)] Loss: -1487.473511\n",
      "Train Epoch: 4164 [34304/60000 (57%)] Loss: -1563.043213\n",
      "Train Epoch: 4164 [45568/60000 (76%)] Loss: -1526.583008\n",
      "Train Epoch: 4164 [56832/60000 (95%)] Loss: -1561.263672\n",
      "    epoch          : 4164\n",
      "    loss           : -1535.918819449042\n",
      "Train Epoch: 4165 [512/60000 (1%)] Loss: -1586.887329\n",
      "Train Epoch: 4165 [11776/60000 (20%)] Loss: -1519.209473\n",
      "Train Epoch: 4165 [23040/60000 (38%)] Loss: -1508.872314\n",
      "Train Epoch: 4165 [34304/60000 (57%)] Loss: -1493.362549\n",
      "Train Epoch: 4165 [45568/60000 (76%)] Loss: -1506.288818\n",
      "Train Epoch: 4165 [56832/60000 (95%)] Loss: -1506.339966\n",
      "    epoch          : 4165\n",
      "    loss           : -1537.3453793283236\n",
      "Train Epoch: 4166 [512/60000 (1%)] Loss: -1594.492554\n",
      "Train Epoch: 4166 [11776/60000 (20%)] Loss: -1537.089844\n",
      "Train Epoch: 4166 [23040/60000 (38%)] Loss: -1557.835693\n",
      "Train Epoch: 4166 [34304/60000 (57%)] Loss: -1460.015137\n",
      "Train Epoch: 4166 [45568/60000 (76%)] Loss: -1521.395142\n",
      "Train Epoch: 4166 [56832/60000 (95%)] Loss: -1539.468750\n",
      "    epoch          : 4166\n",
      "    loss           : -1538.2430764753265\n",
      "Train Epoch: 4167 [512/60000 (1%)] Loss: -1597.826904\n",
      "Train Epoch: 4167 [11776/60000 (20%)] Loss: -1571.487549\n",
      "Train Epoch: 4167 [23040/60000 (38%)] Loss: -1528.678955\n",
      "Train Epoch: 4167 [34304/60000 (57%)] Loss: -1554.627197\n",
      "Train Epoch: 4167 [45568/60000 (76%)] Loss: -1611.174805\n",
      "Train Epoch: 4167 [56832/60000 (95%)] Loss: -1529.553345\n",
      "    epoch          : 4167\n",
      "    loss           : -1538.4542129430395\n",
      "Train Epoch: 4168 [512/60000 (1%)] Loss: -1522.501465\n",
      "Train Epoch: 4168 [11776/60000 (20%)] Loss: -1579.120972\n",
      "Train Epoch: 4168 [23040/60000 (38%)] Loss: -1465.726440\n",
      "Train Epoch: 4168 [34304/60000 (57%)] Loss: -1543.061768\n",
      "Train Epoch: 4168 [45568/60000 (76%)] Loss: -1515.067383\n",
      "Train Epoch: 4168 [56832/60000 (95%)] Loss: -1621.508789\n",
      "    epoch          : 4168\n",
      "    loss           : -1533.9787249376543\n",
      "Train Epoch: 4169 [512/60000 (1%)] Loss: -1550.315796\n",
      "Train Epoch: 4169 [11776/60000 (20%)] Loss: -1585.859375\n",
      "Train Epoch: 4169 [23040/60000 (38%)] Loss: -1494.859375\n",
      "Train Epoch: 4169 [34304/60000 (57%)] Loss: -1555.916992\n",
      "Train Epoch: 4169 [45568/60000 (76%)] Loss: -1557.822998\n",
      "Train Epoch: 4169 [56832/60000 (95%)] Loss: -1576.621094\n",
      "    epoch          : 4169\n",
      "    loss           : -1542.6538548011565\n",
      "Train Epoch: 4170 [512/60000 (1%)] Loss: -1641.069824\n",
      "Train Epoch: 4170 [11776/60000 (20%)] Loss: -1556.799072\n",
      "Train Epoch: 4170 [23040/60000 (38%)] Loss: -1554.032715\n",
      "Train Epoch: 4170 [34304/60000 (57%)] Loss: -1576.086914\n",
      "Train Epoch: 4170 [45568/60000 (76%)] Loss: -1490.650513\n",
      "Train Epoch: 4170 [56832/60000 (95%)] Loss: -1532.687012\n",
      "    epoch          : 4170\n",
      "    loss           : -1536.3167765989142\n",
      "Train Epoch: 4171 [512/60000 (1%)] Loss: -1414.051147\n",
      "Train Epoch: 4171 [11776/60000 (20%)] Loss: -1575.483032\n",
      "Train Epoch: 4171 [23040/60000 (38%)] Loss: -1536.370117\n",
      "Train Epoch: 4171 [34304/60000 (57%)] Loss: -1505.454346\n",
      "Train Epoch: 4171 [45568/60000 (76%)] Loss: -1558.297607\n",
      "Train Epoch: 4171 [56832/60000 (95%)] Loss: -1550.674072\n",
      "    epoch          : 4171\n",
      "    loss           : -1535.4201056701315\n",
      "Train Epoch: 4172 [512/60000 (1%)] Loss: -1497.068115\n",
      "Train Epoch: 4172 [11776/60000 (20%)] Loss: -1566.735962\n",
      "Train Epoch: 4172 [23040/60000 (38%)] Loss: -1490.638428\n",
      "Train Epoch: 4172 [34304/60000 (57%)] Loss: -1518.794067\n",
      "Train Epoch: 4172 [45568/60000 (76%)] Loss: -1583.922852\n",
      "Train Epoch: 4172 [56832/60000 (95%)] Loss: -1491.882080\n",
      "    epoch          : 4172\n",
      "    loss           : -1542.5945841471353\n",
      "Train Epoch: 4173 [512/60000 (1%)] Loss: -1592.231079\n",
      "Train Epoch: 4173 [11776/60000 (20%)] Loss: -1547.479492\n",
      "Train Epoch: 4173 [23040/60000 (38%)] Loss: -1585.888306\n",
      "Train Epoch: 4173 [34304/60000 (57%)] Loss: -1513.331177\n",
      "Train Epoch: 4173 [45568/60000 (76%)] Loss: -1536.458496\n",
      "Train Epoch: 4173 [56832/60000 (95%)] Loss: -1483.258057\n",
      "    epoch          : 4173\n",
      "    loss           : -1532.4372148244393\n",
      "Train Epoch: 4174 [512/60000 (1%)] Loss: -1602.522339\n",
      "Train Epoch: 4174 [11776/60000 (20%)] Loss: -1603.018799\n",
      "Train Epoch: 4174 [23040/60000 (38%)] Loss: -1579.955688\n",
      "Train Epoch: 4174 [34304/60000 (57%)] Loss: -1579.460571\n",
      "Train Epoch: 4174 [45568/60000 (76%)] Loss: -1604.764526\n",
      "Train Epoch: 4174 [56832/60000 (95%)] Loss: -1555.866943\n",
      "    epoch          : 4174\n",
      "    loss           : -1538.5168257029045\n",
      "Train Epoch: 4175 [512/60000 (1%)] Loss: -1536.233398\n",
      "Train Epoch: 4175 [11776/60000 (20%)] Loss: -1550.280518\n",
      "Train Epoch: 4175 [23040/60000 (38%)] Loss: -1499.670044\n",
      "Train Epoch: 4175 [34304/60000 (57%)] Loss: -1453.391724\n",
      "Train Epoch: 4175 [45568/60000 (76%)] Loss: -1458.925537\n",
      "Train Epoch: 4175 [56832/60000 (95%)] Loss: -1497.410522\n",
      "    epoch          : 4175\n",
      "    loss           : -1536.8079985710187\n",
      "Train Epoch: 4176 [512/60000 (1%)] Loss: -1583.060303\n",
      "Train Epoch: 4176 [11776/60000 (20%)] Loss: -1553.381592\n",
      "Train Epoch: 4176 [23040/60000 (38%)] Loss: -1493.251221\n",
      "Train Epoch: 4176 [34304/60000 (57%)] Loss: -1599.996582\n",
      "Train Epoch: 4176 [45568/60000 (76%)] Loss: -1499.312744\n",
      "Train Epoch: 4176 [56832/60000 (95%)] Loss: -1571.513794\n",
      "    epoch          : 4176\n",
      "    loss           : -1535.4010747704801\n",
      "Train Epoch: 4177 [512/60000 (1%)] Loss: -1439.314941\n",
      "Train Epoch: 4177 [11776/60000 (20%)] Loss: -1613.273560\n",
      "Train Epoch: 4177 [23040/60000 (38%)] Loss: -1458.454956\n",
      "Train Epoch: 4177 [34304/60000 (57%)] Loss: -1518.118042\n",
      "Train Epoch: 4177 [45568/60000 (76%)] Loss: -1587.157227\n",
      "Train Epoch: 4177 [56832/60000 (95%)] Loss: -1434.477173\n",
      "    epoch          : 4177\n",
      "    loss           : -1528.6301079873986\n",
      "Train Epoch: 4178 [512/60000 (1%)] Loss: -1494.073120\n",
      "Train Epoch: 4178 [11776/60000 (20%)] Loss: -1569.554688\n",
      "Train Epoch: 4178 [23040/60000 (38%)] Loss: -1529.788574\n",
      "Train Epoch: 4178 [34304/60000 (57%)] Loss: -1574.848022\n",
      "Train Epoch: 4178 [45568/60000 (76%)] Loss: -1517.581299\n",
      "Train Epoch: 4178 [56832/60000 (95%)] Loss: -1494.523071\n",
      "    epoch          : 4178\n",
      "    loss           : -1536.344416214248\n",
      "Train Epoch: 4179 [512/60000 (1%)] Loss: -1600.962280\n",
      "Train Epoch: 4179 [11776/60000 (20%)] Loss: -1481.724365\n",
      "Train Epoch: 4179 [23040/60000 (38%)] Loss: -1573.944824\n",
      "Train Epoch: 4179 [34304/60000 (57%)] Loss: -1485.172485\n",
      "Train Epoch: 4179 [45568/60000 (76%)] Loss: -1550.036743\n",
      "Train Epoch: 4179 [56832/60000 (95%)] Loss: -1472.661377\n",
      "    epoch          : 4179\n",
      "    loss           : -1535.408966236869\n",
      "Train Epoch: 4180 [512/60000 (1%)] Loss: -1558.985840\n",
      "Train Epoch: 4180 [11776/60000 (20%)] Loss: -1492.633057\n",
      "Train Epoch: 4180 [23040/60000 (38%)] Loss: -1535.858887\n",
      "Train Epoch: 4180 [34304/60000 (57%)] Loss: -1446.745117\n",
      "Train Epoch: 4180 [45568/60000 (76%)] Loss: -1559.003174\n",
      "Train Epoch: 4180 [56832/60000 (95%)] Loss: -1540.716675\n",
      "    epoch          : 4180\n",
      "    loss           : -1539.654081010549\n",
      "Train Epoch: 4181 [512/60000 (1%)] Loss: -1485.199829\n",
      "Train Epoch: 4181 [11776/60000 (20%)] Loss: -1558.685303\n",
      "Train Epoch: 4181 [23040/60000 (38%)] Loss: -1497.534180\n",
      "Train Epoch: 4181 [34304/60000 (57%)] Loss: -1556.839233\n",
      "Train Epoch: 4181 [45568/60000 (76%)] Loss: -1507.257080\n",
      "Train Epoch: 4181 [56832/60000 (95%)] Loss: -1540.451294\n",
      "    epoch          : 4181\n",
      "    loss           : -1532.370850643869\n",
      "Train Epoch: 4182 [512/60000 (1%)] Loss: -1564.563843\n",
      "Train Epoch: 4182 [11776/60000 (20%)] Loss: -1545.804688\n",
      "Train Epoch: 4182 [23040/60000 (38%)] Loss: -1579.369141\n",
      "Train Epoch: 4182 [34304/60000 (57%)] Loss: -1503.766235\n",
      "Train Epoch: 4182 [45568/60000 (76%)] Loss: -1554.045532\n",
      "Train Epoch: 4182 [56832/60000 (95%)] Loss: -1564.137085\n",
      "    epoch          : 4182\n",
      "    loss           : -1546.828393623654\n",
      "Train Epoch: 4183 [512/60000 (1%)] Loss: -1580.996948\n",
      "Train Epoch: 4183 [11776/60000 (20%)] Loss: -1547.241089\n",
      "Train Epoch: 4183 [23040/60000 (38%)] Loss: -1533.414307\n",
      "Train Epoch: 4183 [34304/60000 (57%)] Loss: -1447.743896\n",
      "Train Epoch: 4183 [45568/60000 (76%)] Loss: -1458.996338\n",
      "Train Epoch: 4183 [56832/60000 (95%)] Loss: -1572.815918\n",
      "    epoch          : 4183\n",
      "    loss           : -1534.5667510813912\n",
      "Train Epoch: 4184 [512/60000 (1%)] Loss: -1554.166382\n",
      "Train Epoch: 4184 [11776/60000 (20%)] Loss: -1569.246582\n",
      "Train Epoch: 4184 [23040/60000 (38%)] Loss: -1475.561401\n",
      "Train Epoch: 4184 [34304/60000 (57%)] Loss: -1538.037598\n",
      "Train Epoch: 4184 [45568/60000 (76%)] Loss: -1529.909302\n",
      "Train Epoch: 4184 [56832/60000 (95%)] Loss: -1535.277466\n",
      "    epoch          : 4184\n",
      "    loss           : -1537.7636798061221\n",
      "Train Epoch: 4185 [512/60000 (1%)] Loss: -1562.986206\n",
      "Train Epoch: 4185 [11776/60000 (20%)] Loss: -1532.937134\n",
      "Train Epoch: 4185 [23040/60000 (38%)] Loss: -1509.100098\n",
      "Train Epoch: 4185 [34304/60000 (57%)] Loss: -1566.190918\n",
      "Train Epoch: 4185 [45568/60000 (76%)] Loss: -1543.522705\n",
      "Train Epoch: 4185 [56832/60000 (95%)] Loss: -1571.478882\n",
      "    epoch          : 4185\n",
      "    loss           : -1539.4327237404\n",
      "Train Epoch: 4186 [512/60000 (1%)] Loss: -1570.910400\n",
      "Train Epoch: 4186 [11776/60000 (20%)] Loss: -1584.435303\n",
      "Train Epoch: 4186 [23040/60000 (38%)] Loss: -1530.969604\n",
      "Train Epoch: 4186 [34304/60000 (57%)] Loss: -1571.907715\n",
      "Train Epoch: 4186 [45568/60000 (76%)] Loss: -1527.932373\n",
      "Train Epoch: 4186 [56832/60000 (95%)] Loss: -1494.309570\n",
      "    epoch          : 4186\n",
      "    loss           : -1543.4032141044315\n",
      "Train Epoch: 4187 [512/60000 (1%)] Loss: -1577.445679\n",
      "Train Epoch: 4187 [11776/60000 (20%)] Loss: -1626.714966\n",
      "Train Epoch: 4187 [23040/60000 (38%)] Loss: -1549.857056\n",
      "Train Epoch: 4187 [34304/60000 (57%)] Loss: -1512.833496\n",
      "Train Epoch: 4187 [45568/60000 (76%)] Loss: -1549.342773\n",
      "Train Epoch: 4187 [56832/60000 (95%)] Loss: -1614.763184\n",
      "    epoch          : 4187\n",
      "    loss           : -1536.401034770039\n",
      "Train Epoch: 4188 [512/60000 (1%)] Loss: -1483.629517\n",
      "Train Epoch: 4188 [11776/60000 (20%)] Loss: -1588.728760\n",
      "Train Epoch: 4188 [23040/60000 (38%)] Loss: -1517.343018\n",
      "Train Epoch: 4188 [34304/60000 (57%)] Loss: -1555.742188\n",
      "Train Epoch: 4188 [45568/60000 (76%)] Loss: -1529.048706\n",
      "Train Epoch: 4188 [56832/60000 (95%)] Loss: -1563.135132\n",
      "    epoch          : 4188\n",
      "    loss           : -1539.27533855546\n",
      "Train Epoch: 4189 [512/60000 (1%)] Loss: -1578.983398\n",
      "Train Epoch: 4189 [11776/60000 (20%)] Loss: -1559.295898\n",
      "Train Epoch: 4189 [23040/60000 (38%)] Loss: -1518.348389\n",
      "Train Epoch: 4189 [34304/60000 (57%)] Loss: -1625.220215\n",
      "Train Epoch: 4189 [45568/60000 (76%)] Loss: -1518.225586\n",
      "Train Epoch: 4189 [56832/60000 (95%)] Loss: -1539.662842\n",
      "    epoch          : 4189\n",
      "    loss           : -1539.5406494140625\n",
      "Train Epoch: 4190 [512/60000 (1%)] Loss: -1534.146729\n",
      "Train Epoch: 4190 [11776/60000 (20%)] Loss: -1479.467041\n",
      "Train Epoch: 4190 [23040/60000 (38%)] Loss: -1584.246948\n",
      "Train Epoch: 4190 [34304/60000 (57%)] Loss: -1536.220703\n",
      "Train Epoch: 4190 [45568/60000 (76%)] Loss: -1484.238403\n",
      "Train Epoch: 4190 [56832/60000 (95%)] Loss: -1544.471924\n",
      "    epoch          : 4190\n",
      "    loss           : -1532.7823744951668\n",
      "Train Epoch: 4191 [512/60000 (1%)] Loss: -1517.775024\n",
      "Train Epoch: 4191 [11776/60000 (20%)] Loss: -1597.228271\n",
      "Train Epoch: 4191 [23040/60000 (38%)] Loss: -1426.271851\n",
      "Train Epoch: 4191 [34304/60000 (57%)] Loss: -1555.138062\n",
      "Train Epoch: 4191 [45568/60000 (76%)] Loss: -1607.959961\n",
      "Train Epoch: 4191 [56832/60000 (95%)] Loss: -1582.805420\n",
      "    epoch          : 4191\n",
      "    loss           : -1542.3915694931807\n",
      "Train Epoch: 4192 [512/60000 (1%)] Loss: -1509.540039\n",
      "Train Epoch: 4192 [11776/60000 (20%)] Loss: -1611.441406\n",
      "Train Epoch: 4192 [23040/60000 (38%)] Loss: -1565.302612\n",
      "Train Epoch: 4192 [34304/60000 (57%)] Loss: -1546.238037\n",
      "Train Epoch: 4192 [45568/60000 (76%)] Loss: -1574.798584\n",
      "Train Epoch: 4192 [56832/60000 (95%)] Loss: -1514.987061\n",
      "    epoch          : 4192\n",
      "    loss           : -1540.1433015812588\n",
      "Train Epoch: 4193 [512/60000 (1%)] Loss: -1592.678223\n",
      "Train Epoch: 4193 [11776/60000 (20%)] Loss: -1510.182983\n",
      "Train Epoch: 4193 [23040/60000 (38%)] Loss: -1534.948486\n",
      "Train Epoch: 4193 [34304/60000 (57%)] Loss: -1501.352051\n",
      "Train Epoch: 4193 [45568/60000 (76%)] Loss: -1464.499023\n",
      "Train Epoch: 4193 [56832/60000 (95%)] Loss: -1529.012573\n",
      "    epoch          : 4193\n",
      "    loss           : -1534.4268864346088\n",
      "Train Epoch: 4194 [512/60000 (1%)] Loss: -1508.051514\n",
      "Train Epoch: 4194 [11776/60000 (20%)] Loss: -1535.367676\n",
      "Train Epoch: 4194 [23040/60000 (38%)] Loss: -1558.875366\n",
      "Train Epoch: 4194 [34304/60000 (57%)] Loss: -1607.661987\n",
      "Train Epoch: 4194 [45568/60000 (76%)] Loss: -1530.265015\n",
      "Train Epoch: 4194 [56832/60000 (95%)] Loss: -1544.520264\n",
      "    epoch          : 4194\n",
      "    loss           : -1545.1531603107344\n",
      "Train Epoch: 4195 [512/60000 (1%)] Loss: -1465.811035\n",
      "Train Epoch: 4195 [11776/60000 (20%)] Loss: -1452.683350\n",
      "Train Epoch: 4195 [23040/60000 (38%)] Loss: -1509.960693\n",
      "Train Epoch: 4195 [34304/60000 (57%)] Loss: -1491.437012\n",
      "Train Epoch: 4195 [45568/60000 (76%)] Loss: -1486.262695\n",
      "Train Epoch: 4195 [56832/60000 (95%)] Loss: -1571.122925\n",
      "    epoch          : 4195\n",
      "    loss           : -1532.1241827496028\n",
      "Train Epoch: 4196 [512/60000 (1%)] Loss: -1577.825684\n",
      "Train Epoch: 4196 [11776/60000 (20%)] Loss: -1489.793945\n",
      "Train Epoch: 4196 [23040/60000 (38%)] Loss: -1541.208130\n",
      "Train Epoch: 4196 [34304/60000 (57%)] Loss: -1458.137695\n",
      "Train Epoch: 4196 [45568/60000 (76%)] Loss: -1574.545410\n",
      "Train Epoch: 4196 [56832/60000 (95%)] Loss: -1524.361572\n",
      "    epoch          : 4196\n",
      "    loss           : -1530.9112835038181\n",
      "Train Epoch: 4197 [512/60000 (1%)] Loss: -1552.301514\n",
      "Train Epoch: 4197 [11776/60000 (20%)] Loss: -1560.806030\n",
      "Train Epoch: 4197 [23040/60000 (38%)] Loss: -1549.798950\n",
      "Train Epoch: 4197 [34304/60000 (57%)] Loss: -1586.526611\n",
      "Train Epoch: 4197 [45568/60000 (76%)] Loss: -1509.508911\n",
      "Train Epoch: 4197 [56832/60000 (95%)] Loss: -1557.862183\n",
      "    epoch          : 4197\n",
      "    loss           : -1543.1677932308219\n",
      "Train Epoch: 4198 [512/60000 (1%)] Loss: -1454.232666\n",
      "Train Epoch: 4198 [11776/60000 (20%)] Loss: -1598.179932\n",
      "Train Epoch: 4198 [23040/60000 (38%)] Loss: -1486.368042\n",
      "Train Epoch: 4198 [34304/60000 (57%)] Loss: -1529.166138\n",
      "Train Epoch: 4198 [45568/60000 (76%)] Loss: -1604.021118\n",
      "Train Epoch: 4198 [56832/60000 (95%)] Loss: -1508.356079\n",
      "    epoch          : 4198\n",
      "    loss           : -1532.2820162153514\n",
      "Train Epoch: 4199 [512/60000 (1%)] Loss: -1526.403076\n",
      "Train Epoch: 4199 [11776/60000 (20%)] Loss: -1595.593628\n",
      "Train Epoch: 4199 [23040/60000 (38%)] Loss: -1502.171631\n",
      "Train Epoch: 4199 [34304/60000 (57%)] Loss: -1563.459839\n",
      "Train Epoch: 4199 [45568/60000 (76%)] Loss: -1613.130249\n",
      "Train Epoch: 4199 [56832/60000 (95%)] Loss: -1539.007324\n",
      "    epoch          : 4199\n",
      "    loss           : -1538.2061977925273\n",
      "Train Epoch: 4200 [512/60000 (1%)] Loss: -1559.212524\n",
      "Train Epoch: 4200 [11776/60000 (20%)] Loss: -1544.526855\n",
      "Train Epoch: 4200 [23040/60000 (38%)] Loss: -1479.543823\n",
      "Train Epoch: 4200 [34304/60000 (57%)] Loss: -1475.973633\n",
      "Train Epoch: 4200 [45568/60000 (76%)] Loss: -1505.028687\n",
      "Train Epoch: 4200 [56832/60000 (95%)] Loss: -1525.012817\n",
      "    epoch          : 4200\n",
      "    loss           : -1538.4385455287784\n",
      "Saving checkpoint: saved/models/Mnist_DeepGenerativeOperad/0127_111843/checkpoint-epoch4200.pth ...\n",
      "Train Epoch: 4201 [512/60000 (1%)] Loss: -1493.195068\n",
      "Train Epoch: 4201 [11776/60000 (20%)] Loss: -1607.536865\n",
      "Train Epoch: 4201 [23040/60000 (38%)] Loss: -1565.897461\n",
      "Train Epoch: 4201 [34304/60000 (57%)] Loss: -1518.160767\n",
      "Train Epoch: 4201 [45568/60000 (76%)] Loss: -1496.601074\n",
      "Train Epoch: 4201 [56832/60000 (95%)] Loss: -1585.593994\n",
      "    epoch          : 4201\n",
      "    loss           : -1541.3159376241392\n",
      "Train Epoch: 4202 [512/60000 (1%)] Loss: -1548.772339\n",
      "Train Epoch: 4202 [11776/60000 (20%)] Loss: -1536.002197\n",
      "Train Epoch: 4202 [23040/60000 (38%)] Loss: -1573.281616\n",
      "Train Epoch: 4202 [34304/60000 (57%)] Loss: -1456.985229\n",
      "Train Epoch: 4202 [45568/60000 (76%)] Loss: -1530.631104\n",
      "Train Epoch: 4202 [56832/60000 (95%)] Loss: -1487.910156\n",
      "    epoch          : 4202\n",
      "    loss           : -1542.5088673392258\n",
      "Train Epoch: 4203 [512/60000 (1%)] Loss: -1574.204346\n",
      "Train Epoch: 4203 [11776/60000 (20%)] Loss: -1459.313477\n",
      "Train Epoch: 4203 [23040/60000 (38%)] Loss: -1523.956787\n",
      "Train Epoch: 4203 [34304/60000 (57%)] Loss: -1591.943115\n",
      "Train Epoch: 4203 [45568/60000 (76%)] Loss: -1578.096191\n",
      "Train Epoch: 4203 [56832/60000 (95%)] Loss: -1501.905518\n",
      "    epoch          : 4203\n",
      "    loss           : -1533.8030143780898\n",
      "Train Epoch: 4204 [512/60000 (1%)] Loss: -1582.662231\n",
      "Train Epoch: 4204 [11776/60000 (20%)] Loss: -1561.609985\n",
      "Train Epoch: 4204 [23040/60000 (38%)] Loss: -1491.052612\n",
      "Train Epoch: 4204 [34304/60000 (57%)] Loss: -1522.758179\n",
      "Train Epoch: 4204 [45568/60000 (76%)] Loss: -1498.392456\n",
      "Train Epoch: 4204 [56832/60000 (95%)] Loss: -1591.047485\n",
      "    epoch          : 4204\n",
      "    loss           : -1535.7599539029395\n",
      "Train Epoch: 4205 [512/60000 (1%)] Loss: -1520.814941\n",
      "Train Epoch: 4205 [11776/60000 (20%)] Loss: -1543.530762\n",
      "Train Epoch: 4205 [23040/60000 (38%)] Loss: -1559.099854\n",
      "Train Epoch: 4205 [34304/60000 (57%)] Loss: -1523.226074\n",
      "Train Epoch: 4205 [45568/60000 (76%)] Loss: -1596.084595\n",
      "Train Epoch: 4205 [56832/60000 (95%)] Loss: -1502.166748\n",
      "    epoch          : 4205\n",
      "    loss           : -1537.6980849443855\n",
      "Train Epoch: 4206 [512/60000 (1%)] Loss: -1438.858643\n",
      "Train Epoch: 4206 [11776/60000 (20%)] Loss: -1569.082275\n",
      "Train Epoch: 4206 [23040/60000 (38%)] Loss: -1575.237061\n",
      "Train Epoch: 4206 [34304/60000 (57%)] Loss: -1458.154907\n",
      "Train Epoch: 4206 [45568/60000 (76%)] Loss: -1543.885620\n",
      "Train Epoch: 4206 [56832/60000 (95%)] Loss: -1547.888672\n",
      "    epoch          : 4206\n",
      "    loss           : -1539.328501211048\n",
      "Train Epoch: 4207 [512/60000 (1%)] Loss: -1487.144897\n",
      "Train Epoch: 4207 [11776/60000 (20%)] Loss: -1583.354004\n",
      "Train Epoch: 4207 [23040/60000 (38%)] Loss: -1616.914795\n",
      "Train Epoch: 4207 [34304/60000 (57%)] Loss: -1486.193359\n",
      "Train Epoch: 4207 [45568/60000 (76%)] Loss: -1572.891968\n",
      "Train Epoch: 4207 [56832/60000 (95%)] Loss: -1577.754272\n",
      "    epoch          : 4207\n",
      "    loss           : -1539.0116563355182\n",
      "Train Epoch: 4208 [512/60000 (1%)] Loss: -1613.251709\n",
      "Train Epoch: 4208 [11776/60000 (20%)] Loss: -1555.406250\n",
      "Train Epoch: 4208 [23040/60000 (38%)] Loss: -1546.625977\n",
      "Train Epoch: 4208 [34304/60000 (57%)] Loss: -1464.851929\n",
      "Train Epoch: 4208 [45568/60000 (76%)] Loss: -1619.656494\n",
      "Train Epoch: 4208 [56832/60000 (95%)] Loss: -1588.898804\n",
      "    epoch          : 4208\n",
      "    loss           : -1535.8926229530807\n",
      "Train Epoch: 4209 [512/60000 (1%)] Loss: -1534.484619\n",
      "Train Epoch: 4209 [11776/60000 (20%)] Loss: -1562.909180\n",
      "Train Epoch: 4209 [23040/60000 (38%)] Loss: -1580.397217\n",
      "Train Epoch: 4209 [34304/60000 (57%)] Loss: -1526.605347\n",
      "Train Epoch: 4209 [45568/60000 (76%)] Loss: -1618.752808\n",
      "Train Epoch: 4209 [56832/60000 (95%)] Loss: -1547.474243\n",
      "    epoch          : 4209\n",
      "    loss           : -1541.5883344230006\n",
      "Train Epoch: 4210 [512/60000 (1%)] Loss: -1552.806030\n",
      "Train Epoch: 4210 [11776/60000 (20%)] Loss: -1471.562988\n",
      "Train Epoch: 4210 [23040/60000 (38%)] Loss: -1502.956421\n",
      "Train Epoch: 4210 [34304/60000 (57%)] Loss: -1516.835205\n",
      "Train Epoch: 4210 [45568/60000 (76%)] Loss: -1600.898071\n",
      "Train Epoch: 4210 [56832/60000 (95%)] Loss: -1552.875366\n",
      "    epoch          : 4210\n",
      "    loss           : -1538.4776214772025\n",
      "Train Epoch: 4211 [512/60000 (1%)] Loss: -1576.062744\n",
      "Train Epoch: 4211 [11776/60000 (20%)] Loss: -1529.540527\n",
      "Train Epoch: 4211 [23040/60000 (38%)] Loss: -1576.010132\n",
      "Train Epoch: 4211 [34304/60000 (57%)] Loss: -1459.030884\n",
      "Train Epoch: 4211 [45568/60000 (76%)] Loss: -1601.765015\n",
      "Train Epoch: 4211 [56832/60000 (95%)] Loss: -1482.979126\n",
      "    epoch          : 4211\n",
      "    loss           : -1534.517696402167\n",
      "Train Epoch: 4212 [512/60000 (1%)] Loss: -1467.070557\n",
      "Train Epoch: 4212 [11776/60000 (20%)] Loss: -1466.059082\n",
      "Train Epoch: 4212 [23040/60000 (38%)] Loss: -1495.621338\n",
      "Train Epoch: 4212 [34304/60000 (57%)] Loss: -1513.313232\n",
      "Train Epoch: 4212 [45568/60000 (76%)] Loss: -1566.273193\n",
      "Train Epoch: 4212 [56832/60000 (95%)] Loss: -1474.526611\n",
      "    epoch          : 4212\n",
      "    loss           : -1539.0874364820577\n",
      "Train Epoch: 4213 [512/60000 (1%)] Loss: -1533.185303\n",
      "Train Epoch: 4213 [11776/60000 (20%)] Loss: -1571.232178\n",
      "Train Epoch: 4213 [23040/60000 (38%)] Loss: -1545.740967\n",
      "Train Epoch: 4213 [34304/60000 (57%)] Loss: -1406.832031\n",
      "Train Epoch: 4213 [45568/60000 (76%)] Loss: -1546.841919\n",
      "Train Epoch: 4213 [56832/60000 (95%)] Loss: -1570.733765\n",
      "    epoch          : 4213\n",
      "    loss           : -1533.3029254115909\n",
      "Train Epoch: 4214 [512/60000 (1%)] Loss: -1508.720459\n",
      "Train Epoch: 4214 [11776/60000 (20%)] Loss: -1551.776245\n",
      "Train Epoch: 4214 [23040/60000 (38%)] Loss: -1491.788574\n",
      "Train Epoch: 4214 [34304/60000 (57%)] Loss: -1459.226074\n",
      "Train Epoch: 4214 [45568/60000 (76%)] Loss: -1491.903320\n",
      "Train Epoch: 4214 [56832/60000 (95%)] Loss: -1566.602905\n",
      "    epoch          : 4214\n",
      "    loss           : -1536.4679899916136\n",
      "Train Epoch: 4215 [512/60000 (1%)] Loss: -1552.410889\n",
      "Train Epoch: 4215 [11776/60000 (20%)] Loss: -1576.319336\n",
      "Train Epoch: 4215 [23040/60000 (38%)] Loss: -1549.427246\n",
      "Train Epoch: 4215 [34304/60000 (57%)] Loss: -1471.123901\n",
      "Train Epoch: 4215 [45568/60000 (76%)] Loss: -1475.914551\n",
      "Train Epoch: 4215 [56832/60000 (95%)] Loss: -1484.435059\n",
      "    epoch          : 4215\n",
      "    loss           : -1535.3772558869616\n",
      "Train Epoch: 4216 [512/60000 (1%)] Loss: -1520.185547\n",
      "Train Epoch: 4216 [11776/60000 (20%)] Loss: -1604.439331\n",
      "Train Epoch: 4216 [23040/60000 (38%)] Loss: -1491.041992\n",
      "Train Epoch: 4216 [34304/60000 (57%)] Loss: -1566.850464\n",
      "Train Epoch: 4216 [45568/60000 (76%)] Loss: -1557.742065\n",
      "Train Epoch: 4216 [56832/60000 (95%)] Loss: -1580.509277\n",
      "    epoch          : 4216\n",
      "    loss           : -1533.6370401328568\n",
      "Train Epoch: 4217 [512/60000 (1%)] Loss: -1486.404663\n",
      "Train Epoch: 4217 [11776/60000 (20%)] Loss: -1558.221436\n",
      "Train Epoch: 4217 [23040/60000 (38%)] Loss: -1552.348999\n",
      "Train Epoch: 4217 [34304/60000 (57%)] Loss: -1577.592896\n",
      "Train Epoch: 4217 [45568/60000 (76%)] Loss: -1527.496094\n",
      "Train Epoch: 4217 [56832/60000 (95%)] Loss: -1524.280273\n",
      "    epoch          : 4217\n",
      "    loss           : -1533.5481339794094\n",
      "Train Epoch: 4218 [512/60000 (1%)] Loss: -1519.148315\n",
      "Train Epoch: 4218 [11776/60000 (20%)] Loss: -1535.011963\n",
      "Train Epoch: 4218 [23040/60000 (38%)] Loss: -1572.472290\n",
      "Train Epoch: 4218 [34304/60000 (57%)] Loss: -1541.326172\n",
      "Train Epoch: 4218 [45568/60000 (76%)] Loss: -1555.587769\n",
      "Train Epoch: 4218 [56832/60000 (95%)] Loss: -1551.881836\n",
      "    epoch          : 4218\n",
      "    loss           : -1539.1835761635991\n",
      "Train Epoch: 4219 [512/60000 (1%)] Loss: -1509.891113\n",
      "Train Epoch: 4219 [11776/60000 (20%)] Loss: -1504.605591\n",
      "Train Epoch: 4219 [23040/60000 (38%)] Loss: -1595.177734\n",
      "Train Epoch: 4219 [34304/60000 (57%)] Loss: -1517.955200\n",
      "Train Epoch: 4219 [45568/60000 (76%)] Loss: -1550.212036\n",
      "Train Epoch: 4219 [56832/60000 (95%)] Loss: -1571.448608\n",
      "    epoch          : 4219\n",
      "    loss           : -1534.596207268494\n",
      "Train Epoch: 4220 [512/60000 (1%)] Loss: -1519.051514\n",
      "Train Epoch: 4220 [11776/60000 (20%)] Loss: -1487.578613\n",
      "Train Epoch: 4220 [23040/60000 (38%)] Loss: -1535.875732\n",
      "Train Epoch: 4220 [34304/60000 (57%)] Loss: -1596.791748\n",
      "Train Epoch: 4220 [45568/60000 (76%)] Loss: -1518.098755\n",
      "Train Epoch: 4220 [56832/60000 (95%)] Loss: -1531.364990\n",
      "    epoch          : 4220\n",
      "    loss           : -1531.960948189773\n",
      "Train Epoch: 4221 [512/60000 (1%)] Loss: -1552.269653\n",
      "Train Epoch: 4221 [11776/60000 (20%)] Loss: -1546.129272\n",
      "Train Epoch: 4221 [23040/60000 (38%)] Loss: -1451.583618\n",
      "Train Epoch: 4221 [34304/60000 (57%)] Loss: -1588.817139\n",
      "Train Epoch: 4221 [45568/60000 (76%)] Loss: -1578.039429\n",
      "Train Epoch: 4221 [56832/60000 (95%)] Loss: -1497.969971\n",
      "    epoch          : 4221\n",
      "    loss           : -1526.472739354365\n",
      "Train Epoch: 4222 [512/60000 (1%)] Loss: -1592.756226\n",
      "Train Epoch: 4222 [11776/60000 (20%)] Loss: -1467.790039\n",
      "Train Epoch: 4222 [23040/60000 (38%)] Loss: -1543.586304\n",
      "Train Epoch: 4222 [34304/60000 (57%)] Loss: -1569.765259\n",
      "Train Epoch: 4222 [45568/60000 (76%)] Loss: -1546.744995\n",
      "Train Epoch: 4222 [56832/60000 (95%)] Loss: -1573.487183\n",
      "    epoch          : 4222\n",
      "    loss           : -1529.3468296891551\n",
      "Train Epoch: 4223 [512/60000 (1%)] Loss: -1539.571533\n",
      "Train Epoch: 4223 [11776/60000 (20%)] Loss: -1549.924072\n",
      "Train Epoch: 4223 [23040/60000 (38%)] Loss: -1499.482544\n",
      "Train Epoch: 4223 [34304/60000 (57%)] Loss: -1536.843262\n",
      "Train Epoch: 4223 [45568/60000 (76%)] Loss: -1587.283203\n",
      "Train Epoch: 4223 [56832/60000 (95%)] Loss: -1558.025391\n",
      "    epoch          : 4223\n",
      "    loss           : -1537.0017703643625\n",
      "Train Epoch: 4224 [512/60000 (1%)] Loss: -1602.627441\n",
      "Train Epoch: 4224 [11776/60000 (20%)] Loss: -1574.644165\n",
      "Train Epoch: 4224 [23040/60000 (38%)] Loss: -1575.582275\n",
      "Train Epoch: 4224 [34304/60000 (57%)] Loss: -1548.699585\n",
      "Train Epoch: 4224 [45568/60000 (76%)] Loss: -1578.974854\n",
      "Train Epoch: 4224 [56832/60000 (95%)] Loss: -1463.312622\n",
      "    epoch          : 4224\n",
      "    loss           : -1534.4924450890492\n",
      "Train Epoch: 4225 [512/60000 (1%)] Loss: -1519.794434\n",
      "Train Epoch: 4225 [11776/60000 (20%)] Loss: -1407.394043\n",
      "Train Epoch: 4225 [23040/60000 (38%)] Loss: -1547.214355\n",
      "Train Epoch: 4225 [34304/60000 (57%)] Loss: -1475.531372\n",
      "Train Epoch: 4225 [45568/60000 (76%)] Loss: -1458.382446\n",
      "Train Epoch: 4225 [56832/60000 (95%)] Loss: -1413.806885\n",
      "    epoch          : 4225\n",
      "    loss           : -1531.5074011161503\n",
      "Train Epoch: 4226 [512/60000 (1%)] Loss: -1573.871948\n",
      "Train Epoch: 4226 [11776/60000 (20%)] Loss: -1518.927246\n",
      "Train Epoch: 4226 [23040/60000 (38%)] Loss: -1501.243286\n",
      "Train Epoch: 4226 [34304/60000 (57%)] Loss: -1572.193237\n",
      "Train Epoch: 4226 [45568/60000 (76%)] Loss: -1544.725952\n",
      "Train Epoch: 4226 [56832/60000 (95%)] Loss: -1546.504761\n",
      "    epoch          : 4226\n",
      "    loss           : -1540.0397676801952\n",
      "Train Epoch: 4227 [512/60000 (1%)] Loss: -1545.379272\n",
      "Train Epoch: 4227 [11776/60000 (20%)] Loss: -1554.131104\n",
      "Train Epoch: 4227 [23040/60000 (38%)] Loss: -1579.317139\n",
      "Train Epoch: 4227 [34304/60000 (57%)] Loss: -1576.678223\n",
      "Train Epoch: 4227 [45568/60000 (76%)] Loss: -1596.449951\n",
      "Train Epoch: 4227 [56832/60000 (95%)] Loss: -1535.095459\n",
      "    epoch          : 4227\n",
      "    loss           : -1538.9985265354653\n",
      "Train Epoch: 4228 [512/60000 (1%)] Loss: -1557.134766\n",
      "Train Epoch: 4228 [11776/60000 (20%)] Loss: -1469.696045\n",
      "Train Epoch: 4228 [23040/60000 (38%)] Loss: -1564.446411\n",
      "Train Epoch: 4228 [34304/60000 (57%)] Loss: -1549.816162\n",
      "Train Epoch: 4228 [45568/60000 (76%)] Loss: -1494.075806\n",
      "Train Epoch: 4228 [56832/60000 (95%)] Loss: -1507.770020\n",
      "    epoch          : 4228\n",
      "    loss           : -1533.9031213447872\n",
      "Train Epoch: 4229 [512/60000 (1%)] Loss: -1547.968628\n",
      "Train Epoch: 4229 [11776/60000 (20%)] Loss: -1624.022339\n",
      "Train Epoch: 4229 [23040/60000 (38%)] Loss: -1482.844238\n",
      "Train Epoch: 4229 [34304/60000 (57%)] Loss: -1593.405151\n",
      "Train Epoch: 4229 [45568/60000 (76%)] Loss: -1590.661377\n",
      "Train Epoch: 4229 [56832/60000 (95%)] Loss: -1563.055420\n",
      "    epoch          : 4229\n",
      "    loss           : -1541.2995264085673\n",
      "Train Epoch: 4230 [512/60000 (1%)] Loss: -1584.868896\n",
      "Train Epoch: 4230 [11776/60000 (20%)] Loss: -1441.065430\n",
      "Train Epoch: 4230 [23040/60000 (38%)] Loss: -1550.550049\n",
      "Train Epoch: 4230 [34304/60000 (57%)] Loss: -1480.768799\n",
      "Train Epoch: 4230 [45568/60000 (76%)] Loss: -1459.390991\n",
      "Train Epoch: 4230 [56832/60000 (95%)] Loss: -1511.707520\n",
      "    epoch          : 4230\n",
      "    loss           : -1528.278254104873\n",
      "Train Epoch: 4231 [512/60000 (1%)] Loss: -1603.327271\n",
      "Train Epoch: 4231 [11776/60000 (20%)] Loss: -1555.328979\n",
      "Train Epoch: 4231 [23040/60000 (38%)] Loss: -1504.415283\n",
      "Train Epoch: 4231 [34304/60000 (57%)] Loss: -1513.757080\n",
      "Train Epoch: 4231 [45568/60000 (76%)] Loss: -1524.094727\n",
      "Train Epoch: 4231 [56832/60000 (95%)] Loss: -1449.092041\n",
      "    epoch          : 4231\n",
      "    loss           : -1538.936908614164\n",
      "Train Epoch: 4232 [512/60000 (1%)] Loss: -1504.267578\n",
      "Train Epoch: 4232 [11776/60000 (20%)] Loss: -1446.416748\n",
      "Train Epoch: 4232 [23040/60000 (38%)] Loss: -1501.499512\n",
      "Train Epoch: 4232 [34304/60000 (57%)] Loss: -1520.386230\n",
      "Train Epoch: 4232 [45568/60000 (76%)] Loss: -1596.954712\n",
      "Train Epoch: 4232 [56832/60000 (95%)] Loss: -1538.877075\n",
      "    epoch          : 4232\n",
      "    loss           : -1539.675970907265\n",
      "Train Epoch: 4233 [512/60000 (1%)] Loss: -1530.698975\n",
      "Train Epoch: 4233 [11776/60000 (20%)] Loss: -1511.921875\n",
      "Train Epoch: 4233 [23040/60000 (38%)] Loss: -1491.123291\n",
      "Train Epoch: 4233 [34304/60000 (57%)] Loss: -1522.370850\n",
      "Train Epoch: 4233 [45568/60000 (76%)] Loss: -1566.852661\n",
      "Train Epoch: 4233 [56832/60000 (95%)] Loss: -1589.595337\n",
      "    epoch          : 4233\n",
      "    loss           : -1534.8537859728106\n",
      "Train Epoch: 4234 [512/60000 (1%)] Loss: -1540.420654\n",
      "Train Epoch: 4234 [11776/60000 (20%)] Loss: -1542.619507\n",
      "Train Epoch: 4234 [23040/60000 (38%)] Loss: -1497.074097\n",
      "Train Epoch: 4234 [34304/60000 (57%)] Loss: -1559.267944\n",
      "Train Epoch: 4234 [45568/60000 (76%)] Loss: -1508.034180\n",
      "Train Epoch: 4234 [56832/60000 (95%)] Loss: -1574.504639\n",
      "    epoch          : 4234\n",
      "    loss           : -1533.7991919221179\n",
      "Train Epoch: 4235 [512/60000 (1%)] Loss: -1499.606201\n",
      "Train Epoch: 4235 [11776/60000 (20%)] Loss: -1548.745728\n",
      "Train Epoch: 4235 [23040/60000 (38%)] Loss: -1503.404663\n",
      "Train Epoch: 4235 [34304/60000 (57%)] Loss: -1432.277710\n",
      "Train Epoch: 4235 [45568/60000 (76%)] Loss: -1599.683838\n",
      "Train Epoch: 4235 [56832/60000 (95%)] Loss: -1534.977417\n",
      "    epoch          : 4235\n",
      "    loss           : -1530.9856484623278\n",
      "Train Epoch: 4236 [512/60000 (1%)] Loss: -1537.641357\n",
      "Train Epoch: 4236 [11776/60000 (20%)] Loss: -1566.684448\n",
      "Train Epoch: 4236 [23040/60000 (38%)] Loss: -1563.613159\n",
      "Train Epoch: 4236 [34304/60000 (57%)] Loss: -1526.768799\n",
      "Train Epoch: 4236 [45568/60000 (76%)] Loss: -1586.834229\n",
      "Train Epoch: 4236 [56832/60000 (95%)] Loss: -1571.386475\n",
      "    epoch          : 4236\n",
      "    loss           : -1532.3393575377384\n",
      "Train Epoch: 4237 [512/60000 (1%)] Loss: -1600.438110\n",
      "Train Epoch: 4237 [11776/60000 (20%)] Loss: -1538.912964\n",
      "Train Epoch: 4237 [23040/60000 (38%)] Loss: -1587.359253\n",
      "Train Epoch: 4237 [34304/60000 (57%)] Loss: -1499.010132\n",
      "Train Epoch: 4237 [45568/60000 (76%)] Loss: -1587.644165\n",
      "Train Epoch: 4237 [56832/60000 (95%)] Loss: -1520.279663\n",
      "    epoch          : 4237\n",
      "    loss           : -1537.1982159803144\n",
      "Train Epoch: 4238 [512/60000 (1%)] Loss: -1629.803101\n",
      "Train Epoch: 4238 [11776/60000 (20%)] Loss: -1533.418579\n",
      "Train Epoch: 4238 [23040/60000 (38%)] Loss: -1591.535034\n",
      "Train Epoch: 4238 [34304/60000 (57%)] Loss: -1504.718140\n",
      "Train Epoch: 4238 [45568/60000 (76%)] Loss: -1493.412354\n",
      "Train Epoch: 4238 [56832/60000 (95%)] Loss: -1560.729980\n",
      "    epoch          : 4238\n",
      "    loss           : -1533.9334282309321\n",
      "Train Epoch: 4239 [512/60000 (1%)] Loss: -1465.792847\n",
      "Train Epoch: 4239 [11776/60000 (20%)] Loss: -1617.423218\n",
      "Train Epoch: 4239 [23040/60000 (38%)] Loss: -1547.609497\n",
      "Train Epoch: 4239 [34304/60000 (57%)] Loss: -1510.649902\n",
      "Train Epoch: 4239 [45568/60000 (76%)] Loss: -1545.266846\n",
      "Train Epoch: 4239 [56832/60000 (95%)] Loss: -1511.980347\n",
      "    epoch          : 4239\n",
      "    loss           : -1529.9308037192134\n",
      "Train Epoch: 4240 [512/60000 (1%)] Loss: -1537.282715\n",
      "Train Epoch: 4240 [11776/60000 (20%)] Loss: -1511.997803\n",
      "Train Epoch: 4240 [23040/60000 (38%)] Loss: -1587.518311\n",
      "Train Epoch: 4240 [34304/60000 (57%)] Loss: -1539.436035\n",
      "Train Epoch: 4240 [45568/60000 (76%)] Loss: -1537.399658\n",
      "Train Epoch: 4240 [56832/60000 (95%)] Loss: -1456.244019\n",
      "    epoch          : 4240\n",
      "    loss           : -1536.4806522003\n",
      "Train Epoch: 4241 [512/60000 (1%)] Loss: -1529.159668\n",
      "Train Epoch: 4241 [11776/60000 (20%)] Loss: -1473.885986\n",
      "Train Epoch: 4241 [23040/60000 (38%)] Loss: -1584.148438\n",
      "Train Epoch: 4241 [34304/60000 (57%)] Loss: -1524.529053\n",
      "Train Epoch: 4241 [45568/60000 (76%)] Loss: -1438.640991\n",
      "Train Epoch: 4241 [56832/60000 (95%)] Loss: -1519.887573\n",
      "    epoch          : 4241\n",
      "    loss           : -1536.6674721927966\n",
      "Train Epoch: 4242 [512/60000 (1%)] Loss: -1588.056885\n",
      "Train Epoch: 4242 [11776/60000 (20%)] Loss: -1513.972168\n",
      "Train Epoch: 4242 [23040/60000 (38%)] Loss: -1567.696289\n",
      "Train Epoch: 4242 [34304/60000 (57%)] Loss: -1498.064209\n",
      "Train Epoch: 4242 [45568/60000 (76%)] Loss: -1540.573242\n",
      "Train Epoch: 4242 [56832/60000 (95%)] Loss: -1572.563477\n",
      "    epoch          : 4242\n",
      "    loss           : -1536.5845612779176\n",
      "Train Epoch: 4243 [512/60000 (1%)] Loss: -1592.348999\n",
      "Train Epoch: 4243 [11776/60000 (20%)] Loss: -1569.922607\n",
      "Train Epoch: 4243 [23040/60000 (38%)] Loss: -1534.624878\n",
      "Train Epoch: 4243 [34304/60000 (57%)] Loss: -1569.433228\n",
      "Train Epoch: 4243 [45568/60000 (76%)] Loss: -1565.340820\n",
      "Train Epoch: 4243 [56832/60000 (95%)] Loss: -1539.032715\n",
      "    epoch          : 4243\n",
      "    loss           : -1535.288313181387\n",
      "Train Epoch: 4244 [512/60000 (1%)] Loss: -1579.743164\n",
      "Train Epoch: 4244 [11776/60000 (20%)] Loss: -1565.948364\n",
      "Train Epoch: 4244 [23040/60000 (38%)] Loss: -1537.203979\n",
      "Train Epoch: 4244 [34304/60000 (57%)] Loss: -1498.582764\n",
      "Train Epoch: 4244 [45568/60000 (76%)] Loss: -1523.400879\n",
      "Train Epoch: 4244 [56832/60000 (95%)] Loss: -1586.505249\n",
      "    epoch          : 4244\n",
      "    loss           : -1535.4411283158986\n",
      "Train Epoch: 4245 [512/60000 (1%)] Loss: -1606.456787\n",
      "Train Epoch: 4245 [11776/60000 (20%)] Loss: -1485.411621\n",
      "Train Epoch: 4245 [23040/60000 (38%)] Loss: -1561.004150\n",
      "Train Epoch: 4245 [34304/60000 (57%)] Loss: -1469.699951\n",
      "Train Epoch: 4245 [45568/60000 (76%)] Loss: -1565.693115\n",
      "Train Epoch: 4245 [56832/60000 (95%)] Loss: -1624.669678\n",
      "    epoch          : 4245\n",
      "    loss           : -1535.3779652051333\n",
      "Train Epoch: 4246 [512/60000 (1%)] Loss: -1600.927002\n",
      "Train Epoch: 4246 [11776/60000 (20%)] Loss: -1481.711426\n",
      "Train Epoch: 4246 [23040/60000 (38%)] Loss: -1595.391113\n",
      "Train Epoch: 4246 [34304/60000 (57%)] Loss: -1446.407227\n",
      "Train Epoch: 4246 [45568/60000 (76%)] Loss: -1581.101929\n",
      "Train Epoch: 4246 [56832/60000 (95%)] Loss: -1490.623169\n",
      "    epoch          : 4246\n",
      "    loss           : -1537.136678059896\n",
      "Train Epoch: 4247 [512/60000 (1%)] Loss: -1487.260254\n",
      "Train Epoch: 4247 [11776/60000 (20%)] Loss: -1537.176880\n",
      "Train Epoch: 4247 [23040/60000 (38%)] Loss: -1543.060303\n",
      "Train Epoch: 4247 [34304/60000 (57%)] Loss: -1561.740723\n",
      "Train Epoch: 4247 [45568/60000 (76%)] Loss: -1526.789307\n",
      "Train Epoch: 4247 [56832/60000 (95%)] Loss: -1603.482666\n",
      "    epoch          : 4247\n",
      "    loss           : -1536.872024449925\n",
      "Train Epoch: 4248 [512/60000 (1%)] Loss: -1521.168335\n",
      "Train Epoch: 4248 [11776/60000 (20%)] Loss: -1512.519653\n",
      "Train Epoch: 4248 [23040/60000 (38%)] Loss: -1447.416260\n",
      "Train Epoch: 4248 [34304/60000 (57%)] Loss: -1524.348389\n",
      "Train Epoch: 4248 [45568/60000 (76%)] Loss: -1538.260010\n",
      "Train Epoch: 4248 [56832/60000 (95%)] Loss: -1575.841553\n",
      "    epoch          : 4248\n",
      "    loss           : -1530.4575419452906\n",
      "Train Epoch: 4249 [512/60000 (1%)] Loss: -1545.464844\n",
      "Train Epoch: 4249 [11776/60000 (20%)] Loss: -1584.324951\n",
      "Train Epoch: 4249 [23040/60000 (38%)] Loss: -1555.131348\n",
      "Train Epoch: 4249 [34304/60000 (57%)] Loss: -1582.489990\n",
      "Train Epoch: 4249 [45568/60000 (76%)] Loss: -1587.718872\n",
      "Train Epoch: 4249 [56832/60000 (95%)] Loss: -1526.568237\n",
      "    epoch          : 4249\n",
      "    loss           : -1543.6899014058085\n",
      "Train Epoch: 4250 [512/60000 (1%)] Loss: -1603.242920\n",
      "Train Epoch: 4250 [11776/60000 (20%)] Loss: -1574.906860\n",
      "Train Epoch: 4250 [23040/60000 (38%)] Loss: -1491.189453\n",
      "Train Epoch: 4250 [34304/60000 (57%)] Loss: -1476.889038\n",
      "Train Epoch: 4250 [45568/60000 (76%)] Loss: -1544.992798\n",
      "Train Epoch: 4250 [56832/60000 (95%)] Loss: -1414.647217\n",
      "    epoch          : 4250\n",
      "    loss           : -1531.3308781338276\n",
      "Train Epoch: 4251 [512/60000 (1%)] Loss: -1438.409668\n",
      "Train Epoch: 4251 [11776/60000 (20%)] Loss: -1512.793213\n",
      "Train Epoch: 4251 [23040/60000 (38%)] Loss: -1556.248779\n",
      "Train Epoch: 4251 [34304/60000 (57%)] Loss: -1549.689819\n",
      "Train Epoch: 4251 [45568/60000 (76%)] Loss: -1584.728149\n",
      "Train Epoch: 4251 [56832/60000 (95%)] Loss: -1589.966431\n",
      "    epoch          : 4251\n",
      "    loss           : -1546.0159443138684\n",
      "Train Epoch: 4252 [512/60000 (1%)] Loss: -1476.158447\n",
      "Train Epoch: 4252 [11776/60000 (20%)] Loss: -1597.816040\n",
      "Train Epoch: 4252 [23040/60000 (38%)] Loss: -1461.463501\n",
      "Train Epoch: 4252 [34304/60000 (57%)] Loss: -1521.379028\n",
      "Train Epoch: 4252 [45568/60000 (76%)] Loss: -1549.986450\n",
      "Train Epoch: 4252 [56832/60000 (95%)] Loss: -1561.613770\n",
      "    epoch          : 4252\n",
      "    loss           : -1528.0033010709083\n",
      "Train Epoch: 4253 [512/60000 (1%)] Loss: -1513.713867\n",
      "Train Epoch: 4253 [11776/60000 (20%)] Loss: -1528.856812\n",
      "Train Epoch: 4253 [23040/60000 (38%)] Loss: -1525.677734\n",
      "Train Epoch: 4253 [34304/60000 (57%)] Loss: -1499.018066\n",
      "Train Epoch: 4253 [45568/60000 (76%)] Loss: -1546.987549\n",
      "Train Epoch: 4253 [56832/60000 (95%)] Loss: -1543.125488\n",
      "    epoch          : 4253\n",
      "    loss           : -1536.4549443304202\n",
      "Train Epoch: 4254 [512/60000 (1%)] Loss: -1579.909180\n",
      "Train Epoch: 4254 [11776/60000 (20%)] Loss: -1563.986694\n",
      "Train Epoch: 4254 [23040/60000 (38%)] Loss: -1471.351929\n",
      "Train Epoch: 4254 [34304/60000 (57%)] Loss: -1617.533691\n",
      "Train Epoch: 4254 [45568/60000 (76%)] Loss: -1569.337891\n",
      "Train Epoch: 4254 [56832/60000 (95%)] Loss: -1494.174438\n",
      "    epoch          : 4254\n",
      "    loss           : -1535.3685964810645\n",
      "Train Epoch: 4255 [512/60000 (1%)] Loss: -1575.489990\n",
      "Train Epoch: 4255 [11776/60000 (20%)] Loss: -1539.907471\n",
      "Train Epoch: 4255 [23040/60000 (38%)] Loss: -1560.709961\n",
      "Train Epoch: 4255 [34304/60000 (57%)] Loss: -1521.164795\n",
      "Train Epoch: 4255 [45568/60000 (76%)] Loss: -1464.556763\n",
      "Train Epoch: 4255 [56832/60000 (95%)] Loss: -1567.454956\n",
      "    epoch          : 4255\n",
      "    loss           : -1533.8705616751633\n",
      "Train Epoch: 4256 [512/60000 (1%)] Loss: -1479.661865\n",
      "Train Epoch: 4256 [11776/60000 (20%)] Loss: -1471.147217\n",
      "Train Epoch: 4256 [23040/60000 (38%)] Loss: -1459.363281\n",
      "Train Epoch: 4256 [34304/60000 (57%)] Loss: -1510.283325\n",
      "Train Epoch: 4256 [45568/60000 (76%)] Loss: -1616.339478\n",
      "Train Epoch: 4256 [56832/60000 (95%)] Loss: -1552.409424\n",
      "    epoch          : 4256\n",
      "    loss           : -1541.525324417373\n",
      "Train Epoch: 4257 [512/60000 (1%)] Loss: -1538.632812\n",
      "Train Epoch: 4257 [11776/60000 (20%)] Loss: -1509.915161\n",
      "Train Epoch: 4257 [23040/60000 (38%)] Loss: -1514.964966\n",
      "Train Epoch: 4257 [34304/60000 (57%)] Loss: -1526.794434\n",
      "Train Epoch: 4257 [45568/60000 (76%)] Loss: -1500.737061\n",
      "Train Epoch: 4257 [56832/60000 (95%)] Loss: -1517.169312\n",
      "    epoch          : 4257\n",
      "    loss           : -1531.5392887093928\n",
      "Train Epoch: 4258 [512/60000 (1%)] Loss: -1556.882812\n",
      "Train Epoch: 4258 [11776/60000 (20%)] Loss: -1520.197266\n",
      "Train Epoch: 4258 [23040/60000 (38%)] Loss: -1541.984375\n",
      "Train Epoch: 4258 [34304/60000 (57%)] Loss: -1608.182861\n",
      "Train Epoch: 4258 [45568/60000 (76%)] Loss: -1530.550781\n",
      "Train Epoch: 4258 [56832/60000 (95%)] Loss: -1536.473755\n",
      "    epoch          : 4258\n",
      "    loss           : -1547.9349954896054\n",
      "Train Epoch: 4259 [512/60000 (1%)] Loss: -1556.967651\n",
      "Train Epoch: 4259 [11776/60000 (20%)] Loss: -1554.629883\n",
      "Train Epoch: 4259 [23040/60000 (38%)] Loss: -1435.153809\n",
      "Train Epoch: 4259 [34304/60000 (57%)] Loss: -1530.878784\n",
      "Train Epoch: 4259 [45568/60000 (76%)] Loss: -1575.534912\n",
      "Train Epoch: 4259 [56832/60000 (95%)] Loss: -1496.768555\n",
      "    epoch          : 4259\n",
      "    loss           : -1537.9410196940103\n",
      "Train Epoch: 4260 [512/60000 (1%)] Loss: -1522.352661\n",
      "Train Epoch: 4260 [11776/60000 (20%)] Loss: -1565.501465\n",
      "Train Epoch: 4260 [23040/60000 (38%)] Loss: -1558.043457\n",
      "Train Epoch: 4260 [34304/60000 (57%)] Loss: -1520.025757\n",
      "Train Epoch: 4260 [45568/60000 (76%)] Loss: -1478.505615\n",
      "Train Epoch: 4260 [56832/60000 (95%)] Loss: -1594.619141\n",
      "    epoch          : 4260\n",
      "    loss           : -1534.578155689994\n",
      "Train Epoch: 4261 [512/60000 (1%)] Loss: -1478.606201\n",
      "Train Epoch: 4261 [11776/60000 (20%)] Loss: -1459.538452\n",
      "Train Epoch: 4261 [23040/60000 (38%)] Loss: -1603.823486\n",
      "Train Epoch: 4261 [34304/60000 (57%)] Loss: -1487.494385\n",
      "Train Epoch: 4261 [45568/60000 (76%)] Loss: -1508.886353\n",
      "Train Epoch: 4261 [56832/60000 (95%)] Loss: -1594.155518\n",
      "    epoch          : 4261\n",
      "    loss           : -1533.996407546566\n",
      "Train Epoch: 4262 [512/60000 (1%)] Loss: -1579.754883\n",
      "Train Epoch: 4262 [11776/60000 (20%)] Loss: -1523.329102\n",
      "Train Epoch: 4262 [23040/60000 (38%)] Loss: -1540.987305\n",
      "Train Epoch: 4262 [34304/60000 (57%)] Loss: -1584.669922\n",
      "Train Epoch: 4262 [45568/60000 (76%)] Loss: -1588.598145\n",
      "Train Epoch: 4262 [56832/60000 (95%)] Loss: -1509.250732\n",
      "    epoch          : 4262\n",
      "    loss           : -1535.4258060778602\n",
      "Train Epoch: 4263 [512/60000 (1%)] Loss: -1494.940308\n",
      "Train Epoch: 4263 [11776/60000 (20%)] Loss: -1580.923340\n",
      "Train Epoch: 4263 [23040/60000 (38%)] Loss: -1575.974854\n",
      "Train Epoch: 4263 [34304/60000 (57%)] Loss: -1501.310425\n",
      "Train Epoch: 4263 [45568/60000 (76%)] Loss: -1489.109497\n",
      "Train Epoch: 4263 [56832/60000 (95%)] Loss: -1568.697388\n",
      "    epoch          : 4263\n",
      "    loss           : -1545.2498893091233\n",
      "Train Epoch: 4264 [512/60000 (1%)] Loss: -1546.145996\n",
      "Train Epoch: 4264 [11776/60000 (20%)] Loss: -1498.850098\n",
      "Train Epoch: 4264 [23040/60000 (38%)] Loss: -1565.223022\n",
      "Train Epoch: 4264 [34304/60000 (57%)] Loss: -1593.773438\n",
      "Train Epoch: 4264 [45568/60000 (76%)] Loss: -1599.853516\n",
      "Train Epoch: 4264 [56832/60000 (95%)] Loss: -1499.454224\n",
      "    epoch          : 4264\n",
      "    loss           : -1537.0168281167241\n",
      "Train Epoch: 4265 [512/60000 (1%)] Loss: -1554.229858\n",
      "Train Epoch: 4265 [11776/60000 (20%)] Loss: -1467.112183\n",
      "Train Epoch: 4265 [23040/60000 (38%)] Loss: -1580.403442\n",
      "Train Epoch: 4265 [34304/60000 (57%)] Loss: -1624.113037\n",
      "Train Epoch: 4265 [45568/60000 (76%)] Loss: -1508.663330\n",
      "Train Epoch: 4265 [56832/60000 (95%)] Loss: -1575.640991\n",
      "    epoch          : 4265\n",
      "    loss           : -1533.794459111273\n",
      "Train Epoch: 4266 [512/60000 (1%)] Loss: -1548.924927\n",
      "Train Epoch: 4266 [11776/60000 (20%)] Loss: -1504.833862\n",
      "Train Epoch: 4266 [23040/60000 (38%)] Loss: -1523.845703\n",
      "Train Epoch: 4266 [34304/60000 (57%)] Loss: -1469.183350\n",
      "Train Epoch: 4266 [45568/60000 (76%)] Loss: -1558.558105\n",
      "Train Epoch: 4266 [56832/60000 (95%)] Loss: -1583.312012\n",
      "    epoch          : 4266\n",
      "    loss           : -1538.2070874575168\n",
      "Train Epoch: 4267 [512/60000 (1%)] Loss: -1564.216431\n",
      "Train Epoch: 4267 [11776/60000 (20%)] Loss: -1508.569214\n",
      "Train Epoch: 4267 [23040/60000 (38%)] Loss: -1507.493164\n",
      "Train Epoch: 4267 [34304/60000 (57%)] Loss: -1492.771484\n",
      "Train Epoch: 4267 [45568/60000 (76%)] Loss: -1551.629517\n",
      "Train Epoch: 4267 [56832/60000 (95%)] Loss: -1572.439331\n",
      "    epoch          : 4267\n",
      "    loss           : -1539.027503406934\n",
      "Train Epoch: 4268 [512/60000 (1%)] Loss: -1565.487061\n",
      "Train Epoch: 4268 [11776/60000 (20%)] Loss: -1543.813599\n",
      "Train Epoch: 4268 [23040/60000 (38%)] Loss: -1498.784180\n",
      "Train Epoch: 4268 [34304/60000 (57%)] Loss: -1473.632324\n",
      "Train Epoch: 4268 [45568/60000 (76%)] Loss: -1509.060913\n",
      "Train Epoch: 4268 [56832/60000 (95%)] Loss: -1578.338989\n",
      "    epoch          : 4268\n",
      "    loss           : -1537.1288117661989\n",
      "Train Epoch: 4269 [512/60000 (1%)] Loss: -1570.322510\n",
      "Train Epoch: 4269 [11776/60000 (20%)] Loss: -1562.276245\n",
      "Train Epoch: 4269 [23040/60000 (38%)] Loss: -1518.932373\n",
      "Train Epoch: 4269 [34304/60000 (57%)] Loss: -1553.717651\n",
      "Train Epoch: 4269 [45568/60000 (76%)] Loss: -1523.660522\n",
      "Train Epoch: 4269 [56832/60000 (95%)] Loss: -1505.230835\n",
      "    epoch          : 4269\n",
      "    loss           : -1540.6122971012094\n",
      "Train Epoch: 4270 [512/60000 (1%)] Loss: -1594.466309\n",
      "Train Epoch: 4270 [11776/60000 (20%)] Loss: -1536.207031\n",
      "Train Epoch: 4270 [23040/60000 (38%)] Loss: -1566.491089\n",
      "Train Epoch: 4270 [34304/60000 (57%)] Loss: -1453.043945\n",
      "Train Epoch: 4270 [45568/60000 (76%)] Loss: -1520.750244\n",
      "Train Epoch: 4270 [56832/60000 (95%)] Loss: -1585.512817\n",
      "    epoch          : 4270\n",
      "    loss           : -1535.474449718066\n",
      "Train Epoch: 4271 [512/60000 (1%)] Loss: -1614.494019\n",
      "Train Epoch: 4271 [11776/60000 (20%)] Loss: -1547.105957\n",
      "Train Epoch: 4271 [23040/60000 (38%)] Loss: -1546.212158\n",
      "Train Epoch: 4271 [34304/60000 (57%)] Loss: -1487.923950\n",
      "Train Epoch: 4271 [45568/60000 (76%)] Loss: -1511.660034\n",
      "Train Epoch: 4271 [56832/60000 (95%)] Loss: -1519.652832\n",
      "    epoch          : 4271\n",
      "    loss           : -1537.3150645110566\n",
      "Train Epoch: 4272 [512/60000 (1%)] Loss: -1543.753784\n",
      "Train Epoch: 4272 [11776/60000 (20%)] Loss: -1501.273193\n",
      "Train Epoch: 4272 [23040/60000 (38%)] Loss: -1543.589233\n",
      "Train Epoch: 4272 [34304/60000 (57%)] Loss: -1625.726440\n",
      "Train Epoch: 4272 [45568/60000 (76%)] Loss: -1537.366211\n",
      "Train Epoch: 4272 [56832/60000 (95%)] Loss: -1494.644531\n",
      "    epoch          : 4272\n",
      "    loss           : -1537.2239886784957\n",
      "Train Epoch: 4273 [512/60000 (1%)] Loss: -1513.129150\n",
      "Train Epoch: 4273 [11776/60000 (20%)] Loss: -1528.300781\n",
      "Train Epoch: 4273 [23040/60000 (38%)] Loss: -1484.541504\n",
      "Train Epoch: 4273 [34304/60000 (57%)] Loss: -1551.689941\n",
      "Train Epoch: 4273 [45568/60000 (76%)] Loss: -1479.432129\n",
      "Train Epoch: 4273 [56832/60000 (95%)] Loss: -1587.963867\n",
      "    epoch          : 4273\n",
      "    loss           : -1533.9993379237287\n",
      "Train Epoch: 4274 [512/60000 (1%)] Loss: -1492.275146\n",
      "Train Epoch: 4274 [11776/60000 (20%)] Loss: -1495.200562\n",
      "Train Epoch: 4274 [23040/60000 (38%)] Loss: -1608.554199\n",
      "Train Epoch: 4274 [34304/60000 (57%)] Loss: -1529.522095\n",
      "Train Epoch: 4274 [45568/60000 (76%)] Loss: -1522.357666\n",
      "Train Epoch: 4274 [56832/60000 (95%)] Loss: -1575.730713\n",
      "    epoch          : 4274\n",
      "    loss           : -1535.5536116260594\n",
      "Train Epoch: 4275 [512/60000 (1%)] Loss: -1494.329712\n",
      "Train Epoch: 4275 [11776/60000 (20%)] Loss: -1506.245605\n",
      "Train Epoch: 4275 [23040/60000 (38%)] Loss: -1541.360840\n",
      "Train Epoch: 4275 [34304/60000 (57%)] Loss: -1494.560547\n",
      "Train Epoch: 4275 [45568/60000 (76%)] Loss: -1569.272705\n",
      "Train Epoch: 4275 [56832/60000 (95%)] Loss: -1588.928711\n",
      "    epoch          : 4275\n",
      "    loss           : -1528.405655855513\n",
      "Train Epoch: 4276 [512/60000 (1%)] Loss: -1559.112915\n",
      "Train Epoch: 4276 [11776/60000 (20%)] Loss: -1492.900269\n",
      "Train Epoch: 4276 [23040/60000 (38%)] Loss: -1558.125488\n",
      "Train Epoch: 4276 [34304/60000 (57%)] Loss: -1500.128296\n",
      "Train Epoch: 4276 [45568/60000 (76%)] Loss: -1601.060059\n",
      "Train Epoch: 4276 [56832/60000 (95%)] Loss: -1623.889404\n",
      "    epoch          : 4276\n",
      "    loss           : -1541.6114415745278\n",
      "Train Epoch: 4277 [512/60000 (1%)] Loss: -1551.001221\n",
      "Train Epoch: 4277 [11776/60000 (20%)] Loss: -1460.287231\n",
      "Train Epoch: 4277 [23040/60000 (38%)] Loss: -1588.439819\n",
      "Train Epoch: 4277 [34304/60000 (57%)] Loss: -1595.849121\n",
      "Train Epoch: 4277 [45568/60000 (76%)] Loss: -1465.584961\n",
      "Train Epoch: 4277 [56832/60000 (95%)] Loss: -1605.242188\n",
      "    epoch          : 4277\n",
      "    loss           : -1535.4411572817355\n",
      "Train Epoch: 4278 [512/60000 (1%)] Loss: -1588.538696\n",
      "Train Epoch: 4278 [11776/60000 (20%)] Loss: -1535.929199\n",
      "Train Epoch: 4278 [23040/60000 (38%)] Loss: -1445.235962\n",
      "Train Epoch: 4278 [34304/60000 (57%)] Loss: -1559.019531\n",
      "Train Epoch: 4278 [45568/60000 (76%)] Loss: -1555.502197\n",
      "Train Epoch: 4278 [56832/60000 (95%)] Loss: -1516.241211\n",
      "    epoch          : 4278\n",
      "    loss           : -1539.1906045170153\n",
      "Train Epoch: 4279 [512/60000 (1%)] Loss: -1556.283691\n",
      "Train Epoch: 4279 [11776/60000 (20%)] Loss: -1520.825684\n",
      "Train Epoch: 4279 [23040/60000 (38%)] Loss: -1596.984009\n",
      "Train Epoch: 4279 [34304/60000 (57%)] Loss: -1533.380127\n",
      "Train Epoch: 4279 [45568/60000 (76%)] Loss: -1579.225830\n",
      "Train Epoch: 4279 [56832/60000 (95%)] Loss: -1592.230225\n",
      "    epoch          : 4279\n",
      "    loss           : -1539.7629191080728\n",
      "Train Epoch: 4280 [512/60000 (1%)] Loss: -1552.788330\n",
      "Train Epoch: 4280 [11776/60000 (20%)] Loss: -1584.947510\n",
      "Train Epoch: 4280 [23040/60000 (38%)] Loss: -1598.559570\n",
      "Train Epoch: 4280 [34304/60000 (57%)] Loss: -1534.190674\n",
      "Train Epoch: 4280 [45568/60000 (76%)] Loss: -1539.419922\n",
      "Train Epoch: 4280 [56832/60000 (95%)] Loss: -1557.401855\n",
      "    epoch          : 4280\n",
      "    loss           : -1534.8172924666756\n",
      "Train Epoch: 4281 [512/60000 (1%)] Loss: -1457.123779\n",
      "Train Epoch: 4281 [11776/60000 (20%)] Loss: -1421.610107\n",
      "Train Epoch: 4281 [23040/60000 (38%)] Loss: -1620.670532\n",
      "Train Epoch: 4281 [34304/60000 (57%)] Loss: -1503.166260\n",
      "Train Epoch: 4281 [45568/60000 (76%)] Loss: -1554.596069\n",
      "Train Epoch: 4281 [56832/60000 (95%)] Loss: -1558.083984\n",
      "    epoch          : 4281\n",
      "    loss           : -1537.248386878752\n",
      "Train Epoch: 4282 [512/60000 (1%)] Loss: -1578.084961\n",
      "Train Epoch: 4282 [11776/60000 (20%)] Loss: -1487.745361\n",
      "Train Epoch: 4282 [23040/60000 (38%)] Loss: -1595.905762\n",
      "Train Epoch: 4282 [34304/60000 (57%)] Loss: -1504.553223\n",
      "Train Epoch: 4282 [45568/60000 (76%)] Loss: -1560.503418\n",
      "Train Epoch: 4282 [56832/60000 (95%)] Loss: -1549.918701\n",
      "    epoch          : 4282\n",
      "    loss           : -1541.4143390547756\n",
      "Train Epoch: 4283 [512/60000 (1%)] Loss: -1536.406738\n",
      "Train Epoch: 4283 [11776/60000 (20%)] Loss: -1541.530518\n",
      "Train Epoch: 4283 [23040/60000 (38%)] Loss: -1559.340332\n",
      "Train Epoch: 4283 [34304/60000 (57%)] Loss: -1604.700562\n",
      "Train Epoch: 4283 [45568/60000 (76%)] Loss: -1564.321045\n",
      "Train Epoch: 4283 [56832/60000 (95%)] Loss: -1503.860107\n",
      "    epoch          : 4283\n",
      "    loss           : -1543.7436040673551\n",
      "Train Epoch: 4284 [512/60000 (1%)] Loss: -1532.483765\n",
      "Train Epoch: 4284 [11776/60000 (20%)] Loss: -1578.008789\n",
      "Train Epoch: 4284 [23040/60000 (38%)] Loss: -1491.705688\n",
      "Train Epoch: 4284 [34304/60000 (57%)] Loss: -1578.753174\n",
      "Train Epoch: 4284 [45568/60000 (76%)] Loss: -1553.479492\n",
      "Train Epoch: 4284 [56832/60000 (95%)] Loss: -1590.163330\n",
      "    epoch          : 4284\n",
      "    loss           : -1543.0947500110346\n",
      "Train Epoch: 4285 [512/60000 (1%)] Loss: -1529.494873\n",
      "Train Epoch: 4285 [11776/60000 (20%)] Loss: -1582.984375\n",
      "Train Epoch: 4285 [23040/60000 (38%)] Loss: -1521.745361\n",
      "Train Epoch: 4285 [34304/60000 (57%)] Loss: -1582.421631\n",
      "Train Epoch: 4285 [45568/60000 (76%)] Loss: -1588.376709\n",
      "Train Epoch: 4285 [56832/60000 (95%)] Loss: -1527.116455\n",
      "    epoch          : 4285\n",
      "    loss           : -1539.1881048342602\n",
      "Train Epoch: 4286 [512/60000 (1%)] Loss: -1509.284058\n",
      "Train Epoch: 4286 [11776/60000 (20%)] Loss: -1554.104004\n",
      "Train Epoch: 4286 [23040/60000 (38%)] Loss: -1619.087646\n",
      "Train Epoch: 4286 [34304/60000 (57%)] Loss: -1494.661865\n",
      "Train Epoch: 4286 [45568/60000 (76%)] Loss: -1531.693848\n",
      "Train Epoch: 4286 [56832/60000 (95%)] Loss: -1586.093872\n",
      "    epoch          : 4286\n",
      "    loss           : -1535.4019044348074\n",
      "Train Epoch: 4287 [512/60000 (1%)] Loss: -1513.906616\n",
      "Train Epoch: 4287 [11776/60000 (20%)] Loss: -1522.625122\n",
      "Train Epoch: 4287 [23040/60000 (38%)] Loss: -1553.238281\n",
      "Train Epoch: 4287 [34304/60000 (57%)] Loss: -1547.140503\n",
      "Train Epoch: 4287 [45568/60000 (76%)] Loss: -1412.016602\n",
      "Train Epoch: 4287 [56832/60000 (95%)] Loss: -1537.663574\n",
      "    epoch          : 4287\n",
      "    loss           : -1536.8832466427216\n",
      "Train Epoch: 4288 [512/60000 (1%)] Loss: -1581.164307\n",
      "Train Epoch: 4288 [11776/60000 (20%)] Loss: -1499.886353\n",
      "Train Epoch: 4288 [23040/60000 (38%)] Loss: -1538.597900\n",
      "Train Epoch: 4288 [34304/60000 (57%)] Loss: -1577.294067\n",
      "Train Epoch: 4288 [45568/60000 (76%)] Loss: -1484.277588\n",
      "Train Epoch: 4288 [56832/60000 (95%)] Loss: -1497.402588\n",
      "    epoch          : 4288\n",
      "    loss           : -1534.6765357410839\n",
      "Train Epoch: 4289 [512/60000 (1%)] Loss: -1510.584961\n",
      "Train Epoch: 4289 [11776/60000 (20%)] Loss: -1516.127319\n",
      "Train Epoch: 4289 [23040/60000 (38%)] Loss: -1586.468872\n",
      "Train Epoch: 4289 [34304/60000 (57%)] Loss: -1551.704468\n",
      "Train Epoch: 4289 [45568/60000 (76%)] Loss: -1580.770874\n",
      "Train Epoch: 4289 [56832/60000 (95%)] Loss: -1519.052246\n",
      "    epoch          : 4289\n",
      "    loss           : -1535.327430509578\n",
      "Train Epoch: 4290 [512/60000 (1%)] Loss: -1545.928467\n",
      "Train Epoch: 4290 [11776/60000 (20%)] Loss: -1569.200439\n",
      "Train Epoch: 4290 [23040/60000 (38%)] Loss: -1584.966431\n",
      "Train Epoch: 4290 [34304/60000 (57%)] Loss: -1554.409180\n",
      "Train Epoch: 4290 [45568/60000 (76%)] Loss: -1529.226807\n",
      "Train Epoch: 4290 [56832/60000 (95%)] Loss: -1538.756836\n",
      "    epoch          : 4290\n",
      "    loss           : -1534.7629391082937\n",
      "Train Epoch: 4291 [512/60000 (1%)] Loss: -1510.219604\n",
      "Train Epoch: 4291 [11776/60000 (20%)] Loss: -1461.428955\n",
      "Train Epoch: 4291 [23040/60000 (38%)] Loss: -1556.298096\n",
      "Train Epoch: 4291 [34304/60000 (57%)] Loss: -1505.500977\n",
      "Train Epoch: 4291 [45568/60000 (76%)] Loss: -1568.444946\n",
      "Train Epoch: 4291 [56832/60000 (95%)] Loss: -1514.301270\n",
      "    epoch          : 4291\n",
      "    loss           : -1540.3491131626279\n",
      "Train Epoch: 4292 [512/60000 (1%)] Loss: -1507.527588\n",
      "Train Epoch: 4292 [11776/60000 (20%)] Loss: -1611.202271\n",
      "Train Epoch: 4292 [23040/60000 (38%)] Loss: -1514.851074\n",
      "Train Epoch: 4292 [34304/60000 (57%)] Loss: -1563.921875\n",
      "Train Epoch: 4292 [45568/60000 (76%)] Loss: -1553.171143\n",
      "Train Epoch: 4292 [56832/60000 (95%)] Loss: -1513.584229\n",
      "    epoch          : 4292\n",
      "    loss           : -1537.6805954410531\n",
      "Train Epoch: 4293 [512/60000 (1%)] Loss: -1583.796387\n",
      "Train Epoch: 4293 [11776/60000 (20%)] Loss: -1549.409302\n",
      "Train Epoch: 4293 [23040/60000 (38%)] Loss: -1574.116455\n",
      "Train Epoch: 4293 [34304/60000 (57%)] Loss: -1556.222656\n",
      "Train Epoch: 4293 [45568/60000 (76%)] Loss: -1545.593140\n",
      "Train Epoch: 4293 [56832/60000 (95%)] Loss: -1552.880615\n",
      "    epoch          : 4293\n",
      "    loss           : -1535.4987072271142\n",
      "Train Epoch: 4294 [512/60000 (1%)] Loss: -1609.070801\n",
      "Train Epoch: 4294 [11776/60000 (20%)] Loss: -1519.114014\n",
      "Train Epoch: 4294 [23040/60000 (38%)] Loss: -1592.358887\n",
      "Train Epoch: 4294 [34304/60000 (57%)] Loss: -1524.892700\n",
      "Train Epoch: 4294 [45568/60000 (76%)] Loss: -1580.548462\n",
      "Train Epoch: 4294 [56832/60000 (95%)] Loss: -1559.654053\n",
      "    epoch          : 4294\n",
      "    loss           : -1538.6202209817486\n",
      "Train Epoch: 4295 [512/60000 (1%)] Loss: -1593.559814\n",
      "Train Epoch: 4295 [11776/60000 (20%)] Loss: -1606.068115\n",
      "Train Epoch: 4295 [23040/60000 (38%)] Loss: -1540.762207\n",
      "Train Epoch: 4295 [34304/60000 (57%)] Loss: -1473.993774\n",
      "Train Epoch: 4295 [45568/60000 (76%)] Loss: -1529.385132\n",
      "Train Epoch: 4295 [56832/60000 (95%)] Loss: -1564.208252\n",
      "    epoch          : 4295\n",
      "    loss           : -1537.4593654136872\n",
      "Train Epoch: 4296 [512/60000 (1%)] Loss: -1542.555908\n",
      "Train Epoch: 4296 [11776/60000 (20%)] Loss: -1582.848877\n",
      "Train Epoch: 4296 [23040/60000 (38%)] Loss: -1522.209229\n",
      "Train Epoch: 4296 [34304/60000 (57%)] Loss: -1618.451538\n",
      "Train Epoch: 4296 [45568/60000 (76%)] Loss: -1621.133057\n",
      "Train Epoch: 4296 [56832/60000 (95%)] Loss: -1570.472900\n",
      "    epoch          : 4296\n",
      "    loss           : -1533.818391099488\n",
      "Train Epoch: 4297 [512/60000 (1%)] Loss: -1550.918579\n",
      "Train Epoch: 4297 [11776/60000 (20%)] Loss: -1572.225464\n",
      "Train Epoch: 4297 [23040/60000 (38%)] Loss: -1524.565063\n",
      "Train Epoch: 4297 [34304/60000 (57%)] Loss: -1564.582520\n",
      "Train Epoch: 4297 [45568/60000 (76%)] Loss: -1567.767334\n",
      "Train Epoch: 4297 [56832/60000 (95%)] Loss: -1507.982300\n",
      "    epoch          : 4297\n",
      "    loss           : -1544.4419393593307\n",
      "Train Epoch: 4298 [512/60000 (1%)] Loss: -1510.636230\n",
      "Train Epoch: 4298 [11776/60000 (20%)] Loss: -1554.377563\n",
      "Train Epoch: 4298 [23040/60000 (38%)] Loss: -1552.562256\n",
      "Train Epoch: 4298 [34304/60000 (57%)] Loss: -1570.955078\n",
      "Train Epoch: 4298 [45568/60000 (76%)] Loss: -1460.244995\n",
      "Train Epoch: 4298 [56832/60000 (95%)] Loss: -1526.884644\n",
      "    epoch          : 4298\n",
      "    loss           : -1536.3504700741526\n",
      "Train Epoch: 4299 [512/60000 (1%)] Loss: -1486.826904\n",
      "Train Epoch: 4299 [11776/60000 (20%)] Loss: -1458.352661\n",
      "Train Epoch: 4299 [23040/60000 (38%)] Loss: -1491.949951\n",
      "Train Epoch: 4299 [34304/60000 (57%)] Loss: -1513.731689\n",
      "Train Epoch: 4299 [45568/60000 (76%)] Loss: -1525.376587\n",
      "Train Epoch: 4299 [56832/60000 (95%)] Loss: -1552.966553\n",
      "    epoch          : 4299\n",
      "    loss           : -1538.842665850106\n",
      "Train Epoch: 4300 [512/60000 (1%)] Loss: -1567.249756\n",
      "Train Epoch: 4300 [11776/60000 (20%)] Loss: -1451.790771\n",
      "Train Epoch: 4300 [23040/60000 (38%)] Loss: -1563.180298\n",
      "Train Epoch: 4300 [34304/60000 (57%)] Loss: -1517.510742\n",
      "Train Epoch: 4300 [45568/60000 (76%)] Loss: -1555.358032\n",
      "Train Epoch: 4300 [56832/60000 (95%)] Loss: -1544.012207\n",
      "    epoch          : 4300\n",
      "    loss           : -1536.557498910333\n",
      "Saving checkpoint: saved/models/Mnist_DeepGenerativeOperad/0127_111843/checkpoint-epoch4300.pth ...\n",
      "Train Epoch: 4301 [512/60000 (1%)] Loss: -1520.027832\n",
      "Train Epoch: 4301 [11776/60000 (20%)] Loss: -1631.142822\n",
      "Train Epoch: 4301 [23040/60000 (38%)] Loss: -1576.382202\n",
      "Train Epoch: 4301 [34304/60000 (57%)] Loss: -1569.351562\n",
      "Train Epoch: 4301 [45568/60000 (76%)] Loss: -1579.979614\n",
      "Train Epoch: 4301 [56832/60000 (95%)] Loss: -1551.052734\n",
      "    epoch          : 4301\n",
      "    loss           : -1545.543988416424\n",
      "Train Epoch: 4302 [512/60000 (1%)] Loss: -1535.508911\n",
      "Train Epoch: 4302 [11776/60000 (20%)] Loss: -1586.202637\n",
      "Train Epoch: 4302 [23040/60000 (38%)] Loss: -1576.161377\n",
      "Train Epoch: 4302 [34304/60000 (57%)] Loss: -1498.120361\n",
      "Train Epoch: 4302 [45568/60000 (76%)] Loss: -1519.021240\n",
      "Train Epoch: 4302 [56832/60000 (95%)] Loss: -1465.634033\n",
      "    epoch          : 4302\n",
      "    loss           : -1540.2432413047318\n",
      "Train Epoch: 4303 [512/60000 (1%)] Loss: -1522.853271\n",
      "Train Epoch: 4303 [11776/60000 (20%)] Loss: -1538.488281\n",
      "Train Epoch: 4303 [23040/60000 (38%)] Loss: -1577.283325\n",
      "Train Epoch: 4303 [34304/60000 (57%)] Loss: -1492.062500\n",
      "Train Epoch: 4303 [45568/60000 (76%)] Loss: -1468.270508\n",
      "Train Epoch: 4303 [56832/60000 (95%)] Loss: -1521.249512\n",
      "    epoch          : 4303\n",
      "    loss           : -1532.376196220096\n",
      "Train Epoch: 4304 [512/60000 (1%)] Loss: -1592.583130\n",
      "Train Epoch: 4304 [11776/60000 (20%)] Loss: -1600.245850\n",
      "Train Epoch: 4304 [23040/60000 (38%)] Loss: -1484.822632\n",
      "Train Epoch: 4304 [34304/60000 (57%)] Loss: -1588.714111\n",
      "Train Epoch: 4304 [45568/60000 (76%)] Loss: -1416.362671\n",
      "Train Epoch: 4304 [56832/60000 (95%)] Loss: -1516.654297\n",
      "    epoch          : 4304\n",
      "    loss           : -1533.6075460143009\n",
      "Train Epoch: 4305 [512/60000 (1%)] Loss: -1561.302979\n",
      "Train Epoch: 4305 [11776/60000 (20%)] Loss: -1556.184204\n",
      "Train Epoch: 4305 [23040/60000 (38%)] Loss: -1576.733032\n",
      "Train Epoch: 4305 [34304/60000 (57%)] Loss: -1461.560791\n",
      "Train Epoch: 4305 [45568/60000 (76%)] Loss: -1576.519897\n",
      "Train Epoch: 4305 [56832/60000 (95%)] Loss: -1497.199829\n",
      "    epoch          : 4305\n",
      "    loss           : -1533.9554433014434\n",
      "Train Epoch: 4306 [512/60000 (1%)] Loss: -1536.317383\n",
      "Train Epoch: 4306 [11776/60000 (20%)] Loss: -1544.204102\n",
      "Train Epoch: 4306 [23040/60000 (38%)] Loss: -1547.238037\n",
      "Train Epoch: 4306 [34304/60000 (57%)] Loss: -1547.550537\n",
      "Train Epoch: 4306 [45568/60000 (76%)] Loss: -1500.413574\n",
      "Train Epoch: 4306 [56832/60000 (95%)] Loss: -1617.347778\n",
      "    epoch          : 4306\n",
      "    loss           : -1537.4375962079582\n",
      "Train Epoch: 4307 [512/60000 (1%)] Loss: -1559.700928\n",
      "Train Epoch: 4307 [11776/60000 (20%)] Loss: -1515.386108\n",
      "Train Epoch: 4307 [23040/60000 (38%)] Loss: -1558.738037\n",
      "Train Epoch: 4307 [34304/60000 (57%)] Loss: -1562.004883\n",
      "Train Epoch: 4307 [45568/60000 (76%)] Loss: -1451.510254\n",
      "Train Epoch: 4307 [56832/60000 (95%)] Loss: -1534.290527\n",
      "    epoch          : 4307\n",
      "    loss           : -1539.5859592243776\n",
      "Train Epoch: 4308 [512/60000 (1%)] Loss: -1524.106323\n",
      "Train Epoch: 4308 [11776/60000 (20%)] Loss: -1520.084106\n",
      "Train Epoch: 4308 [23040/60000 (38%)] Loss: -1568.863525\n",
      "Train Epoch: 4308 [34304/60000 (57%)] Loss: -1509.416992\n",
      "Train Epoch: 4308 [45568/60000 (76%)] Loss: -1558.817383\n",
      "Train Epoch: 4308 [56832/60000 (95%)] Loss: -1528.911255\n",
      "    epoch          : 4308\n",
      "    loss           : -1538.8326705673994\n",
      "Train Epoch: 4309 [512/60000 (1%)] Loss: -1575.027832\n",
      "Train Epoch: 4309 [11776/60000 (20%)] Loss: -1543.750977\n",
      "Train Epoch: 4309 [23040/60000 (38%)] Loss: -1534.010742\n",
      "Train Epoch: 4309 [34304/60000 (57%)] Loss: -1521.165405\n",
      "Train Epoch: 4309 [45568/60000 (76%)] Loss: -1537.015869\n",
      "Train Epoch: 4309 [56832/60000 (95%)] Loss: -1536.608643\n",
      "    epoch          : 4309\n",
      "    loss           : -1532.278214449263\n",
      "Train Epoch: 4310 [512/60000 (1%)] Loss: -1563.793213\n",
      "Train Epoch: 4310 [11776/60000 (20%)] Loss: -1573.678833\n",
      "Train Epoch: 4310 [23040/60000 (38%)] Loss: -1510.442993\n",
      "Train Epoch: 4310 [34304/60000 (57%)] Loss: -1447.368530\n",
      "Train Epoch: 4310 [45568/60000 (76%)] Loss: -1507.512451\n",
      "Train Epoch: 4310 [56832/60000 (95%)] Loss: -1486.818604\n",
      "    epoch          : 4310\n",
      "    loss           : -1528.9881236620542\n",
      "Train Epoch: 4311 [512/60000 (1%)] Loss: -1502.720215\n",
      "Train Epoch: 4311 [11776/60000 (20%)] Loss: -1508.644287\n",
      "Train Epoch: 4311 [23040/60000 (38%)] Loss: -1568.013428\n",
      "Train Epoch: 4311 [34304/60000 (57%)] Loss: -1537.899902\n",
      "Train Epoch: 4311 [45568/60000 (76%)] Loss: -1577.053223\n",
      "Train Epoch: 4311 [56832/60000 (95%)] Loss: -1522.664307\n",
      "    epoch          : 4311\n",
      "    loss           : -1538.0228723213497\n",
      "Train Epoch: 4312 [512/60000 (1%)] Loss: -1573.440674\n",
      "Train Epoch: 4312 [11776/60000 (20%)] Loss: -1572.463501\n",
      "Train Epoch: 4312 [23040/60000 (38%)] Loss: -1532.603271\n",
      "Train Epoch: 4312 [34304/60000 (57%)] Loss: -1532.468262\n",
      "Train Epoch: 4312 [45568/60000 (76%)] Loss: -1502.477173\n",
      "Train Epoch: 4312 [56832/60000 (95%)] Loss: -1542.543457\n",
      "    epoch          : 4312\n",
      "    loss           : -1537.8861452953965\n",
      "Train Epoch: 4313 [512/60000 (1%)] Loss: -1539.051147\n",
      "Train Epoch: 4313 [11776/60000 (20%)] Loss: -1534.949219\n",
      "Train Epoch: 4313 [23040/60000 (38%)] Loss: -1596.714844\n",
      "Train Epoch: 4313 [34304/60000 (57%)] Loss: -1584.019287\n",
      "Train Epoch: 4313 [45568/60000 (76%)] Loss: -1536.529297\n",
      "Train Epoch: 4313 [56832/60000 (95%)] Loss: -1532.064209\n",
      "    epoch          : 4313\n",
      "    loss           : -1537.6895127808307\n",
      "Train Epoch: 4314 [512/60000 (1%)] Loss: -1534.495728\n",
      "Train Epoch: 4314 [11776/60000 (20%)] Loss: -1528.355713\n",
      "Train Epoch: 4314 [23040/60000 (38%)] Loss: -1471.614014\n",
      "Train Epoch: 4314 [34304/60000 (57%)] Loss: -1549.952881\n",
      "Train Epoch: 4314 [45568/60000 (76%)] Loss: -1623.807495\n",
      "Train Epoch: 4314 [56832/60000 (95%)] Loss: -1571.225708\n",
      "    epoch          : 4314\n",
      "    loss           : -1534.3077071884932\n",
      "Train Epoch: 4315 [512/60000 (1%)] Loss: -1510.975098\n",
      "Train Epoch: 4315 [11776/60000 (20%)] Loss: -1556.391357\n",
      "Train Epoch: 4315 [23040/60000 (38%)] Loss: -1557.322021\n",
      "Train Epoch: 4315 [34304/60000 (57%)] Loss: -1594.066895\n",
      "Train Epoch: 4315 [45568/60000 (76%)] Loss: -1499.221558\n",
      "Train Epoch: 4315 [56832/60000 (95%)] Loss: -1552.365601\n",
      "    epoch          : 4315\n",
      "    loss           : -1533.7733312919315\n",
      "Train Epoch: 4316 [512/60000 (1%)] Loss: -1597.712646\n",
      "Train Epoch: 4316 [11776/60000 (20%)] Loss: -1544.728760\n",
      "Train Epoch: 4316 [23040/60000 (38%)] Loss: -1505.922119\n",
      "Train Epoch: 4316 [34304/60000 (57%)] Loss: -1575.469604\n",
      "Train Epoch: 4316 [45568/60000 (76%)] Loss: -1610.954102\n",
      "Train Epoch: 4316 [56832/60000 (95%)] Loss: -1509.780762\n",
      "    epoch          : 4316\n",
      "    loss           : -1539.4767259500795\n",
      "Train Epoch: 4317 [512/60000 (1%)] Loss: -1508.636719\n",
      "Train Epoch: 4317 [11776/60000 (20%)] Loss: -1462.751953\n",
      "Train Epoch: 4317 [23040/60000 (38%)] Loss: -1474.671875\n",
      "Train Epoch: 4317 [34304/60000 (57%)] Loss: -1515.135986\n",
      "Train Epoch: 4317 [45568/60000 (76%)] Loss: -1563.027100\n",
      "Train Epoch: 4317 [56832/60000 (95%)] Loss: -1571.822510\n",
      "    epoch          : 4317\n",
      "    loss           : -1534.9885581496073\n",
      "Train Epoch: 4318 [512/60000 (1%)] Loss: -1548.261841\n",
      "Train Epoch: 4318 [11776/60000 (20%)] Loss: -1572.277832\n",
      "Train Epoch: 4318 [23040/60000 (38%)] Loss: -1493.451416\n",
      "Train Epoch: 4318 [34304/60000 (57%)] Loss: -1473.027832\n",
      "Train Epoch: 4318 [45568/60000 (76%)] Loss: -1607.783203\n",
      "Train Epoch: 4318 [56832/60000 (95%)] Loss: -1508.970215\n",
      "    epoch          : 4318\n",
      "    loss           : -1543.5288879049701\n",
      "Train Epoch: 4319 [512/60000 (1%)] Loss: -1523.860840\n",
      "Train Epoch: 4319 [11776/60000 (20%)] Loss: -1562.677368\n",
      "Train Epoch: 4319 [23040/60000 (38%)] Loss: -1531.690674\n",
      "Train Epoch: 4319 [34304/60000 (57%)] Loss: -1544.378052\n",
      "Train Epoch: 4319 [45568/60000 (76%)] Loss: -1556.214966\n",
      "Train Epoch: 4319 [56832/60000 (95%)] Loss: -1615.639648\n",
      "    epoch          : 4319\n",
      "    loss           : -1539.4091669287386\n",
      "Train Epoch: 4320 [512/60000 (1%)] Loss: -1596.887695\n",
      "Train Epoch: 4320 [11776/60000 (20%)] Loss: -1558.994629\n",
      "Train Epoch: 4320 [23040/60000 (38%)] Loss: -1521.304199\n",
      "Train Epoch: 4320 [34304/60000 (57%)] Loss: -1534.388184\n",
      "Train Epoch: 4320 [45568/60000 (76%)] Loss: -1573.610962\n",
      "Train Epoch: 4320 [56832/60000 (95%)] Loss: -1600.451660\n",
      "    epoch          : 4320\n",
      "    loss           : -1544.0442829024319\n",
      "Train Epoch: 4321 [512/60000 (1%)] Loss: -1602.998535\n",
      "Train Epoch: 4321 [11776/60000 (20%)] Loss: -1581.481201\n",
      "Train Epoch: 4321 [23040/60000 (38%)] Loss: -1571.315308\n",
      "Train Epoch: 4321 [34304/60000 (57%)] Loss: -1533.733276\n",
      "Train Epoch: 4321 [45568/60000 (76%)] Loss: -1561.362793\n",
      "Train Epoch: 4321 [56832/60000 (95%)] Loss: -1606.921631\n",
      "    epoch          : 4321\n",
      "    loss           : -1542.543423582605\n",
      "Train Epoch: 4322 [512/60000 (1%)] Loss: -1496.533936\n",
      "Train Epoch: 4322 [11776/60000 (20%)] Loss: -1521.000977\n",
      "Train Epoch: 4322 [23040/60000 (38%)] Loss: -1537.789307\n",
      "Train Epoch: 4322 [34304/60000 (57%)] Loss: -1479.352295\n",
      "Train Epoch: 4322 [45568/60000 (76%)] Loss: -1525.719116\n",
      "Train Epoch: 4322 [56832/60000 (95%)] Loss: -1558.775391\n",
      "    epoch          : 4322\n",
      "    loss           : -1539.4487073650469\n",
      "Train Epoch: 4323 [512/60000 (1%)] Loss: -1507.665527\n",
      "Train Epoch: 4323 [11776/60000 (20%)] Loss: -1520.439209\n",
      "Train Epoch: 4323 [23040/60000 (38%)] Loss: -1473.275635\n",
      "Train Epoch: 4323 [34304/60000 (57%)] Loss: -1535.956787\n",
      "Train Epoch: 4323 [45568/60000 (76%)] Loss: -1636.491577\n",
      "Train Epoch: 4323 [56832/60000 (95%)] Loss: -1584.314209\n",
      "    epoch          : 4323\n",
      "    loss           : -1540.5313165524585\n",
      "Train Epoch: 4324 [512/60000 (1%)] Loss: -1480.061768\n",
      "Train Epoch: 4324 [11776/60000 (20%)] Loss: -1588.691162\n",
      "Train Epoch: 4324 [23040/60000 (38%)] Loss: -1613.123169\n",
      "Train Epoch: 4324 [34304/60000 (57%)] Loss: -1537.700928\n",
      "Train Epoch: 4324 [45568/60000 (76%)] Loss: -1540.475586\n",
      "Train Epoch: 4324 [56832/60000 (95%)] Loss: -1535.692871\n",
      "    epoch          : 4324\n",
      "    loss           : -1537.9559122721353\n",
      "Train Epoch: 4325 [512/60000 (1%)] Loss: -1533.416016\n",
      "Train Epoch: 4325 [11776/60000 (20%)] Loss: -1520.566040\n",
      "Train Epoch: 4325 [23040/60000 (38%)] Loss: -1627.534912\n",
      "Train Epoch: 4325 [34304/60000 (57%)] Loss: -1594.836792\n",
      "Train Epoch: 4325 [45568/60000 (76%)] Loss: -1488.771851\n",
      "Train Epoch: 4325 [56832/60000 (95%)] Loss: -1601.381958\n",
      "    epoch          : 4325\n",
      "    loss           : -1537.4482963260284\n",
      "Train Epoch: 4326 [512/60000 (1%)] Loss: -1591.136841\n",
      "Train Epoch: 4326 [11776/60000 (20%)] Loss: -1518.083008\n",
      "Train Epoch: 4326 [23040/60000 (38%)] Loss: -1598.657104\n",
      "Train Epoch: 4326 [34304/60000 (57%)] Loss: -1569.607788\n",
      "Train Epoch: 4326 [45568/60000 (76%)] Loss: -1485.062012\n",
      "Train Epoch: 4326 [56832/60000 (95%)] Loss: -1573.680908\n",
      "    epoch          : 4326\n",
      "    loss           : -1539.6808961340262\n",
      "Train Epoch: 4327 [512/60000 (1%)] Loss: -1543.893799\n",
      "Train Epoch: 4327 [11776/60000 (20%)] Loss: -1564.777832\n",
      "Train Epoch: 4327 [23040/60000 (38%)] Loss: -1560.365601\n",
      "Train Epoch: 4327 [34304/60000 (57%)] Loss: -1607.567749\n",
      "Train Epoch: 4327 [45568/60000 (76%)] Loss: -1496.686768\n",
      "Train Epoch: 4327 [56832/60000 (95%)] Loss: -1589.101562\n",
      "    epoch          : 4327\n",
      "    loss           : -1542.2992667505296\n",
      "Train Epoch: 4328 [512/60000 (1%)] Loss: -1591.844971\n",
      "Train Epoch: 4328 [11776/60000 (20%)] Loss: -1530.155273\n",
      "Train Epoch: 4328 [23040/60000 (38%)] Loss: -1557.167725\n",
      "Train Epoch: 4328 [34304/60000 (57%)] Loss: -1567.736572\n",
      "Train Epoch: 4328 [45568/60000 (76%)] Loss: -1479.671021\n",
      "Train Epoch: 4328 [56832/60000 (95%)] Loss: -1469.405762\n",
      "    epoch          : 4328\n",
      "    loss           : -1529.9284716245145\n",
      "Train Epoch: 4329 [512/60000 (1%)] Loss: -1539.328613\n",
      "Train Epoch: 4329 [11776/60000 (20%)] Loss: -1489.298828\n",
      "Train Epoch: 4329 [23040/60000 (38%)] Loss: -1457.182007\n",
      "Train Epoch: 4329 [34304/60000 (57%)] Loss: -1561.842773\n",
      "Train Epoch: 4329 [45568/60000 (76%)] Loss: -1494.477661\n",
      "Train Epoch: 4329 [56832/60000 (95%)] Loss: -1563.593384\n",
      "    epoch          : 4329\n",
      "    loss           : -1538.2931215103065\n",
      "Train Epoch: 4330 [512/60000 (1%)] Loss: -1529.102539\n",
      "Train Epoch: 4330 [11776/60000 (20%)] Loss: -1558.593506\n",
      "Train Epoch: 4330 [23040/60000 (38%)] Loss: -1501.365967\n",
      "Train Epoch: 4330 [34304/60000 (57%)] Loss: -1586.210571\n",
      "Train Epoch: 4330 [45568/60000 (76%)] Loss: -1521.597656\n",
      "Train Epoch: 4330 [56832/60000 (95%)] Loss: -1551.206299\n",
      "    epoch          : 4330\n",
      "    loss           : -1540.9126742088188\n",
      "Train Epoch: 4331 [512/60000 (1%)] Loss: -1535.433716\n",
      "Train Epoch: 4331 [11776/60000 (20%)] Loss: -1534.796631\n",
      "Train Epoch: 4331 [23040/60000 (38%)] Loss: -1564.636597\n",
      "Train Epoch: 4331 [34304/60000 (57%)] Loss: -1576.631592\n",
      "Train Epoch: 4331 [45568/60000 (76%)] Loss: -1562.746704\n",
      "Train Epoch: 4331 [56832/60000 (95%)] Loss: -1623.638794\n",
      "    epoch          : 4331\n",
      "    loss           : -1539.7357281183793\n",
      "Train Epoch: 4332 [512/60000 (1%)] Loss: -1547.371704\n",
      "Train Epoch: 4332 [11776/60000 (20%)] Loss: -1537.176025\n",
      "Train Epoch: 4332 [23040/60000 (38%)] Loss: -1584.216553\n",
      "Train Epoch: 4332 [34304/60000 (57%)] Loss: -1556.631836\n",
      "Train Epoch: 4332 [45568/60000 (76%)] Loss: -1560.070923\n",
      "Train Epoch: 4332 [56832/60000 (95%)] Loss: -1542.885132\n",
      "    epoch          : 4332\n",
      "    loss           : -1540.8526900986494\n",
      "Train Epoch: 4333 [512/60000 (1%)] Loss: -1560.481445\n",
      "Train Epoch: 4333 [11776/60000 (20%)] Loss: -1531.421997\n",
      "Train Epoch: 4333 [23040/60000 (38%)] Loss: -1588.125244\n",
      "Train Epoch: 4333 [34304/60000 (57%)] Loss: -1586.585205\n",
      "Train Epoch: 4333 [45568/60000 (76%)] Loss: -1597.014282\n",
      "Train Epoch: 4333 [56832/60000 (95%)] Loss: -1467.258545\n",
      "    epoch          : 4333\n",
      "    loss           : -1541.4361296400511\n",
      "Train Epoch: 4334 [512/60000 (1%)] Loss: -1535.678955\n",
      "Train Epoch: 4334 [11776/60000 (20%)] Loss: -1547.184570\n",
      "Train Epoch: 4334 [23040/60000 (38%)] Loss: -1585.669678\n",
      "Train Epoch: 4334 [34304/60000 (57%)] Loss: -1443.448608\n",
      "Train Epoch: 4334 [45568/60000 (76%)] Loss: -1552.361450\n",
      "Train Epoch: 4334 [56832/60000 (95%)] Loss: -1545.292603\n",
      "    epoch          : 4334\n",
      "    loss           : -1542.2115957831259\n",
      "Train Epoch: 4335 [512/60000 (1%)] Loss: -1505.412598\n",
      "Train Epoch: 4335 [11776/60000 (20%)] Loss: -1543.676514\n",
      "Train Epoch: 4335 [23040/60000 (38%)] Loss: -1574.034180\n",
      "Train Epoch: 4335 [34304/60000 (57%)] Loss: -1541.540039\n",
      "Train Epoch: 4335 [45568/60000 (76%)] Loss: -1535.392334\n",
      "Train Epoch: 4335 [56832/60000 (95%)] Loss: -1631.590576\n",
      "    epoch          : 4335\n",
      "    loss           : -1544.6504944192486\n",
      "Train Epoch: 4336 [512/60000 (1%)] Loss: -1586.302002\n",
      "Train Epoch: 4336 [11776/60000 (20%)] Loss: -1595.469238\n",
      "Train Epoch: 4336 [23040/60000 (38%)] Loss: -1487.934814\n",
      "Train Epoch: 4336 [34304/60000 (57%)] Loss: -1563.704712\n",
      "Train Epoch: 4336 [45568/60000 (76%)] Loss: -1521.957275\n",
      "Train Epoch: 4336 [56832/60000 (95%)] Loss: -1520.455811\n",
      "    epoch          : 4336\n",
      "    loss           : -1547.1798040530102\n",
      "Train Epoch: 4337 [512/60000 (1%)] Loss: -1540.074585\n",
      "Train Epoch: 4337 [11776/60000 (20%)] Loss: -1613.593750\n",
      "Train Epoch: 4337 [23040/60000 (38%)] Loss: -1475.791016\n",
      "Train Epoch: 4337 [34304/60000 (57%)] Loss: -1493.445435\n",
      "Train Epoch: 4337 [45568/60000 (76%)] Loss: -1567.978027\n",
      "Train Epoch: 4337 [56832/60000 (95%)] Loss: -1583.798950\n",
      "    epoch          : 4337\n",
      "    loss           : -1533.6730994962704\n",
      "Train Epoch: 4338 [512/60000 (1%)] Loss: -1539.977905\n",
      "Train Epoch: 4338 [11776/60000 (20%)] Loss: -1574.615356\n",
      "Train Epoch: 4338 [23040/60000 (38%)] Loss: -1560.467529\n",
      "Train Epoch: 4338 [34304/60000 (57%)] Loss: -1605.926636\n",
      "Train Epoch: 4338 [45568/60000 (76%)] Loss: -1415.369385\n",
      "Train Epoch: 4338 [56832/60000 (95%)] Loss: -1558.566650\n",
      "    epoch          : 4338\n",
      "    loss           : -1538.2149730617716\n",
      "Train Epoch: 4339 [512/60000 (1%)] Loss: -1525.199341\n",
      "Train Epoch: 4339 [11776/60000 (20%)] Loss: -1522.573730\n",
      "Train Epoch: 4339 [23040/60000 (38%)] Loss: -1541.803955\n",
      "Train Epoch: 4339 [34304/60000 (57%)] Loss: -1557.282227\n",
      "Train Epoch: 4339 [45568/60000 (76%)] Loss: -1480.142822\n",
      "Train Epoch: 4339 [56832/60000 (95%)] Loss: -1585.613892\n",
      "    epoch          : 4339\n",
      "    loss           : -1535.7859455690545\n",
      "Train Epoch: 4340 [512/60000 (1%)] Loss: -1533.407715\n",
      "Train Epoch: 4340 [11776/60000 (20%)] Loss: -1517.731079\n",
      "Train Epoch: 4340 [23040/60000 (38%)] Loss: -1532.433960\n",
      "Train Epoch: 4340 [34304/60000 (57%)] Loss: -1553.166504\n",
      "Train Epoch: 4340 [45568/60000 (76%)] Loss: -1576.741211\n",
      "Train Epoch: 4340 [56832/60000 (95%)] Loss: -1564.471924\n",
      "    epoch          : 4340\n",
      "    loss           : -1535.9772183693062\n",
      "Train Epoch: 4341 [512/60000 (1%)] Loss: -1499.346680\n",
      "Train Epoch: 4341 [11776/60000 (20%)] Loss: -1540.690796\n",
      "Train Epoch: 4341 [23040/60000 (38%)] Loss: -1577.948975\n",
      "Train Epoch: 4341 [34304/60000 (57%)] Loss: -1519.567383\n",
      "Train Epoch: 4341 [45568/60000 (76%)] Loss: -1557.424194\n",
      "Train Epoch: 4341 [56832/60000 (95%)] Loss: -1541.581543\n",
      "    epoch          : 4341\n",
      "    loss           : -1529.5758160090043\n",
      "Train Epoch: 4342 [512/60000 (1%)] Loss: -1539.381104\n",
      "Train Epoch: 4342 [11776/60000 (20%)] Loss: -1532.884521\n",
      "Train Epoch: 4342 [23040/60000 (38%)] Loss: -1516.759521\n",
      "Train Epoch: 4342 [34304/60000 (57%)] Loss: -1607.094238\n",
      "Train Epoch: 4342 [45568/60000 (76%)] Loss: -1509.767212\n",
      "Train Epoch: 4342 [56832/60000 (95%)] Loss: -1593.384277\n",
      "    epoch          : 4342\n",
      "    loss           : -1541.7051870917196\n",
      "Train Epoch: 4343 [512/60000 (1%)] Loss: -1587.895752\n",
      "Train Epoch: 4343 [11776/60000 (20%)] Loss: -1530.688232\n",
      "Train Epoch: 4343 [23040/60000 (38%)] Loss: -1555.547241\n",
      "Train Epoch: 4343 [34304/60000 (57%)] Loss: -1599.619141\n",
      "Train Epoch: 4343 [45568/60000 (76%)] Loss: -1603.178223\n",
      "Train Epoch: 4343 [56832/60000 (95%)] Loss: -1558.132568\n",
      "    epoch          : 4343\n",
      "    loss           : -1541.6251517258122\n",
      "Train Epoch: 4344 [512/60000 (1%)] Loss: -1618.326416\n",
      "Train Epoch: 4344 [11776/60000 (20%)] Loss: -1515.442139\n",
      "Train Epoch: 4344 [23040/60000 (38%)] Loss: -1505.620605\n",
      "Train Epoch: 4344 [34304/60000 (57%)] Loss: -1606.251221\n",
      "Train Epoch: 4344 [45568/60000 (76%)] Loss: -1549.954590\n",
      "Train Epoch: 4344 [56832/60000 (95%)] Loss: -1514.756348\n",
      "    epoch          : 4344\n",
      "    loss           : -1541.0194240074372\n",
      "Train Epoch: 4345 [512/60000 (1%)] Loss: -1563.717773\n",
      "Train Epoch: 4345 [11776/60000 (20%)] Loss: -1594.409790\n",
      "Train Epoch: 4345 [23040/60000 (38%)] Loss: -1555.251221\n",
      "Train Epoch: 4345 [34304/60000 (57%)] Loss: -1523.409424\n",
      "Train Epoch: 4345 [45568/60000 (76%)] Loss: -1548.123779\n",
      "Train Epoch: 4345 [56832/60000 (95%)] Loss: -1570.375854\n",
      "    epoch          : 4345\n",
      "    loss           : -1541.7798048116392\n",
      "Train Epoch: 4346 [512/60000 (1%)] Loss: -1543.693481\n",
      "Train Epoch: 4346 [11776/60000 (20%)] Loss: -1607.023560\n",
      "Train Epoch: 4346 [23040/60000 (38%)] Loss: -1457.873047\n",
      "Train Epoch: 4346 [34304/60000 (57%)] Loss: -1556.321289\n",
      "Train Epoch: 4346 [45568/60000 (76%)] Loss: -1530.561401\n",
      "Train Epoch: 4346 [56832/60000 (95%)] Loss: -1527.273926\n",
      "    epoch          : 4346\n",
      "    loss           : -1538.8354047355006\n",
      "Train Epoch: 4347 [512/60000 (1%)] Loss: -1585.115601\n",
      "Train Epoch: 4347 [11776/60000 (20%)] Loss: -1438.795166\n",
      "Train Epoch: 4347 [23040/60000 (38%)] Loss: -1513.609497\n",
      "Train Epoch: 4347 [34304/60000 (57%)] Loss: -1562.266968\n",
      "Train Epoch: 4347 [45568/60000 (76%)] Loss: -1506.761963\n",
      "Train Epoch: 4347 [56832/60000 (95%)] Loss: -1557.259155\n",
      "    epoch          : 4347\n",
      "    loss           : -1537.320519743666\n",
      "Train Epoch: 4348 [512/60000 (1%)] Loss: -1514.184692\n",
      "Train Epoch: 4348 [11776/60000 (20%)] Loss: -1606.729736\n",
      "Train Epoch: 4348 [23040/60000 (38%)] Loss: -1570.962646\n",
      "Train Epoch: 4348 [34304/60000 (57%)] Loss: -1572.583862\n",
      "Train Epoch: 4348 [45568/60000 (76%)] Loss: -1574.766235\n",
      "Train Epoch: 4348 [56832/60000 (95%)] Loss: -1533.626221\n",
      "    epoch          : 4348\n",
      "    loss           : -1536.9686172399145\n",
      "Train Epoch: 4349 [512/60000 (1%)] Loss: -1520.285645\n",
      "Train Epoch: 4349 [11776/60000 (20%)] Loss: -1529.498291\n",
      "Train Epoch: 4349 [23040/60000 (38%)] Loss: -1598.427734\n",
      "Train Epoch: 4349 [34304/60000 (57%)] Loss: -1476.747192\n",
      "Train Epoch: 4349 [45568/60000 (76%)] Loss: -1602.985474\n",
      "Train Epoch: 4349 [56832/60000 (95%)] Loss: -1533.114624\n",
      "    epoch          : 4349\n",
      "    loss           : -1537.0415914934235\n",
      "Train Epoch: 4350 [512/60000 (1%)] Loss: -1586.309937\n",
      "Train Epoch: 4350 [11776/60000 (20%)] Loss: -1492.029541\n",
      "Train Epoch: 4350 [23040/60000 (38%)] Loss: -1496.841553\n",
      "Train Epoch: 4350 [34304/60000 (57%)] Loss: -1524.420898\n",
      "Train Epoch: 4350 [45568/60000 (76%)] Loss: -1504.093994\n",
      "Train Epoch: 4350 [56832/60000 (95%)] Loss: -1477.076172\n",
      "    epoch          : 4350\n",
      "    loss           : -1537.6160402459614\n",
      "Train Epoch: 4351 [512/60000 (1%)] Loss: -1588.293823\n",
      "Train Epoch: 4351 [11776/60000 (20%)] Loss: -1575.593628\n",
      "Train Epoch: 4351 [23040/60000 (38%)] Loss: -1534.758789\n",
      "Train Epoch: 4351 [34304/60000 (57%)] Loss: -1496.267944\n",
      "Train Epoch: 4351 [45568/60000 (76%)] Loss: -1585.920776\n",
      "Train Epoch: 4351 [56832/60000 (95%)] Loss: -1499.943970\n",
      "    epoch          : 4351\n",
      "    loss           : -1535.2009760107699\n",
      "Train Epoch: 4352 [512/60000 (1%)] Loss: -1521.133301\n",
      "Train Epoch: 4352 [11776/60000 (20%)] Loss: -1561.195801\n",
      "Train Epoch: 4352 [23040/60000 (38%)] Loss: -1531.619751\n",
      "Train Epoch: 4352 [34304/60000 (57%)] Loss: -1594.944214\n",
      "Train Epoch: 4352 [45568/60000 (76%)] Loss: -1519.645874\n",
      "Train Epoch: 4352 [56832/60000 (95%)] Loss: -1533.451660\n",
      "    epoch          : 4352\n",
      "    loss           : -1540.7375343452065\n",
      "Train Epoch: 4353 [512/60000 (1%)] Loss: -1522.040527\n",
      "Train Epoch: 4353 [11776/60000 (20%)] Loss: -1627.431396\n",
      "Train Epoch: 4353 [23040/60000 (38%)] Loss: -1498.330566\n",
      "Train Epoch: 4353 [34304/60000 (57%)] Loss: -1518.420410\n",
      "Train Epoch: 4353 [45568/60000 (76%)] Loss: -1638.444580\n",
      "Train Epoch: 4353 [56832/60000 (95%)] Loss: -1586.931641\n",
      "    epoch          : 4353\n",
      "    loss           : -1537.8009740107477\n",
      "Train Epoch: 4354 [512/60000 (1%)] Loss: -1456.114746\n",
      "Train Epoch: 4354 [11776/60000 (20%)] Loss: -1497.910645\n",
      "Train Epoch: 4354 [23040/60000 (38%)] Loss: -1617.431641\n",
      "Train Epoch: 4354 [34304/60000 (57%)] Loss: -1561.487305\n",
      "Train Epoch: 4354 [45568/60000 (76%)] Loss: -1601.725342\n",
      "Train Epoch: 4354 [56832/60000 (95%)] Loss: -1513.472656\n",
      "    epoch          : 4354\n",
      "    loss           : -1539.153375830354\n",
      "Train Epoch: 4355 [512/60000 (1%)] Loss: -1553.640015\n",
      "Train Epoch: 4355 [11776/60000 (20%)] Loss: -1520.812744\n",
      "Train Epoch: 4355 [23040/60000 (38%)] Loss: -1497.530762\n",
      "Train Epoch: 4355 [34304/60000 (57%)] Loss: -1528.122070\n",
      "Train Epoch: 4355 [45568/60000 (76%)] Loss: -1512.839844\n",
      "Train Epoch: 4355 [56832/60000 (95%)] Loss: -1521.161255\n",
      "    epoch          : 4355\n",
      "    loss           : -1537.3467007222148\n",
      "Train Epoch: 4356 [512/60000 (1%)] Loss: -1584.187378\n",
      "Train Epoch: 4356 [11776/60000 (20%)] Loss: -1512.401245\n",
      "Train Epoch: 4356 [23040/60000 (38%)] Loss: -1538.429077\n",
      "Train Epoch: 4356 [34304/60000 (57%)] Loss: -1423.096191\n",
      "Train Epoch: 4356 [45568/60000 (76%)] Loss: -1623.539307\n",
      "Train Epoch: 4356 [56832/60000 (95%)] Loss: -1528.706665\n",
      "    epoch          : 4356\n",
      "    loss           : -1539.1849658341057\n",
      "Train Epoch: 4357 [512/60000 (1%)] Loss: -1495.088989\n",
      "Train Epoch: 4357 [11776/60000 (20%)] Loss: -1467.520142\n",
      "Train Epoch: 4357 [23040/60000 (38%)] Loss: -1503.360596\n",
      "Train Epoch: 4357 [34304/60000 (57%)] Loss: -1595.762207\n",
      "Train Epoch: 4357 [45568/60000 (76%)] Loss: -1597.585449\n",
      "Train Epoch: 4357 [56832/60000 (95%)] Loss: -1485.548706\n",
      "    epoch          : 4357\n",
      "    loss           : -1539.014374296544\n",
      "Train Epoch: 4358 [512/60000 (1%)] Loss: -1485.810303\n",
      "Train Epoch: 4358 [11776/60000 (20%)] Loss: -1479.789795\n",
      "Train Epoch: 4358 [23040/60000 (38%)] Loss: -1508.293945\n",
      "Train Epoch: 4358 [34304/60000 (57%)] Loss: -1537.376343\n",
      "Train Epoch: 4358 [45568/60000 (76%)] Loss: -1555.772949\n",
      "Train Epoch: 4358 [56832/60000 (95%)] Loss: -1515.134644\n",
      "    epoch          : 4358\n",
      "    loss           : -1538.9787783865202\n",
      "Train Epoch: 4359 [512/60000 (1%)] Loss: -1580.547852\n",
      "Train Epoch: 4359 [11776/60000 (20%)] Loss: -1516.813843\n",
      "Train Epoch: 4359 [23040/60000 (38%)] Loss: -1540.959473\n",
      "Train Epoch: 4359 [34304/60000 (57%)] Loss: -1495.550903\n",
      "Train Epoch: 4359 [45568/60000 (76%)] Loss: -1531.280029\n",
      "Train Epoch: 4359 [56832/60000 (95%)] Loss: -1581.195801\n",
      "    epoch          : 4359\n",
      "    loss           : -1532.671828102931\n",
      "Train Epoch: 4360 [512/60000 (1%)] Loss: -1579.182373\n",
      "Train Epoch: 4360 [11776/60000 (20%)] Loss: -1579.491699\n",
      "Train Epoch: 4360 [23040/60000 (38%)] Loss: -1466.916748\n",
      "Train Epoch: 4360 [34304/60000 (57%)] Loss: -1519.961304\n",
      "Train Epoch: 4360 [45568/60000 (76%)] Loss: -1495.196167\n",
      "Train Epoch: 4360 [56832/60000 (95%)] Loss: -1615.302368\n",
      "    epoch          : 4360\n",
      "    loss           : -1538.8530994135108\n",
      "Train Epoch: 4361 [512/60000 (1%)] Loss: -1621.707764\n",
      "Train Epoch: 4361 [11776/60000 (20%)] Loss: -1559.238037\n",
      "Train Epoch: 4361 [23040/60000 (38%)] Loss: -1619.380127\n",
      "Train Epoch: 4361 [34304/60000 (57%)] Loss: -1557.215576\n",
      "Train Epoch: 4361 [45568/60000 (76%)] Loss: -1581.998047\n",
      "Train Epoch: 4361 [56832/60000 (95%)] Loss: -1538.233643\n",
      "    epoch          : 4361\n",
      "    loss           : -1542.2099726617673\n",
      "Train Epoch: 4362 [512/60000 (1%)] Loss: -1620.761475\n",
      "Train Epoch: 4362 [11776/60000 (20%)] Loss: -1600.571045\n",
      "Train Epoch: 4362 [23040/60000 (38%)] Loss: -1496.077393\n",
      "Train Epoch: 4362 [34304/60000 (57%)] Loss: -1524.970703\n",
      "Train Epoch: 4362 [45568/60000 (76%)] Loss: -1500.172363\n",
      "Train Epoch: 4362 [56832/60000 (95%)] Loss: -1535.181519\n",
      "    epoch          : 4362\n",
      "    loss           : -1539.2783592784474\n",
      "Train Epoch: 4363 [512/60000 (1%)] Loss: -1543.215576\n",
      "Train Epoch: 4363 [11776/60000 (20%)] Loss: -1529.977173\n",
      "Train Epoch: 4363 [23040/60000 (38%)] Loss: -1490.387573\n",
      "Train Epoch: 4363 [34304/60000 (57%)] Loss: -1543.119385\n",
      "Train Epoch: 4363 [45568/60000 (76%)] Loss: -1558.296631\n",
      "Train Epoch: 4363 [56832/60000 (95%)] Loss: -1495.155029\n",
      "    epoch          : 4363\n",
      "    loss           : -1540.564055534406\n",
      "Train Epoch: 4364 [512/60000 (1%)] Loss: -1566.930054\n",
      "Train Epoch: 4364 [11776/60000 (20%)] Loss: -1568.933716\n",
      "Train Epoch: 4364 [23040/60000 (38%)] Loss: -1535.257080\n",
      "Train Epoch: 4364 [34304/60000 (57%)] Loss: -1544.166992\n",
      "Train Epoch: 4364 [45568/60000 (76%)] Loss: -1456.699219\n",
      "Train Epoch: 4364 [56832/60000 (95%)] Loss: -1553.254517\n",
      "    epoch          : 4364\n",
      "    loss           : -1542.321116301973\n",
      "Train Epoch: 4365 [512/60000 (1%)] Loss: -1549.733154\n",
      "Train Epoch: 4365 [11776/60000 (20%)] Loss: -1508.915771\n",
      "Train Epoch: 4365 [23040/60000 (38%)] Loss: -1583.447021\n",
      "Train Epoch: 4365 [34304/60000 (57%)] Loss: -1569.984375\n",
      "Train Epoch: 4365 [45568/60000 (76%)] Loss: -1576.651123\n",
      "Train Epoch: 4365 [56832/60000 (95%)] Loss: -1571.331299\n",
      "    epoch          : 4365\n",
      "    loss           : -1548.3121062025511\n",
      "Train Epoch: 4366 [512/60000 (1%)] Loss: -1569.455200\n",
      "Train Epoch: 4366 [11776/60000 (20%)] Loss: -1565.749512\n",
      "Train Epoch: 4366 [23040/60000 (38%)] Loss: -1505.306519\n",
      "Train Epoch: 4366 [34304/60000 (57%)] Loss: -1582.341675\n",
      "Train Epoch: 4366 [45568/60000 (76%)] Loss: -1555.130981\n",
      "Train Epoch: 4366 [56832/60000 (95%)] Loss: -1454.691650\n",
      "    epoch          : 4366\n",
      "    loss           : -1534.029191011763\n",
      "Train Epoch: 4367 [512/60000 (1%)] Loss: -1562.567749\n",
      "Train Epoch: 4367 [11776/60000 (20%)] Loss: -1495.995728\n",
      "Train Epoch: 4367 [23040/60000 (38%)] Loss: -1559.335205\n",
      "Train Epoch: 4367 [34304/60000 (57%)] Loss: -1492.683105\n",
      "Train Epoch: 4367 [45568/60000 (76%)] Loss: -1563.115479\n",
      "Train Epoch: 4367 [56832/60000 (95%)] Loss: -1523.407715\n",
      "    epoch          : 4367\n",
      "    loss           : -1537.023509914592\n",
      "Train Epoch: 4368 [512/60000 (1%)] Loss: -1569.290405\n",
      "Train Epoch: 4368 [11776/60000 (20%)] Loss: -1583.559448\n",
      "Train Epoch: 4368 [23040/60000 (38%)] Loss: -1525.789062\n",
      "Train Epoch: 4368 [34304/60000 (57%)] Loss: -1526.180420\n",
      "Train Epoch: 4368 [45568/60000 (76%)] Loss: -1512.362305\n",
      "Train Epoch: 4368 [56832/60000 (95%)] Loss: -1580.621948\n",
      "    epoch          : 4368\n",
      "    loss           : -1540.5112990901969\n",
      "Train Epoch: 4369 [512/60000 (1%)] Loss: -1471.052002\n",
      "Train Epoch: 4369 [11776/60000 (20%)] Loss: -1532.291138\n",
      "Train Epoch: 4369 [23040/60000 (38%)] Loss: -1464.600464\n",
      "Train Epoch: 4369 [34304/60000 (57%)] Loss: -1533.661621\n",
      "Train Epoch: 4369 [45568/60000 (76%)] Loss: -1524.858765\n",
      "Train Epoch: 4369 [56832/60000 (95%)] Loss: -1537.275513\n",
      "    epoch          : 4369\n",
      "    loss           : -1536.7499186197915\n",
      "Train Epoch: 4370 [512/60000 (1%)] Loss: -1606.204346\n",
      "Train Epoch: 4370 [11776/60000 (20%)] Loss: -1630.184692\n",
      "Train Epoch: 4370 [23040/60000 (38%)] Loss: -1491.024902\n",
      "Train Epoch: 4370 [34304/60000 (57%)] Loss: -1516.494385\n",
      "Train Epoch: 4370 [45568/60000 (76%)] Loss: -1521.134644\n",
      "Train Epoch: 4370 [56832/60000 (95%)] Loss: -1506.547607\n",
      "    epoch          : 4370\n",
      "    loss           : -1539.198523225084\n",
      "Train Epoch: 4371 [512/60000 (1%)] Loss: -1618.004150\n",
      "Train Epoch: 4371 [11776/60000 (20%)] Loss: -1508.631104\n",
      "Train Epoch: 4371 [23040/60000 (38%)] Loss: -1593.141113\n",
      "Train Epoch: 4371 [34304/60000 (57%)] Loss: -1460.173096\n",
      "Train Epoch: 4371 [45568/60000 (76%)] Loss: -1439.580322\n",
      "Train Epoch: 4371 [56832/60000 (95%)] Loss: -1568.602051\n",
      "    epoch          : 4371\n",
      "    loss           : -1535.1168554273702\n",
      "Train Epoch: 4372 [512/60000 (1%)] Loss: -1604.630981\n",
      "Train Epoch: 4372 [11776/60000 (20%)] Loss: -1564.815796\n",
      "Train Epoch: 4372 [23040/60000 (38%)] Loss: -1559.784668\n",
      "Train Epoch: 4372 [34304/60000 (57%)] Loss: -1573.236328\n",
      "Train Epoch: 4372 [45568/60000 (76%)] Loss: -1506.284180\n",
      "Train Epoch: 4372 [56832/60000 (95%)] Loss: -1451.544678\n",
      "    epoch          : 4372\n",
      "    loss           : -1542.164406296897\n",
      "Train Epoch: 4373 [512/60000 (1%)] Loss: -1609.630737\n",
      "Train Epoch: 4373 [11776/60000 (20%)] Loss: -1568.315552\n",
      "Train Epoch: 4373 [23040/60000 (38%)] Loss: -1577.922241\n",
      "Train Epoch: 4373 [34304/60000 (57%)] Loss: -1557.753906\n",
      "Train Epoch: 4373 [45568/60000 (76%)] Loss: -1502.335693\n",
      "Train Epoch: 4373 [56832/60000 (95%)] Loss: -1505.386841\n",
      "    epoch          : 4373\n",
      "    loss           : -1537.3516756046963\n",
      "Train Epoch: 4374 [512/60000 (1%)] Loss: -1566.422607\n",
      "Train Epoch: 4374 [11776/60000 (20%)] Loss: -1573.751343\n",
      "Train Epoch: 4374 [23040/60000 (38%)] Loss: -1571.156250\n",
      "Train Epoch: 4374 [34304/60000 (57%)] Loss: -1427.208252\n",
      "Train Epoch: 4374 [45568/60000 (76%)] Loss: -1465.967041\n",
      "Train Epoch: 4374 [56832/60000 (95%)] Loss: -1538.204102\n",
      "    epoch          : 4374\n",
      "    loss           : -1536.8274880964202\n",
      "Train Epoch: 4375 [512/60000 (1%)] Loss: -1473.566406\n",
      "Train Epoch: 4375 [11776/60000 (20%)] Loss: -1504.185059\n",
      "Train Epoch: 4375 [23040/60000 (38%)] Loss: -1590.196533\n",
      "Train Epoch: 4375 [34304/60000 (57%)] Loss: -1581.793213\n",
      "Train Epoch: 4375 [45568/60000 (76%)] Loss: -1506.679321\n",
      "Train Epoch: 4375 [56832/60000 (95%)] Loss: -1511.207031\n",
      "    epoch          : 4375\n",
      "    loss           : -1533.7297270176775\n",
      "Train Epoch: 4376 [512/60000 (1%)] Loss: -1535.718140\n",
      "Train Epoch: 4376 [11776/60000 (20%)] Loss: -1514.817383\n",
      "Train Epoch: 4376 [23040/60000 (38%)] Loss: -1568.372559\n",
      "Train Epoch: 4376 [34304/60000 (57%)] Loss: -1602.135498\n",
      "Train Epoch: 4376 [45568/60000 (76%)] Loss: -1538.194336\n",
      "Train Epoch: 4376 [56832/60000 (95%)] Loss: -1557.286011\n",
      "    epoch          : 4376\n",
      "    loss           : -1537.613244353041\n",
      "Train Epoch: 4377 [512/60000 (1%)] Loss: -1474.146484\n",
      "Train Epoch: 4377 [11776/60000 (20%)] Loss: -1566.025635\n",
      "Train Epoch: 4377 [23040/60000 (38%)] Loss: -1555.385986\n",
      "Train Epoch: 4377 [34304/60000 (57%)] Loss: -1519.279297\n",
      "Train Epoch: 4377 [45568/60000 (76%)] Loss: -1539.409668\n",
      "Train Epoch: 4377 [56832/60000 (95%)] Loss: -1620.827148\n",
      "    epoch          : 4377\n",
      "    loss           : -1535.227830789857\n",
      "Train Epoch: 4378 [512/60000 (1%)] Loss: -1548.621704\n",
      "Train Epoch: 4378 [11776/60000 (20%)] Loss: -1592.161743\n",
      "Train Epoch: 4378 [23040/60000 (38%)] Loss: -1523.405396\n",
      "Train Epoch: 4378 [34304/60000 (57%)] Loss: -1485.569702\n",
      "Train Epoch: 4378 [45568/60000 (76%)] Loss: -1484.457275\n",
      "Train Epoch: 4378 [56832/60000 (95%)] Loss: -1451.541016\n",
      "    epoch          : 4378\n",
      "    loss           : -1531.2340836174744\n",
      "Train Epoch: 4379 [512/60000 (1%)] Loss: -1543.839111\n",
      "Train Epoch: 4379 [11776/60000 (20%)] Loss: -1486.197388\n",
      "Train Epoch: 4379 [23040/60000 (38%)] Loss: -1461.700073\n",
      "Train Epoch: 4379 [34304/60000 (57%)] Loss: -1565.026489\n",
      "Train Epoch: 4379 [45568/60000 (76%)] Loss: -1504.786377\n",
      "Train Epoch: 4379 [56832/60000 (95%)] Loss: -1509.803345\n",
      "    epoch          : 4379\n",
      "    loss           : -1538.459605761167\n",
      "Train Epoch: 4380 [512/60000 (1%)] Loss: -1511.887695\n",
      "Train Epoch: 4380 [11776/60000 (20%)] Loss: -1520.243164\n",
      "Train Epoch: 4380 [23040/60000 (38%)] Loss: -1444.361938\n",
      "Train Epoch: 4380 [34304/60000 (57%)] Loss: -1608.022949\n",
      "Train Epoch: 4380 [45568/60000 (76%)] Loss: -1465.104248\n",
      "Train Epoch: 4380 [56832/60000 (95%)] Loss: -1596.712646\n",
      "    epoch          : 4380\n",
      "    loss           : -1541.7289014913267\n",
      "Train Epoch: 4381 [512/60000 (1%)] Loss: -1539.033936\n",
      "Train Epoch: 4381 [11776/60000 (20%)] Loss: -1576.716431\n",
      "Train Epoch: 4381 [23040/60000 (38%)] Loss: -1504.434937\n",
      "Train Epoch: 4381 [34304/60000 (57%)] Loss: -1572.724854\n",
      "Train Epoch: 4381 [45568/60000 (76%)] Loss: -1492.584717\n",
      "Train Epoch: 4381 [56832/60000 (95%)] Loss: -1518.990234\n",
      "    epoch          : 4381\n",
      "    loss           : -1541.955661579714\n",
      "Train Epoch: 4382 [512/60000 (1%)] Loss: -1559.893433\n",
      "Train Epoch: 4382 [11776/60000 (20%)] Loss: -1535.065430\n",
      "Train Epoch: 4382 [23040/60000 (38%)] Loss: -1435.213745\n",
      "Train Epoch: 4382 [34304/60000 (57%)] Loss: -1556.208618\n",
      "Train Epoch: 4382 [45568/60000 (76%)] Loss: -1489.988525\n",
      "Train Epoch: 4382 [56832/60000 (95%)] Loss: -1506.487915\n",
      "    epoch          : 4382\n",
      "    loss           : -1534.7199500132415\n",
      "Train Epoch: 4383 [512/60000 (1%)] Loss: -1562.642334\n",
      "Train Epoch: 4383 [11776/60000 (20%)] Loss: -1457.344360\n",
      "Train Epoch: 4383 [23040/60000 (38%)] Loss: -1516.621582\n",
      "Train Epoch: 4383 [34304/60000 (57%)] Loss: -1523.501953\n",
      "Train Epoch: 4383 [45568/60000 (76%)] Loss: -1466.336548\n",
      "Train Epoch: 4383 [56832/60000 (95%)] Loss: -1590.245850\n",
      "    epoch          : 4383\n",
      "    loss           : -1527.8153334795418\n",
      "Train Epoch: 4384 [512/60000 (1%)] Loss: -1587.697876\n",
      "Train Epoch: 4384 [11776/60000 (20%)] Loss: -1513.627686\n",
      "Train Epoch: 4384 [23040/60000 (38%)] Loss: -1520.160889\n",
      "Train Epoch: 4384 [34304/60000 (57%)] Loss: -1534.166748\n",
      "Train Epoch: 4384 [45568/60000 (76%)] Loss: -1532.892212\n",
      "Train Epoch: 4384 [56832/60000 (95%)] Loss: -1572.967285\n",
      "    epoch          : 4384\n",
      "    loss           : -1524.9058120641332\n",
      "Train Epoch: 4385 [512/60000 (1%)] Loss: -1446.281738\n",
      "Train Epoch: 4385 [11776/60000 (20%)] Loss: -1498.410645\n",
      "Train Epoch: 4385 [23040/60000 (38%)] Loss: -1618.587646\n",
      "Train Epoch: 4385 [34304/60000 (57%)] Loss: -1557.114136\n",
      "Train Epoch: 4385 [45568/60000 (76%)] Loss: -1502.884277\n",
      "Train Epoch: 4385 [56832/60000 (95%)] Loss: -1541.105469\n",
      "    epoch          : 4385\n",
      "    loss           : -1543.8149865791622\n",
      "Train Epoch: 4386 [512/60000 (1%)] Loss: -1537.469238\n",
      "Train Epoch: 4386 [11776/60000 (20%)] Loss: -1563.680176\n",
      "Train Epoch: 4386 [23040/60000 (38%)] Loss: -1553.510010\n",
      "Train Epoch: 4386 [34304/60000 (57%)] Loss: -1601.387451\n",
      "Train Epoch: 4386 [45568/60000 (76%)] Loss: -1551.998535\n",
      "Train Epoch: 4386 [56832/60000 (95%)] Loss: -1521.895630\n",
      "    epoch          : 4386\n",
      "    loss           : -1543.9077534648657\n",
      "Train Epoch: 4387 [512/60000 (1%)] Loss: -1600.600220\n",
      "Train Epoch: 4387 [11776/60000 (20%)] Loss: -1529.315918\n",
      "Train Epoch: 4387 [23040/60000 (38%)] Loss: -1415.938965\n",
      "Train Epoch: 4387 [34304/60000 (57%)] Loss: -1467.330444\n",
      "Train Epoch: 4387 [45568/60000 (76%)] Loss: -1489.684692\n",
      "Train Epoch: 4387 [56832/60000 (95%)] Loss: -1566.985596\n",
      "    epoch          : 4387\n",
      "    loss           : -1536.1325256002826\n",
      "Train Epoch: 4388 [512/60000 (1%)] Loss: -1585.210938\n",
      "Train Epoch: 4388 [11776/60000 (20%)] Loss: -1521.539307\n",
      "Train Epoch: 4388 [23040/60000 (38%)] Loss: -1575.199219\n",
      "Train Epoch: 4388 [34304/60000 (57%)] Loss: -1562.176880\n",
      "Train Epoch: 4388 [45568/60000 (76%)] Loss: -1576.934326\n",
      "Train Epoch: 4388 [56832/60000 (95%)] Loss: -1518.696411\n",
      "    epoch          : 4388\n",
      "    loss           : -1538.3817652470648\n",
      "Train Epoch: 4389 [512/60000 (1%)] Loss: -1538.691406\n",
      "Train Epoch: 4389 [11776/60000 (20%)] Loss: -1522.471313\n",
      "Train Epoch: 4389 [23040/60000 (38%)] Loss: -1516.981934\n",
      "Train Epoch: 4389 [34304/60000 (57%)] Loss: -1565.539307\n",
      "Train Epoch: 4389 [45568/60000 (76%)] Loss: -1593.725098\n",
      "Train Epoch: 4389 [56832/60000 (95%)] Loss: -1577.523926\n",
      "    epoch          : 4389\n",
      "    loss           : -1535.7249576547053\n",
      "Train Epoch: 4390 [512/60000 (1%)] Loss: -1516.761719\n",
      "Train Epoch: 4390 [11776/60000 (20%)] Loss: -1561.647949\n",
      "Train Epoch: 4390 [23040/60000 (38%)] Loss: -1568.538818\n",
      "Train Epoch: 4390 [34304/60000 (57%)] Loss: -1563.389160\n",
      "Train Epoch: 4390 [45568/60000 (76%)] Loss: -1553.232666\n",
      "Train Epoch: 4390 [56832/60000 (95%)] Loss: -1547.725830\n",
      "    epoch          : 4390\n",
      "    loss           : -1540.9633451127736\n",
      "Train Epoch: 4391 [512/60000 (1%)] Loss: -1463.070190\n",
      "Train Epoch: 4391 [11776/60000 (20%)] Loss: -1499.833496\n",
      "Train Epoch: 4391 [23040/60000 (38%)] Loss: -1493.042114\n",
      "Train Epoch: 4391 [34304/60000 (57%)] Loss: -1536.609497\n",
      "Train Epoch: 4391 [45568/60000 (76%)] Loss: -1569.067505\n",
      "Train Epoch: 4391 [56832/60000 (95%)] Loss: -1542.406860\n",
      "    epoch          : 4391\n",
      "    loss           : -1541.0086897510594\n",
      "Train Epoch: 4392 [512/60000 (1%)] Loss: -1604.870972\n",
      "Train Epoch: 4392 [11776/60000 (20%)] Loss: -1504.798462\n",
      "Train Epoch: 4392 [23040/60000 (38%)] Loss: -1545.819946\n",
      "Train Epoch: 4392 [34304/60000 (57%)] Loss: -1581.112549\n",
      "Train Epoch: 4392 [45568/60000 (76%)] Loss: -1509.551025\n",
      "Train Epoch: 4392 [56832/60000 (95%)] Loss: -1588.443726\n",
      "    epoch          : 4392\n",
      "    loss           : -1543.1735508805614\n",
      "Train Epoch: 4393 [512/60000 (1%)] Loss: -1582.659912\n",
      "Train Epoch: 4393 [11776/60000 (20%)] Loss: -1536.548828\n",
      "Train Epoch: 4393 [23040/60000 (38%)] Loss: -1507.448364\n",
      "Train Epoch: 4393 [34304/60000 (57%)] Loss: -1491.037598\n",
      "Train Epoch: 4393 [45568/60000 (76%)] Loss: -1512.351074\n",
      "Train Epoch: 4393 [56832/60000 (95%)] Loss: -1516.804932\n",
      "    epoch          : 4393\n",
      "    loss           : -1539.8757948363568\n",
      "Train Epoch: 4394 [512/60000 (1%)] Loss: -1530.658203\n",
      "Train Epoch: 4394 [11776/60000 (20%)] Loss: -1476.244263\n",
      "Train Epoch: 4394 [23040/60000 (38%)] Loss: -1513.092773\n",
      "Train Epoch: 4394 [34304/60000 (57%)] Loss: -1487.591919\n",
      "Train Epoch: 4394 [45568/60000 (76%)] Loss: -1489.387573\n",
      "Train Epoch: 4394 [56832/60000 (95%)] Loss: -1556.255127\n",
      "    epoch          : 4394\n",
      "    loss           : -1536.174989861957\n",
      "Train Epoch: 4395 [512/60000 (1%)] Loss: -1580.018188\n",
      "Train Epoch: 4395 [11776/60000 (20%)] Loss: -1518.047119\n",
      "Train Epoch: 4395 [23040/60000 (38%)] Loss: -1565.879883\n",
      "Train Epoch: 4395 [34304/60000 (57%)] Loss: -1499.569214\n",
      "Train Epoch: 4395 [45568/60000 (76%)] Loss: -1485.717651\n",
      "Train Epoch: 4395 [56832/60000 (95%)] Loss: -1614.371460\n",
      "    epoch          : 4395\n",
      "    loss           : -1533.9270295396364\n",
      "Train Epoch: 4396 [512/60000 (1%)] Loss: -1614.341919\n",
      "Train Epoch: 4396 [11776/60000 (20%)] Loss: -1534.277832\n",
      "Train Epoch: 4396 [23040/60000 (38%)] Loss: -1538.849243\n",
      "Train Epoch: 4396 [34304/60000 (57%)] Loss: -1579.586670\n",
      "Train Epoch: 4396 [45568/60000 (76%)] Loss: -1470.200317\n",
      "Train Epoch: 4396 [56832/60000 (95%)] Loss: -1525.381226\n",
      "    epoch          : 4396\n",
      "    loss           : -1536.4276302359197\n",
      "Train Epoch: 4397 [512/60000 (1%)] Loss: -1564.713501\n",
      "Train Epoch: 4397 [11776/60000 (20%)] Loss: -1502.244995\n",
      "Train Epoch: 4397 [23040/60000 (38%)] Loss: -1599.882080\n",
      "Train Epoch: 4397 [34304/60000 (57%)] Loss: -1543.841309\n",
      "Train Epoch: 4397 [45568/60000 (76%)] Loss: -1508.738770\n",
      "Train Epoch: 4397 [56832/60000 (95%)] Loss: -1543.574707\n",
      "    epoch          : 4397\n",
      "    loss           : -1539.6900593385858\n",
      "Train Epoch: 4398 [512/60000 (1%)] Loss: -1599.981689\n",
      "Train Epoch: 4398 [11776/60000 (20%)] Loss: -1604.773193\n",
      "Train Epoch: 4398 [23040/60000 (38%)] Loss: -1526.460449\n",
      "Train Epoch: 4398 [34304/60000 (57%)] Loss: -1489.167969\n",
      "Train Epoch: 4398 [45568/60000 (76%)] Loss: -1496.472046\n",
      "Train Epoch: 4398 [56832/60000 (95%)] Loss: -1618.963135\n",
      "    epoch          : 4398\n",
      "    loss           : -1537.9156994146142\n",
      "Train Epoch: 4399 [512/60000 (1%)] Loss: -1547.367432\n",
      "Train Epoch: 4399 [11776/60000 (20%)] Loss: -1600.506836\n",
      "Train Epoch: 4399 [23040/60000 (38%)] Loss: -1543.329224\n",
      "Train Epoch: 4399 [34304/60000 (57%)] Loss: -1524.197144\n",
      "Train Epoch: 4399 [45568/60000 (76%)] Loss: -1550.240112\n",
      "Train Epoch: 4399 [56832/60000 (95%)] Loss: -1471.685791\n",
      "    epoch          : 4399\n",
      "    loss           : -1534.5775029241702\n",
      "Train Epoch: 4400 [512/60000 (1%)] Loss: -1470.298706\n",
      "Train Epoch: 4400 [11776/60000 (20%)] Loss: -1530.939697\n",
      "Train Epoch: 4400 [23040/60000 (38%)] Loss: -1569.068359\n",
      "Train Epoch: 4400 [34304/60000 (57%)] Loss: -1570.438110\n",
      "Train Epoch: 4400 [45568/60000 (76%)] Loss: -1630.804565\n",
      "Train Epoch: 4400 [56832/60000 (95%)] Loss: -1501.572998\n",
      "    epoch          : 4400\n",
      "    loss           : -1539.9359413621114\n",
      "Saving checkpoint: saved/models/Mnist_DeepGenerativeOperad/0127_111843/checkpoint-epoch4400.pth ...\n",
      "Train Epoch: 4401 [512/60000 (1%)] Loss: -1592.373291\n",
      "Train Epoch: 4401 [11776/60000 (20%)] Loss: -1530.844604\n",
      "Train Epoch: 4401 [23040/60000 (38%)] Loss: -1516.060181\n",
      "Train Epoch: 4401 [34304/60000 (57%)] Loss: -1470.993652\n",
      "Train Epoch: 4401 [45568/60000 (76%)] Loss: -1504.481079\n",
      "Train Epoch: 4401 [56832/60000 (95%)] Loss: -1517.912109\n",
      "    epoch          : 4401\n",
      "    loss           : -1537.9415241823358\n",
      "Train Epoch: 4402 [512/60000 (1%)] Loss: -1553.091064\n",
      "Train Epoch: 4402 [11776/60000 (20%)] Loss: -1523.960938\n",
      "Train Epoch: 4402 [23040/60000 (38%)] Loss: -1596.737793\n",
      "Train Epoch: 4402 [34304/60000 (57%)] Loss: -1570.529541\n",
      "Train Epoch: 4402 [45568/60000 (76%)] Loss: -1553.106079\n",
      "Train Epoch: 4402 [56832/60000 (95%)] Loss: -1612.867554\n",
      "    epoch          : 4402\n",
      "    loss           : -1547.2642629160046\n",
      "Train Epoch: 4403 [512/60000 (1%)] Loss: -1453.968628\n",
      "Train Epoch: 4403 [11776/60000 (20%)] Loss: -1585.153198\n",
      "Train Epoch: 4403 [23040/60000 (38%)] Loss: -1582.625977\n",
      "Train Epoch: 4403 [34304/60000 (57%)] Loss: -1582.239380\n",
      "Train Epoch: 4403 [45568/60000 (76%)] Loss: -1551.653687\n",
      "Train Epoch: 4403 [56832/60000 (95%)] Loss: -1587.764893\n",
      "    epoch          : 4403\n",
      "    loss           : -1540.2348384533898\n",
      "Train Epoch: 4404 [512/60000 (1%)] Loss: -1543.661133\n",
      "Train Epoch: 4404 [11776/60000 (20%)] Loss: -1488.848633\n",
      "Train Epoch: 4404 [23040/60000 (38%)] Loss: -1478.951660\n",
      "Train Epoch: 4404 [34304/60000 (57%)] Loss: -1554.303467\n",
      "Train Epoch: 4404 [45568/60000 (76%)] Loss: -1473.384644\n",
      "Train Epoch: 4404 [56832/60000 (95%)] Loss: -1573.436035\n",
      "    epoch          : 4404\n",
      "    loss           : -1545.2594125176554\n",
      "Train Epoch: 4405 [512/60000 (1%)] Loss: -1556.596191\n",
      "Train Epoch: 4405 [11776/60000 (20%)] Loss: -1535.590454\n",
      "Train Epoch: 4405 [23040/60000 (38%)] Loss: -1539.930908\n",
      "Train Epoch: 4405 [34304/60000 (57%)] Loss: -1561.979980\n",
      "Train Epoch: 4405 [45568/60000 (76%)] Loss: -1534.983154\n",
      "Train Epoch: 4405 [56832/60000 (95%)] Loss: -1595.313843\n",
      "    epoch          : 4405\n",
      "    loss           : -1542.5569840770656\n",
      "Train Epoch: 4406 [512/60000 (1%)] Loss: -1547.033691\n",
      "Train Epoch: 4406 [11776/60000 (20%)] Loss: -1559.218994\n",
      "Train Epoch: 4406 [23040/60000 (38%)] Loss: -1571.843994\n",
      "Train Epoch: 4406 [34304/60000 (57%)] Loss: -1525.581421\n",
      "Train Epoch: 4406 [45568/60000 (76%)] Loss: -1548.331787\n",
      "Train Epoch: 4406 [56832/60000 (95%)] Loss: -1500.176147\n",
      "    epoch          : 4406\n",
      "    loss           : -1539.3833273332673\n",
      "Train Epoch: 4407 [512/60000 (1%)] Loss: -1539.516113\n",
      "Train Epoch: 4407 [11776/60000 (20%)] Loss: -1487.679688\n",
      "Train Epoch: 4407 [23040/60000 (38%)] Loss: -1519.005737\n",
      "Train Epoch: 4407 [34304/60000 (57%)] Loss: -1552.983154\n",
      "Train Epoch: 4407 [45568/60000 (76%)] Loss: -1553.033203\n",
      "Train Epoch: 4407 [56832/60000 (95%)] Loss: -1555.485474\n",
      "    epoch          : 4407\n",
      "    loss           : -1536.2725292141154\n",
      "Train Epoch: 4408 [512/60000 (1%)] Loss: -1533.062378\n",
      "Train Epoch: 4408 [11776/60000 (20%)] Loss: -1545.411499\n",
      "Train Epoch: 4408 [23040/60000 (38%)] Loss: -1596.881592\n",
      "Train Epoch: 4408 [34304/60000 (57%)] Loss: -1574.666992\n",
      "Train Epoch: 4408 [45568/60000 (76%)] Loss: -1621.515869\n",
      "Train Epoch: 4408 [56832/60000 (95%)] Loss: -1492.064331\n",
      "    epoch          : 4408\n",
      "    loss           : -1545.732622911701\n",
      "Train Epoch: 4409 [512/60000 (1%)] Loss: -1573.740723\n",
      "Train Epoch: 4409 [11776/60000 (20%)] Loss: -1531.683472\n",
      "Train Epoch: 4409 [23040/60000 (38%)] Loss: -1630.634888\n",
      "Train Epoch: 4409 [34304/60000 (57%)] Loss: -1553.370483\n",
      "Train Epoch: 4409 [45568/60000 (76%)] Loss: -1548.121216\n",
      "Train Epoch: 4409 [56832/60000 (95%)] Loss: -1570.707520\n",
      "    epoch          : 4409\n",
      "    loss           : -1536.188444838012\n",
      "Train Epoch: 4410 [512/60000 (1%)] Loss: -1559.755127\n",
      "Train Epoch: 4410 [11776/60000 (20%)] Loss: -1573.395630\n",
      "Train Epoch: 4410 [23040/60000 (38%)] Loss: -1477.465820\n",
      "Train Epoch: 4410 [34304/60000 (57%)] Loss: -1487.083984\n",
      "Train Epoch: 4410 [45568/60000 (76%)] Loss: -1567.014404\n",
      "Train Epoch: 4410 [56832/60000 (95%)] Loss: -1521.930176\n",
      "    epoch          : 4410\n",
      "    loss           : -1540.1075780836202\n",
      "Train Epoch: 4411 [512/60000 (1%)] Loss: -1390.662964\n",
      "Train Epoch: 4411 [11776/60000 (20%)] Loss: -1548.294189\n",
      "Train Epoch: 4411 [23040/60000 (38%)] Loss: -1480.651611\n",
      "Train Epoch: 4411 [34304/60000 (57%)] Loss: -1550.667358\n",
      "Train Epoch: 4411 [45568/60000 (76%)] Loss: -1480.455200\n",
      "Train Epoch: 4411 [56832/60000 (95%)] Loss: -1472.058228\n",
      "    epoch          : 4411\n",
      "    loss           : -1536.8756572486316\n",
      "Train Epoch: 4412 [512/60000 (1%)] Loss: -1450.270996\n",
      "Train Epoch: 4412 [11776/60000 (20%)] Loss: -1453.858276\n",
      "Train Epoch: 4412 [23040/60000 (38%)] Loss: -1565.822998\n",
      "Train Epoch: 4412 [34304/60000 (57%)] Loss: -1457.333008\n",
      "Train Epoch: 4412 [45568/60000 (76%)] Loss: -1517.027222\n",
      "Train Epoch: 4412 [56832/60000 (95%)] Loss: -1522.370361\n",
      "    epoch          : 4412\n",
      "    loss           : -1535.3584887833244\n",
      "Train Epoch: 4413 [512/60000 (1%)] Loss: -1451.336914\n",
      "Train Epoch: 4413 [11776/60000 (20%)] Loss: -1538.232788\n",
      "Train Epoch: 4413 [23040/60000 (38%)] Loss: -1512.709717\n",
      "Train Epoch: 4413 [34304/60000 (57%)] Loss: -1561.574463\n",
      "Train Epoch: 4413 [45568/60000 (76%)] Loss: -1508.031982\n",
      "Train Epoch: 4413 [56832/60000 (95%)] Loss: -1508.223877\n",
      "    epoch          : 4413\n",
      "    loss           : -1537.4472087278205\n",
      "Train Epoch: 4414 [512/60000 (1%)] Loss: -1480.883667\n",
      "Train Epoch: 4414 [11776/60000 (20%)] Loss: -1481.703491\n",
      "Train Epoch: 4414 [23040/60000 (38%)] Loss: -1477.892578\n",
      "Train Epoch: 4414 [34304/60000 (57%)] Loss: -1536.083008\n",
      "Train Epoch: 4414 [45568/60000 (76%)] Loss: -1555.467285\n",
      "Train Epoch: 4414 [56832/60000 (95%)] Loss: -1506.887695\n",
      "    epoch          : 4414\n",
      "    loss           : -1542.4312061374471\n",
      "Train Epoch: 4415 [512/60000 (1%)] Loss: -1559.781982\n",
      "Train Epoch: 4415 [11776/60000 (20%)] Loss: -1454.752441\n",
      "Train Epoch: 4415 [23040/60000 (38%)] Loss: -1583.725464\n",
      "Train Epoch: 4415 [34304/60000 (57%)] Loss: -1606.260254\n",
      "Train Epoch: 4415 [45568/60000 (76%)] Loss: -1604.596924\n",
      "Train Epoch: 4415 [56832/60000 (95%)] Loss: -1631.072510\n",
      "    epoch          : 4415\n",
      "    loss           : -1542.02606235655\n",
      "Train Epoch: 4416 [512/60000 (1%)] Loss: -1531.169556\n",
      "Train Epoch: 4416 [11776/60000 (20%)] Loss: -1560.050049\n",
      "Train Epoch: 4416 [23040/60000 (38%)] Loss: -1507.280396\n",
      "Train Epoch: 4416 [34304/60000 (57%)] Loss: -1533.181885\n",
      "Train Epoch: 4416 [45568/60000 (76%)] Loss: -1505.216064\n",
      "Train Epoch: 4416 [56832/60000 (95%)] Loss: -1559.754028\n",
      "    epoch          : 4416\n",
      "    loss           : -1539.5541405974134\n",
      "Train Epoch: 4417 [512/60000 (1%)] Loss: -1522.322021\n",
      "Train Epoch: 4417 [11776/60000 (20%)] Loss: -1577.869873\n",
      "Train Epoch: 4417 [23040/60000 (38%)] Loss: -1538.909912\n",
      "Train Epoch: 4417 [34304/60000 (57%)] Loss: -1539.773926\n",
      "Train Epoch: 4417 [45568/60000 (76%)] Loss: -1541.451172\n",
      "Train Epoch: 4417 [56832/60000 (95%)] Loss: -1586.889160\n",
      "    epoch          : 4417\n",
      "    loss           : -1543.4515325686352\n",
      "Train Epoch: 4418 [512/60000 (1%)] Loss: -1517.978271\n",
      "Train Epoch: 4418 [11776/60000 (20%)] Loss: -1476.343750\n",
      "Train Epoch: 4418 [23040/60000 (38%)] Loss: -1567.160400\n",
      "Train Epoch: 4418 [34304/60000 (57%)] Loss: -1563.881226\n",
      "Train Epoch: 4418 [45568/60000 (76%)] Loss: -1498.453491\n",
      "Train Epoch: 4418 [56832/60000 (95%)] Loss: -1590.750488\n",
      "    epoch          : 4418\n",
      "    loss           : -1538.796016714667\n",
      "Train Epoch: 4419 [512/60000 (1%)] Loss: -1537.018311\n",
      "Train Epoch: 4419 [11776/60000 (20%)] Loss: -1568.639648\n",
      "Train Epoch: 4419 [23040/60000 (38%)] Loss: -1528.358521\n",
      "Train Epoch: 4419 [34304/60000 (57%)] Loss: -1523.170898\n",
      "Train Epoch: 4419 [45568/60000 (76%)] Loss: -1561.145874\n",
      "Train Epoch: 4419 [56832/60000 (95%)] Loss: -1551.246216\n",
      "    epoch          : 4419\n",
      "    loss           : -1539.6157912776969\n",
      "Train Epoch: 4420 [512/60000 (1%)] Loss: -1488.375488\n",
      "Train Epoch: 4420 [11776/60000 (20%)] Loss: -1490.769531\n",
      "Train Epoch: 4420 [23040/60000 (38%)] Loss: -1556.122925\n",
      "Train Epoch: 4420 [34304/60000 (57%)] Loss: -1523.082886\n",
      "Train Epoch: 4420 [45568/60000 (76%)] Loss: -1566.802734\n",
      "Train Epoch: 4420 [56832/60000 (95%)] Loss: -1545.356812\n",
      "    epoch          : 4420\n",
      "    loss           : -1540.0362090202375\n",
      "Train Epoch: 4421 [512/60000 (1%)] Loss: -1504.725586\n",
      "Train Epoch: 4421 [11776/60000 (20%)] Loss: -1617.292603\n",
      "Train Epoch: 4421 [23040/60000 (38%)] Loss: -1564.184570\n",
      "Train Epoch: 4421 [34304/60000 (57%)] Loss: -1566.510010\n",
      "Train Epoch: 4421 [45568/60000 (76%)] Loss: -1587.996826\n",
      "Train Epoch: 4421 [56832/60000 (95%)] Loss: -1587.224243\n",
      "    epoch          : 4421\n",
      "    loss           : -1540.8489883336645\n",
      "Train Epoch: 4422 [512/60000 (1%)] Loss: -1508.988770\n",
      "Train Epoch: 4422 [11776/60000 (20%)] Loss: -1388.489014\n",
      "Train Epoch: 4422 [23040/60000 (38%)] Loss: -1547.581055\n",
      "Train Epoch: 4422 [34304/60000 (57%)] Loss: -1559.923340\n",
      "Train Epoch: 4422 [45568/60000 (76%)] Loss: -1590.478760\n",
      "Train Epoch: 4422 [56832/60000 (95%)] Loss: -1449.241821\n",
      "    epoch          : 4422\n",
      "    loss           : -1532.00347003829\n",
      "Train Epoch: 4423 [512/60000 (1%)] Loss: -1564.214844\n",
      "Train Epoch: 4423 [11776/60000 (20%)] Loss: -1546.551514\n",
      "Train Epoch: 4423 [23040/60000 (38%)] Loss: -1482.864624\n",
      "Train Epoch: 4423 [34304/60000 (57%)] Loss: -1540.448608\n",
      "Train Epoch: 4423 [45568/60000 (76%)] Loss: -1533.275269\n",
      "Train Epoch: 4423 [56832/60000 (95%)] Loss: -1480.873901\n",
      "    epoch          : 4423\n",
      "    loss           : -1543.2360163974224\n",
      "Train Epoch: 4424 [512/60000 (1%)] Loss: -1543.876709\n",
      "Train Epoch: 4424 [11776/60000 (20%)] Loss: -1591.842896\n",
      "Train Epoch: 4424 [23040/60000 (38%)] Loss: -1559.224854\n",
      "Train Epoch: 4424 [34304/60000 (57%)] Loss: -1545.407471\n",
      "Train Epoch: 4424 [45568/60000 (76%)] Loss: -1567.593018\n",
      "Train Epoch: 4424 [56832/60000 (95%)] Loss: -1443.578857\n",
      "    epoch          : 4424\n",
      "    loss           : -1545.6182202700168\n",
      "Train Epoch: 4425 [512/60000 (1%)] Loss: -1513.666504\n",
      "Train Epoch: 4425 [11776/60000 (20%)] Loss: -1539.748047\n",
      "Train Epoch: 4425 [23040/60000 (38%)] Loss: -1566.053833\n",
      "Train Epoch: 4425 [34304/60000 (57%)] Loss: -1550.164429\n",
      "Train Epoch: 4425 [45568/60000 (76%)] Loss: -1547.213379\n",
      "Train Epoch: 4425 [56832/60000 (95%)] Loss: -1510.098267\n",
      "    epoch          : 4425\n",
      "    loss           : -1534.8179207494704\n",
      "Train Epoch: 4426 [512/60000 (1%)] Loss: -1483.308105\n",
      "Train Epoch: 4426 [11776/60000 (20%)] Loss: -1471.153931\n",
      "Train Epoch: 4426 [23040/60000 (38%)] Loss: -1544.207153\n",
      "Train Epoch: 4426 [34304/60000 (57%)] Loss: -1567.744263\n",
      "Train Epoch: 4426 [45568/60000 (76%)] Loss: -1526.953613\n",
      "Train Epoch: 4426 [56832/60000 (95%)] Loss: -1579.481201\n",
      "    epoch          : 4426\n",
      "    loss           : -1527.2636104950125\n",
      "Train Epoch: 4427 [512/60000 (1%)] Loss: -1608.917969\n",
      "Train Epoch: 4427 [11776/60000 (20%)] Loss: -1487.077148\n",
      "Train Epoch: 4427 [23040/60000 (38%)] Loss: -1599.152100\n",
      "Train Epoch: 4427 [34304/60000 (57%)] Loss: -1524.431274\n",
      "Train Epoch: 4427 [45568/60000 (76%)] Loss: -1465.598755\n",
      "Train Epoch: 4427 [56832/60000 (95%)] Loss: -1511.372559\n",
      "    epoch          : 4427\n",
      "    loss           : -1541.232239459194\n",
      "Train Epoch: 4428 [512/60000 (1%)] Loss: -1552.484253\n",
      "Train Epoch: 4428 [11776/60000 (20%)] Loss: -1463.871948\n",
      "Train Epoch: 4428 [23040/60000 (38%)] Loss: -1539.943848\n",
      "Train Epoch: 4428 [34304/60000 (57%)] Loss: -1501.318970\n",
      "Train Epoch: 4428 [45568/60000 (76%)] Loss: -1456.414551\n",
      "Train Epoch: 4428 [56832/60000 (95%)] Loss: -1571.758301\n",
      "    epoch          : 4428\n",
      "    loss           : -1541.160298320533\n",
      "Train Epoch: 4429 [512/60000 (1%)] Loss: -1537.913818\n",
      "Train Epoch: 4429 [11776/60000 (20%)] Loss: -1578.670410\n",
      "Train Epoch: 4429 [23040/60000 (38%)] Loss: -1492.681396\n",
      "Train Epoch: 4429 [34304/60000 (57%)] Loss: -1577.755615\n",
      "Train Epoch: 4429 [45568/60000 (76%)] Loss: -1558.035278\n",
      "Train Epoch: 4429 [56832/60000 (95%)] Loss: -1525.897827\n",
      "    epoch          : 4429\n",
      "    loss           : -1535.6660042455642\n",
      "Train Epoch: 4430 [512/60000 (1%)] Loss: -1508.625732\n",
      "Train Epoch: 4430 [11776/60000 (20%)] Loss: -1492.818115\n",
      "Train Epoch: 4430 [23040/60000 (38%)] Loss: -1516.904785\n",
      "Train Epoch: 4430 [34304/60000 (57%)] Loss: -1564.824707\n",
      "Train Epoch: 4430 [45568/60000 (76%)] Loss: -1529.201172\n",
      "Train Epoch: 4430 [56832/60000 (95%)] Loss: -1548.594360\n",
      "    epoch          : 4430\n",
      "    loss           : -1541.4317499365511\n",
      "Train Epoch: 4431 [512/60000 (1%)] Loss: -1560.455322\n",
      "Train Epoch: 4431 [11776/60000 (20%)] Loss: -1563.921509\n",
      "Train Epoch: 4431 [23040/60000 (38%)] Loss: -1560.650635\n",
      "Train Epoch: 4431 [34304/60000 (57%)] Loss: -1520.008057\n",
      "Train Epoch: 4431 [45568/60000 (76%)] Loss: -1572.595459\n",
      "Train Epoch: 4431 [56832/60000 (95%)] Loss: -1561.552979\n",
      "    epoch          : 4431\n",
      "    loss           : -1545.5342214120983\n",
      "Train Epoch: 4432 [512/60000 (1%)] Loss: -1565.591919\n",
      "Train Epoch: 4432 [11776/60000 (20%)] Loss: -1540.383545\n",
      "Train Epoch: 4432 [23040/60000 (38%)] Loss: -1578.528687\n",
      "Train Epoch: 4432 [34304/60000 (57%)] Loss: -1553.510620\n",
      "Train Epoch: 4432 [45568/60000 (76%)] Loss: -1455.575806\n",
      "Train Epoch: 4432 [56832/60000 (95%)] Loss: -1421.738281\n",
      "    epoch          : 4432\n",
      "    loss           : -1543.5749328958111\n",
      "Train Epoch: 4433 [512/60000 (1%)] Loss: -1472.814209\n",
      "Train Epoch: 4433 [11776/60000 (20%)] Loss: -1542.970703\n",
      "Train Epoch: 4433 [23040/60000 (38%)] Loss: -1503.983032\n",
      "Train Epoch: 4433 [34304/60000 (57%)] Loss: -1610.255981\n",
      "Train Epoch: 4433 [45568/60000 (76%)] Loss: -1488.486816\n",
      "Train Epoch: 4433 [56832/60000 (95%)] Loss: -1535.635742\n",
      "    epoch          : 4433\n",
      "    loss           : -1540.9322092519642\n",
      "Train Epoch: 4434 [512/60000 (1%)] Loss: -1553.158936\n",
      "Train Epoch: 4434 [11776/60000 (20%)] Loss: -1497.243774\n",
      "Train Epoch: 4434 [23040/60000 (38%)] Loss: -1500.464844\n",
      "Train Epoch: 4434 [34304/60000 (57%)] Loss: -1546.782715\n",
      "Train Epoch: 4434 [45568/60000 (76%)] Loss: -1625.071533\n",
      "Train Epoch: 4434 [56832/60000 (95%)] Loss: -1566.298218\n",
      "    epoch          : 4434\n",
      "    loss           : -1542.4533487955728\n",
      "Train Epoch: 4435 [512/60000 (1%)] Loss: -1480.659912\n",
      "Train Epoch: 4435 [11776/60000 (20%)] Loss: -1531.477173\n",
      "Train Epoch: 4435 [23040/60000 (38%)] Loss: -1600.425293\n",
      "Train Epoch: 4435 [34304/60000 (57%)] Loss: -1572.800537\n",
      "Train Epoch: 4435 [45568/60000 (76%)] Loss: -1546.694580\n",
      "Train Epoch: 4435 [56832/60000 (95%)] Loss: -1522.864746\n",
      "    epoch          : 4435\n",
      "    loss           : -1543.4022209900247\n",
      "Train Epoch: 4436 [512/60000 (1%)] Loss: -1596.671265\n",
      "Train Epoch: 4436 [11776/60000 (20%)] Loss: -1471.619507\n",
      "Train Epoch: 4436 [23040/60000 (38%)] Loss: -1466.938965\n",
      "Train Epoch: 4436 [34304/60000 (57%)] Loss: -1598.562744\n",
      "Train Epoch: 4436 [45568/60000 (76%)] Loss: -1618.548218\n",
      "Train Epoch: 4436 [56832/60000 (95%)] Loss: -1552.393066\n",
      "    epoch          : 4436\n",
      "    loss           : -1547.0067738678497\n",
      "Train Epoch: 4437 [512/60000 (1%)] Loss: -1590.571533\n",
      "Train Epoch: 4437 [11776/60000 (20%)] Loss: -1584.017334\n",
      "Train Epoch: 4437 [23040/60000 (38%)] Loss: -1588.546387\n",
      "Train Epoch: 4437 [34304/60000 (57%)] Loss: -1597.963013\n",
      "Train Epoch: 4437 [45568/60000 (76%)] Loss: -1495.849121\n",
      "Train Epoch: 4437 [56832/60000 (95%)] Loss: -1468.984863\n",
      "    epoch          : 4437\n",
      "    loss           : -1542.416665977004\n",
      "Train Epoch: 4438 [512/60000 (1%)] Loss: -1505.478760\n",
      "Train Epoch: 4438 [11776/60000 (20%)] Loss: -1472.066162\n",
      "Train Epoch: 4438 [23040/60000 (38%)] Loss: -1528.730713\n",
      "Train Epoch: 4438 [34304/60000 (57%)] Loss: -1567.920410\n",
      "Train Epoch: 4438 [45568/60000 (76%)] Loss: -1522.449829\n",
      "Train Epoch: 4438 [56832/60000 (95%)] Loss: -1588.260498\n",
      "    epoch          : 4438\n",
      "    loss           : -1544.1274589926509\n",
      "Train Epoch: 4439 [512/60000 (1%)] Loss: -1540.004517\n",
      "Train Epoch: 4439 [11776/60000 (20%)] Loss: -1549.047119\n",
      "Train Epoch: 4439 [23040/60000 (38%)] Loss: -1565.338989\n",
      "Train Epoch: 4439 [34304/60000 (57%)] Loss: -1454.012085\n",
      "Train Epoch: 4439 [45568/60000 (76%)] Loss: -1502.424194\n",
      "Train Epoch: 4439 [56832/60000 (95%)] Loss: -1474.342285\n",
      "    epoch          : 4439\n",
      "    loss           : -1540.7330756753179\n",
      "Train Epoch: 4440 [512/60000 (1%)] Loss: -1581.425659\n",
      "Train Epoch: 4440 [11776/60000 (20%)] Loss: -1537.022217\n",
      "Train Epoch: 4440 [23040/60000 (38%)] Loss: -1550.880127\n",
      "Train Epoch: 4440 [34304/60000 (57%)] Loss: -1543.302124\n",
      "Train Epoch: 4440 [45568/60000 (76%)] Loss: -1593.897217\n",
      "Train Epoch: 4440 [56832/60000 (95%)] Loss: -1566.735352\n",
      "    epoch          : 4440\n",
      "    loss           : -1538.395162291446\n",
      "Train Epoch: 4441 [512/60000 (1%)] Loss: -1599.973389\n",
      "Train Epoch: 4441 [11776/60000 (20%)] Loss: -1519.179199\n",
      "Train Epoch: 4441 [23040/60000 (38%)] Loss: -1549.731934\n",
      "Train Epoch: 4441 [34304/60000 (57%)] Loss: -1563.535645\n",
      "Train Epoch: 4441 [45568/60000 (76%)] Loss: -1540.440063\n",
      "Train Epoch: 4441 [56832/60000 (95%)] Loss: -1585.745728\n",
      "    epoch          : 4441\n",
      "    loss           : -1534.1441660735566\n",
      "Train Epoch: 4442 [512/60000 (1%)] Loss: -1527.539185\n",
      "Train Epoch: 4442 [11776/60000 (20%)] Loss: -1537.471680\n",
      "Train Epoch: 4442 [23040/60000 (38%)] Loss: -1561.545410\n",
      "Train Epoch: 4442 [34304/60000 (57%)] Loss: -1562.056885\n",
      "Train Epoch: 4442 [45568/60000 (76%)] Loss: -1503.364258\n",
      "Train Epoch: 4442 [56832/60000 (95%)] Loss: -1591.663330\n",
      "    epoch          : 4442\n",
      "    loss           : -1540.360097766596\n",
      "Train Epoch: 4443 [512/60000 (1%)] Loss: -1541.217896\n",
      "Train Epoch: 4443 [11776/60000 (20%)] Loss: -1512.875244\n",
      "Train Epoch: 4443 [23040/60000 (38%)] Loss: -1551.459839\n",
      "Train Epoch: 4443 [34304/60000 (57%)] Loss: -1525.780762\n",
      "Train Epoch: 4443 [45568/60000 (76%)] Loss: -1485.196167\n",
      "Train Epoch: 4443 [56832/60000 (95%)] Loss: -1443.902344\n",
      "    epoch          : 4443\n",
      "    loss           : -1537.5942300052966\n",
      "Train Epoch: 4444 [512/60000 (1%)] Loss: -1527.434204\n",
      "Train Epoch: 4444 [11776/60000 (20%)] Loss: -1577.163452\n",
      "Train Epoch: 4444 [23040/60000 (38%)] Loss: -1597.327393\n",
      "Train Epoch: 4444 [34304/60000 (57%)] Loss: -1560.104736\n",
      "Train Epoch: 4444 [45568/60000 (76%)] Loss: -1582.675415\n",
      "Train Epoch: 4444 [56832/60000 (95%)] Loss: -1521.538086\n",
      "    epoch          : 4444\n",
      "    loss           : -1547.780156194827\n",
      "Train Epoch: 4445 [512/60000 (1%)] Loss: -1601.782227\n",
      "Train Epoch: 4445 [11776/60000 (20%)] Loss: -1542.212280\n",
      "Train Epoch: 4445 [23040/60000 (38%)] Loss: -1581.187744\n",
      "Train Epoch: 4445 [34304/60000 (57%)] Loss: -1515.884766\n",
      "Train Epoch: 4445 [45568/60000 (76%)] Loss: -1481.922852\n",
      "Train Epoch: 4445 [56832/60000 (95%)] Loss: -1491.427002\n",
      "    epoch          : 4445\n",
      "    loss           : -1538.6269217453435\n",
      "Train Epoch: 4446 [512/60000 (1%)] Loss: -1628.597168\n",
      "Train Epoch: 4446 [11776/60000 (20%)] Loss: -1536.133301\n",
      "Train Epoch: 4446 [23040/60000 (38%)] Loss: -1515.160400\n",
      "Train Epoch: 4446 [34304/60000 (57%)] Loss: -1564.108032\n",
      "Train Epoch: 4446 [45568/60000 (76%)] Loss: -1539.584106\n",
      "Train Epoch: 4446 [56832/60000 (95%)] Loss: -1575.249512\n",
      "    epoch          : 4446\n",
      "    loss           : -1544.2138702909824\n",
      "Train Epoch: 4447 [512/60000 (1%)] Loss: -1543.706421\n",
      "Train Epoch: 4447 [11776/60000 (20%)] Loss: -1607.322266\n",
      "Train Epoch: 4447 [23040/60000 (38%)] Loss: -1564.904053\n",
      "Train Epoch: 4447 [34304/60000 (57%)] Loss: -1602.776855\n",
      "Train Epoch: 4447 [45568/60000 (76%)] Loss: -1511.927612\n",
      "Train Epoch: 4447 [56832/60000 (95%)] Loss: -1432.212891\n",
      "    epoch          : 4447\n",
      "    loss           : -1545.5839405814133\n",
      "Train Epoch: 4448 [512/60000 (1%)] Loss: -1519.612793\n",
      "Train Epoch: 4448 [11776/60000 (20%)] Loss: -1577.756348\n",
      "Train Epoch: 4448 [23040/60000 (38%)] Loss: -1600.407349\n",
      "Train Epoch: 4448 [34304/60000 (57%)] Loss: -1526.798462\n",
      "Train Epoch: 4448 [45568/60000 (76%)] Loss: -1620.113037\n",
      "Train Epoch: 4448 [56832/60000 (95%)] Loss: -1547.774658\n",
      "    epoch          : 4448\n",
      "    loss           : -1546.903879973848\n",
      "Train Epoch: 4449 [512/60000 (1%)] Loss: -1491.582153\n",
      "Train Epoch: 4449 [11776/60000 (20%)] Loss: -1582.655762\n",
      "Train Epoch: 4449 [23040/60000 (38%)] Loss: -1545.195557\n",
      "Train Epoch: 4449 [34304/60000 (57%)] Loss: -1492.744141\n",
      "Train Epoch: 4449 [45568/60000 (76%)] Loss: -1539.894531\n",
      "Train Epoch: 4449 [56832/60000 (95%)] Loss: -1523.411743\n",
      "    epoch          : 4449\n",
      "    loss           : -1534.1628411072122\n",
      "Train Epoch: 4450 [512/60000 (1%)] Loss: -1559.037720\n",
      "Train Epoch: 4450 [11776/60000 (20%)] Loss: -1536.395020\n",
      "Train Epoch: 4450 [23040/60000 (38%)] Loss: -1586.920166\n",
      "Train Epoch: 4450 [34304/60000 (57%)] Loss: -1556.084717\n",
      "Train Epoch: 4450 [45568/60000 (76%)] Loss: -1538.529907\n",
      "Train Epoch: 4450 [56832/60000 (95%)] Loss: -1564.168457\n",
      "    epoch          : 4450\n",
      "    loss           : -1543.9421645342293\n",
      "Train Epoch: 4451 [512/60000 (1%)] Loss: -1547.456543\n",
      "Train Epoch: 4451 [11776/60000 (20%)] Loss: -1520.859009\n",
      "Train Epoch: 4451 [23040/60000 (38%)] Loss: -1516.109619\n",
      "Train Epoch: 4451 [34304/60000 (57%)] Loss: -1607.341309\n",
      "Train Epoch: 4451 [45568/60000 (76%)] Loss: -1575.232056\n",
      "Train Epoch: 4451 [56832/60000 (95%)] Loss: -1561.367798\n",
      "    epoch          : 4451\n",
      "    loss           : -1539.97628491073\n",
      "Train Epoch: 4452 [512/60000 (1%)] Loss: -1521.645386\n",
      "Train Epoch: 4452 [11776/60000 (20%)] Loss: -1598.338623\n",
      "Train Epoch: 4452 [23040/60000 (38%)] Loss: -1528.800171\n",
      "Train Epoch: 4452 [34304/60000 (57%)] Loss: -1494.710815\n",
      "Train Epoch: 4452 [45568/60000 (76%)] Loss: -1534.841797\n",
      "Train Epoch: 4452 [56832/60000 (95%)] Loss: -1528.758423\n",
      "    epoch          : 4452\n",
      "    loss           : -1543.7451361532264\n",
      "Train Epoch: 4453 [512/60000 (1%)] Loss: -1464.079590\n",
      "Train Epoch: 4453 [11776/60000 (20%)] Loss: -1558.180054\n",
      "Train Epoch: 4453 [23040/60000 (38%)] Loss: -1495.884033\n",
      "Train Epoch: 4453 [34304/60000 (57%)] Loss: -1563.297363\n",
      "Train Epoch: 4453 [45568/60000 (76%)] Loss: -1519.331787\n",
      "Train Epoch: 4453 [56832/60000 (95%)] Loss: -1538.964233\n",
      "    epoch          : 4453\n",
      "    loss           : -1531.9185673772952\n",
      "Train Epoch: 4454 [512/60000 (1%)] Loss: -1477.515503\n",
      "Train Epoch: 4454 [11776/60000 (20%)] Loss: -1539.171387\n",
      "Train Epoch: 4454 [23040/60000 (38%)] Loss: -1534.183838\n",
      "Train Epoch: 4454 [34304/60000 (57%)] Loss: -1526.950195\n",
      "Train Epoch: 4454 [45568/60000 (76%)] Loss: -1604.274170\n",
      "Train Epoch: 4454 [56832/60000 (95%)] Loss: -1542.345215\n",
      "    epoch          : 4454\n",
      "    loss           : -1532.7349260405633\n",
      "Train Epoch: 4455 [512/60000 (1%)] Loss: -1552.350098\n",
      "Train Epoch: 4455 [11776/60000 (20%)] Loss: -1465.055786\n",
      "Train Epoch: 4455 [23040/60000 (38%)] Loss: -1559.034790\n",
      "Train Epoch: 4455 [34304/60000 (57%)] Loss: -1605.229614\n",
      "Train Epoch: 4455 [45568/60000 (76%)] Loss: -1467.695312\n",
      "Train Epoch: 4455 [56832/60000 (95%)] Loss: -1496.741699\n",
      "    epoch          : 4455\n",
      "    loss           : -1538.1501109667417\n",
      "Train Epoch: 4456 [512/60000 (1%)] Loss: -1546.767456\n",
      "Train Epoch: 4456 [11776/60000 (20%)] Loss: -1530.242798\n",
      "Train Epoch: 4456 [23040/60000 (38%)] Loss: -1590.562256\n",
      "Train Epoch: 4456 [34304/60000 (57%)] Loss: -1529.309814\n",
      "Train Epoch: 4456 [45568/60000 (76%)] Loss: -1532.542969\n",
      "Train Epoch: 4456 [56832/60000 (95%)] Loss: -1555.414062\n",
      "    epoch          : 4456\n",
      "    loss           : -1536.793420134291\n",
      "Train Epoch: 4457 [512/60000 (1%)] Loss: -1493.854004\n",
      "Train Epoch: 4457 [11776/60000 (20%)] Loss: -1559.053223\n",
      "Train Epoch: 4457 [23040/60000 (38%)] Loss: -1479.853516\n",
      "Train Epoch: 4457 [34304/60000 (57%)] Loss: -1587.477051\n",
      "Train Epoch: 4457 [45568/60000 (76%)] Loss: -1505.065918\n",
      "Train Epoch: 4457 [56832/60000 (95%)] Loss: -1510.105103\n",
      "    epoch          : 4457\n",
      "    loss           : -1531.9978682523392\n",
      "Train Epoch: 4458 [512/60000 (1%)] Loss: -1573.749390\n",
      "Train Epoch: 4458 [11776/60000 (20%)] Loss: -1500.827881\n",
      "Train Epoch: 4458 [23040/60000 (38%)] Loss: -1487.583496\n",
      "Train Epoch: 4458 [34304/60000 (57%)] Loss: -1568.870361\n",
      "Train Epoch: 4458 [45568/60000 (76%)] Loss: -1566.750610\n",
      "Train Epoch: 4458 [56832/60000 (95%)] Loss: -1571.420166\n",
      "    epoch          : 4458\n",
      "    loss           : -1544.5490367479917\n",
      "Train Epoch: 4459 [512/60000 (1%)] Loss: -1486.083130\n",
      "Train Epoch: 4459 [11776/60000 (20%)] Loss: -1631.245117\n",
      "Train Epoch: 4459 [23040/60000 (38%)] Loss: -1541.758057\n",
      "Train Epoch: 4459 [34304/60000 (57%)] Loss: -1583.025757\n",
      "Train Epoch: 4459 [45568/60000 (76%)] Loss: -1515.671875\n",
      "Train Epoch: 4459 [56832/60000 (95%)] Loss: -1550.024658\n",
      "    epoch          : 4459\n",
      "    loss           : -1541.233225676973\n",
      "Train Epoch: 4460 [512/60000 (1%)] Loss: -1490.586670\n",
      "Train Epoch: 4460 [11776/60000 (20%)] Loss: -1618.160034\n",
      "Train Epoch: 4460 [23040/60000 (38%)] Loss: -1492.329712\n",
      "Train Epoch: 4460 [34304/60000 (57%)] Loss: -1552.469238\n",
      "Train Epoch: 4460 [45568/60000 (76%)] Loss: -1511.520508\n",
      "Train Epoch: 4460 [56832/60000 (95%)] Loss: -1606.431274\n",
      "    epoch          : 4460\n",
      "    loss           : -1540.2040356997043\n",
      "Train Epoch: 4461 [512/60000 (1%)] Loss: -1487.075439\n",
      "Train Epoch: 4461 [11776/60000 (20%)] Loss: -1581.899292\n",
      "Train Epoch: 4461 [23040/60000 (38%)] Loss: -1505.986450\n",
      "Train Epoch: 4461 [34304/60000 (57%)] Loss: -1517.073486\n",
      "Train Epoch: 4461 [45568/60000 (76%)] Loss: -1543.353760\n",
      "Train Epoch: 4461 [56832/60000 (95%)] Loss: -1578.116455\n",
      "    epoch          : 4461\n",
      "    loss           : -1540.7068350409384\n",
      "Train Epoch: 4462 [512/60000 (1%)] Loss: -1525.231934\n",
      "Train Epoch: 4462 [11776/60000 (20%)] Loss: -1526.174683\n",
      "Train Epoch: 4462 [23040/60000 (38%)] Loss: -1530.732666\n",
      "Train Epoch: 4462 [34304/60000 (57%)] Loss: -1495.269775\n",
      "Train Epoch: 4462 [45568/60000 (76%)] Loss: -1526.002441\n",
      "Train Epoch: 4462 [56832/60000 (95%)] Loss: -1505.329834\n",
      "    epoch          : 4462\n",
      "    loss           : -1536.8388061523438\n",
      "Train Epoch: 4463 [512/60000 (1%)] Loss: -1534.012695\n",
      "Train Epoch: 4463 [11776/60000 (20%)] Loss: -1563.269531\n",
      "Train Epoch: 4463 [23040/60000 (38%)] Loss: -1545.176392\n",
      "Train Epoch: 4463 [34304/60000 (57%)] Loss: -1600.143555\n",
      "Train Epoch: 4463 [45568/60000 (76%)] Loss: -1614.241211\n",
      "Train Epoch: 4463 [56832/60000 (95%)] Loss: -1510.648315\n",
      "    epoch          : 4463\n",
      "    loss           : -1541.0666052177128\n",
      "Train Epoch: 4464 [512/60000 (1%)] Loss: -1550.559814\n",
      "Train Epoch: 4464 [11776/60000 (20%)] Loss: -1556.926514\n",
      "Train Epoch: 4464 [23040/60000 (38%)] Loss: -1545.945557\n",
      "Train Epoch: 4464 [34304/60000 (57%)] Loss: -1491.513550\n",
      "Train Epoch: 4464 [45568/60000 (76%)] Loss: -1567.860718\n",
      "Train Epoch: 4464 [56832/60000 (95%)] Loss: -1515.440552\n",
      "    epoch          : 4464\n",
      "    loss           : -1539.8264370503398\n",
      "Train Epoch: 4465 [512/60000 (1%)] Loss: -1510.237061\n",
      "Train Epoch: 4465 [11776/60000 (20%)] Loss: -1532.322510\n",
      "Train Epoch: 4465 [23040/60000 (38%)] Loss: -1476.503052\n",
      "Train Epoch: 4465 [34304/60000 (57%)] Loss: -1515.633423\n",
      "Train Epoch: 4465 [45568/60000 (76%)] Loss: -1487.655151\n",
      "Train Epoch: 4465 [56832/60000 (95%)] Loss: -1515.582275\n",
      "    epoch          : 4465\n",
      "    loss           : -1539.75191346939\n",
      "Train Epoch: 4466 [512/60000 (1%)] Loss: -1577.879883\n",
      "Train Epoch: 4466 [11776/60000 (20%)] Loss: -1548.931396\n",
      "Train Epoch: 4466 [23040/60000 (38%)] Loss: -1507.422852\n",
      "Train Epoch: 4466 [34304/60000 (57%)] Loss: -1457.601562\n",
      "Train Epoch: 4466 [45568/60000 (76%)] Loss: -1540.391846\n",
      "Train Epoch: 4466 [56832/60000 (95%)] Loss: -1620.761963\n",
      "    epoch          : 4466\n",
      "    loss           : -1542.2595656227932\n",
      "Train Epoch: 4467 [512/60000 (1%)] Loss: -1604.778564\n",
      "Train Epoch: 4467 [11776/60000 (20%)] Loss: -1619.902344\n",
      "Train Epoch: 4467 [23040/60000 (38%)] Loss: -1577.691406\n",
      "Train Epoch: 4467 [34304/60000 (57%)] Loss: -1513.512939\n",
      "Train Epoch: 4467 [45568/60000 (76%)] Loss: -1590.155396\n",
      "Train Epoch: 4467 [56832/60000 (95%)] Loss: -1572.109009\n",
      "    epoch          : 4467\n",
      "    loss           : -1539.6591679632327\n",
      "Train Epoch: 4468 [512/60000 (1%)] Loss: -1537.844727\n",
      "Train Epoch: 4468 [11776/60000 (20%)] Loss: -1602.841553\n",
      "Train Epoch: 4468 [23040/60000 (38%)] Loss: -1545.262939\n",
      "Train Epoch: 4468 [34304/60000 (57%)] Loss: -1503.832642\n",
      "Train Epoch: 4468 [45568/60000 (76%)] Loss: -1607.479004\n",
      "Train Epoch: 4468 [56832/60000 (95%)] Loss: -1571.196411\n",
      "    epoch          : 4468\n",
      "    loss           : -1537.2121426857125\n",
      "Train Epoch: 4469 [512/60000 (1%)] Loss: -1477.256958\n",
      "Train Epoch: 4469 [11776/60000 (20%)] Loss: -1498.948364\n",
      "Train Epoch: 4469 [23040/60000 (38%)] Loss: -1581.533325\n",
      "Train Epoch: 4469 [34304/60000 (57%)] Loss: -1527.754761\n",
      "Train Epoch: 4469 [45568/60000 (76%)] Loss: -1608.833374\n",
      "Train Epoch: 4469 [56832/60000 (95%)] Loss: -1531.081787\n",
      "    epoch          : 4469\n",
      "    loss           : -1538.4264436711026\n",
      "Train Epoch: 4470 [512/60000 (1%)] Loss: -1534.409180\n",
      "Train Epoch: 4470 [11776/60000 (20%)] Loss: -1569.596191\n",
      "Train Epoch: 4470 [23040/60000 (38%)] Loss: -1451.718994\n",
      "Train Epoch: 4470 [34304/60000 (57%)] Loss: -1622.160767\n",
      "Train Epoch: 4470 [45568/60000 (76%)] Loss: -1532.931152\n",
      "Train Epoch: 4470 [56832/60000 (95%)] Loss: -1540.362671\n",
      "    epoch          : 4470\n",
      "    loss           : -1546.4721214165122\n",
      "Train Epoch: 4471 [512/60000 (1%)] Loss: -1575.534668\n",
      "Train Epoch: 4471 [11776/60000 (20%)] Loss: -1484.723755\n",
      "Train Epoch: 4471 [23040/60000 (38%)] Loss: -1551.620117\n",
      "Train Epoch: 4471 [34304/60000 (57%)] Loss: -1570.199463\n",
      "Train Epoch: 4471 [45568/60000 (76%)] Loss: -1604.595703\n",
      "Train Epoch: 4471 [56832/60000 (95%)] Loss: -1612.640503\n",
      "    epoch          : 4471\n",
      "    loss           : -1536.8613891601562\n",
      "Train Epoch: 4472 [512/60000 (1%)] Loss: -1530.603027\n",
      "Train Epoch: 4472 [11776/60000 (20%)] Loss: -1580.492432\n",
      "Train Epoch: 4472 [23040/60000 (38%)] Loss: -1492.531860\n",
      "Train Epoch: 4472 [34304/60000 (57%)] Loss: -1457.590088\n",
      "Train Epoch: 4472 [45568/60000 (76%)] Loss: -1567.614014\n",
      "Train Epoch: 4472 [56832/60000 (95%)] Loss: -1536.318237\n",
      "    epoch          : 4472\n",
      "    loss           : -1539.7896142302259\n",
      "Train Epoch: 4473 [512/60000 (1%)] Loss: -1493.892700\n",
      "Train Epoch: 4473 [11776/60000 (20%)] Loss: -1620.874634\n",
      "Train Epoch: 4473 [23040/60000 (38%)] Loss: -1518.141968\n",
      "Train Epoch: 4473 [34304/60000 (57%)] Loss: -1621.439697\n",
      "Train Epoch: 4473 [45568/60000 (76%)] Loss: -1582.393799\n",
      "Train Epoch: 4473 [56832/60000 (95%)] Loss: -1428.188354\n",
      "    epoch          : 4473\n",
      "    loss           : -1535.7192520745057\n",
      "Train Epoch: 4474 [512/60000 (1%)] Loss: -1554.204590\n",
      "Train Epoch: 4474 [11776/60000 (20%)] Loss: -1553.863403\n",
      "Train Epoch: 4474 [23040/60000 (38%)] Loss: -1574.683228\n",
      "Train Epoch: 4474 [34304/60000 (57%)] Loss: -1500.120239\n",
      "Train Epoch: 4474 [45568/60000 (76%)] Loss: -1573.682251\n",
      "Train Epoch: 4474 [56832/60000 (95%)] Loss: -1509.265137\n",
      "    epoch          : 4474\n",
      "    loss           : -1543.1894858839823\n",
      "Train Epoch: 4475 [512/60000 (1%)] Loss: -1486.651367\n",
      "Train Epoch: 4475 [11776/60000 (20%)] Loss: -1570.726440\n",
      "Train Epoch: 4475 [23040/60000 (38%)] Loss: -1525.138916\n",
      "Train Epoch: 4475 [34304/60000 (57%)] Loss: -1508.482910\n",
      "Train Epoch: 4475 [45568/60000 (76%)] Loss: -1509.603027\n",
      "Train Epoch: 4475 [56832/60000 (95%)] Loss: -1477.356567\n",
      "    epoch          : 4475\n",
      "    loss           : -1542.1917341846531\n",
      "Train Epoch: 4476 [512/60000 (1%)] Loss: -1576.190796\n",
      "Train Epoch: 4476 [11776/60000 (20%)] Loss: -1576.920532\n",
      "Train Epoch: 4476 [23040/60000 (38%)] Loss: -1514.075562\n",
      "Train Epoch: 4476 [34304/60000 (57%)] Loss: -1567.391846\n",
      "Train Epoch: 4476 [45568/60000 (76%)] Loss: -1533.739014\n",
      "Train Epoch: 4476 [56832/60000 (95%)] Loss: -1539.224365\n",
      "    epoch          : 4476\n",
      "    loss           : -1542.9806825454627\n",
      "Train Epoch: 4477 [512/60000 (1%)] Loss: -1520.160400\n",
      "Train Epoch: 4477 [11776/60000 (20%)] Loss: -1524.915405\n",
      "Train Epoch: 4477 [23040/60000 (38%)] Loss: -1540.479004\n",
      "Train Epoch: 4477 [34304/60000 (57%)] Loss: -1539.536987\n",
      "Train Epoch: 4477 [45568/60000 (76%)] Loss: -1466.564331\n",
      "Train Epoch: 4477 [56832/60000 (95%)] Loss: -1533.226807\n",
      "    epoch          : 4477\n",
      "    loss           : -1537.1417832886432\n",
      "Train Epoch: 4478 [512/60000 (1%)] Loss: -1542.798584\n",
      "Train Epoch: 4478 [11776/60000 (20%)] Loss: -1538.127441\n",
      "Train Epoch: 4478 [23040/60000 (38%)] Loss: -1549.741333\n",
      "Train Epoch: 4478 [34304/60000 (57%)] Loss: -1507.117432\n",
      "Train Epoch: 4478 [45568/60000 (76%)] Loss: -1502.942871\n",
      "Train Epoch: 4478 [56832/60000 (95%)] Loss: -1554.507812\n",
      "    epoch          : 4478\n",
      "    loss           : -1529.9038723875574\n",
      "Train Epoch: 4479 [512/60000 (1%)] Loss: -1452.888672\n",
      "Train Epoch: 4479 [11776/60000 (20%)] Loss: -1545.981934\n",
      "Train Epoch: 4479 [23040/60000 (38%)] Loss: -1510.310791\n",
      "Train Epoch: 4479 [34304/60000 (57%)] Loss: -1532.730225\n",
      "Train Epoch: 4479 [45568/60000 (76%)] Loss: -1587.387329\n",
      "Train Epoch: 4479 [56832/60000 (95%)] Loss: -1525.529297\n",
      "    epoch          : 4479\n",
      "    loss           : -1539.2063098627295\n",
      "Train Epoch: 4480 [512/60000 (1%)] Loss: -1536.002930\n",
      "Train Epoch: 4480 [11776/60000 (20%)] Loss: -1545.145996\n",
      "Train Epoch: 4480 [23040/60000 (38%)] Loss: -1566.649902\n",
      "Train Epoch: 4480 [34304/60000 (57%)] Loss: -1572.093506\n",
      "Train Epoch: 4480 [45568/60000 (76%)] Loss: -1569.324463\n",
      "Train Epoch: 4480 [56832/60000 (95%)] Loss: -1457.196167\n",
      "    epoch          : 4480\n",
      "    loss           : -1535.830901237531\n",
      "Train Epoch: 4481 [512/60000 (1%)] Loss: -1579.692749\n",
      "Train Epoch: 4481 [11776/60000 (20%)] Loss: -1555.267700\n",
      "Train Epoch: 4481 [23040/60000 (38%)] Loss: -1480.649902\n",
      "Train Epoch: 4481 [34304/60000 (57%)] Loss: -1482.812866\n",
      "Train Epoch: 4481 [45568/60000 (76%)] Loss: -1606.243652\n",
      "Train Epoch: 4481 [56832/60000 (95%)] Loss: -1524.155762\n",
      "    epoch          : 4481\n",
      "    loss           : -1539.9756355932204\n",
      "Train Epoch: 4482 [512/60000 (1%)] Loss: -1478.748779\n",
      "Train Epoch: 4482 [11776/60000 (20%)] Loss: -1548.898315\n",
      "Train Epoch: 4482 [23040/60000 (38%)] Loss: -1620.763428\n",
      "Train Epoch: 4482 [34304/60000 (57%)] Loss: -1510.978149\n",
      "Train Epoch: 4482 [45568/60000 (76%)] Loss: -1615.218872\n",
      "Train Epoch: 4482 [56832/60000 (95%)] Loss: -1506.868652\n",
      "    epoch          : 4482\n",
      "    loss           : -1543.7025349934897\n",
      "Train Epoch: 4483 [512/60000 (1%)] Loss: -1546.102661\n",
      "Train Epoch: 4483 [11776/60000 (20%)] Loss: -1484.234497\n",
      "Train Epoch: 4483 [23040/60000 (38%)] Loss: -1623.756348\n",
      "Train Epoch: 4483 [34304/60000 (57%)] Loss: -1622.833496\n",
      "Train Epoch: 4483 [45568/60000 (76%)] Loss: -1532.379639\n",
      "Train Epoch: 4483 [56832/60000 (95%)] Loss: -1477.336670\n",
      "    epoch          : 4483\n",
      "    loss           : -1531.206590555482\n",
      "Train Epoch: 4484 [512/60000 (1%)] Loss: -1584.753174\n",
      "Train Epoch: 4484 [11776/60000 (20%)] Loss: -1591.230957\n",
      "Train Epoch: 4484 [23040/60000 (38%)] Loss: -1620.189331\n",
      "Train Epoch: 4484 [34304/60000 (57%)] Loss: -1477.343628\n",
      "Train Epoch: 4484 [45568/60000 (76%)] Loss: -1490.829102\n",
      "Train Epoch: 4484 [56832/60000 (95%)] Loss: -1593.419312\n",
      "    epoch          : 4484\n",
      "    loss           : -1540.9789787335585\n",
      "Train Epoch: 4485 [512/60000 (1%)] Loss: -1594.259277\n",
      "Train Epoch: 4485 [11776/60000 (20%)] Loss: -1592.605469\n",
      "Train Epoch: 4485 [23040/60000 (38%)] Loss: -1567.562500\n",
      "Train Epoch: 4485 [34304/60000 (57%)] Loss: -1519.154297\n",
      "Train Epoch: 4485 [45568/60000 (76%)] Loss: -1471.234375\n",
      "Train Epoch: 4485 [56832/60000 (95%)] Loss: -1513.166748\n",
      "    epoch          : 4485\n",
      "    loss           : -1543.2774889240156\n",
      "Train Epoch: 4486 [512/60000 (1%)] Loss: -1532.710205\n",
      "Train Epoch: 4486 [11776/60000 (20%)] Loss: -1533.229980\n",
      "Train Epoch: 4486 [23040/60000 (38%)] Loss: -1497.561890\n",
      "Train Epoch: 4486 [34304/60000 (57%)] Loss: -1463.466187\n",
      "Train Epoch: 4486 [45568/60000 (76%)] Loss: -1547.089844\n",
      "Train Epoch: 4486 [56832/60000 (95%)] Loss: -1571.928223\n",
      "    epoch          : 4486\n",
      "    loss           : -1545.800226761123\n",
      "Train Epoch: 4487 [512/60000 (1%)] Loss: -1520.773804\n",
      "Train Epoch: 4487 [11776/60000 (20%)] Loss: -1587.119019\n",
      "Train Epoch: 4487 [23040/60000 (38%)] Loss: -1538.667969\n",
      "Train Epoch: 4487 [34304/60000 (57%)] Loss: -1528.131836\n",
      "Train Epoch: 4487 [45568/60000 (76%)] Loss: -1543.858887\n",
      "Train Epoch: 4487 [56832/60000 (95%)] Loss: -1390.623779\n",
      "    epoch          : 4487\n",
      "    loss           : -1529.9213005109023\n",
      "Train Epoch: 4488 [512/60000 (1%)] Loss: -1568.029541\n",
      "Train Epoch: 4488 [11776/60000 (20%)] Loss: -1551.184082\n",
      "Train Epoch: 4488 [23040/60000 (38%)] Loss: -1496.513184\n",
      "Train Epoch: 4488 [34304/60000 (57%)] Loss: -1602.409302\n",
      "Train Epoch: 4488 [45568/60000 (76%)] Loss: -1545.259155\n",
      "Train Epoch: 4488 [56832/60000 (95%)] Loss: -1556.480591\n",
      "    epoch          : 4488\n",
      "    loss           : -1536.5027369267523\n",
      "Train Epoch: 4489 [512/60000 (1%)] Loss: -1589.408691\n",
      "Train Epoch: 4489 [11776/60000 (20%)] Loss: -1473.370850\n",
      "Train Epoch: 4489 [23040/60000 (38%)] Loss: -1541.234131\n",
      "Train Epoch: 4489 [34304/60000 (57%)] Loss: -1537.045410\n",
      "Train Epoch: 4489 [45568/60000 (76%)] Loss: -1492.509033\n",
      "Train Epoch: 4489 [56832/60000 (95%)] Loss: -1492.398071\n",
      "    epoch          : 4489\n",
      "    loss           : -1541.1838340974796\n",
      "Train Epoch: 4490 [512/60000 (1%)] Loss: -1492.625122\n",
      "Train Epoch: 4490 [11776/60000 (20%)] Loss: -1616.661011\n",
      "Train Epoch: 4490 [23040/60000 (38%)] Loss: -1537.869019\n",
      "Train Epoch: 4490 [34304/60000 (57%)] Loss: -1587.023926\n",
      "Train Epoch: 4490 [45568/60000 (76%)] Loss: -1513.841675\n",
      "Train Epoch: 4490 [56832/60000 (95%)] Loss: -1555.069092\n",
      "    epoch          : 4490\n",
      "    loss           : -1537.5177884721486\n",
      "Train Epoch: 4491 [512/60000 (1%)] Loss: -1433.392334\n",
      "Train Epoch: 4491 [11776/60000 (20%)] Loss: -1550.797729\n",
      "Train Epoch: 4491 [23040/60000 (38%)] Loss: -1554.777588\n",
      "Train Epoch: 4491 [34304/60000 (57%)] Loss: -1479.776611\n",
      "Train Epoch: 4491 [45568/60000 (76%)] Loss: -1554.330322\n",
      "Train Epoch: 4491 [56832/60000 (95%)] Loss: -1600.140503\n",
      "    epoch          : 4491\n",
      "    loss           : -1530.7087078202244\n",
      "Train Epoch: 4492 [512/60000 (1%)] Loss: -1551.874146\n",
      "Train Epoch: 4492 [11776/60000 (20%)] Loss: -1570.386597\n",
      "Train Epoch: 4492 [23040/60000 (38%)] Loss: -1625.536377\n",
      "Train Epoch: 4492 [34304/60000 (57%)] Loss: -1511.593750\n",
      "Train Epoch: 4492 [45568/60000 (76%)] Loss: -1543.193237\n",
      "Train Epoch: 4492 [56832/60000 (95%)] Loss: -1586.644043\n",
      "    epoch          : 4492\n",
      "    loss           : -1542.6790292168741\n",
      "Train Epoch: 4493 [512/60000 (1%)] Loss: -1505.050415\n",
      "Train Epoch: 4493 [11776/60000 (20%)] Loss: -1549.983398\n",
      "Train Epoch: 4493 [23040/60000 (38%)] Loss: -1531.885376\n",
      "Train Epoch: 4493 [34304/60000 (57%)] Loss: -1615.090942\n",
      "Train Epoch: 4493 [45568/60000 (76%)] Loss: -1558.973389\n",
      "Train Epoch: 4493 [56832/60000 (95%)] Loss: -1575.821777\n",
      "    epoch          : 4493\n",
      "    loss           : -1541.771315062787\n",
      "Train Epoch: 4494 [512/60000 (1%)] Loss: -1493.160400\n",
      "Train Epoch: 4494 [11776/60000 (20%)] Loss: -1532.901611\n",
      "Train Epoch: 4494 [23040/60000 (38%)] Loss: -1512.367920\n",
      "Train Epoch: 4494 [34304/60000 (57%)] Loss: -1450.146362\n",
      "Train Epoch: 4494 [45568/60000 (76%)] Loss: -1520.875977\n",
      "Train Epoch: 4494 [56832/60000 (95%)] Loss: -1548.802002\n",
      "    epoch          : 4494\n",
      "    loss           : -1531.17543676344\n",
      "Train Epoch: 4495 [512/60000 (1%)] Loss: -1559.692871\n",
      "Train Epoch: 4495 [11776/60000 (20%)] Loss: -1529.137695\n",
      "Train Epoch: 4495 [23040/60000 (38%)] Loss: -1505.821533\n",
      "Train Epoch: 4495 [34304/60000 (57%)] Loss: -1554.687622\n",
      "Train Epoch: 4495 [45568/60000 (76%)] Loss: -1540.965820\n",
      "Train Epoch: 4495 [56832/60000 (95%)] Loss: -1523.121826\n",
      "    epoch          : 4495\n",
      "    loss           : -1531.8907043112201\n",
      "Train Epoch: 4496 [512/60000 (1%)] Loss: -1510.225098\n",
      "Train Epoch: 4496 [11776/60000 (20%)] Loss: -1484.729736\n",
      "Train Epoch: 4496 [23040/60000 (38%)] Loss: -1563.907104\n",
      "Train Epoch: 4496 [34304/60000 (57%)] Loss: -1438.831787\n",
      "Train Epoch: 4496 [45568/60000 (76%)] Loss: -1557.803589\n",
      "Train Epoch: 4496 [56832/60000 (95%)] Loss: -1533.816772\n",
      "    epoch          : 4496\n",
      "    loss           : -1530.0571189061395\n",
      "Train Epoch: 4497 [512/60000 (1%)] Loss: -1631.341553\n",
      "Train Epoch: 4497 [11776/60000 (20%)] Loss: -1473.562744\n",
      "Train Epoch: 4497 [23040/60000 (38%)] Loss: -1481.377441\n",
      "Train Epoch: 4497 [34304/60000 (57%)] Loss: -1565.535156\n",
      "Train Epoch: 4497 [45568/60000 (76%)] Loss: -1565.673584\n",
      "Train Epoch: 4497 [56832/60000 (95%)] Loss: -1484.959595\n",
      "    epoch          : 4497\n",
      "    loss           : -1535.1015821553892\n",
      "Train Epoch: 4498 [512/60000 (1%)] Loss: -1540.950439\n",
      "Train Epoch: 4498 [11776/60000 (20%)] Loss: -1517.228271\n",
      "Train Epoch: 4498 [23040/60000 (38%)] Loss: -1504.688477\n",
      "Train Epoch: 4498 [34304/60000 (57%)] Loss: -1499.528931\n",
      "Train Epoch: 4498 [45568/60000 (76%)] Loss: -1514.060303\n",
      "Train Epoch: 4498 [56832/60000 (95%)] Loss: -1477.782959\n",
      "    epoch          : 4498\n",
      "    loss           : -1531.5792601849398\n",
      "Train Epoch: 4499 [512/60000 (1%)] Loss: -1446.620728\n",
      "Train Epoch: 4499 [11776/60000 (20%)] Loss: -1540.413818\n",
      "Train Epoch: 4499 [23040/60000 (38%)] Loss: -1565.715942\n",
      "Train Epoch: 4499 [34304/60000 (57%)] Loss: -1556.637695\n",
      "Train Epoch: 4499 [45568/60000 (76%)] Loss: -1584.827026\n",
      "Train Epoch: 4499 [56832/60000 (95%)] Loss: -1615.227051\n",
      "    epoch          : 4499\n",
      "    loss           : -1539.8428293001855\n",
      "Train Epoch: 4500 [512/60000 (1%)] Loss: -1580.637695\n",
      "Train Epoch: 4500 [11776/60000 (20%)] Loss: -1591.234863\n",
      "Train Epoch: 4500 [23040/60000 (38%)] Loss: -1575.540039\n",
      "Train Epoch: 4500 [34304/60000 (57%)] Loss: -1526.335449\n",
      "Train Epoch: 4500 [45568/60000 (76%)] Loss: -1556.612183\n",
      "Train Epoch: 4500 [56832/60000 (95%)] Loss: -1608.293945\n",
      "    epoch          : 4500\n",
      "    loss           : -1539.1985601220426\n",
      "Saving checkpoint: saved/models/Mnist_DeepGenerativeOperad/0127_111843/checkpoint-epoch4500.pth ...\n",
      "Train Epoch: 4501 [512/60000 (1%)] Loss: -1564.021240\n",
      "Train Epoch: 4501 [11776/60000 (20%)] Loss: -1516.766113\n",
      "Train Epoch: 4501 [23040/60000 (38%)] Loss: -1500.620728\n",
      "Train Epoch: 4501 [34304/60000 (57%)] Loss: -1586.641968\n",
      "Train Epoch: 4501 [45568/60000 (76%)] Loss: -1548.637695\n",
      "Train Epoch: 4501 [56832/60000 (95%)] Loss: -1561.995361\n",
      "    epoch          : 4501\n",
      "    loss           : -1534.873116530941\n",
      "Train Epoch: 4502 [512/60000 (1%)] Loss: -1563.797607\n",
      "Train Epoch: 4502 [11776/60000 (20%)] Loss: -1517.803955\n",
      "Train Epoch: 4502 [23040/60000 (38%)] Loss: -1475.333008\n",
      "Train Epoch: 4502 [34304/60000 (57%)] Loss: -1561.815674\n",
      "Train Epoch: 4502 [45568/60000 (76%)] Loss: -1603.402710\n",
      "Train Epoch: 4502 [56832/60000 (95%)] Loss: -1520.037720\n",
      "    epoch          : 4502\n",
      "    loss           : -1536.2338208559543\n",
      "Train Epoch: 4503 [512/60000 (1%)] Loss: -1579.825439\n",
      "Train Epoch: 4503 [11776/60000 (20%)] Loss: -1530.843750\n",
      "Train Epoch: 4503 [23040/60000 (38%)] Loss: -1443.503540\n",
      "Train Epoch: 4503 [34304/60000 (57%)] Loss: -1447.986328\n",
      "Train Epoch: 4503 [45568/60000 (76%)] Loss: -1563.431641\n",
      "Train Epoch: 4503 [56832/60000 (95%)] Loss: -1560.226685\n",
      "    epoch          : 4503\n",
      "    loss           : -1535.433684440656\n",
      "Train Epoch: 4504 [512/60000 (1%)] Loss: -1525.150391\n",
      "Train Epoch: 4504 [11776/60000 (20%)] Loss: -1505.311890\n",
      "Train Epoch: 4504 [23040/60000 (38%)] Loss: -1563.147705\n",
      "Train Epoch: 4504 [34304/60000 (57%)] Loss: -1546.050781\n",
      "Train Epoch: 4504 [45568/60000 (76%)] Loss: -1534.346802\n",
      "Train Epoch: 4504 [56832/60000 (95%)] Loss: -1538.735596\n",
      "    epoch          : 4504\n",
      "    loss           : -1542.561146191958\n",
      "Train Epoch: 4505 [512/60000 (1%)] Loss: -1548.380859\n",
      "Train Epoch: 4505 [11776/60000 (20%)] Loss: -1485.472778\n",
      "Train Epoch: 4505 [23040/60000 (38%)] Loss: -1449.501465\n",
      "Train Epoch: 4505 [34304/60000 (57%)] Loss: -1481.297974\n",
      "Train Epoch: 4505 [45568/60000 (76%)] Loss: -1549.232056\n",
      "Train Epoch: 4505 [56832/60000 (95%)] Loss: -1575.855347\n",
      "    epoch          : 4505\n",
      "    loss           : -1545.0404369979256\n",
      "Train Epoch: 4506 [512/60000 (1%)] Loss: -1562.643555\n",
      "Train Epoch: 4506 [11776/60000 (20%)] Loss: -1519.360840\n",
      "Train Epoch: 4506 [23040/60000 (38%)] Loss: -1599.938477\n",
      "Train Epoch: 4506 [34304/60000 (57%)] Loss: -1559.036011\n",
      "Train Epoch: 4506 [45568/60000 (76%)] Loss: -1490.587402\n",
      "Train Epoch: 4506 [56832/60000 (95%)] Loss: -1594.499756\n",
      "    epoch          : 4506\n",
      "    loss           : -1537.6351766640182\n",
      "Train Epoch: 4507 [512/60000 (1%)] Loss: -1537.344238\n",
      "Train Epoch: 4507 [11776/60000 (20%)] Loss: -1498.101807\n",
      "Train Epoch: 4507 [23040/60000 (38%)] Loss: -1510.763672\n",
      "Train Epoch: 4507 [34304/60000 (57%)] Loss: -1495.741577\n",
      "Train Epoch: 4507 [45568/60000 (76%)] Loss: -1623.616943\n",
      "Train Epoch: 4507 [56832/60000 (95%)] Loss: -1494.651733\n",
      "    epoch          : 4507\n",
      "    loss           : -1532.6262882900776\n",
      "Train Epoch: 4508 [512/60000 (1%)] Loss: -1613.756836\n",
      "Train Epoch: 4508 [11776/60000 (20%)] Loss: -1422.294922\n",
      "Train Epoch: 4508 [23040/60000 (38%)] Loss: -1516.345459\n",
      "Train Epoch: 4508 [34304/60000 (57%)] Loss: -1504.779419\n",
      "Train Epoch: 4508 [45568/60000 (76%)] Loss: -1600.227905\n",
      "Train Epoch: 4508 [56832/60000 (95%)] Loss: -1514.038086\n",
      "    epoch          : 4508\n",
      "    loss           : -1534.9539150087173\n",
      "Train Epoch: 4509 [512/60000 (1%)] Loss: -1526.751831\n",
      "Train Epoch: 4509 [11776/60000 (20%)] Loss: -1534.564453\n",
      "Train Epoch: 4509 [23040/60000 (38%)] Loss: -1529.363525\n",
      "Train Epoch: 4509 [34304/60000 (57%)] Loss: -1507.488037\n",
      "Train Epoch: 4509 [45568/60000 (76%)] Loss: -1511.390137\n",
      "Train Epoch: 4509 [56832/60000 (95%)] Loss: -1564.662720\n",
      "    epoch          : 4509\n",
      "    loss           : -1540.4876253806938\n",
      "Train Epoch: 4510 [512/60000 (1%)] Loss: -1518.911255\n",
      "Train Epoch: 4510 [11776/60000 (20%)] Loss: -1530.814941\n",
      "Train Epoch: 4510 [23040/60000 (38%)] Loss: -1564.266846\n",
      "Train Epoch: 4510 [34304/60000 (57%)] Loss: -1548.986206\n",
      "Train Epoch: 4510 [45568/60000 (76%)] Loss: -1495.666504\n",
      "Train Epoch: 4510 [56832/60000 (95%)] Loss: -1561.221802\n",
      "    epoch          : 4510\n",
      "    loss           : -1536.163190766243\n",
      "Train Epoch: 4511 [512/60000 (1%)] Loss: -1520.079834\n",
      "Train Epoch: 4511 [11776/60000 (20%)] Loss: -1470.924805\n",
      "Train Epoch: 4511 [23040/60000 (38%)] Loss: -1424.305908\n",
      "Train Epoch: 4511 [34304/60000 (57%)] Loss: -1543.972900\n",
      "Train Epoch: 4511 [45568/60000 (76%)] Loss: -1542.787598\n",
      "Train Epoch: 4511 [56832/60000 (95%)] Loss: -1595.932373\n",
      "    epoch          : 4511\n",
      "    loss           : -1540.728785283148\n",
      "Train Epoch: 4512 [512/60000 (1%)] Loss: -1550.390381\n",
      "Train Epoch: 4512 [11776/60000 (20%)] Loss: -1519.151245\n",
      "Train Epoch: 4512 [23040/60000 (38%)] Loss: -1567.912231\n",
      "Train Epoch: 4512 [34304/60000 (57%)] Loss: -1540.531616\n",
      "Train Epoch: 4512 [45568/60000 (76%)] Loss: -1480.341919\n",
      "Train Epoch: 4512 [56832/60000 (95%)] Loss: -1459.405640\n",
      "    epoch          : 4512\n",
      "    loss           : -1535.8460772670596\n",
      "Train Epoch: 4513 [512/60000 (1%)] Loss: -1567.555420\n",
      "Train Epoch: 4513 [11776/60000 (20%)] Loss: -1537.841675\n",
      "Train Epoch: 4513 [23040/60000 (38%)] Loss: -1497.846802\n",
      "Train Epoch: 4513 [34304/60000 (57%)] Loss: -1473.848389\n",
      "Train Epoch: 4513 [45568/60000 (76%)] Loss: -1498.382446\n",
      "Train Epoch: 4513 [56832/60000 (95%)] Loss: -1558.466675\n",
      "    epoch          : 4513\n",
      "    loss           : -1540.0501912434897\n",
      "Train Epoch: 4514 [512/60000 (1%)] Loss: -1521.265625\n",
      "Train Epoch: 4514 [11776/60000 (20%)] Loss: -1581.408691\n",
      "Train Epoch: 4514 [23040/60000 (38%)] Loss: -1521.322266\n",
      "Train Epoch: 4514 [34304/60000 (57%)] Loss: -1578.375610\n",
      "Train Epoch: 4514 [45568/60000 (76%)] Loss: -1500.617432\n",
      "Train Epoch: 4514 [56832/60000 (95%)] Loss: -1593.185547\n",
      "    epoch          : 4514\n",
      "    loss           : -1537.4246433064088\n",
      "Train Epoch: 4515 [512/60000 (1%)] Loss: -1585.251831\n",
      "Train Epoch: 4515 [11776/60000 (20%)] Loss: -1519.974731\n",
      "Train Epoch: 4515 [23040/60000 (38%)] Loss: -1556.256592\n",
      "Train Epoch: 4515 [34304/60000 (57%)] Loss: -1565.138672\n",
      "Train Epoch: 4515 [45568/60000 (76%)] Loss: -1536.412598\n",
      "Train Epoch: 4515 [56832/60000 (95%)] Loss: -1464.557495\n",
      "    epoch          : 4515\n",
      "    loss           : -1535.33028881698\n",
      "Train Epoch: 4516 [512/60000 (1%)] Loss: -1500.503784\n",
      "Train Epoch: 4516 [11776/60000 (20%)] Loss: -1450.817993\n",
      "Train Epoch: 4516 [23040/60000 (38%)] Loss: -1539.422607\n",
      "Train Epoch: 4516 [34304/60000 (57%)] Loss: -1613.251953\n",
      "Train Epoch: 4516 [45568/60000 (76%)] Loss: -1525.648682\n",
      "Train Epoch: 4516 [56832/60000 (95%)] Loss: -1553.851074\n",
      "    epoch          : 4516\n",
      "    loss           : -1541.1546130853858\n",
      "Train Epoch: 4517 [512/60000 (1%)] Loss: -1465.396973\n",
      "Train Epoch: 4517 [11776/60000 (20%)] Loss: -1516.492798\n",
      "Train Epoch: 4517 [23040/60000 (38%)] Loss: -1461.856812\n",
      "Train Epoch: 4517 [34304/60000 (57%)] Loss: -1577.835449\n",
      "Train Epoch: 4517 [45568/60000 (76%)] Loss: -1543.862915\n",
      "Train Epoch: 4517 [56832/60000 (95%)] Loss: -1533.680176\n",
      "    epoch          : 4517\n",
      "    loss           : -1533.5105339093398\n",
      "Train Epoch: 4518 [512/60000 (1%)] Loss: -1550.554199\n",
      "Train Epoch: 4518 [11776/60000 (20%)] Loss: -1470.332275\n",
      "Train Epoch: 4518 [23040/60000 (38%)] Loss: -1474.123535\n",
      "Train Epoch: 4518 [34304/60000 (57%)] Loss: -1588.930176\n",
      "Train Epoch: 4518 [45568/60000 (76%)] Loss: -1565.811768\n",
      "Train Epoch: 4518 [56832/60000 (95%)] Loss: -1497.108032\n",
      "    epoch          : 4518\n",
      "    loss           : -1530.2451347739009\n",
      "Train Epoch: 4519 [512/60000 (1%)] Loss: -1556.255615\n",
      "Train Epoch: 4519 [11776/60000 (20%)] Loss: -1593.411865\n",
      "Train Epoch: 4519 [23040/60000 (38%)] Loss: -1454.764648\n",
      "Train Epoch: 4519 [34304/60000 (57%)] Loss: -1532.231323\n",
      "Train Epoch: 4519 [45568/60000 (76%)] Loss: -1514.945312\n",
      "Train Epoch: 4519 [56832/60000 (95%)] Loss: -1472.250977\n",
      "    epoch          : 4519\n",
      "    loss           : -1537.5268996071682\n",
      "Train Epoch: 4520 [512/60000 (1%)] Loss: -1562.827515\n",
      "Train Epoch: 4520 [11776/60000 (20%)] Loss: -1440.233276\n",
      "Train Epoch: 4520 [23040/60000 (38%)] Loss: -1597.414062\n",
      "Train Epoch: 4520 [34304/60000 (57%)] Loss: -1581.976562\n",
      "Train Epoch: 4520 [45568/60000 (76%)] Loss: -1570.482666\n",
      "Train Epoch: 4520 [56832/60000 (95%)] Loss: -1541.528687\n",
      "    epoch          : 4520\n",
      "    loss           : -1533.696508720096\n",
      "Train Epoch: 4521 [512/60000 (1%)] Loss: -1484.514648\n",
      "Train Epoch: 4521 [11776/60000 (20%)] Loss: -1554.628906\n",
      "Train Epoch: 4521 [23040/60000 (38%)] Loss: -1576.372681\n",
      "Train Epoch: 4521 [34304/60000 (57%)] Loss: -1539.183350\n",
      "Train Epoch: 4521 [45568/60000 (76%)] Loss: -1469.420898\n",
      "Train Epoch: 4521 [56832/60000 (95%)] Loss: -1607.877808\n",
      "    epoch          : 4521\n",
      "    loss           : -1531.7372229624602\n",
      "Train Epoch: 4522 [512/60000 (1%)] Loss: -1486.104980\n",
      "Train Epoch: 4522 [11776/60000 (20%)] Loss: -1497.365112\n",
      "Train Epoch: 4522 [23040/60000 (38%)] Loss: -1511.678223\n",
      "Train Epoch: 4522 [34304/60000 (57%)] Loss: -1456.352539\n",
      "Train Epoch: 4522 [45568/60000 (76%)] Loss: -1481.024902\n",
      "Train Epoch: 4522 [56832/60000 (95%)] Loss: -1520.035034\n",
      "    epoch          : 4522\n",
      "    loss           : -1538.4761324952551\n",
      "Train Epoch: 4523 [512/60000 (1%)] Loss: -1566.687134\n",
      "Train Epoch: 4523 [11776/60000 (20%)] Loss: -1537.292969\n",
      "Train Epoch: 4523 [23040/60000 (38%)] Loss: -1502.475220\n",
      "Train Epoch: 4523 [34304/60000 (57%)] Loss: -1559.366455\n",
      "Train Epoch: 4523 [45568/60000 (76%)] Loss: -1477.297119\n",
      "Train Epoch: 4523 [56832/60000 (95%)] Loss: -1525.299072\n",
      "    epoch          : 4523\n",
      "    loss           : -1538.8967305846134\n",
      "Train Epoch: 4524 [512/60000 (1%)] Loss: -1528.325073\n",
      "Train Epoch: 4524 [11776/60000 (20%)] Loss: -1544.117310\n",
      "Train Epoch: 4524 [23040/60000 (38%)] Loss: -1566.069336\n",
      "Train Epoch: 4524 [34304/60000 (57%)] Loss: -1614.173828\n",
      "Train Epoch: 4524 [45568/60000 (76%)] Loss: -1558.251953\n",
      "Train Epoch: 4524 [56832/60000 (95%)] Loss: -1570.004761\n",
      "    epoch          : 4524\n",
      "    loss           : -1540.8883639405676\n",
      "Train Epoch: 4525 [512/60000 (1%)] Loss: -1515.739258\n",
      "Train Epoch: 4525 [11776/60000 (20%)] Loss: -1541.938477\n",
      "Train Epoch: 4525 [23040/60000 (38%)] Loss: -1609.815186\n",
      "Train Epoch: 4525 [34304/60000 (57%)] Loss: -1510.272583\n",
      "Train Epoch: 4525 [45568/60000 (76%)] Loss: -1549.889648\n",
      "Train Epoch: 4525 [56832/60000 (95%)] Loss: -1542.244873\n",
      "    epoch          : 4525\n",
      "    loss           : -1540.5337731312898\n",
      "Train Epoch: 4526 [512/60000 (1%)] Loss: -1548.803711\n",
      "Train Epoch: 4526 [11776/60000 (20%)] Loss: -1562.602051\n",
      "Train Epoch: 4526 [23040/60000 (38%)] Loss: -1532.702271\n",
      "Train Epoch: 4526 [34304/60000 (57%)] Loss: -1517.184326\n",
      "Train Epoch: 4526 [45568/60000 (76%)] Loss: -1578.617065\n",
      "Train Epoch: 4526 [56832/60000 (95%)] Loss: -1456.595947\n",
      "    epoch          : 4526\n",
      "    loss           : -1534.743550273658\n",
      "Train Epoch: 4527 [512/60000 (1%)] Loss: -1509.595825\n",
      "Train Epoch: 4527 [11776/60000 (20%)] Loss: -1597.383911\n",
      "Train Epoch: 4527 [23040/60000 (38%)] Loss: -1546.504395\n",
      "Train Epoch: 4527 [34304/60000 (57%)] Loss: -1385.569214\n",
      "Train Epoch: 4527 [45568/60000 (76%)] Loss: -1551.705078\n",
      "Train Epoch: 4527 [56832/60000 (95%)] Loss: -1497.115234\n",
      "    epoch          : 4527\n",
      "    loss           : -1535.5991931635108\n",
      "Train Epoch: 4528 [512/60000 (1%)] Loss: -1605.161987\n",
      "Train Epoch: 4528 [11776/60000 (20%)] Loss: -1570.072266\n",
      "Train Epoch: 4528 [23040/60000 (38%)] Loss: -1527.206665\n",
      "Train Epoch: 4528 [34304/60000 (57%)] Loss: -1517.298828\n",
      "Train Epoch: 4528 [45568/60000 (76%)] Loss: -1600.696289\n",
      "Train Epoch: 4528 [56832/60000 (95%)] Loss: -1554.979736\n",
      "    epoch          : 4528\n",
      "    loss           : -1542.6764895336778\n",
      "Train Epoch: 4529 [512/60000 (1%)] Loss: -1587.676880\n",
      "Train Epoch: 4529 [11776/60000 (20%)] Loss: -1549.587891\n",
      "Train Epoch: 4529 [23040/60000 (38%)] Loss: -1575.429199\n",
      "Train Epoch: 4529 [34304/60000 (57%)] Loss: -1443.931030\n",
      "Train Epoch: 4529 [45568/60000 (76%)] Loss: -1519.978271\n",
      "Train Epoch: 4529 [56832/60000 (95%)] Loss: -1579.798462\n",
      "    epoch          : 4529\n",
      "    loss           : -1535.8996613066074\n",
      "Train Epoch: 4530 [512/60000 (1%)] Loss: -1459.388306\n",
      "Train Epoch: 4530 [11776/60000 (20%)] Loss: -1531.378662\n",
      "Train Epoch: 4530 [23040/60000 (38%)] Loss: -1477.455078\n",
      "Train Epoch: 4530 [34304/60000 (57%)] Loss: -1607.619751\n",
      "Train Epoch: 4530 [45568/60000 (76%)] Loss: -1498.154419\n",
      "Train Epoch: 4530 [56832/60000 (95%)] Loss: -1503.172119\n",
      "    epoch          : 4530\n",
      "    loss           : -1537.4697393212614\n",
      "Train Epoch: 4531 [512/60000 (1%)] Loss: -1404.919434\n",
      "Train Epoch: 4531 [11776/60000 (20%)] Loss: -1582.979370\n",
      "Train Epoch: 4531 [23040/60000 (38%)] Loss: -1637.103271\n",
      "Train Epoch: 4531 [34304/60000 (57%)] Loss: -1546.637939\n",
      "Train Epoch: 4531 [45568/60000 (76%)] Loss: -1536.550781\n",
      "Train Epoch: 4531 [56832/60000 (95%)] Loss: -1530.314331\n",
      "    epoch          : 4531\n",
      "    loss           : -1530.7528517556057\n",
      "Train Epoch: 4532 [512/60000 (1%)] Loss: -1447.837402\n",
      "Train Epoch: 4532 [11776/60000 (20%)] Loss: -1548.630371\n",
      "Train Epoch: 4532 [23040/60000 (38%)] Loss: -1590.953369\n",
      "Train Epoch: 4532 [34304/60000 (57%)] Loss: -1517.348267\n",
      "Train Epoch: 4532 [45568/60000 (76%)] Loss: -1516.304077\n",
      "Train Epoch: 4532 [56832/60000 (95%)] Loss: -1572.126831\n",
      "    epoch          : 4532\n",
      "    loss           : -1536.270869195798\n",
      "Train Epoch: 4533 [512/60000 (1%)] Loss: -1581.936279\n",
      "Train Epoch: 4533 [11776/60000 (20%)] Loss: -1495.009766\n",
      "Train Epoch: 4533 [23040/60000 (38%)] Loss: -1573.639893\n",
      "Train Epoch: 4533 [34304/60000 (57%)] Loss: -1548.253174\n",
      "Train Epoch: 4533 [45568/60000 (76%)] Loss: -1511.069824\n",
      "Train Epoch: 4533 [56832/60000 (95%)] Loss: -1508.551147\n",
      "    epoch          : 4533\n",
      "    loss           : -1539.5605206678144\n",
      "Train Epoch: 4534 [512/60000 (1%)] Loss: -1515.687134\n",
      "Train Epoch: 4534 [11776/60000 (20%)] Loss: -1582.246826\n",
      "Train Epoch: 4534 [23040/60000 (38%)] Loss: -1442.361328\n",
      "Train Epoch: 4534 [34304/60000 (57%)] Loss: -1536.509521\n",
      "Train Epoch: 4534 [45568/60000 (76%)] Loss: -1546.216797\n",
      "Train Epoch: 4534 [56832/60000 (95%)] Loss: -1539.880127\n",
      "    epoch          : 4534\n",
      "    loss           : -1538.2310515150511\n",
      "Train Epoch: 4535 [512/60000 (1%)] Loss: -1490.148193\n",
      "Train Epoch: 4535 [11776/60000 (20%)] Loss: -1602.086426\n",
      "Train Epoch: 4535 [23040/60000 (38%)] Loss: -1551.123779\n",
      "Train Epoch: 4535 [34304/60000 (57%)] Loss: -1552.743896\n",
      "Train Epoch: 4535 [45568/60000 (76%)] Loss: -1518.418457\n",
      "Train Epoch: 4535 [56832/60000 (95%)] Loss: -1527.315918\n",
      "    epoch          : 4535\n",
      "    loss           : -1536.4204911916268\n",
      "Train Epoch: 4536 [512/60000 (1%)] Loss: -1581.131592\n",
      "Train Epoch: 4536 [11776/60000 (20%)] Loss: -1558.403687\n",
      "Train Epoch: 4536 [23040/60000 (38%)] Loss: -1565.652466\n",
      "Train Epoch: 4536 [34304/60000 (57%)] Loss: -1553.582764\n",
      "Train Epoch: 4536 [45568/60000 (76%)] Loss: -1446.028442\n",
      "Train Epoch: 4536 [56832/60000 (95%)] Loss: -1527.027832\n",
      "    epoch          : 4536\n",
      "    loss           : -1542.782891052591\n",
      "Train Epoch: 4537 [512/60000 (1%)] Loss: -1528.631592\n",
      "Train Epoch: 4537 [11776/60000 (20%)] Loss: -1493.713257\n",
      "Train Epoch: 4537 [23040/60000 (38%)] Loss: -1509.589844\n",
      "Train Epoch: 4537 [34304/60000 (57%)] Loss: -1439.293335\n",
      "Train Epoch: 4537 [45568/60000 (76%)] Loss: -1577.002441\n",
      "Train Epoch: 4537 [56832/60000 (95%)] Loss: -1518.160278\n",
      "    epoch          : 4537\n",
      "    loss           : -1539.4706503657972\n",
      "Train Epoch: 4538 [512/60000 (1%)] Loss: -1562.386353\n",
      "Train Epoch: 4538 [11776/60000 (20%)] Loss: -1580.492676\n",
      "Train Epoch: 4538 [23040/60000 (38%)] Loss: -1523.926147\n",
      "Train Epoch: 4538 [34304/60000 (57%)] Loss: -1405.441284\n",
      "Train Epoch: 4538 [45568/60000 (76%)] Loss: -1591.291016\n",
      "Train Epoch: 4538 [56832/60000 (95%)] Loss: -1602.124268\n",
      "    epoch          : 4538\n",
      "    loss           : -1538.9098659019685\n",
      "Train Epoch: 4539 [512/60000 (1%)] Loss: -1487.817383\n",
      "Train Epoch: 4539 [11776/60000 (20%)] Loss: -1554.917725\n",
      "Train Epoch: 4539 [23040/60000 (38%)] Loss: -1507.628418\n",
      "Train Epoch: 4539 [34304/60000 (57%)] Loss: -1580.426514\n",
      "Train Epoch: 4539 [45568/60000 (76%)] Loss: -1575.196045\n",
      "Train Epoch: 4539 [56832/60000 (95%)] Loss: -1567.342651\n",
      "    epoch          : 4539\n",
      "    loss           : -1533.8668343926554\n",
      "Train Epoch: 4540 [512/60000 (1%)] Loss: -1509.932495\n",
      "Train Epoch: 4540 [11776/60000 (20%)] Loss: -1527.759277\n",
      "Train Epoch: 4540 [23040/60000 (38%)] Loss: -1498.705322\n",
      "Train Epoch: 4540 [34304/60000 (57%)] Loss: -1545.630127\n",
      "Train Epoch: 4540 [45568/60000 (76%)] Loss: -1501.355469\n",
      "Train Epoch: 4540 [56832/60000 (95%)] Loss: -1492.200195\n",
      "    epoch          : 4540\n",
      "    loss           : -1537.6337200962216\n",
      "Train Epoch: 4541 [512/60000 (1%)] Loss: -1504.649170\n",
      "Train Epoch: 4541 [11776/60000 (20%)] Loss: -1453.891235\n",
      "Train Epoch: 4541 [23040/60000 (38%)] Loss: -1449.465210\n",
      "Train Epoch: 4541 [34304/60000 (57%)] Loss: -1532.066040\n",
      "Train Epoch: 4541 [45568/60000 (76%)] Loss: -1495.579102\n",
      "Train Epoch: 4541 [56832/60000 (95%)] Loss: -1474.240967\n",
      "    epoch          : 4541\n",
      "    loss           : -1533.0467381019378\n",
      "Train Epoch: 4542 [512/60000 (1%)] Loss: -1452.624146\n",
      "Train Epoch: 4542 [11776/60000 (20%)] Loss: -1520.535645\n",
      "Train Epoch: 4542 [23040/60000 (38%)] Loss: -1534.059814\n",
      "Train Epoch: 4542 [34304/60000 (57%)] Loss: -1555.031860\n",
      "Train Epoch: 4542 [45568/60000 (76%)] Loss: -1566.552734\n",
      "Train Epoch: 4542 [56832/60000 (95%)] Loss: -1527.027466\n",
      "    epoch          : 4542\n",
      "    loss           : -1531.6696687687588\n",
      "Train Epoch: 4543 [512/60000 (1%)] Loss: -1582.994141\n",
      "Train Epoch: 4543 [11776/60000 (20%)] Loss: -1442.221924\n",
      "Train Epoch: 4543 [23040/60000 (38%)] Loss: -1575.728271\n",
      "Train Epoch: 4543 [34304/60000 (57%)] Loss: -1573.874756\n",
      "Train Epoch: 4543 [45568/60000 (76%)] Loss: -1549.733765\n",
      "Train Epoch: 4543 [56832/60000 (95%)] Loss: -1522.859863\n",
      "    epoch          : 4543\n",
      "    loss           : -1535.8616805426818\n",
      "Train Epoch: 4544 [512/60000 (1%)] Loss: -1555.001709\n",
      "Train Epoch: 4544 [11776/60000 (20%)] Loss: -1620.648438\n",
      "Train Epoch: 4544 [23040/60000 (38%)] Loss: -1612.487793\n",
      "Train Epoch: 4544 [34304/60000 (57%)] Loss: -1525.243652\n",
      "Train Epoch: 4544 [45568/60000 (76%)] Loss: -1459.315552\n",
      "Train Epoch: 4544 [56832/60000 (95%)] Loss: -1580.570923\n",
      "    epoch          : 4544\n",
      "    loss           : -1538.684842729299\n",
      "Train Epoch: 4545 [512/60000 (1%)] Loss: -1501.109375\n",
      "Train Epoch: 4545 [11776/60000 (20%)] Loss: -1525.434326\n",
      "Train Epoch: 4545 [23040/60000 (38%)] Loss: -1510.902832\n",
      "Train Epoch: 4545 [34304/60000 (57%)] Loss: -1558.037476\n",
      "Train Epoch: 4545 [45568/60000 (76%)] Loss: -1575.850342\n",
      "Train Epoch: 4545 [56832/60000 (95%)] Loss: -1476.251343\n",
      "    epoch          : 4545\n",
      "    loss           : -1539.0655510681497\n",
      "Train Epoch: 4546 [512/60000 (1%)] Loss: -1618.848145\n",
      "Train Epoch: 4546 [11776/60000 (20%)] Loss: -1628.983887\n",
      "Train Epoch: 4546 [23040/60000 (38%)] Loss: -1618.651611\n",
      "Train Epoch: 4546 [34304/60000 (57%)] Loss: -1562.594727\n",
      "Train Epoch: 4546 [45568/60000 (76%)] Loss: -1526.291138\n",
      "Train Epoch: 4546 [56832/60000 (95%)] Loss: -1504.469360\n",
      "    epoch          : 4546\n",
      "    loss           : -1534.8145324362201\n",
      "Train Epoch: 4547 [512/60000 (1%)] Loss: -1579.081787\n",
      "Train Epoch: 4547 [11776/60000 (20%)] Loss: -1536.296997\n",
      "Train Epoch: 4547 [23040/60000 (38%)] Loss: -1564.791260\n",
      "Train Epoch: 4547 [34304/60000 (57%)] Loss: -1530.576660\n",
      "Train Epoch: 4547 [45568/60000 (76%)] Loss: -1538.660156\n",
      "Train Epoch: 4547 [56832/60000 (95%)] Loss: -1599.822876\n",
      "    epoch          : 4547\n",
      "    loss           : -1539.6609245343398\n",
      "Train Epoch: 4548 [512/60000 (1%)] Loss: -1480.946045\n",
      "Train Epoch: 4548 [11776/60000 (20%)] Loss: -1573.776978\n",
      "Train Epoch: 4548 [23040/60000 (38%)] Loss: -1504.358154\n",
      "Train Epoch: 4548 [34304/60000 (57%)] Loss: -1449.167236\n",
      "Train Epoch: 4548 [45568/60000 (76%)] Loss: -1530.422974\n",
      "Train Epoch: 4548 [56832/60000 (95%)] Loss: -1501.904419\n",
      "    epoch          : 4548\n",
      "    loss           : -1531.4410621082714\n",
      "Train Epoch: 4549 [512/60000 (1%)] Loss: -1526.655640\n",
      "Train Epoch: 4549 [11776/60000 (20%)] Loss: -1504.421631\n",
      "Train Epoch: 4549 [23040/60000 (38%)] Loss: -1543.340088\n",
      "Train Epoch: 4549 [34304/60000 (57%)] Loss: -1507.014404\n",
      "Train Epoch: 4549 [45568/60000 (76%)] Loss: -1530.489380\n",
      "Train Epoch: 4549 [56832/60000 (95%)] Loss: -1498.898682\n",
      "    epoch          : 4549\n",
      "    loss           : -1539.5863730220472\n",
      "Train Epoch: 4550 [512/60000 (1%)] Loss: -1530.520874\n",
      "Train Epoch: 4550 [11776/60000 (20%)] Loss: -1543.075073\n",
      "Train Epoch: 4550 [23040/60000 (38%)] Loss: -1607.305054\n",
      "Train Epoch: 4550 [34304/60000 (57%)] Loss: -1566.939697\n",
      "Train Epoch: 4550 [45568/60000 (76%)] Loss: -1427.103882\n",
      "Train Epoch: 4550 [56832/60000 (95%)] Loss: -1502.433228\n",
      "    epoch          : 4550\n",
      "    loss           : -1535.6673018460892\n",
      "Train Epoch: 4551 [512/60000 (1%)] Loss: -1544.620850\n",
      "Train Epoch: 4551 [11776/60000 (20%)] Loss: -1536.614258\n",
      "Train Epoch: 4551 [23040/60000 (38%)] Loss: -1544.973389\n",
      "Train Epoch: 4551 [34304/60000 (57%)] Loss: -1591.750000\n",
      "Train Epoch: 4551 [45568/60000 (76%)] Loss: -1502.978027\n",
      "Train Epoch: 4551 [56832/60000 (95%)] Loss: -1500.784180\n",
      "    epoch          : 4551\n",
      "    loss           : -1540.847788320423\n",
      "Train Epoch: 4552 [512/60000 (1%)] Loss: -1468.621948\n",
      "Train Epoch: 4552 [11776/60000 (20%)] Loss: -1482.704590\n",
      "Train Epoch: 4552 [23040/60000 (38%)] Loss: -1580.867920\n",
      "Train Epoch: 4552 [34304/60000 (57%)] Loss: -1606.335205\n",
      "Train Epoch: 4552 [45568/60000 (76%)] Loss: -1482.816650\n",
      "Train Epoch: 4552 [56832/60000 (95%)] Loss: -1544.756592\n",
      "    epoch          : 4552\n",
      "    loss           : -1539.4766662942486\n",
      "Train Epoch: 4553 [512/60000 (1%)] Loss: -1485.077881\n",
      "Train Epoch: 4553 [11776/60000 (20%)] Loss: -1609.928711\n",
      "Train Epoch: 4553 [23040/60000 (38%)] Loss: -1418.654297\n",
      "Train Epoch: 4553 [34304/60000 (57%)] Loss: -1563.237549\n",
      "Train Epoch: 4553 [45568/60000 (76%)] Loss: -1570.862305\n",
      "Train Epoch: 4553 [56832/60000 (95%)] Loss: -1543.670044\n",
      "    epoch          : 4553\n",
      "    loss           : -1539.6749119300628\n",
      "Train Epoch: 4554 [512/60000 (1%)] Loss: -1523.935181\n",
      "Train Epoch: 4554 [11776/60000 (20%)] Loss: -1570.672607\n",
      "Train Epoch: 4554 [23040/60000 (38%)] Loss: -1607.965820\n",
      "Train Epoch: 4554 [34304/60000 (57%)] Loss: -1583.119629\n",
      "Train Epoch: 4554 [45568/60000 (76%)] Loss: -1602.441772\n",
      "Train Epoch: 4554 [56832/60000 (95%)] Loss: -1555.357422\n",
      "    epoch          : 4554\n",
      "    loss           : -1534.8640933279264\n",
      "Train Epoch: 4555 [512/60000 (1%)] Loss: -1582.562378\n",
      "Train Epoch: 4555 [11776/60000 (20%)] Loss: -1565.301758\n",
      "Train Epoch: 4555 [23040/60000 (38%)] Loss: -1511.049072\n",
      "Train Epoch: 4555 [34304/60000 (57%)] Loss: -1487.922607\n",
      "Train Epoch: 4555 [45568/60000 (76%)] Loss: -1454.848389\n",
      "Train Epoch: 4555 [56832/60000 (95%)] Loss: -1515.063965\n",
      "    epoch          : 4555\n",
      "    loss           : -1535.8451034632105\n",
      "Train Epoch: 4556 [512/60000 (1%)] Loss: -1594.921143\n",
      "Train Epoch: 4556 [11776/60000 (20%)] Loss: -1580.411011\n",
      "Train Epoch: 4556 [23040/60000 (38%)] Loss: -1511.329102\n",
      "Train Epoch: 4556 [34304/60000 (57%)] Loss: -1489.297119\n",
      "Train Epoch: 4556 [45568/60000 (76%)] Loss: -1511.457520\n",
      "Train Epoch: 4556 [56832/60000 (95%)] Loss: -1458.567261\n",
      "    epoch          : 4556\n",
      "    loss           : -1536.5183046847412\n",
      "Train Epoch: 4557 [512/60000 (1%)] Loss: -1445.108398\n",
      "Train Epoch: 4557 [11776/60000 (20%)] Loss: -1589.163818\n",
      "Train Epoch: 4557 [23040/60000 (38%)] Loss: -1535.896484\n",
      "Train Epoch: 4557 [34304/60000 (57%)] Loss: -1586.803589\n",
      "Train Epoch: 4557 [45568/60000 (76%)] Loss: -1446.386475\n",
      "Train Epoch: 4557 [56832/60000 (95%)] Loss: -1568.441650\n",
      "    epoch          : 4557\n",
      "    loss           : -1535.6078160172801\n",
      "Train Epoch: 4558 [512/60000 (1%)] Loss: -1502.340576\n",
      "Train Epoch: 4558 [11776/60000 (20%)] Loss: -1608.378418\n",
      "Train Epoch: 4558 [23040/60000 (38%)] Loss: -1442.405762\n",
      "Train Epoch: 4558 [34304/60000 (57%)] Loss: -1566.250977\n",
      "Train Epoch: 4558 [45568/60000 (76%)] Loss: -1570.173828\n",
      "Train Epoch: 4558 [56832/60000 (95%)] Loss: -1572.116211\n",
      "    epoch          : 4558\n",
      "    loss           : -1534.6001307600636\n",
      "Train Epoch: 4559 [512/60000 (1%)] Loss: -1513.169678\n",
      "Train Epoch: 4559 [11776/60000 (20%)] Loss: -1537.800171\n",
      "Train Epoch: 4559 [23040/60000 (38%)] Loss: -1515.686401\n",
      "Train Epoch: 4559 [34304/60000 (57%)] Loss: -1554.293213\n",
      "Train Epoch: 4559 [45568/60000 (76%)] Loss: -1548.200073\n",
      "Train Epoch: 4559 [56832/60000 (95%)] Loss: -1582.739746\n",
      "    epoch          : 4559\n",
      "    loss           : -1540.9162997660665\n",
      "Train Epoch: 4560 [512/60000 (1%)] Loss: -1483.167358\n",
      "Train Epoch: 4560 [11776/60000 (20%)] Loss: -1532.747070\n",
      "Train Epoch: 4560 [23040/60000 (38%)] Loss: -1532.014771\n",
      "Train Epoch: 4560 [34304/60000 (57%)] Loss: -1559.489624\n",
      "Train Epoch: 4560 [45568/60000 (76%)] Loss: -1552.291992\n",
      "Train Epoch: 4560 [56832/60000 (95%)] Loss: -1504.437500\n",
      "    epoch          : 4560\n",
      "    loss           : -1536.7317322122174\n",
      "Train Epoch: 4561 [512/60000 (1%)] Loss: -1525.668823\n",
      "Train Epoch: 4561 [11776/60000 (20%)] Loss: -1512.224609\n",
      "Train Epoch: 4561 [23040/60000 (38%)] Loss: -1562.333984\n",
      "Train Epoch: 4561 [34304/60000 (57%)] Loss: -1498.441162\n",
      "Train Epoch: 4561 [45568/60000 (76%)] Loss: -1524.190674\n",
      "Train Epoch: 4561 [56832/60000 (95%)] Loss: -1531.606934\n",
      "    epoch          : 4561\n",
      "    loss           : -1541.5710945775954\n",
      "Train Epoch: 4562 [512/60000 (1%)] Loss: -1546.405640\n",
      "Train Epoch: 4562 [11776/60000 (20%)] Loss: -1554.814453\n",
      "Train Epoch: 4562 [23040/60000 (38%)] Loss: -1543.184326\n",
      "Train Epoch: 4562 [34304/60000 (57%)] Loss: -1478.814575\n",
      "Train Epoch: 4562 [45568/60000 (76%)] Loss: -1517.499268\n",
      "Train Epoch: 4562 [56832/60000 (95%)] Loss: -1532.098633\n",
      "    epoch          : 4562\n",
      "    loss           : -1533.3597419006003\n",
      "Train Epoch: 4563 [512/60000 (1%)] Loss: -1508.033936\n",
      "Train Epoch: 4563 [11776/60000 (20%)] Loss: -1511.185547\n",
      "Train Epoch: 4563 [23040/60000 (38%)] Loss: -1610.067871\n",
      "Train Epoch: 4563 [34304/60000 (57%)] Loss: -1513.378174\n",
      "Train Epoch: 4563 [45568/60000 (76%)] Loss: -1594.454468\n",
      "Train Epoch: 4563 [56832/60000 (95%)] Loss: -1593.276245\n",
      "    epoch          : 4563\n",
      "    loss           : -1539.8237008132503\n",
      "Train Epoch: 4564 [512/60000 (1%)] Loss: -1517.481445\n",
      "Train Epoch: 4564 [11776/60000 (20%)] Loss: -1579.732422\n",
      "Train Epoch: 4564 [23040/60000 (38%)] Loss: -1569.072754\n",
      "Train Epoch: 4564 [34304/60000 (57%)] Loss: -1580.885742\n",
      "Train Epoch: 4564 [45568/60000 (76%)] Loss: -1539.902710\n",
      "Train Epoch: 4564 [56832/60000 (95%)] Loss: -1561.468506\n",
      "    epoch          : 4564\n",
      "    loss           : -1544.8891367077154\n",
      "Train Epoch: 4565 [512/60000 (1%)] Loss: -1531.276489\n",
      "Train Epoch: 4565 [11776/60000 (20%)] Loss: -1552.503174\n",
      "Train Epoch: 4565 [23040/60000 (38%)] Loss: -1529.938354\n",
      "Train Epoch: 4565 [34304/60000 (57%)] Loss: -1586.523193\n",
      "Train Epoch: 4565 [45568/60000 (76%)] Loss: -1549.459961\n",
      "Train Epoch: 4565 [56832/60000 (95%)] Loss: -1559.093018\n",
      "    epoch          : 4565\n",
      "    loss           : -1537.7536831440898\n",
      "Train Epoch: 4566 [512/60000 (1%)] Loss: -1535.070312\n",
      "Train Epoch: 4566 [11776/60000 (20%)] Loss: -1569.250854\n",
      "Train Epoch: 4566 [23040/60000 (38%)] Loss: -1493.629761\n",
      "Train Epoch: 4566 [34304/60000 (57%)] Loss: -1589.146851\n",
      "Train Epoch: 4566 [45568/60000 (76%)] Loss: -1541.605835\n",
      "Train Epoch: 4566 [56832/60000 (95%)] Loss: -1447.981445\n",
      "    epoch          : 4566\n",
      "    loss           : -1536.360680186816\n",
      "Train Epoch: 4567 [512/60000 (1%)] Loss: -1615.502930\n",
      "Train Epoch: 4567 [11776/60000 (20%)] Loss: -1556.175171\n",
      "Train Epoch: 4567 [23040/60000 (38%)] Loss: -1513.987305\n",
      "Train Epoch: 4567 [34304/60000 (57%)] Loss: -1554.344360\n",
      "Train Epoch: 4567 [45568/60000 (76%)] Loss: -1512.800171\n",
      "Train Epoch: 4567 [56832/60000 (95%)] Loss: -1580.989136\n",
      "    epoch          : 4567\n",
      "    loss           : -1540.1504323495983\n",
      "Train Epoch: 4568 [512/60000 (1%)] Loss: -1510.618896\n",
      "Train Epoch: 4568 [11776/60000 (20%)] Loss: -1545.242554\n",
      "Train Epoch: 4568 [23040/60000 (38%)] Loss: -1638.790771\n",
      "Train Epoch: 4568 [34304/60000 (57%)] Loss: -1531.092773\n",
      "Train Epoch: 4568 [45568/60000 (76%)] Loss: -1540.257202\n",
      "Train Epoch: 4568 [56832/60000 (95%)] Loss: -1582.818481\n",
      "    epoch          : 4568\n",
      "    loss           : -1540.4296950862906\n",
      "Train Epoch: 4569 [512/60000 (1%)] Loss: -1609.602905\n",
      "Train Epoch: 4569 [11776/60000 (20%)] Loss: -1545.920898\n",
      "Train Epoch: 4569 [23040/60000 (38%)] Loss: -1502.011963\n",
      "Train Epoch: 4569 [34304/60000 (57%)] Loss: -1522.701416\n",
      "Train Epoch: 4569 [45568/60000 (76%)] Loss: -1592.092529\n",
      "Train Epoch: 4569 [56832/60000 (95%)] Loss: -1526.225220\n",
      "    epoch          : 4569\n",
      "    loss           : -1541.3019250557247\n",
      "Train Epoch: 4570 [512/60000 (1%)] Loss: -1461.394897\n",
      "Train Epoch: 4570 [11776/60000 (20%)] Loss: -1579.623535\n",
      "Train Epoch: 4570 [23040/60000 (38%)] Loss: -1570.716309\n",
      "Train Epoch: 4570 [34304/60000 (57%)] Loss: -1470.920898\n",
      "Train Epoch: 4570 [45568/60000 (76%)] Loss: -1548.445068\n",
      "Train Epoch: 4570 [56832/60000 (95%)] Loss: -1502.186401\n",
      "    epoch          : 4570\n",
      "    loss           : -1540.1288403872043\n",
      "Train Epoch: 4571 [512/60000 (1%)] Loss: -1500.983765\n",
      "Train Epoch: 4571 [11776/60000 (20%)] Loss: -1490.129761\n",
      "Train Epoch: 4571 [23040/60000 (38%)] Loss: -1572.601440\n",
      "Train Epoch: 4571 [34304/60000 (57%)] Loss: -1489.264648\n",
      "Train Epoch: 4571 [45568/60000 (76%)] Loss: -1532.761475\n",
      "Train Epoch: 4571 [56832/60000 (95%)] Loss: -1465.765625\n",
      "    epoch          : 4571\n",
      "    loss           : -1533.3541418388065\n",
      "Train Epoch: 4572 [512/60000 (1%)] Loss: -1591.384033\n",
      "Train Epoch: 4572 [11776/60000 (20%)] Loss: -1490.829346\n",
      "Train Epoch: 4572 [23040/60000 (38%)] Loss: -1502.328369\n",
      "Train Epoch: 4572 [34304/60000 (57%)] Loss: -1601.405273\n",
      "Train Epoch: 4572 [45568/60000 (76%)] Loss: -1571.334961\n",
      "Train Epoch: 4572 [56832/60000 (95%)] Loss: -1593.144653\n",
      "    epoch          : 4572\n",
      "    loss           : -1542.2711460954051\n",
      "Train Epoch: 4573 [512/60000 (1%)] Loss: -1575.941040\n",
      "Train Epoch: 4573 [11776/60000 (20%)] Loss: -1560.412598\n",
      "Train Epoch: 4573 [23040/60000 (38%)] Loss: -1523.146973\n",
      "Train Epoch: 4573 [34304/60000 (57%)] Loss: -1508.368164\n",
      "Train Epoch: 4573 [45568/60000 (76%)] Loss: -1565.842529\n",
      "Train Epoch: 4573 [56832/60000 (95%)] Loss: -1510.299561\n",
      "    epoch          : 4573\n",
      "    loss           : -1538.0924196404926\n",
      "Train Epoch: 4574 [512/60000 (1%)] Loss: -1585.076904\n",
      "Train Epoch: 4574 [11776/60000 (20%)] Loss: -1536.734619\n",
      "Train Epoch: 4574 [23040/60000 (38%)] Loss: -1549.588379\n",
      "Train Epoch: 4574 [34304/60000 (57%)] Loss: -1467.553955\n",
      "Train Epoch: 4574 [45568/60000 (76%)] Loss: -1570.566895\n",
      "Train Epoch: 4574 [56832/60000 (95%)] Loss: -1577.545898\n",
      "    epoch          : 4574\n",
      "    loss           : -1539.4095776229256\n",
      "Train Epoch: 4575 [512/60000 (1%)] Loss: -1603.019409\n",
      "Train Epoch: 4575 [11776/60000 (20%)] Loss: -1524.333496\n",
      "Train Epoch: 4575 [23040/60000 (38%)] Loss: -1555.369263\n",
      "Train Epoch: 4575 [34304/60000 (57%)] Loss: -1601.088379\n",
      "Train Epoch: 4575 [45568/60000 (76%)] Loss: -1488.963867\n",
      "Train Epoch: 4575 [56832/60000 (95%)] Loss: -1573.672852\n",
      "    epoch          : 4575\n",
      "    loss           : -1536.715580654683\n",
      "Train Epoch: 4576 [512/60000 (1%)] Loss: -1577.895630\n",
      "Train Epoch: 4576 [11776/60000 (20%)] Loss: -1526.445068\n",
      "Train Epoch: 4576 [23040/60000 (38%)] Loss: -1489.826538\n",
      "Train Epoch: 4576 [34304/60000 (57%)] Loss: -1533.293213\n",
      "Train Epoch: 4576 [45568/60000 (76%)] Loss: -1571.188843\n",
      "Train Epoch: 4576 [56832/60000 (95%)] Loss: -1556.610840\n",
      "    epoch          : 4576\n",
      "    loss           : -1530.1055973721088\n",
      "Train Epoch: 4577 [512/60000 (1%)] Loss: -1540.895996\n",
      "Train Epoch: 4577 [11776/60000 (20%)] Loss: -1525.414185\n",
      "Train Epoch: 4577 [23040/60000 (38%)] Loss: -1446.611450\n",
      "Train Epoch: 4577 [34304/60000 (57%)] Loss: -1480.736938\n",
      "Train Epoch: 4577 [45568/60000 (76%)] Loss: -1570.559082\n",
      "Train Epoch: 4577 [56832/60000 (95%)] Loss: -1528.256348\n",
      "    epoch          : 4577\n",
      "    loss           : -1537.5775977528026\n",
      "Train Epoch: 4578 [512/60000 (1%)] Loss: -1565.136230\n",
      "Train Epoch: 4578 [11776/60000 (20%)] Loss: -1552.400146\n",
      "Train Epoch: 4578 [23040/60000 (38%)] Loss: -1534.023560\n",
      "Train Epoch: 4578 [34304/60000 (57%)] Loss: -1513.664673\n",
      "Train Epoch: 4578 [45568/60000 (76%)] Loss: -1556.281250\n",
      "Train Epoch: 4578 [56832/60000 (95%)] Loss: -1504.991699\n",
      "    epoch          : 4578\n",
      "    loss           : -1534.1306766143625\n",
      "Train Epoch: 4579 [512/60000 (1%)] Loss: -1545.727051\n",
      "Train Epoch: 4579 [11776/60000 (20%)] Loss: -1511.278564\n",
      "Train Epoch: 4579 [23040/60000 (38%)] Loss: -1563.510376\n",
      "Train Epoch: 4579 [34304/60000 (57%)] Loss: -1507.324463\n",
      "Train Epoch: 4579 [45568/60000 (76%)] Loss: -1556.701294\n",
      "Train Epoch: 4579 [56832/60000 (95%)] Loss: -1514.483643\n",
      "    epoch          : 4579\n",
      "    loss           : -1543.4838125800009\n",
      "Train Epoch: 4580 [512/60000 (1%)] Loss: -1503.126587\n",
      "Train Epoch: 4580 [11776/60000 (20%)] Loss: -1475.538452\n",
      "Train Epoch: 4580 [23040/60000 (38%)] Loss: -1603.362793\n",
      "Train Epoch: 4580 [34304/60000 (57%)] Loss: -1476.429321\n",
      "Train Epoch: 4580 [45568/60000 (76%)] Loss: -1623.381592\n",
      "Train Epoch: 4580 [56832/60000 (95%)] Loss: -1508.324585\n",
      "    epoch          : 4580\n",
      "    loss           : -1533.9892071222855\n",
      "Train Epoch: 4581 [512/60000 (1%)] Loss: -1622.753540\n",
      "Train Epoch: 4581 [11776/60000 (20%)] Loss: -1519.501465\n",
      "Train Epoch: 4581 [23040/60000 (38%)] Loss: -1555.052734\n",
      "Train Epoch: 4581 [34304/60000 (57%)] Loss: -1563.778198\n",
      "Train Epoch: 4581 [45568/60000 (76%)] Loss: -1608.995361\n",
      "Train Epoch: 4581 [56832/60000 (95%)] Loss: -1500.321289\n",
      "    epoch          : 4581\n",
      "    loss           : -1548.7613932291665\n",
      "Train Epoch: 4582 [512/60000 (1%)] Loss: -1557.630737\n",
      "Train Epoch: 4582 [11776/60000 (20%)] Loss: -1510.547852\n",
      "Train Epoch: 4582 [23040/60000 (38%)] Loss: -1547.434326\n",
      "Train Epoch: 4582 [34304/60000 (57%)] Loss: -1562.154785\n",
      "Train Epoch: 4582 [45568/60000 (76%)] Loss: -1561.242432\n",
      "Train Epoch: 4582 [56832/60000 (95%)] Loss: -1524.416016\n",
      "    epoch          : 4582\n",
      "    loss           : -1540.0103349416268\n",
      "Train Epoch: 4583 [512/60000 (1%)] Loss: -1574.887695\n",
      "Train Epoch: 4583 [11776/60000 (20%)] Loss: -1471.383545\n",
      "Train Epoch: 4583 [23040/60000 (38%)] Loss: -1556.285156\n",
      "Train Epoch: 4583 [34304/60000 (57%)] Loss: -1511.648438\n",
      "Train Epoch: 4583 [45568/60000 (76%)] Loss: -1559.837769\n",
      "Train Epoch: 4583 [56832/60000 (95%)] Loss: -1557.881470\n",
      "    epoch          : 4583\n",
      "    loss           : -1535.7706891938117\n",
      "Train Epoch: 4584 [512/60000 (1%)] Loss: -1533.276245\n",
      "Train Epoch: 4584 [11776/60000 (20%)] Loss: -1499.830933\n",
      "Train Epoch: 4584 [23040/60000 (38%)] Loss: -1438.652710\n",
      "Train Epoch: 4584 [34304/60000 (57%)] Loss: -1536.204834\n",
      "Train Epoch: 4584 [45568/60000 (76%)] Loss: -1613.196289\n",
      "Train Epoch: 4584 [56832/60000 (95%)] Loss: -1529.120972\n",
      "    epoch          : 4584\n",
      "    loss           : -1544.1422077760858\n",
      "Train Epoch: 4585 [512/60000 (1%)] Loss: -1523.595215\n",
      "Train Epoch: 4585 [11776/60000 (20%)] Loss: -1544.985474\n",
      "Train Epoch: 4585 [23040/60000 (38%)] Loss: -1572.721924\n",
      "Train Epoch: 4585 [34304/60000 (57%)] Loss: -1428.402222\n",
      "Train Epoch: 4585 [45568/60000 (76%)] Loss: -1485.795410\n",
      "Train Epoch: 4585 [56832/60000 (95%)] Loss: -1525.517944\n",
      "    epoch          : 4585\n",
      "    loss           : -1534.637384964248\n",
      "Train Epoch: 4586 [512/60000 (1%)] Loss: -1459.854492\n",
      "Train Epoch: 4586 [11776/60000 (20%)] Loss: -1557.450806\n",
      "Train Epoch: 4586 [23040/60000 (38%)] Loss: -1535.133301\n",
      "Train Epoch: 4586 [34304/60000 (57%)] Loss: -1556.283691\n",
      "Train Epoch: 4586 [45568/60000 (76%)] Loss: -1616.353516\n",
      "Train Epoch: 4586 [56832/60000 (95%)] Loss: -1503.079224\n",
      "    epoch          : 4586\n",
      "    loss           : -1545.7921263269113\n",
      "Train Epoch: 4587 [512/60000 (1%)] Loss: -1558.652588\n",
      "Train Epoch: 4587 [11776/60000 (20%)] Loss: -1487.530151\n",
      "Train Epoch: 4587 [23040/60000 (38%)] Loss: -1565.017578\n",
      "Train Epoch: 4587 [34304/60000 (57%)] Loss: -1498.215332\n",
      "Train Epoch: 4587 [45568/60000 (76%)] Loss: -1538.376709\n",
      "Train Epoch: 4587 [56832/60000 (95%)] Loss: -1594.787964\n",
      "    epoch          : 4587\n",
      "    loss           : -1542.9588843738964\n",
      "Train Epoch: 4588 [512/60000 (1%)] Loss: -1534.024658\n",
      "Train Epoch: 4588 [11776/60000 (20%)] Loss: -1505.286255\n",
      "Train Epoch: 4588 [23040/60000 (38%)] Loss: -1543.699219\n",
      "Train Epoch: 4588 [34304/60000 (57%)] Loss: -1575.453613\n",
      "Train Epoch: 4588 [45568/60000 (76%)] Loss: -1515.554443\n",
      "Train Epoch: 4588 [56832/60000 (95%)] Loss: -1530.856689\n",
      "    epoch          : 4588\n",
      "    loss           : -1538.247258935271\n",
      "Train Epoch: 4589 [512/60000 (1%)] Loss: -1527.873047\n",
      "Train Epoch: 4589 [11776/60000 (20%)] Loss: -1559.514893\n",
      "Train Epoch: 4589 [23040/60000 (38%)] Loss: -1541.220093\n",
      "Train Epoch: 4589 [34304/60000 (57%)] Loss: -1462.418701\n",
      "Train Epoch: 4589 [45568/60000 (76%)] Loss: -1522.660400\n",
      "Train Epoch: 4589 [56832/60000 (95%)] Loss: -1456.975342\n",
      "    epoch          : 4589\n",
      "    loss           : -1535.633203883629\n",
      "Train Epoch: 4590 [512/60000 (1%)] Loss: -1549.970459\n",
      "Train Epoch: 4590 [11776/60000 (20%)] Loss: -1552.818359\n",
      "Train Epoch: 4590 [23040/60000 (38%)] Loss: -1560.554443\n",
      "Train Epoch: 4590 [34304/60000 (57%)] Loss: -1592.398682\n",
      "Train Epoch: 4590 [45568/60000 (76%)] Loss: -1622.540527\n",
      "Train Epoch: 4590 [56832/60000 (95%)] Loss: -1606.814941\n",
      "    epoch          : 4590\n",
      "    loss           : -1542.4767228465969\n",
      "Train Epoch: 4591 [512/60000 (1%)] Loss: -1500.777588\n",
      "Train Epoch: 4591 [11776/60000 (20%)] Loss: -1563.114502\n",
      "Train Epoch: 4591 [23040/60000 (38%)] Loss: -1548.704224\n",
      "Train Epoch: 4591 [34304/60000 (57%)] Loss: -1616.315186\n",
      "Train Epoch: 4591 [45568/60000 (76%)] Loss: -1531.415405\n",
      "Train Epoch: 4591 [56832/60000 (95%)] Loss: -1469.332642\n",
      "    epoch          : 4591\n",
      "    loss           : -1534.0110046041889\n",
      "Train Epoch: 4592 [512/60000 (1%)] Loss: -1582.682739\n",
      "Train Epoch: 4592 [11776/60000 (20%)] Loss: -1569.199951\n",
      "Train Epoch: 4592 [23040/60000 (38%)] Loss: -1597.626221\n",
      "Train Epoch: 4592 [34304/60000 (57%)] Loss: -1559.009033\n",
      "Train Epoch: 4592 [45568/60000 (76%)] Loss: -1535.052002\n",
      "Train Epoch: 4592 [56832/60000 (95%)] Loss: -1462.622314\n",
      "    epoch          : 4592\n",
      "    loss           : -1543.9752797272247\n",
      "Train Epoch: 4593 [512/60000 (1%)] Loss: -1568.611572\n",
      "Train Epoch: 4593 [11776/60000 (20%)] Loss: -1569.593384\n",
      "Train Epoch: 4593 [23040/60000 (38%)] Loss: -1460.760986\n",
      "Train Epoch: 4593 [34304/60000 (57%)] Loss: -1565.060059\n",
      "Train Epoch: 4593 [45568/60000 (76%)] Loss: -1449.134033\n",
      "Train Epoch: 4593 [56832/60000 (95%)] Loss: -1494.404419\n",
      "    epoch          : 4593\n",
      "    loss           : -1541.051729536326\n",
      "Train Epoch: 4594 [512/60000 (1%)] Loss: -1477.593750\n",
      "Train Epoch: 4594 [11776/60000 (20%)] Loss: -1611.332764\n",
      "Train Epoch: 4594 [23040/60000 (38%)] Loss: -1453.585693\n",
      "Train Epoch: 4594 [34304/60000 (57%)] Loss: -1583.029663\n",
      "Train Epoch: 4594 [45568/60000 (76%)] Loss: -1525.706055\n",
      "Train Epoch: 4594 [56832/60000 (95%)] Loss: -1555.354004\n",
      "    epoch          : 4594\n",
      "    loss           : -1538.4150263037386\n",
      "Train Epoch: 4595 [512/60000 (1%)] Loss: -1416.846313\n",
      "Train Epoch: 4595 [11776/60000 (20%)] Loss: -1560.576050\n",
      "Train Epoch: 4595 [23040/60000 (38%)] Loss: -1580.417847\n",
      "Train Epoch: 4595 [34304/60000 (57%)] Loss: -1602.186035\n",
      "Train Epoch: 4595 [45568/60000 (76%)] Loss: -1497.661621\n",
      "Train Epoch: 4595 [56832/60000 (95%)] Loss: -1498.105225\n",
      "    epoch          : 4595\n",
      "    loss           : -1546.0266902945134\n",
      "Train Epoch: 4596 [512/60000 (1%)] Loss: -1622.122192\n",
      "Train Epoch: 4596 [11776/60000 (20%)] Loss: -1539.931641\n",
      "Train Epoch: 4596 [23040/60000 (38%)] Loss: -1614.268677\n",
      "Train Epoch: 4596 [34304/60000 (57%)] Loss: -1517.890991\n",
      "Train Epoch: 4596 [45568/60000 (76%)] Loss: -1527.033203\n",
      "Train Epoch: 4596 [56832/60000 (95%)] Loss: -1508.123291\n",
      "    epoch          : 4596\n",
      "    loss           : -1536.9301464705818\n",
      "Train Epoch: 4597 [512/60000 (1%)] Loss: -1570.263428\n",
      "Train Epoch: 4597 [11776/60000 (20%)] Loss: -1580.864746\n",
      "Train Epoch: 4597 [23040/60000 (38%)] Loss: -1599.432983\n",
      "Train Epoch: 4597 [34304/60000 (57%)] Loss: -1553.745605\n",
      "Train Epoch: 4597 [45568/60000 (76%)] Loss: -1519.759888\n",
      "Train Epoch: 4597 [56832/60000 (95%)] Loss: -1597.615234\n",
      "    epoch          : 4597\n",
      "    loss           : -1542.6392011911857\n",
      "Train Epoch: 4598 [512/60000 (1%)] Loss: -1605.770264\n",
      "Train Epoch: 4598 [11776/60000 (20%)] Loss: -1471.635986\n",
      "Train Epoch: 4598 [23040/60000 (38%)] Loss: -1610.267578\n",
      "Train Epoch: 4598 [34304/60000 (57%)] Loss: -1591.969971\n",
      "Train Epoch: 4598 [45568/60000 (76%)] Loss: -1562.099365\n",
      "Train Epoch: 4598 [56832/60000 (95%)] Loss: -1520.765625\n",
      "    epoch          : 4598\n",
      "    loss           : -1540.6801219875529\n",
      "Train Epoch: 4599 [512/60000 (1%)] Loss: -1499.183105\n",
      "Train Epoch: 4599 [11776/60000 (20%)] Loss: -1587.736084\n",
      "Train Epoch: 4599 [23040/60000 (38%)] Loss: -1526.516602\n",
      "Train Epoch: 4599 [34304/60000 (57%)] Loss: -1562.495117\n",
      "Train Epoch: 4599 [45568/60000 (76%)] Loss: -1497.341797\n",
      "Train Epoch: 4599 [56832/60000 (95%)] Loss: -1594.391357\n",
      "    epoch          : 4599\n",
      "    loss           : -1539.8191000728284\n",
      "Train Epoch: 4600 [512/60000 (1%)] Loss: -1544.280151\n",
      "Train Epoch: 4600 [11776/60000 (20%)] Loss: -1548.877563\n",
      "Train Epoch: 4600 [23040/60000 (38%)] Loss: -1587.144043\n",
      "Train Epoch: 4600 [34304/60000 (57%)] Loss: -1559.975830\n",
      "Train Epoch: 4600 [45568/60000 (76%)] Loss: -1576.233887\n",
      "Train Epoch: 4600 [56832/60000 (95%)] Loss: -1503.978394\n",
      "    epoch          : 4600\n",
      "    loss           : -1538.0829695362156\n",
      "Saving checkpoint: saved/models/Mnist_DeepGenerativeOperad/0127_111843/checkpoint-epoch4600.pth ...\n",
      "Train Epoch: 4601 [512/60000 (1%)] Loss: -1520.535889\n",
      "Train Epoch: 4601 [11776/60000 (20%)] Loss: -1513.242554\n",
      "Train Epoch: 4601 [23040/60000 (38%)] Loss: -1525.640381\n",
      "Train Epoch: 4601 [34304/60000 (57%)] Loss: -1530.957153\n",
      "Train Epoch: 4601 [45568/60000 (76%)] Loss: -1539.643799\n",
      "Train Epoch: 4601 [56832/60000 (95%)] Loss: -1592.648682\n",
      "    epoch          : 4601\n",
      "    loss           : -1540.5256520071946\n",
      "Train Epoch: 4602 [512/60000 (1%)] Loss: -1525.258057\n",
      "Train Epoch: 4602 [11776/60000 (20%)] Loss: -1529.858643\n",
      "Train Epoch: 4602 [23040/60000 (38%)] Loss: -1617.699463\n",
      "Train Epoch: 4602 [34304/60000 (57%)] Loss: -1488.912598\n",
      "Train Epoch: 4602 [45568/60000 (76%)] Loss: -1549.645264\n",
      "Train Epoch: 4602 [56832/60000 (95%)] Loss: -1631.539917\n",
      "    epoch          : 4602\n",
      "    loss           : -1537.1177571614585\n",
      "Train Epoch: 4603 [512/60000 (1%)] Loss: -1503.743896\n",
      "Train Epoch: 4603 [11776/60000 (20%)] Loss: -1548.593994\n",
      "Train Epoch: 4603 [23040/60000 (38%)] Loss: -1420.782104\n",
      "Train Epoch: 4603 [34304/60000 (57%)] Loss: -1550.733154\n",
      "Train Epoch: 4603 [45568/60000 (76%)] Loss: -1554.244873\n",
      "Train Epoch: 4603 [56832/60000 (95%)] Loss: -1527.549438\n",
      "    epoch          : 4603\n",
      "    loss           : -1533.3242349570755\n",
      "Train Epoch: 4604 [512/60000 (1%)] Loss: -1558.055176\n",
      "Train Epoch: 4604 [11776/60000 (20%)] Loss: -1499.779785\n",
      "Train Epoch: 4604 [23040/60000 (38%)] Loss: -1542.564209\n",
      "Train Epoch: 4604 [34304/60000 (57%)] Loss: -1537.159912\n",
      "Train Epoch: 4604 [45568/60000 (76%)] Loss: -1517.360107\n",
      "Train Epoch: 4604 [56832/60000 (95%)] Loss: -1540.342041\n",
      "    epoch          : 4604\n",
      "    loss           : -1535.990962314067\n",
      "Train Epoch: 4605 [512/60000 (1%)] Loss: -1433.105957\n",
      "Train Epoch: 4605 [11776/60000 (20%)] Loss: -1556.354980\n",
      "Train Epoch: 4605 [23040/60000 (38%)] Loss: -1562.169189\n",
      "Train Epoch: 4605 [34304/60000 (57%)] Loss: -1570.260254\n",
      "Train Epoch: 4605 [45568/60000 (76%)] Loss: -1554.162720\n",
      "Train Epoch: 4605 [56832/60000 (95%)] Loss: -1541.988281\n",
      "    epoch          : 4605\n",
      "    loss           : -1540.7294456352622\n",
      "Train Epoch: 4606 [512/60000 (1%)] Loss: -1552.925537\n",
      "Train Epoch: 4606 [11776/60000 (20%)] Loss: -1582.770264\n",
      "Train Epoch: 4606 [23040/60000 (38%)] Loss: -1590.062988\n",
      "Train Epoch: 4606 [34304/60000 (57%)] Loss: -1605.584717\n",
      "Train Epoch: 4606 [45568/60000 (76%)] Loss: -1560.967651\n",
      "Train Epoch: 4606 [56832/60000 (95%)] Loss: -1572.921631\n",
      "    epoch          : 4606\n",
      "    loss           : -1540.4153963078213\n",
      "Train Epoch: 4607 [512/60000 (1%)] Loss: -1423.427490\n",
      "Train Epoch: 4607 [11776/60000 (20%)] Loss: -1485.198486\n",
      "Train Epoch: 4607 [23040/60000 (38%)] Loss: -1560.451294\n",
      "Train Epoch: 4607 [34304/60000 (57%)] Loss: -1608.605469\n",
      "Train Epoch: 4607 [45568/60000 (76%)] Loss: -1547.877686\n",
      "Train Epoch: 4607 [56832/60000 (95%)] Loss: -1585.742432\n",
      "    epoch          : 4607\n",
      "    loss           : -1533.4800546074991\n",
      "Train Epoch: 4608 [512/60000 (1%)] Loss: -1535.002197\n",
      "Train Epoch: 4608 [11776/60000 (20%)] Loss: -1450.933472\n",
      "Train Epoch: 4608 [23040/60000 (38%)] Loss: -1542.502686\n",
      "Train Epoch: 4608 [34304/60000 (57%)] Loss: -1539.075317\n",
      "Train Epoch: 4608 [45568/60000 (76%)] Loss: -1589.663818\n",
      "Train Epoch: 4608 [56832/60000 (95%)] Loss: -1559.796997\n",
      "    epoch          : 4608\n",
      "    loss           : -1540.3857697740114\n",
      "Train Epoch: 4609 [512/60000 (1%)] Loss: -1563.949707\n",
      "Train Epoch: 4609 [11776/60000 (20%)] Loss: -1606.700562\n",
      "Train Epoch: 4609 [23040/60000 (38%)] Loss: -1468.974976\n",
      "Train Epoch: 4609 [34304/60000 (57%)] Loss: -1563.293457\n",
      "Train Epoch: 4609 [45568/60000 (76%)] Loss: -1588.129395\n",
      "Train Epoch: 4609 [56832/60000 (95%)] Loss: -1564.974731\n",
      "    epoch          : 4609\n",
      "    loss           : -1539.5589216846531\n",
      "Train Epoch: 4610 [512/60000 (1%)] Loss: -1499.543091\n",
      "Train Epoch: 4610 [11776/60000 (20%)] Loss: -1587.165527\n",
      "Train Epoch: 4610 [23040/60000 (38%)] Loss: -1552.588257\n",
      "Train Epoch: 4610 [34304/60000 (57%)] Loss: -1578.854004\n",
      "Train Epoch: 4610 [45568/60000 (76%)] Loss: -1548.487305\n",
      "Train Epoch: 4610 [56832/60000 (95%)] Loss: -1546.682617\n",
      "    epoch          : 4610\n",
      "    loss           : -1541.4325330486406\n",
      "Train Epoch: 4611 [512/60000 (1%)] Loss: -1520.293701\n",
      "Train Epoch: 4611 [11776/60000 (20%)] Loss: -1551.292480\n",
      "Train Epoch: 4611 [23040/60000 (38%)] Loss: -1537.853271\n",
      "Train Epoch: 4611 [34304/60000 (57%)] Loss: -1530.305054\n",
      "Train Epoch: 4611 [45568/60000 (76%)] Loss: -1602.839355\n",
      "Train Epoch: 4611 [56832/60000 (95%)] Loss: -1592.390015\n",
      "    epoch          : 4611\n",
      "    loss           : -1541.178263346354\n",
      "Train Epoch: 4612 [512/60000 (1%)] Loss: -1496.587646\n",
      "Train Epoch: 4612 [11776/60000 (20%)] Loss: -1491.908203\n",
      "Train Epoch: 4612 [23040/60000 (38%)] Loss: -1518.311646\n",
      "Train Epoch: 4612 [34304/60000 (57%)] Loss: -1535.714600\n",
      "Train Epoch: 4612 [45568/60000 (76%)] Loss: -1460.304199\n",
      "Train Epoch: 4612 [56832/60000 (95%)] Loss: -1516.437744\n",
      "    epoch          : 4612\n",
      "    loss           : -1537.5362848831435\n",
      "Train Epoch: 4613 [512/60000 (1%)] Loss: -1542.442505\n",
      "Train Epoch: 4613 [11776/60000 (20%)] Loss: -1564.248291\n",
      "Train Epoch: 4613 [23040/60000 (38%)] Loss: -1551.186157\n",
      "Train Epoch: 4613 [34304/60000 (57%)] Loss: -1507.572021\n",
      "Train Epoch: 4613 [45568/60000 (76%)] Loss: -1530.103271\n",
      "Train Epoch: 4613 [56832/60000 (95%)] Loss: -1525.303223\n",
      "    epoch          : 4613\n",
      "    loss           : -1542.0310268940898\n",
      "Train Epoch: 4614 [512/60000 (1%)] Loss: -1572.015869\n",
      "Train Epoch: 4614 [11776/60000 (20%)] Loss: -1504.331665\n",
      "Train Epoch: 4614 [23040/60000 (38%)] Loss: -1539.342773\n",
      "Train Epoch: 4614 [34304/60000 (57%)] Loss: -1580.582275\n",
      "Train Epoch: 4614 [45568/60000 (76%)] Loss: -1533.509644\n",
      "Train Epoch: 4614 [56832/60000 (95%)] Loss: -1493.785522\n",
      "    epoch          : 4614\n",
      "    loss           : -1543.824005299369\n",
      "Train Epoch: 4615 [512/60000 (1%)] Loss: -1621.816406\n",
      "Train Epoch: 4615 [11776/60000 (20%)] Loss: -1500.530396\n",
      "Train Epoch: 4615 [23040/60000 (38%)] Loss: -1589.332764\n",
      "Train Epoch: 4615 [34304/60000 (57%)] Loss: -1534.045410\n",
      "Train Epoch: 4615 [45568/60000 (76%)] Loss: -1519.510620\n",
      "Train Epoch: 4615 [56832/60000 (95%)] Loss: -1585.374512\n",
      "    epoch          : 4615\n",
      "    loss           : -1541.6132002146232\n",
      "Train Epoch: 4616 [512/60000 (1%)] Loss: -1521.034668\n",
      "Train Epoch: 4616 [11776/60000 (20%)] Loss: -1577.236816\n",
      "Train Epoch: 4616 [23040/60000 (38%)] Loss: -1575.098633\n",
      "Train Epoch: 4616 [34304/60000 (57%)] Loss: -1513.771973\n",
      "Train Epoch: 4616 [45568/60000 (76%)] Loss: -1560.091919\n",
      "Train Epoch: 4616 [56832/60000 (95%)] Loss: -1496.019287\n",
      "    epoch          : 4616\n",
      "    loss           : -1538.5806591658943\n",
      "Train Epoch: 4617 [512/60000 (1%)] Loss: -1593.896973\n",
      "Train Epoch: 4617 [11776/60000 (20%)] Loss: -1604.844360\n",
      "Train Epoch: 4617 [23040/60000 (38%)] Loss: -1503.656250\n",
      "Train Epoch: 4617 [34304/60000 (57%)] Loss: -1427.621216\n",
      "Train Epoch: 4617 [45568/60000 (76%)] Loss: -1454.582764\n",
      "Train Epoch: 4617 [56832/60000 (95%)] Loss: -1575.710938\n",
      "    epoch          : 4617\n",
      "    loss           : -1535.9047186037915\n",
      "Train Epoch: 4618 [512/60000 (1%)] Loss: -1562.521606\n",
      "Train Epoch: 4618 [11776/60000 (20%)] Loss: -1517.769043\n",
      "Train Epoch: 4618 [23040/60000 (38%)] Loss: -1485.671387\n",
      "Train Epoch: 4618 [34304/60000 (57%)] Loss: -1561.125122\n",
      "Train Epoch: 4618 [45568/60000 (76%)] Loss: -1560.974609\n",
      "Train Epoch: 4618 [56832/60000 (95%)] Loss: -1457.420898\n",
      "    epoch          : 4618\n",
      "    loss           : -1535.869896840241\n",
      "Train Epoch: 4619 [512/60000 (1%)] Loss: -1526.190796\n",
      "Train Epoch: 4619 [11776/60000 (20%)] Loss: -1600.395020\n",
      "Train Epoch: 4619 [23040/60000 (38%)] Loss: -1556.032349\n",
      "Train Epoch: 4619 [34304/60000 (57%)] Loss: -1515.026978\n",
      "Train Epoch: 4619 [45568/60000 (76%)] Loss: -1514.626953\n",
      "Train Epoch: 4619 [56832/60000 (95%)] Loss: -1516.327393\n",
      "    epoch          : 4619\n",
      "    loss           : -1541.1433639957406\n",
      "Train Epoch: 4620 [512/60000 (1%)] Loss: -1558.772339\n",
      "Train Epoch: 4620 [11776/60000 (20%)] Loss: -1503.386230\n",
      "Train Epoch: 4620 [23040/60000 (38%)] Loss: -1592.552246\n",
      "Train Epoch: 4620 [34304/60000 (57%)] Loss: -1556.878418\n",
      "Train Epoch: 4620 [45568/60000 (76%)] Loss: -1484.936035\n",
      "Train Epoch: 4620 [56832/60000 (95%)] Loss: -1570.638916\n",
      "    epoch          : 4620\n",
      "    loss           : -1544.0946175957804\n",
      "Train Epoch: 4621 [512/60000 (1%)] Loss: -1515.252441\n",
      "Train Epoch: 4621 [11776/60000 (20%)] Loss: -1597.053101\n",
      "Train Epoch: 4621 [23040/60000 (38%)] Loss: -1458.767334\n",
      "Train Epoch: 4621 [34304/60000 (57%)] Loss: -1567.910034\n",
      "Train Epoch: 4621 [45568/60000 (76%)] Loss: -1488.718750\n",
      "Train Epoch: 4621 [56832/60000 (95%)] Loss: -1533.926147\n",
      "    epoch          : 4621\n",
      "    loss           : -1541.8406454829847\n",
      "Train Epoch: 4622 [512/60000 (1%)] Loss: -1514.725098\n",
      "Train Epoch: 4622 [11776/60000 (20%)] Loss: -1519.042969\n",
      "Train Epoch: 4622 [23040/60000 (38%)] Loss: -1589.870117\n",
      "Train Epoch: 4622 [34304/60000 (57%)] Loss: -1617.783691\n",
      "Train Epoch: 4622 [45568/60000 (76%)] Loss: -1547.617188\n",
      "Train Epoch: 4622 [56832/60000 (95%)] Loss: -1530.177734\n",
      "    epoch          : 4622\n",
      "    loss           : -1546.8428434382724\n",
      "Train Epoch: 4623 [512/60000 (1%)] Loss: -1528.482666\n",
      "Train Epoch: 4623 [11776/60000 (20%)] Loss: -1576.663452\n",
      "Train Epoch: 4623 [23040/60000 (38%)] Loss: -1552.551880\n",
      "Train Epoch: 4623 [34304/60000 (57%)] Loss: -1566.722290\n",
      "Train Epoch: 4623 [45568/60000 (76%)] Loss: -1473.750244\n",
      "Train Epoch: 4623 [56832/60000 (95%)] Loss: -1490.475098\n",
      "    epoch          : 4623\n",
      "    loss           : -1542.9012882211116\n",
      "Train Epoch: 4624 [512/60000 (1%)] Loss: -1495.670898\n",
      "Train Epoch: 4624 [11776/60000 (20%)] Loss: -1541.082275\n",
      "Train Epoch: 4624 [23040/60000 (38%)] Loss: -1599.573120\n",
      "Train Epoch: 4624 [34304/60000 (57%)] Loss: -1479.352295\n",
      "Train Epoch: 4624 [45568/60000 (76%)] Loss: -1480.440308\n",
      "Train Epoch: 4624 [56832/60000 (95%)] Loss: -1512.172363\n",
      "    epoch          : 4624\n",
      "    loss           : -1539.5587985798463\n",
      "Train Epoch: 4625 [512/60000 (1%)] Loss: -1501.755127\n",
      "Train Epoch: 4625 [11776/60000 (20%)] Loss: -1558.119995\n",
      "Train Epoch: 4625 [23040/60000 (38%)] Loss: -1506.884033\n",
      "Train Epoch: 4625 [34304/60000 (57%)] Loss: -1565.078369\n",
      "Train Epoch: 4625 [45568/60000 (76%)] Loss: -1581.203369\n",
      "Train Epoch: 4625 [56832/60000 (95%)] Loss: -1537.217773\n",
      "    epoch          : 4625\n",
      "    loss           : -1540.2010684255827\n",
      "Train Epoch: 4626 [512/60000 (1%)] Loss: -1582.711914\n",
      "Train Epoch: 4626 [11776/60000 (20%)] Loss: -1565.441772\n",
      "Train Epoch: 4626 [23040/60000 (38%)] Loss: -1484.024048\n",
      "Train Epoch: 4626 [34304/60000 (57%)] Loss: -1549.231201\n",
      "Train Epoch: 4626 [45568/60000 (76%)] Loss: -1574.465820\n",
      "Train Epoch: 4626 [56832/60000 (95%)] Loss: -1549.730835\n",
      "    epoch          : 4626\n",
      "    loss           : -1543.5096842447915\n",
      "Train Epoch: 4627 [512/60000 (1%)] Loss: -1590.897217\n",
      "Train Epoch: 4627 [11776/60000 (20%)] Loss: -1547.933594\n",
      "Train Epoch: 4627 [23040/60000 (38%)] Loss: -1551.866089\n",
      "Train Epoch: 4627 [34304/60000 (57%)] Loss: -1614.664062\n",
      "Train Epoch: 4627 [45568/60000 (76%)] Loss: -1525.968506\n",
      "Train Epoch: 4627 [56832/60000 (95%)] Loss: -1490.050415\n",
      "    epoch          : 4627\n",
      "    loss           : -1539.9770142291227\n",
      "Train Epoch: 4628 [512/60000 (1%)] Loss: -1524.023682\n",
      "Train Epoch: 4628 [11776/60000 (20%)] Loss: -1531.153564\n",
      "Train Epoch: 4628 [23040/60000 (38%)] Loss: -1593.802246\n",
      "Train Epoch: 4628 [34304/60000 (57%)] Loss: -1535.728271\n",
      "Train Epoch: 4628 [45568/60000 (76%)] Loss: -1533.439941\n",
      "Train Epoch: 4628 [56832/60000 (95%)] Loss: -1518.754517\n",
      "    epoch          : 4628\n",
      "    loss           : -1544.59926488844\n",
      "Train Epoch: 4629 [512/60000 (1%)] Loss: -1546.375732\n",
      "Train Epoch: 4629 [11776/60000 (20%)] Loss: -1480.691895\n",
      "Train Epoch: 4629 [23040/60000 (38%)] Loss: -1608.230225\n",
      "Train Epoch: 4629 [34304/60000 (57%)] Loss: -1537.630859\n",
      "Train Epoch: 4629 [45568/60000 (76%)] Loss: -1552.011597\n",
      "Train Epoch: 4629 [56832/60000 (95%)] Loss: -1547.655762\n",
      "    epoch          : 4629\n",
      "    loss           : -1541.755704890537\n",
      "Train Epoch: 4630 [512/60000 (1%)] Loss: -1509.103516\n",
      "Train Epoch: 4630 [11776/60000 (20%)] Loss: -1614.817627\n",
      "Train Epoch: 4630 [23040/60000 (38%)] Loss: -1441.478394\n",
      "Train Epoch: 4630 [34304/60000 (57%)] Loss: -1548.847656\n",
      "Train Epoch: 4630 [45568/60000 (76%)] Loss: -1522.659180\n",
      "Train Epoch: 4630 [56832/60000 (95%)] Loss: -1460.909424\n",
      "    epoch          : 4630\n",
      "    loss           : -1534.1800616420596\n",
      "Train Epoch: 4631 [512/60000 (1%)] Loss: -1507.342651\n",
      "Train Epoch: 4631 [11776/60000 (20%)] Loss: -1522.341919\n",
      "Train Epoch: 4631 [23040/60000 (38%)] Loss: -1558.057983\n",
      "Train Epoch: 4631 [34304/60000 (57%)] Loss: -1611.595459\n",
      "Train Epoch: 4631 [45568/60000 (76%)] Loss: -1576.045044\n",
      "Train Epoch: 4631 [56832/60000 (95%)] Loss: -1588.884033\n",
      "    epoch          : 4631\n",
      "    loss           : -1540.7222503834525\n",
      "Train Epoch: 4632 [512/60000 (1%)] Loss: -1562.456177\n",
      "Train Epoch: 4632 [11776/60000 (20%)] Loss: -1539.869263\n",
      "Train Epoch: 4632 [23040/60000 (38%)] Loss: -1595.540283\n",
      "Train Epoch: 4632 [34304/60000 (57%)] Loss: -1533.638062\n",
      "Train Epoch: 4632 [45568/60000 (76%)] Loss: -1553.827881\n",
      "Train Epoch: 4632 [56832/60000 (95%)] Loss: -1526.855103\n",
      "    epoch          : 4632\n",
      "    loss           : -1536.0926089529264\n",
      "Train Epoch: 4633 [512/60000 (1%)] Loss: -1475.543091\n",
      "Train Epoch: 4633 [11776/60000 (20%)] Loss: -1441.708252\n",
      "Train Epoch: 4633 [23040/60000 (38%)] Loss: -1503.550171\n",
      "Train Epoch: 4633 [34304/60000 (57%)] Loss: -1506.006348\n",
      "Train Epoch: 4633 [45568/60000 (76%)] Loss: -1538.562134\n",
      "Train Epoch: 4633 [56832/60000 (95%)] Loss: -1557.956299\n",
      "    epoch          : 4633\n",
      "    loss           : -1536.3584105065988\n",
      "Train Epoch: 4634 [512/60000 (1%)] Loss: -1525.504761\n",
      "Train Epoch: 4634 [11776/60000 (20%)] Loss: -1545.099976\n",
      "Train Epoch: 4634 [23040/60000 (38%)] Loss: -1582.280273\n",
      "Train Epoch: 4634 [34304/60000 (57%)] Loss: -1590.158203\n",
      "Train Epoch: 4634 [45568/60000 (76%)] Loss: -1562.249878\n",
      "Train Epoch: 4634 [56832/60000 (95%)] Loss: -1563.219971\n",
      "    epoch          : 4634\n",
      "    loss           : -1536.7324491166798\n",
      "Train Epoch: 4635 [512/60000 (1%)] Loss: -1562.577881\n",
      "Train Epoch: 4635 [11776/60000 (20%)] Loss: -1464.220337\n",
      "Train Epoch: 4635 [23040/60000 (38%)] Loss: -1522.477661\n",
      "Train Epoch: 4635 [34304/60000 (57%)] Loss: -1492.432739\n",
      "Train Epoch: 4635 [45568/60000 (76%)] Loss: -1489.617065\n",
      "Train Epoch: 4635 [56832/60000 (95%)] Loss: -1498.302734\n",
      "    epoch          : 4635\n",
      "    loss           : -1539.5724114886784\n",
      "Train Epoch: 4636 [512/60000 (1%)] Loss: -1561.014160\n",
      "Train Epoch: 4636 [11776/60000 (20%)] Loss: -1531.616455\n",
      "Train Epoch: 4636 [23040/60000 (38%)] Loss: -1570.992554\n",
      "Train Epoch: 4636 [34304/60000 (57%)] Loss: -1524.055664\n",
      "Train Epoch: 4636 [45568/60000 (76%)] Loss: -1556.579468\n",
      "Train Epoch: 4636 [56832/60000 (95%)] Loss: -1570.954346\n",
      "    epoch          : 4636\n",
      "    loss           : -1537.3089306502693\n",
      "Train Epoch: 4637 [512/60000 (1%)] Loss: -1517.205811\n",
      "Train Epoch: 4637 [11776/60000 (20%)] Loss: -1559.819580\n",
      "Train Epoch: 4637 [23040/60000 (38%)] Loss: -1571.642334\n",
      "Train Epoch: 4637 [34304/60000 (57%)] Loss: -1583.022827\n",
      "Train Epoch: 4637 [45568/60000 (76%)] Loss: -1525.387695\n",
      "Train Epoch: 4637 [56832/60000 (95%)] Loss: -1467.809814\n",
      "    epoch          : 4637\n",
      "    loss           : -1542.7052467475503\n",
      "Train Epoch: 4638 [512/60000 (1%)] Loss: -1564.024658\n",
      "Train Epoch: 4638 [11776/60000 (20%)] Loss: -1570.717285\n",
      "Train Epoch: 4638 [23040/60000 (38%)] Loss: -1547.409424\n",
      "Train Epoch: 4638 [34304/60000 (57%)] Loss: -1574.987671\n",
      "Train Epoch: 4638 [45568/60000 (76%)] Loss: -1516.620728\n",
      "Train Epoch: 4638 [56832/60000 (95%)] Loss: -1542.562256\n",
      "    epoch          : 4638\n",
      "    loss           : -1538.4129990399895\n",
      "Train Epoch: 4639 [512/60000 (1%)] Loss: -1508.480103\n",
      "Train Epoch: 4639 [11776/60000 (20%)] Loss: -1558.812012\n",
      "Train Epoch: 4639 [23040/60000 (38%)] Loss: -1581.197266\n",
      "Train Epoch: 4639 [34304/60000 (57%)] Loss: -1544.446411\n",
      "Train Epoch: 4639 [45568/60000 (76%)] Loss: -1559.853027\n",
      "Train Epoch: 4639 [56832/60000 (95%)] Loss: -1494.005127\n",
      "    epoch          : 4639\n",
      "    loss           : -1544.8142189844855\n",
      "Train Epoch: 4640 [512/60000 (1%)] Loss: -1546.796875\n",
      "Train Epoch: 4640 [11776/60000 (20%)] Loss: -1493.715576\n",
      "Train Epoch: 4640 [23040/60000 (38%)] Loss: -1609.230713\n",
      "Train Epoch: 4640 [34304/60000 (57%)] Loss: -1527.070435\n",
      "Train Epoch: 4640 [45568/60000 (76%)] Loss: -1560.362915\n",
      "Train Epoch: 4640 [56832/60000 (95%)] Loss: -1584.484985\n",
      "    epoch          : 4640\n",
      "    loss           : -1540.1133409058307\n",
      "Train Epoch: 4641 [512/60000 (1%)] Loss: -1461.492920\n",
      "Train Epoch: 4641 [11776/60000 (20%)] Loss: -1531.842163\n",
      "Train Epoch: 4641 [23040/60000 (38%)] Loss: -1581.269897\n",
      "Train Epoch: 4641 [34304/60000 (57%)] Loss: -1520.725098\n",
      "Train Epoch: 4641 [45568/60000 (76%)] Loss: -1526.475220\n",
      "Train Epoch: 4641 [56832/60000 (95%)] Loss: -1557.031738\n",
      "    epoch          : 4641\n",
      "    loss           : -1537.9527346508653\n",
      "Train Epoch: 4642 [512/60000 (1%)] Loss: -1552.157837\n",
      "Train Epoch: 4642 [11776/60000 (20%)] Loss: -1511.229492\n",
      "Train Epoch: 4642 [23040/60000 (38%)] Loss: -1557.225586\n",
      "Train Epoch: 4642 [34304/60000 (57%)] Loss: -1573.870361\n",
      "Train Epoch: 4642 [45568/60000 (76%)] Loss: -1565.185791\n",
      "Train Epoch: 4642 [56832/60000 (95%)] Loss: -1604.994263\n",
      "    epoch          : 4642\n",
      "    loss           : -1541.0675179864054\n",
      "Train Epoch: 4643 [512/60000 (1%)] Loss: -1600.909790\n",
      "Train Epoch: 4643 [11776/60000 (20%)] Loss: -1564.046875\n",
      "Train Epoch: 4643 [23040/60000 (38%)] Loss: -1600.858521\n",
      "Train Epoch: 4643 [34304/60000 (57%)] Loss: -1540.467773\n",
      "Train Epoch: 4643 [45568/60000 (76%)] Loss: -1588.491089\n",
      "Train Epoch: 4643 [56832/60000 (95%)] Loss: -1620.294800\n",
      "    epoch          : 4643\n",
      "    loss           : -1540.5762418757724\n",
      "Train Epoch: 4644 [512/60000 (1%)] Loss: -1546.740479\n",
      "Train Epoch: 4644 [11776/60000 (20%)] Loss: -1582.133301\n",
      "Train Epoch: 4644 [23040/60000 (38%)] Loss: -1557.323853\n",
      "Train Epoch: 4644 [34304/60000 (57%)] Loss: -1577.503174\n",
      "Train Epoch: 4644 [45568/60000 (76%)] Loss: -1514.786377\n",
      "Train Epoch: 4644 [56832/60000 (95%)] Loss: -1547.256470\n",
      "    epoch          : 4644\n",
      "    loss           : -1541.5065686931719\n",
      "Train Epoch: 4645 [512/60000 (1%)] Loss: -1553.122070\n",
      "Train Epoch: 4645 [11776/60000 (20%)] Loss: -1531.279907\n",
      "Train Epoch: 4645 [23040/60000 (38%)] Loss: -1588.683105\n",
      "Train Epoch: 4645 [34304/60000 (57%)] Loss: -1569.240723\n",
      "Train Epoch: 4645 [45568/60000 (76%)] Loss: -1535.855957\n",
      "Train Epoch: 4645 [56832/60000 (95%)] Loss: -1546.092163\n",
      "    epoch          : 4645\n",
      "    loss           : -1541.1252279335495\n",
      "Train Epoch: 4646 [512/60000 (1%)] Loss: -1597.216064\n",
      "Train Epoch: 4646 [11776/60000 (20%)] Loss: -1619.524292\n",
      "Train Epoch: 4646 [23040/60000 (38%)] Loss: -1532.002563\n",
      "Train Epoch: 4646 [34304/60000 (57%)] Loss: -1493.714600\n",
      "Train Epoch: 4646 [45568/60000 (76%)] Loss: -1618.561157\n",
      "Train Epoch: 4646 [56832/60000 (95%)] Loss: -1578.509399\n",
      "    epoch          : 4646\n",
      "    loss           : -1545.9753273139565\n",
      "Train Epoch: 4647 [512/60000 (1%)] Loss: -1582.345581\n",
      "Train Epoch: 4647 [11776/60000 (20%)] Loss: -1568.748291\n",
      "Train Epoch: 4647 [23040/60000 (38%)] Loss: -1529.123535\n",
      "Train Epoch: 4647 [34304/60000 (57%)] Loss: -1469.167236\n",
      "Train Epoch: 4647 [45568/60000 (76%)] Loss: -1562.192871\n",
      "Train Epoch: 4647 [56832/60000 (95%)] Loss: -1570.712524\n",
      "    epoch          : 4647\n",
      "    loss           : -1539.303739903337\n",
      "Train Epoch: 4648 [512/60000 (1%)] Loss: -1479.174072\n",
      "Train Epoch: 4648 [11776/60000 (20%)] Loss: -1549.380615\n",
      "Train Epoch: 4648 [23040/60000 (38%)] Loss: -1550.769531\n",
      "Train Epoch: 4648 [34304/60000 (57%)] Loss: -1514.145264\n",
      "Train Epoch: 4648 [45568/60000 (76%)] Loss: -1522.547363\n",
      "Train Epoch: 4648 [56832/60000 (95%)] Loss: -1569.060303\n",
      "    epoch          : 4648\n",
      "    loss           : -1540.2679384738037\n",
      "Train Epoch: 4649 [512/60000 (1%)] Loss: -1504.530396\n",
      "Train Epoch: 4649 [11776/60000 (20%)] Loss: -1525.900635\n",
      "Train Epoch: 4649 [23040/60000 (38%)] Loss: -1514.459229\n",
      "Train Epoch: 4649 [34304/60000 (57%)] Loss: -1570.238770\n",
      "Train Epoch: 4649 [45568/60000 (76%)] Loss: -1484.293945\n",
      "Train Epoch: 4649 [56832/60000 (95%)] Loss: -1498.207397\n",
      "    epoch          : 4649\n",
      "    loss           : -1540.4172218452065\n",
      "Train Epoch: 4650 [512/60000 (1%)] Loss: -1558.355225\n",
      "Train Epoch: 4650 [11776/60000 (20%)] Loss: -1558.352661\n",
      "Train Epoch: 4650 [23040/60000 (38%)] Loss: -1475.138794\n",
      "Train Epoch: 4650 [34304/60000 (57%)] Loss: -1505.546021\n",
      "Train Epoch: 4650 [45568/60000 (76%)] Loss: -1571.765869\n",
      "Train Epoch: 4650 [56832/60000 (95%)] Loss: -1558.992188\n",
      "    epoch          : 4650\n",
      "    loss           : -1539.87675484695\n",
      "Train Epoch: 4651 [512/60000 (1%)] Loss: -1531.979614\n",
      "Train Epoch: 4651 [11776/60000 (20%)] Loss: -1592.734985\n",
      "Train Epoch: 4651 [23040/60000 (38%)] Loss: -1519.752075\n",
      "Train Epoch: 4651 [34304/60000 (57%)] Loss: -1546.243164\n",
      "Train Epoch: 4651 [45568/60000 (76%)] Loss: -1543.070312\n",
      "Train Epoch: 4651 [56832/60000 (95%)] Loss: -1550.298340\n",
      "    epoch          : 4651\n",
      "    loss           : -1540.124375165519\n",
      "Train Epoch: 4652 [512/60000 (1%)] Loss: -1500.715332\n",
      "Train Epoch: 4652 [11776/60000 (20%)] Loss: -1558.610474\n",
      "Train Epoch: 4652 [23040/60000 (38%)] Loss: -1505.719482\n",
      "Train Epoch: 4652 [34304/60000 (57%)] Loss: -1533.289307\n",
      "Train Epoch: 4652 [45568/60000 (76%)] Loss: -1608.968018\n",
      "Train Epoch: 4652 [56832/60000 (95%)] Loss: -1522.660767\n",
      "    epoch          : 4652\n",
      "    loss           : -1535.3887894625045\n",
      "Train Epoch: 4653 [512/60000 (1%)] Loss: -1498.878662\n",
      "Train Epoch: 4653 [11776/60000 (20%)] Loss: -1518.599365\n",
      "Train Epoch: 4653 [23040/60000 (38%)] Loss: -1582.281128\n",
      "Train Epoch: 4653 [34304/60000 (57%)] Loss: -1482.651733\n",
      "Train Epoch: 4653 [45568/60000 (76%)] Loss: -1472.219971\n",
      "Train Epoch: 4653 [56832/60000 (95%)] Loss: -1548.759766\n",
      "    epoch          : 4653\n",
      "    loss           : -1543.0025879595914\n",
      "Train Epoch: 4654 [512/60000 (1%)] Loss: -1587.213745\n",
      "Train Epoch: 4654 [11776/60000 (20%)] Loss: -1577.109741\n",
      "Train Epoch: 4654 [23040/60000 (38%)] Loss: -1533.480591\n",
      "Train Epoch: 4654 [34304/60000 (57%)] Loss: -1598.397827\n",
      "Train Epoch: 4654 [45568/60000 (76%)] Loss: -1572.086060\n",
      "Train Epoch: 4654 [56832/60000 (95%)] Loss: -1527.198120\n",
      "    epoch          : 4654\n",
      "    loss           : -1545.0073124944827\n",
      "Train Epoch: 4655 [512/60000 (1%)] Loss: -1491.652710\n",
      "Train Epoch: 4655 [11776/60000 (20%)] Loss: -1558.855469\n",
      "Train Epoch: 4655 [23040/60000 (38%)] Loss: -1520.924438\n",
      "Train Epoch: 4655 [34304/60000 (57%)] Loss: -1520.882812\n",
      "Train Epoch: 4655 [45568/60000 (76%)] Loss: -1566.513184\n",
      "Train Epoch: 4655 [56832/60000 (95%)] Loss: -1564.876831\n",
      "    epoch          : 4655\n",
      "    loss           : -1539.2571504237287\n",
      "Train Epoch: 4656 [512/60000 (1%)] Loss: -1551.462646\n",
      "Train Epoch: 4656 [11776/60000 (20%)] Loss: -1538.444702\n",
      "Train Epoch: 4656 [23040/60000 (38%)] Loss: -1589.016846\n",
      "Train Epoch: 4656 [34304/60000 (57%)] Loss: -1609.673706\n",
      "Train Epoch: 4656 [45568/60000 (76%)] Loss: -1565.630127\n",
      "Train Epoch: 4656 [56832/60000 (95%)] Loss: -1524.197998\n",
      "    epoch          : 4656\n",
      "    loss           : -1539.0844678286105\n",
      "Train Epoch: 4657 [512/60000 (1%)] Loss: -1554.279175\n",
      "Train Epoch: 4657 [11776/60000 (20%)] Loss: -1502.770020\n",
      "Train Epoch: 4657 [23040/60000 (38%)] Loss: -1586.895508\n",
      "Train Epoch: 4657 [34304/60000 (57%)] Loss: -1513.745483\n",
      "Train Epoch: 4657 [45568/60000 (76%)] Loss: -1615.373291\n",
      "Train Epoch: 4657 [56832/60000 (95%)] Loss: -1488.490479\n",
      "    epoch          : 4657\n",
      "    loss           : -1544.0018845035531\n",
      "Train Epoch: 4658 [512/60000 (1%)] Loss: -1584.058350\n",
      "Train Epoch: 4658 [11776/60000 (20%)] Loss: -1569.932617\n",
      "Train Epoch: 4658 [23040/60000 (38%)] Loss: -1599.287598\n",
      "Train Epoch: 4658 [34304/60000 (57%)] Loss: -1465.107544\n",
      "Train Epoch: 4658 [45568/60000 (76%)] Loss: -1558.321533\n",
      "Train Epoch: 4658 [56832/60000 (95%)] Loss: -1494.276123\n",
      "    epoch          : 4658\n",
      "    loss           : -1537.2466485837085\n",
      "Train Epoch: 4659 [512/60000 (1%)] Loss: -1593.636841\n",
      "Train Epoch: 4659 [11776/60000 (20%)] Loss: -1493.541504\n",
      "Train Epoch: 4659 [23040/60000 (38%)] Loss: -1492.206787\n",
      "Train Epoch: 4659 [34304/60000 (57%)] Loss: -1474.012573\n",
      "Train Epoch: 4659 [45568/60000 (76%)] Loss: -1456.860840\n",
      "Train Epoch: 4659 [56832/60000 (95%)] Loss: -1511.957031\n",
      "    epoch          : 4659\n",
      "    loss           : -1537.3122331005031\n",
      "Train Epoch: 4660 [512/60000 (1%)] Loss: -1568.296143\n",
      "Train Epoch: 4660 [11776/60000 (20%)] Loss: -1537.324219\n",
      "Train Epoch: 4660 [23040/60000 (38%)] Loss: -1502.464844\n",
      "Train Epoch: 4660 [34304/60000 (57%)] Loss: -1575.821777\n",
      "Train Epoch: 4660 [45568/60000 (76%)] Loss: -1563.486572\n",
      "Train Epoch: 4660 [56832/60000 (95%)] Loss: -1513.501465\n",
      "    epoch          : 4660\n",
      "    loss           : -1537.3294360489494\n",
      "Train Epoch: 4661 [512/60000 (1%)] Loss: -1600.400879\n",
      "Train Epoch: 4661 [11776/60000 (20%)] Loss: -1504.461426\n",
      "Train Epoch: 4661 [23040/60000 (38%)] Loss: -1502.869141\n",
      "Train Epoch: 4661 [34304/60000 (57%)] Loss: -1543.678467\n",
      "Train Epoch: 4661 [45568/60000 (76%)] Loss: -1462.902222\n",
      "Train Epoch: 4661 [56832/60000 (95%)] Loss: -1551.509888\n",
      "    epoch          : 4661\n",
      "    loss           : -1532.4006968352753\n",
      "Train Epoch: 4662 [512/60000 (1%)] Loss: -1571.749756\n",
      "Train Epoch: 4662 [11776/60000 (20%)] Loss: -1527.235840\n",
      "Train Epoch: 4662 [23040/60000 (38%)] Loss: -1544.077515\n",
      "Train Epoch: 4662 [34304/60000 (57%)] Loss: -1506.978027\n",
      "Train Epoch: 4662 [45568/60000 (76%)] Loss: -1556.012573\n",
      "Train Epoch: 4662 [56832/60000 (95%)] Loss: -1545.354736\n",
      "    epoch          : 4662\n",
      "    loss           : -1539.3165665965969\n",
      "Train Epoch: 4663 [512/60000 (1%)] Loss: -1557.184082\n",
      "Train Epoch: 4663 [11776/60000 (20%)] Loss: -1403.893799\n",
      "Train Epoch: 4663 [23040/60000 (38%)] Loss: -1554.582520\n",
      "Train Epoch: 4663 [34304/60000 (57%)] Loss: -1515.006836\n",
      "Train Epoch: 4663 [45568/60000 (76%)] Loss: -1550.992188\n",
      "Train Epoch: 4663 [56832/60000 (95%)] Loss: -1537.017334\n",
      "    epoch          : 4663\n",
      "    loss           : -1536.49663410079\n",
      "Train Epoch: 4664 [512/60000 (1%)] Loss: -1563.936279\n",
      "Train Epoch: 4664 [11776/60000 (20%)] Loss: -1580.958496\n",
      "Train Epoch: 4664 [23040/60000 (38%)] Loss: -1548.810303\n",
      "Train Epoch: 4664 [34304/60000 (57%)] Loss: -1557.565552\n",
      "Train Epoch: 4664 [45568/60000 (76%)] Loss: -1516.006836\n",
      "Train Epoch: 4664 [56832/60000 (95%)] Loss: -1540.662354\n",
      "    epoch          : 4664\n",
      "    loss           : -1538.8943495238568\n",
      "Train Epoch: 4665 [512/60000 (1%)] Loss: -1584.957886\n",
      "Train Epoch: 4665 [11776/60000 (20%)] Loss: -1551.707275\n",
      "Train Epoch: 4665 [23040/60000 (38%)] Loss: -1603.307495\n",
      "Train Epoch: 4665 [34304/60000 (57%)] Loss: -1496.410645\n",
      "Train Epoch: 4665 [45568/60000 (76%)] Loss: -1565.724121\n",
      "Train Epoch: 4665 [56832/60000 (95%)] Loss: -1589.247559\n",
      "    epoch          : 4665\n",
      "    loss           : -1537.2455971927966\n",
      "Train Epoch: 4666 [512/60000 (1%)] Loss: -1569.349976\n",
      "Train Epoch: 4666 [11776/60000 (20%)] Loss: -1466.971558\n",
      "Train Epoch: 4666 [23040/60000 (38%)] Loss: -1509.795898\n",
      "Train Epoch: 4666 [34304/60000 (57%)] Loss: -1538.967529\n",
      "Train Epoch: 4666 [45568/60000 (76%)] Loss: -1534.219482\n",
      "Train Epoch: 4666 [56832/60000 (95%)] Loss: -1489.952759\n",
      "    epoch          : 4666\n",
      "    loss           : -1535.5299079162253\n",
      "Train Epoch: 4667 [512/60000 (1%)] Loss: -1484.805664\n",
      "Train Epoch: 4667 [11776/60000 (20%)] Loss: -1576.408203\n",
      "Train Epoch: 4667 [23040/60000 (38%)] Loss: -1536.676025\n",
      "Train Epoch: 4667 [34304/60000 (57%)] Loss: -1547.229248\n",
      "Train Epoch: 4667 [45568/60000 (76%)] Loss: -1574.428467\n",
      "Train Epoch: 4667 [56832/60000 (95%)] Loss: -1532.090942\n",
      "    epoch          : 4667\n",
      "    loss           : -1537.1701922228106\n",
      "Train Epoch: 4668 [512/60000 (1%)] Loss: -1502.112549\n",
      "Train Epoch: 4668 [11776/60000 (20%)] Loss: -1567.889526\n",
      "Train Epoch: 4668 [23040/60000 (38%)] Loss: -1587.702515\n",
      "Train Epoch: 4668 [34304/60000 (57%)] Loss: -1547.125610\n",
      "Train Epoch: 4668 [45568/60000 (76%)] Loss: -1453.633179\n",
      "Train Epoch: 4668 [56832/60000 (95%)] Loss: -1557.687500\n",
      "    epoch          : 4668\n",
      "    loss           : -1537.981705315369\n",
      "Train Epoch: 4669 [512/60000 (1%)] Loss: -1545.746948\n",
      "Train Epoch: 4669 [11776/60000 (20%)] Loss: -1535.041992\n",
      "Train Epoch: 4669 [23040/60000 (38%)] Loss: -1513.115723\n",
      "Train Epoch: 4669 [34304/60000 (57%)] Loss: -1425.090088\n",
      "Train Epoch: 4669 [45568/60000 (76%)] Loss: -1549.199463\n",
      "Train Epoch: 4669 [56832/60000 (95%)] Loss: -1581.059326\n",
      "    epoch          : 4669\n",
      "    loss           : -1537.4160425218486\n",
      "Train Epoch: 4670 [512/60000 (1%)] Loss: -1529.506348\n",
      "Train Epoch: 4670 [11776/60000 (20%)] Loss: -1474.132202\n",
      "Train Epoch: 4670 [23040/60000 (38%)] Loss: -1521.389282\n",
      "Train Epoch: 4670 [34304/60000 (57%)] Loss: -1607.799683\n",
      "Train Epoch: 4670 [45568/60000 (76%)] Loss: -1434.538452\n",
      "Train Epoch: 4670 [56832/60000 (95%)] Loss: -1608.703735\n",
      "    epoch          : 4670\n",
      "    loss           : -1540.426500568282\n",
      "Train Epoch: 4671 [512/60000 (1%)] Loss: -1578.103271\n",
      "Train Epoch: 4671 [11776/60000 (20%)] Loss: -1605.818115\n",
      "Train Epoch: 4671 [23040/60000 (38%)] Loss: -1575.652588\n",
      "Train Epoch: 4671 [34304/60000 (57%)] Loss: -1569.785767\n",
      "Train Epoch: 4671 [45568/60000 (76%)] Loss: -1559.631104\n",
      "Train Epoch: 4671 [56832/60000 (95%)] Loss: -1567.128540\n",
      "    epoch          : 4671\n",
      "    loss           : -1542.4024975448006\n",
      "Train Epoch: 4672 [512/60000 (1%)] Loss: -1474.143311\n",
      "Train Epoch: 4672 [11776/60000 (20%)] Loss: -1531.242920\n",
      "Train Epoch: 4672 [23040/60000 (38%)] Loss: -1543.323975\n",
      "Train Epoch: 4672 [34304/60000 (57%)] Loss: -1543.600830\n",
      "Train Epoch: 4672 [45568/60000 (76%)] Loss: -1541.117920\n",
      "Train Epoch: 4672 [56832/60000 (95%)] Loss: -1534.078979\n",
      "    epoch          : 4672\n",
      "    loss           : -1543.165846312787\n",
      "Train Epoch: 4673 [512/60000 (1%)] Loss: -1558.683594\n",
      "Train Epoch: 4673 [11776/60000 (20%)] Loss: -1560.102661\n",
      "Train Epoch: 4673 [23040/60000 (38%)] Loss: -1533.991943\n",
      "Train Epoch: 4673 [34304/60000 (57%)] Loss: -1514.430908\n",
      "Train Epoch: 4673 [45568/60000 (76%)] Loss: -1472.932251\n",
      "Train Epoch: 4673 [56832/60000 (95%)] Loss: -1566.509644\n",
      "    epoch          : 4673\n",
      "    loss           : -1538.0622889631886\n",
      "Train Epoch: 4674 [512/60000 (1%)] Loss: -1559.307861\n",
      "Train Epoch: 4674 [11776/60000 (20%)] Loss: -1585.135620\n",
      "Train Epoch: 4674 [23040/60000 (38%)] Loss: -1548.358887\n",
      "Train Epoch: 4674 [34304/60000 (57%)] Loss: -1483.530518\n",
      "Train Epoch: 4674 [45568/60000 (76%)] Loss: -1552.237549\n",
      "Train Epoch: 4674 [56832/60000 (95%)] Loss: -1550.934448\n",
      "    epoch          : 4674\n",
      "    loss           : -1543.628126241393\n",
      "Train Epoch: 4675 [512/60000 (1%)] Loss: -1543.042236\n",
      "Train Epoch: 4675 [11776/60000 (20%)] Loss: -1526.317993\n",
      "Train Epoch: 4675 [23040/60000 (38%)] Loss: -1633.055908\n",
      "Train Epoch: 4675 [34304/60000 (57%)] Loss: -1483.649170\n",
      "Train Epoch: 4675 [45568/60000 (76%)] Loss: -1562.944824\n",
      "Train Epoch: 4675 [56832/60000 (95%)] Loss: -1522.933228\n",
      "    epoch          : 4675\n",
      "    loss           : -1539.1643449169094\n",
      "Train Epoch: 4676 [512/60000 (1%)] Loss: -1588.249268\n",
      "Train Epoch: 4676 [11776/60000 (20%)] Loss: -1539.951538\n",
      "Train Epoch: 4676 [23040/60000 (38%)] Loss: -1590.704712\n",
      "Train Epoch: 4676 [34304/60000 (57%)] Loss: -1529.338013\n",
      "Train Epoch: 4676 [45568/60000 (76%)] Loss: -1599.553345\n",
      "Train Epoch: 4676 [56832/60000 (95%)] Loss: -1656.091919\n",
      "    epoch          : 4676\n",
      "    loss           : -1542.8143258822167\n",
      "Train Epoch: 4677 [512/60000 (1%)] Loss: -1535.755859\n",
      "Train Epoch: 4677 [11776/60000 (20%)] Loss: -1615.019287\n",
      "Train Epoch: 4677 [23040/60000 (38%)] Loss: -1562.704956\n",
      "Train Epoch: 4677 [34304/60000 (57%)] Loss: -1549.771973\n",
      "Train Epoch: 4677 [45568/60000 (76%)] Loss: -1507.230225\n",
      "Train Epoch: 4677 [56832/60000 (95%)] Loss: -1580.085449\n",
      "    epoch          : 4677\n",
      "    loss           : -1543.4055268885725\n",
      "Train Epoch: 4678 [512/60000 (1%)] Loss: -1556.640625\n",
      "Train Epoch: 4678 [11776/60000 (20%)] Loss: -1524.869141\n",
      "Train Epoch: 4678 [23040/60000 (38%)] Loss: -1521.929565\n",
      "Train Epoch: 4678 [34304/60000 (57%)] Loss: -1587.152588\n",
      "Train Epoch: 4678 [45568/60000 (76%)] Loss: -1528.868408\n",
      "Train Epoch: 4678 [56832/60000 (95%)] Loss: -1490.942139\n",
      "    epoch          : 4678\n",
      "    loss           : -1539.4595102428716\n",
      "Train Epoch: 4679 [512/60000 (1%)] Loss: -1579.822021\n",
      "Train Epoch: 4679 [11776/60000 (20%)] Loss: -1497.226562\n",
      "Train Epoch: 4679 [23040/60000 (38%)] Loss: -1569.214355\n",
      "Train Epoch: 4679 [34304/60000 (57%)] Loss: -1580.829834\n",
      "Train Epoch: 4679 [45568/60000 (76%)] Loss: -1516.758423\n",
      "Train Epoch: 4679 [56832/60000 (95%)] Loss: -1501.067627\n",
      "    epoch          : 4679\n",
      "    loss           : -1540.2905311368954\n",
      "Train Epoch: 4680 [512/60000 (1%)] Loss: -1484.936279\n",
      "Train Epoch: 4680 [11776/60000 (20%)] Loss: -1625.589355\n",
      "Train Epoch: 4680 [23040/60000 (38%)] Loss: -1578.305298\n",
      "Train Epoch: 4680 [34304/60000 (57%)] Loss: -1483.088745\n",
      "Train Epoch: 4680 [45568/60000 (76%)] Loss: -1511.972900\n",
      "Train Epoch: 4680 [56832/60000 (95%)] Loss: -1437.651978\n",
      "    epoch          : 4680\n",
      "    loss           : -1552.9717027912031\n",
      "Train Epoch: 4681 [512/60000 (1%)] Loss: -1547.292480\n",
      "Train Epoch: 4681 [11776/60000 (20%)] Loss: -1532.587158\n",
      "Train Epoch: 4681 [23040/60000 (38%)] Loss: -1518.418457\n",
      "Train Epoch: 4681 [34304/60000 (57%)] Loss: -1566.726318\n",
      "Train Epoch: 4681 [45568/60000 (76%)] Loss: -1500.708984\n",
      "Train Epoch: 4681 [56832/60000 (95%)] Loss: -1541.809204\n",
      "    epoch          : 4681\n",
      "    loss           : -1546.0498826193943\n",
      "Train Epoch: 4682 [512/60000 (1%)] Loss: -1549.011841\n",
      "Train Epoch: 4682 [11776/60000 (20%)] Loss: -1569.780273\n",
      "Train Epoch: 4682 [23040/60000 (38%)] Loss: -1602.840820\n",
      "Train Epoch: 4682 [34304/60000 (57%)] Loss: -1585.605591\n",
      "Train Epoch: 4682 [45568/60000 (76%)] Loss: -1496.584595\n",
      "Train Epoch: 4682 [56832/60000 (95%)] Loss: -1543.819214\n",
      "    epoch          : 4682\n",
      "    loss           : -1537.196602859066\n",
      "Train Epoch: 4683 [512/60000 (1%)] Loss: -1575.456543\n",
      "Train Epoch: 4683 [11776/60000 (20%)] Loss: -1558.283081\n",
      "Train Epoch: 4683 [23040/60000 (38%)] Loss: -1607.666748\n",
      "Train Epoch: 4683 [34304/60000 (57%)] Loss: -1575.314453\n",
      "Train Epoch: 4683 [45568/60000 (76%)] Loss: -1465.731323\n",
      "Train Epoch: 4683 [56832/60000 (95%)] Loss: -1609.872314\n",
      "    epoch          : 4683\n",
      "    loss           : -1541.1248182738568\n",
      "Train Epoch: 4684 [512/60000 (1%)] Loss: -1611.626343\n",
      "Train Epoch: 4684 [11776/60000 (20%)] Loss: -1535.376465\n",
      "Train Epoch: 4684 [23040/60000 (38%)] Loss: -1577.312622\n",
      "Train Epoch: 4684 [34304/60000 (57%)] Loss: -1463.845947\n",
      "Train Epoch: 4684 [45568/60000 (76%)] Loss: -1574.405518\n",
      "Train Epoch: 4684 [56832/60000 (95%)] Loss: -1538.094482\n",
      "    epoch          : 4684\n",
      "    loss           : -1545.1928072999426\n",
      "Train Epoch: 4685 [512/60000 (1%)] Loss: -1519.801147\n",
      "Train Epoch: 4685 [11776/60000 (20%)] Loss: -1620.599854\n",
      "Train Epoch: 4685 [23040/60000 (38%)] Loss: -1575.429077\n",
      "Train Epoch: 4685 [34304/60000 (57%)] Loss: -1512.531982\n",
      "Train Epoch: 4685 [45568/60000 (76%)] Loss: -1493.654663\n",
      "Train Epoch: 4685 [56832/60000 (95%)] Loss: -1584.541992\n",
      "    epoch          : 4685\n",
      "    loss           : -1539.4468421720517\n",
      "Train Epoch: 4686 [512/60000 (1%)] Loss: -1565.692383\n",
      "Train Epoch: 4686 [11776/60000 (20%)] Loss: -1525.316650\n",
      "Train Epoch: 4686 [23040/60000 (38%)] Loss: -1563.782227\n",
      "Train Epoch: 4686 [34304/60000 (57%)] Loss: -1588.437134\n",
      "Train Epoch: 4686 [45568/60000 (76%)] Loss: -1644.154907\n",
      "Train Epoch: 4686 [56832/60000 (95%)] Loss: -1593.804932\n",
      "    epoch          : 4686\n",
      "    loss           : -1538.9093627929688\n",
      "Train Epoch: 4687 [512/60000 (1%)] Loss: -1471.738892\n",
      "Train Epoch: 4687 [11776/60000 (20%)] Loss: -1484.154663\n",
      "Train Epoch: 4687 [23040/60000 (38%)] Loss: -1608.889526\n",
      "Train Epoch: 4687 [34304/60000 (57%)] Loss: -1499.503174\n",
      "Train Epoch: 4687 [45568/60000 (76%)] Loss: -1541.702026\n",
      "Train Epoch: 4687 [56832/60000 (95%)] Loss: -1513.729736\n",
      "    epoch          : 4687\n",
      "    loss           : -1542.4743138544977\n",
      "Train Epoch: 4688 [512/60000 (1%)] Loss: -1585.833008\n",
      "Train Epoch: 4688 [11776/60000 (20%)] Loss: -1565.221680\n",
      "Train Epoch: 4688 [23040/60000 (38%)] Loss: -1490.629883\n",
      "Train Epoch: 4688 [34304/60000 (57%)] Loss: -1602.628052\n",
      "Train Epoch: 4688 [45568/60000 (76%)] Loss: -1595.663208\n",
      "Train Epoch: 4688 [56832/60000 (95%)] Loss: -1521.554077\n",
      "    epoch          : 4688\n",
      "    loss           : -1536.3360130180747\n",
      "Train Epoch: 4689 [512/60000 (1%)] Loss: -1622.277832\n",
      "Train Epoch: 4689 [11776/60000 (20%)] Loss: -1606.889526\n",
      "Train Epoch: 4689 [23040/60000 (38%)] Loss: -1584.736206\n",
      "Train Epoch: 4689 [34304/60000 (57%)] Loss: -1608.702148\n",
      "Train Epoch: 4689 [45568/60000 (76%)] Loss: -1516.902832\n",
      "Train Epoch: 4689 [56832/60000 (95%)] Loss: -1509.281250\n",
      "    epoch          : 4689\n",
      "    loss           : -1536.600799388131\n",
      "Train Epoch: 4690 [512/60000 (1%)] Loss: -1590.906738\n",
      "Train Epoch: 4690 [11776/60000 (20%)] Loss: -1559.060059\n",
      "Train Epoch: 4690 [23040/60000 (38%)] Loss: -1588.589844\n",
      "Train Epoch: 4690 [34304/60000 (57%)] Loss: -1547.930054\n",
      "Train Epoch: 4690 [45568/60000 (76%)] Loss: -1554.332031\n",
      "Train Epoch: 4690 [56832/60000 (95%)] Loss: -1604.671021\n",
      "    epoch          : 4690\n",
      "    loss           : -1542.322552869549\n",
      "Train Epoch: 4691 [512/60000 (1%)] Loss: -1562.104004\n",
      "Train Epoch: 4691 [11776/60000 (20%)] Loss: -1623.747437\n",
      "Train Epoch: 4691 [23040/60000 (38%)] Loss: -1579.009399\n",
      "Train Epoch: 4691 [34304/60000 (57%)] Loss: -1531.371582\n",
      "Train Epoch: 4691 [45568/60000 (76%)] Loss: -1516.565430\n",
      "Train Epoch: 4691 [56832/60000 (95%)] Loss: -1594.920654\n",
      "    epoch          : 4691\n",
      "    loss           : -1538.623563432424\n",
      "Train Epoch: 4692 [512/60000 (1%)] Loss: -1619.536743\n",
      "Train Epoch: 4692 [11776/60000 (20%)] Loss: -1503.164795\n",
      "Train Epoch: 4692 [23040/60000 (38%)] Loss: -1512.673096\n",
      "Train Epoch: 4692 [34304/60000 (57%)] Loss: -1623.897949\n",
      "Train Epoch: 4692 [45568/60000 (76%)] Loss: -1427.551392\n",
      "Train Epoch: 4692 [56832/60000 (95%)] Loss: -1498.511475\n",
      "    epoch          : 4692\n",
      "    loss           : -1538.7972491420596\n",
      "Train Epoch: 4693 [512/60000 (1%)] Loss: -1506.113892\n",
      "Train Epoch: 4693 [11776/60000 (20%)] Loss: -1602.573730\n",
      "Train Epoch: 4693 [23040/60000 (38%)] Loss: -1548.998779\n",
      "Train Epoch: 4693 [34304/60000 (57%)] Loss: -1574.709229\n",
      "Train Epoch: 4693 [45568/60000 (76%)] Loss: -1506.043091\n",
      "Train Epoch: 4693 [56832/60000 (95%)] Loss: -1563.435791\n",
      "    epoch          : 4693\n",
      "    loss           : -1544.5176888158767\n",
      "Train Epoch: 4694 [512/60000 (1%)] Loss: -1477.491333\n",
      "Train Epoch: 4694 [11776/60000 (20%)] Loss: -1582.516846\n",
      "Train Epoch: 4694 [23040/60000 (38%)] Loss: -1593.639404\n",
      "Train Epoch: 4694 [34304/60000 (57%)] Loss: -1530.873779\n",
      "Train Epoch: 4694 [45568/60000 (76%)] Loss: -1458.792236\n",
      "Train Epoch: 4694 [56832/60000 (95%)] Loss: -1579.385498\n",
      "    epoch          : 4694\n",
      "    loss           : -1538.14055810271\n",
      "Train Epoch: 4695 [512/60000 (1%)] Loss: -1602.644165\n",
      "Train Epoch: 4695 [11776/60000 (20%)] Loss: -1561.705078\n",
      "Train Epoch: 4695 [23040/60000 (38%)] Loss: -1504.395386\n",
      "Train Epoch: 4695 [34304/60000 (57%)] Loss: -1577.415771\n",
      "Train Epoch: 4695 [45568/60000 (76%)] Loss: -1456.207397\n",
      "Train Epoch: 4695 [56832/60000 (95%)] Loss: -1550.197021\n",
      "    epoch          : 4695\n",
      "    loss           : -1537.4496315131753\n",
      "Train Epoch: 4696 [512/60000 (1%)] Loss: -1535.558228\n",
      "Train Epoch: 4696 [11776/60000 (20%)] Loss: -1584.246338\n",
      "Train Epoch: 4696 [23040/60000 (38%)] Loss: -1560.748657\n",
      "Train Epoch: 4696 [34304/60000 (57%)] Loss: -1512.757324\n",
      "Train Epoch: 4696 [45568/60000 (76%)] Loss: -1545.374756\n",
      "Train Epoch: 4696 [56832/60000 (95%)] Loss: -1465.399170\n",
      "    epoch          : 4696\n",
      "    loss           : -1543.737578828456\n",
      "Train Epoch: 4697 [512/60000 (1%)] Loss: -1573.308350\n",
      "Train Epoch: 4697 [11776/60000 (20%)] Loss: -1533.695923\n",
      "Train Epoch: 4697 [23040/60000 (38%)] Loss: -1560.049561\n",
      "Train Epoch: 4697 [34304/60000 (57%)] Loss: -1624.794434\n",
      "Train Epoch: 4697 [45568/60000 (76%)] Loss: -1502.317993\n",
      "Train Epoch: 4697 [56832/60000 (95%)] Loss: -1499.745361\n",
      "    epoch          : 4697\n",
      "    loss           : -1533.1023214738923\n",
      "Train Epoch: 4698 [512/60000 (1%)] Loss: -1565.885498\n",
      "Train Epoch: 4698 [11776/60000 (20%)] Loss: -1511.588867\n",
      "Train Epoch: 4698 [23040/60000 (38%)] Loss: -1539.733276\n",
      "Train Epoch: 4698 [34304/60000 (57%)] Loss: -1569.387695\n",
      "Train Epoch: 4698 [45568/60000 (76%)] Loss: -1567.232666\n",
      "Train Epoch: 4698 [56832/60000 (95%)] Loss: -1557.123047\n",
      "    epoch          : 4698\n",
      "    loss           : -1539.7503948319431\n",
      "Train Epoch: 4699 [512/60000 (1%)] Loss: -1584.681152\n",
      "Train Epoch: 4699 [11776/60000 (20%)] Loss: -1560.166260\n",
      "Train Epoch: 4699 [23040/60000 (38%)] Loss: -1508.647217\n",
      "Train Epoch: 4699 [34304/60000 (57%)] Loss: -1606.872803\n",
      "Train Epoch: 4699 [45568/60000 (76%)] Loss: -1548.739990\n",
      "Train Epoch: 4699 [56832/60000 (95%)] Loss: -1479.495117\n",
      "    epoch          : 4699\n",
      "    loss           : -1545.204147425075\n",
      "Train Epoch: 4700 [512/60000 (1%)] Loss: -1547.449341\n",
      "Train Epoch: 4700 [11776/60000 (20%)] Loss: -1602.884644\n",
      "Train Epoch: 4700 [23040/60000 (38%)] Loss: -1528.887939\n",
      "Train Epoch: 4700 [34304/60000 (57%)] Loss: -1601.347290\n",
      "Train Epoch: 4700 [45568/60000 (76%)] Loss: -1589.411377\n",
      "Train Epoch: 4700 [56832/60000 (95%)] Loss: -1587.884766\n",
      "    epoch          : 4700\n",
      "    loss           : -1546.4427800582628\n",
      "Saving checkpoint: saved/models/Mnist_DeepGenerativeOperad/0127_111843/checkpoint-epoch4700.pth ...\n",
      "Train Epoch: 4701 [512/60000 (1%)] Loss: -1470.888428\n",
      "Train Epoch: 4701 [11776/60000 (20%)] Loss: -1527.791870\n",
      "Train Epoch: 4701 [23040/60000 (38%)] Loss: -1558.109375\n",
      "Train Epoch: 4701 [34304/60000 (57%)] Loss: -1579.066650\n",
      "Train Epoch: 4701 [45568/60000 (76%)] Loss: -1598.808350\n",
      "Train Epoch: 4701 [56832/60000 (95%)] Loss: -1596.384521\n",
      "    epoch          : 4701\n",
      "    loss           : -1543.063302077816\n",
      "Train Epoch: 4702 [512/60000 (1%)] Loss: -1494.713379\n",
      "Train Epoch: 4702 [11776/60000 (20%)] Loss: -1523.849487\n",
      "Train Epoch: 4702 [23040/60000 (38%)] Loss: -1611.498413\n",
      "Train Epoch: 4702 [34304/60000 (57%)] Loss: -1488.484863\n",
      "Train Epoch: 4702 [45568/60000 (76%)] Loss: -1541.285278\n",
      "Train Epoch: 4702 [56832/60000 (95%)] Loss: -1563.561035\n",
      "    epoch          : 4702\n",
      "    loss           : -1535.8510021489892\n",
      "Train Epoch: 4703 [512/60000 (1%)] Loss: -1508.551514\n",
      "Train Epoch: 4703 [11776/60000 (20%)] Loss: -1385.951660\n",
      "Train Epoch: 4703 [23040/60000 (38%)] Loss: -1527.334106\n",
      "Train Epoch: 4703 [34304/60000 (57%)] Loss: -1533.226685\n",
      "Train Epoch: 4703 [45568/60000 (76%)] Loss: -1594.517456\n",
      "Train Epoch: 4703 [56832/60000 (95%)] Loss: -1548.859253\n",
      "    epoch          : 4703\n",
      "    loss           : -1537.286495230292\n",
      "Train Epoch: 4704 [512/60000 (1%)] Loss: -1554.713013\n",
      "Train Epoch: 4704 [11776/60000 (20%)] Loss: -1559.885254\n",
      "Train Epoch: 4704 [23040/60000 (38%)] Loss: -1532.719116\n",
      "Train Epoch: 4704 [34304/60000 (57%)] Loss: -1540.673462\n",
      "Train Epoch: 4704 [45568/60000 (76%)] Loss: -1504.020874\n",
      "Train Epoch: 4704 [56832/60000 (95%)] Loss: -1599.557617\n",
      "    epoch          : 4704\n",
      "    loss           : -1546.799124335165\n",
      "Train Epoch: 4705 [512/60000 (1%)] Loss: -1559.954102\n",
      "Train Epoch: 4705 [11776/60000 (20%)] Loss: -1565.854004\n",
      "Train Epoch: 4705 [23040/60000 (38%)] Loss: -1471.413086\n",
      "Train Epoch: 4705 [34304/60000 (57%)] Loss: -1573.403687\n",
      "Train Epoch: 4705 [45568/60000 (76%)] Loss: -1487.696289\n",
      "Train Epoch: 4705 [56832/60000 (95%)] Loss: -1506.080200\n",
      "    epoch          : 4705\n",
      "    loss           : -1544.091965152719\n",
      "Train Epoch: 4706 [512/60000 (1%)] Loss: -1533.774536\n",
      "Train Epoch: 4706 [11776/60000 (20%)] Loss: -1584.682129\n",
      "Train Epoch: 4706 [23040/60000 (38%)] Loss: -1557.309937\n",
      "Train Epoch: 4706 [34304/60000 (57%)] Loss: -1542.220703\n",
      "Train Epoch: 4706 [45568/60000 (76%)] Loss: -1518.996826\n",
      "Train Epoch: 4706 [56832/60000 (95%)] Loss: -1517.425171\n",
      "    epoch          : 4706\n",
      "    loss           : -1536.4622216521009\n",
      "Train Epoch: 4707 [512/60000 (1%)] Loss: -1590.282104\n",
      "Train Epoch: 4707 [11776/60000 (20%)] Loss: -1570.245117\n",
      "Train Epoch: 4707 [23040/60000 (38%)] Loss: -1580.454956\n",
      "Train Epoch: 4707 [34304/60000 (57%)] Loss: -1595.676514\n",
      "Train Epoch: 4707 [45568/60000 (76%)] Loss: -1622.043945\n",
      "Train Epoch: 4707 [56832/60000 (95%)] Loss: -1511.478638\n",
      "    epoch          : 4707\n",
      "    loss           : -1540.9516060177216\n",
      "Train Epoch: 4708 [512/60000 (1%)] Loss: -1476.705444\n",
      "Train Epoch: 4708 [11776/60000 (20%)] Loss: -1568.036987\n",
      "Train Epoch: 4708 [23040/60000 (38%)] Loss: -1541.098511\n",
      "Train Epoch: 4708 [34304/60000 (57%)] Loss: -1561.936279\n",
      "Train Epoch: 4708 [45568/60000 (76%)] Loss: -1540.763672\n",
      "Train Epoch: 4708 [56832/60000 (95%)] Loss: -1565.109741\n",
      "    epoch          : 4708\n",
      "    loss           : -1544.0574813239318\n",
      "Train Epoch: 4709 [512/60000 (1%)] Loss: -1543.253906\n",
      "Train Epoch: 4709 [11776/60000 (20%)] Loss: -1573.270508\n",
      "Train Epoch: 4709 [23040/60000 (38%)] Loss: -1513.102417\n",
      "Train Epoch: 4709 [34304/60000 (57%)] Loss: -1566.389404\n",
      "Train Epoch: 4709 [45568/60000 (76%)] Loss: -1620.921997\n",
      "Train Epoch: 4709 [56832/60000 (95%)] Loss: -1496.232788\n",
      "    epoch          : 4709\n",
      "    loss           : -1541.0212240272995\n",
      "Train Epoch: 4710 [512/60000 (1%)] Loss: -1575.212891\n",
      "Train Epoch: 4710 [11776/60000 (20%)] Loss: -1620.203857\n",
      "Train Epoch: 4710 [23040/60000 (38%)] Loss: -1556.820679\n",
      "Train Epoch: 4710 [34304/60000 (57%)] Loss: -1469.148071\n",
      "Train Epoch: 4710 [45568/60000 (76%)] Loss: -1591.755615\n",
      "Train Epoch: 4710 [56832/60000 (95%)] Loss: -1522.563477\n",
      "    epoch          : 4710\n",
      "    loss           : -1551.698065978659\n",
      "Train Epoch: 4711 [512/60000 (1%)] Loss: -1572.053101\n",
      "Train Epoch: 4711 [11776/60000 (20%)] Loss: -1530.917725\n",
      "Train Epoch: 4711 [23040/60000 (38%)] Loss: -1560.540405\n",
      "Train Epoch: 4711 [34304/60000 (57%)] Loss: -1572.782593\n",
      "Train Epoch: 4711 [45568/60000 (76%)] Loss: -1554.839355\n",
      "Train Epoch: 4711 [56832/60000 (95%)] Loss: -1515.227051\n",
      "    epoch          : 4711\n",
      "    loss           : -1535.3367440606241\n",
      "Train Epoch: 4712 [512/60000 (1%)] Loss: -1495.996582\n",
      "Train Epoch: 4712 [11776/60000 (20%)] Loss: -1519.268433\n",
      "Train Epoch: 4712 [23040/60000 (38%)] Loss: -1493.871216\n",
      "Train Epoch: 4712 [34304/60000 (57%)] Loss: -1496.525024\n",
      "Train Epoch: 4712 [45568/60000 (76%)] Loss: -1537.971313\n",
      "Train Epoch: 4712 [56832/60000 (95%)] Loss: -1521.001343\n",
      "    epoch          : 4712\n",
      "    loss           : -1538.8248563432423\n",
      "Train Epoch: 4713 [512/60000 (1%)] Loss: -1501.458252\n",
      "Train Epoch: 4713 [11776/60000 (20%)] Loss: -1618.512329\n",
      "Train Epoch: 4713 [23040/60000 (38%)] Loss: -1576.573242\n",
      "Train Epoch: 4713 [34304/60000 (57%)] Loss: -1502.046143\n",
      "Train Epoch: 4713 [45568/60000 (76%)] Loss: -1533.864746\n",
      "Train Epoch: 4713 [56832/60000 (95%)] Loss: -1527.170166\n",
      "    epoch          : 4713\n",
      "    loss           : -1536.2770002979344\n",
      "Train Epoch: 4714 [512/60000 (1%)] Loss: -1570.324585\n",
      "Train Epoch: 4714 [11776/60000 (20%)] Loss: -1554.770020\n",
      "Train Epoch: 4714 [23040/60000 (38%)] Loss: -1581.806152\n",
      "Train Epoch: 4714 [34304/60000 (57%)] Loss: -1589.562988\n",
      "Train Epoch: 4714 [45568/60000 (76%)] Loss: -1456.495605\n",
      "Train Epoch: 4714 [56832/60000 (95%)] Loss: -1518.856201\n",
      "    epoch          : 4714\n",
      "    loss           : -1541.1545810160665\n",
      "Train Epoch: 4715 [512/60000 (1%)] Loss: -1536.385498\n",
      "Train Epoch: 4715 [11776/60000 (20%)] Loss: -1561.526123\n",
      "Train Epoch: 4715 [23040/60000 (38%)] Loss: -1568.218872\n",
      "Train Epoch: 4715 [34304/60000 (57%)] Loss: -1526.548828\n",
      "Train Epoch: 4715 [45568/60000 (76%)] Loss: -1562.078613\n",
      "Train Epoch: 4715 [56832/60000 (95%)] Loss: -1569.671387\n",
      "    epoch          : 4715\n",
      "    loss           : -1542.275788215594\n",
      "Train Epoch: 4716 [512/60000 (1%)] Loss: -1469.681274\n",
      "Train Epoch: 4716 [11776/60000 (20%)] Loss: -1517.257324\n",
      "Train Epoch: 4716 [23040/60000 (38%)] Loss: -1470.564209\n",
      "Train Epoch: 4716 [34304/60000 (57%)] Loss: -1552.937500\n",
      "Train Epoch: 4716 [45568/60000 (76%)] Loss: -1530.802979\n",
      "Train Epoch: 4716 [56832/60000 (95%)] Loss: -1559.311523\n",
      "    epoch          : 4716\n",
      "    loss           : -1546.843029992055\n",
      "Train Epoch: 4717 [512/60000 (1%)] Loss: -1549.968994\n",
      "Train Epoch: 4717 [11776/60000 (20%)] Loss: -1569.848267\n",
      "Train Epoch: 4717 [23040/60000 (38%)] Loss: -1542.832886\n",
      "Train Epoch: 4717 [34304/60000 (57%)] Loss: -1525.231934\n",
      "Train Epoch: 4717 [45568/60000 (76%)] Loss: -1601.359497\n",
      "Train Epoch: 4717 [56832/60000 (95%)] Loss: -1490.041748\n",
      "    epoch          : 4717\n",
      "    loss           : -1548.1243658550716\n",
      "Train Epoch: 4718 [512/60000 (1%)] Loss: -1527.395020\n",
      "Train Epoch: 4718 [11776/60000 (20%)] Loss: -1603.805420\n",
      "Train Epoch: 4718 [23040/60000 (38%)] Loss: -1588.063110\n",
      "Train Epoch: 4718 [34304/60000 (57%)] Loss: -1565.736816\n",
      "Train Epoch: 4718 [45568/60000 (76%)] Loss: -1552.818237\n",
      "Train Epoch: 4718 [56832/60000 (95%)] Loss: -1509.198730\n",
      "    epoch          : 4718\n",
      "    loss           : -1536.5191577976034\n",
      "Train Epoch: 4719 [512/60000 (1%)] Loss: -1540.314087\n",
      "Train Epoch: 4719 [11776/60000 (20%)] Loss: -1517.127930\n",
      "Train Epoch: 4719 [23040/60000 (38%)] Loss: -1642.395874\n",
      "Train Epoch: 4719 [34304/60000 (57%)] Loss: -1479.074463\n",
      "Train Epoch: 4719 [45568/60000 (76%)] Loss: -1520.109009\n",
      "Train Epoch: 4719 [56832/60000 (95%)] Loss: -1530.214355\n",
      "    epoch          : 4719\n",
      "    loss           : -1539.1353732179114\n",
      "Train Epoch: 4720 [512/60000 (1%)] Loss: -1516.288818\n",
      "Train Epoch: 4720 [11776/60000 (20%)] Loss: -1572.535645\n",
      "Train Epoch: 4720 [23040/60000 (38%)] Loss: -1558.564575\n",
      "Train Epoch: 4720 [34304/60000 (57%)] Loss: -1530.316040\n",
      "Train Epoch: 4720 [45568/60000 (76%)] Loss: -1560.542236\n",
      "Train Epoch: 4720 [56832/60000 (95%)] Loss: -1464.239258\n",
      "    epoch          : 4720\n",
      "    loss           : -1548.310649979586\n",
      "Train Epoch: 4721 [512/60000 (1%)] Loss: -1570.966675\n",
      "Train Epoch: 4721 [11776/60000 (20%)] Loss: -1556.873047\n",
      "Train Epoch: 4721 [23040/60000 (38%)] Loss: -1610.665771\n",
      "Train Epoch: 4721 [34304/60000 (57%)] Loss: -1549.371094\n",
      "Train Epoch: 4721 [45568/60000 (76%)] Loss: -1543.576416\n",
      "Train Epoch: 4721 [56832/60000 (95%)] Loss: -1553.286255\n",
      "    epoch          : 4721\n",
      "    loss           : -1554.4943520066427\n",
      "Train Epoch: 4722 [512/60000 (1%)] Loss: -1553.691528\n",
      "Train Epoch: 4722 [11776/60000 (20%)] Loss: -1577.230225\n",
      "Train Epoch: 4722 [23040/60000 (38%)] Loss: -1474.705566\n",
      "Train Epoch: 4722 [34304/60000 (57%)] Loss: -1574.607666\n",
      "Train Epoch: 4722 [45568/60000 (76%)] Loss: -1564.943359\n",
      "Train Epoch: 4722 [56832/60000 (95%)] Loss: -1580.026611\n",
      "    epoch          : 4722\n",
      "    loss           : -1547.7333308505474\n",
      "Train Epoch: 4723 [512/60000 (1%)] Loss: -1513.946899\n",
      "Train Epoch: 4723 [11776/60000 (20%)] Loss: -1502.017700\n",
      "Train Epoch: 4723 [23040/60000 (38%)] Loss: -1559.868652\n",
      "Train Epoch: 4723 [34304/60000 (57%)] Loss: -1524.625488\n",
      "Train Epoch: 4723 [45568/60000 (76%)] Loss: -1497.631714\n",
      "Train Epoch: 4723 [56832/60000 (95%)] Loss: -1551.149658\n",
      "    epoch          : 4723\n",
      "    loss           : -1545.9126190357963\n",
      "Train Epoch: 4724 [512/60000 (1%)] Loss: -1510.613403\n",
      "Train Epoch: 4724 [11776/60000 (20%)] Loss: -1518.981445\n",
      "Train Epoch: 4724 [23040/60000 (38%)] Loss: -1579.390015\n",
      "Train Epoch: 4724 [34304/60000 (57%)] Loss: -1426.069214\n",
      "Train Epoch: 4724 [45568/60000 (76%)] Loss: -1614.453247\n",
      "Train Epoch: 4724 [56832/60000 (95%)] Loss: -1597.166260\n",
      "    epoch          : 4724\n",
      "    loss           : -1541.6896407132767\n",
      "Train Epoch: 4725 [512/60000 (1%)] Loss: -1496.247803\n",
      "Train Epoch: 4725 [11776/60000 (20%)] Loss: -1576.348022\n",
      "Train Epoch: 4725 [23040/60000 (38%)] Loss: -1468.600098\n",
      "Train Epoch: 4725 [34304/60000 (57%)] Loss: -1433.948853\n",
      "Train Epoch: 4725 [45568/60000 (76%)] Loss: -1513.946289\n",
      "Train Epoch: 4725 [56832/60000 (95%)] Loss: -1496.756104\n",
      "    epoch          : 4725\n",
      "    loss           : -1538.7569197315281\n",
      "Train Epoch: 4726 [512/60000 (1%)] Loss: -1546.503784\n",
      "Train Epoch: 4726 [11776/60000 (20%)] Loss: -1501.819946\n",
      "Train Epoch: 4726 [23040/60000 (38%)] Loss: -1594.051880\n",
      "Train Epoch: 4726 [34304/60000 (57%)] Loss: -1419.074097\n",
      "Train Epoch: 4726 [45568/60000 (76%)] Loss: -1525.492920\n",
      "Train Epoch: 4726 [56832/60000 (95%)] Loss: -1535.510498\n",
      "    epoch          : 4726\n",
      "    loss           : -1545.0823702192577\n",
      "Train Epoch: 4727 [512/60000 (1%)] Loss: -1503.811157\n",
      "Train Epoch: 4727 [11776/60000 (20%)] Loss: -1562.902466\n",
      "Train Epoch: 4727 [23040/60000 (38%)] Loss: -1585.764526\n",
      "Train Epoch: 4727 [34304/60000 (57%)] Loss: -1489.890869\n",
      "Train Epoch: 4727 [45568/60000 (76%)] Loss: -1497.467651\n",
      "Train Epoch: 4727 [56832/60000 (95%)] Loss: -1560.079346\n",
      "    epoch          : 4727\n",
      "    loss           : -1543.5259985627429\n",
      "Train Epoch: 4728 [512/60000 (1%)] Loss: -1599.945312\n",
      "Train Epoch: 4728 [11776/60000 (20%)] Loss: -1539.842285\n",
      "Train Epoch: 4728 [23040/60000 (38%)] Loss: -1565.274170\n",
      "Train Epoch: 4728 [34304/60000 (57%)] Loss: -1480.980225\n",
      "Train Epoch: 4728 [45568/60000 (76%)] Loss: -1445.091919\n",
      "Train Epoch: 4728 [56832/60000 (95%)] Loss: -1594.824341\n",
      "    epoch          : 4728\n",
      "    loss           : -1539.5492008877338\n",
      "Train Epoch: 4729 [512/60000 (1%)] Loss: -1522.234619\n",
      "Train Epoch: 4729 [11776/60000 (20%)] Loss: -1532.037109\n",
      "Train Epoch: 4729 [23040/60000 (38%)] Loss: -1505.149292\n",
      "Train Epoch: 4729 [34304/60000 (57%)] Loss: -1579.736328\n",
      "Train Epoch: 4729 [45568/60000 (76%)] Loss: -1626.192871\n",
      "Train Epoch: 4729 [56832/60000 (95%)] Loss: -1574.101074\n",
      "    epoch          : 4729\n",
      "    loss           : -1540.9517125706216\n",
      "Train Epoch: 4730 [512/60000 (1%)] Loss: -1491.719238\n",
      "Train Epoch: 4730 [11776/60000 (20%)] Loss: -1484.172363\n",
      "Train Epoch: 4730 [23040/60000 (38%)] Loss: -1540.067261\n",
      "Train Epoch: 4730 [34304/60000 (57%)] Loss: -1567.761353\n",
      "Train Epoch: 4730 [45568/60000 (76%)] Loss: -1565.488525\n",
      "Train Epoch: 4730 [56832/60000 (95%)] Loss: -1541.236084\n",
      "    epoch          : 4730\n",
      "    loss           : -1542.8910567289017\n",
      "Train Epoch: 4731 [512/60000 (1%)] Loss: -1620.094727\n",
      "Train Epoch: 4731 [11776/60000 (20%)] Loss: -1560.165161\n",
      "Train Epoch: 4731 [23040/60000 (38%)] Loss: -1567.344238\n",
      "Train Epoch: 4731 [34304/60000 (57%)] Loss: -1456.494141\n",
      "Train Epoch: 4731 [45568/60000 (76%)] Loss: -1482.798950\n",
      "Train Epoch: 4731 [56832/60000 (95%)] Loss: -1482.743774\n",
      "    epoch          : 4731\n",
      "    loss           : -1544.6676570224224\n",
      "Train Epoch: 4732 [512/60000 (1%)] Loss: -1552.327393\n",
      "Train Epoch: 4732 [11776/60000 (20%)] Loss: -1542.990234\n",
      "Train Epoch: 4732 [23040/60000 (38%)] Loss: -1511.092041\n",
      "Train Epoch: 4732 [34304/60000 (57%)] Loss: -1467.518311\n",
      "Train Epoch: 4732 [45568/60000 (76%)] Loss: -1573.636475\n",
      "Train Epoch: 4732 [56832/60000 (95%)] Loss: -1560.231201\n",
      "    epoch          : 4732\n",
      "    loss           : -1547.095577951205\n",
      "Train Epoch: 4733 [512/60000 (1%)] Loss: -1562.379150\n",
      "Train Epoch: 4733 [11776/60000 (20%)] Loss: -1569.992188\n",
      "Train Epoch: 4733 [23040/60000 (38%)] Loss: -1558.936768\n",
      "Train Epoch: 4733 [34304/60000 (57%)] Loss: -1560.135742\n",
      "Train Epoch: 4733 [45568/60000 (76%)] Loss: -1618.297852\n",
      "Train Epoch: 4733 [56832/60000 (95%)] Loss: -1581.384277\n",
      "    epoch          : 4733\n",
      "    loss           : -1543.9847843148616\n",
      "Train Epoch: 4734 [512/60000 (1%)] Loss: -1538.973389\n",
      "Train Epoch: 4734 [11776/60000 (20%)] Loss: -1550.558716\n",
      "Train Epoch: 4734 [23040/60000 (38%)] Loss: -1526.879883\n",
      "Train Epoch: 4734 [34304/60000 (57%)] Loss: -1524.976685\n",
      "Train Epoch: 4734 [45568/60000 (76%)] Loss: -1527.125977\n",
      "Train Epoch: 4734 [56832/60000 (95%)] Loss: -1634.218018\n",
      "    epoch          : 4734\n",
      "    loss           : -1544.8561742750264\n",
      "Train Epoch: 4735 [512/60000 (1%)] Loss: -1563.393311\n",
      "Train Epoch: 4735 [11776/60000 (20%)] Loss: -1551.160889\n",
      "Train Epoch: 4735 [23040/60000 (38%)] Loss: -1523.622314\n",
      "Train Epoch: 4735 [34304/60000 (57%)] Loss: -1423.154785\n",
      "Train Epoch: 4735 [45568/60000 (76%)] Loss: -1542.260864\n",
      "Train Epoch: 4735 [56832/60000 (95%)] Loss: -1578.328735\n",
      "    epoch          : 4735\n",
      "    loss           : -1541.5258992513022\n",
      "Train Epoch: 4736 [512/60000 (1%)] Loss: -1504.723633\n",
      "Train Epoch: 4736 [11776/60000 (20%)] Loss: -1494.042358\n",
      "Train Epoch: 4736 [23040/60000 (38%)] Loss: -1561.272705\n",
      "Train Epoch: 4736 [34304/60000 (57%)] Loss: -1482.263306\n",
      "Train Epoch: 4736 [45568/60000 (76%)] Loss: -1555.318604\n",
      "Train Epoch: 4736 [56832/60000 (95%)] Loss: -1557.595215\n",
      "    epoch          : 4736\n",
      "    loss           : -1545.297278797559\n",
      "Train Epoch: 4737 [512/60000 (1%)] Loss: -1623.090820\n",
      "Train Epoch: 4737 [11776/60000 (20%)] Loss: -1558.691650\n",
      "Train Epoch: 4737 [23040/60000 (38%)] Loss: -1604.630737\n",
      "Train Epoch: 4737 [34304/60000 (57%)] Loss: -1527.648926\n",
      "Train Epoch: 4737 [45568/60000 (76%)] Loss: -1478.269409\n",
      "Train Epoch: 4737 [56832/60000 (95%)] Loss: -1554.074463\n",
      "    epoch          : 4737\n",
      "    loss           : -1551.0468743103372\n",
      "Train Epoch: 4738 [512/60000 (1%)] Loss: -1523.959717\n",
      "Train Epoch: 4738 [11776/60000 (20%)] Loss: -1486.158936\n",
      "Train Epoch: 4738 [23040/60000 (38%)] Loss: -1577.722900\n",
      "Train Epoch: 4738 [34304/60000 (57%)] Loss: -1504.683594\n",
      "Train Epoch: 4738 [45568/60000 (76%)] Loss: -1622.605591\n",
      "Train Epoch: 4738 [56832/60000 (95%)] Loss: -1611.164185\n",
      "    epoch          : 4738\n",
      "    loss           : -1550.6609700520835\n",
      "Train Epoch: 4739 [512/60000 (1%)] Loss: -1484.868896\n",
      "Train Epoch: 4739 [11776/60000 (20%)] Loss: -1590.727051\n",
      "Train Epoch: 4739 [23040/60000 (38%)] Loss: -1498.252563\n",
      "Train Epoch: 4739 [34304/60000 (57%)] Loss: -1563.071411\n",
      "Train Epoch: 4739 [45568/60000 (76%)] Loss: -1539.353394\n",
      "Train Epoch: 4739 [56832/60000 (95%)] Loss: -1501.121094\n",
      "    epoch          : 4739\n",
      "    loss           : -1540.1680273713366\n",
      "Train Epoch: 4740 [512/60000 (1%)] Loss: -1594.191406\n",
      "Train Epoch: 4740 [11776/60000 (20%)] Loss: -1564.004883\n",
      "Train Epoch: 4740 [23040/60000 (38%)] Loss: -1447.585571\n",
      "Train Epoch: 4740 [34304/60000 (57%)] Loss: -1533.676147\n",
      "Train Epoch: 4740 [45568/60000 (76%)] Loss: -1628.205688\n",
      "Train Epoch: 4740 [56832/60000 (95%)] Loss: -1576.126221\n",
      "    epoch          : 4740\n",
      "    loss           : -1539.2452347750045\n",
      "Train Epoch: 4741 [512/60000 (1%)] Loss: -1627.100952\n",
      "Train Epoch: 4741 [11776/60000 (20%)] Loss: -1514.012451\n",
      "Train Epoch: 4741 [23040/60000 (38%)] Loss: -1559.232178\n",
      "Train Epoch: 4741 [34304/60000 (57%)] Loss: -1512.231201\n",
      "Train Epoch: 4741 [45568/60000 (76%)] Loss: -1579.538818\n",
      "Train Epoch: 4741 [56832/60000 (95%)] Loss: -1465.548828\n",
      "    epoch          : 4741\n",
      "    loss           : -1547.1626486912958\n",
      "Train Epoch: 4742 [512/60000 (1%)] Loss: -1562.365234\n",
      "Train Epoch: 4742 [11776/60000 (20%)] Loss: -1482.359863\n",
      "Train Epoch: 4742 [23040/60000 (38%)] Loss: -1570.673584\n",
      "Train Epoch: 4742 [34304/60000 (57%)] Loss: -1469.874878\n",
      "Train Epoch: 4742 [45568/60000 (76%)] Loss: -1530.723877\n",
      "Train Epoch: 4742 [56832/60000 (95%)] Loss: -1584.748047\n",
      "    epoch          : 4742\n",
      "    loss           : -1542.4365592999648\n",
      "Train Epoch: 4743 [512/60000 (1%)] Loss: -1585.357422\n",
      "Train Epoch: 4743 [11776/60000 (20%)] Loss: -1506.299927\n",
      "Train Epoch: 4743 [23040/60000 (38%)] Loss: -1497.916504\n",
      "Train Epoch: 4743 [34304/60000 (57%)] Loss: -1530.272461\n",
      "Train Epoch: 4743 [45568/60000 (76%)] Loss: -1489.780273\n",
      "Train Epoch: 4743 [56832/60000 (95%)] Loss: -1530.004639\n",
      "    epoch          : 4743\n",
      "    loss           : -1542.0071362856418\n",
      "Train Epoch: 4744 [512/60000 (1%)] Loss: -1530.139404\n",
      "Train Epoch: 4744 [11776/60000 (20%)] Loss: -1521.440186\n",
      "Train Epoch: 4744 [23040/60000 (38%)] Loss: -1565.451660\n",
      "Train Epoch: 4744 [34304/60000 (57%)] Loss: -1572.762817\n",
      "Train Epoch: 4744 [45568/60000 (76%)] Loss: -1557.852539\n",
      "Train Epoch: 4744 [56832/60000 (95%)] Loss: -1600.434570\n",
      "    epoch          : 4744\n",
      "    loss           : -1546.2912328687764\n",
      "Train Epoch: 4745 [512/60000 (1%)] Loss: -1547.110596\n",
      "Train Epoch: 4745 [11776/60000 (20%)] Loss: -1572.484497\n",
      "Train Epoch: 4745 [23040/60000 (38%)] Loss: -1502.641846\n",
      "Train Epoch: 4745 [34304/60000 (57%)] Loss: -1455.424194\n",
      "Train Epoch: 4745 [45568/60000 (76%)] Loss: -1596.903198\n",
      "Train Epoch: 4745 [56832/60000 (95%)] Loss: -1562.405884\n",
      "    epoch          : 4745\n",
      "    loss           : -1542.987696071129\n",
      "Train Epoch: 4746 [512/60000 (1%)] Loss: -1602.496094\n",
      "Train Epoch: 4746 [11776/60000 (20%)] Loss: -1496.267700\n",
      "Train Epoch: 4746 [23040/60000 (38%)] Loss: -1484.660889\n",
      "Train Epoch: 4746 [34304/60000 (57%)] Loss: -1556.590942\n",
      "Train Epoch: 4746 [45568/60000 (76%)] Loss: -1585.568848\n",
      "Train Epoch: 4746 [56832/60000 (95%)] Loss: -1595.522461\n",
      "    epoch          : 4746\n",
      "    loss           : -1551.6899896826449\n",
      "Train Epoch: 4747 [512/60000 (1%)] Loss: -1533.123779\n",
      "Train Epoch: 4747 [11776/60000 (20%)] Loss: -1479.983643\n",
      "Train Epoch: 4747 [23040/60000 (38%)] Loss: -1514.720947\n",
      "Train Epoch: 4747 [34304/60000 (57%)] Loss: -1544.809692\n",
      "Train Epoch: 4747 [45568/60000 (76%)] Loss: -1583.685791\n",
      "Train Epoch: 4747 [56832/60000 (95%)] Loss: -1621.484131\n",
      "    epoch          : 4747\n",
      "    loss           : -1540.392681229586\n",
      "Train Epoch: 4748 [512/60000 (1%)] Loss: -1528.733765\n",
      "Train Epoch: 4748 [11776/60000 (20%)] Loss: -1517.355835\n",
      "Train Epoch: 4748 [23040/60000 (38%)] Loss: -1563.617798\n",
      "Train Epoch: 4748 [34304/60000 (57%)] Loss: -1620.756470\n",
      "Train Epoch: 4748 [45568/60000 (76%)] Loss: -1487.845459\n",
      "Train Epoch: 4748 [56832/60000 (95%)] Loss: -1580.443237\n",
      "    epoch          : 4748\n",
      "    loss           : -1538.8815207616083\n",
      "Train Epoch: 4749 [512/60000 (1%)] Loss: -1571.880859\n",
      "Train Epoch: 4749 [11776/60000 (20%)] Loss: -1621.482788\n",
      "Train Epoch: 4749 [23040/60000 (38%)] Loss: -1518.398804\n",
      "Train Epoch: 4749 [34304/60000 (57%)] Loss: -1553.087036\n",
      "Train Epoch: 4749 [45568/60000 (76%)] Loss: -1517.407104\n",
      "Train Epoch: 4749 [56832/60000 (95%)] Loss: -1578.691162\n",
      "    epoch          : 4749\n",
      "    loss           : -1547.9649503029\n",
      "Train Epoch: 4750 [512/60000 (1%)] Loss: -1627.382080\n",
      "Train Epoch: 4750 [11776/60000 (20%)] Loss: -1564.910400\n",
      "Train Epoch: 4750 [23040/60000 (38%)] Loss: -1575.035278\n",
      "Train Epoch: 4750 [34304/60000 (57%)] Loss: -1508.536133\n",
      "Train Epoch: 4750 [45568/60000 (76%)] Loss: -1602.538330\n",
      "Train Epoch: 4750 [56832/60000 (95%)] Loss: -1497.509766\n",
      "    epoch          : 4750\n",
      "    loss           : -1543.4604454256046\n",
      "Train Epoch: 4751 [512/60000 (1%)] Loss: -1453.831421\n",
      "Train Epoch: 4751 [11776/60000 (20%)] Loss: -1572.082275\n",
      "Train Epoch: 4751 [23040/60000 (38%)] Loss: -1596.238281\n",
      "Train Epoch: 4751 [34304/60000 (57%)] Loss: -1617.622070\n",
      "Train Epoch: 4751 [45568/60000 (76%)] Loss: -1585.329590\n",
      "Train Epoch: 4751 [56832/60000 (95%)] Loss: -1481.407715\n",
      "    epoch          : 4751\n",
      "    loss           : -1540.9331858144642\n",
      "Train Epoch: 4752 [512/60000 (1%)] Loss: -1602.787598\n",
      "Train Epoch: 4752 [11776/60000 (20%)] Loss: -1581.693970\n",
      "Train Epoch: 4752 [23040/60000 (38%)] Loss: -1540.046387\n",
      "Train Epoch: 4752 [34304/60000 (57%)] Loss: -1455.470459\n",
      "Train Epoch: 4752 [45568/60000 (76%)] Loss: -1589.087158\n",
      "Train Epoch: 4752 [56832/60000 (95%)] Loss: -1539.946777\n",
      "    epoch          : 4752\n",
      "    loss           : -1542.7323942884886\n",
      "Train Epoch: 4753 [512/60000 (1%)] Loss: -1568.790649\n",
      "Train Epoch: 4753 [11776/60000 (20%)] Loss: -1582.224609\n",
      "Train Epoch: 4753 [23040/60000 (38%)] Loss: -1626.585938\n",
      "Train Epoch: 4753 [34304/60000 (57%)] Loss: -1600.326904\n",
      "Train Epoch: 4753 [45568/60000 (76%)] Loss: -1598.751465\n",
      "Train Epoch: 4753 [56832/60000 (95%)] Loss: -1514.230591\n",
      "    epoch          : 4753\n",
      "    loss           : -1555.309184101342\n",
      "Train Epoch: 4754 [512/60000 (1%)] Loss: -1508.586548\n",
      "Train Epoch: 4754 [11776/60000 (20%)] Loss: -1574.283569\n",
      "Train Epoch: 4754 [23040/60000 (38%)] Loss: -1484.283447\n",
      "Train Epoch: 4754 [34304/60000 (57%)] Loss: -1628.423828\n",
      "Train Epoch: 4754 [45568/60000 (76%)] Loss: -1506.789062\n",
      "Train Epoch: 4754 [56832/60000 (95%)] Loss: -1547.055786\n",
      "    epoch          : 4754\n",
      "    loss           : -1544.6217406536898\n",
      "Train Epoch: 4755 [512/60000 (1%)] Loss: -1614.109497\n",
      "Train Epoch: 4755 [11776/60000 (20%)] Loss: -1550.457764\n",
      "Train Epoch: 4755 [23040/60000 (38%)] Loss: -1520.693848\n",
      "Train Epoch: 4755 [34304/60000 (57%)] Loss: -1549.820068\n",
      "Train Epoch: 4755 [45568/60000 (76%)] Loss: -1610.366699\n",
      "Train Epoch: 4755 [56832/60000 (95%)] Loss: -1572.516968\n",
      "    epoch          : 4755\n",
      "    loss           : -1542.112746071681\n",
      "Train Epoch: 4756 [512/60000 (1%)] Loss: -1592.807373\n",
      "Train Epoch: 4756 [11776/60000 (20%)] Loss: -1506.124634\n",
      "Train Epoch: 4756 [23040/60000 (38%)] Loss: -1538.597290\n",
      "Train Epoch: 4756 [34304/60000 (57%)] Loss: -1485.139648\n",
      "Train Epoch: 4756 [45568/60000 (76%)] Loss: -1581.859253\n",
      "Train Epoch: 4756 [56832/60000 (95%)] Loss: -1551.654053\n",
      "    epoch          : 4756\n",
      "    loss           : -1543.9757611118466\n",
      "Train Epoch: 4757 [512/60000 (1%)] Loss: -1555.123047\n",
      "Train Epoch: 4757 [11776/60000 (20%)] Loss: -1624.633057\n",
      "Train Epoch: 4757 [23040/60000 (38%)] Loss: -1572.401611\n",
      "Train Epoch: 4757 [34304/60000 (57%)] Loss: -1450.557251\n",
      "Train Epoch: 4757 [45568/60000 (76%)] Loss: -1517.492065\n",
      "Train Epoch: 4757 [56832/60000 (95%)] Loss: -1591.197388\n",
      "    epoch          : 4757\n",
      "    loss           : -1541.7684757211116\n",
      "Train Epoch: 4758 [512/60000 (1%)] Loss: -1475.962769\n",
      "Train Epoch: 4758 [11776/60000 (20%)] Loss: -1509.987427\n",
      "Train Epoch: 4758 [23040/60000 (38%)] Loss: -1540.619751\n",
      "Train Epoch: 4758 [34304/60000 (57%)] Loss: -1585.056274\n",
      "Train Epoch: 4758 [45568/60000 (76%)] Loss: -1607.475586\n",
      "Train Epoch: 4758 [56832/60000 (95%)] Loss: -1574.428223\n",
      "    epoch          : 4758\n",
      "    loss           : -1546.2645870575125\n",
      "Train Epoch: 4759 [512/60000 (1%)] Loss: -1506.667725\n",
      "Train Epoch: 4759 [11776/60000 (20%)] Loss: -1520.086670\n",
      "Train Epoch: 4759 [23040/60000 (38%)] Loss: -1472.107544\n",
      "Train Epoch: 4759 [34304/60000 (57%)] Loss: -1531.463135\n",
      "Train Epoch: 4759 [45568/60000 (76%)] Loss: -1500.896851\n",
      "Train Epoch: 4759 [56832/60000 (95%)] Loss: -1525.803223\n",
      "    epoch          : 4759\n",
      "    loss           : -1544.67655953445\n",
      "Train Epoch: 4760 [512/60000 (1%)] Loss: -1490.142212\n",
      "Train Epoch: 4760 [11776/60000 (20%)] Loss: -1606.861694\n",
      "Train Epoch: 4760 [23040/60000 (38%)] Loss: -1582.447021\n",
      "Train Epoch: 4760 [34304/60000 (57%)] Loss: -1611.243896\n",
      "Train Epoch: 4760 [45568/60000 (76%)] Loss: -1548.608643\n",
      "Train Epoch: 4760 [56832/60000 (95%)] Loss: -1505.667236\n",
      "    epoch          : 4760\n",
      "    loss           : -1548.2363470907264\n",
      "Train Epoch: 4761 [512/60000 (1%)] Loss: -1520.470215\n",
      "Train Epoch: 4761 [11776/60000 (20%)] Loss: -1588.512329\n",
      "Train Epoch: 4761 [23040/60000 (38%)] Loss: -1601.517700\n",
      "Train Epoch: 4761 [34304/60000 (57%)] Loss: -1558.090210\n",
      "Train Epoch: 4761 [45568/60000 (76%)] Loss: -1547.631836\n",
      "Train Epoch: 4761 [56832/60000 (95%)] Loss: -1635.213379\n",
      "    epoch          : 4761\n",
      "    loss           : -1550.1827651201668\n",
      "Train Epoch: 4762 [512/60000 (1%)] Loss: -1581.253540\n",
      "Train Epoch: 4762 [11776/60000 (20%)] Loss: -1544.475830\n",
      "Train Epoch: 4762 [23040/60000 (38%)] Loss: -1587.957031\n",
      "Train Epoch: 4762 [34304/60000 (57%)] Loss: -1511.170044\n",
      "Train Epoch: 4762 [45568/60000 (76%)] Loss: -1526.048706\n",
      "Train Epoch: 4762 [56832/60000 (95%)] Loss: -1543.593872\n",
      "    epoch          : 4762\n",
      "    loss           : -1544.6535534185205\n",
      "Train Epoch: 4763 [512/60000 (1%)] Loss: -1557.509033\n",
      "Train Epoch: 4763 [11776/60000 (20%)] Loss: -1501.738770\n",
      "Train Epoch: 4763 [23040/60000 (38%)] Loss: -1585.336182\n",
      "Train Epoch: 4763 [34304/60000 (57%)] Loss: -1567.909302\n",
      "Train Epoch: 4763 [45568/60000 (76%)] Loss: -1464.717041\n",
      "Train Epoch: 4763 [56832/60000 (95%)] Loss: -1592.210083\n",
      "    epoch          : 4763\n",
      "    loss           : -1547.7404588602358\n",
      "Train Epoch: 4764 [512/60000 (1%)] Loss: -1562.775024\n",
      "Train Epoch: 4764 [11776/60000 (20%)] Loss: -1606.037109\n",
      "Train Epoch: 4764 [23040/60000 (38%)] Loss: -1552.315918\n",
      "Train Epoch: 4764 [34304/60000 (57%)] Loss: -1598.848755\n",
      "Train Epoch: 4764 [45568/60000 (76%)] Loss: -1517.233398\n",
      "Train Epoch: 4764 [56832/60000 (95%)] Loss: -1504.678223\n",
      "    epoch          : 4764\n",
      "    loss           : -1547.7096326580156\n",
      "Train Epoch: 4765 [512/60000 (1%)] Loss: -1515.270752\n",
      "Train Epoch: 4765 [11776/60000 (20%)] Loss: -1608.424805\n",
      "Train Epoch: 4765 [23040/60000 (38%)] Loss: -1577.478516\n",
      "Train Epoch: 4765 [34304/60000 (57%)] Loss: -1552.109619\n",
      "Train Epoch: 4765 [45568/60000 (76%)] Loss: -1527.525635\n",
      "Train Epoch: 4765 [56832/60000 (95%)] Loss: -1505.833008\n",
      "    epoch          : 4765\n",
      "    loss           : -1547.6263500148966\n",
      "Train Epoch: 4766 [512/60000 (1%)] Loss: -1543.754639\n",
      "Train Epoch: 4766 [11776/60000 (20%)] Loss: -1545.071045\n",
      "Train Epoch: 4766 [23040/60000 (38%)] Loss: -1578.704712\n",
      "Train Epoch: 4766 [34304/60000 (57%)] Loss: -1548.972900\n",
      "Train Epoch: 4766 [45568/60000 (76%)] Loss: -1472.729370\n",
      "Train Epoch: 4766 [56832/60000 (95%)] Loss: -1575.848877\n",
      "    epoch          : 4766\n",
      "    loss           : -1543.6348173497088\n",
      "Train Epoch: 4767 [512/60000 (1%)] Loss: -1553.242432\n",
      "Train Epoch: 4767 [11776/60000 (20%)] Loss: -1559.399170\n",
      "Train Epoch: 4767 [23040/60000 (38%)] Loss: -1554.775635\n",
      "Train Epoch: 4767 [34304/60000 (57%)] Loss: -1573.150635\n",
      "Train Epoch: 4767 [45568/60000 (76%)] Loss: -1542.937378\n",
      "Train Epoch: 4767 [56832/60000 (95%)] Loss: -1619.885742\n",
      "    epoch          : 4767\n",
      "    loss           : -1541.0615430928892\n",
      "Train Epoch: 4768 [512/60000 (1%)] Loss: -1519.373047\n",
      "Train Epoch: 4768 [11776/60000 (20%)] Loss: -1555.276489\n",
      "Train Epoch: 4768 [23040/60000 (38%)] Loss: -1482.977295\n",
      "Train Epoch: 4768 [34304/60000 (57%)] Loss: -1580.579834\n",
      "Train Epoch: 4768 [45568/60000 (76%)] Loss: -1535.518555\n",
      "Train Epoch: 4768 [56832/60000 (95%)] Loss: -1456.110840\n",
      "    epoch          : 4768\n",
      "    loss           : -1536.5205188471045\n",
      "Train Epoch: 4769 [512/60000 (1%)] Loss: -1577.739868\n",
      "Train Epoch: 4769 [11776/60000 (20%)] Loss: -1487.073975\n",
      "Train Epoch: 4769 [23040/60000 (38%)] Loss: -1508.693115\n",
      "Train Epoch: 4769 [34304/60000 (57%)] Loss: -1619.839966\n",
      "Train Epoch: 4769 [45568/60000 (76%)] Loss: -1584.552612\n",
      "Train Epoch: 4769 [56832/60000 (95%)] Loss: -1516.372925\n",
      "    epoch          : 4769\n",
      "    loss           : -1536.8204814673816\n",
      "Train Epoch: 4770 [512/60000 (1%)] Loss: -1598.203613\n",
      "Train Epoch: 4770 [11776/60000 (20%)] Loss: -1568.826172\n",
      "Train Epoch: 4770 [23040/60000 (38%)] Loss: -1584.539795\n",
      "Train Epoch: 4770 [34304/60000 (57%)] Loss: -1455.705811\n",
      "Train Epoch: 4770 [45568/60000 (76%)] Loss: -1600.543091\n",
      "Train Epoch: 4770 [56832/60000 (95%)] Loss: -1537.338135\n",
      "    epoch          : 4770\n",
      "    loss           : -1541.0184671003265\n",
      "Train Epoch: 4771 [512/60000 (1%)] Loss: -1531.679321\n",
      "Train Epoch: 4771 [11776/60000 (20%)] Loss: -1510.193604\n",
      "Train Epoch: 4771 [23040/60000 (38%)] Loss: -1588.499023\n",
      "Train Epoch: 4771 [34304/60000 (57%)] Loss: -1626.342163\n",
      "Train Epoch: 4771 [45568/60000 (76%)] Loss: -1513.765137\n",
      "Train Epoch: 4771 [56832/60000 (95%)] Loss: -1444.402222\n",
      "    epoch          : 4771\n",
      "    loss           : -1547.5552999205509\n",
      "Train Epoch: 4772 [512/60000 (1%)] Loss: -1550.918945\n",
      "Train Epoch: 4772 [11776/60000 (20%)] Loss: -1505.859497\n",
      "Train Epoch: 4772 [23040/60000 (38%)] Loss: -1553.114014\n",
      "Train Epoch: 4772 [34304/60000 (57%)] Loss: -1548.641113\n",
      "Train Epoch: 4772 [45568/60000 (76%)] Loss: -1545.029541\n",
      "Train Epoch: 4772 [56832/60000 (95%)] Loss: -1610.882568\n",
      "    epoch          : 4772\n",
      "    loss           : -1545.4654434117895\n",
      "Train Epoch: 4773 [512/60000 (1%)] Loss: -1512.620850\n",
      "Train Epoch: 4773 [11776/60000 (20%)] Loss: -1535.207764\n",
      "Train Epoch: 4773 [23040/60000 (38%)] Loss: -1519.270020\n",
      "Train Epoch: 4773 [34304/60000 (57%)] Loss: -1464.093384\n",
      "Train Epoch: 4773 [45568/60000 (76%)] Loss: -1547.543701\n",
      "Train Epoch: 4773 [56832/60000 (95%)] Loss: -1576.479736\n",
      "    epoch          : 4773\n",
      "    loss           : -1537.4855222540386\n",
      "Train Epoch: 4774 [512/60000 (1%)] Loss: -1586.427246\n",
      "Train Epoch: 4774 [11776/60000 (20%)] Loss: -1553.697510\n",
      "Train Epoch: 4774 [23040/60000 (38%)] Loss: -1511.458496\n",
      "Train Epoch: 4774 [34304/60000 (57%)] Loss: -1497.994385\n",
      "Train Epoch: 4774 [45568/60000 (76%)] Loss: -1511.894287\n",
      "Train Epoch: 4774 [56832/60000 (95%)] Loss: -1511.071045\n",
      "    epoch          : 4774\n",
      "    loss           : -1536.5152898238878\n",
      "Train Epoch: 4775 [512/60000 (1%)] Loss: -1503.612549\n",
      "Train Epoch: 4775 [11776/60000 (20%)] Loss: -1527.253784\n",
      "Train Epoch: 4775 [23040/60000 (38%)] Loss: -1586.595459\n",
      "Train Epoch: 4775 [34304/60000 (57%)] Loss: -1489.228027\n",
      "Train Epoch: 4775 [45568/60000 (76%)] Loss: -1490.517456\n",
      "Train Epoch: 4775 [56832/60000 (95%)] Loss: -1631.378174\n",
      "    epoch          : 4775\n",
      "    loss           : -1543.28282139665\n",
      "Train Epoch: 4776 [512/60000 (1%)] Loss: -1589.589600\n",
      "Train Epoch: 4776 [11776/60000 (20%)] Loss: -1535.926147\n",
      "Train Epoch: 4776 [23040/60000 (38%)] Loss: -1466.596558\n",
      "Train Epoch: 4776 [34304/60000 (57%)] Loss: -1583.280029\n",
      "Train Epoch: 4776 [45568/60000 (76%)] Loss: -1550.371460\n",
      "Train Epoch: 4776 [56832/60000 (95%)] Loss: -1555.571655\n",
      "    epoch          : 4776\n",
      "    loss           : -1543.2434199273923\n",
      "Train Epoch: 4777 [512/60000 (1%)] Loss: -1501.447144\n",
      "Train Epoch: 4777 [11776/60000 (20%)] Loss: -1549.571045\n",
      "Train Epoch: 4777 [23040/60000 (38%)] Loss: -1564.649902\n",
      "Train Epoch: 4777 [34304/60000 (57%)] Loss: -1533.146973\n",
      "Train Epoch: 4777 [45568/60000 (76%)] Loss: -1448.775146\n",
      "Train Epoch: 4777 [56832/60000 (95%)] Loss: -1499.987305\n",
      "    epoch          : 4777\n",
      "    loss           : -1548.332870224775\n",
      "Train Epoch: 4778 [512/60000 (1%)] Loss: -1530.413330\n",
      "Train Epoch: 4778 [11776/60000 (20%)] Loss: -1609.944580\n",
      "Train Epoch: 4778 [23040/60000 (38%)] Loss: -1422.962280\n",
      "Train Epoch: 4778 [34304/60000 (57%)] Loss: -1552.303223\n",
      "Train Epoch: 4778 [45568/60000 (76%)] Loss: -1513.279785\n",
      "Train Epoch: 4778 [56832/60000 (95%)] Loss: -1589.962769\n",
      "    epoch          : 4778\n",
      "    loss           : -1543.8138341526528\n",
      "Train Epoch: 4779 [512/60000 (1%)] Loss: -1611.275635\n",
      "Train Epoch: 4779 [11776/60000 (20%)] Loss: -1547.069946\n",
      "Train Epoch: 4779 [23040/60000 (38%)] Loss: -1529.770874\n",
      "Train Epoch: 4779 [34304/60000 (57%)] Loss: -1596.387939\n",
      "Train Epoch: 4779 [45568/60000 (76%)] Loss: -1544.013184\n",
      "Train Epoch: 4779 [56832/60000 (95%)] Loss: -1608.482178\n",
      "    epoch          : 4779\n",
      "    loss           : -1547.5693138682911\n",
      "Train Epoch: 4780 [512/60000 (1%)] Loss: -1548.726318\n",
      "Train Epoch: 4780 [11776/60000 (20%)] Loss: -1502.926636\n",
      "Train Epoch: 4780 [23040/60000 (38%)] Loss: -1556.168335\n",
      "Train Epoch: 4780 [34304/60000 (57%)] Loss: -1501.670044\n",
      "Train Epoch: 4780 [45568/60000 (76%)] Loss: -1572.934570\n",
      "Train Epoch: 4780 [56832/60000 (95%)] Loss: -1649.176880\n",
      "    epoch          : 4780\n",
      "    loss           : -1546.81483485335\n",
      "Train Epoch: 4781 [512/60000 (1%)] Loss: -1558.670654\n",
      "Train Epoch: 4781 [11776/60000 (20%)] Loss: -1511.192627\n",
      "Train Epoch: 4781 [23040/60000 (38%)] Loss: -1608.162109\n",
      "Train Epoch: 4781 [34304/60000 (57%)] Loss: -1552.539551\n",
      "Train Epoch: 4781 [45568/60000 (76%)] Loss: -1566.096802\n",
      "Train Epoch: 4781 [56832/60000 (95%)] Loss: -1576.640259\n",
      "    epoch          : 4781\n",
      "    loss           : -1545.3613208835409\n",
      "Train Epoch: 4782 [512/60000 (1%)] Loss: -1547.043701\n",
      "Train Epoch: 4782 [11776/60000 (20%)] Loss: -1573.547852\n",
      "Train Epoch: 4782 [23040/60000 (38%)] Loss: -1563.241699\n",
      "Train Epoch: 4782 [34304/60000 (57%)] Loss: -1573.346436\n",
      "Train Epoch: 4782 [45568/60000 (76%)] Loss: -1462.859253\n",
      "Train Epoch: 4782 [56832/60000 (95%)] Loss: -1527.662720\n",
      "    epoch          : 4782\n",
      "    loss           : -1541.8297526041665\n",
      "Train Epoch: 4783 [512/60000 (1%)] Loss: -1610.484619\n",
      "Train Epoch: 4783 [11776/60000 (20%)] Loss: -1616.910889\n",
      "Train Epoch: 4783 [23040/60000 (38%)] Loss: -1545.671265\n",
      "Train Epoch: 4783 [34304/60000 (57%)] Loss: -1558.167236\n",
      "Train Epoch: 4783 [45568/60000 (76%)] Loss: -1497.772949\n",
      "Train Epoch: 4783 [56832/60000 (95%)] Loss: -1537.863037\n",
      "    epoch          : 4783\n",
      "    loss           : -1544.4089189949682\n",
      "Train Epoch: 4784 [512/60000 (1%)] Loss: -1478.442139\n",
      "Train Epoch: 4784 [11776/60000 (20%)] Loss: -1513.279053\n",
      "Train Epoch: 4784 [23040/60000 (38%)] Loss: -1419.200928\n",
      "Train Epoch: 4784 [34304/60000 (57%)] Loss: -1518.176025\n",
      "Train Epoch: 4784 [45568/60000 (76%)] Loss: -1415.961426\n",
      "Train Epoch: 4784 [56832/60000 (95%)] Loss: -1532.889160\n",
      "    epoch          : 4784\n",
      "    loss           : -1537.0957479530807\n",
      "Train Epoch: 4785 [512/60000 (1%)] Loss: -1568.522827\n",
      "Train Epoch: 4785 [11776/60000 (20%)] Loss: -1585.286255\n",
      "Train Epoch: 4785 [23040/60000 (38%)] Loss: -1556.750610\n",
      "Train Epoch: 4785 [34304/60000 (57%)] Loss: -1495.916382\n",
      "Train Epoch: 4785 [45568/60000 (76%)] Loss: -1539.846924\n",
      "Train Epoch: 4785 [56832/60000 (95%)] Loss: -1493.878784\n",
      "    epoch          : 4785\n",
      "    loss           : -1536.7007660084525\n",
      "Train Epoch: 4786 [512/60000 (1%)] Loss: -1517.693848\n",
      "Train Epoch: 4786 [11776/60000 (20%)] Loss: -1520.450073\n",
      "Train Epoch: 4786 [23040/60000 (38%)] Loss: -1536.217773\n",
      "Train Epoch: 4786 [34304/60000 (57%)] Loss: -1543.789551\n",
      "Train Epoch: 4786 [45568/60000 (76%)] Loss: -1576.785400\n",
      "Train Epoch: 4786 [56832/60000 (95%)] Loss: -1574.224854\n",
      "    epoch          : 4786\n",
      "    loss           : -1545.1249848274188\n",
      "Train Epoch: 4787 [512/60000 (1%)] Loss: -1523.951416\n",
      "Train Epoch: 4787 [11776/60000 (20%)] Loss: -1458.868286\n",
      "Train Epoch: 4787 [23040/60000 (38%)] Loss: -1564.812256\n",
      "Train Epoch: 4787 [34304/60000 (57%)] Loss: -1574.911255\n",
      "Train Epoch: 4787 [45568/60000 (76%)] Loss: -1580.076172\n",
      "Train Epoch: 4787 [56832/60000 (95%)] Loss: -1546.321777\n",
      "    epoch          : 4787\n",
      "    loss           : -1541.6534096238302\n",
      "Train Epoch: 4788 [512/60000 (1%)] Loss: -1634.110352\n",
      "Train Epoch: 4788 [11776/60000 (20%)] Loss: -1578.497192\n",
      "Train Epoch: 4788 [23040/60000 (38%)] Loss: -1585.217529\n",
      "Train Epoch: 4788 [34304/60000 (57%)] Loss: -1504.010254\n",
      "Train Epoch: 4788 [45568/60000 (76%)] Loss: -1539.427979\n",
      "Train Epoch: 4788 [56832/60000 (95%)] Loss: -1545.791382\n",
      "    epoch          : 4788\n",
      "    loss           : -1542.3409265205685\n",
      "Train Epoch: 4789 [512/60000 (1%)] Loss: -1456.916870\n",
      "Train Epoch: 4789 [11776/60000 (20%)] Loss: -1534.985596\n",
      "Train Epoch: 4789 [23040/60000 (38%)] Loss: -1542.036621\n",
      "Train Epoch: 4789 [34304/60000 (57%)] Loss: -1584.339355\n",
      "Train Epoch: 4789 [45568/60000 (76%)] Loss: -1611.593750\n",
      "Train Epoch: 4789 [56832/60000 (95%)] Loss: -1412.712646\n",
      "    epoch          : 4789\n",
      "    loss           : -1541.1365021958864\n",
      "Train Epoch: 4790 [512/60000 (1%)] Loss: -1556.202393\n",
      "Train Epoch: 4790 [11776/60000 (20%)] Loss: -1608.816650\n",
      "Train Epoch: 4790 [23040/60000 (38%)] Loss: -1564.042847\n",
      "Train Epoch: 4790 [34304/60000 (57%)] Loss: -1560.855225\n",
      "Train Epoch: 4790 [45568/60000 (76%)] Loss: -1438.862183\n",
      "Train Epoch: 4790 [56832/60000 (95%)] Loss: -1544.502686\n",
      "    epoch          : 4790\n",
      "    loss           : -1546.8521911276264\n",
      "Train Epoch: 4791 [512/60000 (1%)] Loss: -1553.056396\n",
      "Train Epoch: 4791 [11776/60000 (20%)] Loss: -1568.478638\n",
      "Train Epoch: 4791 [23040/60000 (38%)] Loss: -1596.267212\n",
      "Train Epoch: 4791 [34304/60000 (57%)] Loss: -1534.080322\n",
      "Train Epoch: 4791 [45568/60000 (76%)] Loss: -1583.438477\n",
      "Train Epoch: 4791 [56832/60000 (95%)] Loss: -1429.617432\n",
      "    epoch          : 4791\n",
      "    loss           : -1546.4837177513684\n",
      "Train Epoch: 4792 [512/60000 (1%)] Loss: -1587.569458\n",
      "Train Epoch: 4792 [11776/60000 (20%)] Loss: -1543.882568\n",
      "Train Epoch: 4792 [23040/60000 (38%)] Loss: -1543.615479\n",
      "Train Epoch: 4792 [34304/60000 (57%)] Loss: -1572.449341\n",
      "Train Epoch: 4792 [45568/60000 (76%)] Loss: -1549.316406\n",
      "Train Epoch: 4792 [56832/60000 (95%)] Loss: -1542.793213\n",
      "    epoch          : 4792\n",
      "    loss           : -1542.8549711583025\n",
      "Train Epoch: 4793 [512/60000 (1%)] Loss: -1503.223877\n",
      "Train Epoch: 4793 [11776/60000 (20%)] Loss: -1577.381226\n",
      "Train Epoch: 4793 [23040/60000 (38%)] Loss: -1514.624512\n",
      "Train Epoch: 4793 [34304/60000 (57%)] Loss: -1499.702271\n",
      "Train Epoch: 4793 [45568/60000 (76%)] Loss: -1552.355225\n",
      "Train Epoch: 4793 [56832/60000 (95%)] Loss: -1531.635010\n",
      "    epoch          : 4793\n",
      "    loss           : -1541.8229921847412\n",
      "Train Epoch: 4794 [512/60000 (1%)] Loss: -1582.390381\n",
      "Train Epoch: 4794 [11776/60000 (20%)] Loss: -1546.045776\n",
      "Train Epoch: 4794 [23040/60000 (38%)] Loss: -1534.007690\n",
      "Train Epoch: 4794 [34304/60000 (57%)] Loss: -1531.163208\n",
      "Train Epoch: 4794 [45568/60000 (76%)] Loss: -1531.596924\n",
      "Train Epoch: 4794 [56832/60000 (95%)] Loss: -1546.447388\n",
      "    epoch          : 4794\n",
      "    loss           : -1544.4606212896142\n",
      "Train Epoch: 4795 [512/60000 (1%)] Loss: -1569.521606\n",
      "Train Epoch: 4795 [11776/60000 (20%)] Loss: -1554.741699\n",
      "Train Epoch: 4795 [23040/60000 (38%)] Loss: -1522.759033\n",
      "Train Epoch: 4795 [34304/60000 (57%)] Loss: -1586.478882\n",
      "Train Epoch: 4795 [45568/60000 (76%)] Loss: -1569.993164\n",
      "Train Epoch: 4795 [56832/60000 (95%)] Loss: -1620.834351\n",
      "    epoch          : 4795\n",
      "    loss           : -1541.1182033732787\n",
      "Train Epoch: 4796 [512/60000 (1%)] Loss: -1576.695312\n",
      "Train Epoch: 4796 [11776/60000 (20%)] Loss: -1486.767700\n",
      "Train Epoch: 4796 [23040/60000 (38%)] Loss: -1506.576294\n",
      "Train Epoch: 4796 [34304/60000 (57%)] Loss: -1521.597290\n",
      "Train Epoch: 4796 [45568/60000 (76%)] Loss: -1509.679932\n",
      "Train Epoch: 4796 [56832/60000 (95%)] Loss: -1520.881958\n",
      "    epoch          : 4796\n",
      "    loss           : -1546.7756730419094\n",
      "Train Epoch: 4797 [512/60000 (1%)] Loss: -1488.555420\n",
      "Train Epoch: 4797 [11776/60000 (20%)] Loss: -1548.214966\n",
      "Train Epoch: 4797 [23040/60000 (38%)] Loss: -1528.640625\n",
      "Train Epoch: 4797 [34304/60000 (57%)] Loss: -1562.261719\n",
      "Train Epoch: 4797 [45568/60000 (76%)] Loss: -1525.474365\n",
      "Train Epoch: 4797 [56832/60000 (95%)] Loss: -1508.536743\n",
      "    epoch          : 4797\n",
      "    loss           : -1543.4444966289282\n",
      "Train Epoch: 4798 [512/60000 (1%)] Loss: -1566.460083\n",
      "Train Epoch: 4798 [11776/60000 (20%)] Loss: -1585.363037\n",
      "Train Epoch: 4798 [23040/60000 (38%)] Loss: -1588.869995\n",
      "Train Epoch: 4798 [34304/60000 (57%)] Loss: -1552.076416\n",
      "Train Epoch: 4798 [45568/60000 (76%)] Loss: -1627.281250\n",
      "Train Epoch: 4798 [56832/60000 (95%)] Loss: -1635.474365\n",
      "    epoch          : 4798\n",
      "    loss           : -1546.5462436137227\n",
      "Train Epoch: 4799 [512/60000 (1%)] Loss: -1618.057007\n",
      "Train Epoch: 4799 [11776/60000 (20%)] Loss: -1439.854858\n",
      "Train Epoch: 4799 [23040/60000 (38%)] Loss: -1516.101807\n",
      "Train Epoch: 4799 [34304/60000 (57%)] Loss: -1561.278809\n",
      "Train Epoch: 4799 [45568/60000 (76%)] Loss: -1471.287598\n",
      "Train Epoch: 4799 [56832/60000 (95%)] Loss: -1534.965088\n",
      "    epoch          : 4799\n",
      "    loss           : -1539.1075460143009\n",
      "Train Epoch: 4800 [512/60000 (1%)] Loss: -1569.274170\n",
      "Train Epoch: 4800 [11776/60000 (20%)] Loss: -1544.108276\n",
      "Train Epoch: 4800 [23040/60000 (38%)] Loss: -1556.749512\n",
      "Train Epoch: 4800 [34304/60000 (57%)] Loss: -1519.129395\n",
      "Train Epoch: 4800 [45568/60000 (76%)] Loss: -1607.894165\n",
      "Train Epoch: 4800 [56832/60000 (95%)] Loss: -1553.277954\n",
      "    epoch          : 4800\n",
      "    loss           : -1549.7434378586247\n",
      "Saving checkpoint: saved/models/Mnist_DeepGenerativeOperad/0127_111843/checkpoint-epoch4800.pth ...\n",
      "Train Epoch: 4801 [512/60000 (1%)] Loss: -1586.989990\n",
      "Train Epoch: 4801 [11776/60000 (20%)] Loss: -1574.843262\n",
      "Train Epoch: 4801 [23040/60000 (38%)] Loss: -1555.475952\n",
      "Train Epoch: 4801 [34304/60000 (57%)] Loss: -1576.072510\n",
      "Train Epoch: 4801 [45568/60000 (76%)] Loss: -1589.143677\n",
      "Train Epoch: 4801 [56832/60000 (95%)] Loss: -1562.656982\n",
      "    epoch          : 4801\n",
      "    loss           : -1547.3213600977667\n",
      "Train Epoch: 4802 [512/60000 (1%)] Loss: -1613.704102\n",
      "Train Epoch: 4802 [11776/60000 (20%)] Loss: -1493.193481\n",
      "Train Epoch: 4802 [23040/60000 (38%)] Loss: -1553.028564\n",
      "Train Epoch: 4802 [34304/60000 (57%)] Loss: -1535.446533\n",
      "Train Epoch: 4802 [45568/60000 (76%)] Loss: -1477.589600\n",
      "Train Epoch: 4802 [56832/60000 (95%)] Loss: -1619.976807\n",
      "    epoch          : 4802\n",
      "    loss           : -1549.4002006229034\n",
      "Train Epoch: 4803 [512/60000 (1%)] Loss: -1547.779053\n",
      "Train Epoch: 4803 [11776/60000 (20%)] Loss: -1538.171143\n",
      "Train Epoch: 4803 [23040/60000 (38%)] Loss: -1581.588501\n",
      "Train Epoch: 4803 [34304/60000 (57%)] Loss: -1511.039551\n",
      "Train Epoch: 4803 [45568/60000 (76%)] Loss: -1515.669556\n",
      "Train Epoch: 4803 [56832/60000 (95%)] Loss: -1548.790771\n",
      "    epoch          : 4803\n",
      "    loss           : -1543.479532877604\n",
      "Train Epoch: 4804 [512/60000 (1%)] Loss: -1607.543335\n",
      "Train Epoch: 4804 [11776/60000 (20%)] Loss: -1558.719727\n",
      "Train Epoch: 4804 [23040/60000 (38%)] Loss: -1411.798584\n",
      "Train Epoch: 4804 [34304/60000 (57%)] Loss: -1597.347168\n",
      "Train Epoch: 4804 [45568/60000 (76%)] Loss: -1489.778442\n",
      "Train Epoch: 4804 [56832/60000 (95%)] Loss: -1542.822266\n",
      "    epoch          : 4804\n",
      "    loss           : -1544.2821893207097\n",
      "Train Epoch: 4805 [512/60000 (1%)] Loss: -1501.703857\n",
      "Train Epoch: 4805 [11776/60000 (20%)] Loss: -1536.188477\n",
      "Train Epoch: 4805 [23040/60000 (38%)] Loss: -1526.976685\n",
      "Train Epoch: 4805 [34304/60000 (57%)] Loss: -1533.405640\n",
      "Train Epoch: 4805 [45568/60000 (76%)] Loss: -1570.838623\n",
      "Train Epoch: 4805 [56832/60000 (95%)] Loss: -1583.302734\n",
      "    epoch          : 4805\n",
      "    loss           : -1550.9200304968883\n",
      "Train Epoch: 4806 [512/60000 (1%)] Loss: -1614.285645\n",
      "Train Epoch: 4806 [11776/60000 (20%)] Loss: -1493.626343\n",
      "Train Epoch: 4806 [23040/60000 (38%)] Loss: -1579.735352\n",
      "Train Epoch: 4806 [34304/60000 (57%)] Loss: -1599.588135\n",
      "Train Epoch: 4806 [45568/60000 (76%)] Loss: -1562.676880\n",
      "Train Epoch: 4806 [56832/60000 (95%)] Loss: -1521.721558\n",
      "    epoch          : 4806\n",
      "    loss           : -1542.7626380704892\n",
      "Train Epoch: 4807 [512/60000 (1%)] Loss: -1613.138184\n",
      "Train Epoch: 4807 [11776/60000 (20%)] Loss: -1540.268555\n",
      "Train Epoch: 4807 [23040/60000 (38%)] Loss: -1573.037598\n",
      "Train Epoch: 4807 [34304/60000 (57%)] Loss: -1524.870239\n",
      "Train Epoch: 4807 [45568/60000 (76%)] Loss: -1600.931641\n",
      "Train Epoch: 4807 [56832/60000 (95%)] Loss: -1627.331787\n",
      "    epoch          : 4807\n",
      "    loss           : -1545.0896596100372\n",
      "Train Epoch: 4808 [512/60000 (1%)] Loss: -1545.019287\n",
      "Train Epoch: 4808 [11776/60000 (20%)] Loss: -1486.644287\n",
      "Train Epoch: 4808 [23040/60000 (38%)] Loss: -1541.181152\n",
      "Train Epoch: 4808 [34304/60000 (57%)] Loss: -1468.193970\n",
      "Train Epoch: 4808 [45568/60000 (76%)] Loss: -1476.203003\n",
      "Train Epoch: 4808 [56832/60000 (95%)] Loss: -1503.498291\n",
      "    epoch          : 4808\n",
      "    loss           : -1538.580936410333\n",
      "Train Epoch: 4809 [512/60000 (1%)] Loss: -1531.168457\n",
      "Train Epoch: 4809 [11776/60000 (20%)] Loss: -1545.737915\n",
      "Train Epoch: 4809 [23040/60000 (38%)] Loss: -1572.583252\n",
      "Train Epoch: 4809 [34304/60000 (57%)] Loss: -1548.883545\n",
      "Train Epoch: 4809 [45568/60000 (76%)] Loss: -1548.097900\n",
      "Train Epoch: 4809 [56832/60000 (95%)] Loss: -1572.351196\n",
      "    epoch          : 4809\n",
      "    loss           : -1547.597751423464\n",
      "Train Epoch: 4810 [512/60000 (1%)] Loss: -1561.009644\n",
      "Train Epoch: 4810 [11776/60000 (20%)] Loss: -1570.912842\n",
      "Train Epoch: 4810 [23040/60000 (38%)] Loss: -1572.570312\n",
      "Train Epoch: 4810 [34304/60000 (57%)] Loss: -1587.059326\n",
      "Train Epoch: 4810 [45568/60000 (76%)] Loss: -1527.375000\n",
      "Train Epoch: 4810 [56832/60000 (95%)] Loss: -1565.387329\n",
      "    epoch          : 4810\n",
      "    loss           : -1546.8492945439398\n",
      "Train Epoch: 4811 [512/60000 (1%)] Loss: -1581.740967\n",
      "Train Epoch: 4811 [11776/60000 (20%)] Loss: -1517.844849\n",
      "Train Epoch: 4811 [23040/60000 (38%)] Loss: -1567.646240\n",
      "Train Epoch: 4811 [34304/60000 (57%)] Loss: -1513.176880\n",
      "Train Epoch: 4811 [45568/60000 (76%)] Loss: -1574.613525\n",
      "Train Epoch: 4811 [56832/60000 (95%)] Loss: -1562.573853\n",
      "    epoch          : 4811\n",
      "    loss           : -1542.2721871413753\n",
      "Train Epoch: 4812 [512/60000 (1%)] Loss: -1582.601318\n",
      "Train Epoch: 4812 [11776/60000 (20%)] Loss: -1602.376465\n",
      "Train Epoch: 4812 [23040/60000 (38%)] Loss: -1523.160400\n",
      "Train Epoch: 4812 [34304/60000 (57%)] Loss: -1611.300781\n",
      "Train Epoch: 4812 [45568/60000 (76%)] Loss: -1557.892090\n",
      "Train Epoch: 4812 [56832/60000 (95%)] Loss: -1588.526733\n",
      "    epoch          : 4812\n",
      "    loss           : -1547.7418661171432\n",
      "Train Epoch: 4813 [512/60000 (1%)] Loss: -1505.247559\n",
      "Train Epoch: 4813 [11776/60000 (20%)] Loss: -1508.802002\n",
      "Train Epoch: 4813 [23040/60000 (38%)] Loss: -1505.748047\n",
      "Train Epoch: 4813 [34304/60000 (57%)] Loss: -1584.283081\n",
      "Train Epoch: 4813 [45568/60000 (76%)] Loss: -1484.414307\n",
      "Train Epoch: 4813 [56832/60000 (95%)] Loss: -1552.804443\n",
      "    epoch          : 4813\n",
      "    loss           : -1546.709102652167\n",
      "Train Epoch: 4814 [512/60000 (1%)] Loss: -1558.909546\n",
      "Train Epoch: 4814 [11776/60000 (20%)] Loss: -1491.260864\n",
      "Train Epoch: 4814 [23040/60000 (38%)] Loss: -1552.331543\n",
      "Train Epoch: 4814 [34304/60000 (57%)] Loss: -1550.064209\n",
      "Train Epoch: 4814 [45568/60000 (76%)] Loss: -1503.550049\n",
      "Train Epoch: 4814 [56832/60000 (95%)] Loss: -1566.044922\n",
      "    epoch          : 4814\n",
      "    loss           : -1545.85512426344\n",
      "Train Epoch: 4815 [512/60000 (1%)] Loss: -1511.181152\n",
      "Train Epoch: 4815 [11776/60000 (20%)] Loss: -1589.045410\n",
      "Train Epoch: 4815 [23040/60000 (38%)] Loss: -1602.571289\n",
      "Train Epoch: 4815 [34304/60000 (57%)] Loss: -1626.018799\n",
      "Train Epoch: 4815 [45568/60000 (76%)] Loss: -1531.716431\n",
      "Train Epoch: 4815 [56832/60000 (95%)] Loss: -1516.841309\n",
      "    epoch          : 4815\n",
      "    loss           : -1549.774859929489\n",
      "Train Epoch: 4816 [512/60000 (1%)] Loss: -1515.600708\n",
      "Train Epoch: 4816 [11776/60000 (20%)] Loss: -1568.236450\n",
      "Train Epoch: 4816 [23040/60000 (38%)] Loss: -1578.544922\n",
      "Train Epoch: 4816 [34304/60000 (57%)] Loss: -1519.853027\n",
      "Train Epoch: 4816 [45568/60000 (76%)] Loss: -1539.637817\n",
      "Train Epoch: 4816 [56832/60000 (95%)] Loss: -1565.157349\n",
      "    epoch          : 4816\n",
      "    loss           : -1537.8402434095824\n",
      "Train Epoch: 4817 [512/60000 (1%)] Loss: -1547.862793\n",
      "Train Epoch: 4817 [11776/60000 (20%)] Loss: -1547.721436\n",
      "Train Epoch: 4817 [23040/60000 (38%)] Loss: -1548.800903\n",
      "Train Epoch: 4817 [34304/60000 (57%)] Loss: -1587.960205\n",
      "Train Epoch: 4817 [45568/60000 (76%)] Loss: -1529.145020\n",
      "Train Epoch: 4817 [56832/60000 (95%)] Loss: -1601.244751\n",
      "    epoch          : 4817\n",
      "    loss           : -1545.5829260874602\n",
      "Train Epoch: 4818 [512/60000 (1%)] Loss: -1522.567139\n",
      "Train Epoch: 4818 [11776/60000 (20%)] Loss: -1548.022827\n",
      "Train Epoch: 4818 [23040/60000 (38%)] Loss: -1470.210205\n",
      "Train Epoch: 4818 [34304/60000 (57%)] Loss: -1525.672241\n",
      "Train Epoch: 4818 [45568/60000 (76%)] Loss: -1567.927368\n",
      "Train Epoch: 4818 [56832/60000 (95%)] Loss: -1583.572266\n",
      "    epoch          : 4818\n",
      "    loss           : -1549.5959379551775\n",
      "Train Epoch: 4819 [512/60000 (1%)] Loss: -1566.168213\n",
      "Train Epoch: 4819 [11776/60000 (20%)] Loss: -1498.349487\n",
      "Train Epoch: 4819 [23040/60000 (38%)] Loss: -1577.493408\n",
      "Train Epoch: 4819 [34304/60000 (57%)] Loss: -1563.208740\n",
      "Train Epoch: 4819 [45568/60000 (76%)] Loss: -1558.224121\n",
      "Train Epoch: 4819 [56832/60000 (95%)] Loss: -1496.179443\n",
      "    epoch          : 4819\n",
      "    loss           : -1544.4414514229122\n",
      "Train Epoch: 4820 [512/60000 (1%)] Loss: -1586.412598\n",
      "Train Epoch: 4820 [11776/60000 (20%)] Loss: -1584.319092\n",
      "Train Epoch: 4820 [23040/60000 (38%)] Loss: -1534.459229\n",
      "Train Epoch: 4820 [34304/60000 (57%)] Loss: -1619.677490\n",
      "Train Epoch: 4820 [45568/60000 (76%)] Loss: -1468.224854\n",
      "Train Epoch: 4820 [56832/60000 (95%)] Loss: -1525.300293\n",
      "    epoch          : 4820\n",
      "    loss           : -1548.4840215478239\n",
      "Train Epoch: 4821 [512/60000 (1%)] Loss: -1486.171387\n",
      "Train Epoch: 4821 [11776/60000 (20%)] Loss: -1577.030029\n",
      "Train Epoch: 4821 [23040/60000 (38%)] Loss: -1495.544312\n",
      "Train Epoch: 4821 [34304/60000 (57%)] Loss: -1539.790527\n",
      "Train Epoch: 4821 [45568/60000 (76%)] Loss: -1514.761719\n",
      "Train Epoch: 4821 [56832/60000 (95%)] Loss: -1486.421143\n",
      "    epoch          : 4821\n",
      "    loss           : -1547.6341673425363\n",
      "Train Epoch: 4822 [512/60000 (1%)] Loss: -1574.498901\n",
      "Train Epoch: 4822 [11776/60000 (20%)] Loss: -1541.039673\n",
      "Train Epoch: 4822 [23040/60000 (38%)] Loss: -1478.639526\n",
      "Train Epoch: 4822 [34304/60000 (57%)] Loss: -1472.017944\n",
      "Train Epoch: 4822 [45568/60000 (76%)] Loss: -1481.407593\n",
      "Train Epoch: 4822 [56832/60000 (95%)] Loss: -1602.943115\n",
      "    epoch          : 4822\n",
      "    loss           : -1541.8157331391242\n",
      "Train Epoch: 4823 [512/60000 (1%)] Loss: -1516.003296\n",
      "Train Epoch: 4823 [11776/60000 (20%)] Loss: -1556.544922\n",
      "Train Epoch: 4823 [23040/60000 (38%)] Loss: -1628.517822\n",
      "Train Epoch: 4823 [34304/60000 (57%)] Loss: -1529.445557\n",
      "Train Epoch: 4823 [45568/60000 (76%)] Loss: -1637.810669\n",
      "Train Epoch: 4823 [56832/60000 (95%)] Loss: -1528.631592\n",
      "    epoch          : 4823\n",
      "    loss           : -1547.2584528518935\n",
      "Train Epoch: 4824 [512/60000 (1%)] Loss: -1589.805176\n",
      "Train Epoch: 4824 [11776/60000 (20%)] Loss: -1614.725952\n",
      "Train Epoch: 4824 [23040/60000 (38%)] Loss: -1454.535278\n",
      "Train Epoch: 4824 [34304/60000 (57%)] Loss: -1569.550903\n",
      "Train Epoch: 4824 [45568/60000 (76%)] Loss: -1529.207886\n",
      "Train Epoch: 4824 [56832/60000 (95%)] Loss: -1521.843018\n",
      "    epoch          : 4824\n",
      "    loss           : -1549.1032394150557\n",
      "Train Epoch: 4825 [512/60000 (1%)] Loss: -1442.058594\n",
      "Train Epoch: 4825 [11776/60000 (20%)] Loss: -1558.835815\n",
      "Train Epoch: 4825 [23040/60000 (38%)] Loss: -1623.722168\n",
      "Train Epoch: 4825 [34304/60000 (57%)] Loss: -1495.233032\n",
      "Train Epoch: 4825 [45568/60000 (76%)] Loss: -1549.469482\n",
      "Train Epoch: 4825 [56832/60000 (95%)] Loss: -1555.072266\n",
      "    epoch          : 4825\n",
      "    loss           : -1543.7041701839469\n",
      "Train Epoch: 4826 [512/60000 (1%)] Loss: -1560.897339\n",
      "Train Epoch: 4826 [11776/60000 (20%)] Loss: -1590.961914\n",
      "Train Epoch: 4826 [23040/60000 (38%)] Loss: -1541.388184\n",
      "Train Epoch: 4826 [34304/60000 (57%)] Loss: -1543.973022\n",
      "Train Epoch: 4826 [45568/60000 (76%)] Loss: -1516.404663\n",
      "Train Epoch: 4826 [56832/60000 (95%)] Loss: -1573.205322\n",
      "    epoch          : 4826\n",
      "    loss           : -1551.2477051470914\n",
      "Train Epoch: 4827 [512/60000 (1%)] Loss: -1546.762451\n",
      "Train Epoch: 4827 [11776/60000 (20%)] Loss: -1546.642456\n",
      "Train Epoch: 4827 [23040/60000 (38%)] Loss: -1576.390137\n",
      "Train Epoch: 4827 [34304/60000 (57%)] Loss: -1584.397217\n",
      "Train Epoch: 4827 [45568/60000 (76%)] Loss: -1583.473022\n",
      "Train Epoch: 4827 [56832/60000 (95%)] Loss: -1532.437134\n",
      "    epoch          : 4827\n",
      "    loss           : -1544.9775700973253\n",
      "Train Epoch: 4828 [512/60000 (1%)] Loss: -1530.235840\n",
      "Train Epoch: 4828 [11776/60000 (20%)] Loss: -1568.712891\n",
      "Train Epoch: 4828 [23040/60000 (38%)] Loss: -1559.503784\n",
      "Train Epoch: 4828 [34304/60000 (57%)] Loss: -1561.385254\n",
      "Train Epoch: 4828 [45568/60000 (76%)] Loss: -1532.236450\n",
      "Train Epoch: 4828 [56832/60000 (95%)] Loss: -1573.542480\n",
      "    epoch          : 4828\n",
      "    loss           : -1545.7560448942884\n",
      "Train Epoch: 4829 [512/60000 (1%)] Loss: -1545.291382\n",
      "Train Epoch: 4829 [11776/60000 (20%)] Loss: -1595.235718\n",
      "Train Epoch: 4829 [23040/60000 (38%)] Loss: -1559.295044\n",
      "Train Epoch: 4829 [34304/60000 (57%)] Loss: -1597.188232\n",
      "Train Epoch: 4829 [45568/60000 (76%)] Loss: -1523.388428\n",
      "Train Epoch: 4829 [56832/60000 (95%)] Loss: -1591.042236\n",
      "    epoch          : 4829\n",
      "    loss           : -1553.0617827507062\n",
      "Train Epoch: 4830 [512/60000 (1%)] Loss: -1612.092529\n",
      "Train Epoch: 4830 [11776/60000 (20%)] Loss: -1601.854980\n",
      "Train Epoch: 4830 [23040/60000 (38%)] Loss: -1567.680420\n",
      "Train Epoch: 4830 [34304/60000 (57%)] Loss: -1549.577515\n",
      "Train Epoch: 4830 [45568/60000 (76%)] Loss: -1562.118408\n",
      "Train Epoch: 4830 [56832/60000 (95%)] Loss: -1538.747070\n",
      "    epoch          : 4830\n",
      "    loss           : -1541.0863992292327\n",
      "Train Epoch: 4831 [512/60000 (1%)] Loss: -1540.748413\n",
      "Train Epoch: 4831 [11776/60000 (20%)] Loss: -1615.917969\n",
      "Train Epoch: 4831 [23040/60000 (38%)] Loss: -1513.168213\n",
      "Train Epoch: 4831 [34304/60000 (57%)] Loss: -1478.383057\n",
      "Train Epoch: 4831 [45568/60000 (76%)] Loss: -1605.374146\n",
      "Train Epoch: 4831 [56832/60000 (95%)] Loss: -1489.264648\n",
      "    epoch          : 4831\n",
      "    loss           : -1550.644544353593\n",
      "Train Epoch: 4832 [512/60000 (1%)] Loss: -1576.917603\n",
      "Train Epoch: 4832 [11776/60000 (20%)] Loss: -1535.557861\n",
      "Train Epoch: 4832 [23040/60000 (38%)] Loss: -1559.940430\n",
      "Train Epoch: 4832 [34304/60000 (57%)] Loss: -1554.676758\n",
      "Train Epoch: 4832 [45568/60000 (76%)] Loss: -1529.572144\n",
      "Train Epoch: 4832 [56832/60000 (95%)] Loss: -1549.090942\n",
      "    epoch          : 4832\n",
      "    loss           : -1546.999587581656\n",
      "Train Epoch: 4833 [512/60000 (1%)] Loss: -1522.224609\n",
      "Train Epoch: 4833 [11776/60000 (20%)] Loss: -1563.234985\n",
      "Train Epoch: 4833 [23040/60000 (38%)] Loss: -1503.557129\n",
      "Train Epoch: 4833 [34304/60000 (57%)] Loss: -1500.451416\n",
      "Train Epoch: 4833 [45568/60000 (76%)] Loss: -1507.726685\n",
      "Train Epoch: 4833 [56832/60000 (95%)] Loss: -1611.553589\n",
      "    epoch          : 4833\n",
      "    loss           : -1543.7619670286017\n",
      "Train Epoch: 4834 [512/60000 (1%)] Loss: -1611.482056\n",
      "Train Epoch: 4834 [11776/60000 (20%)] Loss: -1557.335449\n",
      "Train Epoch: 4834 [23040/60000 (38%)] Loss: -1547.327026\n",
      "Train Epoch: 4834 [34304/60000 (57%)] Loss: -1552.295532\n",
      "Train Epoch: 4834 [45568/60000 (76%)] Loss: -1498.780029\n",
      "Train Epoch: 4834 [56832/60000 (95%)] Loss: -1551.889648\n",
      "    epoch          : 4834\n",
      "    loss           : -1548.420265671897\n",
      "Train Epoch: 4835 [512/60000 (1%)] Loss: -1531.253662\n",
      "Train Epoch: 4835 [11776/60000 (20%)] Loss: -1569.114990\n",
      "Train Epoch: 4835 [23040/60000 (38%)] Loss: -1519.198120\n",
      "Train Epoch: 4835 [34304/60000 (57%)] Loss: -1617.031738\n",
      "Train Epoch: 4835 [45568/60000 (76%)] Loss: -1570.742676\n",
      "Train Epoch: 4835 [56832/60000 (95%)] Loss: -1569.199219\n",
      "    epoch          : 4835\n",
      "    loss           : -1547.939105879789\n",
      "Train Epoch: 4836 [512/60000 (1%)] Loss: -1593.473267\n",
      "Train Epoch: 4836 [11776/60000 (20%)] Loss: -1512.177368\n",
      "Train Epoch: 4836 [23040/60000 (38%)] Loss: -1560.306396\n",
      "Train Epoch: 4836 [34304/60000 (57%)] Loss: -1485.625977\n",
      "Train Epoch: 4836 [45568/60000 (76%)] Loss: -1591.637573\n",
      "Train Epoch: 4836 [56832/60000 (95%)] Loss: -1534.562744\n",
      "    epoch          : 4836\n",
      "    loss           : -1544.8363044006003\n",
      "Train Epoch: 4837 [512/60000 (1%)] Loss: -1518.699341\n",
      "Train Epoch: 4837 [11776/60000 (20%)] Loss: -1586.733398\n",
      "Train Epoch: 4837 [23040/60000 (38%)] Loss: -1593.505005\n",
      "Train Epoch: 4837 [34304/60000 (57%)] Loss: -1541.586914\n",
      "Train Epoch: 4837 [45568/60000 (76%)] Loss: -1587.750977\n",
      "Train Epoch: 4837 [56832/60000 (95%)] Loss: -1563.062134\n",
      "    epoch          : 4837\n",
      "    loss           : -1549.2480685993776\n",
      "Train Epoch: 4838 [512/60000 (1%)] Loss: -1557.307983\n",
      "Train Epoch: 4838 [11776/60000 (20%)] Loss: -1496.696899\n",
      "Train Epoch: 4838 [23040/60000 (38%)] Loss: -1509.762207\n",
      "Train Epoch: 4838 [34304/60000 (57%)] Loss: -1580.247925\n",
      "Train Epoch: 4838 [45568/60000 (76%)] Loss: -1524.792236\n",
      "Train Epoch: 4838 [56832/60000 (95%)] Loss: -1573.443237\n",
      "    epoch          : 4838\n",
      "    loss           : -1552.2700167725989\n",
      "Train Epoch: 4839 [512/60000 (1%)] Loss: -1487.966675\n",
      "Train Epoch: 4839 [11776/60000 (20%)] Loss: -1562.603027\n",
      "Train Epoch: 4839 [23040/60000 (38%)] Loss: -1610.495117\n",
      "Train Epoch: 4839 [34304/60000 (57%)] Loss: -1505.757080\n",
      "Train Epoch: 4839 [45568/60000 (76%)] Loss: -1588.885010\n",
      "Train Epoch: 4839 [56832/60000 (95%)] Loss: -1543.374023\n",
      "    epoch          : 4839\n",
      "    loss           : -1547.4116138522909\n",
      "Train Epoch: 4840 [512/60000 (1%)] Loss: -1501.793579\n",
      "Train Epoch: 4840 [11776/60000 (20%)] Loss: -1537.499268\n",
      "Train Epoch: 4840 [23040/60000 (38%)] Loss: -1532.272827\n",
      "Train Epoch: 4840 [34304/60000 (57%)] Loss: -1571.572876\n",
      "Train Epoch: 4840 [45568/60000 (76%)] Loss: -1567.810303\n",
      "Train Epoch: 4840 [56832/60000 (95%)] Loss: -1564.836914\n",
      "    epoch          : 4840\n",
      "    loss           : -1546.4241688184145\n",
      "Train Epoch: 4841 [512/60000 (1%)] Loss: -1550.621338\n",
      "Train Epoch: 4841 [11776/60000 (20%)] Loss: -1545.607910\n",
      "Train Epoch: 4841 [23040/60000 (38%)] Loss: -1542.261108\n",
      "Train Epoch: 4841 [34304/60000 (57%)] Loss: -1560.136230\n",
      "Train Epoch: 4841 [45568/60000 (76%)] Loss: -1492.946045\n",
      "Train Epoch: 4841 [56832/60000 (95%)] Loss: -1520.077026\n",
      "    epoch          : 4841\n",
      "    loss           : -1543.2634535967293\n",
      "Train Epoch: 4842 [512/60000 (1%)] Loss: -1541.555298\n",
      "Train Epoch: 4842 [11776/60000 (20%)] Loss: -1522.477173\n",
      "Train Epoch: 4842 [23040/60000 (38%)] Loss: -1569.738159\n",
      "Train Epoch: 4842 [34304/60000 (57%)] Loss: -1532.441040\n",
      "Train Epoch: 4842 [45568/60000 (76%)] Loss: -1568.175781\n",
      "Train Epoch: 4842 [56832/60000 (95%)] Loss: -1472.519897\n",
      "    epoch          : 4842\n",
      "    loss           : -1548.7827744995807\n",
      "Train Epoch: 4843 [512/60000 (1%)] Loss: -1588.636475\n",
      "Train Epoch: 4843 [11776/60000 (20%)] Loss: -1440.677856\n",
      "Train Epoch: 4843 [23040/60000 (38%)] Loss: -1556.865234\n",
      "Train Epoch: 4843 [34304/60000 (57%)] Loss: -1510.995239\n",
      "Train Epoch: 4843 [45568/60000 (76%)] Loss: -1478.616455\n",
      "Train Epoch: 4843 [56832/60000 (95%)] Loss: -1496.922729\n",
      "    epoch          : 4843\n",
      "    loss           : -1546.4296606031514\n",
      "Train Epoch: 4844 [512/60000 (1%)] Loss: -1566.918457\n",
      "Train Epoch: 4844 [11776/60000 (20%)] Loss: -1547.911865\n",
      "Train Epoch: 4844 [23040/60000 (38%)] Loss: -1539.366821\n",
      "Train Epoch: 4844 [34304/60000 (57%)] Loss: -1551.014893\n",
      "Train Epoch: 4844 [45568/60000 (76%)] Loss: -1604.379639\n",
      "Train Epoch: 4844 [56832/60000 (95%)] Loss: -1512.471680\n",
      "    epoch          : 4844\n",
      "    loss           : -1546.306064066914\n",
      "Train Epoch: 4845 [512/60000 (1%)] Loss: -1591.394531\n",
      "Train Epoch: 4845 [11776/60000 (20%)] Loss: -1544.649170\n",
      "Train Epoch: 4845 [23040/60000 (38%)] Loss: -1528.849731\n",
      "Train Epoch: 4845 [34304/60000 (57%)] Loss: -1530.269043\n",
      "Train Epoch: 4845 [45568/60000 (76%)] Loss: -1551.619629\n",
      "Train Epoch: 4845 [56832/60000 (95%)] Loss: -1508.894775\n",
      "    epoch          : 4845\n",
      "    loss           : -1549.0449373924125\n",
      "Train Epoch: 4846 [512/60000 (1%)] Loss: -1504.199341\n",
      "Train Epoch: 4846 [11776/60000 (20%)] Loss: -1539.298828\n",
      "Train Epoch: 4846 [23040/60000 (38%)] Loss: -1546.058472\n",
      "Train Epoch: 4846 [34304/60000 (57%)] Loss: -1584.236694\n",
      "Train Epoch: 4846 [45568/60000 (76%)] Loss: -1572.474121\n",
      "Train Epoch: 4846 [56832/60000 (95%)] Loss: -1521.823486\n",
      "    epoch          : 4846\n",
      "    loss           : -1537.7241428181276\n",
      "Train Epoch: 4847 [512/60000 (1%)] Loss: -1531.680298\n",
      "Train Epoch: 4847 [11776/60000 (20%)] Loss: -1482.318970\n",
      "Train Epoch: 4847 [23040/60000 (38%)] Loss: -1468.634155\n",
      "Train Epoch: 4847 [34304/60000 (57%)] Loss: -1605.059082\n",
      "Train Epoch: 4847 [45568/60000 (76%)] Loss: -1478.767334\n",
      "Train Epoch: 4847 [56832/60000 (95%)] Loss: -1516.129395\n",
      "    epoch          : 4847\n",
      "    loss           : -1546.3158707268494\n",
      "Train Epoch: 4848 [512/60000 (1%)] Loss: -1529.104370\n",
      "Train Epoch: 4848 [11776/60000 (20%)] Loss: -1501.198975\n",
      "Train Epoch: 4848 [23040/60000 (38%)] Loss: -1537.119507\n",
      "Train Epoch: 4848 [34304/60000 (57%)] Loss: -1470.984131\n",
      "Train Epoch: 4848 [45568/60000 (76%)] Loss: -1543.389893\n",
      "Train Epoch: 4848 [56832/60000 (95%)] Loss: -1533.868164\n",
      "    epoch          : 4848\n",
      "    loss           : -1542.6090046510858\n",
      "Train Epoch: 4849 [512/60000 (1%)] Loss: -1535.537598\n",
      "Train Epoch: 4849 [11776/60000 (20%)] Loss: -1544.085327\n",
      "Train Epoch: 4849 [23040/60000 (38%)] Loss: -1534.658691\n",
      "Train Epoch: 4849 [34304/60000 (57%)] Loss: -1523.059570\n",
      "Train Epoch: 4849 [45568/60000 (76%)] Loss: -1536.133667\n",
      "Train Epoch: 4849 [56832/60000 (95%)] Loss: -1517.668701\n",
      "    epoch          : 4849\n",
      "    loss           : -1547.5508415954935\n",
      "Train Epoch: 4850 [512/60000 (1%)] Loss: -1536.780884\n",
      "Train Epoch: 4850 [11776/60000 (20%)] Loss: -1558.407715\n",
      "Train Epoch: 4850 [23040/60000 (38%)] Loss: -1533.185303\n",
      "Train Epoch: 4850 [34304/60000 (57%)] Loss: -1561.229004\n",
      "Train Epoch: 4850 [45568/60000 (76%)] Loss: -1561.524170\n",
      "Train Epoch: 4850 [56832/60000 (95%)] Loss: -1516.414673\n",
      "    epoch          : 4850\n",
      "    loss           : -1543.1864779197563\n",
      "Train Epoch: 4851 [512/60000 (1%)] Loss: -1485.974487\n",
      "Train Epoch: 4851 [11776/60000 (20%)] Loss: -1497.454956\n",
      "Train Epoch: 4851 [23040/60000 (38%)] Loss: -1475.957275\n",
      "Train Epoch: 4851 [34304/60000 (57%)] Loss: -1602.045410\n",
      "Train Epoch: 4851 [45568/60000 (76%)] Loss: -1626.785767\n",
      "Train Epoch: 4851 [56832/60000 (95%)] Loss: -1602.915283\n",
      "    epoch          : 4851\n",
      "    loss           : -1552.7641153281693\n",
      "Train Epoch: 4852 [512/60000 (1%)] Loss: -1536.990234\n",
      "Train Epoch: 4852 [11776/60000 (20%)] Loss: -1537.523926\n",
      "Train Epoch: 4852 [23040/60000 (38%)] Loss: -1584.499634\n",
      "Train Epoch: 4852 [34304/60000 (57%)] Loss: -1515.554199\n",
      "Train Epoch: 4852 [45568/60000 (76%)] Loss: -1563.231812\n",
      "Train Epoch: 4852 [56832/60000 (95%)] Loss: -1598.227783\n",
      "    epoch          : 4852\n",
      "    loss           : -1549.7557935122043\n",
      "Train Epoch: 4853 [512/60000 (1%)] Loss: -1479.372070\n",
      "Train Epoch: 4853 [11776/60000 (20%)] Loss: -1516.505859\n",
      "Train Epoch: 4853 [23040/60000 (38%)] Loss: -1536.092529\n",
      "Train Epoch: 4853 [34304/60000 (57%)] Loss: -1495.470459\n",
      "Train Epoch: 4853 [45568/60000 (76%)] Loss: -1520.902466\n",
      "Train Epoch: 4853 [56832/60000 (95%)] Loss: -1577.383789\n",
      "    epoch          : 4853\n",
      "    loss           : -1546.7277556166136\n",
      "Train Epoch: 4854 [512/60000 (1%)] Loss: -1559.709473\n",
      "Train Epoch: 4854 [11776/60000 (20%)] Loss: -1529.556885\n",
      "Train Epoch: 4854 [23040/60000 (38%)] Loss: -1513.468994\n",
      "Train Epoch: 4854 [34304/60000 (57%)] Loss: -1509.300659\n",
      "Train Epoch: 4854 [45568/60000 (76%)] Loss: -1533.874634\n",
      "Train Epoch: 4854 [56832/60000 (95%)] Loss: -1523.746704\n",
      "    epoch          : 4854\n",
      "    loss           : -1548.4858322574594\n",
      "Train Epoch: 4855 [512/60000 (1%)] Loss: -1584.404541\n",
      "Train Epoch: 4855 [11776/60000 (20%)] Loss: -1568.235474\n",
      "Train Epoch: 4855 [23040/60000 (38%)] Loss: -1566.652588\n",
      "Train Epoch: 4855 [34304/60000 (57%)] Loss: -1571.561401\n",
      "Train Epoch: 4855 [45568/60000 (76%)] Loss: -1591.768921\n",
      "Train Epoch: 4855 [56832/60000 (95%)] Loss: -1604.807129\n",
      "    epoch          : 4855\n",
      "    loss           : -1546.2042312191031\n",
      "Train Epoch: 4856 [512/60000 (1%)] Loss: -1497.271362\n",
      "Train Epoch: 4856 [11776/60000 (20%)] Loss: -1512.426758\n",
      "Train Epoch: 4856 [23040/60000 (38%)] Loss: -1533.962158\n",
      "Train Epoch: 4856 [34304/60000 (57%)] Loss: -1584.388184\n",
      "Train Epoch: 4856 [45568/60000 (76%)] Loss: -1611.079834\n",
      "Train Epoch: 4856 [56832/60000 (95%)] Loss: -1529.417480\n",
      "    epoch          : 4856\n",
      "    loss           : -1540.1643314684852\n",
      "Train Epoch: 4857 [512/60000 (1%)] Loss: -1539.763428\n",
      "Train Epoch: 4857 [11776/60000 (20%)] Loss: -1587.954590\n",
      "Train Epoch: 4857 [23040/60000 (38%)] Loss: -1564.557129\n",
      "Train Epoch: 4857 [34304/60000 (57%)] Loss: -1519.234131\n",
      "Train Epoch: 4857 [45568/60000 (76%)] Loss: -1503.033081\n",
      "Train Epoch: 4857 [56832/60000 (95%)] Loss: -1502.967651\n",
      "    epoch          : 4857\n",
      "    loss           : -1548.9464232019113\n",
      "Train Epoch: 4858 [512/60000 (1%)] Loss: -1474.851807\n",
      "Train Epoch: 4858 [11776/60000 (20%)] Loss: -1604.128906\n",
      "Train Epoch: 4858 [23040/60000 (38%)] Loss: -1451.675537\n",
      "Train Epoch: 4858 [34304/60000 (57%)] Loss: -1563.050537\n",
      "Train Epoch: 4858 [45568/60000 (76%)] Loss: -1528.481323\n",
      "Train Epoch: 4858 [56832/60000 (95%)] Loss: -1510.330933\n",
      "    epoch          : 4858\n",
      "    loss           : -1547.0027658925892\n",
      "Train Epoch: 4859 [512/60000 (1%)] Loss: -1574.305298\n",
      "Train Epoch: 4859 [11776/60000 (20%)] Loss: -1531.250732\n",
      "Train Epoch: 4859 [23040/60000 (38%)] Loss: -1581.464844\n",
      "Train Epoch: 4859 [34304/60000 (57%)] Loss: -1592.138672\n",
      "Train Epoch: 4859 [45568/60000 (76%)] Loss: -1530.592163\n",
      "Train Epoch: 4859 [56832/60000 (95%)] Loss: -1586.873169\n",
      "    epoch          : 4859\n",
      "    loss           : -1549.7141502940724\n",
      "Train Epoch: 4860 [512/60000 (1%)] Loss: -1591.330444\n",
      "Train Epoch: 4860 [11776/60000 (20%)] Loss: -1526.926758\n",
      "Train Epoch: 4860 [23040/60000 (38%)] Loss: -1569.950928\n",
      "Train Epoch: 4860 [34304/60000 (57%)] Loss: -1555.854248\n",
      "Train Epoch: 4860 [45568/60000 (76%)] Loss: -1519.013672\n",
      "Train Epoch: 4860 [56832/60000 (95%)] Loss: -1519.047485\n",
      "    epoch          : 4860\n",
      "    loss           : -1542.9714531332759\n",
      "Train Epoch: 4861 [512/60000 (1%)] Loss: -1550.003784\n",
      "Train Epoch: 4861 [11776/60000 (20%)] Loss: -1519.541992\n",
      "Train Epoch: 4861 [23040/60000 (38%)] Loss: -1513.258789\n",
      "Train Epoch: 4861 [34304/60000 (57%)] Loss: -1486.536133\n",
      "Train Epoch: 4861 [45568/60000 (76%)] Loss: -1495.955933\n",
      "Train Epoch: 4861 [56832/60000 (95%)] Loss: -1533.418213\n",
      "    epoch          : 4861\n",
      "    loss           : -1550.9280012744969\n",
      "Train Epoch: 4862 [512/60000 (1%)] Loss: -1530.894653\n",
      "Train Epoch: 4862 [11776/60000 (20%)] Loss: -1493.592285\n",
      "Train Epoch: 4862 [23040/60000 (38%)] Loss: -1540.626831\n",
      "Train Epoch: 4862 [34304/60000 (57%)] Loss: -1537.349609\n",
      "Train Epoch: 4862 [45568/60000 (76%)] Loss: -1446.340942\n",
      "Train Epoch: 4862 [56832/60000 (95%)] Loss: -1518.587646\n",
      "    epoch          : 4862\n",
      "    loss           : -1549.743102337681\n",
      "Train Epoch: 4863 [512/60000 (1%)] Loss: -1618.617920\n",
      "Train Epoch: 4863 [11776/60000 (20%)] Loss: -1552.782227\n",
      "Train Epoch: 4863 [23040/60000 (38%)] Loss: -1577.274170\n",
      "Train Epoch: 4863 [34304/60000 (57%)] Loss: -1461.438232\n",
      "Train Epoch: 4863 [45568/60000 (76%)] Loss: -1543.872314\n",
      "Train Epoch: 4863 [56832/60000 (95%)] Loss: -1616.393677\n",
      "    epoch          : 4863\n",
      "    loss           : -1554.3068095923816\n",
      "Train Epoch: 4864 [512/60000 (1%)] Loss: -1513.397461\n",
      "Train Epoch: 4864 [11776/60000 (20%)] Loss: -1473.417847\n",
      "Train Epoch: 4864 [23040/60000 (38%)] Loss: -1582.052612\n",
      "Train Epoch: 4864 [34304/60000 (57%)] Loss: -1603.198364\n",
      "Train Epoch: 4864 [45568/60000 (76%)] Loss: -1508.345581\n",
      "Train Epoch: 4864 [56832/60000 (95%)] Loss: -1535.536133\n",
      "    epoch          : 4864\n",
      "    loss           : -1542.5814695196636\n",
      "Train Epoch: 4865 [512/60000 (1%)] Loss: -1594.145996\n",
      "Train Epoch: 4865 [11776/60000 (20%)] Loss: -1520.102295\n",
      "Train Epoch: 4865 [23040/60000 (38%)] Loss: -1478.511597\n",
      "Train Epoch: 4865 [34304/60000 (57%)] Loss: -1560.765869\n",
      "Train Epoch: 4865 [45568/60000 (76%)] Loss: -1560.190186\n",
      "Train Epoch: 4865 [56832/60000 (95%)] Loss: -1550.126709\n",
      "    epoch          : 4865\n",
      "    loss           : -1546.6585745084083\n",
      "Train Epoch: 4866 [512/60000 (1%)] Loss: -1559.673828\n",
      "Train Epoch: 4866 [11776/60000 (20%)] Loss: -1530.394897\n",
      "Train Epoch: 4866 [23040/60000 (38%)] Loss: -1458.269409\n",
      "Train Epoch: 4866 [34304/60000 (57%)] Loss: -1615.065796\n",
      "Train Epoch: 4866 [45568/60000 (76%)] Loss: -1483.552979\n",
      "Train Epoch: 4866 [56832/60000 (95%)] Loss: -1610.190796\n",
      "    epoch          : 4866\n",
      "    loss           : -1543.499428614385\n",
      "Train Epoch: 4867 [512/60000 (1%)] Loss: -1524.910889\n",
      "Train Epoch: 4867 [11776/60000 (20%)] Loss: -1555.585327\n",
      "Train Epoch: 4867 [23040/60000 (38%)] Loss: -1558.965820\n",
      "Train Epoch: 4867 [34304/60000 (57%)] Loss: -1408.844727\n",
      "Train Epoch: 4867 [45568/60000 (76%)] Loss: -1556.317139\n",
      "Train Epoch: 4867 [56832/60000 (95%)] Loss: -1452.539551\n",
      "    epoch          : 4867\n",
      "    loss           : -1543.3545708090571\n",
      "Train Epoch: 4868 [512/60000 (1%)] Loss: -1633.711426\n",
      "Train Epoch: 4868 [11776/60000 (20%)] Loss: -1498.765259\n",
      "Train Epoch: 4868 [23040/60000 (38%)] Loss: -1613.138306\n",
      "Train Epoch: 4868 [34304/60000 (57%)] Loss: -1574.938965\n",
      "Train Epoch: 4868 [45568/60000 (76%)] Loss: -1500.792480\n",
      "Train Epoch: 4868 [56832/60000 (95%)] Loss: -1591.481079\n",
      "    epoch          : 4868\n",
      "    loss           : -1548.1813392423642\n",
      "Train Epoch: 4869 [512/60000 (1%)] Loss: -1536.022705\n",
      "Train Epoch: 4869 [11776/60000 (20%)] Loss: -1522.553955\n",
      "Train Epoch: 4869 [23040/60000 (38%)] Loss: -1506.271484\n",
      "Train Epoch: 4869 [34304/60000 (57%)] Loss: -1523.909912\n",
      "Train Epoch: 4869 [45568/60000 (76%)] Loss: -1547.406372\n",
      "Train Epoch: 4869 [56832/60000 (95%)] Loss: -1556.392456\n",
      "    epoch          : 4869\n",
      "    loss           : -1554.3606757040077\n",
      "Train Epoch: 4870 [512/60000 (1%)] Loss: -1589.077393\n",
      "Train Epoch: 4870 [11776/60000 (20%)] Loss: -1513.974731\n",
      "Train Epoch: 4870 [23040/60000 (38%)] Loss: -1579.109985\n",
      "Train Epoch: 4870 [34304/60000 (57%)] Loss: -1588.022705\n",
      "Train Epoch: 4870 [45568/60000 (76%)] Loss: -1577.025635\n",
      "Train Epoch: 4870 [56832/60000 (95%)] Loss: -1520.699951\n",
      "    epoch          : 4870\n",
      "    loss           : -1544.9036154881708\n",
      "Train Epoch: 4871 [512/60000 (1%)] Loss: -1533.442139\n",
      "Train Epoch: 4871 [11776/60000 (20%)] Loss: -1566.230713\n",
      "Train Epoch: 4871 [23040/60000 (38%)] Loss: -1503.204102\n",
      "Train Epoch: 4871 [34304/60000 (57%)] Loss: -1537.643433\n",
      "Train Epoch: 4871 [45568/60000 (76%)] Loss: -1519.364258\n",
      "Train Epoch: 4871 [56832/60000 (95%)] Loss: -1536.192139\n",
      "    epoch          : 4871\n",
      "    loss           : -1552.5293472203832\n",
      "Train Epoch: 4872 [512/60000 (1%)] Loss: -1594.387817\n",
      "Train Epoch: 4872 [11776/60000 (20%)] Loss: -1482.842041\n",
      "Train Epoch: 4872 [23040/60000 (38%)] Loss: -1511.259277\n",
      "Train Epoch: 4872 [34304/60000 (57%)] Loss: -1536.757568\n",
      "Train Epoch: 4872 [45568/60000 (76%)] Loss: -1570.574707\n",
      "Train Epoch: 4872 [56832/60000 (95%)] Loss: -1535.023315\n",
      "    epoch          : 4872\n",
      "    loss           : -1552.7236369504767\n",
      "Train Epoch: 4873 [512/60000 (1%)] Loss: -1605.872192\n",
      "Train Epoch: 4873 [11776/60000 (20%)] Loss: -1569.226685\n",
      "Train Epoch: 4873 [23040/60000 (38%)] Loss: -1517.423584\n",
      "Train Epoch: 4873 [34304/60000 (57%)] Loss: -1618.455322\n",
      "Train Epoch: 4873 [45568/60000 (76%)] Loss: -1575.527588\n",
      "Train Epoch: 4873 [56832/60000 (95%)] Loss: -1511.022949\n",
      "    epoch          : 4873\n",
      "    loss           : -1551.020900920286\n",
      "Train Epoch: 4874 [512/60000 (1%)] Loss: -1598.910156\n",
      "Train Epoch: 4874 [11776/60000 (20%)] Loss: -1560.555908\n",
      "Train Epoch: 4874 [23040/60000 (38%)] Loss: -1492.469971\n",
      "Train Epoch: 4874 [34304/60000 (57%)] Loss: -1596.992310\n",
      "Train Epoch: 4874 [45568/60000 (76%)] Loss: -1536.970703\n",
      "Train Epoch: 4874 [56832/60000 (95%)] Loss: -1576.997192\n",
      "    epoch          : 4874\n",
      "    loss           : -1551.756561106881\n",
      "Train Epoch: 4875 [512/60000 (1%)] Loss: -1607.069336\n",
      "Train Epoch: 4875 [11776/60000 (20%)] Loss: -1615.648926\n",
      "Train Epoch: 4875 [23040/60000 (38%)] Loss: -1576.833740\n",
      "Train Epoch: 4875 [34304/60000 (57%)] Loss: -1565.205933\n",
      "Train Epoch: 4875 [45568/60000 (76%)] Loss: -1563.213013\n",
      "Train Epoch: 4875 [56832/60000 (95%)] Loss: -1554.230469\n",
      "    epoch          : 4875\n",
      "    loss           : -1550.2204672603284\n",
      "Train Epoch: 4876 [512/60000 (1%)] Loss: -1564.279663\n",
      "Train Epoch: 4876 [11776/60000 (20%)] Loss: -1514.293823\n",
      "Train Epoch: 4876 [23040/60000 (38%)] Loss: -1563.788818\n",
      "Train Epoch: 4876 [34304/60000 (57%)] Loss: -1594.552490\n",
      "Train Epoch: 4876 [45568/60000 (76%)] Loss: -1609.915894\n",
      "Train Epoch: 4876 [56832/60000 (95%)] Loss: -1429.422119\n",
      "    epoch          : 4876\n",
      "    loss           : -1549.6008559404793\n",
      "Train Epoch: 4877 [512/60000 (1%)] Loss: -1578.893799\n",
      "Train Epoch: 4877 [11776/60000 (20%)] Loss: -1555.810791\n",
      "Train Epoch: 4877 [23040/60000 (38%)] Loss: -1569.699219\n",
      "Train Epoch: 4877 [34304/60000 (57%)] Loss: -1606.840088\n",
      "Train Epoch: 4877 [45568/60000 (76%)] Loss: -1618.540527\n",
      "Train Epoch: 4877 [56832/60000 (95%)] Loss: -1629.000977\n",
      "    epoch          : 4877\n",
      "    loss           : -1546.1310390321548\n",
      "Train Epoch: 4878 [512/60000 (1%)] Loss: -1564.536255\n",
      "Train Epoch: 4878 [11776/60000 (20%)] Loss: -1514.367676\n",
      "Train Epoch: 4878 [23040/60000 (38%)] Loss: -1539.368896\n",
      "Train Epoch: 4878 [34304/60000 (57%)] Loss: -1549.458862\n",
      "Train Epoch: 4878 [45568/60000 (76%)] Loss: -1410.047607\n",
      "Train Epoch: 4878 [56832/60000 (95%)] Loss: -1623.980957\n",
      "    epoch          : 4878\n",
      "    loss           : -1542.8368040612863\n",
      "Train Epoch: 4879 [512/60000 (1%)] Loss: -1558.561768\n",
      "Train Epoch: 4879 [11776/60000 (20%)] Loss: -1592.222778\n",
      "Train Epoch: 4879 [23040/60000 (38%)] Loss: -1478.150269\n",
      "Train Epoch: 4879 [34304/60000 (57%)] Loss: -1560.196533\n",
      "Train Epoch: 4879 [45568/60000 (76%)] Loss: -1510.196533\n",
      "Train Epoch: 4879 [56832/60000 (95%)] Loss: -1519.119385\n",
      "    epoch          : 4879\n",
      "    loss           : -1543.8803045412915\n",
      "Train Epoch: 4880 [512/60000 (1%)] Loss: -1605.008545\n",
      "Train Epoch: 4880 [11776/60000 (20%)] Loss: -1433.011475\n",
      "Train Epoch: 4880 [23040/60000 (38%)] Loss: -1533.089111\n",
      "Train Epoch: 4880 [34304/60000 (57%)] Loss: -1546.206787\n",
      "Train Epoch: 4880 [45568/60000 (76%)] Loss: -1596.357178\n",
      "Train Epoch: 4880 [56832/60000 (95%)] Loss: -1490.069092\n",
      "    epoch          : 4880\n",
      "    loss           : -1551.4053075758077\n",
      "Train Epoch: 4881 [512/60000 (1%)] Loss: -1469.525757\n",
      "Train Epoch: 4881 [11776/60000 (20%)] Loss: -1642.572998\n",
      "Train Epoch: 4881 [23040/60000 (38%)] Loss: -1437.549805\n",
      "Train Epoch: 4881 [34304/60000 (57%)] Loss: -1563.153809\n",
      "Train Epoch: 4881 [45568/60000 (76%)] Loss: -1474.999878\n",
      "Train Epoch: 4881 [56832/60000 (95%)] Loss: -1584.722900\n",
      "    epoch          : 4881\n",
      "    loss           : -1542.1449943585585\n",
      "Train Epoch: 4882 [512/60000 (1%)] Loss: -1574.391602\n",
      "Train Epoch: 4882 [11776/60000 (20%)] Loss: -1580.201172\n",
      "Train Epoch: 4882 [23040/60000 (38%)] Loss: -1462.134521\n",
      "Train Epoch: 4882 [34304/60000 (57%)] Loss: -1539.385620\n",
      "Train Epoch: 4882 [45568/60000 (76%)] Loss: -1539.360474\n",
      "Train Epoch: 4882 [56832/60000 (95%)] Loss: -1594.246948\n",
      "    epoch          : 4882\n",
      "    loss           : -1552.8171672928806\n",
      "Train Epoch: 4883 [512/60000 (1%)] Loss: -1588.748169\n",
      "Train Epoch: 4883 [11776/60000 (20%)] Loss: -1591.710571\n",
      "Train Epoch: 4883 [23040/60000 (38%)] Loss: -1514.177246\n",
      "Train Epoch: 4883 [34304/60000 (57%)] Loss: -1593.556519\n",
      "Train Epoch: 4883 [45568/60000 (76%)] Loss: -1582.694214\n",
      "Train Epoch: 4883 [56832/60000 (95%)] Loss: -1585.176514\n",
      "    epoch          : 4883\n",
      "    loss           : -1542.824776687191\n",
      "Train Epoch: 4884 [512/60000 (1%)] Loss: -1609.415771\n",
      "Train Epoch: 4884 [11776/60000 (20%)] Loss: -1556.149170\n",
      "Train Epoch: 4884 [23040/60000 (38%)] Loss: -1496.424316\n",
      "Train Epoch: 4884 [34304/60000 (57%)] Loss: -1622.619629\n",
      "Train Epoch: 4884 [45568/60000 (76%)] Loss: -1587.174561\n",
      "Train Epoch: 4884 [56832/60000 (95%)] Loss: -1512.088257\n",
      "    epoch          : 4884\n",
      "    loss           : -1549.3941391767082\n",
      "Train Epoch: 4885 [512/60000 (1%)] Loss: -1532.052002\n",
      "Train Epoch: 4885 [11776/60000 (20%)] Loss: -1505.435669\n",
      "Train Epoch: 4885 [23040/60000 (38%)] Loss: -1600.067627\n",
      "Train Epoch: 4885 [34304/60000 (57%)] Loss: -1534.729614\n",
      "Train Epoch: 4885 [45568/60000 (76%)] Loss: -1539.310547\n",
      "Train Epoch: 4885 [56832/60000 (95%)] Loss: -1581.977661\n",
      "    epoch          : 4885\n",
      "    loss           : -1551.2427802651616\n",
      "Train Epoch: 4886 [512/60000 (1%)] Loss: -1593.687500\n",
      "Train Epoch: 4886 [11776/60000 (20%)] Loss: -1537.700806\n",
      "Train Epoch: 4886 [23040/60000 (38%)] Loss: -1515.209717\n",
      "Train Epoch: 4886 [34304/60000 (57%)] Loss: -1516.444336\n",
      "Train Epoch: 4886 [45568/60000 (76%)] Loss: -1556.093750\n",
      "Train Epoch: 4886 [56832/60000 (95%)] Loss: -1579.338013\n",
      "    epoch          : 4886\n",
      "    loss           : -1547.7606052894378\n",
      "Train Epoch: 4887 [512/60000 (1%)] Loss: -1591.913452\n",
      "Train Epoch: 4887 [11776/60000 (20%)] Loss: -1429.713379\n",
      "Train Epoch: 4887 [23040/60000 (38%)] Loss: -1540.402344\n",
      "Train Epoch: 4887 [34304/60000 (57%)] Loss: -1545.392822\n",
      "Train Epoch: 4887 [45568/60000 (76%)] Loss: -1516.825195\n",
      "Train Epoch: 4887 [56832/60000 (95%)] Loss: -1500.382324\n",
      "    epoch          : 4887\n",
      "    loss           : -1551.0011196675273\n",
      "Train Epoch: 4888 [512/60000 (1%)] Loss: -1503.173340\n",
      "Train Epoch: 4888 [11776/60000 (20%)] Loss: -1500.810181\n",
      "Train Epoch: 4888 [23040/60000 (38%)] Loss: -1446.929443\n",
      "Train Epoch: 4888 [34304/60000 (57%)] Loss: -1561.743164\n",
      "Train Epoch: 4888 [45568/60000 (76%)] Loss: -1546.582764\n",
      "Train Epoch: 4888 [56832/60000 (95%)] Loss: -1518.035156\n",
      "    epoch          : 4888\n",
      "    loss           : -1540.0591209971974\n",
      "Train Epoch: 4889 [512/60000 (1%)] Loss: -1517.826904\n",
      "Train Epoch: 4889 [11776/60000 (20%)] Loss: -1469.491455\n",
      "Train Epoch: 4889 [23040/60000 (38%)] Loss: -1542.302856\n",
      "Train Epoch: 4889 [34304/60000 (57%)] Loss: -1536.389893\n",
      "Train Epoch: 4889 [45568/60000 (76%)] Loss: -1559.564209\n",
      "Train Epoch: 4889 [56832/60000 (95%)] Loss: -1549.281494\n",
      "    epoch          : 4889\n",
      "    loss           : -1546.1106229448048\n",
      "Train Epoch: 4890 [512/60000 (1%)] Loss: -1543.994263\n",
      "Train Epoch: 4890 [11776/60000 (20%)] Loss: -1564.073608\n",
      "Train Epoch: 4890 [23040/60000 (38%)] Loss: -1486.765869\n",
      "Train Epoch: 4890 [34304/60000 (57%)] Loss: -1469.221924\n",
      "Train Epoch: 4890 [45568/60000 (76%)] Loss: -1535.520874\n",
      "Train Epoch: 4890 [56832/60000 (95%)] Loss: -1579.161377\n",
      "    epoch          : 4890\n",
      "    loss           : -1546.9507835948536\n",
      "Train Epoch: 4891 [512/60000 (1%)] Loss: -1594.791016\n",
      "Train Epoch: 4891 [11776/60000 (20%)] Loss: -1547.978271\n",
      "Train Epoch: 4891 [23040/60000 (38%)] Loss: -1566.677002\n",
      "Train Epoch: 4891 [34304/60000 (57%)] Loss: -1552.597778\n",
      "Train Epoch: 4891 [45568/60000 (76%)] Loss: -1492.245972\n",
      "Train Epoch: 4891 [56832/60000 (95%)] Loss: -1527.453613\n",
      "    epoch          : 4891\n",
      "    loss           : -1550.3556925455728\n",
      "Train Epoch: 4892 [512/60000 (1%)] Loss: -1608.873291\n",
      "Train Epoch: 4892 [11776/60000 (20%)] Loss: -1522.257812\n",
      "Train Epoch: 4892 [23040/60000 (38%)] Loss: -1602.883545\n",
      "Train Epoch: 4892 [34304/60000 (57%)] Loss: -1619.904663\n",
      "Train Epoch: 4892 [45568/60000 (76%)] Loss: -1547.788330\n",
      "Train Epoch: 4892 [56832/60000 (95%)] Loss: -1522.758545\n",
      "    epoch          : 4892\n",
      "    loss           : -1544.0908903132724\n",
      "Train Epoch: 4893 [512/60000 (1%)] Loss: -1465.150879\n",
      "Train Epoch: 4893 [11776/60000 (20%)] Loss: -1573.851562\n",
      "Train Epoch: 4893 [23040/60000 (38%)] Loss: -1511.461670\n",
      "Train Epoch: 4893 [34304/60000 (57%)] Loss: -1474.642822\n",
      "Train Epoch: 4893 [45568/60000 (76%)] Loss: -1586.539551\n",
      "Train Epoch: 4893 [56832/60000 (95%)] Loss: -1547.062988\n",
      "    epoch          : 4893\n",
      "    loss           : -1546.0337683036503\n",
      "Train Epoch: 4894 [512/60000 (1%)] Loss: -1523.013794\n",
      "Train Epoch: 4894 [11776/60000 (20%)] Loss: -1557.718262\n",
      "Train Epoch: 4894 [23040/60000 (38%)] Loss: -1439.488037\n",
      "Train Epoch: 4894 [34304/60000 (57%)] Loss: -1562.347046\n",
      "Train Epoch: 4894 [45568/60000 (76%)] Loss: -1522.645996\n",
      "Train Epoch: 4894 [56832/60000 (95%)] Loss: -1526.569580\n",
      "    epoch          : 4894\n",
      "    loss           : -1546.2041925979872\n",
      "Train Epoch: 4895 [512/60000 (1%)] Loss: -1536.359741\n",
      "Train Epoch: 4895 [11776/60000 (20%)] Loss: -1564.680786\n",
      "Train Epoch: 4895 [23040/60000 (38%)] Loss: -1556.086792\n",
      "Train Epoch: 4895 [34304/60000 (57%)] Loss: -1576.020752\n",
      "Train Epoch: 4895 [45568/60000 (76%)] Loss: -1499.139038\n",
      "Train Epoch: 4895 [56832/60000 (95%)] Loss: -1583.885986\n",
      "    epoch          : 4895\n",
      "    loss           : -1553.8858721889346\n",
      "Train Epoch: 4896 [512/60000 (1%)] Loss: -1557.546875\n",
      "Train Epoch: 4896 [11776/60000 (20%)] Loss: -1560.471191\n",
      "Train Epoch: 4896 [23040/60000 (38%)] Loss: -1609.515259\n",
      "Train Epoch: 4896 [34304/60000 (57%)] Loss: -1554.948364\n",
      "Train Epoch: 4896 [45568/60000 (76%)] Loss: -1565.992676\n",
      "Train Epoch: 4896 [56832/60000 (95%)] Loss: -1545.122559\n",
      "    epoch          : 4896\n",
      "    loss           : -1548.0882637325653\n",
      "Train Epoch: 4897 [512/60000 (1%)] Loss: -1527.634766\n",
      "Train Epoch: 4897 [11776/60000 (20%)] Loss: -1578.388794\n",
      "Train Epoch: 4897 [23040/60000 (38%)] Loss: -1543.471191\n",
      "Train Epoch: 4897 [34304/60000 (57%)] Loss: -1525.133789\n",
      "Train Epoch: 4897 [45568/60000 (76%)] Loss: -1556.319092\n",
      "Train Epoch: 4897 [56832/60000 (95%)] Loss: -1564.900269\n",
      "    epoch          : 4897\n",
      "    loss           : -1542.0642445020083\n",
      "Train Epoch: 4898 [512/60000 (1%)] Loss: -1598.517822\n",
      "Train Epoch: 4898 [11776/60000 (20%)] Loss: -1555.460693\n",
      "Train Epoch: 4898 [23040/60000 (38%)] Loss: -1540.358032\n",
      "Train Epoch: 4898 [34304/60000 (57%)] Loss: -1508.202637\n",
      "Train Epoch: 4898 [45568/60000 (76%)] Loss: -1489.025879\n",
      "Train Epoch: 4898 [56832/60000 (95%)] Loss: -1567.172607\n",
      "    epoch          : 4898\n",
      "    loss           : -1553.163190766243\n",
      "Train Epoch: 4899 [512/60000 (1%)] Loss: -1564.999023\n",
      "Train Epoch: 4899 [11776/60000 (20%)] Loss: -1581.534790\n",
      "Train Epoch: 4899 [23040/60000 (38%)] Loss: -1521.976074\n",
      "Train Epoch: 4899 [34304/60000 (57%)] Loss: -1495.791992\n",
      "Train Epoch: 4899 [45568/60000 (76%)] Loss: -1561.207031\n",
      "Train Epoch: 4899 [56832/60000 (95%)] Loss: -1586.174072\n",
      "    epoch          : 4899\n",
      "    loss           : -1543.2711391987773\n",
      "Train Epoch: 4900 [512/60000 (1%)] Loss: -1593.079590\n",
      "Train Epoch: 4900 [11776/60000 (20%)] Loss: -1604.452393\n",
      "Train Epoch: 4900 [23040/60000 (38%)] Loss: -1553.436523\n",
      "Train Epoch: 4900 [34304/60000 (57%)] Loss: -1498.404541\n",
      "Train Epoch: 4900 [45568/60000 (76%)] Loss: -1466.833496\n",
      "Train Epoch: 4900 [56832/60000 (95%)] Loss: -1506.010254\n",
      "    epoch          : 4900\n",
      "    loss           : -1552.2861772957494\n",
      "Saving checkpoint: saved/models/Mnist_DeepGenerativeOperad/0127_111843/checkpoint-epoch4900.pth ...\n",
      "Train Epoch: 4901 [512/60000 (1%)] Loss: -1545.224487\n",
      "Train Epoch: 4901 [11776/60000 (20%)] Loss: -1577.123291\n",
      "Train Epoch: 4901 [23040/60000 (38%)] Loss: -1523.642456\n",
      "Train Epoch: 4901 [34304/60000 (57%)] Loss: -1595.074707\n",
      "Train Epoch: 4901 [45568/60000 (76%)] Loss: -1500.235474\n",
      "Train Epoch: 4901 [56832/60000 (95%)] Loss: -1582.933594\n",
      "    epoch          : 4901\n",
      "    loss           : -1545.5233026709261\n",
      "Train Epoch: 4902 [512/60000 (1%)] Loss: -1549.139526\n",
      "Train Epoch: 4902 [11776/60000 (20%)] Loss: -1609.044556\n",
      "Train Epoch: 4902 [23040/60000 (38%)] Loss: -1533.567139\n",
      "Train Epoch: 4902 [34304/60000 (57%)] Loss: -1631.681152\n",
      "Train Epoch: 4902 [45568/60000 (76%)] Loss: -1561.447144\n",
      "Train Epoch: 4902 [56832/60000 (95%)] Loss: -1464.052979\n",
      "    epoch          : 4902\n",
      "    loss           : -1548.9406527934102\n",
      "Train Epoch: 4903 [512/60000 (1%)] Loss: -1545.744751\n",
      "Train Epoch: 4903 [11776/60000 (20%)] Loss: -1531.596802\n",
      "Train Epoch: 4903 [23040/60000 (38%)] Loss: -1534.806274\n",
      "Train Epoch: 4903 [34304/60000 (57%)] Loss: -1466.043091\n",
      "Train Epoch: 4903 [45568/60000 (76%)] Loss: -1498.391846\n",
      "Train Epoch: 4903 [56832/60000 (95%)] Loss: -1537.624146\n",
      "    epoch          : 4903\n",
      "    loss           : -1547.0301648156117\n",
      "Train Epoch: 4904 [512/60000 (1%)] Loss: -1622.938599\n",
      "Train Epoch: 4904 [11776/60000 (20%)] Loss: -1605.476318\n",
      "Train Epoch: 4904 [23040/60000 (38%)] Loss: -1472.948853\n",
      "Train Epoch: 4904 [34304/60000 (57%)] Loss: -1535.199097\n",
      "Train Epoch: 4904 [45568/60000 (76%)] Loss: -1565.685303\n",
      "Train Epoch: 4904 [56832/60000 (95%)] Loss: -1568.704834\n",
      "    epoch          : 4904\n",
      "    loss           : -1550.816237972281\n",
      "Train Epoch: 4905 [512/60000 (1%)] Loss: -1579.133301\n",
      "Train Epoch: 4905 [11776/60000 (20%)] Loss: -1479.941650\n",
      "Train Epoch: 4905 [23040/60000 (38%)] Loss: -1506.391968\n",
      "Train Epoch: 4905 [34304/60000 (57%)] Loss: -1466.964355\n",
      "Train Epoch: 4905 [45568/60000 (76%)] Loss: -1595.135498\n",
      "Train Epoch: 4905 [56832/60000 (95%)] Loss: -1514.754517\n",
      "    epoch          : 4905\n",
      "    loss           : -1547.242867852335\n",
      "Train Epoch: 4906 [512/60000 (1%)] Loss: -1551.248047\n",
      "Train Epoch: 4906 [11776/60000 (20%)] Loss: -1481.398926\n",
      "Train Epoch: 4906 [23040/60000 (38%)] Loss: -1523.770020\n",
      "Train Epoch: 4906 [34304/60000 (57%)] Loss: -1557.722656\n",
      "Train Epoch: 4906 [45568/60000 (76%)] Loss: -1523.458984\n",
      "Train Epoch: 4906 [56832/60000 (95%)] Loss: -1615.234009\n",
      "    epoch          : 4906\n",
      "    loss           : -1551.37349550064\n",
      "Train Epoch: 4907 [512/60000 (1%)] Loss: -1536.031006\n",
      "Train Epoch: 4907 [11776/60000 (20%)] Loss: -1572.537598\n",
      "Train Epoch: 4907 [23040/60000 (38%)] Loss: -1490.129028\n",
      "Train Epoch: 4907 [34304/60000 (57%)] Loss: -1611.468994\n",
      "Train Epoch: 4907 [45568/60000 (76%)] Loss: -1567.608643\n",
      "Train Epoch: 4907 [56832/60000 (95%)] Loss: -1568.489258\n",
      "    epoch          : 4907\n",
      "    loss           : -1550.3414958371955\n",
      "Train Epoch: 4908 [512/60000 (1%)] Loss: -1618.533813\n",
      "Train Epoch: 4908 [11776/60000 (20%)] Loss: -1600.411255\n",
      "Train Epoch: 4908 [23040/60000 (38%)] Loss: -1514.367188\n",
      "Train Epoch: 4908 [34304/60000 (57%)] Loss: -1531.597656\n",
      "Train Epoch: 4908 [45568/60000 (76%)] Loss: -1535.234497\n",
      "Train Epoch: 4908 [56832/60000 (95%)] Loss: -1508.686768\n",
      "    epoch          : 4908\n",
      "    loss           : -1549.5804581291932\n",
      "Train Epoch: 4909 [512/60000 (1%)] Loss: -1537.365967\n",
      "Train Epoch: 4909 [11776/60000 (20%)] Loss: -1560.846191\n",
      "Train Epoch: 4909 [23040/60000 (38%)] Loss: -1613.374634\n",
      "Train Epoch: 4909 [34304/60000 (57%)] Loss: -1539.482544\n",
      "Train Epoch: 4909 [45568/60000 (76%)] Loss: -1541.501343\n",
      "Train Epoch: 4909 [56832/60000 (95%)] Loss: -1534.830811\n",
      "    epoch          : 4909\n",
      "    loss           : -1545.570927679202\n",
      "Train Epoch: 4910 [512/60000 (1%)] Loss: -1584.885254\n",
      "Train Epoch: 4910 [11776/60000 (20%)] Loss: -1599.549316\n",
      "Train Epoch: 4910 [23040/60000 (38%)] Loss: -1567.725464\n",
      "Train Epoch: 4910 [34304/60000 (57%)] Loss: -1526.032471\n",
      "Train Epoch: 4910 [45568/60000 (76%)] Loss: -1566.710449\n",
      "Train Epoch: 4910 [56832/60000 (95%)] Loss: -1549.760620\n",
      "    epoch          : 4910\n",
      "    loss           : -1551.4731828075344\n",
      "Train Epoch: 4911 [512/60000 (1%)] Loss: -1502.297607\n",
      "Train Epoch: 4911 [11776/60000 (20%)] Loss: -1478.855713\n",
      "Train Epoch: 4911 [23040/60000 (38%)] Loss: -1544.830566\n",
      "Train Epoch: 4911 [34304/60000 (57%)] Loss: -1524.394165\n",
      "Train Epoch: 4911 [45568/60000 (76%)] Loss: -1533.755127\n",
      "Train Epoch: 4911 [56832/60000 (95%)] Loss: -1521.605469\n",
      "    epoch          : 4911\n",
      "    loss           : -1547.688939326227\n",
      "Train Epoch: 4912 [512/60000 (1%)] Loss: -1628.239014\n",
      "Train Epoch: 4912 [11776/60000 (20%)] Loss: -1581.212891\n",
      "Train Epoch: 4912 [23040/60000 (38%)] Loss: -1471.257812\n",
      "Train Epoch: 4912 [34304/60000 (57%)] Loss: -1595.284424\n",
      "Train Epoch: 4912 [45568/60000 (76%)] Loss: -1554.152100\n",
      "Train Epoch: 4912 [56832/60000 (95%)] Loss: -1483.403931\n",
      "    epoch          : 4912\n",
      "    loss           : -1549.3449007023526\n",
      "Train Epoch: 4913 [512/60000 (1%)] Loss: -1593.751221\n",
      "Train Epoch: 4913 [11776/60000 (20%)] Loss: -1507.868652\n",
      "Train Epoch: 4913 [23040/60000 (38%)] Loss: -1559.666992\n",
      "Train Epoch: 4913 [34304/60000 (57%)] Loss: -1556.454468\n",
      "Train Epoch: 4913 [45568/60000 (76%)] Loss: -1612.848633\n",
      "Train Epoch: 4913 [56832/60000 (95%)] Loss: -1554.909546\n",
      "    epoch          : 4913\n",
      "    loss           : -1554.2550507453875\n",
      "Train Epoch: 4914 [512/60000 (1%)] Loss: -1586.050171\n",
      "Train Epoch: 4914 [11776/60000 (20%)] Loss: -1596.165283\n",
      "Train Epoch: 4914 [23040/60000 (38%)] Loss: -1571.579346\n",
      "Train Epoch: 4914 [34304/60000 (57%)] Loss: -1620.033081\n",
      "Train Epoch: 4914 [45568/60000 (76%)] Loss: -1508.373901\n",
      "Train Epoch: 4914 [56832/60000 (95%)] Loss: -1543.918091\n",
      "    epoch          : 4914\n",
      "    loss           : -1547.179108528094\n",
      "Train Epoch: 4915 [512/60000 (1%)] Loss: -1475.129395\n",
      "Train Epoch: 4915 [11776/60000 (20%)] Loss: -1609.040771\n",
      "Train Epoch: 4915 [23040/60000 (38%)] Loss: -1563.249512\n",
      "Train Epoch: 4915 [34304/60000 (57%)] Loss: -1601.734131\n",
      "Train Epoch: 4915 [45568/60000 (76%)] Loss: -1535.893311\n",
      "Train Epoch: 4915 [56832/60000 (95%)] Loss: -1480.139160\n",
      "    epoch          : 4915\n",
      "    loss           : -1550.575099449373\n",
      "Train Epoch: 4916 [512/60000 (1%)] Loss: -1571.180664\n",
      "Train Epoch: 4916 [11776/60000 (20%)] Loss: -1552.287354\n",
      "Train Epoch: 4916 [23040/60000 (38%)] Loss: -1455.390991\n",
      "Train Epoch: 4916 [34304/60000 (57%)] Loss: -1593.432373\n",
      "Train Epoch: 4916 [45568/60000 (76%)] Loss: -1614.157471\n",
      "Train Epoch: 4916 [56832/60000 (95%)] Loss: -1480.797607\n",
      "    epoch          : 4916\n",
      "    loss           : -1554.6223934195134\n",
      "Train Epoch: 4917 [512/60000 (1%)] Loss: -1545.795044\n",
      "Train Epoch: 4917 [11776/60000 (20%)] Loss: -1640.493164\n",
      "Train Epoch: 4917 [23040/60000 (38%)] Loss: -1521.416626\n",
      "Train Epoch: 4917 [34304/60000 (57%)] Loss: -1592.998901\n",
      "Train Epoch: 4917 [45568/60000 (76%)] Loss: -1607.027344\n",
      "Train Epoch: 4917 [56832/60000 (95%)] Loss: -1601.280029\n",
      "    epoch          : 4917\n",
      "    loss           : -1553.793344271385\n",
      "Train Epoch: 4918 [512/60000 (1%)] Loss: -1565.587646\n",
      "Train Epoch: 4918 [11776/60000 (20%)] Loss: -1517.324951\n",
      "Train Epoch: 4918 [23040/60000 (38%)] Loss: -1491.002930\n",
      "Train Epoch: 4918 [34304/60000 (57%)] Loss: -1532.825317\n",
      "Train Epoch: 4918 [45568/60000 (76%)] Loss: -1478.400513\n",
      "Train Epoch: 4918 [56832/60000 (95%)] Loss: -1536.471313\n",
      "    epoch          : 4918\n",
      "    loss           : -1546.423056047515\n",
      "Train Epoch: 4919 [512/60000 (1%)] Loss: -1495.900391\n",
      "Train Epoch: 4919 [11776/60000 (20%)] Loss: -1544.952759\n",
      "Train Epoch: 4919 [23040/60000 (38%)] Loss: -1542.376343\n",
      "Train Epoch: 4919 [34304/60000 (57%)] Loss: -1522.217529\n",
      "Train Epoch: 4919 [45568/60000 (76%)] Loss: -1629.870850\n",
      "Train Epoch: 4919 [56832/60000 (95%)] Loss: -1536.624146\n",
      "    epoch          : 4919\n",
      "    loss           : -1541.1626614500574\n",
      "Train Epoch: 4920 [512/60000 (1%)] Loss: -1569.213135\n",
      "Train Epoch: 4920 [11776/60000 (20%)] Loss: -1539.141357\n",
      "Train Epoch: 4920 [23040/60000 (38%)] Loss: -1599.194458\n",
      "Train Epoch: 4920 [34304/60000 (57%)] Loss: -1575.310547\n",
      "Train Epoch: 4920 [45568/60000 (76%)] Loss: -1516.115845\n",
      "Train Epoch: 4920 [56832/60000 (95%)] Loss: -1518.422852\n",
      "    epoch          : 4920\n",
      "    loss           : -1551.9680230954273\n",
      "Train Epoch: 4921 [512/60000 (1%)] Loss: -1507.900635\n",
      "Train Epoch: 4921 [11776/60000 (20%)] Loss: -1560.013672\n",
      "Train Epoch: 4921 [23040/60000 (38%)] Loss: -1572.754395\n",
      "Train Epoch: 4921 [34304/60000 (57%)] Loss: -1587.083252\n",
      "Train Epoch: 4921 [45568/60000 (76%)] Loss: -1505.421753\n",
      "Train Epoch: 4921 [56832/60000 (95%)] Loss: -1558.154907\n",
      "    epoch          : 4921\n",
      "    loss           : -1555.6455829857434\n",
      "Train Epoch: 4922 [512/60000 (1%)] Loss: -1587.435059\n",
      "Train Epoch: 4922 [11776/60000 (20%)] Loss: -1569.133423\n",
      "Train Epoch: 4922 [23040/60000 (38%)] Loss: -1593.201538\n",
      "Train Epoch: 4922 [34304/60000 (57%)] Loss: -1501.135742\n",
      "Train Epoch: 4922 [45568/60000 (76%)] Loss: -1519.408203\n",
      "Train Epoch: 4922 [56832/60000 (95%)] Loss: -1478.056885\n",
      "    epoch          : 4922\n",
      "    loss           : -1551.208532301046\n",
      "Train Epoch: 4923 [512/60000 (1%)] Loss: -1517.873779\n",
      "Train Epoch: 4923 [11776/60000 (20%)] Loss: -1428.657227\n",
      "Train Epoch: 4923 [23040/60000 (38%)] Loss: -1507.942139\n",
      "Train Epoch: 4923 [34304/60000 (57%)] Loss: -1579.955322\n",
      "Train Epoch: 4923 [45568/60000 (76%)] Loss: -1559.545776\n",
      "Train Epoch: 4923 [56832/60000 (95%)] Loss: -1510.221924\n",
      "    epoch          : 4923\n",
      "    loss           : -1542.5077945687678\n",
      "Train Epoch: 4924 [512/60000 (1%)] Loss: -1519.012451\n",
      "Train Epoch: 4924 [11776/60000 (20%)] Loss: -1552.082764\n",
      "Train Epoch: 4924 [23040/60000 (38%)] Loss: -1505.225342\n",
      "Train Epoch: 4924 [34304/60000 (57%)] Loss: -1492.141602\n",
      "Train Epoch: 4924 [45568/60000 (76%)] Loss: -1541.859619\n",
      "Train Epoch: 4924 [56832/60000 (95%)] Loss: -1565.339600\n",
      "    epoch          : 4924\n",
      "    loss           : -1547.4408607267392\n",
      "Train Epoch: 4925 [512/60000 (1%)] Loss: -1512.605469\n",
      "Train Epoch: 4925 [11776/60000 (20%)] Loss: -1507.939941\n",
      "Train Epoch: 4925 [23040/60000 (38%)] Loss: -1555.434570\n",
      "Train Epoch: 4925 [34304/60000 (57%)] Loss: -1613.241211\n",
      "Train Epoch: 4925 [45568/60000 (76%)] Loss: -1590.652344\n",
      "Train Epoch: 4925 [56832/60000 (95%)] Loss: -1482.600586\n",
      "    epoch          : 4925\n",
      "    loss           : -1552.2643667102534\n",
      "Train Epoch: 4926 [512/60000 (1%)] Loss: -1622.257324\n",
      "Train Epoch: 4926 [11776/60000 (20%)] Loss: -1480.111572\n",
      "Train Epoch: 4926 [23040/60000 (38%)] Loss: -1573.751831\n",
      "Train Epoch: 4926 [34304/60000 (57%)] Loss: -1608.242188\n",
      "Train Epoch: 4926 [45568/60000 (76%)] Loss: -1514.058350\n",
      "Train Epoch: 4926 [56832/60000 (95%)] Loss: -1562.256104\n",
      "    epoch          : 4926\n",
      "    loss           : -1550.6603672868114\n",
      "Train Epoch: 4927 [512/60000 (1%)] Loss: -1419.483154\n",
      "Train Epoch: 4927 [11776/60000 (20%)] Loss: -1605.956299\n",
      "Train Epoch: 4927 [23040/60000 (38%)] Loss: -1580.179810\n",
      "Train Epoch: 4927 [34304/60000 (57%)] Loss: -1585.048584\n",
      "Train Epoch: 4927 [45568/60000 (76%)] Loss: -1531.948608\n",
      "Train Epoch: 4927 [56832/60000 (95%)] Loss: -1588.478638\n",
      "    epoch          : 4927\n",
      "    loss           : -1549.2508710440943\n",
      "Train Epoch: 4928 [512/60000 (1%)] Loss: -1556.702637\n",
      "Train Epoch: 4928 [11776/60000 (20%)] Loss: -1533.446411\n",
      "Train Epoch: 4928 [23040/60000 (38%)] Loss: -1482.482178\n",
      "Train Epoch: 4928 [34304/60000 (57%)] Loss: -1536.785156\n",
      "Train Epoch: 4928 [45568/60000 (76%)] Loss: -1490.003784\n",
      "Train Epoch: 4928 [56832/60000 (95%)] Loss: -1506.092529\n",
      "    epoch          : 4928\n",
      "    loss           : -1540.3324919447386\n",
      "Train Epoch: 4929 [512/60000 (1%)] Loss: -1546.278809\n",
      "Train Epoch: 4929 [11776/60000 (20%)] Loss: -1490.293945\n",
      "Train Epoch: 4929 [23040/60000 (38%)] Loss: -1491.098389\n",
      "Train Epoch: 4929 [34304/60000 (57%)] Loss: -1609.877930\n",
      "Train Epoch: 4929 [45568/60000 (76%)] Loss: -1604.856079\n",
      "Train Epoch: 4929 [56832/60000 (95%)] Loss: -1547.522705\n",
      "    epoch          : 4929\n",
      "    loss           : -1539.5898451293256\n",
      "Train Epoch: 4930 [512/60000 (1%)] Loss: -1520.979370\n",
      "Train Epoch: 4930 [11776/60000 (20%)] Loss: -1571.815552\n",
      "Train Epoch: 4930 [23040/60000 (38%)] Loss: -1645.354126\n",
      "Train Epoch: 4930 [34304/60000 (57%)] Loss: -1544.529175\n",
      "Train Epoch: 4930 [45568/60000 (76%)] Loss: -1549.398926\n",
      "Train Epoch: 4930 [56832/60000 (95%)] Loss: -1596.452148\n",
      "    epoch          : 4930\n",
      "    loss           : -1555.2710750601384\n",
      "Train Epoch: 4931 [512/60000 (1%)] Loss: -1526.361572\n",
      "Train Epoch: 4931 [11776/60000 (20%)] Loss: -1526.628418\n",
      "Train Epoch: 4931 [23040/60000 (38%)] Loss: -1556.413574\n",
      "Train Epoch: 4931 [34304/60000 (57%)] Loss: -1598.876465\n",
      "Train Epoch: 4931 [45568/60000 (76%)] Loss: -1542.406006\n",
      "Train Epoch: 4931 [56832/60000 (95%)] Loss: -1591.631104\n",
      "    epoch          : 4931\n",
      "    loss           : -1547.3185552392301\n",
      "Train Epoch: 4932 [512/60000 (1%)] Loss: -1552.430908\n",
      "Train Epoch: 4932 [11776/60000 (20%)] Loss: -1586.740479\n",
      "Train Epoch: 4932 [23040/60000 (38%)] Loss: -1473.844116\n",
      "Train Epoch: 4932 [34304/60000 (57%)] Loss: -1600.981445\n",
      "Train Epoch: 4932 [45568/60000 (76%)] Loss: -1622.222168\n",
      "Train Epoch: 4932 [56832/60000 (95%)] Loss: -1527.607666\n",
      "    epoch          : 4932\n",
      "    loss           : -1543.4705186402057\n",
      "Train Epoch: 4933 [512/60000 (1%)] Loss: -1564.514038\n",
      "Train Epoch: 4933 [11776/60000 (20%)] Loss: -1505.834595\n",
      "Train Epoch: 4933 [23040/60000 (38%)] Loss: -1487.984131\n",
      "Train Epoch: 4933 [34304/60000 (57%)] Loss: -1589.400391\n",
      "Train Epoch: 4933 [45568/60000 (76%)] Loss: -1576.670654\n",
      "Train Epoch: 4933 [56832/60000 (95%)] Loss: -1550.460205\n",
      "    epoch          : 4933\n",
      "    loss           : -1557.7759051134356\n",
      "Train Epoch: 4934 [512/60000 (1%)] Loss: -1534.092651\n",
      "Train Epoch: 4934 [11776/60000 (20%)] Loss: -1530.787231\n",
      "Train Epoch: 4934 [23040/60000 (38%)] Loss: -1528.366943\n",
      "Train Epoch: 4934 [34304/60000 (57%)] Loss: -1535.942871\n",
      "Train Epoch: 4934 [45568/60000 (76%)] Loss: -1458.483154\n",
      "Train Epoch: 4934 [56832/60000 (95%)] Loss: -1507.537354\n",
      "    epoch          : 4934\n",
      "    loss           : -1546.9982137733932\n",
      "Train Epoch: 4935 [512/60000 (1%)] Loss: -1548.682617\n",
      "Train Epoch: 4935 [11776/60000 (20%)] Loss: -1635.132446\n",
      "Train Epoch: 4935 [23040/60000 (38%)] Loss: -1560.005737\n",
      "Train Epoch: 4935 [34304/60000 (57%)] Loss: -1584.434326\n",
      "Train Epoch: 4935 [45568/60000 (76%)] Loss: -1483.942383\n",
      "Train Epoch: 4935 [56832/60000 (95%)] Loss: -1628.972900\n",
      "    epoch          : 4935\n",
      "    loss           : -1556.62593690689\n",
      "Train Epoch: 4936 [512/60000 (1%)] Loss: -1580.078491\n",
      "Train Epoch: 4936 [11776/60000 (20%)] Loss: -1540.634521\n",
      "Train Epoch: 4936 [23040/60000 (38%)] Loss: -1564.421753\n",
      "Train Epoch: 4936 [34304/60000 (57%)] Loss: -1561.708252\n",
      "Train Epoch: 4936 [45568/60000 (76%)] Loss: -1513.763062\n",
      "Train Epoch: 4936 [56832/60000 (95%)] Loss: -1481.321045\n",
      "    epoch          : 4936\n",
      "    loss           : -1550.0898413361804\n",
      "Train Epoch: 4937 [512/60000 (1%)] Loss: -1552.636230\n",
      "Train Epoch: 4937 [11776/60000 (20%)] Loss: -1503.027954\n",
      "Train Epoch: 4937 [23040/60000 (38%)] Loss: -1463.461304\n",
      "Train Epoch: 4937 [34304/60000 (57%)] Loss: -1594.349976\n",
      "Train Epoch: 4937 [45568/60000 (76%)] Loss: -1550.733398\n",
      "Train Epoch: 4937 [56832/60000 (95%)] Loss: -1438.937256\n",
      "    epoch          : 4937\n",
      "    loss           : -1546.9306599245233\n",
      "Train Epoch: 4938 [512/60000 (1%)] Loss: -1564.875610\n",
      "Train Epoch: 4938 [11776/60000 (20%)] Loss: -1516.989380\n",
      "Train Epoch: 4938 [23040/60000 (38%)] Loss: -1584.420288\n",
      "Train Epoch: 4938 [34304/60000 (57%)] Loss: -1525.259644\n",
      "Train Epoch: 4938 [45568/60000 (76%)] Loss: -1610.877075\n",
      "Train Epoch: 4938 [56832/60000 (95%)] Loss: -1588.101318\n",
      "    epoch          : 4938\n",
      "    loss           : -1547.559494449594\n",
      "Train Epoch: 4939 [512/60000 (1%)] Loss: -1540.189453\n",
      "Train Epoch: 4939 [11776/60000 (20%)] Loss: -1581.977051\n",
      "Train Epoch: 4939 [23040/60000 (38%)] Loss: -1559.488525\n",
      "Train Epoch: 4939 [34304/60000 (57%)] Loss: -1548.138428\n",
      "Train Epoch: 4939 [45568/60000 (76%)] Loss: -1569.143799\n",
      "Train Epoch: 4939 [56832/60000 (95%)] Loss: -1537.648560\n",
      "    epoch          : 4939\n",
      "    loss           : -1554.1793212890625\n",
      "Train Epoch: 4940 [512/60000 (1%)] Loss: -1504.117554\n",
      "Train Epoch: 4940 [11776/60000 (20%)] Loss: -1592.346558\n",
      "Train Epoch: 4940 [23040/60000 (38%)] Loss: -1564.807861\n",
      "Train Epoch: 4940 [34304/60000 (57%)] Loss: -1598.155884\n",
      "Train Epoch: 4940 [45568/60000 (76%)] Loss: -1579.303955\n",
      "Train Epoch: 4940 [56832/60000 (95%)] Loss: -1550.556030\n",
      "    epoch          : 4940\n",
      "    loss           : -1548.9182156492761\n",
      "Train Epoch: 4941 [512/60000 (1%)] Loss: -1582.504150\n",
      "Train Epoch: 4941 [11776/60000 (20%)] Loss: -1598.499634\n",
      "Train Epoch: 4941 [23040/60000 (38%)] Loss: -1575.405762\n",
      "Train Epoch: 4941 [34304/60000 (57%)] Loss: -1523.628540\n",
      "Train Epoch: 4941 [45568/60000 (76%)] Loss: -1569.705811\n",
      "Train Epoch: 4941 [56832/60000 (95%)] Loss: -1576.501709\n",
      "    epoch          : 4941\n",
      "    loss           : -1546.006385587703\n",
      "Train Epoch: 4942 [512/60000 (1%)] Loss: -1571.528687\n",
      "Train Epoch: 4942 [11776/60000 (20%)] Loss: -1610.004639\n",
      "Train Epoch: 4942 [23040/60000 (38%)] Loss: -1511.458984\n",
      "Train Epoch: 4942 [34304/60000 (57%)] Loss: -1543.507812\n",
      "Train Epoch: 4942 [45568/60000 (76%)] Loss: -1530.369385\n",
      "Train Epoch: 4942 [56832/60000 (95%)] Loss: -1494.210815\n",
      "    epoch          : 4942\n",
      "    loss           : -1553.3819183522025\n",
      "Train Epoch: 4943 [512/60000 (1%)] Loss: -1509.977051\n",
      "Train Epoch: 4943 [11776/60000 (20%)] Loss: -1543.956177\n",
      "Train Epoch: 4943 [23040/60000 (38%)] Loss: -1535.967041\n",
      "Train Epoch: 4943 [34304/60000 (57%)] Loss: -1502.464355\n",
      "Train Epoch: 4943 [45568/60000 (76%)] Loss: -1533.160767\n",
      "Train Epoch: 4943 [56832/60000 (95%)] Loss: -1519.281860\n",
      "    epoch          : 4943\n",
      "    loss           : -1552.761837027167\n",
      "Train Epoch: 4944 [512/60000 (1%)] Loss: -1477.218506\n",
      "Train Epoch: 4944 [11776/60000 (20%)] Loss: -1532.340210\n",
      "Train Epoch: 4944 [23040/60000 (38%)] Loss: -1557.043823\n",
      "Train Epoch: 4944 [34304/60000 (57%)] Loss: -1589.396240\n",
      "Train Epoch: 4944 [45568/60000 (76%)] Loss: -1505.710815\n",
      "Train Epoch: 4944 [56832/60000 (95%)] Loss: -1618.664307\n",
      "    epoch          : 4944\n",
      "    loss           : -1551.2383122848253\n",
      "Train Epoch: 4945 [512/60000 (1%)] Loss: -1637.526245\n",
      "Train Epoch: 4945 [11776/60000 (20%)] Loss: -1647.779297\n",
      "Train Epoch: 4945 [23040/60000 (38%)] Loss: -1506.522217\n",
      "Train Epoch: 4945 [34304/60000 (57%)] Loss: -1480.979370\n",
      "Train Epoch: 4945 [45568/60000 (76%)] Loss: -1540.713257\n",
      "Train Epoch: 4945 [56832/60000 (95%)] Loss: -1521.904297\n",
      "    epoch          : 4945\n",
      "    loss           : -1547.373503431762\n",
      "Train Epoch: 4946 [512/60000 (1%)] Loss: -1524.905762\n",
      "Train Epoch: 4946 [11776/60000 (20%)] Loss: -1551.040771\n",
      "Train Epoch: 4946 [23040/60000 (38%)] Loss: -1566.192017\n",
      "Train Epoch: 4946 [34304/60000 (57%)] Loss: -1477.172607\n",
      "Train Epoch: 4946 [45568/60000 (76%)] Loss: -1490.955078\n",
      "Train Epoch: 4946 [56832/60000 (95%)] Loss: -1533.987183\n",
      "    epoch          : 4946\n",
      "    loss           : -1544.5069066279352\n",
      "Train Epoch: 4947 [512/60000 (1%)] Loss: -1565.647217\n",
      "Train Epoch: 4947 [11776/60000 (20%)] Loss: -1591.968506\n",
      "Train Epoch: 4947 [23040/60000 (38%)] Loss: -1457.593262\n",
      "Train Epoch: 4947 [34304/60000 (57%)] Loss: -1606.081421\n",
      "Train Epoch: 4947 [45568/60000 (76%)] Loss: -1469.978638\n",
      "Train Epoch: 4947 [56832/60000 (95%)] Loss: -1541.763794\n",
      "    epoch          : 4947\n",
      "    loss           : -1544.3427661960409\n",
      "Train Epoch: 4948 [512/60000 (1%)] Loss: -1589.069214\n",
      "Train Epoch: 4948 [11776/60000 (20%)] Loss: -1531.458496\n",
      "Train Epoch: 4948 [23040/60000 (38%)] Loss: -1566.707520\n",
      "Train Epoch: 4948 [34304/60000 (57%)] Loss: -1594.605713\n",
      "Train Epoch: 4948 [45568/60000 (76%)] Loss: -1502.694336\n",
      "Train Epoch: 4948 [56832/60000 (95%)] Loss: -1490.023193\n",
      "    epoch          : 4948\n",
      "    loss           : -1550.7607218424478\n",
      "Train Epoch: 4949 [512/60000 (1%)] Loss: -1526.422119\n",
      "Train Epoch: 4949 [11776/60000 (20%)] Loss: -1436.576904\n",
      "Train Epoch: 4949 [23040/60000 (38%)] Loss: -1614.808472\n",
      "Train Epoch: 4949 [34304/60000 (57%)] Loss: -1525.568115\n",
      "Train Epoch: 4949 [45568/60000 (76%)] Loss: -1566.839233\n",
      "Train Epoch: 4949 [56832/60000 (95%)] Loss: -1602.995972\n",
      "    epoch          : 4949\n",
      "    loss           : -1547.000557937191\n",
      "Train Epoch: 4950 [512/60000 (1%)] Loss: -1551.609131\n",
      "Train Epoch: 4950 [11776/60000 (20%)] Loss: -1601.303711\n",
      "Train Epoch: 4950 [23040/60000 (38%)] Loss: -1528.303589\n",
      "Train Epoch: 4950 [34304/60000 (57%)] Loss: -1582.489624\n",
      "Train Epoch: 4950 [45568/60000 (76%)] Loss: -1499.533691\n",
      "Train Epoch: 4950 [56832/60000 (95%)] Loss: -1493.752563\n",
      "    epoch          : 4950\n",
      "    loss           : -1544.7597542455642\n",
      "Train Epoch: 4951 [512/60000 (1%)] Loss: -1522.335693\n",
      "Train Epoch: 4951 [11776/60000 (20%)] Loss: -1517.100952\n",
      "Train Epoch: 4951 [23040/60000 (38%)] Loss: -1507.816895\n",
      "Train Epoch: 4951 [34304/60000 (57%)] Loss: -1569.686646\n",
      "Train Epoch: 4951 [45568/60000 (76%)] Loss: -1514.871094\n",
      "Train Epoch: 4951 [56832/60000 (95%)] Loss: -1610.311401\n",
      "    epoch          : 4951\n",
      "    loss           : -1551.9856753591764\n",
      "Train Epoch: 4952 [512/60000 (1%)] Loss: -1546.492676\n",
      "Train Epoch: 4952 [11776/60000 (20%)] Loss: -1591.772827\n",
      "Train Epoch: 4952 [23040/60000 (38%)] Loss: -1525.665527\n",
      "Train Epoch: 4952 [34304/60000 (57%)] Loss: -1550.580933\n",
      "Train Epoch: 4952 [45568/60000 (76%)] Loss: -1566.598145\n",
      "Train Epoch: 4952 [56832/60000 (95%)] Loss: -1601.479980\n",
      "    epoch          : 4952\n",
      "    loss           : -1544.7443109717074\n",
      "Train Epoch: 4953 [512/60000 (1%)] Loss: -1478.519775\n",
      "Train Epoch: 4953 [11776/60000 (20%)] Loss: -1524.035767\n",
      "Train Epoch: 4953 [23040/60000 (38%)] Loss: -1573.005371\n",
      "Train Epoch: 4953 [34304/60000 (57%)] Loss: -1531.125732\n",
      "Train Epoch: 4953 [45568/60000 (76%)] Loss: -1524.900635\n",
      "Train Epoch: 4953 [56832/60000 (95%)] Loss: -1533.995239\n",
      "    epoch          : 4953\n",
      "    loss           : -1540.044446697343\n",
      "Train Epoch: 4954 [512/60000 (1%)] Loss: -1481.016724\n",
      "Train Epoch: 4954 [11776/60000 (20%)] Loss: -1503.072510\n",
      "Train Epoch: 4954 [23040/60000 (38%)] Loss: -1628.032104\n",
      "Train Epoch: 4954 [34304/60000 (57%)] Loss: -1528.040283\n",
      "Train Epoch: 4954 [45568/60000 (76%)] Loss: -1577.518433\n",
      "Train Epoch: 4954 [56832/60000 (95%)] Loss: -1545.445068\n",
      "    epoch          : 4954\n",
      "    loss           : -1545.7479741155764\n",
      "Train Epoch: 4955 [512/60000 (1%)] Loss: -1605.750244\n",
      "Train Epoch: 4955 [11776/60000 (20%)] Loss: -1627.513184\n",
      "Train Epoch: 4955 [23040/60000 (38%)] Loss: -1538.127197\n",
      "Train Epoch: 4955 [34304/60000 (57%)] Loss: -1581.064209\n",
      "Train Epoch: 4955 [45568/60000 (76%)] Loss: -1549.911499\n",
      "Train Epoch: 4955 [56832/60000 (95%)] Loss: -1534.362305\n",
      "    epoch          : 4955\n",
      "    loss           : -1548.0644503663489\n",
      "Train Epoch: 4956 [512/60000 (1%)] Loss: -1532.312256\n",
      "Train Epoch: 4956 [11776/60000 (20%)] Loss: -1558.447388\n",
      "Train Epoch: 4956 [23040/60000 (38%)] Loss: -1503.846313\n",
      "Train Epoch: 4956 [34304/60000 (57%)] Loss: -1488.020996\n",
      "Train Epoch: 4956 [45568/60000 (76%)] Loss: -1620.991699\n",
      "Train Epoch: 4956 [56832/60000 (95%)] Loss: -1567.127197\n",
      "    epoch          : 4956\n",
      "    loss           : -1549.7000453108449\n",
      "Train Epoch: 4957 [512/60000 (1%)] Loss: -1497.817749\n",
      "Train Epoch: 4957 [11776/60000 (20%)] Loss: -1573.738770\n",
      "Train Epoch: 4957 [23040/60000 (38%)] Loss: -1508.045166\n",
      "Train Epoch: 4957 [34304/60000 (57%)] Loss: -1488.413086\n",
      "Train Epoch: 4957 [45568/60000 (76%)] Loss: -1570.833374\n",
      "Train Epoch: 4957 [56832/60000 (95%)] Loss: -1497.555298\n",
      "    epoch          : 4957\n",
      "    loss           : -1547.873327912584\n",
      "Train Epoch: 4958 [512/60000 (1%)] Loss: -1518.092041\n",
      "Train Epoch: 4958 [11776/60000 (20%)] Loss: -1502.244019\n",
      "Train Epoch: 4958 [23040/60000 (38%)] Loss: -1471.529419\n",
      "Train Epoch: 4958 [34304/60000 (57%)] Loss: -1599.004150\n",
      "Train Epoch: 4958 [45568/60000 (76%)] Loss: -1597.919067\n",
      "Train Epoch: 4958 [56832/60000 (95%)] Loss: -1628.625488\n",
      "    epoch          : 4958\n",
      "    loss           : -1549.0435170319122\n",
      "Train Epoch: 4959 [512/60000 (1%)] Loss: -1487.645020\n",
      "Train Epoch: 4959 [11776/60000 (20%)] Loss: -1543.280273\n",
      "Train Epoch: 4959 [23040/60000 (38%)] Loss: -1575.043457\n",
      "Train Epoch: 4959 [34304/60000 (57%)] Loss: -1510.606934\n",
      "Train Epoch: 4959 [45568/60000 (76%)] Loss: -1494.809692\n",
      "Train Epoch: 4959 [56832/60000 (95%)] Loss: -1630.160034\n",
      "    epoch          : 4959\n",
      "    loss           : -1546.7360467425847\n",
      "Train Epoch: 4960 [512/60000 (1%)] Loss: -1497.436035\n",
      "Train Epoch: 4960 [11776/60000 (20%)] Loss: -1545.052124\n",
      "Train Epoch: 4960 [23040/60000 (38%)] Loss: -1543.178711\n",
      "Train Epoch: 4960 [34304/60000 (57%)] Loss: -1614.787354\n",
      "Train Epoch: 4960 [45568/60000 (76%)] Loss: -1507.630493\n",
      "Train Epoch: 4960 [56832/60000 (95%)] Loss: -1542.652466\n",
      "    epoch          : 4960\n",
      "    loss           : -1551.642321570445\n",
      "Train Epoch: 4961 [512/60000 (1%)] Loss: -1611.210938\n",
      "Train Epoch: 4961 [11776/60000 (20%)] Loss: -1487.147461\n",
      "Train Epoch: 4961 [23040/60000 (38%)] Loss: -1555.090210\n",
      "Train Epoch: 4961 [34304/60000 (57%)] Loss: -1583.491333\n",
      "Train Epoch: 4961 [45568/60000 (76%)] Loss: -1592.137451\n",
      "Train Epoch: 4961 [56832/60000 (95%)] Loss: -1613.117310\n",
      "    epoch          : 4961\n",
      "    loss           : -1544.2860717773438\n",
      "Train Epoch: 4962 [512/60000 (1%)] Loss: -1557.253662\n",
      "Train Epoch: 4962 [11776/60000 (20%)] Loss: -1536.937988\n",
      "Train Epoch: 4962 [23040/60000 (38%)] Loss: -1537.682617\n",
      "Train Epoch: 4962 [34304/60000 (57%)] Loss: -1535.241943\n",
      "Train Epoch: 4962 [45568/60000 (76%)] Loss: -1545.280762\n",
      "Train Epoch: 4962 [56832/60000 (95%)] Loss: -1518.115967\n",
      "    epoch          : 4962\n",
      "    loss           : -1551.956574693238\n",
      "Train Epoch: 4963 [512/60000 (1%)] Loss: -1596.704712\n",
      "Train Epoch: 4963 [11776/60000 (20%)] Loss: -1575.894165\n",
      "Train Epoch: 4963 [23040/60000 (38%)] Loss: -1512.487427\n",
      "Train Epoch: 4963 [34304/60000 (57%)] Loss: -1554.011108\n",
      "Train Epoch: 4963 [45568/60000 (76%)] Loss: -1461.624146\n",
      "Train Epoch: 4963 [56832/60000 (95%)] Loss: -1484.090332\n",
      "    epoch          : 4963\n",
      "    loss           : -1546.2652674098472\n",
      "Train Epoch: 4964 [512/60000 (1%)] Loss: -1538.902588\n",
      "Train Epoch: 4964 [11776/60000 (20%)] Loss: -1552.134766\n",
      "Train Epoch: 4964 [23040/60000 (38%)] Loss: -1498.266846\n",
      "Train Epoch: 4964 [34304/60000 (57%)] Loss: -1555.102295\n",
      "Train Epoch: 4964 [45568/60000 (76%)] Loss: -1461.230713\n",
      "Train Epoch: 4964 [56832/60000 (95%)] Loss: -1583.502197\n",
      "    epoch          : 4964\n",
      "    loss           : -1547.0161339711335\n",
      "Train Epoch: 4965 [512/60000 (1%)] Loss: -1496.552368\n",
      "Train Epoch: 4965 [11776/60000 (20%)] Loss: -1586.048340\n",
      "Train Epoch: 4965 [23040/60000 (38%)] Loss: -1524.246460\n",
      "Train Epoch: 4965 [34304/60000 (57%)] Loss: -1549.029785\n",
      "Train Epoch: 4965 [45568/60000 (76%)] Loss: -1483.837524\n",
      "Train Epoch: 4965 [56832/60000 (95%)] Loss: -1592.805664\n",
      "    epoch          : 4965\n",
      "    loss           : -1547.9107376357256\n",
      "Train Epoch: 4966 [512/60000 (1%)] Loss: -1564.351562\n",
      "Train Epoch: 4966 [11776/60000 (20%)] Loss: -1480.691040\n",
      "Train Epoch: 4966 [23040/60000 (38%)] Loss: -1572.588135\n",
      "Train Epoch: 4966 [34304/60000 (57%)] Loss: -1536.961182\n",
      "Train Epoch: 4966 [45568/60000 (76%)] Loss: -1570.109985\n",
      "Train Epoch: 4966 [56832/60000 (95%)] Loss: -1582.927490\n",
      "    epoch          : 4966\n",
      "    loss           : -1547.6431719246557\n",
      "Train Epoch: 4967 [512/60000 (1%)] Loss: -1561.934448\n",
      "Train Epoch: 4967 [11776/60000 (20%)] Loss: -1485.922119\n",
      "Train Epoch: 4967 [23040/60000 (38%)] Loss: -1530.046387\n",
      "Train Epoch: 4967 [34304/60000 (57%)] Loss: -1516.473022\n",
      "Train Epoch: 4967 [45568/60000 (76%)] Loss: -1539.941406\n",
      "Train Epoch: 4967 [56832/60000 (95%)] Loss: -1581.814941\n",
      "    epoch          : 4967\n",
      "    loss           : -1549.0768601584568\n",
      "Train Epoch: 4968 [512/60000 (1%)] Loss: -1494.704102\n",
      "Train Epoch: 4968 [11776/60000 (20%)] Loss: -1513.528076\n",
      "Train Epoch: 4968 [23040/60000 (38%)] Loss: -1503.735962\n",
      "Train Epoch: 4968 [34304/60000 (57%)] Loss: -1558.107910\n",
      "Train Epoch: 4968 [45568/60000 (76%)] Loss: -1478.378906\n",
      "Train Epoch: 4968 [56832/60000 (95%)] Loss: -1487.535156\n",
      "    epoch          : 4968\n",
      "    loss           : -1534.0422890873278\n",
      "Train Epoch: 4969 [512/60000 (1%)] Loss: -1603.474121\n",
      "Train Epoch: 4969 [11776/60000 (20%)] Loss: -1587.080566\n",
      "Train Epoch: 4969 [23040/60000 (38%)] Loss: -1572.797363\n",
      "Train Epoch: 4969 [34304/60000 (57%)] Loss: -1547.806030\n",
      "Train Epoch: 4969 [45568/60000 (76%)] Loss: -1569.957153\n",
      "Train Epoch: 4969 [56832/60000 (95%)] Loss: -1491.365234\n",
      "    epoch          : 4969\n",
      "    loss           : -1542.5499102059057\n",
      "Train Epoch: 4970 [512/60000 (1%)] Loss: -1472.927734\n",
      "Train Epoch: 4970 [11776/60000 (20%)] Loss: -1544.473145\n",
      "Train Epoch: 4970 [23040/60000 (38%)] Loss: -1513.358154\n",
      "Train Epoch: 4970 [34304/60000 (57%)] Loss: -1569.502441\n",
      "Train Epoch: 4970 [45568/60000 (76%)] Loss: -1517.216064\n",
      "Train Epoch: 4970 [56832/60000 (95%)] Loss: -1586.415405\n",
      "    epoch          : 4970\n",
      "    loss           : -1551.5762584276792\n",
      "Train Epoch: 4971 [512/60000 (1%)] Loss: -1622.964600\n",
      "Train Epoch: 4971 [11776/60000 (20%)] Loss: -1599.959351\n",
      "Train Epoch: 4971 [23040/60000 (38%)] Loss: -1561.690063\n",
      "Train Epoch: 4971 [34304/60000 (57%)] Loss: -1588.546753\n",
      "Train Epoch: 4971 [45568/60000 (76%)] Loss: -1615.160400\n",
      "Train Epoch: 4971 [56832/60000 (95%)] Loss: -1546.022095\n",
      "    epoch          : 4971\n",
      "    loss           : -1551.8194814563471\n",
      "Train Epoch: 4972 [512/60000 (1%)] Loss: -1612.652710\n",
      "Train Epoch: 4972 [11776/60000 (20%)] Loss: -1597.749512\n",
      "Train Epoch: 4972 [23040/60000 (38%)] Loss: -1477.658081\n",
      "Train Epoch: 4972 [34304/60000 (57%)] Loss: -1515.398560\n",
      "Train Epoch: 4972 [45568/60000 (76%)] Loss: -1504.675293\n",
      "Train Epoch: 4972 [56832/60000 (95%)] Loss: -1500.518799\n",
      "    epoch          : 4972\n",
      "    loss           : -1556.010765980866\n",
      "Train Epoch: 4973 [512/60000 (1%)] Loss: -1601.102783\n",
      "Train Epoch: 4973 [11776/60000 (20%)] Loss: -1563.956177\n",
      "Train Epoch: 4973 [23040/60000 (38%)] Loss: -1509.635498\n",
      "Train Epoch: 4973 [34304/60000 (57%)] Loss: -1555.347778\n",
      "Train Epoch: 4973 [45568/60000 (76%)] Loss: -1522.279541\n",
      "Train Epoch: 4973 [56832/60000 (95%)] Loss: -1495.201904\n",
      "    epoch          : 4973\n",
      "    loss           : -1545.2581804350946\n",
      "Train Epoch: 4974 [512/60000 (1%)] Loss: -1579.893555\n",
      "Train Epoch: 4974 [11776/60000 (20%)] Loss: -1611.977051\n",
      "Train Epoch: 4974 [23040/60000 (38%)] Loss: -1499.260010\n",
      "Train Epoch: 4974 [34304/60000 (57%)] Loss: -1559.287964\n",
      "Train Epoch: 4974 [45568/60000 (76%)] Loss: -1565.562500\n",
      "Train Epoch: 4974 [56832/60000 (95%)] Loss: -1556.495239\n",
      "    epoch          : 4974\n",
      "    loss           : -1546.9736369504767\n",
      "Train Epoch: 4975 [512/60000 (1%)] Loss: -1581.754639\n",
      "Train Epoch: 4975 [11776/60000 (20%)] Loss: -1513.259033\n",
      "Train Epoch: 4975 [23040/60000 (38%)] Loss: -1581.217285\n",
      "Train Epoch: 4975 [34304/60000 (57%)] Loss: -1592.764526\n",
      "Train Epoch: 4975 [45568/60000 (76%)] Loss: -1572.788330\n",
      "Train Epoch: 4975 [56832/60000 (95%)] Loss: -1545.989258\n",
      "    epoch          : 4975\n",
      "    loss           : -1545.3851908021054\n",
      "Train Epoch: 4976 [512/60000 (1%)] Loss: -1540.842163\n",
      "Train Epoch: 4976 [11776/60000 (20%)] Loss: -1596.314087\n",
      "Train Epoch: 4976 [23040/60000 (38%)] Loss: -1578.086304\n",
      "Train Epoch: 4976 [34304/60000 (57%)] Loss: -1561.589111\n",
      "Train Epoch: 4976 [45568/60000 (76%)] Loss: -1523.569214\n",
      "Train Epoch: 4976 [56832/60000 (95%)] Loss: -1547.194946\n",
      "    epoch          : 4976\n",
      "    loss           : -1553.8319350420418\n",
      "Train Epoch: 4977 [512/60000 (1%)] Loss: -1508.043579\n",
      "Train Epoch: 4977 [11776/60000 (20%)] Loss: -1547.815674\n",
      "Train Epoch: 4977 [23040/60000 (38%)] Loss: -1465.822876\n",
      "Train Epoch: 4977 [34304/60000 (57%)] Loss: -1588.581299\n",
      "Train Epoch: 4977 [45568/60000 (76%)] Loss: -1543.088135\n",
      "Train Epoch: 4977 [56832/60000 (95%)] Loss: -1594.119263\n",
      "    epoch          : 4977\n",
      "    loss           : -1543.3218852759753\n",
      "Train Epoch: 4978 [512/60000 (1%)] Loss: -1532.231079\n",
      "Train Epoch: 4978 [11776/60000 (20%)] Loss: -1558.713745\n",
      "Train Epoch: 4978 [23040/60000 (38%)] Loss: -1537.459595\n",
      "Train Epoch: 4978 [34304/60000 (57%)] Loss: -1541.273804\n",
      "Train Epoch: 4978 [45568/60000 (76%)] Loss: -1534.651611\n",
      "Train Epoch: 4978 [56832/60000 (95%)] Loss: -1501.116211\n",
      "    epoch          : 4978\n",
      "    loss           : -1550.7141551217117\n",
      "Train Epoch: 4979 [512/60000 (1%)] Loss: -1552.419922\n",
      "Train Epoch: 4979 [11776/60000 (20%)] Loss: -1558.297974\n",
      "Train Epoch: 4979 [23040/60000 (38%)] Loss: -1509.753906\n",
      "Train Epoch: 4979 [34304/60000 (57%)] Loss: -1503.768799\n",
      "Train Epoch: 4979 [45568/60000 (76%)] Loss: -1500.200684\n",
      "Train Epoch: 4979 [56832/60000 (95%)] Loss: -1605.996582\n",
      "    epoch          : 4979\n",
      "    loss           : -1556.415503550384\n",
      "Train Epoch: 4980 [512/60000 (1%)] Loss: -1606.764404\n",
      "Train Epoch: 4980 [11776/60000 (20%)] Loss: -1562.126953\n",
      "Train Epoch: 4980 [23040/60000 (38%)] Loss: -1603.220825\n",
      "Train Epoch: 4980 [34304/60000 (57%)] Loss: -1514.520264\n",
      "Train Epoch: 4980 [45568/60000 (76%)] Loss: -1532.457153\n",
      "Train Epoch: 4980 [56832/60000 (95%)] Loss: -1543.178345\n",
      "    epoch          : 4980\n",
      "    loss           : -1543.906595521054\n",
      "Train Epoch: 4981 [512/60000 (1%)] Loss: -1566.067139\n",
      "Train Epoch: 4981 [11776/60000 (20%)] Loss: -1555.834229\n",
      "Train Epoch: 4981 [23040/60000 (38%)] Loss: -1532.825684\n",
      "Train Epoch: 4981 [34304/60000 (57%)] Loss: -1610.772949\n",
      "Train Epoch: 4981 [45568/60000 (76%)] Loss: -1492.481689\n",
      "Train Epoch: 4981 [56832/60000 (95%)] Loss: -1615.125366\n",
      "    epoch          : 4981\n",
      "    loss           : -1550.308405127229\n",
      "Train Epoch: 4982 [512/60000 (1%)] Loss: -1554.044067\n",
      "Train Epoch: 4982 [11776/60000 (20%)] Loss: -1580.776245\n",
      "Train Epoch: 4982 [23040/60000 (38%)] Loss: -1554.342773\n",
      "Train Epoch: 4982 [34304/60000 (57%)] Loss: -1527.512939\n",
      "Train Epoch: 4982 [45568/60000 (76%)] Loss: -1553.934326\n",
      "Train Epoch: 4982 [56832/60000 (95%)] Loss: -1547.332520\n",
      "    epoch          : 4982\n",
      "    loss           : -1552.1186985511565\n",
      "Train Epoch: 4983 [512/60000 (1%)] Loss: -1542.587646\n",
      "Train Epoch: 4983 [11776/60000 (20%)] Loss: -1569.326904\n",
      "Train Epoch: 4983 [23040/60000 (38%)] Loss: -1552.227539\n",
      "Train Epoch: 4983 [34304/60000 (57%)] Loss: -1533.332642\n",
      "Train Epoch: 4983 [45568/60000 (76%)] Loss: -1454.021606\n",
      "Train Epoch: 4983 [56832/60000 (95%)] Loss: -1598.076050\n",
      "    epoch          : 4983\n",
      "    loss           : -1550.1429122666182\n",
      "Train Epoch: 4984 [512/60000 (1%)] Loss: -1581.353760\n",
      "Train Epoch: 4984 [11776/60000 (20%)] Loss: -1525.351074\n",
      "Train Epoch: 4984 [23040/60000 (38%)] Loss: -1537.420166\n",
      "Train Epoch: 4984 [34304/60000 (57%)] Loss: -1547.303589\n",
      "Train Epoch: 4984 [45568/60000 (76%)] Loss: -1570.346558\n",
      "Train Epoch: 4984 [56832/60000 (95%)] Loss: -1568.920532\n",
      "    epoch          : 4984\n",
      "    loss           : -1547.7122971701756\n",
      "Train Epoch: 4985 [512/60000 (1%)] Loss: -1486.621338\n",
      "Train Epoch: 4985 [11776/60000 (20%)] Loss: -1445.094727\n",
      "Train Epoch: 4985 [23040/60000 (38%)] Loss: -1607.252808\n",
      "Train Epoch: 4985 [34304/60000 (57%)] Loss: -1492.016113\n",
      "Train Epoch: 4985 [45568/60000 (76%)] Loss: -1557.058105\n",
      "Train Epoch: 4985 [56832/60000 (95%)] Loss: -1496.670654\n",
      "    epoch          : 4985\n",
      "    loss           : -1548.071552513683\n",
      "Train Epoch: 4986 [512/60000 (1%)] Loss: -1609.204102\n",
      "Train Epoch: 4986 [11776/60000 (20%)] Loss: -1544.287842\n",
      "Train Epoch: 4986 [23040/60000 (38%)] Loss: -1507.410400\n",
      "Train Epoch: 4986 [34304/60000 (57%)] Loss: -1538.832764\n",
      "Train Epoch: 4986 [45568/60000 (76%)] Loss: -1621.434937\n",
      "Train Epoch: 4986 [56832/60000 (95%)] Loss: -1530.054810\n",
      "    epoch          : 4986\n",
      "    loss           : -1541.8292763920153\n",
      "Train Epoch: 4987 [512/60000 (1%)] Loss: -1566.327637\n",
      "Train Epoch: 4987 [11776/60000 (20%)] Loss: -1625.452148\n",
      "Train Epoch: 4987 [23040/60000 (38%)] Loss: -1588.634033\n",
      "Train Epoch: 4987 [34304/60000 (57%)] Loss: -1536.744141\n",
      "Train Epoch: 4987 [45568/60000 (76%)] Loss: -1523.193604\n",
      "Train Epoch: 4987 [56832/60000 (95%)] Loss: -1525.601807\n",
      "    epoch          : 4987\n",
      "    loss           : -1550.5510115973693\n",
      "Train Epoch: 4988 [512/60000 (1%)] Loss: -1534.527222\n",
      "Train Epoch: 4988 [11776/60000 (20%)] Loss: -1604.163818\n",
      "Train Epoch: 4988 [23040/60000 (38%)] Loss: -1540.657837\n",
      "Train Epoch: 4988 [34304/60000 (57%)] Loss: -1535.044312\n",
      "Train Epoch: 4988 [45568/60000 (76%)] Loss: -1592.400879\n",
      "Train Epoch: 4988 [56832/60000 (95%)] Loss: -1555.782471\n",
      "    epoch          : 4988\n",
      "    loss           : -1549.5599237646761\n",
      "Train Epoch: 4989 [512/60000 (1%)] Loss: -1557.619629\n",
      "Train Epoch: 4989 [11776/60000 (20%)] Loss: -1500.155151\n",
      "Train Epoch: 4989 [23040/60000 (38%)] Loss: -1583.414795\n",
      "Train Epoch: 4989 [34304/60000 (57%)] Loss: -1566.550781\n",
      "Train Epoch: 4989 [45568/60000 (76%)] Loss: -1466.587402\n",
      "Train Epoch: 4989 [56832/60000 (95%)] Loss: -1543.085938\n",
      "    epoch          : 4989\n",
      "    loss           : -1540.3605284610037\n",
      "Train Epoch: 4990 [512/60000 (1%)] Loss: -1576.242188\n",
      "Train Epoch: 4990 [11776/60000 (20%)] Loss: -1508.919922\n",
      "Train Epoch: 4990 [23040/60000 (38%)] Loss: -1578.078369\n",
      "Train Epoch: 4990 [34304/60000 (57%)] Loss: -1547.537231\n",
      "Train Epoch: 4990 [45568/60000 (76%)] Loss: -1522.679810\n",
      "Train Epoch: 4990 [56832/60000 (95%)] Loss: -1565.330811\n",
      "    epoch          : 4990\n",
      "    loss           : -1543.763546011542\n",
      "Train Epoch: 4991 [512/60000 (1%)] Loss: -1481.165894\n",
      "Train Epoch: 4991 [11776/60000 (20%)] Loss: -1540.350220\n",
      "Train Epoch: 4991 [23040/60000 (38%)] Loss: -1520.630615\n",
      "Train Epoch: 4991 [34304/60000 (57%)] Loss: -1525.765259\n",
      "Train Epoch: 4991 [45568/60000 (76%)] Loss: -1525.965454\n",
      "Train Epoch: 4991 [56832/60000 (95%)] Loss: -1543.393188\n",
      "    epoch          : 4991\n",
      "    loss           : -1548.1947797355006\n",
      "Train Epoch: 4992 [512/60000 (1%)] Loss: -1534.712646\n",
      "Train Epoch: 4992 [11776/60000 (20%)] Loss: -1553.901611\n",
      "Train Epoch: 4992 [23040/60000 (38%)] Loss: -1576.961182\n",
      "Train Epoch: 4992 [34304/60000 (57%)] Loss: -1536.575806\n",
      "Train Epoch: 4992 [45568/60000 (76%)] Loss: -1550.978394\n",
      "Train Epoch: 4992 [56832/60000 (95%)] Loss: -1605.185791\n",
      "    epoch          : 4992\n",
      "    loss           : -1548.2041081142963\n",
      "Train Epoch: 4993 [512/60000 (1%)] Loss: -1574.716919\n",
      "Train Epoch: 4993 [11776/60000 (20%)] Loss: -1585.210693\n",
      "Train Epoch: 4993 [23040/60000 (38%)] Loss: -1572.799561\n",
      "Train Epoch: 4993 [34304/60000 (57%)] Loss: -1535.536621\n",
      "Train Epoch: 4993 [45568/60000 (76%)] Loss: -1534.321533\n",
      "Train Epoch: 4993 [56832/60000 (95%)] Loss: -1506.598511\n",
      "    epoch          : 4993\n",
      "    loss           : -1547.1390301548154\n",
      "Train Epoch: 4994 [512/60000 (1%)] Loss: -1535.319946\n",
      "Train Epoch: 4994 [11776/60000 (20%)] Loss: -1570.549316\n",
      "Train Epoch: 4994 [23040/60000 (38%)] Loss: -1524.109863\n",
      "Train Epoch: 4994 [34304/60000 (57%)] Loss: -1611.553223\n",
      "Train Epoch: 4994 [45568/60000 (76%)] Loss: -1511.208008\n",
      "Train Epoch: 4994 [56832/60000 (95%)] Loss: -1419.338867\n",
      "    epoch          : 4994\n",
      "    loss           : -1548.4382796637756\n",
      "Train Epoch: 4995 [512/60000 (1%)] Loss: -1639.439697\n",
      "Train Epoch: 4995 [11776/60000 (20%)] Loss: -1517.287476\n",
      "Train Epoch: 4995 [23040/60000 (38%)] Loss: -1524.982910\n",
      "Train Epoch: 4995 [34304/60000 (57%)] Loss: -1514.981445\n",
      "Train Epoch: 4995 [45568/60000 (76%)] Loss: -1437.440186\n",
      "Train Epoch: 4995 [56832/60000 (95%)] Loss: -1546.819824\n",
      "    epoch          : 4995\n",
      "    loss           : -1548.1110412252826\n",
      "Train Epoch: 4996 [512/60000 (1%)] Loss: -1589.277710\n",
      "Train Epoch: 4996 [11776/60000 (20%)] Loss: -1537.367432\n",
      "Train Epoch: 4996 [23040/60000 (38%)] Loss: -1518.282104\n",
      "Train Epoch: 4996 [34304/60000 (57%)] Loss: -1519.635986\n",
      "Train Epoch: 4996 [45568/60000 (76%)] Loss: -1595.675659\n",
      "Train Epoch: 4996 [56832/60000 (95%)] Loss: -1522.457275\n",
      "    epoch          : 4996\n",
      "    loss           : -1541.9488721944517\n",
      "Train Epoch: 4997 [512/60000 (1%)] Loss: -1549.213013\n",
      "Train Epoch: 4997 [11776/60000 (20%)] Loss: -1525.258301\n",
      "Train Epoch: 4997 [23040/60000 (38%)] Loss: -1505.163208\n",
      "Train Epoch: 4997 [34304/60000 (57%)] Loss: -1501.285889\n",
      "Train Epoch: 4997 [45568/60000 (76%)] Loss: -1515.766357\n",
      "Train Epoch: 4997 [56832/60000 (95%)] Loss: -1580.176514\n",
      "    epoch          : 4997\n",
      "    loss           : -1545.5460291285972\n",
      "Train Epoch: 4998 [512/60000 (1%)] Loss: -1530.666748\n",
      "Train Epoch: 4998 [11776/60000 (20%)] Loss: -1555.277100\n",
      "Train Epoch: 4998 [23040/60000 (38%)] Loss: -1596.366089\n",
      "Train Epoch: 4998 [34304/60000 (57%)] Loss: -1499.547852\n",
      "Train Epoch: 4998 [45568/60000 (76%)] Loss: -1528.420898\n",
      "Train Epoch: 4998 [56832/60000 (95%)] Loss: -1605.965332\n",
      "    epoch          : 4998\n",
      "    loss           : -1553.0222936942753\n",
      "Train Epoch: 4999 [512/60000 (1%)] Loss: -1517.958252\n",
      "Train Epoch: 4999 [11776/60000 (20%)] Loss: -1573.688965\n",
      "Train Epoch: 4999 [23040/60000 (38%)] Loss: -1494.429321\n",
      "Train Epoch: 4999 [34304/60000 (57%)] Loss: -1565.843994\n",
      "Train Epoch: 4999 [45568/60000 (76%)] Loss: -1524.224243\n",
      "Train Epoch: 4999 [56832/60000 (95%)] Loss: -1533.423096\n",
      "    epoch          : 4999\n",
      "    loss           : -1545.0861695715262\n",
      "Train Epoch: 5000 [512/60000 (1%)] Loss: -1510.647095\n",
      "Train Epoch: 5000 [11776/60000 (20%)] Loss: -1538.437988\n",
      "Train Epoch: 5000 [23040/60000 (38%)] Loss: -1573.894287\n",
      "Train Epoch: 5000 [34304/60000 (57%)] Loss: -1544.522705\n",
      "Train Epoch: 5000 [45568/60000 (76%)] Loss: -1595.790161\n",
      "Train Epoch: 5000 [56832/60000 (95%)] Loss: -1544.642700\n",
      "    epoch          : 5000\n",
      "    loss           : -1545.351945952507\n",
      "Saving checkpoint: saved/models/Mnist_DeepGenerativeOperad/0127_111843/checkpoint-epoch5000.pth ...\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepGenerativeOperadicModel(\n",
       "  (_operad): FreeOperad(\n",
       "    (generator_0): DensityDecoder(\n",
       "      (distribution): DiagonalGaussian()\n",
       "      (neural_layers): Sequential(\n",
       "        (0): Linear(in_features=16, out_features=24, bias=True)\n",
       "        (1): LayerNorm((24,), eps=1e-05, elementwise_affine=True)\n",
       "        (2): PReLU(num_parameters=1)\n",
       "        (3): Linear(in_features=24, out_features=24, bias=True)\n",
       "        (4): LayerNorm((24,), eps=1e-05, elementwise_affine=True)\n",
       "        (5): PReLU(num_parameters=1)\n",
       "        (6): Linear(in_features=24, out_features=64, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (generator_1): DensityDecoder(\n",
       "      (distribution): DiagonalGaussian()\n",
       "      (neural_layers): Sequential(\n",
       "        (0): Linear(in_features=16, out_features=40, bias=True)\n",
       "        (1): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
       "        (2): PReLU(num_parameters=1)\n",
       "        (3): Linear(in_features=40, out_features=40, bias=True)\n",
       "        (4): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
       "        (5): PReLU(num_parameters=1)\n",
       "        (6): Linear(in_features=40, out_features=128, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (generator_2): DensityDecoder(\n",
       "      (distribution): DiagonalGaussian()\n",
       "      (neural_layers): Sequential(\n",
       "        (0): Linear(in_features=16, out_features=72, bias=True)\n",
       "        (1): LayerNorm((72,), eps=1e-05, elementwise_affine=True)\n",
       "        (2): PReLU(num_parameters=1)\n",
       "        (3): Linear(in_features=72, out_features=72, bias=True)\n",
       "        (4): LayerNorm((72,), eps=1e-05, elementwise_affine=True)\n",
       "        (5): PReLU(num_parameters=1)\n",
       "        (6): Linear(in_features=72, out_features=256, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (generator_3): DensityDecoder(\n",
       "      (distribution): DiagonalGaussian()\n",
       "      (neural_layers): Sequential(\n",
       "        (0): Linear(in_features=16, out_features=106, bias=True)\n",
       "        (1): LayerNorm((106,), eps=1e-05, elementwise_affine=True)\n",
       "        (2): PReLU(num_parameters=1)\n",
       "        (3): Linear(in_features=106, out_features=106, bias=True)\n",
       "        (4): LayerNorm((106,), eps=1e-05, elementwise_affine=True)\n",
       "        (5): PReLU(num_parameters=1)\n",
       "        (6): Linear(in_features=106, out_features=392, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (generator_4): DensityDecoder(\n",
       "      (distribution): ContinuousBernoulliModel()\n",
       "      (dense_layers): Sequential(\n",
       "        (0): Linear(in_features=16, out_features=2744, bias=True)\n",
       "        (1): LayerNorm((2744,), eps=1e-05, elementwise_affine=True)\n",
       "        (2): PReLU(num_parameters=1)\n",
       "        (3): Linear(in_features=2744, out_features=2744, bias=True)\n",
       "      )\n",
       "      (conv_layers): Sequential(\n",
       "        (0): ConvTranspose2d(56, 28, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "        (1): InstanceNorm2d(28, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (2): PReLU(num_parameters=1)\n",
       "        (3): ConvTranspose2d(28, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "        (4): ReflectionPad2d((0, 0, 0, 0))\n",
       "      )\n",
       "    )\n",
       "    (generator_5): DensityDecoder(\n",
       "      (distribution): DiagonalGaussian()\n",
       "      (neural_layers): Sequential(\n",
       "        (0): Linear(in_features=32, out_features=48, bias=True)\n",
       "        (1): LayerNorm((48,), eps=1e-05, elementwise_affine=True)\n",
       "        (2): PReLU(num_parameters=1)\n",
       "        (3): Linear(in_features=48, out_features=48, bias=True)\n",
       "        (4): LayerNorm((48,), eps=1e-05, elementwise_affine=True)\n",
       "        (5): PReLU(num_parameters=1)\n",
       "        (6): Linear(in_features=48, out_features=128, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (generator_6): DensityDecoder(\n",
       "      (distribution): DiagonalGaussian()\n",
       "      (neural_layers): Sequential(\n",
       "        (0): Linear(in_features=32, out_features=80, bias=True)\n",
       "        (1): LayerNorm((80,), eps=1e-05, elementwise_affine=True)\n",
       "        (2): PReLU(num_parameters=1)\n",
       "        (3): Linear(in_features=80, out_features=80, bias=True)\n",
       "        (4): LayerNorm((80,), eps=1e-05, elementwise_affine=True)\n",
       "        (5): PReLU(num_parameters=1)\n",
       "        (6): Linear(in_features=80, out_features=256, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (generator_7): DensityDecoder(\n",
       "      (distribution): DiagonalGaussian()\n",
       "      (neural_layers): Sequential(\n",
       "        (0): Linear(in_features=32, out_features=114, bias=True)\n",
       "        (1): LayerNorm((114,), eps=1e-05, elementwise_affine=True)\n",
       "        (2): PReLU(num_parameters=1)\n",
       "        (3): Linear(in_features=114, out_features=114, bias=True)\n",
       "        (4): LayerNorm((114,), eps=1e-05, elementwise_affine=True)\n",
       "        (5): PReLU(num_parameters=1)\n",
       "        (6): Linear(in_features=114, out_features=392, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (generator_8): DensityDecoder(\n",
       "      (distribution): ContinuousBernoulliModel()\n",
       "      (dense_layers): Sequential(\n",
       "        (0): Linear(in_features=32, out_features=2744, bias=True)\n",
       "        (1): LayerNorm((2744,), eps=1e-05, elementwise_affine=True)\n",
       "        (2): PReLU(num_parameters=1)\n",
       "        (3): Linear(in_features=2744, out_features=2744, bias=True)\n",
       "      )\n",
       "      (conv_layers): Sequential(\n",
       "        (0): ConvTranspose2d(56, 28, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "        (1): InstanceNorm2d(28, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (2): PReLU(num_parameters=1)\n",
       "        (3): ConvTranspose2d(28, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "        (4): ReflectionPad2d((0, 0, 0, 0))\n",
       "      )\n",
       "    )\n",
       "    (generator_9): DensityDecoder(\n",
       "      (distribution): DiagonalGaussian()\n",
       "      (neural_layers): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=96, bias=True)\n",
       "        (1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "        (2): PReLU(num_parameters=1)\n",
       "        (3): Linear(in_features=96, out_features=96, bias=True)\n",
       "        (4): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "        (5): PReLU(num_parameters=1)\n",
       "        (6): Linear(in_features=96, out_features=256, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (generator_10): DensityDecoder(\n",
       "      (distribution): DiagonalGaussian()\n",
       "      (neural_layers): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=130, bias=True)\n",
       "        (1): LayerNorm((130,), eps=1e-05, elementwise_affine=True)\n",
       "        (2): PReLU(num_parameters=1)\n",
       "        (3): Linear(in_features=130, out_features=130, bias=True)\n",
       "        (4): LayerNorm((130,), eps=1e-05, elementwise_affine=True)\n",
       "        (5): PReLU(num_parameters=1)\n",
       "        (6): Linear(in_features=130, out_features=392, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (generator_11): DensityDecoder(\n",
       "      (distribution): ContinuousBernoulliModel()\n",
       "      (dense_layers): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=2744, bias=True)\n",
       "        (1): LayerNorm((2744,), eps=1e-05, elementwise_affine=True)\n",
       "        (2): PReLU(num_parameters=1)\n",
       "        (3): Linear(in_features=2744, out_features=2744, bias=True)\n",
       "      )\n",
       "      (conv_layers): Sequential(\n",
       "        (0): ConvTranspose2d(56, 28, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "        (1): InstanceNorm2d(28, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (2): PReLU(num_parameters=1)\n",
       "        (3): ConvTranspose2d(28, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "        (4): ReflectionPad2d((0, 0, 0, 0))\n",
       "      )\n",
       "    )\n",
       "    (generator_12): DensityDecoder(\n",
       "      (distribution): DiagonalGaussian()\n",
       "      (neural_layers): Sequential(\n",
       "        (0): Linear(in_features=128, out_features=162, bias=True)\n",
       "        (1): LayerNorm((162,), eps=1e-05, elementwise_affine=True)\n",
       "        (2): PReLU(num_parameters=1)\n",
       "        (3): Linear(in_features=162, out_features=162, bias=True)\n",
       "        (4): LayerNorm((162,), eps=1e-05, elementwise_affine=True)\n",
       "        (5): PReLU(num_parameters=1)\n",
       "        (6): Linear(in_features=162, out_features=392, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (generator_13): DensityDecoder(\n",
       "      (distribution): ContinuousBernoulliModel()\n",
       "      (dense_layers): Sequential(\n",
       "        (0): Linear(in_features=128, out_features=2744, bias=True)\n",
       "        (1): LayerNorm((2744,), eps=1e-05, elementwise_affine=True)\n",
       "        (2): PReLU(num_parameters=1)\n",
       "        (3): Linear(in_features=2744, out_features=2744, bias=True)\n",
       "      )\n",
       "      (conv_layers): Sequential(\n",
       "        (0): ConvTranspose2d(56, 28, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "        (1): InstanceNorm2d(28, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (2): PReLU(num_parameters=1)\n",
       "        (3): ConvTranspose2d(28, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "        (4): ReflectionPad2d((0, 0, 0, 0))\n",
       "      )\n",
       "    )\n",
       "    (generator_14): DensityDecoder(\n",
       "      (distribution): ContinuousBernoulliModel()\n",
       "      (dense_layers): Sequential(\n",
       "        (0): Linear(in_features=196, out_features=2744, bias=True)\n",
       "        (1): LayerNorm((2744,), eps=1e-05, elementwise_affine=True)\n",
       "        (2): PReLU(num_parameters=1)\n",
       "        (3): Linear(in_features=2744, out_features=2744, bias=True)\n",
       "      )\n",
       "      (conv_layers): Sequential(\n",
       "        (0): ConvTranspose2d(56, 28, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "        (1): InstanceNorm2d(28, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (2): PReLU(num_parameters=1)\n",
       "        (3): ConvTranspose2d(28, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "        (4): ReflectionPad2d((0, 0, 0, 0))\n",
       "      )\n",
       "    )\n",
       "    (global_element_0): StandardNormal()\n",
       "    (global_element_1): StandardNormal()\n",
       "    (global_element_2): StandardNormal()\n",
       "    (global_element_3): StandardNormal()\n",
       "    (global_element_4): StandardNormal()\n",
       "  )\n",
       "  (guide_temperatures): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=256, bias=True)\n",
       "    (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    (2): PReLU(num_parameters=1)\n",
       "    (3): Linear(in_features=256, out_features=2, bias=True)\n",
       "    (4): Softplus(beta=1, threshold=20)\n",
       "  )\n",
       "  (guide_arrow_weights): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=256, bias=True)\n",
       "    (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    (2): PReLU(num_parameters=1)\n",
       "    (3): Linear(in_features=256, out_features=40, bias=True)\n",
       "  )\n",
       "  (asvi_params): PyroModuleDict(\n",
       "    (prior_logits): PyroParameterDict(\n",
       "        ($Z^{196}$): Parameter containing: [torch.FloatTensor of size 60000]\n",
       "        ($Z^{128}$): Parameter containing: [torch.FloatTensor of size 60000]\n",
       "        ($Z^{32}$): Parameter containing: [torch.FloatTensor of size 60000]\n",
       "        ($Z^{64}$): Parameter containing: [torch.FloatTensor of size 60000]\n",
       "        ($Z^{16}$): Parameter containing: [torch.FloatTensor of size 60000]\n",
       "    )\n",
       "    (mean_fields): PyroModuleDict(\n",
       "      ($Z^{196}$): PyroParameterDict(\n",
       "          (loc): Parameter containing: [torch.FloatTensor of size 60000x196]\n",
       "          (scale): Parameter containing: [torch.FloatTensor of size 60000x196]\n",
       "      )\n",
       "      ($Z^{128}$): PyroParameterDict(\n",
       "          (loc): Parameter containing: [torch.FloatTensor of size 60000x128]\n",
       "          (scale): Parameter containing: [torch.FloatTensor of size 60000x128]\n",
       "      )\n",
       "      ($Z^{32}$): PyroParameterDict(\n",
       "          (loc): Parameter containing: [torch.FloatTensor of size 60000x32]\n",
       "          (scale): Parameter containing: [torch.FloatTensor of size 60000x32]\n",
       "      )\n",
       "      ($Z^{64}$): PyroParameterDict(\n",
       "          (loc): Parameter containing: [torch.FloatTensor of size 60000x64]\n",
       "          (scale): Parameter containing: [torch.FloatTensor of size 60000x64]\n",
       "      )\n",
       "      ($Z^{16}$): PyroParameterDict(\n",
       "          (loc): Parameter containing: [torch.FloatTensor of size 60000x16]\n",
       "          (scale): Parameter containing: [torch.FloatTensor of size 60000x16]\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAb4AAAEuCAYAAADx63eqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAALyklEQVR4nO3cP3KbR57H4W9vOaAzFBJPDN8A5pxgwdAZaJ9giBuIpROoyBuINxgSN+B7BA5uIMTjwChssnawVb2BSJj6Z49sERT1e54qlgjgBbqp5FPdb5Ot9x4AqOK/HnsCALBPwgdAKcIHQCnCB0ApwgdAKcIHQCnCB0ApwgdAKcIHQCnCB0ApwgdAKcIHQCnCB0ApwgdAKcIHQCnCB0ApwgdAKcIHQCnCB0ApwgdAKcIHQCnCB0ApwgdAKcIHQCnCB0ApwgdAKcIHQCnCB0ApwgdAKcIHQClf7XOwr7/++t+//vrrN/scE4Cn4eDg4Kdffvnlbw89Tuu9P/QYvw3WWt/neAA8Ha219N7bQ49jqxOAUoQPgFKED4BShA+AUoQPgFKED4BShA+AUoQPgFKED4BShA+AUoQPgFKED4BShA+AUoQPgFKED4BShA+AUoQPgFKED4BShA+AUoQPgFKED4BShA+AUoQPgFKED4BShA+AUoQPgFKEDz4D6/U6q9Uq5+fn2W637zwGPh3hg8/AeDzOZDJJkmw2m6xWq0yn08xms1xeXj7y7ODLInzwwJbL5RuPF4tFTk9Ps1wuc3FxkW+//Taj0eiNa+bzeZJkGIbMZrMkyXa7feezgI8nfPCAhmHIdDp947nvvvsuZ2dnmc/nubq6yvX1dZbLZUajUWaz2S5uwzBkPp9nPB4nyS6O6/V6rz8DfGla731/g7XW9zke7MtqtcowDJlMJplMJlmv15nP5zk9Pc3Z2dl733N8fJznz59nOp1mvV5nu91mGIacnJzk5uYmZ2dnmUwmOTo62q0Ak/zuZ8JT1lpL77099DhfPfQAUMXPP/+c2WyW6XSaFy9eZD6ff/BgymKxyI8//rhbDd7d37t7PJvNdlucb7Pig7/GVid8Anertrtw/d5JzPPz83z77be7MH7sqc27rU/gzxE++MSWy2UWi8UHX3v16lWePXuWJLm8vHznYAvwsIQPPoH79+g2m83untz9qK1Wq5yenubo6GgXx1evXn30WEIJf43DLfAJXFxcZDKZvHNf7v6Bl0/hU38efE72dbjFig/+ou12m6urq/e+NpvNslqtPtk4SUQP/iIrPgA+C1Z8APAAhA+AUoQPgFKED4BShA+AUoQPgFKED4BShA+AUoQPgFKED4BShA+AUoQPgFKED4BShA+AUoQPgFKED4BShA+AUoQPgFKED4BShA+AUoQPgFKED4BShA+AUoQPgFKED4BShA+AUoQPgFKED4BSvtrnYAcHBz+11r7Z55gAPA0HBwc/7WOc1nvfxzjAPa2175Oc9N6/f+y5QDW2OgEoRfgAKEX4AChF+AAoRfgAKEX4AChF+AAoRfgAKEX4AChF+AAoZa9/qxPgobXWJklGSWZJLpKM7z/uvW8fa258Hqz4gC/NJsn69vtxkmnvfZVkSPLDo82Kz4YVH/DktNZmSY5vH75K8vckL3vvQ+9921ob3V3be1/efjtLsgzlWfEBT07vfUhyneS6936e5J9JNq21UWttfrudOSSZJ7tQLvN6NUhxwgd8ScZJVq21aW7v6d1G7/T2a/aYk+PzYKsTeMomrbWTJEdJ/nlvWzNJVrf/DrdfkMSKD3ja7g6xXL8VPfgg4QOeusu8vr938tgT4WkQPuDJub1vd3T7NU6yTTJqrZ095rx4GtzjA56c21Od9+/breM+Hv8hKz4AShE+AEoRPgBKET4AShE+AEoRPgBKET4AShE+AEoRPgBKET4AShE+AEoRPgBKET4AShE+AEoRPgBKET4AShE+AEoRPgBKET4AShE+AEoRPgBKET4AShE+AEoRPgBKET4AShE+AEoRPgBKET4AShE+AEoRPgBKET4AShE+AEoRPgBKET4AShE+AEoRPgBKET4AShE+AEoRPgBKET4AShE+AEoRPgBKET4AShE+AEoRPgBKET4AShE+eBz/l+R/H3sSUFHrve9tsK+//vrfv/766zd7GxCAJ+Pg4OCnX3755W8PPc5ew9da6/scD4Cno7WW3nt76HFsdQJQivABUIrwAVCK8AFQivABUIrwAVCK8AFQivABUIrwAVCK8AFQivABUIrwAVCK8AFQivABUIrwAVCK8AFQivABUIrwAVCK8AFQivABUIrwAVCK8AFQivABUIrwAVCK8AFQivABUIrwwQNaLpc5Pj7OYrHIxcVFttttVqtVlstlttvt7rrT09OP+tz1ep3VapXz8/Nst9t3HgMf9tVjTwC+ZJPJJFdXV1mv1xmPx7m5ucl6vc7h4WHW63Wm02lWq9VHx2o8Hmc8HidJNptNVqtV5vN5kuTy8jInJyef+keBL4YVH3yk5XL5zuPWWlarVZJksVjk9PQ02+020+k0yesV2mg0yuHhYf71r3/lH//4RyaTye4zRqPR7vuLi4skyTAMWSwWWSwWOT8/z/HxcYZheOf6JLvoDcOQ2WyWJNlut+/MFbDig48yDMMuZnfm83nm83k2m022222Oj4938Uleh/HuPZeXl3n58mW2220uLi4ymUwymUyyXq+zXq/fiOFsNtutBOfzeZbLZcbjcbbbbYZhyHw+z2w2y3K5zLNnz3bP3a0E7+L49udCdVZ88B5398uWy+XunlySXF9fvzciz58/z9nZWW5ubt6IXpLdNmeSHB4eZhiGrNfrXTAnk8lHbXVuNpvdFukwDDk5OckwDDk7O8vZ2dluVZi8DubLly//xP8AfLms+OADfv7558xms0yn07x48SLz+fyDgZpOp7m5ucnh4eE7rz179uyN6942Go1yfX39wXms1+tcXFzk+vo6P/74425b8/7nzWazd4J7//3Ab6z44D2m0+nu8EmSP1yRLZfLPH/+PC9evPjkc7lbYR4dHb0Rvf/U3WoTeE344A8sl8ssFovffX0+n+fk5OTBDpP88MMPGY/Hu4MvwJ8nfPAe6/V6d4hks9nsVlr3T1OuVqscHR29c8LyY38n70OGYcj19XWur6+z2WwyGo2y3W4/+vPfnh9U13rv+xustb7P8eDPujtx+fZ9s2EYdicxH3LsT/V7ePuYL3wqrbX03ttDj2PFB2/Zbre5urp672uz2Wz3+3qfu7v7kqIHb7LiA+CzYMUHAA9A+AAoRfgAKEX4AChF+AAoRfgAKEX4AChF+AAoRfgAKEX4AChF+AAoRfgAKEX4AChF+AAoRfgAKEX4AChF+AAoRfgAKEX4AChF+AAoRfgAKEX4AChF+AAoRfgAKEX4AChF+AAoRfgAKEX4AChF+AAo5at9DnZwcPBTa+2bfY4JwNNwcHDw0z7Gab33fYwD3NNa+z7JSe/9+8eeC1RjqxOAUoQPgFKED4BShA+AUoQPgFKED4BShA+AUoQPgFKED4BShA+AUoQP+KK01uattavW2svW2klrbdRam94+P7p33dkjTpNHtNc/Ug2wB+ve+3FrbZJkk+QwySTJze2/q9baNMno8abIYxI+4Mlprc2SHN8+fJXk70le9t6H3vvq9vlJ733dWru5vXaR5L/vfcx2X/Pl8yJ8wJPTex/uti1778vW2jzJprU26r1vbx/fBfCH3vvi9vqT1to6yTrJpLU26b2vH+Nn4PEIH/AlGef1Sm6SZLh97uZ2hbhJsrxdBY5iq7Ms4QOesklr7STJUZJ/9t6XSdJ7P7+74N7WZ+49t719DwU51Qk8ZXfblNd30YM/InzAU3eZ1/f3Th57IjwNwgc8Obf37I5uv+7u6438bh7/Cff4gCen9z7kt8Mryestz+EDl8MbrPgAKEX4AChF+AAoRfgAKEX4AChF+AAoRfgAKEX4AChF+AAoRfgAKEX4AChF+OBx/E+SV489Caio9d4few4AsDdWfACUInwAlCJ8AJQifACUInwAlCJ8AJQifACUInwAlCJ8AJQifACUInwAlCJ8AJQifACUInwAlCJ8AJQifACUInwAlCJ8AJQifACUInwAlCJ8AJQifACUInwAlCJ8AJQifACUInwAlCJ8AJQifACUInwAlCJ8AJTy/wTtGIEDMxcBAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAEFCAYAAADOqip4AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAQPElEQVR4nO3dzW9c53XH8XP4IkqiKI0o66V2/DZyYiN1k5YeIUCQRYFSQFEU6Wac7ror9R/I8J8grbIVFwG66MZm0E13JLII2qKAablBHbiuI9ZyndiSJXL0RkkkhycLPmONRnPPDIe8M5eH3w9AeOae+/LwWj/eO/eZex81MwEQ09CgGwAgPwQcCIyAA4ERcCAwAg4ENjLoBkSmqlURmRSRZRGpiUjZzGZz3ua0iFwxs7Ndzj8lIhURecvMLuTZNvQfR/CcqGpZRM6Z2ayZzclWyEt5b9fMFkRkaRuLvCsi7xU13Kp6bdBt2MsIeH7KInK78cbMrsr2gtcvJTOrDboRjrcG3YC9jIDnZ1FE3lXVi+loLulILiJbp9Lp55KqlpqmrajqVHp9RVXL6f2Vxnqa5ntmHa1UdSbNc7F1nnR6PpnmKatqVVWvpfnfb2pXNU2rpo8AXbe1ZXuZ7W637dS+D5uWb9eOtm1GYmb85PQjIlMiMi8iJlv/UEtNtSvpv9Micqlp+ryITKXXl0TkYsZ8364vbef95nU0Tb+UXpca22xp43zr+7RcuWkdF5vb3bTdrtrasn633c3bbvO7uO1oXo6frR+O4Dkys6tmdt7MVEQWZCsEjVrzZ95Sy6KNU/nbTa+X26y/1tiObIWq1d+LyO10JCynn04mU7sb270gIleb6tdattVVW7tsd+u2m3nt8Jbb1wh4ThqnkA1m9o40BSydnk6LE9yk1lrfhpKIXE3/+K+a2fkulnHDmUw2XuxiW7vddrt2bHe5fYOA56eUuslERCR9NlxKr2dE5LZtXfFu1Ke2u4Gmz69l2TpDaPW+iJxvmn/b20jraF7uXMa2utZFu/vSjv2AgOcsXQSqisiMiLyTJi+IyNmWo/xk41S66cLceRF5OwXigohMt1y8mk7ruCAi/5i211jHTPoD0rgA9cwpfMv2SmmeSvoDJCLfdrvVGhe3ZOtz/FIPbW3Wrt3PbLvN79KuHc8shyc0XaTAHqOqH5rZnutC2qvt3qs4ggOBEfA9KJ2Wlvfaaelebfdexik6EBhHcCAwAg4Elvvtogd0zA7KeN6bAfa1e7Jyy8xOtk7vKeCpH7ImXdzffFDG5Uf6V71sBkCXFmzuervp2z5Fb3w7q/EtrHZfoABQDL18Bj8nT24qWJKnvz4oIt/eorioqovr8ngn7QOwA70EvNTy/kTrDLb1FJOKmVVGZaynhgHYuV4CXpOmu4kAFFcvAf9AnhzFy7J1sz2AAtp2wG3rsUPldHGt1HzLI4Bi6ambzMwup5eEGygwvskGBEbAgcAIOBAYAQcCI+BAYAQcCIyAA4ERcCAwAg4ERsCBwAg4EBgBBwIj4EBgBBwIjIADgRFwIDACDgRGwIHACDgQGAEHAiPgQGC5jy6K/tPKm2790elD/grMLx/6/X23PnRzJbO28dXX/sqxqziCA4ERcCAwAg4ERsCBwAg4EBgBBwIj4EBg9IMX1MiZ0279678rZ9bW/vqOu+yPX/jYrX9+74Rb//TLU279wOfHM2unPnrJXfbIp9l96CIi9U8+c+t4GkdwILCeAq6qK6o6r6oXd7tBAHZPr6fob5vZwq62BMCu6/UUvaSqmR8CVXVGVRdVdXFdHve4CQA71WvAJ0VkWVWvtCua2ayZVcysMipjvbcOwI70FPAU4JqI1FS1urtNArBbth3wdPo9lUdjAOyuXi6yvSci5caR28zmdrdJEBG58bfZ/dwiIsM/vZVZ+/UP/sldtra56dZ/NfGaW//lkP/3/ctjxzJrXx8oucseOfOcWz9T99te/99rbn2/2XbA06n51fRDuIEC44suQGAEHAiMgAOBEXAgMAIOBMbtogMy/L2zbn35L/zuoF+88cvM2vHhw+6yP1/+U7f+z78959brdw+4dfexy6W6u+jq+rBbv/NDvxvtCN1kT+EIDgRGwIHACDgQGAEHAiPgQGAEHAiMgAOB0Q+eEx3xd+29N/3+3Fdf/8qtj+pGZu0frv+lu+ziv/rDC7/yH4/c+uao30f/8ET2737vJf+YUu8wsvHaEX/54VL2rar1mv846Yg4ggOBEXAgMAIOBEbAgcAIOBAYAQcCI+BAYPSD52T4T8649Vs/8O97Pjdec+uX/v9vMmvX/8V/5PIrv/CHD67fvevW/ZaLHDj3Z5m1tYkj7rL3J/x1rx1Tt64TzgroBwcQCQEHAiPgQGAEHAiMgAOBEXAgMAIOBEY/eE4ev3bKrddff+DW7675N0Z//JuXM2vf/c/7/rY79HPvlA1n91Vvjvr92PVD/r3m3rpFROzwQbe+33AEBwLrGHBVrarqfJtp06o6k1/TAOxUx4Cb2Vzze1WtpukL6f10Pk0DsFO9nKKfE5Gl9HpJRKZaZ1DVGVVdVNXFdXm8k/YB2IFeAl5qeX+idQYzmzWziplVRmWsp4YB2LleAl4TkcldbgeAHPQS8A/kyVG8LCLz2bMCGKSO/eDpIlpFVatmNmdmc6p6MU0vNS624Wkbh/y7ptcf+f25/3PD70c/9FX2+ofv+dc9/BG6Oxs5c9qt330+uw9/9Yw3eLhI/ajfuvqtDsck89e/33QMeArw8ZZpl9NLwg0UGF90AQIj4EBgBBwIjIADgRFwIDBuF81JfazD387HfjfZyDH/tsm1Y9ndQfe/mz2ErojIxP0X3bqN+v8sVs8+8+XFp3iPhK6XH7rLHh33hy7eWDru1vE0juBAYAQcCIyAA4ERcCAwAg4ERsCBwAg4EBj94Dk5/PtVtz60Ou7WVTvcVvlCdn/xrTf9Ry6vnviOW98cdcuy+rxft9ezH9t88qj/uOh7D/3HHg93eAKYPvD72fcbjuBAYAQcCIyAA4ERcCAwAg4ERsCBwAg4EBj94DnZHPN37ebxdbd+/LDfnzsylH2/+J3v+feaP3zeb9vQhN+28Qn/nu3vn7yRWVt5dNhd9sHjA269Uz+4jPnL7zccwYHACDgQGAEHAiPgQGAEHAiMgAOBEXAgMPrBczJy1+8rHrrjP7t87bQ//PDkePb95ut1f9m1AxtufXTUH8J3bMSvX7+b/ezyjQ5te3Dfvx983C+LHaQfvFnHI7iqVlV1vmXaiqrOq+rF/JoGYKe6GR98TlUvtEx+O40bDqDAev0MXlLV8q62BMCu6zXgkyKyrKpX2hVVdUZVF1V1cV06fXkYQF56CriZzZpZTURqqlrNqFfMrDIqYzttI4AebTvg6eg8lUdjAOyubq6iT4tIpelI/V6aXhXZugiXX/MA7EQ3V9EXROR40/uaiFxNP4Q7Q/2I/9FkeNW/Z7vj+jez/zY/euQ/2Hxz2W/bRoemrY76Y5frWHY/+VCHZYc79LGvHXXLsn4y+3nz+/FbXfvxdwb2DQIOBEbAgcAIOBAYAQcCI+BAYNwumpPhO/7tomM1//HBN2/5/UFDw9nDCw9d9++pPPqFW+78aOIOx4XVM9nddKsv+beqjp3yhxd+WPK72TZHstu2H49m+/F3BvYNAg4ERsCBwAg4EBgBBwIj4EBgBBwIjH7wnNQn/Fsy149k92OLiNhD//HC9iC7Pv4H/37P0u/8ju6xm35f9OZh/9HE9YPZt2yuvuwuKqeO3nfrnx/yvz/waDL7n/QRf9MhcQQHAiPgQGAEHAiMgAOBEXAgMAIOBEbAgcDoB8/J0IZ/3/LYSqfHJvv/a0YeZC9/+GaHbd966Nb1xrJf/85Jt14/mN22sUl/2+WJ2279i8OTbn3kof/I6P2GIzgQGAEHAiPgQGAEHAiMgAOBEXAgMAIOBEY/eE6Gav491WMr/t3Jm8N+P/mQM8rupn8ruawf95+bbidedOv3XvTvB7//VnZf949e+NJd9sfHfufWfz30mlsfeegPP7zfuAFX1ZKIlNPPOTN7J02vikhNRMpmNptzGwH0qNMp+s9EpGJmcyIiqjqTwi1mtpCmTefbRAC9cgNuZrNNR+iyiCyJyLn0X0n/ncqveQB2oquLbKpaFpHldNQutZRPtJl/RlUXVXVxXToOdAUgJ91eRa+a2YX0uiYi7jf+05G/YmaVUfEfPgggPx0DrqpVM7ucXk+JyAfy5CheFpH53FoHYEc6XUWfFpFLqvpumvSOmc2p6sVUKzUutuFp9c+W3Prk0UNu/fYP/eGDV09nd6Otnvb/bt99xe8mW5/wH+m88YL/sesnZ69l1kqj/u2i88vfd+sjn/qPTT54Lbsbzh+4OCY34Cm8Z9tMv5xeEm6gwPgmGxAYAQcCI+BAYAQcCIyAA4ERcCAwbhcdkKEvbrr1kdcn3Pr6sezao9N+P/bmUb9H+PAxv6/6jef8RxufPJA9BPD/PXjmm81P+ei3r7r1V//d74Pf+PwLt77fcAQHAiPgQGAEHAiMgAOBEXAgMAIOBEbAgcDoBx+Q+jffuPXjH5Xc+vDj7IfqrJ7qcD942R9id3XNX/6/b/v3ZH/8+OXM2sSS/0znN3614tY3f/OJW8fTOIIDgRFwIDACDgRGwIHACDgQGAEHAiPgQGD0gxdU/ZPP3Pq40x083mHdJ37y5/4M6g9d3OmwcODTP2TWNr6+4S676a8a28QRHAiMgAOBEXAgMAIOBEbAgcAIOBAYAQcCox98Hxr6t//Kdf37cRzuonKP4KpaUtUpVa2q6qWm6SuqOq+qF/NvIoBedTpF/5mIVMxsTkREVWfS9LfN7LyZXc61dQB2xD1FN7PZprdlEZlPr0uqWjazpdxaBmDHurrIpqplEVk2s4U0aVJEllX1Ssb8M6q6qKqL6+KPJQUgP91eRa+a2YXGGzObNbOaiNRUtdo6c6pXzKwyKmO71FQA29XxKrqqVhuftVV1SkQqIrJoZlfzbhyAnel0FX1aRC6p6oeq+qFsnZq/l2pVEZHGBTgAxdPpItuCiJxtU7qafgg3UGB8kw0IjIADgRFwIDACDgRGwIHACDgQGAEHAiPgQGAEHAiMgAOBEXAgMAIOBEbAgcAIOBCYmlm+G1D9RkSuN016TkRu5brR3tG23hS1bUVtl8jut+1lMzvZOjH3gD+zQdVFM6v0daNdom29KWrbitoukf61jVN0IDACDgQ2iIDPdp5lYGhbb4ratqK2S6RPbev7Z3AA/cMpOhAYAQcC62vA0yil002DGBZCEUdLTftqvs20ge+/jLYNdB86I+EOfJ8NcpTevgW8aaCEhfR+ul/b7kLhRkttHVCiSPsvY7CLQe/DZ0bCLdA+G9govf08gp8TkcZopEsiMtXHbXdSSgMsFlmR95/IgPdhGg+vcWW6LFv7qBD7LKNtIn3YZ/0MeKnl/Yk+brsTd7TUgii1vC/S/hMpyD5sGQm31FIe6D7b7ii9u6GfAa/J1i9UOJ1GSy2ImhR0/4kUah82j4Rbk2Lts22N0rsb+hnwD+TJX9SyiMxnz9o/6bNa0U532ynk/hMpzj5sMxJuYfZZa9v6tc/6FvB0gaGcLnSUmk5TBq2Qo6Wm/VRpaVch9l9r26QA+7DdSLhF2WeDHKWXb7IBgfFFFyAwAg4ERsCBwAg4EBgBBwIj4EBgBBwI7I/I7ASn63FrogAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAb4AAAEuCAYAAADx63eqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAOuUlEQVR4nO3dT3ITWbbA4XNf1MDMFJpUj8UOhGsFTx7WTIYVtLUDHF4BgXdg7aBN7kC5gwbtgBw3AxT5RjC7b2BZbQOmCrBly+f7Igisf3kvo1+czBQutdYAgCz+5743AADbJHwApCJ8AKQifACkInwApCJ8AKQifACkInwApCJ8AKQifACkInwApCJ8AKQifACkInwApCJ8AKQifACkInwApCJ8AKQifACkInwApCJ8AKQifACkInwApCJ8AKQifACkInwApCJ8AKQifACkInwApCJ8AKTy2zYXe/LkyX8+f/78+zbXBGA37O3tffj06dM/7nqdUmu96zX+u1gpdZvrAbA7SilRay13vY5TnQCkInwApCJ8AKQifACkInwApCJ8AKQifACkInwApCJ8AKQifACkInwApCJ8AKQifACkInzwQMzn82jb9qvHy+XyHncFj89Wfx8fcLP9/f3oui4iLqI3Go1iMpnc867g8THxwR1rmuba49lsFsfHx9E0Tczn83j69OlXn3n37l30fR9N02wmvsvHwK8x8cEdats2xuPxteeePXsWR0dHERFxcHAQi8Xiq88NBoOYTCaxWq2iaZoYj8cxGAwiIqLruhiNRne+d3is/AZ2uAXL5TLato3RaBSj0Si6rovpdBrHx8fx+vXrb37m8PAwTk5ONmE8PT2Njx8/xsnJSUREnJ+fx3A4jMlksoleRHz3mLDLtvUb2E18cEs+fvwYk8kkxuNxvHr1KqbTafR9/833zmazePHixbVp8OXLl9feczkVfunyOiDwc1zjg1swHo+j67pNyG4KXsTFZPf06dNNGL/33m8ZDoe/sFNA+OCWNU0Ts9nsxtfev3+/me7Oz8+vncYE7p7wwS3oui76vo+2bWO1WsV0Oo2IuBa15XIZx8fHcXBwsInj+/fvf3gtoYRf4+YWuAU3fe/u6g0vt+G2jwcPybZubjHxwS/q+z7evHnzzdcmk8mt/c8rl9cCRQ9+jYkPgAfBxAcAd0D4AEhF+ABIRfgASEX4AEhF+ABIRfgASEX4AEhF+ABIRfgASEX4AEhF+ABIRfgASEX4AEhF+ABIRfgASOW3bS62t7f3oZTy+zbXBGA37O3tfdjGOlv9DezAhVLKnxFxVGv98773Atk41QlAKsIHQCrCB0AqwgdAKsIHQCrCBzw6pZSjUsrky8ellPF97ouHYavf4wPYkrcRMYq4iF5EdLXW9n63xEMhfMDOWU9zh+uH7yPij4g4uyFuzyJiVUqZxkUAl1vaJg+U8AE7p9ballIG65+bddRWpZRBrbX/4u19RLQRMYyIaUQIX3Ku8QGPyXD99yQi/ljH8VVEPI+IcUTM72lfPCAmPmCXjdbX8A4i4l+11iYiotZ6+sX7BI8NEx+wy7r134vL6MFfET5g153HxfW9o/veCLtB+ICds76r82D9ZxgXN7AMSimv73Nf7AbX+ICds/7awtWvLnRfPIYbmfgASEX4AEhF+ABIRfgASEX4AEhF+ABIRfgASEX4AEhF+ABIRfgASEX4AEhF+ABIRfgASEX4AEhF+ABIRfgASEX4AEhF+ABIRfgASEX4AEhF+ABIRfgASEX4AEhF+ABIRfgASEX4AEhF+ABIpdRat7bYkydP/vP58+fft7YgADtjb2/vw6dPn/5x1+tsNXyllLrN9QDYHaWUqLWWu17HqU4AUhE+AFIRPgBSET4AUhE+AFIRPgBSET4AUhE+AFIRPgBSET4AUhE+AFIRPgBSET4AUhE+AFIRPtiC+XwebdvGcrncPHd8fPxLx/resYGb/XbfG4DHbj6fx2g0islksnluuVxG3/c/dbz9/f3ouu7GYwPfZ+KDX9A0zbXHs9ksjo+Po2mamM/n8fTp03j37l30fR9N01ybygaDwbXPzufziIho2zZms1nMZrM4PT2Nw8PDaxPeVV8e+/Jn4GYmPvhJbdvGeDy+9tyzZ8/i6OgoIiIODg5isVjE2dlZTCaTWK1W0TRNdF0Xo9Eouq7b/HzVZDLZTIPT6TSaponhcBh9338Vy8FgcO3YL1++jIj45nGBCyY++AvL5TJOT083U9XlRLVYLL6Ky2X0Dg8P4/Xr1zEajeLk5CTOz89juVzG0dFRTKfTGI1GP3yqc7VaRcRFcP/9739H3/dfHTviIpZnZ2e/+K+Gx8vEB3/Dx48fYzKZxHg8jlevXsV0Or0xXLPZLF68eLGZBgeDwSZKlwaDQSwWi++u2XVdzOfzWCwW8eLFi5hOpxERm6nu0pfHvvws8G0mPvgL4/E4uq7bhOx7k9rp6Wk8ffp0E8afvYElIjbT5MHBwSZ6f9dwOPzpdeGxEz74AU3TxGw2u/G19+/fbyay8/Pzr67J/ajnz5/HcDjc3PgC/Drhg7/QdV30fR9t28ZqtdpMX1ejtlwu4/j4OA4ODjZxfP/+/U+t17ZtLBaLWCwWsVqtYjAYRN/3P/S9v18NLjxmpda6vcVKqdtcD27DTd+Va9s2RqPRrd09OZ/Pv3m97kfd9r5gW0opUWstd72OiQ++o+/7ePPmzTdfm0wmD+5/S7m8pih6cDMTHwAPgokPAO6A8AGQivABkIrwAZCK8AGQivABkIrwAZCK8AGQivABkIrwAZCK8AGQivABkIrwAZCK8AGQivABkIrwAZDKb9tcbG9v70Mp5fdtrgnAbtjb2/uwjXW2+hvYgQullD8j4qjW+ud97wWycaoTgFSED4BUhA+AVIQPgFSED4BUhA94dEopR6WUSSllfOW51/e5Jx6OrX6PD+CulVKOIqKrtbZXnhtHxODeNsWDInzAzimlTCLicP3wfUT8ERFn69g9i4hVKWUaFwFcrt/Xb32jPEjCB+ycWmtbShmsf27WkVutn+sjoo2IYURMSymjiOgiYlRKGdVau/vZNQ+F8AGPyTAiXkXE84hYRcS81tqvgzi4x33xgAgfsMtG62t6BxHxr1prs35+fvVNtdZ+/R5wVyew0y5PWy6uRA++S/iAXXceF9f3ju57I+wG4QN2zvquzoP1n2Fc3NAy8F09/g7X+ICds/7aQnvlqe6Lx3AjEx8AqQgfAKkIHwCpCB8AqQgfAKkIHwCpCB8AqQgfAKkIHwCpCB8AqQgfAKkIHwCpCB8AqQgfAKkIHwCpCB8AqQgfAKkIHwCpCB8AqQgfAKkIHwCpCB8AqQgfAKkIHwCpCB8AqQgfAKmUWuvWFnvy5Ml/Pn/+/PvWFgRgZ+zt7X349OnTP+56na2Gr5RSt7keALujlBK11nLX6zjVCUAqwgdAKsIHQCrCB0AqwgdAKsIHQCrCB0AqwgdAKsIHQCrCB0AqwgdAKsIHQCrCB0AqwgdAKsIHd6hpmjg8PIzZbBbz+Tz6vo/lchlN00Tf95v3HR8f//Cx5/N5tG0by+Xyl44D2fx23xuAx2w0GsWbN2+i67oYDofx9u3b6Lou9vf3o+u6GI/HsVwur0Xw75jP5zEajWIymWye+5njQEYmPvhBTdN89biUspm8ZrNZHB8fR9/3MR6PIyKi67oYDAaxv78f7969i3/+858xGo02xxgMBpuf5/N5RES0bRuz2Sxms1mcnp7G4eFhtG0bERHv3r2Lvu+jaZprE9/V41y+Dlxn4oMf0LbtJmaXptNpTKfTWK1W0fd9HB4eXpvEmqbZfOb8/DzOzs6i7/vN1DYajaLruui67loMJ5PJZoKbTqfRNE0Mh8Po+z4Gg0FMJpNYrVbRNM3ms1ePcxnBL48L2Zn44BuWy2Wcnp5uJqrLyWmxWHwzIicnJ/H69et4+/bttehFxOY0Z0TE/v5+tG0bXddtgjkajX7oFOVqtYqTk5M4Pz+P5XIZR0dHNx5nOp3G2dnZj/3j4ZEz8cENPn78GJPJJMbjcbx69Sqm0+mNgRqPx/H27dvY39//6rWXL19ee9+XBoNBLBaLG/fRdV3M5/NYLBbx4sWLmE6nERFxdHT0t47Tdd2Nx4aMTHzwDePxeHPzSUT85UTWNE2cnJzEq1evbn0vlxPmwcHBJno/4nLaBC4IH/yFpmliNpt99/XpdBpHR0d3djPJ8+fPYzgcbm58AX6e8ME3dF0Xfd9H27axWq02k9bVuyaXy2UcHBxcey7i9r5L17ZtLBaLWCwWsVqtYjAYRN/3P3z8L/cH2ZVa6/YWK6Vucz34Wd/6nlzERYwu78S8y7W/vH73s7axX7gtpZSotZa7XsfEB1/o+z7evHnzzdcmk8m17809ZJfXJUUPrjPxAfAgmPgA4A4IHwCpCB8AqQgfAKkIHwCpCB8AqQgfAKkIHwCpCB8AqQgfAKkIHwCpCB8AqQgfAKkIHwCpCB8AqQgfAKn8ts3F9vb2PpRSft/mmgDshr29vQ/bWGerv4EduFBK+TMijmqtf973XiAbpzoBSEX4AEhF+ABIRfgASEX4AEhF+IBHpZQyLaW8KaWclVKOSimDUsp4/fzgyvte3+M2uUdb/R4fwBZ0tdbDUsooIlYRsR8Ro4h4u/57WUoZR8Tg/rbIfRI+YOeUUiYRcbh++D4i/oiIs1prW2tdrp8f1Vq7Usrb9XtnEfG/Vw7Tb2u/PCzCB+ycWmt7edqy1tqUUqYRsSqlDGqt/frxZQCf11pn6/cflVK6iOgiYlRKGdVau/v4N3B/hA94TIZxMcmNIqJdP/d2PSGuIqJZT4GDcKozLeEDdtmolHIUEQcR8a9aaxMRUWs9vXzDlVOfceW5fv0ZEnJXJ7DLLk9TLi6jB39F+IBddx4X1/eO7nsj7AbhA3bO+prdwfrP5XW9ge/m8Xe4xgfsnFprG/+9eSXi4pRne8Pb4RoTHwCpCB8AqQgfAKkIHwCpCB/cj/+Li/9jEtiyUmu97z0AwNaY+ABIRfgASEX4AEhF+ABIRfgASEX4AEhF+ABIRfgASEX4AEhF+ABIRfgASEX4AEhF+ABIRfgASEX4AEhF+ABIRfgASEX4AEhF+ABIRfgASEX4AEhF+ABIRfgASEX4AEhF+ABIRfgASEX4AEhF+ABIRfgASEX4AEjl/wHav5DdK0C2PQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for k in range(10):\n",
    "    path, sample = model(observations=None)\n",
    "    sample = sample.view(28, 28).detach().cpu().numpy()\n",
    "    path.draw()\n",
    "\n",
    "    plt.title('Sample from prior')\n",
    "    plt.imshow(sample)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:categorical_bpl] *",
   "language": "python",
   "name": "conda-env-categorical_bpl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
