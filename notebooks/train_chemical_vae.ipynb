{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/eli/AnacondaProjects/categorical_bpl\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit WARNING: [19:46:29] Enabling RDKit 2019.09.3 jupyter extensions\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import collections\n",
    "import pyro\n",
    "import torch\n",
    "import numpy as np\n",
    "import data_loader.data_loaders as module_data\n",
    "import model.model as module_arch\n",
    "from parse_config import ConfigParser\n",
    "from trainer import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyro.enable_validation(True)\n",
    "# torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seeds for reproducibility\n",
    "SEED = 123\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Args = collections.namedtuple('Args', 'config resume device')\n",
    "config = ConfigParser.from_args(Args(config='chemical_config.json', resume=None, device=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = config.get_logger('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup data_loader instances\n",
    "data_loader = config.init_obj('data_loader', module_data)\n",
    "valid_data_loader = data_loader.split_validation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model architecture, then print to console\n",
    "model = config.init_obj('arch', module_arch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = pyro.optim.ReduceLROnPlateau({\n",
    "    'optimizer': torch.optim.Adam,\n",
    "    'optim_args': {\n",
    "        \"lr\": 1e-4,\n",
    "        \"weight_decay\": 0,\n",
    "        \"amsgrad\": True\n",
    "    },\n",
    "    \"patience\": 5,\n",
    "    \"factor\": 0.1,\n",
    "    \"verbose\": True,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = config.init_obj('optimizer', pyro.optim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model, [], optimizer, config=config,\n",
    "                  data_loader=data_loader,\n",
    "                  valid_data_loader=valid_data_loader,\n",
    "                  lr_scheduler=optimizer, log_images=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [192/225000 (0%)] Loss: 82811.687500\n",
      "Train Epoch: 1 [2688/225000 (1%)] Loss: 79181.625000\n",
      "Train Epoch: 1 [5184/225000 (2%)] Loss: 63810.339844\n",
      "Train Epoch: 1 [7680/225000 (3%)] Loss: 74515.312500\n",
      "Train Epoch: 1 [10176/225000 (5%)] Loss: 68839.460938\n",
      "Train Epoch: 1 [12672/225000 (6%)] Loss: 61265.140625\n",
      "Train Epoch: 1 [15168/225000 (7%)] Loss: 53784.226562\n",
      "Train Epoch: 1 [17664/225000 (8%)] Loss: 49350.484375\n",
      "Train Epoch: 1 [20160/225000 (9%)] Loss: 45318.972656\n",
      "Train Epoch: 1 [22656/225000 (10%)] Loss: 43960.312500\n",
      "Train Epoch: 1 [25152/225000 (11%)] Loss: 42003.164062\n",
      "Train Epoch: 1 [27648/225000 (12%)] Loss: 40534.101562\n",
      "Train Epoch: 1 [30144/225000 (13%)] Loss: 39913.339844\n",
      "Train Epoch: 1 [32640/225000 (15%)] Loss: 39042.605469\n",
      "Train Epoch: 1 [35136/225000 (16%)] Loss: 38234.027344\n",
      "Train Epoch: 1 [37632/225000 (17%)] Loss: 37457.445312\n",
      "Train Epoch: 1 [40128/225000 (18%)] Loss: 37150.691406\n",
      "Train Epoch: 1 [42624/225000 (19%)] Loss: 48165.988281\n",
      "Train Epoch: 1 [45120/225000 (20%)] Loss: 36558.675781\n",
      "Train Epoch: 1 [47616/225000 (21%)] Loss: 35328.949219\n",
      "Train Epoch: 1 [50112/225000 (22%)] Loss: 36001.203125\n",
      "Train Epoch: 1 [52608/225000 (23%)] Loss: 34876.480469\n",
      "Train Epoch: 1 [55104/225000 (24%)] Loss: 34439.421875\n",
      "Train Epoch: 1 [57600/225000 (26%)] Loss: 34660.015625\n",
      "Train Epoch: 1 [60096/225000 (27%)] Loss: 33967.406250\n",
      "Train Epoch: 1 [62592/225000 (28%)] Loss: 33968.546875\n",
      "Train Epoch: 1 [65088/225000 (29%)] Loss: 33151.679688\n",
      "Train Epoch: 1 [67584/225000 (30%)] Loss: 33675.839844\n",
      "Train Epoch: 1 [70080/225000 (31%)] Loss: 33115.050781\n",
      "Train Epoch: 1 [72576/225000 (32%)] Loss: 31966.226562\n",
      "Train Epoch: 1 [75072/225000 (33%)] Loss: 31209.238281\n",
      "Train Epoch: 1 [77568/225000 (34%)] Loss: 30984.273438\n",
      "Train Epoch: 1 [80064/225000 (36%)] Loss: 30072.859375\n",
      "Train Epoch: 1 [82560/225000 (37%)] Loss: 30028.726562\n",
      "Train Epoch: 1 [85056/225000 (38%)] Loss: 29075.816406\n",
      "Train Epoch: 1 [87552/225000 (39%)] Loss: 29126.892578\n",
      "Train Epoch: 1 [90048/225000 (40%)] Loss: 28179.332031\n",
      "Train Epoch: 1 [92544/225000 (41%)] Loss: 27848.484375\n",
      "Train Epoch: 1 [95040/225000 (42%)] Loss: 28297.630859\n",
      "Train Epoch: 1 [97536/225000 (43%)] Loss: 27571.142578\n",
      "Train Epoch: 1 [100032/225000 (44%)] Loss: 27448.687500\n",
      "Train Epoch: 1 [102528/225000 (46%)] Loss: 26971.689453\n",
      "Train Epoch: 1 [105024/225000 (47%)] Loss: 26999.673828\n",
      "Train Epoch: 1 [107520/225000 (48%)] Loss: 26331.880859\n",
      "Train Epoch: 1 [110016/225000 (49%)] Loss: 26899.396484\n",
      "Train Epoch: 1 [112512/225000 (50%)] Loss: 26817.351562\n",
      "Train Epoch: 1 [115008/225000 (51%)] Loss: 26232.322266\n",
      "Train Epoch: 1 [117504/225000 (52%)] Loss: 26275.552734\n",
      "Train Epoch: 1 [120000/225000 (53%)] Loss: 25891.011719\n",
      "Train Epoch: 1 [122496/225000 (54%)] Loss: 26267.222656\n",
      "Train Epoch: 1 [124992/225000 (56%)] Loss: 26219.548828\n",
      "Train Epoch: 1 [127488/225000 (57%)] Loss: 26138.980469\n",
      "Train Epoch: 1 [129984/225000 (58%)] Loss: 26263.912109\n",
      "Train Epoch: 1 [132480/225000 (59%)] Loss: 25831.755859\n",
      "Train Epoch: 1 [134976/225000 (60%)] Loss: 26137.464844\n",
      "Train Epoch: 1 [137472/225000 (61%)] Loss: 25313.335938\n",
      "Train Epoch: 1 [139968/225000 (62%)] Loss: 25957.376953\n",
      "Train Epoch: 1 [142464/225000 (63%)] Loss: 24981.363281\n",
      "Train Epoch: 1 [144960/225000 (64%)] Loss: 25422.347656\n",
      "Train Epoch: 1 [147456/225000 (66%)] Loss: 25639.845703\n",
      "Train Epoch: 1 [149952/225000 (67%)] Loss: 24818.304688\n",
      "Train Epoch: 1 [152448/225000 (68%)] Loss: 25647.871094\n",
      "Train Epoch: 1 [154944/225000 (69%)] Loss: 24978.685547\n",
      "Train Epoch: 1 [157440/225000 (70%)] Loss: 24316.406250\n",
      "Train Epoch: 1 [159936/225000 (71%)] Loss: 24643.431641\n",
      "Train Epoch: 1 [162432/225000 (72%)] Loss: 23947.625000\n",
      "Train Epoch: 1 [164928/225000 (73%)] Loss: 25020.185547\n",
      "Train Epoch: 1 [167424/225000 (74%)] Loss: 25367.933594\n",
      "Train Epoch: 1 [169920/225000 (76%)] Loss: 24808.328125\n",
      "Train Epoch: 1 [172416/225000 (77%)] Loss: 24535.271484\n",
      "Train Epoch: 1 [174912/225000 (78%)] Loss: 24141.343750\n",
      "Train Epoch: 1 [177408/225000 (79%)] Loss: 24633.777344\n",
      "Train Epoch: 1 [179904/225000 (80%)] Loss: 24576.279297\n",
      "Train Epoch: 1 [182400/225000 (81%)] Loss: 24050.039062\n",
      "Train Epoch: 1 [184896/225000 (82%)] Loss: 23916.318359\n",
      "Train Epoch: 1 [187392/225000 (83%)] Loss: 24152.992188\n",
      "Train Epoch: 1 [189888/225000 (84%)] Loss: 23955.906250\n",
      "Train Epoch: 1 [192384/225000 (86%)] Loss: 23427.984375\n",
      "Train Epoch: 1 [194880/225000 (87%)] Loss: 23785.847656\n",
      "Train Epoch: 1 [197376/225000 (88%)] Loss: 24210.960938\n",
      "Train Epoch: 1 [199872/225000 (89%)] Loss: 23872.935547\n",
      "Train Epoch: 1 [202368/225000 (90%)] Loss: 23628.628906\n",
      "Train Epoch: 1 [204864/225000 (91%)] Loss: 24011.173828\n",
      "Train Epoch: 1 [207360/225000 (92%)] Loss: 23560.066406\n",
      "Train Epoch: 1 [209856/225000 (93%)] Loss: 23318.339844\n",
      "Train Epoch: 1 [212352/225000 (94%)] Loss: 23986.873047\n",
      "Train Epoch: 1 [214848/225000 (95%)] Loss: 23418.832031\n",
      "Train Epoch: 1 [217344/225000 (97%)] Loss: 23406.835938\n",
      "Train Epoch: 1 [219840/225000 (98%)] Loss: 23134.435547\n",
      "Train Epoch: 1 [222336/225000 (99%)] Loss: 24132.742188\n",
      "Train Epoch: 1 [224832/225000 (100%)] Loss: 24024.699219\n",
      "    epoch          : 1\n",
      "    loss           : 31931.124110094923\n",
      "    val_loss       : 23639.291135074527\n",
      "Train Epoch: 2 [192/225000 (0%)] Loss: 23588.898438\n",
      "Train Epoch: 2 [2688/225000 (1%)] Loss: 23462.605469\n",
      "Train Epoch: 2 [5184/225000 (2%)] Loss: 23360.632812\n",
      "Train Epoch: 2 [7680/225000 (3%)] Loss: 23802.386719\n",
      "Train Epoch: 2 [10176/225000 (5%)] Loss: 23489.876953\n",
      "Train Epoch: 2 [12672/225000 (6%)] Loss: 23526.894531\n",
      "Train Epoch: 2 [15168/225000 (7%)] Loss: 23741.677734\n",
      "Train Epoch: 2 [17664/225000 (8%)] Loss: 23876.281250\n",
      "Train Epoch: 2 [20160/225000 (9%)] Loss: 22841.261719\n",
      "Train Epoch: 2 [22656/225000 (10%)] Loss: 23592.908203\n",
      "Train Epoch: 2 [25152/225000 (11%)] Loss: 23720.912109\n",
      "Train Epoch: 2 [27648/225000 (12%)] Loss: 22972.119141\n",
      "Train Epoch: 2 [30144/225000 (13%)] Loss: 23045.326172\n",
      "Train Epoch: 2 [32640/225000 (15%)] Loss: 23277.035156\n",
      "Train Epoch: 2 [35136/225000 (16%)] Loss: 23636.583984\n",
      "Train Epoch: 2 [37632/225000 (17%)] Loss: 23061.412109\n",
      "Train Epoch: 2 [40128/225000 (18%)] Loss: 23045.242188\n",
      "Train Epoch: 2 [42624/225000 (19%)] Loss: 23121.396484\n",
      "Train Epoch: 2 [45120/225000 (20%)] Loss: 23679.992188\n",
      "Train Epoch: 2 [47616/225000 (21%)] Loss: 23312.949219\n",
      "Train Epoch: 2 [50112/225000 (22%)] Loss: 22661.550781\n",
      "Train Epoch: 2 [52608/225000 (23%)] Loss: 22978.644531\n",
      "Train Epoch: 2 [55104/225000 (24%)] Loss: 23672.468750\n",
      "Train Epoch: 2 [57600/225000 (26%)] Loss: 23336.179688\n",
      "Train Epoch: 2 [60096/225000 (27%)] Loss: 23135.074219\n",
      "Train Epoch: 2 [62592/225000 (28%)] Loss: 23740.394531\n",
      "Train Epoch: 2 [65088/225000 (29%)] Loss: 23428.832031\n",
      "Train Epoch: 2 [67584/225000 (30%)] Loss: 22625.416016\n",
      "Train Epoch: 2 [70080/225000 (31%)] Loss: 23335.396484\n",
      "Train Epoch: 2 [72576/225000 (32%)] Loss: 22748.707031\n",
      "Train Epoch: 2 [75072/225000 (33%)] Loss: 22968.324219\n",
      "Train Epoch: 2 [77568/225000 (34%)] Loss: 22980.357422\n",
      "Train Epoch: 2 [80064/225000 (36%)] Loss: 23293.619141\n",
      "Train Epoch: 2 [82560/225000 (37%)] Loss: 23421.542969\n",
      "Train Epoch: 2 [85056/225000 (38%)] Loss: 23351.507812\n",
      "Train Epoch: 2 [87552/225000 (39%)] Loss: 22974.298828\n",
      "Train Epoch: 2 [90048/225000 (40%)] Loss: 22630.246094\n",
      "Train Epoch: 2 [92544/225000 (41%)] Loss: 22065.646484\n",
      "Train Epoch: 2 [95040/225000 (42%)] Loss: 23119.886719\n",
      "Train Epoch: 2 [97536/225000 (43%)] Loss: 23111.121094\n",
      "Train Epoch: 2 [100032/225000 (44%)] Loss: 22247.703125\n",
      "Train Epoch: 2 [102528/225000 (46%)] Loss: 22598.736328\n",
      "Train Epoch: 2 [105024/225000 (47%)] Loss: 23100.740234\n",
      "Train Epoch: 2 [107520/225000 (48%)] Loss: 22799.832031\n",
      "Train Epoch: 2 [110016/225000 (49%)] Loss: 22244.531250\n",
      "Train Epoch: 2 [112512/225000 (50%)] Loss: 22123.878906\n",
      "Train Epoch: 2 [115008/225000 (51%)] Loss: 22405.515625\n",
      "Train Epoch: 2 [117504/225000 (52%)] Loss: 22622.804688\n",
      "Train Epoch: 2 [120000/225000 (53%)] Loss: 22712.880859\n",
      "Train Epoch: 2 [122496/225000 (54%)] Loss: 22603.519531\n",
      "Train Epoch: 2 [124992/225000 (56%)] Loss: 22498.394531\n",
      "Train Epoch: 2 [127488/225000 (57%)] Loss: 21783.957031\n",
      "Train Epoch: 2 [129984/225000 (58%)] Loss: 22349.542969\n",
      "Train Epoch: 2 [132480/225000 (59%)] Loss: 22265.380859\n",
      "Train Epoch: 2 [134976/225000 (60%)] Loss: 22022.777344\n",
      "Train Epoch: 2 [137472/225000 (61%)] Loss: 21788.136719\n",
      "Train Epoch: 2 [139968/225000 (62%)] Loss: 22025.078125\n",
      "Train Epoch: 2 [142464/225000 (63%)] Loss: 22144.460938\n",
      "Train Epoch: 2 [144960/225000 (64%)] Loss: 21211.353516\n",
      "Train Epoch: 2 [147456/225000 (66%)] Loss: 21800.470703\n",
      "Train Epoch: 2 [149952/225000 (67%)] Loss: 22449.892578\n",
      "Train Epoch: 2 [152448/225000 (68%)] Loss: 21631.953125\n",
      "Train Epoch: 2 [154944/225000 (69%)] Loss: 22389.730469\n",
      "Train Epoch: 2 [157440/225000 (70%)] Loss: 22320.433594\n",
      "Train Epoch: 2 [159936/225000 (71%)] Loss: 22034.058594\n",
      "Train Epoch: 2 [162432/225000 (72%)] Loss: 22315.689453\n",
      "Train Epoch: 2 [164928/225000 (73%)] Loss: 22363.074219\n",
      "Train Epoch: 2 [167424/225000 (74%)] Loss: 21698.652344\n",
      "Train Epoch: 2 [169920/225000 (76%)] Loss: 21956.460938\n",
      "Train Epoch: 2 [172416/225000 (77%)] Loss: 22185.693359\n",
      "Train Epoch: 2 [174912/225000 (78%)] Loss: 21851.396484\n",
      "Train Epoch: 2 [177408/225000 (79%)] Loss: 21922.736328\n",
      "Train Epoch: 2 [179904/225000 (80%)] Loss: 21679.335938\n",
      "Train Epoch: 2 [182400/225000 (81%)] Loss: 21960.757812\n",
      "Train Epoch: 2 [184896/225000 (82%)] Loss: 22521.900391\n",
      "Train Epoch: 2 [187392/225000 (83%)] Loss: 22038.535156\n",
      "Train Epoch: 2 [189888/225000 (84%)] Loss: 21680.878906\n",
      "Train Epoch: 2 [192384/225000 (86%)] Loss: 21541.296875\n",
      "Train Epoch: 2 [194880/225000 (87%)] Loss: 22211.597656\n",
      "Train Epoch: 2 [197376/225000 (88%)] Loss: 21972.972656\n",
      "Train Epoch: 2 [199872/225000 (89%)] Loss: 21832.082031\n",
      "Train Epoch: 2 [202368/225000 (90%)] Loss: 21773.550781\n",
      "Train Epoch: 2 [204864/225000 (91%)] Loss: 21760.320312\n",
      "Train Epoch: 2 [207360/225000 (92%)] Loss: 21319.447266\n",
      "Train Epoch: 2 [209856/225000 (93%)] Loss: 21798.593750\n",
      "Train Epoch: 2 [212352/225000 (94%)] Loss: 21864.230469\n",
      "Train Epoch: 2 [214848/225000 (95%)] Loss: 21844.406250\n",
      "Train Epoch: 2 [217344/225000 (97%)] Loss: 21662.882812\n",
      "Train Epoch: 2 [219840/225000 (98%)] Loss: 21598.648438\n",
      "Train Epoch: 2 [222336/225000 (99%)] Loss: 21947.603516\n",
      "Train Epoch: 2 [224832/225000 (100%)] Loss: 21952.671875\n",
      "    epoch          : 2\n",
      "    loss           : 22602.933402103776\n",
      "    val_loss       : 21641.625861329885\n",
      "Train Epoch: 3 [192/225000 (0%)] Loss: 21689.000000\n",
      "Train Epoch: 3 [2688/225000 (1%)] Loss: 21962.750000\n",
      "Train Epoch: 3 [5184/225000 (2%)] Loss: 21882.484375\n",
      "Train Epoch: 3 [7680/225000 (3%)] Loss: 22231.929688\n",
      "Train Epoch: 3 [10176/225000 (5%)] Loss: 21969.597656\n",
      "Train Epoch: 3 [12672/225000 (6%)] Loss: 21592.664062\n",
      "Train Epoch: 3 [15168/225000 (7%)] Loss: 21928.410156\n",
      "Train Epoch: 3 [17664/225000 (8%)] Loss: 21320.607422\n",
      "Train Epoch: 3 [20160/225000 (9%)] Loss: 21787.484375\n",
      "Train Epoch: 3 [22656/225000 (10%)] Loss: 21671.007812\n",
      "Train Epoch: 3 [25152/225000 (11%)] Loss: 21862.078125\n",
      "Train Epoch: 3 [27648/225000 (12%)] Loss: 21763.333984\n",
      "Train Epoch: 3 [30144/225000 (13%)] Loss: 21600.878906\n",
      "Train Epoch: 3 [32640/225000 (15%)] Loss: 21857.062500\n",
      "Train Epoch: 3 [35136/225000 (16%)] Loss: 22189.101562\n",
      "Train Epoch: 3 [37632/225000 (17%)] Loss: 21759.703125\n",
      "Train Epoch: 3 [40128/225000 (18%)] Loss: 21798.853516\n",
      "Train Epoch: 3 [42624/225000 (19%)] Loss: 21332.416016\n",
      "Train Epoch: 3 [45120/225000 (20%)] Loss: 21794.027344\n",
      "Train Epoch: 3 [47616/225000 (21%)] Loss: 21786.156250\n",
      "Train Epoch: 3 [50112/225000 (22%)] Loss: 21556.658203\n",
      "Train Epoch: 3 [52608/225000 (23%)] Loss: 21807.011719\n",
      "Train Epoch: 3 [55104/225000 (24%)] Loss: 21784.691406\n",
      "Train Epoch: 3 [57600/225000 (26%)] Loss: 21498.371094\n",
      "Train Epoch: 3 [60096/225000 (27%)] Loss: 21723.751953\n",
      "Train Epoch: 3 [62592/225000 (28%)] Loss: 21452.789062\n",
      "Train Epoch: 3 [65088/225000 (29%)] Loss: 21858.105469\n",
      "Train Epoch: 3 [67584/225000 (30%)] Loss: 21724.121094\n",
      "Train Epoch: 3 [70080/225000 (31%)] Loss: 21941.580078\n",
      "Train Epoch: 3 [72576/225000 (32%)] Loss: 21085.476562\n",
      "Train Epoch: 3 [75072/225000 (33%)] Loss: 21469.884766\n",
      "Train Epoch: 3 [77568/225000 (34%)] Loss: 21471.382812\n",
      "Train Epoch: 3 [80064/225000 (36%)] Loss: 21571.917969\n",
      "Train Epoch: 3 [82560/225000 (37%)] Loss: 21218.039062\n",
      "Train Epoch: 3 [85056/225000 (38%)] Loss: 21863.505859\n",
      "Train Epoch: 3 [87552/225000 (39%)] Loss: 21343.619141\n",
      "Train Epoch: 3 [90048/225000 (40%)] Loss: 21144.531250\n",
      "Train Epoch: 3 [92544/225000 (41%)] Loss: 21173.476562\n",
      "Train Epoch: 3 [95040/225000 (42%)] Loss: 21199.580078\n",
      "Train Epoch: 3 [97536/225000 (43%)] Loss: 21543.019531\n",
      "Train Epoch: 3 [100032/225000 (44%)] Loss: 21963.021484\n",
      "Train Epoch: 3 [102528/225000 (46%)] Loss: 21568.355469\n",
      "Train Epoch: 3 [105024/225000 (47%)] Loss: 21153.132812\n",
      "Train Epoch: 3 [107520/225000 (48%)] Loss: 21543.074219\n",
      "Train Epoch: 3 [110016/225000 (49%)] Loss: 21243.753906\n",
      "Train Epoch: 3 [112512/225000 (50%)] Loss: 21320.238281\n",
      "Train Epoch: 3 [115008/225000 (51%)] Loss: 21424.714844\n",
      "Train Epoch: 3 [117504/225000 (52%)] Loss: 21387.595703\n",
      "Train Epoch: 3 [120000/225000 (53%)] Loss: 21917.152344\n",
      "Train Epoch: 3 [122496/225000 (54%)] Loss: 21583.384766\n",
      "Train Epoch: 3 [124992/225000 (56%)] Loss: 21654.390625\n",
      "Train Epoch: 3 [127488/225000 (57%)] Loss: 21452.041016\n",
      "Train Epoch: 3 [129984/225000 (58%)] Loss: 21077.566406\n",
      "Train Epoch: 3 [132480/225000 (59%)] Loss: 21733.539062\n",
      "Train Epoch: 3 [134976/225000 (60%)] Loss: 21235.265625\n",
      "Train Epoch: 3 [137472/225000 (61%)] Loss: 21571.226562\n",
      "Train Epoch: 3 [139968/225000 (62%)] Loss: 21834.082031\n",
      "Train Epoch: 3 [142464/225000 (63%)] Loss: 21870.246094\n",
      "Train Epoch: 3 [144960/225000 (64%)] Loss: 21453.074219\n",
      "Train Epoch: 3 [147456/225000 (66%)] Loss: 21120.503906\n",
      "Train Epoch: 3 [149952/225000 (67%)] Loss: 21385.750000\n",
      "Train Epoch: 3 [152448/225000 (68%)] Loss: 21714.769531\n",
      "Train Epoch: 3 [154944/225000 (69%)] Loss: 21625.054688\n",
      "Train Epoch: 3 [157440/225000 (70%)] Loss: 21457.183594\n",
      "Train Epoch: 3 [159936/225000 (71%)] Loss: 21255.210938\n",
      "Train Epoch: 3 [162432/225000 (72%)] Loss: 20872.068359\n",
      "Train Epoch: 3 [164928/225000 (73%)] Loss: 21519.781250\n",
      "Train Epoch: 3 [167424/225000 (74%)] Loss: 21500.412109\n",
      "Train Epoch: 3 [169920/225000 (76%)] Loss: 21665.316406\n",
      "Train Epoch: 3 [172416/225000 (77%)] Loss: 21649.134766\n",
      "Train Epoch: 3 [174912/225000 (78%)] Loss: 21167.015625\n",
      "Train Epoch: 3 [177408/225000 (79%)] Loss: 21467.964844\n",
      "Train Epoch: 3 [179904/225000 (80%)] Loss: 21228.976562\n",
      "Train Epoch: 3 [182400/225000 (81%)] Loss: 21557.500000\n",
      "Train Epoch: 3 [184896/225000 (82%)] Loss: 21272.429688\n",
      "Train Epoch: 3 [187392/225000 (83%)] Loss: 21652.716797\n",
      "Train Epoch: 3 [189888/225000 (84%)] Loss: 21751.611328\n",
      "Train Epoch: 3 [192384/225000 (86%)] Loss: 21431.523438\n",
      "Train Epoch: 3 [194880/225000 (87%)] Loss: 21313.664062\n",
      "Train Epoch: 3 [197376/225000 (88%)] Loss: 21455.800781\n",
      "Train Epoch: 3 [199872/225000 (89%)] Loss: 20771.599609\n",
      "Train Epoch: 3 [202368/225000 (90%)] Loss: 22014.203125\n",
      "Train Epoch: 3 [204864/225000 (91%)] Loss: 20752.367188\n",
      "Train Epoch: 3 [207360/225000 (92%)] Loss: 21558.232422\n",
      "Train Epoch: 3 [209856/225000 (93%)] Loss: 21547.902344\n",
      "Train Epoch: 3 [212352/225000 (94%)] Loss: 21347.660156\n",
      "Train Epoch: 3 [214848/225000 (95%)] Loss: 21018.519531\n",
      "Train Epoch: 3 [217344/225000 (97%)] Loss: 21108.242188\n",
      "Train Epoch: 3 [219840/225000 (98%)] Loss: 20943.222656\n",
      "Train Epoch: 3 [222336/225000 (99%)] Loss: 20805.007812\n",
      "Train Epoch: 3 [224832/225000 (100%)] Loss: 21433.216797\n",
      "    epoch          : 3\n",
      "    loss           : 21558.244393931313\n",
      "    val_loss       : 21382.67244413791\n",
      "Train Epoch: 4 [192/225000 (0%)] Loss: 21353.726562\n",
      "Train Epoch: 4 [2688/225000 (1%)] Loss: 21347.148438\n",
      "Train Epoch: 4 [5184/225000 (2%)] Loss: 21578.308594\n",
      "Train Epoch: 4 [7680/225000 (3%)] Loss: 21424.664062\n",
      "Train Epoch: 4 [10176/225000 (5%)] Loss: 21118.910156\n",
      "Train Epoch: 4 [12672/225000 (6%)] Loss: 21247.863281\n",
      "Train Epoch: 4 [15168/225000 (7%)] Loss: 21494.205078\n",
      "Train Epoch: 4 [17664/225000 (8%)] Loss: 21449.765625\n",
      "Train Epoch: 4 [20160/225000 (9%)] Loss: 21336.460938\n",
      "Train Epoch: 4 [22656/225000 (10%)] Loss: 21342.763672\n",
      "Train Epoch: 4 [25152/225000 (11%)] Loss: 21446.535156\n",
      "Train Epoch: 4 [27648/225000 (12%)] Loss: 21682.056641\n",
      "Train Epoch: 4 [30144/225000 (13%)] Loss: 20915.023438\n",
      "Train Epoch: 4 [32640/225000 (15%)] Loss: 20729.000000\n",
      "Train Epoch: 4 [35136/225000 (16%)] Loss: 21471.394531\n",
      "Train Epoch: 4 [37632/225000 (17%)] Loss: 21532.960938\n",
      "Train Epoch: 4 [40128/225000 (18%)] Loss: 21184.509766\n",
      "Train Epoch: 4 [42624/225000 (19%)] Loss: 21077.863281\n",
      "Train Epoch: 4 [45120/225000 (20%)] Loss: 21452.257812\n",
      "Train Epoch: 4 [47616/225000 (21%)] Loss: 21076.492188\n",
      "Train Epoch: 4 [50112/225000 (22%)] Loss: 21398.640625\n",
      "Train Epoch: 4 [52608/225000 (23%)] Loss: 21202.468750\n",
      "Train Epoch: 4 [55104/225000 (24%)] Loss: 20544.925781\n",
      "Train Epoch: 4 [57600/225000 (26%)] Loss: 21628.568359\n",
      "Train Epoch: 4 [60096/225000 (27%)] Loss: 21126.589844\n",
      "Train Epoch: 4 [62592/225000 (28%)] Loss: 21228.925781\n",
      "Train Epoch: 4 [65088/225000 (29%)] Loss: 21362.912109\n",
      "Train Epoch: 4 [67584/225000 (30%)] Loss: 21222.671875\n",
      "Train Epoch: 4 [70080/225000 (31%)] Loss: 21291.796875\n",
      "Train Epoch: 4 [72576/225000 (32%)] Loss: 20967.734375\n",
      "Train Epoch: 4 [75072/225000 (33%)] Loss: 21832.296875\n",
      "Train Epoch: 4 [77568/225000 (34%)] Loss: 21011.007812\n",
      "Train Epoch: 4 [80064/225000 (36%)] Loss: 21059.617188\n",
      "Train Epoch: 4 [82560/225000 (37%)] Loss: 21376.638672\n",
      "Train Epoch: 4 [85056/225000 (38%)] Loss: 21931.917969\n",
      "Train Epoch: 4 [87552/225000 (39%)] Loss: 21223.943359\n",
      "Train Epoch: 4 [90048/225000 (40%)] Loss: 21111.812500\n",
      "Train Epoch: 4 [92544/225000 (41%)] Loss: 21641.546875\n",
      "Train Epoch: 4 [95040/225000 (42%)] Loss: 21383.011719\n",
      "Train Epoch: 4 [97536/225000 (43%)] Loss: 20735.371094\n",
      "Train Epoch: 4 [100032/225000 (44%)] Loss: 20937.728516\n",
      "Train Epoch: 4 [102528/225000 (46%)] Loss: 21324.207031\n",
      "Train Epoch: 4 [105024/225000 (47%)] Loss: 20575.242188\n",
      "Train Epoch: 4 [107520/225000 (48%)] Loss: 21081.183594\n",
      "Train Epoch: 4 [110016/225000 (49%)] Loss: 21226.855469\n",
      "Train Epoch: 4 [112512/225000 (50%)] Loss: 21420.025391\n",
      "Train Epoch: 4 [115008/225000 (51%)] Loss: 21084.496094\n",
      "Train Epoch: 4 [117504/225000 (52%)] Loss: 21157.763672\n",
      "Train Epoch: 4 [120000/225000 (53%)] Loss: 21262.980469\n",
      "Train Epoch: 4 [122496/225000 (54%)] Loss: 21428.214844\n",
      "Train Epoch: 4 [124992/225000 (56%)] Loss: 21364.531250\n",
      "Train Epoch: 4 [127488/225000 (57%)] Loss: 20997.656250\n",
      "Train Epoch: 4 [129984/225000 (58%)] Loss: 21470.615234\n",
      "Train Epoch: 4 [132480/225000 (59%)] Loss: 21428.263672\n",
      "Train Epoch: 4 [134976/225000 (60%)] Loss: 21947.796875\n",
      "Train Epoch: 4 [137472/225000 (61%)] Loss: 21009.492188\n",
      "Train Epoch: 4 [139968/225000 (62%)] Loss: 21043.275391\n",
      "Train Epoch: 4 [142464/225000 (63%)] Loss: 20668.621094\n",
      "Train Epoch: 4 [144960/225000 (64%)] Loss: 21427.078125\n",
      "Train Epoch: 4 [147456/225000 (66%)] Loss: 21003.443359\n",
      "Train Epoch: 4 [149952/225000 (67%)] Loss: 21141.687500\n",
      "Train Epoch: 4 [152448/225000 (68%)] Loss: 21222.332031\n",
      "Train Epoch: 4 [154944/225000 (69%)] Loss: 20991.068359\n",
      "Train Epoch: 4 [157440/225000 (70%)] Loss: 21288.017578\n",
      "Train Epoch: 4 [159936/225000 (71%)] Loss: 21248.339844\n",
      "Train Epoch: 4 [162432/225000 (72%)] Loss: 21424.007812\n",
      "Train Epoch: 4 [164928/225000 (73%)] Loss: 21162.392578\n",
      "Train Epoch: 4 [167424/225000 (74%)] Loss: 20838.437500\n",
      "Train Epoch: 4 [169920/225000 (76%)] Loss: 20786.910156\n",
      "Train Epoch: 4 [172416/225000 (77%)] Loss: 21268.890625\n",
      "Train Epoch: 4 [174912/225000 (78%)] Loss: 21066.937500\n",
      "Train Epoch: 4 [177408/225000 (79%)] Loss: 20698.464844\n",
      "Train Epoch: 4 [179904/225000 (80%)] Loss: 21143.425781\n",
      "Train Epoch: 4 [182400/225000 (81%)] Loss: 21136.617188\n",
      "Train Epoch: 4 [184896/225000 (82%)] Loss: 21346.355469\n",
      "Train Epoch: 4 [187392/225000 (83%)] Loss: 21073.146484\n",
      "Train Epoch: 4 [189888/225000 (84%)] Loss: 20746.304688\n",
      "Train Epoch: 4 [192384/225000 (86%)] Loss: 21057.173828\n",
      "Train Epoch: 4 [194880/225000 (87%)] Loss: 21375.371094\n",
      "Train Epoch: 4 [197376/225000 (88%)] Loss: 20716.574219\n",
      "Train Epoch: 4 [199872/225000 (89%)] Loss: 21784.060547\n",
      "Train Epoch: 4 [202368/225000 (90%)] Loss: 21184.228516\n",
      "Train Epoch: 4 [204864/225000 (91%)] Loss: 20781.949219\n",
      "Train Epoch: 4 [207360/225000 (92%)] Loss: 20878.066406\n",
      "Train Epoch: 4 [209856/225000 (93%)] Loss: 20769.806641\n",
      "Train Epoch: 4 [212352/225000 (94%)] Loss: 20803.699219\n",
      "Train Epoch: 4 [214848/225000 (95%)] Loss: 21051.285156\n",
      "Train Epoch: 4 [217344/225000 (97%)] Loss: 21563.984375\n",
      "Train Epoch: 4 [219840/225000 (98%)] Loss: 20774.707031\n",
      "Train Epoch: 4 [222336/225000 (99%)] Loss: 21097.636719\n",
      "Train Epoch: 4 [224832/225000 (100%)] Loss: 21148.675781\n",
      "    epoch          : 4\n",
      "    loss           : 21281.185568539357\n",
      "    val_loss       : 21153.943108900814\n",
      "Train Epoch: 5 [192/225000 (0%)] Loss: 21194.761719\n",
      "Train Epoch: 5 [2688/225000 (1%)] Loss: 21613.318359\n",
      "Train Epoch: 5 [5184/225000 (2%)] Loss: 21585.058594\n",
      "Train Epoch: 5 [7680/225000 (3%)] Loss: 21403.613281\n",
      "Train Epoch: 5 [10176/225000 (5%)] Loss: 21526.765625\n",
      "Train Epoch: 5 [12672/225000 (6%)] Loss: 20967.283203\n",
      "Train Epoch: 5 [15168/225000 (7%)] Loss: 21662.302734\n",
      "Train Epoch: 5 [17664/225000 (8%)] Loss: 21268.605469\n",
      "Train Epoch: 5 [20160/225000 (9%)] Loss: 20828.652344\n",
      "Train Epoch: 5 [22656/225000 (10%)] Loss: 21182.837891\n",
      "Train Epoch: 5 [25152/225000 (11%)] Loss: 20473.898438\n",
      "Train Epoch: 5 [27648/225000 (12%)] Loss: 22156.757812\n",
      "Train Epoch: 5 [30144/225000 (13%)] Loss: 21247.675781\n",
      "Train Epoch: 5 [32640/225000 (15%)] Loss: 20833.996094\n",
      "Train Epoch: 5 [35136/225000 (16%)] Loss: 21617.187500\n",
      "Train Epoch: 5 [37632/225000 (17%)] Loss: 21289.062500\n",
      "Train Epoch: 5 [40128/225000 (18%)] Loss: 21051.316406\n",
      "Train Epoch: 5 [42624/225000 (19%)] Loss: 20792.046875\n",
      "Train Epoch: 5 [45120/225000 (20%)] Loss: 20749.839844\n",
      "Train Epoch: 5 [47616/225000 (21%)] Loss: 20765.605469\n",
      "Train Epoch: 5 [50112/225000 (22%)] Loss: 21022.914062\n",
      "Train Epoch: 5 [52608/225000 (23%)] Loss: 21234.292969\n",
      "Train Epoch: 5 [55104/225000 (24%)] Loss: 21119.787109\n",
      "Train Epoch: 5 [57600/225000 (26%)] Loss: 21322.515625\n",
      "Train Epoch: 5 [60096/225000 (27%)] Loss: 21171.408203\n",
      "Train Epoch: 5 [62592/225000 (28%)] Loss: 21115.023438\n",
      "Train Epoch: 5 [65088/225000 (29%)] Loss: 21084.775391\n",
      "Train Epoch: 5 [67584/225000 (30%)] Loss: 21219.167969\n",
      "Train Epoch: 5 [70080/225000 (31%)] Loss: 20713.537109\n",
      "Train Epoch: 5 [72576/225000 (32%)] Loss: 20514.558594\n",
      "Train Epoch: 5 [75072/225000 (33%)] Loss: 20932.941406\n",
      "Train Epoch: 5 [77568/225000 (34%)] Loss: 21635.947266\n",
      "Train Epoch: 5 [80064/225000 (36%)] Loss: 20956.890625\n",
      "Train Epoch: 5 [82560/225000 (37%)] Loss: 21278.328125\n",
      "Train Epoch: 5 [85056/225000 (38%)] Loss: 20867.531250\n",
      "Train Epoch: 5 [87552/225000 (39%)] Loss: 20950.667969\n",
      "Train Epoch: 5 [90048/225000 (40%)] Loss: 21169.703125\n",
      "Train Epoch: 5 [92544/225000 (41%)] Loss: 20769.636719\n",
      "Train Epoch: 5 [95040/225000 (42%)] Loss: 20674.742188\n",
      "Train Epoch: 5 [97536/225000 (43%)] Loss: 20756.044922\n",
      "Train Epoch: 5 [100032/225000 (44%)] Loss: 21413.292969\n",
      "Train Epoch: 5 [102528/225000 (46%)] Loss: 20748.347656\n",
      "Train Epoch: 5 [105024/225000 (47%)] Loss: 21078.248047\n",
      "Train Epoch: 5 [107520/225000 (48%)] Loss: 20679.423828\n",
      "Train Epoch: 5 [110016/225000 (49%)] Loss: 20893.488281\n",
      "Train Epoch: 5 [112512/225000 (50%)] Loss: 21272.486328\n",
      "Train Epoch: 5 [115008/225000 (51%)] Loss: 20606.148438\n",
      "Train Epoch: 5 [117504/225000 (52%)] Loss: 20856.136719\n",
      "Train Epoch: 5 [120000/225000 (53%)] Loss: 21207.451172\n",
      "Train Epoch: 5 [122496/225000 (54%)] Loss: 21374.097656\n",
      "Train Epoch: 5 [124992/225000 (56%)] Loss: 21256.664062\n",
      "Train Epoch: 5 [127488/225000 (57%)] Loss: 21332.195312\n",
      "Train Epoch: 5 [129984/225000 (58%)] Loss: 20774.628906\n",
      "Train Epoch: 5 [132480/225000 (59%)] Loss: 20814.578125\n",
      "Train Epoch: 5 [134976/225000 (60%)] Loss: 20737.539062\n",
      "Train Epoch: 5 [137472/225000 (61%)] Loss: 21372.109375\n",
      "Train Epoch: 5 [139968/225000 (62%)] Loss: 20536.716797\n",
      "Train Epoch: 5 [142464/225000 (63%)] Loss: 21531.630859\n",
      "Train Epoch: 5 [144960/225000 (64%)] Loss: 21194.617188\n",
      "Train Epoch: 5 [147456/225000 (66%)] Loss: 21171.367188\n",
      "Train Epoch: 5 [149952/225000 (67%)] Loss: 21620.375000\n",
      "Train Epoch: 5 [152448/225000 (68%)] Loss: 20988.322266\n",
      "Train Epoch: 5 [154944/225000 (69%)] Loss: 21559.830078\n",
      "Train Epoch: 5 [157440/225000 (70%)] Loss: 21041.644531\n",
      "Train Epoch: 5 [159936/225000 (71%)] Loss: 20685.097656\n",
      "Train Epoch: 5 [162432/225000 (72%)] Loss: 20993.794922\n",
      "Train Epoch: 5 [164928/225000 (73%)] Loss: 20924.265625\n",
      "Train Epoch: 5 [167424/225000 (74%)] Loss: 20915.097656\n",
      "Train Epoch: 5 [169920/225000 (76%)] Loss: 20281.191406\n",
      "Train Epoch: 5 [172416/225000 (77%)] Loss: 20685.558594\n",
      "Train Epoch: 5 [174912/225000 (78%)] Loss: 20454.576172\n",
      "Train Epoch: 5 [177408/225000 (79%)] Loss: 21128.109375\n",
      "Train Epoch: 5 [179904/225000 (80%)] Loss: 21259.699219\n",
      "Train Epoch: 5 [182400/225000 (81%)] Loss: 20756.500000\n",
      "Train Epoch: 5 [184896/225000 (82%)] Loss: 20862.730469\n",
      "Train Epoch: 5 [187392/225000 (83%)] Loss: 21159.570312\n",
      "Train Epoch: 5 [189888/225000 (84%)] Loss: 21227.441406\n",
      "Train Epoch: 5 [192384/225000 (86%)] Loss: 21293.484375\n",
      "Train Epoch: 5 [194880/225000 (87%)] Loss: 21412.052734\n",
      "Train Epoch: 5 [197376/225000 (88%)] Loss: 20930.750000\n",
      "Train Epoch: 5 [199872/225000 (89%)] Loss: 21105.812500\n",
      "Train Epoch: 5 [202368/225000 (90%)] Loss: 21878.218750\n",
      "Train Epoch: 5 [204864/225000 (91%)] Loss: 20753.535156\n",
      "Train Epoch: 5 [207360/225000 (92%)] Loss: 20539.621094\n",
      "Train Epoch: 5 [209856/225000 (93%)] Loss: 20880.289062\n",
      "Train Epoch: 5 [212352/225000 (94%)] Loss: 21516.550781\n",
      "Train Epoch: 5 [214848/225000 (95%)] Loss: 20976.626953\n",
      "Train Epoch: 5 [217344/225000 (97%)] Loss: 21247.488281\n",
      "Train Epoch: 5 [219840/225000 (98%)] Loss: 20806.365234\n",
      "Train Epoch: 5 [222336/225000 (99%)] Loss: 21305.312500\n",
      "Train Epoch: 5 [224832/225000 (100%)] Loss: 21058.996094\n",
      "    epoch          : 5\n",
      "    loss           : 21137.57281223336\n",
      "    val_loss       : 21053.74821007684\n",
      "Train Epoch: 6 [192/225000 (0%)] Loss: 21157.169922\n",
      "Train Epoch: 6 [2688/225000 (1%)] Loss: 20789.597656\n",
      "Train Epoch: 6 [5184/225000 (2%)] Loss: 21555.066406\n",
      "Train Epoch: 6 [7680/225000 (3%)] Loss: 21147.013672\n",
      "Train Epoch: 6 [10176/225000 (5%)] Loss: 21237.269531\n",
      "Train Epoch: 6 [12672/225000 (6%)] Loss: 21116.945312\n",
      "Train Epoch: 6 [15168/225000 (7%)] Loss: 21102.355469\n",
      "Train Epoch: 6 [17664/225000 (8%)] Loss: 21175.769531\n",
      "Train Epoch: 6 [20160/225000 (9%)] Loss: 20478.710938\n",
      "Train Epoch: 6 [22656/225000 (10%)] Loss: 20840.015625\n",
      "Train Epoch: 6 [25152/225000 (11%)] Loss: 20962.335938\n",
      "Train Epoch: 6 [27648/225000 (12%)] Loss: 21017.675781\n",
      "Train Epoch: 6 [30144/225000 (13%)] Loss: 20777.707031\n",
      "Train Epoch: 6 [32640/225000 (15%)] Loss: 20455.851562\n",
      "Train Epoch: 6 [35136/225000 (16%)] Loss: 20912.990234\n",
      "Train Epoch: 6 [37632/225000 (17%)] Loss: 21831.042969\n",
      "Train Epoch: 6 [40128/225000 (18%)] Loss: 20973.847656\n",
      "Train Epoch: 6 [42624/225000 (19%)] Loss: 21202.841797\n",
      "Train Epoch: 6 [45120/225000 (20%)] Loss: 20888.865234\n",
      "Train Epoch: 6 [47616/225000 (21%)] Loss: 21218.109375\n",
      "Train Epoch: 6 [50112/225000 (22%)] Loss: 20766.544922\n",
      "Train Epoch: 6 [52608/225000 (23%)] Loss: 21439.457031\n",
      "Train Epoch: 6 [55104/225000 (24%)] Loss: 21068.218750\n",
      "Train Epoch: 6 [57600/225000 (26%)] Loss: 21326.148438\n",
      "Train Epoch: 6 [60096/225000 (27%)] Loss: 21098.273438\n",
      "Train Epoch: 6 [62592/225000 (28%)] Loss: 20484.230469\n",
      "Train Epoch: 6 [65088/225000 (29%)] Loss: 21419.781250\n",
      "Train Epoch: 6 [67584/225000 (30%)] Loss: 20819.703125\n",
      "Train Epoch: 6 [70080/225000 (31%)] Loss: 21986.095703\n",
      "Train Epoch: 6 [72576/225000 (32%)] Loss: 20976.437500\n",
      "Train Epoch: 6 [75072/225000 (33%)] Loss: 20456.296875\n",
      "Train Epoch: 6 [77568/225000 (34%)] Loss: 21103.398438\n",
      "Train Epoch: 6 [80064/225000 (36%)] Loss: 21618.367188\n",
      "Train Epoch: 6 [82560/225000 (37%)] Loss: 20786.429688\n",
      "Train Epoch: 6 [85056/225000 (38%)] Loss: 21248.187500\n",
      "Train Epoch: 6 [87552/225000 (39%)] Loss: 20938.560547\n",
      "Train Epoch: 6 [90048/225000 (40%)] Loss: 20921.894531\n",
      "Train Epoch: 6 [92544/225000 (41%)] Loss: 21078.958984\n",
      "Train Epoch: 6 [95040/225000 (42%)] Loss: 20833.949219\n",
      "Train Epoch: 6 [97536/225000 (43%)] Loss: 20874.355469\n",
      "Train Epoch: 6 [100032/225000 (44%)] Loss: 21028.699219\n",
      "Train Epoch: 6 [102528/225000 (46%)] Loss: 21352.583984\n",
      "Train Epoch: 6 [105024/225000 (47%)] Loss: 20527.867188\n",
      "Train Epoch: 6 [107520/225000 (48%)] Loss: 20819.960938\n",
      "Train Epoch: 6 [110016/225000 (49%)] Loss: 20769.167969\n",
      "Train Epoch: 6 [112512/225000 (50%)] Loss: 20907.275391\n",
      "Train Epoch: 6 [115008/225000 (51%)] Loss: 20754.375000\n",
      "Train Epoch: 6 [117504/225000 (52%)] Loss: 20894.314453\n",
      "Train Epoch: 6 [120000/225000 (53%)] Loss: 21205.855469\n",
      "Train Epoch: 6 [122496/225000 (54%)] Loss: 20883.591797\n",
      "Train Epoch: 6 [124992/225000 (56%)] Loss: 21356.386719\n",
      "Train Epoch: 6 [127488/225000 (57%)] Loss: 20817.464844\n",
      "Train Epoch: 6 [129984/225000 (58%)] Loss: 20971.339844\n",
      "Train Epoch: 6 [132480/225000 (59%)] Loss: 20605.882812\n",
      "Train Epoch: 6 [134976/225000 (60%)] Loss: 21637.466797\n",
      "Train Epoch: 6 [137472/225000 (61%)] Loss: 20778.480469\n",
      "Train Epoch: 6 [139968/225000 (62%)] Loss: 21061.556641\n",
      "Train Epoch: 6 [142464/225000 (63%)] Loss: 21249.523438\n",
      "Train Epoch: 6 [144960/225000 (64%)] Loss: 20940.820312\n",
      "Train Epoch: 6 [147456/225000 (66%)] Loss: 20754.001953\n",
      "Train Epoch: 6 [149952/225000 (67%)] Loss: 20801.908203\n",
      "Train Epoch: 6 [152448/225000 (68%)] Loss: 20687.867188\n",
      "Train Epoch: 6 [154944/225000 (69%)] Loss: 21218.611328\n",
      "Train Epoch: 6 [157440/225000 (70%)] Loss: 21130.648438\n",
      "Train Epoch: 6 [159936/225000 (71%)] Loss: 20719.140625\n",
      "Train Epoch: 6 [162432/225000 (72%)] Loss: 20667.320312\n",
      "Train Epoch: 6 [164928/225000 (73%)] Loss: 20849.191406\n",
      "Train Epoch: 6 [167424/225000 (74%)] Loss: 21215.386719\n",
      "Train Epoch: 6 [169920/225000 (76%)] Loss: 20626.378906\n",
      "Train Epoch: 6 [172416/225000 (77%)] Loss: 21782.765625\n",
      "Train Epoch: 6 [174912/225000 (78%)] Loss: 20928.250000\n",
      "Train Epoch: 6 [177408/225000 (79%)] Loss: 21104.933594\n",
      "Train Epoch: 6 [179904/225000 (80%)] Loss: 20660.007812\n",
      "Train Epoch: 6 [182400/225000 (81%)] Loss: 20301.031250\n",
      "Train Epoch: 6 [184896/225000 (82%)] Loss: 20635.847656\n",
      "Train Epoch: 6 [187392/225000 (83%)] Loss: 20557.984375\n",
      "Train Epoch: 6 [189888/225000 (84%)] Loss: 20746.148438\n",
      "Train Epoch: 6 [192384/225000 (86%)] Loss: 20943.531250\n",
      "Train Epoch: 6 [194880/225000 (87%)] Loss: 21056.470703\n",
      "Train Epoch: 6 [197376/225000 (88%)] Loss: 21412.636719\n",
      "Train Epoch: 6 [199872/225000 (89%)] Loss: 21073.015625\n",
      "Train Epoch: 6 [202368/225000 (90%)] Loss: 20767.810547\n",
      "Train Epoch: 6 [204864/225000 (91%)] Loss: 20698.390625\n",
      "Train Epoch: 6 [207360/225000 (92%)] Loss: 21251.339844\n",
      "Train Epoch: 6 [209856/225000 (93%)] Loss: 20346.000000\n",
      "Train Epoch: 6 [212352/225000 (94%)] Loss: 20808.773438\n",
      "Train Epoch: 6 [214848/225000 (95%)] Loss: 20874.593750\n",
      "Train Epoch: 6 [217344/225000 (97%)] Loss: 20779.367188\n",
      "Train Epoch: 6 [219840/225000 (98%)] Loss: 20666.439453\n",
      "Train Epoch: 6 [222336/225000 (99%)] Loss: 21261.496094\n",
      "Train Epoch: 6 [224832/225000 (100%)] Loss: 20933.398438\n",
      "    epoch          : 6\n",
      "    loss           : 21010.087454004904\n",
      "    val_loss       : 20869.71012652193\n",
      "Train Epoch: 7 [192/225000 (0%)] Loss: 21101.720703\n",
      "Train Epoch: 7 [2688/225000 (1%)] Loss: 21177.531250\n",
      "Train Epoch: 7 [5184/225000 (2%)] Loss: 21111.824219\n",
      "Train Epoch: 7 [7680/225000 (3%)] Loss: 21196.683594\n",
      "Train Epoch: 7 [10176/225000 (5%)] Loss: 21387.617188\n",
      "Train Epoch: 7 [12672/225000 (6%)] Loss: 20545.417969\n",
      "Train Epoch: 7 [15168/225000 (7%)] Loss: 20699.429688\n",
      "Train Epoch: 7 [17664/225000 (8%)] Loss: 20976.587891\n",
      "Train Epoch: 7 [20160/225000 (9%)] Loss: 21080.892578\n",
      "Train Epoch: 7 [22656/225000 (10%)] Loss: 21374.820312\n",
      "Train Epoch: 7 [25152/225000 (11%)] Loss: 20874.605469\n",
      "Train Epoch: 7 [27648/225000 (12%)] Loss: 21275.662109\n",
      "Train Epoch: 7 [30144/225000 (13%)] Loss: 20232.791016\n",
      "Train Epoch: 7 [32640/225000 (15%)] Loss: 20674.132812\n",
      "Train Epoch: 7 [35136/225000 (16%)] Loss: 21130.455078\n",
      "Train Epoch: 7 [37632/225000 (17%)] Loss: 20781.125000\n",
      "Train Epoch: 7 [40128/225000 (18%)] Loss: 20502.595703\n",
      "Train Epoch: 7 [42624/225000 (19%)] Loss: 20948.810547\n",
      "Train Epoch: 7 [45120/225000 (20%)] Loss: 20858.085938\n",
      "Train Epoch: 7 [47616/225000 (21%)] Loss: 20746.449219\n",
      "Train Epoch: 7 [50112/225000 (22%)] Loss: 21083.675781\n",
      "Train Epoch: 7 [52608/225000 (23%)] Loss: 20874.931641\n",
      "Train Epoch: 7 [55104/225000 (24%)] Loss: 21234.644531\n",
      "Train Epoch: 7 [57600/225000 (26%)] Loss: 21636.566406\n",
      "Train Epoch: 7 [60096/225000 (27%)] Loss: 21024.560547\n",
      "Train Epoch: 7 [62592/225000 (28%)] Loss: 20658.449219\n",
      "Train Epoch: 7 [65088/225000 (29%)] Loss: 21212.617188\n",
      "Train Epoch: 7 [67584/225000 (30%)] Loss: 20763.341797\n",
      "Train Epoch: 7 [70080/225000 (31%)] Loss: 20926.173828\n",
      "Train Epoch: 7 [72576/225000 (32%)] Loss: 20459.660156\n",
      "Train Epoch: 7 [75072/225000 (33%)] Loss: 20843.283203\n",
      "Train Epoch: 7 [77568/225000 (34%)] Loss: 20629.785156\n",
      "Train Epoch: 7 [80064/225000 (36%)] Loss: 21070.949219\n",
      "Train Epoch: 7 [82560/225000 (37%)] Loss: 20733.517578\n",
      "Train Epoch: 7 [85056/225000 (38%)] Loss: 20984.625000\n",
      "Train Epoch: 7 [87552/225000 (39%)] Loss: 20824.193359\n",
      "Train Epoch: 7 [90048/225000 (40%)] Loss: 20556.550781\n",
      "Train Epoch: 7 [92544/225000 (41%)] Loss: 20737.269531\n",
      "Train Epoch: 7 [95040/225000 (42%)] Loss: 20752.640625\n",
      "Train Epoch: 7 [97536/225000 (43%)] Loss: 20911.816406\n",
      "Train Epoch: 7 [100032/225000 (44%)] Loss: 20854.214844\n",
      "Train Epoch: 7 [102528/225000 (46%)] Loss: 20838.312500\n",
      "Train Epoch: 7 [105024/225000 (47%)] Loss: 20754.246094\n",
      "Train Epoch: 7 [107520/225000 (48%)] Loss: 20977.720703\n",
      "Train Epoch: 7 [110016/225000 (49%)] Loss: 20652.007812\n",
      "Train Epoch: 7 [112512/225000 (50%)] Loss: 20805.992188\n",
      "Train Epoch: 7 [115008/225000 (51%)] Loss: 20511.900391\n",
      "Train Epoch: 7 [117504/225000 (52%)] Loss: 20545.261719\n",
      "Train Epoch: 7 [120000/225000 (53%)] Loss: 21000.738281\n",
      "Train Epoch: 7 [122496/225000 (54%)] Loss: 20831.402344\n",
      "Train Epoch: 7 [124992/225000 (56%)] Loss: 20640.460938\n",
      "Train Epoch: 7 [127488/225000 (57%)] Loss: 21379.404297\n",
      "Train Epoch: 7 [129984/225000 (58%)] Loss: 20801.824219\n",
      "Train Epoch: 7 [132480/225000 (59%)] Loss: 20408.796875\n",
      "Train Epoch: 7 [134976/225000 (60%)] Loss: 21213.285156\n",
      "Train Epoch: 7 [137472/225000 (61%)] Loss: 21052.716797\n",
      "Train Epoch: 7 [139968/225000 (62%)] Loss: 21157.867188\n",
      "Train Epoch: 7 [142464/225000 (63%)] Loss: 20313.867188\n",
      "Train Epoch: 7 [144960/225000 (64%)] Loss: 20765.558594\n",
      "Train Epoch: 7 [147456/225000 (66%)] Loss: 20967.984375\n",
      "Train Epoch: 7 [149952/225000 (67%)] Loss: 21460.421875\n",
      "Train Epoch: 7 [152448/225000 (68%)] Loss: 21432.533203\n",
      "Train Epoch: 7 [154944/225000 (69%)] Loss: 20961.734375\n",
      "Train Epoch: 7 [157440/225000 (70%)] Loss: 20417.429688\n",
      "Train Epoch: 7 [159936/225000 (71%)] Loss: 20869.126953\n",
      "Train Epoch: 7 [162432/225000 (72%)] Loss: 20728.542969\n",
      "Train Epoch: 7 [164928/225000 (73%)] Loss: 21202.320312\n",
      "Train Epoch: 7 [167424/225000 (74%)] Loss: 20902.640625\n",
      "Train Epoch: 7 [169920/225000 (76%)] Loss: 20596.484375\n",
      "Train Epoch: 7 [172416/225000 (77%)] Loss: 20512.453125\n",
      "Train Epoch: 7 [174912/225000 (78%)] Loss: 21713.125000\n",
      "Train Epoch: 7 [177408/225000 (79%)] Loss: 20512.357422\n",
      "Train Epoch: 7 [179904/225000 (80%)] Loss: 21359.378906\n",
      "Train Epoch: 7 [182400/225000 (81%)] Loss: 20950.509766\n",
      "Train Epoch: 7 [184896/225000 (82%)] Loss: 20951.847656\n",
      "Train Epoch: 7 [187392/225000 (83%)] Loss: 21104.548828\n",
      "Train Epoch: 7 [189888/225000 (84%)] Loss: 20841.332031\n",
      "Train Epoch: 7 [192384/225000 (86%)] Loss: 20527.097656\n",
      "Train Epoch: 7 [194880/225000 (87%)] Loss: 20832.392578\n",
      "Train Epoch: 7 [197376/225000 (88%)] Loss: 20638.568359\n",
      "Train Epoch: 7 [199872/225000 (89%)] Loss: 20891.023438\n",
      "Train Epoch: 7 [202368/225000 (90%)] Loss: 20936.724609\n",
      "Train Epoch: 7 [204864/225000 (91%)] Loss: 20755.328125\n",
      "Train Epoch: 7 [207360/225000 (92%)] Loss: 20842.720703\n",
      "Train Epoch: 7 [209856/225000 (93%)] Loss: 20582.962891\n",
      "Train Epoch: 7 [212352/225000 (94%)] Loss: 21107.216797\n",
      "Train Epoch: 7 [214848/225000 (95%)] Loss: 21123.246094\n",
      "Train Epoch: 7 [217344/225000 (97%)] Loss: 20502.164062\n",
      "Train Epoch: 7 [219840/225000 (98%)] Loss: 20525.785156\n",
      "Train Epoch: 7 [222336/225000 (99%)] Loss: 20934.253906\n",
      "Train Epoch: 7 [224832/225000 (100%)] Loss: 20792.203125\n",
      "    epoch          : 7\n",
      "    loss           : 20909.208757732507\n",
      "    val_loss       : 20762.819365686133\n",
      "Train Epoch: 8 [192/225000 (0%)] Loss: 21807.187500\n",
      "Train Epoch: 8 [2688/225000 (1%)] Loss: 20556.681641\n",
      "Train Epoch: 8 [5184/225000 (2%)] Loss: 20829.312500\n",
      "Train Epoch: 8 [7680/225000 (3%)] Loss: 20841.765625\n",
      "Train Epoch: 8 [10176/225000 (5%)] Loss: 20594.144531\n",
      "Train Epoch: 8 [12672/225000 (6%)] Loss: 21110.714844\n",
      "Train Epoch: 8 [15168/225000 (7%)] Loss: 21008.613281\n",
      "Train Epoch: 8 [17664/225000 (8%)] Loss: 20612.320312\n",
      "Train Epoch: 8 [20160/225000 (9%)] Loss: 20502.048828\n",
      "Train Epoch: 8 [22656/225000 (10%)] Loss: 20711.597656\n",
      "Train Epoch: 8 [25152/225000 (11%)] Loss: 20526.931641\n",
      "Train Epoch: 8 [27648/225000 (12%)] Loss: 20444.042969\n",
      "Train Epoch: 8 [30144/225000 (13%)] Loss: 20885.476562\n",
      "Train Epoch: 8 [32640/225000 (15%)] Loss: 21029.236328\n",
      "Train Epoch: 8 [35136/225000 (16%)] Loss: 20851.183594\n",
      "Train Epoch: 8 [37632/225000 (17%)] Loss: 21124.060547\n",
      "Train Epoch: 8 [40128/225000 (18%)] Loss: 21106.160156\n",
      "Train Epoch: 8 [42624/225000 (19%)] Loss: 20731.074219\n",
      "Train Epoch: 8 [45120/225000 (20%)] Loss: 20909.855469\n",
      "Train Epoch: 8 [47616/225000 (21%)] Loss: 21072.644531\n",
      "Train Epoch: 8 [50112/225000 (22%)] Loss: 20688.107422\n",
      "Train Epoch: 8 [52608/225000 (23%)] Loss: 21142.966797\n",
      "Train Epoch: 8 [55104/225000 (24%)] Loss: 20977.703125\n",
      "Train Epoch: 8 [57600/225000 (26%)] Loss: 21004.589844\n",
      "Train Epoch: 8 [60096/225000 (27%)] Loss: 21121.824219\n",
      "Train Epoch: 8 [62592/225000 (28%)] Loss: 20660.277344\n",
      "Train Epoch: 8 [65088/225000 (29%)] Loss: 20989.056641\n",
      "Train Epoch: 8 [67584/225000 (30%)] Loss: 20974.246094\n",
      "Train Epoch: 8 [70080/225000 (31%)] Loss: 21282.791016\n",
      "Train Epoch: 8 [72576/225000 (32%)] Loss: 20828.210938\n",
      "Train Epoch: 8 [75072/225000 (33%)] Loss: 20624.960938\n",
      "Train Epoch: 8 [77568/225000 (34%)] Loss: 20871.289062\n",
      "Train Epoch: 8 [80064/225000 (36%)] Loss: 20900.996094\n",
      "Train Epoch: 8 [82560/225000 (37%)] Loss: 20338.902344\n",
      "Train Epoch: 8 [85056/225000 (38%)] Loss: 21127.406250\n",
      "Train Epoch: 8 [87552/225000 (39%)] Loss: 20719.289062\n",
      "Train Epoch: 8 [90048/225000 (40%)] Loss: 21230.289062\n",
      "Train Epoch: 8 [92544/225000 (41%)] Loss: 20638.183594\n",
      "Train Epoch: 8 [95040/225000 (42%)] Loss: 20809.593750\n",
      "Train Epoch: 8 [97536/225000 (43%)] Loss: 20727.695312\n",
      "Train Epoch: 8 [100032/225000 (44%)] Loss: 20467.472656\n",
      "Train Epoch: 8 [102528/225000 (46%)] Loss: 20976.734375\n",
      "Train Epoch: 8 [105024/225000 (47%)] Loss: 20712.962891\n",
      "Train Epoch: 8 [107520/225000 (48%)] Loss: 20611.277344\n",
      "Train Epoch: 8 [110016/225000 (49%)] Loss: 20940.054688\n",
      "Train Epoch: 8 [112512/225000 (50%)] Loss: 21284.906250\n",
      "Train Epoch: 8 [115008/225000 (51%)] Loss: 20888.718750\n",
      "Train Epoch: 8 [117504/225000 (52%)] Loss: 20878.730469\n",
      "Train Epoch: 8 [120000/225000 (53%)] Loss: 20824.445312\n",
      "Train Epoch: 8 [122496/225000 (54%)] Loss: 20870.062500\n",
      "Train Epoch: 8 [124992/225000 (56%)] Loss: 21069.449219\n",
      "Train Epoch: 8 [127488/225000 (57%)] Loss: 20702.148438\n",
      "Train Epoch: 8 [129984/225000 (58%)] Loss: 20467.261719\n",
      "Train Epoch: 8 [132480/225000 (59%)] Loss: 20940.265625\n",
      "Train Epoch: 8 [134976/225000 (60%)] Loss: 20868.556641\n",
      "Train Epoch: 8 [137472/225000 (61%)] Loss: 21143.380859\n",
      "Train Epoch: 8 [139968/225000 (62%)] Loss: 20228.214844\n",
      "Train Epoch: 8 [142464/225000 (63%)] Loss: 20593.406250\n",
      "Train Epoch: 8 [144960/225000 (64%)] Loss: 20846.718750\n",
      "Train Epoch: 8 [147456/225000 (66%)] Loss: 20832.101562\n",
      "Train Epoch: 8 [149952/225000 (67%)] Loss: 20547.570312\n",
      "Train Epoch: 8 [152448/225000 (68%)] Loss: 20291.621094\n",
      "Train Epoch: 8 [154944/225000 (69%)] Loss: 20873.625000\n",
      "Train Epoch: 8 [157440/225000 (70%)] Loss: 20081.171875\n",
      "Train Epoch: 8 [159936/225000 (71%)] Loss: 20674.535156\n",
      "Train Epoch: 8 [162432/225000 (72%)] Loss: 21281.042969\n",
      "Train Epoch: 8 [164928/225000 (73%)] Loss: 20861.998047\n",
      "Train Epoch: 8 [167424/225000 (74%)] Loss: 21142.328125\n",
      "Train Epoch: 8 [169920/225000 (76%)] Loss: 20924.623047\n",
      "Train Epoch: 8 [172416/225000 (77%)] Loss: 20598.953125\n",
      "Train Epoch: 8 [174912/225000 (78%)] Loss: 20872.332031\n",
      "Train Epoch: 8 [177408/225000 (79%)] Loss: 20690.066406\n",
      "Train Epoch: 8 [179904/225000 (80%)] Loss: 20372.839844\n",
      "Train Epoch: 8 [182400/225000 (81%)] Loss: 20775.394531\n",
      "Train Epoch: 8 [184896/225000 (82%)] Loss: 20548.523438\n",
      "Train Epoch: 8 [187392/225000 (83%)] Loss: 20718.585938\n",
      "Train Epoch: 8 [189888/225000 (84%)] Loss: 21354.976562\n",
      "Train Epoch: 8 [192384/225000 (86%)] Loss: 20813.277344\n",
      "Train Epoch: 8 [194880/225000 (87%)] Loss: 20481.175781\n",
      "Train Epoch: 8 [197376/225000 (88%)] Loss: 20857.210938\n",
      "Train Epoch: 8 [199872/225000 (89%)] Loss: 20738.039062\n",
      "Train Epoch: 8 [202368/225000 (90%)] Loss: 20667.027344\n",
      "Train Epoch: 8 [204864/225000 (91%)] Loss: 20648.050781\n",
      "Train Epoch: 8 [207360/225000 (92%)] Loss: 21107.179688\n",
      "Train Epoch: 8 [209856/225000 (93%)] Loss: 20870.804688\n",
      "Train Epoch: 8 [212352/225000 (94%)] Loss: 20492.875000\n",
      "Train Epoch: 8 [214848/225000 (95%)] Loss: 20951.222656\n",
      "Train Epoch: 8 [217344/225000 (97%)] Loss: 20823.296875\n",
      "Train Epoch: 8 [219840/225000 (98%)] Loss: 20664.306641\n",
      "Train Epoch: 8 [222336/225000 (99%)] Loss: 20628.195312\n",
      "Train Epoch: 8 [224832/225000 (100%)] Loss: 21003.843750\n",
      "    epoch          : 8\n",
      "    loss           : 20841.687205031463\n",
      "    val_loss       : 20968.142700413257\n",
      "Train Epoch: 9 [192/225000 (0%)] Loss: 20705.787109\n",
      "Train Epoch: 9 [2688/225000 (1%)] Loss: 20858.679688\n",
      "Train Epoch: 9 [5184/225000 (2%)] Loss: 20955.703125\n",
      "Train Epoch: 9 [7680/225000 (3%)] Loss: 20801.091797\n",
      "Train Epoch: 9 [10176/225000 (5%)] Loss: 20682.115234\n",
      "Train Epoch: 9 [12672/225000 (6%)] Loss: 20601.451172\n",
      "Train Epoch: 9 [15168/225000 (7%)] Loss: 20627.105469\n",
      "Train Epoch: 9 [17664/225000 (8%)] Loss: 20944.806641\n",
      "Train Epoch: 9 [20160/225000 (9%)] Loss: 20860.501953\n",
      "Train Epoch: 9 [22656/225000 (10%)] Loss: 21084.996094\n",
      "Train Epoch: 9 [25152/225000 (11%)] Loss: 21178.291016\n",
      "Train Epoch: 9 [27648/225000 (12%)] Loss: 20493.812500\n",
      "Train Epoch: 9 [30144/225000 (13%)] Loss: 21244.476562\n",
      "Train Epoch: 9 [32640/225000 (15%)] Loss: 20571.898438\n",
      "Train Epoch: 9 [35136/225000 (16%)] Loss: 20653.675781\n",
      "Train Epoch: 9 [37632/225000 (17%)] Loss: 20571.236328\n",
      "Train Epoch: 9 [40128/225000 (18%)] Loss: 21094.312500\n",
      "Train Epoch: 9 [42624/225000 (19%)] Loss: 21300.167969\n",
      "Train Epoch: 9 [45120/225000 (20%)] Loss: 20954.746094\n",
      "Train Epoch: 9 [47616/225000 (21%)] Loss: 20709.076172\n",
      "Train Epoch: 9 [50112/225000 (22%)] Loss: 20831.554688\n",
      "Train Epoch: 9 [52608/225000 (23%)] Loss: 21111.089844\n",
      "Train Epoch: 9 [55104/225000 (24%)] Loss: 20923.876953\n",
      "Train Epoch: 9 [57600/225000 (26%)] Loss: 20716.738281\n",
      "Train Epoch: 9 [60096/225000 (27%)] Loss: 20904.878906\n",
      "Train Epoch: 9 [62592/225000 (28%)] Loss: 20715.460938\n",
      "Train Epoch: 9 [65088/225000 (29%)] Loss: 20585.984375\n",
      "Train Epoch: 9 [67584/225000 (30%)] Loss: 21044.312500\n",
      "Train Epoch: 9 [70080/225000 (31%)] Loss: 21090.621094\n",
      "Train Epoch: 9 [72576/225000 (32%)] Loss: 20955.968750\n",
      "Train Epoch: 9 [75072/225000 (33%)] Loss: 21256.761719\n",
      "Train Epoch: 9 [77568/225000 (34%)] Loss: 20587.398438\n",
      "Train Epoch: 9 [80064/225000 (36%)] Loss: 20658.445312\n",
      "Train Epoch: 9 [82560/225000 (37%)] Loss: 20487.832031\n",
      "Train Epoch: 9 [85056/225000 (38%)] Loss: 20554.941406\n",
      "Train Epoch: 9 [87552/225000 (39%)] Loss: 20684.421875\n",
      "Train Epoch: 9 [90048/225000 (40%)] Loss: 21033.765625\n",
      "Train Epoch: 9 [92544/225000 (41%)] Loss: 20643.304688\n",
      "Train Epoch: 9 [95040/225000 (42%)] Loss: 20646.839844\n",
      "Train Epoch: 9 [97536/225000 (43%)] Loss: 20733.597656\n",
      "Train Epoch: 9 [100032/225000 (44%)] Loss: 20803.601562\n",
      "Train Epoch: 9 [102528/225000 (46%)] Loss: 21157.363281\n",
      "Train Epoch: 9 [105024/225000 (47%)] Loss: 21090.890625\n",
      "Train Epoch: 9 [107520/225000 (48%)] Loss: 21182.605469\n",
      "Train Epoch: 9 [110016/225000 (49%)] Loss: 20955.171875\n",
      "Train Epoch: 9 [112512/225000 (50%)] Loss: 19864.656250\n",
      "Train Epoch: 9 [115008/225000 (51%)] Loss: 20767.781250\n",
      "Train Epoch: 9 [117504/225000 (52%)] Loss: 21195.582031\n",
      "Train Epoch: 9 [120000/225000 (53%)] Loss: 20959.244141\n",
      "Train Epoch: 9 [122496/225000 (54%)] Loss: 20658.398438\n",
      "Train Epoch: 9 [124992/225000 (56%)] Loss: 21031.607422\n",
      "Train Epoch: 9 [127488/225000 (57%)] Loss: 20571.917969\n",
      "Train Epoch: 9 [129984/225000 (58%)] Loss: 20763.298828\n",
      "Train Epoch: 9 [132480/225000 (59%)] Loss: 20547.306641\n",
      "Train Epoch: 9 [134976/225000 (60%)] Loss: 20878.904297\n",
      "Train Epoch: 9 [137472/225000 (61%)] Loss: 20547.521484\n",
      "Train Epoch: 9 [139968/225000 (62%)] Loss: 20468.945312\n",
      "Train Epoch: 9 [142464/225000 (63%)] Loss: 20849.445312\n",
      "Train Epoch: 9 [144960/225000 (64%)] Loss: 20545.615234\n",
      "Train Epoch: 9 [147456/225000 (66%)] Loss: 20520.199219\n",
      "Train Epoch: 9 [149952/225000 (67%)] Loss: 20778.451172\n",
      "Train Epoch: 9 [152448/225000 (68%)] Loss: 20707.613281\n",
      "Train Epoch: 9 [154944/225000 (69%)] Loss: 21073.433594\n",
      "Train Epoch: 9 [157440/225000 (70%)] Loss: 20800.382812\n",
      "Train Epoch: 9 [159936/225000 (71%)] Loss: 20951.259766\n",
      "Train Epoch: 9 [162432/225000 (72%)] Loss: 20584.269531\n",
      "Train Epoch: 9 [164928/225000 (73%)] Loss: 21203.175781\n",
      "Train Epoch: 9 [167424/225000 (74%)] Loss: 21113.253906\n",
      "Train Epoch: 9 [169920/225000 (76%)] Loss: 20629.748047\n",
      "Train Epoch: 9 [172416/225000 (77%)] Loss: 20650.916016\n",
      "Train Epoch: 9 [174912/225000 (78%)] Loss: 21003.072266\n",
      "Train Epoch: 9 [177408/225000 (79%)] Loss: 20319.910156\n",
      "Train Epoch: 9 [179904/225000 (80%)] Loss: 20741.154297\n",
      "Train Epoch: 9 [182400/225000 (81%)] Loss: 20541.558594\n",
      "Train Epoch: 9 [184896/225000 (82%)] Loss: 20858.812500\n",
      "Train Epoch: 9 [187392/225000 (83%)] Loss: 20641.410156\n",
      "Train Epoch: 9 [189888/225000 (84%)] Loss: 20752.375000\n",
      "Train Epoch: 9 [192384/225000 (86%)] Loss: 20977.400391\n",
      "Train Epoch: 9 [194880/225000 (87%)] Loss: 21039.988281\n",
      "Train Epoch: 9 [197376/225000 (88%)] Loss: 20602.703125\n",
      "Train Epoch: 9 [199872/225000 (89%)] Loss: 20682.427734\n",
      "Train Epoch: 9 [202368/225000 (90%)] Loss: 20556.152344\n",
      "Train Epoch: 9 [204864/225000 (91%)] Loss: 20580.214844\n",
      "Train Epoch: 9 [207360/225000 (92%)] Loss: 20638.359375\n",
      "Train Epoch: 9 [209856/225000 (93%)] Loss: 20480.238281\n",
      "Train Epoch: 9 [212352/225000 (94%)] Loss: 20700.664062\n",
      "Train Epoch: 9 [214848/225000 (95%)] Loss: 20358.464844\n",
      "Train Epoch: 9 [217344/225000 (97%)] Loss: 21205.923828\n",
      "Train Epoch: 9 [219840/225000 (98%)] Loss: 21363.394531\n",
      "Train Epoch: 9 [222336/225000 (99%)] Loss: 20689.751953\n",
      "Train Epoch: 9 [224832/225000 (100%)] Loss: 21093.742188\n",
      "    epoch          : 9\n",
      "    loss           : 20879.810721856335\n",
      "    val_loss       : 20792.072276242816\n",
      "Train Epoch: 10 [192/225000 (0%)] Loss: 20859.085938\n",
      "Train Epoch: 10 [2688/225000 (1%)] Loss: 20165.753906\n",
      "Train Epoch: 10 [5184/225000 (2%)] Loss: 20859.726562\n",
      "Train Epoch: 10 [7680/225000 (3%)] Loss: 21219.181641\n",
      "Train Epoch: 10 [10176/225000 (5%)] Loss: 20454.578125\n",
      "Train Epoch: 10 [12672/225000 (6%)] Loss: 20549.154297\n",
      "Train Epoch: 10 [15168/225000 (7%)] Loss: 20969.878906\n",
      "Train Epoch: 10 [17664/225000 (8%)] Loss: 20899.101562\n",
      "Train Epoch: 10 [20160/225000 (9%)] Loss: 20359.660156\n",
      "Train Epoch: 10 [22656/225000 (10%)] Loss: 20935.800781\n",
      "Train Epoch: 10 [25152/225000 (11%)] Loss: 20445.458984\n",
      "Train Epoch: 10 [27648/225000 (12%)] Loss: 20172.273438\n",
      "Train Epoch: 10 [30144/225000 (13%)] Loss: 36748.695312\n",
      "Train Epoch: 10 [32640/225000 (15%)] Loss: 20354.925781\n",
      "Train Epoch: 10 [35136/225000 (16%)] Loss: 20959.292969\n",
      "Train Epoch: 10 [37632/225000 (17%)] Loss: 20741.554688\n",
      "Train Epoch: 10 [40128/225000 (18%)] Loss: 20723.431641\n",
      "Train Epoch: 10 [42624/225000 (19%)] Loss: 20905.382812\n",
      "Train Epoch: 10 [45120/225000 (20%)] Loss: 20198.972656\n",
      "Train Epoch: 10 [47616/225000 (21%)] Loss: 20585.419922\n",
      "Train Epoch: 10 [50112/225000 (22%)] Loss: 20569.945312\n",
      "Train Epoch: 10 [52608/225000 (23%)] Loss: 19935.148438\n",
      "Train Epoch: 10 [55104/225000 (24%)] Loss: 20536.636719\n",
      "Train Epoch: 10 [57600/225000 (26%)] Loss: 21204.167969\n",
      "Train Epoch: 10 [60096/225000 (27%)] Loss: 20950.554688\n",
      "Train Epoch: 10 [62592/225000 (28%)] Loss: 21156.945312\n",
      "Train Epoch: 10 [65088/225000 (29%)] Loss: 20733.869141\n",
      "Train Epoch: 10 [67584/225000 (30%)] Loss: 21177.238281\n",
      "Train Epoch: 10 [70080/225000 (31%)] Loss: 20742.998047\n",
      "Train Epoch: 10 [72576/225000 (32%)] Loss: 20615.468750\n",
      "Train Epoch: 10 [75072/225000 (33%)] Loss: 20637.074219\n",
      "Train Epoch: 10 [77568/225000 (34%)] Loss: 20941.570312\n",
      "Train Epoch: 10 [80064/225000 (36%)] Loss: 20988.644531\n",
      "Train Epoch: 10 [82560/225000 (37%)] Loss: 20942.652344\n",
      "Train Epoch: 10 [85056/225000 (38%)] Loss: 20990.605469\n",
      "Train Epoch: 10 [87552/225000 (39%)] Loss: 20431.941406\n",
      "Train Epoch: 10 [90048/225000 (40%)] Loss: 20704.861328\n",
      "Train Epoch: 10 [92544/225000 (41%)] Loss: 20847.808594\n",
      "Train Epoch: 10 [95040/225000 (42%)] Loss: 20922.175781\n",
      "Train Epoch: 10 [97536/225000 (43%)] Loss: 21158.076172\n",
      "Train Epoch: 10 [100032/225000 (44%)] Loss: 20765.595703\n",
      "Train Epoch: 10 [102528/225000 (46%)] Loss: 20821.087891\n",
      "Train Epoch: 10 [105024/225000 (47%)] Loss: 20603.410156\n",
      "Train Epoch: 10 [107520/225000 (48%)] Loss: 20475.691406\n",
      "Train Epoch: 10 [110016/225000 (49%)] Loss: 21046.224609\n",
      "Train Epoch: 10 [112512/225000 (50%)] Loss: 21217.763672\n",
      "Train Epoch: 10 [115008/225000 (51%)] Loss: 20678.996094\n",
      "Train Epoch: 10 [117504/225000 (52%)] Loss: 20431.718750\n",
      "Train Epoch: 10 [120000/225000 (53%)] Loss: 20415.023438\n",
      "Train Epoch: 10 [122496/225000 (54%)] Loss: 20887.433594\n",
      "Train Epoch: 10 [124992/225000 (56%)] Loss: 20709.199219\n",
      "Train Epoch: 10 [127488/225000 (57%)] Loss: 20627.400391\n",
      "Train Epoch: 10 [129984/225000 (58%)] Loss: 21227.837891\n",
      "Train Epoch: 10 [132480/225000 (59%)] Loss: 20240.937500\n",
      "Train Epoch: 10 [134976/225000 (60%)] Loss: 20834.867188\n",
      "Train Epoch: 10 [137472/225000 (61%)] Loss: 21424.669922\n",
      "Train Epoch: 10 [139968/225000 (62%)] Loss: 21208.144531\n",
      "Train Epoch: 10 [142464/225000 (63%)] Loss: 20652.794922\n",
      "Train Epoch: 10 [144960/225000 (64%)] Loss: 20840.673828\n",
      "Train Epoch: 10 [147456/225000 (66%)] Loss: 20820.335938\n",
      "Train Epoch: 10 [149952/225000 (67%)] Loss: 20758.335938\n",
      "Train Epoch: 10 [152448/225000 (68%)] Loss: 20832.800781\n",
      "Train Epoch: 10 [154944/225000 (69%)] Loss: 20491.257812\n",
      "Train Epoch: 10 [157440/225000 (70%)] Loss: 20599.164062\n",
      "Train Epoch: 10 [159936/225000 (71%)] Loss: 21068.160156\n",
      "Train Epoch: 10 [162432/225000 (72%)] Loss: 20733.789062\n",
      "Train Epoch: 10 [164928/225000 (73%)] Loss: 20652.656250\n",
      "Train Epoch: 10 [167424/225000 (74%)] Loss: 20541.957031\n",
      "Train Epoch: 10 [169920/225000 (76%)] Loss: 21251.216797\n",
      "Train Epoch: 10 [172416/225000 (77%)] Loss: 20831.341797\n",
      "Train Epoch: 10 [174912/225000 (78%)] Loss: 20323.134766\n",
      "Train Epoch: 10 [177408/225000 (79%)] Loss: 20862.281250\n",
      "Train Epoch: 10 [179904/225000 (80%)] Loss: 20508.910156\n",
      "Train Epoch: 10 [182400/225000 (81%)] Loss: 20860.628906\n",
      "Train Epoch: 10 [184896/225000 (82%)] Loss: 20982.066406\n",
      "Train Epoch: 10 [187392/225000 (83%)] Loss: 20535.056641\n",
      "Train Epoch: 10 [189888/225000 (84%)] Loss: 20972.775391\n",
      "Train Epoch: 10 [192384/225000 (86%)] Loss: 20686.541016\n",
      "Train Epoch: 10 [194880/225000 (87%)] Loss: 20822.636719\n",
      "Train Epoch: 10 [197376/225000 (88%)] Loss: 20814.125000\n",
      "Train Epoch: 10 [199872/225000 (89%)] Loss: 21027.556641\n",
      "Train Epoch: 10 [202368/225000 (90%)] Loss: 20756.753906\n",
      "Train Epoch: 10 [204864/225000 (91%)] Loss: 20570.613281\n",
      "Train Epoch: 10 [207360/225000 (92%)] Loss: 20836.382812\n",
      "Train Epoch: 10 [209856/225000 (93%)] Loss: 20407.632812\n",
      "Train Epoch: 10 [212352/225000 (94%)] Loss: 20541.677734\n",
      "Train Epoch: 10 [214848/225000 (95%)] Loss: 20454.402344\n",
      "Train Epoch: 10 [217344/225000 (97%)] Loss: 20839.855469\n",
      "Train Epoch: 10 [219840/225000 (98%)] Loss: 20889.318359\n",
      "Train Epoch: 10 [222336/225000 (99%)] Loss: 20775.736328\n",
      "Train Epoch: 10 [224832/225000 (100%)] Loss: 20623.968750\n",
      "    epoch          : 10\n",
      "    loss           : 20806.254887811967\n",
      "    val_loss       : 20645.834268437087\n",
      "Train Epoch: 11 [192/225000 (0%)] Loss: 20343.429688\n",
      "Train Epoch: 11 [2688/225000 (1%)] Loss: 20888.046875\n",
      "Train Epoch: 11 [5184/225000 (2%)] Loss: 20541.841797\n",
      "Train Epoch: 11 [7680/225000 (3%)] Loss: 20699.410156\n",
      "Train Epoch: 11 [10176/225000 (5%)] Loss: 20760.261719\n",
      "Train Epoch: 11 [12672/225000 (6%)] Loss: 20971.394531\n",
      "Train Epoch: 11 [15168/225000 (7%)] Loss: 20941.687500\n",
      "Train Epoch: 11 [17664/225000 (8%)] Loss: 20304.353516\n",
      "Train Epoch: 11 [20160/225000 (9%)] Loss: 20778.521484\n",
      "Train Epoch: 11 [22656/225000 (10%)] Loss: 21133.468750\n",
      "Train Epoch: 11 [25152/225000 (11%)] Loss: 20738.164062\n",
      "Train Epoch: 11 [27648/225000 (12%)] Loss: 20827.625000\n",
      "Train Epoch: 11 [30144/225000 (13%)] Loss: 20843.888672\n",
      "Train Epoch: 11 [32640/225000 (15%)] Loss: 20847.583984\n",
      "Train Epoch: 11 [35136/225000 (16%)] Loss: 20620.355469\n",
      "Train Epoch: 11 [37632/225000 (17%)] Loss: 20727.914062\n",
      "Train Epoch: 11 [40128/225000 (18%)] Loss: 20658.640625\n",
      "Train Epoch: 11 [42624/225000 (19%)] Loss: 20914.906250\n",
      "Train Epoch: 11 [45120/225000 (20%)] Loss: 20576.707031\n",
      "Train Epoch: 11 [47616/225000 (21%)] Loss: 21051.039062\n",
      "Train Epoch: 11 [50112/225000 (22%)] Loss: 20755.550781\n",
      "Train Epoch: 11 [52608/225000 (23%)] Loss: 20431.546875\n",
      "Train Epoch: 11 [55104/225000 (24%)] Loss: 21000.132812\n",
      "Train Epoch: 11 [57600/225000 (26%)] Loss: 20915.083984\n",
      "Train Epoch: 11 [60096/225000 (27%)] Loss: 20531.484375\n",
      "Train Epoch: 11 [62592/225000 (28%)] Loss: 20877.095703\n",
      "Train Epoch: 11 [65088/225000 (29%)] Loss: 20817.263672\n",
      "Train Epoch: 11 [67584/225000 (30%)] Loss: 20563.910156\n",
      "Train Epoch: 11 [70080/225000 (31%)] Loss: 20945.699219\n",
      "Train Epoch: 11 [72576/225000 (32%)] Loss: 20723.433594\n",
      "Train Epoch: 11 [75072/225000 (33%)] Loss: 20482.794922\n",
      "Train Epoch: 11 [77568/225000 (34%)] Loss: 20311.609375\n",
      "Train Epoch: 11 [80064/225000 (36%)] Loss: 20517.406250\n",
      "Train Epoch: 11 [82560/225000 (37%)] Loss: 20390.611328\n",
      "Train Epoch: 11 [85056/225000 (38%)] Loss: 20683.234375\n",
      "Train Epoch: 11 [87552/225000 (39%)] Loss: 20765.773438\n",
      "Train Epoch: 11 [90048/225000 (40%)] Loss: 20969.640625\n",
      "Train Epoch: 11 [92544/225000 (41%)] Loss: 21237.214844\n",
      "Train Epoch: 11 [95040/225000 (42%)] Loss: 20708.500000\n",
      "Train Epoch: 11 [97536/225000 (43%)] Loss: 20660.271484\n",
      "Train Epoch: 11 [100032/225000 (44%)] Loss: 21167.564453\n",
      "Train Epoch: 11 [102528/225000 (46%)] Loss: 20662.234375\n",
      "Train Epoch: 11 [105024/225000 (47%)] Loss: 20581.691406\n",
      "Train Epoch: 11 [107520/225000 (48%)] Loss: 20984.097656\n",
      "Train Epoch: 11 [110016/225000 (49%)] Loss: 20710.488281\n",
      "Train Epoch: 11 [112512/225000 (50%)] Loss: 20749.847656\n",
      "Train Epoch: 11 [115008/225000 (51%)] Loss: 20614.207031\n",
      "Train Epoch: 11 [117504/225000 (52%)] Loss: 20700.677734\n",
      "Train Epoch: 11 [120000/225000 (53%)] Loss: 20727.570312\n",
      "Train Epoch: 11 [122496/225000 (54%)] Loss: 20759.570312\n",
      "Train Epoch: 11 [124992/225000 (56%)] Loss: 20651.574219\n",
      "Train Epoch: 11 [127488/225000 (57%)] Loss: 20687.003906\n",
      "Train Epoch: 11 [129984/225000 (58%)] Loss: 20867.769531\n",
      "Train Epoch: 11 [132480/225000 (59%)] Loss: 20922.724609\n",
      "Train Epoch: 11 [134976/225000 (60%)] Loss: 21428.675781\n",
      "Train Epoch: 11 [137472/225000 (61%)] Loss: 20742.474609\n",
      "Train Epoch: 11 [139968/225000 (62%)] Loss: 20975.757812\n",
      "Train Epoch: 11 [142464/225000 (63%)] Loss: 20637.138672\n",
      "Train Epoch: 11 [144960/225000 (64%)] Loss: 20878.746094\n",
      "Train Epoch: 11 [147456/225000 (66%)] Loss: 20816.878906\n",
      "Train Epoch: 11 [149952/225000 (67%)] Loss: 20879.496094\n",
      "Train Epoch: 11 [152448/225000 (68%)] Loss: 20078.210938\n",
      "Train Epoch: 11 [154944/225000 (69%)] Loss: 20917.181641\n",
      "Train Epoch: 11 [157440/225000 (70%)] Loss: 19808.527344\n",
      "Train Epoch: 11 [159936/225000 (71%)] Loss: 20474.593750\n",
      "Train Epoch: 11 [162432/225000 (72%)] Loss: 20838.949219\n",
      "Train Epoch: 11 [164928/225000 (73%)] Loss: 20360.423828\n",
      "Train Epoch: 11 [167424/225000 (74%)] Loss: 20836.378906\n",
      "Train Epoch: 11 [169920/225000 (76%)] Loss: 21445.558594\n",
      "Train Epoch: 11 [172416/225000 (77%)] Loss: 20458.179688\n",
      "Train Epoch: 11 [174912/225000 (78%)] Loss: 20828.458984\n",
      "Train Epoch: 11 [177408/225000 (79%)] Loss: 20692.806641\n",
      "Train Epoch: 11 [179904/225000 (80%)] Loss: 21327.199219\n",
      "Train Epoch: 11 [182400/225000 (81%)] Loss: 21160.910156\n",
      "Train Epoch: 11 [184896/225000 (82%)] Loss: 20597.820312\n",
      "Train Epoch: 11 [187392/225000 (83%)] Loss: 20824.296875\n",
      "Train Epoch: 11 [189888/225000 (84%)] Loss: 20211.296875\n",
      "Train Epoch: 11 [192384/225000 (86%)] Loss: 20201.742188\n",
      "Train Epoch: 11 [194880/225000 (87%)] Loss: 20649.669922\n",
      "Train Epoch: 11 [197376/225000 (88%)] Loss: 20840.343750\n",
      "Train Epoch: 11 [199872/225000 (89%)] Loss: 21007.296875\n",
      "Train Epoch: 11 [202368/225000 (90%)] Loss: 20811.615234\n",
      "Train Epoch: 11 [204864/225000 (91%)] Loss: 21227.683594\n",
      "Train Epoch: 11 [207360/225000 (92%)] Loss: 21114.664062\n",
      "Train Epoch: 11 [209856/225000 (93%)] Loss: 20467.820312\n",
      "Train Epoch: 11 [212352/225000 (94%)] Loss: 20617.992188\n",
      "Train Epoch: 11 [214848/225000 (95%)] Loss: 20875.324219\n",
      "Train Epoch: 11 [217344/225000 (97%)] Loss: 20736.527344\n",
      "Train Epoch: 11 [219840/225000 (98%)] Loss: 21044.175781\n",
      "Train Epoch: 11 [222336/225000 (99%)] Loss: 20746.351562\n",
      "Train Epoch: 11 [224832/225000 (100%)] Loss: 20871.476562\n",
      "    epoch          : 11\n",
      "    loss           : 20724.35826011892\n",
      "    val_loss       : 20600.261942988134\n",
      "Train Epoch: 12 [192/225000 (0%)] Loss: 20146.390625\n",
      "Train Epoch: 12 [2688/225000 (1%)] Loss: 20507.789062\n",
      "Train Epoch: 12 [5184/225000 (2%)] Loss: 20248.875000\n",
      "Train Epoch: 12 [7680/225000 (3%)] Loss: 21128.457031\n",
      "Train Epoch: 12 [10176/225000 (5%)] Loss: 20342.603516\n",
      "Train Epoch: 12 [12672/225000 (6%)] Loss: 20784.828125\n",
      "Train Epoch: 12 [15168/225000 (7%)] Loss: 20713.894531\n",
      "Train Epoch: 12 [17664/225000 (8%)] Loss: 20466.996094\n",
      "Train Epoch: 12 [20160/225000 (9%)] Loss: 20893.195312\n",
      "Train Epoch: 12 [22656/225000 (10%)] Loss: 21367.433594\n",
      "Train Epoch: 12 [25152/225000 (11%)] Loss: 21304.203125\n",
      "Train Epoch: 12 [27648/225000 (12%)] Loss: 21269.406250\n",
      "Train Epoch: 12 [30144/225000 (13%)] Loss: 20612.265625\n",
      "Train Epoch: 12 [32640/225000 (15%)] Loss: 20749.410156\n",
      "Train Epoch: 12 [35136/225000 (16%)] Loss: 20724.589844\n",
      "Train Epoch: 12 [37632/225000 (17%)] Loss: 20733.871094\n",
      "Train Epoch: 12 [40128/225000 (18%)] Loss: 20831.242188\n",
      "Train Epoch: 12 [42624/225000 (19%)] Loss: 20598.273438\n",
      "Train Epoch: 12 [45120/225000 (20%)] Loss: 20778.816406\n",
      "Train Epoch: 12 [47616/225000 (21%)] Loss: 20313.730469\n",
      "Train Epoch: 12 [50112/225000 (22%)] Loss: 20815.609375\n",
      "Train Epoch: 12 [52608/225000 (23%)] Loss: 20860.531250\n",
      "Train Epoch: 12 [55104/225000 (24%)] Loss: 20512.568359\n",
      "Train Epoch: 12 [57600/225000 (26%)] Loss: 20919.789062\n",
      "Train Epoch: 12 [60096/225000 (27%)] Loss: 20541.712891\n",
      "Train Epoch: 12 [62592/225000 (28%)] Loss: 20981.566406\n",
      "Train Epoch: 12 [65088/225000 (29%)] Loss: 21040.925781\n",
      "Train Epoch: 12 [67584/225000 (30%)] Loss: 20432.011719\n",
      "Train Epoch: 12 [70080/225000 (31%)] Loss: 20527.156250\n",
      "Train Epoch: 12 [72576/225000 (32%)] Loss: 20438.011719\n",
      "Train Epoch: 12 [75072/225000 (33%)] Loss: 21066.078125\n",
      "Train Epoch: 12 [77568/225000 (34%)] Loss: 20941.671875\n",
      "Train Epoch: 12 [80064/225000 (36%)] Loss: 20835.039062\n",
      "Train Epoch: 12 [82560/225000 (37%)] Loss: 20648.347656\n",
      "Train Epoch: 12 [85056/225000 (38%)] Loss: 20455.250000\n",
      "Train Epoch: 12 [87552/225000 (39%)] Loss: 20318.664062\n",
      "Train Epoch: 12 [90048/225000 (40%)] Loss: 20827.480469\n",
      "Train Epoch: 12 [92544/225000 (41%)] Loss: 20774.240234\n",
      "Train Epoch: 12 [95040/225000 (42%)] Loss: 21146.355469\n",
      "Train Epoch: 12 [97536/225000 (43%)] Loss: 20132.828125\n",
      "Train Epoch: 12 [100032/225000 (44%)] Loss: 20604.675781\n",
      "Train Epoch: 12 [102528/225000 (46%)] Loss: 20347.695312\n",
      "Train Epoch: 12 [105024/225000 (47%)] Loss: 21167.003906\n",
      "Train Epoch: 12 [107520/225000 (48%)] Loss: 20101.992188\n",
      "Train Epoch: 12 [110016/225000 (49%)] Loss: 20456.328125\n",
      "Train Epoch: 12 [112512/225000 (50%)] Loss: 20697.308594\n",
      "Train Epoch: 12 [115008/225000 (51%)] Loss: 20731.585938\n",
      "Train Epoch: 12 [117504/225000 (52%)] Loss: 20841.976562\n",
      "Train Epoch: 12 [120000/225000 (53%)] Loss: 20758.416016\n",
      "Train Epoch: 12 [122496/225000 (54%)] Loss: 20905.976562\n",
      "Train Epoch: 12 [124992/225000 (56%)] Loss: 20664.548828\n",
      "Train Epoch: 12 [127488/225000 (57%)] Loss: 20352.095703\n",
      "Train Epoch: 12 [129984/225000 (58%)] Loss: 20862.070312\n",
      "Train Epoch: 12 [132480/225000 (59%)] Loss: 20607.921875\n",
      "Train Epoch: 12 [134976/225000 (60%)] Loss: 20490.292969\n",
      "Train Epoch: 12 [137472/225000 (61%)] Loss: 21169.343750\n",
      "Train Epoch: 12 [139968/225000 (62%)] Loss: 20499.269531\n",
      "Train Epoch: 12 [142464/225000 (63%)] Loss: 20921.470703\n",
      "Train Epoch: 12 [144960/225000 (64%)] Loss: 20960.003906\n",
      "Train Epoch: 12 [147456/225000 (66%)] Loss: 21290.746094\n",
      "Train Epoch: 12 [149952/225000 (67%)] Loss: 20751.621094\n",
      "Train Epoch: 12 [152448/225000 (68%)] Loss: 20482.201172\n",
      "Train Epoch: 12 [154944/225000 (69%)] Loss: 20815.441406\n",
      "Train Epoch: 12 [157440/225000 (70%)] Loss: 21152.835938\n",
      "Train Epoch: 12 [159936/225000 (71%)] Loss: 20887.001953\n",
      "Train Epoch: 12 [162432/225000 (72%)] Loss: 20886.226562\n",
      "Train Epoch: 12 [164928/225000 (73%)] Loss: 36524.367188\n",
      "Train Epoch: 12 [167424/225000 (74%)] Loss: 20853.470703\n",
      "Train Epoch: 12 [169920/225000 (76%)] Loss: 20532.781250\n",
      "Train Epoch: 12 [172416/225000 (77%)] Loss: 20874.164062\n",
      "Train Epoch: 12 [174912/225000 (78%)] Loss: 20536.906250\n",
      "Train Epoch: 12 [177408/225000 (79%)] Loss: 20394.386719\n",
      "Train Epoch: 12 [179904/225000 (80%)] Loss: 20629.949219\n",
      "Train Epoch: 12 [182400/225000 (81%)] Loss: 20532.826172\n",
      "Train Epoch: 12 [184896/225000 (82%)] Loss: 20730.632812\n",
      "Train Epoch: 12 [187392/225000 (83%)] Loss: 20893.949219\n",
      "Train Epoch: 12 [189888/225000 (84%)] Loss: 20683.187500\n",
      "Train Epoch: 12 [192384/225000 (86%)] Loss: 20630.789062\n",
      "Train Epoch: 12 [194880/225000 (87%)] Loss: 20520.480469\n",
      "Train Epoch: 12 [197376/225000 (88%)] Loss: 20893.914062\n",
      "Train Epoch: 12 [199872/225000 (89%)] Loss: 20592.808594\n",
      "Train Epoch: 12 [202368/225000 (90%)] Loss: 20868.789062\n",
      "Train Epoch: 12 [204864/225000 (91%)] Loss: 21163.585938\n",
      "Train Epoch: 12 [207360/225000 (92%)] Loss: 20376.050781\n",
      "Train Epoch: 12 [209856/225000 (93%)] Loss: 20681.755859\n",
      "Train Epoch: 12 [212352/225000 (94%)] Loss: 20315.078125\n",
      "Train Epoch: 12 [214848/225000 (95%)] Loss: 20245.128906\n",
      "Train Epoch: 12 [217344/225000 (97%)] Loss: 20330.179688\n",
      "Train Epoch: 12 [219840/225000 (98%)] Loss: 20350.060547\n",
      "Train Epoch: 12 [222336/225000 (99%)] Loss: 20537.710938\n",
      "Train Epoch: 12 [224832/225000 (100%)] Loss: 20607.722656\n",
      "    epoch          : 12\n",
      "    loss           : 20677.722234628305\n",
      "    val_loss       : 20552.658972171426\n",
      "Train Epoch: 13 [192/225000 (0%)] Loss: 20968.445312\n",
      "Train Epoch: 13 [2688/225000 (1%)] Loss: 20630.644531\n",
      "Train Epoch: 13 [5184/225000 (2%)] Loss: 20778.271484\n",
      "Train Epoch: 13 [7680/225000 (3%)] Loss: 21065.378906\n",
      "Train Epoch: 13 [10176/225000 (5%)] Loss: 20602.210938\n",
      "Train Epoch: 13 [12672/225000 (6%)] Loss: 20906.261719\n",
      "Train Epoch: 13 [15168/225000 (7%)] Loss: 20983.654297\n",
      "Train Epoch: 13 [17664/225000 (8%)] Loss: 21113.058594\n",
      "Train Epoch: 13 [20160/225000 (9%)] Loss: 20442.214844\n",
      "Train Epoch: 13 [22656/225000 (10%)] Loss: 20870.009766\n",
      "Train Epoch: 13 [25152/225000 (11%)] Loss: 20195.628906\n",
      "Train Epoch: 13 [27648/225000 (12%)] Loss: 20361.681641\n",
      "Train Epoch: 13 [30144/225000 (13%)] Loss: 20771.585938\n",
      "Train Epoch: 13 [32640/225000 (15%)] Loss: 21173.460938\n",
      "Train Epoch: 13 [35136/225000 (16%)] Loss: 20269.712891\n",
      "Train Epoch: 13 [37632/225000 (17%)] Loss: 20922.806641\n",
      "Train Epoch: 13 [40128/225000 (18%)] Loss: 20183.292969\n",
      "Train Epoch: 13 [42624/225000 (19%)] Loss: 20490.203125\n",
      "Train Epoch: 13 [45120/225000 (20%)] Loss: 20913.496094\n",
      "Train Epoch: 13 [47616/225000 (21%)] Loss: 20536.402344\n",
      "Train Epoch: 13 [50112/225000 (22%)] Loss: 20482.150391\n",
      "Train Epoch: 13 [52608/225000 (23%)] Loss: 20680.152344\n",
      "Train Epoch: 13 [55104/225000 (24%)] Loss: 20793.164062\n",
      "Train Epoch: 13 [57600/225000 (26%)] Loss: 20434.945312\n",
      "Train Epoch: 13 [60096/225000 (27%)] Loss: 20438.207031\n",
      "Train Epoch: 13 [62592/225000 (28%)] Loss: 20496.742188\n",
      "Train Epoch: 13 [65088/225000 (29%)] Loss: 20655.574219\n",
      "Train Epoch: 13 [67584/225000 (30%)] Loss: 20867.277344\n",
      "Train Epoch: 13 [70080/225000 (31%)] Loss: 20392.335938\n",
      "Train Epoch: 13 [72576/225000 (32%)] Loss: 21000.216797\n",
      "Train Epoch: 13 [75072/225000 (33%)] Loss: 20316.496094\n",
      "Train Epoch: 13 [77568/225000 (34%)] Loss: 20623.851562\n",
      "Train Epoch: 13 [80064/225000 (36%)] Loss: 20815.072266\n",
      "Train Epoch: 13 [82560/225000 (37%)] Loss: 20386.812500\n",
      "Train Epoch: 13 [85056/225000 (38%)] Loss: 21063.894531\n",
      "Train Epoch: 13 [87552/225000 (39%)] Loss: 21150.082031\n",
      "Train Epoch: 13 [90048/225000 (40%)] Loss: 20633.863281\n",
      "Train Epoch: 13 [92544/225000 (41%)] Loss: 20685.398438\n",
      "Train Epoch: 13 [95040/225000 (42%)] Loss: 20193.072266\n",
      "Train Epoch: 13 [97536/225000 (43%)] Loss: 20799.152344\n",
      "Train Epoch: 13 [100032/225000 (44%)] Loss: 20615.804688\n",
      "Train Epoch: 13 [102528/225000 (46%)] Loss: 21125.058594\n",
      "Train Epoch: 13 [105024/225000 (47%)] Loss: 20369.205078\n",
      "Train Epoch: 13 [107520/225000 (48%)] Loss: 21000.132812\n",
      "Train Epoch: 13 [110016/225000 (49%)] Loss: 20423.560547\n",
      "Train Epoch: 13 [112512/225000 (50%)] Loss: 20534.183594\n",
      "Train Epoch: 13 [115008/225000 (51%)] Loss: 20413.535156\n",
      "Train Epoch: 13 [117504/225000 (52%)] Loss: 20201.125000\n",
      "Train Epoch: 13 [120000/225000 (53%)] Loss: 20553.089844\n",
      "Train Epoch: 13 [122496/225000 (54%)] Loss: 20743.529297\n",
      "Train Epoch: 13 [124992/225000 (56%)] Loss: 21156.277344\n",
      "Train Epoch: 13 [127488/225000 (57%)] Loss: 20544.464844\n",
      "Train Epoch: 13 [129984/225000 (58%)] Loss: 20345.873047\n",
      "Train Epoch: 13 [132480/225000 (59%)] Loss: 20332.457031\n",
      "Train Epoch: 13 [134976/225000 (60%)] Loss: 20538.273438\n",
      "Train Epoch: 13 [137472/225000 (61%)] Loss: 20613.312500\n",
      "Train Epoch: 13 [139968/225000 (62%)] Loss: 21120.964844\n",
      "Train Epoch: 13 [142464/225000 (63%)] Loss: 20713.779297\n",
      "Train Epoch: 13 [144960/225000 (64%)] Loss: 20533.390625\n",
      "Train Epoch: 13 [147456/225000 (66%)] Loss: 20734.964844\n",
      "Train Epoch: 13 [149952/225000 (67%)] Loss: 20462.501953\n",
      "Train Epoch: 13 [152448/225000 (68%)] Loss: 20552.675781\n",
      "Train Epoch: 13 [154944/225000 (69%)] Loss: 20350.238281\n",
      "Train Epoch: 13 [157440/225000 (70%)] Loss: 20482.960938\n",
      "Train Epoch: 13 [159936/225000 (71%)] Loss: 21255.742188\n",
      "Train Epoch: 13 [162432/225000 (72%)] Loss: 20470.828125\n",
      "Train Epoch: 13 [164928/225000 (73%)] Loss: 20925.621094\n",
      "Train Epoch: 13 [167424/225000 (74%)] Loss: 20618.785156\n",
      "Train Epoch: 13 [169920/225000 (76%)] Loss: 20640.925781\n",
      "Train Epoch: 13 [172416/225000 (77%)] Loss: 20165.976562\n",
      "Train Epoch: 13 [174912/225000 (78%)] Loss: 20433.425781\n",
      "Train Epoch: 13 [177408/225000 (79%)] Loss: 20445.429688\n",
      "Train Epoch: 13 [179904/225000 (80%)] Loss: 20720.484375\n",
      "Train Epoch: 13 [182400/225000 (81%)] Loss: 20526.449219\n",
      "Train Epoch: 13 [184896/225000 (82%)] Loss: 20947.695312\n",
      "Train Epoch: 13 [187392/225000 (83%)] Loss: 20337.445312\n",
      "Train Epoch: 13 [189888/225000 (84%)] Loss: 20485.560547\n",
      "Train Epoch: 13 [192384/225000 (86%)] Loss: 20719.607422\n",
      "Train Epoch: 13 [194880/225000 (87%)] Loss: 20805.023438\n",
      "Train Epoch: 13 [197376/225000 (88%)] Loss: 20608.306641\n",
      "Train Epoch: 13 [199872/225000 (89%)] Loss: 20831.736328\n",
      "Train Epoch: 13 [202368/225000 (90%)] Loss: 20186.498047\n",
      "Train Epoch: 13 [204864/225000 (91%)] Loss: 20607.339844\n",
      "Train Epoch: 13 [207360/225000 (92%)] Loss: 21253.767578\n",
      "Train Epoch: 13 [209856/225000 (93%)] Loss: 20670.416016\n",
      "Train Epoch: 13 [212352/225000 (94%)] Loss: 20430.664062\n",
      "Train Epoch: 13 [214848/225000 (95%)] Loss: 20430.593750\n",
      "Train Epoch: 13 [217344/225000 (97%)] Loss: 20789.789062\n",
      "Train Epoch: 13 [219840/225000 (98%)] Loss: 21016.160156\n",
      "Train Epoch: 13 [222336/225000 (99%)] Loss: 21013.521484\n",
      "Train Epoch: 13 [224832/225000 (100%)] Loss: 20696.851562\n",
      "    epoch          : 13\n",
      "    loss           : 20646.23622146971\n",
      "    val_loss       : 20577.352355438336\n",
      "Train Epoch: 14 [192/225000 (0%)] Loss: 20771.777344\n",
      "Train Epoch: 14 [2688/225000 (1%)] Loss: 20424.585938\n",
      "Train Epoch: 14 [5184/225000 (2%)] Loss: 20497.191406\n",
      "Train Epoch: 14 [7680/225000 (3%)] Loss: 20440.037109\n",
      "Train Epoch: 14 [10176/225000 (5%)] Loss: 20269.207031\n",
      "Train Epoch: 14 [12672/225000 (6%)] Loss: 20744.255859\n",
      "Train Epoch: 14 [15168/225000 (7%)] Loss: 20751.939453\n",
      "Train Epoch: 14 [17664/225000 (8%)] Loss: 20664.087891\n",
      "Train Epoch: 14 [20160/225000 (9%)] Loss: 20102.816406\n",
      "Train Epoch: 14 [22656/225000 (10%)] Loss: 20746.835938\n",
      "Train Epoch: 14 [25152/225000 (11%)] Loss: 20435.378906\n",
      "Train Epoch: 14 [27648/225000 (12%)] Loss: 20803.515625\n",
      "Train Epoch: 14 [30144/225000 (13%)] Loss: 20643.917969\n",
      "Train Epoch: 14 [32640/225000 (15%)] Loss: 20700.664062\n",
      "Train Epoch: 14 [35136/225000 (16%)] Loss: 20565.107422\n",
      "Train Epoch: 14 [37632/225000 (17%)] Loss: 20383.117188\n",
      "Train Epoch: 14 [40128/225000 (18%)] Loss: 20430.183594\n",
      "Train Epoch: 14 [42624/225000 (19%)] Loss: 20577.062500\n",
      "Train Epoch: 14 [45120/225000 (20%)] Loss: 20592.009766\n",
      "Train Epoch: 14 [47616/225000 (21%)] Loss: 20505.460938\n",
      "Train Epoch: 14 [50112/225000 (22%)] Loss: 20493.509766\n",
      "Train Epoch: 14 [52608/225000 (23%)] Loss: 20541.234375\n",
      "Train Epoch: 14 [55104/225000 (24%)] Loss: 20987.269531\n",
      "Train Epoch: 14 [57600/225000 (26%)] Loss: 20408.611328\n",
      "Train Epoch: 14 [60096/225000 (27%)] Loss: 20054.570312\n",
      "Train Epoch: 14 [62592/225000 (28%)] Loss: 20691.496094\n",
      "Train Epoch: 14 [65088/225000 (29%)] Loss: 20180.457031\n",
      "Train Epoch: 14 [67584/225000 (30%)] Loss: 20370.531250\n",
      "Train Epoch: 14 [70080/225000 (31%)] Loss: 20385.378906\n",
      "Train Epoch: 14 [72576/225000 (32%)] Loss: 20715.871094\n",
      "Train Epoch: 14 [75072/225000 (33%)] Loss: 20498.750000\n",
      "Train Epoch: 14 [77568/225000 (34%)] Loss: 20889.931641\n",
      "Train Epoch: 14 [80064/225000 (36%)] Loss: 20594.828125\n",
      "Train Epoch: 14 [82560/225000 (37%)] Loss: 20467.439453\n",
      "Train Epoch: 14 [85056/225000 (38%)] Loss: 21067.535156\n",
      "Train Epoch: 14 [87552/225000 (39%)] Loss: 20464.496094\n",
      "Train Epoch: 14 [90048/225000 (40%)] Loss: 20425.992188\n",
      "Train Epoch: 14 [92544/225000 (41%)] Loss: 20264.890625\n",
      "Train Epoch: 14 [95040/225000 (42%)] Loss: 20588.669922\n",
      "Train Epoch: 14 [97536/225000 (43%)] Loss: 20370.546875\n",
      "Train Epoch: 14 [100032/225000 (44%)] Loss: 21040.292969\n",
      "Train Epoch: 14 [102528/225000 (46%)] Loss: 20547.091797\n",
      "Train Epoch: 14 [105024/225000 (47%)] Loss: 20738.919922\n",
      "Train Epoch: 14 [107520/225000 (48%)] Loss: 20747.136719\n",
      "Train Epoch: 14 [110016/225000 (49%)] Loss: 20852.125000\n",
      "Train Epoch: 14 [112512/225000 (50%)] Loss: 20147.232422\n",
      "Train Epoch: 14 [115008/225000 (51%)] Loss: 20711.136719\n",
      "Train Epoch: 14 [117504/225000 (52%)] Loss: 20727.621094\n",
      "Train Epoch: 14 [120000/225000 (53%)] Loss: 20411.294922\n",
      "Train Epoch: 14 [122496/225000 (54%)] Loss: 20212.859375\n",
      "Train Epoch: 14 [124992/225000 (56%)] Loss: 20673.496094\n",
      "Train Epoch: 14 [127488/225000 (57%)] Loss: 20583.496094\n",
      "Train Epoch: 14 [129984/225000 (58%)] Loss: 20173.769531\n",
      "Train Epoch: 14 [132480/225000 (59%)] Loss: 20259.039062\n",
      "Train Epoch: 14 [134976/225000 (60%)] Loss: 20574.578125\n",
      "Train Epoch: 14 [137472/225000 (61%)] Loss: 20964.906250\n",
      "Train Epoch: 14 [139968/225000 (62%)] Loss: 20746.082031\n",
      "Train Epoch: 14 [142464/225000 (63%)] Loss: 20441.080078\n",
      "Train Epoch: 14 [144960/225000 (64%)] Loss: 20645.929688\n",
      "Train Epoch: 14 [147456/225000 (66%)] Loss: 20202.583984\n",
      "Train Epoch: 14 [149952/225000 (67%)] Loss: 20539.314453\n",
      "Train Epoch: 14 [152448/225000 (68%)] Loss: 21020.480469\n",
      "Train Epoch: 14 [154944/225000 (69%)] Loss: 20429.722656\n",
      "Train Epoch: 14 [157440/225000 (70%)] Loss: 34882.875000\n",
      "Train Epoch: 14 [159936/225000 (71%)] Loss: 20195.779297\n",
      "Train Epoch: 14 [162432/225000 (72%)] Loss: 20324.589844\n",
      "Train Epoch: 14 [164928/225000 (73%)] Loss: 20560.925781\n",
      "Train Epoch: 14 [167424/225000 (74%)] Loss: 21061.644531\n",
      "Train Epoch: 14 [169920/225000 (76%)] Loss: 20577.935547\n",
      "Train Epoch: 14 [172416/225000 (77%)] Loss: 20528.332031\n",
      "Train Epoch: 14 [174912/225000 (78%)] Loss: 20423.964844\n",
      "Train Epoch: 14 [177408/225000 (79%)] Loss: 20611.519531\n",
      "Train Epoch: 14 [179904/225000 (80%)] Loss: 20802.238281\n",
      "Train Epoch: 14 [182400/225000 (81%)] Loss: 20807.421875\n",
      "Train Epoch: 14 [184896/225000 (82%)] Loss: 20041.308594\n",
      "Train Epoch: 14 [187392/225000 (83%)] Loss: 20246.890625\n",
      "Train Epoch: 14 [189888/225000 (84%)] Loss: 20469.054688\n",
      "Train Epoch: 14 [192384/225000 (86%)] Loss: 20716.910156\n",
      "Train Epoch: 14 [194880/225000 (87%)] Loss: 20694.972656\n",
      "Train Epoch: 14 [197376/225000 (88%)] Loss: 20269.128906\n",
      "Train Epoch: 14 [199872/225000 (89%)] Loss: 20602.833984\n",
      "Train Epoch: 14 [202368/225000 (90%)] Loss: 20609.693359\n",
      "Train Epoch: 14 [204864/225000 (91%)] Loss: 20648.648438\n",
      "Train Epoch: 14 [207360/225000 (92%)] Loss: 20868.669922\n",
      "Train Epoch: 14 [209856/225000 (93%)] Loss: 20603.025391\n",
      "Train Epoch: 14 [212352/225000 (94%)] Loss: 20248.322266\n",
      "Train Epoch: 14 [214848/225000 (95%)] Loss: 20584.132812\n",
      "Train Epoch: 14 [217344/225000 (97%)] Loss: 20736.851562\n",
      "Train Epoch: 14 [219840/225000 (98%)] Loss: 20078.781250\n",
      "Train Epoch: 14 [222336/225000 (99%)] Loss: 20803.296875\n",
      "Train Epoch: 14 [224832/225000 (100%)] Loss: 20684.265625\n",
      "    epoch          : 14\n",
      "    loss           : 20619.98784129693\n",
      "    val_loss       : 20489.480741676485\n",
      "Train Epoch: 15 [192/225000 (0%)] Loss: 20540.593750\n",
      "Train Epoch: 15 [2688/225000 (1%)] Loss: 20377.529297\n",
      "Train Epoch: 15 [5184/225000 (2%)] Loss: 20788.433594\n",
      "Train Epoch: 15 [7680/225000 (3%)] Loss: 20743.511719\n",
      "Train Epoch: 15 [10176/225000 (5%)] Loss: 20423.714844\n",
      "Train Epoch: 15 [12672/225000 (6%)] Loss: 20784.951172\n",
      "Train Epoch: 15 [15168/225000 (7%)] Loss: 21113.072266\n",
      "Train Epoch: 15 [17664/225000 (8%)] Loss: 21030.171875\n",
      "Train Epoch: 15 [20160/225000 (9%)] Loss: 20711.804688\n",
      "Train Epoch: 15 [22656/225000 (10%)] Loss: 20602.587891\n",
      "Train Epoch: 15 [25152/225000 (11%)] Loss: 20754.214844\n",
      "Train Epoch: 15 [27648/225000 (12%)] Loss: 20484.187500\n",
      "Train Epoch: 15 [30144/225000 (13%)] Loss: 20870.691406\n",
      "Train Epoch: 15 [32640/225000 (15%)] Loss: 20661.667969\n",
      "Train Epoch: 15 [35136/225000 (16%)] Loss: 20734.574219\n",
      "Train Epoch: 15 [37632/225000 (17%)] Loss: 20361.775391\n",
      "Train Epoch: 15 [40128/225000 (18%)] Loss: 20839.951172\n",
      "Train Epoch: 15 [42624/225000 (19%)] Loss: 20452.087891\n",
      "Train Epoch: 15 [45120/225000 (20%)] Loss: 20164.746094\n",
      "Train Epoch: 15 [47616/225000 (21%)] Loss: 20246.171875\n",
      "Train Epoch: 15 [50112/225000 (22%)] Loss: 20530.982422\n",
      "Train Epoch: 15 [52608/225000 (23%)] Loss: 20738.416016\n",
      "Train Epoch: 15 [55104/225000 (24%)] Loss: 20520.097656\n",
      "Train Epoch: 15 [57600/225000 (26%)] Loss: 20810.597656\n",
      "Train Epoch: 15 [60096/225000 (27%)] Loss: 20617.884766\n",
      "Train Epoch: 15 [62592/225000 (28%)] Loss: 20314.146484\n",
      "Train Epoch: 15 [65088/225000 (29%)] Loss: 20966.097656\n",
      "Train Epoch: 15 [67584/225000 (30%)] Loss: 20235.542969\n",
      "Train Epoch: 15 [70080/225000 (31%)] Loss: 20916.675781\n",
      "Train Epoch: 15 [72576/225000 (32%)] Loss: 20488.121094\n",
      "Train Epoch: 15 [75072/225000 (33%)] Loss: 20606.035156\n",
      "Train Epoch: 15 [77568/225000 (34%)] Loss: 20532.187500\n",
      "Train Epoch: 15 [80064/225000 (36%)] Loss: 20835.664062\n",
      "Train Epoch: 15 [82560/225000 (37%)] Loss: 20614.250000\n",
      "Train Epoch: 15 [85056/225000 (38%)] Loss: 20405.677734\n",
      "Train Epoch: 15 [87552/225000 (39%)] Loss: 20643.410156\n",
      "Train Epoch: 15 [90048/225000 (40%)] Loss: 20517.421875\n",
      "Train Epoch: 15 [92544/225000 (41%)] Loss: 20647.335938\n",
      "Train Epoch: 15 [95040/225000 (42%)] Loss: 20840.132812\n",
      "Train Epoch: 15 [97536/225000 (43%)] Loss: 20861.531250\n",
      "Train Epoch: 15 [100032/225000 (44%)] Loss: 21030.050781\n",
      "Train Epoch: 15 [102528/225000 (46%)] Loss: 20854.152344\n",
      "Train Epoch: 15 [105024/225000 (47%)] Loss: 20611.675781\n",
      "Train Epoch: 15 [107520/225000 (48%)] Loss: 20009.800781\n",
      "Train Epoch: 15 [110016/225000 (49%)] Loss: 20692.085938\n",
      "Train Epoch: 15 [112512/225000 (50%)] Loss: 20927.455078\n",
      "Train Epoch: 15 [115008/225000 (51%)] Loss: 20335.625000\n",
      "Train Epoch: 15 [117504/225000 (52%)] Loss: 20615.712891\n",
      "Train Epoch: 15 [120000/225000 (53%)] Loss: 20772.156250\n",
      "Train Epoch: 15 [122496/225000 (54%)] Loss: 20595.691406\n",
      "Train Epoch: 15 [124992/225000 (56%)] Loss: 20569.339844\n",
      "Train Epoch: 15 [127488/225000 (57%)] Loss: 20378.707031\n",
      "Train Epoch: 15 [129984/225000 (58%)] Loss: 21134.605469\n",
      "Train Epoch: 15 [132480/225000 (59%)] Loss: 20657.468750\n",
      "Train Epoch: 15 [134976/225000 (60%)] Loss: 20801.078125\n",
      "Train Epoch: 15 [137472/225000 (61%)] Loss: 20415.185547\n",
      "Train Epoch: 15 [139968/225000 (62%)] Loss: 20869.773438\n",
      "Train Epoch: 15 [142464/225000 (63%)] Loss: 20637.011719\n",
      "Train Epoch: 15 [144960/225000 (64%)] Loss: 20485.625000\n",
      "Train Epoch: 15 [147456/225000 (66%)] Loss: 20717.240234\n",
      "Train Epoch: 15 [149952/225000 (67%)] Loss: 20257.826172\n",
      "Train Epoch: 15 [152448/225000 (68%)] Loss: 20495.148438\n",
      "Train Epoch: 15 [154944/225000 (69%)] Loss: 20709.013672\n",
      "Train Epoch: 15 [157440/225000 (70%)] Loss: 20677.371094\n",
      "Train Epoch: 15 [159936/225000 (71%)] Loss: 21055.125000\n",
      "Train Epoch: 15 [162432/225000 (72%)] Loss: 20916.210938\n",
      "Train Epoch: 15 [164928/225000 (73%)] Loss: 20644.832031\n",
      "Train Epoch: 15 [167424/225000 (74%)] Loss: 20731.523438\n",
      "Train Epoch: 15 [169920/225000 (76%)] Loss: 20754.513672\n",
      "Train Epoch: 15 [172416/225000 (77%)] Loss: 20442.574219\n",
      "Train Epoch: 15 [174912/225000 (78%)] Loss: 20746.744141\n",
      "Train Epoch: 15 [177408/225000 (79%)] Loss: 20207.601562\n",
      "Train Epoch: 15 [179904/225000 (80%)] Loss: 20362.937500\n",
      "Train Epoch: 15 [182400/225000 (81%)] Loss: 20857.359375\n",
      "Train Epoch: 15 [184896/225000 (82%)] Loss: 20238.996094\n",
      "Train Epoch: 15 [187392/225000 (83%)] Loss: 20680.976562\n",
      "Train Epoch: 15 [189888/225000 (84%)] Loss: 20361.457031\n",
      "Train Epoch: 15 [192384/225000 (86%)] Loss: 20806.677734\n",
      "Train Epoch: 15 [194880/225000 (87%)] Loss: 20562.917969\n",
      "Train Epoch: 15 [197376/225000 (88%)] Loss: 20514.355469\n",
      "Train Epoch: 15 [199872/225000 (89%)] Loss: 20634.128906\n",
      "Train Epoch: 15 [202368/225000 (90%)] Loss: 20625.087891\n",
      "Train Epoch: 15 [204864/225000 (91%)] Loss: 20412.962891\n",
      "Train Epoch: 15 [207360/225000 (92%)] Loss: 20642.531250\n",
      "Train Epoch: 15 [209856/225000 (93%)] Loss: 20565.710938\n",
      "Train Epoch: 15 [212352/225000 (94%)] Loss: 20645.671875\n",
      "Train Epoch: 15 [214848/225000 (95%)] Loss: 20505.529297\n",
      "Train Epoch: 15 [217344/225000 (97%)] Loss: 20461.914062\n",
      "Train Epoch: 15 [219840/225000 (98%)] Loss: 20345.933594\n",
      "Train Epoch: 15 [222336/225000 (99%)] Loss: 20552.347656\n",
      "Train Epoch: 15 [224832/225000 (100%)] Loss: 20358.980469\n",
      "    epoch          : 15\n",
      "    loss           : 20596.641134945607\n",
      "    val_loss       : 20466.279485934563\n",
      "Train Epoch: 16 [192/225000 (0%)] Loss: 20789.519531\n",
      "Train Epoch: 16 [2688/225000 (1%)] Loss: 20745.849609\n",
      "Train Epoch: 16 [5184/225000 (2%)] Loss: 20688.476562\n",
      "Train Epoch: 16 [7680/225000 (3%)] Loss: 20770.933594\n",
      "Train Epoch: 16 [10176/225000 (5%)] Loss: 20604.167969\n",
      "Train Epoch: 16 [12672/225000 (6%)] Loss: 20503.128906\n",
      "Train Epoch: 16 [15168/225000 (7%)] Loss: 20851.867188\n",
      "Train Epoch: 16 [17664/225000 (8%)] Loss: 20627.832031\n",
      "Train Epoch: 16 [20160/225000 (9%)] Loss: 20121.222656\n",
      "Train Epoch: 16 [22656/225000 (10%)] Loss: 20714.966797\n",
      "Train Epoch: 16 [25152/225000 (11%)] Loss: 20847.187500\n",
      "Train Epoch: 16 [27648/225000 (12%)] Loss: 20222.867188\n",
      "Train Epoch: 16 [30144/225000 (13%)] Loss: 20516.687500\n",
      "Train Epoch: 16 [32640/225000 (15%)] Loss: 20341.542969\n",
      "Train Epoch: 16 [35136/225000 (16%)] Loss: 20653.664062\n",
      "Train Epoch: 16 [37632/225000 (17%)] Loss: 20685.207031\n",
      "Train Epoch: 16 [40128/225000 (18%)] Loss: 20418.724609\n",
      "Train Epoch: 16 [42624/225000 (19%)] Loss: 20437.875000\n",
      "Train Epoch: 16 [45120/225000 (20%)] Loss: 20589.919922\n",
      "Train Epoch: 16 [47616/225000 (21%)] Loss: 20539.203125\n",
      "Train Epoch: 16 [50112/225000 (22%)] Loss: 20204.703125\n",
      "Train Epoch: 16 [52608/225000 (23%)] Loss: 20754.509766\n",
      "Train Epoch: 16 [55104/225000 (24%)] Loss: 21102.597656\n",
      "Train Epoch: 16 [57600/225000 (26%)] Loss: 20191.078125\n",
      "Train Epoch: 16 [60096/225000 (27%)] Loss: 20360.214844\n",
      "Train Epoch: 16 [62592/225000 (28%)] Loss: 20461.779297\n",
      "Train Epoch: 16 [65088/225000 (29%)] Loss: 20279.191406\n",
      "Train Epoch: 16 [67584/225000 (30%)] Loss: 20694.767578\n",
      "Train Epoch: 16 [70080/225000 (31%)] Loss: 20633.777344\n",
      "Train Epoch: 16 [72576/225000 (32%)] Loss: 20472.097656\n",
      "Train Epoch: 16 [75072/225000 (33%)] Loss: 20843.101562\n",
      "Train Epoch: 16 [77568/225000 (34%)] Loss: 20956.437500\n",
      "Train Epoch: 16 [80064/225000 (36%)] Loss: 20535.753906\n",
      "Train Epoch: 16 [82560/225000 (37%)] Loss: 20702.480469\n",
      "Train Epoch: 16 [85056/225000 (38%)] Loss: 20455.800781\n",
      "Train Epoch: 16 [87552/225000 (39%)] Loss: 20541.386719\n",
      "Train Epoch: 16 [90048/225000 (40%)] Loss: 20341.416016\n",
      "Train Epoch: 16 [92544/225000 (41%)] Loss: 20999.419922\n",
      "Train Epoch: 16 [95040/225000 (42%)] Loss: 20297.765625\n",
      "Train Epoch: 16 [97536/225000 (43%)] Loss: 20672.148438\n",
      "Train Epoch: 16 [100032/225000 (44%)] Loss: 20475.292969\n",
      "Train Epoch: 16 [102528/225000 (46%)] Loss: 20387.384766\n",
      "Train Epoch: 16 [105024/225000 (47%)] Loss: 20359.011719\n",
      "Train Epoch: 16 [107520/225000 (48%)] Loss: 20252.660156\n",
      "Train Epoch: 16 [110016/225000 (49%)] Loss: 20127.593750\n",
      "Train Epoch: 16 [112512/225000 (50%)] Loss: 20412.597656\n",
      "Train Epoch: 16 [115008/225000 (51%)] Loss: 20475.406250\n",
      "Train Epoch: 16 [117504/225000 (52%)] Loss: 20569.800781\n",
      "Train Epoch: 16 [120000/225000 (53%)] Loss: 20655.431641\n",
      "Train Epoch: 16 [122496/225000 (54%)] Loss: 20274.703125\n",
      "Train Epoch: 16 [124992/225000 (56%)] Loss: 20538.953125\n",
      "Train Epoch: 16 [127488/225000 (57%)] Loss: 20487.560547\n",
      "Train Epoch: 16 [129984/225000 (58%)] Loss: 20601.984375\n",
      "Train Epoch: 16 [132480/225000 (59%)] Loss: 20519.972656\n",
      "Train Epoch: 16 [134976/225000 (60%)] Loss: 20322.902344\n",
      "Train Epoch: 16 [137472/225000 (61%)] Loss: 20429.796875\n",
      "Train Epoch: 16 [139968/225000 (62%)] Loss: 20667.431641\n",
      "Train Epoch: 16 [142464/225000 (63%)] Loss: 20995.937500\n",
      "Train Epoch: 16 [144960/225000 (64%)] Loss: 20414.156250\n",
      "Train Epoch: 16 [147456/225000 (66%)] Loss: 34785.375000\n",
      "Train Epoch: 16 [149952/225000 (67%)] Loss: 20601.585938\n",
      "Train Epoch: 16 [152448/225000 (68%)] Loss: 20086.187500\n",
      "Train Epoch: 16 [154944/225000 (69%)] Loss: 20125.652344\n",
      "Train Epoch: 16 [157440/225000 (70%)] Loss: 20542.912109\n",
      "Train Epoch: 16 [159936/225000 (71%)] Loss: 20643.214844\n",
      "Train Epoch: 16 [162432/225000 (72%)] Loss: 20478.105469\n",
      "Train Epoch: 16 [164928/225000 (73%)] Loss: 20690.380859\n",
      "Train Epoch: 16 [167424/225000 (74%)] Loss: 20336.199219\n",
      "Train Epoch: 16 [169920/225000 (76%)] Loss: 20028.937500\n",
      "Train Epoch: 16 [172416/225000 (77%)] Loss: 20813.082031\n",
      "Train Epoch: 16 [174912/225000 (78%)] Loss: 20624.968750\n",
      "Train Epoch: 16 [177408/225000 (79%)] Loss: 20786.371094\n",
      "Train Epoch: 16 [179904/225000 (80%)] Loss: 20638.304688\n",
      "Train Epoch: 16 [182400/225000 (81%)] Loss: 20145.832031\n",
      "Train Epoch: 16 [184896/225000 (82%)] Loss: 21225.386719\n",
      "Train Epoch: 16 [187392/225000 (83%)] Loss: 20143.207031\n",
      "Train Epoch: 16 [189888/225000 (84%)] Loss: 20318.453125\n",
      "Train Epoch: 16 [192384/225000 (86%)] Loss: 20636.542969\n",
      "Train Epoch: 16 [194880/225000 (87%)] Loss: 20382.585938\n",
      "Train Epoch: 16 [197376/225000 (88%)] Loss: 20557.347656\n",
      "Train Epoch: 16 [199872/225000 (89%)] Loss: 20897.054688\n",
      "Train Epoch: 16 [202368/225000 (90%)] Loss: 20625.882812\n",
      "Train Epoch: 16 [204864/225000 (91%)] Loss: 20249.931641\n",
      "Train Epoch: 16 [207360/225000 (92%)] Loss: 20270.277344\n",
      "Train Epoch: 16 [209856/225000 (93%)] Loss: 20625.625000\n",
      "Train Epoch: 16 [212352/225000 (94%)] Loss: 20035.976562\n",
      "Train Epoch: 16 [214848/225000 (95%)] Loss: 20512.046875\n",
      "Train Epoch: 16 [217344/225000 (97%)] Loss: 20310.240234\n",
      "Train Epoch: 16 [219840/225000 (98%)] Loss: 20376.996094\n",
      "Train Epoch: 16 [222336/225000 (99%)] Loss: 20806.238281\n",
      "Train Epoch: 16 [224832/225000 (100%)] Loss: 20372.128906\n",
      "    epoch          : 16\n",
      "    loss           : 20580.31902763705\n",
      "    val_loss       : 20444.791617218776\n",
      "Train Epoch: 17 [192/225000 (0%)] Loss: 20594.402344\n",
      "Train Epoch: 17 [2688/225000 (1%)] Loss: 20050.281250\n",
      "Train Epoch: 17 [5184/225000 (2%)] Loss: 20266.296875\n",
      "Train Epoch: 17 [7680/225000 (3%)] Loss: 20538.439453\n",
      "Train Epoch: 17 [10176/225000 (5%)] Loss: 20605.292969\n",
      "Train Epoch: 17 [12672/225000 (6%)] Loss: 20864.095703\n",
      "Train Epoch: 17 [15168/225000 (7%)] Loss: 20898.140625\n",
      "Train Epoch: 17 [17664/225000 (8%)] Loss: 20815.218750\n",
      "Train Epoch: 17 [20160/225000 (9%)] Loss: 20648.238281\n",
      "Train Epoch: 17 [22656/225000 (10%)] Loss: 20488.539062\n",
      "Train Epoch: 17 [25152/225000 (11%)] Loss: 20706.988281\n",
      "Train Epoch: 17 [27648/225000 (12%)] Loss: 20247.675781\n",
      "Train Epoch: 17 [30144/225000 (13%)] Loss: 20452.937500\n",
      "Train Epoch: 17 [32640/225000 (15%)] Loss: 20983.925781\n",
      "Train Epoch: 17 [35136/225000 (16%)] Loss: 20301.925781\n",
      "Train Epoch: 17 [37632/225000 (17%)] Loss: 20120.835938\n",
      "Train Epoch: 17 [40128/225000 (18%)] Loss: 20570.488281\n",
      "Train Epoch: 17 [42624/225000 (19%)] Loss: 20724.261719\n",
      "Train Epoch: 17 [45120/225000 (20%)] Loss: 20944.625000\n",
      "Train Epoch: 17 [47616/225000 (21%)] Loss: 20570.464844\n",
      "Train Epoch: 17 [50112/225000 (22%)] Loss: 20495.283203\n",
      "Train Epoch: 17 [52608/225000 (23%)] Loss: 20619.916016\n",
      "Train Epoch: 17 [55104/225000 (24%)] Loss: 20646.070312\n",
      "Train Epoch: 17 [57600/225000 (26%)] Loss: 20590.140625\n",
      "Train Epoch: 17 [60096/225000 (27%)] Loss: 20778.679688\n",
      "Train Epoch: 17 [62592/225000 (28%)] Loss: 20524.343750\n",
      "Train Epoch: 17 [65088/225000 (29%)] Loss: 20722.179688\n",
      "Train Epoch: 17 [67584/225000 (30%)] Loss: 20226.464844\n",
      "Train Epoch: 17 [70080/225000 (31%)] Loss: 20486.072266\n",
      "Train Epoch: 17 [72576/225000 (32%)] Loss: 20198.808594\n",
      "Train Epoch: 17 [75072/225000 (33%)] Loss: 20444.785156\n",
      "Train Epoch: 17 [77568/225000 (34%)] Loss: 19777.097656\n",
      "Train Epoch: 17 [80064/225000 (36%)] Loss: 20701.882812\n",
      "Train Epoch: 17 [82560/225000 (37%)] Loss: 20212.591797\n",
      "Train Epoch: 17 [85056/225000 (38%)] Loss: 20687.353516\n",
      "Train Epoch: 17 [87552/225000 (39%)] Loss: 21097.136719\n",
      "Train Epoch: 17 [90048/225000 (40%)] Loss: 20443.779297\n",
      "Train Epoch: 17 [92544/225000 (41%)] Loss: 20603.417969\n",
      "Train Epoch: 17 [95040/225000 (42%)] Loss: 20590.195312\n",
      "Train Epoch: 17 [97536/225000 (43%)] Loss: 20468.523438\n",
      "Train Epoch: 17 [100032/225000 (44%)] Loss: 20291.320312\n",
      "Train Epoch: 17 [102528/225000 (46%)] Loss: 20646.587891\n",
      "Train Epoch: 17 [105024/225000 (47%)] Loss: 20195.148438\n",
      "Train Epoch: 17 [107520/225000 (48%)] Loss: 20657.531250\n",
      "Train Epoch: 17 [110016/225000 (49%)] Loss: 20737.005859\n",
      "Train Epoch: 17 [112512/225000 (50%)] Loss: 20084.460938\n",
      "Train Epoch: 17 [115008/225000 (51%)] Loss: 20360.396484\n",
      "Train Epoch: 17 [117504/225000 (52%)] Loss: 20193.906250\n",
      "Train Epoch: 17 [120000/225000 (53%)] Loss: 20987.445312\n",
      "Train Epoch: 17 [122496/225000 (54%)] Loss: 20991.912109\n",
      "Train Epoch: 17 [124992/225000 (56%)] Loss: 20341.343750\n",
      "Train Epoch: 17 [127488/225000 (57%)] Loss: 20171.183594\n",
      "Train Epoch: 17 [129984/225000 (58%)] Loss: 20331.199219\n",
      "Train Epoch: 17 [132480/225000 (59%)] Loss: 25477.992188\n",
      "Train Epoch: 17 [134976/225000 (60%)] Loss: 20614.609375\n",
      "Train Epoch: 17 [137472/225000 (61%)] Loss: 20720.789062\n",
      "Train Epoch: 17 [139968/225000 (62%)] Loss: 20574.958984\n",
      "Train Epoch: 17 [142464/225000 (63%)] Loss: 19930.886719\n",
      "Train Epoch: 17 [144960/225000 (64%)] Loss: 20353.660156\n",
      "Train Epoch: 17 [147456/225000 (66%)] Loss: 20052.167969\n",
      "Train Epoch: 17 [149952/225000 (67%)] Loss: 20375.589844\n",
      "Train Epoch: 17 [152448/225000 (68%)] Loss: 20429.597656\n",
      "Train Epoch: 17 [154944/225000 (69%)] Loss: 20349.806641\n",
      "Train Epoch: 17 [157440/225000 (70%)] Loss: 20276.326172\n",
      "Train Epoch: 17 [159936/225000 (71%)] Loss: 20634.511719\n",
      "Train Epoch: 17 [162432/225000 (72%)] Loss: 20849.660156\n",
      "Train Epoch: 17 [164928/225000 (73%)] Loss: 20120.921875\n",
      "Train Epoch: 17 [167424/225000 (74%)] Loss: 20759.083984\n",
      "Train Epoch: 17 [169920/225000 (76%)] Loss: 20491.320312\n",
      "Train Epoch: 17 [172416/225000 (77%)] Loss: 20528.816406\n",
      "Train Epoch: 17 [174912/225000 (78%)] Loss: 20465.269531\n",
      "Train Epoch: 17 [177408/225000 (79%)] Loss: 20144.169922\n",
      "Train Epoch: 17 [179904/225000 (80%)] Loss: 20607.757812\n",
      "Train Epoch: 17 [182400/225000 (81%)] Loss: 20997.835938\n",
      "Train Epoch: 17 [184896/225000 (82%)] Loss: 21182.644531\n",
      "Train Epoch: 17 [187392/225000 (83%)] Loss: 20917.460938\n",
      "Train Epoch: 17 [189888/225000 (84%)] Loss: 20479.361328\n",
      "Train Epoch: 17 [192384/225000 (86%)] Loss: 20661.390625\n",
      "Train Epoch: 17 [194880/225000 (87%)] Loss: 20657.527344\n",
      "Train Epoch: 17 [197376/225000 (88%)] Loss: 20790.488281\n",
      "Train Epoch: 17 [199872/225000 (89%)] Loss: 20078.308594\n",
      "Train Epoch: 17 [202368/225000 (90%)] Loss: 20252.300781\n",
      "Train Epoch: 17 [204864/225000 (91%)] Loss: 20686.980469\n",
      "Train Epoch: 17 [207360/225000 (92%)] Loss: 19838.335938\n",
      "Train Epoch: 17 [209856/225000 (93%)] Loss: 20744.347656\n",
      "Train Epoch: 17 [212352/225000 (94%)] Loss: 21096.242188\n",
      "Train Epoch: 17 [214848/225000 (95%)] Loss: 20506.132812\n",
      "Train Epoch: 17 [217344/225000 (97%)] Loss: 20765.080078\n",
      "Train Epoch: 17 [219840/225000 (98%)] Loss: 20461.080078\n",
      "Train Epoch: 17 [222336/225000 (99%)] Loss: 21032.369141\n",
      "Train Epoch: 17 [224832/225000 (100%)] Loss: 20542.083984\n",
      "    epoch          : 17\n",
      "    loss           : 20557.082864494452\n",
      "    val_loss       : 20576.218766398102\n",
      "Train Epoch: 18 [192/225000 (0%)] Loss: 20458.800781\n",
      "Train Epoch: 18 [2688/225000 (1%)] Loss: 20818.230469\n",
      "Train Epoch: 18 [5184/225000 (2%)] Loss: 20630.994141\n",
      "Train Epoch: 18 [7680/225000 (3%)] Loss: 20491.601562\n",
      "Train Epoch: 18 [10176/225000 (5%)] Loss: 20242.156250\n",
      "Train Epoch: 18 [12672/225000 (6%)] Loss: 20320.031250\n",
      "Train Epoch: 18 [15168/225000 (7%)] Loss: 20146.619141\n",
      "Train Epoch: 18 [17664/225000 (8%)] Loss: 20333.515625\n",
      "Train Epoch: 18 [20160/225000 (9%)] Loss: 20121.671875\n",
      "Train Epoch: 18 [22656/225000 (10%)] Loss: 20958.419922\n",
      "Train Epoch: 18 [25152/225000 (11%)] Loss: 20410.273438\n",
      "Train Epoch: 18 [27648/225000 (12%)] Loss: 20413.062500\n",
      "Train Epoch: 18 [30144/225000 (13%)] Loss: 20695.000000\n",
      "Train Epoch: 18 [32640/225000 (15%)] Loss: 20490.875000\n",
      "Train Epoch: 18 [35136/225000 (16%)] Loss: 20392.640625\n",
      "Train Epoch: 18 [37632/225000 (17%)] Loss: 20533.642578\n",
      "Train Epoch: 18 [40128/225000 (18%)] Loss: 20780.851562\n",
      "Train Epoch: 18 [42624/225000 (19%)] Loss: 20278.876953\n",
      "Train Epoch: 18 [45120/225000 (20%)] Loss: 20429.427734\n",
      "Train Epoch: 18 [47616/225000 (21%)] Loss: 20335.550781\n",
      "Train Epoch: 18 [50112/225000 (22%)] Loss: 20612.656250\n",
      "Train Epoch: 18 [52608/225000 (23%)] Loss: 19997.050781\n",
      "Train Epoch: 18 [55104/225000 (24%)] Loss: 20467.353516\n",
      "Train Epoch: 18 [57600/225000 (26%)] Loss: 20881.705078\n",
      "Train Epoch: 18 [60096/225000 (27%)] Loss: 20801.050781\n",
      "Train Epoch: 18 [62592/225000 (28%)] Loss: 20796.890625\n",
      "Train Epoch: 18 [65088/225000 (29%)] Loss: 20722.191406\n",
      "Train Epoch: 18 [67584/225000 (30%)] Loss: 20584.074219\n",
      "Train Epoch: 18 [70080/225000 (31%)] Loss: 20097.832031\n",
      "Train Epoch: 18 [72576/225000 (32%)] Loss: 20206.103516\n",
      "Train Epoch: 18 [75072/225000 (33%)] Loss: 20428.939453\n",
      "Train Epoch: 18 [77568/225000 (34%)] Loss: 20874.531250\n",
      "Train Epoch: 18 [80064/225000 (36%)] Loss: 20360.607422\n",
      "Train Epoch: 18 [82560/225000 (37%)] Loss: 20644.267578\n",
      "Train Epoch: 18 [85056/225000 (38%)] Loss: 21000.093750\n",
      "Train Epoch: 18 [87552/225000 (39%)] Loss: 20678.369141\n",
      "Train Epoch: 18 [90048/225000 (40%)] Loss: 20438.933594\n",
      "Train Epoch: 18 [92544/225000 (41%)] Loss: 20752.765625\n",
      "Train Epoch: 18 [95040/225000 (42%)] Loss: 20344.113281\n",
      "Train Epoch: 18 [97536/225000 (43%)] Loss: 20391.453125\n",
      "Train Epoch: 18 [100032/225000 (44%)] Loss: 20416.003906\n",
      "Train Epoch: 18 [102528/225000 (46%)] Loss: 20850.673828\n",
      "Train Epoch: 18 [105024/225000 (47%)] Loss: 20654.591797\n",
      "Train Epoch: 18 [107520/225000 (48%)] Loss: 20787.095703\n",
      "Train Epoch: 18 [110016/225000 (49%)] Loss: 20696.929688\n",
      "Train Epoch: 18 [112512/225000 (50%)] Loss: 20775.035156\n",
      "Train Epoch: 18 [115008/225000 (51%)] Loss: 20369.804688\n",
      "Train Epoch: 18 [117504/225000 (52%)] Loss: 20362.392578\n",
      "Train Epoch: 18 [120000/225000 (53%)] Loss: 20894.613281\n",
      "Train Epoch: 18 [122496/225000 (54%)] Loss: 20575.736328\n",
      "Train Epoch: 18 [124992/225000 (56%)] Loss: 20516.003906\n",
      "Train Epoch: 18 [127488/225000 (57%)] Loss: 21104.191406\n",
      "Train Epoch: 18 [129984/225000 (58%)] Loss: 20650.285156\n",
      "Train Epoch: 18 [132480/225000 (59%)] Loss: 20288.964844\n",
      "Train Epoch: 18 [134976/225000 (60%)] Loss: 20196.792969\n",
      "Train Epoch: 18 [137472/225000 (61%)] Loss: 20585.970703\n",
      "Train Epoch: 18 [139968/225000 (62%)] Loss: 20249.628906\n",
      "Train Epoch: 18 [142464/225000 (63%)] Loss: 20481.310547\n",
      "Train Epoch: 18 [144960/225000 (64%)] Loss: 20137.041016\n",
      "Train Epoch: 18 [147456/225000 (66%)] Loss: 20787.558594\n",
      "Train Epoch: 18 [149952/225000 (67%)] Loss: 20421.660156\n",
      "Train Epoch: 18 [152448/225000 (68%)] Loss: 20127.429688\n",
      "Train Epoch: 18 [154944/225000 (69%)] Loss: 20940.640625\n",
      "Train Epoch: 18 [157440/225000 (70%)] Loss: 20473.767578\n",
      "Train Epoch: 18 [159936/225000 (71%)] Loss: 20297.433594\n",
      "Train Epoch: 18 [162432/225000 (72%)] Loss: 20216.664062\n",
      "Train Epoch: 18 [164928/225000 (73%)] Loss: 20154.183594\n",
      "Train Epoch: 18 [167424/225000 (74%)] Loss: 19963.980469\n",
      "Train Epoch: 18 [169920/225000 (76%)] Loss: 20789.605469\n",
      "Train Epoch: 18 [172416/225000 (77%)] Loss: 20460.964844\n",
      "Train Epoch: 18 [174912/225000 (78%)] Loss: 20265.867188\n",
      "Train Epoch: 18 [177408/225000 (79%)] Loss: 20881.146484\n",
      "Train Epoch: 18 [179904/225000 (80%)] Loss: 20765.589844\n",
      "Train Epoch: 18 [182400/225000 (81%)] Loss: 20424.503906\n",
      "Train Epoch: 18 [184896/225000 (82%)] Loss: 20924.023438\n",
      "Train Epoch: 18 [187392/225000 (83%)] Loss: 20111.617188\n",
      "Train Epoch: 18 [189888/225000 (84%)] Loss: 20554.703125\n",
      "Train Epoch: 18 [192384/225000 (86%)] Loss: 20894.898438\n",
      "Train Epoch: 18 [194880/225000 (87%)] Loss: 20063.978516\n",
      "Train Epoch: 18 [197376/225000 (88%)] Loss: 19973.867188\n",
      "Train Epoch: 18 [199872/225000 (89%)] Loss: 20591.003906\n",
      "Train Epoch: 18 [202368/225000 (90%)] Loss: 20520.519531\n",
      "Train Epoch: 18 [204864/225000 (91%)] Loss: 20740.833984\n",
      "Train Epoch: 18 [207360/225000 (92%)] Loss: 20752.177734\n",
      "Train Epoch: 18 [209856/225000 (93%)] Loss: 20677.804688\n",
      "Train Epoch: 18 [212352/225000 (94%)] Loss: 20421.884766\n",
      "Train Epoch: 18 [214848/225000 (95%)] Loss: 20410.236328\n",
      "Train Epoch: 18 [217344/225000 (97%)] Loss: 21035.955078\n",
      "Train Epoch: 18 [219840/225000 (98%)] Loss: 20717.472656\n",
      "Train Epoch: 18 [222336/225000 (99%)] Loss: 20134.984375\n",
      "Train Epoch: 18 [224832/225000 (100%)] Loss: 20371.761719\n",
      "    epoch          : 18\n",
      "    loss           : 20526.599939339805\n",
      "    val_loss       : 20509.79514004802\n",
      "Train Epoch: 19 [192/225000 (0%)] Loss: 19966.291016\n",
      "Train Epoch: 19 [2688/225000 (1%)] Loss: 20373.712891\n",
      "Train Epoch: 19 [5184/225000 (2%)] Loss: 20530.941406\n",
      "Train Epoch: 19 [7680/225000 (3%)] Loss: 20853.570312\n",
      "Train Epoch: 19 [10176/225000 (5%)] Loss: 20683.785156\n",
      "Train Epoch: 19 [12672/225000 (6%)] Loss: 20442.628906\n",
      "Train Epoch: 19 [15168/225000 (7%)] Loss: 20507.421875\n",
      "Train Epoch: 19 [17664/225000 (8%)] Loss: 20588.761719\n",
      "Train Epoch: 19 [20160/225000 (9%)] Loss: 20366.472656\n",
      "Train Epoch: 19 [22656/225000 (10%)] Loss: 20722.261719\n",
      "Train Epoch: 19 [25152/225000 (11%)] Loss: 19668.320312\n",
      "Train Epoch: 19 [27648/225000 (12%)] Loss: 20894.261719\n",
      "Train Epoch: 19 [30144/225000 (13%)] Loss: 20204.503906\n",
      "Train Epoch: 19 [32640/225000 (15%)] Loss: 20937.339844\n",
      "Train Epoch: 19 [35136/225000 (16%)] Loss: 20685.197266\n",
      "Train Epoch: 19 [37632/225000 (17%)] Loss: 20645.041016\n",
      "Train Epoch: 19 [40128/225000 (18%)] Loss: 20151.195312\n",
      "Train Epoch: 19 [42624/225000 (19%)] Loss: 20830.083984\n",
      "Train Epoch: 19 [45120/225000 (20%)] Loss: 20398.886719\n",
      "Train Epoch: 19 [47616/225000 (21%)] Loss: 20469.769531\n",
      "Train Epoch: 19 [50112/225000 (22%)] Loss: 20758.156250\n",
      "Train Epoch: 19 [52608/225000 (23%)] Loss: 20142.781250\n",
      "Train Epoch: 19 [55104/225000 (24%)] Loss: 20685.728516\n",
      "Train Epoch: 19 [57600/225000 (26%)] Loss: 19851.292969\n",
      "Train Epoch: 19 [60096/225000 (27%)] Loss: 20438.000000\n",
      "Train Epoch: 19 [62592/225000 (28%)] Loss: 20883.167969\n",
      "Train Epoch: 19 [65088/225000 (29%)] Loss: 20865.480469\n",
      "Train Epoch: 19 [67584/225000 (30%)] Loss: 20181.109375\n",
      "Train Epoch: 19 [70080/225000 (31%)] Loss: 20783.316406\n",
      "Train Epoch: 19 [72576/225000 (32%)] Loss: 20386.537109\n",
      "Train Epoch: 19 [75072/225000 (33%)] Loss: 20549.347656\n",
      "Train Epoch: 19 [77568/225000 (34%)] Loss: 20619.843750\n",
      "Train Epoch: 19 [80064/225000 (36%)] Loss: 19740.003906\n",
      "Train Epoch: 19 [82560/225000 (37%)] Loss: 20277.628906\n",
      "Train Epoch: 19 [85056/225000 (38%)] Loss: 20496.976562\n",
      "Train Epoch: 19 [87552/225000 (39%)] Loss: 20477.744141\n",
      "Train Epoch: 19 [90048/225000 (40%)] Loss: 20028.683594\n",
      "Train Epoch: 19 [92544/225000 (41%)] Loss: 20290.589844\n",
      "Train Epoch: 19 [95040/225000 (42%)] Loss: 20354.539062\n",
      "Train Epoch: 19 [97536/225000 (43%)] Loss: 20549.468750\n",
      "Train Epoch: 19 [100032/225000 (44%)] Loss: 20301.720703\n",
      "Train Epoch: 19 [102528/225000 (46%)] Loss: 20659.373047\n",
      "Train Epoch: 19 [105024/225000 (47%)] Loss: 20897.160156\n",
      "Train Epoch: 19 [107520/225000 (48%)] Loss: 20265.626953\n",
      "Train Epoch: 19 [110016/225000 (49%)] Loss: 20409.701172\n",
      "Train Epoch: 19 [112512/225000 (50%)] Loss: 20204.552734\n",
      "Train Epoch: 19 [115008/225000 (51%)] Loss: 20168.914062\n",
      "Train Epoch: 19 [117504/225000 (52%)] Loss: 20509.730469\n",
      "Train Epoch: 19 [120000/225000 (53%)] Loss: 20067.515625\n",
      "Train Epoch: 19 [122496/225000 (54%)] Loss: 20719.388672\n",
      "Train Epoch: 19 [124992/225000 (56%)] Loss: 20425.449219\n",
      "Train Epoch: 19 [127488/225000 (57%)] Loss: 20681.824219\n",
      "Train Epoch: 19 [129984/225000 (58%)] Loss: 20306.001953\n",
      "Train Epoch: 19 [132480/225000 (59%)] Loss: 20800.652344\n",
      "Train Epoch: 19 [134976/225000 (60%)] Loss: 20210.667969\n",
      "Train Epoch: 19 [137472/225000 (61%)] Loss: 20240.273438\n",
      "Train Epoch: 19 [139968/225000 (62%)] Loss: 20669.246094\n",
      "Train Epoch: 19 [142464/225000 (63%)] Loss: 20783.853516\n",
      "Train Epoch: 19 [144960/225000 (64%)] Loss: 20175.152344\n",
      "Train Epoch: 19 [147456/225000 (66%)] Loss: 19834.640625\n",
      "Train Epoch: 19 [149952/225000 (67%)] Loss: 21301.000000\n",
      "Train Epoch: 19 [152448/225000 (68%)] Loss: 20675.753906\n",
      "Train Epoch: 19 [154944/225000 (69%)] Loss: 20068.943359\n",
      "Train Epoch: 19 [157440/225000 (70%)] Loss: 20800.699219\n",
      "Train Epoch: 19 [159936/225000 (71%)] Loss: 20518.849609\n",
      "Train Epoch: 19 [162432/225000 (72%)] Loss: 20591.976562\n",
      "Train Epoch: 19 [164928/225000 (73%)] Loss: 20882.509766\n",
      "Train Epoch: 19 [167424/225000 (74%)] Loss: 20831.142578\n",
      "Train Epoch: 19 [169920/225000 (76%)] Loss: 20659.550781\n",
      "Train Epoch: 19 [172416/225000 (77%)] Loss: 20487.960938\n",
      "Train Epoch: 19 [174912/225000 (78%)] Loss: 20011.375000\n",
      "Train Epoch: 19 [177408/225000 (79%)] Loss: 20557.335938\n",
      "Train Epoch: 19 [179904/225000 (80%)] Loss: 20581.988281\n",
      "Train Epoch: 19 [182400/225000 (81%)] Loss: 21086.207031\n",
      "Train Epoch: 19 [184896/225000 (82%)] Loss: 20502.654297\n",
      "Train Epoch: 19 [187392/225000 (83%)] Loss: 20575.593750\n",
      "Train Epoch: 19 [189888/225000 (84%)] Loss: 20332.804688\n",
      "Train Epoch: 19 [192384/225000 (86%)] Loss: 20265.449219\n",
      "Train Epoch: 19 [194880/225000 (87%)] Loss: 20067.355469\n",
      "Train Epoch: 19 [197376/225000 (88%)] Loss: 20008.843750\n",
      "Train Epoch: 19 [199872/225000 (89%)] Loss: 20526.921875\n",
      "Train Epoch: 19 [202368/225000 (90%)] Loss: 20021.193359\n",
      "Train Epoch: 19 [204864/225000 (91%)] Loss: 20982.675781\n",
      "Train Epoch: 19 [207360/225000 (92%)] Loss: 20826.523438\n",
      "Train Epoch: 19 [209856/225000 (93%)] Loss: 20052.085938\n",
      "Train Epoch: 19 [212352/225000 (94%)] Loss: 20866.888672\n",
      "Train Epoch: 19 [214848/225000 (95%)] Loss: 20165.435547\n",
      "Train Epoch: 19 [217344/225000 (97%)] Loss: 20694.613281\n",
      "Train Epoch: 19 [219840/225000 (98%)] Loss: 20297.605469\n",
      "Train Epoch: 19 [222336/225000 (99%)] Loss: 20312.457031\n",
      "Train Epoch: 19 [224832/225000 (100%)] Loss: 20396.755859\n",
      "    epoch          : 19\n",
      "    loss           : 20528.840395357827\n",
      "    val_loss       : 20376.98676357606\n",
      "Train Epoch: 20 [192/225000 (0%)] Loss: 20733.001953\n",
      "Train Epoch: 20 [2688/225000 (1%)] Loss: 20017.806641\n",
      "Train Epoch: 20 [5184/225000 (2%)] Loss: 20546.498047\n",
      "Train Epoch: 20 [7680/225000 (3%)] Loss: 20395.234375\n",
      "Train Epoch: 20 [10176/225000 (5%)] Loss: 19981.396484\n",
      "Train Epoch: 20 [12672/225000 (6%)] Loss: 20837.570312\n",
      "Train Epoch: 20 [15168/225000 (7%)] Loss: 20924.705078\n",
      "Train Epoch: 20 [17664/225000 (8%)] Loss: 20507.070312\n",
      "Train Epoch: 20 [20160/225000 (9%)] Loss: 20758.091797\n",
      "Train Epoch: 20 [22656/225000 (10%)] Loss: 20796.259766\n",
      "Train Epoch: 20 [25152/225000 (11%)] Loss: 20321.214844\n",
      "Train Epoch: 20 [27648/225000 (12%)] Loss: 20389.054688\n",
      "Train Epoch: 20 [30144/225000 (13%)] Loss: 20645.542969\n",
      "Train Epoch: 20 [32640/225000 (15%)] Loss: 20515.734375\n",
      "Train Epoch: 20 [35136/225000 (16%)] Loss: 20424.511719\n",
      "Train Epoch: 20 [37632/225000 (17%)] Loss: 20732.175781\n",
      "Train Epoch: 20 [40128/225000 (18%)] Loss: 20285.109375\n",
      "Train Epoch: 20 [42624/225000 (19%)] Loss: 20059.845703\n",
      "Train Epoch: 20 [45120/225000 (20%)] Loss: 20792.886719\n",
      "Train Epoch: 20 [47616/225000 (21%)] Loss: 20492.929688\n",
      "Train Epoch: 20 [50112/225000 (22%)] Loss: 20172.308594\n",
      "Train Epoch: 20 [52608/225000 (23%)] Loss: 20329.718750\n",
      "Train Epoch: 20 [55104/225000 (24%)] Loss: 20830.359375\n",
      "Train Epoch: 20 [57600/225000 (26%)] Loss: 20731.593750\n",
      "Train Epoch: 20 [60096/225000 (27%)] Loss: 20595.957031\n",
      "Train Epoch: 20 [62592/225000 (28%)] Loss: 20701.800781\n",
      "Train Epoch: 20 [65088/225000 (29%)] Loss: 20274.785156\n",
      "Train Epoch: 20 [67584/225000 (30%)] Loss: 20537.093750\n",
      "Train Epoch: 20 [70080/225000 (31%)] Loss: 20462.937500\n",
      "Train Epoch: 20 [72576/225000 (32%)] Loss: 20523.671875\n",
      "Train Epoch: 20 [75072/225000 (33%)] Loss: 20253.947266\n",
      "Train Epoch: 20 [77568/225000 (34%)] Loss: 20764.898438\n",
      "Train Epoch: 20 [80064/225000 (36%)] Loss: 20203.902344\n",
      "Train Epoch: 20 [82560/225000 (37%)] Loss: 20535.613281\n",
      "Train Epoch: 20 [85056/225000 (38%)] Loss: 20810.710938\n",
      "Train Epoch: 20 [87552/225000 (39%)] Loss: 20048.343750\n",
      "Train Epoch: 20 [90048/225000 (40%)] Loss: 20905.382812\n",
      "Train Epoch: 20 [92544/225000 (41%)] Loss: 20268.746094\n",
      "Train Epoch: 20 [95040/225000 (42%)] Loss: 19925.996094\n",
      "Train Epoch: 20 [97536/225000 (43%)] Loss: 20430.003906\n",
      "Train Epoch: 20 [100032/225000 (44%)] Loss: 20195.931641\n",
      "Train Epoch: 20 [102528/225000 (46%)] Loss: 20344.437500\n",
      "Train Epoch: 20 [105024/225000 (47%)] Loss: 20176.078125\n",
      "Train Epoch: 20 [107520/225000 (48%)] Loss: 20636.955078\n",
      "Train Epoch: 20 [110016/225000 (49%)] Loss: 20804.148438\n",
      "Train Epoch: 20 [112512/225000 (50%)] Loss: 20341.765625\n",
      "Train Epoch: 20 [115008/225000 (51%)] Loss: 20316.771484\n",
      "Train Epoch: 20 [117504/225000 (52%)] Loss: 20081.679688\n",
      "Train Epoch: 20 [120000/225000 (53%)] Loss: 20506.267578\n",
      "Train Epoch: 20 [122496/225000 (54%)] Loss: 20149.548828\n",
      "Train Epoch: 20 [124992/225000 (56%)] Loss: 20479.089844\n",
      "Train Epoch: 20 [127488/225000 (57%)] Loss: 20115.529297\n",
      "Train Epoch: 20 [129984/225000 (58%)] Loss: 20251.679688\n",
      "Train Epoch: 20 [132480/225000 (59%)] Loss: 20794.830078\n",
      "Train Epoch: 20 [134976/225000 (60%)] Loss: 20452.158203\n",
      "Train Epoch: 20 [137472/225000 (61%)] Loss: 20156.234375\n",
      "Train Epoch: 20 [139968/225000 (62%)] Loss: 20090.871094\n",
      "Train Epoch: 20 [142464/225000 (63%)] Loss: 20826.201172\n",
      "Train Epoch: 20 [144960/225000 (64%)] Loss: 20297.169922\n",
      "Train Epoch: 20 [147456/225000 (66%)] Loss: 20403.648438\n",
      "Train Epoch: 20 [149952/225000 (67%)] Loss: 20463.576172\n",
      "Train Epoch: 20 [152448/225000 (68%)] Loss: 20667.232422\n",
      "Train Epoch: 20 [154944/225000 (69%)] Loss: 20489.371094\n",
      "Train Epoch: 20 [157440/225000 (70%)] Loss: 20168.921875\n",
      "Train Epoch: 20 [159936/225000 (71%)] Loss: 20658.187500\n",
      "Train Epoch: 20 [162432/225000 (72%)] Loss: 19898.703125\n",
      "Train Epoch: 20 [164928/225000 (73%)] Loss: 20388.349609\n",
      "Train Epoch: 20 [167424/225000 (74%)] Loss: 20589.585938\n",
      "Train Epoch: 20 [169920/225000 (76%)] Loss: 20524.904297\n",
      "Train Epoch: 20 [172416/225000 (77%)] Loss: 20278.363281\n",
      "Train Epoch: 20 [174912/225000 (78%)] Loss: 20116.419922\n",
      "Train Epoch: 20 [177408/225000 (79%)] Loss: 20517.945312\n",
      "Train Epoch: 20 [179904/225000 (80%)] Loss: 20611.367188\n",
      "Train Epoch: 20 [182400/225000 (81%)] Loss: 20457.105469\n",
      "Train Epoch: 20 [184896/225000 (82%)] Loss: 20112.140625\n",
      "Train Epoch: 20 [187392/225000 (83%)] Loss: 20299.304688\n",
      "Train Epoch: 20 [189888/225000 (84%)] Loss: 20388.693359\n",
      "Train Epoch: 20 [192384/225000 (86%)] Loss: 20142.392578\n",
      "Train Epoch: 20 [194880/225000 (87%)] Loss: 21261.039062\n",
      "Train Epoch: 20 [197376/225000 (88%)] Loss: 20128.500000\n",
      "Train Epoch: 20 [199872/225000 (89%)] Loss: 20218.146484\n",
      "Train Epoch: 20 [202368/225000 (90%)] Loss: 20506.476562\n",
      "Train Epoch: 20 [204864/225000 (91%)] Loss: 20386.080078\n",
      "Train Epoch: 20 [207360/225000 (92%)] Loss: 20599.310547\n",
      "Train Epoch: 20 [209856/225000 (93%)] Loss: 20472.250000\n",
      "Train Epoch: 20 [212352/225000 (94%)] Loss: 20552.107422\n",
      "Train Epoch: 20 [214848/225000 (95%)] Loss: 20468.050781\n",
      "Train Epoch: 20 [217344/225000 (97%)] Loss: 20768.148438\n",
      "Train Epoch: 20 [219840/225000 (98%)] Loss: 20583.058594\n",
      "Train Epoch: 20 [222336/225000 (99%)] Loss: 20704.203125\n",
      "Train Epoch: 20 [224832/225000 (100%)] Loss: 20507.736328\n",
      "    epoch          : 20\n",
      "    loss           : 20518.102910689526\n",
      "    val_loss       : 20365.991022587732\n",
      "Train Epoch: 21 [192/225000 (0%)] Loss: 20340.398438\n",
      "Train Epoch: 21 [2688/225000 (1%)] Loss: 20510.382812\n",
      "Train Epoch: 21 [5184/225000 (2%)] Loss: 20197.773438\n",
      "Train Epoch: 21 [7680/225000 (3%)] Loss: 20671.771484\n",
      "Train Epoch: 21 [10176/225000 (5%)] Loss: 20507.210938\n",
      "Train Epoch: 21 [12672/225000 (6%)] Loss: 20435.464844\n",
      "Train Epoch: 21 [15168/225000 (7%)] Loss: 20314.083984\n",
      "Train Epoch: 21 [17664/225000 (8%)] Loss: 20669.929688\n",
      "Train Epoch: 21 [20160/225000 (9%)] Loss: 20293.074219\n",
      "Train Epoch: 21 [22656/225000 (10%)] Loss: 20759.750000\n",
      "Train Epoch: 21 [25152/225000 (11%)] Loss: 20398.535156\n",
      "Train Epoch: 21 [27648/225000 (12%)] Loss: 20672.898438\n",
      "Train Epoch: 21 [30144/225000 (13%)] Loss: 19926.101562\n",
      "Train Epoch: 21 [32640/225000 (15%)] Loss: 20797.214844\n",
      "Train Epoch: 21 [35136/225000 (16%)] Loss: 20762.265625\n",
      "Train Epoch: 21 [37632/225000 (17%)] Loss: 20696.179688\n",
      "Train Epoch: 21 [40128/225000 (18%)] Loss: 20272.933594\n",
      "Train Epoch: 21 [42624/225000 (19%)] Loss: 20314.173828\n",
      "Train Epoch: 21 [45120/225000 (20%)] Loss: 20775.964844\n",
      "Train Epoch: 21 [47616/225000 (21%)] Loss: 20560.761719\n",
      "Train Epoch: 21 [50112/225000 (22%)] Loss: 20721.527344\n",
      "Train Epoch: 21 [52608/225000 (23%)] Loss: 20330.054688\n",
      "Train Epoch: 21 [55104/225000 (24%)] Loss: 20000.408203\n",
      "Train Epoch: 21 [57600/225000 (26%)] Loss: 20425.886719\n",
      "Train Epoch: 21 [60096/225000 (27%)] Loss: 20439.082031\n",
      "Train Epoch: 21 [62592/225000 (28%)] Loss: 20543.787109\n",
      "Train Epoch: 21 [65088/225000 (29%)] Loss: 20722.777344\n",
      "Train Epoch: 21 [67584/225000 (30%)] Loss: 20159.546875\n",
      "Train Epoch: 21 [70080/225000 (31%)] Loss: 20668.253906\n",
      "Train Epoch: 21 [72576/225000 (32%)] Loss: 20602.380859\n",
      "Train Epoch: 21 [75072/225000 (33%)] Loss: 20680.816406\n",
      "Train Epoch: 21 [77568/225000 (34%)] Loss: 20030.675781\n",
      "Train Epoch: 21 [80064/225000 (36%)] Loss: 20247.203125\n",
      "Train Epoch: 21 [82560/225000 (37%)] Loss: 20542.773438\n",
      "Train Epoch: 21 [85056/225000 (38%)] Loss: 20383.386719\n",
      "Train Epoch: 21 [87552/225000 (39%)] Loss: 20551.298828\n",
      "Train Epoch: 21 [90048/225000 (40%)] Loss: 20215.074219\n",
      "Train Epoch: 21 [92544/225000 (41%)] Loss: 20289.718750\n",
      "Train Epoch: 21 [95040/225000 (42%)] Loss: 20562.068359\n",
      "Train Epoch: 21 [97536/225000 (43%)] Loss: 20497.851562\n",
      "Train Epoch: 21 [100032/225000 (44%)] Loss: 20151.906250\n",
      "Train Epoch: 21 [102528/225000 (46%)] Loss: 20553.843750\n",
      "Train Epoch: 21 [105024/225000 (47%)] Loss: 20185.906250\n",
      "Train Epoch: 21 [107520/225000 (48%)] Loss: 20674.261719\n",
      "Train Epoch: 21 [110016/225000 (49%)] Loss: 20048.769531\n",
      "Train Epoch: 21 [112512/225000 (50%)] Loss: 20787.072266\n",
      "Train Epoch: 21 [115008/225000 (51%)] Loss: 20390.964844\n",
      "Train Epoch: 21 [117504/225000 (52%)] Loss: 20225.261719\n",
      "Train Epoch: 21 [120000/225000 (53%)] Loss: 20233.093750\n",
      "Train Epoch: 21 [122496/225000 (54%)] Loss: 20191.433594\n",
      "Train Epoch: 21 [124992/225000 (56%)] Loss: 20294.994141\n",
      "Train Epoch: 21 [127488/225000 (57%)] Loss: 20287.636719\n",
      "Train Epoch: 21 [129984/225000 (58%)] Loss: 20343.417969\n",
      "Train Epoch: 21 [132480/225000 (59%)] Loss: 20397.644531\n",
      "Train Epoch: 21 [134976/225000 (60%)] Loss: 20246.839844\n",
      "Train Epoch: 21 [137472/225000 (61%)] Loss: 20820.421875\n",
      "Train Epoch: 21 [139968/225000 (62%)] Loss: 20174.750000\n",
      "Train Epoch: 21 [142464/225000 (63%)] Loss: 20149.257812\n",
      "Train Epoch: 21 [144960/225000 (64%)] Loss: 20257.708984\n",
      "Train Epoch: 21 [147456/225000 (66%)] Loss: 20408.359375\n",
      "Train Epoch: 21 [149952/225000 (67%)] Loss: 20586.472656\n",
      "Train Epoch: 21 [152448/225000 (68%)] Loss: 20927.402344\n",
      "Train Epoch: 21 [154944/225000 (69%)] Loss: 20391.656250\n",
      "Train Epoch: 21 [157440/225000 (70%)] Loss: 20805.873047\n",
      "Train Epoch: 21 [159936/225000 (71%)] Loss: 20389.292969\n",
      "Train Epoch: 21 [162432/225000 (72%)] Loss: 20906.707031\n",
      "Train Epoch: 21 [164928/225000 (73%)] Loss: 20257.181641\n",
      "Train Epoch: 21 [167424/225000 (74%)] Loss: 21000.347656\n",
      "Train Epoch: 21 [169920/225000 (76%)] Loss: 20526.736328\n",
      "Train Epoch: 21 [172416/225000 (77%)] Loss: 19985.808594\n",
      "Train Epoch: 21 [174912/225000 (78%)] Loss: 20236.234375\n",
      "Train Epoch: 21 [177408/225000 (79%)] Loss: 20473.597656\n",
      "Train Epoch: 21 [179904/225000 (80%)] Loss: 20367.230469\n",
      "Train Epoch: 21 [182400/225000 (81%)] Loss: 19951.193359\n",
      "Train Epoch: 21 [184896/225000 (82%)] Loss: 20464.080078\n",
      "Train Epoch: 21 [187392/225000 (83%)] Loss: 20453.181641\n",
      "Train Epoch: 21 [189888/225000 (84%)] Loss: 20441.679688\n",
      "Train Epoch: 21 [192384/225000 (86%)] Loss: 20276.160156\n",
      "Train Epoch: 21 [194880/225000 (87%)] Loss: 20066.869141\n",
      "Train Epoch: 21 [197376/225000 (88%)] Loss: 20574.400391\n",
      "Train Epoch: 21 [199872/225000 (89%)] Loss: 20186.652344\n",
      "Train Epoch: 21 [202368/225000 (90%)] Loss: 20444.636719\n",
      "Train Epoch: 21 [204864/225000 (91%)] Loss: 20320.468750\n",
      "Train Epoch: 21 [207360/225000 (92%)] Loss: 21047.218750\n",
      "Train Epoch: 21 [209856/225000 (93%)] Loss: 20207.464844\n",
      "Train Epoch: 21 [212352/225000 (94%)] Loss: 20444.349609\n",
      "Train Epoch: 21 [214848/225000 (95%)] Loss: 20324.376953\n",
      "Train Epoch: 21 [217344/225000 (97%)] Loss: 20136.121094\n",
      "Train Epoch: 21 [219840/225000 (98%)] Loss: 20018.109375\n",
      "Train Epoch: 21 [222336/225000 (99%)] Loss: 20779.376953\n",
      "Train Epoch: 21 [224832/225000 (100%)] Loss: 20342.740234\n",
      "    epoch          : 21\n",
      "    loss           : 20464.97430440753\n",
      "    val_loss       : 20348.579479766257\n",
      "Train Epoch: 22 [192/225000 (0%)] Loss: 20253.484375\n",
      "Train Epoch: 22 [2688/225000 (1%)] Loss: 20677.906250\n",
      "Train Epoch: 22 [5184/225000 (2%)] Loss: 20566.710938\n",
      "Train Epoch: 22 [7680/225000 (3%)] Loss: 20401.171875\n",
      "Train Epoch: 22 [10176/225000 (5%)] Loss: 20481.119141\n",
      "Train Epoch: 22 [12672/225000 (6%)] Loss: 20249.714844\n",
      "Train Epoch: 22 [15168/225000 (7%)] Loss: 20314.347656\n",
      "Train Epoch: 22 [17664/225000 (8%)] Loss: 20152.761719\n",
      "Train Epoch: 22 [20160/225000 (9%)] Loss: 20470.437500\n",
      "Train Epoch: 22 [22656/225000 (10%)] Loss: 20046.031250\n",
      "Train Epoch: 22 [25152/225000 (11%)] Loss: 20759.273438\n",
      "Train Epoch: 22 [27648/225000 (12%)] Loss: 20155.433594\n",
      "Train Epoch: 22 [30144/225000 (13%)] Loss: 21122.070312\n",
      "Train Epoch: 22 [32640/225000 (15%)] Loss: 20663.148438\n",
      "Train Epoch: 22 [35136/225000 (16%)] Loss: 20998.363281\n",
      "Train Epoch: 22 [37632/225000 (17%)] Loss: 20563.113281\n",
      "Train Epoch: 22 [40128/225000 (18%)] Loss: 20327.132812\n",
      "Train Epoch: 22 [42624/225000 (19%)] Loss: 20562.878906\n",
      "Train Epoch: 22 [45120/225000 (20%)] Loss: 20640.171875\n",
      "Train Epoch: 22 [47616/225000 (21%)] Loss: 20220.363281\n",
      "Train Epoch: 22 [50112/225000 (22%)] Loss: 20216.992188\n",
      "Train Epoch: 22 [52608/225000 (23%)] Loss: 20718.087891\n",
      "Train Epoch: 22 [55104/225000 (24%)] Loss: 20298.017578\n",
      "Train Epoch: 22 [57600/225000 (26%)] Loss: 20247.066406\n",
      "Train Epoch: 22 [60096/225000 (27%)] Loss: 20383.638672\n",
      "Train Epoch: 22 [62592/225000 (28%)] Loss: 20680.414062\n",
      "Train Epoch: 22 [65088/225000 (29%)] Loss: 20280.439453\n",
      "Train Epoch: 22 [67584/225000 (30%)] Loss: 20700.074219\n",
      "Train Epoch: 22 [70080/225000 (31%)] Loss: 20885.609375\n",
      "Train Epoch: 22 [72576/225000 (32%)] Loss: 19959.578125\n",
      "Train Epoch: 22 [75072/225000 (33%)] Loss: 20518.500000\n",
      "Train Epoch: 22 [77568/225000 (34%)] Loss: 20514.867188\n",
      "Train Epoch: 22 [80064/225000 (36%)] Loss: 20792.859375\n",
      "Train Epoch: 22 [82560/225000 (37%)] Loss: 20812.281250\n",
      "Train Epoch: 22 [85056/225000 (38%)] Loss: 20415.648438\n",
      "Train Epoch: 22 [87552/225000 (39%)] Loss: 20272.486328\n",
      "Train Epoch: 22 [90048/225000 (40%)] Loss: 20068.023438\n",
      "Train Epoch: 22 [92544/225000 (41%)] Loss: 20028.839844\n",
      "Train Epoch: 22 [95040/225000 (42%)] Loss: 20422.222656\n",
      "Train Epoch: 22 [97536/225000 (43%)] Loss: 20873.691406\n",
      "Train Epoch: 22 [100032/225000 (44%)] Loss: 20260.798828\n",
      "Train Epoch: 22 [102528/225000 (46%)] Loss: 20600.093750\n",
      "Train Epoch: 22 [105024/225000 (47%)] Loss: 20260.953125\n",
      "Train Epoch: 22 [107520/225000 (48%)] Loss: 20216.796875\n",
      "Train Epoch: 22 [110016/225000 (49%)] Loss: 20323.699219\n",
      "Train Epoch: 22 [112512/225000 (50%)] Loss: 20392.496094\n",
      "Train Epoch: 22 [115008/225000 (51%)] Loss: 20302.011719\n",
      "Train Epoch: 22 [117504/225000 (52%)] Loss: 20780.517578\n",
      "Train Epoch: 22 [120000/225000 (53%)] Loss: 20763.308594\n",
      "Train Epoch: 22 [122496/225000 (54%)] Loss: 20714.730469\n",
      "Train Epoch: 22 [124992/225000 (56%)] Loss: 20567.615234\n",
      "Train Epoch: 22 [127488/225000 (57%)] Loss: 20560.259766\n",
      "Train Epoch: 22 [129984/225000 (58%)] Loss: 20128.712891\n",
      "Train Epoch: 22 [132480/225000 (59%)] Loss: 20604.484375\n",
      "Train Epoch: 22 [134976/225000 (60%)] Loss: 20526.746094\n",
      "Train Epoch: 22 [137472/225000 (61%)] Loss: 20742.455078\n",
      "Train Epoch: 22 [139968/225000 (62%)] Loss: 19937.585938\n",
      "Train Epoch: 22 [142464/225000 (63%)] Loss: 19901.960938\n",
      "Train Epoch: 22 [144960/225000 (64%)] Loss: 20488.636719\n",
      "Train Epoch: 22 [147456/225000 (66%)] Loss: 20650.210938\n",
      "Train Epoch: 22 [149952/225000 (67%)] Loss: 20320.490234\n",
      "Train Epoch: 22 [152448/225000 (68%)] Loss: 20087.775391\n",
      "Train Epoch: 22 [154944/225000 (69%)] Loss: 20713.785156\n",
      "Train Epoch: 22 [157440/225000 (70%)] Loss: 20173.107422\n",
      "Train Epoch: 22 [159936/225000 (71%)] Loss: 20350.468750\n",
      "Train Epoch: 22 [162432/225000 (72%)] Loss: 20551.824219\n",
      "Train Epoch: 22 [164928/225000 (73%)] Loss: 20309.089844\n",
      "Train Epoch: 22 [167424/225000 (74%)] Loss: 20102.765625\n",
      "Train Epoch: 22 [169920/225000 (76%)] Loss: 20314.617188\n",
      "Train Epoch: 22 [172416/225000 (77%)] Loss: 19928.386719\n",
      "Train Epoch: 22 [174912/225000 (78%)] Loss: 20164.820312\n",
      "Train Epoch: 22 [177408/225000 (79%)] Loss: 20449.457031\n",
      "Train Epoch: 22 [179904/225000 (80%)] Loss: 20207.037109\n",
      "Train Epoch: 22 [182400/225000 (81%)] Loss: 20825.675781\n",
      "Train Epoch: 22 [184896/225000 (82%)] Loss: 20287.308594\n",
      "Train Epoch: 22 [187392/225000 (83%)] Loss: 20384.046875\n",
      "Train Epoch: 22 [189888/225000 (84%)] Loss: 20227.992188\n",
      "Train Epoch: 22 [192384/225000 (86%)] Loss: 20560.857422\n",
      "Train Epoch: 22 [194880/225000 (87%)] Loss: 20645.539062\n",
      "Train Epoch: 22 [197376/225000 (88%)] Loss: 20356.080078\n",
      "Train Epoch: 22 [199872/225000 (89%)] Loss: 19880.187500\n",
      "Train Epoch: 22 [202368/225000 (90%)] Loss: 19616.912109\n",
      "Train Epoch: 22 [204864/225000 (91%)] Loss: 19959.875000\n",
      "Train Epoch: 22 [207360/225000 (92%)] Loss: 20372.816406\n",
      "Train Epoch: 22 [209856/225000 (93%)] Loss: 20515.033203\n",
      "Train Epoch: 22 [212352/225000 (94%)] Loss: 19878.455078\n",
      "Train Epoch: 22 [214848/225000 (95%)] Loss: 19915.019531\n",
      "Train Epoch: 22 [217344/225000 (97%)] Loss: 20138.156250\n",
      "Train Epoch: 22 [219840/225000 (98%)] Loss: 20482.031250\n",
      "Train Epoch: 22 [222336/225000 (99%)] Loss: 21081.636719\n",
      "Train Epoch: 22 [224832/225000 (100%)] Loss: 20495.824219\n",
      "    epoch          : 22\n",
      "    loss           : 20443.547098309515\n",
      "    val_loss       : 20417.542681264968\n",
      "Train Epoch: 23 [192/225000 (0%)] Loss: 20877.027344\n",
      "Train Epoch: 23 [2688/225000 (1%)] Loss: 20540.978516\n",
      "Train Epoch: 23 [5184/225000 (2%)] Loss: 20258.824219\n",
      "Train Epoch: 23 [7680/225000 (3%)] Loss: 20408.937500\n",
      "Train Epoch: 23 [10176/225000 (5%)] Loss: 20707.496094\n",
      "Train Epoch: 23 [12672/225000 (6%)] Loss: 20405.343750\n",
      "Train Epoch: 23 [15168/225000 (7%)] Loss: 19860.812500\n",
      "Train Epoch: 23 [17664/225000 (8%)] Loss: 20172.289062\n",
      "Train Epoch: 23 [20160/225000 (9%)] Loss: 20233.251953\n",
      "Train Epoch: 23 [22656/225000 (10%)] Loss: 20304.253906\n",
      "Train Epoch: 23 [25152/225000 (11%)] Loss: 20546.335938\n",
      "Train Epoch: 23 [27648/225000 (12%)] Loss: 20606.806641\n",
      "Train Epoch: 23 [30144/225000 (13%)] Loss: 19912.757812\n",
      "Train Epoch: 23 [32640/225000 (15%)] Loss: 20073.378906\n",
      "Train Epoch: 23 [35136/225000 (16%)] Loss: 20244.861328\n",
      "Train Epoch: 23 [37632/225000 (17%)] Loss: 20510.667969\n",
      "Train Epoch: 23 [40128/225000 (18%)] Loss: 20149.605469\n",
      "Train Epoch: 23 [42624/225000 (19%)] Loss: 20120.308594\n",
      "Train Epoch: 23 [45120/225000 (20%)] Loss: 20468.195312\n",
      "Train Epoch: 23 [47616/225000 (21%)] Loss: 20039.484375\n",
      "Train Epoch: 23 [50112/225000 (22%)] Loss: 20580.296875\n",
      "Train Epoch: 23 [52608/225000 (23%)] Loss: 20367.439453\n",
      "Train Epoch: 23 [55104/225000 (24%)] Loss: 20830.865234\n",
      "Train Epoch: 23 [57600/225000 (26%)] Loss: 20270.777344\n",
      "Train Epoch: 23 [60096/225000 (27%)] Loss: 19899.500000\n",
      "Train Epoch: 23 [62592/225000 (28%)] Loss: 20557.923828\n",
      "Train Epoch: 23 [65088/225000 (29%)] Loss: 20160.511719\n",
      "Train Epoch: 23 [67584/225000 (30%)] Loss: 20199.017578\n",
      "Train Epoch: 23 [70080/225000 (31%)] Loss: 20163.980469\n",
      "Train Epoch: 23 [72576/225000 (32%)] Loss: 20356.785156\n",
      "Train Epoch: 23 [75072/225000 (33%)] Loss: 20194.281250\n",
      "Train Epoch: 23 [77568/225000 (34%)] Loss: 20849.019531\n",
      "Train Epoch: 23 [80064/225000 (36%)] Loss: 20367.140625\n",
      "Train Epoch: 23 [82560/225000 (37%)] Loss: 20316.919922\n",
      "Train Epoch: 23 [85056/225000 (38%)] Loss: 20491.792969\n",
      "Train Epoch: 23 [87552/225000 (39%)] Loss: 19775.519531\n",
      "Train Epoch: 23 [90048/225000 (40%)] Loss: 20411.453125\n",
      "Train Epoch: 23 [92544/225000 (41%)] Loss: 20387.658203\n",
      "Train Epoch: 23 [95040/225000 (42%)] Loss: 20166.605469\n",
      "Train Epoch: 23 [97536/225000 (43%)] Loss: 20838.738281\n",
      "Train Epoch: 23 [100032/225000 (44%)] Loss: 19807.253906\n",
      "Train Epoch: 23 [102528/225000 (46%)] Loss: 20632.292969\n",
      "Train Epoch: 23 [105024/225000 (47%)] Loss: 20778.976562\n",
      "Train Epoch: 23 [107520/225000 (48%)] Loss: 20496.351562\n",
      "Train Epoch: 23 [110016/225000 (49%)] Loss: 20803.636719\n",
      "Train Epoch: 23 [112512/225000 (50%)] Loss: 20246.121094\n",
      "Train Epoch: 23 [115008/225000 (51%)] Loss: 21057.117188\n",
      "Train Epoch: 23 [117504/225000 (52%)] Loss: 20180.951172\n",
      "Train Epoch: 23 [120000/225000 (53%)] Loss: 20628.621094\n",
      "Train Epoch: 23 [122496/225000 (54%)] Loss: 20422.154297\n",
      "Train Epoch: 23 [124992/225000 (56%)] Loss: 20237.628906\n",
      "Train Epoch: 23 [127488/225000 (57%)] Loss: 20509.210938\n",
      "Train Epoch: 23 [129984/225000 (58%)] Loss: 20395.332031\n",
      "Train Epoch: 23 [132480/225000 (59%)] Loss: 20733.980469\n",
      "Train Epoch: 23 [134976/225000 (60%)] Loss: 20273.328125\n",
      "Train Epoch: 23 [137472/225000 (61%)] Loss: 20564.128906\n",
      "Train Epoch: 23 [139968/225000 (62%)] Loss: 20627.388672\n",
      "Train Epoch: 23 [142464/225000 (63%)] Loss: 20412.576172\n",
      "Train Epoch: 23 [144960/225000 (64%)] Loss: 20355.414062\n",
      "Train Epoch: 23 [147456/225000 (66%)] Loss: 19920.031250\n",
      "Train Epoch: 23 [149952/225000 (67%)] Loss: 20404.566406\n",
      "Train Epoch: 23 [152448/225000 (68%)] Loss: 20547.519531\n",
      "Train Epoch: 23 [154944/225000 (69%)] Loss: 20736.667969\n",
      "Train Epoch: 23 [157440/225000 (70%)] Loss: 20117.511719\n",
      "Train Epoch: 23 [159936/225000 (71%)] Loss: 20478.226562\n",
      "Train Epoch: 23 [162432/225000 (72%)] Loss: 19815.134766\n",
      "Train Epoch: 23 [164928/225000 (73%)] Loss: 20636.269531\n",
      "Train Epoch: 23 [167424/225000 (74%)] Loss: 20328.335938\n",
      "Train Epoch: 23 [169920/225000 (76%)] Loss: 20491.580078\n",
      "Train Epoch: 23 [172416/225000 (77%)] Loss: 20440.906250\n",
      "Train Epoch: 23 [174912/225000 (78%)] Loss: 19934.656250\n",
      "Train Epoch: 23 [177408/225000 (79%)] Loss: 20483.644531\n",
      "Train Epoch: 23 [179904/225000 (80%)] Loss: 20425.503906\n",
      "Train Epoch: 23 [182400/225000 (81%)] Loss: 20062.449219\n",
      "Train Epoch: 23 [184896/225000 (82%)] Loss: 20220.589844\n",
      "Train Epoch: 23 [187392/225000 (83%)] Loss: 20550.283203\n",
      "Train Epoch: 23 [189888/225000 (84%)] Loss: 20154.470703\n",
      "Train Epoch: 23 [192384/225000 (86%)] Loss: 20373.011719\n",
      "Train Epoch: 23 [194880/225000 (87%)] Loss: 20871.582031\n",
      "Train Epoch: 23 [197376/225000 (88%)] Loss: 20290.771484\n",
      "Train Epoch: 23 [199872/225000 (89%)] Loss: 20111.621094\n",
      "Train Epoch: 23 [202368/225000 (90%)] Loss: 20394.890625\n",
      "Train Epoch: 23 [204864/225000 (91%)] Loss: 20721.966797\n",
      "Train Epoch: 23 [207360/225000 (92%)] Loss: 20068.451172\n",
      "Train Epoch: 23 [209856/225000 (93%)] Loss: 20165.140625\n",
      "Train Epoch: 23 [212352/225000 (94%)] Loss: 20472.736328\n",
      "Train Epoch: 23 [214848/225000 (95%)] Loss: 20253.386719\n",
      "Train Epoch: 23 [217344/225000 (97%)] Loss: 20572.644531\n",
      "Train Epoch: 23 [219840/225000 (98%)] Loss: 20367.171875\n",
      "Train Epoch: 23 [222336/225000 (99%)] Loss: 20625.550781\n",
      "Train Epoch: 23 [224832/225000 (100%)] Loss: 20159.226562\n",
      "    epoch          : 23\n",
      "    loss           : 20428.804765824978\n",
      "    val_loss       : 20316.44812950469\n",
      "Train Epoch: 24 [192/225000 (0%)] Loss: 20266.267578\n",
      "Train Epoch: 24 [2688/225000 (1%)] Loss: 20647.162109\n",
      "Train Epoch: 24 [5184/225000 (2%)] Loss: 20325.628906\n",
      "Train Epoch: 24 [7680/225000 (3%)] Loss: 20472.480469\n",
      "Train Epoch: 24 [10176/225000 (5%)] Loss: 20766.062500\n",
      "Train Epoch: 24 [12672/225000 (6%)] Loss: 20433.386719\n",
      "Train Epoch: 24 [15168/225000 (7%)] Loss: 20240.492188\n",
      "Train Epoch: 24 [17664/225000 (8%)] Loss: 20131.779297\n",
      "Train Epoch: 24 [20160/225000 (9%)] Loss: 19877.515625\n",
      "Train Epoch: 24 [22656/225000 (10%)] Loss: 20606.730469\n",
      "Train Epoch: 24 [25152/225000 (11%)] Loss: 20271.707031\n",
      "Train Epoch: 24 [27648/225000 (12%)] Loss: 20234.447266\n",
      "Train Epoch: 24 [30144/225000 (13%)] Loss: 19633.460938\n",
      "Train Epoch: 24 [32640/225000 (15%)] Loss: 20629.515625\n",
      "Train Epoch: 24 [35136/225000 (16%)] Loss: 20513.031250\n",
      "Train Epoch: 24 [37632/225000 (17%)] Loss: 20390.328125\n",
      "Train Epoch: 24 [40128/225000 (18%)] Loss: 20689.800781\n",
      "Train Epoch: 24 [42624/225000 (19%)] Loss: 20769.095703\n",
      "Train Epoch: 24 [45120/225000 (20%)] Loss: 20172.789062\n",
      "Train Epoch: 24 [47616/225000 (21%)] Loss: 20318.671875\n",
      "Train Epoch: 24 [50112/225000 (22%)] Loss: 20648.595703\n",
      "Train Epoch: 24 [52608/225000 (23%)] Loss: 20341.710938\n",
      "Train Epoch: 24 [55104/225000 (24%)] Loss: 20671.281250\n",
      "Train Epoch: 24 [57600/225000 (26%)] Loss: 20802.765625\n",
      "Train Epoch: 24 [60096/225000 (27%)] Loss: 20743.554688\n",
      "Train Epoch: 24 [62592/225000 (28%)] Loss: 20378.195312\n",
      "Train Epoch: 24 [65088/225000 (29%)] Loss: 20613.173828\n",
      "Train Epoch: 24 [67584/225000 (30%)] Loss: 20459.099609\n",
      "Train Epoch: 24 [70080/225000 (31%)] Loss: 20429.048828\n",
      "Train Epoch: 24 [72576/225000 (32%)] Loss: 20288.851562\n",
      "Train Epoch: 24 [75072/225000 (33%)] Loss: 20249.705078\n",
      "Train Epoch: 24 [77568/225000 (34%)] Loss: 20480.769531\n",
      "Train Epoch: 24 [80064/225000 (36%)] Loss: 20644.515625\n",
      "Train Epoch: 24 [82560/225000 (37%)] Loss: 20145.265625\n",
      "Train Epoch: 24 [85056/225000 (38%)] Loss: 20849.650391\n",
      "Train Epoch: 24 [87552/225000 (39%)] Loss: 20535.400391\n",
      "Train Epoch: 24 [90048/225000 (40%)] Loss: 20505.935547\n",
      "Train Epoch: 24 [92544/225000 (41%)] Loss: 20530.417969\n",
      "Train Epoch: 24 [95040/225000 (42%)] Loss: 20037.931641\n",
      "Train Epoch: 24 [97536/225000 (43%)] Loss: 20379.550781\n",
      "Train Epoch: 24 [100032/225000 (44%)] Loss: 20232.050781\n",
      "Train Epoch: 24 [102528/225000 (46%)] Loss: 20649.234375\n",
      "Train Epoch: 24 [105024/225000 (47%)] Loss: 20346.388672\n",
      "Train Epoch: 24 [107520/225000 (48%)] Loss: 20222.814453\n",
      "Train Epoch: 24 [110016/225000 (49%)] Loss: 20510.937500\n",
      "Train Epoch: 24 [112512/225000 (50%)] Loss: 20569.808594\n",
      "Train Epoch: 24 [115008/225000 (51%)] Loss: 20665.238281\n",
      "Train Epoch: 24 [117504/225000 (52%)] Loss: 20438.753906\n",
      "Train Epoch: 24 [120000/225000 (53%)] Loss: 20219.710938\n",
      "Train Epoch: 24 [122496/225000 (54%)] Loss: 20367.457031\n",
      "Train Epoch: 24 [124992/225000 (56%)] Loss: 20757.511719\n",
      "Train Epoch: 24 [127488/225000 (57%)] Loss: 20068.408203\n",
      "Train Epoch: 24 [129984/225000 (58%)] Loss: 20105.410156\n",
      "Train Epoch: 24 [132480/225000 (59%)] Loss: 20077.400391\n",
      "Train Epoch: 24 [134976/225000 (60%)] Loss: 20123.753906\n",
      "Train Epoch: 24 [137472/225000 (61%)] Loss: 20374.582031\n",
      "Train Epoch: 24 [139968/225000 (62%)] Loss: 20382.972656\n",
      "Train Epoch: 24 [142464/225000 (63%)] Loss: 20237.191406\n",
      "Train Epoch: 24 [144960/225000 (64%)] Loss: 20249.917969\n",
      "Train Epoch: 24 [147456/225000 (66%)] Loss: 20434.548828\n",
      "Train Epoch: 24 [149952/225000 (67%)] Loss: 20363.341797\n",
      "Train Epoch: 24 [152448/225000 (68%)] Loss: 20747.271484\n",
      "Train Epoch: 24 [154944/225000 (69%)] Loss: 20688.796875\n",
      "Train Epoch: 24 [157440/225000 (70%)] Loss: 19794.890625\n",
      "Train Epoch: 24 [159936/225000 (71%)] Loss: 20195.681641\n",
      "Train Epoch: 24 [162432/225000 (72%)] Loss: 20836.337891\n",
      "Train Epoch: 24 [164928/225000 (73%)] Loss: 20361.746094\n",
      "Train Epoch: 24 [167424/225000 (74%)] Loss: 20157.664062\n",
      "Train Epoch: 24 [169920/225000 (76%)] Loss: 20205.910156\n",
      "Train Epoch: 24 [172416/225000 (77%)] Loss: 20569.496094\n",
      "Train Epoch: 24 [174912/225000 (78%)] Loss: 19872.308594\n",
      "Train Epoch: 24 [177408/225000 (79%)] Loss: 20278.597656\n",
      "Train Epoch: 24 [179904/225000 (80%)] Loss: 20702.597656\n",
      "Train Epoch: 24 [182400/225000 (81%)] Loss: 19860.562500\n",
      "Train Epoch: 24 [184896/225000 (82%)] Loss: 20875.351562\n",
      "Train Epoch: 24 [187392/225000 (83%)] Loss: 19855.109375\n",
      "Train Epoch: 24 [189888/225000 (84%)] Loss: 20283.683594\n",
      "Train Epoch: 24 [192384/225000 (86%)] Loss: 20617.931641\n",
      "Train Epoch: 24 [194880/225000 (87%)] Loss: 20837.351562\n",
      "Train Epoch: 24 [197376/225000 (88%)] Loss: 20147.593750\n",
      "Train Epoch: 24 [199872/225000 (89%)] Loss: 20122.140625\n",
      "Train Epoch: 24 [202368/225000 (90%)] Loss: 19623.558594\n",
      "Train Epoch: 24 [204864/225000 (91%)] Loss: 20354.763672\n",
      "Train Epoch: 24 [207360/225000 (92%)] Loss: 20285.480469\n",
      "Train Epoch: 24 [209856/225000 (93%)] Loss: 20287.414062\n",
      "Train Epoch: 24 [212352/225000 (94%)] Loss: 20750.916016\n",
      "Train Epoch: 24 [214848/225000 (95%)] Loss: 20268.562500\n",
      "Train Epoch: 24 [217344/225000 (97%)] Loss: 19972.050781\n",
      "Train Epoch: 24 [219840/225000 (98%)] Loss: 20671.925781\n",
      "Train Epoch: 24 [222336/225000 (99%)] Loss: 20248.039062\n",
      "Train Epoch: 24 [224832/225000 (100%)] Loss: 20155.988281\n",
      "    epoch          : 24\n",
      "    loss           : 20401.4365834311\n",
      "    val_loss       : 20299.083942032954\n",
      "Train Epoch: 25 [192/225000 (0%)] Loss: 20493.433594\n",
      "Train Epoch: 25 [2688/225000 (1%)] Loss: 20394.107422\n",
      "Train Epoch: 25 [5184/225000 (2%)] Loss: 20438.175781\n",
      "Train Epoch: 25 [7680/225000 (3%)] Loss: 20112.242188\n",
      "Train Epoch: 25 [10176/225000 (5%)] Loss: 20281.601562\n",
      "Train Epoch: 25 [12672/225000 (6%)] Loss: 19651.476562\n",
      "Train Epoch: 25 [15168/225000 (7%)] Loss: 20226.312500\n",
      "Train Epoch: 25 [17664/225000 (8%)] Loss: 21039.054688\n",
      "Train Epoch: 25 [20160/225000 (9%)] Loss: 20533.324219\n",
      "Train Epoch: 25 [22656/225000 (10%)] Loss: 19762.339844\n",
      "Train Epoch: 25 [25152/225000 (11%)] Loss: 20837.472656\n",
      "Train Epoch: 25 [27648/225000 (12%)] Loss: 20578.871094\n",
      "Train Epoch: 25 [30144/225000 (13%)] Loss: 19968.898438\n",
      "Train Epoch: 25 [32640/225000 (15%)] Loss: 20505.042969\n",
      "Train Epoch: 25 [35136/225000 (16%)] Loss: 19974.398438\n",
      "Train Epoch: 25 [37632/225000 (17%)] Loss: 20549.085938\n",
      "Train Epoch: 25 [40128/225000 (18%)] Loss: 20737.681641\n",
      "Train Epoch: 25 [42624/225000 (19%)] Loss: 20163.345703\n",
      "Train Epoch: 25 [45120/225000 (20%)] Loss: 20396.964844\n",
      "Train Epoch: 25 [47616/225000 (21%)] Loss: 20390.539062\n",
      "Train Epoch: 25 [50112/225000 (22%)] Loss: 20417.080078\n",
      "Train Epoch: 25 [52608/225000 (23%)] Loss: 20356.546875\n",
      "Train Epoch: 25 [55104/225000 (24%)] Loss: 20384.753906\n",
      "Train Epoch: 25 [57600/225000 (26%)] Loss: 20988.181641\n",
      "Train Epoch: 25 [60096/225000 (27%)] Loss: 20860.085938\n",
      "Train Epoch: 25 [62592/225000 (28%)] Loss: 20998.376953\n",
      "Train Epoch: 25 [65088/225000 (29%)] Loss: 20248.353516\n",
      "Train Epoch: 25 [67584/225000 (30%)] Loss: 20472.812500\n",
      "Train Epoch: 25 [70080/225000 (31%)] Loss: 20301.648438\n",
      "Train Epoch: 25 [72576/225000 (32%)] Loss: 20309.781250\n",
      "Train Epoch: 25 [75072/225000 (33%)] Loss: 20480.859375\n",
      "Train Epoch: 25 [77568/225000 (34%)] Loss: 20159.396484\n",
      "Train Epoch: 25 [80064/225000 (36%)] Loss: 20090.714844\n",
      "Train Epoch: 25 [82560/225000 (37%)] Loss: 20274.779297\n",
      "Train Epoch: 25 [85056/225000 (38%)] Loss: 20214.396484\n",
      "Train Epoch: 25 [87552/225000 (39%)] Loss: 20667.031250\n",
      "Train Epoch: 25 [90048/225000 (40%)] Loss: 20437.400391\n",
      "Train Epoch: 25 [92544/225000 (41%)] Loss: 19992.066406\n",
      "Train Epoch: 25 [95040/225000 (42%)] Loss: 20135.261719\n",
      "Train Epoch: 25 [97536/225000 (43%)] Loss: 20821.433594\n",
      "Train Epoch: 25 [100032/225000 (44%)] Loss: 20338.785156\n",
      "Train Epoch: 25 [102528/225000 (46%)] Loss: 20729.320312\n",
      "Train Epoch: 25 [105024/225000 (47%)] Loss: 20351.296875\n",
      "Train Epoch: 25 [107520/225000 (48%)] Loss: 20269.078125\n",
      "Train Epoch: 25 [110016/225000 (49%)] Loss: 20290.496094\n",
      "Train Epoch: 25 [112512/225000 (50%)] Loss: 19882.587891\n",
      "Train Epoch: 25 [115008/225000 (51%)] Loss: 20459.679688\n",
      "Train Epoch: 25 [117504/225000 (52%)] Loss: 20309.386719\n",
      "Train Epoch: 25 [120000/225000 (53%)] Loss: 20036.753906\n",
      "Train Epoch: 25 [122496/225000 (54%)] Loss: 20666.105469\n",
      "Train Epoch: 25 [124992/225000 (56%)] Loss: 19831.732422\n",
      "Train Epoch: 25 [127488/225000 (57%)] Loss: 20289.023438\n",
      "Train Epoch: 25 [129984/225000 (58%)] Loss: 20260.423828\n",
      "Train Epoch: 25 [132480/225000 (59%)] Loss: 20294.576172\n",
      "Train Epoch: 25 [134976/225000 (60%)] Loss: 20193.378906\n",
      "Train Epoch: 25 [137472/225000 (61%)] Loss: 20705.177734\n",
      "Train Epoch: 25 [139968/225000 (62%)] Loss: 20204.406250\n",
      "Train Epoch: 25 [142464/225000 (63%)] Loss: 20373.869141\n",
      "Train Epoch: 25 [144960/225000 (64%)] Loss: 20254.857422\n",
      "Train Epoch: 25 [147456/225000 (66%)] Loss: 20773.835938\n",
      "Train Epoch: 25 [149952/225000 (67%)] Loss: 19871.792969\n",
      "Train Epoch: 25 [152448/225000 (68%)] Loss: 20324.140625\n",
      "Train Epoch: 25 [154944/225000 (69%)] Loss: 20593.835938\n",
      "Train Epoch: 25 [157440/225000 (70%)] Loss: 20033.699219\n",
      "Train Epoch: 25 [159936/225000 (71%)] Loss: 20673.507812\n",
      "Train Epoch: 25 [162432/225000 (72%)] Loss: 20341.761719\n",
      "Train Epoch: 25 [164928/225000 (73%)] Loss: 19989.257812\n",
      "Train Epoch: 25 [167424/225000 (74%)] Loss: 20305.769531\n",
      "Train Epoch: 25 [169920/225000 (76%)] Loss: 20319.703125\n",
      "Train Epoch: 25 [172416/225000 (77%)] Loss: 20427.187500\n",
      "Train Epoch: 25 [174912/225000 (78%)] Loss: 20034.015625\n",
      "Train Epoch: 25 [177408/225000 (79%)] Loss: 20492.507812\n",
      "Train Epoch: 25 [179904/225000 (80%)] Loss: 20438.109375\n",
      "Train Epoch: 25 [182400/225000 (81%)] Loss: 20473.761719\n",
      "Train Epoch: 25 [184896/225000 (82%)] Loss: 20219.785156\n",
      "Train Epoch: 25 [187392/225000 (83%)] Loss: 20232.597656\n",
      "Train Epoch: 25 [189888/225000 (84%)] Loss: 21107.386719\n",
      "Train Epoch: 25 [192384/225000 (86%)] Loss: 20495.974609\n",
      "Train Epoch: 25 [194880/225000 (87%)] Loss: 20547.550781\n",
      "Train Epoch: 25 [197376/225000 (88%)] Loss: 20600.017578\n",
      "Train Epoch: 25 [199872/225000 (89%)] Loss: 20724.865234\n",
      "Train Epoch: 25 [202368/225000 (90%)] Loss: 20950.273438\n",
      "Train Epoch: 25 [204864/225000 (91%)] Loss: 20570.337891\n",
      "Train Epoch: 25 [207360/225000 (92%)] Loss: 20634.746094\n",
      "Train Epoch: 25 [209856/225000 (93%)] Loss: 20369.636719\n",
      "Train Epoch: 25 [212352/225000 (94%)] Loss: 20784.367188\n",
      "Train Epoch: 25 [214848/225000 (95%)] Loss: 20649.781250\n",
      "Train Epoch: 25 [217344/225000 (97%)] Loss: 20467.787109\n",
      "Train Epoch: 25 [219840/225000 (98%)] Loss: 20616.433594\n",
      "Train Epoch: 25 [222336/225000 (99%)] Loss: 20235.246094\n",
      "Train Epoch: 25 [224832/225000 (100%)] Loss: 20539.988281\n",
      "    epoch          : 25\n",
      "    loss           : 20428.28915082391\n",
      "    val_loss       : 20289.354559149906\n",
      "Train Epoch: 26 [192/225000 (0%)] Loss: 20907.417969\n",
      "Train Epoch: 26 [2688/225000 (1%)] Loss: 20236.261719\n",
      "Train Epoch: 26 [5184/225000 (2%)] Loss: 20990.113281\n",
      "Train Epoch: 26 [7680/225000 (3%)] Loss: 20522.548828\n",
      "Train Epoch: 26 [10176/225000 (5%)] Loss: 20540.789062\n",
      "Train Epoch: 26 [12672/225000 (6%)] Loss: 20261.578125\n",
      "Train Epoch: 26 [15168/225000 (7%)] Loss: 20692.886719\n",
      "Train Epoch: 26 [17664/225000 (8%)] Loss: 20397.750000\n",
      "Train Epoch: 26 [20160/225000 (9%)] Loss: 20237.324219\n",
      "Train Epoch: 26 [22656/225000 (10%)] Loss: 20116.638672\n",
      "Train Epoch: 26 [25152/225000 (11%)] Loss: 20737.935547\n",
      "Train Epoch: 26 [27648/225000 (12%)] Loss: 20516.736328\n",
      "Train Epoch: 26 [30144/225000 (13%)] Loss: 19922.574219\n",
      "Train Epoch: 26 [32640/225000 (15%)] Loss: 19899.968750\n",
      "Train Epoch: 26 [35136/225000 (16%)] Loss: 20163.298828\n",
      "Train Epoch: 26 [37632/225000 (17%)] Loss: 20858.519531\n",
      "Train Epoch: 26 [40128/225000 (18%)] Loss: 20543.103516\n",
      "Train Epoch: 26 [42624/225000 (19%)] Loss: 20547.300781\n",
      "Train Epoch: 26 [45120/225000 (20%)] Loss: 20790.742188\n",
      "Train Epoch: 26 [47616/225000 (21%)] Loss: 20455.671875\n",
      "Train Epoch: 26 [50112/225000 (22%)] Loss: 20685.500000\n",
      "Train Epoch: 26 [52608/225000 (23%)] Loss: 20620.193359\n",
      "Train Epoch: 26 [55104/225000 (24%)] Loss: 20025.208984\n",
      "Train Epoch: 26 [57600/225000 (26%)] Loss: 20214.843750\n",
      "Train Epoch: 26 [60096/225000 (27%)] Loss: 20029.707031\n",
      "Train Epoch: 26 [62592/225000 (28%)] Loss: 20958.343750\n",
      "Train Epoch: 26 [65088/225000 (29%)] Loss: 20479.472656\n",
      "Train Epoch: 26 [67584/225000 (30%)] Loss: 20399.957031\n",
      "Train Epoch: 26 [70080/225000 (31%)] Loss: 20346.621094\n",
      "Train Epoch: 26 [72576/225000 (32%)] Loss: 20414.773438\n",
      "Train Epoch: 26 [75072/225000 (33%)] Loss: 20680.085938\n",
      "Train Epoch: 26 [77568/225000 (34%)] Loss: 20120.246094\n",
      "Train Epoch: 26 [80064/225000 (36%)] Loss: 20224.027344\n",
      "Train Epoch: 26 [82560/225000 (37%)] Loss: 20612.441406\n",
      "Train Epoch: 26 [85056/225000 (38%)] Loss: 20459.402344\n",
      "Train Epoch: 26 [87552/225000 (39%)] Loss: 20263.097656\n",
      "Train Epoch: 26 [90048/225000 (40%)] Loss: 20183.392578\n",
      "Train Epoch: 26 [92544/225000 (41%)] Loss: 20125.042969\n",
      "Train Epoch: 26 [95040/225000 (42%)] Loss: 20377.683594\n",
      "Train Epoch: 26 [97536/225000 (43%)] Loss: 20714.912109\n",
      "Train Epoch: 26 [100032/225000 (44%)] Loss: 20347.626953\n",
      "Train Epoch: 26 [102528/225000 (46%)] Loss: 20362.355469\n",
      "Train Epoch: 26 [105024/225000 (47%)] Loss: 20242.671875\n",
      "Train Epoch: 26 [107520/225000 (48%)] Loss: 20513.878906\n",
      "Train Epoch: 26 [110016/225000 (49%)] Loss: 20197.384766\n",
      "Train Epoch: 26 [112512/225000 (50%)] Loss: 20494.642578\n",
      "Train Epoch: 26 [115008/225000 (51%)] Loss: 20097.121094\n",
      "Train Epoch: 26 [117504/225000 (52%)] Loss: 20512.750000\n",
      "Train Epoch: 26 [120000/225000 (53%)] Loss: 20611.156250\n",
      "Train Epoch: 26 [122496/225000 (54%)] Loss: 20554.949219\n",
      "Train Epoch: 26 [124992/225000 (56%)] Loss: 20297.226562\n",
      "Train Epoch: 26 [127488/225000 (57%)] Loss: 20684.691406\n",
      "Train Epoch: 26 [129984/225000 (58%)] Loss: 20632.816406\n",
      "Train Epoch: 26 [132480/225000 (59%)] Loss: 19894.531250\n",
      "Train Epoch: 26 [134976/225000 (60%)] Loss: 20574.218750\n",
      "Train Epoch: 26 [137472/225000 (61%)] Loss: 20628.875000\n",
      "Train Epoch: 26 [139968/225000 (62%)] Loss: 20301.945312\n",
      "Train Epoch: 26 [142464/225000 (63%)] Loss: 20031.476562\n",
      "Train Epoch: 26 [144960/225000 (64%)] Loss: 20497.732422\n",
      "Train Epoch: 26 [147456/225000 (66%)] Loss: 20762.767578\n",
      "Train Epoch: 26 [149952/225000 (67%)] Loss: 20670.505859\n",
      "Train Epoch: 26 [152448/225000 (68%)] Loss: 20233.046875\n",
      "Train Epoch: 26 [154944/225000 (69%)] Loss: 20449.880859\n",
      "Train Epoch: 26 [157440/225000 (70%)] Loss: 20403.142578\n",
      "Train Epoch: 26 [159936/225000 (71%)] Loss: 19985.119141\n",
      "Train Epoch: 26 [162432/225000 (72%)] Loss: 20652.457031\n",
      "Train Epoch: 26 [164928/225000 (73%)] Loss: 20181.699219\n",
      "Train Epoch: 26 [167424/225000 (74%)] Loss: 20158.603516\n",
      "Train Epoch: 26 [169920/225000 (76%)] Loss: 20405.757812\n",
      "Train Epoch: 26 [172416/225000 (77%)] Loss: 20007.277344\n",
      "Train Epoch: 26 [174912/225000 (78%)] Loss: 19898.755859\n",
      "Train Epoch: 26 [177408/225000 (79%)] Loss: 20128.937500\n",
      "Train Epoch: 26 [179904/225000 (80%)] Loss: 20367.869141\n",
      "Train Epoch: 26 [182400/225000 (81%)] Loss: 20241.324219\n",
      "Train Epoch: 26 [184896/225000 (82%)] Loss: 21104.179688\n",
      "Train Epoch: 26 [187392/225000 (83%)] Loss: 20690.843750\n",
      "Train Epoch: 26 [189888/225000 (84%)] Loss: 20581.560547\n",
      "Train Epoch: 26 [192384/225000 (86%)] Loss: 20400.837891\n",
      "Train Epoch: 26 [194880/225000 (87%)] Loss: 20060.748047\n",
      "Train Epoch: 26 [197376/225000 (88%)] Loss: 19992.939453\n",
      "Train Epoch: 26 [199872/225000 (89%)] Loss: 20411.033203\n",
      "Train Epoch: 26 [202368/225000 (90%)] Loss: 19953.117188\n",
      "Train Epoch: 26 [204864/225000 (91%)] Loss: 20426.042969\n",
      "Train Epoch: 26 [207360/225000 (92%)] Loss: 20376.363281\n",
      "Train Epoch: 26 [209856/225000 (93%)] Loss: 20252.583984\n",
      "Train Epoch: 26 [212352/225000 (94%)] Loss: 20323.785156\n",
      "Train Epoch: 26 [214848/225000 (95%)] Loss: 20709.386719\n",
      "Train Epoch: 26 [217344/225000 (97%)] Loss: 20261.269531\n",
      "Train Epoch: 26 [219840/225000 (98%)] Loss: 20201.195312\n",
      "Train Epoch: 26 [222336/225000 (99%)] Loss: 20270.568359\n",
      "Train Epoch: 26 [224832/225000 (100%)] Loss: 20777.015625\n",
      "    epoch          : 26\n",
      "    loss           : 20385.178392638118\n",
      "    val_loss       : 20276.094029752352\n",
      "Train Epoch: 27 [192/225000 (0%)] Loss: 20299.074219\n",
      "Train Epoch: 27 [2688/225000 (1%)] Loss: 19831.636719\n",
      "Train Epoch: 27 [5184/225000 (2%)] Loss: 20230.427734\n",
      "Train Epoch: 27 [7680/225000 (3%)] Loss: 20750.445312\n",
      "Train Epoch: 27 [10176/225000 (5%)] Loss: 20217.671875\n",
      "Train Epoch: 27 [12672/225000 (6%)] Loss: 20212.050781\n",
      "Train Epoch: 27 [15168/225000 (7%)] Loss: 20255.781250\n",
      "Train Epoch: 27 [17664/225000 (8%)] Loss: 20695.574219\n",
      "Train Epoch: 27 [20160/225000 (9%)] Loss: 20271.974609\n",
      "Train Epoch: 27 [22656/225000 (10%)] Loss: 20391.441406\n",
      "Train Epoch: 27 [25152/225000 (11%)] Loss: 20633.316406\n",
      "Train Epoch: 27 [27648/225000 (12%)] Loss: 20368.160156\n",
      "Train Epoch: 27 [30144/225000 (13%)] Loss: 20136.792969\n",
      "Train Epoch: 27 [32640/225000 (15%)] Loss: 20181.345703\n",
      "Train Epoch: 27 [35136/225000 (16%)] Loss: 20222.476562\n",
      "Train Epoch: 27 [37632/225000 (17%)] Loss: 20408.234375\n",
      "Train Epoch: 27 [40128/225000 (18%)] Loss: 20154.554688\n",
      "Train Epoch: 27 [42624/225000 (19%)] Loss: 20209.187500\n",
      "Train Epoch: 27 [45120/225000 (20%)] Loss: 20599.882812\n",
      "Train Epoch: 27 [47616/225000 (21%)] Loss: 20190.316406\n",
      "Train Epoch: 27 [50112/225000 (22%)] Loss: 20435.757812\n",
      "Train Epoch: 27 [52608/225000 (23%)] Loss: 20621.730469\n",
      "Train Epoch: 27 [55104/225000 (24%)] Loss: 19913.744141\n",
      "Train Epoch: 27 [57600/225000 (26%)] Loss: 20038.207031\n",
      "Train Epoch: 27 [60096/225000 (27%)] Loss: 20596.757812\n",
      "Train Epoch: 27 [62592/225000 (28%)] Loss: 20545.007812\n",
      "Train Epoch: 27 [65088/225000 (29%)] Loss: 20361.335938\n",
      "Train Epoch: 27 [67584/225000 (30%)] Loss: 20129.718750\n",
      "Train Epoch: 27 [70080/225000 (31%)] Loss: 20551.656250\n",
      "Train Epoch: 27 [72576/225000 (32%)] Loss: 20170.289062\n",
      "Train Epoch: 27 [75072/225000 (33%)] Loss: 20700.664062\n",
      "Train Epoch: 27 [77568/225000 (34%)] Loss: 20339.185547\n",
      "Train Epoch: 27 [80064/225000 (36%)] Loss: 20186.195312\n",
      "Train Epoch: 27 [82560/225000 (37%)] Loss: 20527.582031\n",
      "Train Epoch: 27 [85056/225000 (38%)] Loss: 20846.416016\n",
      "Train Epoch: 27 [87552/225000 (39%)] Loss: 20468.636719\n",
      "Train Epoch: 27 [90048/225000 (40%)] Loss: 20979.238281\n",
      "Train Epoch: 27 [92544/225000 (41%)] Loss: 20132.816406\n",
      "Train Epoch: 27 [95040/225000 (42%)] Loss: 20935.234375\n",
      "Train Epoch: 27 [97536/225000 (43%)] Loss: 20246.468750\n",
      "Train Epoch: 27 [100032/225000 (44%)] Loss: 20253.212891\n",
      "Train Epoch: 27 [102528/225000 (46%)] Loss: 19953.132812\n",
      "Train Epoch: 27 [105024/225000 (47%)] Loss: 20196.037109\n",
      "Train Epoch: 27 [107520/225000 (48%)] Loss: 20315.675781\n",
      "Train Epoch: 27 [110016/225000 (49%)] Loss: 20370.578125\n",
      "Train Epoch: 27 [112512/225000 (50%)] Loss: 20349.535156\n",
      "Train Epoch: 27 [115008/225000 (51%)] Loss: 20070.984375\n",
      "Train Epoch: 27 [117504/225000 (52%)] Loss: 20258.083984\n",
      "Train Epoch: 27 [120000/225000 (53%)] Loss: 20316.808594\n",
      "Train Epoch: 27 [122496/225000 (54%)] Loss: 20599.480469\n",
      "Train Epoch: 27 [124992/225000 (56%)] Loss: 20908.687500\n",
      "Train Epoch: 27 [127488/225000 (57%)] Loss: 20367.125000\n",
      "Train Epoch: 27 [129984/225000 (58%)] Loss: 20779.585938\n",
      "Train Epoch: 27 [132480/225000 (59%)] Loss: 20924.830078\n",
      "Train Epoch: 27 [134976/225000 (60%)] Loss: 20221.714844\n",
      "Train Epoch: 27 [137472/225000 (61%)] Loss: 19644.273438\n",
      "Train Epoch: 27 [139968/225000 (62%)] Loss: 19925.753906\n",
      "Train Epoch: 27 [142464/225000 (63%)] Loss: 20974.960938\n",
      "Train Epoch: 27 [144960/225000 (64%)] Loss: 19895.007812\n",
      "Train Epoch: 27 [147456/225000 (66%)] Loss: 19995.203125\n",
      "Train Epoch: 27 [149952/225000 (67%)] Loss: 20465.271484\n",
      "Train Epoch: 27 [152448/225000 (68%)] Loss: 20145.869141\n",
      "Train Epoch: 27 [154944/225000 (69%)] Loss: 20446.878906\n",
      "Train Epoch: 27 [157440/225000 (70%)] Loss: 19763.800781\n",
      "Train Epoch: 27 [159936/225000 (71%)] Loss: 20093.902344\n",
      "Train Epoch: 27 [162432/225000 (72%)] Loss: 20624.591797\n",
      "Train Epoch: 27 [164928/225000 (73%)] Loss: 20061.156250\n",
      "Train Epoch: 27 [167424/225000 (74%)] Loss: 19889.742188\n",
      "Train Epoch: 27 [169920/225000 (76%)] Loss: 20153.746094\n",
      "Train Epoch: 27 [172416/225000 (77%)] Loss: 20546.550781\n",
      "Train Epoch: 27 [174912/225000 (78%)] Loss: 20138.343750\n",
      "Train Epoch: 27 [177408/225000 (79%)] Loss: 20733.355469\n",
      "Train Epoch: 27 [179904/225000 (80%)] Loss: 20272.320312\n",
      "Train Epoch: 27 [182400/225000 (81%)] Loss: 20664.882812\n",
      "Train Epoch: 27 [184896/225000 (82%)] Loss: 20519.980469\n",
      "Train Epoch: 27 [187392/225000 (83%)] Loss: 20694.722656\n",
      "Train Epoch: 27 [189888/225000 (84%)] Loss: 20128.947266\n",
      "Train Epoch: 27 [192384/225000 (86%)] Loss: 20439.191406\n",
      "Train Epoch: 27 [194880/225000 (87%)] Loss: 20652.769531\n",
      "Train Epoch: 27 [197376/225000 (88%)] Loss: 20331.679688\n",
      "Train Epoch: 27 [199872/225000 (89%)] Loss: 20319.843750\n",
      "Train Epoch: 27 [202368/225000 (90%)] Loss: 20366.916016\n",
      "Train Epoch: 27 [204864/225000 (91%)] Loss: 20473.550781\n",
      "Train Epoch: 27 [207360/225000 (92%)] Loss: 20386.912109\n",
      "Train Epoch: 27 [209856/225000 (93%)] Loss: 20209.349609\n",
      "Train Epoch: 27 [212352/225000 (94%)] Loss: 20392.533203\n",
      "Train Epoch: 27 [214848/225000 (95%)] Loss: 20180.835938\n",
      "Train Epoch: 27 [217344/225000 (97%)] Loss: 20283.109375\n",
      "Train Epoch: 27 [219840/225000 (98%)] Loss: 20387.929688\n",
      "Train Epoch: 27 [222336/225000 (99%)] Loss: 20097.035156\n",
      "Train Epoch: 27 [224832/225000 (100%)] Loss: 20458.132812\n",
      "    epoch          : 27\n",
      "    loss           : 20370.1192006186\n",
      "    val_loss       : 20266.42765058543\n",
      "Train Epoch: 28 [192/225000 (0%)] Loss: 20268.121094\n",
      "Train Epoch: 28 [2688/225000 (1%)] Loss: 20404.662109\n",
      "Train Epoch: 28 [5184/225000 (2%)] Loss: 19799.503906\n",
      "Train Epoch: 28 [7680/225000 (3%)] Loss: 20567.042969\n",
      "Train Epoch: 28 [10176/225000 (5%)] Loss: 20798.792969\n",
      "Train Epoch: 28 [12672/225000 (6%)] Loss: 20630.873047\n",
      "Train Epoch: 28 [15168/225000 (7%)] Loss: 20328.484375\n",
      "Train Epoch: 28 [17664/225000 (8%)] Loss: 20187.925781\n",
      "Train Epoch: 28 [20160/225000 (9%)] Loss: 20297.677734\n",
      "Train Epoch: 28 [22656/225000 (10%)] Loss: 20062.353516\n",
      "Train Epoch: 28 [25152/225000 (11%)] Loss: 20744.007812\n",
      "Train Epoch: 28 [27648/225000 (12%)] Loss: 20573.339844\n",
      "Train Epoch: 28 [30144/225000 (13%)] Loss: 20346.015625\n",
      "Train Epoch: 28 [32640/225000 (15%)] Loss: 20147.578125\n",
      "Train Epoch: 28 [35136/225000 (16%)] Loss: 20279.144531\n",
      "Train Epoch: 28 [37632/225000 (17%)] Loss: 20246.625000\n",
      "Train Epoch: 28 [40128/225000 (18%)] Loss: 20139.089844\n",
      "Train Epoch: 28 [42624/225000 (19%)] Loss: 20519.923828\n",
      "Train Epoch: 28 [45120/225000 (20%)] Loss: 20325.015625\n",
      "Train Epoch: 28 [47616/225000 (21%)] Loss: 21053.396484\n",
      "Train Epoch: 28 [50112/225000 (22%)] Loss: 21007.140625\n",
      "Train Epoch: 28 [52608/225000 (23%)] Loss: 20193.011719\n",
      "Train Epoch: 28 [55104/225000 (24%)] Loss: 20414.529297\n",
      "Train Epoch: 28 [57600/225000 (26%)] Loss: 20383.667969\n",
      "Train Epoch: 28 [60096/225000 (27%)] Loss: 20204.011719\n",
      "Train Epoch: 28 [62592/225000 (28%)] Loss: 20411.771484\n",
      "Train Epoch: 28 [65088/225000 (29%)] Loss: 20737.875000\n",
      "Train Epoch: 28 [67584/225000 (30%)] Loss: 20437.515625\n",
      "Train Epoch: 28 [70080/225000 (31%)] Loss: 20441.617188\n",
      "Train Epoch: 28 [72576/225000 (32%)] Loss: 20874.949219\n",
      "Train Epoch: 28 [75072/225000 (33%)] Loss: 20167.222656\n",
      "Train Epoch: 28 [77568/225000 (34%)] Loss: 20301.857422\n",
      "Train Epoch: 28 [80064/225000 (36%)] Loss: 20266.730469\n",
      "Train Epoch: 28 [82560/225000 (37%)] Loss: 20380.460938\n",
      "Train Epoch: 28 [85056/225000 (38%)] Loss: 20179.988281\n",
      "Train Epoch: 28 [87552/225000 (39%)] Loss: 20236.419922\n",
      "Train Epoch: 28 [90048/225000 (40%)] Loss: 20243.812500\n",
      "Train Epoch: 28 [92544/225000 (41%)] Loss: 20149.695312\n",
      "Train Epoch: 28 [95040/225000 (42%)] Loss: 20845.427734\n",
      "Train Epoch: 28 [97536/225000 (43%)] Loss: 20170.402344\n",
      "Train Epoch: 28 [100032/225000 (44%)] Loss: 20033.642578\n",
      "Train Epoch: 28 [102528/225000 (46%)] Loss: 19921.699219\n",
      "Train Epoch: 28 [105024/225000 (47%)] Loss: 20345.308594\n",
      "Train Epoch: 28 [107520/225000 (48%)] Loss: 20371.093750\n",
      "Train Epoch: 28 [110016/225000 (49%)] Loss: 20157.212891\n",
      "Train Epoch: 28 [112512/225000 (50%)] Loss: 20254.451172\n",
      "Train Epoch: 28 [115008/225000 (51%)] Loss: 20356.083984\n",
      "Train Epoch: 28 [117504/225000 (52%)] Loss: 20726.863281\n",
      "Train Epoch: 28 [120000/225000 (53%)] Loss: 20395.648438\n",
      "Train Epoch: 28 [122496/225000 (54%)] Loss: 20565.988281\n",
      "Train Epoch: 28 [124992/225000 (56%)] Loss: 20242.402344\n",
      "Train Epoch: 28 [127488/225000 (57%)] Loss: 20286.359375\n",
      "Train Epoch: 28 [129984/225000 (58%)] Loss: 21044.277344\n",
      "Train Epoch: 28 [132480/225000 (59%)] Loss: 20160.482422\n",
      "Train Epoch: 28 [134976/225000 (60%)] Loss: 19681.628906\n",
      "Train Epoch: 28 [137472/225000 (61%)] Loss: 20539.138672\n",
      "Train Epoch: 28 [139968/225000 (62%)] Loss: 19944.210938\n",
      "Train Epoch: 28 [142464/225000 (63%)] Loss: 20208.505859\n",
      "Train Epoch: 28 [144960/225000 (64%)] Loss: 19906.804688\n",
      "Train Epoch: 28 [147456/225000 (66%)] Loss: 20457.623047\n",
      "Train Epoch: 28 [149952/225000 (67%)] Loss: 20333.843750\n",
      "Train Epoch: 28 [152448/225000 (68%)] Loss: 20125.638672\n",
      "Train Epoch: 28 [154944/225000 (69%)] Loss: 20053.953125\n",
      "Train Epoch: 28 [157440/225000 (70%)] Loss: 20133.453125\n",
      "Train Epoch: 28 [159936/225000 (71%)] Loss: 21356.449219\n",
      "Train Epoch: 28 [162432/225000 (72%)] Loss: 20258.759766\n",
      "Train Epoch: 28 [164928/225000 (73%)] Loss: 20437.083984\n",
      "Train Epoch: 28 [167424/225000 (74%)] Loss: 20050.449219\n",
      "Train Epoch: 28 [169920/225000 (76%)] Loss: 20057.037109\n",
      "Train Epoch: 28 [172416/225000 (77%)] Loss: 20054.582031\n",
      "Train Epoch: 28 [174912/225000 (78%)] Loss: 20780.578125\n",
      "Train Epoch: 28 [177408/225000 (79%)] Loss: 20167.910156\n",
      "Train Epoch: 28 [179904/225000 (80%)] Loss: 20773.537109\n",
      "Train Epoch: 28 [182400/225000 (81%)] Loss: 19944.742188\n",
      "Train Epoch: 28 [184896/225000 (82%)] Loss: 19830.253906\n",
      "Train Epoch: 28 [187392/225000 (83%)] Loss: 20749.953125\n",
      "Train Epoch: 28 [189888/225000 (84%)] Loss: 20224.894531\n",
      "Train Epoch: 28 [192384/225000 (86%)] Loss: 20434.589844\n",
      "Train Epoch: 28 [194880/225000 (87%)] Loss: 20700.156250\n",
      "Train Epoch: 28 [197376/225000 (88%)] Loss: 20374.779297\n",
      "Train Epoch: 28 [199872/225000 (89%)] Loss: 20271.988281\n",
      "Train Epoch: 28 [202368/225000 (90%)] Loss: 20542.523438\n",
      "Train Epoch: 28 [204864/225000 (91%)] Loss: 20490.046875\n",
      "Train Epoch: 28 [207360/225000 (92%)] Loss: 20069.671875\n",
      "Train Epoch: 28 [209856/225000 (93%)] Loss: 20533.896484\n",
      "Train Epoch: 28 [212352/225000 (94%)] Loss: 20089.843750\n",
      "Train Epoch: 28 [214848/225000 (95%)] Loss: 20275.070312\n",
      "Train Epoch: 28 [217344/225000 (97%)] Loss: 20335.265625\n",
      "Train Epoch: 28 [219840/225000 (98%)] Loss: 20555.779297\n",
      "Train Epoch: 28 [222336/225000 (99%)] Loss: 20299.095703\n",
      "Train Epoch: 28 [224832/225000 (100%)] Loss: 19993.732422\n",
      "    epoch          : 28\n",
      "    loss           : 20368.63845523144\n",
      "    val_loss       : 20346.189747826742\n",
      "Train Epoch: 29 [192/225000 (0%)] Loss: 20267.988281\n",
      "Train Epoch: 29 [2688/225000 (1%)] Loss: 20366.488281\n",
      "Train Epoch: 29 [5184/225000 (2%)] Loss: 20404.052734\n",
      "Train Epoch: 29 [7680/225000 (3%)] Loss: 20110.527344\n",
      "Train Epoch: 29 [10176/225000 (5%)] Loss: 20241.623047\n",
      "Train Epoch: 29 [12672/225000 (6%)] Loss: 20815.962891\n",
      "Train Epoch: 29 [15168/225000 (7%)] Loss: 20438.992188\n",
      "Train Epoch: 29 [17664/225000 (8%)] Loss: 19882.601562\n",
      "Train Epoch: 29 [20160/225000 (9%)] Loss: 20355.859375\n",
      "Train Epoch: 29 [22656/225000 (10%)] Loss: 20246.712891\n",
      "Train Epoch: 29 [25152/225000 (11%)] Loss: 20974.492188\n",
      "Train Epoch: 29 [27648/225000 (12%)] Loss: 20220.554688\n",
      "Train Epoch: 29 [30144/225000 (13%)] Loss: 20204.019531\n",
      "Train Epoch: 29 [32640/225000 (15%)] Loss: 20313.871094\n",
      "Train Epoch: 29 [35136/225000 (16%)] Loss: 20412.191406\n",
      "Train Epoch: 29 [37632/225000 (17%)] Loss: 20294.527344\n",
      "Train Epoch: 29 [40128/225000 (18%)] Loss: 20873.519531\n",
      "Train Epoch: 29 [42624/225000 (19%)] Loss: 20167.804688\n",
      "Train Epoch: 29 [45120/225000 (20%)] Loss: 20467.169922\n",
      "Train Epoch: 29 [47616/225000 (21%)] Loss: 19780.912109\n",
      "Train Epoch: 29 [50112/225000 (22%)] Loss: 20138.753906\n",
      "Train Epoch: 29 [52608/225000 (23%)] Loss: 20425.003906\n",
      "Train Epoch: 29 [55104/225000 (24%)] Loss: 20472.093750\n",
      "Train Epoch: 29 [57600/225000 (26%)] Loss: 19607.326172\n",
      "Train Epoch: 29 [60096/225000 (27%)] Loss: 19765.421875\n",
      "Train Epoch: 29 [62592/225000 (28%)] Loss: 19944.929688\n",
      "Train Epoch: 29 [65088/225000 (29%)] Loss: 19963.169922\n",
      "Train Epoch: 29 [67584/225000 (30%)] Loss: 20496.261719\n",
      "Train Epoch: 29 [70080/225000 (31%)] Loss: 20425.878906\n",
      "Train Epoch: 29 [72576/225000 (32%)] Loss: 20226.513672\n",
      "Train Epoch: 29 [75072/225000 (33%)] Loss: 20320.144531\n",
      "Train Epoch: 29 [77568/225000 (34%)] Loss: 20003.164062\n",
      "Train Epoch: 29 [80064/225000 (36%)] Loss: 20639.396484\n",
      "Train Epoch: 29 [82560/225000 (37%)] Loss: 20283.156250\n",
      "Train Epoch: 29 [85056/225000 (38%)] Loss: 20187.710938\n",
      "Train Epoch: 29 [87552/225000 (39%)] Loss: 20007.677734\n",
      "Train Epoch: 29 [90048/225000 (40%)] Loss: 20667.453125\n",
      "Train Epoch: 29 [92544/225000 (41%)] Loss: 20053.626953\n",
      "Train Epoch: 29 [95040/225000 (42%)] Loss: 20454.539062\n",
      "Train Epoch: 29 [97536/225000 (43%)] Loss: 19888.074219\n",
      "Train Epoch: 29 [100032/225000 (44%)] Loss: 20519.712891\n",
      "Train Epoch: 29 [102528/225000 (46%)] Loss: 20543.679688\n",
      "Train Epoch: 29 [105024/225000 (47%)] Loss: 20392.503906\n",
      "Train Epoch: 29 [107520/225000 (48%)] Loss: 20683.082031\n",
      "Train Epoch: 29 [110016/225000 (49%)] Loss: 20224.712891\n",
      "Train Epoch: 29 [112512/225000 (50%)] Loss: 20790.712891\n",
      "Train Epoch: 29 [115008/225000 (51%)] Loss: 20680.013672\n",
      "Train Epoch: 29 [117504/225000 (52%)] Loss: 20298.394531\n",
      "Train Epoch: 29 [120000/225000 (53%)] Loss: 19741.925781\n",
      "Train Epoch: 29 [122496/225000 (54%)] Loss: 20537.722656\n",
      "Train Epoch: 29 [124992/225000 (56%)] Loss: 20477.621094\n",
      "Train Epoch: 29 [127488/225000 (57%)] Loss: 19872.253906\n",
      "Train Epoch: 29 [129984/225000 (58%)] Loss: 20115.570312\n",
      "Train Epoch: 29 [132480/225000 (59%)] Loss: 20503.203125\n",
      "Train Epoch: 29 [134976/225000 (60%)] Loss: 20496.226562\n",
      "Train Epoch: 29 [137472/225000 (61%)] Loss: 20639.322266\n",
      "Train Epoch: 29 [139968/225000 (62%)] Loss: 20572.109375\n",
      "Train Epoch: 29 [142464/225000 (63%)] Loss: 20571.722656\n",
      "Train Epoch: 29 [144960/225000 (64%)] Loss: 19958.367188\n",
      "Train Epoch: 29 [147456/225000 (66%)] Loss: 20677.140625\n",
      "Train Epoch: 29 [149952/225000 (67%)] Loss: 20075.121094\n",
      "Train Epoch: 29 [152448/225000 (68%)] Loss: 20374.294922\n",
      "Train Epoch: 29 [154944/225000 (69%)] Loss: 20008.121094\n",
      "Train Epoch: 29 [157440/225000 (70%)] Loss: 20251.396484\n",
      "Train Epoch: 29 [159936/225000 (71%)] Loss: 20488.886719\n",
      "Train Epoch: 29 [162432/225000 (72%)] Loss: 20877.667969\n",
      "Train Epoch: 29 [164928/225000 (73%)] Loss: 20767.621094\n",
      "Train Epoch: 29 [167424/225000 (74%)] Loss: 20401.613281\n",
      "Train Epoch: 29 [169920/225000 (76%)] Loss: 20524.453125\n",
      "Train Epoch: 29 [172416/225000 (77%)] Loss: 20401.384766\n",
      "Train Epoch: 29 [174912/225000 (78%)] Loss: 20365.732422\n",
      "Train Epoch: 29 [177408/225000 (79%)] Loss: 20349.304688\n",
      "Train Epoch: 29 [179904/225000 (80%)] Loss: 20648.488281\n",
      "Train Epoch: 29 [182400/225000 (81%)] Loss: 20575.492188\n",
      "Train Epoch: 29 [184896/225000 (82%)] Loss: 20543.566406\n",
      "Train Epoch: 29 [187392/225000 (83%)] Loss: 20401.994141\n",
      "Train Epoch: 29 [189888/225000 (84%)] Loss: 20202.382812\n",
      "Train Epoch: 29 [192384/225000 (86%)] Loss: 20732.777344\n",
      "Train Epoch: 29 [194880/225000 (87%)] Loss: 20244.142578\n",
      "Train Epoch: 29 [197376/225000 (88%)] Loss: 20265.242188\n",
      "Train Epoch: 29 [199872/225000 (89%)] Loss: 20375.392578\n",
      "Train Epoch: 29 [202368/225000 (90%)] Loss: 20266.406250\n",
      "Train Epoch: 29 [204864/225000 (91%)] Loss: 20471.441406\n",
      "Train Epoch: 29 [207360/225000 (92%)] Loss: 20150.728516\n",
      "Train Epoch: 29 [209856/225000 (93%)] Loss: 20069.750000\n",
      "Train Epoch: 29 [212352/225000 (94%)] Loss: 20364.457031\n",
      "Train Epoch: 29 [214848/225000 (95%)] Loss: 20033.882812\n",
      "Train Epoch: 29 [217344/225000 (97%)] Loss: 20227.273438\n",
      "Train Epoch: 29 [219840/225000 (98%)] Loss: 20180.908203\n",
      "Train Epoch: 29 [222336/225000 (99%)] Loss: 20034.687500\n",
      "Train Epoch: 29 [224832/225000 (100%)] Loss: 19847.746094\n",
      "    epoch          : 29\n",
      "    loss           : 20355.024442392812\n",
      "    val_loss       : 20245.045007535973\n",
      "Train Epoch: 30 [192/225000 (0%)] Loss: 19981.513672\n",
      "Train Epoch: 30 [2688/225000 (1%)] Loss: 20643.281250\n",
      "Train Epoch: 30 [5184/225000 (2%)] Loss: 20646.544922\n",
      "Train Epoch: 30 [7680/225000 (3%)] Loss: 20070.433594\n",
      "Train Epoch: 30 [10176/225000 (5%)] Loss: 19918.285156\n",
      "Train Epoch: 30 [12672/225000 (6%)] Loss: 20445.222656\n",
      "Train Epoch: 30 [15168/225000 (7%)] Loss: 20298.791016\n",
      "Train Epoch: 30 [17664/225000 (8%)] Loss: 20045.265625\n",
      "Train Epoch: 30 [20160/225000 (9%)] Loss: 20308.375000\n",
      "Train Epoch: 30 [22656/225000 (10%)] Loss: 20287.658203\n",
      "Train Epoch: 30 [25152/225000 (11%)] Loss: 20203.314453\n",
      "Train Epoch: 30 [27648/225000 (12%)] Loss: 20395.308594\n",
      "Train Epoch: 30 [30144/225000 (13%)] Loss: 20283.578125\n",
      "Train Epoch: 30 [32640/225000 (15%)] Loss: 20063.343750\n",
      "Train Epoch: 30 [35136/225000 (16%)] Loss: 20096.939453\n",
      "Train Epoch: 30 [37632/225000 (17%)] Loss: 20134.572266\n",
      "Train Epoch: 30 [40128/225000 (18%)] Loss: 20508.183594\n",
      "Train Epoch: 30 [42624/225000 (19%)] Loss: 20514.992188\n",
      "Train Epoch: 30 [45120/225000 (20%)] Loss: 21280.826172\n",
      "Train Epoch: 30 [47616/225000 (21%)] Loss: 20770.902344\n",
      "Train Epoch: 30 [50112/225000 (22%)] Loss: 20032.087891\n",
      "Train Epoch: 30 [52608/225000 (23%)] Loss: 20117.585938\n",
      "Train Epoch: 30 [55104/225000 (24%)] Loss: 20249.332031\n",
      "Train Epoch: 30 [57600/225000 (26%)] Loss: 20428.142578\n",
      "Train Epoch: 30 [60096/225000 (27%)] Loss: 19875.097656\n",
      "Train Epoch: 30 [62592/225000 (28%)] Loss: 21014.308594\n",
      "Train Epoch: 30 [65088/225000 (29%)] Loss: 20656.808594\n",
      "Train Epoch: 30 [67584/225000 (30%)] Loss: 20612.414062\n",
      "Train Epoch: 30 [70080/225000 (31%)] Loss: 20085.785156\n",
      "Train Epoch: 30 [72576/225000 (32%)] Loss: 20035.953125\n",
      "Train Epoch: 30 [75072/225000 (33%)] Loss: 20604.244141\n",
      "Train Epoch: 30 [77568/225000 (34%)] Loss: 20604.076172\n",
      "Train Epoch: 30 [80064/225000 (36%)] Loss: 20106.023438\n",
      "Train Epoch: 30 [82560/225000 (37%)] Loss: 20521.691406\n",
      "Train Epoch: 30 [85056/225000 (38%)] Loss: 20527.787109\n",
      "Train Epoch: 30 [87552/225000 (39%)] Loss: 19991.851562\n",
      "Train Epoch: 30 [90048/225000 (40%)] Loss: 20359.207031\n",
      "Train Epoch: 30 [92544/225000 (41%)] Loss: 20085.375000\n",
      "Train Epoch: 30 [95040/225000 (42%)] Loss: 20125.074219\n",
      "Train Epoch: 30 [97536/225000 (43%)] Loss: 20371.980469\n",
      "Train Epoch: 30 [100032/225000 (44%)] Loss: 20420.667969\n",
      "Train Epoch: 30 [102528/225000 (46%)] Loss: 20565.027344\n",
      "Train Epoch: 30 [105024/225000 (47%)] Loss: 20267.640625\n",
      "Train Epoch: 30 [107520/225000 (48%)] Loss: 20448.539062\n",
      "Train Epoch: 30 [110016/225000 (49%)] Loss: 20839.363281\n",
      "Train Epoch: 30 [112512/225000 (50%)] Loss: 19881.705078\n",
      "Train Epoch: 30 [115008/225000 (51%)] Loss: 20336.398438\n",
      "Train Epoch: 30 [117504/225000 (52%)] Loss: 20551.957031\n",
      "Train Epoch: 30 [120000/225000 (53%)] Loss: 20118.656250\n",
      "Train Epoch: 30 [122496/225000 (54%)] Loss: 20672.800781\n",
      "Train Epoch: 30 [124992/225000 (56%)] Loss: 20378.402344\n",
      "Train Epoch: 30 [127488/225000 (57%)] Loss: 20116.203125\n",
      "Train Epoch: 30 [129984/225000 (58%)] Loss: 20119.035156\n",
      "Train Epoch: 30 [132480/225000 (59%)] Loss: 20095.886719\n",
      "Train Epoch: 30 [134976/225000 (60%)] Loss: 20633.496094\n",
      "Train Epoch: 30 [137472/225000 (61%)] Loss: 20684.242188\n",
      "Train Epoch: 30 [139968/225000 (62%)] Loss: 20075.320312\n",
      "Train Epoch: 30 [142464/225000 (63%)] Loss: 20369.179688\n",
      "Train Epoch: 30 [144960/225000 (64%)] Loss: 19879.082031\n",
      "Train Epoch: 30 [147456/225000 (66%)] Loss: 20271.312500\n",
      "Train Epoch: 30 [149952/225000 (67%)] Loss: 20549.144531\n",
      "Train Epoch: 30 [152448/225000 (68%)] Loss: 20266.683594\n",
      "Train Epoch: 30 [154944/225000 (69%)] Loss: 20314.050781\n",
      "Train Epoch: 30 [157440/225000 (70%)] Loss: 20066.636719\n",
      "Train Epoch: 30 [159936/225000 (71%)] Loss: 20042.285156\n",
      "Train Epoch: 30 [162432/225000 (72%)] Loss: 20291.144531\n",
      "Train Epoch: 30 [164928/225000 (73%)] Loss: 20398.390625\n",
      "Train Epoch: 30 [167424/225000 (74%)] Loss: 20605.503906\n",
      "Train Epoch: 30 [169920/225000 (76%)] Loss: 20576.011719\n",
      "Train Epoch: 30 [172416/225000 (77%)] Loss: 20270.066406\n",
      "Train Epoch: 30 [174912/225000 (78%)] Loss: 20243.414062\n",
      "Train Epoch: 30 [177408/225000 (79%)] Loss: 20940.361328\n",
      "Train Epoch: 30 [179904/225000 (80%)] Loss: 20368.949219\n",
      "Train Epoch: 30 [182400/225000 (81%)] Loss: 19901.261719\n",
      "Train Epoch: 30 [184896/225000 (82%)] Loss: 20358.570312\n",
      "Train Epoch: 30 [187392/225000 (83%)] Loss: 20325.980469\n",
      "Train Epoch: 30 [189888/225000 (84%)] Loss: 20611.556641\n",
      "Train Epoch: 30 [192384/225000 (86%)] Loss: 20296.505859\n",
      "Train Epoch: 30 [194880/225000 (87%)] Loss: 20460.406250\n",
      "Train Epoch: 30 [197376/225000 (88%)] Loss: 20794.416016\n",
      "Train Epoch: 30 [199872/225000 (89%)] Loss: 20368.710938\n",
      "Train Epoch: 30 [202368/225000 (90%)] Loss: 20711.433594\n",
      "Train Epoch: 30 [204864/225000 (91%)] Loss: 20307.574219\n",
      "Train Epoch: 30 [207360/225000 (92%)] Loss: 19733.029297\n",
      "Train Epoch: 30 [209856/225000 (93%)] Loss: 20104.894531\n",
      "Train Epoch: 30 [212352/225000 (94%)] Loss: 20600.531250\n",
      "Train Epoch: 30 [214848/225000 (95%)] Loss: 20401.533203\n",
      "Train Epoch: 30 [217344/225000 (97%)] Loss: 20408.785156\n",
      "Train Epoch: 30 [219840/225000 (98%)] Loss: 20270.005859\n",
      "Train Epoch: 30 [222336/225000 (99%)] Loss: 20713.617188\n",
      "Train Epoch: 30 [224832/225000 (100%)] Loss: 20146.183594\n",
      "    epoch          : 30\n",
      "    loss           : 20335.489814419794\n",
      "    val_loss       : 20241.360062311625\n",
      "Train Epoch: 31 [192/225000 (0%)] Loss: 20060.904297\n",
      "Train Epoch: 31 [2688/225000 (1%)] Loss: 20706.054688\n",
      "Train Epoch: 31 [5184/225000 (2%)] Loss: 20749.453125\n",
      "Train Epoch: 31 [7680/225000 (3%)] Loss: 20113.044922\n",
      "Train Epoch: 31 [10176/225000 (5%)] Loss: 20232.980469\n",
      "Train Epoch: 31 [12672/225000 (6%)] Loss: 20360.335938\n",
      "Train Epoch: 31 [15168/225000 (7%)] Loss: 20076.544922\n",
      "Train Epoch: 31 [17664/225000 (8%)] Loss: 20152.894531\n",
      "Train Epoch: 31 [20160/225000 (9%)] Loss: 20719.640625\n",
      "Train Epoch: 31 [22656/225000 (10%)] Loss: 20256.787109\n",
      "Train Epoch: 31 [25152/225000 (11%)] Loss: 20074.312500\n",
      "Train Epoch: 31 [27648/225000 (12%)] Loss: 20422.722656\n",
      "Train Epoch: 31 [30144/225000 (13%)] Loss: 20247.734375\n",
      "Train Epoch: 31 [32640/225000 (15%)] Loss: 20274.628906\n",
      "Train Epoch: 31 [35136/225000 (16%)] Loss: 20371.875000\n",
      "Train Epoch: 31 [37632/225000 (17%)] Loss: 20465.380859\n",
      "Train Epoch: 31 [40128/225000 (18%)] Loss: 20361.132812\n",
      "Train Epoch: 31 [42624/225000 (19%)] Loss: 20482.480469\n",
      "Train Epoch: 31 [45120/225000 (20%)] Loss: 20292.898438\n",
      "Train Epoch: 31 [47616/225000 (21%)] Loss: 20436.410156\n",
      "Train Epoch: 31 [50112/225000 (22%)] Loss: 20693.535156\n",
      "Train Epoch: 31 [52608/225000 (23%)] Loss: 20426.304688\n",
      "Train Epoch: 31 [55104/225000 (24%)] Loss: 20086.578125\n",
      "Train Epoch: 31 [57600/225000 (26%)] Loss: 20149.646484\n",
      "Train Epoch: 31 [60096/225000 (27%)] Loss: 20200.949219\n",
      "Train Epoch: 31 [62592/225000 (28%)] Loss: 19400.457031\n",
      "Train Epoch: 31 [65088/225000 (29%)] Loss: 20454.343750\n",
      "Train Epoch: 31 [67584/225000 (30%)] Loss: 20383.558594\n",
      "Train Epoch: 31 [70080/225000 (31%)] Loss: 20087.746094\n",
      "Train Epoch: 31 [72576/225000 (32%)] Loss: 20011.164062\n",
      "Train Epoch: 31 [75072/225000 (33%)] Loss: 20536.460938\n",
      "Train Epoch: 31 [77568/225000 (34%)] Loss: 20284.169922\n",
      "Train Epoch: 31 [80064/225000 (36%)] Loss: 20329.472656\n",
      "Train Epoch: 31 [82560/225000 (37%)] Loss: 20608.341797\n",
      "Train Epoch: 31 [85056/225000 (38%)] Loss: 20309.109375\n",
      "Train Epoch: 31 [87552/225000 (39%)] Loss: 20483.714844\n",
      "Train Epoch: 31 [90048/225000 (40%)] Loss: 20490.835938\n",
      "Train Epoch: 31 [92544/225000 (41%)] Loss: 20097.730469\n",
      "Train Epoch: 31 [95040/225000 (42%)] Loss: 20377.140625\n",
      "Train Epoch: 31 [97536/225000 (43%)] Loss: 20464.312500\n",
      "Train Epoch: 31 [100032/225000 (44%)] Loss: 20683.066406\n",
      "Train Epoch: 31 [102528/225000 (46%)] Loss: 19699.261719\n",
      "Train Epoch: 31 [105024/225000 (47%)] Loss: 19990.144531\n",
      "Train Epoch: 31 [107520/225000 (48%)] Loss: 20237.201172\n",
      "Train Epoch: 31 [110016/225000 (49%)] Loss: 20676.541016\n",
      "Train Epoch: 31 [112512/225000 (50%)] Loss: 20406.023438\n",
      "Train Epoch: 31 [115008/225000 (51%)] Loss: 20107.476562\n",
      "Train Epoch: 31 [117504/225000 (52%)] Loss: 19967.757812\n",
      "Train Epoch: 31 [120000/225000 (53%)] Loss: 20442.347656\n",
      "Train Epoch: 31 [122496/225000 (54%)] Loss: 20360.585938\n",
      "Train Epoch: 31 [124992/225000 (56%)] Loss: 20359.609375\n",
      "Train Epoch: 31 [127488/225000 (57%)] Loss: 20043.828125\n",
      "Train Epoch: 31 [129984/225000 (58%)] Loss: 20394.015625\n",
      "Train Epoch: 31 [132480/225000 (59%)] Loss: 20781.109375\n",
      "Train Epoch: 31 [134976/225000 (60%)] Loss: 20274.136719\n",
      "Train Epoch: 31 [137472/225000 (61%)] Loss: 20141.011719\n",
      "Train Epoch: 31 [139968/225000 (62%)] Loss: 20207.132812\n",
      "Train Epoch: 31 [142464/225000 (63%)] Loss: 20172.035156\n",
      "Train Epoch: 31 [144960/225000 (64%)] Loss: 20388.101562\n",
      "Train Epoch: 31 [147456/225000 (66%)] Loss: 20360.666016\n",
      "Train Epoch: 31 [149952/225000 (67%)] Loss: 19882.902344\n",
      "Train Epoch: 31 [152448/225000 (68%)] Loss: 20148.060547\n",
      "Train Epoch: 31 [154944/225000 (69%)] Loss: 19739.328125\n",
      "Train Epoch: 31 [157440/225000 (70%)] Loss: 20249.326172\n",
      "Train Epoch: 31 [159936/225000 (71%)] Loss: 20195.386719\n",
      "Train Epoch: 31 [162432/225000 (72%)] Loss: 20845.578125\n",
      "Train Epoch: 31 [164928/225000 (73%)] Loss: 20282.806641\n",
      "Train Epoch: 31 [167424/225000 (74%)] Loss: 20877.914062\n",
      "Train Epoch: 31 [169920/225000 (76%)] Loss: 20308.132812\n",
      "Train Epoch: 31 [172416/225000 (77%)] Loss: 20606.515625\n",
      "Train Epoch: 31 [174912/225000 (78%)] Loss: 20383.490234\n",
      "Train Epoch: 31 [177408/225000 (79%)] Loss: 20423.625000\n",
      "Train Epoch: 31 [179904/225000 (80%)] Loss: 20018.636719\n",
      "Train Epoch: 31 [182400/225000 (81%)] Loss: 20115.210938\n",
      "Train Epoch: 31 [184896/225000 (82%)] Loss: 20494.964844\n",
      "Train Epoch: 31 [187392/225000 (83%)] Loss: 19747.468750\n",
      "Train Epoch: 31 [189888/225000 (84%)] Loss: 20237.078125\n",
      "Train Epoch: 31 [192384/225000 (86%)] Loss: 20675.898438\n",
      "Train Epoch: 31 [194880/225000 (87%)] Loss: 20918.800781\n",
      "Train Epoch: 31 [197376/225000 (88%)] Loss: 20181.654297\n",
      "Train Epoch: 31 [199872/225000 (89%)] Loss: 20096.332031\n",
      "Train Epoch: 31 [202368/225000 (90%)] Loss: 20169.800781\n",
      "Train Epoch: 31 [204864/225000 (91%)] Loss: 20888.796875\n",
      "Train Epoch: 31 [207360/225000 (92%)] Loss: 20685.097656\n",
      "Train Epoch: 31 [209856/225000 (93%)] Loss: 20217.824219\n",
      "Train Epoch: 31 [212352/225000 (94%)] Loss: 20300.238281\n",
      "Train Epoch: 31 [214848/225000 (95%)] Loss: 20404.570312\n",
      "Train Epoch: 31 [217344/225000 (97%)] Loss: 20193.882812\n",
      "Train Epoch: 31 [219840/225000 (98%)] Loss: 20048.058594\n",
      "Train Epoch: 31 [222336/225000 (99%)] Loss: 20392.285156\n",
      "Train Epoch: 31 [224832/225000 (100%)] Loss: 20008.544922\n",
      "    epoch          : 31\n",
      "    loss           : 20328.762631985923\n",
      "    val_loss       : 20229.432509150214\n",
      "Train Epoch: 32 [192/225000 (0%)] Loss: 20396.906250\n",
      "Train Epoch: 32 [2688/225000 (1%)] Loss: 20309.371094\n",
      "Train Epoch: 32 [5184/225000 (2%)] Loss: 20057.587891\n",
      "Train Epoch: 32 [7680/225000 (3%)] Loss: 20112.746094\n",
      "Train Epoch: 32 [10176/225000 (5%)] Loss: 20474.230469\n",
      "Train Epoch: 32 [12672/225000 (6%)] Loss: 20949.669922\n",
      "Train Epoch: 32 [15168/225000 (7%)] Loss: 20326.226562\n",
      "Train Epoch: 32 [17664/225000 (8%)] Loss: 19981.824219\n",
      "Train Epoch: 32 [20160/225000 (9%)] Loss: 19809.718750\n",
      "Train Epoch: 32 [22656/225000 (10%)] Loss: 20442.894531\n",
      "Train Epoch: 32 [25152/225000 (11%)] Loss: 20390.113281\n",
      "Train Epoch: 32 [27648/225000 (12%)] Loss: 20111.148438\n",
      "Train Epoch: 32 [30144/225000 (13%)] Loss: 20139.490234\n",
      "Train Epoch: 32 [32640/225000 (15%)] Loss: 20282.566406\n",
      "Train Epoch: 32 [35136/225000 (16%)] Loss: 20538.019531\n",
      "Train Epoch: 32 [37632/225000 (17%)] Loss: 19692.421875\n",
      "Train Epoch: 32 [40128/225000 (18%)] Loss: 20727.117188\n",
      "Train Epoch: 32 [42624/225000 (19%)] Loss: 20198.960938\n",
      "Train Epoch: 32 [45120/225000 (20%)] Loss: 19877.814453\n",
      "Train Epoch: 32 [47616/225000 (21%)] Loss: 20186.644531\n",
      "Train Epoch: 32 [50112/225000 (22%)] Loss: 20489.839844\n",
      "Train Epoch: 32 [52608/225000 (23%)] Loss: 20126.179688\n",
      "Train Epoch: 32 [55104/225000 (24%)] Loss: 20289.804688\n",
      "Train Epoch: 32 [57600/225000 (26%)] Loss: 20535.269531\n",
      "Train Epoch: 32 [60096/225000 (27%)] Loss: 20362.986328\n",
      "Train Epoch: 32 [62592/225000 (28%)] Loss: 20603.796875\n",
      "Train Epoch: 32 [65088/225000 (29%)] Loss: 20418.449219\n",
      "Train Epoch: 32 [67584/225000 (30%)] Loss: 20276.683594\n",
      "Train Epoch: 32 [70080/225000 (31%)] Loss: 20026.585938\n",
      "Train Epoch: 32 [72576/225000 (32%)] Loss: 20596.708984\n",
      "Train Epoch: 32 [75072/225000 (33%)] Loss: 20202.000000\n",
      "Train Epoch: 32 [77568/225000 (34%)] Loss: 21001.910156\n",
      "Train Epoch: 32 [80064/225000 (36%)] Loss: 20322.503906\n",
      "Train Epoch: 32 [82560/225000 (37%)] Loss: 20150.097656\n",
      "Train Epoch: 32 [85056/225000 (38%)] Loss: 20797.054688\n",
      "Train Epoch: 32 [87552/225000 (39%)] Loss: 19910.658203\n",
      "Train Epoch: 32 [90048/225000 (40%)] Loss: 20187.691406\n",
      "Train Epoch: 32 [92544/225000 (41%)] Loss: 20356.281250\n",
      "Train Epoch: 32 [95040/225000 (42%)] Loss: 20134.712891\n",
      "Train Epoch: 32 [97536/225000 (43%)] Loss: 20317.384766\n",
      "Train Epoch: 32 [100032/225000 (44%)] Loss: 20171.796875\n",
      "Train Epoch: 32 [102528/225000 (46%)] Loss: 20731.238281\n",
      "Train Epoch: 32 [105024/225000 (47%)] Loss: 20530.277344\n",
      "Train Epoch: 32 [107520/225000 (48%)] Loss: 20154.759766\n",
      "Train Epoch: 32 [110016/225000 (49%)] Loss: 20403.824219\n",
      "Train Epoch: 32 [112512/225000 (50%)] Loss: 20615.931641\n",
      "Train Epoch: 32 [115008/225000 (51%)] Loss: 20553.050781\n",
      "Train Epoch: 32 [117504/225000 (52%)] Loss: 20740.679688\n",
      "Train Epoch: 32 [120000/225000 (53%)] Loss: 20460.937500\n",
      "Train Epoch: 32 [122496/225000 (54%)] Loss: 20424.035156\n",
      "Train Epoch: 32 [124992/225000 (56%)] Loss: 20382.027344\n",
      "Train Epoch: 32 [127488/225000 (57%)] Loss: 20579.007812\n",
      "Train Epoch: 32 [129984/225000 (58%)] Loss: 19911.798828\n",
      "Train Epoch: 32 [132480/225000 (59%)] Loss: 19780.378906\n",
      "Train Epoch: 32 [134976/225000 (60%)] Loss: 20800.271484\n",
      "Train Epoch: 32 [137472/225000 (61%)] Loss: 19851.888672\n",
      "Train Epoch: 32 [139968/225000 (62%)] Loss: 20463.324219\n",
      "Train Epoch: 32 [142464/225000 (63%)] Loss: 20481.851562\n",
      "Train Epoch: 32 [144960/225000 (64%)] Loss: 20756.253906\n",
      "Train Epoch: 32 [147456/225000 (66%)] Loss: 20235.189453\n",
      "Train Epoch: 32 [149952/225000 (67%)] Loss: 20335.546875\n",
      "Train Epoch: 32 [152448/225000 (68%)] Loss: 20314.431641\n",
      "Train Epoch: 32 [154944/225000 (69%)] Loss: 20154.562500\n",
      "Train Epoch: 32 [157440/225000 (70%)] Loss: 20257.933594\n",
      "Train Epoch: 32 [159936/225000 (71%)] Loss: 19975.183594\n",
      "Train Epoch: 32 [162432/225000 (72%)] Loss: 20389.222656\n",
      "Train Epoch: 32 [164928/225000 (73%)] Loss: 19830.623047\n",
      "Train Epoch: 32 [167424/225000 (74%)] Loss: 19339.476562\n",
      "Train Epoch: 32 [169920/225000 (76%)] Loss: 20324.042969\n",
      "Train Epoch: 32 [172416/225000 (77%)] Loss: 20090.035156\n",
      "Train Epoch: 32 [174912/225000 (78%)] Loss: 20686.587891\n",
      "Train Epoch: 32 [177408/225000 (79%)] Loss: 20463.070312\n",
      "Train Epoch: 32 [179904/225000 (80%)] Loss: 20363.250000\n",
      "Train Epoch: 32 [182400/225000 (81%)] Loss: 20218.566406\n",
      "Train Epoch: 32 [184896/225000 (82%)] Loss: 20477.042969\n",
      "Train Epoch: 32 [187392/225000 (83%)] Loss: 20676.671875\n",
      "Train Epoch: 32 [189888/225000 (84%)] Loss: 20216.062500\n",
      "Train Epoch: 32 [192384/225000 (86%)] Loss: 20798.283203\n",
      "Train Epoch: 32 [194880/225000 (87%)] Loss: 20519.292969\n",
      "Train Epoch: 32 [197376/225000 (88%)] Loss: 20533.300781\n",
      "Train Epoch: 32 [199872/225000 (89%)] Loss: 20140.429688\n",
      "Train Epoch: 32 [202368/225000 (90%)] Loss: 20405.660156\n",
      "Train Epoch: 32 [204864/225000 (91%)] Loss: 20329.792969\n",
      "Train Epoch: 32 [207360/225000 (92%)] Loss: 20403.562500\n",
      "Train Epoch: 32 [209856/225000 (93%)] Loss: 21018.750000\n",
      "Train Epoch: 32 [212352/225000 (94%)] Loss: 20578.027344\n",
      "Train Epoch: 32 [214848/225000 (95%)] Loss: 20200.156250\n",
      "Train Epoch: 32 [217344/225000 (97%)] Loss: 20770.292969\n",
      "Train Epoch: 32 [219840/225000 (98%)] Loss: 20355.074219\n",
      "Train Epoch: 32 [222336/225000 (99%)] Loss: 21349.750000\n",
      "Train Epoch: 32 [224832/225000 (100%)] Loss: 20207.976562\n",
      "    epoch          : 32\n",
      "    loss           : 20326.175196312393\n",
      "    val_loss       : 20231.138168018282\n",
      "Train Epoch: 33 [192/225000 (0%)] Loss: 20456.566406\n",
      "Train Epoch: 33 [2688/225000 (1%)] Loss: 19978.738281\n",
      "Train Epoch: 33 [5184/225000 (2%)] Loss: 20315.980469\n",
      "Train Epoch: 33 [7680/225000 (3%)] Loss: 20194.546875\n",
      "Train Epoch: 33 [10176/225000 (5%)] Loss: 20555.898438\n",
      "Train Epoch: 33 [12672/225000 (6%)] Loss: 20685.574219\n",
      "Train Epoch: 33 [15168/225000 (7%)] Loss: 20356.388672\n",
      "Train Epoch: 33 [17664/225000 (8%)] Loss: 20253.753906\n",
      "Train Epoch: 33 [20160/225000 (9%)] Loss: 20111.890625\n",
      "Train Epoch: 33 [22656/225000 (10%)] Loss: 20188.949219\n",
      "Train Epoch: 33 [25152/225000 (11%)] Loss: 20042.980469\n",
      "Train Epoch: 33 [27648/225000 (12%)] Loss: 20077.792969\n",
      "Train Epoch: 33 [30144/225000 (13%)] Loss: 19843.351562\n",
      "Train Epoch: 33 [32640/225000 (15%)] Loss: 20464.429688\n",
      "Train Epoch: 33 [35136/225000 (16%)] Loss: 20338.621094\n",
      "Train Epoch: 33 [37632/225000 (17%)] Loss: 20315.417969\n",
      "Train Epoch: 33 [40128/225000 (18%)] Loss: 20491.402344\n",
      "Train Epoch: 33 [42624/225000 (19%)] Loss: 20397.386719\n",
      "Train Epoch: 33 [45120/225000 (20%)] Loss: 20784.560547\n",
      "Train Epoch: 33 [47616/225000 (21%)] Loss: 20332.277344\n",
      "Train Epoch: 33 [50112/225000 (22%)] Loss: 20361.718750\n",
      "Train Epoch: 33 [52608/225000 (23%)] Loss: 20518.876953\n",
      "Train Epoch: 33 [55104/225000 (24%)] Loss: 20172.189453\n",
      "Train Epoch: 33 [57600/225000 (26%)] Loss: 20524.564453\n",
      "Train Epoch: 33 [60096/225000 (27%)] Loss: 20220.566406\n",
      "Train Epoch: 33 [62592/225000 (28%)] Loss: 20212.566406\n",
      "Train Epoch: 33 [65088/225000 (29%)] Loss: 19860.746094\n",
      "Train Epoch: 33 [67584/225000 (30%)] Loss: 19698.554688\n",
      "Train Epoch: 33 [70080/225000 (31%)] Loss: 20537.966797\n",
      "Train Epoch: 33 [72576/225000 (32%)] Loss: 21067.281250\n",
      "Train Epoch: 33 [75072/225000 (33%)] Loss: 19937.552734\n",
      "Train Epoch: 33 [77568/225000 (34%)] Loss: 20229.742188\n",
      "Train Epoch: 33 [80064/225000 (36%)] Loss: 20281.593750\n",
      "Train Epoch: 33 [82560/225000 (37%)] Loss: 20286.160156\n",
      "Train Epoch: 33 [85056/225000 (38%)] Loss: 20339.457031\n",
      "Train Epoch: 33 [87552/225000 (39%)] Loss: 20405.236328\n",
      "Train Epoch: 33 [90048/225000 (40%)] Loss: 19959.945312\n",
      "Train Epoch: 33 [92544/225000 (41%)] Loss: 20114.111328\n",
      "Train Epoch: 33 [95040/225000 (42%)] Loss: 20218.503906\n",
      "Train Epoch: 33 [97536/225000 (43%)] Loss: 20471.121094\n",
      "Train Epoch: 33 [100032/225000 (44%)] Loss: 20052.703125\n",
      "Train Epoch: 33 [102528/225000 (46%)] Loss: 20371.757812\n",
      "Train Epoch: 33 [105024/225000 (47%)] Loss: 19925.769531\n",
      "Train Epoch: 33 [107520/225000 (48%)] Loss: 20091.457031\n",
      "Train Epoch: 33 [110016/225000 (49%)] Loss: 20528.197266\n",
      "Train Epoch: 33 [112512/225000 (50%)] Loss: 19975.630859\n",
      "Train Epoch: 33 [115008/225000 (51%)] Loss: 20104.359375\n",
      "Train Epoch: 33 [117504/225000 (52%)] Loss: 20357.363281\n",
      "Train Epoch: 33 [120000/225000 (53%)] Loss: 20364.824219\n",
      "Train Epoch: 33 [122496/225000 (54%)] Loss: 20208.628906\n",
      "Train Epoch: 33 [124992/225000 (56%)] Loss: 20354.570312\n",
      "Train Epoch: 33 [127488/225000 (57%)] Loss: 20523.353516\n",
      "Train Epoch: 33 [129984/225000 (58%)] Loss: 19976.031250\n",
      "Train Epoch: 33 [132480/225000 (59%)] Loss: 21016.171875\n",
      "Train Epoch: 33 [134976/225000 (60%)] Loss: 20302.726562\n",
      "Train Epoch: 33 [137472/225000 (61%)] Loss: 20700.742188\n",
      "Train Epoch: 33 [139968/225000 (62%)] Loss: 20330.750000\n",
      "Train Epoch: 33 [142464/225000 (63%)] Loss: 20038.474609\n",
      "Train Epoch: 33 [144960/225000 (64%)] Loss: 20421.130859\n",
      "Train Epoch: 33 [147456/225000 (66%)] Loss: 20398.646484\n",
      "Train Epoch: 33 [149952/225000 (67%)] Loss: 20465.861328\n",
      "Train Epoch: 33 [152448/225000 (68%)] Loss: 20567.070312\n",
      "Train Epoch: 33 [154944/225000 (69%)] Loss: 19795.242188\n",
      "Train Epoch: 33 [157440/225000 (70%)] Loss: 20549.539062\n",
      "Train Epoch: 33 [159936/225000 (71%)] Loss: 20176.148438\n",
      "Train Epoch: 33 [162432/225000 (72%)] Loss: 20005.625000\n",
      "Train Epoch: 33 [164928/225000 (73%)] Loss: 20509.564453\n",
      "Train Epoch: 33 [167424/225000 (74%)] Loss: 20256.837891\n",
      "Train Epoch: 33 [169920/225000 (76%)] Loss: 19879.121094\n",
      "Train Epoch: 33 [172416/225000 (77%)] Loss: 20361.396484\n",
      "Train Epoch: 33 [174912/225000 (78%)] Loss: 20382.470703\n",
      "Train Epoch: 33 [177408/225000 (79%)] Loss: 20499.527344\n",
      "Train Epoch: 33 [179904/225000 (80%)] Loss: 20110.832031\n",
      "Train Epoch: 33 [182400/225000 (81%)] Loss: 20559.742188\n",
      "Train Epoch: 33 [184896/225000 (82%)] Loss: 20223.425781\n",
      "Train Epoch: 33 [187392/225000 (83%)] Loss: 20682.052734\n",
      "Train Epoch: 33 [189888/225000 (84%)] Loss: 20696.093750\n",
      "Train Epoch: 33 [192384/225000 (86%)] Loss: 20484.285156\n",
      "Train Epoch: 33 [194880/225000 (87%)] Loss: 20764.140625\n",
      "Train Epoch: 33 [197376/225000 (88%)] Loss: 20456.796875\n",
      "Train Epoch: 33 [199872/225000 (89%)] Loss: 20574.335938\n",
      "Train Epoch: 33 [202368/225000 (90%)] Loss: 20113.644531\n",
      "Train Epoch: 33 [204864/225000 (91%)] Loss: 20151.835938\n",
      "Train Epoch: 33 [207360/225000 (92%)] Loss: 20155.425781\n",
      "Train Epoch: 33 [209856/225000 (93%)] Loss: 20249.013672\n",
      "Train Epoch: 33 [212352/225000 (94%)] Loss: 20574.113281\n",
      "Train Epoch: 33 [214848/225000 (95%)] Loss: 20485.570312\n",
      "Train Epoch: 33 [217344/225000 (97%)] Loss: 20605.558594\n",
      "Train Epoch: 33 [219840/225000 (98%)] Loss: 20134.738281\n",
      "Train Epoch: 33 [222336/225000 (99%)] Loss: 20406.419922\n",
      "Train Epoch: 33 [224832/225000 (100%)] Loss: 20612.361328\n",
      "    epoch          : 33\n",
      "    loss           : 20325.375939899743\n",
      "    val_loss       : 20215.819059460217\n",
      "Train Epoch: 34 [192/225000 (0%)] Loss: 20490.923828\n",
      "Train Epoch: 34 [2688/225000 (1%)] Loss: 20071.140625\n",
      "Train Epoch: 34 [5184/225000 (2%)] Loss: 20505.507812\n",
      "Train Epoch: 34 [7680/225000 (3%)] Loss: 20449.892578\n",
      "Train Epoch: 34 [10176/225000 (5%)] Loss: 20545.480469\n",
      "Train Epoch: 34 [12672/225000 (6%)] Loss: 20374.228516\n",
      "Train Epoch: 34 [15168/225000 (7%)] Loss: 19985.542969\n",
      "Train Epoch: 34 [17664/225000 (8%)] Loss: 20377.800781\n",
      "Train Epoch: 34 [20160/225000 (9%)] Loss: 19710.404297\n",
      "Train Epoch: 34 [22656/225000 (10%)] Loss: 19900.136719\n",
      "Train Epoch: 34 [25152/225000 (11%)] Loss: 20319.707031\n",
      "Train Epoch: 34 [27648/225000 (12%)] Loss: 20229.781250\n",
      "Train Epoch: 34 [30144/225000 (13%)] Loss: 19812.218750\n",
      "Train Epoch: 34 [32640/225000 (15%)] Loss: 20085.593750\n",
      "Train Epoch: 34 [35136/225000 (16%)] Loss: 20158.453125\n",
      "Train Epoch: 34 [37632/225000 (17%)] Loss: 20822.761719\n",
      "Train Epoch: 34 [40128/225000 (18%)] Loss: 20242.126953\n",
      "Train Epoch: 34 [42624/225000 (19%)] Loss: 20831.820312\n",
      "Train Epoch: 34 [45120/225000 (20%)] Loss: 20804.804688\n",
      "Train Epoch: 34 [47616/225000 (21%)] Loss: 20227.802734\n",
      "Train Epoch: 34 [50112/225000 (22%)] Loss: 20467.710938\n",
      "Train Epoch: 34 [52608/225000 (23%)] Loss: 19951.531250\n",
      "Train Epoch: 34 [55104/225000 (24%)] Loss: 20456.996094\n",
      "Train Epoch: 34 [57600/225000 (26%)] Loss: 19814.345703\n",
      "Train Epoch: 34 [60096/225000 (27%)] Loss: 20371.167969\n",
      "Train Epoch: 34 [62592/225000 (28%)] Loss: 19858.957031\n",
      "Train Epoch: 34 [65088/225000 (29%)] Loss: 20506.009766\n",
      "Train Epoch: 34 [67584/225000 (30%)] Loss: 20342.574219\n",
      "Train Epoch: 34 [70080/225000 (31%)] Loss: 20324.675781\n",
      "Train Epoch: 34 [72576/225000 (32%)] Loss: 20801.580078\n",
      "Train Epoch: 34 [75072/225000 (33%)] Loss: 20714.986328\n",
      "Train Epoch: 34 [77568/225000 (34%)] Loss: 20005.785156\n",
      "Train Epoch: 34 [80064/225000 (36%)] Loss: 20598.972656\n",
      "Train Epoch: 34 [82560/225000 (37%)] Loss: 20273.363281\n",
      "Train Epoch: 34 [85056/225000 (38%)] Loss: 19924.230469\n",
      "Train Epoch: 34 [87552/225000 (39%)] Loss: 20493.896484\n",
      "Train Epoch: 34 [90048/225000 (40%)] Loss: 20184.117188\n",
      "Train Epoch: 34 [92544/225000 (41%)] Loss: 20701.251953\n",
      "Train Epoch: 34 [95040/225000 (42%)] Loss: 20440.136719\n",
      "Train Epoch: 34 [97536/225000 (43%)] Loss: 20000.373047\n",
      "Train Epoch: 34 [100032/225000 (44%)] Loss: 20210.464844\n",
      "Train Epoch: 34 [102528/225000 (46%)] Loss: 20037.304688\n",
      "Train Epoch: 34 [105024/225000 (47%)] Loss: 20176.017578\n",
      "Train Epoch: 34 [107520/225000 (48%)] Loss: 20281.457031\n",
      "Train Epoch: 34 [110016/225000 (49%)] Loss: 20580.949219\n",
      "Train Epoch: 34 [112512/225000 (50%)] Loss: 19938.578125\n",
      "Train Epoch: 34 [115008/225000 (51%)] Loss: 20159.130859\n",
      "Train Epoch: 34 [117504/225000 (52%)] Loss: 19947.042969\n",
      "Train Epoch: 34 [120000/225000 (53%)] Loss: 20520.173828\n",
      "Train Epoch: 34 [122496/225000 (54%)] Loss: 20022.437500\n",
      "Train Epoch: 34 [124992/225000 (56%)] Loss: 20302.017578\n",
      "Train Epoch: 34 [127488/225000 (57%)] Loss: 20278.929688\n",
      "Train Epoch: 34 [129984/225000 (58%)] Loss: 20307.375000\n",
      "Train Epoch: 34 [132480/225000 (59%)] Loss: 20089.947266\n",
      "Train Epoch: 34 [134976/225000 (60%)] Loss: 20396.582031\n",
      "Train Epoch: 34 [137472/225000 (61%)] Loss: 20391.406250\n",
      "Train Epoch: 34 [139968/225000 (62%)] Loss: 20240.703125\n",
      "Train Epoch: 34 [142464/225000 (63%)] Loss: 20639.335938\n",
      "Train Epoch: 34 [144960/225000 (64%)] Loss: 19962.605469\n",
      "Train Epoch: 34 [147456/225000 (66%)] Loss: 20534.984375\n",
      "Train Epoch: 34 [149952/225000 (67%)] Loss: 20631.480469\n",
      "Train Epoch: 34 [152448/225000 (68%)] Loss: 20000.761719\n",
      "Train Epoch: 34 [154944/225000 (69%)] Loss: 20474.027344\n",
      "Train Epoch: 34 [157440/225000 (70%)] Loss: 20245.617188\n",
      "Train Epoch: 34 [159936/225000 (71%)] Loss: 19669.613281\n",
      "Train Epoch: 34 [162432/225000 (72%)] Loss: 20629.199219\n",
      "Train Epoch: 34 [164928/225000 (73%)] Loss: 20305.220703\n",
      "Train Epoch: 34 [167424/225000 (74%)] Loss: 19885.128906\n",
      "Train Epoch: 34 [169920/225000 (76%)] Loss: 19831.435547\n",
      "Train Epoch: 34 [172416/225000 (77%)] Loss: 20437.429688\n",
      "Train Epoch: 34 [174912/225000 (78%)] Loss: 19690.398438\n",
      "Train Epoch: 34 [177408/225000 (79%)] Loss: 19919.728516\n",
      "Train Epoch: 34 [179904/225000 (80%)] Loss: 20636.441406\n",
      "Train Epoch: 34 [182400/225000 (81%)] Loss: 20673.343750\n",
      "Train Epoch: 34 [184896/225000 (82%)] Loss: 20675.113281\n",
      "Train Epoch: 34 [187392/225000 (83%)] Loss: 20046.695312\n",
      "Train Epoch: 34 [189888/225000 (84%)] Loss: 20514.226562\n",
      "Train Epoch: 34 [192384/225000 (86%)] Loss: 20126.738281\n",
      "Train Epoch: 34 [194880/225000 (87%)] Loss: 19900.169922\n",
      "Train Epoch: 34 [197376/225000 (88%)] Loss: 19806.423828\n",
      "Train Epoch: 34 [199872/225000 (89%)] Loss: 20154.257812\n",
      "Train Epoch: 34 [202368/225000 (90%)] Loss: 20076.642578\n",
      "Train Epoch: 34 [204864/225000 (91%)] Loss: 20735.302734\n",
      "Train Epoch: 34 [207360/225000 (92%)] Loss: 20446.636719\n",
      "Train Epoch: 34 [209856/225000 (93%)] Loss: 20344.242188\n",
      "Train Epoch: 34 [212352/225000 (94%)] Loss: 20265.937500\n",
      "Train Epoch: 34 [214848/225000 (95%)] Loss: 20353.511719\n",
      "Train Epoch: 34 [217344/225000 (97%)] Loss: 20552.355469\n",
      "Train Epoch: 34 [219840/225000 (98%)] Loss: 19611.707031\n",
      "Train Epoch: 34 [222336/225000 (99%)] Loss: 19823.011719\n",
      "Train Epoch: 34 [224832/225000 (100%)] Loss: 20288.265625\n",
      "    epoch          : 34\n",
      "    loss           : 20329.484551647824\n",
      "    val_loss       : 20248.77476262682\n",
      "Train Epoch: 35 [192/225000 (0%)] Loss: 20334.078125\n",
      "Train Epoch: 35 [2688/225000 (1%)] Loss: 20496.953125\n",
      "Train Epoch: 35 [5184/225000 (2%)] Loss: 20194.660156\n",
      "Train Epoch: 35 [7680/225000 (3%)] Loss: 20134.191406\n",
      "Train Epoch: 35 [10176/225000 (5%)] Loss: 20561.490234\n",
      "Train Epoch: 35 [12672/225000 (6%)] Loss: 20372.855469\n",
      "Train Epoch: 35 [15168/225000 (7%)] Loss: 19829.585938\n",
      "Train Epoch: 35 [17664/225000 (8%)] Loss: 20347.294922\n",
      "Train Epoch: 35 [20160/225000 (9%)] Loss: 20506.660156\n",
      "Train Epoch: 35 [22656/225000 (10%)] Loss: 20852.130859\n",
      "Train Epoch: 35 [25152/225000 (11%)] Loss: 20353.292969\n",
      "Train Epoch: 35 [27648/225000 (12%)] Loss: 20593.191406\n",
      "Train Epoch: 35 [30144/225000 (13%)] Loss: 20127.746094\n",
      "Train Epoch: 35 [32640/225000 (15%)] Loss: 20736.082031\n",
      "Train Epoch: 35 [35136/225000 (16%)] Loss: 20236.755859\n",
      "Train Epoch: 35 [37632/225000 (17%)] Loss: 20353.750000\n",
      "Train Epoch: 35 [40128/225000 (18%)] Loss: 20246.019531\n",
      "Train Epoch: 35 [42624/225000 (19%)] Loss: 20335.083984\n",
      "Train Epoch: 35 [45120/225000 (20%)] Loss: 20198.136719\n",
      "Train Epoch: 35 [47616/225000 (21%)] Loss: 20577.625000\n",
      "Train Epoch: 35 [50112/225000 (22%)] Loss: 19829.521484\n",
      "Train Epoch: 35 [52608/225000 (23%)] Loss: 20268.525391\n",
      "Train Epoch: 35 [55104/225000 (24%)] Loss: 20524.390625\n",
      "Train Epoch: 35 [57600/225000 (26%)] Loss: 20967.199219\n",
      "Train Epoch: 35 [60096/225000 (27%)] Loss: 19940.878906\n",
      "Train Epoch: 35 [62592/225000 (28%)] Loss: 20367.449219\n",
      "Train Epoch: 35 [65088/225000 (29%)] Loss: 20366.462891\n",
      "Train Epoch: 35 [67584/225000 (30%)] Loss: 20291.326172\n",
      "Train Epoch: 35 [70080/225000 (31%)] Loss: 20361.101562\n",
      "Train Epoch: 35 [72576/225000 (32%)] Loss: 19798.171875\n",
      "Train Epoch: 35 [75072/225000 (33%)] Loss: 20578.222656\n",
      "Train Epoch: 35 [77568/225000 (34%)] Loss: 19863.320312\n",
      "Train Epoch: 35 [80064/225000 (36%)] Loss: 20529.703125\n",
      "Train Epoch: 35 [82560/225000 (37%)] Loss: 20790.667969\n",
      "Train Epoch: 35 [85056/225000 (38%)] Loss: 20449.142578\n",
      "Train Epoch: 35 [87552/225000 (39%)] Loss: 19728.101562\n",
      "Train Epoch: 35 [90048/225000 (40%)] Loss: 20454.207031\n",
      "Train Epoch: 35 [92544/225000 (41%)] Loss: 20234.320312\n",
      "Train Epoch: 35 [95040/225000 (42%)] Loss: 20695.964844\n",
      "Train Epoch: 35 [97536/225000 (43%)] Loss: 20012.773438\n",
      "Train Epoch: 35 [100032/225000 (44%)] Loss: 20388.673828\n",
      "Train Epoch: 35 [102528/225000 (46%)] Loss: 20277.753906\n",
      "Train Epoch: 35 [105024/225000 (47%)] Loss: 20085.732422\n",
      "Train Epoch: 35 [107520/225000 (48%)] Loss: 20305.697266\n",
      "Train Epoch: 35 [110016/225000 (49%)] Loss: 20106.042969\n",
      "Train Epoch: 35 [112512/225000 (50%)] Loss: 19993.976562\n",
      "Train Epoch: 35 [115008/225000 (51%)] Loss: 19952.855469\n",
      "Train Epoch: 35 [117504/225000 (52%)] Loss: 20475.613281\n",
      "Train Epoch: 35 [120000/225000 (53%)] Loss: 20497.238281\n",
      "Train Epoch: 35 [122496/225000 (54%)] Loss: 20105.185547\n",
      "Train Epoch: 35 [124992/225000 (56%)] Loss: 20565.527344\n",
      "Train Epoch: 35 [127488/225000 (57%)] Loss: 20209.996094\n",
      "Train Epoch: 35 [129984/225000 (58%)] Loss: 20362.140625\n",
      "Train Epoch: 35 [132480/225000 (59%)] Loss: 20049.386719\n",
      "Train Epoch: 35 [134976/225000 (60%)] Loss: 21095.613281\n",
      "Train Epoch: 35 [137472/225000 (61%)] Loss: 20166.187500\n",
      "Train Epoch: 35 [139968/225000 (62%)] Loss: 19852.365234\n",
      "Train Epoch: 35 [142464/225000 (63%)] Loss: 20145.800781\n",
      "Train Epoch: 35 [144960/225000 (64%)] Loss: 20256.394531\n",
      "Train Epoch: 35 [147456/225000 (66%)] Loss: 20924.218750\n",
      "Train Epoch: 35 [149952/225000 (67%)] Loss: 20196.980469\n",
      "Train Epoch: 35 [152448/225000 (68%)] Loss: 20288.140625\n",
      "Train Epoch: 35 [154944/225000 (69%)] Loss: 20487.689453\n",
      "Train Epoch: 35 [157440/225000 (70%)] Loss: 20750.937500\n",
      "Train Epoch: 35 [159936/225000 (71%)] Loss: 20144.003906\n",
      "Train Epoch: 35 [162432/225000 (72%)] Loss: 20539.783203\n",
      "Train Epoch: 35 [164928/225000 (73%)] Loss: 19914.599609\n",
      "Train Epoch: 35 [167424/225000 (74%)] Loss: 20249.212891\n",
      "Train Epoch: 35 [169920/225000 (76%)] Loss: 20635.578125\n",
      "Train Epoch: 35 [172416/225000 (77%)] Loss: 20894.988281\n",
      "Train Epoch: 35 [174912/225000 (78%)] Loss: 20017.958984\n",
      "Train Epoch: 35 [177408/225000 (79%)] Loss: 20658.988281\n",
      "Train Epoch: 35 [179904/225000 (80%)] Loss: 20318.966797\n",
      "Train Epoch: 35 [182400/225000 (81%)] Loss: 20633.925781\n",
      "Train Epoch: 35 [184896/225000 (82%)] Loss: 20347.203125\n",
      "Train Epoch: 35 [187392/225000 (83%)] Loss: 20431.710938\n",
      "Train Epoch: 35 [189888/225000 (84%)] Loss: 20376.169922\n",
      "Train Epoch: 35 [192384/225000 (86%)] Loss: 20344.869141\n",
      "Train Epoch: 35 [194880/225000 (87%)] Loss: 20342.992188\n",
      "Train Epoch: 35 [197376/225000 (88%)] Loss: 20245.957031\n",
      "Train Epoch: 35 [199872/225000 (89%)] Loss: 20331.847656\n",
      "Train Epoch: 35 [202368/225000 (90%)] Loss: 20669.140625\n",
      "Train Epoch: 35 [204864/225000 (91%)] Loss: 20386.000000\n",
      "Train Epoch: 35 [207360/225000 (92%)] Loss: 20585.304688\n",
      "Train Epoch: 35 [209856/225000 (93%)] Loss: 20344.734375\n",
      "Train Epoch: 35 [212352/225000 (94%)] Loss: 20334.445312\n",
      "Train Epoch: 35 [214848/225000 (95%)] Loss: 19985.628906\n",
      "Train Epoch: 35 [217344/225000 (97%)] Loss: 20256.535156\n",
      "Train Epoch: 35 [219840/225000 (98%)] Loss: 20548.886719\n",
      "Train Epoch: 35 [222336/225000 (99%)] Loss: 20174.898438\n",
      "Train Epoch: 35 [224832/225000 (100%)] Loss: 20427.902344\n",
      "    epoch          : 35\n",
      "    loss           : 20322.297279956805\n",
      "    val_loss       : 20215.774625918337\n",
      "Train Epoch: 36 [192/225000 (0%)] Loss: 20110.863281\n",
      "Train Epoch: 36 [2688/225000 (1%)] Loss: 20412.974609\n",
      "Train Epoch: 36 [5184/225000 (2%)] Loss: 20399.664062\n",
      "Train Epoch: 36 [7680/225000 (3%)] Loss: 20501.453125\n",
      "Train Epoch: 36 [10176/225000 (5%)] Loss: 20098.031250\n",
      "Train Epoch: 36 [12672/225000 (6%)] Loss: 20259.691406\n",
      "Train Epoch: 36 [15168/225000 (7%)] Loss: 20255.093750\n",
      "Train Epoch: 36 [17664/225000 (8%)] Loss: 20524.085938\n",
      "Train Epoch: 36 [20160/225000 (9%)] Loss: 20746.921875\n",
      "Train Epoch: 36 [22656/225000 (10%)] Loss: 20421.128906\n",
      "Train Epoch: 36 [25152/225000 (11%)] Loss: 20053.843750\n",
      "Train Epoch: 36 [27648/225000 (12%)] Loss: 20114.505859\n",
      "Train Epoch: 36 [30144/225000 (13%)] Loss: 20263.103516\n",
      "Train Epoch: 36 [32640/225000 (15%)] Loss: 20332.517578\n",
      "Train Epoch: 36 [35136/225000 (16%)] Loss: 19968.625000\n",
      "Train Epoch: 36 [37632/225000 (17%)] Loss: 20112.527344\n",
      "Train Epoch: 36 [40128/225000 (18%)] Loss: 20793.828125\n",
      "Train Epoch: 36 [42624/225000 (19%)] Loss: 20010.222656\n",
      "Train Epoch: 36 [45120/225000 (20%)] Loss: 19801.117188\n",
      "Train Epoch: 36 [47616/225000 (21%)] Loss: 20437.474609\n",
      "Train Epoch: 36 [50112/225000 (22%)] Loss: 20322.785156\n",
      "Train Epoch: 36 [52608/225000 (23%)] Loss: 20620.714844\n",
      "Train Epoch: 36 [55104/225000 (24%)] Loss: 20343.027344\n",
      "Train Epoch: 36 [57600/225000 (26%)] Loss: 20742.695312\n",
      "Train Epoch: 36 [60096/225000 (27%)] Loss: 20477.914062\n",
      "Train Epoch: 36 [62592/225000 (28%)] Loss: 19599.531250\n",
      "Train Epoch: 36 [65088/225000 (29%)] Loss: 19607.765625\n",
      "Train Epoch: 36 [67584/225000 (30%)] Loss: 20418.058594\n",
      "Train Epoch: 36 [70080/225000 (31%)] Loss: 20523.837891\n",
      "Train Epoch: 36 [72576/225000 (32%)] Loss: 19960.015625\n",
      "Train Epoch: 36 [75072/225000 (33%)] Loss: 20380.042969\n",
      "Train Epoch: 36 [77568/225000 (34%)] Loss: 20286.562500\n",
      "Train Epoch: 36 [80064/225000 (36%)] Loss: 20479.417969\n",
      "Train Epoch: 36 [82560/225000 (37%)] Loss: 20848.457031\n",
      "Train Epoch: 36 [85056/225000 (38%)] Loss: 20056.851562\n",
      "Train Epoch: 36 [87552/225000 (39%)] Loss: 20423.949219\n",
      "Train Epoch: 36 [90048/225000 (40%)] Loss: 20308.867188\n",
      "Train Epoch: 36 [92544/225000 (41%)] Loss: 20183.300781\n",
      "Train Epoch: 36 [95040/225000 (42%)] Loss: 20318.679688\n",
      "Train Epoch: 36 [97536/225000 (43%)] Loss: 20750.046875\n",
      "Train Epoch: 36 [100032/225000 (44%)] Loss: 20491.332031\n",
      "Train Epoch: 36 [102528/225000 (46%)] Loss: 20032.718750\n",
      "Train Epoch: 36 [105024/225000 (47%)] Loss: 20246.386719\n",
      "Train Epoch: 36 [107520/225000 (48%)] Loss: 20719.720703\n",
      "Train Epoch: 36 [110016/225000 (49%)] Loss: 20067.970703\n",
      "Train Epoch: 36 [112512/225000 (50%)] Loss: 20306.052734\n",
      "Train Epoch: 36 [115008/225000 (51%)] Loss: 20402.339844\n",
      "Train Epoch: 36 [117504/225000 (52%)] Loss: 20308.230469\n",
      "Train Epoch: 36 [120000/225000 (53%)] Loss: 20010.363281\n",
      "Train Epoch: 36 [122496/225000 (54%)] Loss: 20036.988281\n",
      "Train Epoch: 36 [124992/225000 (56%)] Loss: 20303.890625\n",
      "Train Epoch: 36 [127488/225000 (57%)] Loss: 20324.271484\n",
      "Train Epoch: 36 [129984/225000 (58%)] Loss: 20182.632812\n",
      "Train Epoch: 36 [132480/225000 (59%)] Loss: 20147.378906\n",
      "Train Epoch: 36 [134976/225000 (60%)] Loss: 20718.398438\n",
      "Train Epoch: 36 [137472/225000 (61%)] Loss: 20829.214844\n",
      "Train Epoch: 36 [139968/225000 (62%)] Loss: 19993.605469\n",
      "Train Epoch: 36 [142464/225000 (63%)] Loss: 20478.769531\n",
      "Train Epoch: 36 [144960/225000 (64%)] Loss: 19902.656250\n",
      "Train Epoch: 36 [147456/225000 (66%)] Loss: 20374.255859\n",
      "Train Epoch: 36 [149952/225000 (67%)] Loss: 21052.140625\n",
      "Train Epoch: 36 [152448/225000 (68%)] Loss: 20120.417969\n",
      "Train Epoch: 36 [154944/225000 (69%)] Loss: 20023.281250\n",
      "Train Epoch: 36 [157440/225000 (70%)] Loss: 20226.132812\n",
      "Train Epoch: 36 [159936/225000 (71%)] Loss: 20233.218750\n",
      "Train Epoch: 36 [162432/225000 (72%)] Loss: 19852.535156\n",
      "Train Epoch: 36 [164928/225000 (73%)] Loss: 20084.480469\n",
      "Train Epoch: 36 [167424/225000 (74%)] Loss: 20017.105469\n",
      "Train Epoch: 36 [169920/225000 (76%)] Loss: 21087.957031\n",
      "Train Epoch: 36 [172416/225000 (77%)] Loss: 20831.476562\n",
      "Train Epoch: 36 [174912/225000 (78%)] Loss: 20230.281250\n",
      "Train Epoch: 36 [177408/225000 (79%)] Loss: 20402.062500\n",
      "Train Epoch: 36 [179904/225000 (80%)] Loss: 19663.080078\n",
      "Train Epoch: 36 [182400/225000 (81%)] Loss: 20298.769531\n",
      "Train Epoch: 36 [184896/225000 (82%)] Loss: 20505.189453\n",
      "Train Epoch: 36 [187392/225000 (83%)] Loss: 19954.294922\n",
      "Train Epoch: 36 [189888/225000 (84%)] Loss: 19939.582031\n",
      "Train Epoch: 36 [192384/225000 (86%)] Loss: 20335.640625\n",
      "Train Epoch: 36 [194880/225000 (87%)] Loss: 20228.535156\n",
      "Train Epoch: 36 [197376/225000 (88%)] Loss: 20360.779297\n",
      "Train Epoch: 36 [199872/225000 (89%)] Loss: 19905.095703\n",
      "Train Epoch: 36 [202368/225000 (90%)] Loss: 20549.255859\n",
      "Train Epoch: 36 [204864/225000 (91%)] Loss: 20070.494141\n",
      "Train Epoch: 36 [207360/225000 (92%)] Loss: 19805.048828\n",
      "Train Epoch: 36 [209856/225000 (93%)] Loss: 20247.089844\n",
      "Train Epoch: 36 [212352/225000 (94%)] Loss: 20153.902344\n",
      "Train Epoch: 36 [214848/225000 (95%)] Loss: 20118.730469\n",
      "Train Epoch: 36 [217344/225000 (97%)] Loss: 19855.835938\n",
      "Train Epoch: 36 [219840/225000 (98%)] Loss: 20246.871094\n",
      "Train Epoch: 36 [222336/225000 (99%)] Loss: 20317.921875\n",
      "Train Epoch: 36 [224832/225000 (100%)] Loss: 19766.990234\n",
      "    epoch          : 36\n",
      "    loss           : 20305.01855302101\n",
      "    val_loss       : 20199.76046186185\n",
      "Train Epoch: 37 [192/225000 (0%)] Loss: 20503.611328\n",
      "Train Epoch: 37 [2688/225000 (1%)] Loss: 20192.191406\n",
      "Train Epoch: 37 [5184/225000 (2%)] Loss: 20315.777344\n",
      "Train Epoch: 37 [7680/225000 (3%)] Loss: 20461.535156\n",
      "Train Epoch: 37 [10176/225000 (5%)] Loss: 20686.648438\n",
      "Train Epoch: 37 [12672/225000 (6%)] Loss: 20446.470703\n",
      "Train Epoch: 37 [15168/225000 (7%)] Loss: 20480.796875\n",
      "Train Epoch: 37 [17664/225000 (8%)] Loss: 19885.986328\n",
      "Train Epoch: 37 [20160/225000 (9%)] Loss: 20583.410156\n",
      "Train Epoch: 37 [22656/225000 (10%)] Loss: 20884.144531\n",
      "Train Epoch: 37 [25152/225000 (11%)] Loss: 20426.238281\n",
      "Train Epoch: 37 [27648/225000 (12%)] Loss: 20225.906250\n",
      "Train Epoch: 37 [30144/225000 (13%)] Loss: 19765.115234\n",
      "Train Epoch: 37 [32640/225000 (15%)] Loss: 20705.808594\n",
      "Train Epoch: 37 [35136/225000 (16%)] Loss: 20406.246094\n",
      "Train Epoch: 37 [37632/225000 (17%)] Loss: 20957.812500\n",
      "Train Epoch: 37 [40128/225000 (18%)] Loss: 20181.617188\n",
      "Train Epoch: 37 [42624/225000 (19%)] Loss: 20218.210938\n",
      "Train Epoch: 37 [45120/225000 (20%)] Loss: 20152.339844\n",
      "Train Epoch: 37 [47616/225000 (21%)] Loss: 20155.429688\n",
      "Train Epoch: 37 [50112/225000 (22%)] Loss: 20112.132812\n",
      "Train Epoch: 37 [52608/225000 (23%)] Loss: 20089.992188\n",
      "Train Epoch: 37 [55104/225000 (24%)] Loss: 20186.750000\n",
      "Train Epoch: 37 [57600/225000 (26%)] Loss: 20220.441406\n",
      "Train Epoch: 37 [60096/225000 (27%)] Loss: 20210.554688\n",
      "Train Epoch: 37 [62592/225000 (28%)] Loss: 20378.541016\n",
      "Train Epoch: 37 [65088/225000 (29%)] Loss: 19951.845703\n",
      "Train Epoch: 37 [67584/225000 (30%)] Loss: 20100.042969\n",
      "Train Epoch: 37 [70080/225000 (31%)] Loss: 19712.378906\n",
      "Train Epoch: 37 [72576/225000 (32%)] Loss: 20295.943359\n",
      "Train Epoch: 37 [75072/225000 (33%)] Loss: 20589.378906\n",
      "Train Epoch: 37 [77568/225000 (34%)] Loss: 20561.328125\n",
      "Train Epoch: 37 [80064/225000 (36%)] Loss: 20347.031250\n",
      "Train Epoch: 37 [82560/225000 (37%)] Loss: 20004.687500\n",
      "Train Epoch: 37 [85056/225000 (38%)] Loss: 20190.917969\n",
      "Train Epoch: 37 [87552/225000 (39%)] Loss: 20432.691406\n",
      "Train Epoch: 37 [90048/225000 (40%)] Loss: 20112.421875\n",
      "Train Epoch: 37 [92544/225000 (41%)] Loss: 19693.203125\n",
      "Train Epoch: 37 [95040/225000 (42%)] Loss: 20292.306641\n",
      "Train Epoch: 37 [97536/225000 (43%)] Loss: 20134.925781\n",
      "Train Epoch: 37 [100032/225000 (44%)] Loss: 20333.082031\n",
      "Train Epoch: 37 [102528/225000 (46%)] Loss: 20446.515625\n",
      "Train Epoch: 37 [105024/225000 (47%)] Loss: 20011.894531\n",
      "Train Epoch: 37 [107520/225000 (48%)] Loss: 19627.398438\n",
      "Train Epoch: 37 [110016/225000 (49%)] Loss: 19931.333984\n",
      "Train Epoch: 37 [112512/225000 (50%)] Loss: 20256.128906\n",
      "Train Epoch: 37 [115008/225000 (51%)] Loss: 19976.175781\n",
      "Train Epoch: 37 [117504/225000 (52%)] Loss: 19996.718750\n",
      "Train Epoch: 37 [120000/225000 (53%)] Loss: 20557.769531\n",
      "Train Epoch: 37 [122496/225000 (54%)] Loss: 20375.738281\n",
      "Train Epoch: 37 [124992/225000 (56%)] Loss: 20328.468750\n",
      "Train Epoch: 37 [127488/225000 (57%)] Loss: 20327.613281\n",
      "Train Epoch: 37 [129984/225000 (58%)] Loss: 19964.378906\n",
      "Train Epoch: 37 [132480/225000 (59%)] Loss: 20084.298828\n",
      "Train Epoch: 37 [134976/225000 (60%)] Loss: 19779.468750\n",
      "Train Epoch: 37 [137472/225000 (61%)] Loss: 20382.970703\n",
      "Train Epoch: 37 [139968/225000 (62%)] Loss: 20304.480469\n",
      "Train Epoch: 37 [142464/225000 (63%)] Loss: 20850.416016\n",
      "Train Epoch: 37 [144960/225000 (64%)] Loss: 20558.906250\n",
      "Train Epoch: 37 [147456/225000 (66%)] Loss: 20221.335938\n",
      "Train Epoch: 37 [149952/225000 (67%)] Loss: 20764.566406\n",
      "Train Epoch: 37 [152448/225000 (68%)] Loss: 20271.296875\n",
      "Train Epoch: 37 [154944/225000 (69%)] Loss: 19978.257812\n",
      "Train Epoch: 37 [157440/225000 (70%)] Loss: 20285.292969\n",
      "Train Epoch: 37 [159936/225000 (71%)] Loss: 20110.078125\n",
      "Train Epoch: 37 [162432/225000 (72%)] Loss: 20152.878906\n",
      "Train Epoch: 37 [164928/225000 (73%)] Loss: 20381.308594\n",
      "Train Epoch: 37 [167424/225000 (74%)] Loss: 19896.591797\n",
      "Train Epoch: 37 [169920/225000 (76%)] Loss: 20693.890625\n",
      "Train Epoch: 37 [172416/225000 (77%)] Loss: 20096.496094\n",
      "Train Epoch: 37 [174912/225000 (78%)] Loss: 20621.376953\n",
      "Train Epoch: 37 [177408/225000 (79%)] Loss: 20366.935547\n",
      "Train Epoch: 37 [179904/225000 (80%)] Loss: 20311.359375\n",
      "Train Epoch: 37 [182400/225000 (81%)] Loss: 20321.718750\n",
      "Train Epoch: 37 [184896/225000 (82%)] Loss: 20614.554688\n",
      "Train Epoch: 37 [187392/225000 (83%)] Loss: 20276.539062\n",
      "Train Epoch: 37 [189888/225000 (84%)] Loss: 20234.398438\n",
      "Train Epoch: 37 [192384/225000 (86%)] Loss: 20852.806641\n",
      "Train Epoch: 37 [194880/225000 (87%)] Loss: 20348.007812\n",
      "Train Epoch: 37 [197376/225000 (88%)] Loss: 20239.542969\n",
      "Train Epoch: 37 [199872/225000 (89%)] Loss: 20569.695312\n",
      "Train Epoch: 37 [202368/225000 (90%)] Loss: 20518.390625\n",
      "Train Epoch: 37 [204864/225000 (91%)] Loss: 20309.800781\n",
      "Train Epoch: 37 [207360/225000 (92%)] Loss: 20652.718750\n",
      "Train Epoch: 37 [209856/225000 (93%)] Loss: 20408.632812\n",
      "Train Epoch: 37 [212352/225000 (94%)] Loss: 19946.074219\n",
      "Train Epoch: 37 [214848/225000 (95%)] Loss: 20365.925781\n",
      "Train Epoch: 37 [217344/225000 (97%)] Loss: 20156.261719\n",
      "Train Epoch: 37 [219840/225000 (98%)] Loss: 20220.078125\n",
      "Train Epoch: 37 [222336/225000 (99%)] Loss: 20366.974609\n",
      "Train Epoch: 37 [224832/225000 (100%)] Loss: 20388.281250\n",
      "    epoch          : 37\n",
      "    loss           : 20298.98645144518\n",
      "    val_loss       : 20195.65824703133\n",
      "Train Epoch: 38 [192/225000 (0%)] Loss: 19583.347656\n",
      "Train Epoch: 38 [2688/225000 (1%)] Loss: 20070.964844\n",
      "Train Epoch: 38 [5184/225000 (2%)] Loss: 20608.457031\n",
      "Train Epoch: 38 [7680/225000 (3%)] Loss: 20445.898438\n",
      "Train Epoch: 38 [10176/225000 (5%)] Loss: 20205.087891\n",
      "Train Epoch: 38 [12672/225000 (6%)] Loss: 20505.050781\n",
      "Train Epoch: 38 [15168/225000 (7%)] Loss: 20436.730469\n",
      "Train Epoch: 38 [17664/225000 (8%)] Loss: 20576.160156\n",
      "Train Epoch: 38 [20160/225000 (9%)] Loss: 20508.349609\n",
      "Train Epoch: 38 [22656/225000 (10%)] Loss: 19416.599609\n",
      "Train Epoch: 38 [25152/225000 (11%)] Loss: 20147.574219\n",
      "Train Epoch: 38 [27648/225000 (12%)] Loss: 20216.070312\n",
      "Train Epoch: 38 [30144/225000 (13%)] Loss: 20100.339844\n",
      "Train Epoch: 38 [32640/225000 (15%)] Loss: 20207.607422\n",
      "Train Epoch: 38 [35136/225000 (16%)] Loss: 20362.648438\n",
      "Train Epoch: 38 [37632/225000 (17%)] Loss: 20325.312500\n",
      "Train Epoch: 38 [40128/225000 (18%)] Loss: 20489.925781\n",
      "Train Epoch: 38 [42624/225000 (19%)] Loss: 20201.660156\n",
      "Train Epoch: 38 [45120/225000 (20%)] Loss: 20325.453125\n",
      "Train Epoch: 38 [47616/225000 (21%)] Loss: 20056.128906\n",
      "Train Epoch: 38 [50112/225000 (22%)] Loss: 20585.296875\n",
      "Train Epoch: 38 [52608/225000 (23%)] Loss: 19841.914062\n",
      "Train Epoch: 38 [55104/225000 (24%)] Loss: 20058.816406\n",
      "Train Epoch: 38 [57600/225000 (26%)] Loss: 20731.710938\n",
      "Train Epoch: 38 [60096/225000 (27%)] Loss: 20090.373047\n",
      "Train Epoch: 38 [62592/225000 (28%)] Loss: 20794.707031\n",
      "Train Epoch: 38 [65088/225000 (29%)] Loss: 20235.929688\n",
      "Train Epoch: 38 [67584/225000 (30%)] Loss: 20631.369141\n",
      "Train Epoch: 38 [70080/225000 (31%)] Loss: 20313.216797\n",
      "Train Epoch: 38 [72576/225000 (32%)] Loss: 20084.117188\n",
      "Train Epoch: 38 [75072/225000 (33%)] Loss: 20381.082031\n",
      "Train Epoch: 38 [77568/225000 (34%)] Loss: 19845.384766\n",
      "Train Epoch: 38 [80064/225000 (36%)] Loss: 20452.888672\n",
      "Train Epoch: 38 [82560/225000 (37%)] Loss: 20794.117188\n",
      "Train Epoch: 38 [85056/225000 (38%)] Loss: 20261.162109\n",
      "Train Epoch: 38 [87552/225000 (39%)] Loss: 20329.156250\n",
      "Train Epoch: 38 [90048/225000 (40%)] Loss: 20364.082031\n",
      "Train Epoch: 38 [92544/225000 (41%)] Loss: 20226.390625\n",
      "Train Epoch: 38 [95040/225000 (42%)] Loss: 20450.361328\n",
      "Train Epoch: 38 [97536/225000 (43%)] Loss: 19933.376953\n",
      "Train Epoch: 38 [100032/225000 (44%)] Loss: 20031.673828\n",
      "Train Epoch: 38 [102528/225000 (46%)] Loss: 20029.164062\n",
      "Train Epoch: 38 [105024/225000 (47%)] Loss: 20501.886719\n",
      "Train Epoch: 38 [107520/225000 (48%)] Loss: 20358.994141\n",
      "Train Epoch: 38 [110016/225000 (49%)] Loss: 20668.730469\n",
      "Train Epoch: 38 [112512/225000 (50%)] Loss: 20178.167969\n",
      "Train Epoch: 38 [115008/225000 (51%)] Loss: 20117.355469\n",
      "Train Epoch: 38 [117504/225000 (52%)] Loss: 20633.816406\n",
      "Train Epoch: 38 [120000/225000 (53%)] Loss: 20381.052734\n",
      "Train Epoch: 38 [122496/225000 (54%)] Loss: 20561.685547\n",
      "Train Epoch: 38 [124992/225000 (56%)] Loss: 19874.662109\n",
      "Train Epoch: 38 [127488/225000 (57%)] Loss: 20422.740234\n",
      "Train Epoch: 38 [129984/225000 (58%)] Loss: 20035.242188\n",
      "Train Epoch: 38 [132480/225000 (59%)] Loss: 20704.398438\n",
      "Train Epoch: 38 [134976/225000 (60%)] Loss: 20231.365234\n",
      "Train Epoch: 38 [137472/225000 (61%)] Loss: 20647.335938\n",
      "Train Epoch: 38 [139968/225000 (62%)] Loss: 19931.832031\n",
      "Train Epoch: 38 [142464/225000 (63%)] Loss: 20416.283203\n",
      "Train Epoch: 38 [144960/225000 (64%)] Loss: 20645.605469\n",
      "Train Epoch: 38 [147456/225000 (66%)] Loss: 20427.382812\n",
      "Train Epoch: 38 [149952/225000 (67%)] Loss: 20252.314453\n",
      "Train Epoch: 38 [152448/225000 (68%)] Loss: 20063.029297\n",
      "Train Epoch: 38 [154944/225000 (69%)] Loss: 20051.314453\n",
      "Train Epoch: 38 [157440/225000 (70%)] Loss: 19996.320312\n",
      "Train Epoch: 38 [159936/225000 (71%)] Loss: 20038.175781\n",
      "Train Epoch: 38 [162432/225000 (72%)] Loss: 19911.554688\n",
      "Train Epoch: 38 [164928/225000 (73%)] Loss: 20327.347656\n",
      "Train Epoch: 38 [167424/225000 (74%)] Loss: 20125.111328\n",
      "Train Epoch: 38 [169920/225000 (76%)] Loss: 20940.296875\n",
      "Train Epoch: 38 [172416/225000 (77%)] Loss: 20526.585938\n",
      "Train Epoch: 38 [174912/225000 (78%)] Loss: 20422.611328\n",
      "Train Epoch: 38 [177408/225000 (79%)] Loss: 20431.656250\n",
      "Train Epoch: 38 [179904/225000 (80%)] Loss: 20142.148438\n",
      "Train Epoch: 38 [182400/225000 (81%)] Loss: 20391.541016\n",
      "Train Epoch: 38 [184896/225000 (82%)] Loss: 20182.222656\n",
      "Train Epoch: 38 [187392/225000 (83%)] Loss: 19916.820312\n",
      "Train Epoch: 38 [189888/225000 (84%)] Loss: 20537.666016\n",
      "Train Epoch: 38 [192384/225000 (86%)] Loss: 20201.015625\n",
      "Train Epoch: 38 [194880/225000 (87%)] Loss: 20434.232422\n",
      "Train Epoch: 38 [197376/225000 (88%)] Loss: 20482.611328\n",
      "Train Epoch: 38 [199872/225000 (89%)] Loss: 20341.878906\n",
      "Train Epoch: 38 [202368/225000 (90%)] Loss: 20963.757812\n",
      "Train Epoch: 38 [204864/225000 (91%)] Loss: 20228.818359\n",
      "Train Epoch: 38 [207360/225000 (92%)] Loss: 20079.828125\n",
      "Train Epoch: 38 [209856/225000 (93%)] Loss: 20297.812500\n",
      "Train Epoch: 38 [212352/225000 (94%)] Loss: 19923.890625\n",
      "Train Epoch: 38 [214848/225000 (95%)] Loss: 20293.925781\n",
      "Train Epoch: 38 [217344/225000 (97%)] Loss: 20143.339844\n",
      "Train Epoch: 38 [219840/225000 (98%)] Loss: 20272.953125\n",
      "Train Epoch: 38 [222336/225000 (99%)] Loss: 20221.691406\n",
      "Train Epoch: 38 [224832/225000 (100%)] Loss: 19941.369141\n",
      "    epoch          : 38\n",
      "    loss           : 20290.278057007254\n",
      "    val_loss       : 20188.35770404657\n",
      "Train Epoch: 39 [192/225000 (0%)] Loss: 20582.941406\n",
      "Train Epoch: 39 [2688/225000 (1%)] Loss: 20618.697266\n",
      "Train Epoch: 39 [5184/225000 (2%)] Loss: 20223.890625\n",
      "Train Epoch: 39 [7680/225000 (3%)] Loss: 20581.441406\n",
      "Train Epoch: 39 [10176/225000 (5%)] Loss: 20259.875000\n",
      "Train Epoch: 39 [12672/225000 (6%)] Loss: 20919.144531\n",
      "Train Epoch: 39 [15168/225000 (7%)] Loss: 20472.207031\n",
      "Train Epoch: 39 [17664/225000 (8%)] Loss: 20002.261719\n",
      "Train Epoch: 39 [20160/225000 (9%)] Loss: 20384.972656\n",
      "Train Epoch: 39 [22656/225000 (10%)] Loss: 20559.542969\n",
      "Train Epoch: 39 [25152/225000 (11%)] Loss: 20116.183594\n",
      "Train Epoch: 39 [27648/225000 (12%)] Loss: 20288.386719\n",
      "Train Epoch: 39 [30144/225000 (13%)] Loss: 20023.591797\n",
      "Train Epoch: 39 [32640/225000 (15%)] Loss: 20138.367188\n",
      "Train Epoch: 39 [35136/225000 (16%)] Loss: 20657.345703\n",
      "Train Epoch: 39 [37632/225000 (17%)] Loss: 20427.763672\n",
      "Train Epoch: 39 [40128/225000 (18%)] Loss: 19746.970703\n",
      "Train Epoch: 39 [42624/225000 (19%)] Loss: 20404.914062\n",
      "Train Epoch: 39 [45120/225000 (20%)] Loss: 20592.314453\n",
      "Train Epoch: 39 [47616/225000 (21%)] Loss: 20258.566406\n",
      "Train Epoch: 39 [50112/225000 (22%)] Loss: 20138.673828\n",
      "Train Epoch: 39 [52608/225000 (23%)] Loss: 20140.902344\n",
      "Train Epoch: 39 [55104/225000 (24%)] Loss: 20509.923828\n",
      "Train Epoch: 39 [57600/225000 (26%)] Loss: 20323.425781\n",
      "Train Epoch: 39 [60096/225000 (27%)] Loss: 20372.464844\n",
      "Train Epoch: 39 [62592/225000 (28%)] Loss: 20843.923828\n",
      "Train Epoch: 39 [65088/225000 (29%)] Loss: 20583.394531\n",
      "Train Epoch: 39 [67584/225000 (30%)] Loss: 20552.367188\n",
      "Train Epoch: 39 [70080/225000 (31%)] Loss: 20268.566406\n",
      "Train Epoch: 39 [72576/225000 (32%)] Loss: 20015.968750\n",
      "Train Epoch: 39 [75072/225000 (33%)] Loss: 20272.515625\n",
      "Train Epoch: 39 [77568/225000 (34%)] Loss: 20099.466797\n",
      "Train Epoch: 39 [80064/225000 (36%)] Loss: 20516.160156\n",
      "Train Epoch: 39 [82560/225000 (37%)] Loss: 20426.625000\n",
      "Train Epoch: 39 [85056/225000 (38%)] Loss: 20655.207031\n",
      "Train Epoch: 39 [87552/225000 (39%)] Loss: 20318.324219\n",
      "Train Epoch: 39 [90048/225000 (40%)] Loss: 20263.980469\n",
      "Train Epoch: 39 [92544/225000 (41%)] Loss: 20314.500000\n",
      "Train Epoch: 39 [95040/225000 (42%)] Loss: 20099.849609\n",
      "Train Epoch: 39 [97536/225000 (43%)] Loss: 20235.273438\n",
      "Train Epoch: 39 [100032/225000 (44%)] Loss: 20178.371094\n",
      "Train Epoch: 39 [102528/225000 (46%)] Loss: 20238.046875\n",
      "Train Epoch: 39 [105024/225000 (47%)] Loss: 20875.679688\n",
      "Train Epoch: 39 [107520/225000 (48%)] Loss: 20765.902344\n",
      "Train Epoch: 39 [110016/225000 (49%)] Loss: 20075.447266\n",
      "Train Epoch: 39 [112512/225000 (50%)] Loss: 19459.626953\n",
      "Train Epoch: 39 [115008/225000 (51%)] Loss: 20466.953125\n",
      "Train Epoch: 39 [117504/225000 (52%)] Loss: 20404.796875\n",
      "Train Epoch: 39 [120000/225000 (53%)] Loss: 20487.878906\n",
      "Train Epoch: 39 [122496/225000 (54%)] Loss: 20092.468750\n",
      "Train Epoch: 39 [124992/225000 (56%)] Loss: 20577.724609\n",
      "Train Epoch: 39 [127488/225000 (57%)] Loss: 20399.298828\n",
      "Train Epoch: 39 [129984/225000 (58%)] Loss: 19898.943359\n",
      "Train Epoch: 39 [132480/225000 (59%)] Loss: 20510.646484\n",
      "Train Epoch: 39 [134976/225000 (60%)] Loss: 20034.814453\n",
      "Train Epoch: 39 [137472/225000 (61%)] Loss: 20159.429688\n",
      "Train Epoch: 39 [139968/225000 (62%)] Loss: 20239.164062\n",
      "Train Epoch: 39 [142464/225000 (63%)] Loss: 20088.378906\n",
      "Train Epoch: 39 [144960/225000 (64%)] Loss: 19934.242188\n",
      "Train Epoch: 39 [147456/225000 (66%)] Loss: 20273.285156\n",
      "Train Epoch: 39 [149952/225000 (67%)] Loss: 19959.019531\n",
      "Train Epoch: 39 [152448/225000 (68%)] Loss: 20209.892578\n",
      "Train Epoch: 39 [154944/225000 (69%)] Loss: 19438.136719\n",
      "Train Epoch: 39 [157440/225000 (70%)] Loss: 20233.691406\n",
      "Train Epoch: 39 [159936/225000 (71%)] Loss: 19970.226562\n",
      "Train Epoch: 39 [162432/225000 (72%)] Loss: 20039.367188\n",
      "Train Epoch: 39 [164928/225000 (73%)] Loss: 19797.599609\n",
      "Train Epoch: 39 [167424/225000 (74%)] Loss: 19653.593750\n",
      "Train Epoch: 39 [169920/225000 (76%)] Loss: 20373.212891\n",
      "Train Epoch: 39 [172416/225000 (77%)] Loss: 20188.500000\n",
      "Train Epoch: 39 [174912/225000 (78%)] Loss: 20252.289062\n",
      "Train Epoch: 39 [177408/225000 (79%)] Loss: 20002.328125\n",
      "Train Epoch: 39 [179904/225000 (80%)] Loss: 20618.197266\n",
      "Train Epoch: 39 [182400/225000 (81%)] Loss: 20705.226562\n",
      "Train Epoch: 39 [184896/225000 (82%)] Loss: 19962.097656\n",
      "Train Epoch: 39 [187392/225000 (83%)] Loss: 19959.539062\n",
      "Train Epoch: 39 [189888/225000 (84%)] Loss: 20739.488281\n",
      "Train Epoch: 39 [192384/225000 (86%)] Loss: 20567.167969\n",
      "Train Epoch: 39 [194880/225000 (87%)] Loss: 20435.417969\n",
      "Train Epoch: 39 [197376/225000 (88%)] Loss: 20297.162109\n",
      "Train Epoch: 39 [199872/225000 (89%)] Loss: 19751.236328\n",
      "Train Epoch: 39 [202368/225000 (90%)] Loss: 20517.544922\n",
      "Train Epoch: 39 [204864/225000 (91%)] Loss: 20677.601562\n",
      "Train Epoch: 39 [207360/225000 (92%)] Loss: 20167.691406\n",
      "Train Epoch: 39 [209856/225000 (93%)] Loss: 20539.117188\n",
      "Train Epoch: 39 [212352/225000 (94%)] Loss: 20204.792969\n",
      "Train Epoch: 39 [214848/225000 (95%)] Loss: 20173.593750\n",
      "Train Epoch: 39 [217344/225000 (97%)] Loss: 19858.156250\n",
      "Train Epoch: 39 [219840/225000 (98%)] Loss: 20277.519531\n",
      "Train Epoch: 39 [222336/225000 (99%)] Loss: 19926.281250\n",
      "Train Epoch: 39 [224832/225000 (100%)] Loss: 20439.076172\n",
      "    epoch          : 39\n",
      "    loss           : 20278.391638225257\n",
      "    val_loss       : 20179.79235273827\n",
      "Train Epoch: 40 [192/225000 (0%)] Loss: 20446.001953\n",
      "Train Epoch: 40 [2688/225000 (1%)] Loss: 20672.347656\n",
      "Train Epoch: 40 [5184/225000 (2%)] Loss: 20133.156250\n",
      "Train Epoch: 40 [7680/225000 (3%)] Loss: 20039.855469\n",
      "Train Epoch: 40 [10176/225000 (5%)] Loss: 20436.507812\n",
      "Train Epoch: 40 [12672/225000 (6%)] Loss: 19879.556641\n",
      "Train Epoch: 40 [15168/225000 (7%)] Loss: 20105.070312\n",
      "Train Epoch: 40 [17664/225000 (8%)] Loss: 20055.300781\n",
      "Train Epoch: 40 [20160/225000 (9%)] Loss: 20352.007812\n",
      "Train Epoch: 40 [22656/225000 (10%)] Loss: 20207.171875\n",
      "Train Epoch: 40 [25152/225000 (11%)] Loss: 20880.167969\n",
      "Train Epoch: 40 [27648/225000 (12%)] Loss: 20240.894531\n",
      "Train Epoch: 40 [30144/225000 (13%)] Loss: 20340.757812\n",
      "Train Epoch: 40 [32640/225000 (15%)] Loss: 20019.472656\n",
      "Train Epoch: 40 [35136/225000 (16%)] Loss: 20401.843750\n",
      "Train Epoch: 40 [37632/225000 (17%)] Loss: 20528.792969\n",
      "Train Epoch: 40 [40128/225000 (18%)] Loss: 20968.023438\n",
      "Train Epoch: 40 [42624/225000 (19%)] Loss: 20525.468750\n",
      "Train Epoch: 40 [45120/225000 (20%)] Loss: 20996.371094\n",
      "Train Epoch: 40 [47616/225000 (21%)] Loss: 20430.929688\n",
      "Train Epoch: 40 [50112/225000 (22%)] Loss: 20561.820312\n",
      "Train Epoch: 40 [52608/225000 (23%)] Loss: 19976.273438\n",
      "Train Epoch: 40 [55104/225000 (24%)] Loss: 20106.212891\n",
      "Train Epoch: 40 [57600/225000 (26%)] Loss: 19919.664062\n",
      "Train Epoch: 40 [60096/225000 (27%)] Loss: 19944.539062\n",
      "Train Epoch: 40 [62592/225000 (28%)] Loss: 19916.148438\n",
      "Train Epoch: 40 [65088/225000 (29%)] Loss: 20173.539062\n",
      "Train Epoch: 40 [67584/225000 (30%)] Loss: 20490.431641\n",
      "Train Epoch: 40 [70080/225000 (31%)] Loss: 19939.906250\n",
      "Train Epoch: 40 [72576/225000 (32%)] Loss: 19980.601562\n",
      "Train Epoch: 40 [75072/225000 (33%)] Loss: 20552.332031\n",
      "Train Epoch: 40 [77568/225000 (34%)] Loss: 19968.347656\n",
      "Train Epoch: 40 [80064/225000 (36%)] Loss: 20104.832031\n",
      "Train Epoch: 40 [82560/225000 (37%)] Loss: 20180.642578\n",
      "Train Epoch: 40 [85056/225000 (38%)] Loss: 20405.392578\n",
      "Train Epoch: 40 [87552/225000 (39%)] Loss: 20493.511719\n",
      "Train Epoch: 40 [90048/225000 (40%)] Loss: 20604.894531\n",
      "Train Epoch: 40 [92544/225000 (41%)] Loss: 20451.734375\n",
      "Train Epoch: 40 [95040/225000 (42%)] Loss: 20032.859375\n",
      "Train Epoch: 40 [97536/225000 (43%)] Loss: 19911.562500\n",
      "Train Epoch: 40 [100032/225000 (44%)] Loss: 20573.203125\n",
      "Train Epoch: 40 [102528/225000 (46%)] Loss: 20292.101562\n",
      "Train Epoch: 40 [105024/225000 (47%)] Loss: 20793.968750\n",
      "Train Epoch: 40 [107520/225000 (48%)] Loss: 20539.761719\n",
      "Train Epoch: 40 [110016/225000 (49%)] Loss: 20437.148438\n",
      "Train Epoch: 40 [112512/225000 (50%)] Loss: 20273.503906\n",
      "Train Epoch: 40 [115008/225000 (51%)] Loss: 20670.390625\n",
      "Train Epoch: 40 [117504/225000 (52%)] Loss: 19954.007812\n",
      "Train Epoch: 40 [120000/225000 (53%)] Loss: 20226.796875\n",
      "Train Epoch: 40 [122496/225000 (54%)] Loss: 20597.648438\n",
      "Train Epoch: 40 [124992/225000 (56%)] Loss: 20353.089844\n",
      "Train Epoch: 40 [127488/225000 (57%)] Loss: 19950.111328\n",
      "Train Epoch: 40 [129984/225000 (58%)] Loss: 20139.699219\n",
      "Train Epoch: 40 [132480/225000 (59%)] Loss: 20017.101562\n",
      "Train Epoch: 40 [134976/225000 (60%)] Loss: 20444.066406\n",
      "Train Epoch: 40 [137472/225000 (61%)] Loss: 19965.113281\n",
      "Train Epoch: 40 [139968/225000 (62%)] Loss: 20406.742188\n",
      "Train Epoch: 40 [142464/225000 (63%)] Loss: 20164.066406\n",
      "Train Epoch: 40 [144960/225000 (64%)] Loss: 20403.734375\n",
      "Train Epoch: 40 [147456/225000 (66%)] Loss: 20878.388672\n",
      "Train Epoch: 40 [149952/225000 (67%)] Loss: 19772.843750\n",
      "Train Epoch: 40 [152448/225000 (68%)] Loss: 20222.816406\n",
      "Train Epoch: 40 [154944/225000 (69%)] Loss: 20329.765625\n",
      "Train Epoch: 40 [157440/225000 (70%)] Loss: 20527.294922\n",
      "Train Epoch: 40 [159936/225000 (71%)] Loss: 20385.791016\n",
      "Train Epoch: 40 [162432/225000 (72%)] Loss: 21161.863281\n",
      "Train Epoch: 40 [164928/225000 (73%)] Loss: 20018.146484\n",
      "Train Epoch: 40 [167424/225000 (74%)] Loss: 20141.423828\n",
      "Train Epoch: 40 [169920/225000 (76%)] Loss: 20695.748047\n",
      "Train Epoch: 40 [172416/225000 (77%)] Loss: 20167.441406\n",
      "Train Epoch: 40 [174912/225000 (78%)] Loss: 20067.941406\n",
      "Train Epoch: 40 [177408/225000 (79%)] Loss: 20185.988281\n",
      "Train Epoch: 40 [179904/225000 (80%)] Loss: 20312.164062\n",
      "Train Epoch: 40 [182400/225000 (81%)] Loss: 20032.214844\n",
      "Train Epoch: 40 [184896/225000 (82%)] Loss: 20254.966797\n",
      "Train Epoch: 40 [187392/225000 (83%)] Loss: 20158.792969\n",
      "Train Epoch: 40 [189888/225000 (84%)] Loss: 20102.947266\n",
      "Train Epoch: 40 [192384/225000 (86%)] Loss: 20317.880859\n",
      "Train Epoch: 40 [194880/225000 (87%)] Loss: 20082.289062\n",
      "Train Epoch: 40 [197376/225000 (88%)] Loss: 19910.201172\n",
      "Train Epoch: 40 [199872/225000 (89%)] Loss: 20218.955078\n",
      "Train Epoch: 40 [202368/225000 (90%)] Loss: 20252.166016\n",
      "Train Epoch: 40 [204864/225000 (91%)] Loss: 20344.808594\n",
      "Train Epoch: 40 [207360/225000 (92%)] Loss: 19830.320312\n",
      "Train Epoch: 40 [209856/225000 (93%)] Loss: 20348.566406\n",
      "Train Epoch: 40 [212352/225000 (94%)] Loss: 20726.841797\n",
      "Train Epoch: 40 [214848/225000 (95%)] Loss: 20345.523438\n",
      "Train Epoch: 40 [217344/225000 (97%)] Loss: 20102.445312\n",
      "Train Epoch: 40 [219840/225000 (98%)] Loss: 19878.156250\n",
      "Train Epoch: 40 [222336/225000 (99%)] Loss: 20048.832031\n",
      "Train Epoch: 40 [224832/225000 (100%)] Loss: 20259.466797\n",
      "    epoch          : 40\n",
      "    loss           : 20279.51551501173\n",
      "    val_loss       : 20183.991216839724\n",
      "Train Epoch: 41 [192/225000 (0%)] Loss: 19533.550781\n",
      "Train Epoch: 41 [2688/225000 (1%)] Loss: 20289.619141\n",
      "Train Epoch: 41 [5184/225000 (2%)] Loss: 20510.058594\n",
      "Train Epoch: 41 [7680/225000 (3%)] Loss: 20561.031250\n",
      "Train Epoch: 41 [10176/225000 (5%)] Loss: 20668.210938\n",
      "Train Epoch: 41 [12672/225000 (6%)] Loss: 20945.800781\n",
      "Train Epoch: 41 [15168/225000 (7%)] Loss: 20113.976562\n",
      "Train Epoch: 41 [17664/225000 (8%)] Loss: 19963.841797\n",
      "Train Epoch: 41 [20160/225000 (9%)] Loss: 20078.816406\n",
      "Train Epoch: 41 [22656/225000 (10%)] Loss: 20082.683594\n",
      "Train Epoch: 41 [25152/225000 (11%)] Loss: 20335.683594\n",
      "Train Epoch: 41 [27648/225000 (12%)] Loss: 20765.191406\n",
      "Train Epoch: 41 [30144/225000 (13%)] Loss: 20278.865234\n",
      "Train Epoch: 41 [32640/225000 (15%)] Loss: 20303.914062\n",
      "Train Epoch: 41 [35136/225000 (16%)] Loss: 19991.230469\n",
      "Train Epoch: 41 [37632/225000 (17%)] Loss: 20088.720703\n",
      "Train Epoch: 41 [40128/225000 (18%)] Loss: 20252.253906\n",
      "Train Epoch: 41 [42624/225000 (19%)] Loss: 20226.988281\n",
      "Train Epoch: 41 [45120/225000 (20%)] Loss: 20173.349609\n",
      "Train Epoch: 41 [47616/225000 (21%)] Loss: 19720.724609\n",
      "Train Epoch: 41 [50112/225000 (22%)] Loss: 20365.972656\n",
      "Train Epoch: 41 [52608/225000 (23%)] Loss: 20349.746094\n",
      "Train Epoch: 41 [55104/225000 (24%)] Loss: 20792.136719\n",
      "Train Epoch: 41 [57600/225000 (26%)] Loss: 20396.578125\n",
      "Train Epoch: 41 [60096/225000 (27%)] Loss: 19771.023438\n",
      "Train Epoch: 41 [62592/225000 (28%)] Loss: 19734.697266\n",
      "Train Epoch: 41 [65088/225000 (29%)] Loss: 20656.218750\n",
      "Train Epoch: 41 [67584/225000 (30%)] Loss: 20633.701172\n",
      "Train Epoch: 41 [70080/225000 (31%)] Loss: 20279.273438\n",
      "Train Epoch: 41 [72576/225000 (32%)] Loss: 19737.765625\n",
      "Train Epoch: 41 [75072/225000 (33%)] Loss: 20308.886719\n",
      "Train Epoch: 41 [77568/225000 (34%)] Loss: 20029.414062\n",
      "Train Epoch: 41 [80064/225000 (36%)] Loss: 20642.435547\n",
      "Train Epoch: 41 [82560/225000 (37%)] Loss: 19865.244141\n",
      "Train Epoch: 41 [85056/225000 (38%)] Loss: 20410.675781\n",
      "Train Epoch: 41 [87552/225000 (39%)] Loss: 20361.589844\n",
      "Train Epoch: 41 [90048/225000 (40%)] Loss: 20176.316406\n",
      "Train Epoch: 41 [92544/225000 (41%)] Loss: 20615.871094\n",
      "Train Epoch: 41 [95040/225000 (42%)] Loss: 20479.746094\n",
      "Train Epoch: 41 [97536/225000 (43%)] Loss: 20371.222656\n",
      "Train Epoch: 41 [100032/225000 (44%)] Loss: 20189.939453\n",
      "Train Epoch: 41 [102528/225000 (46%)] Loss: 20404.128906\n",
      "Train Epoch: 41 [105024/225000 (47%)] Loss: 20103.015625\n",
      "Train Epoch: 41 [107520/225000 (48%)] Loss: 20157.115234\n",
      "Train Epoch: 41 [110016/225000 (49%)] Loss: 20494.914062\n",
      "Train Epoch: 41 [112512/225000 (50%)] Loss: 20337.488281\n",
      "Train Epoch: 41 [115008/225000 (51%)] Loss: 20333.974609\n",
      "Train Epoch: 41 [117504/225000 (52%)] Loss: 19834.832031\n",
      "Train Epoch: 41 [120000/225000 (53%)] Loss: 20134.738281\n",
      "Train Epoch: 41 [122496/225000 (54%)] Loss: 20078.964844\n",
      "Train Epoch: 41 [124992/225000 (56%)] Loss: 20724.539062\n",
      "Train Epoch: 41 [127488/225000 (57%)] Loss: 20097.558594\n",
      "Train Epoch: 41 [129984/225000 (58%)] Loss: 20070.710938\n",
      "Train Epoch: 41 [132480/225000 (59%)] Loss: 19818.992188\n",
      "Train Epoch: 41 [134976/225000 (60%)] Loss: 20503.562500\n",
      "Train Epoch: 41 [137472/225000 (61%)] Loss: 20217.253906\n",
      "Train Epoch: 41 [139968/225000 (62%)] Loss: 19962.972656\n",
      "Train Epoch: 41 [142464/225000 (63%)] Loss: 20334.011719\n",
      "Train Epoch: 41 [144960/225000 (64%)] Loss: 20289.701172\n",
      "Train Epoch: 41 [147456/225000 (66%)] Loss: 20188.392578\n",
      "Train Epoch: 41 [149952/225000 (67%)] Loss: 20365.876953\n",
      "Train Epoch: 41 [152448/225000 (68%)] Loss: 19956.585938\n",
      "Train Epoch: 41 [154944/225000 (69%)] Loss: 19910.074219\n",
      "Train Epoch: 41 [157440/225000 (70%)] Loss: 19937.402344\n",
      "Train Epoch: 41 [159936/225000 (71%)] Loss: 20595.691406\n",
      "Train Epoch: 41 [162432/225000 (72%)] Loss: 20266.910156\n",
      "Train Epoch: 41 [164928/225000 (73%)] Loss: 20664.726562\n",
      "Train Epoch: 41 [167424/225000 (74%)] Loss: 20277.023438\n",
      "Train Epoch: 41 [169920/225000 (76%)] Loss: 20841.968750\n",
      "Train Epoch: 41 [172416/225000 (77%)] Loss: 20435.414062\n",
      "Train Epoch: 41 [174912/225000 (78%)] Loss: 20318.250000\n",
      "Train Epoch: 41 [177408/225000 (79%)] Loss: 20397.173828\n",
      "Train Epoch: 41 [179904/225000 (80%)] Loss: 19863.183594\n",
      "Train Epoch: 41 [182400/225000 (81%)] Loss: 20445.265625\n",
      "Train Epoch: 41 [184896/225000 (82%)] Loss: 19819.511719\n",
      "Train Epoch: 41 [187392/225000 (83%)] Loss: 20267.207031\n",
      "Train Epoch: 41 [189888/225000 (84%)] Loss: 19876.076172\n",
      "Train Epoch: 41 [192384/225000 (86%)] Loss: 20014.046875\n",
      "Train Epoch: 41 [194880/225000 (87%)] Loss: 20070.414062\n",
      "Train Epoch: 41 [197376/225000 (88%)] Loss: 20380.769531\n",
      "Train Epoch: 41 [199872/225000 (89%)] Loss: 20316.726562\n",
      "Train Epoch: 41 [202368/225000 (90%)] Loss: 20246.103516\n",
      "Train Epoch: 41 [204864/225000 (91%)] Loss: 20503.007812\n",
      "Train Epoch: 41 [207360/225000 (92%)] Loss: 20248.613281\n",
      "Train Epoch: 41 [209856/225000 (93%)] Loss: 20288.998047\n",
      "Train Epoch: 41 [212352/225000 (94%)] Loss: 20019.900391\n",
      "Train Epoch: 41 [214848/225000 (95%)] Loss: 20741.289062\n",
      "Train Epoch: 41 [217344/225000 (97%)] Loss: 20587.523438\n",
      "Train Epoch: 41 [219840/225000 (98%)] Loss: 20135.292969\n",
      "Train Epoch: 41 [222336/225000 (99%)] Loss: 20102.007812\n",
      "Train Epoch: 41 [224832/225000 (100%)] Loss: 20416.300781\n",
      "    epoch          : 41\n",
      "    loss           : 20276.080719723228\n",
      "    val_loss       : 20172.98808616764\n",
      "Train Epoch: 42 [192/225000 (0%)] Loss: 20180.837891\n",
      "Train Epoch: 42 [2688/225000 (1%)] Loss: 20664.298828\n",
      "Train Epoch: 42 [5184/225000 (2%)] Loss: 20620.875000\n",
      "Train Epoch: 42 [7680/225000 (3%)] Loss: 20525.468750\n",
      "Train Epoch: 42 [10176/225000 (5%)] Loss: 20226.478516\n",
      "Train Epoch: 42 [12672/225000 (6%)] Loss: 20480.757812\n",
      "Train Epoch: 42 [15168/225000 (7%)] Loss: 19735.064453\n",
      "Train Epoch: 42 [17664/225000 (8%)] Loss: 20599.527344\n",
      "Train Epoch: 42 [20160/225000 (9%)] Loss: 20565.546875\n",
      "Train Epoch: 42 [22656/225000 (10%)] Loss: 20039.742188\n",
      "Train Epoch: 42 [25152/225000 (11%)] Loss: 19960.500000\n",
      "Train Epoch: 42 [27648/225000 (12%)] Loss: 20127.460938\n",
      "Train Epoch: 42 [30144/225000 (13%)] Loss: 19946.994141\n",
      "Train Epoch: 42 [32640/225000 (15%)] Loss: 20333.800781\n",
      "Train Epoch: 42 [35136/225000 (16%)] Loss: 20012.578125\n",
      "Train Epoch: 42 [37632/225000 (17%)] Loss: 20023.886719\n",
      "Train Epoch: 42 [40128/225000 (18%)] Loss: 20526.738281\n",
      "Train Epoch: 42 [42624/225000 (19%)] Loss: 20497.523438\n",
      "Train Epoch: 42 [45120/225000 (20%)] Loss: 19707.718750\n",
      "Train Epoch: 42 [47616/225000 (21%)] Loss: 20320.070312\n",
      "Train Epoch: 42 [50112/225000 (22%)] Loss: 19959.359375\n",
      "Train Epoch: 42 [52608/225000 (23%)] Loss: 20248.675781\n",
      "Train Epoch: 42 [55104/225000 (24%)] Loss: 20115.589844\n",
      "Train Epoch: 42 [57600/225000 (26%)] Loss: 20184.648438\n",
      "Train Epoch: 42 [60096/225000 (27%)] Loss: 20320.970703\n",
      "Train Epoch: 42 [62592/225000 (28%)] Loss: 20579.636719\n",
      "Train Epoch: 42 [65088/225000 (29%)] Loss: 20086.531250\n",
      "Train Epoch: 42 [67584/225000 (30%)] Loss: 20550.480469\n",
      "Train Epoch: 42 [70080/225000 (31%)] Loss: 20511.210938\n",
      "Train Epoch: 42 [72576/225000 (32%)] Loss: 20242.390625\n",
      "Train Epoch: 42 [75072/225000 (33%)] Loss: 20326.837891\n",
      "Train Epoch: 42 [77568/225000 (34%)] Loss: 20294.785156\n",
      "Train Epoch: 42 [80064/225000 (36%)] Loss: 19649.972656\n",
      "Train Epoch: 42 [82560/225000 (37%)] Loss: 19718.851562\n",
      "Train Epoch: 42 [85056/225000 (38%)] Loss: 20215.421875\n",
      "Train Epoch: 42 [87552/225000 (39%)] Loss: 20243.804688\n",
      "Train Epoch: 42 [90048/225000 (40%)] Loss: 20359.394531\n",
      "Train Epoch: 42 [92544/225000 (41%)] Loss: 19911.185547\n",
      "Train Epoch: 42 [95040/225000 (42%)] Loss: 19879.308594\n",
      "Train Epoch: 42 [97536/225000 (43%)] Loss: 20268.339844\n",
      "Train Epoch: 42 [100032/225000 (44%)] Loss: 20838.484375\n",
      "Train Epoch: 42 [102528/225000 (46%)] Loss: 20720.197266\n",
      "Train Epoch: 42 [105024/225000 (47%)] Loss: 19858.226562\n",
      "Train Epoch: 42 [107520/225000 (48%)] Loss: 20087.320312\n",
      "Train Epoch: 42 [110016/225000 (49%)] Loss: 20039.863281\n",
      "Train Epoch: 42 [112512/225000 (50%)] Loss: 19928.160156\n",
      "Train Epoch: 42 [115008/225000 (51%)] Loss: 20277.242188\n",
      "Train Epoch: 42 [117504/225000 (52%)] Loss: 20191.574219\n",
      "Train Epoch: 42 [120000/225000 (53%)] Loss: 20247.367188\n",
      "Train Epoch: 42 [122496/225000 (54%)] Loss: 20462.406250\n",
      "Train Epoch: 42 [124992/225000 (56%)] Loss: 20323.691406\n",
      "Train Epoch: 42 [127488/225000 (57%)] Loss: 19912.468750\n",
      "Train Epoch: 42 [129984/225000 (58%)] Loss: 20154.417969\n",
      "Train Epoch: 42 [132480/225000 (59%)] Loss: 20175.398438\n",
      "Train Epoch: 42 [134976/225000 (60%)] Loss: 20217.468750\n",
      "Train Epoch: 42 [137472/225000 (61%)] Loss: 20167.445312\n",
      "Train Epoch: 42 [139968/225000 (62%)] Loss: 20317.542969\n",
      "Train Epoch: 42 [142464/225000 (63%)] Loss: 20231.472656\n",
      "Train Epoch: 42 [144960/225000 (64%)] Loss: 20000.152344\n",
      "Train Epoch: 42 [147456/225000 (66%)] Loss: 20659.550781\n",
      "Train Epoch: 42 [149952/225000 (67%)] Loss: 20131.062500\n",
      "Train Epoch: 42 [152448/225000 (68%)] Loss: 20550.824219\n",
      "Train Epoch: 42 [154944/225000 (69%)] Loss: 20312.214844\n",
      "Train Epoch: 42 [157440/225000 (70%)] Loss: 20011.408203\n",
      "Train Epoch: 42 [159936/225000 (71%)] Loss: 20126.242188\n",
      "Train Epoch: 42 [162432/225000 (72%)] Loss: 20482.503906\n",
      "Train Epoch: 42 [164928/225000 (73%)] Loss: 20121.515625\n",
      "Train Epoch: 42 [167424/225000 (74%)] Loss: 20116.535156\n",
      "Train Epoch: 42 [169920/225000 (76%)] Loss: 20229.691406\n",
      "Train Epoch: 42 [172416/225000 (77%)] Loss: 20094.367188\n",
      "Train Epoch: 42 [174912/225000 (78%)] Loss: 20153.894531\n",
      "Train Epoch: 42 [177408/225000 (79%)] Loss: 20414.242188\n",
      "Train Epoch: 42 [179904/225000 (80%)] Loss: 20088.068359\n",
      "Train Epoch: 42 [182400/225000 (81%)] Loss: 20281.195312\n",
      "Train Epoch: 42 [184896/225000 (82%)] Loss: 20218.679688\n",
      "Train Epoch: 42 [187392/225000 (83%)] Loss: 20503.425781\n",
      "Train Epoch: 42 [189888/225000 (84%)] Loss: 20123.238281\n",
      "Train Epoch: 42 [192384/225000 (86%)] Loss: 20246.091797\n",
      "Train Epoch: 42 [194880/225000 (87%)] Loss: 20284.285156\n",
      "Train Epoch: 42 [197376/225000 (88%)] Loss: 20115.583984\n",
      "Train Epoch: 42 [199872/225000 (89%)] Loss: 19784.941406\n",
      "Train Epoch: 42 [202368/225000 (90%)] Loss: 20427.589844\n",
      "Train Epoch: 42 [204864/225000 (91%)] Loss: 20754.468750\n",
      "Train Epoch: 42 [207360/225000 (92%)] Loss: 20058.285156\n",
      "Train Epoch: 42 [209856/225000 (93%)] Loss: 19832.876953\n",
      "Train Epoch: 42 [212352/225000 (94%)] Loss: 19876.121094\n",
      "Train Epoch: 42 [214848/225000 (95%)] Loss: 20153.304688\n",
      "Train Epoch: 42 [217344/225000 (97%)] Loss: 20229.892578\n",
      "Train Epoch: 42 [219840/225000 (98%)] Loss: 20638.634766\n",
      "Train Epoch: 42 [222336/225000 (99%)] Loss: 20605.279297\n",
      "Train Epoch: 42 [224832/225000 (100%)] Loss: 20411.197266\n",
      "    epoch          : 42\n",
      "    loss           : 20278.46840170382\n",
      "    val_loss       : 20168.489492000514\n",
      "Train Epoch: 43 [192/225000 (0%)] Loss: 19701.257812\n",
      "Train Epoch: 43 [2688/225000 (1%)] Loss: 20716.281250\n",
      "Train Epoch: 43 [5184/225000 (2%)] Loss: 20327.582031\n",
      "Train Epoch: 43 [7680/225000 (3%)] Loss: 19882.800781\n",
      "Train Epoch: 43 [10176/225000 (5%)] Loss: 20384.390625\n",
      "Train Epoch: 43 [12672/225000 (6%)] Loss: 20656.414062\n",
      "Train Epoch: 43 [15168/225000 (7%)] Loss: 20083.390625\n",
      "Train Epoch: 43 [17664/225000 (8%)] Loss: 20213.953125\n",
      "Train Epoch: 43 [20160/225000 (9%)] Loss: 19847.472656\n",
      "Train Epoch: 43 [22656/225000 (10%)] Loss: 20063.652344\n",
      "Train Epoch: 43 [25152/225000 (11%)] Loss: 20292.015625\n",
      "Train Epoch: 43 [27648/225000 (12%)] Loss: 19785.906250\n",
      "Train Epoch: 43 [30144/225000 (13%)] Loss: 19941.708984\n",
      "Train Epoch: 43 [32640/225000 (15%)] Loss: 20221.003906\n",
      "Train Epoch: 43 [35136/225000 (16%)] Loss: 20222.589844\n",
      "Train Epoch: 43 [37632/225000 (17%)] Loss: 20483.039062\n",
      "Train Epoch: 43 [40128/225000 (18%)] Loss: 20072.021484\n",
      "Train Epoch: 43 [42624/225000 (19%)] Loss: 20249.373047\n",
      "Train Epoch: 43 [45120/225000 (20%)] Loss: 20187.236328\n",
      "Train Epoch: 43 [47616/225000 (21%)] Loss: 20551.828125\n",
      "Train Epoch: 43 [50112/225000 (22%)] Loss: 20151.113281\n",
      "Train Epoch: 43 [52608/225000 (23%)] Loss: 20196.046875\n",
      "Train Epoch: 43 [55104/225000 (24%)] Loss: 20146.179688\n",
      "Train Epoch: 43 [57600/225000 (26%)] Loss: 19869.607422\n",
      "Train Epoch: 43 [60096/225000 (27%)] Loss: 20459.609375\n",
      "Train Epoch: 43 [62592/225000 (28%)] Loss: 20420.935547\n",
      "Train Epoch: 43 [65088/225000 (29%)] Loss: 20454.449219\n",
      "Train Epoch: 43 [67584/225000 (30%)] Loss: 20072.828125\n",
      "Train Epoch: 43 [70080/225000 (31%)] Loss: 20290.857422\n",
      "Train Epoch: 43 [72576/225000 (32%)] Loss: 20529.146484\n",
      "Train Epoch: 43 [75072/225000 (33%)] Loss: 20665.015625\n",
      "Train Epoch: 43 [77568/225000 (34%)] Loss: 19711.273438\n",
      "Train Epoch: 43 [80064/225000 (36%)] Loss: 20009.820312\n",
      "Train Epoch: 43 [82560/225000 (37%)] Loss: 20393.320312\n",
      "Train Epoch: 43 [85056/225000 (38%)] Loss: 20177.074219\n",
      "Train Epoch: 43 [87552/225000 (39%)] Loss: 20403.539062\n",
      "Train Epoch: 43 [90048/225000 (40%)] Loss: 20739.148438\n",
      "Train Epoch: 43 [92544/225000 (41%)] Loss: 19987.269531\n",
      "Train Epoch: 43 [95040/225000 (42%)] Loss: 20283.441406\n",
      "Train Epoch: 43 [97536/225000 (43%)] Loss: 20201.843750\n",
      "Train Epoch: 43 [100032/225000 (44%)] Loss: 20161.539062\n",
      "Train Epoch: 43 [102528/225000 (46%)] Loss: 20439.882812\n",
      "Train Epoch: 43 [105024/225000 (47%)] Loss: 20046.132812\n",
      "Train Epoch: 43 [107520/225000 (48%)] Loss: 20122.482422\n",
      "Train Epoch: 43 [110016/225000 (49%)] Loss: 21063.041016\n",
      "Train Epoch: 43 [112512/225000 (50%)] Loss: 20128.882812\n",
      "Train Epoch: 43 [115008/225000 (51%)] Loss: 20457.273438\n",
      "Train Epoch: 43 [117504/225000 (52%)] Loss: 20024.355469\n",
      "Train Epoch: 43 [120000/225000 (53%)] Loss: 19950.484375\n",
      "Train Epoch: 43 [122496/225000 (54%)] Loss: 20544.027344\n",
      "Train Epoch: 43 [124992/225000 (56%)] Loss: 20440.789062\n",
      "Train Epoch: 43 [127488/225000 (57%)] Loss: 20565.074219\n",
      "Train Epoch: 43 [129984/225000 (58%)] Loss: 20249.968750\n",
      "Train Epoch: 43 [132480/225000 (59%)] Loss: 20395.011719\n",
      "Train Epoch: 43 [134976/225000 (60%)] Loss: 20031.621094\n",
      "Train Epoch: 43 [137472/225000 (61%)] Loss: 20737.300781\n",
      "Train Epoch: 43 [139968/225000 (62%)] Loss: 19915.908203\n",
      "Train Epoch: 43 [142464/225000 (63%)] Loss: 20756.046875\n",
      "Train Epoch: 43 [144960/225000 (64%)] Loss: 20673.554688\n",
      "Train Epoch: 43 [147456/225000 (66%)] Loss: 20634.800781\n",
      "Train Epoch: 43 [149952/225000 (67%)] Loss: 20370.363281\n",
      "Train Epoch: 43 [152448/225000 (68%)] Loss: 20517.515625\n",
      "Train Epoch: 43 [154944/225000 (69%)] Loss: 20402.421875\n",
      "Train Epoch: 43 [157440/225000 (70%)] Loss: 20407.011719\n",
      "Train Epoch: 43 [159936/225000 (71%)] Loss: 20479.656250\n",
      "Train Epoch: 43 [162432/225000 (72%)] Loss: 20271.685547\n",
      "Train Epoch: 43 [164928/225000 (73%)] Loss: 20551.636719\n",
      "Train Epoch: 43 [167424/225000 (74%)] Loss: 20288.851562\n",
      "Train Epoch: 43 [169920/225000 (76%)] Loss: 19959.687500\n",
      "Train Epoch: 43 [172416/225000 (77%)] Loss: 20607.109375\n",
      "Train Epoch: 43 [174912/225000 (78%)] Loss: 20397.281250\n",
      "Train Epoch: 43 [177408/225000 (79%)] Loss: 19946.361328\n",
      "Train Epoch: 43 [179904/225000 (80%)] Loss: 20144.355469\n",
      "Train Epoch: 43 [182400/225000 (81%)] Loss: 20161.470703\n",
      "Train Epoch: 43 [184896/225000 (82%)] Loss: 20733.988281\n",
      "Train Epoch: 43 [187392/225000 (83%)] Loss: 19942.875000\n",
      "Train Epoch: 43 [189888/225000 (84%)] Loss: 19976.812500\n",
      "Train Epoch: 43 [192384/225000 (86%)] Loss: 20004.976562\n",
      "Train Epoch: 43 [194880/225000 (87%)] Loss: 20824.697266\n",
      "Train Epoch: 43 [197376/225000 (88%)] Loss: 20130.388672\n",
      "Train Epoch: 43 [199872/225000 (89%)] Loss: 20381.285156\n",
      "Train Epoch: 43 [202368/225000 (90%)] Loss: 20616.054688\n",
      "Train Epoch: 43 [204864/225000 (91%)] Loss: 20241.218750\n",
      "Train Epoch: 43 [207360/225000 (92%)] Loss: 20290.480469\n",
      "Train Epoch: 43 [209856/225000 (93%)] Loss: 20637.863281\n",
      "Train Epoch: 43 [212352/225000 (94%)] Loss: 20173.496094\n",
      "Train Epoch: 43 [214848/225000 (95%)] Loss: 20311.728516\n",
      "Train Epoch: 43 [217344/225000 (97%)] Loss: 20439.832031\n",
      "Train Epoch: 43 [219840/225000 (98%)] Loss: 20153.480469\n",
      "Train Epoch: 43 [222336/225000 (99%)] Loss: 20140.992188\n",
      "Train Epoch: 43 [224832/225000 (100%)] Loss: 20883.222656\n",
      "    epoch          : 43\n",
      "    loss           : 20268.752156436647\n",
      "    val_loss       : 20169.36233079206\n",
      "Train Epoch: 44 [192/225000 (0%)] Loss: 20377.615234\n",
      "Train Epoch: 44 [2688/225000 (1%)] Loss: 20446.851562\n",
      "Train Epoch: 44 [5184/225000 (2%)] Loss: 20347.968750\n",
      "Train Epoch: 44 [7680/225000 (3%)] Loss: 20521.949219\n",
      "Train Epoch: 44 [10176/225000 (5%)] Loss: 20753.603516\n",
      "Train Epoch: 44 [12672/225000 (6%)] Loss: 20546.501953\n",
      "Train Epoch: 44 [15168/225000 (7%)] Loss: 20015.265625\n",
      "Train Epoch: 44 [17664/225000 (8%)] Loss: 19941.539062\n",
      "Train Epoch: 44 [20160/225000 (9%)] Loss: 20024.849609\n",
      "Train Epoch: 44 [22656/225000 (10%)] Loss: 20053.281250\n",
      "Train Epoch: 44 [25152/225000 (11%)] Loss: 20393.105469\n",
      "Train Epoch: 44 [27648/225000 (12%)] Loss: 20265.564453\n",
      "Train Epoch: 44 [30144/225000 (13%)] Loss: 20219.068359\n",
      "Train Epoch: 44 [32640/225000 (15%)] Loss: 20798.818359\n",
      "Train Epoch: 44 [35136/225000 (16%)] Loss: 20047.544922\n",
      "Train Epoch: 44 [37632/225000 (17%)] Loss: 20178.191406\n",
      "Train Epoch: 44 [40128/225000 (18%)] Loss: 20254.837891\n",
      "Train Epoch: 44 [42624/225000 (19%)] Loss: 20668.500000\n",
      "Train Epoch: 44 [45120/225000 (20%)] Loss: 19940.392578\n",
      "Train Epoch: 44 [47616/225000 (21%)] Loss: 19801.093750\n",
      "Train Epoch: 44 [50112/225000 (22%)] Loss: 19971.931641\n",
      "Train Epoch: 44 [52608/225000 (23%)] Loss: 20176.234375\n",
      "Train Epoch: 44 [55104/225000 (24%)] Loss: 20331.187500\n",
      "Train Epoch: 44 [57600/225000 (26%)] Loss: 20734.443359\n",
      "Train Epoch: 44 [60096/225000 (27%)] Loss: 19870.121094\n",
      "Train Epoch: 44 [62592/225000 (28%)] Loss: 20460.468750\n",
      "Train Epoch: 44 [65088/225000 (29%)] Loss: 20177.078125\n",
      "Train Epoch: 44 [67584/225000 (30%)] Loss: 20335.078125\n",
      "Train Epoch: 44 [70080/225000 (31%)] Loss: 20365.691406\n",
      "Train Epoch: 44 [72576/225000 (32%)] Loss: 20522.945312\n",
      "Train Epoch: 44 [75072/225000 (33%)] Loss: 19969.671875\n",
      "Train Epoch: 44 [77568/225000 (34%)] Loss: 19767.009766\n",
      "Train Epoch: 44 [80064/225000 (36%)] Loss: 20387.324219\n",
      "Train Epoch: 44 [82560/225000 (37%)] Loss: 20114.062500\n",
      "Train Epoch: 44 [85056/225000 (38%)] Loss: 20356.078125\n",
      "Train Epoch: 44 [87552/225000 (39%)] Loss: 20264.367188\n",
      "Train Epoch: 44 [90048/225000 (40%)] Loss: 20243.925781\n",
      "Train Epoch: 44 [92544/225000 (41%)] Loss: 20198.289062\n",
      "Train Epoch: 44 [95040/225000 (42%)] Loss: 19993.425781\n",
      "Train Epoch: 44 [97536/225000 (43%)] Loss: 19911.191406\n",
      "Train Epoch: 44 [100032/225000 (44%)] Loss: 19899.203125\n",
      "Train Epoch: 44 [102528/225000 (46%)] Loss: 20217.851562\n",
      "Train Epoch: 44 [105024/225000 (47%)] Loss: 20220.125000\n",
      "Train Epoch: 44 [107520/225000 (48%)] Loss: 20205.574219\n",
      "Train Epoch: 44 [110016/225000 (49%)] Loss: 20226.156250\n",
      "Train Epoch: 44 [112512/225000 (50%)] Loss: 20439.103516\n",
      "Train Epoch: 44 [115008/225000 (51%)] Loss: 19943.242188\n",
      "Train Epoch: 44 [117504/225000 (52%)] Loss: 20096.957031\n",
      "Train Epoch: 44 [120000/225000 (53%)] Loss: 19931.628906\n",
      "Train Epoch: 44 [122496/225000 (54%)] Loss: 20254.632812\n",
      "Train Epoch: 44 [124992/225000 (56%)] Loss: 20434.746094\n",
      "Train Epoch: 44 [127488/225000 (57%)] Loss: 20602.130859\n",
      "Train Epoch: 44 [129984/225000 (58%)] Loss: 20397.751953\n",
      "Train Epoch: 44 [132480/225000 (59%)] Loss: 20378.361328\n",
      "Train Epoch: 44 [134976/225000 (60%)] Loss: 20343.292969\n",
      "Train Epoch: 44 [137472/225000 (61%)] Loss: 20182.101562\n",
      "Train Epoch: 44 [139968/225000 (62%)] Loss: 20117.128906\n",
      "Train Epoch: 44 [142464/225000 (63%)] Loss: 20021.449219\n",
      "Train Epoch: 44 [144960/225000 (64%)] Loss: 20164.457031\n",
      "Train Epoch: 44 [147456/225000 (66%)] Loss: 20340.933594\n",
      "Train Epoch: 44 [149952/225000 (67%)] Loss: 20427.691406\n",
      "Train Epoch: 44 [152448/225000 (68%)] Loss: 20217.654297\n",
      "Train Epoch: 44 [154944/225000 (69%)] Loss: 20158.773438\n",
      "Train Epoch: 44 [157440/225000 (70%)] Loss: 20668.726562\n",
      "Train Epoch: 44 [159936/225000 (71%)] Loss: 20636.603516\n",
      "Train Epoch: 44 [162432/225000 (72%)] Loss: 19789.000000\n",
      "Train Epoch: 44 [164928/225000 (73%)] Loss: 20252.750000\n",
      "Train Epoch: 44 [167424/225000 (74%)] Loss: 20549.062500\n",
      "Train Epoch: 44 [169920/225000 (76%)] Loss: 20543.976562\n",
      "Train Epoch: 44 [172416/225000 (77%)] Loss: 20098.384766\n",
      "Train Epoch: 44 [174912/225000 (78%)] Loss: 20305.189453\n",
      "Train Epoch: 44 [177408/225000 (79%)] Loss: 20103.267578\n",
      "Train Epoch: 44 [179904/225000 (80%)] Loss: 20166.324219\n",
      "Train Epoch: 44 [182400/225000 (81%)] Loss: 20389.753906\n",
      "Train Epoch: 44 [184896/225000 (82%)] Loss: 20567.177734\n",
      "Train Epoch: 44 [187392/225000 (83%)] Loss: 20280.744141\n",
      "Train Epoch: 44 [189888/225000 (84%)] Loss: 20224.148438\n",
      "Train Epoch: 44 [192384/225000 (86%)] Loss: 20387.722656\n",
      "Train Epoch: 44 [194880/225000 (87%)] Loss: 20464.953125\n",
      "Train Epoch: 44 [197376/225000 (88%)] Loss: 20334.496094\n",
      "Train Epoch: 44 [199872/225000 (89%)] Loss: 20254.281250\n",
      "Train Epoch: 44 [202368/225000 (90%)] Loss: 20373.783203\n",
      "Train Epoch: 44 [204864/225000 (91%)] Loss: 20307.968750\n",
      "Train Epoch: 44 [207360/225000 (92%)] Loss: 20705.164062\n",
      "Train Epoch: 44 [209856/225000 (93%)] Loss: 20273.945312\n",
      "Train Epoch: 44 [212352/225000 (94%)] Loss: 20184.480469\n",
      "Train Epoch: 44 [214848/225000 (95%)] Loss: 20624.800781\n",
      "Train Epoch: 44 [217344/225000 (97%)] Loss: 20398.390625\n",
      "Train Epoch: 44 [219840/225000 (98%)] Loss: 20396.898438\n",
      "Train Epoch: 44 [222336/225000 (99%)] Loss: 20047.699219\n",
      "Train Epoch: 44 [224832/225000 (100%)] Loss: 20811.386719\n",
      "    epoch          : 44\n",
      "    loss           : 20264.180345763118\n",
      "    val_loss       : 20159.63170656266\n",
      "Train Epoch: 45 [192/225000 (0%)] Loss: 20197.175781\n",
      "Train Epoch: 45 [2688/225000 (1%)] Loss: 20115.013672\n",
      "Train Epoch: 45 [5184/225000 (2%)] Loss: 20315.908203\n",
      "Train Epoch: 45 [7680/225000 (3%)] Loss: 20080.023438\n",
      "Train Epoch: 45 [10176/225000 (5%)] Loss: 20570.546875\n",
      "Train Epoch: 45 [12672/225000 (6%)] Loss: 20086.238281\n",
      "Train Epoch: 45 [15168/225000 (7%)] Loss: 20668.554688\n",
      "Train Epoch: 45 [17664/225000 (8%)] Loss: 20425.460938\n",
      "Train Epoch: 45 [20160/225000 (9%)] Loss: 20174.619141\n",
      "Train Epoch: 45 [22656/225000 (10%)] Loss: 20185.937500\n",
      "Train Epoch: 45 [25152/225000 (11%)] Loss: 20077.746094\n",
      "Train Epoch: 45 [27648/225000 (12%)] Loss: 20172.552734\n",
      "Train Epoch: 45 [30144/225000 (13%)] Loss: 20414.113281\n",
      "Train Epoch: 45 [32640/225000 (15%)] Loss: 20634.462891\n",
      "Train Epoch: 45 [35136/225000 (16%)] Loss: 20301.945312\n",
      "Train Epoch: 45 [37632/225000 (17%)] Loss: 20080.666016\n",
      "Train Epoch: 45 [40128/225000 (18%)] Loss: 20144.484375\n",
      "Train Epoch: 45 [42624/225000 (19%)] Loss: 19860.003906\n",
      "Train Epoch: 45 [45120/225000 (20%)] Loss: 20195.027344\n",
      "Train Epoch: 45 [47616/225000 (21%)] Loss: 20420.222656\n",
      "Train Epoch: 45 [50112/225000 (22%)] Loss: 20036.439453\n",
      "Train Epoch: 45 [52608/225000 (23%)] Loss: 20384.845703\n",
      "Train Epoch: 45 [55104/225000 (24%)] Loss: 20015.007812\n",
      "Train Epoch: 45 [57600/225000 (26%)] Loss: 19978.593750\n",
      "Train Epoch: 45 [60096/225000 (27%)] Loss: 19948.605469\n",
      "Train Epoch: 45 [62592/225000 (28%)] Loss: 20614.023438\n",
      "Train Epoch: 45 [65088/225000 (29%)] Loss: 20289.625000\n",
      "Train Epoch: 45 [67584/225000 (30%)] Loss: 19949.523438\n",
      "Train Epoch: 45 [70080/225000 (31%)] Loss: 20351.605469\n",
      "Train Epoch: 45 [72576/225000 (32%)] Loss: 19939.445312\n",
      "Train Epoch: 45 [75072/225000 (33%)] Loss: 20347.515625\n",
      "Train Epoch: 45 [77568/225000 (34%)] Loss: 20296.578125\n",
      "Train Epoch: 45 [80064/225000 (36%)] Loss: 20209.875000\n",
      "Train Epoch: 45 [82560/225000 (37%)] Loss: 20046.146484\n",
      "Train Epoch: 45 [85056/225000 (38%)] Loss: 20350.912109\n",
      "Train Epoch: 45 [87552/225000 (39%)] Loss: 20305.183594\n",
      "Train Epoch: 45 [90048/225000 (40%)] Loss: 20341.523438\n",
      "Train Epoch: 45 [92544/225000 (41%)] Loss: 20638.492188\n",
      "Train Epoch: 45 [95040/225000 (42%)] Loss: 20210.898438\n",
      "Train Epoch: 45 [97536/225000 (43%)] Loss: 20132.492188\n",
      "Train Epoch: 45 [100032/225000 (44%)] Loss: 19874.996094\n",
      "Train Epoch: 45 [102528/225000 (46%)] Loss: 20357.761719\n",
      "Train Epoch: 45 [105024/225000 (47%)] Loss: 20706.679688\n",
      "Train Epoch: 45 [107520/225000 (48%)] Loss: 20619.386719\n",
      "Train Epoch: 45 [110016/225000 (49%)] Loss: 20510.369141\n",
      "Train Epoch: 45 [112512/225000 (50%)] Loss: 20411.308594\n",
      "Train Epoch: 45 [115008/225000 (51%)] Loss: 20694.380859\n",
      "Train Epoch: 45 [117504/225000 (52%)] Loss: 20052.771484\n",
      "Train Epoch: 45 [120000/225000 (53%)] Loss: 19973.992188\n",
      "Train Epoch: 45 [122496/225000 (54%)] Loss: 20429.339844\n",
      "Train Epoch: 45 [124992/225000 (56%)] Loss: 20048.371094\n",
      "Train Epoch: 45 [127488/225000 (57%)] Loss: 20333.675781\n",
      "Train Epoch: 45 [129984/225000 (58%)] Loss: 20024.835938\n",
      "Train Epoch: 45 [132480/225000 (59%)] Loss: 20470.128906\n",
      "Train Epoch: 45 [134976/225000 (60%)] Loss: 20476.839844\n",
      "Train Epoch: 45 [137472/225000 (61%)] Loss: 20209.697266\n",
      "Train Epoch: 45 [139968/225000 (62%)] Loss: 20623.515625\n",
      "Train Epoch: 45 [142464/225000 (63%)] Loss: 20248.941406\n",
      "Train Epoch: 45 [144960/225000 (64%)] Loss: 20135.283203\n",
      "Train Epoch: 45 [147456/225000 (66%)] Loss: 20723.251953\n",
      "Train Epoch: 45 [149952/225000 (67%)] Loss: 20208.218750\n",
      "Train Epoch: 45 [152448/225000 (68%)] Loss: 20127.980469\n",
      "Train Epoch: 45 [154944/225000 (69%)] Loss: 20574.236328\n",
      "Train Epoch: 45 [157440/225000 (70%)] Loss: 19960.705078\n",
      "Train Epoch: 45 [159936/225000 (71%)] Loss: 20793.308594\n",
      "Train Epoch: 45 [162432/225000 (72%)] Loss: 20331.292969\n",
      "Train Epoch: 45 [164928/225000 (73%)] Loss: 20340.183594\n",
      "Train Epoch: 45 [167424/225000 (74%)] Loss: 35277.394531\n",
      "Train Epoch: 45 [169920/225000 (76%)] Loss: 20092.070312\n",
      "Train Epoch: 45 [172416/225000 (77%)] Loss: 20153.597656\n",
      "Train Epoch: 45 [174912/225000 (78%)] Loss: 20084.753906\n",
      "Train Epoch: 45 [177408/225000 (79%)] Loss: 20400.136719\n",
      "Train Epoch: 45 [179904/225000 (80%)] Loss: 20551.437500\n",
      "Train Epoch: 45 [182400/225000 (81%)] Loss: 20497.414062\n",
      "Train Epoch: 45 [184896/225000 (82%)] Loss: 20336.332031\n",
      "Train Epoch: 45 [187392/225000 (83%)] Loss: 20024.451172\n",
      "Train Epoch: 45 [189888/225000 (84%)] Loss: 19885.035156\n",
      "Train Epoch: 45 [192384/225000 (86%)] Loss: 20001.488281\n",
      "Train Epoch: 45 [194880/225000 (87%)] Loss: 20255.343750\n",
      "Train Epoch: 45 [197376/225000 (88%)] Loss: 20306.003906\n",
      "Train Epoch: 45 [199872/225000 (89%)] Loss: 20040.464844\n",
      "Train Epoch: 45 [202368/225000 (90%)] Loss: 20358.597656\n",
      "Train Epoch: 45 [204864/225000 (91%)] Loss: 19789.144531\n",
      "Train Epoch: 45 [207360/225000 (92%)] Loss: 19900.871094\n",
      "Train Epoch: 45 [209856/225000 (93%)] Loss: 20324.644531\n",
      "Train Epoch: 45 [212352/225000 (94%)] Loss: 19957.515625\n",
      "Train Epoch: 45 [214848/225000 (95%)] Loss: 20614.414062\n",
      "Train Epoch: 45 [217344/225000 (97%)] Loss: 19991.066406\n",
      "Train Epoch: 45 [219840/225000 (98%)] Loss: 20131.335938\n",
      "Train Epoch: 45 [222336/225000 (99%)] Loss: 20107.398438\n",
      "Train Epoch: 45 [224832/225000 (100%)] Loss: 20023.318359\n",
      "    epoch          : 45\n",
      "    loss           : 20266.07306054021\n",
      "    val_loss       : 20166.923360861896\n",
      "Train Epoch: 46 [192/225000 (0%)] Loss: 20234.050781\n",
      "Train Epoch: 46 [2688/225000 (1%)] Loss: 20410.449219\n",
      "Train Epoch: 46 [5184/225000 (2%)] Loss: 20404.199219\n",
      "Train Epoch: 46 [7680/225000 (3%)] Loss: 20546.746094\n",
      "Train Epoch: 46 [10176/225000 (5%)] Loss: 20116.046875\n",
      "Train Epoch: 46 [12672/225000 (6%)] Loss: 20661.976562\n",
      "Train Epoch: 46 [15168/225000 (7%)] Loss: 20414.287109\n",
      "Train Epoch: 46 [17664/225000 (8%)] Loss: 20087.792969\n",
      "Train Epoch: 46 [20160/225000 (9%)] Loss: 20022.378906\n",
      "Train Epoch: 46 [22656/225000 (10%)] Loss: 20380.652344\n",
      "Train Epoch: 46 [25152/225000 (11%)] Loss: 20281.736328\n",
      "Train Epoch: 46 [27648/225000 (12%)] Loss: 20120.351562\n",
      "Train Epoch: 46 [30144/225000 (13%)] Loss: 20280.195312\n",
      "Train Epoch: 46 [32640/225000 (15%)] Loss: 20157.363281\n",
      "Train Epoch: 46 [35136/225000 (16%)] Loss: 20551.792969\n",
      "Train Epoch: 46 [37632/225000 (17%)] Loss: 20389.552734\n",
      "Train Epoch: 46 [40128/225000 (18%)] Loss: 19894.367188\n",
      "Train Epoch: 46 [42624/225000 (19%)] Loss: 19923.242188\n",
      "Train Epoch: 46 [45120/225000 (20%)] Loss: 20509.777344\n",
      "Train Epoch: 46 [47616/225000 (21%)] Loss: 20668.343750\n",
      "Train Epoch: 46 [50112/225000 (22%)] Loss: 20130.226562\n",
      "Train Epoch: 46 [52608/225000 (23%)] Loss: 20259.031250\n",
      "Train Epoch: 46 [55104/225000 (24%)] Loss: 20664.175781\n",
      "Train Epoch: 46 [57600/225000 (26%)] Loss: 20413.843750\n",
      "Train Epoch: 46 [60096/225000 (27%)] Loss: 21064.166016\n",
      "Train Epoch: 46 [62592/225000 (28%)] Loss: 19951.542969\n",
      "Train Epoch: 46 [65088/225000 (29%)] Loss: 20321.382812\n",
      "Train Epoch: 46 [67584/225000 (30%)] Loss: 20661.839844\n",
      "Train Epoch: 46 [70080/225000 (31%)] Loss: 20711.820312\n",
      "Train Epoch: 46 [72576/225000 (32%)] Loss: 20033.277344\n",
      "Train Epoch: 46 [75072/225000 (33%)] Loss: 20702.574219\n",
      "Train Epoch: 46 [77568/225000 (34%)] Loss: 20503.712891\n",
      "Train Epoch: 46 [80064/225000 (36%)] Loss: 20288.302734\n",
      "Train Epoch: 46 [82560/225000 (37%)] Loss: 20334.058594\n",
      "Train Epoch: 46 [85056/225000 (38%)] Loss: 20254.894531\n",
      "Train Epoch: 46 [87552/225000 (39%)] Loss: 20529.171875\n",
      "Train Epoch: 46 [90048/225000 (40%)] Loss: 19967.378906\n",
      "Train Epoch: 46 [92544/225000 (41%)] Loss: 20356.697266\n",
      "Train Epoch: 46 [95040/225000 (42%)] Loss: 19735.570312\n",
      "Train Epoch: 46 [97536/225000 (43%)] Loss: 20281.593750\n",
      "Train Epoch: 46 [100032/225000 (44%)] Loss: 20631.207031\n",
      "Train Epoch: 46 [102528/225000 (46%)] Loss: 20298.875000\n",
      "Train Epoch: 46 [105024/225000 (47%)] Loss: 20129.531250\n",
      "Train Epoch: 46 [107520/225000 (48%)] Loss: 20239.640625\n",
      "Train Epoch: 46 [110016/225000 (49%)] Loss: 20495.507812\n",
      "Train Epoch: 46 [112512/225000 (50%)] Loss: 20497.414062\n",
      "Train Epoch: 46 [115008/225000 (51%)] Loss: 20361.531250\n",
      "Train Epoch: 46 [117504/225000 (52%)] Loss: 20510.693359\n",
      "Train Epoch: 46 [120000/225000 (53%)] Loss: 20384.929688\n",
      "Train Epoch: 46 [122496/225000 (54%)] Loss: 19159.156250\n",
      "Train Epoch: 46 [124992/225000 (56%)] Loss: 19959.992188\n",
      "Train Epoch: 46 [127488/225000 (57%)] Loss: 20004.947266\n",
      "Train Epoch: 46 [129984/225000 (58%)] Loss: 20576.917969\n",
      "Train Epoch: 46 [132480/225000 (59%)] Loss: 20318.152344\n",
      "Train Epoch: 46 [134976/225000 (60%)] Loss: 20002.093750\n",
      "Train Epoch: 46 [137472/225000 (61%)] Loss: 19691.693359\n",
      "Train Epoch: 46 [139968/225000 (62%)] Loss: 19945.820312\n",
      "Train Epoch: 46 [142464/225000 (63%)] Loss: 19755.984375\n",
      "Train Epoch: 46 [144960/225000 (64%)] Loss: 20660.066406\n",
      "Train Epoch: 46 [147456/225000 (66%)] Loss: 20055.457031\n",
      "Train Epoch: 46 [149952/225000 (67%)] Loss: 20573.082031\n",
      "Train Epoch: 46 [152448/225000 (68%)] Loss: 20060.777344\n",
      "Train Epoch: 46 [154944/225000 (69%)] Loss: 20260.791016\n",
      "Train Epoch: 46 [157440/225000 (70%)] Loss: 20608.511719\n",
      "Train Epoch: 46 [159936/225000 (71%)] Loss: 20117.503906\n",
      "Train Epoch: 46 [162432/225000 (72%)] Loss: 20065.023438\n",
      "Train Epoch: 46 [164928/225000 (73%)] Loss: 20263.656250\n",
      "Train Epoch: 46 [167424/225000 (74%)] Loss: 19763.921875\n",
      "Train Epoch: 46 [169920/225000 (76%)] Loss: 20310.621094\n",
      "Train Epoch: 46 [172416/225000 (77%)] Loss: 20260.880859\n",
      "Train Epoch: 46 [174912/225000 (78%)] Loss: 20020.429688\n",
      "Train Epoch: 46 [177408/225000 (79%)] Loss: 20298.757812\n",
      "Train Epoch: 46 [179904/225000 (80%)] Loss: 20054.333984\n",
      "Train Epoch: 46 [182400/225000 (81%)] Loss: 20467.101562\n",
      "Train Epoch: 46 [184896/225000 (82%)] Loss: 20417.015625\n",
      "Train Epoch: 46 [187392/225000 (83%)] Loss: 20560.972656\n",
      "Train Epoch: 46 [189888/225000 (84%)] Loss: 20179.960938\n",
      "Train Epoch: 46 [192384/225000 (86%)] Loss: 19698.503906\n",
      "Train Epoch: 46 [194880/225000 (87%)] Loss: 20469.896484\n",
      "Train Epoch: 46 [197376/225000 (88%)] Loss: 19972.171875\n",
      "Train Epoch: 46 [199872/225000 (89%)] Loss: 20771.773438\n",
      "Train Epoch: 46 [202368/225000 (90%)] Loss: 19796.355469\n",
      "Train Epoch: 46 [204864/225000 (91%)] Loss: 20297.527344\n",
      "Train Epoch: 46 [207360/225000 (92%)] Loss: 20015.966797\n",
      "Train Epoch: 46 [209856/225000 (93%)] Loss: 19963.875000\n",
      "Train Epoch: 46 [212352/225000 (94%)] Loss: 20087.541016\n",
      "Train Epoch: 46 [214848/225000 (95%)] Loss: 20615.710938\n",
      "Train Epoch: 46 [217344/225000 (97%)] Loss: 19579.121094\n",
      "Train Epoch: 46 [219840/225000 (98%)] Loss: 19778.529297\n",
      "Train Epoch: 46 [222336/225000 (99%)] Loss: 19716.732422\n",
      "Train Epoch: 46 [224832/225000 (100%)] Loss: 20304.421875\n",
      "    epoch          : 46\n",
      "    loss           : 20251.305545741787\n",
      "    val_loss       : 20157.158851457916\n",
      "Train Epoch: 47 [192/225000 (0%)] Loss: 20183.078125\n",
      "Train Epoch: 47 [2688/225000 (1%)] Loss: 19970.011719\n",
      "Train Epoch: 47 [5184/225000 (2%)] Loss: 20436.123047\n",
      "Train Epoch: 47 [7680/225000 (3%)] Loss: 20086.058594\n",
      "Train Epoch: 47 [10176/225000 (5%)] Loss: 20439.761719\n",
      "Train Epoch: 47 [12672/225000 (6%)] Loss: 20444.708984\n",
      "Train Epoch: 47 [15168/225000 (7%)] Loss: 20265.937500\n",
      "Train Epoch: 47 [17664/225000 (8%)] Loss: 20111.632812\n",
      "Train Epoch: 47 [20160/225000 (9%)] Loss: 20000.371094\n",
      "Train Epoch: 47 [22656/225000 (10%)] Loss: 20471.617188\n",
      "Train Epoch: 47 [25152/225000 (11%)] Loss: 19753.375000\n",
      "Train Epoch: 47 [27648/225000 (12%)] Loss: 20003.996094\n",
      "Train Epoch: 47 [30144/225000 (13%)] Loss: 20308.113281\n",
      "Train Epoch: 47 [32640/225000 (15%)] Loss: 20032.679688\n",
      "Train Epoch: 47 [35136/225000 (16%)] Loss: 20288.253906\n",
      "Train Epoch: 47 [37632/225000 (17%)] Loss: 20495.519531\n",
      "Train Epoch: 47 [40128/225000 (18%)] Loss: 20081.765625\n",
      "Train Epoch: 47 [42624/225000 (19%)] Loss: 20665.863281\n",
      "Train Epoch: 47 [45120/225000 (20%)] Loss: 20390.869141\n",
      "Train Epoch: 47 [47616/225000 (21%)] Loss: 20402.496094\n",
      "Train Epoch: 47 [50112/225000 (22%)] Loss: 20435.472656\n",
      "Train Epoch: 47 [52608/225000 (23%)] Loss: 20261.083984\n",
      "Train Epoch: 47 [55104/225000 (24%)] Loss: 20395.871094\n",
      "Train Epoch: 47 [57600/225000 (26%)] Loss: 20165.511719\n",
      "Train Epoch: 47 [60096/225000 (27%)] Loss: 20700.062500\n",
      "Train Epoch: 47 [62592/225000 (28%)] Loss: 19861.660156\n",
      "Train Epoch: 47 [65088/225000 (29%)] Loss: 20184.990234\n",
      "Train Epoch: 47 [67584/225000 (30%)] Loss: 20225.914062\n",
      "Train Epoch: 47 [70080/225000 (31%)] Loss: 20720.058594\n",
      "Train Epoch: 47 [72576/225000 (32%)] Loss: 20730.988281\n",
      "Train Epoch: 47 [75072/225000 (33%)] Loss: 19885.990234\n",
      "Train Epoch: 47 [77568/225000 (34%)] Loss: 20714.085938\n",
      "Train Epoch: 47 [80064/225000 (36%)] Loss: 19799.671875\n",
      "Train Epoch: 47 [82560/225000 (37%)] Loss: 20501.296875\n",
      "Train Epoch: 47 [85056/225000 (38%)] Loss: 20389.695312\n",
      "Train Epoch: 47 [87552/225000 (39%)] Loss: 19855.265625\n",
      "Train Epoch: 47 [90048/225000 (40%)] Loss: 19636.884766\n",
      "Train Epoch: 47 [92544/225000 (41%)] Loss: 20301.152344\n",
      "Train Epoch: 47 [95040/225000 (42%)] Loss: 20721.343750\n",
      "Train Epoch: 47 [97536/225000 (43%)] Loss: 20597.462891\n",
      "Train Epoch: 47 [100032/225000 (44%)] Loss: 20708.974609\n",
      "Train Epoch: 47 [102528/225000 (46%)] Loss: 20213.074219\n",
      "Train Epoch: 47 [105024/225000 (47%)] Loss: 20019.980469\n",
      "Train Epoch: 47 [107520/225000 (48%)] Loss: 20308.179688\n",
      "Train Epoch: 47 [110016/225000 (49%)] Loss: 20196.634766\n",
      "Train Epoch: 47 [112512/225000 (50%)] Loss: 20353.039062\n",
      "Train Epoch: 47 [115008/225000 (51%)] Loss: 19415.230469\n",
      "Train Epoch: 47 [117504/225000 (52%)] Loss: 20059.714844\n",
      "Train Epoch: 47 [120000/225000 (53%)] Loss: 20126.142578\n",
      "Train Epoch: 47 [122496/225000 (54%)] Loss: 20565.546875\n",
      "Train Epoch: 47 [124992/225000 (56%)] Loss: 19979.507812\n",
      "Train Epoch: 47 [127488/225000 (57%)] Loss: 20170.445312\n",
      "Train Epoch: 47 [129984/225000 (58%)] Loss: 20562.736328\n",
      "Train Epoch: 47 [132480/225000 (59%)] Loss: 20632.597656\n",
      "Train Epoch: 47 [134976/225000 (60%)] Loss: 20695.550781\n",
      "Train Epoch: 47 [137472/225000 (61%)] Loss: 20808.527344\n",
      "Train Epoch: 47 [139968/225000 (62%)] Loss: 20203.246094\n",
      "Train Epoch: 47 [142464/225000 (63%)] Loss: 20076.802734\n",
      "Train Epoch: 47 [144960/225000 (64%)] Loss: 20600.781250\n",
      "Train Epoch: 47 [147456/225000 (66%)] Loss: 20126.691406\n",
      "Train Epoch: 47 [149952/225000 (67%)] Loss: 19971.593750\n",
      "Train Epoch: 47 [152448/225000 (68%)] Loss: 20606.966797\n",
      "Train Epoch: 47 [154944/225000 (69%)] Loss: 20094.375000\n",
      "Train Epoch: 47 [157440/225000 (70%)] Loss: 20495.529297\n",
      "Train Epoch: 47 [159936/225000 (71%)] Loss: 19895.000000\n",
      "Train Epoch: 47 [162432/225000 (72%)] Loss: 20450.609375\n",
      "Train Epoch: 47 [164928/225000 (73%)] Loss: 20147.613281\n",
      "Train Epoch: 47 [167424/225000 (74%)] Loss: 20444.501953\n",
      "Train Epoch: 47 [169920/225000 (76%)] Loss: 20013.552734\n",
      "Train Epoch: 47 [172416/225000 (77%)] Loss: 20105.222656\n",
      "Train Epoch: 47 [174912/225000 (78%)] Loss: 19897.570312\n",
      "Train Epoch: 47 [177408/225000 (79%)] Loss: 20406.189453\n",
      "Train Epoch: 47 [179904/225000 (80%)] Loss: 20282.105469\n",
      "Train Epoch: 47 [182400/225000 (81%)] Loss: 19982.298828\n",
      "Train Epoch: 47 [184896/225000 (82%)] Loss: 19942.191406\n",
      "Train Epoch: 47 [187392/225000 (83%)] Loss: 20114.142578\n",
      "Train Epoch: 47 [189888/225000 (84%)] Loss: 20592.328125\n",
      "Train Epoch: 47 [192384/225000 (86%)] Loss: 20556.523438\n",
      "Train Epoch: 47 [194880/225000 (87%)] Loss: 20185.753906\n",
      "Train Epoch: 47 [197376/225000 (88%)] Loss: 20437.433594\n",
      "Train Epoch: 47 [199872/225000 (89%)] Loss: 20652.085938\n",
      "Train Epoch: 47 [202368/225000 (90%)] Loss: 20081.429688\n",
      "Train Epoch: 47 [204864/225000 (91%)] Loss: 20472.371094\n",
      "Train Epoch: 47 [207360/225000 (92%)] Loss: 20667.240234\n",
      "Train Epoch: 47 [209856/225000 (93%)] Loss: 20138.578125\n",
      "Train Epoch: 47 [212352/225000 (94%)] Loss: 20092.687500\n",
      "Train Epoch: 47 [214848/225000 (95%)] Loss: 20374.666016\n",
      "Train Epoch: 47 [217344/225000 (97%)] Loss: 20096.433594\n",
      "Train Epoch: 47 [219840/225000 (98%)] Loss: 20239.054688\n",
      "Train Epoch: 47 [222336/225000 (99%)] Loss: 20369.736328\n",
      "Train Epoch: 47 [224832/225000 (100%)] Loss: 20045.326172\n",
      "    epoch          : 47\n",
      "    loss           : 20247.923684806952\n",
      "    val_loss       : 20267.057221894047\n",
      "Train Epoch: 48 [192/225000 (0%)] Loss: 20837.296875\n",
      "Train Epoch: 48 [2688/225000 (1%)] Loss: 19895.148438\n",
      "Train Epoch: 48 [5184/225000 (2%)] Loss: 20064.296875\n",
      "Train Epoch: 48 [7680/225000 (3%)] Loss: 20596.421875\n",
      "Train Epoch: 48 [10176/225000 (5%)] Loss: 20454.701172\n",
      "Train Epoch: 48 [12672/225000 (6%)] Loss: 20536.164062\n",
      "Train Epoch: 48 [15168/225000 (7%)] Loss: 20677.433594\n",
      "Train Epoch: 48 [17664/225000 (8%)] Loss: 20471.820312\n",
      "Train Epoch: 48 [20160/225000 (9%)] Loss: 20230.865234\n",
      "Train Epoch: 48 [22656/225000 (10%)] Loss: 20000.373047\n",
      "Train Epoch: 48 [25152/225000 (11%)] Loss: 20541.046875\n",
      "Train Epoch: 48 [27648/225000 (12%)] Loss: 20623.193359\n",
      "Train Epoch: 48 [30144/225000 (13%)] Loss: 20760.562500\n",
      "Train Epoch: 48 [32640/225000 (15%)] Loss: 19988.269531\n",
      "Train Epoch: 48 [35136/225000 (16%)] Loss: 19987.167969\n",
      "Train Epoch: 48 [37632/225000 (17%)] Loss: 20707.214844\n",
      "Train Epoch: 48 [40128/225000 (18%)] Loss: 20411.074219\n",
      "Train Epoch: 48 [42624/225000 (19%)] Loss: 19951.091797\n",
      "Train Epoch: 48 [45120/225000 (20%)] Loss: 20556.103516\n",
      "Train Epoch: 48 [47616/225000 (21%)] Loss: 19894.019531\n",
      "Train Epoch: 48 [50112/225000 (22%)] Loss: 19826.863281\n",
      "Train Epoch: 48 [52608/225000 (23%)] Loss: 20478.007812\n",
      "Train Epoch: 48 [55104/225000 (24%)] Loss: 20423.730469\n",
      "Train Epoch: 48 [57600/225000 (26%)] Loss: 19905.708984\n",
      "Train Epoch: 48 [60096/225000 (27%)] Loss: 20375.917969\n",
      "Train Epoch: 48 [62592/225000 (28%)] Loss: 19822.437500\n",
      "Train Epoch: 48 [65088/225000 (29%)] Loss: 20408.425781\n",
      "Train Epoch: 48 [67584/225000 (30%)] Loss: 20035.062500\n",
      "Train Epoch: 48 [70080/225000 (31%)] Loss: 20157.632812\n",
      "Train Epoch: 48 [72576/225000 (32%)] Loss: 20457.136719\n",
      "Train Epoch: 48 [75072/225000 (33%)] Loss: 20395.298828\n",
      "Train Epoch: 48 [77568/225000 (34%)] Loss: 19949.289062\n",
      "Train Epoch: 48 [80064/225000 (36%)] Loss: 20583.765625\n",
      "Train Epoch: 48 [82560/225000 (37%)] Loss: 20435.175781\n",
      "Train Epoch: 48 [85056/225000 (38%)] Loss: 20042.898438\n",
      "Train Epoch: 48 [87552/225000 (39%)] Loss: 20303.621094\n",
      "Train Epoch: 48 [90048/225000 (40%)] Loss: 20294.824219\n",
      "Train Epoch: 48 [92544/225000 (41%)] Loss: 20833.066406\n",
      "Train Epoch: 48 [95040/225000 (42%)] Loss: 20255.265625\n",
      "Train Epoch: 48 [97536/225000 (43%)] Loss: 19951.433594\n",
      "Train Epoch: 48 [100032/225000 (44%)] Loss: 20571.882812\n",
      "Train Epoch: 48 [102528/225000 (46%)] Loss: 20181.714844\n",
      "Train Epoch: 48 [105024/225000 (47%)] Loss: 20219.984375\n",
      "Train Epoch: 48 [107520/225000 (48%)] Loss: 20259.195312\n",
      "Train Epoch: 48 [110016/225000 (49%)] Loss: 20286.353516\n",
      "Train Epoch: 48 [112512/225000 (50%)] Loss: 20651.937500\n",
      "Train Epoch: 48 [115008/225000 (51%)] Loss: 20511.523438\n",
      "Train Epoch: 48 [117504/225000 (52%)] Loss: 20110.074219\n",
      "Train Epoch: 48 [120000/225000 (53%)] Loss: 20610.128906\n",
      "Train Epoch: 48 [122496/225000 (54%)] Loss: 20601.011719\n",
      "Train Epoch: 48 [124992/225000 (56%)] Loss: 20406.876953\n",
      "Train Epoch: 48 [127488/225000 (57%)] Loss: 20572.101562\n",
      "Train Epoch: 48 [129984/225000 (58%)] Loss: 19961.953125\n",
      "Train Epoch: 48 [132480/225000 (59%)] Loss: 20620.097656\n",
      "Train Epoch: 48 [134976/225000 (60%)] Loss: 19860.968750\n",
      "Train Epoch: 48 [137472/225000 (61%)] Loss: 19805.113281\n",
      "Train Epoch: 48 [139968/225000 (62%)] Loss: 19948.976562\n",
      "Train Epoch: 48 [142464/225000 (63%)] Loss: 20164.517578\n",
      "Train Epoch: 48 [144960/225000 (64%)] Loss: 20210.166016\n",
      "Train Epoch: 48 [147456/225000 (66%)] Loss: 19879.183594\n",
      "Train Epoch: 48 [149952/225000 (67%)] Loss: 20235.476562\n",
      "Train Epoch: 48 [152448/225000 (68%)] Loss: 20372.460938\n",
      "Train Epoch: 48 [154944/225000 (69%)] Loss: 19774.128906\n",
      "Train Epoch: 48 [157440/225000 (70%)] Loss: 19921.511719\n",
      "Train Epoch: 48 [159936/225000 (71%)] Loss: 20296.841797\n",
      "Train Epoch: 48 [162432/225000 (72%)] Loss: 20605.888672\n",
      "Train Epoch: 48 [164928/225000 (73%)] Loss: 20317.636719\n",
      "Train Epoch: 48 [167424/225000 (74%)] Loss: 20036.871094\n",
      "Train Epoch: 48 [169920/225000 (76%)] Loss: 19808.472656\n",
      "Train Epoch: 48 [172416/225000 (77%)] Loss: 20180.710938\n",
      "Train Epoch: 48 [174912/225000 (78%)] Loss: 19915.644531\n",
      "Train Epoch: 48 [177408/225000 (79%)] Loss: 20162.425781\n",
      "Train Epoch: 48 [179904/225000 (80%)] Loss: 20585.927734\n",
      "Train Epoch: 48 [182400/225000 (81%)] Loss: 20104.242188\n",
      "Train Epoch: 48 [184896/225000 (82%)] Loss: 20003.830078\n",
      "Train Epoch: 48 [187392/225000 (83%)] Loss: 20046.523438\n",
      "Train Epoch: 48 [189888/225000 (84%)] Loss: 20131.531250\n",
      "Train Epoch: 48 [192384/225000 (86%)] Loss: 19812.800781\n",
      "Train Epoch: 48 [194880/225000 (87%)] Loss: 20105.523438\n",
      "Train Epoch: 48 [197376/225000 (88%)] Loss: 20049.648438\n",
      "Train Epoch: 48 [199872/225000 (89%)] Loss: 20139.070312\n",
      "Train Epoch: 48 [202368/225000 (90%)] Loss: 20276.824219\n",
      "Train Epoch: 48 [204864/225000 (91%)] Loss: 19828.402344\n",
      "Train Epoch: 48 [207360/225000 (92%)] Loss: 20544.962891\n",
      "Train Epoch: 48 [209856/225000 (93%)] Loss: 20384.941406\n",
      "Train Epoch: 48 [212352/225000 (94%)] Loss: 20549.894531\n",
      "Train Epoch: 48 [214848/225000 (95%)] Loss: 19847.910156\n",
      "Train Epoch: 48 [217344/225000 (97%)] Loss: 19888.539062\n",
      "Train Epoch: 48 [219840/225000 (98%)] Loss: 20068.742188\n",
      "Train Epoch: 48 [222336/225000 (99%)] Loss: 20068.150391\n",
      "Train Epoch: 48 [224832/225000 (100%)] Loss: 20480.625000\n",
      "    epoch          : 48\n",
      "    loss           : 20246.434455324765\n",
      "    val_loss       : 20154.434922069082\n",
      "Train Epoch: 49 [192/225000 (0%)] Loss: 20368.769531\n",
      "Train Epoch: 49 [2688/225000 (1%)] Loss: 20840.281250\n",
      "Train Epoch: 49 [5184/225000 (2%)] Loss: 20344.339844\n",
      "Train Epoch: 49 [7680/225000 (3%)] Loss: 20201.669922\n",
      "Train Epoch: 49 [10176/225000 (5%)] Loss: 20662.750000\n",
      "Train Epoch: 49 [12672/225000 (6%)] Loss: 20477.183594\n",
      "Train Epoch: 49 [15168/225000 (7%)] Loss: 20582.314453\n",
      "Train Epoch: 49 [17664/225000 (8%)] Loss: 20058.007812\n",
      "Train Epoch: 49 [20160/225000 (9%)] Loss: 20103.208984\n",
      "Train Epoch: 49 [22656/225000 (10%)] Loss: 20261.199219\n",
      "Train Epoch: 49 [25152/225000 (11%)] Loss: 19783.363281\n",
      "Train Epoch: 49 [27648/225000 (12%)] Loss: 20439.062500\n",
      "Train Epoch: 49 [30144/225000 (13%)] Loss: 20392.265625\n",
      "Train Epoch: 49 [32640/225000 (15%)] Loss: 19987.820312\n",
      "Train Epoch: 49 [35136/225000 (16%)] Loss: 19502.417969\n",
      "Train Epoch: 49 [37632/225000 (17%)] Loss: 20146.769531\n",
      "Train Epoch: 49 [40128/225000 (18%)] Loss: 19804.312500\n",
      "Train Epoch: 49 [42624/225000 (19%)] Loss: 20085.710938\n",
      "Train Epoch: 49 [45120/225000 (20%)] Loss: 19949.824219\n",
      "Train Epoch: 49 [47616/225000 (21%)] Loss: 19781.767578\n",
      "Train Epoch: 49 [50112/225000 (22%)] Loss: 20228.484375\n",
      "Train Epoch: 49 [52608/225000 (23%)] Loss: 20029.179688\n",
      "Train Epoch: 49 [55104/225000 (24%)] Loss: 20400.207031\n",
      "Train Epoch: 49 [57600/225000 (26%)] Loss: 20537.322266\n",
      "Train Epoch: 49 [60096/225000 (27%)] Loss: 20233.484375\n",
      "Train Epoch: 49 [62592/225000 (28%)] Loss: 20018.742188\n",
      "Train Epoch: 49 [65088/225000 (29%)] Loss: 20377.224609\n",
      "Train Epoch: 49 [67584/225000 (30%)] Loss: 20212.451172\n",
      "Train Epoch: 49 [70080/225000 (31%)] Loss: 20521.468750\n",
      "Train Epoch: 49 [72576/225000 (32%)] Loss: 20301.847656\n",
      "Train Epoch: 49 [75072/225000 (33%)] Loss: 20293.210938\n",
      "Train Epoch: 49 [77568/225000 (34%)] Loss: 20279.789062\n",
      "Train Epoch: 49 [80064/225000 (36%)] Loss: 20051.523438\n",
      "Train Epoch: 49 [82560/225000 (37%)] Loss: 20358.375000\n",
      "Train Epoch: 49 [85056/225000 (38%)] Loss: 20127.687500\n",
      "Train Epoch: 49 [87552/225000 (39%)] Loss: 20342.544922\n",
      "Train Epoch: 49 [90048/225000 (40%)] Loss: 20349.746094\n",
      "Train Epoch: 49 [92544/225000 (41%)] Loss: 20281.361328\n",
      "Train Epoch: 49 [95040/225000 (42%)] Loss: 20645.783203\n",
      "Train Epoch: 49 [97536/225000 (43%)] Loss: 20632.464844\n",
      "Train Epoch: 49 [100032/225000 (44%)] Loss: 20045.587891\n",
      "Train Epoch: 49 [102528/225000 (46%)] Loss: 20387.554688\n",
      "Train Epoch: 49 [105024/225000 (47%)] Loss: 20046.314453\n",
      "Train Epoch: 49 [107520/225000 (48%)] Loss: 20352.238281\n",
      "Train Epoch: 49 [110016/225000 (49%)] Loss: 20728.074219\n",
      "Train Epoch: 49 [112512/225000 (50%)] Loss: 20222.261719\n",
      "Train Epoch: 49 [115008/225000 (51%)] Loss: 21011.435547\n",
      "Train Epoch: 49 [117504/225000 (52%)] Loss: 20346.066406\n",
      "Train Epoch: 49 [120000/225000 (53%)] Loss: 20138.599609\n",
      "Train Epoch: 49 [122496/225000 (54%)] Loss: 20197.849609\n",
      "Train Epoch: 49 [124992/225000 (56%)] Loss: 20433.333984\n",
      "Train Epoch: 49 [127488/225000 (57%)] Loss: 19811.710938\n",
      "Train Epoch: 49 [129984/225000 (58%)] Loss: 19922.656250\n",
      "Train Epoch: 49 [132480/225000 (59%)] Loss: 20033.812500\n",
      "Train Epoch: 49 [134976/225000 (60%)] Loss: 20840.144531\n",
      "Train Epoch: 49 [137472/225000 (61%)] Loss: 20188.937500\n",
      "Train Epoch: 49 [139968/225000 (62%)] Loss: 20085.515625\n",
      "Train Epoch: 49 [142464/225000 (63%)] Loss: 20334.414062\n",
      "Train Epoch: 49 [144960/225000 (64%)] Loss: 20619.085938\n",
      "Train Epoch: 49 [147456/225000 (66%)] Loss: 20575.068359\n",
      "Train Epoch: 49 [149952/225000 (67%)] Loss: 20317.164062\n",
      "Train Epoch: 49 [152448/225000 (68%)] Loss: 20323.839844\n",
      "Train Epoch: 49 [154944/225000 (69%)] Loss: 20179.316406\n",
      "Train Epoch: 49 [157440/225000 (70%)] Loss: 20242.621094\n",
      "Train Epoch: 49 [159936/225000 (71%)] Loss: 20201.208984\n",
      "Train Epoch: 49 [162432/225000 (72%)] Loss: 20073.464844\n",
      "Train Epoch: 49 [164928/225000 (73%)] Loss: 20000.722656\n",
      "Train Epoch: 49 [167424/225000 (74%)] Loss: 20070.882812\n",
      "Train Epoch: 49 [169920/225000 (76%)] Loss: 19983.636719\n",
      "Train Epoch: 49 [172416/225000 (77%)] Loss: 19929.679688\n",
      "Train Epoch: 49 [174912/225000 (78%)] Loss: 20487.474609\n",
      "Train Epoch: 49 [177408/225000 (79%)] Loss: 20367.953125\n",
      "Train Epoch: 49 [179904/225000 (80%)] Loss: 19903.556641\n",
      "Train Epoch: 49 [182400/225000 (81%)] Loss: 20201.757812\n",
      "Train Epoch: 49 [184896/225000 (82%)] Loss: 20050.666016\n",
      "Train Epoch: 49 [187392/225000 (83%)] Loss: 20247.658203\n",
      "Train Epoch: 49 [189888/225000 (84%)] Loss: 20368.677734\n",
      "Train Epoch: 49 [192384/225000 (86%)] Loss: 19918.617188\n",
      "Train Epoch: 49 [194880/225000 (87%)] Loss: 20344.824219\n",
      "Train Epoch: 49 [197376/225000 (88%)] Loss: 20300.343750\n",
      "Train Epoch: 49 [199872/225000 (89%)] Loss: 20270.816406\n",
      "Train Epoch: 49 [202368/225000 (90%)] Loss: 20273.441406\n",
      "Train Epoch: 49 [204864/225000 (91%)] Loss: 19843.527344\n",
      "Train Epoch: 49 [207360/225000 (92%)] Loss: 19774.869141\n",
      "Train Epoch: 49 [209856/225000 (93%)] Loss: 20111.191406\n",
      "Train Epoch: 49 [212352/225000 (94%)] Loss: 20401.335938\n",
      "Train Epoch: 49 [214848/225000 (95%)] Loss: 20953.480469\n",
      "Train Epoch: 49 [217344/225000 (97%)] Loss: 20184.003906\n",
      "Train Epoch: 49 [219840/225000 (98%)] Loss: 20205.449219\n",
      "Train Epoch: 49 [222336/225000 (99%)] Loss: 20618.521484\n",
      "Train Epoch: 49 [224832/225000 (100%)] Loss: 19926.875000\n",
      "    epoch          : 49\n",
      "    loss           : 20256.16214103829\n",
      "    val_loss       : 20143.5452929262\n",
      "Train Epoch: 50 [192/225000 (0%)] Loss: 20380.937500\n",
      "Train Epoch: 50 [2688/225000 (1%)] Loss: 20037.605469\n",
      "Train Epoch: 50 [5184/225000 (2%)] Loss: 20386.078125\n",
      "Train Epoch: 50 [7680/225000 (3%)] Loss: 20387.449219\n",
      "Train Epoch: 50 [10176/225000 (5%)] Loss: 20129.746094\n",
      "Train Epoch: 50 [12672/225000 (6%)] Loss: 20591.218750\n",
      "Train Epoch: 50 [15168/225000 (7%)] Loss: 20073.800781\n",
      "Train Epoch: 50 [17664/225000 (8%)] Loss: 20328.492188\n",
      "Train Epoch: 50 [20160/225000 (9%)] Loss: 20414.951172\n",
      "Train Epoch: 50 [22656/225000 (10%)] Loss: 20307.449219\n",
      "Train Epoch: 50 [25152/225000 (11%)] Loss: 20413.589844\n",
      "Train Epoch: 50 [27648/225000 (12%)] Loss: 19972.765625\n",
      "Train Epoch: 50 [30144/225000 (13%)] Loss: 20195.382812\n",
      "Train Epoch: 50 [32640/225000 (15%)] Loss: 20070.179688\n",
      "Train Epoch: 50 [35136/225000 (16%)] Loss: 19988.015625\n",
      "Train Epoch: 50 [37632/225000 (17%)] Loss: 20372.345703\n",
      "Train Epoch: 50 [40128/225000 (18%)] Loss: 20445.603516\n",
      "Train Epoch: 50 [42624/225000 (19%)] Loss: 20574.917969\n",
      "Train Epoch: 50 [45120/225000 (20%)] Loss: 20081.542969\n",
      "Train Epoch: 50 [47616/225000 (21%)] Loss: 19703.679688\n",
      "Train Epoch: 50 [50112/225000 (22%)] Loss: 20844.962891\n",
      "Train Epoch: 50 [52608/225000 (23%)] Loss: 20513.023438\n",
      "Train Epoch: 50 [55104/225000 (24%)] Loss: 20588.523438\n",
      "Train Epoch: 50 [57600/225000 (26%)] Loss: 19559.183594\n",
      "Train Epoch: 50 [60096/225000 (27%)] Loss: 20521.988281\n",
      "Train Epoch: 50 [62592/225000 (28%)] Loss: 20103.707031\n",
      "Train Epoch: 50 [65088/225000 (29%)] Loss: 20103.007812\n",
      "Train Epoch: 50 [67584/225000 (30%)] Loss: 20048.804688\n",
      "Train Epoch: 50 [70080/225000 (31%)] Loss: 20121.177734\n",
      "Train Epoch: 50 [72576/225000 (32%)] Loss: 19944.355469\n",
      "Train Epoch: 50 [75072/225000 (33%)] Loss: 19766.480469\n",
      "Train Epoch: 50 [77568/225000 (34%)] Loss: 20191.847656\n",
      "Train Epoch: 50 [80064/225000 (36%)] Loss: 20357.724609\n",
      "Train Epoch: 50 [82560/225000 (37%)] Loss: 20912.898438\n",
      "Train Epoch: 50 [85056/225000 (38%)] Loss: 20755.386719\n",
      "Train Epoch: 50 [87552/225000 (39%)] Loss: 20489.644531\n",
      "Train Epoch: 50 [90048/225000 (40%)] Loss: 20480.242188\n",
      "Train Epoch: 50 [92544/225000 (41%)] Loss: 19788.007812\n",
      "Train Epoch: 50 [95040/225000 (42%)] Loss: 19845.113281\n",
      "Train Epoch: 50 [97536/225000 (43%)] Loss: 19898.949219\n",
      "Train Epoch: 50 [100032/225000 (44%)] Loss: 20200.330078\n",
      "Train Epoch: 50 [102528/225000 (46%)] Loss: 20114.005859\n",
      "Train Epoch: 50 [105024/225000 (47%)] Loss: 19894.138672\n",
      "Train Epoch: 50 [107520/225000 (48%)] Loss: 20261.777344\n",
      "Train Epoch: 50 [110016/225000 (49%)] Loss: 20578.552734\n",
      "Train Epoch: 50 [112512/225000 (50%)] Loss: 20103.324219\n",
      "Train Epoch: 50 [115008/225000 (51%)] Loss: 20828.107422\n",
      "Train Epoch: 50 [117504/225000 (52%)] Loss: 19921.646484\n",
      "Train Epoch: 50 [120000/225000 (53%)] Loss: 19974.710938\n",
      "Train Epoch: 50 [122496/225000 (54%)] Loss: 20338.773438\n",
      "Train Epoch: 50 [124992/225000 (56%)] Loss: 20127.826172\n",
      "Train Epoch: 50 [127488/225000 (57%)] Loss: 20343.355469\n",
      "Train Epoch: 50 [129984/225000 (58%)] Loss: 20158.023438\n",
      "Train Epoch: 50 [132480/225000 (59%)] Loss: 19767.496094\n",
      "Train Epoch: 50 [134976/225000 (60%)] Loss: 19912.677734\n",
      "Train Epoch: 50 [137472/225000 (61%)] Loss: 20275.792969\n",
      "Train Epoch: 50 [139968/225000 (62%)] Loss: 20737.566406\n",
      "Train Epoch: 50 [142464/225000 (63%)] Loss: 20240.023438\n",
      "Train Epoch: 50 [144960/225000 (64%)] Loss: 20155.255859\n",
      "Train Epoch: 50 [147456/225000 (66%)] Loss: 19503.591797\n",
      "Train Epoch: 50 [149952/225000 (67%)] Loss: 20280.455078\n",
      "Train Epoch: 50 [152448/225000 (68%)] Loss: 20432.113281\n",
      "Train Epoch: 50 [154944/225000 (69%)] Loss: 19827.277344\n",
      "Train Epoch: 50 [157440/225000 (70%)] Loss: 19916.337891\n",
      "Train Epoch: 50 [159936/225000 (71%)] Loss: 19819.328125\n",
      "Train Epoch: 50 [162432/225000 (72%)] Loss: 20191.494141\n",
      "Train Epoch: 50 [164928/225000 (73%)] Loss: 19950.421875\n",
      "Train Epoch: 50 [167424/225000 (74%)] Loss: 20448.855469\n",
      "Train Epoch: 50 [169920/225000 (76%)] Loss: 20347.328125\n",
      "Train Epoch: 50 [172416/225000 (77%)] Loss: 20201.091797\n",
      "Train Epoch: 50 [174912/225000 (78%)] Loss: 20323.164062\n",
      "Train Epoch: 50 [177408/225000 (79%)] Loss: 19903.955078\n",
      "Train Epoch: 50 [179904/225000 (80%)] Loss: 20201.642578\n",
      "Train Epoch: 50 [182400/225000 (81%)] Loss: 20460.570312\n",
      "Train Epoch: 50 [184896/225000 (82%)] Loss: 20474.501953\n",
      "Train Epoch: 50 [187392/225000 (83%)] Loss: 20228.046875\n",
      "Train Epoch: 50 [189888/225000 (84%)] Loss: 20807.898438\n",
      "Train Epoch: 50 [192384/225000 (86%)] Loss: 19874.027344\n",
      "Train Epoch: 50 [194880/225000 (87%)] Loss: 20319.558594\n",
      "Train Epoch: 50 [197376/225000 (88%)] Loss: 19786.677734\n",
      "Train Epoch: 50 [199872/225000 (89%)] Loss: 20169.152344\n",
      "Train Epoch: 50 [202368/225000 (90%)] Loss: 20524.343750\n",
      "Train Epoch: 50 [204864/225000 (91%)] Loss: 20504.984375\n",
      "Train Epoch: 50 [207360/225000 (92%)] Loss: 19892.005859\n",
      "Train Epoch: 50 [209856/225000 (93%)] Loss: 20139.855469\n",
      "Train Epoch: 50 [212352/225000 (94%)] Loss: 20145.265625\n",
      "Train Epoch: 50 [214848/225000 (95%)] Loss: 19964.808594\n",
      "Train Epoch: 50 [217344/225000 (97%)] Loss: 20041.277344\n",
      "Train Epoch: 50 [219840/225000 (98%)] Loss: 20078.800781\n",
      "Train Epoch: 50 [222336/225000 (99%)] Loss: 20480.382812\n",
      "Train Epoch: 50 [224832/225000 (100%)] Loss: 20215.558594\n",
      "    epoch          : 50\n",
      "    loss           : 20254.083579418195\n",
      "    val_loss       : 20129.925958857282\n",
      "Saving checkpoint: saved/models/Molecular_VaeCategory/0803_194629/checkpoint-epoch50.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 51 [192/225000 (0%)] Loss: 20347.597656\n",
      "Train Epoch: 51 [2688/225000 (1%)] Loss: 20063.138672\n",
      "Train Epoch: 51 [5184/225000 (2%)] Loss: 20235.945312\n",
      "Train Epoch: 51 [7680/225000 (3%)] Loss: 19951.753906\n",
      "Train Epoch: 51 [10176/225000 (5%)] Loss: 20156.773438\n",
      "Train Epoch: 51 [12672/225000 (6%)] Loss: 20180.980469\n",
      "Train Epoch: 51 [15168/225000 (7%)] Loss: 20418.058594\n",
      "Train Epoch: 51 [17664/225000 (8%)] Loss: 19651.722656\n",
      "Train Epoch: 51 [20160/225000 (9%)] Loss: 20086.281250\n",
      "Train Epoch: 51 [22656/225000 (10%)] Loss: 20030.152344\n",
      "Train Epoch: 51 [25152/225000 (11%)] Loss: 20397.287109\n",
      "Train Epoch: 51 [27648/225000 (12%)] Loss: 20969.035156\n",
      "Train Epoch: 51 [30144/225000 (13%)] Loss: 20599.437500\n",
      "Train Epoch: 51 [32640/225000 (15%)] Loss: 19930.625000\n",
      "Train Epoch: 51 [35136/225000 (16%)] Loss: 19738.427734\n",
      "Train Epoch: 51 [37632/225000 (17%)] Loss: 20063.667969\n",
      "Train Epoch: 51 [40128/225000 (18%)] Loss: 19933.324219\n",
      "Train Epoch: 51 [42624/225000 (19%)] Loss: 20033.933594\n",
      "Train Epoch: 51 [45120/225000 (20%)] Loss: 20342.992188\n",
      "Train Epoch: 51 [47616/225000 (21%)] Loss: 20182.470703\n",
      "Train Epoch: 51 [50112/225000 (22%)] Loss: 20112.572266\n",
      "Train Epoch: 51 [52608/225000 (23%)] Loss: 20160.294922\n",
      "Train Epoch: 51 [55104/225000 (24%)] Loss: 20400.378906\n",
      "Train Epoch: 51 [57600/225000 (26%)] Loss: 19804.386719\n",
      "Train Epoch: 51 [60096/225000 (27%)] Loss: 20283.574219\n",
      "Train Epoch: 51 [62592/225000 (28%)] Loss: 20017.312500\n",
      "Train Epoch: 51 [65088/225000 (29%)] Loss: 20204.060547\n",
      "Train Epoch: 51 [67584/225000 (30%)] Loss: 20773.156250\n",
      "Train Epoch: 51 [70080/225000 (31%)] Loss: 19880.574219\n",
      "Train Epoch: 51 [72576/225000 (32%)] Loss: 19908.435547\n",
      "Train Epoch: 51 [75072/225000 (33%)] Loss: 20049.816406\n",
      "Train Epoch: 51 [77568/225000 (34%)] Loss: 20517.468750\n",
      "Train Epoch: 51 [80064/225000 (36%)] Loss: 20001.341797\n",
      "Train Epoch: 51 [82560/225000 (37%)] Loss: 20462.398438\n",
      "Train Epoch: 51 [85056/225000 (38%)] Loss: 20368.449219\n",
      "Train Epoch: 51 [87552/225000 (39%)] Loss: 20182.919922\n",
      "Train Epoch: 51 [90048/225000 (40%)] Loss: 19571.152344\n",
      "Train Epoch: 51 [92544/225000 (41%)] Loss: 20371.148438\n",
      "Train Epoch: 51 [95040/225000 (42%)] Loss: 20422.992188\n",
      "Train Epoch: 51 [97536/225000 (43%)] Loss: 20180.234375\n",
      "Train Epoch: 51 [100032/225000 (44%)] Loss: 20464.507812\n",
      "Train Epoch: 51 [102528/225000 (46%)] Loss: 20422.484375\n",
      "Train Epoch: 51 [105024/225000 (47%)] Loss: 20112.894531\n",
      "Train Epoch: 51 [107520/225000 (48%)] Loss: 20264.851562\n",
      "Train Epoch: 51 [110016/225000 (49%)] Loss: 19970.710938\n",
      "Train Epoch: 51 [112512/225000 (50%)] Loss: 19770.730469\n",
      "Train Epoch: 51 [115008/225000 (51%)] Loss: 20290.574219\n",
      "Train Epoch: 51 [117504/225000 (52%)] Loss: 20132.660156\n",
      "Train Epoch: 51 [120000/225000 (53%)] Loss: 20346.136719\n",
      "Train Epoch: 51 [122496/225000 (54%)] Loss: 20301.613281\n",
      "Train Epoch: 51 [124992/225000 (56%)] Loss: 20279.269531\n",
      "Train Epoch: 51 [127488/225000 (57%)] Loss: 20052.277344\n",
      "Train Epoch: 51 [129984/225000 (58%)] Loss: 20030.255859\n",
      "Train Epoch: 51 [132480/225000 (59%)] Loss: 20534.773438\n",
      "Train Epoch: 51 [134976/225000 (60%)] Loss: 20271.021484\n",
      "Train Epoch: 51 [137472/225000 (61%)] Loss: 20773.136719\n",
      "Train Epoch: 51 [139968/225000 (62%)] Loss: 20193.867188\n",
      "Train Epoch: 51 [142464/225000 (63%)] Loss: 20429.527344\n",
      "Train Epoch: 51 [144960/225000 (64%)] Loss: 20262.867188\n",
      "Train Epoch: 51 [147456/225000 (66%)] Loss: 20040.101562\n",
      "Train Epoch: 51 [149952/225000 (67%)] Loss: 20314.574219\n",
      "Train Epoch: 51 [152448/225000 (68%)] Loss: 20459.191406\n",
      "Train Epoch: 51 [154944/225000 (69%)] Loss: 20891.392578\n",
      "Train Epoch: 51 [157440/225000 (70%)] Loss: 20203.074219\n",
      "Train Epoch: 51 [159936/225000 (71%)] Loss: 20189.111328\n",
      "Train Epoch: 51 [162432/225000 (72%)] Loss: 20297.826172\n",
      "Train Epoch: 51 [164928/225000 (73%)] Loss: 19871.119141\n",
      "Train Epoch: 51 [167424/225000 (74%)] Loss: 20185.738281\n",
      "Train Epoch: 51 [169920/225000 (76%)] Loss: 20243.341797\n",
      "Train Epoch: 51 [172416/225000 (77%)] Loss: 20220.568359\n",
      "Train Epoch: 51 [174912/225000 (78%)] Loss: 20259.410156\n",
      "Train Epoch: 51 [177408/225000 (79%)] Loss: 20082.740234\n",
      "Train Epoch: 51 [179904/225000 (80%)] Loss: 20084.304688\n",
      "Train Epoch: 51 [182400/225000 (81%)] Loss: 20512.542969\n",
      "Train Epoch: 51 [184896/225000 (82%)] Loss: 20468.500000\n",
      "Train Epoch: 51 [187392/225000 (83%)] Loss: 19858.285156\n",
      "Train Epoch: 51 [189888/225000 (84%)] Loss: 20284.746094\n",
      "Train Epoch: 51 [192384/225000 (86%)] Loss: 20348.748047\n",
      "Train Epoch: 51 [194880/225000 (87%)] Loss: 19874.091797\n",
      "Train Epoch: 51 [197376/225000 (88%)] Loss: 20801.244141\n",
      "Train Epoch: 51 [199872/225000 (89%)] Loss: 20124.263672\n",
      "Train Epoch: 51 [202368/225000 (90%)] Loss: 19853.476562\n",
      "Train Epoch: 51 [204864/225000 (91%)] Loss: 20597.128906\n",
      "Train Epoch: 51 [207360/225000 (92%)] Loss: 20151.263672\n",
      "Train Epoch: 51 [209856/225000 (93%)] Loss: 20568.046875\n",
      "Train Epoch: 51 [212352/225000 (94%)] Loss: 20192.027344\n",
      "Train Epoch: 51 [214848/225000 (95%)] Loss: 20166.355469\n",
      "Train Epoch: 51 [217344/225000 (97%)] Loss: 20743.134766\n",
      "Train Epoch: 51 [219840/225000 (98%)] Loss: 20212.478516\n",
      "Train Epoch: 51 [222336/225000 (99%)] Loss: 19787.089844\n",
      "Train Epoch: 51 [224832/225000 (100%)] Loss: 20204.554688\n",
      "    epoch          : 51\n",
      "    loss           : 20247.78973409503\n",
      "    val_loss       : 20113.9083173457\n",
      "Train Epoch: 52 [192/225000 (0%)] Loss: 19893.181641\n",
      "Train Epoch: 52 [2688/225000 (1%)] Loss: 19746.097656\n",
      "Train Epoch: 52 [5184/225000 (2%)] Loss: 20147.558594\n",
      "Train Epoch: 52 [7680/225000 (3%)] Loss: 20268.755859\n",
      "Train Epoch: 52 [10176/225000 (5%)] Loss: 20461.769531\n",
      "Train Epoch: 52 [12672/225000 (6%)] Loss: 20268.023438\n",
      "Train Epoch: 52 [15168/225000 (7%)] Loss: 20228.222656\n",
      "Train Epoch: 52 [17664/225000 (8%)] Loss: 20103.757812\n",
      "Train Epoch: 52 [20160/225000 (9%)] Loss: 20230.312500\n",
      "Train Epoch: 52 [22656/225000 (10%)] Loss: 20699.263672\n",
      "Train Epoch: 52 [25152/225000 (11%)] Loss: 20338.859375\n",
      "Train Epoch: 52 [27648/225000 (12%)] Loss: 20487.976562\n",
      "Train Epoch: 52 [30144/225000 (13%)] Loss: 20437.541016\n",
      "Train Epoch: 52 [32640/225000 (15%)] Loss: 19764.984375\n",
      "Train Epoch: 52 [35136/225000 (16%)] Loss: 20502.546875\n",
      "Train Epoch: 52 [37632/225000 (17%)] Loss: 20293.593750\n",
      "Train Epoch: 52 [40128/225000 (18%)] Loss: 19974.800781\n",
      "Train Epoch: 52 [42624/225000 (19%)] Loss: 20375.660156\n",
      "Train Epoch: 52 [45120/225000 (20%)] Loss: 20068.687500\n",
      "Train Epoch: 52 [47616/225000 (21%)] Loss: 20183.757812\n",
      "Train Epoch: 52 [50112/225000 (22%)] Loss: 20473.214844\n",
      "Train Epoch: 52 [52608/225000 (23%)] Loss: 20581.464844\n",
      "Train Epoch: 52 [55104/225000 (24%)] Loss: 20055.619141\n",
      "Train Epoch: 52 [57600/225000 (26%)] Loss: 20349.441406\n",
      "Train Epoch: 52 [60096/225000 (27%)] Loss: 19978.394531\n",
      "Train Epoch: 52 [62592/225000 (28%)] Loss: 20226.285156\n",
      "Train Epoch: 52 [65088/225000 (29%)] Loss: 20377.615234\n",
      "Train Epoch: 52 [67584/225000 (30%)] Loss: 20190.078125\n",
      "Train Epoch: 52 [70080/225000 (31%)] Loss: 20164.220703\n",
      "Train Epoch: 52 [72576/225000 (32%)] Loss: 20802.929688\n",
      "Train Epoch: 52 [75072/225000 (33%)] Loss: 20143.951172\n",
      "Train Epoch: 52 [77568/225000 (34%)] Loss: 20298.902344\n",
      "Train Epoch: 52 [80064/225000 (36%)] Loss: 20201.156250\n",
      "Train Epoch: 52 [82560/225000 (37%)] Loss: 20274.621094\n",
      "Train Epoch: 52 [85056/225000 (38%)] Loss: 19991.570312\n",
      "Train Epoch: 52 [87552/225000 (39%)] Loss: 20135.183594\n",
      "Train Epoch: 52 [90048/225000 (40%)] Loss: 20571.144531\n",
      "Train Epoch: 52 [92544/225000 (41%)] Loss: 20638.925781\n",
      "Train Epoch: 52 [95040/225000 (42%)] Loss: 19922.570312\n",
      "Train Epoch: 52 [97536/225000 (43%)] Loss: 20329.371094\n",
      "Train Epoch: 52 [100032/225000 (44%)] Loss: 20200.457031\n",
      "Train Epoch: 52 [102528/225000 (46%)] Loss: 20232.009766\n",
      "Train Epoch: 52 [105024/225000 (47%)] Loss: 19971.802734\n",
      "Train Epoch: 52 [107520/225000 (48%)] Loss: 20025.083984\n",
      "Train Epoch: 52 [110016/225000 (49%)] Loss: 20400.845703\n",
      "Train Epoch: 52 [112512/225000 (50%)] Loss: 20143.990234\n",
      "Train Epoch: 52 [115008/225000 (51%)] Loss: 19935.261719\n",
      "Train Epoch: 52 [117504/225000 (52%)] Loss: 20204.781250\n",
      "Train Epoch: 52 [120000/225000 (53%)] Loss: 19948.539062\n",
      "Train Epoch: 52 [122496/225000 (54%)] Loss: 20069.556641\n",
      "Train Epoch: 52 [124992/225000 (56%)] Loss: 20761.955078\n",
      "Train Epoch: 52 [127488/225000 (57%)] Loss: 19947.017578\n",
      "Train Epoch: 52 [129984/225000 (58%)] Loss: 19827.814453\n",
      "Train Epoch: 52 [132480/225000 (59%)] Loss: 19996.404297\n",
      "Train Epoch: 52 [134976/225000 (60%)] Loss: 20148.183594\n",
      "Train Epoch: 52 [137472/225000 (61%)] Loss: 20260.146484\n",
      "Train Epoch: 52 [139968/225000 (62%)] Loss: 20380.265625\n",
      "Train Epoch: 52 [142464/225000 (63%)] Loss: 20362.121094\n",
      "Train Epoch: 52 [144960/225000 (64%)] Loss: 20273.623047\n",
      "Train Epoch: 52 [147456/225000 (66%)] Loss: 20501.457031\n",
      "Train Epoch: 52 [149952/225000 (67%)] Loss: 20095.060547\n",
      "Train Epoch: 52 [152448/225000 (68%)] Loss: 20188.273438\n",
      "Train Epoch: 52 [154944/225000 (69%)] Loss: 20349.876953\n",
      "Train Epoch: 52 [157440/225000 (70%)] Loss: 19820.894531\n",
      "Train Epoch: 52 [159936/225000 (71%)] Loss: 20302.937500\n",
      "Train Epoch: 52 [162432/225000 (72%)] Loss: 19978.992188\n",
      "Train Epoch: 52 [164928/225000 (73%)] Loss: 20112.412109\n",
      "Train Epoch: 52 [167424/225000 (74%)] Loss: 20319.253906\n",
      "Train Epoch: 52 [169920/225000 (76%)] Loss: 19704.937500\n",
      "Train Epoch: 52 [172416/225000 (77%)] Loss: 20015.412109\n",
      "Train Epoch: 52 [174912/225000 (78%)] Loss: 20230.980469\n",
      "Train Epoch: 52 [177408/225000 (79%)] Loss: 20007.689453\n",
      "Train Epoch: 52 [179904/225000 (80%)] Loss: 19730.462891\n",
      "Train Epoch: 52 [182400/225000 (81%)] Loss: 20319.644531\n",
      "Train Epoch: 52 [184896/225000 (82%)] Loss: 20268.576172\n",
      "Train Epoch: 52 [187392/225000 (83%)] Loss: 20010.080078\n",
      "Train Epoch: 52 [189888/225000 (84%)] Loss: 19964.363281\n",
      "Train Epoch: 52 [192384/225000 (86%)] Loss: 20161.832031\n",
      "Train Epoch: 52 [194880/225000 (87%)] Loss: 20099.210938\n",
      "Train Epoch: 52 [197376/225000 (88%)] Loss: 20295.429688\n",
      "Train Epoch: 52 [199872/225000 (89%)] Loss: 20444.453125\n",
      "Train Epoch: 52 [202368/225000 (90%)] Loss: 20490.281250\n",
      "Train Epoch: 52 [204864/225000 (91%)] Loss: 20407.380859\n",
      "Train Epoch: 52 [207360/225000 (92%)] Loss: 20147.121094\n",
      "Train Epoch: 52 [209856/225000 (93%)] Loss: 19978.796875\n",
      "Train Epoch: 52 [212352/225000 (94%)] Loss: 36379.832031\n",
      "Train Epoch: 52 [214848/225000 (95%)] Loss: 20431.746094\n",
      "Train Epoch: 52 [217344/225000 (97%)] Loss: 20156.992188\n",
      "Train Epoch: 52 [219840/225000 (98%)] Loss: 20352.429688\n",
      "Train Epoch: 52 [222336/225000 (99%)] Loss: 20446.890625\n",
      "Train Epoch: 52 [224832/225000 (100%)] Loss: 20507.429688\n",
      "    epoch          : 52\n",
      "    loss           : 20218.487061380118\n",
      "    val_loss       : 20089.621385434657\n",
      "Train Epoch: 53 [192/225000 (0%)] Loss: 19869.246094\n",
      "Train Epoch: 53 [2688/225000 (1%)] Loss: 19829.312500\n",
      "Train Epoch: 53 [5184/225000 (2%)] Loss: 19985.753906\n",
      "Train Epoch: 53 [7680/225000 (3%)] Loss: 20148.125000\n",
      "Train Epoch: 53 [10176/225000 (5%)] Loss: 20410.035156\n",
      "Train Epoch: 53 [12672/225000 (6%)] Loss: 20323.917969\n",
      "Train Epoch: 53 [15168/225000 (7%)] Loss: 20167.546875\n",
      "Train Epoch: 53 [17664/225000 (8%)] Loss: 20456.355469\n",
      "Train Epoch: 53 [20160/225000 (9%)] Loss: 20475.535156\n",
      "Train Epoch: 53 [22656/225000 (10%)] Loss: 20078.906250\n",
      "Train Epoch: 53 [25152/225000 (11%)] Loss: 20588.242188\n",
      "Train Epoch: 53 [27648/225000 (12%)] Loss: 20294.425781\n",
      "Train Epoch: 53 [30144/225000 (13%)] Loss: 20482.214844\n",
      "Train Epoch: 53 [32640/225000 (15%)] Loss: 20292.824219\n",
      "Train Epoch: 53 [35136/225000 (16%)] Loss: 20254.142578\n",
      "Train Epoch: 53 [37632/225000 (17%)] Loss: 20178.074219\n",
      "Train Epoch: 53 [40128/225000 (18%)] Loss: 19974.218750\n",
      "Train Epoch: 53 [42624/225000 (19%)] Loss: 20140.115234\n",
      "Train Epoch: 53 [45120/225000 (20%)] Loss: 20316.886719\n",
      "Train Epoch: 53 [47616/225000 (21%)] Loss: 20230.910156\n",
      "Train Epoch: 53 [50112/225000 (22%)] Loss: 20153.412109\n",
      "Train Epoch: 53 [52608/225000 (23%)] Loss: 20354.447266\n",
      "Train Epoch: 53 [55104/225000 (24%)] Loss: 20259.582031\n",
      "Train Epoch: 53 [57600/225000 (26%)] Loss: 20462.902344\n",
      "Train Epoch: 53 [60096/225000 (27%)] Loss: 20332.310547\n",
      "Train Epoch: 53 [62592/225000 (28%)] Loss: 20116.832031\n",
      "Train Epoch: 53 [65088/225000 (29%)] Loss: 19921.328125\n",
      "Train Epoch: 53 [67584/225000 (30%)] Loss: 20279.009766\n",
      "Train Epoch: 53 [70080/225000 (31%)] Loss: 20343.697266\n",
      "Train Epoch: 53 [72576/225000 (32%)] Loss: 20515.710938\n",
      "Train Epoch: 53 [75072/225000 (33%)] Loss: 20113.015625\n",
      "Train Epoch: 53 [77568/225000 (34%)] Loss: 19938.722656\n",
      "Train Epoch: 53 [80064/225000 (36%)] Loss: 20126.878906\n",
      "Train Epoch: 53 [82560/225000 (37%)] Loss: 20251.777344\n",
      "Train Epoch: 53 [85056/225000 (38%)] Loss: 20462.089844\n",
      "Train Epoch: 53 [87552/225000 (39%)] Loss: 20036.183594\n",
      "Train Epoch: 53 [90048/225000 (40%)] Loss: 20167.267578\n",
      "Train Epoch: 53 [92544/225000 (41%)] Loss: 20045.093750\n",
      "Train Epoch: 53 [95040/225000 (42%)] Loss: 20945.265625\n",
      "Train Epoch: 53 [97536/225000 (43%)] Loss: 19952.714844\n",
      "Train Epoch: 53 [100032/225000 (44%)] Loss: 20314.074219\n",
      "Train Epoch: 53 [102528/225000 (46%)] Loss: 19783.238281\n",
      "Train Epoch: 53 [105024/225000 (47%)] Loss: 19845.132812\n",
      "Train Epoch: 53 [107520/225000 (48%)] Loss: 20116.498047\n",
      "Train Epoch: 53 [110016/225000 (49%)] Loss: 20055.390625\n",
      "Train Epoch: 53 [112512/225000 (50%)] Loss: 20076.464844\n",
      "Train Epoch: 53 [115008/225000 (51%)] Loss: 19828.742188\n",
      "Train Epoch: 53 [117504/225000 (52%)] Loss: 20771.931641\n",
      "Train Epoch: 53 [120000/225000 (53%)] Loss: 19994.285156\n",
      "Train Epoch: 53 [122496/225000 (54%)] Loss: 20160.406250\n",
      "Train Epoch: 53 [124992/225000 (56%)] Loss: 20067.804688\n",
      "Train Epoch: 53 [127488/225000 (57%)] Loss: 20027.101562\n",
      "Train Epoch: 53 [129984/225000 (58%)] Loss: 20357.296875\n",
      "Train Epoch: 53 [132480/225000 (59%)] Loss: 20137.144531\n",
      "Train Epoch: 53 [134976/225000 (60%)] Loss: 20114.261719\n",
      "Train Epoch: 53 [137472/225000 (61%)] Loss: 20254.187500\n",
      "Train Epoch: 53 [139968/225000 (62%)] Loss: 20297.175781\n",
      "Train Epoch: 53 [142464/225000 (63%)] Loss: 19887.714844\n",
      "Train Epoch: 53 [144960/225000 (64%)] Loss: 20391.214844\n",
      "Train Epoch: 53 [147456/225000 (66%)] Loss: 20137.414062\n",
      "Train Epoch: 53 [149952/225000 (67%)] Loss: 20245.253906\n",
      "Train Epoch: 53 [152448/225000 (68%)] Loss: 20694.826172\n",
      "Train Epoch: 53 [154944/225000 (69%)] Loss: 20376.308594\n",
      "Train Epoch: 53 [157440/225000 (70%)] Loss: 19915.421875\n",
      "Train Epoch: 53 [159936/225000 (71%)] Loss: 19726.666016\n",
      "Train Epoch: 53 [162432/225000 (72%)] Loss: 20390.044922\n",
      "Train Epoch: 53 [164928/225000 (73%)] Loss: 20695.824219\n",
      "Train Epoch: 53 [167424/225000 (74%)] Loss: 19819.078125\n",
      "Train Epoch: 53 [169920/225000 (76%)] Loss: 20055.429688\n",
      "Train Epoch: 53 [172416/225000 (77%)] Loss: 20503.146484\n",
      "Train Epoch: 53 [174912/225000 (78%)] Loss: 20798.679688\n",
      "Train Epoch: 53 [177408/225000 (79%)] Loss: 20270.593750\n",
      "Train Epoch: 53 [179904/225000 (80%)] Loss: 19964.402344\n",
      "Train Epoch: 53 [182400/225000 (81%)] Loss: 19952.039062\n",
      "Train Epoch: 53 [184896/225000 (82%)] Loss: 20089.953125\n",
      "Train Epoch: 53 [187392/225000 (83%)] Loss: 20187.785156\n",
      "Train Epoch: 53 [189888/225000 (84%)] Loss: 20561.410156\n",
      "Train Epoch: 53 [192384/225000 (86%)] Loss: 20353.046875\n",
      "Train Epoch: 53 [194880/225000 (87%)] Loss: 20148.962891\n",
      "Train Epoch: 53 [197376/225000 (88%)] Loss: 20504.582031\n",
      "Train Epoch: 53 [199872/225000 (89%)] Loss: 19991.880859\n",
      "Train Epoch: 53 [202368/225000 (90%)] Loss: 20195.650391\n",
      "Train Epoch: 53 [204864/225000 (91%)] Loss: 20508.896484\n",
      "Train Epoch: 53 [207360/225000 (92%)] Loss: 20919.183594\n",
      "Train Epoch: 53 [209856/225000 (93%)] Loss: 20419.453125\n",
      "Train Epoch: 53 [212352/225000 (94%)] Loss: 20223.257812\n",
      "Train Epoch: 53 [214848/225000 (95%)] Loss: 20272.531250\n",
      "Train Epoch: 53 [217344/225000 (97%)] Loss: 20032.613281\n",
      "Train Epoch: 53 [219840/225000 (98%)] Loss: 20388.046875\n",
      "Train Epoch: 53 [222336/225000 (99%)] Loss: 19716.978516\n",
      "Train Epoch: 53 [224832/225000 (100%)] Loss: 19755.455078\n",
      "    epoch          : 53\n",
      "    loss           : 20183.795281836603\n",
      "    val_loss       : 20076.837777173245\n",
      "Train Epoch: 54 [192/225000 (0%)] Loss: 20114.166016\n",
      "Train Epoch: 54 [2688/225000 (1%)] Loss: 20023.921875\n",
      "Train Epoch: 54 [5184/225000 (2%)] Loss: 20232.378906\n",
      "Train Epoch: 54 [7680/225000 (3%)] Loss: 20570.544922\n",
      "Train Epoch: 54 [10176/225000 (5%)] Loss: 19847.921875\n",
      "Train Epoch: 54 [12672/225000 (6%)] Loss: 20283.574219\n",
      "Train Epoch: 54 [15168/225000 (7%)] Loss: 20243.324219\n",
      "Train Epoch: 54 [17664/225000 (8%)] Loss: 20181.398438\n",
      "Train Epoch: 54 [20160/225000 (9%)] Loss: 20230.656250\n",
      "Train Epoch: 54 [22656/225000 (10%)] Loss: 20260.789062\n",
      "Train Epoch: 54 [25152/225000 (11%)] Loss: 19941.640625\n",
      "Train Epoch: 54 [27648/225000 (12%)] Loss: 20187.166016\n",
      "Train Epoch: 54 [30144/225000 (13%)] Loss: 20030.386719\n",
      "Train Epoch: 54 [32640/225000 (15%)] Loss: 20078.488281\n",
      "Train Epoch: 54 [35136/225000 (16%)] Loss: 20661.226562\n",
      "Train Epoch: 54 [37632/225000 (17%)] Loss: 20479.832031\n",
      "Train Epoch: 54 [40128/225000 (18%)] Loss: 20167.867188\n",
      "Train Epoch: 54 [42624/225000 (19%)] Loss: 20116.691406\n",
      "Train Epoch: 54 [45120/225000 (20%)] Loss: 19896.312500\n",
      "Train Epoch: 54 [47616/225000 (21%)] Loss: 20261.734375\n",
      "Train Epoch: 54 [50112/225000 (22%)] Loss: 19986.746094\n",
      "Train Epoch: 54 [52608/225000 (23%)] Loss: 19829.082031\n",
      "Train Epoch: 54 [55104/225000 (24%)] Loss: 20171.207031\n",
      "Train Epoch: 54 [57600/225000 (26%)] Loss: 20347.394531\n",
      "Train Epoch: 54 [60096/225000 (27%)] Loss: 20132.792969\n",
      "Train Epoch: 54 [62592/225000 (28%)] Loss: 20301.037109\n",
      "Train Epoch: 54 [65088/225000 (29%)] Loss: 20274.572266\n",
      "Train Epoch: 54 [67584/225000 (30%)] Loss: 20510.810547\n",
      "Train Epoch: 54 [70080/225000 (31%)] Loss: 19872.480469\n",
      "Train Epoch: 54 [72576/225000 (32%)] Loss: 20293.265625\n",
      "Train Epoch: 54 [75072/225000 (33%)] Loss: 20423.175781\n",
      "Train Epoch: 54 [77568/225000 (34%)] Loss: 19880.539062\n",
      "Train Epoch: 54 [80064/225000 (36%)] Loss: 19503.371094\n",
      "Train Epoch: 54 [82560/225000 (37%)] Loss: 19924.466797\n",
      "Train Epoch: 54 [85056/225000 (38%)] Loss: 20331.750000\n",
      "Train Epoch: 54 [87552/225000 (39%)] Loss: 20553.277344\n",
      "Train Epoch: 54 [90048/225000 (40%)] Loss: 19884.945312\n",
      "Train Epoch: 54 [92544/225000 (41%)] Loss: 20204.035156\n",
      "Train Epoch: 54 [95040/225000 (42%)] Loss: 20223.826172\n",
      "Train Epoch: 54 [97536/225000 (43%)] Loss: 20193.169922\n",
      "Train Epoch: 54 [100032/225000 (44%)] Loss: 20201.763672\n",
      "Train Epoch: 54 [102528/225000 (46%)] Loss: 19981.281250\n",
      "Train Epoch: 54 [105024/225000 (47%)] Loss: 20261.730469\n",
      "Train Epoch: 54 [107520/225000 (48%)] Loss: 20242.986328\n",
      "Train Epoch: 54 [110016/225000 (49%)] Loss: 20387.738281\n",
      "Train Epoch: 54 [112512/225000 (50%)] Loss: 20259.656250\n",
      "Train Epoch: 54 [115008/225000 (51%)] Loss: 20121.664062\n",
      "Train Epoch: 54 [117504/225000 (52%)] Loss: 19952.519531\n",
      "Train Epoch: 54 [120000/225000 (53%)] Loss: 19935.113281\n",
      "Train Epoch: 54 [122496/225000 (54%)] Loss: 20011.505859\n",
      "Train Epoch: 54 [124992/225000 (56%)] Loss: 19791.621094\n",
      "Train Epoch: 54 [127488/225000 (57%)] Loss: 20186.492188\n",
      "Train Epoch: 54 [129984/225000 (58%)] Loss: 20201.914062\n",
      "Train Epoch: 54 [132480/225000 (59%)] Loss: 20069.968750\n",
      "Train Epoch: 54 [134976/225000 (60%)] Loss: 20201.000000\n",
      "Train Epoch: 54 [137472/225000 (61%)] Loss: 20199.429688\n",
      "Train Epoch: 54 [139968/225000 (62%)] Loss: 19767.349609\n",
      "Train Epoch: 54 [142464/225000 (63%)] Loss: 20454.378906\n",
      "Train Epoch: 54 [144960/225000 (64%)] Loss: 19700.242188\n",
      "Train Epoch: 54 [147456/225000 (66%)] Loss: 19826.714844\n",
      "Train Epoch: 54 [149952/225000 (67%)] Loss: 20264.000000\n",
      "Train Epoch: 54 [152448/225000 (68%)] Loss: 20166.964844\n",
      "Train Epoch: 54 [154944/225000 (69%)] Loss: 20202.701172\n",
      "Train Epoch: 54 [157440/225000 (70%)] Loss: 20024.955078\n",
      "Train Epoch: 54 [159936/225000 (71%)] Loss: 20055.125000\n",
      "Train Epoch: 54 [162432/225000 (72%)] Loss: 20651.582031\n",
      "Train Epoch: 54 [164928/225000 (73%)] Loss: 20222.753906\n",
      "Train Epoch: 54 [167424/225000 (74%)] Loss: 20614.345703\n",
      "Train Epoch: 54 [169920/225000 (76%)] Loss: 20233.574219\n",
      "Train Epoch: 54 [172416/225000 (77%)] Loss: 19987.167969\n",
      "Train Epoch: 54 [174912/225000 (78%)] Loss: 19994.593750\n",
      "Train Epoch: 54 [177408/225000 (79%)] Loss: 20115.609375\n",
      "Train Epoch: 54 [179904/225000 (80%)] Loss: 20329.708984\n",
      "Train Epoch: 54 [182400/225000 (81%)] Loss: 20275.636719\n",
      "Train Epoch: 54 [184896/225000 (82%)] Loss: 19838.570312\n",
      "Train Epoch: 54 [187392/225000 (83%)] Loss: 20340.326172\n",
      "Train Epoch: 54 [189888/225000 (84%)] Loss: 20077.056641\n",
      "Train Epoch: 54 [192384/225000 (86%)] Loss: 20237.769531\n",
      "Train Epoch: 54 [194880/225000 (87%)] Loss: 20416.712891\n",
      "Train Epoch: 54 [197376/225000 (88%)] Loss: 19975.925781\n",
      "Train Epoch: 54 [199872/225000 (89%)] Loss: 20317.484375\n",
      "Train Epoch: 54 [202368/225000 (90%)] Loss: 20114.923828\n",
      "Train Epoch: 54 [204864/225000 (91%)] Loss: 20609.062500\n",
      "Train Epoch: 54 [207360/225000 (92%)] Loss: 20214.500000\n",
      "Train Epoch: 54 [209856/225000 (93%)] Loss: 20064.628906\n",
      "Train Epoch: 54 [212352/225000 (94%)] Loss: 19666.320312\n",
      "Train Epoch: 54 [214848/225000 (95%)] Loss: 20409.169922\n",
      "Train Epoch: 54 [217344/225000 (97%)] Loss: 19963.699219\n",
      "Train Epoch: 54 [219840/225000 (98%)] Loss: 20419.556641\n",
      "Train Epoch: 54 [222336/225000 (99%)] Loss: 19894.609375\n",
      "Train Epoch: 54 [224832/225000 (100%)] Loss: 20117.121094\n",
      "    epoch          : 54\n",
      "    loss           : 20175.495335497548\n",
      "    val_loss       : 20172.30140907255\n",
      "Train Epoch: 55 [192/225000 (0%)] Loss: 20034.769531\n",
      "Train Epoch: 55 [2688/225000 (1%)] Loss: 19988.253906\n",
      "Train Epoch: 55 [5184/225000 (2%)] Loss: 19895.591797\n",
      "Train Epoch: 55 [7680/225000 (3%)] Loss: 20024.285156\n",
      "Train Epoch: 55 [10176/225000 (5%)] Loss: 19996.345703\n",
      "Train Epoch: 55 [12672/225000 (6%)] Loss: 20204.839844\n",
      "Train Epoch: 55 [15168/225000 (7%)] Loss: 20153.062500\n",
      "Train Epoch: 55 [17664/225000 (8%)] Loss: 20204.492188\n",
      "Train Epoch: 55 [20160/225000 (9%)] Loss: 20438.664062\n",
      "Train Epoch: 55 [22656/225000 (10%)] Loss: 20788.876953\n",
      "Train Epoch: 55 [25152/225000 (11%)] Loss: 20391.117188\n",
      "Train Epoch: 55 [27648/225000 (12%)] Loss: 20514.730469\n",
      "Train Epoch: 55 [30144/225000 (13%)] Loss: 20371.035156\n",
      "Train Epoch: 55 [32640/225000 (15%)] Loss: 20380.751953\n",
      "Train Epoch: 55 [35136/225000 (16%)] Loss: 20350.365234\n",
      "Train Epoch: 55 [37632/225000 (17%)] Loss: 19666.765625\n",
      "Train Epoch: 55 [40128/225000 (18%)] Loss: 19911.287109\n",
      "Train Epoch: 55 [42624/225000 (19%)] Loss: 20732.593750\n",
      "Train Epoch: 55 [45120/225000 (20%)] Loss: 20476.820312\n",
      "Train Epoch: 55 [47616/225000 (21%)] Loss: 20194.511719\n",
      "Train Epoch: 55 [50112/225000 (22%)] Loss: 20341.898438\n",
      "Train Epoch: 55 [52608/225000 (23%)] Loss: 20326.492188\n",
      "Train Epoch: 55 [55104/225000 (24%)] Loss: 19986.832031\n",
      "Train Epoch: 55 [57600/225000 (26%)] Loss: 20714.400391\n",
      "Train Epoch: 55 [60096/225000 (27%)] Loss: 20142.312500\n",
      "Train Epoch: 55 [62592/225000 (28%)] Loss: 19956.445312\n",
      "Train Epoch: 55 [65088/225000 (29%)] Loss: 19886.166016\n",
      "Train Epoch: 55 [67584/225000 (30%)] Loss: 20238.330078\n",
      "Train Epoch: 55 [70080/225000 (31%)] Loss: 20144.406250\n",
      "Train Epoch: 55 [72576/225000 (32%)] Loss: 20082.078125\n",
      "Train Epoch: 55 [75072/225000 (33%)] Loss: 20114.023438\n",
      "Train Epoch: 55 [77568/225000 (34%)] Loss: 20774.751953\n",
      "Train Epoch: 55 [80064/225000 (36%)] Loss: 19454.593750\n",
      "Train Epoch: 55 [82560/225000 (37%)] Loss: 20241.437500\n",
      "Train Epoch: 55 [85056/225000 (38%)] Loss: 20068.853516\n",
      "Train Epoch: 55 [87552/225000 (39%)] Loss: 20050.335938\n",
      "Train Epoch: 55 [90048/225000 (40%)] Loss: 19656.917969\n",
      "Train Epoch: 55 [92544/225000 (41%)] Loss: 19730.093750\n",
      "Train Epoch: 55 [95040/225000 (42%)] Loss: 19840.406250\n",
      "Train Epoch: 55 [97536/225000 (43%)] Loss: 19654.273438\n",
      "Train Epoch: 55 [100032/225000 (44%)] Loss: 20438.648438\n",
      "Train Epoch: 55 [102528/225000 (46%)] Loss: 20128.300781\n",
      "Train Epoch: 55 [105024/225000 (47%)] Loss: 20404.693359\n",
      "Train Epoch: 55 [107520/225000 (48%)] Loss: 20055.863281\n",
      "Train Epoch: 55 [110016/225000 (49%)] Loss: 20647.699219\n",
      "Train Epoch: 55 [112512/225000 (50%)] Loss: 20342.070312\n",
      "Train Epoch: 55 [115008/225000 (51%)] Loss: 20191.000000\n",
      "Train Epoch: 55 [117504/225000 (52%)] Loss: 20635.339844\n",
      "Train Epoch: 55 [120000/225000 (53%)] Loss: 20557.210938\n",
      "Train Epoch: 55 [122496/225000 (54%)] Loss: 19832.355469\n",
      "Train Epoch: 55 [124992/225000 (56%)] Loss: 20183.298828\n",
      "Train Epoch: 55 [127488/225000 (57%)] Loss: 20380.160156\n",
      "Train Epoch: 55 [129984/225000 (58%)] Loss: 20167.595703\n",
      "Train Epoch: 55 [132480/225000 (59%)] Loss: 19919.972656\n",
      "Train Epoch: 55 [134976/225000 (60%)] Loss: 20721.183594\n",
      "Train Epoch: 55 [137472/225000 (61%)] Loss: 20283.406250\n",
      "Train Epoch: 55 [139968/225000 (62%)] Loss: 20228.201172\n",
      "Train Epoch: 55 [142464/225000 (63%)] Loss: 20371.546875\n",
      "Train Epoch: 55 [144960/225000 (64%)] Loss: 20024.121094\n",
      "Train Epoch: 55 [147456/225000 (66%)] Loss: 20775.285156\n",
      "Train Epoch: 55 [149952/225000 (67%)] Loss: 19945.824219\n",
      "Train Epoch: 55 [152448/225000 (68%)] Loss: 20132.031250\n",
      "Train Epoch: 55 [154944/225000 (69%)] Loss: 19982.875000\n",
      "Train Epoch: 55 [157440/225000 (70%)] Loss: 19841.289062\n",
      "Train Epoch: 55 [159936/225000 (71%)] Loss: 20575.890625\n",
      "Train Epoch: 55 [162432/225000 (72%)] Loss: 20129.132812\n",
      "Train Epoch: 55 [164928/225000 (73%)] Loss: 20454.955078\n",
      "Train Epoch: 55 [167424/225000 (74%)] Loss: 19679.947266\n",
      "Train Epoch: 55 [169920/225000 (76%)] Loss: 19888.246094\n",
      "Train Epoch: 55 [172416/225000 (77%)] Loss: 19893.734375\n",
      "Train Epoch: 55 [174912/225000 (78%)] Loss: 19838.671875\n",
      "Train Epoch: 55 [177408/225000 (79%)] Loss: 20302.199219\n",
      "Train Epoch: 55 [179904/225000 (80%)] Loss: 20366.597656\n",
      "Train Epoch: 55 [182400/225000 (81%)] Loss: 20517.121094\n",
      "Train Epoch: 55 [184896/225000 (82%)] Loss: 20136.101562\n",
      "Train Epoch: 55 [187392/225000 (83%)] Loss: 20138.046875\n",
      "Train Epoch: 55 [189888/225000 (84%)] Loss: 20097.910156\n",
      "Train Epoch: 55 [192384/225000 (86%)] Loss: 20423.597656\n",
      "Train Epoch: 55 [194880/225000 (87%)] Loss: 19558.750000\n",
      "Train Epoch: 55 [197376/225000 (88%)] Loss: 20519.937500\n",
      "Train Epoch: 55 [199872/225000 (89%)] Loss: 19808.035156\n",
      "Train Epoch: 55 [202368/225000 (90%)] Loss: 19588.035156\n",
      "Train Epoch: 55 [204864/225000 (91%)] Loss: 19925.787109\n",
      "Train Epoch: 55 [207360/225000 (92%)] Loss: 19991.447266\n",
      "Train Epoch: 55 [209856/225000 (93%)] Loss: 19828.503906\n",
      "Train Epoch: 55 [212352/225000 (94%)] Loss: 20521.728516\n",
      "Train Epoch: 55 [214848/225000 (95%)] Loss: 20314.015625\n",
      "Train Epoch: 55 [217344/225000 (97%)] Loss: 20378.707031\n",
      "Train Epoch: 55 [219840/225000 (98%)] Loss: 20564.960938\n",
      "Train Epoch: 55 [222336/225000 (99%)] Loss: 20309.908203\n",
      "Train Epoch: 55 [224832/225000 (100%)] Loss: 20301.117188\n",
      "    epoch          : 55\n",
      "    loss           : 20142.309441992853\n",
      "    val_loss       : 20093.59723822397\n",
      "Train Epoch: 56 [192/225000 (0%)] Loss: 20167.246094\n",
      "Train Epoch: 56 [2688/225000 (1%)] Loss: 19684.398438\n",
      "Train Epoch: 56 [5184/225000 (2%)] Loss: 20475.232422\n",
      "Train Epoch: 56 [7680/225000 (3%)] Loss: 20588.437500\n",
      "Train Epoch: 56 [10176/225000 (5%)] Loss: 20123.076172\n",
      "Train Epoch: 56 [12672/225000 (6%)] Loss: 19963.656250\n",
      "Train Epoch: 56 [15168/225000 (7%)] Loss: 20685.326172\n",
      "Train Epoch: 56 [17664/225000 (8%)] Loss: 20603.287109\n",
      "Train Epoch: 56 [20160/225000 (9%)] Loss: 20258.175781\n",
      "Train Epoch: 56 [22656/225000 (10%)] Loss: 20336.082031\n",
      "Train Epoch: 56 [25152/225000 (11%)] Loss: 20089.792969\n",
      "Train Epoch: 56 [27648/225000 (12%)] Loss: 19633.378906\n",
      "Train Epoch: 56 [30144/225000 (13%)] Loss: 20071.757812\n",
      "Train Epoch: 56 [32640/225000 (15%)] Loss: 20233.669922\n",
      "Train Epoch: 56 [35136/225000 (16%)] Loss: 19686.511719\n",
      "Train Epoch: 56 [37632/225000 (17%)] Loss: 19433.406250\n",
      "Train Epoch: 56 [40128/225000 (18%)] Loss: 20073.222656\n",
      "Train Epoch: 56 [42624/225000 (19%)] Loss: 20124.890625\n",
      "Train Epoch: 56 [45120/225000 (20%)] Loss: 20602.082031\n",
      "Train Epoch: 56 [47616/225000 (21%)] Loss: 20129.367188\n",
      "Train Epoch: 56 [50112/225000 (22%)] Loss: 20433.587891\n",
      "Train Epoch: 56 [52608/225000 (23%)] Loss: 19416.107422\n",
      "Train Epoch: 56 [55104/225000 (24%)] Loss: 20110.562500\n",
      "Train Epoch: 56 [57600/225000 (26%)] Loss: 20201.402344\n",
      "Train Epoch: 56 [60096/225000 (27%)] Loss: 20208.210938\n",
      "Train Epoch: 56 [62592/225000 (28%)] Loss: 20176.519531\n",
      "Train Epoch: 56 [65088/225000 (29%)] Loss: 20001.921875\n",
      "Train Epoch: 56 [67584/225000 (30%)] Loss: 20031.113281\n",
      "Train Epoch: 56 [70080/225000 (31%)] Loss: 19921.347656\n",
      "Train Epoch: 56 [72576/225000 (32%)] Loss: 20430.195312\n",
      "Train Epoch: 56 [75072/225000 (33%)] Loss: 20516.507812\n",
      "Train Epoch: 56 [77568/225000 (34%)] Loss: 19841.984375\n",
      "Train Epoch: 56 [80064/225000 (36%)] Loss: 20479.429688\n",
      "Train Epoch: 56 [82560/225000 (37%)] Loss: 19650.003906\n",
      "Train Epoch: 56 [85056/225000 (38%)] Loss: 20118.613281\n",
      "Train Epoch: 56 [87552/225000 (39%)] Loss: 20298.847656\n",
      "Train Epoch: 56 [90048/225000 (40%)] Loss: 19984.437500\n",
      "Train Epoch: 56 [92544/225000 (41%)] Loss: 19818.597656\n",
      "Train Epoch: 56 [95040/225000 (42%)] Loss: 20246.582031\n",
      "Train Epoch: 56 [97536/225000 (43%)] Loss: 20337.281250\n",
      "Train Epoch: 56 [100032/225000 (44%)] Loss: 20744.357422\n",
      "Train Epoch: 56 [102528/225000 (46%)] Loss: 20056.128906\n",
      "Train Epoch: 56 [105024/225000 (47%)] Loss: 19644.007812\n",
      "Train Epoch: 56 [107520/225000 (48%)] Loss: 20014.566406\n",
      "Train Epoch: 56 [110016/225000 (49%)] Loss: 20268.574219\n",
      "Train Epoch: 56 [112512/225000 (50%)] Loss: 20242.207031\n",
      "Train Epoch: 56 [115008/225000 (51%)] Loss: 19735.121094\n",
      "Train Epoch: 56 [117504/225000 (52%)] Loss: 20301.070312\n",
      "Train Epoch: 56 [120000/225000 (53%)] Loss: 20305.890625\n",
      "Train Epoch: 56 [122496/225000 (54%)] Loss: 19810.642578\n",
      "Train Epoch: 56 [124992/225000 (56%)] Loss: 20149.894531\n",
      "Train Epoch: 56 [127488/225000 (57%)] Loss: 20003.011719\n",
      "Train Epoch: 56 [129984/225000 (58%)] Loss: 20064.099609\n",
      "Train Epoch: 56 [132480/225000 (59%)] Loss: 19934.244141\n",
      "Train Epoch: 56 [134976/225000 (60%)] Loss: 20063.835938\n",
      "Train Epoch: 56 [137472/225000 (61%)] Loss: 19801.101562\n",
      "Train Epoch: 56 [139968/225000 (62%)] Loss: 20175.351562\n",
      "Train Epoch: 56 [142464/225000 (63%)] Loss: 19891.593750\n",
      "Train Epoch: 56 [144960/225000 (64%)] Loss: 20166.390625\n",
      "Train Epoch: 56 [147456/225000 (66%)] Loss: 19847.554688\n",
      "Train Epoch: 56 [149952/225000 (67%)] Loss: 20016.968750\n",
      "Train Epoch: 56 [152448/225000 (68%)] Loss: 20287.480469\n",
      "Train Epoch: 56 [154944/225000 (69%)] Loss: 20270.017578\n",
      "Train Epoch: 56 [157440/225000 (70%)] Loss: 20568.332031\n",
      "Train Epoch: 56 [159936/225000 (71%)] Loss: 19821.082031\n",
      "Train Epoch: 56 [162432/225000 (72%)] Loss: 19936.480469\n",
      "Train Epoch: 56 [164928/225000 (73%)] Loss: 20593.320312\n",
      "Train Epoch: 56 [167424/225000 (74%)] Loss: 19930.902344\n",
      "Train Epoch: 56 [169920/225000 (76%)] Loss: 19522.843750\n",
      "Train Epoch: 56 [172416/225000 (77%)] Loss: 19731.951172\n",
      "Train Epoch: 56 [174912/225000 (78%)] Loss: 19954.400391\n",
      "Train Epoch: 56 [177408/225000 (79%)] Loss: 20055.062500\n",
      "Train Epoch: 56 [179904/225000 (80%)] Loss: 20035.025391\n",
      "Train Epoch: 56 [182400/225000 (81%)] Loss: 20285.472656\n",
      "Train Epoch: 56 [184896/225000 (82%)] Loss: 19941.921875\n",
      "Train Epoch: 56 [187392/225000 (83%)] Loss: 19931.292969\n",
      "Train Epoch: 56 [189888/225000 (84%)] Loss: 20160.111328\n",
      "Train Epoch: 56 [192384/225000 (86%)] Loss: 20474.800781\n",
      "Train Epoch: 56 [194880/225000 (87%)] Loss: 20133.552734\n",
      "Train Epoch: 56 [197376/225000 (88%)] Loss: 20085.312500\n",
      "Train Epoch: 56 [199872/225000 (89%)] Loss: 20387.605469\n",
      "Train Epoch: 56 [202368/225000 (90%)] Loss: 20317.292969\n",
      "Train Epoch: 56 [204864/225000 (91%)] Loss: 20249.761719\n",
      "Train Epoch: 56 [207360/225000 (92%)] Loss: 20299.369141\n",
      "Train Epoch: 56 [209856/225000 (93%)] Loss: 20313.925781\n",
      "Train Epoch: 56 [212352/225000 (94%)] Loss: 20174.173828\n",
      "Train Epoch: 56 [214848/225000 (95%)] Loss: 19800.457031\n",
      "Train Epoch: 56 [217344/225000 (97%)] Loss: 20479.183594\n",
      "Train Epoch: 56 [219840/225000 (98%)] Loss: 20240.257812\n",
      "Train Epoch: 56 [222336/225000 (99%)] Loss: 19620.175781\n",
      "Train Epoch: 56 [224832/225000 (100%)] Loss: 20170.904297\n",
      "    epoch          : 56\n",
      "    loss           : 20126.740346029757\n",
      "    val_loss       : 20021.87927673518\n",
      "Train Epoch: 57 [192/225000 (0%)] Loss: 20167.660156\n",
      "Train Epoch: 57 [2688/225000 (1%)] Loss: 19914.339844\n",
      "Train Epoch: 57 [5184/225000 (2%)] Loss: 20171.285156\n",
      "Train Epoch: 57 [7680/225000 (3%)] Loss: 20190.871094\n",
      "Train Epoch: 57 [10176/225000 (5%)] Loss: 19868.482422\n",
      "Train Epoch: 57 [12672/225000 (6%)] Loss: 19559.710938\n",
      "Train Epoch: 57 [15168/225000 (7%)] Loss: 19988.072266\n",
      "Train Epoch: 57 [17664/225000 (8%)] Loss: 19941.880859\n",
      "Train Epoch: 57 [20160/225000 (9%)] Loss: 20245.964844\n",
      "Train Epoch: 57 [22656/225000 (10%)] Loss: 19779.082031\n",
      "Train Epoch: 57 [25152/225000 (11%)] Loss: 20339.449219\n",
      "Train Epoch: 57 [27648/225000 (12%)] Loss: 20064.923828\n",
      "Train Epoch: 57 [30144/225000 (13%)] Loss: 20514.355469\n",
      "Train Epoch: 57 [32640/225000 (15%)] Loss: 20071.179688\n",
      "Train Epoch: 57 [35136/225000 (16%)] Loss: 20112.806641\n",
      "Train Epoch: 57 [37632/225000 (17%)] Loss: 19712.765625\n",
      "Train Epoch: 57 [40128/225000 (18%)] Loss: 19935.714844\n",
      "Train Epoch: 57 [42624/225000 (19%)] Loss: 20610.492188\n",
      "Train Epoch: 57 [45120/225000 (20%)] Loss: 20478.089844\n",
      "Train Epoch: 57 [47616/225000 (21%)] Loss: 20046.753906\n",
      "Train Epoch: 57 [50112/225000 (22%)] Loss: 19883.898438\n",
      "Train Epoch: 57 [52608/225000 (23%)] Loss: 20246.570312\n",
      "Train Epoch: 57 [55104/225000 (24%)] Loss: 19842.539062\n",
      "Train Epoch: 57 [57600/225000 (26%)] Loss: 19656.312500\n",
      "Train Epoch: 57 [60096/225000 (27%)] Loss: 20035.632812\n",
      "Train Epoch: 57 [62592/225000 (28%)] Loss: 20017.601562\n",
      "Train Epoch: 57 [65088/225000 (29%)] Loss: 20103.689453\n",
      "Train Epoch: 57 [67584/225000 (30%)] Loss: 19965.269531\n",
      "Train Epoch: 57 [70080/225000 (31%)] Loss: 20443.484375\n",
      "Train Epoch: 57 [72576/225000 (32%)] Loss: 20066.064453\n",
      "Train Epoch: 57 [75072/225000 (33%)] Loss: 20426.832031\n",
      "Train Epoch: 57 [77568/225000 (34%)] Loss: 20313.656250\n",
      "Train Epoch: 57 [80064/225000 (36%)] Loss: 19857.289062\n",
      "Train Epoch: 57 [82560/225000 (37%)] Loss: 20175.039062\n",
      "Train Epoch: 57 [85056/225000 (38%)] Loss: 20356.015625\n",
      "Train Epoch: 57 [87552/225000 (39%)] Loss: 20151.130859\n",
      "Train Epoch: 57 [90048/225000 (40%)] Loss: 20285.082031\n",
      "Train Epoch: 57 [92544/225000 (41%)] Loss: 20241.265625\n",
      "Train Epoch: 57 [95040/225000 (42%)] Loss: 20603.824219\n",
      "Train Epoch: 57 [97536/225000 (43%)] Loss: 20436.742188\n",
      "Train Epoch: 57 [100032/225000 (44%)] Loss: 19919.597656\n",
      "Train Epoch: 57 [102528/225000 (46%)] Loss: 20232.074219\n",
      "Train Epoch: 57 [105024/225000 (47%)] Loss: 20636.375000\n",
      "Train Epoch: 57 [107520/225000 (48%)] Loss: 20992.603516\n",
      "Train Epoch: 57 [110016/225000 (49%)] Loss: 20535.597656\n",
      "Train Epoch: 57 [112512/225000 (50%)] Loss: 19662.597656\n",
      "Train Epoch: 57 [115008/225000 (51%)] Loss: 20060.845703\n",
      "Train Epoch: 57 [117504/225000 (52%)] Loss: 19879.382812\n",
      "Train Epoch: 57 [120000/225000 (53%)] Loss: 20327.458984\n",
      "Train Epoch: 57 [122496/225000 (54%)] Loss: 20287.515625\n",
      "Train Epoch: 57 [124992/225000 (56%)] Loss: 20143.875000\n",
      "Train Epoch: 57 [127488/225000 (57%)] Loss: 20328.443359\n",
      "Train Epoch: 57 [129984/225000 (58%)] Loss: 20279.500000\n",
      "Train Epoch: 57 [132480/225000 (59%)] Loss: 19993.966797\n",
      "Train Epoch: 57 [134976/225000 (60%)] Loss: 20345.839844\n",
      "Train Epoch: 57 [137472/225000 (61%)] Loss: 20542.285156\n",
      "Train Epoch: 57 [139968/225000 (62%)] Loss: 20513.691406\n",
      "Train Epoch: 57 [142464/225000 (63%)] Loss: 20134.439453\n",
      "Train Epoch: 57 [144960/225000 (64%)] Loss: 19855.033203\n",
      "Train Epoch: 57 [147456/225000 (66%)] Loss: 20287.031250\n",
      "Train Epoch: 57 [149952/225000 (67%)] Loss: 20188.173828\n",
      "Train Epoch: 57 [152448/225000 (68%)] Loss: 20261.816406\n",
      "Train Epoch: 57 [154944/225000 (69%)] Loss: 20289.226562\n",
      "Train Epoch: 57 [157440/225000 (70%)] Loss: 20129.835938\n",
      "Train Epoch: 57 [159936/225000 (71%)] Loss: 19821.574219\n",
      "Train Epoch: 57 [162432/225000 (72%)] Loss: 20401.574219\n",
      "Train Epoch: 57 [164928/225000 (73%)] Loss: 19465.589844\n",
      "Train Epoch: 57 [167424/225000 (74%)] Loss: 20070.496094\n",
      "Train Epoch: 57 [169920/225000 (76%)] Loss: 20025.640625\n",
      "Train Epoch: 57 [172416/225000 (77%)] Loss: 20303.500000\n",
      "Train Epoch: 57 [174912/225000 (78%)] Loss: 20025.035156\n",
      "Train Epoch: 57 [177408/225000 (79%)] Loss: 19975.484375\n",
      "Train Epoch: 57 [179904/225000 (80%)] Loss: 19902.542969\n",
      "Train Epoch: 57 [182400/225000 (81%)] Loss: 19975.664062\n",
      "Train Epoch: 57 [184896/225000 (82%)] Loss: 20086.859375\n",
      "Train Epoch: 57 [187392/225000 (83%)] Loss: 20319.488281\n",
      "Train Epoch: 57 [189888/225000 (84%)] Loss: 20506.720703\n",
      "Train Epoch: 57 [192384/225000 (86%)] Loss: 20511.240234\n",
      "Train Epoch: 57 [194880/225000 (87%)] Loss: 19890.359375\n",
      "Train Epoch: 57 [197376/225000 (88%)] Loss: 19906.554688\n",
      "Train Epoch: 57 [199872/225000 (89%)] Loss: 19631.892578\n",
      "Train Epoch: 57 [202368/225000 (90%)] Loss: 20425.404297\n",
      "Train Epoch: 57 [204864/225000 (91%)] Loss: 19947.925781\n",
      "Train Epoch: 57 [207360/225000 (92%)] Loss: 19885.941406\n",
      "Train Epoch: 57 [209856/225000 (93%)] Loss: 19988.753906\n",
      "Train Epoch: 57 [212352/225000 (94%)] Loss: 20300.164062\n",
      "Train Epoch: 57 [214848/225000 (95%)] Loss: 20310.421875\n",
      "Train Epoch: 57 [217344/225000 (97%)] Loss: 20284.660156\n",
      "Train Epoch: 57 [219840/225000 (98%)] Loss: 20381.699219\n",
      "Train Epoch: 57 [222336/225000 (99%)] Loss: 20480.175781\n",
      "Train Epoch: 57 [224832/225000 (100%)] Loss: 19905.134766\n",
      "    epoch          : 57\n",
      "    loss           : 20119.744207284555\n",
      "    val_loss       : 20022.737475115835\n",
      "Train Epoch: 58 [192/225000 (0%)] Loss: 19892.968750\n",
      "Train Epoch: 58 [2688/225000 (1%)] Loss: 20238.214844\n",
      "Train Epoch: 58 [5184/225000 (2%)] Loss: 20094.972656\n",
      "Train Epoch: 58 [7680/225000 (3%)] Loss: 19822.640625\n",
      "Train Epoch: 58 [10176/225000 (5%)] Loss: 20202.324219\n",
      "Train Epoch: 58 [12672/225000 (6%)] Loss: 20037.976562\n",
      "Train Epoch: 58 [15168/225000 (7%)] Loss: 20257.359375\n",
      "Train Epoch: 58 [17664/225000 (8%)] Loss: 20095.533203\n",
      "Train Epoch: 58 [20160/225000 (9%)] Loss: 20329.427734\n",
      "Train Epoch: 58 [22656/225000 (10%)] Loss: 19984.488281\n",
      "Train Epoch: 58 [25152/225000 (11%)] Loss: 19991.093750\n",
      "Train Epoch: 58 [27648/225000 (12%)] Loss: 19795.492188\n",
      "Train Epoch: 58 [30144/225000 (13%)] Loss: 20280.945312\n",
      "Train Epoch: 58 [32640/225000 (15%)] Loss: 20536.593750\n",
      "Train Epoch: 58 [35136/225000 (16%)] Loss: 20681.865234\n",
      "Train Epoch: 58 [37632/225000 (17%)] Loss: 19906.726562\n",
      "Train Epoch: 58 [40128/225000 (18%)] Loss: 20158.343750\n",
      "Train Epoch: 58 [42624/225000 (19%)] Loss: 20054.628906\n",
      "Train Epoch: 58 [45120/225000 (20%)] Loss: 20883.160156\n",
      "Train Epoch: 58 [47616/225000 (21%)] Loss: 20257.039062\n",
      "Train Epoch: 58 [50112/225000 (22%)] Loss: 20128.273438\n",
      "Train Epoch: 58 [52608/225000 (23%)] Loss: 20197.833984\n",
      "Train Epoch: 58 [55104/225000 (24%)] Loss: 20009.851562\n",
      "Train Epoch: 58 [57600/225000 (26%)] Loss: 20122.921875\n",
      "Train Epoch: 58 [60096/225000 (27%)] Loss: 20438.656250\n",
      "Train Epoch: 58 [62592/225000 (28%)] Loss: 20291.992188\n",
      "Train Epoch: 58 [65088/225000 (29%)] Loss: 19646.560547\n",
      "Train Epoch: 58 [67584/225000 (30%)] Loss: 20270.658203\n",
      "Train Epoch: 58 [70080/225000 (31%)] Loss: 20289.183594\n",
      "Train Epoch: 58 [72576/225000 (32%)] Loss: 20420.839844\n",
      "Train Epoch: 58 [75072/225000 (33%)] Loss: 19797.480469\n",
      "Train Epoch: 58 [77568/225000 (34%)] Loss: 19781.708984\n",
      "Train Epoch: 58 [80064/225000 (36%)] Loss: 20388.843750\n",
      "Train Epoch: 58 [82560/225000 (37%)] Loss: 20037.050781\n",
      "Train Epoch: 58 [85056/225000 (38%)] Loss: 19648.697266\n",
      "Train Epoch: 58 [87552/225000 (39%)] Loss: 20153.306641\n",
      "Train Epoch: 58 [90048/225000 (40%)] Loss: 19832.878906\n",
      "Train Epoch: 58 [92544/225000 (41%)] Loss: 20063.908203\n",
      "Train Epoch: 58 [95040/225000 (42%)] Loss: 19966.898438\n",
      "Train Epoch: 58 [97536/225000 (43%)] Loss: 20241.980469\n",
      "Train Epoch: 58 [100032/225000 (44%)] Loss: 19980.347656\n",
      "Train Epoch: 58 [102528/225000 (46%)] Loss: 19803.660156\n",
      "Train Epoch: 58 [105024/225000 (47%)] Loss: 20026.574219\n",
      "Train Epoch: 58 [107520/225000 (48%)] Loss: 19884.769531\n",
      "Train Epoch: 58 [110016/225000 (49%)] Loss: 19616.984375\n",
      "Train Epoch: 58 [112512/225000 (50%)] Loss: 20414.726562\n",
      "Train Epoch: 58 [115008/225000 (51%)] Loss: 19985.199219\n",
      "Train Epoch: 58 [117504/225000 (52%)] Loss: 20291.421875\n",
      "Train Epoch: 58 [120000/225000 (53%)] Loss: 19969.667969\n",
      "Train Epoch: 58 [122496/225000 (54%)] Loss: 20299.304688\n",
      "Train Epoch: 58 [124992/225000 (56%)] Loss: 20007.808594\n",
      "Train Epoch: 58 [127488/225000 (57%)] Loss: 19770.425781\n",
      "Train Epoch: 58 [129984/225000 (58%)] Loss: 20311.617188\n",
      "Train Epoch: 58 [132480/225000 (59%)] Loss: 20205.496094\n",
      "Train Epoch: 58 [134976/225000 (60%)] Loss: 20111.029297\n",
      "Train Epoch: 58 [137472/225000 (61%)] Loss: 19932.169922\n",
      "Train Epoch: 58 [139968/225000 (62%)] Loss: 20211.480469\n",
      "Train Epoch: 58 [142464/225000 (63%)] Loss: 20099.062500\n",
      "Train Epoch: 58 [144960/225000 (64%)] Loss: 20262.808594\n",
      "Train Epoch: 58 [147456/225000 (66%)] Loss: 20448.667969\n",
      "Train Epoch: 58 [149952/225000 (67%)] Loss: 20245.007812\n",
      "Train Epoch: 58 [152448/225000 (68%)] Loss: 20046.777344\n",
      "Train Epoch: 58 [154944/225000 (69%)] Loss: 19904.789062\n",
      "Train Epoch: 58 [157440/225000 (70%)] Loss: 19953.835938\n",
      "Train Epoch: 58 [159936/225000 (71%)] Loss: 19790.142578\n",
      "Train Epoch: 58 [162432/225000 (72%)] Loss: 20387.636719\n",
      "Train Epoch: 58 [164928/225000 (73%)] Loss: 20040.656250\n",
      "Train Epoch: 58 [167424/225000 (74%)] Loss: 20415.246094\n",
      "Train Epoch: 58 [169920/225000 (76%)] Loss: 20247.613281\n",
      "Train Epoch: 58 [172416/225000 (77%)] Loss: 20374.246094\n",
      "Train Epoch: 58 [174912/225000 (78%)] Loss: 20390.271484\n",
      "Train Epoch: 58 [177408/225000 (79%)] Loss: 20596.267578\n",
      "Train Epoch: 58 [179904/225000 (80%)] Loss: 19556.378906\n",
      "Train Epoch: 58 [182400/225000 (81%)] Loss: 20367.189453\n",
      "Train Epoch: 58 [184896/225000 (82%)] Loss: 20041.482422\n",
      "Train Epoch: 58 [187392/225000 (83%)] Loss: 19573.906250\n",
      "Train Epoch: 58 [189888/225000 (84%)] Loss: 20354.312500\n",
      "Train Epoch: 58 [192384/225000 (86%)] Loss: 20210.343750\n",
      "Train Epoch: 58 [194880/225000 (87%)] Loss: 20265.222656\n",
      "Train Epoch: 58 [197376/225000 (88%)] Loss: 19938.710938\n",
      "Train Epoch: 58 [199872/225000 (89%)] Loss: 19804.886719\n",
      "Train Epoch: 58 [202368/225000 (90%)] Loss: 20161.111328\n",
      "Train Epoch: 58 [204864/225000 (91%)] Loss: 19925.429688\n",
      "Train Epoch: 58 [207360/225000 (92%)] Loss: 20296.968750\n",
      "Train Epoch: 58 [209856/225000 (93%)] Loss: 19953.457031\n",
      "Train Epoch: 58 [212352/225000 (94%)] Loss: 19305.785156\n",
      "Train Epoch: 58 [214848/225000 (95%)] Loss: 20264.548828\n",
      "Train Epoch: 58 [217344/225000 (97%)] Loss: 20186.525391\n",
      "Train Epoch: 58 [219840/225000 (98%)] Loss: 20111.523438\n",
      "Train Epoch: 58 [222336/225000 (99%)] Loss: 20436.849609\n",
      "Train Epoch: 58 [224832/225000 (100%)] Loss: 20027.039062\n",
      "    epoch          : 58\n",
      "    loss           : 20106.757624186754\n",
      "    val_loss       : 20016.01089705038\n",
      "Train Epoch: 59 [192/225000 (0%)] Loss: 19820.308594\n",
      "Train Epoch: 59 [2688/225000 (1%)] Loss: 20036.183594\n",
      "Train Epoch: 59 [5184/225000 (2%)] Loss: 19812.837891\n",
      "Train Epoch: 59 [7680/225000 (3%)] Loss: 20149.359375\n",
      "Train Epoch: 59 [10176/225000 (5%)] Loss: 20613.091797\n",
      "Train Epoch: 59 [12672/225000 (6%)] Loss: 20003.097656\n",
      "Train Epoch: 59 [15168/225000 (7%)] Loss: 19959.662109\n",
      "Train Epoch: 59 [17664/225000 (8%)] Loss: 19484.359375\n",
      "Train Epoch: 59 [20160/225000 (9%)] Loss: 20020.261719\n",
      "Train Epoch: 59 [22656/225000 (10%)] Loss: 20273.875000\n",
      "Train Epoch: 59 [25152/225000 (11%)] Loss: 19960.816406\n",
      "Train Epoch: 59 [27648/225000 (12%)] Loss: 19918.972656\n",
      "Train Epoch: 59 [30144/225000 (13%)] Loss: 20154.144531\n",
      "Train Epoch: 59 [32640/225000 (15%)] Loss: 20041.875000\n",
      "Train Epoch: 59 [35136/225000 (16%)] Loss: 20224.400391\n",
      "Train Epoch: 59 [37632/225000 (17%)] Loss: 20296.541016\n",
      "Train Epoch: 59 [40128/225000 (18%)] Loss: 19903.656250\n",
      "Train Epoch: 59 [42624/225000 (19%)] Loss: 20397.439453\n",
      "Train Epoch: 59 [45120/225000 (20%)] Loss: 20808.167969\n",
      "Train Epoch: 59 [47616/225000 (21%)] Loss: 19918.785156\n",
      "Train Epoch: 59 [50112/225000 (22%)] Loss: 19971.144531\n",
      "Train Epoch: 59 [52608/225000 (23%)] Loss: 19916.003906\n",
      "Train Epoch: 59 [55104/225000 (24%)] Loss: 20183.378906\n",
      "Train Epoch: 59 [57600/225000 (26%)] Loss: 19851.462891\n",
      "Train Epoch: 59 [60096/225000 (27%)] Loss: 20077.597656\n",
      "Train Epoch: 59 [62592/225000 (28%)] Loss: 20134.066406\n",
      "Train Epoch: 59 [65088/225000 (29%)] Loss: 20212.017578\n",
      "Train Epoch: 59 [67584/225000 (30%)] Loss: 20171.191406\n",
      "Train Epoch: 59 [70080/225000 (31%)] Loss: 20408.470703\n",
      "Train Epoch: 59 [72576/225000 (32%)] Loss: 20029.203125\n",
      "Train Epoch: 59 [75072/225000 (33%)] Loss: 20099.476562\n",
      "Train Epoch: 59 [77568/225000 (34%)] Loss: 20425.613281\n",
      "Train Epoch: 59 [80064/225000 (36%)] Loss: 20001.832031\n",
      "Train Epoch: 59 [82560/225000 (37%)] Loss: 20090.671875\n",
      "Train Epoch: 59 [85056/225000 (38%)] Loss: 20282.388672\n",
      "Train Epoch: 59 [87552/225000 (39%)] Loss: 20392.570312\n",
      "Train Epoch: 59 [90048/225000 (40%)] Loss: 20184.355469\n",
      "Train Epoch: 59 [92544/225000 (41%)] Loss: 20121.816406\n",
      "Train Epoch: 59 [95040/225000 (42%)] Loss: 19734.488281\n",
      "Train Epoch: 59 [97536/225000 (43%)] Loss: 20184.781250\n",
      "Train Epoch: 59 [100032/225000 (44%)] Loss: 20068.251953\n",
      "Train Epoch: 59 [102528/225000 (46%)] Loss: 19961.167969\n",
      "Train Epoch: 59 [105024/225000 (47%)] Loss: 19874.785156\n",
      "Train Epoch: 59 [107520/225000 (48%)] Loss: 20154.062500\n",
      "Train Epoch: 59 [110016/225000 (49%)] Loss: 19282.179688\n",
      "Train Epoch: 59 [112512/225000 (50%)] Loss: 20411.291016\n",
      "Train Epoch: 59 [115008/225000 (51%)] Loss: 20271.986328\n",
      "Train Epoch: 59 [117504/225000 (52%)] Loss: 20197.382812\n",
      "Train Epoch: 59 [120000/225000 (53%)] Loss: 20229.218750\n",
      "Train Epoch: 59 [122496/225000 (54%)] Loss: 19683.457031\n",
      "Train Epoch: 59 [124992/225000 (56%)] Loss: 20320.728516\n",
      "Train Epoch: 59 [127488/225000 (57%)] Loss: 20334.494141\n",
      "Train Epoch: 59 [129984/225000 (58%)] Loss: 20402.378906\n",
      "Train Epoch: 59 [132480/225000 (59%)] Loss: 20247.000000\n",
      "Train Epoch: 59 [134976/225000 (60%)] Loss: 19953.712891\n",
      "Train Epoch: 59 [137472/225000 (61%)] Loss: 19478.804688\n",
      "Train Epoch: 59 [139968/225000 (62%)] Loss: 20210.296875\n",
      "Train Epoch: 59 [142464/225000 (63%)] Loss: 20333.677734\n",
      "Train Epoch: 59 [144960/225000 (64%)] Loss: 19774.236328\n",
      "Train Epoch: 59 [147456/225000 (66%)] Loss: 19695.552734\n",
      "Train Epoch: 59 [149952/225000 (67%)] Loss: 20314.306641\n",
      "Train Epoch: 59 [152448/225000 (68%)] Loss: 19764.445312\n",
      "Train Epoch: 59 [154944/225000 (69%)] Loss: 20019.425781\n",
      "Train Epoch: 59 [157440/225000 (70%)] Loss: 19976.910156\n",
      "Train Epoch: 59 [159936/225000 (71%)] Loss: 19924.339844\n",
      "Train Epoch: 59 [162432/225000 (72%)] Loss: 20017.771484\n",
      "Train Epoch: 59 [164928/225000 (73%)] Loss: 20066.099609\n",
      "Train Epoch: 59 [167424/225000 (74%)] Loss: 19774.707031\n",
      "Train Epoch: 59 [169920/225000 (76%)] Loss: 20040.242188\n",
      "Train Epoch: 59 [172416/225000 (77%)] Loss: 19753.660156\n",
      "Train Epoch: 59 [174912/225000 (78%)] Loss: 20071.818359\n",
      "Train Epoch: 59 [177408/225000 (79%)] Loss: 19926.566406\n",
      "Train Epoch: 59 [179904/225000 (80%)] Loss: 19695.177734\n",
      "Train Epoch: 59 [182400/225000 (81%)] Loss: 19814.398438\n",
      "Train Epoch: 59 [184896/225000 (82%)] Loss: 19849.625000\n",
      "Train Epoch: 59 [187392/225000 (83%)] Loss: 20123.054688\n",
      "Train Epoch: 59 [189888/225000 (84%)] Loss: 20118.152344\n",
      "Train Epoch: 59 [192384/225000 (86%)] Loss: 20043.960938\n",
      "Train Epoch: 59 [194880/225000 (87%)] Loss: 20229.037109\n",
      "Train Epoch: 59 [197376/225000 (88%)] Loss: 20024.496094\n",
      "Train Epoch: 59 [199872/225000 (89%)] Loss: 20205.113281\n",
      "Train Epoch: 59 [202368/225000 (90%)] Loss: 19597.285156\n",
      "Train Epoch: 59 [204864/225000 (91%)] Loss: 20046.533203\n",
      "Train Epoch: 59 [207360/225000 (92%)] Loss: 20006.085938\n",
      "Train Epoch: 59 [209856/225000 (93%)] Loss: 20042.046875\n",
      "Train Epoch: 59 [212352/225000 (94%)] Loss: 19989.871094\n",
      "Train Epoch: 59 [214848/225000 (95%)] Loss: 20540.072266\n",
      "Train Epoch: 59 [217344/225000 (97%)] Loss: 19796.050781\n",
      "Train Epoch: 59 [219840/225000 (98%)] Loss: 20076.929688\n",
      "Train Epoch: 59 [222336/225000 (99%)] Loss: 19925.402344\n",
      "Train Epoch: 59 [224832/225000 (100%)] Loss: 20431.041016\n",
      "    epoch          : 59\n",
      "    loss           : 20093.982126906463\n",
      "    val_loss       : 19989.365207741277\n",
      "Train Epoch: 60 [192/225000 (0%)] Loss: 19803.015625\n",
      "Train Epoch: 60 [2688/225000 (1%)] Loss: 20202.710938\n",
      "Train Epoch: 60 [5184/225000 (2%)] Loss: 20035.632812\n",
      "Train Epoch: 60 [7680/225000 (3%)] Loss: 20105.855469\n",
      "Train Epoch: 60 [10176/225000 (5%)] Loss: 20427.490234\n",
      "Train Epoch: 60 [12672/225000 (6%)] Loss: 19437.035156\n",
      "Train Epoch: 60 [15168/225000 (7%)] Loss: 20188.179688\n",
      "Train Epoch: 60 [17664/225000 (8%)] Loss: 20381.916016\n",
      "Train Epoch: 60 [20160/225000 (9%)] Loss: 20094.988281\n",
      "Train Epoch: 60 [22656/225000 (10%)] Loss: 20256.980469\n",
      "Train Epoch: 60 [25152/225000 (11%)] Loss: 20172.654297\n",
      "Train Epoch: 60 [27648/225000 (12%)] Loss: 19776.070312\n",
      "Train Epoch: 60 [30144/225000 (13%)] Loss: 20087.476562\n",
      "Train Epoch: 60 [32640/225000 (15%)] Loss: 20332.707031\n",
      "Train Epoch: 60 [35136/225000 (16%)] Loss: 20516.703125\n",
      "Train Epoch: 60 [37632/225000 (17%)] Loss: 20188.824219\n",
      "Train Epoch: 60 [40128/225000 (18%)] Loss: 20530.171875\n",
      "Train Epoch: 60 [42624/225000 (19%)] Loss: 19641.792969\n",
      "Train Epoch: 60 [45120/225000 (20%)] Loss: 20049.890625\n",
      "Train Epoch: 60 [47616/225000 (21%)] Loss: 20672.304688\n",
      "Train Epoch: 60 [50112/225000 (22%)] Loss: 20090.226562\n",
      "Train Epoch: 60 [52608/225000 (23%)] Loss: 20397.480469\n",
      "Train Epoch: 60 [55104/225000 (24%)] Loss: 20447.585938\n",
      "Train Epoch: 60 [57600/225000 (26%)] Loss: 19918.453125\n",
      "Train Epoch: 60 [60096/225000 (27%)] Loss: 20016.972656\n",
      "Train Epoch: 60 [62592/225000 (28%)] Loss: 19981.671875\n",
      "Train Epoch: 60 [65088/225000 (29%)] Loss: 20064.578125\n",
      "Train Epoch: 60 [67584/225000 (30%)] Loss: 19595.781250\n",
      "Train Epoch: 60 [70080/225000 (31%)] Loss: 20058.882812\n",
      "Train Epoch: 60 [72576/225000 (32%)] Loss: 20067.740234\n",
      "Train Epoch: 60 [75072/225000 (33%)] Loss: 20392.685547\n",
      "Train Epoch: 60 [77568/225000 (34%)] Loss: 20383.894531\n",
      "Train Epoch: 60 [80064/225000 (36%)] Loss: 20233.921875\n",
      "Train Epoch: 60 [82560/225000 (37%)] Loss: 20529.921875\n",
      "Train Epoch: 60 [85056/225000 (38%)] Loss: 20300.484375\n",
      "Train Epoch: 60 [87552/225000 (39%)] Loss: 19961.685547\n",
      "Train Epoch: 60 [90048/225000 (40%)] Loss: 20160.175781\n",
      "Train Epoch: 60 [92544/225000 (41%)] Loss: 20160.882812\n",
      "Train Epoch: 60 [95040/225000 (42%)] Loss: 19515.197266\n",
      "Train Epoch: 60 [97536/225000 (43%)] Loss: 20395.404297\n",
      "Train Epoch: 60 [100032/225000 (44%)] Loss: 20357.490234\n",
      "Train Epoch: 60 [102528/225000 (46%)] Loss: 20356.099609\n",
      "Train Epoch: 60 [105024/225000 (47%)] Loss: 20057.470703\n",
      "Train Epoch: 60 [107520/225000 (48%)] Loss: 20147.425781\n",
      "Train Epoch: 60 [110016/225000 (49%)] Loss: 20145.371094\n",
      "Train Epoch: 60 [112512/225000 (50%)] Loss: 20073.769531\n",
      "Train Epoch: 60 [115008/225000 (51%)] Loss: 20332.755859\n",
      "Train Epoch: 60 [117504/225000 (52%)] Loss: 20125.443359\n",
      "Train Epoch: 60 [120000/225000 (53%)] Loss: 19957.472656\n",
      "Train Epoch: 60 [122496/225000 (54%)] Loss: 20433.578125\n",
      "Train Epoch: 60 [124992/225000 (56%)] Loss: 20409.941406\n",
      "Train Epoch: 60 [127488/225000 (57%)] Loss: 20115.886719\n",
      "Train Epoch: 60 [129984/225000 (58%)] Loss: 20311.609375\n",
      "Train Epoch: 60 [132480/225000 (59%)] Loss: 20214.953125\n",
      "Train Epoch: 60 [134976/225000 (60%)] Loss: 20257.675781\n",
      "Train Epoch: 60 [137472/225000 (61%)] Loss: 20190.406250\n",
      "Train Epoch: 60 [139968/225000 (62%)] Loss: 20265.035156\n",
      "Train Epoch: 60 [142464/225000 (63%)] Loss: 19757.869141\n",
      "Train Epoch: 60 [144960/225000 (64%)] Loss: 20144.980469\n",
      "Train Epoch: 60 [147456/225000 (66%)] Loss: 19788.416016\n",
      "Train Epoch: 60 [149952/225000 (67%)] Loss: 20325.980469\n",
      "Train Epoch: 60 [152448/225000 (68%)] Loss: 20125.595703\n",
      "Train Epoch: 60 [154944/225000 (69%)] Loss: 19584.828125\n",
      "Train Epoch: 60 [157440/225000 (70%)] Loss: 19919.810547\n",
      "Train Epoch: 60 [159936/225000 (71%)] Loss: 20578.750000\n",
      "Train Epoch: 60 [162432/225000 (72%)] Loss: 19878.099609\n",
      "Train Epoch: 60 [164928/225000 (73%)] Loss: 20245.851562\n",
      "Train Epoch: 60 [167424/225000 (74%)] Loss: 20290.392578\n",
      "Train Epoch: 60 [169920/225000 (76%)] Loss: 20087.820312\n",
      "Train Epoch: 60 [172416/225000 (77%)] Loss: 20619.191406\n",
      "Train Epoch: 60 [174912/225000 (78%)] Loss: 20159.750000\n",
      "Train Epoch: 60 [177408/225000 (79%)] Loss: 20117.406250\n",
      "Train Epoch: 60 [179904/225000 (80%)] Loss: 19974.031250\n",
      "Train Epoch: 60 [182400/225000 (81%)] Loss: 20517.230469\n",
      "Train Epoch: 60 [184896/225000 (82%)] Loss: 20529.417969\n",
      "Train Epoch: 60 [187392/225000 (83%)] Loss: 19601.650391\n",
      "Train Epoch: 60 [189888/225000 (84%)] Loss: 20302.933594\n",
      "Train Epoch: 60 [192384/225000 (86%)] Loss: 19826.154297\n",
      "Train Epoch: 60 [194880/225000 (87%)] Loss: 20143.531250\n",
      "Train Epoch: 60 [197376/225000 (88%)] Loss: 20257.328125\n",
      "Train Epoch: 60 [199872/225000 (89%)] Loss: 19813.996094\n",
      "Train Epoch: 60 [202368/225000 (90%)] Loss: 20020.238281\n",
      "Train Epoch: 60 [204864/225000 (91%)] Loss: 19499.523438\n",
      "Train Epoch: 60 [207360/225000 (92%)] Loss: 19882.648438\n",
      "Train Epoch: 60 [209856/225000 (93%)] Loss: 19971.832031\n",
      "Train Epoch: 60 [212352/225000 (94%)] Loss: 20416.699219\n",
      "Train Epoch: 60 [214848/225000 (95%)] Loss: 20652.808594\n",
      "Train Epoch: 60 [217344/225000 (97%)] Loss: 20131.714844\n",
      "Train Epoch: 60 [219840/225000 (98%)] Loss: 19810.679688\n",
      "Train Epoch: 60 [222336/225000 (99%)] Loss: 19937.939453\n",
      "Train Epoch: 60 [224832/225000 (100%)] Loss: 20587.148438\n",
      "    epoch          : 60\n",
      "    loss           : 20080.79783489761\n",
      "    val_loss       : 19978.880370578692\n",
      "Train Epoch: 61 [192/225000 (0%)] Loss: 19857.302734\n",
      "Train Epoch: 61 [2688/225000 (1%)] Loss: 20169.826172\n",
      "Train Epoch: 61 [5184/225000 (2%)] Loss: 19983.458984\n",
      "Train Epoch: 61 [7680/225000 (3%)] Loss: 19950.464844\n",
      "Train Epoch: 61 [10176/225000 (5%)] Loss: 20553.718750\n",
      "Train Epoch: 61 [12672/225000 (6%)] Loss: 19682.871094\n",
      "Train Epoch: 61 [15168/225000 (7%)] Loss: 19821.566406\n",
      "Train Epoch: 61 [17664/225000 (8%)] Loss: 19950.757812\n",
      "Train Epoch: 61 [20160/225000 (9%)] Loss: 20336.736328\n",
      "Train Epoch: 61 [22656/225000 (10%)] Loss: 19977.414062\n",
      "Train Epoch: 61 [25152/225000 (11%)] Loss: 20322.353516\n",
      "Train Epoch: 61 [27648/225000 (12%)] Loss: 19972.498047\n",
      "Train Epoch: 61 [30144/225000 (13%)] Loss: 20535.308594\n",
      "Train Epoch: 61 [32640/225000 (15%)] Loss: 20549.675781\n",
      "Train Epoch: 61 [35136/225000 (16%)] Loss: 20078.318359\n",
      "Train Epoch: 61 [37632/225000 (17%)] Loss: 20425.193359\n",
      "Train Epoch: 61 [40128/225000 (18%)] Loss: 19531.214844\n",
      "Train Epoch: 61 [42624/225000 (19%)] Loss: 20245.378906\n",
      "Train Epoch: 61 [45120/225000 (20%)] Loss: 20551.667969\n",
      "Train Epoch: 61 [47616/225000 (21%)] Loss: 19885.343750\n",
      "Train Epoch: 61 [50112/225000 (22%)] Loss: 20593.144531\n",
      "Train Epoch: 61 [52608/225000 (23%)] Loss: 19917.105469\n",
      "Train Epoch: 61 [55104/225000 (24%)] Loss: 20473.011719\n",
      "Train Epoch: 61 [57600/225000 (26%)] Loss: 19929.964844\n",
      "Train Epoch: 61 [60096/225000 (27%)] Loss: 20056.826172\n",
      "Train Epoch: 61 [62592/225000 (28%)] Loss: 19911.302734\n",
      "Train Epoch: 61 [65088/225000 (29%)] Loss: 20044.550781\n",
      "Train Epoch: 61 [67584/225000 (30%)] Loss: 20091.468750\n",
      "Train Epoch: 61 [70080/225000 (31%)] Loss: 19597.533203\n",
      "Train Epoch: 61 [72576/225000 (32%)] Loss: 20060.164062\n",
      "Train Epoch: 61 [75072/225000 (33%)] Loss: 19775.226562\n",
      "Train Epoch: 61 [77568/225000 (34%)] Loss: 19990.097656\n",
      "Train Epoch: 61 [80064/225000 (36%)] Loss: 19990.066406\n",
      "Train Epoch: 61 [82560/225000 (37%)] Loss: 20106.138672\n",
      "Train Epoch: 61 [85056/225000 (38%)] Loss: 20239.716797\n",
      "Train Epoch: 61 [87552/225000 (39%)] Loss: 19897.707031\n",
      "Train Epoch: 61 [90048/225000 (40%)] Loss: 19546.646484\n",
      "Train Epoch: 61 [92544/225000 (41%)] Loss: 19841.833984\n",
      "Train Epoch: 61 [95040/225000 (42%)] Loss: 20098.550781\n",
      "Train Epoch: 61 [97536/225000 (43%)] Loss: 20359.683594\n",
      "Train Epoch: 61 [100032/225000 (44%)] Loss: 20136.546875\n",
      "Train Epoch: 61 [102528/225000 (46%)] Loss: 20191.457031\n",
      "Train Epoch: 61 [105024/225000 (47%)] Loss: 20152.957031\n",
      "Train Epoch: 61 [107520/225000 (48%)] Loss: 19583.945312\n",
      "Train Epoch: 61 [110016/225000 (49%)] Loss: 19814.080078\n",
      "Train Epoch: 61 [112512/225000 (50%)] Loss: 19736.468750\n",
      "Train Epoch: 61 [115008/225000 (51%)] Loss: 20250.406250\n",
      "Train Epoch: 61 [117504/225000 (52%)] Loss: 19967.289062\n",
      "Train Epoch: 61 [120000/225000 (53%)] Loss: 19705.871094\n",
      "Train Epoch: 61 [122496/225000 (54%)] Loss: 19931.589844\n",
      "Train Epoch: 61 [124992/225000 (56%)] Loss: 20019.511719\n",
      "Train Epoch: 61 [127488/225000 (57%)] Loss: 19800.066406\n",
      "Train Epoch: 61 [129984/225000 (58%)] Loss: 20207.732422\n",
      "Train Epoch: 61 [132480/225000 (59%)] Loss: 19862.179688\n",
      "Train Epoch: 61 [134976/225000 (60%)] Loss: 19775.125000\n",
      "Train Epoch: 61 [137472/225000 (61%)] Loss: 20348.464844\n",
      "Train Epoch: 61 [139968/225000 (62%)] Loss: 20331.285156\n",
      "Train Epoch: 61 [142464/225000 (63%)] Loss: 20223.917969\n",
      "Train Epoch: 61 [144960/225000 (64%)] Loss: 20300.722656\n",
      "Train Epoch: 61 [147456/225000 (66%)] Loss: 20791.537109\n",
      "Train Epoch: 61 [149952/225000 (67%)] Loss: 20597.281250\n",
      "Train Epoch: 61 [152448/225000 (68%)] Loss: 20288.191406\n",
      "Train Epoch: 61 [154944/225000 (69%)] Loss: 20437.697266\n",
      "Train Epoch: 61 [157440/225000 (70%)] Loss: 19900.195312\n",
      "Train Epoch: 61 [159936/225000 (71%)] Loss: 19708.021484\n",
      "Train Epoch: 61 [162432/225000 (72%)] Loss: 20069.062500\n",
      "Train Epoch: 61 [164928/225000 (73%)] Loss: 20021.550781\n",
      "Train Epoch: 61 [167424/225000 (74%)] Loss: 19994.080078\n",
      "Train Epoch: 61 [169920/225000 (76%)] Loss: 19790.882812\n",
      "Train Epoch: 61 [172416/225000 (77%)] Loss: 19860.105469\n",
      "Train Epoch: 61 [174912/225000 (78%)] Loss: 19424.458984\n",
      "Train Epoch: 61 [177408/225000 (79%)] Loss: 19900.839844\n",
      "Train Epoch: 61 [179904/225000 (80%)] Loss: 19482.972656\n",
      "Train Epoch: 61 [182400/225000 (81%)] Loss: 20527.912109\n",
      "Train Epoch: 61 [184896/225000 (82%)] Loss: 19932.666016\n",
      "Train Epoch: 61 [187392/225000 (83%)] Loss: 19899.601562\n",
      "Train Epoch: 61 [189888/225000 (84%)] Loss: 19948.607422\n",
      "Train Epoch: 61 [192384/225000 (86%)] Loss: 20307.158203\n",
      "Train Epoch: 61 [194880/225000 (87%)] Loss: 19861.863281\n",
      "Train Epoch: 61 [197376/225000 (88%)] Loss: 20082.960938\n",
      "Train Epoch: 61 [199872/225000 (89%)] Loss: 19807.041016\n",
      "Train Epoch: 61 [202368/225000 (90%)] Loss: 19854.175781\n",
      "Train Epoch: 61 [204864/225000 (91%)] Loss: 19763.214844\n",
      "Train Epoch: 61 [207360/225000 (92%)] Loss: 19425.859375\n",
      "Train Epoch: 61 [209856/225000 (93%)] Loss: 20345.910156\n",
      "Train Epoch: 61 [212352/225000 (94%)] Loss: 20066.216797\n",
      "Train Epoch: 61 [214848/225000 (95%)] Loss: 20573.738281\n",
      "Train Epoch: 61 [217344/225000 (97%)] Loss: 19978.839844\n",
      "Train Epoch: 61 [219840/225000 (98%)] Loss: 20291.617188\n",
      "Train Epoch: 61 [222336/225000 (99%)] Loss: 20353.296875\n",
      "Train Epoch: 61 [224832/225000 (100%)] Loss: 19378.429688\n",
      "    epoch          : 61\n",
      "    loss           : 20077.682643851324\n",
      "    val_loss       : 19995.062565055512\n",
      "Train Epoch: 62 [192/225000 (0%)] Loss: 19990.457031\n",
      "Train Epoch: 62 [2688/225000 (1%)] Loss: 19902.531250\n",
      "Train Epoch: 62 [5184/225000 (2%)] Loss: 20104.580078\n",
      "Train Epoch: 62 [7680/225000 (3%)] Loss: 19725.363281\n",
      "Train Epoch: 62 [10176/225000 (5%)] Loss: 20387.572266\n",
      "Train Epoch: 62 [12672/225000 (6%)] Loss: 20277.187500\n",
      "Train Epoch: 62 [15168/225000 (7%)] Loss: 19537.480469\n",
      "Train Epoch: 62 [17664/225000 (8%)] Loss: 19553.181641\n",
      "Train Epoch: 62 [20160/225000 (9%)] Loss: 19966.292969\n",
      "Train Epoch: 62 [22656/225000 (10%)] Loss: 20635.511719\n",
      "Train Epoch: 62 [25152/225000 (11%)] Loss: 20045.443359\n",
      "Train Epoch: 62 [27648/225000 (12%)] Loss: 20258.589844\n",
      "Train Epoch: 62 [30144/225000 (13%)] Loss: 19936.765625\n",
      "Train Epoch: 62 [32640/225000 (15%)] Loss: 20202.027344\n",
      "Train Epoch: 62 [35136/225000 (16%)] Loss: 19665.257812\n",
      "Train Epoch: 62 [37632/225000 (17%)] Loss: 19699.593750\n",
      "Train Epoch: 62 [40128/225000 (18%)] Loss: 20129.296875\n",
      "Train Epoch: 62 [42624/225000 (19%)] Loss: 20200.140625\n",
      "Train Epoch: 62 [45120/225000 (20%)] Loss: 19869.044922\n",
      "Train Epoch: 62 [47616/225000 (21%)] Loss: 20018.492188\n",
      "Train Epoch: 62 [50112/225000 (22%)] Loss: 19985.841797\n",
      "Train Epoch: 62 [52608/225000 (23%)] Loss: 20136.410156\n",
      "Train Epoch: 62 [55104/225000 (24%)] Loss: 19897.658203\n",
      "Train Epoch: 62 [57600/225000 (26%)] Loss: 20063.562500\n",
      "Train Epoch: 62 [60096/225000 (27%)] Loss: 20285.304688\n",
      "Train Epoch: 62 [62592/225000 (28%)] Loss: 20343.714844\n",
      "Train Epoch: 62 [65088/225000 (29%)] Loss: 20317.443359\n",
      "Train Epoch: 62 [67584/225000 (30%)] Loss: 19580.222656\n",
      "Train Epoch: 62 [70080/225000 (31%)] Loss: 20013.375000\n",
      "Train Epoch: 62 [72576/225000 (32%)] Loss: 20354.458984\n",
      "Train Epoch: 62 [75072/225000 (33%)] Loss: 20240.689453\n",
      "Train Epoch: 62 [77568/225000 (34%)] Loss: 20348.449219\n",
      "Train Epoch: 62 [80064/225000 (36%)] Loss: 20036.199219\n",
      "Train Epoch: 62 [82560/225000 (37%)] Loss: 19980.199219\n",
      "Train Epoch: 62 [85056/225000 (38%)] Loss: 20397.152344\n",
      "Train Epoch: 62 [87552/225000 (39%)] Loss: 19879.017578\n",
      "Train Epoch: 62 [90048/225000 (40%)] Loss: 19818.445312\n",
      "Train Epoch: 62 [92544/225000 (41%)] Loss: 20434.513672\n",
      "Train Epoch: 62 [95040/225000 (42%)] Loss: 20609.507812\n",
      "Train Epoch: 62 [97536/225000 (43%)] Loss: 19779.199219\n",
      "Train Epoch: 62 [100032/225000 (44%)] Loss: 20539.679688\n",
      "Train Epoch: 62 [102528/225000 (46%)] Loss: 19906.609375\n",
      "Train Epoch: 62 [105024/225000 (47%)] Loss: 20241.058594\n",
      "Train Epoch: 62 [107520/225000 (48%)] Loss: 19609.839844\n",
      "Train Epoch: 62 [110016/225000 (49%)] Loss: 20234.871094\n",
      "Train Epoch: 62 [112512/225000 (50%)] Loss: 19842.734375\n",
      "Train Epoch: 62 [115008/225000 (51%)] Loss: 20352.781250\n",
      "Train Epoch: 62 [117504/225000 (52%)] Loss: 19717.523438\n",
      "Train Epoch: 62 [120000/225000 (53%)] Loss: 20035.890625\n",
      "Train Epoch: 62 [122496/225000 (54%)] Loss: 20445.091797\n",
      "Train Epoch: 62 [124992/225000 (56%)] Loss: 19736.750000\n",
      "Train Epoch: 62 [127488/225000 (57%)] Loss: 20177.871094\n",
      "Train Epoch: 62 [129984/225000 (58%)] Loss: 20340.113281\n",
      "Train Epoch: 62 [132480/225000 (59%)] Loss: 19841.679688\n",
      "Train Epoch: 62 [134976/225000 (60%)] Loss: 20055.929688\n",
      "Train Epoch: 62 [137472/225000 (61%)] Loss: 20164.714844\n",
      "Train Epoch: 62 [139968/225000 (62%)] Loss: 19803.121094\n",
      "Train Epoch: 62 [142464/225000 (63%)] Loss: 19735.285156\n",
      "Train Epoch: 62 [144960/225000 (64%)] Loss: 19745.105469\n",
      "Train Epoch: 62 [147456/225000 (66%)] Loss: 20168.625000\n",
      "Train Epoch: 62 [149952/225000 (67%)] Loss: 19598.867188\n",
      "Train Epoch: 62 [152448/225000 (68%)] Loss: 20007.695312\n",
      "Train Epoch: 62 [154944/225000 (69%)] Loss: 19599.843750\n",
      "Train Epoch: 62 [157440/225000 (70%)] Loss: 20739.029297\n",
      "Train Epoch: 62 [159936/225000 (71%)] Loss: 20191.197266\n",
      "Train Epoch: 62 [162432/225000 (72%)] Loss: 20518.169922\n",
      "Train Epoch: 62 [164928/225000 (73%)] Loss: 20039.037109\n",
      "Train Epoch: 62 [167424/225000 (74%)] Loss: 19940.687500\n",
      "Train Epoch: 62 [169920/225000 (76%)] Loss: 20285.880859\n",
      "Train Epoch: 62 [172416/225000 (77%)] Loss: 19820.097656\n",
      "Train Epoch: 62 [174912/225000 (78%)] Loss: 20328.775391\n",
      "Train Epoch: 62 [177408/225000 (79%)] Loss: 19931.974609\n",
      "Train Epoch: 62 [179904/225000 (80%)] Loss: 20372.466797\n",
      "Train Epoch: 62 [182400/225000 (81%)] Loss: 20366.042969\n",
      "Train Epoch: 62 [184896/225000 (82%)] Loss: 20217.617188\n",
      "Train Epoch: 62 [187392/225000 (83%)] Loss: 20364.478516\n",
      "Train Epoch: 62 [189888/225000 (84%)] Loss: 20266.720703\n",
      "Train Epoch: 62 [192384/225000 (86%)] Loss: 20016.679688\n",
      "Train Epoch: 62 [194880/225000 (87%)] Loss: 19924.953125\n",
      "Train Epoch: 62 [197376/225000 (88%)] Loss: 20179.972656\n",
      "Train Epoch: 62 [199872/225000 (89%)] Loss: 20427.931641\n",
      "Train Epoch: 62 [202368/225000 (90%)] Loss: 20334.910156\n",
      "Train Epoch: 62 [204864/225000 (91%)] Loss: 19816.953125\n",
      "Train Epoch: 62 [207360/225000 (92%)] Loss: 20137.906250\n",
      "Train Epoch: 62 [209856/225000 (93%)] Loss: 19821.535156\n",
      "Train Epoch: 62 [212352/225000 (94%)] Loss: 19858.236328\n",
      "Train Epoch: 62 [214848/225000 (95%)] Loss: 19705.011719\n",
      "Train Epoch: 62 [217344/225000 (97%)] Loss: 20348.488281\n",
      "Train Epoch: 62 [219840/225000 (98%)] Loss: 19646.404297\n",
      "Train Epoch: 62 [222336/225000 (99%)] Loss: 19832.894531\n",
      "Train Epoch: 62 [224832/225000 (100%)] Loss: 19859.660156\n",
      "    epoch          : 62\n",
      "    loss           : 20055.121793675342\n",
      "    val_loss       : 19971.817452567226\n",
      "Train Epoch: 63 [192/225000 (0%)] Loss: 19855.177734\n",
      "Train Epoch: 63 [2688/225000 (1%)] Loss: 20439.964844\n",
      "Train Epoch: 63 [5184/225000 (2%)] Loss: 19931.265625\n",
      "Train Epoch: 63 [7680/225000 (3%)] Loss: 20034.031250\n",
      "Train Epoch: 63 [10176/225000 (5%)] Loss: 19927.964844\n",
      "Train Epoch: 63 [12672/225000 (6%)] Loss: 20113.371094\n",
      "Train Epoch: 63 [15168/225000 (7%)] Loss: 19852.033203\n",
      "Train Epoch: 63 [17664/225000 (8%)] Loss: 20910.132812\n",
      "Train Epoch: 63 [20160/225000 (9%)] Loss: 19742.421875\n",
      "Train Epoch: 63 [22656/225000 (10%)] Loss: 20293.933594\n",
      "Train Epoch: 63 [25152/225000 (11%)] Loss: 20226.601562\n",
      "Train Epoch: 63 [27648/225000 (12%)] Loss: 20327.796875\n",
      "Train Epoch: 63 [30144/225000 (13%)] Loss: 19777.789062\n",
      "Train Epoch: 63 [32640/225000 (15%)] Loss: 19947.810547\n",
      "Train Epoch: 63 [35136/225000 (16%)] Loss: 20494.162109\n",
      "Train Epoch: 63 [37632/225000 (17%)] Loss: 20025.220703\n",
      "Train Epoch: 63 [40128/225000 (18%)] Loss: 20337.191406\n",
      "Train Epoch: 63 [42624/225000 (19%)] Loss: 20250.435547\n",
      "Train Epoch: 63 [45120/225000 (20%)] Loss: 20235.378906\n",
      "Train Epoch: 63 [47616/225000 (21%)] Loss: 20286.703125\n",
      "Train Epoch: 63 [50112/225000 (22%)] Loss: 20004.535156\n",
      "Train Epoch: 63 [52608/225000 (23%)] Loss: 19705.060547\n",
      "Train Epoch: 63 [55104/225000 (24%)] Loss: 20257.255859\n",
      "Train Epoch: 63 [57600/225000 (26%)] Loss: 20151.785156\n",
      "Train Epoch: 63 [60096/225000 (27%)] Loss: 20012.195312\n",
      "Train Epoch: 63 [62592/225000 (28%)] Loss: 20533.349609\n",
      "Train Epoch: 63 [65088/225000 (29%)] Loss: 20452.781250\n",
      "Train Epoch: 63 [67584/225000 (30%)] Loss: 20289.232422\n",
      "Train Epoch: 63 [70080/225000 (31%)] Loss: 19985.582031\n",
      "Train Epoch: 63 [72576/225000 (32%)] Loss: 20276.960938\n",
      "Train Epoch: 63 [75072/225000 (33%)] Loss: 19935.132812\n",
      "Train Epoch: 63 [77568/225000 (34%)] Loss: 20184.375000\n",
      "Train Epoch: 63 [80064/225000 (36%)] Loss: 19744.728516\n",
      "Train Epoch: 63 [82560/225000 (37%)] Loss: 19585.496094\n",
      "Train Epoch: 63 [85056/225000 (38%)] Loss: 19520.787109\n",
      "Train Epoch: 63 [87552/225000 (39%)] Loss: 20085.628906\n",
      "Train Epoch: 63 [90048/225000 (40%)] Loss: 19689.656250\n",
      "Train Epoch: 63 [92544/225000 (41%)] Loss: 20045.175781\n",
      "Train Epoch: 63 [95040/225000 (42%)] Loss: 19782.921875\n",
      "Train Epoch: 63 [97536/225000 (43%)] Loss: 20379.164062\n",
      "Train Epoch: 63 [100032/225000 (44%)] Loss: 19960.767578\n",
      "Train Epoch: 63 [102528/225000 (46%)] Loss: 19832.578125\n",
      "Train Epoch: 63 [105024/225000 (47%)] Loss: 19977.705078\n",
      "Train Epoch: 63 [107520/225000 (48%)] Loss: 19685.875000\n",
      "Train Epoch: 63 [110016/225000 (49%)] Loss: 20174.126953\n",
      "Train Epoch: 63 [112512/225000 (50%)] Loss: 19851.570312\n",
      "Train Epoch: 63 [115008/225000 (51%)] Loss: 20071.669922\n",
      "Train Epoch: 63 [117504/225000 (52%)] Loss: 19707.757812\n",
      "Train Epoch: 63 [120000/225000 (53%)] Loss: 19993.742188\n",
      "Train Epoch: 63 [122496/225000 (54%)] Loss: 20543.808594\n",
      "Train Epoch: 63 [124992/225000 (56%)] Loss: 19701.519531\n",
      "Train Epoch: 63 [127488/225000 (57%)] Loss: 20029.232422\n",
      "Train Epoch: 63 [129984/225000 (58%)] Loss: 19996.597656\n",
      "Train Epoch: 63 [132480/225000 (59%)] Loss: 20061.960938\n",
      "Train Epoch: 63 [134976/225000 (60%)] Loss: 20027.921875\n",
      "Train Epoch: 63 [137472/225000 (61%)] Loss: 19784.644531\n",
      "Train Epoch: 63 [139968/225000 (62%)] Loss: 19718.486328\n",
      "Train Epoch: 63 [142464/225000 (63%)] Loss: 20125.802734\n",
      "Train Epoch: 63 [144960/225000 (64%)] Loss: 19735.300781\n",
      "Train Epoch: 63 [147456/225000 (66%)] Loss: 20634.175781\n",
      "Train Epoch: 63 [149952/225000 (67%)] Loss: 19726.666016\n",
      "Train Epoch: 63 [152448/225000 (68%)] Loss: 19661.804688\n",
      "Train Epoch: 63 [154944/225000 (69%)] Loss: 20526.904297\n",
      "Train Epoch: 63 [157440/225000 (70%)] Loss: 20134.386719\n",
      "Train Epoch: 63 [159936/225000 (71%)] Loss: 20412.748047\n",
      "Train Epoch: 63 [162432/225000 (72%)] Loss: 20034.876953\n",
      "Train Epoch: 63 [164928/225000 (73%)] Loss: 19866.255859\n",
      "Train Epoch: 63 [167424/225000 (74%)] Loss: 19830.843750\n",
      "Train Epoch: 63 [169920/225000 (76%)] Loss: 20111.134766\n",
      "Train Epoch: 63 [172416/225000 (77%)] Loss: 19669.091797\n",
      "Train Epoch: 63 [174912/225000 (78%)] Loss: 19872.419922\n",
      "Train Epoch: 63 [177408/225000 (79%)] Loss: 19895.910156\n",
      "Train Epoch: 63 [179904/225000 (80%)] Loss: 19637.218750\n",
      "Train Epoch: 63 [182400/225000 (81%)] Loss: 19767.300781\n",
      "Train Epoch: 63 [184896/225000 (82%)] Loss: 19785.466797\n",
      "Train Epoch: 63 [187392/225000 (83%)] Loss: 20118.750000\n",
      "Train Epoch: 63 [189888/225000 (84%)] Loss: 20459.498047\n",
      "Train Epoch: 63 [192384/225000 (86%)] Loss: 20261.437500\n",
      "Train Epoch: 63 [194880/225000 (87%)] Loss: 20121.476562\n",
      "Train Epoch: 63 [197376/225000 (88%)] Loss: 19669.312500\n",
      "Train Epoch: 63 [199872/225000 (89%)] Loss: 19940.816406\n",
      "Train Epoch: 63 [202368/225000 (90%)] Loss: 20052.490234\n",
      "Train Epoch: 63 [204864/225000 (91%)] Loss: 20114.187500\n",
      "Train Epoch: 63 [207360/225000 (92%)] Loss: 20202.728516\n",
      "Train Epoch: 63 [209856/225000 (93%)] Loss: 20032.144531\n",
      "Train Epoch: 63 [212352/225000 (94%)] Loss: 20342.843750\n",
      "Train Epoch: 63 [214848/225000 (95%)] Loss: 20024.816406\n",
      "Train Epoch: 63 [217344/225000 (97%)] Loss: 19515.207031\n",
      "Train Epoch: 63 [219840/225000 (98%)] Loss: 20354.486328\n",
      "Train Epoch: 63 [222336/225000 (99%)] Loss: 20117.925781\n",
      "Train Epoch: 63 [224832/225000 (100%)] Loss: 20380.144531\n",
      "    epoch          : 63\n",
      "    loss           : 20032.782109908276\n",
      "    val_loss       : 19919.032272646444\n",
      "Train Epoch: 64 [192/225000 (0%)] Loss: 19946.203125\n",
      "Train Epoch: 64 [2688/225000 (1%)] Loss: 20438.324219\n",
      "Train Epoch: 64 [5184/225000 (2%)] Loss: 19935.199219\n",
      "Train Epoch: 64 [7680/225000 (3%)] Loss: 19900.957031\n",
      "Train Epoch: 64 [10176/225000 (5%)] Loss: 19809.484375\n",
      "Train Epoch: 64 [12672/225000 (6%)] Loss: 20341.458984\n",
      "Train Epoch: 64 [15168/225000 (7%)] Loss: 20359.070312\n",
      "Train Epoch: 64 [17664/225000 (8%)] Loss: 19901.140625\n",
      "Train Epoch: 64 [20160/225000 (9%)] Loss: 20341.257812\n",
      "Train Epoch: 64 [22656/225000 (10%)] Loss: 19915.128906\n",
      "Train Epoch: 64 [25152/225000 (11%)] Loss: 19796.248047\n",
      "Train Epoch: 64 [27648/225000 (12%)] Loss: 19612.414062\n",
      "Train Epoch: 64 [30144/225000 (13%)] Loss: 20089.451172\n",
      "Train Epoch: 64 [32640/225000 (15%)] Loss: 19642.890625\n",
      "Train Epoch: 64 [35136/225000 (16%)] Loss: 20092.085938\n",
      "Train Epoch: 64 [37632/225000 (17%)] Loss: 20049.292969\n",
      "Train Epoch: 64 [40128/225000 (18%)] Loss: 19962.417969\n",
      "Train Epoch: 64 [42624/225000 (19%)] Loss: 19542.925781\n",
      "Train Epoch: 64 [45120/225000 (20%)] Loss: 19867.031250\n",
      "Train Epoch: 64 [47616/225000 (21%)] Loss: 19443.228516\n",
      "Train Epoch: 64 [50112/225000 (22%)] Loss: 19994.539062\n",
      "Train Epoch: 64 [52608/225000 (23%)] Loss: 20181.082031\n",
      "Train Epoch: 64 [55104/225000 (24%)] Loss: 19625.394531\n",
      "Train Epoch: 64 [57600/225000 (26%)] Loss: 19620.589844\n",
      "Train Epoch: 64 [60096/225000 (27%)] Loss: 20026.488281\n",
      "Train Epoch: 64 [62592/225000 (28%)] Loss: 19911.878906\n",
      "Train Epoch: 64 [65088/225000 (29%)] Loss: 19972.923828\n",
      "Train Epoch: 64 [67584/225000 (30%)] Loss: 19627.062500\n",
      "Train Epoch: 64 [70080/225000 (31%)] Loss: 19616.980469\n",
      "Train Epoch: 64 [72576/225000 (32%)] Loss: 19606.632812\n",
      "Train Epoch: 64 [75072/225000 (33%)] Loss: 20364.593750\n",
      "Train Epoch: 64 [77568/225000 (34%)] Loss: 19864.304688\n",
      "Train Epoch: 64 [80064/225000 (36%)] Loss: 20077.019531\n",
      "Train Epoch: 64 [82560/225000 (37%)] Loss: 19544.714844\n",
      "Train Epoch: 64 [85056/225000 (38%)] Loss: 19756.390625\n",
      "Train Epoch: 64 [87552/225000 (39%)] Loss: 20019.691406\n",
      "Train Epoch: 64 [90048/225000 (40%)] Loss: 19482.548828\n",
      "Train Epoch: 64 [92544/225000 (41%)] Loss: 20185.853516\n",
      "Train Epoch: 64 [95040/225000 (42%)] Loss: 20269.238281\n",
      "Train Epoch: 64 [97536/225000 (43%)] Loss: 34691.203125\n",
      "Train Epoch: 64 [100032/225000 (44%)] Loss: 19784.316406\n",
      "Train Epoch: 64 [102528/225000 (46%)] Loss: 20090.001953\n",
      "Train Epoch: 64 [105024/225000 (47%)] Loss: 20180.005859\n",
      "Train Epoch: 64 [107520/225000 (48%)] Loss: 19755.417969\n",
      "Train Epoch: 64 [110016/225000 (49%)] Loss: 19649.238281\n",
      "Train Epoch: 64 [112512/225000 (50%)] Loss: 19675.828125\n",
      "Train Epoch: 64 [115008/225000 (51%)] Loss: 19979.791016\n",
      "Train Epoch: 64 [117504/225000 (52%)] Loss: 20028.031250\n",
      "Train Epoch: 64 [120000/225000 (53%)] Loss: 19590.751953\n",
      "Train Epoch: 64 [122496/225000 (54%)] Loss: 19891.761719\n",
      "Train Epoch: 64 [124992/225000 (56%)] Loss: 20146.328125\n",
      "Train Epoch: 64 [127488/225000 (57%)] Loss: 19786.921875\n",
      "Train Epoch: 64 [129984/225000 (58%)] Loss: 20030.136719\n",
      "Train Epoch: 64 [132480/225000 (59%)] Loss: 19636.804688\n",
      "Train Epoch: 64 [134976/225000 (60%)] Loss: 19934.349609\n",
      "Train Epoch: 64 [137472/225000 (61%)] Loss: 20107.453125\n",
      "Train Epoch: 64 [139968/225000 (62%)] Loss: 20489.648438\n",
      "Train Epoch: 64 [142464/225000 (63%)] Loss: 20018.847656\n",
      "Train Epoch: 64 [144960/225000 (64%)] Loss: 19710.515625\n",
      "Train Epoch: 64 [147456/225000 (66%)] Loss: 19829.429688\n",
      "Train Epoch: 64 [149952/225000 (67%)] Loss: 19729.843750\n",
      "Train Epoch: 64 [152448/225000 (68%)] Loss: 19856.300781\n",
      "Train Epoch: 64 [154944/225000 (69%)] Loss: 19965.691406\n",
      "Train Epoch: 64 [157440/225000 (70%)] Loss: 20105.406250\n",
      "Train Epoch: 64 [159936/225000 (71%)] Loss: 19631.250000\n",
      "Train Epoch: 64 [162432/225000 (72%)] Loss: 19324.796875\n",
      "Train Epoch: 64 [164928/225000 (73%)] Loss: 19812.597656\n",
      "Train Epoch: 64 [167424/225000 (74%)] Loss: 19898.554688\n",
      "Train Epoch: 64 [169920/225000 (76%)] Loss: 19750.033203\n",
      "Train Epoch: 64 [172416/225000 (77%)] Loss: 19564.808594\n",
      "Train Epoch: 64 [174912/225000 (78%)] Loss: 19910.203125\n",
      "Train Epoch: 64 [177408/225000 (79%)] Loss: 20514.726562\n",
      "Train Epoch: 64 [179904/225000 (80%)] Loss: 20310.136719\n",
      "Train Epoch: 64 [182400/225000 (81%)] Loss: 20101.511719\n",
      "Train Epoch: 64 [184896/225000 (82%)] Loss: 20141.105469\n",
      "Train Epoch: 64 [187392/225000 (83%)] Loss: 20309.949219\n",
      "Train Epoch: 64 [189888/225000 (84%)] Loss: 20526.066406\n",
      "Train Epoch: 64 [192384/225000 (86%)] Loss: 19836.644531\n",
      "Train Epoch: 64 [194880/225000 (87%)] Loss: 20210.078125\n",
      "Train Epoch: 64 [197376/225000 (88%)] Loss: 19441.136719\n",
      "Train Epoch: 64 [199872/225000 (89%)] Loss: 20084.636719\n",
      "Train Epoch: 64 [202368/225000 (90%)] Loss: 19832.630859\n",
      "Train Epoch: 64 [204864/225000 (91%)] Loss: 19652.779297\n",
      "Train Epoch: 64 [207360/225000 (92%)] Loss: 19764.007812\n",
      "Train Epoch: 64 [209856/225000 (93%)] Loss: 19854.447266\n",
      "Train Epoch: 64 [212352/225000 (94%)] Loss: 20167.902344\n",
      "Train Epoch: 64 [214848/225000 (95%)] Loss: 19935.007812\n",
      "Train Epoch: 64 [217344/225000 (97%)] Loss: 19583.732422\n",
      "Train Epoch: 64 [219840/225000 (98%)] Loss: 20051.265625\n",
      "Train Epoch: 64 [222336/225000 (99%)] Loss: 19658.164062\n",
      "Train Epoch: 64 [224832/225000 (100%)] Loss: 19887.880859\n",
      "    epoch          : 64\n",
      "    loss           : 19997.91774044102\n",
      "    val_loss       : 19868.80508492648\n",
      "Train Epoch: 65 [192/225000 (0%)] Loss: 19713.765625\n",
      "Train Epoch: 65 [2688/225000 (1%)] Loss: 20146.679688\n",
      "Train Epoch: 65 [5184/225000 (2%)] Loss: 19966.886719\n",
      "Train Epoch: 65 [7680/225000 (3%)] Loss: 19549.927734\n",
      "Train Epoch: 65 [10176/225000 (5%)] Loss: 20290.464844\n",
      "Train Epoch: 65 [12672/225000 (6%)] Loss: 19842.677734\n",
      "Train Epoch: 65 [15168/225000 (7%)] Loss: 19735.921875\n",
      "Train Epoch: 65 [17664/225000 (8%)] Loss: 20013.656250\n",
      "Train Epoch: 65 [20160/225000 (9%)] Loss: 20293.136719\n",
      "Train Epoch: 65 [22656/225000 (10%)] Loss: 19895.363281\n",
      "Train Epoch: 65 [25152/225000 (11%)] Loss: 19524.242188\n",
      "Train Epoch: 65 [27648/225000 (12%)] Loss: 20294.578125\n",
      "Train Epoch: 65 [30144/225000 (13%)] Loss: 19976.148438\n",
      "Train Epoch: 65 [32640/225000 (15%)] Loss: 20108.273438\n",
      "Train Epoch: 65 [35136/225000 (16%)] Loss: 19711.214844\n",
      "Train Epoch: 65 [37632/225000 (17%)] Loss: 19489.582031\n",
      "Train Epoch: 65 [40128/225000 (18%)] Loss: 20004.109375\n",
      "Train Epoch: 65 [42624/225000 (19%)] Loss: 20153.906250\n",
      "Train Epoch: 65 [45120/225000 (20%)] Loss: 19892.363281\n",
      "Train Epoch: 65 [47616/225000 (21%)] Loss: 20017.800781\n",
      "Train Epoch: 65 [50112/225000 (22%)] Loss: 19765.492188\n",
      "Train Epoch: 65 [52608/225000 (23%)] Loss: 19622.089844\n",
      "Train Epoch: 65 [55104/225000 (24%)] Loss: 19510.484375\n",
      "Train Epoch: 65 [57600/225000 (26%)] Loss: 19963.914062\n",
      "Train Epoch: 65 [60096/225000 (27%)] Loss: 19828.355469\n",
      "Train Epoch: 65 [62592/225000 (28%)] Loss: 19873.080078\n",
      "Train Epoch: 65 [65088/225000 (29%)] Loss: 19756.183594\n",
      "Train Epoch: 65 [67584/225000 (30%)] Loss: 19683.929688\n",
      "Train Epoch: 65 [70080/225000 (31%)] Loss: 19717.937500\n",
      "Train Epoch: 65 [72576/225000 (32%)] Loss: 20009.285156\n",
      "Train Epoch: 65 [75072/225000 (33%)] Loss: 19884.273438\n",
      "Train Epoch: 65 [77568/225000 (34%)] Loss: 19733.148438\n",
      "Train Epoch: 65 [80064/225000 (36%)] Loss: 19839.529297\n",
      "Train Epoch: 65 [82560/225000 (37%)] Loss: 20052.679688\n",
      "Train Epoch: 65 [85056/225000 (38%)] Loss: 19891.410156\n",
      "Train Epoch: 65 [87552/225000 (39%)] Loss: 20511.412109\n",
      "Train Epoch: 65 [90048/225000 (40%)] Loss: 19753.726562\n",
      "Train Epoch: 65 [92544/225000 (41%)] Loss: 19657.355469\n",
      "Train Epoch: 65 [95040/225000 (42%)] Loss: 19365.621094\n",
      "Train Epoch: 65 [97536/225000 (43%)] Loss: 20114.312500\n",
      "Train Epoch: 65 [100032/225000 (44%)] Loss: 19469.597656\n",
      "Train Epoch: 65 [102528/225000 (46%)] Loss: 19784.365234\n",
      "Train Epoch: 65 [105024/225000 (47%)] Loss: 19745.128906\n",
      "Train Epoch: 65 [107520/225000 (48%)] Loss: 19939.388672\n",
      "Train Epoch: 65 [110016/225000 (49%)] Loss: 20242.605469\n",
      "Train Epoch: 65 [112512/225000 (50%)] Loss: 19904.355469\n",
      "Train Epoch: 65 [115008/225000 (51%)] Loss: 19596.796875\n",
      "Train Epoch: 65 [117504/225000 (52%)] Loss: 19674.753906\n",
      "Train Epoch: 65 [120000/225000 (53%)] Loss: 20191.505859\n",
      "Train Epoch: 65 [122496/225000 (54%)] Loss: 20185.699219\n",
      "Train Epoch: 65 [124992/225000 (56%)] Loss: 19634.216797\n",
      "Train Epoch: 65 [127488/225000 (57%)] Loss: 20133.818359\n",
      "Train Epoch: 65 [129984/225000 (58%)] Loss: 19633.902344\n",
      "Train Epoch: 65 [132480/225000 (59%)] Loss: 20357.218750\n",
      "Train Epoch: 65 [134976/225000 (60%)] Loss: 19629.101562\n",
      "Train Epoch: 65 [137472/225000 (61%)] Loss: 20174.763672\n",
      "Train Epoch: 65 [139968/225000 (62%)] Loss: 19924.078125\n",
      "Train Epoch: 65 [142464/225000 (63%)] Loss: 19965.062500\n",
      "Train Epoch: 65 [144960/225000 (64%)] Loss: 19908.640625\n",
      "Train Epoch: 65 [147456/225000 (66%)] Loss: 20148.906250\n",
      "Train Epoch: 65 [149952/225000 (67%)] Loss: 20114.248047\n",
      "Train Epoch: 65 [152448/225000 (68%)] Loss: 20081.070312\n",
      "Train Epoch: 65 [154944/225000 (69%)] Loss: 19584.507812\n",
      "Train Epoch: 65 [157440/225000 (70%)] Loss: 19789.146484\n",
      "Train Epoch: 65 [159936/225000 (71%)] Loss: 19868.105469\n",
      "Train Epoch: 65 [162432/225000 (72%)] Loss: 20462.718750\n",
      "Train Epoch: 65 [164928/225000 (73%)] Loss: 20092.835938\n",
      "Train Epoch: 65 [167424/225000 (74%)] Loss: 19948.503906\n",
      "Train Epoch: 65 [169920/225000 (76%)] Loss: 19895.699219\n",
      "Train Epoch: 65 [172416/225000 (77%)] Loss: 20091.121094\n",
      "Train Epoch: 65 [174912/225000 (78%)] Loss: 19277.398438\n",
      "Train Epoch: 65 [177408/225000 (79%)] Loss: 20085.023438\n",
      "Train Epoch: 65 [179904/225000 (80%)] Loss: 19830.611328\n",
      "Train Epoch: 65 [182400/225000 (81%)] Loss: 19658.339844\n",
      "Train Epoch: 65 [184896/225000 (82%)] Loss: 19815.767578\n",
      "Train Epoch: 65 [187392/225000 (83%)] Loss: 19672.173828\n",
      "Train Epoch: 65 [189888/225000 (84%)] Loss: 19619.972656\n",
      "Train Epoch: 65 [192384/225000 (86%)] Loss: 19605.007812\n",
      "Train Epoch: 65 [194880/225000 (87%)] Loss: 20207.707031\n",
      "Train Epoch: 65 [197376/225000 (88%)] Loss: 20269.675781\n",
      "Train Epoch: 65 [199872/225000 (89%)] Loss: 19821.556641\n",
      "Train Epoch: 65 [202368/225000 (90%)] Loss: 19376.082031\n",
      "Train Epoch: 65 [204864/225000 (91%)] Loss: 20015.453125\n",
      "Train Epoch: 65 [207360/225000 (92%)] Loss: 19670.226562\n",
      "Train Epoch: 65 [209856/225000 (93%)] Loss: 19930.185547\n",
      "Train Epoch: 65 [212352/225000 (94%)] Loss: 20479.539062\n",
      "Train Epoch: 65 [214848/225000 (95%)] Loss: 19830.039062\n",
      "Train Epoch: 65 [217344/225000 (97%)] Loss: 19418.734375\n",
      "Train Epoch: 65 [219840/225000 (98%)] Loss: 20222.660156\n",
      "Train Epoch: 65 [222336/225000 (99%)] Loss: 20625.847656\n",
      "Train Epoch: 65 [224832/225000 (100%)] Loss: 19813.328125\n",
      "    epoch          : 65\n",
      "    loss           : 19952.924701365188\n",
      "    val_loss       : 19829.61776775986\n",
      "Train Epoch: 66 [192/225000 (0%)] Loss: 19130.757812\n",
      "Train Epoch: 66 [2688/225000 (1%)] Loss: 19840.785156\n",
      "Train Epoch: 66 [5184/225000 (2%)] Loss: 19171.095703\n",
      "Train Epoch: 66 [7680/225000 (3%)] Loss: 20024.849609\n",
      "Train Epoch: 66 [10176/225000 (5%)] Loss: 20107.218750\n",
      "Train Epoch: 66 [12672/225000 (6%)] Loss: 19426.093750\n",
      "Train Epoch: 66 [15168/225000 (7%)] Loss: 20007.822266\n",
      "Train Epoch: 66 [17664/225000 (8%)] Loss: 19806.972656\n",
      "Train Epoch: 66 [20160/225000 (9%)] Loss: 20373.304688\n",
      "Train Epoch: 66 [22656/225000 (10%)] Loss: 19543.316406\n",
      "Train Epoch: 66 [25152/225000 (11%)] Loss: 19954.425781\n",
      "Train Epoch: 66 [27648/225000 (12%)] Loss: 19819.150391\n",
      "Train Epoch: 66 [30144/225000 (13%)] Loss: 20040.132812\n",
      "Train Epoch: 66 [32640/225000 (15%)] Loss: 20089.541016\n",
      "Train Epoch: 66 [35136/225000 (16%)] Loss: 20080.078125\n",
      "Train Epoch: 66 [37632/225000 (17%)] Loss: 20076.859375\n",
      "Train Epoch: 66 [40128/225000 (18%)] Loss: 19983.843750\n",
      "Train Epoch: 66 [42624/225000 (19%)] Loss: 19827.111328\n",
      "Train Epoch: 66 [45120/225000 (20%)] Loss: 20056.541016\n",
      "Train Epoch: 66 [47616/225000 (21%)] Loss: 19954.484375\n",
      "Train Epoch: 66 [50112/225000 (22%)] Loss: 19817.578125\n",
      "Train Epoch: 66 [52608/225000 (23%)] Loss: 19881.849609\n",
      "Train Epoch: 66 [55104/225000 (24%)] Loss: 19574.765625\n",
      "Train Epoch: 66 [57600/225000 (26%)] Loss: 19813.500000\n",
      "Train Epoch: 66 [60096/225000 (27%)] Loss: 19494.753906\n",
      "Train Epoch: 66 [62592/225000 (28%)] Loss: 20015.189453\n",
      "Train Epoch: 66 [65088/225000 (29%)] Loss: 19809.513672\n",
      "Train Epoch: 66 [67584/225000 (30%)] Loss: 19708.367188\n",
      "Train Epoch: 66 [70080/225000 (31%)] Loss: 20344.460938\n",
      "Train Epoch: 66 [72576/225000 (32%)] Loss: 19566.083984\n",
      "Train Epoch: 66 [75072/225000 (33%)] Loss: 19600.519531\n",
      "Train Epoch: 66 [77568/225000 (34%)] Loss: 19852.488281\n",
      "Train Epoch: 66 [80064/225000 (36%)] Loss: 19861.031250\n",
      "Train Epoch: 66 [82560/225000 (37%)] Loss: 19973.357422\n",
      "Train Epoch: 66 [85056/225000 (38%)] Loss: 19920.593750\n",
      "Train Epoch: 66 [87552/225000 (39%)] Loss: 19578.580078\n",
      "Train Epoch: 66 [90048/225000 (40%)] Loss: 19919.039062\n",
      "Train Epoch: 66 [92544/225000 (41%)] Loss: 19731.738281\n",
      "Train Epoch: 66 [95040/225000 (42%)] Loss: 20010.355469\n",
      "Train Epoch: 66 [97536/225000 (43%)] Loss: 20006.695312\n",
      "Train Epoch: 66 [100032/225000 (44%)] Loss: 19561.246094\n",
      "Train Epoch: 66 [102528/225000 (46%)] Loss: 19952.753906\n",
      "Train Epoch: 66 [105024/225000 (47%)] Loss: 19429.621094\n",
      "Train Epoch: 66 [107520/225000 (48%)] Loss: 20093.914062\n",
      "Train Epoch: 66 [110016/225000 (49%)] Loss: 19954.734375\n",
      "Train Epoch: 66 [112512/225000 (50%)] Loss: 20052.529297\n",
      "Train Epoch: 66 [115008/225000 (51%)] Loss: 19924.253906\n",
      "Train Epoch: 66 [117504/225000 (52%)] Loss: 20508.486328\n",
      "Train Epoch: 66 [120000/225000 (53%)] Loss: 19823.388672\n",
      "Train Epoch: 66 [122496/225000 (54%)] Loss: 20287.476562\n",
      "Train Epoch: 66 [124992/225000 (56%)] Loss: 20104.828125\n",
      "Train Epoch: 66 [127488/225000 (57%)] Loss: 20109.421875\n",
      "Train Epoch: 66 [129984/225000 (58%)] Loss: 19660.783203\n",
      "Train Epoch: 66 [132480/225000 (59%)] Loss: 19611.441406\n",
      "Train Epoch: 66 [134976/225000 (60%)] Loss: 19988.847656\n",
      "Train Epoch: 66 [137472/225000 (61%)] Loss: 20504.765625\n",
      "Train Epoch: 66 [139968/225000 (62%)] Loss: 19642.324219\n",
      "Train Epoch: 66 [142464/225000 (63%)] Loss: 20145.199219\n",
      "Train Epoch: 66 [144960/225000 (64%)] Loss: 20027.175781\n",
      "Train Epoch: 66 [147456/225000 (66%)] Loss: 20042.957031\n",
      "Train Epoch: 66 [149952/225000 (67%)] Loss: 19473.156250\n",
      "Train Epoch: 66 [152448/225000 (68%)] Loss: 19824.066406\n",
      "Train Epoch: 66 [154944/225000 (69%)] Loss: 19715.066406\n",
      "Train Epoch: 66 [157440/225000 (70%)] Loss: 19774.156250\n",
      "Train Epoch: 66 [159936/225000 (71%)] Loss: 19699.339844\n",
      "Train Epoch: 66 [162432/225000 (72%)] Loss: 19443.191406\n",
      "Train Epoch: 66 [164928/225000 (73%)] Loss: 19884.599609\n",
      "Train Epoch: 66 [167424/225000 (74%)] Loss: 19422.277344\n",
      "Train Epoch: 66 [169920/225000 (76%)] Loss: 19730.105469\n",
      "Train Epoch: 66 [172416/225000 (77%)] Loss: 19569.214844\n",
      "Train Epoch: 66 [174912/225000 (78%)] Loss: 20177.402344\n",
      "Train Epoch: 66 [177408/225000 (79%)] Loss: 19771.554688\n",
      "Train Epoch: 66 [179904/225000 (80%)] Loss: 19654.595703\n",
      "Train Epoch: 66 [182400/225000 (81%)] Loss: 19515.042969\n",
      "Train Epoch: 66 [184896/225000 (82%)] Loss: 20253.230469\n",
      "Train Epoch: 66 [187392/225000 (83%)] Loss: 19861.253906\n",
      "Train Epoch: 66 [189888/225000 (84%)] Loss: 19912.429688\n",
      "Train Epoch: 66 [192384/225000 (86%)] Loss: 19977.429688\n",
      "Train Epoch: 66 [194880/225000 (87%)] Loss: 19675.144531\n",
      "Train Epoch: 66 [197376/225000 (88%)] Loss: 19755.207031\n",
      "Train Epoch: 66 [199872/225000 (89%)] Loss: 20073.074219\n",
      "Train Epoch: 66 [202368/225000 (90%)] Loss: 19710.726562\n",
      "Train Epoch: 66 [204864/225000 (91%)] Loss: 19934.804688\n",
      "Train Epoch: 66 [207360/225000 (92%)] Loss: 19850.343750\n",
      "Train Epoch: 66 [209856/225000 (93%)] Loss: 19703.859375\n",
      "Train Epoch: 66 [212352/225000 (94%)] Loss: 20170.242188\n",
      "Train Epoch: 66 [214848/225000 (95%)] Loss: 19687.671875\n",
      "Train Epoch: 66 [217344/225000 (97%)] Loss: 19984.447266\n",
      "Train Epoch: 66 [219840/225000 (98%)] Loss: 20085.304688\n",
      "Train Epoch: 66 [222336/225000 (99%)] Loss: 19913.796875\n",
      "Train Epoch: 66 [224832/225000 (100%)] Loss: 19334.636719\n",
      "    epoch          : 66\n",
      "    loss           : 19924.58626246534\n",
      "    val_loss       : 19813.64559366139\n",
      "Train Epoch: 67 [192/225000 (0%)] Loss: 19549.060547\n",
      "Train Epoch: 67 [2688/225000 (1%)] Loss: 19973.132812\n",
      "Train Epoch: 67 [5184/225000 (2%)] Loss: 20013.371094\n",
      "Train Epoch: 67 [7680/225000 (3%)] Loss: 20342.640625\n",
      "Train Epoch: 67 [10176/225000 (5%)] Loss: 19903.714844\n",
      "Train Epoch: 67 [12672/225000 (6%)] Loss: 20040.511719\n",
      "Train Epoch: 67 [15168/225000 (7%)] Loss: 20242.636719\n",
      "Train Epoch: 67 [17664/225000 (8%)] Loss: 19762.365234\n",
      "Train Epoch: 67 [20160/225000 (9%)] Loss: 20080.515625\n",
      "Train Epoch: 67 [22656/225000 (10%)] Loss: 20101.347656\n",
      "Train Epoch: 67 [25152/225000 (11%)] Loss: 19940.667969\n",
      "Train Epoch: 67 [27648/225000 (12%)] Loss: 20069.468750\n",
      "Train Epoch: 67 [30144/225000 (13%)] Loss: 20142.515625\n",
      "Train Epoch: 67 [32640/225000 (15%)] Loss: 20156.234375\n",
      "Train Epoch: 67 [35136/225000 (16%)] Loss: 19891.714844\n",
      "Train Epoch: 67 [37632/225000 (17%)] Loss: 20000.261719\n",
      "Train Epoch: 67 [40128/225000 (18%)] Loss: 19839.369141\n",
      "Train Epoch: 67 [42624/225000 (19%)] Loss: 19746.552734\n",
      "Train Epoch: 67 [45120/225000 (20%)] Loss: 20204.816406\n",
      "Train Epoch: 67 [47616/225000 (21%)] Loss: 19705.542969\n",
      "Train Epoch: 67 [50112/225000 (22%)] Loss: 19688.886719\n",
      "Train Epoch: 67 [52608/225000 (23%)] Loss: 20347.609375\n",
      "Train Epoch: 67 [55104/225000 (24%)] Loss: 19567.292969\n",
      "Train Epoch: 67 [57600/225000 (26%)] Loss: 19523.339844\n",
      "Train Epoch: 67 [60096/225000 (27%)] Loss: 19839.285156\n",
      "Train Epoch: 67 [62592/225000 (28%)] Loss: 19906.318359\n",
      "Train Epoch: 67 [65088/225000 (29%)] Loss: 19726.857422\n",
      "Train Epoch: 67 [67584/225000 (30%)] Loss: 19870.550781\n",
      "Train Epoch: 67 [70080/225000 (31%)] Loss: 20893.398438\n",
      "Train Epoch: 67 [72576/225000 (32%)] Loss: 19901.496094\n",
      "Train Epoch: 67 [75072/225000 (33%)] Loss: 19592.726562\n",
      "Train Epoch: 67 [77568/225000 (34%)] Loss: 19965.982422\n",
      "Train Epoch: 67 [80064/225000 (36%)] Loss: 20234.419922\n",
      "Train Epoch: 67 [82560/225000 (37%)] Loss: 19739.480469\n",
      "Train Epoch: 67 [85056/225000 (38%)] Loss: 19689.027344\n",
      "Train Epoch: 67 [87552/225000 (39%)] Loss: 19854.085938\n",
      "Train Epoch: 67 [90048/225000 (40%)] Loss: 20056.562500\n",
      "Train Epoch: 67 [92544/225000 (41%)] Loss: 20389.248047\n",
      "Train Epoch: 67 [95040/225000 (42%)] Loss: 19535.953125\n",
      "Train Epoch: 67 [97536/225000 (43%)] Loss: 20005.781250\n",
      "Train Epoch: 67 [100032/225000 (44%)] Loss: 19955.464844\n",
      "Train Epoch: 67 [102528/225000 (46%)] Loss: 19732.042969\n",
      "Train Epoch: 67 [105024/225000 (47%)] Loss: 20216.765625\n",
      "Train Epoch: 67 [107520/225000 (48%)] Loss: 19689.566406\n",
      "Train Epoch: 67 [110016/225000 (49%)] Loss: 19741.105469\n",
      "Train Epoch: 67 [112512/225000 (50%)] Loss: 20085.765625\n",
      "Train Epoch: 67 [115008/225000 (51%)] Loss: 19437.384766\n",
      "Train Epoch: 67 [117504/225000 (52%)] Loss: 20277.080078\n",
      "Train Epoch: 67 [120000/225000 (53%)] Loss: 19859.041016\n",
      "Train Epoch: 67 [122496/225000 (54%)] Loss: 19769.175781\n",
      "Train Epoch: 67 [124992/225000 (56%)] Loss: 19623.023438\n",
      "Train Epoch: 67 [127488/225000 (57%)] Loss: 19724.291016\n",
      "Train Epoch: 67 [129984/225000 (58%)] Loss: 19990.777344\n",
      "Train Epoch: 67 [132480/225000 (59%)] Loss: 19986.093750\n",
      "Train Epoch: 67 [134976/225000 (60%)] Loss: 20131.542969\n",
      "Train Epoch: 67 [137472/225000 (61%)] Loss: 19864.992188\n",
      "Train Epoch: 67 [139968/225000 (62%)] Loss: 20114.722656\n",
      "Train Epoch: 67 [142464/225000 (63%)] Loss: 19604.507812\n",
      "Train Epoch: 67 [144960/225000 (64%)] Loss: 19605.167969\n",
      "Train Epoch: 67 [147456/225000 (66%)] Loss: 19677.746094\n",
      "Train Epoch: 67 [149952/225000 (67%)] Loss: 20451.882812\n",
      "Train Epoch: 67 [152448/225000 (68%)] Loss: 19815.675781\n",
      "Train Epoch: 67 [154944/225000 (69%)] Loss: 19817.708984\n",
      "Train Epoch: 67 [157440/225000 (70%)] Loss: 19778.761719\n",
      "Train Epoch: 67 [159936/225000 (71%)] Loss: 19753.949219\n",
      "Train Epoch: 67 [162432/225000 (72%)] Loss: 19840.535156\n",
      "Train Epoch: 67 [164928/225000 (73%)] Loss: 20132.062500\n",
      "Train Epoch: 67 [167424/225000 (74%)] Loss: 19884.382812\n",
      "Train Epoch: 67 [169920/225000 (76%)] Loss: 20004.826172\n",
      "Train Epoch: 67 [172416/225000 (77%)] Loss: 20035.580078\n",
      "Train Epoch: 67 [174912/225000 (78%)] Loss: 19866.621094\n",
      "Train Epoch: 67 [177408/225000 (79%)] Loss: 19787.714844\n",
      "Train Epoch: 67 [179904/225000 (80%)] Loss: 19876.394531\n",
      "Train Epoch: 67 [182400/225000 (81%)] Loss: 19754.894531\n",
      "Train Epoch: 67 [184896/225000 (82%)] Loss: 20050.394531\n",
      "Train Epoch: 67 [187392/225000 (83%)] Loss: 19868.226562\n",
      "Train Epoch: 67 [189888/225000 (84%)] Loss: 20150.535156\n",
      "Train Epoch: 67 [192384/225000 (86%)] Loss: 19718.972656\n",
      "Train Epoch: 67 [194880/225000 (87%)] Loss: 19993.664062\n",
      "Train Epoch: 67 [197376/225000 (88%)] Loss: 19898.912109\n",
      "Train Epoch: 67 [199872/225000 (89%)] Loss: 19495.265625\n",
      "Train Epoch: 67 [202368/225000 (90%)] Loss: 20078.273438\n",
      "Train Epoch: 67 [204864/225000 (91%)] Loss: 20097.353516\n",
      "Train Epoch: 67 [207360/225000 (92%)] Loss: 20112.589844\n",
      "Train Epoch: 67 [209856/225000 (93%)] Loss: 19710.775391\n",
      "Train Epoch: 67 [212352/225000 (94%)] Loss: 20064.521484\n",
      "Train Epoch: 67 [214848/225000 (95%)] Loss: 20163.179688\n",
      "Train Epoch: 67 [217344/225000 (97%)] Loss: 24163.988281\n",
      "Train Epoch: 67 [219840/225000 (98%)] Loss: 19694.046875\n",
      "Train Epoch: 67 [222336/225000 (99%)] Loss: 19854.222656\n",
      "Train Epoch: 67 [224832/225000 (100%)] Loss: 19582.105469\n",
      "    epoch          : 67\n",
      "    loss           : 19899.367924088096\n",
      "    val_loss       : 19788.721988060093\n",
      "Train Epoch: 68 [192/225000 (0%)] Loss: 19748.906250\n",
      "Train Epoch: 68 [2688/225000 (1%)] Loss: 19756.958984\n",
      "Train Epoch: 68 [5184/225000 (2%)] Loss: 19624.220703\n",
      "Train Epoch: 68 [7680/225000 (3%)] Loss: 20290.554688\n",
      "Train Epoch: 68 [10176/225000 (5%)] Loss: 20202.896484\n",
      "Train Epoch: 68 [12672/225000 (6%)] Loss: 19800.285156\n",
      "Train Epoch: 68 [15168/225000 (7%)] Loss: 19963.796875\n",
      "Train Epoch: 68 [17664/225000 (8%)] Loss: 19561.353516\n",
      "Train Epoch: 68 [20160/225000 (9%)] Loss: 20028.515625\n",
      "Train Epoch: 68 [22656/225000 (10%)] Loss: 20137.996094\n",
      "Train Epoch: 68 [25152/225000 (11%)] Loss: 19778.833984\n",
      "Train Epoch: 68 [27648/225000 (12%)] Loss: 19707.906250\n",
      "Train Epoch: 68 [30144/225000 (13%)] Loss: 19512.521484\n",
      "Train Epoch: 68 [32640/225000 (15%)] Loss: 20214.187500\n",
      "Train Epoch: 68 [35136/225000 (16%)] Loss: 20366.896484\n",
      "Train Epoch: 68 [37632/225000 (17%)] Loss: 19434.794922\n",
      "Train Epoch: 68 [40128/225000 (18%)] Loss: 19867.500000\n",
      "Train Epoch: 68 [42624/225000 (19%)] Loss: 20198.511719\n",
      "Train Epoch: 68 [45120/225000 (20%)] Loss: 19868.835938\n",
      "Train Epoch: 68 [47616/225000 (21%)] Loss: 19802.251953\n",
      "Train Epoch: 68 [50112/225000 (22%)] Loss: 19479.054688\n",
      "Train Epoch: 68 [52608/225000 (23%)] Loss: 19650.087891\n",
      "Train Epoch: 68 [55104/225000 (24%)] Loss: 19482.550781\n",
      "Train Epoch: 68 [57600/225000 (26%)] Loss: 20271.183594\n",
      "Train Epoch: 68 [60096/225000 (27%)] Loss: 19846.287109\n",
      "Train Epoch: 68 [62592/225000 (28%)] Loss: 20090.845703\n",
      "Train Epoch: 68 [65088/225000 (29%)] Loss: 19524.445312\n",
      "Train Epoch: 68 [67584/225000 (30%)] Loss: 20305.796875\n",
      "Train Epoch: 68 [70080/225000 (31%)] Loss: 20337.904297\n",
      "Train Epoch: 68 [72576/225000 (32%)] Loss: 19860.722656\n",
      "Train Epoch: 68 [75072/225000 (33%)] Loss: 20014.460938\n",
      "Train Epoch: 68 [77568/225000 (34%)] Loss: 19297.697266\n",
      "Train Epoch: 68 [80064/225000 (36%)] Loss: 19848.710938\n",
      "Train Epoch: 68 [82560/225000 (37%)] Loss: 20444.779297\n",
      "Train Epoch: 68 [85056/225000 (38%)] Loss: 19674.062500\n",
      "Train Epoch: 68 [87552/225000 (39%)] Loss: 20209.771484\n",
      "Train Epoch: 68 [90048/225000 (40%)] Loss: 20080.878906\n",
      "Train Epoch: 68 [92544/225000 (41%)] Loss: 19800.859375\n",
      "Train Epoch: 68 [95040/225000 (42%)] Loss: 19778.695312\n",
      "Train Epoch: 68 [97536/225000 (43%)] Loss: 20156.734375\n",
      "Train Epoch: 68 [100032/225000 (44%)] Loss: 20225.324219\n",
      "Train Epoch: 68 [102528/225000 (46%)] Loss: 20062.453125\n",
      "Train Epoch: 68 [105024/225000 (47%)] Loss: 19791.707031\n",
      "Train Epoch: 68 [107520/225000 (48%)] Loss: 19960.076172\n",
      "Train Epoch: 68 [110016/225000 (49%)] Loss: 19839.511719\n",
      "Train Epoch: 68 [112512/225000 (50%)] Loss: 19789.269531\n",
      "Train Epoch: 68 [115008/225000 (51%)] Loss: 19591.226562\n",
      "Train Epoch: 68 [117504/225000 (52%)] Loss: 19626.927734\n",
      "Train Epoch: 68 [120000/225000 (53%)] Loss: 20093.945312\n",
      "Train Epoch: 68 [122496/225000 (54%)] Loss: 19222.611328\n",
      "Train Epoch: 68 [124992/225000 (56%)] Loss: 19894.447266\n",
      "Train Epoch: 68 [127488/225000 (57%)] Loss: 20181.714844\n",
      "Train Epoch: 68 [129984/225000 (58%)] Loss: 19650.847656\n",
      "Train Epoch: 68 [132480/225000 (59%)] Loss: 19965.029297\n",
      "Train Epoch: 68 [134976/225000 (60%)] Loss: 19783.408203\n",
      "Train Epoch: 68 [137472/225000 (61%)] Loss: 19394.105469\n",
      "Train Epoch: 68 [139968/225000 (62%)] Loss: 20148.265625\n",
      "Train Epoch: 68 [142464/225000 (63%)] Loss: 18924.541016\n",
      "Train Epoch: 68 [144960/225000 (64%)] Loss: 20089.210938\n",
      "Train Epoch: 68 [147456/225000 (66%)] Loss: 19421.917969\n",
      "Train Epoch: 68 [149952/225000 (67%)] Loss: 20218.101562\n",
      "Train Epoch: 68 [152448/225000 (68%)] Loss: 19708.136719\n",
      "Train Epoch: 68 [154944/225000 (69%)] Loss: 19743.222656\n",
      "Train Epoch: 68 [157440/225000 (70%)] Loss: 20077.066406\n",
      "Train Epoch: 68 [159936/225000 (71%)] Loss: 19653.306641\n",
      "Train Epoch: 68 [162432/225000 (72%)] Loss: 19925.486328\n",
      "Train Epoch: 68 [164928/225000 (73%)] Loss: 19569.558594\n",
      "Train Epoch: 68 [167424/225000 (74%)] Loss: 19723.685547\n",
      "Train Epoch: 68 [169920/225000 (76%)] Loss: 19530.410156\n",
      "Train Epoch: 68 [172416/225000 (77%)] Loss: 19770.171875\n",
      "Train Epoch: 68 [174912/225000 (78%)] Loss: 19713.550781\n",
      "Train Epoch: 68 [177408/225000 (79%)] Loss: 20573.738281\n",
      "Train Epoch: 68 [179904/225000 (80%)] Loss: 20024.144531\n",
      "Train Epoch: 68 [182400/225000 (81%)] Loss: 19729.201172\n",
      "Train Epoch: 68 [184896/225000 (82%)] Loss: 19822.310547\n",
      "Train Epoch: 68 [187392/225000 (83%)] Loss: 19621.355469\n",
      "Train Epoch: 68 [189888/225000 (84%)] Loss: 20178.289062\n",
      "Train Epoch: 68 [192384/225000 (86%)] Loss: 19580.802734\n",
      "Train Epoch: 68 [194880/225000 (87%)] Loss: 19469.617188\n",
      "Train Epoch: 68 [197376/225000 (88%)] Loss: 20399.671875\n",
      "Train Epoch: 68 [199872/225000 (89%)] Loss: 19435.703125\n",
      "Train Epoch: 68 [202368/225000 (90%)] Loss: 20091.398438\n",
      "Train Epoch: 68 [204864/225000 (91%)] Loss: 19946.246094\n",
      "Train Epoch: 68 [207360/225000 (92%)] Loss: 20466.574219\n",
      "Train Epoch: 68 [209856/225000 (93%)] Loss: 19282.121094\n",
      "Train Epoch: 68 [212352/225000 (94%)] Loss: 20173.195312\n",
      "Train Epoch: 68 [214848/225000 (95%)] Loss: 19241.089844\n",
      "Train Epoch: 68 [217344/225000 (97%)] Loss: 19976.625000\n",
      "Train Epoch: 68 [219840/225000 (98%)] Loss: 20096.679688\n",
      "Train Epoch: 68 [222336/225000 (99%)] Loss: 19910.636719\n",
      "Train Epoch: 68 [224832/225000 (100%)] Loss: 19405.941406\n",
      "    epoch          : 68\n",
      "    loss           : 19868.756464310474\n",
      "    val_loss       : 19814.466197080284\n",
      "Train Epoch: 69 [192/225000 (0%)] Loss: 19979.029297\n",
      "Train Epoch: 69 [2688/225000 (1%)] Loss: 19723.562500\n",
      "Train Epoch: 69 [5184/225000 (2%)] Loss: 19942.212891\n",
      "Train Epoch: 69 [7680/225000 (3%)] Loss: 20221.050781\n",
      "Train Epoch: 69 [10176/225000 (5%)] Loss: 19781.181641\n",
      "Train Epoch: 69 [12672/225000 (6%)] Loss: 19863.750000\n",
      "Train Epoch: 69 [15168/225000 (7%)] Loss: 19835.052734\n",
      "Train Epoch: 69 [17664/225000 (8%)] Loss: 19796.613281\n",
      "Train Epoch: 69 [20160/225000 (9%)] Loss: 19617.304688\n",
      "Train Epoch: 69 [22656/225000 (10%)] Loss: 19836.492188\n",
      "Train Epoch: 69 [25152/225000 (11%)] Loss: 19853.121094\n",
      "Train Epoch: 69 [27648/225000 (12%)] Loss: 19973.164062\n",
      "Train Epoch: 69 [30144/225000 (13%)] Loss: 20134.179688\n",
      "Train Epoch: 69 [32640/225000 (15%)] Loss: 19333.449219\n",
      "Train Epoch: 69 [35136/225000 (16%)] Loss: 19458.089844\n",
      "Train Epoch: 69 [37632/225000 (17%)] Loss: 20000.593750\n",
      "Train Epoch: 69 [40128/225000 (18%)] Loss: 19315.523438\n",
      "Train Epoch: 69 [42624/225000 (19%)] Loss: 19855.941406\n",
      "Train Epoch: 69 [45120/225000 (20%)] Loss: 19530.269531\n",
      "Train Epoch: 69 [47616/225000 (21%)] Loss: 20205.679688\n",
      "Train Epoch: 69 [50112/225000 (22%)] Loss: 19926.152344\n",
      "Train Epoch: 69 [52608/225000 (23%)] Loss: 20059.683594\n",
      "Train Epoch: 69 [55104/225000 (24%)] Loss: 19747.248047\n",
      "Train Epoch: 69 [57600/225000 (26%)] Loss: 19873.886719\n",
      "Train Epoch: 69 [60096/225000 (27%)] Loss: 19435.919922\n",
      "Train Epoch: 69 [62592/225000 (28%)] Loss: 19640.791016\n",
      "Train Epoch: 69 [65088/225000 (29%)] Loss: 20110.855469\n",
      "Train Epoch: 69 [67584/225000 (30%)] Loss: 19717.515625\n",
      "Train Epoch: 69 [70080/225000 (31%)] Loss: 19905.693359\n",
      "Train Epoch: 69 [72576/225000 (32%)] Loss: 19577.279297\n",
      "Train Epoch: 69 [75072/225000 (33%)] Loss: 19704.640625\n",
      "Train Epoch: 69 [77568/225000 (34%)] Loss: 20373.699219\n",
      "Train Epoch: 69 [80064/225000 (36%)] Loss: 19481.875000\n",
      "Train Epoch: 69 [82560/225000 (37%)] Loss: 20324.195312\n",
      "Train Epoch: 69 [85056/225000 (38%)] Loss: 19922.214844\n",
      "Train Epoch: 69 [87552/225000 (39%)] Loss: 19923.140625\n",
      "Train Epoch: 69 [90048/225000 (40%)] Loss: 19651.480469\n",
      "Train Epoch: 69 [92544/225000 (41%)] Loss: 20041.042969\n",
      "Train Epoch: 69 [95040/225000 (42%)] Loss: 19504.625000\n",
      "Train Epoch: 69 [97536/225000 (43%)] Loss: 19639.679688\n",
      "Train Epoch: 69 [100032/225000 (44%)] Loss: 19516.410156\n",
      "Train Epoch: 69 [102528/225000 (46%)] Loss: 19793.414062\n",
      "Train Epoch: 69 [105024/225000 (47%)] Loss: 19665.980469\n",
      "Train Epoch: 69 [107520/225000 (48%)] Loss: 20006.123047\n",
      "Train Epoch: 69 [110016/225000 (49%)] Loss: 19952.070312\n",
      "Train Epoch: 69 [112512/225000 (50%)] Loss: 19796.072266\n",
      "Train Epoch: 69 [115008/225000 (51%)] Loss: 19961.167969\n",
      "Train Epoch: 69 [117504/225000 (52%)] Loss: 19624.957031\n",
      "Train Epoch: 69 [120000/225000 (53%)] Loss: 20131.255859\n",
      "Train Epoch: 69 [122496/225000 (54%)] Loss: 20581.371094\n",
      "Train Epoch: 69 [124992/225000 (56%)] Loss: 19509.839844\n",
      "Train Epoch: 69 [127488/225000 (57%)] Loss: 19565.167969\n",
      "Train Epoch: 69 [129984/225000 (58%)] Loss: 20303.822266\n",
      "Train Epoch: 69 [132480/225000 (59%)] Loss: 19377.634766\n",
      "Train Epoch: 69 [134976/225000 (60%)] Loss: 19521.500000\n",
      "Train Epoch: 69 [137472/225000 (61%)] Loss: 20552.382812\n",
      "Train Epoch: 69 [139968/225000 (62%)] Loss: 19950.929688\n",
      "Train Epoch: 69 [142464/225000 (63%)] Loss: 19403.371094\n",
      "Train Epoch: 69 [144960/225000 (64%)] Loss: 20108.927734\n",
      "Train Epoch: 69 [147456/225000 (66%)] Loss: 20122.894531\n",
      "Train Epoch: 69 [149952/225000 (67%)] Loss: 20139.265625\n",
      "Train Epoch: 69 [152448/225000 (68%)] Loss: 20307.710938\n",
      "Train Epoch: 69 [154944/225000 (69%)] Loss: 20345.128906\n",
      "Train Epoch: 69 [157440/225000 (70%)] Loss: 19964.126953\n",
      "Train Epoch: 69 [159936/225000 (71%)] Loss: 20093.156250\n",
      "Train Epoch: 69 [162432/225000 (72%)] Loss: 20012.070312\n",
      "Train Epoch: 69 [164928/225000 (73%)] Loss: 19800.585938\n",
      "Train Epoch: 69 [167424/225000 (74%)] Loss: 19469.109375\n",
      "Train Epoch: 69 [169920/225000 (76%)] Loss: 20287.859375\n",
      "Train Epoch: 69 [172416/225000 (77%)] Loss: 19895.230469\n",
      "Train Epoch: 69 [174912/225000 (78%)] Loss: 20232.191406\n",
      "Train Epoch: 69 [177408/225000 (79%)] Loss: 19542.181641\n",
      "Train Epoch: 69 [179904/225000 (80%)] Loss: 19291.281250\n",
      "Train Epoch: 69 [182400/225000 (81%)] Loss: 19796.582031\n",
      "Train Epoch: 69 [184896/225000 (82%)] Loss: 19558.216797\n",
      "Train Epoch: 69 [187392/225000 (83%)] Loss: 19703.699219\n",
      "Train Epoch: 69 [189888/225000 (84%)] Loss: 20081.644531\n",
      "Train Epoch: 69 [192384/225000 (86%)] Loss: 19761.351562\n",
      "Train Epoch: 69 [194880/225000 (87%)] Loss: 20299.859375\n",
      "Train Epoch: 69 [197376/225000 (88%)] Loss: 20384.570312\n",
      "Train Epoch: 69 [199872/225000 (89%)] Loss: 19804.789062\n",
      "Train Epoch: 69 [202368/225000 (90%)] Loss: 20168.187500\n",
      "Train Epoch: 69 [204864/225000 (91%)] Loss: 20359.910156\n",
      "Train Epoch: 69 [207360/225000 (92%)] Loss: 20124.589844\n",
      "Train Epoch: 69 [209856/225000 (93%)] Loss: 20371.542969\n",
      "Train Epoch: 69 [212352/225000 (94%)] Loss: 19935.281250\n",
      "Train Epoch: 69 [214848/225000 (95%)] Loss: 19829.363281\n",
      "Train Epoch: 69 [217344/225000 (97%)] Loss: 19894.488281\n",
      "Train Epoch: 69 [219840/225000 (98%)] Loss: 19680.164062\n",
      "Train Epoch: 69 [222336/225000 (99%)] Loss: 19296.712891\n",
      "Train Epoch: 69 [224832/225000 (100%)] Loss: 19957.923828\n",
      "    epoch          : 69\n",
      "    loss           : 19863.595639798423\n",
      "    val_loss       : 19794.74078816949\n",
      "Train Epoch: 70 [192/225000 (0%)] Loss: 19407.058594\n",
      "Train Epoch: 70 [2688/225000 (1%)] Loss: 20210.164062\n",
      "Train Epoch: 70 [5184/225000 (2%)] Loss: 19412.878906\n",
      "Train Epoch: 70 [7680/225000 (3%)] Loss: 19764.781250\n",
      "Train Epoch: 70 [10176/225000 (5%)] Loss: 19776.990234\n",
      "Train Epoch: 70 [12672/225000 (6%)] Loss: 19521.710938\n",
      "Train Epoch: 70 [15168/225000 (7%)] Loss: 19955.654297\n",
      "Train Epoch: 70 [17664/225000 (8%)] Loss: 20053.847656\n",
      "Train Epoch: 70 [20160/225000 (9%)] Loss: 19609.941406\n",
      "Train Epoch: 70 [22656/225000 (10%)] Loss: 19762.371094\n",
      "Train Epoch: 70 [25152/225000 (11%)] Loss: 19676.199219\n",
      "Train Epoch: 70 [27648/225000 (12%)] Loss: 19898.154297\n",
      "Train Epoch: 70 [30144/225000 (13%)] Loss: 19811.718750\n",
      "Train Epoch: 70 [32640/225000 (15%)] Loss: 19783.570312\n",
      "Train Epoch: 70 [35136/225000 (16%)] Loss: 19894.296875\n",
      "Train Epoch: 70 [37632/225000 (17%)] Loss: 19515.664062\n",
      "Train Epoch: 70 [40128/225000 (18%)] Loss: 20277.244141\n",
      "Train Epoch: 70 [42624/225000 (19%)] Loss: 19593.906250\n",
      "Train Epoch: 70 [45120/225000 (20%)] Loss: 19943.843750\n",
      "Train Epoch: 70 [47616/225000 (21%)] Loss: 20276.320312\n",
      "Train Epoch: 70 [50112/225000 (22%)] Loss: 20206.425781\n",
      "Train Epoch: 70 [52608/225000 (23%)] Loss: 19686.718750\n",
      "Train Epoch: 70 [55104/225000 (24%)] Loss: 19782.910156\n",
      "Train Epoch: 70 [57600/225000 (26%)] Loss: 19632.439453\n",
      "Train Epoch: 70 [60096/225000 (27%)] Loss: 19608.914062\n",
      "Train Epoch: 70 [62592/225000 (28%)] Loss: 19573.484375\n",
      "Train Epoch: 70 [65088/225000 (29%)] Loss: 20136.478516\n",
      "Train Epoch: 70 [67584/225000 (30%)] Loss: 19517.390625\n",
      "Train Epoch: 70 [70080/225000 (31%)] Loss: 19523.937500\n",
      "Train Epoch: 70 [72576/225000 (32%)] Loss: 20035.357422\n",
      "Train Epoch: 70 [75072/225000 (33%)] Loss: 19370.636719\n",
      "Train Epoch: 70 [77568/225000 (34%)] Loss: 19792.554688\n",
      "Train Epoch: 70 [80064/225000 (36%)] Loss: 19831.464844\n",
      "Train Epoch: 70 [82560/225000 (37%)] Loss: 19357.011719\n",
      "Train Epoch: 70 [85056/225000 (38%)] Loss: 20051.820312\n",
      "Train Epoch: 70 [87552/225000 (39%)] Loss: 19703.109375\n",
      "Train Epoch: 70 [90048/225000 (40%)] Loss: 19833.933594\n",
      "Train Epoch: 70 [92544/225000 (41%)] Loss: 19375.511719\n",
      "Train Epoch: 70 [95040/225000 (42%)] Loss: 19595.707031\n",
      "Train Epoch: 70 [97536/225000 (43%)] Loss: 20043.894531\n",
      "Train Epoch: 70 [100032/225000 (44%)] Loss: 19646.119141\n",
      "Train Epoch: 70 [102528/225000 (46%)] Loss: 19644.917969\n",
      "Train Epoch: 70 [105024/225000 (47%)] Loss: 20030.042969\n",
      "Train Epoch: 70 [107520/225000 (48%)] Loss: 19827.445312\n",
      "Train Epoch: 70 [110016/225000 (49%)] Loss: 19759.179688\n",
      "Train Epoch: 70 [112512/225000 (50%)] Loss: 19816.951172\n",
      "Train Epoch: 70 [115008/225000 (51%)] Loss: 19810.072266\n",
      "Train Epoch: 70 [117504/225000 (52%)] Loss: 20200.316406\n",
      "Train Epoch: 70 [120000/225000 (53%)] Loss: 19936.164062\n",
      "Train Epoch: 70 [122496/225000 (54%)] Loss: 19489.945312\n",
      "Train Epoch: 70 [124992/225000 (56%)] Loss: 19427.011719\n",
      "Train Epoch: 70 [127488/225000 (57%)] Loss: 20091.597656\n",
      "Train Epoch: 70 [129984/225000 (58%)] Loss: 19846.828125\n",
      "Train Epoch: 70 [132480/225000 (59%)] Loss: 19852.310547\n",
      "Train Epoch: 70 [134976/225000 (60%)] Loss: 19503.914062\n",
      "Train Epoch: 70 [137472/225000 (61%)] Loss: 20031.906250\n",
      "Train Epoch: 70 [139968/225000 (62%)] Loss: 19726.556641\n",
      "Train Epoch: 70 [142464/225000 (63%)] Loss: 20020.289062\n",
      "Train Epoch: 70 [144960/225000 (64%)] Loss: 20196.726562\n",
      "Train Epoch: 70 [147456/225000 (66%)] Loss: 19872.257812\n",
      "Train Epoch: 70 [149952/225000 (67%)] Loss: 20264.664062\n",
      "Train Epoch: 70 [152448/225000 (68%)] Loss: 19447.687500\n",
      "Train Epoch: 70 [154944/225000 (69%)] Loss: 19527.269531\n",
      "Train Epoch: 70 [157440/225000 (70%)] Loss: 20097.933594\n",
      "Train Epoch: 70 [159936/225000 (71%)] Loss: 20583.666016\n",
      "Train Epoch: 70 [162432/225000 (72%)] Loss: 19393.367188\n",
      "Train Epoch: 70 [164928/225000 (73%)] Loss: 20220.199219\n",
      "Train Epoch: 70 [167424/225000 (74%)] Loss: 19604.632812\n",
      "Train Epoch: 70 [169920/225000 (76%)] Loss: 19635.763672\n",
      "Train Epoch: 70 [172416/225000 (77%)] Loss: 19855.507812\n",
      "Train Epoch: 70 [174912/225000 (78%)] Loss: 19722.556641\n",
      "Train Epoch: 70 [177408/225000 (79%)] Loss: 19278.939453\n",
      "Train Epoch: 70 [179904/225000 (80%)] Loss: 19883.283203\n",
      "Train Epoch: 70 [182400/225000 (81%)] Loss: 19310.160156\n",
      "Train Epoch: 70 [184896/225000 (82%)] Loss: 20142.476562\n",
      "Train Epoch: 70 [187392/225000 (83%)] Loss: 19971.212891\n",
      "Train Epoch: 70 [189888/225000 (84%)] Loss: 19856.570312\n",
      "Train Epoch: 70 [192384/225000 (86%)] Loss: 19664.445312\n",
      "Train Epoch: 70 [194880/225000 (87%)] Loss: 20153.763672\n",
      "Train Epoch: 70 [197376/225000 (88%)] Loss: 19505.087891\n",
      "Train Epoch: 70 [199872/225000 (89%)] Loss: 19680.191406\n",
      "Train Epoch: 70 [202368/225000 (90%)] Loss: 19796.117188\n",
      "Train Epoch: 70 [204864/225000 (91%)] Loss: 20004.171875\n",
      "Train Epoch: 70 [207360/225000 (92%)] Loss: 19430.347656\n",
      "Train Epoch: 70 [209856/225000 (93%)] Loss: 20098.550781\n",
      "Train Epoch: 70 [212352/225000 (94%)] Loss: 19781.328125\n",
      "Train Epoch: 70 [214848/225000 (95%)] Loss: 20266.882812\n",
      "Train Epoch: 70 [217344/225000 (97%)] Loss: 19733.572266\n",
      "Train Epoch: 70 [219840/225000 (98%)] Loss: 20312.269531\n",
      "Train Epoch: 70 [222336/225000 (99%)] Loss: 19855.835938\n",
      "Train Epoch: 70 [224832/225000 (100%)] Loss: 19253.039062\n",
      "    epoch          : 70\n",
      "    loss           : 19823.96403383639\n",
      "    val_loss       : 19728.806258915945\n",
      "Train Epoch: 71 [192/225000 (0%)] Loss: 19855.417969\n",
      "Train Epoch: 71 [2688/225000 (1%)] Loss: 19978.226562\n",
      "Train Epoch: 71 [5184/225000 (2%)] Loss: 19910.894531\n",
      "Train Epoch: 71 [7680/225000 (3%)] Loss: 19901.382812\n",
      "Train Epoch: 71 [10176/225000 (5%)] Loss: 19985.025391\n",
      "Train Epoch: 71 [12672/225000 (6%)] Loss: 19615.101562\n",
      "Train Epoch: 71 [15168/225000 (7%)] Loss: 19933.773438\n",
      "Train Epoch: 71 [17664/225000 (8%)] Loss: 19980.363281\n",
      "Train Epoch: 71 [20160/225000 (9%)] Loss: 19652.785156\n",
      "Train Epoch: 71 [22656/225000 (10%)] Loss: 19873.351562\n",
      "Train Epoch: 71 [25152/225000 (11%)] Loss: 19789.365234\n",
      "Train Epoch: 71 [27648/225000 (12%)] Loss: 19468.500000\n",
      "Train Epoch: 71 [30144/225000 (13%)] Loss: 19240.648438\n",
      "Train Epoch: 71 [32640/225000 (15%)] Loss: 20043.828125\n",
      "Train Epoch: 71 [35136/225000 (16%)] Loss: 19719.097656\n",
      "Train Epoch: 71 [37632/225000 (17%)] Loss: 19795.093750\n",
      "Train Epoch: 71 [40128/225000 (18%)] Loss: 20045.269531\n",
      "Train Epoch: 71 [42624/225000 (19%)] Loss: 19746.878906\n",
      "Train Epoch: 71 [45120/225000 (20%)] Loss: 19670.496094\n",
      "Train Epoch: 71 [47616/225000 (21%)] Loss: 19922.638672\n",
      "Train Epoch: 71 [50112/225000 (22%)] Loss: 19865.968750\n",
      "Train Epoch: 71 [52608/225000 (23%)] Loss: 19433.375000\n",
      "Train Epoch: 71 [55104/225000 (24%)] Loss: 19912.671875\n",
      "Train Epoch: 71 [57600/225000 (26%)] Loss: 20039.199219\n",
      "Train Epoch: 71 [60096/225000 (27%)] Loss: 19932.755859\n",
      "Train Epoch: 71 [62592/225000 (28%)] Loss: 20369.582031\n",
      "Train Epoch: 71 [65088/225000 (29%)] Loss: 19576.226562\n",
      "Train Epoch: 71 [67584/225000 (30%)] Loss: 19653.800781\n",
      "Train Epoch: 71 [70080/225000 (31%)] Loss: 19966.515625\n",
      "Train Epoch: 71 [72576/225000 (32%)] Loss: 19574.578125\n",
      "Train Epoch: 71 [75072/225000 (33%)] Loss: 20046.902344\n",
      "Train Epoch: 71 [77568/225000 (34%)] Loss: 19900.109375\n",
      "Train Epoch: 71 [80064/225000 (36%)] Loss: 19810.427734\n",
      "Train Epoch: 71 [82560/225000 (37%)] Loss: 19923.984375\n",
      "Train Epoch: 71 [85056/225000 (38%)] Loss: 19719.320312\n",
      "Train Epoch: 71 [87552/225000 (39%)] Loss: 20111.230469\n",
      "Train Epoch: 71 [90048/225000 (40%)] Loss: 19740.289062\n",
      "Train Epoch: 71 [92544/225000 (41%)] Loss: 20041.375000\n",
      "Train Epoch: 71 [95040/225000 (42%)] Loss: 19856.941406\n",
      "Train Epoch: 71 [97536/225000 (43%)] Loss: 19989.044922\n",
      "Train Epoch: 71 [100032/225000 (44%)] Loss: 19915.257812\n",
      "Train Epoch: 71 [102528/225000 (46%)] Loss: 20048.894531\n",
      "Train Epoch: 71 [105024/225000 (47%)] Loss: 20455.277344\n",
      "Train Epoch: 71 [107520/225000 (48%)] Loss: 19609.734375\n",
      "Train Epoch: 71 [110016/225000 (49%)] Loss: 19616.875000\n",
      "Train Epoch: 71 [112512/225000 (50%)] Loss: 19774.482422\n",
      "Train Epoch: 71 [115008/225000 (51%)] Loss: 20285.511719\n",
      "Train Epoch: 71 [117504/225000 (52%)] Loss: 19096.910156\n",
      "Train Epoch: 71 [120000/225000 (53%)] Loss: 19492.511719\n",
      "Train Epoch: 71 [122496/225000 (54%)] Loss: 20008.433594\n",
      "Train Epoch: 71 [124992/225000 (56%)] Loss: 20087.269531\n",
      "Train Epoch: 71 [127488/225000 (57%)] Loss: 19676.203125\n",
      "Train Epoch: 71 [129984/225000 (58%)] Loss: 19606.351562\n",
      "Train Epoch: 71 [132480/225000 (59%)] Loss: 20085.792969\n",
      "Train Epoch: 71 [134976/225000 (60%)] Loss: 19721.253906\n",
      "Train Epoch: 71 [137472/225000 (61%)] Loss: 19845.519531\n",
      "Train Epoch: 71 [139968/225000 (62%)] Loss: 19319.494141\n",
      "Train Epoch: 71 [142464/225000 (63%)] Loss: 19937.009766\n",
      "Train Epoch: 71 [144960/225000 (64%)] Loss: 19741.974609\n",
      "Train Epoch: 71 [147456/225000 (66%)] Loss: 20098.890625\n",
      "Train Epoch: 71 [149952/225000 (67%)] Loss: 19577.482422\n",
      "Train Epoch: 71 [152448/225000 (68%)] Loss: 19645.679688\n",
      "Train Epoch: 71 [154944/225000 (69%)] Loss: 19565.929688\n",
      "Train Epoch: 71 [157440/225000 (70%)] Loss: 19983.089844\n",
      "Train Epoch: 71 [159936/225000 (71%)] Loss: 19908.105469\n",
      "Train Epoch: 71 [162432/225000 (72%)] Loss: 19816.375000\n",
      "Train Epoch: 71 [164928/225000 (73%)] Loss: 20051.453125\n",
      "Train Epoch: 71 [167424/225000 (74%)] Loss: 19518.121094\n",
      "Train Epoch: 71 [169920/225000 (76%)] Loss: 19694.427734\n",
      "Train Epoch: 71 [172416/225000 (77%)] Loss: 19854.457031\n",
      "Train Epoch: 71 [174912/225000 (78%)] Loss: 19751.750000\n",
      "Train Epoch: 71 [177408/225000 (79%)] Loss: 19873.269531\n",
      "Train Epoch: 71 [179904/225000 (80%)] Loss: 19726.500000\n",
      "Train Epoch: 71 [182400/225000 (81%)] Loss: 20042.925781\n",
      "Train Epoch: 71 [184896/225000 (82%)] Loss: 20067.792969\n",
      "Train Epoch: 71 [187392/225000 (83%)] Loss: 19892.419922\n",
      "Train Epoch: 71 [189888/225000 (84%)] Loss: 19786.105469\n",
      "Train Epoch: 71 [192384/225000 (86%)] Loss: 19930.222656\n",
      "Train Epoch: 71 [194880/225000 (87%)] Loss: 19464.679688\n",
      "Train Epoch: 71 [197376/225000 (88%)] Loss: 19698.529297\n",
      "Train Epoch: 71 [199872/225000 (89%)] Loss: 20159.333984\n",
      "Train Epoch: 71 [202368/225000 (90%)] Loss: 19829.011719\n",
      "Train Epoch: 71 [204864/225000 (91%)] Loss: 19995.023438\n",
      "Train Epoch: 71 [207360/225000 (92%)] Loss: 19895.267578\n",
      "Train Epoch: 71 [209856/225000 (93%)] Loss: 19886.277344\n",
      "Train Epoch: 71 [212352/225000 (94%)] Loss: 19901.285156\n",
      "Train Epoch: 71 [214848/225000 (95%)] Loss: 19737.746094\n",
      "Train Epoch: 71 [217344/225000 (97%)] Loss: 19590.937500\n",
      "Train Epoch: 71 [219840/225000 (98%)] Loss: 19932.251953\n",
      "Train Epoch: 71 [222336/225000 (99%)] Loss: 19482.234375\n",
      "Train Epoch: 71 [224832/225000 (100%)] Loss: 19610.576172\n",
      "    epoch          : 71\n",
      "    loss           : 19818.267603122335\n",
      "    val_loss       : 19747.62282515482\n",
      "Train Epoch: 72 [192/225000 (0%)] Loss: 19408.769531\n",
      "Train Epoch: 72 [2688/225000 (1%)] Loss: 19632.689453\n",
      "Train Epoch: 72 [5184/225000 (2%)] Loss: 20048.457031\n",
      "Train Epoch: 72 [7680/225000 (3%)] Loss: 19990.982422\n",
      "Train Epoch: 72 [10176/225000 (5%)] Loss: 19581.173828\n",
      "Train Epoch: 72 [12672/225000 (6%)] Loss: 20442.800781\n",
      "Train Epoch: 72 [15168/225000 (7%)] Loss: 19243.503906\n",
      "Train Epoch: 72 [17664/225000 (8%)] Loss: 19672.916016\n",
      "Train Epoch: 72 [20160/225000 (9%)] Loss: 20023.507812\n",
      "Train Epoch: 72 [22656/225000 (10%)] Loss: 19700.980469\n",
      "Train Epoch: 72 [25152/225000 (11%)] Loss: 19966.703125\n",
      "Train Epoch: 72 [27648/225000 (12%)] Loss: 19669.687500\n",
      "Train Epoch: 72 [30144/225000 (13%)] Loss: 19758.359375\n",
      "Train Epoch: 72 [32640/225000 (15%)] Loss: 19648.017578\n",
      "Train Epoch: 72 [35136/225000 (16%)] Loss: 19851.787109\n",
      "Train Epoch: 72 [37632/225000 (17%)] Loss: 20142.597656\n",
      "Train Epoch: 72 [40128/225000 (18%)] Loss: 19649.791016\n",
      "Train Epoch: 72 [42624/225000 (19%)] Loss: 19721.988281\n",
      "Train Epoch: 72 [45120/225000 (20%)] Loss: 19577.746094\n",
      "Train Epoch: 72 [47616/225000 (21%)] Loss: 19484.294922\n",
      "Train Epoch: 72 [50112/225000 (22%)] Loss: 20273.986328\n",
      "Train Epoch: 72 [52608/225000 (23%)] Loss: 19555.910156\n",
      "Train Epoch: 72 [55104/225000 (24%)] Loss: 19553.201172\n",
      "Train Epoch: 72 [57600/225000 (26%)] Loss: 19322.828125\n",
      "Train Epoch: 72 [60096/225000 (27%)] Loss: 19417.238281\n",
      "Train Epoch: 72 [62592/225000 (28%)] Loss: 19526.720703\n",
      "Train Epoch: 72 [65088/225000 (29%)] Loss: 19849.238281\n",
      "Train Epoch: 72 [67584/225000 (30%)] Loss: 19605.804688\n",
      "Train Epoch: 72 [70080/225000 (31%)] Loss: 20150.812500\n",
      "Train Epoch: 72 [72576/225000 (32%)] Loss: 19149.039062\n",
      "Train Epoch: 72 [75072/225000 (33%)] Loss: 20033.693359\n",
      "Train Epoch: 72 [77568/225000 (34%)] Loss: 19545.390625\n",
      "Train Epoch: 72 [80064/225000 (36%)] Loss: 19731.744141\n",
      "Train Epoch: 72 [82560/225000 (37%)] Loss: 20050.042969\n",
      "Train Epoch: 72 [85056/225000 (38%)] Loss: 19727.167969\n",
      "Train Epoch: 72 [87552/225000 (39%)] Loss: 19548.906250\n",
      "Train Epoch: 72 [90048/225000 (40%)] Loss: 19788.679688\n",
      "Train Epoch: 72 [92544/225000 (41%)] Loss: 19886.478516\n",
      "Train Epoch: 72 [95040/225000 (42%)] Loss: 20242.287109\n",
      "Train Epoch: 72 [97536/225000 (43%)] Loss: 19932.328125\n",
      "Train Epoch: 72 [100032/225000 (44%)] Loss: 19971.488281\n",
      "Train Epoch: 72 [102528/225000 (46%)] Loss: 19652.007812\n",
      "Train Epoch: 72 [105024/225000 (47%)] Loss: 19889.101562\n",
      "Train Epoch: 72 [107520/225000 (48%)] Loss: 19839.207031\n",
      "Train Epoch: 72 [110016/225000 (49%)] Loss: 19687.230469\n",
      "Train Epoch: 72 [112512/225000 (50%)] Loss: 19360.960938\n",
      "Train Epoch: 72 [115008/225000 (51%)] Loss: 19605.511719\n",
      "Train Epoch: 72 [117504/225000 (52%)] Loss: 19891.044922\n",
      "Train Epoch: 72 [120000/225000 (53%)] Loss: 19746.363281\n",
      "Train Epoch: 72 [122496/225000 (54%)] Loss: 19808.283203\n",
      "Train Epoch: 72 [124992/225000 (56%)] Loss: 19765.320312\n",
      "Train Epoch: 72 [127488/225000 (57%)] Loss: 19539.916016\n",
      "Train Epoch: 72 [129984/225000 (58%)] Loss: 19888.679688\n",
      "Train Epoch: 72 [132480/225000 (59%)] Loss: 19615.164062\n",
      "Train Epoch: 72 [134976/225000 (60%)] Loss: 19959.488281\n",
      "Train Epoch: 72 [137472/225000 (61%)] Loss: 19930.281250\n",
      "Train Epoch: 72 [139968/225000 (62%)] Loss: 19922.519531\n",
      "Train Epoch: 72 [142464/225000 (63%)] Loss: 19780.320312\n",
      "Train Epoch: 72 [144960/225000 (64%)] Loss: 19964.742188\n",
      "Train Epoch: 72 [147456/225000 (66%)] Loss: 19894.158203\n",
      "Train Epoch: 72 [149952/225000 (67%)] Loss: 19861.349609\n",
      "Train Epoch: 72 [152448/225000 (68%)] Loss: 19597.933594\n",
      "Train Epoch: 72 [154944/225000 (69%)] Loss: 19568.441406\n",
      "Train Epoch: 72 [157440/225000 (70%)] Loss: 19378.257812\n",
      "Train Epoch: 72 [159936/225000 (71%)] Loss: 20215.175781\n",
      "Train Epoch: 72 [162432/225000 (72%)] Loss: 19884.685547\n",
      "Train Epoch: 72 [164928/225000 (73%)] Loss: 19512.748047\n",
      "Train Epoch: 72 [167424/225000 (74%)] Loss: 19836.687500\n",
      "Train Epoch: 72 [169920/225000 (76%)] Loss: 20076.449219\n",
      "Train Epoch: 72 [172416/225000 (77%)] Loss: 19860.210938\n",
      "Train Epoch: 72 [174912/225000 (78%)] Loss: 19709.312500\n",
      "Train Epoch: 72 [177408/225000 (79%)] Loss: 19764.121094\n",
      "Train Epoch: 72 [179904/225000 (80%)] Loss: 19905.376953\n",
      "Train Epoch: 72 [182400/225000 (81%)] Loss: 19759.654297\n",
      "Train Epoch: 72 [184896/225000 (82%)] Loss: 19971.007812\n",
      "Train Epoch: 72 [187392/225000 (83%)] Loss: 19409.613281\n",
      "Train Epoch: 72 [189888/225000 (84%)] Loss: 20164.136719\n",
      "Train Epoch: 72 [192384/225000 (86%)] Loss: 20234.406250\n",
      "Train Epoch: 72 [194880/225000 (87%)] Loss: 20007.513672\n",
      "Train Epoch: 72 [197376/225000 (88%)] Loss: 19395.984375\n",
      "Train Epoch: 72 [199872/225000 (89%)] Loss: 20553.125000\n",
      "Train Epoch: 72 [202368/225000 (90%)] Loss: 19759.156250\n",
      "Train Epoch: 72 [204864/225000 (91%)] Loss: 19909.443359\n",
      "Train Epoch: 72 [207360/225000 (92%)] Loss: 19467.808594\n",
      "Train Epoch: 72 [209856/225000 (93%)] Loss: 19690.894531\n",
      "Train Epoch: 72 [212352/225000 (94%)] Loss: 19718.126953\n",
      "Train Epoch: 72 [214848/225000 (95%)] Loss: 19894.531250\n",
      "Train Epoch: 72 [217344/225000 (97%)] Loss: 19815.949219\n",
      "Train Epoch: 72 [219840/225000 (98%)] Loss: 19590.222656\n",
      "Train Epoch: 72 [222336/225000 (99%)] Loss: 19473.220703\n",
      "Train Epoch: 72 [224832/225000 (100%)] Loss: 19419.535156\n",
      "    epoch          : 72\n",
      "    loss           : 19786.9757509199\n",
      "    val_loss       : 19698.377766461774\n",
      "Train Epoch: 73 [192/225000 (0%)] Loss: 19862.748047\n",
      "Train Epoch: 73 [2688/225000 (1%)] Loss: 20092.755859\n",
      "Train Epoch: 73 [5184/225000 (2%)] Loss: 20254.632812\n",
      "Train Epoch: 73 [7680/225000 (3%)] Loss: 19891.988281\n",
      "Train Epoch: 73 [10176/225000 (5%)] Loss: 19699.617188\n",
      "Train Epoch: 73 [12672/225000 (6%)] Loss: 19739.289062\n",
      "Train Epoch: 73 [15168/225000 (7%)] Loss: 20134.792969\n",
      "Train Epoch: 73 [17664/225000 (8%)] Loss: 20035.238281\n",
      "Train Epoch: 73 [20160/225000 (9%)] Loss: 19411.687500\n",
      "Train Epoch: 73 [22656/225000 (10%)] Loss: 19727.625000\n",
      "Train Epoch: 73 [25152/225000 (11%)] Loss: 19879.003906\n",
      "Train Epoch: 73 [27648/225000 (12%)] Loss: 20125.382812\n",
      "Train Epoch: 73 [30144/225000 (13%)] Loss: 20418.968750\n",
      "Train Epoch: 73 [32640/225000 (15%)] Loss: 20044.917969\n",
      "Train Epoch: 73 [35136/225000 (16%)] Loss: 20041.843750\n",
      "Train Epoch: 73 [37632/225000 (17%)] Loss: 19791.994141\n",
      "Train Epoch: 73 [40128/225000 (18%)] Loss: 19614.800781\n",
      "Train Epoch: 73 [42624/225000 (19%)] Loss: 19642.019531\n",
      "Train Epoch: 73 [45120/225000 (20%)] Loss: 19691.132812\n",
      "Train Epoch: 73 [47616/225000 (21%)] Loss: 19747.859375\n",
      "Train Epoch: 73 [50112/225000 (22%)] Loss: 19571.226562\n",
      "Train Epoch: 73 [52608/225000 (23%)] Loss: 19855.226562\n",
      "Train Epoch: 73 [55104/225000 (24%)] Loss: 19779.707031\n",
      "Train Epoch: 73 [57600/225000 (26%)] Loss: 19680.582031\n",
      "Train Epoch: 73 [60096/225000 (27%)] Loss: 20049.806641\n",
      "Train Epoch: 73 [62592/225000 (28%)] Loss: 19522.824219\n",
      "Train Epoch: 73 [65088/225000 (29%)] Loss: 20280.787109\n",
      "Train Epoch: 73 [67584/225000 (30%)] Loss: 19705.593750\n",
      "Train Epoch: 73 [70080/225000 (31%)] Loss: 19669.933594\n",
      "Train Epoch: 73 [72576/225000 (32%)] Loss: 19891.804688\n",
      "Train Epoch: 73 [75072/225000 (33%)] Loss: 19714.861328\n",
      "Train Epoch: 73 [77568/225000 (34%)] Loss: 20111.191406\n",
      "Train Epoch: 73 [80064/225000 (36%)] Loss: 20193.261719\n",
      "Train Epoch: 73 [82560/225000 (37%)] Loss: 19843.019531\n",
      "Train Epoch: 73 [85056/225000 (38%)] Loss: 19807.062500\n",
      "Train Epoch: 73 [87552/225000 (39%)] Loss: 20120.097656\n",
      "Train Epoch: 73 [90048/225000 (40%)] Loss: 19453.710938\n",
      "Train Epoch: 73 [92544/225000 (41%)] Loss: 19358.257812\n",
      "Train Epoch: 73 [95040/225000 (42%)] Loss: 19506.070312\n",
      "Train Epoch: 73 [97536/225000 (43%)] Loss: 20242.226562\n",
      "Train Epoch: 73 [100032/225000 (44%)] Loss: 20126.218750\n",
      "Train Epoch: 73 [102528/225000 (46%)] Loss: 19865.617188\n",
      "Train Epoch: 73 [105024/225000 (47%)] Loss: 19796.498047\n",
      "Train Epoch: 73 [107520/225000 (48%)] Loss: 19847.539062\n",
      "Train Epoch: 73 [110016/225000 (49%)] Loss: 19965.589844\n",
      "Train Epoch: 73 [112512/225000 (50%)] Loss: 19602.435547\n",
      "Train Epoch: 73 [115008/225000 (51%)] Loss: 19860.820312\n",
      "Train Epoch: 73 [117504/225000 (52%)] Loss: 19680.701172\n",
      "Train Epoch: 73 [120000/225000 (53%)] Loss: 19591.230469\n",
      "Train Epoch: 73 [122496/225000 (54%)] Loss: 19565.226562\n",
      "Train Epoch: 73 [124992/225000 (56%)] Loss: 19834.386719\n",
      "Train Epoch: 73 [127488/225000 (57%)] Loss: 19490.164062\n",
      "Train Epoch: 73 [129984/225000 (58%)] Loss: 19234.031250\n",
      "Train Epoch: 73 [132480/225000 (59%)] Loss: 19998.527344\n",
      "Train Epoch: 73 [134976/225000 (60%)] Loss: 19324.136719\n",
      "Train Epoch: 73 [137472/225000 (61%)] Loss: 20141.046875\n",
      "Train Epoch: 73 [139968/225000 (62%)] Loss: 19490.042969\n",
      "Train Epoch: 73 [142464/225000 (63%)] Loss: 19916.027344\n",
      "Train Epoch: 73 [144960/225000 (64%)] Loss: 19690.753906\n",
      "Train Epoch: 73 [147456/225000 (66%)] Loss: 19744.855469\n",
      "Train Epoch: 73 [149952/225000 (67%)] Loss: 19782.587891\n",
      "Train Epoch: 73 [152448/225000 (68%)] Loss: 19809.941406\n",
      "Train Epoch: 73 [154944/225000 (69%)] Loss: 19685.193359\n",
      "Train Epoch: 73 [157440/225000 (70%)] Loss: 19739.421875\n",
      "Train Epoch: 73 [159936/225000 (71%)] Loss: 19739.851562\n",
      "Train Epoch: 73 [162432/225000 (72%)] Loss: 19483.054688\n",
      "Train Epoch: 73 [164928/225000 (73%)] Loss: 19471.945312\n",
      "Train Epoch: 73 [167424/225000 (74%)] Loss: 19455.582031\n",
      "Train Epoch: 73 [169920/225000 (76%)] Loss: 19711.248047\n",
      "Train Epoch: 73 [172416/225000 (77%)] Loss: 19260.357422\n",
      "Train Epoch: 73 [174912/225000 (78%)] Loss: 19725.039062\n",
      "Train Epoch: 73 [177408/225000 (79%)] Loss: 20080.556641\n",
      "Train Epoch: 73 [179904/225000 (80%)] Loss: 19663.914062\n",
      "Train Epoch: 73 [182400/225000 (81%)] Loss: 19922.734375\n",
      "Train Epoch: 73 [184896/225000 (82%)] Loss: 19443.144531\n",
      "Train Epoch: 73 [187392/225000 (83%)] Loss: 19861.263672\n",
      "Train Epoch: 73 [189888/225000 (84%)] Loss: 19847.347656\n",
      "Train Epoch: 73 [192384/225000 (86%)] Loss: 19828.601562\n",
      "Train Epoch: 73 [194880/225000 (87%)] Loss: 19890.798828\n",
      "Train Epoch: 73 [197376/225000 (88%)] Loss: 19974.378906\n",
      "Train Epoch: 73 [199872/225000 (89%)] Loss: 19772.533203\n",
      "Train Epoch: 73 [202368/225000 (90%)] Loss: 20162.726562\n",
      "Train Epoch: 73 [204864/225000 (91%)] Loss: 19848.673828\n",
      "Train Epoch: 73 [207360/225000 (92%)] Loss: 19646.195312\n",
      "Train Epoch: 73 [209856/225000 (93%)] Loss: 19926.189453\n",
      "Train Epoch: 73 [212352/225000 (94%)] Loss: 20211.429688\n",
      "Train Epoch: 73 [214848/225000 (95%)] Loss: 19590.203125\n",
      "Train Epoch: 73 [217344/225000 (97%)] Loss: 19896.837891\n",
      "Train Epoch: 73 [219840/225000 (98%)] Loss: 19868.220703\n",
      "Train Epoch: 73 [222336/225000 (99%)] Loss: 19601.742188\n",
      "Train Epoch: 73 [224832/225000 (100%)] Loss: 19620.382812\n",
      "    epoch          : 73\n",
      "    loss           : 19767.37610154917\n",
      "    val_loss       : 19668.679984868028\n",
      "Train Epoch: 74 [192/225000 (0%)] Loss: 19516.175781\n",
      "Train Epoch: 74 [2688/225000 (1%)] Loss: 19896.027344\n",
      "Train Epoch: 74 [5184/225000 (2%)] Loss: 19978.062500\n",
      "Train Epoch: 74 [7680/225000 (3%)] Loss: 19431.546875\n",
      "Train Epoch: 74 [10176/225000 (5%)] Loss: 19736.773438\n",
      "Train Epoch: 74 [12672/225000 (6%)] Loss: 19094.613281\n",
      "Train Epoch: 74 [15168/225000 (7%)] Loss: 19467.003906\n",
      "Train Epoch: 74 [17664/225000 (8%)] Loss: 19359.503906\n",
      "Train Epoch: 74 [20160/225000 (9%)] Loss: 20234.261719\n",
      "Train Epoch: 74 [22656/225000 (10%)] Loss: 19839.441406\n",
      "Train Epoch: 74 [25152/225000 (11%)] Loss: 20064.320312\n",
      "Train Epoch: 74 [27648/225000 (12%)] Loss: 19626.324219\n",
      "Train Epoch: 74 [30144/225000 (13%)] Loss: 19820.816406\n",
      "Train Epoch: 74 [32640/225000 (15%)] Loss: 19509.761719\n",
      "Train Epoch: 74 [35136/225000 (16%)] Loss: 19409.414062\n",
      "Train Epoch: 74 [37632/225000 (17%)] Loss: 19725.853516\n",
      "Train Epoch: 74 [40128/225000 (18%)] Loss: 19592.039062\n",
      "Train Epoch: 74 [42624/225000 (19%)] Loss: 19827.617188\n",
      "Train Epoch: 74 [45120/225000 (20%)] Loss: 19681.464844\n",
      "Train Epoch: 74 [47616/225000 (21%)] Loss: 19739.753906\n",
      "Train Epoch: 74 [50112/225000 (22%)] Loss: 19447.322266\n",
      "Train Epoch: 74 [52608/225000 (23%)] Loss: 19532.808594\n",
      "Train Epoch: 74 [55104/225000 (24%)] Loss: 19586.113281\n",
      "Train Epoch: 74 [57600/225000 (26%)] Loss: 20143.708984\n",
      "Train Epoch: 74 [60096/225000 (27%)] Loss: 19671.960938\n",
      "Train Epoch: 74 [62592/225000 (28%)] Loss: 19565.027344\n",
      "Train Epoch: 74 [65088/225000 (29%)] Loss: 19364.246094\n",
      "Train Epoch: 74 [67584/225000 (30%)] Loss: 19965.021484\n",
      "Train Epoch: 74 [70080/225000 (31%)] Loss: 20016.775391\n",
      "Train Epoch: 74 [72576/225000 (32%)] Loss: 19824.326172\n",
      "Train Epoch: 74 [75072/225000 (33%)] Loss: 19632.666016\n",
      "Train Epoch: 74 [77568/225000 (34%)] Loss: 20139.283203\n",
      "Train Epoch: 74 [80064/225000 (36%)] Loss: 19431.048828\n",
      "Train Epoch: 74 [82560/225000 (37%)] Loss: 19807.958984\n",
      "Train Epoch: 74 [85056/225000 (38%)] Loss: 19344.369141\n",
      "Train Epoch: 74 [87552/225000 (39%)] Loss: 19293.433594\n",
      "Train Epoch: 74 [90048/225000 (40%)] Loss: 19712.964844\n",
      "Train Epoch: 74 [92544/225000 (41%)] Loss: 19580.886719\n",
      "Train Epoch: 74 [95040/225000 (42%)] Loss: 19571.339844\n",
      "Train Epoch: 74 [97536/225000 (43%)] Loss: 19379.189453\n",
      "Train Epoch: 74 [100032/225000 (44%)] Loss: 19749.261719\n",
      "Train Epoch: 74 [102528/225000 (46%)] Loss: 19540.648438\n",
      "Train Epoch: 74 [105024/225000 (47%)] Loss: 19461.792969\n",
      "Train Epoch: 74 [107520/225000 (48%)] Loss: 19675.675781\n",
      "Train Epoch: 74 [110016/225000 (49%)] Loss: 19602.775391\n",
      "Train Epoch: 74 [112512/225000 (50%)] Loss: 19957.660156\n",
      "Train Epoch: 74 [115008/225000 (51%)] Loss: 19504.707031\n",
      "Train Epoch: 74 [117504/225000 (52%)] Loss: 19710.216797\n",
      "Train Epoch: 74 [120000/225000 (53%)] Loss: 19636.179688\n",
      "Train Epoch: 74 [122496/225000 (54%)] Loss: 19487.828125\n",
      "Train Epoch: 74 [124992/225000 (56%)] Loss: 19687.566406\n",
      "Train Epoch: 74 [127488/225000 (57%)] Loss: 20129.830078\n",
      "Train Epoch: 74 [129984/225000 (58%)] Loss: 19839.519531\n",
      "Train Epoch: 74 [132480/225000 (59%)] Loss: 19705.187500\n",
      "Train Epoch: 74 [134976/225000 (60%)] Loss: 19854.734375\n",
      "Train Epoch: 74 [137472/225000 (61%)] Loss: 19523.732422\n",
      "Train Epoch: 74 [139968/225000 (62%)] Loss: 20019.335938\n",
      "Train Epoch: 74 [142464/225000 (63%)] Loss: 19532.123047\n",
      "Train Epoch: 74 [144960/225000 (64%)] Loss: 19635.917969\n",
      "Train Epoch: 74 [147456/225000 (66%)] Loss: 19889.250000\n",
      "Train Epoch: 74 [149952/225000 (67%)] Loss: 20049.998047\n",
      "Train Epoch: 74 [152448/225000 (68%)] Loss: 19461.804688\n",
      "Train Epoch: 74 [154944/225000 (69%)] Loss: 19595.546875\n",
      "Train Epoch: 74 [157440/225000 (70%)] Loss: 19794.501953\n",
      "Train Epoch: 74 [159936/225000 (71%)] Loss: 20221.791016\n",
      "Train Epoch: 74 [162432/225000 (72%)] Loss: 20034.626953\n",
      "Train Epoch: 74 [164928/225000 (73%)] Loss: 19679.230469\n",
      "Train Epoch: 74 [167424/225000 (74%)] Loss: 19730.880859\n",
      "Train Epoch: 74 [169920/225000 (76%)] Loss: 20334.082031\n",
      "Train Epoch: 74 [172416/225000 (77%)] Loss: 19361.410156\n",
      "Train Epoch: 74 [174912/225000 (78%)] Loss: 19865.791016\n",
      "Train Epoch: 74 [177408/225000 (79%)] Loss: 19807.382812\n",
      "Train Epoch: 74 [179904/225000 (80%)] Loss: 20218.261719\n",
      "Train Epoch: 74 [182400/225000 (81%)] Loss: 19572.503906\n",
      "Train Epoch: 74 [184896/225000 (82%)] Loss: 19497.300781\n",
      "Train Epoch: 74 [187392/225000 (83%)] Loss: 20158.996094\n",
      "Train Epoch: 74 [189888/225000 (84%)] Loss: 20020.587891\n",
      "Train Epoch: 74 [192384/225000 (86%)] Loss: 19988.505859\n",
      "Train Epoch: 74 [194880/225000 (87%)] Loss: 19992.580078\n",
      "Train Epoch: 74 [197376/225000 (88%)] Loss: 19765.585938\n",
      "Train Epoch: 74 [199872/225000 (89%)] Loss: 19800.181641\n",
      "Train Epoch: 74 [202368/225000 (90%)] Loss: 19433.824219\n",
      "Train Epoch: 74 [204864/225000 (91%)] Loss: 19721.980469\n",
      "Train Epoch: 74 [207360/225000 (92%)] Loss: 19264.333984\n",
      "Train Epoch: 74 [209856/225000 (93%)] Loss: 19529.457031\n",
      "Train Epoch: 74 [212352/225000 (94%)] Loss: 19906.248047\n",
      "Train Epoch: 74 [214848/225000 (95%)] Loss: 19126.500000\n",
      "Train Epoch: 74 [217344/225000 (97%)] Loss: 19471.970703\n",
      "Train Epoch: 74 [219840/225000 (98%)] Loss: 19756.441406\n",
      "Train Epoch: 74 [222336/225000 (99%)] Loss: 19955.537109\n",
      "Train Epoch: 74 [224832/225000 (100%)] Loss: 19887.843750\n",
      "    epoch          : 74\n",
      "    loss           : 19755.92770104522\n",
      "    val_loss       : 19744.568580573752\n",
      "Train Epoch: 75 [192/225000 (0%)] Loss: 20053.093750\n",
      "Train Epoch: 75 [2688/225000 (1%)] Loss: 19755.433594\n",
      "Train Epoch: 75 [5184/225000 (2%)] Loss: 20012.753906\n",
      "Train Epoch: 75 [7680/225000 (3%)] Loss: 19344.423828\n",
      "Train Epoch: 75 [10176/225000 (5%)] Loss: 19535.912109\n",
      "Train Epoch: 75 [12672/225000 (6%)] Loss: 19846.433594\n",
      "Train Epoch: 75 [15168/225000 (7%)] Loss: 19919.916016\n",
      "Train Epoch: 75 [17664/225000 (8%)] Loss: 19675.574219\n",
      "Train Epoch: 75 [20160/225000 (9%)] Loss: 19409.998047\n",
      "Train Epoch: 75 [22656/225000 (10%)] Loss: 19622.660156\n",
      "Train Epoch: 75 [25152/225000 (11%)] Loss: 19636.875000\n",
      "Train Epoch: 75 [27648/225000 (12%)] Loss: 19821.923828\n",
      "Train Epoch: 75 [30144/225000 (13%)] Loss: 19547.537109\n",
      "Train Epoch: 75 [32640/225000 (15%)] Loss: 19666.931641\n",
      "Train Epoch: 75 [35136/225000 (16%)] Loss: 19203.958984\n",
      "Train Epoch: 75 [37632/225000 (17%)] Loss: 19631.945312\n",
      "Train Epoch: 75 [40128/225000 (18%)] Loss: 19906.703125\n",
      "Train Epoch: 75 [42624/225000 (19%)] Loss: 19061.617188\n",
      "Train Epoch: 75 [45120/225000 (20%)] Loss: 19706.710938\n",
      "Train Epoch: 75 [47616/225000 (21%)] Loss: 19762.056641\n",
      "Train Epoch: 75 [50112/225000 (22%)] Loss: 19886.580078\n",
      "Train Epoch: 75 [52608/225000 (23%)] Loss: 19887.183594\n",
      "Train Epoch: 75 [55104/225000 (24%)] Loss: 20042.023438\n",
      "Train Epoch: 75 [57600/225000 (26%)] Loss: 20082.052734\n",
      "Train Epoch: 75 [60096/225000 (27%)] Loss: 19823.617188\n",
      "Train Epoch: 75 [62592/225000 (28%)] Loss: 19638.535156\n",
      "Train Epoch: 75 [65088/225000 (29%)] Loss: 19466.640625\n",
      "Train Epoch: 75 [67584/225000 (30%)] Loss: 19598.916016\n",
      "Train Epoch: 75 [70080/225000 (31%)] Loss: 19551.279297\n",
      "Train Epoch: 75 [72576/225000 (32%)] Loss: 19606.324219\n",
      "Train Epoch: 75 [75072/225000 (33%)] Loss: 19828.558594\n",
      "Train Epoch: 75 [77568/225000 (34%)] Loss: 19722.406250\n",
      "Train Epoch: 75 [80064/225000 (36%)] Loss: 19648.960938\n",
      "Train Epoch: 75 [82560/225000 (37%)] Loss: 19711.097656\n",
      "Train Epoch: 75 [85056/225000 (38%)] Loss: 19723.062500\n",
      "Train Epoch: 75 [87552/225000 (39%)] Loss: 19295.214844\n",
      "Train Epoch: 75 [90048/225000 (40%)] Loss: 19945.527344\n",
      "Train Epoch: 75 [92544/225000 (41%)] Loss: 19398.359375\n",
      "Train Epoch: 75 [95040/225000 (42%)] Loss: 19955.142578\n",
      "Train Epoch: 75 [97536/225000 (43%)] Loss: 19444.867188\n",
      "Train Epoch: 75 [100032/225000 (44%)] Loss: 19466.224609\n",
      "Train Epoch: 75 [102528/225000 (46%)] Loss: 19903.175781\n",
      "Train Epoch: 75 [105024/225000 (47%)] Loss: 20147.804688\n",
      "Train Epoch: 75 [107520/225000 (48%)] Loss: 20016.222656\n",
      "Train Epoch: 75 [110016/225000 (49%)] Loss: 20229.347656\n",
      "Train Epoch: 75 [112512/225000 (50%)] Loss: 19633.171875\n",
      "Train Epoch: 75 [115008/225000 (51%)] Loss: 19875.041016\n",
      "Train Epoch: 75 [117504/225000 (52%)] Loss: 19894.224609\n",
      "Train Epoch: 75 [120000/225000 (53%)] Loss: 19779.843750\n",
      "Train Epoch: 75 [122496/225000 (54%)] Loss: 19854.199219\n",
      "Train Epoch: 75 [124992/225000 (56%)] Loss: 20107.484375\n",
      "Train Epoch: 75 [127488/225000 (57%)] Loss: 19649.992188\n",
      "Train Epoch: 75 [129984/225000 (58%)] Loss: 19700.000000\n",
      "Train Epoch: 75 [132480/225000 (59%)] Loss: 19914.570312\n",
      "Train Epoch: 75 [134976/225000 (60%)] Loss: 19886.945312\n",
      "Train Epoch: 75 [137472/225000 (61%)] Loss: 20212.140625\n",
      "Train Epoch: 75 [139968/225000 (62%)] Loss: 20006.625000\n",
      "Train Epoch: 75 [142464/225000 (63%)] Loss: 19559.197266\n",
      "Train Epoch: 75 [144960/225000 (64%)] Loss: 18802.445312\n",
      "Train Epoch: 75 [147456/225000 (66%)] Loss: 19445.562500\n",
      "Train Epoch: 75 [149952/225000 (67%)] Loss: 19934.515625\n",
      "Train Epoch: 75 [152448/225000 (68%)] Loss: 20188.150391\n",
      "Train Epoch: 75 [154944/225000 (69%)] Loss: 19785.828125\n",
      "Train Epoch: 75 [157440/225000 (70%)] Loss: 19768.443359\n",
      "Train Epoch: 75 [159936/225000 (71%)] Loss: 20246.044922\n",
      "Train Epoch: 75 [162432/225000 (72%)] Loss: 19426.496094\n",
      "Train Epoch: 75 [164928/225000 (73%)] Loss: 19651.035156\n",
      "Train Epoch: 75 [167424/225000 (74%)] Loss: 19459.759766\n",
      "Train Epoch: 75 [169920/225000 (76%)] Loss: 19317.847656\n",
      "Train Epoch: 75 [172416/225000 (77%)] Loss: 19567.398438\n",
      "Train Epoch: 75 [174912/225000 (78%)] Loss: 19576.039062\n",
      "Train Epoch: 75 [177408/225000 (79%)] Loss: 20006.378906\n",
      "Train Epoch: 75 [179904/225000 (80%)] Loss: 19301.619141\n",
      "Train Epoch: 75 [182400/225000 (81%)] Loss: 19324.824219\n",
      "Train Epoch: 75 [184896/225000 (82%)] Loss: 20203.214844\n",
      "Train Epoch: 75 [187392/225000 (83%)] Loss: 20607.433594\n",
      "Train Epoch: 75 [189888/225000 (84%)] Loss: 19718.949219\n",
      "Train Epoch: 75 [192384/225000 (86%)] Loss: 19484.535156\n",
      "Train Epoch: 75 [194880/225000 (87%)] Loss: 19412.251953\n",
      "Train Epoch: 75 [197376/225000 (88%)] Loss: 19670.519531\n",
      "Train Epoch: 75 [199872/225000 (89%)] Loss: 19750.261719\n",
      "Train Epoch: 75 [202368/225000 (90%)] Loss: 20197.716797\n",
      "Train Epoch: 75 [204864/225000 (91%)] Loss: 20091.001953\n",
      "Train Epoch: 75 [207360/225000 (92%)] Loss: 20025.724609\n",
      "Train Epoch: 75 [209856/225000 (93%)] Loss: 19643.265625\n",
      "Train Epoch: 75 [212352/225000 (94%)] Loss: 19705.835938\n",
      "Train Epoch: 75 [214848/225000 (95%)] Loss: 19753.507812\n",
      "Train Epoch: 75 [217344/225000 (97%)] Loss: 19862.681641\n",
      "Train Epoch: 75 [219840/225000 (98%)] Loss: 19945.156250\n",
      "Train Epoch: 75 [222336/225000 (99%)] Loss: 19861.554688\n",
      "Train Epoch: 75 [224832/225000 (100%)] Loss: 19515.945312\n",
      "    epoch          : 75\n",
      "    loss           : 19739.779015238375\n",
      "    val_loss       : 19650.450103441268\n",
      "Train Epoch: 76 [192/225000 (0%)] Loss: 20140.707031\n",
      "Train Epoch: 76 [2688/225000 (1%)] Loss: 19377.265625\n",
      "Train Epoch: 76 [5184/225000 (2%)] Loss: 20100.121094\n",
      "Train Epoch: 76 [7680/225000 (3%)] Loss: 19820.625000\n",
      "Train Epoch: 76 [10176/225000 (5%)] Loss: 19995.574219\n",
      "Train Epoch: 76 [12672/225000 (6%)] Loss: 20032.177734\n",
      "Train Epoch: 76 [15168/225000 (7%)] Loss: 19397.583984\n",
      "Train Epoch: 76 [17664/225000 (8%)] Loss: 20105.816406\n",
      "Train Epoch: 76 [20160/225000 (9%)] Loss: 19521.085938\n",
      "Train Epoch: 76 [22656/225000 (10%)] Loss: 19240.185547\n",
      "Train Epoch: 76 [25152/225000 (11%)] Loss: 19825.953125\n",
      "Train Epoch: 76 [27648/225000 (12%)] Loss: 19495.546875\n",
      "Train Epoch: 76 [30144/225000 (13%)] Loss: 19497.156250\n",
      "Train Epoch: 76 [32640/225000 (15%)] Loss: 19340.960938\n",
      "Train Epoch: 76 [35136/225000 (16%)] Loss: 19918.656250\n",
      "Train Epoch: 76 [37632/225000 (17%)] Loss: 20126.156250\n",
      "Train Epoch: 76 [40128/225000 (18%)] Loss: 19761.757812\n",
      "Train Epoch: 76 [42624/225000 (19%)] Loss: 18964.726562\n",
      "Train Epoch: 76 [45120/225000 (20%)] Loss: 19897.238281\n",
      "Train Epoch: 76 [47616/225000 (21%)] Loss: 19766.925781\n",
      "Train Epoch: 76 [50112/225000 (22%)] Loss: 19783.410156\n",
      "Train Epoch: 76 [52608/225000 (23%)] Loss: 20102.144531\n",
      "Train Epoch: 76 [55104/225000 (24%)] Loss: 19777.523438\n",
      "Train Epoch: 76 [57600/225000 (26%)] Loss: 19890.054688\n",
      "Train Epoch: 76 [60096/225000 (27%)] Loss: 19484.605469\n",
      "Train Epoch: 76 [62592/225000 (28%)] Loss: 19519.726562\n",
      "Train Epoch: 76 [65088/225000 (29%)] Loss: 19892.527344\n",
      "Train Epoch: 76 [67584/225000 (30%)] Loss: 19652.755859\n",
      "Train Epoch: 76 [70080/225000 (31%)] Loss: 19975.695312\n",
      "Train Epoch: 76 [72576/225000 (32%)] Loss: 19113.906250\n",
      "Train Epoch: 76 [75072/225000 (33%)] Loss: 19906.021484\n",
      "Train Epoch: 76 [77568/225000 (34%)] Loss: 19600.427734\n",
      "Train Epoch: 76 [80064/225000 (36%)] Loss: 20328.183594\n",
      "Train Epoch: 76 [82560/225000 (37%)] Loss: 19662.898438\n",
      "Train Epoch: 76 [85056/225000 (38%)] Loss: 19432.939453\n",
      "Train Epoch: 76 [87552/225000 (39%)] Loss: 20181.035156\n",
      "Train Epoch: 76 [90048/225000 (40%)] Loss: 19723.984375\n",
      "Train Epoch: 76 [92544/225000 (41%)] Loss: 20111.974609\n",
      "Train Epoch: 76 [95040/225000 (42%)] Loss: 19570.500000\n",
      "Train Epoch: 76 [97536/225000 (43%)] Loss: 19604.960938\n",
      "Train Epoch: 76 [100032/225000 (44%)] Loss: 19881.378906\n",
      "Train Epoch: 76 [102528/225000 (46%)] Loss: 19835.763672\n",
      "Train Epoch: 76 [105024/225000 (47%)] Loss: 19785.644531\n",
      "Train Epoch: 76 [107520/225000 (48%)] Loss: 19610.199219\n",
      "Train Epoch: 76 [110016/225000 (49%)] Loss: 19843.066406\n",
      "Train Epoch: 76 [112512/225000 (50%)] Loss: 20149.041016\n",
      "Train Epoch: 76 [115008/225000 (51%)] Loss: 20086.531250\n",
      "Train Epoch: 76 [117504/225000 (52%)] Loss: 19569.941406\n",
      "Train Epoch: 76 [120000/225000 (53%)] Loss: 19549.410156\n",
      "Train Epoch: 76 [122496/225000 (54%)] Loss: 19645.734375\n",
      "Train Epoch: 76 [124992/225000 (56%)] Loss: 20127.851562\n",
      "Train Epoch: 76 [127488/225000 (57%)] Loss: 18935.802734\n",
      "Train Epoch: 76 [129984/225000 (58%)] Loss: 19501.875000\n",
      "Train Epoch: 76 [132480/225000 (59%)] Loss: 20166.707031\n",
      "Train Epoch: 76 [134976/225000 (60%)] Loss: 19601.759766\n",
      "Train Epoch: 76 [137472/225000 (61%)] Loss: 19708.863281\n",
      "Train Epoch: 76 [139968/225000 (62%)] Loss: 19917.203125\n",
      "Train Epoch: 76 [142464/225000 (63%)] Loss: 20357.689453\n",
      "Train Epoch: 76 [144960/225000 (64%)] Loss: 19808.816406\n",
      "Train Epoch: 76 [147456/225000 (66%)] Loss: 19828.367188\n",
      "Train Epoch: 76 [149952/225000 (67%)] Loss: 19696.386719\n",
      "Train Epoch: 76 [152448/225000 (68%)] Loss: 19639.828125\n",
      "Train Epoch: 76 [154944/225000 (69%)] Loss: 20049.535156\n",
      "Train Epoch: 76 [157440/225000 (70%)] Loss: 19686.931641\n",
      "Train Epoch: 76 [159936/225000 (71%)] Loss: 19309.294922\n",
      "Train Epoch: 76 [162432/225000 (72%)] Loss: 20043.210938\n",
      "Train Epoch: 76 [164928/225000 (73%)] Loss: 19629.601562\n",
      "Train Epoch: 76 [167424/225000 (74%)] Loss: 20164.789062\n",
      "Train Epoch: 76 [169920/225000 (76%)] Loss: 19378.044922\n",
      "Train Epoch: 76 [172416/225000 (77%)] Loss: 19650.195312\n",
      "Train Epoch: 76 [174912/225000 (78%)] Loss: 19973.701172\n",
      "Train Epoch: 76 [177408/225000 (79%)] Loss: 19610.441406\n",
      "Train Epoch: 76 [179904/225000 (80%)] Loss: 19808.351562\n",
      "Train Epoch: 76 [182400/225000 (81%)] Loss: 19333.367188\n",
      "Train Epoch: 76 [184896/225000 (82%)] Loss: 19316.730469\n",
      "Train Epoch: 76 [187392/225000 (83%)] Loss: 20291.046875\n",
      "Train Epoch: 76 [189888/225000 (84%)] Loss: 19896.519531\n",
      "Train Epoch: 76 [192384/225000 (86%)] Loss: 20156.265625\n",
      "Train Epoch: 76 [194880/225000 (87%)] Loss: 19708.550781\n",
      "Train Epoch: 76 [197376/225000 (88%)] Loss: 19548.988281\n",
      "Train Epoch: 76 [199872/225000 (89%)] Loss: 19680.005859\n",
      "Train Epoch: 76 [202368/225000 (90%)] Loss: 19999.708984\n",
      "Train Epoch: 76 [204864/225000 (91%)] Loss: 19653.740234\n",
      "Train Epoch: 76 [207360/225000 (92%)] Loss: 19418.378906\n",
      "Train Epoch: 76 [209856/225000 (93%)] Loss: 19529.601562\n",
      "Train Epoch: 76 [212352/225000 (94%)] Loss: 19667.251953\n",
      "Train Epoch: 76 [214848/225000 (95%)] Loss: 19331.250000\n",
      "Train Epoch: 76 [217344/225000 (97%)] Loss: 19401.148438\n",
      "Train Epoch: 76 [219840/225000 (98%)] Loss: 19472.980469\n",
      "Train Epoch: 76 [222336/225000 (99%)] Loss: 19650.484375\n",
      "Train Epoch: 76 [224832/225000 (100%)] Loss: 20165.357422\n",
      "    epoch          : 76\n",
      "    loss           : 19732.591786876066\n",
      "    val_loss       : 19655.37252277454\n",
      "Train Epoch: 77 [192/225000 (0%)] Loss: 20119.080078\n",
      "Train Epoch: 77 [2688/225000 (1%)] Loss: 19665.054688\n",
      "Train Epoch: 77 [5184/225000 (2%)] Loss: 19763.597656\n",
      "Train Epoch: 77 [7680/225000 (3%)] Loss: 19648.429688\n",
      "Train Epoch: 77 [10176/225000 (5%)] Loss: 20071.808594\n",
      "Train Epoch: 77 [12672/225000 (6%)] Loss: 19513.285156\n",
      "Train Epoch: 77 [15168/225000 (7%)] Loss: 20127.574219\n",
      "Train Epoch: 77 [17664/225000 (8%)] Loss: 20017.007812\n",
      "Train Epoch: 77 [20160/225000 (9%)] Loss: 19903.304688\n",
      "Train Epoch: 77 [22656/225000 (10%)] Loss: 19901.767578\n",
      "Train Epoch: 77 [25152/225000 (11%)] Loss: 19772.458984\n",
      "Train Epoch: 77 [27648/225000 (12%)] Loss: 19566.929688\n",
      "Train Epoch: 77 [30144/225000 (13%)] Loss: 19804.847656\n",
      "Train Epoch: 77 [32640/225000 (15%)] Loss: 19944.023438\n",
      "Train Epoch: 77 [35136/225000 (16%)] Loss: 19458.597656\n",
      "Train Epoch: 77 [37632/225000 (17%)] Loss: 19705.546875\n",
      "Train Epoch: 77 [40128/225000 (18%)] Loss: 19305.238281\n",
      "Train Epoch: 77 [42624/225000 (19%)] Loss: 19559.820312\n",
      "Train Epoch: 77 [45120/225000 (20%)] Loss: 19783.109375\n",
      "Train Epoch: 77 [47616/225000 (21%)] Loss: 20003.810547\n",
      "Train Epoch: 77 [50112/225000 (22%)] Loss: 19779.515625\n",
      "Train Epoch: 77 [52608/225000 (23%)] Loss: 19808.050781\n",
      "Train Epoch: 77 [55104/225000 (24%)] Loss: 19682.015625\n",
      "Train Epoch: 77 [57600/225000 (26%)] Loss: 19314.263672\n",
      "Train Epoch: 77 [60096/225000 (27%)] Loss: 20143.531250\n",
      "Train Epoch: 77 [62592/225000 (28%)] Loss: 19425.500000\n",
      "Train Epoch: 77 [65088/225000 (29%)] Loss: 20174.781250\n",
      "Train Epoch: 77 [67584/225000 (30%)] Loss: 19949.441406\n",
      "Train Epoch: 77 [70080/225000 (31%)] Loss: 19449.613281\n",
      "Train Epoch: 77 [72576/225000 (32%)] Loss: 19689.527344\n",
      "Train Epoch: 77 [75072/225000 (33%)] Loss: 20176.304688\n",
      "Train Epoch: 77 [77568/225000 (34%)] Loss: 19901.351562\n",
      "Train Epoch: 77 [80064/225000 (36%)] Loss: 20105.513672\n",
      "Train Epoch: 77 [82560/225000 (37%)] Loss: 19752.031250\n",
      "Train Epoch: 77 [85056/225000 (38%)] Loss: 19425.091797\n",
      "Train Epoch: 77 [87552/225000 (39%)] Loss: 19684.500000\n",
      "Train Epoch: 77 [90048/225000 (40%)] Loss: 19777.906250\n",
      "Train Epoch: 77 [92544/225000 (41%)] Loss: 19731.769531\n",
      "Train Epoch: 77 [95040/225000 (42%)] Loss: 19660.726562\n",
      "Train Epoch: 77 [97536/225000 (43%)] Loss: 19456.265625\n",
      "Train Epoch: 77 [100032/225000 (44%)] Loss: 19925.480469\n",
      "Train Epoch: 77 [102528/225000 (46%)] Loss: 20043.714844\n",
      "Train Epoch: 77 [105024/225000 (47%)] Loss: 20232.000000\n",
      "Train Epoch: 77 [107520/225000 (48%)] Loss: 19373.082031\n",
      "Train Epoch: 77 [110016/225000 (49%)] Loss: 19918.648438\n",
      "Train Epoch: 77 [112512/225000 (50%)] Loss: 19741.902344\n",
      "Train Epoch: 77 [115008/225000 (51%)] Loss: 19928.523438\n",
      "Train Epoch: 77 [117504/225000 (52%)] Loss: 20030.023438\n",
      "Train Epoch: 77 [120000/225000 (53%)] Loss: 19716.210938\n",
      "Train Epoch: 77 [122496/225000 (54%)] Loss: 19991.351562\n",
      "Train Epoch: 77 [124992/225000 (56%)] Loss: 19406.369141\n",
      "Train Epoch: 77 [127488/225000 (57%)] Loss: 19297.371094\n",
      "Train Epoch: 77 [129984/225000 (58%)] Loss: 20002.611328\n",
      "Train Epoch: 77 [132480/225000 (59%)] Loss: 19917.878906\n",
      "Train Epoch: 77 [134976/225000 (60%)] Loss: 19857.125000\n",
      "Train Epoch: 77 [137472/225000 (61%)] Loss: 20137.751953\n",
      "Train Epoch: 77 [139968/225000 (62%)] Loss: 19551.921875\n",
      "Train Epoch: 77 [142464/225000 (63%)] Loss: 19301.275391\n",
      "Train Epoch: 77 [144960/225000 (64%)] Loss: 19849.007812\n",
      "Train Epoch: 77 [147456/225000 (66%)] Loss: 20105.802734\n",
      "Train Epoch: 77 [149952/225000 (67%)] Loss: 19666.843750\n",
      "Train Epoch: 77 [152448/225000 (68%)] Loss: 19781.851562\n",
      "Train Epoch: 77 [154944/225000 (69%)] Loss: 19749.710938\n",
      "Train Epoch: 77 [157440/225000 (70%)] Loss: 19943.427734\n",
      "Train Epoch: 77 [159936/225000 (71%)] Loss: 19707.902344\n",
      "Train Epoch: 77 [162432/225000 (72%)] Loss: 19749.082031\n",
      "Train Epoch: 77 [164928/225000 (73%)] Loss: 19461.796875\n",
      "Train Epoch: 77 [167424/225000 (74%)] Loss: 19767.042969\n",
      "Train Epoch: 77 [169920/225000 (76%)] Loss: 19682.886719\n",
      "Train Epoch: 77 [172416/225000 (77%)] Loss: 19313.250000\n",
      "Train Epoch: 77 [174912/225000 (78%)] Loss: 19443.238281\n",
      "Train Epoch: 77 [177408/225000 (79%)] Loss: 19451.781250\n",
      "Train Epoch: 77 [179904/225000 (80%)] Loss: 19576.191406\n",
      "Train Epoch: 77 [182400/225000 (81%)] Loss: 19295.925781\n",
      "Train Epoch: 77 [184896/225000 (82%)] Loss: 19570.312500\n",
      "Train Epoch: 77 [187392/225000 (83%)] Loss: 19851.945312\n",
      "Train Epoch: 77 [189888/225000 (84%)] Loss: 19344.927734\n",
      "Train Epoch: 77 [192384/225000 (86%)] Loss: 19961.935547\n",
      "Train Epoch: 77 [194880/225000 (87%)] Loss: 19374.000000\n",
      "Train Epoch: 77 [197376/225000 (88%)] Loss: 19920.371094\n",
      "Train Epoch: 77 [199872/225000 (89%)] Loss: 19262.628906\n",
      "Train Epoch: 77 [202368/225000 (90%)] Loss: 19724.375000\n",
      "Train Epoch: 77 [204864/225000 (91%)] Loss: 19803.847656\n",
      "Train Epoch: 77 [207360/225000 (92%)] Loss: 19618.277344\n",
      "Train Epoch: 77 [209856/225000 (93%)] Loss: 19885.367188\n",
      "Train Epoch: 77 [212352/225000 (94%)] Loss: 19732.718750\n",
      "Train Epoch: 77 [214848/225000 (95%)] Loss: 19741.943359\n",
      "Train Epoch: 77 [217344/225000 (97%)] Loss: 19648.232422\n",
      "Train Epoch: 77 [219840/225000 (98%)] Loss: 19505.750000\n",
      "Train Epoch: 77 [222336/225000 (99%)] Loss: 19783.824219\n",
      "Train Epoch: 77 [224832/225000 (100%)] Loss: 19957.402344\n",
      "    epoch          : 77\n",
      "    loss           : 19710.991762545327\n",
      "    val_loss       : 19610.478863387616\n",
      "Train Epoch: 78 [192/225000 (0%)] Loss: 19884.324219\n",
      "Train Epoch: 78 [2688/225000 (1%)] Loss: 19415.125000\n",
      "Train Epoch: 78 [5184/225000 (2%)] Loss: 19860.849609\n",
      "Train Epoch: 78 [7680/225000 (3%)] Loss: 19441.640625\n",
      "Train Epoch: 78 [10176/225000 (5%)] Loss: 20024.339844\n",
      "Train Epoch: 78 [12672/225000 (6%)] Loss: 20016.191406\n",
      "Train Epoch: 78 [15168/225000 (7%)] Loss: 19886.417969\n",
      "Train Epoch: 78 [17664/225000 (8%)] Loss: 19278.593750\n",
      "Train Epoch: 78 [20160/225000 (9%)] Loss: 19833.937500\n",
      "Train Epoch: 78 [22656/225000 (10%)] Loss: 19730.964844\n",
      "Train Epoch: 78 [25152/225000 (11%)] Loss: 19219.701172\n",
      "Train Epoch: 78 [27648/225000 (12%)] Loss: 20330.718750\n",
      "Train Epoch: 78 [30144/225000 (13%)] Loss: 19564.296875\n",
      "Train Epoch: 78 [32640/225000 (15%)] Loss: 19480.726562\n",
      "Train Epoch: 78 [35136/225000 (16%)] Loss: 19291.679688\n",
      "Train Epoch: 78 [37632/225000 (17%)] Loss: 19778.359375\n",
      "Train Epoch: 78 [40128/225000 (18%)] Loss: 19742.689453\n",
      "Train Epoch: 78 [42624/225000 (19%)] Loss: 19803.808594\n",
      "Train Epoch: 78 [45120/225000 (20%)] Loss: 19926.734375\n",
      "Train Epoch: 78 [47616/225000 (21%)] Loss: 19777.572266\n",
      "Train Epoch: 78 [50112/225000 (22%)] Loss: 19725.652344\n",
      "Train Epoch: 78 [52608/225000 (23%)] Loss: 19850.511719\n",
      "Train Epoch: 78 [55104/225000 (24%)] Loss: 19466.119141\n",
      "Train Epoch: 78 [57600/225000 (26%)] Loss: 19765.078125\n",
      "Train Epoch: 78 [60096/225000 (27%)] Loss: 19818.613281\n",
      "Train Epoch: 78 [62592/225000 (28%)] Loss: 19771.605469\n",
      "Train Epoch: 78 [65088/225000 (29%)] Loss: 19431.152344\n",
      "Train Epoch: 78 [67584/225000 (30%)] Loss: 19745.339844\n",
      "Train Epoch: 78 [70080/225000 (31%)] Loss: 19759.480469\n",
      "Train Epoch: 78 [72576/225000 (32%)] Loss: 19594.726562\n",
      "Train Epoch: 78 [75072/225000 (33%)] Loss: 20358.503906\n",
      "Train Epoch: 78 [77568/225000 (34%)] Loss: 19969.419922\n",
      "Train Epoch: 78 [80064/225000 (36%)] Loss: 19541.037109\n",
      "Train Epoch: 78 [82560/225000 (37%)] Loss: 19725.054688\n",
      "Train Epoch: 78 [85056/225000 (38%)] Loss: 19395.693359\n",
      "Train Epoch: 78 [87552/225000 (39%)] Loss: 19644.046875\n",
      "Train Epoch: 78 [90048/225000 (40%)] Loss: 20052.130859\n",
      "Train Epoch: 78 [92544/225000 (41%)] Loss: 19960.382812\n",
      "Train Epoch: 78 [95040/225000 (42%)] Loss: 19701.119141\n",
      "Train Epoch: 78 [97536/225000 (43%)] Loss: 19432.902344\n",
      "Train Epoch: 78 [100032/225000 (44%)] Loss: 19951.265625\n",
      "Train Epoch: 78 [102528/225000 (46%)] Loss: 19493.453125\n",
      "Train Epoch: 78 [105024/225000 (47%)] Loss: 19956.894531\n",
      "Train Epoch: 78 [107520/225000 (48%)] Loss: 19574.925781\n",
      "Train Epoch: 78 [110016/225000 (49%)] Loss: 19322.011719\n",
      "Train Epoch: 78 [112512/225000 (50%)] Loss: 19978.001953\n",
      "Train Epoch: 78 [115008/225000 (51%)] Loss: 19427.343750\n",
      "Train Epoch: 78 [117504/225000 (52%)] Loss: 19366.207031\n",
      "Train Epoch: 78 [120000/225000 (53%)] Loss: 19643.763672\n",
      "Train Epoch: 78 [122496/225000 (54%)] Loss: 20256.042969\n",
      "Train Epoch: 78 [124992/225000 (56%)] Loss: 19876.697266\n",
      "Train Epoch: 78 [127488/225000 (57%)] Loss: 19400.654297\n",
      "Train Epoch: 78 [129984/225000 (58%)] Loss: 20066.593750\n",
      "Train Epoch: 78 [132480/225000 (59%)] Loss: 19638.093750\n",
      "Train Epoch: 78 [134976/225000 (60%)] Loss: 20075.718750\n",
      "Train Epoch: 78 [137472/225000 (61%)] Loss: 19573.439453\n",
      "Train Epoch: 78 [139968/225000 (62%)] Loss: 20098.685547\n",
      "Train Epoch: 78 [142464/225000 (63%)] Loss: 19497.832031\n",
      "Train Epoch: 78 [144960/225000 (64%)] Loss: 19505.578125\n",
      "Train Epoch: 78 [147456/225000 (66%)] Loss: 19718.308594\n",
      "Train Epoch: 78 [149952/225000 (67%)] Loss: 19845.281250\n",
      "Train Epoch: 78 [152448/225000 (68%)] Loss: 19232.109375\n",
      "Train Epoch: 78 [154944/225000 (69%)] Loss: 20027.955078\n",
      "Train Epoch: 78 [157440/225000 (70%)] Loss: 19210.089844\n",
      "Train Epoch: 78 [159936/225000 (71%)] Loss: 19844.000000\n",
      "Train Epoch: 78 [162432/225000 (72%)] Loss: 19804.210938\n",
      "Train Epoch: 78 [164928/225000 (73%)] Loss: 20107.312500\n",
      "Train Epoch: 78 [167424/225000 (74%)] Loss: 19450.257812\n",
      "Train Epoch: 78 [169920/225000 (76%)] Loss: 19681.726562\n",
      "Train Epoch: 78 [172416/225000 (77%)] Loss: 19455.230469\n",
      "Train Epoch: 78 [174912/225000 (78%)] Loss: 19967.853516\n",
      "Train Epoch: 78 [177408/225000 (79%)] Loss: 19322.121094\n",
      "Train Epoch: 78 [179904/225000 (80%)] Loss: 19986.972656\n",
      "Train Epoch: 78 [182400/225000 (81%)] Loss: 19369.537109\n",
      "Train Epoch: 78 [184896/225000 (82%)] Loss: 19537.173828\n",
      "Train Epoch: 78 [187392/225000 (83%)] Loss: 19527.273438\n",
      "Train Epoch: 78 [189888/225000 (84%)] Loss: 19544.865234\n",
      "Train Epoch: 78 [192384/225000 (86%)] Loss: 19147.519531\n",
      "Train Epoch: 78 [194880/225000 (87%)] Loss: 19715.439453\n",
      "Train Epoch: 78 [197376/225000 (88%)] Loss: 19417.519531\n",
      "Train Epoch: 78 [199872/225000 (89%)] Loss: 19505.892578\n",
      "Train Epoch: 78 [202368/225000 (90%)] Loss: 19544.224609\n",
      "Train Epoch: 78 [204864/225000 (91%)] Loss: 19871.904297\n",
      "Train Epoch: 78 [207360/225000 (92%)] Loss: 19300.085938\n",
      "Train Epoch: 78 [209856/225000 (93%)] Loss: 19178.835938\n",
      "Train Epoch: 78 [212352/225000 (94%)] Loss: 19059.367188\n",
      "Train Epoch: 78 [214848/225000 (95%)] Loss: 19409.699219\n",
      "Train Epoch: 78 [217344/225000 (97%)] Loss: 19322.775391\n",
      "Train Epoch: 78 [219840/225000 (98%)] Loss: 19662.992188\n",
      "Train Epoch: 78 [222336/225000 (99%)] Loss: 20041.933594\n",
      "Train Epoch: 78 [224832/225000 (100%)] Loss: 19630.269531\n",
      "    epoch          : 78\n",
      "    loss           : 19707.813761532103\n",
      "    val_loss       : 19603.871453893094\n",
      "Train Epoch: 79 [192/225000 (0%)] Loss: 20087.480469\n",
      "Train Epoch: 79 [2688/225000 (1%)] Loss: 19670.730469\n",
      "Train Epoch: 79 [5184/225000 (2%)] Loss: 19718.656250\n",
      "Train Epoch: 79 [7680/225000 (3%)] Loss: 19738.308594\n",
      "Train Epoch: 79 [10176/225000 (5%)] Loss: 19761.144531\n",
      "Train Epoch: 79 [12672/225000 (6%)] Loss: 19833.773438\n",
      "Train Epoch: 79 [15168/225000 (7%)] Loss: 19493.832031\n",
      "Train Epoch: 79 [17664/225000 (8%)] Loss: 19854.556641\n",
      "Train Epoch: 79 [20160/225000 (9%)] Loss: 19596.078125\n",
      "Train Epoch: 79 [22656/225000 (10%)] Loss: 19443.259766\n",
      "Train Epoch: 79 [25152/225000 (11%)] Loss: 19673.781250\n",
      "Train Epoch: 79 [27648/225000 (12%)] Loss: 19859.300781\n",
      "Train Epoch: 79 [30144/225000 (13%)] Loss: 19527.755859\n",
      "Train Epoch: 79 [32640/225000 (15%)] Loss: 20026.113281\n",
      "Train Epoch: 79 [35136/225000 (16%)] Loss: 19729.929688\n",
      "Train Epoch: 79 [37632/225000 (17%)] Loss: 19788.281250\n",
      "Train Epoch: 79 [40128/225000 (18%)] Loss: 19526.824219\n",
      "Train Epoch: 79 [42624/225000 (19%)] Loss: 19375.851562\n",
      "Train Epoch: 79 [45120/225000 (20%)] Loss: 19417.181641\n",
      "Train Epoch: 79 [47616/225000 (21%)] Loss: 19536.851562\n",
      "Train Epoch: 79 [50112/225000 (22%)] Loss: 19727.296875\n",
      "Train Epoch: 79 [52608/225000 (23%)] Loss: 19823.171875\n",
      "Train Epoch: 79 [55104/225000 (24%)] Loss: 19440.433594\n",
      "Train Epoch: 79 [57600/225000 (26%)] Loss: 19560.835938\n",
      "Train Epoch: 79 [60096/225000 (27%)] Loss: 19879.687500\n",
      "Train Epoch: 79 [62592/225000 (28%)] Loss: 19693.242188\n",
      "Train Epoch: 79 [65088/225000 (29%)] Loss: 20137.320312\n",
      "Train Epoch: 79 [67584/225000 (30%)] Loss: 19764.343750\n",
      "Train Epoch: 79 [70080/225000 (31%)] Loss: 19495.449219\n",
      "Train Epoch: 79 [72576/225000 (32%)] Loss: 19472.527344\n",
      "Train Epoch: 79 [75072/225000 (33%)] Loss: 19514.638672\n",
      "Train Epoch: 79 [77568/225000 (34%)] Loss: 19523.195312\n",
      "Train Epoch: 79 [80064/225000 (36%)] Loss: 19469.289062\n",
      "Train Epoch: 79 [82560/225000 (37%)] Loss: 19934.406250\n",
      "Train Epoch: 79 [85056/225000 (38%)] Loss: 19499.140625\n",
      "Train Epoch: 79 [87552/225000 (39%)] Loss: 19167.285156\n",
      "Train Epoch: 79 [90048/225000 (40%)] Loss: 20035.156250\n",
      "Train Epoch: 79 [92544/225000 (41%)] Loss: 19867.820312\n",
      "Train Epoch: 79 [95040/225000 (42%)] Loss: 19802.025391\n",
      "Train Epoch: 79 [97536/225000 (43%)] Loss: 19394.781250\n",
      "Train Epoch: 79 [100032/225000 (44%)] Loss: 19669.095703\n",
      "Train Epoch: 79 [102528/225000 (46%)] Loss: 20102.732422\n",
      "Train Epoch: 79 [105024/225000 (47%)] Loss: 19755.351562\n",
      "Train Epoch: 79 [107520/225000 (48%)] Loss: 19984.363281\n",
      "Train Epoch: 79 [110016/225000 (49%)] Loss: 19490.886719\n",
      "Train Epoch: 79 [112512/225000 (50%)] Loss: 19313.625000\n",
      "Train Epoch: 79 [115008/225000 (51%)] Loss: 19917.289062\n",
      "Train Epoch: 79 [117504/225000 (52%)] Loss: 20135.017578\n",
      "Train Epoch: 79 [120000/225000 (53%)] Loss: 19863.542969\n",
      "Train Epoch: 79 [122496/225000 (54%)] Loss: 19408.654297\n",
      "Train Epoch: 79 [124992/225000 (56%)] Loss: 19626.250000\n",
      "Train Epoch: 79 [127488/225000 (57%)] Loss: 19068.937500\n",
      "Train Epoch: 79 [129984/225000 (58%)] Loss: 19725.160156\n",
      "Train Epoch: 79 [132480/225000 (59%)] Loss: 19981.976562\n",
      "Train Epoch: 79 [134976/225000 (60%)] Loss: 19797.416016\n",
      "Train Epoch: 79 [137472/225000 (61%)] Loss: 19371.958984\n",
      "Train Epoch: 79 [139968/225000 (62%)] Loss: 19564.894531\n",
      "Train Epoch: 79 [142464/225000 (63%)] Loss: 19650.230469\n",
      "Train Epoch: 79 [144960/225000 (64%)] Loss: 19826.564453\n",
      "Train Epoch: 79 [147456/225000 (66%)] Loss: 19592.722656\n",
      "Train Epoch: 79 [149952/225000 (67%)] Loss: 19886.564453\n",
      "Train Epoch: 79 [152448/225000 (68%)] Loss: 19485.312500\n",
      "Train Epoch: 79 [154944/225000 (69%)] Loss: 20154.976562\n",
      "Train Epoch: 79 [157440/225000 (70%)] Loss: 19319.675781\n",
      "Train Epoch: 79 [159936/225000 (71%)] Loss: 19618.531250\n",
      "Train Epoch: 79 [162432/225000 (72%)] Loss: 19573.880859\n",
      "Train Epoch: 79 [164928/225000 (73%)] Loss: 20013.902344\n",
      "Train Epoch: 79 [167424/225000 (74%)] Loss: 19790.138672\n",
      "Train Epoch: 79 [169920/225000 (76%)] Loss: 19451.462891\n",
      "Train Epoch: 79 [172416/225000 (77%)] Loss: 19947.515625\n",
      "Train Epoch: 79 [174912/225000 (78%)] Loss: 19256.390625\n",
      "Train Epoch: 79 [177408/225000 (79%)] Loss: 19494.503906\n",
      "Train Epoch: 79 [179904/225000 (80%)] Loss: 19489.810547\n",
      "Train Epoch: 79 [182400/225000 (81%)] Loss: 19670.246094\n",
      "Train Epoch: 79 [184896/225000 (82%)] Loss: 19511.867188\n",
      "Train Epoch: 79 [187392/225000 (83%)] Loss: 19342.023438\n",
      "Train Epoch: 79 [189888/225000 (84%)] Loss: 19730.964844\n",
      "Train Epoch: 79 [192384/225000 (86%)] Loss: 19527.375000\n",
      "Train Epoch: 79 [194880/225000 (87%)] Loss: 19977.511719\n",
      "Train Epoch: 79 [197376/225000 (88%)] Loss: 19722.894531\n",
      "Train Epoch: 79 [199872/225000 (89%)] Loss: 19538.140625\n",
      "Train Epoch: 79 [202368/225000 (90%)] Loss: 19734.152344\n",
      "Train Epoch: 79 [204864/225000 (91%)] Loss: 19713.382812\n",
      "Train Epoch: 79 [207360/225000 (92%)] Loss: 19621.648438\n",
      "Train Epoch: 79 [209856/225000 (93%)] Loss: 20158.041016\n",
      "Train Epoch: 79 [212352/225000 (94%)] Loss: 19611.988281\n",
      "Train Epoch: 79 [214848/225000 (95%)] Loss: 19719.410156\n",
      "Train Epoch: 79 [217344/225000 (97%)] Loss: 19538.363281\n",
      "Train Epoch: 79 [219840/225000 (98%)] Loss: 19524.109375\n",
      "Train Epoch: 79 [222336/225000 (99%)] Loss: 19217.187500\n",
      "Train Epoch: 79 [224832/225000 (100%)] Loss: 19244.644531\n",
      "    epoch          : 79\n",
      "    loss           : 19702.898152530397\n",
      "    val_loss       : 19592.182392959377\n",
      "Train Epoch: 80 [192/225000 (0%)] Loss: 19904.503906\n",
      "Train Epoch: 80 [2688/225000 (1%)] Loss: 19779.847656\n",
      "Train Epoch: 80 [5184/225000 (2%)] Loss: 19787.265625\n",
      "Train Epoch: 80 [7680/225000 (3%)] Loss: 20036.343750\n",
      "Train Epoch: 80 [10176/225000 (5%)] Loss: 19817.578125\n",
      "Train Epoch: 80 [12672/225000 (6%)] Loss: 19720.982422\n",
      "Train Epoch: 80 [15168/225000 (7%)] Loss: 19719.246094\n",
      "Train Epoch: 80 [17664/225000 (8%)] Loss: 19542.398438\n",
      "Train Epoch: 80 [20160/225000 (9%)] Loss: 19397.328125\n",
      "Train Epoch: 80 [22656/225000 (10%)] Loss: 19794.234375\n",
      "Train Epoch: 80 [25152/225000 (11%)] Loss: 19659.033203\n",
      "Train Epoch: 80 [27648/225000 (12%)] Loss: 19554.285156\n",
      "Train Epoch: 80 [30144/225000 (13%)] Loss: 19803.812500\n",
      "Train Epoch: 80 [32640/225000 (15%)] Loss: 19524.439453\n",
      "Train Epoch: 80 [35136/225000 (16%)] Loss: 19833.181641\n",
      "Train Epoch: 80 [37632/225000 (17%)] Loss: 19197.083984\n",
      "Train Epoch: 80 [40128/225000 (18%)] Loss: 19695.863281\n",
      "Train Epoch: 80 [42624/225000 (19%)] Loss: 19423.945312\n",
      "Train Epoch: 80 [45120/225000 (20%)] Loss: 19398.343750\n",
      "Train Epoch: 80 [47616/225000 (21%)] Loss: 19861.419922\n",
      "Train Epoch: 80 [50112/225000 (22%)] Loss: 19646.820312\n",
      "Train Epoch: 80 [52608/225000 (23%)] Loss: 19544.591797\n",
      "Train Epoch: 80 [55104/225000 (24%)] Loss: 19893.378906\n",
      "Train Epoch: 80 [57600/225000 (26%)] Loss: 19812.355469\n",
      "Train Epoch: 80 [60096/225000 (27%)] Loss: 19759.839844\n",
      "Train Epoch: 80 [62592/225000 (28%)] Loss: 19576.916016\n",
      "Train Epoch: 80 [65088/225000 (29%)] Loss: 19744.746094\n",
      "Train Epoch: 80 [67584/225000 (30%)] Loss: 19569.855469\n",
      "Train Epoch: 80 [70080/225000 (31%)] Loss: 19897.660156\n",
      "Train Epoch: 80 [72576/225000 (32%)] Loss: 19953.513672\n",
      "Train Epoch: 80 [75072/225000 (33%)] Loss: 19122.789062\n",
      "Train Epoch: 80 [77568/225000 (34%)] Loss: 19496.740234\n",
      "Train Epoch: 80 [80064/225000 (36%)] Loss: 19643.779297\n",
      "Train Epoch: 80 [82560/225000 (37%)] Loss: 19618.535156\n",
      "Train Epoch: 80 [85056/225000 (38%)] Loss: 19506.902344\n",
      "Train Epoch: 80 [87552/225000 (39%)] Loss: 20203.175781\n",
      "Train Epoch: 80 [90048/225000 (40%)] Loss: 19248.031250\n",
      "Train Epoch: 80 [92544/225000 (41%)] Loss: 19513.507812\n",
      "Train Epoch: 80 [95040/225000 (42%)] Loss: 19602.128906\n",
      "Train Epoch: 80 [97536/225000 (43%)] Loss: 19095.296875\n",
      "Train Epoch: 80 [100032/225000 (44%)] Loss: 19610.582031\n",
      "Train Epoch: 80 [102528/225000 (46%)] Loss: 19272.851562\n",
      "Train Epoch: 80 [105024/225000 (47%)] Loss: 19718.828125\n",
      "Train Epoch: 80 [107520/225000 (48%)] Loss: 19662.402344\n",
      "Train Epoch: 80 [110016/225000 (49%)] Loss: 19881.783203\n",
      "Train Epoch: 80 [112512/225000 (50%)] Loss: 19657.996094\n",
      "Train Epoch: 80 [115008/225000 (51%)] Loss: 19373.421875\n",
      "Train Epoch: 80 [117504/225000 (52%)] Loss: 18886.488281\n",
      "Train Epoch: 80 [120000/225000 (53%)] Loss: 19794.236328\n",
      "Train Epoch: 80 [122496/225000 (54%)] Loss: 19691.998047\n",
      "Train Epoch: 80 [124992/225000 (56%)] Loss: 19285.308594\n",
      "Train Epoch: 80 [127488/225000 (57%)] Loss: 19523.964844\n",
      "Train Epoch: 80 [129984/225000 (58%)] Loss: 19660.703125\n",
      "Train Epoch: 80 [132480/225000 (59%)] Loss: 19359.492188\n",
      "Train Epoch: 80 [134976/225000 (60%)] Loss: 19635.460938\n",
      "Train Epoch: 80 [137472/225000 (61%)] Loss: 19316.126953\n",
      "Train Epoch: 80 [139968/225000 (62%)] Loss: 19500.982422\n",
      "Train Epoch: 80 [142464/225000 (63%)] Loss: 19526.140625\n",
      "Train Epoch: 80 [144960/225000 (64%)] Loss: 19884.984375\n",
      "Train Epoch: 80 [147456/225000 (66%)] Loss: 20169.699219\n",
      "Train Epoch: 80 [149952/225000 (67%)] Loss: 19350.474609\n",
      "Train Epoch: 80 [152448/225000 (68%)] Loss: 19690.783203\n",
      "Train Epoch: 80 [154944/225000 (69%)] Loss: 19755.533203\n",
      "Train Epoch: 80 [157440/225000 (70%)] Loss: 19366.171875\n",
      "Train Epoch: 80 [159936/225000 (71%)] Loss: 19605.669922\n",
      "Train Epoch: 80 [162432/225000 (72%)] Loss: 19560.734375\n",
      "Train Epoch: 80 [164928/225000 (73%)] Loss: 19393.695312\n",
      "Train Epoch: 80 [167424/225000 (74%)] Loss: 19251.933594\n",
      "Train Epoch: 80 [169920/225000 (76%)] Loss: 19923.097656\n",
      "Train Epoch: 80 [172416/225000 (77%)] Loss: 19318.824219\n",
      "Train Epoch: 80 [174912/225000 (78%)] Loss: 19737.320312\n",
      "Train Epoch: 80 [177408/225000 (79%)] Loss: 20075.679688\n",
      "Train Epoch: 80 [179904/225000 (80%)] Loss: 19737.058594\n",
      "Train Epoch: 80 [182400/225000 (81%)] Loss: 19503.238281\n",
      "Train Epoch: 80 [184896/225000 (82%)] Loss: 19472.054688\n",
      "Train Epoch: 80 [187392/225000 (83%)] Loss: 19547.265625\n",
      "Train Epoch: 80 [189888/225000 (84%)] Loss: 19466.160156\n",
      "Train Epoch: 80 [192384/225000 (86%)] Loss: 19365.521484\n",
      "Train Epoch: 80 [194880/225000 (87%)] Loss: 19880.472656\n",
      "Train Epoch: 80 [197376/225000 (88%)] Loss: 19693.078125\n",
      "Train Epoch: 80 [199872/225000 (89%)] Loss: 19009.199219\n",
      "Train Epoch: 80 [202368/225000 (90%)] Loss: 19681.824219\n",
      "Train Epoch: 80 [204864/225000 (91%)] Loss: 20201.750000\n",
      "Train Epoch: 80 [207360/225000 (92%)] Loss: 19684.910156\n",
      "Train Epoch: 80 [209856/225000 (93%)] Loss: 19578.818359\n",
      "Train Epoch: 80 [212352/225000 (94%)] Loss: 18955.724609\n",
      "Train Epoch: 80 [214848/225000 (95%)] Loss: 19458.191406\n",
      "Train Epoch: 80 [217344/225000 (97%)] Loss: 19677.611328\n",
      "Train Epoch: 80 [219840/225000 (98%)] Loss: 19388.251953\n",
      "Train Epoch: 80 [222336/225000 (99%)] Loss: 19431.050781\n",
      "Train Epoch: 80 [224832/225000 (100%)] Loss: 19530.414062\n",
      "    epoch          : 80\n",
      "    loss           : 19694.793463697206\n",
      "    val_loss       : 19582.969044435114\n",
      "Train Epoch: 81 [192/225000 (0%)] Loss: 19008.681641\n",
      "Train Epoch: 81 [2688/225000 (1%)] Loss: 19636.736328\n",
      "Train Epoch: 81 [5184/225000 (2%)] Loss: 20006.800781\n",
      "Train Epoch: 81 [7680/225000 (3%)] Loss: 19615.167969\n",
      "Train Epoch: 81 [10176/225000 (5%)] Loss: 19798.429688\n",
      "Train Epoch: 81 [12672/225000 (6%)] Loss: 19390.000000\n",
      "Train Epoch: 81 [15168/225000 (7%)] Loss: 19461.498047\n",
      "Train Epoch: 81 [17664/225000 (8%)] Loss: 19865.230469\n",
      "Train Epoch: 81 [20160/225000 (9%)] Loss: 19895.234375\n",
      "Train Epoch: 81 [22656/225000 (10%)] Loss: 19559.236328\n",
      "Train Epoch: 81 [25152/225000 (11%)] Loss: 19633.396484\n",
      "Train Epoch: 81 [27648/225000 (12%)] Loss: 19637.787109\n",
      "Train Epoch: 81 [30144/225000 (13%)] Loss: 19365.027344\n",
      "Train Epoch: 81 [32640/225000 (15%)] Loss: 19967.248047\n",
      "Train Epoch: 81 [35136/225000 (16%)] Loss: 19823.972656\n",
      "Train Epoch: 81 [37632/225000 (17%)] Loss: 19760.916016\n",
      "Train Epoch: 81 [40128/225000 (18%)] Loss: 19303.322266\n",
      "Train Epoch: 81 [42624/225000 (19%)] Loss: 19225.078125\n",
      "Train Epoch: 81 [45120/225000 (20%)] Loss: 19777.402344\n",
      "Train Epoch: 81 [47616/225000 (21%)] Loss: 19273.281250\n",
      "Train Epoch: 81 [50112/225000 (22%)] Loss: 19893.492188\n",
      "Train Epoch: 81 [52608/225000 (23%)] Loss: 19953.285156\n",
      "Train Epoch: 81 [55104/225000 (24%)] Loss: 19715.017578\n",
      "Train Epoch: 81 [57600/225000 (26%)] Loss: 19399.275391\n",
      "Train Epoch: 81 [60096/225000 (27%)] Loss: 19293.271484\n",
      "Train Epoch: 81 [62592/225000 (28%)] Loss: 19629.664062\n",
      "Train Epoch: 81 [65088/225000 (29%)] Loss: 19546.888672\n",
      "Train Epoch: 81 [67584/225000 (30%)] Loss: 19385.492188\n",
      "Train Epoch: 81 [70080/225000 (31%)] Loss: 19426.589844\n",
      "Train Epoch: 81 [72576/225000 (32%)] Loss: 19818.716797\n",
      "Train Epoch: 81 [75072/225000 (33%)] Loss: 20020.484375\n",
      "Train Epoch: 81 [77568/225000 (34%)] Loss: 19949.820312\n",
      "Train Epoch: 81 [80064/225000 (36%)] Loss: 19351.583984\n",
      "Train Epoch: 81 [82560/225000 (37%)] Loss: 19452.095703\n",
      "Train Epoch: 81 [85056/225000 (38%)] Loss: 19600.339844\n",
      "Train Epoch: 81 [87552/225000 (39%)] Loss: 19754.966797\n",
      "Train Epoch: 81 [90048/225000 (40%)] Loss: 19012.484375\n",
      "Train Epoch: 81 [92544/225000 (41%)] Loss: 19476.703125\n",
      "Train Epoch: 81 [95040/225000 (42%)] Loss: 19810.117188\n",
      "Train Epoch: 81 [97536/225000 (43%)] Loss: 19933.691406\n",
      "Train Epoch: 81 [100032/225000 (44%)] Loss: 19027.230469\n",
      "Train Epoch: 81 [102528/225000 (46%)] Loss: 19612.992188\n",
      "Train Epoch: 81 [105024/225000 (47%)] Loss: 19036.662109\n",
      "Train Epoch: 81 [107520/225000 (48%)] Loss: 19576.802734\n",
      "Train Epoch: 81 [110016/225000 (49%)] Loss: 19874.394531\n",
      "Train Epoch: 81 [112512/225000 (50%)] Loss: 19569.851562\n",
      "Train Epoch: 81 [115008/225000 (51%)] Loss: 19766.724609\n",
      "Train Epoch: 81 [117504/225000 (52%)] Loss: 19934.873047\n",
      "Train Epoch: 81 [120000/225000 (53%)] Loss: 19771.435547\n",
      "Train Epoch: 81 [122496/225000 (54%)] Loss: 19686.207031\n",
      "Train Epoch: 81 [124992/225000 (56%)] Loss: 19261.515625\n",
      "Train Epoch: 81 [127488/225000 (57%)] Loss: 19371.929688\n",
      "Train Epoch: 81 [129984/225000 (58%)] Loss: 19923.158203\n",
      "Train Epoch: 81 [132480/225000 (59%)] Loss: 20373.794922\n",
      "Train Epoch: 81 [134976/225000 (60%)] Loss: 19708.089844\n",
      "Train Epoch: 81 [137472/225000 (61%)] Loss: 20022.115234\n",
      "Train Epoch: 81 [139968/225000 (62%)] Loss: 19842.611328\n",
      "Train Epoch: 81 [142464/225000 (63%)] Loss: 19617.800781\n",
      "Train Epoch: 81 [144960/225000 (64%)] Loss: 19856.535156\n",
      "Train Epoch: 81 [147456/225000 (66%)] Loss: 19526.322266\n",
      "Train Epoch: 81 [149952/225000 (67%)] Loss: 20246.052734\n",
      "Train Epoch: 81 [152448/225000 (68%)] Loss: 19576.837891\n",
      "Train Epoch: 81 [154944/225000 (69%)] Loss: 19621.269531\n",
      "Train Epoch: 81 [157440/225000 (70%)] Loss: 19870.378906\n",
      "Train Epoch: 81 [159936/225000 (71%)] Loss: 19647.769531\n",
      "Train Epoch: 81 [162432/225000 (72%)] Loss: 19508.242188\n",
      "Train Epoch: 81 [164928/225000 (73%)] Loss: 19413.224609\n",
      "Train Epoch: 81 [167424/225000 (74%)] Loss: 19581.632812\n",
      "Train Epoch: 81 [169920/225000 (76%)] Loss: 19640.601562\n",
      "Train Epoch: 81 [172416/225000 (77%)] Loss: 19152.156250\n",
      "Train Epoch: 81 [174912/225000 (78%)] Loss: 19763.472656\n",
      "Train Epoch: 81 [177408/225000 (79%)] Loss: 19609.042969\n",
      "Train Epoch: 81 [179904/225000 (80%)] Loss: 19461.927734\n",
      "Train Epoch: 81 [182400/225000 (81%)] Loss: 19760.902344\n",
      "Train Epoch: 81 [184896/225000 (82%)] Loss: 19463.535156\n",
      "Train Epoch: 81 [187392/225000 (83%)] Loss: 19214.025391\n",
      "Train Epoch: 81 [189888/225000 (84%)] Loss: 19808.039062\n",
      "Train Epoch: 81 [192384/225000 (86%)] Loss: 19646.183594\n",
      "Train Epoch: 81 [194880/225000 (87%)] Loss: 19753.125000\n",
      "Train Epoch: 81 [197376/225000 (88%)] Loss: 20062.890625\n",
      "Train Epoch: 81 [199872/225000 (89%)] Loss: 19788.093750\n",
      "Train Epoch: 81 [202368/225000 (90%)] Loss: 19214.304688\n",
      "Train Epoch: 81 [204864/225000 (91%)] Loss: 19403.546875\n",
      "Train Epoch: 81 [207360/225000 (92%)] Loss: 19697.912109\n",
      "Train Epoch: 81 [209856/225000 (93%)] Loss: 19723.994141\n",
      "Train Epoch: 81 [212352/225000 (94%)] Loss: 19459.609375\n",
      "Train Epoch: 81 [214848/225000 (95%)] Loss: 19845.628906\n",
      "Train Epoch: 81 [217344/225000 (97%)] Loss: 19418.927734\n",
      "Train Epoch: 81 [219840/225000 (98%)] Loss: 19376.933594\n",
      "Train Epoch: 81 [222336/225000 (99%)] Loss: 19744.732422\n",
      "Train Epoch: 81 [224832/225000 (100%)] Loss: 18891.572266\n",
      "    epoch          : 81\n",
      "    loss           : 19665.750079991467\n",
      "    val_loss       : 19560.757710578786\n",
      "Train Epoch: 82 [192/225000 (0%)] Loss: 19599.642578\n",
      "Train Epoch: 82 [2688/225000 (1%)] Loss: 19583.210938\n",
      "Train Epoch: 82 [5184/225000 (2%)] Loss: 20382.980469\n",
      "Train Epoch: 82 [7680/225000 (3%)] Loss: 19610.417969\n",
      "Train Epoch: 82 [10176/225000 (5%)] Loss: 19544.175781\n",
      "Train Epoch: 82 [12672/225000 (6%)] Loss: 19908.875000\n",
      "Train Epoch: 82 [15168/225000 (7%)] Loss: 19599.730469\n",
      "Train Epoch: 82 [17664/225000 (8%)] Loss: 19512.320312\n",
      "Train Epoch: 82 [20160/225000 (9%)] Loss: 19593.621094\n",
      "Train Epoch: 82 [22656/225000 (10%)] Loss: 19447.167969\n",
      "Train Epoch: 82 [25152/225000 (11%)] Loss: 19853.796875\n",
      "Train Epoch: 82 [27648/225000 (12%)] Loss: 20357.146484\n",
      "Train Epoch: 82 [30144/225000 (13%)] Loss: 19466.001953\n",
      "Train Epoch: 82 [32640/225000 (15%)] Loss: 19713.242188\n",
      "Train Epoch: 82 [35136/225000 (16%)] Loss: 19713.414062\n",
      "Train Epoch: 82 [37632/225000 (17%)] Loss: 19563.429688\n",
      "Train Epoch: 82 [40128/225000 (18%)] Loss: 19746.902344\n",
      "Train Epoch: 82 [42624/225000 (19%)] Loss: 19511.933594\n",
      "Train Epoch: 82 [45120/225000 (20%)] Loss: 19726.144531\n",
      "Train Epoch: 82 [47616/225000 (21%)] Loss: 19503.941406\n",
      "Train Epoch: 82 [50112/225000 (22%)] Loss: 19700.332031\n",
      "Train Epoch: 82 [52608/225000 (23%)] Loss: 19292.410156\n",
      "Train Epoch: 82 [55104/225000 (24%)] Loss: 19623.984375\n",
      "Train Epoch: 82 [57600/225000 (26%)] Loss: 19564.880859\n",
      "Train Epoch: 82 [60096/225000 (27%)] Loss: 20003.369141\n",
      "Train Epoch: 82 [62592/225000 (28%)] Loss: 19482.433594\n",
      "Train Epoch: 82 [65088/225000 (29%)] Loss: 19877.207031\n",
      "Train Epoch: 82 [67584/225000 (30%)] Loss: 19695.917969\n",
      "Train Epoch: 82 [70080/225000 (31%)] Loss: 18918.437500\n",
      "Train Epoch: 82 [72576/225000 (32%)] Loss: 19452.648438\n",
      "Train Epoch: 82 [75072/225000 (33%)] Loss: 19461.816406\n",
      "Train Epoch: 82 [77568/225000 (34%)] Loss: 19060.273438\n",
      "Train Epoch: 82 [80064/225000 (36%)] Loss: 19631.156250\n",
      "Train Epoch: 82 [82560/225000 (37%)] Loss: 19643.373047\n",
      "Train Epoch: 82 [85056/225000 (38%)] Loss: 19468.837891\n",
      "Train Epoch: 82 [87552/225000 (39%)] Loss: 19493.476562\n",
      "Train Epoch: 82 [90048/225000 (40%)] Loss: 19564.164062\n",
      "Train Epoch: 82 [92544/225000 (41%)] Loss: 19622.216797\n",
      "Train Epoch: 82 [95040/225000 (42%)] Loss: 19599.863281\n",
      "Train Epoch: 82 [97536/225000 (43%)] Loss: 19522.814453\n",
      "Train Epoch: 82 [100032/225000 (44%)] Loss: 19694.316406\n",
      "Train Epoch: 82 [102528/225000 (46%)] Loss: 19744.683594\n",
      "Train Epoch: 82 [105024/225000 (47%)] Loss: 19700.265625\n",
      "Train Epoch: 82 [107520/225000 (48%)] Loss: 19711.378906\n",
      "Train Epoch: 82 [110016/225000 (49%)] Loss: 19493.527344\n",
      "Train Epoch: 82 [112512/225000 (50%)] Loss: 19302.875000\n",
      "Train Epoch: 82 [115008/225000 (51%)] Loss: 19844.011719\n",
      "Train Epoch: 82 [117504/225000 (52%)] Loss: 19691.316406\n",
      "Train Epoch: 82 [120000/225000 (53%)] Loss: 19412.007812\n",
      "Train Epoch: 82 [122496/225000 (54%)] Loss: 20019.167969\n",
      "Train Epoch: 82 [124992/225000 (56%)] Loss: 19767.968750\n",
      "Train Epoch: 82 [127488/225000 (57%)] Loss: 19622.494141\n",
      "Train Epoch: 82 [129984/225000 (58%)] Loss: 19851.837891\n",
      "Train Epoch: 82 [132480/225000 (59%)] Loss: 19918.396484\n",
      "Train Epoch: 82 [134976/225000 (60%)] Loss: 19409.058594\n",
      "Train Epoch: 82 [137472/225000 (61%)] Loss: 19779.943359\n",
      "Train Epoch: 82 [139968/225000 (62%)] Loss: 19528.742188\n",
      "Train Epoch: 82 [142464/225000 (63%)] Loss: 19731.117188\n",
      "Train Epoch: 82 [144960/225000 (64%)] Loss: 20128.734375\n",
      "Train Epoch: 82 [147456/225000 (66%)] Loss: 19746.226562\n",
      "Train Epoch: 82 [149952/225000 (67%)] Loss: 19816.828125\n",
      "Train Epoch: 82 [152448/225000 (68%)] Loss: 19366.765625\n",
      "Train Epoch: 82 [154944/225000 (69%)] Loss: 19707.160156\n",
      "Train Epoch: 82 [157440/225000 (70%)] Loss: 19768.529297\n",
      "Train Epoch: 82 [159936/225000 (71%)] Loss: 19389.699219\n",
      "Train Epoch: 82 [162432/225000 (72%)] Loss: 19960.302734\n",
      "Train Epoch: 82 [164928/225000 (73%)] Loss: 20113.578125\n",
      "Train Epoch: 82 [167424/225000 (74%)] Loss: 19894.361328\n",
      "Train Epoch: 82 [169920/225000 (76%)] Loss: 19634.902344\n",
      "Train Epoch: 82 [172416/225000 (77%)] Loss: 19737.066406\n",
      "Train Epoch: 82 [174912/225000 (78%)] Loss: 19537.031250\n",
      "Train Epoch: 82 [177408/225000 (79%)] Loss: 19528.300781\n",
      "Train Epoch: 82 [179904/225000 (80%)] Loss: 19304.513672\n",
      "Train Epoch: 82 [182400/225000 (81%)] Loss: 20015.373047\n",
      "Train Epoch: 82 [184896/225000 (82%)] Loss: 19363.230469\n",
      "Train Epoch: 82 [187392/225000 (83%)] Loss: 19253.562500\n",
      "Train Epoch: 82 [189888/225000 (84%)] Loss: 19506.023438\n",
      "Train Epoch: 82 [192384/225000 (86%)] Loss: 19602.656250\n",
      "Train Epoch: 82 [194880/225000 (87%)] Loss: 19950.750000\n",
      "Train Epoch: 82 [197376/225000 (88%)] Loss: 20262.687500\n",
      "Train Epoch: 82 [199872/225000 (89%)] Loss: 19398.746094\n",
      "Train Epoch: 82 [202368/225000 (90%)] Loss: 19238.033203\n",
      "Train Epoch: 82 [204864/225000 (91%)] Loss: 19777.343750\n",
      "Train Epoch: 82 [207360/225000 (92%)] Loss: 19522.566406\n",
      "Train Epoch: 82 [209856/225000 (93%)] Loss: 19556.257812\n",
      "Train Epoch: 82 [212352/225000 (94%)] Loss: 19624.230469\n",
      "Train Epoch: 82 [214848/225000 (95%)] Loss: 19691.097656\n",
      "Train Epoch: 82 [217344/225000 (97%)] Loss: 19662.644531\n",
      "Train Epoch: 82 [219840/225000 (98%)] Loss: 19536.468750\n",
      "Train Epoch: 82 [222336/225000 (99%)] Loss: 19565.082031\n",
      "Train Epoch: 82 [224832/225000 (100%)] Loss: 19923.839844\n",
      "    epoch          : 82\n",
      "    loss           : 19667.338828858254\n",
      "    val_loss       : 19670.10195211964\n",
      "Train Epoch: 83 [192/225000 (0%)] Loss: 19877.867188\n",
      "Train Epoch: 83 [2688/225000 (1%)] Loss: 19413.466797\n",
      "Train Epoch: 83 [5184/225000 (2%)] Loss: 20110.826172\n",
      "Train Epoch: 83 [7680/225000 (3%)] Loss: 19464.820312\n",
      "Train Epoch: 83 [10176/225000 (5%)] Loss: 19507.339844\n",
      "Train Epoch: 83 [12672/225000 (6%)] Loss: 19602.019531\n",
      "Train Epoch: 83 [15168/225000 (7%)] Loss: 19496.988281\n",
      "Train Epoch: 83 [17664/225000 (8%)] Loss: 19881.722656\n",
      "Train Epoch: 83 [20160/225000 (9%)] Loss: 19799.140625\n",
      "Train Epoch: 83 [22656/225000 (10%)] Loss: 19758.121094\n",
      "Train Epoch: 83 [25152/225000 (11%)] Loss: 19666.992188\n",
      "Train Epoch: 83 [27648/225000 (12%)] Loss: 20272.804688\n",
      "Train Epoch: 83 [30144/225000 (13%)] Loss: 19746.757812\n",
      "Train Epoch: 83 [32640/225000 (15%)] Loss: 20064.765625\n",
      "Train Epoch: 83 [35136/225000 (16%)] Loss: 19849.425781\n",
      "Train Epoch: 83 [37632/225000 (17%)] Loss: 19428.718750\n",
      "Train Epoch: 83 [40128/225000 (18%)] Loss: 19719.988281\n",
      "Train Epoch: 83 [42624/225000 (19%)] Loss: 19110.800781\n",
      "Train Epoch: 83 [45120/225000 (20%)] Loss: 19511.378906\n",
      "Train Epoch: 83 [47616/225000 (21%)] Loss: 19616.425781\n",
      "Train Epoch: 83 [50112/225000 (22%)] Loss: 19430.855469\n",
      "Train Epoch: 83 [52608/225000 (23%)] Loss: 19578.351562\n",
      "Train Epoch: 83 [55104/225000 (24%)] Loss: 19196.582031\n",
      "Train Epoch: 83 [57600/225000 (26%)] Loss: 20051.343750\n",
      "Train Epoch: 83 [60096/225000 (27%)] Loss: 19294.851562\n",
      "Train Epoch: 83 [62592/225000 (28%)] Loss: 20070.960938\n",
      "Train Epoch: 83 [65088/225000 (29%)] Loss: 19969.011719\n",
      "Train Epoch: 83 [67584/225000 (30%)] Loss: 20189.462891\n",
      "Train Epoch: 83 [70080/225000 (31%)] Loss: 19621.378906\n",
      "Train Epoch: 83 [72576/225000 (32%)] Loss: 19658.011719\n",
      "Train Epoch: 83 [75072/225000 (33%)] Loss: 20002.683594\n",
      "Train Epoch: 83 [77568/225000 (34%)] Loss: 19101.933594\n",
      "Train Epoch: 83 [80064/225000 (36%)] Loss: 19572.503906\n",
      "Train Epoch: 83 [82560/225000 (37%)] Loss: 20013.308594\n",
      "Train Epoch: 83 [85056/225000 (38%)] Loss: 19462.585938\n",
      "Train Epoch: 83 [87552/225000 (39%)] Loss: 19821.085938\n",
      "Train Epoch: 83 [90048/225000 (40%)] Loss: 18822.939453\n",
      "Train Epoch: 83 [92544/225000 (41%)] Loss: 19823.332031\n",
      "Train Epoch: 83 [95040/225000 (42%)] Loss: 19549.626953\n",
      "Train Epoch: 83 [97536/225000 (43%)] Loss: 19469.757812\n",
      "Train Epoch: 83 [100032/225000 (44%)] Loss: 19844.265625\n",
      "Train Epoch: 83 [102528/225000 (46%)] Loss: 19549.722656\n",
      "Train Epoch: 83 [105024/225000 (47%)] Loss: 19485.808594\n",
      "Train Epoch: 83 [107520/225000 (48%)] Loss: 19598.218750\n",
      "Train Epoch: 83 [110016/225000 (49%)] Loss: 19439.816406\n",
      "Train Epoch: 83 [112512/225000 (50%)] Loss: 19156.453125\n",
      "Train Epoch: 83 [115008/225000 (51%)] Loss: 19588.601562\n",
      "Train Epoch: 83 [117504/225000 (52%)] Loss: 19787.791016\n",
      "Train Epoch: 83 [120000/225000 (53%)] Loss: 19765.683594\n",
      "Train Epoch: 83 [122496/225000 (54%)] Loss: 19572.925781\n",
      "Train Epoch: 83 [124992/225000 (56%)] Loss: 19659.664062\n",
      "Train Epoch: 83 [127488/225000 (57%)] Loss: 18866.166016\n",
      "Train Epoch: 83 [129984/225000 (58%)] Loss: 19730.402344\n",
      "Train Epoch: 83 [132480/225000 (59%)] Loss: 19853.960938\n",
      "Train Epoch: 83 [134976/225000 (60%)] Loss: 19836.007812\n",
      "Train Epoch: 83 [137472/225000 (61%)] Loss: 19232.238281\n",
      "Train Epoch: 83 [139968/225000 (62%)] Loss: 20035.253906\n",
      "Train Epoch: 83 [142464/225000 (63%)] Loss: 19442.783203\n",
      "Train Epoch: 83 [144960/225000 (64%)] Loss: 19794.355469\n",
      "Train Epoch: 83 [147456/225000 (66%)] Loss: 19870.003906\n",
      "Train Epoch: 83 [149952/225000 (67%)] Loss: 19289.457031\n",
      "Train Epoch: 83 [152448/225000 (68%)] Loss: 19565.230469\n",
      "Train Epoch: 83 [154944/225000 (69%)] Loss: 19741.500000\n",
      "Train Epoch: 83 [157440/225000 (70%)] Loss: 19392.347656\n",
      "Train Epoch: 83 [159936/225000 (71%)] Loss: 19829.410156\n",
      "Train Epoch: 83 [162432/225000 (72%)] Loss: 19862.718750\n",
      "Train Epoch: 83 [164928/225000 (73%)] Loss: 19900.675781\n",
      "Train Epoch: 83 [167424/225000 (74%)] Loss: 19500.425781\n",
      "Train Epoch: 83 [169920/225000 (76%)] Loss: 19497.523438\n",
      "Train Epoch: 83 [172416/225000 (77%)] Loss: 19375.835938\n",
      "Train Epoch: 83 [174912/225000 (78%)] Loss: 19908.359375\n",
      "Train Epoch: 83 [177408/225000 (79%)] Loss: 19798.255859\n",
      "Train Epoch: 83 [179904/225000 (80%)] Loss: 19669.339844\n",
      "Train Epoch: 83 [182400/225000 (81%)] Loss: 19916.441406\n",
      "Train Epoch: 83 [184896/225000 (82%)] Loss: 19619.578125\n",
      "Train Epoch: 83 [187392/225000 (83%)] Loss: 19501.417969\n",
      "Train Epoch: 83 [189888/225000 (84%)] Loss: 19856.824219\n",
      "Train Epoch: 83 [192384/225000 (86%)] Loss: 19563.902344\n",
      "Train Epoch: 83 [194880/225000 (87%)] Loss: 19781.167969\n",
      "Train Epoch: 83 [197376/225000 (88%)] Loss: 19910.535156\n",
      "Train Epoch: 83 [199872/225000 (89%)] Loss: 19244.652344\n",
      "Train Epoch: 83 [202368/225000 (90%)] Loss: 19311.101562\n",
      "Train Epoch: 83 [204864/225000 (91%)] Loss: 19541.843750\n",
      "Train Epoch: 83 [207360/225000 (92%)] Loss: 19314.162109\n",
      "Train Epoch: 83 [209856/225000 (93%)] Loss: 19837.847656\n",
      "Train Epoch: 83 [212352/225000 (94%)] Loss: 19722.250000\n",
      "Train Epoch: 83 [214848/225000 (95%)] Loss: 19443.169922\n",
      "Train Epoch: 83 [217344/225000 (97%)] Loss: 19983.425781\n",
      "Train Epoch: 83 [219840/225000 (98%)] Loss: 20238.478516\n",
      "Train Epoch: 83 [222336/225000 (99%)] Loss: 19442.367188\n",
      "Train Epoch: 83 [224832/225000 (100%)] Loss: 19616.839844\n",
      "    epoch          : 83\n",
      "    loss           : 19651.666927194434\n",
      "    val_loss       : 19544.809414092822\n",
      "Train Epoch: 84 [192/225000 (0%)] Loss: 19403.521484\n",
      "Train Epoch: 84 [2688/225000 (1%)] Loss: 19607.675781\n",
      "Train Epoch: 84 [5184/225000 (2%)] Loss: 19288.324219\n",
      "Train Epoch: 84 [7680/225000 (3%)] Loss: 19480.212891\n",
      "Train Epoch: 84 [10176/225000 (5%)] Loss: 19695.523438\n",
      "Train Epoch: 84 [12672/225000 (6%)] Loss: 19137.585938\n",
      "Train Epoch: 84 [15168/225000 (7%)] Loss: 19583.332031\n",
      "Train Epoch: 84 [17664/225000 (8%)] Loss: 19720.062500\n",
      "Train Epoch: 84 [20160/225000 (9%)] Loss: 19741.777344\n",
      "Train Epoch: 84 [22656/225000 (10%)] Loss: 19253.781250\n",
      "Train Epoch: 84 [25152/225000 (11%)] Loss: 19467.626953\n",
      "Train Epoch: 84 [27648/225000 (12%)] Loss: 19941.406250\n",
      "Train Epoch: 84 [30144/225000 (13%)] Loss: 19586.789062\n",
      "Train Epoch: 84 [32640/225000 (15%)] Loss: 20153.148438\n",
      "Train Epoch: 84 [35136/225000 (16%)] Loss: 19750.134766\n",
      "Train Epoch: 84 [37632/225000 (17%)] Loss: 19185.312500\n",
      "Train Epoch: 84 [40128/225000 (18%)] Loss: 19824.832031\n",
      "Train Epoch: 84 [42624/225000 (19%)] Loss: 20025.000000\n",
      "Train Epoch: 84 [45120/225000 (20%)] Loss: 19524.966797\n",
      "Train Epoch: 84 [47616/225000 (21%)] Loss: 19453.769531\n",
      "Train Epoch: 84 [50112/225000 (22%)] Loss: 19965.277344\n",
      "Train Epoch: 84 [52608/225000 (23%)] Loss: 19383.173828\n",
      "Train Epoch: 84 [55104/225000 (24%)] Loss: 19725.488281\n",
      "Train Epoch: 84 [57600/225000 (26%)] Loss: 19417.626953\n",
      "Train Epoch: 84 [60096/225000 (27%)] Loss: 19772.585938\n",
      "Train Epoch: 84 [62592/225000 (28%)] Loss: 20176.859375\n",
      "Train Epoch: 84 [65088/225000 (29%)] Loss: 19748.111328\n",
      "Train Epoch: 84 [67584/225000 (30%)] Loss: 20080.578125\n",
      "Train Epoch: 84 [70080/225000 (31%)] Loss: 19032.726562\n",
      "Train Epoch: 84 [72576/225000 (32%)] Loss: 19545.621094\n",
      "Train Epoch: 84 [75072/225000 (33%)] Loss: 19911.687500\n",
      "Train Epoch: 84 [77568/225000 (34%)] Loss: 19733.033203\n",
      "Train Epoch: 84 [80064/225000 (36%)] Loss: 18958.839844\n",
      "Train Epoch: 84 [82560/225000 (37%)] Loss: 19748.921875\n",
      "Train Epoch: 84 [85056/225000 (38%)] Loss: 19667.429688\n",
      "Train Epoch: 84 [87552/225000 (39%)] Loss: 19772.277344\n",
      "Train Epoch: 84 [90048/225000 (40%)] Loss: 20327.683594\n",
      "Train Epoch: 84 [92544/225000 (41%)] Loss: 19807.406250\n",
      "Train Epoch: 84 [95040/225000 (42%)] Loss: 19810.828125\n",
      "Train Epoch: 84 [97536/225000 (43%)] Loss: 19053.001953\n",
      "Train Epoch: 84 [100032/225000 (44%)] Loss: 19811.830078\n",
      "Train Epoch: 84 [102528/225000 (46%)] Loss: 19553.242188\n",
      "Train Epoch: 84 [105024/225000 (47%)] Loss: 19751.636719\n",
      "Train Epoch: 84 [107520/225000 (48%)] Loss: 19297.259766\n",
      "Train Epoch: 84 [110016/225000 (49%)] Loss: 19978.193359\n",
      "Train Epoch: 84 [112512/225000 (50%)] Loss: 19512.208984\n",
      "Train Epoch: 84 [115008/225000 (51%)] Loss: 19529.039062\n",
      "Train Epoch: 84 [117504/225000 (52%)] Loss: 19859.396484\n",
      "Train Epoch: 84 [120000/225000 (53%)] Loss: 19725.449219\n",
      "Train Epoch: 84 [122496/225000 (54%)] Loss: 19388.308594\n",
      "Train Epoch: 84 [124992/225000 (56%)] Loss: 19626.867188\n",
      "Train Epoch: 84 [127488/225000 (57%)] Loss: 19407.191406\n",
      "Train Epoch: 84 [129984/225000 (58%)] Loss: 19643.642578\n",
      "Train Epoch: 84 [132480/225000 (59%)] Loss: 19520.921875\n",
      "Train Epoch: 84 [134976/225000 (60%)] Loss: 19734.621094\n",
      "Train Epoch: 84 [137472/225000 (61%)] Loss: 19408.140625\n",
      "Train Epoch: 84 [139968/225000 (62%)] Loss: 19172.861328\n",
      "Train Epoch: 84 [142464/225000 (63%)] Loss: 19559.162109\n",
      "Train Epoch: 84 [144960/225000 (64%)] Loss: 19720.445312\n",
      "Train Epoch: 84 [147456/225000 (66%)] Loss: 19901.494141\n",
      "Train Epoch: 84 [149952/225000 (67%)] Loss: 19059.921875\n",
      "Train Epoch: 84 [152448/225000 (68%)] Loss: 19344.953125\n",
      "Train Epoch: 84 [154944/225000 (69%)] Loss: 19946.445312\n",
      "Train Epoch: 84 [157440/225000 (70%)] Loss: 19390.992188\n",
      "Train Epoch: 84 [159936/225000 (71%)] Loss: 19499.531250\n",
      "Train Epoch: 84 [162432/225000 (72%)] Loss: 19794.996094\n",
      "Train Epoch: 84 [164928/225000 (73%)] Loss: 19511.062500\n",
      "Train Epoch: 84 [167424/225000 (74%)] Loss: 20087.785156\n",
      "Train Epoch: 84 [169920/225000 (76%)] Loss: 19522.041016\n",
      "Train Epoch: 84 [172416/225000 (77%)] Loss: 19783.628906\n",
      "Train Epoch: 84 [174912/225000 (78%)] Loss: 20135.248047\n",
      "Train Epoch: 84 [177408/225000 (79%)] Loss: 19066.666016\n",
      "Train Epoch: 84 [179904/225000 (80%)] Loss: 20111.343750\n",
      "Train Epoch: 84 [182400/225000 (81%)] Loss: 19761.574219\n",
      "Train Epoch: 84 [184896/225000 (82%)] Loss: 19741.722656\n",
      "Train Epoch: 84 [187392/225000 (83%)] Loss: 19376.648438\n",
      "Train Epoch: 84 [189888/225000 (84%)] Loss: 19199.132812\n",
      "Train Epoch: 84 [192384/225000 (86%)] Loss: 19164.876953\n",
      "Train Epoch: 84 [194880/225000 (87%)] Loss: 19233.216797\n",
      "Train Epoch: 84 [197376/225000 (88%)] Loss: 19527.156250\n",
      "Train Epoch: 84 [199872/225000 (89%)] Loss: 19493.521484\n",
      "Train Epoch: 84 [202368/225000 (90%)] Loss: 19634.580078\n",
      "Train Epoch: 84 [204864/225000 (91%)] Loss: 19452.441406\n",
      "Train Epoch: 84 [207360/225000 (92%)] Loss: 19697.056641\n",
      "Train Epoch: 84 [209856/225000 (93%)] Loss: 20035.224609\n",
      "Train Epoch: 84 [212352/225000 (94%)] Loss: 19633.296875\n",
      "Train Epoch: 84 [214848/225000 (95%)] Loss: 20094.707031\n",
      "Train Epoch: 84 [217344/225000 (97%)] Loss: 19834.957031\n",
      "Train Epoch: 84 [219840/225000 (98%)] Loss: 19692.039062\n",
      "Train Epoch: 84 [222336/225000 (99%)] Loss: 19880.925781\n",
      "Train Epoch: 84 [224832/225000 (100%)] Loss: 19822.324219\n",
      "    epoch          : 84\n",
      "    loss           : 19632.04470856442\n",
      "    val_loss       : 19540.946734406567\n",
      "Train Epoch: 85 [192/225000 (0%)] Loss: 19386.960938\n",
      "Train Epoch: 85 [2688/225000 (1%)] Loss: 19677.806641\n",
      "Train Epoch: 85 [5184/225000 (2%)] Loss: 19372.152344\n",
      "Train Epoch: 85 [7680/225000 (3%)] Loss: 19194.117188\n",
      "Train Epoch: 85 [10176/225000 (5%)] Loss: 19407.841797\n",
      "Train Epoch: 85 [12672/225000 (6%)] Loss: 19277.369141\n",
      "Train Epoch: 85 [15168/225000 (7%)] Loss: 19778.486328\n",
      "Train Epoch: 85 [17664/225000 (8%)] Loss: 19770.806641\n",
      "Train Epoch: 85 [20160/225000 (9%)] Loss: 19376.044922\n",
      "Train Epoch: 85 [22656/225000 (10%)] Loss: 19487.269531\n",
      "Train Epoch: 85 [25152/225000 (11%)] Loss: 19446.115234\n",
      "Train Epoch: 85 [27648/225000 (12%)] Loss: 19949.703125\n",
      "Train Epoch: 85 [30144/225000 (13%)] Loss: 19451.796875\n",
      "Train Epoch: 85 [32640/225000 (15%)] Loss: 19499.681641\n",
      "Train Epoch: 85 [35136/225000 (16%)] Loss: 19219.015625\n",
      "Train Epoch: 85 [37632/225000 (17%)] Loss: 19767.378906\n",
      "Train Epoch: 85 [40128/225000 (18%)] Loss: 19410.470703\n",
      "Train Epoch: 85 [42624/225000 (19%)] Loss: 19840.121094\n",
      "Train Epoch: 85 [45120/225000 (20%)] Loss: 19551.164062\n",
      "Train Epoch: 85 [47616/225000 (21%)] Loss: 19444.242188\n",
      "Train Epoch: 85 [50112/225000 (22%)] Loss: 19051.320312\n",
      "Train Epoch: 85 [52608/225000 (23%)] Loss: 19611.207031\n",
      "Train Epoch: 85 [55104/225000 (24%)] Loss: 19581.177734\n",
      "Train Epoch: 85 [57600/225000 (26%)] Loss: 19408.957031\n",
      "Train Epoch: 85 [60096/225000 (27%)] Loss: 19711.742188\n",
      "Train Epoch: 85 [62592/225000 (28%)] Loss: 19259.007812\n",
      "Train Epoch: 85 [65088/225000 (29%)] Loss: 20009.921875\n",
      "Train Epoch: 85 [67584/225000 (30%)] Loss: 19672.476562\n",
      "Train Epoch: 85 [70080/225000 (31%)] Loss: 20251.386719\n",
      "Train Epoch: 85 [72576/225000 (32%)] Loss: 20188.781250\n",
      "Train Epoch: 85 [75072/225000 (33%)] Loss: 19373.882812\n",
      "Train Epoch: 85 [77568/225000 (34%)] Loss: 19913.308594\n",
      "Train Epoch: 85 [80064/225000 (36%)] Loss: 19463.587891\n",
      "Train Epoch: 85 [82560/225000 (37%)] Loss: 20140.992188\n",
      "Train Epoch: 85 [85056/225000 (38%)] Loss: 19803.117188\n",
      "Train Epoch: 85 [87552/225000 (39%)] Loss: 19478.503906\n",
      "Train Epoch: 85 [90048/225000 (40%)] Loss: 19641.080078\n",
      "Train Epoch: 85 [92544/225000 (41%)] Loss: 19288.382812\n",
      "Train Epoch: 85 [95040/225000 (42%)] Loss: 19384.222656\n",
      "Train Epoch: 85 [97536/225000 (43%)] Loss: 19736.582031\n",
      "Train Epoch: 85 [100032/225000 (44%)] Loss: 19473.960938\n",
      "Train Epoch: 85 [102528/225000 (46%)] Loss: 20356.554688\n",
      "Train Epoch: 85 [105024/225000 (47%)] Loss: 19370.205078\n",
      "Train Epoch: 85 [107520/225000 (48%)] Loss: 19760.843750\n",
      "Train Epoch: 85 [110016/225000 (49%)] Loss: 19715.968750\n",
      "Train Epoch: 85 [112512/225000 (50%)] Loss: 20125.478516\n",
      "Train Epoch: 85 [115008/225000 (51%)] Loss: 19569.074219\n",
      "Train Epoch: 85 [117504/225000 (52%)] Loss: 19655.976562\n",
      "Train Epoch: 85 [120000/225000 (53%)] Loss: 19726.343750\n",
      "Train Epoch: 85 [122496/225000 (54%)] Loss: 19430.101562\n",
      "Train Epoch: 85 [124992/225000 (56%)] Loss: 20027.994141\n",
      "Train Epoch: 85 [127488/225000 (57%)] Loss: 20055.949219\n",
      "Train Epoch: 85 [129984/225000 (58%)] Loss: 18770.289062\n",
      "Train Epoch: 85 [132480/225000 (59%)] Loss: 19574.222656\n",
      "Train Epoch: 85 [134976/225000 (60%)] Loss: 20019.076172\n",
      "Train Epoch: 85 [137472/225000 (61%)] Loss: 19485.562500\n",
      "Train Epoch: 85 [139968/225000 (62%)] Loss: 19604.199219\n",
      "Train Epoch: 85 [142464/225000 (63%)] Loss: 19345.050781\n",
      "Train Epoch: 85 [144960/225000 (64%)] Loss: 19514.472656\n",
      "Train Epoch: 85 [147456/225000 (66%)] Loss: 19961.171875\n",
      "Train Epoch: 85 [149952/225000 (67%)] Loss: 19345.105469\n",
      "Train Epoch: 85 [152448/225000 (68%)] Loss: 20279.789062\n",
      "Train Epoch: 85 [154944/225000 (69%)] Loss: 19618.312500\n",
      "Train Epoch: 85 [157440/225000 (70%)] Loss: 19919.496094\n",
      "Train Epoch: 85 [159936/225000 (71%)] Loss: 19522.257812\n",
      "Train Epoch: 85 [162432/225000 (72%)] Loss: 19703.472656\n",
      "Train Epoch: 85 [164928/225000 (73%)] Loss: 19863.425781\n",
      "Train Epoch: 85 [167424/225000 (74%)] Loss: 19978.607422\n",
      "Train Epoch: 85 [169920/225000 (76%)] Loss: 19818.144531\n",
      "Train Epoch: 85 [172416/225000 (77%)] Loss: 19662.378906\n",
      "Train Epoch: 85 [174912/225000 (78%)] Loss: 20414.636719\n",
      "Train Epoch: 85 [177408/225000 (79%)] Loss: 19663.777344\n",
      "Train Epoch: 85 [179904/225000 (80%)] Loss: 19469.664062\n",
      "Train Epoch: 85 [182400/225000 (81%)] Loss: 19987.097656\n",
      "Train Epoch: 85 [184896/225000 (82%)] Loss: 19179.917969\n",
      "Train Epoch: 85 [187392/225000 (83%)] Loss: 19547.144531\n",
      "Train Epoch: 85 [189888/225000 (84%)] Loss: 19347.312500\n",
      "Train Epoch: 85 [192384/225000 (86%)] Loss: 19664.148438\n",
      "Train Epoch: 85 [194880/225000 (87%)] Loss: 19706.408203\n",
      "Train Epoch: 85 [197376/225000 (88%)] Loss: 19341.683594\n",
      "Train Epoch: 85 [199872/225000 (89%)] Loss: 19601.998047\n",
      "Train Epoch: 85 [202368/225000 (90%)] Loss: 19700.964844\n",
      "Train Epoch: 85 [204864/225000 (91%)] Loss: 19504.144531\n",
      "Train Epoch: 85 [207360/225000 (92%)] Loss: 19302.402344\n",
      "Train Epoch: 85 [209856/225000 (93%)] Loss: 19625.781250\n",
      "Train Epoch: 85 [212352/225000 (94%)] Loss: 19866.132812\n",
      "Train Epoch: 85 [214848/225000 (95%)] Loss: 19530.546875\n",
      "Train Epoch: 85 [217344/225000 (97%)] Loss: 19748.095703\n",
      "Train Epoch: 85 [219840/225000 (98%)] Loss: 20104.160156\n",
      "Train Epoch: 85 [222336/225000 (99%)] Loss: 19739.083984\n",
      "Train Epoch: 85 [224832/225000 (100%)] Loss: 19193.517578\n",
      "    epoch          : 85\n",
      "    loss           : 19633.17527463737\n",
      "    val_loss       : 19528.255709533474\n",
      "Train Epoch: 86 [192/225000 (0%)] Loss: 19638.470703\n",
      "Train Epoch: 86 [2688/225000 (1%)] Loss: 19876.089844\n",
      "Train Epoch: 86 [5184/225000 (2%)] Loss: 19271.429688\n",
      "Train Epoch: 86 [7680/225000 (3%)] Loss: 19130.945312\n",
      "Train Epoch: 86 [10176/225000 (5%)] Loss: 19652.921875\n",
      "Train Epoch: 86 [12672/225000 (6%)] Loss: 19534.175781\n",
      "Train Epoch: 86 [15168/225000 (7%)] Loss: 20212.453125\n",
      "Train Epoch: 86 [17664/225000 (8%)] Loss: 19431.242188\n",
      "Train Epoch: 86 [20160/225000 (9%)] Loss: 19339.898438\n",
      "Train Epoch: 86 [22656/225000 (10%)] Loss: 19810.503906\n",
      "Train Epoch: 86 [25152/225000 (11%)] Loss: 19198.835938\n",
      "Train Epoch: 86 [27648/225000 (12%)] Loss: 19708.945312\n",
      "Train Epoch: 86 [30144/225000 (13%)] Loss: 19172.693359\n",
      "Train Epoch: 86 [32640/225000 (15%)] Loss: 19373.316406\n",
      "Train Epoch: 86 [35136/225000 (16%)] Loss: 19644.914062\n",
      "Train Epoch: 86 [37632/225000 (17%)] Loss: 19082.601562\n",
      "Train Epoch: 86 [40128/225000 (18%)] Loss: 20085.726562\n",
      "Train Epoch: 86 [42624/225000 (19%)] Loss: 19558.046875\n",
      "Train Epoch: 86 [45120/225000 (20%)] Loss: 19952.867188\n",
      "Train Epoch: 86 [47616/225000 (21%)] Loss: 19941.746094\n",
      "Train Epoch: 86 [50112/225000 (22%)] Loss: 19962.712891\n",
      "Train Epoch: 86 [52608/225000 (23%)] Loss: 19231.531250\n",
      "Train Epoch: 86 [55104/225000 (24%)] Loss: 19607.515625\n",
      "Train Epoch: 86 [57600/225000 (26%)] Loss: 19794.484375\n",
      "Train Epoch: 86 [60096/225000 (27%)] Loss: 19427.179688\n",
      "Train Epoch: 86 [62592/225000 (28%)] Loss: 19773.421875\n",
      "Train Epoch: 86 [65088/225000 (29%)] Loss: 19706.546875\n",
      "Train Epoch: 86 [67584/225000 (30%)] Loss: 19350.613281\n",
      "Train Epoch: 86 [70080/225000 (31%)] Loss: 19473.367188\n",
      "Train Epoch: 86 [72576/225000 (32%)] Loss: 20079.046875\n",
      "Train Epoch: 86 [75072/225000 (33%)] Loss: 19337.851562\n",
      "Train Epoch: 86 [77568/225000 (34%)] Loss: 19620.863281\n",
      "Train Epoch: 86 [80064/225000 (36%)] Loss: 19133.308594\n",
      "Train Epoch: 86 [82560/225000 (37%)] Loss: 19590.000000\n",
      "Train Epoch: 86 [85056/225000 (38%)] Loss: 19718.664062\n",
      "Train Epoch: 86 [87552/225000 (39%)] Loss: 19151.824219\n",
      "Train Epoch: 86 [90048/225000 (40%)] Loss: 19680.203125\n",
      "Train Epoch: 86 [92544/225000 (41%)] Loss: 19630.226562\n",
      "Train Epoch: 86 [95040/225000 (42%)] Loss: 19330.226562\n",
      "Train Epoch: 86 [97536/225000 (43%)] Loss: 19537.562500\n",
      "Train Epoch: 86 [100032/225000 (44%)] Loss: 19643.960938\n",
      "Train Epoch: 86 [102528/225000 (46%)] Loss: 19480.380859\n",
      "Train Epoch: 86 [105024/225000 (47%)] Loss: 19672.339844\n",
      "Train Epoch: 86 [107520/225000 (48%)] Loss: 19356.984375\n",
      "Train Epoch: 86 [110016/225000 (49%)] Loss: 19411.011719\n",
      "Train Epoch: 86 [112512/225000 (50%)] Loss: 19540.708984\n",
      "Train Epoch: 86 [115008/225000 (51%)] Loss: 19452.166016\n",
      "Train Epoch: 86 [117504/225000 (52%)] Loss: 19870.291016\n",
      "Train Epoch: 86 [120000/225000 (53%)] Loss: 19675.351562\n",
      "Train Epoch: 86 [122496/225000 (54%)] Loss: 19433.384766\n",
      "Train Epoch: 86 [124992/225000 (56%)] Loss: 19346.238281\n",
      "Train Epoch: 86 [127488/225000 (57%)] Loss: 19677.962891\n",
      "Train Epoch: 86 [129984/225000 (58%)] Loss: 19292.878906\n",
      "Train Epoch: 86 [132480/225000 (59%)] Loss: 19602.062500\n",
      "Train Epoch: 86 [134976/225000 (60%)] Loss: 19801.886719\n",
      "Train Epoch: 86 [137472/225000 (61%)] Loss: 20015.570312\n",
      "Train Epoch: 86 [139968/225000 (62%)] Loss: 19573.074219\n",
      "Train Epoch: 86 [142464/225000 (63%)] Loss: 19691.937500\n",
      "Train Epoch: 86 [144960/225000 (64%)] Loss: 19761.816406\n",
      "Train Epoch: 86 [147456/225000 (66%)] Loss: 19287.742188\n",
      "Train Epoch: 86 [149952/225000 (67%)] Loss: 19929.033203\n",
      "Train Epoch: 86 [152448/225000 (68%)] Loss: 19291.347656\n",
      "Train Epoch: 86 [154944/225000 (69%)] Loss: 20195.683594\n",
      "Train Epoch: 86 [157440/225000 (70%)] Loss: 19525.660156\n",
      "Train Epoch: 86 [159936/225000 (71%)] Loss: 19481.921875\n",
      "Train Epoch: 86 [162432/225000 (72%)] Loss: 19456.460938\n",
      "Train Epoch: 86 [164928/225000 (73%)] Loss: 19295.373047\n",
      "Train Epoch: 86 [167424/225000 (74%)] Loss: 19600.722656\n",
      "Train Epoch: 86 [169920/225000 (76%)] Loss: 19548.792969\n",
      "Train Epoch: 86 [172416/225000 (77%)] Loss: 20104.558594\n",
      "Train Epoch: 86 [174912/225000 (78%)] Loss: 19759.363281\n",
      "Train Epoch: 86 [177408/225000 (79%)] Loss: 19765.265625\n",
      "Train Epoch: 86 [179904/225000 (80%)] Loss: 19977.285156\n",
      "Train Epoch: 86 [182400/225000 (81%)] Loss: 19605.617188\n",
      "Train Epoch: 86 [184896/225000 (82%)] Loss: 19187.316406\n",
      "Train Epoch: 86 [187392/225000 (83%)] Loss: 19990.746094\n",
      "Train Epoch: 86 [189888/225000 (84%)] Loss: 19838.873047\n",
      "Train Epoch: 86 [192384/225000 (86%)] Loss: 20057.015625\n",
      "Train Epoch: 86 [194880/225000 (87%)] Loss: 19703.378906\n",
      "Train Epoch: 86 [197376/225000 (88%)] Loss: 19674.312500\n",
      "Train Epoch: 86 [199872/225000 (89%)] Loss: 19316.222656\n",
      "Train Epoch: 86 [202368/225000 (90%)] Loss: 19629.173828\n",
      "Train Epoch: 86 [204864/225000 (91%)] Loss: 19643.511719\n",
      "Train Epoch: 86 [207360/225000 (92%)] Loss: 19819.947266\n",
      "Train Epoch: 86 [209856/225000 (93%)] Loss: 19534.220703\n",
      "Train Epoch: 86 [212352/225000 (94%)] Loss: 19303.609375\n",
      "Train Epoch: 86 [214848/225000 (95%)] Loss: 19508.128906\n",
      "Train Epoch: 86 [217344/225000 (97%)] Loss: 19459.554688\n",
      "Train Epoch: 86 [219840/225000 (98%)] Loss: 19826.871094\n",
      "Train Epoch: 86 [222336/225000 (99%)] Loss: 19293.902344\n",
      "Train Epoch: 86 [224832/225000 (100%)] Loss: 19571.539062\n",
      "    epoch          : 86\n",
      "    loss           : 19613.920755119452\n",
      "    val_loss       : 19517.996763928248\n",
      "Train Epoch: 87 [192/225000 (0%)] Loss: 19408.089844\n",
      "Train Epoch: 87 [2688/225000 (1%)] Loss: 19889.451172\n",
      "Train Epoch: 87 [5184/225000 (2%)] Loss: 19496.527344\n",
      "Train Epoch: 87 [7680/225000 (3%)] Loss: 19224.507812\n",
      "Train Epoch: 87 [10176/225000 (5%)] Loss: 19510.023438\n",
      "Train Epoch: 87 [12672/225000 (6%)] Loss: 19002.517578\n",
      "Train Epoch: 87 [15168/225000 (7%)] Loss: 19078.898438\n",
      "Train Epoch: 87 [17664/225000 (8%)] Loss: 18814.515625\n",
      "Train Epoch: 87 [20160/225000 (9%)] Loss: 19891.556641\n",
      "Train Epoch: 87 [22656/225000 (10%)] Loss: 19896.773438\n",
      "Train Epoch: 87 [25152/225000 (11%)] Loss: 19194.976562\n",
      "Train Epoch: 87 [27648/225000 (12%)] Loss: 18982.292969\n",
      "Train Epoch: 87 [30144/225000 (13%)] Loss: 19348.703125\n",
      "Train Epoch: 87 [32640/225000 (15%)] Loss: 19937.867188\n",
      "Train Epoch: 87 [35136/225000 (16%)] Loss: 19655.468750\n",
      "Train Epoch: 87 [37632/225000 (17%)] Loss: 19626.787109\n",
      "Train Epoch: 87 [40128/225000 (18%)] Loss: 19700.412109\n",
      "Train Epoch: 87 [42624/225000 (19%)] Loss: 19165.632812\n",
      "Train Epoch: 87 [45120/225000 (20%)] Loss: 19583.710938\n",
      "Train Epoch: 87 [47616/225000 (21%)] Loss: 19707.337891\n",
      "Train Epoch: 87 [50112/225000 (22%)] Loss: 19106.453125\n",
      "Train Epoch: 87 [52608/225000 (23%)] Loss: 19555.789062\n",
      "Train Epoch: 87 [55104/225000 (24%)] Loss: 19400.732422\n",
      "Train Epoch: 87 [57600/225000 (26%)] Loss: 19512.746094\n",
      "Train Epoch: 87 [60096/225000 (27%)] Loss: 19737.492188\n",
      "Train Epoch: 87 [62592/225000 (28%)] Loss: 19651.351562\n",
      "Train Epoch: 87 [65088/225000 (29%)] Loss: 19406.550781\n",
      "Train Epoch: 87 [67584/225000 (30%)] Loss: 19943.996094\n",
      "Train Epoch: 87 [70080/225000 (31%)] Loss: 19355.041016\n",
      "Train Epoch: 87 [72576/225000 (32%)] Loss: 19551.085938\n",
      "Train Epoch: 87 [75072/225000 (33%)] Loss: 19779.082031\n",
      "Train Epoch: 87 [77568/225000 (34%)] Loss: 19399.781250\n",
      "Train Epoch: 87 [80064/225000 (36%)] Loss: 19638.962891\n",
      "Train Epoch: 87 [82560/225000 (37%)] Loss: 19718.115234\n",
      "Train Epoch: 87 [85056/225000 (38%)] Loss: 19266.574219\n",
      "Train Epoch: 87 [87552/225000 (39%)] Loss: 20251.382812\n",
      "Train Epoch: 87 [90048/225000 (40%)] Loss: 19570.939453\n",
      "Train Epoch: 87 [92544/225000 (41%)] Loss: 18813.785156\n",
      "Train Epoch: 87 [95040/225000 (42%)] Loss: 19487.906250\n",
      "Train Epoch: 87 [97536/225000 (43%)] Loss: 20149.691406\n",
      "Train Epoch: 87 [100032/225000 (44%)] Loss: 19370.343750\n",
      "Train Epoch: 87 [102528/225000 (46%)] Loss: 19451.308594\n",
      "Train Epoch: 87 [105024/225000 (47%)] Loss: 19217.222656\n",
      "Train Epoch: 87 [107520/225000 (48%)] Loss: 19830.521484\n",
      "Train Epoch: 87 [110016/225000 (49%)] Loss: 19939.328125\n",
      "Train Epoch: 87 [112512/225000 (50%)] Loss: 20137.265625\n",
      "Train Epoch: 87 [115008/225000 (51%)] Loss: 19698.636719\n",
      "Train Epoch: 87 [117504/225000 (52%)] Loss: 19273.460938\n",
      "Train Epoch: 87 [120000/225000 (53%)] Loss: 20178.986328\n",
      "Train Epoch: 87 [122496/225000 (54%)] Loss: 19314.857422\n",
      "Train Epoch: 87 [124992/225000 (56%)] Loss: 19338.621094\n",
      "Train Epoch: 87 [127488/225000 (57%)] Loss: 19500.757812\n",
      "Train Epoch: 87 [129984/225000 (58%)] Loss: 19631.996094\n",
      "Train Epoch: 87 [132480/225000 (59%)] Loss: 19396.037109\n",
      "Train Epoch: 87 [134976/225000 (60%)] Loss: 19469.910156\n",
      "Train Epoch: 87 [137472/225000 (61%)] Loss: 19806.343750\n",
      "Train Epoch: 87 [139968/225000 (62%)] Loss: 19623.230469\n",
      "Train Epoch: 87 [142464/225000 (63%)] Loss: 19602.187500\n",
      "Train Epoch: 87 [144960/225000 (64%)] Loss: 19730.060547\n",
      "Train Epoch: 87 [147456/225000 (66%)] Loss: 19618.867188\n",
      "Train Epoch: 87 [149952/225000 (67%)] Loss: 19696.683594\n",
      "Train Epoch: 87 [152448/225000 (68%)] Loss: 20175.695312\n",
      "Train Epoch: 87 [154944/225000 (69%)] Loss: 19818.828125\n",
      "Train Epoch: 87 [157440/225000 (70%)] Loss: 19656.683594\n",
      "Train Epoch: 87 [159936/225000 (71%)] Loss: 20121.910156\n",
      "Train Epoch: 87 [162432/225000 (72%)] Loss: 19385.359375\n",
      "Train Epoch: 87 [164928/225000 (73%)] Loss: 19480.353516\n",
      "Train Epoch: 87 [167424/225000 (74%)] Loss: 19005.757812\n",
      "Train Epoch: 87 [169920/225000 (76%)] Loss: 19334.429688\n",
      "Train Epoch: 87 [172416/225000 (77%)] Loss: 19814.507812\n",
      "Train Epoch: 87 [174912/225000 (78%)] Loss: 19527.687500\n",
      "Train Epoch: 87 [177408/225000 (79%)] Loss: 19444.621094\n",
      "Train Epoch: 87 [179904/225000 (80%)] Loss: 19149.554688\n",
      "Train Epoch: 87 [182400/225000 (81%)] Loss: 19294.974609\n",
      "Train Epoch: 87 [184896/225000 (82%)] Loss: 19099.253906\n",
      "Train Epoch: 87 [187392/225000 (83%)] Loss: 19407.814453\n",
      "Train Epoch: 87 [189888/225000 (84%)] Loss: 19830.876953\n",
      "Train Epoch: 87 [192384/225000 (86%)] Loss: 19399.925781\n",
      "Train Epoch: 87 [194880/225000 (87%)] Loss: 19336.492188\n",
      "Train Epoch: 87 [197376/225000 (88%)] Loss: 19657.968750\n",
      "Train Epoch: 87 [199872/225000 (89%)] Loss: 19573.277344\n",
      "Train Epoch: 87 [202368/225000 (90%)] Loss: 20253.855469\n",
      "Train Epoch: 87 [204864/225000 (91%)] Loss: 19571.953125\n",
      "Train Epoch: 87 [207360/225000 (92%)] Loss: 19503.789062\n",
      "Train Epoch: 87 [209856/225000 (93%)] Loss: 19743.511719\n",
      "Train Epoch: 87 [212352/225000 (94%)] Loss: 19365.125000\n",
      "Train Epoch: 87 [214848/225000 (95%)] Loss: 19302.324219\n",
      "Train Epoch: 87 [217344/225000 (97%)] Loss: 19616.878906\n",
      "Train Epoch: 87 [219840/225000 (98%)] Loss: 19649.230469\n",
      "Train Epoch: 87 [222336/225000 (99%)] Loss: 19520.800781\n",
      "Train Epoch: 87 [224832/225000 (100%)] Loss: 19017.972656\n",
      "    epoch          : 87\n",
      "    loss           : 19624.15266538236\n",
      "    val_loss       : 19511.055648057514\n",
      "Train Epoch: 88 [192/225000 (0%)] Loss: 19455.080078\n",
      "Train Epoch: 88 [2688/225000 (1%)] Loss: 19860.480469\n",
      "Train Epoch: 88 [5184/225000 (2%)] Loss: 19201.734375\n",
      "Train Epoch: 88 [7680/225000 (3%)] Loss: 19228.464844\n",
      "Train Epoch: 88 [10176/225000 (5%)] Loss: 19892.789062\n",
      "Train Epoch: 88 [12672/225000 (6%)] Loss: 20141.650391\n",
      "Train Epoch: 88 [15168/225000 (7%)] Loss: 19799.718750\n",
      "Train Epoch: 88 [17664/225000 (8%)] Loss: 19836.515625\n",
      "Train Epoch: 88 [20160/225000 (9%)] Loss: 19682.246094\n",
      "Train Epoch: 88 [22656/225000 (10%)] Loss: 19400.269531\n",
      "Train Epoch: 88 [25152/225000 (11%)] Loss: 19323.109375\n",
      "Train Epoch: 88 [27648/225000 (12%)] Loss: 19309.755859\n",
      "Train Epoch: 88 [30144/225000 (13%)] Loss: 19760.136719\n",
      "Train Epoch: 88 [32640/225000 (15%)] Loss: 19939.515625\n",
      "Train Epoch: 88 [35136/225000 (16%)] Loss: 20226.585938\n",
      "Train Epoch: 88 [37632/225000 (17%)] Loss: 19784.742188\n",
      "Train Epoch: 88 [40128/225000 (18%)] Loss: 20196.437500\n",
      "Train Epoch: 88 [42624/225000 (19%)] Loss: 19680.703125\n",
      "Train Epoch: 88 [45120/225000 (20%)] Loss: 19582.777344\n",
      "Train Epoch: 88 [47616/225000 (21%)] Loss: 19361.308594\n",
      "Train Epoch: 88 [50112/225000 (22%)] Loss: 19117.476562\n",
      "Train Epoch: 88 [52608/225000 (23%)] Loss: 19607.865234\n",
      "Train Epoch: 88 [55104/225000 (24%)] Loss: 20053.878906\n",
      "Train Epoch: 88 [57600/225000 (26%)] Loss: 19346.628906\n",
      "Train Epoch: 88 [60096/225000 (27%)] Loss: 19614.191406\n",
      "Train Epoch: 88 [62592/225000 (28%)] Loss: 19551.472656\n",
      "Train Epoch: 88 [65088/225000 (29%)] Loss: 18905.363281\n",
      "Train Epoch: 88 [67584/225000 (30%)] Loss: 19848.802734\n",
      "Train Epoch: 88 [70080/225000 (31%)] Loss: 19816.710938\n",
      "Train Epoch: 88 [72576/225000 (32%)] Loss: 19481.802734\n",
      "Train Epoch: 88 [75072/225000 (33%)] Loss: 19787.410156\n",
      "Train Epoch: 88 [77568/225000 (34%)] Loss: 19576.128906\n",
      "Train Epoch: 88 [80064/225000 (36%)] Loss: 19811.167969\n",
      "Train Epoch: 88 [82560/225000 (37%)] Loss: 19426.156250\n",
      "Train Epoch: 88 [85056/225000 (38%)] Loss: 19329.009766\n",
      "Train Epoch: 88 [87552/225000 (39%)] Loss: 20190.460938\n",
      "Train Epoch: 88 [90048/225000 (40%)] Loss: 19949.625000\n",
      "Train Epoch: 88 [92544/225000 (41%)] Loss: 19410.519531\n",
      "Train Epoch: 88 [95040/225000 (42%)] Loss: 19410.076172\n",
      "Train Epoch: 88 [97536/225000 (43%)] Loss: 19324.121094\n",
      "Train Epoch: 88 [100032/225000 (44%)] Loss: 19682.101562\n",
      "Train Epoch: 88 [102528/225000 (46%)] Loss: 19293.261719\n",
      "Train Epoch: 88 [105024/225000 (47%)] Loss: 19995.234375\n",
      "Train Epoch: 88 [107520/225000 (48%)] Loss: 19990.236328\n",
      "Train Epoch: 88 [110016/225000 (49%)] Loss: 19702.070312\n",
      "Train Epoch: 88 [112512/225000 (50%)] Loss: 19670.273438\n",
      "Train Epoch: 88 [115008/225000 (51%)] Loss: 19776.351562\n",
      "Train Epoch: 88 [117504/225000 (52%)] Loss: 19895.250000\n",
      "Train Epoch: 88 [120000/225000 (53%)] Loss: 19832.169922\n",
      "Train Epoch: 88 [122496/225000 (54%)] Loss: 19554.810547\n",
      "Train Epoch: 88 [124992/225000 (56%)] Loss: 19416.792969\n",
      "Train Epoch: 88 [127488/225000 (57%)] Loss: 19522.050781\n",
      "Train Epoch: 88 [129984/225000 (58%)] Loss: 19147.238281\n",
      "Train Epoch: 88 [132480/225000 (59%)] Loss: 19223.847656\n",
      "Train Epoch: 88 [134976/225000 (60%)] Loss: 19860.851562\n",
      "Train Epoch: 88 [137472/225000 (61%)] Loss: 19928.976562\n",
      "Train Epoch: 88 [139968/225000 (62%)] Loss: 19275.296875\n",
      "Train Epoch: 88 [142464/225000 (63%)] Loss: 19414.011719\n",
      "Train Epoch: 88 [144960/225000 (64%)] Loss: 19263.623047\n",
      "Train Epoch: 88 [147456/225000 (66%)] Loss: 20034.697266\n",
      "Train Epoch: 88 [149952/225000 (67%)] Loss: 19633.863281\n",
      "Train Epoch: 88 [152448/225000 (68%)] Loss: 19192.246094\n",
      "Train Epoch: 88 [154944/225000 (69%)] Loss: 19312.261719\n",
      "Train Epoch: 88 [157440/225000 (70%)] Loss: 19048.298828\n",
      "Train Epoch: 88 [159936/225000 (71%)] Loss: 19682.578125\n",
      "Train Epoch: 88 [162432/225000 (72%)] Loss: 19659.015625\n",
      "Train Epoch: 88 [164928/225000 (73%)] Loss: 19346.562500\n",
      "Train Epoch: 88 [167424/225000 (74%)] Loss: 19633.730469\n",
      "Train Epoch: 88 [169920/225000 (76%)] Loss: 19594.515625\n",
      "Train Epoch: 88 [172416/225000 (77%)] Loss: 19998.460938\n",
      "Train Epoch: 88 [174912/225000 (78%)] Loss: 19578.712891\n",
      "Train Epoch: 88 [177408/225000 (79%)] Loss: 19223.402344\n",
      "Train Epoch: 88 [179904/225000 (80%)] Loss: 19259.007812\n",
      "Train Epoch: 88 [182400/225000 (81%)] Loss: 19985.355469\n",
      "Train Epoch: 88 [184896/225000 (82%)] Loss: 19664.378906\n",
      "Train Epoch: 88 [187392/225000 (83%)] Loss: 19497.656250\n",
      "Train Epoch: 88 [189888/225000 (84%)] Loss: 19373.445312\n",
      "Train Epoch: 88 [192384/225000 (86%)] Loss: 19312.648438\n",
      "Train Epoch: 88 [194880/225000 (87%)] Loss: 19295.646484\n",
      "Train Epoch: 88 [197376/225000 (88%)] Loss: 19209.048828\n",
      "Train Epoch: 88 [199872/225000 (89%)] Loss: 19112.619141\n",
      "Train Epoch: 88 [202368/225000 (90%)] Loss: 19476.865234\n",
      "Train Epoch: 88 [204864/225000 (91%)] Loss: 19560.687500\n",
      "Train Epoch: 88 [207360/225000 (92%)] Loss: 19362.863281\n",
      "Train Epoch: 88 [209856/225000 (93%)] Loss: 20287.914062\n",
      "Train Epoch: 88 [212352/225000 (94%)] Loss: 19171.099609\n",
      "Train Epoch: 88 [214848/225000 (95%)] Loss: 19423.787109\n",
      "Train Epoch: 88 [217344/225000 (97%)] Loss: 19805.234375\n",
      "Train Epoch: 88 [219840/225000 (98%)] Loss: 19233.013672\n",
      "Train Epoch: 88 [222336/225000 (99%)] Loss: 19954.046875\n",
      "Train Epoch: 88 [224832/225000 (100%)] Loss: 20088.671875\n",
      "    epoch          : 88\n",
      "    loss           : 19605.30499580045\n",
      "    val_loss       : 19490.79204581166\n",
      "Train Epoch: 89 [192/225000 (0%)] Loss: 19624.560547\n",
      "Train Epoch: 89 [2688/225000 (1%)] Loss: 19187.859375\n",
      "Train Epoch: 89 [5184/225000 (2%)] Loss: 19939.289062\n",
      "Train Epoch: 89 [7680/225000 (3%)] Loss: 19850.046875\n",
      "Train Epoch: 89 [10176/225000 (5%)] Loss: 19659.683594\n",
      "Train Epoch: 89 [12672/225000 (6%)] Loss: 19540.714844\n",
      "Train Epoch: 89 [15168/225000 (7%)] Loss: 19092.500000\n",
      "Train Epoch: 89 [17664/225000 (8%)] Loss: 19425.855469\n",
      "Train Epoch: 89 [20160/225000 (9%)] Loss: 19268.183594\n",
      "Train Epoch: 89 [22656/225000 (10%)] Loss: 20059.419922\n",
      "Train Epoch: 89 [25152/225000 (11%)] Loss: 19490.988281\n",
      "Train Epoch: 89 [27648/225000 (12%)] Loss: 19042.085938\n",
      "Train Epoch: 89 [30144/225000 (13%)] Loss: 19495.238281\n",
      "Train Epoch: 89 [32640/225000 (15%)] Loss: 19285.566406\n",
      "Train Epoch: 89 [35136/225000 (16%)] Loss: 19188.333984\n",
      "Train Epoch: 89 [37632/225000 (17%)] Loss: 19301.300781\n",
      "Train Epoch: 89 [40128/225000 (18%)] Loss: 19800.589844\n",
      "Train Epoch: 89 [42624/225000 (19%)] Loss: 19237.800781\n",
      "Train Epoch: 89 [45120/225000 (20%)] Loss: 19109.125000\n",
      "Train Epoch: 89 [47616/225000 (21%)] Loss: 19538.195312\n",
      "Train Epoch: 89 [50112/225000 (22%)] Loss: 19454.714844\n",
      "Train Epoch: 89 [52608/225000 (23%)] Loss: 19944.179688\n",
      "Train Epoch: 89 [55104/225000 (24%)] Loss: 19491.132812\n",
      "Train Epoch: 89 [57600/225000 (26%)] Loss: 19773.609375\n",
      "Train Epoch: 89 [60096/225000 (27%)] Loss: 19511.222656\n",
      "Train Epoch: 89 [62592/225000 (28%)] Loss: 19329.800781\n",
      "Train Epoch: 89 [65088/225000 (29%)] Loss: 20086.789062\n",
      "Train Epoch: 89 [67584/225000 (30%)] Loss: 19455.250000\n",
      "Train Epoch: 89 [70080/225000 (31%)] Loss: 19779.542969\n",
      "Train Epoch: 89 [72576/225000 (32%)] Loss: 20081.464844\n",
      "Train Epoch: 89 [75072/225000 (33%)] Loss: 19481.460938\n",
      "Train Epoch: 89 [77568/225000 (34%)] Loss: 19424.894531\n",
      "Train Epoch: 89 [80064/225000 (36%)] Loss: 19244.587891\n",
      "Train Epoch: 89 [82560/225000 (37%)] Loss: 19314.955078\n",
      "Train Epoch: 89 [85056/225000 (38%)] Loss: 19237.886719\n",
      "Train Epoch: 89 [87552/225000 (39%)] Loss: 19656.496094\n",
      "Train Epoch: 89 [90048/225000 (40%)] Loss: 19624.265625\n",
      "Train Epoch: 89 [92544/225000 (41%)] Loss: 19608.035156\n",
      "Train Epoch: 89 [95040/225000 (42%)] Loss: 19387.820312\n",
      "Train Epoch: 89 [97536/225000 (43%)] Loss: 19900.873047\n",
      "Train Epoch: 89 [100032/225000 (44%)] Loss: 19203.042969\n",
      "Train Epoch: 89 [102528/225000 (46%)] Loss: 19466.050781\n",
      "Train Epoch: 89 [105024/225000 (47%)] Loss: 19886.820312\n",
      "Train Epoch: 89 [107520/225000 (48%)] Loss: 20119.054688\n",
      "Train Epoch: 89 [110016/225000 (49%)] Loss: 19377.773438\n",
      "Train Epoch: 89 [112512/225000 (50%)] Loss: 20278.875000\n",
      "Train Epoch: 89 [115008/225000 (51%)] Loss: 19359.792969\n",
      "Train Epoch: 89 [117504/225000 (52%)] Loss: 19945.203125\n",
      "Train Epoch: 89 [120000/225000 (53%)] Loss: 19781.937500\n",
      "Train Epoch: 89 [122496/225000 (54%)] Loss: 19783.890625\n",
      "Train Epoch: 89 [124992/225000 (56%)] Loss: 19795.103516\n",
      "Train Epoch: 89 [127488/225000 (57%)] Loss: 19359.554688\n",
      "Train Epoch: 89 [129984/225000 (58%)] Loss: 19390.984375\n",
      "Train Epoch: 89 [132480/225000 (59%)] Loss: 19432.980469\n",
      "Train Epoch: 89 [134976/225000 (60%)] Loss: 20053.679688\n",
      "Train Epoch: 89 [137472/225000 (61%)] Loss: 19754.648438\n",
      "Train Epoch: 89 [139968/225000 (62%)] Loss: 19475.621094\n",
      "Train Epoch: 89 [142464/225000 (63%)] Loss: 20025.003906\n",
      "Train Epoch: 89 [144960/225000 (64%)] Loss: 19630.472656\n",
      "Train Epoch: 89 [147456/225000 (66%)] Loss: 19761.724609\n",
      "Train Epoch: 89 [149952/225000 (67%)] Loss: 19606.683594\n",
      "Train Epoch: 89 [152448/225000 (68%)] Loss: 19009.820312\n",
      "Train Epoch: 89 [154944/225000 (69%)] Loss: 19764.664062\n",
      "Train Epoch: 89 [157440/225000 (70%)] Loss: 19976.031250\n",
      "Train Epoch: 89 [159936/225000 (71%)] Loss: 19733.197266\n",
      "Train Epoch: 89 [162432/225000 (72%)] Loss: 19657.847656\n",
      "Train Epoch: 89 [164928/225000 (73%)] Loss: 19656.021484\n",
      "Train Epoch: 89 [167424/225000 (74%)] Loss: 19573.189453\n",
      "Train Epoch: 89 [169920/225000 (76%)] Loss: 19692.601562\n",
      "Train Epoch: 89 [172416/225000 (77%)] Loss: 19645.242188\n",
      "Train Epoch: 89 [174912/225000 (78%)] Loss: 19755.847656\n",
      "Train Epoch: 89 [177408/225000 (79%)] Loss: 19702.167969\n",
      "Train Epoch: 89 [179904/225000 (80%)] Loss: 19484.220703\n",
      "Train Epoch: 89 [182400/225000 (81%)] Loss: 19532.027344\n",
      "Train Epoch: 89 [184896/225000 (82%)] Loss: 19599.845703\n",
      "Train Epoch: 89 [187392/225000 (83%)] Loss: 19484.162109\n",
      "Train Epoch: 89 [189888/225000 (84%)] Loss: 20061.894531\n",
      "Train Epoch: 89 [192384/225000 (86%)] Loss: 19491.166016\n",
      "Train Epoch: 89 [194880/225000 (87%)] Loss: 19108.898438\n",
      "Train Epoch: 89 [197376/225000 (88%)] Loss: 19626.720703\n",
      "Train Epoch: 89 [199872/225000 (89%)] Loss: 20005.544922\n",
      "Train Epoch: 89 [202368/225000 (90%)] Loss: 19721.240234\n",
      "Train Epoch: 89 [204864/225000 (91%)] Loss: 20335.730469\n",
      "Train Epoch: 89 [207360/225000 (92%)] Loss: 19764.812500\n",
      "Train Epoch: 89 [209856/225000 (93%)] Loss: 19596.197266\n",
      "Train Epoch: 89 [212352/225000 (94%)] Loss: 19533.736328\n",
      "Train Epoch: 89 [214848/225000 (95%)] Loss: 19460.351562\n",
      "Train Epoch: 89 [217344/225000 (97%)] Loss: 20131.417969\n",
      "Train Epoch: 89 [219840/225000 (98%)] Loss: 19342.732422\n",
      "Train Epoch: 89 [222336/225000 (99%)] Loss: 19512.152344\n",
      "Train Epoch: 89 [224832/225000 (100%)] Loss: 19535.673828\n",
      "    epoch          : 89\n",
      "    loss           : 19585.5663912516\n",
      "    val_loss       : 19485.905604508087\n",
      "Train Epoch: 90 [192/225000 (0%)] Loss: 19491.431641\n",
      "Train Epoch: 90 [2688/225000 (1%)] Loss: 19871.011719\n",
      "Train Epoch: 90 [5184/225000 (2%)] Loss: 19824.953125\n",
      "Train Epoch: 90 [7680/225000 (3%)] Loss: 19159.384766\n",
      "Train Epoch: 90 [10176/225000 (5%)] Loss: 19946.109375\n",
      "Train Epoch: 90 [12672/225000 (6%)] Loss: 19246.720703\n",
      "Train Epoch: 90 [15168/225000 (7%)] Loss: 19381.781250\n",
      "Train Epoch: 90 [17664/225000 (8%)] Loss: 19514.945312\n",
      "Train Epoch: 90 [20160/225000 (9%)] Loss: 19914.082031\n",
      "Train Epoch: 90 [22656/225000 (10%)] Loss: 20026.605469\n",
      "Train Epoch: 90 [25152/225000 (11%)] Loss: 19296.615234\n",
      "Train Epoch: 90 [27648/225000 (12%)] Loss: 19768.908203\n",
      "Train Epoch: 90 [30144/225000 (13%)] Loss: 19446.357422\n",
      "Train Epoch: 90 [32640/225000 (15%)] Loss: 19472.636719\n",
      "Train Epoch: 90 [35136/225000 (16%)] Loss: 19727.785156\n",
      "Train Epoch: 90 [37632/225000 (17%)] Loss: 19294.386719\n",
      "Train Epoch: 90 [40128/225000 (18%)] Loss: 19740.960938\n",
      "Train Epoch: 90 [42624/225000 (19%)] Loss: 19909.451172\n",
      "Train Epoch: 90 [45120/225000 (20%)] Loss: 19488.203125\n",
      "Train Epoch: 90 [47616/225000 (21%)] Loss: 19380.466797\n",
      "Train Epoch: 90 [50112/225000 (22%)] Loss: 19527.171875\n",
      "Train Epoch: 90 [52608/225000 (23%)] Loss: 19541.800781\n",
      "Train Epoch: 90 [55104/225000 (24%)] Loss: 19751.835938\n",
      "Train Epoch: 90 [57600/225000 (26%)] Loss: 19343.140625\n",
      "Train Epoch: 90 [60096/225000 (27%)] Loss: 19705.394531\n",
      "Train Epoch: 90 [62592/225000 (28%)] Loss: 19858.074219\n",
      "Train Epoch: 90 [65088/225000 (29%)] Loss: 19152.585938\n",
      "Train Epoch: 90 [67584/225000 (30%)] Loss: 19596.080078\n",
      "Train Epoch: 90 [70080/225000 (31%)] Loss: 19697.843750\n",
      "Train Epoch: 90 [72576/225000 (32%)] Loss: 20024.640625\n",
      "Train Epoch: 90 [75072/225000 (33%)] Loss: 19332.322266\n",
      "Train Epoch: 90 [77568/225000 (34%)] Loss: 19240.279297\n",
      "Train Epoch: 90 [80064/225000 (36%)] Loss: 19215.664062\n",
      "Train Epoch: 90 [82560/225000 (37%)] Loss: 19563.091797\n",
      "Train Epoch: 90 [85056/225000 (38%)] Loss: 19255.804688\n",
      "Train Epoch: 90 [87552/225000 (39%)] Loss: 20071.748047\n",
      "Train Epoch: 90 [90048/225000 (40%)] Loss: 19393.234375\n",
      "Train Epoch: 90 [92544/225000 (41%)] Loss: 19896.679688\n",
      "Train Epoch: 90 [95040/225000 (42%)] Loss: 19276.859375\n",
      "Train Epoch: 90 [97536/225000 (43%)] Loss: 20020.554688\n",
      "Train Epoch: 90 [100032/225000 (44%)] Loss: 19731.205078\n",
      "Train Epoch: 90 [102528/225000 (46%)] Loss: 19897.990234\n",
      "Train Epoch: 90 [105024/225000 (47%)] Loss: 19120.574219\n",
      "Train Epoch: 90 [107520/225000 (48%)] Loss: 19413.642578\n",
      "Train Epoch: 90 [110016/225000 (49%)] Loss: 19756.587891\n",
      "Train Epoch: 90 [112512/225000 (50%)] Loss: 19193.566406\n",
      "Train Epoch: 90 [115008/225000 (51%)] Loss: 19255.636719\n",
      "Train Epoch: 90 [117504/225000 (52%)] Loss: 19140.808594\n",
      "Train Epoch: 90 [120000/225000 (53%)] Loss: 19714.238281\n",
      "Train Epoch: 90 [122496/225000 (54%)] Loss: 19605.816406\n",
      "Train Epoch: 90 [124992/225000 (56%)] Loss: 19869.078125\n",
      "Train Epoch: 90 [127488/225000 (57%)] Loss: 19665.191406\n",
      "Train Epoch: 90 [129984/225000 (58%)] Loss: 19893.652344\n",
      "Train Epoch: 90 [132480/225000 (59%)] Loss: 19452.539062\n",
      "Train Epoch: 90 [134976/225000 (60%)] Loss: 19592.539062\n",
      "Train Epoch: 90 [137472/225000 (61%)] Loss: 19629.187500\n",
      "Train Epoch: 90 [139968/225000 (62%)] Loss: 19767.460938\n",
      "Train Epoch: 90 [142464/225000 (63%)] Loss: 19287.503906\n",
      "Train Epoch: 90 [144960/225000 (64%)] Loss: 19321.593750\n",
      "Train Epoch: 90 [147456/225000 (66%)] Loss: 19780.605469\n",
      "Train Epoch: 90 [149952/225000 (67%)] Loss: 19535.652344\n",
      "Train Epoch: 90 [152448/225000 (68%)] Loss: 19816.492188\n",
      "Train Epoch: 90 [154944/225000 (69%)] Loss: 19316.777344\n",
      "Train Epoch: 90 [157440/225000 (70%)] Loss: 19644.509766\n",
      "Train Epoch: 90 [159936/225000 (71%)] Loss: 19879.328125\n",
      "Train Epoch: 90 [162432/225000 (72%)] Loss: 19524.050781\n",
      "Train Epoch: 90 [164928/225000 (73%)] Loss: 19976.833984\n",
      "Train Epoch: 90 [167424/225000 (74%)] Loss: 20076.511719\n",
      "Train Epoch: 90 [169920/225000 (76%)] Loss: 19347.148438\n",
      "Train Epoch: 90 [172416/225000 (77%)] Loss: 19743.125000\n",
      "Train Epoch: 90 [174912/225000 (78%)] Loss: 19638.470703\n",
      "Train Epoch: 90 [177408/225000 (79%)] Loss: 19755.902344\n",
      "Train Epoch: 90 [179904/225000 (80%)] Loss: 19682.421875\n",
      "Train Epoch: 90 [182400/225000 (81%)] Loss: 19571.531250\n",
      "Train Epoch: 90 [184896/225000 (82%)] Loss: 19265.714844\n",
      "Train Epoch: 90 [187392/225000 (83%)] Loss: 19776.746094\n",
      "Train Epoch: 90 [189888/225000 (84%)] Loss: 19679.597656\n",
      "Train Epoch: 90 [192384/225000 (86%)] Loss: 19153.761719\n",
      "Train Epoch: 90 [194880/225000 (87%)] Loss: 19443.484375\n",
      "Train Epoch: 90 [197376/225000 (88%)] Loss: 19790.179688\n",
      "Train Epoch: 90 [199872/225000 (89%)] Loss: 24294.128906\n",
      "Train Epoch: 90 [202368/225000 (90%)] Loss: 19886.126953\n",
      "Train Epoch: 90 [204864/225000 (91%)] Loss: 19452.365234\n",
      "Train Epoch: 90 [207360/225000 (92%)] Loss: 19595.089844\n",
      "Train Epoch: 90 [209856/225000 (93%)] Loss: 20133.658203\n",
      "Train Epoch: 90 [212352/225000 (94%)] Loss: 20240.148438\n",
      "Train Epoch: 90 [214848/225000 (95%)] Loss: 19588.128906\n",
      "Train Epoch: 90 [217344/225000 (97%)] Loss: 19360.265625\n",
      "Train Epoch: 90 [219840/225000 (98%)] Loss: 19469.218750\n",
      "Train Epoch: 90 [222336/225000 (99%)] Loss: 19371.453125\n",
      "Train Epoch: 90 [224832/225000 (100%)] Loss: 19419.183594\n",
      "    epoch          : 90\n",
      "    loss           : 19586.190987961283\n",
      "    val_loss       : 19475.924868764767\n",
      "Train Epoch: 91 [192/225000 (0%)] Loss: 19548.363281\n",
      "Train Epoch: 91 [2688/225000 (1%)] Loss: 19724.523438\n",
      "Train Epoch: 91 [5184/225000 (2%)] Loss: 19621.562500\n",
      "Train Epoch: 91 [7680/225000 (3%)] Loss: 19407.367188\n",
      "Train Epoch: 91 [10176/225000 (5%)] Loss: 19726.242188\n",
      "Train Epoch: 91 [12672/225000 (6%)] Loss: 19484.886719\n",
      "Train Epoch: 91 [15168/225000 (7%)] Loss: 19896.781250\n",
      "Train Epoch: 91 [17664/225000 (8%)] Loss: 19667.128906\n",
      "Train Epoch: 91 [20160/225000 (9%)] Loss: 19478.886719\n",
      "Train Epoch: 91 [22656/225000 (10%)] Loss: 19309.394531\n",
      "Train Epoch: 91 [25152/225000 (11%)] Loss: 19447.882812\n",
      "Train Epoch: 91 [27648/225000 (12%)] Loss: 19761.341797\n",
      "Train Epoch: 91 [30144/225000 (13%)] Loss: 19550.755859\n",
      "Train Epoch: 91 [32640/225000 (15%)] Loss: 19994.820312\n",
      "Train Epoch: 91 [35136/225000 (16%)] Loss: 19735.923828\n",
      "Train Epoch: 91 [37632/225000 (17%)] Loss: 19409.632812\n",
      "Train Epoch: 91 [40128/225000 (18%)] Loss: 19742.601562\n",
      "Train Epoch: 91 [42624/225000 (19%)] Loss: 19426.183594\n",
      "Train Epoch: 91 [45120/225000 (20%)] Loss: 19380.931641\n",
      "Train Epoch: 91 [47616/225000 (21%)] Loss: 19546.320312\n",
      "Train Epoch: 91 [50112/225000 (22%)] Loss: 19472.328125\n",
      "Train Epoch: 91 [52608/225000 (23%)] Loss: 19524.199219\n",
      "Train Epoch: 91 [55104/225000 (24%)] Loss: 19512.304688\n",
      "Train Epoch: 91 [57600/225000 (26%)] Loss: 19569.765625\n",
      "Train Epoch: 91 [60096/225000 (27%)] Loss: 19567.623047\n",
      "Train Epoch: 91 [62592/225000 (28%)] Loss: 19437.404297\n",
      "Train Epoch: 91 [65088/225000 (29%)] Loss: 19454.740234\n",
      "Train Epoch: 91 [67584/225000 (30%)] Loss: 19405.435547\n",
      "Train Epoch: 91 [70080/225000 (31%)] Loss: 19793.902344\n",
      "Train Epoch: 91 [72576/225000 (32%)] Loss: 19862.816406\n",
      "Train Epoch: 91 [75072/225000 (33%)] Loss: 19359.539062\n",
      "Train Epoch: 91 [77568/225000 (34%)] Loss: 19543.031250\n",
      "Train Epoch: 91 [80064/225000 (36%)] Loss: 19486.939453\n",
      "Train Epoch: 91 [82560/225000 (37%)] Loss: 19728.148438\n",
      "Train Epoch: 91 [85056/225000 (38%)] Loss: 18855.591797\n",
      "Train Epoch: 91 [87552/225000 (39%)] Loss: 19807.064453\n",
      "Train Epoch: 91 [90048/225000 (40%)] Loss: 19853.878906\n",
      "Train Epoch: 91 [92544/225000 (41%)] Loss: 19572.267578\n",
      "Train Epoch: 91 [95040/225000 (42%)] Loss: 19299.697266\n",
      "Train Epoch: 91 [97536/225000 (43%)] Loss: 19404.226562\n",
      "Train Epoch: 91 [100032/225000 (44%)] Loss: 19681.470703\n",
      "Train Epoch: 91 [102528/225000 (46%)] Loss: 19649.542969\n",
      "Train Epoch: 91 [105024/225000 (47%)] Loss: 20107.125000\n",
      "Train Epoch: 91 [107520/225000 (48%)] Loss: 19121.976562\n",
      "Train Epoch: 91 [110016/225000 (49%)] Loss: 19548.269531\n",
      "Train Epoch: 91 [112512/225000 (50%)] Loss: 19306.695312\n",
      "Train Epoch: 91 [115008/225000 (51%)] Loss: 19464.578125\n",
      "Train Epoch: 91 [117504/225000 (52%)] Loss: 19962.515625\n",
      "Train Epoch: 91 [120000/225000 (53%)] Loss: 19426.708984\n",
      "Train Epoch: 91 [122496/225000 (54%)] Loss: 19411.605469\n",
      "Train Epoch: 91 [124992/225000 (56%)] Loss: 19573.261719\n",
      "Train Epoch: 91 [127488/225000 (57%)] Loss: 19908.212891\n",
      "Train Epoch: 91 [129984/225000 (58%)] Loss: 19154.000000\n",
      "Train Epoch: 91 [132480/225000 (59%)] Loss: 19513.111328\n",
      "Train Epoch: 91 [134976/225000 (60%)] Loss: 19760.988281\n",
      "Train Epoch: 91 [137472/225000 (61%)] Loss: 20131.443359\n",
      "Train Epoch: 91 [139968/225000 (62%)] Loss: 19312.132812\n",
      "Train Epoch: 91 [142464/225000 (63%)] Loss: 19435.376953\n",
      "Train Epoch: 91 [144960/225000 (64%)] Loss: 19581.220703\n",
      "Train Epoch: 91 [147456/225000 (66%)] Loss: 18989.011719\n",
      "Train Epoch: 91 [149952/225000 (67%)] Loss: 19845.140625\n",
      "Train Epoch: 91 [152448/225000 (68%)] Loss: 19356.167969\n",
      "Train Epoch: 91 [154944/225000 (69%)] Loss: 20049.414062\n",
      "Train Epoch: 91 [157440/225000 (70%)] Loss: 19646.658203\n",
      "Train Epoch: 91 [159936/225000 (71%)] Loss: 18892.876953\n",
      "Train Epoch: 91 [162432/225000 (72%)] Loss: 19490.880859\n",
      "Train Epoch: 91 [164928/225000 (73%)] Loss: 19347.761719\n",
      "Train Epoch: 91 [167424/225000 (74%)] Loss: 19584.976562\n",
      "Train Epoch: 91 [169920/225000 (76%)] Loss: 19743.623047\n",
      "Train Epoch: 91 [172416/225000 (77%)] Loss: 19556.820312\n",
      "Train Epoch: 91 [174912/225000 (78%)] Loss: 19706.773438\n",
      "Train Epoch: 91 [177408/225000 (79%)] Loss: 19714.904297\n",
      "Train Epoch: 91 [179904/225000 (80%)] Loss: 20011.804688\n",
      "Train Epoch: 91 [182400/225000 (81%)] Loss: 19822.457031\n",
      "Train Epoch: 91 [184896/225000 (82%)] Loss: 19447.558594\n",
      "Train Epoch: 91 [187392/225000 (83%)] Loss: 19726.410156\n",
      "Train Epoch: 91 [189888/225000 (84%)] Loss: 19738.421875\n",
      "Train Epoch: 91 [192384/225000 (86%)] Loss: 19433.132812\n",
      "Train Epoch: 91 [194880/225000 (87%)] Loss: 20265.683594\n",
      "Train Epoch: 91 [197376/225000 (88%)] Loss: 19664.783203\n",
      "Train Epoch: 91 [199872/225000 (89%)] Loss: 19939.103516\n",
      "Train Epoch: 91 [202368/225000 (90%)] Loss: 19920.777344\n",
      "Train Epoch: 91 [204864/225000 (91%)] Loss: 19452.009766\n",
      "Train Epoch: 91 [207360/225000 (92%)] Loss: 19686.796875\n",
      "Train Epoch: 91 [209856/225000 (93%)] Loss: 19670.796875\n",
      "Train Epoch: 91 [212352/225000 (94%)] Loss: 19196.673828\n",
      "Train Epoch: 91 [214848/225000 (95%)] Loss: 19609.093750\n",
      "Train Epoch: 91 [217344/225000 (97%)] Loss: 19744.214844\n",
      "Train Epoch: 91 [219840/225000 (98%)] Loss: 19702.796875\n",
      "Train Epoch: 91 [222336/225000 (99%)] Loss: 19923.607422\n",
      "Train Epoch: 91 [224832/225000 (100%)] Loss: 19491.062500\n",
      "    epoch          : 91\n",
      "    loss           : 19574.224981002026\n",
      "    val_loss       : 19465.856796714186\n",
      "Train Epoch: 92 [192/225000 (0%)] Loss: 20055.242188\n",
      "Train Epoch: 92 [2688/225000 (1%)] Loss: 19790.695312\n",
      "Train Epoch: 92 [5184/225000 (2%)] Loss: 19528.410156\n",
      "Train Epoch: 92 [7680/225000 (3%)] Loss: 19584.425781\n",
      "Train Epoch: 92 [10176/225000 (5%)] Loss: 20092.056641\n",
      "Train Epoch: 92 [12672/225000 (6%)] Loss: 19609.578125\n",
      "Train Epoch: 92 [15168/225000 (7%)] Loss: 19673.785156\n",
      "Train Epoch: 92 [17664/225000 (8%)] Loss: 19968.419922\n",
      "Train Epoch: 92 [20160/225000 (9%)] Loss: 20026.593750\n",
      "Train Epoch: 92 [22656/225000 (10%)] Loss: 19366.400391\n",
      "Train Epoch: 92 [25152/225000 (11%)] Loss: 19995.871094\n",
      "Train Epoch: 92 [27648/225000 (12%)] Loss: 19625.695312\n",
      "Train Epoch: 92 [30144/225000 (13%)] Loss: 19651.300781\n",
      "Train Epoch: 92 [32640/225000 (15%)] Loss: 19639.736328\n",
      "Train Epoch: 92 [35136/225000 (16%)] Loss: 19727.558594\n",
      "Train Epoch: 92 [37632/225000 (17%)] Loss: 19655.152344\n",
      "Train Epoch: 92 [40128/225000 (18%)] Loss: 19817.039062\n",
      "Train Epoch: 92 [42624/225000 (19%)] Loss: 19907.710938\n",
      "Train Epoch: 92 [45120/225000 (20%)] Loss: 19545.201172\n",
      "Train Epoch: 92 [47616/225000 (21%)] Loss: 19659.689453\n",
      "Train Epoch: 92 [50112/225000 (22%)] Loss: 19265.958984\n",
      "Train Epoch: 92 [52608/225000 (23%)] Loss: 19939.039062\n",
      "Train Epoch: 92 [55104/225000 (24%)] Loss: 19734.160156\n",
      "Train Epoch: 92 [57600/225000 (26%)] Loss: 19286.500000\n",
      "Train Epoch: 92 [60096/225000 (27%)] Loss: 19983.144531\n",
      "Train Epoch: 92 [62592/225000 (28%)] Loss: 19685.021484\n",
      "Train Epoch: 92 [65088/225000 (29%)] Loss: 19225.859375\n",
      "Train Epoch: 92 [67584/225000 (30%)] Loss: 19539.285156\n",
      "Train Epoch: 92 [70080/225000 (31%)] Loss: 19586.906250\n",
      "Train Epoch: 92 [72576/225000 (32%)] Loss: 19316.011719\n",
      "Train Epoch: 92 [75072/225000 (33%)] Loss: 19174.261719\n",
      "Train Epoch: 92 [77568/225000 (34%)] Loss: 19081.958984\n",
      "Train Epoch: 92 [80064/225000 (36%)] Loss: 19753.429688\n",
      "Train Epoch: 92 [82560/225000 (37%)] Loss: 19729.324219\n",
      "Train Epoch: 92 [85056/225000 (38%)] Loss: 19212.714844\n",
      "Train Epoch: 92 [87552/225000 (39%)] Loss: 19826.226562\n",
      "Train Epoch: 92 [90048/225000 (40%)] Loss: 19411.728516\n",
      "Train Epoch: 92 [92544/225000 (41%)] Loss: 19403.425781\n",
      "Train Epoch: 92 [95040/225000 (42%)] Loss: 19990.017578\n",
      "Train Epoch: 92 [97536/225000 (43%)] Loss: 19832.589844\n",
      "Train Epoch: 92 [100032/225000 (44%)] Loss: 19098.921875\n",
      "Train Epoch: 92 [102528/225000 (46%)] Loss: 19697.605469\n",
      "Train Epoch: 92 [105024/225000 (47%)] Loss: 19403.839844\n",
      "Train Epoch: 92 [107520/225000 (48%)] Loss: 19467.367188\n",
      "Train Epoch: 92 [110016/225000 (49%)] Loss: 19459.787109\n",
      "Train Epoch: 92 [112512/225000 (50%)] Loss: 19827.320312\n",
      "Train Epoch: 92 [115008/225000 (51%)] Loss: 19672.746094\n",
      "Train Epoch: 92 [117504/225000 (52%)] Loss: 19733.242188\n",
      "Train Epoch: 92 [120000/225000 (53%)] Loss: 19843.203125\n",
      "Train Epoch: 92 [122496/225000 (54%)] Loss: 19436.417969\n",
      "Train Epoch: 92 [124992/225000 (56%)] Loss: 19801.593750\n",
      "Train Epoch: 92 [127488/225000 (57%)] Loss: 19880.523438\n",
      "Train Epoch: 92 [129984/225000 (58%)] Loss: 19741.093750\n",
      "Train Epoch: 92 [132480/225000 (59%)] Loss: 19182.406250\n",
      "Train Epoch: 92 [134976/225000 (60%)] Loss: 19459.972656\n",
      "Train Epoch: 92 [137472/225000 (61%)] Loss: 19916.609375\n",
      "Train Epoch: 92 [139968/225000 (62%)] Loss: 19240.785156\n",
      "Train Epoch: 92 [142464/225000 (63%)] Loss: 19968.980469\n",
      "Train Epoch: 92 [144960/225000 (64%)] Loss: 19117.218750\n",
      "Train Epoch: 92 [147456/225000 (66%)] Loss: 19588.054688\n",
      "Train Epoch: 92 [149952/225000 (67%)] Loss: 19943.828125\n",
      "Train Epoch: 92 [152448/225000 (68%)] Loss: 19195.214844\n",
      "Train Epoch: 92 [154944/225000 (69%)] Loss: 19480.296875\n",
      "Train Epoch: 92 [157440/225000 (70%)] Loss: 19467.574219\n",
      "Train Epoch: 92 [159936/225000 (71%)] Loss: 19822.687500\n",
      "Train Epoch: 92 [162432/225000 (72%)] Loss: 19474.296875\n",
      "Train Epoch: 92 [164928/225000 (73%)] Loss: 19353.238281\n",
      "Train Epoch: 92 [167424/225000 (74%)] Loss: 19520.761719\n",
      "Train Epoch: 92 [169920/225000 (76%)] Loss: 19691.132812\n",
      "Train Epoch: 92 [172416/225000 (77%)] Loss: 19763.599609\n",
      "Train Epoch: 92 [174912/225000 (78%)] Loss: 19218.884766\n",
      "Train Epoch: 92 [177408/225000 (79%)] Loss: 19023.441406\n",
      "Train Epoch: 92 [179904/225000 (80%)] Loss: 19203.248047\n",
      "Train Epoch: 92 [182400/225000 (81%)] Loss: 19474.695312\n",
      "Train Epoch: 92 [184896/225000 (82%)] Loss: 19097.656250\n",
      "Train Epoch: 92 [187392/225000 (83%)] Loss: 19341.154297\n",
      "Train Epoch: 92 [189888/225000 (84%)] Loss: 19140.332031\n",
      "Train Epoch: 92 [192384/225000 (86%)] Loss: 19693.292969\n",
      "Train Epoch: 92 [194880/225000 (87%)] Loss: 19545.972656\n",
      "Train Epoch: 92 [197376/225000 (88%)] Loss: 19233.978516\n",
      "Train Epoch: 92 [199872/225000 (89%)] Loss: 19612.265625\n",
      "Train Epoch: 92 [202368/225000 (90%)] Loss: 19448.396484\n",
      "Train Epoch: 92 [204864/225000 (91%)] Loss: 19726.847656\n",
      "Train Epoch: 92 [207360/225000 (92%)] Loss: 19888.695312\n",
      "Train Epoch: 92 [209856/225000 (93%)] Loss: 19050.998047\n",
      "Train Epoch: 92 [212352/225000 (94%)] Loss: 19418.386719\n",
      "Train Epoch: 92 [214848/225000 (95%)] Loss: 19221.039062\n",
      "Train Epoch: 92 [217344/225000 (97%)] Loss: 19741.484375\n",
      "Train Epoch: 92 [219840/225000 (98%)] Loss: 19720.000000\n",
      "Train Epoch: 92 [222336/225000 (99%)] Loss: 19986.042969\n",
      "Train Epoch: 92 [224832/225000 (100%)] Loss: 19481.667969\n",
      "    epoch          : 92\n",
      "    loss           : 19559.137425341298\n",
      "    val_loss       : 19470.220948577837\n",
      "Train Epoch: 93 [192/225000 (0%)] Loss: 19573.070312\n",
      "Train Epoch: 93 [2688/225000 (1%)] Loss: 19203.650391\n",
      "Train Epoch: 93 [5184/225000 (2%)] Loss: 18980.742188\n",
      "Train Epoch: 93 [7680/225000 (3%)] Loss: 19430.242188\n",
      "Train Epoch: 93 [10176/225000 (5%)] Loss: 19646.351562\n",
      "Train Epoch: 93 [12672/225000 (6%)] Loss: 19283.521484\n",
      "Train Epoch: 93 [15168/225000 (7%)] Loss: 19850.878906\n",
      "Train Epoch: 93 [17664/225000 (8%)] Loss: 19281.875000\n",
      "Train Epoch: 93 [20160/225000 (9%)] Loss: 19295.556641\n",
      "Train Epoch: 93 [22656/225000 (10%)] Loss: 19708.021484\n",
      "Train Epoch: 93 [25152/225000 (11%)] Loss: 19485.744141\n",
      "Train Epoch: 93 [27648/225000 (12%)] Loss: 19624.289062\n",
      "Train Epoch: 93 [30144/225000 (13%)] Loss: 19333.351562\n",
      "Train Epoch: 93 [32640/225000 (15%)] Loss: 19453.023438\n",
      "Train Epoch: 93 [35136/225000 (16%)] Loss: 19630.851562\n",
      "Train Epoch: 93 [37632/225000 (17%)] Loss: 19546.812500\n",
      "Train Epoch: 93 [40128/225000 (18%)] Loss: 19689.910156\n",
      "Train Epoch: 93 [42624/225000 (19%)] Loss: 20000.314453\n",
      "Train Epoch: 93 [45120/225000 (20%)] Loss: 18948.710938\n",
      "Train Epoch: 93 [47616/225000 (21%)] Loss: 19829.953125\n",
      "Train Epoch: 93 [50112/225000 (22%)] Loss: 20035.550781\n",
      "Train Epoch: 93 [52608/225000 (23%)] Loss: 19320.021484\n",
      "Train Epoch: 93 [55104/225000 (24%)] Loss: 20101.023438\n",
      "Train Epoch: 93 [57600/225000 (26%)] Loss: 19848.015625\n",
      "Train Epoch: 93 [60096/225000 (27%)] Loss: 19627.640625\n",
      "Train Epoch: 93 [62592/225000 (28%)] Loss: 19651.843750\n",
      "Train Epoch: 93 [65088/225000 (29%)] Loss: 19586.324219\n",
      "Train Epoch: 93 [67584/225000 (30%)] Loss: 19753.111328\n",
      "Train Epoch: 93 [70080/225000 (31%)] Loss: 19506.468750\n",
      "Train Epoch: 93 [72576/225000 (32%)] Loss: 19084.722656\n",
      "Train Epoch: 93 [75072/225000 (33%)] Loss: 19668.289062\n",
      "Train Epoch: 93 [77568/225000 (34%)] Loss: 19724.070312\n",
      "Train Epoch: 93 [80064/225000 (36%)] Loss: 19532.003906\n",
      "Train Epoch: 93 [82560/225000 (37%)] Loss: 19996.757812\n",
      "Train Epoch: 93 [85056/225000 (38%)] Loss: 19921.033203\n",
      "Train Epoch: 93 [87552/225000 (39%)] Loss: 19473.691406\n",
      "Train Epoch: 93 [90048/225000 (40%)] Loss: 19557.046875\n",
      "Train Epoch: 93 [92544/225000 (41%)] Loss: 19161.734375\n",
      "Train Epoch: 93 [95040/225000 (42%)] Loss: 19028.519531\n",
      "Train Epoch: 93 [97536/225000 (43%)] Loss: 19522.492188\n",
      "Train Epoch: 93 [100032/225000 (44%)] Loss: 19934.714844\n",
      "Train Epoch: 93 [102528/225000 (46%)] Loss: 19620.234375\n",
      "Train Epoch: 93 [105024/225000 (47%)] Loss: 19907.703125\n",
      "Train Epoch: 93 [107520/225000 (48%)] Loss: 19768.281250\n",
      "Train Epoch: 93 [110016/225000 (49%)] Loss: 19747.070312\n",
      "Train Epoch: 93 [112512/225000 (50%)] Loss: 19389.218750\n",
      "Train Epoch: 93 [115008/225000 (51%)] Loss: 19802.871094\n",
      "Train Epoch: 93 [117504/225000 (52%)] Loss: 19224.464844\n",
      "Train Epoch: 93 [120000/225000 (53%)] Loss: 19027.578125\n",
      "Train Epoch: 93 [122496/225000 (54%)] Loss: 19502.316406\n",
      "Train Epoch: 93 [124992/225000 (56%)] Loss: 19510.359375\n",
      "Train Epoch: 93 [127488/225000 (57%)] Loss: 19718.302734\n",
      "Train Epoch: 93 [129984/225000 (58%)] Loss: 19658.828125\n",
      "Train Epoch: 93 [132480/225000 (59%)] Loss: 19611.363281\n",
      "Train Epoch: 93 [134976/225000 (60%)] Loss: 19580.187500\n",
      "Train Epoch: 93 [137472/225000 (61%)] Loss: 19630.519531\n",
      "Train Epoch: 93 [139968/225000 (62%)] Loss: 19816.539062\n",
      "Train Epoch: 93 [142464/225000 (63%)] Loss: 19526.972656\n",
      "Train Epoch: 93 [144960/225000 (64%)] Loss: 19637.910156\n",
      "Train Epoch: 93 [147456/225000 (66%)] Loss: 19741.445312\n",
      "Train Epoch: 93 [149952/225000 (67%)] Loss: 19489.771484\n",
      "Train Epoch: 93 [152448/225000 (68%)] Loss: 19617.257812\n",
      "Train Epoch: 93 [154944/225000 (69%)] Loss: 19770.316406\n",
      "Train Epoch: 93 [157440/225000 (70%)] Loss: 19593.507812\n",
      "Train Epoch: 93 [159936/225000 (71%)] Loss: 18849.214844\n",
      "Train Epoch: 93 [162432/225000 (72%)] Loss: 19498.750000\n",
      "Train Epoch: 93 [164928/225000 (73%)] Loss: 19758.769531\n",
      "Train Epoch: 93 [167424/225000 (74%)] Loss: 19967.394531\n",
      "Train Epoch: 93 [169920/225000 (76%)] Loss: 19957.703125\n",
      "Train Epoch: 93 [172416/225000 (77%)] Loss: 19365.226562\n",
      "Train Epoch: 93 [174912/225000 (78%)] Loss: 19343.109375\n",
      "Train Epoch: 93 [177408/225000 (79%)] Loss: 19350.410156\n",
      "Train Epoch: 93 [179904/225000 (80%)] Loss: 19043.076172\n",
      "Train Epoch: 93 [182400/225000 (81%)] Loss: 19433.824219\n",
      "Train Epoch: 93 [184896/225000 (82%)] Loss: 19357.070312\n",
      "Train Epoch: 93 [187392/225000 (83%)] Loss: 19318.488281\n",
      "Train Epoch: 93 [189888/225000 (84%)] Loss: 19549.378906\n",
      "Train Epoch: 93 [192384/225000 (86%)] Loss: 19447.367188\n",
      "Train Epoch: 93 [194880/225000 (87%)] Loss: 19289.566406\n",
      "Train Epoch: 93 [197376/225000 (88%)] Loss: 19351.376953\n",
      "Train Epoch: 93 [199872/225000 (89%)] Loss: 19539.964844\n",
      "Train Epoch: 93 [202368/225000 (90%)] Loss: 19424.943359\n",
      "Train Epoch: 93 [204864/225000 (91%)] Loss: 19593.882812\n",
      "Train Epoch: 93 [207360/225000 (92%)] Loss: 19926.230469\n",
      "Train Epoch: 93 [209856/225000 (93%)] Loss: 19312.359375\n",
      "Train Epoch: 93 [212352/225000 (94%)] Loss: 20189.333984\n",
      "Train Epoch: 93 [214848/225000 (95%)] Loss: 19277.367188\n",
      "Train Epoch: 93 [217344/225000 (97%)] Loss: 19636.683594\n",
      "Train Epoch: 93 [219840/225000 (98%)] Loss: 19402.046875\n",
      "Train Epoch: 93 [222336/225000 (99%)] Loss: 19749.132812\n",
      "Train Epoch: 93 [224832/225000 (100%)] Loss: 19986.882812\n",
      "    epoch          : 93\n",
      "    loss           : 19549.839193819327\n",
      "    val_loss       : 19448.58067354901\n",
      "Train Epoch: 94 [192/225000 (0%)] Loss: 19834.421875\n",
      "Train Epoch: 94 [2688/225000 (1%)] Loss: 19685.822266\n",
      "Train Epoch: 94 [5184/225000 (2%)] Loss: 19495.078125\n",
      "Train Epoch: 94 [7680/225000 (3%)] Loss: 19562.843750\n",
      "Train Epoch: 94 [10176/225000 (5%)] Loss: 19573.527344\n",
      "Train Epoch: 94 [12672/225000 (6%)] Loss: 19417.929688\n",
      "Train Epoch: 94 [15168/225000 (7%)] Loss: 20018.791016\n",
      "Train Epoch: 94 [17664/225000 (8%)] Loss: 19362.355469\n",
      "Train Epoch: 94 [20160/225000 (9%)] Loss: 19313.695312\n",
      "Train Epoch: 94 [22656/225000 (10%)] Loss: 19631.255859\n",
      "Train Epoch: 94 [25152/225000 (11%)] Loss: 19486.457031\n",
      "Train Epoch: 94 [27648/225000 (12%)] Loss: 19670.050781\n",
      "Train Epoch: 94 [30144/225000 (13%)] Loss: 19634.359375\n",
      "Train Epoch: 94 [32640/225000 (15%)] Loss: 19561.199219\n",
      "Train Epoch: 94 [35136/225000 (16%)] Loss: 19684.734375\n",
      "Train Epoch: 94 [37632/225000 (17%)] Loss: 19293.714844\n",
      "Train Epoch: 94 [40128/225000 (18%)] Loss: 19534.824219\n",
      "Train Epoch: 94 [42624/225000 (19%)] Loss: 19406.878906\n",
      "Train Epoch: 94 [45120/225000 (20%)] Loss: 19414.042969\n",
      "Train Epoch: 94 [47616/225000 (21%)] Loss: 19893.472656\n",
      "Train Epoch: 94 [50112/225000 (22%)] Loss: 19926.656250\n",
      "Train Epoch: 94 [52608/225000 (23%)] Loss: 19325.371094\n",
      "Train Epoch: 94 [55104/225000 (24%)] Loss: 19511.384766\n",
      "Train Epoch: 94 [57600/225000 (26%)] Loss: 19169.988281\n",
      "Train Epoch: 94 [60096/225000 (27%)] Loss: 19798.265625\n",
      "Train Epoch: 94 [62592/225000 (28%)] Loss: 19477.449219\n",
      "Train Epoch: 94 [65088/225000 (29%)] Loss: 19479.123047\n",
      "Train Epoch: 94 [67584/225000 (30%)] Loss: 19567.341797\n",
      "Train Epoch: 94 [70080/225000 (31%)] Loss: 19785.150391\n",
      "Train Epoch: 94 [72576/225000 (32%)] Loss: 19871.613281\n",
      "Train Epoch: 94 [75072/225000 (33%)] Loss: 19590.595703\n",
      "Train Epoch: 94 [77568/225000 (34%)] Loss: 19095.923828\n",
      "Train Epoch: 94 [80064/225000 (36%)] Loss: 19268.312500\n",
      "Train Epoch: 94 [82560/225000 (37%)] Loss: 19781.121094\n",
      "Train Epoch: 94 [85056/225000 (38%)] Loss: 19570.482422\n",
      "Train Epoch: 94 [87552/225000 (39%)] Loss: 19493.265625\n",
      "Train Epoch: 94 [90048/225000 (40%)] Loss: 20029.255859\n",
      "Train Epoch: 94 [92544/225000 (41%)] Loss: 19394.919922\n",
      "Train Epoch: 94 [95040/225000 (42%)] Loss: 19654.367188\n",
      "Train Epoch: 94 [97536/225000 (43%)] Loss: 19495.703125\n",
      "Train Epoch: 94 [100032/225000 (44%)] Loss: 19604.919922\n",
      "Train Epoch: 94 [102528/225000 (46%)] Loss: 19731.941406\n",
      "Train Epoch: 94 [105024/225000 (47%)] Loss: 19376.527344\n",
      "Train Epoch: 94 [107520/225000 (48%)] Loss: 19666.738281\n",
      "Train Epoch: 94 [110016/225000 (49%)] Loss: 19222.839844\n",
      "Train Epoch: 94 [112512/225000 (50%)] Loss: 20035.417969\n",
      "Train Epoch: 94 [115008/225000 (51%)] Loss: 19391.726562\n",
      "Train Epoch: 94 [117504/225000 (52%)] Loss: 19605.757812\n",
      "Train Epoch: 94 [120000/225000 (53%)] Loss: 19833.300781\n",
      "Train Epoch: 94 [122496/225000 (54%)] Loss: 19514.421875\n",
      "Train Epoch: 94 [124992/225000 (56%)] Loss: 19398.058594\n",
      "Train Epoch: 94 [127488/225000 (57%)] Loss: 19267.123047\n",
      "Train Epoch: 94 [129984/225000 (58%)] Loss: 19445.585938\n",
      "Train Epoch: 94 [132480/225000 (59%)] Loss: 19759.320312\n",
      "Train Epoch: 94 [134976/225000 (60%)] Loss: 19743.386719\n",
      "Train Epoch: 94 [137472/225000 (61%)] Loss: 19016.376953\n",
      "Train Epoch: 94 [139968/225000 (62%)] Loss: 19667.320312\n",
      "Train Epoch: 94 [142464/225000 (63%)] Loss: 19605.998047\n",
      "Train Epoch: 94 [144960/225000 (64%)] Loss: 19833.082031\n",
      "Train Epoch: 94 [147456/225000 (66%)] Loss: 19739.769531\n",
      "Train Epoch: 94 [149952/225000 (67%)] Loss: 19470.880859\n",
      "Train Epoch: 94 [152448/225000 (68%)] Loss: 19479.234375\n",
      "Train Epoch: 94 [154944/225000 (69%)] Loss: 19265.609375\n",
      "Train Epoch: 94 [157440/225000 (70%)] Loss: 19349.023438\n",
      "Train Epoch: 94 [159936/225000 (71%)] Loss: 19130.558594\n",
      "Train Epoch: 94 [162432/225000 (72%)] Loss: 19674.716797\n",
      "Train Epoch: 94 [164928/225000 (73%)] Loss: 19392.185547\n",
      "Train Epoch: 94 [167424/225000 (74%)] Loss: 19479.412109\n",
      "Train Epoch: 94 [169920/225000 (76%)] Loss: 19718.597656\n",
      "Train Epoch: 94 [172416/225000 (77%)] Loss: 19760.304688\n",
      "Train Epoch: 94 [174912/225000 (78%)] Loss: 19991.152344\n",
      "Train Epoch: 94 [177408/225000 (79%)] Loss: 19209.310547\n",
      "Train Epoch: 94 [179904/225000 (80%)] Loss: 19564.605469\n",
      "Train Epoch: 94 [182400/225000 (81%)] Loss: 19101.093750\n",
      "Train Epoch: 94 [184896/225000 (82%)] Loss: 19998.074219\n",
      "Train Epoch: 94 [187392/225000 (83%)] Loss: 18996.789062\n",
      "Train Epoch: 94 [189888/225000 (84%)] Loss: 19161.695312\n",
      "Train Epoch: 94 [192384/225000 (86%)] Loss: 19507.019531\n",
      "Train Epoch: 94 [194880/225000 (87%)] Loss: 19206.101562\n",
      "Train Epoch: 94 [197376/225000 (88%)] Loss: 19618.308594\n",
      "Train Epoch: 94 [199872/225000 (89%)] Loss: 19101.214844\n",
      "Train Epoch: 94 [202368/225000 (90%)] Loss: 19576.871094\n",
      "Train Epoch: 94 [204864/225000 (91%)] Loss: 19815.128906\n",
      "Train Epoch: 94 [207360/225000 (92%)] Loss: 19292.558594\n",
      "Train Epoch: 94 [209856/225000 (93%)] Loss: 19703.955078\n",
      "Train Epoch: 94 [212352/225000 (94%)] Loss: 19717.982422\n",
      "Train Epoch: 94 [214848/225000 (95%)] Loss: 19792.058594\n",
      "Train Epoch: 94 [217344/225000 (97%)] Loss: 19580.785156\n",
      "Train Epoch: 94 [219840/225000 (98%)] Loss: 19536.916016\n",
      "Train Epoch: 94 [222336/225000 (99%)] Loss: 19215.656250\n",
      "Train Epoch: 94 [224832/225000 (100%)] Loss: 20095.000000\n",
      "    epoch          : 94\n",
      "    loss           : 19544.61091650224\n",
      "    val_loss       : 19510.66735934119\n",
      "Train Epoch: 95 [192/225000 (0%)] Loss: 20026.156250\n",
      "Train Epoch: 95 [2688/225000 (1%)] Loss: 19869.453125\n",
      "Train Epoch: 95 [5184/225000 (2%)] Loss: 19261.697266\n",
      "Train Epoch: 95 [7680/225000 (3%)] Loss: 19463.046875\n",
      "Train Epoch: 95 [10176/225000 (5%)] Loss: 20067.376953\n",
      "Train Epoch: 95 [12672/225000 (6%)] Loss: 19476.302734\n",
      "Train Epoch: 95 [15168/225000 (7%)] Loss: 20068.765625\n",
      "Train Epoch: 95 [17664/225000 (8%)] Loss: 19560.070312\n",
      "Train Epoch: 95 [20160/225000 (9%)] Loss: 19493.685547\n",
      "Train Epoch: 95 [22656/225000 (10%)] Loss: 19443.570312\n",
      "Train Epoch: 95 [25152/225000 (11%)] Loss: 19488.714844\n",
      "Train Epoch: 95 [27648/225000 (12%)] Loss: 19034.777344\n",
      "Train Epoch: 95 [30144/225000 (13%)] Loss: 19502.015625\n",
      "Train Epoch: 95 [32640/225000 (15%)] Loss: 19685.890625\n",
      "Train Epoch: 95 [35136/225000 (16%)] Loss: 19379.136719\n",
      "Train Epoch: 95 [37632/225000 (17%)] Loss: 19729.531250\n",
      "Train Epoch: 95 [40128/225000 (18%)] Loss: 19749.011719\n",
      "Train Epoch: 95 [42624/225000 (19%)] Loss: 19499.046875\n",
      "Train Epoch: 95 [45120/225000 (20%)] Loss: 19632.464844\n",
      "Train Epoch: 95 [47616/225000 (21%)] Loss: 19682.164062\n",
      "Train Epoch: 95 [50112/225000 (22%)] Loss: 19079.300781\n",
      "Train Epoch: 95 [52608/225000 (23%)] Loss: 19341.910156\n",
      "Train Epoch: 95 [55104/225000 (24%)] Loss: 19641.656250\n",
      "Train Epoch: 95 [57600/225000 (26%)] Loss: 19817.507812\n",
      "Train Epoch: 95 [60096/225000 (27%)] Loss: 19948.330078\n",
      "Train Epoch: 95 [62592/225000 (28%)] Loss: 19006.935547\n",
      "Train Epoch: 95 [65088/225000 (29%)] Loss: 19056.994141\n",
      "Train Epoch: 95 [67584/225000 (30%)] Loss: 19887.406250\n",
      "Train Epoch: 95 [70080/225000 (31%)] Loss: 19175.906250\n",
      "Train Epoch: 95 [72576/225000 (32%)] Loss: 19289.781250\n",
      "Train Epoch: 95 [75072/225000 (33%)] Loss: 19401.074219\n",
      "Train Epoch: 95 [77568/225000 (34%)] Loss: 19753.007812\n",
      "Train Epoch: 95 [80064/225000 (36%)] Loss: 19532.921875\n",
      "Train Epoch: 95 [82560/225000 (37%)] Loss: 19285.183594\n",
      "Train Epoch: 95 [85056/225000 (38%)] Loss: 19445.402344\n",
      "Train Epoch: 95 [87552/225000 (39%)] Loss: 19676.750000\n",
      "Train Epoch: 95 [90048/225000 (40%)] Loss: 19676.519531\n",
      "Train Epoch: 95 [92544/225000 (41%)] Loss: 19898.421875\n",
      "Train Epoch: 95 [95040/225000 (42%)] Loss: 19416.218750\n",
      "Train Epoch: 95 [97536/225000 (43%)] Loss: 19286.386719\n",
      "Train Epoch: 95 [100032/225000 (44%)] Loss: 19543.429688\n",
      "Train Epoch: 95 [102528/225000 (46%)] Loss: 19281.441406\n",
      "Train Epoch: 95 [105024/225000 (47%)] Loss: 19850.294922\n",
      "Train Epoch: 95 [107520/225000 (48%)] Loss: 19481.593750\n",
      "Train Epoch: 95 [110016/225000 (49%)] Loss: 19508.191406\n",
      "Train Epoch: 95 [112512/225000 (50%)] Loss: 19578.324219\n",
      "Train Epoch: 95 [115008/225000 (51%)] Loss: 20002.539062\n",
      "Train Epoch: 95 [117504/225000 (52%)] Loss: 19514.769531\n",
      "Train Epoch: 95 [120000/225000 (53%)] Loss: 19574.658203\n",
      "Train Epoch: 95 [122496/225000 (54%)] Loss: 19323.818359\n",
      "Train Epoch: 95 [124992/225000 (56%)] Loss: 19775.390625\n",
      "Train Epoch: 95 [127488/225000 (57%)] Loss: 19721.308594\n",
      "Train Epoch: 95 [129984/225000 (58%)] Loss: 19627.447266\n",
      "Train Epoch: 95 [132480/225000 (59%)] Loss: 19525.773438\n",
      "Train Epoch: 95 [134976/225000 (60%)] Loss: 19178.400391\n",
      "Train Epoch: 95 [137472/225000 (61%)] Loss: 19045.949219\n",
      "Train Epoch: 95 [139968/225000 (62%)] Loss: 19096.070312\n",
      "Train Epoch: 95 [142464/225000 (63%)] Loss: 20267.320312\n",
      "Train Epoch: 95 [144960/225000 (64%)] Loss: 19811.332031\n",
      "Train Epoch: 95 [147456/225000 (66%)] Loss: 19368.773438\n",
      "Train Epoch: 95 [149952/225000 (67%)] Loss: 19427.007812\n",
      "Train Epoch: 95 [152448/225000 (68%)] Loss: 19663.628906\n",
      "Train Epoch: 95 [154944/225000 (69%)] Loss: 19650.390625\n",
      "Train Epoch: 95 [157440/225000 (70%)] Loss: 19359.748047\n",
      "Train Epoch: 95 [159936/225000 (71%)] Loss: 19485.710938\n",
      "Train Epoch: 95 [162432/225000 (72%)] Loss: 19683.689453\n",
      "Train Epoch: 95 [164928/225000 (73%)] Loss: 19789.660156\n",
      "Train Epoch: 95 [167424/225000 (74%)] Loss: 20054.666016\n",
      "Train Epoch: 95 [169920/225000 (76%)] Loss: 19541.410156\n",
      "Train Epoch: 95 [172416/225000 (77%)] Loss: 19789.382812\n",
      "Train Epoch: 95 [174912/225000 (78%)] Loss: 19232.050781\n",
      "Train Epoch: 95 [177408/225000 (79%)] Loss: 19498.097656\n",
      "Train Epoch: 95 [179904/225000 (80%)] Loss: 19467.974609\n",
      "Train Epoch: 95 [182400/225000 (81%)] Loss: 20070.535156\n",
      "Train Epoch: 95 [184896/225000 (82%)] Loss: 19459.705078\n",
      "Train Epoch: 95 [187392/225000 (83%)] Loss: 19718.187500\n",
      "Train Epoch: 95 [189888/225000 (84%)] Loss: 19683.667969\n",
      "Train Epoch: 95 [192384/225000 (86%)] Loss: 19379.734375\n",
      "Train Epoch: 95 [194880/225000 (87%)] Loss: 19493.509766\n",
      "Train Epoch: 95 [197376/225000 (88%)] Loss: 19985.203125\n",
      "Train Epoch: 95 [199872/225000 (89%)] Loss: 19295.250000\n",
      "Train Epoch: 95 [202368/225000 (90%)] Loss: 19396.414062\n",
      "Train Epoch: 95 [204864/225000 (91%)] Loss: 19398.289062\n",
      "Train Epoch: 95 [207360/225000 (92%)] Loss: 19258.941406\n",
      "Train Epoch: 95 [209856/225000 (93%)] Loss: 19465.019531\n",
      "Train Epoch: 95 [212352/225000 (94%)] Loss: 19535.869141\n",
      "Train Epoch: 95 [214848/225000 (95%)] Loss: 19478.326172\n",
      "Train Epoch: 95 [217344/225000 (97%)] Loss: 19389.753906\n",
      "Train Epoch: 95 [219840/225000 (98%)] Loss: 19545.234375\n",
      "Train Epoch: 95 [222336/225000 (99%)] Loss: 19521.781250\n",
      "Train Epoch: 95 [224832/225000 (100%)] Loss: 19836.750000\n",
      "    epoch          : 95\n",
      "    loss           : 19535.296715017066\n",
      "    val_loss       : 19429.0050721578\n",
      "Train Epoch: 96 [192/225000 (0%)] Loss: 19516.763672\n",
      "Train Epoch: 96 [2688/225000 (1%)] Loss: 19563.373047\n",
      "Train Epoch: 96 [5184/225000 (2%)] Loss: 20086.660156\n",
      "Train Epoch: 96 [7680/225000 (3%)] Loss: 19341.593750\n",
      "Train Epoch: 96 [10176/225000 (5%)] Loss: 19156.734375\n",
      "Train Epoch: 96 [12672/225000 (6%)] Loss: 19434.292969\n",
      "Train Epoch: 96 [15168/225000 (7%)] Loss: 19462.996094\n",
      "Train Epoch: 96 [17664/225000 (8%)] Loss: 19409.937500\n",
      "Train Epoch: 96 [20160/225000 (9%)] Loss: 19521.636719\n",
      "Train Epoch: 96 [22656/225000 (10%)] Loss: 19768.507812\n",
      "Train Epoch: 96 [25152/225000 (11%)] Loss: 19817.140625\n",
      "Train Epoch: 96 [27648/225000 (12%)] Loss: 19134.798828\n",
      "Train Epoch: 96 [30144/225000 (13%)] Loss: 19311.949219\n",
      "Train Epoch: 96 [32640/225000 (15%)] Loss: 20000.345703\n",
      "Train Epoch: 96 [35136/225000 (16%)] Loss: 19382.480469\n",
      "Train Epoch: 96 [37632/225000 (17%)] Loss: 19561.847656\n",
      "Train Epoch: 96 [40128/225000 (18%)] Loss: 19236.244141\n",
      "Train Epoch: 96 [42624/225000 (19%)] Loss: 19666.337891\n",
      "Train Epoch: 96 [45120/225000 (20%)] Loss: 19504.085938\n",
      "Train Epoch: 96 [47616/225000 (21%)] Loss: 19614.119141\n",
      "Train Epoch: 96 [50112/225000 (22%)] Loss: 19506.304688\n",
      "Train Epoch: 96 [52608/225000 (23%)] Loss: 19431.417969\n",
      "Train Epoch: 96 [55104/225000 (24%)] Loss: 19801.568359\n",
      "Train Epoch: 96 [57600/225000 (26%)] Loss: 19684.751953\n",
      "Train Epoch: 96 [60096/225000 (27%)] Loss: 19683.003906\n",
      "Train Epoch: 96 [62592/225000 (28%)] Loss: 19568.523438\n",
      "Train Epoch: 96 [65088/225000 (29%)] Loss: 19560.125000\n",
      "Train Epoch: 96 [67584/225000 (30%)] Loss: 19549.242188\n",
      "Train Epoch: 96 [70080/225000 (31%)] Loss: 19794.894531\n",
      "Train Epoch: 96 [72576/225000 (32%)] Loss: 19116.523438\n",
      "Train Epoch: 96 [75072/225000 (33%)] Loss: 19701.839844\n",
      "Train Epoch: 96 [77568/225000 (34%)] Loss: 19507.687500\n",
      "Train Epoch: 96 [80064/225000 (36%)] Loss: 19601.050781\n",
      "Train Epoch: 96 [82560/225000 (37%)] Loss: 19267.529297\n",
      "Train Epoch: 96 [85056/225000 (38%)] Loss: 19417.412109\n",
      "Train Epoch: 96 [87552/225000 (39%)] Loss: 19835.412109\n",
      "Train Epoch: 96 [90048/225000 (40%)] Loss: 19642.527344\n",
      "Train Epoch: 96 [92544/225000 (41%)] Loss: 19733.042969\n",
      "Train Epoch: 96 [95040/225000 (42%)] Loss: 19641.070312\n",
      "Train Epoch: 96 [97536/225000 (43%)] Loss: 19471.523438\n",
      "Train Epoch: 96 [100032/225000 (44%)] Loss: 19427.761719\n",
      "Train Epoch: 96 [102528/225000 (46%)] Loss: 19845.484375\n",
      "Train Epoch: 96 [105024/225000 (47%)] Loss: 19516.808594\n",
      "Train Epoch: 96 [107520/225000 (48%)] Loss: 19620.677734\n",
      "Train Epoch: 96 [110016/225000 (49%)] Loss: 19314.730469\n",
      "Train Epoch: 96 [112512/225000 (50%)] Loss: 19087.150391\n",
      "Train Epoch: 96 [115008/225000 (51%)] Loss: 19418.763672\n",
      "Train Epoch: 96 [117504/225000 (52%)] Loss: 19764.937500\n",
      "Train Epoch: 96 [120000/225000 (53%)] Loss: 19816.818359\n",
      "Train Epoch: 96 [122496/225000 (54%)] Loss: 19317.496094\n",
      "Train Epoch: 96 [124992/225000 (56%)] Loss: 19077.410156\n",
      "Train Epoch: 96 [127488/225000 (57%)] Loss: 19300.011719\n",
      "Train Epoch: 96 [129984/225000 (58%)] Loss: 19570.023438\n",
      "Train Epoch: 96 [132480/225000 (59%)] Loss: 19349.777344\n",
      "Train Epoch: 96 [134976/225000 (60%)] Loss: 19545.832031\n",
      "Train Epoch: 96 [137472/225000 (61%)] Loss: 19706.105469\n",
      "Train Epoch: 96 [139968/225000 (62%)] Loss: 19142.986328\n",
      "Train Epoch: 96 [142464/225000 (63%)] Loss: 19677.171875\n",
      "Train Epoch: 96 [144960/225000 (64%)] Loss: 19620.435547\n",
      "Train Epoch: 96 [147456/225000 (66%)] Loss: 19457.820312\n",
      "Train Epoch: 96 [149952/225000 (67%)] Loss: 19766.394531\n",
      "Train Epoch: 96 [152448/225000 (68%)] Loss: 19637.552734\n",
      "Train Epoch: 96 [154944/225000 (69%)] Loss: 19425.031250\n",
      "Train Epoch: 96 [157440/225000 (70%)] Loss: 19197.919922\n",
      "Train Epoch: 96 [159936/225000 (71%)] Loss: 19742.210938\n",
      "Train Epoch: 96 [162432/225000 (72%)] Loss: 19378.960938\n",
      "Train Epoch: 96 [164928/225000 (73%)] Loss: 19726.046875\n",
      "Train Epoch: 96 [167424/225000 (74%)] Loss: 19426.320312\n",
      "Train Epoch: 96 [169920/225000 (76%)] Loss: 19417.283203\n",
      "Train Epoch: 96 [172416/225000 (77%)] Loss: 19140.986328\n",
      "Train Epoch: 96 [174912/225000 (78%)] Loss: 20053.648438\n",
      "Train Epoch: 96 [177408/225000 (79%)] Loss: 19410.601562\n",
      "Train Epoch: 96 [179904/225000 (80%)] Loss: 19510.626953\n",
      "Train Epoch: 96 [182400/225000 (81%)] Loss: 19530.011719\n",
      "Train Epoch: 96 [184896/225000 (82%)] Loss: 19248.220703\n",
      "Train Epoch: 96 [187392/225000 (83%)] Loss: 19806.228516\n",
      "Train Epoch: 96 [189888/225000 (84%)] Loss: 19606.546875\n",
      "Train Epoch: 96 [192384/225000 (86%)] Loss: 19431.246094\n",
      "Train Epoch: 96 [194880/225000 (87%)] Loss: 19893.318359\n",
      "Train Epoch: 96 [197376/225000 (88%)] Loss: 19731.189453\n",
      "Train Epoch: 96 [199872/225000 (89%)] Loss: 19152.927734\n",
      "Train Epoch: 96 [202368/225000 (90%)] Loss: 19193.699219\n",
      "Train Epoch: 96 [204864/225000 (91%)] Loss: 19548.527344\n",
      "Train Epoch: 96 [207360/225000 (92%)] Loss: 19294.519531\n",
      "Train Epoch: 96 [209856/225000 (93%)] Loss: 19789.652344\n",
      "Train Epoch: 96 [212352/225000 (94%)] Loss: 19541.810547\n",
      "Train Epoch: 96 [214848/225000 (95%)] Loss: 18928.818359\n",
      "Train Epoch: 96 [217344/225000 (97%)] Loss: 19536.130859\n",
      "Train Epoch: 96 [219840/225000 (98%)] Loss: 19359.023438\n",
      "Train Epoch: 96 [222336/225000 (99%)] Loss: 19349.710938\n",
      "Train Epoch: 96 [224832/225000 (100%)] Loss: 19605.101562\n",
      "    epoch          : 96\n",
      "    loss           : 19528.649344069967\n",
      "    val_loss       : 19443.82794223578\n",
      "Train Epoch: 97 [192/225000 (0%)] Loss: 19385.853516\n",
      "Train Epoch: 97 [2688/225000 (1%)] Loss: 19750.416016\n",
      "Train Epoch: 97 [5184/225000 (2%)] Loss: 19162.585938\n",
      "Train Epoch: 97 [7680/225000 (3%)] Loss: 19449.158203\n",
      "Train Epoch: 97 [10176/225000 (5%)] Loss: 19447.980469\n",
      "Train Epoch: 97 [12672/225000 (6%)] Loss: 19518.111328\n",
      "Train Epoch: 97 [15168/225000 (7%)] Loss: 19468.566406\n",
      "Train Epoch: 97 [17664/225000 (8%)] Loss: 19467.277344\n",
      "Train Epoch: 97 [20160/225000 (9%)] Loss: 19285.402344\n",
      "Train Epoch: 97 [22656/225000 (10%)] Loss: 19641.824219\n",
      "Train Epoch: 97 [25152/225000 (11%)] Loss: 19619.707031\n",
      "Train Epoch: 97 [27648/225000 (12%)] Loss: 19495.333984\n",
      "Train Epoch: 97 [30144/225000 (13%)] Loss: 19360.048828\n",
      "Train Epoch: 97 [32640/225000 (15%)] Loss: 19036.316406\n",
      "Train Epoch: 97 [35136/225000 (16%)] Loss: 19559.058594\n",
      "Train Epoch: 97 [37632/225000 (17%)] Loss: 19084.113281\n",
      "Train Epoch: 97 [40128/225000 (18%)] Loss: 19368.843750\n",
      "Train Epoch: 97 [42624/225000 (19%)] Loss: 19001.199219\n",
      "Train Epoch: 97 [45120/225000 (20%)] Loss: 19671.132812\n",
      "Train Epoch: 97 [47616/225000 (21%)] Loss: 19306.042969\n",
      "Train Epoch: 97 [50112/225000 (22%)] Loss: 19344.195312\n",
      "Train Epoch: 97 [52608/225000 (23%)] Loss: 19034.347656\n",
      "Train Epoch: 97 [55104/225000 (24%)] Loss: 19652.537109\n",
      "Train Epoch: 97 [57600/225000 (26%)] Loss: 19086.427734\n",
      "Train Epoch: 97 [60096/225000 (27%)] Loss: 19359.296875\n",
      "Train Epoch: 97 [62592/225000 (28%)] Loss: 19711.140625\n",
      "Train Epoch: 97 [65088/225000 (29%)] Loss: 19657.628906\n",
      "Train Epoch: 97 [67584/225000 (30%)] Loss: 19387.937500\n",
      "Train Epoch: 97 [70080/225000 (31%)] Loss: 19487.443359\n",
      "Train Epoch: 97 [72576/225000 (32%)] Loss: 19179.160156\n",
      "Train Epoch: 97 [75072/225000 (33%)] Loss: 19600.777344\n",
      "Train Epoch: 97 [77568/225000 (34%)] Loss: 19404.007812\n",
      "Train Epoch: 97 [80064/225000 (36%)] Loss: 18781.863281\n",
      "Train Epoch: 97 [82560/225000 (37%)] Loss: 18976.308594\n",
      "Train Epoch: 97 [85056/225000 (38%)] Loss: 19764.646484\n",
      "Train Epoch: 97 [87552/225000 (39%)] Loss: 19362.496094\n",
      "Train Epoch: 97 [90048/225000 (40%)] Loss: 19308.402344\n",
      "Train Epoch: 97 [92544/225000 (41%)] Loss: 19306.347656\n",
      "Train Epoch: 97 [95040/225000 (42%)] Loss: 19537.625000\n",
      "Train Epoch: 97 [97536/225000 (43%)] Loss: 19796.537109\n",
      "Train Epoch: 97 [100032/225000 (44%)] Loss: 19650.324219\n",
      "Train Epoch: 97 [102528/225000 (46%)] Loss: 19455.742188\n",
      "Train Epoch: 97 [105024/225000 (47%)] Loss: 19957.527344\n",
      "Train Epoch: 97 [107520/225000 (48%)] Loss: 19484.224609\n",
      "Train Epoch: 97 [110016/225000 (49%)] Loss: 19692.300781\n",
      "Train Epoch: 97 [112512/225000 (50%)] Loss: 19785.914062\n",
      "Train Epoch: 97 [115008/225000 (51%)] Loss: 19343.500000\n",
      "Train Epoch: 97 [117504/225000 (52%)] Loss: 19564.902344\n",
      "Train Epoch: 97 [120000/225000 (53%)] Loss: 19584.794922\n",
      "Train Epoch: 97 [122496/225000 (54%)] Loss: 19758.542969\n",
      "Train Epoch: 97 [124992/225000 (56%)] Loss: 19664.328125\n",
      "Train Epoch: 97 [127488/225000 (57%)] Loss: 19122.679688\n",
      "Train Epoch: 97 [129984/225000 (58%)] Loss: 19579.199219\n",
      "Train Epoch: 97 [132480/225000 (59%)] Loss: 19932.300781\n",
      "Train Epoch: 97 [134976/225000 (60%)] Loss: 19317.328125\n",
      "Train Epoch: 97 [137472/225000 (61%)] Loss: 19274.261719\n",
      "Train Epoch: 97 [139968/225000 (62%)] Loss: 19484.320312\n",
      "Train Epoch: 97 [142464/225000 (63%)] Loss: 19571.039062\n",
      "Train Epoch: 97 [144960/225000 (64%)] Loss: 19485.421875\n",
      "Train Epoch: 97 [147456/225000 (66%)] Loss: 19499.626953\n",
      "Train Epoch: 97 [149952/225000 (67%)] Loss: 20147.355469\n",
      "Train Epoch: 97 [152448/225000 (68%)] Loss: 19459.578125\n",
      "Train Epoch: 97 [154944/225000 (69%)] Loss: 19571.023438\n",
      "Train Epoch: 97 [157440/225000 (70%)] Loss: 19434.324219\n",
      "Train Epoch: 97 [159936/225000 (71%)] Loss: 19490.361328\n",
      "Train Epoch: 97 [162432/225000 (72%)] Loss: 19699.888672\n",
      "Train Epoch: 97 [164928/225000 (73%)] Loss: 19862.695312\n",
      "Train Epoch: 97 [167424/225000 (74%)] Loss: 19749.222656\n",
      "Train Epoch: 97 [169920/225000 (76%)] Loss: 19457.042969\n",
      "Train Epoch: 97 [172416/225000 (77%)] Loss: 19733.750000\n",
      "Train Epoch: 97 [174912/225000 (78%)] Loss: 19016.285156\n",
      "Train Epoch: 97 [177408/225000 (79%)] Loss: 19265.984375\n",
      "Train Epoch: 97 [179904/225000 (80%)] Loss: 19401.562500\n",
      "Train Epoch: 97 [182400/225000 (81%)] Loss: 19219.390625\n",
      "Train Epoch: 97 [184896/225000 (82%)] Loss: 19630.185547\n",
      "Train Epoch: 97 [187392/225000 (83%)] Loss: 19582.320312\n",
      "Train Epoch: 97 [189888/225000 (84%)] Loss: 19468.812500\n",
      "Train Epoch: 97 [192384/225000 (86%)] Loss: 19685.341797\n",
      "Train Epoch: 97 [194880/225000 (87%)] Loss: 19861.035156\n",
      "Train Epoch: 97 [197376/225000 (88%)] Loss: 19253.966797\n",
      "Train Epoch: 97 [199872/225000 (89%)] Loss: 19094.378906\n",
      "Train Epoch: 97 [202368/225000 (90%)] Loss: 19821.191406\n",
      "Train Epoch: 97 [204864/225000 (91%)] Loss: 20193.138672\n",
      "Train Epoch: 97 [207360/225000 (92%)] Loss: 19350.691406\n",
      "Train Epoch: 97 [209856/225000 (93%)] Loss: 19615.232422\n",
      "Train Epoch: 97 [212352/225000 (94%)] Loss: 19153.966797\n",
      "Train Epoch: 97 [214848/225000 (95%)] Loss: 19066.402344\n",
      "Train Epoch: 97 [217344/225000 (97%)] Loss: 19628.589844\n",
      "Train Epoch: 97 [219840/225000 (98%)] Loss: 19276.406250\n",
      "Train Epoch: 97 [222336/225000 (99%)] Loss: 19258.195312\n",
      "Train Epoch: 97 [224832/225000 (100%)] Loss: 19360.339844\n",
      "    epoch          : 97\n",
      "    loss           : 19516.722711244132\n",
      "    val_loss       : 19412.407438615806\n",
      "Train Epoch: 98 [192/225000 (0%)] Loss: 19165.921875\n",
      "Train Epoch: 98 [2688/225000 (1%)] Loss: 19373.101562\n",
      "Train Epoch: 98 [5184/225000 (2%)] Loss: 19378.363281\n",
      "Train Epoch: 98 [7680/225000 (3%)] Loss: 19754.576172\n",
      "Train Epoch: 98 [10176/225000 (5%)] Loss: 19346.968750\n",
      "Train Epoch: 98 [12672/225000 (6%)] Loss: 19121.640625\n",
      "Train Epoch: 98 [15168/225000 (7%)] Loss: 19258.292969\n",
      "Train Epoch: 98 [17664/225000 (8%)] Loss: 19217.974609\n",
      "Train Epoch: 98 [20160/225000 (9%)] Loss: 19832.960938\n",
      "Train Epoch: 98 [22656/225000 (10%)] Loss: 19522.914062\n",
      "Train Epoch: 98 [25152/225000 (11%)] Loss: 19479.316406\n",
      "Train Epoch: 98 [27648/225000 (12%)] Loss: 19123.025391\n",
      "Train Epoch: 98 [30144/225000 (13%)] Loss: 19631.296875\n",
      "Train Epoch: 98 [32640/225000 (15%)] Loss: 19379.851562\n",
      "Train Epoch: 98 [35136/225000 (16%)] Loss: 20008.394531\n",
      "Train Epoch: 98 [37632/225000 (17%)] Loss: 19355.587891\n",
      "Train Epoch: 98 [40128/225000 (18%)] Loss: 19327.742188\n",
      "Train Epoch: 98 [42624/225000 (19%)] Loss: 19349.636719\n",
      "Train Epoch: 98 [45120/225000 (20%)] Loss: 19604.957031\n",
      "Train Epoch: 98 [47616/225000 (21%)] Loss: 19423.156250\n",
      "Train Epoch: 98 [50112/225000 (22%)] Loss: 19939.160156\n",
      "Train Epoch: 98 [52608/225000 (23%)] Loss: 19559.324219\n",
      "Train Epoch: 98 [55104/225000 (24%)] Loss: 19156.472656\n",
      "Train Epoch: 98 [57600/225000 (26%)] Loss: 18804.738281\n",
      "Train Epoch: 98 [60096/225000 (27%)] Loss: 19807.537109\n",
      "Train Epoch: 98 [62592/225000 (28%)] Loss: 19698.804688\n",
      "Train Epoch: 98 [65088/225000 (29%)] Loss: 19570.093750\n",
      "Train Epoch: 98 [67584/225000 (30%)] Loss: 19436.019531\n",
      "Train Epoch: 98 [70080/225000 (31%)] Loss: 19441.625000\n",
      "Train Epoch: 98 [72576/225000 (32%)] Loss: 20115.269531\n",
      "Train Epoch: 98 [75072/225000 (33%)] Loss: 19636.109375\n",
      "Train Epoch: 98 [77568/225000 (34%)] Loss: 19181.027344\n",
      "Train Epoch: 98 [80064/225000 (36%)] Loss: 19602.828125\n",
      "Train Epoch: 98 [82560/225000 (37%)] Loss: 19382.281250\n",
      "Train Epoch: 98 [85056/225000 (38%)] Loss: 19821.761719\n",
      "Train Epoch: 98 [87552/225000 (39%)] Loss: 19773.279297\n",
      "Train Epoch: 98 [90048/225000 (40%)] Loss: 19377.453125\n",
      "Train Epoch: 98 [92544/225000 (41%)] Loss: 19244.753906\n",
      "Train Epoch: 98 [95040/225000 (42%)] Loss: 19531.183594\n",
      "Train Epoch: 98 [97536/225000 (43%)] Loss: 19199.199219\n",
      "Train Epoch: 98 [100032/225000 (44%)] Loss: 19428.369141\n",
      "Train Epoch: 98 [102528/225000 (46%)] Loss: 19078.734375\n",
      "Train Epoch: 98 [105024/225000 (47%)] Loss: 19362.070312\n",
      "Train Epoch: 98 [107520/225000 (48%)] Loss: 18865.035156\n",
      "Train Epoch: 98 [110016/225000 (49%)] Loss: 19267.755859\n",
      "Train Epoch: 98 [112512/225000 (50%)] Loss: 18481.757812\n",
      "Train Epoch: 98 [115008/225000 (51%)] Loss: 19268.367188\n",
      "Train Epoch: 98 [117504/225000 (52%)] Loss: 19460.251953\n",
      "Train Epoch: 98 [120000/225000 (53%)] Loss: 19728.466797\n",
      "Train Epoch: 98 [122496/225000 (54%)] Loss: 19778.642578\n",
      "Train Epoch: 98 [124992/225000 (56%)] Loss: 19662.015625\n",
      "Train Epoch: 98 [127488/225000 (57%)] Loss: 19771.371094\n",
      "Train Epoch: 98 [129984/225000 (58%)] Loss: 19883.285156\n",
      "Train Epoch: 98 [132480/225000 (59%)] Loss: 18827.853516\n",
      "Train Epoch: 98 [134976/225000 (60%)] Loss: 19436.417969\n",
      "Train Epoch: 98 [137472/225000 (61%)] Loss: 19685.617188\n",
      "Train Epoch: 98 [139968/225000 (62%)] Loss: 19594.058594\n",
      "Train Epoch: 98 [142464/225000 (63%)] Loss: 19232.585938\n",
      "Train Epoch: 98 [144960/225000 (64%)] Loss: 19160.839844\n",
      "Train Epoch: 98 [147456/225000 (66%)] Loss: 19756.628906\n",
      "Train Epoch: 98 [149952/225000 (67%)] Loss: 19400.128906\n",
      "Train Epoch: 98 [152448/225000 (68%)] Loss: 19493.195312\n",
      "Train Epoch: 98 [154944/225000 (69%)] Loss: 19686.222656\n",
      "Train Epoch: 98 [157440/225000 (70%)] Loss: 19744.523438\n",
      "Train Epoch: 98 [159936/225000 (71%)] Loss: 19464.277344\n",
      "Train Epoch: 98 [162432/225000 (72%)] Loss: 19819.902344\n",
      "Train Epoch: 98 [164928/225000 (73%)] Loss: 19441.769531\n",
      "Train Epoch: 98 [167424/225000 (74%)] Loss: 19352.308594\n",
      "Train Epoch: 98 [169920/225000 (76%)] Loss: 19351.601562\n",
      "Train Epoch: 98 [172416/225000 (77%)] Loss: 19626.453125\n",
      "Train Epoch: 98 [174912/225000 (78%)] Loss: 19471.503906\n",
      "Train Epoch: 98 [177408/225000 (79%)] Loss: 19388.095703\n",
      "Train Epoch: 98 [179904/225000 (80%)] Loss: 19440.472656\n",
      "Train Epoch: 98 [182400/225000 (81%)] Loss: 19387.265625\n",
      "Train Epoch: 98 [184896/225000 (82%)] Loss: 19376.792969\n",
      "Train Epoch: 98 [187392/225000 (83%)] Loss: 19623.890625\n",
      "Train Epoch: 98 [189888/225000 (84%)] Loss: 19225.664062\n",
      "Train Epoch: 98 [192384/225000 (86%)] Loss: 19646.398438\n",
      "Train Epoch: 98 [194880/225000 (87%)] Loss: 19693.843750\n",
      "Train Epoch: 98 [197376/225000 (88%)] Loss: 19715.361328\n",
      "Train Epoch: 98 [199872/225000 (89%)] Loss: 19632.882812\n",
      "Train Epoch: 98 [202368/225000 (90%)] Loss: 19499.357422\n",
      "Train Epoch: 98 [204864/225000 (91%)] Loss: 19426.285156\n",
      "Train Epoch: 98 [207360/225000 (92%)] Loss: 19481.050781\n",
      "Train Epoch: 98 [209856/225000 (93%)] Loss: 19476.000000\n",
      "Train Epoch: 98 [212352/225000 (94%)] Loss: 19601.976562\n",
      "Train Epoch: 98 [214848/225000 (95%)] Loss: 19355.835938\n",
      "Train Epoch: 98 [217344/225000 (97%)] Loss: 19203.601562\n",
      "Train Epoch: 98 [219840/225000 (98%)] Loss: 19747.296875\n",
      "Train Epoch: 98 [222336/225000 (99%)] Loss: 19453.107422\n",
      "Train Epoch: 98 [224832/225000 (100%)] Loss: 19247.978516\n",
      "    epoch          : 98\n",
      "    loss           : 19520.043865321033\n",
      "    val_loss       : 19409.7286094418\n",
      "Train Epoch: 99 [192/225000 (0%)] Loss: 19373.677734\n",
      "Train Epoch: 99 [2688/225000 (1%)] Loss: 19688.349609\n",
      "Train Epoch: 99 [5184/225000 (2%)] Loss: 19900.468750\n",
      "Train Epoch: 99 [7680/225000 (3%)] Loss: 19528.113281\n",
      "Train Epoch: 99 [10176/225000 (5%)] Loss: 19680.671875\n",
      "Train Epoch: 99 [12672/225000 (6%)] Loss: 19581.417969\n",
      "Train Epoch: 99 [15168/225000 (7%)] Loss: 19037.257812\n",
      "Train Epoch: 99 [17664/225000 (8%)] Loss: 19764.759766\n",
      "Train Epoch: 99 [20160/225000 (9%)] Loss: 20276.236328\n",
      "Train Epoch: 99 [22656/225000 (10%)] Loss: 19136.119141\n",
      "Train Epoch: 99 [25152/225000 (11%)] Loss: 19771.558594\n",
      "Train Epoch: 99 [27648/225000 (12%)] Loss: 19370.380859\n",
      "Train Epoch: 99 [30144/225000 (13%)] Loss: 18883.792969\n",
      "Train Epoch: 99 [32640/225000 (15%)] Loss: 19915.820312\n",
      "Train Epoch: 99 [35136/225000 (16%)] Loss: 19842.748047\n",
      "Train Epoch: 99 [37632/225000 (17%)] Loss: 19655.320312\n",
      "Train Epoch: 99 [40128/225000 (18%)] Loss: 19801.232422\n",
      "Train Epoch: 99 [42624/225000 (19%)] Loss: 19587.595703\n",
      "Train Epoch: 99 [45120/225000 (20%)] Loss: 18988.566406\n",
      "Train Epoch: 99 [47616/225000 (21%)] Loss: 19903.808594\n",
      "Train Epoch: 99 [50112/225000 (22%)] Loss: 19287.148438\n",
      "Train Epoch: 99 [52608/225000 (23%)] Loss: 19150.863281\n",
      "Train Epoch: 99 [55104/225000 (24%)] Loss: 20006.773438\n",
      "Train Epoch: 99 [57600/225000 (26%)] Loss: 20066.542969\n",
      "Train Epoch: 99 [60096/225000 (27%)] Loss: 19676.417969\n",
      "Train Epoch: 99 [62592/225000 (28%)] Loss: 19990.941406\n",
      "Train Epoch: 99 [65088/225000 (29%)] Loss: 19367.126953\n",
      "Train Epoch: 99 [67584/225000 (30%)] Loss: 19572.820312\n",
      "Train Epoch: 99 [70080/225000 (31%)] Loss: 19542.281250\n",
      "Train Epoch: 99 [72576/225000 (32%)] Loss: 19623.445312\n",
      "Train Epoch: 99 [75072/225000 (33%)] Loss: 19781.226562\n",
      "Train Epoch: 99 [77568/225000 (34%)] Loss: 19595.242188\n",
      "Train Epoch: 99 [80064/225000 (36%)] Loss: 20168.560547\n",
      "Train Epoch: 99 [82560/225000 (37%)] Loss: 19942.117188\n",
      "Train Epoch: 99 [85056/225000 (38%)] Loss: 19486.113281\n",
      "Train Epoch: 99 [87552/225000 (39%)] Loss: 19845.931641\n",
      "Train Epoch: 99 [90048/225000 (40%)] Loss: 19258.640625\n",
      "Train Epoch: 99 [92544/225000 (41%)] Loss: 20008.140625\n",
      "Train Epoch: 99 [95040/225000 (42%)] Loss: 19716.238281\n",
      "Train Epoch: 99 [97536/225000 (43%)] Loss: 18971.132812\n",
      "Train Epoch: 99 [100032/225000 (44%)] Loss: 19590.767578\n",
      "Train Epoch: 99 [102528/225000 (46%)] Loss: 19843.945312\n",
      "Train Epoch: 99 [105024/225000 (47%)] Loss: 19434.964844\n",
      "Train Epoch: 99 [107520/225000 (48%)] Loss: 19526.742188\n",
      "Train Epoch: 99 [110016/225000 (49%)] Loss: 19605.878906\n",
      "Train Epoch: 99 [112512/225000 (50%)] Loss: 19638.822266\n",
      "Train Epoch: 99 [115008/225000 (51%)] Loss: 19426.843750\n",
      "Train Epoch: 99 [117504/225000 (52%)] Loss: 19968.378906\n",
      "Train Epoch: 99 [120000/225000 (53%)] Loss: 19590.046875\n",
      "Train Epoch: 99 [122496/225000 (54%)] Loss: 19918.531250\n",
      "Train Epoch: 99 [124992/225000 (56%)] Loss: 19095.117188\n",
      "Train Epoch: 99 [127488/225000 (57%)] Loss: 19386.824219\n",
      "Train Epoch: 99 [129984/225000 (58%)] Loss: 19359.312500\n",
      "Train Epoch: 99 [132480/225000 (59%)] Loss: 19791.824219\n",
      "Train Epoch: 99 [134976/225000 (60%)] Loss: 19544.683594\n",
      "Train Epoch: 99 [137472/225000 (61%)] Loss: 19600.781250\n",
      "Train Epoch: 99 [139968/225000 (62%)] Loss: 19002.539062\n",
      "Train Epoch: 99 [142464/225000 (63%)] Loss: 19970.962891\n",
      "Train Epoch: 99 [144960/225000 (64%)] Loss: 18979.566406\n",
      "Train Epoch: 99 [147456/225000 (66%)] Loss: 19684.613281\n",
      "Train Epoch: 99 [149952/225000 (67%)] Loss: 20218.417969\n",
      "Train Epoch: 99 [152448/225000 (68%)] Loss: 19368.451172\n",
      "Train Epoch: 99 [154944/225000 (69%)] Loss: 19540.304688\n",
      "Train Epoch: 99 [157440/225000 (70%)] Loss: 19332.437500\n",
      "Train Epoch: 99 [159936/225000 (71%)] Loss: 19559.789062\n",
      "Train Epoch: 99 [162432/225000 (72%)] Loss: 19114.339844\n",
      "Train Epoch: 99 [164928/225000 (73%)] Loss: 19557.968750\n",
      "Train Epoch: 99 [167424/225000 (74%)] Loss: 19145.347656\n",
      "Train Epoch: 99 [169920/225000 (76%)] Loss: 19760.964844\n",
      "Train Epoch: 99 [172416/225000 (77%)] Loss: 19554.544922\n",
      "Train Epoch: 99 [174912/225000 (78%)] Loss: 19818.285156\n",
      "Train Epoch: 99 [177408/225000 (79%)] Loss: 19814.425781\n",
      "Train Epoch: 99 [179904/225000 (80%)] Loss: 19824.835938\n",
      "Train Epoch: 99 [182400/225000 (81%)] Loss: 19781.570312\n",
      "Train Epoch: 99 [184896/225000 (82%)] Loss: 19166.980469\n",
      "Train Epoch: 99 [187392/225000 (83%)] Loss: 19058.517578\n",
      "Train Epoch: 99 [189888/225000 (84%)] Loss: 19228.687500\n",
      "Train Epoch: 99 [192384/225000 (86%)] Loss: 19252.490234\n",
      "Train Epoch: 99 [194880/225000 (87%)] Loss: 19431.142578\n",
      "Train Epoch: 99 [197376/225000 (88%)] Loss: 19545.386719\n",
      "Train Epoch: 99 [199872/225000 (89%)] Loss: 19973.828125\n",
      "Train Epoch: 99 [202368/225000 (90%)] Loss: 19370.265625\n",
      "Train Epoch: 99 [204864/225000 (91%)] Loss: 19635.091797\n",
      "Train Epoch: 99 [207360/225000 (92%)] Loss: 19481.607422\n",
      "Train Epoch: 99 [209856/225000 (93%)] Loss: 20022.328125\n",
      "Train Epoch: 99 [212352/225000 (94%)] Loss: 20128.503906\n",
      "Train Epoch: 99 [214848/225000 (95%)] Loss: 19634.445312\n",
      "Train Epoch: 99 [217344/225000 (97%)] Loss: 19826.875000\n",
      "Train Epoch: 99 [219840/225000 (98%)] Loss: 19844.097656\n",
      "Train Epoch: 99 [222336/225000 (99%)] Loss: 19364.546875\n",
      "Train Epoch: 99 [224832/225000 (100%)] Loss: 19292.218750\n",
      "    epoch          : 99\n",
      "    loss           : 19504.862939619772\n",
      "    val_loss       : 19411.33794424552\n",
      "Train Epoch: 100 [192/225000 (0%)] Loss: 19240.906250\n",
      "Train Epoch: 100 [2688/225000 (1%)] Loss: 19211.369141\n",
      "Train Epoch: 100 [5184/225000 (2%)] Loss: 19946.859375\n",
      "Train Epoch: 100 [7680/225000 (3%)] Loss: 19665.564453\n",
      "Train Epoch: 100 [10176/225000 (5%)] Loss: 19430.906250\n",
      "Train Epoch: 100 [12672/225000 (6%)] Loss: 19498.531250\n",
      "Train Epoch: 100 [15168/225000 (7%)] Loss: 19194.312500\n",
      "Train Epoch: 100 [17664/225000 (8%)] Loss: 19321.378906\n",
      "Train Epoch: 100 [20160/225000 (9%)] Loss: 19617.486328\n",
      "Train Epoch: 100 [22656/225000 (10%)] Loss: 20149.066406\n",
      "Train Epoch: 100 [25152/225000 (11%)] Loss: 19594.996094\n",
      "Train Epoch: 100 [27648/225000 (12%)] Loss: 20091.261719\n",
      "Train Epoch: 100 [30144/225000 (13%)] Loss: 19774.841797\n",
      "Train Epoch: 100 [32640/225000 (15%)] Loss: 20188.820312\n",
      "Train Epoch: 100 [35136/225000 (16%)] Loss: 20188.919922\n",
      "Train Epoch: 100 [37632/225000 (17%)] Loss: 19217.255859\n",
      "Train Epoch: 100 [40128/225000 (18%)] Loss: 19608.296875\n",
      "Train Epoch: 100 [42624/225000 (19%)] Loss: 19467.712891\n",
      "Train Epoch: 100 [45120/225000 (20%)] Loss: 19343.279297\n",
      "Train Epoch: 100 [47616/225000 (21%)] Loss: 19031.316406\n",
      "Train Epoch: 100 [50112/225000 (22%)] Loss: 19045.070312\n",
      "Train Epoch: 100 [52608/225000 (23%)] Loss: 19660.447266\n",
      "Train Epoch: 100 [55104/225000 (24%)] Loss: 19134.011719\n",
      "Train Epoch: 100 [57600/225000 (26%)] Loss: 19962.271484\n",
      "Train Epoch: 100 [60096/225000 (27%)] Loss: 19246.458984\n",
      "Train Epoch: 100 [62592/225000 (28%)] Loss: 19098.546875\n",
      "Train Epoch: 100 [65088/225000 (29%)] Loss: 19671.949219\n",
      "Train Epoch: 100 [67584/225000 (30%)] Loss: 19653.412109\n",
      "Train Epoch: 100 [70080/225000 (31%)] Loss: 19344.199219\n",
      "Train Epoch: 100 [72576/225000 (32%)] Loss: 19899.210938\n",
      "Train Epoch: 100 [75072/225000 (33%)] Loss: 19840.960938\n",
      "Train Epoch: 100 [77568/225000 (34%)] Loss: 19461.328125\n",
      "Train Epoch: 100 [80064/225000 (36%)] Loss: 19421.476562\n",
      "Train Epoch: 100 [82560/225000 (37%)] Loss: 19081.050781\n",
      "Train Epoch: 100 [85056/225000 (38%)] Loss: 19569.412109\n",
      "Train Epoch: 100 [87552/225000 (39%)] Loss: 19468.105469\n",
      "Train Epoch: 100 [90048/225000 (40%)] Loss: 19340.042969\n",
      "Train Epoch: 100 [92544/225000 (41%)] Loss: 19468.187500\n",
      "Train Epoch: 100 [95040/225000 (42%)] Loss: 19714.421875\n",
      "Train Epoch: 100 [97536/225000 (43%)] Loss: 19733.468750\n",
      "Train Epoch: 100 [100032/225000 (44%)] Loss: 19398.546875\n",
      "Train Epoch: 100 [102528/225000 (46%)] Loss: 19898.861328\n",
      "Train Epoch: 100 [105024/225000 (47%)] Loss: 19705.478516\n",
      "Train Epoch: 100 [107520/225000 (48%)] Loss: 19578.970703\n",
      "Train Epoch: 100 [110016/225000 (49%)] Loss: 19668.675781\n",
      "Train Epoch: 100 [112512/225000 (50%)] Loss: 20037.171875\n",
      "Train Epoch: 100 [115008/225000 (51%)] Loss: 19434.373047\n",
      "Train Epoch: 100 [117504/225000 (52%)] Loss: 19311.337891\n",
      "Train Epoch: 100 [120000/225000 (53%)] Loss: 19613.744141\n",
      "Train Epoch: 100 [122496/225000 (54%)] Loss: 19516.253906\n",
      "Train Epoch: 100 [124992/225000 (56%)] Loss: 19823.843750\n",
      "Train Epoch: 100 [127488/225000 (57%)] Loss: 19539.375000\n",
      "Train Epoch: 100 [129984/225000 (58%)] Loss: 19631.714844\n",
      "Train Epoch: 100 [132480/225000 (59%)] Loss: 19102.078125\n",
      "Train Epoch: 100 [134976/225000 (60%)] Loss: 19011.410156\n",
      "Train Epoch: 100 [137472/225000 (61%)] Loss: 19765.640625\n",
      "Train Epoch: 100 [139968/225000 (62%)] Loss: 19943.246094\n",
      "Train Epoch: 100 [142464/225000 (63%)] Loss: 19083.183594\n",
      "Train Epoch: 100 [144960/225000 (64%)] Loss: 19277.787109\n",
      "Train Epoch: 100 [147456/225000 (66%)] Loss: 19376.093750\n",
      "Train Epoch: 100 [149952/225000 (67%)] Loss: 19539.863281\n",
      "Train Epoch: 100 [152448/225000 (68%)] Loss: 19486.382812\n",
      "Train Epoch: 100 [154944/225000 (69%)] Loss: 19899.832031\n",
      "Train Epoch: 100 [157440/225000 (70%)] Loss: 19511.283203\n",
      "Train Epoch: 100 [159936/225000 (71%)] Loss: 19802.914062\n",
      "Train Epoch: 100 [162432/225000 (72%)] Loss: 19411.916016\n",
      "Train Epoch: 100 [164928/225000 (73%)] Loss: 19800.695312\n",
      "Train Epoch: 100 [167424/225000 (74%)] Loss: 19550.488281\n",
      "Train Epoch: 100 [169920/225000 (76%)] Loss: 19493.068359\n",
      "Train Epoch: 100 [172416/225000 (77%)] Loss: 19416.394531\n",
      "Train Epoch: 100 [174912/225000 (78%)] Loss: 19490.398438\n",
      "Train Epoch: 100 [177408/225000 (79%)] Loss: 19345.794922\n",
      "Train Epoch: 100 [179904/225000 (80%)] Loss: 19488.261719\n",
      "Train Epoch: 100 [182400/225000 (81%)] Loss: 19199.433594\n",
      "Train Epoch: 100 [184896/225000 (82%)] Loss: 18821.605469\n",
      "Train Epoch: 100 [187392/225000 (83%)] Loss: 19421.523438\n",
      "Train Epoch: 100 [189888/225000 (84%)] Loss: 19210.712891\n",
      "Train Epoch: 100 [192384/225000 (86%)] Loss: 18839.384766\n",
      "Train Epoch: 100 [194880/225000 (87%)] Loss: 18711.996094\n",
      "Train Epoch: 100 [197376/225000 (88%)] Loss: 19132.126953\n",
      "Train Epoch: 100 [199872/225000 (89%)] Loss: 19695.097656\n",
      "Train Epoch: 100 [202368/225000 (90%)] Loss: 19814.613281\n",
      "Train Epoch: 100 [204864/225000 (91%)] Loss: 19350.035156\n",
      "Train Epoch: 100 [207360/225000 (92%)] Loss: 19484.388672\n",
      "Train Epoch: 100 [209856/225000 (93%)] Loss: 19325.986328\n",
      "Train Epoch: 100 [212352/225000 (94%)] Loss: 19067.287109\n",
      "Train Epoch: 100 [214848/225000 (95%)] Loss: 19713.566406\n",
      "Train Epoch: 100 [217344/225000 (97%)] Loss: 19527.246094\n",
      "Train Epoch: 100 [219840/225000 (98%)] Loss: 19398.656250\n",
      "Train Epoch: 100 [222336/225000 (99%)] Loss: 19434.796875\n",
      "Train Epoch: 100 [224832/225000 (100%)] Loss: 20035.662109\n",
      "    epoch          : 100\n",
      "    loss           : 19493.053155996695\n",
      "    val_loss       : 19406.047886959015\n",
      "Saving checkpoint: saved/models/Molecular_VaeCategory/0803_194629/checkpoint-epoch100.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 101 [192/225000 (0%)] Loss: 19409.101562\n",
      "Train Epoch: 101 [2688/225000 (1%)] Loss: 19671.144531\n",
      "Train Epoch: 101 [5184/225000 (2%)] Loss: 19372.269531\n",
      "Train Epoch: 101 [7680/225000 (3%)] Loss: 19845.128906\n",
      "Train Epoch: 101 [10176/225000 (5%)] Loss: 19092.501953\n",
      "Train Epoch: 101 [12672/225000 (6%)] Loss: 19794.365234\n",
      "Train Epoch: 101 [15168/225000 (7%)] Loss: 19237.246094\n",
      "Train Epoch: 101 [17664/225000 (8%)] Loss: 18926.460938\n",
      "Train Epoch: 101 [20160/225000 (9%)] Loss: 19540.011719\n",
      "Train Epoch: 101 [22656/225000 (10%)] Loss: 19178.578125\n",
      "Train Epoch: 101 [25152/225000 (11%)] Loss: 19412.615234\n",
      "Train Epoch: 101 [27648/225000 (12%)] Loss: 19741.101562\n",
      "Train Epoch: 101 [30144/225000 (13%)] Loss: 19709.433594\n",
      "Train Epoch: 101 [32640/225000 (15%)] Loss: 19417.107422\n",
      "Train Epoch: 101 [35136/225000 (16%)] Loss: 19577.238281\n",
      "Train Epoch: 101 [37632/225000 (17%)] Loss: 19195.250000\n",
      "Train Epoch: 101 [40128/225000 (18%)] Loss: 19346.378906\n",
      "Train Epoch: 101 [42624/225000 (19%)] Loss: 19940.027344\n",
      "Train Epoch: 101 [45120/225000 (20%)] Loss: 19481.718750\n",
      "Train Epoch: 101 [47616/225000 (21%)] Loss: 19211.210938\n",
      "Train Epoch: 101 [50112/225000 (22%)] Loss: 19786.183594\n",
      "Train Epoch: 101 [52608/225000 (23%)] Loss: 19262.019531\n",
      "Train Epoch: 101 [55104/225000 (24%)] Loss: 19203.332031\n",
      "Train Epoch: 101 [57600/225000 (26%)] Loss: 19874.750000\n",
      "Train Epoch: 101 [60096/225000 (27%)] Loss: 19264.539062\n",
      "Train Epoch: 101 [62592/225000 (28%)] Loss: 19412.839844\n",
      "Train Epoch: 101 [65088/225000 (29%)] Loss: 19653.453125\n",
      "Train Epoch: 101 [67584/225000 (30%)] Loss: 19891.898438\n",
      "Train Epoch: 101 [70080/225000 (31%)] Loss: 19383.183594\n",
      "Train Epoch: 101 [72576/225000 (32%)] Loss: 19861.050781\n",
      "Train Epoch: 101 [75072/225000 (33%)] Loss: 19540.476562\n",
      "Train Epoch: 101 [77568/225000 (34%)] Loss: 19653.023438\n",
      "Train Epoch: 101 [80064/225000 (36%)] Loss: 19226.242188\n",
      "Train Epoch: 101 [82560/225000 (37%)] Loss: 19819.867188\n",
      "Train Epoch: 101 [85056/225000 (38%)] Loss: 19108.152344\n",
      "Train Epoch: 101 [87552/225000 (39%)] Loss: 19039.582031\n",
      "Train Epoch: 101 [90048/225000 (40%)] Loss: 19691.886719\n",
      "Train Epoch: 101 [92544/225000 (41%)] Loss: 19684.542969\n",
      "Train Epoch: 101 [95040/225000 (42%)] Loss: 19558.312500\n",
      "Train Epoch: 101 [97536/225000 (43%)] Loss: 19687.488281\n",
      "Train Epoch: 101 [100032/225000 (44%)] Loss: 19232.863281\n",
      "Train Epoch: 101 [102528/225000 (46%)] Loss: 19679.925781\n",
      "Train Epoch: 101 [105024/225000 (47%)] Loss: 19543.261719\n",
      "Train Epoch: 101 [107520/225000 (48%)] Loss: 19075.312500\n",
      "Train Epoch: 101 [110016/225000 (49%)] Loss: 19219.769531\n",
      "Train Epoch: 101 [112512/225000 (50%)] Loss: 19242.945312\n",
      "Train Epoch: 101 [115008/225000 (51%)] Loss: 19041.652344\n",
      "Train Epoch: 101 [117504/225000 (52%)] Loss: 19388.027344\n",
      "Train Epoch: 101 [120000/225000 (53%)] Loss: 19483.523438\n",
      "Train Epoch: 101 [122496/225000 (54%)] Loss: 19449.250000\n",
      "Train Epoch: 101 [124992/225000 (56%)] Loss: 19680.257812\n",
      "Train Epoch: 101 [127488/225000 (57%)] Loss: 19358.603516\n",
      "Train Epoch: 101 [129984/225000 (58%)] Loss: 19520.789062\n",
      "Train Epoch: 101 [132480/225000 (59%)] Loss: 19553.255859\n",
      "Train Epoch: 101 [134976/225000 (60%)] Loss: 19169.515625\n",
      "Train Epoch: 101 [137472/225000 (61%)] Loss: 18939.242188\n",
      "Train Epoch: 101 [139968/225000 (62%)] Loss: 19401.785156\n",
      "Train Epoch: 101 [142464/225000 (63%)] Loss: 19427.423828\n",
      "Train Epoch: 101 [144960/225000 (64%)] Loss: 19456.433594\n",
      "Train Epoch: 101 [147456/225000 (66%)] Loss: 19349.771484\n",
      "Train Epoch: 101 [149952/225000 (67%)] Loss: 19761.056641\n",
      "Train Epoch: 101 [152448/225000 (68%)] Loss: 19689.210938\n",
      "Train Epoch: 101 [154944/225000 (69%)] Loss: 19922.363281\n",
      "Train Epoch: 101 [157440/225000 (70%)] Loss: 19891.238281\n",
      "Train Epoch: 101 [159936/225000 (71%)] Loss: 19394.500000\n",
      "Train Epoch: 101 [162432/225000 (72%)] Loss: 19012.539062\n",
      "Train Epoch: 101 [164928/225000 (73%)] Loss: 19372.654297\n",
      "Train Epoch: 101 [167424/225000 (74%)] Loss: 19694.457031\n",
      "Train Epoch: 101 [169920/225000 (76%)] Loss: 19405.835938\n",
      "Train Epoch: 101 [172416/225000 (77%)] Loss: 19374.900391\n",
      "Train Epoch: 101 [174912/225000 (78%)] Loss: 19221.220703\n",
      "Train Epoch: 101 [177408/225000 (79%)] Loss: 19654.070312\n",
      "Train Epoch: 101 [179904/225000 (80%)] Loss: 19657.615234\n",
      "Train Epoch: 101 [182400/225000 (81%)] Loss: 19399.900391\n",
      "Train Epoch: 101 [184896/225000 (82%)] Loss: 19036.609375\n",
      "Train Epoch: 101 [187392/225000 (83%)] Loss: 19608.078125\n",
      "Train Epoch: 101 [189888/225000 (84%)] Loss: 19231.957031\n",
      "Train Epoch: 101 [192384/225000 (86%)] Loss: 19371.464844\n",
      "Train Epoch: 101 [194880/225000 (87%)] Loss: 19838.804688\n",
      "Train Epoch: 101 [197376/225000 (88%)] Loss: 19902.984375\n",
      "Train Epoch: 101 [199872/225000 (89%)] Loss: 19355.464844\n",
      "Train Epoch: 101 [202368/225000 (90%)] Loss: 19363.421875\n",
      "Train Epoch: 101 [204864/225000 (91%)] Loss: 19343.130859\n",
      "Train Epoch: 101 [207360/225000 (92%)] Loss: 19360.031250\n",
      "Train Epoch: 101 [209856/225000 (93%)] Loss: 19173.976562\n",
      "Train Epoch: 101 [212352/225000 (94%)] Loss: 19646.753906\n",
      "Train Epoch: 101 [214848/225000 (95%)] Loss: 19214.785156\n",
      "Train Epoch: 101 [217344/225000 (97%)] Loss: 19290.119141\n",
      "Train Epoch: 101 [219840/225000 (98%)] Loss: 19202.287109\n",
      "Train Epoch: 101 [222336/225000 (99%)] Loss: 19462.863281\n",
      "Train Epoch: 101 [224832/225000 (100%)] Loss: 19789.250000\n",
      "    epoch          : 101\n",
      "    loss           : 19490.385532209897\n",
      "    val_loss       : 19387.97823185684\n",
      "Train Epoch: 102 [192/225000 (0%)] Loss: 18934.101562\n",
      "Train Epoch: 102 [2688/225000 (1%)] Loss: 19555.226562\n",
      "Train Epoch: 102 [5184/225000 (2%)] Loss: 18877.130859\n",
      "Train Epoch: 102 [7680/225000 (3%)] Loss: 19723.984375\n",
      "Train Epoch: 102 [10176/225000 (5%)] Loss: 19779.658203\n",
      "Train Epoch: 102 [12672/225000 (6%)] Loss: 19259.484375\n",
      "Train Epoch: 102 [15168/225000 (7%)] Loss: 19790.421875\n",
      "Train Epoch: 102 [17664/225000 (8%)] Loss: 19745.007812\n",
      "Train Epoch: 102 [20160/225000 (9%)] Loss: 19399.535156\n",
      "Train Epoch: 102 [22656/225000 (10%)] Loss: 19044.785156\n",
      "Train Epoch: 102 [25152/225000 (11%)] Loss: 19550.960938\n",
      "Train Epoch: 102 [27648/225000 (12%)] Loss: 19687.417969\n",
      "Train Epoch: 102 [30144/225000 (13%)] Loss: 19067.773438\n",
      "Train Epoch: 102 [32640/225000 (15%)] Loss: 19629.412109\n",
      "Train Epoch: 102 [35136/225000 (16%)] Loss: 18938.087891\n",
      "Train Epoch: 102 [37632/225000 (17%)] Loss: 18947.636719\n",
      "Train Epoch: 102 [40128/225000 (18%)] Loss: 19589.984375\n",
      "Train Epoch: 102 [42624/225000 (19%)] Loss: 19202.400391\n",
      "Train Epoch: 102 [45120/225000 (20%)] Loss: 19372.404297\n",
      "Train Epoch: 102 [47616/225000 (21%)] Loss: 19335.990234\n",
      "Train Epoch: 102 [50112/225000 (22%)] Loss: 19359.728516\n",
      "Train Epoch: 102 [52608/225000 (23%)] Loss: 18991.994141\n",
      "Train Epoch: 102 [55104/225000 (24%)] Loss: 19369.019531\n",
      "Train Epoch: 102 [57600/225000 (26%)] Loss: 19139.255859\n",
      "Train Epoch: 102 [60096/225000 (27%)] Loss: 19386.609375\n",
      "Train Epoch: 102 [62592/225000 (28%)] Loss: 19641.152344\n",
      "Train Epoch: 102 [65088/225000 (29%)] Loss: 19478.015625\n",
      "Train Epoch: 102 [67584/225000 (30%)] Loss: 20125.722656\n",
      "Train Epoch: 102 [70080/225000 (31%)] Loss: 19157.884766\n",
      "Train Epoch: 102 [72576/225000 (32%)] Loss: 19368.777344\n",
      "Train Epoch: 102 [75072/225000 (33%)] Loss: 19026.156250\n",
      "Train Epoch: 102 [77568/225000 (34%)] Loss: 19638.457031\n",
      "Train Epoch: 102 [80064/225000 (36%)] Loss: 19580.921875\n",
      "Train Epoch: 102 [82560/225000 (37%)] Loss: 19059.289062\n",
      "Train Epoch: 102 [85056/225000 (38%)] Loss: 19431.585938\n",
      "Train Epoch: 102 [87552/225000 (39%)] Loss: 19704.732422\n",
      "Train Epoch: 102 [90048/225000 (40%)] Loss: 19152.878906\n",
      "Train Epoch: 102 [92544/225000 (41%)] Loss: 19770.062500\n",
      "Train Epoch: 102 [95040/225000 (42%)] Loss: 19753.761719\n",
      "Train Epoch: 102 [97536/225000 (43%)] Loss: 19400.935547\n",
      "Train Epoch: 102 [100032/225000 (44%)] Loss: 19284.875000\n",
      "Train Epoch: 102 [102528/225000 (46%)] Loss: 19527.179688\n",
      "Train Epoch: 102 [105024/225000 (47%)] Loss: 19788.107422\n",
      "Train Epoch: 102 [107520/225000 (48%)] Loss: 19343.919922\n",
      "Train Epoch: 102 [110016/225000 (49%)] Loss: 19455.585938\n",
      "Train Epoch: 102 [112512/225000 (50%)] Loss: 19425.871094\n",
      "Train Epoch: 102 [115008/225000 (51%)] Loss: 19571.894531\n",
      "Train Epoch: 102 [117504/225000 (52%)] Loss: 19313.697266\n",
      "Train Epoch: 102 [120000/225000 (53%)] Loss: 19734.011719\n",
      "Train Epoch: 102 [122496/225000 (54%)] Loss: 19855.414062\n",
      "Train Epoch: 102 [124992/225000 (56%)] Loss: 19624.117188\n",
      "Train Epoch: 102 [127488/225000 (57%)] Loss: 19381.414062\n",
      "Train Epoch: 102 [129984/225000 (58%)] Loss: 19831.650391\n",
      "Train Epoch: 102 [132480/225000 (59%)] Loss: 19940.650391\n",
      "Train Epoch: 102 [134976/225000 (60%)] Loss: 19411.679688\n",
      "Train Epoch: 102 [137472/225000 (61%)] Loss: 19246.132812\n",
      "Train Epoch: 102 [139968/225000 (62%)] Loss: 19188.410156\n",
      "Train Epoch: 102 [142464/225000 (63%)] Loss: 19959.078125\n",
      "Train Epoch: 102 [144960/225000 (64%)] Loss: 19136.753906\n",
      "Train Epoch: 102 [147456/225000 (66%)] Loss: 19295.750000\n",
      "Train Epoch: 102 [149952/225000 (67%)] Loss: 19541.982422\n",
      "Train Epoch: 102 [152448/225000 (68%)] Loss: 19302.992188\n",
      "Train Epoch: 102 [154944/225000 (69%)] Loss: 19587.720703\n",
      "Train Epoch: 102 [157440/225000 (70%)] Loss: 19767.566406\n",
      "Train Epoch: 102 [159936/225000 (71%)] Loss: 19528.171875\n",
      "Train Epoch: 102 [162432/225000 (72%)] Loss: 19416.417969\n",
      "Train Epoch: 102 [164928/225000 (73%)] Loss: 19531.710938\n",
      "Train Epoch: 102 [167424/225000 (74%)] Loss: 19081.757812\n",
      "Train Epoch: 102 [169920/225000 (76%)] Loss: 19701.757812\n",
      "Train Epoch: 102 [172416/225000 (77%)] Loss: 19011.378906\n",
      "Train Epoch: 102 [174912/225000 (78%)] Loss: 19412.777344\n",
      "Train Epoch: 102 [177408/225000 (79%)] Loss: 19716.640625\n",
      "Train Epoch: 102 [179904/225000 (80%)] Loss: 19664.667969\n",
      "Train Epoch: 102 [182400/225000 (81%)] Loss: 19200.925781\n",
      "Train Epoch: 102 [184896/225000 (82%)] Loss: 19567.667969\n",
      "Train Epoch: 102 [187392/225000 (83%)] Loss: 19157.890625\n",
      "Train Epoch: 102 [189888/225000 (84%)] Loss: 19850.541016\n",
      "Train Epoch: 102 [192384/225000 (86%)] Loss: 19206.435547\n",
      "Train Epoch: 102 [194880/225000 (87%)] Loss: 19853.875000\n",
      "Train Epoch: 102 [197376/225000 (88%)] Loss: 19309.054688\n",
      "Train Epoch: 102 [199872/225000 (89%)] Loss: 19470.453125\n",
      "Train Epoch: 102 [202368/225000 (90%)] Loss: 19559.824219\n",
      "Train Epoch: 102 [204864/225000 (91%)] Loss: 20037.650391\n",
      "Train Epoch: 102 [207360/225000 (92%)] Loss: 19802.087891\n",
      "Train Epoch: 102 [209856/225000 (93%)] Loss: 19411.054688\n",
      "Train Epoch: 102 [212352/225000 (94%)] Loss: 19109.982422\n",
      "Train Epoch: 102 [214848/225000 (95%)] Loss: 19168.640625\n",
      "Train Epoch: 102 [217344/225000 (97%)] Loss: 19644.285156\n",
      "Train Epoch: 102 [219840/225000 (98%)] Loss: 19551.072266\n",
      "Train Epoch: 102 [222336/225000 (99%)] Loss: 19664.902344\n",
      "Train Epoch: 102 [224832/225000 (100%)] Loss: 18972.132812\n",
      "    epoch          : 102\n",
      "    loss           : 19480.145916102283\n",
      "    val_loss       : 19391.595206858547\n",
      "Train Epoch: 103 [192/225000 (0%)] Loss: 19241.388672\n",
      "Train Epoch: 103 [2688/225000 (1%)] Loss: 19412.261719\n",
      "Train Epoch: 103 [5184/225000 (2%)] Loss: 19493.027344\n",
      "Train Epoch: 103 [7680/225000 (3%)] Loss: 19254.394531\n",
      "Train Epoch: 103 [10176/225000 (5%)] Loss: 19111.394531\n",
      "Train Epoch: 103 [12672/225000 (6%)] Loss: 18995.531250\n",
      "Train Epoch: 103 [15168/225000 (7%)] Loss: 19370.703125\n",
      "Train Epoch: 103 [17664/225000 (8%)] Loss: 19627.808594\n",
      "Train Epoch: 103 [20160/225000 (9%)] Loss: 19345.425781\n",
      "Train Epoch: 103 [22656/225000 (10%)] Loss: 19541.589844\n",
      "Train Epoch: 103 [25152/225000 (11%)] Loss: 19233.777344\n",
      "Train Epoch: 103 [27648/225000 (12%)] Loss: 19584.269531\n",
      "Train Epoch: 103 [30144/225000 (13%)] Loss: 19536.972656\n",
      "Train Epoch: 103 [32640/225000 (15%)] Loss: 19585.041016\n",
      "Train Epoch: 103 [35136/225000 (16%)] Loss: 19304.246094\n",
      "Train Epoch: 103 [37632/225000 (17%)] Loss: 19163.654297\n",
      "Train Epoch: 103 [40128/225000 (18%)] Loss: 19155.613281\n",
      "Train Epoch: 103 [42624/225000 (19%)] Loss: 19890.583984\n",
      "Train Epoch: 103 [45120/225000 (20%)] Loss: 19699.285156\n",
      "Train Epoch: 103 [47616/225000 (21%)] Loss: 19439.341797\n",
      "Train Epoch: 103 [50112/225000 (22%)] Loss: 19364.330078\n",
      "Train Epoch: 103 [52608/225000 (23%)] Loss: 19711.279297\n",
      "Train Epoch: 103 [55104/225000 (24%)] Loss: 19458.199219\n",
      "Train Epoch: 103 [57600/225000 (26%)] Loss: 19460.023438\n",
      "Train Epoch: 103 [60096/225000 (27%)] Loss: 19639.291016\n",
      "Train Epoch: 103 [62592/225000 (28%)] Loss: 19707.421875\n",
      "Train Epoch: 103 [65088/225000 (29%)] Loss: 19309.591797\n",
      "Train Epoch: 103 [67584/225000 (30%)] Loss: 19390.523438\n",
      "Train Epoch: 103 [70080/225000 (31%)] Loss: 19937.005859\n",
      "Train Epoch: 103 [72576/225000 (32%)] Loss: 19363.574219\n",
      "Train Epoch: 103 [75072/225000 (33%)] Loss: 19689.421875\n",
      "Train Epoch: 103 [77568/225000 (34%)] Loss: 19978.833984\n",
      "Train Epoch: 103 [80064/225000 (36%)] Loss: 19722.191406\n",
      "Train Epoch: 103 [82560/225000 (37%)] Loss: 20030.171875\n",
      "Train Epoch: 103 [85056/225000 (38%)] Loss: 19509.140625\n",
      "Train Epoch: 103 [87552/225000 (39%)] Loss: 19839.644531\n",
      "Train Epoch: 103 [90048/225000 (40%)] Loss: 19858.332031\n",
      "Train Epoch: 103 [92544/225000 (41%)] Loss: 19067.757812\n",
      "Train Epoch: 103 [95040/225000 (42%)] Loss: 19351.367188\n",
      "Train Epoch: 103 [97536/225000 (43%)] Loss: 19766.929688\n",
      "Train Epoch: 103 [100032/225000 (44%)] Loss: 19705.068359\n",
      "Train Epoch: 103 [102528/225000 (46%)] Loss: 19100.722656\n",
      "Train Epoch: 103 [105024/225000 (47%)] Loss: 19328.570312\n",
      "Train Epoch: 103 [107520/225000 (48%)] Loss: 19401.701172\n",
      "Train Epoch: 103 [110016/225000 (49%)] Loss: 19338.427734\n",
      "Train Epoch: 103 [112512/225000 (50%)] Loss: 19099.062500\n",
      "Train Epoch: 103 [115008/225000 (51%)] Loss: 19418.664062\n",
      "Train Epoch: 103 [117504/225000 (52%)] Loss: 19353.605469\n",
      "Train Epoch: 103 [120000/225000 (53%)] Loss: 19386.582031\n",
      "Train Epoch: 103 [122496/225000 (54%)] Loss: 19577.751953\n",
      "Train Epoch: 103 [124992/225000 (56%)] Loss: 19271.134766\n",
      "Train Epoch: 103 [127488/225000 (57%)] Loss: 19589.667969\n",
      "Train Epoch: 103 [129984/225000 (58%)] Loss: 19434.251953\n",
      "Train Epoch: 103 [132480/225000 (59%)] Loss: 19122.480469\n",
      "Train Epoch: 103 [134976/225000 (60%)] Loss: 19570.349609\n",
      "Train Epoch: 103 [137472/225000 (61%)] Loss: 19311.900391\n",
      "Train Epoch: 103 [139968/225000 (62%)] Loss: 19457.480469\n",
      "Train Epoch: 103 [142464/225000 (63%)] Loss: 19651.419922\n",
      "Train Epoch: 103 [144960/225000 (64%)] Loss: 19148.951172\n",
      "Train Epoch: 103 [147456/225000 (66%)] Loss: 19496.039062\n",
      "Train Epoch: 103 [149952/225000 (67%)] Loss: 18894.082031\n",
      "Train Epoch: 103 [152448/225000 (68%)] Loss: 19185.884766\n",
      "Train Epoch: 103 [154944/225000 (69%)] Loss: 19920.695312\n",
      "Train Epoch: 103 [157440/225000 (70%)] Loss: 19377.173828\n",
      "Train Epoch: 103 [159936/225000 (71%)] Loss: 19710.082031\n",
      "Train Epoch: 103 [162432/225000 (72%)] Loss: 19246.105469\n",
      "Train Epoch: 103 [164928/225000 (73%)] Loss: 19303.287109\n",
      "Train Epoch: 103 [167424/225000 (74%)] Loss: 19262.656250\n",
      "Train Epoch: 103 [169920/225000 (76%)] Loss: 18852.425781\n",
      "Train Epoch: 103 [172416/225000 (77%)] Loss: 19576.597656\n",
      "Train Epoch: 103 [174912/225000 (78%)] Loss: 19308.335938\n",
      "Train Epoch: 103 [177408/225000 (79%)] Loss: 19609.931641\n",
      "Train Epoch: 103 [179904/225000 (80%)] Loss: 19260.710938\n",
      "Train Epoch: 103 [182400/225000 (81%)] Loss: 19521.027344\n",
      "Train Epoch: 103 [184896/225000 (82%)] Loss: 19183.873047\n",
      "Train Epoch: 103 [187392/225000 (83%)] Loss: 19350.523438\n",
      "Train Epoch: 103 [189888/225000 (84%)] Loss: 19683.417969\n",
      "Train Epoch: 103 [192384/225000 (86%)] Loss: 19500.550781\n",
      "Train Epoch: 103 [194880/225000 (87%)] Loss: 19193.644531\n",
      "Train Epoch: 103 [197376/225000 (88%)] Loss: 19670.894531\n",
      "Train Epoch: 103 [199872/225000 (89%)] Loss: 19559.853516\n",
      "Train Epoch: 103 [202368/225000 (90%)] Loss: 19725.750000\n",
      "Train Epoch: 103 [204864/225000 (91%)] Loss: 19585.960938\n",
      "Train Epoch: 103 [207360/225000 (92%)] Loss: 19404.121094\n",
      "Train Epoch: 103 [209856/225000 (93%)] Loss: 19432.437500\n",
      "Train Epoch: 103 [212352/225000 (94%)] Loss: 19330.132812\n",
      "Train Epoch: 103 [214848/225000 (95%)] Loss: 19979.214844\n",
      "Train Epoch: 103 [217344/225000 (97%)] Loss: 19519.130859\n",
      "Train Epoch: 103 [219840/225000 (98%)] Loss: 19642.464844\n",
      "Train Epoch: 103 [222336/225000 (99%)] Loss: 19557.035156\n",
      "Train Epoch: 103 [224832/225000 (100%)] Loss: 19855.015625\n",
      "    epoch          : 103\n",
      "    loss           : 19479.040672328287\n",
      "    val_loss       : 19408.32003183037\n",
      "Train Epoch: 104 [192/225000 (0%)] Loss: 19408.664062\n",
      "Train Epoch: 104 [2688/225000 (1%)] Loss: 18511.605469\n",
      "Train Epoch: 104 [5184/225000 (2%)] Loss: 19252.554688\n",
      "Train Epoch: 104 [7680/225000 (3%)] Loss: 19437.269531\n",
      "Train Epoch: 104 [10176/225000 (5%)] Loss: 19497.126953\n",
      "Train Epoch: 104 [12672/225000 (6%)] Loss: 19383.851562\n",
      "Train Epoch: 104 [15168/225000 (7%)] Loss: 19401.998047\n",
      "Train Epoch: 104 [17664/225000 (8%)] Loss: 19520.644531\n",
      "Train Epoch: 104 [20160/225000 (9%)] Loss: 19512.031250\n",
      "Train Epoch: 104 [22656/225000 (10%)] Loss: 19559.875000\n",
      "Train Epoch: 104 [25152/225000 (11%)] Loss: 20020.238281\n",
      "Train Epoch: 104 [27648/225000 (12%)] Loss: 19801.083984\n",
      "Train Epoch: 104 [30144/225000 (13%)] Loss: 19204.669922\n",
      "Train Epoch: 104 [32640/225000 (15%)] Loss: 19791.281250\n",
      "Train Epoch: 104 [35136/225000 (16%)] Loss: 20003.621094\n",
      "Train Epoch: 104 [37632/225000 (17%)] Loss: 19051.044922\n",
      "Train Epoch: 104 [40128/225000 (18%)] Loss: 19931.457031\n",
      "Train Epoch: 104 [42624/225000 (19%)] Loss: 19558.984375\n",
      "Train Epoch: 104 [45120/225000 (20%)] Loss: 19296.847656\n",
      "Train Epoch: 104 [47616/225000 (21%)] Loss: 19285.746094\n",
      "Train Epoch: 104 [50112/225000 (22%)] Loss: 19544.824219\n",
      "Train Epoch: 104 [52608/225000 (23%)] Loss: 19431.734375\n",
      "Train Epoch: 104 [55104/225000 (24%)] Loss: 19787.408203\n",
      "Train Epoch: 104 [57600/225000 (26%)] Loss: 19792.986328\n",
      "Train Epoch: 104 [60096/225000 (27%)] Loss: 19549.984375\n",
      "Train Epoch: 104 [62592/225000 (28%)] Loss: 19703.292969\n",
      "Train Epoch: 104 [65088/225000 (29%)] Loss: 19954.373047\n",
      "Train Epoch: 104 [67584/225000 (30%)] Loss: 19519.746094\n",
      "Train Epoch: 104 [70080/225000 (31%)] Loss: 19006.589844\n",
      "Train Epoch: 104 [72576/225000 (32%)] Loss: 19894.335938\n",
      "Train Epoch: 104 [75072/225000 (33%)] Loss: 19596.675781\n",
      "Train Epoch: 104 [77568/225000 (34%)] Loss: 18919.625000\n",
      "Train Epoch: 104 [80064/225000 (36%)] Loss: 18976.015625\n",
      "Train Epoch: 104 [82560/225000 (37%)] Loss: 19787.023438\n",
      "Train Epoch: 104 [85056/225000 (38%)] Loss: 19315.695312\n",
      "Train Epoch: 104 [87552/225000 (39%)] Loss: 19505.492188\n",
      "Train Epoch: 104 [90048/225000 (40%)] Loss: 19621.691406\n",
      "Train Epoch: 104 [92544/225000 (41%)] Loss: 19151.941406\n",
      "Train Epoch: 104 [95040/225000 (42%)] Loss: 19656.914062\n",
      "Train Epoch: 104 [97536/225000 (43%)] Loss: 18951.726562\n",
      "Train Epoch: 104 [100032/225000 (44%)] Loss: 19144.941406\n",
      "Train Epoch: 104 [102528/225000 (46%)] Loss: 19700.314453\n",
      "Train Epoch: 104 [105024/225000 (47%)] Loss: 19038.335938\n",
      "Train Epoch: 104 [107520/225000 (48%)] Loss: 19267.078125\n",
      "Train Epoch: 104 [110016/225000 (49%)] Loss: 19654.722656\n",
      "Train Epoch: 104 [112512/225000 (50%)] Loss: 19080.617188\n",
      "Train Epoch: 104 [115008/225000 (51%)] Loss: 19518.914062\n",
      "Train Epoch: 104 [117504/225000 (52%)] Loss: 19442.257812\n",
      "Train Epoch: 104 [120000/225000 (53%)] Loss: 19662.882812\n",
      "Train Epoch: 104 [122496/225000 (54%)] Loss: 19367.531250\n",
      "Train Epoch: 104 [124992/225000 (56%)] Loss: 19866.824219\n",
      "Train Epoch: 104 [127488/225000 (57%)] Loss: 19143.132812\n",
      "Train Epoch: 104 [129984/225000 (58%)] Loss: 19884.699219\n",
      "Train Epoch: 104 [132480/225000 (59%)] Loss: 19164.128906\n",
      "Train Epoch: 104 [134976/225000 (60%)] Loss: 19241.400391\n",
      "Train Epoch: 104 [137472/225000 (61%)] Loss: 19430.003906\n",
      "Train Epoch: 104 [139968/225000 (62%)] Loss: 19327.580078\n",
      "Train Epoch: 104 [142464/225000 (63%)] Loss: 19431.982422\n",
      "Train Epoch: 104 [144960/225000 (64%)] Loss: 19184.503906\n",
      "Train Epoch: 104 [147456/225000 (66%)] Loss: 19779.421875\n",
      "Train Epoch: 104 [149952/225000 (67%)] Loss: 19187.406250\n",
      "Train Epoch: 104 [152448/225000 (68%)] Loss: 19600.832031\n",
      "Train Epoch: 104 [154944/225000 (69%)] Loss: 19489.789062\n",
      "Train Epoch: 104 [157440/225000 (70%)] Loss: 19745.634766\n",
      "Train Epoch: 104 [159936/225000 (71%)] Loss: 19490.609375\n",
      "Train Epoch: 104 [162432/225000 (72%)] Loss: 19133.490234\n",
      "Train Epoch: 104 [164928/225000 (73%)] Loss: 19202.972656\n",
      "Train Epoch: 104 [167424/225000 (74%)] Loss: 19335.378906\n",
      "Train Epoch: 104 [169920/225000 (76%)] Loss: 19803.455078\n",
      "Train Epoch: 104 [172416/225000 (77%)] Loss: 19905.683594\n",
      "Train Epoch: 104 [174912/225000 (78%)] Loss: 19136.539062\n",
      "Train Epoch: 104 [177408/225000 (79%)] Loss: 19099.210938\n",
      "Train Epoch: 104 [179904/225000 (80%)] Loss: 19456.212891\n",
      "Train Epoch: 104 [182400/225000 (81%)] Loss: 19438.406250\n",
      "Train Epoch: 104 [184896/225000 (82%)] Loss: 19237.783203\n",
      "Train Epoch: 104 [187392/225000 (83%)] Loss: 19176.066406\n",
      "Train Epoch: 104 [189888/225000 (84%)] Loss: 19262.464844\n",
      "Train Epoch: 104 [192384/225000 (86%)] Loss: 18862.166016\n",
      "Train Epoch: 104 [194880/225000 (87%)] Loss: 19610.457031\n",
      "Train Epoch: 104 [197376/225000 (88%)] Loss: 19144.576172\n",
      "Train Epoch: 104 [199872/225000 (89%)] Loss: 19693.878906\n",
      "Train Epoch: 104 [202368/225000 (90%)] Loss: 19862.646484\n",
      "Train Epoch: 104 [204864/225000 (91%)] Loss: 19416.425781\n",
      "Train Epoch: 104 [207360/225000 (92%)] Loss: 20141.785156\n",
      "Train Epoch: 104 [209856/225000 (93%)] Loss: 19149.746094\n",
      "Train Epoch: 104 [212352/225000 (94%)] Loss: 19118.175781\n",
      "Train Epoch: 104 [214848/225000 (95%)] Loss: 19306.726562\n",
      "Train Epoch: 104 [217344/225000 (97%)] Loss: 19134.230469\n",
      "Train Epoch: 104 [219840/225000 (98%)] Loss: 19542.402344\n",
      "Train Epoch: 104 [222336/225000 (99%)] Loss: 19881.900391\n",
      "Train Epoch: 104 [224832/225000 (100%)] Loss: 19663.216797\n",
      "    epoch          : 104\n",
      "    loss           : 19474.547523264184\n",
      "    val_loss       : 19366.427338034144\n",
      "Train Epoch: 105 [192/225000 (0%)] Loss: 19618.253906\n",
      "Train Epoch: 105 [2688/225000 (1%)] Loss: 19671.806641\n",
      "Train Epoch: 105 [5184/225000 (2%)] Loss: 19767.664062\n",
      "Train Epoch: 105 [7680/225000 (3%)] Loss: 19109.644531\n",
      "Train Epoch: 105 [10176/225000 (5%)] Loss: 19374.984375\n",
      "Train Epoch: 105 [12672/225000 (6%)] Loss: 19019.425781\n",
      "Train Epoch: 105 [15168/225000 (7%)] Loss: 19528.273438\n",
      "Train Epoch: 105 [17664/225000 (8%)] Loss: 19058.550781\n",
      "Train Epoch: 105 [20160/225000 (9%)] Loss: 19867.367188\n",
      "Train Epoch: 105 [22656/225000 (10%)] Loss: 19982.351562\n",
      "Train Epoch: 105 [25152/225000 (11%)] Loss: 19548.085938\n",
      "Train Epoch: 105 [27648/225000 (12%)] Loss: 19452.203125\n",
      "Train Epoch: 105 [30144/225000 (13%)] Loss: 19613.171875\n",
      "Train Epoch: 105 [32640/225000 (15%)] Loss: 19675.613281\n",
      "Train Epoch: 105 [35136/225000 (16%)] Loss: 19357.898438\n",
      "Train Epoch: 105 [37632/225000 (17%)] Loss: 19253.425781\n",
      "Train Epoch: 105 [40128/225000 (18%)] Loss: 19515.593750\n",
      "Train Epoch: 105 [42624/225000 (19%)] Loss: 19539.902344\n",
      "Train Epoch: 105 [45120/225000 (20%)] Loss: 19739.726562\n",
      "Train Epoch: 105 [47616/225000 (21%)] Loss: 19604.707031\n",
      "Train Epoch: 105 [50112/225000 (22%)] Loss: 19463.917969\n",
      "Train Epoch: 105 [52608/225000 (23%)] Loss: 19350.857422\n",
      "Train Epoch: 105 [55104/225000 (24%)] Loss: 19365.248047\n",
      "Train Epoch: 105 [57600/225000 (26%)] Loss: 19021.648438\n",
      "Train Epoch: 105 [60096/225000 (27%)] Loss: 19680.687500\n",
      "Train Epoch: 105 [62592/225000 (28%)] Loss: 19584.906250\n",
      "Train Epoch: 105 [65088/225000 (29%)] Loss: 19446.953125\n",
      "Train Epoch: 105 [67584/225000 (30%)] Loss: 18948.054688\n",
      "Train Epoch: 105 [70080/225000 (31%)] Loss: 19563.277344\n",
      "Train Epoch: 105 [72576/225000 (32%)] Loss: 19672.816406\n",
      "Train Epoch: 105 [75072/225000 (33%)] Loss: 19543.277344\n",
      "Train Epoch: 105 [77568/225000 (34%)] Loss: 19595.033203\n",
      "Train Epoch: 105 [80064/225000 (36%)] Loss: 19804.667969\n",
      "Train Epoch: 105 [82560/225000 (37%)] Loss: 19842.123047\n",
      "Train Epoch: 105 [85056/225000 (38%)] Loss: 19394.066406\n",
      "Train Epoch: 105 [87552/225000 (39%)] Loss: 19570.734375\n",
      "Train Epoch: 105 [90048/225000 (40%)] Loss: 19914.308594\n",
      "Train Epoch: 105 [92544/225000 (41%)] Loss: 19106.775391\n",
      "Train Epoch: 105 [95040/225000 (42%)] Loss: 19120.109375\n",
      "Train Epoch: 105 [97536/225000 (43%)] Loss: 19153.277344\n",
      "Train Epoch: 105 [100032/225000 (44%)] Loss: 19359.927734\n",
      "Train Epoch: 105 [102528/225000 (46%)] Loss: 19565.248047\n",
      "Train Epoch: 105 [105024/225000 (47%)] Loss: 19449.404297\n",
      "Train Epoch: 105 [107520/225000 (48%)] Loss: 19685.718750\n",
      "Train Epoch: 105 [110016/225000 (49%)] Loss: 19413.125000\n",
      "Train Epoch: 105 [112512/225000 (50%)] Loss: 19623.710938\n",
      "Train Epoch: 105 [115008/225000 (51%)] Loss: 20007.107422\n",
      "Train Epoch: 105 [117504/225000 (52%)] Loss: 19301.429688\n",
      "Train Epoch: 105 [120000/225000 (53%)] Loss: 18658.089844\n",
      "Train Epoch: 105 [122496/225000 (54%)] Loss: 19495.179688\n",
      "Train Epoch: 105 [124992/225000 (56%)] Loss: 19240.742188\n",
      "Train Epoch: 105 [127488/225000 (57%)] Loss: 19972.191406\n",
      "Train Epoch: 105 [129984/225000 (58%)] Loss: 19384.703125\n",
      "Train Epoch: 105 [132480/225000 (59%)] Loss: 19363.699219\n",
      "Train Epoch: 105 [134976/225000 (60%)] Loss: 19238.285156\n",
      "Train Epoch: 105 [137472/225000 (61%)] Loss: 19851.568359\n",
      "Train Epoch: 105 [139968/225000 (62%)] Loss: 19475.925781\n",
      "Train Epoch: 105 [142464/225000 (63%)] Loss: 19097.611328\n",
      "Train Epoch: 105 [144960/225000 (64%)] Loss: 19084.195312\n",
      "Train Epoch: 105 [147456/225000 (66%)] Loss: 18841.964844\n",
      "Train Epoch: 105 [149952/225000 (67%)] Loss: 19343.140625\n",
      "Train Epoch: 105 [152448/225000 (68%)] Loss: 19986.517578\n",
      "Train Epoch: 105 [154944/225000 (69%)] Loss: 19145.003906\n",
      "Train Epoch: 105 [157440/225000 (70%)] Loss: 19776.601562\n",
      "Train Epoch: 105 [159936/225000 (71%)] Loss: 19956.640625\n",
      "Train Epoch: 105 [162432/225000 (72%)] Loss: 19308.250000\n",
      "Train Epoch: 105 [164928/225000 (73%)] Loss: 19328.187500\n",
      "Train Epoch: 105 [167424/225000 (74%)] Loss: 19928.765625\n",
      "Train Epoch: 105 [169920/225000 (76%)] Loss: 19389.031250\n",
      "Train Epoch: 105 [172416/225000 (77%)] Loss: 19614.675781\n",
      "Train Epoch: 105 [174912/225000 (78%)] Loss: 19715.085938\n",
      "Train Epoch: 105 [177408/225000 (79%)] Loss: 19154.382812\n",
      "Train Epoch: 105 [179904/225000 (80%)] Loss: 19814.042969\n",
      "Train Epoch: 105 [182400/225000 (81%)] Loss: 19685.564453\n",
      "Train Epoch: 105 [184896/225000 (82%)] Loss: 19313.429688\n",
      "Train Epoch: 105 [187392/225000 (83%)] Loss: 19207.097656\n",
      "Train Epoch: 105 [189888/225000 (84%)] Loss: 19876.195312\n",
      "Train Epoch: 105 [192384/225000 (86%)] Loss: 19527.308594\n",
      "Train Epoch: 105 [194880/225000 (87%)] Loss: 19084.056641\n",
      "Train Epoch: 105 [197376/225000 (88%)] Loss: 18965.335938\n",
      "Train Epoch: 105 [199872/225000 (89%)] Loss: 19077.695312\n",
      "Train Epoch: 105 [202368/225000 (90%)] Loss: 19524.628906\n",
      "Train Epoch: 105 [204864/225000 (91%)] Loss: 19981.439453\n",
      "Train Epoch: 105 [207360/225000 (92%)] Loss: 19346.123047\n",
      "Train Epoch: 105 [209856/225000 (93%)] Loss: 18963.113281\n",
      "Train Epoch: 105 [212352/225000 (94%)] Loss: 19554.544922\n",
      "Train Epoch: 105 [214848/225000 (95%)] Loss: 19168.781250\n",
      "Train Epoch: 105 [217344/225000 (97%)] Loss: 19541.298828\n",
      "Train Epoch: 105 [219840/225000 (98%)] Loss: 19699.007812\n",
      "Train Epoch: 105 [222336/225000 (99%)] Loss: 19120.261719\n",
      "Train Epoch: 105 [224832/225000 (100%)] Loss: 18961.972656\n",
      "    epoch          : 105\n",
      "    loss           : 19461.356711950724\n",
      "    val_loss       : 19366.807368680722\n",
      "Train Epoch: 106 [192/225000 (0%)] Loss: 19650.246094\n",
      "Train Epoch: 106 [2688/225000 (1%)] Loss: 19201.367188\n",
      "Train Epoch: 106 [5184/225000 (2%)] Loss: 19632.753906\n",
      "Train Epoch: 106 [7680/225000 (3%)] Loss: 19629.953125\n",
      "Train Epoch: 106 [10176/225000 (5%)] Loss: 19136.550781\n",
      "Train Epoch: 106 [12672/225000 (6%)] Loss: 19615.615234\n",
      "Train Epoch: 106 [15168/225000 (7%)] Loss: 19446.785156\n",
      "Train Epoch: 106 [17664/225000 (8%)] Loss: 19073.730469\n",
      "Train Epoch: 106 [20160/225000 (9%)] Loss: 19712.419922\n",
      "Train Epoch: 106 [22656/225000 (10%)] Loss: 19014.558594\n",
      "Train Epoch: 106 [25152/225000 (11%)] Loss: 20018.650391\n",
      "Train Epoch: 106 [27648/225000 (12%)] Loss: 19057.015625\n",
      "Train Epoch: 106 [30144/225000 (13%)] Loss: 19717.171875\n",
      "Train Epoch: 106 [32640/225000 (15%)] Loss: 19890.697266\n",
      "Train Epoch: 106 [35136/225000 (16%)] Loss: 19178.208984\n",
      "Train Epoch: 106 [37632/225000 (17%)] Loss: 19781.046875\n",
      "Train Epoch: 106 [40128/225000 (18%)] Loss: 19484.640625\n",
      "Train Epoch: 106 [42624/225000 (19%)] Loss: 19587.988281\n",
      "Train Epoch: 106 [45120/225000 (20%)] Loss: 19097.824219\n",
      "Train Epoch: 106 [47616/225000 (21%)] Loss: 19235.886719\n",
      "Train Epoch: 106 [50112/225000 (22%)] Loss: 19713.757812\n",
      "Train Epoch: 106 [52608/225000 (23%)] Loss: 19408.353516\n",
      "Train Epoch: 106 [55104/225000 (24%)] Loss: 19323.753906\n",
      "Train Epoch: 106 [57600/225000 (26%)] Loss: 19609.462891\n",
      "Train Epoch: 106 [60096/225000 (27%)] Loss: 19305.484375\n",
      "Train Epoch: 106 [62592/225000 (28%)] Loss: 19769.406250\n",
      "Train Epoch: 106 [65088/225000 (29%)] Loss: 19907.759766\n",
      "Train Epoch: 106 [67584/225000 (30%)] Loss: 19338.439453\n",
      "Train Epoch: 106 [70080/225000 (31%)] Loss: 19458.138672\n",
      "Train Epoch: 106 [72576/225000 (32%)] Loss: 19508.480469\n",
      "Train Epoch: 106 [75072/225000 (33%)] Loss: 19975.609375\n",
      "Train Epoch: 106 [77568/225000 (34%)] Loss: 19624.632812\n",
      "Train Epoch: 106 [80064/225000 (36%)] Loss: 19244.093750\n",
      "Train Epoch: 106 [82560/225000 (37%)] Loss: 19825.638672\n",
      "Train Epoch: 106 [85056/225000 (38%)] Loss: 19411.521484\n",
      "Train Epoch: 106 [87552/225000 (39%)] Loss: 19470.261719\n",
      "Train Epoch: 106 [90048/225000 (40%)] Loss: 19432.910156\n",
      "Train Epoch: 106 [92544/225000 (41%)] Loss: 19762.289062\n",
      "Train Epoch: 106 [95040/225000 (42%)] Loss: 19782.414062\n",
      "Train Epoch: 106 [97536/225000 (43%)] Loss: 19060.498047\n",
      "Train Epoch: 106 [100032/225000 (44%)] Loss: 19654.187500\n",
      "Train Epoch: 106 [102528/225000 (46%)] Loss: 19440.933594\n",
      "Train Epoch: 106 [105024/225000 (47%)] Loss: 19530.777344\n",
      "Train Epoch: 106 [107520/225000 (48%)] Loss: 19466.863281\n",
      "Train Epoch: 106 [110016/225000 (49%)] Loss: 19520.664062\n",
      "Train Epoch: 106 [112512/225000 (50%)] Loss: 19493.673828\n",
      "Train Epoch: 106 [115008/225000 (51%)] Loss: 19704.714844\n",
      "Train Epoch: 106 [117504/225000 (52%)] Loss: 19458.201172\n",
      "Train Epoch: 106 [120000/225000 (53%)] Loss: 19280.382812\n",
      "Train Epoch: 106 [122496/225000 (54%)] Loss: 19929.085938\n",
      "Train Epoch: 106 [124992/225000 (56%)] Loss: 19964.796875\n",
      "Train Epoch: 106 [127488/225000 (57%)] Loss: 19203.933594\n",
      "Train Epoch: 106 [129984/225000 (58%)] Loss: 19661.074219\n",
      "Train Epoch: 106 [132480/225000 (59%)] Loss: 19479.804688\n",
      "Train Epoch: 106 [134976/225000 (60%)] Loss: 19604.062500\n",
      "Train Epoch: 106 [137472/225000 (61%)] Loss: 19036.560547\n",
      "Train Epoch: 106 [139968/225000 (62%)] Loss: 19604.068359\n",
      "Train Epoch: 106 [142464/225000 (63%)] Loss: 19253.054688\n",
      "Train Epoch: 106 [144960/225000 (64%)] Loss: 19385.013672\n",
      "Train Epoch: 106 [147456/225000 (66%)] Loss: 19071.472656\n",
      "Train Epoch: 106 [149952/225000 (67%)] Loss: 19763.953125\n",
      "Train Epoch: 106 [152448/225000 (68%)] Loss: 19323.445312\n",
      "Train Epoch: 106 [154944/225000 (69%)] Loss: 19503.095703\n",
      "Train Epoch: 106 [157440/225000 (70%)] Loss: 19225.876953\n",
      "Train Epoch: 106 [159936/225000 (71%)] Loss: 19992.197266\n",
      "Train Epoch: 106 [162432/225000 (72%)] Loss: 19469.986328\n",
      "Train Epoch: 106 [164928/225000 (73%)] Loss: 19465.085938\n",
      "Train Epoch: 106 [167424/225000 (74%)] Loss: 19438.183594\n",
      "Train Epoch: 106 [169920/225000 (76%)] Loss: 19382.324219\n",
      "Train Epoch: 106 [172416/225000 (77%)] Loss: 19485.626953\n",
      "Train Epoch: 106 [174912/225000 (78%)] Loss: 19235.363281\n",
      "Train Epoch: 106 [177408/225000 (79%)] Loss: 19946.027344\n",
      "Train Epoch: 106 [179904/225000 (80%)] Loss: 19761.039062\n",
      "Train Epoch: 106 [182400/225000 (81%)] Loss: 18899.738281\n",
      "Train Epoch: 106 [184896/225000 (82%)] Loss: 19776.349609\n",
      "Train Epoch: 106 [187392/225000 (83%)] Loss: 20029.875000\n",
      "Train Epoch: 106 [189888/225000 (84%)] Loss: 19782.712891\n",
      "Train Epoch: 106 [192384/225000 (86%)] Loss: 19704.144531\n",
      "Train Epoch: 106 [194880/225000 (87%)] Loss: 19159.593750\n",
      "Train Epoch: 106 [197376/225000 (88%)] Loss: 19626.955078\n",
      "Train Epoch: 106 [199872/225000 (89%)] Loss: 19500.394531\n",
      "Train Epoch: 106 [202368/225000 (90%)] Loss: 18715.136719\n",
      "Train Epoch: 106 [204864/225000 (91%)] Loss: 18774.085938\n",
      "Train Epoch: 106 [207360/225000 (92%)] Loss: 19570.199219\n",
      "Train Epoch: 106 [209856/225000 (93%)] Loss: 19446.330078\n",
      "Train Epoch: 106 [212352/225000 (94%)] Loss: 19476.949219\n",
      "Train Epoch: 106 [214848/225000 (95%)] Loss: 19842.167969\n",
      "Train Epoch: 106 [217344/225000 (97%)] Loss: 19304.433594\n",
      "Train Epoch: 106 [219840/225000 (98%)] Loss: 19334.574219\n",
      "Train Epoch: 106 [222336/225000 (99%)] Loss: 19436.222656\n",
      "Train Epoch: 106 [224832/225000 (100%)] Loss: 19404.537109\n",
      "    epoch          : 106\n",
      "    loss           : 19455.143772997548\n",
      "    val_loss       : 19361.504189918058\n",
      "Train Epoch: 107 [192/225000 (0%)] Loss: 19395.238281\n",
      "Train Epoch: 107 [2688/225000 (1%)] Loss: 19191.761719\n",
      "Train Epoch: 107 [5184/225000 (2%)] Loss: 19528.503906\n",
      "Train Epoch: 107 [7680/225000 (3%)] Loss: 19687.746094\n",
      "Train Epoch: 107 [10176/225000 (5%)] Loss: 19172.863281\n",
      "Train Epoch: 107 [12672/225000 (6%)] Loss: 19639.828125\n",
      "Train Epoch: 107 [15168/225000 (7%)] Loss: 19386.070312\n",
      "Train Epoch: 107 [17664/225000 (8%)] Loss: 19230.332031\n",
      "Train Epoch: 107 [20160/225000 (9%)] Loss: 19336.253906\n",
      "Train Epoch: 107 [22656/225000 (10%)] Loss: 19151.457031\n",
      "Train Epoch: 107 [25152/225000 (11%)] Loss: 19374.843750\n",
      "Train Epoch: 107 [27648/225000 (12%)] Loss: 19037.628906\n",
      "Train Epoch: 107 [30144/225000 (13%)] Loss: 19551.070312\n",
      "Train Epoch: 107 [32640/225000 (15%)] Loss: 19390.617188\n",
      "Train Epoch: 107 [35136/225000 (16%)] Loss: 19480.289062\n",
      "Train Epoch: 107 [37632/225000 (17%)] Loss: 19665.945312\n",
      "Train Epoch: 107 [40128/225000 (18%)] Loss: 19403.679688\n",
      "Train Epoch: 107 [42624/225000 (19%)] Loss: 19229.925781\n",
      "Train Epoch: 107 [45120/225000 (20%)] Loss: 19271.089844\n",
      "Train Epoch: 107 [47616/225000 (21%)] Loss: 19150.281250\n",
      "Train Epoch: 107 [50112/225000 (22%)] Loss: 19261.062500\n",
      "Train Epoch: 107 [52608/225000 (23%)] Loss: 19283.640625\n",
      "Train Epoch: 107 [55104/225000 (24%)] Loss: 19202.820312\n",
      "Train Epoch: 107 [57600/225000 (26%)] Loss: 19236.251953\n",
      "Train Epoch: 107 [60096/225000 (27%)] Loss: 19685.230469\n",
      "Train Epoch: 107 [62592/225000 (28%)] Loss: 19889.371094\n",
      "Train Epoch: 107 [65088/225000 (29%)] Loss: 19516.880859\n",
      "Train Epoch: 107 [67584/225000 (30%)] Loss: 19283.556641\n",
      "Train Epoch: 107 [70080/225000 (31%)] Loss: 19116.078125\n",
      "Train Epoch: 107 [72576/225000 (32%)] Loss: 19899.425781\n",
      "Train Epoch: 107 [75072/225000 (33%)] Loss: 19141.400391\n",
      "Train Epoch: 107 [77568/225000 (34%)] Loss: 19949.244141\n",
      "Train Epoch: 107 [80064/225000 (36%)] Loss: 19647.984375\n",
      "Train Epoch: 107 [82560/225000 (37%)] Loss: 19172.123047\n",
      "Train Epoch: 107 [85056/225000 (38%)] Loss: 19779.722656\n",
      "Train Epoch: 107 [87552/225000 (39%)] Loss: 19108.392578\n",
      "Train Epoch: 107 [90048/225000 (40%)] Loss: 19345.525391\n",
      "Train Epoch: 107 [92544/225000 (41%)] Loss: 19393.533203\n",
      "Train Epoch: 107 [95040/225000 (42%)] Loss: 19043.820312\n",
      "Train Epoch: 107 [97536/225000 (43%)] Loss: 19589.814453\n",
      "Train Epoch: 107 [100032/225000 (44%)] Loss: 19799.361328\n",
      "Train Epoch: 107 [102528/225000 (46%)] Loss: 19353.693359\n",
      "Train Epoch: 107 [105024/225000 (47%)] Loss: 19442.664062\n",
      "Train Epoch: 107 [107520/225000 (48%)] Loss: 19330.433594\n",
      "Train Epoch: 107 [110016/225000 (49%)] Loss: 19884.947266\n",
      "Train Epoch: 107 [112512/225000 (50%)] Loss: 19646.699219\n",
      "Train Epoch: 107 [115008/225000 (51%)] Loss: 19748.658203\n",
      "Train Epoch: 107 [117504/225000 (52%)] Loss: 19237.992188\n",
      "Train Epoch: 107 [120000/225000 (53%)] Loss: 19640.863281\n",
      "Train Epoch: 107 [122496/225000 (54%)] Loss: 19058.406250\n",
      "Train Epoch: 107 [124992/225000 (56%)] Loss: 19600.466797\n",
      "Train Epoch: 107 [127488/225000 (57%)] Loss: 19383.685547\n",
      "Train Epoch: 107 [129984/225000 (58%)] Loss: 19289.546875\n",
      "Train Epoch: 107 [132480/225000 (59%)] Loss: 19183.490234\n",
      "Train Epoch: 107 [134976/225000 (60%)] Loss: 19343.162109\n",
      "Train Epoch: 107 [137472/225000 (61%)] Loss: 19073.041016\n",
      "Train Epoch: 107 [139968/225000 (62%)] Loss: 19477.998047\n",
      "Train Epoch: 107 [142464/225000 (63%)] Loss: 19625.156250\n",
      "Train Epoch: 107 [144960/225000 (64%)] Loss: 19287.978516\n",
      "Train Epoch: 107 [147456/225000 (66%)] Loss: 19162.304688\n",
      "Train Epoch: 107 [149952/225000 (67%)] Loss: 19607.935547\n",
      "Train Epoch: 107 [152448/225000 (68%)] Loss: 19562.597656\n",
      "Train Epoch: 107 [154944/225000 (69%)] Loss: 18939.072266\n",
      "Train Epoch: 107 [157440/225000 (70%)] Loss: 19192.878906\n",
      "Train Epoch: 107 [159936/225000 (71%)] Loss: 19749.933594\n",
      "Train Epoch: 107 [162432/225000 (72%)] Loss: 19459.253906\n",
      "Train Epoch: 107 [164928/225000 (73%)] Loss: 19454.046875\n",
      "Train Epoch: 107 [167424/225000 (74%)] Loss: 19502.867188\n",
      "Train Epoch: 107 [169920/225000 (76%)] Loss: 19779.511719\n",
      "Train Epoch: 107 [172416/225000 (77%)] Loss: 19500.855469\n",
      "Train Epoch: 107 [174912/225000 (78%)] Loss: 19652.593750\n",
      "Train Epoch: 107 [177408/225000 (79%)] Loss: 18863.767578\n",
      "Train Epoch: 107 [179904/225000 (80%)] Loss: 19687.208984\n",
      "Train Epoch: 107 [182400/225000 (81%)] Loss: 19343.171875\n",
      "Train Epoch: 107 [184896/225000 (82%)] Loss: 19881.167969\n",
      "Train Epoch: 107 [187392/225000 (83%)] Loss: 18926.240234\n",
      "Train Epoch: 107 [189888/225000 (84%)] Loss: 19438.773438\n",
      "Train Epoch: 107 [192384/225000 (86%)] Loss: 19709.650391\n",
      "Train Epoch: 107 [194880/225000 (87%)] Loss: 19288.421875\n",
      "Train Epoch: 107 [197376/225000 (88%)] Loss: 19216.113281\n",
      "Train Epoch: 107 [199872/225000 (89%)] Loss: 19466.386719\n",
      "Train Epoch: 107 [202368/225000 (90%)] Loss: 19445.898438\n",
      "Train Epoch: 107 [204864/225000 (91%)] Loss: 19845.919922\n",
      "Train Epoch: 107 [207360/225000 (92%)] Loss: 18985.898438\n",
      "Train Epoch: 107 [209856/225000 (93%)] Loss: 19295.605469\n",
      "Train Epoch: 107 [212352/225000 (94%)] Loss: 19301.164062\n",
      "Train Epoch: 107 [214848/225000 (95%)] Loss: 19672.277344\n",
      "Train Epoch: 107 [217344/225000 (97%)] Loss: 19440.992188\n",
      "Train Epoch: 107 [219840/225000 (98%)] Loss: 19123.167969\n",
      "Train Epoch: 107 [222336/225000 (99%)] Loss: 19421.519531\n",
      "Train Epoch: 107 [224832/225000 (100%)] Loss: 19174.445312\n",
      "    epoch          : 107\n",
      "    loss           : 19451.761892064846\n",
      "    val_loss       : 19344.420214184367\n",
      "Train Epoch: 108 [192/225000 (0%)] Loss: 19722.646484\n",
      "Train Epoch: 108 [2688/225000 (1%)] Loss: 19363.355469\n",
      "Train Epoch: 108 [5184/225000 (2%)] Loss: 19356.496094\n",
      "Train Epoch: 108 [7680/225000 (3%)] Loss: 19424.269531\n",
      "Train Epoch: 108 [10176/225000 (5%)] Loss: 19167.609375\n",
      "Train Epoch: 108 [12672/225000 (6%)] Loss: 19502.519531\n",
      "Train Epoch: 108 [15168/225000 (7%)] Loss: 19623.714844\n",
      "Train Epoch: 108 [17664/225000 (8%)] Loss: 19701.238281\n",
      "Train Epoch: 108 [20160/225000 (9%)] Loss: 19455.742188\n",
      "Train Epoch: 108 [22656/225000 (10%)] Loss: 18986.640625\n",
      "Train Epoch: 108 [25152/225000 (11%)] Loss: 19481.097656\n",
      "Train Epoch: 108 [27648/225000 (12%)] Loss: 19491.566406\n",
      "Train Epoch: 108 [30144/225000 (13%)] Loss: 19680.238281\n",
      "Train Epoch: 108 [32640/225000 (15%)] Loss: 19657.490234\n",
      "Train Epoch: 108 [35136/225000 (16%)] Loss: 19238.884766\n",
      "Train Epoch: 108 [37632/225000 (17%)] Loss: 20029.820312\n",
      "Train Epoch: 108 [40128/225000 (18%)] Loss: 19241.837891\n",
      "Train Epoch: 108 [42624/225000 (19%)] Loss: 19325.746094\n",
      "Train Epoch: 108 [45120/225000 (20%)] Loss: 19791.144531\n",
      "Train Epoch: 108 [47616/225000 (21%)] Loss: 19785.978516\n",
      "Train Epoch: 108 [50112/225000 (22%)] Loss: 19938.679688\n",
      "Train Epoch: 108 [52608/225000 (23%)] Loss: 19036.871094\n",
      "Train Epoch: 108 [55104/225000 (24%)] Loss: 19451.082031\n",
      "Train Epoch: 108 [57600/225000 (26%)] Loss: 19348.531250\n",
      "Train Epoch: 108 [60096/225000 (27%)] Loss: 19895.839844\n",
      "Train Epoch: 108 [62592/225000 (28%)] Loss: 19953.824219\n",
      "Train Epoch: 108 [65088/225000 (29%)] Loss: 19269.507812\n",
      "Train Epoch: 108 [67584/225000 (30%)] Loss: 19286.048828\n",
      "Train Epoch: 108 [70080/225000 (31%)] Loss: 19571.250000\n",
      "Train Epoch: 108 [72576/225000 (32%)] Loss: 19362.500000\n",
      "Train Epoch: 108 [75072/225000 (33%)] Loss: 19662.906250\n",
      "Train Epoch: 108 [77568/225000 (34%)] Loss: 19565.804688\n",
      "Train Epoch: 108 [80064/225000 (36%)] Loss: 19080.441406\n",
      "Train Epoch: 108 [82560/225000 (37%)] Loss: 19761.957031\n",
      "Train Epoch: 108 [85056/225000 (38%)] Loss: 19509.097656\n",
      "Train Epoch: 108 [87552/225000 (39%)] Loss: 19529.515625\n",
      "Train Epoch: 108 [90048/225000 (40%)] Loss: 19319.902344\n",
      "Train Epoch: 108 [92544/225000 (41%)] Loss: 19218.179688\n",
      "Train Epoch: 108 [95040/225000 (42%)] Loss: 19476.742188\n",
      "Train Epoch: 108 [97536/225000 (43%)] Loss: 19222.960938\n",
      "Train Epoch: 108 [100032/225000 (44%)] Loss: 19535.744141\n",
      "Train Epoch: 108 [102528/225000 (46%)] Loss: 19797.367188\n",
      "Train Epoch: 108 [105024/225000 (47%)] Loss: 19766.664062\n",
      "Train Epoch: 108 [107520/225000 (48%)] Loss: 19814.421875\n",
      "Train Epoch: 108 [110016/225000 (49%)] Loss: 19317.578125\n",
      "Train Epoch: 108 [112512/225000 (50%)] Loss: 19769.160156\n",
      "Train Epoch: 108 [115008/225000 (51%)] Loss: 19390.246094\n",
      "Train Epoch: 108 [117504/225000 (52%)] Loss: 19658.859375\n",
      "Train Epoch: 108 [120000/225000 (53%)] Loss: 19352.234375\n",
      "Train Epoch: 108 [122496/225000 (54%)] Loss: 19494.974609\n",
      "Train Epoch: 108 [124992/225000 (56%)] Loss: 19321.083984\n",
      "Train Epoch: 108 [127488/225000 (57%)] Loss: 18865.841797\n",
      "Train Epoch: 108 [129984/225000 (58%)] Loss: 19616.667969\n",
      "Train Epoch: 108 [132480/225000 (59%)] Loss: 19296.914062\n",
      "Train Epoch: 108 [134976/225000 (60%)] Loss: 19326.056641\n",
      "Train Epoch: 108 [137472/225000 (61%)] Loss: 19125.601562\n",
      "Train Epoch: 108 [139968/225000 (62%)] Loss: 18976.990234\n",
      "Train Epoch: 108 [142464/225000 (63%)] Loss: 19167.683594\n",
      "Train Epoch: 108 [144960/225000 (64%)] Loss: 19542.429688\n",
      "Train Epoch: 108 [147456/225000 (66%)] Loss: 19253.093750\n",
      "Train Epoch: 108 [149952/225000 (67%)] Loss: 19408.671875\n",
      "Train Epoch: 108 [152448/225000 (68%)] Loss: 19018.283203\n",
      "Train Epoch: 108 [154944/225000 (69%)] Loss: 19740.939453\n",
      "Train Epoch: 108 [157440/225000 (70%)] Loss: 19330.480469\n",
      "Train Epoch: 108 [159936/225000 (71%)] Loss: 19681.648438\n",
      "Train Epoch: 108 [162432/225000 (72%)] Loss: 19552.675781\n",
      "Train Epoch: 108 [164928/225000 (73%)] Loss: 19601.527344\n",
      "Train Epoch: 108 [167424/225000 (74%)] Loss: 19502.082031\n",
      "Train Epoch: 108 [169920/225000 (76%)] Loss: 18957.660156\n",
      "Train Epoch: 108 [172416/225000 (77%)] Loss: 19359.164062\n",
      "Train Epoch: 108 [174912/225000 (78%)] Loss: 19262.478516\n",
      "Train Epoch: 108 [177408/225000 (79%)] Loss: 19441.621094\n",
      "Train Epoch: 108 [179904/225000 (80%)] Loss: 19432.398438\n",
      "Train Epoch: 108 [182400/225000 (81%)] Loss: 19806.179688\n",
      "Train Epoch: 108 [184896/225000 (82%)] Loss: 19540.265625\n",
      "Train Epoch: 108 [187392/225000 (83%)] Loss: 19293.503906\n",
      "Train Epoch: 108 [189888/225000 (84%)] Loss: 19368.562500\n",
      "Train Epoch: 108 [192384/225000 (86%)] Loss: 19721.041016\n",
      "Train Epoch: 108 [194880/225000 (87%)] Loss: 19356.039062\n",
      "Train Epoch: 108 [197376/225000 (88%)] Loss: 19317.177734\n",
      "Train Epoch: 108 [199872/225000 (89%)] Loss: 19028.082031\n",
      "Train Epoch: 108 [202368/225000 (90%)] Loss: 19416.421875\n",
      "Train Epoch: 108 [204864/225000 (91%)] Loss: 19201.822266\n",
      "Train Epoch: 108 [207360/225000 (92%)] Loss: 19876.951172\n",
      "Train Epoch: 108 [209856/225000 (93%)] Loss: 19678.082031\n",
      "Train Epoch: 108 [212352/225000 (94%)] Loss: 19164.701172\n",
      "Train Epoch: 108 [214848/225000 (95%)] Loss: 19358.152344\n",
      "Train Epoch: 108 [217344/225000 (97%)] Loss: 19152.900391\n",
      "Train Epoch: 108 [219840/225000 (98%)] Loss: 19540.683594\n",
      "Train Epoch: 108 [222336/225000 (99%)] Loss: 19537.007812\n",
      "Train Epoch: 108 [224832/225000 (100%)] Loss: 19231.962891\n",
      "    epoch          : 108\n",
      "    loss           : 19440.103707271224\n",
      "    val_loss       : 19384.77122038603\n",
      "Train Epoch: 109 [192/225000 (0%)] Loss: 19898.988281\n",
      "Train Epoch: 109 [2688/225000 (1%)] Loss: 19246.958984\n",
      "Train Epoch: 109 [5184/225000 (2%)] Loss: 19549.710938\n",
      "Train Epoch: 109 [7680/225000 (3%)] Loss: 19246.751953\n",
      "Train Epoch: 109 [10176/225000 (5%)] Loss: 19437.908203\n",
      "Train Epoch: 109 [12672/225000 (6%)] Loss: 19898.349609\n",
      "Train Epoch: 109 [15168/225000 (7%)] Loss: 19701.162109\n",
      "Train Epoch: 109 [17664/225000 (8%)] Loss: 19588.207031\n",
      "Train Epoch: 109 [20160/225000 (9%)] Loss: 19488.960938\n",
      "Train Epoch: 109 [22656/225000 (10%)] Loss: 19555.496094\n",
      "Train Epoch: 109 [25152/225000 (11%)] Loss: 19700.863281\n",
      "Train Epoch: 109 [27648/225000 (12%)] Loss: 19728.277344\n",
      "Train Epoch: 109 [30144/225000 (13%)] Loss: 19270.873047\n",
      "Train Epoch: 109 [32640/225000 (15%)] Loss: 19225.806641\n",
      "Train Epoch: 109 [35136/225000 (16%)] Loss: 19542.976562\n",
      "Train Epoch: 109 [37632/225000 (17%)] Loss: 19670.558594\n",
      "Train Epoch: 109 [40128/225000 (18%)] Loss: 19209.691406\n",
      "Train Epoch: 109 [42624/225000 (19%)] Loss: 19468.222656\n",
      "Train Epoch: 109 [45120/225000 (20%)] Loss: 19353.636719\n",
      "Train Epoch: 109 [47616/225000 (21%)] Loss: 19119.289062\n",
      "Train Epoch: 109 [50112/225000 (22%)] Loss: 19509.445312\n",
      "Train Epoch: 109 [52608/225000 (23%)] Loss: 19750.164062\n",
      "Train Epoch: 109 [55104/225000 (24%)] Loss: 19666.019531\n",
      "Train Epoch: 109 [57600/225000 (26%)] Loss: 19377.972656\n",
      "Train Epoch: 109 [60096/225000 (27%)] Loss: 19437.503906\n",
      "Train Epoch: 109 [62592/225000 (28%)] Loss: 19009.369141\n",
      "Train Epoch: 109 [65088/225000 (29%)] Loss: 19514.898438\n",
      "Train Epoch: 109 [67584/225000 (30%)] Loss: 19261.226562\n",
      "Train Epoch: 109 [70080/225000 (31%)] Loss: 19609.568359\n",
      "Train Epoch: 109 [72576/225000 (32%)] Loss: 19806.453125\n",
      "Train Epoch: 109 [75072/225000 (33%)] Loss: 19285.244141\n",
      "Train Epoch: 109 [77568/225000 (34%)] Loss: 19607.503906\n",
      "Train Epoch: 109 [80064/225000 (36%)] Loss: 19427.734375\n",
      "Train Epoch: 109 [82560/225000 (37%)] Loss: 19541.503906\n",
      "Train Epoch: 109 [85056/225000 (38%)] Loss: 19271.492188\n",
      "Train Epoch: 109 [87552/225000 (39%)] Loss: 19696.757812\n",
      "Train Epoch: 109 [90048/225000 (40%)] Loss: 19335.308594\n",
      "Train Epoch: 109 [92544/225000 (41%)] Loss: 19149.914062\n",
      "Train Epoch: 109 [95040/225000 (42%)] Loss: 19296.386719\n",
      "Train Epoch: 109 [97536/225000 (43%)] Loss: 19352.671875\n",
      "Train Epoch: 109 [100032/225000 (44%)] Loss: 19518.027344\n",
      "Train Epoch: 109 [102528/225000 (46%)] Loss: 19169.429688\n",
      "Train Epoch: 109 [105024/225000 (47%)] Loss: 19195.253906\n",
      "Train Epoch: 109 [107520/225000 (48%)] Loss: 18792.148438\n",
      "Train Epoch: 109 [110016/225000 (49%)] Loss: 19086.511719\n",
      "Train Epoch: 109 [112512/225000 (50%)] Loss: 19208.968750\n",
      "Train Epoch: 109 [115008/225000 (51%)] Loss: 19335.218750\n",
      "Train Epoch: 109 [117504/225000 (52%)] Loss: 19701.351562\n",
      "Train Epoch: 109 [120000/225000 (53%)] Loss: 19281.185547\n",
      "Train Epoch: 109 [122496/225000 (54%)] Loss: 19804.609375\n",
      "Train Epoch: 109 [124992/225000 (56%)] Loss: 19701.230469\n",
      "Train Epoch: 109 [127488/225000 (57%)] Loss: 19842.761719\n",
      "Train Epoch: 109 [129984/225000 (58%)] Loss: 19300.687500\n",
      "Train Epoch: 109 [132480/225000 (59%)] Loss: 19051.097656\n",
      "Train Epoch: 109 [134976/225000 (60%)] Loss: 19323.880859\n",
      "Train Epoch: 109 [137472/225000 (61%)] Loss: 19314.865234\n",
      "Train Epoch: 109 [139968/225000 (62%)] Loss: 19613.578125\n",
      "Train Epoch: 109 [142464/225000 (63%)] Loss: 18759.890625\n",
      "Train Epoch: 109 [144960/225000 (64%)] Loss: 19670.582031\n",
      "Train Epoch: 109 [147456/225000 (66%)] Loss: 19761.011719\n",
      "Train Epoch: 109 [149952/225000 (67%)] Loss: 19188.464844\n",
      "Train Epoch: 109 [152448/225000 (68%)] Loss: 19224.892578\n",
      "Train Epoch: 109 [154944/225000 (69%)] Loss: 19799.933594\n",
      "Train Epoch: 109 [157440/225000 (70%)] Loss: 19640.773438\n",
      "Train Epoch: 109 [159936/225000 (71%)] Loss: 19632.062500\n",
      "Train Epoch: 109 [162432/225000 (72%)] Loss: 18788.839844\n",
      "Train Epoch: 109 [164928/225000 (73%)] Loss: 19905.042969\n",
      "Train Epoch: 109 [167424/225000 (74%)] Loss: 19211.347656\n",
      "Train Epoch: 109 [169920/225000 (76%)] Loss: 19561.460938\n",
      "Train Epoch: 109 [172416/225000 (77%)] Loss: 19396.353516\n",
      "Train Epoch: 109 [174912/225000 (78%)] Loss: 19446.947266\n",
      "Train Epoch: 109 [177408/225000 (79%)] Loss: 19092.300781\n",
      "Train Epoch: 109 [179904/225000 (80%)] Loss: 19776.119141\n",
      "Train Epoch: 109 [182400/225000 (81%)] Loss: 19096.023438\n",
      "Train Epoch: 109 [184896/225000 (82%)] Loss: 19278.921875\n",
      "Train Epoch: 109 [187392/225000 (83%)] Loss: 18911.359375\n",
      "Train Epoch: 109 [189888/225000 (84%)] Loss: 19956.597656\n",
      "Train Epoch: 109 [192384/225000 (86%)] Loss: 19169.914062\n",
      "Train Epoch: 109 [194880/225000 (87%)] Loss: 19425.828125\n",
      "Train Epoch: 109 [197376/225000 (88%)] Loss: 19803.699219\n",
      "Train Epoch: 109 [199872/225000 (89%)] Loss: 18909.515625\n",
      "Train Epoch: 109 [202368/225000 (90%)] Loss: 19161.691406\n",
      "Train Epoch: 109 [204864/225000 (91%)] Loss: 19332.351562\n",
      "Train Epoch: 109 [207360/225000 (92%)] Loss: 18826.357422\n",
      "Train Epoch: 109 [209856/225000 (93%)] Loss: 19333.238281\n",
      "Train Epoch: 109 [212352/225000 (94%)] Loss: 19511.296875\n",
      "Train Epoch: 109 [214848/225000 (95%)] Loss: 19330.019531\n",
      "Train Epoch: 109 [217344/225000 (97%)] Loss: 19476.437500\n",
      "Train Epoch: 109 [219840/225000 (98%)] Loss: 19430.398438\n",
      "Train Epoch: 109 [222336/225000 (99%)] Loss: 19692.628906\n",
      "Train Epoch: 109 [224832/225000 (100%)] Loss: 19478.437500\n",
      "    epoch          : 109\n",
      "    loss           : 19435.71856501973\n",
      "    val_loss       : 19340.2229185573\n",
      "Train Epoch: 110 [192/225000 (0%)] Loss: 19662.218750\n",
      "Train Epoch: 110 [2688/225000 (1%)] Loss: 18921.994141\n",
      "Train Epoch: 110 [5184/225000 (2%)] Loss: 19517.917969\n",
      "Train Epoch: 110 [7680/225000 (3%)] Loss: 19737.626953\n",
      "Train Epoch: 110 [10176/225000 (5%)] Loss: 19467.109375\n",
      "Train Epoch: 110 [12672/225000 (6%)] Loss: 19114.691406\n",
      "Train Epoch: 110 [15168/225000 (7%)] Loss: 19708.691406\n",
      "Train Epoch: 110 [17664/225000 (8%)] Loss: 19142.761719\n",
      "Train Epoch: 110 [20160/225000 (9%)] Loss: 20006.255859\n",
      "Train Epoch: 110 [22656/225000 (10%)] Loss: 19594.894531\n",
      "Train Epoch: 110 [25152/225000 (11%)] Loss: 19411.433594\n",
      "Train Epoch: 110 [27648/225000 (12%)] Loss: 18967.380859\n",
      "Train Epoch: 110 [30144/225000 (13%)] Loss: 19730.800781\n",
      "Train Epoch: 110 [32640/225000 (15%)] Loss: 19678.769531\n",
      "Train Epoch: 110 [35136/225000 (16%)] Loss: 19705.900391\n",
      "Train Epoch: 110 [37632/225000 (17%)] Loss: 19517.468750\n",
      "Train Epoch: 110 [40128/225000 (18%)] Loss: 19778.904297\n",
      "Train Epoch: 110 [42624/225000 (19%)] Loss: 19125.710938\n",
      "Train Epoch: 110 [45120/225000 (20%)] Loss: 19594.437500\n",
      "Train Epoch: 110 [47616/225000 (21%)] Loss: 19513.962891\n",
      "Train Epoch: 110 [50112/225000 (22%)] Loss: 19460.714844\n",
      "Train Epoch: 110 [52608/225000 (23%)] Loss: 19544.730469\n",
      "Train Epoch: 110 [55104/225000 (24%)] Loss: 19301.857422\n",
      "Train Epoch: 110 [57600/225000 (26%)] Loss: 19507.253906\n",
      "Train Epoch: 110 [60096/225000 (27%)] Loss: 19290.296875\n",
      "Train Epoch: 110 [62592/225000 (28%)] Loss: 19887.828125\n",
      "Train Epoch: 110 [65088/225000 (29%)] Loss: 19535.023438\n",
      "Train Epoch: 110 [67584/225000 (30%)] Loss: 19616.046875\n",
      "Train Epoch: 110 [70080/225000 (31%)] Loss: 19660.902344\n",
      "Train Epoch: 110 [72576/225000 (32%)] Loss: 19224.074219\n",
      "Train Epoch: 110 [75072/225000 (33%)] Loss: 19576.484375\n",
      "Train Epoch: 110 [77568/225000 (34%)] Loss: 18962.273438\n",
      "Train Epoch: 110 [80064/225000 (36%)] Loss: 19337.568359\n",
      "Train Epoch: 110 [82560/225000 (37%)] Loss: 19712.230469\n",
      "Train Epoch: 110 [85056/225000 (38%)] Loss: 19259.546875\n",
      "Train Epoch: 110 [87552/225000 (39%)] Loss: 19098.230469\n",
      "Train Epoch: 110 [90048/225000 (40%)] Loss: 19622.531250\n",
      "Train Epoch: 110 [92544/225000 (41%)] Loss: 19581.546875\n",
      "Train Epoch: 110 [95040/225000 (42%)] Loss: 19560.769531\n",
      "Train Epoch: 110 [97536/225000 (43%)] Loss: 19158.234375\n",
      "Train Epoch: 110 [100032/225000 (44%)] Loss: 19456.646484\n",
      "Train Epoch: 110 [102528/225000 (46%)] Loss: 19212.537109\n",
      "Train Epoch: 110 [105024/225000 (47%)] Loss: 19487.312500\n",
      "Train Epoch: 110 [107520/225000 (48%)] Loss: 19645.171875\n",
      "Train Epoch: 110 [110016/225000 (49%)] Loss: 19464.875000\n",
      "Train Epoch: 110 [112512/225000 (50%)] Loss: 19427.732422\n",
      "Train Epoch: 110 [115008/225000 (51%)] Loss: 19485.287109\n",
      "Train Epoch: 110 [117504/225000 (52%)] Loss: 19056.125000\n",
      "Train Epoch: 110 [120000/225000 (53%)] Loss: 19529.568359\n",
      "Train Epoch: 110 [122496/225000 (54%)] Loss: 19387.500000\n",
      "Train Epoch: 110 [124992/225000 (56%)] Loss: 19351.441406\n",
      "Train Epoch: 110 [127488/225000 (57%)] Loss: 19343.632812\n",
      "Train Epoch: 110 [129984/225000 (58%)] Loss: 19339.351562\n",
      "Train Epoch: 110 [132480/225000 (59%)] Loss: 19505.427734\n",
      "Train Epoch: 110 [134976/225000 (60%)] Loss: 19381.869141\n",
      "Train Epoch: 110 [137472/225000 (61%)] Loss: 19100.107422\n",
      "Train Epoch: 110 [139968/225000 (62%)] Loss: 19511.060547\n",
      "Train Epoch: 110 [142464/225000 (63%)] Loss: 19175.035156\n",
      "Train Epoch: 110 [144960/225000 (64%)] Loss: 19746.839844\n",
      "Train Epoch: 110 [147456/225000 (66%)] Loss: 19616.039062\n",
      "Train Epoch: 110 [149952/225000 (67%)] Loss: 18903.998047\n",
      "Train Epoch: 110 [152448/225000 (68%)] Loss: 19591.863281\n",
      "Train Epoch: 110 [154944/225000 (69%)] Loss: 19725.453125\n",
      "Train Epoch: 110 [157440/225000 (70%)] Loss: 19476.675781\n",
      "Train Epoch: 110 [159936/225000 (71%)] Loss: 19747.472656\n",
      "Train Epoch: 110 [162432/225000 (72%)] Loss: 19618.257812\n",
      "Train Epoch: 110 [164928/225000 (73%)] Loss: 19752.175781\n",
      "Train Epoch: 110 [167424/225000 (74%)] Loss: 19302.085938\n",
      "Train Epoch: 110 [169920/225000 (76%)] Loss: 18659.761719\n",
      "Train Epoch: 110 [172416/225000 (77%)] Loss: 19455.080078\n",
      "Train Epoch: 110 [174912/225000 (78%)] Loss: 19311.378906\n",
      "Train Epoch: 110 [177408/225000 (79%)] Loss: 19716.912109\n",
      "Train Epoch: 110 [179904/225000 (80%)] Loss: 19288.527344\n",
      "Train Epoch: 110 [182400/225000 (81%)] Loss: 19638.019531\n",
      "Train Epoch: 110 [184896/225000 (82%)] Loss: 19424.279297\n",
      "Train Epoch: 110 [187392/225000 (83%)] Loss: 19074.195312\n",
      "Train Epoch: 110 [189888/225000 (84%)] Loss: 19659.636719\n",
      "Train Epoch: 110 [192384/225000 (86%)] Loss: 19438.816406\n",
      "Train Epoch: 110 [194880/225000 (87%)] Loss: 19212.744141\n",
      "Train Epoch: 110 [197376/225000 (88%)] Loss: 19839.638672\n",
      "Train Epoch: 110 [199872/225000 (89%)] Loss: 19666.166016\n",
      "Train Epoch: 110 [202368/225000 (90%)] Loss: 19296.988281\n",
      "Train Epoch: 110 [204864/225000 (91%)] Loss: 19454.656250\n",
      "Train Epoch: 110 [207360/225000 (92%)] Loss: 19641.804688\n",
      "Train Epoch: 110 [209856/225000 (93%)] Loss: 19461.535156\n",
      "Train Epoch: 110 [212352/225000 (94%)] Loss: 19339.683594\n",
      "Train Epoch: 110 [214848/225000 (95%)] Loss: 19495.375000\n",
      "Train Epoch: 110 [217344/225000 (97%)] Loss: 19785.619141\n",
      "Train Epoch: 110 [219840/225000 (98%)] Loss: 19219.796875\n",
      "Train Epoch: 110 [222336/225000 (99%)] Loss: 19645.164062\n",
      "Train Epoch: 110 [224832/225000 (100%)] Loss: 19499.464844\n",
      "    epoch          : 110\n",
      "    loss           : 19432.153758599085\n",
      "    val_loss       : 19345.3859200878\n",
      "Train Epoch: 111 [192/225000 (0%)] Loss: 19218.181641\n",
      "Train Epoch: 111 [2688/225000 (1%)] Loss: 19415.259766\n",
      "Train Epoch: 111 [5184/225000 (2%)] Loss: 18689.222656\n",
      "Train Epoch: 111 [7680/225000 (3%)] Loss: 19164.255859\n",
      "Train Epoch: 111 [10176/225000 (5%)] Loss: 19421.572266\n",
      "Train Epoch: 111 [12672/225000 (6%)] Loss: 19588.527344\n",
      "Train Epoch: 111 [15168/225000 (7%)] Loss: 19488.734375\n",
      "Train Epoch: 111 [17664/225000 (8%)] Loss: 19530.910156\n",
      "Train Epoch: 111 [20160/225000 (9%)] Loss: 19418.480469\n",
      "Train Epoch: 111 [22656/225000 (10%)] Loss: 19430.332031\n",
      "Train Epoch: 111 [25152/225000 (11%)] Loss: 19127.734375\n",
      "Train Epoch: 111 [27648/225000 (12%)] Loss: 19189.154297\n",
      "Train Epoch: 111 [30144/225000 (13%)] Loss: 19524.113281\n",
      "Train Epoch: 111 [32640/225000 (15%)] Loss: 19651.253906\n",
      "Train Epoch: 111 [35136/225000 (16%)] Loss: 19638.599609\n",
      "Train Epoch: 111 [37632/225000 (17%)] Loss: 19376.851562\n",
      "Train Epoch: 111 [40128/225000 (18%)] Loss: 18649.033203\n",
      "Train Epoch: 111 [42624/225000 (19%)] Loss: 19519.281250\n",
      "Train Epoch: 111 [45120/225000 (20%)] Loss: 19242.335938\n",
      "Train Epoch: 111 [47616/225000 (21%)] Loss: 19290.820312\n",
      "Train Epoch: 111 [50112/225000 (22%)] Loss: 19289.812500\n",
      "Train Epoch: 111 [52608/225000 (23%)] Loss: 19227.851562\n",
      "Train Epoch: 111 [55104/225000 (24%)] Loss: 19255.003906\n",
      "Train Epoch: 111 [57600/225000 (26%)] Loss: 19112.722656\n",
      "Train Epoch: 111 [60096/225000 (27%)] Loss: 19653.019531\n",
      "Train Epoch: 111 [62592/225000 (28%)] Loss: 19095.976562\n",
      "Train Epoch: 111 [65088/225000 (29%)] Loss: 19570.910156\n",
      "Train Epoch: 111 [67584/225000 (30%)] Loss: 18660.480469\n",
      "Train Epoch: 111 [70080/225000 (31%)] Loss: 19832.187500\n",
      "Train Epoch: 111 [72576/225000 (32%)] Loss: 19327.753906\n",
      "Train Epoch: 111 [75072/225000 (33%)] Loss: 19426.740234\n",
      "Train Epoch: 111 [77568/225000 (34%)] Loss: 19696.363281\n",
      "Train Epoch: 111 [80064/225000 (36%)] Loss: 19687.632812\n",
      "Train Epoch: 111 [82560/225000 (37%)] Loss: 19547.166016\n",
      "Train Epoch: 111 [85056/225000 (38%)] Loss: 19305.441406\n",
      "Train Epoch: 111 [87552/225000 (39%)] Loss: 19653.144531\n",
      "Train Epoch: 111 [90048/225000 (40%)] Loss: 19766.816406\n",
      "Train Epoch: 111 [92544/225000 (41%)] Loss: 19094.777344\n",
      "Train Epoch: 111 [95040/225000 (42%)] Loss: 19349.876953\n",
      "Train Epoch: 111 [97536/225000 (43%)] Loss: 19613.777344\n",
      "Train Epoch: 111 [100032/225000 (44%)] Loss: 19071.458984\n",
      "Train Epoch: 111 [102528/225000 (46%)] Loss: 19173.347656\n",
      "Train Epoch: 111 [105024/225000 (47%)] Loss: 19086.191406\n",
      "Train Epoch: 111 [107520/225000 (48%)] Loss: 19541.777344\n",
      "Train Epoch: 111 [110016/225000 (49%)] Loss: 19406.285156\n",
      "Train Epoch: 111 [112512/225000 (50%)] Loss: 19396.507812\n",
      "Train Epoch: 111 [115008/225000 (51%)] Loss: 19547.794922\n",
      "Train Epoch: 111 [117504/225000 (52%)] Loss: 19713.597656\n",
      "Train Epoch: 111 [120000/225000 (53%)] Loss: 19803.421875\n",
      "Train Epoch: 111 [122496/225000 (54%)] Loss: 19327.167969\n",
      "Train Epoch: 111 [124992/225000 (56%)] Loss: 19315.884766\n",
      "Train Epoch: 111 [127488/225000 (57%)] Loss: 19539.675781\n",
      "Train Epoch: 111 [129984/225000 (58%)] Loss: 19530.000000\n",
      "Train Epoch: 111 [132480/225000 (59%)] Loss: 19080.218750\n",
      "Train Epoch: 111 [134976/225000 (60%)] Loss: 19565.839844\n",
      "Train Epoch: 111 [137472/225000 (61%)] Loss: 19252.423828\n",
      "Train Epoch: 111 [139968/225000 (62%)] Loss: 19529.742188\n",
      "Train Epoch: 111 [142464/225000 (63%)] Loss: 19283.574219\n",
      "Train Epoch: 111 [144960/225000 (64%)] Loss: 19147.984375\n",
      "Train Epoch: 111 [147456/225000 (66%)] Loss: 19536.761719\n",
      "Train Epoch: 111 [149952/225000 (67%)] Loss: 19634.359375\n",
      "Train Epoch: 111 [152448/225000 (68%)] Loss: 19499.375000\n",
      "Train Epoch: 111 [154944/225000 (69%)] Loss: 18868.699219\n",
      "Train Epoch: 111 [157440/225000 (70%)] Loss: 19287.082031\n",
      "Train Epoch: 111 [159936/225000 (71%)] Loss: 19597.222656\n",
      "Train Epoch: 111 [162432/225000 (72%)] Loss: 19397.470703\n",
      "Train Epoch: 111 [164928/225000 (73%)] Loss: 19413.410156\n",
      "Train Epoch: 111 [167424/225000 (74%)] Loss: 19581.148438\n",
      "Train Epoch: 111 [169920/225000 (76%)] Loss: 19197.111328\n",
      "Train Epoch: 111 [172416/225000 (77%)] Loss: 18731.994141\n",
      "Train Epoch: 111 [174912/225000 (78%)] Loss: 19111.785156\n",
      "Train Epoch: 111 [177408/225000 (79%)] Loss: 19686.716797\n",
      "Train Epoch: 111 [179904/225000 (80%)] Loss: 19460.482422\n",
      "Train Epoch: 111 [182400/225000 (81%)] Loss: 19230.322266\n",
      "Train Epoch: 111 [184896/225000 (82%)] Loss: 19692.267578\n",
      "Train Epoch: 111 [187392/225000 (83%)] Loss: 19071.617188\n",
      "Train Epoch: 111 [189888/225000 (84%)] Loss: 19281.394531\n",
      "Train Epoch: 111 [192384/225000 (86%)] Loss: 19423.281250\n",
      "Train Epoch: 111 [194880/225000 (87%)] Loss: 19578.873047\n",
      "Train Epoch: 111 [197376/225000 (88%)] Loss: 19365.343750\n",
      "Train Epoch: 111 [199872/225000 (89%)] Loss: 19454.583984\n",
      "Train Epoch: 111 [202368/225000 (90%)] Loss: 19330.019531\n",
      "Train Epoch: 111 [204864/225000 (91%)] Loss: 19491.574219\n",
      "Train Epoch: 111 [207360/225000 (92%)] Loss: 18976.166016\n",
      "Train Epoch: 111 [209856/225000 (93%)] Loss: 18924.066406\n",
      "Train Epoch: 111 [212352/225000 (94%)] Loss: 19337.675781\n",
      "Train Epoch: 111 [214848/225000 (95%)] Loss: 19658.746094\n",
      "Train Epoch: 111 [217344/225000 (97%)] Loss: 19676.171875\n",
      "Train Epoch: 111 [219840/225000 (98%)] Loss: 19568.246094\n",
      "Train Epoch: 111 [222336/225000 (99%)] Loss: 19473.082031\n",
      "Train Epoch: 111 [224832/225000 (100%)] Loss: 19481.695312\n",
      "    epoch          : 111\n",
      "    loss           : 19420.664182487202\n",
      "    val_loss       : 19345.37752357876\n",
      "Train Epoch: 112 [192/225000 (0%)] Loss: 19781.142578\n",
      "Train Epoch: 112 [2688/225000 (1%)] Loss: 19288.863281\n",
      "Train Epoch: 112 [5184/225000 (2%)] Loss: 19127.074219\n",
      "Train Epoch: 112 [7680/225000 (3%)] Loss: 19119.656250\n",
      "Train Epoch: 112 [10176/225000 (5%)] Loss: 19483.244141\n",
      "Train Epoch: 112 [12672/225000 (6%)] Loss: 19368.193359\n",
      "Train Epoch: 112 [15168/225000 (7%)] Loss: 18782.642578\n",
      "Train Epoch: 112 [17664/225000 (8%)] Loss: 19411.519531\n",
      "Train Epoch: 112 [20160/225000 (9%)] Loss: 19298.474609\n",
      "Train Epoch: 112 [22656/225000 (10%)] Loss: 19257.214844\n",
      "Train Epoch: 112 [25152/225000 (11%)] Loss: 18882.875000\n",
      "Train Epoch: 112 [27648/225000 (12%)] Loss: 19019.185547\n",
      "Train Epoch: 112 [30144/225000 (13%)] Loss: 19567.847656\n",
      "Train Epoch: 112 [32640/225000 (15%)] Loss: 19550.718750\n",
      "Train Epoch: 112 [35136/225000 (16%)] Loss: 19497.847656\n",
      "Train Epoch: 112 [37632/225000 (17%)] Loss: 19791.658203\n",
      "Train Epoch: 112 [40128/225000 (18%)] Loss: 19389.589844\n",
      "Train Epoch: 112 [42624/225000 (19%)] Loss: 19107.238281\n",
      "Train Epoch: 112 [45120/225000 (20%)] Loss: 19871.277344\n",
      "Train Epoch: 112 [47616/225000 (21%)] Loss: 19405.355469\n",
      "Train Epoch: 112 [50112/225000 (22%)] Loss: 19636.265625\n",
      "Train Epoch: 112 [52608/225000 (23%)] Loss: 19213.253906\n",
      "Train Epoch: 112 [55104/225000 (24%)] Loss: 19502.558594\n",
      "Train Epoch: 112 [57600/225000 (26%)] Loss: 19344.597656\n",
      "Train Epoch: 112 [60096/225000 (27%)] Loss: 19649.871094\n",
      "Train Epoch: 112 [62592/225000 (28%)] Loss: 18956.566406\n",
      "Train Epoch: 112 [65088/225000 (29%)] Loss: 19456.781250\n",
      "Train Epoch: 112 [67584/225000 (30%)] Loss: 18960.648438\n",
      "Train Epoch: 112 [70080/225000 (31%)] Loss: 19363.917969\n",
      "Train Epoch: 112 [72576/225000 (32%)] Loss: 18999.634766\n",
      "Train Epoch: 112 [75072/225000 (33%)] Loss: 19938.183594\n",
      "Train Epoch: 112 [77568/225000 (34%)] Loss: 19155.490234\n",
      "Train Epoch: 112 [80064/225000 (36%)] Loss: 19465.097656\n",
      "Train Epoch: 112 [82560/225000 (37%)] Loss: 19860.263672\n",
      "Train Epoch: 112 [85056/225000 (38%)] Loss: 19541.802734\n",
      "Train Epoch: 112 [87552/225000 (39%)] Loss: 19049.205078\n",
      "Train Epoch: 112 [90048/225000 (40%)] Loss: 19539.564453\n",
      "Train Epoch: 112 [92544/225000 (41%)] Loss: 19561.585938\n",
      "Train Epoch: 112 [95040/225000 (42%)] Loss: 19619.103516\n",
      "Train Epoch: 112 [97536/225000 (43%)] Loss: 20111.896484\n",
      "Train Epoch: 112 [100032/225000 (44%)] Loss: 19588.363281\n",
      "Train Epoch: 112 [102528/225000 (46%)] Loss: 19855.531250\n",
      "Train Epoch: 112 [105024/225000 (47%)] Loss: 19775.628906\n",
      "Train Epoch: 112 [107520/225000 (48%)] Loss: 19221.789062\n",
      "Train Epoch: 112 [110016/225000 (49%)] Loss: 19826.414062\n",
      "Train Epoch: 112 [112512/225000 (50%)] Loss: 19341.433594\n",
      "Train Epoch: 112 [115008/225000 (51%)] Loss: 19196.203125\n",
      "Train Epoch: 112 [117504/225000 (52%)] Loss: 19487.445312\n",
      "Train Epoch: 112 [120000/225000 (53%)] Loss: 18984.343750\n",
      "Train Epoch: 112 [122496/225000 (54%)] Loss: 19182.134766\n",
      "Train Epoch: 112 [124992/225000 (56%)] Loss: 19433.087891\n",
      "Train Epoch: 112 [127488/225000 (57%)] Loss: 19052.449219\n",
      "Train Epoch: 112 [129984/225000 (58%)] Loss: 19421.972656\n",
      "Train Epoch: 112 [132480/225000 (59%)] Loss: 19334.316406\n",
      "Train Epoch: 112 [134976/225000 (60%)] Loss: 19130.089844\n",
      "Train Epoch: 112 [137472/225000 (61%)] Loss: 19208.892578\n",
      "Train Epoch: 112 [139968/225000 (62%)] Loss: 19902.734375\n",
      "Train Epoch: 112 [142464/225000 (63%)] Loss: 19110.375000\n",
      "Train Epoch: 112 [144960/225000 (64%)] Loss: 19462.710938\n",
      "Train Epoch: 112 [147456/225000 (66%)] Loss: 19481.574219\n",
      "Train Epoch: 112 [149952/225000 (67%)] Loss: 19525.648438\n",
      "Train Epoch: 112 [152448/225000 (68%)] Loss: 19720.601562\n",
      "Train Epoch: 112 [154944/225000 (69%)] Loss: 19843.105469\n",
      "Train Epoch: 112 [157440/225000 (70%)] Loss: 19068.398438\n",
      "Train Epoch: 112 [159936/225000 (71%)] Loss: 19072.748047\n",
      "Train Epoch: 112 [162432/225000 (72%)] Loss: 19825.210938\n",
      "Train Epoch: 112 [164928/225000 (73%)] Loss: 19067.261719\n",
      "Train Epoch: 112 [167424/225000 (74%)] Loss: 19326.306641\n",
      "Train Epoch: 112 [169920/225000 (76%)] Loss: 19709.822266\n",
      "Train Epoch: 112 [172416/225000 (77%)] Loss: 19583.005859\n",
      "Train Epoch: 112 [174912/225000 (78%)] Loss: 19412.916016\n",
      "Train Epoch: 112 [177408/225000 (79%)] Loss: 19355.332031\n",
      "Train Epoch: 112 [179904/225000 (80%)] Loss: 19293.662109\n",
      "Train Epoch: 112 [182400/225000 (81%)] Loss: 19558.003906\n",
      "Train Epoch: 112 [184896/225000 (82%)] Loss: 18898.453125\n",
      "Train Epoch: 112 [187392/225000 (83%)] Loss: 19219.886719\n",
      "Train Epoch: 112 [189888/225000 (84%)] Loss: 19341.832031\n",
      "Train Epoch: 112 [192384/225000 (86%)] Loss: 19231.070312\n",
      "Train Epoch: 112 [194880/225000 (87%)] Loss: 19437.859375\n",
      "Train Epoch: 112 [197376/225000 (88%)] Loss: 19256.531250\n",
      "Train Epoch: 112 [199872/225000 (89%)] Loss: 19803.566406\n",
      "Train Epoch: 112 [202368/225000 (90%)] Loss: 18930.531250\n",
      "Train Epoch: 112 [204864/225000 (91%)] Loss: 19611.250000\n",
      "Train Epoch: 112 [207360/225000 (92%)] Loss: 19533.835938\n",
      "Train Epoch: 112 [209856/225000 (93%)] Loss: 19393.660156\n",
      "Train Epoch: 112 [212352/225000 (94%)] Loss: 19512.191406\n",
      "Train Epoch: 112 [214848/225000 (95%)] Loss: 19421.488281\n",
      "Train Epoch: 112 [217344/225000 (97%)] Loss: 19349.515625\n",
      "Train Epoch: 112 [219840/225000 (98%)] Loss: 19068.982422\n",
      "Train Epoch: 112 [222336/225000 (99%)] Loss: 19715.734375\n",
      "Train Epoch: 112 [224832/225000 (100%)] Loss: 19209.601562\n",
      "    epoch          : 112\n",
      "    loss           : 19418.512931953926\n",
      "    val_loss       : 19324.598220569485\n",
      "Train Epoch: 113 [192/225000 (0%)] Loss: 19052.988281\n",
      "Train Epoch: 113 [2688/225000 (1%)] Loss: 19134.365234\n",
      "Train Epoch: 113 [5184/225000 (2%)] Loss: 19758.806641\n",
      "Train Epoch: 113 [7680/225000 (3%)] Loss: 19485.724609\n",
      "Train Epoch: 113 [10176/225000 (5%)] Loss: 20138.205078\n",
      "Train Epoch: 113 [12672/225000 (6%)] Loss: 19164.820312\n",
      "Train Epoch: 113 [15168/225000 (7%)] Loss: 18824.851562\n",
      "Train Epoch: 113 [17664/225000 (8%)] Loss: 19179.609375\n",
      "Train Epoch: 113 [20160/225000 (9%)] Loss: 18998.101562\n",
      "Train Epoch: 113 [22656/225000 (10%)] Loss: 19936.207031\n",
      "Train Epoch: 113 [25152/225000 (11%)] Loss: 19759.777344\n",
      "Train Epoch: 113 [27648/225000 (12%)] Loss: 19405.187500\n",
      "Train Epoch: 113 [30144/225000 (13%)] Loss: 19441.658203\n",
      "Train Epoch: 113 [32640/225000 (15%)] Loss: 19640.726562\n",
      "Train Epoch: 113 [35136/225000 (16%)] Loss: 19816.625000\n",
      "Train Epoch: 113 [37632/225000 (17%)] Loss: 19529.953125\n",
      "Train Epoch: 113 [40128/225000 (18%)] Loss: 19822.042969\n",
      "Train Epoch: 113 [42624/225000 (19%)] Loss: 19638.257812\n",
      "Train Epoch: 113 [45120/225000 (20%)] Loss: 19329.136719\n",
      "Train Epoch: 113 [47616/225000 (21%)] Loss: 19118.292969\n",
      "Train Epoch: 113 [50112/225000 (22%)] Loss: 19685.691406\n",
      "Train Epoch: 113 [52608/225000 (23%)] Loss: 20289.382812\n",
      "Train Epoch: 113 [55104/225000 (24%)] Loss: 19527.250000\n",
      "Train Epoch: 113 [57600/225000 (26%)] Loss: 19399.156250\n",
      "Train Epoch: 113 [60096/225000 (27%)] Loss: 19338.914062\n",
      "Train Epoch: 113 [62592/225000 (28%)] Loss: 19559.775391\n",
      "Train Epoch: 113 [65088/225000 (29%)] Loss: 19437.230469\n",
      "Train Epoch: 113 [67584/225000 (30%)] Loss: 19256.085938\n",
      "Train Epoch: 113 [70080/225000 (31%)] Loss: 18931.630859\n",
      "Train Epoch: 113 [72576/225000 (32%)] Loss: 19432.875000\n",
      "Train Epoch: 113 [75072/225000 (33%)] Loss: 19729.093750\n",
      "Train Epoch: 113 [77568/225000 (34%)] Loss: 19930.238281\n",
      "Train Epoch: 113 [80064/225000 (36%)] Loss: 19505.492188\n",
      "Train Epoch: 113 [82560/225000 (37%)] Loss: 19406.912109\n",
      "Train Epoch: 113 [85056/225000 (38%)] Loss: 19470.041016\n",
      "Train Epoch: 113 [87552/225000 (39%)] Loss: 19557.544922\n",
      "Train Epoch: 113 [90048/225000 (40%)] Loss: 19387.164062\n",
      "Train Epoch: 113 [92544/225000 (41%)] Loss: 19406.818359\n",
      "Train Epoch: 113 [95040/225000 (42%)] Loss: 19942.617188\n",
      "Train Epoch: 113 [97536/225000 (43%)] Loss: 19015.208984\n",
      "Train Epoch: 113 [100032/225000 (44%)] Loss: 19871.671875\n",
      "Train Epoch: 113 [102528/225000 (46%)] Loss: 19544.914062\n",
      "Train Epoch: 113 [105024/225000 (47%)] Loss: 19281.394531\n",
      "Train Epoch: 113 [107520/225000 (48%)] Loss: 19325.666016\n",
      "Train Epoch: 113 [110016/225000 (49%)] Loss: 19332.429688\n",
      "Train Epoch: 113 [112512/225000 (50%)] Loss: 19196.814453\n",
      "Train Epoch: 113 [115008/225000 (51%)] Loss: 19728.171875\n",
      "Train Epoch: 113 [117504/225000 (52%)] Loss: 19139.769531\n",
      "Train Epoch: 113 [120000/225000 (53%)] Loss: 19570.195312\n",
      "Train Epoch: 113 [122496/225000 (54%)] Loss: 19734.503906\n",
      "Train Epoch: 113 [124992/225000 (56%)] Loss: 19049.625000\n",
      "Train Epoch: 113 [127488/225000 (57%)] Loss: 19698.480469\n",
      "Train Epoch: 113 [129984/225000 (58%)] Loss: 19156.417969\n",
      "Train Epoch: 113 [132480/225000 (59%)] Loss: 19569.187500\n",
      "Train Epoch: 113 [134976/225000 (60%)] Loss: 19379.037109\n",
      "Train Epoch: 113 [137472/225000 (61%)] Loss: 19660.580078\n",
      "Train Epoch: 113 [139968/225000 (62%)] Loss: 19375.037109\n",
      "Train Epoch: 113 [142464/225000 (63%)] Loss: 19646.013672\n",
      "Train Epoch: 113 [144960/225000 (64%)] Loss: 19530.960938\n",
      "Train Epoch: 113 [147456/225000 (66%)] Loss: 19476.031250\n",
      "Train Epoch: 113 [149952/225000 (67%)] Loss: 19126.394531\n",
      "Train Epoch: 113 [152448/225000 (68%)] Loss: 19133.933594\n",
      "Train Epoch: 113 [154944/225000 (69%)] Loss: 19574.996094\n",
      "Train Epoch: 113 [157440/225000 (70%)] Loss: 19042.089844\n",
      "Train Epoch: 113 [159936/225000 (71%)] Loss: 19375.988281\n",
      "Train Epoch: 113 [162432/225000 (72%)] Loss: 19749.029297\n",
      "Train Epoch: 113 [164928/225000 (73%)] Loss: 19767.150391\n",
      "Train Epoch: 113 [167424/225000 (74%)] Loss: 19715.468750\n",
      "Train Epoch: 113 [169920/225000 (76%)] Loss: 19541.996094\n",
      "Train Epoch: 113 [172416/225000 (77%)] Loss: 19616.912109\n",
      "Train Epoch: 113 [174912/225000 (78%)] Loss: 19413.048828\n",
      "Train Epoch: 113 [177408/225000 (79%)] Loss: 19334.218750\n",
      "Train Epoch: 113 [179904/225000 (80%)] Loss: 18965.037109\n",
      "Train Epoch: 113 [182400/225000 (81%)] Loss: 19209.011719\n",
      "Train Epoch: 113 [184896/225000 (82%)] Loss: 19462.136719\n",
      "Train Epoch: 113 [187392/225000 (83%)] Loss: 18759.835938\n",
      "Train Epoch: 113 [189888/225000 (84%)] Loss: 19449.363281\n",
      "Train Epoch: 113 [192384/225000 (86%)] Loss: 19678.796875\n",
      "Train Epoch: 113 [194880/225000 (87%)] Loss: 19502.339844\n",
      "Train Epoch: 113 [197376/225000 (88%)] Loss: 19676.662109\n",
      "Train Epoch: 113 [199872/225000 (89%)] Loss: 19529.183594\n",
      "Train Epoch: 113 [202368/225000 (90%)] Loss: 20219.109375\n",
      "Train Epoch: 113 [204864/225000 (91%)] Loss: 19528.742188\n",
      "Train Epoch: 113 [207360/225000 (92%)] Loss: 19218.511719\n",
      "Train Epoch: 113 [209856/225000 (93%)] Loss: 19026.613281\n",
      "Train Epoch: 113 [212352/225000 (94%)] Loss: 19463.312500\n",
      "Train Epoch: 113 [214848/225000 (95%)] Loss: 19515.203125\n",
      "Train Epoch: 113 [217344/225000 (97%)] Loss: 19659.902344\n",
      "Train Epoch: 113 [219840/225000 (98%)] Loss: 19446.480469\n",
      "Train Epoch: 113 [222336/225000 (99%)] Loss: 19137.648438\n",
      "Train Epoch: 113 [224832/225000 (100%)] Loss: 19429.859375\n",
      "    epoch          : 113\n",
      "    loss           : 19413.437425008\n",
      "    val_loss       : 19312.87087508422\n",
      "Train Epoch: 114 [192/225000 (0%)] Loss: 19652.320312\n",
      "Train Epoch: 114 [2688/225000 (1%)] Loss: 19629.031250\n",
      "Train Epoch: 114 [5184/225000 (2%)] Loss: 19493.199219\n",
      "Train Epoch: 114 [7680/225000 (3%)] Loss: 19332.742188\n",
      "Train Epoch: 114 [10176/225000 (5%)] Loss: 19254.667969\n",
      "Train Epoch: 114 [12672/225000 (6%)] Loss: 19085.919922\n",
      "Train Epoch: 114 [15168/225000 (7%)] Loss: 19690.125000\n",
      "Train Epoch: 114 [17664/225000 (8%)] Loss: 19707.378906\n",
      "Train Epoch: 114 [20160/225000 (9%)] Loss: 19014.320312\n",
      "Train Epoch: 114 [22656/225000 (10%)] Loss: 19246.863281\n",
      "Train Epoch: 114 [25152/225000 (11%)] Loss: 19378.310547\n",
      "Train Epoch: 114 [27648/225000 (12%)] Loss: 19321.722656\n",
      "Train Epoch: 114 [30144/225000 (13%)] Loss: 19584.728516\n",
      "Train Epoch: 114 [32640/225000 (15%)] Loss: 19552.681641\n",
      "Train Epoch: 114 [35136/225000 (16%)] Loss: 19620.203125\n",
      "Train Epoch: 114 [37632/225000 (17%)] Loss: 19672.837891\n",
      "Train Epoch: 114 [40128/225000 (18%)] Loss: 18985.214844\n",
      "Train Epoch: 114 [42624/225000 (19%)] Loss: 19424.125000\n",
      "Train Epoch: 114 [45120/225000 (20%)] Loss: 19215.789062\n",
      "Train Epoch: 114 [47616/225000 (21%)] Loss: 19224.064453\n",
      "Train Epoch: 114 [50112/225000 (22%)] Loss: 19692.871094\n",
      "Train Epoch: 114 [52608/225000 (23%)] Loss: 19358.263672\n",
      "Train Epoch: 114 [55104/225000 (24%)] Loss: 19094.375000\n",
      "Train Epoch: 114 [57600/225000 (26%)] Loss: 19604.597656\n",
      "Train Epoch: 114 [60096/225000 (27%)] Loss: 19142.632812\n",
      "Train Epoch: 114 [62592/225000 (28%)] Loss: 19184.320312\n",
      "Train Epoch: 114 [65088/225000 (29%)] Loss: 19262.755859\n",
      "Train Epoch: 114 [67584/225000 (30%)] Loss: 19630.023438\n",
      "Train Epoch: 114 [70080/225000 (31%)] Loss: 19311.425781\n",
      "Train Epoch: 114 [72576/225000 (32%)] Loss: 19345.904297\n",
      "Train Epoch: 114 [75072/225000 (33%)] Loss: 19740.675781\n",
      "Train Epoch: 114 [77568/225000 (34%)] Loss: 19457.585938\n",
      "Train Epoch: 114 [80064/225000 (36%)] Loss: 19127.654297\n",
      "Train Epoch: 114 [82560/225000 (37%)] Loss: 19678.142578\n",
      "Train Epoch: 114 [85056/225000 (38%)] Loss: 19599.812500\n",
      "Train Epoch: 114 [87552/225000 (39%)] Loss: 19621.882812\n",
      "Train Epoch: 114 [90048/225000 (40%)] Loss: 19240.632812\n",
      "Train Epoch: 114 [92544/225000 (41%)] Loss: 19196.175781\n",
      "Train Epoch: 114 [95040/225000 (42%)] Loss: 19739.693359\n",
      "Train Epoch: 114 [97536/225000 (43%)] Loss: 19695.033203\n",
      "Train Epoch: 114 [100032/225000 (44%)] Loss: 19653.767578\n",
      "Train Epoch: 114 [102528/225000 (46%)] Loss: 19437.968750\n",
      "Train Epoch: 114 [105024/225000 (47%)] Loss: 19366.031250\n",
      "Train Epoch: 114 [107520/225000 (48%)] Loss: 19819.142578\n",
      "Train Epoch: 114 [110016/225000 (49%)] Loss: 19596.691406\n",
      "Train Epoch: 114 [112512/225000 (50%)] Loss: 19123.187500\n",
      "Train Epoch: 114 [115008/225000 (51%)] Loss: 19856.742188\n",
      "Train Epoch: 114 [117504/225000 (52%)] Loss: 19219.908203\n",
      "Train Epoch: 114 [120000/225000 (53%)] Loss: 19777.675781\n",
      "Train Epoch: 114 [122496/225000 (54%)] Loss: 19853.105469\n",
      "Train Epoch: 114 [124992/225000 (56%)] Loss: 19502.433594\n",
      "Train Epoch: 114 [127488/225000 (57%)] Loss: 19423.501953\n",
      "Train Epoch: 114 [129984/225000 (58%)] Loss: 19304.111328\n",
      "Train Epoch: 114 [132480/225000 (59%)] Loss: 19141.666016\n",
      "Train Epoch: 114 [134976/225000 (60%)] Loss: 19415.480469\n",
      "Train Epoch: 114 [137472/225000 (61%)] Loss: 18764.109375\n",
      "Train Epoch: 114 [139968/225000 (62%)] Loss: 19107.162109\n",
      "Train Epoch: 114 [142464/225000 (63%)] Loss: 19353.593750\n",
      "Train Epoch: 114 [144960/225000 (64%)] Loss: 19725.523438\n",
      "Train Epoch: 114 [147456/225000 (66%)] Loss: 19431.496094\n",
      "Train Epoch: 114 [149952/225000 (67%)] Loss: 19405.234375\n",
      "Train Epoch: 114 [152448/225000 (68%)] Loss: 19351.910156\n",
      "Train Epoch: 114 [154944/225000 (69%)] Loss: 19312.664062\n",
      "Train Epoch: 114 [157440/225000 (70%)] Loss: 19163.347656\n",
      "Train Epoch: 114 [159936/225000 (71%)] Loss: 19450.355469\n",
      "Train Epoch: 114 [162432/225000 (72%)] Loss: 19229.242188\n",
      "Train Epoch: 114 [164928/225000 (73%)] Loss: 19651.289062\n",
      "Train Epoch: 114 [167424/225000 (74%)] Loss: 19390.347656\n",
      "Train Epoch: 114 [169920/225000 (76%)] Loss: 19447.041016\n",
      "Train Epoch: 114 [172416/225000 (77%)] Loss: 19121.417969\n",
      "Train Epoch: 114 [174912/225000 (78%)] Loss: 19837.619141\n",
      "Train Epoch: 114 [177408/225000 (79%)] Loss: 19859.308594\n",
      "Train Epoch: 114 [179904/225000 (80%)] Loss: 20057.751953\n",
      "Train Epoch: 114 [182400/225000 (81%)] Loss: 19405.673828\n",
      "Train Epoch: 114 [184896/225000 (82%)] Loss: 19071.367188\n",
      "Train Epoch: 114 [187392/225000 (83%)] Loss: 18925.414062\n",
      "Train Epoch: 114 [189888/225000 (84%)] Loss: 19461.554688\n",
      "Train Epoch: 114 [192384/225000 (86%)] Loss: 19770.265625\n",
      "Train Epoch: 114 [194880/225000 (87%)] Loss: 19460.843750\n",
      "Train Epoch: 114 [197376/225000 (88%)] Loss: 19491.898438\n",
      "Train Epoch: 114 [199872/225000 (89%)] Loss: 19140.078125\n",
      "Train Epoch: 114 [202368/225000 (90%)] Loss: 19598.865234\n",
      "Train Epoch: 114 [204864/225000 (91%)] Loss: 19384.480469\n",
      "Train Epoch: 114 [207360/225000 (92%)] Loss: 19162.277344\n",
      "Train Epoch: 114 [209856/225000 (93%)] Loss: 19209.722656\n",
      "Train Epoch: 114 [212352/225000 (94%)] Loss: 19265.042969\n",
      "Train Epoch: 114 [214848/225000 (95%)] Loss: 19689.433594\n",
      "Train Epoch: 114 [217344/225000 (97%)] Loss: 19476.728516\n",
      "Train Epoch: 114 [219840/225000 (98%)] Loss: 20092.943359\n",
      "Train Epoch: 114 [222336/225000 (99%)] Loss: 19979.679688\n",
      "Train Epoch: 114 [224832/225000 (100%)] Loss: 19556.744141\n",
      "    epoch          : 114\n",
      "    loss           : 19400.845906436647\n",
      "    val_loss       : 19327.155789707453\n",
      "Train Epoch: 115 [192/225000 (0%)] Loss: 19688.351562\n",
      "Train Epoch: 115 [2688/225000 (1%)] Loss: 19599.117188\n",
      "Train Epoch: 115 [5184/225000 (2%)] Loss: 19495.042969\n",
      "Train Epoch: 115 [7680/225000 (3%)] Loss: 19749.185547\n",
      "Train Epoch: 115 [10176/225000 (5%)] Loss: 19421.101562\n",
      "Train Epoch: 115 [12672/225000 (6%)] Loss: 19210.949219\n",
      "Train Epoch: 115 [15168/225000 (7%)] Loss: 19037.181641\n",
      "Train Epoch: 115 [17664/225000 (8%)] Loss: 19120.832031\n",
      "Train Epoch: 115 [20160/225000 (9%)] Loss: 19388.957031\n",
      "Train Epoch: 115 [22656/225000 (10%)] Loss: 19537.417969\n",
      "Train Epoch: 115 [25152/225000 (11%)] Loss: 19311.375000\n",
      "Train Epoch: 115 [27648/225000 (12%)] Loss: 19437.605469\n",
      "Train Epoch: 115 [30144/225000 (13%)] Loss: 19724.867188\n",
      "Train Epoch: 115 [32640/225000 (15%)] Loss: 19144.621094\n",
      "Train Epoch: 115 [35136/225000 (16%)] Loss: 19262.562500\n",
      "Train Epoch: 115 [37632/225000 (17%)] Loss: 19796.125000\n",
      "Train Epoch: 115 [40128/225000 (18%)] Loss: 18950.125000\n",
      "Train Epoch: 115 [42624/225000 (19%)] Loss: 19398.541016\n",
      "Train Epoch: 115 [45120/225000 (20%)] Loss: 19539.300781\n",
      "Train Epoch: 115 [47616/225000 (21%)] Loss: 19243.099609\n",
      "Train Epoch: 115 [50112/225000 (22%)] Loss: 19290.121094\n",
      "Train Epoch: 115 [52608/225000 (23%)] Loss: 19445.292969\n",
      "Train Epoch: 115 [55104/225000 (24%)] Loss: 19984.984375\n",
      "Train Epoch: 115 [57600/225000 (26%)] Loss: 19744.912109\n",
      "Train Epoch: 115 [60096/225000 (27%)] Loss: 19294.357422\n",
      "Train Epoch: 115 [62592/225000 (28%)] Loss: 19575.656250\n",
      "Train Epoch: 115 [65088/225000 (29%)] Loss: 19522.367188\n",
      "Train Epoch: 115 [67584/225000 (30%)] Loss: 19786.566406\n",
      "Train Epoch: 115 [70080/225000 (31%)] Loss: 19735.152344\n",
      "Train Epoch: 115 [72576/225000 (32%)] Loss: 19155.509766\n",
      "Train Epoch: 115 [75072/225000 (33%)] Loss: 19719.941406\n",
      "Train Epoch: 115 [77568/225000 (34%)] Loss: 20095.097656\n",
      "Train Epoch: 115 [80064/225000 (36%)] Loss: 19329.937500\n",
      "Train Epoch: 115 [82560/225000 (37%)] Loss: 19508.871094\n",
      "Train Epoch: 115 [85056/225000 (38%)] Loss: 19162.488281\n",
      "Train Epoch: 115 [87552/225000 (39%)] Loss: 19136.199219\n",
      "Train Epoch: 115 [90048/225000 (40%)] Loss: 19318.425781\n",
      "Train Epoch: 115 [92544/225000 (41%)] Loss: 19333.806641\n",
      "Train Epoch: 115 [95040/225000 (42%)] Loss: 19418.941406\n",
      "Train Epoch: 115 [97536/225000 (43%)] Loss: 19512.380859\n",
      "Train Epoch: 115 [100032/225000 (44%)] Loss: 19751.019531\n",
      "Train Epoch: 115 [102528/225000 (46%)] Loss: 19318.261719\n",
      "Train Epoch: 115 [105024/225000 (47%)] Loss: 18833.585938\n",
      "Train Epoch: 115 [107520/225000 (48%)] Loss: 19452.742188\n",
      "Train Epoch: 115 [110016/225000 (49%)] Loss: 19036.259766\n",
      "Train Epoch: 115 [112512/225000 (50%)] Loss: 19324.894531\n",
      "Train Epoch: 115 [115008/225000 (51%)] Loss: 19634.585938\n",
      "Train Epoch: 115 [117504/225000 (52%)] Loss: 19299.572266\n",
      "Train Epoch: 115 [120000/225000 (53%)] Loss: 19392.367188\n",
      "Train Epoch: 115 [122496/225000 (54%)] Loss: 19468.158203\n",
      "Train Epoch: 115 [124992/225000 (56%)] Loss: 19478.000000\n",
      "Train Epoch: 115 [127488/225000 (57%)] Loss: 19152.794922\n",
      "Train Epoch: 115 [129984/225000 (58%)] Loss: 19292.734375\n",
      "Train Epoch: 115 [132480/225000 (59%)] Loss: 19515.150391\n",
      "Train Epoch: 115 [134976/225000 (60%)] Loss: 19112.765625\n",
      "Train Epoch: 115 [137472/225000 (61%)] Loss: 19335.158203\n",
      "Train Epoch: 115 [139968/225000 (62%)] Loss: 19191.640625\n",
      "Train Epoch: 115 [142464/225000 (63%)] Loss: 19422.576172\n",
      "Train Epoch: 115 [144960/225000 (64%)] Loss: 18946.675781\n",
      "Train Epoch: 115 [147456/225000 (66%)] Loss: 19448.519531\n",
      "Train Epoch: 115 [149952/225000 (67%)] Loss: 19116.921875\n",
      "Train Epoch: 115 [152448/225000 (68%)] Loss: 19413.843750\n",
      "Train Epoch: 115 [154944/225000 (69%)] Loss: 19265.058594\n",
      "Train Epoch: 115 [157440/225000 (70%)] Loss: 19306.335938\n",
      "Train Epoch: 115 [159936/225000 (71%)] Loss: 19450.318359\n",
      "Train Epoch: 115 [162432/225000 (72%)] Loss: 19655.166016\n",
      "Train Epoch: 115 [164928/225000 (73%)] Loss: 19463.765625\n",
      "Train Epoch: 115 [167424/225000 (74%)] Loss: 19353.148438\n",
      "Train Epoch: 115 [169920/225000 (76%)] Loss: 19011.578125\n",
      "Train Epoch: 115 [172416/225000 (77%)] Loss: 19044.865234\n",
      "Train Epoch: 115 [174912/225000 (78%)] Loss: 19679.750000\n",
      "Train Epoch: 115 [177408/225000 (79%)] Loss: 19455.433594\n",
      "Train Epoch: 115 [179904/225000 (80%)] Loss: 19494.156250\n",
      "Train Epoch: 115 [182400/225000 (81%)] Loss: 19863.007812\n",
      "Train Epoch: 115 [184896/225000 (82%)] Loss: 19147.941406\n",
      "Train Epoch: 115 [187392/225000 (83%)] Loss: 19235.640625\n",
      "Train Epoch: 115 [189888/225000 (84%)] Loss: 19171.875000\n",
      "Train Epoch: 115 [192384/225000 (86%)] Loss: 19639.814453\n",
      "Train Epoch: 115 [194880/225000 (87%)] Loss: 19660.382812\n",
      "Train Epoch: 115 [197376/225000 (88%)] Loss: 19283.144531\n",
      "Train Epoch: 115 [199872/225000 (89%)] Loss: 19424.701172\n",
      "Train Epoch: 115 [202368/225000 (90%)] Loss: 19634.814453\n",
      "Train Epoch: 115 [204864/225000 (91%)] Loss: 19497.414062\n",
      "Train Epoch: 115 [207360/225000 (92%)] Loss: 19372.410156\n",
      "Train Epoch: 115 [209856/225000 (93%)] Loss: 20013.378906\n",
      "Train Epoch: 115 [212352/225000 (94%)] Loss: 19258.054688\n",
      "Train Epoch: 115 [214848/225000 (95%)] Loss: 19592.335938\n",
      "Train Epoch: 115 [217344/225000 (97%)] Loss: 19418.644531\n",
      "Train Epoch: 115 [219840/225000 (98%)] Loss: 19646.097656\n",
      "Train Epoch: 115 [222336/225000 (99%)] Loss: 19471.716797\n",
      "Train Epoch: 115 [224832/225000 (100%)] Loss: 19630.572266\n",
      "    epoch          : 115\n",
      "    loss           : 19401.324333737735\n",
      "    val_loss       : 19297.36298399754\n",
      "Train Epoch: 116 [192/225000 (0%)] Loss: 19491.269531\n",
      "Train Epoch: 116 [2688/225000 (1%)] Loss: 19574.693359\n",
      "Train Epoch: 116 [5184/225000 (2%)] Loss: 20091.433594\n",
      "Train Epoch: 116 [7680/225000 (3%)] Loss: 19542.796875\n",
      "Train Epoch: 116 [10176/225000 (5%)] Loss: 19238.056641\n",
      "Train Epoch: 116 [12672/225000 (6%)] Loss: 19799.396484\n",
      "Train Epoch: 116 [15168/225000 (7%)] Loss: 19307.324219\n",
      "Train Epoch: 116 [17664/225000 (8%)] Loss: 19024.523438\n",
      "Train Epoch: 116 [20160/225000 (9%)] Loss: 19524.599609\n",
      "Train Epoch: 116 [22656/225000 (10%)] Loss: 19385.111328\n",
      "Train Epoch: 116 [25152/225000 (11%)] Loss: 20088.824219\n",
      "Train Epoch: 116 [27648/225000 (12%)] Loss: 20100.298828\n",
      "Train Epoch: 116 [30144/225000 (13%)] Loss: 19611.937500\n",
      "Train Epoch: 116 [32640/225000 (15%)] Loss: 19617.082031\n",
      "Train Epoch: 116 [35136/225000 (16%)] Loss: 19624.328125\n",
      "Train Epoch: 116 [37632/225000 (17%)] Loss: 19385.714844\n",
      "Train Epoch: 116 [40128/225000 (18%)] Loss: 18970.289062\n",
      "Train Epoch: 116 [42624/225000 (19%)] Loss: 19437.326172\n",
      "Train Epoch: 116 [45120/225000 (20%)] Loss: 19202.382812\n",
      "Train Epoch: 116 [47616/225000 (21%)] Loss: 19234.429688\n",
      "Train Epoch: 116 [50112/225000 (22%)] Loss: 19242.050781\n",
      "Train Epoch: 116 [52608/225000 (23%)] Loss: 19287.337891\n",
      "Train Epoch: 116 [55104/225000 (24%)] Loss: 19437.134766\n",
      "Train Epoch: 116 [57600/225000 (26%)] Loss: 19256.556641\n",
      "Train Epoch: 116 [60096/225000 (27%)] Loss: 19862.148438\n",
      "Train Epoch: 116 [62592/225000 (28%)] Loss: 19333.744141\n",
      "Train Epoch: 116 [65088/225000 (29%)] Loss: 19239.984375\n",
      "Train Epoch: 116 [67584/225000 (30%)] Loss: 19688.748047\n",
      "Train Epoch: 116 [70080/225000 (31%)] Loss: 19410.525391\n",
      "Train Epoch: 116 [72576/225000 (32%)] Loss: 19694.701172\n",
      "Train Epoch: 116 [75072/225000 (33%)] Loss: 19545.306641\n",
      "Train Epoch: 116 [77568/225000 (34%)] Loss: 19448.291016\n",
      "Train Epoch: 116 [80064/225000 (36%)] Loss: 19118.449219\n",
      "Train Epoch: 116 [82560/225000 (37%)] Loss: 19534.578125\n",
      "Train Epoch: 116 [85056/225000 (38%)] Loss: 19698.324219\n",
      "Train Epoch: 116 [87552/225000 (39%)] Loss: 19413.232422\n",
      "Train Epoch: 116 [90048/225000 (40%)] Loss: 19058.941406\n",
      "Train Epoch: 116 [92544/225000 (41%)] Loss: 19258.880859\n",
      "Train Epoch: 116 [95040/225000 (42%)] Loss: 19758.152344\n",
      "Train Epoch: 116 [97536/225000 (43%)] Loss: 19074.511719\n",
      "Train Epoch: 116 [100032/225000 (44%)] Loss: 19364.753906\n",
      "Train Epoch: 116 [102528/225000 (46%)] Loss: 19496.214844\n",
      "Train Epoch: 116 [105024/225000 (47%)] Loss: 19640.878906\n",
      "Train Epoch: 116 [107520/225000 (48%)] Loss: 19514.894531\n",
      "Train Epoch: 116 [110016/225000 (49%)] Loss: 19631.855469\n",
      "Train Epoch: 116 [112512/225000 (50%)] Loss: 19859.351562\n",
      "Train Epoch: 116 [115008/225000 (51%)] Loss: 19607.859375\n",
      "Train Epoch: 116 [117504/225000 (52%)] Loss: 19438.570312\n",
      "Train Epoch: 116 [120000/225000 (53%)] Loss: 19267.531250\n",
      "Train Epoch: 116 [122496/225000 (54%)] Loss: 19330.839844\n",
      "Train Epoch: 116 [124992/225000 (56%)] Loss: 19502.562500\n",
      "Train Epoch: 116 [127488/225000 (57%)] Loss: 19202.605469\n",
      "Train Epoch: 116 [129984/225000 (58%)] Loss: 19362.859375\n",
      "Train Epoch: 116 [132480/225000 (59%)] Loss: 19533.808594\n",
      "Train Epoch: 116 [134976/225000 (60%)] Loss: 19399.816406\n",
      "Train Epoch: 116 [137472/225000 (61%)] Loss: 19517.406250\n",
      "Train Epoch: 116 [139968/225000 (62%)] Loss: 19473.941406\n",
      "Train Epoch: 116 [142464/225000 (63%)] Loss: 19244.320312\n",
      "Train Epoch: 116 [144960/225000 (64%)] Loss: 19622.380859\n",
      "Train Epoch: 116 [147456/225000 (66%)] Loss: 19608.242188\n",
      "Train Epoch: 116 [149952/225000 (67%)] Loss: 18961.943359\n",
      "Train Epoch: 116 [152448/225000 (68%)] Loss: 19682.625000\n",
      "Train Epoch: 116 [154944/225000 (69%)] Loss: 19661.535156\n",
      "Train Epoch: 116 [157440/225000 (70%)] Loss: 19502.056641\n",
      "Train Epoch: 116 [159936/225000 (71%)] Loss: 19538.652344\n",
      "Train Epoch: 116 [162432/225000 (72%)] Loss: 19553.546875\n",
      "Train Epoch: 116 [164928/225000 (73%)] Loss: 19653.695312\n",
      "Train Epoch: 116 [167424/225000 (74%)] Loss: 18853.769531\n",
      "Train Epoch: 116 [169920/225000 (76%)] Loss: 19143.691406\n",
      "Train Epoch: 116 [172416/225000 (77%)] Loss: 19417.757812\n",
      "Train Epoch: 116 [174912/225000 (78%)] Loss: 20230.750000\n",
      "Train Epoch: 116 [177408/225000 (79%)] Loss: 19589.718750\n",
      "Train Epoch: 116 [179904/225000 (80%)] Loss: 19879.804688\n",
      "Train Epoch: 116 [182400/225000 (81%)] Loss: 19526.925781\n",
      "Train Epoch: 116 [184896/225000 (82%)] Loss: 19397.820312\n",
      "Train Epoch: 116 [187392/225000 (83%)] Loss: 19516.468750\n",
      "Train Epoch: 116 [189888/225000 (84%)] Loss: 19928.835938\n",
      "Train Epoch: 116 [192384/225000 (86%)] Loss: 19781.207031\n",
      "Train Epoch: 116 [194880/225000 (87%)] Loss: 19386.728516\n",
      "Train Epoch: 116 [197376/225000 (88%)] Loss: 19523.105469\n",
      "Train Epoch: 116 [199872/225000 (89%)] Loss: 18825.437500\n",
      "Train Epoch: 116 [202368/225000 (90%)] Loss: 19546.878906\n",
      "Train Epoch: 116 [204864/225000 (91%)] Loss: 19721.029297\n",
      "Train Epoch: 116 [207360/225000 (92%)] Loss: 19627.130859\n",
      "Train Epoch: 116 [209856/225000 (93%)] Loss: 18954.886719\n",
      "Train Epoch: 116 [212352/225000 (94%)] Loss: 19343.726562\n",
      "Train Epoch: 116 [214848/225000 (95%)] Loss: 19419.656250\n",
      "Train Epoch: 116 [217344/225000 (97%)] Loss: 18991.812500\n",
      "Train Epoch: 116 [219840/225000 (98%)] Loss: 19815.929688\n",
      "Train Epoch: 116 [222336/225000 (99%)] Loss: 19578.109375\n",
      "Train Epoch: 116 [224832/225000 (100%)] Loss: 19803.593750\n",
      "    epoch          : 116\n",
      "    loss           : 19397.29751326525\n",
      "    val_loss       : 19317.278138480113\n",
      "Train Epoch: 117 [192/225000 (0%)] Loss: 19666.419922\n",
      "Train Epoch: 117 [2688/225000 (1%)] Loss: 19500.843750\n",
      "Train Epoch: 117 [5184/225000 (2%)] Loss: 19663.796875\n",
      "Train Epoch: 117 [7680/225000 (3%)] Loss: 19372.416016\n",
      "Train Epoch: 117 [10176/225000 (5%)] Loss: 19417.693359\n",
      "Train Epoch: 117 [12672/225000 (6%)] Loss: 19166.849609\n",
      "Train Epoch: 117 [15168/225000 (7%)] Loss: 19204.283203\n",
      "Train Epoch: 117 [17664/225000 (8%)] Loss: 19410.394531\n",
      "Train Epoch: 117 [20160/225000 (9%)] Loss: 19399.191406\n",
      "Train Epoch: 117 [22656/225000 (10%)] Loss: 19185.228516\n",
      "Train Epoch: 117 [25152/225000 (11%)] Loss: 18914.648438\n",
      "Train Epoch: 117 [27648/225000 (12%)] Loss: 19525.328125\n",
      "Train Epoch: 117 [30144/225000 (13%)] Loss: 19261.111328\n",
      "Train Epoch: 117 [32640/225000 (15%)] Loss: 18667.058594\n",
      "Train Epoch: 117 [35136/225000 (16%)] Loss: 19306.886719\n",
      "Train Epoch: 117 [37632/225000 (17%)] Loss: 19339.980469\n",
      "Train Epoch: 117 [40128/225000 (18%)] Loss: 19672.519531\n",
      "Train Epoch: 117 [42624/225000 (19%)] Loss: 19561.449219\n",
      "Train Epoch: 117 [45120/225000 (20%)] Loss: 19383.152344\n",
      "Train Epoch: 117 [47616/225000 (21%)] Loss: 19674.519531\n",
      "Train Epoch: 117 [50112/225000 (22%)] Loss: 19521.394531\n",
      "Train Epoch: 117 [52608/225000 (23%)] Loss: 19042.072266\n",
      "Train Epoch: 117 [55104/225000 (24%)] Loss: 19646.816406\n",
      "Train Epoch: 117 [57600/225000 (26%)] Loss: 19482.953125\n",
      "Train Epoch: 117 [60096/225000 (27%)] Loss: 19760.976562\n",
      "Train Epoch: 117 [62592/225000 (28%)] Loss: 19358.082031\n",
      "Train Epoch: 117 [65088/225000 (29%)] Loss: 19357.113281\n",
      "Train Epoch: 117 [67584/225000 (30%)] Loss: 19417.755859\n",
      "Train Epoch: 117 [70080/225000 (31%)] Loss: 19571.273438\n",
      "Train Epoch: 117 [72576/225000 (32%)] Loss: 19828.203125\n",
      "Train Epoch: 117 [75072/225000 (33%)] Loss: 18935.542969\n",
      "Train Epoch: 117 [77568/225000 (34%)] Loss: 19591.316406\n",
      "Train Epoch: 117 [80064/225000 (36%)] Loss: 19284.667969\n",
      "Train Epoch: 117 [82560/225000 (37%)] Loss: 19516.587891\n",
      "Train Epoch: 117 [85056/225000 (38%)] Loss: 18955.416016\n",
      "Train Epoch: 117 [87552/225000 (39%)] Loss: 19376.863281\n",
      "Train Epoch: 117 [90048/225000 (40%)] Loss: 19321.058594\n",
      "Train Epoch: 117 [92544/225000 (41%)] Loss: 18897.498047\n",
      "Train Epoch: 117 [95040/225000 (42%)] Loss: 19294.101562\n",
      "Train Epoch: 117 [97536/225000 (43%)] Loss: 19535.703125\n",
      "Train Epoch: 117 [100032/225000 (44%)] Loss: 19647.789062\n",
      "Train Epoch: 117 [102528/225000 (46%)] Loss: 19176.689453\n",
      "Train Epoch: 117 [105024/225000 (47%)] Loss: 19162.992188\n",
      "Train Epoch: 117 [107520/225000 (48%)] Loss: 19504.785156\n",
      "Train Epoch: 117 [110016/225000 (49%)] Loss: 19717.355469\n",
      "Train Epoch: 117 [112512/225000 (50%)] Loss: 19247.019531\n",
      "Train Epoch: 117 [115008/225000 (51%)] Loss: 19744.566406\n",
      "Train Epoch: 117 [117504/225000 (52%)] Loss: 19135.332031\n",
      "Train Epoch: 117 [120000/225000 (53%)] Loss: 18898.466797\n",
      "Train Epoch: 117 [122496/225000 (54%)] Loss: 19451.781250\n",
      "Train Epoch: 117 [124992/225000 (56%)] Loss: 19357.683594\n",
      "Train Epoch: 117 [127488/225000 (57%)] Loss: 18664.333984\n",
      "Train Epoch: 117 [129984/225000 (58%)] Loss: 19346.308594\n",
      "Train Epoch: 117 [132480/225000 (59%)] Loss: 19054.238281\n",
      "Train Epoch: 117 [134976/225000 (60%)] Loss: 19852.328125\n",
      "Train Epoch: 117 [137472/225000 (61%)] Loss: 19286.542969\n",
      "Train Epoch: 117 [139968/225000 (62%)] Loss: 19365.751953\n",
      "Train Epoch: 117 [142464/225000 (63%)] Loss: 19548.117188\n",
      "Train Epoch: 117 [144960/225000 (64%)] Loss: 19204.035156\n",
      "Train Epoch: 117 [147456/225000 (66%)] Loss: 19154.500000\n",
      "Train Epoch: 117 [149952/225000 (67%)] Loss: 19380.240234\n",
      "Train Epoch: 117 [152448/225000 (68%)] Loss: 19710.753906\n",
      "Train Epoch: 117 [154944/225000 (69%)] Loss: 19092.107422\n",
      "Train Epoch: 117 [157440/225000 (70%)] Loss: 19474.269531\n",
      "Train Epoch: 117 [159936/225000 (71%)] Loss: 18888.457031\n",
      "Train Epoch: 117 [162432/225000 (72%)] Loss: 19161.675781\n",
      "Train Epoch: 117 [164928/225000 (73%)] Loss: 19342.777344\n",
      "Train Epoch: 117 [167424/225000 (74%)] Loss: 19627.083984\n",
      "Train Epoch: 117 [169920/225000 (76%)] Loss: 19731.691406\n",
      "Train Epoch: 117 [172416/225000 (77%)] Loss: 19481.972656\n",
      "Train Epoch: 117 [174912/225000 (78%)] Loss: 19555.035156\n",
      "Train Epoch: 117 [177408/225000 (79%)] Loss: 19151.656250\n",
      "Train Epoch: 117 [179904/225000 (80%)] Loss: 18983.609375\n",
      "Train Epoch: 117 [182400/225000 (81%)] Loss: 19603.406250\n",
      "Train Epoch: 117 [184896/225000 (82%)] Loss: 18967.470703\n",
      "Train Epoch: 117 [187392/225000 (83%)] Loss: 19081.826172\n",
      "Train Epoch: 117 [189888/225000 (84%)] Loss: 19618.113281\n",
      "Train Epoch: 117 [192384/225000 (86%)] Loss: 19032.529297\n",
      "Train Epoch: 117 [194880/225000 (87%)] Loss: 19843.964844\n",
      "Train Epoch: 117 [197376/225000 (88%)] Loss: 19572.574219\n",
      "Train Epoch: 117 [199872/225000 (89%)] Loss: 19169.587891\n",
      "Train Epoch: 117 [202368/225000 (90%)] Loss: 18895.671875\n",
      "Train Epoch: 117 [204864/225000 (91%)] Loss: 19570.541016\n",
      "Train Epoch: 117 [207360/225000 (92%)] Loss: 19604.371094\n",
      "Train Epoch: 117 [209856/225000 (93%)] Loss: 19549.482422\n",
      "Train Epoch: 117 [212352/225000 (94%)] Loss: 19106.445312\n",
      "Train Epoch: 117 [214848/225000 (95%)] Loss: 19386.531250\n",
      "Train Epoch: 117 [217344/225000 (97%)] Loss: 19638.199219\n",
      "Train Epoch: 117 [219840/225000 (98%)] Loss: 19594.460938\n",
      "Train Epoch: 117 [222336/225000 (99%)] Loss: 19712.546875\n",
      "Train Epoch: 117 [224832/225000 (100%)] Loss: 19031.312500\n",
      "    epoch          : 117\n",
      "    loss           : 19398.944204284875\n",
      "    val_loss       : 19339.678817823642\n",
      "Train Epoch: 118 [192/225000 (0%)] Loss: 19585.505859\n",
      "Train Epoch: 118 [2688/225000 (1%)] Loss: 18985.919922\n",
      "Train Epoch: 118 [5184/225000 (2%)] Loss: 19123.816406\n",
      "Train Epoch: 118 [7680/225000 (3%)] Loss: 19363.882812\n",
      "Train Epoch: 118 [10176/225000 (5%)] Loss: 19207.537109\n",
      "Train Epoch: 118 [12672/225000 (6%)] Loss: 18893.468750\n",
      "Train Epoch: 118 [15168/225000 (7%)] Loss: 19300.867188\n",
      "Train Epoch: 118 [17664/225000 (8%)] Loss: 19832.294922\n",
      "Train Epoch: 118 [20160/225000 (9%)] Loss: 19673.095703\n",
      "Train Epoch: 118 [22656/225000 (10%)] Loss: 19555.507812\n",
      "Train Epoch: 118 [25152/225000 (11%)] Loss: 19746.507812\n",
      "Train Epoch: 118 [27648/225000 (12%)] Loss: 19225.644531\n",
      "Train Epoch: 118 [30144/225000 (13%)] Loss: 19581.875000\n",
      "Train Epoch: 118 [32640/225000 (15%)] Loss: 19415.238281\n",
      "Train Epoch: 118 [35136/225000 (16%)] Loss: 19316.181641\n",
      "Train Epoch: 118 [37632/225000 (17%)] Loss: 19520.031250\n",
      "Train Epoch: 118 [40128/225000 (18%)] Loss: 18913.296875\n",
      "Train Epoch: 118 [42624/225000 (19%)] Loss: 19609.074219\n",
      "Train Epoch: 118 [45120/225000 (20%)] Loss: 19157.468750\n",
      "Train Epoch: 118 [47616/225000 (21%)] Loss: 19229.691406\n",
      "Train Epoch: 118 [50112/225000 (22%)] Loss: 19129.863281\n",
      "Train Epoch: 118 [52608/225000 (23%)] Loss: 18996.533203\n",
      "Train Epoch: 118 [55104/225000 (24%)] Loss: 19605.750000\n",
      "Train Epoch: 118 [57600/225000 (26%)] Loss: 19591.207031\n",
      "Train Epoch: 118 [60096/225000 (27%)] Loss: 19538.941406\n",
      "Train Epoch: 118 [62592/225000 (28%)] Loss: 19685.335938\n",
      "Train Epoch: 118 [65088/225000 (29%)] Loss: 19524.800781\n",
      "Train Epoch: 118 [67584/225000 (30%)] Loss: 19008.617188\n",
      "Train Epoch: 118 [70080/225000 (31%)] Loss: 19747.544922\n",
      "Train Epoch: 118 [72576/225000 (32%)] Loss: 19219.248047\n",
      "Train Epoch: 118 [75072/225000 (33%)] Loss: 18960.175781\n",
      "Train Epoch: 118 [77568/225000 (34%)] Loss: 19673.371094\n",
      "Train Epoch: 118 [80064/225000 (36%)] Loss: 19782.781250\n",
      "Train Epoch: 118 [82560/225000 (37%)] Loss: 19715.218750\n",
      "Train Epoch: 118 [85056/225000 (38%)] Loss: 19395.578125\n",
      "Train Epoch: 118 [87552/225000 (39%)] Loss: 19389.675781\n",
      "Train Epoch: 118 [90048/225000 (40%)] Loss: 19261.449219\n",
      "Train Epoch: 118 [92544/225000 (41%)] Loss: 19643.056641\n",
      "Train Epoch: 118 [95040/225000 (42%)] Loss: 19282.949219\n",
      "Train Epoch: 118 [97536/225000 (43%)] Loss: 19379.960938\n",
      "Train Epoch: 118 [100032/225000 (44%)] Loss: 19075.373047\n",
      "Train Epoch: 118 [102528/225000 (46%)] Loss: 19704.515625\n",
      "Train Epoch: 118 [105024/225000 (47%)] Loss: 19019.150391\n",
      "Train Epoch: 118 [107520/225000 (48%)] Loss: 19473.345703\n",
      "Train Epoch: 118 [110016/225000 (49%)] Loss: 19334.964844\n",
      "Train Epoch: 118 [112512/225000 (50%)] Loss: 19118.238281\n",
      "Train Epoch: 118 [115008/225000 (51%)] Loss: 19461.140625\n",
      "Train Epoch: 118 [117504/225000 (52%)] Loss: 19035.480469\n",
      "Train Epoch: 118 [120000/225000 (53%)] Loss: 19755.880859\n",
      "Train Epoch: 118 [122496/225000 (54%)] Loss: 19350.775391\n",
      "Train Epoch: 118 [124992/225000 (56%)] Loss: 19359.894531\n",
      "Train Epoch: 118 [127488/225000 (57%)] Loss: 19233.576172\n",
      "Train Epoch: 118 [129984/225000 (58%)] Loss: 19537.072266\n",
      "Train Epoch: 118 [132480/225000 (59%)] Loss: 19289.210938\n",
      "Train Epoch: 118 [134976/225000 (60%)] Loss: 18753.066406\n",
      "Train Epoch: 118 [137472/225000 (61%)] Loss: 19706.382812\n",
      "Train Epoch: 118 [139968/225000 (62%)] Loss: 19429.810547\n",
      "Train Epoch: 118 [142464/225000 (63%)] Loss: 19396.375000\n",
      "Train Epoch: 118 [144960/225000 (64%)] Loss: 19499.988281\n",
      "Train Epoch: 118 [147456/225000 (66%)] Loss: 19231.164062\n",
      "Train Epoch: 118 [149952/225000 (67%)] Loss: 19397.974609\n",
      "Train Epoch: 118 [152448/225000 (68%)] Loss: 19492.402344\n",
      "Train Epoch: 118 [154944/225000 (69%)] Loss: 19794.242188\n",
      "Train Epoch: 118 [157440/225000 (70%)] Loss: 19552.806641\n",
      "Train Epoch: 118 [159936/225000 (71%)] Loss: 19396.457031\n",
      "Train Epoch: 118 [162432/225000 (72%)] Loss: 19192.292969\n",
      "Train Epoch: 118 [164928/225000 (73%)] Loss: 19119.703125\n",
      "Train Epoch: 118 [167424/225000 (74%)] Loss: 19308.365234\n",
      "Train Epoch: 118 [169920/225000 (76%)] Loss: 19497.042969\n",
      "Train Epoch: 118 [172416/225000 (77%)] Loss: 19646.705078\n",
      "Train Epoch: 118 [174912/225000 (78%)] Loss: 19507.031250\n",
      "Train Epoch: 118 [177408/225000 (79%)] Loss: 19341.480469\n",
      "Train Epoch: 118 [179904/225000 (80%)] Loss: 19669.578125\n",
      "Train Epoch: 118 [182400/225000 (81%)] Loss: 19210.656250\n",
      "Train Epoch: 118 [184896/225000 (82%)] Loss: 19592.087891\n",
      "Train Epoch: 118 [187392/225000 (83%)] Loss: 19721.384766\n",
      "Train Epoch: 118 [189888/225000 (84%)] Loss: 18849.359375\n",
      "Train Epoch: 118 [192384/225000 (86%)] Loss: 19777.384766\n",
      "Train Epoch: 118 [194880/225000 (87%)] Loss: 19543.917969\n",
      "Train Epoch: 118 [197376/225000 (88%)] Loss: 19335.550781\n",
      "Train Epoch: 118 [199872/225000 (89%)] Loss: 18983.179688\n",
      "Train Epoch: 118 [202368/225000 (90%)] Loss: 19540.867188\n",
      "Train Epoch: 118 [204864/225000 (91%)] Loss: 19914.093750\n",
      "Train Epoch: 118 [207360/225000 (92%)] Loss: 19341.183594\n",
      "Train Epoch: 118 [209856/225000 (93%)] Loss: 19014.152344\n",
      "Train Epoch: 118 [212352/225000 (94%)] Loss: 19323.773438\n",
      "Train Epoch: 118 [214848/225000 (95%)] Loss: 19338.314453\n",
      "Train Epoch: 118 [217344/225000 (97%)] Loss: 19090.847656\n",
      "Train Epoch: 118 [219840/225000 (98%)] Loss: 19545.193359\n",
      "Train Epoch: 118 [222336/225000 (99%)] Loss: 19153.324219\n",
      "Train Epoch: 118 [224832/225000 (100%)] Loss: 19602.009766\n",
      "    epoch          : 118\n",
      "    loss           : 19387.0654596843\n",
      "    val_loss       : 19286.487844755633\n",
      "Train Epoch: 119 [192/225000 (0%)] Loss: 19555.093750\n",
      "Train Epoch: 119 [2688/225000 (1%)] Loss: 19605.792969\n",
      "Train Epoch: 119 [5184/225000 (2%)] Loss: 18582.480469\n",
      "Train Epoch: 119 [7680/225000 (3%)] Loss: 19242.773438\n",
      "Train Epoch: 119 [10176/225000 (5%)] Loss: 19258.841797\n",
      "Train Epoch: 119 [12672/225000 (6%)] Loss: 18877.927734\n",
      "Train Epoch: 119 [15168/225000 (7%)] Loss: 19121.855469\n",
      "Train Epoch: 119 [17664/225000 (8%)] Loss: 19796.980469\n",
      "Train Epoch: 119 [20160/225000 (9%)] Loss: 19162.189453\n",
      "Train Epoch: 119 [22656/225000 (10%)] Loss: 18998.566406\n",
      "Train Epoch: 119 [25152/225000 (11%)] Loss: 18953.910156\n",
      "Train Epoch: 119 [27648/225000 (12%)] Loss: 19426.746094\n",
      "Train Epoch: 119 [30144/225000 (13%)] Loss: 19583.031250\n",
      "Train Epoch: 119 [32640/225000 (15%)] Loss: 19588.414062\n",
      "Train Epoch: 119 [35136/225000 (16%)] Loss: 19329.841797\n",
      "Train Epoch: 119 [37632/225000 (17%)] Loss: 19429.093750\n",
      "Train Epoch: 119 [40128/225000 (18%)] Loss: 18730.386719\n",
      "Train Epoch: 119 [42624/225000 (19%)] Loss: 19519.062500\n",
      "Train Epoch: 119 [45120/225000 (20%)] Loss: 19217.550781\n",
      "Train Epoch: 119 [47616/225000 (21%)] Loss: 19118.480469\n",
      "Train Epoch: 119 [50112/225000 (22%)] Loss: 19372.392578\n",
      "Train Epoch: 119 [52608/225000 (23%)] Loss: 18773.783203\n",
      "Train Epoch: 119 [55104/225000 (24%)] Loss: 19405.462891\n",
      "Train Epoch: 119 [57600/225000 (26%)] Loss: 19485.447266\n",
      "Train Epoch: 119 [60096/225000 (27%)] Loss: 19552.576172\n",
      "Train Epoch: 119 [62592/225000 (28%)] Loss: 19912.683594\n",
      "Train Epoch: 119 [65088/225000 (29%)] Loss: 19866.185547\n",
      "Train Epoch: 119 [67584/225000 (30%)] Loss: 19365.078125\n",
      "Train Epoch: 119 [70080/225000 (31%)] Loss: 19268.082031\n",
      "Train Epoch: 119 [72576/225000 (32%)] Loss: 19883.529297\n",
      "Train Epoch: 119 [75072/225000 (33%)] Loss: 19543.888672\n",
      "Train Epoch: 119 [77568/225000 (34%)] Loss: 19509.765625\n",
      "Train Epoch: 119 [80064/225000 (36%)] Loss: 19070.535156\n",
      "Train Epoch: 119 [82560/225000 (37%)] Loss: 19924.076172\n",
      "Train Epoch: 119 [85056/225000 (38%)] Loss: 19408.753906\n",
      "Train Epoch: 119 [87552/225000 (39%)] Loss: 19724.056641\n",
      "Train Epoch: 119 [90048/225000 (40%)] Loss: 19461.003906\n",
      "Train Epoch: 119 [92544/225000 (41%)] Loss: 19424.634766\n",
      "Train Epoch: 119 [95040/225000 (42%)] Loss: 19298.726562\n",
      "Train Epoch: 119 [97536/225000 (43%)] Loss: 19794.753906\n",
      "Train Epoch: 119 [100032/225000 (44%)] Loss: 19175.242188\n",
      "Train Epoch: 119 [102528/225000 (46%)] Loss: 19030.498047\n",
      "Train Epoch: 119 [105024/225000 (47%)] Loss: 19216.535156\n",
      "Train Epoch: 119 [107520/225000 (48%)] Loss: 19513.650391\n",
      "Train Epoch: 119 [110016/225000 (49%)] Loss: 19383.257812\n",
      "Train Epoch: 119 [112512/225000 (50%)] Loss: 19086.972656\n",
      "Train Epoch: 119 [115008/225000 (51%)] Loss: 19182.082031\n",
      "Train Epoch: 119 [117504/225000 (52%)] Loss: 19470.455078\n",
      "Train Epoch: 119 [120000/225000 (53%)] Loss: 18921.308594\n",
      "Train Epoch: 119 [122496/225000 (54%)] Loss: 19379.035156\n",
      "Train Epoch: 119 [124992/225000 (56%)] Loss: 19283.546875\n",
      "Train Epoch: 119 [127488/225000 (57%)] Loss: 19264.292969\n",
      "Train Epoch: 119 [129984/225000 (58%)] Loss: 19808.394531\n",
      "Train Epoch: 119 [132480/225000 (59%)] Loss: 19021.511719\n",
      "Train Epoch: 119 [134976/225000 (60%)] Loss: 19433.945312\n",
      "Train Epoch: 119 [137472/225000 (61%)] Loss: 19436.833984\n",
      "Train Epoch: 119 [139968/225000 (62%)] Loss: 19288.160156\n",
      "Train Epoch: 119 [142464/225000 (63%)] Loss: 19990.238281\n",
      "Train Epoch: 119 [144960/225000 (64%)] Loss: 19176.521484\n",
      "Train Epoch: 119 [147456/225000 (66%)] Loss: 19379.722656\n",
      "Train Epoch: 119 [149952/225000 (67%)] Loss: 19713.578125\n",
      "Train Epoch: 119 [152448/225000 (68%)] Loss: 18550.023438\n",
      "Train Epoch: 119 [154944/225000 (69%)] Loss: 19556.408203\n",
      "Train Epoch: 119 [157440/225000 (70%)] Loss: 19342.501953\n",
      "Train Epoch: 119 [159936/225000 (71%)] Loss: 18915.363281\n",
      "Train Epoch: 119 [162432/225000 (72%)] Loss: 19500.339844\n",
      "Train Epoch: 119 [164928/225000 (73%)] Loss: 19591.365234\n",
      "Train Epoch: 119 [167424/225000 (74%)] Loss: 19442.289062\n",
      "Train Epoch: 119 [169920/225000 (76%)] Loss: 19351.304688\n",
      "Train Epoch: 119 [172416/225000 (77%)] Loss: 19461.507812\n",
      "Train Epoch: 119 [174912/225000 (78%)] Loss: 19560.712891\n",
      "Train Epoch: 119 [177408/225000 (79%)] Loss: 19873.156250\n",
      "Train Epoch: 119 [179904/225000 (80%)] Loss: 19179.503906\n",
      "Train Epoch: 119 [182400/225000 (81%)] Loss: 19324.144531\n",
      "Train Epoch: 119 [184896/225000 (82%)] Loss: 19549.730469\n",
      "Train Epoch: 119 [187392/225000 (83%)] Loss: 19403.250000\n",
      "Train Epoch: 119 [189888/225000 (84%)] Loss: 18863.691406\n",
      "Train Epoch: 119 [192384/225000 (86%)] Loss: 19400.351562\n",
      "Train Epoch: 119 [194880/225000 (87%)] Loss: 19944.257812\n",
      "Train Epoch: 119 [197376/225000 (88%)] Loss: 19512.183594\n",
      "Train Epoch: 119 [199872/225000 (89%)] Loss: 19021.445312\n",
      "Train Epoch: 119 [202368/225000 (90%)] Loss: 19334.089844\n",
      "Train Epoch: 119 [204864/225000 (91%)] Loss: 19354.269531\n",
      "Train Epoch: 119 [207360/225000 (92%)] Loss: 19526.648438\n",
      "Train Epoch: 119 [209856/225000 (93%)] Loss: 19710.273438\n",
      "Train Epoch: 119 [212352/225000 (94%)] Loss: 19484.867188\n",
      "Train Epoch: 119 [214848/225000 (95%)] Loss: 18843.757812\n",
      "Train Epoch: 119 [217344/225000 (97%)] Loss: 18526.703125\n",
      "Train Epoch: 119 [219840/225000 (98%)] Loss: 19049.093750\n",
      "Train Epoch: 119 [222336/225000 (99%)] Loss: 19625.273438\n",
      "Train Epoch: 119 [224832/225000 (100%)] Loss: 19741.181641\n",
      "    epoch          : 119\n",
      "    loss           : 19385.8953278317\n",
      "    val_loss       : 19288.47548664526\n",
      "Train Epoch: 120 [192/225000 (0%)] Loss: 19208.921875\n",
      "Train Epoch: 120 [2688/225000 (1%)] Loss: 19101.441406\n",
      "Train Epoch: 120 [5184/225000 (2%)] Loss: 19552.156250\n",
      "Train Epoch: 120 [7680/225000 (3%)] Loss: 18839.738281\n",
      "Train Epoch: 120 [10176/225000 (5%)] Loss: 19882.492188\n",
      "Train Epoch: 120 [12672/225000 (6%)] Loss: 19250.226562\n",
      "Train Epoch: 120 [15168/225000 (7%)] Loss: 19542.265625\n",
      "Train Epoch: 120 [17664/225000 (8%)] Loss: 19178.019531\n",
      "Train Epoch: 120 [20160/225000 (9%)] Loss: 19503.742188\n",
      "Train Epoch: 120 [22656/225000 (10%)] Loss: 19142.601562\n",
      "Train Epoch: 120 [25152/225000 (11%)] Loss: 19186.367188\n",
      "Train Epoch: 120 [27648/225000 (12%)] Loss: 19275.533203\n",
      "Train Epoch: 120 [30144/225000 (13%)] Loss: 19670.085938\n",
      "Train Epoch: 120 [32640/225000 (15%)] Loss: 19304.855469\n",
      "Train Epoch: 120 [35136/225000 (16%)] Loss: 19744.732422\n",
      "Train Epoch: 120 [37632/225000 (17%)] Loss: 19620.531250\n",
      "Train Epoch: 120 [40128/225000 (18%)] Loss: 19360.753906\n",
      "Train Epoch: 120 [42624/225000 (19%)] Loss: 19232.728516\n",
      "Train Epoch: 120 [45120/225000 (20%)] Loss: 19363.007812\n",
      "Train Epoch: 120 [47616/225000 (21%)] Loss: 19501.730469\n",
      "Train Epoch: 120 [50112/225000 (22%)] Loss: 18864.066406\n",
      "Train Epoch: 120 [52608/225000 (23%)] Loss: 19221.341797\n",
      "Train Epoch: 120 [55104/225000 (24%)] Loss: 18931.990234\n",
      "Train Epoch: 120 [57600/225000 (26%)] Loss: 19283.250000\n",
      "Train Epoch: 120 [60096/225000 (27%)] Loss: 18904.445312\n",
      "Train Epoch: 120 [62592/225000 (28%)] Loss: 19233.142578\n",
      "Train Epoch: 120 [65088/225000 (29%)] Loss: 19179.634766\n",
      "Train Epoch: 120 [67584/225000 (30%)] Loss: 19297.957031\n",
      "Train Epoch: 120 [70080/225000 (31%)] Loss: 19197.886719\n",
      "Train Epoch: 120 [72576/225000 (32%)] Loss: 19096.851562\n",
      "Train Epoch: 120 [75072/225000 (33%)] Loss: 18949.585938\n",
      "Train Epoch: 120 [77568/225000 (34%)] Loss: 19202.638672\n",
      "Train Epoch: 120 [80064/225000 (36%)] Loss: 19264.207031\n",
      "Train Epoch: 120 [82560/225000 (37%)] Loss: 19090.171875\n",
      "Train Epoch: 120 [85056/225000 (38%)] Loss: 19629.000000\n",
      "Train Epoch: 120 [87552/225000 (39%)] Loss: 19117.570312\n",
      "Train Epoch: 120 [90048/225000 (40%)] Loss: 20084.716797\n",
      "Train Epoch: 120 [92544/225000 (41%)] Loss: 19263.675781\n",
      "Train Epoch: 120 [95040/225000 (42%)] Loss: 19169.390625\n",
      "Train Epoch: 120 [97536/225000 (43%)] Loss: 19101.250000\n",
      "Train Epoch: 120 [100032/225000 (44%)] Loss: 19742.355469\n",
      "Train Epoch: 120 [102528/225000 (46%)] Loss: 19233.273438\n",
      "Train Epoch: 120 [105024/225000 (47%)] Loss: 19236.804688\n",
      "Train Epoch: 120 [107520/225000 (48%)] Loss: 19299.062500\n",
      "Train Epoch: 120 [110016/225000 (49%)] Loss: 19277.996094\n",
      "Train Epoch: 120 [112512/225000 (50%)] Loss: 19493.376953\n",
      "Train Epoch: 120 [115008/225000 (51%)] Loss: 19147.859375\n",
      "Train Epoch: 120 [117504/225000 (52%)] Loss: 19252.738281\n",
      "Train Epoch: 120 [120000/225000 (53%)] Loss: 19008.410156\n",
      "Train Epoch: 120 [122496/225000 (54%)] Loss: 19340.533203\n",
      "Train Epoch: 120 [124992/225000 (56%)] Loss: 19555.093750\n",
      "Train Epoch: 120 [127488/225000 (57%)] Loss: 18882.861328\n",
      "Train Epoch: 120 [129984/225000 (58%)] Loss: 19322.607422\n",
      "Train Epoch: 120 [132480/225000 (59%)] Loss: 19564.707031\n",
      "Train Epoch: 120 [134976/225000 (60%)] Loss: 19226.035156\n",
      "Train Epoch: 120 [137472/225000 (61%)] Loss: 19586.089844\n",
      "Train Epoch: 120 [139968/225000 (62%)] Loss: 19415.687500\n",
      "Train Epoch: 120 [142464/225000 (63%)] Loss: 19952.296875\n",
      "Train Epoch: 120 [144960/225000 (64%)] Loss: 19202.447266\n",
      "Train Epoch: 120 [147456/225000 (66%)] Loss: 19556.558594\n",
      "Train Epoch: 120 [149952/225000 (67%)] Loss: 19622.396484\n",
      "Train Epoch: 120 [152448/225000 (68%)] Loss: 19258.625000\n",
      "Train Epoch: 120 [154944/225000 (69%)] Loss: 19582.667969\n",
      "Train Epoch: 120 [157440/225000 (70%)] Loss: 19257.195312\n",
      "Train Epoch: 120 [159936/225000 (71%)] Loss: 19503.132812\n",
      "Train Epoch: 120 [162432/225000 (72%)] Loss: 18969.160156\n",
      "Train Epoch: 120 [164928/225000 (73%)] Loss: 19356.957031\n",
      "Train Epoch: 120 [167424/225000 (74%)] Loss: 19543.960938\n",
      "Train Epoch: 120 [169920/225000 (76%)] Loss: 19522.546875\n",
      "Train Epoch: 120 [172416/225000 (77%)] Loss: 19009.507812\n",
      "Train Epoch: 120 [174912/225000 (78%)] Loss: 19396.652344\n",
      "Train Epoch: 120 [177408/225000 (79%)] Loss: 18892.902344\n",
      "Train Epoch: 120 [179904/225000 (80%)] Loss: 19192.332031\n",
      "Train Epoch: 120 [182400/225000 (81%)] Loss: 19360.871094\n",
      "Train Epoch: 120 [184896/225000 (82%)] Loss: 19672.007812\n",
      "Train Epoch: 120 [187392/225000 (83%)] Loss: 19374.656250\n",
      "Train Epoch: 120 [189888/225000 (84%)] Loss: 19119.115234\n",
      "Train Epoch: 120 [192384/225000 (86%)] Loss: 19599.425781\n",
      "Train Epoch: 120 [194880/225000 (87%)] Loss: 19874.621094\n",
      "Train Epoch: 120 [197376/225000 (88%)] Loss: 19113.873047\n",
      "Train Epoch: 120 [199872/225000 (89%)] Loss: 19731.929688\n",
      "Train Epoch: 120 [202368/225000 (90%)] Loss: 19151.105469\n",
      "Train Epoch: 120 [204864/225000 (91%)] Loss: 19462.792969\n",
      "Train Epoch: 120 [207360/225000 (92%)] Loss: 19992.285156\n",
      "Train Epoch: 120 [209856/225000 (93%)] Loss: 19495.531250\n",
      "Train Epoch: 120 [212352/225000 (94%)] Loss: 19211.226562\n",
      "Train Epoch: 120 [214848/225000 (95%)] Loss: 18496.154297\n",
      "Train Epoch: 120 [217344/225000 (97%)] Loss: 19538.156250\n",
      "Train Epoch: 120 [219840/225000 (98%)] Loss: 19211.644531\n",
      "Train Epoch: 120 [222336/225000 (99%)] Loss: 18871.666016\n",
      "Train Epoch: 120 [224832/225000 (100%)] Loss: 18983.457031\n",
      "    epoch          : 120\n",
      "    loss           : 19369.518458031143\n",
      "    val_loss       : 19271.898421814425\n",
      "Train Epoch: 121 [192/225000 (0%)] Loss: 19472.898438\n",
      "Train Epoch: 121 [2688/225000 (1%)] Loss: 19883.453125\n",
      "Train Epoch: 121 [5184/225000 (2%)] Loss: 19423.873047\n",
      "Train Epoch: 121 [7680/225000 (3%)] Loss: 19762.835938\n",
      "Train Epoch: 121 [10176/225000 (5%)] Loss: 19304.544922\n",
      "Train Epoch: 121 [12672/225000 (6%)] Loss: 19354.333984\n",
      "Train Epoch: 121 [15168/225000 (7%)] Loss: 19019.521484\n",
      "Train Epoch: 121 [17664/225000 (8%)] Loss: 19259.837891\n",
      "Train Epoch: 121 [20160/225000 (9%)] Loss: 19391.919922\n",
      "Train Epoch: 121 [22656/225000 (10%)] Loss: 18967.150391\n",
      "Train Epoch: 121 [25152/225000 (11%)] Loss: 19483.962891\n",
      "Train Epoch: 121 [27648/225000 (12%)] Loss: 19314.687500\n",
      "Train Epoch: 121 [30144/225000 (13%)] Loss: 19423.402344\n",
      "Train Epoch: 121 [32640/225000 (15%)] Loss: 19232.007812\n",
      "Train Epoch: 121 [35136/225000 (16%)] Loss: 19173.031250\n",
      "Train Epoch: 121 [37632/225000 (17%)] Loss: 19885.988281\n",
      "Train Epoch: 121 [40128/225000 (18%)] Loss: 19642.753906\n",
      "Train Epoch: 121 [42624/225000 (19%)] Loss: 19176.707031\n",
      "Train Epoch: 121 [45120/225000 (20%)] Loss: 19819.332031\n",
      "Train Epoch: 121 [47616/225000 (21%)] Loss: 18480.382812\n",
      "Train Epoch: 121 [50112/225000 (22%)] Loss: 19021.347656\n",
      "Train Epoch: 121 [52608/225000 (23%)] Loss: 19565.431641\n",
      "Train Epoch: 121 [55104/225000 (24%)] Loss: 19222.285156\n",
      "Train Epoch: 121 [57600/225000 (26%)] Loss: 19421.621094\n",
      "Train Epoch: 121 [60096/225000 (27%)] Loss: 19285.914062\n",
      "Train Epoch: 121 [62592/225000 (28%)] Loss: 19236.267578\n",
      "Train Epoch: 121 [65088/225000 (29%)] Loss: 19297.623047\n",
      "Train Epoch: 121 [67584/225000 (30%)] Loss: 19536.714844\n",
      "Train Epoch: 121 [70080/225000 (31%)] Loss: 19503.451172\n",
      "Train Epoch: 121 [72576/225000 (32%)] Loss: 19304.826172\n",
      "Train Epoch: 121 [75072/225000 (33%)] Loss: 19162.371094\n",
      "Train Epoch: 121 [77568/225000 (34%)] Loss: 19160.580078\n",
      "Train Epoch: 121 [80064/225000 (36%)] Loss: 19550.042969\n",
      "Train Epoch: 121 [82560/225000 (37%)] Loss: 19365.769531\n",
      "Train Epoch: 121 [85056/225000 (38%)] Loss: 19595.171875\n",
      "Train Epoch: 121 [87552/225000 (39%)] Loss: 19200.533203\n",
      "Train Epoch: 121 [90048/225000 (40%)] Loss: 19341.386719\n",
      "Train Epoch: 121 [92544/225000 (41%)] Loss: 19368.367188\n",
      "Train Epoch: 121 [95040/225000 (42%)] Loss: 19471.871094\n",
      "Train Epoch: 121 [97536/225000 (43%)] Loss: 19509.765625\n",
      "Train Epoch: 121 [100032/225000 (44%)] Loss: 19113.679688\n",
      "Train Epoch: 121 [102528/225000 (46%)] Loss: 19406.500000\n",
      "Train Epoch: 121 [105024/225000 (47%)] Loss: 19037.242188\n",
      "Train Epoch: 121 [107520/225000 (48%)] Loss: 19399.970703\n",
      "Train Epoch: 121 [110016/225000 (49%)] Loss: 19168.935547\n",
      "Train Epoch: 121 [112512/225000 (50%)] Loss: 19225.503906\n",
      "Train Epoch: 121 [115008/225000 (51%)] Loss: 19385.796875\n",
      "Train Epoch: 121 [117504/225000 (52%)] Loss: 19349.669922\n",
      "Train Epoch: 121 [120000/225000 (53%)] Loss: 18813.589844\n",
      "Train Epoch: 121 [122496/225000 (54%)] Loss: 18948.462891\n",
      "Train Epoch: 121 [124992/225000 (56%)] Loss: 19806.886719\n",
      "Train Epoch: 121 [127488/225000 (57%)] Loss: 19298.148438\n",
      "Train Epoch: 121 [129984/225000 (58%)] Loss: 19150.304688\n",
      "Train Epoch: 121 [132480/225000 (59%)] Loss: 19242.224609\n",
      "Train Epoch: 121 [134976/225000 (60%)] Loss: 19386.601562\n",
      "Train Epoch: 121 [137472/225000 (61%)] Loss: 19709.050781\n",
      "Train Epoch: 121 [139968/225000 (62%)] Loss: 19302.253906\n",
      "Train Epoch: 121 [142464/225000 (63%)] Loss: 19265.789062\n",
      "Train Epoch: 121 [144960/225000 (64%)] Loss: 19379.437500\n",
      "Train Epoch: 121 [147456/225000 (66%)] Loss: 19377.509766\n",
      "Train Epoch: 121 [149952/225000 (67%)] Loss: 19872.947266\n",
      "Train Epoch: 121 [152448/225000 (68%)] Loss: 19341.626953\n",
      "Train Epoch: 121 [154944/225000 (69%)] Loss: 19680.039062\n",
      "Train Epoch: 121 [157440/225000 (70%)] Loss: 19602.054688\n",
      "Train Epoch: 121 [159936/225000 (71%)] Loss: 19032.199219\n",
      "Train Epoch: 121 [162432/225000 (72%)] Loss: 19473.804688\n",
      "Train Epoch: 121 [164928/225000 (73%)] Loss: 19340.302734\n",
      "Train Epoch: 121 [167424/225000 (74%)] Loss: 19008.697266\n",
      "Train Epoch: 121 [169920/225000 (76%)] Loss: 19581.154297\n",
      "Train Epoch: 121 [172416/225000 (77%)] Loss: 19103.593750\n",
      "Train Epoch: 121 [174912/225000 (78%)] Loss: 19070.648438\n",
      "Train Epoch: 121 [177408/225000 (79%)] Loss: 19206.488281\n",
      "Train Epoch: 121 [179904/225000 (80%)] Loss: 19620.925781\n",
      "Train Epoch: 121 [182400/225000 (81%)] Loss: 19609.046875\n",
      "Train Epoch: 121 [184896/225000 (82%)] Loss: 19294.496094\n",
      "Train Epoch: 121 [187392/225000 (83%)] Loss: 19462.496094\n",
      "Train Epoch: 121 [189888/225000 (84%)] Loss: 19559.271484\n",
      "Train Epoch: 121 [192384/225000 (86%)] Loss: 19359.478516\n",
      "Train Epoch: 121 [194880/225000 (87%)] Loss: 19436.671875\n",
      "Train Epoch: 121 [197376/225000 (88%)] Loss: 19028.998047\n",
      "Train Epoch: 121 [199872/225000 (89%)] Loss: 19223.064453\n",
      "Train Epoch: 121 [202368/225000 (90%)] Loss: 19175.707031\n",
      "Train Epoch: 121 [204864/225000 (91%)] Loss: 19433.562500\n",
      "Train Epoch: 121 [207360/225000 (92%)] Loss: 19395.535156\n",
      "Train Epoch: 121 [209856/225000 (93%)] Loss: 19137.140625\n",
      "Train Epoch: 121 [212352/225000 (94%)] Loss: 19358.189453\n",
      "Train Epoch: 121 [214848/225000 (95%)] Loss: 19181.785156\n",
      "Train Epoch: 121 [217344/225000 (97%)] Loss: 19344.441406\n",
      "Train Epoch: 121 [219840/225000 (98%)] Loss: 19601.976562\n",
      "Train Epoch: 121 [222336/225000 (99%)] Loss: 19608.968750\n",
      "Train Epoch: 121 [224832/225000 (100%)] Loss: 19495.113281\n",
      "    epoch          : 121\n",
      "    loss           : 19381.720818112735\n",
      "    val_loss       : 19306.692409486262\n",
      "Train Epoch: 122 [192/225000 (0%)] Loss: 19205.853516\n",
      "Train Epoch: 122 [2688/225000 (1%)] Loss: 19314.595703\n",
      "Train Epoch: 122 [5184/225000 (2%)] Loss: 19392.392578\n",
      "Train Epoch: 122 [7680/225000 (3%)] Loss: 19115.531250\n",
      "Train Epoch: 122 [10176/225000 (5%)] Loss: 19763.726562\n",
      "Train Epoch: 122 [12672/225000 (6%)] Loss: 19683.062500\n",
      "Train Epoch: 122 [15168/225000 (7%)] Loss: 19496.449219\n",
      "Train Epoch: 122 [17664/225000 (8%)] Loss: 19692.957031\n",
      "Train Epoch: 122 [20160/225000 (9%)] Loss: 19512.572266\n",
      "Train Epoch: 122 [22656/225000 (10%)] Loss: 19323.841797\n",
      "Train Epoch: 122 [25152/225000 (11%)] Loss: 19318.480469\n",
      "Train Epoch: 122 [27648/225000 (12%)] Loss: 19614.839844\n",
      "Train Epoch: 122 [30144/225000 (13%)] Loss: 19416.121094\n",
      "Train Epoch: 122 [32640/225000 (15%)] Loss: 19669.037109\n",
      "Train Epoch: 122 [35136/225000 (16%)] Loss: 19820.761719\n",
      "Train Epoch: 122 [37632/225000 (17%)] Loss: 19424.666016\n",
      "Train Epoch: 122 [40128/225000 (18%)] Loss: 19245.167969\n",
      "Train Epoch: 122 [42624/225000 (19%)] Loss: 18909.156250\n",
      "Train Epoch: 122 [45120/225000 (20%)] Loss: 19260.968750\n",
      "Train Epoch: 122 [47616/225000 (21%)] Loss: 19190.628906\n",
      "Train Epoch: 122 [50112/225000 (22%)] Loss: 18872.843750\n",
      "Train Epoch: 122 [52608/225000 (23%)] Loss: 19680.753906\n",
      "Train Epoch: 122 [55104/225000 (24%)] Loss: 19311.691406\n",
      "Train Epoch: 122 [57600/225000 (26%)] Loss: 18868.531250\n",
      "Train Epoch: 122 [60096/225000 (27%)] Loss: 19746.507812\n",
      "Train Epoch: 122 [62592/225000 (28%)] Loss: 18857.816406\n",
      "Train Epoch: 122 [65088/225000 (29%)] Loss: 19471.574219\n",
      "Train Epoch: 122 [67584/225000 (30%)] Loss: 19145.583984\n",
      "Train Epoch: 122 [70080/225000 (31%)] Loss: 19411.177734\n",
      "Train Epoch: 122 [72576/225000 (32%)] Loss: 19554.718750\n",
      "Train Epoch: 122 [75072/225000 (33%)] Loss: 19418.925781\n",
      "Train Epoch: 122 [77568/225000 (34%)] Loss: 19239.259766\n",
      "Train Epoch: 122 [80064/225000 (36%)] Loss: 19254.056641\n",
      "Train Epoch: 122 [82560/225000 (37%)] Loss: 19634.652344\n",
      "Train Epoch: 122 [85056/225000 (38%)] Loss: 19296.164062\n",
      "Train Epoch: 122 [87552/225000 (39%)] Loss: 19303.183594\n",
      "Train Epoch: 122 [90048/225000 (40%)] Loss: 19698.574219\n",
      "Train Epoch: 122 [92544/225000 (41%)] Loss: 19375.789062\n",
      "Train Epoch: 122 [95040/225000 (42%)] Loss: 19267.865234\n",
      "Train Epoch: 122 [97536/225000 (43%)] Loss: 19088.398438\n",
      "Train Epoch: 122 [100032/225000 (44%)] Loss: 19121.191406\n",
      "Train Epoch: 122 [102528/225000 (46%)] Loss: 19126.957031\n",
      "Train Epoch: 122 [105024/225000 (47%)] Loss: 19283.281250\n",
      "Train Epoch: 122 [107520/225000 (48%)] Loss: 19399.548828\n",
      "Train Epoch: 122 [110016/225000 (49%)] Loss: 19352.300781\n",
      "Train Epoch: 122 [112512/225000 (50%)] Loss: 19403.476562\n",
      "Train Epoch: 122 [115008/225000 (51%)] Loss: 19539.919922\n",
      "Train Epoch: 122 [117504/225000 (52%)] Loss: 19180.439453\n",
      "Train Epoch: 122 [120000/225000 (53%)] Loss: 19340.244141\n",
      "Train Epoch: 122 [122496/225000 (54%)] Loss: 19186.140625\n",
      "Train Epoch: 122 [124992/225000 (56%)] Loss: 19257.970703\n",
      "Train Epoch: 122 [127488/225000 (57%)] Loss: 19377.617188\n",
      "Train Epoch: 122 [129984/225000 (58%)] Loss: 19862.447266\n",
      "Train Epoch: 122 [132480/225000 (59%)] Loss: 18944.732422\n",
      "Train Epoch: 122 [134976/225000 (60%)] Loss: 19233.333984\n",
      "Train Epoch: 122 [137472/225000 (61%)] Loss: 19320.886719\n",
      "Train Epoch: 122 [139968/225000 (62%)] Loss: 19292.523438\n",
      "Train Epoch: 122 [142464/225000 (63%)] Loss: 19711.988281\n",
      "Train Epoch: 122 [144960/225000 (64%)] Loss: 19369.640625\n",
      "Train Epoch: 122 [147456/225000 (66%)] Loss: 19029.726562\n",
      "Train Epoch: 122 [149952/225000 (67%)] Loss: 19240.337891\n",
      "Train Epoch: 122 [152448/225000 (68%)] Loss: 19551.300781\n",
      "Train Epoch: 122 [154944/225000 (69%)] Loss: 19556.744141\n",
      "Train Epoch: 122 [157440/225000 (70%)] Loss: 18922.544922\n",
      "Train Epoch: 122 [159936/225000 (71%)] Loss: 19237.925781\n",
      "Train Epoch: 122 [162432/225000 (72%)] Loss: 19049.869141\n",
      "Train Epoch: 122 [164928/225000 (73%)] Loss: 19473.699219\n",
      "Train Epoch: 122 [167424/225000 (74%)] Loss: 19105.816406\n",
      "Train Epoch: 122 [169920/225000 (76%)] Loss: 19787.740234\n",
      "Train Epoch: 122 [172416/225000 (77%)] Loss: 19476.900391\n",
      "Train Epoch: 122 [174912/225000 (78%)] Loss: 19128.464844\n",
      "Train Epoch: 122 [177408/225000 (79%)] Loss: 19636.630859\n",
      "Train Epoch: 122 [179904/225000 (80%)] Loss: 19489.005859\n",
      "Train Epoch: 122 [182400/225000 (81%)] Loss: 19496.175781\n",
      "Train Epoch: 122 [184896/225000 (82%)] Loss: 19040.332031\n",
      "Train Epoch: 122 [187392/225000 (83%)] Loss: 19094.917969\n",
      "Train Epoch: 122 [189888/225000 (84%)] Loss: 19607.722656\n",
      "Train Epoch: 122 [192384/225000 (86%)] Loss: 19297.070312\n",
      "Train Epoch: 122 [194880/225000 (87%)] Loss: 19762.500000\n",
      "Train Epoch: 122 [197376/225000 (88%)] Loss: 19460.855469\n",
      "Train Epoch: 122 [199872/225000 (89%)] Loss: 18897.753906\n",
      "Train Epoch: 122 [202368/225000 (90%)] Loss: 19156.835938\n",
      "Train Epoch: 122 [204864/225000 (91%)] Loss: 19095.878906\n",
      "Train Epoch: 122 [207360/225000 (92%)] Loss: 18754.941406\n",
      "Train Epoch: 122 [209856/225000 (93%)] Loss: 19359.654297\n",
      "Train Epoch: 122 [212352/225000 (94%)] Loss: 19166.242188\n",
      "Train Epoch: 122 [214848/225000 (95%)] Loss: 19737.003906\n",
      "Train Epoch: 122 [217344/225000 (97%)] Loss: 19445.414062\n",
      "Train Epoch: 122 [219840/225000 (98%)] Loss: 19439.328125\n",
      "Train Epoch: 122 [222336/225000 (99%)] Loss: 19245.250000\n",
      "Train Epoch: 122 [224832/225000 (100%)] Loss: 19719.867188\n",
      "    epoch          : 122\n",
      "    loss           : 19360.723352842364\n",
      "    val_loss       : 19262.45069230786\n",
      "Train Epoch: 123 [192/225000 (0%)] Loss: 19804.919922\n",
      "Train Epoch: 123 [2688/225000 (1%)] Loss: 19483.480469\n",
      "Train Epoch: 123 [5184/225000 (2%)] Loss: 19256.492188\n",
      "Train Epoch: 123 [7680/225000 (3%)] Loss: 19454.232422\n",
      "Train Epoch: 123 [10176/225000 (5%)] Loss: 19533.257812\n",
      "Train Epoch: 123 [12672/225000 (6%)] Loss: 19521.003906\n",
      "Train Epoch: 123 [15168/225000 (7%)] Loss: 19299.335938\n",
      "Train Epoch: 123 [17664/225000 (8%)] Loss: 18747.371094\n",
      "Train Epoch: 123 [20160/225000 (9%)] Loss: 18776.179688\n",
      "Train Epoch: 123 [22656/225000 (10%)] Loss: 19234.271484\n",
      "Train Epoch: 123 [25152/225000 (11%)] Loss: 19252.242188\n",
      "Train Epoch: 123 [27648/225000 (12%)] Loss: 19568.632812\n",
      "Train Epoch: 123 [30144/225000 (13%)] Loss: 19368.406250\n",
      "Train Epoch: 123 [32640/225000 (15%)] Loss: 19378.402344\n",
      "Train Epoch: 123 [35136/225000 (16%)] Loss: 19370.035156\n",
      "Train Epoch: 123 [37632/225000 (17%)] Loss: 19641.169922\n",
      "Train Epoch: 123 [40128/225000 (18%)] Loss: 18667.025391\n",
      "Train Epoch: 123 [42624/225000 (19%)] Loss: 19572.074219\n",
      "Train Epoch: 123 [45120/225000 (20%)] Loss: 19118.134766\n",
      "Train Epoch: 123 [47616/225000 (21%)] Loss: 19437.371094\n",
      "Train Epoch: 123 [50112/225000 (22%)] Loss: 19294.519531\n",
      "Train Epoch: 123 [52608/225000 (23%)] Loss: 18700.421875\n",
      "Train Epoch: 123 [55104/225000 (24%)] Loss: 19685.166016\n",
      "Train Epoch: 123 [57600/225000 (26%)] Loss: 19368.777344\n",
      "Train Epoch: 123 [60096/225000 (27%)] Loss: 19416.203125\n",
      "Train Epoch: 123 [62592/225000 (28%)] Loss: 19813.562500\n",
      "Train Epoch: 123 [65088/225000 (29%)] Loss: 19377.101562\n",
      "Train Epoch: 123 [67584/225000 (30%)] Loss: 19362.861328\n",
      "Train Epoch: 123 [70080/225000 (31%)] Loss: 19369.199219\n",
      "Train Epoch: 123 [72576/225000 (32%)] Loss: 19583.703125\n",
      "Train Epoch: 123 [75072/225000 (33%)] Loss: 19528.234375\n",
      "Train Epoch: 123 [77568/225000 (34%)] Loss: 19637.593750\n",
      "Train Epoch: 123 [80064/225000 (36%)] Loss: 19463.593750\n",
      "Train Epoch: 123 [82560/225000 (37%)] Loss: 19146.734375\n",
      "Train Epoch: 123 [85056/225000 (38%)] Loss: 19428.667969\n",
      "Train Epoch: 123 [87552/225000 (39%)] Loss: 19487.816406\n",
      "Train Epoch: 123 [90048/225000 (40%)] Loss: 19144.847656\n",
      "Train Epoch: 123 [92544/225000 (41%)] Loss: 19612.158203\n",
      "Train Epoch: 123 [95040/225000 (42%)] Loss: 18907.871094\n",
      "Train Epoch: 123 [97536/225000 (43%)] Loss: 18894.621094\n",
      "Train Epoch: 123 [100032/225000 (44%)] Loss: 19827.714844\n",
      "Train Epoch: 123 [102528/225000 (46%)] Loss: 19434.685547\n",
      "Train Epoch: 123 [105024/225000 (47%)] Loss: 19364.550781\n",
      "Train Epoch: 123 [107520/225000 (48%)] Loss: 19150.113281\n",
      "Train Epoch: 123 [110016/225000 (49%)] Loss: 19755.962891\n",
      "Train Epoch: 123 [112512/225000 (50%)] Loss: 19484.931641\n",
      "Train Epoch: 123 [115008/225000 (51%)] Loss: 19325.992188\n",
      "Train Epoch: 123 [117504/225000 (52%)] Loss: 19169.378906\n",
      "Train Epoch: 123 [120000/225000 (53%)] Loss: 19371.351562\n",
      "Train Epoch: 123 [122496/225000 (54%)] Loss: 19431.917969\n",
      "Train Epoch: 123 [124992/225000 (56%)] Loss: 18994.484375\n",
      "Train Epoch: 123 [127488/225000 (57%)] Loss: 19174.843750\n",
      "Train Epoch: 123 [129984/225000 (58%)] Loss: 19610.824219\n",
      "Train Epoch: 123 [132480/225000 (59%)] Loss: 19499.152344\n",
      "Train Epoch: 123 [134976/225000 (60%)] Loss: 19299.402344\n",
      "Train Epoch: 123 [137472/225000 (61%)] Loss: 19741.488281\n",
      "Train Epoch: 123 [139968/225000 (62%)] Loss: 19628.296875\n",
      "Train Epoch: 123 [142464/225000 (63%)] Loss: 19142.789062\n",
      "Train Epoch: 123 [144960/225000 (64%)] Loss: 19215.638672\n",
      "Train Epoch: 123 [147456/225000 (66%)] Loss: 19004.580078\n",
      "Train Epoch: 123 [149952/225000 (67%)] Loss: 19258.287109\n",
      "Train Epoch: 123 [152448/225000 (68%)] Loss: 19126.984375\n",
      "Train Epoch: 123 [154944/225000 (69%)] Loss: 19219.191406\n",
      "Train Epoch: 123 [157440/225000 (70%)] Loss: 19655.173828\n",
      "Train Epoch: 123 [159936/225000 (71%)] Loss: 19028.320312\n",
      "Train Epoch: 123 [162432/225000 (72%)] Loss: 19531.330078\n",
      "Train Epoch: 123 [164928/225000 (73%)] Loss: 19209.085938\n",
      "Train Epoch: 123 [167424/225000 (74%)] Loss: 19305.851562\n",
      "Train Epoch: 123 [169920/225000 (76%)] Loss: 19198.953125\n",
      "Train Epoch: 123 [172416/225000 (77%)] Loss: 19370.492188\n",
      "Train Epoch: 123 [174912/225000 (78%)] Loss: 19416.988281\n",
      "Train Epoch: 123 [177408/225000 (79%)] Loss: 19162.824219\n",
      "Train Epoch: 123 [179904/225000 (80%)] Loss: 19536.279297\n",
      "Train Epoch: 123 [182400/225000 (81%)] Loss: 19288.978516\n",
      "Train Epoch: 123 [184896/225000 (82%)] Loss: 19449.851562\n",
      "Train Epoch: 123 [187392/225000 (83%)] Loss: 19364.125000\n",
      "Train Epoch: 123 [189888/225000 (84%)] Loss: 18942.578125\n",
      "Train Epoch: 123 [192384/225000 (86%)] Loss: 19257.275391\n",
      "Train Epoch: 123 [194880/225000 (87%)] Loss: 19673.445312\n",
      "Train Epoch: 123 [197376/225000 (88%)] Loss: 19105.164062\n",
      "Train Epoch: 123 [199872/225000 (89%)] Loss: 19323.025391\n",
      "Train Epoch: 123 [202368/225000 (90%)] Loss: 19373.794922\n",
      "Train Epoch: 123 [204864/225000 (91%)] Loss: 19695.367188\n",
      "Train Epoch: 123 [207360/225000 (92%)] Loss: 19134.781250\n",
      "Train Epoch: 123 [209856/225000 (93%)] Loss: 19207.351562\n",
      "Train Epoch: 123 [212352/225000 (94%)] Loss: 18809.750000\n",
      "Train Epoch: 123 [214848/225000 (95%)] Loss: 19175.757812\n",
      "Train Epoch: 123 [217344/225000 (97%)] Loss: 19544.320312\n",
      "Train Epoch: 123 [219840/225000 (98%)] Loss: 19765.726562\n",
      "Train Epoch: 123 [222336/225000 (99%)] Loss: 19435.019531\n",
      "Train Epoch: 123 [224832/225000 (100%)] Loss: 19852.673828\n",
      "    epoch          : 123\n",
      "    loss           : 19363.874426727816\n",
      "    val_loss       : 19256.98437963096\n",
      "Train Epoch: 124 [192/225000 (0%)] Loss: 19731.111328\n",
      "Train Epoch: 124 [2688/225000 (1%)] Loss: 19317.015625\n",
      "Train Epoch: 124 [5184/225000 (2%)] Loss: 19423.800781\n",
      "Train Epoch: 124 [7680/225000 (3%)] Loss: 19557.679688\n",
      "Train Epoch: 124 [10176/225000 (5%)] Loss: 19739.435547\n",
      "Train Epoch: 124 [12672/225000 (6%)] Loss: 19385.732422\n",
      "Train Epoch: 124 [15168/225000 (7%)] Loss: 19490.369141\n",
      "Train Epoch: 124 [17664/225000 (8%)] Loss: 18883.453125\n",
      "Train Epoch: 124 [20160/225000 (9%)] Loss: 19164.605469\n",
      "Train Epoch: 124 [22656/225000 (10%)] Loss: 19205.894531\n",
      "Train Epoch: 124 [25152/225000 (11%)] Loss: 19519.593750\n",
      "Train Epoch: 124 [27648/225000 (12%)] Loss: 19837.175781\n",
      "Train Epoch: 124 [30144/225000 (13%)] Loss: 19194.830078\n",
      "Train Epoch: 124 [32640/225000 (15%)] Loss: 19270.283203\n",
      "Train Epoch: 124 [35136/225000 (16%)] Loss: 18426.705078\n",
      "Train Epoch: 124 [37632/225000 (17%)] Loss: 19365.250000\n",
      "Train Epoch: 124 [40128/225000 (18%)] Loss: 19727.152344\n",
      "Train Epoch: 124 [42624/225000 (19%)] Loss: 19598.878906\n",
      "Train Epoch: 124 [45120/225000 (20%)] Loss: 19099.757812\n",
      "Train Epoch: 124 [47616/225000 (21%)] Loss: 19102.035156\n",
      "Train Epoch: 124 [50112/225000 (22%)] Loss: 18884.972656\n",
      "Train Epoch: 124 [52608/225000 (23%)] Loss: 19496.927734\n",
      "Train Epoch: 124 [55104/225000 (24%)] Loss: 19633.335938\n",
      "Train Epoch: 124 [57600/225000 (26%)] Loss: 19525.781250\n",
      "Train Epoch: 124 [60096/225000 (27%)] Loss: 19376.847656\n",
      "Train Epoch: 124 [62592/225000 (28%)] Loss: 19337.427734\n",
      "Train Epoch: 124 [65088/225000 (29%)] Loss: 19103.597656\n",
      "Train Epoch: 124 [67584/225000 (30%)] Loss: 19277.250000\n",
      "Train Epoch: 124 [70080/225000 (31%)] Loss: 18885.416016\n",
      "Train Epoch: 124 [72576/225000 (32%)] Loss: 18984.408203\n",
      "Train Epoch: 124 [75072/225000 (33%)] Loss: 19439.359375\n",
      "Train Epoch: 124 [77568/225000 (34%)] Loss: 18701.746094\n",
      "Train Epoch: 124 [80064/225000 (36%)] Loss: 19269.923828\n",
      "Train Epoch: 124 [82560/225000 (37%)] Loss: 19498.044922\n",
      "Train Epoch: 124 [85056/225000 (38%)] Loss: 19014.859375\n",
      "Train Epoch: 124 [87552/225000 (39%)] Loss: 19163.074219\n",
      "Train Epoch: 124 [90048/225000 (40%)] Loss: 19335.451172\n",
      "Train Epoch: 124 [92544/225000 (41%)] Loss: 19638.984375\n",
      "Train Epoch: 124 [95040/225000 (42%)] Loss: 18924.195312\n",
      "Train Epoch: 124 [97536/225000 (43%)] Loss: 19918.244141\n",
      "Train Epoch: 124 [100032/225000 (44%)] Loss: 19380.699219\n",
      "Train Epoch: 124 [102528/225000 (46%)] Loss: 19388.777344\n",
      "Train Epoch: 124 [105024/225000 (47%)] Loss: 19635.181641\n",
      "Train Epoch: 124 [107520/225000 (48%)] Loss: 19309.507812\n",
      "Train Epoch: 124 [110016/225000 (49%)] Loss: 18602.458984\n",
      "Train Epoch: 124 [112512/225000 (50%)] Loss: 19320.664062\n",
      "Train Epoch: 124 [115008/225000 (51%)] Loss: 19616.521484\n",
      "Train Epoch: 124 [117504/225000 (52%)] Loss: 19459.738281\n",
      "Train Epoch: 124 [120000/225000 (53%)] Loss: 19412.888672\n",
      "Train Epoch: 124 [122496/225000 (54%)] Loss: 19591.750000\n",
      "Train Epoch: 124 [124992/225000 (56%)] Loss: 19367.220703\n",
      "Train Epoch: 124 [127488/225000 (57%)] Loss: 19945.763672\n",
      "Train Epoch: 124 [129984/225000 (58%)] Loss: 19293.675781\n",
      "Train Epoch: 124 [132480/225000 (59%)] Loss: 19001.468750\n",
      "Train Epoch: 124 [134976/225000 (60%)] Loss: 19626.814453\n",
      "Train Epoch: 124 [137472/225000 (61%)] Loss: 19607.308594\n",
      "Train Epoch: 124 [139968/225000 (62%)] Loss: 19355.289062\n",
      "Train Epoch: 124 [142464/225000 (63%)] Loss: 19743.414062\n",
      "Train Epoch: 124 [144960/225000 (64%)] Loss: 19217.804688\n",
      "Train Epoch: 124 [147456/225000 (66%)] Loss: 19334.537109\n",
      "Train Epoch: 124 [149952/225000 (67%)] Loss: 19132.712891\n",
      "Train Epoch: 124 [152448/225000 (68%)] Loss: 19240.566406\n",
      "Train Epoch: 124 [154944/225000 (69%)] Loss: 19796.806641\n",
      "Train Epoch: 124 [157440/225000 (70%)] Loss: 19453.554688\n",
      "Train Epoch: 124 [159936/225000 (71%)] Loss: 19405.117188\n",
      "Train Epoch: 124 [162432/225000 (72%)] Loss: 19064.957031\n",
      "Train Epoch: 124 [164928/225000 (73%)] Loss: 19534.990234\n",
      "Train Epoch: 124 [167424/225000 (74%)] Loss: 20055.273438\n",
      "Train Epoch: 124 [169920/225000 (76%)] Loss: 19204.726562\n",
      "Train Epoch: 124 [172416/225000 (77%)] Loss: 19064.351562\n",
      "Train Epoch: 124 [174912/225000 (78%)] Loss: 19536.011719\n",
      "Train Epoch: 124 [177408/225000 (79%)] Loss: 19532.234375\n",
      "Train Epoch: 124 [179904/225000 (80%)] Loss: 19119.519531\n",
      "Train Epoch: 124 [182400/225000 (81%)] Loss: 19284.656250\n",
      "Train Epoch: 124 [184896/225000 (82%)] Loss: 19416.824219\n",
      "Train Epoch: 124 [187392/225000 (83%)] Loss: 19554.875000\n",
      "Train Epoch: 124 [189888/225000 (84%)] Loss: 19173.257812\n",
      "Train Epoch: 124 [192384/225000 (86%)] Loss: 19261.273438\n",
      "Train Epoch: 124 [194880/225000 (87%)] Loss: 19654.625000\n",
      "Train Epoch: 124 [197376/225000 (88%)] Loss: 19251.375000\n",
      "Train Epoch: 124 [199872/225000 (89%)] Loss: 19200.925781\n",
      "Train Epoch: 124 [202368/225000 (90%)] Loss: 19669.394531\n",
      "Train Epoch: 124 [204864/225000 (91%)] Loss: 19469.253906\n",
      "Train Epoch: 124 [207360/225000 (92%)] Loss: 19587.347656\n",
      "Train Epoch: 124 [209856/225000 (93%)] Loss: 19310.425781\n",
      "Train Epoch: 124 [212352/225000 (94%)] Loss: 19351.800781\n",
      "Train Epoch: 124 [214848/225000 (95%)] Loss: 19058.460938\n",
      "Train Epoch: 124 [217344/225000 (97%)] Loss: 19339.421875\n",
      "Train Epoch: 124 [219840/225000 (98%)] Loss: 19507.238281\n",
      "Train Epoch: 124 [222336/225000 (99%)] Loss: 19590.804688\n",
      "Train Epoch: 124 [224832/225000 (100%)] Loss: 19175.089844\n",
      "    epoch          : 124\n",
      "    loss           : 19349.298424834684\n",
      "    val_loss       : 19260.215925427794\n",
      "Train Epoch: 125 [192/225000 (0%)] Loss: 19211.339844\n",
      "Train Epoch: 125 [2688/225000 (1%)] Loss: 19081.822266\n",
      "Train Epoch: 125 [5184/225000 (2%)] Loss: 18860.933594\n",
      "Train Epoch: 125 [7680/225000 (3%)] Loss: 19240.925781\n",
      "Train Epoch: 125 [10176/225000 (5%)] Loss: 19844.589844\n",
      "Train Epoch: 125 [12672/225000 (6%)] Loss: 19820.958984\n",
      "Train Epoch: 125 [15168/225000 (7%)] Loss: 19298.957031\n",
      "Train Epoch: 125 [17664/225000 (8%)] Loss: 19450.488281\n",
      "Train Epoch: 125 [20160/225000 (9%)] Loss: 19581.527344\n",
      "Train Epoch: 125 [22656/225000 (10%)] Loss: 19019.687500\n",
      "Train Epoch: 125 [25152/225000 (11%)] Loss: 18808.066406\n",
      "Train Epoch: 125 [27648/225000 (12%)] Loss: 19137.007812\n",
      "Train Epoch: 125 [30144/225000 (13%)] Loss: 20170.857422\n",
      "Train Epoch: 125 [32640/225000 (15%)] Loss: 18967.486328\n",
      "Train Epoch: 125 [35136/225000 (16%)] Loss: 19609.611328\n",
      "Train Epoch: 125 [37632/225000 (17%)] Loss: 19325.708984\n",
      "Train Epoch: 125 [40128/225000 (18%)] Loss: 19109.433594\n",
      "Train Epoch: 125 [42624/225000 (19%)] Loss: 19380.992188\n",
      "Train Epoch: 125 [45120/225000 (20%)] Loss: 19072.933594\n",
      "Train Epoch: 125 [47616/225000 (21%)] Loss: 19793.566406\n",
      "Train Epoch: 125 [50112/225000 (22%)] Loss: 19515.070312\n",
      "Train Epoch: 125 [52608/225000 (23%)] Loss: 19405.574219\n",
      "Train Epoch: 125 [55104/225000 (24%)] Loss: 19405.326172\n",
      "Train Epoch: 125 [57600/225000 (26%)] Loss: 19386.050781\n",
      "Train Epoch: 125 [60096/225000 (27%)] Loss: 19222.917969\n",
      "Train Epoch: 125 [62592/225000 (28%)] Loss: 19487.382812\n",
      "Train Epoch: 125 [65088/225000 (29%)] Loss: 19193.820312\n",
      "Train Epoch: 125 [67584/225000 (30%)] Loss: 19351.750000\n",
      "Train Epoch: 125 [70080/225000 (31%)] Loss: 19765.900391\n",
      "Train Epoch: 125 [72576/225000 (32%)] Loss: 19286.357422\n",
      "Train Epoch: 125 [75072/225000 (33%)] Loss: 18983.222656\n",
      "Train Epoch: 125 [77568/225000 (34%)] Loss: 19074.070312\n",
      "Train Epoch: 125 [80064/225000 (36%)] Loss: 19203.839844\n",
      "Train Epoch: 125 [82560/225000 (37%)] Loss: 19205.968750\n",
      "Train Epoch: 125 [85056/225000 (38%)] Loss: 19512.230469\n",
      "Train Epoch: 125 [87552/225000 (39%)] Loss: 19357.023438\n",
      "Train Epoch: 125 [90048/225000 (40%)] Loss: 19416.384766\n",
      "Train Epoch: 125 [92544/225000 (41%)] Loss: 19404.316406\n",
      "Train Epoch: 125 [95040/225000 (42%)] Loss: 19212.953125\n",
      "Train Epoch: 125 [97536/225000 (43%)] Loss: 19217.560547\n",
      "Train Epoch: 125 [100032/225000 (44%)] Loss: 19075.302734\n",
      "Train Epoch: 125 [102528/225000 (46%)] Loss: 19450.503906\n",
      "Train Epoch: 125 [105024/225000 (47%)] Loss: 19510.519531\n",
      "Train Epoch: 125 [107520/225000 (48%)] Loss: 19243.425781\n",
      "Train Epoch: 125 [110016/225000 (49%)] Loss: 19624.464844\n",
      "Train Epoch: 125 [112512/225000 (50%)] Loss: 19606.781250\n",
      "Train Epoch: 125 [115008/225000 (51%)] Loss: 19380.257812\n",
      "Train Epoch: 125 [117504/225000 (52%)] Loss: 19027.886719\n",
      "Train Epoch: 125 [120000/225000 (53%)] Loss: 19353.167969\n",
      "Train Epoch: 125 [122496/225000 (54%)] Loss: 19026.861328\n",
      "Train Epoch: 125 [124992/225000 (56%)] Loss: 19164.343750\n",
      "Train Epoch: 125 [127488/225000 (57%)] Loss: 19655.542969\n",
      "Train Epoch: 125 [129984/225000 (58%)] Loss: 19143.605469\n",
      "Train Epoch: 125 [132480/225000 (59%)] Loss: 19370.964844\n",
      "Train Epoch: 125 [134976/225000 (60%)] Loss: 19425.824219\n",
      "Train Epoch: 125 [137472/225000 (61%)] Loss: 19472.748047\n",
      "Train Epoch: 125 [139968/225000 (62%)] Loss: 19344.812500\n",
      "Train Epoch: 125 [142464/225000 (63%)] Loss: 19791.214844\n",
      "Train Epoch: 125 [144960/225000 (64%)] Loss: 19544.720703\n",
      "Train Epoch: 125 [147456/225000 (66%)] Loss: 19635.562500\n",
      "Train Epoch: 125 [149952/225000 (67%)] Loss: 19382.988281\n",
      "Train Epoch: 125 [152448/225000 (68%)] Loss: 19525.816406\n",
      "Train Epoch: 125 [154944/225000 (69%)] Loss: 19595.265625\n",
      "Train Epoch: 125 [157440/225000 (70%)] Loss: 19309.859375\n",
      "Train Epoch: 125 [159936/225000 (71%)] Loss: 19040.710938\n",
      "Train Epoch: 125 [162432/225000 (72%)] Loss: 19371.351562\n",
      "Train Epoch: 125 [164928/225000 (73%)] Loss: 19457.718750\n",
      "Train Epoch: 125 [167424/225000 (74%)] Loss: 19517.765625\n",
      "Train Epoch: 125 [169920/225000 (76%)] Loss: 18845.378906\n",
      "Train Epoch: 125 [172416/225000 (77%)] Loss: 19577.183594\n",
      "Train Epoch: 125 [174912/225000 (78%)] Loss: 19338.005859\n",
      "Train Epoch: 125 [177408/225000 (79%)] Loss: 19450.058594\n",
      "Train Epoch: 125 [179904/225000 (80%)] Loss: 18732.865234\n",
      "Train Epoch: 125 [182400/225000 (81%)] Loss: 19570.550781\n",
      "Train Epoch: 125 [184896/225000 (82%)] Loss: 19550.390625\n",
      "Train Epoch: 125 [187392/225000 (83%)] Loss: 19343.755859\n",
      "Train Epoch: 125 [189888/225000 (84%)] Loss: 18884.638672\n",
      "Train Epoch: 125 [192384/225000 (86%)] Loss: 19369.593750\n",
      "Train Epoch: 125 [194880/225000 (87%)] Loss: 19448.765625\n",
      "Train Epoch: 125 [197376/225000 (88%)] Loss: 20060.330078\n",
      "Train Epoch: 125 [199872/225000 (89%)] Loss: 19229.359375\n",
      "Train Epoch: 125 [202368/225000 (90%)] Loss: 19951.910156\n",
      "Train Epoch: 125 [204864/225000 (91%)] Loss: 18546.757812\n",
      "Train Epoch: 125 [207360/225000 (92%)] Loss: 19390.390625\n",
      "Train Epoch: 125 [209856/225000 (93%)] Loss: 19481.312500\n",
      "Train Epoch: 125 [212352/225000 (94%)] Loss: 19250.496094\n",
      "Train Epoch: 125 [214848/225000 (95%)] Loss: 19554.472656\n",
      "Train Epoch: 125 [217344/225000 (97%)] Loss: 19082.054688\n",
      "Train Epoch: 125 [219840/225000 (98%)] Loss: 19191.484375\n",
      "Train Epoch: 125 [222336/225000 (99%)] Loss: 19136.765625\n",
      "Train Epoch: 125 [224832/225000 (100%)] Loss: 19727.343750\n",
      "    epoch          : 125\n",
      "    loss           : 19345.89476455845\n",
      "    val_loss       : 19277.273218604445\n",
      "Train Epoch: 126 [192/225000 (0%)] Loss: 19284.457031\n",
      "Train Epoch: 126 [2688/225000 (1%)] Loss: 19490.890625\n",
      "Train Epoch: 126 [5184/225000 (2%)] Loss: 19739.187500\n",
      "Train Epoch: 126 [7680/225000 (3%)] Loss: 19001.546875\n",
      "Train Epoch: 126 [10176/225000 (5%)] Loss: 19315.513672\n",
      "Train Epoch: 126 [12672/225000 (6%)] Loss: 19309.296875\n",
      "Train Epoch: 126 [15168/225000 (7%)] Loss: 19459.578125\n",
      "Train Epoch: 126 [17664/225000 (8%)] Loss: 19662.734375\n",
      "Train Epoch: 126 [20160/225000 (9%)] Loss: 19279.437500\n",
      "Train Epoch: 126 [22656/225000 (10%)] Loss: 19254.615234\n",
      "Train Epoch: 126 [25152/225000 (11%)] Loss: 19326.792969\n",
      "Train Epoch: 126 [27648/225000 (12%)] Loss: 19493.085938\n",
      "Train Epoch: 126 [30144/225000 (13%)] Loss: 19087.855469\n",
      "Train Epoch: 126 [32640/225000 (15%)] Loss: 19189.820312\n",
      "Train Epoch: 126 [35136/225000 (16%)] Loss: 19398.439453\n",
      "Train Epoch: 126 [37632/225000 (17%)] Loss: 19240.203125\n",
      "Train Epoch: 126 [40128/225000 (18%)] Loss: 19215.367188\n",
      "Train Epoch: 126 [42624/225000 (19%)] Loss: 19183.722656\n",
      "Train Epoch: 126 [45120/225000 (20%)] Loss: 19266.501953\n",
      "Train Epoch: 126 [47616/225000 (21%)] Loss: 19181.246094\n",
      "Train Epoch: 126 [50112/225000 (22%)] Loss: 19366.558594\n",
      "Train Epoch: 126 [52608/225000 (23%)] Loss: 19497.816406\n",
      "Train Epoch: 126 [55104/225000 (24%)] Loss: 19714.980469\n",
      "Train Epoch: 126 [57600/225000 (26%)] Loss: 19270.875000\n",
      "Train Epoch: 126 [60096/225000 (27%)] Loss: 19429.185547\n",
      "Train Epoch: 126 [62592/225000 (28%)] Loss: 19579.285156\n",
      "Train Epoch: 126 [65088/225000 (29%)] Loss: 19006.501953\n",
      "Train Epoch: 126 [67584/225000 (30%)] Loss: 19691.183594\n",
      "Train Epoch: 126 [70080/225000 (31%)] Loss: 19245.218750\n",
      "Train Epoch: 126 [72576/225000 (32%)] Loss: 18839.394531\n",
      "Train Epoch: 126 [75072/225000 (33%)] Loss: 19363.144531\n",
      "Train Epoch: 126 [77568/225000 (34%)] Loss: 19559.203125\n",
      "Train Epoch: 126 [80064/225000 (36%)] Loss: 19396.742188\n",
      "Train Epoch: 126 [82560/225000 (37%)] Loss: 19663.746094\n",
      "Train Epoch: 126 [85056/225000 (38%)] Loss: 19112.220703\n",
      "Train Epoch: 126 [87552/225000 (39%)] Loss: 19119.222656\n",
      "Train Epoch: 126 [90048/225000 (40%)] Loss: 19882.187500\n",
      "Train Epoch: 126 [92544/225000 (41%)] Loss: 19400.591797\n",
      "Train Epoch: 126 [95040/225000 (42%)] Loss: 19229.027344\n",
      "Train Epoch: 126 [97536/225000 (43%)] Loss: 19134.255859\n",
      "Train Epoch: 126 [100032/225000 (44%)] Loss: 19434.642578\n",
      "Train Epoch: 126 [102528/225000 (46%)] Loss: 19217.126953\n",
      "Train Epoch: 126 [105024/225000 (47%)] Loss: 19539.482422\n",
      "Train Epoch: 126 [107520/225000 (48%)] Loss: 19390.195312\n",
      "Train Epoch: 126 [110016/225000 (49%)] Loss: 19874.683594\n",
      "Train Epoch: 126 [112512/225000 (50%)] Loss: 19333.560547\n",
      "Train Epoch: 126 [115008/225000 (51%)] Loss: 18982.683594\n",
      "Train Epoch: 126 [117504/225000 (52%)] Loss: 19094.761719\n",
      "Train Epoch: 126 [120000/225000 (53%)] Loss: 19164.968750\n",
      "Train Epoch: 126 [122496/225000 (54%)] Loss: 18903.859375\n",
      "Train Epoch: 126 [124992/225000 (56%)] Loss: 19333.269531\n",
      "Train Epoch: 126 [127488/225000 (57%)] Loss: 19552.802734\n",
      "Train Epoch: 126 [129984/225000 (58%)] Loss: 19268.189453\n",
      "Train Epoch: 126 [132480/225000 (59%)] Loss: 19428.746094\n",
      "Train Epoch: 126 [134976/225000 (60%)] Loss: 19528.855469\n",
      "Train Epoch: 126 [137472/225000 (61%)] Loss: 19140.078125\n",
      "Train Epoch: 126 [139968/225000 (62%)] Loss: 19380.785156\n",
      "Train Epoch: 126 [142464/225000 (63%)] Loss: 19509.191406\n",
      "Train Epoch: 126 [144960/225000 (64%)] Loss: 19284.226562\n",
      "Train Epoch: 126 [147456/225000 (66%)] Loss: 19472.861328\n",
      "Train Epoch: 126 [149952/225000 (67%)] Loss: 19463.603516\n",
      "Train Epoch: 126 [152448/225000 (68%)] Loss: 19355.472656\n",
      "Train Epoch: 126 [154944/225000 (69%)] Loss: 19359.849609\n",
      "Train Epoch: 126 [157440/225000 (70%)] Loss: 19109.351562\n",
      "Train Epoch: 126 [159936/225000 (71%)] Loss: 19081.058594\n",
      "Train Epoch: 126 [162432/225000 (72%)] Loss: 19465.410156\n",
      "Train Epoch: 126 [164928/225000 (73%)] Loss: 19679.835938\n",
      "Train Epoch: 126 [167424/225000 (74%)] Loss: 19369.082031\n",
      "Train Epoch: 126 [169920/225000 (76%)] Loss: 19679.353516\n",
      "Train Epoch: 126 [172416/225000 (77%)] Loss: 19400.304688\n",
      "Train Epoch: 126 [174912/225000 (78%)] Loss: 19025.248047\n",
      "Train Epoch: 126 [177408/225000 (79%)] Loss: 19960.435547\n",
      "Train Epoch: 126 [179904/225000 (80%)] Loss: 19486.970703\n",
      "Train Epoch: 126 [182400/225000 (81%)] Loss: 19337.261719\n",
      "Train Epoch: 126 [184896/225000 (82%)] Loss: 19655.296875\n",
      "Train Epoch: 126 [187392/225000 (83%)] Loss: 19137.511719\n",
      "Train Epoch: 126 [189888/225000 (84%)] Loss: 19293.746094\n",
      "Train Epoch: 126 [192384/225000 (86%)] Loss: 18659.148438\n",
      "Train Epoch: 126 [194880/225000 (87%)] Loss: 19400.035156\n",
      "Train Epoch: 126 [197376/225000 (88%)] Loss: 19074.871094\n",
      "Train Epoch: 126 [199872/225000 (89%)] Loss: 19347.359375\n",
      "Train Epoch: 126 [202368/225000 (90%)] Loss: 19321.082031\n",
      "Train Epoch: 126 [204864/225000 (91%)] Loss: 19137.539062\n",
      "Train Epoch: 126 [207360/225000 (92%)] Loss: 19113.466797\n",
      "Train Epoch: 126 [209856/225000 (93%)] Loss: 19678.945312\n",
      "Train Epoch: 126 [212352/225000 (94%)] Loss: 19510.640625\n",
      "Train Epoch: 126 [214848/225000 (95%)] Loss: 19374.476562\n",
      "Train Epoch: 126 [217344/225000 (97%)] Loss: 19394.578125\n",
      "Train Epoch: 126 [219840/225000 (98%)] Loss: 19289.394531\n",
      "Train Epoch: 126 [222336/225000 (99%)] Loss: 19360.320312\n",
      "Train Epoch: 126 [224832/225000 (100%)] Loss: 19003.378906\n",
      "    epoch          : 126\n",
      "    loss           : 19351.213045608467\n",
      "    val_loss       : 19248.259266990743\n",
      "Train Epoch: 127 [192/225000 (0%)] Loss: 19310.988281\n",
      "Train Epoch: 127 [2688/225000 (1%)] Loss: 19089.089844\n",
      "Train Epoch: 127 [5184/225000 (2%)] Loss: 19183.111328\n",
      "Train Epoch: 127 [7680/225000 (3%)] Loss: 18838.941406\n",
      "Train Epoch: 127 [10176/225000 (5%)] Loss: 19107.009766\n",
      "Train Epoch: 127 [12672/225000 (6%)] Loss: 18665.394531\n",
      "Train Epoch: 127 [15168/225000 (7%)] Loss: 19470.630859\n",
      "Train Epoch: 127 [17664/225000 (8%)] Loss: 19487.488281\n",
      "Train Epoch: 127 [20160/225000 (9%)] Loss: 19267.152344\n",
      "Train Epoch: 127 [22656/225000 (10%)] Loss: 19078.257812\n",
      "Train Epoch: 127 [25152/225000 (11%)] Loss: 19444.242188\n",
      "Train Epoch: 127 [27648/225000 (12%)] Loss: 19677.578125\n",
      "Train Epoch: 127 [30144/225000 (13%)] Loss: 19610.548828\n",
      "Train Epoch: 127 [32640/225000 (15%)] Loss: 18996.205078\n",
      "Train Epoch: 127 [35136/225000 (16%)] Loss: 19283.953125\n",
      "Train Epoch: 127 [37632/225000 (17%)] Loss: 19389.808594\n",
      "Train Epoch: 127 [40128/225000 (18%)] Loss: 18901.552734\n",
      "Train Epoch: 127 [42624/225000 (19%)] Loss: 18897.722656\n",
      "Train Epoch: 127 [45120/225000 (20%)] Loss: 19086.429688\n",
      "Train Epoch: 127 [47616/225000 (21%)] Loss: 19281.796875\n",
      "Train Epoch: 127 [50112/225000 (22%)] Loss: 19334.226562\n",
      "Train Epoch: 127 [52608/225000 (23%)] Loss: 19474.917969\n",
      "Train Epoch: 127 [55104/225000 (24%)] Loss: 19081.109375\n",
      "Train Epoch: 127 [57600/225000 (26%)] Loss: 19578.873047\n",
      "Train Epoch: 127 [60096/225000 (27%)] Loss: 19356.412109\n",
      "Train Epoch: 127 [62592/225000 (28%)] Loss: 18757.078125\n",
      "Train Epoch: 127 [65088/225000 (29%)] Loss: 19542.292969\n",
      "Train Epoch: 127 [67584/225000 (30%)] Loss: 19334.746094\n",
      "Train Epoch: 127 [70080/225000 (31%)] Loss: 19074.222656\n",
      "Train Epoch: 127 [72576/225000 (32%)] Loss: 19524.777344\n",
      "Train Epoch: 127 [75072/225000 (33%)] Loss: 20088.398438\n",
      "Train Epoch: 127 [77568/225000 (34%)] Loss: 19939.734375\n",
      "Train Epoch: 127 [80064/225000 (36%)] Loss: 19518.367188\n",
      "Train Epoch: 127 [82560/225000 (37%)] Loss: 19156.626953\n",
      "Train Epoch: 127 [85056/225000 (38%)] Loss: 19002.281250\n",
      "Train Epoch: 127 [87552/225000 (39%)] Loss: 19165.453125\n",
      "Train Epoch: 127 [90048/225000 (40%)] Loss: 19758.857422\n",
      "Train Epoch: 127 [92544/225000 (41%)] Loss: 19696.646484\n",
      "Train Epoch: 127 [95040/225000 (42%)] Loss: 19330.027344\n",
      "Train Epoch: 127 [97536/225000 (43%)] Loss: 18922.833984\n",
      "Train Epoch: 127 [100032/225000 (44%)] Loss: 19139.652344\n",
      "Train Epoch: 127 [102528/225000 (46%)] Loss: 19722.289062\n",
      "Train Epoch: 127 [105024/225000 (47%)] Loss: 19400.906250\n",
      "Train Epoch: 127 [107520/225000 (48%)] Loss: 19638.238281\n",
      "Train Epoch: 127 [110016/225000 (49%)] Loss: 19160.523438\n",
      "Train Epoch: 127 [112512/225000 (50%)] Loss: 19609.398438\n",
      "Train Epoch: 127 [115008/225000 (51%)] Loss: 19485.250000\n",
      "Train Epoch: 127 [117504/225000 (52%)] Loss: 19312.613281\n",
      "Train Epoch: 127 [120000/225000 (53%)] Loss: 19036.246094\n",
      "Train Epoch: 127 [122496/225000 (54%)] Loss: 19142.509766\n",
      "Train Epoch: 127 [124992/225000 (56%)] Loss: 19538.937500\n",
      "Train Epoch: 127 [127488/225000 (57%)] Loss: 19463.335938\n",
      "Train Epoch: 127 [129984/225000 (58%)] Loss: 19605.486328\n",
      "Train Epoch: 127 [132480/225000 (59%)] Loss: 19375.632812\n",
      "Train Epoch: 127 [134976/225000 (60%)] Loss: 19122.263672\n",
      "Train Epoch: 127 [137472/225000 (61%)] Loss: 19222.376953\n",
      "Train Epoch: 127 [139968/225000 (62%)] Loss: 19464.910156\n",
      "Train Epoch: 127 [142464/225000 (63%)] Loss: 19099.935547\n",
      "Train Epoch: 127 [144960/225000 (64%)] Loss: 19499.316406\n",
      "Train Epoch: 127 [147456/225000 (66%)] Loss: 19188.710938\n",
      "Train Epoch: 127 [149952/225000 (67%)] Loss: 19177.992188\n",
      "Train Epoch: 127 [152448/225000 (68%)] Loss: 19270.158203\n",
      "Train Epoch: 127 [154944/225000 (69%)] Loss: 19691.117188\n",
      "Train Epoch: 127 [157440/225000 (70%)] Loss: 19412.156250\n",
      "Train Epoch: 127 [159936/225000 (71%)] Loss: 19518.802734\n",
      "Train Epoch: 127 [162432/225000 (72%)] Loss: 19042.675781\n",
      "Train Epoch: 127 [164928/225000 (73%)] Loss: 19524.476562\n",
      "Train Epoch: 127 [167424/225000 (74%)] Loss: 19649.363281\n",
      "Train Epoch: 127 [169920/225000 (76%)] Loss: 18892.523438\n",
      "Train Epoch: 127 [172416/225000 (77%)] Loss: 19451.425781\n",
      "Train Epoch: 127 [174912/225000 (78%)] Loss: 19352.937500\n",
      "Train Epoch: 127 [177408/225000 (79%)] Loss: 19242.476562\n",
      "Train Epoch: 127 [179904/225000 (80%)] Loss: 19440.960938\n",
      "Train Epoch: 127 [182400/225000 (81%)] Loss: 18683.210938\n",
      "Train Epoch: 127 [184896/225000 (82%)] Loss: 19694.818359\n",
      "Train Epoch: 127 [187392/225000 (83%)] Loss: 19588.167969\n",
      "Train Epoch: 127 [189888/225000 (84%)] Loss: 19516.566406\n",
      "Train Epoch: 127 [192384/225000 (86%)] Loss: 19580.691406\n",
      "Train Epoch: 127 [194880/225000 (87%)] Loss: 19381.335938\n",
      "Train Epoch: 127 [197376/225000 (88%)] Loss: 19400.109375\n",
      "Train Epoch: 127 [199872/225000 (89%)] Loss: 19248.867188\n",
      "Train Epoch: 127 [202368/225000 (90%)] Loss: 19571.265625\n",
      "Train Epoch: 127 [204864/225000 (91%)] Loss: 19065.085938\n",
      "Train Epoch: 127 [207360/225000 (92%)] Loss: 19083.875000\n",
      "Train Epoch: 127 [209856/225000 (93%)] Loss: 19039.386719\n",
      "Train Epoch: 127 [212352/225000 (94%)] Loss: 19632.419922\n",
      "Train Epoch: 127 [214848/225000 (95%)] Loss: 18973.416016\n",
      "Train Epoch: 127 [217344/225000 (97%)] Loss: 19270.083984\n",
      "Train Epoch: 127 [219840/225000 (98%)] Loss: 19558.392578\n",
      "Train Epoch: 127 [222336/225000 (99%)] Loss: 19370.960938\n",
      "Train Epoch: 127 [224832/225000 (100%)] Loss: 19145.683594\n",
      "    epoch          : 127\n",
      "    loss           : 19341.51002226429\n",
      "    val_loss       : 19244.06972690757\n",
      "Train Epoch: 128 [192/225000 (0%)] Loss: 19492.062500\n",
      "Train Epoch: 128 [2688/225000 (1%)] Loss: 19382.160156\n",
      "Train Epoch: 128 [5184/225000 (2%)] Loss: 19380.951172\n",
      "Train Epoch: 128 [7680/225000 (3%)] Loss: 19790.503906\n",
      "Train Epoch: 128 [10176/225000 (5%)] Loss: 19929.371094\n",
      "Train Epoch: 128 [12672/225000 (6%)] Loss: 20134.029297\n",
      "Train Epoch: 128 [15168/225000 (7%)] Loss: 19451.789062\n",
      "Train Epoch: 128 [17664/225000 (8%)] Loss: 19612.296875\n",
      "Train Epoch: 128 [20160/225000 (9%)] Loss: 19730.570312\n",
      "Train Epoch: 128 [22656/225000 (10%)] Loss: 19321.242188\n",
      "Train Epoch: 128 [25152/225000 (11%)] Loss: 20019.664062\n",
      "Train Epoch: 128 [27648/225000 (12%)] Loss: 19251.740234\n",
      "Train Epoch: 128 [30144/225000 (13%)] Loss: 19189.886719\n",
      "Train Epoch: 128 [32640/225000 (15%)] Loss: 18889.703125\n",
      "Train Epoch: 128 [35136/225000 (16%)] Loss: 19718.464844\n",
      "Train Epoch: 128 [37632/225000 (17%)] Loss: 19148.476562\n",
      "Train Epoch: 128 [40128/225000 (18%)] Loss: 18679.675781\n",
      "Train Epoch: 128 [42624/225000 (19%)] Loss: 19242.335938\n",
      "Train Epoch: 128 [45120/225000 (20%)] Loss: 19102.664062\n",
      "Train Epoch: 128 [47616/225000 (21%)] Loss: 19332.617188\n",
      "Train Epoch: 128 [50112/225000 (22%)] Loss: 19459.511719\n",
      "Train Epoch: 128 [52608/225000 (23%)] Loss: 19304.992188\n",
      "Train Epoch: 128 [55104/225000 (24%)] Loss: 19094.324219\n",
      "Train Epoch: 128 [57600/225000 (26%)] Loss: 19141.421875\n",
      "Train Epoch: 128 [60096/225000 (27%)] Loss: 19630.968750\n",
      "Train Epoch: 128 [62592/225000 (28%)] Loss: 18809.542969\n",
      "Train Epoch: 128 [65088/225000 (29%)] Loss: 19486.294922\n",
      "Train Epoch: 128 [67584/225000 (30%)] Loss: 19284.029297\n",
      "Train Epoch: 128 [70080/225000 (31%)] Loss: 19659.253906\n",
      "Train Epoch: 128 [72576/225000 (32%)] Loss: 19501.054688\n",
      "Train Epoch: 128 [75072/225000 (33%)] Loss: 18987.035156\n",
      "Train Epoch: 128 [77568/225000 (34%)] Loss: 19901.812500\n",
      "Train Epoch: 128 [80064/225000 (36%)] Loss: 19596.314453\n",
      "Train Epoch: 128 [82560/225000 (37%)] Loss: 19482.990234\n",
      "Train Epoch: 128 [85056/225000 (38%)] Loss: 19140.023438\n",
      "Train Epoch: 128 [87552/225000 (39%)] Loss: 19245.089844\n",
      "Train Epoch: 128 [90048/225000 (40%)] Loss: 18898.804688\n",
      "Train Epoch: 128 [92544/225000 (41%)] Loss: 19275.375000\n",
      "Train Epoch: 128 [95040/225000 (42%)] Loss: 19286.976562\n",
      "Train Epoch: 128 [97536/225000 (43%)] Loss: 19514.371094\n",
      "Train Epoch: 128 [100032/225000 (44%)] Loss: 18954.453125\n",
      "Train Epoch: 128 [102528/225000 (46%)] Loss: 19105.003906\n",
      "Train Epoch: 128 [105024/225000 (47%)] Loss: 18892.425781\n",
      "Train Epoch: 128 [107520/225000 (48%)] Loss: 19157.210938\n",
      "Train Epoch: 128 [110016/225000 (49%)] Loss: 19058.453125\n",
      "Train Epoch: 128 [112512/225000 (50%)] Loss: 19249.824219\n",
      "Train Epoch: 128 [115008/225000 (51%)] Loss: 19267.867188\n",
      "Train Epoch: 128 [117504/225000 (52%)] Loss: 19479.972656\n",
      "Train Epoch: 128 [120000/225000 (53%)] Loss: 19629.765625\n",
      "Train Epoch: 128 [122496/225000 (54%)] Loss: 19253.005859\n",
      "Train Epoch: 128 [124992/225000 (56%)] Loss: 19190.472656\n",
      "Train Epoch: 128 [127488/225000 (57%)] Loss: 19532.171875\n",
      "Train Epoch: 128 [129984/225000 (58%)] Loss: 19918.171875\n",
      "Train Epoch: 128 [132480/225000 (59%)] Loss: 19452.433594\n",
      "Train Epoch: 128 [134976/225000 (60%)] Loss: 19426.626953\n",
      "Train Epoch: 128 [137472/225000 (61%)] Loss: 18905.148438\n",
      "Train Epoch: 128 [139968/225000 (62%)] Loss: 19649.261719\n",
      "Train Epoch: 128 [142464/225000 (63%)] Loss: 18905.376953\n",
      "Train Epoch: 128 [144960/225000 (64%)] Loss: 18869.585938\n",
      "Train Epoch: 128 [147456/225000 (66%)] Loss: 19074.269531\n",
      "Train Epoch: 128 [149952/225000 (67%)] Loss: 19193.873047\n",
      "Train Epoch: 128 [152448/225000 (68%)] Loss: 19356.076172\n",
      "Train Epoch: 128 [154944/225000 (69%)] Loss: 19441.910156\n",
      "Train Epoch: 128 [157440/225000 (70%)] Loss: 19647.351562\n",
      "Train Epoch: 128 [159936/225000 (71%)] Loss: 19201.390625\n",
      "Train Epoch: 128 [162432/225000 (72%)] Loss: 19623.757812\n",
      "Train Epoch: 128 [164928/225000 (73%)] Loss: 19403.792969\n",
      "Train Epoch: 128 [167424/225000 (74%)] Loss: 19212.142578\n",
      "Train Epoch: 128 [169920/225000 (76%)] Loss: 19183.851562\n",
      "Train Epoch: 128 [172416/225000 (77%)] Loss: 19400.830078\n",
      "Train Epoch: 128 [174912/225000 (78%)] Loss: 19399.425781\n",
      "Train Epoch: 128 [177408/225000 (79%)] Loss: 19253.351562\n",
      "Train Epoch: 128 [179904/225000 (80%)] Loss: 19440.662109\n",
      "Train Epoch: 128 [182400/225000 (81%)] Loss: 18930.078125\n",
      "Train Epoch: 128 [184896/225000 (82%)] Loss: 18745.736328\n",
      "Train Epoch: 128 [187392/225000 (83%)] Loss: 19120.171875\n",
      "Train Epoch: 128 [189888/225000 (84%)] Loss: 19656.337891\n",
      "Train Epoch: 128 [192384/225000 (86%)] Loss: 19586.234375\n",
      "Train Epoch: 128 [194880/225000 (87%)] Loss: 19483.562500\n",
      "Train Epoch: 128 [197376/225000 (88%)] Loss: 19411.177734\n",
      "Train Epoch: 128 [199872/225000 (89%)] Loss: 19054.800781\n",
      "Train Epoch: 128 [202368/225000 (90%)] Loss: 19676.285156\n",
      "Train Epoch: 128 [204864/225000 (91%)] Loss: 18980.148438\n",
      "Train Epoch: 128 [207360/225000 (92%)] Loss: 19671.873047\n",
      "Train Epoch: 128 [209856/225000 (93%)] Loss: 19590.855469\n",
      "Train Epoch: 128 [212352/225000 (94%)] Loss: 19032.896484\n",
      "Train Epoch: 128 [214848/225000 (95%)] Loss: 19631.386719\n",
      "Train Epoch: 128 [217344/225000 (97%)] Loss: 19235.675781\n",
      "Train Epoch: 128 [219840/225000 (98%)] Loss: 19494.546875\n",
      "Train Epoch: 128 [222336/225000 (99%)] Loss: 19363.527344\n",
      "Train Epoch: 128 [224832/225000 (100%)] Loss: 19136.652344\n",
      "    epoch          : 128\n",
      "    loss           : 19340.508992374147\n",
      "    val_loss       : 19244.07581962975\n",
      "Train Epoch: 129 [192/225000 (0%)] Loss: 19316.511719\n",
      "Train Epoch: 129 [2688/225000 (1%)] Loss: 19163.015625\n",
      "Train Epoch: 129 [5184/225000 (2%)] Loss: 19054.281250\n",
      "Train Epoch: 129 [7680/225000 (3%)] Loss: 19371.429688\n",
      "Train Epoch: 129 [10176/225000 (5%)] Loss: 19231.556641\n",
      "Train Epoch: 129 [12672/225000 (6%)] Loss: 19058.570312\n",
      "Train Epoch: 129 [15168/225000 (7%)] Loss: 18896.835938\n",
      "Train Epoch: 129 [17664/225000 (8%)] Loss: 19309.316406\n",
      "Train Epoch: 129 [20160/225000 (9%)] Loss: 19468.755859\n",
      "Train Epoch: 129 [22656/225000 (10%)] Loss: 18953.851562\n",
      "Train Epoch: 129 [25152/225000 (11%)] Loss: 19379.707031\n",
      "Train Epoch: 129 [27648/225000 (12%)] Loss: 19362.773438\n",
      "Train Epoch: 129 [30144/225000 (13%)] Loss: 19340.425781\n",
      "Train Epoch: 129 [32640/225000 (15%)] Loss: 19110.132812\n",
      "Train Epoch: 129 [35136/225000 (16%)] Loss: 19248.994141\n",
      "Train Epoch: 129 [37632/225000 (17%)] Loss: 19140.472656\n",
      "Train Epoch: 129 [40128/225000 (18%)] Loss: 19610.914062\n",
      "Train Epoch: 129 [42624/225000 (19%)] Loss: 19690.179688\n",
      "Train Epoch: 129 [45120/225000 (20%)] Loss: 19384.808594\n",
      "Train Epoch: 129 [47616/225000 (21%)] Loss: 19060.253906\n",
      "Train Epoch: 129 [50112/225000 (22%)] Loss: 18792.951172\n",
      "Train Epoch: 129 [52608/225000 (23%)] Loss: 19115.718750\n",
      "Train Epoch: 129 [55104/225000 (24%)] Loss: 19179.437500\n",
      "Train Epoch: 129 [57600/225000 (26%)] Loss: 19175.656250\n",
      "Train Epoch: 129 [60096/225000 (27%)] Loss: 19227.468750\n",
      "Train Epoch: 129 [62592/225000 (28%)] Loss: 19311.796875\n",
      "Train Epoch: 129 [65088/225000 (29%)] Loss: 19243.183594\n",
      "Train Epoch: 129 [67584/225000 (30%)] Loss: 19675.337891\n",
      "Train Epoch: 129 [70080/225000 (31%)] Loss: 19139.478516\n",
      "Train Epoch: 129 [72576/225000 (32%)] Loss: 19440.000000\n",
      "Train Epoch: 129 [75072/225000 (33%)] Loss: 19049.445312\n",
      "Train Epoch: 129 [77568/225000 (34%)] Loss: 19238.878906\n",
      "Train Epoch: 129 [80064/225000 (36%)] Loss: 18719.761719\n",
      "Train Epoch: 129 [82560/225000 (37%)] Loss: 19225.910156\n",
      "Train Epoch: 129 [85056/225000 (38%)] Loss: 19015.369141\n",
      "Train Epoch: 129 [87552/225000 (39%)] Loss: 19198.738281\n",
      "Train Epoch: 129 [90048/225000 (40%)] Loss: 19152.316406\n",
      "Train Epoch: 129 [92544/225000 (41%)] Loss: 19730.412109\n",
      "Train Epoch: 129 [95040/225000 (42%)] Loss: 19488.513672\n",
      "Train Epoch: 129 [97536/225000 (43%)] Loss: 19139.734375\n",
      "Train Epoch: 129 [100032/225000 (44%)] Loss: 19522.974609\n",
      "Train Epoch: 129 [102528/225000 (46%)] Loss: 19497.257812\n",
      "Train Epoch: 129 [105024/225000 (47%)] Loss: 19283.650391\n",
      "Train Epoch: 129 [107520/225000 (48%)] Loss: 19294.689453\n",
      "Train Epoch: 129 [110016/225000 (49%)] Loss: 19439.527344\n",
      "Train Epoch: 129 [112512/225000 (50%)] Loss: 19100.947266\n",
      "Train Epoch: 129 [115008/225000 (51%)] Loss: 18960.539062\n",
      "Train Epoch: 129 [117504/225000 (52%)] Loss: 19229.250000\n",
      "Train Epoch: 129 [120000/225000 (53%)] Loss: 19027.126953\n",
      "Train Epoch: 129 [122496/225000 (54%)] Loss: 19012.160156\n",
      "Train Epoch: 129 [124992/225000 (56%)] Loss: 19224.781250\n",
      "Train Epoch: 129 [127488/225000 (57%)] Loss: 19334.964844\n",
      "Train Epoch: 129 [129984/225000 (58%)] Loss: 19285.568359\n",
      "Train Epoch: 129 [132480/225000 (59%)] Loss: 19386.593750\n",
      "Train Epoch: 129 [134976/225000 (60%)] Loss: 19311.437500\n",
      "Train Epoch: 129 [137472/225000 (61%)] Loss: 19738.396484\n",
      "Train Epoch: 129 [139968/225000 (62%)] Loss: 19172.269531\n",
      "Train Epoch: 129 [142464/225000 (63%)] Loss: 19475.851562\n",
      "Train Epoch: 129 [144960/225000 (64%)] Loss: 19577.322266\n",
      "Train Epoch: 129 [147456/225000 (66%)] Loss: 19193.507812\n",
      "Train Epoch: 129 [149952/225000 (67%)] Loss: 19728.972656\n",
      "Train Epoch: 129 [152448/225000 (68%)] Loss: 19042.121094\n",
      "Train Epoch: 129 [154944/225000 (69%)] Loss: 19242.058594\n",
      "Train Epoch: 129 [157440/225000 (70%)] Loss: 19370.722656\n",
      "Train Epoch: 129 [159936/225000 (71%)] Loss: 19148.066406\n",
      "Train Epoch: 129 [162432/225000 (72%)] Loss: 19317.332031\n",
      "Train Epoch: 129 [164928/225000 (73%)] Loss: 19496.703125\n",
      "Train Epoch: 129 [167424/225000 (74%)] Loss: 19469.332031\n",
      "Train Epoch: 129 [169920/225000 (76%)] Loss: 19114.070312\n",
      "Train Epoch: 129 [172416/225000 (77%)] Loss: 19243.792969\n",
      "Train Epoch: 129 [174912/225000 (78%)] Loss: 18913.884766\n",
      "Train Epoch: 129 [177408/225000 (79%)] Loss: 19514.097656\n",
      "Train Epoch: 129 [179904/225000 (80%)] Loss: 19549.464844\n",
      "Train Epoch: 129 [182400/225000 (81%)] Loss: 18939.839844\n",
      "Train Epoch: 129 [184896/225000 (82%)] Loss: 18852.771484\n",
      "Train Epoch: 129 [187392/225000 (83%)] Loss: 19243.402344\n",
      "Train Epoch: 129 [189888/225000 (84%)] Loss: 18766.589844\n",
      "Train Epoch: 129 [192384/225000 (86%)] Loss: 19656.214844\n",
      "Train Epoch: 129 [194880/225000 (87%)] Loss: 19796.019531\n",
      "Train Epoch: 129 [197376/225000 (88%)] Loss: 19338.570312\n",
      "Train Epoch: 129 [199872/225000 (89%)] Loss: 19261.972656\n",
      "Train Epoch: 129 [202368/225000 (90%)] Loss: 19554.765625\n",
      "Train Epoch: 129 [204864/225000 (91%)] Loss: 19482.484375\n",
      "Train Epoch: 129 [207360/225000 (92%)] Loss: 19303.035156\n",
      "Train Epoch: 129 [209856/225000 (93%)] Loss: 18948.511719\n",
      "Train Epoch: 129 [212352/225000 (94%)] Loss: 19958.304688\n",
      "Train Epoch: 129 [214848/225000 (95%)] Loss: 18844.640625\n",
      "Train Epoch: 129 [217344/225000 (97%)] Loss: 19012.121094\n",
      "Train Epoch: 129 [219840/225000 (98%)] Loss: 19194.890625\n",
      "Train Epoch: 129 [222336/225000 (99%)] Loss: 19786.277344\n",
      "Train Epoch: 129 [224832/225000 (100%)] Loss: 19795.335938\n",
      "    epoch          : 129\n",
      "    loss           : 19335.817514465125\n",
      "    val_loss       : 19265.38489996568\n",
      "Train Epoch: 130 [192/225000 (0%)] Loss: 19172.660156\n",
      "Train Epoch: 130 [2688/225000 (1%)] Loss: 19057.048828\n",
      "Train Epoch: 130 [5184/225000 (2%)] Loss: 19112.478516\n",
      "Train Epoch: 130 [7680/225000 (3%)] Loss: 19260.685547\n",
      "Train Epoch: 130 [10176/225000 (5%)] Loss: 19840.062500\n",
      "Train Epoch: 130 [12672/225000 (6%)] Loss: 19308.195312\n",
      "Train Epoch: 130 [15168/225000 (7%)] Loss: 19341.929688\n",
      "Train Epoch: 130 [17664/225000 (8%)] Loss: 19034.951172\n",
      "Train Epoch: 130 [20160/225000 (9%)] Loss: 19155.191406\n",
      "Train Epoch: 130 [22656/225000 (10%)] Loss: 19311.658203\n",
      "Train Epoch: 130 [25152/225000 (11%)] Loss: 19526.671875\n",
      "Train Epoch: 130 [27648/225000 (12%)] Loss: 19653.390625\n",
      "Train Epoch: 130 [30144/225000 (13%)] Loss: 19417.843750\n",
      "Train Epoch: 130 [32640/225000 (15%)] Loss: 19000.839844\n",
      "Train Epoch: 130 [35136/225000 (16%)] Loss: 18950.988281\n",
      "Train Epoch: 130 [37632/225000 (17%)] Loss: 19590.910156\n",
      "Train Epoch: 130 [40128/225000 (18%)] Loss: 19438.964844\n",
      "Train Epoch: 130 [42624/225000 (19%)] Loss: 19133.343750\n",
      "Train Epoch: 130 [45120/225000 (20%)] Loss: 19021.894531\n",
      "Train Epoch: 130 [47616/225000 (21%)] Loss: 19329.210938\n",
      "Train Epoch: 130 [50112/225000 (22%)] Loss: 18870.941406\n",
      "Train Epoch: 130 [52608/225000 (23%)] Loss: 19286.218750\n",
      "Train Epoch: 130 [55104/225000 (24%)] Loss: 18835.070312\n",
      "Train Epoch: 130 [57600/225000 (26%)] Loss: 19141.388672\n",
      "Train Epoch: 130 [60096/225000 (27%)] Loss: 19864.347656\n",
      "Train Epoch: 130 [62592/225000 (28%)] Loss: 19451.554688\n",
      "Train Epoch: 130 [65088/225000 (29%)] Loss: 18998.724609\n",
      "Train Epoch: 130 [67584/225000 (30%)] Loss: 18976.083984\n",
      "Train Epoch: 130 [70080/225000 (31%)] Loss: 19442.812500\n",
      "Train Epoch: 130 [72576/225000 (32%)] Loss: 19312.269531\n",
      "Train Epoch: 130 [75072/225000 (33%)] Loss: 19338.074219\n",
      "Train Epoch: 130 [77568/225000 (34%)] Loss: 19664.457031\n",
      "Train Epoch: 130 [80064/225000 (36%)] Loss: 19056.882812\n",
      "Train Epoch: 130 [82560/225000 (37%)] Loss: 19357.203125\n",
      "Train Epoch: 130 [85056/225000 (38%)] Loss: 18994.654297\n",
      "Train Epoch: 130 [87552/225000 (39%)] Loss: 19564.359375\n",
      "Train Epoch: 130 [90048/225000 (40%)] Loss: 19481.125000\n",
      "Train Epoch: 130 [92544/225000 (41%)] Loss: 19315.214844\n",
      "Train Epoch: 130 [95040/225000 (42%)] Loss: 19575.050781\n",
      "Train Epoch: 130 [97536/225000 (43%)] Loss: 19142.074219\n",
      "Train Epoch: 130 [100032/225000 (44%)] Loss: 19651.468750\n",
      "Train Epoch: 130 [102528/225000 (46%)] Loss: 19209.421875\n",
      "Train Epoch: 130 [105024/225000 (47%)] Loss: 19570.593750\n",
      "Train Epoch: 130 [107520/225000 (48%)] Loss: 19631.546875\n",
      "Train Epoch: 130 [110016/225000 (49%)] Loss: 19503.195312\n",
      "Train Epoch: 130 [112512/225000 (50%)] Loss: 18954.865234\n",
      "Train Epoch: 130 [115008/225000 (51%)] Loss: 19537.472656\n",
      "Train Epoch: 130 [117504/225000 (52%)] Loss: 19747.531250\n",
      "Train Epoch: 130 [120000/225000 (53%)] Loss: 19023.550781\n",
      "Train Epoch: 130 [122496/225000 (54%)] Loss: 19469.697266\n",
      "Train Epoch: 130 [124992/225000 (56%)] Loss: 19352.423828\n",
      "Train Epoch: 130 [127488/225000 (57%)] Loss: 18859.318359\n",
      "Train Epoch: 130 [129984/225000 (58%)] Loss: 18929.812500\n",
      "Train Epoch: 130 [132480/225000 (59%)] Loss: 19210.128906\n",
      "Train Epoch: 130 [134976/225000 (60%)] Loss: 19363.992188\n",
      "Train Epoch: 130 [137472/225000 (61%)] Loss: 19418.447266\n",
      "Train Epoch: 130 [139968/225000 (62%)] Loss: 19762.687500\n",
      "Train Epoch: 130 [142464/225000 (63%)] Loss: 19677.642578\n",
      "Train Epoch: 130 [144960/225000 (64%)] Loss: 19702.791016\n",
      "Train Epoch: 130 [147456/225000 (66%)] Loss: 19136.345703\n",
      "Train Epoch: 130 [149952/225000 (67%)] Loss: 19702.792969\n",
      "Train Epoch: 130 [152448/225000 (68%)] Loss: 19105.914062\n",
      "Train Epoch: 130 [154944/225000 (69%)] Loss: 18616.480469\n",
      "Train Epoch: 130 [157440/225000 (70%)] Loss: 19565.968750\n",
      "Train Epoch: 130 [159936/225000 (71%)] Loss: 19738.812500\n",
      "Train Epoch: 130 [162432/225000 (72%)] Loss: 19191.962891\n",
      "Train Epoch: 130 [164928/225000 (73%)] Loss: 19332.074219\n",
      "Train Epoch: 130 [167424/225000 (74%)] Loss: 19369.738281\n",
      "Train Epoch: 130 [169920/225000 (76%)] Loss: 19149.328125\n",
      "Train Epoch: 130 [172416/225000 (77%)] Loss: 19713.226562\n",
      "Train Epoch: 130 [174912/225000 (78%)] Loss: 19315.582031\n",
      "Train Epoch: 130 [177408/225000 (79%)] Loss: 19227.363281\n",
      "Train Epoch: 130 [179904/225000 (80%)] Loss: 19216.875000\n",
      "Train Epoch: 130 [182400/225000 (81%)] Loss: 18595.894531\n",
      "Train Epoch: 130 [184896/225000 (82%)] Loss: 19506.074219\n",
      "Train Epoch: 130 [187392/225000 (83%)] Loss: 19322.029297\n",
      "Train Epoch: 130 [189888/225000 (84%)] Loss: 19139.595703\n",
      "Train Epoch: 130 [192384/225000 (86%)] Loss: 19324.177734\n",
      "Train Epoch: 130 [194880/225000 (87%)] Loss: 18986.921875\n",
      "Train Epoch: 130 [197376/225000 (88%)] Loss: 19214.718750\n",
      "Train Epoch: 130 [199872/225000 (89%)] Loss: 19168.259766\n",
      "Train Epoch: 130 [202368/225000 (90%)] Loss: 19222.255859\n",
      "Train Epoch: 130 [204864/225000 (91%)] Loss: 19310.378906\n",
      "Train Epoch: 130 [207360/225000 (92%)] Loss: 19093.332031\n",
      "Train Epoch: 130 [209856/225000 (93%)] Loss: 19068.914062\n",
      "Train Epoch: 130 [212352/225000 (94%)] Loss: 19658.132812\n",
      "Train Epoch: 130 [214848/225000 (95%)] Loss: 19370.773438\n",
      "Train Epoch: 130 [217344/225000 (97%)] Loss: 19437.968750\n",
      "Train Epoch: 130 [219840/225000 (98%)] Loss: 19353.951172\n",
      "Train Epoch: 130 [222336/225000 (99%)] Loss: 19213.160156\n",
      "Train Epoch: 130 [224832/225000 (100%)] Loss: 19461.957031\n",
      "    epoch          : 130\n",
      "    loss           : 19340.837733975044\n",
      "    val_loss       : 19227.73493724379\n",
      "Train Epoch: 131 [192/225000 (0%)] Loss: 19613.121094\n",
      "Train Epoch: 131 [2688/225000 (1%)] Loss: 19084.554688\n",
      "Train Epoch: 131 [5184/225000 (2%)] Loss: 19402.070312\n",
      "Train Epoch: 131 [7680/225000 (3%)] Loss: 18961.292969\n",
      "Train Epoch: 131 [10176/225000 (5%)] Loss: 19097.392578\n",
      "Train Epoch: 131 [12672/225000 (6%)] Loss: 19470.847656\n",
      "Train Epoch: 131 [15168/225000 (7%)] Loss: 19212.367188\n",
      "Train Epoch: 131 [17664/225000 (8%)] Loss: 18882.062500\n",
      "Train Epoch: 131 [20160/225000 (9%)] Loss: 19966.935547\n",
      "Train Epoch: 131 [22656/225000 (10%)] Loss: 19292.638672\n",
      "Train Epoch: 131 [25152/225000 (11%)] Loss: 19518.943359\n",
      "Train Epoch: 131 [27648/225000 (12%)] Loss: 19361.558594\n",
      "Train Epoch: 131 [30144/225000 (13%)] Loss: 19763.535156\n",
      "Train Epoch: 131 [32640/225000 (15%)] Loss: 19505.080078\n",
      "Train Epoch: 131 [35136/225000 (16%)] Loss: 19298.435547\n",
      "Train Epoch: 131 [37632/225000 (17%)] Loss: 19288.769531\n",
      "Train Epoch: 131 [40128/225000 (18%)] Loss: 19053.031250\n",
      "Train Epoch: 131 [42624/225000 (19%)] Loss: 19503.707031\n",
      "Train Epoch: 131 [45120/225000 (20%)] Loss: 18619.312500\n",
      "Train Epoch: 131 [47616/225000 (21%)] Loss: 18963.804688\n",
      "Train Epoch: 131 [50112/225000 (22%)] Loss: 18812.050781\n",
      "Train Epoch: 131 [52608/225000 (23%)] Loss: 19150.107422\n",
      "Train Epoch: 131 [55104/225000 (24%)] Loss: 19090.515625\n",
      "Train Epoch: 131 [57600/225000 (26%)] Loss: 19281.982422\n",
      "Train Epoch: 131 [60096/225000 (27%)] Loss: 19812.710938\n",
      "Train Epoch: 131 [62592/225000 (28%)] Loss: 19097.599609\n",
      "Train Epoch: 131 [65088/225000 (29%)] Loss: 19016.203125\n",
      "Train Epoch: 131 [67584/225000 (30%)] Loss: 19243.617188\n",
      "Train Epoch: 131 [70080/225000 (31%)] Loss: 19118.150391\n",
      "Train Epoch: 131 [72576/225000 (32%)] Loss: 19360.800781\n",
      "Train Epoch: 131 [75072/225000 (33%)] Loss: 19140.949219\n",
      "Train Epoch: 131 [77568/225000 (34%)] Loss: 19158.888672\n",
      "Train Epoch: 131 [80064/225000 (36%)] Loss: 19256.523438\n",
      "Train Epoch: 131 [82560/225000 (37%)] Loss: 19487.138672\n",
      "Train Epoch: 131 [85056/225000 (38%)] Loss: 19484.634766\n",
      "Train Epoch: 131 [87552/225000 (39%)] Loss: 19991.992188\n",
      "Train Epoch: 131 [90048/225000 (40%)] Loss: 19126.595703\n",
      "Train Epoch: 131 [92544/225000 (41%)] Loss: 19292.927734\n",
      "Train Epoch: 131 [95040/225000 (42%)] Loss: 19464.378906\n",
      "Train Epoch: 131 [97536/225000 (43%)] Loss: 19444.601562\n",
      "Train Epoch: 131 [100032/225000 (44%)] Loss: 18647.101562\n",
      "Train Epoch: 131 [102528/225000 (46%)] Loss: 19370.767578\n",
      "Train Epoch: 131 [105024/225000 (47%)] Loss: 19232.347656\n",
      "Train Epoch: 131 [107520/225000 (48%)] Loss: 19238.875000\n",
      "Train Epoch: 131 [110016/225000 (49%)] Loss: 19831.482422\n",
      "Train Epoch: 131 [112512/225000 (50%)] Loss: 19359.667969\n",
      "Train Epoch: 131 [115008/225000 (51%)] Loss: 19193.810547\n",
      "Train Epoch: 131 [117504/225000 (52%)] Loss: 19294.300781\n",
      "Train Epoch: 131 [120000/225000 (53%)] Loss: 18946.144531\n",
      "Train Epoch: 131 [122496/225000 (54%)] Loss: 19041.824219\n",
      "Train Epoch: 131 [124992/225000 (56%)] Loss: 19273.162109\n",
      "Train Epoch: 131 [127488/225000 (57%)] Loss: 18806.953125\n",
      "Train Epoch: 131 [129984/225000 (58%)] Loss: 19503.964844\n",
      "Train Epoch: 131 [132480/225000 (59%)] Loss: 18694.898438\n",
      "Train Epoch: 131 [134976/225000 (60%)] Loss: 19507.121094\n",
      "Train Epoch: 131 [137472/225000 (61%)] Loss: 18982.574219\n",
      "Train Epoch: 131 [139968/225000 (62%)] Loss: 19458.890625\n",
      "Train Epoch: 131 [142464/225000 (63%)] Loss: 19049.322266\n",
      "Train Epoch: 131 [144960/225000 (64%)] Loss: 19061.031250\n",
      "Train Epoch: 131 [147456/225000 (66%)] Loss: 19416.509766\n",
      "Train Epoch: 131 [149952/225000 (67%)] Loss: 18927.021484\n",
      "Train Epoch: 131 [152448/225000 (68%)] Loss: 19077.076172\n",
      "Train Epoch: 131 [154944/225000 (69%)] Loss: 18980.113281\n",
      "Train Epoch: 131 [157440/225000 (70%)] Loss: 18648.792969\n",
      "Train Epoch: 131 [159936/225000 (71%)] Loss: 19090.042969\n",
      "Train Epoch: 131 [162432/225000 (72%)] Loss: 18852.199219\n",
      "Train Epoch: 131 [164928/225000 (73%)] Loss: 19138.609375\n",
      "Train Epoch: 131 [167424/225000 (74%)] Loss: 19186.156250\n",
      "Train Epoch: 131 [169920/225000 (76%)] Loss: 19436.789062\n",
      "Train Epoch: 131 [172416/225000 (77%)] Loss: 19486.697266\n",
      "Train Epoch: 131 [174912/225000 (78%)] Loss: 19335.539062\n",
      "Train Epoch: 131 [177408/225000 (79%)] Loss: 19354.070312\n",
      "Train Epoch: 131 [179904/225000 (80%)] Loss: 19277.078125\n",
      "Train Epoch: 131 [182400/225000 (81%)] Loss: 19128.476562\n",
      "Train Epoch: 131 [184896/225000 (82%)] Loss: 18678.773438\n",
      "Train Epoch: 131 [187392/225000 (83%)] Loss: 19415.742188\n",
      "Train Epoch: 131 [189888/225000 (84%)] Loss: 19366.945312\n",
      "Train Epoch: 131 [192384/225000 (86%)] Loss: 19380.406250\n",
      "Train Epoch: 131 [194880/225000 (87%)] Loss: 19279.503906\n",
      "Train Epoch: 131 [197376/225000 (88%)] Loss: 19165.517578\n",
      "Train Epoch: 131 [199872/225000 (89%)] Loss: 19931.351562\n",
      "Train Epoch: 131 [202368/225000 (90%)] Loss: 19367.425781\n",
      "Train Epoch: 131 [204864/225000 (91%)] Loss: 19425.910156\n",
      "Train Epoch: 131 [207360/225000 (92%)] Loss: 18650.773438\n",
      "Train Epoch: 131 [209856/225000 (93%)] Loss: 19484.945312\n",
      "Train Epoch: 131 [212352/225000 (94%)] Loss: 19724.757812\n",
      "Train Epoch: 131 [214848/225000 (95%)] Loss: 19366.404297\n",
      "Train Epoch: 131 [217344/225000 (97%)] Loss: 19753.191406\n",
      "Train Epoch: 131 [219840/225000 (98%)] Loss: 19430.164062\n",
      "Train Epoch: 131 [222336/225000 (99%)] Loss: 19423.978516\n",
      "Train Epoch: 131 [224832/225000 (100%)] Loss: 19709.121094\n",
      "    epoch          : 131\n",
      "    loss           : 19329.69412262692\n",
      "    val_loss       : 19252.159875146306\n",
      "Train Epoch: 132 [192/225000 (0%)] Loss: 19140.990234\n",
      "Train Epoch: 132 [2688/225000 (1%)] Loss: 19573.062500\n",
      "Train Epoch: 132 [5184/225000 (2%)] Loss: 19314.458984\n",
      "Train Epoch: 132 [7680/225000 (3%)] Loss: 19676.447266\n",
      "Train Epoch: 132 [10176/225000 (5%)] Loss: 19586.539062\n",
      "Train Epoch: 132 [12672/225000 (6%)] Loss: 19432.128906\n",
      "Train Epoch: 132 [15168/225000 (7%)] Loss: 19300.064453\n",
      "Train Epoch: 132 [17664/225000 (8%)] Loss: 19535.166016\n",
      "Train Epoch: 132 [20160/225000 (9%)] Loss: 19333.433594\n",
      "Train Epoch: 132 [22656/225000 (10%)] Loss: 19817.777344\n",
      "Train Epoch: 132 [25152/225000 (11%)] Loss: 19576.941406\n",
      "Train Epoch: 132 [27648/225000 (12%)] Loss: 20222.603516\n",
      "Train Epoch: 132 [30144/225000 (13%)] Loss: 19577.386719\n",
      "Train Epoch: 132 [32640/225000 (15%)] Loss: 19312.285156\n",
      "Train Epoch: 132 [35136/225000 (16%)] Loss: 19391.087891\n",
      "Train Epoch: 132 [37632/225000 (17%)] Loss: 19875.566406\n",
      "Train Epoch: 132 [40128/225000 (18%)] Loss: 19085.755859\n",
      "Train Epoch: 132 [42624/225000 (19%)] Loss: 18722.101562\n",
      "Train Epoch: 132 [45120/225000 (20%)] Loss: 19244.261719\n",
      "Train Epoch: 132 [47616/225000 (21%)] Loss: 19567.933594\n",
      "Train Epoch: 132 [50112/225000 (22%)] Loss: 18907.482422\n",
      "Train Epoch: 132 [52608/225000 (23%)] Loss: 19474.679688\n",
      "Train Epoch: 132 [55104/225000 (24%)] Loss: 19143.425781\n",
      "Train Epoch: 132 [57600/225000 (26%)] Loss: 19146.212891\n",
      "Train Epoch: 132 [60096/225000 (27%)] Loss: 19332.544922\n",
      "Train Epoch: 132 [62592/225000 (28%)] Loss: 19802.558594\n",
      "Train Epoch: 132 [65088/225000 (29%)] Loss: 19761.644531\n",
      "Train Epoch: 132 [67584/225000 (30%)] Loss: 18811.695312\n",
      "Train Epoch: 132 [70080/225000 (31%)] Loss: 19318.833984\n",
      "Train Epoch: 132 [72576/225000 (32%)] Loss: 19262.236328\n",
      "Train Epoch: 132 [75072/225000 (33%)] Loss: 19252.230469\n",
      "Train Epoch: 132 [77568/225000 (34%)] Loss: 19476.839844\n",
      "Train Epoch: 132 [80064/225000 (36%)] Loss: 19536.593750\n",
      "Train Epoch: 132 [82560/225000 (37%)] Loss: 18939.105469\n",
      "Train Epoch: 132 [85056/225000 (38%)] Loss: 19598.710938\n",
      "Train Epoch: 132 [87552/225000 (39%)] Loss: 19459.164062\n",
      "Train Epoch: 132 [90048/225000 (40%)] Loss: 19247.933594\n",
      "Train Epoch: 132 [92544/225000 (41%)] Loss: 19721.914062\n",
      "Train Epoch: 132 [95040/225000 (42%)] Loss: 19636.835938\n",
      "Train Epoch: 132 [97536/225000 (43%)] Loss: 19626.031250\n",
      "Train Epoch: 132 [100032/225000 (44%)] Loss: 19482.759766\n",
      "Train Epoch: 132 [102528/225000 (46%)] Loss: 19474.152344\n",
      "Train Epoch: 132 [105024/225000 (47%)] Loss: 19099.265625\n",
      "Train Epoch: 132 [107520/225000 (48%)] Loss: 19086.464844\n",
      "Train Epoch: 132 [110016/225000 (49%)] Loss: 19413.376953\n",
      "Train Epoch: 132 [112512/225000 (50%)] Loss: 19350.628906\n",
      "Train Epoch: 132 [115008/225000 (51%)] Loss: 19590.675781\n",
      "Train Epoch: 132 [117504/225000 (52%)] Loss: 19310.970703\n",
      "Train Epoch: 132 [120000/225000 (53%)] Loss: 19476.750000\n",
      "Train Epoch: 132 [122496/225000 (54%)] Loss: 19004.941406\n",
      "Train Epoch: 132 [124992/225000 (56%)] Loss: 20025.460938\n",
      "Train Epoch: 132 [127488/225000 (57%)] Loss: 19253.046875\n",
      "Train Epoch: 132 [129984/225000 (58%)] Loss: 19837.496094\n",
      "Train Epoch: 132 [132480/225000 (59%)] Loss: 18901.742188\n",
      "Train Epoch: 132 [134976/225000 (60%)] Loss: 19134.761719\n",
      "Train Epoch: 132 [137472/225000 (61%)] Loss: 19414.097656\n",
      "Train Epoch: 132 [139968/225000 (62%)] Loss: 19699.656250\n",
      "Train Epoch: 132 [142464/225000 (63%)] Loss: 19431.767578\n",
      "Train Epoch: 132 [144960/225000 (64%)] Loss: 19296.121094\n",
      "Train Epoch: 132 [147456/225000 (66%)] Loss: 19645.138672\n",
      "Train Epoch: 132 [149952/225000 (67%)] Loss: 19230.357422\n",
      "Train Epoch: 132 [152448/225000 (68%)] Loss: 19572.787109\n",
      "Train Epoch: 132 [154944/225000 (69%)] Loss: 19233.191406\n",
      "Train Epoch: 132 [157440/225000 (70%)] Loss: 19730.558594\n",
      "Train Epoch: 132 [159936/225000 (71%)] Loss: 19432.833984\n",
      "Train Epoch: 132 [162432/225000 (72%)] Loss: 19555.699219\n",
      "Train Epoch: 132 [164928/225000 (73%)] Loss: 19078.414062\n",
      "Train Epoch: 132 [167424/225000 (74%)] Loss: 19216.179688\n",
      "Train Epoch: 132 [169920/225000 (76%)] Loss: 19462.537109\n",
      "Train Epoch: 132 [172416/225000 (77%)] Loss: 19579.390625\n",
      "Train Epoch: 132 [174912/225000 (78%)] Loss: 18760.953125\n",
      "Train Epoch: 132 [177408/225000 (79%)] Loss: 19300.757812\n",
      "Train Epoch: 132 [179904/225000 (80%)] Loss: 19094.302734\n",
      "Train Epoch: 132 [182400/225000 (81%)] Loss: 19312.037109\n",
      "Train Epoch: 132 [184896/225000 (82%)] Loss: 19717.087891\n",
      "Train Epoch: 132 [187392/225000 (83%)] Loss: 19179.671875\n",
      "Train Epoch: 132 [189888/225000 (84%)] Loss: 19202.859375\n",
      "Train Epoch: 132 [192384/225000 (86%)] Loss: 19095.957031\n",
      "Train Epoch: 132 [194880/225000 (87%)] Loss: 19276.316406\n",
      "Train Epoch: 132 [197376/225000 (88%)] Loss: 19424.482422\n",
      "Train Epoch: 132 [199872/225000 (89%)] Loss: 19100.724609\n",
      "Train Epoch: 132 [202368/225000 (90%)] Loss: 19543.671875\n",
      "Train Epoch: 132 [204864/225000 (91%)] Loss: 19063.091797\n",
      "Train Epoch: 132 [207360/225000 (92%)] Loss: 19448.017578\n",
      "Train Epoch: 132 [209856/225000 (93%)] Loss: 19203.574219\n",
      "Train Epoch: 132 [212352/225000 (94%)] Loss: 19101.835938\n",
      "Train Epoch: 132 [214848/225000 (95%)] Loss: 19845.404297\n",
      "Train Epoch: 132 [217344/225000 (97%)] Loss: 19803.503906\n",
      "Train Epoch: 132 [219840/225000 (98%)] Loss: 19299.371094\n",
      "Train Epoch: 132 [222336/225000 (99%)] Loss: 18792.625000\n",
      "Train Epoch: 132 [224832/225000 (100%)] Loss: 19542.761719\n",
      "    epoch          : 132\n",
      "    loss           : 19322.859105028798\n",
      "    val_loss       : 19225.298892589926\n",
      "Train Epoch: 133 [192/225000 (0%)] Loss: 19734.484375\n",
      "Train Epoch: 133 [2688/225000 (1%)] Loss: 19528.087891\n",
      "Train Epoch: 133 [5184/225000 (2%)] Loss: 19539.033203\n",
      "Train Epoch: 133 [7680/225000 (3%)] Loss: 19537.757812\n",
      "Train Epoch: 133 [10176/225000 (5%)] Loss: 18833.820312\n",
      "Train Epoch: 133 [12672/225000 (6%)] Loss: 19581.242188\n",
      "Train Epoch: 133 [15168/225000 (7%)] Loss: 19131.978516\n",
      "Train Epoch: 133 [17664/225000 (8%)] Loss: 19421.035156\n",
      "Train Epoch: 133 [20160/225000 (9%)] Loss: 19792.453125\n",
      "Train Epoch: 133 [22656/225000 (10%)] Loss: 19198.929688\n",
      "Train Epoch: 133 [25152/225000 (11%)] Loss: 19297.984375\n",
      "Train Epoch: 133 [27648/225000 (12%)] Loss: 18977.734375\n",
      "Train Epoch: 133 [30144/225000 (13%)] Loss: 19459.238281\n",
      "Train Epoch: 133 [32640/225000 (15%)] Loss: 19647.925781\n",
      "Train Epoch: 133 [35136/225000 (16%)] Loss: 19705.521484\n",
      "Train Epoch: 133 [37632/225000 (17%)] Loss: 19235.042969\n",
      "Train Epoch: 133 [40128/225000 (18%)] Loss: 19470.187500\n",
      "Train Epoch: 133 [42624/225000 (19%)] Loss: 19143.089844\n",
      "Train Epoch: 133 [45120/225000 (20%)] Loss: 19397.777344\n",
      "Train Epoch: 133 [47616/225000 (21%)] Loss: 19347.128906\n",
      "Train Epoch: 133 [50112/225000 (22%)] Loss: 19000.359375\n",
      "Train Epoch: 133 [52608/225000 (23%)] Loss: 19605.125000\n",
      "Train Epoch: 133 [55104/225000 (24%)] Loss: 19094.929688\n",
      "Train Epoch: 133 [57600/225000 (26%)] Loss: 19325.808594\n",
      "Train Epoch: 133 [60096/225000 (27%)] Loss: 19198.941406\n",
      "Train Epoch: 133 [62592/225000 (28%)] Loss: 19077.640625\n",
      "Train Epoch: 133 [65088/225000 (29%)] Loss: 19573.376953\n",
      "Train Epoch: 133 [67584/225000 (30%)] Loss: 19564.617188\n",
      "Train Epoch: 133 [70080/225000 (31%)] Loss: 19147.972656\n",
      "Train Epoch: 133 [72576/225000 (32%)] Loss: 19264.636719\n",
      "Train Epoch: 133 [75072/225000 (33%)] Loss: 18945.619141\n",
      "Train Epoch: 133 [77568/225000 (34%)] Loss: 19392.585938\n",
      "Train Epoch: 133 [80064/225000 (36%)] Loss: 19070.917969\n",
      "Train Epoch: 133 [82560/225000 (37%)] Loss: 19319.742188\n",
      "Train Epoch: 133 [85056/225000 (38%)] Loss: 19142.480469\n",
      "Train Epoch: 133 [87552/225000 (39%)] Loss: 19740.867188\n",
      "Train Epoch: 133 [90048/225000 (40%)] Loss: 19938.314453\n",
      "Train Epoch: 133 [92544/225000 (41%)] Loss: 19554.468750\n",
      "Train Epoch: 133 [95040/225000 (42%)] Loss: 19182.810547\n",
      "Train Epoch: 133 [97536/225000 (43%)] Loss: 19148.226562\n",
      "Train Epoch: 133 [100032/225000 (44%)] Loss: 19670.421875\n",
      "Train Epoch: 133 [102528/225000 (46%)] Loss: 19145.644531\n",
      "Train Epoch: 133 [105024/225000 (47%)] Loss: 19023.408203\n",
      "Train Epoch: 133 [107520/225000 (48%)] Loss: 18887.621094\n",
      "Train Epoch: 133 [110016/225000 (49%)] Loss: 19538.109375\n",
      "Train Epoch: 133 [112512/225000 (50%)] Loss: 19554.675781\n",
      "Train Epoch: 133 [115008/225000 (51%)] Loss: 20004.175781\n",
      "Train Epoch: 133 [117504/225000 (52%)] Loss: 19662.361328\n",
      "Train Epoch: 133 [120000/225000 (53%)] Loss: 19667.806641\n",
      "Train Epoch: 133 [122496/225000 (54%)] Loss: 19664.429688\n",
      "Train Epoch: 133 [124992/225000 (56%)] Loss: 19263.613281\n",
      "Train Epoch: 133 [127488/225000 (57%)] Loss: 19035.130859\n",
      "Train Epoch: 133 [129984/225000 (58%)] Loss: 19046.474609\n",
      "Train Epoch: 133 [132480/225000 (59%)] Loss: 19097.523438\n",
      "Train Epoch: 133 [134976/225000 (60%)] Loss: 19559.304688\n",
      "Train Epoch: 133 [137472/225000 (61%)] Loss: 19830.160156\n",
      "Train Epoch: 133 [139968/225000 (62%)] Loss: 19357.527344\n",
      "Train Epoch: 133 [142464/225000 (63%)] Loss: 19729.687500\n",
      "Train Epoch: 133 [144960/225000 (64%)] Loss: 19659.292969\n",
      "Train Epoch: 133 [147456/225000 (66%)] Loss: 19203.341797\n",
      "Train Epoch: 133 [149952/225000 (67%)] Loss: 18951.943359\n",
      "Train Epoch: 133 [152448/225000 (68%)] Loss: 19160.003906\n",
      "Train Epoch: 133 [154944/225000 (69%)] Loss: 19072.255859\n",
      "Train Epoch: 133 [157440/225000 (70%)] Loss: 19264.291016\n",
      "Train Epoch: 133 [159936/225000 (71%)] Loss: 19079.357422\n",
      "Train Epoch: 133 [162432/225000 (72%)] Loss: 18786.871094\n",
      "Train Epoch: 133 [164928/225000 (73%)] Loss: 19339.558594\n",
      "Train Epoch: 133 [167424/225000 (74%)] Loss: 19098.820312\n",
      "Train Epoch: 133 [169920/225000 (76%)] Loss: 19118.031250\n",
      "Train Epoch: 133 [172416/225000 (77%)] Loss: 19297.070312\n",
      "Train Epoch: 133 [174912/225000 (78%)] Loss: 19641.851562\n",
      "Train Epoch: 133 [177408/225000 (79%)] Loss: 19256.816406\n",
      "Train Epoch: 133 [179904/225000 (80%)] Loss: 19801.031250\n",
      "Train Epoch: 133 [182400/225000 (81%)] Loss: 18903.587891\n",
      "Train Epoch: 133 [184896/225000 (82%)] Loss: 19236.660156\n",
      "Train Epoch: 133 [187392/225000 (83%)] Loss: 19669.160156\n",
      "Train Epoch: 133 [189888/225000 (84%)] Loss: 19378.511719\n",
      "Train Epoch: 133 [192384/225000 (86%)] Loss: 19391.335938\n",
      "Train Epoch: 133 [194880/225000 (87%)] Loss: 19717.992188\n",
      "Train Epoch: 133 [197376/225000 (88%)] Loss: 19216.023438\n",
      "Train Epoch: 133 [199872/225000 (89%)] Loss: 19481.011719\n",
      "Train Epoch: 133 [202368/225000 (90%)] Loss: 19506.072266\n",
      "Train Epoch: 133 [204864/225000 (91%)] Loss: 19419.716797\n",
      "Train Epoch: 133 [207360/225000 (92%)] Loss: 18932.230469\n",
      "Train Epoch: 133 [209856/225000 (93%)] Loss: 19109.578125\n",
      "Train Epoch: 133 [212352/225000 (94%)] Loss: 19345.550781\n",
      "Train Epoch: 133 [214848/225000 (95%)] Loss: 19497.230469\n",
      "Train Epoch: 133 [217344/225000 (97%)] Loss: 19502.281250\n",
      "Train Epoch: 133 [219840/225000 (98%)] Loss: 19135.976562\n",
      "Train Epoch: 133 [222336/225000 (99%)] Loss: 19421.625000\n",
      "Train Epoch: 133 [224832/225000 (100%)] Loss: 19247.791016\n",
      "    epoch          : 133\n",
      "    loss           : 19318.691566232934\n",
      "    val_loss       : 19215.57435974183\n",
      "Train Epoch: 134 [192/225000 (0%)] Loss: 19102.050781\n",
      "Train Epoch: 134 [2688/225000 (1%)] Loss: 18988.492188\n",
      "Train Epoch: 134 [5184/225000 (2%)] Loss: 18793.640625\n",
      "Train Epoch: 134 [7680/225000 (3%)] Loss: 19443.492188\n",
      "Train Epoch: 134 [10176/225000 (5%)] Loss: 19258.517578\n",
      "Train Epoch: 134 [12672/225000 (6%)] Loss: 22563.156250\n",
      "Train Epoch: 134 [15168/225000 (7%)] Loss: 19774.390625\n",
      "Train Epoch: 134 [17664/225000 (8%)] Loss: 19416.113281\n",
      "Train Epoch: 134 [20160/225000 (9%)] Loss: 19598.843750\n",
      "Train Epoch: 134 [22656/225000 (10%)] Loss: 19141.015625\n",
      "Train Epoch: 134 [25152/225000 (11%)] Loss: 19268.957031\n",
      "Train Epoch: 134 [27648/225000 (12%)] Loss: 19251.863281\n",
      "Train Epoch: 134 [30144/225000 (13%)] Loss: 19452.744141\n",
      "Train Epoch: 134 [32640/225000 (15%)] Loss: 19198.265625\n",
      "Train Epoch: 134 [35136/225000 (16%)] Loss: 18937.416016\n",
      "Train Epoch: 134 [37632/225000 (17%)] Loss: 19463.812500\n",
      "Train Epoch: 134 [40128/225000 (18%)] Loss: 18903.054688\n",
      "Train Epoch: 134 [42624/225000 (19%)] Loss: 19455.796875\n",
      "Train Epoch: 134 [45120/225000 (20%)] Loss: 19635.535156\n",
      "Train Epoch: 134 [47616/225000 (21%)] Loss: 19363.980469\n",
      "Train Epoch: 134 [50112/225000 (22%)] Loss: 19141.865234\n",
      "Train Epoch: 134 [52608/225000 (23%)] Loss: 18884.482422\n",
      "Train Epoch: 134 [55104/225000 (24%)] Loss: 19350.197266\n",
      "Train Epoch: 134 [57600/225000 (26%)] Loss: 18866.419922\n",
      "Train Epoch: 134 [60096/225000 (27%)] Loss: 19174.730469\n",
      "Train Epoch: 134 [62592/225000 (28%)] Loss: 18848.925781\n",
      "Train Epoch: 134 [65088/225000 (29%)] Loss: 18953.541016\n",
      "Train Epoch: 134 [67584/225000 (30%)] Loss: 19670.810547\n",
      "Train Epoch: 134 [70080/225000 (31%)] Loss: 19882.240234\n",
      "Train Epoch: 134 [72576/225000 (32%)] Loss: 19246.582031\n",
      "Train Epoch: 134 [75072/225000 (33%)] Loss: 19488.652344\n",
      "Train Epoch: 134 [77568/225000 (34%)] Loss: 19253.117188\n",
      "Train Epoch: 134 [80064/225000 (36%)] Loss: 19656.308594\n",
      "Train Epoch: 134 [82560/225000 (37%)] Loss: 19575.230469\n",
      "Train Epoch: 134 [85056/225000 (38%)] Loss: 19282.669922\n",
      "Train Epoch: 134 [87552/225000 (39%)] Loss: 19324.392578\n",
      "Train Epoch: 134 [90048/225000 (40%)] Loss: 19066.601562\n",
      "Train Epoch: 134 [92544/225000 (41%)] Loss: 19168.605469\n",
      "Train Epoch: 134 [95040/225000 (42%)] Loss: 19395.695312\n",
      "Train Epoch: 134 [97536/225000 (43%)] Loss: 19757.482422\n",
      "Train Epoch: 134 [100032/225000 (44%)] Loss: 19220.628906\n",
      "Train Epoch: 134 [102528/225000 (46%)] Loss: 19084.847656\n",
      "Train Epoch: 134 [105024/225000 (47%)] Loss: 19752.408203\n",
      "Train Epoch: 134 [107520/225000 (48%)] Loss: 18846.707031\n",
      "Train Epoch: 134 [110016/225000 (49%)] Loss: 19178.988281\n",
      "Train Epoch: 134 [112512/225000 (50%)] Loss: 19060.066406\n",
      "Train Epoch: 134 [115008/225000 (51%)] Loss: 19726.054688\n",
      "Train Epoch: 134 [117504/225000 (52%)] Loss: 18653.173828\n",
      "Train Epoch: 134 [120000/225000 (53%)] Loss: 19020.669922\n",
      "Train Epoch: 134 [122496/225000 (54%)] Loss: 19624.800781\n",
      "Train Epoch: 134 [124992/225000 (56%)] Loss: 19186.746094\n",
      "Train Epoch: 134 [127488/225000 (57%)] Loss: 19214.087891\n",
      "Train Epoch: 134 [129984/225000 (58%)] Loss: 19573.394531\n",
      "Train Epoch: 134 [132480/225000 (59%)] Loss: 19476.722656\n",
      "Train Epoch: 134 [134976/225000 (60%)] Loss: 19259.359375\n",
      "Train Epoch: 134 [137472/225000 (61%)] Loss: 19616.843750\n",
      "Train Epoch: 134 [139968/225000 (62%)] Loss: 19234.083984\n",
      "Train Epoch: 134 [142464/225000 (63%)] Loss: 19540.818359\n",
      "Train Epoch: 134 [144960/225000 (64%)] Loss: 19176.722656\n",
      "Train Epoch: 134 [147456/225000 (66%)] Loss: 18683.238281\n",
      "Train Epoch: 134 [149952/225000 (67%)] Loss: 19038.277344\n",
      "Train Epoch: 134 [152448/225000 (68%)] Loss: 18826.583984\n",
      "Train Epoch: 134 [154944/225000 (69%)] Loss: 19904.925781\n",
      "Train Epoch: 134 [157440/225000 (70%)] Loss: 18862.789062\n",
      "Train Epoch: 134 [159936/225000 (71%)] Loss: 19177.292969\n",
      "Train Epoch: 134 [162432/225000 (72%)] Loss: 19192.730469\n",
      "Train Epoch: 134 [164928/225000 (73%)] Loss: 19427.271484\n",
      "Train Epoch: 134 [167424/225000 (74%)] Loss: 19005.246094\n",
      "Train Epoch: 134 [169920/225000 (76%)] Loss: 19544.480469\n",
      "Train Epoch: 134 [172416/225000 (77%)] Loss: 19182.265625\n",
      "Train Epoch: 134 [174912/225000 (78%)] Loss: 18824.218750\n",
      "Train Epoch: 134 [177408/225000 (79%)] Loss: 19256.339844\n",
      "Train Epoch: 134 [179904/225000 (80%)] Loss: 19542.765625\n",
      "Train Epoch: 134 [182400/225000 (81%)] Loss: 19235.457031\n",
      "Train Epoch: 134 [184896/225000 (82%)] Loss: 19391.662109\n",
      "Train Epoch: 134 [187392/225000 (83%)] Loss: 19353.105469\n",
      "Train Epoch: 134 [189888/225000 (84%)] Loss: 19216.757812\n",
      "Train Epoch: 134 [192384/225000 (86%)] Loss: 19252.287109\n",
      "Train Epoch: 134 [194880/225000 (87%)] Loss: 19461.000000\n",
      "Train Epoch: 134 [197376/225000 (88%)] Loss: 19385.140625\n",
      "Train Epoch: 134 [199872/225000 (89%)] Loss: 18941.445312\n",
      "Train Epoch: 134 [202368/225000 (90%)] Loss: 19261.623047\n",
      "Train Epoch: 134 [204864/225000 (91%)] Loss: 19293.419922\n",
      "Train Epoch: 134 [207360/225000 (92%)] Loss: 19120.304688\n",
      "Train Epoch: 134 [209856/225000 (93%)] Loss: 18741.005859\n",
      "Train Epoch: 134 [212352/225000 (94%)] Loss: 19432.355469\n",
      "Train Epoch: 134 [214848/225000 (95%)] Loss: 19713.250000\n",
      "Train Epoch: 134 [217344/225000 (97%)] Loss: 19059.322266\n",
      "Train Epoch: 134 [219840/225000 (98%)] Loss: 18904.828125\n",
      "Train Epoch: 134 [222336/225000 (99%)] Loss: 19247.941406\n",
      "Train Epoch: 134 [224832/225000 (100%)] Loss: 18885.800781\n",
      "    epoch          : 134\n",
      "    loss           : 19313.72026150544\n",
      "    val_loss       : 19256.98793377767\n",
      "Train Epoch: 135 [192/225000 (0%)] Loss: 19427.605469\n",
      "Train Epoch: 135 [2688/225000 (1%)] Loss: 19503.148438\n",
      "Train Epoch: 135 [5184/225000 (2%)] Loss: 19251.847656\n",
      "Train Epoch: 135 [7680/225000 (3%)] Loss: 18899.574219\n",
      "Train Epoch: 135 [10176/225000 (5%)] Loss: 19215.263672\n",
      "Train Epoch: 135 [12672/225000 (6%)] Loss: 19657.535156\n",
      "Train Epoch: 135 [15168/225000 (7%)] Loss: 19895.242188\n",
      "Train Epoch: 135 [17664/225000 (8%)] Loss: 19795.355469\n",
      "Train Epoch: 135 [20160/225000 (9%)] Loss: 18936.367188\n",
      "Train Epoch: 135 [22656/225000 (10%)] Loss: 18750.871094\n",
      "Train Epoch: 135 [25152/225000 (11%)] Loss: 19374.085938\n",
      "Train Epoch: 135 [27648/225000 (12%)] Loss: 18861.509766\n",
      "Train Epoch: 135 [30144/225000 (13%)] Loss: 19598.738281\n",
      "Train Epoch: 135 [32640/225000 (15%)] Loss: 19364.777344\n",
      "Train Epoch: 135 [35136/225000 (16%)] Loss: 19454.931641\n",
      "Train Epoch: 135 [37632/225000 (17%)] Loss: 19485.453125\n",
      "Train Epoch: 135 [40128/225000 (18%)] Loss: 18984.878906\n",
      "Train Epoch: 135 [42624/225000 (19%)] Loss: 19056.296875\n",
      "Train Epoch: 135 [45120/225000 (20%)] Loss: 19500.880859\n",
      "Train Epoch: 135 [47616/225000 (21%)] Loss: 18904.425781\n",
      "Train Epoch: 135 [50112/225000 (22%)] Loss: 19085.507812\n",
      "Train Epoch: 135 [52608/225000 (23%)] Loss: 19214.101562\n",
      "Train Epoch: 135 [55104/225000 (24%)] Loss: 19294.943359\n",
      "Train Epoch: 135 [57600/225000 (26%)] Loss: 19383.294922\n",
      "Train Epoch: 135 [60096/225000 (27%)] Loss: 19311.167969\n",
      "Train Epoch: 135 [62592/225000 (28%)] Loss: 19020.951172\n",
      "Train Epoch: 135 [65088/225000 (29%)] Loss: 19175.460938\n",
      "Train Epoch: 135 [67584/225000 (30%)] Loss: 19310.218750\n",
      "Train Epoch: 135 [70080/225000 (31%)] Loss: 19449.714844\n",
      "Train Epoch: 135 [72576/225000 (32%)] Loss: 18850.191406\n",
      "Train Epoch: 135 [75072/225000 (33%)] Loss: 19521.283203\n",
      "Train Epoch: 135 [77568/225000 (34%)] Loss: 19246.236328\n",
      "Train Epoch: 135 [80064/225000 (36%)] Loss: 19828.875000\n",
      "Train Epoch: 135 [82560/225000 (37%)] Loss: 20005.384766\n",
      "Train Epoch: 135 [85056/225000 (38%)] Loss: 19389.675781\n",
      "Train Epoch: 135 [87552/225000 (39%)] Loss: 18977.908203\n",
      "Train Epoch: 135 [90048/225000 (40%)] Loss: 19002.097656\n",
      "Train Epoch: 135 [92544/225000 (41%)] Loss: 19093.048828\n",
      "Train Epoch: 135 [95040/225000 (42%)] Loss: 18697.746094\n",
      "Train Epoch: 135 [97536/225000 (43%)] Loss: 19032.355469\n",
      "Train Epoch: 135 [100032/225000 (44%)] Loss: 19250.861328\n",
      "Train Epoch: 135 [102528/225000 (46%)] Loss: 18886.101562\n",
      "Train Epoch: 135 [105024/225000 (47%)] Loss: 19530.490234\n",
      "Train Epoch: 135 [107520/225000 (48%)] Loss: 19715.263672\n",
      "Train Epoch: 135 [110016/225000 (49%)] Loss: 18998.912109\n",
      "Train Epoch: 135 [112512/225000 (50%)] Loss: 19793.406250\n",
      "Train Epoch: 135 [115008/225000 (51%)] Loss: 19443.876953\n",
      "Train Epoch: 135 [117504/225000 (52%)] Loss: 19250.605469\n",
      "Train Epoch: 135 [120000/225000 (53%)] Loss: 19055.455078\n",
      "Train Epoch: 135 [122496/225000 (54%)] Loss: 19452.210938\n",
      "Train Epoch: 135 [124992/225000 (56%)] Loss: 19437.058594\n",
      "Train Epoch: 135 [127488/225000 (57%)] Loss: 19390.343750\n",
      "Train Epoch: 135 [129984/225000 (58%)] Loss: 19253.292969\n",
      "Train Epoch: 135 [132480/225000 (59%)] Loss: 19093.390625\n",
      "Train Epoch: 135 [134976/225000 (60%)] Loss: 19602.011719\n",
      "Train Epoch: 135 [137472/225000 (61%)] Loss: 19169.585938\n",
      "Train Epoch: 135 [139968/225000 (62%)] Loss: 19138.738281\n",
      "Train Epoch: 135 [142464/225000 (63%)] Loss: 19257.033203\n",
      "Train Epoch: 135 [144960/225000 (64%)] Loss: 19412.664062\n",
      "Train Epoch: 135 [147456/225000 (66%)] Loss: 19569.962891\n",
      "Train Epoch: 135 [149952/225000 (67%)] Loss: 19142.019531\n",
      "Train Epoch: 135 [152448/225000 (68%)] Loss: 19390.113281\n",
      "Train Epoch: 135 [154944/225000 (69%)] Loss: 19132.425781\n",
      "Train Epoch: 135 [157440/225000 (70%)] Loss: 19214.248047\n",
      "Train Epoch: 135 [159936/225000 (71%)] Loss: 18854.027344\n",
      "Train Epoch: 135 [162432/225000 (72%)] Loss: 19809.578125\n",
      "Train Epoch: 135 [164928/225000 (73%)] Loss: 18945.845703\n",
      "Train Epoch: 135 [167424/225000 (74%)] Loss: 19713.755859\n",
      "Train Epoch: 135 [169920/225000 (76%)] Loss: 18683.425781\n",
      "Train Epoch: 135 [172416/225000 (77%)] Loss: 19109.917969\n",
      "Train Epoch: 135 [174912/225000 (78%)] Loss: 19380.437500\n",
      "Train Epoch: 135 [177408/225000 (79%)] Loss: 19281.574219\n",
      "Train Epoch: 135 [179904/225000 (80%)] Loss: 19698.439453\n",
      "Train Epoch: 135 [182400/225000 (81%)] Loss: 19334.259766\n",
      "Train Epoch: 135 [184896/225000 (82%)] Loss: 19360.421875\n",
      "Train Epoch: 135 [187392/225000 (83%)] Loss: 19654.816406\n",
      "Train Epoch: 135 [189888/225000 (84%)] Loss: 19192.308594\n",
      "Train Epoch: 135 [192384/225000 (86%)] Loss: 19422.529297\n",
      "Train Epoch: 135 [194880/225000 (87%)] Loss: 19388.205078\n",
      "Train Epoch: 135 [197376/225000 (88%)] Loss: 19374.585938\n",
      "Train Epoch: 135 [199872/225000 (89%)] Loss: 19313.312500\n",
      "Train Epoch: 135 [202368/225000 (90%)] Loss: 19783.777344\n",
      "Train Epoch: 135 [204864/225000 (91%)] Loss: 20000.652344\n",
      "Train Epoch: 135 [207360/225000 (92%)] Loss: 19276.441406\n",
      "Train Epoch: 135 [209856/225000 (93%)] Loss: 19617.089844\n",
      "Train Epoch: 135 [212352/225000 (94%)] Loss: 19190.929688\n",
      "Train Epoch: 135 [214848/225000 (95%)] Loss: 19409.187500\n",
      "Train Epoch: 135 [217344/225000 (97%)] Loss: 19529.246094\n",
      "Train Epoch: 135 [219840/225000 (98%)] Loss: 19225.921875\n",
      "Train Epoch: 135 [222336/225000 (99%)] Loss: 18875.775391\n",
      "Train Epoch: 135 [224832/225000 (100%)] Loss: 19541.167969\n",
      "    epoch          : 135\n",
      "    loss           : 19310.671633359107\n",
      "    val_loss       : 19210.34551998677\n",
      "Train Epoch: 136 [192/225000 (0%)] Loss: 19203.707031\n",
      "Train Epoch: 136 [2688/225000 (1%)] Loss: 19031.804688\n",
      "Train Epoch: 136 [5184/225000 (2%)] Loss: 19383.898438\n",
      "Train Epoch: 136 [7680/225000 (3%)] Loss: 19223.091797\n",
      "Train Epoch: 136 [10176/225000 (5%)] Loss: 19576.242188\n",
      "Train Epoch: 136 [12672/225000 (6%)] Loss: 19001.296875\n",
      "Train Epoch: 136 [15168/225000 (7%)] Loss: 19525.914062\n",
      "Train Epoch: 136 [17664/225000 (8%)] Loss: 19641.023438\n",
      "Train Epoch: 136 [20160/225000 (9%)] Loss: 19858.933594\n",
      "Train Epoch: 136 [22656/225000 (10%)] Loss: 19751.613281\n",
      "Train Epoch: 136 [25152/225000 (11%)] Loss: 19089.976562\n",
      "Train Epoch: 136 [27648/225000 (12%)] Loss: 19202.781250\n",
      "Train Epoch: 136 [30144/225000 (13%)] Loss: 18935.753906\n",
      "Train Epoch: 136 [32640/225000 (15%)] Loss: 19463.308594\n",
      "Train Epoch: 136 [35136/225000 (16%)] Loss: 19696.318359\n",
      "Train Epoch: 136 [37632/225000 (17%)] Loss: 19376.617188\n",
      "Train Epoch: 136 [40128/225000 (18%)] Loss: 19115.398438\n",
      "Train Epoch: 136 [42624/225000 (19%)] Loss: 19262.650391\n",
      "Train Epoch: 136 [45120/225000 (20%)] Loss: 19335.140625\n",
      "Train Epoch: 136 [47616/225000 (21%)] Loss: 19213.371094\n",
      "Train Epoch: 136 [50112/225000 (22%)] Loss: 19619.488281\n",
      "Train Epoch: 136 [52608/225000 (23%)] Loss: 18984.882812\n",
      "Train Epoch: 136 [55104/225000 (24%)] Loss: 19065.824219\n",
      "Train Epoch: 136 [57600/225000 (26%)] Loss: 19280.335938\n",
      "Train Epoch: 136 [60096/225000 (27%)] Loss: 19287.916016\n",
      "Train Epoch: 136 [62592/225000 (28%)] Loss: 18925.113281\n",
      "Train Epoch: 136 [65088/225000 (29%)] Loss: 19607.031250\n",
      "Train Epoch: 136 [67584/225000 (30%)] Loss: 19259.457031\n",
      "Train Epoch: 136 [70080/225000 (31%)] Loss: 19876.984375\n",
      "Train Epoch: 136 [72576/225000 (32%)] Loss: 19486.394531\n",
      "Train Epoch: 136 [75072/225000 (33%)] Loss: 19114.171875\n",
      "Train Epoch: 136 [77568/225000 (34%)] Loss: 19511.804688\n",
      "Train Epoch: 136 [80064/225000 (36%)] Loss: 19196.992188\n",
      "Train Epoch: 136 [82560/225000 (37%)] Loss: 19162.957031\n",
      "Train Epoch: 136 [85056/225000 (38%)] Loss: 18848.035156\n",
      "Train Epoch: 136 [87552/225000 (39%)] Loss: 19896.201172\n",
      "Train Epoch: 136 [90048/225000 (40%)] Loss: 19566.324219\n",
      "Train Epoch: 136 [92544/225000 (41%)] Loss: 19224.667969\n",
      "Train Epoch: 136 [95040/225000 (42%)] Loss: 18882.152344\n",
      "Train Epoch: 136 [97536/225000 (43%)] Loss: 19427.917969\n",
      "Train Epoch: 136 [100032/225000 (44%)] Loss: 19305.800781\n",
      "Train Epoch: 136 [102528/225000 (46%)] Loss: 19378.617188\n",
      "Train Epoch: 136 [105024/225000 (47%)] Loss: 19666.742188\n",
      "Train Epoch: 136 [107520/225000 (48%)] Loss: 19037.335938\n",
      "Train Epoch: 136 [110016/225000 (49%)] Loss: 19350.421875\n",
      "Train Epoch: 136 [112512/225000 (50%)] Loss: 18814.519531\n",
      "Train Epoch: 136 [115008/225000 (51%)] Loss: 18813.566406\n",
      "Train Epoch: 136 [117504/225000 (52%)] Loss: 19516.101562\n",
      "Train Epoch: 136 [120000/225000 (53%)] Loss: 18979.976562\n",
      "Train Epoch: 136 [122496/225000 (54%)] Loss: 19661.363281\n",
      "Train Epoch: 136 [124992/225000 (56%)] Loss: 19146.867188\n",
      "Train Epoch: 136 [127488/225000 (57%)] Loss: 19267.044922\n",
      "Train Epoch: 136 [129984/225000 (58%)] Loss: 19725.945312\n",
      "Train Epoch: 136 [132480/225000 (59%)] Loss: 19167.277344\n",
      "Train Epoch: 136 [134976/225000 (60%)] Loss: 19567.316406\n",
      "Train Epoch: 136 [137472/225000 (61%)] Loss: 19489.542969\n",
      "Train Epoch: 136 [139968/225000 (62%)] Loss: 18842.859375\n",
      "Train Epoch: 136 [142464/225000 (63%)] Loss: 19227.566406\n",
      "Train Epoch: 136 [144960/225000 (64%)] Loss: 19143.058594\n",
      "Train Epoch: 136 [147456/225000 (66%)] Loss: 19192.550781\n",
      "Train Epoch: 136 [149952/225000 (67%)] Loss: 19130.328125\n",
      "Train Epoch: 136 [152448/225000 (68%)] Loss: 20027.757812\n",
      "Train Epoch: 136 [154944/225000 (69%)] Loss: 19318.773438\n",
      "Train Epoch: 136 [157440/225000 (70%)] Loss: 19393.257812\n",
      "Train Epoch: 136 [159936/225000 (71%)] Loss: 18906.289062\n",
      "Train Epoch: 136 [162432/225000 (72%)] Loss: 18964.503906\n",
      "Train Epoch: 136 [164928/225000 (73%)] Loss: 19462.939453\n",
      "Train Epoch: 136 [167424/225000 (74%)] Loss: 19130.369141\n",
      "Train Epoch: 136 [169920/225000 (76%)] Loss: 18946.480469\n",
      "Train Epoch: 136 [172416/225000 (77%)] Loss: 19368.085938\n",
      "Train Epoch: 136 [174912/225000 (78%)] Loss: 19145.398438\n",
      "Train Epoch: 136 [177408/225000 (79%)] Loss: 19750.326172\n",
      "Train Epoch: 136 [179904/225000 (80%)] Loss: 18962.814453\n",
      "Train Epoch: 136 [182400/225000 (81%)] Loss: 19729.835938\n",
      "Train Epoch: 136 [184896/225000 (82%)] Loss: 19695.740234\n",
      "Train Epoch: 136 [187392/225000 (83%)] Loss: 19016.708984\n",
      "Train Epoch: 136 [189888/225000 (84%)] Loss: 19529.906250\n",
      "Train Epoch: 136 [192384/225000 (86%)] Loss: 19569.968750\n",
      "Train Epoch: 136 [194880/225000 (87%)] Loss: 19405.595703\n",
      "Train Epoch: 136 [197376/225000 (88%)] Loss: 19818.441406\n",
      "Train Epoch: 136 [199872/225000 (89%)] Loss: 19406.703125\n",
      "Train Epoch: 136 [202368/225000 (90%)] Loss: 18983.617188\n",
      "Train Epoch: 136 [204864/225000 (91%)] Loss: 19384.453125\n",
      "Train Epoch: 136 [207360/225000 (92%)] Loss: 19153.152344\n",
      "Train Epoch: 136 [209856/225000 (93%)] Loss: 19142.742188\n",
      "Train Epoch: 136 [212352/225000 (94%)] Loss: 19260.066406\n",
      "Train Epoch: 136 [214848/225000 (95%)] Loss: 19069.359375\n",
      "Train Epoch: 136 [217344/225000 (97%)] Loss: 19282.304688\n",
      "Train Epoch: 136 [219840/225000 (98%)] Loss: 19318.855469\n",
      "Train Epoch: 136 [222336/225000 (99%)] Loss: 18903.027344\n",
      "Train Epoch: 136 [224832/225000 (100%)] Loss: 19215.503906\n",
      "    epoch          : 136\n",
      "    loss           : 19306.02772204298\n",
      "    val_loss       : 19209.731348470876\n",
      "Train Epoch: 137 [192/225000 (0%)] Loss: 19337.203125\n",
      "Train Epoch: 137 [2688/225000 (1%)] Loss: 19169.960938\n",
      "Train Epoch: 137 [5184/225000 (2%)] Loss: 19408.119141\n",
      "Train Epoch: 137 [7680/225000 (3%)] Loss: 19423.933594\n",
      "Train Epoch: 137 [10176/225000 (5%)] Loss: 19142.599609\n",
      "Train Epoch: 137 [12672/225000 (6%)] Loss: 19081.150391\n",
      "Train Epoch: 137 [15168/225000 (7%)] Loss: 19083.691406\n",
      "Train Epoch: 137 [17664/225000 (8%)] Loss: 19507.015625\n",
      "Train Epoch: 137 [20160/225000 (9%)] Loss: 18711.279297\n",
      "Train Epoch: 137 [22656/225000 (10%)] Loss: 18843.132812\n",
      "Train Epoch: 137 [25152/225000 (11%)] Loss: 19110.603516\n",
      "Train Epoch: 137 [27648/225000 (12%)] Loss: 19025.732422\n",
      "Train Epoch: 137 [30144/225000 (13%)] Loss: 19430.054688\n",
      "Train Epoch: 137 [32640/225000 (15%)] Loss: 19411.400391\n",
      "Train Epoch: 137 [35136/225000 (16%)] Loss: 19247.832031\n",
      "Train Epoch: 137 [37632/225000 (17%)] Loss: 19349.009766\n",
      "Train Epoch: 137 [40128/225000 (18%)] Loss: 19790.101562\n",
      "Train Epoch: 137 [42624/225000 (19%)] Loss: 19407.646484\n",
      "Train Epoch: 137 [45120/225000 (20%)] Loss: 19468.964844\n",
      "Train Epoch: 137 [47616/225000 (21%)] Loss: 19423.578125\n",
      "Train Epoch: 137 [50112/225000 (22%)] Loss: 19493.796875\n",
      "Train Epoch: 137 [52608/225000 (23%)] Loss: 19270.878906\n",
      "Train Epoch: 137 [55104/225000 (24%)] Loss: 19507.871094\n",
      "Train Epoch: 137 [57600/225000 (26%)] Loss: 18958.980469\n",
      "Train Epoch: 137 [60096/225000 (27%)] Loss: 19094.660156\n",
      "Train Epoch: 137 [62592/225000 (28%)] Loss: 19233.472656\n",
      "Train Epoch: 137 [65088/225000 (29%)] Loss: 19669.261719\n",
      "Train Epoch: 137 [67584/225000 (30%)] Loss: 19485.548828\n",
      "Train Epoch: 137 [70080/225000 (31%)] Loss: 19291.718750\n",
      "Train Epoch: 137 [72576/225000 (32%)] Loss: 19252.597656\n",
      "Train Epoch: 137 [75072/225000 (33%)] Loss: 18962.695312\n",
      "Train Epoch: 137 [77568/225000 (34%)] Loss: 19224.003906\n",
      "Train Epoch: 137 [80064/225000 (36%)] Loss: 19400.093750\n",
      "Train Epoch: 137 [82560/225000 (37%)] Loss: 19487.679688\n",
      "Train Epoch: 137 [85056/225000 (38%)] Loss: 19438.054688\n",
      "Train Epoch: 137 [87552/225000 (39%)] Loss: 19481.027344\n",
      "Train Epoch: 137 [90048/225000 (40%)] Loss: 19102.878906\n",
      "Train Epoch: 137 [92544/225000 (41%)] Loss: 19674.218750\n",
      "Train Epoch: 137 [95040/225000 (42%)] Loss: 19344.019531\n",
      "Train Epoch: 137 [97536/225000 (43%)] Loss: 19442.404297\n",
      "Train Epoch: 137 [100032/225000 (44%)] Loss: 18728.304688\n",
      "Train Epoch: 137 [102528/225000 (46%)] Loss: 19290.433594\n",
      "Train Epoch: 137 [105024/225000 (47%)] Loss: 19315.308594\n",
      "Train Epoch: 137 [107520/225000 (48%)] Loss: 19291.632812\n",
      "Train Epoch: 137 [110016/225000 (49%)] Loss: 19722.667969\n",
      "Train Epoch: 137 [112512/225000 (50%)] Loss: 19455.976562\n",
      "Train Epoch: 137 [115008/225000 (51%)] Loss: 19195.019531\n",
      "Train Epoch: 137 [117504/225000 (52%)] Loss: 19271.847656\n",
      "Train Epoch: 137 [120000/225000 (53%)] Loss: 19550.066406\n",
      "Train Epoch: 137 [122496/225000 (54%)] Loss: 19331.789062\n",
      "Train Epoch: 137 [124992/225000 (56%)] Loss: 19447.136719\n",
      "Train Epoch: 137 [127488/225000 (57%)] Loss: 19318.972656\n",
      "Train Epoch: 137 [129984/225000 (58%)] Loss: 19418.449219\n",
      "Train Epoch: 137 [132480/225000 (59%)] Loss: 19042.281250\n",
      "Train Epoch: 137 [134976/225000 (60%)] Loss: 19594.619141\n",
      "Train Epoch: 137 [137472/225000 (61%)] Loss: 18946.863281\n",
      "Train Epoch: 137 [139968/225000 (62%)] Loss: 18989.800781\n",
      "Train Epoch: 137 [142464/225000 (63%)] Loss: 19057.800781\n",
      "Train Epoch: 137 [144960/225000 (64%)] Loss: 19560.964844\n",
      "Train Epoch: 137 [147456/225000 (66%)] Loss: 19311.906250\n",
      "Train Epoch: 137 [149952/225000 (67%)] Loss: 19443.822266\n",
      "Train Epoch: 137 [152448/225000 (68%)] Loss: 19056.648438\n",
      "Train Epoch: 137 [154944/225000 (69%)] Loss: 19479.054688\n",
      "Train Epoch: 137 [157440/225000 (70%)] Loss: 18700.101562\n",
      "Train Epoch: 137 [159936/225000 (71%)] Loss: 19267.242188\n",
      "Train Epoch: 137 [162432/225000 (72%)] Loss: 19117.898438\n",
      "Train Epoch: 137 [164928/225000 (73%)] Loss: 19117.574219\n",
      "Train Epoch: 137 [167424/225000 (74%)] Loss: 19118.105469\n",
      "Train Epoch: 137 [169920/225000 (76%)] Loss: 19661.003906\n",
      "Train Epoch: 137 [172416/225000 (77%)] Loss: 19353.875000\n",
      "Train Epoch: 137 [174912/225000 (78%)] Loss: 19427.667969\n",
      "Train Epoch: 137 [177408/225000 (79%)] Loss: 19228.970703\n",
      "Train Epoch: 137 [179904/225000 (80%)] Loss: 19189.138672\n",
      "Train Epoch: 137 [182400/225000 (81%)] Loss: 19425.792969\n",
      "Train Epoch: 137 [184896/225000 (82%)] Loss: 19422.554688\n",
      "Train Epoch: 137 [187392/225000 (83%)] Loss: 19064.804688\n",
      "Train Epoch: 137 [189888/225000 (84%)] Loss: 19383.289062\n",
      "Train Epoch: 137 [192384/225000 (86%)] Loss: 19225.232422\n",
      "Train Epoch: 137 [194880/225000 (87%)] Loss: 19620.023438\n",
      "Train Epoch: 137 [197376/225000 (88%)] Loss: 18823.175781\n",
      "Train Epoch: 137 [199872/225000 (89%)] Loss: 19203.291016\n",
      "Train Epoch: 137 [202368/225000 (90%)] Loss: 19309.355469\n",
      "Train Epoch: 137 [204864/225000 (91%)] Loss: 19214.453125\n",
      "Train Epoch: 137 [207360/225000 (92%)] Loss: 19500.988281\n",
      "Train Epoch: 137 [209856/225000 (93%)] Loss: 19170.199219\n",
      "Train Epoch: 137 [212352/225000 (94%)] Loss: 18593.708984\n",
      "Train Epoch: 137 [214848/225000 (95%)] Loss: 18998.667969\n",
      "Train Epoch: 137 [217344/225000 (97%)] Loss: 19365.953125\n",
      "Train Epoch: 137 [219840/225000 (98%)] Loss: 18794.406250\n",
      "Train Epoch: 137 [222336/225000 (99%)] Loss: 19135.460938\n",
      "Train Epoch: 137 [224832/225000 (100%)] Loss: 19700.296875\n",
      "    epoch          : 137\n",
      "    loss           : 19306.214517118173\n",
      "    val_loss       : 19213.991111496023\n",
      "Train Epoch: 138 [192/225000 (0%)] Loss: 19167.566406\n",
      "Train Epoch: 138 [2688/225000 (1%)] Loss: 19773.833984\n",
      "Train Epoch: 138 [5184/225000 (2%)] Loss: 19623.353516\n",
      "Train Epoch: 138 [7680/225000 (3%)] Loss: 19709.658203\n",
      "Train Epoch: 138 [10176/225000 (5%)] Loss: 19414.589844\n",
      "Train Epoch: 138 [12672/225000 (6%)] Loss: 19757.761719\n",
      "Train Epoch: 138 [15168/225000 (7%)] Loss: 19653.240234\n",
      "Train Epoch: 138 [17664/225000 (8%)] Loss: 18982.531250\n",
      "Train Epoch: 138 [20160/225000 (9%)] Loss: 19554.777344\n",
      "Train Epoch: 138 [22656/225000 (10%)] Loss: 19348.679688\n",
      "Train Epoch: 138 [25152/225000 (11%)] Loss: 19072.876953\n",
      "Train Epoch: 138 [27648/225000 (12%)] Loss: 19042.994141\n",
      "Train Epoch: 138 [30144/225000 (13%)] Loss: 19208.789062\n",
      "Train Epoch: 138 [32640/225000 (15%)] Loss: 18501.916016\n",
      "Train Epoch: 138 [35136/225000 (16%)] Loss: 19607.953125\n",
      "Train Epoch: 138 [37632/225000 (17%)] Loss: 19004.824219\n",
      "Train Epoch: 138 [40128/225000 (18%)] Loss: 19043.355469\n",
      "Train Epoch: 138 [42624/225000 (19%)] Loss: 19098.408203\n",
      "Train Epoch: 138 [45120/225000 (20%)] Loss: 19384.132812\n",
      "Train Epoch: 138 [47616/225000 (21%)] Loss: 18851.722656\n",
      "Train Epoch: 138 [50112/225000 (22%)] Loss: 18841.371094\n",
      "Train Epoch: 138 [52608/225000 (23%)] Loss: 19358.863281\n",
      "Train Epoch: 138 [55104/225000 (24%)] Loss: 18913.992188\n",
      "Train Epoch: 138 [57600/225000 (26%)] Loss: 19190.320312\n",
      "Train Epoch: 138 [60096/225000 (27%)] Loss: 19076.906250\n",
      "Train Epoch: 138 [62592/225000 (28%)] Loss: 19218.404297\n",
      "Train Epoch: 138 [65088/225000 (29%)] Loss: 18859.013672\n",
      "Train Epoch: 138 [67584/225000 (30%)] Loss: 19401.867188\n",
      "Train Epoch: 138 [70080/225000 (31%)] Loss: 19667.906250\n",
      "Train Epoch: 138 [72576/225000 (32%)] Loss: 19113.914062\n",
      "Train Epoch: 138 [75072/225000 (33%)] Loss: 18616.078125\n",
      "Train Epoch: 138 [77568/225000 (34%)] Loss: 18889.189453\n",
      "Train Epoch: 138 [80064/225000 (36%)] Loss: 19299.414062\n",
      "Train Epoch: 138 [82560/225000 (37%)] Loss: 19332.843750\n",
      "Train Epoch: 138 [85056/225000 (38%)] Loss: 19384.554688\n",
      "Train Epoch: 138 [87552/225000 (39%)] Loss: 19157.005859\n",
      "Train Epoch: 138 [90048/225000 (40%)] Loss: 19461.917969\n",
      "Train Epoch: 138 [92544/225000 (41%)] Loss: 19239.697266\n",
      "Train Epoch: 138 [95040/225000 (42%)] Loss: 19415.556641\n",
      "Train Epoch: 138 [97536/225000 (43%)] Loss: 19251.607422\n",
      "Train Epoch: 138 [100032/225000 (44%)] Loss: 19233.763672\n",
      "Train Epoch: 138 [102528/225000 (46%)] Loss: 19738.421875\n",
      "Train Epoch: 138 [105024/225000 (47%)] Loss: 19024.482422\n",
      "Train Epoch: 138 [107520/225000 (48%)] Loss: 19107.554688\n",
      "Train Epoch: 138 [110016/225000 (49%)] Loss: 19015.820312\n",
      "Train Epoch: 138 [112512/225000 (50%)] Loss: 19503.699219\n",
      "Train Epoch: 138 [115008/225000 (51%)] Loss: 19153.437500\n",
      "Train Epoch: 138 [117504/225000 (52%)] Loss: 19388.351562\n",
      "Train Epoch: 138 [120000/225000 (53%)] Loss: 19225.117188\n",
      "Train Epoch: 138 [122496/225000 (54%)] Loss: 19328.613281\n",
      "Train Epoch: 138 [124992/225000 (56%)] Loss: 19254.453125\n",
      "Train Epoch: 138 [127488/225000 (57%)] Loss: 19481.644531\n",
      "Train Epoch: 138 [129984/225000 (58%)] Loss: 19066.707031\n",
      "Train Epoch: 138 [132480/225000 (59%)] Loss: 19395.794922\n",
      "Train Epoch: 138 [134976/225000 (60%)] Loss: 19140.792969\n",
      "Train Epoch: 138 [137472/225000 (61%)] Loss: 19343.941406\n",
      "Train Epoch: 138 [139968/225000 (62%)] Loss: 19353.513672\n",
      "Train Epoch: 138 [142464/225000 (63%)] Loss: 19027.367188\n",
      "Train Epoch: 138 [144960/225000 (64%)] Loss: 19003.941406\n",
      "Train Epoch: 138 [147456/225000 (66%)] Loss: 19090.214844\n",
      "Train Epoch: 138 [149952/225000 (67%)] Loss: 19178.128906\n",
      "Train Epoch: 138 [152448/225000 (68%)] Loss: 18961.488281\n",
      "Train Epoch: 138 [154944/225000 (69%)] Loss: 19231.683594\n",
      "Train Epoch: 138 [157440/225000 (70%)] Loss: 19508.763672\n",
      "Train Epoch: 138 [159936/225000 (71%)] Loss: 19382.347656\n",
      "Train Epoch: 138 [162432/225000 (72%)] Loss: 19389.281250\n",
      "Train Epoch: 138 [164928/225000 (73%)] Loss: 19415.171875\n",
      "Train Epoch: 138 [167424/225000 (74%)] Loss: 19481.937500\n",
      "Train Epoch: 138 [169920/225000 (76%)] Loss: 19464.093750\n",
      "Train Epoch: 138 [172416/225000 (77%)] Loss: 19243.535156\n",
      "Train Epoch: 138 [174912/225000 (78%)] Loss: 19351.769531\n",
      "Train Epoch: 138 [177408/225000 (79%)] Loss: 19755.474609\n",
      "Train Epoch: 138 [179904/225000 (80%)] Loss: 19038.636719\n",
      "Train Epoch: 138 [182400/225000 (81%)] Loss: 19527.054688\n",
      "Train Epoch: 138 [184896/225000 (82%)] Loss: 19080.375000\n",
      "Train Epoch: 138 [187392/225000 (83%)] Loss: 19160.703125\n",
      "Train Epoch: 138 [189888/225000 (84%)] Loss: 19804.394531\n",
      "Train Epoch: 138 [192384/225000 (86%)] Loss: 19165.968750\n",
      "Train Epoch: 138 [194880/225000 (87%)] Loss: 19838.531250\n",
      "Train Epoch: 138 [197376/225000 (88%)] Loss: 19175.644531\n",
      "Train Epoch: 138 [199872/225000 (89%)] Loss: 19456.437500\n",
      "Train Epoch: 138 [202368/225000 (90%)] Loss: 18988.417969\n",
      "Train Epoch: 138 [204864/225000 (91%)] Loss: 19144.708984\n",
      "Train Epoch: 138 [207360/225000 (92%)] Loss: 19483.298828\n",
      "Train Epoch: 138 [209856/225000 (93%)] Loss: 19638.601562\n",
      "Train Epoch: 138 [212352/225000 (94%)] Loss: 18851.031250\n",
      "Train Epoch: 138 [214848/225000 (95%)] Loss: 19234.537109\n",
      "Train Epoch: 138 [217344/225000 (97%)] Loss: 19378.658203\n",
      "Train Epoch: 138 [219840/225000 (98%)] Loss: 19961.890625\n",
      "Train Epoch: 138 [222336/225000 (99%)] Loss: 19122.425781\n",
      "Train Epoch: 138 [224832/225000 (100%)] Loss: 19690.429688\n",
      "    epoch          : 138\n",
      "    loss           : 19298.991600895904\n",
      "    val_loss       : 19212.291722246708\n",
      "Train Epoch: 139 [192/225000 (0%)] Loss: 19479.476562\n",
      "Train Epoch: 139 [2688/225000 (1%)] Loss: 19744.261719\n",
      "Train Epoch: 139 [5184/225000 (2%)] Loss: 19528.546875\n",
      "Train Epoch: 139 [7680/225000 (3%)] Loss: 19480.681641\n",
      "Train Epoch: 139 [10176/225000 (5%)] Loss: 19579.035156\n",
      "Train Epoch: 139 [12672/225000 (6%)] Loss: 19810.429688\n",
      "Train Epoch: 139 [15168/225000 (7%)] Loss: 19487.078125\n",
      "Train Epoch: 139 [17664/225000 (8%)] Loss: 19767.921875\n",
      "Train Epoch: 139 [20160/225000 (9%)] Loss: 19615.566406\n",
      "Train Epoch: 139 [22656/225000 (10%)] Loss: 19260.507812\n",
      "Train Epoch: 139 [25152/225000 (11%)] Loss: 19202.480469\n",
      "Train Epoch: 139 [27648/225000 (12%)] Loss: 19287.480469\n",
      "Train Epoch: 139 [30144/225000 (13%)] Loss: 19445.820312\n",
      "Train Epoch: 139 [32640/225000 (15%)] Loss: 19175.708984\n",
      "Train Epoch: 139 [35136/225000 (16%)] Loss: 19523.683594\n",
      "Train Epoch: 139 [37632/225000 (17%)] Loss: 19366.703125\n",
      "Train Epoch: 139 [40128/225000 (18%)] Loss: 18794.832031\n",
      "Train Epoch: 139 [42624/225000 (19%)] Loss: 19502.906250\n",
      "Train Epoch: 139 [45120/225000 (20%)] Loss: 19247.695312\n",
      "Train Epoch: 139 [47616/225000 (21%)] Loss: 18913.531250\n",
      "Train Epoch: 139 [50112/225000 (22%)] Loss: 19255.451172\n",
      "Train Epoch: 139 [52608/225000 (23%)] Loss: 19371.324219\n",
      "Train Epoch: 139 [55104/225000 (24%)] Loss: 19490.695312\n",
      "Train Epoch: 139 [57600/225000 (26%)] Loss: 19024.941406\n",
      "Train Epoch: 139 [60096/225000 (27%)] Loss: 19575.707031\n",
      "Train Epoch: 139 [62592/225000 (28%)] Loss: 19089.898438\n",
      "Train Epoch: 139 [65088/225000 (29%)] Loss: 19278.828125\n",
      "Train Epoch: 139 [67584/225000 (30%)] Loss: 19607.974609\n",
      "Train Epoch: 139 [70080/225000 (31%)] Loss: 18941.296875\n",
      "Train Epoch: 139 [72576/225000 (32%)] Loss: 19561.455078\n",
      "Train Epoch: 139 [75072/225000 (33%)] Loss: 19163.414062\n",
      "Train Epoch: 139 [77568/225000 (34%)] Loss: 19349.144531\n",
      "Train Epoch: 139 [80064/225000 (36%)] Loss: 19426.765625\n",
      "Train Epoch: 139 [82560/225000 (37%)] Loss: 19510.298828\n",
      "Train Epoch: 139 [85056/225000 (38%)] Loss: 19317.751953\n",
      "Train Epoch: 139 [87552/225000 (39%)] Loss: 19148.507812\n",
      "Train Epoch: 139 [90048/225000 (40%)] Loss: 19137.500000\n",
      "Train Epoch: 139 [92544/225000 (41%)] Loss: 19600.867188\n",
      "Train Epoch: 139 [95040/225000 (42%)] Loss: 19489.611328\n",
      "Train Epoch: 139 [97536/225000 (43%)] Loss: 19091.218750\n",
      "Train Epoch: 139 [100032/225000 (44%)] Loss: 19391.683594\n",
      "Train Epoch: 139 [102528/225000 (46%)] Loss: 19195.460938\n",
      "Train Epoch: 139 [105024/225000 (47%)] Loss: 19220.585938\n",
      "Train Epoch: 139 [107520/225000 (48%)] Loss: 18999.300781\n",
      "Train Epoch: 139 [110016/225000 (49%)] Loss: 19239.527344\n",
      "Train Epoch: 139 [112512/225000 (50%)] Loss: 19231.099609\n",
      "Train Epoch: 139 [115008/225000 (51%)] Loss: 19457.582031\n",
      "Train Epoch: 139 [117504/225000 (52%)] Loss: 18787.828125\n",
      "Train Epoch: 139 [120000/225000 (53%)] Loss: 19348.626953\n",
      "Train Epoch: 139 [122496/225000 (54%)] Loss: 19340.601562\n",
      "Train Epoch: 139 [124992/225000 (56%)] Loss: 19556.816406\n",
      "Train Epoch: 139 [127488/225000 (57%)] Loss: 19068.613281\n",
      "Train Epoch: 139 [129984/225000 (58%)] Loss: 18989.984375\n",
      "Train Epoch: 139 [132480/225000 (59%)] Loss: 19877.019531\n",
      "Train Epoch: 139 [134976/225000 (60%)] Loss: 19158.720703\n",
      "Train Epoch: 139 [137472/225000 (61%)] Loss: 19310.484375\n",
      "Train Epoch: 139 [139968/225000 (62%)] Loss: 19509.285156\n",
      "Train Epoch: 139 [142464/225000 (63%)] Loss: 18963.054688\n",
      "Train Epoch: 139 [144960/225000 (64%)] Loss: 18652.816406\n",
      "Train Epoch: 139 [147456/225000 (66%)] Loss: 19564.796875\n",
      "Train Epoch: 139 [149952/225000 (67%)] Loss: 19367.779297\n",
      "Train Epoch: 139 [152448/225000 (68%)] Loss: 18972.406250\n",
      "Train Epoch: 139 [154944/225000 (69%)] Loss: 19186.351562\n",
      "Train Epoch: 139 [157440/225000 (70%)] Loss: 19399.980469\n",
      "Train Epoch: 139 [159936/225000 (71%)] Loss: 19155.714844\n",
      "Train Epoch: 139 [162432/225000 (72%)] Loss: 18948.675781\n",
      "Train Epoch: 139 [164928/225000 (73%)] Loss: 19501.234375\n",
      "Train Epoch: 139 [167424/225000 (74%)] Loss: 18908.750000\n",
      "Train Epoch: 139 [169920/225000 (76%)] Loss: 19146.560547\n",
      "Train Epoch: 139 [172416/225000 (77%)] Loss: 18740.113281\n",
      "Train Epoch: 139 [174912/225000 (78%)] Loss: 19521.970703\n",
      "Train Epoch: 139 [177408/225000 (79%)] Loss: 19708.703125\n",
      "Train Epoch: 139 [179904/225000 (80%)] Loss: 19059.441406\n",
      "Train Epoch: 139 [182400/225000 (81%)] Loss: 19494.753906\n",
      "Train Epoch: 139 [184896/225000 (82%)] Loss: 18994.099609\n",
      "Train Epoch: 139 [187392/225000 (83%)] Loss: 19350.876953\n",
      "Train Epoch: 139 [189888/225000 (84%)] Loss: 19264.042969\n",
      "Train Epoch: 139 [192384/225000 (86%)] Loss: 18896.558594\n",
      "Train Epoch: 139 [194880/225000 (87%)] Loss: 18925.898438\n",
      "Train Epoch: 139 [197376/225000 (88%)] Loss: 18854.207031\n",
      "Train Epoch: 139 [199872/225000 (89%)] Loss: 19235.281250\n",
      "Train Epoch: 139 [202368/225000 (90%)] Loss: 19250.691406\n",
      "Train Epoch: 139 [204864/225000 (91%)] Loss: 18880.845703\n",
      "Train Epoch: 139 [207360/225000 (92%)] Loss: 19091.816406\n",
      "Train Epoch: 139 [209856/225000 (93%)] Loss: 19343.832031\n",
      "Train Epoch: 139 [212352/225000 (94%)] Loss: 19247.894531\n",
      "Train Epoch: 139 [214848/225000 (95%)] Loss: 19456.818359\n",
      "Train Epoch: 139 [217344/225000 (97%)] Loss: 19157.976562\n",
      "Train Epoch: 139 [219840/225000 (98%)] Loss: 19280.917969\n",
      "Train Epoch: 139 [222336/225000 (99%)] Loss: 19447.210938\n",
      "Train Epoch: 139 [224832/225000 (100%)] Loss: 19798.390625\n",
      "    epoch          : 139\n",
      "    loss           : 19304.090366194272\n",
      "    val_loss       : 19235.868312074937\n",
      "Train Epoch: 140 [192/225000 (0%)] Loss: 19503.744141\n",
      "Train Epoch: 140 [2688/225000 (1%)] Loss: 19167.148438\n",
      "Train Epoch: 140 [5184/225000 (2%)] Loss: 18892.382812\n",
      "Train Epoch: 140 [7680/225000 (3%)] Loss: 19046.169922\n",
      "Train Epoch: 140 [10176/225000 (5%)] Loss: 19219.429688\n",
      "Train Epoch: 140 [12672/225000 (6%)] Loss: 19307.541016\n",
      "Train Epoch: 140 [15168/225000 (7%)] Loss: 19168.800781\n",
      "Train Epoch: 140 [17664/225000 (8%)] Loss: 19249.835938\n",
      "Train Epoch: 140 [20160/225000 (9%)] Loss: 19147.636719\n",
      "Train Epoch: 140 [22656/225000 (10%)] Loss: 19254.185547\n",
      "Train Epoch: 140 [25152/225000 (11%)] Loss: 18916.371094\n",
      "Train Epoch: 140 [27648/225000 (12%)] Loss: 19154.603516\n",
      "Train Epoch: 140 [30144/225000 (13%)] Loss: 19099.007812\n",
      "Train Epoch: 140 [32640/225000 (15%)] Loss: 19003.314453\n",
      "Train Epoch: 140 [35136/225000 (16%)] Loss: 19577.708984\n",
      "Train Epoch: 140 [37632/225000 (17%)] Loss: 19448.121094\n",
      "Train Epoch: 140 [40128/225000 (18%)] Loss: 19529.816406\n",
      "Train Epoch: 140 [42624/225000 (19%)] Loss: 19316.949219\n",
      "Train Epoch: 140 [45120/225000 (20%)] Loss: 19497.544922\n",
      "Train Epoch: 140 [47616/225000 (21%)] Loss: 19116.126953\n",
      "Train Epoch: 140 [50112/225000 (22%)] Loss: 19498.359375\n",
      "Train Epoch: 140 [52608/225000 (23%)] Loss: 19270.871094\n",
      "Train Epoch: 140 [55104/225000 (24%)] Loss: 19508.765625\n",
      "Train Epoch: 140 [57600/225000 (26%)] Loss: 19699.027344\n",
      "Train Epoch: 140 [60096/225000 (27%)] Loss: 19363.687500\n",
      "Train Epoch: 140 [62592/225000 (28%)] Loss: 19405.376953\n",
      "Train Epoch: 140 [65088/225000 (29%)] Loss: 19144.183594\n",
      "Train Epoch: 140 [67584/225000 (30%)] Loss: 19332.244141\n",
      "Train Epoch: 140 [70080/225000 (31%)] Loss: 19540.453125\n",
      "Train Epoch: 140 [72576/225000 (32%)] Loss: 19400.050781\n",
      "Train Epoch: 140 [75072/225000 (33%)] Loss: 19497.847656\n",
      "Train Epoch: 140 [77568/225000 (34%)] Loss: 19180.287109\n",
      "Train Epoch: 140 [80064/225000 (36%)] Loss: 19318.320312\n",
      "Train Epoch: 140 [82560/225000 (37%)] Loss: 18812.501953\n",
      "Train Epoch: 140 [85056/225000 (38%)] Loss: 19211.707031\n",
      "Train Epoch: 140 [87552/225000 (39%)] Loss: 19409.326172\n",
      "Train Epoch: 140 [90048/225000 (40%)] Loss: 19090.025391\n",
      "Train Epoch: 140 [92544/225000 (41%)] Loss: 19562.730469\n",
      "Train Epoch: 140 [95040/225000 (42%)] Loss: 19345.433594\n",
      "Train Epoch: 140 [97536/225000 (43%)] Loss: 19644.148438\n",
      "Train Epoch: 140 [100032/225000 (44%)] Loss: 19383.806641\n",
      "Train Epoch: 140 [102528/225000 (46%)] Loss: 19134.113281\n",
      "Train Epoch: 140 [105024/225000 (47%)] Loss: 19550.406250\n",
      "Train Epoch: 140 [107520/225000 (48%)] Loss: 19259.496094\n",
      "Train Epoch: 140 [110016/225000 (49%)] Loss: 19605.308594\n",
      "Train Epoch: 140 [112512/225000 (50%)] Loss: 19408.328125\n",
      "Train Epoch: 140 [115008/225000 (51%)] Loss: 19317.406250\n",
      "Train Epoch: 140 [117504/225000 (52%)] Loss: 19554.875000\n",
      "Train Epoch: 140 [120000/225000 (53%)] Loss: 18993.691406\n",
      "Train Epoch: 140 [122496/225000 (54%)] Loss: 19628.324219\n",
      "Train Epoch: 140 [124992/225000 (56%)] Loss: 19252.656250\n",
      "Train Epoch: 140 [127488/225000 (57%)] Loss: 19291.677734\n",
      "Train Epoch: 140 [129984/225000 (58%)] Loss: 19203.658203\n",
      "Train Epoch: 140 [132480/225000 (59%)] Loss: 19243.570312\n",
      "Train Epoch: 140 [134976/225000 (60%)] Loss: 19024.542969\n",
      "Train Epoch: 140 [137472/225000 (61%)] Loss: 19322.625000\n",
      "Train Epoch: 140 [139968/225000 (62%)] Loss: 18946.865234\n",
      "Train Epoch: 140 [142464/225000 (63%)] Loss: 18660.585938\n",
      "Train Epoch: 140 [144960/225000 (64%)] Loss: 19452.027344\n",
      "Train Epoch: 140 [147456/225000 (66%)] Loss: 19428.730469\n",
      "Train Epoch: 140 [149952/225000 (67%)] Loss: 19176.511719\n",
      "Train Epoch: 140 [152448/225000 (68%)] Loss: 18844.935547\n",
      "Train Epoch: 140 [154944/225000 (69%)] Loss: 19432.964844\n",
      "Train Epoch: 140 [157440/225000 (70%)] Loss: 19440.894531\n",
      "Train Epoch: 140 [159936/225000 (71%)] Loss: 19650.666016\n",
      "Train Epoch: 140 [162432/225000 (72%)] Loss: 19416.076172\n",
      "Train Epoch: 140 [164928/225000 (73%)] Loss: 19628.359375\n",
      "Train Epoch: 140 [167424/225000 (74%)] Loss: 19548.015625\n",
      "Train Epoch: 140 [169920/225000 (76%)] Loss: 19492.550781\n",
      "Train Epoch: 140 [172416/225000 (77%)] Loss: 19399.330078\n",
      "Train Epoch: 140 [174912/225000 (78%)] Loss: 19024.792969\n",
      "Train Epoch: 140 [177408/225000 (79%)] Loss: 19257.525391\n",
      "Train Epoch: 140 [179904/225000 (80%)] Loss: 19265.818359\n",
      "Train Epoch: 140 [182400/225000 (81%)] Loss: 19140.347656\n",
      "Train Epoch: 140 [184896/225000 (82%)] Loss: 23402.101562\n",
      "Train Epoch: 140 [187392/225000 (83%)] Loss: 19509.156250\n",
      "Train Epoch: 140 [189888/225000 (84%)] Loss: 19144.070312\n",
      "Train Epoch: 140 [192384/225000 (86%)] Loss: 18973.947266\n",
      "Train Epoch: 140 [194880/225000 (87%)] Loss: 19316.955078\n",
      "Train Epoch: 140 [197376/225000 (88%)] Loss: 19236.328125\n",
      "Train Epoch: 140 [199872/225000 (89%)] Loss: 18814.105469\n",
      "Train Epoch: 140 [202368/225000 (90%)] Loss: 19212.492188\n",
      "Train Epoch: 140 [204864/225000 (91%)] Loss: 19071.867188\n",
      "Train Epoch: 140 [207360/225000 (92%)] Loss: 19532.906250\n",
      "Train Epoch: 140 [209856/225000 (93%)] Loss: 18971.660156\n",
      "Train Epoch: 140 [212352/225000 (94%)] Loss: 19229.027344\n",
      "Train Epoch: 140 [214848/225000 (95%)] Loss: 19461.113281\n",
      "Train Epoch: 140 [217344/225000 (97%)] Loss: 19303.957031\n",
      "Train Epoch: 140 [219840/225000 (98%)] Loss: 19380.089844\n",
      "Train Epoch: 140 [222336/225000 (99%)] Loss: 19271.421875\n",
      "Train Epoch: 140 [224832/225000 (100%)] Loss: 19362.833984\n",
      "    epoch          : 140\n",
      "    loss           : 19295.764090163717\n",
      "    val_loss       : 19243.425047549583\n",
      "Train Epoch: 141 [192/225000 (0%)] Loss: 18973.044922\n",
      "Train Epoch: 141 [2688/225000 (1%)] Loss: 19740.630859\n",
      "Train Epoch: 141 [5184/225000 (2%)] Loss: 19458.169922\n",
      "Train Epoch: 141 [7680/225000 (3%)] Loss: 19554.296875\n",
      "Train Epoch: 141 [10176/225000 (5%)] Loss: 19722.671875\n",
      "Train Epoch: 141 [12672/225000 (6%)] Loss: 19294.724609\n",
      "Train Epoch: 141 [15168/225000 (7%)] Loss: 19094.587891\n",
      "Train Epoch: 141 [17664/225000 (8%)] Loss: 19487.111328\n",
      "Train Epoch: 141 [20160/225000 (9%)] Loss: 19382.009766\n",
      "Train Epoch: 141 [22656/225000 (10%)] Loss: 19711.648438\n",
      "Train Epoch: 141 [25152/225000 (11%)] Loss: 19344.742188\n",
      "Train Epoch: 141 [27648/225000 (12%)] Loss: 18738.042969\n",
      "Train Epoch: 141 [30144/225000 (13%)] Loss: 18990.378906\n",
      "Train Epoch: 141 [32640/225000 (15%)] Loss: 19094.863281\n",
      "Train Epoch: 141 [35136/225000 (16%)] Loss: 18984.132812\n",
      "Train Epoch: 141 [37632/225000 (17%)] Loss: 19568.986328\n",
      "Train Epoch: 141 [40128/225000 (18%)] Loss: 19645.021484\n",
      "Train Epoch: 141 [42624/225000 (19%)] Loss: 19064.814453\n",
      "Train Epoch: 141 [45120/225000 (20%)] Loss: 19187.683594\n",
      "Train Epoch: 141 [47616/225000 (21%)] Loss: 19156.115234\n",
      "Train Epoch: 141 [50112/225000 (22%)] Loss: 19798.480469\n",
      "Train Epoch: 141 [52608/225000 (23%)] Loss: 19416.472656\n",
      "Train Epoch: 141 [55104/225000 (24%)] Loss: 19441.220703\n",
      "Train Epoch: 141 [57600/225000 (26%)] Loss: 19181.257812\n",
      "Train Epoch: 141 [60096/225000 (27%)] Loss: 19165.587891\n",
      "Train Epoch: 141 [62592/225000 (28%)] Loss: 19815.185547\n",
      "Train Epoch: 141 [65088/225000 (29%)] Loss: 19836.816406\n",
      "Train Epoch: 141 [67584/225000 (30%)] Loss: 19451.148438\n",
      "Train Epoch: 141 [70080/225000 (31%)] Loss: 18805.906250\n",
      "Train Epoch: 141 [72576/225000 (32%)] Loss: 19060.320312\n",
      "Train Epoch: 141 [75072/225000 (33%)] Loss: 19689.656250\n",
      "Train Epoch: 141 [77568/225000 (34%)] Loss: 19688.968750\n",
      "Train Epoch: 141 [80064/225000 (36%)] Loss: 19527.585938\n",
      "Train Epoch: 141 [82560/225000 (37%)] Loss: 19406.269531\n",
      "Train Epoch: 141 [85056/225000 (38%)] Loss: 19237.869141\n",
      "Train Epoch: 141 [87552/225000 (39%)] Loss: 18634.277344\n",
      "Train Epoch: 141 [90048/225000 (40%)] Loss: 18852.039062\n",
      "Train Epoch: 141 [92544/225000 (41%)] Loss: 18963.333984\n",
      "Train Epoch: 141 [95040/225000 (42%)] Loss: 19588.558594\n",
      "Train Epoch: 141 [97536/225000 (43%)] Loss: 19728.699219\n",
      "Train Epoch: 141 [100032/225000 (44%)] Loss: 19144.925781\n",
      "Train Epoch: 141 [102528/225000 (46%)] Loss: 19076.140625\n",
      "Train Epoch: 141 [105024/225000 (47%)] Loss: 19412.537109\n",
      "Train Epoch: 141 [107520/225000 (48%)] Loss: 19126.576172\n",
      "Train Epoch: 141 [110016/225000 (49%)] Loss: 19508.203125\n",
      "Train Epoch: 141 [112512/225000 (50%)] Loss: 18625.578125\n",
      "Train Epoch: 141 [115008/225000 (51%)] Loss: 19101.078125\n",
      "Train Epoch: 141 [117504/225000 (52%)] Loss: 19398.894531\n",
      "Train Epoch: 141 [120000/225000 (53%)] Loss: 19308.517578\n",
      "Train Epoch: 141 [122496/225000 (54%)] Loss: 19209.062500\n",
      "Train Epoch: 141 [124992/225000 (56%)] Loss: 19386.976562\n",
      "Train Epoch: 141 [127488/225000 (57%)] Loss: 18951.546875\n",
      "Train Epoch: 141 [129984/225000 (58%)] Loss: 19397.753906\n",
      "Train Epoch: 141 [132480/225000 (59%)] Loss: 19501.402344\n",
      "Train Epoch: 141 [134976/225000 (60%)] Loss: 19379.716797\n",
      "Train Epoch: 141 [137472/225000 (61%)] Loss: 19246.382812\n",
      "Train Epoch: 141 [139968/225000 (62%)] Loss: 19226.498047\n",
      "Train Epoch: 141 [142464/225000 (63%)] Loss: 19300.986328\n",
      "Train Epoch: 141 [144960/225000 (64%)] Loss: 18924.363281\n",
      "Train Epoch: 141 [147456/225000 (66%)] Loss: 19477.285156\n",
      "Train Epoch: 141 [149952/225000 (67%)] Loss: 19429.130859\n",
      "Train Epoch: 141 [152448/225000 (68%)] Loss: 20063.167969\n",
      "Train Epoch: 141 [154944/225000 (69%)] Loss: 19180.601562\n",
      "Train Epoch: 141 [157440/225000 (70%)] Loss: 19350.283203\n",
      "Train Epoch: 141 [159936/225000 (71%)] Loss: 19503.947266\n",
      "Train Epoch: 141 [162432/225000 (72%)] Loss: 19149.447266\n",
      "Train Epoch: 141 [164928/225000 (73%)] Loss: 19046.511719\n",
      "Train Epoch: 141 [167424/225000 (74%)] Loss: 18705.691406\n",
      "Train Epoch: 141 [169920/225000 (76%)] Loss: 19000.931641\n",
      "Train Epoch: 141 [172416/225000 (77%)] Loss: 19301.824219\n",
      "Train Epoch: 141 [174912/225000 (78%)] Loss: 19039.792969\n",
      "Train Epoch: 141 [177408/225000 (79%)] Loss: 19435.000000\n",
      "Train Epoch: 141 [179904/225000 (80%)] Loss: 19169.460938\n",
      "Train Epoch: 141 [182400/225000 (81%)] Loss: 18982.578125\n",
      "Train Epoch: 141 [184896/225000 (82%)] Loss: 19397.001953\n",
      "Train Epoch: 141 [187392/225000 (83%)] Loss: 19175.896484\n",
      "Train Epoch: 141 [189888/225000 (84%)] Loss: 19661.736328\n",
      "Train Epoch: 141 [192384/225000 (86%)] Loss: 19869.046875\n",
      "Train Epoch: 141 [194880/225000 (87%)] Loss: 19446.535156\n",
      "Train Epoch: 141 [197376/225000 (88%)] Loss: 19738.388672\n",
      "Train Epoch: 141 [199872/225000 (89%)] Loss: 19132.726562\n",
      "Train Epoch: 141 [202368/225000 (90%)] Loss: 19378.871094\n",
      "Train Epoch: 141 [204864/225000 (91%)] Loss: 19782.369141\n",
      "Train Epoch: 141 [207360/225000 (92%)] Loss: 19135.515625\n",
      "Train Epoch: 141 [209856/225000 (93%)] Loss: 18958.148438\n",
      "Train Epoch: 141 [212352/225000 (94%)] Loss: 19971.087891\n",
      "Train Epoch: 141 [214848/225000 (95%)] Loss: 19407.972656\n",
      "Train Epoch: 141 [217344/225000 (97%)] Loss: 19509.230469\n",
      "Train Epoch: 141 [219840/225000 (98%)] Loss: 19562.859375\n",
      "Train Epoch: 141 [222336/225000 (99%)] Loss: 19323.695312\n",
      "Train Epoch: 141 [224832/225000 (100%)] Loss: 19135.267578\n",
      "    epoch          : 141\n",
      "    loss           : 19293.20540309034\n",
      "    val_loss       : 19191.084313657448\n",
      "Train Epoch: 142 [192/225000 (0%)] Loss: 19482.718750\n",
      "Train Epoch: 142 [2688/225000 (1%)] Loss: 19877.574219\n",
      "Train Epoch: 142 [5184/225000 (2%)] Loss: 19018.496094\n",
      "Train Epoch: 142 [7680/225000 (3%)] Loss: 19162.533203\n",
      "Train Epoch: 142 [10176/225000 (5%)] Loss: 19383.371094\n",
      "Train Epoch: 142 [12672/225000 (6%)] Loss: 19300.929688\n",
      "Train Epoch: 142 [15168/225000 (7%)] Loss: 18651.007812\n",
      "Train Epoch: 142 [17664/225000 (8%)] Loss: 19059.878906\n",
      "Train Epoch: 142 [20160/225000 (9%)] Loss: 19446.035156\n",
      "Train Epoch: 142 [22656/225000 (10%)] Loss: 19231.011719\n",
      "Train Epoch: 142 [25152/225000 (11%)] Loss: 19080.937500\n",
      "Train Epoch: 142 [27648/225000 (12%)] Loss: 18897.964844\n",
      "Train Epoch: 142 [30144/225000 (13%)] Loss: 19768.671875\n",
      "Train Epoch: 142 [32640/225000 (15%)] Loss: 19297.121094\n",
      "Train Epoch: 142 [35136/225000 (16%)] Loss: 19380.074219\n",
      "Train Epoch: 142 [37632/225000 (17%)] Loss: 19303.605469\n",
      "Train Epoch: 142 [40128/225000 (18%)] Loss: 19195.353516\n",
      "Train Epoch: 142 [42624/225000 (19%)] Loss: 19854.136719\n",
      "Train Epoch: 142 [45120/225000 (20%)] Loss: 18921.328125\n",
      "Train Epoch: 142 [47616/225000 (21%)] Loss: 19143.171875\n",
      "Train Epoch: 142 [50112/225000 (22%)] Loss: 19283.480469\n",
      "Train Epoch: 142 [52608/225000 (23%)] Loss: 18935.070312\n",
      "Train Epoch: 142 [55104/225000 (24%)] Loss: 18706.500000\n",
      "Train Epoch: 142 [57600/225000 (26%)] Loss: 19165.498047\n",
      "Train Epoch: 142 [60096/225000 (27%)] Loss: 19168.544922\n",
      "Train Epoch: 142 [62592/225000 (28%)] Loss: 18992.519531\n",
      "Train Epoch: 142 [65088/225000 (29%)] Loss: 19514.500000\n",
      "Train Epoch: 142 [67584/225000 (30%)] Loss: 19855.697266\n",
      "Train Epoch: 142 [70080/225000 (31%)] Loss: 19313.332031\n",
      "Train Epoch: 142 [72576/225000 (32%)] Loss: 19347.136719\n",
      "Train Epoch: 142 [75072/225000 (33%)] Loss: 19385.630859\n",
      "Train Epoch: 142 [77568/225000 (34%)] Loss: 19294.437500\n",
      "Train Epoch: 142 [80064/225000 (36%)] Loss: 19782.029297\n",
      "Train Epoch: 142 [82560/225000 (37%)] Loss: 19083.210938\n",
      "Train Epoch: 142 [85056/225000 (38%)] Loss: 19356.925781\n",
      "Train Epoch: 142 [87552/225000 (39%)] Loss: 19150.476562\n",
      "Train Epoch: 142 [90048/225000 (40%)] Loss: 19256.765625\n",
      "Train Epoch: 142 [92544/225000 (41%)] Loss: 19684.468750\n",
      "Train Epoch: 142 [95040/225000 (42%)] Loss: 18852.046875\n",
      "Train Epoch: 142 [97536/225000 (43%)] Loss: 19252.269531\n",
      "Train Epoch: 142 [100032/225000 (44%)] Loss: 19201.976562\n",
      "Train Epoch: 142 [102528/225000 (46%)] Loss: 19009.636719\n",
      "Train Epoch: 142 [105024/225000 (47%)] Loss: 19335.978516\n",
      "Train Epoch: 142 [107520/225000 (48%)] Loss: 19087.035156\n",
      "Train Epoch: 142 [110016/225000 (49%)] Loss: 18576.019531\n",
      "Train Epoch: 142 [112512/225000 (50%)] Loss: 19038.583984\n",
      "Train Epoch: 142 [115008/225000 (51%)] Loss: 19497.785156\n",
      "Train Epoch: 142 [117504/225000 (52%)] Loss: 19525.816406\n",
      "Train Epoch: 142 [120000/225000 (53%)] Loss: 19531.257812\n",
      "Train Epoch: 142 [122496/225000 (54%)] Loss: 18871.691406\n",
      "Train Epoch: 142 [124992/225000 (56%)] Loss: 19373.808594\n",
      "Train Epoch: 142 [127488/225000 (57%)] Loss: 19576.046875\n",
      "Train Epoch: 142 [129984/225000 (58%)] Loss: 19300.666016\n",
      "Train Epoch: 142 [132480/225000 (59%)] Loss: 19095.408203\n",
      "Train Epoch: 142 [134976/225000 (60%)] Loss: 19338.664062\n",
      "Train Epoch: 142 [137472/225000 (61%)] Loss: 19559.111328\n",
      "Train Epoch: 142 [139968/225000 (62%)] Loss: 18921.773438\n",
      "Train Epoch: 142 [142464/225000 (63%)] Loss: 19335.085938\n",
      "Train Epoch: 142 [144960/225000 (64%)] Loss: 19372.634766\n",
      "Train Epoch: 142 [147456/225000 (66%)] Loss: 19754.818359\n",
      "Train Epoch: 142 [149952/225000 (67%)] Loss: 19371.648438\n",
      "Train Epoch: 142 [152448/225000 (68%)] Loss: 19346.335938\n",
      "Train Epoch: 142 [154944/225000 (69%)] Loss: 19258.316406\n",
      "Train Epoch: 142 [157440/225000 (70%)] Loss: 18910.611328\n",
      "Train Epoch: 142 [159936/225000 (71%)] Loss: 19306.839844\n",
      "Train Epoch: 142 [162432/225000 (72%)] Loss: 19053.621094\n",
      "Train Epoch: 142 [164928/225000 (73%)] Loss: 19377.130859\n",
      "Train Epoch: 142 [167424/225000 (74%)] Loss: 19339.667969\n",
      "Train Epoch: 142 [169920/225000 (76%)] Loss: 19771.757812\n",
      "Train Epoch: 142 [172416/225000 (77%)] Loss: 19795.273438\n",
      "Train Epoch: 142 [174912/225000 (78%)] Loss: 18613.058594\n",
      "Train Epoch: 142 [177408/225000 (79%)] Loss: 18869.734375\n",
      "Train Epoch: 142 [179904/225000 (80%)] Loss: 19048.638672\n",
      "Train Epoch: 142 [182400/225000 (81%)] Loss: 19466.566406\n",
      "Train Epoch: 142 [184896/225000 (82%)] Loss: 19465.687500\n",
      "Train Epoch: 142 [187392/225000 (83%)] Loss: 19155.828125\n",
      "Train Epoch: 142 [189888/225000 (84%)] Loss: 19218.142578\n",
      "Train Epoch: 142 [192384/225000 (86%)] Loss: 19289.261719\n",
      "Train Epoch: 142 [194880/225000 (87%)] Loss: 19375.423828\n",
      "Train Epoch: 142 [197376/225000 (88%)] Loss: 19072.207031\n",
      "Train Epoch: 142 [199872/225000 (89%)] Loss: 19420.679688\n",
      "Train Epoch: 142 [202368/225000 (90%)] Loss: 19295.964844\n",
      "Train Epoch: 142 [204864/225000 (91%)] Loss: 19055.765625\n",
      "Train Epoch: 142 [207360/225000 (92%)] Loss: 18776.750000\n",
      "Train Epoch: 142 [209856/225000 (93%)] Loss: 19204.492188\n",
      "Train Epoch: 142 [212352/225000 (94%)] Loss: 19640.843750\n",
      "Train Epoch: 142 [214848/225000 (95%)] Loss: 19711.224609\n",
      "Train Epoch: 142 [217344/225000 (97%)] Loss: 19722.351562\n",
      "Train Epoch: 142 [219840/225000 (98%)] Loss: 19395.085938\n",
      "Train Epoch: 142 [222336/225000 (99%)] Loss: 19404.480469\n",
      "Train Epoch: 142 [224832/225000 (100%)] Loss: 19492.716797\n",
      "    epoch          : 142\n",
      "    loss           : 19287.821279063566\n",
      "    val_loss       : 19201.209771938906\n",
      "Train Epoch: 143 [192/225000 (0%)] Loss: 19037.707031\n",
      "Train Epoch: 143 [2688/225000 (1%)] Loss: 19717.894531\n",
      "Train Epoch: 143 [5184/225000 (2%)] Loss: 19564.238281\n",
      "Train Epoch: 143 [7680/225000 (3%)] Loss: 19361.269531\n",
      "Train Epoch: 143 [10176/225000 (5%)] Loss: 19051.925781\n",
      "Train Epoch: 143 [12672/225000 (6%)] Loss: 19521.261719\n",
      "Train Epoch: 143 [15168/225000 (7%)] Loss: 19559.333984\n",
      "Train Epoch: 143 [17664/225000 (8%)] Loss: 19229.382812\n",
      "Train Epoch: 143 [20160/225000 (9%)] Loss: 18952.855469\n",
      "Train Epoch: 143 [22656/225000 (10%)] Loss: 19517.072266\n",
      "Train Epoch: 143 [25152/225000 (11%)] Loss: 19152.949219\n",
      "Train Epoch: 143 [27648/225000 (12%)] Loss: 19670.109375\n",
      "Train Epoch: 143 [30144/225000 (13%)] Loss: 18917.109375\n",
      "Train Epoch: 143 [32640/225000 (15%)] Loss: 19024.699219\n",
      "Train Epoch: 143 [35136/225000 (16%)] Loss: 19018.171875\n",
      "Train Epoch: 143 [37632/225000 (17%)] Loss: 19572.160156\n",
      "Train Epoch: 143 [40128/225000 (18%)] Loss: 19359.078125\n",
      "Train Epoch: 143 [42624/225000 (19%)] Loss: 19149.445312\n",
      "Train Epoch: 143 [45120/225000 (20%)] Loss: 19914.785156\n",
      "Train Epoch: 143 [47616/225000 (21%)] Loss: 19146.718750\n",
      "Train Epoch: 143 [50112/225000 (22%)] Loss: 19099.429688\n",
      "Train Epoch: 143 [52608/225000 (23%)] Loss: 20139.175781\n",
      "Train Epoch: 143 [55104/225000 (24%)] Loss: 19063.707031\n",
      "Train Epoch: 143 [57600/225000 (26%)] Loss: 19468.410156\n",
      "Train Epoch: 143 [60096/225000 (27%)] Loss: 18704.710938\n",
      "Train Epoch: 143 [62592/225000 (28%)] Loss: 19370.134766\n",
      "Train Epoch: 143 [65088/225000 (29%)] Loss: 19165.718750\n",
      "Train Epoch: 143 [67584/225000 (30%)] Loss: 19174.884766\n",
      "Train Epoch: 143 [70080/225000 (31%)] Loss: 18944.078125\n",
      "Train Epoch: 143 [72576/225000 (32%)] Loss: 18991.839844\n",
      "Train Epoch: 143 [75072/225000 (33%)] Loss: 19051.318359\n",
      "Train Epoch: 143 [77568/225000 (34%)] Loss: 19902.511719\n",
      "Train Epoch: 143 [80064/225000 (36%)] Loss: 19377.087891\n",
      "Train Epoch: 143 [82560/225000 (37%)] Loss: 19353.708984\n",
      "Train Epoch: 143 [85056/225000 (38%)] Loss: 19324.994141\n",
      "Train Epoch: 143 [87552/225000 (39%)] Loss: 19327.355469\n",
      "Train Epoch: 143 [90048/225000 (40%)] Loss: 19307.804688\n",
      "Train Epoch: 143 [92544/225000 (41%)] Loss: 18912.113281\n",
      "Train Epoch: 143 [95040/225000 (42%)] Loss: 19392.769531\n",
      "Train Epoch: 143 [97536/225000 (43%)] Loss: 19659.085938\n",
      "Train Epoch: 143 [100032/225000 (44%)] Loss: 19485.539062\n",
      "Train Epoch: 143 [102528/225000 (46%)] Loss: 18847.097656\n",
      "Train Epoch: 143 [105024/225000 (47%)] Loss: 19247.003906\n",
      "Train Epoch: 143 [107520/225000 (48%)] Loss: 19156.988281\n",
      "Train Epoch: 143 [110016/225000 (49%)] Loss: 19378.376953\n",
      "Train Epoch: 143 [112512/225000 (50%)] Loss: 19363.425781\n",
      "Train Epoch: 143 [115008/225000 (51%)] Loss: 18951.976562\n",
      "Train Epoch: 143 [117504/225000 (52%)] Loss: 19479.537109\n",
      "Train Epoch: 143 [120000/225000 (53%)] Loss: 19164.109375\n",
      "Train Epoch: 143 [122496/225000 (54%)] Loss: 18909.660156\n",
      "Train Epoch: 143 [124992/225000 (56%)] Loss: 19106.908203\n",
      "Train Epoch: 143 [127488/225000 (57%)] Loss: 19358.773438\n",
      "Train Epoch: 143 [129984/225000 (58%)] Loss: 19111.292969\n",
      "Train Epoch: 143 [132480/225000 (59%)] Loss: 19374.390625\n",
      "Train Epoch: 143 [134976/225000 (60%)] Loss: 19404.007812\n",
      "Train Epoch: 143 [137472/225000 (61%)] Loss: 19363.074219\n",
      "Train Epoch: 143 [139968/225000 (62%)] Loss: 19682.722656\n",
      "Train Epoch: 143 [142464/225000 (63%)] Loss: 19147.300781\n",
      "Train Epoch: 143 [144960/225000 (64%)] Loss: 18841.494141\n",
      "Train Epoch: 143 [147456/225000 (66%)] Loss: 19559.943359\n",
      "Train Epoch: 143 [149952/225000 (67%)] Loss: 19404.468750\n",
      "Train Epoch: 143 [152448/225000 (68%)] Loss: 19504.082031\n",
      "Train Epoch: 143 [154944/225000 (69%)] Loss: 19233.453125\n",
      "Train Epoch: 143 [157440/225000 (70%)] Loss: 19809.015625\n",
      "Train Epoch: 143 [159936/225000 (71%)] Loss: 19513.853516\n",
      "Train Epoch: 143 [162432/225000 (72%)] Loss: 19334.623047\n",
      "Train Epoch: 143 [164928/225000 (73%)] Loss: 19169.970703\n",
      "Train Epoch: 143 [167424/225000 (74%)] Loss: 19343.673828\n",
      "Train Epoch: 143 [169920/225000 (76%)] Loss: 19338.652344\n",
      "Train Epoch: 143 [172416/225000 (77%)] Loss: 18717.304688\n",
      "Train Epoch: 143 [174912/225000 (78%)] Loss: 19104.839844\n",
      "Train Epoch: 143 [177408/225000 (79%)] Loss: 18836.058594\n",
      "Train Epoch: 143 [179904/225000 (80%)] Loss: 19495.451172\n",
      "Train Epoch: 143 [182400/225000 (81%)] Loss: 18832.035156\n",
      "Train Epoch: 143 [184896/225000 (82%)] Loss: 19609.269531\n",
      "Train Epoch: 143 [187392/225000 (83%)] Loss: 19217.978516\n",
      "Train Epoch: 143 [189888/225000 (84%)] Loss: 19388.949219\n",
      "Train Epoch: 143 [192384/225000 (86%)] Loss: 19027.558594\n",
      "Train Epoch: 143 [194880/225000 (87%)] Loss: 18966.457031\n",
      "Train Epoch: 143 [197376/225000 (88%)] Loss: 19126.574219\n",
      "Train Epoch: 143 [199872/225000 (89%)] Loss: 19448.855469\n",
      "Train Epoch: 143 [202368/225000 (90%)] Loss: 19217.701172\n",
      "Train Epoch: 143 [204864/225000 (91%)] Loss: 19393.158203\n",
      "Train Epoch: 143 [207360/225000 (92%)] Loss: 19262.113281\n",
      "Train Epoch: 143 [209856/225000 (93%)] Loss: 19284.355469\n",
      "Train Epoch: 143 [212352/225000 (94%)] Loss: 19233.406250\n",
      "Train Epoch: 143 [214848/225000 (95%)] Loss: 19144.847656\n",
      "Train Epoch: 143 [217344/225000 (97%)] Loss: 19076.660156\n",
      "Train Epoch: 143 [219840/225000 (98%)] Loss: 18862.240234\n",
      "Train Epoch: 143 [222336/225000 (99%)] Loss: 19037.349609\n",
      "Train Epoch: 143 [224832/225000 (100%)] Loss: 19454.822266\n",
      "    epoch          : 143\n",
      "    loss           : 19277.565186380118\n",
      "    val_loss       : 19179.528079650783\n",
      "Train Epoch: 144 [192/225000 (0%)] Loss: 19033.230469\n",
      "Train Epoch: 144 [2688/225000 (1%)] Loss: 19174.994141\n",
      "Train Epoch: 144 [5184/225000 (2%)] Loss: 19478.511719\n",
      "Train Epoch: 144 [7680/225000 (3%)] Loss: 19079.519531\n",
      "Train Epoch: 144 [10176/225000 (5%)] Loss: 19269.687500\n",
      "Train Epoch: 144 [12672/225000 (6%)] Loss: 19242.609375\n",
      "Train Epoch: 144 [15168/225000 (7%)] Loss: 18914.261719\n",
      "Train Epoch: 144 [17664/225000 (8%)] Loss: 19098.142578\n",
      "Train Epoch: 144 [20160/225000 (9%)] Loss: 19193.734375\n",
      "Train Epoch: 144 [22656/225000 (10%)] Loss: 19308.472656\n",
      "Train Epoch: 144 [25152/225000 (11%)] Loss: 19207.179688\n",
      "Train Epoch: 144 [27648/225000 (12%)] Loss: 19243.234375\n",
      "Train Epoch: 144 [30144/225000 (13%)] Loss: 19316.718750\n",
      "Train Epoch: 144 [32640/225000 (15%)] Loss: 19329.076172\n",
      "Train Epoch: 144 [35136/225000 (16%)] Loss: 19459.953125\n",
      "Train Epoch: 144 [37632/225000 (17%)] Loss: 19072.863281\n",
      "Train Epoch: 144 [40128/225000 (18%)] Loss: 19406.158203\n",
      "Train Epoch: 144 [42624/225000 (19%)] Loss: 19116.078125\n",
      "Train Epoch: 144 [45120/225000 (20%)] Loss: 19447.123047\n",
      "Train Epoch: 144 [47616/225000 (21%)] Loss: 19245.576172\n",
      "Train Epoch: 144 [50112/225000 (22%)] Loss: 19302.466797\n",
      "Train Epoch: 144 [52608/225000 (23%)] Loss: 19173.675781\n",
      "Train Epoch: 144 [55104/225000 (24%)] Loss: 19075.984375\n",
      "Train Epoch: 144 [57600/225000 (26%)] Loss: 19312.968750\n",
      "Train Epoch: 144 [60096/225000 (27%)] Loss: 19750.117188\n",
      "Train Epoch: 144 [62592/225000 (28%)] Loss: 19419.886719\n",
      "Train Epoch: 144 [65088/225000 (29%)] Loss: 18999.894531\n",
      "Train Epoch: 144 [67584/225000 (30%)] Loss: 19484.335938\n",
      "Train Epoch: 144 [70080/225000 (31%)] Loss: 19845.378906\n",
      "Train Epoch: 144 [72576/225000 (32%)] Loss: 19329.787109\n",
      "Train Epoch: 144 [75072/225000 (33%)] Loss: 19303.203125\n",
      "Train Epoch: 144 [77568/225000 (34%)] Loss: 19562.796875\n",
      "Train Epoch: 144 [80064/225000 (36%)] Loss: 19574.650391\n",
      "Train Epoch: 144 [82560/225000 (37%)] Loss: 19504.392578\n",
      "Train Epoch: 144 [85056/225000 (38%)] Loss: 18645.734375\n",
      "Train Epoch: 144 [87552/225000 (39%)] Loss: 18979.796875\n",
      "Train Epoch: 144 [90048/225000 (40%)] Loss: 19077.863281\n",
      "Train Epoch: 144 [92544/225000 (41%)] Loss: 19363.599609\n",
      "Train Epoch: 144 [95040/225000 (42%)] Loss: 19333.664062\n",
      "Train Epoch: 144 [97536/225000 (43%)] Loss: 19237.175781\n",
      "Train Epoch: 144 [100032/225000 (44%)] Loss: 19033.921875\n",
      "Train Epoch: 144 [102528/225000 (46%)] Loss: 19428.359375\n",
      "Train Epoch: 144 [105024/225000 (47%)] Loss: 19283.414062\n",
      "Train Epoch: 144 [107520/225000 (48%)] Loss: 19534.972656\n",
      "Train Epoch: 144 [110016/225000 (49%)] Loss: 19258.496094\n",
      "Train Epoch: 144 [112512/225000 (50%)] Loss: 19621.136719\n",
      "Train Epoch: 144 [115008/225000 (51%)] Loss: 19337.892578\n",
      "Train Epoch: 144 [117504/225000 (52%)] Loss: 19412.816406\n",
      "Train Epoch: 144 [120000/225000 (53%)] Loss: 19436.669922\n",
      "Train Epoch: 144 [122496/225000 (54%)] Loss: 19169.933594\n",
      "Train Epoch: 144 [124992/225000 (56%)] Loss: 19537.960938\n",
      "Train Epoch: 144 [127488/225000 (57%)] Loss: 18949.115234\n",
      "Train Epoch: 144 [129984/225000 (58%)] Loss: 19299.882812\n",
      "Train Epoch: 144 [132480/225000 (59%)] Loss: 19421.929688\n",
      "Train Epoch: 144 [134976/225000 (60%)] Loss: 19471.378906\n",
      "Train Epoch: 144 [137472/225000 (61%)] Loss: 19529.027344\n",
      "Train Epoch: 144 [139968/225000 (62%)] Loss: 19623.789062\n",
      "Train Epoch: 144 [142464/225000 (63%)] Loss: 19097.132812\n",
      "Train Epoch: 144 [144960/225000 (64%)] Loss: 19207.390625\n",
      "Train Epoch: 144 [147456/225000 (66%)] Loss: 19512.269531\n",
      "Train Epoch: 144 [149952/225000 (67%)] Loss: 19337.183594\n",
      "Train Epoch: 144 [152448/225000 (68%)] Loss: 19234.878906\n",
      "Train Epoch: 144 [154944/225000 (69%)] Loss: 19629.773438\n",
      "Train Epoch: 144 [157440/225000 (70%)] Loss: 19398.675781\n",
      "Train Epoch: 144 [159936/225000 (71%)] Loss: 19289.230469\n",
      "Train Epoch: 144 [162432/225000 (72%)] Loss: 19417.652344\n",
      "Train Epoch: 144 [164928/225000 (73%)] Loss: 19212.218750\n",
      "Train Epoch: 144 [167424/225000 (74%)] Loss: 19046.644531\n",
      "Train Epoch: 144 [169920/225000 (76%)] Loss: 19589.886719\n",
      "Train Epoch: 144 [172416/225000 (77%)] Loss: 19147.007812\n",
      "Train Epoch: 144 [174912/225000 (78%)] Loss: 18802.804688\n",
      "Train Epoch: 144 [177408/225000 (79%)] Loss: 19311.609375\n",
      "Train Epoch: 144 [179904/225000 (80%)] Loss: 19207.488281\n",
      "Train Epoch: 144 [182400/225000 (81%)] Loss: 19377.976562\n",
      "Train Epoch: 144 [184896/225000 (82%)] Loss: 19261.185547\n",
      "Train Epoch: 144 [187392/225000 (83%)] Loss: 19060.953125\n",
      "Train Epoch: 144 [189888/225000 (84%)] Loss: 18795.851562\n",
      "Train Epoch: 144 [192384/225000 (86%)] Loss: 18961.583984\n",
      "Train Epoch: 144 [194880/225000 (87%)] Loss: 19782.808594\n",
      "Train Epoch: 144 [197376/225000 (88%)] Loss: 19499.078125\n",
      "Train Epoch: 144 [199872/225000 (89%)] Loss: 19382.267578\n",
      "Train Epoch: 144 [202368/225000 (90%)] Loss: 19754.154297\n",
      "Train Epoch: 144 [204864/225000 (91%)] Loss: 19432.429688\n",
      "Train Epoch: 144 [207360/225000 (92%)] Loss: 19285.953125\n",
      "Train Epoch: 144 [209856/225000 (93%)] Loss: 18962.363281\n",
      "Train Epoch: 144 [212352/225000 (94%)] Loss: 19325.875000\n",
      "Train Epoch: 144 [214848/225000 (95%)] Loss: 18754.722656\n",
      "Train Epoch: 144 [217344/225000 (97%)] Loss: 19501.363281\n",
      "Train Epoch: 144 [219840/225000 (98%)] Loss: 19229.230469\n",
      "Train Epoch: 144 [222336/225000 (99%)] Loss: 18922.929688\n",
      "Train Epoch: 144 [224832/225000 (100%)] Loss: 19088.476562\n",
      "    epoch          : 144\n",
      "    loss           : 19281.917657116574\n",
      "    val_loss       : 19245.13705095535\n",
      "Train Epoch: 145 [192/225000 (0%)] Loss: 19642.800781\n",
      "Train Epoch: 145 [2688/225000 (1%)] Loss: 19293.769531\n",
      "Train Epoch: 145 [5184/225000 (2%)] Loss: 19270.179688\n",
      "Train Epoch: 145 [7680/225000 (3%)] Loss: 19125.578125\n",
      "Train Epoch: 145 [10176/225000 (5%)] Loss: 19799.972656\n",
      "Train Epoch: 145 [12672/225000 (6%)] Loss: 19844.771484\n",
      "Train Epoch: 145 [15168/225000 (7%)] Loss: 19424.648438\n",
      "Train Epoch: 145 [17664/225000 (8%)] Loss: 19686.007812\n",
      "Train Epoch: 145 [20160/225000 (9%)] Loss: 18939.628906\n",
      "Train Epoch: 145 [22656/225000 (10%)] Loss: 19149.882812\n",
      "Train Epoch: 145 [25152/225000 (11%)] Loss: 19612.531250\n",
      "Train Epoch: 145 [27648/225000 (12%)] Loss: 19252.511719\n",
      "Train Epoch: 145 [30144/225000 (13%)] Loss: 18979.953125\n",
      "Train Epoch: 145 [32640/225000 (15%)] Loss: 19648.816406\n",
      "Train Epoch: 145 [35136/225000 (16%)] Loss: 19126.304688\n",
      "Train Epoch: 145 [37632/225000 (17%)] Loss: 19104.769531\n",
      "Train Epoch: 145 [40128/225000 (18%)] Loss: 19494.464844\n",
      "Train Epoch: 145 [42624/225000 (19%)] Loss: 19346.027344\n",
      "Train Epoch: 145 [45120/225000 (20%)] Loss: 19351.816406\n",
      "Train Epoch: 145 [47616/225000 (21%)] Loss: 19195.324219\n",
      "Train Epoch: 145 [50112/225000 (22%)] Loss: 19078.718750\n",
      "Train Epoch: 145 [52608/225000 (23%)] Loss: 19530.960938\n",
      "Train Epoch: 145 [55104/225000 (24%)] Loss: 19211.322266\n",
      "Train Epoch: 145 [57600/225000 (26%)] Loss: 19457.929688\n",
      "Train Epoch: 145 [60096/225000 (27%)] Loss: 19291.294922\n",
      "Train Epoch: 145 [62592/225000 (28%)] Loss: 19490.064453\n",
      "Train Epoch: 145 [65088/225000 (29%)] Loss: 18923.138672\n",
      "Train Epoch: 145 [67584/225000 (30%)] Loss: 18969.197266\n",
      "Train Epoch: 145 [70080/225000 (31%)] Loss: 19128.691406\n",
      "Train Epoch: 145 [72576/225000 (32%)] Loss: 19643.949219\n",
      "Train Epoch: 145 [75072/225000 (33%)] Loss: 18987.564453\n",
      "Train Epoch: 145 [77568/225000 (34%)] Loss: 19335.773438\n",
      "Train Epoch: 145 [80064/225000 (36%)] Loss: 18631.208984\n",
      "Train Epoch: 145 [82560/225000 (37%)] Loss: 19447.960938\n",
      "Train Epoch: 145 [85056/225000 (38%)] Loss: 19602.925781\n",
      "Train Epoch: 145 [87552/225000 (39%)] Loss: 19156.015625\n",
      "Train Epoch: 145 [90048/225000 (40%)] Loss: 19224.304688\n",
      "Train Epoch: 145 [92544/225000 (41%)] Loss: 19342.375000\n",
      "Train Epoch: 145 [95040/225000 (42%)] Loss: 18745.402344\n",
      "Train Epoch: 145 [97536/225000 (43%)] Loss: 19229.929688\n",
      "Train Epoch: 145 [100032/225000 (44%)] Loss: 19255.906250\n",
      "Train Epoch: 145 [102528/225000 (46%)] Loss: 19291.214844\n",
      "Train Epoch: 145 [105024/225000 (47%)] Loss: 19272.691406\n",
      "Train Epoch: 145 [107520/225000 (48%)] Loss: 18763.945312\n",
      "Train Epoch: 145 [110016/225000 (49%)] Loss: 19737.960938\n",
      "Train Epoch: 145 [112512/225000 (50%)] Loss: 19281.949219\n",
      "Train Epoch: 145 [115008/225000 (51%)] Loss: 19132.136719\n",
      "Train Epoch: 145 [117504/225000 (52%)] Loss: 19448.019531\n",
      "Train Epoch: 145 [120000/225000 (53%)] Loss: 19587.542969\n",
      "Train Epoch: 145 [122496/225000 (54%)] Loss: 19132.195312\n",
      "Train Epoch: 145 [124992/225000 (56%)] Loss: 19979.382812\n",
      "Train Epoch: 145 [127488/225000 (57%)] Loss: 19022.880859\n",
      "Train Epoch: 145 [129984/225000 (58%)] Loss: 19365.720703\n",
      "Train Epoch: 145 [132480/225000 (59%)] Loss: 19618.904297\n",
      "Train Epoch: 145 [134976/225000 (60%)] Loss: 19467.105469\n",
      "Train Epoch: 145 [137472/225000 (61%)] Loss: 19276.218750\n",
      "Train Epoch: 145 [139968/225000 (62%)] Loss: 19459.789062\n",
      "Train Epoch: 145 [142464/225000 (63%)] Loss: 19125.050781\n",
      "Train Epoch: 145 [144960/225000 (64%)] Loss: 18980.703125\n",
      "Train Epoch: 145 [147456/225000 (66%)] Loss: 19416.093750\n",
      "Train Epoch: 145 [149952/225000 (67%)] Loss: 19672.548828\n",
      "Train Epoch: 145 [152448/225000 (68%)] Loss: 19501.261719\n",
      "Train Epoch: 145 [154944/225000 (69%)] Loss: 19511.464844\n",
      "Train Epoch: 145 [157440/225000 (70%)] Loss: 19491.599609\n",
      "Train Epoch: 145 [159936/225000 (71%)] Loss: 19099.302734\n",
      "Train Epoch: 145 [162432/225000 (72%)] Loss: 19836.861328\n",
      "Train Epoch: 145 [164928/225000 (73%)] Loss: 19399.396484\n",
      "Train Epoch: 145 [167424/225000 (74%)] Loss: 19672.386719\n",
      "Train Epoch: 145 [169920/225000 (76%)] Loss: 19636.882812\n",
      "Train Epoch: 145 [172416/225000 (77%)] Loss: 19078.035156\n",
      "Train Epoch: 145 [174912/225000 (78%)] Loss: 19145.197266\n",
      "Train Epoch: 145 [177408/225000 (79%)] Loss: 19133.619141\n",
      "Train Epoch: 145 [179904/225000 (80%)] Loss: 19122.433594\n",
      "Train Epoch: 145 [182400/225000 (81%)] Loss: 19593.628906\n",
      "Train Epoch: 145 [184896/225000 (82%)] Loss: 19134.242188\n",
      "Train Epoch: 145 [187392/225000 (83%)] Loss: 19204.773438\n",
      "Train Epoch: 145 [189888/225000 (84%)] Loss: 19563.005859\n",
      "Train Epoch: 145 [192384/225000 (86%)] Loss: 18959.716797\n",
      "Train Epoch: 145 [194880/225000 (87%)] Loss: 19766.748047\n",
      "Train Epoch: 145 [197376/225000 (88%)] Loss: 19093.082031\n",
      "Train Epoch: 145 [199872/225000 (89%)] Loss: 19434.285156\n",
      "Train Epoch: 145 [202368/225000 (90%)] Loss: 18974.800781\n",
      "Train Epoch: 145 [204864/225000 (91%)] Loss: 19414.318359\n",
      "Train Epoch: 145 [207360/225000 (92%)] Loss: 19196.644531\n",
      "Train Epoch: 145 [209856/225000 (93%)] Loss: 19186.587891\n",
      "Train Epoch: 145 [212352/225000 (94%)] Loss: 18840.564453\n",
      "Train Epoch: 145 [214848/225000 (95%)] Loss: 19126.394531\n",
      "Train Epoch: 145 [217344/225000 (97%)] Loss: 19492.800781\n",
      "Train Epoch: 145 [219840/225000 (98%)] Loss: 19609.191406\n",
      "Train Epoch: 145 [222336/225000 (99%)] Loss: 19454.667969\n",
      "Train Epoch: 145 [224832/225000 (100%)] Loss: 18930.406250\n",
      "    epoch          : 145\n",
      "    loss           : 19279.6320159183\n",
      "    val_loss       : 19205.869158026828\n",
      "Train Epoch: 146 [192/225000 (0%)] Loss: 19303.406250\n",
      "Train Epoch: 146 [2688/225000 (1%)] Loss: 19099.398438\n",
      "Train Epoch: 146 [5184/225000 (2%)] Loss: 19416.136719\n",
      "Train Epoch: 146 [7680/225000 (3%)] Loss: 19666.916016\n",
      "Train Epoch: 146 [10176/225000 (5%)] Loss: 19588.910156\n",
      "Train Epoch: 146 [12672/225000 (6%)] Loss: 19419.595703\n",
      "Train Epoch: 146 [15168/225000 (7%)] Loss: 19171.373047\n",
      "Train Epoch: 146 [17664/225000 (8%)] Loss: 19211.851562\n",
      "Train Epoch: 146 [20160/225000 (9%)] Loss: 19216.589844\n",
      "Train Epoch: 146 [22656/225000 (10%)] Loss: 19326.890625\n",
      "Train Epoch: 146 [25152/225000 (11%)] Loss: 18999.023438\n",
      "Train Epoch: 146 [27648/225000 (12%)] Loss: 19338.332031\n",
      "Train Epoch: 146 [30144/225000 (13%)] Loss: 19278.384766\n",
      "Train Epoch: 146 [32640/225000 (15%)] Loss: 19209.599609\n",
      "Train Epoch: 146 [35136/225000 (16%)] Loss: 19311.589844\n",
      "Train Epoch: 146 [37632/225000 (17%)] Loss: 19209.898438\n",
      "Train Epoch: 146 [40128/225000 (18%)] Loss: 19534.347656\n",
      "Train Epoch: 146 [42624/225000 (19%)] Loss: 19501.058594\n",
      "Train Epoch: 146 [45120/225000 (20%)] Loss: 19233.677734\n",
      "Train Epoch: 146 [47616/225000 (21%)] Loss: 19455.841797\n",
      "Train Epoch: 146 [50112/225000 (22%)] Loss: 19617.617188\n",
      "Train Epoch: 146 [52608/225000 (23%)] Loss: 19780.992188\n",
      "Train Epoch: 146 [55104/225000 (24%)] Loss: 19538.152344\n",
      "Train Epoch: 146 [57600/225000 (26%)] Loss: 18751.347656\n",
      "Train Epoch: 146 [60096/225000 (27%)] Loss: 19271.541016\n",
      "Train Epoch: 146 [62592/225000 (28%)] Loss: 19126.144531\n",
      "Train Epoch: 146 [65088/225000 (29%)] Loss: 19397.230469\n",
      "Train Epoch: 146 [67584/225000 (30%)] Loss: 18968.558594\n",
      "Train Epoch: 146 [70080/225000 (31%)] Loss: 19206.187500\n",
      "Train Epoch: 146 [72576/225000 (32%)] Loss: 18702.505859\n",
      "Train Epoch: 146 [75072/225000 (33%)] Loss: 19231.429688\n",
      "Train Epoch: 146 [77568/225000 (34%)] Loss: 19264.574219\n",
      "Train Epoch: 146 [80064/225000 (36%)] Loss: 18958.996094\n",
      "Train Epoch: 146 [82560/225000 (37%)] Loss: 19485.082031\n",
      "Train Epoch: 146 [85056/225000 (38%)] Loss: 19988.451172\n",
      "Train Epoch: 146 [87552/225000 (39%)] Loss: 19628.800781\n",
      "Train Epoch: 146 [90048/225000 (40%)] Loss: 19433.304688\n",
      "Train Epoch: 146 [92544/225000 (41%)] Loss: 19366.447266\n",
      "Train Epoch: 146 [95040/225000 (42%)] Loss: 19585.101562\n",
      "Train Epoch: 146 [97536/225000 (43%)] Loss: 19179.826172\n",
      "Train Epoch: 146 [100032/225000 (44%)] Loss: 19601.537109\n",
      "Train Epoch: 146 [102528/225000 (46%)] Loss: 19444.152344\n",
      "Train Epoch: 146 [105024/225000 (47%)] Loss: 18952.691406\n",
      "Train Epoch: 146 [107520/225000 (48%)] Loss: 19515.982422\n",
      "Train Epoch: 146 [110016/225000 (49%)] Loss: 19115.855469\n",
      "Train Epoch: 146 [112512/225000 (50%)] Loss: 18689.914062\n",
      "Train Epoch: 146 [115008/225000 (51%)] Loss: 19121.537109\n",
      "Train Epoch: 146 [117504/225000 (52%)] Loss: 19756.183594\n",
      "Train Epoch: 146 [120000/225000 (53%)] Loss: 18939.941406\n",
      "Train Epoch: 146 [122496/225000 (54%)] Loss: 19478.761719\n",
      "Train Epoch: 146 [124992/225000 (56%)] Loss: 19188.511719\n",
      "Train Epoch: 146 [127488/225000 (57%)] Loss: 19157.128906\n",
      "Train Epoch: 146 [129984/225000 (58%)] Loss: 19127.591797\n",
      "Train Epoch: 146 [132480/225000 (59%)] Loss: 19386.849609\n",
      "Train Epoch: 146 [134976/225000 (60%)] Loss: 19787.378906\n",
      "Train Epoch: 146 [137472/225000 (61%)] Loss: 19077.099609\n",
      "Train Epoch: 146 [139968/225000 (62%)] Loss: 19260.554688\n",
      "Train Epoch: 146 [142464/225000 (63%)] Loss: 19423.578125\n",
      "Train Epoch: 146 [144960/225000 (64%)] Loss: 18869.228516\n",
      "Train Epoch: 146 [147456/225000 (66%)] Loss: 19588.867188\n",
      "Train Epoch: 146 [149952/225000 (67%)] Loss: 19286.652344\n",
      "Train Epoch: 146 [152448/225000 (68%)] Loss: 19420.570312\n",
      "Train Epoch: 146 [154944/225000 (69%)] Loss: 18979.527344\n",
      "Train Epoch: 146 [157440/225000 (70%)] Loss: 19893.648438\n",
      "Train Epoch: 146 [159936/225000 (71%)] Loss: 18795.566406\n",
      "Train Epoch: 146 [162432/225000 (72%)] Loss: 19505.511719\n",
      "Train Epoch: 146 [164928/225000 (73%)] Loss: 19426.996094\n",
      "Train Epoch: 146 [167424/225000 (74%)] Loss: 19712.570312\n",
      "Train Epoch: 146 [169920/225000 (76%)] Loss: 19685.740234\n",
      "Train Epoch: 146 [172416/225000 (77%)] Loss: 19387.730469\n",
      "Train Epoch: 146 [174912/225000 (78%)] Loss: 18946.273438\n",
      "Train Epoch: 146 [177408/225000 (79%)] Loss: 19505.650391\n",
      "Train Epoch: 146 [179904/225000 (80%)] Loss: 18986.757812\n",
      "Train Epoch: 146 [182400/225000 (81%)] Loss: 18919.996094\n",
      "Train Epoch: 146 [184896/225000 (82%)] Loss: 19424.849609\n",
      "Train Epoch: 146 [187392/225000 (83%)] Loss: 19214.667969\n",
      "Train Epoch: 146 [189888/225000 (84%)] Loss: 19778.224609\n",
      "Train Epoch: 146 [192384/225000 (86%)] Loss: 19451.707031\n",
      "Train Epoch: 146 [194880/225000 (87%)] Loss: 19689.279297\n",
      "Train Epoch: 146 [197376/225000 (88%)] Loss: 19520.066406\n",
      "Train Epoch: 146 [199872/225000 (89%)] Loss: 19208.457031\n",
      "Train Epoch: 146 [202368/225000 (90%)] Loss: 19748.962891\n",
      "Train Epoch: 146 [204864/225000 (91%)] Loss: 19734.742188\n",
      "Train Epoch: 146 [207360/225000 (92%)] Loss: 18622.355469\n",
      "Train Epoch: 146 [209856/225000 (93%)] Loss: 19104.765625\n",
      "Train Epoch: 146 [212352/225000 (94%)] Loss: 19075.515625\n",
      "Train Epoch: 146 [214848/225000 (95%)] Loss: 19346.853516\n",
      "Train Epoch: 146 [217344/225000 (97%)] Loss: 19488.580078\n",
      "Train Epoch: 146 [219840/225000 (98%)] Loss: 19281.917969\n",
      "Train Epoch: 146 [222336/225000 (99%)] Loss: 19281.763672\n",
      "Train Epoch: 146 [224832/225000 (100%)] Loss: 19095.871094\n",
      "    epoch          : 146\n",
      "    loss           : 19274.61393784663\n",
      "    val_loss       : 19180.236514939606\n",
      "Train Epoch: 147 [192/225000 (0%)] Loss: 19528.583984\n",
      "Train Epoch: 147 [2688/225000 (1%)] Loss: 19444.750000\n",
      "Train Epoch: 147 [5184/225000 (2%)] Loss: 19396.451172\n",
      "Train Epoch: 147 [7680/225000 (3%)] Loss: 19407.609375\n",
      "Train Epoch: 147 [10176/225000 (5%)] Loss: 19336.757812\n",
      "Train Epoch: 147 [12672/225000 (6%)] Loss: 19306.982422\n",
      "Train Epoch: 147 [15168/225000 (7%)] Loss: 19350.332031\n",
      "Train Epoch: 147 [17664/225000 (8%)] Loss: 19572.320312\n",
      "Train Epoch: 147 [20160/225000 (9%)] Loss: 19263.855469\n",
      "Train Epoch: 147 [22656/225000 (10%)] Loss: 19109.068359\n",
      "Train Epoch: 147 [25152/225000 (11%)] Loss: 19449.683594\n",
      "Train Epoch: 147 [27648/225000 (12%)] Loss: 18865.128906\n",
      "Train Epoch: 147 [30144/225000 (13%)] Loss: 19367.099609\n",
      "Train Epoch: 147 [32640/225000 (15%)] Loss: 19338.773438\n",
      "Train Epoch: 147 [35136/225000 (16%)] Loss: 19214.474609\n",
      "Train Epoch: 147 [37632/225000 (17%)] Loss: 19217.470703\n",
      "Train Epoch: 147 [40128/225000 (18%)] Loss: 19519.445312\n",
      "Train Epoch: 147 [42624/225000 (19%)] Loss: 19101.503906\n",
      "Train Epoch: 147 [45120/225000 (20%)] Loss: 19256.410156\n",
      "Train Epoch: 147 [47616/225000 (21%)] Loss: 19403.958984\n",
      "Train Epoch: 147 [50112/225000 (22%)] Loss: 19301.843750\n",
      "Train Epoch: 147 [52608/225000 (23%)] Loss: 19170.082031\n",
      "Train Epoch: 147 [55104/225000 (24%)] Loss: 18714.757812\n",
      "Train Epoch: 147 [57600/225000 (26%)] Loss: 19016.871094\n",
      "Train Epoch: 147 [60096/225000 (27%)] Loss: 19435.033203\n",
      "Train Epoch: 147 [62592/225000 (28%)] Loss: 19667.154297\n",
      "Train Epoch: 147 [65088/225000 (29%)] Loss: 19323.867188\n",
      "Train Epoch: 147 [67584/225000 (30%)] Loss: 19498.576172\n",
      "Train Epoch: 147 [70080/225000 (31%)] Loss: 18869.007812\n",
      "Train Epoch: 147 [72576/225000 (32%)] Loss: 19256.273438\n",
      "Train Epoch: 147 [75072/225000 (33%)] Loss: 18791.574219\n",
      "Train Epoch: 147 [77568/225000 (34%)] Loss: 19192.980469\n",
      "Train Epoch: 147 [80064/225000 (36%)] Loss: 19209.623047\n",
      "Train Epoch: 147 [82560/225000 (37%)] Loss: 19198.875000\n",
      "Train Epoch: 147 [85056/225000 (38%)] Loss: 19559.324219\n",
      "Train Epoch: 147 [87552/225000 (39%)] Loss: 19230.855469\n",
      "Train Epoch: 147 [90048/225000 (40%)] Loss: 19082.746094\n",
      "Train Epoch: 147 [92544/225000 (41%)] Loss: 18992.914062\n",
      "Train Epoch: 147 [95040/225000 (42%)] Loss: 19720.222656\n",
      "Train Epoch: 147 [97536/225000 (43%)] Loss: 19372.292969\n",
      "Train Epoch: 147 [100032/225000 (44%)] Loss: 19702.000000\n",
      "Train Epoch: 147 [102528/225000 (46%)] Loss: 18744.996094\n",
      "Train Epoch: 147 [105024/225000 (47%)] Loss: 19373.476562\n",
      "Train Epoch: 147 [107520/225000 (48%)] Loss: 19264.001953\n",
      "Train Epoch: 147 [110016/225000 (49%)] Loss: 19000.390625\n",
      "Train Epoch: 147 [112512/225000 (50%)] Loss: 19572.177734\n",
      "Train Epoch: 147 [115008/225000 (51%)] Loss: 19071.166016\n",
      "Train Epoch: 147 [117504/225000 (52%)] Loss: 19525.125000\n",
      "Train Epoch: 147 [120000/225000 (53%)] Loss: 19515.070312\n",
      "Train Epoch: 147 [122496/225000 (54%)] Loss: 19467.539062\n",
      "Train Epoch: 147 [124992/225000 (56%)] Loss: 18683.750000\n",
      "Train Epoch: 147 [127488/225000 (57%)] Loss: 19721.046875\n",
      "Train Epoch: 147 [129984/225000 (58%)] Loss: 18937.406250\n",
      "Train Epoch: 147 [132480/225000 (59%)] Loss: 19146.933594\n",
      "Train Epoch: 147 [134976/225000 (60%)] Loss: 19219.976562\n",
      "Train Epoch: 147 [137472/225000 (61%)] Loss: 18887.621094\n",
      "Train Epoch: 147 [139968/225000 (62%)] Loss: 18910.781250\n",
      "Train Epoch: 147 [142464/225000 (63%)] Loss: 19638.236328\n",
      "Train Epoch: 147 [144960/225000 (64%)] Loss: 18705.312500\n",
      "Train Epoch: 147 [147456/225000 (66%)] Loss: 19340.628906\n",
      "Train Epoch: 147 [149952/225000 (67%)] Loss: 19274.076172\n",
      "Train Epoch: 147 [152448/225000 (68%)] Loss: 19346.349609\n",
      "Train Epoch: 147 [154944/225000 (69%)] Loss: 19228.273438\n",
      "Train Epoch: 147 [157440/225000 (70%)] Loss: 19005.750000\n",
      "Train Epoch: 147 [159936/225000 (71%)] Loss: 19140.992188\n",
      "Train Epoch: 147 [162432/225000 (72%)] Loss: 19170.480469\n",
      "Train Epoch: 147 [164928/225000 (73%)] Loss: 19416.683594\n",
      "Train Epoch: 147 [167424/225000 (74%)] Loss: 19201.355469\n",
      "Train Epoch: 147 [169920/225000 (76%)] Loss: 18952.814453\n",
      "Train Epoch: 147 [172416/225000 (77%)] Loss: 19063.994141\n",
      "Train Epoch: 147 [174912/225000 (78%)] Loss: 19401.691406\n",
      "Train Epoch: 147 [177408/225000 (79%)] Loss: 19492.195312\n",
      "Train Epoch: 147 [179904/225000 (80%)] Loss: 19031.792969\n",
      "Train Epoch: 147 [182400/225000 (81%)] Loss: 19293.921875\n",
      "Train Epoch: 147 [184896/225000 (82%)] Loss: 19354.125000\n",
      "Train Epoch: 147 [187392/225000 (83%)] Loss: 19051.171875\n",
      "Train Epoch: 147 [189888/225000 (84%)] Loss: 19187.917969\n",
      "Train Epoch: 147 [192384/225000 (86%)] Loss: 19302.630859\n",
      "Train Epoch: 147 [194880/225000 (87%)] Loss: 19022.703125\n",
      "Train Epoch: 147 [197376/225000 (88%)] Loss: 18732.800781\n",
      "Train Epoch: 147 [199872/225000 (89%)] Loss: 19289.498047\n",
      "Train Epoch: 147 [202368/225000 (90%)] Loss: 19551.224609\n",
      "Train Epoch: 147 [204864/225000 (91%)] Loss: 19634.164062\n",
      "Train Epoch: 147 [207360/225000 (92%)] Loss: 19612.406250\n",
      "Train Epoch: 147 [209856/225000 (93%)] Loss: 18983.205078\n",
      "Train Epoch: 147 [212352/225000 (94%)] Loss: 19118.632812\n",
      "Train Epoch: 147 [214848/225000 (95%)] Loss: 19538.437500\n",
      "Train Epoch: 147 [217344/225000 (97%)] Loss: 19464.156250\n",
      "Train Epoch: 147 [219840/225000 (98%)] Loss: 19259.759766\n",
      "Train Epoch: 147 [222336/225000 (99%)] Loss: 19366.662109\n",
      "Train Epoch: 147 [224832/225000 (100%)] Loss: 18478.255859\n",
      "    epoch          : 147\n",
      "    loss           : 19270.61445612468\n",
      "    val_loss       : 19185.467670111255\n",
      "Train Epoch: 148 [192/225000 (0%)] Loss: 18968.929688\n",
      "Train Epoch: 148 [2688/225000 (1%)] Loss: 18981.113281\n",
      "Train Epoch: 148 [5184/225000 (2%)] Loss: 19095.341797\n",
      "Train Epoch: 148 [7680/225000 (3%)] Loss: 19160.550781\n",
      "Train Epoch: 148 [10176/225000 (5%)] Loss: 19283.816406\n",
      "Train Epoch: 148 [12672/225000 (6%)] Loss: 19249.007812\n",
      "Train Epoch: 148 [15168/225000 (7%)] Loss: 19274.453125\n",
      "Train Epoch: 148 [17664/225000 (8%)] Loss: 19086.265625\n",
      "Train Epoch: 148 [20160/225000 (9%)] Loss: 19278.730469\n",
      "Train Epoch: 148 [22656/225000 (10%)] Loss: 19643.699219\n",
      "Train Epoch: 148 [25152/225000 (11%)] Loss: 18813.982422\n",
      "Train Epoch: 148 [27648/225000 (12%)] Loss: 19332.781250\n",
      "Train Epoch: 148 [30144/225000 (13%)] Loss: 19545.515625\n",
      "Train Epoch: 148 [32640/225000 (15%)] Loss: 19247.027344\n",
      "Train Epoch: 148 [35136/225000 (16%)] Loss: 18997.843750\n",
      "Train Epoch: 148 [37632/225000 (17%)] Loss: 19315.888672\n",
      "Train Epoch: 148 [40128/225000 (18%)] Loss: 18974.371094\n",
      "Train Epoch: 148 [42624/225000 (19%)] Loss: 19186.472656\n",
      "Train Epoch: 148 [45120/225000 (20%)] Loss: 18978.671875\n",
      "Train Epoch: 148 [47616/225000 (21%)] Loss: 18507.222656\n",
      "Train Epoch: 148 [50112/225000 (22%)] Loss: 19517.269531\n",
      "Train Epoch: 148 [52608/225000 (23%)] Loss: 19543.101562\n",
      "Train Epoch: 148 [55104/225000 (24%)] Loss: 19449.414062\n",
      "Train Epoch: 148 [57600/225000 (26%)] Loss: 19366.328125\n",
      "Train Epoch: 148 [60096/225000 (27%)] Loss: 19156.300781\n",
      "Train Epoch: 148 [62592/225000 (28%)] Loss: 18941.466797\n",
      "Train Epoch: 148 [65088/225000 (29%)] Loss: 19169.660156\n",
      "Train Epoch: 148 [67584/225000 (30%)] Loss: 19362.882812\n",
      "Train Epoch: 148 [70080/225000 (31%)] Loss: 19518.349609\n",
      "Train Epoch: 148 [72576/225000 (32%)] Loss: 19436.082031\n",
      "Train Epoch: 148 [75072/225000 (33%)] Loss: 19320.148438\n",
      "Train Epoch: 148 [77568/225000 (34%)] Loss: 19362.224609\n",
      "Train Epoch: 148 [80064/225000 (36%)] Loss: 19072.302734\n",
      "Train Epoch: 148 [82560/225000 (37%)] Loss: 19661.546875\n",
      "Train Epoch: 148 [85056/225000 (38%)] Loss: 19031.494141\n",
      "Train Epoch: 148 [87552/225000 (39%)] Loss: 19285.822266\n",
      "Train Epoch: 148 [90048/225000 (40%)] Loss: 19715.373047\n",
      "Train Epoch: 148 [92544/225000 (41%)] Loss: 19140.644531\n",
      "Train Epoch: 148 [95040/225000 (42%)] Loss: 19079.582031\n",
      "Train Epoch: 148 [97536/225000 (43%)] Loss: 19595.841797\n",
      "Train Epoch: 148 [100032/225000 (44%)] Loss: 19451.769531\n",
      "Train Epoch: 148 [102528/225000 (46%)] Loss: 19207.423828\n",
      "Train Epoch: 148 [105024/225000 (47%)] Loss: 19850.457031\n",
      "Train Epoch: 148 [107520/225000 (48%)] Loss: 19359.269531\n",
      "Train Epoch: 148 [110016/225000 (49%)] Loss: 19202.501953\n",
      "Train Epoch: 148 [112512/225000 (50%)] Loss: 18997.269531\n",
      "Train Epoch: 148 [115008/225000 (51%)] Loss: 19151.734375\n",
      "Train Epoch: 148 [117504/225000 (52%)] Loss: 18797.082031\n",
      "Train Epoch: 148 [120000/225000 (53%)] Loss: 19356.550781\n",
      "Train Epoch: 148 [122496/225000 (54%)] Loss: 19108.654297\n",
      "Train Epoch: 148 [124992/225000 (56%)] Loss: 19210.019531\n",
      "Train Epoch: 148 [127488/225000 (57%)] Loss: 19075.248047\n",
      "Train Epoch: 148 [129984/225000 (58%)] Loss: 19422.126953\n",
      "Train Epoch: 148 [132480/225000 (59%)] Loss: 19540.625000\n",
      "Train Epoch: 148 [134976/225000 (60%)] Loss: 19389.144531\n",
      "Train Epoch: 148 [137472/225000 (61%)] Loss: 18977.531250\n",
      "Train Epoch: 148 [139968/225000 (62%)] Loss: 19795.460938\n",
      "Train Epoch: 148 [142464/225000 (63%)] Loss: 19242.050781\n",
      "Train Epoch: 148 [144960/225000 (64%)] Loss: 19079.142578\n",
      "Train Epoch: 148 [147456/225000 (66%)] Loss: 19665.425781\n",
      "Train Epoch: 148 [149952/225000 (67%)] Loss: 18897.015625\n",
      "Train Epoch: 148 [152448/225000 (68%)] Loss: 19146.275391\n",
      "Train Epoch: 148 [154944/225000 (69%)] Loss: 19240.078125\n",
      "Train Epoch: 148 [157440/225000 (70%)] Loss: 19720.722656\n",
      "Train Epoch: 148 [159936/225000 (71%)] Loss: 19283.677734\n",
      "Train Epoch: 148 [162432/225000 (72%)] Loss: 19024.015625\n",
      "Train Epoch: 148 [164928/225000 (73%)] Loss: 19556.835938\n",
      "Train Epoch: 148 [167424/225000 (74%)] Loss: 19569.488281\n",
      "Train Epoch: 148 [169920/225000 (76%)] Loss: 19461.201172\n",
      "Train Epoch: 148 [172416/225000 (77%)] Loss: 19460.716797\n",
      "Train Epoch: 148 [174912/225000 (78%)] Loss: 19271.187500\n",
      "Train Epoch: 148 [177408/225000 (79%)] Loss: 19413.625000\n",
      "Train Epoch: 148 [179904/225000 (80%)] Loss: 19409.539062\n",
      "Train Epoch: 148 [182400/225000 (81%)] Loss: 19622.140625\n",
      "Train Epoch: 148 [184896/225000 (82%)] Loss: 19257.705078\n",
      "Train Epoch: 148 [187392/225000 (83%)] Loss: 19462.332031\n",
      "Train Epoch: 148 [189888/225000 (84%)] Loss: 19008.199219\n",
      "Train Epoch: 148 [192384/225000 (86%)] Loss: 19442.644531\n",
      "Train Epoch: 148 [194880/225000 (87%)] Loss: 19147.550781\n",
      "Train Epoch: 148 [197376/225000 (88%)] Loss: 18686.796875\n",
      "Train Epoch: 148 [199872/225000 (89%)] Loss: 19956.199219\n",
      "Train Epoch: 148 [202368/225000 (90%)] Loss: 19069.152344\n",
      "Train Epoch: 148 [204864/225000 (91%)] Loss: 19179.496094\n",
      "Train Epoch: 148 [207360/225000 (92%)] Loss: 19091.753906\n",
      "Train Epoch: 148 [209856/225000 (93%)] Loss: 19179.351562\n",
      "Train Epoch: 148 [212352/225000 (94%)] Loss: 19153.761719\n",
      "Train Epoch: 148 [214848/225000 (95%)] Loss: 18912.605469\n",
      "Train Epoch: 148 [217344/225000 (97%)] Loss: 19142.132812\n",
      "Train Epoch: 148 [219840/225000 (98%)] Loss: 19649.113281\n",
      "Train Epoch: 148 [222336/225000 (99%)] Loss: 19213.511719\n",
      "Train Epoch: 148 [224832/225000 (100%)] Loss: 19471.042969\n",
      "    epoch          : 148\n",
      "    loss           : 19262.19175454618\n",
      "    val_loss       : 19177.163182517044\n",
      "Train Epoch: 149 [192/225000 (0%)] Loss: 19131.054688\n",
      "Train Epoch: 149 [2688/225000 (1%)] Loss: 19758.951172\n",
      "Train Epoch: 149 [5184/225000 (2%)] Loss: 19162.595703\n",
      "Train Epoch: 149 [7680/225000 (3%)] Loss: 18996.117188\n",
      "Train Epoch: 149 [10176/225000 (5%)] Loss: 18831.375000\n",
      "Train Epoch: 149 [12672/225000 (6%)] Loss: 19763.466797\n",
      "Train Epoch: 149 [15168/225000 (7%)] Loss: 19214.134766\n",
      "Train Epoch: 149 [17664/225000 (8%)] Loss: 18716.691406\n",
      "Train Epoch: 149 [20160/225000 (9%)] Loss: 19215.650391\n",
      "Train Epoch: 149 [22656/225000 (10%)] Loss: 19204.996094\n",
      "Train Epoch: 149 [25152/225000 (11%)] Loss: 19680.687500\n",
      "Train Epoch: 149 [27648/225000 (12%)] Loss: 19187.804688\n",
      "Train Epoch: 149 [30144/225000 (13%)] Loss: 19569.441406\n",
      "Train Epoch: 149 [32640/225000 (15%)] Loss: 19231.695312\n",
      "Train Epoch: 149 [35136/225000 (16%)] Loss: 19397.724609\n",
      "Train Epoch: 149 [37632/225000 (17%)] Loss: 19123.199219\n",
      "Train Epoch: 149 [40128/225000 (18%)] Loss: 19787.492188\n",
      "Train Epoch: 149 [42624/225000 (19%)] Loss: 19496.617188\n",
      "Train Epoch: 149 [45120/225000 (20%)] Loss: 19811.300781\n",
      "Train Epoch: 149 [47616/225000 (21%)] Loss: 19550.767578\n",
      "Train Epoch: 149 [50112/225000 (22%)] Loss: 19759.902344\n",
      "Train Epoch: 149 [52608/225000 (23%)] Loss: 19878.005859\n",
      "Train Epoch: 149 [55104/225000 (24%)] Loss: 19220.833984\n",
      "Train Epoch: 149 [57600/225000 (26%)] Loss: 19138.279297\n",
      "Train Epoch: 149 [60096/225000 (27%)] Loss: 19798.160156\n",
      "Train Epoch: 149 [62592/225000 (28%)] Loss: 19344.146484\n",
      "Train Epoch: 149 [65088/225000 (29%)] Loss: 19206.878906\n",
      "Train Epoch: 149 [67584/225000 (30%)] Loss: 19068.388672\n",
      "Train Epoch: 149 [70080/225000 (31%)] Loss: 19446.517578\n",
      "Train Epoch: 149 [72576/225000 (32%)] Loss: 18632.359375\n",
      "Train Epoch: 149 [75072/225000 (33%)] Loss: 19219.787109\n",
      "Train Epoch: 149 [77568/225000 (34%)] Loss: 19010.144531\n",
      "Train Epoch: 149 [80064/225000 (36%)] Loss: 19208.851562\n",
      "Train Epoch: 149 [82560/225000 (37%)] Loss: 19177.515625\n",
      "Train Epoch: 149 [85056/225000 (38%)] Loss: 18841.824219\n",
      "Train Epoch: 149 [87552/225000 (39%)] Loss: 19240.492188\n",
      "Train Epoch: 149 [90048/225000 (40%)] Loss: 19523.048828\n",
      "Train Epoch: 149 [92544/225000 (41%)] Loss: 19276.691406\n",
      "Train Epoch: 149 [95040/225000 (42%)] Loss: 19273.128906\n",
      "Train Epoch: 149 [97536/225000 (43%)] Loss: 19142.748047\n",
      "Train Epoch: 149 [100032/225000 (44%)] Loss: 19176.257812\n",
      "Train Epoch: 149 [102528/225000 (46%)] Loss: 19484.007812\n",
      "Train Epoch: 149 [105024/225000 (47%)] Loss: 18935.978516\n",
      "Train Epoch: 149 [107520/225000 (48%)] Loss: 19342.656250\n",
      "Train Epoch: 149 [110016/225000 (49%)] Loss: 19241.437500\n",
      "Train Epoch: 149 [112512/225000 (50%)] Loss: 19045.906250\n",
      "Train Epoch: 149 [115008/225000 (51%)] Loss: 19532.798828\n",
      "Train Epoch: 149 [117504/225000 (52%)] Loss: 18992.535156\n",
      "Train Epoch: 149 [120000/225000 (53%)] Loss: 19030.462891\n",
      "Train Epoch: 149 [122496/225000 (54%)] Loss: 19615.671875\n",
      "Train Epoch: 149 [124992/225000 (56%)] Loss: 19478.617188\n",
      "Train Epoch: 149 [127488/225000 (57%)] Loss: 19351.089844\n",
      "Train Epoch: 149 [129984/225000 (58%)] Loss: 19477.382812\n",
      "Train Epoch: 149 [132480/225000 (59%)] Loss: 19015.939453\n",
      "Train Epoch: 149 [134976/225000 (60%)] Loss: 19208.453125\n",
      "Train Epoch: 149 [137472/225000 (61%)] Loss: 19467.390625\n",
      "Train Epoch: 149 [139968/225000 (62%)] Loss: 19332.472656\n",
      "Train Epoch: 149 [142464/225000 (63%)] Loss: 19251.353516\n",
      "Train Epoch: 149 [144960/225000 (64%)] Loss: 19689.279297\n",
      "Train Epoch: 149 [147456/225000 (66%)] Loss: 19352.140625\n",
      "Train Epoch: 149 [149952/225000 (67%)] Loss: 18708.470703\n",
      "Train Epoch: 149 [152448/225000 (68%)] Loss: 19265.632812\n",
      "Train Epoch: 149 [154944/225000 (69%)] Loss: 19573.699219\n",
      "Train Epoch: 149 [157440/225000 (70%)] Loss: 19409.957031\n",
      "Train Epoch: 149 [159936/225000 (71%)] Loss: 19737.121094\n",
      "Train Epoch: 149 [162432/225000 (72%)] Loss: 19356.628906\n",
      "Train Epoch: 149 [164928/225000 (73%)] Loss: 19160.468750\n",
      "Train Epoch: 149 [167424/225000 (74%)] Loss: 18863.912109\n",
      "Train Epoch: 149 [169920/225000 (76%)] Loss: 18744.300781\n",
      "Train Epoch: 149 [172416/225000 (77%)] Loss: 19079.769531\n",
      "Train Epoch: 149 [174912/225000 (78%)] Loss: 19492.871094\n",
      "Train Epoch: 149 [177408/225000 (79%)] Loss: 19441.378906\n",
      "Train Epoch: 149 [179904/225000 (80%)] Loss: 19296.193359\n",
      "Train Epoch: 149 [182400/225000 (81%)] Loss: 19175.570312\n",
      "Train Epoch: 149 [184896/225000 (82%)] Loss: 19335.541016\n",
      "Train Epoch: 149 [187392/225000 (83%)] Loss: 18847.621094\n",
      "Train Epoch: 149 [189888/225000 (84%)] Loss: 19505.019531\n",
      "Train Epoch: 149 [192384/225000 (86%)] Loss: 18816.958984\n",
      "Train Epoch: 149 [194880/225000 (87%)] Loss: 19267.390625\n",
      "Train Epoch: 149 [197376/225000 (88%)] Loss: 19223.089844\n",
      "Train Epoch: 149 [199872/225000 (89%)] Loss: 19555.310547\n",
      "Train Epoch: 149 [202368/225000 (90%)] Loss: 19186.558594\n",
      "Train Epoch: 149 [204864/225000 (91%)] Loss: 18994.841797\n",
      "Train Epoch: 149 [207360/225000 (92%)] Loss: 19248.179688\n",
      "Train Epoch: 149 [209856/225000 (93%)] Loss: 18873.734375\n",
      "Train Epoch: 149 [212352/225000 (94%)] Loss: 19276.863281\n",
      "Train Epoch: 149 [214848/225000 (95%)] Loss: 19243.392578\n",
      "Train Epoch: 149 [217344/225000 (97%)] Loss: 19673.621094\n",
      "Train Epoch: 149 [219840/225000 (98%)] Loss: 19221.078125\n",
      "Train Epoch: 149 [222336/225000 (99%)] Loss: 19648.294922\n",
      "Train Epoch: 149 [224832/225000 (100%)] Loss: 19107.107422\n",
      "    epoch          : 149\n",
      "    loss           : 19264.628552954353\n",
      "    val_loss       : 19163.287039054714\n",
      "Train Epoch: 150 [192/225000 (0%)] Loss: 19088.464844\n",
      "Train Epoch: 150 [2688/225000 (1%)] Loss: 19223.179688\n",
      "Train Epoch: 150 [5184/225000 (2%)] Loss: 19506.072266\n",
      "Train Epoch: 150 [7680/225000 (3%)] Loss: 19794.550781\n",
      "Train Epoch: 150 [10176/225000 (5%)] Loss: 19120.658203\n",
      "Train Epoch: 150 [12672/225000 (6%)] Loss: 19552.271484\n",
      "Train Epoch: 150 [15168/225000 (7%)] Loss: 19009.677734\n",
      "Train Epoch: 150 [17664/225000 (8%)] Loss: 18931.781250\n",
      "Train Epoch: 150 [20160/225000 (9%)] Loss: 20051.972656\n",
      "Train Epoch: 150 [22656/225000 (10%)] Loss: 19089.814453\n",
      "Train Epoch: 150 [25152/225000 (11%)] Loss: 19064.933594\n",
      "Train Epoch: 150 [27648/225000 (12%)] Loss: 19510.478516\n",
      "Train Epoch: 150 [30144/225000 (13%)] Loss: 19555.503906\n",
      "Train Epoch: 150 [32640/225000 (15%)] Loss: 18988.138672\n",
      "Train Epoch: 150 [35136/225000 (16%)] Loss: 19660.753906\n",
      "Train Epoch: 150 [37632/225000 (17%)] Loss: 19339.558594\n",
      "Train Epoch: 150 [40128/225000 (18%)] Loss: 19070.687500\n",
      "Train Epoch: 150 [42624/225000 (19%)] Loss: 19506.664062\n",
      "Train Epoch: 150 [45120/225000 (20%)] Loss: 19345.476562\n",
      "Train Epoch: 150 [47616/225000 (21%)] Loss: 19016.916016\n",
      "Train Epoch: 150 [50112/225000 (22%)] Loss: 18983.796875\n",
      "Train Epoch: 150 [52608/225000 (23%)] Loss: 18876.884766\n",
      "Train Epoch: 150 [55104/225000 (24%)] Loss: 19368.332031\n",
      "Train Epoch: 150 [57600/225000 (26%)] Loss: 19039.871094\n",
      "Train Epoch: 150 [60096/225000 (27%)] Loss: 19833.906250\n",
      "Train Epoch: 150 [62592/225000 (28%)] Loss: 18915.718750\n",
      "Train Epoch: 150 [65088/225000 (29%)] Loss: 19421.519531\n",
      "Train Epoch: 150 [67584/225000 (30%)] Loss: 18971.703125\n",
      "Train Epoch: 150 [70080/225000 (31%)] Loss: 19378.716797\n",
      "Train Epoch: 150 [72576/225000 (32%)] Loss: 19123.214844\n",
      "Train Epoch: 150 [75072/225000 (33%)] Loss: 19360.093750\n",
      "Train Epoch: 150 [77568/225000 (34%)] Loss: 18859.730469\n",
      "Train Epoch: 150 [80064/225000 (36%)] Loss: 19218.066406\n",
      "Train Epoch: 150 [82560/225000 (37%)] Loss: 18856.992188\n",
      "Train Epoch: 150 [85056/225000 (38%)] Loss: 19096.763672\n",
      "Train Epoch: 150 [87552/225000 (39%)] Loss: 19075.751953\n",
      "Train Epoch: 150 [90048/225000 (40%)] Loss: 19013.812500\n",
      "Train Epoch: 150 [92544/225000 (41%)] Loss: 19149.701172\n",
      "Train Epoch: 150 [95040/225000 (42%)] Loss: 19212.335938\n",
      "Train Epoch: 150 [97536/225000 (43%)] Loss: 19154.792969\n",
      "Train Epoch: 150 [100032/225000 (44%)] Loss: 19345.882812\n",
      "Train Epoch: 150 [102528/225000 (46%)] Loss: 19373.195312\n",
      "Train Epoch: 150 [105024/225000 (47%)] Loss: 19669.384766\n",
      "Train Epoch: 150 [107520/225000 (48%)] Loss: 19171.789062\n",
      "Train Epoch: 150 [110016/225000 (49%)] Loss: 18475.222656\n",
      "Train Epoch: 150 [112512/225000 (50%)] Loss: 19219.933594\n",
      "Train Epoch: 150 [115008/225000 (51%)] Loss: 19206.726562\n",
      "Train Epoch: 150 [117504/225000 (52%)] Loss: 18950.527344\n",
      "Train Epoch: 150 [120000/225000 (53%)] Loss: 19015.828125\n",
      "Train Epoch: 150 [122496/225000 (54%)] Loss: 18985.164062\n",
      "Train Epoch: 150 [124992/225000 (56%)] Loss: 19129.132812\n",
      "Train Epoch: 150 [127488/225000 (57%)] Loss: 19169.376953\n",
      "Train Epoch: 150 [129984/225000 (58%)] Loss: 19187.185547\n",
      "Train Epoch: 150 [132480/225000 (59%)] Loss: 19205.242188\n",
      "Train Epoch: 150 [134976/225000 (60%)] Loss: 19132.470703\n",
      "Train Epoch: 150 [137472/225000 (61%)] Loss: 19449.710938\n",
      "Train Epoch: 150 [139968/225000 (62%)] Loss: 19645.236328\n",
      "Train Epoch: 150 [142464/225000 (63%)] Loss: 19393.992188\n",
      "Train Epoch: 150 [144960/225000 (64%)] Loss: 19064.527344\n",
      "Train Epoch: 150 [147456/225000 (66%)] Loss: 19330.472656\n",
      "Train Epoch: 150 [149952/225000 (67%)] Loss: 19315.648438\n",
      "Train Epoch: 150 [152448/225000 (68%)] Loss: 18718.898438\n",
      "Train Epoch: 150 [154944/225000 (69%)] Loss: 19690.414062\n",
      "Train Epoch: 150 [157440/225000 (70%)] Loss: 18694.847656\n",
      "Train Epoch: 150 [159936/225000 (71%)] Loss: 18883.894531\n",
      "Train Epoch: 150 [162432/225000 (72%)] Loss: 19235.929688\n",
      "Train Epoch: 150 [164928/225000 (73%)] Loss: 19013.140625\n",
      "Train Epoch: 150 [167424/225000 (74%)] Loss: 19158.835938\n",
      "Train Epoch: 150 [169920/225000 (76%)] Loss: 19324.033203\n",
      "Train Epoch: 150 [172416/225000 (77%)] Loss: 19304.605469\n",
      "Train Epoch: 150 [174912/225000 (78%)] Loss: 19439.601562\n",
      "Train Epoch: 150 [177408/225000 (79%)] Loss: 19022.980469\n",
      "Train Epoch: 150 [179904/225000 (80%)] Loss: 19934.078125\n",
      "Train Epoch: 150 [182400/225000 (81%)] Loss: 19106.308594\n",
      "Train Epoch: 150 [184896/225000 (82%)] Loss: 19220.265625\n",
      "Train Epoch: 150 [187392/225000 (83%)] Loss: 19642.390625\n",
      "Train Epoch: 150 [189888/225000 (84%)] Loss: 19443.076172\n",
      "Train Epoch: 150 [192384/225000 (86%)] Loss: 18858.367188\n",
      "Train Epoch: 150 [194880/225000 (87%)] Loss: 18987.310547\n",
      "Train Epoch: 150 [197376/225000 (88%)] Loss: 18847.496094\n",
      "Train Epoch: 150 [199872/225000 (89%)] Loss: 19287.796875\n",
      "Train Epoch: 150 [202368/225000 (90%)] Loss: 19443.378906\n",
      "Train Epoch: 150 [204864/225000 (91%)] Loss: 19262.117188\n",
      "Train Epoch: 150 [207360/225000 (92%)] Loss: 18850.380859\n",
      "Train Epoch: 150 [209856/225000 (93%)] Loss: 19532.632812\n",
      "Train Epoch: 150 [212352/225000 (94%)] Loss: 19102.613281\n",
      "Train Epoch: 150 [214848/225000 (95%)] Loss: 18901.437500\n",
      "Train Epoch: 150 [217344/225000 (97%)] Loss: 18836.664062\n",
      "Train Epoch: 150 [219840/225000 (98%)] Loss: 19583.005859\n",
      "Train Epoch: 150 [222336/225000 (99%)] Loss: 18735.769531\n",
      "Train Epoch: 150 [224832/225000 (100%)] Loss: 18911.431641\n",
      "    epoch          : 150\n",
      "    loss           : 19263.57088910516\n",
      "    val_loss       : 19160.009107536942\n",
      "Saving checkpoint: saved/models/Molecular_VaeCategory/0803_194629/checkpoint-epoch150.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 151 [192/225000 (0%)] Loss: 19433.130859\n",
      "Train Epoch: 151 [2688/225000 (1%)] Loss: 19167.376953\n",
      "Train Epoch: 151 [5184/225000 (2%)] Loss: 18840.138672\n",
      "Train Epoch: 151 [7680/225000 (3%)] Loss: 19219.687500\n",
      "Train Epoch: 151 [10176/225000 (5%)] Loss: 19399.523438\n",
      "Train Epoch: 151 [12672/225000 (6%)] Loss: 18842.949219\n",
      "Train Epoch: 151 [15168/225000 (7%)] Loss: 19373.906250\n",
      "Train Epoch: 151 [17664/225000 (8%)] Loss: 18919.328125\n",
      "Train Epoch: 151 [20160/225000 (9%)] Loss: 19409.851562\n",
      "Train Epoch: 151 [22656/225000 (10%)] Loss: 19265.111328\n",
      "Train Epoch: 151 [25152/225000 (11%)] Loss: 19193.376953\n",
      "Train Epoch: 151 [27648/225000 (12%)] Loss: 19506.152344\n",
      "Train Epoch: 151 [30144/225000 (13%)] Loss: 19599.734375\n",
      "Train Epoch: 151 [32640/225000 (15%)] Loss: 19116.927734\n",
      "Train Epoch: 151 [35136/225000 (16%)] Loss: 19383.478516\n",
      "Train Epoch: 151 [37632/225000 (17%)] Loss: 19139.621094\n",
      "Train Epoch: 151 [40128/225000 (18%)] Loss: 19345.291016\n",
      "Train Epoch: 151 [42624/225000 (19%)] Loss: 19290.630859\n",
      "Train Epoch: 151 [45120/225000 (20%)] Loss: 19090.326172\n",
      "Train Epoch: 151 [47616/225000 (21%)] Loss: 19255.832031\n",
      "Train Epoch: 151 [50112/225000 (22%)] Loss: 19380.609375\n",
      "Train Epoch: 151 [52608/225000 (23%)] Loss: 19107.554688\n",
      "Train Epoch: 151 [55104/225000 (24%)] Loss: 18746.328125\n",
      "Train Epoch: 151 [57600/225000 (26%)] Loss: 19107.027344\n",
      "Train Epoch: 151 [60096/225000 (27%)] Loss: 19343.484375\n",
      "Train Epoch: 151 [62592/225000 (28%)] Loss: 19218.974609\n",
      "Train Epoch: 151 [65088/225000 (29%)] Loss: 19545.734375\n",
      "Train Epoch: 151 [67584/225000 (30%)] Loss: 19475.191406\n",
      "Train Epoch: 151 [70080/225000 (31%)] Loss: 19199.841797\n",
      "Train Epoch: 151 [72576/225000 (32%)] Loss: 19620.585938\n",
      "Train Epoch: 151 [75072/225000 (33%)] Loss: 19679.056641\n",
      "Train Epoch: 151 [77568/225000 (34%)] Loss: 18966.699219\n",
      "Train Epoch: 151 [80064/225000 (36%)] Loss: 19053.285156\n",
      "Train Epoch: 151 [82560/225000 (37%)] Loss: 19582.054688\n",
      "Train Epoch: 151 [85056/225000 (38%)] Loss: 19363.541016\n",
      "Train Epoch: 151 [87552/225000 (39%)] Loss: 19328.542969\n",
      "Train Epoch: 151 [90048/225000 (40%)] Loss: 19498.351562\n",
      "Train Epoch: 151 [92544/225000 (41%)] Loss: 19653.453125\n",
      "Train Epoch: 151 [95040/225000 (42%)] Loss: 19005.251953\n",
      "Train Epoch: 151 [97536/225000 (43%)] Loss: 19153.771484\n",
      "Train Epoch: 151 [100032/225000 (44%)] Loss: 19312.914062\n",
      "Train Epoch: 151 [102528/225000 (46%)] Loss: 18827.062500\n",
      "Train Epoch: 151 [105024/225000 (47%)] Loss: 18725.113281\n",
      "Train Epoch: 151 [107520/225000 (48%)] Loss: 19772.507812\n",
      "Train Epoch: 151 [110016/225000 (49%)] Loss: 19826.398438\n",
      "Train Epoch: 151 [112512/225000 (50%)] Loss: 19047.585938\n",
      "Train Epoch: 151 [115008/225000 (51%)] Loss: 19289.416016\n",
      "Train Epoch: 151 [117504/225000 (52%)] Loss: 18950.798828\n",
      "Train Epoch: 151 [120000/225000 (53%)] Loss: 18948.404297\n",
      "Train Epoch: 151 [122496/225000 (54%)] Loss: 19614.867188\n",
      "Train Epoch: 151 [124992/225000 (56%)] Loss: 19327.978516\n",
      "Train Epoch: 151 [127488/225000 (57%)] Loss: 19491.597656\n",
      "Train Epoch: 151 [129984/225000 (58%)] Loss: 19135.345703\n",
      "Train Epoch: 151 [132480/225000 (59%)] Loss: 19470.253906\n",
      "Train Epoch: 151 [134976/225000 (60%)] Loss: 19070.511719\n",
      "Train Epoch: 151 [137472/225000 (61%)] Loss: 19152.691406\n",
      "Train Epoch: 151 [139968/225000 (62%)] Loss: 18874.595703\n",
      "Train Epoch: 151 [142464/225000 (63%)] Loss: 19042.789062\n",
      "Train Epoch: 151 [144960/225000 (64%)] Loss: 19294.656250\n",
      "Train Epoch: 151 [147456/225000 (66%)] Loss: 19590.777344\n",
      "Train Epoch: 151 [149952/225000 (67%)] Loss: 19443.406250\n",
      "Train Epoch: 151 [152448/225000 (68%)] Loss: 19526.074219\n",
      "Train Epoch: 151 [154944/225000 (69%)] Loss: 19629.107422\n",
      "Train Epoch: 151 [157440/225000 (70%)] Loss: 19824.796875\n",
      "Train Epoch: 151 [159936/225000 (71%)] Loss: 19262.230469\n",
      "Train Epoch: 151 [162432/225000 (72%)] Loss: 19360.841797\n",
      "Train Epoch: 151 [164928/225000 (73%)] Loss: 19032.335938\n",
      "Train Epoch: 151 [167424/225000 (74%)] Loss: 19649.894531\n",
      "Train Epoch: 151 [169920/225000 (76%)] Loss: 18669.503906\n",
      "Train Epoch: 151 [172416/225000 (77%)] Loss: 19045.105469\n",
      "Train Epoch: 151 [174912/225000 (78%)] Loss: 18707.714844\n",
      "Train Epoch: 151 [177408/225000 (79%)] Loss: 19036.570312\n",
      "Train Epoch: 151 [179904/225000 (80%)] Loss: 19296.080078\n",
      "Train Epoch: 151 [182400/225000 (81%)] Loss: 19158.308594\n",
      "Train Epoch: 151 [184896/225000 (82%)] Loss: 19266.896484\n",
      "Train Epoch: 151 [187392/225000 (83%)] Loss: 18848.617188\n",
      "Train Epoch: 151 [189888/225000 (84%)] Loss: 19354.910156\n",
      "Train Epoch: 151 [192384/225000 (86%)] Loss: 19111.496094\n",
      "Train Epoch: 151 [194880/225000 (87%)] Loss: 19768.345703\n",
      "Train Epoch: 151 [197376/225000 (88%)] Loss: 19432.949219\n",
      "Train Epoch: 151 [199872/225000 (89%)] Loss: 18971.214844\n",
      "Train Epoch: 151 [202368/225000 (90%)] Loss: 18862.332031\n",
      "Train Epoch: 151 [204864/225000 (91%)] Loss: 19677.894531\n",
      "Train Epoch: 151 [207360/225000 (92%)] Loss: 19393.898438\n",
      "Train Epoch: 151 [209856/225000 (93%)] Loss: 19155.769531\n",
      "Train Epoch: 151 [212352/225000 (94%)] Loss: 19651.175781\n",
      "Train Epoch: 151 [214848/225000 (95%)] Loss: 19791.763672\n",
      "Train Epoch: 151 [217344/225000 (97%)] Loss: 19202.857422\n",
      "Train Epoch: 151 [219840/225000 (98%)] Loss: 19496.535156\n",
      "Train Epoch: 151 [222336/225000 (99%)] Loss: 19249.828125\n",
      "Train Epoch: 151 [224832/225000 (100%)] Loss: 18855.363281\n",
      "    epoch          : 151\n",
      "    loss           : 19260.27533229789\n",
      "    val_loss       : 19162.57050186441\n",
      "Train Epoch: 152 [192/225000 (0%)] Loss: 18652.841797\n",
      "Train Epoch: 152 [2688/225000 (1%)] Loss: 19264.791016\n",
      "Train Epoch: 152 [5184/225000 (2%)] Loss: 19579.976562\n",
      "Train Epoch: 152 [7680/225000 (3%)] Loss: 19156.003906\n",
      "Train Epoch: 152 [10176/225000 (5%)] Loss: 19362.671875\n",
      "Train Epoch: 152 [12672/225000 (6%)] Loss: 18964.136719\n",
      "Train Epoch: 152 [15168/225000 (7%)] Loss: 19122.171875\n",
      "Train Epoch: 152 [17664/225000 (8%)] Loss: 18800.011719\n",
      "Train Epoch: 152 [20160/225000 (9%)] Loss: 19381.398438\n",
      "Train Epoch: 152 [22656/225000 (10%)] Loss: 19420.074219\n",
      "Train Epoch: 152 [25152/225000 (11%)] Loss: 19524.640625\n",
      "Train Epoch: 152 [27648/225000 (12%)] Loss: 19415.337891\n",
      "Train Epoch: 152 [30144/225000 (13%)] Loss: 19503.779297\n",
      "Train Epoch: 152 [32640/225000 (15%)] Loss: 19101.400391\n",
      "Train Epoch: 152 [35136/225000 (16%)] Loss: 19405.996094\n",
      "Train Epoch: 152 [37632/225000 (17%)] Loss: 19429.152344\n",
      "Train Epoch: 152 [40128/225000 (18%)] Loss: 18900.625000\n",
      "Train Epoch: 152 [42624/225000 (19%)] Loss: 19378.234375\n",
      "Train Epoch: 152 [45120/225000 (20%)] Loss: 19163.625000\n",
      "Train Epoch: 152 [47616/225000 (21%)] Loss: 19569.835938\n",
      "Train Epoch: 152 [50112/225000 (22%)] Loss: 19035.085938\n",
      "Train Epoch: 152 [52608/225000 (23%)] Loss: 19253.480469\n",
      "Train Epoch: 152 [55104/225000 (24%)] Loss: 19454.759766\n",
      "Train Epoch: 152 [57600/225000 (26%)] Loss: 19238.500000\n",
      "Train Epoch: 152 [60096/225000 (27%)] Loss: 19484.070312\n",
      "Train Epoch: 152 [62592/225000 (28%)] Loss: 19331.761719\n",
      "Train Epoch: 152 [65088/225000 (29%)] Loss: 19239.855469\n",
      "Train Epoch: 152 [67584/225000 (30%)] Loss: 19151.933594\n",
      "Train Epoch: 152 [70080/225000 (31%)] Loss: 19099.992188\n",
      "Train Epoch: 152 [72576/225000 (32%)] Loss: 19084.138672\n",
      "Train Epoch: 152 [75072/225000 (33%)] Loss: 19468.851562\n",
      "Train Epoch: 152 [77568/225000 (34%)] Loss: 19354.710938\n",
      "Train Epoch: 152 [80064/225000 (36%)] Loss: 19427.218750\n",
      "Train Epoch: 152 [82560/225000 (37%)] Loss: 19694.587891\n",
      "Train Epoch: 152 [85056/225000 (38%)] Loss: 18985.699219\n",
      "Train Epoch: 152 [87552/225000 (39%)] Loss: 19378.890625\n",
      "Train Epoch: 152 [90048/225000 (40%)] Loss: 19554.441406\n",
      "Train Epoch: 152 [92544/225000 (41%)] Loss: 19218.296875\n",
      "Train Epoch: 152 [95040/225000 (42%)] Loss: 18821.925781\n",
      "Train Epoch: 152 [97536/225000 (43%)] Loss: 19062.949219\n",
      "Train Epoch: 152 [100032/225000 (44%)] Loss: 18697.210938\n",
      "Train Epoch: 152 [102528/225000 (46%)] Loss: 19198.964844\n",
      "Train Epoch: 152 [105024/225000 (47%)] Loss: 19361.031250\n",
      "Train Epoch: 152 [107520/225000 (48%)] Loss: 19112.343750\n",
      "Train Epoch: 152 [110016/225000 (49%)] Loss: 19207.925781\n",
      "Train Epoch: 152 [112512/225000 (50%)] Loss: 19468.101562\n",
      "Train Epoch: 152 [115008/225000 (51%)] Loss: 19255.621094\n",
      "Train Epoch: 152 [117504/225000 (52%)] Loss: 19464.740234\n",
      "Train Epoch: 152 [120000/225000 (53%)] Loss: 18954.222656\n",
      "Train Epoch: 152 [122496/225000 (54%)] Loss: 19287.230469\n",
      "Train Epoch: 152 [124992/225000 (56%)] Loss: 19545.316406\n",
      "Train Epoch: 152 [127488/225000 (57%)] Loss: 18751.900391\n",
      "Train Epoch: 152 [129984/225000 (58%)] Loss: 19392.615234\n",
      "Train Epoch: 152 [132480/225000 (59%)] Loss: 19511.488281\n",
      "Train Epoch: 152 [134976/225000 (60%)] Loss: 19156.744141\n",
      "Train Epoch: 152 [137472/225000 (61%)] Loss: 18961.328125\n",
      "Train Epoch: 152 [139968/225000 (62%)] Loss: 19585.962891\n",
      "Train Epoch: 152 [142464/225000 (63%)] Loss: 19880.925781\n",
      "Train Epoch: 152 [144960/225000 (64%)] Loss: 19413.943359\n",
      "Train Epoch: 152 [147456/225000 (66%)] Loss: 18962.773438\n",
      "Train Epoch: 152 [149952/225000 (67%)] Loss: 19455.111328\n",
      "Train Epoch: 152 [152448/225000 (68%)] Loss: 19367.921875\n",
      "Train Epoch: 152 [154944/225000 (69%)] Loss: 19005.789062\n",
      "Train Epoch: 152 [157440/225000 (70%)] Loss: 18975.949219\n",
      "Train Epoch: 152 [159936/225000 (71%)] Loss: 19259.128906\n",
      "Train Epoch: 152 [162432/225000 (72%)] Loss: 19676.599609\n",
      "Train Epoch: 152 [164928/225000 (73%)] Loss: 19377.332031\n",
      "Train Epoch: 152 [167424/225000 (74%)] Loss: 19060.546875\n",
      "Train Epoch: 152 [169920/225000 (76%)] Loss: 19254.656250\n",
      "Train Epoch: 152 [172416/225000 (77%)] Loss: 19197.125000\n",
      "Train Epoch: 152 [174912/225000 (78%)] Loss: 18767.837891\n",
      "Train Epoch: 152 [177408/225000 (79%)] Loss: 19313.304688\n",
      "Train Epoch: 152 [179904/225000 (80%)] Loss: 19025.492188\n",
      "Train Epoch: 152 [182400/225000 (81%)] Loss: 18982.498047\n",
      "Train Epoch: 152 [184896/225000 (82%)] Loss: 18879.263672\n",
      "Train Epoch: 152 [187392/225000 (83%)] Loss: 19436.996094\n",
      "Train Epoch: 152 [189888/225000 (84%)] Loss: 19125.832031\n",
      "Train Epoch: 152 [192384/225000 (86%)] Loss: 19057.261719\n",
      "Train Epoch: 152 [194880/225000 (87%)] Loss: 19051.113281\n",
      "Train Epoch: 152 [197376/225000 (88%)] Loss: 19143.042969\n",
      "Train Epoch: 152 [199872/225000 (89%)] Loss: 18947.855469\n",
      "Train Epoch: 152 [202368/225000 (90%)] Loss: 19068.597656\n",
      "Train Epoch: 152 [204864/225000 (91%)] Loss: 19585.480469\n",
      "Train Epoch: 152 [207360/225000 (92%)] Loss: 19047.613281\n",
      "Train Epoch: 152 [209856/225000 (93%)] Loss: 19495.109375\n",
      "Train Epoch: 152 [212352/225000 (94%)] Loss: 19485.744141\n",
      "Train Epoch: 152 [214848/225000 (95%)] Loss: 19533.070312\n",
      "Train Epoch: 152 [217344/225000 (97%)] Loss: 19239.677734\n",
      "Train Epoch: 152 [219840/225000 (98%)] Loss: 19092.033203\n",
      "Train Epoch: 152 [222336/225000 (99%)] Loss: 19598.265625\n",
      "Train Epoch: 152 [224832/225000 (100%)] Loss: 19037.751953\n",
      "    epoch          : 152\n",
      "    loss           : 19254.09118360708\n",
      "    val_loss       : 19156.843274152914\n",
      "Train Epoch: 153 [192/225000 (0%)] Loss: 19728.937500\n",
      "Train Epoch: 153 [2688/225000 (1%)] Loss: 19331.972656\n",
      "Train Epoch: 153 [5184/225000 (2%)] Loss: 18730.568359\n",
      "Train Epoch: 153 [7680/225000 (3%)] Loss: 19499.781250\n",
      "Train Epoch: 153 [10176/225000 (5%)] Loss: 19254.533203\n",
      "Train Epoch: 153 [12672/225000 (6%)] Loss: 19369.144531\n",
      "Train Epoch: 153 [15168/225000 (7%)] Loss: 19569.523438\n",
      "Train Epoch: 153 [17664/225000 (8%)] Loss: 19384.722656\n",
      "Train Epoch: 153 [20160/225000 (9%)] Loss: 19479.054688\n",
      "Train Epoch: 153 [22656/225000 (10%)] Loss: 18627.988281\n",
      "Train Epoch: 153 [25152/225000 (11%)] Loss: 19082.613281\n",
      "Train Epoch: 153 [27648/225000 (12%)] Loss: 19319.453125\n",
      "Train Epoch: 153 [30144/225000 (13%)] Loss: 19279.097656\n",
      "Train Epoch: 153 [32640/225000 (15%)] Loss: 19324.972656\n",
      "Train Epoch: 153 [35136/225000 (16%)] Loss: 19703.222656\n",
      "Train Epoch: 153 [37632/225000 (17%)] Loss: 18916.382812\n",
      "Train Epoch: 153 [40128/225000 (18%)] Loss: 19311.613281\n",
      "Train Epoch: 153 [42624/225000 (19%)] Loss: 19052.031250\n",
      "Train Epoch: 153 [45120/225000 (20%)] Loss: 19157.773438\n",
      "Train Epoch: 153 [47616/225000 (21%)] Loss: 19356.673828\n",
      "Train Epoch: 153 [50112/225000 (22%)] Loss: 18844.042969\n",
      "Train Epoch: 153 [52608/225000 (23%)] Loss: 19175.863281\n",
      "Train Epoch: 153 [55104/225000 (24%)] Loss: 19110.468750\n",
      "Train Epoch: 153 [57600/225000 (26%)] Loss: 19193.203125\n",
      "Train Epoch: 153 [60096/225000 (27%)] Loss: 24101.281250\n",
      "Train Epoch: 153 [62592/225000 (28%)] Loss: 19516.261719\n",
      "Train Epoch: 153 [65088/225000 (29%)] Loss: 19500.593750\n",
      "Train Epoch: 153 [67584/225000 (30%)] Loss: 19629.685547\n",
      "Train Epoch: 153 [70080/225000 (31%)] Loss: 19732.335938\n",
      "Train Epoch: 153 [72576/225000 (32%)] Loss: 19776.218750\n",
      "Train Epoch: 153 [75072/225000 (33%)] Loss: 19081.757812\n",
      "Train Epoch: 153 [77568/225000 (34%)] Loss: 22675.925781\n",
      "Train Epoch: 153 [80064/225000 (36%)] Loss: 19779.167969\n",
      "Train Epoch: 153 [82560/225000 (37%)] Loss: 19006.500000\n",
      "Train Epoch: 153 [85056/225000 (38%)] Loss: 19247.730469\n",
      "Train Epoch: 153 [87552/225000 (39%)] Loss: 19439.167969\n",
      "Train Epoch: 153 [90048/225000 (40%)] Loss: 19464.982422\n",
      "Train Epoch: 153 [92544/225000 (41%)] Loss: 19171.072266\n",
      "Train Epoch: 153 [95040/225000 (42%)] Loss: 18915.210938\n",
      "Train Epoch: 153 [97536/225000 (43%)] Loss: 19161.550781\n",
      "Train Epoch: 153 [100032/225000 (44%)] Loss: 19609.214844\n",
      "Train Epoch: 153 [102528/225000 (46%)] Loss: 19616.562500\n",
      "Train Epoch: 153 [105024/225000 (47%)] Loss: 19206.671875\n",
      "Train Epoch: 153 [107520/225000 (48%)] Loss: 18720.339844\n",
      "Train Epoch: 153 [110016/225000 (49%)] Loss: 19006.386719\n",
      "Train Epoch: 153 [112512/225000 (50%)] Loss: 19046.488281\n",
      "Train Epoch: 153 [115008/225000 (51%)] Loss: 19504.058594\n",
      "Train Epoch: 153 [117504/225000 (52%)] Loss: 19482.785156\n",
      "Train Epoch: 153 [120000/225000 (53%)] Loss: 19118.974609\n",
      "Train Epoch: 153 [122496/225000 (54%)] Loss: 19409.765625\n",
      "Train Epoch: 153 [124992/225000 (56%)] Loss: 19505.218750\n",
      "Train Epoch: 153 [127488/225000 (57%)] Loss: 19764.574219\n",
      "Train Epoch: 153 [129984/225000 (58%)] Loss: 19293.808594\n",
      "Train Epoch: 153 [132480/225000 (59%)] Loss: 19392.835938\n",
      "Train Epoch: 153 [134976/225000 (60%)] Loss: 19726.773438\n",
      "Train Epoch: 153 [137472/225000 (61%)] Loss: 19692.574219\n",
      "Train Epoch: 153 [139968/225000 (62%)] Loss: 19080.472656\n",
      "Train Epoch: 153 [142464/225000 (63%)] Loss: 19080.873047\n",
      "Train Epoch: 153 [144960/225000 (64%)] Loss: 19081.347656\n",
      "Train Epoch: 153 [147456/225000 (66%)] Loss: 19316.244141\n",
      "Train Epoch: 153 [149952/225000 (67%)] Loss: 19164.117188\n",
      "Train Epoch: 153 [152448/225000 (68%)] Loss: 19225.183594\n",
      "Train Epoch: 153 [154944/225000 (69%)] Loss: 18587.039062\n",
      "Train Epoch: 153 [157440/225000 (70%)] Loss: 19835.761719\n",
      "Train Epoch: 153 [159936/225000 (71%)] Loss: 19306.935547\n",
      "Train Epoch: 153 [162432/225000 (72%)] Loss: 19370.578125\n",
      "Train Epoch: 153 [164928/225000 (73%)] Loss: 19053.476562\n",
      "Train Epoch: 153 [167424/225000 (74%)] Loss: 19631.054688\n",
      "Train Epoch: 153 [169920/225000 (76%)] Loss: 19144.253906\n",
      "Train Epoch: 153 [172416/225000 (77%)] Loss: 19114.257812\n",
      "Train Epoch: 153 [174912/225000 (78%)] Loss: 19082.464844\n",
      "Train Epoch: 153 [177408/225000 (79%)] Loss: 19352.101562\n",
      "Train Epoch: 153 [179904/225000 (80%)] Loss: 19442.339844\n",
      "Train Epoch: 153 [182400/225000 (81%)] Loss: 19247.513672\n",
      "Train Epoch: 153 [184896/225000 (82%)] Loss: 19191.978516\n",
      "Train Epoch: 153 [187392/225000 (83%)] Loss: 19056.718750\n",
      "Train Epoch: 153 [189888/225000 (84%)] Loss: 18985.203125\n",
      "Train Epoch: 153 [192384/225000 (86%)] Loss: 18914.583984\n",
      "Train Epoch: 153 [194880/225000 (87%)] Loss: 19565.910156\n",
      "Train Epoch: 153 [197376/225000 (88%)] Loss: 19482.271484\n",
      "Train Epoch: 153 [199872/225000 (89%)] Loss: 19336.783203\n",
      "Train Epoch: 153 [202368/225000 (90%)] Loss: 19359.367188\n",
      "Train Epoch: 153 [204864/225000 (91%)] Loss: 19331.671875\n",
      "Train Epoch: 153 [207360/225000 (92%)] Loss: 19259.445312\n",
      "Train Epoch: 153 [209856/225000 (93%)] Loss: 19646.960938\n",
      "Train Epoch: 153 [212352/225000 (94%)] Loss: 19152.261719\n",
      "Train Epoch: 153 [214848/225000 (95%)] Loss: 19015.691406\n",
      "Train Epoch: 153 [217344/225000 (97%)] Loss: 19001.392578\n",
      "Train Epoch: 153 [219840/225000 (98%)] Loss: 18616.687500\n",
      "Train Epoch: 153 [222336/225000 (99%)] Loss: 19039.777344\n",
      "Train Epoch: 153 [224832/225000 (100%)] Loss: 19331.455078\n",
      "    epoch          : 153\n",
      "    loss           : 19274.223569485923\n",
      "    val_loss       : 19157.637584163942\n",
      "Train Epoch: 154 [192/225000 (0%)] Loss: 19144.085938\n",
      "Train Epoch: 154 [2688/225000 (1%)] Loss: 19149.890625\n",
      "Train Epoch: 154 [5184/225000 (2%)] Loss: 19867.582031\n",
      "Train Epoch: 154 [7680/225000 (3%)] Loss: 19189.302734\n",
      "Train Epoch: 154 [10176/225000 (5%)] Loss: 19353.281250\n",
      "Train Epoch: 154 [12672/225000 (6%)] Loss: 19220.849609\n",
      "Train Epoch: 154 [15168/225000 (7%)] Loss: 19366.585938\n",
      "Train Epoch: 154 [17664/225000 (8%)] Loss: 19081.527344\n",
      "Train Epoch: 154 [20160/225000 (9%)] Loss: 19220.812500\n",
      "Train Epoch: 154 [22656/225000 (10%)] Loss: 18859.009766\n",
      "Train Epoch: 154 [25152/225000 (11%)] Loss: 19328.777344\n",
      "Train Epoch: 154 [27648/225000 (12%)] Loss: 19675.898438\n",
      "Train Epoch: 154 [30144/225000 (13%)] Loss: 18776.359375\n",
      "Train Epoch: 154 [32640/225000 (15%)] Loss: 19051.455078\n",
      "Train Epoch: 154 [35136/225000 (16%)] Loss: 18957.433594\n",
      "Train Epoch: 154 [37632/225000 (17%)] Loss: 19104.603516\n",
      "Train Epoch: 154 [40128/225000 (18%)] Loss: 19107.291016\n",
      "Train Epoch: 154 [42624/225000 (19%)] Loss: 19605.777344\n",
      "Train Epoch: 154 [45120/225000 (20%)] Loss: 19744.972656\n",
      "Train Epoch: 154 [47616/225000 (21%)] Loss: 19300.363281\n",
      "Train Epoch: 154 [50112/225000 (22%)] Loss: 19060.669922\n",
      "Train Epoch: 154 [52608/225000 (23%)] Loss: 18717.597656\n",
      "Train Epoch: 154 [55104/225000 (24%)] Loss: 18859.398438\n",
      "Train Epoch: 154 [57600/225000 (26%)] Loss: 19078.042969\n",
      "Train Epoch: 154 [60096/225000 (27%)] Loss: 19355.986328\n",
      "Train Epoch: 154 [62592/225000 (28%)] Loss: 19244.947266\n",
      "Train Epoch: 154 [65088/225000 (29%)] Loss: 19206.058594\n",
      "Train Epoch: 154 [67584/225000 (30%)] Loss: 19191.082031\n",
      "Train Epoch: 154 [70080/225000 (31%)] Loss: 18986.753906\n",
      "Train Epoch: 154 [72576/225000 (32%)] Loss: 18902.646484\n",
      "Train Epoch: 154 [75072/225000 (33%)] Loss: 19633.845703\n",
      "Train Epoch: 154 [77568/225000 (34%)] Loss: 19347.904297\n",
      "Train Epoch: 154 [80064/225000 (36%)] Loss: 19390.199219\n",
      "Train Epoch: 154 [82560/225000 (37%)] Loss: 19112.492188\n",
      "Train Epoch: 154 [85056/225000 (38%)] Loss: 18833.695312\n",
      "Train Epoch: 154 [87552/225000 (39%)] Loss: 19144.683594\n",
      "Train Epoch: 154 [90048/225000 (40%)] Loss: 19760.039062\n",
      "Train Epoch: 154 [92544/225000 (41%)] Loss: 18862.705078\n",
      "Train Epoch: 154 [95040/225000 (42%)] Loss: 19052.185547\n",
      "Train Epoch: 154 [97536/225000 (43%)] Loss: 18957.953125\n",
      "Train Epoch: 154 [100032/225000 (44%)] Loss: 19045.480469\n",
      "Train Epoch: 154 [102528/225000 (46%)] Loss: 19361.613281\n",
      "Train Epoch: 154 [105024/225000 (47%)] Loss: 19307.847656\n",
      "Train Epoch: 154 [107520/225000 (48%)] Loss: 19015.802734\n",
      "Train Epoch: 154 [110016/225000 (49%)] Loss: 19187.435547\n",
      "Train Epoch: 154 [112512/225000 (50%)] Loss: 19767.632812\n",
      "Train Epoch: 154 [115008/225000 (51%)] Loss: 19434.460938\n",
      "Train Epoch: 154 [117504/225000 (52%)] Loss: 19102.437500\n",
      "Train Epoch: 154 [120000/225000 (53%)] Loss: 19045.173828\n",
      "Train Epoch: 154 [122496/225000 (54%)] Loss: 19318.730469\n",
      "Train Epoch: 154 [124992/225000 (56%)] Loss: 19411.050781\n",
      "Train Epoch: 154 [127488/225000 (57%)] Loss: 19291.156250\n",
      "Train Epoch: 154 [129984/225000 (58%)] Loss: 19490.712891\n",
      "Train Epoch: 154 [132480/225000 (59%)] Loss: 18976.480469\n",
      "Train Epoch: 154 [134976/225000 (60%)] Loss: 19652.140625\n",
      "Train Epoch: 154 [137472/225000 (61%)] Loss: 19982.539062\n",
      "Train Epoch: 154 [139968/225000 (62%)] Loss: 19660.773438\n",
      "Train Epoch: 154 [142464/225000 (63%)] Loss: 18970.925781\n",
      "Train Epoch: 154 [144960/225000 (64%)] Loss: 19115.320312\n",
      "Train Epoch: 154 [147456/225000 (66%)] Loss: 18866.003906\n",
      "Train Epoch: 154 [149952/225000 (67%)] Loss: 19364.884766\n",
      "Train Epoch: 154 [152448/225000 (68%)] Loss: 18853.707031\n",
      "Train Epoch: 154 [154944/225000 (69%)] Loss: 19324.445312\n",
      "Train Epoch: 154 [157440/225000 (70%)] Loss: 18733.949219\n",
      "Train Epoch: 154 [159936/225000 (71%)] Loss: 18878.800781\n",
      "Train Epoch: 154 [162432/225000 (72%)] Loss: 19654.125000\n",
      "Train Epoch: 154 [164928/225000 (73%)] Loss: 19664.308594\n",
      "Train Epoch: 154 [167424/225000 (74%)] Loss: 18915.767578\n",
      "Train Epoch: 154 [169920/225000 (76%)] Loss: 19326.779297\n",
      "Train Epoch: 154 [172416/225000 (77%)] Loss: 19069.367188\n",
      "Train Epoch: 154 [174912/225000 (78%)] Loss: 18591.656250\n",
      "Train Epoch: 154 [177408/225000 (79%)] Loss: 19286.392578\n",
      "Train Epoch: 154 [179904/225000 (80%)] Loss: 18927.673828\n",
      "Train Epoch: 154 [182400/225000 (81%)] Loss: 19289.767578\n",
      "Train Epoch: 154 [184896/225000 (82%)] Loss: 19147.701172\n",
      "Train Epoch: 154 [187392/225000 (83%)] Loss: 19325.417969\n",
      "Train Epoch: 154 [189888/225000 (84%)] Loss: 18916.857422\n",
      "Train Epoch: 154 [192384/225000 (86%)] Loss: 19440.269531\n",
      "Train Epoch: 154 [194880/225000 (87%)] Loss: 19148.269531\n",
      "Train Epoch: 154 [197376/225000 (88%)] Loss: 19306.365234\n",
      "Train Epoch: 154 [199872/225000 (89%)] Loss: 18569.531250\n",
      "Train Epoch: 154 [202368/225000 (90%)] Loss: 18865.664062\n",
      "Train Epoch: 154 [204864/225000 (91%)] Loss: 19143.171875\n",
      "Train Epoch: 154 [207360/225000 (92%)] Loss: 19249.390625\n",
      "Train Epoch: 154 [209856/225000 (93%)] Loss: 19831.958984\n",
      "Train Epoch: 154 [212352/225000 (94%)] Loss: 19159.900391\n",
      "Train Epoch: 154 [214848/225000 (95%)] Loss: 19549.671875\n",
      "Train Epoch: 154 [217344/225000 (97%)] Loss: 19292.886719\n",
      "Train Epoch: 154 [219840/225000 (98%)] Loss: 18875.386719\n",
      "Train Epoch: 154 [222336/225000 (99%)] Loss: 19708.746094\n",
      "Train Epoch: 154 [224832/225000 (100%)] Loss: 19313.505859\n",
      "    epoch          : 154\n",
      "    loss           : 19256.116677554393\n",
      "    val_loss       : 19149.90193782326\n",
      "Train Epoch: 155 [192/225000 (0%)] Loss: 19086.742188\n",
      "Train Epoch: 155 [2688/225000 (1%)] Loss: 19045.453125\n",
      "Train Epoch: 155 [5184/225000 (2%)] Loss: 24584.511719\n",
      "Train Epoch: 155 [7680/225000 (3%)] Loss: 18946.445312\n",
      "Train Epoch: 155 [10176/225000 (5%)] Loss: 19025.410156\n",
      "Train Epoch: 155 [12672/225000 (6%)] Loss: 19153.339844\n",
      "Train Epoch: 155 [15168/225000 (7%)] Loss: 19280.087891\n",
      "Train Epoch: 155 [17664/225000 (8%)] Loss: 19318.289062\n",
      "Train Epoch: 155 [20160/225000 (9%)] Loss: 18988.046875\n",
      "Train Epoch: 155 [22656/225000 (10%)] Loss: 18993.130859\n",
      "Train Epoch: 155 [25152/225000 (11%)] Loss: 19297.210938\n",
      "Train Epoch: 155 [27648/225000 (12%)] Loss: 19226.726562\n",
      "Train Epoch: 155 [30144/225000 (13%)] Loss: 19154.541016\n",
      "Train Epoch: 155 [32640/225000 (15%)] Loss: 18985.203125\n",
      "Train Epoch: 155 [35136/225000 (16%)] Loss: 19343.628906\n",
      "Train Epoch: 155 [37632/225000 (17%)] Loss: 19076.478516\n",
      "Train Epoch: 155 [40128/225000 (18%)] Loss: 19255.826172\n",
      "Train Epoch: 155 [42624/225000 (19%)] Loss: 18738.683594\n",
      "Train Epoch: 155 [45120/225000 (20%)] Loss: 19076.041016\n",
      "Train Epoch: 155 [47616/225000 (21%)] Loss: 19205.427734\n",
      "Train Epoch: 155 [50112/225000 (22%)] Loss: 19484.662109\n",
      "Train Epoch: 155 [52608/225000 (23%)] Loss: 19332.828125\n",
      "Train Epoch: 155 [55104/225000 (24%)] Loss: 19721.347656\n",
      "Train Epoch: 155 [57600/225000 (26%)] Loss: 19122.224609\n",
      "Train Epoch: 155 [60096/225000 (27%)] Loss: 19063.775391\n",
      "Train Epoch: 155 [62592/225000 (28%)] Loss: 19636.605469\n",
      "Train Epoch: 155 [65088/225000 (29%)] Loss: 19094.457031\n",
      "Train Epoch: 155 [67584/225000 (30%)] Loss: 19081.556641\n",
      "Train Epoch: 155 [70080/225000 (31%)] Loss: 19671.996094\n",
      "Train Epoch: 155 [72576/225000 (32%)] Loss: 19406.921875\n",
      "Train Epoch: 155 [75072/225000 (33%)] Loss: 19256.771484\n",
      "Train Epoch: 155 [77568/225000 (34%)] Loss: 19475.378906\n",
      "Train Epoch: 155 [80064/225000 (36%)] Loss: 19304.537109\n",
      "Train Epoch: 155 [82560/225000 (37%)] Loss: 19864.892578\n",
      "Train Epoch: 155 [85056/225000 (38%)] Loss: 19479.660156\n",
      "Train Epoch: 155 [87552/225000 (39%)] Loss: 20214.355469\n",
      "Train Epoch: 155 [90048/225000 (40%)] Loss: 19598.408203\n",
      "Train Epoch: 155 [92544/225000 (41%)] Loss: 19698.640625\n",
      "Train Epoch: 155 [95040/225000 (42%)] Loss: 19172.648438\n",
      "Train Epoch: 155 [97536/225000 (43%)] Loss: 19321.521484\n",
      "Train Epoch: 155 [100032/225000 (44%)] Loss: 19128.800781\n",
      "Train Epoch: 155 [102528/225000 (46%)] Loss: 19348.683594\n",
      "Train Epoch: 155 [105024/225000 (47%)] Loss: 19357.398438\n",
      "Train Epoch: 155 [107520/225000 (48%)] Loss: 19175.365234\n",
      "Train Epoch: 155 [110016/225000 (49%)] Loss: 19045.765625\n",
      "Train Epoch: 155 [112512/225000 (50%)] Loss: 19374.882812\n",
      "Train Epoch: 155 [115008/225000 (51%)] Loss: 19521.503906\n",
      "Train Epoch: 155 [117504/225000 (52%)] Loss: 19403.283203\n",
      "Train Epoch: 155 [120000/225000 (53%)] Loss: 19634.384766\n",
      "Train Epoch: 155 [122496/225000 (54%)] Loss: 19707.000000\n",
      "Train Epoch: 155 [124992/225000 (56%)] Loss: 18992.835938\n",
      "Train Epoch: 155 [127488/225000 (57%)] Loss: 19279.267578\n",
      "Train Epoch: 155 [129984/225000 (58%)] Loss: 19665.933594\n",
      "Train Epoch: 155 [132480/225000 (59%)] Loss: 19275.263672\n",
      "Train Epoch: 155 [134976/225000 (60%)] Loss: 18875.707031\n",
      "Train Epoch: 155 [137472/225000 (61%)] Loss: 19082.734375\n",
      "Train Epoch: 155 [139968/225000 (62%)] Loss: 19070.421875\n",
      "Train Epoch: 155 [142464/225000 (63%)] Loss: 19014.201172\n",
      "Train Epoch: 155 [144960/225000 (64%)] Loss: 19123.166016\n",
      "Train Epoch: 155 [147456/225000 (66%)] Loss: 18866.373047\n",
      "Train Epoch: 155 [149952/225000 (67%)] Loss: 19272.623047\n",
      "Train Epoch: 155 [152448/225000 (68%)] Loss: 19628.941406\n",
      "Train Epoch: 155 [154944/225000 (69%)] Loss: 19414.716797\n",
      "Train Epoch: 155 [157440/225000 (70%)] Loss: 19456.296875\n",
      "Train Epoch: 155 [159936/225000 (71%)] Loss: 19206.812500\n",
      "Train Epoch: 155 [162432/225000 (72%)] Loss: 19507.527344\n",
      "Train Epoch: 155 [164928/225000 (73%)] Loss: 19527.710938\n",
      "Train Epoch: 155 [167424/225000 (74%)] Loss: 19356.808594\n",
      "Train Epoch: 155 [169920/225000 (76%)] Loss: 19652.259766\n",
      "Train Epoch: 155 [172416/225000 (77%)] Loss: 19494.683594\n",
      "Train Epoch: 155 [174912/225000 (78%)] Loss: 18942.767578\n",
      "Train Epoch: 155 [177408/225000 (79%)] Loss: 19568.148438\n",
      "Train Epoch: 155 [179904/225000 (80%)] Loss: 19214.011719\n",
      "Train Epoch: 155 [182400/225000 (81%)] Loss: 18958.564453\n",
      "Train Epoch: 155 [184896/225000 (82%)] Loss: 18876.593750\n",
      "Train Epoch: 155 [187392/225000 (83%)] Loss: 19598.357422\n",
      "Train Epoch: 155 [189888/225000 (84%)] Loss: 18800.445312\n",
      "Train Epoch: 155 [192384/225000 (86%)] Loss: 19016.449219\n",
      "Train Epoch: 155 [194880/225000 (87%)] Loss: 18697.031250\n",
      "Train Epoch: 155 [197376/225000 (88%)] Loss: 19127.388672\n",
      "Train Epoch: 155 [199872/225000 (89%)] Loss: 19118.851562\n",
      "Train Epoch: 155 [202368/225000 (90%)] Loss: 19153.521484\n",
      "Train Epoch: 155 [204864/225000 (91%)] Loss: 19671.871094\n",
      "Train Epoch: 155 [207360/225000 (92%)] Loss: 19720.507812\n",
      "Train Epoch: 155 [209856/225000 (93%)] Loss: 19136.484375\n",
      "Train Epoch: 155 [212352/225000 (94%)] Loss: 19585.929688\n",
      "Train Epoch: 155 [214848/225000 (95%)] Loss: 19311.892578\n",
      "Train Epoch: 155 [217344/225000 (97%)] Loss: 19215.734375\n",
      "Train Epoch: 155 [219840/225000 (98%)] Loss: 19139.515625\n",
      "Train Epoch: 155 [222336/225000 (99%)] Loss: 19127.599609\n",
      "Train Epoch: 155 [224832/225000 (100%)] Loss: 18736.417969\n",
      "    epoch          : 155\n",
      "    loss           : 19248.68874986668\n",
      "    val_loss       : 19145.501430653432\n",
      "Train Epoch: 156 [192/225000 (0%)] Loss: 19139.789062\n",
      "Train Epoch: 156 [2688/225000 (1%)] Loss: 19859.933594\n",
      "Train Epoch: 156 [5184/225000 (2%)] Loss: 19651.765625\n",
      "Train Epoch: 156 [7680/225000 (3%)] Loss: 19448.714844\n",
      "Train Epoch: 156 [10176/225000 (5%)] Loss: 19698.589844\n",
      "Train Epoch: 156 [12672/225000 (6%)] Loss: 19416.101562\n",
      "Train Epoch: 156 [15168/225000 (7%)] Loss: 19448.148438\n",
      "Train Epoch: 156 [17664/225000 (8%)] Loss: 19941.142578\n",
      "Train Epoch: 156 [20160/225000 (9%)] Loss: 19371.316406\n",
      "Train Epoch: 156 [22656/225000 (10%)] Loss: 19142.136719\n",
      "Train Epoch: 156 [25152/225000 (11%)] Loss: 19461.078125\n",
      "Train Epoch: 156 [27648/225000 (12%)] Loss: 19150.445312\n",
      "Train Epoch: 156 [30144/225000 (13%)] Loss: 19424.078125\n",
      "Train Epoch: 156 [32640/225000 (15%)] Loss: 19136.085938\n",
      "Train Epoch: 156 [35136/225000 (16%)] Loss: 18789.691406\n",
      "Train Epoch: 156 [37632/225000 (17%)] Loss: 19696.246094\n",
      "Train Epoch: 156 [40128/225000 (18%)] Loss: 19033.951172\n",
      "Train Epoch: 156 [42624/225000 (19%)] Loss: 19046.267578\n",
      "Train Epoch: 156 [45120/225000 (20%)] Loss: 19238.464844\n",
      "Train Epoch: 156 [47616/225000 (21%)] Loss: 19261.351562\n",
      "Train Epoch: 156 [50112/225000 (22%)] Loss: 19261.605469\n",
      "Train Epoch: 156 [52608/225000 (23%)] Loss: 19508.191406\n",
      "Train Epoch: 156 [55104/225000 (24%)] Loss: 19111.917969\n",
      "Train Epoch: 156 [57600/225000 (26%)] Loss: 19434.974609\n",
      "Train Epoch: 156 [60096/225000 (27%)] Loss: 19121.998047\n",
      "Train Epoch: 156 [62592/225000 (28%)] Loss: 19390.181641\n",
      "Train Epoch: 156 [65088/225000 (29%)] Loss: 19335.421875\n",
      "Train Epoch: 156 [67584/225000 (30%)] Loss: 19527.488281\n",
      "Train Epoch: 156 [70080/225000 (31%)] Loss: 19451.697266\n",
      "Train Epoch: 156 [72576/225000 (32%)] Loss: 18919.382812\n",
      "Train Epoch: 156 [75072/225000 (33%)] Loss: 19222.390625\n",
      "Train Epoch: 156 [77568/225000 (34%)] Loss: 19205.892578\n",
      "Train Epoch: 156 [80064/225000 (36%)] Loss: 19733.867188\n",
      "Train Epoch: 156 [82560/225000 (37%)] Loss: 19497.207031\n",
      "Train Epoch: 156 [85056/225000 (38%)] Loss: 19605.109375\n",
      "Train Epoch: 156 [87552/225000 (39%)] Loss: 19487.398438\n",
      "Train Epoch: 156 [90048/225000 (40%)] Loss: 19196.730469\n",
      "Train Epoch: 156 [92544/225000 (41%)] Loss: 19123.128906\n",
      "Train Epoch: 156 [95040/225000 (42%)] Loss: 19291.714844\n",
      "Train Epoch: 156 [97536/225000 (43%)] Loss: 19073.941406\n",
      "Train Epoch: 156 [100032/225000 (44%)] Loss: 19101.070312\n",
      "Train Epoch: 156 [102528/225000 (46%)] Loss: 19543.246094\n",
      "Train Epoch: 156 [105024/225000 (47%)] Loss: 19313.505859\n",
      "Train Epoch: 156 [107520/225000 (48%)] Loss: 19571.597656\n",
      "Train Epoch: 156 [110016/225000 (49%)] Loss: 19212.835938\n",
      "Train Epoch: 156 [112512/225000 (50%)] Loss: 18929.730469\n",
      "Train Epoch: 156 [115008/225000 (51%)] Loss: 19106.396484\n",
      "Train Epoch: 156 [117504/225000 (52%)] Loss: 19211.417969\n",
      "Train Epoch: 156 [120000/225000 (53%)] Loss: 18815.917969\n",
      "Train Epoch: 156 [122496/225000 (54%)] Loss: 19423.910156\n",
      "Train Epoch: 156 [124992/225000 (56%)] Loss: 19415.156250\n",
      "Train Epoch: 156 [127488/225000 (57%)] Loss: 19072.671875\n",
      "Train Epoch: 156 [129984/225000 (58%)] Loss: 18975.820312\n",
      "Train Epoch: 156 [132480/225000 (59%)] Loss: 19233.013672\n",
      "Train Epoch: 156 [134976/225000 (60%)] Loss: 19144.945312\n",
      "Train Epoch: 156 [137472/225000 (61%)] Loss: 19432.412109\n",
      "Train Epoch: 156 [139968/225000 (62%)] Loss: 19534.287109\n",
      "Train Epoch: 156 [142464/225000 (63%)] Loss: 19151.636719\n",
      "Train Epoch: 156 [144960/225000 (64%)] Loss: 18617.246094\n",
      "Train Epoch: 156 [147456/225000 (66%)] Loss: 19202.609375\n",
      "Train Epoch: 156 [149952/225000 (67%)] Loss: 19647.808594\n",
      "Train Epoch: 156 [152448/225000 (68%)] Loss: 19358.699219\n",
      "Train Epoch: 156 [154944/225000 (69%)] Loss: 19483.210938\n",
      "Train Epoch: 156 [157440/225000 (70%)] Loss: 19511.593750\n",
      "Train Epoch: 156 [159936/225000 (71%)] Loss: 19158.015625\n",
      "Train Epoch: 156 [162432/225000 (72%)] Loss: 19683.339844\n",
      "Train Epoch: 156 [164928/225000 (73%)] Loss: 19024.500000\n",
      "Train Epoch: 156 [167424/225000 (74%)] Loss: 19077.214844\n",
      "Train Epoch: 156 [169920/225000 (76%)] Loss: 19070.734375\n",
      "Train Epoch: 156 [172416/225000 (77%)] Loss: 18611.105469\n",
      "Train Epoch: 156 [174912/225000 (78%)] Loss: 19541.289062\n",
      "Train Epoch: 156 [177408/225000 (79%)] Loss: 19470.126953\n",
      "Train Epoch: 156 [179904/225000 (80%)] Loss: 19436.886719\n",
      "Train Epoch: 156 [182400/225000 (81%)] Loss: 19238.992188\n",
      "Train Epoch: 156 [184896/225000 (82%)] Loss: 18898.675781\n",
      "Train Epoch: 156 [187392/225000 (83%)] Loss: 19377.332031\n",
      "Train Epoch: 156 [189888/225000 (84%)] Loss: 18677.246094\n",
      "Train Epoch: 156 [192384/225000 (86%)] Loss: 19164.945312\n",
      "Train Epoch: 156 [194880/225000 (87%)] Loss: 19910.775391\n",
      "Train Epoch: 156 [197376/225000 (88%)] Loss: 19087.425781\n",
      "Train Epoch: 156 [199872/225000 (89%)] Loss: 19098.781250\n",
      "Train Epoch: 156 [202368/225000 (90%)] Loss: 19391.121094\n",
      "Train Epoch: 156 [204864/225000 (91%)] Loss: 18888.960938\n",
      "Train Epoch: 156 [207360/225000 (92%)] Loss: 19638.167969\n",
      "Train Epoch: 156 [209856/225000 (93%)] Loss: 19062.832031\n",
      "Train Epoch: 156 [212352/225000 (94%)] Loss: 19229.566406\n",
      "Train Epoch: 156 [214848/225000 (95%)] Loss: 18892.726562\n",
      "Train Epoch: 156 [217344/225000 (97%)] Loss: 19117.236328\n",
      "Train Epoch: 156 [219840/225000 (98%)] Loss: 19272.785156\n",
      "Train Epoch: 156 [222336/225000 (99%)] Loss: 19442.121094\n",
      "Train Epoch: 156 [224832/225000 (100%)] Loss: 19065.443359\n",
      "    epoch          : 156\n",
      "    loss           : 19241.325406956592\n",
      "    val_loss       : 19212.588582790533\n",
      "Train Epoch: 157 [192/225000 (0%)] Loss: 19515.623047\n",
      "Train Epoch: 157 [2688/225000 (1%)] Loss: 19019.429688\n",
      "Train Epoch: 157 [5184/225000 (2%)] Loss: 19643.242188\n",
      "Train Epoch: 157 [7680/225000 (3%)] Loss: 19840.710938\n",
      "Train Epoch: 157 [10176/225000 (5%)] Loss: 18832.550781\n",
      "Train Epoch: 157 [12672/225000 (6%)] Loss: 19032.492188\n",
      "Train Epoch: 157 [15168/225000 (7%)] Loss: 19495.255859\n",
      "Train Epoch: 157 [17664/225000 (8%)] Loss: 19051.207031\n",
      "Train Epoch: 157 [20160/225000 (9%)] Loss: 19415.675781\n",
      "Train Epoch: 157 [22656/225000 (10%)] Loss: 19234.152344\n",
      "Train Epoch: 157 [25152/225000 (11%)] Loss: 19769.699219\n",
      "Train Epoch: 157 [27648/225000 (12%)] Loss: 18909.730469\n",
      "Train Epoch: 157 [30144/225000 (13%)] Loss: 19079.541016\n",
      "Train Epoch: 157 [32640/225000 (15%)] Loss: 19200.761719\n",
      "Train Epoch: 157 [35136/225000 (16%)] Loss: 19797.949219\n",
      "Train Epoch: 157 [37632/225000 (17%)] Loss: 19198.710938\n",
      "Train Epoch: 157 [40128/225000 (18%)] Loss: 19403.554688\n",
      "Train Epoch: 157 [42624/225000 (19%)] Loss: 19254.541016\n",
      "Train Epoch: 157 [45120/225000 (20%)] Loss: 18484.228516\n",
      "Train Epoch: 157 [47616/225000 (21%)] Loss: 18932.648438\n",
      "Train Epoch: 157 [50112/225000 (22%)] Loss: 19460.179688\n",
      "Train Epoch: 157 [52608/225000 (23%)] Loss: 18805.859375\n",
      "Train Epoch: 157 [55104/225000 (24%)] Loss: 19808.490234\n",
      "Train Epoch: 157 [57600/225000 (26%)] Loss: 19119.890625\n",
      "Train Epoch: 157 [60096/225000 (27%)] Loss: 19637.031250\n",
      "Train Epoch: 157 [62592/225000 (28%)] Loss: 19327.289062\n",
      "Train Epoch: 157 [65088/225000 (29%)] Loss: 19448.457031\n",
      "Train Epoch: 157 [67584/225000 (30%)] Loss: 18871.615234\n",
      "Train Epoch: 157 [70080/225000 (31%)] Loss: 19510.947266\n",
      "Train Epoch: 157 [72576/225000 (32%)] Loss: 18859.625000\n",
      "Train Epoch: 157 [75072/225000 (33%)] Loss: 19692.806641\n",
      "Train Epoch: 157 [77568/225000 (34%)] Loss: 19106.875000\n",
      "Train Epoch: 157 [80064/225000 (36%)] Loss: 19239.964844\n",
      "Train Epoch: 157 [82560/225000 (37%)] Loss: 19374.412109\n",
      "Train Epoch: 157 [85056/225000 (38%)] Loss: 19402.447266\n",
      "Train Epoch: 157 [87552/225000 (39%)] Loss: 19208.896484\n",
      "Train Epoch: 157 [90048/225000 (40%)] Loss: 18762.806641\n",
      "Train Epoch: 157 [92544/225000 (41%)] Loss: 19195.714844\n",
      "Train Epoch: 157 [95040/225000 (42%)] Loss: 19082.644531\n",
      "Train Epoch: 157 [97536/225000 (43%)] Loss: 19281.480469\n",
      "Train Epoch: 157 [100032/225000 (44%)] Loss: 19601.773438\n",
      "Train Epoch: 157 [102528/225000 (46%)] Loss: 19147.789062\n",
      "Train Epoch: 157 [105024/225000 (47%)] Loss: 20010.615234\n",
      "Train Epoch: 157 [107520/225000 (48%)] Loss: 19516.289062\n",
      "Train Epoch: 157 [110016/225000 (49%)] Loss: 19108.507812\n",
      "Train Epoch: 157 [112512/225000 (50%)] Loss: 19200.101562\n",
      "Train Epoch: 157 [115008/225000 (51%)] Loss: 19183.351562\n",
      "Train Epoch: 157 [117504/225000 (52%)] Loss: 19040.072266\n",
      "Train Epoch: 157 [120000/225000 (53%)] Loss: 19372.488281\n",
      "Train Epoch: 157 [122496/225000 (54%)] Loss: 19470.125000\n",
      "Train Epoch: 157 [124992/225000 (56%)] Loss: 19105.937500\n",
      "Train Epoch: 157 [127488/225000 (57%)] Loss: 19149.884766\n",
      "Train Epoch: 157 [129984/225000 (58%)] Loss: 19305.218750\n",
      "Train Epoch: 157 [132480/225000 (59%)] Loss: 19502.638672\n",
      "Train Epoch: 157 [134976/225000 (60%)] Loss: 19614.425781\n",
      "Train Epoch: 157 [137472/225000 (61%)] Loss: 18823.025391\n",
      "Train Epoch: 157 [139968/225000 (62%)] Loss: 19135.144531\n",
      "Train Epoch: 157 [142464/225000 (63%)] Loss: 19556.841797\n",
      "Train Epoch: 157 [144960/225000 (64%)] Loss: 18867.923828\n",
      "Train Epoch: 157 [147456/225000 (66%)] Loss: 19813.298828\n",
      "Train Epoch: 157 [149952/225000 (67%)] Loss: 19386.871094\n",
      "Train Epoch: 157 [152448/225000 (68%)] Loss: 19182.927734\n",
      "Train Epoch: 157 [154944/225000 (69%)] Loss: 19201.083984\n",
      "Train Epoch: 157 [157440/225000 (70%)] Loss: 19300.125000\n",
      "Train Epoch: 157 [159936/225000 (71%)] Loss: 19463.832031\n",
      "Train Epoch: 157 [162432/225000 (72%)] Loss: 19292.656250\n",
      "Train Epoch: 157 [164928/225000 (73%)] Loss: 19350.445312\n",
      "Train Epoch: 157 [167424/225000 (74%)] Loss: 19563.759766\n",
      "Train Epoch: 157 [169920/225000 (76%)] Loss: 19070.343750\n",
      "Train Epoch: 157 [172416/225000 (77%)] Loss: 19157.253906\n",
      "Train Epoch: 157 [174912/225000 (78%)] Loss: 19284.962891\n",
      "Train Epoch: 157 [177408/225000 (79%)] Loss: 18973.015625\n",
      "Train Epoch: 157 [179904/225000 (80%)] Loss: 19044.636719\n",
      "Train Epoch: 157 [182400/225000 (81%)] Loss: 19097.693359\n",
      "Train Epoch: 157 [184896/225000 (82%)] Loss: 19087.130859\n",
      "Train Epoch: 157 [187392/225000 (83%)] Loss: 19176.349609\n",
      "Train Epoch: 157 [189888/225000 (84%)] Loss: 19372.343750\n",
      "Train Epoch: 157 [192384/225000 (86%)] Loss: 19169.187500\n",
      "Train Epoch: 157 [194880/225000 (87%)] Loss: 19674.826172\n",
      "Train Epoch: 157 [197376/225000 (88%)] Loss: 18943.029297\n",
      "Train Epoch: 157 [199872/225000 (89%)] Loss: 19308.384766\n",
      "Train Epoch: 157 [202368/225000 (90%)] Loss: 19114.136719\n",
      "Train Epoch: 157 [204864/225000 (91%)] Loss: 19456.857422\n",
      "Train Epoch: 157 [207360/225000 (92%)] Loss: 19568.445312\n",
      "Train Epoch: 157 [209856/225000 (93%)] Loss: 19509.416016\n",
      "Train Epoch: 157 [212352/225000 (94%)] Loss: 19320.855469\n",
      "Train Epoch: 157 [214848/225000 (95%)] Loss: 19215.824219\n",
      "Train Epoch: 157 [217344/225000 (97%)] Loss: 18917.347656\n",
      "Train Epoch: 157 [219840/225000 (98%)] Loss: 19160.925781\n",
      "Train Epoch: 157 [222336/225000 (99%)] Loss: 19551.769531\n",
      "Train Epoch: 157 [224832/225000 (100%)] Loss: 19001.988281\n",
      "    epoch          : 157\n",
      "    loss           : 19248.776570499147\n",
      "    val_loss       : 19146.568368835302\n",
      "Train Epoch: 158 [192/225000 (0%)] Loss: 19330.369141\n",
      "Train Epoch: 158 [2688/225000 (1%)] Loss: 19242.417969\n",
      "Train Epoch: 158 [5184/225000 (2%)] Loss: 18901.847656\n",
      "Train Epoch: 158 [7680/225000 (3%)] Loss: 19477.738281\n",
      "Train Epoch: 158 [10176/225000 (5%)] Loss: 18990.164062\n",
      "Train Epoch: 158 [12672/225000 (6%)] Loss: 19181.402344\n",
      "Train Epoch: 158 [15168/225000 (7%)] Loss: 19244.683594\n",
      "Train Epoch: 158 [17664/225000 (8%)] Loss: 19215.160156\n",
      "Train Epoch: 158 [20160/225000 (9%)] Loss: 19640.105469\n",
      "Train Epoch: 158 [22656/225000 (10%)] Loss: 19264.773438\n",
      "Train Epoch: 158 [25152/225000 (11%)] Loss: 19284.328125\n",
      "Train Epoch: 158 [27648/225000 (12%)] Loss: 19294.064453\n",
      "Train Epoch: 158 [30144/225000 (13%)] Loss: 19002.179688\n",
      "Train Epoch: 158 [32640/225000 (15%)] Loss: 19847.777344\n",
      "Train Epoch: 158 [35136/225000 (16%)] Loss: 19454.833984\n",
      "Train Epoch: 158 [37632/225000 (17%)] Loss: 19389.941406\n",
      "Train Epoch: 158 [40128/225000 (18%)] Loss: 19236.210938\n",
      "Train Epoch: 158 [42624/225000 (19%)] Loss: 19225.742188\n",
      "Train Epoch: 158 [45120/225000 (20%)] Loss: 19476.878906\n",
      "Train Epoch: 158 [47616/225000 (21%)] Loss: 19012.251953\n",
      "Train Epoch: 158 [50112/225000 (22%)] Loss: 19061.121094\n",
      "Train Epoch: 158 [52608/225000 (23%)] Loss: 19362.871094\n",
      "Train Epoch: 158 [55104/225000 (24%)] Loss: 19289.804688\n",
      "Train Epoch: 158 [57600/225000 (26%)] Loss: 19337.667969\n",
      "Train Epoch: 158 [60096/225000 (27%)] Loss: 19085.134766\n",
      "Train Epoch: 158 [62592/225000 (28%)] Loss: 19585.513672\n",
      "Train Epoch: 158 [65088/225000 (29%)] Loss: 19152.939453\n",
      "Train Epoch: 158 [67584/225000 (30%)] Loss: 19034.601562\n",
      "Train Epoch: 158 [70080/225000 (31%)] Loss: 19574.359375\n",
      "Train Epoch: 158 [72576/225000 (32%)] Loss: 19333.527344\n",
      "Train Epoch: 158 [75072/225000 (33%)] Loss: 19018.929688\n",
      "Train Epoch: 158 [77568/225000 (34%)] Loss: 19262.392578\n",
      "Train Epoch: 158 [80064/225000 (36%)] Loss: 18991.664062\n",
      "Train Epoch: 158 [82560/225000 (37%)] Loss: 19411.333984\n",
      "Train Epoch: 158 [85056/225000 (38%)] Loss: 19619.359375\n",
      "Train Epoch: 158 [87552/225000 (39%)] Loss: 19141.837891\n",
      "Train Epoch: 158 [90048/225000 (40%)] Loss: 19222.609375\n",
      "Train Epoch: 158 [92544/225000 (41%)] Loss: 19030.046875\n",
      "Train Epoch: 158 [95040/225000 (42%)] Loss: 19462.796875\n",
      "Train Epoch: 158 [97536/225000 (43%)] Loss: 19427.558594\n",
      "Train Epoch: 158 [100032/225000 (44%)] Loss: 19466.691406\n",
      "Train Epoch: 158 [102528/225000 (46%)] Loss: 19433.156250\n",
      "Train Epoch: 158 [105024/225000 (47%)] Loss: 19482.718750\n",
      "Train Epoch: 158 [107520/225000 (48%)] Loss: 19181.863281\n",
      "Train Epoch: 158 [110016/225000 (49%)] Loss: 18891.757812\n",
      "Train Epoch: 158 [112512/225000 (50%)] Loss: 19346.605469\n",
      "Train Epoch: 158 [115008/225000 (51%)] Loss: 19433.898438\n",
      "Train Epoch: 158 [117504/225000 (52%)] Loss: 19295.480469\n",
      "Train Epoch: 158 [120000/225000 (53%)] Loss: 19052.138672\n",
      "Train Epoch: 158 [122496/225000 (54%)] Loss: 18930.808594\n",
      "Train Epoch: 158 [124992/225000 (56%)] Loss: 19290.472656\n",
      "Train Epoch: 158 [127488/225000 (57%)] Loss: 19399.414062\n",
      "Train Epoch: 158 [129984/225000 (58%)] Loss: 19020.472656\n",
      "Train Epoch: 158 [132480/225000 (59%)] Loss: 18959.470703\n",
      "Train Epoch: 158 [134976/225000 (60%)] Loss: 19363.425781\n",
      "Train Epoch: 158 [137472/225000 (61%)] Loss: 19189.753906\n",
      "Train Epoch: 158 [139968/225000 (62%)] Loss: 18942.035156\n",
      "Train Epoch: 158 [142464/225000 (63%)] Loss: 18560.785156\n",
      "Train Epoch: 158 [144960/225000 (64%)] Loss: 18888.898438\n",
      "Train Epoch: 158 [147456/225000 (66%)] Loss: 19085.146484\n",
      "Train Epoch: 158 [149952/225000 (67%)] Loss: 18980.859375\n",
      "Train Epoch: 158 [152448/225000 (68%)] Loss: 18843.962891\n",
      "Train Epoch: 158 [154944/225000 (69%)] Loss: 18816.496094\n",
      "Train Epoch: 158 [157440/225000 (70%)] Loss: 19421.478516\n",
      "Train Epoch: 158 [159936/225000 (71%)] Loss: 19250.468750\n",
      "Train Epoch: 158 [162432/225000 (72%)] Loss: 19099.269531\n",
      "Train Epoch: 158 [164928/225000 (73%)] Loss: 19235.310547\n",
      "Train Epoch: 158 [167424/225000 (74%)] Loss: 19014.431641\n",
      "Train Epoch: 158 [169920/225000 (76%)] Loss: 19186.281250\n",
      "Train Epoch: 158 [172416/225000 (77%)] Loss: 19155.656250\n",
      "Train Epoch: 158 [174912/225000 (78%)] Loss: 19357.390625\n",
      "Train Epoch: 158 [177408/225000 (79%)] Loss: 18909.650391\n",
      "Train Epoch: 158 [179904/225000 (80%)] Loss: 18764.302734\n",
      "Train Epoch: 158 [182400/225000 (81%)] Loss: 19214.722656\n",
      "Train Epoch: 158 [184896/225000 (82%)] Loss: 18907.386719\n",
      "Train Epoch: 158 [187392/225000 (83%)] Loss: 19422.402344\n",
      "Train Epoch: 158 [189888/225000 (84%)] Loss: 19622.875000\n",
      "Train Epoch: 158 [192384/225000 (86%)] Loss: 19021.375000\n",
      "Train Epoch: 158 [194880/225000 (87%)] Loss: 19272.375000\n",
      "Train Epoch: 158 [197376/225000 (88%)] Loss: 19046.824219\n",
      "Train Epoch: 158 [199872/225000 (89%)] Loss: 19004.123047\n",
      "Train Epoch: 158 [202368/225000 (90%)] Loss: 19310.218750\n",
      "Train Epoch: 158 [204864/225000 (91%)] Loss: 19304.390625\n",
      "Train Epoch: 158 [207360/225000 (92%)] Loss: 19288.750000\n",
      "Train Epoch: 158 [209856/225000 (93%)] Loss: 19064.595703\n",
      "Train Epoch: 158 [212352/225000 (94%)] Loss: 19567.980469\n",
      "Train Epoch: 158 [214848/225000 (95%)] Loss: 19306.640625\n",
      "Train Epoch: 158 [217344/225000 (97%)] Loss: 19155.289062\n",
      "Train Epoch: 158 [219840/225000 (98%)] Loss: 19004.304688\n",
      "Train Epoch: 158 [222336/225000 (99%)] Loss: 19322.923828\n",
      "Train Epoch: 158 [224832/225000 (100%)] Loss: 19016.914062\n",
      "    epoch          : 158\n",
      "    loss           : 19238.036767744772\n",
      "    val_loss       : 19145.461611398303\n",
      "Train Epoch: 159 [192/225000 (0%)] Loss: 19436.304688\n",
      "Train Epoch: 159 [2688/225000 (1%)] Loss: 19643.412109\n",
      "Train Epoch: 159 [5184/225000 (2%)] Loss: 19007.625000\n",
      "Train Epoch: 159 [7680/225000 (3%)] Loss: 19436.144531\n",
      "Train Epoch: 159 [10176/225000 (5%)] Loss: 19177.929688\n",
      "Train Epoch: 159 [12672/225000 (6%)] Loss: 19609.921875\n",
      "Train Epoch: 159 [15168/225000 (7%)] Loss: 19553.236328\n",
      "Train Epoch: 159 [17664/225000 (8%)] Loss: 19799.667969\n",
      "Train Epoch: 159 [20160/225000 (9%)] Loss: 19133.171875\n",
      "Train Epoch: 159 [22656/225000 (10%)] Loss: 19347.125000\n",
      "Train Epoch: 159 [25152/225000 (11%)] Loss: 19010.808594\n",
      "Train Epoch: 159 [27648/225000 (12%)] Loss: 19018.955078\n",
      "Train Epoch: 159 [30144/225000 (13%)] Loss: 19285.804688\n",
      "Train Epoch: 159 [32640/225000 (15%)] Loss: 19442.574219\n",
      "Train Epoch: 159 [35136/225000 (16%)] Loss: 19125.343750\n",
      "Train Epoch: 159 [37632/225000 (17%)] Loss: 19312.855469\n",
      "Train Epoch: 159 [40128/225000 (18%)] Loss: 19274.601562\n",
      "Train Epoch: 159 [42624/225000 (19%)] Loss: 19256.007812\n",
      "Train Epoch: 159 [45120/225000 (20%)] Loss: 18670.105469\n",
      "Train Epoch: 159 [47616/225000 (21%)] Loss: 19197.417969\n",
      "Train Epoch: 159 [50112/225000 (22%)] Loss: 19081.578125\n",
      "Train Epoch: 159 [52608/225000 (23%)] Loss: 19180.599609\n",
      "Train Epoch: 159 [55104/225000 (24%)] Loss: 19162.621094\n",
      "Train Epoch: 159 [57600/225000 (26%)] Loss: 19373.751953\n",
      "Train Epoch: 159 [60096/225000 (27%)] Loss: 19594.287109\n",
      "Train Epoch: 159 [62592/225000 (28%)] Loss: 19271.511719\n",
      "Train Epoch: 159 [65088/225000 (29%)] Loss: 19103.105469\n",
      "Train Epoch: 159 [67584/225000 (30%)] Loss: 19314.851562\n",
      "Train Epoch: 159 [70080/225000 (31%)] Loss: 19407.429688\n",
      "Train Epoch: 159 [72576/225000 (32%)] Loss: 19612.296875\n",
      "Train Epoch: 159 [75072/225000 (33%)] Loss: 18895.990234\n",
      "Train Epoch: 159 [77568/225000 (34%)] Loss: 19184.076172\n",
      "Train Epoch: 159 [80064/225000 (36%)] Loss: 19589.972656\n",
      "Train Epoch: 159 [82560/225000 (37%)] Loss: 19229.851562\n",
      "Train Epoch: 159 [85056/225000 (38%)] Loss: 19447.097656\n",
      "Train Epoch: 159 [87552/225000 (39%)] Loss: 19006.814453\n",
      "Train Epoch: 159 [90048/225000 (40%)] Loss: 19325.263672\n",
      "Train Epoch: 159 [92544/225000 (41%)] Loss: 19048.964844\n",
      "Train Epoch: 159 [95040/225000 (42%)] Loss: 19548.878906\n",
      "Train Epoch: 159 [97536/225000 (43%)] Loss: 19479.218750\n",
      "Train Epoch: 159 [100032/225000 (44%)] Loss: 19269.382812\n",
      "Train Epoch: 159 [102528/225000 (46%)] Loss: 19462.144531\n",
      "Train Epoch: 159 [105024/225000 (47%)] Loss: 19601.808594\n",
      "Train Epoch: 159 [107520/225000 (48%)] Loss: 18625.505859\n",
      "Train Epoch: 159 [110016/225000 (49%)] Loss: 19066.253906\n",
      "Train Epoch: 159 [112512/225000 (50%)] Loss: 19091.292969\n",
      "Train Epoch: 159 [115008/225000 (51%)] Loss: 19193.337891\n",
      "Train Epoch: 159 [117504/225000 (52%)] Loss: 19282.292969\n",
      "Train Epoch: 159 [120000/225000 (53%)] Loss: 19382.175781\n",
      "Train Epoch: 159 [122496/225000 (54%)] Loss: 19383.664062\n",
      "Train Epoch: 159 [124992/225000 (56%)] Loss: 19072.632812\n",
      "Train Epoch: 159 [127488/225000 (57%)] Loss: 19416.617188\n",
      "Train Epoch: 159 [129984/225000 (58%)] Loss: 19613.724609\n",
      "Train Epoch: 159 [132480/225000 (59%)] Loss: 19998.066406\n",
      "Train Epoch: 159 [134976/225000 (60%)] Loss: 19584.953125\n",
      "Train Epoch: 159 [137472/225000 (61%)] Loss: 19214.597656\n",
      "Train Epoch: 159 [139968/225000 (62%)] Loss: 18720.230469\n",
      "Train Epoch: 159 [142464/225000 (63%)] Loss: 33334.253906\n",
      "Train Epoch: 159 [144960/225000 (64%)] Loss: 19661.738281\n",
      "Train Epoch: 159 [147456/225000 (66%)] Loss: 19626.978516\n",
      "Train Epoch: 159 [149952/225000 (67%)] Loss: 19567.824219\n",
      "Train Epoch: 159 [152448/225000 (68%)] Loss: 18650.691406\n",
      "Train Epoch: 159 [154944/225000 (69%)] Loss: 18877.472656\n",
      "Train Epoch: 159 [157440/225000 (70%)] Loss: 19328.828125\n",
      "Train Epoch: 159 [159936/225000 (71%)] Loss: 19436.812500\n",
      "Train Epoch: 159 [162432/225000 (72%)] Loss: 19252.578125\n",
      "Train Epoch: 159 [164928/225000 (73%)] Loss: 19309.884766\n",
      "Train Epoch: 159 [167424/225000 (74%)] Loss: 18969.763672\n",
      "Train Epoch: 159 [169920/225000 (76%)] Loss: 19047.501953\n",
      "Train Epoch: 159 [172416/225000 (77%)] Loss: 19045.425781\n",
      "Train Epoch: 159 [174912/225000 (78%)] Loss: 19310.574219\n",
      "Train Epoch: 159 [177408/225000 (79%)] Loss: 19032.699219\n",
      "Train Epoch: 159 [179904/225000 (80%)] Loss: 19264.070312\n",
      "Train Epoch: 159 [182400/225000 (81%)] Loss: 19397.835938\n",
      "Train Epoch: 159 [184896/225000 (82%)] Loss: 19047.605469\n",
      "Train Epoch: 159 [187392/225000 (83%)] Loss: 19244.552734\n",
      "Train Epoch: 159 [189888/225000 (84%)] Loss: 18923.250000\n",
      "Train Epoch: 159 [192384/225000 (86%)] Loss: 19084.882812\n",
      "Train Epoch: 159 [194880/225000 (87%)] Loss: 19207.927734\n",
      "Train Epoch: 159 [197376/225000 (88%)] Loss: 19380.421875\n",
      "Train Epoch: 159 [199872/225000 (89%)] Loss: 18957.884766\n",
      "Train Epoch: 159 [202368/225000 (90%)] Loss: 19472.439453\n",
      "Train Epoch: 159 [204864/225000 (91%)] Loss: 19540.361328\n",
      "Train Epoch: 159 [207360/225000 (92%)] Loss: 19436.207031\n",
      "Train Epoch: 159 [209856/225000 (93%)] Loss: 19012.007812\n",
      "Train Epoch: 159 [212352/225000 (94%)] Loss: 19304.509766\n",
      "Train Epoch: 159 [214848/225000 (95%)] Loss: 18986.966797\n",
      "Train Epoch: 159 [217344/225000 (97%)] Loss: 19248.968750\n",
      "Train Epoch: 159 [219840/225000 (98%)] Loss: 19496.160156\n",
      "Train Epoch: 159 [222336/225000 (99%)] Loss: 19192.908203\n",
      "Train Epoch: 159 [224832/225000 (100%)] Loss: 19397.917969\n",
      "    epoch          : 159\n",
      "    loss           : 19249.42199832018\n",
      "    val_loss       : 19169.466818916888\n",
      "Train Epoch: 160 [192/225000 (0%)] Loss: 19314.054688\n",
      "Train Epoch: 160 [2688/225000 (1%)] Loss: 19280.722656\n",
      "Train Epoch: 160 [5184/225000 (2%)] Loss: 19509.742188\n",
      "Train Epoch: 160 [7680/225000 (3%)] Loss: 19411.949219\n",
      "Train Epoch: 160 [10176/225000 (5%)] Loss: 19382.988281\n",
      "Train Epoch: 160 [12672/225000 (6%)] Loss: 19413.640625\n",
      "Train Epoch: 160 [15168/225000 (7%)] Loss: 19484.437500\n",
      "Train Epoch: 160 [17664/225000 (8%)] Loss: 19255.078125\n",
      "Train Epoch: 160 [20160/225000 (9%)] Loss: 19075.640625\n",
      "Train Epoch: 160 [22656/225000 (10%)] Loss: 19352.546875\n",
      "Train Epoch: 160 [25152/225000 (11%)] Loss: 19239.246094\n",
      "Train Epoch: 160 [27648/225000 (12%)] Loss: 19467.707031\n",
      "Train Epoch: 160 [30144/225000 (13%)] Loss: 19027.816406\n",
      "Train Epoch: 160 [32640/225000 (15%)] Loss: 19266.980469\n",
      "Train Epoch: 160 [35136/225000 (16%)] Loss: 20075.732422\n",
      "Train Epoch: 160 [37632/225000 (17%)] Loss: 19019.582031\n",
      "Train Epoch: 160 [40128/225000 (18%)] Loss: 19882.798828\n",
      "Train Epoch: 160 [42624/225000 (19%)] Loss: 19691.515625\n",
      "Train Epoch: 160 [45120/225000 (20%)] Loss: 18936.570312\n",
      "Train Epoch: 160 [47616/225000 (21%)] Loss: 19215.550781\n",
      "Train Epoch: 160 [50112/225000 (22%)] Loss: 19033.220703\n",
      "Train Epoch: 160 [52608/225000 (23%)] Loss: 19497.748047\n",
      "Train Epoch: 160 [55104/225000 (24%)] Loss: 19186.714844\n",
      "Train Epoch: 160 [57600/225000 (26%)] Loss: 19231.824219\n",
      "Train Epoch: 160 [60096/225000 (27%)] Loss: 19226.109375\n",
      "Train Epoch: 160 [62592/225000 (28%)] Loss: 19231.523438\n",
      "Train Epoch: 160 [65088/225000 (29%)] Loss: 18979.710938\n",
      "Train Epoch: 160 [67584/225000 (30%)] Loss: 18989.558594\n",
      "Train Epoch: 160 [70080/225000 (31%)] Loss: 19601.847656\n",
      "Train Epoch: 160 [72576/225000 (32%)] Loss: 19668.410156\n",
      "Train Epoch: 160 [75072/225000 (33%)] Loss: 19182.160156\n",
      "Train Epoch: 160 [77568/225000 (34%)] Loss: 19401.574219\n",
      "Train Epoch: 160 [80064/225000 (36%)] Loss: 19130.664062\n",
      "Train Epoch: 160 [82560/225000 (37%)] Loss: 19033.990234\n",
      "Train Epoch: 160 [85056/225000 (38%)] Loss: 19308.285156\n",
      "Train Epoch: 160 [87552/225000 (39%)] Loss: 19370.863281\n",
      "Train Epoch: 160 [90048/225000 (40%)] Loss: 18634.916016\n",
      "Train Epoch: 160 [92544/225000 (41%)] Loss: 19295.472656\n",
      "Train Epoch: 160 [95040/225000 (42%)] Loss: 19441.425781\n",
      "Train Epoch: 160 [97536/225000 (43%)] Loss: 19235.083984\n",
      "Train Epoch: 160 [100032/225000 (44%)] Loss: 19021.085938\n",
      "Train Epoch: 160 [102528/225000 (46%)] Loss: 19122.117188\n",
      "Train Epoch: 160 [105024/225000 (47%)] Loss: 19450.208984\n",
      "Train Epoch: 160 [107520/225000 (48%)] Loss: 19458.152344\n",
      "Train Epoch: 160 [110016/225000 (49%)] Loss: 18996.632812\n",
      "Train Epoch: 160 [112512/225000 (50%)] Loss: 19186.121094\n",
      "Train Epoch: 160 [115008/225000 (51%)] Loss: 19025.425781\n",
      "Train Epoch: 160 [117504/225000 (52%)] Loss: 19349.792969\n",
      "Train Epoch: 160 [120000/225000 (53%)] Loss: 19031.746094\n",
      "Train Epoch: 160 [122496/225000 (54%)] Loss: 18619.882812\n",
      "Train Epoch: 160 [124992/225000 (56%)] Loss: 19015.636719\n",
      "Train Epoch: 160 [127488/225000 (57%)] Loss: 19571.775391\n",
      "Train Epoch: 160 [129984/225000 (58%)] Loss: 19486.218750\n",
      "Train Epoch: 160 [132480/225000 (59%)] Loss: 19223.212891\n",
      "Train Epoch: 160 [134976/225000 (60%)] Loss: 19596.261719\n",
      "Train Epoch: 160 [137472/225000 (61%)] Loss: 19281.812500\n",
      "Train Epoch: 160 [139968/225000 (62%)] Loss: 18954.546875\n",
      "Train Epoch: 160 [142464/225000 (63%)] Loss: 18853.126953\n",
      "Train Epoch: 160 [144960/225000 (64%)] Loss: 19413.722656\n",
      "Train Epoch: 160 [147456/225000 (66%)] Loss: 19359.562500\n",
      "Train Epoch: 160 [149952/225000 (67%)] Loss: 19369.355469\n",
      "Train Epoch: 160 [152448/225000 (68%)] Loss: 19117.052734\n",
      "Train Epoch: 160 [154944/225000 (69%)] Loss: 18928.417969\n",
      "Train Epoch: 160 [157440/225000 (70%)] Loss: 19071.466797\n",
      "Train Epoch: 160 [159936/225000 (71%)] Loss: 18736.613281\n",
      "Train Epoch: 160 [162432/225000 (72%)] Loss: 18982.910156\n",
      "Train Epoch: 160 [164928/225000 (73%)] Loss: 18684.375000\n",
      "Train Epoch: 160 [167424/225000 (74%)] Loss: 19177.226562\n",
      "Train Epoch: 160 [169920/225000 (76%)] Loss: 19480.859375\n",
      "Train Epoch: 160 [172416/225000 (77%)] Loss: 19512.359375\n",
      "Train Epoch: 160 [174912/225000 (78%)] Loss: 19553.777344\n",
      "Train Epoch: 160 [177408/225000 (79%)] Loss: 19152.019531\n",
      "Train Epoch: 160 [179904/225000 (80%)] Loss: 19238.972656\n",
      "Train Epoch: 160 [182400/225000 (81%)] Loss: 19628.558594\n",
      "Train Epoch: 160 [184896/225000 (82%)] Loss: 19110.347656\n",
      "Train Epoch: 160 [187392/225000 (83%)] Loss: 19343.875000\n",
      "Train Epoch: 160 [189888/225000 (84%)] Loss: 19423.457031\n",
      "Train Epoch: 160 [192384/225000 (86%)] Loss: 19779.523438\n",
      "Train Epoch: 160 [194880/225000 (87%)] Loss: 19164.691406\n",
      "Train Epoch: 160 [197376/225000 (88%)] Loss: 19084.072266\n",
      "Train Epoch: 160 [199872/225000 (89%)] Loss: 18893.230469\n",
      "Train Epoch: 160 [202368/225000 (90%)] Loss: 19060.808594\n",
      "Train Epoch: 160 [204864/225000 (91%)] Loss: 19316.484375\n",
      "Train Epoch: 160 [207360/225000 (92%)] Loss: 18965.761719\n",
      "Train Epoch: 160 [209856/225000 (93%)] Loss: 18962.447266\n",
      "Train Epoch: 160 [212352/225000 (94%)] Loss: 19066.867188\n",
      "Train Epoch: 160 [214848/225000 (95%)] Loss: 19168.957031\n",
      "Train Epoch: 160 [217344/225000 (97%)] Loss: 18889.996094\n",
      "Train Epoch: 160 [219840/225000 (98%)] Loss: 19142.519531\n",
      "Train Epoch: 160 [222336/225000 (99%)] Loss: 18956.125000\n",
      "Train Epoch: 160 [224832/225000 (100%)] Loss: 19624.738281\n",
      "    epoch          : 160\n",
      "    loss           : 19232.30508579085\n",
      "    val_loss       : 19135.704215007885\n",
      "Train Epoch: 161 [192/225000 (0%)] Loss: 18874.404297\n",
      "Train Epoch: 161 [2688/225000 (1%)] Loss: 18797.046875\n",
      "Train Epoch: 161 [5184/225000 (2%)] Loss: 18795.509766\n",
      "Train Epoch: 161 [7680/225000 (3%)] Loss: 19175.117188\n",
      "Train Epoch: 161 [10176/225000 (5%)] Loss: 18777.855469\n",
      "Train Epoch: 161 [12672/225000 (6%)] Loss: 19150.416016\n",
      "Train Epoch: 161 [15168/225000 (7%)] Loss: 19287.652344\n",
      "Train Epoch: 161 [17664/225000 (8%)] Loss: 19397.671875\n",
      "Train Epoch: 161 [20160/225000 (9%)] Loss: 19180.466797\n",
      "Train Epoch: 161 [22656/225000 (10%)] Loss: 18874.544922\n",
      "Train Epoch: 161 [25152/225000 (11%)] Loss: 19002.824219\n",
      "Train Epoch: 161 [27648/225000 (12%)] Loss: 19752.960938\n",
      "Train Epoch: 161 [30144/225000 (13%)] Loss: 18812.835938\n",
      "Train Epoch: 161 [32640/225000 (15%)] Loss: 19025.576172\n",
      "Train Epoch: 161 [35136/225000 (16%)] Loss: 19219.785156\n",
      "Train Epoch: 161 [37632/225000 (17%)] Loss: 19965.275391\n",
      "Train Epoch: 161 [40128/225000 (18%)] Loss: 19627.429688\n",
      "Train Epoch: 161 [42624/225000 (19%)] Loss: 19454.546875\n",
      "Train Epoch: 161 [45120/225000 (20%)] Loss: 19470.558594\n",
      "Train Epoch: 161 [47616/225000 (21%)] Loss: 19429.027344\n",
      "Train Epoch: 161 [50112/225000 (22%)] Loss: 19749.425781\n",
      "Train Epoch: 161 [52608/225000 (23%)] Loss: 18697.058594\n",
      "Train Epoch: 161 [55104/225000 (24%)] Loss: 19266.132812\n",
      "Train Epoch: 161 [57600/225000 (26%)] Loss: 19500.191406\n",
      "Train Epoch: 161 [60096/225000 (27%)] Loss: 19016.082031\n",
      "Train Epoch: 161 [62592/225000 (28%)] Loss: 19530.742188\n",
      "Train Epoch: 161 [65088/225000 (29%)] Loss: 18459.187500\n",
      "Train Epoch: 161 [67584/225000 (30%)] Loss: 19391.960938\n",
      "Train Epoch: 161 [70080/225000 (31%)] Loss: 18634.375000\n",
      "Train Epoch: 161 [72576/225000 (32%)] Loss: 19242.820312\n",
      "Train Epoch: 161 [75072/225000 (33%)] Loss: 19211.009766\n",
      "Train Epoch: 161 [77568/225000 (34%)] Loss: 19276.808594\n",
      "Train Epoch: 161 [80064/225000 (36%)] Loss: 18940.259766\n",
      "Train Epoch: 161 [82560/225000 (37%)] Loss: 19261.433594\n",
      "Train Epoch: 161 [85056/225000 (38%)] Loss: 19329.111328\n",
      "Train Epoch: 161 [87552/225000 (39%)] Loss: 19323.044922\n",
      "Train Epoch: 161 [90048/225000 (40%)] Loss: 18923.765625\n",
      "Train Epoch: 161 [92544/225000 (41%)] Loss: 19096.890625\n",
      "Train Epoch: 161 [95040/225000 (42%)] Loss: 19057.613281\n",
      "Train Epoch: 161 [97536/225000 (43%)] Loss: 19181.390625\n",
      "Train Epoch: 161 [100032/225000 (44%)] Loss: 19360.882812\n",
      "Train Epoch: 161 [102528/225000 (46%)] Loss: 18993.177734\n",
      "Train Epoch: 161 [105024/225000 (47%)] Loss: 18840.035156\n",
      "Train Epoch: 161 [107520/225000 (48%)] Loss: 19567.818359\n",
      "Train Epoch: 161 [110016/225000 (49%)] Loss: 19047.050781\n",
      "Train Epoch: 161 [112512/225000 (50%)] Loss: 19235.832031\n",
      "Train Epoch: 161 [115008/225000 (51%)] Loss: 19757.496094\n",
      "Train Epoch: 161 [117504/225000 (52%)] Loss: 19529.441406\n",
      "Train Epoch: 161 [120000/225000 (53%)] Loss: 19104.611328\n",
      "Train Epoch: 161 [122496/225000 (54%)] Loss: 19383.460938\n",
      "Train Epoch: 161 [124992/225000 (56%)] Loss: 19559.878906\n",
      "Train Epoch: 161 [127488/225000 (57%)] Loss: 19160.132812\n",
      "Train Epoch: 161 [129984/225000 (58%)] Loss: 19059.966797\n",
      "Train Epoch: 161 [132480/225000 (59%)] Loss: 19202.144531\n",
      "Train Epoch: 161 [134976/225000 (60%)] Loss: 19512.150391\n",
      "Train Epoch: 161 [137472/225000 (61%)] Loss: 19513.039062\n",
      "Train Epoch: 161 [139968/225000 (62%)] Loss: 19201.376953\n",
      "Train Epoch: 161 [142464/225000 (63%)] Loss: 19165.945312\n",
      "Train Epoch: 161 [144960/225000 (64%)] Loss: 19080.816406\n",
      "Train Epoch: 161 [147456/225000 (66%)] Loss: 19047.992188\n",
      "Train Epoch: 161 [149952/225000 (67%)] Loss: 19436.634766\n",
      "Train Epoch: 161 [152448/225000 (68%)] Loss: 18787.056641\n",
      "Train Epoch: 161 [154944/225000 (69%)] Loss: 19204.054688\n",
      "Train Epoch: 161 [157440/225000 (70%)] Loss: 19262.847656\n",
      "Train Epoch: 161 [159936/225000 (71%)] Loss: 18936.519531\n",
      "Train Epoch: 161 [162432/225000 (72%)] Loss: 19747.171875\n",
      "Train Epoch: 161 [164928/225000 (73%)] Loss: 19087.960938\n",
      "Train Epoch: 161 [167424/225000 (74%)] Loss: 19266.167969\n",
      "Train Epoch: 161 [169920/225000 (76%)] Loss: 18862.757812\n",
      "Train Epoch: 161 [172416/225000 (77%)] Loss: 19400.296875\n",
      "Train Epoch: 161 [174912/225000 (78%)] Loss: 19051.632812\n",
      "Train Epoch: 161 [177408/225000 (79%)] Loss: 19329.242188\n",
      "Train Epoch: 161 [179904/225000 (80%)] Loss: 18865.216797\n",
      "Train Epoch: 161 [182400/225000 (81%)] Loss: 19324.035156\n",
      "Train Epoch: 161 [184896/225000 (82%)] Loss: 19372.025391\n",
      "Train Epoch: 161 [187392/225000 (83%)] Loss: 19242.398438\n",
      "Train Epoch: 161 [189888/225000 (84%)] Loss: 18982.224609\n",
      "Train Epoch: 161 [192384/225000 (86%)] Loss: 19137.886719\n",
      "Train Epoch: 161 [194880/225000 (87%)] Loss: 18757.882812\n",
      "Train Epoch: 161 [197376/225000 (88%)] Loss: 19488.882812\n",
      "Train Epoch: 161 [199872/225000 (89%)] Loss: 19369.677734\n",
      "Train Epoch: 161 [202368/225000 (90%)] Loss: 19312.058594\n",
      "Train Epoch: 161 [204864/225000 (91%)] Loss: 18674.244141\n",
      "Train Epoch: 161 [207360/225000 (92%)] Loss: 19170.689453\n",
      "Train Epoch: 161 [209856/225000 (93%)] Loss: 19845.652344\n",
      "Train Epoch: 161 [212352/225000 (94%)] Loss: 19467.816406\n",
      "Train Epoch: 161 [214848/225000 (95%)] Loss: 19377.501953\n",
      "Train Epoch: 161 [217344/225000 (97%)] Loss: 19514.398438\n",
      "Train Epoch: 161 [219840/225000 (98%)] Loss: 19615.669922\n",
      "Train Epoch: 161 [222336/225000 (99%)] Loss: 18936.363281\n",
      "Train Epoch: 161 [224832/225000 (100%)] Loss: 19216.376953\n",
      "    epoch          : 161\n",
      "    loss           : 19231.211529103562\n",
      "    val_loss       : 19143.925486712964\n",
      "Train Epoch: 162 [192/225000 (0%)] Loss: 19250.167969\n",
      "Train Epoch: 162 [2688/225000 (1%)] Loss: 19271.023438\n",
      "Train Epoch: 162 [5184/225000 (2%)] Loss: 19431.460938\n",
      "Train Epoch: 162 [7680/225000 (3%)] Loss: 19125.207031\n",
      "Train Epoch: 162 [10176/225000 (5%)] Loss: 19415.707031\n",
      "Train Epoch: 162 [12672/225000 (6%)] Loss: 18841.253906\n",
      "Train Epoch: 162 [15168/225000 (7%)] Loss: 19525.835938\n",
      "Train Epoch: 162 [17664/225000 (8%)] Loss: 19128.519531\n",
      "Train Epoch: 162 [20160/225000 (9%)] Loss: 19359.603516\n",
      "Train Epoch: 162 [22656/225000 (10%)] Loss: 18926.250000\n",
      "Train Epoch: 162 [25152/225000 (11%)] Loss: 18614.019531\n",
      "Train Epoch: 162 [27648/225000 (12%)] Loss: 19302.796875\n",
      "Train Epoch: 162 [30144/225000 (13%)] Loss: 19736.636719\n",
      "Train Epoch: 162 [32640/225000 (15%)] Loss: 19619.820312\n",
      "Train Epoch: 162 [35136/225000 (16%)] Loss: 19228.677734\n",
      "Train Epoch: 162 [37632/225000 (17%)] Loss: 19004.425781\n",
      "Train Epoch: 162 [40128/225000 (18%)] Loss: 19245.441406\n",
      "Train Epoch: 162 [42624/225000 (19%)] Loss: 18778.882812\n",
      "Train Epoch: 162 [45120/225000 (20%)] Loss: 19656.945312\n",
      "Train Epoch: 162 [47616/225000 (21%)] Loss: 19313.736328\n",
      "Train Epoch: 162 [50112/225000 (22%)] Loss: 24130.271484\n",
      "Train Epoch: 162 [52608/225000 (23%)] Loss: 19072.281250\n",
      "Train Epoch: 162 [55104/225000 (24%)] Loss: 19276.277344\n",
      "Train Epoch: 162 [57600/225000 (26%)] Loss: 19495.257812\n",
      "Train Epoch: 162 [60096/225000 (27%)] Loss: 18823.128906\n",
      "Train Epoch: 162 [62592/225000 (28%)] Loss: 18996.107422\n",
      "Train Epoch: 162 [65088/225000 (29%)] Loss: 18833.890625\n",
      "Train Epoch: 162 [67584/225000 (30%)] Loss: 18908.003906\n",
      "Train Epoch: 162 [70080/225000 (31%)] Loss: 19321.203125\n",
      "Train Epoch: 162 [72576/225000 (32%)] Loss: 19189.292969\n",
      "Train Epoch: 162 [75072/225000 (33%)] Loss: 19253.917969\n",
      "Train Epoch: 162 [77568/225000 (34%)] Loss: 19098.134766\n",
      "Train Epoch: 162 [80064/225000 (36%)] Loss: 19594.738281\n",
      "Train Epoch: 162 [82560/225000 (37%)] Loss: 19823.867188\n",
      "Train Epoch: 162 [85056/225000 (38%)] Loss: 19677.951172\n",
      "Train Epoch: 162 [87552/225000 (39%)] Loss: 19400.882812\n",
      "Train Epoch: 162 [90048/225000 (40%)] Loss: 18668.289062\n",
      "Train Epoch: 162 [92544/225000 (41%)] Loss: 19387.808594\n",
      "Train Epoch: 162 [95040/225000 (42%)] Loss: 19495.722656\n",
      "Train Epoch: 162 [97536/225000 (43%)] Loss: 19241.234375\n",
      "Train Epoch: 162 [100032/225000 (44%)] Loss: 19014.150391\n",
      "Train Epoch: 162 [102528/225000 (46%)] Loss: 19047.550781\n",
      "Train Epoch: 162 [105024/225000 (47%)] Loss: 18696.361328\n",
      "Train Epoch: 162 [107520/225000 (48%)] Loss: 19088.787109\n",
      "Train Epoch: 162 [110016/225000 (49%)] Loss: 19723.777344\n",
      "Train Epoch: 162 [112512/225000 (50%)] Loss: 19141.511719\n",
      "Train Epoch: 162 [115008/225000 (51%)] Loss: 18753.625000\n",
      "Train Epoch: 162 [117504/225000 (52%)] Loss: 19145.359375\n",
      "Train Epoch: 162 [120000/225000 (53%)] Loss: 19235.351562\n",
      "Train Epoch: 162 [122496/225000 (54%)] Loss: 18936.246094\n",
      "Train Epoch: 162 [124992/225000 (56%)] Loss: 18902.382812\n",
      "Train Epoch: 162 [127488/225000 (57%)] Loss: 19537.847656\n",
      "Train Epoch: 162 [129984/225000 (58%)] Loss: 18960.531250\n",
      "Train Epoch: 162 [132480/225000 (59%)] Loss: 19407.707031\n",
      "Train Epoch: 162 [134976/225000 (60%)] Loss: 19092.781250\n",
      "Train Epoch: 162 [137472/225000 (61%)] Loss: 18954.681641\n",
      "Train Epoch: 162 [139968/225000 (62%)] Loss: 19309.117188\n",
      "Train Epoch: 162 [142464/225000 (63%)] Loss: 19631.125000\n",
      "Train Epoch: 162 [144960/225000 (64%)] Loss: 19995.847656\n",
      "Train Epoch: 162 [147456/225000 (66%)] Loss: 19225.941406\n",
      "Train Epoch: 162 [149952/225000 (67%)] Loss: 18808.523438\n",
      "Train Epoch: 162 [152448/225000 (68%)] Loss: 19378.363281\n",
      "Train Epoch: 162 [154944/225000 (69%)] Loss: 19669.115234\n",
      "Train Epoch: 162 [157440/225000 (70%)] Loss: 19369.439453\n",
      "Train Epoch: 162 [159936/225000 (71%)] Loss: 19894.472656\n",
      "Train Epoch: 162 [162432/225000 (72%)] Loss: 19235.128906\n",
      "Train Epoch: 162 [164928/225000 (73%)] Loss: 19144.173828\n",
      "Train Epoch: 162 [167424/225000 (74%)] Loss: 18866.640625\n",
      "Train Epoch: 162 [169920/225000 (76%)] Loss: 18802.099609\n",
      "Train Epoch: 162 [172416/225000 (77%)] Loss: 19355.992188\n",
      "Train Epoch: 162 [174912/225000 (78%)] Loss: 18705.207031\n",
      "Train Epoch: 162 [177408/225000 (79%)] Loss: 19099.062500\n",
      "Train Epoch: 162 [179904/225000 (80%)] Loss: 19217.214844\n",
      "Train Epoch: 162 [182400/225000 (81%)] Loss: 19235.500000\n",
      "Train Epoch: 162 [184896/225000 (82%)] Loss: 19326.843750\n",
      "Train Epoch: 162 [187392/225000 (83%)] Loss: 18652.335938\n",
      "Train Epoch: 162 [189888/225000 (84%)] Loss: 19688.994141\n",
      "Train Epoch: 162 [192384/225000 (86%)] Loss: 19020.693359\n",
      "Train Epoch: 162 [194880/225000 (87%)] Loss: 19431.994141\n",
      "Train Epoch: 162 [197376/225000 (88%)] Loss: 19429.550781\n",
      "Train Epoch: 162 [199872/225000 (89%)] Loss: 19170.273438\n",
      "Train Epoch: 162 [202368/225000 (90%)] Loss: 19115.218750\n",
      "Train Epoch: 162 [204864/225000 (91%)] Loss: 18526.707031\n",
      "Train Epoch: 162 [207360/225000 (92%)] Loss: 19217.722656\n",
      "Train Epoch: 162 [209856/225000 (93%)] Loss: 19091.404297\n",
      "Train Epoch: 162 [212352/225000 (94%)] Loss: 19334.714844\n",
      "Train Epoch: 162 [214848/225000 (95%)] Loss: 19567.585938\n",
      "Train Epoch: 162 [217344/225000 (97%)] Loss: 19500.101562\n",
      "Train Epoch: 162 [219840/225000 (98%)] Loss: 19350.410156\n",
      "Train Epoch: 162 [222336/225000 (99%)] Loss: 19385.421875\n",
      "Train Epoch: 162 [224832/225000 (100%)] Loss: 19591.503906\n",
      "    epoch          : 162\n",
      "    loss           : 19234.584844283276\n",
      "    val_loss       : 19144.71322278212\n",
      "Train Epoch: 163 [192/225000 (0%)] Loss: 19285.539062\n",
      "Train Epoch: 163 [2688/225000 (1%)] Loss: 19249.175781\n",
      "Train Epoch: 163 [5184/225000 (2%)] Loss: 19439.269531\n",
      "Train Epoch: 163 [7680/225000 (3%)] Loss: 18802.699219\n",
      "Train Epoch: 163 [10176/225000 (5%)] Loss: 18749.628906\n",
      "Train Epoch: 163 [12672/225000 (6%)] Loss: 19286.990234\n",
      "Train Epoch: 163 [15168/225000 (7%)] Loss: 19295.539062\n",
      "Train Epoch: 163 [17664/225000 (8%)] Loss: 19634.154297\n",
      "Train Epoch: 163 [20160/225000 (9%)] Loss: 19440.478516\n",
      "Train Epoch: 163 [22656/225000 (10%)] Loss: 19075.607422\n",
      "Train Epoch: 163 [25152/225000 (11%)] Loss: 19757.261719\n",
      "Train Epoch: 163 [27648/225000 (12%)] Loss: 19136.261719\n",
      "Train Epoch: 163 [30144/225000 (13%)] Loss: 18787.177734\n",
      "Train Epoch: 163 [32640/225000 (15%)] Loss: 18604.921875\n",
      "Train Epoch: 163 [35136/225000 (16%)] Loss: 18797.476562\n",
      "Train Epoch: 163 [37632/225000 (17%)] Loss: 19422.496094\n",
      "Train Epoch: 163 [40128/225000 (18%)] Loss: 19528.718750\n",
      "Train Epoch: 163 [42624/225000 (19%)] Loss: 18970.804688\n",
      "Train Epoch: 163 [45120/225000 (20%)] Loss: 18879.298828\n",
      "Train Epoch: 163 [47616/225000 (21%)] Loss: 19215.468750\n",
      "Train Epoch: 163 [50112/225000 (22%)] Loss: 19067.121094\n",
      "Train Epoch: 163 [52608/225000 (23%)] Loss: 19384.914062\n",
      "Train Epoch: 163 [55104/225000 (24%)] Loss: 19359.154297\n",
      "Train Epoch: 163 [57600/225000 (26%)] Loss: 19549.679688\n",
      "Train Epoch: 163 [60096/225000 (27%)] Loss: 19224.132812\n",
      "Train Epoch: 163 [62592/225000 (28%)] Loss: 19025.769531\n",
      "Train Epoch: 163 [65088/225000 (29%)] Loss: 19028.234375\n",
      "Train Epoch: 163 [67584/225000 (30%)] Loss: 19220.851562\n",
      "Train Epoch: 163 [70080/225000 (31%)] Loss: 19055.132812\n",
      "Train Epoch: 163 [72576/225000 (32%)] Loss: 19281.232422\n",
      "Train Epoch: 163 [75072/225000 (33%)] Loss: 19018.414062\n",
      "Train Epoch: 163 [77568/225000 (34%)] Loss: 19145.398438\n",
      "Train Epoch: 163 [80064/225000 (36%)] Loss: 19714.722656\n",
      "Train Epoch: 163 [82560/225000 (37%)] Loss: 19589.390625\n",
      "Train Epoch: 163 [85056/225000 (38%)] Loss: 19239.513672\n",
      "Train Epoch: 163 [87552/225000 (39%)] Loss: 19442.097656\n",
      "Train Epoch: 163 [90048/225000 (40%)] Loss: 19085.144531\n",
      "Train Epoch: 163 [92544/225000 (41%)] Loss: 19453.921875\n",
      "Train Epoch: 163 [95040/225000 (42%)] Loss: 19064.136719\n",
      "Train Epoch: 163 [97536/225000 (43%)] Loss: 19405.400391\n",
      "Train Epoch: 163 [100032/225000 (44%)] Loss: 19120.656250\n",
      "Train Epoch: 163 [102528/225000 (46%)] Loss: 19252.343750\n",
      "Train Epoch: 163 [105024/225000 (47%)] Loss: 19105.222656\n",
      "Train Epoch: 163 [107520/225000 (48%)] Loss: 19068.951172\n",
      "Train Epoch: 163 [110016/225000 (49%)] Loss: 19200.828125\n",
      "Train Epoch: 163 [112512/225000 (50%)] Loss: 19102.285156\n",
      "Train Epoch: 163 [115008/225000 (51%)] Loss: 19487.734375\n",
      "Train Epoch: 163 [117504/225000 (52%)] Loss: 18841.486328\n",
      "Train Epoch: 163 [120000/225000 (53%)] Loss: 18894.945312\n",
      "Train Epoch: 163 [122496/225000 (54%)] Loss: 19196.285156\n",
      "Train Epoch: 163 [124992/225000 (56%)] Loss: 19395.634766\n",
      "Train Epoch: 163 [127488/225000 (57%)] Loss: 19326.208984\n",
      "Train Epoch: 163 [129984/225000 (58%)] Loss: 19277.378906\n",
      "Train Epoch: 163 [132480/225000 (59%)] Loss: 19374.287109\n",
      "Train Epoch: 163 [134976/225000 (60%)] Loss: 19492.800781\n",
      "Train Epoch: 163 [137472/225000 (61%)] Loss: 18697.568359\n",
      "Train Epoch: 163 [139968/225000 (62%)] Loss: 19391.062500\n",
      "Train Epoch: 163 [142464/225000 (63%)] Loss: 18754.007812\n",
      "Train Epoch: 163 [144960/225000 (64%)] Loss: 19221.388672\n",
      "Train Epoch: 163 [147456/225000 (66%)] Loss: 18847.169922\n",
      "Train Epoch: 163 [149952/225000 (67%)] Loss: 19701.707031\n",
      "Train Epoch: 163 [152448/225000 (68%)] Loss: 18544.523438\n",
      "Train Epoch: 163 [154944/225000 (69%)] Loss: 19713.480469\n",
      "Train Epoch: 163 [157440/225000 (70%)] Loss: 19147.023438\n",
      "Train Epoch: 163 [159936/225000 (71%)] Loss: 18963.685547\n",
      "Train Epoch: 163 [162432/225000 (72%)] Loss: 19477.000000\n",
      "Train Epoch: 163 [164928/225000 (73%)] Loss: 18958.855469\n",
      "Train Epoch: 163 [167424/225000 (74%)] Loss: 19166.007812\n",
      "Train Epoch: 163 [169920/225000 (76%)] Loss: 18935.835938\n",
      "Train Epoch: 163 [172416/225000 (77%)] Loss: 19013.011719\n",
      "Train Epoch: 163 [174912/225000 (78%)] Loss: 19453.988281\n",
      "Train Epoch: 163 [177408/225000 (79%)] Loss: 19331.593750\n",
      "Train Epoch: 163 [179904/225000 (80%)] Loss: 19261.910156\n",
      "Train Epoch: 163 [182400/225000 (81%)] Loss: 19464.234375\n",
      "Train Epoch: 163 [184896/225000 (82%)] Loss: 19271.849609\n",
      "Train Epoch: 163 [187392/225000 (83%)] Loss: 19090.511719\n",
      "Train Epoch: 163 [189888/225000 (84%)] Loss: 18973.195312\n",
      "Train Epoch: 163 [192384/225000 (86%)] Loss: 19971.267578\n",
      "Train Epoch: 163 [194880/225000 (87%)] Loss: 19142.181641\n",
      "Train Epoch: 163 [197376/225000 (88%)] Loss: 19131.304688\n",
      "Train Epoch: 163 [199872/225000 (89%)] Loss: 19480.039062\n",
      "Train Epoch: 163 [202368/225000 (90%)] Loss: 19583.488281\n",
      "Train Epoch: 163 [204864/225000 (91%)] Loss: 19305.476562\n",
      "Train Epoch: 163 [207360/225000 (92%)] Loss: 19542.634766\n",
      "Train Epoch: 163 [209856/225000 (93%)] Loss: 18960.171875\n",
      "Train Epoch: 163 [212352/225000 (94%)] Loss: 18995.835938\n",
      "Train Epoch: 163 [214848/225000 (95%)] Loss: 19696.621094\n",
      "Train Epoch: 163 [217344/225000 (97%)] Loss: 19291.742188\n",
      "Train Epoch: 163 [219840/225000 (98%)] Loss: 18892.224609\n",
      "Train Epoch: 163 [222336/225000 (99%)] Loss: 18750.357422\n",
      "Train Epoch: 163 [224832/225000 (100%)] Loss: 19257.949219\n",
      "    epoch          : 163\n",
      "    loss           : 19218.27050614601\n",
      "    val_loss       : 19145.254064569035\n",
      "Train Epoch: 164 [192/225000 (0%)] Loss: 18900.542969\n",
      "Train Epoch: 164 [2688/225000 (1%)] Loss: 19730.628906\n",
      "Train Epoch: 164 [5184/225000 (2%)] Loss: 19429.023438\n",
      "Train Epoch: 164 [7680/225000 (3%)] Loss: 19251.521484\n",
      "Train Epoch: 164 [10176/225000 (5%)] Loss: 19060.738281\n",
      "Train Epoch: 164 [12672/225000 (6%)] Loss: 18974.179688\n",
      "Train Epoch: 164 [15168/225000 (7%)] Loss: 19382.777344\n",
      "Train Epoch: 164 [17664/225000 (8%)] Loss: 19149.515625\n",
      "Train Epoch: 164 [20160/225000 (9%)] Loss: 19276.210938\n",
      "Train Epoch: 164 [22656/225000 (10%)] Loss: 19467.625000\n",
      "Train Epoch: 164 [25152/225000 (11%)] Loss: 18858.726562\n",
      "Train Epoch: 164 [27648/225000 (12%)] Loss: 19974.980469\n",
      "Train Epoch: 164 [30144/225000 (13%)] Loss: 19374.734375\n",
      "Train Epoch: 164 [32640/225000 (15%)] Loss: 19051.007812\n",
      "Train Epoch: 164 [35136/225000 (16%)] Loss: 19029.939453\n",
      "Train Epoch: 164 [37632/225000 (17%)] Loss: 19638.826172\n",
      "Train Epoch: 164 [40128/225000 (18%)] Loss: 19750.156250\n",
      "Train Epoch: 164 [42624/225000 (19%)] Loss: 18909.800781\n",
      "Train Epoch: 164 [45120/225000 (20%)] Loss: 19521.162109\n",
      "Train Epoch: 164 [47616/225000 (21%)] Loss: 18983.562500\n",
      "Train Epoch: 164 [50112/225000 (22%)] Loss: 19590.699219\n",
      "Train Epoch: 164 [52608/225000 (23%)] Loss: 19025.257812\n",
      "Train Epoch: 164 [55104/225000 (24%)] Loss: 18894.408203\n",
      "Train Epoch: 164 [57600/225000 (26%)] Loss: 19239.771484\n",
      "Train Epoch: 164 [60096/225000 (27%)] Loss: 19515.455078\n",
      "Train Epoch: 164 [62592/225000 (28%)] Loss: 19341.443359\n",
      "Train Epoch: 164 [65088/225000 (29%)] Loss: 19010.910156\n",
      "Train Epoch: 164 [67584/225000 (30%)] Loss: 19078.964844\n",
      "Train Epoch: 164 [70080/225000 (31%)] Loss: 19624.109375\n",
      "Train Epoch: 164 [72576/225000 (32%)] Loss: 19440.775391\n",
      "Train Epoch: 164 [75072/225000 (33%)] Loss: 19104.080078\n",
      "Train Epoch: 164 [77568/225000 (34%)] Loss: 19550.671875\n",
      "Train Epoch: 164 [80064/225000 (36%)] Loss: 19577.833984\n",
      "Train Epoch: 164 [82560/225000 (37%)] Loss: 18697.472656\n",
      "Train Epoch: 164 [85056/225000 (38%)] Loss: 18856.150391\n",
      "Train Epoch: 164 [87552/225000 (39%)] Loss: 19139.621094\n",
      "Train Epoch: 164 [90048/225000 (40%)] Loss: 19161.152344\n",
      "Train Epoch: 164 [92544/225000 (41%)] Loss: 19100.003906\n",
      "Train Epoch: 164 [95040/225000 (42%)] Loss: 19322.173828\n",
      "Train Epoch: 164 [97536/225000 (43%)] Loss: 19840.605469\n",
      "Train Epoch: 164 [100032/225000 (44%)] Loss: 18935.257812\n",
      "Train Epoch: 164 [102528/225000 (46%)] Loss: 19571.863281\n",
      "Train Epoch: 164 [105024/225000 (47%)] Loss: 18428.730469\n",
      "Train Epoch: 164 [107520/225000 (48%)] Loss: 19265.189453\n",
      "Train Epoch: 164 [110016/225000 (49%)] Loss: 19774.912109\n",
      "Train Epoch: 164 [112512/225000 (50%)] Loss: 19756.521484\n",
      "Train Epoch: 164 [115008/225000 (51%)] Loss: 19177.812500\n",
      "Train Epoch: 164 [117504/225000 (52%)] Loss: 19021.835938\n",
      "Train Epoch: 164 [120000/225000 (53%)] Loss: 19045.384766\n",
      "Train Epoch: 164 [122496/225000 (54%)] Loss: 19486.328125\n",
      "Train Epoch: 164 [124992/225000 (56%)] Loss: 19109.742188\n",
      "Train Epoch: 164 [127488/225000 (57%)] Loss: 19040.121094\n",
      "Train Epoch: 164 [129984/225000 (58%)] Loss: 19321.835938\n",
      "Train Epoch: 164 [132480/225000 (59%)] Loss: 19472.023438\n",
      "Train Epoch: 164 [134976/225000 (60%)] Loss: 19256.462891\n",
      "Train Epoch: 164 [137472/225000 (61%)] Loss: 19104.531250\n",
      "Train Epoch: 164 [139968/225000 (62%)] Loss: 19499.121094\n",
      "Train Epoch: 164 [142464/225000 (63%)] Loss: 19308.589844\n",
      "Train Epoch: 164 [144960/225000 (64%)] Loss: 19173.861328\n",
      "Train Epoch: 164 [147456/225000 (66%)] Loss: 19392.169922\n",
      "Train Epoch: 164 [149952/225000 (67%)] Loss: 18884.617188\n",
      "Train Epoch: 164 [152448/225000 (68%)] Loss: 19287.367188\n",
      "Train Epoch: 164 [154944/225000 (69%)] Loss: 18854.453125\n",
      "Train Epoch: 164 [157440/225000 (70%)] Loss: 19451.894531\n",
      "Train Epoch: 164 [159936/225000 (71%)] Loss: 18798.222656\n",
      "Train Epoch: 164 [162432/225000 (72%)] Loss: 18938.048828\n",
      "Train Epoch: 164 [164928/225000 (73%)] Loss: 18878.982422\n",
      "Train Epoch: 164 [167424/225000 (74%)] Loss: 19016.546875\n",
      "Train Epoch: 164 [169920/225000 (76%)] Loss: 19250.781250\n",
      "Train Epoch: 164 [172416/225000 (77%)] Loss: 19211.726562\n",
      "Train Epoch: 164 [174912/225000 (78%)] Loss: 19482.859375\n",
      "Train Epoch: 164 [177408/225000 (79%)] Loss: 19031.164062\n",
      "Train Epoch: 164 [179904/225000 (80%)] Loss: 18889.175781\n",
      "Train Epoch: 164 [182400/225000 (81%)] Loss: 19060.269531\n",
      "Train Epoch: 164 [184896/225000 (82%)] Loss: 19187.591797\n",
      "Train Epoch: 164 [187392/225000 (83%)] Loss: 19374.767578\n",
      "Train Epoch: 164 [189888/225000 (84%)] Loss: 19240.498047\n",
      "Train Epoch: 164 [192384/225000 (86%)] Loss: 19106.335938\n",
      "Train Epoch: 164 [194880/225000 (87%)] Loss: 18852.746094\n",
      "Train Epoch: 164 [197376/225000 (88%)] Loss: 19118.289062\n",
      "Train Epoch: 164 [199872/225000 (89%)] Loss: 19013.802734\n",
      "Train Epoch: 164 [202368/225000 (90%)] Loss: 18642.921875\n",
      "Train Epoch: 164 [204864/225000 (91%)] Loss: 18938.382812\n",
      "Train Epoch: 164 [207360/225000 (92%)] Loss: 19511.015625\n",
      "Train Epoch: 164 [209856/225000 (93%)] Loss: 19187.144531\n",
      "Train Epoch: 164 [212352/225000 (94%)] Loss: 19675.273438\n",
      "Train Epoch: 164 [214848/225000 (95%)] Loss: 18833.972656\n",
      "Train Epoch: 164 [217344/225000 (97%)] Loss: 19386.089844\n",
      "Train Epoch: 164 [219840/225000 (98%)] Loss: 18868.417969\n",
      "Train Epoch: 164 [222336/225000 (99%)] Loss: 19418.003906\n",
      "Train Epoch: 164 [224832/225000 (100%)] Loss: 18988.365234\n",
      "    epoch          : 164\n",
      "    loss           : 19218.852227429074\n",
      "    val_loss       : 19119.953449405788\n",
      "Train Epoch: 165 [192/225000 (0%)] Loss: 19534.636719\n",
      "Train Epoch: 165 [2688/225000 (1%)] Loss: 19771.634766\n",
      "Train Epoch: 165 [5184/225000 (2%)] Loss: 19368.451172\n",
      "Train Epoch: 165 [7680/225000 (3%)] Loss: 19684.101562\n",
      "Train Epoch: 165 [10176/225000 (5%)] Loss: 18628.951172\n",
      "Train Epoch: 165 [12672/225000 (6%)] Loss: 19293.160156\n",
      "Train Epoch: 165 [15168/225000 (7%)] Loss: 19345.994141\n",
      "Train Epoch: 165 [17664/225000 (8%)] Loss: 19321.105469\n",
      "Train Epoch: 165 [20160/225000 (9%)] Loss: 19258.621094\n",
      "Train Epoch: 165 [22656/225000 (10%)] Loss: 19215.728516\n",
      "Train Epoch: 165 [25152/225000 (11%)] Loss: 19227.412109\n",
      "Train Epoch: 165 [27648/225000 (12%)] Loss: 18634.191406\n",
      "Train Epoch: 165 [30144/225000 (13%)] Loss: 19246.531250\n",
      "Train Epoch: 165 [32640/225000 (15%)] Loss: 19268.378906\n",
      "Train Epoch: 165 [35136/225000 (16%)] Loss: 19829.966797\n",
      "Train Epoch: 165 [37632/225000 (17%)] Loss: 19047.664062\n",
      "Train Epoch: 165 [40128/225000 (18%)] Loss: 18969.527344\n",
      "Train Epoch: 165 [42624/225000 (19%)] Loss: 19600.992188\n",
      "Train Epoch: 165 [45120/225000 (20%)] Loss: 19505.951172\n",
      "Train Epoch: 165 [47616/225000 (21%)] Loss: 19393.863281\n",
      "Train Epoch: 165 [50112/225000 (22%)] Loss: 19205.535156\n",
      "Train Epoch: 165 [52608/225000 (23%)] Loss: 19438.187500\n",
      "Train Epoch: 165 [55104/225000 (24%)] Loss: 19040.046875\n",
      "Train Epoch: 165 [57600/225000 (26%)] Loss: 18990.156250\n",
      "Train Epoch: 165 [60096/225000 (27%)] Loss: 19020.968750\n",
      "Train Epoch: 165 [62592/225000 (28%)] Loss: 19293.484375\n",
      "Train Epoch: 165 [65088/225000 (29%)] Loss: 18812.269531\n",
      "Train Epoch: 165 [67584/225000 (30%)] Loss: 19335.533203\n",
      "Train Epoch: 165 [70080/225000 (31%)] Loss: 19031.042969\n",
      "Train Epoch: 165 [72576/225000 (32%)] Loss: 19144.808594\n",
      "Train Epoch: 165 [75072/225000 (33%)] Loss: 19391.566406\n",
      "Train Epoch: 165 [77568/225000 (34%)] Loss: 18990.578125\n",
      "Train Epoch: 165 [80064/225000 (36%)] Loss: 19138.597656\n",
      "Train Epoch: 165 [82560/225000 (37%)] Loss: 19558.853516\n",
      "Train Epoch: 165 [85056/225000 (38%)] Loss: 19305.585938\n",
      "Train Epoch: 165 [87552/225000 (39%)] Loss: 19390.810547\n",
      "Train Epoch: 165 [90048/225000 (40%)] Loss: 19587.330078\n",
      "Train Epoch: 165 [92544/225000 (41%)] Loss: 19214.814453\n",
      "Train Epoch: 165 [95040/225000 (42%)] Loss: 19293.113281\n",
      "Train Epoch: 165 [97536/225000 (43%)] Loss: 19208.332031\n",
      "Train Epoch: 165 [100032/225000 (44%)] Loss: 18705.205078\n",
      "Train Epoch: 165 [102528/225000 (46%)] Loss: 19491.539062\n",
      "Train Epoch: 165 [105024/225000 (47%)] Loss: 19461.175781\n",
      "Train Epoch: 165 [107520/225000 (48%)] Loss: 18880.335938\n",
      "Train Epoch: 165 [110016/225000 (49%)] Loss: 19166.335938\n",
      "Train Epoch: 165 [112512/225000 (50%)] Loss: 19237.566406\n",
      "Train Epoch: 165 [115008/225000 (51%)] Loss: 19190.714844\n",
      "Train Epoch: 165 [117504/225000 (52%)] Loss: 19531.087891\n",
      "Train Epoch: 165 [120000/225000 (53%)] Loss: 19610.404297\n",
      "Train Epoch: 165 [122496/225000 (54%)] Loss: 20280.628906\n",
      "Train Epoch: 165 [124992/225000 (56%)] Loss: 19572.449219\n",
      "Train Epoch: 165 [127488/225000 (57%)] Loss: 19079.218750\n",
      "Train Epoch: 165 [129984/225000 (58%)] Loss: 19318.460938\n",
      "Train Epoch: 165 [132480/225000 (59%)] Loss: 19618.121094\n",
      "Train Epoch: 165 [134976/225000 (60%)] Loss: 19481.664062\n",
      "Train Epoch: 165 [137472/225000 (61%)] Loss: 19486.673828\n",
      "Train Epoch: 165 [139968/225000 (62%)] Loss: 19275.333984\n",
      "Train Epoch: 165 [142464/225000 (63%)] Loss: 18967.671875\n",
      "Train Epoch: 165 [144960/225000 (64%)] Loss: 19563.650391\n",
      "Train Epoch: 165 [147456/225000 (66%)] Loss: 19469.322266\n",
      "Train Epoch: 165 [149952/225000 (67%)] Loss: 19045.863281\n",
      "Train Epoch: 165 [152448/225000 (68%)] Loss: 19308.681641\n",
      "Train Epoch: 165 [154944/225000 (69%)] Loss: 19275.787109\n",
      "Train Epoch: 165 [157440/225000 (70%)] Loss: 19589.296875\n",
      "Train Epoch: 165 [159936/225000 (71%)] Loss: 19624.664062\n",
      "Train Epoch: 165 [162432/225000 (72%)] Loss: 19222.875000\n",
      "Train Epoch: 165 [164928/225000 (73%)] Loss: 19324.507812\n",
      "Train Epoch: 165 [167424/225000 (74%)] Loss: 18432.078125\n",
      "Train Epoch: 165 [169920/225000 (76%)] Loss: 19489.355469\n",
      "Train Epoch: 165 [172416/225000 (77%)] Loss: 19022.718750\n",
      "Train Epoch: 165 [174912/225000 (78%)] Loss: 19148.210938\n",
      "Train Epoch: 165 [177408/225000 (79%)] Loss: 18934.445312\n",
      "Train Epoch: 165 [179904/225000 (80%)] Loss: 18810.007812\n",
      "Train Epoch: 165 [182400/225000 (81%)] Loss: 19023.636719\n",
      "Train Epoch: 165 [184896/225000 (82%)] Loss: 19139.343750\n",
      "Train Epoch: 165 [187392/225000 (83%)] Loss: 19393.843750\n",
      "Train Epoch: 165 [189888/225000 (84%)] Loss: 18910.375000\n",
      "Train Epoch: 165 [192384/225000 (86%)] Loss: 19151.072266\n",
      "Train Epoch: 165 [194880/225000 (87%)] Loss: 18932.056641\n",
      "Train Epoch: 165 [197376/225000 (88%)] Loss: 19143.484375\n",
      "Train Epoch: 165 [199872/225000 (89%)] Loss: 19192.314453\n",
      "Train Epoch: 165 [202368/225000 (90%)] Loss: 19027.699219\n",
      "Train Epoch: 165 [204864/225000 (91%)] Loss: 19202.917969\n",
      "Train Epoch: 165 [207360/225000 (92%)] Loss: 19217.134766\n",
      "Train Epoch: 165 [209856/225000 (93%)] Loss: 19534.525391\n",
      "Train Epoch: 165 [212352/225000 (94%)] Loss: 19331.390625\n",
      "Train Epoch: 165 [214848/225000 (95%)] Loss: 19399.279297\n",
      "Train Epoch: 165 [217344/225000 (97%)] Loss: 19091.417969\n",
      "Train Epoch: 165 [219840/225000 (98%)] Loss: 19896.126953\n",
      "Train Epoch: 165 [222336/225000 (99%)] Loss: 19110.990234\n",
      "Train Epoch: 165 [224832/225000 (100%)] Loss: 19488.347656\n",
      "    epoch          : 165\n",
      "    loss           : 19225.990302701044\n",
      "    val_loss       : 19163.279921976664\n",
      "Train Epoch: 166 [192/225000 (0%)] Loss: 18640.207031\n",
      "Train Epoch: 166 [2688/225000 (1%)] Loss: 18772.003906\n",
      "Train Epoch: 166 [5184/225000 (2%)] Loss: 19200.478516\n",
      "Train Epoch: 166 [7680/225000 (3%)] Loss: 19272.896484\n",
      "Train Epoch: 166 [10176/225000 (5%)] Loss: 19746.304688\n",
      "Train Epoch: 166 [12672/225000 (6%)] Loss: 19222.525391\n",
      "Train Epoch: 166 [15168/225000 (7%)] Loss: 19064.134766\n",
      "Train Epoch: 166 [17664/225000 (8%)] Loss: 19000.421875\n",
      "Train Epoch: 166 [20160/225000 (9%)] Loss: 19452.820312\n",
      "Train Epoch: 166 [22656/225000 (10%)] Loss: 18995.273438\n",
      "Train Epoch: 166 [25152/225000 (11%)] Loss: 19334.160156\n",
      "Train Epoch: 166 [27648/225000 (12%)] Loss: 19166.287109\n",
      "Train Epoch: 166 [30144/225000 (13%)] Loss: 19302.345703\n",
      "Train Epoch: 166 [32640/225000 (15%)] Loss: 19155.898438\n",
      "Train Epoch: 166 [35136/225000 (16%)] Loss: 19022.160156\n",
      "Train Epoch: 166 [37632/225000 (17%)] Loss: 19402.718750\n",
      "Train Epoch: 166 [40128/225000 (18%)] Loss: 19645.103516\n",
      "Train Epoch: 166 [42624/225000 (19%)] Loss: 19686.517578\n",
      "Train Epoch: 166 [45120/225000 (20%)] Loss: 19302.927734\n",
      "Train Epoch: 166 [47616/225000 (21%)] Loss: 19430.796875\n",
      "Train Epoch: 166 [50112/225000 (22%)] Loss: 19152.341797\n",
      "Train Epoch: 166 [52608/225000 (23%)] Loss: 19303.554688\n",
      "Train Epoch: 166 [55104/225000 (24%)] Loss: 19666.710938\n",
      "Train Epoch: 166 [57600/225000 (26%)] Loss: 19337.373047\n",
      "Train Epoch: 166 [60096/225000 (27%)] Loss: 19125.841797\n",
      "Train Epoch: 166 [62592/225000 (28%)] Loss: 19024.414062\n",
      "Train Epoch: 166 [65088/225000 (29%)] Loss: 19178.617188\n",
      "Train Epoch: 166 [67584/225000 (30%)] Loss: 19290.054688\n",
      "Train Epoch: 166 [70080/225000 (31%)] Loss: 18968.052734\n",
      "Train Epoch: 166 [72576/225000 (32%)] Loss: 19353.652344\n",
      "Train Epoch: 166 [75072/225000 (33%)] Loss: 19065.097656\n",
      "Train Epoch: 166 [77568/225000 (34%)] Loss: 18888.414062\n",
      "Train Epoch: 166 [80064/225000 (36%)] Loss: 19249.519531\n",
      "Train Epoch: 166 [82560/225000 (37%)] Loss: 19300.394531\n",
      "Train Epoch: 166 [85056/225000 (38%)] Loss: 18664.824219\n",
      "Train Epoch: 166 [87552/225000 (39%)] Loss: 19163.529297\n",
      "Train Epoch: 166 [90048/225000 (40%)] Loss: 19214.187500\n",
      "Train Epoch: 166 [92544/225000 (41%)] Loss: 19284.078125\n",
      "Train Epoch: 166 [95040/225000 (42%)] Loss: 19136.453125\n",
      "Train Epoch: 166 [97536/225000 (43%)] Loss: 18872.808594\n",
      "Train Epoch: 166 [100032/225000 (44%)] Loss: 19544.031250\n",
      "Train Epoch: 166 [102528/225000 (46%)] Loss: 19567.748047\n",
      "Train Epoch: 166 [105024/225000 (47%)] Loss: 18894.855469\n",
      "Train Epoch: 166 [107520/225000 (48%)] Loss: 19313.390625\n",
      "Train Epoch: 166 [110016/225000 (49%)] Loss: 19023.082031\n",
      "Train Epoch: 166 [112512/225000 (50%)] Loss: 19005.320312\n",
      "Train Epoch: 166 [115008/225000 (51%)] Loss: 19127.656250\n",
      "Train Epoch: 166 [117504/225000 (52%)] Loss: 18728.015625\n",
      "Train Epoch: 166 [120000/225000 (53%)] Loss: 19209.406250\n",
      "Train Epoch: 166 [122496/225000 (54%)] Loss: 19315.355469\n",
      "Train Epoch: 166 [124992/225000 (56%)] Loss: 19368.390625\n",
      "Train Epoch: 166 [127488/225000 (57%)] Loss: 19010.689453\n",
      "Train Epoch: 166 [129984/225000 (58%)] Loss: 19037.855469\n",
      "Train Epoch: 166 [132480/225000 (59%)] Loss: 18984.460938\n",
      "Train Epoch: 166 [134976/225000 (60%)] Loss: 19615.898438\n",
      "Train Epoch: 166 [137472/225000 (61%)] Loss: 19132.183594\n",
      "Train Epoch: 166 [139968/225000 (62%)] Loss: 19216.042969\n",
      "Train Epoch: 166 [142464/225000 (63%)] Loss: 18842.515625\n",
      "Train Epoch: 166 [144960/225000 (64%)] Loss: 19453.910156\n",
      "Train Epoch: 166 [147456/225000 (66%)] Loss: 19323.339844\n",
      "Train Epoch: 166 [149952/225000 (67%)] Loss: 19327.560547\n",
      "Train Epoch: 166 [152448/225000 (68%)] Loss: 19342.179688\n",
      "Train Epoch: 166 [154944/225000 (69%)] Loss: 19300.000000\n",
      "Train Epoch: 166 [157440/225000 (70%)] Loss: 19309.906250\n",
      "Train Epoch: 166 [159936/225000 (71%)] Loss: 18990.207031\n",
      "Train Epoch: 166 [162432/225000 (72%)] Loss: 19224.207031\n",
      "Train Epoch: 166 [164928/225000 (73%)] Loss: 19127.382812\n",
      "Train Epoch: 166 [167424/225000 (74%)] Loss: 18805.460938\n",
      "Train Epoch: 166 [169920/225000 (76%)] Loss: 19143.576172\n",
      "Train Epoch: 166 [172416/225000 (77%)] Loss: 18889.746094\n",
      "Train Epoch: 166 [174912/225000 (78%)] Loss: 18983.478516\n",
      "Train Epoch: 166 [177408/225000 (79%)] Loss: 18797.218750\n",
      "Train Epoch: 166 [179904/225000 (80%)] Loss: 19010.130859\n",
      "Train Epoch: 166 [182400/225000 (81%)] Loss: 18925.037109\n",
      "Train Epoch: 166 [184896/225000 (82%)] Loss: 19262.308594\n",
      "Train Epoch: 166 [187392/225000 (83%)] Loss: 19343.115234\n",
      "Train Epoch: 166 [189888/225000 (84%)] Loss: 18975.234375\n",
      "Train Epoch: 166 [192384/225000 (86%)] Loss: 19046.816406\n",
      "Train Epoch: 166 [194880/225000 (87%)] Loss: 18987.847656\n",
      "Train Epoch: 166 [197376/225000 (88%)] Loss: 19245.173828\n",
      "Train Epoch: 166 [199872/225000 (89%)] Loss: 19247.640625\n",
      "Train Epoch: 166 [202368/225000 (90%)] Loss: 19002.285156\n",
      "Train Epoch: 166 [204864/225000 (91%)] Loss: 18945.820312\n",
      "Train Epoch: 166 [207360/225000 (92%)] Loss: 18819.753906\n",
      "Train Epoch: 166 [209856/225000 (93%)] Loss: 19351.652344\n",
      "Train Epoch: 166 [212352/225000 (94%)] Loss: 19317.982422\n",
      "Train Epoch: 166 [214848/225000 (95%)] Loss: 19365.226562\n",
      "Train Epoch: 166 [217344/225000 (97%)] Loss: 19484.404297\n",
      "Train Epoch: 166 [219840/225000 (98%)] Loss: 19318.441406\n",
      "Train Epoch: 166 [222336/225000 (99%)] Loss: 19689.009766\n",
      "Train Epoch: 166 [224832/225000 (100%)] Loss: 19333.226562\n",
      "    epoch          : 166\n",
      "    loss           : 19220.36653090337\n",
      "    val_loss       : 19113.46707072968\n",
      "Train Epoch: 167 [192/225000 (0%)] Loss: 19010.125000\n",
      "Train Epoch: 167 [2688/225000 (1%)] Loss: 19548.210938\n",
      "Train Epoch: 167 [5184/225000 (2%)] Loss: 19562.058594\n",
      "Train Epoch: 167 [7680/225000 (3%)] Loss: 19395.130859\n",
      "Train Epoch: 167 [10176/225000 (5%)] Loss: 19154.849609\n",
      "Train Epoch: 167 [12672/225000 (6%)] Loss: 19229.839844\n",
      "Train Epoch: 167 [15168/225000 (7%)] Loss: 19046.839844\n",
      "Train Epoch: 167 [17664/225000 (8%)] Loss: 19066.343750\n",
      "Train Epoch: 167 [20160/225000 (9%)] Loss: 19078.839844\n",
      "Train Epoch: 167 [22656/225000 (10%)] Loss: 19076.062500\n",
      "Train Epoch: 167 [25152/225000 (11%)] Loss: 19422.722656\n",
      "Train Epoch: 167 [27648/225000 (12%)] Loss: 18927.316406\n",
      "Train Epoch: 167 [30144/225000 (13%)] Loss: 19277.501953\n",
      "Train Epoch: 167 [32640/225000 (15%)] Loss: 19618.453125\n",
      "Train Epoch: 167 [35136/225000 (16%)] Loss: 19516.574219\n",
      "Train Epoch: 167 [37632/225000 (17%)] Loss: 18803.476562\n",
      "Train Epoch: 167 [40128/225000 (18%)] Loss: 19104.949219\n",
      "Train Epoch: 167 [42624/225000 (19%)] Loss: 19074.869141\n",
      "Train Epoch: 167 [45120/225000 (20%)] Loss: 19372.234375\n",
      "Train Epoch: 167 [47616/225000 (21%)] Loss: 19616.578125\n",
      "Train Epoch: 167 [50112/225000 (22%)] Loss: 19049.382812\n",
      "Train Epoch: 167 [52608/225000 (23%)] Loss: 19470.433594\n",
      "Train Epoch: 167 [55104/225000 (24%)] Loss: 18763.089844\n",
      "Train Epoch: 167 [57600/225000 (26%)] Loss: 18888.218750\n",
      "Train Epoch: 167 [60096/225000 (27%)] Loss: 19465.144531\n",
      "Train Epoch: 167 [62592/225000 (28%)] Loss: 19149.828125\n",
      "Train Epoch: 167 [65088/225000 (29%)] Loss: 19273.349609\n",
      "Train Epoch: 167 [67584/225000 (30%)] Loss: 19157.550781\n",
      "Train Epoch: 167 [70080/225000 (31%)] Loss: 18690.925781\n",
      "Train Epoch: 167 [72576/225000 (32%)] Loss: 19854.513672\n",
      "Train Epoch: 167 [75072/225000 (33%)] Loss: 19364.421875\n",
      "Train Epoch: 167 [77568/225000 (34%)] Loss: 19499.908203\n",
      "Train Epoch: 167 [80064/225000 (36%)] Loss: 19076.712891\n",
      "Train Epoch: 167 [82560/225000 (37%)] Loss: 19453.523438\n",
      "Train Epoch: 167 [85056/225000 (38%)] Loss: 19218.984375\n",
      "Train Epoch: 167 [87552/225000 (39%)] Loss: 18941.093750\n",
      "Train Epoch: 167 [90048/225000 (40%)] Loss: 19523.691406\n",
      "Train Epoch: 167 [92544/225000 (41%)] Loss: 19298.144531\n",
      "Train Epoch: 167 [95040/225000 (42%)] Loss: 19511.423828\n",
      "Train Epoch: 167 [97536/225000 (43%)] Loss: 18977.195312\n",
      "Train Epoch: 167 [100032/225000 (44%)] Loss: 18808.888672\n",
      "Train Epoch: 167 [102528/225000 (46%)] Loss: 19145.865234\n",
      "Train Epoch: 167 [105024/225000 (47%)] Loss: 19429.714844\n",
      "Train Epoch: 167 [107520/225000 (48%)] Loss: 18960.722656\n",
      "Train Epoch: 167 [110016/225000 (49%)] Loss: 19099.453125\n",
      "Train Epoch: 167 [112512/225000 (50%)] Loss: 19183.015625\n",
      "Train Epoch: 167 [115008/225000 (51%)] Loss: 19189.066406\n",
      "Train Epoch: 167 [117504/225000 (52%)] Loss: 19247.726562\n",
      "Train Epoch: 167 [120000/225000 (53%)] Loss: 19116.968750\n",
      "Train Epoch: 167 [122496/225000 (54%)] Loss: 19302.898438\n",
      "Train Epoch: 167 [124992/225000 (56%)] Loss: 19015.515625\n",
      "Train Epoch: 167 [127488/225000 (57%)] Loss: 18971.433594\n",
      "Train Epoch: 167 [129984/225000 (58%)] Loss: 18953.062500\n",
      "Train Epoch: 167 [132480/225000 (59%)] Loss: 19101.234375\n",
      "Train Epoch: 167 [134976/225000 (60%)] Loss: 19357.121094\n",
      "Train Epoch: 167 [137472/225000 (61%)] Loss: 19219.277344\n",
      "Train Epoch: 167 [139968/225000 (62%)] Loss: 18966.626953\n",
      "Train Epoch: 167 [142464/225000 (63%)] Loss: 19059.664062\n",
      "Train Epoch: 167 [144960/225000 (64%)] Loss: 19371.312500\n",
      "Train Epoch: 167 [147456/225000 (66%)] Loss: 19281.777344\n",
      "Train Epoch: 167 [149952/225000 (67%)] Loss: 19216.333984\n",
      "Train Epoch: 167 [152448/225000 (68%)] Loss: 19084.634766\n",
      "Train Epoch: 167 [154944/225000 (69%)] Loss: 18972.148438\n",
      "Train Epoch: 167 [157440/225000 (70%)] Loss: 19338.726562\n",
      "Train Epoch: 167 [159936/225000 (71%)] Loss: 19246.433594\n",
      "Train Epoch: 167 [162432/225000 (72%)] Loss: 18793.044922\n",
      "Train Epoch: 167 [164928/225000 (73%)] Loss: 18974.636719\n",
      "Train Epoch: 167 [167424/225000 (74%)] Loss: 19847.382812\n",
      "Train Epoch: 167 [169920/225000 (76%)] Loss: 19295.953125\n",
      "Train Epoch: 167 [172416/225000 (77%)] Loss: 19103.468750\n",
      "Train Epoch: 167 [174912/225000 (78%)] Loss: 19198.687500\n",
      "Train Epoch: 167 [177408/225000 (79%)] Loss: 19721.718750\n",
      "Train Epoch: 167 [179904/225000 (80%)] Loss: 18896.687500\n",
      "Train Epoch: 167 [182400/225000 (81%)] Loss: 19087.269531\n",
      "Train Epoch: 167 [184896/225000 (82%)] Loss: 19521.500000\n",
      "Train Epoch: 167 [187392/225000 (83%)] Loss: 19005.800781\n",
      "Train Epoch: 167 [189888/225000 (84%)] Loss: 19218.000000\n",
      "Train Epoch: 167 [192384/225000 (86%)] Loss: 19343.259766\n",
      "Train Epoch: 167 [194880/225000 (87%)] Loss: 18937.128906\n",
      "Train Epoch: 167 [197376/225000 (88%)] Loss: 19154.431641\n",
      "Train Epoch: 167 [199872/225000 (89%)] Loss: 19475.875000\n",
      "Train Epoch: 167 [202368/225000 (90%)] Loss: 19432.367188\n",
      "Train Epoch: 167 [204864/225000 (91%)] Loss: 19050.960938\n",
      "Train Epoch: 167 [207360/225000 (92%)] Loss: 19162.171875\n",
      "Train Epoch: 167 [209856/225000 (93%)] Loss: 19714.472656\n",
      "Train Epoch: 167 [212352/225000 (94%)] Loss: 19037.542969\n",
      "Train Epoch: 167 [214848/225000 (95%)] Loss: 19413.093750\n",
      "Train Epoch: 167 [217344/225000 (97%)] Loss: 19288.773438\n",
      "Train Epoch: 167 [219840/225000 (98%)] Loss: 19056.289062\n",
      "Train Epoch: 167 [222336/225000 (99%)] Loss: 19185.878906\n",
      "Train Epoch: 167 [224832/225000 (100%)] Loss: 18740.001953\n",
      "    epoch          : 167\n",
      "    loss           : 19211.824047101643\n",
      "    val_loss       : 19123.29339090786\n",
      "Train Epoch: 168 [192/225000 (0%)] Loss: 19051.951172\n",
      "Train Epoch: 168 [2688/225000 (1%)] Loss: 19280.605469\n",
      "Train Epoch: 168 [5184/225000 (2%)] Loss: 19117.027344\n",
      "Train Epoch: 168 [7680/225000 (3%)] Loss: 19137.458984\n",
      "Train Epoch: 168 [10176/225000 (5%)] Loss: 18691.093750\n",
      "Train Epoch: 168 [12672/225000 (6%)] Loss: 19219.207031\n",
      "Train Epoch: 168 [15168/225000 (7%)] Loss: 19006.267578\n",
      "Train Epoch: 168 [17664/225000 (8%)] Loss: 19208.042969\n",
      "Train Epoch: 168 [20160/225000 (9%)] Loss: 19673.259766\n",
      "Train Epoch: 168 [22656/225000 (10%)] Loss: 19427.113281\n",
      "Train Epoch: 168 [25152/225000 (11%)] Loss: 19290.394531\n",
      "Train Epoch: 168 [27648/225000 (12%)] Loss: 19364.542969\n",
      "Train Epoch: 168 [30144/225000 (13%)] Loss: 19363.656250\n",
      "Train Epoch: 168 [32640/225000 (15%)] Loss: 19401.457031\n",
      "Train Epoch: 168 [35136/225000 (16%)] Loss: 19160.703125\n",
      "Train Epoch: 168 [37632/225000 (17%)] Loss: 19432.990234\n",
      "Train Epoch: 168 [40128/225000 (18%)] Loss: 19153.957031\n",
      "Train Epoch: 168 [42624/225000 (19%)] Loss: 19446.593750\n",
      "Train Epoch: 168 [45120/225000 (20%)] Loss: 19494.720703\n",
      "Train Epoch: 168 [47616/225000 (21%)] Loss: 19342.941406\n",
      "Train Epoch: 168 [50112/225000 (22%)] Loss: 19367.785156\n",
      "Train Epoch: 168 [52608/225000 (23%)] Loss: 19096.617188\n",
      "Train Epoch: 168 [55104/225000 (24%)] Loss: 20000.457031\n",
      "Train Epoch: 168 [57600/225000 (26%)] Loss: 19079.628906\n",
      "Train Epoch: 168 [60096/225000 (27%)] Loss: 19286.328125\n",
      "Train Epoch: 168 [62592/225000 (28%)] Loss: 19150.855469\n",
      "Train Epoch: 168 [65088/225000 (29%)] Loss: 19476.871094\n",
      "Train Epoch: 168 [67584/225000 (30%)] Loss: 19188.826172\n",
      "Train Epoch: 168 [70080/225000 (31%)] Loss: 19052.863281\n",
      "Train Epoch: 168 [72576/225000 (32%)] Loss: 19182.804688\n",
      "Train Epoch: 168 [75072/225000 (33%)] Loss: 19421.152344\n",
      "Train Epoch: 168 [77568/225000 (34%)] Loss: 19414.281250\n",
      "Train Epoch: 168 [80064/225000 (36%)] Loss: 18627.777344\n",
      "Train Epoch: 168 [82560/225000 (37%)] Loss: 19065.113281\n",
      "Train Epoch: 168 [85056/225000 (38%)] Loss: 19176.287109\n",
      "Train Epoch: 168 [87552/225000 (39%)] Loss: 18744.583984\n",
      "Train Epoch: 168 [90048/225000 (40%)] Loss: 19226.183594\n",
      "Train Epoch: 168 [92544/225000 (41%)] Loss: 18710.296875\n",
      "Train Epoch: 168 [95040/225000 (42%)] Loss: 18770.476562\n",
      "Train Epoch: 168 [97536/225000 (43%)] Loss: 18690.699219\n",
      "Train Epoch: 168 [100032/225000 (44%)] Loss: 18968.519531\n",
      "Train Epoch: 168 [102528/225000 (46%)] Loss: 19361.695312\n",
      "Train Epoch: 168 [105024/225000 (47%)] Loss: 18822.458984\n",
      "Train Epoch: 168 [107520/225000 (48%)] Loss: 19185.121094\n",
      "Train Epoch: 168 [110016/225000 (49%)] Loss: 19549.121094\n",
      "Train Epoch: 168 [112512/225000 (50%)] Loss: 19349.718750\n",
      "Train Epoch: 168 [115008/225000 (51%)] Loss: 19312.037109\n",
      "Train Epoch: 168 [117504/225000 (52%)] Loss: 19181.009766\n",
      "Train Epoch: 168 [120000/225000 (53%)] Loss: 19032.539062\n",
      "Train Epoch: 168 [122496/225000 (54%)] Loss: 18934.050781\n",
      "Train Epoch: 168 [124992/225000 (56%)] Loss: 18937.734375\n",
      "Train Epoch: 168 [127488/225000 (57%)] Loss: 19353.830078\n",
      "Train Epoch: 168 [129984/225000 (58%)] Loss: 19164.011719\n",
      "Train Epoch: 168 [132480/225000 (59%)] Loss: 19263.562500\n",
      "Train Epoch: 168 [134976/225000 (60%)] Loss: 18896.171875\n",
      "Train Epoch: 168 [137472/225000 (61%)] Loss: 18866.742188\n",
      "Train Epoch: 168 [139968/225000 (62%)] Loss: 19399.105469\n",
      "Train Epoch: 168 [142464/225000 (63%)] Loss: 19028.945312\n",
      "Train Epoch: 168 [144960/225000 (64%)] Loss: 19536.941406\n",
      "Train Epoch: 168 [147456/225000 (66%)] Loss: 19716.089844\n",
      "Train Epoch: 168 [149952/225000 (67%)] Loss: 18581.566406\n",
      "Train Epoch: 168 [152448/225000 (68%)] Loss: 19102.902344\n",
      "Train Epoch: 168 [154944/225000 (69%)] Loss: 18739.771484\n",
      "Train Epoch: 168 [157440/225000 (70%)] Loss: 18992.636719\n",
      "Train Epoch: 168 [159936/225000 (71%)] Loss: 19372.742188\n",
      "Train Epoch: 168 [162432/225000 (72%)] Loss: 19275.919922\n",
      "Train Epoch: 168 [164928/225000 (73%)] Loss: 18935.210938\n",
      "Train Epoch: 168 [167424/225000 (74%)] Loss: 18876.603516\n",
      "Train Epoch: 168 [169920/225000 (76%)] Loss: 19366.937500\n",
      "Train Epoch: 168 [172416/225000 (77%)] Loss: 19451.101562\n",
      "Train Epoch: 168 [174912/225000 (78%)] Loss: 18866.195312\n",
      "Train Epoch: 168 [177408/225000 (79%)] Loss: 19293.705078\n",
      "Train Epoch: 168 [179904/225000 (80%)] Loss: 19246.132812\n",
      "Train Epoch: 168 [182400/225000 (81%)] Loss: 18893.343750\n",
      "Train Epoch: 168 [184896/225000 (82%)] Loss: 19350.162109\n",
      "Train Epoch: 168 [187392/225000 (83%)] Loss: 19219.960938\n",
      "Train Epoch: 168 [189888/225000 (84%)] Loss: 19282.326172\n",
      "Train Epoch: 168 [192384/225000 (86%)] Loss: 19187.105469\n",
      "Train Epoch: 168 [194880/225000 (87%)] Loss: 18906.156250\n",
      "Train Epoch: 168 [197376/225000 (88%)] Loss: 19257.253906\n",
      "Train Epoch: 168 [199872/225000 (89%)] Loss: 19203.191406\n",
      "Train Epoch: 168 [202368/225000 (90%)] Loss: 19673.359375\n",
      "Train Epoch: 168 [204864/225000 (91%)] Loss: 19029.878906\n",
      "Train Epoch: 168 [207360/225000 (92%)] Loss: 19242.671875\n",
      "Train Epoch: 168 [209856/225000 (93%)] Loss: 19651.484375\n",
      "Train Epoch: 168 [212352/225000 (94%)] Loss: 19118.107422\n",
      "Train Epoch: 168 [214848/225000 (95%)] Loss: 18900.582031\n",
      "Train Epoch: 168 [217344/225000 (97%)] Loss: 19145.369141\n",
      "Train Epoch: 168 [219840/225000 (98%)] Loss: 19173.175781\n",
      "Train Epoch: 168 [222336/225000 (99%)] Loss: 19291.433594\n",
      "Train Epoch: 168 [224832/225000 (100%)] Loss: 18997.042969\n",
      "    epoch          : 168\n",
      "    loss           : 19197.600194312607\n",
      "    val_loss       : 19105.602451058745\n",
      "Train Epoch: 169 [192/225000 (0%)] Loss: 18716.687500\n",
      "Train Epoch: 169 [2688/225000 (1%)] Loss: 19423.714844\n",
      "Train Epoch: 169 [5184/225000 (2%)] Loss: 19429.335938\n",
      "Train Epoch: 169 [7680/225000 (3%)] Loss: 18757.285156\n",
      "Train Epoch: 169 [10176/225000 (5%)] Loss: 19015.628906\n",
      "Train Epoch: 169 [12672/225000 (6%)] Loss: 19000.876953\n",
      "Train Epoch: 169 [15168/225000 (7%)] Loss: 19419.894531\n",
      "Train Epoch: 169 [17664/225000 (8%)] Loss: 19093.175781\n",
      "Train Epoch: 169 [20160/225000 (9%)] Loss: 19437.814453\n",
      "Train Epoch: 169 [22656/225000 (10%)] Loss: 19499.972656\n",
      "Train Epoch: 169 [25152/225000 (11%)] Loss: 19340.068359\n",
      "Train Epoch: 169 [27648/225000 (12%)] Loss: 18957.921875\n",
      "Train Epoch: 169 [30144/225000 (13%)] Loss: 19265.167969\n",
      "Train Epoch: 169 [32640/225000 (15%)] Loss: 19078.847656\n",
      "Train Epoch: 169 [35136/225000 (16%)] Loss: 19059.820312\n",
      "Train Epoch: 169 [37632/225000 (17%)] Loss: 19101.566406\n",
      "Train Epoch: 169 [40128/225000 (18%)] Loss: 18738.052734\n",
      "Train Epoch: 169 [42624/225000 (19%)] Loss: 19132.507812\n",
      "Train Epoch: 169 [45120/225000 (20%)] Loss: 19141.728516\n",
      "Train Epoch: 169 [47616/225000 (21%)] Loss: 19213.656250\n",
      "Train Epoch: 169 [50112/225000 (22%)] Loss: 18872.326172\n",
      "Train Epoch: 169 [52608/225000 (23%)] Loss: 19203.968750\n",
      "Train Epoch: 169 [55104/225000 (24%)] Loss: 19087.611328\n",
      "Train Epoch: 169 [57600/225000 (26%)] Loss: 19311.210938\n",
      "Train Epoch: 169 [60096/225000 (27%)] Loss: 19008.792969\n",
      "Train Epoch: 169 [62592/225000 (28%)] Loss: 19276.929688\n",
      "Train Epoch: 169 [65088/225000 (29%)] Loss: 18938.726562\n",
      "Train Epoch: 169 [67584/225000 (30%)] Loss: 19335.613281\n",
      "Train Epoch: 169 [70080/225000 (31%)] Loss: 19379.371094\n",
      "Train Epoch: 169 [72576/225000 (32%)] Loss: 19318.640625\n",
      "Train Epoch: 169 [75072/225000 (33%)] Loss: 19393.994141\n",
      "Train Epoch: 169 [77568/225000 (34%)] Loss: 18718.179688\n",
      "Train Epoch: 169 [80064/225000 (36%)] Loss: 19048.220703\n",
      "Train Epoch: 169 [82560/225000 (37%)] Loss: 19185.472656\n",
      "Train Epoch: 169 [85056/225000 (38%)] Loss: 19586.691406\n",
      "Train Epoch: 169 [87552/225000 (39%)] Loss: 19317.814453\n",
      "Train Epoch: 169 [90048/225000 (40%)] Loss: 19294.617188\n",
      "Train Epoch: 169 [92544/225000 (41%)] Loss: 18838.714844\n",
      "Train Epoch: 169 [95040/225000 (42%)] Loss: 18728.458984\n",
      "Train Epoch: 169 [97536/225000 (43%)] Loss: 19153.503906\n",
      "Train Epoch: 169 [100032/225000 (44%)] Loss: 18910.058594\n",
      "Train Epoch: 169 [102528/225000 (46%)] Loss: 19609.042969\n",
      "Train Epoch: 169 [105024/225000 (47%)] Loss: 19385.757812\n",
      "Train Epoch: 169 [107520/225000 (48%)] Loss: 19543.123047\n",
      "Train Epoch: 169 [110016/225000 (49%)] Loss: 19349.062500\n",
      "Train Epoch: 169 [112512/225000 (50%)] Loss: 19552.414062\n",
      "Train Epoch: 169 [115008/225000 (51%)] Loss: 19098.476562\n",
      "Train Epoch: 169 [117504/225000 (52%)] Loss: 18919.466797\n",
      "Train Epoch: 169 [120000/225000 (53%)] Loss: 19513.136719\n",
      "Train Epoch: 169 [122496/225000 (54%)] Loss: 19153.591797\n",
      "Train Epoch: 169 [124992/225000 (56%)] Loss: 19422.296875\n",
      "Train Epoch: 169 [127488/225000 (57%)] Loss: 18997.052734\n",
      "Train Epoch: 169 [129984/225000 (58%)] Loss: 18928.791016\n",
      "Train Epoch: 169 [132480/225000 (59%)] Loss: 19464.800781\n",
      "Train Epoch: 169 [134976/225000 (60%)] Loss: 19160.109375\n",
      "Train Epoch: 169 [137472/225000 (61%)] Loss: 19442.853516\n",
      "Train Epoch: 169 [139968/225000 (62%)] Loss: 19322.378906\n",
      "Train Epoch: 169 [142464/225000 (63%)] Loss: 19597.632812\n",
      "Train Epoch: 169 [144960/225000 (64%)] Loss: 19263.242188\n",
      "Train Epoch: 169 [147456/225000 (66%)] Loss: 18945.554688\n",
      "Train Epoch: 169 [149952/225000 (67%)] Loss: 19252.773438\n",
      "Train Epoch: 169 [152448/225000 (68%)] Loss: 19556.109375\n",
      "Train Epoch: 169 [154944/225000 (69%)] Loss: 19240.070312\n",
      "Train Epoch: 169 [157440/225000 (70%)] Loss: 19305.851562\n",
      "Train Epoch: 169 [159936/225000 (71%)] Loss: 19469.480469\n",
      "Train Epoch: 169 [162432/225000 (72%)] Loss: 19171.339844\n",
      "Train Epoch: 169 [164928/225000 (73%)] Loss: 19502.720703\n",
      "Train Epoch: 169 [167424/225000 (74%)] Loss: 19218.355469\n",
      "Train Epoch: 169 [169920/225000 (76%)] Loss: 19087.759766\n",
      "Train Epoch: 169 [172416/225000 (77%)] Loss: 19477.830078\n",
      "Train Epoch: 169 [174912/225000 (78%)] Loss: 19294.734375\n",
      "Train Epoch: 169 [177408/225000 (79%)] Loss: 19762.812500\n",
      "Train Epoch: 169 [179904/225000 (80%)] Loss: 19049.587891\n",
      "Train Epoch: 169 [182400/225000 (81%)] Loss: 19508.656250\n",
      "Train Epoch: 169 [184896/225000 (82%)] Loss: 18714.097656\n",
      "Train Epoch: 169 [187392/225000 (83%)] Loss: 18875.978516\n",
      "Train Epoch: 169 [189888/225000 (84%)] Loss: 19358.275391\n",
      "Train Epoch: 169 [192384/225000 (86%)] Loss: 18575.296875\n",
      "Train Epoch: 169 [194880/225000 (87%)] Loss: 19035.175781\n",
      "Train Epoch: 169 [197376/225000 (88%)] Loss: 19007.343750\n",
      "Train Epoch: 169 [199872/225000 (89%)] Loss: 19127.380859\n",
      "Train Epoch: 169 [202368/225000 (90%)] Loss: 19202.191406\n",
      "Train Epoch: 169 [204864/225000 (91%)] Loss: 19352.001953\n",
      "Train Epoch: 169 [207360/225000 (92%)] Loss: 19542.527344\n",
      "Train Epoch: 169 [209856/225000 (93%)] Loss: 18866.539062\n",
      "Train Epoch: 169 [212352/225000 (94%)] Loss: 19799.921875\n",
      "Train Epoch: 169 [214848/225000 (95%)] Loss: 19327.251953\n",
      "Train Epoch: 169 [217344/225000 (97%)] Loss: 19467.609375\n",
      "Train Epoch: 169 [219840/225000 (98%)] Loss: 19276.007812\n",
      "Train Epoch: 169 [222336/225000 (99%)] Loss: 22443.666016\n",
      "Train Epoch: 169 [224832/225000 (100%)] Loss: 19045.078125\n",
      "    epoch          : 169\n",
      "    loss           : 19201.149589043835\n",
      "    val_loss       : 19109.135546299338\n",
      "Train Epoch: 170 [192/225000 (0%)] Loss: 19224.644531\n",
      "Train Epoch: 170 [2688/225000 (1%)] Loss: 19118.935547\n",
      "Train Epoch: 170 [5184/225000 (2%)] Loss: 19394.937500\n",
      "Train Epoch: 170 [7680/225000 (3%)] Loss: 19270.410156\n",
      "Train Epoch: 170 [10176/225000 (5%)] Loss: 19655.718750\n",
      "Train Epoch: 170 [12672/225000 (6%)] Loss: 19018.123047\n",
      "Train Epoch: 170 [15168/225000 (7%)] Loss: 18698.375000\n",
      "Train Epoch: 170 [17664/225000 (8%)] Loss: 18957.402344\n",
      "Train Epoch: 170 [20160/225000 (9%)] Loss: 19097.994141\n",
      "Train Epoch: 170 [22656/225000 (10%)] Loss: 19642.691406\n",
      "Train Epoch: 170 [25152/225000 (11%)] Loss: 19013.097656\n",
      "Train Epoch: 170 [27648/225000 (12%)] Loss: 19094.958984\n",
      "Train Epoch: 170 [30144/225000 (13%)] Loss: 18717.267578\n",
      "Train Epoch: 170 [32640/225000 (15%)] Loss: 19522.925781\n",
      "Train Epoch: 170 [35136/225000 (16%)] Loss: 19761.503906\n",
      "Train Epoch: 170 [37632/225000 (17%)] Loss: 18946.738281\n",
      "Train Epoch: 170 [40128/225000 (18%)] Loss: 18861.722656\n",
      "Train Epoch: 170 [42624/225000 (19%)] Loss: 19193.226562\n",
      "Train Epoch: 170 [45120/225000 (20%)] Loss: 19513.839844\n",
      "Train Epoch: 170 [47616/225000 (21%)] Loss: 18844.882812\n",
      "Train Epoch: 170 [50112/225000 (22%)] Loss: 18863.695312\n",
      "Train Epoch: 170 [52608/225000 (23%)] Loss: 18904.087891\n",
      "Train Epoch: 170 [55104/225000 (24%)] Loss: 18831.968750\n",
      "Train Epoch: 170 [57600/225000 (26%)] Loss: 19419.753906\n",
      "Train Epoch: 170 [60096/225000 (27%)] Loss: 18888.980469\n",
      "Train Epoch: 170 [62592/225000 (28%)] Loss: 19033.523438\n",
      "Train Epoch: 170 [65088/225000 (29%)] Loss: 19056.361328\n",
      "Train Epoch: 170 [67584/225000 (30%)] Loss: 19393.070312\n",
      "Train Epoch: 170 [70080/225000 (31%)] Loss: 19041.193359\n",
      "Train Epoch: 170 [72576/225000 (32%)] Loss: 18829.757812\n",
      "Train Epoch: 170 [75072/225000 (33%)] Loss: 18823.921875\n",
      "Train Epoch: 170 [77568/225000 (34%)] Loss: 18994.304688\n",
      "Train Epoch: 170 [80064/225000 (36%)] Loss: 19043.351562\n",
      "Train Epoch: 170 [82560/225000 (37%)] Loss: 19501.496094\n",
      "Train Epoch: 170 [85056/225000 (38%)] Loss: 19293.480469\n",
      "Train Epoch: 170 [87552/225000 (39%)] Loss: 18967.253906\n",
      "Train Epoch: 170 [90048/225000 (40%)] Loss: 18704.416016\n",
      "Train Epoch: 170 [92544/225000 (41%)] Loss: 19125.710938\n",
      "Train Epoch: 170 [95040/225000 (42%)] Loss: 19543.072266\n",
      "Train Epoch: 170 [97536/225000 (43%)] Loss: 19172.601562\n",
      "Train Epoch: 170 [100032/225000 (44%)] Loss: 19415.621094\n",
      "Train Epoch: 170 [102528/225000 (46%)] Loss: 18974.851562\n",
      "Train Epoch: 170 [105024/225000 (47%)] Loss: 18705.666016\n",
      "Train Epoch: 170 [107520/225000 (48%)] Loss: 19015.320312\n",
      "Train Epoch: 170 [110016/225000 (49%)] Loss: 19297.751953\n",
      "Train Epoch: 170 [112512/225000 (50%)] Loss: 18854.535156\n",
      "Train Epoch: 170 [115008/225000 (51%)] Loss: 18983.501953\n",
      "Train Epoch: 170 [117504/225000 (52%)] Loss: 19270.007812\n",
      "Train Epoch: 170 [120000/225000 (53%)] Loss: 18886.753906\n",
      "Train Epoch: 170 [122496/225000 (54%)] Loss: 19053.027344\n",
      "Train Epoch: 170 [124992/225000 (56%)] Loss: 19749.974609\n",
      "Train Epoch: 170 [127488/225000 (57%)] Loss: 19227.699219\n",
      "Train Epoch: 170 [129984/225000 (58%)] Loss: 19043.449219\n",
      "Train Epoch: 170 [132480/225000 (59%)] Loss: 19425.738281\n",
      "Train Epoch: 170 [134976/225000 (60%)] Loss: 18697.775391\n",
      "Train Epoch: 170 [137472/225000 (61%)] Loss: 19198.203125\n",
      "Train Epoch: 170 [139968/225000 (62%)] Loss: 19374.158203\n",
      "Train Epoch: 170 [142464/225000 (63%)] Loss: 19406.132812\n",
      "Train Epoch: 170 [144960/225000 (64%)] Loss: 19052.593750\n",
      "Train Epoch: 170 [147456/225000 (66%)] Loss: 18949.046875\n",
      "Train Epoch: 170 [149952/225000 (67%)] Loss: 19538.101562\n",
      "Train Epoch: 170 [152448/225000 (68%)] Loss: 19007.152344\n",
      "Train Epoch: 170 [154944/225000 (69%)] Loss: 19074.792969\n",
      "Train Epoch: 170 [157440/225000 (70%)] Loss: 18741.355469\n",
      "Train Epoch: 170 [159936/225000 (71%)] Loss: 19069.382812\n",
      "Train Epoch: 170 [162432/225000 (72%)] Loss: 19231.580078\n",
      "Train Epoch: 170 [164928/225000 (73%)] Loss: 18883.476562\n",
      "Train Epoch: 170 [167424/225000 (74%)] Loss: 19666.810547\n",
      "Train Epoch: 170 [169920/225000 (76%)] Loss: 18680.101562\n",
      "Train Epoch: 170 [172416/225000 (77%)] Loss: 18701.250000\n",
      "Train Epoch: 170 [174912/225000 (78%)] Loss: 19186.640625\n",
      "Train Epoch: 170 [177408/225000 (79%)] Loss: 19544.585938\n",
      "Train Epoch: 170 [179904/225000 (80%)] Loss: 19248.765625\n",
      "Train Epoch: 170 [182400/225000 (81%)] Loss: 19488.544922\n",
      "Train Epoch: 170 [184896/225000 (82%)] Loss: 19564.644531\n",
      "Train Epoch: 170 [187392/225000 (83%)] Loss: 19406.107422\n",
      "Train Epoch: 170 [189888/225000 (84%)] Loss: 19144.695312\n",
      "Train Epoch: 170 [192384/225000 (86%)] Loss: 19329.394531\n",
      "Train Epoch: 170 [194880/225000 (87%)] Loss: 19371.021484\n",
      "Train Epoch: 170 [197376/225000 (88%)] Loss: 19128.386719\n",
      "Train Epoch: 170 [199872/225000 (89%)] Loss: 18929.833984\n",
      "Train Epoch: 170 [202368/225000 (90%)] Loss: 19470.898438\n",
      "Train Epoch: 170 [204864/225000 (91%)] Loss: 18847.457031\n",
      "Train Epoch: 170 [207360/225000 (92%)] Loss: 19511.275391\n",
      "Train Epoch: 170 [209856/225000 (93%)] Loss: 18916.878906\n",
      "Train Epoch: 170 [212352/225000 (94%)] Loss: 19058.589844\n",
      "Train Epoch: 170 [214848/225000 (95%)] Loss: 18983.949219\n",
      "Train Epoch: 170 [217344/225000 (97%)] Loss: 19133.503906\n",
      "Train Epoch: 170 [219840/225000 (98%)] Loss: 18985.257812\n",
      "Train Epoch: 170 [222336/225000 (99%)] Loss: 19333.800781\n",
      "Train Epoch: 170 [224832/225000 (100%)] Loss: 18883.375000\n",
      "    epoch          : 170\n",
      "    loss           : 19190.78190326365\n",
      "    val_loss       : 19129.959786254032\n",
      "Train Epoch: 171 [192/225000 (0%)] Loss: 19179.164062\n",
      "Train Epoch: 171 [2688/225000 (1%)] Loss: 19464.693359\n",
      "Train Epoch: 171 [5184/225000 (2%)] Loss: 19476.484375\n",
      "Train Epoch: 171 [7680/225000 (3%)] Loss: 19274.330078\n",
      "Train Epoch: 171 [10176/225000 (5%)] Loss: 19105.871094\n",
      "Train Epoch: 171 [12672/225000 (6%)] Loss: 18839.890625\n",
      "Train Epoch: 171 [15168/225000 (7%)] Loss: 18863.781250\n",
      "Train Epoch: 171 [17664/225000 (8%)] Loss: 19416.832031\n",
      "Train Epoch: 171 [20160/225000 (9%)] Loss: 19062.015625\n",
      "Train Epoch: 171 [22656/225000 (10%)] Loss: 18868.548828\n",
      "Train Epoch: 171 [25152/225000 (11%)] Loss: 18918.984375\n",
      "Train Epoch: 171 [27648/225000 (12%)] Loss: 18911.150391\n",
      "Train Epoch: 171 [30144/225000 (13%)] Loss: 19017.726562\n",
      "Train Epoch: 171 [32640/225000 (15%)] Loss: 19379.343750\n",
      "Train Epoch: 171 [35136/225000 (16%)] Loss: 18987.115234\n",
      "Train Epoch: 171 [37632/225000 (17%)] Loss: 19374.355469\n",
      "Train Epoch: 171 [40128/225000 (18%)] Loss: 19439.898438\n",
      "Train Epoch: 171 [42624/225000 (19%)] Loss: 19419.363281\n",
      "Train Epoch: 171 [45120/225000 (20%)] Loss: 19297.292969\n",
      "Train Epoch: 171 [47616/225000 (21%)] Loss: 19407.207031\n",
      "Train Epoch: 171 [50112/225000 (22%)] Loss: 19113.054688\n",
      "Train Epoch: 171 [52608/225000 (23%)] Loss: 19085.933594\n",
      "Train Epoch: 171 [55104/225000 (24%)] Loss: 19225.425781\n",
      "Train Epoch: 171 [57600/225000 (26%)] Loss: 18809.458984\n",
      "Train Epoch: 171 [60096/225000 (27%)] Loss: 18996.875000\n",
      "Train Epoch: 171 [62592/225000 (28%)] Loss: 18895.078125\n",
      "Train Epoch: 171 [65088/225000 (29%)] Loss: 18650.007812\n",
      "Train Epoch: 171 [67584/225000 (30%)] Loss: 19441.464844\n",
      "Train Epoch: 171 [70080/225000 (31%)] Loss: 19000.425781\n",
      "Train Epoch: 171 [72576/225000 (32%)] Loss: 19139.478516\n",
      "Train Epoch: 171 [75072/225000 (33%)] Loss: 19350.539062\n",
      "Train Epoch: 171 [77568/225000 (34%)] Loss: 19298.605469\n",
      "Train Epoch: 171 [80064/225000 (36%)] Loss: 19201.349609\n",
      "Train Epoch: 171 [82560/225000 (37%)] Loss: 19196.980469\n",
      "Train Epoch: 171 [85056/225000 (38%)] Loss: 19124.683594\n",
      "Train Epoch: 171 [87552/225000 (39%)] Loss: 18917.058594\n",
      "Train Epoch: 171 [90048/225000 (40%)] Loss: 19243.644531\n",
      "Train Epoch: 171 [92544/225000 (41%)] Loss: 19359.117188\n",
      "Train Epoch: 171 [95040/225000 (42%)] Loss: 19117.162109\n",
      "Train Epoch: 171 [97536/225000 (43%)] Loss: 19497.019531\n",
      "Train Epoch: 171 [100032/225000 (44%)] Loss: 18712.355469\n",
      "Train Epoch: 171 [102528/225000 (46%)] Loss: 19314.335938\n",
      "Train Epoch: 171 [105024/225000 (47%)] Loss: 18455.986328\n",
      "Train Epoch: 171 [107520/225000 (48%)] Loss: 19338.779297\n",
      "Train Epoch: 171 [110016/225000 (49%)] Loss: 19211.376953\n",
      "Train Epoch: 171 [112512/225000 (50%)] Loss: 19285.322266\n",
      "Train Epoch: 171 [115008/225000 (51%)] Loss: 19239.201172\n",
      "Train Epoch: 171 [117504/225000 (52%)] Loss: 19129.855469\n",
      "Train Epoch: 171 [120000/225000 (53%)] Loss: 19098.029297\n",
      "Train Epoch: 171 [122496/225000 (54%)] Loss: 19413.589844\n",
      "Train Epoch: 171 [124992/225000 (56%)] Loss: 18822.273438\n",
      "Train Epoch: 171 [127488/225000 (57%)] Loss: 19074.414062\n",
      "Train Epoch: 171 [129984/225000 (58%)] Loss: 19450.779297\n",
      "Train Epoch: 171 [132480/225000 (59%)] Loss: 19079.773438\n",
      "Train Epoch: 171 [134976/225000 (60%)] Loss: 19548.324219\n",
      "Train Epoch: 171 [137472/225000 (61%)] Loss: 19372.550781\n",
      "Train Epoch: 171 [139968/225000 (62%)] Loss: 19076.189453\n",
      "Train Epoch: 171 [142464/225000 (63%)] Loss: 19463.203125\n",
      "Train Epoch: 171 [144960/225000 (64%)] Loss: 19080.988281\n",
      "Train Epoch: 171 [147456/225000 (66%)] Loss: 18981.378906\n",
      "Train Epoch: 171 [149952/225000 (67%)] Loss: 19299.886719\n",
      "Train Epoch: 171 [152448/225000 (68%)] Loss: 19385.601562\n",
      "Train Epoch: 171 [154944/225000 (69%)] Loss: 19327.585938\n",
      "Train Epoch: 171 [157440/225000 (70%)] Loss: 19322.060547\n",
      "Train Epoch: 171 [159936/225000 (71%)] Loss: 19255.929688\n",
      "Train Epoch: 171 [162432/225000 (72%)] Loss: 19261.488281\n",
      "Train Epoch: 171 [164928/225000 (73%)] Loss: 19103.322266\n",
      "Train Epoch: 171 [167424/225000 (74%)] Loss: 19090.720703\n",
      "Train Epoch: 171 [169920/225000 (76%)] Loss: 19052.562500\n",
      "Train Epoch: 171 [172416/225000 (77%)] Loss: 19370.222656\n",
      "Train Epoch: 171 [174912/225000 (78%)] Loss: 19227.943359\n",
      "Train Epoch: 171 [177408/225000 (79%)] Loss: 19943.117188\n",
      "Train Epoch: 171 [179904/225000 (80%)] Loss: 19227.546875\n",
      "Train Epoch: 171 [182400/225000 (81%)] Loss: 19302.009766\n",
      "Train Epoch: 171 [184896/225000 (82%)] Loss: 19561.753906\n",
      "Train Epoch: 171 [187392/225000 (83%)] Loss: 18960.515625\n",
      "Train Epoch: 171 [189888/225000 (84%)] Loss: 19388.328125\n",
      "Train Epoch: 171 [192384/225000 (86%)] Loss: 18793.746094\n",
      "Train Epoch: 171 [194880/225000 (87%)] Loss: 19017.882812\n",
      "Train Epoch: 171 [197376/225000 (88%)] Loss: 19103.703125\n",
      "Train Epoch: 171 [199872/225000 (89%)] Loss: 19534.121094\n",
      "Train Epoch: 171 [202368/225000 (90%)] Loss: 19269.515625\n",
      "Train Epoch: 171 [204864/225000 (91%)] Loss: 19370.437500\n",
      "Train Epoch: 171 [207360/225000 (92%)] Loss: 19046.113281\n",
      "Train Epoch: 171 [209856/225000 (93%)] Loss: 19128.230469\n",
      "Train Epoch: 171 [212352/225000 (94%)] Loss: 19018.382812\n",
      "Train Epoch: 171 [214848/225000 (95%)] Loss: 19201.703125\n",
      "Train Epoch: 171 [217344/225000 (97%)] Loss: 19782.546875\n",
      "Train Epoch: 171 [219840/225000 (98%)] Loss: 18961.048828\n",
      "Train Epoch: 171 [222336/225000 (99%)] Loss: 19409.742188\n",
      "Train Epoch: 171 [224832/225000 (100%)] Loss: 18859.257812\n",
      "    epoch          : 171\n",
      "    loss           : 19184.648045875107\n",
      "    val_loss       : 19111.28250053411\n",
      "Train Epoch: 172 [192/225000 (0%)] Loss: 19694.660156\n",
      "Train Epoch: 172 [2688/225000 (1%)] Loss: 19426.031250\n",
      "Train Epoch: 172 [5184/225000 (2%)] Loss: 18386.582031\n",
      "Train Epoch: 172 [7680/225000 (3%)] Loss: 18939.189453\n",
      "Train Epoch: 172 [10176/225000 (5%)] Loss: 19096.337891\n",
      "Train Epoch: 172 [12672/225000 (6%)] Loss: 19029.576172\n",
      "Train Epoch: 172 [15168/225000 (7%)] Loss: 19008.007812\n",
      "Train Epoch: 172 [17664/225000 (8%)] Loss: 19020.546875\n",
      "Train Epoch: 172 [20160/225000 (9%)] Loss: 19173.437500\n",
      "Train Epoch: 172 [22656/225000 (10%)] Loss: 19378.433594\n",
      "Train Epoch: 172 [25152/225000 (11%)] Loss: 19064.062500\n",
      "Train Epoch: 172 [27648/225000 (12%)] Loss: 19025.960938\n",
      "Train Epoch: 172 [30144/225000 (13%)] Loss: 19338.169922\n",
      "Train Epoch: 172 [32640/225000 (15%)] Loss: 19300.511719\n",
      "Train Epoch: 172 [35136/225000 (16%)] Loss: 19349.906250\n",
      "Train Epoch: 172 [37632/225000 (17%)] Loss: 19082.041016\n",
      "Train Epoch: 172 [40128/225000 (18%)] Loss: 19392.089844\n",
      "Train Epoch: 172 [42624/225000 (19%)] Loss: 19310.667969\n",
      "Train Epoch: 172 [45120/225000 (20%)] Loss: 19211.222656\n",
      "Train Epoch: 172 [47616/225000 (21%)] Loss: 19327.554688\n",
      "Train Epoch: 172 [50112/225000 (22%)] Loss: 19261.550781\n",
      "Train Epoch: 172 [52608/225000 (23%)] Loss: 19129.154297\n",
      "Train Epoch: 172 [55104/225000 (24%)] Loss: 19010.232422\n",
      "Train Epoch: 172 [57600/225000 (26%)] Loss: 19468.609375\n",
      "Train Epoch: 172 [60096/225000 (27%)] Loss: 19470.882812\n",
      "Train Epoch: 172 [62592/225000 (28%)] Loss: 18930.560547\n",
      "Train Epoch: 172 [65088/225000 (29%)] Loss: 19206.080078\n",
      "Train Epoch: 172 [67584/225000 (30%)] Loss: 19064.875000\n",
      "Train Epoch: 172 [70080/225000 (31%)] Loss: 19201.683594\n",
      "Train Epoch: 172 [72576/225000 (32%)] Loss: 19169.363281\n",
      "Train Epoch: 172 [75072/225000 (33%)] Loss: 19465.339844\n",
      "Train Epoch: 172 [77568/225000 (34%)] Loss: 18952.191406\n",
      "Train Epoch: 172 [80064/225000 (36%)] Loss: 18944.179688\n",
      "Train Epoch: 172 [82560/225000 (37%)] Loss: 18894.400391\n",
      "Train Epoch: 172 [85056/225000 (38%)] Loss: 19163.539062\n",
      "Train Epoch: 172 [87552/225000 (39%)] Loss: 18891.148438\n",
      "Train Epoch: 172 [90048/225000 (40%)] Loss: 19426.777344\n",
      "Train Epoch: 172 [92544/225000 (41%)] Loss: 19417.757812\n",
      "Train Epoch: 172 [95040/225000 (42%)] Loss: 18969.039062\n",
      "Train Epoch: 172 [97536/225000 (43%)] Loss: 18713.207031\n",
      "Train Epoch: 172 [100032/225000 (44%)] Loss: 18495.921875\n",
      "Train Epoch: 172 [102528/225000 (46%)] Loss: 19945.730469\n",
      "Train Epoch: 172 [105024/225000 (47%)] Loss: 19093.464844\n",
      "Train Epoch: 172 [107520/225000 (48%)] Loss: 19025.109375\n",
      "Train Epoch: 172 [110016/225000 (49%)] Loss: 19137.925781\n",
      "Train Epoch: 172 [112512/225000 (50%)] Loss: 19071.007812\n",
      "Train Epoch: 172 [115008/225000 (51%)] Loss: 19242.652344\n",
      "Train Epoch: 172 [117504/225000 (52%)] Loss: 19039.617188\n",
      "Train Epoch: 172 [120000/225000 (53%)] Loss: 18965.218750\n",
      "Train Epoch: 172 [122496/225000 (54%)] Loss: 18962.605469\n",
      "Train Epoch: 172 [124992/225000 (56%)] Loss: 19646.097656\n",
      "Train Epoch: 172 [127488/225000 (57%)] Loss: 19202.998047\n",
      "Train Epoch: 172 [129984/225000 (58%)] Loss: 19201.060547\n",
      "Train Epoch: 172 [132480/225000 (59%)] Loss: 18979.621094\n",
      "Train Epoch: 172 [134976/225000 (60%)] Loss: 18963.996094\n",
      "Train Epoch: 172 [137472/225000 (61%)] Loss: 19805.476562\n",
      "Train Epoch: 172 [139968/225000 (62%)] Loss: 19322.878906\n",
      "Train Epoch: 172 [142464/225000 (63%)] Loss: 19051.996094\n",
      "Train Epoch: 172 [144960/225000 (64%)] Loss: 19106.378906\n",
      "Train Epoch: 172 [147456/225000 (66%)] Loss: 19231.121094\n",
      "Train Epoch: 172 [149952/225000 (67%)] Loss: 18538.718750\n",
      "Train Epoch: 172 [152448/225000 (68%)] Loss: 19307.480469\n",
      "Train Epoch: 172 [154944/225000 (69%)] Loss: 19466.683594\n",
      "Train Epoch: 172 [157440/225000 (70%)] Loss: 18819.464844\n",
      "Train Epoch: 172 [159936/225000 (71%)] Loss: 19556.929688\n",
      "Train Epoch: 172 [162432/225000 (72%)] Loss: 19103.804688\n",
      "Train Epoch: 172 [164928/225000 (73%)] Loss: 19306.136719\n",
      "Train Epoch: 172 [167424/225000 (74%)] Loss: 19282.402344\n",
      "Train Epoch: 172 [169920/225000 (76%)] Loss: 18844.441406\n",
      "Train Epoch: 172 [172416/225000 (77%)] Loss: 19163.875000\n",
      "Train Epoch: 172 [174912/225000 (78%)] Loss: 19005.640625\n",
      "Train Epoch: 172 [177408/225000 (79%)] Loss: 19256.109375\n",
      "Train Epoch: 172 [179904/225000 (80%)] Loss: 19334.453125\n",
      "Train Epoch: 172 [182400/225000 (81%)] Loss: 18699.140625\n",
      "Train Epoch: 172 [184896/225000 (82%)] Loss: 19279.156250\n",
      "Train Epoch: 172 [187392/225000 (83%)] Loss: 19043.468750\n",
      "Train Epoch: 172 [189888/225000 (84%)] Loss: 18995.796875\n",
      "Train Epoch: 172 [192384/225000 (86%)] Loss: 19193.964844\n",
      "Train Epoch: 172 [194880/225000 (87%)] Loss: 18685.880859\n",
      "Train Epoch: 172 [197376/225000 (88%)] Loss: 19324.113281\n",
      "Train Epoch: 172 [199872/225000 (89%)] Loss: 19180.353516\n",
      "Train Epoch: 172 [202368/225000 (90%)] Loss: 19260.917969\n",
      "Train Epoch: 172 [204864/225000 (91%)] Loss: 19229.320312\n",
      "Train Epoch: 172 [207360/225000 (92%)] Loss: 19463.527344\n",
      "Train Epoch: 172 [209856/225000 (93%)] Loss: 19207.820312\n",
      "Train Epoch: 172 [212352/225000 (94%)] Loss: 19377.890625\n",
      "Train Epoch: 172 [214848/225000 (95%)] Loss: 19022.093750\n",
      "Train Epoch: 172 [217344/225000 (97%)] Loss: 19177.343750\n",
      "Train Epoch: 172 [219840/225000 (98%)] Loss: 19282.308594\n",
      "Train Epoch: 172 [222336/225000 (99%)] Loss: 19546.865234\n",
      "Train Epoch: 172 [224832/225000 (100%)] Loss: 19281.941406\n",
      "    epoch          : 172\n",
      "    loss           : 19179.36413615881\n",
      "    val_loss       : 19085.56845159021\n",
      "Train Epoch: 173 [192/225000 (0%)] Loss: 19006.976562\n",
      "Train Epoch: 173 [2688/225000 (1%)] Loss: 19346.929688\n",
      "Train Epoch: 173 [5184/225000 (2%)] Loss: 18941.089844\n",
      "Train Epoch: 173 [7680/225000 (3%)] Loss: 19329.218750\n",
      "Train Epoch: 173 [10176/225000 (5%)] Loss: 18544.082031\n",
      "Train Epoch: 173 [12672/225000 (6%)] Loss: 18575.089844\n",
      "Train Epoch: 173 [15168/225000 (7%)] Loss: 18480.953125\n",
      "Train Epoch: 173 [17664/225000 (8%)] Loss: 19719.105469\n",
      "Train Epoch: 173 [20160/225000 (9%)] Loss: 19032.812500\n",
      "Train Epoch: 173 [22656/225000 (10%)] Loss: 19191.240234\n",
      "Train Epoch: 173 [25152/225000 (11%)] Loss: 18823.568359\n",
      "Train Epoch: 173 [27648/225000 (12%)] Loss: 19271.613281\n",
      "Train Epoch: 173 [30144/225000 (13%)] Loss: 19027.615234\n",
      "Train Epoch: 173 [32640/225000 (15%)] Loss: 19408.693359\n",
      "Train Epoch: 173 [35136/225000 (16%)] Loss: 19201.546875\n",
      "Train Epoch: 173 [37632/225000 (17%)] Loss: 19431.058594\n",
      "Train Epoch: 173 [40128/225000 (18%)] Loss: 19291.626953\n",
      "Train Epoch: 173 [42624/225000 (19%)] Loss: 19582.492188\n",
      "Train Epoch: 173 [45120/225000 (20%)] Loss: 19133.244141\n",
      "Train Epoch: 173 [47616/225000 (21%)] Loss: 19580.000000\n",
      "Train Epoch: 173 [50112/225000 (22%)] Loss: 19082.523438\n",
      "Train Epoch: 173 [52608/225000 (23%)] Loss: 19162.554688\n",
      "Train Epoch: 173 [55104/225000 (24%)] Loss: 19257.017578\n",
      "Train Epoch: 173 [57600/225000 (26%)] Loss: 18545.464844\n",
      "Train Epoch: 173 [60096/225000 (27%)] Loss: 18916.230469\n",
      "Train Epoch: 173 [62592/225000 (28%)] Loss: 19441.878906\n",
      "Train Epoch: 173 [65088/225000 (29%)] Loss: 18849.347656\n",
      "Train Epoch: 173 [67584/225000 (30%)] Loss: 18865.513672\n",
      "Train Epoch: 173 [70080/225000 (31%)] Loss: 19259.816406\n",
      "Train Epoch: 173 [72576/225000 (32%)] Loss: 18978.242188\n",
      "Train Epoch: 173 [75072/225000 (33%)] Loss: 18979.781250\n",
      "Train Epoch: 173 [77568/225000 (34%)] Loss: 19110.386719\n",
      "Train Epoch: 173 [80064/225000 (36%)] Loss: 19100.644531\n",
      "Train Epoch: 173 [82560/225000 (37%)] Loss: 19018.140625\n",
      "Train Epoch: 173 [85056/225000 (38%)] Loss: 19475.958984\n",
      "Train Epoch: 173 [87552/225000 (39%)] Loss: 19517.140625\n",
      "Train Epoch: 173 [90048/225000 (40%)] Loss: 19413.503906\n",
      "Train Epoch: 173 [92544/225000 (41%)] Loss: 19340.896484\n",
      "Train Epoch: 173 [95040/225000 (42%)] Loss: 19465.125000\n",
      "Train Epoch: 173 [97536/225000 (43%)] Loss: 19357.457031\n",
      "Train Epoch: 173 [100032/225000 (44%)] Loss: 19285.332031\n",
      "Train Epoch: 173 [102528/225000 (46%)] Loss: 19513.308594\n",
      "Train Epoch: 173 [105024/225000 (47%)] Loss: 19109.714844\n",
      "Train Epoch: 173 [107520/225000 (48%)] Loss: 19119.755859\n",
      "Train Epoch: 173 [110016/225000 (49%)] Loss: 19642.808594\n",
      "Train Epoch: 173 [112512/225000 (50%)] Loss: 19200.865234\n",
      "Train Epoch: 173 [115008/225000 (51%)] Loss: 19347.699219\n",
      "Train Epoch: 173 [117504/225000 (52%)] Loss: 18845.457031\n",
      "Train Epoch: 173 [120000/225000 (53%)] Loss: 18836.414062\n",
      "Train Epoch: 173 [122496/225000 (54%)] Loss: 19046.585938\n",
      "Train Epoch: 173 [124992/225000 (56%)] Loss: 19079.619141\n",
      "Train Epoch: 173 [127488/225000 (57%)] Loss: 19079.929688\n",
      "Train Epoch: 173 [129984/225000 (58%)] Loss: 19169.316406\n",
      "Train Epoch: 173 [132480/225000 (59%)] Loss: 19391.582031\n",
      "Train Epoch: 173 [134976/225000 (60%)] Loss: 19360.697266\n",
      "Train Epoch: 173 [137472/225000 (61%)] Loss: 19390.585938\n",
      "Train Epoch: 173 [139968/225000 (62%)] Loss: 18988.617188\n",
      "Train Epoch: 173 [142464/225000 (63%)] Loss: 18999.568359\n",
      "Train Epoch: 173 [144960/225000 (64%)] Loss: 19013.693359\n",
      "Train Epoch: 173 [147456/225000 (66%)] Loss: 18737.820312\n",
      "Train Epoch: 173 [149952/225000 (67%)] Loss: 19233.667969\n",
      "Train Epoch: 173 [152448/225000 (68%)] Loss: 18911.482422\n",
      "Train Epoch: 173 [154944/225000 (69%)] Loss: 19857.757812\n",
      "Train Epoch: 173 [157440/225000 (70%)] Loss: 18474.695312\n",
      "Train Epoch: 173 [159936/225000 (71%)] Loss: 19093.759766\n",
      "Train Epoch: 173 [162432/225000 (72%)] Loss: 19077.042969\n",
      "Train Epoch: 173 [164928/225000 (73%)] Loss: 18836.976562\n",
      "Train Epoch: 173 [167424/225000 (74%)] Loss: 18949.781250\n",
      "Train Epoch: 173 [169920/225000 (76%)] Loss: 19366.410156\n",
      "Train Epoch: 173 [172416/225000 (77%)] Loss: 19610.679688\n",
      "Train Epoch: 173 [174912/225000 (78%)] Loss: 19171.990234\n",
      "Train Epoch: 173 [177408/225000 (79%)] Loss: 19394.253906\n",
      "Train Epoch: 173 [179904/225000 (80%)] Loss: 19285.941406\n",
      "Train Epoch: 173 [182400/225000 (81%)] Loss: 18808.773438\n",
      "Train Epoch: 173 [184896/225000 (82%)] Loss: 19342.859375\n",
      "Train Epoch: 173 [187392/225000 (83%)] Loss: 19480.339844\n",
      "Train Epoch: 173 [189888/225000 (84%)] Loss: 19148.648438\n",
      "Train Epoch: 173 [192384/225000 (86%)] Loss: 18948.796875\n",
      "Train Epoch: 173 [194880/225000 (87%)] Loss: 19570.222656\n",
      "Train Epoch: 173 [197376/225000 (88%)] Loss: 18980.019531\n",
      "Train Epoch: 173 [199872/225000 (89%)] Loss: 18867.765625\n",
      "Train Epoch: 173 [202368/225000 (90%)] Loss: 18865.949219\n",
      "Train Epoch: 173 [204864/225000 (91%)] Loss: 19671.402344\n",
      "Train Epoch: 173 [207360/225000 (92%)] Loss: 18992.462891\n",
      "Train Epoch: 173 [209856/225000 (93%)] Loss: 19546.226562\n",
      "Train Epoch: 173 [212352/225000 (94%)] Loss: 19117.425781\n",
      "Train Epoch: 173 [214848/225000 (95%)] Loss: 19394.984375\n",
      "Train Epoch: 173 [217344/225000 (97%)] Loss: 19357.699219\n",
      "Train Epoch: 173 [219840/225000 (98%)] Loss: 19105.017578\n",
      "Train Epoch: 173 [222336/225000 (99%)] Loss: 19023.402344\n",
      "Train Epoch: 173 [224832/225000 (100%)] Loss: 19008.000000\n",
      "    epoch          : 173\n",
      "    loss           : 19171.215122053647\n",
      "    val_loss       : 19082.18542509179\n",
      "Train Epoch: 174 [192/225000 (0%)] Loss: 19165.458984\n",
      "Train Epoch: 174 [2688/225000 (1%)] Loss: 19299.074219\n",
      "Train Epoch: 174 [5184/225000 (2%)] Loss: 19404.751953\n",
      "Train Epoch: 174 [7680/225000 (3%)] Loss: 18860.146484\n",
      "Train Epoch: 174 [10176/225000 (5%)] Loss: 19027.687500\n",
      "Train Epoch: 174 [12672/225000 (6%)] Loss: 19292.283203\n",
      "Train Epoch: 174 [15168/225000 (7%)] Loss: 19814.564453\n",
      "Train Epoch: 174 [17664/225000 (8%)] Loss: 19131.925781\n",
      "Train Epoch: 174 [20160/225000 (9%)] Loss: 19241.175781\n",
      "Train Epoch: 174 [22656/225000 (10%)] Loss: 19273.472656\n",
      "Train Epoch: 174 [25152/225000 (11%)] Loss: 19255.912109\n",
      "Train Epoch: 174 [27648/225000 (12%)] Loss: 19089.748047\n",
      "Train Epoch: 174 [30144/225000 (13%)] Loss: 19035.042969\n",
      "Train Epoch: 174 [32640/225000 (15%)] Loss: 19647.261719\n",
      "Train Epoch: 174 [35136/225000 (16%)] Loss: 22600.576172\n",
      "Train Epoch: 174 [37632/225000 (17%)] Loss: 19478.144531\n",
      "Train Epoch: 174 [40128/225000 (18%)] Loss: 19049.812500\n",
      "Train Epoch: 174 [42624/225000 (19%)] Loss: 19100.738281\n",
      "Train Epoch: 174 [45120/225000 (20%)] Loss: 19178.294922\n",
      "Train Epoch: 174 [47616/225000 (21%)] Loss: 19128.300781\n",
      "Train Epoch: 174 [50112/225000 (22%)] Loss: 18926.828125\n",
      "Train Epoch: 174 [52608/225000 (23%)] Loss: 19240.240234\n",
      "Train Epoch: 174 [55104/225000 (24%)] Loss: 19194.656250\n",
      "Train Epoch: 174 [57600/225000 (26%)] Loss: 19251.128906\n",
      "Train Epoch: 174 [60096/225000 (27%)] Loss: 19274.601562\n",
      "Train Epoch: 174 [62592/225000 (28%)] Loss: 19004.460938\n",
      "Train Epoch: 174 [65088/225000 (29%)] Loss: 19075.414062\n",
      "Train Epoch: 174 [67584/225000 (30%)] Loss: 19500.945312\n",
      "Train Epoch: 174 [70080/225000 (31%)] Loss: 19520.595703\n",
      "Train Epoch: 174 [72576/225000 (32%)] Loss: 18824.250000\n",
      "Train Epoch: 174 [75072/225000 (33%)] Loss: 19100.078125\n",
      "Train Epoch: 174 [77568/225000 (34%)] Loss: 18990.160156\n",
      "Train Epoch: 174 [80064/225000 (36%)] Loss: 19062.654297\n",
      "Train Epoch: 174 [82560/225000 (37%)] Loss: 19504.972656\n",
      "Train Epoch: 174 [85056/225000 (38%)] Loss: 19439.431641\n",
      "Train Epoch: 174 [87552/225000 (39%)] Loss: 19261.746094\n",
      "Train Epoch: 174 [90048/225000 (40%)] Loss: 19199.839844\n",
      "Train Epoch: 174 [92544/225000 (41%)] Loss: 19194.617188\n",
      "Train Epoch: 174 [95040/225000 (42%)] Loss: 19351.640625\n",
      "Train Epoch: 174 [97536/225000 (43%)] Loss: 19354.351562\n",
      "Train Epoch: 174 [100032/225000 (44%)] Loss: 19361.591797\n",
      "Train Epoch: 174 [102528/225000 (46%)] Loss: 19170.976562\n",
      "Train Epoch: 174 [105024/225000 (47%)] Loss: 19301.898438\n",
      "Train Epoch: 174 [107520/225000 (48%)] Loss: 19249.109375\n",
      "Train Epoch: 174 [110016/225000 (49%)] Loss: 18978.449219\n",
      "Train Epoch: 174 [112512/225000 (50%)] Loss: 18415.121094\n",
      "Train Epoch: 174 [115008/225000 (51%)] Loss: 19181.603516\n",
      "Train Epoch: 174 [117504/225000 (52%)] Loss: 19565.283203\n",
      "Train Epoch: 174 [120000/225000 (53%)] Loss: 19594.453125\n",
      "Train Epoch: 174 [122496/225000 (54%)] Loss: 19025.824219\n",
      "Train Epoch: 174 [124992/225000 (56%)] Loss: 19401.697266\n",
      "Train Epoch: 174 [127488/225000 (57%)] Loss: 18809.361328\n",
      "Train Epoch: 174 [129984/225000 (58%)] Loss: 19050.751953\n",
      "Train Epoch: 174 [132480/225000 (59%)] Loss: 19242.746094\n",
      "Train Epoch: 174 [134976/225000 (60%)] Loss: 18777.853516\n",
      "Train Epoch: 174 [137472/225000 (61%)] Loss: 19221.416016\n",
      "Train Epoch: 174 [139968/225000 (62%)] Loss: 18814.636719\n",
      "Train Epoch: 174 [142464/225000 (63%)] Loss: 19087.925781\n",
      "Train Epoch: 174 [144960/225000 (64%)] Loss: 19503.109375\n",
      "Train Epoch: 174 [147456/225000 (66%)] Loss: 19368.091797\n",
      "Train Epoch: 174 [149952/225000 (67%)] Loss: 18932.671875\n",
      "Train Epoch: 174 [152448/225000 (68%)] Loss: 18801.636719\n",
      "Train Epoch: 174 [154944/225000 (69%)] Loss: 18772.148438\n",
      "Train Epoch: 174 [157440/225000 (70%)] Loss: 19159.755859\n",
      "Train Epoch: 174 [159936/225000 (71%)] Loss: 19178.718750\n",
      "Train Epoch: 174 [162432/225000 (72%)] Loss: 19390.486328\n",
      "Train Epoch: 174 [164928/225000 (73%)] Loss: 18873.707031\n",
      "Train Epoch: 174 [167424/225000 (74%)] Loss: 19006.738281\n",
      "Train Epoch: 174 [169920/225000 (76%)] Loss: 18973.806641\n",
      "Train Epoch: 174 [172416/225000 (77%)] Loss: 19542.365234\n",
      "Train Epoch: 174 [174912/225000 (78%)] Loss: 19105.787109\n",
      "Train Epoch: 174 [177408/225000 (79%)] Loss: 19454.761719\n",
      "Train Epoch: 174 [179904/225000 (80%)] Loss: 19381.345703\n",
      "Train Epoch: 174 [182400/225000 (81%)] Loss: 18885.304688\n",
      "Train Epoch: 174 [184896/225000 (82%)] Loss: 18370.992188\n",
      "Train Epoch: 174 [187392/225000 (83%)] Loss: 19611.078125\n",
      "Train Epoch: 174 [189888/225000 (84%)] Loss: 19398.210938\n",
      "Train Epoch: 174 [192384/225000 (86%)] Loss: 18970.613281\n",
      "Train Epoch: 174 [194880/225000 (87%)] Loss: 19125.699219\n",
      "Train Epoch: 174 [197376/225000 (88%)] Loss: 18760.000000\n",
      "Train Epoch: 174 [199872/225000 (89%)] Loss: 19346.867188\n",
      "Train Epoch: 174 [202368/225000 (90%)] Loss: 19195.960938\n",
      "Train Epoch: 174 [204864/225000 (91%)] Loss: 18962.091797\n",
      "Train Epoch: 174 [207360/225000 (92%)] Loss: 18809.332031\n",
      "Train Epoch: 174 [209856/225000 (93%)] Loss: 19084.210938\n",
      "Train Epoch: 174 [212352/225000 (94%)] Loss: 19168.710938\n",
      "Train Epoch: 174 [214848/225000 (95%)] Loss: 19306.152344\n",
      "Train Epoch: 174 [217344/225000 (97%)] Loss: 18967.019531\n",
      "Train Epoch: 174 [219840/225000 (98%)] Loss: 18541.726562\n",
      "Train Epoch: 174 [222336/225000 (99%)] Loss: 19368.982422\n",
      "Train Epoch: 174 [224832/225000 (100%)] Loss: 19370.755859\n",
      "    epoch          : 174\n",
      "    loss           : 19165.112101375853\n",
      "    val_loss       : 19101.74654637675\n",
      "Train Epoch: 175 [192/225000 (0%)] Loss: 19107.724609\n",
      "Train Epoch: 175 [2688/225000 (1%)] Loss: 19387.078125\n",
      "Train Epoch: 175 [5184/225000 (2%)] Loss: 19595.611328\n",
      "Train Epoch: 175 [7680/225000 (3%)] Loss: 19277.296875\n",
      "Train Epoch: 175 [10176/225000 (5%)] Loss: 18916.589844\n",
      "Train Epoch: 175 [12672/225000 (6%)] Loss: 19460.505859\n",
      "Train Epoch: 175 [15168/225000 (7%)] Loss: 19009.316406\n",
      "Train Epoch: 175 [17664/225000 (8%)] Loss: 19450.640625\n",
      "Train Epoch: 175 [20160/225000 (9%)] Loss: 19392.863281\n",
      "Train Epoch: 175 [22656/225000 (10%)] Loss: 19402.187500\n",
      "Train Epoch: 175 [25152/225000 (11%)] Loss: 19059.609375\n",
      "Train Epoch: 175 [27648/225000 (12%)] Loss: 19237.308594\n",
      "Train Epoch: 175 [30144/225000 (13%)] Loss: 18942.570312\n",
      "Train Epoch: 175 [32640/225000 (15%)] Loss: 19092.740234\n",
      "Train Epoch: 175 [35136/225000 (16%)] Loss: 19150.941406\n",
      "Train Epoch: 175 [37632/225000 (17%)] Loss: 19101.583984\n",
      "Train Epoch: 175 [40128/225000 (18%)] Loss: 19236.472656\n",
      "Train Epoch: 175 [42624/225000 (19%)] Loss: 19041.585938\n",
      "Train Epoch: 175 [45120/225000 (20%)] Loss: 19242.000000\n",
      "Train Epoch: 175 [47616/225000 (21%)] Loss: 19326.054688\n",
      "Train Epoch: 175 [50112/225000 (22%)] Loss: 24089.152344\n",
      "Train Epoch: 175 [52608/225000 (23%)] Loss: 19005.648438\n",
      "Train Epoch: 175 [55104/225000 (24%)] Loss: 18600.064453\n",
      "Train Epoch: 175 [57600/225000 (26%)] Loss: 19448.042969\n",
      "Train Epoch: 175 [60096/225000 (27%)] Loss: 19381.078125\n",
      "Train Epoch: 175 [62592/225000 (28%)] Loss: 19046.425781\n",
      "Train Epoch: 175 [65088/225000 (29%)] Loss: 19100.527344\n",
      "Train Epoch: 175 [67584/225000 (30%)] Loss: 19009.871094\n",
      "Train Epoch: 175 [70080/225000 (31%)] Loss: 19202.007812\n",
      "Train Epoch: 175 [72576/225000 (32%)] Loss: 18622.285156\n",
      "Train Epoch: 175 [75072/225000 (33%)] Loss: 19408.701172\n",
      "Train Epoch: 175 [77568/225000 (34%)] Loss: 19423.796875\n",
      "Train Epoch: 175 [80064/225000 (36%)] Loss: 19122.164062\n",
      "Train Epoch: 175 [82560/225000 (37%)] Loss: 19426.046875\n",
      "Train Epoch: 175 [85056/225000 (38%)] Loss: 18842.041016\n",
      "Train Epoch: 175 [87552/225000 (39%)] Loss: 19042.304688\n",
      "Train Epoch: 175 [90048/225000 (40%)] Loss: 19873.984375\n",
      "Train Epoch: 175 [92544/225000 (41%)] Loss: 19160.527344\n",
      "Train Epoch: 175 [95040/225000 (42%)] Loss: 19161.890625\n",
      "Train Epoch: 175 [97536/225000 (43%)] Loss: 19089.554688\n",
      "Train Epoch: 175 [100032/225000 (44%)] Loss: 19298.257812\n",
      "Train Epoch: 175 [102528/225000 (46%)] Loss: 19125.480469\n",
      "Train Epoch: 175 [105024/225000 (47%)] Loss: 19337.195312\n",
      "Train Epoch: 175 [107520/225000 (48%)] Loss: 19146.167969\n",
      "Train Epoch: 175 [110016/225000 (49%)] Loss: 19434.664062\n",
      "Train Epoch: 175 [112512/225000 (50%)] Loss: 19023.214844\n",
      "Train Epoch: 175 [115008/225000 (51%)] Loss: 18984.257812\n",
      "Train Epoch: 175 [117504/225000 (52%)] Loss: 18936.294922\n",
      "Train Epoch: 175 [120000/225000 (53%)] Loss: 19018.843750\n",
      "Train Epoch: 175 [122496/225000 (54%)] Loss: 19368.193359\n",
      "Train Epoch: 175 [124992/225000 (56%)] Loss: 19105.660156\n",
      "Train Epoch: 175 [127488/225000 (57%)] Loss: 18841.070312\n",
      "Train Epoch: 175 [129984/225000 (58%)] Loss: 19265.486328\n",
      "Train Epoch: 175 [132480/225000 (59%)] Loss: 19218.703125\n",
      "Train Epoch: 175 [134976/225000 (60%)] Loss: 19252.191406\n",
      "Train Epoch: 175 [137472/225000 (61%)] Loss: 18936.048828\n",
      "Train Epoch: 175 [139968/225000 (62%)] Loss: 19513.517578\n",
      "Train Epoch: 175 [142464/225000 (63%)] Loss: 18943.675781\n",
      "Train Epoch: 175 [144960/225000 (64%)] Loss: 18782.306641\n",
      "Train Epoch: 175 [147456/225000 (66%)] Loss: 19423.191406\n",
      "Train Epoch: 175 [149952/225000 (67%)] Loss: 19683.601562\n",
      "Train Epoch: 175 [152448/225000 (68%)] Loss: 19384.947266\n",
      "Train Epoch: 175 [154944/225000 (69%)] Loss: 19231.691406\n",
      "Train Epoch: 175 [157440/225000 (70%)] Loss: 18858.779297\n",
      "Train Epoch: 175 [159936/225000 (71%)] Loss: 19346.189453\n",
      "Train Epoch: 175 [162432/225000 (72%)] Loss: 19168.972656\n",
      "Train Epoch: 175 [164928/225000 (73%)] Loss: 19364.333984\n",
      "Train Epoch: 175 [167424/225000 (74%)] Loss: 19073.722656\n",
      "Train Epoch: 175 [169920/225000 (76%)] Loss: 18908.554688\n",
      "Train Epoch: 175 [172416/225000 (77%)] Loss: 19146.193359\n",
      "Train Epoch: 175 [174912/225000 (78%)] Loss: 19495.033203\n",
      "Train Epoch: 175 [177408/225000 (79%)] Loss: 18971.597656\n",
      "Train Epoch: 175 [179904/225000 (80%)] Loss: 19072.490234\n",
      "Train Epoch: 175 [182400/225000 (81%)] Loss: 19325.324219\n",
      "Train Epoch: 175 [184896/225000 (82%)] Loss: 19162.089844\n",
      "Train Epoch: 175 [187392/225000 (83%)] Loss: 19195.791016\n",
      "Train Epoch: 175 [189888/225000 (84%)] Loss: 19082.742188\n",
      "Train Epoch: 175 [192384/225000 (86%)] Loss: 18628.742188\n",
      "Train Epoch: 175 [194880/225000 (87%)] Loss: 19275.617188\n",
      "Train Epoch: 175 [197376/225000 (88%)] Loss: 19124.419922\n",
      "Train Epoch: 175 [199872/225000 (89%)] Loss: 19033.281250\n",
      "Train Epoch: 175 [202368/225000 (90%)] Loss: 18818.171875\n",
      "Train Epoch: 175 [204864/225000 (91%)] Loss: 19017.212891\n",
      "Train Epoch: 175 [207360/225000 (92%)] Loss: 18812.132812\n",
      "Train Epoch: 175 [209856/225000 (93%)] Loss: 18908.621094\n",
      "Train Epoch: 175 [212352/225000 (94%)] Loss: 18990.376953\n",
      "Train Epoch: 175 [214848/225000 (95%)] Loss: 19078.167969\n",
      "Train Epoch: 175 [217344/225000 (97%)] Loss: 19166.722656\n",
      "Train Epoch: 175 [219840/225000 (98%)] Loss: 19305.435547\n",
      "Train Epoch: 175 [222336/225000 (99%)] Loss: 19231.875000\n",
      "Train Epoch: 175 [224832/225000 (100%)] Loss: 19668.828125\n",
      "    epoch          : 175\n",
      "    loss           : 19164.17503632946\n",
      "    val_loss       : 19107.009150774426\n",
      "Train Epoch: 176 [192/225000 (0%)] Loss: 19526.035156\n",
      "Train Epoch: 176 [2688/225000 (1%)] Loss: 19363.791016\n",
      "Train Epoch: 176 [5184/225000 (2%)] Loss: 19055.808594\n",
      "Train Epoch: 176 [7680/225000 (3%)] Loss: 18701.625000\n",
      "Train Epoch: 176 [10176/225000 (5%)] Loss: 19616.316406\n",
      "Train Epoch: 176 [12672/225000 (6%)] Loss: 18940.376953\n",
      "Train Epoch: 176 [15168/225000 (7%)] Loss: 19032.386719\n",
      "Train Epoch: 176 [17664/225000 (8%)] Loss: 19667.332031\n",
      "Train Epoch: 176 [20160/225000 (9%)] Loss: 18984.134766\n",
      "Train Epoch: 176 [22656/225000 (10%)] Loss: 19463.035156\n",
      "Train Epoch: 176 [25152/225000 (11%)] Loss: 19769.169922\n",
      "Train Epoch: 176 [27648/225000 (12%)] Loss: 18712.562500\n",
      "Train Epoch: 176 [30144/225000 (13%)] Loss: 19142.070312\n",
      "Train Epoch: 176 [32640/225000 (15%)] Loss: 19187.085938\n",
      "Train Epoch: 176 [35136/225000 (16%)] Loss: 19428.769531\n",
      "Train Epoch: 176 [37632/225000 (17%)] Loss: 19072.421875\n",
      "Train Epoch: 176 [40128/225000 (18%)] Loss: 18934.542969\n",
      "Train Epoch: 176 [42624/225000 (19%)] Loss: 19061.421875\n",
      "Train Epoch: 176 [45120/225000 (20%)] Loss: 19360.871094\n",
      "Train Epoch: 176 [47616/225000 (21%)] Loss: 18948.056641\n",
      "Train Epoch: 176 [50112/225000 (22%)] Loss: 18951.964844\n",
      "Train Epoch: 176 [52608/225000 (23%)] Loss: 18676.300781\n",
      "Train Epoch: 176 [55104/225000 (24%)] Loss: 19440.207031\n",
      "Train Epoch: 176 [57600/225000 (26%)] Loss: 18692.220703\n",
      "Train Epoch: 176 [60096/225000 (27%)] Loss: 18868.507812\n",
      "Train Epoch: 176 [62592/225000 (28%)] Loss: 19119.789062\n",
      "Train Epoch: 176 [65088/225000 (29%)] Loss: 19367.582031\n",
      "Train Epoch: 176 [67584/225000 (30%)] Loss: 19291.662109\n",
      "Train Epoch: 176 [70080/225000 (31%)] Loss: 19095.218750\n",
      "Train Epoch: 176 [72576/225000 (32%)] Loss: 19333.234375\n",
      "Train Epoch: 176 [75072/225000 (33%)] Loss: 18957.121094\n",
      "Train Epoch: 176 [77568/225000 (34%)] Loss: 18699.066406\n",
      "Train Epoch: 176 [80064/225000 (36%)] Loss: 19169.468750\n",
      "Train Epoch: 176 [82560/225000 (37%)] Loss: 19162.828125\n",
      "Train Epoch: 176 [85056/225000 (38%)] Loss: 19593.927734\n",
      "Train Epoch: 176 [87552/225000 (39%)] Loss: 18872.548828\n",
      "Train Epoch: 176 [90048/225000 (40%)] Loss: 19404.455078\n",
      "Train Epoch: 176 [92544/225000 (41%)] Loss: 18474.953125\n",
      "Train Epoch: 176 [95040/225000 (42%)] Loss: 18910.857422\n",
      "Train Epoch: 176 [97536/225000 (43%)] Loss: 19054.601562\n",
      "Train Epoch: 176 [100032/225000 (44%)] Loss: 18948.894531\n",
      "Train Epoch: 176 [102528/225000 (46%)] Loss: 19837.601562\n",
      "Train Epoch: 176 [105024/225000 (47%)] Loss: 18904.218750\n",
      "Train Epoch: 176 [107520/225000 (48%)] Loss: 18953.548828\n",
      "Train Epoch: 176 [110016/225000 (49%)] Loss: 19387.312500\n",
      "Train Epoch: 176 [112512/225000 (50%)] Loss: 19374.800781\n",
      "Train Epoch: 176 [115008/225000 (51%)] Loss: 19470.085938\n",
      "Train Epoch: 176 [117504/225000 (52%)] Loss: 19101.851562\n",
      "Train Epoch: 176 [120000/225000 (53%)] Loss: 19222.742188\n",
      "Train Epoch: 176 [122496/225000 (54%)] Loss: 18678.296875\n",
      "Train Epoch: 176 [124992/225000 (56%)] Loss: 19043.587891\n",
      "Train Epoch: 176 [127488/225000 (57%)] Loss: 19462.363281\n",
      "Train Epoch: 176 [129984/225000 (58%)] Loss: 19111.587891\n",
      "Train Epoch: 176 [132480/225000 (59%)] Loss: 19329.064453\n",
      "Train Epoch: 176 [134976/225000 (60%)] Loss: 18985.429688\n",
      "Train Epoch: 176 [137472/225000 (61%)] Loss: 18980.992188\n",
      "Train Epoch: 176 [139968/225000 (62%)] Loss: 19637.597656\n",
      "Train Epoch: 176 [142464/225000 (63%)] Loss: 19550.808594\n",
      "Train Epoch: 176 [144960/225000 (64%)] Loss: 19125.337891\n",
      "Train Epoch: 176 [147456/225000 (66%)] Loss: 18891.769531\n",
      "Train Epoch: 176 [149952/225000 (67%)] Loss: 19069.839844\n",
      "Train Epoch: 176 [152448/225000 (68%)] Loss: 19023.242188\n",
      "Train Epoch: 176 [154944/225000 (69%)] Loss: 19250.605469\n",
      "Train Epoch: 176 [157440/225000 (70%)] Loss: 19672.054688\n",
      "Train Epoch: 176 [159936/225000 (71%)] Loss: 18976.910156\n",
      "Train Epoch: 176 [162432/225000 (72%)] Loss: 19275.087891\n",
      "Train Epoch: 176 [164928/225000 (73%)] Loss: 19243.753906\n",
      "Train Epoch: 176 [167424/225000 (74%)] Loss: 19560.199219\n",
      "Train Epoch: 176 [169920/225000 (76%)] Loss: 19111.542969\n",
      "Train Epoch: 176 [172416/225000 (77%)] Loss: 19204.472656\n",
      "Train Epoch: 176 [174912/225000 (78%)] Loss: 19265.812500\n",
      "Train Epoch: 176 [177408/225000 (79%)] Loss: 19190.816406\n",
      "Train Epoch: 176 [179904/225000 (80%)] Loss: 19019.828125\n",
      "Train Epoch: 176 [182400/225000 (81%)] Loss: 19249.667969\n",
      "Train Epoch: 176 [184896/225000 (82%)] Loss: 19395.398438\n",
      "Train Epoch: 176 [187392/225000 (83%)] Loss: 18665.076172\n",
      "Train Epoch: 176 [189888/225000 (84%)] Loss: 18889.285156\n",
      "Train Epoch: 176 [192384/225000 (86%)] Loss: 18477.921875\n",
      "Train Epoch: 176 [194880/225000 (87%)] Loss: 19185.892578\n",
      "Train Epoch: 176 [197376/225000 (88%)] Loss: 19413.261719\n",
      "Train Epoch: 176 [199872/225000 (89%)] Loss: 18760.404297\n",
      "Train Epoch: 176 [202368/225000 (90%)] Loss: 19326.371094\n",
      "Train Epoch: 176 [204864/225000 (91%)] Loss: 19045.847656\n",
      "Train Epoch: 176 [207360/225000 (92%)] Loss: 19359.906250\n",
      "Train Epoch: 176 [209856/225000 (93%)] Loss: 19214.710938\n",
      "Train Epoch: 176 [212352/225000 (94%)] Loss: 19319.417969\n",
      "Train Epoch: 176 [214848/225000 (95%)] Loss: 19063.000000\n",
      "Train Epoch: 176 [217344/225000 (97%)] Loss: 19204.654297\n",
      "Train Epoch: 176 [219840/225000 (98%)] Loss: 18923.138672\n",
      "Train Epoch: 176 [222336/225000 (99%)] Loss: 18997.574219\n",
      "Train Epoch: 176 [224832/225000 (100%)] Loss: 18891.027344\n",
      "    epoch          : 176\n",
      "    loss           : 19151.93609681634\n",
      "    val_loss       : 19066.997080204143\n",
      "Train Epoch: 177 [192/225000 (0%)] Loss: 18932.000000\n",
      "Train Epoch: 177 [2688/225000 (1%)] Loss: 19141.033203\n",
      "Train Epoch: 177 [5184/225000 (2%)] Loss: 18487.214844\n",
      "Train Epoch: 177 [7680/225000 (3%)] Loss: 19176.017578\n",
      "Train Epoch: 177 [10176/225000 (5%)] Loss: 18978.195312\n",
      "Train Epoch: 177 [12672/225000 (6%)] Loss: 19745.986328\n",
      "Train Epoch: 177 [15168/225000 (7%)] Loss: 18833.691406\n",
      "Train Epoch: 177 [17664/225000 (8%)] Loss: 19032.011719\n",
      "Train Epoch: 177 [20160/225000 (9%)] Loss: 18904.527344\n",
      "Train Epoch: 177 [22656/225000 (10%)] Loss: 19534.986328\n",
      "Train Epoch: 177 [25152/225000 (11%)] Loss: 19265.220703\n",
      "Train Epoch: 177 [27648/225000 (12%)] Loss: 19221.453125\n",
      "Train Epoch: 177 [30144/225000 (13%)] Loss: 19417.867188\n",
      "Train Epoch: 177 [32640/225000 (15%)] Loss: 19094.941406\n",
      "Train Epoch: 177 [35136/225000 (16%)] Loss: 19079.117188\n",
      "Train Epoch: 177 [37632/225000 (17%)] Loss: 18941.216797\n",
      "Train Epoch: 177 [40128/225000 (18%)] Loss: 19219.251953\n",
      "Train Epoch: 177 [42624/225000 (19%)] Loss: 19412.632812\n",
      "Train Epoch: 177 [45120/225000 (20%)] Loss: 19060.927734\n",
      "Train Epoch: 177 [47616/225000 (21%)] Loss: 18811.433594\n",
      "Train Epoch: 177 [50112/225000 (22%)] Loss: 19322.179688\n",
      "Train Epoch: 177 [52608/225000 (23%)] Loss: 18861.035156\n",
      "Train Epoch: 177 [55104/225000 (24%)] Loss: 19092.773438\n",
      "Train Epoch: 177 [57600/225000 (26%)] Loss: 18963.253906\n",
      "Train Epoch: 177 [60096/225000 (27%)] Loss: 19086.875000\n",
      "Train Epoch: 177 [62592/225000 (28%)] Loss: 19497.316406\n",
      "Train Epoch: 177 [65088/225000 (29%)] Loss: 18839.841797\n",
      "Train Epoch: 177 [67584/225000 (30%)] Loss: 19105.609375\n",
      "Train Epoch: 177 [70080/225000 (31%)] Loss: 19275.097656\n",
      "Train Epoch: 177 [72576/225000 (32%)] Loss: 19209.519531\n",
      "Train Epoch: 177 [75072/225000 (33%)] Loss: 19324.574219\n",
      "Train Epoch: 177 [77568/225000 (34%)] Loss: 18888.240234\n",
      "Train Epoch: 177 [80064/225000 (36%)] Loss: 18861.011719\n",
      "Train Epoch: 177 [82560/225000 (37%)] Loss: 19576.382812\n",
      "Train Epoch: 177 [85056/225000 (38%)] Loss: 19370.761719\n",
      "Train Epoch: 177 [87552/225000 (39%)] Loss: 19606.703125\n",
      "Train Epoch: 177 [90048/225000 (40%)] Loss: 19697.566406\n",
      "Train Epoch: 177 [92544/225000 (41%)] Loss: 19149.285156\n",
      "Train Epoch: 177 [95040/225000 (42%)] Loss: 19033.625000\n",
      "Train Epoch: 177 [97536/225000 (43%)] Loss: 19148.902344\n",
      "Train Epoch: 177 [100032/225000 (44%)] Loss: 19051.886719\n",
      "Train Epoch: 177 [102528/225000 (46%)] Loss: 18988.746094\n",
      "Train Epoch: 177 [105024/225000 (47%)] Loss: 19075.273438\n",
      "Train Epoch: 177 [107520/225000 (48%)] Loss: 18687.257812\n",
      "Train Epoch: 177 [110016/225000 (49%)] Loss: 19666.009766\n",
      "Train Epoch: 177 [112512/225000 (50%)] Loss: 19612.791016\n",
      "Train Epoch: 177 [115008/225000 (51%)] Loss: 19088.175781\n",
      "Train Epoch: 177 [117504/225000 (52%)] Loss: 19111.199219\n",
      "Train Epoch: 177 [120000/225000 (53%)] Loss: 19141.628906\n",
      "Train Epoch: 177 [122496/225000 (54%)] Loss: 19702.554688\n",
      "Train Epoch: 177 [124992/225000 (56%)] Loss: 19597.433594\n",
      "Train Epoch: 177 [127488/225000 (57%)] Loss: 19017.992188\n",
      "Train Epoch: 177 [129984/225000 (58%)] Loss: 18671.953125\n",
      "Train Epoch: 177 [132480/225000 (59%)] Loss: 19076.947266\n",
      "Train Epoch: 177 [134976/225000 (60%)] Loss: 19087.820312\n",
      "Train Epoch: 177 [137472/225000 (61%)] Loss: 19026.445312\n",
      "Train Epoch: 177 [139968/225000 (62%)] Loss: 19233.332031\n",
      "Train Epoch: 177 [142464/225000 (63%)] Loss: 18932.814453\n",
      "Train Epoch: 177 [144960/225000 (64%)] Loss: 19135.351562\n",
      "Train Epoch: 177 [147456/225000 (66%)] Loss: 18813.837891\n",
      "Train Epoch: 177 [149952/225000 (67%)] Loss: 19376.906250\n",
      "Train Epoch: 177 [152448/225000 (68%)] Loss: 19305.238281\n",
      "Train Epoch: 177 [154944/225000 (69%)] Loss: 19062.816406\n",
      "Train Epoch: 177 [157440/225000 (70%)] Loss: 18876.437500\n",
      "Train Epoch: 177 [159936/225000 (71%)] Loss: 19428.695312\n",
      "Train Epoch: 177 [162432/225000 (72%)] Loss: 19396.421875\n",
      "Train Epoch: 177 [164928/225000 (73%)] Loss: 19304.925781\n",
      "Train Epoch: 177 [167424/225000 (74%)] Loss: 18893.537109\n",
      "Train Epoch: 177 [169920/225000 (76%)] Loss: 18892.902344\n",
      "Train Epoch: 177 [172416/225000 (77%)] Loss: 19128.962891\n",
      "Train Epoch: 177 [174912/225000 (78%)] Loss: 18828.326172\n",
      "Train Epoch: 177 [177408/225000 (79%)] Loss: 19387.080078\n",
      "Train Epoch: 177 [179904/225000 (80%)] Loss: 19266.140625\n",
      "Train Epoch: 177 [182400/225000 (81%)] Loss: 19068.156250\n",
      "Train Epoch: 177 [184896/225000 (82%)] Loss: 19074.621094\n",
      "Train Epoch: 177 [187392/225000 (83%)] Loss: 19025.191406\n",
      "Train Epoch: 177 [189888/225000 (84%)] Loss: 18988.054688\n",
      "Train Epoch: 177 [192384/225000 (86%)] Loss: 18551.626953\n",
      "Train Epoch: 177 [194880/225000 (87%)] Loss: 19076.496094\n",
      "Train Epoch: 177 [197376/225000 (88%)] Loss: 19573.125000\n",
      "Train Epoch: 177 [199872/225000 (89%)] Loss: 19007.093750\n",
      "Train Epoch: 177 [202368/225000 (90%)] Loss: 18926.171875\n",
      "Train Epoch: 177 [204864/225000 (91%)] Loss: 19082.667969\n",
      "Train Epoch: 177 [207360/225000 (92%)] Loss: 19710.462891\n",
      "Train Epoch: 177 [209856/225000 (93%)] Loss: 19081.816406\n",
      "Train Epoch: 177 [212352/225000 (94%)] Loss: 19026.988281\n",
      "Train Epoch: 177 [214848/225000 (95%)] Loss: 19057.101562\n",
      "Train Epoch: 177 [217344/225000 (97%)] Loss: 18963.238281\n",
      "Train Epoch: 177 [219840/225000 (98%)] Loss: 18965.523438\n",
      "Train Epoch: 177 [222336/225000 (99%)] Loss: 19271.925781\n",
      "Train Epoch: 177 [224832/225000 (100%)] Loss: 19250.738281\n",
      "    epoch          : 177\n",
      "    loss           : 19138.526087217364\n",
      "    val_loss       : 19034.671624487593\n",
      "Train Epoch: 178 [192/225000 (0%)] Loss: 18861.457031\n",
      "Train Epoch: 178 [2688/225000 (1%)] Loss: 19696.226562\n",
      "Train Epoch: 178 [5184/225000 (2%)] Loss: 19227.625000\n",
      "Train Epoch: 178 [7680/225000 (3%)] Loss: 19044.304688\n",
      "Train Epoch: 178 [10176/225000 (5%)] Loss: 19491.664062\n",
      "Train Epoch: 178 [12672/225000 (6%)] Loss: 18994.744141\n",
      "Train Epoch: 178 [15168/225000 (7%)] Loss: 19578.859375\n",
      "Train Epoch: 178 [17664/225000 (8%)] Loss: 19674.472656\n",
      "Train Epoch: 178 [20160/225000 (9%)] Loss: 19924.105469\n",
      "Train Epoch: 178 [22656/225000 (10%)] Loss: 19823.675781\n",
      "Train Epoch: 178 [25152/225000 (11%)] Loss: 18857.191406\n",
      "Train Epoch: 178 [27648/225000 (12%)] Loss: 19231.292969\n",
      "Train Epoch: 178 [30144/225000 (13%)] Loss: 19439.875000\n",
      "Train Epoch: 178 [32640/225000 (15%)] Loss: 19253.980469\n",
      "Train Epoch: 178 [35136/225000 (16%)] Loss: 19073.460938\n",
      "Train Epoch: 178 [37632/225000 (17%)] Loss: 18913.537109\n",
      "Train Epoch: 178 [40128/225000 (18%)] Loss: 19159.429688\n",
      "Train Epoch: 178 [42624/225000 (19%)] Loss: 18941.753906\n",
      "Train Epoch: 178 [45120/225000 (20%)] Loss: 19241.011719\n",
      "Train Epoch: 178 [47616/225000 (21%)] Loss: 18946.691406\n",
      "Train Epoch: 178 [50112/225000 (22%)] Loss: 19644.515625\n",
      "Train Epoch: 178 [52608/225000 (23%)] Loss: 18727.722656\n",
      "Train Epoch: 178 [55104/225000 (24%)] Loss: 19189.558594\n",
      "Train Epoch: 178 [57600/225000 (26%)] Loss: 19050.078125\n",
      "Train Epoch: 178 [60096/225000 (27%)] Loss: 19088.972656\n",
      "Train Epoch: 178 [62592/225000 (28%)] Loss: 18838.449219\n",
      "Train Epoch: 178 [65088/225000 (29%)] Loss: 19265.916016\n",
      "Train Epoch: 178 [67584/225000 (30%)] Loss: 19771.164062\n",
      "Train Epoch: 178 [70080/225000 (31%)] Loss: 19282.541016\n",
      "Train Epoch: 178 [72576/225000 (32%)] Loss: 19286.511719\n",
      "Train Epoch: 178 [75072/225000 (33%)] Loss: 19576.859375\n",
      "Train Epoch: 178 [77568/225000 (34%)] Loss: 19498.707031\n",
      "Train Epoch: 178 [80064/225000 (36%)] Loss: 18879.406250\n",
      "Train Epoch: 178 [82560/225000 (37%)] Loss: 19123.484375\n",
      "Train Epoch: 178 [85056/225000 (38%)] Loss: 18871.406250\n",
      "Train Epoch: 178 [87552/225000 (39%)] Loss: 19355.582031\n",
      "Train Epoch: 178 [90048/225000 (40%)] Loss: 18968.855469\n",
      "Train Epoch: 178 [92544/225000 (41%)] Loss: 19292.175781\n",
      "Train Epoch: 178 [95040/225000 (42%)] Loss: 19135.634766\n",
      "Train Epoch: 178 [97536/225000 (43%)] Loss: 19124.806641\n",
      "Train Epoch: 178 [100032/225000 (44%)] Loss: 18971.369141\n",
      "Train Epoch: 178 [102528/225000 (46%)] Loss: 18949.736328\n",
      "Train Epoch: 178 [105024/225000 (47%)] Loss: 18996.277344\n",
      "Train Epoch: 178 [107520/225000 (48%)] Loss: 18750.335938\n",
      "Train Epoch: 178 [110016/225000 (49%)] Loss: 19554.699219\n",
      "Train Epoch: 178 [112512/225000 (50%)] Loss: 18879.273438\n",
      "Train Epoch: 178 [115008/225000 (51%)] Loss: 19143.710938\n",
      "Train Epoch: 178 [117504/225000 (52%)] Loss: 19380.742188\n",
      "Train Epoch: 178 [120000/225000 (53%)] Loss: 19076.277344\n",
      "Train Epoch: 178 [122496/225000 (54%)] Loss: 19292.207031\n",
      "Train Epoch: 178 [124992/225000 (56%)] Loss: 19511.496094\n",
      "Train Epoch: 178 [127488/225000 (57%)] Loss: 19119.902344\n",
      "Train Epoch: 178 [129984/225000 (58%)] Loss: 19773.457031\n",
      "Train Epoch: 178 [132480/225000 (59%)] Loss: 19230.019531\n",
      "Train Epoch: 178 [134976/225000 (60%)] Loss: 18870.093750\n",
      "Train Epoch: 178 [137472/225000 (61%)] Loss: 19094.171875\n",
      "Train Epoch: 178 [139968/225000 (62%)] Loss: 19235.685547\n",
      "Train Epoch: 178 [142464/225000 (63%)] Loss: 19303.437500\n",
      "Train Epoch: 178 [144960/225000 (64%)] Loss: 19277.343750\n",
      "Train Epoch: 178 [147456/225000 (66%)] Loss: 19147.623047\n",
      "Train Epoch: 178 [149952/225000 (67%)] Loss: 18990.214844\n",
      "Train Epoch: 178 [152448/225000 (68%)] Loss: 19202.312500\n",
      "Train Epoch: 178 [154944/225000 (69%)] Loss: 19386.681641\n",
      "Train Epoch: 178 [157440/225000 (70%)] Loss: 19117.281250\n",
      "Train Epoch: 178 [159936/225000 (71%)] Loss: 19007.212891\n",
      "Train Epoch: 178 [162432/225000 (72%)] Loss: 19145.726562\n",
      "Train Epoch: 178 [164928/225000 (73%)] Loss: 18995.552734\n",
      "Train Epoch: 178 [167424/225000 (74%)] Loss: 18968.576172\n",
      "Train Epoch: 178 [169920/225000 (76%)] Loss: 18758.048828\n",
      "Train Epoch: 178 [172416/225000 (77%)] Loss: 19393.134766\n",
      "Train Epoch: 178 [174912/225000 (78%)] Loss: 19041.199219\n",
      "Train Epoch: 178 [177408/225000 (79%)] Loss: 19349.298828\n",
      "Train Epoch: 178 [179904/225000 (80%)] Loss: 19321.589844\n",
      "Train Epoch: 178 [182400/225000 (81%)] Loss: 18817.816406\n",
      "Train Epoch: 178 [184896/225000 (82%)] Loss: 19225.908203\n",
      "Train Epoch: 178 [187392/225000 (83%)] Loss: 19314.091797\n",
      "Train Epoch: 178 [189888/225000 (84%)] Loss: 19613.988281\n",
      "Train Epoch: 178 [192384/225000 (86%)] Loss: 19426.628906\n",
      "Train Epoch: 178 [194880/225000 (87%)] Loss: 18902.447266\n",
      "Train Epoch: 178 [197376/225000 (88%)] Loss: 18887.414062\n",
      "Train Epoch: 178 [199872/225000 (89%)] Loss: 19141.589844\n",
      "Train Epoch: 178 [202368/225000 (90%)] Loss: 19167.574219\n",
      "Train Epoch: 178 [204864/225000 (91%)] Loss: 19144.800781\n",
      "Train Epoch: 178 [207360/225000 (92%)] Loss: 19533.068359\n",
      "Train Epoch: 178 [209856/225000 (93%)] Loss: 19145.835938\n",
      "Train Epoch: 178 [212352/225000 (94%)] Loss: 18961.425781\n",
      "Train Epoch: 178 [214848/225000 (95%)] Loss: 19414.482422\n",
      "Train Epoch: 178 [217344/225000 (97%)] Loss: 18814.148438\n",
      "Train Epoch: 178 [219840/225000 (98%)] Loss: 18993.628906\n",
      "Train Epoch: 178 [222336/225000 (99%)] Loss: 19265.257812\n",
      "Train Epoch: 178 [224832/225000 (100%)] Loss: 18740.253906\n",
      "    epoch          : 178\n",
      "    loss           : 19129.748201858467\n",
      "    val_loss       : 19022.642317049376\n",
      "Train Epoch: 179 [192/225000 (0%)] Loss: 18876.097656\n",
      "Train Epoch: 179 [2688/225000 (1%)] Loss: 19208.615234\n",
      "Train Epoch: 179 [5184/225000 (2%)] Loss: 19197.507812\n",
      "Train Epoch: 179 [7680/225000 (3%)] Loss: 19317.890625\n",
      "Train Epoch: 179 [10176/225000 (5%)] Loss: 18604.468750\n",
      "Train Epoch: 179 [12672/225000 (6%)] Loss: 19621.683594\n",
      "Train Epoch: 179 [15168/225000 (7%)] Loss: 18989.433594\n",
      "Train Epoch: 179 [17664/225000 (8%)] Loss: 19098.011719\n",
      "Train Epoch: 179 [20160/225000 (9%)] Loss: 19378.775391\n",
      "Train Epoch: 179 [22656/225000 (10%)] Loss: 19358.753906\n",
      "Train Epoch: 179 [25152/225000 (11%)] Loss: 19822.037109\n",
      "Train Epoch: 179 [27648/225000 (12%)] Loss: 19021.449219\n",
      "Train Epoch: 179 [30144/225000 (13%)] Loss: 19022.542969\n",
      "Train Epoch: 179 [32640/225000 (15%)] Loss: 19131.283203\n",
      "Train Epoch: 179 [35136/225000 (16%)] Loss: 19351.933594\n",
      "Train Epoch: 179 [37632/225000 (17%)] Loss: 18920.722656\n",
      "Train Epoch: 179 [40128/225000 (18%)] Loss: 18583.242188\n",
      "Train Epoch: 179 [42624/225000 (19%)] Loss: 18940.238281\n",
      "Train Epoch: 179 [45120/225000 (20%)] Loss: 19194.261719\n",
      "Train Epoch: 179 [47616/225000 (21%)] Loss: 19293.009766\n",
      "Train Epoch: 179 [50112/225000 (22%)] Loss: 18863.638672\n",
      "Train Epoch: 179 [52608/225000 (23%)] Loss: 19113.166016\n",
      "Train Epoch: 179 [55104/225000 (24%)] Loss: 19243.310547\n",
      "Train Epoch: 179 [57600/225000 (26%)] Loss: 19311.785156\n",
      "Train Epoch: 179 [60096/225000 (27%)] Loss: 18826.750000\n",
      "Train Epoch: 179 [62592/225000 (28%)] Loss: 19303.162109\n",
      "Train Epoch: 179 [65088/225000 (29%)] Loss: 19275.820312\n",
      "Train Epoch: 179 [67584/225000 (30%)] Loss: 18966.562500\n",
      "Train Epoch: 179 [70080/225000 (31%)] Loss: 18973.519531\n",
      "Train Epoch: 179 [72576/225000 (32%)] Loss: 19140.367188\n",
      "Train Epoch: 179 [75072/225000 (33%)] Loss: 18764.453125\n",
      "Train Epoch: 179 [77568/225000 (34%)] Loss: 19624.972656\n",
      "Train Epoch: 179 [80064/225000 (36%)] Loss: 19555.566406\n",
      "Train Epoch: 179 [82560/225000 (37%)] Loss: 19095.187500\n",
      "Train Epoch: 179 [85056/225000 (38%)] Loss: 18526.650391\n",
      "Train Epoch: 179 [87552/225000 (39%)] Loss: 18538.062500\n",
      "Train Epoch: 179 [90048/225000 (40%)] Loss: 19115.277344\n",
      "Train Epoch: 179 [92544/225000 (41%)] Loss: 19032.679688\n",
      "Train Epoch: 179 [95040/225000 (42%)] Loss: 19098.998047\n",
      "Train Epoch: 179 [97536/225000 (43%)] Loss: 19181.101562\n",
      "Train Epoch: 179 [100032/225000 (44%)] Loss: 18864.613281\n",
      "Train Epoch: 179 [102528/225000 (46%)] Loss: 19284.652344\n",
      "Train Epoch: 179 [105024/225000 (47%)] Loss: 19046.753906\n",
      "Train Epoch: 179 [107520/225000 (48%)] Loss: 18957.212891\n",
      "Train Epoch: 179 [110016/225000 (49%)] Loss: 18958.558594\n",
      "Train Epoch: 179 [112512/225000 (50%)] Loss: 19435.550781\n",
      "Train Epoch: 179 [115008/225000 (51%)] Loss: 19306.691406\n",
      "Train Epoch: 179 [117504/225000 (52%)] Loss: 18584.011719\n",
      "Train Epoch: 179 [120000/225000 (53%)] Loss: 18910.664062\n",
      "Train Epoch: 179 [122496/225000 (54%)] Loss: 19114.808594\n",
      "Train Epoch: 179 [124992/225000 (56%)] Loss: 19084.931641\n",
      "Train Epoch: 179 [127488/225000 (57%)] Loss: 19476.164062\n",
      "Train Epoch: 179 [129984/225000 (58%)] Loss: 19310.341797\n",
      "Train Epoch: 179 [132480/225000 (59%)] Loss: 18886.730469\n",
      "Train Epoch: 179 [134976/225000 (60%)] Loss: 19149.859375\n",
      "Train Epoch: 179 [137472/225000 (61%)] Loss: 19234.105469\n",
      "Train Epoch: 179 [139968/225000 (62%)] Loss: 18989.132812\n",
      "Train Epoch: 179 [142464/225000 (63%)] Loss: 19307.279297\n",
      "Train Epoch: 179 [144960/225000 (64%)] Loss: 18890.082031\n",
      "Train Epoch: 179 [147456/225000 (66%)] Loss: 19244.316406\n",
      "Train Epoch: 179 [149952/225000 (67%)] Loss: 18890.734375\n",
      "Train Epoch: 179 [152448/225000 (68%)] Loss: 19281.333984\n",
      "Train Epoch: 179 [154944/225000 (69%)] Loss: 19289.285156\n",
      "Train Epoch: 179 [157440/225000 (70%)] Loss: 19097.568359\n",
      "Train Epoch: 179 [159936/225000 (71%)] Loss: 19061.947266\n",
      "Train Epoch: 179 [162432/225000 (72%)] Loss: 18888.437500\n",
      "Train Epoch: 179 [164928/225000 (73%)] Loss: 19116.962891\n",
      "Train Epoch: 179 [167424/225000 (74%)] Loss: 19128.882812\n",
      "Train Epoch: 179 [169920/225000 (76%)] Loss: 18950.445312\n",
      "Train Epoch: 179 [172416/225000 (77%)] Loss: 18476.177734\n",
      "Train Epoch: 179 [174912/225000 (78%)] Loss: 18993.533203\n",
      "Train Epoch: 179 [177408/225000 (79%)] Loss: 18747.343750\n",
      "Train Epoch: 179 [179904/225000 (80%)] Loss: 19580.328125\n",
      "Train Epoch: 179 [182400/225000 (81%)] Loss: 19649.968750\n",
      "Train Epoch: 179 [184896/225000 (82%)] Loss: 19414.601562\n",
      "Train Epoch: 179 [187392/225000 (83%)] Loss: 19369.207031\n",
      "Train Epoch: 179 [189888/225000 (84%)] Loss: 19652.273438\n",
      "Train Epoch: 179 [192384/225000 (86%)] Loss: 19164.117188\n",
      "Train Epoch: 179 [194880/225000 (87%)] Loss: 19161.910156\n",
      "Train Epoch: 179 [197376/225000 (88%)] Loss: 19072.542969\n",
      "Train Epoch: 179 [199872/225000 (89%)] Loss: 19389.255859\n",
      "Train Epoch: 179 [202368/225000 (90%)] Loss: 18825.996094\n",
      "Train Epoch: 179 [204864/225000 (91%)] Loss: 19168.753906\n",
      "Train Epoch: 179 [207360/225000 (92%)] Loss: 19065.650391\n",
      "Train Epoch: 179 [209856/225000 (93%)] Loss: 18947.308594\n",
      "Train Epoch: 179 [212352/225000 (94%)] Loss: 19254.769531\n",
      "Train Epoch: 179 [214848/225000 (95%)] Loss: 19273.748047\n",
      "Train Epoch: 179 [217344/225000 (97%)] Loss: 18733.082031\n",
      "Train Epoch: 179 [219840/225000 (98%)] Loss: 18724.367188\n",
      "Train Epoch: 179 [222336/225000 (99%)] Loss: 19262.484375\n",
      "Train Epoch: 179 [224832/225000 (100%)] Loss: 19507.898438\n",
      "    epoch          : 179\n",
      "    loss           : 19130.832384545647\n",
      "    val_loss       : 19068.853146147183\n",
      "Train Epoch: 180 [192/225000 (0%)] Loss: 19236.578125\n",
      "Train Epoch: 180 [2688/225000 (1%)] Loss: 19354.722656\n",
      "Train Epoch: 180 [5184/225000 (2%)] Loss: 19363.332031\n",
      "Train Epoch: 180 [7680/225000 (3%)] Loss: 19182.224609\n",
      "Train Epoch: 180 [10176/225000 (5%)] Loss: 19409.478516\n",
      "Train Epoch: 180 [12672/225000 (6%)] Loss: 19058.330078\n",
      "Train Epoch: 180 [15168/225000 (7%)] Loss: 19181.460938\n",
      "Train Epoch: 180 [17664/225000 (8%)] Loss: 18867.310547\n",
      "Train Epoch: 180 [20160/225000 (9%)] Loss: 19079.023438\n",
      "Train Epoch: 180 [22656/225000 (10%)] Loss: 18778.367188\n",
      "Train Epoch: 180 [25152/225000 (11%)] Loss: 19555.828125\n",
      "Train Epoch: 180 [27648/225000 (12%)] Loss: 19279.925781\n",
      "Train Epoch: 180 [30144/225000 (13%)] Loss: 18892.101562\n",
      "Train Epoch: 180 [32640/225000 (15%)] Loss: 19396.855469\n",
      "Train Epoch: 180 [35136/225000 (16%)] Loss: 19156.800781\n",
      "Train Epoch: 180 [37632/225000 (17%)] Loss: 18659.300781\n",
      "Train Epoch: 180 [40128/225000 (18%)] Loss: 19273.953125\n",
      "Train Epoch: 180 [42624/225000 (19%)] Loss: 18985.691406\n",
      "Train Epoch: 180 [45120/225000 (20%)] Loss: 18653.699219\n",
      "Train Epoch: 180 [47616/225000 (21%)] Loss: 19528.621094\n",
      "Train Epoch: 180 [50112/225000 (22%)] Loss: 19386.025391\n",
      "Train Epoch: 180 [52608/225000 (23%)] Loss: 19325.582031\n",
      "Train Epoch: 180 [55104/225000 (24%)] Loss: 18625.562500\n",
      "Train Epoch: 180 [57600/225000 (26%)] Loss: 18705.597656\n",
      "Train Epoch: 180 [60096/225000 (27%)] Loss: 18717.421875\n",
      "Train Epoch: 180 [62592/225000 (28%)] Loss: 18738.763672\n",
      "Train Epoch: 180 [65088/225000 (29%)] Loss: 19356.847656\n",
      "Train Epoch: 180 [67584/225000 (30%)] Loss: 19432.697266\n",
      "Train Epoch: 180 [70080/225000 (31%)] Loss: 19053.968750\n",
      "Train Epoch: 180 [72576/225000 (32%)] Loss: 19825.265625\n",
      "Train Epoch: 180 [75072/225000 (33%)] Loss: 19345.796875\n",
      "Train Epoch: 180 [77568/225000 (34%)] Loss: 19772.667969\n",
      "Train Epoch: 180 [80064/225000 (36%)] Loss: 19685.566406\n",
      "Train Epoch: 180 [82560/225000 (37%)] Loss: 19161.722656\n",
      "Train Epoch: 180 [85056/225000 (38%)] Loss: 18894.785156\n",
      "Train Epoch: 180 [87552/225000 (39%)] Loss: 18754.199219\n",
      "Train Epoch: 180 [90048/225000 (40%)] Loss: 19312.628906\n",
      "Train Epoch: 180 [92544/225000 (41%)] Loss: 19064.919922\n",
      "Train Epoch: 180 [95040/225000 (42%)] Loss: 18890.972656\n",
      "Train Epoch: 180 [97536/225000 (43%)] Loss: 19086.347656\n",
      "Train Epoch: 180 [100032/225000 (44%)] Loss: 19460.437500\n",
      "Train Epoch: 180 [102528/225000 (46%)] Loss: 18682.445312\n",
      "Train Epoch: 180 [105024/225000 (47%)] Loss: 19343.476562\n",
      "Train Epoch: 180 [107520/225000 (48%)] Loss: 19207.314453\n",
      "Train Epoch: 180 [110016/225000 (49%)] Loss: 19034.634766\n",
      "Train Epoch: 180 [112512/225000 (50%)] Loss: 19258.060547\n",
      "Train Epoch: 180 [115008/225000 (51%)] Loss: 18678.564453\n",
      "Train Epoch: 180 [117504/225000 (52%)] Loss: 19389.119141\n",
      "Train Epoch: 180 [120000/225000 (53%)] Loss: 19239.732422\n",
      "Train Epoch: 180 [122496/225000 (54%)] Loss: 19236.113281\n",
      "Train Epoch: 180 [124992/225000 (56%)] Loss: 18801.261719\n",
      "Train Epoch: 180 [127488/225000 (57%)] Loss: 19116.035156\n",
      "Train Epoch: 180 [129984/225000 (58%)] Loss: 19346.363281\n",
      "Train Epoch: 180 [132480/225000 (59%)] Loss: 19640.750000\n",
      "Train Epoch: 180 [134976/225000 (60%)] Loss: 19318.171875\n",
      "Train Epoch: 180 [137472/225000 (61%)] Loss: 18962.144531\n",
      "Train Epoch: 180 [139968/225000 (62%)] Loss: 19211.871094\n",
      "Train Epoch: 180 [142464/225000 (63%)] Loss: 18931.986328\n",
      "Train Epoch: 180 [144960/225000 (64%)] Loss: 18685.082031\n",
      "Train Epoch: 180 [147456/225000 (66%)] Loss: 19255.324219\n",
      "Train Epoch: 180 [149952/225000 (67%)] Loss: 19076.933594\n",
      "Train Epoch: 180 [152448/225000 (68%)] Loss: 19017.677734\n",
      "Train Epoch: 180 [154944/225000 (69%)] Loss: 18969.507812\n",
      "Train Epoch: 180 [157440/225000 (70%)] Loss: 18908.984375\n",
      "Train Epoch: 180 [159936/225000 (71%)] Loss: 19126.156250\n",
      "Train Epoch: 180 [162432/225000 (72%)] Loss: 19034.792969\n",
      "Train Epoch: 180 [164928/225000 (73%)] Loss: 19446.742188\n",
      "Train Epoch: 180 [167424/225000 (74%)] Loss: 19421.218750\n",
      "Train Epoch: 180 [169920/225000 (76%)] Loss: 18989.695312\n",
      "Train Epoch: 180 [172416/225000 (77%)] Loss: 19301.832031\n",
      "Train Epoch: 180 [174912/225000 (78%)] Loss: 19229.029297\n",
      "Train Epoch: 180 [177408/225000 (79%)] Loss: 19290.550781\n",
      "Train Epoch: 180 [179904/225000 (80%)] Loss: 18653.265625\n",
      "Train Epoch: 180 [182400/225000 (81%)] Loss: 18731.648438\n",
      "Train Epoch: 180 [184896/225000 (82%)] Loss: 19018.390625\n",
      "Train Epoch: 180 [187392/225000 (83%)] Loss: 19325.820312\n",
      "Train Epoch: 180 [189888/225000 (84%)] Loss: 19372.414062\n",
      "Train Epoch: 180 [192384/225000 (86%)] Loss: 19306.910156\n",
      "Train Epoch: 180 [194880/225000 (87%)] Loss: 19345.058594\n",
      "Train Epoch: 180 [197376/225000 (88%)] Loss: 18583.714844\n",
      "Train Epoch: 180 [199872/225000 (89%)] Loss: 19475.416016\n",
      "Train Epoch: 180 [202368/225000 (90%)] Loss: 19373.787109\n",
      "Train Epoch: 180 [204864/225000 (91%)] Loss: 19094.806641\n",
      "Train Epoch: 180 [207360/225000 (92%)] Loss: 19119.488281\n",
      "Train Epoch: 180 [209856/225000 (93%)] Loss: 19048.097656\n",
      "Train Epoch: 180 [212352/225000 (94%)] Loss: 18711.853516\n",
      "Train Epoch: 180 [214848/225000 (95%)] Loss: 18967.699219\n",
      "Train Epoch: 180 [217344/225000 (97%)] Loss: 19151.796875\n",
      "Train Epoch: 180 [219840/225000 (98%)] Loss: 19617.933594\n",
      "Train Epoch: 180 [222336/225000 (99%)] Loss: 18650.630859\n",
      "Train Epoch: 180 [224832/225000 (100%)] Loss: 19292.984375\n",
      "    epoch          : 180\n",
      "    loss           : 19124.414925741254\n",
      "    val_loss       : 19021.44695551978\n",
      "Train Epoch: 181 [192/225000 (0%)] Loss: 18895.054688\n",
      "Train Epoch: 181 [2688/225000 (1%)] Loss: 18787.503906\n",
      "Train Epoch: 181 [5184/225000 (2%)] Loss: 18794.089844\n",
      "Train Epoch: 181 [7680/225000 (3%)] Loss: 19446.656250\n",
      "Train Epoch: 181 [10176/225000 (5%)] Loss: 18861.777344\n",
      "Train Epoch: 181 [12672/225000 (6%)] Loss: 19063.728516\n",
      "Train Epoch: 181 [15168/225000 (7%)] Loss: 19305.535156\n",
      "Train Epoch: 181 [17664/225000 (8%)] Loss: 18957.109375\n",
      "Train Epoch: 181 [20160/225000 (9%)] Loss: 19053.253906\n",
      "Train Epoch: 181 [22656/225000 (10%)] Loss: 19203.351562\n",
      "Train Epoch: 181 [25152/225000 (11%)] Loss: 19208.777344\n",
      "Train Epoch: 181 [27648/225000 (12%)] Loss: 19251.261719\n",
      "Train Epoch: 181 [30144/225000 (13%)] Loss: 19357.255859\n",
      "Train Epoch: 181 [32640/225000 (15%)] Loss: 18763.839844\n",
      "Train Epoch: 181 [35136/225000 (16%)] Loss: 18916.214844\n",
      "Train Epoch: 181 [37632/225000 (17%)] Loss: 19531.769531\n",
      "Train Epoch: 181 [40128/225000 (18%)] Loss: 19430.003906\n",
      "Train Epoch: 181 [42624/225000 (19%)] Loss: 19447.750000\n",
      "Train Epoch: 181 [45120/225000 (20%)] Loss: 18965.779297\n",
      "Train Epoch: 181 [47616/225000 (21%)] Loss: 19040.796875\n",
      "Train Epoch: 181 [50112/225000 (22%)] Loss: 19498.960938\n",
      "Train Epoch: 181 [52608/225000 (23%)] Loss: 19094.308594\n",
      "Train Epoch: 181 [55104/225000 (24%)] Loss: 18790.167969\n",
      "Train Epoch: 181 [57600/225000 (26%)] Loss: 18761.109375\n",
      "Train Epoch: 181 [60096/225000 (27%)] Loss: 19442.332031\n",
      "Train Epoch: 181 [62592/225000 (28%)] Loss: 19082.882812\n",
      "Train Epoch: 181 [65088/225000 (29%)] Loss: 19099.757812\n",
      "Train Epoch: 181 [67584/225000 (30%)] Loss: 19149.791016\n",
      "Train Epoch: 181 [70080/225000 (31%)] Loss: 19132.195312\n",
      "Train Epoch: 181 [72576/225000 (32%)] Loss: 19130.417969\n",
      "Train Epoch: 181 [75072/225000 (33%)] Loss: 19043.781250\n",
      "Train Epoch: 181 [77568/225000 (34%)] Loss: 19048.582031\n",
      "Train Epoch: 181 [80064/225000 (36%)] Loss: 19569.039062\n",
      "Train Epoch: 181 [82560/225000 (37%)] Loss: 19020.527344\n",
      "Train Epoch: 181 [85056/225000 (38%)] Loss: 19328.820312\n",
      "Train Epoch: 181 [87552/225000 (39%)] Loss: 19102.851562\n",
      "Train Epoch: 181 [90048/225000 (40%)] Loss: 18829.375000\n",
      "Train Epoch: 181 [92544/225000 (41%)] Loss: 19431.937500\n",
      "Train Epoch: 181 [95040/225000 (42%)] Loss: 18941.828125\n",
      "Train Epoch: 181 [97536/225000 (43%)] Loss: 18780.328125\n",
      "Train Epoch: 181 [100032/225000 (44%)] Loss: 18944.308594\n",
      "Train Epoch: 181 [102528/225000 (46%)] Loss: 19138.306641\n",
      "Train Epoch: 181 [105024/225000 (47%)] Loss: 18881.320312\n",
      "Train Epoch: 181 [107520/225000 (48%)] Loss: 18881.445312\n",
      "Train Epoch: 181 [110016/225000 (49%)] Loss: 18464.664062\n",
      "Train Epoch: 181 [112512/225000 (50%)] Loss: 18954.523438\n",
      "Train Epoch: 181 [115008/225000 (51%)] Loss: 19423.402344\n",
      "Train Epoch: 181 [117504/225000 (52%)] Loss: 18808.183594\n",
      "Train Epoch: 181 [120000/225000 (53%)] Loss: 18750.382812\n",
      "Train Epoch: 181 [122496/225000 (54%)] Loss: 19013.609375\n",
      "Train Epoch: 181 [124992/225000 (56%)] Loss: 18891.277344\n",
      "Train Epoch: 181 [127488/225000 (57%)] Loss: 19391.869141\n",
      "Train Epoch: 181 [129984/225000 (58%)] Loss: 19262.851562\n",
      "Train Epoch: 181 [132480/225000 (59%)] Loss: 19073.761719\n",
      "Train Epoch: 181 [134976/225000 (60%)] Loss: 19267.140625\n",
      "Train Epoch: 181 [137472/225000 (61%)] Loss: 19550.947266\n",
      "Train Epoch: 181 [139968/225000 (62%)] Loss: 19104.705078\n",
      "Train Epoch: 181 [142464/225000 (63%)] Loss: 18680.855469\n",
      "Train Epoch: 181 [144960/225000 (64%)] Loss: 19039.566406\n",
      "Train Epoch: 181 [147456/225000 (66%)] Loss: 19502.304688\n",
      "Train Epoch: 181 [149952/225000 (67%)] Loss: 19178.027344\n",
      "Train Epoch: 181 [152448/225000 (68%)] Loss: 19175.464844\n",
      "Train Epoch: 181 [154944/225000 (69%)] Loss: 19327.628906\n",
      "Train Epoch: 181 [157440/225000 (70%)] Loss: 19058.304688\n",
      "Train Epoch: 181 [159936/225000 (71%)] Loss: 18868.703125\n",
      "Train Epoch: 181 [162432/225000 (72%)] Loss: 19218.664062\n",
      "Train Epoch: 181 [164928/225000 (73%)] Loss: 19514.722656\n",
      "Train Epoch: 181 [167424/225000 (74%)] Loss: 18917.984375\n",
      "Train Epoch: 181 [169920/225000 (76%)] Loss: 19680.171875\n",
      "Train Epoch: 181 [172416/225000 (77%)] Loss: 19225.869141\n",
      "Train Epoch: 181 [174912/225000 (78%)] Loss: 19669.992188\n",
      "Train Epoch: 181 [177408/225000 (79%)] Loss: 19194.794922\n",
      "Train Epoch: 181 [179904/225000 (80%)] Loss: 19631.187500\n",
      "Train Epoch: 181 [182400/225000 (81%)] Loss: 18604.031250\n",
      "Train Epoch: 181 [184896/225000 (82%)] Loss: 18860.308594\n",
      "Train Epoch: 181 [187392/225000 (83%)] Loss: 18837.787109\n",
      "Train Epoch: 181 [189888/225000 (84%)] Loss: 18661.769531\n",
      "Train Epoch: 181 [192384/225000 (86%)] Loss: 18713.804688\n",
      "Train Epoch: 181 [194880/225000 (87%)] Loss: 18577.531250\n",
      "Train Epoch: 181 [197376/225000 (88%)] Loss: 18479.097656\n",
      "Train Epoch: 181 [199872/225000 (89%)] Loss: 19379.128906\n",
      "Train Epoch: 181 [202368/225000 (90%)] Loss: 19048.238281\n",
      "Train Epoch: 181 [204864/225000 (91%)] Loss: 18975.058594\n",
      "Train Epoch: 181 [207360/225000 (92%)] Loss: 19453.753906\n",
      "Train Epoch: 181 [209856/225000 (93%)] Loss: 19339.964844\n",
      "Train Epoch: 181 [212352/225000 (94%)] Loss: 19330.253906\n",
      "Train Epoch: 181 [214848/225000 (95%)] Loss: 18369.121094\n",
      "Train Epoch: 181 [217344/225000 (97%)] Loss: 19384.851562\n",
      "Train Epoch: 181 [219840/225000 (98%)] Loss: 18928.503906\n",
      "Train Epoch: 181 [222336/225000 (99%)] Loss: 19109.681641\n",
      "Train Epoch: 181 [224832/225000 (100%)] Loss: 18799.101562\n",
      "    epoch          : 181\n",
      "    loss           : 19092.47403276984\n",
      "    val_loss       : 18999.67957667358\n",
      "Train Epoch: 182 [192/225000 (0%)] Loss: 18950.927734\n",
      "Train Epoch: 182 [2688/225000 (1%)] Loss: 19380.492188\n",
      "Train Epoch: 182 [5184/225000 (2%)] Loss: 19295.691406\n",
      "Train Epoch: 182 [7680/225000 (3%)] Loss: 19168.933594\n",
      "Train Epoch: 182 [10176/225000 (5%)] Loss: 19055.978516\n",
      "Train Epoch: 182 [12672/225000 (6%)] Loss: 18839.687500\n",
      "Train Epoch: 182 [15168/225000 (7%)] Loss: 18815.218750\n",
      "Train Epoch: 182 [17664/225000 (8%)] Loss: 18990.140625\n",
      "Train Epoch: 182 [20160/225000 (9%)] Loss: 18981.195312\n",
      "Train Epoch: 182 [22656/225000 (10%)] Loss: 19198.947266\n",
      "Train Epoch: 182 [25152/225000 (11%)] Loss: 19067.947266\n",
      "Train Epoch: 182 [27648/225000 (12%)] Loss: 19157.759766\n",
      "Train Epoch: 182 [30144/225000 (13%)] Loss: 19442.517578\n",
      "Train Epoch: 182 [32640/225000 (15%)] Loss: 19117.671875\n",
      "Train Epoch: 182 [35136/225000 (16%)] Loss: 19464.113281\n",
      "Train Epoch: 182 [37632/225000 (17%)] Loss: 18915.343750\n",
      "Train Epoch: 182 [40128/225000 (18%)] Loss: 19127.789062\n",
      "Train Epoch: 182 [42624/225000 (19%)] Loss: 19262.572266\n",
      "Train Epoch: 182 [45120/225000 (20%)] Loss: 18944.914062\n",
      "Train Epoch: 182 [47616/225000 (21%)] Loss: 18806.082031\n",
      "Train Epoch: 182 [50112/225000 (22%)] Loss: 19248.953125\n",
      "Train Epoch: 182 [52608/225000 (23%)] Loss: 18966.183594\n",
      "Train Epoch: 182 [55104/225000 (24%)] Loss: 19237.841797\n",
      "Train Epoch: 182 [57600/225000 (26%)] Loss: 18639.820312\n",
      "Train Epoch: 182 [60096/225000 (27%)] Loss: 19127.130859\n",
      "Train Epoch: 182 [62592/225000 (28%)] Loss: 19265.658203\n",
      "Train Epoch: 182 [65088/225000 (29%)] Loss: 18977.101562\n",
      "Train Epoch: 182 [67584/225000 (30%)] Loss: 18974.650391\n",
      "Train Epoch: 182 [70080/225000 (31%)] Loss: 19444.513672\n",
      "Train Epoch: 182 [72576/225000 (32%)] Loss: 19402.695312\n",
      "Train Epoch: 182 [75072/225000 (33%)] Loss: 18986.289062\n",
      "Train Epoch: 182 [77568/225000 (34%)] Loss: 18935.964844\n",
      "Train Epoch: 182 [80064/225000 (36%)] Loss: 18958.714844\n",
      "Train Epoch: 182 [82560/225000 (37%)] Loss: 19546.550781\n",
      "Train Epoch: 182 [85056/225000 (38%)] Loss: 19380.035156\n",
      "Train Epoch: 182 [87552/225000 (39%)] Loss: 19318.792969\n",
      "Train Epoch: 182 [90048/225000 (40%)] Loss: 19504.816406\n",
      "Train Epoch: 182 [92544/225000 (41%)] Loss: 18699.144531\n",
      "Train Epoch: 182 [95040/225000 (42%)] Loss: 18939.632812\n",
      "Train Epoch: 182 [97536/225000 (43%)] Loss: 19185.146484\n",
      "Train Epoch: 182 [100032/225000 (44%)] Loss: 19179.123047\n",
      "Train Epoch: 182 [102528/225000 (46%)] Loss: 19015.253906\n",
      "Train Epoch: 182 [105024/225000 (47%)] Loss: 19146.636719\n",
      "Train Epoch: 182 [107520/225000 (48%)] Loss: 19481.464844\n",
      "Train Epoch: 182 [110016/225000 (49%)] Loss: 19790.949219\n",
      "Train Epoch: 182 [112512/225000 (50%)] Loss: 19389.773438\n",
      "Train Epoch: 182 [115008/225000 (51%)] Loss: 19498.437500\n",
      "Train Epoch: 182 [117504/225000 (52%)] Loss: 19279.628906\n",
      "Train Epoch: 182 [120000/225000 (53%)] Loss: 19309.050781\n",
      "Train Epoch: 182 [122496/225000 (54%)] Loss: 19107.255859\n",
      "Train Epoch: 182 [124992/225000 (56%)] Loss: 18424.687500\n",
      "Train Epoch: 182 [127488/225000 (57%)] Loss: 19283.595703\n",
      "Train Epoch: 182 [129984/225000 (58%)] Loss: 19493.980469\n",
      "Train Epoch: 182 [132480/225000 (59%)] Loss: 19112.640625\n",
      "Train Epoch: 182 [134976/225000 (60%)] Loss: 19167.410156\n",
      "Train Epoch: 182 [137472/225000 (61%)] Loss: 18768.501953\n",
      "Train Epoch: 182 [139968/225000 (62%)] Loss: 19234.367188\n",
      "Train Epoch: 182 [142464/225000 (63%)] Loss: 18883.019531\n",
      "Train Epoch: 182 [144960/225000 (64%)] Loss: 19225.060547\n",
      "Train Epoch: 182 [147456/225000 (66%)] Loss: 19554.666016\n",
      "Train Epoch: 182 [149952/225000 (67%)] Loss: 19626.812500\n",
      "Train Epoch: 182 [152448/225000 (68%)] Loss: 19528.742188\n",
      "Train Epoch: 182 [154944/225000 (69%)] Loss: 19114.035156\n",
      "Train Epoch: 182 [157440/225000 (70%)] Loss: 18865.781250\n",
      "Train Epoch: 182 [159936/225000 (71%)] Loss: 19139.375000\n",
      "Train Epoch: 182 [162432/225000 (72%)] Loss: 18884.173828\n",
      "Train Epoch: 182 [164928/225000 (73%)] Loss: 18933.125000\n",
      "Train Epoch: 182 [167424/225000 (74%)] Loss: 19171.013672\n",
      "Train Epoch: 182 [169920/225000 (76%)] Loss: 19121.507812\n",
      "Train Epoch: 182 [172416/225000 (77%)] Loss: 19403.593750\n",
      "Train Epoch: 182 [174912/225000 (78%)] Loss: 18865.843750\n",
      "Train Epoch: 182 [177408/225000 (79%)] Loss: 18638.189453\n",
      "Train Epoch: 182 [179904/225000 (80%)] Loss: 18952.853516\n",
      "Train Epoch: 182 [182400/225000 (81%)] Loss: 19079.392578\n",
      "Train Epoch: 182 [184896/225000 (82%)] Loss: 18769.515625\n",
      "Train Epoch: 182 [187392/225000 (83%)] Loss: 19203.060547\n",
      "Train Epoch: 182 [189888/225000 (84%)] Loss: 18707.626953\n",
      "Train Epoch: 182 [192384/225000 (86%)] Loss: 19297.574219\n",
      "Train Epoch: 182 [194880/225000 (87%)] Loss: 18654.554688\n",
      "Train Epoch: 182 [197376/225000 (88%)] Loss: 19479.207031\n",
      "Train Epoch: 182 [199872/225000 (89%)] Loss: 18885.656250\n",
      "Train Epoch: 182 [202368/225000 (90%)] Loss: 19435.968750\n",
      "Train Epoch: 182 [204864/225000 (91%)] Loss: 18941.207031\n",
      "Train Epoch: 182 [207360/225000 (92%)] Loss: 18843.062500\n",
      "Train Epoch: 182 [209856/225000 (93%)] Loss: 21952.980469\n",
      "Train Epoch: 182 [212352/225000 (94%)] Loss: 18898.925781\n",
      "Train Epoch: 182 [214848/225000 (95%)] Loss: 18997.253906\n",
      "Train Epoch: 182 [217344/225000 (97%)] Loss: 19095.970703\n",
      "Train Epoch: 182 [219840/225000 (98%)] Loss: 19361.736328\n",
      "Train Epoch: 182 [222336/225000 (99%)] Loss: 19369.804688\n",
      "Train Epoch: 182 [224832/225000 (100%)] Loss: 19253.660156\n",
      "    epoch          : 182\n",
      "    loss           : 19112.302724376066\n",
      "    val_loss       : 18985.00472309298\n",
      "Train Epoch: 183 [192/225000 (0%)] Loss: 19315.019531\n",
      "Train Epoch: 183 [2688/225000 (1%)] Loss: 18515.871094\n",
      "Train Epoch: 183 [5184/225000 (2%)] Loss: 19129.912109\n",
      "Train Epoch: 183 [7680/225000 (3%)] Loss: 19666.792969\n",
      "Train Epoch: 183 [10176/225000 (5%)] Loss: 19343.128906\n",
      "Train Epoch: 183 [12672/225000 (6%)] Loss: 18448.064453\n",
      "Train Epoch: 183 [15168/225000 (7%)] Loss: 19620.726562\n",
      "Train Epoch: 183 [17664/225000 (8%)] Loss: 18815.011719\n",
      "Train Epoch: 183 [20160/225000 (9%)] Loss: 19151.714844\n",
      "Train Epoch: 183 [22656/225000 (10%)] Loss: 18688.906250\n",
      "Train Epoch: 183 [25152/225000 (11%)] Loss: 19403.503906\n",
      "Train Epoch: 183 [27648/225000 (12%)] Loss: 18963.632812\n",
      "Train Epoch: 183 [30144/225000 (13%)] Loss: 19207.048828\n",
      "Train Epoch: 183 [32640/225000 (15%)] Loss: 19398.660156\n",
      "Train Epoch: 183 [35136/225000 (16%)] Loss: 19028.156250\n",
      "Train Epoch: 183 [37632/225000 (17%)] Loss: 19140.203125\n",
      "Train Epoch: 183 [40128/225000 (18%)] Loss: 19334.654297\n",
      "Train Epoch: 183 [42624/225000 (19%)] Loss: 19502.332031\n",
      "Train Epoch: 183 [45120/225000 (20%)] Loss: 19449.089844\n",
      "Train Epoch: 183 [47616/225000 (21%)] Loss: 19109.695312\n",
      "Train Epoch: 183 [50112/225000 (22%)] Loss: 18877.707031\n",
      "Train Epoch: 183 [52608/225000 (23%)] Loss: 18996.148438\n",
      "Train Epoch: 183 [55104/225000 (24%)] Loss: 19161.531250\n",
      "Train Epoch: 183 [57600/225000 (26%)] Loss: 19191.851562\n",
      "Train Epoch: 183 [60096/225000 (27%)] Loss: 18920.666016\n",
      "Train Epoch: 183 [62592/225000 (28%)] Loss: 19063.291016\n",
      "Train Epoch: 183 [65088/225000 (29%)] Loss: 19806.640625\n",
      "Train Epoch: 183 [67584/225000 (30%)] Loss: 19404.902344\n",
      "Train Epoch: 183 [70080/225000 (31%)] Loss: 19168.832031\n",
      "Train Epoch: 183 [72576/225000 (32%)] Loss: 19190.208984\n",
      "Train Epoch: 183 [75072/225000 (33%)] Loss: 19275.160156\n",
      "Train Epoch: 183 [77568/225000 (34%)] Loss: 18795.726562\n",
      "Train Epoch: 183 [80064/225000 (36%)] Loss: 18784.683594\n",
      "Train Epoch: 183 [82560/225000 (37%)] Loss: 18857.218750\n",
      "Train Epoch: 183 [85056/225000 (38%)] Loss: 19090.996094\n",
      "Train Epoch: 183 [87552/225000 (39%)] Loss: 18866.572266\n",
      "Train Epoch: 183 [90048/225000 (40%)] Loss: 18718.414062\n",
      "Train Epoch: 183 [92544/225000 (41%)] Loss: 19079.085938\n",
      "Train Epoch: 183 [95040/225000 (42%)] Loss: 18713.060547\n",
      "Train Epoch: 183 [97536/225000 (43%)] Loss: 19118.660156\n",
      "Train Epoch: 183 [100032/225000 (44%)] Loss: 18943.464844\n",
      "Train Epoch: 183 [102528/225000 (46%)] Loss: 18958.160156\n",
      "Train Epoch: 183 [105024/225000 (47%)] Loss: 18992.300781\n",
      "Train Epoch: 183 [107520/225000 (48%)] Loss: 19085.050781\n",
      "Train Epoch: 183 [110016/225000 (49%)] Loss: 19086.931641\n",
      "Train Epoch: 183 [112512/225000 (50%)] Loss: 19260.757812\n",
      "Train Epoch: 183 [115008/225000 (51%)] Loss: 19348.261719\n",
      "Train Epoch: 183 [117504/225000 (52%)] Loss: 19049.505859\n",
      "Train Epoch: 183 [120000/225000 (53%)] Loss: 19155.841797\n",
      "Train Epoch: 183 [122496/225000 (54%)] Loss: 19408.208984\n",
      "Train Epoch: 183 [124992/225000 (56%)] Loss: 19164.578125\n",
      "Train Epoch: 183 [127488/225000 (57%)] Loss: 18615.867188\n",
      "Train Epoch: 183 [129984/225000 (58%)] Loss: 19171.546875\n",
      "Train Epoch: 183 [132480/225000 (59%)] Loss: 19133.138672\n",
      "Train Epoch: 183 [134976/225000 (60%)] Loss: 19191.402344\n",
      "Train Epoch: 183 [137472/225000 (61%)] Loss: 19039.488281\n",
      "Train Epoch: 183 [139968/225000 (62%)] Loss: 19696.605469\n",
      "Train Epoch: 183 [142464/225000 (63%)] Loss: 19052.054688\n",
      "Train Epoch: 183 [144960/225000 (64%)] Loss: 18855.966797\n",
      "Train Epoch: 183 [147456/225000 (66%)] Loss: 19515.164062\n",
      "Train Epoch: 183 [149952/225000 (67%)] Loss: 19364.273438\n",
      "Train Epoch: 183 [152448/225000 (68%)] Loss: 18897.501953\n",
      "Train Epoch: 183 [154944/225000 (69%)] Loss: 18576.466797\n",
      "Train Epoch: 183 [157440/225000 (70%)] Loss: 18764.269531\n",
      "Train Epoch: 183 [159936/225000 (71%)] Loss: 19181.679688\n",
      "Train Epoch: 183 [162432/225000 (72%)] Loss: 19198.435547\n",
      "Train Epoch: 183 [164928/225000 (73%)] Loss: 19352.835938\n",
      "Train Epoch: 183 [167424/225000 (74%)] Loss: 18978.230469\n",
      "Train Epoch: 183 [169920/225000 (76%)] Loss: 19524.777344\n",
      "Train Epoch: 183 [172416/225000 (77%)] Loss: 19006.611328\n",
      "Train Epoch: 183 [174912/225000 (78%)] Loss: 18772.582031\n",
      "Train Epoch: 183 [177408/225000 (79%)] Loss: 18797.830078\n",
      "Train Epoch: 183 [179904/225000 (80%)] Loss: 19489.470703\n",
      "Train Epoch: 183 [182400/225000 (81%)] Loss: 19012.429688\n",
      "Train Epoch: 183 [184896/225000 (82%)] Loss: 19486.527344\n",
      "Train Epoch: 183 [187392/225000 (83%)] Loss: 19178.179688\n",
      "Train Epoch: 183 [189888/225000 (84%)] Loss: 18777.003906\n",
      "Train Epoch: 183 [192384/225000 (86%)] Loss: 18508.515625\n",
      "Train Epoch: 183 [194880/225000 (87%)] Loss: 18923.345703\n",
      "Train Epoch: 183 [197376/225000 (88%)] Loss: 19574.736328\n",
      "Train Epoch: 183 [199872/225000 (89%)] Loss: 19227.785156\n",
      "Train Epoch: 183 [202368/225000 (90%)] Loss: 19219.226562\n",
      "Train Epoch: 183 [204864/225000 (91%)] Loss: 18881.275391\n",
      "Train Epoch: 183 [207360/225000 (92%)] Loss: 18907.800781\n",
      "Train Epoch: 183 [209856/225000 (93%)] Loss: 19130.890625\n",
      "Train Epoch: 183 [212352/225000 (94%)] Loss: 18834.843750\n",
      "Train Epoch: 183 [214848/225000 (95%)] Loss: 19067.849609\n",
      "Train Epoch: 183 [217344/225000 (97%)] Loss: 19213.402344\n",
      "Train Epoch: 183 [219840/225000 (98%)] Loss: 19276.074219\n",
      "Train Epoch: 183 [222336/225000 (99%)] Loss: 19030.259766\n",
      "Train Epoch: 183 [224832/225000 (100%)] Loss: 18904.218750\n",
      "    epoch          : 183\n",
      "    loss           : 19076.611654756827\n",
      "    val_loss       : 18981.410959013545\n",
      "Train Epoch: 184 [192/225000 (0%)] Loss: 18967.886719\n",
      "Train Epoch: 184 [2688/225000 (1%)] Loss: 19208.433594\n",
      "Train Epoch: 184 [5184/225000 (2%)] Loss: 18904.023438\n",
      "Train Epoch: 184 [7680/225000 (3%)] Loss: 19726.037109\n",
      "Train Epoch: 184 [10176/225000 (5%)] Loss: 18883.048828\n",
      "Train Epoch: 184 [12672/225000 (6%)] Loss: 18846.097656\n",
      "Train Epoch: 184 [15168/225000 (7%)] Loss: 18925.425781\n",
      "Train Epoch: 184 [17664/225000 (8%)] Loss: 18893.357422\n",
      "Train Epoch: 184 [20160/225000 (9%)] Loss: 18878.339844\n",
      "Train Epoch: 184 [22656/225000 (10%)] Loss: 18336.771484\n",
      "Train Epoch: 184 [25152/225000 (11%)] Loss: 19062.550781\n",
      "Train Epoch: 184 [27648/225000 (12%)] Loss: 18814.820312\n",
      "Train Epoch: 184 [30144/225000 (13%)] Loss: 18774.080078\n",
      "Train Epoch: 184 [32640/225000 (15%)] Loss: 19493.613281\n",
      "Train Epoch: 184 [35136/225000 (16%)] Loss: 19198.113281\n",
      "Train Epoch: 184 [37632/225000 (17%)] Loss: 19193.480469\n",
      "Train Epoch: 184 [40128/225000 (18%)] Loss: 19143.082031\n",
      "Train Epoch: 184 [42624/225000 (19%)] Loss: 19146.242188\n",
      "Train Epoch: 184 [45120/225000 (20%)] Loss: 19283.630859\n",
      "Train Epoch: 184 [47616/225000 (21%)] Loss: 18621.808594\n",
      "Train Epoch: 184 [50112/225000 (22%)] Loss: 18712.355469\n",
      "Train Epoch: 184 [52608/225000 (23%)] Loss: 19140.677734\n",
      "Train Epoch: 184 [55104/225000 (24%)] Loss: 18919.113281\n",
      "Train Epoch: 184 [57600/225000 (26%)] Loss: 18980.152344\n",
      "Train Epoch: 184 [60096/225000 (27%)] Loss: 19425.275391\n",
      "Train Epoch: 184 [62592/225000 (28%)] Loss: 19564.888672\n",
      "Train Epoch: 184 [65088/225000 (29%)] Loss: 19208.412109\n",
      "Train Epoch: 184 [67584/225000 (30%)] Loss: 19421.636719\n",
      "Train Epoch: 184 [70080/225000 (31%)] Loss: 18956.476562\n",
      "Train Epoch: 184 [72576/225000 (32%)] Loss: 19106.242188\n",
      "Train Epoch: 184 [75072/225000 (33%)] Loss: 18423.933594\n",
      "Train Epoch: 184 [77568/225000 (34%)] Loss: 19500.066406\n",
      "Train Epoch: 184 [80064/225000 (36%)] Loss: 18966.259766\n",
      "Train Epoch: 184 [82560/225000 (37%)] Loss: 18938.927734\n",
      "Train Epoch: 184 [85056/225000 (38%)] Loss: 19255.367188\n",
      "Train Epoch: 184 [87552/225000 (39%)] Loss: 19218.515625\n",
      "Train Epoch: 184 [90048/225000 (40%)] Loss: 19451.031250\n",
      "Train Epoch: 184 [92544/225000 (41%)] Loss: 18914.427734\n",
      "Train Epoch: 184 [95040/225000 (42%)] Loss: 18743.535156\n",
      "Train Epoch: 184 [97536/225000 (43%)] Loss: 18985.203125\n",
      "Train Epoch: 184 [100032/225000 (44%)] Loss: 19266.753906\n",
      "Train Epoch: 184 [102528/225000 (46%)] Loss: 19159.507812\n",
      "Train Epoch: 184 [105024/225000 (47%)] Loss: 19156.562500\n",
      "Train Epoch: 184 [107520/225000 (48%)] Loss: 19011.261719\n",
      "Train Epoch: 184 [110016/225000 (49%)] Loss: 19091.339844\n",
      "Train Epoch: 184 [112512/225000 (50%)] Loss: 19221.527344\n",
      "Train Epoch: 184 [115008/225000 (51%)] Loss: 19445.312500\n",
      "Train Epoch: 184 [117504/225000 (52%)] Loss: 19254.792969\n",
      "Train Epoch: 184 [120000/225000 (53%)] Loss: 18552.599609\n",
      "Train Epoch: 184 [122496/225000 (54%)] Loss: 18816.667969\n",
      "Train Epoch: 184 [124992/225000 (56%)] Loss: 19497.269531\n",
      "Train Epoch: 184 [127488/225000 (57%)] Loss: 18687.796875\n",
      "Train Epoch: 184 [129984/225000 (58%)] Loss: 18737.785156\n",
      "Train Epoch: 184 [132480/225000 (59%)] Loss: 19107.894531\n",
      "Train Epoch: 184 [134976/225000 (60%)] Loss: 19150.625000\n",
      "Train Epoch: 184 [137472/225000 (61%)] Loss: 19138.785156\n",
      "Train Epoch: 184 [139968/225000 (62%)] Loss: 19036.460938\n",
      "Train Epoch: 184 [142464/225000 (63%)] Loss: 19267.054688\n",
      "Train Epoch: 184 [144960/225000 (64%)] Loss: 18956.863281\n",
      "Train Epoch: 184 [147456/225000 (66%)] Loss: 19185.458984\n",
      "Train Epoch: 184 [149952/225000 (67%)] Loss: 19314.855469\n",
      "Train Epoch: 184 [152448/225000 (68%)] Loss: 19249.611328\n",
      "Train Epoch: 184 [154944/225000 (69%)] Loss: 18846.146484\n",
      "Train Epoch: 184 [157440/225000 (70%)] Loss: 19021.636719\n",
      "Train Epoch: 184 [159936/225000 (71%)] Loss: 19271.597656\n",
      "Train Epoch: 184 [162432/225000 (72%)] Loss: 18536.125000\n",
      "Train Epoch: 184 [164928/225000 (73%)] Loss: 18939.931641\n",
      "Train Epoch: 184 [167424/225000 (74%)] Loss: 19158.871094\n",
      "Train Epoch: 184 [169920/225000 (76%)] Loss: 19121.398438\n",
      "Train Epoch: 184 [172416/225000 (77%)] Loss: 19571.894531\n",
      "Train Epoch: 184 [174912/225000 (78%)] Loss: 19246.644531\n",
      "Train Epoch: 184 [177408/225000 (79%)] Loss: 18715.367188\n",
      "Train Epoch: 184 [179904/225000 (80%)] Loss: 19251.679688\n",
      "Train Epoch: 184 [182400/225000 (81%)] Loss: 18900.064453\n",
      "Train Epoch: 184 [184896/225000 (82%)] Loss: 19196.316406\n",
      "Train Epoch: 184 [187392/225000 (83%)] Loss: 19190.750000\n",
      "Train Epoch: 184 [189888/225000 (84%)] Loss: 18704.560547\n",
      "Train Epoch: 184 [192384/225000 (86%)] Loss: 19323.179688\n",
      "Train Epoch: 184 [194880/225000 (87%)] Loss: 19264.585938\n",
      "Train Epoch: 184 [197376/225000 (88%)] Loss: 18510.042969\n",
      "Train Epoch: 184 [199872/225000 (89%)] Loss: 19131.566406\n",
      "Train Epoch: 184 [202368/225000 (90%)] Loss: 18632.539062\n",
      "Train Epoch: 184 [204864/225000 (91%)] Loss: 18714.464844\n",
      "Train Epoch: 184 [207360/225000 (92%)] Loss: 18500.162109\n",
      "Train Epoch: 184 [209856/225000 (93%)] Loss: 19092.386719\n",
      "Train Epoch: 184 [212352/225000 (94%)] Loss: 19294.597656\n",
      "Train Epoch: 184 [214848/225000 (95%)] Loss: 18778.693359\n",
      "Train Epoch: 184 [217344/225000 (97%)] Loss: 19200.976562\n",
      "Train Epoch: 184 [219840/225000 (98%)] Loss: 19336.542969\n",
      "Train Epoch: 184 [222336/225000 (99%)] Loss: 18639.886719\n",
      "Train Epoch: 184 [224832/225000 (100%)] Loss: 18903.968750\n",
      "    epoch          : 184\n",
      "    loss           : 19059.681647290956\n",
      "    val_loss       : 18989.042038075797\n",
      "Train Epoch: 185 [192/225000 (0%)] Loss: 19194.457031\n",
      "Train Epoch: 185 [2688/225000 (1%)] Loss: 19209.734375\n",
      "Train Epoch: 185 [5184/225000 (2%)] Loss: 18738.158203\n",
      "Train Epoch: 185 [7680/225000 (3%)] Loss: 18992.974609\n",
      "Train Epoch: 185 [10176/225000 (5%)] Loss: 19116.738281\n",
      "Train Epoch: 185 [12672/225000 (6%)] Loss: 19209.996094\n",
      "Train Epoch: 185 [15168/225000 (7%)] Loss: 19017.294922\n",
      "Train Epoch: 185 [17664/225000 (8%)] Loss: 18977.726562\n",
      "Train Epoch: 185 [20160/225000 (9%)] Loss: 18928.158203\n",
      "Train Epoch: 185 [22656/225000 (10%)] Loss: 18943.330078\n",
      "Train Epoch: 185 [25152/225000 (11%)] Loss: 19590.734375\n",
      "Train Epoch: 185 [27648/225000 (12%)] Loss: 18988.455078\n",
      "Train Epoch: 185 [30144/225000 (13%)] Loss: 19397.248047\n",
      "Train Epoch: 185 [32640/225000 (15%)] Loss: 18565.406250\n",
      "Train Epoch: 185 [35136/225000 (16%)] Loss: 18944.232422\n",
      "Train Epoch: 185 [37632/225000 (17%)] Loss: 19294.632812\n",
      "Train Epoch: 185 [40128/225000 (18%)] Loss: 19045.888672\n",
      "Train Epoch: 185 [42624/225000 (19%)] Loss: 19585.542969\n",
      "Train Epoch: 185 [45120/225000 (20%)] Loss: 18796.468750\n",
      "Train Epoch: 185 [47616/225000 (21%)] Loss: 18888.433594\n",
      "Train Epoch: 185 [50112/225000 (22%)] Loss: 18752.613281\n",
      "Train Epoch: 185 [52608/225000 (23%)] Loss: 18515.007812\n",
      "Train Epoch: 185 [55104/225000 (24%)] Loss: 19317.671875\n",
      "Train Epoch: 185 [57600/225000 (26%)] Loss: 19133.281250\n",
      "Train Epoch: 185 [60096/225000 (27%)] Loss: 19373.603516\n",
      "Train Epoch: 185 [62592/225000 (28%)] Loss: 19491.636719\n",
      "Train Epoch: 185 [65088/225000 (29%)] Loss: 18978.392578\n",
      "Train Epoch: 185 [67584/225000 (30%)] Loss: 19035.644531\n",
      "Train Epoch: 185 [70080/225000 (31%)] Loss: 18976.765625\n",
      "Train Epoch: 185 [72576/225000 (32%)] Loss: 19191.035156\n",
      "Train Epoch: 185 [75072/225000 (33%)] Loss: 18586.578125\n",
      "Train Epoch: 185 [77568/225000 (34%)] Loss: 18731.042969\n",
      "Train Epoch: 185 [80064/225000 (36%)] Loss: 18984.734375\n",
      "Train Epoch: 185 [82560/225000 (37%)] Loss: 18783.750000\n",
      "Train Epoch: 185 [85056/225000 (38%)] Loss: 18603.082031\n",
      "Train Epoch: 185 [87552/225000 (39%)] Loss: 19348.296875\n",
      "Train Epoch: 185 [90048/225000 (40%)] Loss: 18838.941406\n",
      "Train Epoch: 185 [92544/225000 (41%)] Loss: 18852.371094\n",
      "Train Epoch: 185 [95040/225000 (42%)] Loss: 19277.355469\n",
      "Train Epoch: 185 [97536/225000 (43%)] Loss: 18931.386719\n",
      "Train Epoch: 185 [100032/225000 (44%)] Loss: 19121.718750\n",
      "Train Epoch: 185 [102528/225000 (46%)] Loss: 18908.195312\n",
      "Train Epoch: 185 [105024/225000 (47%)] Loss: 18943.363281\n",
      "Train Epoch: 185 [107520/225000 (48%)] Loss: 18781.851562\n",
      "Train Epoch: 185 [110016/225000 (49%)] Loss: 19239.812500\n",
      "Train Epoch: 185 [112512/225000 (50%)] Loss: 19158.585938\n",
      "Train Epoch: 185 [115008/225000 (51%)] Loss: 19058.316406\n",
      "Train Epoch: 185 [117504/225000 (52%)] Loss: 19256.621094\n",
      "Train Epoch: 185 [120000/225000 (53%)] Loss: 19160.587891\n",
      "Train Epoch: 185 [122496/225000 (54%)] Loss: 19167.281250\n",
      "Train Epoch: 185 [124992/225000 (56%)] Loss: 19185.757812\n",
      "Train Epoch: 185 [127488/225000 (57%)] Loss: 19364.912109\n",
      "Train Epoch: 185 [129984/225000 (58%)] Loss: 18916.093750\n",
      "Train Epoch: 185 [132480/225000 (59%)] Loss: 18590.714844\n",
      "Train Epoch: 185 [134976/225000 (60%)] Loss: 19094.753906\n",
      "Train Epoch: 185 [137472/225000 (61%)] Loss: 19051.425781\n",
      "Train Epoch: 185 [139968/225000 (62%)] Loss: 18853.058594\n",
      "Train Epoch: 185 [142464/225000 (63%)] Loss: 18995.355469\n",
      "Train Epoch: 185 [144960/225000 (64%)] Loss: 19297.810547\n",
      "Train Epoch: 185 [147456/225000 (66%)] Loss: 19330.193359\n",
      "Train Epoch: 185 [149952/225000 (67%)] Loss: 19270.275391\n",
      "Train Epoch: 185 [152448/225000 (68%)] Loss: 19310.310547\n",
      "Train Epoch: 185 [154944/225000 (69%)] Loss: 19119.371094\n",
      "Train Epoch: 185 [157440/225000 (70%)] Loss: 19170.800781\n",
      "Train Epoch: 185 [159936/225000 (71%)] Loss: 18871.978516\n",
      "Train Epoch: 185 [162432/225000 (72%)] Loss: 19114.871094\n",
      "Train Epoch: 185 [164928/225000 (73%)] Loss: 18862.386719\n",
      "Train Epoch: 185 [167424/225000 (74%)] Loss: 18632.933594\n",
      "Train Epoch: 185 [169920/225000 (76%)] Loss: 19184.261719\n",
      "Train Epoch: 185 [172416/225000 (77%)] Loss: 19288.587891\n",
      "Train Epoch: 185 [174912/225000 (78%)] Loss: 18982.798828\n",
      "Train Epoch: 185 [177408/225000 (79%)] Loss: 18763.453125\n",
      "Train Epoch: 185 [179904/225000 (80%)] Loss: 19088.167969\n",
      "Train Epoch: 185 [182400/225000 (81%)] Loss: 18835.996094\n",
      "Train Epoch: 185 [184896/225000 (82%)] Loss: 18956.121094\n",
      "Train Epoch: 185 [187392/225000 (83%)] Loss: 18450.814453\n",
      "Train Epoch: 185 [189888/225000 (84%)] Loss: 19299.984375\n",
      "Train Epoch: 185 [192384/225000 (86%)] Loss: 19215.193359\n",
      "Train Epoch: 185 [194880/225000 (87%)] Loss: 18595.767578\n",
      "Train Epoch: 185 [197376/225000 (88%)] Loss: 18715.505859\n",
      "Train Epoch: 185 [199872/225000 (89%)] Loss: 18813.171875\n",
      "Train Epoch: 185 [202368/225000 (90%)] Loss: 19149.097656\n",
      "Train Epoch: 185 [204864/225000 (91%)] Loss: 18824.052734\n",
      "Train Epoch: 185 [207360/225000 (92%)] Loss: 18725.066406\n",
      "Train Epoch: 185 [209856/225000 (93%)] Loss: 19122.050781\n",
      "Train Epoch: 185 [212352/225000 (94%)] Loss: 18969.058594\n",
      "Train Epoch: 185 [214848/225000 (95%)] Loss: 18413.728516\n",
      "Train Epoch: 185 [217344/225000 (97%)] Loss: 18624.103516\n",
      "Train Epoch: 185 [219840/225000 (98%)] Loss: 19205.355469\n",
      "Train Epoch: 185 [222336/225000 (99%)] Loss: 19263.292969\n",
      "Train Epoch: 185 [224832/225000 (100%)] Loss: 18901.941406\n",
      "    epoch          : 185\n",
      "    loss           : 19044.414802421074\n",
      "    val_loss       : 18943.347220420383\n",
      "Train Epoch: 186 [192/225000 (0%)] Loss: 19120.759766\n",
      "Train Epoch: 186 [2688/225000 (1%)] Loss: 19081.470703\n",
      "Train Epoch: 186 [5184/225000 (2%)] Loss: 19334.531250\n",
      "Train Epoch: 186 [7680/225000 (3%)] Loss: 19289.003906\n",
      "Train Epoch: 186 [10176/225000 (5%)] Loss: 19024.841797\n",
      "Train Epoch: 186 [12672/225000 (6%)] Loss: 19189.966797\n",
      "Train Epoch: 186 [15168/225000 (7%)] Loss: 18855.976562\n",
      "Train Epoch: 186 [17664/225000 (8%)] Loss: 19128.738281\n",
      "Train Epoch: 186 [20160/225000 (9%)] Loss: 18349.703125\n",
      "Train Epoch: 186 [22656/225000 (10%)] Loss: 19032.013672\n",
      "Train Epoch: 186 [25152/225000 (11%)] Loss: 19200.904297\n",
      "Train Epoch: 186 [27648/225000 (12%)] Loss: 19129.501953\n",
      "Train Epoch: 186 [30144/225000 (13%)] Loss: 18698.488281\n",
      "Train Epoch: 186 [32640/225000 (15%)] Loss: 18859.035156\n",
      "Train Epoch: 186 [35136/225000 (16%)] Loss: 19123.574219\n",
      "Train Epoch: 186 [37632/225000 (17%)] Loss: 19286.628906\n",
      "Train Epoch: 186 [40128/225000 (18%)] Loss: 19600.175781\n",
      "Train Epoch: 186 [42624/225000 (19%)] Loss: 19178.345703\n",
      "Train Epoch: 186 [45120/225000 (20%)] Loss: 18828.732422\n",
      "Train Epoch: 186 [47616/225000 (21%)] Loss: 18636.601562\n",
      "Train Epoch: 186 [50112/225000 (22%)] Loss: 18915.433594\n",
      "Train Epoch: 186 [52608/225000 (23%)] Loss: 19556.384766\n",
      "Train Epoch: 186 [55104/225000 (24%)] Loss: 18958.125000\n",
      "Train Epoch: 186 [57600/225000 (26%)] Loss: 18947.978516\n",
      "Train Epoch: 186 [60096/225000 (27%)] Loss: 19248.074219\n",
      "Train Epoch: 186 [62592/225000 (28%)] Loss: 18740.476562\n",
      "Train Epoch: 186 [65088/225000 (29%)] Loss: 18705.730469\n",
      "Train Epoch: 186 [67584/225000 (30%)] Loss: 18951.218750\n",
      "Train Epoch: 186 [70080/225000 (31%)] Loss: 18869.968750\n",
      "Train Epoch: 186 [72576/225000 (32%)] Loss: 18250.949219\n",
      "Train Epoch: 186 [75072/225000 (33%)] Loss: 18937.867188\n",
      "Train Epoch: 186 [77568/225000 (34%)] Loss: 19385.144531\n",
      "Train Epoch: 186 [80064/225000 (36%)] Loss: 18956.751953\n",
      "Train Epoch: 186 [82560/225000 (37%)] Loss: 19575.605469\n",
      "Train Epoch: 186 [85056/225000 (38%)] Loss: 19133.707031\n",
      "Train Epoch: 186 [87552/225000 (39%)] Loss: 19062.996094\n",
      "Train Epoch: 186 [90048/225000 (40%)] Loss: 19010.617188\n",
      "Train Epoch: 186 [92544/225000 (41%)] Loss: 18958.199219\n",
      "Train Epoch: 186 [95040/225000 (42%)] Loss: 18714.183594\n",
      "Train Epoch: 186 [97536/225000 (43%)] Loss: 19004.949219\n",
      "Train Epoch: 186 [100032/225000 (44%)] Loss: 18950.544922\n",
      "Train Epoch: 186 [102528/225000 (46%)] Loss: 19226.308594\n",
      "Train Epoch: 186 [105024/225000 (47%)] Loss: 19368.343750\n",
      "Train Epoch: 186 [107520/225000 (48%)] Loss: 18823.449219\n",
      "Train Epoch: 186 [110016/225000 (49%)] Loss: 19198.783203\n",
      "Train Epoch: 186 [112512/225000 (50%)] Loss: 19328.558594\n",
      "Train Epoch: 186 [115008/225000 (51%)] Loss: 19084.300781\n",
      "Train Epoch: 186 [117504/225000 (52%)] Loss: 19101.837891\n",
      "Train Epoch: 186 [120000/225000 (53%)] Loss: 18769.468750\n",
      "Train Epoch: 186 [122496/225000 (54%)] Loss: 18643.806641\n",
      "Train Epoch: 186 [124992/225000 (56%)] Loss: 18957.703125\n",
      "Train Epoch: 186 [127488/225000 (57%)] Loss: 19158.158203\n",
      "Train Epoch: 186 [129984/225000 (58%)] Loss: 18740.070312\n",
      "Train Epoch: 186 [132480/225000 (59%)] Loss: 19069.796875\n",
      "Train Epoch: 186 [134976/225000 (60%)] Loss: 18944.416016\n",
      "Train Epoch: 186 [137472/225000 (61%)] Loss: 18536.605469\n",
      "Train Epoch: 186 [139968/225000 (62%)] Loss: 19188.837891\n",
      "Train Epoch: 186 [142464/225000 (63%)] Loss: 19070.652344\n",
      "Train Epoch: 186 [144960/225000 (64%)] Loss: 18907.406250\n",
      "Train Epoch: 186 [147456/225000 (66%)] Loss: 18962.406250\n",
      "Train Epoch: 186 [149952/225000 (67%)] Loss: 19114.722656\n",
      "Train Epoch: 186 [152448/225000 (68%)] Loss: 19501.792969\n",
      "Train Epoch: 186 [154944/225000 (69%)] Loss: 19229.777344\n",
      "Train Epoch: 186 [157440/225000 (70%)] Loss: 18714.095703\n",
      "Train Epoch: 186 [159936/225000 (71%)] Loss: 18909.511719\n",
      "Train Epoch: 186 [162432/225000 (72%)] Loss: 18995.009766\n",
      "Train Epoch: 186 [164928/225000 (73%)] Loss: 19120.380859\n",
      "Train Epoch: 186 [167424/225000 (74%)] Loss: 19202.171875\n",
      "Train Epoch: 186 [169920/225000 (76%)] Loss: 18979.189453\n",
      "Train Epoch: 186 [172416/225000 (77%)] Loss: 18401.794922\n",
      "Train Epoch: 186 [174912/225000 (78%)] Loss: 19110.324219\n",
      "Train Epoch: 186 [177408/225000 (79%)] Loss: 18844.078125\n",
      "Train Epoch: 186 [179904/225000 (80%)] Loss: 18687.890625\n",
      "Train Epoch: 186 [182400/225000 (81%)] Loss: 18865.226562\n",
      "Train Epoch: 186 [184896/225000 (82%)] Loss: 18827.220703\n",
      "Train Epoch: 186 [187392/225000 (83%)] Loss: 18982.910156\n",
      "Train Epoch: 186 [189888/225000 (84%)] Loss: 19084.707031\n",
      "Train Epoch: 186 [192384/225000 (86%)] Loss: 18920.292969\n",
      "Train Epoch: 186 [194880/225000 (87%)] Loss: 18718.433594\n",
      "Train Epoch: 186 [197376/225000 (88%)] Loss: 19477.626953\n",
      "Train Epoch: 186 [199872/225000 (89%)] Loss: 19364.050781\n",
      "Train Epoch: 186 [202368/225000 (90%)] Loss: 19533.753906\n",
      "Train Epoch: 186 [204864/225000 (91%)] Loss: 19251.708984\n",
      "Train Epoch: 186 [207360/225000 (92%)] Loss: 18724.824219\n",
      "Train Epoch: 186 [209856/225000 (93%)] Loss: 19195.714844\n",
      "Train Epoch: 186 [212352/225000 (94%)] Loss: 18874.156250\n",
      "Train Epoch: 186 [214848/225000 (95%)] Loss: 19287.734375\n",
      "Train Epoch: 186 [217344/225000 (97%)] Loss: 19286.765625\n",
      "Train Epoch: 186 [219840/225000 (98%)] Loss: 18524.984375\n",
      "Train Epoch: 186 [222336/225000 (99%)] Loss: 19164.476562\n",
      "Train Epoch: 186 [224832/225000 (100%)] Loss: 18830.515625\n",
      "    epoch          : 186\n",
      "    loss           : 19030.048071539037\n",
      "    val_loss       : 18964.189335028634\n",
      "Train Epoch: 187 [192/225000 (0%)] Loss: 19155.011719\n",
      "Train Epoch: 187 [2688/225000 (1%)] Loss: 19198.199219\n",
      "Train Epoch: 187 [5184/225000 (2%)] Loss: 19089.054688\n",
      "Train Epoch: 187 [7680/225000 (3%)] Loss: 19175.554688\n",
      "Train Epoch: 187 [10176/225000 (5%)] Loss: 18878.050781\n",
      "Train Epoch: 187 [12672/225000 (6%)] Loss: 18922.312500\n",
      "Train Epoch: 187 [15168/225000 (7%)] Loss: 18924.359375\n",
      "Train Epoch: 187 [17664/225000 (8%)] Loss: 24092.326172\n",
      "Train Epoch: 187 [20160/225000 (9%)] Loss: 19205.089844\n",
      "Train Epoch: 187 [22656/225000 (10%)] Loss: 18887.232422\n",
      "Train Epoch: 187 [25152/225000 (11%)] Loss: 19036.222656\n",
      "Train Epoch: 187 [27648/225000 (12%)] Loss: 18917.904297\n",
      "Train Epoch: 187 [30144/225000 (13%)] Loss: 19260.232422\n",
      "Train Epoch: 187 [32640/225000 (15%)] Loss: 18815.917969\n",
      "Train Epoch: 187 [35136/225000 (16%)] Loss: 18723.386719\n",
      "Train Epoch: 187 [37632/225000 (17%)] Loss: 18900.951172\n",
      "Train Epoch: 187 [40128/225000 (18%)] Loss: 18717.128906\n",
      "Train Epoch: 187 [42624/225000 (19%)] Loss: 19011.449219\n",
      "Train Epoch: 187 [45120/225000 (20%)] Loss: 18428.689453\n",
      "Train Epoch: 187 [47616/225000 (21%)] Loss: 19182.035156\n",
      "Train Epoch: 187 [50112/225000 (22%)] Loss: 19073.554688\n",
      "Train Epoch: 187 [52608/225000 (23%)] Loss: 19404.416016\n",
      "Train Epoch: 187 [55104/225000 (24%)] Loss: 18872.597656\n",
      "Train Epoch: 187 [57600/225000 (26%)] Loss: 19081.238281\n",
      "Train Epoch: 187 [60096/225000 (27%)] Loss: 18915.992188\n",
      "Train Epoch: 187 [62592/225000 (28%)] Loss: 18759.218750\n",
      "Train Epoch: 187 [65088/225000 (29%)] Loss: 18927.164062\n",
      "Train Epoch: 187 [67584/225000 (30%)] Loss: 18955.113281\n",
      "Train Epoch: 187 [70080/225000 (31%)] Loss: 19459.324219\n",
      "Train Epoch: 187 [72576/225000 (32%)] Loss: 18843.308594\n",
      "Train Epoch: 187 [75072/225000 (33%)] Loss: 19153.113281\n",
      "Train Epoch: 187 [77568/225000 (34%)] Loss: 18966.296875\n",
      "Train Epoch: 187 [80064/225000 (36%)] Loss: 19143.941406\n",
      "Train Epoch: 187 [82560/225000 (37%)] Loss: 19019.791016\n",
      "Train Epoch: 187 [85056/225000 (38%)] Loss: 19127.476562\n",
      "Train Epoch: 187 [87552/225000 (39%)] Loss: 18608.248047\n",
      "Train Epoch: 187 [90048/225000 (40%)] Loss: 19768.039062\n",
      "Train Epoch: 187 [92544/225000 (41%)] Loss: 19246.871094\n",
      "Train Epoch: 187 [95040/225000 (42%)] Loss: 19138.027344\n",
      "Train Epoch: 187 [97536/225000 (43%)] Loss: 18327.550781\n",
      "Train Epoch: 187 [100032/225000 (44%)] Loss: 19170.085938\n",
      "Train Epoch: 187 [102528/225000 (46%)] Loss: 18868.859375\n",
      "Train Epoch: 187 [105024/225000 (47%)] Loss: 19152.398438\n",
      "Train Epoch: 187 [107520/225000 (48%)] Loss: 19325.363281\n",
      "Train Epoch: 187 [110016/225000 (49%)] Loss: 19244.238281\n",
      "Train Epoch: 187 [112512/225000 (50%)] Loss: 19164.740234\n",
      "Train Epoch: 187 [115008/225000 (51%)] Loss: 19107.750000\n",
      "Train Epoch: 187 [117504/225000 (52%)] Loss: 19294.619141\n",
      "Train Epoch: 187 [120000/225000 (53%)] Loss: 18946.982422\n",
      "Train Epoch: 187 [122496/225000 (54%)] Loss: 19005.970703\n",
      "Train Epoch: 187 [124992/225000 (56%)] Loss: 19172.343750\n",
      "Train Epoch: 187 [127488/225000 (57%)] Loss: 19033.953125\n",
      "Train Epoch: 187 [129984/225000 (58%)] Loss: 18968.812500\n",
      "Train Epoch: 187 [132480/225000 (59%)] Loss: 19378.281250\n",
      "Train Epoch: 187 [134976/225000 (60%)] Loss: 18925.474609\n",
      "Train Epoch: 187 [137472/225000 (61%)] Loss: 18874.933594\n",
      "Train Epoch: 187 [139968/225000 (62%)] Loss: 19159.554688\n",
      "Train Epoch: 187 [142464/225000 (63%)] Loss: 18741.058594\n",
      "Train Epoch: 187 [144960/225000 (64%)] Loss: 18836.820312\n",
      "Train Epoch: 187 [147456/225000 (66%)] Loss: 19346.960938\n",
      "Train Epoch: 187 [149952/225000 (67%)] Loss: 18970.175781\n",
      "Train Epoch: 187 [152448/225000 (68%)] Loss: 19123.556641\n",
      "Train Epoch: 187 [154944/225000 (69%)] Loss: 19142.019531\n",
      "Train Epoch: 187 [157440/225000 (70%)] Loss: 18979.582031\n",
      "Train Epoch: 187 [159936/225000 (71%)] Loss: 18881.414062\n",
      "Train Epoch: 187 [162432/225000 (72%)] Loss: 18978.554688\n",
      "Train Epoch: 187 [164928/225000 (73%)] Loss: 19279.472656\n",
      "Train Epoch: 187 [167424/225000 (74%)] Loss: 19083.117188\n",
      "Train Epoch: 187 [169920/225000 (76%)] Loss: 18993.929688\n",
      "Train Epoch: 187 [172416/225000 (77%)] Loss: 18522.628906\n",
      "Train Epoch: 187 [174912/225000 (78%)] Loss: 19169.875000\n",
      "Train Epoch: 187 [177408/225000 (79%)] Loss: 19061.531250\n",
      "Train Epoch: 187 [179904/225000 (80%)] Loss: 18774.945312\n",
      "Train Epoch: 187 [182400/225000 (81%)] Loss: 19271.601562\n",
      "Train Epoch: 187 [184896/225000 (82%)] Loss: 19224.570312\n",
      "Train Epoch: 187 [187392/225000 (83%)] Loss: 19216.755859\n",
      "Train Epoch: 187 [189888/225000 (84%)] Loss: 18428.062500\n",
      "Train Epoch: 187 [192384/225000 (86%)] Loss: 18899.468750\n",
      "Train Epoch: 187 [194880/225000 (87%)] Loss: 19089.630859\n",
      "Train Epoch: 187 [197376/225000 (88%)] Loss: 19509.300781\n",
      "Train Epoch: 187 [199872/225000 (89%)] Loss: 18830.322266\n",
      "Train Epoch: 187 [202368/225000 (90%)] Loss: 19359.398438\n",
      "Train Epoch: 187 [204864/225000 (91%)] Loss: 19172.328125\n",
      "Train Epoch: 187 [207360/225000 (92%)] Loss: 18745.607422\n",
      "Train Epoch: 187 [209856/225000 (93%)] Loss: 18376.207031\n",
      "Train Epoch: 187 [212352/225000 (94%)] Loss: 19066.263672\n",
      "Train Epoch: 187 [214848/225000 (95%)] Loss: 19214.636719\n",
      "Train Epoch: 187 [217344/225000 (97%)] Loss: 19100.917969\n",
      "Train Epoch: 187 [219840/225000 (98%)] Loss: 18953.945312\n",
      "Train Epoch: 187 [222336/225000 (99%)] Loss: 18904.503906\n",
      "Train Epoch: 187 [224832/225000 (100%)] Loss: 18650.972656\n",
      "    epoch          : 187\n",
      "    loss           : 19029.136738747868\n",
      "    val_loss       : 18954.07008118029\n",
      "Train Epoch: 188 [192/225000 (0%)] Loss: 18731.207031\n",
      "Train Epoch: 188 [2688/225000 (1%)] Loss: 19066.816406\n",
      "Train Epoch: 188 [5184/225000 (2%)] Loss: 18765.246094\n",
      "Train Epoch: 188 [7680/225000 (3%)] Loss: 18685.644531\n",
      "Train Epoch: 188 [10176/225000 (5%)] Loss: 18980.113281\n",
      "Train Epoch: 188 [12672/225000 (6%)] Loss: 19269.292969\n",
      "Train Epoch: 188 [15168/225000 (7%)] Loss: 19147.197266\n",
      "Train Epoch: 188 [17664/225000 (8%)] Loss: 18969.869141\n",
      "Train Epoch: 188 [20160/225000 (9%)] Loss: 19620.921875\n",
      "Train Epoch: 188 [22656/225000 (10%)] Loss: 19046.863281\n",
      "Train Epoch: 188 [25152/225000 (11%)] Loss: 19076.623047\n",
      "Train Epoch: 188 [27648/225000 (12%)] Loss: 18509.554688\n",
      "Train Epoch: 188 [30144/225000 (13%)] Loss: 19196.707031\n",
      "Train Epoch: 188 [32640/225000 (15%)] Loss: 19415.181641\n",
      "Train Epoch: 188 [35136/225000 (16%)] Loss: 19336.734375\n",
      "Train Epoch: 188 [37632/225000 (17%)] Loss: 18604.308594\n",
      "Train Epoch: 188 [40128/225000 (18%)] Loss: 18488.613281\n",
      "Train Epoch: 188 [42624/225000 (19%)] Loss: 18997.466797\n",
      "Train Epoch: 188 [45120/225000 (20%)] Loss: 18580.580078\n",
      "Train Epoch: 188 [47616/225000 (21%)] Loss: 19146.087891\n",
      "Train Epoch: 188 [50112/225000 (22%)] Loss: 18740.820312\n",
      "Train Epoch: 188 [52608/225000 (23%)] Loss: 19056.660156\n",
      "Train Epoch: 188 [55104/225000 (24%)] Loss: 19282.300781\n",
      "Train Epoch: 188 [57600/225000 (26%)] Loss: 19042.601562\n",
      "Train Epoch: 188 [60096/225000 (27%)] Loss: 19186.542969\n",
      "Train Epoch: 188 [62592/225000 (28%)] Loss: 19151.023438\n",
      "Train Epoch: 188 [65088/225000 (29%)] Loss: 19132.164062\n",
      "Train Epoch: 188 [67584/225000 (30%)] Loss: 19008.179688\n",
      "Train Epoch: 188 [70080/225000 (31%)] Loss: 19015.312500\n",
      "Train Epoch: 188 [72576/225000 (32%)] Loss: 18997.691406\n",
      "Train Epoch: 188 [75072/225000 (33%)] Loss: 18409.746094\n",
      "Train Epoch: 188 [77568/225000 (34%)] Loss: 18706.578125\n",
      "Train Epoch: 188 [80064/225000 (36%)] Loss: 18554.191406\n",
      "Train Epoch: 188 [82560/225000 (37%)] Loss: 19263.113281\n",
      "Train Epoch: 188 [85056/225000 (38%)] Loss: 19017.273438\n",
      "Train Epoch: 188 [87552/225000 (39%)] Loss: 18227.050781\n",
      "Train Epoch: 188 [90048/225000 (40%)] Loss: 18857.636719\n",
      "Train Epoch: 188 [92544/225000 (41%)] Loss: 18676.718750\n",
      "Train Epoch: 188 [95040/225000 (42%)] Loss: 18672.857422\n",
      "Train Epoch: 188 [97536/225000 (43%)] Loss: 19101.412109\n",
      "Train Epoch: 188 [100032/225000 (44%)] Loss: 18913.101562\n",
      "Train Epoch: 188 [102528/225000 (46%)] Loss: 19140.533203\n",
      "Train Epoch: 188 [105024/225000 (47%)] Loss: 18671.251953\n",
      "Train Epoch: 188 [107520/225000 (48%)] Loss: 19040.250000\n",
      "Train Epoch: 188 [110016/225000 (49%)] Loss: 19251.257812\n",
      "Train Epoch: 188 [112512/225000 (50%)] Loss: 19358.542969\n",
      "Train Epoch: 188 [115008/225000 (51%)] Loss: 19402.615234\n",
      "Train Epoch: 188 [117504/225000 (52%)] Loss: 18926.269531\n",
      "Train Epoch: 188 [120000/225000 (53%)] Loss: 19190.394531\n",
      "Train Epoch: 188 [122496/225000 (54%)] Loss: 19341.992188\n",
      "Train Epoch: 188 [124992/225000 (56%)] Loss: 19175.783203\n",
      "Train Epoch: 188 [127488/225000 (57%)] Loss: 19002.488281\n",
      "Train Epoch: 188 [129984/225000 (58%)] Loss: 19068.539062\n",
      "Train Epoch: 188 [132480/225000 (59%)] Loss: 18439.693359\n",
      "Train Epoch: 188 [134976/225000 (60%)] Loss: 19278.960938\n",
      "Train Epoch: 188 [137472/225000 (61%)] Loss: 18644.000000\n",
      "Train Epoch: 188 [139968/225000 (62%)] Loss: 18746.800781\n",
      "Train Epoch: 188 [142464/225000 (63%)] Loss: 18713.187500\n",
      "Train Epoch: 188 [144960/225000 (64%)] Loss: 19247.841797\n",
      "Train Epoch: 188 [147456/225000 (66%)] Loss: 18876.746094\n",
      "Train Epoch: 188 [149952/225000 (67%)] Loss: 19072.486328\n",
      "Train Epoch: 188 [152448/225000 (68%)] Loss: 19207.125000\n",
      "Train Epoch: 188 [154944/225000 (69%)] Loss: 18919.250000\n",
      "Train Epoch: 188 [157440/225000 (70%)] Loss: 19392.710938\n",
      "Train Epoch: 188 [159936/225000 (71%)] Loss: 18822.312500\n",
      "Train Epoch: 188 [162432/225000 (72%)] Loss: 19117.429688\n",
      "Train Epoch: 188 [164928/225000 (73%)] Loss: 19069.375000\n",
      "Train Epoch: 188 [167424/225000 (74%)] Loss: 18884.046875\n",
      "Train Epoch: 188 [169920/225000 (76%)] Loss: 19336.839844\n",
      "Train Epoch: 188 [172416/225000 (77%)] Loss: 18671.492188\n",
      "Train Epoch: 188 [174912/225000 (78%)] Loss: 19411.382812\n",
      "Train Epoch: 188 [177408/225000 (79%)] Loss: 18883.689453\n",
      "Train Epoch: 188 [179904/225000 (80%)] Loss: 19253.246094\n",
      "Train Epoch: 188 [182400/225000 (81%)] Loss: 19059.031250\n",
      "Train Epoch: 188 [184896/225000 (82%)] Loss: 19135.425781\n",
      "Train Epoch: 188 [187392/225000 (83%)] Loss: 19325.710938\n",
      "Train Epoch: 188 [189888/225000 (84%)] Loss: 19061.833984\n",
      "Train Epoch: 188 [192384/225000 (86%)] Loss: 19032.224609\n",
      "Train Epoch: 188 [194880/225000 (87%)] Loss: 18903.271484\n",
      "Train Epoch: 188 [197376/225000 (88%)] Loss: 19419.210938\n",
      "Train Epoch: 188 [199872/225000 (89%)] Loss: 19400.906250\n",
      "Train Epoch: 188 [202368/225000 (90%)] Loss: 19043.128906\n",
      "Train Epoch: 188 [204864/225000 (91%)] Loss: 19140.402344\n",
      "Train Epoch: 188 [207360/225000 (92%)] Loss: 18746.494141\n",
      "Train Epoch: 188 [209856/225000 (93%)] Loss: 18718.070312\n",
      "Train Epoch: 188 [212352/225000 (94%)] Loss: 18982.412109\n",
      "Train Epoch: 188 [214848/225000 (95%)] Loss: 18977.687500\n",
      "Train Epoch: 188 [217344/225000 (97%)] Loss: 19239.933594\n",
      "Train Epoch: 188 [219840/225000 (98%)] Loss: 18724.597656\n",
      "Train Epoch: 188 [222336/225000 (99%)] Loss: 18765.857422\n",
      "Train Epoch: 188 [224832/225000 (100%)] Loss: 18765.250000\n",
      "    epoch          : 188\n",
      "    loss           : 19013.62665898971\n",
      "    val_loss       : 18917.968311406275\n",
      "Train Epoch: 189 [192/225000 (0%)] Loss: 18870.091797\n",
      "Train Epoch: 189 [2688/225000 (1%)] Loss: 18446.957031\n",
      "Train Epoch: 189 [5184/225000 (2%)] Loss: 18919.333984\n",
      "Train Epoch: 189 [7680/225000 (3%)] Loss: 19349.734375\n",
      "Train Epoch: 189 [10176/225000 (5%)] Loss: 19206.707031\n",
      "Train Epoch: 189 [12672/225000 (6%)] Loss: 18917.595703\n",
      "Train Epoch: 189 [15168/225000 (7%)] Loss: 19541.250000\n",
      "Train Epoch: 189 [17664/225000 (8%)] Loss: 18816.888672\n",
      "Train Epoch: 189 [20160/225000 (9%)] Loss: 18743.562500\n",
      "Train Epoch: 189 [22656/225000 (10%)] Loss: 19129.347656\n",
      "Train Epoch: 189 [25152/225000 (11%)] Loss: 18520.638672\n",
      "Train Epoch: 189 [27648/225000 (12%)] Loss: 19125.962891\n",
      "Train Epoch: 189 [30144/225000 (13%)] Loss: 19116.453125\n",
      "Train Epoch: 189 [32640/225000 (15%)] Loss: 19227.507812\n",
      "Train Epoch: 189 [35136/225000 (16%)] Loss: 18988.039062\n",
      "Train Epoch: 189 [37632/225000 (17%)] Loss: 19034.890625\n",
      "Train Epoch: 189 [40128/225000 (18%)] Loss: 18914.371094\n",
      "Train Epoch: 189 [42624/225000 (19%)] Loss: 19247.265625\n",
      "Train Epoch: 189 [45120/225000 (20%)] Loss: 19099.015625\n",
      "Train Epoch: 189 [47616/225000 (21%)] Loss: 18764.070312\n",
      "Train Epoch: 189 [50112/225000 (22%)] Loss: 19251.082031\n",
      "Train Epoch: 189 [52608/225000 (23%)] Loss: 18946.675781\n",
      "Train Epoch: 189 [55104/225000 (24%)] Loss: 19088.371094\n",
      "Train Epoch: 189 [57600/225000 (26%)] Loss: 19013.035156\n",
      "Train Epoch: 189 [60096/225000 (27%)] Loss: 19372.384766\n",
      "Train Epoch: 189 [62592/225000 (28%)] Loss: 19016.523438\n",
      "Train Epoch: 189 [65088/225000 (29%)] Loss: 18730.273438\n",
      "Train Epoch: 189 [67584/225000 (30%)] Loss: 19068.890625\n",
      "Train Epoch: 189 [70080/225000 (31%)] Loss: 19064.253906\n",
      "Train Epoch: 189 [72576/225000 (32%)] Loss: 19123.568359\n",
      "Train Epoch: 189 [75072/225000 (33%)] Loss: 18982.539062\n",
      "Train Epoch: 189 [77568/225000 (34%)] Loss: 19182.562500\n",
      "Train Epoch: 189 [80064/225000 (36%)] Loss: 18573.253906\n",
      "Train Epoch: 189 [82560/225000 (37%)] Loss: 19191.406250\n",
      "Train Epoch: 189 [85056/225000 (38%)] Loss: 19168.976562\n",
      "Train Epoch: 189 [87552/225000 (39%)] Loss: 19574.808594\n",
      "Train Epoch: 189 [90048/225000 (40%)] Loss: 19175.519531\n",
      "Train Epoch: 189 [92544/225000 (41%)] Loss: 18893.019531\n",
      "Train Epoch: 189 [95040/225000 (42%)] Loss: 19065.941406\n",
      "Train Epoch: 189 [97536/225000 (43%)] Loss: 19359.164062\n",
      "Train Epoch: 189 [100032/225000 (44%)] Loss: 19728.974609\n",
      "Train Epoch: 189 [102528/225000 (46%)] Loss: 18540.621094\n",
      "Train Epoch: 189 [105024/225000 (47%)] Loss: 19494.515625\n",
      "Train Epoch: 189 [107520/225000 (48%)] Loss: 18827.949219\n",
      "Train Epoch: 189 [110016/225000 (49%)] Loss: 19247.574219\n",
      "Train Epoch: 189 [112512/225000 (50%)] Loss: 19282.695312\n",
      "Train Epoch: 189 [115008/225000 (51%)] Loss: 19077.621094\n",
      "Train Epoch: 189 [117504/225000 (52%)] Loss: 19152.640625\n",
      "Train Epoch: 189 [120000/225000 (53%)] Loss: 19266.691406\n",
      "Train Epoch: 189 [122496/225000 (54%)] Loss: 19002.785156\n",
      "Train Epoch: 189 [124992/225000 (56%)] Loss: 19352.425781\n",
      "Train Epoch: 189 [127488/225000 (57%)] Loss: 19490.664062\n",
      "Train Epoch: 189 [129984/225000 (58%)] Loss: 19064.910156\n",
      "Train Epoch: 189 [132480/225000 (59%)] Loss: 18783.554688\n",
      "Train Epoch: 189 [134976/225000 (60%)] Loss: 18914.425781\n",
      "Train Epoch: 189 [137472/225000 (61%)] Loss: 19187.511719\n",
      "Train Epoch: 189 [139968/225000 (62%)] Loss: 19181.361328\n",
      "Train Epoch: 189 [142464/225000 (63%)] Loss: 19288.851562\n",
      "Train Epoch: 189 [144960/225000 (64%)] Loss: 18324.214844\n",
      "Train Epoch: 189 [147456/225000 (66%)] Loss: 18830.244141\n",
      "Train Epoch: 189 [149952/225000 (67%)] Loss: 19282.335938\n",
      "Train Epoch: 189 [152448/225000 (68%)] Loss: 18881.175781\n",
      "Train Epoch: 189 [154944/225000 (69%)] Loss: 18468.347656\n",
      "Train Epoch: 189 [157440/225000 (70%)] Loss: 19652.304688\n",
      "Train Epoch: 189 [159936/225000 (71%)] Loss: 18942.203125\n",
      "Train Epoch: 189 [162432/225000 (72%)] Loss: 18966.789062\n",
      "Train Epoch: 189 [164928/225000 (73%)] Loss: 18869.039062\n",
      "Train Epoch: 189 [167424/225000 (74%)] Loss: 18901.666016\n",
      "Train Epoch: 189 [169920/225000 (76%)] Loss: 19118.125000\n",
      "Train Epoch: 189 [172416/225000 (77%)] Loss: 18984.753906\n",
      "Train Epoch: 189 [174912/225000 (78%)] Loss: 18912.658203\n",
      "Train Epoch: 189 [177408/225000 (79%)] Loss: 19463.273438\n",
      "Train Epoch: 189 [179904/225000 (80%)] Loss: 18550.820312\n",
      "Train Epoch: 189 [182400/225000 (81%)] Loss: 18785.771484\n",
      "Train Epoch: 189 [184896/225000 (82%)] Loss: 19032.460938\n",
      "Train Epoch: 189 [187392/225000 (83%)] Loss: 18583.906250\n",
      "Train Epoch: 189 [189888/225000 (84%)] Loss: 18352.257812\n",
      "Train Epoch: 189 [192384/225000 (86%)] Loss: 19264.769531\n",
      "Train Epoch: 189 [194880/225000 (87%)] Loss: 18851.984375\n",
      "Train Epoch: 189 [197376/225000 (88%)] Loss: 18883.734375\n",
      "Train Epoch: 189 [199872/225000 (89%)] Loss: 18976.906250\n",
      "Train Epoch: 189 [202368/225000 (90%)] Loss: 19339.970703\n",
      "Train Epoch: 189 [204864/225000 (91%)] Loss: 18721.062500\n",
      "Train Epoch: 189 [207360/225000 (92%)] Loss: 18682.460938\n",
      "Train Epoch: 189 [209856/225000 (93%)] Loss: 19358.261719\n",
      "Train Epoch: 189 [212352/225000 (94%)] Loss: 18991.455078\n",
      "Train Epoch: 189 [214848/225000 (95%)] Loss: 19395.421875\n",
      "Train Epoch: 189 [217344/225000 (97%)] Loss: 19284.972656\n",
      "Train Epoch: 189 [219840/225000 (98%)] Loss: 18894.546875\n",
      "Train Epoch: 189 [222336/225000 (99%)] Loss: 18721.933594\n",
      "Train Epoch: 189 [224832/225000 (100%)] Loss: 19699.949219\n",
      "    epoch          : 189\n",
      "    loss           : 18997.57231395318\n",
      "    val_loss       : 18892.923356208183\n",
      "Train Epoch: 190 [192/225000 (0%)] Loss: 19139.197266\n",
      "Train Epoch: 190 [2688/225000 (1%)] Loss: 19227.957031\n",
      "Train Epoch: 190 [5184/225000 (2%)] Loss: 18572.511719\n",
      "Train Epoch: 190 [7680/225000 (3%)] Loss: 18916.781250\n",
      "Train Epoch: 190 [10176/225000 (5%)] Loss: 19326.390625\n",
      "Train Epoch: 190 [12672/225000 (6%)] Loss: 19444.144531\n",
      "Train Epoch: 190 [15168/225000 (7%)] Loss: 18731.009766\n",
      "Train Epoch: 190 [17664/225000 (8%)] Loss: 19339.300781\n",
      "Train Epoch: 190 [20160/225000 (9%)] Loss: 19110.035156\n",
      "Train Epoch: 190 [22656/225000 (10%)] Loss: 18960.480469\n",
      "Train Epoch: 190 [25152/225000 (11%)] Loss: 18601.638672\n",
      "Train Epoch: 190 [27648/225000 (12%)] Loss: 18967.085938\n",
      "Train Epoch: 190 [30144/225000 (13%)] Loss: 18922.960938\n",
      "Train Epoch: 190 [32640/225000 (15%)] Loss: 19383.732422\n",
      "Train Epoch: 190 [35136/225000 (16%)] Loss: 18768.968750\n",
      "Train Epoch: 190 [37632/225000 (17%)] Loss: 18597.621094\n",
      "Train Epoch: 190 [40128/225000 (18%)] Loss: 19470.875000\n",
      "Train Epoch: 190 [42624/225000 (19%)] Loss: 19179.460938\n",
      "Train Epoch: 190 [45120/225000 (20%)] Loss: 18732.007812\n",
      "Train Epoch: 190 [47616/225000 (21%)] Loss: 18857.771484\n",
      "Train Epoch: 190 [50112/225000 (22%)] Loss: 19581.910156\n",
      "Train Epoch: 190 [52608/225000 (23%)] Loss: 19145.468750\n",
      "Train Epoch: 190 [55104/225000 (24%)] Loss: 18744.626953\n",
      "Train Epoch: 190 [57600/225000 (26%)] Loss: 19094.558594\n",
      "Train Epoch: 190 [60096/225000 (27%)] Loss: 19525.500000\n",
      "Train Epoch: 190 [62592/225000 (28%)] Loss: 18440.330078\n",
      "Train Epoch: 190 [65088/225000 (29%)] Loss: 19143.335938\n",
      "Train Epoch: 190 [67584/225000 (30%)] Loss: 18688.796875\n",
      "Train Epoch: 190 [70080/225000 (31%)] Loss: 19195.960938\n",
      "Train Epoch: 190 [72576/225000 (32%)] Loss: 18980.355469\n",
      "Train Epoch: 190 [75072/225000 (33%)] Loss: 19333.896484\n",
      "Train Epoch: 190 [77568/225000 (34%)] Loss: 18970.890625\n",
      "Train Epoch: 190 [80064/225000 (36%)] Loss: 19090.546875\n",
      "Train Epoch: 190 [82560/225000 (37%)] Loss: 18547.167969\n",
      "Train Epoch: 190 [85056/225000 (38%)] Loss: 19385.042969\n",
      "Train Epoch: 190 [87552/225000 (39%)] Loss: 19145.677734\n",
      "Train Epoch: 190 [90048/225000 (40%)] Loss: 18952.097656\n",
      "Train Epoch: 190 [92544/225000 (41%)] Loss: 19125.310547\n",
      "Train Epoch: 190 [95040/225000 (42%)] Loss: 19138.582031\n",
      "Train Epoch: 190 [97536/225000 (43%)] Loss: 18814.234375\n",
      "Train Epoch: 190 [100032/225000 (44%)] Loss: 19447.066406\n",
      "Train Epoch: 190 [102528/225000 (46%)] Loss: 19453.652344\n",
      "Train Epoch: 190 [105024/225000 (47%)] Loss: 19423.402344\n",
      "Train Epoch: 190 [107520/225000 (48%)] Loss: 18839.636719\n",
      "Train Epoch: 190 [110016/225000 (49%)] Loss: 19100.316406\n",
      "Train Epoch: 190 [112512/225000 (50%)] Loss: 18733.515625\n",
      "Train Epoch: 190 [115008/225000 (51%)] Loss: 18759.216797\n",
      "Train Epoch: 190 [117504/225000 (52%)] Loss: 19369.203125\n",
      "Train Epoch: 190 [120000/225000 (53%)] Loss: 19001.863281\n",
      "Train Epoch: 190 [122496/225000 (54%)] Loss: 19144.046875\n",
      "Train Epoch: 190 [124992/225000 (56%)] Loss: 18882.957031\n",
      "Train Epoch: 190 [127488/225000 (57%)] Loss: 18701.585938\n",
      "Train Epoch: 190 [129984/225000 (58%)] Loss: 19272.601562\n",
      "Train Epoch: 190 [132480/225000 (59%)] Loss: 18840.632812\n",
      "Train Epoch: 190 [134976/225000 (60%)] Loss: 19607.982422\n",
      "Train Epoch: 190 [137472/225000 (61%)] Loss: 18918.019531\n",
      "Train Epoch: 190 [139968/225000 (62%)] Loss: 18766.410156\n",
      "Train Epoch: 190 [142464/225000 (63%)] Loss: 19172.156250\n",
      "Train Epoch: 190 [144960/225000 (64%)] Loss: 18843.964844\n",
      "Train Epoch: 190 [147456/225000 (66%)] Loss: 19239.953125\n",
      "Train Epoch: 190 [149952/225000 (67%)] Loss: 18790.437500\n",
      "Train Epoch: 190 [152448/225000 (68%)] Loss: 18983.576172\n",
      "Train Epoch: 190 [154944/225000 (69%)] Loss: 18810.050781\n",
      "Train Epoch: 190 [157440/225000 (70%)] Loss: 18849.707031\n",
      "Train Epoch: 190 [159936/225000 (71%)] Loss: 19078.875000\n",
      "Train Epoch: 190 [162432/225000 (72%)] Loss: 18993.353516\n",
      "Train Epoch: 190 [164928/225000 (73%)] Loss: 18657.003906\n",
      "Train Epoch: 190 [167424/225000 (74%)] Loss: 18788.388672\n",
      "Train Epoch: 190 [169920/225000 (76%)] Loss: 19434.792969\n",
      "Train Epoch: 190 [172416/225000 (77%)] Loss: 18695.408203\n",
      "Train Epoch: 190 [174912/225000 (78%)] Loss: 19335.562500\n",
      "Train Epoch: 190 [177408/225000 (79%)] Loss: 18866.208984\n",
      "Train Epoch: 190 [179904/225000 (80%)] Loss: 18212.292969\n",
      "Train Epoch: 190 [182400/225000 (81%)] Loss: 19145.687500\n",
      "Train Epoch: 190 [184896/225000 (82%)] Loss: 18847.863281\n",
      "Train Epoch: 190 [187392/225000 (83%)] Loss: 18916.634766\n",
      "Train Epoch: 190 [189888/225000 (84%)] Loss: 18988.035156\n",
      "Train Epoch: 190 [192384/225000 (86%)] Loss: 18560.115234\n",
      "Train Epoch: 190 [194880/225000 (87%)] Loss: 18869.671875\n",
      "Train Epoch: 190 [197376/225000 (88%)] Loss: 18950.441406\n",
      "Train Epoch: 190 [199872/225000 (89%)] Loss: 19456.505859\n",
      "Train Epoch: 190 [202368/225000 (90%)] Loss: 18989.570312\n",
      "Train Epoch: 190 [204864/225000 (91%)] Loss: 18884.816406\n",
      "Train Epoch: 190 [207360/225000 (92%)] Loss: 18713.921875\n",
      "Train Epoch: 190 [209856/225000 (93%)] Loss: 18971.019531\n",
      "Train Epoch: 190 [212352/225000 (94%)] Loss: 19015.855469\n",
      "Train Epoch: 190 [214848/225000 (95%)] Loss: 18873.871094\n",
      "Train Epoch: 190 [217344/225000 (97%)] Loss: 18933.062500\n",
      "Train Epoch: 190 [219840/225000 (98%)] Loss: 19137.347656\n",
      "Train Epoch: 190 [222336/225000 (99%)] Loss: 19163.160156\n",
      "Train Epoch: 190 [224832/225000 (100%)] Loss: 18913.949219\n",
      "    epoch          : 190\n",
      "    loss           : 18990.82640351696\n",
      "    val_loss       : 18876.813005350017\n",
      "Train Epoch: 191 [192/225000 (0%)] Loss: 19106.695312\n",
      "Train Epoch: 191 [2688/225000 (1%)] Loss: 19057.343750\n",
      "Train Epoch: 191 [5184/225000 (2%)] Loss: 18901.814453\n",
      "Train Epoch: 191 [7680/225000 (3%)] Loss: 18671.191406\n",
      "Train Epoch: 191 [10176/225000 (5%)] Loss: 18670.570312\n",
      "Train Epoch: 191 [12672/225000 (6%)] Loss: 18976.867188\n",
      "Train Epoch: 191 [15168/225000 (7%)] Loss: 19174.507812\n",
      "Train Epoch: 191 [17664/225000 (8%)] Loss: 19003.570312\n",
      "Train Epoch: 191 [20160/225000 (9%)] Loss: 19228.250000\n",
      "Train Epoch: 191 [22656/225000 (10%)] Loss: 19002.261719\n",
      "Train Epoch: 191 [25152/225000 (11%)] Loss: 19847.308594\n",
      "Train Epoch: 191 [27648/225000 (12%)] Loss: 18804.246094\n",
      "Train Epoch: 191 [30144/225000 (13%)] Loss: 19192.056641\n",
      "Train Epoch: 191 [32640/225000 (15%)] Loss: 19103.369141\n",
      "Train Epoch: 191 [35136/225000 (16%)] Loss: 18826.132812\n",
      "Train Epoch: 191 [37632/225000 (17%)] Loss: 18914.126953\n",
      "Train Epoch: 191 [40128/225000 (18%)] Loss: 19435.914062\n",
      "Train Epoch: 191 [42624/225000 (19%)] Loss: 18721.097656\n",
      "Train Epoch: 191 [45120/225000 (20%)] Loss: 18920.542969\n",
      "Train Epoch: 191 [47616/225000 (21%)] Loss: 18646.898438\n",
      "Train Epoch: 191 [50112/225000 (22%)] Loss: 18977.230469\n",
      "Train Epoch: 191 [52608/225000 (23%)] Loss: 18897.128906\n",
      "Train Epoch: 191 [55104/225000 (24%)] Loss: 18769.171875\n",
      "Train Epoch: 191 [57600/225000 (26%)] Loss: 18678.878906\n",
      "Train Epoch: 191 [60096/225000 (27%)] Loss: 18595.253906\n",
      "Train Epoch: 191 [62592/225000 (28%)] Loss: 18895.191406\n",
      "Train Epoch: 191 [65088/225000 (29%)] Loss: 18734.093750\n",
      "Train Epoch: 191 [67584/225000 (30%)] Loss: 19028.828125\n",
      "Train Epoch: 191 [70080/225000 (31%)] Loss: 18878.550781\n",
      "Train Epoch: 191 [72576/225000 (32%)] Loss: 19111.853516\n",
      "Train Epoch: 191 [75072/225000 (33%)] Loss: 19728.798828\n",
      "Train Epoch: 191 [77568/225000 (34%)] Loss: 19278.335938\n",
      "Train Epoch: 191 [80064/225000 (36%)] Loss: 18610.042969\n",
      "Train Epoch: 191 [82560/225000 (37%)] Loss: 19325.710938\n",
      "Train Epoch: 191 [85056/225000 (38%)] Loss: 19085.187500\n",
      "Train Epoch: 191 [87552/225000 (39%)] Loss: 19203.511719\n",
      "Train Epoch: 191 [90048/225000 (40%)] Loss: 19130.031250\n",
      "Train Epoch: 191 [92544/225000 (41%)] Loss: 19000.136719\n",
      "Train Epoch: 191 [95040/225000 (42%)] Loss: 19443.847656\n",
      "Train Epoch: 191 [97536/225000 (43%)] Loss: 19243.269531\n",
      "Train Epoch: 191 [100032/225000 (44%)] Loss: 19091.646484\n",
      "Train Epoch: 191 [102528/225000 (46%)] Loss: 19320.066406\n",
      "Train Epoch: 191 [105024/225000 (47%)] Loss: 18483.914062\n",
      "Train Epoch: 191 [107520/225000 (48%)] Loss: 18830.226562\n",
      "Train Epoch: 191 [110016/225000 (49%)] Loss: 19570.160156\n",
      "Train Epoch: 191 [112512/225000 (50%)] Loss: 19271.871094\n",
      "Train Epoch: 191 [115008/225000 (51%)] Loss: 18392.871094\n",
      "Train Epoch: 191 [117504/225000 (52%)] Loss: 18897.482422\n",
      "Train Epoch: 191 [120000/225000 (53%)] Loss: 18599.890625\n",
      "Train Epoch: 191 [122496/225000 (54%)] Loss: 18528.738281\n",
      "Train Epoch: 191 [124992/225000 (56%)] Loss: 19011.978516\n",
      "Train Epoch: 191 [127488/225000 (57%)] Loss: 18779.078125\n",
      "Train Epoch: 191 [129984/225000 (58%)] Loss: 19070.800781\n",
      "Train Epoch: 191 [132480/225000 (59%)] Loss: 18493.382812\n",
      "Train Epoch: 191 [134976/225000 (60%)] Loss: 18646.343750\n",
      "Train Epoch: 191 [137472/225000 (61%)] Loss: 18943.164062\n",
      "Train Epoch: 191 [139968/225000 (62%)] Loss: 18884.595703\n",
      "Train Epoch: 191 [142464/225000 (63%)] Loss: 18947.718750\n",
      "Train Epoch: 191 [144960/225000 (64%)] Loss: 19081.705078\n",
      "Train Epoch: 191 [147456/225000 (66%)] Loss: 19184.148438\n",
      "Train Epoch: 191 [149952/225000 (67%)] Loss: 18728.222656\n",
      "Train Epoch: 191 [152448/225000 (68%)] Loss: 18844.281250\n",
      "Train Epoch: 191 [154944/225000 (69%)] Loss: 19256.222656\n",
      "Train Epoch: 191 [157440/225000 (70%)] Loss: 18708.250000\n",
      "Train Epoch: 191 [159936/225000 (71%)] Loss: 18835.130859\n",
      "Train Epoch: 191 [162432/225000 (72%)] Loss: 19089.113281\n",
      "Train Epoch: 191 [164928/225000 (73%)] Loss: 18780.511719\n",
      "Train Epoch: 191 [167424/225000 (74%)] Loss: 19572.773438\n",
      "Train Epoch: 191 [169920/225000 (76%)] Loss: 18699.078125\n",
      "Train Epoch: 191 [172416/225000 (77%)] Loss: 19234.457031\n",
      "Train Epoch: 191 [174912/225000 (78%)] Loss: 19238.027344\n",
      "Train Epoch: 191 [177408/225000 (79%)] Loss: 18898.628906\n",
      "Train Epoch: 191 [179904/225000 (80%)] Loss: 18652.343750\n",
      "Train Epoch: 191 [182400/225000 (81%)] Loss: 19482.160156\n",
      "Train Epoch: 191 [184896/225000 (82%)] Loss: 18748.447266\n",
      "Train Epoch: 191 [187392/225000 (83%)] Loss: 18879.164062\n",
      "Train Epoch: 191 [189888/225000 (84%)] Loss: 18880.082031\n",
      "Train Epoch: 191 [192384/225000 (86%)] Loss: 18650.054688\n",
      "Train Epoch: 191 [194880/225000 (87%)] Loss: 18898.726562\n",
      "Train Epoch: 191 [197376/225000 (88%)] Loss: 18700.849609\n",
      "Train Epoch: 191 [199872/225000 (89%)] Loss: 19363.156250\n",
      "Train Epoch: 191 [202368/225000 (90%)] Loss: 19304.695312\n",
      "Train Epoch: 191 [204864/225000 (91%)] Loss: 19214.128906\n",
      "Train Epoch: 191 [207360/225000 (92%)] Loss: 18619.779297\n",
      "Train Epoch: 191 [209856/225000 (93%)] Loss: 19145.460938\n",
      "Train Epoch: 191 [212352/225000 (94%)] Loss: 18898.341797\n",
      "Train Epoch: 191 [214848/225000 (95%)] Loss: 19093.109375\n",
      "Train Epoch: 191 [217344/225000 (97%)] Loss: 18982.162109\n",
      "Train Epoch: 191 [219840/225000 (98%)] Loss: 19092.378906\n",
      "Train Epoch: 191 [222336/225000 (99%)] Loss: 18859.859375\n",
      "Train Epoch: 191 [224832/225000 (100%)] Loss: 18967.972656\n",
      "    epoch          : 191\n",
      "    loss           : 18973.451373520158\n",
      "    val_loss       : 18874.029200026096\n",
      "Train Epoch: 192 [192/225000 (0%)] Loss: 19335.078125\n",
      "Train Epoch: 192 [2688/225000 (1%)] Loss: 19049.050781\n",
      "Train Epoch: 192 [5184/225000 (2%)] Loss: 18745.621094\n",
      "Train Epoch: 192 [7680/225000 (3%)] Loss: 18804.175781\n",
      "Train Epoch: 192 [10176/225000 (5%)] Loss: 18838.302734\n",
      "Train Epoch: 192 [12672/225000 (6%)] Loss: 18539.871094\n",
      "Train Epoch: 192 [15168/225000 (7%)] Loss: 19180.429688\n",
      "Train Epoch: 192 [17664/225000 (8%)] Loss: 18985.363281\n",
      "Train Epoch: 192 [20160/225000 (9%)] Loss: 18657.187500\n",
      "Train Epoch: 192 [22656/225000 (10%)] Loss: 18888.171875\n",
      "Train Epoch: 192 [25152/225000 (11%)] Loss: 18679.353516\n",
      "Train Epoch: 192 [27648/225000 (12%)] Loss: 18760.957031\n",
      "Train Epoch: 192 [30144/225000 (13%)] Loss: 19590.865234\n",
      "Train Epoch: 192 [32640/225000 (15%)] Loss: 19007.425781\n",
      "Train Epoch: 192 [35136/225000 (16%)] Loss: 19458.523438\n",
      "Train Epoch: 192 [37632/225000 (17%)] Loss: 18820.394531\n",
      "Train Epoch: 192 [40128/225000 (18%)] Loss: 19171.519531\n",
      "Train Epoch: 192 [42624/225000 (19%)] Loss: 18772.765625\n",
      "Train Epoch: 192 [45120/225000 (20%)] Loss: 18774.710938\n",
      "Train Epoch: 192 [47616/225000 (21%)] Loss: 19438.421875\n",
      "Train Epoch: 192 [50112/225000 (22%)] Loss: 18320.179688\n",
      "Train Epoch: 192 [52608/225000 (23%)] Loss: 19015.621094\n",
      "Train Epoch: 192 [55104/225000 (24%)] Loss: 18638.263672\n",
      "Train Epoch: 192 [57600/225000 (26%)] Loss: 19191.367188\n",
      "Train Epoch: 192 [60096/225000 (27%)] Loss: 18799.367188\n",
      "Train Epoch: 192 [62592/225000 (28%)] Loss: 18855.449219\n",
      "Train Epoch: 192 [65088/225000 (29%)] Loss: 18596.015625\n",
      "Train Epoch: 192 [67584/225000 (30%)] Loss: 19212.539062\n",
      "Train Epoch: 192 [70080/225000 (31%)] Loss: 18568.222656\n",
      "Train Epoch: 192 [72576/225000 (32%)] Loss: 18725.998047\n",
      "Train Epoch: 192 [75072/225000 (33%)] Loss: 19257.384766\n",
      "Train Epoch: 192 [77568/225000 (34%)] Loss: 19221.576172\n",
      "Train Epoch: 192 [80064/225000 (36%)] Loss: 19157.359375\n",
      "Train Epoch: 192 [82560/225000 (37%)] Loss: 18844.062500\n",
      "Train Epoch: 192 [85056/225000 (38%)] Loss: 18755.593750\n",
      "Train Epoch: 192 [87552/225000 (39%)] Loss: 18248.552734\n",
      "Train Epoch: 192 [90048/225000 (40%)] Loss: 18481.634766\n",
      "Train Epoch: 192 [92544/225000 (41%)] Loss: 18891.804688\n",
      "Train Epoch: 192 [95040/225000 (42%)] Loss: 19085.611328\n",
      "Train Epoch: 192 [97536/225000 (43%)] Loss: 18970.175781\n",
      "Train Epoch: 192 [100032/225000 (44%)] Loss: 19058.519531\n",
      "Train Epoch: 192 [102528/225000 (46%)] Loss: 18790.212891\n",
      "Train Epoch: 192 [105024/225000 (47%)] Loss: 18773.005859\n",
      "Train Epoch: 192 [107520/225000 (48%)] Loss: 18707.558594\n",
      "Train Epoch: 192 [110016/225000 (49%)] Loss: 19257.535156\n",
      "Train Epoch: 192 [112512/225000 (50%)] Loss: 18664.421875\n",
      "Train Epoch: 192 [115008/225000 (51%)] Loss: 18815.468750\n",
      "Train Epoch: 192 [117504/225000 (52%)] Loss: 18971.884766\n",
      "Train Epoch: 192 [120000/225000 (53%)] Loss: 19133.726562\n",
      "Train Epoch: 192 [122496/225000 (54%)] Loss: 19152.658203\n",
      "Train Epoch: 192 [124992/225000 (56%)] Loss: 18824.226562\n",
      "Train Epoch: 192 [127488/225000 (57%)] Loss: 19183.925781\n",
      "Train Epoch: 192 [129984/225000 (58%)] Loss: 18653.964844\n",
      "Train Epoch: 192 [132480/225000 (59%)] Loss: 18874.492188\n",
      "Train Epoch: 192 [134976/225000 (60%)] Loss: 18891.480469\n",
      "Train Epoch: 192 [137472/225000 (61%)] Loss: 18740.316406\n",
      "Train Epoch: 192 [139968/225000 (62%)] Loss: 18966.455078\n",
      "Train Epoch: 192 [142464/225000 (63%)] Loss: 18840.343750\n",
      "Train Epoch: 192 [144960/225000 (64%)] Loss: 19069.988281\n",
      "Train Epoch: 192 [147456/225000 (66%)] Loss: 18956.335938\n",
      "Train Epoch: 192 [149952/225000 (67%)] Loss: 19179.644531\n",
      "Train Epoch: 192 [152448/225000 (68%)] Loss: 19161.761719\n",
      "Train Epoch: 192 [154944/225000 (69%)] Loss: 19481.986328\n",
      "Train Epoch: 192 [157440/225000 (70%)] Loss: 19147.558594\n",
      "Train Epoch: 192 [159936/225000 (71%)] Loss: 19178.375000\n",
      "Train Epoch: 192 [162432/225000 (72%)] Loss: 19158.068359\n",
      "Train Epoch: 192 [164928/225000 (73%)] Loss: 18494.039062\n",
      "Train Epoch: 192 [167424/225000 (74%)] Loss: 19270.597656\n",
      "Train Epoch: 192 [169920/225000 (76%)] Loss: 19333.214844\n",
      "Train Epoch: 192 [172416/225000 (77%)] Loss: 18952.283203\n",
      "Train Epoch: 192 [174912/225000 (78%)] Loss: 18763.417969\n",
      "Train Epoch: 192 [177408/225000 (79%)] Loss: 19064.056641\n",
      "Train Epoch: 192 [179904/225000 (80%)] Loss: 18863.576172\n",
      "Train Epoch: 192 [182400/225000 (81%)] Loss: 18897.710938\n",
      "Train Epoch: 192 [184896/225000 (82%)] Loss: 18907.531250\n",
      "Train Epoch: 192 [187392/225000 (83%)] Loss: 19248.378906\n",
      "Train Epoch: 192 [189888/225000 (84%)] Loss: 18817.796875\n",
      "Train Epoch: 192 [192384/225000 (86%)] Loss: 18556.890625\n",
      "Train Epoch: 192 [194880/225000 (87%)] Loss: 18978.343750\n",
      "Train Epoch: 192 [197376/225000 (88%)] Loss: 18507.761719\n",
      "Train Epoch: 192 [199872/225000 (89%)] Loss: 18850.878906\n",
      "Train Epoch: 192 [202368/225000 (90%)] Loss: 18991.023438\n",
      "Train Epoch: 192 [204864/225000 (91%)] Loss: 18590.509766\n",
      "Train Epoch: 192 [207360/225000 (92%)] Loss: 19468.210938\n",
      "Train Epoch: 192 [209856/225000 (93%)] Loss: 18976.886719\n",
      "Train Epoch: 192 [212352/225000 (94%)] Loss: 18822.441406\n",
      "Train Epoch: 192 [214848/225000 (95%)] Loss: 18714.841797\n",
      "Train Epoch: 192 [217344/225000 (97%)] Loss: 18876.515625\n",
      "Train Epoch: 192 [219840/225000 (98%)] Loss: 18796.218750\n",
      "Train Epoch: 192 [222336/225000 (99%)] Loss: 19086.125000\n",
      "Train Epoch: 192 [224832/225000 (100%)] Loss: 19395.718750\n",
      "    epoch          : 192\n",
      "    loss           : 18964.336650757254\n",
      "    val_loss       : 18859.979279801137\n",
      "Train Epoch: 193 [192/225000 (0%)] Loss: 18536.185547\n",
      "Train Epoch: 193 [2688/225000 (1%)] Loss: 18929.230469\n",
      "Train Epoch: 193 [5184/225000 (2%)] Loss: 18925.386719\n",
      "Train Epoch: 193 [7680/225000 (3%)] Loss: 18910.960938\n",
      "Train Epoch: 193 [10176/225000 (5%)] Loss: 19031.935547\n",
      "Train Epoch: 193 [12672/225000 (6%)] Loss: 18704.558594\n",
      "Train Epoch: 193 [15168/225000 (7%)] Loss: 18911.847656\n",
      "Train Epoch: 193 [17664/225000 (8%)] Loss: 18784.246094\n",
      "Train Epoch: 193 [20160/225000 (9%)] Loss: 19221.386719\n",
      "Train Epoch: 193 [22656/225000 (10%)] Loss: 18900.496094\n",
      "Train Epoch: 193 [25152/225000 (11%)] Loss: 19454.699219\n",
      "Train Epoch: 193 [27648/225000 (12%)] Loss: 18842.062500\n",
      "Train Epoch: 193 [30144/225000 (13%)] Loss: 18726.320312\n",
      "Train Epoch: 193 [32640/225000 (15%)] Loss: 19225.685547\n",
      "Train Epoch: 193 [35136/225000 (16%)] Loss: 18705.845703\n",
      "Train Epoch: 193 [37632/225000 (17%)] Loss: 19552.566406\n",
      "Train Epoch: 193 [40128/225000 (18%)] Loss: 18737.726562\n",
      "Train Epoch: 193 [42624/225000 (19%)] Loss: 18922.345703\n",
      "Train Epoch: 193 [45120/225000 (20%)] Loss: 18796.812500\n",
      "Train Epoch: 193 [47616/225000 (21%)] Loss: 18906.962891\n",
      "Train Epoch: 193 [50112/225000 (22%)] Loss: 18285.582031\n",
      "Train Epoch: 193 [52608/225000 (23%)] Loss: 19032.330078\n",
      "Train Epoch: 193 [55104/225000 (24%)] Loss: 19110.441406\n",
      "Train Epoch: 193 [57600/225000 (26%)] Loss: 19108.812500\n",
      "Train Epoch: 193 [60096/225000 (27%)] Loss: 19013.726562\n",
      "Train Epoch: 193 [62592/225000 (28%)] Loss: 18977.041016\n",
      "Train Epoch: 193 [65088/225000 (29%)] Loss: 19027.210938\n",
      "Train Epoch: 193 [67584/225000 (30%)] Loss: 18755.597656\n",
      "Train Epoch: 193 [70080/225000 (31%)] Loss: 18655.619141\n",
      "Train Epoch: 193 [72576/225000 (32%)] Loss: 19198.712891\n",
      "Train Epoch: 193 [75072/225000 (33%)] Loss: 18772.552734\n",
      "Train Epoch: 193 [77568/225000 (34%)] Loss: 18773.960938\n",
      "Train Epoch: 193 [80064/225000 (36%)] Loss: 18733.640625\n",
      "Train Epoch: 193 [82560/225000 (37%)] Loss: 19008.910156\n",
      "Train Epoch: 193 [85056/225000 (38%)] Loss: 18712.621094\n",
      "Train Epoch: 193 [87552/225000 (39%)] Loss: 18853.994141\n",
      "Train Epoch: 193 [90048/225000 (40%)] Loss: 18340.136719\n",
      "Train Epoch: 193 [92544/225000 (41%)] Loss: 18910.199219\n",
      "Train Epoch: 193 [95040/225000 (42%)] Loss: 18902.468750\n",
      "Train Epoch: 193 [97536/225000 (43%)] Loss: 19344.000000\n",
      "Train Epoch: 193 [100032/225000 (44%)] Loss: 19234.654297\n",
      "Train Epoch: 193 [102528/225000 (46%)] Loss: 19115.128906\n",
      "Train Epoch: 193 [105024/225000 (47%)] Loss: 18963.910156\n",
      "Train Epoch: 193 [107520/225000 (48%)] Loss: 18870.789062\n",
      "Train Epoch: 193 [110016/225000 (49%)] Loss: 18772.144531\n",
      "Train Epoch: 193 [112512/225000 (50%)] Loss: 18587.277344\n",
      "Train Epoch: 193 [115008/225000 (51%)] Loss: 19265.048828\n",
      "Train Epoch: 193 [117504/225000 (52%)] Loss: 19134.519531\n",
      "Train Epoch: 193 [120000/225000 (53%)] Loss: 18784.207031\n",
      "Train Epoch: 193 [122496/225000 (54%)] Loss: 18487.074219\n",
      "Train Epoch: 193 [124992/225000 (56%)] Loss: 19219.382812\n",
      "Train Epoch: 193 [127488/225000 (57%)] Loss: 19102.714844\n",
      "Train Epoch: 193 [129984/225000 (58%)] Loss: 18792.632812\n",
      "Train Epoch: 193 [132480/225000 (59%)] Loss: 18725.839844\n",
      "Train Epoch: 193 [134976/225000 (60%)] Loss: 18775.201172\n",
      "Train Epoch: 193 [137472/225000 (61%)] Loss: 18757.250000\n",
      "Train Epoch: 193 [139968/225000 (62%)] Loss: 19030.441406\n",
      "Train Epoch: 193 [142464/225000 (63%)] Loss: 19122.953125\n",
      "Train Epoch: 193 [144960/225000 (64%)] Loss: 18916.734375\n",
      "Train Epoch: 193 [147456/225000 (66%)] Loss: 19082.455078\n",
      "Train Epoch: 193 [149952/225000 (67%)] Loss: 18810.511719\n",
      "Train Epoch: 193 [152448/225000 (68%)] Loss: 19107.617188\n",
      "Train Epoch: 193 [154944/225000 (69%)] Loss: 19240.292969\n",
      "Train Epoch: 193 [157440/225000 (70%)] Loss: 19024.242188\n",
      "Train Epoch: 193 [159936/225000 (71%)] Loss: 18738.765625\n",
      "Train Epoch: 193 [162432/225000 (72%)] Loss: 18297.351562\n",
      "Train Epoch: 193 [164928/225000 (73%)] Loss: 18603.117188\n",
      "Train Epoch: 193 [167424/225000 (74%)] Loss: 19176.804688\n",
      "Train Epoch: 193 [169920/225000 (76%)] Loss: 18861.886719\n",
      "Train Epoch: 193 [172416/225000 (77%)] Loss: 19367.468750\n",
      "Train Epoch: 193 [174912/225000 (78%)] Loss: 19011.660156\n",
      "Train Epoch: 193 [177408/225000 (79%)] Loss: 18542.187500\n",
      "Train Epoch: 193 [179904/225000 (80%)] Loss: 18808.523438\n",
      "Train Epoch: 193 [182400/225000 (81%)] Loss: 19052.345703\n",
      "Train Epoch: 193 [184896/225000 (82%)] Loss: 19138.187500\n",
      "Train Epoch: 193 [187392/225000 (83%)] Loss: 18652.714844\n",
      "Train Epoch: 193 [189888/225000 (84%)] Loss: 19113.652344\n",
      "Train Epoch: 193 [192384/225000 (86%)] Loss: 18846.076172\n",
      "Train Epoch: 193 [194880/225000 (87%)] Loss: 19325.230469\n",
      "Train Epoch: 193 [197376/225000 (88%)] Loss: 19293.921875\n",
      "Train Epoch: 193 [199872/225000 (89%)] Loss: 18715.181641\n",
      "Train Epoch: 193 [202368/225000 (90%)] Loss: 18879.589844\n",
      "Train Epoch: 193 [204864/225000 (91%)] Loss: 18729.390625\n",
      "Train Epoch: 193 [207360/225000 (92%)] Loss: 18566.265625\n",
      "Train Epoch: 193 [209856/225000 (93%)] Loss: 18762.593750\n",
      "Train Epoch: 193 [212352/225000 (94%)] Loss: 18522.000000\n",
      "Train Epoch: 193 [214848/225000 (95%)] Loss: 19022.457031\n",
      "Train Epoch: 193 [217344/225000 (97%)] Loss: 18732.648438\n",
      "Train Epoch: 193 [219840/225000 (98%)] Loss: 18610.933594\n",
      "Train Epoch: 193 [222336/225000 (99%)] Loss: 19186.960938\n",
      "Train Epoch: 193 [224832/225000 (100%)] Loss: 18761.027344\n",
      "    epoch          : 193\n",
      "    loss           : 18955.410467883426\n",
      "    val_loss       : 18853.356620265782\n",
      "Train Epoch: 194 [192/225000 (0%)] Loss: 19040.164062\n",
      "Train Epoch: 194 [2688/225000 (1%)] Loss: 19283.105469\n",
      "Train Epoch: 194 [5184/225000 (2%)] Loss: 18874.730469\n",
      "Train Epoch: 194 [7680/225000 (3%)] Loss: 19613.125000\n",
      "Train Epoch: 194 [10176/225000 (5%)] Loss: 19464.812500\n",
      "Train Epoch: 194 [12672/225000 (6%)] Loss: 19312.898438\n",
      "Train Epoch: 194 [15168/225000 (7%)] Loss: 19091.644531\n",
      "Train Epoch: 194 [17664/225000 (8%)] Loss: 18961.914062\n",
      "Train Epoch: 194 [20160/225000 (9%)] Loss: 19210.218750\n",
      "Train Epoch: 194 [22656/225000 (10%)] Loss: 19581.890625\n",
      "Train Epoch: 194 [25152/225000 (11%)] Loss: 19190.109375\n",
      "Train Epoch: 194 [27648/225000 (12%)] Loss: 18869.882812\n",
      "Train Epoch: 194 [30144/225000 (13%)] Loss: 18979.019531\n",
      "Train Epoch: 194 [32640/225000 (15%)] Loss: 18794.988281\n",
      "Train Epoch: 194 [35136/225000 (16%)] Loss: 18724.197266\n",
      "Train Epoch: 194 [37632/225000 (17%)] Loss: 18737.257812\n",
      "Train Epoch: 194 [40128/225000 (18%)] Loss: 18830.503906\n",
      "Train Epoch: 194 [42624/225000 (19%)] Loss: 19222.300781\n",
      "Train Epoch: 194 [45120/225000 (20%)] Loss: 18886.140625\n",
      "Train Epoch: 194 [47616/225000 (21%)] Loss: 19600.154297\n",
      "Train Epoch: 194 [50112/225000 (22%)] Loss: 18853.128906\n",
      "Train Epoch: 194 [52608/225000 (23%)] Loss: 18948.619141\n",
      "Train Epoch: 194 [55104/225000 (24%)] Loss: 19269.734375\n",
      "Train Epoch: 194 [57600/225000 (26%)] Loss: 19379.841797\n",
      "Train Epoch: 194 [60096/225000 (27%)] Loss: 18897.822266\n",
      "Train Epoch: 194 [62592/225000 (28%)] Loss: 18807.917969\n",
      "Train Epoch: 194 [65088/225000 (29%)] Loss: 19276.349609\n",
      "Train Epoch: 194 [67584/225000 (30%)] Loss: 18751.070312\n",
      "Train Epoch: 194 [70080/225000 (31%)] Loss: 18507.224609\n",
      "Train Epoch: 194 [72576/225000 (32%)] Loss: 18650.980469\n",
      "Train Epoch: 194 [75072/225000 (33%)] Loss: 18458.037109\n",
      "Train Epoch: 194 [77568/225000 (34%)] Loss: 19186.484375\n",
      "Train Epoch: 194 [80064/225000 (36%)] Loss: 18756.781250\n",
      "Train Epoch: 194 [82560/225000 (37%)] Loss: 18878.273438\n",
      "Train Epoch: 194 [85056/225000 (38%)] Loss: 18460.703125\n",
      "Train Epoch: 194 [87552/225000 (39%)] Loss: 19148.398438\n",
      "Train Epoch: 194 [90048/225000 (40%)] Loss: 19310.132812\n",
      "Train Epoch: 194 [92544/225000 (41%)] Loss: 19287.109375\n",
      "Train Epoch: 194 [95040/225000 (42%)] Loss: 19359.976562\n",
      "Train Epoch: 194 [97536/225000 (43%)] Loss: 18870.451172\n",
      "Train Epoch: 194 [100032/225000 (44%)] Loss: 18478.785156\n",
      "Train Epoch: 194 [102528/225000 (46%)] Loss: 19277.402344\n",
      "Train Epoch: 194 [105024/225000 (47%)] Loss: 19355.804688\n",
      "Train Epoch: 194 [107520/225000 (48%)] Loss: 18624.732422\n",
      "Train Epoch: 194 [110016/225000 (49%)] Loss: 18737.794922\n",
      "Train Epoch: 194 [112512/225000 (50%)] Loss: 19014.123047\n",
      "Train Epoch: 194 [115008/225000 (51%)] Loss: 18817.599609\n",
      "Train Epoch: 194 [117504/225000 (52%)] Loss: 18813.066406\n",
      "Train Epoch: 194 [120000/225000 (53%)] Loss: 18791.208984\n",
      "Train Epoch: 194 [122496/225000 (54%)] Loss: 18744.486328\n",
      "Train Epoch: 194 [124992/225000 (56%)] Loss: 18999.648438\n",
      "Train Epoch: 194 [127488/225000 (57%)] Loss: 19143.054688\n",
      "Train Epoch: 194 [129984/225000 (58%)] Loss: 18833.576172\n",
      "Train Epoch: 194 [132480/225000 (59%)] Loss: 18878.070312\n",
      "Train Epoch: 194 [134976/225000 (60%)] Loss: 18866.228516\n",
      "Train Epoch: 194 [137472/225000 (61%)] Loss: 18923.433594\n",
      "Train Epoch: 194 [139968/225000 (62%)] Loss: 18466.228516\n",
      "Train Epoch: 194 [142464/225000 (63%)] Loss: 18926.292969\n",
      "Train Epoch: 194 [144960/225000 (64%)] Loss: 18787.207031\n",
      "Train Epoch: 194 [147456/225000 (66%)] Loss: 19334.605469\n",
      "Train Epoch: 194 [149952/225000 (67%)] Loss: 18673.660156\n",
      "Train Epoch: 194 [152448/225000 (68%)] Loss: 19139.630859\n",
      "Train Epoch: 194 [154944/225000 (69%)] Loss: 19268.503906\n",
      "Train Epoch: 194 [157440/225000 (70%)] Loss: 18512.650391\n",
      "Train Epoch: 194 [159936/225000 (71%)] Loss: 18578.177734\n",
      "Train Epoch: 194 [162432/225000 (72%)] Loss: 18943.976562\n",
      "Train Epoch: 194 [164928/225000 (73%)] Loss: 19073.015625\n",
      "Train Epoch: 194 [167424/225000 (74%)] Loss: 18876.515625\n",
      "Train Epoch: 194 [169920/225000 (76%)] Loss: 18667.080078\n",
      "Train Epoch: 194 [172416/225000 (77%)] Loss: 18557.146484\n",
      "Train Epoch: 194 [174912/225000 (78%)] Loss: 18639.578125\n",
      "Train Epoch: 194 [177408/225000 (79%)] Loss: 18963.949219\n",
      "Train Epoch: 194 [179904/225000 (80%)] Loss: 18739.060547\n",
      "Train Epoch: 194 [182400/225000 (81%)] Loss: 19066.482422\n",
      "Train Epoch: 194 [184896/225000 (82%)] Loss: 19313.593750\n",
      "Train Epoch: 194 [187392/225000 (83%)] Loss: 19086.597656\n",
      "Train Epoch: 194 [189888/225000 (84%)] Loss: 18920.980469\n",
      "Train Epoch: 194 [192384/225000 (86%)] Loss: 18417.185547\n",
      "Train Epoch: 194 [194880/225000 (87%)] Loss: 18568.220703\n",
      "Train Epoch: 194 [197376/225000 (88%)] Loss: 18816.617188\n",
      "Train Epoch: 194 [199872/225000 (89%)] Loss: 18848.023438\n",
      "Train Epoch: 194 [202368/225000 (90%)] Loss: 18802.355469\n",
      "Train Epoch: 194 [204864/225000 (91%)] Loss: 18787.656250\n",
      "Train Epoch: 194 [207360/225000 (92%)] Loss: 18673.939453\n",
      "Train Epoch: 194 [209856/225000 (93%)] Loss: 18596.250000\n",
      "Train Epoch: 194 [212352/225000 (94%)] Loss: 19429.947266\n",
      "Train Epoch: 194 [214848/225000 (95%)] Loss: 19210.675781\n",
      "Train Epoch: 194 [217344/225000 (97%)] Loss: 18452.806641\n",
      "Train Epoch: 194 [219840/225000 (98%)] Loss: 19364.500000\n",
      "Train Epoch: 194 [222336/225000 (99%)] Loss: 19398.292969\n",
      "Train Epoch: 194 [224832/225000 (100%)] Loss: 18948.957031\n",
      "    epoch          : 194\n",
      "    loss           : 18931.12839880413\n",
      "    val_loss       : 18824.736107149198\n",
      "Train Epoch: 195 [192/225000 (0%)] Loss: 19097.785156\n",
      "Train Epoch: 195 [2688/225000 (1%)] Loss: 18532.375000\n",
      "Train Epoch: 195 [5184/225000 (2%)] Loss: 18791.046875\n",
      "Train Epoch: 195 [7680/225000 (3%)] Loss: 18902.050781\n",
      "Train Epoch: 195 [10176/225000 (5%)] Loss: 18678.767578\n",
      "Train Epoch: 195 [12672/225000 (6%)] Loss: 19023.601562\n",
      "Train Epoch: 195 [15168/225000 (7%)] Loss: 19038.222656\n",
      "Train Epoch: 195 [17664/225000 (8%)] Loss: 18786.017578\n",
      "Train Epoch: 195 [20160/225000 (9%)] Loss: 18659.529297\n",
      "Train Epoch: 195 [22656/225000 (10%)] Loss: 18909.042969\n",
      "Train Epoch: 195 [25152/225000 (11%)] Loss: 19063.769531\n",
      "Train Epoch: 195 [27648/225000 (12%)] Loss: 18885.750000\n",
      "Train Epoch: 195 [30144/225000 (13%)] Loss: 18847.835938\n",
      "Train Epoch: 195 [32640/225000 (15%)] Loss: 19082.273438\n",
      "Train Epoch: 195 [35136/225000 (16%)] Loss: 19144.039062\n",
      "Train Epoch: 195 [37632/225000 (17%)] Loss: 18765.742188\n",
      "Train Epoch: 195 [40128/225000 (18%)] Loss: 19302.949219\n",
      "Train Epoch: 195 [42624/225000 (19%)] Loss: 18958.535156\n",
      "Train Epoch: 195 [45120/225000 (20%)] Loss: 19302.917969\n",
      "Train Epoch: 195 [47616/225000 (21%)] Loss: 18926.460938\n",
      "Train Epoch: 195 [50112/225000 (22%)] Loss: 18555.667969\n",
      "Train Epoch: 195 [52608/225000 (23%)] Loss: 19272.980469\n",
      "Train Epoch: 195 [55104/225000 (24%)] Loss: 18785.009766\n",
      "Train Epoch: 195 [57600/225000 (26%)] Loss: 18689.703125\n",
      "Train Epoch: 195 [60096/225000 (27%)] Loss: 18943.882812\n",
      "Train Epoch: 195 [62592/225000 (28%)] Loss: 19131.011719\n",
      "Train Epoch: 195 [65088/225000 (29%)] Loss: 19079.314453\n",
      "Train Epoch: 195 [67584/225000 (30%)] Loss: 18425.708984\n",
      "Train Epoch: 195 [70080/225000 (31%)] Loss: 18987.457031\n",
      "Train Epoch: 195 [72576/225000 (32%)] Loss: 18612.974609\n",
      "Train Epoch: 195 [75072/225000 (33%)] Loss: 19038.382812\n",
      "Train Epoch: 195 [77568/225000 (34%)] Loss: 18790.039062\n",
      "Train Epoch: 195 [80064/225000 (36%)] Loss: 18821.279297\n",
      "Train Epoch: 195 [82560/225000 (37%)] Loss: 18928.007812\n",
      "Train Epoch: 195 [85056/225000 (38%)] Loss: 18994.574219\n",
      "Train Epoch: 195 [87552/225000 (39%)] Loss: 18563.306641\n",
      "Train Epoch: 195 [90048/225000 (40%)] Loss: 19241.306641\n",
      "Train Epoch: 195 [92544/225000 (41%)] Loss: 18952.386719\n",
      "Train Epoch: 195 [95040/225000 (42%)] Loss: 19040.726562\n",
      "Train Epoch: 195 [97536/225000 (43%)] Loss: 19247.822266\n",
      "Train Epoch: 195 [100032/225000 (44%)] Loss: 19004.335938\n",
      "Train Epoch: 195 [102528/225000 (46%)] Loss: 18907.296875\n",
      "Train Epoch: 195 [105024/225000 (47%)] Loss: 18887.585938\n",
      "Train Epoch: 195 [107520/225000 (48%)] Loss: 18646.185547\n",
      "Train Epoch: 195 [110016/225000 (49%)] Loss: 18932.652344\n",
      "Train Epoch: 195 [112512/225000 (50%)] Loss: 18688.460938\n",
      "Train Epoch: 195 [115008/225000 (51%)] Loss: 19225.458984\n",
      "Train Epoch: 195 [117504/225000 (52%)] Loss: 19583.570312\n",
      "Train Epoch: 195 [120000/225000 (53%)] Loss: 18888.019531\n",
      "Train Epoch: 195 [122496/225000 (54%)] Loss: 23800.902344\n",
      "Train Epoch: 195 [124992/225000 (56%)] Loss: 18723.824219\n",
      "Train Epoch: 195 [127488/225000 (57%)] Loss: 18916.957031\n",
      "Train Epoch: 195 [129984/225000 (58%)] Loss: 18881.175781\n",
      "Train Epoch: 195 [132480/225000 (59%)] Loss: 19259.132812\n",
      "Train Epoch: 195 [134976/225000 (60%)] Loss: 18558.080078\n",
      "Train Epoch: 195 [137472/225000 (61%)] Loss: 18963.447266\n",
      "Train Epoch: 195 [139968/225000 (62%)] Loss: 18805.476562\n",
      "Train Epoch: 195 [142464/225000 (63%)] Loss: 18965.058594\n",
      "Train Epoch: 195 [144960/225000 (64%)] Loss: 18742.244141\n",
      "Train Epoch: 195 [147456/225000 (66%)] Loss: 18894.402344\n",
      "Train Epoch: 195 [149952/225000 (67%)] Loss: 18933.894531\n",
      "Train Epoch: 195 [152448/225000 (68%)] Loss: 18829.355469\n",
      "Train Epoch: 195 [154944/225000 (69%)] Loss: 19165.050781\n",
      "Train Epoch: 195 [157440/225000 (70%)] Loss: 18905.328125\n",
      "Train Epoch: 195 [159936/225000 (71%)] Loss: 18714.773438\n",
      "Train Epoch: 195 [162432/225000 (72%)] Loss: 18827.562500\n",
      "Train Epoch: 195 [164928/225000 (73%)] Loss: 18980.582031\n",
      "Train Epoch: 195 [167424/225000 (74%)] Loss: 18554.281250\n",
      "Train Epoch: 195 [169920/225000 (76%)] Loss: 18811.910156\n",
      "Train Epoch: 195 [172416/225000 (77%)] Loss: 19034.824219\n",
      "Train Epoch: 195 [174912/225000 (78%)] Loss: 19347.246094\n",
      "Train Epoch: 195 [177408/225000 (79%)] Loss: 18882.318359\n",
      "Train Epoch: 195 [179904/225000 (80%)] Loss: 18783.750000\n",
      "Train Epoch: 195 [182400/225000 (81%)] Loss: 19429.498047\n",
      "Train Epoch: 195 [184896/225000 (82%)] Loss: 18685.060547\n",
      "Train Epoch: 195 [187392/225000 (83%)] Loss: 19160.445312\n",
      "Train Epoch: 195 [189888/225000 (84%)] Loss: 18980.205078\n",
      "Train Epoch: 195 [192384/225000 (86%)] Loss: 18811.175781\n",
      "Train Epoch: 195 [194880/225000 (87%)] Loss: 18907.617188\n",
      "Train Epoch: 195 [197376/225000 (88%)] Loss: 19094.111328\n",
      "Train Epoch: 195 [199872/225000 (89%)] Loss: 18667.888672\n",
      "Train Epoch: 195 [202368/225000 (90%)] Loss: 18815.429688\n",
      "Train Epoch: 195 [204864/225000 (91%)] Loss: 18961.896484\n",
      "Train Epoch: 195 [207360/225000 (92%)] Loss: 19151.062500\n",
      "Train Epoch: 195 [209856/225000 (93%)] Loss: 18744.919922\n",
      "Train Epoch: 195 [212352/225000 (94%)] Loss: 19129.839844\n",
      "Train Epoch: 195 [214848/225000 (95%)] Loss: 18758.650391\n",
      "Train Epoch: 195 [217344/225000 (97%)] Loss: 18759.679688\n",
      "Train Epoch: 195 [219840/225000 (98%)] Loss: 19107.757812\n",
      "Train Epoch: 195 [222336/225000 (99%)] Loss: 19002.070312\n",
      "Train Epoch: 195 [224832/225000 (100%)] Loss: 18774.666016\n",
      "    epoch          : 195\n",
      "    loss           : 18909.50629932807\n",
      "    val_loss       : 18765.379745578946\n",
      "Train Epoch: 196 [192/225000 (0%)] Loss: 19110.123047\n",
      "Train Epoch: 196 [2688/225000 (1%)] Loss: 18763.435547\n",
      "Train Epoch: 196 [5184/225000 (2%)] Loss: 19080.914062\n",
      "Train Epoch: 196 [7680/225000 (3%)] Loss: 19018.531250\n",
      "Train Epoch: 196 [10176/225000 (5%)] Loss: 19021.976562\n",
      "Train Epoch: 196 [12672/225000 (6%)] Loss: 18587.609375\n",
      "Train Epoch: 196 [15168/225000 (7%)] Loss: 18407.675781\n",
      "Train Epoch: 196 [17664/225000 (8%)] Loss: 18805.220703\n",
      "Train Epoch: 196 [20160/225000 (9%)] Loss: 18593.496094\n",
      "Train Epoch: 196 [22656/225000 (10%)] Loss: 18988.812500\n",
      "Train Epoch: 196 [25152/225000 (11%)] Loss: 19196.345703\n",
      "Train Epoch: 196 [27648/225000 (12%)] Loss: 18862.250000\n",
      "Train Epoch: 196 [30144/225000 (13%)] Loss: 18345.984375\n",
      "Train Epoch: 196 [32640/225000 (15%)] Loss: 18841.968750\n",
      "Train Epoch: 196 [35136/225000 (16%)] Loss: 18699.982422\n",
      "Train Epoch: 196 [37632/225000 (17%)] Loss: 18703.464844\n",
      "Train Epoch: 196 [40128/225000 (18%)] Loss: 18789.808594\n",
      "Train Epoch: 196 [42624/225000 (19%)] Loss: 19309.691406\n",
      "Train Epoch: 196 [45120/225000 (20%)] Loss: 18845.691406\n",
      "Train Epoch: 196 [47616/225000 (21%)] Loss: 18986.525391\n",
      "Train Epoch: 196 [50112/225000 (22%)] Loss: 18428.974609\n",
      "Train Epoch: 196 [52608/225000 (23%)] Loss: 18929.269531\n",
      "Train Epoch: 196 [55104/225000 (24%)] Loss: 19081.335938\n",
      "Train Epoch: 196 [57600/225000 (26%)] Loss: 18960.527344\n",
      "Train Epoch: 196 [60096/225000 (27%)] Loss: 18748.097656\n",
      "Train Epoch: 196 [62592/225000 (28%)] Loss: 18744.228516\n",
      "Train Epoch: 196 [65088/225000 (29%)] Loss: 19006.132812\n",
      "Train Epoch: 196 [67584/225000 (30%)] Loss: 18688.722656\n",
      "Train Epoch: 196 [70080/225000 (31%)] Loss: 18194.675781\n",
      "Train Epoch: 196 [72576/225000 (32%)] Loss: 19246.687500\n",
      "Train Epoch: 196 [75072/225000 (33%)] Loss: 18911.398438\n",
      "Train Epoch: 196 [77568/225000 (34%)] Loss: 18860.636719\n",
      "Train Epoch: 196 [80064/225000 (36%)] Loss: 19079.513672\n",
      "Train Epoch: 196 [82560/225000 (37%)] Loss: 18731.804688\n",
      "Train Epoch: 196 [85056/225000 (38%)] Loss: 18911.667969\n",
      "Train Epoch: 196 [87552/225000 (39%)] Loss: 18781.253906\n",
      "Train Epoch: 196 [90048/225000 (40%)] Loss: 19061.531250\n",
      "Train Epoch: 196 [92544/225000 (41%)] Loss: 18858.931641\n",
      "Train Epoch: 196 [95040/225000 (42%)] Loss: 18897.798828\n",
      "Train Epoch: 196 [97536/225000 (43%)] Loss: 18794.287109\n",
      "Train Epoch: 196 [100032/225000 (44%)] Loss: 19015.710938\n",
      "Train Epoch: 196 [102528/225000 (46%)] Loss: 19187.257812\n",
      "Train Epoch: 196 [105024/225000 (47%)] Loss: 18931.455078\n",
      "Train Epoch: 196 [107520/225000 (48%)] Loss: 18944.480469\n",
      "Train Epoch: 196 [110016/225000 (49%)] Loss: 18554.601562\n",
      "Train Epoch: 196 [112512/225000 (50%)] Loss: 18743.679688\n",
      "Train Epoch: 196 [115008/225000 (51%)] Loss: 18811.070312\n",
      "Train Epoch: 196 [117504/225000 (52%)] Loss: 18945.712891\n",
      "Train Epoch: 196 [120000/225000 (53%)] Loss: 18793.031250\n",
      "Train Epoch: 196 [122496/225000 (54%)] Loss: 18972.125000\n",
      "Train Epoch: 196 [124992/225000 (56%)] Loss: 18722.160156\n",
      "Train Epoch: 196 [127488/225000 (57%)] Loss: 18607.054688\n",
      "Train Epoch: 196 [129984/225000 (58%)] Loss: 19177.353516\n",
      "Train Epoch: 196 [132480/225000 (59%)] Loss: 18649.875000\n",
      "Train Epoch: 196 [134976/225000 (60%)] Loss: 18776.228516\n",
      "Train Epoch: 196 [137472/225000 (61%)] Loss: 19034.208984\n",
      "Train Epoch: 196 [139968/225000 (62%)] Loss: 18963.277344\n",
      "Train Epoch: 196 [142464/225000 (63%)] Loss: 19099.062500\n",
      "Train Epoch: 196 [144960/225000 (64%)] Loss: 19117.402344\n",
      "Train Epoch: 196 [147456/225000 (66%)] Loss: 19099.119141\n",
      "Train Epoch: 196 [149952/225000 (67%)] Loss: 18826.207031\n",
      "Train Epoch: 196 [152448/225000 (68%)] Loss: 18653.187500\n",
      "Train Epoch: 196 [154944/225000 (69%)] Loss: 18739.681641\n",
      "Train Epoch: 196 [157440/225000 (70%)] Loss: 18635.160156\n",
      "Train Epoch: 196 [159936/225000 (71%)] Loss: 19258.445312\n",
      "Train Epoch: 196 [162432/225000 (72%)] Loss: 19337.193359\n",
      "Train Epoch: 196 [164928/225000 (73%)] Loss: 18925.121094\n",
      "Train Epoch: 196 [167424/225000 (74%)] Loss: 18844.693359\n",
      "Train Epoch: 196 [169920/225000 (76%)] Loss: 18719.343750\n",
      "Train Epoch: 196 [172416/225000 (77%)] Loss: 18968.482422\n",
      "Train Epoch: 196 [174912/225000 (78%)] Loss: 19054.447266\n",
      "Train Epoch: 196 [177408/225000 (79%)] Loss: 18941.144531\n",
      "Train Epoch: 196 [179904/225000 (80%)] Loss: 19393.035156\n",
      "Train Epoch: 196 [182400/225000 (81%)] Loss: 18934.484375\n",
      "Train Epoch: 196 [184896/225000 (82%)] Loss: 19044.976562\n",
      "Train Epoch: 196 [187392/225000 (83%)] Loss: 18700.453125\n",
      "Train Epoch: 196 [189888/225000 (84%)] Loss: 18613.083984\n",
      "Train Epoch: 196 [192384/225000 (86%)] Loss: 18953.607422\n",
      "Train Epoch: 196 [194880/225000 (87%)] Loss: 18426.175781\n",
      "Train Epoch: 196 [197376/225000 (88%)] Loss: 18884.886719\n",
      "Train Epoch: 196 [199872/225000 (89%)] Loss: 18407.388672\n",
      "Train Epoch: 196 [202368/225000 (90%)] Loss: 18836.353516\n",
      "Train Epoch: 196 [204864/225000 (91%)] Loss: 18731.683594\n",
      "Train Epoch: 196 [207360/225000 (92%)] Loss: 18656.695312\n",
      "Train Epoch: 196 [209856/225000 (93%)] Loss: 18536.160156\n",
      "Train Epoch: 196 [212352/225000 (94%)] Loss: 18543.326172\n",
      "Train Epoch: 196 [214848/225000 (95%)] Loss: 18585.583984\n",
      "Train Epoch: 196 [217344/225000 (97%)] Loss: 18963.882812\n",
      "Train Epoch: 196 [219840/225000 (98%)] Loss: 19114.998047\n",
      "Train Epoch: 196 [222336/225000 (99%)] Loss: 18584.732422\n",
      "Train Epoch: 196 [224832/225000 (100%)] Loss: 19005.808594\n",
      "    epoch          : 196\n",
      "    loss           : 18838.157278223654\n",
      "    val_loss       : 18727.672809184052\n",
      "Train Epoch: 197 [192/225000 (0%)] Loss: 18840.492188\n",
      "Train Epoch: 197 [2688/225000 (1%)] Loss: 18589.316406\n",
      "Train Epoch: 197 [5184/225000 (2%)] Loss: 19047.882812\n",
      "Train Epoch: 197 [7680/225000 (3%)] Loss: 19095.570312\n",
      "Train Epoch: 197 [10176/225000 (5%)] Loss: 19114.382812\n",
      "Train Epoch: 197 [12672/225000 (6%)] Loss: 19011.822266\n",
      "Train Epoch: 197 [15168/225000 (7%)] Loss: 18843.164062\n",
      "Train Epoch: 197 [17664/225000 (8%)] Loss: 18709.058594\n",
      "Train Epoch: 197 [20160/225000 (9%)] Loss: 18496.269531\n",
      "Train Epoch: 197 [22656/225000 (10%)] Loss: 18883.921875\n",
      "Train Epoch: 197 [25152/225000 (11%)] Loss: 18569.457031\n",
      "Train Epoch: 197 [27648/225000 (12%)] Loss: 18807.945312\n",
      "Train Epoch: 197 [30144/225000 (13%)] Loss: 18711.964844\n",
      "Train Epoch: 197 [32640/225000 (15%)] Loss: 19148.228516\n",
      "Train Epoch: 197 [35136/225000 (16%)] Loss: 18556.179688\n",
      "Train Epoch: 197 [37632/225000 (17%)] Loss: 18617.931641\n",
      "Train Epoch: 197 [40128/225000 (18%)] Loss: 18585.367188\n",
      "Train Epoch: 197 [42624/225000 (19%)] Loss: 18626.730469\n",
      "Train Epoch: 197 [45120/225000 (20%)] Loss: 19396.537109\n",
      "Train Epoch: 197 [47616/225000 (21%)] Loss: 18912.320312\n",
      "Train Epoch: 197 [50112/225000 (22%)] Loss: 18773.507812\n",
      "Train Epoch: 197 [52608/225000 (23%)] Loss: 18385.789062\n",
      "Train Epoch: 197 [55104/225000 (24%)] Loss: 18748.296875\n",
      "Train Epoch: 197 [57600/225000 (26%)] Loss: 19124.796875\n",
      "Train Epoch: 197 [60096/225000 (27%)] Loss: 18855.919922\n",
      "Train Epoch: 197 [62592/225000 (28%)] Loss: 18600.445312\n",
      "Train Epoch: 197 [65088/225000 (29%)] Loss: 19225.033203\n",
      "Train Epoch: 197 [67584/225000 (30%)] Loss: 18962.988281\n",
      "Train Epoch: 197 [70080/225000 (31%)] Loss: 18401.300781\n",
      "Train Epoch: 197 [72576/225000 (32%)] Loss: 18938.210938\n",
      "Train Epoch: 197 [75072/225000 (33%)] Loss: 18781.632812\n",
      "Train Epoch: 197 [77568/225000 (34%)] Loss: 18779.630859\n",
      "Train Epoch: 197 [80064/225000 (36%)] Loss: 19067.101562\n",
      "Train Epoch: 197 [82560/225000 (37%)] Loss: 18435.632812\n",
      "Train Epoch: 197 [85056/225000 (38%)] Loss: 19220.203125\n",
      "Train Epoch: 197 [87552/225000 (39%)] Loss: 18371.400391\n",
      "Train Epoch: 197 [90048/225000 (40%)] Loss: 18728.914062\n",
      "Train Epoch: 197 [92544/225000 (41%)] Loss: 19124.937500\n",
      "Train Epoch: 197 [95040/225000 (42%)] Loss: 18705.550781\n",
      "Train Epoch: 197 [97536/225000 (43%)] Loss: 19149.347656\n",
      "Train Epoch: 197 [100032/225000 (44%)] Loss: 18999.716797\n",
      "Train Epoch: 197 [102528/225000 (46%)] Loss: 19044.871094\n",
      "Train Epoch: 197 [105024/225000 (47%)] Loss: 18939.470703\n",
      "Train Epoch: 197 [107520/225000 (48%)] Loss: 18982.500000\n",
      "Train Epoch: 197 [110016/225000 (49%)] Loss: 18413.800781\n",
      "Train Epoch: 197 [112512/225000 (50%)] Loss: 18566.878906\n",
      "Train Epoch: 197 [115008/225000 (51%)] Loss: 18488.269531\n",
      "Train Epoch: 197 [117504/225000 (52%)] Loss: 19128.949219\n",
      "Train Epoch: 197 [120000/225000 (53%)] Loss: 18901.769531\n",
      "Train Epoch: 197 [122496/225000 (54%)] Loss: 18874.773438\n",
      "Train Epoch: 197 [124992/225000 (56%)] Loss: 18526.880859\n",
      "Train Epoch: 197 [127488/225000 (57%)] Loss: 18395.785156\n",
      "Train Epoch: 197 [129984/225000 (58%)] Loss: 18717.246094\n",
      "Train Epoch: 197 [132480/225000 (59%)] Loss: 18720.500000\n",
      "Train Epoch: 197 [134976/225000 (60%)] Loss: 18476.664062\n",
      "Train Epoch: 197 [137472/225000 (61%)] Loss: 18478.384766\n",
      "Train Epoch: 197 [139968/225000 (62%)] Loss: 18672.062500\n",
      "Train Epoch: 197 [142464/225000 (63%)] Loss: 18843.384766\n",
      "Train Epoch: 197 [144960/225000 (64%)] Loss: 17882.882812\n",
      "Train Epoch: 197 [147456/225000 (66%)] Loss: 19056.035156\n",
      "Train Epoch: 197 [149952/225000 (67%)] Loss: 18593.244141\n",
      "Train Epoch: 197 [152448/225000 (68%)] Loss: 18640.505859\n",
      "Train Epoch: 197 [154944/225000 (69%)] Loss: 19362.298828\n",
      "Train Epoch: 197 [157440/225000 (70%)] Loss: 18568.548828\n",
      "Train Epoch: 197 [159936/225000 (71%)] Loss: 18672.070312\n",
      "Train Epoch: 197 [162432/225000 (72%)] Loss: 18299.816406\n",
      "Train Epoch: 197 [164928/225000 (73%)] Loss: 18984.160156\n",
      "Train Epoch: 197 [167424/225000 (74%)] Loss: 18244.476562\n",
      "Train Epoch: 197 [169920/225000 (76%)] Loss: 18713.267578\n",
      "Train Epoch: 197 [172416/225000 (77%)] Loss: 18770.863281\n",
      "Train Epoch: 197 [174912/225000 (78%)] Loss: 18800.789062\n",
      "Train Epoch: 197 [177408/225000 (79%)] Loss: 18618.685547\n",
      "Train Epoch: 197 [179904/225000 (80%)] Loss: 18594.328125\n",
      "Train Epoch: 197 [182400/225000 (81%)] Loss: 19394.320312\n",
      "Train Epoch: 197 [184896/225000 (82%)] Loss: 18596.621094\n",
      "Train Epoch: 197 [187392/225000 (83%)] Loss: 18829.248047\n",
      "Train Epoch: 197 [189888/225000 (84%)] Loss: 18649.839844\n",
      "Train Epoch: 197 [192384/225000 (86%)] Loss: 18869.378906\n",
      "Train Epoch: 197 [194880/225000 (87%)] Loss: 19014.281250\n",
      "Train Epoch: 197 [197376/225000 (88%)] Loss: 18985.195312\n",
      "Train Epoch: 197 [199872/225000 (89%)] Loss: 19338.902344\n",
      "Train Epoch: 197 [202368/225000 (90%)] Loss: 18802.744141\n",
      "Train Epoch: 197 [204864/225000 (91%)] Loss: 18470.949219\n",
      "Train Epoch: 197 [207360/225000 (92%)] Loss: 18669.712891\n",
      "Train Epoch: 197 [209856/225000 (93%)] Loss: 18547.859375\n",
      "Train Epoch: 197 [212352/225000 (94%)] Loss: 19060.554688\n",
      "Train Epoch: 197 [214848/225000 (95%)] Loss: 18867.085938\n",
      "Train Epoch: 197 [217344/225000 (97%)] Loss: 18795.433594\n",
      "Train Epoch: 197 [219840/225000 (98%)] Loss: 18478.394531\n",
      "Train Epoch: 197 [222336/225000 (99%)] Loss: 18949.808594\n",
      "Train Epoch: 197 [224832/225000 (100%)] Loss: 18493.193359\n",
      "    epoch          : 197\n",
      "    loss           : 18796.585027597055\n",
      "    val_loss       : 18664.679550626806\n",
      "Train Epoch: 198 [192/225000 (0%)] Loss: 18869.417969\n",
      "Train Epoch: 198 [2688/225000 (1%)] Loss: 18898.789062\n",
      "Train Epoch: 198 [5184/225000 (2%)] Loss: 18481.816406\n",
      "Train Epoch: 198 [7680/225000 (3%)] Loss: 18591.667969\n",
      "Train Epoch: 198 [10176/225000 (5%)] Loss: 18770.955078\n",
      "Train Epoch: 198 [12672/225000 (6%)] Loss: 18765.445312\n",
      "Train Epoch: 198 [15168/225000 (7%)] Loss: 18892.691406\n",
      "Train Epoch: 198 [17664/225000 (8%)] Loss: 18763.921875\n",
      "Train Epoch: 198 [20160/225000 (9%)] Loss: 18944.417969\n",
      "Train Epoch: 198 [22656/225000 (10%)] Loss: 18510.054688\n",
      "Train Epoch: 198 [25152/225000 (11%)] Loss: 18789.292969\n",
      "Train Epoch: 198 [27648/225000 (12%)] Loss: 18675.941406\n",
      "Train Epoch: 198 [30144/225000 (13%)] Loss: 18911.351562\n",
      "Train Epoch: 198 [32640/225000 (15%)] Loss: 19558.154297\n",
      "Train Epoch: 198 [35136/225000 (16%)] Loss: 18547.488281\n",
      "Train Epoch: 198 [37632/225000 (17%)] Loss: 18478.208984\n",
      "Train Epoch: 198 [40128/225000 (18%)] Loss: 23634.414062\n",
      "Train Epoch: 198 [42624/225000 (19%)] Loss: 18984.140625\n",
      "Train Epoch: 198 [45120/225000 (20%)] Loss: 18384.921875\n",
      "Train Epoch: 198 [47616/225000 (21%)] Loss: 18639.765625\n",
      "Train Epoch: 198 [50112/225000 (22%)] Loss: 18619.658203\n",
      "Train Epoch: 198 [52608/225000 (23%)] Loss: 18808.230469\n",
      "Train Epoch: 198 [55104/225000 (24%)] Loss: 18669.148438\n",
      "Train Epoch: 198 [57600/225000 (26%)] Loss: 19371.312500\n",
      "Train Epoch: 198 [60096/225000 (27%)] Loss: 18705.800781\n",
      "Train Epoch: 198 [62592/225000 (28%)] Loss: 18828.714844\n",
      "Train Epoch: 198 [65088/225000 (29%)] Loss: 18287.445312\n",
      "Train Epoch: 198 [67584/225000 (30%)] Loss: 19182.306641\n",
      "Train Epoch: 198 [70080/225000 (31%)] Loss: 18528.894531\n",
      "Train Epoch: 198 [72576/225000 (32%)] Loss: 19121.871094\n",
      "Train Epoch: 198 [75072/225000 (33%)] Loss: 19386.332031\n",
      "Train Epoch: 198 [77568/225000 (34%)] Loss: 18473.548828\n",
      "Train Epoch: 198 [80064/225000 (36%)] Loss: 19122.402344\n",
      "Train Epoch: 198 [82560/225000 (37%)] Loss: 19005.316406\n",
      "Train Epoch: 198 [85056/225000 (38%)] Loss: 18511.648438\n",
      "Train Epoch: 198 [87552/225000 (39%)] Loss: 18107.839844\n",
      "Train Epoch: 198 [90048/225000 (40%)] Loss: 18832.302734\n",
      "Train Epoch: 198 [92544/225000 (41%)] Loss: 18921.542969\n",
      "Train Epoch: 198 [95040/225000 (42%)] Loss: 19154.683594\n",
      "Train Epoch: 198 [97536/225000 (43%)] Loss: 18359.802734\n",
      "Train Epoch: 198 [100032/225000 (44%)] Loss: 18382.097656\n",
      "Train Epoch: 198 [102528/225000 (46%)] Loss: 18977.609375\n",
      "Train Epoch: 198 [105024/225000 (47%)] Loss: 18629.224609\n",
      "Train Epoch: 198 [107520/225000 (48%)] Loss: 18833.722656\n",
      "Train Epoch: 198 [110016/225000 (49%)] Loss: 18647.664062\n",
      "Train Epoch: 198 [112512/225000 (50%)] Loss: 18690.160156\n",
      "Train Epoch: 198 [115008/225000 (51%)] Loss: 18700.197266\n",
      "Train Epoch: 198 [117504/225000 (52%)] Loss: 19214.671875\n",
      "Train Epoch: 198 [120000/225000 (53%)] Loss: 18364.433594\n",
      "Train Epoch: 198 [122496/225000 (54%)] Loss: 18842.867188\n",
      "Train Epoch: 198 [124992/225000 (56%)] Loss: 18775.585938\n",
      "Train Epoch: 198 [127488/225000 (57%)] Loss: 18801.691406\n",
      "Train Epoch: 198 [129984/225000 (58%)] Loss: 19050.878906\n",
      "Train Epoch: 198 [132480/225000 (59%)] Loss: 18863.111328\n",
      "Train Epoch: 198 [134976/225000 (60%)] Loss: 18372.878906\n",
      "Train Epoch: 198 [137472/225000 (61%)] Loss: 18747.957031\n",
      "Train Epoch: 198 [139968/225000 (62%)] Loss: 18573.300781\n",
      "Train Epoch: 198 [142464/225000 (63%)] Loss: 18944.583984\n",
      "Train Epoch: 198 [144960/225000 (64%)] Loss: 18754.671875\n",
      "Train Epoch: 198 [147456/225000 (66%)] Loss: 18543.685547\n",
      "Train Epoch: 198 [149952/225000 (67%)] Loss: 19059.933594\n",
      "Train Epoch: 198 [152448/225000 (68%)] Loss: 18768.437500\n",
      "Train Epoch: 198 [154944/225000 (69%)] Loss: 18619.134766\n",
      "Train Epoch: 198 [157440/225000 (70%)] Loss: 18511.273438\n",
      "Train Epoch: 198 [159936/225000 (71%)] Loss: 18589.378906\n",
      "Train Epoch: 198 [162432/225000 (72%)] Loss: 18892.500000\n",
      "Train Epoch: 198 [164928/225000 (73%)] Loss: 18609.019531\n",
      "Train Epoch: 198 [167424/225000 (74%)] Loss: 18490.507812\n",
      "Train Epoch: 198 [169920/225000 (76%)] Loss: 18612.175781\n",
      "Train Epoch: 198 [172416/225000 (77%)] Loss: 18741.425781\n",
      "Train Epoch: 198 [174912/225000 (78%)] Loss: 18583.175781\n",
      "Train Epoch: 198 [177408/225000 (79%)] Loss: 19001.214844\n",
      "Train Epoch: 198 [179904/225000 (80%)] Loss: 18379.632812\n",
      "Train Epoch: 198 [182400/225000 (81%)] Loss: 19267.968750\n",
      "Train Epoch: 198 [184896/225000 (82%)] Loss: 18812.408203\n",
      "Train Epoch: 198 [187392/225000 (83%)] Loss: 18454.544922\n",
      "Train Epoch: 198 [189888/225000 (84%)] Loss: 18318.109375\n",
      "Train Epoch: 198 [192384/225000 (86%)] Loss: 18860.488281\n",
      "Train Epoch: 198 [194880/225000 (87%)] Loss: 18870.259766\n",
      "Train Epoch: 198 [197376/225000 (88%)] Loss: 19090.412109\n",
      "Train Epoch: 198 [199872/225000 (89%)] Loss: 18683.279297\n",
      "Train Epoch: 198 [202368/225000 (90%)] Loss: 18588.792969\n",
      "Train Epoch: 198 [204864/225000 (91%)] Loss: 18627.119141\n",
      "Train Epoch: 198 [207360/225000 (92%)] Loss: 18199.089844\n",
      "Train Epoch: 198 [209856/225000 (93%)] Loss: 18881.730469\n",
      "Train Epoch: 198 [212352/225000 (94%)] Loss: 18892.648438\n",
      "Train Epoch: 198 [214848/225000 (95%)] Loss: 18823.271484\n",
      "Train Epoch: 198 [217344/225000 (97%)] Loss: 19303.031250\n",
      "Train Epoch: 198 [219840/225000 (98%)] Loss: 18381.992188\n",
      "Train Epoch: 198 [222336/225000 (99%)] Loss: 18782.531250\n",
      "Train Epoch: 198 [224832/225000 (100%)] Loss: 19257.003906\n",
      "    epoch          : 198\n",
      "    loss           : 18757.24621707018\n",
      "    val_loss       : 18647.240330426746\n",
      "Train Epoch: 199 [192/225000 (0%)] Loss: 18998.890625\n",
      "Train Epoch: 199 [2688/225000 (1%)] Loss: 18700.097656\n",
      "Train Epoch: 199 [5184/225000 (2%)] Loss: 18682.640625\n",
      "Train Epoch: 199 [7680/225000 (3%)] Loss: 18695.167969\n",
      "Train Epoch: 199 [10176/225000 (5%)] Loss: 18817.013672\n",
      "Train Epoch: 199 [12672/225000 (6%)] Loss: 19154.285156\n",
      "Train Epoch: 199 [15168/225000 (7%)] Loss: 18700.462891\n",
      "Train Epoch: 199 [17664/225000 (8%)] Loss: 19146.582031\n",
      "Train Epoch: 199 [20160/225000 (9%)] Loss: 18941.125000\n",
      "Train Epoch: 199 [22656/225000 (10%)] Loss: 19028.039062\n",
      "Train Epoch: 199 [25152/225000 (11%)] Loss: 18800.876953\n",
      "Train Epoch: 199 [27648/225000 (12%)] Loss: 18340.750000\n",
      "Train Epoch: 199 [30144/225000 (13%)] Loss: 18707.367188\n",
      "Train Epoch: 199 [32640/225000 (15%)] Loss: 18604.855469\n",
      "Train Epoch: 199 [35136/225000 (16%)] Loss: 18451.125000\n",
      "Train Epoch: 199 [37632/225000 (17%)] Loss: 18983.498047\n",
      "Train Epoch: 199 [40128/225000 (18%)] Loss: 18783.300781\n",
      "Train Epoch: 199 [42624/225000 (19%)] Loss: 18378.933594\n",
      "Train Epoch: 199 [45120/225000 (20%)] Loss: 18391.775391\n",
      "Train Epoch: 199 [47616/225000 (21%)] Loss: 18305.933594\n",
      "Train Epoch: 199 [50112/225000 (22%)] Loss: 18590.816406\n",
      "Train Epoch: 199 [52608/225000 (23%)] Loss: 18525.207031\n",
      "Train Epoch: 199 [55104/225000 (24%)] Loss: 18706.996094\n",
      "Train Epoch: 199 [57600/225000 (26%)] Loss: 18767.185547\n",
      "Train Epoch: 199 [60096/225000 (27%)] Loss: 19279.777344\n",
      "Train Epoch: 199 [62592/225000 (28%)] Loss: 18398.890625\n",
      "Train Epoch: 199 [65088/225000 (29%)] Loss: 18567.437500\n",
      "Train Epoch: 199 [67584/225000 (30%)] Loss: 18575.445312\n",
      "Train Epoch: 199 [70080/225000 (31%)] Loss: 19053.808594\n",
      "Train Epoch: 199 [72576/225000 (32%)] Loss: 19369.457031\n",
      "Train Epoch: 199 [75072/225000 (33%)] Loss: 18719.609375\n",
      "Train Epoch: 199 [77568/225000 (34%)] Loss: 18332.277344\n",
      "Train Epoch: 199 [80064/225000 (36%)] Loss: 18927.316406\n",
      "Train Epoch: 199 [82560/225000 (37%)] Loss: 18725.171875\n",
      "Train Epoch: 199 [85056/225000 (38%)] Loss: 18577.671875\n",
      "Train Epoch: 199 [87552/225000 (39%)] Loss: 18481.488281\n",
      "Train Epoch: 199 [90048/225000 (40%)] Loss: 18440.570312\n",
      "Train Epoch: 199 [92544/225000 (41%)] Loss: 19150.410156\n",
      "Train Epoch: 199 [95040/225000 (42%)] Loss: 18147.478516\n",
      "Train Epoch: 199 [97536/225000 (43%)] Loss: 18803.976562\n",
      "Train Epoch: 199 [100032/225000 (44%)] Loss: 18595.808594\n",
      "Train Epoch: 199 [102528/225000 (46%)] Loss: 19178.714844\n",
      "Train Epoch: 199 [105024/225000 (47%)] Loss: 18618.050781\n",
      "Train Epoch: 199 [107520/225000 (48%)] Loss: 18711.726562\n",
      "Train Epoch: 199 [110016/225000 (49%)] Loss: 18779.072266\n",
      "Train Epoch: 199 [112512/225000 (50%)] Loss: 18787.039062\n",
      "Train Epoch: 199 [115008/225000 (51%)] Loss: 18860.982422\n",
      "Train Epoch: 199 [117504/225000 (52%)] Loss: 18856.582031\n",
      "Train Epoch: 199 [120000/225000 (53%)] Loss: 18925.412109\n",
      "Train Epoch: 199 [122496/225000 (54%)] Loss: 18884.804688\n",
      "Train Epoch: 199 [124992/225000 (56%)] Loss: 18716.921875\n",
      "Train Epoch: 199 [127488/225000 (57%)] Loss: 18855.712891\n",
      "Train Epoch: 199 [129984/225000 (58%)] Loss: 18657.011719\n",
      "Train Epoch: 199 [132480/225000 (59%)] Loss: 18946.878906\n",
      "Train Epoch: 199 [134976/225000 (60%)] Loss: 18997.246094\n",
      "Train Epoch: 199 [137472/225000 (61%)] Loss: 18947.683594\n",
      "Train Epoch: 199 [139968/225000 (62%)] Loss: 18480.839844\n",
      "Train Epoch: 199 [142464/225000 (63%)] Loss: 18577.863281\n",
      "Train Epoch: 199 [144960/225000 (64%)] Loss: 18455.267578\n",
      "Train Epoch: 199 [147456/225000 (66%)] Loss: 18636.574219\n",
      "Train Epoch: 199 [149952/225000 (67%)] Loss: 18426.500000\n",
      "Train Epoch: 199 [152448/225000 (68%)] Loss: 18773.281250\n",
      "Train Epoch: 199 [154944/225000 (69%)] Loss: 18740.789062\n",
      "Train Epoch: 199 [157440/225000 (70%)] Loss: 19013.281250\n",
      "Train Epoch: 199 [159936/225000 (71%)] Loss: 18871.953125\n",
      "Train Epoch: 199 [162432/225000 (72%)] Loss: 18712.855469\n",
      "Train Epoch: 199 [164928/225000 (73%)] Loss: 19017.078125\n",
      "Train Epoch: 199 [167424/225000 (74%)] Loss: 18520.378906\n",
      "Train Epoch: 199 [169920/225000 (76%)] Loss: 18862.765625\n",
      "Train Epoch: 199 [172416/225000 (77%)] Loss: 18700.445312\n",
      "Train Epoch: 199 [174912/225000 (78%)] Loss: 19068.894531\n",
      "Train Epoch: 199 [177408/225000 (79%)] Loss: 18852.402344\n",
      "Train Epoch: 199 [179904/225000 (80%)] Loss: 18889.654297\n",
      "Train Epoch: 199 [182400/225000 (81%)] Loss: 18745.111328\n",
      "Train Epoch: 199 [184896/225000 (82%)] Loss: 19241.503906\n",
      "Train Epoch: 199 [187392/225000 (83%)] Loss: 18317.324219\n",
      "Train Epoch: 199 [189888/225000 (84%)] Loss: 18492.996094\n",
      "Train Epoch: 199 [192384/225000 (86%)] Loss: 18750.144531\n",
      "Train Epoch: 199 [194880/225000 (87%)] Loss: 18980.105469\n",
      "Train Epoch: 199 [197376/225000 (88%)] Loss: 19166.203125\n",
      "Train Epoch: 199 [199872/225000 (89%)] Loss: 18712.109375\n",
      "Train Epoch: 199 [202368/225000 (90%)] Loss: 18473.613281\n",
      "Train Epoch: 199 [204864/225000 (91%)] Loss: 18985.224609\n",
      "Train Epoch: 199 [207360/225000 (92%)] Loss: 18774.095703\n",
      "Train Epoch: 199 [209856/225000 (93%)] Loss: 18943.734375\n",
      "Train Epoch: 199 [212352/225000 (94%)] Loss: 18549.949219\n",
      "Train Epoch: 199 [214848/225000 (95%)] Loss: 18549.384766\n",
      "Train Epoch: 199 [217344/225000 (97%)] Loss: 18731.691406\n",
      "Train Epoch: 199 [219840/225000 (98%)] Loss: 18970.900391\n",
      "Train Epoch: 199 [222336/225000 (99%)] Loss: 19162.402344\n",
      "Train Epoch: 199 [224832/225000 (100%)] Loss: 18993.337891\n",
      "    epoch          : 199\n",
      "    loss           : 18730.752251426515\n",
      "    val_loss       : 18640.636613048217\n",
      "Train Epoch: 200 [192/225000 (0%)] Loss: 18379.876953\n",
      "Train Epoch: 200 [2688/225000 (1%)] Loss: 18968.902344\n",
      "Train Epoch: 200 [5184/225000 (2%)] Loss: 18476.732422\n",
      "Train Epoch: 200 [7680/225000 (3%)] Loss: 18537.859375\n",
      "Train Epoch: 200 [10176/225000 (5%)] Loss: 18773.675781\n",
      "Train Epoch: 200 [12672/225000 (6%)] Loss: 18691.281250\n",
      "Train Epoch: 200 [15168/225000 (7%)] Loss: 18862.964844\n",
      "Train Epoch: 200 [17664/225000 (8%)] Loss: 18493.404297\n",
      "Train Epoch: 200 [20160/225000 (9%)] Loss: 18700.919922\n",
      "Train Epoch: 200 [22656/225000 (10%)] Loss: 18855.796875\n",
      "Train Epoch: 200 [25152/225000 (11%)] Loss: 18989.406250\n",
      "Train Epoch: 200 [27648/225000 (12%)] Loss: 18957.757812\n",
      "Train Epoch: 200 [30144/225000 (13%)] Loss: 18651.511719\n",
      "Train Epoch: 200 [32640/225000 (15%)] Loss: 17718.771484\n",
      "Train Epoch: 200 [35136/225000 (16%)] Loss: 18579.298828\n",
      "Train Epoch: 200 [37632/225000 (17%)] Loss: 18538.812500\n",
      "Train Epoch: 200 [40128/225000 (18%)] Loss: 18199.373047\n",
      "Train Epoch: 200 [42624/225000 (19%)] Loss: 18943.906250\n",
      "Train Epoch: 200 [45120/225000 (20%)] Loss: 18415.027344\n",
      "Train Epoch: 200 [47616/225000 (21%)] Loss: 18407.853516\n",
      "Train Epoch: 200 [50112/225000 (22%)] Loss: 18383.476562\n",
      "Train Epoch: 200 [52608/225000 (23%)] Loss: 18971.667969\n",
      "Train Epoch: 200 [55104/225000 (24%)] Loss: 19162.097656\n",
      "Train Epoch: 200 [57600/225000 (26%)] Loss: 18506.945312\n",
      "Train Epoch: 200 [60096/225000 (27%)] Loss: 18798.041016\n",
      "Train Epoch: 200 [62592/225000 (28%)] Loss: 18729.066406\n",
      "Train Epoch: 200 [65088/225000 (29%)] Loss: 18367.726562\n",
      "Train Epoch: 200 [67584/225000 (30%)] Loss: 18987.289062\n",
      "Train Epoch: 200 [70080/225000 (31%)] Loss: 18670.980469\n",
      "Train Epoch: 200 [72576/225000 (32%)] Loss: 17976.693359\n",
      "Train Epoch: 200 [75072/225000 (33%)] Loss: 18915.984375\n",
      "Train Epoch: 200 [77568/225000 (34%)] Loss: 18513.488281\n",
      "Train Epoch: 200 [80064/225000 (36%)] Loss: 19094.255859\n",
      "Train Epoch: 200 [82560/225000 (37%)] Loss: 18421.316406\n",
      "Train Epoch: 200 [85056/225000 (38%)] Loss: 19221.812500\n",
      "Train Epoch: 200 [87552/225000 (39%)] Loss: 18529.164062\n",
      "Train Epoch: 200 [90048/225000 (40%)] Loss: 18926.117188\n",
      "Train Epoch: 200 [92544/225000 (41%)] Loss: 18633.839844\n",
      "Train Epoch: 200 [95040/225000 (42%)] Loss: 18641.125000\n",
      "Train Epoch: 200 [97536/225000 (43%)] Loss: 19291.794922\n",
      "Train Epoch: 200 [100032/225000 (44%)] Loss: 19114.103516\n",
      "Train Epoch: 200 [102528/225000 (46%)] Loss: 18828.710938\n",
      "Train Epoch: 200 [105024/225000 (47%)] Loss: 18430.974609\n",
      "Train Epoch: 200 [107520/225000 (48%)] Loss: 18951.699219\n",
      "Train Epoch: 200 [110016/225000 (49%)] Loss: 18237.574219\n",
      "Train Epoch: 200 [112512/225000 (50%)] Loss: 18470.402344\n",
      "Train Epoch: 200 [115008/225000 (51%)] Loss: 18402.755859\n",
      "Train Epoch: 200 [117504/225000 (52%)] Loss: 18774.542969\n",
      "Train Epoch: 200 [120000/225000 (53%)] Loss: 18628.441406\n",
      "Train Epoch: 200 [122496/225000 (54%)] Loss: 18825.960938\n",
      "Train Epoch: 200 [124992/225000 (56%)] Loss: 19004.406250\n",
      "Train Epoch: 200 [127488/225000 (57%)] Loss: 18280.423828\n",
      "Train Epoch: 200 [129984/225000 (58%)] Loss: 18374.326172\n",
      "Train Epoch: 200 [132480/225000 (59%)] Loss: 19041.199219\n",
      "Train Epoch: 200 [134976/225000 (60%)] Loss: 18792.765625\n",
      "Train Epoch: 200 [137472/225000 (61%)] Loss: 18480.867188\n",
      "Train Epoch: 200 [139968/225000 (62%)] Loss: 18298.054688\n",
      "Train Epoch: 200 [142464/225000 (63%)] Loss: 18748.517578\n",
      "Train Epoch: 200 [144960/225000 (64%)] Loss: 18615.275391\n",
      "Train Epoch: 200 [147456/225000 (66%)] Loss: 18221.332031\n",
      "Train Epoch: 200 [149952/225000 (67%)] Loss: 18590.398438\n",
      "Train Epoch: 200 [152448/225000 (68%)] Loss: 18500.220703\n",
      "Train Epoch: 200 [154944/225000 (69%)] Loss: 18844.732422\n",
      "Train Epoch: 200 [157440/225000 (70%)] Loss: 18991.480469\n",
      "Train Epoch: 200 [159936/225000 (71%)] Loss: 18409.468750\n",
      "Train Epoch: 200 [162432/225000 (72%)] Loss: 18487.468750\n",
      "Train Epoch: 200 [164928/225000 (73%)] Loss: 18444.843750\n",
      "Train Epoch: 200 [167424/225000 (74%)] Loss: 18583.427734\n",
      "Train Epoch: 200 [169920/225000 (76%)] Loss: 18569.402344\n",
      "Train Epoch: 200 [172416/225000 (77%)] Loss: 18783.777344\n",
      "Train Epoch: 200 [174912/225000 (78%)] Loss: 18894.640625\n",
      "Train Epoch: 200 [177408/225000 (79%)] Loss: 18755.017578\n",
      "Train Epoch: 200 [179904/225000 (80%)] Loss: 17964.048828\n",
      "Train Epoch: 200 [182400/225000 (81%)] Loss: 18827.449219\n",
      "Train Epoch: 200 [184896/225000 (82%)] Loss: 18632.636719\n",
      "Train Epoch: 200 [187392/225000 (83%)] Loss: 18828.626953\n",
      "Train Epoch: 200 [189888/225000 (84%)] Loss: 18640.628906\n",
      "Train Epoch: 200 [192384/225000 (86%)] Loss: 18326.488281\n",
      "Train Epoch: 200 [194880/225000 (87%)] Loss: 18933.681641\n",
      "Train Epoch: 200 [197376/225000 (88%)] Loss: 18892.671875\n",
      "Train Epoch: 200 [199872/225000 (89%)] Loss: 18265.683594\n",
      "Train Epoch: 200 [202368/225000 (90%)] Loss: 18742.988281\n",
      "Train Epoch: 200 [204864/225000 (91%)] Loss: 18559.308594\n",
      "Train Epoch: 200 [207360/225000 (92%)] Loss: 18203.695312\n",
      "Train Epoch: 200 [209856/225000 (93%)] Loss: 18888.824219\n",
      "Train Epoch: 200 [212352/225000 (94%)] Loss: 18945.246094\n",
      "Train Epoch: 200 [214848/225000 (95%)] Loss: 18657.630859\n",
      "Train Epoch: 200 [217344/225000 (97%)] Loss: 18506.984375\n",
      "Train Epoch: 200 [219840/225000 (98%)] Loss: 18511.951172\n",
      "Train Epoch: 200 [222336/225000 (99%)] Loss: 18486.207031\n",
      "Train Epoch: 200 [224832/225000 (100%)] Loss: 19063.097656\n",
      "    epoch          : 200\n",
      "    loss           : 18699.260668028743\n",
      "    val_loss       : 18590.398063863053\n",
      "Saving checkpoint: saved/models/Molecular_VaeCategory/0803_194629/checkpoint-epoch200.pth ...\n",
      "Saving current best: model_best.pth ...\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MolecularVaeCategoryModel(\n",
       "  (_category): FreeCategory(\n",
       "    (generator_0): MolecularDecoder(\n",
       "      (pre_recurrence_linear): Sequential(\n",
       "        (0): Linear(in_features=196, out_features=196, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (recurrence): GRU(196, 50, num_layers=3, batch_first=True)\n",
       "      (decoder): Sequential(\n",
       "        (0): Linear(in_features=50, out_features=34, bias=True)\n",
       "        (1): LogSoftmax(dim=-1)\n",
       "      )\n",
       "    )\n",
       "    (generator_0_dagger): ConvMolecularEncoder(\n",
       "      (smiles_conv): Sequential(\n",
       "        (0): Conv1d(120, 9, kernel_size=(9,), stride=(1,))\n",
       "        (1): ReLU()\n",
       "        (2): Conv1d(9, 9, kernel_size=(9,), stride=(1,))\n",
       "        (3): ReLU()\n",
       "        (4): Conv1d(9, 10, kernel_size=(11,), stride=(1,))\n",
       "        (5): ReLU()\n",
       "      )\n",
       "      (smiles_linear): Sequential(\n",
       "        (0): Linear(in_features=80, out_features=196, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (embedding_loc): Linear(in_features=196, out_features=196, bias=True)\n",
       "      (embedding_log_scale): Linear(in_features=196, out_features=196, bias=True)\n",
       "      (embedding_dist): DiagonalGaussian()\n",
       "    )\n",
       "    (generator_1): MolecularDecoder(\n",
       "      (pre_recurrence_linear): Sequential(\n",
       "        (0): Linear(in_features=196, out_features=196, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (recurrence): GRU(196, 50, num_layers=3, batch_first=True)\n",
       "      (decoder): Sequential(\n",
       "        (0): Linear(in_features=50, out_features=34, bias=True)\n",
       "        (1): LogSoftmax(dim=-1)\n",
       "      )\n",
       "    )\n",
       "    (generator_1_dagger): RecurrentMolecularEncoder(\n",
       "      (encoder_linear): Sequential(\n",
       "        (0): Linear(in_features=34, out_features=50, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (recurrence): GRU(50, 196, num_layers=3, batch_first=True)\n",
       "      (postrecurrence_linear): Sequential(\n",
       "        (0): Linear(in_features=196, out_features=196, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (embedding_loc): Linear(in_features=196, out_features=196, bias=True)\n",
       "      (embedding_log_scale): Linear(in_features=196, out_features=196, bias=True)\n",
       "      (embedding_dist): DiagonalGaussian()\n",
       "    )\n",
       "    (generator_2): MolecularDecoder(\n",
       "      (pre_recurrence_linear): Sequential(\n",
       "        (0): Linear(in_features=196, out_features=196, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (recurrence): GRU(196, 488, num_layers=3, batch_first=True)\n",
       "      (decoder): Sequential(\n",
       "        (0): Linear(in_features=488, out_features=34, bias=True)\n",
       "        (1): LogSoftmax(dim=-1)\n",
       "      )\n",
       "    )\n",
       "    (generator_2_dagger): ConvMolecularEncoder(\n",
       "      (smiles_conv): Sequential(\n",
       "        (0): Conv1d(120, 9, kernel_size=(9,), stride=(1,))\n",
       "        (1): ReLU()\n",
       "        (2): Conv1d(9, 9, kernel_size=(9,), stride=(1,))\n",
       "        (3): ReLU()\n",
       "        (4): Conv1d(9, 10, kernel_size=(11,), stride=(1,))\n",
       "        (5): ReLU()\n",
       "      )\n",
       "      (smiles_linear): Sequential(\n",
       "        (0): Linear(in_features=80, out_features=196, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (embedding_loc): Linear(in_features=196, out_features=196, bias=True)\n",
       "      (embedding_log_scale): Linear(in_features=196, out_features=196, bias=True)\n",
       "      (embedding_dist): DiagonalGaussian()\n",
       "    )\n",
       "    (generator_3): MolecularDecoder(\n",
       "      (pre_recurrence_linear): Sequential(\n",
       "        (0): Linear(in_features=196, out_features=196, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (recurrence): GRU(196, 488, num_layers=3, batch_first=True)\n",
       "      (decoder): Sequential(\n",
       "        (0): Linear(in_features=488, out_features=34, bias=True)\n",
       "        (1): LogSoftmax(dim=-1)\n",
       "      )\n",
       "    )\n",
       "    (generator_3_dagger): RecurrentMolecularEncoder(\n",
       "      (encoder_linear): Sequential(\n",
       "        (0): Linear(in_features=34, out_features=488, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (recurrence): GRU(488, 196, num_layers=3, batch_first=True)\n",
       "      (postrecurrence_linear): Sequential(\n",
       "        (0): Linear(in_features=196, out_features=196, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (embedding_loc): Linear(in_features=196, out_features=196, bias=True)\n",
       "      (embedding_log_scale): Linear(in_features=196, out_features=196, bias=True)\n",
       "      (embedding_dist): DiagonalGaussian()\n",
       "    )\n",
       "    (generator_4): MolecularDecoder(\n",
       "      (pre_recurrence_linear): Sequential(\n",
       "        (0): Linear(in_features=196, out_features=196, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (recurrence): GRU(196, 501, num_layers=3, batch_first=True)\n",
       "      (decoder): Sequential(\n",
       "        (0): Linear(in_features=501, out_features=34, bias=True)\n",
       "        (1): LogSoftmax(dim=-1)\n",
       "      )\n",
       "    )\n",
       "    (generator_4_dagger): ConvMolecularEncoder(\n",
       "      (smiles_conv): Sequential(\n",
       "        (0): Conv1d(120, 9, kernel_size=(9,), stride=(1,))\n",
       "        (1): ReLU()\n",
       "        (2): Conv1d(9, 9, kernel_size=(9,), stride=(1,))\n",
       "        (3): ReLU()\n",
       "        (4): Conv1d(9, 10, kernel_size=(11,), stride=(1,))\n",
       "        (5): ReLU()\n",
       "      )\n",
       "      (smiles_linear): Sequential(\n",
       "        (0): Linear(in_features=80, out_features=196, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (embedding_loc): Linear(in_features=196, out_features=196, bias=True)\n",
       "      (embedding_log_scale): Linear(in_features=196, out_features=196, bias=True)\n",
       "      (embedding_dist): DiagonalGaussian()\n",
       "    )\n",
       "    (generator_5): MolecularDecoder(\n",
       "      (pre_recurrence_linear): Sequential(\n",
       "        (0): Linear(in_features=196, out_features=196, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (recurrence): GRU(196, 501, num_layers=3, batch_first=True)\n",
       "      (decoder): Sequential(\n",
       "        (0): Linear(in_features=501, out_features=34, bias=True)\n",
       "        (1): LogSoftmax(dim=-1)\n",
       "      )\n",
       "    )\n",
       "    (generator_5_dagger): RecurrentMolecularEncoder(\n",
       "      (encoder_linear): Sequential(\n",
       "        (0): Linear(in_features=34, out_features=501, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (recurrence): GRU(501, 196, num_layers=3, batch_first=True)\n",
       "      (postrecurrence_linear): Sequential(\n",
       "        (0): Linear(in_features=196, out_features=196, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (embedding_loc): Linear(in_features=196, out_features=196, bias=True)\n",
       "      (embedding_log_scale): Linear(in_features=196, out_features=196, bias=True)\n",
       "      (embedding_dist): DiagonalGaussian()\n",
       "    )\n",
       "    (generator_6): MolecularDecoder(\n",
       "      (pre_recurrence_linear): Sequential(\n",
       "        (0): Linear(in_features=292, out_features=292, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (recurrence): GRU(292, 50, num_layers=3, batch_first=True)\n",
       "      (decoder): Sequential(\n",
       "        (0): Linear(in_features=50, out_features=34, bias=True)\n",
       "        (1): LogSoftmax(dim=-1)\n",
       "      )\n",
       "    )\n",
       "    (generator_6_dagger): ConvMolecularEncoder(\n",
       "      (smiles_conv): Sequential(\n",
       "        (0): Conv1d(120, 9, kernel_size=(9,), stride=(1,))\n",
       "        (1): ReLU()\n",
       "        (2): Conv1d(9, 9, kernel_size=(9,), stride=(1,))\n",
       "        (3): ReLU()\n",
       "        (4): Conv1d(9, 10, kernel_size=(11,), stride=(1,))\n",
       "        (5): ReLU()\n",
       "      )\n",
       "      (smiles_linear): Sequential(\n",
       "        (0): Linear(in_features=80, out_features=292, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (embedding_loc): Linear(in_features=292, out_features=292, bias=True)\n",
       "      (embedding_log_scale): Linear(in_features=292, out_features=292, bias=True)\n",
       "      (embedding_dist): DiagonalGaussian()\n",
       "    )\n",
       "    (generator_7): MolecularDecoder(\n",
       "      (pre_recurrence_linear): Sequential(\n",
       "        (0): Linear(in_features=292, out_features=292, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (recurrence): GRU(292, 50, num_layers=3, batch_first=True)\n",
       "      (decoder): Sequential(\n",
       "        (0): Linear(in_features=50, out_features=34, bias=True)\n",
       "        (1): LogSoftmax(dim=-1)\n",
       "      )\n",
       "    )\n",
       "    (generator_7_dagger): RecurrentMolecularEncoder(\n",
       "      (encoder_linear): Sequential(\n",
       "        (0): Linear(in_features=34, out_features=50, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (recurrence): GRU(50, 292, num_layers=3, batch_first=True)\n",
       "      (postrecurrence_linear): Sequential(\n",
       "        (0): Linear(in_features=292, out_features=292, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (embedding_loc): Linear(in_features=292, out_features=292, bias=True)\n",
       "      (embedding_log_scale): Linear(in_features=292, out_features=292, bias=True)\n",
       "      (embedding_dist): DiagonalGaussian()\n",
       "    )\n",
       "    (generator_8): MolecularDecoder(\n",
       "      (pre_recurrence_linear): Sequential(\n",
       "        (0): Linear(in_features=292, out_features=292, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (recurrence): GRU(292, 488, num_layers=3, batch_first=True)\n",
       "      (decoder): Sequential(\n",
       "        (0): Linear(in_features=488, out_features=34, bias=True)\n",
       "        (1): LogSoftmax(dim=-1)\n",
       "      )\n",
       "    )\n",
       "    (generator_8_dagger): ConvMolecularEncoder(\n",
       "      (smiles_conv): Sequential(\n",
       "        (0): Conv1d(120, 9, kernel_size=(9,), stride=(1,))\n",
       "        (1): ReLU()\n",
       "        (2): Conv1d(9, 9, kernel_size=(9,), stride=(1,))\n",
       "        (3): ReLU()\n",
       "        (4): Conv1d(9, 10, kernel_size=(11,), stride=(1,))\n",
       "        (5): ReLU()\n",
       "      )\n",
       "      (smiles_linear): Sequential(\n",
       "        (0): Linear(in_features=80, out_features=292, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (embedding_loc): Linear(in_features=292, out_features=292, bias=True)\n",
       "      (embedding_log_scale): Linear(in_features=292, out_features=292, bias=True)\n",
       "      (embedding_dist): DiagonalGaussian()\n",
       "    )\n",
       "    (generator_9): MolecularDecoder(\n",
       "      (pre_recurrence_linear): Sequential(\n",
       "        (0): Linear(in_features=292, out_features=292, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (recurrence): GRU(292, 488, num_layers=3, batch_first=True)\n",
       "      (decoder): Sequential(\n",
       "        (0): Linear(in_features=488, out_features=34, bias=True)\n",
       "        (1): LogSoftmax(dim=-1)\n",
       "      )\n",
       "    )\n",
       "    (generator_9_dagger): RecurrentMolecularEncoder(\n",
       "      (encoder_linear): Sequential(\n",
       "        (0): Linear(in_features=34, out_features=488, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (recurrence): GRU(488, 292, num_layers=3, batch_first=True)\n",
       "      (postrecurrence_linear): Sequential(\n",
       "        (0): Linear(in_features=292, out_features=292, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (embedding_loc): Linear(in_features=292, out_features=292, bias=True)\n",
       "      (embedding_log_scale): Linear(in_features=292, out_features=292, bias=True)\n",
       "      (embedding_dist): DiagonalGaussian()\n",
       "    )\n",
       "    (generator_10): MolecularDecoder(\n",
       "      (pre_recurrence_linear): Sequential(\n",
       "        (0): Linear(in_features=292, out_features=292, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (recurrence): GRU(292, 501, num_layers=3, batch_first=True)\n",
       "      (decoder): Sequential(\n",
       "        (0): Linear(in_features=501, out_features=34, bias=True)\n",
       "        (1): LogSoftmax(dim=-1)\n",
       "      )\n",
       "    )\n",
       "    (generator_10_dagger): ConvMolecularEncoder(\n",
       "      (smiles_conv): Sequential(\n",
       "        (0): Conv1d(120, 9, kernel_size=(9,), stride=(1,))\n",
       "        (1): ReLU()\n",
       "        (2): Conv1d(9, 9, kernel_size=(9,), stride=(1,))\n",
       "        (3): ReLU()\n",
       "        (4): Conv1d(9, 10, kernel_size=(11,), stride=(1,))\n",
       "        (5): ReLU()\n",
       "      )\n",
       "      (smiles_linear): Sequential(\n",
       "        (0): Linear(in_features=80, out_features=292, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (embedding_loc): Linear(in_features=292, out_features=292, bias=True)\n",
       "      (embedding_log_scale): Linear(in_features=292, out_features=292, bias=True)\n",
       "      (embedding_dist): DiagonalGaussian()\n",
       "    )\n",
       "    (generator_11): MolecularDecoder(\n",
       "      (pre_recurrence_linear): Sequential(\n",
       "        (0): Linear(in_features=292, out_features=292, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (recurrence): GRU(292, 501, num_layers=3, batch_first=True)\n",
       "      (decoder): Sequential(\n",
       "        (0): Linear(in_features=501, out_features=34, bias=True)\n",
       "        (1): LogSoftmax(dim=-1)\n",
       "      )\n",
       "    )\n",
       "    (generator_11_dagger): RecurrentMolecularEncoder(\n",
       "      (encoder_linear): Sequential(\n",
       "        (0): Linear(in_features=34, out_features=501, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (recurrence): GRU(501, 292, num_layers=3, batch_first=True)\n",
       "      (postrecurrence_linear): Sequential(\n",
       "        (0): Linear(in_features=292, out_features=292, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (embedding_loc): Linear(in_features=292, out_features=292, bias=True)\n",
       "      (embedding_log_scale): Linear(in_features=292, out_features=292, bias=True)\n",
       "      (embedding_dist): DiagonalGaussian()\n",
       "    )\n",
       "    (generator_12): MolecularDecoder(\n",
       "      (pre_recurrence_linear): Sequential(\n",
       "        (0): Linear(in_features=435, out_features=435, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (recurrence): GRU(435, 50, num_layers=3, batch_first=True)\n",
       "      (decoder): Sequential(\n",
       "        (0): Linear(in_features=50, out_features=34, bias=True)\n",
       "        (1): LogSoftmax(dim=-1)\n",
       "      )\n",
       "    )\n",
       "    (generator_12_dagger): ConvMolecularEncoder(\n",
       "      (smiles_conv): Sequential(\n",
       "        (0): Conv1d(120, 9, kernel_size=(9,), stride=(1,))\n",
       "        (1): ReLU()\n",
       "        (2): Conv1d(9, 9, kernel_size=(9,), stride=(1,))\n",
       "        (3): ReLU()\n",
       "        (4): Conv1d(9, 10, kernel_size=(11,), stride=(1,))\n",
       "        (5): ReLU()\n",
       "      )\n",
       "      (smiles_linear): Sequential(\n",
       "        (0): Linear(in_features=80, out_features=435, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (embedding_loc): Linear(in_features=435, out_features=435, bias=True)\n",
       "      (embedding_log_scale): Linear(in_features=435, out_features=435, bias=True)\n",
       "      (embedding_dist): DiagonalGaussian()\n",
       "    )\n",
       "    (generator_13): MolecularDecoder(\n",
       "      (pre_recurrence_linear): Sequential(\n",
       "        (0): Linear(in_features=435, out_features=435, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (recurrence): GRU(435, 50, num_layers=3, batch_first=True)\n",
       "      (decoder): Sequential(\n",
       "        (0): Linear(in_features=50, out_features=34, bias=True)\n",
       "        (1): LogSoftmax(dim=-1)\n",
       "      )\n",
       "    )\n",
       "    (generator_13_dagger): RecurrentMolecularEncoder(\n",
       "      (encoder_linear): Sequential(\n",
       "        (0): Linear(in_features=34, out_features=50, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (recurrence): GRU(50, 435, num_layers=3, batch_first=True)\n",
       "      (postrecurrence_linear): Sequential(\n",
       "        (0): Linear(in_features=435, out_features=435, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (embedding_loc): Linear(in_features=435, out_features=435, bias=True)\n",
       "      (embedding_log_scale): Linear(in_features=435, out_features=435, bias=True)\n",
       "      (embedding_dist): DiagonalGaussian()\n",
       "    )\n",
       "    (generator_14): MolecularDecoder(\n",
       "      (pre_recurrence_linear): Sequential(\n",
       "        (0): Linear(in_features=435, out_features=435, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (recurrence): GRU(435, 488, num_layers=3, batch_first=True)\n",
       "      (decoder): Sequential(\n",
       "        (0): Linear(in_features=488, out_features=34, bias=True)\n",
       "        (1): LogSoftmax(dim=-1)\n",
       "      )\n",
       "    )\n",
       "    (generator_14_dagger): ConvMolecularEncoder(\n",
       "      (smiles_conv): Sequential(\n",
       "        (0): Conv1d(120, 9, kernel_size=(9,), stride=(1,))\n",
       "        (1): ReLU()\n",
       "        (2): Conv1d(9, 9, kernel_size=(9,), stride=(1,))\n",
       "        (3): ReLU()\n",
       "        (4): Conv1d(9, 10, kernel_size=(11,), stride=(1,))\n",
       "        (5): ReLU()\n",
       "      )\n",
       "      (smiles_linear): Sequential(\n",
       "        (0): Linear(in_features=80, out_features=435, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (embedding_loc): Linear(in_features=435, out_features=435, bias=True)\n",
       "      (embedding_log_scale): Linear(in_features=435, out_features=435, bias=True)\n",
       "      (embedding_dist): DiagonalGaussian()\n",
       "    )\n",
       "    (generator_15): MolecularDecoder(\n",
       "      (pre_recurrence_linear): Sequential(\n",
       "        (0): Linear(in_features=435, out_features=435, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (recurrence): GRU(435, 488, num_layers=3, batch_first=True)\n",
       "      (decoder): Sequential(\n",
       "        (0): Linear(in_features=488, out_features=34, bias=True)\n",
       "        (1): LogSoftmax(dim=-1)\n",
       "      )\n",
       "    )\n",
       "    (generator_15_dagger): RecurrentMolecularEncoder(\n",
       "      (encoder_linear): Sequential(\n",
       "        (0): Linear(in_features=34, out_features=488, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (recurrence): GRU(488, 435, num_layers=3, batch_first=True)\n",
       "      (postrecurrence_linear): Sequential(\n",
       "        (0): Linear(in_features=435, out_features=435, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (embedding_loc): Linear(in_features=435, out_features=435, bias=True)\n",
       "      (embedding_log_scale): Linear(in_features=435, out_features=435, bias=True)\n",
       "      (embedding_dist): DiagonalGaussian()\n",
       "    )\n",
       "    (generator_16): MolecularDecoder(\n",
       "      (pre_recurrence_linear): Sequential(\n",
       "        (0): Linear(in_features=435, out_features=435, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (recurrence): GRU(435, 501, num_layers=3, batch_first=True)\n",
       "      (decoder): Sequential(\n",
       "        (0): Linear(in_features=501, out_features=34, bias=True)\n",
       "        (1): LogSoftmax(dim=-1)\n",
       "      )\n",
       "    )\n",
       "    (generator_16_dagger): ConvMolecularEncoder(\n",
       "      (smiles_conv): Sequential(\n",
       "        (0): Conv1d(120, 9, kernel_size=(9,), stride=(1,))\n",
       "        (1): ReLU()\n",
       "        (2): Conv1d(9, 9, kernel_size=(9,), stride=(1,))\n",
       "        (3): ReLU()\n",
       "        (4): Conv1d(9, 10, kernel_size=(11,), stride=(1,))\n",
       "        (5): ReLU()\n",
       "      )\n",
       "      (smiles_linear): Sequential(\n",
       "        (0): Linear(in_features=80, out_features=435, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (embedding_loc): Linear(in_features=435, out_features=435, bias=True)\n",
       "      (embedding_log_scale): Linear(in_features=435, out_features=435, bias=True)\n",
       "      (embedding_dist): DiagonalGaussian()\n",
       "    )\n",
       "    (generator_17): MolecularDecoder(\n",
       "      (pre_recurrence_linear): Sequential(\n",
       "        (0): Linear(in_features=435, out_features=435, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (recurrence): GRU(435, 501, num_layers=3, batch_first=True)\n",
       "      (decoder): Sequential(\n",
       "        (0): Linear(in_features=501, out_features=34, bias=True)\n",
       "        (1): LogSoftmax(dim=-1)\n",
       "      )\n",
       "    )\n",
       "    (generator_17_dagger): RecurrentMolecularEncoder(\n",
       "      (encoder_linear): Sequential(\n",
       "        (0): Linear(in_features=34, out_features=501, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (recurrence): GRU(501, 435, num_layers=3, batch_first=True)\n",
       "      (postrecurrence_linear): Sequential(\n",
       "        (0): Linear(in_features=435, out_features=435, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (embedding_loc): Linear(in_features=435, out_features=435, bias=True)\n",
       "      (embedding_log_scale): Linear(in_features=435, out_features=435, bias=True)\n",
       "      (embedding_dist): DiagonalGaussian()\n",
       "    )\n",
       "    (global_element_0): StandardNormal()\n",
       "    (global_element_1): StandardNormal()\n",
       "    (global_element_2): StandardNormal()\n",
       "    (global_element_3): StandardNormal()\n",
       "  )\n",
       "  (guide_temperatures): Sequential(\n",
       "    (0): Linear(in_features=4080, out_features=256, bias=True)\n",
       "    (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    (2): PReLU(num_parameters=1)\n",
       "    (3): Linear(in_features=256, out_features=2, bias=True)\n",
       "    (4): Softplus(beta=1, threshold=20)\n",
       "  )\n",
       "  (guide_arrow_weights): Sequential(\n",
       "    (0): Linear(in_features=4080, out_features=256, bias=True)\n",
       "    (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    (2): PReLU(num_parameters=1)\n",
       "    (3): Linear(in_features=256, out_features=44, bias=True)\n",
       "    (4): Softplus(beta=1, threshold=20)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_xs, valid_ys = list(valid_data_loader)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "m, recons = model(observations=valid_xs, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6935)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(recons == valid_xs).all(dim=-1).flatten().to(dtype=torch.float).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:categorical_bpl] *",
   "language": "python",
   "name": "conda-env-categorical_bpl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
