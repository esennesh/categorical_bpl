{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/eli/AnacondaProjects/categorical_bpl\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit WARNING: [12:40:18] Enabling RDKit 2019.09.3 jupyter extensions\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import collections\n",
    "import pyro\n",
    "import torch\n",
    "import numpy as np\n",
    "import data_loader.data_loaders as module_data\n",
    "import model.model as module_arch\n",
    "from parse_config import ConfigParser\n",
    "from trainer import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyro.enable_validation(True)\n",
    "# torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seeds for reproducibility\n",
    "SEED = 123\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Args = collections.namedtuple('Args', 'config resume device')\n",
    "config = ConfigParser.from_args(Args(config='chemical_config.json', resume=None, device=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = config.get_logger('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup data_loader instances\n",
    "data_loader = config.init_obj('data_loader', module_data)\n",
    "valid_data_loader = data_loader.split_validation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model architecture, then print to console\n",
    "model = config.init_obj('arch', module_arch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = pyro.optim.ReduceLROnPlateau({\n",
    "    'optimizer': torch.optim.Adam,\n",
    "    'optim_args': {\n",
    "        \"lr\": 1e-4,\n",
    "        \"weight_decay\": 0,\n",
    "        \"amsgrad\": True\n",
    "    },\n",
    "    \"patience\": 5,\n",
    "    \"factor\": 0.1,\n",
    "    \"verbose\": True,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = config.init_obj('optimizer', pyro.optim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model, [], optimizer, config=config,\n",
    "                  data_loader=data_loader,\n",
    "                  valid_data_loader=valid_data_loader,\n",
    "                  lr_scheduler=optimizer, log_images=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [192/225000 (0%)] Loss: 82811.687500\n",
      "Train Epoch: 1 [2688/225000 (1%)] Loss: 79181.625000\n",
      "Train Epoch: 1 [5184/225000 (2%)] Loss: 63810.339844\n",
      "Train Epoch: 1 [7680/225000 (3%)] Loss: 74515.312500\n",
      "Train Epoch: 1 [10176/225000 (5%)] Loss: 68839.460938\n",
      "Train Epoch: 1 [12672/225000 (6%)] Loss: 61265.140625\n",
      "Train Epoch: 1 [15168/225000 (7%)] Loss: 53784.226562\n",
      "Train Epoch: 1 [17664/225000 (8%)] Loss: 49350.484375\n",
      "Train Epoch: 1 [20160/225000 (9%)] Loss: 45318.972656\n",
      "Train Epoch: 1 [22656/225000 (10%)] Loss: 43960.312500\n",
      "Train Epoch: 1 [25152/225000 (11%)] Loss: 42003.164062\n",
      "Train Epoch: 1 [27648/225000 (12%)] Loss: 40534.101562\n",
      "Train Epoch: 1 [30144/225000 (13%)] Loss: 39913.339844\n",
      "Train Epoch: 1 [32640/225000 (15%)] Loss: 39042.605469\n",
      "Train Epoch: 1 [35136/225000 (16%)] Loss: 38234.027344\n",
      "Train Epoch: 1 [37632/225000 (17%)] Loss: 37457.445312\n",
      "Train Epoch: 1 [40128/225000 (18%)] Loss: 37150.691406\n",
      "Train Epoch: 1 [42624/225000 (19%)] Loss: 48165.988281\n",
      "Train Epoch: 1 [45120/225000 (20%)] Loss: 36558.675781\n",
      "Train Epoch: 1 [47616/225000 (21%)] Loss: 35328.949219\n",
      "Train Epoch: 1 [50112/225000 (22%)] Loss: 36001.203125\n",
      "Train Epoch: 1 [52608/225000 (23%)] Loss: 34876.480469\n",
      "Train Epoch: 1 [55104/225000 (24%)] Loss: 34439.421875\n",
      "Train Epoch: 1 [57600/225000 (26%)] Loss: 34660.015625\n",
      "Train Epoch: 1 [60096/225000 (27%)] Loss: 33967.406250\n",
      "Train Epoch: 1 [62592/225000 (28%)] Loss: 33968.546875\n",
      "Train Epoch: 1 [65088/225000 (29%)] Loss: 33151.679688\n",
      "Train Epoch: 1 [67584/225000 (30%)] Loss: 33675.839844\n",
      "Train Epoch: 1 [70080/225000 (31%)] Loss: 33115.050781\n",
      "Train Epoch: 1 [72576/225000 (32%)] Loss: 31966.226562\n",
      "Train Epoch: 1 [75072/225000 (33%)] Loss: 31209.238281\n",
      "Train Epoch: 1 [77568/225000 (34%)] Loss: 30984.273438\n",
      "Train Epoch: 1 [80064/225000 (36%)] Loss: 30072.859375\n",
      "Train Epoch: 1 [82560/225000 (37%)] Loss: 30028.726562\n",
      "Train Epoch: 1 [85056/225000 (38%)] Loss: 29075.816406\n",
      "Train Epoch: 1 [87552/225000 (39%)] Loss: 29126.892578\n",
      "Train Epoch: 1 [90048/225000 (40%)] Loss: 28179.332031\n",
      "Train Epoch: 1 [92544/225000 (41%)] Loss: 27848.484375\n",
      "Train Epoch: 1 [95040/225000 (42%)] Loss: 28297.630859\n",
      "Train Epoch: 1 [97536/225000 (43%)] Loss: 27571.142578\n",
      "Train Epoch: 1 [100032/225000 (44%)] Loss: 27448.687500\n",
      "Train Epoch: 1 [102528/225000 (46%)] Loss: 26971.689453\n",
      "Train Epoch: 1 [105024/225000 (47%)] Loss: 26999.673828\n",
      "Train Epoch: 1 [107520/225000 (48%)] Loss: 26331.880859\n",
      "Train Epoch: 1 [110016/225000 (49%)] Loss: 26899.396484\n",
      "Train Epoch: 1 [112512/225000 (50%)] Loss: 26817.351562\n",
      "Train Epoch: 1 [115008/225000 (51%)] Loss: 26232.322266\n",
      "Train Epoch: 1 [117504/225000 (52%)] Loss: 26275.552734\n",
      "Train Epoch: 1 [120000/225000 (53%)] Loss: 25891.011719\n",
      "Train Epoch: 1 [122496/225000 (54%)] Loss: 26267.222656\n",
      "Train Epoch: 1 [124992/225000 (56%)] Loss: 26219.548828\n",
      "Train Epoch: 1 [127488/225000 (57%)] Loss: 26138.980469\n",
      "Train Epoch: 1 [129984/225000 (58%)] Loss: 26263.912109\n",
      "Train Epoch: 1 [132480/225000 (59%)] Loss: 25831.755859\n",
      "Train Epoch: 1 [134976/225000 (60%)] Loss: 26137.464844\n",
      "Train Epoch: 1 [137472/225000 (61%)] Loss: 25313.335938\n",
      "Train Epoch: 1 [139968/225000 (62%)] Loss: 25957.376953\n",
      "Train Epoch: 1 [142464/225000 (63%)] Loss: 24981.363281\n",
      "Train Epoch: 1 [144960/225000 (64%)] Loss: 25422.347656\n",
      "Train Epoch: 1 [147456/225000 (66%)] Loss: 25639.845703\n",
      "Train Epoch: 1 [149952/225000 (67%)] Loss: 24818.304688\n",
      "Train Epoch: 1 [152448/225000 (68%)] Loss: 25647.871094\n",
      "Train Epoch: 1 [154944/225000 (69%)] Loss: 24978.685547\n",
      "Train Epoch: 1 [157440/225000 (70%)] Loss: 24316.406250\n",
      "Train Epoch: 1 [159936/225000 (71%)] Loss: 24643.431641\n",
      "Train Epoch: 1 [162432/225000 (72%)] Loss: 23947.625000\n",
      "Train Epoch: 1 [164928/225000 (73%)] Loss: 25020.185547\n",
      "Train Epoch: 1 [167424/225000 (74%)] Loss: 25367.933594\n",
      "Train Epoch: 1 [169920/225000 (76%)] Loss: 24808.328125\n",
      "Train Epoch: 1 [172416/225000 (77%)] Loss: 24535.271484\n",
      "Train Epoch: 1 [174912/225000 (78%)] Loss: 24141.343750\n",
      "Train Epoch: 1 [177408/225000 (79%)] Loss: 24633.777344\n",
      "Train Epoch: 1 [179904/225000 (80%)] Loss: 24576.279297\n",
      "Train Epoch: 1 [182400/225000 (81%)] Loss: 24050.039062\n",
      "Train Epoch: 1 [184896/225000 (82%)] Loss: 23916.318359\n",
      "Train Epoch: 1 [187392/225000 (83%)] Loss: 24152.992188\n",
      "Train Epoch: 1 [189888/225000 (84%)] Loss: 23955.906250\n",
      "Train Epoch: 1 [192384/225000 (86%)] Loss: 23427.984375\n",
      "Train Epoch: 1 [194880/225000 (87%)] Loss: 23785.847656\n",
      "Train Epoch: 1 [197376/225000 (88%)] Loss: 24210.960938\n",
      "Train Epoch: 1 [199872/225000 (89%)] Loss: 23872.935547\n",
      "Train Epoch: 1 [202368/225000 (90%)] Loss: 23628.628906\n",
      "Train Epoch: 1 [204864/225000 (91%)] Loss: 24011.173828\n",
      "Train Epoch: 1 [207360/225000 (92%)] Loss: 23560.066406\n",
      "Train Epoch: 1 [209856/225000 (93%)] Loss: 23318.339844\n",
      "Train Epoch: 1 [212352/225000 (94%)] Loss: 23986.873047\n",
      "Train Epoch: 1 [214848/225000 (95%)] Loss: 23418.832031\n",
      "Train Epoch: 1 [217344/225000 (97%)] Loss: 23406.835938\n",
      "Train Epoch: 1 [219840/225000 (98%)] Loss: 23134.435547\n",
      "Train Epoch: 1 [222336/225000 (99%)] Loss: 24132.742188\n",
      "Train Epoch: 1 [224832/225000 (100%)] Loss: 24024.699219\n",
      "    epoch          : 1\n",
      "    loss           : 31931.124110094923\n",
      "    val_loss       : 23639.291135074527\n",
      "Train Epoch: 2 [192/225000 (0%)] Loss: 23588.898438\n",
      "Train Epoch: 2 [2688/225000 (1%)] Loss: 23462.605469\n",
      "Train Epoch: 2 [5184/225000 (2%)] Loss: 23360.632812\n",
      "Train Epoch: 2 [7680/225000 (3%)] Loss: 23802.386719\n",
      "Train Epoch: 2 [10176/225000 (5%)] Loss: 23489.876953\n",
      "Train Epoch: 2 [12672/225000 (6%)] Loss: 23526.894531\n",
      "Train Epoch: 2 [15168/225000 (7%)] Loss: 23741.677734\n",
      "Train Epoch: 2 [17664/225000 (8%)] Loss: 23876.281250\n",
      "Train Epoch: 2 [20160/225000 (9%)] Loss: 22841.261719\n",
      "Train Epoch: 2 [22656/225000 (10%)] Loss: 23592.908203\n",
      "Train Epoch: 2 [25152/225000 (11%)] Loss: 23720.912109\n",
      "Train Epoch: 2 [27648/225000 (12%)] Loss: 22972.119141\n",
      "Train Epoch: 2 [30144/225000 (13%)] Loss: 23045.326172\n",
      "Train Epoch: 2 [32640/225000 (15%)] Loss: 23277.035156\n",
      "Train Epoch: 2 [35136/225000 (16%)] Loss: 23636.583984\n",
      "Train Epoch: 2 [37632/225000 (17%)] Loss: 23061.412109\n",
      "Train Epoch: 2 [40128/225000 (18%)] Loss: 23045.242188\n",
      "Train Epoch: 2 [42624/225000 (19%)] Loss: 23121.396484\n",
      "Train Epoch: 2 [45120/225000 (20%)] Loss: 23679.992188\n",
      "Train Epoch: 2 [47616/225000 (21%)] Loss: 23312.949219\n",
      "Train Epoch: 2 [50112/225000 (22%)] Loss: 22661.550781\n",
      "Train Epoch: 2 [52608/225000 (23%)] Loss: 22978.644531\n",
      "Train Epoch: 2 [55104/225000 (24%)] Loss: 23672.468750\n",
      "Train Epoch: 2 [57600/225000 (26%)] Loss: 23336.179688\n",
      "Train Epoch: 2 [60096/225000 (27%)] Loss: 23135.074219\n",
      "Train Epoch: 2 [62592/225000 (28%)] Loss: 23740.394531\n",
      "Train Epoch: 2 [65088/225000 (29%)] Loss: 23428.832031\n",
      "Train Epoch: 2 [67584/225000 (30%)] Loss: 22625.416016\n",
      "Train Epoch: 2 [70080/225000 (31%)] Loss: 23335.396484\n",
      "Train Epoch: 2 [72576/225000 (32%)] Loss: 22748.707031\n",
      "Train Epoch: 2 [75072/225000 (33%)] Loss: 22968.324219\n",
      "Train Epoch: 2 [77568/225000 (34%)] Loss: 22980.357422\n",
      "Train Epoch: 2 [80064/225000 (36%)] Loss: 23293.619141\n",
      "Train Epoch: 2 [82560/225000 (37%)] Loss: 23421.542969\n",
      "Train Epoch: 2 [85056/225000 (38%)] Loss: 23351.507812\n",
      "Train Epoch: 2 [87552/225000 (39%)] Loss: 22974.298828\n",
      "Train Epoch: 2 [90048/225000 (40%)] Loss: 22630.246094\n",
      "Train Epoch: 2 [92544/225000 (41%)] Loss: 22065.646484\n",
      "Train Epoch: 2 [95040/225000 (42%)] Loss: 23119.886719\n",
      "Train Epoch: 2 [97536/225000 (43%)] Loss: 23111.121094\n",
      "Train Epoch: 2 [100032/225000 (44%)] Loss: 22247.703125\n",
      "Train Epoch: 2 [102528/225000 (46%)] Loss: 22598.736328\n",
      "Train Epoch: 2 [105024/225000 (47%)] Loss: 23100.740234\n",
      "Train Epoch: 2 [107520/225000 (48%)] Loss: 22799.832031\n",
      "Train Epoch: 2 [110016/225000 (49%)] Loss: 22244.531250\n",
      "Train Epoch: 2 [112512/225000 (50%)] Loss: 22123.878906\n",
      "Train Epoch: 2 [115008/225000 (51%)] Loss: 22405.515625\n",
      "Train Epoch: 2 [117504/225000 (52%)] Loss: 22622.804688\n",
      "Train Epoch: 2 [120000/225000 (53%)] Loss: 22712.880859\n",
      "Train Epoch: 2 [122496/225000 (54%)] Loss: 22603.519531\n",
      "Train Epoch: 2 [124992/225000 (56%)] Loss: 22498.394531\n",
      "Train Epoch: 2 [127488/225000 (57%)] Loss: 21783.957031\n",
      "Train Epoch: 2 [129984/225000 (58%)] Loss: 22349.542969\n",
      "Train Epoch: 2 [132480/225000 (59%)] Loss: 22265.380859\n",
      "Train Epoch: 2 [134976/225000 (60%)] Loss: 22022.777344\n",
      "Train Epoch: 2 [137472/225000 (61%)] Loss: 21788.136719\n",
      "Train Epoch: 2 [139968/225000 (62%)] Loss: 22025.078125\n",
      "Train Epoch: 2 [142464/225000 (63%)] Loss: 22144.460938\n",
      "Train Epoch: 2 [144960/225000 (64%)] Loss: 21211.353516\n",
      "Train Epoch: 2 [147456/225000 (66%)] Loss: 21800.470703\n",
      "Train Epoch: 2 [149952/225000 (67%)] Loss: 22449.892578\n",
      "Train Epoch: 2 [152448/225000 (68%)] Loss: 21631.953125\n",
      "Train Epoch: 2 [154944/225000 (69%)] Loss: 22389.730469\n",
      "Train Epoch: 2 [157440/225000 (70%)] Loss: 22320.433594\n",
      "Train Epoch: 2 [159936/225000 (71%)] Loss: 22034.058594\n",
      "Train Epoch: 2 [162432/225000 (72%)] Loss: 22315.689453\n",
      "Train Epoch: 2 [164928/225000 (73%)] Loss: 22363.074219\n",
      "Train Epoch: 2 [167424/225000 (74%)] Loss: 21698.652344\n",
      "Train Epoch: 2 [169920/225000 (76%)] Loss: 21956.460938\n",
      "Train Epoch: 2 [172416/225000 (77%)] Loss: 22185.693359\n",
      "Train Epoch: 2 [174912/225000 (78%)] Loss: 21851.396484\n",
      "Train Epoch: 2 [177408/225000 (79%)] Loss: 21922.736328\n",
      "Train Epoch: 2 [179904/225000 (80%)] Loss: 21679.335938\n",
      "Train Epoch: 2 [182400/225000 (81%)] Loss: 21960.757812\n",
      "Train Epoch: 2 [184896/225000 (82%)] Loss: 22521.900391\n",
      "Train Epoch: 2 [187392/225000 (83%)] Loss: 22038.535156\n",
      "Train Epoch: 2 [189888/225000 (84%)] Loss: 21680.878906\n",
      "Train Epoch: 2 [192384/225000 (86%)] Loss: 21541.296875\n",
      "Train Epoch: 2 [194880/225000 (87%)] Loss: 22211.597656\n",
      "Train Epoch: 2 [197376/225000 (88%)] Loss: 21972.972656\n",
      "Train Epoch: 2 [199872/225000 (89%)] Loss: 21832.082031\n",
      "Train Epoch: 2 [202368/225000 (90%)] Loss: 21773.550781\n",
      "Train Epoch: 2 [204864/225000 (91%)] Loss: 21760.320312\n",
      "Train Epoch: 2 [207360/225000 (92%)] Loss: 21319.447266\n",
      "Train Epoch: 2 [209856/225000 (93%)] Loss: 21798.593750\n",
      "Train Epoch: 2 [212352/225000 (94%)] Loss: 21864.230469\n",
      "Train Epoch: 2 [214848/225000 (95%)] Loss: 21844.406250\n",
      "Train Epoch: 2 [217344/225000 (97%)] Loss: 21662.882812\n",
      "Train Epoch: 2 [219840/225000 (98%)] Loss: 21598.648438\n",
      "Train Epoch: 2 [222336/225000 (99%)] Loss: 21947.603516\n",
      "Train Epoch: 2 [224832/225000 (100%)] Loss: 21952.671875\n",
      "    epoch          : 2\n",
      "    loss           : 22602.933402103776\n",
      "    val_loss       : 21641.625861329885\n",
      "Train Epoch: 3 [192/225000 (0%)] Loss: 21689.000000\n",
      "Train Epoch: 3 [2688/225000 (1%)] Loss: 21962.750000\n",
      "Train Epoch: 3 [5184/225000 (2%)] Loss: 21882.484375\n",
      "Train Epoch: 3 [7680/225000 (3%)] Loss: 22231.929688\n",
      "Train Epoch: 3 [10176/225000 (5%)] Loss: 21969.597656\n",
      "Train Epoch: 3 [12672/225000 (6%)] Loss: 21592.664062\n",
      "Train Epoch: 3 [15168/225000 (7%)] Loss: 21928.410156\n",
      "Train Epoch: 3 [17664/225000 (8%)] Loss: 21320.607422\n",
      "Train Epoch: 3 [20160/225000 (9%)] Loss: 21787.484375\n",
      "Train Epoch: 3 [22656/225000 (10%)] Loss: 21671.007812\n",
      "Train Epoch: 3 [25152/225000 (11%)] Loss: 21862.078125\n",
      "Train Epoch: 3 [27648/225000 (12%)] Loss: 21763.333984\n",
      "Train Epoch: 3 [30144/225000 (13%)] Loss: 21600.878906\n",
      "Train Epoch: 3 [32640/225000 (15%)] Loss: 21857.062500\n",
      "Train Epoch: 3 [35136/225000 (16%)] Loss: 22189.101562\n",
      "Train Epoch: 3 [37632/225000 (17%)] Loss: 21759.703125\n",
      "Train Epoch: 3 [40128/225000 (18%)] Loss: 21798.853516\n",
      "Train Epoch: 3 [42624/225000 (19%)] Loss: 21332.416016\n",
      "Train Epoch: 3 [45120/225000 (20%)] Loss: 21794.027344\n",
      "Train Epoch: 3 [47616/225000 (21%)] Loss: 21786.156250\n",
      "Train Epoch: 3 [50112/225000 (22%)] Loss: 21556.658203\n",
      "Train Epoch: 3 [52608/225000 (23%)] Loss: 21807.011719\n",
      "Train Epoch: 3 [55104/225000 (24%)] Loss: 21784.691406\n",
      "Train Epoch: 3 [57600/225000 (26%)] Loss: 21498.371094\n",
      "Train Epoch: 3 [60096/225000 (27%)] Loss: 21723.751953\n",
      "Train Epoch: 3 [62592/225000 (28%)] Loss: 21452.789062\n",
      "Train Epoch: 3 [65088/225000 (29%)] Loss: 21858.105469\n",
      "Train Epoch: 3 [67584/225000 (30%)] Loss: 21724.121094\n",
      "Train Epoch: 3 [70080/225000 (31%)] Loss: 21941.580078\n",
      "Train Epoch: 3 [72576/225000 (32%)] Loss: 21085.476562\n",
      "Train Epoch: 3 [75072/225000 (33%)] Loss: 21469.884766\n",
      "Train Epoch: 3 [77568/225000 (34%)] Loss: 21471.382812\n",
      "Train Epoch: 3 [80064/225000 (36%)] Loss: 21571.917969\n",
      "Train Epoch: 3 [82560/225000 (37%)] Loss: 21218.039062\n",
      "Train Epoch: 3 [85056/225000 (38%)] Loss: 21863.505859\n",
      "Train Epoch: 3 [87552/225000 (39%)] Loss: 21343.619141\n",
      "Train Epoch: 3 [90048/225000 (40%)] Loss: 21144.531250\n",
      "Train Epoch: 3 [92544/225000 (41%)] Loss: 21173.476562\n",
      "Train Epoch: 3 [95040/225000 (42%)] Loss: 21199.580078\n",
      "Train Epoch: 3 [97536/225000 (43%)] Loss: 21543.019531\n",
      "Train Epoch: 3 [100032/225000 (44%)] Loss: 21963.021484\n",
      "Train Epoch: 3 [102528/225000 (46%)] Loss: 21568.355469\n",
      "Train Epoch: 3 [105024/225000 (47%)] Loss: 21153.132812\n",
      "Train Epoch: 3 [107520/225000 (48%)] Loss: 21543.074219\n",
      "Train Epoch: 3 [110016/225000 (49%)] Loss: 21243.753906\n",
      "Train Epoch: 3 [112512/225000 (50%)] Loss: 21320.238281\n",
      "Train Epoch: 3 [115008/225000 (51%)] Loss: 21424.714844\n",
      "Train Epoch: 3 [117504/225000 (52%)] Loss: 21387.595703\n",
      "Train Epoch: 3 [120000/225000 (53%)] Loss: 21917.152344\n",
      "Train Epoch: 3 [122496/225000 (54%)] Loss: 21583.384766\n",
      "Train Epoch: 3 [124992/225000 (56%)] Loss: 21654.390625\n",
      "Train Epoch: 3 [127488/225000 (57%)] Loss: 21452.041016\n",
      "Train Epoch: 3 [129984/225000 (58%)] Loss: 21077.566406\n",
      "Train Epoch: 3 [132480/225000 (59%)] Loss: 21733.539062\n",
      "Train Epoch: 3 [134976/225000 (60%)] Loss: 21235.265625\n",
      "Train Epoch: 3 [137472/225000 (61%)] Loss: 21571.226562\n",
      "Train Epoch: 3 [139968/225000 (62%)] Loss: 21834.082031\n",
      "Train Epoch: 3 [142464/225000 (63%)] Loss: 21870.246094\n",
      "Train Epoch: 3 [144960/225000 (64%)] Loss: 21453.074219\n",
      "Train Epoch: 3 [147456/225000 (66%)] Loss: 21120.503906\n",
      "Train Epoch: 3 [149952/225000 (67%)] Loss: 21385.750000\n",
      "Train Epoch: 3 [152448/225000 (68%)] Loss: 21714.769531\n",
      "Train Epoch: 3 [154944/225000 (69%)] Loss: 21625.054688\n",
      "Train Epoch: 3 [157440/225000 (70%)] Loss: 21457.183594\n",
      "Train Epoch: 3 [159936/225000 (71%)] Loss: 21255.210938\n",
      "Train Epoch: 3 [162432/225000 (72%)] Loss: 20872.068359\n",
      "Train Epoch: 3 [164928/225000 (73%)] Loss: 21519.781250\n",
      "Train Epoch: 3 [167424/225000 (74%)] Loss: 21500.412109\n",
      "Train Epoch: 3 [169920/225000 (76%)] Loss: 21665.316406\n",
      "Train Epoch: 3 [172416/225000 (77%)] Loss: 21649.134766\n",
      "Train Epoch: 3 [174912/225000 (78%)] Loss: 21167.015625\n",
      "Train Epoch: 3 [177408/225000 (79%)] Loss: 21467.964844\n",
      "Train Epoch: 3 [179904/225000 (80%)] Loss: 21228.976562\n",
      "Train Epoch: 3 [182400/225000 (81%)] Loss: 21557.500000\n",
      "Train Epoch: 3 [184896/225000 (82%)] Loss: 21272.429688\n",
      "Train Epoch: 3 [187392/225000 (83%)] Loss: 21652.716797\n",
      "Train Epoch: 3 [189888/225000 (84%)] Loss: 21751.611328\n",
      "Train Epoch: 3 [192384/225000 (86%)] Loss: 21431.523438\n",
      "Train Epoch: 3 [194880/225000 (87%)] Loss: 21313.664062\n",
      "Train Epoch: 3 [197376/225000 (88%)] Loss: 21455.800781\n",
      "Train Epoch: 3 [199872/225000 (89%)] Loss: 20771.599609\n",
      "Train Epoch: 3 [202368/225000 (90%)] Loss: 22014.203125\n",
      "Train Epoch: 3 [204864/225000 (91%)] Loss: 20752.367188\n",
      "Train Epoch: 3 [207360/225000 (92%)] Loss: 21558.232422\n",
      "Train Epoch: 3 [209856/225000 (93%)] Loss: 21547.902344\n",
      "Train Epoch: 3 [212352/225000 (94%)] Loss: 21347.660156\n",
      "Train Epoch: 3 [214848/225000 (95%)] Loss: 21018.519531\n",
      "Train Epoch: 3 [217344/225000 (97%)] Loss: 21108.242188\n",
      "Train Epoch: 3 [219840/225000 (98%)] Loss: 20943.222656\n",
      "Train Epoch: 3 [222336/225000 (99%)] Loss: 20805.007812\n",
      "Train Epoch: 3 [224832/225000 (100%)] Loss: 21433.216797\n",
      "    epoch          : 3\n",
      "    loss           : 21558.244393931313\n",
      "    val_loss       : 21382.67244413791\n",
      "Train Epoch: 4 [192/225000 (0%)] Loss: 21353.726562\n",
      "Train Epoch: 4 [2688/225000 (1%)] Loss: 21347.148438\n",
      "Train Epoch: 4 [5184/225000 (2%)] Loss: 21578.308594\n",
      "Train Epoch: 4 [7680/225000 (3%)] Loss: 21424.664062\n",
      "Train Epoch: 4 [10176/225000 (5%)] Loss: 21118.910156\n",
      "Train Epoch: 4 [12672/225000 (6%)] Loss: 21247.863281\n",
      "Train Epoch: 4 [15168/225000 (7%)] Loss: 21494.205078\n",
      "Train Epoch: 4 [17664/225000 (8%)] Loss: 21449.765625\n",
      "Train Epoch: 4 [20160/225000 (9%)] Loss: 21336.460938\n",
      "Train Epoch: 4 [22656/225000 (10%)] Loss: 21342.763672\n",
      "Train Epoch: 4 [25152/225000 (11%)] Loss: 21446.535156\n",
      "Train Epoch: 4 [27648/225000 (12%)] Loss: 21682.056641\n",
      "Train Epoch: 4 [30144/225000 (13%)] Loss: 20915.023438\n",
      "Train Epoch: 4 [32640/225000 (15%)] Loss: 20729.000000\n",
      "Train Epoch: 4 [35136/225000 (16%)] Loss: 21471.394531\n",
      "Train Epoch: 4 [37632/225000 (17%)] Loss: 21532.960938\n",
      "Train Epoch: 4 [40128/225000 (18%)] Loss: 21184.509766\n",
      "Train Epoch: 4 [42624/225000 (19%)] Loss: 21077.863281\n",
      "Train Epoch: 4 [45120/225000 (20%)] Loss: 21452.257812\n",
      "Train Epoch: 4 [47616/225000 (21%)] Loss: 21076.492188\n",
      "Train Epoch: 4 [50112/225000 (22%)] Loss: 21398.640625\n",
      "Train Epoch: 4 [52608/225000 (23%)] Loss: 21202.468750\n",
      "Train Epoch: 4 [55104/225000 (24%)] Loss: 20544.925781\n",
      "Train Epoch: 4 [57600/225000 (26%)] Loss: 21628.568359\n",
      "Train Epoch: 4 [60096/225000 (27%)] Loss: 21126.589844\n",
      "Train Epoch: 4 [62592/225000 (28%)] Loss: 21228.925781\n",
      "Train Epoch: 4 [65088/225000 (29%)] Loss: 21362.912109\n",
      "Train Epoch: 4 [67584/225000 (30%)] Loss: 21222.671875\n",
      "Train Epoch: 4 [70080/225000 (31%)] Loss: 21291.796875\n",
      "Train Epoch: 4 [72576/225000 (32%)] Loss: 20967.734375\n",
      "Train Epoch: 4 [75072/225000 (33%)] Loss: 21832.296875\n",
      "Train Epoch: 4 [77568/225000 (34%)] Loss: 21011.007812\n",
      "Train Epoch: 4 [80064/225000 (36%)] Loss: 21059.617188\n",
      "Train Epoch: 4 [82560/225000 (37%)] Loss: 21376.638672\n",
      "Train Epoch: 4 [85056/225000 (38%)] Loss: 21931.917969\n",
      "Train Epoch: 4 [87552/225000 (39%)] Loss: 21223.943359\n",
      "Train Epoch: 4 [90048/225000 (40%)] Loss: 21111.812500\n",
      "Train Epoch: 4 [92544/225000 (41%)] Loss: 21641.546875\n",
      "Train Epoch: 4 [95040/225000 (42%)] Loss: 21383.011719\n",
      "Train Epoch: 4 [97536/225000 (43%)] Loss: 20735.371094\n",
      "Train Epoch: 4 [100032/225000 (44%)] Loss: 20937.728516\n",
      "Train Epoch: 4 [102528/225000 (46%)] Loss: 21324.207031\n",
      "Train Epoch: 4 [105024/225000 (47%)] Loss: 20575.242188\n",
      "Train Epoch: 4 [107520/225000 (48%)] Loss: 21081.183594\n",
      "Train Epoch: 4 [110016/225000 (49%)] Loss: 21226.855469\n",
      "Train Epoch: 4 [112512/225000 (50%)] Loss: 21420.025391\n",
      "Train Epoch: 4 [115008/225000 (51%)] Loss: 21084.496094\n",
      "Train Epoch: 4 [117504/225000 (52%)] Loss: 21157.763672\n",
      "Train Epoch: 4 [120000/225000 (53%)] Loss: 21262.980469\n",
      "Train Epoch: 4 [122496/225000 (54%)] Loss: 21428.214844\n",
      "Train Epoch: 4 [124992/225000 (56%)] Loss: 21364.531250\n",
      "Train Epoch: 4 [127488/225000 (57%)] Loss: 20997.656250\n",
      "Train Epoch: 4 [129984/225000 (58%)] Loss: 21470.615234\n",
      "Train Epoch: 4 [132480/225000 (59%)] Loss: 21428.263672\n",
      "Train Epoch: 4 [134976/225000 (60%)] Loss: 21947.796875\n",
      "Train Epoch: 4 [137472/225000 (61%)] Loss: 21009.492188\n",
      "Train Epoch: 4 [139968/225000 (62%)] Loss: 21043.275391\n",
      "Train Epoch: 4 [142464/225000 (63%)] Loss: 20668.621094\n",
      "Train Epoch: 4 [144960/225000 (64%)] Loss: 21427.078125\n",
      "Train Epoch: 4 [147456/225000 (66%)] Loss: 21003.443359\n",
      "Train Epoch: 4 [149952/225000 (67%)] Loss: 21141.687500\n",
      "Train Epoch: 4 [152448/225000 (68%)] Loss: 21222.332031\n",
      "Train Epoch: 4 [154944/225000 (69%)] Loss: 20991.068359\n",
      "Train Epoch: 4 [157440/225000 (70%)] Loss: 21288.017578\n",
      "Train Epoch: 4 [159936/225000 (71%)] Loss: 21248.339844\n",
      "Train Epoch: 4 [162432/225000 (72%)] Loss: 21424.007812\n",
      "Train Epoch: 4 [164928/225000 (73%)] Loss: 21162.392578\n",
      "Train Epoch: 4 [167424/225000 (74%)] Loss: 20838.437500\n",
      "Train Epoch: 4 [169920/225000 (76%)] Loss: 20786.910156\n",
      "Train Epoch: 4 [172416/225000 (77%)] Loss: 21268.890625\n",
      "Train Epoch: 4 [174912/225000 (78%)] Loss: 21066.937500\n",
      "Train Epoch: 4 [177408/225000 (79%)] Loss: 20698.464844\n",
      "Train Epoch: 4 [179904/225000 (80%)] Loss: 21143.425781\n",
      "Train Epoch: 4 [182400/225000 (81%)] Loss: 21136.617188\n",
      "Train Epoch: 4 [184896/225000 (82%)] Loss: 21346.355469\n",
      "Train Epoch: 4 [187392/225000 (83%)] Loss: 21073.146484\n",
      "Train Epoch: 4 [189888/225000 (84%)] Loss: 20746.304688\n",
      "Train Epoch: 4 [192384/225000 (86%)] Loss: 21057.173828\n",
      "Train Epoch: 4 [194880/225000 (87%)] Loss: 21375.371094\n",
      "Train Epoch: 4 [197376/225000 (88%)] Loss: 20716.574219\n",
      "Train Epoch: 4 [199872/225000 (89%)] Loss: 21784.060547\n",
      "Train Epoch: 4 [202368/225000 (90%)] Loss: 21184.228516\n",
      "Train Epoch: 4 [204864/225000 (91%)] Loss: 20781.949219\n",
      "Train Epoch: 4 [207360/225000 (92%)] Loss: 20878.066406\n",
      "Train Epoch: 4 [209856/225000 (93%)] Loss: 20769.806641\n",
      "Train Epoch: 4 [212352/225000 (94%)] Loss: 20803.699219\n",
      "Train Epoch: 4 [214848/225000 (95%)] Loss: 21051.285156\n",
      "Train Epoch: 4 [217344/225000 (97%)] Loss: 21563.984375\n",
      "Train Epoch: 4 [219840/225000 (98%)] Loss: 20774.707031\n",
      "Train Epoch: 4 [222336/225000 (99%)] Loss: 21097.636719\n",
      "Train Epoch: 4 [224832/225000 (100%)] Loss: 21148.675781\n",
      "    epoch          : 4\n",
      "    loss           : 21281.185568539357\n",
      "    val_loss       : 21153.943108900814\n",
      "Train Epoch: 5 [192/225000 (0%)] Loss: 21194.761719\n",
      "Train Epoch: 5 [2688/225000 (1%)] Loss: 21613.318359\n",
      "Train Epoch: 5 [5184/225000 (2%)] Loss: 21585.058594\n",
      "Train Epoch: 5 [7680/225000 (3%)] Loss: 21403.613281\n",
      "Train Epoch: 5 [10176/225000 (5%)] Loss: 21526.765625\n",
      "Train Epoch: 5 [12672/225000 (6%)] Loss: 20967.283203\n",
      "Train Epoch: 5 [15168/225000 (7%)] Loss: 21662.302734\n",
      "Train Epoch: 5 [17664/225000 (8%)] Loss: 21268.605469\n",
      "Train Epoch: 5 [20160/225000 (9%)] Loss: 20828.652344\n",
      "Train Epoch: 5 [22656/225000 (10%)] Loss: 21182.837891\n",
      "Train Epoch: 5 [25152/225000 (11%)] Loss: 20473.898438\n",
      "Train Epoch: 5 [27648/225000 (12%)] Loss: 22156.757812\n",
      "Train Epoch: 5 [30144/225000 (13%)] Loss: 21247.675781\n",
      "Train Epoch: 5 [32640/225000 (15%)] Loss: 20833.996094\n",
      "Train Epoch: 5 [35136/225000 (16%)] Loss: 21617.187500\n",
      "Train Epoch: 5 [37632/225000 (17%)] Loss: 21289.062500\n",
      "Train Epoch: 5 [40128/225000 (18%)] Loss: 21051.316406\n",
      "Train Epoch: 5 [42624/225000 (19%)] Loss: 20792.046875\n",
      "Train Epoch: 5 [45120/225000 (20%)] Loss: 20749.839844\n",
      "Train Epoch: 5 [47616/225000 (21%)] Loss: 20765.605469\n",
      "Train Epoch: 5 [50112/225000 (22%)] Loss: 21022.914062\n",
      "Train Epoch: 5 [52608/225000 (23%)] Loss: 21234.292969\n",
      "Train Epoch: 5 [55104/225000 (24%)] Loss: 21119.787109\n",
      "Train Epoch: 5 [57600/225000 (26%)] Loss: 21322.515625\n",
      "Train Epoch: 5 [60096/225000 (27%)] Loss: 21171.408203\n",
      "Train Epoch: 5 [62592/225000 (28%)] Loss: 21115.023438\n",
      "Train Epoch: 5 [65088/225000 (29%)] Loss: 21084.775391\n",
      "Train Epoch: 5 [67584/225000 (30%)] Loss: 21219.167969\n",
      "Train Epoch: 5 [70080/225000 (31%)] Loss: 20713.537109\n",
      "Train Epoch: 5 [72576/225000 (32%)] Loss: 20514.558594\n",
      "Train Epoch: 5 [75072/225000 (33%)] Loss: 20932.941406\n",
      "Train Epoch: 5 [77568/225000 (34%)] Loss: 21635.947266\n",
      "Train Epoch: 5 [80064/225000 (36%)] Loss: 20956.890625\n",
      "Train Epoch: 5 [82560/225000 (37%)] Loss: 21278.328125\n",
      "Train Epoch: 5 [85056/225000 (38%)] Loss: 20867.531250\n",
      "Train Epoch: 5 [87552/225000 (39%)] Loss: 20950.667969\n",
      "Train Epoch: 5 [90048/225000 (40%)] Loss: 21169.703125\n",
      "Train Epoch: 5 [92544/225000 (41%)] Loss: 20769.636719\n",
      "Train Epoch: 5 [95040/225000 (42%)] Loss: 20674.742188\n",
      "Train Epoch: 5 [97536/225000 (43%)] Loss: 20756.044922\n",
      "Train Epoch: 5 [100032/225000 (44%)] Loss: 21413.292969\n",
      "Train Epoch: 5 [102528/225000 (46%)] Loss: 20748.347656\n",
      "Train Epoch: 5 [105024/225000 (47%)] Loss: 21078.248047\n",
      "Train Epoch: 5 [107520/225000 (48%)] Loss: 20679.423828\n",
      "Train Epoch: 5 [110016/225000 (49%)] Loss: 20893.488281\n",
      "Train Epoch: 5 [112512/225000 (50%)] Loss: 21272.486328\n",
      "Train Epoch: 5 [115008/225000 (51%)] Loss: 20606.148438\n",
      "Train Epoch: 5 [117504/225000 (52%)] Loss: 20856.136719\n",
      "Train Epoch: 5 [120000/225000 (53%)] Loss: 21207.451172\n",
      "Train Epoch: 5 [122496/225000 (54%)] Loss: 21374.097656\n",
      "Train Epoch: 5 [124992/225000 (56%)] Loss: 21256.664062\n",
      "Train Epoch: 5 [127488/225000 (57%)] Loss: 21332.195312\n",
      "Train Epoch: 5 [129984/225000 (58%)] Loss: 20774.628906\n",
      "Train Epoch: 5 [132480/225000 (59%)] Loss: 20814.578125\n",
      "Train Epoch: 5 [134976/225000 (60%)] Loss: 20737.539062\n",
      "Train Epoch: 5 [137472/225000 (61%)] Loss: 21372.109375\n",
      "Train Epoch: 5 [139968/225000 (62%)] Loss: 20536.716797\n",
      "Train Epoch: 5 [142464/225000 (63%)] Loss: 21531.630859\n",
      "Train Epoch: 5 [144960/225000 (64%)] Loss: 21194.617188\n",
      "Train Epoch: 5 [147456/225000 (66%)] Loss: 21171.367188\n",
      "Train Epoch: 5 [149952/225000 (67%)] Loss: 21620.375000\n",
      "Train Epoch: 5 [152448/225000 (68%)] Loss: 20988.322266\n",
      "Train Epoch: 5 [154944/225000 (69%)] Loss: 21559.830078\n",
      "Train Epoch: 5 [157440/225000 (70%)] Loss: 21041.644531\n",
      "Train Epoch: 5 [159936/225000 (71%)] Loss: 20685.097656\n",
      "Train Epoch: 5 [162432/225000 (72%)] Loss: 20993.794922\n",
      "Train Epoch: 5 [164928/225000 (73%)] Loss: 20924.265625\n",
      "Train Epoch: 5 [167424/225000 (74%)] Loss: 20915.097656\n",
      "Train Epoch: 5 [169920/225000 (76%)] Loss: 20281.191406\n",
      "Train Epoch: 5 [172416/225000 (77%)] Loss: 20685.558594\n",
      "Train Epoch: 5 [174912/225000 (78%)] Loss: 20454.576172\n",
      "Train Epoch: 5 [177408/225000 (79%)] Loss: 21128.109375\n",
      "Train Epoch: 5 [179904/225000 (80%)] Loss: 21259.699219\n",
      "Train Epoch: 5 [182400/225000 (81%)] Loss: 20756.500000\n",
      "Train Epoch: 5 [184896/225000 (82%)] Loss: 20862.730469\n",
      "Train Epoch: 5 [187392/225000 (83%)] Loss: 21159.570312\n",
      "Train Epoch: 5 [189888/225000 (84%)] Loss: 21227.441406\n",
      "Train Epoch: 5 [192384/225000 (86%)] Loss: 21293.484375\n",
      "Train Epoch: 5 [194880/225000 (87%)] Loss: 21412.052734\n",
      "Train Epoch: 5 [197376/225000 (88%)] Loss: 20930.750000\n",
      "Train Epoch: 5 [199872/225000 (89%)] Loss: 21105.812500\n",
      "Train Epoch: 5 [202368/225000 (90%)] Loss: 21878.218750\n",
      "Train Epoch: 5 [204864/225000 (91%)] Loss: 20753.535156\n",
      "Train Epoch: 5 [207360/225000 (92%)] Loss: 20539.621094\n",
      "Train Epoch: 5 [209856/225000 (93%)] Loss: 20880.289062\n",
      "Train Epoch: 5 [212352/225000 (94%)] Loss: 21516.550781\n",
      "Train Epoch: 5 [214848/225000 (95%)] Loss: 20976.626953\n",
      "Train Epoch: 5 [217344/225000 (97%)] Loss: 21247.488281\n",
      "Train Epoch: 5 [219840/225000 (98%)] Loss: 20806.365234\n",
      "Train Epoch: 5 [222336/225000 (99%)] Loss: 21305.312500\n",
      "Train Epoch: 5 [224832/225000 (100%)] Loss: 21058.996094\n",
      "    epoch          : 5\n",
      "    loss           : 21137.57281223336\n",
      "    val_loss       : 21053.74821007684\n",
      "Train Epoch: 6 [192/225000 (0%)] Loss: 21157.169922\n",
      "Train Epoch: 6 [2688/225000 (1%)] Loss: 20789.597656\n",
      "Train Epoch: 6 [5184/225000 (2%)] Loss: 21555.066406\n",
      "Train Epoch: 6 [7680/225000 (3%)] Loss: 21147.013672\n",
      "Train Epoch: 6 [10176/225000 (5%)] Loss: 21237.269531\n",
      "Train Epoch: 6 [12672/225000 (6%)] Loss: 21116.945312\n",
      "Train Epoch: 6 [15168/225000 (7%)] Loss: 21102.355469\n",
      "Train Epoch: 6 [17664/225000 (8%)] Loss: 21175.769531\n",
      "Train Epoch: 6 [20160/225000 (9%)] Loss: 20478.710938\n",
      "Train Epoch: 6 [22656/225000 (10%)] Loss: 20840.015625\n",
      "Train Epoch: 6 [25152/225000 (11%)] Loss: 20962.335938\n",
      "Train Epoch: 6 [27648/225000 (12%)] Loss: 21017.675781\n",
      "Train Epoch: 6 [30144/225000 (13%)] Loss: 20777.707031\n",
      "Train Epoch: 6 [32640/225000 (15%)] Loss: 20455.851562\n",
      "Train Epoch: 6 [35136/225000 (16%)] Loss: 20912.990234\n",
      "Train Epoch: 6 [37632/225000 (17%)] Loss: 21831.042969\n",
      "Train Epoch: 6 [40128/225000 (18%)] Loss: 20973.847656\n",
      "Train Epoch: 6 [42624/225000 (19%)] Loss: 21202.841797\n",
      "Train Epoch: 6 [45120/225000 (20%)] Loss: 20888.865234\n",
      "Train Epoch: 6 [47616/225000 (21%)] Loss: 21218.109375\n",
      "Train Epoch: 6 [50112/225000 (22%)] Loss: 20766.544922\n",
      "Train Epoch: 6 [52608/225000 (23%)] Loss: 21439.457031\n",
      "Train Epoch: 6 [55104/225000 (24%)] Loss: 21068.218750\n",
      "Train Epoch: 6 [57600/225000 (26%)] Loss: 21326.148438\n",
      "Train Epoch: 6 [60096/225000 (27%)] Loss: 21098.273438\n",
      "Train Epoch: 6 [62592/225000 (28%)] Loss: 20484.230469\n",
      "Train Epoch: 6 [65088/225000 (29%)] Loss: 21419.781250\n",
      "Train Epoch: 6 [67584/225000 (30%)] Loss: 20819.703125\n",
      "Train Epoch: 6 [70080/225000 (31%)] Loss: 21986.095703\n",
      "Train Epoch: 6 [72576/225000 (32%)] Loss: 20976.437500\n",
      "Train Epoch: 6 [75072/225000 (33%)] Loss: 20456.296875\n",
      "Train Epoch: 6 [77568/225000 (34%)] Loss: 21103.398438\n",
      "Train Epoch: 6 [80064/225000 (36%)] Loss: 21618.367188\n",
      "Train Epoch: 6 [82560/225000 (37%)] Loss: 20786.429688\n",
      "Train Epoch: 6 [85056/225000 (38%)] Loss: 21248.187500\n",
      "Train Epoch: 6 [87552/225000 (39%)] Loss: 20938.560547\n",
      "Train Epoch: 6 [90048/225000 (40%)] Loss: 20921.894531\n",
      "Train Epoch: 6 [92544/225000 (41%)] Loss: 21078.958984\n",
      "Train Epoch: 6 [95040/225000 (42%)] Loss: 20833.949219\n",
      "Train Epoch: 6 [97536/225000 (43%)] Loss: 20874.355469\n",
      "Train Epoch: 6 [100032/225000 (44%)] Loss: 21028.699219\n",
      "Train Epoch: 6 [102528/225000 (46%)] Loss: 21352.583984\n",
      "Train Epoch: 6 [105024/225000 (47%)] Loss: 20527.867188\n",
      "Train Epoch: 6 [107520/225000 (48%)] Loss: 20819.960938\n",
      "Train Epoch: 6 [110016/225000 (49%)] Loss: 20769.167969\n",
      "Train Epoch: 6 [112512/225000 (50%)] Loss: 20907.275391\n",
      "Train Epoch: 6 [115008/225000 (51%)] Loss: 20754.375000\n",
      "Train Epoch: 6 [117504/225000 (52%)] Loss: 20894.314453\n",
      "Train Epoch: 6 [120000/225000 (53%)] Loss: 21205.855469\n",
      "Train Epoch: 6 [122496/225000 (54%)] Loss: 20883.591797\n",
      "Train Epoch: 6 [124992/225000 (56%)] Loss: 21356.386719\n",
      "Train Epoch: 6 [127488/225000 (57%)] Loss: 20817.464844\n",
      "Train Epoch: 6 [129984/225000 (58%)] Loss: 20971.339844\n",
      "Train Epoch: 6 [132480/225000 (59%)] Loss: 20605.882812\n",
      "Train Epoch: 6 [134976/225000 (60%)] Loss: 21637.466797\n",
      "Train Epoch: 6 [137472/225000 (61%)] Loss: 20778.480469\n",
      "Train Epoch: 6 [139968/225000 (62%)] Loss: 21061.556641\n",
      "Train Epoch: 6 [142464/225000 (63%)] Loss: 21249.523438\n",
      "Train Epoch: 6 [144960/225000 (64%)] Loss: 20940.820312\n",
      "Train Epoch: 6 [147456/225000 (66%)] Loss: 20754.001953\n",
      "Train Epoch: 6 [149952/225000 (67%)] Loss: 20801.908203\n",
      "Train Epoch: 6 [152448/225000 (68%)] Loss: 20687.867188\n",
      "Train Epoch: 6 [154944/225000 (69%)] Loss: 21218.611328\n",
      "Train Epoch: 6 [157440/225000 (70%)] Loss: 21130.648438\n",
      "Train Epoch: 6 [159936/225000 (71%)] Loss: 20719.140625\n",
      "Train Epoch: 6 [162432/225000 (72%)] Loss: 20667.320312\n",
      "Train Epoch: 6 [164928/225000 (73%)] Loss: 20849.191406\n",
      "Train Epoch: 6 [167424/225000 (74%)] Loss: 21215.386719\n",
      "Train Epoch: 6 [169920/225000 (76%)] Loss: 20626.378906\n",
      "Train Epoch: 6 [172416/225000 (77%)] Loss: 21782.765625\n",
      "Train Epoch: 6 [174912/225000 (78%)] Loss: 20928.250000\n",
      "Train Epoch: 6 [177408/225000 (79%)] Loss: 21104.933594\n",
      "Train Epoch: 6 [179904/225000 (80%)] Loss: 20660.007812\n",
      "Train Epoch: 6 [182400/225000 (81%)] Loss: 20301.031250\n",
      "Train Epoch: 6 [184896/225000 (82%)] Loss: 20635.847656\n",
      "Train Epoch: 6 [187392/225000 (83%)] Loss: 20557.984375\n",
      "Train Epoch: 6 [189888/225000 (84%)] Loss: 20746.148438\n",
      "Train Epoch: 6 [192384/225000 (86%)] Loss: 20943.531250\n",
      "Train Epoch: 6 [194880/225000 (87%)] Loss: 21056.470703\n",
      "Train Epoch: 6 [197376/225000 (88%)] Loss: 21412.636719\n",
      "Train Epoch: 6 [199872/225000 (89%)] Loss: 21073.015625\n",
      "Train Epoch: 6 [202368/225000 (90%)] Loss: 20767.810547\n",
      "Train Epoch: 6 [204864/225000 (91%)] Loss: 20698.390625\n",
      "Train Epoch: 6 [207360/225000 (92%)] Loss: 21251.339844\n",
      "Train Epoch: 6 [209856/225000 (93%)] Loss: 20346.000000\n",
      "Train Epoch: 6 [212352/225000 (94%)] Loss: 20808.773438\n",
      "Train Epoch: 6 [214848/225000 (95%)] Loss: 20874.593750\n",
      "Train Epoch: 6 [217344/225000 (97%)] Loss: 20779.367188\n",
      "Train Epoch: 6 [219840/225000 (98%)] Loss: 20666.439453\n",
      "Train Epoch: 6 [222336/225000 (99%)] Loss: 21261.496094\n",
      "Train Epoch: 6 [224832/225000 (100%)] Loss: 20933.398438\n",
      "    epoch          : 6\n",
      "    loss           : 21010.087454004904\n",
      "    val_loss       : 20869.71012652193\n",
      "Train Epoch: 7 [192/225000 (0%)] Loss: 21101.720703\n",
      "Train Epoch: 7 [2688/225000 (1%)] Loss: 21177.531250\n",
      "Train Epoch: 7 [5184/225000 (2%)] Loss: 21111.824219\n",
      "Train Epoch: 7 [7680/225000 (3%)] Loss: 21196.683594\n",
      "Train Epoch: 7 [10176/225000 (5%)] Loss: 21387.617188\n",
      "Train Epoch: 7 [12672/225000 (6%)] Loss: 20545.417969\n",
      "Train Epoch: 7 [15168/225000 (7%)] Loss: 20699.429688\n",
      "Train Epoch: 7 [17664/225000 (8%)] Loss: 20976.587891\n",
      "Train Epoch: 7 [20160/225000 (9%)] Loss: 21080.892578\n",
      "Train Epoch: 7 [22656/225000 (10%)] Loss: 21374.820312\n",
      "Train Epoch: 7 [25152/225000 (11%)] Loss: 20874.605469\n",
      "Train Epoch: 7 [27648/225000 (12%)] Loss: 21275.662109\n",
      "Train Epoch: 7 [30144/225000 (13%)] Loss: 20232.791016\n",
      "Train Epoch: 7 [32640/225000 (15%)] Loss: 20674.132812\n",
      "Train Epoch: 7 [35136/225000 (16%)] Loss: 21130.455078\n",
      "Train Epoch: 7 [37632/225000 (17%)] Loss: 20781.125000\n",
      "Train Epoch: 7 [40128/225000 (18%)] Loss: 20502.595703\n",
      "Train Epoch: 7 [42624/225000 (19%)] Loss: 20948.810547\n",
      "Train Epoch: 7 [45120/225000 (20%)] Loss: 20858.085938\n",
      "Train Epoch: 7 [47616/225000 (21%)] Loss: 20746.449219\n",
      "Train Epoch: 7 [50112/225000 (22%)] Loss: 21083.675781\n",
      "Train Epoch: 7 [52608/225000 (23%)] Loss: 20874.931641\n",
      "Train Epoch: 7 [55104/225000 (24%)] Loss: 21234.644531\n",
      "Train Epoch: 7 [57600/225000 (26%)] Loss: 21636.566406\n",
      "Train Epoch: 7 [60096/225000 (27%)] Loss: 21024.560547\n",
      "Train Epoch: 7 [62592/225000 (28%)] Loss: 20658.449219\n",
      "Train Epoch: 7 [65088/225000 (29%)] Loss: 21212.617188\n",
      "Train Epoch: 7 [67584/225000 (30%)] Loss: 20763.341797\n",
      "Train Epoch: 7 [70080/225000 (31%)] Loss: 20926.173828\n",
      "Train Epoch: 7 [72576/225000 (32%)] Loss: 20459.660156\n",
      "Train Epoch: 7 [75072/225000 (33%)] Loss: 20843.283203\n",
      "Train Epoch: 7 [77568/225000 (34%)] Loss: 20629.785156\n",
      "Train Epoch: 7 [80064/225000 (36%)] Loss: 21070.949219\n",
      "Train Epoch: 7 [82560/225000 (37%)] Loss: 20733.517578\n",
      "Train Epoch: 7 [85056/225000 (38%)] Loss: 20984.625000\n",
      "Train Epoch: 7 [87552/225000 (39%)] Loss: 20824.193359\n",
      "Train Epoch: 7 [90048/225000 (40%)] Loss: 20556.550781\n",
      "Train Epoch: 7 [92544/225000 (41%)] Loss: 20737.269531\n",
      "Train Epoch: 7 [95040/225000 (42%)] Loss: 20752.640625\n",
      "Train Epoch: 7 [97536/225000 (43%)] Loss: 20911.816406\n",
      "Train Epoch: 7 [100032/225000 (44%)] Loss: 20854.214844\n",
      "Train Epoch: 7 [102528/225000 (46%)] Loss: 20838.312500\n",
      "Train Epoch: 7 [105024/225000 (47%)] Loss: 20754.246094\n",
      "Train Epoch: 7 [107520/225000 (48%)] Loss: 20977.720703\n",
      "Train Epoch: 7 [110016/225000 (49%)] Loss: 20652.007812\n",
      "Train Epoch: 7 [112512/225000 (50%)] Loss: 20805.992188\n",
      "Train Epoch: 7 [115008/225000 (51%)] Loss: 20511.900391\n",
      "Train Epoch: 7 [117504/225000 (52%)] Loss: 20545.261719\n",
      "Train Epoch: 7 [120000/225000 (53%)] Loss: 21000.738281\n",
      "Train Epoch: 7 [122496/225000 (54%)] Loss: 20831.402344\n",
      "Train Epoch: 7 [124992/225000 (56%)] Loss: 20640.460938\n",
      "Train Epoch: 7 [127488/225000 (57%)] Loss: 21379.404297\n",
      "Train Epoch: 7 [129984/225000 (58%)] Loss: 20801.824219\n",
      "Train Epoch: 7 [132480/225000 (59%)] Loss: 20408.796875\n",
      "Train Epoch: 7 [134976/225000 (60%)] Loss: 21213.285156\n",
      "Train Epoch: 7 [137472/225000 (61%)] Loss: 21052.716797\n",
      "Train Epoch: 7 [139968/225000 (62%)] Loss: 21157.867188\n",
      "Train Epoch: 7 [142464/225000 (63%)] Loss: 20313.867188\n",
      "Train Epoch: 7 [144960/225000 (64%)] Loss: 20765.558594\n",
      "Train Epoch: 7 [147456/225000 (66%)] Loss: 20967.984375\n",
      "Train Epoch: 7 [149952/225000 (67%)] Loss: 21460.421875\n",
      "Train Epoch: 7 [152448/225000 (68%)] Loss: 21432.533203\n",
      "Train Epoch: 7 [154944/225000 (69%)] Loss: 20961.734375\n",
      "Train Epoch: 7 [157440/225000 (70%)] Loss: 20417.429688\n",
      "Train Epoch: 7 [159936/225000 (71%)] Loss: 20869.126953\n",
      "Train Epoch: 7 [162432/225000 (72%)] Loss: 20728.542969\n",
      "Train Epoch: 7 [164928/225000 (73%)] Loss: 21202.320312\n",
      "Train Epoch: 7 [167424/225000 (74%)] Loss: 20902.640625\n",
      "Train Epoch: 7 [169920/225000 (76%)] Loss: 20596.484375\n",
      "Train Epoch: 7 [172416/225000 (77%)] Loss: 20512.453125\n",
      "Train Epoch: 7 [174912/225000 (78%)] Loss: 21713.125000\n",
      "Train Epoch: 7 [177408/225000 (79%)] Loss: 20512.357422\n",
      "Train Epoch: 7 [179904/225000 (80%)] Loss: 21359.378906\n",
      "Train Epoch: 7 [182400/225000 (81%)] Loss: 20950.509766\n",
      "Train Epoch: 7 [184896/225000 (82%)] Loss: 20951.847656\n",
      "Train Epoch: 7 [187392/225000 (83%)] Loss: 21104.548828\n",
      "Train Epoch: 7 [189888/225000 (84%)] Loss: 20841.332031\n",
      "Train Epoch: 7 [192384/225000 (86%)] Loss: 20527.097656\n",
      "Train Epoch: 7 [194880/225000 (87%)] Loss: 20832.392578\n",
      "Train Epoch: 7 [197376/225000 (88%)] Loss: 20638.568359\n",
      "Train Epoch: 7 [199872/225000 (89%)] Loss: 20891.023438\n",
      "Train Epoch: 7 [202368/225000 (90%)] Loss: 20936.724609\n",
      "Train Epoch: 7 [204864/225000 (91%)] Loss: 20755.328125\n",
      "Train Epoch: 7 [207360/225000 (92%)] Loss: 20842.720703\n",
      "Train Epoch: 7 [209856/225000 (93%)] Loss: 20582.962891\n",
      "Train Epoch: 7 [212352/225000 (94%)] Loss: 21107.216797\n",
      "Train Epoch: 7 [214848/225000 (95%)] Loss: 21123.246094\n",
      "Train Epoch: 7 [217344/225000 (97%)] Loss: 20502.164062\n",
      "Train Epoch: 7 [219840/225000 (98%)] Loss: 20525.785156\n",
      "Train Epoch: 7 [222336/225000 (99%)] Loss: 20934.253906\n",
      "Train Epoch: 7 [224832/225000 (100%)] Loss: 20792.203125\n",
      "    epoch          : 7\n",
      "    loss           : 20909.208757732507\n",
      "    val_loss       : 20762.819365686133\n",
      "Train Epoch: 8 [192/225000 (0%)] Loss: 21807.187500\n",
      "Train Epoch: 8 [2688/225000 (1%)] Loss: 20556.681641\n",
      "Train Epoch: 8 [5184/225000 (2%)] Loss: 20829.312500\n",
      "Train Epoch: 8 [7680/225000 (3%)] Loss: 20841.765625\n",
      "Train Epoch: 8 [10176/225000 (5%)] Loss: 20594.144531\n",
      "Train Epoch: 8 [12672/225000 (6%)] Loss: 21110.714844\n",
      "Train Epoch: 8 [15168/225000 (7%)] Loss: 21008.613281\n",
      "Train Epoch: 8 [17664/225000 (8%)] Loss: 20612.320312\n",
      "Train Epoch: 8 [20160/225000 (9%)] Loss: 20502.048828\n",
      "Train Epoch: 8 [22656/225000 (10%)] Loss: 20711.597656\n",
      "Train Epoch: 8 [25152/225000 (11%)] Loss: 20526.931641\n",
      "Train Epoch: 8 [27648/225000 (12%)] Loss: 20444.042969\n",
      "Train Epoch: 8 [30144/225000 (13%)] Loss: 20885.476562\n",
      "Train Epoch: 8 [32640/225000 (15%)] Loss: 21029.236328\n",
      "Train Epoch: 8 [35136/225000 (16%)] Loss: 20851.183594\n",
      "Train Epoch: 8 [37632/225000 (17%)] Loss: 21124.060547\n",
      "Train Epoch: 8 [40128/225000 (18%)] Loss: 21106.160156\n",
      "Train Epoch: 8 [42624/225000 (19%)] Loss: 20731.074219\n",
      "Train Epoch: 8 [45120/225000 (20%)] Loss: 20909.855469\n",
      "Train Epoch: 8 [47616/225000 (21%)] Loss: 21072.644531\n",
      "Train Epoch: 8 [50112/225000 (22%)] Loss: 20688.107422\n",
      "Train Epoch: 8 [52608/225000 (23%)] Loss: 21142.966797\n",
      "Train Epoch: 8 [55104/225000 (24%)] Loss: 20977.703125\n",
      "Train Epoch: 8 [57600/225000 (26%)] Loss: 21004.589844\n",
      "Train Epoch: 8 [60096/225000 (27%)] Loss: 21121.824219\n",
      "Train Epoch: 8 [62592/225000 (28%)] Loss: 20660.277344\n",
      "Train Epoch: 8 [65088/225000 (29%)] Loss: 20989.056641\n",
      "Train Epoch: 8 [67584/225000 (30%)] Loss: 20974.246094\n",
      "Train Epoch: 8 [70080/225000 (31%)] Loss: 21282.791016\n",
      "Train Epoch: 8 [72576/225000 (32%)] Loss: 20828.210938\n",
      "Train Epoch: 8 [75072/225000 (33%)] Loss: 20624.960938\n",
      "Train Epoch: 8 [77568/225000 (34%)] Loss: 20871.289062\n",
      "Train Epoch: 8 [80064/225000 (36%)] Loss: 20900.996094\n",
      "Train Epoch: 8 [82560/225000 (37%)] Loss: 20338.902344\n",
      "Train Epoch: 8 [85056/225000 (38%)] Loss: 21127.406250\n",
      "Train Epoch: 8 [87552/225000 (39%)] Loss: 20719.289062\n",
      "Train Epoch: 8 [90048/225000 (40%)] Loss: 21230.289062\n",
      "Train Epoch: 8 [92544/225000 (41%)] Loss: 20638.183594\n",
      "Train Epoch: 8 [95040/225000 (42%)] Loss: 20809.593750\n",
      "Train Epoch: 8 [97536/225000 (43%)] Loss: 20727.695312\n",
      "Train Epoch: 8 [100032/225000 (44%)] Loss: 20467.472656\n",
      "Train Epoch: 8 [102528/225000 (46%)] Loss: 20976.734375\n",
      "Train Epoch: 8 [105024/225000 (47%)] Loss: 20712.962891\n",
      "Train Epoch: 8 [107520/225000 (48%)] Loss: 20611.277344\n",
      "Train Epoch: 8 [110016/225000 (49%)] Loss: 20940.054688\n",
      "Train Epoch: 8 [112512/225000 (50%)] Loss: 21284.906250\n",
      "Train Epoch: 8 [115008/225000 (51%)] Loss: 20888.718750\n",
      "Train Epoch: 8 [117504/225000 (52%)] Loss: 20878.730469\n",
      "Train Epoch: 8 [120000/225000 (53%)] Loss: 20824.445312\n",
      "Train Epoch: 8 [122496/225000 (54%)] Loss: 20870.062500\n",
      "Train Epoch: 8 [124992/225000 (56%)] Loss: 21069.449219\n",
      "Train Epoch: 8 [127488/225000 (57%)] Loss: 20702.148438\n",
      "Train Epoch: 8 [129984/225000 (58%)] Loss: 20467.261719\n",
      "Train Epoch: 8 [132480/225000 (59%)] Loss: 20940.265625\n",
      "Train Epoch: 8 [134976/225000 (60%)] Loss: 20868.556641\n",
      "Train Epoch: 8 [137472/225000 (61%)] Loss: 21143.380859\n",
      "Train Epoch: 8 [139968/225000 (62%)] Loss: 20228.214844\n",
      "Train Epoch: 8 [142464/225000 (63%)] Loss: 20593.406250\n",
      "Train Epoch: 8 [144960/225000 (64%)] Loss: 20846.718750\n",
      "Train Epoch: 8 [147456/225000 (66%)] Loss: 20832.101562\n",
      "Train Epoch: 8 [149952/225000 (67%)] Loss: 20547.570312\n",
      "Train Epoch: 8 [152448/225000 (68%)] Loss: 20291.621094\n",
      "Train Epoch: 8 [154944/225000 (69%)] Loss: 20873.625000\n",
      "Train Epoch: 8 [157440/225000 (70%)] Loss: 20081.171875\n",
      "Train Epoch: 8 [159936/225000 (71%)] Loss: 20674.535156\n",
      "Train Epoch: 8 [162432/225000 (72%)] Loss: 21281.042969\n",
      "Train Epoch: 8 [164928/225000 (73%)] Loss: 20861.998047\n",
      "Train Epoch: 8 [167424/225000 (74%)] Loss: 21142.328125\n",
      "Train Epoch: 8 [169920/225000 (76%)] Loss: 20924.623047\n",
      "Train Epoch: 8 [172416/225000 (77%)] Loss: 20598.953125\n",
      "Train Epoch: 8 [174912/225000 (78%)] Loss: 20872.332031\n",
      "Train Epoch: 8 [177408/225000 (79%)] Loss: 20690.066406\n",
      "Train Epoch: 8 [179904/225000 (80%)] Loss: 20372.839844\n",
      "Train Epoch: 8 [182400/225000 (81%)] Loss: 20775.394531\n",
      "Train Epoch: 8 [184896/225000 (82%)] Loss: 20548.523438\n",
      "Train Epoch: 8 [187392/225000 (83%)] Loss: 20718.585938\n",
      "Train Epoch: 8 [189888/225000 (84%)] Loss: 21354.976562\n",
      "Train Epoch: 8 [192384/225000 (86%)] Loss: 20813.277344\n",
      "Train Epoch: 8 [194880/225000 (87%)] Loss: 20481.175781\n",
      "Train Epoch: 8 [197376/225000 (88%)] Loss: 20857.210938\n",
      "Train Epoch: 8 [199872/225000 (89%)] Loss: 20738.039062\n",
      "Train Epoch: 8 [202368/225000 (90%)] Loss: 20667.027344\n",
      "Train Epoch: 8 [204864/225000 (91%)] Loss: 20648.050781\n",
      "Train Epoch: 8 [207360/225000 (92%)] Loss: 21107.179688\n",
      "Train Epoch: 8 [209856/225000 (93%)] Loss: 20870.804688\n",
      "Train Epoch: 8 [212352/225000 (94%)] Loss: 20492.875000\n",
      "Train Epoch: 8 [214848/225000 (95%)] Loss: 20951.222656\n",
      "Train Epoch: 8 [217344/225000 (97%)] Loss: 20823.296875\n",
      "Train Epoch: 8 [219840/225000 (98%)] Loss: 20664.306641\n",
      "Train Epoch: 8 [222336/225000 (99%)] Loss: 20628.195312\n",
      "Train Epoch: 8 [224832/225000 (100%)] Loss: 21003.843750\n",
      "    epoch          : 8\n",
      "    loss           : 20841.687205031463\n",
      "    val_loss       : 20968.142700413257\n",
      "Train Epoch: 9 [192/225000 (0%)] Loss: 20705.787109\n",
      "Train Epoch: 9 [2688/225000 (1%)] Loss: 20858.679688\n",
      "Train Epoch: 9 [5184/225000 (2%)] Loss: 20955.703125\n",
      "Train Epoch: 9 [7680/225000 (3%)] Loss: 20801.091797\n",
      "Train Epoch: 9 [10176/225000 (5%)] Loss: 20682.115234\n",
      "Train Epoch: 9 [12672/225000 (6%)] Loss: 20601.451172\n",
      "Train Epoch: 9 [15168/225000 (7%)] Loss: 20627.105469\n",
      "Train Epoch: 9 [17664/225000 (8%)] Loss: 20944.806641\n",
      "Train Epoch: 9 [20160/225000 (9%)] Loss: 20860.501953\n",
      "Train Epoch: 9 [22656/225000 (10%)] Loss: 21084.996094\n",
      "Train Epoch: 9 [25152/225000 (11%)] Loss: 21178.291016\n",
      "Train Epoch: 9 [27648/225000 (12%)] Loss: 20493.812500\n",
      "Train Epoch: 9 [30144/225000 (13%)] Loss: 21244.476562\n",
      "Train Epoch: 9 [32640/225000 (15%)] Loss: 20571.898438\n",
      "Train Epoch: 9 [35136/225000 (16%)] Loss: 20653.675781\n",
      "Train Epoch: 9 [37632/225000 (17%)] Loss: 20571.236328\n",
      "Train Epoch: 9 [40128/225000 (18%)] Loss: 21094.312500\n",
      "Train Epoch: 9 [42624/225000 (19%)] Loss: 21300.167969\n",
      "Train Epoch: 9 [45120/225000 (20%)] Loss: 20954.746094\n",
      "Train Epoch: 9 [47616/225000 (21%)] Loss: 20709.076172\n",
      "Train Epoch: 9 [50112/225000 (22%)] Loss: 20831.554688\n",
      "Train Epoch: 9 [52608/225000 (23%)] Loss: 21111.089844\n",
      "Train Epoch: 9 [55104/225000 (24%)] Loss: 20923.876953\n",
      "Train Epoch: 9 [57600/225000 (26%)] Loss: 20716.738281\n",
      "Train Epoch: 9 [60096/225000 (27%)] Loss: 20904.878906\n",
      "Train Epoch: 9 [62592/225000 (28%)] Loss: 20715.460938\n",
      "Train Epoch: 9 [65088/225000 (29%)] Loss: 20585.984375\n",
      "Train Epoch: 9 [67584/225000 (30%)] Loss: 21044.312500\n",
      "Train Epoch: 9 [70080/225000 (31%)] Loss: 21090.621094\n",
      "Train Epoch: 9 [72576/225000 (32%)] Loss: 20955.968750\n",
      "Train Epoch: 9 [75072/225000 (33%)] Loss: 21256.761719\n",
      "Train Epoch: 9 [77568/225000 (34%)] Loss: 20587.398438\n",
      "Train Epoch: 9 [80064/225000 (36%)] Loss: 20658.445312\n",
      "Train Epoch: 9 [82560/225000 (37%)] Loss: 20487.832031\n",
      "Train Epoch: 9 [85056/225000 (38%)] Loss: 20554.941406\n",
      "Train Epoch: 9 [87552/225000 (39%)] Loss: 20684.421875\n",
      "Train Epoch: 9 [90048/225000 (40%)] Loss: 21033.765625\n",
      "Train Epoch: 9 [92544/225000 (41%)] Loss: 20643.304688\n",
      "Train Epoch: 9 [95040/225000 (42%)] Loss: 20646.839844\n",
      "Train Epoch: 9 [97536/225000 (43%)] Loss: 20733.597656\n",
      "Train Epoch: 9 [100032/225000 (44%)] Loss: 20803.601562\n",
      "Train Epoch: 9 [102528/225000 (46%)] Loss: 21157.363281\n",
      "Train Epoch: 9 [105024/225000 (47%)] Loss: 21090.890625\n",
      "Train Epoch: 9 [107520/225000 (48%)] Loss: 21182.605469\n",
      "Train Epoch: 9 [110016/225000 (49%)] Loss: 20955.171875\n",
      "Train Epoch: 9 [112512/225000 (50%)] Loss: 19864.656250\n",
      "Train Epoch: 9 [115008/225000 (51%)] Loss: 20767.781250\n",
      "Train Epoch: 9 [117504/225000 (52%)] Loss: 21195.582031\n",
      "Train Epoch: 9 [120000/225000 (53%)] Loss: 20959.244141\n",
      "Train Epoch: 9 [122496/225000 (54%)] Loss: 20658.398438\n",
      "Train Epoch: 9 [124992/225000 (56%)] Loss: 21031.607422\n",
      "Train Epoch: 9 [127488/225000 (57%)] Loss: 20571.917969\n",
      "Train Epoch: 9 [129984/225000 (58%)] Loss: 20763.298828\n",
      "Train Epoch: 9 [132480/225000 (59%)] Loss: 20547.306641\n",
      "Train Epoch: 9 [134976/225000 (60%)] Loss: 20878.904297\n",
      "Train Epoch: 9 [137472/225000 (61%)] Loss: 20547.521484\n",
      "Train Epoch: 9 [139968/225000 (62%)] Loss: 20468.945312\n",
      "Train Epoch: 9 [142464/225000 (63%)] Loss: 20849.445312\n",
      "Train Epoch: 9 [144960/225000 (64%)] Loss: 20545.615234\n",
      "Train Epoch: 9 [147456/225000 (66%)] Loss: 20520.199219\n",
      "Train Epoch: 9 [149952/225000 (67%)] Loss: 20778.451172\n",
      "Train Epoch: 9 [152448/225000 (68%)] Loss: 20707.613281\n",
      "Train Epoch: 9 [154944/225000 (69%)] Loss: 21073.433594\n",
      "Train Epoch: 9 [157440/225000 (70%)] Loss: 20800.382812\n",
      "Train Epoch: 9 [159936/225000 (71%)] Loss: 20951.259766\n",
      "Train Epoch: 9 [162432/225000 (72%)] Loss: 20584.269531\n",
      "Train Epoch: 9 [164928/225000 (73%)] Loss: 21203.175781\n",
      "Train Epoch: 9 [167424/225000 (74%)] Loss: 21113.253906\n",
      "Train Epoch: 9 [169920/225000 (76%)] Loss: 20629.748047\n",
      "Train Epoch: 9 [172416/225000 (77%)] Loss: 20650.916016\n",
      "Train Epoch: 9 [174912/225000 (78%)] Loss: 21003.072266\n",
      "Train Epoch: 9 [177408/225000 (79%)] Loss: 20319.910156\n",
      "Train Epoch: 9 [179904/225000 (80%)] Loss: 20741.154297\n",
      "Train Epoch: 9 [182400/225000 (81%)] Loss: 20541.558594\n",
      "Train Epoch: 9 [184896/225000 (82%)] Loss: 20858.812500\n",
      "Train Epoch: 9 [187392/225000 (83%)] Loss: 20641.410156\n",
      "Train Epoch: 9 [189888/225000 (84%)] Loss: 20752.375000\n",
      "Train Epoch: 9 [192384/225000 (86%)] Loss: 20977.400391\n",
      "Train Epoch: 9 [194880/225000 (87%)] Loss: 21039.988281\n",
      "Train Epoch: 9 [197376/225000 (88%)] Loss: 20602.703125\n",
      "Train Epoch: 9 [199872/225000 (89%)] Loss: 20682.427734\n",
      "Train Epoch: 9 [202368/225000 (90%)] Loss: 20556.152344\n",
      "Train Epoch: 9 [204864/225000 (91%)] Loss: 20580.214844\n",
      "Train Epoch: 9 [207360/225000 (92%)] Loss: 20638.359375\n",
      "Train Epoch: 9 [209856/225000 (93%)] Loss: 20480.238281\n",
      "Train Epoch: 9 [212352/225000 (94%)] Loss: 20700.664062\n",
      "Train Epoch: 9 [214848/225000 (95%)] Loss: 20358.464844\n",
      "Train Epoch: 9 [217344/225000 (97%)] Loss: 21205.923828\n",
      "Train Epoch: 9 [219840/225000 (98%)] Loss: 21363.394531\n",
      "Train Epoch: 9 [222336/225000 (99%)] Loss: 20689.751953\n",
      "Train Epoch: 9 [224832/225000 (100%)] Loss: 21093.742188\n",
      "    epoch          : 9\n",
      "    loss           : 20879.810721856335\n",
      "    val_loss       : 20792.072276242816\n",
      "Train Epoch: 10 [192/225000 (0%)] Loss: 20859.085938\n",
      "Train Epoch: 10 [2688/225000 (1%)] Loss: 20165.753906\n",
      "Train Epoch: 10 [5184/225000 (2%)] Loss: 20859.726562\n",
      "Train Epoch: 10 [7680/225000 (3%)] Loss: 21219.181641\n",
      "Train Epoch: 10 [10176/225000 (5%)] Loss: 20454.578125\n",
      "Train Epoch: 10 [12672/225000 (6%)] Loss: 20549.154297\n",
      "Train Epoch: 10 [15168/225000 (7%)] Loss: 20969.878906\n",
      "Train Epoch: 10 [17664/225000 (8%)] Loss: 20899.101562\n",
      "Train Epoch: 10 [20160/225000 (9%)] Loss: 20359.660156\n",
      "Train Epoch: 10 [22656/225000 (10%)] Loss: 20935.800781\n",
      "Train Epoch: 10 [25152/225000 (11%)] Loss: 20445.458984\n",
      "Train Epoch: 10 [27648/225000 (12%)] Loss: 20172.273438\n",
      "Train Epoch: 10 [30144/225000 (13%)] Loss: 36748.695312\n",
      "Train Epoch: 10 [32640/225000 (15%)] Loss: 20354.925781\n",
      "Train Epoch: 10 [35136/225000 (16%)] Loss: 20959.292969\n",
      "Train Epoch: 10 [37632/225000 (17%)] Loss: 20741.554688\n",
      "Train Epoch: 10 [40128/225000 (18%)] Loss: 20723.431641\n",
      "Train Epoch: 10 [42624/225000 (19%)] Loss: 20905.382812\n",
      "Train Epoch: 10 [45120/225000 (20%)] Loss: 20198.972656\n",
      "Train Epoch: 10 [47616/225000 (21%)] Loss: 20585.419922\n",
      "Train Epoch: 10 [50112/225000 (22%)] Loss: 20569.945312\n",
      "Train Epoch: 10 [52608/225000 (23%)] Loss: 19935.148438\n",
      "Train Epoch: 10 [55104/225000 (24%)] Loss: 20536.636719\n",
      "Train Epoch: 10 [57600/225000 (26%)] Loss: 21204.167969\n",
      "Train Epoch: 10 [60096/225000 (27%)] Loss: 20950.554688\n",
      "Train Epoch: 10 [62592/225000 (28%)] Loss: 21156.945312\n",
      "Train Epoch: 10 [65088/225000 (29%)] Loss: 20733.869141\n",
      "Train Epoch: 10 [67584/225000 (30%)] Loss: 21177.238281\n",
      "Train Epoch: 10 [70080/225000 (31%)] Loss: 20742.998047\n",
      "Train Epoch: 10 [72576/225000 (32%)] Loss: 20615.468750\n",
      "Train Epoch: 10 [75072/225000 (33%)] Loss: 20637.074219\n",
      "Train Epoch: 10 [77568/225000 (34%)] Loss: 20941.570312\n",
      "Train Epoch: 10 [80064/225000 (36%)] Loss: 20988.644531\n",
      "Train Epoch: 10 [82560/225000 (37%)] Loss: 20942.652344\n",
      "Train Epoch: 10 [85056/225000 (38%)] Loss: 20990.605469\n",
      "Train Epoch: 10 [87552/225000 (39%)] Loss: 20431.941406\n",
      "Train Epoch: 10 [90048/225000 (40%)] Loss: 20704.861328\n",
      "Train Epoch: 10 [92544/225000 (41%)] Loss: 20847.808594\n",
      "Train Epoch: 10 [95040/225000 (42%)] Loss: 20922.175781\n",
      "Train Epoch: 10 [97536/225000 (43%)] Loss: 21158.076172\n",
      "Train Epoch: 10 [100032/225000 (44%)] Loss: 20765.595703\n",
      "Train Epoch: 10 [102528/225000 (46%)] Loss: 20821.087891\n",
      "Train Epoch: 10 [105024/225000 (47%)] Loss: 20603.410156\n",
      "Train Epoch: 10 [107520/225000 (48%)] Loss: 20475.691406\n",
      "Train Epoch: 10 [110016/225000 (49%)] Loss: 21046.224609\n",
      "Train Epoch: 10 [112512/225000 (50%)] Loss: 21217.763672\n",
      "Train Epoch: 10 [115008/225000 (51%)] Loss: 20678.996094\n",
      "Train Epoch: 10 [117504/225000 (52%)] Loss: 20431.718750\n",
      "Train Epoch: 10 [120000/225000 (53%)] Loss: 20415.023438\n",
      "Train Epoch: 10 [122496/225000 (54%)] Loss: 20887.433594\n",
      "Train Epoch: 10 [124992/225000 (56%)] Loss: 20709.199219\n",
      "Train Epoch: 10 [127488/225000 (57%)] Loss: 20627.400391\n",
      "Train Epoch: 10 [129984/225000 (58%)] Loss: 21227.837891\n",
      "Train Epoch: 10 [132480/225000 (59%)] Loss: 20240.937500\n",
      "Train Epoch: 10 [134976/225000 (60%)] Loss: 20834.867188\n",
      "Train Epoch: 10 [137472/225000 (61%)] Loss: 21424.669922\n",
      "Train Epoch: 10 [139968/225000 (62%)] Loss: 21208.144531\n",
      "Train Epoch: 10 [142464/225000 (63%)] Loss: 20652.794922\n",
      "Train Epoch: 10 [144960/225000 (64%)] Loss: 20840.673828\n",
      "Train Epoch: 10 [147456/225000 (66%)] Loss: 20820.335938\n",
      "Train Epoch: 10 [149952/225000 (67%)] Loss: 20758.335938\n",
      "Train Epoch: 10 [152448/225000 (68%)] Loss: 20832.800781\n",
      "Train Epoch: 10 [154944/225000 (69%)] Loss: 20491.257812\n",
      "Train Epoch: 10 [157440/225000 (70%)] Loss: 20599.164062\n",
      "Train Epoch: 10 [159936/225000 (71%)] Loss: 21068.160156\n",
      "Train Epoch: 10 [162432/225000 (72%)] Loss: 20733.789062\n",
      "Train Epoch: 10 [164928/225000 (73%)] Loss: 20652.656250\n",
      "Train Epoch: 10 [167424/225000 (74%)] Loss: 20541.957031\n",
      "Train Epoch: 10 [169920/225000 (76%)] Loss: 21251.216797\n",
      "Train Epoch: 10 [172416/225000 (77%)] Loss: 20831.341797\n",
      "Train Epoch: 10 [174912/225000 (78%)] Loss: 20323.134766\n",
      "Train Epoch: 10 [177408/225000 (79%)] Loss: 20862.281250\n",
      "Train Epoch: 10 [179904/225000 (80%)] Loss: 20508.910156\n",
      "Train Epoch: 10 [182400/225000 (81%)] Loss: 20860.628906\n",
      "Train Epoch: 10 [184896/225000 (82%)] Loss: 20982.066406\n",
      "Train Epoch: 10 [187392/225000 (83%)] Loss: 20535.056641\n",
      "Train Epoch: 10 [189888/225000 (84%)] Loss: 20972.775391\n",
      "Train Epoch: 10 [192384/225000 (86%)] Loss: 20686.541016\n",
      "Train Epoch: 10 [194880/225000 (87%)] Loss: 20822.636719\n",
      "Train Epoch: 10 [197376/225000 (88%)] Loss: 20814.125000\n",
      "Train Epoch: 10 [199872/225000 (89%)] Loss: 21027.556641\n",
      "Train Epoch: 10 [202368/225000 (90%)] Loss: 20756.753906\n",
      "Train Epoch: 10 [204864/225000 (91%)] Loss: 20570.613281\n",
      "Train Epoch: 10 [207360/225000 (92%)] Loss: 20836.382812\n",
      "Train Epoch: 10 [209856/225000 (93%)] Loss: 20407.632812\n",
      "Train Epoch: 10 [212352/225000 (94%)] Loss: 20541.677734\n",
      "Train Epoch: 10 [214848/225000 (95%)] Loss: 20454.402344\n",
      "Train Epoch: 10 [217344/225000 (97%)] Loss: 20839.855469\n",
      "Train Epoch: 10 [219840/225000 (98%)] Loss: 20889.318359\n",
      "Train Epoch: 10 [222336/225000 (99%)] Loss: 20775.736328\n",
      "Train Epoch: 10 [224832/225000 (100%)] Loss: 20623.968750\n",
      "    epoch          : 10\n",
      "    loss           : 20806.254887811967\n",
      "    val_loss       : 20645.834268437087\n",
      "Train Epoch: 11 [192/225000 (0%)] Loss: 20343.429688\n",
      "Train Epoch: 11 [2688/225000 (1%)] Loss: 20888.046875\n",
      "Train Epoch: 11 [5184/225000 (2%)] Loss: 20541.841797\n",
      "Train Epoch: 11 [7680/225000 (3%)] Loss: 20699.410156\n",
      "Train Epoch: 11 [10176/225000 (5%)] Loss: 20760.261719\n",
      "Train Epoch: 11 [12672/225000 (6%)] Loss: 20971.394531\n",
      "Train Epoch: 11 [15168/225000 (7%)] Loss: 20941.687500\n",
      "Train Epoch: 11 [17664/225000 (8%)] Loss: 20304.353516\n",
      "Train Epoch: 11 [20160/225000 (9%)] Loss: 20778.521484\n",
      "Train Epoch: 11 [22656/225000 (10%)] Loss: 21133.468750\n",
      "Train Epoch: 11 [25152/225000 (11%)] Loss: 20738.164062\n",
      "Train Epoch: 11 [27648/225000 (12%)] Loss: 20827.625000\n",
      "Train Epoch: 11 [30144/225000 (13%)] Loss: 20843.888672\n",
      "Train Epoch: 11 [32640/225000 (15%)] Loss: 20847.583984\n",
      "Train Epoch: 11 [35136/225000 (16%)] Loss: 20620.355469\n",
      "Train Epoch: 11 [37632/225000 (17%)] Loss: 20727.914062\n",
      "Train Epoch: 11 [40128/225000 (18%)] Loss: 20658.640625\n",
      "Train Epoch: 11 [42624/225000 (19%)] Loss: 20914.906250\n",
      "Train Epoch: 11 [45120/225000 (20%)] Loss: 20576.707031\n",
      "Train Epoch: 11 [47616/225000 (21%)] Loss: 21051.039062\n",
      "Train Epoch: 11 [50112/225000 (22%)] Loss: 20755.550781\n",
      "Train Epoch: 11 [52608/225000 (23%)] Loss: 20431.546875\n",
      "Train Epoch: 11 [55104/225000 (24%)] Loss: 21000.132812\n",
      "Train Epoch: 11 [57600/225000 (26%)] Loss: 20915.083984\n",
      "Train Epoch: 11 [60096/225000 (27%)] Loss: 20531.484375\n",
      "Train Epoch: 11 [62592/225000 (28%)] Loss: 20877.095703\n",
      "Train Epoch: 11 [65088/225000 (29%)] Loss: 20817.263672\n",
      "Train Epoch: 11 [67584/225000 (30%)] Loss: 20563.910156\n",
      "Train Epoch: 11 [70080/225000 (31%)] Loss: 20945.699219\n",
      "Train Epoch: 11 [72576/225000 (32%)] Loss: 20723.433594\n",
      "Train Epoch: 11 [75072/225000 (33%)] Loss: 20482.794922\n",
      "Train Epoch: 11 [77568/225000 (34%)] Loss: 20311.609375\n",
      "Train Epoch: 11 [80064/225000 (36%)] Loss: 20517.406250\n",
      "Train Epoch: 11 [82560/225000 (37%)] Loss: 20390.611328\n",
      "Train Epoch: 11 [85056/225000 (38%)] Loss: 20683.234375\n",
      "Train Epoch: 11 [87552/225000 (39%)] Loss: 20765.773438\n",
      "Train Epoch: 11 [90048/225000 (40%)] Loss: 20969.640625\n",
      "Train Epoch: 11 [92544/225000 (41%)] Loss: 21237.214844\n",
      "Train Epoch: 11 [95040/225000 (42%)] Loss: 20708.500000\n",
      "Train Epoch: 11 [97536/225000 (43%)] Loss: 20660.271484\n",
      "Train Epoch: 11 [100032/225000 (44%)] Loss: 21167.564453\n",
      "Train Epoch: 11 [102528/225000 (46%)] Loss: 20662.234375\n",
      "Train Epoch: 11 [105024/225000 (47%)] Loss: 20581.691406\n",
      "Train Epoch: 11 [107520/225000 (48%)] Loss: 20984.097656\n",
      "Train Epoch: 11 [110016/225000 (49%)] Loss: 20710.488281\n",
      "Train Epoch: 11 [112512/225000 (50%)] Loss: 20749.847656\n",
      "Train Epoch: 11 [115008/225000 (51%)] Loss: 20614.207031\n",
      "Train Epoch: 11 [117504/225000 (52%)] Loss: 20700.677734\n",
      "Train Epoch: 11 [120000/225000 (53%)] Loss: 20727.570312\n",
      "Train Epoch: 11 [122496/225000 (54%)] Loss: 20759.570312\n",
      "Train Epoch: 11 [124992/225000 (56%)] Loss: 20651.574219\n",
      "Train Epoch: 11 [127488/225000 (57%)] Loss: 20687.003906\n",
      "Train Epoch: 11 [129984/225000 (58%)] Loss: 20867.769531\n",
      "Train Epoch: 11 [132480/225000 (59%)] Loss: 20922.724609\n",
      "Train Epoch: 11 [134976/225000 (60%)] Loss: 21428.675781\n",
      "Train Epoch: 11 [137472/225000 (61%)] Loss: 20742.474609\n",
      "Train Epoch: 11 [139968/225000 (62%)] Loss: 20975.757812\n",
      "Train Epoch: 11 [142464/225000 (63%)] Loss: 20637.138672\n",
      "Train Epoch: 11 [144960/225000 (64%)] Loss: 20878.746094\n",
      "Train Epoch: 11 [147456/225000 (66%)] Loss: 20816.878906\n",
      "Train Epoch: 11 [149952/225000 (67%)] Loss: 20879.496094\n",
      "Train Epoch: 11 [152448/225000 (68%)] Loss: 20078.210938\n",
      "Train Epoch: 11 [154944/225000 (69%)] Loss: 20917.181641\n",
      "Train Epoch: 11 [157440/225000 (70%)] Loss: 19808.527344\n",
      "Train Epoch: 11 [159936/225000 (71%)] Loss: 20474.593750\n",
      "Train Epoch: 11 [162432/225000 (72%)] Loss: 20838.949219\n",
      "Train Epoch: 11 [164928/225000 (73%)] Loss: 20360.423828\n",
      "Train Epoch: 11 [167424/225000 (74%)] Loss: 20836.378906\n",
      "Train Epoch: 11 [169920/225000 (76%)] Loss: 21445.558594\n",
      "Train Epoch: 11 [172416/225000 (77%)] Loss: 20458.179688\n",
      "Train Epoch: 11 [174912/225000 (78%)] Loss: 20828.458984\n",
      "Train Epoch: 11 [177408/225000 (79%)] Loss: 20692.806641\n",
      "Train Epoch: 11 [179904/225000 (80%)] Loss: 21327.199219\n",
      "Train Epoch: 11 [182400/225000 (81%)] Loss: 21160.910156\n",
      "Train Epoch: 11 [184896/225000 (82%)] Loss: 20597.820312\n",
      "Train Epoch: 11 [187392/225000 (83%)] Loss: 20824.296875\n",
      "Train Epoch: 11 [189888/225000 (84%)] Loss: 20211.296875\n",
      "Train Epoch: 11 [192384/225000 (86%)] Loss: 20201.742188\n",
      "Train Epoch: 11 [194880/225000 (87%)] Loss: 20649.669922\n",
      "Train Epoch: 11 [197376/225000 (88%)] Loss: 20840.343750\n",
      "Train Epoch: 11 [199872/225000 (89%)] Loss: 21007.296875\n",
      "Train Epoch: 11 [202368/225000 (90%)] Loss: 20811.615234\n",
      "Train Epoch: 11 [204864/225000 (91%)] Loss: 21227.683594\n",
      "Train Epoch: 11 [207360/225000 (92%)] Loss: 21114.664062\n",
      "Train Epoch: 11 [209856/225000 (93%)] Loss: 20467.820312\n",
      "Train Epoch: 11 [212352/225000 (94%)] Loss: 20617.992188\n",
      "Train Epoch: 11 [214848/225000 (95%)] Loss: 20875.324219\n",
      "Train Epoch: 11 [217344/225000 (97%)] Loss: 20736.527344\n",
      "Train Epoch: 11 [219840/225000 (98%)] Loss: 21044.175781\n",
      "Train Epoch: 11 [222336/225000 (99%)] Loss: 20746.351562\n",
      "Train Epoch: 11 [224832/225000 (100%)] Loss: 20871.476562\n",
      "    epoch          : 11\n",
      "    loss           : 20724.35826011892\n",
      "    val_loss       : 20600.261942988134\n",
      "Train Epoch: 12 [192/225000 (0%)] Loss: 20146.390625\n",
      "Train Epoch: 12 [2688/225000 (1%)] Loss: 20507.789062\n",
      "Train Epoch: 12 [5184/225000 (2%)] Loss: 20248.875000\n",
      "Train Epoch: 12 [7680/225000 (3%)] Loss: 21128.457031\n",
      "Train Epoch: 12 [10176/225000 (5%)] Loss: 20342.603516\n",
      "Train Epoch: 12 [12672/225000 (6%)] Loss: 20784.828125\n",
      "Train Epoch: 12 [15168/225000 (7%)] Loss: 20713.894531\n",
      "Train Epoch: 12 [17664/225000 (8%)] Loss: 20466.996094\n",
      "Train Epoch: 12 [20160/225000 (9%)] Loss: 20893.195312\n",
      "Train Epoch: 12 [22656/225000 (10%)] Loss: 21367.433594\n",
      "Train Epoch: 12 [25152/225000 (11%)] Loss: 21304.203125\n",
      "Train Epoch: 12 [27648/225000 (12%)] Loss: 21269.406250\n",
      "Train Epoch: 12 [30144/225000 (13%)] Loss: 20612.265625\n",
      "Train Epoch: 12 [32640/225000 (15%)] Loss: 20749.410156\n",
      "Train Epoch: 12 [35136/225000 (16%)] Loss: 20724.589844\n",
      "Train Epoch: 12 [37632/225000 (17%)] Loss: 20733.871094\n",
      "Train Epoch: 12 [40128/225000 (18%)] Loss: 20831.242188\n",
      "Train Epoch: 12 [42624/225000 (19%)] Loss: 20598.273438\n",
      "Train Epoch: 12 [45120/225000 (20%)] Loss: 20778.816406\n",
      "Train Epoch: 12 [47616/225000 (21%)] Loss: 20313.730469\n",
      "Train Epoch: 12 [50112/225000 (22%)] Loss: 20815.609375\n",
      "Train Epoch: 12 [52608/225000 (23%)] Loss: 20860.531250\n",
      "Train Epoch: 12 [55104/225000 (24%)] Loss: 20512.568359\n",
      "Train Epoch: 12 [57600/225000 (26%)] Loss: 20919.789062\n",
      "Train Epoch: 12 [60096/225000 (27%)] Loss: 20541.712891\n",
      "Train Epoch: 12 [62592/225000 (28%)] Loss: 20981.566406\n",
      "Train Epoch: 12 [65088/225000 (29%)] Loss: 21040.925781\n",
      "Train Epoch: 12 [67584/225000 (30%)] Loss: 20432.011719\n",
      "Train Epoch: 12 [70080/225000 (31%)] Loss: 20527.156250\n",
      "Train Epoch: 12 [72576/225000 (32%)] Loss: 20438.011719\n",
      "Train Epoch: 12 [75072/225000 (33%)] Loss: 21066.078125\n",
      "Train Epoch: 12 [77568/225000 (34%)] Loss: 20941.671875\n",
      "Train Epoch: 12 [80064/225000 (36%)] Loss: 20835.039062\n",
      "Train Epoch: 12 [82560/225000 (37%)] Loss: 20648.347656\n",
      "Train Epoch: 12 [85056/225000 (38%)] Loss: 20455.250000\n",
      "Train Epoch: 12 [87552/225000 (39%)] Loss: 20318.664062\n",
      "Train Epoch: 12 [90048/225000 (40%)] Loss: 20827.480469\n",
      "Train Epoch: 12 [92544/225000 (41%)] Loss: 20774.240234\n",
      "Train Epoch: 12 [95040/225000 (42%)] Loss: 21146.355469\n",
      "Train Epoch: 12 [97536/225000 (43%)] Loss: 20132.828125\n",
      "Train Epoch: 12 [100032/225000 (44%)] Loss: 20604.675781\n",
      "Train Epoch: 12 [102528/225000 (46%)] Loss: 20347.695312\n",
      "Train Epoch: 12 [105024/225000 (47%)] Loss: 21167.003906\n",
      "Train Epoch: 12 [107520/225000 (48%)] Loss: 20101.992188\n",
      "Train Epoch: 12 [110016/225000 (49%)] Loss: 20456.328125\n",
      "Train Epoch: 12 [112512/225000 (50%)] Loss: 20697.308594\n",
      "Train Epoch: 12 [115008/225000 (51%)] Loss: 20731.585938\n",
      "Train Epoch: 12 [117504/225000 (52%)] Loss: 20841.976562\n",
      "Train Epoch: 12 [120000/225000 (53%)] Loss: 20758.416016\n",
      "Train Epoch: 12 [122496/225000 (54%)] Loss: 20905.976562\n",
      "Train Epoch: 12 [124992/225000 (56%)] Loss: 20664.548828\n",
      "Train Epoch: 12 [127488/225000 (57%)] Loss: 20352.095703\n",
      "Train Epoch: 12 [129984/225000 (58%)] Loss: 20862.070312\n",
      "Train Epoch: 12 [132480/225000 (59%)] Loss: 20607.921875\n",
      "Train Epoch: 12 [134976/225000 (60%)] Loss: 20490.292969\n",
      "Train Epoch: 12 [137472/225000 (61%)] Loss: 21169.343750\n",
      "Train Epoch: 12 [139968/225000 (62%)] Loss: 20499.269531\n",
      "Train Epoch: 12 [142464/225000 (63%)] Loss: 20921.470703\n",
      "Train Epoch: 12 [144960/225000 (64%)] Loss: 20960.003906\n",
      "Train Epoch: 12 [147456/225000 (66%)] Loss: 21290.746094\n",
      "Train Epoch: 12 [149952/225000 (67%)] Loss: 20751.621094\n",
      "Train Epoch: 12 [152448/225000 (68%)] Loss: 20482.201172\n",
      "Train Epoch: 12 [154944/225000 (69%)] Loss: 20815.441406\n",
      "Train Epoch: 12 [157440/225000 (70%)] Loss: 21152.835938\n",
      "Train Epoch: 12 [159936/225000 (71%)] Loss: 20887.001953\n",
      "Train Epoch: 12 [162432/225000 (72%)] Loss: 20886.226562\n",
      "Train Epoch: 12 [164928/225000 (73%)] Loss: 36524.367188\n",
      "Train Epoch: 12 [167424/225000 (74%)] Loss: 20853.470703\n",
      "Train Epoch: 12 [169920/225000 (76%)] Loss: 20532.781250\n",
      "Train Epoch: 12 [172416/225000 (77%)] Loss: 20874.164062\n",
      "Train Epoch: 12 [174912/225000 (78%)] Loss: 20536.906250\n",
      "Train Epoch: 12 [177408/225000 (79%)] Loss: 20394.386719\n",
      "Train Epoch: 12 [179904/225000 (80%)] Loss: 20629.949219\n",
      "Train Epoch: 12 [182400/225000 (81%)] Loss: 20532.826172\n",
      "Train Epoch: 12 [184896/225000 (82%)] Loss: 20730.632812\n",
      "Train Epoch: 12 [187392/225000 (83%)] Loss: 20893.949219\n",
      "Train Epoch: 12 [189888/225000 (84%)] Loss: 20683.187500\n",
      "Train Epoch: 12 [192384/225000 (86%)] Loss: 20630.789062\n",
      "Train Epoch: 12 [194880/225000 (87%)] Loss: 20520.480469\n",
      "Train Epoch: 12 [197376/225000 (88%)] Loss: 20893.914062\n",
      "Train Epoch: 12 [199872/225000 (89%)] Loss: 20592.808594\n",
      "Train Epoch: 12 [202368/225000 (90%)] Loss: 20868.789062\n",
      "Train Epoch: 12 [204864/225000 (91%)] Loss: 21163.585938\n",
      "Train Epoch: 12 [207360/225000 (92%)] Loss: 20376.050781\n",
      "Train Epoch: 12 [209856/225000 (93%)] Loss: 20681.755859\n",
      "Train Epoch: 12 [212352/225000 (94%)] Loss: 20315.078125\n",
      "Train Epoch: 12 [214848/225000 (95%)] Loss: 20245.128906\n",
      "Train Epoch: 12 [217344/225000 (97%)] Loss: 20330.179688\n",
      "Train Epoch: 12 [219840/225000 (98%)] Loss: 20350.060547\n",
      "Train Epoch: 12 [222336/225000 (99%)] Loss: 20537.710938\n",
      "Train Epoch: 12 [224832/225000 (100%)] Loss: 20607.722656\n",
      "    epoch          : 12\n",
      "    loss           : 20677.722234628305\n",
      "    val_loss       : 20552.658972171426\n",
      "Train Epoch: 13 [192/225000 (0%)] Loss: 20968.445312\n",
      "Train Epoch: 13 [2688/225000 (1%)] Loss: 20630.644531\n",
      "Train Epoch: 13 [5184/225000 (2%)] Loss: 20778.271484\n",
      "Train Epoch: 13 [7680/225000 (3%)] Loss: 21065.378906\n",
      "Train Epoch: 13 [10176/225000 (5%)] Loss: 20602.210938\n",
      "Train Epoch: 13 [12672/225000 (6%)] Loss: 20906.261719\n",
      "Train Epoch: 13 [15168/225000 (7%)] Loss: 20983.654297\n",
      "Train Epoch: 13 [17664/225000 (8%)] Loss: 21113.058594\n",
      "Train Epoch: 13 [20160/225000 (9%)] Loss: 20442.214844\n",
      "Train Epoch: 13 [22656/225000 (10%)] Loss: 20870.009766\n",
      "Train Epoch: 13 [25152/225000 (11%)] Loss: 20195.628906\n",
      "Train Epoch: 13 [27648/225000 (12%)] Loss: 20361.681641\n",
      "Train Epoch: 13 [30144/225000 (13%)] Loss: 20771.585938\n",
      "Train Epoch: 13 [32640/225000 (15%)] Loss: 21173.460938\n",
      "Train Epoch: 13 [35136/225000 (16%)] Loss: 20269.712891\n",
      "Train Epoch: 13 [37632/225000 (17%)] Loss: 20922.806641\n",
      "Train Epoch: 13 [40128/225000 (18%)] Loss: 20183.292969\n",
      "Train Epoch: 13 [42624/225000 (19%)] Loss: 20490.203125\n",
      "Train Epoch: 13 [45120/225000 (20%)] Loss: 20913.496094\n",
      "Train Epoch: 13 [47616/225000 (21%)] Loss: 20536.402344\n",
      "Train Epoch: 13 [50112/225000 (22%)] Loss: 20482.150391\n",
      "Train Epoch: 13 [52608/225000 (23%)] Loss: 20680.152344\n",
      "Train Epoch: 13 [55104/225000 (24%)] Loss: 20793.164062\n",
      "Train Epoch: 13 [57600/225000 (26%)] Loss: 20434.945312\n",
      "Train Epoch: 13 [60096/225000 (27%)] Loss: 20438.207031\n",
      "Train Epoch: 13 [62592/225000 (28%)] Loss: 20496.742188\n",
      "Train Epoch: 13 [65088/225000 (29%)] Loss: 20655.574219\n",
      "Train Epoch: 13 [67584/225000 (30%)] Loss: 20867.277344\n",
      "Train Epoch: 13 [70080/225000 (31%)] Loss: 20392.335938\n",
      "Train Epoch: 13 [72576/225000 (32%)] Loss: 21000.216797\n",
      "Train Epoch: 13 [75072/225000 (33%)] Loss: 20316.496094\n",
      "Train Epoch: 13 [77568/225000 (34%)] Loss: 20623.851562\n",
      "Train Epoch: 13 [80064/225000 (36%)] Loss: 20815.072266\n",
      "Train Epoch: 13 [82560/225000 (37%)] Loss: 20386.812500\n",
      "Train Epoch: 13 [85056/225000 (38%)] Loss: 21063.894531\n",
      "Train Epoch: 13 [87552/225000 (39%)] Loss: 21150.082031\n",
      "Train Epoch: 13 [90048/225000 (40%)] Loss: 20633.863281\n",
      "Train Epoch: 13 [92544/225000 (41%)] Loss: 20685.398438\n",
      "Train Epoch: 13 [95040/225000 (42%)] Loss: 20193.072266\n",
      "Train Epoch: 13 [97536/225000 (43%)] Loss: 20799.152344\n",
      "Train Epoch: 13 [100032/225000 (44%)] Loss: 20615.804688\n",
      "Train Epoch: 13 [102528/225000 (46%)] Loss: 21125.058594\n",
      "Train Epoch: 13 [105024/225000 (47%)] Loss: 20369.205078\n",
      "Train Epoch: 13 [107520/225000 (48%)] Loss: 21000.132812\n",
      "Train Epoch: 13 [110016/225000 (49%)] Loss: 20423.560547\n",
      "Train Epoch: 13 [112512/225000 (50%)] Loss: 20534.183594\n",
      "Train Epoch: 13 [115008/225000 (51%)] Loss: 20413.535156\n",
      "Train Epoch: 13 [117504/225000 (52%)] Loss: 20201.125000\n",
      "Train Epoch: 13 [120000/225000 (53%)] Loss: 20553.089844\n",
      "Train Epoch: 13 [122496/225000 (54%)] Loss: 20743.529297\n",
      "Train Epoch: 13 [124992/225000 (56%)] Loss: 21156.277344\n",
      "Train Epoch: 13 [127488/225000 (57%)] Loss: 20544.464844\n",
      "Train Epoch: 13 [129984/225000 (58%)] Loss: 20345.873047\n",
      "Train Epoch: 13 [132480/225000 (59%)] Loss: 20332.457031\n",
      "Train Epoch: 13 [134976/225000 (60%)] Loss: 20538.273438\n",
      "Train Epoch: 13 [137472/225000 (61%)] Loss: 20613.312500\n",
      "Train Epoch: 13 [139968/225000 (62%)] Loss: 21120.964844\n",
      "Train Epoch: 13 [142464/225000 (63%)] Loss: 20713.779297\n",
      "Train Epoch: 13 [144960/225000 (64%)] Loss: 20533.390625\n",
      "Train Epoch: 13 [147456/225000 (66%)] Loss: 20734.964844\n",
      "Train Epoch: 13 [149952/225000 (67%)] Loss: 20462.501953\n",
      "Train Epoch: 13 [152448/225000 (68%)] Loss: 20552.675781\n",
      "Train Epoch: 13 [154944/225000 (69%)] Loss: 20350.238281\n",
      "Train Epoch: 13 [157440/225000 (70%)] Loss: 20482.960938\n",
      "Train Epoch: 13 [159936/225000 (71%)] Loss: 21255.742188\n",
      "Train Epoch: 13 [162432/225000 (72%)] Loss: 20470.828125\n",
      "Train Epoch: 13 [164928/225000 (73%)] Loss: 20925.621094\n",
      "Train Epoch: 13 [167424/225000 (74%)] Loss: 20618.785156\n",
      "Train Epoch: 13 [169920/225000 (76%)] Loss: 20640.925781\n",
      "Train Epoch: 13 [172416/225000 (77%)] Loss: 20165.976562\n",
      "Train Epoch: 13 [174912/225000 (78%)] Loss: 20433.425781\n",
      "Train Epoch: 13 [177408/225000 (79%)] Loss: 20445.429688\n",
      "Train Epoch: 13 [179904/225000 (80%)] Loss: 20720.484375\n",
      "Train Epoch: 13 [182400/225000 (81%)] Loss: 20526.449219\n",
      "Train Epoch: 13 [184896/225000 (82%)] Loss: 20947.695312\n",
      "Train Epoch: 13 [187392/225000 (83%)] Loss: 20337.445312\n",
      "Train Epoch: 13 [189888/225000 (84%)] Loss: 20485.560547\n",
      "Train Epoch: 13 [192384/225000 (86%)] Loss: 20719.607422\n",
      "Train Epoch: 13 [194880/225000 (87%)] Loss: 20805.023438\n",
      "Train Epoch: 13 [197376/225000 (88%)] Loss: 20608.306641\n",
      "Train Epoch: 13 [199872/225000 (89%)] Loss: 20831.736328\n",
      "Train Epoch: 13 [202368/225000 (90%)] Loss: 20186.498047\n",
      "Train Epoch: 13 [204864/225000 (91%)] Loss: 20607.339844\n",
      "Train Epoch: 13 [207360/225000 (92%)] Loss: 21253.767578\n",
      "Train Epoch: 13 [209856/225000 (93%)] Loss: 20670.416016\n",
      "Train Epoch: 13 [212352/225000 (94%)] Loss: 20430.664062\n",
      "Train Epoch: 13 [214848/225000 (95%)] Loss: 20430.593750\n",
      "Train Epoch: 13 [217344/225000 (97%)] Loss: 20789.789062\n",
      "Train Epoch: 13 [219840/225000 (98%)] Loss: 21016.160156\n",
      "Train Epoch: 13 [222336/225000 (99%)] Loss: 21013.521484\n",
      "Train Epoch: 13 [224832/225000 (100%)] Loss: 20696.851562\n",
      "    epoch          : 13\n",
      "    loss           : 20646.23622146971\n",
      "    val_loss       : 20577.352355438336\n",
      "Train Epoch: 14 [192/225000 (0%)] Loss: 20771.777344\n",
      "Train Epoch: 14 [2688/225000 (1%)] Loss: 20424.585938\n",
      "Train Epoch: 14 [5184/225000 (2%)] Loss: 20497.191406\n",
      "Train Epoch: 14 [7680/225000 (3%)] Loss: 20440.037109\n",
      "Train Epoch: 14 [10176/225000 (5%)] Loss: 20269.207031\n",
      "Train Epoch: 14 [12672/225000 (6%)] Loss: 20744.255859\n",
      "Train Epoch: 14 [15168/225000 (7%)] Loss: 20751.939453\n",
      "Train Epoch: 14 [17664/225000 (8%)] Loss: 20664.087891\n",
      "Train Epoch: 14 [20160/225000 (9%)] Loss: 20102.816406\n",
      "Train Epoch: 14 [22656/225000 (10%)] Loss: 20746.835938\n",
      "Train Epoch: 14 [25152/225000 (11%)] Loss: 20435.378906\n",
      "Train Epoch: 14 [27648/225000 (12%)] Loss: 20803.515625\n",
      "Train Epoch: 14 [30144/225000 (13%)] Loss: 20643.917969\n",
      "Train Epoch: 14 [32640/225000 (15%)] Loss: 20700.664062\n",
      "Train Epoch: 14 [35136/225000 (16%)] Loss: 20565.107422\n",
      "Train Epoch: 14 [37632/225000 (17%)] Loss: 20383.117188\n",
      "Train Epoch: 14 [40128/225000 (18%)] Loss: 20430.183594\n",
      "Train Epoch: 14 [42624/225000 (19%)] Loss: 20577.062500\n",
      "Train Epoch: 14 [45120/225000 (20%)] Loss: 20592.009766\n",
      "Train Epoch: 14 [47616/225000 (21%)] Loss: 20505.460938\n",
      "Train Epoch: 14 [50112/225000 (22%)] Loss: 20493.509766\n",
      "Train Epoch: 14 [52608/225000 (23%)] Loss: 20541.234375\n",
      "Train Epoch: 14 [55104/225000 (24%)] Loss: 20987.269531\n",
      "Train Epoch: 14 [57600/225000 (26%)] Loss: 20408.611328\n",
      "Train Epoch: 14 [60096/225000 (27%)] Loss: 20054.570312\n",
      "Train Epoch: 14 [62592/225000 (28%)] Loss: 20691.496094\n",
      "Train Epoch: 14 [65088/225000 (29%)] Loss: 20180.457031\n",
      "Train Epoch: 14 [67584/225000 (30%)] Loss: 20370.531250\n",
      "Train Epoch: 14 [70080/225000 (31%)] Loss: 20385.378906\n",
      "Train Epoch: 14 [72576/225000 (32%)] Loss: 20715.871094\n",
      "Train Epoch: 14 [75072/225000 (33%)] Loss: 20498.750000\n",
      "Train Epoch: 14 [77568/225000 (34%)] Loss: 20889.931641\n",
      "Train Epoch: 14 [80064/225000 (36%)] Loss: 20594.828125\n",
      "Train Epoch: 14 [82560/225000 (37%)] Loss: 20467.439453\n",
      "Train Epoch: 14 [85056/225000 (38%)] Loss: 21067.535156\n",
      "Train Epoch: 14 [87552/225000 (39%)] Loss: 20464.496094\n",
      "Train Epoch: 14 [90048/225000 (40%)] Loss: 20425.992188\n",
      "Train Epoch: 14 [92544/225000 (41%)] Loss: 20264.890625\n",
      "Train Epoch: 14 [95040/225000 (42%)] Loss: 20588.669922\n",
      "Train Epoch: 14 [97536/225000 (43%)] Loss: 20370.546875\n",
      "Train Epoch: 14 [100032/225000 (44%)] Loss: 21040.292969\n",
      "Train Epoch: 14 [102528/225000 (46%)] Loss: 20547.091797\n",
      "Train Epoch: 14 [105024/225000 (47%)] Loss: 20738.919922\n",
      "Train Epoch: 14 [107520/225000 (48%)] Loss: 20747.136719\n",
      "Train Epoch: 14 [110016/225000 (49%)] Loss: 20852.125000\n",
      "Train Epoch: 14 [112512/225000 (50%)] Loss: 20147.232422\n",
      "Train Epoch: 14 [115008/225000 (51%)] Loss: 20711.136719\n",
      "Train Epoch: 14 [117504/225000 (52%)] Loss: 20727.621094\n",
      "Train Epoch: 14 [120000/225000 (53%)] Loss: 20411.294922\n",
      "Train Epoch: 14 [122496/225000 (54%)] Loss: 20212.859375\n",
      "Train Epoch: 14 [124992/225000 (56%)] Loss: 20673.496094\n",
      "Train Epoch: 14 [127488/225000 (57%)] Loss: 20583.496094\n",
      "Train Epoch: 14 [129984/225000 (58%)] Loss: 20173.769531\n",
      "Train Epoch: 14 [132480/225000 (59%)] Loss: 20259.039062\n",
      "Train Epoch: 14 [134976/225000 (60%)] Loss: 20574.578125\n",
      "Train Epoch: 14 [137472/225000 (61%)] Loss: 20964.906250\n",
      "Train Epoch: 14 [139968/225000 (62%)] Loss: 20746.082031\n",
      "Train Epoch: 14 [142464/225000 (63%)] Loss: 20441.080078\n",
      "Train Epoch: 14 [144960/225000 (64%)] Loss: 20645.929688\n",
      "Train Epoch: 14 [147456/225000 (66%)] Loss: 20202.583984\n",
      "Train Epoch: 14 [149952/225000 (67%)] Loss: 20539.314453\n",
      "Train Epoch: 14 [152448/225000 (68%)] Loss: 21020.480469\n",
      "Train Epoch: 14 [154944/225000 (69%)] Loss: 20429.722656\n",
      "Train Epoch: 14 [157440/225000 (70%)] Loss: 34882.875000\n",
      "Train Epoch: 14 [159936/225000 (71%)] Loss: 20195.779297\n",
      "Train Epoch: 14 [162432/225000 (72%)] Loss: 20324.589844\n",
      "Train Epoch: 14 [164928/225000 (73%)] Loss: 20560.925781\n",
      "Train Epoch: 14 [167424/225000 (74%)] Loss: 21061.644531\n",
      "Train Epoch: 14 [169920/225000 (76%)] Loss: 20577.935547\n",
      "Train Epoch: 14 [172416/225000 (77%)] Loss: 20528.332031\n",
      "Train Epoch: 14 [174912/225000 (78%)] Loss: 20423.964844\n",
      "Train Epoch: 14 [177408/225000 (79%)] Loss: 20611.519531\n",
      "Train Epoch: 14 [179904/225000 (80%)] Loss: 20802.238281\n",
      "Train Epoch: 14 [182400/225000 (81%)] Loss: 20807.421875\n",
      "Train Epoch: 14 [184896/225000 (82%)] Loss: 20041.308594\n",
      "Train Epoch: 14 [187392/225000 (83%)] Loss: 20246.890625\n",
      "Train Epoch: 14 [189888/225000 (84%)] Loss: 20469.054688\n",
      "Train Epoch: 14 [192384/225000 (86%)] Loss: 20716.910156\n",
      "Train Epoch: 14 [194880/225000 (87%)] Loss: 20694.972656\n",
      "Train Epoch: 14 [197376/225000 (88%)] Loss: 20269.128906\n",
      "Train Epoch: 14 [199872/225000 (89%)] Loss: 20602.833984\n",
      "Train Epoch: 14 [202368/225000 (90%)] Loss: 20609.693359\n",
      "Train Epoch: 14 [204864/225000 (91%)] Loss: 20648.648438\n",
      "Train Epoch: 14 [207360/225000 (92%)] Loss: 20868.669922\n",
      "Train Epoch: 14 [209856/225000 (93%)] Loss: 20603.025391\n",
      "Train Epoch: 14 [212352/225000 (94%)] Loss: 20248.322266\n",
      "Train Epoch: 14 [214848/225000 (95%)] Loss: 20584.132812\n",
      "Train Epoch: 14 [217344/225000 (97%)] Loss: 20736.851562\n",
      "Train Epoch: 14 [219840/225000 (98%)] Loss: 20078.781250\n",
      "Train Epoch: 14 [222336/225000 (99%)] Loss: 20803.296875\n",
      "Train Epoch: 14 [224832/225000 (100%)] Loss: 20684.265625\n",
      "    epoch          : 14\n",
      "    loss           : 20619.98784129693\n",
      "    val_loss       : 20489.480741676485\n",
      "Train Epoch: 15 [192/225000 (0%)] Loss: 20540.593750\n",
      "Train Epoch: 15 [2688/225000 (1%)] Loss: 20377.529297\n",
      "Train Epoch: 15 [5184/225000 (2%)] Loss: 20788.433594\n",
      "Train Epoch: 15 [7680/225000 (3%)] Loss: 20743.511719\n",
      "Train Epoch: 15 [10176/225000 (5%)] Loss: 20423.714844\n",
      "Train Epoch: 15 [12672/225000 (6%)] Loss: 20784.951172\n",
      "Train Epoch: 15 [15168/225000 (7%)] Loss: 21113.072266\n",
      "Train Epoch: 15 [17664/225000 (8%)] Loss: 21030.171875\n",
      "Train Epoch: 15 [20160/225000 (9%)] Loss: 20711.804688\n",
      "Train Epoch: 15 [22656/225000 (10%)] Loss: 20602.587891\n",
      "Train Epoch: 15 [25152/225000 (11%)] Loss: 20754.214844\n",
      "Train Epoch: 15 [27648/225000 (12%)] Loss: 20484.187500\n",
      "Train Epoch: 15 [30144/225000 (13%)] Loss: 20870.691406\n",
      "Train Epoch: 15 [32640/225000 (15%)] Loss: 20661.667969\n",
      "Train Epoch: 15 [35136/225000 (16%)] Loss: 20734.574219\n",
      "Train Epoch: 15 [37632/225000 (17%)] Loss: 20361.775391\n",
      "Train Epoch: 15 [40128/225000 (18%)] Loss: 20839.951172\n",
      "Train Epoch: 15 [42624/225000 (19%)] Loss: 20452.087891\n",
      "Train Epoch: 15 [45120/225000 (20%)] Loss: 20164.746094\n",
      "Train Epoch: 15 [47616/225000 (21%)] Loss: 20246.171875\n",
      "Train Epoch: 15 [50112/225000 (22%)] Loss: 20530.982422\n",
      "Train Epoch: 15 [52608/225000 (23%)] Loss: 20738.416016\n",
      "Train Epoch: 15 [55104/225000 (24%)] Loss: 20520.097656\n",
      "Train Epoch: 15 [57600/225000 (26%)] Loss: 20810.597656\n",
      "Train Epoch: 15 [60096/225000 (27%)] Loss: 20617.884766\n",
      "Train Epoch: 15 [62592/225000 (28%)] Loss: 20314.146484\n",
      "Train Epoch: 15 [65088/225000 (29%)] Loss: 20966.097656\n",
      "Train Epoch: 15 [67584/225000 (30%)] Loss: 20235.542969\n",
      "Train Epoch: 15 [70080/225000 (31%)] Loss: 20916.675781\n",
      "Train Epoch: 15 [72576/225000 (32%)] Loss: 20488.121094\n",
      "Train Epoch: 15 [75072/225000 (33%)] Loss: 20606.035156\n",
      "Train Epoch: 15 [77568/225000 (34%)] Loss: 20532.187500\n",
      "Train Epoch: 15 [80064/225000 (36%)] Loss: 20835.664062\n",
      "Train Epoch: 15 [82560/225000 (37%)] Loss: 20614.250000\n",
      "Train Epoch: 15 [85056/225000 (38%)] Loss: 20405.677734\n",
      "Train Epoch: 15 [87552/225000 (39%)] Loss: 20643.410156\n",
      "Train Epoch: 15 [90048/225000 (40%)] Loss: 20517.421875\n",
      "Train Epoch: 15 [92544/225000 (41%)] Loss: 20647.335938\n",
      "Train Epoch: 15 [95040/225000 (42%)] Loss: 20840.132812\n",
      "Train Epoch: 15 [97536/225000 (43%)] Loss: 20861.531250\n",
      "Train Epoch: 15 [100032/225000 (44%)] Loss: 21030.050781\n",
      "Train Epoch: 15 [102528/225000 (46%)] Loss: 20854.152344\n",
      "Train Epoch: 15 [105024/225000 (47%)] Loss: 20611.675781\n",
      "Train Epoch: 15 [107520/225000 (48%)] Loss: 20009.800781\n",
      "Train Epoch: 15 [110016/225000 (49%)] Loss: 20692.085938\n",
      "Train Epoch: 15 [112512/225000 (50%)] Loss: 20927.455078\n",
      "Train Epoch: 15 [115008/225000 (51%)] Loss: 20335.625000\n",
      "Train Epoch: 15 [117504/225000 (52%)] Loss: 20615.712891\n",
      "Train Epoch: 15 [120000/225000 (53%)] Loss: 20772.156250\n",
      "Train Epoch: 15 [122496/225000 (54%)] Loss: 20595.691406\n",
      "Train Epoch: 15 [124992/225000 (56%)] Loss: 20569.339844\n",
      "Train Epoch: 15 [127488/225000 (57%)] Loss: 20378.707031\n",
      "Train Epoch: 15 [129984/225000 (58%)] Loss: 21134.605469\n",
      "Train Epoch: 15 [132480/225000 (59%)] Loss: 20657.468750\n",
      "Train Epoch: 15 [134976/225000 (60%)] Loss: 20801.078125\n",
      "Train Epoch: 15 [137472/225000 (61%)] Loss: 20415.185547\n",
      "Train Epoch: 15 [139968/225000 (62%)] Loss: 20869.773438\n",
      "Train Epoch: 15 [142464/225000 (63%)] Loss: 20637.011719\n",
      "Train Epoch: 15 [144960/225000 (64%)] Loss: 20485.625000\n",
      "Train Epoch: 15 [147456/225000 (66%)] Loss: 20717.240234\n",
      "Train Epoch: 15 [149952/225000 (67%)] Loss: 20257.826172\n",
      "Train Epoch: 15 [152448/225000 (68%)] Loss: 20495.148438\n",
      "Train Epoch: 15 [154944/225000 (69%)] Loss: 20709.013672\n",
      "Train Epoch: 15 [157440/225000 (70%)] Loss: 20677.371094\n",
      "Train Epoch: 15 [159936/225000 (71%)] Loss: 21055.125000\n",
      "Train Epoch: 15 [162432/225000 (72%)] Loss: 20916.210938\n",
      "Train Epoch: 15 [164928/225000 (73%)] Loss: 20644.832031\n",
      "Train Epoch: 15 [167424/225000 (74%)] Loss: 20731.523438\n",
      "Train Epoch: 15 [169920/225000 (76%)] Loss: 20754.513672\n",
      "Train Epoch: 15 [172416/225000 (77%)] Loss: 20442.574219\n",
      "Train Epoch: 15 [174912/225000 (78%)] Loss: 20746.744141\n",
      "Train Epoch: 15 [177408/225000 (79%)] Loss: 20207.601562\n",
      "Train Epoch: 15 [179904/225000 (80%)] Loss: 20362.937500\n",
      "Train Epoch: 15 [182400/225000 (81%)] Loss: 20857.359375\n",
      "Train Epoch: 15 [184896/225000 (82%)] Loss: 20238.996094\n",
      "Train Epoch: 15 [187392/225000 (83%)] Loss: 20680.976562\n",
      "Train Epoch: 15 [189888/225000 (84%)] Loss: 20361.457031\n",
      "Train Epoch: 15 [192384/225000 (86%)] Loss: 20806.677734\n",
      "Train Epoch: 15 [194880/225000 (87%)] Loss: 20562.917969\n",
      "Train Epoch: 15 [197376/225000 (88%)] Loss: 20514.355469\n",
      "Train Epoch: 15 [199872/225000 (89%)] Loss: 20634.128906\n",
      "Train Epoch: 15 [202368/225000 (90%)] Loss: 20625.087891\n",
      "Train Epoch: 15 [204864/225000 (91%)] Loss: 20412.962891\n",
      "Train Epoch: 15 [207360/225000 (92%)] Loss: 20642.531250\n",
      "Train Epoch: 15 [209856/225000 (93%)] Loss: 20565.710938\n",
      "Train Epoch: 15 [212352/225000 (94%)] Loss: 20645.671875\n",
      "Train Epoch: 15 [214848/225000 (95%)] Loss: 20505.529297\n",
      "Train Epoch: 15 [217344/225000 (97%)] Loss: 20461.914062\n",
      "Train Epoch: 15 [219840/225000 (98%)] Loss: 20345.933594\n",
      "Train Epoch: 15 [222336/225000 (99%)] Loss: 20552.347656\n",
      "Train Epoch: 15 [224832/225000 (100%)] Loss: 20358.980469\n",
      "    epoch          : 15\n",
      "    loss           : 20596.641134945607\n",
      "    val_loss       : 20466.279485934563\n",
      "Train Epoch: 16 [192/225000 (0%)] Loss: 20789.519531\n",
      "Train Epoch: 16 [2688/225000 (1%)] Loss: 20745.849609\n",
      "Train Epoch: 16 [5184/225000 (2%)] Loss: 20688.476562\n",
      "Train Epoch: 16 [7680/225000 (3%)] Loss: 20770.933594\n",
      "Train Epoch: 16 [10176/225000 (5%)] Loss: 20604.167969\n",
      "Train Epoch: 16 [12672/225000 (6%)] Loss: 20503.128906\n",
      "Train Epoch: 16 [15168/225000 (7%)] Loss: 20851.867188\n",
      "Train Epoch: 16 [17664/225000 (8%)] Loss: 20627.832031\n",
      "Train Epoch: 16 [20160/225000 (9%)] Loss: 20121.222656\n",
      "Train Epoch: 16 [22656/225000 (10%)] Loss: 20714.966797\n",
      "Train Epoch: 16 [25152/225000 (11%)] Loss: 20847.187500\n",
      "Train Epoch: 16 [27648/225000 (12%)] Loss: 20222.867188\n",
      "Train Epoch: 16 [30144/225000 (13%)] Loss: 20516.687500\n",
      "Train Epoch: 16 [32640/225000 (15%)] Loss: 20341.542969\n",
      "Train Epoch: 16 [35136/225000 (16%)] Loss: 20653.664062\n",
      "Train Epoch: 16 [37632/225000 (17%)] Loss: 20685.207031\n",
      "Train Epoch: 16 [40128/225000 (18%)] Loss: 20418.724609\n",
      "Train Epoch: 16 [42624/225000 (19%)] Loss: 20437.875000\n",
      "Train Epoch: 16 [45120/225000 (20%)] Loss: 20589.919922\n",
      "Train Epoch: 16 [47616/225000 (21%)] Loss: 20539.203125\n",
      "Train Epoch: 16 [50112/225000 (22%)] Loss: 20204.703125\n",
      "Train Epoch: 16 [52608/225000 (23%)] Loss: 20754.509766\n",
      "Train Epoch: 16 [55104/225000 (24%)] Loss: 21102.597656\n",
      "Train Epoch: 16 [57600/225000 (26%)] Loss: 20191.078125\n",
      "Train Epoch: 16 [60096/225000 (27%)] Loss: 20360.214844\n",
      "Train Epoch: 16 [62592/225000 (28%)] Loss: 20461.779297\n",
      "Train Epoch: 16 [65088/225000 (29%)] Loss: 20279.191406\n",
      "Train Epoch: 16 [67584/225000 (30%)] Loss: 20694.767578\n",
      "Train Epoch: 16 [70080/225000 (31%)] Loss: 20633.777344\n",
      "Train Epoch: 16 [72576/225000 (32%)] Loss: 20472.097656\n",
      "Train Epoch: 16 [75072/225000 (33%)] Loss: 20843.101562\n",
      "Train Epoch: 16 [77568/225000 (34%)] Loss: 20956.437500\n",
      "Train Epoch: 16 [80064/225000 (36%)] Loss: 20535.753906\n",
      "Train Epoch: 16 [82560/225000 (37%)] Loss: 20702.480469\n",
      "Train Epoch: 16 [85056/225000 (38%)] Loss: 20455.800781\n",
      "Train Epoch: 16 [87552/225000 (39%)] Loss: 20541.386719\n",
      "Train Epoch: 16 [90048/225000 (40%)] Loss: 20341.416016\n",
      "Train Epoch: 16 [92544/225000 (41%)] Loss: 20999.419922\n",
      "Train Epoch: 16 [95040/225000 (42%)] Loss: 20297.765625\n",
      "Train Epoch: 16 [97536/225000 (43%)] Loss: 20672.148438\n",
      "Train Epoch: 16 [100032/225000 (44%)] Loss: 20475.292969\n",
      "Train Epoch: 16 [102528/225000 (46%)] Loss: 20387.384766\n",
      "Train Epoch: 16 [105024/225000 (47%)] Loss: 20359.011719\n",
      "Train Epoch: 16 [107520/225000 (48%)] Loss: 20252.660156\n",
      "Train Epoch: 16 [110016/225000 (49%)] Loss: 20127.593750\n",
      "Train Epoch: 16 [112512/225000 (50%)] Loss: 20412.597656\n",
      "Train Epoch: 16 [115008/225000 (51%)] Loss: 20475.406250\n",
      "Train Epoch: 16 [117504/225000 (52%)] Loss: 20569.800781\n",
      "Train Epoch: 16 [120000/225000 (53%)] Loss: 20655.431641\n",
      "Train Epoch: 16 [122496/225000 (54%)] Loss: 20274.703125\n",
      "Train Epoch: 16 [124992/225000 (56%)] Loss: 20538.953125\n",
      "Train Epoch: 16 [127488/225000 (57%)] Loss: 20487.560547\n",
      "Train Epoch: 16 [129984/225000 (58%)] Loss: 20601.984375\n",
      "Train Epoch: 16 [132480/225000 (59%)] Loss: 20519.972656\n",
      "Train Epoch: 16 [134976/225000 (60%)] Loss: 20322.902344\n",
      "Train Epoch: 16 [137472/225000 (61%)] Loss: 20429.796875\n",
      "Train Epoch: 16 [139968/225000 (62%)] Loss: 20667.431641\n",
      "Train Epoch: 16 [142464/225000 (63%)] Loss: 20995.937500\n",
      "Train Epoch: 16 [144960/225000 (64%)] Loss: 20414.156250\n",
      "Train Epoch: 16 [147456/225000 (66%)] Loss: 34785.375000\n",
      "Train Epoch: 16 [149952/225000 (67%)] Loss: 20601.585938\n",
      "Train Epoch: 16 [152448/225000 (68%)] Loss: 20086.187500\n",
      "Train Epoch: 16 [154944/225000 (69%)] Loss: 20125.652344\n",
      "Train Epoch: 16 [157440/225000 (70%)] Loss: 20542.912109\n",
      "Train Epoch: 16 [159936/225000 (71%)] Loss: 20643.214844\n",
      "Train Epoch: 16 [162432/225000 (72%)] Loss: 20478.105469\n",
      "Train Epoch: 16 [164928/225000 (73%)] Loss: 20690.380859\n",
      "Train Epoch: 16 [167424/225000 (74%)] Loss: 20336.199219\n",
      "Train Epoch: 16 [169920/225000 (76%)] Loss: 20028.937500\n",
      "Train Epoch: 16 [172416/225000 (77%)] Loss: 20813.082031\n",
      "Train Epoch: 16 [174912/225000 (78%)] Loss: 20624.968750\n",
      "Train Epoch: 16 [177408/225000 (79%)] Loss: 20786.371094\n",
      "Train Epoch: 16 [179904/225000 (80%)] Loss: 20638.304688\n",
      "Train Epoch: 16 [182400/225000 (81%)] Loss: 20145.832031\n",
      "Train Epoch: 16 [184896/225000 (82%)] Loss: 21225.386719\n",
      "Train Epoch: 16 [187392/225000 (83%)] Loss: 20143.207031\n",
      "Train Epoch: 16 [189888/225000 (84%)] Loss: 20318.453125\n",
      "Train Epoch: 16 [192384/225000 (86%)] Loss: 20636.542969\n",
      "Train Epoch: 16 [194880/225000 (87%)] Loss: 20382.585938\n",
      "Train Epoch: 16 [197376/225000 (88%)] Loss: 20557.347656\n",
      "Train Epoch: 16 [199872/225000 (89%)] Loss: 20897.054688\n",
      "Train Epoch: 16 [202368/225000 (90%)] Loss: 20625.882812\n",
      "Train Epoch: 16 [204864/225000 (91%)] Loss: 20249.931641\n",
      "Train Epoch: 16 [207360/225000 (92%)] Loss: 20270.277344\n",
      "Train Epoch: 16 [209856/225000 (93%)] Loss: 20625.625000\n",
      "Train Epoch: 16 [212352/225000 (94%)] Loss: 20035.976562\n",
      "Train Epoch: 16 [214848/225000 (95%)] Loss: 20512.046875\n",
      "Train Epoch: 16 [217344/225000 (97%)] Loss: 20310.240234\n",
      "Train Epoch: 16 [219840/225000 (98%)] Loss: 20376.996094\n",
      "Train Epoch: 16 [222336/225000 (99%)] Loss: 20806.238281\n",
      "Train Epoch: 16 [224832/225000 (100%)] Loss: 20372.128906\n",
      "    epoch          : 16\n",
      "    loss           : 20580.31902763705\n",
      "    val_loss       : 20444.791617218776\n",
      "Train Epoch: 17 [192/225000 (0%)] Loss: 20594.402344\n",
      "Train Epoch: 17 [2688/225000 (1%)] Loss: 20050.281250\n",
      "Train Epoch: 17 [5184/225000 (2%)] Loss: 20266.296875\n",
      "Train Epoch: 17 [7680/225000 (3%)] Loss: 20538.439453\n",
      "Train Epoch: 17 [10176/225000 (5%)] Loss: 20605.292969\n",
      "Train Epoch: 17 [12672/225000 (6%)] Loss: 20864.095703\n",
      "Train Epoch: 17 [15168/225000 (7%)] Loss: 20898.140625\n",
      "Train Epoch: 17 [17664/225000 (8%)] Loss: 20815.218750\n",
      "Train Epoch: 17 [20160/225000 (9%)] Loss: 20648.238281\n",
      "Train Epoch: 17 [22656/225000 (10%)] Loss: 20488.539062\n",
      "Train Epoch: 17 [25152/225000 (11%)] Loss: 20706.988281\n",
      "Train Epoch: 17 [27648/225000 (12%)] Loss: 20247.675781\n",
      "Train Epoch: 17 [30144/225000 (13%)] Loss: 20452.937500\n",
      "Train Epoch: 17 [32640/225000 (15%)] Loss: 20983.925781\n",
      "Train Epoch: 17 [35136/225000 (16%)] Loss: 20301.925781\n",
      "Train Epoch: 17 [37632/225000 (17%)] Loss: 20120.835938\n",
      "Train Epoch: 17 [40128/225000 (18%)] Loss: 20570.488281\n",
      "Train Epoch: 17 [42624/225000 (19%)] Loss: 20724.261719\n",
      "Train Epoch: 17 [45120/225000 (20%)] Loss: 20944.625000\n",
      "Train Epoch: 17 [47616/225000 (21%)] Loss: 20570.464844\n",
      "Train Epoch: 17 [50112/225000 (22%)] Loss: 20495.283203\n",
      "Train Epoch: 17 [52608/225000 (23%)] Loss: 20619.916016\n",
      "Train Epoch: 17 [55104/225000 (24%)] Loss: 20646.070312\n",
      "Train Epoch: 17 [57600/225000 (26%)] Loss: 20590.140625\n",
      "Train Epoch: 17 [60096/225000 (27%)] Loss: 20778.679688\n",
      "Train Epoch: 17 [62592/225000 (28%)] Loss: 20524.343750\n",
      "Train Epoch: 17 [65088/225000 (29%)] Loss: 20722.179688\n",
      "Train Epoch: 17 [67584/225000 (30%)] Loss: 20226.464844\n",
      "Train Epoch: 17 [70080/225000 (31%)] Loss: 20486.072266\n",
      "Train Epoch: 17 [72576/225000 (32%)] Loss: 20198.808594\n",
      "Train Epoch: 17 [75072/225000 (33%)] Loss: 20444.785156\n",
      "Train Epoch: 17 [77568/225000 (34%)] Loss: 19777.097656\n",
      "Train Epoch: 17 [80064/225000 (36%)] Loss: 20701.882812\n",
      "Train Epoch: 17 [82560/225000 (37%)] Loss: 20212.591797\n",
      "Train Epoch: 17 [85056/225000 (38%)] Loss: 20687.353516\n",
      "Train Epoch: 17 [87552/225000 (39%)] Loss: 21097.136719\n",
      "Train Epoch: 17 [90048/225000 (40%)] Loss: 20443.779297\n",
      "Train Epoch: 17 [92544/225000 (41%)] Loss: 20603.417969\n",
      "Train Epoch: 17 [95040/225000 (42%)] Loss: 20590.195312\n",
      "Train Epoch: 17 [97536/225000 (43%)] Loss: 20468.523438\n",
      "Train Epoch: 17 [100032/225000 (44%)] Loss: 20291.320312\n",
      "Train Epoch: 17 [102528/225000 (46%)] Loss: 20646.587891\n",
      "Train Epoch: 17 [105024/225000 (47%)] Loss: 20195.148438\n",
      "Train Epoch: 17 [107520/225000 (48%)] Loss: 20657.531250\n",
      "Train Epoch: 17 [110016/225000 (49%)] Loss: 20737.005859\n",
      "Train Epoch: 17 [112512/225000 (50%)] Loss: 20084.460938\n",
      "Train Epoch: 17 [115008/225000 (51%)] Loss: 20360.396484\n",
      "Train Epoch: 17 [117504/225000 (52%)] Loss: 20193.906250\n",
      "Train Epoch: 17 [120000/225000 (53%)] Loss: 20987.445312\n",
      "Train Epoch: 17 [122496/225000 (54%)] Loss: 20991.912109\n",
      "Train Epoch: 17 [124992/225000 (56%)] Loss: 20341.343750\n",
      "Train Epoch: 17 [127488/225000 (57%)] Loss: 20171.183594\n",
      "Train Epoch: 17 [129984/225000 (58%)] Loss: 20331.199219\n",
      "Train Epoch: 17 [132480/225000 (59%)] Loss: 25477.992188\n",
      "Train Epoch: 17 [134976/225000 (60%)] Loss: 20614.609375\n",
      "Train Epoch: 17 [137472/225000 (61%)] Loss: 20720.789062\n",
      "Train Epoch: 17 [139968/225000 (62%)] Loss: 20574.958984\n",
      "Train Epoch: 17 [142464/225000 (63%)] Loss: 19930.886719\n",
      "Train Epoch: 17 [144960/225000 (64%)] Loss: 20353.660156\n",
      "Train Epoch: 17 [147456/225000 (66%)] Loss: 20052.167969\n",
      "Train Epoch: 17 [149952/225000 (67%)] Loss: 20375.589844\n",
      "Train Epoch: 17 [152448/225000 (68%)] Loss: 20429.597656\n",
      "Train Epoch: 17 [154944/225000 (69%)] Loss: 20349.806641\n",
      "Train Epoch: 17 [157440/225000 (70%)] Loss: 20276.326172\n",
      "Train Epoch: 17 [159936/225000 (71%)] Loss: 20634.511719\n",
      "Train Epoch: 17 [162432/225000 (72%)] Loss: 20849.660156\n",
      "Train Epoch: 17 [164928/225000 (73%)] Loss: 20120.921875\n",
      "Train Epoch: 17 [167424/225000 (74%)] Loss: 20759.083984\n",
      "Train Epoch: 17 [169920/225000 (76%)] Loss: 20491.320312\n",
      "Train Epoch: 17 [172416/225000 (77%)] Loss: 20528.816406\n",
      "Train Epoch: 17 [174912/225000 (78%)] Loss: 20465.269531\n",
      "Train Epoch: 17 [177408/225000 (79%)] Loss: 20144.169922\n",
      "Train Epoch: 17 [179904/225000 (80%)] Loss: 20607.757812\n",
      "Train Epoch: 17 [182400/225000 (81%)] Loss: 20997.835938\n",
      "Train Epoch: 17 [184896/225000 (82%)] Loss: 21182.644531\n",
      "Train Epoch: 17 [187392/225000 (83%)] Loss: 20917.460938\n",
      "Train Epoch: 17 [189888/225000 (84%)] Loss: 20479.361328\n",
      "Train Epoch: 17 [192384/225000 (86%)] Loss: 20661.390625\n",
      "Train Epoch: 17 [194880/225000 (87%)] Loss: 20657.527344\n",
      "Train Epoch: 17 [197376/225000 (88%)] Loss: 20790.488281\n",
      "Train Epoch: 17 [199872/225000 (89%)] Loss: 20078.308594\n",
      "Train Epoch: 17 [202368/225000 (90%)] Loss: 20252.300781\n",
      "Train Epoch: 17 [204864/225000 (91%)] Loss: 20686.980469\n",
      "Train Epoch: 17 [207360/225000 (92%)] Loss: 19838.335938\n",
      "Train Epoch: 17 [209856/225000 (93%)] Loss: 20744.347656\n",
      "Train Epoch: 17 [212352/225000 (94%)] Loss: 21096.242188\n",
      "Train Epoch: 17 [214848/225000 (95%)] Loss: 20506.132812\n",
      "Train Epoch: 17 [217344/225000 (97%)] Loss: 20765.080078\n",
      "Train Epoch: 17 [219840/225000 (98%)] Loss: 20461.080078\n",
      "Train Epoch: 17 [222336/225000 (99%)] Loss: 21032.369141\n",
      "Train Epoch: 17 [224832/225000 (100%)] Loss: 20542.083984\n",
      "    epoch          : 17\n",
      "    loss           : 20557.082864494452\n",
      "    val_loss       : 20576.218766398102\n",
      "Train Epoch: 18 [192/225000 (0%)] Loss: 20458.800781\n",
      "Train Epoch: 18 [2688/225000 (1%)] Loss: 20818.230469\n",
      "Train Epoch: 18 [5184/225000 (2%)] Loss: 20630.994141\n",
      "Train Epoch: 18 [7680/225000 (3%)] Loss: 20491.601562\n",
      "Train Epoch: 18 [10176/225000 (5%)] Loss: 20242.156250\n",
      "Train Epoch: 18 [12672/225000 (6%)] Loss: 20320.031250\n",
      "Train Epoch: 18 [15168/225000 (7%)] Loss: 20146.619141\n",
      "Train Epoch: 18 [17664/225000 (8%)] Loss: 20333.515625\n",
      "Train Epoch: 18 [20160/225000 (9%)] Loss: 20121.671875\n",
      "Train Epoch: 18 [22656/225000 (10%)] Loss: 20958.419922\n",
      "Train Epoch: 18 [25152/225000 (11%)] Loss: 20410.273438\n",
      "Train Epoch: 18 [27648/225000 (12%)] Loss: 20413.062500\n",
      "Train Epoch: 18 [30144/225000 (13%)] Loss: 20695.000000\n",
      "Train Epoch: 18 [32640/225000 (15%)] Loss: 20490.875000\n",
      "Train Epoch: 18 [35136/225000 (16%)] Loss: 20392.640625\n",
      "Train Epoch: 18 [37632/225000 (17%)] Loss: 20533.642578\n",
      "Train Epoch: 18 [40128/225000 (18%)] Loss: 20780.851562\n",
      "Train Epoch: 18 [42624/225000 (19%)] Loss: 20278.876953\n",
      "Train Epoch: 18 [45120/225000 (20%)] Loss: 20429.427734\n",
      "Train Epoch: 18 [47616/225000 (21%)] Loss: 20335.550781\n",
      "Train Epoch: 18 [50112/225000 (22%)] Loss: 20612.656250\n",
      "Train Epoch: 18 [52608/225000 (23%)] Loss: 19997.050781\n",
      "Train Epoch: 18 [55104/225000 (24%)] Loss: 20467.353516\n",
      "Train Epoch: 18 [57600/225000 (26%)] Loss: 20881.705078\n",
      "Train Epoch: 18 [60096/225000 (27%)] Loss: 20801.050781\n",
      "Train Epoch: 18 [62592/225000 (28%)] Loss: 20796.890625\n",
      "Train Epoch: 18 [65088/225000 (29%)] Loss: 20722.191406\n",
      "Train Epoch: 18 [67584/225000 (30%)] Loss: 20584.074219\n",
      "Train Epoch: 18 [70080/225000 (31%)] Loss: 20097.832031\n",
      "Train Epoch: 18 [72576/225000 (32%)] Loss: 20206.103516\n",
      "Train Epoch: 18 [75072/225000 (33%)] Loss: 20428.939453\n",
      "Train Epoch: 18 [77568/225000 (34%)] Loss: 20874.531250\n",
      "Train Epoch: 18 [80064/225000 (36%)] Loss: 20360.607422\n",
      "Train Epoch: 18 [82560/225000 (37%)] Loss: 20644.267578\n",
      "Train Epoch: 18 [85056/225000 (38%)] Loss: 21000.093750\n",
      "Train Epoch: 18 [87552/225000 (39%)] Loss: 20678.369141\n",
      "Train Epoch: 18 [90048/225000 (40%)] Loss: 20438.933594\n",
      "Train Epoch: 18 [92544/225000 (41%)] Loss: 20752.765625\n",
      "Train Epoch: 18 [95040/225000 (42%)] Loss: 20344.113281\n",
      "Train Epoch: 18 [97536/225000 (43%)] Loss: 20391.453125\n",
      "Train Epoch: 18 [100032/225000 (44%)] Loss: 20416.003906\n",
      "Train Epoch: 18 [102528/225000 (46%)] Loss: 20850.673828\n",
      "Train Epoch: 18 [105024/225000 (47%)] Loss: 20654.591797\n",
      "Train Epoch: 18 [107520/225000 (48%)] Loss: 20787.095703\n",
      "Train Epoch: 18 [110016/225000 (49%)] Loss: 20696.929688\n",
      "Train Epoch: 18 [112512/225000 (50%)] Loss: 20775.035156\n",
      "Train Epoch: 18 [115008/225000 (51%)] Loss: 20369.804688\n",
      "Train Epoch: 18 [117504/225000 (52%)] Loss: 20362.392578\n",
      "Train Epoch: 18 [120000/225000 (53%)] Loss: 20894.613281\n",
      "Train Epoch: 18 [122496/225000 (54%)] Loss: 20575.736328\n",
      "Train Epoch: 18 [124992/225000 (56%)] Loss: 20516.003906\n",
      "Train Epoch: 18 [127488/225000 (57%)] Loss: 21104.191406\n",
      "Train Epoch: 18 [129984/225000 (58%)] Loss: 20650.285156\n",
      "Train Epoch: 18 [132480/225000 (59%)] Loss: 20288.964844\n",
      "Train Epoch: 18 [134976/225000 (60%)] Loss: 20196.792969\n",
      "Train Epoch: 18 [137472/225000 (61%)] Loss: 20585.970703\n",
      "Train Epoch: 18 [139968/225000 (62%)] Loss: 20249.628906\n",
      "Train Epoch: 18 [142464/225000 (63%)] Loss: 20481.310547\n",
      "Train Epoch: 18 [144960/225000 (64%)] Loss: 20137.041016\n",
      "Train Epoch: 18 [147456/225000 (66%)] Loss: 20787.558594\n",
      "Train Epoch: 18 [149952/225000 (67%)] Loss: 20421.660156\n",
      "Train Epoch: 18 [152448/225000 (68%)] Loss: 20127.429688\n",
      "Train Epoch: 18 [154944/225000 (69%)] Loss: 20940.640625\n",
      "Train Epoch: 18 [157440/225000 (70%)] Loss: 20473.767578\n",
      "Train Epoch: 18 [159936/225000 (71%)] Loss: 20297.433594\n",
      "Train Epoch: 18 [162432/225000 (72%)] Loss: 20216.664062\n",
      "Train Epoch: 18 [164928/225000 (73%)] Loss: 20154.183594\n",
      "Train Epoch: 18 [167424/225000 (74%)] Loss: 19963.980469\n",
      "Train Epoch: 18 [169920/225000 (76%)] Loss: 20789.605469\n",
      "Train Epoch: 18 [172416/225000 (77%)] Loss: 20460.964844\n",
      "Train Epoch: 18 [174912/225000 (78%)] Loss: 20265.867188\n",
      "Train Epoch: 18 [177408/225000 (79%)] Loss: 20881.146484\n",
      "Train Epoch: 18 [179904/225000 (80%)] Loss: 20765.589844\n",
      "Train Epoch: 18 [182400/225000 (81%)] Loss: 20424.503906\n",
      "Train Epoch: 18 [184896/225000 (82%)] Loss: 20924.023438\n",
      "Train Epoch: 18 [187392/225000 (83%)] Loss: 20111.617188\n",
      "Train Epoch: 18 [189888/225000 (84%)] Loss: 20554.703125\n",
      "Train Epoch: 18 [192384/225000 (86%)] Loss: 20894.898438\n",
      "Train Epoch: 18 [194880/225000 (87%)] Loss: 20063.978516\n",
      "Train Epoch: 18 [197376/225000 (88%)] Loss: 19973.867188\n",
      "Train Epoch: 18 [199872/225000 (89%)] Loss: 20591.003906\n",
      "Train Epoch: 18 [202368/225000 (90%)] Loss: 20520.519531\n",
      "Train Epoch: 18 [204864/225000 (91%)] Loss: 20740.833984\n",
      "Train Epoch: 18 [207360/225000 (92%)] Loss: 20752.177734\n",
      "Train Epoch: 18 [209856/225000 (93%)] Loss: 20677.804688\n",
      "Train Epoch: 18 [212352/225000 (94%)] Loss: 20421.884766\n",
      "Train Epoch: 18 [214848/225000 (95%)] Loss: 20410.236328\n",
      "Train Epoch: 18 [217344/225000 (97%)] Loss: 21035.955078\n",
      "Train Epoch: 18 [219840/225000 (98%)] Loss: 20717.472656\n",
      "Train Epoch: 18 [222336/225000 (99%)] Loss: 20134.984375\n",
      "Train Epoch: 18 [224832/225000 (100%)] Loss: 20371.761719\n",
      "    epoch          : 18\n",
      "    loss           : 20526.599939339805\n",
      "    val_loss       : 20509.79514004802\n",
      "Train Epoch: 19 [192/225000 (0%)] Loss: 19966.291016\n",
      "Train Epoch: 19 [2688/225000 (1%)] Loss: 20373.712891\n",
      "Train Epoch: 19 [5184/225000 (2%)] Loss: 20530.941406\n",
      "Train Epoch: 19 [7680/225000 (3%)] Loss: 20853.570312\n",
      "Train Epoch: 19 [10176/225000 (5%)] Loss: 20683.785156\n",
      "Train Epoch: 19 [12672/225000 (6%)] Loss: 20442.628906\n",
      "Train Epoch: 19 [15168/225000 (7%)] Loss: 20507.421875\n",
      "Train Epoch: 19 [17664/225000 (8%)] Loss: 20588.761719\n",
      "Train Epoch: 19 [20160/225000 (9%)] Loss: 20366.472656\n",
      "Train Epoch: 19 [22656/225000 (10%)] Loss: 20722.261719\n",
      "Train Epoch: 19 [25152/225000 (11%)] Loss: 19668.320312\n",
      "Train Epoch: 19 [27648/225000 (12%)] Loss: 20894.261719\n",
      "Train Epoch: 19 [30144/225000 (13%)] Loss: 20204.503906\n",
      "Train Epoch: 19 [32640/225000 (15%)] Loss: 20937.339844\n",
      "Train Epoch: 19 [35136/225000 (16%)] Loss: 20685.197266\n",
      "Train Epoch: 19 [37632/225000 (17%)] Loss: 20645.041016\n",
      "Train Epoch: 19 [40128/225000 (18%)] Loss: 20151.195312\n",
      "Train Epoch: 19 [42624/225000 (19%)] Loss: 20830.083984\n",
      "Train Epoch: 19 [45120/225000 (20%)] Loss: 20398.886719\n",
      "Train Epoch: 19 [47616/225000 (21%)] Loss: 20469.769531\n",
      "Train Epoch: 19 [50112/225000 (22%)] Loss: 20758.156250\n",
      "Train Epoch: 19 [52608/225000 (23%)] Loss: 20142.781250\n",
      "Train Epoch: 19 [55104/225000 (24%)] Loss: 20685.728516\n",
      "Train Epoch: 19 [57600/225000 (26%)] Loss: 19851.292969\n",
      "Train Epoch: 19 [60096/225000 (27%)] Loss: 20438.000000\n",
      "Train Epoch: 19 [62592/225000 (28%)] Loss: 20883.167969\n",
      "Train Epoch: 19 [65088/225000 (29%)] Loss: 20865.480469\n",
      "Train Epoch: 19 [67584/225000 (30%)] Loss: 20181.109375\n",
      "Train Epoch: 19 [70080/225000 (31%)] Loss: 20783.316406\n",
      "Train Epoch: 19 [72576/225000 (32%)] Loss: 20386.537109\n",
      "Train Epoch: 19 [75072/225000 (33%)] Loss: 20549.347656\n",
      "Train Epoch: 19 [77568/225000 (34%)] Loss: 20619.843750\n",
      "Train Epoch: 19 [80064/225000 (36%)] Loss: 19740.003906\n",
      "Train Epoch: 19 [82560/225000 (37%)] Loss: 20277.628906\n",
      "Train Epoch: 19 [85056/225000 (38%)] Loss: 20496.976562\n",
      "Train Epoch: 19 [87552/225000 (39%)] Loss: 20477.744141\n",
      "Train Epoch: 19 [90048/225000 (40%)] Loss: 20028.683594\n",
      "Train Epoch: 19 [92544/225000 (41%)] Loss: 20290.589844\n",
      "Train Epoch: 19 [95040/225000 (42%)] Loss: 20354.539062\n",
      "Train Epoch: 19 [97536/225000 (43%)] Loss: 20549.468750\n",
      "Train Epoch: 19 [100032/225000 (44%)] Loss: 20301.720703\n",
      "Train Epoch: 19 [102528/225000 (46%)] Loss: 20659.373047\n",
      "Train Epoch: 19 [105024/225000 (47%)] Loss: 20897.160156\n",
      "Train Epoch: 19 [107520/225000 (48%)] Loss: 20265.626953\n",
      "Train Epoch: 19 [110016/225000 (49%)] Loss: 20409.701172\n",
      "Train Epoch: 19 [112512/225000 (50%)] Loss: 20204.552734\n",
      "Train Epoch: 19 [115008/225000 (51%)] Loss: 20168.914062\n",
      "Train Epoch: 19 [117504/225000 (52%)] Loss: 20509.730469\n",
      "Train Epoch: 19 [120000/225000 (53%)] Loss: 20067.515625\n",
      "Train Epoch: 19 [122496/225000 (54%)] Loss: 20719.388672\n",
      "Train Epoch: 19 [124992/225000 (56%)] Loss: 20425.449219\n",
      "Train Epoch: 19 [127488/225000 (57%)] Loss: 20681.824219\n",
      "Train Epoch: 19 [129984/225000 (58%)] Loss: 20306.001953\n",
      "Train Epoch: 19 [132480/225000 (59%)] Loss: 20800.652344\n",
      "Train Epoch: 19 [134976/225000 (60%)] Loss: 20210.667969\n",
      "Train Epoch: 19 [137472/225000 (61%)] Loss: 20240.273438\n",
      "Train Epoch: 19 [139968/225000 (62%)] Loss: 20669.246094\n",
      "Train Epoch: 19 [142464/225000 (63%)] Loss: 20783.853516\n",
      "Train Epoch: 19 [144960/225000 (64%)] Loss: 20175.152344\n",
      "Train Epoch: 19 [147456/225000 (66%)] Loss: 19834.640625\n",
      "Train Epoch: 19 [149952/225000 (67%)] Loss: 21301.000000\n",
      "Train Epoch: 19 [152448/225000 (68%)] Loss: 20675.753906\n",
      "Train Epoch: 19 [154944/225000 (69%)] Loss: 20068.943359\n",
      "Train Epoch: 19 [157440/225000 (70%)] Loss: 20800.699219\n",
      "Train Epoch: 19 [159936/225000 (71%)] Loss: 20518.849609\n",
      "Train Epoch: 19 [162432/225000 (72%)] Loss: 20591.976562\n",
      "Train Epoch: 19 [164928/225000 (73%)] Loss: 20882.509766\n",
      "Train Epoch: 19 [167424/225000 (74%)] Loss: 20831.142578\n",
      "Train Epoch: 19 [169920/225000 (76%)] Loss: 20659.550781\n",
      "Train Epoch: 19 [172416/225000 (77%)] Loss: 20487.960938\n",
      "Train Epoch: 19 [174912/225000 (78%)] Loss: 20011.375000\n",
      "Train Epoch: 19 [177408/225000 (79%)] Loss: 20557.335938\n",
      "Train Epoch: 19 [179904/225000 (80%)] Loss: 20581.988281\n",
      "Train Epoch: 19 [182400/225000 (81%)] Loss: 21086.207031\n",
      "Train Epoch: 19 [184896/225000 (82%)] Loss: 20502.654297\n",
      "Train Epoch: 19 [187392/225000 (83%)] Loss: 20575.593750\n",
      "Train Epoch: 19 [189888/225000 (84%)] Loss: 20332.804688\n",
      "Train Epoch: 19 [192384/225000 (86%)] Loss: 20265.449219\n",
      "Train Epoch: 19 [194880/225000 (87%)] Loss: 20067.355469\n",
      "Train Epoch: 19 [197376/225000 (88%)] Loss: 20008.843750\n",
      "Train Epoch: 19 [199872/225000 (89%)] Loss: 20526.921875\n",
      "Train Epoch: 19 [202368/225000 (90%)] Loss: 20021.193359\n",
      "Train Epoch: 19 [204864/225000 (91%)] Loss: 20982.675781\n",
      "Train Epoch: 19 [207360/225000 (92%)] Loss: 20826.523438\n",
      "Train Epoch: 19 [209856/225000 (93%)] Loss: 20052.085938\n",
      "Train Epoch: 19 [212352/225000 (94%)] Loss: 20866.888672\n",
      "Train Epoch: 19 [214848/225000 (95%)] Loss: 20165.435547\n",
      "Train Epoch: 19 [217344/225000 (97%)] Loss: 20694.613281\n",
      "Train Epoch: 19 [219840/225000 (98%)] Loss: 20297.605469\n",
      "Train Epoch: 19 [222336/225000 (99%)] Loss: 20312.457031\n",
      "Train Epoch: 19 [224832/225000 (100%)] Loss: 20396.755859\n",
      "    epoch          : 19\n",
      "    loss           : 20528.840395357827\n",
      "    val_loss       : 20376.98676357606\n",
      "Train Epoch: 20 [192/225000 (0%)] Loss: 20733.001953\n",
      "Train Epoch: 20 [2688/225000 (1%)] Loss: 20017.806641\n",
      "Train Epoch: 20 [5184/225000 (2%)] Loss: 20546.498047\n",
      "Train Epoch: 20 [7680/225000 (3%)] Loss: 20395.234375\n",
      "Train Epoch: 20 [10176/225000 (5%)] Loss: 19981.396484\n",
      "Train Epoch: 20 [12672/225000 (6%)] Loss: 20837.570312\n",
      "Train Epoch: 20 [15168/225000 (7%)] Loss: 20924.705078\n",
      "Train Epoch: 20 [17664/225000 (8%)] Loss: 20507.070312\n",
      "Train Epoch: 20 [20160/225000 (9%)] Loss: 20758.091797\n",
      "Train Epoch: 20 [22656/225000 (10%)] Loss: 20796.259766\n",
      "Train Epoch: 20 [25152/225000 (11%)] Loss: 20321.214844\n",
      "Train Epoch: 20 [27648/225000 (12%)] Loss: 20389.054688\n",
      "Train Epoch: 20 [30144/225000 (13%)] Loss: 20645.542969\n",
      "Train Epoch: 20 [32640/225000 (15%)] Loss: 20515.734375\n",
      "Train Epoch: 20 [35136/225000 (16%)] Loss: 20424.511719\n",
      "Train Epoch: 20 [37632/225000 (17%)] Loss: 20732.175781\n",
      "Train Epoch: 20 [40128/225000 (18%)] Loss: 20285.109375\n",
      "Train Epoch: 20 [42624/225000 (19%)] Loss: 20059.845703\n",
      "Train Epoch: 20 [45120/225000 (20%)] Loss: 20792.886719\n",
      "Train Epoch: 20 [47616/225000 (21%)] Loss: 20492.929688\n",
      "Train Epoch: 20 [50112/225000 (22%)] Loss: 20172.308594\n",
      "Train Epoch: 20 [52608/225000 (23%)] Loss: 20329.718750\n",
      "Train Epoch: 20 [55104/225000 (24%)] Loss: 20830.359375\n",
      "Train Epoch: 20 [57600/225000 (26%)] Loss: 20731.593750\n",
      "Train Epoch: 20 [60096/225000 (27%)] Loss: 20595.957031\n",
      "Train Epoch: 20 [62592/225000 (28%)] Loss: 20701.800781\n",
      "Train Epoch: 20 [65088/225000 (29%)] Loss: 20274.785156\n",
      "Train Epoch: 20 [67584/225000 (30%)] Loss: 20537.093750\n",
      "Train Epoch: 20 [70080/225000 (31%)] Loss: 20462.937500\n",
      "Train Epoch: 20 [72576/225000 (32%)] Loss: 20523.671875\n",
      "Train Epoch: 20 [75072/225000 (33%)] Loss: 20253.947266\n",
      "Train Epoch: 20 [77568/225000 (34%)] Loss: 20764.898438\n",
      "Train Epoch: 20 [80064/225000 (36%)] Loss: 20203.902344\n",
      "Train Epoch: 20 [82560/225000 (37%)] Loss: 20535.613281\n",
      "Train Epoch: 20 [85056/225000 (38%)] Loss: 20810.710938\n",
      "Train Epoch: 20 [87552/225000 (39%)] Loss: 20048.343750\n",
      "Train Epoch: 20 [90048/225000 (40%)] Loss: 20905.382812\n",
      "Train Epoch: 20 [92544/225000 (41%)] Loss: 20268.746094\n",
      "Train Epoch: 20 [95040/225000 (42%)] Loss: 19925.996094\n",
      "Train Epoch: 20 [97536/225000 (43%)] Loss: 20430.003906\n",
      "Train Epoch: 20 [100032/225000 (44%)] Loss: 20195.931641\n",
      "Train Epoch: 20 [102528/225000 (46%)] Loss: 20344.437500\n",
      "Train Epoch: 20 [105024/225000 (47%)] Loss: 20176.078125\n",
      "Train Epoch: 20 [107520/225000 (48%)] Loss: 20636.955078\n",
      "Train Epoch: 20 [110016/225000 (49%)] Loss: 20804.148438\n",
      "Train Epoch: 20 [112512/225000 (50%)] Loss: 20341.765625\n",
      "Train Epoch: 20 [115008/225000 (51%)] Loss: 20316.771484\n",
      "Train Epoch: 20 [117504/225000 (52%)] Loss: 20081.679688\n",
      "Train Epoch: 20 [120000/225000 (53%)] Loss: 20506.267578\n",
      "Train Epoch: 20 [122496/225000 (54%)] Loss: 20149.548828\n",
      "Train Epoch: 20 [124992/225000 (56%)] Loss: 20479.089844\n",
      "Train Epoch: 20 [127488/225000 (57%)] Loss: 20115.529297\n",
      "Train Epoch: 20 [129984/225000 (58%)] Loss: 20251.679688\n",
      "Train Epoch: 20 [132480/225000 (59%)] Loss: 20794.830078\n",
      "Train Epoch: 20 [134976/225000 (60%)] Loss: 20452.158203\n",
      "Train Epoch: 20 [137472/225000 (61%)] Loss: 20156.234375\n",
      "Train Epoch: 20 [139968/225000 (62%)] Loss: 20090.871094\n",
      "Train Epoch: 20 [142464/225000 (63%)] Loss: 20826.201172\n",
      "Train Epoch: 20 [144960/225000 (64%)] Loss: 20297.169922\n",
      "Train Epoch: 20 [147456/225000 (66%)] Loss: 20403.648438\n",
      "Train Epoch: 20 [149952/225000 (67%)] Loss: 20463.576172\n",
      "Train Epoch: 20 [152448/225000 (68%)] Loss: 20667.232422\n",
      "Train Epoch: 20 [154944/225000 (69%)] Loss: 20489.371094\n",
      "Train Epoch: 20 [157440/225000 (70%)] Loss: 20168.921875\n",
      "Train Epoch: 20 [159936/225000 (71%)] Loss: 20658.187500\n",
      "Train Epoch: 20 [162432/225000 (72%)] Loss: 19898.703125\n",
      "Train Epoch: 20 [164928/225000 (73%)] Loss: 20388.349609\n",
      "Train Epoch: 20 [167424/225000 (74%)] Loss: 20589.585938\n",
      "Train Epoch: 20 [169920/225000 (76%)] Loss: 20524.904297\n",
      "Train Epoch: 20 [172416/225000 (77%)] Loss: 20278.363281\n",
      "Train Epoch: 20 [174912/225000 (78%)] Loss: 20116.419922\n",
      "Train Epoch: 20 [177408/225000 (79%)] Loss: 20517.945312\n",
      "Train Epoch: 20 [179904/225000 (80%)] Loss: 20611.367188\n",
      "Train Epoch: 20 [182400/225000 (81%)] Loss: 20457.105469\n",
      "Train Epoch: 20 [184896/225000 (82%)] Loss: 20112.140625\n",
      "Train Epoch: 20 [187392/225000 (83%)] Loss: 20299.304688\n",
      "Train Epoch: 20 [189888/225000 (84%)] Loss: 20388.693359\n",
      "Train Epoch: 20 [192384/225000 (86%)] Loss: 20142.392578\n",
      "Train Epoch: 20 [194880/225000 (87%)] Loss: 21261.039062\n",
      "Train Epoch: 20 [197376/225000 (88%)] Loss: 20128.500000\n",
      "Train Epoch: 20 [199872/225000 (89%)] Loss: 20218.146484\n",
      "Train Epoch: 20 [202368/225000 (90%)] Loss: 20506.476562\n",
      "Train Epoch: 20 [204864/225000 (91%)] Loss: 20386.080078\n",
      "Train Epoch: 20 [207360/225000 (92%)] Loss: 20599.310547\n",
      "Train Epoch: 20 [209856/225000 (93%)] Loss: 20472.250000\n",
      "Train Epoch: 20 [212352/225000 (94%)] Loss: 20552.107422\n",
      "Train Epoch: 20 [214848/225000 (95%)] Loss: 20468.050781\n",
      "Train Epoch: 20 [217344/225000 (97%)] Loss: 20768.148438\n",
      "Train Epoch: 20 [219840/225000 (98%)] Loss: 20583.058594\n",
      "Train Epoch: 20 [222336/225000 (99%)] Loss: 20704.203125\n",
      "Train Epoch: 20 [224832/225000 (100%)] Loss: 20507.736328\n",
      "    epoch          : 20\n",
      "    loss           : 20518.102910689526\n",
      "    val_loss       : 20365.991022587732\n",
      "Train Epoch: 21 [192/225000 (0%)] Loss: 20340.398438\n",
      "Train Epoch: 21 [2688/225000 (1%)] Loss: 20510.382812\n",
      "Train Epoch: 21 [5184/225000 (2%)] Loss: 20197.773438\n",
      "Train Epoch: 21 [7680/225000 (3%)] Loss: 20671.771484\n",
      "Train Epoch: 21 [10176/225000 (5%)] Loss: 20507.210938\n",
      "Train Epoch: 21 [12672/225000 (6%)] Loss: 20435.464844\n",
      "Train Epoch: 21 [15168/225000 (7%)] Loss: 20314.083984\n",
      "Train Epoch: 21 [17664/225000 (8%)] Loss: 20669.929688\n",
      "Train Epoch: 21 [20160/225000 (9%)] Loss: 20293.074219\n",
      "Train Epoch: 21 [22656/225000 (10%)] Loss: 20759.750000\n",
      "Train Epoch: 21 [25152/225000 (11%)] Loss: 20398.535156\n",
      "Train Epoch: 21 [27648/225000 (12%)] Loss: 20672.898438\n",
      "Train Epoch: 21 [30144/225000 (13%)] Loss: 19926.101562\n",
      "Train Epoch: 21 [32640/225000 (15%)] Loss: 20797.214844\n",
      "Train Epoch: 21 [35136/225000 (16%)] Loss: 20762.265625\n",
      "Train Epoch: 21 [37632/225000 (17%)] Loss: 20696.179688\n",
      "Train Epoch: 21 [40128/225000 (18%)] Loss: 20272.933594\n",
      "Train Epoch: 21 [42624/225000 (19%)] Loss: 20314.173828\n",
      "Train Epoch: 21 [45120/225000 (20%)] Loss: 20775.964844\n",
      "Train Epoch: 21 [47616/225000 (21%)] Loss: 20560.761719\n",
      "Train Epoch: 21 [50112/225000 (22%)] Loss: 20721.527344\n",
      "Train Epoch: 21 [52608/225000 (23%)] Loss: 20330.054688\n",
      "Train Epoch: 21 [55104/225000 (24%)] Loss: 20000.408203\n",
      "Train Epoch: 21 [57600/225000 (26%)] Loss: 20425.886719\n",
      "Train Epoch: 21 [60096/225000 (27%)] Loss: 20439.082031\n",
      "Train Epoch: 21 [62592/225000 (28%)] Loss: 20543.787109\n",
      "Train Epoch: 21 [65088/225000 (29%)] Loss: 20722.777344\n",
      "Train Epoch: 21 [67584/225000 (30%)] Loss: 20159.546875\n",
      "Train Epoch: 21 [70080/225000 (31%)] Loss: 20668.253906\n",
      "Train Epoch: 21 [72576/225000 (32%)] Loss: 20602.380859\n",
      "Train Epoch: 21 [75072/225000 (33%)] Loss: 20680.816406\n",
      "Train Epoch: 21 [77568/225000 (34%)] Loss: 20030.675781\n",
      "Train Epoch: 21 [80064/225000 (36%)] Loss: 20247.203125\n",
      "Train Epoch: 21 [82560/225000 (37%)] Loss: 20542.773438\n",
      "Train Epoch: 21 [85056/225000 (38%)] Loss: 20383.386719\n",
      "Train Epoch: 21 [87552/225000 (39%)] Loss: 20551.298828\n",
      "Train Epoch: 21 [90048/225000 (40%)] Loss: 20215.074219\n",
      "Train Epoch: 21 [92544/225000 (41%)] Loss: 20289.718750\n",
      "Train Epoch: 21 [95040/225000 (42%)] Loss: 20562.068359\n",
      "Train Epoch: 21 [97536/225000 (43%)] Loss: 20497.851562\n",
      "Train Epoch: 21 [100032/225000 (44%)] Loss: 20151.906250\n",
      "Train Epoch: 21 [102528/225000 (46%)] Loss: 20553.843750\n",
      "Train Epoch: 21 [105024/225000 (47%)] Loss: 20185.906250\n",
      "Train Epoch: 21 [107520/225000 (48%)] Loss: 20674.261719\n",
      "Train Epoch: 21 [110016/225000 (49%)] Loss: 20048.769531\n",
      "Train Epoch: 21 [112512/225000 (50%)] Loss: 20787.072266\n",
      "Train Epoch: 21 [115008/225000 (51%)] Loss: 20390.964844\n",
      "Train Epoch: 21 [117504/225000 (52%)] Loss: 20225.261719\n",
      "Train Epoch: 21 [120000/225000 (53%)] Loss: 20233.093750\n",
      "Train Epoch: 21 [122496/225000 (54%)] Loss: 20191.433594\n",
      "Train Epoch: 21 [124992/225000 (56%)] Loss: 20294.994141\n",
      "Train Epoch: 21 [127488/225000 (57%)] Loss: 20287.636719\n",
      "Train Epoch: 21 [129984/225000 (58%)] Loss: 20343.417969\n",
      "Train Epoch: 21 [132480/225000 (59%)] Loss: 20397.644531\n",
      "Train Epoch: 21 [134976/225000 (60%)] Loss: 20246.839844\n",
      "Train Epoch: 21 [137472/225000 (61%)] Loss: 20820.421875\n",
      "Train Epoch: 21 [139968/225000 (62%)] Loss: 20174.750000\n",
      "Train Epoch: 21 [142464/225000 (63%)] Loss: 20149.257812\n",
      "Train Epoch: 21 [144960/225000 (64%)] Loss: 20257.708984\n",
      "Train Epoch: 21 [147456/225000 (66%)] Loss: 20408.359375\n",
      "Train Epoch: 21 [149952/225000 (67%)] Loss: 20586.472656\n",
      "Train Epoch: 21 [152448/225000 (68%)] Loss: 20927.402344\n",
      "Train Epoch: 21 [154944/225000 (69%)] Loss: 20391.656250\n",
      "Train Epoch: 21 [157440/225000 (70%)] Loss: 20805.873047\n",
      "Train Epoch: 21 [159936/225000 (71%)] Loss: 20389.292969\n",
      "Train Epoch: 21 [162432/225000 (72%)] Loss: 20906.707031\n",
      "Train Epoch: 21 [164928/225000 (73%)] Loss: 20257.181641\n",
      "Train Epoch: 21 [167424/225000 (74%)] Loss: 21000.347656\n",
      "Train Epoch: 21 [169920/225000 (76%)] Loss: 20526.736328\n",
      "Train Epoch: 21 [172416/225000 (77%)] Loss: 19985.808594\n",
      "Train Epoch: 21 [174912/225000 (78%)] Loss: 20236.234375\n",
      "Train Epoch: 21 [177408/225000 (79%)] Loss: 20473.597656\n",
      "Train Epoch: 21 [179904/225000 (80%)] Loss: 20367.230469\n",
      "Train Epoch: 21 [182400/225000 (81%)] Loss: 19951.193359\n",
      "Train Epoch: 21 [184896/225000 (82%)] Loss: 20464.080078\n",
      "Train Epoch: 21 [187392/225000 (83%)] Loss: 20453.181641\n",
      "Train Epoch: 21 [189888/225000 (84%)] Loss: 20441.679688\n",
      "Train Epoch: 21 [192384/225000 (86%)] Loss: 20276.160156\n",
      "Train Epoch: 21 [194880/225000 (87%)] Loss: 20066.869141\n",
      "Train Epoch: 21 [197376/225000 (88%)] Loss: 20574.400391\n",
      "Train Epoch: 21 [199872/225000 (89%)] Loss: 20186.652344\n",
      "Train Epoch: 21 [202368/225000 (90%)] Loss: 20444.636719\n",
      "Train Epoch: 21 [204864/225000 (91%)] Loss: 20320.468750\n",
      "Train Epoch: 21 [207360/225000 (92%)] Loss: 21047.218750\n",
      "Train Epoch: 21 [209856/225000 (93%)] Loss: 20207.464844\n",
      "Train Epoch: 21 [212352/225000 (94%)] Loss: 20444.349609\n",
      "Train Epoch: 21 [214848/225000 (95%)] Loss: 20324.376953\n",
      "Train Epoch: 21 [217344/225000 (97%)] Loss: 20136.121094\n",
      "Train Epoch: 21 [219840/225000 (98%)] Loss: 20018.109375\n",
      "Train Epoch: 21 [222336/225000 (99%)] Loss: 20779.376953\n",
      "Train Epoch: 21 [224832/225000 (100%)] Loss: 20342.740234\n",
      "    epoch          : 21\n",
      "    loss           : 20464.97430440753\n",
      "    val_loss       : 20348.579479766257\n",
      "Train Epoch: 22 [192/225000 (0%)] Loss: 20253.484375\n",
      "Train Epoch: 22 [2688/225000 (1%)] Loss: 20677.906250\n",
      "Train Epoch: 22 [5184/225000 (2%)] Loss: 20566.710938\n",
      "Train Epoch: 22 [7680/225000 (3%)] Loss: 20401.171875\n",
      "Train Epoch: 22 [10176/225000 (5%)] Loss: 20481.119141\n",
      "Train Epoch: 22 [12672/225000 (6%)] Loss: 20249.714844\n",
      "Train Epoch: 22 [15168/225000 (7%)] Loss: 20314.347656\n",
      "Train Epoch: 22 [17664/225000 (8%)] Loss: 20152.761719\n",
      "Train Epoch: 22 [20160/225000 (9%)] Loss: 20470.437500\n",
      "Train Epoch: 22 [22656/225000 (10%)] Loss: 20046.031250\n",
      "Train Epoch: 22 [25152/225000 (11%)] Loss: 20759.273438\n",
      "Train Epoch: 22 [27648/225000 (12%)] Loss: 20155.433594\n",
      "Train Epoch: 22 [30144/225000 (13%)] Loss: 21122.070312\n",
      "Train Epoch: 22 [32640/225000 (15%)] Loss: 20663.148438\n",
      "Train Epoch: 22 [35136/225000 (16%)] Loss: 20998.363281\n",
      "Train Epoch: 22 [37632/225000 (17%)] Loss: 20563.113281\n",
      "Train Epoch: 22 [40128/225000 (18%)] Loss: 20327.132812\n",
      "Train Epoch: 22 [42624/225000 (19%)] Loss: 20562.878906\n",
      "Train Epoch: 22 [45120/225000 (20%)] Loss: 20640.171875\n",
      "Train Epoch: 22 [47616/225000 (21%)] Loss: 20220.363281\n",
      "Train Epoch: 22 [50112/225000 (22%)] Loss: 20216.992188\n",
      "Train Epoch: 22 [52608/225000 (23%)] Loss: 20718.087891\n",
      "Train Epoch: 22 [55104/225000 (24%)] Loss: 20298.017578\n",
      "Train Epoch: 22 [57600/225000 (26%)] Loss: 20247.066406\n",
      "Train Epoch: 22 [60096/225000 (27%)] Loss: 20383.638672\n",
      "Train Epoch: 22 [62592/225000 (28%)] Loss: 20680.414062\n",
      "Train Epoch: 22 [65088/225000 (29%)] Loss: 20280.439453\n",
      "Train Epoch: 22 [67584/225000 (30%)] Loss: 20700.074219\n",
      "Train Epoch: 22 [70080/225000 (31%)] Loss: 20885.609375\n",
      "Train Epoch: 22 [72576/225000 (32%)] Loss: 19959.578125\n",
      "Train Epoch: 22 [75072/225000 (33%)] Loss: 20518.500000\n",
      "Train Epoch: 22 [77568/225000 (34%)] Loss: 20514.867188\n",
      "Train Epoch: 22 [80064/225000 (36%)] Loss: 20792.859375\n",
      "Train Epoch: 22 [82560/225000 (37%)] Loss: 20812.281250\n",
      "Train Epoch: 22 [85056/225000 (38%)] Loss: 20415.648438\n",
      "Train Epoch: 22 [87552/225000 (39%)] Loss: 20272.486328\n",
      "Train Epoch: 22 [90048/225000 (40%)] Loss: 20068.023438\n",
      "Train Epoch: 22 [92544/225000 (41%)] Loss: 20028.839844\n",
      "Train Epoch: 22 [95040/225000 (42%)] Loss: 20422.222656\n",
      "Train Epoch: 22 [97536/225000 (43%)] Loss: 20873.691406\n",
      "Train Epoch: 22 [100032/225000 (44%)] Loss: 20260.798828\n",
      "Train Epoch: 22 [102528/225000 (46%)] Loss: 20600.093750\n",
      "Train Epoch: 22 [105024/225000 (47%)] Loss: 20260.953125\n",
      "Train Epoch: 22 [107520/225000 (48%)] Loss: 20216.796875\n",
      "Train Epoch: 22 [110016/225000 (49%)] Loss: 20323.699219\n",
      "Train Epoch: 22 [112512/225000 (50%)] Loss: 20392.496094\n",
      "Train Epoch: 22 [115008/225000 (51%)] Loss: 20302.011719\n",
      "Train Epoch: 22 [117504/225000 (52%)] Loss: 20780.517578\n",
      "Train Epoch: 22 [120000/225000 (53%)] Loss: 20763.308594\n",
      "Train Epoch: 22 [122496/225000 (54%)] Loss: 20714.730469\n",
      "Train Epoch: 22 [124992/225000 (56%)] Loss: 20567.615234\n",
      "Train Epoch: 22 [127488/225000 (57%)] Loss: 20560.259766\n",
      "Train Epoch: 22 [129984/225000 (58%)] Loss: 20128.712891\n",
      "Train Epoch: 22 [132480/225000 (59%)] Loss: 20604.484375\n",
      "Train Epoch: 22 [134976/225000 (60%)] Loss: 20526.746094\n",
      "Train Epoch: 22 [137472/225000 (61%)] Loss: 20742.455078\n",
      "Train Epoch: 22 [139968/225000 (62%)] Loss: 19937.585938\n",
      "Train Epoch: 22 [142464/225000 (63%)] Loss: 19901.960938\n",
      "Train Epoch: 22 [144960/225000 (64%)] Loss: 20488.636719\n",
      "Train Epoch: 22 [147456/225000 (66%)] Loss: 20650.210938\n",
      "Train Epoch: 22 [149952/225000 (67%)] Loss: 20320.490234\n",
      "Train Epoch: 22 [152448/225000 (68%)] Loss: 20087.775391\n",
      "Train Epoch: 22 [154944/225000 (69%)] Loss: 20713.785156\n",
      "Train Epoch: 22 [157440/225000 (70%)] Loss: 20173.107422\n",
      "Train Epoch: 22 [159936/225000 (71%)] Loss: 20350.468750\n",
      "Train Epoch: 22 [162432/225000 (72%)] Loss: 20551.824219\n",
      "Train Epoch: 22 [164928/225000 (73%)] Loss: 20309.089844\n",
      "Train Epoch: 22 [167424/225000 (74%)] Loss: 20102.765625\n",
      "Train Epoch: 22 [169920/225000 (76%)] Loss: 20314.617188\n",
      "Train Epoch: 22 [172416/225000 (77%)] Loss: 19928.386719\n",
      "Train Epoch: 22 [174912/225000 (78%)] Loss: 20164.820312\n",
      "Train Epoch: 22 [177408/225000 (79%)] Loss: 20449.457031\n",
      "Train Epoch: 22 [179904/225000 (80%)] Loss: 20207.037109\n",
      "Train Epoch: 22 [182400/225000 (81%)] Loss: 20825.675781\n",
      "Train Epoch: 22 [184896/225000 (82%)] Loss: 20287.308594\n",
      "Train Epoch: 22 [187392/225000 (83%)] Loss: 20384.046875\n",
      "Train Epoch: 22 [189888/225000 (84%)] Loss: 20227.992188\n",
      "Train Epoch: 22 [192384/225000 (86%)] Loss: 20560.857422\n",
      "Train Epoch: 22 [194880/225000 (87%)] Loss: 20645.539062\n",
      "Train Epoch: 22 [197376/225000 (88%)] Loss: 20356.080078\n",
      "Train Epoch: 22 [199872/225000 (89%)] Loss: 19880.187500\n",
      "Train Epoch: 22 [202368/225000 (90%)] Loss: 19616.912109\n",
      "Train Epoch: 22 [204864/225000 (91%)] Loss: 19959.875000\n",
      "Train Epoch: 22 [207360/225000 (92%)] Loss: 20372.816406\n",
      "Train Epoch: 22 [209856/225000 (93%)] Loss: 20515.033203\n",
      "Train Epoch: 22 [212352/225000 (94%)] Loss: 19878.455078\n",
      "Train Epoch: 22 [214848/225000 (95%)] Loss: 19915.019531\n",
      "Train Epoch: 22 [217344/225000 (97%)] Loss: 20138.156250\n",
      "Train Epoch: 22 [219840/225000 (98%)] Loss: 20482.031250\n",
      "Train Epoch: 22 [222336/225000 (99%)] Loss: 21081.636719\n",
      "Train Epoch: 22 [224832/225000 (100%)] Loss: 20495.824219\n",
      "    epoch          : 22\n",
      "    loss           : 20443.547098309515\n",
      "    val_loss       : 20417.542681264968\n",
      "Train Epoch: 23 [192/225000 (0%)] Loss: 20877.027344\n",
      "Train Epoch: 23 [2688/225000 (1%)] Loss: 20540.978516\n",
      "Train Epoch: 23 [5184/225000 (2%)] Loss: 20258.824219\n",
      "Train Epoch: 23 [7680/225000 (3%)] Loss: 20408.937500\n",
      "Train Epoch: 23 [10176/225000 (5%)] Loss: 20707.496094\n",
      "Train Epoch: 23 [12672/225000 (6%)] Loss: 20405.343750\n",
      "Train Epoch: 23 [15168/225000 (7%)] Loss: 19860.812500\n",
      "Train Epoch: 23 [17664/225000 (8%)] Loss: 20172.289062\n",
      "Train Epoch: 23 [20160/225000 (9%)] Loss: 20233.251953\n",
      "Train Epoch: 23 [22656/225000 (10%)] Loss: 20304.253906\n",
      "Train Epoch: 23 [25152/225000 (11%)] Loss: 20546.335938\n",
      "Train Epoch: 23 [27648/225000 (12%)] Loss: 20606.806641\n",
      "Train Epoch: 23 [30144/225000 (13%)] Loss: 19912.757812\n",
      "Train Epoch: 23 [32640/225000 (15%)] Loss: 20073.378906\n",
      "Train Epoch: 23 [35136/225000 (16%)] Loss: 20244.861328\n",
      "Train Epoch: 23 [37632/225000 (17%)] Loss: 20510.667969\n",
      "Train Epoch: 23 [40128/225000 (18%)] Loss: 20149.605469\n",
      "Train Epoch: 23 [42624/225000 (19%)] Loss: 20120.308594\n",
      "Train Epoch: 23 [45120/225000 (20%)] Loss: 20468.195312\n",
      "Train Epoch: 23 [47616/225000 (21%)] Loss: 20039.484375\n",
      "Train Epoch: 23 [50112/225000 (22%)] Loss: 20580.296875\n",
      "Train Epoch: 23 [52608/225000 (23%)] Loss: 20367.439453\n",
      "Train Epoch: 23 [55104/225000 (24%)] Loss: 20830.865234\n",
      "Train Epoch: 23 [57600/225000 (26%)] Loss: 20270.777344\n",
      "Train Epoch: 23 [60096/225000 (27%)] Loss: 19899.500000\n",
      "Train Epoch: 23 [62592/225000 (28%)] Loss: 20557.923828\n",
      "Train Epoch: 23 [65088/225000 (29%)] Loss: 20160.511719\n",
      "Train Epoch: 23 [67584/225000 (30%)] Loss: 20199.017578\n",
      "Train Epoch: 23 [70080/225000 (31%)] Loss: 20163.980469\n",
      "Train Epoch: 23 [72576/225000 (32%)] Loss: 20356.785156\n",
      "Train Epoch: 23 [75072/225000 (33%)] Loss: 20194.281250\n",
      "Train Epoch: 23 [77568/225000 (34%)] Loss: 20849.019531\n",
      "Train Epoch: 23 [80064/225000 (36%)] Loss: 20367.140625\n",
      "Train Epoch: 23 [82560/225000 (37%)] Loss: 20316.919922\n",
      "Train Epoch: 23 [85056/225000 (38%)] Loss: 20491.792969\n",
      "Train Epoch: 23 [87552/225000 (39%)] Loss: 19775.519531\n",
      "Train Epoch: 23 [90048/225000 (40%)] Loss: 20411.453125\n",
      "Train Epoch: 23 [92544/225000 (41%)] Loss: 20387.658203\n",
      "Train Epoch: 23 [95040/225000 (42%)] Loss: 20166.605469\n",
      "Train Epoch: 23 [97536/225000 (43%)] Loss: 20838.738281\n",
      "Train Epoch: 23 [100032/225000 (44%)] Loss: 19807.253906\n",
      "Train Epoch: 23 [102528/225000 (46%)] Loss: 20632.292969\n",
      "Train Epoch: 23 [105024/225000 (47%)] Loss: 20778.976562\n",
      "Train Epoch: 23 [107520/225000 (48%)] Loss: 20496.351562\n",
      "Train Epoch: 23 [110016/225000 (49%)] Loss: 20803.636719\n",
      "Train Epoch: 23 [112512/225000 (50%)] Loss: 20246.121094\n",
      "Train Epoch: 23 [115008/225000 (51%)] Loss: 21057.117188\n",
      "Train Epoch: 23 [117504/225000 (52%)] Loss: 20180.951172\n",
      "Train Epoch: 23 [120000/225000 (53%)] Loss: 20628.621094\n",
      "Train Epoch: 23 [122496/225000 (54%)] Loss: 20422.154297\n",
      "Train Epoch: 23 [124992/225000 (56%)] Loss: 20237.628906\n",
      "Train Epoch: 23 [127488/225000 (57%)] Loss: 20509.210938\n",
      "Train Epoch: 23 [129984/225000 (58%)] Loss: 20395.332031\n",
      "Train Epoch: 23 [132480/225000 (59%)] Loss: 20733.980469\n",
      "Train Epoch: 23 [134976/225000 (60%)] Loss: 20273.328125\n",
      "Train Epoch: 23 [137472/225000 (61%)] Loss: 20564.128906\n",
      "Train Epoch: 23 [139968/225000 (62%)] Loss: 20627.388672\n",
      "Train Epoch: 23 [142464/225000 (63%)] Loss: 20412.576172\n",
      "Train Epoch: 23 [144960/225000 (64%)] Loss: 20355.414062\n",
      "Train Epoch: 23 [147456/225000 (66%)] Loss: 19920.031250\n",
      "Train Epoch: 23 [149952/225000 (67%)] Loss: 20404.566406\n",
      "Train Epoch: 23 [152448/225000 (68%)] Loss: 20547.519531\n",
      "Train Epoch: 23 [154944/225000 (69%)] Loss: 20736.667969\n",
      "Train Epoch: 23 [157440/225000 (70%)] Loss: 20117.511719\n",
      "Train Epoch: 23 [159936/225000 (71%)] Loss: 20478.226562\n",
      "Train Epoch: 23 [162432/225000 (72%)] Loss: 19815.134766\n",
      "Train Epoch: 23 [164928/225000 (73%)] Loss: 20636.269531\n",
      "Train Epoch: 23 [167424/225000 (74%)] Loss: 20328.335938\n",
      "Train Epoch: 23 [169920/225000 (76%)] Loss: 20491.580078\n",
      "Train Epoch: 23 [172416/225000 (77%)] Loss: 20440.906250\n",
      "Train Epoch: 23 [174912/225000 (78%)] Loss: 19934.656250\n",
      "Train Epoch: 23 [177408/225000 (79%)] Loss: 20483.644531\n",
      "Train Epoch: 23 [179904/225000 (80%)] Loss: 20425.503906\n",
      "Train Epoch: 23 [182400/225000 (81%)] Loss: 20062.449219\n",
      "Train Epoch: 23 [184896/225000 (82%)] Loss: 20220.589844\n",
      "Train Epoch: 23 [187392/225000 (83%)] Loss: 20550.283203\n",
      "Train Epoch: 23 [189888/225000 (84%)] Loss: 20154.470703\n",
      "Train Epoch: 23 [192384/225000 (86%)] Loss: 20373.011719\n",
      "Train Epoch: 23 [194880/225000 (87%)] Loss: 20871.582031\n",
      "Train Epoch: 23 [197376/225000 (88%)] Loss: 20290.771484\n",
      "Train Epoch: 23 [199872/225000 (89%)] Loss: 20111.621094\n",
      "Train Epoch: 23 [202368/225000 (90%)] Loss: 20394.890625\n",
      "Train Epoch: 23 [204864/225000 (91%)] Loss: 20721.966797\n",
      "Train Epoch: 23 [207360/225000 (92%)] Loss: 20068.451172\n",
      "Train Epoch: 23 [209856/225000 (93%)] Loss: 20165.140625\n",
      "Train Epoch: 23 [212352/225000 (94%)] Loss: 20472.736328\n",
      "Train Epoch: 23 [214848/225000 (95%)] Loss: 20253.386719\n",
      "Train Epoch: 23 [217344/225000 (97%)] Loss: 20572.644531\n",
      "Train Epoch: 23 [219840/225000 (98%)] Loss: 20367.171875\n",
      "Train Epoch: 23 [222336/225000 (99%)] Loss: 20625.550781\n",
      "Train Epoch: 23 [224832/225000 (100%)] Loss: 20159.226562\n",
      "    epoch          : 23\n",
      "    loss           : 20428.804765824978\n",
      "    val_loss       : 20316.44812950469\n",
      "Train Epoch: 24 [192/225000 (0%)] Loss: 20266.267578\n",
      "Train Epoch: 24 [2688/225000 (1%)] Loss: 20647.162109\n",
      "Train Epoch: 24 [5184/225000 (2%)] Loss: 20325.628906\n",
      "Train Epoch: 24 [7680/225000 (3%)] Loss: 20472.480469\n",
      "Train Epoch: 24 [10176/225000 (5%)] Loss: 20766.062500\n",
      "Train Epoch: 24 [12672/225000 (6%)] Loss: 20433.386719\n",
      "Train Epoch: 24 [15168/225000 (7%)] Loss: 20240.492188\n",
      "Train Epoch: 24 [17664/225000 (8%)] Loss: 20131.779297\n",
      "Train Epoch: 24 [20160/225000 (9%)] Loss: 19877.515625\n",
      "Train Epoch: 24 [22656/225000 (10%)] Loss: 20606.730469\n",
      "Train Epoch: 24 [25152/225000 (11%)] Loss: 20271.707031\n",
      "Train Epoch: 24 [27648/225000 (12%)] Loss: 20234.447266\n",
      "Train Epoch: 24 [30144/225000 (13%)] Loss: 19633.460938\n",
      "Train Epoch: 24 [32640/225000 (15%)] Loss: 20629.515625\n",
      "Train Epoch: 24 [35136/225000 (16%)] Loss: 20513.031250\n",
      "Train Epoch: 24 [37632/225000 (17%)] Loss: 20390.328125\n",
      "Train Epoch: 24 [40128/225000 (18%)] Loss: 20689.800781\n",
      "Train Epoch: 24 [42624/225000 (19%)] Loss: 20769.095703\n",
      "Train Epoch: 24 [45120/225000 (20%)] Loss: 20172.789062\n",
      "Train Epoch: 24 [47616/225000 (21%)] Loss: 20318.671875\n",
      "Train Epoch: 24 [50112/225000 (22%)] Loss: 20648.595703\n",
      "Train Epoch: 24 [52608/225000 (23%)] Loss: 20341.710938\n",
      "Train Epoch: 24 [55104/225000 (24%)] Loss: 20671.281250\n",
      "Train Epoch: 24 [57600/225000 (26%)] Loss: 20802.765625\n",
      "Train Epoch: 24 [60096/225000 (27%)] Loss: 20743.554688\n",
      "Train Epoch: 24 [62592/225000 (28%)] Loss: 20378.195312\n",
      "Train Epoch: 24 [65088/225000 (29%)] Loss: 20613.173828\n",
      "Train Epoch: 24 [67584/225000 (30%)] Loss: 20459.099609\n",
      "Train Epoch: 24 [70080/225000 (31%)] Loss: 20429.048828\n",
      "Train Epoch: 24 [72576/225000 (32%)] Loss: 20288.851562\n",
      "Train Epoch: 24 [75072/225000 (33%)] Loss: 20249.705078\n",
      "Train Epoch: 24 [77568/225000 (34%)] Loss: 20480.769531\n",
      "Train Epoch: 24 [80064/225000 (36%)] Loss: 20644.515625\n",
      "Train Epoch: 24 [82560/225000 (37%)] Loss: 20145.265625\n",
      "Train Epoch: 24 [85056/225000 (38%)] Loss: 20849.650391\n",
      "Train Epoch: 24 [87552/225000 (39%)] Loss: 20535.400391\n",
      "Train Epoch: 24 [90048/225000 (40%)] Loss: 20505.935547\n",
      "Train Epoch: 24 [92544/225000 (41%)] Loss: 20530.417969\n",
      "Train Epoch: 24 [95040/225000 (42%)] Loss: 20037.931641\n",
      "Train Epoch: 24 [97536/225000 (43%)] Loss: 20379.550781\n",
      "Train Epoch: 24 [100032/225000 (44%)] Loss: 20232.050781\n",
      "Train Epoch: 24 [102528/225000 (46%)] Loss: 20649.234375\n",
      "Train Epoch: 24 [105024/225000 (47%)] Loss: 20346.388672\n",
      "Train Epoch: 24 [107520/225000 (48%)] Loss: 20222.814453\n",
      "Train Epoch: 24 [110016/225000 (49%)] Loss: 20510.937500\n",
      "Train Epoch: 24 [112512/225000 (50%)] Loss: 20569.808594\n",
      "Train Epoch: 24 [115008/225000 (51%)] Loss: 20665.238281\n",
      "Train Epoch: 24 [117504/225000 (52%)] Loss: 20438.753906\n",
      "Train Epoch: 24 [120000/225000 (53%)] Loss: 20219.710938\n",
      "Train Epoch: 24 [122496/225000 (54%)] Loss: 20367.457031\n",
      "Train Epoch: 24 [124992/225000 (56%)] Loss: 20757.511719\n",
      "Train Epoch: 24 [127488/225000 (57%)] Loss: 20068.408203\n",
      "Train Epoch: 24 [129984/225000 (58%)] Loss: 20105.410156\n",
      "Train Epoch: 24 [132480/225000 (59%)] Loss: 20077.400391\n",
      "Train Epoch: 24 [134976/225000 (60%)] Loss: 20123.753906\n",
      "Train Epoch: 24 [137472/225000 (61%)] Loss: 20374.582031\n",
      "Train Epoch: 24 [139968/225000 (62%)] Loss: 20382.972656\n",
      "Train Epoch: 24 [142464/225000 (63%)] Loss: 20237.191406\n",
      "Train Epoch: 24 [144960/225000 (64%)] Loss: 20249.917969\n",
      "Train Epoch: 24 [147456/225000 (66%)] Loss: 20434.548828\n",
      "Train Epoch: 24 [149952/225000 (67%)] Loss: 20363.341797\n",
      "Train Epoch: 24 [152448/225000 (68%)] Loss: 20747.271484\n",
      "Train Epoch: 24 [154944/225000 (69%)] Loss: 20688.796875\n",
      "Train Epoch: 24 [157440/225000 (70%)] Loss: 19794.890625\n",
      "Train Epoch: 24 [159936/225000 (71%)] Loss: 20195.681641\n",
      "Train Epoch: 24 [162432/225000 (72%)] Loss: 20836.337891\n",
      "Train Epoch: 24 [164928/225000 (73%)] Loss: 20361.746094\n",
      "Train Epoch: 24 [167424/225000 (74%)] Loss: 20157.664062\n",
      "Train Epoch: 24 [169920/225000 (76%)] Loss: 20205.910156\n",
      "Train Epoch: 24 [172416/225000 (77%)] Loss: 20569.496094\n",
      "Train Epoch: 24 [174912/225000 (78%)] Loss: 19872.308594\n",
      "Train Epoch: 24 [177408/225000 (79%)] Loss: 20278.597656\n",
      "Train Epoch: 24 [179904/225000 (80%)] Loss: 20702.597656\n",
      "Train Epoch: 24 [182400/225000 (81%)] Loss: 19860.562500\n",
      "Train Epoch: 24 [184896/225000 (82%)] Loss: 20875.351562\n",
      "Train Epoch: 24 [187392/225000 (83%)] Loss: 19855.109375\n",
      "Train Epoch: 24 [189888/225000 (84%)] Loss: 20283.683594\n",
      "Train Epoch: 24 [192384/225000 (86%)] Loss: 20617.931641\n",
      "Train Epoch: 24 [194880/225000 (87%)] Loss: 20837.351562\n",
      "Train Epoch: 24 [197376/225000 (88%)] Loss: 20147.593750\n",
      "Train Epoch: 24 [199872/225000 (89%)] Loss: 20122.140625\n",
      "Train Epoch: 24 [202368/225000 (90%)] Loss: 19623.558594\n",
      "Train Epoch: 24 [204864/225000 (91%)] Loss: 20354.763672\n",
      "Train Epoch: 24 [207360/225000 (92%)] Loss: 20285.480469\n",
      "Train Epoch: 24 [209856/225000 (93%)] Loss: 20287.414062\n",
      "Train Epoch: 24 [212352/225000 (94%)] Loss: 20750.916016\n",
      "Train Epoch: 24 [214848/225000 (95%)] Loss: 20268.562500\n",
      "Train Epoch: 24 [217344/225000 (97%)] Loss: 19972.050781\n",
      "Train Epoch: 24 [219840/225000 (98%)] Loss: 20671.925781\n",
      "Train Epoch: 24 [222336/225000 (99%)] Loss: 20248.039062\n",
      "Train Epoch: 24 [224832/225000 (100%)] Loss: 20155.988281\n",
      "    epoch          : 24\n",
      "    loss           : 20401.4365834311\n",
      "    val_loss       : 20299.083942032954\n",
      "Train Epoch: 25 [192/225000 (0%)] Loss: 20493.433594\n",
      "Train Epoch: 25 [2688/225000 (1%)] Loss: 20394.107422\n",
      "Train Epoch: 25 [5184/225000 (2%)] Loss: 20438.175781\n",
      "Train Epoch: 25 [7680/225000 (3%)] Loss: 20112.242188\n",
      "Train Epoch: 25 [10176/225000 (5%)] Loss: 20281.601562\n",
      "Train Epoch: 25 [12672/225000 (6%)] Loss: 19651.476562\n",
      "Train Epoch: 25 [15168/225000 (7%)] Loss: 20226.312500\n",
      "Train Epoch: 25 [17664/225000 (8%)] Loss: 21039.054688\n",
      "Train Epoch: 25 [20160/225000 (9%)] Loss: 20533.324219\n",
      "Train Epoch: 25 [22656/225000 (10%)] Loss: 19762.339844\n",
      "Train Epoch: 25 [25152/225000 (11%)] Loss: 20837.472656\n",
      "Train Epoch: 25 [27648/225000 (12%)] Loss: 20578.871094\n",
      "Train Epoch: 25 [30144/225000 (13%)] Loss: 19968.898438\n",
      "Train Epoch: 25 [32640/225000 (15%)] Loss: 20505.042969\n",
      "Train Epoch: 25 [35136/225000 (16%)] Loss: 19974.398438\n",
      "Train Epoch: 25 [37632/225000 (17%)] Loss: 20549.085938\n",
      "Train Epoch: 25 [40128/225000 (18%)] Loss: 20737.681641\n",
      "Train Epoch: 25 [42624/225000 (19%)] Loss: 20163.345703\n",
      "Train Epoch: 25 [45120/225000 (20%)] Loss: 20396.964844\n",
      "Train Epoch: 25 [47616/225000 (21%)] Loss: 20390.539062\n",
      "Train Epoch: 25 [50112/225000 (22%)] Loss: 20417.080078\n",
      "Train Epoch: 25 [52608/225000 (23%)] Loss: 20356.546875\n",
      "Train Epoch: 25 [55104/225000 (24%)] Loss: 20384.753906\n",
      "Train Epoch: 25 [57600/225000 (26%)] Loss: 20988.181641\n",
      "Train Epoch: 25 [60096/225000 (27%)] Loss: 20860.085938\n",
      "Train Epoch: 25 [62592/225000 (28%)] Loss: 20998.376953\n",
      "Train Epoch: 25 [65088/225000 (29%)] Loss: 20248.353516\n",
      "Train Epoch: 25 [67584/225000 (30%)] Loss: 20472.812500\n",
      "Train Epoch: 25 [70080/225000 (31%)] Loss: 20301.648438\n",
      "Train Epoch: 25 [72576/225000 (32%)] Loss: 20309.781250\n",
      "Train Epoch: 25 [75072/225000 (33%)] Loss: 20480.859375\n",
      "Train Epoch: 25 [77568/225000 (34%)] Loss: 20159.396484\n",
      "Train Epoch: 25 [80064/225000 (36%)] Loss: 20090.714844\n",
      "Train Epoch: 25 [82560/225000 (37%)] Loss: 20274.779297\n",
      "Train Epoch: 25 [85056/225000 (38%)] Loss: 20214.396484\n",
      "Train Epoch: 25 [87552/225000 (39%)] Loss: 20667.031250\n",
      "Train Epoch: 25 [90048/225000 (40%)] Loss: 20437.400391\n",
      "Train Epoch: 25 [92544/225000 (41%)] Loss: 19992.066406\n",
      "Train Epoch: 25 [95040/225000 (42%)] Loss: 20135.261719\n",
      "Train Epoch: 25 [97536/225000 (43%)] Loss: 20821.433594\n",
      "Train Epoch: 25 [100032/225000 (44%)] Loss: 20338.785156\n",
      "Train Epoch: 25 [102528/225000 (46%)] Loss: 20729.320312\n",
      "Train Epoch: 25 [105024/225000 (47%)] Loss: 20351.296875\n",
      "Train Epoch: 25 [107520/225000 (48%)] Loss: 20269.078125\n",
      "Train Epoch: 25 [110016/225000 (49%)] Loss: 20290.496094\n",
      "Train Epoch: 25 [112512/225000 (50%)] Loss: 19882.587891\n",
      "Train Epoch: 25 [115008/225000 (51%)] Loss: 20459.679688\n",
      "Train Epoch: 25 [117504/225000 (52%)] Loss: 20309.386719\n",
      "Train Epoch: 25 [120000/225000 (53%)] Loss: 20036.753906\n",
      "Train Epoch: 25 [122496/225000 (54%)] Loss: 20666.105469\n",
      "Train Epoch: 25 [124992/225000 (56%)] Loss: 19831.732422\n",
      "Train Epoch: 25 [127488/225000 (57%)] Loss: 20289.023438\n",
      "Train Epoch: 25 [129984/225000 (58%)] Loss: 20260.423828\n",
      "Train Epoch: 25 [132480/225000 (59%)] Loss: 20294.576172\n",
      "Train Epoch: 25 [134976/225000 (60%)] Loss: 20193.378906\n",
      "Train Epoch: 25 [137472/225000 (61%)] Loss: 20705.177734\n",
      "Train Epoch: 25 [139968/225000 (62%)] Loss: 20204.406250\n",
      "Train Epoch: 25 [142464/225000 (63%)] Loss: 20373.869141\n",
      "Train Epoch: 25 [144960/225000 (64%)] Loss: 20254.857422\n",
      "Train Epoch: 25 [147456/225000 (66%)] Loss: 20773.835938\n",
      "Train Epoch: 25 [149952/225000 (67%)] Loss: 19871.792969\n",
      "Train Epoch: 25 [152448/225000 (68%)] Loss: 20324.140625\n",
      "Train Epoch: 25 [154944/225000 (69%)] Loss: 20593.835938\n",
      "Train Epoch: 25 [157440/225000 (70%)] Loss: 20033.699219\n",
      "Train Epoch: 25 [159936/225000 (71%)] Loss: 20673.507812\n",
      "Train Epoch: 25 [162432/225000 (72%)] Loss: 20341.761719\n",
      "Train Epoch: 25 [164928/225000 (73%)] Loss: 19989.257812\n",
      "Train Epoch: 25 [167424/225000 (74%)] Loss: 20305.769531\n",
      "Train Epoch: 25 [169920/225000 (76%)] Loss: 20319.703125\n",
      "Train Epoch: 25 [172416/225000 (77%)] Loss: 20427.187500\n",
      "Train Epoch: 25 [174912/225000 (78%)] Loss: 20034.015625\n",
      "Train Epoch: 25 [177408/225000 (79%)] Loss: 20492.507812\n",
      "Train Epoch: 25 [179904/225000 (80%)] Loss: 20438.109375\n",
      "Train Epoch: 25 [182400/225000 (81%)] Loss: 20473.761719\n",
      "Train Epoch: 25 [184896/225000 (82%)] Loss: 20219.785156\n",
      "Train Epoch: 25 [187392/225000 (83%)] Loss: 20232.597656\n",
      "Train Epoch: 25 [189888/225000 (84%)] Loss: 21107.386719\n",
      "Train Epoch: 25 [192384/225000 (86%)] Loss: 20495.974609\n",
      "Train Epoch: 25 [194880/225000 (87%)] Loss: 20547.550781\n",
      "Train Epoch: 25 [197376/225000 (88%)] Loss: 20600.017578\n",
      "Train Epoch: 25 [199872/225000 (89%)] Loss: 20724.865234\n",
      "Train Epoch: 25 [202368/225000 (90%)] Loss: 20950.273438\n",
      "Train Epoch: 25 [204864/225000 (91%)] Loss: 20570.337891\n",
      "Train Epoch: 25 [207360/225000 (92%)] Loss: 20634.746094\n",
      "Train Epoch: 25 [209856/225000 (93%)] Loss: 20369.636719\n",
      "Train Epoch: 25 [212352/225000 (94%)] Loss: 20784.367188\n",
      "Train Epoch: 25 [214848/225000 (95%)] Loss: 20649.781250\n",
      "Train Epoch: 25 [217344/225000 (97%)] Loss: 20467.787109\n",
      "Train Epoch: 25 [219840/225000 (98%)] Loss: 20616.433594\n",
      "Train Epoch: 25 [222336/225000 (99%)] Loss: 20235.246094\n",
      "Train Epoch: 25 [224832/225000 (100%)] Loss: 20539.988281\n",
      "    epoch          : 25\n",
      "    loss           : 20428.28915082391\n",
      "    val_loss       : 20289.354559149906\n",
      "Train Epoch: 26 [192/225000 (0%)] Loss: 20907.417969\n",
      "Train Epoch: 26 [2688/225000 (1%)] Loss: 20236.261719\n",
      "Train Epoch: 26 [5184/225000 (2%)] Loss: 20990.113281\n",
      "Train Epoch: 26 [7680/225000 (3%)] Loss: 20522.548828\n",
      "Train Epoch: 26 [10176/225000 (5%)] Loss: 20540.789062\n",
      "Train Epoch: 26 [12672/225000 (6%)] Loss: 20261.578125\n",
      "Train Epoch: 26 [15168/225000 (7%)] Loss: 20692.886719\n",
      "Train Epoch: 26 [17664/225000 (8%)] Loss: 20397.750000\n",
      "Train Epoch: 26 [20160/225000 (9%)] Loss: 20237.324219\n",
      "Train Epoch: 26 [22656/225000 (10%)] Loss: 20116.638672\n",
      "Train Epoch: 26 [25152/225000 (11%)] Loss: 20737.935547\n",
      "Train Epoch: 26 [27648/225000 (12%)] Loss: 20516.736328\n",
      "Train Epoch: 26 [30144/225000 (13%)] Loss: 19922.574219\n",
      "Train Epoch: 26 [32640/225000 (15%)] Loss: 19899.968750\n",
      "Train Epoch: 26 [35136/225000 (16%)] Loss: 20163.298828\n",
      "Train Epoch: 26 [37632/225000 (17%)] Loss: 20858.519531\n",
      "Train Epoch: 26 [40128/225000 (18%)] Loss: 20543.103516\n",
      "Train Epoch: 26 [42624/225000 (19%)] Loss: 20547.300781\n",
      "Train Epoch: 26 [45120/225000 (20%)] Loss: 20790.742188\n",
      "Train Epoch: 26 [47616/225000 (21%)] Loss: 20455.671875\n",
      "Train Epoch: 26 [50112/225000 (22%)] Loss: 20685.500000\n",
      "Train Epoch: 26 [52608/225000 (23%)] Loss: 20620.193359\n",
      "Train Epoch: 26 [55104/225000 (24%)] Loss: 20025.208984\n",
      "Train Epoch: 26 [57600/225000 (26%)] Loss: 20214.843750\n",
      "Train Epoch: 26 [60096/225000 (27%)] Loss: 20029.707031\n",
      "Train Epoch: 26 [62592/225000 (28%)] Loss: 20958.343750\n",
      "Train Epoch: 26 [65088/225000 (29%)] Loss: 20479.472656\n",
      "Train Epoch: 26 [67584/225000 (30%)] Loss: 20399.957031\n",
      "Train Epoch: 26 [70080/225000 (31%)] Loss: 20346.621094\n",
      "Train Epoch: 26 [72576/225000 (32%)] Loss: 20414.773438\n",
      "Train Epoch: 26 [75072/225000 (33%)] Loss: 20680.085938\n",
      "Train Epoch: 26 [77568/225000 (34%)] Loss: 20120.246094\n",
      "Train Epoch: 26 [80064/225000 (36%)] Loss: 20224.027344\n",
      "Train Epoch: 26 [82560/225000 (37%)] Loss: 20612.441406\n",
      "Train Epoch: 26 [85056/225000 (38%)] Loss: 20459.402344\n",
      "Train Epoch: 26 [87552/225000 (39%)] Loss: 20263.097656\n",
      "Train Epoch: 26 [90048/225000 (40%)] Loss: 20183.392578\n",
      "Train Epoch: 26 [92544/225000 (41%)] Loss: 20125.042969\n",
      "Train Epoch: 26 [95040/225000 (42%)] Loss: 20377.683594\n",
      "Train Epoch: 26 [97536/225000 (43%)] Loss: 20714.912109\n",
      "Train Epoch: 26 [100032/225000 (44%)] Loss: 20347.626953\n",
      "Train Epoch: 26 [102528/225000 (46%)] Loss: 20362.355469\n",
      "Train Epoch: 26 [105024/225000 (47%)] Loss: 20242.671875\n",
      "Train Epoch: 26 [107520/225000 (48%)] Loss: 20513.878906\n",
      "Train Epoch: 26 [110016/225000 (49%)] Loss: 20197.384766\n",
      "Train Epoch: 26 [112512/225000 (50%)] Loss: 20494.642578\n",
      "Train Epoch: 26 [115008/225000 (51%)] Loss: 20097.121094\n",
      "Train Epoch: 26 [117504/225000 (52%)] Loss: 20512.750000\n",
      "Train Epoch: 26 [120000/225000 (53%)] Loss: 20611.156250\n",
      "Train Epoch: 26 [122496/225000 (54%)] Loss: 20554.949219\n",
      "Train Epoch: 26 [124992/225000 (56%)] Loss: 20297.226562\n",
      "Train Epoch: 26 [127488/225000 (57%)] Loss: 20684.691406\n",
      "Train Epoch: 26 [129984/225000 (58%)] Loss: 20632.816406\n",
      "Train Epoch: 26 [132480/225000 (59%)] Loss: 19894.531250\n",
      "Train Epoch: 26 [134976/225000 (60%)] Loss: 20574.218750\n",
      "Train Epoch: 26 [137472/225000 (61%)] Loss: 20628.875000\n",
      "Train Epoch: 26 [139968/225000 (62%)] Loss: 20301.945312\n",
      "Train Epoch: 26 [142464/225000 (63%)] Loss: 20031.476562\n",
      "Train Epoch: 26 [144960/225000 (64%)] Loss: 20497.732422\n",
      "Train Epoch: 26 [147456/225000 (66%)] Loss: 20762.767578\n",
      "Train Epoch: 26 [149952/225000 (67%)] Loss: 20670.505859\n",
      "Train Epoch: 26 [152448/225000 (68%)] Loss: 20233.046875\n",
      "Train Epoch: 26 [154944/225000 (69%)] Loss: 20449.880859\n",
      "Train Epoch: 26 [157440/225000 (70%)] Loss: 20403.142578\n",
      "Train Epoch: 26 [159936/225000 (71%)] Loss: 19985.119141\n",
      "Train Epoch: 26 [162432/225000 (72%)] Loss: 20652.457031\n",
      "Train Epoch: 26 [164928/225000 (73%)] Loss: 20181.699219\n",
      "Train Epoch: 26 [167424/225000 (74%)] Loss: 20158.603516\n",
      "Train Epoch: 26 [169920/225000 (76%)] Loss: 20405.757812\n",
      "Train Epoch: 26 [172416/225000 (77%)] Loss: 20007.277344\n",
      "Train Epoch: 26 [174912/225000 (78%)] Loss: 19898.755859\n",
      "Train Epoch: 26 [177408/225000 (79%)] Loss: 20128.937500\n",
      "Train Epoch: 26 [179904/225000 (80%)] Loss: 20367.869141\n",
      "Train Epoch: 26 [182400/225000 (81%)] Loss: 20241.324219\n",
      "Train Epoch: 26 [184896/225000 (82%)] Loss: 21104.179688\n",
      "Train Epoch: 26 [187392/225000 (83%)] Loss: 20690.843750\n",
      "Train Epoch: 26 [189888/225000 (84%)] Loss: 20581.560547\n",
      "Train Epoch: 26 [192384/225000 (86%)] Loss: 20400.837891\n",
      "Train Epoch: 26 [194880/225000 (87%)] Loss: 20060.748047\n",
      "Train Epoch: 26 [197376/225000 (88%)] Loss: 19992.939453\n",
      "Train Epoch: 26 [199872/225000 (89%)] Loss: 20411.033203\n",
      "Train Epoch: 26 [202368/225000 (90%)] Loss: 19953.117188\n",
      "Train Epoch: 26 [204864/225000 (91%)] Loss: 20426.042969\n",
      "Train Epoch: 26 [207360/225000 (92%)] Loss: 20376.363281\n",
      "Train Epoch: 26 [209856/225000 (93%)] Loss: 20252.583984\n",
      "Train Epoch: 26 [212352/225000 (94%)] Loss: 20323.785156\n",
      "Train Epoch: 26 [214848/225000 (95%)] Loss: 20709.386719\n",
      "Train Epoch: 26 [217344/225000 (97%)] Loss: 20261.269531\n",
      "Train Epoch: 26 [219840/225000 (98%)] Loss: 20201.195312\n",
      "Train Epoch: 26 [222336/225000 (99%)] Loss: 20270.568359\n",
      "Train Epoch: 26 [224832/225000 (100%)] Loss: 20777.015625\n",
      "    epoch          : 26\n",
      "    loss           : 20385.178392638118\n",
      "    val_loss       : 20276.094029752352\n",
      "Train Epoch: 27 [192/225000 (0%)] Loss: 20299.074219\n",
      "Train Epoch: 27 [2688/225000 (1%)] Loss: 19831.636719\n",
      "Train Epoch: 27 [5184/225000 (2%)] Loss: 20230.427734\n",
      "Train Epoch: 27 [7680/225000 (3%)] Loss: 20750.445312\n",
      "Train Epoch: 27 [10176/225000 (5%)] Loss: 20217.671875\n",
      "Train Epoch: 27 [12672/225000 (6%)] Loss: 20212.050781\n",
      "Train Epoch: 27 [15168/225000 (7%)] Loss: 20255.781250\n",
      "Train Epoch: 27 [17664/225000 (8%)] Loss: 20695.574219\n",
      "Train Epoch: 27 [20160/225000 (9%)] Loss: 20271.974609\n",
      "Train Epoch: 27 [22656/225000 (10%)] Loss: 20391.441406\n",
      "Train Epoch: 27 [25152/225000 (11%)] Loss: 20633.316406\n",
      "Train Epoch: 27 [27648/225000 (12%)] Loss: 20368.160156\n",
      "Train Epoch: 27 [30144/225000 (13%)] Loss: 20136.792969\n",
      "Train Epoch: 27 [32640/225000 (15%)] Loss: 20181.345703\n",
      "Train Epoch: 27 [35136/225000 (16%)] Loss: 20222.476562\n",
      "Train Epoch: 27 [37632/225000 (17%)] Loss: 20408.234375\n",
      "Train Epoch: 27 [40128/225000 (18%)] Loss: 20154.554688\n",
      "Train Epoch: 27 [42624/225000 (19%)] Loss: 20209.187500\n",
      "Train Epoch: 27 [45120/225000 (20%)] Loss: 20599.882812\n",
      "Train Epoch: 27 [47616/225000 (21%)] Loss: 20190.316406\n",
      "Train Epoch: 27 [50112/225000 (22%)] Loss: 20435.757812\n",
      "Train Epoch: 27 [52608/225000 (23%)] Loss: 20621.730469\n",
      "Train Epoch: 27 [55104/225000 (24%)] Loss: 19913.744141\n",
      "Train Epoch: 27 [57600/225000 (26%)] Loss: 20038.207031\n",
      "Train Epoch: 27 [60096/225000 (27%)] Loss: 20596.757812\n",
      "Train Epoch: 27 [62592/225000 (28%)] Loss: 20545.007812\n",
      "Train Epoch: 27 [65088/225000 (29%)] Loss: 20361.335938\n",
      "Train Epoch: 27 [67584/225000 (30%)] Loss: 20129.718750\n",
      "Train Epoch: 27 [70080/225000 (31%)] Loss: 20551.656250\n",
      "Train Epoch: 27 [72576/225000 (32%)] Loss: 20170.289062\n",
      "Train Epoch: 27 [75072/225000 (33%)] Loss: 20700.664062\n",
      "Train Epoch: 27 [77568/225000 (34%)] Loss: 20339.185547\n",
      "Train Epoch: 27 [80064/225000 (36%)] Loss: 20186.195312\n",
      "Train Epoch: 27 [82560/225000 (37%)] Loss: 20527.582031\n",
      "Train Epoch: 27 [85056/225000 (38%)] Loss: 20846.416016\n",
      "Train Epoch: 27 [87552/225000 (39%)] Loss: 20468.636719\n",
      "Train Epoch: 27 [90048/225000 (40%)] Loss: 20979.238281\n",
      "Train Epoch: 27 [92544/225000 (41%)] Loss: 20132.816406\n",
      "Train Epoch: 27 [95040/225000 (42%)] Loss: 20935.234375\n",
      "Train Epoch: 27 [97536/225000 (43%)] Loss: 20246.468750\n",
      "Train Epoch: 27 [100032/225000 (44%)] Loss: 20253.212891\n",
      "Train Epoch: 27 [102528/225000 (46%)] Loss: 19953.132812\n",
      "Train Epoch: 27 [105024/225000 (47%)] Loss: 20196.037109\n",
      "Train Epoch: 27 [107520/225000 (48%)] Loss: 20315.675781\n",
      "Train Epoch: 27 [110016/225000 (49%)] Loss: 20370.578125\n",
      "Train Epoch: 27 [112512/225000 (50%)] Loss: 20349.535156\n",
      "Train Epoch: 27 [115008/225000 (51%)] Loss: 20070.984375\n",
      "Train Epoch: 27 [117504/225000 (52%)] Loss: 20258.083984\n",
      "Train Epoch: 27 [120000/225000 (53%)] Loss: 20316.808594\n",
      "Train Epoch: 27 [122496/225000 (54%)] Loss: 20599.480469\n",
      "Train Epoch: 27 [124992/225000 (56%)] Loss: 20908.687500\n",
      "Train Epoch: 27 [127488/225000 (57%)] Loss: 20367.125000\n",
      "Train Epoch: 27 [129984/225000 (58%)] Loss: 20779.585938\n",
      "Train Epoch: 27 [132480/225000 (59%)] Loss: 20924.830078\n",
      "Train Epoch: 27 [134976/225000 (60%)] Loss: 20221.714844\n",
      "Train Epoch: 27 [137472/225000 (61%)] Loss: 19644.273438\n",
      "Train Epoch: 27 [139968/225000 (62%)] Loss: 19925.753906\n",
      "Train Epoch: 27 [142464/225000 (63%)] Loss: 20974.960938\n",
      "Train Epoch: 27 [144960/225000 (64%)] Loss: 19895.007812\n",
      "Train Epoch: 27 [147456/225000 (66%)] Loss: 19995.203125\n",
      "Train Epoch: 27 [149952/225000 (67%)] Loss: 20465.271484\n",
      "Train Epoch: 27 [152448/225000 (68%)] Loss: 20145.869141\n",
      "Train Epoch: 27 [154944/225000 (69%)] Loss: 20446.878906\n",
      "Train Epoch: 27 [157440/225000 (70%)] Loss: 19763.800781\n",
      "Train Epoch: 27 [159936/225000 (71%)] Loss: 20093.902344\n",
      "Train Epoch: 27 [162432/225000 (72%)] Loss: 20624.591797\n",
      "Train Epoch: 27 [164928/225000 (73%)] Loss: 20061.156250\n",
      "Train Epoch: 27 [167424/225000 (74%)] Loss: 19889.742188\n",
      "Train Epoch: 27 [169920/225000 (76%)] Loss: 20153.746094\n",
      "Train Epoch: 27 [172416/225000 (77%)] Loss: 20546.550781\n",
      "Train Epoch: 27 [174912/225000 (78%)] Loss: 20138.343750\n",
      "Train Epoch: 27 [177408/225000 (79%)] Loss: 20733.355469\n",
      "Train Epoch: 27 [179904/225000 (80%)] Loss: 20272.320312\n",
      "Train Epoch: 27 [182400/225000 (81%)] Loss: 20664.882812\n",
      "Train Epoch: 27 [184896/225000 (82%)] Loss: 20519.980469\n",
      "Train Epoch: 27 [187392/225000 (83%)] Loss: 20694.722656\n",
      "Train Epoch: 27 [189888/225000 (84%)] Loss: 20128.947266\n",
      "Train Epoch: 27 [192384/225000 (86%)] Loss: 20439.191406\n",
      "Train Epoch: 27 [194880/225000 (87%)] Loss: 20652.769531\n",
      "Train Epoch: 27 [197376/225000 (88%)] Loss: 20331.679688\n",
      "Train Epoch: 27 [199872/225000 (89%)] Loss: 20319.843750\n",
      "Train Epoch: 27 [202368/225000 (90%)] Loss: 20366.916016\n",
      "Train Epoch: 27 [204864/225000 (91%)] Loss: 20473.550781\n",
      "Train Epoch: 27 [207360/225000 (92%)] Loss: 20386.912109\n",
      "Train Epoch: 27 [209856/225000 (93%)] Loss: 20209.349609\n",
      "Train Epoch: 27 [212352/225000 (94%)] Loss: 20392.533203\n",
      "Train Epoch: 27 [214848/225000 (95%)] Loss: 20180.835938\n",
      "Train Epoch: 27 [217344/225000 (97%)] Loss: 20283.109375\n",
      "Train Epoch: 27 [219840/225000 (98%)] Loss: 20387.929688\n",
      "Train Epoch: 27 [222336/225000 (99%)] Loss: 20097.035156\n",
      "Train Epoch: 27 [224832/225000 (100%)] Loss: 20458.132812\n",
      "    epoch          : 27\n",
      "    loss           : 20370.1192006186\n",
      "    val_loss       : 20266.42765058543\n",
      "Train Epoch: 28 [192/225000 (0%)] Loss: 20268.121094\n",
      "Train Epoch: 28 [2688/225000 (1%)] Loss: 20404.662109\n",
      "Train Epoch: 28 [5184/225000 (2%)] Loss: 19799.503906\n",
      "Train Epoch: 28 [7680/225000 (3%)] Loss: 20567.042969\n",
      "Train Epoch: 28 [10176/225000 (5%)] Loss: 20798.792969\n",
      "Train Epoch: 28 [12672/225000 (6%)] Loss: 20630.873047\n",
      "Train Epoch: 28 [15168/225000 (7%)] Loss: 20328.484375\n",
      "Train Epoch: 28 [17664/225000 (8%)] Loss: 20187.925781\n",
      "Train Epoch: 28 [20160/225000 (9%)] Loss: 20297.677734\n",
      "Train Epoch: 28 [22656/225000 (10%)] Loss: 20062.353516\n",
      "Train Epoch: 28 [25152/225000 (11%)] Loss: 20744.007812\n",
      "Train Epoch: 28 [27648/225000 (12%)] Loss: 20573.339844\n",
      "Train Epoch: 28 [30144/225000 (13%)] Loss: 20346.015625\n",
      "Train Epoch: 28 [32640/225000 (15%)] Loss: 20147.578125\n",
      "Train Epoch: 28 [35136/225000 (16%)] Loss: 20279.144531\n",
      "Train Epoch: 28 [37632/225000 (17%)] Loss: 20246.625000\n",
      "Train Epoch: 28 [40128/225000 (18%)] Loss: 20139.089844\n",
      "Train Epoch: 28 [42624/225000 (19%)] Loss: 20519.923828\n",
      "Train Epoch: 28 [45120/225000 (20%)] Loss: 20325.015625\n",
      "Train Epoch: 28 [47616/225000 (21%)] Loss: 21053.396484\n",
      "Train Epoch: 28 [50112/225000 (22%)] Loss: 21007.140625\n",
      "Train Epoch: 28 [52608/225000 (23%)] Loss: 20193.011719\n",
      "Train Epoch: 28 [55104/225000 (24%)] Loss: 20414.529297\n",
      "Train Epoch: 28 [57600/225000 (26%)] Loss: 20383.667969\n",
      "Train Epoch: 28 [60096/225000 (27%)] Loss: 20204.011719\n",
      "Train Epoch: 28 [62592/225000 (28%)] Loss: 20411.771484\n",
      "Train Epoch: 28 [65088/225000 (29%)] Loss: 20737.875000\n",
      "Train Epoch: 28 [67584/225000 (30%)] Loss: 20437.515625\n",
      "Train Epoch: 28 [70080/225000 (31%)] Loss: 20441.617188\n",
      "Train Epoch: 28 [72576/225000 (32%)] Loss: 20874.949219\n",
      "Train Epoch: 28 [75072/225000 (33%)] Loss: 20167.222656\n",
      "Train Epoch: 28 [77568/225000 (34%)] Loss: 20301.857422\n",
      "Train Epoch: 28 [80064/225000 (36%)] Loss: 20266.730469\n",
      "Train Epoch: 28 [82560/225000 (37%)] Loss: 20380.460938\n",
      "Train Epoch: 28 [85056/225000 (38%)] Loss: 20179.988281\n",
      "Train Epoch: 28 [87552/225000 (39%)] Loss: 20236.419922\n",
      "Train Epoch: 28 [90048/225000 (40%)] Loss: 20243.812500\n",
      "Train Epoch: 28 [92544/225000 (41%)] Loss: 20149.695312\n",
      "Train Epoch: 28 [95040/225000 (42%)] Loss: 20845.427734\n",
      "Train Epoch: 28 [97536/225000 (43%)] Loss: 20170.402344\n",
      "Train Epoch: 28 [100032/225000 (44%)] Loss: 20033.642578\n",
      "Train Epoch: 28 [102528/225000 (46%)] Loss: 19921.699219\n",
      "Train Epoch: 28 [105024/225000 (47%)] Loss: 20345.308594\n",
      "Train Epoch: 28 [107520/225000 (48%)] Loss: 20371.093750\n",
      "Train Epoch: 28 [110016/225000 (49%)] Loss: 20157.212891\n",
      "Train Epoch: 28 [112512/225000 (50%)] Loss: 20254.451172\n",
      "Train Epoch: 28 [115008/225000 (51%)] Loss: 20356.083984\n",
      "Train Epoch: 28 [117504/225000 (52%)] Loss: 20726.863281\n",
      "Train Epoch: 28 [120000/225000 (53%)] Loss: 20395.648438\n",
      "Train Epoch: 28 [122496/225000 (54%)] Loss: 20565.988281\n",
      "Train Epoch: 28 [124992/225000 (56%)] Loss: 20242.402344\n",
      "Train Epoch: 28 [127488/225000 (57%)] Loss: 20286.359375\n",
      "Train Epoch: 28 [129984/225000 (58%)] Loss: 21044.277344\n",
      "Train Epoch: 28 [132480/225000 (59%)] Loss: 20160.482422\n",
      "Train Epoch: 28 [134976/225000 (60%)] Loss: 19681.628906\n",
      "Train Epoch: 28 [137472/225000 (61%)] Loss: 20539.138672\n",
      "Train Epoch: 28 [139968/225000 (62%)] Loss: 19944.210938\n",
      "Train Epoch: 28 [142464/225000 (63%)] Loss: 20208.505859\n",
      "Train Epoch: 28 [144960/225000 (64%)] Loss: 19906.804688\n",
      "Train Epoch: 28 [147456/225000 (66%)] Loss: 20457.623047\n",
      "Train Epoch: 28 [149952/225000 (67%)] Loss: 20333.843750\n",
      "Train Epoch: 28 [152448/225000 (68%)] Loss: 20125.638672\n",
      "Train Epoch: 28 [154944/225000 (69%)] Loss: 20053.953125\n",
      "Train Epoch: 28 [157440/225000 (70%)] Loss: 20133.453125\n",
      "Train Epoch: 28 [159936/225000 (71%)] Loss: 21356.449219\n",
      "Train Epoch: 28 [162432/225000 (72%)] Loss: 20258.759766\n",
      "Train Epoch: 28 [164928/225000 (73%)] Loss: 20437.083984\n",
      "Train Epoch: 28 [167424/225000 (74%)] Loss: 20050.449219\n",
      "Train Epoch: 28 [169920/225000 (76%)] Loss: 20057.037109\n",
      "Train Epoch: 28 [172416/225000 (77%)] Loss: 20054.582031\n",
      "Train Epoch: 28 [174912/225000 (78%)] Loss: 20780.578125\n",
      "Train Epoch: 28 [177408/225000 (79%)] Loss: 20167.910156\n",
      "Train Epoch: 28 [179904/225000 (80%)] Loss: 20773.537109\n",
      "Train Epoch: 28 [182400/225000 (81%)] Loss: 19944.742188\n",
      "Train Epoch: 28 [184896/225000 (82%)] Loss: 19830.253906\n",
      "Train Epoch: 28 [187392/225000 (83%)] Loss: 20749.953125\n",
      "Train Epoch: 28 [189888/225000 (84%)] Loss: 20224.894531\n",
      "Train Epoch: 28 [192384/225000 (86%)] Loss: 20434.589844\n",
      "Train Epoch: 28 [194880/225000 (87%)] Loss: 20700.156250\n",
      "Train Epoch: 28 [197376/225000 (88%)] Loss: 20374.779297\n",
      "Train Epoch: 28 [199872/225000 (89%)] Loss: 20271.988281\n",
      "Train Epoch: 28 [202368/225000 (90%)] Loss: 20542.523438\n",
      "Train Epoch: 28 [204864/225000 (91%)] Loss: 20490.046875\n",
      "Train Epoch: 28 [207360/225000 (92%)] Loss: 20069.671875\n",
      "Train Epoch: 28 [209856/225000 (93%)] Loss: 20533.896484\n",
      "Train Epoch: 28 [212352/225000 (94%)] Loss: 20089.843750\n",
      "Train Epoch: 28 [214848/225000 (95%)] Loss: 20275.070312\n",
      "Train Epoch: 28 [217344/225000 (97%)] Loss: 20335.265625\n",
      "Train Epoch: 28 [219840/225000 (98%)] Loss: 20555.779297\n",
      "Train Epoch: 28 [222336/225000 (99%)] Loss: 20299.095703\n",
      "Train Epoch: 28 [224832/225000 (100%)] Loss: 19993.732422\n",
      "    epoch          : 28\n",
      "    loss           : 20368.63845523144\n",
      "    val_loss       : 20346.189747826742\n",
      "Train Epoch: 29 [192/225000 (0%)] Loss: 20267.988281\n",
      "Train Epoch: 29 [2688/225000 (1%)] Loss: 20366.488281\n",
      "Train Epoch: 29 [5184/225000 (2%)] Loss: 20404.052734\n",
      "Train Epoch: 29 [7680/225000 (3%)] Loss: 20110.527344\n",
      "Train Epoch: 29 [10176/225000 (5%)] Loss: 20241.623047\n",
      "Train Epoch: 29 [12672/225000 (6%)] Loss: 20815.962891\n",
      "Train Epoch: 29 [15168/225000 (7%)] Loss: 20438.992188\n",
      "Train Epoch: 29 [17664/225000 (8%)] Loss: 19882.601562\n",
      "Train Epoch: 29 [20160/225000 (9%)] Loss: 20355.859375\n",
      "Train Epoch: 29 [22656/225000 (10%)] Loss: 20246.712891\n",
      "Train Epoch: 29 [25152/225000 (11%)] Loss: 20974.492188\n",
      "Train Epoch: 29 [27648/225000 (12%)] Loss: 20220.554688\n",
      "Train Epoch: 29 [30144/225000 (13%)] Loss: 20204.019531\n",
      "Train Epoch: 29 [32640/225000 (15%)] Loss: 20313.871094\n",
      "Train Epoch: 29 [35136/225000 (16%)] Loss: 20412.191406\n",
      "Train Epoch: 29 [37632/225000 (17%)] Loss: 20294.527344\n",
      "Train Epoch: 29 [40128/225000 (18%)] Loss: 20873.519531\n",
      "Train Epoch: 29 [42624/225000 (19%)] Loss: 20167.804688\n",
      "Train Epoch: 29 [45120/225000 (20%)] Loss: 20467.169922\n",
      "Train Epoch: 29 [47616/225000 (21%)] Loss: 19780.912109\n",
      "Train Epoch: 29 [50112/225000 (22%)] Loss: 20138.753906\n",
      "Train Epoch: 29 [52608/225000 (23%)] Loss: 20425.003906\n",
      "Train Epoch: 29 [55104/225000 (24%)] Loss: 20472.093750\n",
      "Train Epoch: 29 [57600/225000 (26%)] Loss: 19607.326172\n",
      "Train Epoch: 29 [60096/225000 (27%)] Loss: 19765.421875\n",
      "Train Epoch: 29 [62592/225000 (28%)] Loss: 19944.929688\n",
      "Train Epoch: 29 [65088/225000 (29%)] Loss: 19963.169922\n",
      "Train Epoch: 29 [67584/225000 (30%)] Loss: 20496.261719\n",
      "Train Epoch: 29 [70080/225000 (31%)] Loss: 20425.878906\n",
      "Train Epoch: 29 [72576/225000 (32%)] Loss: 20226.513672\n",
      "Train Epoch: 29 [75072/225000 (33%)] Loss: 20320.144531\n",
      "Train Epoch: 29 [77568/225000 (34%)] Loss: 20003.164062\n",
      "Train Epoch: 29 [80064/225000 (36%)] Loss: 20639.396484\n",
      "Train Epoch: 29 [82560/225000 (37%)] Loss: 20283.156250\n",
      "Train Epoch: 29 [85056/225000 (38%)] Loss: 20187.710938\n",
      "Train Epoch: 29 [87552/225000 (39%)] Loss: 20007.677734\n",
      "Train Epoch: 29 [90048/225000 (40%)] Loss: 20667.453125\n",
      "Train Epoch: 29 [92544/225000 (41%)] Loss: 20053.626953\n",
      "Train Epoch: 29 [95040/225000 (42%)] Loss: 20454.539062\n",
      "Train Epoch: 29 [97536/225000 (43%)] Loss: 19888.074219\n",
      "Train Epoch: 29 [100032/225000 (44%)] Loss: 20519.712891\n",
      "Train Epoch: 29 [102528/225000 (46%)] Loss: 20543.679688\n",
      "Train Epoch: 29 [105024/225000 (47%)] Loss: 20392.503906\n",
      "Train Epoch: 29 [107520/225000 (48%)] Loss: 20683.082031\n",
      "Train Epoch: 29 [110016/225000 (49%)] Loss: 20224.712891\n",
      "Train Epoch: 29 [112512/225000 (50%)] Loss: 20790.712891\n",
      "Train Epoch: 29 [115008/225000 (51%)] Loss: 20680.013672\n",
      "Train Epoch: 29 [117504/225000 (52%)] Loss: 20298.394531\n",
      "Train Epoch: 29 [120000/225000 (53%)] Loss: 19741.925781\n",
      "Train Epoch: 29 [122496/225000 (54%)] Loss: 20537.722656\n",
      "Train Epoch: 29 [124992/225000 (56%)] Loss: 20477.621094\n",
      "Train Epoch: 29 [127488/225000 (57%)] Loss: 19872.253906\n",
      "Train Epoch: 29 [129984/225000 (58%)] Loss: 20115.570312\n",
      "Train Epoch: 29 [132480/225000 (59%)] Loss: 20503.203125\n",
      "Train Epoch: 29 [134976/225000 (60%)] Loss: 20496.226562\n",
      "Train Epoch: 29 [137472/225000 (61%)] Loss: 20639.322266\n",
      "Train Epoch: 29 [139968/225000 (62%)] Loss: 20572.109375\n",
      "Train Epoch: 29 [142464/225000 (63%)] Loss: 20571.722656\n",
      "Train Epoch: 29 [144960/225000 (64%)] Loss: 19958.367188\n",
      "Train Epoch: 29 [147456/225000 (66%)] Loss: 20677.140625\n",
      "Train Epoch: 29 [149952/225000 (67%)] Loss: 20075.121094\n",
      "Train Epoch: 29 [152448/225000 (68%)] Loss: 20374.294922\n",
      "Train Epoch: 29 [154944/225000 (69%)] Loss: 20008.121094\n",
      "Train Epoch: 29 [157440/225000 (70%)] Loss: 20251.396484\n",
      "Train Epoch: 29 [159936/225000 (71%)] Loss: 20488.886719\n",
      "Train Epoch: 29 [162432/225000 (72%)] Loss: 20877.667969\n",
      "Train Epoch: 29 [164928/225000 (73%)] Loss: 20767.621094\n",
      "Train Epoch: 29 [167424/225000 (74%)] Loss: 20401.613281\n",
      "Train Epoch: 29 [169920/225000 (76%)] Loss: 20524.453125\n",
      "Train Epoch: 29 [172416/225000 (77%)] Loss: 20401.384766\n",
      "Train Epoch: 29 [174912/225000 (78%)] Loss: 20365.732422\n",
      "Train Epoch: 29 [177408/225000 (79%)] Loss: 20349.304688\n",
      "Train Epoch: 29 [179904/225000 (80%)] Loss: 20648.488281\n",
      "Train Epoch: 29 [182400/225000 (81%)] Loss: 20575.492188\n",
      "Train Epoch: 29 [184896/225000 (82%)] Loss: 20543.566406\n",
      "Train Epoch: 29 [187392/225000 (83%)] Loss: 20401.994141\n",
      "Train Epoch: 29 [189888/225000 (84%)] Loss: 20202.382812\n",
      "Train Epoch: 29 [192384/225000 (86%)] Loss: 20732.777344\n",
      "Train Epoch: 29 [194880/225000 (87%)] Loss: 20244.142578\n",
      "Train Epoch: 29 [197376/225000 (88%)] Loss: 20265.242188\n",
      "Train Epoch: 29 [199872/225000 (89%)] Loss: 20375.392578\n",
      "Train Epoch: 29 [202368/225000 (90%)] Loss: 20266.406250\n",
      "Train Epoch: 29 [204864/225000 (91%)] Loss: 20471.441406\n",
      "Train Epoch: 29 [207360/225000 (92%)] Loss: 20150.728516\n",
      "Train Epoch: 29 [209856/225000 (93%)] Loss: 20069.750000\n",
      "Train Epoch: 29 [212352/225000 (94%)] Loss: 20364.457031\n",
      "Train Epoch: 29 [214848/225000 (95%)] Loss: 20033.882812\n",
      "Train Epoch: 29 [217344/225000 (97%)] Loss: 20227.273438\n",
      "Train Epoch: 29 [219840/225000 (98%)] Loss: 20180.908203\n",
      "Train Epoch: 29 [222336/225000 (99%)] Loss: 20034.687500\n",
      "Train Epoch: 29 [224832/225000 (100%)] Loss: 19847.746094\n",
      "    epoch          : 29\n",
      "    loss           : 20355.024442392812\n",
      "    val_loss       : 20245.045007535973\n",
      "Train Epoch: 30 [192/225000 (0%)] Loss: 19981.513672\n",
      "Train Epoch: 30 [2688/225000 (1%)] Loss: 20643.281250\n",
      "Train Epoch: 30 [5184/225000 (2%)] Loss: 20646.544922\n",
      "Train Epoch: 30 [7680/225000 (3%)] Loss: 20070.433594\n",
      "Train Epoch: 30 [10176/225000 (5%)] Loss: 19918.285156\n",
      "Train Epoch: 30 [12672/225000 (6%)] Loss: 20445.222656\n",
      "Train Epoch: 30 [15168/225000 (7%)] Loss: 20298.791016\n",
      "Train Epoch: 30 [17664/225000 (8%)] Loss: 20045.265625\n",
      "Train Epoch: 30 [20160/225000 (9%)] Loss: 20308.375000\n",
      "Train Epoch: 30 [22656/225000 (10%)] Loss: 20287.658203\n",
      "Train Epoch: 30 [25152/225000 (11%)] Loss: 20203.314453\n",
      "Train Epoch: 30 [27648/225000 (12%)] Loss: 20395.308594\n",
      "Train Epoch: 30 [30144/225000 (13%)] Loss: 20283.578125\n",
      "Train Epoch: 30 [32640/225000 (15%)] Loss: 20063.343750\n",
      "Train Epoch: 30 [35136/225000 (16%)] Loss: 20096.939453\n",
      "Train Epoch: 30 [37632/225000 (17%)] Loss: 20134.572266\n",
      "Train Epoch: 30 [40128/225000 (18%)] Loss: 20508.183594\n",
      "Train Epoch: 30 [42624/225000 (19%)] Loss: 20514.992188\n",
      "Train Epoch: 30 [45120/225000 (20%)] Loss: 21280.826172\n",
      "Train Epoch: 30 [47616/225000 (21%)] Loss: 20770.902344\n",
      "Train Epoch: 30 [50112/225000 (22%)] Loss: 20032.087891\n",
      "Train Epoch: 30 [52608/225000 (23%)] Loss: 20117.585938\n",
      "Train Epoch: 30 [55104/225000 (24%)] Loss: 20249.332031\n",
      "Train Epoch: 30 [57600/225000 (26%)] Loss: 20428.142578\n",
      "Train Epoch: 30 [60096/225000 (27%)] Loss: 19875.097656\n",
      "Train Epoch: 30 [62592/225000 (28%)] Loss: 21014.308594\n",
      "Train Epoch: 30 [65088/225000 (29%)] Loss: 20656.808594\n",
      "Train Epoch: 30 [67584/225000 (30%)] Loss: 20612.414062\n",
      "Train Epoch: 30 [70080/225000 (31%)] Loss: 20085.785156\n",
      "Train Epoch: 30 [72576/225000 (32%)] Loss: 20035.953125\n",
      "Train Epoch: 30 [75072/225000 (33%)] Loss: 20604.244141\n",
      "Train Epoch: 30 [77568/225000 (34%)] Loss: 20604.076172\n",
      "Train Epoch: 30 [80064/225000 (36%)] Loss: 20106.023438\n",
      "Train Epoch: 30 [82560/225000 (37%)] Loss: 20521.691406\n",
      "Train Epoch: 30 [85056/225000 (38%)] Loss: 20527.787109\n",
      "Train Epoch: 30 [87552/225000 (39%)] Loss: 19991.851562\n",
      "Train Epoch: 30 [90048/225000 (40%)] Loss: 20359.207031\n",
      "Train Epoch: 30 [92544/225000 (41%)] Loss: 20085.375000\n",
      "Train Epoch: 30 [95040/225000 (42%)] Loss: 20125.074219\n",
      "Train Epoch: 30 [97536/225000 (43%)] Loss: 20371.980469\n",
      "Train Epoch: 30 [100032/225000 (44%)] Loss: 20420.667969\n",
      "Train Epoch: 30 [102528/225000 (46%)] Loss: 20565.027344\n",
      "Train Epoch: 30 [105024/225000 (47%)] Loss: 20267.640625\n",
      "Train Epoch: 30 [107520/225000 (48%)] Loss: 20448.539062\n",
      "Train Epoch: 30 [110016/225000 (49%)] Loss: 20839.363281\n",
      "Train Epoch: 30 [112512/225000 (50%)] Loss: 19881.705078\n",
      "Train Epoch: 30 [115008/225000 (51%)] Loss: 20336.398438\n",
      "Train Epoch: 30 [117504/225000 (52%)] Loss: 20551.957031\n",
      "Train Epoch: 30 [120000/225000 (53%)] Loss: 20118.656250\n",
      "Train Epoch: 30 [122496/225000 (54%)] Loss: 20672.800781\n",
      "Train Epoch: 30 [124992/225000 (56%)] Loss: 20378.402344\n",
      "Train Epoch: 30 [127488/225000 (57%)] Loss: 20116.203125\n",
      "Train Epoch: 30 [129984/225000 (58%)] Loss: 20119.035156\n",
      "Train Epoch: 30 [132480/225000 (59%)] Loss: 20095.886719\n",
      "Train Epoch: 30 [134976/225000 (60%)] Loss: 20633.496094\n",
      "Train Epoch: 30 [137472/225000 (61%)] Loss: 20684.242188\n",
      "Train Epoch: 30 [139968/225000 (62%)] Loss: 20075.320312\n",
      "Train Epoch: 30 [142464/225000 (63%)] Loss: 20369.179688\n",
      "Train Epoch: 30 [144960/225000 (64%)] Loss: 19879.082031\n",
      "Train Epoch: 30 [147456/225000 (66%)] Loss: 20271.312500\n",
      "Train Epoch: 30 [149952/225000 (67%)] Loss: 20549.144531\n",
      "Train Epoch: 30 [152448/225000 (68%)] Loss: 20266.683594\n",
      "Train Epoch: 30 [154944/225000 (69%)] Loss: 20314.050781\n",
      "Train Epoch: 30 [157440/225000 (70%)] Loss: 20066.636719\n",
      "Train Epoch: 30 [159936/225000 (71%)] Loss: 20042.285156\n",
      "Train Epoch: 30 [162432/225000 (72%)] Loss: 20291.144531\n",
      "Train Epoch: 30 [164928/225000 (73%)] Loss: 20398.390625\n",
      "Train Epoch: 30 [167424/225000 (74%)] Loss: 20605.503906\n",
      "Train Epoch: 30 [169920/225000 (76%)] Loss: 20576.011719\n",
      "Train Epoch: 30 [172416/225000 (77%)] Loss: 20270.066406\n",
      "Train Epoch: 30 [174912/225000 (78%)] Loss: 20243.414062\n",
      "Train Epoch: 30 [177408/225000 (79%)] Loss: 20940.361328\n",
      "Train Epoch: 30 [179904/225000 (80%)] Loss: 20368.949219\n",
      "Train Epoch: 30 [182400/225000 (81%)] Loss: 19901.261719\n",
      "Train Epoch: 30 [184896/225000 (82%)] Loss: 20358.570312\n",
      "Train Epoch: 30 [187392/225000 (83%)] Loss: 20325.980469\n",
      "Train Epoch: 30 [189888/225000 (84%)] Loss: 20611.556641\n",
      "Train Epoch: 30 [192384/225000 (86%)] Loss: 20296.505859\n",
      "Train Epoch: 30 [194880/225000 (87%)] Loss: 20460.406250\n",
      "Train Epoch: 30 [197376/225000 (88%)] Loss: 20794.416016\n",
      "Train Epoch: 30 [199872/225000 (89%)] Loss: 20368.710938\n",
      "Train Epoch: 30 [202368/225000 (90%)] Loss: 20711.433594\n",
      "Train Epoch: 30 [204864/225000 (91%)] Loss: 20307.574219\n",
      "Train Epoch: 30 [207360/225000 (92%)] Loss: 19733.029297\n",
      "Train Epoch: 30 [209856/225000 (93%)] Loss: 20104.894531\n",
      "Train Epoch: 30 [212352/225000 (94%)] Loss: 20600.531250\n",
      "Train Epoch: 30 [214848/225000 (95%)] Loss: 20401.533203\n",
      "Train Epoch: 30 [217344/225000 (97%)] Loss: 20408.785156\n",
      "Train Epoch: 30 [219840/225000 (98%)] Loss: 20270.005859\n",
      "Train Epoch: 30 [222336/225000 (99%)] Loss: 20713.617188\n",
      "Train Epoch: 30 [224832/225000 (100%)] Loss: 20146.183594\n",
      "    epoch          : 30\n",
      "    loss           : 20335.489814419794\n",
      "    val_loss       : 20241.360062311625\n",
      "Train Epoch: 31 [192/225000 (0%)] Loss: 20060.904297\n",
      "Train Epoch: 31 [2688/225000 (1%)] Loss: 20706.054688\n",
      "Train Epoch: 31 [5184/225000 (2%)] Loss: 20749.453125\n",
      "Train Epoch: 31 [7680/225000 (3%)] Loss: 20113.044922\n",
      "Train Epoch: 31 [10176/225000 (5%)] Loss: 20232.980469\n",
      "Train Epoch: 31 [12672/225000 (6%)] Loss: 20360.335938\n",
      "Train Epoch: 31 [15168/225000 (7%)] Loss: 20076.544922\n",
      "Train Epoch: 31 [17664/225000 (8%)] Loss: 20152.894531\n",
      "Train Epoch: 31 [20160/225000 (9%)] Loss: 20719.640625\n",
      "Train Epoch: 31 [22656/225000 (10%)] Loss: 20256.787109\n",
      "Train Epoch: 31 [25152/225000 (11%)] Loss: 20074.312500\n",
      "Train Epoch: 31 [27648/225000 (12%)] Loss: 20422.722656\n",
      "Train Epoch: 31 [30144/225000 (13%)] Loss: 20247.734375\n",
      "Train Epoch: 31 [32640/225000 (15%)] Loss: 20274.628906\n",
      "Train Epoch: 31 [35136/225000 (16%)] Loss: 20371.875000\n",
      "Train Epoch: 31 [37632/225000 (17%)] Loss: 20465.380859\n",
      "Train Epoch: 31 [40128/225000 (18%)] Loss: 20361.132812\n",
      "Train Epoch: 31 [42624/225000 (19%)] Loss: 20482.480469\n",
      "Train Epoch: 31 [45120/225000 (20%)] Loss: 20292.898438\n",
      "Train Epoch: 31 [47616/225000 (21%)] Loss: 20436.410156\n",
      "Train Epoch: 31 [50112/225000 (22%)] Loss: 20693.535156\n",
      "Train Epoch: 31 [52608/225000 (23%)] Loss: 20426.304688\n",
      "Train Epoch: 31 [55104/225000 (24%)] Loss: 20086.578125\n",
      "Train Epoch: 31 [57600/225000 (26%)] Loss: 20149.646484\n",
      "Train Epoch: 31 [60096/225000 (27%)] Loss: 20200.949219\n",
      "Train Epoch: 31 [62592/225000 (28%)] Loss: 19400.457031\n",
      "Train Epoch: 31 [65088/225000 (29%)] Loss: 20454.343750\n",
      "Train Epoch: 31 [67584/225000 (30%)] Loss: 20383.558594\n",
      "Train Epoch: 31 [70080/225000 (31%)] Loss: 20087.746094\n",
      "Train Epoch: 31 [72576/225000 (32%)] Loss: 20011.164062\n",
      "Train Epoch: 31 [75072/225000 (33%)] Loss: 20536.460938\n",
      "Train Epoch: 31 [77568/225000 (34%)] Loss: 20284.169922\n",
      "Train Epoch: 31 [80064/225000 (36%)] Loss: 20329.472656\n",
      "Train Epoch: 31 [82560/225000 (37%)] Loss: 20608.341797\n",
      "Train Epoch: 31 [85056/225000 (38%)] Loss: 20309.109375\n",
      "Train Epoch: 31 [87552/225000 (39%)] Loss: 20483.714844\n",
      "Train Epoch: 31 [90048/225000 (40%)] Loss: 20490.835938\n",
      "Train Epoch: 31 [92544/225000 (41%)] Loss: 20097.730469\n",
      "Train Epoch: 31 [95040/225000 (42%)] Loss: 20377.140625\n",
      "Train Epoch: 31 [97536/225000 (43%)] Loss: 20464.312500\n",
      "Train Epoch: 31 [100032/225000 (44%)] Loss: 20683.066406\n",
      "Train Epoch: 31 [102528/225000 (46%)] Loss: 19699.261719\n",
      "Train Epoch: 31 [105024/225000 (47%)] Loss: 19990.144531\n",
      "Train Epoch: 31 [107520/225000 (48%)] Loss: 20237.201172\n",
      "Train Epoch: 31 [110016/225000 (49%)] Loss: 20676.541016\n",
      "Train Epoch: 31 [112512/225000 (50%)] Loss: 20406.023438\n",
      "Train Epoch: 31 [115008/225000 (51%)] Loss: 20107.476562\n",
      "Train Epoch: 31 [117504/225000 (52%)] Loss: 19967.757812\n",
      "Train Epoch: 31 [120000/225000 (53%)] Loss: 20442.347656\n",
      "Train Epoch: 31 [122496/225000 (54%)] Loss: 20360.585938\n",
      "Train Epoch: 31 [124992/225000 (56%)] Loss: 20359.609375\n",
      "Train Epoch: 31 [127488/225000 (57%)] Loss: 20043.828125\n",
      "Train Epoch: 31 [129984/225000 (58%)] Loss: 20394.015625\n",
      "Train Epoch: 31 [132480/225000 (59%)] Loss: 20781.109375\n",
      "Train Epoch: 31 [134976/225000 (60%)] Loss: 20274.136719\n",
      "Train Epoch: 31 [137472/225000 (61%)] Loss: 20141.011719\n",
      "Train Epoch: 31 [139968/225000 (62%)] Loss: 20207.132812\n",
      "Train Epoch: 31 [142464/225000 (63%)] Loss: 20172.035156\n",
      "Train Epoch: 31 [144960/225000 (64%)] Loss: 20388.101562\n",
      "Train Epoch: 31 [147456/225000 (66%)] Loss: 20360.666016\n",
      "Train Epoch: 31 [149952/225000 (67%)] Loss: 19882.902344\n",
      "Train Epoch: 31 [152448/225000 (68%)] Loss: 20148.060547\n",
      "Train Epoch: 31 [154944/225000 (69%)] Loss: 19739.328125\n",
      "Train Epoch: 31 [157440/225000 (70%)] Loss: 20249.326172\n",
      "Train Epoch: 31 [159936/225000 (71%)] Loss: 20195.386719\n",
      "Train Epoch: 31 [162432/225000 (72%)] Loss: 20845.578125\n",
      "Train Epoch: 31 [164928/225000 (73%)] Loss: 20282.806641\n",
      "Train Epoch: 31 [167424/225000 (74%)] Loss: 20877.914062\n",
      "Train Epoch: 31 [169920/225000 (76%)] Loss: 20308.132812\n",
      "Train Epoch: 31 [172416/225000 (77%)] Loss: 20606.515625\n",
      "Train Epoch: 31 [174912/225000 (78%)] Loss: 20383.490234\n",
      "Train Epoch: 31 [177408/225000 (79%)] Loss: 20423.625000\n",
      "Train Epoch: 31 [179904/225000 (80%)] Loss: 20018.636719\n",
      "Train Epoch: 31 [182400/225000 (81%)] Loss: 20115.210938\n",
      "Train Epoch: 31 [184896/225000 (82%)] Loss: 20494.964844\n",
      "Train Epoch: 31 [187392/225000 (83%)] Loss: 19747.468750\n",
      "Train Epoch: 31 [189888/225000 (84%)] Loss: 20237.078125\n",
      "Train Epoch: 31 [192384/225000 (86%)] Loss: 20675.898438\n",
      "Train Epoch: 31 [194880/225000 (87%)] Loss: 20918.800781\n",
      "Train Epoch: 31 [197376/225000 (88%)] Loss: 20181.654297\n",
      "Train Epoch: 31 [199872/225000 (89%)] Loss: 20096.332031\n",
      "Train Epoch: 31 [202368/225000 (90%)] Loss: 20169.800781\n",
      "Train Epoch: 31 [204864/225000 (91%)] Loss: 20888.796875\n",
      "Train Epoch: 31 [207360/225000 (92%)] Loss: 20685.097656\n",
      "Train Epoch: 31 [209856/225000 (93%)] Loss: 20217.824219\n",
      "Train Epoch: 31 [212352/225000 (94%)] Loss: 20300.238281\n",
      "Train Epoch: 31 [214848/225000 (95%)] Loss: 20404.570312\n",
      "Train Epoch: 31 [217344/225000 (97%)] Loss: 20193.882812\n",
      "Train Epoch: 31 [219840/225000 (98%)] Loss: 20048.058594\n",
      "Train Epoch: 31 [222336/225000 (99%)] Loss: 20392.285156\n",
      "Train Epoch: 31 [224832/225000 (100%)] Loss: 20008.544922\n",
      "    epoch          : 31\n",
      "    loss           : 20328.762631985923\n",
      "    val_loss       : 20229.432509150214\n",
      "Train Epoch: 32 [192/225000 (0%)] Loss: 20396.906250\n",
      "Train Epoch: 32 [2688/225000 (1%)] Loss: 20309.371094\n",
      "Train Epoch: 32 [5184/225000 (2%)] Loss: 20057.587891\n",
      "Train Epoch: 32 [7680/225000 (3%)] Loss: 20112.746094\n",
      "Train Epoch: 32 [10176/225000 (5%)] Loss: 20474.230469\n",
      "Train Epoch: 32 [12672/225000 (6%)] Loss: 20949.669922\n",
      "Train Epoch: 32 [15168/225000 (7%)] Loss: 20326.226562\n",
      "Train Epoch: 32 [17664/225000 (8%)] Loss: 19981.824219\n",
      "Train Epoch: 32 [20160/225000 (9%)] Loss: 19809.718750\n",
      "Train Epoch: 32 [22656/225000 (10%)] Loss: 20442.894531\n",
      "Train Epoch: 32 [25152/225000 (11%)] Loss: 20390.113281\n",
      "Train Epoch: 32 [27648/225000 (12%)] Loss: 20111.148438\n",
      "Train Epoch: 32 [30144/225000 (13%)] Loss: 20139.490234\n",
      "Train Epoch: 32 [32640/225000 (15%)] Loss: 20282.566406\n",
      "Train Epoch: 32 [35136/225000 (16%)] Loss: 20538.019531\n",
      "Train Epoch: 32 [37632/225000 (17%)] Loss: 19692.421875\n",
      "Train Epoch: 32 [40128/225000 (18%)] Loss: 20727.117188\n",
      "Train Epoch: 32 [42624/225000 (19%)] Loss: 20198.960938\n",
      "Train Epoch: 32 [45120/225000 (20%)] Loss: 19877.814453\n",
      "Train Epoch: 32 [47616/225000 (21%)] Loss: 20186.644531\n",
      "Train Epoch: 32 [50112/225000 (22%)] Loss: 20489.839844\n",
      "Train Epoch: 32 [52608/225000 (23%)] Loss: 20126.179688\n",
      "Train Epoch: 32 [55104/225000 (24%)] Loss: 20289.804688\n",
      "Train Epoch: 32 [57600/225000 (26%)] Loss: 20535.269531\n",
      "Train Epoch: 32 [60096/225000 (27%)] Loss: 20362.986328\n",
      "Train Epoch: 32 [62592/225000 (28%)] Loss: 20603.796875\n",
      "Train Epoch: 32 [65088/225000 (29%)] Loss: 20418.449219\n",
      "Train Epoch: 32 [67584/225000 (30%)] Loss: 20276.683594\n",
      "Train Epoch: 32 [70080/225000 (31%)] Loss: 20026.585938\n",
      "Train Epoch: 32 [72576/225000 (32%)] Loss: 20596.708984\n",
      "Train Epoch: 32 [75072/225000 (33%)] Loss: 20202.000000\n",
      "Train Epoch: 32 [77568/225000 (34%)] Loss: 21001.910156\n",
      "Train Epoch: 32 [80064/225000 (36%)] Loss: 20322.503906\n",
      "Train Epoch: 32 [82560/225000 (37%)] Loss: 20150.097656\n",
      "Train Epoch: 32 [85056/225000 (38%)] Loss: 20797.054688\n",
      "Train Epoch: 32 [87552/225000 (39%)] Loss: 19910.658203\n",
      "Train Epoch: 32 [90048/225000 (40%)] Loss: 20187.691406\n",
      "Train Epoch: 32 [92544/225000 (41%)] Loss: 20356.281250\n",
      "Train Epoch: 32 [95040/225000 (42%)] Loss: 20134.712891\n",
      "Train Epoch: 32 [97536/225000 (43%)] Loss: 20317.384766\n",
      "Train Epoch: 32 [100032/225000 (44%)] Loss: 20171.796875\n",
      "Train Epoch: 32 [102528/225000 (46%)] Loss: 20731.238281\n",
      "Train Epoch: 32 [105024/225000 (47%)] Loss: 20530.277344\n",
      "Train Epoch: 32 [107520/225000 (48%)] Loss: 20154.759766\n",
      "Train Epoch: 32 [110016/225000 (49%)] Loss: 20403.824219\n",
      "Train Epoch: 32 [112512/225000 (50%)] Loss: 20615.931641\n",
      "Train Epoch: 32 [115008/225000 (51%)] Loss: 20553.050781\n",
      "Train Epoch: 32 [117504/225000 (52%)] Loss: 20740.679688\n",
      "Train Epoch: 32 [120000/225000 (53%)] Loss: 20460.937500\n",
      "Train Epoch: 32 [122496/225000 (54%)] Loss: 20424.035156\n",
      "Train Epoch: 32 [124992/225000 (56%)] Loss: 20382.027344\n",
      "Train Epoch: 32 [127488/225000 (57%)] Loss: 20579.007812\n",
      "Train Epoch: 32 [129984/225000 (58%)] Loss: 19911.798828\n",
      "Train Epoch: 32 [132480/225000 (59%)] Loss: 19780.378906\n",
      "Train Epoch: 32 [134976/225000 (60%)] Loss: 20800.271484\n",
      "Train Epoch: 32 [137472/225000 (61%)] Loss: 19851.888672\n",
      "Train Epoch: 32 [139968/225000 (62%)] Loss: 20463.324219\n",
      "Train Epoch: 32 [142464/225000 (63%)] Loss: 20481.851562\n",
      "Train Epoch: 32 [144960/225000 (64%)] Loss: 20756.253906\n",
      "Train Epoch: 32 [147456/225000 (66%)] Loss: 20235.189453\n",
      "Train Epoch: 32 [149952/225000 (67%)] Loss: 20335.546875\n",
      "Train Epoch: 32 [152448/225000 (68%)] Loss: 20314.431641\n",
      "Train Epoch: 32 [154944/225000 (69%)] Loss: 20154.562500\n",
      "Train Epoch: 32 [157440/225000 (70%)] Loss: 20257.933594\n",
      "Train Epoch: 32 [159936/225000 (71%)] Loss: 19975.183594\n",
      "Train Epoch: 32 [162432/225000 (72%)] Loss: 20389.222656\n",
      "Train Epoch: 32 [164928/225000 (73%)] Loss: 19830.623047\n",
      "Train Epoch: 32 [167424/225000 (74%)] Loss: 19339.476562\n",
      "Train Epoch: 32 [169920/225000 (76%)] Loss: 20324.042969\n",
      "Train Epoch: 32 [172416/225000 (77%)] Loss: 20090.035156\n",
      "Train Epoch: 32 [174912/225000 (78%)] Loss: 20686.587891\n",
      "Train Epoch: 32 [177408/225000 (79%)] Loss: 20463.070312\n",
      "Train Epoch: 32 [179904/225000 (80%)] Loss: 20363.250000\n",
      "Train Epoch: 32 [182400/225000 (81%)] Loss: 20218.566406\n",
      "Train Epoch: 32 [184896/225000 (82%)] Loss: 20477.042969\n",
      "Train Epoch: 32 [187392/225000 (83%)] Loss: 20676.671875\n",
      "Train Epoch: 32 [189888/225000 (84%)] Loss: 20216.062500\n",
      "Train Epoch: 32 [192384/225000 (86%)] Loss: 20798.283203\n",
      "Train Epoch: 32 [194880/225000 (87%)] Loss: 20519.292969\n",
      "Train Epoch: 32 [197376/225000 (88%)] Loss: 20533.300781\n",
      "Train Epoch: 32 [199872/225000 (89%)] Loss: 20140.429688\n",
      "Train Epoch: 32 [202368/225000 (90%)] Loss: 20405.660156\n",
      "Train Epoch: 32 [204864/225000 (91%)] Loss: 20329.792969\n",
      "Train Epoch: 32 [207360/225000 (92%)] Loss: 20403.562500\n",
      "Train Epoch: 32 [209856/225000 (93%)] Loss: 21018.750000\n",
      "Train Epoch: 32 [212352/225000 (94%)] Loss: 20578.027344\n",
      "Train Epoch: 32 [214848/225000 (95%)] Loss: 20200.156250\n",
      "Train Epoch: 32 [217344/225000 (97%)] Loss: 20770.292969\n",
      "Train Epoch: 32 [219840/225000 (98%)] Loss: 20355.074219\n",
      "Train Epoch: 32 [222336/225000 (99%)] Loss: 21349.750000\n",
      "Train Epoch: 32 [224832/225000 (100%)] Loss: 20207.976562\n",
      "    epoch          : 32\n",
      "    loss           : 20326.175196312393\n",
      "    val_loss       : 20231.138168018282\n",
      "Train Epoch: 33 [192/225000 (0%)] Loss: 20456.566406\n",
      "Train Epoch: 33 [2688/225000 (1%)] Loss: 19978.738281\n",
      "Train Epoch: 33 [5184/225000 (2%)] Loss: 20315.980469\n",
      "Train Epoch: 33 [7680/225000 (3%)] Loss: 20194.546875\n",
      "Train Epoch: 33 [10176/225000 (5%)] Loss: 20555.898438\n",
      "Train Epoch: 33 [12672/225000 (6%)] Loss: 20685.574219\n",
      "Train Epoch: 33 [15168/225000 (7%)] Loss: 20356.388672\n",
      "Train Epoch: 33 [17664/225000 (8%)] Loss: 20253.753906\n",
      "Train Epoch: 33 [20160/225000 (9%)] Loss: 20111.890625\n",
      "Train Epoch: 33 [22656/225000 (10%)] Loss: 20188.949219\n",
      "Train Epoch: 33 [25152/225000 (11%)] Loss: 20042.980469\n",
      "Train Epoch: 33 [27648/225000 (12%)] Loss: 20077.792969\n",
      "Train Epoch: 33 [30144/225000 (13%)] Loss: 19843.351562\n",
      "Train Epoch: 33 [32640/225000 (15%)] Loss: 20464.429688\n",
      "Train Epoch: 33 [35136/225000 (16%)] Loss: 20338.621094\n",
      "Train Epoch: 33 [37632/225000 (17%)] Loss: 20315.417969\n",
      "Train Epoch: 33 [40128/225000 (18%)] Loss: 20491.402344\n",
      "Train Epoch: 33 [42624/225000 (19%)] Loss: 20397.386719\n",
      "Train Epoch: 33 [45120/225000 (20%)] Loss: 20784.560547\n",
      "Train Epoch: 33 [47616/225000 (21%)] Loss: 20332.277344\n",
      "Train Epoch: 33 [50112/225000 (22%)] Loss: 20361.718750\n",
      "Train Epoch: 33 [52608/225000 (23%)] Loss: 20518.876953\n",
      "Train Epoch: 33 [55104/225000 (24%)] Loss: 20172.189453\n",
      "Train Epoch: 33 [57600/225000 (26%)] Loss: 20524.564453\n",
      "Train Epoch: 33 [60096/225000 (27%)] Loss: 20220.566406\n",
      "Train Epoch: 33 [62592/225000 (28%)] Loss: 20212.566406\n",
      "Train Epoch: 33 [65088/225000 (29%)] Loss: 19860.746094\n",
      "Train Epoch: 33 [67584/225000 (30%)] Loss: 19698.554688\n",
      "Train Epoch: 33 [70080/225000 (31%)] Loss: 20537.966797\n",
      "Train Epoch: 33 [72576/225000 (32%)] Loss: 21067.281250\n",
      "Train Epoch: 33 [75072/225000 (33%)] Loss: 19937.552734\n",
      "Train Epoch: 33 [77568/225000 (34%)] Loss: 20229.742188\n",
      "Train Epoch: 33 [80064/225000 (36%)] Loss: 20281.593750\n",
      "Train Epoch: 33 [82560/225000 (37%)] Loss: 20286.160156\n",
      "Train Epoch: 33 [85056/225000 (38%)] Loss: 20339.457031\n",
      "Train Epoch: 33 [87552/225000 (39%)] Loss: 20405.236328\n",
      "Train Epoch: 33 [90048/225000 (40%)] Loss: 19959.945312\n",
      "Train Epoch: 33 [92544/225000 (41%)] Loss: 20114.111328\n",
      "Train Epoch: 33 [95040/225000 (42%)] Loss: 20218.503906\n",
      "Train Epoch: 33 [97536/225000 (43%)] Loss: 20471.121094\n",
      "Train Epoch: 33 [100032/225000 (44%)] Loss: 20052.703125\n",
      "Train Epoch: 33 [102528/225000 (46%)] Loss: 20371.757812\n",
      "Train Epoch: 33 [105024/225000 (47%)] Loss: 19925.769531\n",
      "Train Epoch: 33 [107520/225000 (48%)] Loss: 20091.457031\n",
      "Train Epoch: 33 [110016/225000 (49%)] Loss: 20528.197266\n",
      "Train Epoch: 33 [112512/225000 (50%)] Loss: 19975.630859\n",
      "Train Epoch: 33 [115008/225000 (51%)] Loss: 20104.359375\n",
      "Train Epoch: 33 [117504/225000 (52%)] Loss: 20357.363281\n",
      "Train Epoch: 33 [120000/225000 (53%)] Loss: 20364.824219\n",
      "Train Epoch: 33 [122496/225000 (54%)] Loss: 20208.628906\n",
      "Train Epoch: 33 [124992/225000 (56%)] Loss: 20354.570312\n",
      "Train Epoch: 33 [127488/225000 (57%)] Loss: 20523.353516\n",
      "Train Epoch: 33 [129984/225000 (58%)] Loss: 19976.031250\n",
      "Train Epoch: 33 [132480/225000 (59%)] Loss: 21016.171875\n",
      "Train Epoch: 33 [134976/225000 (60%)] Loss: 20302.726562\n",
      "Train Epoch: 33 [137472/225000 (61%)] Loss: 20700.742188\n",
      "Train Epoch: 33 [139968/225000 (62%)] Loss: 20330.750000\n",
      "Train Epoch: 33 [142464/225000 (63%)] Loss: 20038.474609\n",
      "Train Epoch: 33 [144960/225000 (64%)] Loss: 20421.130859\n",
      "Train Epoch: 33 [147456/225000 (66%)] Loss: 20398.646484\n",
      "Train Epoch: 33 [149952/225000 (67%)] Loss: 20465.861328\n",
      "Train Epoch: 33 [152448/225000 (68%)] Loss: 20567.070312\n",
      "Train Epoch: 33 [154944/225000 (69%)] Loss: 19795.242188\n",
      "Train Epoch: 33 [157440/225000 (70%)] Loss: 20549.539062\n",
      "Train Epoch: 33 [159936/225000 (71%)] Loss: 20176.148438\n",
      "Train Epoch: 33 [162432/225000 (72%)] Loss: 20005.625000\n",
      "Train Epoch: 33 [164928/225000 (73%)] Loss: 20509.564453\n",
      "Train Epoch: 33 [167424/225000 (74%)] Loss: 20256.837891\n",
      "Train Epoch: 33 [169920/225000 (76%)] Loss: 19879.121094\n",
      "Train Epoch: 33 [172416/225000 (77%)] Loss: 20361.396484\n",
      "Train Epoch: 33 [174912/225000 (78%)] Loss: 20382.470703\n",
      "Train Epoch: 33 [177408/225000 (79%)] Loss: 20499.527344\n",
      "Train Epoch: 33 [179904/225000 (80%)] Loss: 20110.832031\n",
      "Train Epoch: 33 [182400/225000 (81%)] Loss: 20559.742188\n",
      "Train Epoch: 33 [184896/225000 (82%)] Loss: 20223.425781\n",
      "Train Epoch: 33 [187392/225000 (83%)] Loss: 20682.052734\n",
      "Train Epoch: 33 [189888/225000 (84%)] Loss: 20696.093750\n",
      "Train Epoch: 33 [192384/225000 (86%)] Loss: 20484.285156\n",
      "Train Epoch: 33 [194880/225000 (87%)] Loss: 20764.140625\n",
      "Train Epoch: 33 [197376/225000 (88%)] Loss: 20456.796875\n",
      "Train Epoch: 33 [199872/225000 (89%)] Loss: 20574.335938\n",
      "Train Epoch: 33 [202368/225000 (90%)] Loss: 20113.644531\n",
      "Train Epoch: 33 [204864/225000 (91%)] Loss: 20151.835938\n",
      "Train Epoch: 33 [207360/225000 (92%)] Loss: 20155.425781\n",
      "Train Epoch: 33 [209856/225000 (93%)] Loss: 20249.013672\n",
      "Train Epoch: 33 [212352/225000 (94%)] Loss: 20574.113281\n",
      "Train Epoch: 33 [214848/225000 (95%)] Loss: 20485.570312\n",
      "Train Epoch: 33 [217344/225000 (97%)] Loss: 20605.558594\n",
      "Train Epoch: 33 [219840/225000 (98%)] Loss: 20134.738281\n",
      "Train Epoch: 33 [222336/225000 (99%)] Loss: 20406.419922\n",
      "Train Epoch: 33 [224832/225000 (100%)] Loss: 20612.361328\n",
      "    epoch          : 33\n",
      "    loss           : 20325.375939899743\n",
      "    val_loss       : 20215.819059460217\n",
      "Train Epoch: 34 [192/225000 (0%)] Loss: 20490.923828\n",
      "Train Epoch: 34 [2688/225000 (1%)] Loss: 20071.140625\n",
      "Train Epoch: 34 [5184/225000 (2%)] Loss: 20505.507812\n",
      "Train Epoch: 34 [7680/225000 (3%)] Loss: 20449.892578\n",
      "Train Epoch: 34 [10176/225000 (5%)] Loss: 20545.480469\n",
      "Train Epoch: 34 [12672/225000 (6%)] Loss: 20374.228516\n",
      "Train Epoch: 34 [15168/225000 (7%)] Loss: 19985.542969\n",
      "Train Epoch: 34 [17664/225000 (8%)] Loss: 20377.800781\n",
      "Train Epoch: 34 [20160/225000 (9%)] Loss: 19710.404297\n",
      "Train Epoch: 34 [22656/225000 (10%)] Loss: 19900.136719\n",
      "Train Epoch: 34 [25152/225000 (11%)] Loss: 20319.707031\n",
      "Train Epoch: 34 [27648/225000 (12%)] Loss: 20229.781250\n",
      "Train Epoch: 34 [30144/225000 (13%)] Loss: 19812.218750\n",
      "Train Epoch: 34 [32640/225000 (15%)] Loss: 20085.593750\n",
      "Train Epoch: 34 [35136/225000 (16%)] Loss: 20158.453125\n",
      "Train Epoch: 34 [37632/225000 (17%)] Loss: 20822.761719\n",
      "Train Epoch: 34 [40128/225000 (18%)] Loss: 20242.126953\n",
      "Train Epoch: 34 [42624/225000 (19%)] Loss: 20831.820312\n",
      "Train Epoch: 34 [45120/225000 (20%)] Loss: 20804.804688\n",
      "Train Epoch: 34 [47616/225000 (21%)] Loss: 20227.802734\n",
      "Train Epoch: 34 [50112/225000 (22%)] Loss: 20467.710938\n",
      "Train Epoch: 34 [52608/225000 (23%)] Loss: 19951.531250\n",
      "Train Epoch: 34 [55104/225000 (24%)] Loss: 20456.996094\n",
      "Train Epoch: 34 [57600/225000 (26%)] Loss: 19814.345703\n",
      "Train Epoch: 34 [60096/225000 (27%)] Loss: 20371.167969\n",
      "Train Epoch: 34 [62592/225000 (28%)] Loss: 19858.957031\n",
      "Train Epoch: 34 [65088/225000 (29%)] Loss: 20506.009766\n",
      "Train Epoch: 34 [67584/225000 (30%)] Loss: 20342.574219\n",
      "Train Epoch: 34 [70080/225000 (31%)] Loss: 20324.675781\n",
      "Train Epoch: 34 [72576/225000 (32%)] Loss: 20801.580078\n",
      "Train Epoch: 34 [75072/225000 (33%)] Loss: 20714.986328\n",
      "Train Epoch: 34 [77568/225000 (34%)] Loss: 20005.785156\n",
      "Train Epoch: 34 [80064/225000 (36%)] Loss: 20598.972656\n",
      "Train Epoch: 34 [82560/225000 (37%)] Loss: 20273.363281\n",
      "Train Epoch: 34 [85056/225000 (38%)] Loss: 19924.230469\n",
      "Train Epoch: 34 [87552/225000 (39%)] Loss: 20493.896484\n",
      "Train Epoch: 34 [90048/225000 (40%)] Loss: 20184.117188\n",
      "Train Epoch: 34 [92544/225000 (41%)] Loss: 20701.251953\n",
      "Train Epoch: 34 [95040/225000 (42%)] Loss: 20440.136719\n",
      "Train Epoch: 34 [97536/225000 (43%)] Loss: 20000.373047\n",
      "Train Epoch: 34 [100032/225000 (44%)] Loss: 20210.464844\n",
      "Train Epoch: 34 [102528/225000 (46%)] Loss: 20037.304688\n",
      "Train Epoch: 34 [105024/225000 (47%)] Loss: 20176.017578\n",
      "Train Epoch: 34 [107520/225000 (48%)] Loss: 20281.457031\n",
      "Train Epoch: 34 [110016/225000 (49%)] Loss: 20580.949219\n",
      "Train Epoch: 34 [112512/225000 (50%)] Loss: 19938.578125\n",
      "Train Epoch: 34 [115008/225000 (51%)] Loss: 20159.130859\n",
      "Train Epoch: 34 [117504/225000 (52%)] Loss: 19947.042969\n",
      "Train Epoch: 34 [120000/225000 (53%)] Loss: 20520.173828\n",
      "Train Epoch: 34 [122496/225000 (54%)] Loss: 20022.437500\n",
      "Train Epoch: 34 [124992/225000 (56%)] Loss: 20302.017578\n",
      "Train Epoch: 34 [127488/225000 (57%)] Loss: 20278.929688\n",
      "Train Epoch: 34 [129984/225000 (58%)] Loss: 20307.375000\n",
      "Train Epoch: 34 [132480/225000 (59%)] Loss: 20089.947266\n",
      "Train Epoch: 34 [134976/225000 (60%)] Loss: 20396.582031\n",
      "Train Epoch: 34 [137472/225000 (61%)] Loss: 20391.406250\n",
      "Train Epoch: 34 [139968/225000 (62%)] Loss: 20240.703125\n",
      "Train Epoch: 34 [142464/225000 (63%)] Loss: 20639.335938\n",
      "Train Epoch: 34 [144960/225000 (64%)] Loss: 19962.605469\n",
      "Train Epoch: 34 [147456/225000 (66%)] Loss: 20534.984375\n",
      "Train Epoch: 34 [149952/225000 (67%)] Loss: 20631.480469\n",
      "Train Epoch: 34 [152448/225000 (68%)] Loss: 20000.761719\n",
      "Train Epoch: 34 [154944/225000 (69%)] Loss: 20474.027344\n",
      "Train Epoch: 34 [157440/225000 (70%)] Loss: 20245.617188\n",
      "Train Epoch: 34 [159936/225000 (71%)] Loss: 19669.613281\n",
      "Train Epoch: 34 [162432/225000 (72%)] Loss: 20629.199219\n",
      "Train Epoch: 34 [164928/225000 (73%)] Loss: 20305.220703\n",
      "Train Epoch: 34 [167424/225000 (74%)] Loss: 19885.128906\n",
      "Train Epoch: 34 [169920/225000 (76%)] Loss: 19831.435547\n",
      "Train Epoch: 34 [172416/225000 (77%)] Loss: 20437.429688\n",
      "Train Epoch: 34 [174912/225000 (78%)] Loss: 19690.398438\n",
      "Train Epoch: 34 [177408/225000 (79%)] Loss: 19919.728516\n",
      "Train Epoch: 34 [179904/225000 (80%)] Loss: 20636.441406\n",
      "Train Epoch: 34 [182400/225000 (81%)] Loss: 20673.343750\n",
      "Train Epoch: 34 [184896/225000 (82%)] Loss: 20675.113281\n",
      "Train Epoch: 34 [187392/225000 (83%)] Loss: 20046.695312\n",
      "Train Epoch: 34 [189888/225000 (84%)] Loss: 20514.226562\n",
      "Train Epoch: 34 [192384/225000 (86%)] Loss: 20126.738281\n",
      "Train Epoch: 34 [194880/225000 (87%)] Loss: 19900.169922\n",
      "Train Epoch: 34 [197376/225000 (88%)] Loss: 19806.423828\n",
      "Train Epoch: 34 [199872/225000 (89%)] Loss: 20154.257812\n",
      "Train Epoch: 34 [202368/225000 (90%)] Loss: 20076.642578\n",
      "Train Epoch: 34 [204864/225000 (91%)] Loss: 20735.302734\n",
      "Train Epoch: 34 [207360/225000 (92%)] Loss: 20446.636719\n",
      "Train Epoch: 34 [209856/225000 (93%)] Loss: 20344.242188\n",
      "Train Epoch: 34 [212352/225000 (94%)] Loss: 20265.937500\n",
      "Train Epoch: 34 [214848/225000 (95%)] Loss: 20353.511719\n",
      "Train Epoch: 34 [217344/225000 (97%)] Loss: 20552.355469\n",
      "Train Epoch: 34 [219840/225000 (98%)] Loss: 19611.707031\n",
      "Train Epoch: 34 [222336/225000 (99%)] Loss: 19823.011719\n",
      "Train Epoch: 34 [224832/225000 (100%)] Loss: 20288.265625\n",
      "    epoch          : 34\n",
      "    loss           : 20329.484551647824\n",
      "    val_loss       : 20248.77476262682\n",
      "Train Epoch: 35 [192/225000 (0%)] Loss: 20334.078125\n",
      "Train Epoch: 35 [2688/225000 (1%)] Loss: 20496.953125\n",
      "Train Epoch: 35 [5184/225000 (2%)] Loss: 20194.660156\n",
      "Train Epoch: 35 [7680/225000 (3%)] Loss: 20134.191406\n",
      "Train Epoch: 35 [10176/225000 (5%)] Loss: 20561.490234\n",
      "Train Epoch: 35 [12672/225000 (6%)] Loss: 20372.855469\n",
      "Train Epoch: 35 [15168/225000 (7%)] Loss: 19829.585938\n",
      "Train Epoch: 35 [17664/225000 (8%)] Loss: 20347.294922\n",
      "Train Epoch: 35 [20160/225000 (9%)] Loss: 20506.660156\n",
      "Train Epoch: 35 [22656/225000 (10%)] Loss: 20852.130859\n",
      "Train Epoch: 35 [25152/225000 (11%)] Loss: 20353.292969\n",
      "Train Epoch: 35 [27648/225000 (12%)] Loss: 20593.191406\n",
      "Train Epoch: 35 [30144/225000 (13%)] Loss: 20127.746094\n",
      "Train Epoch: 35 [32640/225000 (15%)] Loss: 20736.082031\n",
      "Train Epoch: 35 [35136/225000 (16%)] Loss: 20236.755859\n",
      "Train Epoch: 35 [37632/225000 (17%)] Loss: 20353.750000\n",
      "Train Epoch: 35 [40128/225000 (18%)] Loss: 20246.019531\n",
      "Train Epoch: 35 [42624/225000 (19%)] Loss: 20335.083984\n",
      "Train Epoch: 35 [45120/225000 (20%)] Loss: 20198.136719\n",
      "Train Epoch: 35 [47616/225000 (21%)] Loss: 20577.625000\n",
      "Train Epoch: 35 [50112/225000 (22%)] Loss: 19829.521484\n",
      "Train Epoch: 35 [52608/225000 (23%)] Loss: 20268.525391\n",
      "Train Epoch: 35 [55104/225000 (24%)] Loss: 20524.390625\n",
      "Train Epoch: 35 [57600/225000 (26%)] Loss: 20967.199219\n",
      "Train Epoch: 35 [60096/225000 (27%)] Loss: 19940.878906\n",
      "Train Epoch: 35 [62592/225000 (28%)] Loss: 20367.449219\n",
      "Train Epoch: 35 [65088/225000 (29%)] Loss: 20366.462891\n",
      "Train Epoch: 35 [67584/225000 (30%)] Loss: 20291.326172\n",
      "Train Epoch: 35 [70080/225000 (31%)] Loss: 20361.101562\n",
      "Train Epoch: 35 [72576/225000 (32%)] Loss: 19798.171875\n",
      "Train Epoch: 35 [75072/225000 (33%)] Loss: 20578.222656\n",
      "Train Epoch: 35 [77568/225000 (34%)] Loss: 19863.320312\n",
      "Train Epoch: 35 [80064/225000 (36%)] Loss: 20529.703125\n",
      "Train Epoch: 35 [82560/225000 (37%)] Loss: 20790.667969\n",
      "Train Epoch: 35 [85056/225000 (38%)] Loss: 20449.142578\n",
      "Train Epoch: 35 [87552/225000 (39%)] Loss: 19728.101562\n",
      "Train Epoch: 35 [90048/225000 (40%)] Loss: 20454.207031\n",
      "Train Epoch: 35 [92544/225000 (41%)] Loss: 20234.320312\n",
      "Train Epoch: 35 [95040/225000 (42%)] Loss: 20695.964844\n",
      "Train Epoch: 35 [97536/225000 (43%)] Loss: 20012.773438\n",
      "Train Epoch: 35 [100032/225000 (44%)] Loss: 20388.673828\n",
      "Train Epoch: 35 [102528/225000 (46%)] Loss: 20277.753906\n",
      "Train Epoch: 35 [105024/225000 (47%)] Loss: 20085.732422\n",
      "Train Epoch: 35 [107520/225000 (48%)] Loss: 20305.697266\n",
      "Train Epoch: 35 [110016/225000 (49%)] Loss: 20106.042969\n",
      "Train Epoch: 35 [112512/225000 (50%)] Loss: 19993.976562\n",
      "Train Epoch: 35 [115008/225000 (51%)] Loss: 19952.855469\n",
      "Train Epoch: 35 [117504/225000 (52%)] Loss: 20475.613281\n",
      "Train Epoch: 35 [120000/225000 (53%)] Loss: 20497.238281\n",
      "Train Epoch: 35 [122496/225000 (54%)] Loss: 20105.185547\n",
      "Train Epoch: 35 [124992/225000 (56%)] Loss: 20565.527344\n",
      "Train Epoch: 35 [127488/225000 (57%)] Loss: 20209.996094\n",
      "Train Epoch: 35 [129984/225000 (58%)] Loss: 20362.140625\n",
      "Train Epoch: 35 [132480/225000 (59%)] Loss: 20049.386719\n",
      "Train Epoch: 35 [134976/225000 (60%)] Loss: 21095.613281\n",
      "Train Epoch: 35 [137472/225000 (61%)] Loss: 20166.187500\n",
      "Train Epoch: 35 [139968/225000 (62%)] Loss: 19852.365234\n",
      "Train Epoch: 35 [142464/225000 (63%)] Loss: 20145.800781\n",
      "Train Epoch: 35 [144960/225000 (64%)] Loss: 20256.394531\n",
      "Train Epoch: 35 [147456/225000 (66%)] Loss: 20924.218750\n",
      "Train Epoch: 35 [149952/225000 (67%)] Loss: 20196.980469\n",
      "Train Epoch: 35 [152448/225000 (68%)] Loss: 20288.140625\n",
      "Train Epoch: 35 [154944/225000 (69%)] Loss: 20487.689453\n",
      "Train Epoch: 35 [157440/225000 (70%)] Loss: 20750.937500\n",
      "Train Epoch: 35 [159936/225000 (71%)] Loss: 20144.003906\n",
      "Train Epoch: 35 [162432/225000 (72%)] Loss: 20539.783203\n",
      "Train Epoch: 35 [164928/225000 (73%)] Loss: 19914.599609\n",
      "Train Epoch: 35 [167424/225000 (74%)] Loss: 20249.212891\n",
      "Train Epoch: 35 [169920/225000 (76%)] Loss: 20635.578125\n",
      "Train Epoch: 35 [172416/225000 (77%)] Loss: 20894.988281\n",
      "Train Epoch: 35 [174912/225000 (78%)] Loss: 20017.958984\n",
      "Train Epoch: 35 [177408/225000 (79%)] Loss: 20658.988281\n",
      "Train Epoch: 35 [179904/225000 (80%)] Loss: 20318.966797\n",
      "Train Epoch: 35 [182400/225000 (81%)] Loss: 20633.925781\n",
      "Train Epoch: 35 [184896/225000 (82%)] Loss: 20347.203125\n",
      "Train Epoch: 35 [187392/225000 (83%)] Loss: 20431.710938\n",
      "Train Epoch: 35 [189888/225000 (84%)] Loss: 20376.169922\n",
      "Train Epoch: 35 [192384/225000 (86%)] Loss: 20344.869141\n",
      "Train Epoch: 35 [194880/225000 (87%)] Loss: 20342.992188\n",
      "Train Epoch: 35 [197376/225000 (88%)] Loss: 20245.957031\n",
      "Train Epoch: 35 [199872/225000 (89%)] Loss: 20331.847656\n",
      "Train Epoch: 35 [202368/225000 (90%)] Loss: 20669.140625\n",
      "Train Epoch: 35 [204864/225000 (91%)] Loss: 20386.000000\n",
      "Train Epoch: 35 [207360/225000 (92%)] Loss: 20585.304688\n",
      "Train Epoch: 35 [209856/225000 (93%)] Loss: 20344.734375\n",
      "Train Epoch: 35 [212352/225000 (94%)] Loss: 20334.445312\n",
      "Train Epoch: 35 [214848/225000 (95%)] Loss: 19985.628906\n",
      "Train Epoch: 35 [217344/225000 (97%)] Loss: 20256.535156\n",
      "Train Epoch: 35 [219840/225000 (98%)] Loss: 20548.886719\n",
      "Train Epoch: 35 [222336/225000 (99%)] Loss: 20174.898438\n",
      "Train Epoch: 35 [224832/225000 (100%)] Loss: 20427.902344\n",
      "    epoch          : 35\n",
      "    loss           : 20322.297279956805\n",
      "    val_loss       : 20215.774625918337\n",
      "Train Epoch: 36 [192/225000 (0%)] Loss: 20110.863281\n",
      "Train Epoch: 36 [2688/225000 (1%)] Loss: 20412.974609\n",
      "Train Epoch: 36 [5184/225000 (2%)] Loss: 20399.664062\n",
      "Train Epoch: 36 [7680/225000 (3%)] Loss: 20501.453125\n",
      "Train Epoch: 36 [10176/225000 (5%)] Loss: 20098.031250\n",
      "Train Epoch: 36 [12672/225000 (6%)] Loss: 20259.691406\n",
      "Train Epoch: 36 [15168/225000 (7%)] Loss: 20255.093750\n",
      "Train Epoch: 36 [17664/225000 (8%)] Loss: 20524.085938\n",
      "Train Epoch: 36 [20160/225000 (9%)] Loss: 20746.921875\n",
      "Train Epoch: 36 [22656/225000 (10%)] Loss: 20421.128906\n",
      "Train Epoch: 36 [25152/225000 (11%)] Loss: 20053.843750\n",
      "Train Epoch: 36 [27648/225000 (12%)] Loss: 20114.505859\n",
      "Train Epoch: 36 [30144/225000 (13%)] Loss: 20263.103516\n",
      "Train Epoch: 36 [32640/225000 (15%)] Loss: 20332.517578\n",
      "Train Epoch: 36 [35136/225000 (16%)] Loss: 19968.625000\n",
      "Train Epoch: 36 [37632/225000 (17%)] Loss: 20112.527344\n",
      "Train Epoch: 36 [40128/225000 (18%)] Loss: 20793.828125\n",
      "Train Epoch: 36 [42624/225000 (19%)] Loss: 20010.222656\n",
      "Train Epoch: 36 [45120/225000 (20%)] Loss: 19801.117188\n",
      "Train Epoch: 36 [47616/225000 (21%)] Loss: 20437.474609\n",
      "Train Epoch: 36 [50112/225000 (22%)] Loss: 20322.785156\n",
      "Train Epoch: 36 [52608/225000 (23%)] Loss: 20620.714844\n",
      "Train Epoch: 36 [55104/225000 (24%)] Loss: 20343.027344\n",
      "Train Epoch: 36 [57600/225000 (26%)] Loss: 20742.695312\n",
      "Train Epoch: 36 [60096/225000 (27%)] Loss: 20477.914062\n",
      "Train Epoch: 36 [62592/225000 (28%)] Loss: 19599.531250\n",
      "Train Epoch: 36 [65088/225000 (29%)] Loss: 19607.765625\n",
      "Train Epoch: 36 [67584/225000 (30%)] Loss: 20418.058594\n",
      "Train Epoch: 36 [70080/225000 (31%)] Loss: 20523.837891\n",
      "Train Epoch: 36 [72576/225000 (32%)] Loss: 19960.015625\n",
      "Train Epoch: 36 [75072/225000 (33%)] Loss: 20380.042969\n",
      "Train Epoch: 36 [77568/225000 (34%)] Loss: 20286.562500\n",
      "Train Epoch: 36 [80064/225000 (36%)] Loss: 20479.417969\n",
      "Train Epoch: 36 [82560/225000 (37%)] Loss: 20848.457031\n",
      "Train Epoch: 36 [85056/225000 (38%)] Loss: 20056.851562\n",
      "Train Epoch: 36 [87552/225000 (39%)] Loss: 20423.949219\n",
      "Train Epoch: 36 [90048/225000 (40%)] Loss: 20308.867188\n",
      "Train Epoch: 36 [92544/225000 (41%)] Loss: 20183.300781\n",
      "Train Epoch: 36 [95040/225000 (42%)] Loss: 20318.679688\n",
      "Train Epoch: 36 [97536/225000 (43%)] Loss: 20750.046875\n",
      "Train Epoch: 36 [100032/225000 (44%)] Loss: 20491.332031\n",
      "Train Epoch: 36 [102528/225000 (46%)] Loss: 20032.718750\n",
      "Train Epoch: 36 [105024/225000 (47%)] Loss: 20246.386719\n",
      "Train Epoch: 36 [107520/225000 (48%)] Loss: 20719.720703\n",
      "Train Epoch: 36 [110016/225000 (49%)] Loss: 20067.970703\n",
      "Train Epoch: 36 [112512/225000 (50%)] Loss: 20306.052734\n",
      "Train Epoch: 36 [115008/225000 (51%)] Loss: 20402.339844\n",
      "Train Epoch: 36 [117504/225000 (52%)] Loss: 20308.230469\n",
      "Train Epoch: 36 [120000/225000 (53%)] Loss: 20010.363281\n",
      "Train Epoch: 36 [122496/225000 (54%)] Loss: 20036.988281\n",
      "Train Epoch: 36 [124992/225000 (56%)] Loss: 20303.890625\n",
      "Train Epoch: 36 [127488/225000 (57%)] Loss: 20324.271484\n",
      "Train Epoch: 36 [129984/225000 (58%)] Loss: 20182.632812\n",
      "Train Epoch: 36 [132480/225000 (59%)] Loss: 20147.378906\n",
      "Train Epoch: 36 [134976/225000 (60%)] Loss: 20718.398438\n",
      "Train Epoch: 36 [137472/225000 (61%)] Loss: 20829.214844\n",
      "Train Epoch: 36 [139968/225000 (62%)] Loss: 19993.605469\n",
      "Train Epoch: 36 [142464/225000 (63%)] Loss: 20478.769531\n",
      "Train Epoch: 36 [144960/225000 (64%)] Loss: 19902.656250\n",
      "Train Epoch: 36 [147456/225000 (66%)] Loss: 20374.255859\n",
      "Train Epoch: 36 [149952/225000 (67%)] Loss: 21052.140625\n",
      "Train Epoch: 36 [152448/225000 (68%)] Loss: 20120.417969\n",
      "Train Epoch: 36 [154944/225000 (69%)] Loss: 20023.281250\n",
      "Train Epoch: 36 [157440/225000 (70%)] Loss: 20226.132812\n",
      "Train Epoch: 36 [159936/225000 (71%)] Loss: 20233.218750\n",
      "Train Epoch: 36 [162432/225000 (72%)] Loss: 19852.535156\n",
      "Train Epoch: 36 [164928/225000 (73%)] Loss: 20084.480469\n",
      "Train Epoch: 36 [167424/225000 (74%)] Loss: 20017.105469\n",
      "Train Epoch: 36 [169920/225000 (76%)] Loss: 21087.957031\n",
      "Train Epoch: 36 [172416/225000 (77%)] Loss: 20831.476562\n",
      "Train Epoch: 36 [174912/225000 (78%)] Loss: 20230.281250\n",
      "Train Epoch: 36 [177408/225000 (79%)] Loss: 20402.062500\n",
      "Train Epoch: 36 [179904/225000 (80%)] Loss: 19663.080078\n",
      "Train Epoch: 36 [182400/225000 (81%)] Loss: 20298.769531\n",
      "Train Epoch: 36 [184896/225000 (82%)] Loss: 20505.189453\n",
      "Train Epoch: 36 [187392/225000 (83%)] Loss: 19954.294922\n",
      "Train Epoch: 36 [189888/225000 (84%)] Loss: 19939.582031\n",
      "Train Epoch: 36 [192384/225000 (86%)] Loss: 20335.640625\n",
      "Train Epoch: 36 [194880/225000 (87%)] Loss: 20228.535156\n",
      "Train Epoch: 36 [197376/225000 (88%)] Loss: 20360.779297\n",
      "Train Epoch: 36 [199872/225000 (89%)] Loss: 19905.095703\n",
      "Train Epoch: 36 [202368/225000 (90%)] Loss: 20549.255859\n",
      "Train Epoch: 36 [204864/225000 (91%)] Loss: 20070.494141\n",
      "Train Epoch: 36 [207360/225000 (92%)] Loss: 19805.048828\n",
      "Train Epoch: 36 [209856/225000 (93%)] Loss: 20247.089844\n",
      "Train Epoch: 36 [212352/225000 (94%)] Loss: 20153.902344\n",
      "Train Epoch: 36 [214848/225000 (95%)] Loss: 20118.730469\n",
      "Train Epoch: 36 [217344/225000 (97%)] Loss: 19855.835938\n",
      "Train Epoch: 36 [219840/225000 (98%)] Loss: 20246.871094\n",
      "Train Epoch: 36 [222336/225000 (99%)] Loss: 20317.921875\n",
      "Train Epoch: 36 [224832/225000 (100%)] Loss: 19766.990234\n",
      "    epoch          : 36\n",
      "    loss           : 20305.01855302101\n",
      "    val_loss       : 20199.76046186185\n",
      "Train Epoch: 37 [192/225000 (0%)] Loss: 20503.611328\n",
      "Train Epoch: 37 [2688/225000 (1%)] Loss: 20192.191406\n",
      "Train Epoch: 37 [5184/225000 (2%)] Loss: 20315.777344\n",
      "Train Epoch: 37 [7680/225000 (3%)] Loss: 20461.535156\n",
      "Train Epoch: 37 [10176/225000 (5%)] Loss: 20686.648438\n",
      "Train Epoch: 37 [12672/225000 (6%)] Loss: 20446.470703\n",
      "Train Epoch: 37 [15168/225000 (7%)] Loss: 20480.796875\n",
      "Train Epoch: 37 [17664/225000 (8%)] Loss: 19885.986328\n",
      "Train Epoch: 37 [20160/225000 (9%)] Loss: 20583.410156\n",
      "Train Epoch: 37 [22656/225000 (10%)] Loss: 20884.144531\n",
      "Train Epoch: 37 [25152/225000 (11%)] Loss: 20426.238281\n",
      "Train Epoch: 37 [27648/225000 (12%)] Loss: 20225.906250\n",
      "Train Epoch: 37 [30144/225000 (13%)] Loss: 19765.115234\n",
      "Train Epoch: 37 [32640/225000 (15%)] Loss: 20705.808594\n",
      "Train Epoch: 37 [35136/225000 (16%)] Loss: 20406.246094\n",
      "Train Epoch: 37 [37632/225000 (17%)] Loss: 20957.812500\n",
      "Train Epoch: 37 [40128/225000 (18%)] Loss: 20181.617188\n",
      "Train Epoch: 37 [42624/225000 (19%)] Loss: 20218.210938\n",
      "Train Epoch: 37 [45120/225000 (20%)] Loss: 20152.339844\n",
      "Train Epoch: 37 [47616/225000 (21%)] Loss: 20155.429688\n",
      "Train Epoch: 37 [50112/225000 (22%)] Loss: 20112.132812\n",
      "Train Epoch: 37 [52608/225000 (23%)] Loss: 20089.992188\n",
      "Train Epoch: 37 [55104/225000 (24%)] Loss: 20186.750000\n",
      "Train Epoch: 37 [57600/225000 (26%)] Loss: 20220.441406\n",
      "Train Epoch: 37 [60096/225000 (27%)] Loss: 20210.554688\n",
      "Train Epoch: 37 [62592/225000 (28%)] Loss: 20378.541016\n",
      "Train Epoch: 37 [65088/225000 (29%)] Loss: 19951.845703\n",
      "Train Epoch: 37 [67584/225000 (30%)] Loss: 20100.042969\n",
      "Train Epoch: 37 [70080/225000 (31%)] Loss: 19712.378906\n",
      "Train Epoch: 37 [72576/225000 (32%)] Loss: 20295.943359\n",
      "Train Epoch: 37 [75072/225000 (33%)] Loss: 20589.378906\n",
      "Train Epoch: 37 [77568/225000 (34%)] Loss: 20561.328125\n",
      "Train Epoch: 37 [80064/225000 (36%)] Loss: 20347.031250\n",
      "Train Epoch: 37 [82560/225000 (37%)] Loss: 20004.687500\n",
      "Train Epoch: 37 [85056/225000 (38%)] Loss: 20190.917969\n",
      "Train Epoch: 37 [87552/225000 (39%)] Loss: 20432.691406\n",
      "Train Epoch: 37 [90048/225000 (40%)] Loss: 20112.421875\n",
      "Train Epoch: 37 [92544/225000 (41%)] Loss: 19693.203125\n",
      "Train Epoch: 37 [95040/225000 (42%)] Loss: 20292.306641\n",
      "Train Epoch: 37 [97536/225000 (43%)] Loss: 20134.925781\n",
      "Train Epoch: 37 [100032/225000 (44%)] Loss: 20333.082031\n",
      "Train Epoch: 37 [102528/225000 (46%)] Loss: 20446.515625\n",
      "Train Epoch: 37 [105024/225000 (47%)] Loss: 20011.894531\n",
      "Train Epoch: 37 [107520/225000 (48%)] Loss: 19627.398438\n",
      "Train Epoch: 37 [110016/225000 (49%)] Loss: 19931.333984\n",
      "Train Epoch: 37 [112512/225000 (50%)] Loss: 20256.128906\n",
      "Train Epoch: 37 [115008/225000 (51%)] Loss: 19976.175781\n",
      "Train Epoch: 37 [117504/225000 (52%)] Loss: 19996.718750\n",
      "Train Epoch: 37 [120000/225000 (53%)] Loss: 20557.769531\n",
      "Train Epoch: 37 [122496/225000 (54%)] Loss: 20375.738281\n",
      "Train Epoch: 37 [124992/225000 (56%)] Loss: 20328.468750\n",
      "Train Epoch: 37 [127488/225000 (57%)] Loss: 20327.613281\n",
      "Train Epoch: 37 [129984/225000 (58%)] Loss: 19964.378906\n",
      "Train Epoch: 37 [132480/225000 (59%)] Loss: 20084.298828\n",
      "Train Epoch: 37 [134976/225000 (60%)] Loss: 19779.468750\n",
      "Train Epoch: 37 [137472/225000 (61%)] Loss: 20382.970703\n",
      "Train Epoch: 37 [139968/225000 (62%)] Loss: 20304.480469\n",
      "Train Epoch: 37 [142464/225000 (63%)] Loss: 20850.416016\n",
      "Train Epoch: 37 [144960/225000 (64%)] Loss: 20558.906250\n",
      "Train Epoch: 37 [147456/225000 (66%)] Loss: 20221.335938\n",
      "Train Epoch: 37 [149952/225000 (67%)] Loss: 20764.566406\n",
      "Train Epoch: 37 [152448/225000 (68%)] Loss: 20271.296875\n",
      "Train Epoch: 37 [154944/225000 (69%)] Loss: 19978.257812\n",
      "Train Epoch: 37 [157440/225000 (70%)] Loss: 20285.292969\n",
      "Train Epoch: 37 [159936/225000 (71%)] Loss: 20110.078125\n",
      "Train Epoch: 37 [162432/225000 (72%)] Loss: 20152.878906\n",
      "Train Epoch: 37 [164928/225000 (73%)] Loss: 20381.308594\n",
      "Train Epoch: 37 [167424/225000 (74%)] Loss: 19896.591797\n",
      "Train Epoch: 37 [169920/225000 (76%)] Loss: 20693.890625\n",
      "Train Epoch: 37 [172416/225000 (77%)] Loss: 20096.496094\n",
      "Train Epoch: 37 [174912/225000 (78%)] Loss: 20621.376953\n",
      "Train Epoch: 37 [177408/225000 (79%)] Loss: 20366.935547\n",
      "Train Epoch: 37 [179904/225000 (80%)] Loss: 20311.359375\n",
      "Train Epoch: 37 [182400/225000 (81%)] Loss: 20321.718750\n",
      "Train Epoch: 37 [184896/225000 (82%)] Loss: 20614.554688\n",
      "Train Epoch: 37 [187392/225000 (83%)] Loss: 20276.539062\n",
      "Train Epoch: 37 [189888/225000 (84%)] Loss: 20234.398438\n",
      "Train Epoch: 37 [192384/225000 (86%)] Loss: 20852.806641\n",
      "Train Epoch: 37 [194880/225000 (87%)] Loss: 20348.007812\n",
      "Train Epoch: 37 [197376/225000 (88%)] Loss: 20239.542969\n",
      "Train Epoch: 37 [199872/225000 (89%)] Loss: 20569.695312\n",
      "Train Epoch: 37 [202368/225000 (90%)] Loss: 20518.390625\n",
      "Train Epoch: 37 [204864/225000 (91%)] Loss: 20309.800781\n",
      "Train Epoch: 37 [207360/225000 (92%)] Loss: 20652.718750\n",
      "Train Epoch: 37 [209856/225000 (93%)] Loss: 20408.632812\n",
      "Train Epoch: 37 [212352/225000 (94%)] Loss: 19946.074219\n",
      "Train Epoch: 37 [214848/225000 (95%)] Loss: 20365.925781\n",
      "Train Epoch: 37 [217344/225000 (97%)] Loss: 20156.261719\n",
      "Train Epoch: 37 [219840/225000 (98%)] Loss: 20220.078125\n",
      "Train Epoch: 37 [222336/225000 (99%)] Loss: 20366.974609\n",
      "Train Epoch: 37 [224832/225000 (100%)] Loss: 20388.281250\n",
      "    epoch          : 37\n",
      "    loss           : 20298.98645144518\n",
      "    val_loss       : 20195.65824703133\n",
      "Train Epoch: 38 [192/225000 (0%)] Loss: 19583.347656\n",
      "Train Epoch: 38 [2688/225000 (1%)] Loss: 20070.964844\n",
      "Train Epoch: 38 [5184/225000 (2%)] Loss: 20608.457031\n",
      "Train Epoch: 38 [7680/225000 (3%)] Loss: 20445.898438\n",
      "Train Epoch: 38 [10176/225000 (5%)] Loss: 20205.087891\n",
      "Train Epoch: 38 [12672/225000 (6%)] Loss: 20505.050781\n",
      "Train Epoch: 38 [15168/225000 (7%)] Loss: 20436.730469\n",
      "Train Epoch: 38 [17664/225000 (8%)] Loss: 20576.160156\n",
      "Train Epoch: 38 [20160/225000 (9%)] Loss: 20508.349609\n",
      "Train Epoch: 38 [22656/225000 (10%)] Loss: 19416.599609\n",
      "Train Epoch: 38 [25152/225000 (11%)] Loss: 20147.574219\n",
      "Train Epoch: 38 [27648/225000 (12%)] Loss: 20216.070312\n",
      "Train Epoch: 38 [30144/225000 (13%)] Loss: 20100.339844\n",
      "Train Epoch: 38 [32640/225000 (15%)] Loss: 20207.607422\n",
      "Train Epoch: 38 [35136/225000 (16%)] Loss: 20362.648438\n",
      "Train Epoch: 38 [37632/225000 (17%)] Loss: 20325.312500\n",
      "Train Epoch: 38 [40128/225000 (18%)] Loss: 20489.925781\n",
      "Train Epoch: 38 [42624/225000 (19%)] Loss: 20201.660156\n",
      "Train Epoch: 38 [45120/225000 (20%)] Loss: 20325.453125\n",
      "Train Epoch: 38 [47616/225000 (21%)] Loss: 20056.128906\n",
      "Train Epoch: 38 [50112/225000 (22%)] Loss: 20585.296875\n",
      "Train Epoch: 38 [52608/225000 (23%)] Loss: 19841.914062\n",
      "Train Epoch: 38 [55104/225000 (24%)] Loss: 20058.816406\n",
      "Train Epoch: 38 [57600/225000 (26%)] Loss: 20731.710938\n",
      "Train Epoch: 38 [60096/225000 (27%)] Loss: 20090.373047\n",
      "Train Epoch: 38 [62592/225000 (28%)] Loss: 20794.707031\n",
      "Train Epoch: 38 [65088/225000 (29%)] Loss: 20235.929688\n",
      "Train Epoch: 38 [67584/225000 (30%)] Loss: 20631.369141\n",
      "Train Epoch: 38 [70080/225000 (31%)] Loss: 20313.216797\n",
      "Train Epoch: 38 [72576/225000 (32%)] Loss: 20084.117188\n",
      "Train Epoch: 38 [75072/225000 (33%)] Loss: 20381.082031\n",
      "Train Epoch: 38 [77568/225000 (34%)] Loss: 19845.384766\n",
      "Train Epoch: 38 [80064/225000 (36%)] Loss: 20452.888672\n",
      "Train Epoch: 38 [82560/225000 (37%)] Loss: 20794.117188\n",
      "Train Epoch: 38 [85056/225000 (38%)] Loss: 20261.162109\n",
      "Train Epoch: 38 [87552/225000 (39%)] Loss: 20329.156250\n",
      "Train Epoch: 38 [90048/225000 (40%)] Loss: 20364.082031\n",
      "Train Epoch: 38 [92544/225000 (41%)] Loss: 20226.390625\n",
      "Train Epoch: 38 [95040/225000 (42%)] Loss: 20450.361328\n",
      "Train Epoch: 38 [97536/225000 (43%)] Loss: 19933.376953\n",
      "Train Epoch: 38 [100032/225000 (44%)] Loss: 20031.673828\n",
      "Train Epoch: 38 [102528/225000 (46%)] Loss: 20029.164062\n",
      "Train Epoch: 38 [105024/225000 (47%)] Loss: 20501.886719\n",
      "Train Epoch: 38 [107520/225000 (48%)] Loss: 20358.994141\n",
      "Train Epoch: 38 [110016/225000 (49%)] Loss: 20668.730469\n",
      "Train Epoch: 38 [112512/225000 (50%)] Loss: 20178.167969\n",
      "Train Epoch: 38 [115008/225000 (51%)] Loss: 20117.355469\n",
      "Train Epoch: 38 [117504/225000 (52%)] Loss: 20633.816406\n",
      "Train Epoch: 38 [120000/225000 (53%)] Loss: 20381.052734\n",
      "Train Epoch: 38 [122496/225000 (54%)] Loss: 20561.685547\n",
      "Train Epoch: 38 [124992/225000 (56%)] Loss: 19874.662109\n",
      "Train Epoch: 38 [127488/225000 (57%)] Loss: 20422.740234\n",
      "Train Epoch: 38 [129984/225000 (58%)] Loss: 20035.242188\n",
      "Train Epoch: 38 [132480/225000 (59%)] Loss: 20704.398438\n",
      "Train Epoch: 38 [134976/225000 (60%)] Loss: 20231.365234\n",
      "Train Epoch: 38 [137472/225000 (61%)] Loss: 20647.335938\n",
      "Train Epoch: 38 [139968/225000 (62%)] Loss: 19931.832031\n",
      "Train Epoch: 38 [142464/225000 (63%)] Loss: 20416.283203\n",
      "Train Epoch: 38 [144960/225000 (64%)] Loss: 20645.605469\n",
      "Train Epoch: 38 [147456/225000 (66%)] Loss: 20427.382812\n",
      "Train Epoch: 38 [149952/225000 (67%)] Loss: 20252.314453\n",
      "Train Epoch: 38 [152448/225000 (68%)] Loss: 20063.029297\n",
      "Train Epoch: 38 [154944/225000 (69%)] Loss: 20051.314453\n",
      "Train Epoch: 38 [157440/225000 (70%)] Loss: 19996.320312\n",
      "Train Epoch: 38 [159936/225000 (71%)] Loss: 20038.175781\n",
      "Train Epoch: 38 [162432/225000 (72%)] Loss: 19911.554688\n",
      "Train Epoch: 38 [164928/225000 (73%)] Loss: 20327.347656\n",
      "Train Epoch: 38 [167424/225000 (74%)] Loss: 20125.111328\n",
      "Train Epoch: 38 [169920/225000 (76%)] Loss: 20940.296875\n",
      "Train Epoch: 38 [172416/225000 (77%)] Loss: 20526.585938\n",
      "Train Epoch: 38 [174912/225000 (78%)] Loss: 20422.611328\n",
      "Train Epoch: 38 [177408/225000 (79%)] Loss: 20431.656250\n",
      "Train Epoch: 38 [179904/225000 (80%)] Loss: 20142.148438\n",
      "Train Epoch: 38 [182400/225000 (81%)] Loss: 20391.541016\n",
      "Train Epoch: 38 [184896/225000 (82%)] Loss: 20182.222656\n",
      "Train Epoch: 38 [187392/225000 (83%)] Loss: 19916.820312\n",
      "Train Epoch: 38 [189888/225000 (84%)] Loss: 20537.666016\n",
      "Train Epoch: 38 [192384/225000 (86%)] Loss: 20201.015625\n",
      "Train Epoch: 38 [194880/225000 (87%)] Loss: 20434.232422\n",
      "Train Epoch: 38 [197376/225000 (88%)] Loss: 20482.611328\n",
      "Train Epoch: 38 [199872/225000 (89%)] Loss: 20341.878906\n",
      "Train Epoch: 38 [202368/225000 (90%)] Loss: 20963.757812\n",
      "Train Epoch: 38 [204864/225000 (91%)] Loss: 20228.818359\n",
      "Train Epoch: 38 [207360/225000 (92%)] Loss: 20079.828125\n",
      "Train Epoch: 38 [209856/225000 (93%)] Loss: 20297.812500\n",
      "Train Epoch: 38 [212352/225000 (94%)] Loss: 19923.890625\n",
      "Train Epoch: 38 [214848/225000 (95%)] Loss: 20293.925781\n",
      "Train Epoch: 38 [217344/225000 (97%)] Loss: 20143.339844\n",
      "Train Epoch: 38 [219840/225000 (98%)] Loss: 20272.953125\n",
      "Train Epoch: 38 [222336/225000 (99%)] Loss: 20221.691406\n",
      "Train Epoch: 38 [224832/225000 (100%)] Loss: 19941.369141\n",
      "    epoch          : 38\n",
      "    loss           : 20290.278057007254\n",
      "    val_loss       : 20188.35770404657\n",
      "Train Epoch: 39 [192/225000 (0%)] Loss: 20582.941406\n",
      "Train Epoch: 39 [2688/225000 (1%)] Loss: 20618.697266\n",
      "Train Epoch: 39 [5184/225000 (2%)] Loss: 20223.890625\n",
      "Train Epoch: 39 [7680/225000 (3%)] Loss: 20581.441406\n",
      "Train Epoch: 39 [10176/225000 (5%)] Loss: 20259.875000\n",
      "Train Epoch: 39 [12672/225000 (6%)] Loss: 20919.144531\n",
      "Train Epoch: 39 [15168/225000 (7%)] Loss: 20472.207031\n",
      "Train Epoch: 39 [17664/225000 (8%)] Loss: 20002.261719\n",
      "Train Epoch: 39 [20160/225000 (9%)] Loss: 20384.972656\n",
      "Train Epoch: 39 [22656/225000 (10%)] Loss: 20559.542969\n",
      "Train Epoch: 39 [25152/225000 (11%)] Loss: 20116.183594\n",
      "Train Epoch: 39 [27648/225000 (12%)] Loss: 20288.386719\n",
      "Train Epoch: 39 [30144/225000 (13%)] Loss: 20023.591797\n",
      "Train Epoch: 39 [32640/225000 (15%)] Loss: 20138.367188\n",
      "Train Epoch: 39 [35136/225000 (16%)] Loss: 20657.345703\n",
      "Train Epoch: 39 [37632/225000 (17%)] Loss: 20427.763672\n",
      "Train Epoch: 39 [40128/225000 (18%)] Loss: 19746.970703\n",
      "Train Epoch: 39 [42624/225000 (19%)] Loss: 20404.914062\n",
      "Train Epoch: 39 [45120/225000 (20%)] Loss: 20592.314453\n",
      "Train Epoch: 39 [47616/225000 (21%)] Loss: 20258.566406\n",
      "Train Epoch: 39 [50112/225000 (22%)] Loss: 20138.673828\n",
      "Train Epoch: 39 [52608/225000 (23%)] Loss: 20140.902344\n",
      "Train Epoch: 39 [55104/225000 (24%)] Loss: 20509.923828\n",
      "Train Epoch: 39 [57600/225000 (26%)] Loss: 20323.425781\n",
      "Train Epoch: 39 [60096/225000 (27%)] Loss: 20372.464844\n",
      "Train Epoch: 39 [62592/225000 (28%)] Loss: 20843.923828\n",
      "Train Epoch: 39 [65088/225000 (29%)] Loss: 20583.394531\n",
      "Train Epoch: 39 [67584/225000 (30%)] Loss: 20552.367188\n",
      "Train Epoch: 39 [70080/225000 (31%)] Loss: 20268.566406\n",
      "Train Epoch: 39 [72576/225000 (32%)] Loss: 20015.968750\n",
      "Train Epoch: 39 [75072/225000 (33%)] Loss: 20272.515625\n",
      "Train Epoch: 39 [77568/225000 (34%)] Loss: 20099.466797\n",
      "Train Epoch: 39 [80064/225000 (36%)] Loss: 20516.160156\n",
      "Train Epoch: 39 [82560/225000 (37%)] Loss: 20426.625000\n",
      "Train Epoch: 39 [85056/225000 (38%)] Loss: 20655.207031\n",
      "Train Epoch: 39 [87552/225000 (39%)] Loss: 20318.324219\n",
      "Train Epoch: 39 [90048/225000 (40%)] Loss: 20263.980469\n",
      "Train Epoch: 39 [92544/225000 (41%)] Loss: 20314.500000\n",
      "Train Epoch: 39 [95040/225000 (42%)] Loss: 20099.849609\n",
      "Train Epoch: 39 [97536/225000 (43%)] Loss: 20235.273438\n",
      "Train Epoch: 39 [100032/225000 (44%)] Loss: 20178.371094\n",
      "Train Epoch: 39 [102528/225000 (46%)] Loss: 20238.046875\n",
      "Train Epoch: 39 [105024/225000 (47%)] Loss: 20875.679688\n",
      "Train Epoch: 39 [107520/225000 (48%)] Loss: 20765.902344\n",
      "Train Epoch: 39 [110016/225000 (49%)] Loss: 20075.447266\n",
      "Train Epoch: 39 [112512/225000 (50%)] Loss: 19459.626953\n",
      "Train Epoch: 39 [115008/225000 (51%)] Loss: 20466.953125\n",
      "Train Epoch: 39 [117504/225000 (52%)] Loss: 20404.796875\n",
      "Train Epoch: 39 [120000/225000 (53%)] Loss: 20487.878906\n",
      "Train Epoch: 39 [122496/225000 (54%)] Loss: 20092.468750\n",
      "Train Epoch: 39 [124992/225000 (56%)] Loss: 20577.724609\n",
      "Train Epoch: 39 [127488/225000 (57%)] Loss: 20399.298828\n",
      "Train Epoch: 39 [129984/225000 (58%)] Loss: 19898.943359\n",
      "Train Epoch: 39 [132480/225000 (59%)] Loss: 20510.646484\n",
      "Train Epoch: 39 [134976/225000 (60%)] Loss: 20034.814453\n",
      "Train Epoch: 39 [137472/225000 (61%)] Loss: 20159.429688\n",
      "Train Epoch: 39 [139968/225000 (62%)] Loss: 20239.164062\n",
      "Train Epoch: 39 [142464/225000 (63%)] Loss: 20088.378906\n",
      "Train Epoch: 39 [144960/225000 (64%)] Loss: 19934.242188\n",
      "Train Epoch: 39 [147456/225000 (66%)] Loss: 20273.285156\n",
      "Train Epoch: 39 [149952/225000 (67%)] Loss: 19959.019531\n",
      "Train Epoch: 39 [152448/225000 (68%)] Loss: 20209.892578\n",
      "Train Epoch: 39 [154944/225000 (69%)] Loss: 19438.136719\n",
      "Train Epoch: 39 [157440/225000 (70%)] Loss: 20233.691406\n",
      "Train Epoch: 39 [159936/225000 (71%)] Loss: 19970.226562\n",
      "Train Epoch: 39 [162432/225000 (72%)] Loss: 20039.367188\n",
      "Train Epoch: 39 [164928/225000 (73%)] Loss: 19797.599609\n",
      "Train Epoch: 39 [167424/225000 (74%)] Loss: 19653.593750\n",
      "Train Epoch: 39 [169920/225000 (76%)] Loss: 20373.212891\n",
      "Train Epoch: 39 [172416/225000 (77%)] Loss: 20188.500000\n",
      "Train Epoch: 39 [174912/225000 (78%)] Loss: 20252.289062\n",
      "Train Epoch: 39 [177408/225000 (79%)] Loss: 20002.328125\n",
      "Train Epoch: 39 [179904/225000 (80%)] Loss: 20618.197266\n",
      "Train Epoch: 39 [182400/225000 (81%)] Loss: 20705.226562\n",
      "Train Epoch: 39 [184896/225000 (82%)] Loss: 19962.097656\n",
      "Train Epoch: 39 [187392/225000 (83%)] Loss: 19959.539062\n",
      "Train Epoch: 39 [189888/225000 (84%)] Loss: 20739.488281\n",
      "Train Epoch: 39 [192384/225000 (86%)] Loss: 20567.167969\n",
      "Train Epoch: 39 [194880/225000 (87%)] Loss: 20435.417969\n",
      "Train Epoch: 39 [197376/225000 (88%)] Loss: 20297.162109\n",
      "Train Epoch: 39 [199872/225000 (89%)] Loss: 19751.236328\n",
      "Train Epoch: 39 [202368/225000 (90%)] Loss: 20517.544922\n",
      "Train Epoch: 39 [204864/225000 (91%)] Loss: 20677.601562\n",
      "Train Epoch: 39 [207360/225000 (92%)] Loss: 20167.691406\n",
      "Train Epoch: 39 [209856/225000 (93%)] Loss: 20539.117188\n",
      "Train Epoch: 39 [212352/225000 (94%)] Loss: 20204.792969\n",
      "Train Epoch: 39 [214848/225000 (95%)] Loss: 20173.593750\n",
      "Train Epoch: 39 [217344/225000 (97%)] Loss: 19858.156250\n",
      "Train Epoch: 39 [219840/225000 (98%)] Loss: 20277.519531\n",
      "Train Epoch: 39 [222336/225000 (99%)] Loss: 19926.281250\n",
      "Train Epoch: 39 [224832/225000 (100%)] Loss: 20439.076172\n",
      "    epoch          : 39\n",
      "    loss           : 20278.391638225257\n",
      "    val_loss       : 20179.79235273827\n",
      "Train Epoch: 40 [192/225000 (0%)] Loss: 20446.001953\n",
      "Train Epoch: 40 [2688/225000 (1%)] Loss: 20672.347656\n",
      "Train Epoch: 40 [5184/225000 (2%)] Loss: 20133.156250\n",
      "Train Epoch: 40 [7680/225000 (3%)] Loss: 20039.855469\n",
      "Train Epoch: 40 [10176/225000 (5%)] Loss: 20436.507812\n",
      "Train Epoch: 40 [12672/225000 (6%)] Loss: 19879.556641\n",
      "Train Epoch: 40 [15168/225000 (7%)] Loss: 20105.070312\n",
      "Train Epoch: 40 [17664/225000 (8%)] Loss: 20055.300781\n",
      "Train Epoch: 40 [20160/225000 (9%)] Loss: 20352.007812\n",
      "Train Epoch: 40 [22656/225000 (10%)] Loss: 20207.171875\n",
      "Train Epoch: 40 [25152/225000 (11%)] Loss: 20880.167969\n",
      "Train Epoch: 40 [27648/225000 (12%)] Loss: 20240.894531\n",
      "Train Epoch: 40 [30144/225000 (13%)] Loss: 20340.757812\n",
      "Train Epoch: 40 [32640/225000 (15%)] Loss: 20019.472656\n",
      "Train Epoch: 40 [35136/225000 (16%)] Loss: 20401.843750\n",
      "Train Epoch: 40 [37632/225000 (17%)] Loss: 20528.792969\n",
      "Train Epoch: 40 [40128/225000 (18%)] Loss: 20968.023438\n",
      "Train Epoch: 40 [42624/225000 (19%)] Loss: 20525.468750\n",
      "Train Epoch: 40 [45120/225000 (20%)] Loss: 20996.371094\n",
      "Train Epoch: 40 [47616/225000 (21%)] Loss: 20430.929688\n",
      "Train Epoch: 40 [50112/225000 (22%)] Loss: 20561.820312\n",
      "Train Epoch: 40 [52608/225000 (23%)] Loss: 19976.273438\n",
      "Train Epoch: 40 [55104/225000 (24%)] Loss: 20106.212891\n",
      "Train Epoch: 40 [57600/225000 (26%)] Loss: 19919.664062\n",
      "Train Epoch: 40 [60096/225000 (27%)] Loss: 19944.539062\n",
      "Train Epoch: 40 [62592/225000 (28%)] Loss: 19916.148438\n",
      "Train Epoch: 40 [65088/225000 (29%)] Loss: 20173.539062\n",
      "Train Epoch: 40 [67584/225000 (30%)] Loss: 20490.431641\n",
      "Train Epoch: 40 [70080/225000 (31%)] Loss: 19939.906250\n",
      "Train Epoch: 40 [72576/225000 (32%)] Loss: 19980.601562\n",
      "Train Epoch: 40 [75072/225000 (33%)] Loss: 20552.332031\n",
      "Train Epoch: 40 [77568/225000 (34%)] Loss: 19968.347656\n",
      "Train Epoch: 40 [80064/225000 (36%)] Loss: 20104.832031\n",
      "Train Epoch: 40 [82560/225000 (37%)] Loss: 20180.642578\n",
      "Train Epoch: 40 [85056/225000 (38%)] Loss: 20405.392578\n",
      "Train Epoch: 40 [87552/225000 (39%)] Loss: 20493.511719\n",
      "Train Epoch: 40 [90048/225000 (40%)] Loss: 20604.894531\n",
      "Train Epoch: 40 [92544/225000 (41%)] Loss: 20451.734375\n",
      "Train Epoch: 40 [95040/225000 (42%)] Loss: 20032.859375\n",
      "Train Epoch: 40 [97536/225000 (43%)] Loss: 19911.562500\n",
      "Train Epoch: 40 [100032/225000 (44%)] Loss: 20573.203125\n",
      "Train Epoch: 40 [102528/225000 (46%)] Loss: 20292.101562\n",
      "Train Epoch: 40 [105024/225000 (47%)] Loss: 20793.968750\n",
      "Train Epoch: 40 [107520/225000 (48%)] Loss: 20539.761719\n",
      "Train Epoch: 40 [110016/225000 (49%)] Loss: 20437.148438\n",
      "Train Epoch: 40 [112512/225000 (50%)] Loss: 20273.503906\n",
      "Train Epoch: 40 [115008/225000 (51%)] Loss: 20670.390625\n",
      "Train Epoch: 40 [117504/225000 (52%)] Loss: 19954.007812\n",
      "Train Epoch: 40 [120000/225000 (53%)] Loss: 20226.796875\n",
      "Train Epoch: 40 [122496/225000 (54%)] Loss: 20597.648438\n",
      "Train Epoch: 40 [124992/225000 (56%)] Loss: 20353.089844\n",
      "Train Epoch: 40 [127488/225000 (57%)] Loss: 19950.111328\n",
      "Train Epoch: 40 [129984/225000 (58%)] Loss: 20139.699219\n",
      "Train Epoch: 40 [132480/225000 (59%)] Loss: 20017.101562\n",
      "Train Epoch: 40 [134976/225000 (60%)] Loss: 20444.066406\n",
      "Train Epoch: 40 [137472/225000 (61%)] Loss: 19965.113281\n",
      "Train Epoch: 40 [139968/225000 (62%)] Loss: 20406.742188\n",
      "Train Epoch: 40 [142464/225000 (63%)] Loss: 20164.066406\n",
      "Train Epoch: 40 [144960/225000 (64%)] Loss: 20403.734375\n",
      "Train Epoch: 40 [147456/225000 (66%)] Loss: 20878.388672\n",
      "Train Epoch: 40 [149952/225000 (67%)] Loss: 19772.843750\n",
      "Train Epoch: 40 [152448/225000 (68%)] Loss: 20222.816406\n",
      "Train Epoch: 40 [154944/225000 (69%)] Loss: 20329.765625\n",
      "Train Epoch: 40 [157440/225000 (70%)] Loss: 20527.294922\n",
      "Train Epoch: 40 [159936/225000 (71%)] Loss: 20385.791016\n",
      "Train Epoch: 40 [162432/225000 (72%)] Loss: 21161.863281\n",
      "Train Epoch: 40 [164928/225000 (73%)] Loss: 20018.146484\n",
      "Train Epoch: 40 [167424/225000 (74%)] Loss: 20141.423828\n",
      "Train Epoch: 40 [169920/225000 (76%)] Loss: 20695.748047\n",
      "Train Epoch: 40 [172416/225000 (77%)] Loss: 20167.441406\n",
      "Train Epoch: 40 [174912/225000 (78%)] Loss: 20067.941406\n",
      "Train Epoch: 40 [177408/225000 (79%)] Loss: 20185.988281\n",
      "Train Epoch: 40 [179904/225000 (80%)] Loss: 20312.164062\n",
      "Train Epoch: 40 [182400/225000 (81%)] Loss: 20032.214844\n",
      "Train Epoch: 40 [184896/225000 (82%)] Loss: 20254.966797\n",
      "Train Epoch: 40 [187392/225000 (83%)] Loss: 20158.792969\n",
      "Train Epoch: 40 [189888/225000 (84%)] Loss: 20102.947266\n",
      "Train Epoch: 40 [192384/225000 (86%)] Loss: 20317.880859\n",
      "Train Epoch: 40 [194880/225000 (87%)] Loss: 20082.289062\n",
      "Train Epoch: 40 [197376/225000 (88%)] Loss: 19910.201172\n",
      "Train Epoch: 40 [199872/225000 (89%)] Loss: 20218.955078\n",
      "Train Epoch: 40 [202368/225000 (90%)] Loss: 20252.166016\n",
      "Train Epoch: 40 [204864/225000 (91%)] Loss: 20344.808594\n",
      "Train Epoch: 40 [207360/225000 (92%)] Loss: 19830.320312\n",
      "Train Epoch: 40 [209856/225000 (93%)] Loss: 20348.566406\n",
      "Train Epoch: 40 [212352/225000 (94%)] Loss: 20726.841797\n",
      "Train Epoch: 40 [214848/225000 (95%)] Loss: 20345.523438\n",
      "Train Epoch: 40 [217344/225000 (97%)] Loss: 20102.445312\n",
      "Train Epoch: 40 [219840/225000 (98%)] Loss: 19878.156250\n",
      "Train Epoch: 40 [222336/225000 (99%)] Loss: 20048.832031\n",
      "Train Epoch: 40 [224832/225000 (100%)] Loss: 20259.466797\n",
      "    epoch          : 40\n",
      "    loss           : 20279.51551501173\n",
      "    val_loss       : 20183.991216839724\n",
      "Train Epoch: 41 [192/225000 (0%)] Loss: 19533.550781\n",
      "Train Epoch: 41 [2688/225000 (1%)] Loss: 20289.619141\n",
      "Train Epoch: 41 [5184/225000 (2%)] Loss: 20510.058594\n",
      "Train Epoch: 41 [7680/225000 (3%)] Loss: 20561.031250\n",
      "Train Epoch: 41 [10176/225000 (5%)] Loss: 20668.210938\n",
      "Train Epoch: 41 [12672/225000 (6%)] Loss: 20945.800781\n",
      "Train Epoch: 41 [15168/225000 (7%)] Loss: 20113.976562\n",
      "Train Epoch: 41 [17664/225000 (8%)] Loss: 19963.841797\n",
      "Train Epoch: 41 [20160/225000 (9%)] Loss: 20078.816406\n",
      "Train Epoch: 41 [22656/225000 (10%)] Loss: 20082.683594\n",
      "Train Epoch: 41 [25152/225000 (11%)] Loss: 20335.683594\n",
      "Train Epoch: 41 [27648/225000 (12%)] Loss: 20765.191406\n",
      "Train Epoch: 41 [30144/225000 (13%)] Loss: 20278.865234\n",
      "Train Epoch: 41 [32640/225000 (15%)] Loss: 20303.914062\n",
      "Train Epoch: 41 [35136/225000 (16%)] Loss: 19991.230469\n",
      "Train Epoch: 41 [37632/225000 (17%)] Loss: 20088.720703\n",
      "Train Epoch: 41 [40128/225000 (18%)] Loss: 20252.253906\n",
      "Train Epoch: 41 [42624/225000 (19%)] Loss: 20226.988281\n",
      "Train Epoch: 41 [45120/225000 (20%)] Loss: 20173.349609\n",
      "Train Epoch: 41 [47616/225000 (21%)] Loss: 19720.724609\n",
      "Train Epoch: 41 [50112/225000 (22%)] Loss: 20365.972656\n",
      "Train Epoch: 41 [52608/225000 (23%)] Loss: 20349.746094\n",
      "Train Epoch: 41 [55104/225000 (24%)] Loss: 20792.136719\n",
      "Train Epoch: 41 [57600/225000 (26%)] Loss: 20396.578125\n",
      "Train Epoch: 41 [60096/225000 (27%)] Loss: 19771.023438\n",
      "Train Epoch: 41 [62592/225000 (28%)] Loss: 19734.697266\n",
      "Train Epoch: 41 [65088/225000 (29%)] Loss: 20656.218750\n",
      "Train Epoch: 41 [67584/225000 (30%)] Loss: 20633.701172\n",
      "Train Epoch: 41 [70080/225000 (31%)] Loss: 20279.273438\n",
      "Train Epoch: 41 [72576/225000 (32%)] Loss: 19737.765625\n",
      "Train Epoch: 41 [75072/225000 (33%)] Loss: 20308.886719\n",
      "Train Epoch: 41 [77568/225000 (34%)] Loss: 20029.414062\n",
      "Train Epoch: 41 [80064/225000 (36%)] Loss: 20642.435547\n",
      "Train Epoch: 41 [82560/225000 (37%)] Loss: 19865.244141\n",
      "Train Epoch: 41 [85056/225000 (38%)] Loss: 20410.675781\n",
      "Train Epoch: 41 [87552/225000 (39%)] Loss: 20361.589844\n",
      "Train Epoch: 41 [90048/225000 (40%)] Loss: 20176.316406\n",
      "Train Epoch: 41 [92544/225000 (41%)] Loss: 20615.871094\n",
      "Train Epoch: 41 [95040/225000 (42%)] Loss: 20479.746094\n",
      "Train Epoch: 41 [97536/225000 (43%)] Loss: 20371.222656\n",
      "Train Epoch: 41 [100032/225000 (44%)] Loss: 20189.939453\n",
      "Train Epoch: 41 [102528/225000 (46%)] Loss: 20404.128906\n",
      "Train Epoch: 41 [105024/225000 (47%)] Loss: 20103.015625\n",
      "Train Epoch: 41 [107520/225000 (48%)] Loss: 20157.115234\n",
      "Train Epoch: 41 [110016/225000 (49%)] Loss: 20494.914062\n",
      "Train Epoch: 41 [112512/225000 (50%)] Loss: 20337.488281\n",
      "Train Epoch: 41 [115008/225000 (51%)] Loss: 20333.974609\n",
      "Train Epoch: 41 [117504/225000 (52%)] Loss: 19834.832031\n",
      "Train Epoch: 41 [120000/225000 (53%)] Loss: 20134.738281\n",
      "Train Epoch: 41 [122496/225000 (54%)] Loss: 20078.964844\n",
      "Train Epoch: 41 [124992/225000 (56%)] Loss: 20724.539062\n",
      "Train Epoch: 41 [127488/225000 (57%)] Loss: 20097.558594\n",
      "Train Epoch: 41 [129984/225000 (58%)] Loss: 20070.710938\n",
      "Train Epoch: 41 [132480/225000 (59%)] Loss: 19818.992188\n",
      "Train Epoch: 41 [134976/225000 (60%)] Loss: 20503.562500\n",
      "Train Epoch: 41 [137472/225000 (61%)] Loss: 20217.253906\n",
      "Train Epoch: 41 [139968/225000 (62%)] Loss: 19962.972656\n",
      "Train Epoch: 41 [142464/225000 (63%)] Loss: 20334.011719\n",
      "Train Epoch: 41 [144960/225000 (64%)] Loss: 20289.701172\n",
      "Train Epoch: 41 [147456/225000 (66%)] Loss: 20188.392578\n",
      "Train Epoch: 41 [149952/225000 (67%)] Loss: 20365.876953\n",
      "Train Epoch: 41 [152448/225000 (68%)] Loss: 19956.585938\n",
      "Train Epoch: 41 [154944/225000 (69%)] Loss: 19910.074219\n",
      "Train Epoch: 41 [157440/225000 (70%)] Loss: 19937.402344\n",
      "Train Epoch: 41 [159936/225000 (71%)] Loss: 20595.691406\n",
      "Train Epoch: 41 [162432/225000 (72%)] Loss: 20266.910156\n",
      "Train Epoch: 41 [164928/225000 (73%)] Loss: 20664.726562\n",
      "Train Epoch: 41 [167424/225000 (74%)] Loss: 20277.023438\n",
      "Train Epoch: 41 [169920/225000 (76%)] Loss: 20841.968750\n",
      "Train Epoch: 41 [172416/225000 (77%)] Loss: 20435.414062\n",
      "Train Epoch: 41 [174912/225000 (78%)] Loss: 20318.250000\n",
      "Train Epoch: 41 [177408/225000 (79%)] Loss: 20397.173828\n",
      "Train Epoch: 41 [179904/225000 (80%)] Loss: 19863.183594\n",
      "Train Epoch: 41 [182400/225000 (81%)] Loss: 20445.265625\n",
      "Train Epoch: 41 [184896/225000 (82%)] Loss: 19819.511719\n",
      "Train Epoch: 41 [187392/225000 (83%)] Loss: 20267.207031\n",
      "Train Epoch: 41 [189888/225000 (84%)] Loss: 19876.076172\n",
      "Train Epoch: 41 [192384/225000 (86%)] Loss: 20014.046875\n",
      "Train Epoch: 41 [194880/225000 (87%)] Loss: 20070.414062\n",
      "Train Epoch: 41 [197376/225000 (88%)] Loss: 20380.769531\n",
      "Train Epoch: 41 [199872/225000 (89%)] Loss: 20316.726562\n",
      "Train Epoch: 41 [202368/225000 (90%)] Loss: 20246.103516\n",
      "Train Epoch: 41 [204864/225000 (91%)] Loss: 20503.007812\n",
      "Train Epoch: 41 [207360/225000 (92%)] Loss: 20248.613281\n",
      "Train Epoch: 41 [209856/225000 (93%)] Loss: 20288.998047\n",
      "Train Epoch: 41 [212352/225000 (94%)] Loss: 20019.900391\n",
      "Train Epoch: 41 [214848/225000 (95%)] Loss: 20741.289062\n",
      "Train Epoch: 41 [217344/225000 (97%)] Loss: 20587.523438\n",
      "Train Epoch: 41 [219840/225000 (98%)] Loss: 20135.292969\n",
      "Train Epoch: 41 [222336/225000 (99%)] Loss: 20102.007812\n",
      "Train Epoch: 41 [224832/225000 (100%)] Loss: 20416.300781\n",
      "    epoch          : 41\n",
      "    loss           : 20276.080719723228\n",
      "    val_loss       : 20172.98808616764\n",
      "Train Epoch: 42 [192/225000 (0%)] Loss: 20180.837891\n",
      "Train Epoch: 42 [2688/225000 (1%)] Loss: 20664.298828\n",
      "Train Epoch: 42 [5184/225000 (2%)] Loss: 20620.875000\n",
      "Train Epoch: 42 [7680/225000 (3%)] Loss: 20525.468750\n",
      "Train Epoch: 42 [10176/225000 (5%)] Loss: 20226.478516\n",
      "Train Epoch: 42 [12672/225000 (6%)] Loss: 20480.757812\n",
      "Train Epoch: 42 [15168/225000 (7%)] Loss: 19735.064453\n",
      "Train Epoch: 42 [17664/225000 (8%)] Loss: 20599.527344\n",
      "Train Epoch: 42 [20160/225000 (9%)] Loss: 20565.546875\n",
      "Train Epoch: 42 [22656/225000 (10%)] Loss: 20039.742188\n",
      "Train Epoch: 42 [25152/225000 (11%)] Loss: 19960.500000\n",
      "Train Epoch: 42 [27648/225000 (12%)] Loss: 20127.460938\n",
      "Train Epoch: 42 [30144/225000 (13%)] Loss: 19946.994141\n",
      "Train Epoch: 42 [32640/225000 (15%)] Loss: 20333.800781\n",
      "Train Epoch: 42 [35136/225000 (16%)] Loss: 20012.578125\n",
      "Train Epoch: 42 [37632/225000 (17%)] Loss: 20023.886719\n",
      "Train Epoch: 42 [40128/225000 (18%)] Loss: 20526.738281\n",
      "Train Epoch: 42 [42624/225000 (19%)] Loss: 20497.523438\n",
      "Train Epoch: 42 [45120/225000 (20%)] Loss: 19707.718750\n",
      "Train Epoch: 42 [47616/225000 (21%)] Loss: 20320.070312\n",
      "Train Epoch: 42 [50112/225000 (22%)] Loss: 19959.359375\n",
      "Train Epoch: 42 [52608/225000 (23%)] Loss: 20248.675781\n",
      "Train Epoch: 42 [55104/225000 (24%)] Loss: 20115.589844\n",
      "Train Epoch: 42 [57600/225000 (26%)] Loss: 20184.648438\n",
      "Train Epoch: 42 [60096/225000 (27%)] Loss: 20320.970703\n",
      "Train Epoch: 42 [62592/225000 (28%)] Loss: 20579.636719\n",
      "Train Epoch: 42 [65088/225000 (29%)] Loss: 20086.531250\n",
      "Train Epoch: 42 [67584/225000 (30%)] Loss: 20550.480469\n",
      "Train Epoch: 42 [70080/225000 (31%)] Loss: 20511.210938\n",
      "Train Epoch: 42 [72576/225000 (32%)] Loss: 20242.390625\n",
      "Train Epoch: 42 [75072/225000 (33%)] Loss: 20326.837891\n",
      "Train Epoch: 42 [77568/225000 (34%)] Loss: 20294.785156\n",
      "Train Epoch: 42 [80064/225000 (36%)] Loss: 19649.972656\n",
      "Train Epoch: 42 [82560/225000 (37%)] Loss: 19718.851562\n",
      "Train Epoch: 42 [85056/225000 (38%)] Loss: 20215.421875\n",
      "Train Epoch: 42 [87552/225000 (39%)] Loss: 20243.804688\n",
      "Train Epoch: 42 [90048/225000 (40%)] Loss: 20359.394531\n",
      "Train Epoch: 42 [92544/225000 (41%)] Loss: 19911.185547\n",
      "Train Epoch: 42 [95040/225000 (42%)] Loss: 19879.308594\n",
      "Train Epoch: 42 [97536/225000 (43%)] Loss: 20268.339844\n",
      "Train Epoch: 42 [100032/225000 (44%)] Loss: 20838.484375\n",
      "Train Epoch: 42 [102528/225000 (46%)] Loss: 20720.197266\n",
      "Train Epoch: 42 [105024/225000 (47%)] Loss: 19858.226562\n",
      "Train Epoch: 42 [107520/225000 (48%)] Loss: 20087.320312\n",
      "Train Epoch: 42 [110016/225000 (49%)] Loss: 20039.863281\n",
      "Train Epoch: 42 [112512/225000 (50%)] Loss: 19928.160156\n",
      "Train Epoch: 42 [115008/225000 (51%)] Loss: 20277.242188\n",
      "Train Epoch: 42 [117504/225000 (52%)] Loss: 20191.574219\n",
      "Train Epoch: 42 [120000/225000 (53%)] Loss: 20247.367188\n",
      "Train Epoch: 42 [122496/225000 (54%)] Loss: 20462.406250\n",
      "Train Epoch: 42 [124992/225000 (56%)] Loss: 20323.691406\n",
      "Train Epoch: 42 [127488/225000 (57%)] Loss: 19912.468750\n",
      "Train Epoch: 42 [129984/225000 (58%)] Loss: 20154.417969\n",
      "Train Epoch: 42 [132480/225000 (59%)] Loss: 20175.398438\n",
      "Train Epoch: 42 [134976/225000 (60%)] Loss: 20217.468750\n",
      "Train Epoch: 42 [137472/225000 (61%)] Loss: 20167.445312\n",
      "Train Epoch: 42 [139968/225000 (62%)] Loss: 20317.542969\n",
      "Train Epoch: 42 [142464/225000 (63%)] Loss: 20231.472656\n",
      "Train Epoch: 42 [144960/225000 (64%)] Loss: 20000.152344\n",
      "Train Epoch: 42 [147456/225000 (66%)] Loss: 20659.550781\n",
      "Train Epoch: 42 [149952/225000 (67%)] Loss: 20131.062500\n",
      "Train Epoch: 42 [152448/225000 (68%)] Loss: 20550.824219\n",
      "Train Epoch: 42 [154944/225000 (69%)] Loss: 20312.214844\n",
      "Train Epoch: 42 [157440/225000 (70%)] Loss: 20011.408203\n",
      "Train Epoch: 42 [159936/225000 (71%)] Loss: 20126.242188\n",
      "Train Epoch: 42 [162432/225000 (72%)] Loss: 20482.503906\n",
      "Train Epoch: 42 [164928/225000 (73%)] Loss: 20121.515625\n",
      "Train Epoch: 42 [167424/225000 (74%)] Loss: 20116.535156\n",
      "Train Epoch: 42 [169920/225000 (76%)] Loss: 20229.691406\n",
      "Train Epoch: 42 [172416/225000 (77%)] Loss: 20094.367188\n",
      "Train Epoch: 42 [174912/225000 (78%)] Loss: 20153.894531\n",
      "Train Epoch: 42 [177408/225000 (79%)] Loss: 20414.242188\n",
      "Train Epoch: 42 [179904/225000 (80%)] Loss: 20088.068359\n",
      "Train Epoch: 42 [182400/225000 (81%)] Loss: 20281.195312\n",
      "Train Epoch: 42 [184896/225000 (82%)] Loss: 20218.679688\n",
      "Train Epoch: 42 [187392/225000 (83%)] Loss: 20503.425781\n",
      "Train Epoch: 42 [189888/225000 (84%)] Loss: 20123.238281\n",
      "Train Epoch: 42 [192384/225000 (86%)] Loss: 20246.091797\n",
      "Train Epoch: 42 [194880/225000 (87%)] Loss: 20284.285156\n",
      "Train Epoch: 42 [197376/225000 (88%)] Loss: 20115.583984\n",
      "Train Epoch: 42 [199872/225000 (89%)] Loss: 19784.941406\n",
      "Train Epoch: 42 [202368/225000 (90%)] Loss: 20427.589844\n",
      "Train Epoch: 42 [204864/225000 (91%)] Loss: 20754.468750\n",
      "Train Epoch: 42 [207360/225000 (92%)] Loss: 20058.285156\n",
      "Train Epoch: 42 [209856/225000 (93%)] Loss: 19832.876953\n",
      "Train Epoch: 42 [212352/225000 (94%)] Loss: 19876.121094\n",
      "Train Epoch: 42 [214848/225000 (95%)] Loss: 20153.304688\n",
      "Train Epoch: 42 [217344/225000 (97%)] Loss: 20229.892578\n",
      "Train Epoch: 42 [219840/225000 (98%)] Loss: 20638.634766\n",
      "Train Epoch: 42 [222336/225000 (99%)] Loss: 20605.279297\n",
      "Train Epoch: 42 [224832/225000 (100%)] Loss: 20411.197266\n",
      "    epoch          : 42\n",
      "    loss           : 20278.46840170382\n",
      "    val_loss       : 20168.489492000514\n",
      "Train Epoch: 43 [192/225000 (0%)] Loss: 19701.257812\n",
      "Train Epoch: 43 [2688/225000 (1%)] Loss: 20716.281250\n",
      "Train Epoch: 43 [5184/225000 (2%)] Loss: 20327.582031\n",
      "Train Epoch: 43 [7680/225000 (3%)] Loss: 19882.800781\n",
      "Train Epoch: 43 [10176/225000 (5%)] Loss: 20384.390625\n",
      "Train Epoch: 43 [12672/225000 (6%)] Loss: 20656.414062\n",
      "Train Epoch: 43 [15168/225000 (7%)] Loss: 20083.390625\n",
      "Train Epoch: 43 [17664/225000 (8%)] Loss: 20213.953125\n",
      "Train Epoch: 43 [20160/225000 (9%)] Loss: 19847.472656\n",
      "Train Epoch: 43 [22656/225000 (10%)] Loss: 20063.652344\n",
      "Train Epoch: 43 [25152/225000 (11%)] Loss: 20292.015625\n",
      "Train Epoch: 43 [27648/225000 (12%)] Loss: 19785.906250\n",
      "Train Epoch: 43 [30144/225000 (13%)] Loss: 19941.708984\n",
      "Train Epoch: 43 [32640/225000 (15%)] Loss: 20221.003906\n",
      "Train Epoch: 43 [35136/225000 (16%)] Loss: 20222.589844\n",
      "Train Epoch: 43 [37632/225000 (17%)] Loss: 20483.039062\n",
      "Train Epoch: 43 [40128/225000 (18%)] Loss: 20072.021484\n",
      "Train Epoch: 43 [42624/225000 (19%)] Loss: 20249.373047\n",
      "Train Epoch: 43 [45120/225000 (20%)] Loss: 20187.236328\n",
      "Train Epoch: 43 [47616/225000 (21%)] Loss: 20551.828125\n",
      "Train Epoch: 43 [50112/225000 (22%)] Loss: 20151.113281\n",
      "Train Epoch: 43 [52608/225000 (23%)] Loss: 20196.046875\n",
      "Train Epoch: 43 [55104/225000 (24%)] Loss: 20146.179688\n",
      "Train Epoch: 43 [57600/225000 (26%)] Loss: 19869.607422\n",
      "Train Epoch: 43 [60096/225000 (27%)] Loss: 20459.609375\n",
      "Train Epoch: 43 [62592/225000 (28%)] Loss: 20420.935547\n",
      "Train Epoch: 43 [65088/225000 (29%)] Loss: 20454.449219\n",
      "Train Epoch: 43 [67584/225000 (30%)] Loss: 20072.828125\n",
      "Train Epoch: 43 [70080/225000 (31%)] Loss: 20290.857422\n",
      "Train Epoch: 43 [72576/225000 (32%)] Loss: 20529.146484\n",
      "Train Epoch: 43 [75072/225000 (33%)] Loss: 20665.015625\n",
      "Train Epoch: 43 [77568/225000 (34%)] Loss: 19711.273438\n",
      "Train Epoch: 43 [80064/225000 (36%)] Loss: 20009.820312\n",
      "Train Epoch: 43 [82560/225000 (37%)] Loss: 20393.320312\n",
      "Train Epoch: 43 [85056/225000 (38%)] Loss: 20177.074219\n",
      "Train Epoch: 43 [87552/225000 (39%)] Loss: 20403.539062\n",
      "Train Epoch: 43 [90048/225000 (40%)] Loss: 20739.148438\n",
      "Train Epoch: 43 [92544/225000 (41%)] Loss: 19987.269531\n",
      "Train Epoch: 43 [95040/225000 (42%)] Loss: 20283.441406\n",
      "Train Epoch: 43 [97536/225000 (43%)] Loss: 20201.843750\n",
      "Train Epoch: 43 [100032/225000 (44%)] Loss: 20161.539062\n",
      "Train Epoch: 43 [102528/225000 (46%)] Loss: 20439.882812\n",
      "Train Epoch: 43 [105024/225000 (47%)] Loss: 20046.132812\n",
      "Train Epoch: 43 [107520/225000 (48%)] Loss: 20122.482422\n",
      "Train Epoch: 43 [110016/225000 (49%)] Loss: 21063.041016\n",
      "Train Epoch: 43 [112512/225000 (50%)] Loss: 20128.882812\n",
      "Train Epoch: 43 [115008/225000 (51%)] Loss: 20457.273438\n",
      "Train Epoch: 43 [117504/225000 (52%)] Loss: 20024.355469\n",
      "Train Epoch: 43 [120000/225000 (53%)] Loss: 19950.484375\n",
      "Train Epoch: 43 [122496/225000 (54%)] Loss: 20544.027344\n",
      "Train Epoch: 43 [124992/225000 (56%)] Loss: 20440.789062\n",
      "Train Epoch: 43 [127488/225000 (57%)] Loss: 20565.074219\n",
      "Train Epoch: 43 [129984/225000 (58%)] Loss: 20249.968750\n",
      "Train Epoch: 43 [132480/225000 (59%)] Loss: 20395.011719\n",
      "Train Epoch: 43 [134976/225000 (60%)] Loss: 20031.621094\n",
      "Train Epoch: 43 [137472/225000 (61%)] Loss: 20737.300781\n",
      "Train Epoch: 43 [139968/225000 (62%)] Loss: 19915.908203\n",
      "Train Epoch: 43 [142464/225000 (63%)] Loss: 20756.046875\n",
      "Train Epoch: 43 [144960/225000 (64%)] Loss: 20673.554688\n",
      "Train Epoch: 43 [147456/225000 (66%)] Loss: 20634.800781\n",
      "Train Epoch: 43 [149952/225000 (67%)] Loss: 20370.363281\n",
      "Train Epoch: 43 [152448/225000 (68%)] Loss: 20517.515625\n",
      "Train Epoch: 43 [154944/225000 (69%)] Loss: 20402.421875\n",
      "Train Epoch: 43 [157440/225000 (70%)] Loss: 20407.011719\n",
      "Train Epoch: 43 [159936/225000 (71%)] Loss: 20479.656250\n",
      "Train Epoch: 43 [162432/225000 (72%)] Loss: 20271.685547\n",
      "Train Epoch: 43 [164928/225000 (73%)] Loss: 20551.636719\n",
      "Train Epoch: 43 [167424/225000 (74%)] Loss: 20288.851562\n",
      "Train Epoch: 43 [169920/225000 (76%)] Loss: 19959.687500\n",
      "Train Epoch: 43 [172416/225000 (77%)] Loss: 20607.109375\n",
      "Train Epoch: 43 [174912/225000 (78%)] Loss: 20397.281250\n",
      "Train Epoch: 43 [177408/225000 (79%)] Loss: 19946.361328\n",
      "Train Epoch: 43 [179904/225000 (80%)] Loss: 20144.355469\n",
      "Train Epoch: 43 [182400/225000 (81%)] Loss: 20161.470703\n",
      "Train Epoch: 43 [184896/225000 (82%)] Loss: 20733.988281\n",
      "Train Epoch: 43 [187392/225000 (83%)] Loss: 19942.875000\n",
      "Train Epoch: 43 [189888/225000 (84%)] Loss: 19976.812500\n",
      "Train Epoch: 43 [192384/225000 (86%)] Loss: 20004.976562\n",
      "Train Epoch: 43 [194880/225000 (87%)] Loss: 20824.697266\n",
      "Train Epoch: 43 [197376/225000 (88%)] Loss: 20130.388672\n",
      "Train Epoch: 43 [199872/225000 (89%)] Loss: 20381.285156\n",
      "Train Epoch: 43 [202368/225000 (90%)] Loss: 20616.054688\n",
      "Train Epoch: 43 [204864/225000 (91%)] Loss: 20241.218750\n",
      "Train Epoch: 43 [207360/225000 (92%)] Loss: 20290.480469\n",
      "Train Epoch: 43 [209856/225000 (93%)] Loss: 20637.863281\n",
      "Train Epoch: 43 [212352/225000 (94%)] Loss: 20173.496094\n",
      "Train Epoch: 43 [214848/225000 (95%)] Loss: 20311.728516\n",
      "Train Epoch: 43 [217344/225000 (97%)] Loss: 20439.832031\n",
      "Train Epoch: 43 [219840/225000 (98%)] Loss: 20153.480469\n",
      "Train Epoch: 43 [222336/225000 (99%)] Loss: 20140.992188\n",
      "Train Epoch: 43 [224832/225000 (100%)] Loss: 20883.222656\n",
      "    epoch          : 43\n",
      "    loss           : 20268.752156436647\n",
      "    val_loss       : 20169.36233079206\n",
      "Train Epoch: 44 [192/225000 (0%)] Loss: 20377.615234\n",
      "Train Epoch: 44 [2688/225000 (1%)] Loss: 20446.851562\n",
      "Train Epoch: 44 [5184/225000 (2%)] Loss: 20347.968750\n",
      "Train Epoch: 44 [7680/225000 (3%)] Loss: 20521.949219\n",
      "Train Epoch: 44 [10176/225000 (5%)] Loss: 20753.603516\n",
      "Train Epoch: 44 [12672/225000 (6%)] Loss: 20546.501953\n",
      "Train Epoch: 44 [15168/225000 (7%)] Loss: 20015.265625\n",
      "Train Epoch: 44 [17664/225000 (8%)] Loss: 19941.539062\n",
      "Train Epoch: 44 [20160/225000 (9%)] Loss: 20024.849609\n",
      "Train Epoch: 44 [22656/225000 (10%)] Loss: 20053.281250\n",
      "Train Epoch: 44 [25152/225000 (11%)] Loss: 20393.105469\n",
      "Train Epoch: 44 [27648/225000 (12%)] Loss: 20265.564453\n",
      "Train Epoch: 44 [30144/225000 (13%)] Loss: 20219.068359\n",
      "Train Epoch: 44 [32640/225000 (15%)] Loss: 20798.818359\n",
      "Train Epoch: 44 [35136/225000 (16%)] Loss: 20047.544922\n",
      "Train Epoch: 44 [37632/225000 (17%)] Loss: 20178.191406\n",
      "Train Epoch: 44 [40128/225000 (18%)] Loss: 20254.837891\n",
      "Train Epoch: 44 [42624/225000 (19%)] Loss: 20668.500000\n",
      "Train Epoch: 44 [45120/225000 (20%)] Loss: 19940.392578\n",
      "Train Epoch: 44 [47616/225000 (21%)] Loss: 19801.093750\n",
      "Train Epoch: 44 [50112/225000 (22%)] Loss: 19971.931641\n",
      "Train Epoch: 44 [52608/225000 (23%)] Loss: 20176.234375\n",
      "Train Epoch: 44 [55104/225000 (24%)] Loss: 20331.187500\n",
      "Train Epoch: 44 [57600/225000 (26%)] Loss: 20734.443359\n",
      "Train Epoch: 44 [60096/225000 (27%)] Loss: 19870.121094\n",
      "Train Epoch: 44 [62592/225000 (28%)] Loss: 20460.468750\n",
      "Train Epoch: 44 [65088/225000 (29%)] Loss: 20177.078125\n",
      "Train Epoch: 44 [67584/225000 (30%)] Loss: 20335.078125\n",
      "Train Epoch: 44 [70080/225000 (31%)] Loss: 20365.691406\n",
      "Train Epoch: 44 [72576/225000 (32%)] Loss: 20522.945312\n",
      "Train Epoch: 44 [75072/225000 (33%)] Loss: 19969.671875\n",
      "Train Epoch: 44 [77568/225000 (34%)] Loss: 19767.009766\n",
      "Train Epoch: 44 [80064/225000 (36%)] Loss: 20387.324219\n",
      "Train Epoch: 44 [82560/225000 (37%)] Loss: 20114.062500\n",
      "Train Epoch: 44 [85056/225000 (38%)] Loss: 20356.078125\n",
      "Train Epoch: 44 [87552/225000 (39%)] Loss: 20264.367188\n",
      "Train Epoch: 44 [90048/225000 (40%)] Loss: 20243.925781\n",
      "Train Epoch: 44 [92544/225000 (41%)] Loss: 20198.289062\n",
      "Train Epoch: 44 [95040/225000 (42%)] Loss: 19993.425781\n",
      "Train Epoch: 44 [97536/225000 (43%)] Loss: 19911.191406\n",
      "Train Epoch: 44 [100032/225000 (44%)] Loss: 19899.203125\n",
      "Train Epoch: 44 [102528/225000 (46%)] Loss: 20217.851562\n",
      "Train Epoch: 44 [105024/225000 (47%)] Loss: 20220.125000\n",
      "Train Epoch: 44 [107520/225000 (48%)] Loss: 20205.574219\n",
      "Train Epoch: 44 [110016/225000 (49%)] Loss: 20226.156250\n",
      "Train Epoch: 44 [112512/225000 (50%)] Loss: 20439.103516\n",
      "Train Epoch: 44 [115008/225000 (51%)] Loss: 19943.242188\n",
      "Train Epoch: 44 [117504/225000 (52%)] Loss: 20096.957031\n",
      "Train Epoch: 44 [120000/225000 (53%)] Loss: 19931.628906\n",
      "Train Epoch: 44 [122496/225000 (54%)] Loss: 20254.632812\n",
      "Train Epoch: 44 [124992/225000 (56%)] Loss: 20434.746094\n",
      "Train Epoch: 44 [127488/225000 (57%)] Loss: 20602.130859\n",
      "Train Epoch: 44 [129984/225000 (58%)] Loss: 20397.751953\n",
      "Train Epoch: 44 [132480/225000 (59%)] Loss: 20378.361328\n",
      "Train Epoch: 44 [134976/225000 (60%)] Loss: 20343.292969\n",
      "Train Epoch: 44 [137472/225000 (61%)] Loss: 20182.101562\n",
      "Train Epoch: 44 [139968/225000 (62%)] Loss: 20117.128906\n",
      "Train Epoch: 44 [142464/225000 (63%)] Loss: 20021.449219\n",
      "Train Epoch: 44 [144960/225000 (64%)] Loss: 20164.457031\n",
      "Train Epoch: 44 [147456/225000 (66%)] Loss: 20340.933594\n",
      "Train Epoch: 44 [149952/225000 (67%)] Loss: 20427.691406\n",
      "Train Epoch: 44 [152448/225000 (68%)] Loss: 20217.654297\n",
      "Train Epoch: 44 [154944/225000 (69%)] Loss: 20158.773438\n",
      "Train Epoch: 44 [157440/225000 (70%)] Loss: 20668.726562\n",
      "Train Epoch: 44 [159936/225000 (71%)] Loss: 20636.603516\n",
      "Train Epoch: 44 [162432/225000 (72%)] Loss: 19789.000000\n",
      "Train Epoch: 44 [164928/225000 (73%)] Loss: 20252.750000\n",
      "Train Epoch: 44 [167424/225000 (74%)] Loss: 20549.062500\n",
      "Train Epoch: 44 [169920/225000 (76%)] Loss: 20543.976562\n",
      "Train Epoch: 44 [172416/225000 (77%)] Loss: 20098.384766\n",
      "Train Epoch: 44 [174912/225000 (78%)] Loss: 20305.189453\n",
      "Train Epoch: 44 [177408/225000 (79%)] Loss: 20103.267578\n",
      "Train Epoch: 44 [179904/225000 (80%)] Loss: 20166.324219\n",
      "Train Epoch: 44 [182400/225000 (81%)] Loss: 20389.753906\n",
      "Train Epoch: 44 [184896/225000 (82%)] Loss: 20567.177734\n",
      "Train Epoch: 44 [187392/225000 (83%)] Loss: 20280.744141\n",
      "Train Epoch: 44 [189888/225000 (84%)] Loss: 20224.148438\n",
      "Train Epoch: 44 [192384/225000 (86%)] Loss: 20387.722656\n",
      "Train Epoch: 44 [194880/225000 (87%)] Loss: 20464.953125\n",
      "Train Epoch: 44 [197376/225000 (88%)] Loss: 20334.496094\n",
      "Train Epoch: 44 [199872/225000 (89%)] Loss: 20254.281250\n",
      "Train Epoch: 44 [202368/225000 (90%)] Loss: 20373.783203\n",
      "Train Epoch: 44 [204864/225000 (91%)] Loss: 20307.968750\n",
      "Train Epoch: 44 [207360/225000 (92%)] Loss: 20705.164062\n",
      "Train Epoch: 44 [209856/225000 (93%)] Loss: 20273.945312\n",
      "Train Epoch: 44 [212352/225000 (94%)] Loss: 20184.480469\n",
      "Train Epoch: 44 [214848/225000 (95%)] Loss: 20624.800781\n",
      "Train Epoch: 44 [217344/225000 (97%)] Loss: 20398.390625\n",
      "Train Epoch: 44 [219840/225000 (98%)] Loss: 20396.898438\n",
      "Train Epoch: 44 [222336/225000 (99%)] Loss: 20047.699219\n",
      "Train Epoch: 44 [224832/225000 (100%)] Loss: 20811.386719\n",
      "    epoch          : 44\n",
      "    loss           : 20264.180345763118\n",
      "    val_loss       : 20159.63170656266\n",
      "Train Epoch: 45 [192/225000 (0%)] Loss: 20197.175781\n",
      "Train Epoch: 45 [2688/225000 (1%)] Loss: 20115.013672\n",
      "Train Epoch: 45 [5184/225000 (2%)] Loss: 20315.908203\n",
      "Train Epoch: 45 [7680/225000 (3%)] Loss: 20080.023438\n",
      "Train Epoch: 45 [10176/225000 (5%)] Loss: 20570.546875\n",
      "Train Epoch: 45 [12672/225000 (6%)] Loss: 20086.238281\n",
      "Train Epoch: 45 [15168/225000 (7%)] Loss: 20668.554688\n",
      "Train Epoch: 45 [17664/225000 (8%)] Loss: 20425.460938\n",
      "Train Epoch: 45 [20160/225000 (9%)] Loss: 20174.619141\n",
      "Train Epoch: 45 [22656/225000 (10%)] Loss: 20185.937500\n",
      "Train Epoch: 45 [25152/225000 (11%)] Loss: 20077.746094\n",
      "Train Epoch: 45 [27648/225000 (12%)] Loss: 20172.552734\n",
      "Train Epoch: 45 [30144/225000 (13%)] Loss: 20414.113281\n",
      "Train Epoch: 45 [32640/225000 (15%)] Loss: 20634.462891\n",
      "Train Epoch: 45 [35136/225000 (16%)] Loss: 20301.945312\n",
      "Train Epoch: 45 [37632/225000 (17%)] Loss: 20080.666016\n",
      "Train Epoch: 45 [40128/225000 (18%)] Loss: 20144.484375\n",
      "Train Epoch: 45 [42624/225000 (19%)] Loss: 19860.003906\n",
      "Train Epoch: 45 [45120/225000 (20%)] Loss: 20195.027344\n",
      "Train Epoch: 45 [47616/225000 (21%)] Loss: 20420.222656\n",
      "Train Epoch: 45 [50112/225000 (22%)] Loss: 20036.439453\n",
      "Train Epoch: 45 [52608/225000 (23%)] Loss: 20384.845703\n",
      "Train Epoch: 45 [55104/225000 (24%)] Loss: 20015.007812\n",
      "Train Epoch: 45 [57600/225000 (26%)] Loss: 19978.593750\n",
      "Train Epoch: 45 [60096/225000 (27%)] Loss: 19948.605469\n",
      "Train Epoch: 45 [62592/225000 (28%)] Loss: 20614.023438\n",
      "Train Epoch: 45 [65088/225000 (29%)] Loss: 20289.625000\n",
      "Train Epoch: 45 [67584/225000 (30%)] Loss: 19949.523438\n",
      "Train Epoch: 45 [70080/225000 (31%)] Loss: 20351.605469\n",
      "Train Epoch: 45 [72576/225000 (32%)] Loss: 19939.445312\n",
      "Train Epoch: 45 [75072/225000 (33%)] Loss: 20347.515625\n",
      "Train Epoch: 45 [77568/225000 (34%)] Loss: 20296.578125\n",
      "Train Epoch: 45 [80064/225000 (36%)] Loss: 20209.875000\n",
      "Train Epoch: 45 [82560/225000 (37%)] Loss: 20046.146484\n",
      "Train Epoch: 45 [85056/225000 (38%)] Loss: 20350.912109\n",
      "Train Epoch: 45 [87552/225000 (39%)] Loss: 20305.183594\n",
      "Train Epoch: 45 [90048/225000 (40%)] Loss: 20341.523438\n",
      "Train Epoch: 45 [92544/225000 (41%)] Loss: 20638.492188\n",
      "Train Epoch: 45 [95040/225000 (42%)] Loss: 20210.898438\n",
      "Train Epoch: 45 [97536/225000 (43%)] Loss: 20132.492188\n",
      "Train Epoch: 45 [100032/225000 (44%)] Loss: 19874.996094\n",
      "Train Epoch: 45 [102528/225000 (46%)] Loss: 20357.761719\n",
      "Train Epoch: 45 [105024/225000 (47%)] Loss: 20706.679688\n",
      "Train Epoch: 45 [107520/225000 (48%)] Loss: 20619.386719\n",
      "Train Epoch: 45 [110016/225000 (49%)] Loss: 20510.369141\n",
      "Train Epoch: 45 [112512/225000 (50%)] Loss: 20411.308594\n",
      "Train Epoch: 45 [115008/225000 (51%)] Loss: 20694.380859\n",
      "Train Epoch: 45 [117504/225000 (52%)] Loss: 20052.771484\n",
      "Train Epoch: 45 [120000/225000 (53%)] Loss: 19973.992188\n",
      "Train Epoch: 45 [122496/225000 (54%)] Loss: 20429.339844\n",
      "Train Epoch: 45 [124992/225000 (56%)] Loss: 20048.371094\n",
      "Train Epoch: 45 [127488/225000 (57%)] Loss: 20333.675781\n",
      "Train Epoch: 45 [129984/225000 (58%)] Loss: 20024.835938\n",
      "Train Epoch: 45 [132480/225000 (59%)] Loss: 20470.128906\n",
      "Train Epoch: 45 [134976/225000 (60%)] Loss: 20476.839844\n",
      "Train Epoch: 45 [137472/225000 (61%)] Loss: 20209.697266\n",
      "Train Epoch: 45 [139968/225000 (62%)] Loss: 20623.515625\n",
      "Train Epoch: 45 [142464/225000 (63%)] Loss: 20248.941406\n",
      "Train Epoch: 45 [144960/225000 (64%)] Loss: 20135.283203\n",
      "Train Epoch: 45 [147456/225000 (66%)] Loss: 20723.251953\n",
      "Train Epoch: 45 [149952/225000 (67%)] Loss: 20208.218750\n",
      "Train Epoch: 45 [152448/225000 (68%)] Loss: 20127.980469\n",
      "Train Epoch: 45 [154944/225000 (69%)] Loss: 20574.236328\n",
      "Train Epoch: 45 [157440/225000 (70%)] Loss: 19960.705078\n",
      "Train Epoch: 45 [159936/225000 (71%)] Loss: 20793.308594\n",
      "Train Epoch: 45 [162432/225000 (72%)] Loss: 20331.292969\n",
      "Train Epoch: 45 [164928/225000 (73%)] Loss: 20340.183594\n",
      "Train Epoch: 45 [167424/225000 (74%)] Loss: 35277.394531\n",
      "Train Epoch: 45 [169920/225000 (76%)] Loss: 20092.070312\n",
      "Train Epoch: 45 [172416/225000 (77%)] Loss: 20153.597656\n",
      "Train Epoch: 45 [174912/225000 (78%)] Loss: 20084.753906\n",
      "Train Epoch: 45 [177408/225000 (79%)] Loss: 20400.136719\n",
      "Train Epoch: 45 [179904/225000 (80%)] Loss: 20551.437500\n",
      "Train Epoch: 45 [182400/225000 (81%)] Loss: 20497.414062\n",
      "Train Epoch: 45 [184896/225000 (82%)] Loss: 20336.332031\n",
      "Train Epoch: 45 [187392/225000 (83%)] Loss: 20024.451172\n",
      "Train Epoch: 45 [189888/225000 (84%)] Loss: 19885.035156\n",
      "Train Epoch: 45 [192384/225000 (86%)] Loss: 20001.488281\n",
      "Train Epoch: 45 [194880/225000 (87%)] Loss: 20255.343750\n",
      "Train Epoch: 45 [197376/225000 (88%)] Loss: 20306.003906\n",
      "Train Epoch: 45 [199872/225000 (89%)] Loss: 20040.464844\n",
      "Train Epoch: 45 [202368/225000 (90%)] Loss: 20358.597656\n",
      "Train Epoch: 45 [204864/225000 (91%)] Loss: 19789.144531\n",
      "Train Epoch: 45 [207360/225000 (92%)] Loss: 19900.871094\n",
      "Train Epoch: 45 [209856/225000 (93%)] Loss: 20324.644531\n",
      "Train Epoch: 45 [212352/225000 (94%)] Loss: 19957.515625\n",
      "Train Epoch: 45 [214848/225000 (95%)] Loss: 20614.414062\n",
      "Train Epoch: 45 [217344/225000 (97%)] Loss: 19991.066406\n",
      "Train Epoch: 45 [219840/225000 (98%)] Loss: 20131.335938\n",
      "Train Epoch: 45 [222336/225000 (99%)] Loss: 20107.398438\n",
      "Train Epoch: 45 [224832/225000 (100%)] Loss: 20023.318359\n",
      "    epoch          : 45\n",
      "    loss           : 20266.07306054021\n",
      "    val_loss       : 20166.923360861896\n",
      "Train Epoch: 46 [192/225000 (0%)] Loss: 20234.050781\n",
      "Train Epoch: 46 [2688/225000 (1%)] Loss: 20410.449219\n",
      "Train Epoch: 46 [5184/225000 (2%)] Loss: 20404.199219\n",
      "Train Epoch: 46 [7680/225000 (3%)] Loss: 20546.746094\n",
      "Train Epoch: 46 [10176/225000 (5%)] Loss: 20116.046875\n",
      "Train Epoch: 46 [12672/225000 (6%)] Loss: 20661.976562\n",
      "Train Epoch: 46 [15168/225000 (7%)] Loss: 20414.287109\n",
      "Train Epoch: 46 [17664/225000 (8%)] Loss: 20087.792969\n",
      "Train Epoch: 46 [20160/225000 (9%)] Loss: 20022.378906\n",
      "Train Epoch: 46 [22656/225000 (10%)] Loss: 20380.652344\n",
      "Train Epoch: 46 [25152/225000 (11%)] Loss: 20281.736328\n",
      "Train Epoch: 46 [27648/225000 (12%)] Loss: 20120.351562\n",
      "Train Epoch: 46 [30144/225000 (13%)] Loss: 20280.195312\n",
      "Train Epoch: 46 [32640/225000 (15%)] Loss: 20157.363281\n",
      "Train Epoch: 46 [35136/225000 (16%)] Loss: 20551.792969\n",
      "Train Epoch: 46 [37632/225000 (17%)] Loss: 20389.552734\n",
      "Train Epoch: 46 [40128/225000 (18%)] Loss: 19894.367188\n",
      "Train Epoch: 46 [42624/225000 (19%)] Loss: 19923.242188\n",
      "Train Epoch: 46 [45120/225000 (20%)] Loss: 20509.777344\n",
      "Train Epoch: 46 [47616/225000 (21%)] Loss: 20668.343750\n",
      "Train Epoch: 46 [50112/225000 (22%)] Loss: 20130.226562\n",
      "Train Epoch: 46 [52608/225000 (23%)] Loss: 20259.031250\n",
      "Train Epoch: 46 [55104/225000 (24%)] Loss: 20664.175781\n",
      "Train Epoch: 46 [57600/225000 (26%)] Loss: 20413.843750\n",
      "Train Epoch: 46 [60096/225000 (27%)] Loss: 21064.166016\n",
      "Train Epoch: 46 [62592/225000 (28%)] Loss: 19951.542969\n",
      "Train Epoch: 46 [65088/225000 (29%)] Loss: 20321.382812\n",
      "Train Epoch: 46 [67584/225000 (30%)] Loss: 20661.839844\n",
      "Train Epoch: 46 [70080/225000 (31%)] Loss: 20711.820312\n",
      "Train Epoch: 46 [72576/225000 (32%)] Loss: 20033.277344\n",
      "Train Epoch: 46 [75072/225000 (33%)] Loss: 20702.574219\n",
      "Train Epoch: 46 [77568/225000 (34%)] Loss: 20503.712891\n",
      "Train Epoch: 46 [80064/225000 (36%)] Loss: 20288.302734\n",
      "Train Epoch: 46 [82560/225000 (37%)] Loss: 20334.058594\n",
      "Train Epoch: 46 [85056/225000 (38%)] Loss: 20254.894531\n",
      "Train Epoch: 46 [87552/225000 (39%)] Loss: 20529.171875\n",
      "Train Epoch: 46 [90048/225000 (40%)] Loss: 19967.378906\n",
      "Train Epoch: 46 [92544/225000 (41%)] Loss: 20356.697266\n",
      "Train Epoch: 46 [95040/225000 (42%)] Loss: 19735.570312\n",
      "Train Epoch: 46 [97536/225000 (43%)] Loss: 20281.593750\n",
      "Train Epoch: 46 [100032/225000 (44%)] Loss: 20631.207031\n",
      "Train Epoch: 46 [102528/225000 (46%)] Loss: 20298.875000\n",
      "Train Epoch: 46 [105024/225000 (47%)] Loss: 20129.531250\n",
      "Train Epoch: 46 [107520/225000 (48%)] Loss: 20239.640625\n",
      "Train Epoch: 46 [110016/225000 (49%)] Loss: 20495.507812\n",
      "Train Epoch: 46 [112512/225000 (50%)] Loss: 20497.414062\n",
      "Train Epoch: 46 [115008/225000 (51%)] Loss: 20361.531250\n",
      "Train Epoch: 46 [117504/225000 (52%)] Loss: 20510.693359\n",
      "Train Epoch: 46 [120000/225000 (53%)] Loss: 20384.929688\n",
      "Train Epoch: 46 [122496/225000 (54%)] Loss: 19159.156250\n",
      "Train Epoch: 46 [124992/225000 (56%)] Loss: 19959.992188\n",
      "Train Epoch: 46 [127488/225000 (57%)] Loss: 20004.947266\n",
      "Train Epoch: 46 [129984/225000 (58%)] Loss: 20576.917969\n",
      "Train Epoch: 46 [132480/225000 (59%)] Loss: 20318.152344\n",
      "Train Epoch: 46 [134976/225000 (60%)] Loss: 20002.093750\n",
      "Train Epoch: 46 [137472/225000 (61%)] Loss: 19691.693359\n",
      "Train Epoch: 46 [139968/225000 (62%)] Loss: 19945.820312\n",
      "Train Epoch: 46 [142464/225000 (63%)] Loss: 19755.984375\n",
      "Train Epoch: 46 [144960/225000 (64%)] Loss: 20660.066406\n",
      "Train Epoch: 46 [147456/225000 (66%)] Loss: 20055.457031\n",
      "Train Epoch: 46 [149952/225000 (67%)] Loss: 20573.082031\n",
      "Train Epoch: 46 [152448/225000 (68%)] Loss: 20060.777344\n",
      "Train Epoch: 46 [154944/225000 (69%)] Loss: 20260.791016\n",
      "Train Epoch: 46 [157440/225000 (70%)] Loss: 20608.511719\n",
      "Train Epoch: 46 [159936/225000 (71%)] Loss: 20117.503906\n",
      "Train Epoch: 46 [162432/225000 (72%)] Loss: 20065.023438\n",
      "Train Epoch: 46 [164928/225000 (73%)] Loss: 20263.656250\n",
      "Train Epoch: 46 [167424/225000 (74%)] Loss: 19763.921875\n",
      "Train Epoch: 46 [169920/225000 (76%)] Loss: 20310.621094\n",
      "Train Epoch: 46 [172416/225000 (77%)] Loss: 20260.880859\n",
      "Train Epoch: 46 [174912/225000 (78%)] Loss: 20020.429688\n",
      "Train Epoch: 46 [177408/225000 (79%)] Loss: 20298.757812\n",
      "Train Epoch: 46 [179904/225000 (80%)] Loss: 20054.333984\n",
      "Train Epoch: 46 [182400/225000 (81%)] Loss: 20467.101562\n",
      "Train Epoch: 46 [184896/225000 (82%)] Loss: 20417.015625\n",
      "Train Epoch: 46 [187392/225000 (83%)] Loss: 20560.972656\n",
      "Train Epoch: 46 [189888/225000 (84%)] Loss: 20179.960938\n",
      "Train Epoch: 46 [192384/225000 (86%)] Loss: 19698.503906\n",
      "Train Epoch: 46 [194880/225000 (87%)] Loss: 20469.896484\n",
      "Train Epoch: 46 [197376/225000 (88%)] Loss: 19972.171875\n",
      "Train Epoch: 46 [199872/225000 (89%)] Loss: 20771.773438\n",
      "Train Epoch: 46 [202368/225000 (90%)] Loss: 19796.355469\n",
      "Train Epoch: 46 [204864/225000 (91%)] Loss: 20297.527344\n",
      "Train Epoch: 46 [207360/225000 (92%)] Loss: 20015.966797\n",
      "Train Epoch: 46 [209856/225000 (93%)] Loss: 19963.875000\n",
      "Train Epoch: 46 [212352/225000 (94%)] Loss: 20087.541016\n",
      "Train Epoch: 46 [214848/225000 (95%)] Loss: 20615.710938\n",
      "Train Epoch: 46 [217344/225000 (97%)] Loss: 19579.121094\n",
      "Train Epoch: 46 [219840/225000 (98%)] Loss: 19778.529297\n",
      "Train Epoch: 46 [222336/225000 (99%)] Loss: 19716.732422\n",
      "Train Epoch: 46 [224832/225000 (100%)] Loss: 20304.421875\n",
      "    epoch          : 46\n",
      "    loss           : 20251.305545741787\n",
      "    val_loss       : 20157.158851457916\n",
      "Train Epoch: 47 [192/225000 (0%)] Loss: 20183.078125\n",
      "Train Epoch: 47 [2688/225000 (1%)] Loss: 19970.011719\n",
      "Train Epoch: 47 [5184/225000 (2%)] Loss: 20436.123047\n",
      "Train Epoch: 47 [7680/225000 (3%)] Loss: 20086.058594\n",
      "Train Epoch: 47 [10176/225000 (5%)] Loss: 20439.761719\n",
      "Train Epoch: 47 [12672/225000 (6%)] Loss: 20444.708984\n",
      "Train Epoch: 47 [15168/225000 (7%)] Loss: 20265.937500\n",
      "Train Epoch: 47 [17664/225000 (8%)] Loss: 20111.632812\n",
      "Train Epoch: 47 [20160/225000 (9%)] Loss: 20000.371094\n",
      "Train Epoch: 47 [22656/225000 (10%)] Loss: 20471.617188\n",
      "Train Epoch: 47 [25152/225000 (11%)] Loss: 19753.375000\n",
      "Train Epoch: 47 [27648/225000 (12%)] Loss: 20003.996094\n",
      "Train Epoch: 47 [30144/225000 (13%)] Loss: 20308.113281\n",
      "Train Epoch: 47 [32640/225000 (15%)] Loss: 20032.679688\n",
      "Train Epoch: 47 [35136/225000 (16%)] Loss: 20288.253906\n",
      "Train Epoch: 47 [37632/225000 (17%)] Loss: 20495.519531\n",
      "Train Epoch: 47 [40128/225000 (18%)] Loss: 20081.765625\n",
      "Train Epoch: 47 [42624/225000 (19%)] Loss: 20665.863281\n",
      "Train Epoch: 47 [45120/225000 (20%)] Loss: 20390.869141\n",
      "Train Epoch: 47 [47616/225000 (21%)] Loss: 20402.496094\n",
      "Train Epoch: 47 [50112/225000 (22%)] Loss: 20435.472656\n",
      "Train Epoch: 47 [52608/225000 (23%)] Loss: 20261.083984\n",
      "Train Epoch: 47 [55104/225000 (24%)] Loss: 20395.871094\n",
      "Train Epoch: 47 [57600/225000 (26%)] Loss: 20165.511719\n",
      "Train Epoch: 47 [60096/225000 (27%)] Loss: 20700.062500\n",
      "Train Epoch: 47 [62592/225000 (28%)] Loss: 19861.660156\n",
      "Train Epoch: 47 [65088/225000 (29%)] Loss: 20184.990234\n",
      "Train Epoch: 47 [67584/225000 (30%)] Loss: 20225.914062\n",
      "Train Epoch: 47 [70080/225000 (31%)] Loss: 20720.058594\n",
      "Train Epoch: 47 [72576/225000 (32%)] Loss: 20730.988281\n",
      "Train Epoch: 47 [75072/225000 (33%)] Loss: 19885.990234\n",
      "Train Epoch: 47 [77568/225000 (34%)] Loss: 20714.085938\n",
      "Train Epoch: 47 [80064/225000 (36%)] Loss: 19799.671875\n",
      "Train Epoch: 47 [82560/225000 (37%)] Loss: 20501.296875\n",
      "Train Epoch: 47 [85056/225000 (38%)] Loss: 20389.695312\n",
      "Train Epoch: 47 [87552/225000 (39%)] Loss: 19855.265625\n",
      "Train Epoch: 47 [90048/225000 (40%)] Loss: 19636.884766\n",
      "Train Epoch: 47 [92544/225000 (41%)] Loss: 20301.152344\n",
      "Train Epoch: 47 [95040/225000 (42%)] Loss: 20721.343750\n",
      "Train Epoch: 47 [97536/225000 (43%)] Loss: 20597.462891\n",
      "Train Epoch: 47 [100032/225000 (44%)] Loss: 20708.974609\n",
      "Train Epoch: 47 [102528/225000 (46%)] Loss: 20213.074219\n",
      "Train Epoch: 47 [105024/225000 (47%)] Loss: 20019.980469\n",
      "Train Epoch: 47 [107520/225000 (48%)] Loss: 20308.179688\n",
      "Train Epoch: 47 [110016/225000 (49%)] Loss: 20196.634766\n",
      "Train Epoch: 47 [112512/225000 (50%)] Loss: 20353.039062\n",
      "Train Epoch: 47 [115008/225000 (51%)] Loss: 19415.230469\n",
      "Train Epoch: 47 [117504/225000 (52%)] Loss: 20059.714844\n",
      "Train Epoch: 47 [120000/225000 (53%)] Loss: 20126.142578\n",
      "Train Epoch: 47 [122496/225000 (54%)] Loss: 20565.546875\n",
      "Train Epoch: 47 [124992/225000 (56%)] Loss: 19979.507812\n",
      "Train Epoch: 47 [127488/225000 (57%)] Loss: 20170.445312\n",
      "Train Epoch: 47 [129984/225000 (58%)] Loss: 20562.736328\n",
      "Train Epoch: 47 [132480/225000 (59%)] Loss: 20632.597656\n",
      "Train Epoch: 47 [134976/225000 (60%)] Loss: 20695.550781\n",
      "Train Epoch: 47 [137472/225000 (61%)] Loss: 20808.527344\n",
      "Train Epoch: 47 [139968/225000 (62%)] Loss: 20203.246094\n",
      "Train Epoch: 47 [142464/225000 (63%)] Loss: 20076.802734\n",
      "Train Epoch: 47 [144960/225000 (64%)] Loss: 20600.781250\n",
      "Train Epoch: 47 [147456/225000 (66%)] Loss: 20126.691406\n",
      "Train Epoch: 47 [149952/225000 (67%)] Loss: 19971.593750\n",
      "Train Epoch: 47 [152448/225000 (68%)] Loss: 20606.966797\n",
      "Train Epoch: 47 [154944/225000 (69%)] Loss: 20094.375000\n",
      "Train Epoch: 47 [157440/225000 (70%)] Loss: 20495.529297\n",
      "Train Epoch: 47 [159936/225000 (71%)] Loss: 19895.000000\n",
      "Train Epoch: 47 [162432/225000 (72%)] Loss: 20450.609375\n",
      "Train Epoch: 47 [164928/225000 (73%)] Loss: 20147.613281\n",
      "Train Epoch: 47 [167424/225000 (74%)] Loss: 20444.501953\n",
      "Train Epoch: 47 [169920/225000 (76%)] Loss: 20013.552734\n",
      "Train Epoch: 47 [172416/225000 (77%)] Loss: 20105.222656\n",
      "Train Epoch: 47 [174912/225000 (78%)] Loss: 19897.570312\n",
      "Train Epoch: 47 [177408/225000 (79%)] Loss: 20406.189453\n",
      "Train Epoch: 47 [179904/225000 (80%)] Loss: 20282.105469\n",
      "Train Epoch: 47 [182400/225000 (81%)] Loss: 19982.298828\n",
      "Train Epoch: 47 [184896/225000 (82%)] Loss: 19942.191406\n",
      "Train Epoch: 47 [187392/225000 (83%)] Loss: 20114.142578\n",
      "Train Epoch: 47 [189888/225000 (84%)] Loss: 20592.328125\n",
      "Train Epoch: 47 [192384/225000 (86%)] Loss: 20556.523438\n",
      "Train Epoch: 47 [194880/225000 (87%)] Loss: 20185.753906\n",
      "Train Epoch: 47 [197376/225000 (88%)] Loss: 20437.433594\n",
      "Train Epoch: 47 [199872/225000 (89%)] Loss: 20652.085938\n",
      "Train Epoch: 47 [202368/225000 (90%)] Loss: 20081.429688\n",
      "Train Epoch: 47 [204864/225000 (91%)] Loss: 20472.371094\n",
      "Train Epoch: 47 [207360/225000 (92%)] Loss: 20667.240234\n",
      "Train Epoch: 47 [209856/225000 (93%)] Loss: 20138.578125\n",
      "Train Epoch: 47 [212352/225000 (94%)] Loss: 20092.687500\n",
      "Train Epoch: 47 [214848/225000 (95%)] Loss: 20374.666016\n",
      "Train Epoch: 47 [217344/225000 (97%)] Loss: 20096.433594\n",
      "Train Epoch: 47 [219840/225000 (98%)] Loss: 20239.054688\n",
      "Train Epoch: 47 [222336/225000 (99%)] Loss: 20369.736328\n",
      "Train Epoch: 47 [224832/225000 (100%)] Loss: 20045.326172\n",
      "    epoch          : 47\n",
      "    loss           : 20247.923684806952\n",
      "    val_loss       : 20267.057221894047\n",
      "Train Epoch: 48 [192/225000 (0%)] Loss: 20837.296875\n",
      "Train Epoch: 48 [2688/225000 (1%)] Loss: 19895.148438\n",
      "Train Epoch: 48 [5184/225000 (2%)] Loss: 20064.296875\n",
      "Train Epoch: 48 [7680/225000 (3%)] Loss: 20596.421875\n",
      "Train Epoch: 48 [10176/225000 (5%)] Loss: 20454.701172\n",
      "Train Epoch: 48 [12672/225000 (6%)] Loss: 20536.164062\n",
      "Train Epoch: 48 [15168/225000 (7%)] Loss: 20677.433594\n",
      "Train Epoch: 48 [17664/225000 (8%)] Loss: 20471.820312\n",
      "Train Epoch: 48 [20160/225000 (9%)] Loss: 20230.865234\n",
      "Train Epoch: 48 [22656/225000 (10%)] Loss: 20000.373047\n",
      "Train Epoch: 48 [25152/225000 (11%)] Loss: 20541.046875\n",
      "Train Epoch: 48 [27648/225000 (12%)] Loss: 20623.193359\n",
      "Train Epoch: 48 [30144/225000 (13%)] Loss: 20760.562500\n",
      "Train Epoch: 48 [32640/225000 (15%)] Loss: 19988.269531\n",
      "Train Epoch: 48 [35136/225000 (16%)] Loss: 19987.167969\n",
      "Train Epoch: 48 [37632/225000 (17%)] Loss: 20707.214844\n",
      "Train Epoch: 48 [40128/225000 (18%)] Loss: 20411.074219\n",
      "Train Epoch: 48 [42624/225000 (19%)] Loss: 19951.091797\n",
      "Train Epoch: 48 [45120/225000 (20%)] Loss: 20556.103516\n",
      "Train Epoch: 48 [47616/225000 (21%)] Loss: 19894.019531\n",
      "Train Epoch: 48 [50112/225000 (22%)] Loss: 19826.863281\n",
      "Train Epoch: 48 [52608/225000 (23%)] Loss: 20478.007812\n",
      "Train Epoch: 48 [55104/225000 (24%)] Loss: 20423.730469\n",
      "Train Epoch: 48 [57600/225000 (26%)] Loss: 19905.708984\n",
      "Train Epoch: 48 [60096/225000 (27%)] Loss: 20375.917969\n",
      "Train Epoch: 48 [62592/225000 (28%)] Loss: 19822.437500\n",
      "Train Epoch: 48 [65088/225000 (29%)] Loss: 20408.425781\n",
      "Train Epoch: 48 [67584/225000 (30%)] Loss: 20035.062500\n",
      "Train Epoch: 48 [70080/225000 (31%)] Loss: 20157.632812\n",
      "Train Epoch: 48 [72576/225000 (32%)] Loss: 20457.136719\n",
      "Train Epoch: 48 [75072/225000 (33%)] Loss: 20395.298828\n",
      "Train Epoch: 48 [77568/225000 (34%)] Loss: 19949.289062\n",
      "Train Epoch: 48 [80064/225000 (36%)] Loss: 20583.765625\n",
      "Train Epoch: 48 [82560/225000 (37%)] Loss: 20435.175781\n",
      "Train Epoch: 48 [85056/225000 (38%)] Loss: 20042.898438\n",
      "Train Epoch: 48 [87552/225000 (39%)] Loss: 20303.621094\n",
      "Train Epoch: 48 [90048/225000 (40%)] Loss: 20294.824219\n",
      "Train Epoch: 48 [92544/225000 (41%)] Loss: 20833.066406\n",
      "Train Epoch: 48 [95040/225000 (42%)] Loss: 20255.265625\n",
      "Train Epoch: 48 [97536/225000 (43%)] Loss: 19951.433594\n",
      "Train Epoch: 48 [100032/225000 (44%)] Loss: 20571.882812\n",
      "Train Epoch: 48 [102528/225000 (46%)] Loss: 20181.714844\n",
      "Train Epoch: 48 [105024/225000 (47%)] Loss: 20219.984375\n",
      "Train Epoch: 48 [107520/225000 (48%)] Loss: 20259.195312\n",
      "Train Epoch: 48 [110016/225000 (49%)] Loss: 20286.353516\n",
      "Train Epoch: 48 [112512/225000 (50%)] Loss: 20651.937500\n",
      "Train Epoch: 48 [115008/225000 (51%)] Loss: 20511.523438\n",
      "Train Epoch: 48 [117504/225000 (52%)] Loss: 20110.074219\n",
      "Train Epoch: 48 [120000/225000 (53%)] Loss: 20610.128906\n",
      "Train Epoch: 48 [122496/225000 (54%)] Loss: 20601.011719\n",
      "Train Epoch: 48 [124992/225000 (56%)] Loss: 20406.876953\n",
      "Train Epoch: 48 [127488/225000 (57%)] Loss: 20572.101562\n",
      "Train Epoch: 48 [129984/225000 (58%)] Loss: 19961.953125\n",
      "Train Epoch: 48 [132480/225000 (59%)] Loss: 20620.097656\n",
      "Train Epoch: 48 [134976/225000 (60%)] Loss: 19860.968750\n",
      "Train Epoch: 48 [137472/225000 (61%)] Loss: 19805.113281\n",
      "Train Epoch: 48 [139968/225000 (62%)] Loss: 19948.976562\n",
      "Train Epoch: 48 [142464/225000 (63%)] Loss: 20164.517578\n",
      "Train Epoch: 48 [144960/225000 (64%)] Loss: 20210.166016\n",
      "Train Epoch: 48 [147456/225000 (66%)] Loss: 19879.183594\n",
      "Train Epoch: 48 [149952/225000 (67%)] Loss: 20235.476562\n",
      "Train Epoch: 48 [152448/225000 (68%)] Loss: 20372.460938\n",
      "Train Epoch: 48 [154944/225000 (69%)] Loss: 19774.128906\n",
      "Train Epoch: 48 [157440/225000 (70%)] Loss: 19921.511719\n",
      "Train Epoch: 48 [159936/225000 (71%)] Loss: 20296.841797\n",
      "Train Epoch: 48 [162432/225000 (72%)] Loss: 20605.888672\n",
      "Train Epoch: 48 [164928/225000 (73%)] Loss: 20317.636719\n",
      "Train Epoch: 48 [167424/225000 (74%)] Loss: 20036.871094\n",
      "Train Epoch: 48 [169920/225000 (76%)] Loss: 19808.472656\n",
      "Train Epoch: 48 [172416/225000 (77%)] Loss: 20180.710938\n",
      "Train Epoch: 48 [174912/225000 (78%)] Loss: 19915.644531\n",
      "Train Epoch: 48 [177408/225000 (79%)] Loss: 20162.425781\n",
      "Train Epoch: 48 [179904/225000 (80%)] Loss: 20585.927734\n",
      "Train Epoch: 48 [182400/225000 (81%)] Loss: 20104.242188\n",
      "Train Epoch: 48 [184896/225000 (82%)] Loss: 20003.830078\n",
      "Train Epoch: 48 [187392/225000 (83%)] Loss: 20046.523438\n",
      "Train Epoch: 48 [189888/225000 (84%)] Loss: 20131.531250\n",
      "Train Epoch: 48 [192384/225000 (86%)] Loss: 19812.800781\n",
      "Train Epoch: 48 [194880/225000 (87%)] Loss: 20105.523438\n",
      "Train Epoch: 48 [197376/225000 (88%)] Loss: 20049.648438\n",
      "Train Epoch: 48 [199872/225000 (89%)] Loss: 20139.070312\n",
      "Train Epoch: 48 [202368/225000 (90%)] Loss: 20276.824219\n",
      "Train Epoch: 48 [204864/225000 (91%)] Loss: 19828.402344\n",
      "Train Epoch: 48 [207360/225000 (92%)] Loss: 20544.962891\n",
      "Train Epoch: 48 [209856/225000 (93%)] Loss: 20384.941406\n",
      "Train Epoch: 48 [212352/225000 (94%)] Loss: 20549.894531\n",
      "Train Epoch: 48 [214848/225000 (95%)] Loss: 19847.910156\n",
      "Train Epoch: 48 [217344/225000 (97%)] Loss: 19888.539062\n",
      "Train Epoch: 48 [219840/225000 (98%)] Loss: 20068.742188\n",
      "Train Epoch: 48 [222336/225000 (99%)] Loss: 20068.150391\n",
      "Train Epoch: 48 [224832/225000 (100%)] Loss: 20480.625000\n",
      "    epoch          : 48\n",
      "    loss           : 20246.434455324765\n",
      "    val_loss       : 20154.434922069082\n",
      "Train Epoch: 49 [192/225000 (0%)] Loss: 20368.769531\n",
      "Train Epoch: 49 [2688/225000 (1%)] Loss: 20840.281250\n",
      "Train Epoch: 49 [5184/225000 (2%)] Loss: 20344.339844\n",
      "Train Epoch: 49 [7680/225000 (3%)] Loss: 20201.669922\n",
      "Train Epoch: 49 [10176/225000 (5%)] Loss: 20662.750000\n",
      "Train Epoch: 49 [12672/225000 (6%)] Loss: 20477.183594\n",
      "Train Epoch: 49 [15168/225000 (7%)] Loss: 20582.314453\n",
      "Train Epoch: 49 [17664/225000 (8%)] Loss: 20058.007812\n",
      "Train Epoch: 49 [20160/225000 (9%)] Loss: 20103.208984\n",
      "Train Epoch: 49 [22656/225000 (10%)] Loss: 20261.199219\n",
      "Train Epoch: 49 [25152/225000 (11%)] Loss: 19783.363281\n",
      "Train Epoch: 49 [27648/225000 (12%)] Loss: 20439.062500\n",
      "Train Epoch: 49 [30144/225000 (13%)] Loss: 20392.265625\n",
      "Train Epoch: 49 [32640/225000 (15%)] Loss: 19987.820312\n",
      "Train Epoch: 49 [35136/225000 (16%)] Loss: 19502.417969\n",
      "Train Epoch: 49 [37632/225000 (17%)] Loss: 20146.769531\n",
      "Train Epoch: 49 [40128/225000 (18%)] Loss: 19804.312500\n",
      "Train Epoch: 49 [42624/225000 (19%)] Loss: 20085.710938\n",
      "Train Epoch: 49 [45120/225000 (20%)] Loss: 19949.824219\n",
      "Train Epoch: 49 [47616/225000 (21%)] Loss: 19781.767578\n",
      "Train Epoch: 49 [50112/225000 (22%)] Loss: 20228.484375\n",
      "Train Epoch: 49 [52608/225000 (23%)] Loss: 20029.179688\n",
      "Train Epoch: 49 [55104/225000 (24%)] Loss: 20400.207031\n",
      "Train Epoch: 49 [57600/225000 (26%)] Loss: 20537.322266\n",
      "Train Epoch: 49 [60096/225000 (27%)] Loss: 20233.484375\n",
      "Train Epoch: 49 [62592/225000 (28%)] Loss: 20018.742188\n",
      "Train Epoch: 49 [65088/225000 (29%)] Loss: 20377.224609\n",
      "Train Epoch: 49 [67584/225000 (30%)] Loss: 20212.451172\n",
      "Train Epoch: 49 [70080/225000 (31%)] Loss: 20521.468750\n",
      "Train Epoch: 49 [72576/225000 (32%)] Loss: 20301.847656\n",
      "Train Epoch: 49 [75072/225000 (33%)] Loss: 20293.210938\n",
      "Train Epoch: 49 [77568/225000 (34%)] Loss: 20279.789062\n",
      "Train Epoch: 49 [80064/225000 (36%)] Loss: 20051.523438\n",
      "Train Epoch: 49 [82560/225000 (37%)] Loss: 20358.375000\n",
      "Train Epoch: 49 [85056/225000 (38%)] Loss: 20127.687500\n",
      "Train Epoch: 49 [87552/225000 (39%)] Loss: 20342.544922\n",
      "Train Epoch: 49 [90048/225000 (40%)] Loss: 20349.746094\n",
      "Train Epoch: 49 [92544/225000 (41%)] Loss: 20281.361328\n",
      "Train Epoch: 49 [95040/225000 (42%)] Loss: 20645.783203\n",
      "Train Epoch: 49 [97536/225000 (43%)] Loss: 20632.464844\n",
      "Train Epoch: 49 [100032/225000 (44%)] Loss: 20045.587891\n",
      "Train Epoch: 49 [102528/225000 (46%)] Loss: 20387.554688\n",
      "Train Epoch: 49 [105024/225000 (47%)] Loss: 20046.314453\n",
      "Train Epoch: 49 [107520/225000 (48%)] Loss: 20352.238281\n",
      "Train Epoch: 49 [110016/225000 (49%)] Loss: 20728.074219\n",
      "Train Epoch: 49 [112512/225000 (50%)] Loss: 20222.261719\n",
      "Train Epoch: 49 [115008/225000 (51%)] Loss: 21011.435547\n",
      "Train Epoch: 49 [117504/225000 (52%)] Loss: 20346.066406\n",
      "Train Epoch: 49 [120000/225000 (53%)] Loss: 20138.599609\n",
      "Train Epoch: 49 [122496/225000 (54%)] Loss: 20197.849609\n",
      "Train Epoch: 49 [124992/225000 (56%)] Loss: 20433.333984\n",
      "Train Epoch: 49 [127488/225000 (57%)] Loss: 19811.710938\n",
      "Train Epoch: 49 [129984/225000 (58%)] Loss: 19922.656250\n",
      "Train Epoch: 49 [132480/225000 (59%)] Loss: 20033.812500\n",
      "Train Epoch: 49 [134976/225000 (60%)] Loss: 20840.144531\n",
      "Train Epoch: 49 [137472/225000 (61%)] Loss: 20188.937500\n",
      "Train Epoch: 49 [139968/225000 (62%)] Loss: 20085.515625\n",
      "Train Epoch: 49 [142464/225000 (63%)] Loss: 20334.414062\n",
      "Train Epoch: 49 [144960/225000 (64%)] Loss: 20619.085938\n",
      "Train Epoch: 49 [147456/225000 (66%)] Loss: 20575.068359\n",
      "Train Epoch: 49 [149952/225000 (67%)] Loss: 20317.164062\n",
      "Train Epoch: 49 [152448/225000 (68%)] Loss: 20323.839844\n",
      "Train Epoch: 49 [154944/225000 (69%)] Loss: 20179.316406\n",
      "Train Epoch: 49 [157440/225000 (70%)] Loss: 20242.621094\n",
      "Train Epoch: 49 [159936/225000 (71%)] Loss: 20201.208984\n",
      "Train Epoch: 49 [162432/225000 (72%)] Loss: 20073.464844\n",
      "Train Epoch: 49 [164928/225000 (73%)] Loss: 20000.722656\n",
      "Train Epoch: 49 [167424/225000 (74%)] Loss: 20070.882812\n",
      "Train Epoch: 49 [169920/225000 (76%)] Loss: 19983.636719\n",
      "Train Epoch: 49 [172416/225000 (77%)] Loss: 19929.679688\n",
      "Train Epoch: 49 [174912/225000 (78%)] Loss: 20487.474609\n",
      "Train Epoch: 49 [177408/225000 (79%)] Loss: 20367.953125\n",
      "Train Epoch: 49 [179904/225000 (80%)] Loss: 19903.556641\n",
      "Train Epoch: 49 [182400/225000 (81%)] Loss: 20201.757812\n",
      "Train Epoch: 49 [184896/225000 (82%)] Loss: 20050.666016\n",
      "Train Epoch: 49 [187392/225000 (83%)] Loss: 20247.658203\n",
      "Train Epoch: 49 [189888/225000 (84%)] Loss: 20368.677734\n",
      "Train Epoch: 49 [192384/225000 (86%)] Loss: 19918.617188\n",
      "Train Epoch: 49 [194880/225000 (87%)] Loss: 20344.824219\n",
      "Train Epoch: 49 [197376/225000 (88%)] Loss: 20300.343750\n",
      "Train Epoch: 49 [199872/225000 (89%)] Loss: 20270.816406\n",
      "Train Epoch: 49 [202368/225000 (90%)] Loss: 20273.441406\n",
      "Train Epoch: 49 [204864/225000 (91%)] Loss: 19843.527344\n",
      "Train Epoch: 49 [207360/225000 (92%)] Loss: 19774.869141\n",
      "Train Epoch: 49 [209856/225000 (93%)] Loss: 20111.191406\n",
      "Train Epoch: 49 [212352/225000 (94%)] Loss: 20401.335938\n",
      "Train Epoch: 49 [214848/225000 (95%)] Loss: 20953.480469\n",
      "Train Epoch: 49 [217344/225000 (97%)] Loss: 20184.003906\n",
      "Train Epoch: 49 [219840/225000 (98%)] Loss: 20205.449219\n",
      "Train Epoch: 49 [222336/225000 (99%)] Loss: 20618.521484\n",
      "Train Epoch: 49 [224832/225000 (100%)] Loss: 19926.875000\n",
      "    epoch          : 49\n",
      "    loss           : 20256.16214103829\n",
      "    val_loss       : 20143.5452929262\n",
      "Train Epoch: 50 [192/225000 (0%)] Loss: 20380.937500\n",
      "Train Epoch: 50 [2688/225000 (1%)] Loss: 20037.605469\n",
      "Train Epoch: 50 [5184/225000 (2%)] Loss: 20386.078125\n",
      "Train Epoch: 50 [7680/225000 (3%)] Loss: 20387.449219\n",
      "Train Epoch: 50 [10176/225000 (5%)] Loss: 20129.746094\n",
      "Train Epoch: 50 [12672/225000 (6%)] Loss: 20591.218750\n",
      "Train Epoch: 50 [15168/225000 (7%)] Loss: 20073.800781\n",
      "Train Epoch: 50 [17664/225000 (8%)] Loss: 20328.492188\n",
      "Train Epoch: 50 [20160/225000 (9%)] Loss: 20414.951172\n",
      "Train Epoch: 50 [22656/225000 (10%)] Loss: 20307.449219\n",
      "Train Epoch: 50 [25152/225000 (11%)] Loss: 20413.589844\n",
      "Train Epoch: 50 [27648/225000 (12%)] Loss: 19972.765625\n",
      "Train Epoch: 50 [30144/225000 (13%)] Loss: 20195.382812\n",
      "Train Epoch: 50 [32640/225000 (15%)] Loss: 20070.179688\n",
      "Train Epoch: 50 [35136/225000 (16%)] Loss: 19988.015625\n",
      "Train Epoch: 50 [37632/225000 (17%)] Loss: 20372.345703\n",
      "Train Epoch: 50 [40128/225000 (18%)] Loss: 20445.603516\n",
      "Train Epoch: 50 [42624/225000 (19%)] Loss: 20574.917969\n",
      "Train Epoch: 50 [45120/225000 (20%)] Loss: 20081.542969\n",
      "Train Epoch: 50 [47616/225000 (21%)] Loss: 19703.679688\n",
      "Train Epoch: 50 [50112/225000 (22%)] Loss: 20844.962891\n",
      "Train Epoch: 50 [52608/225000 (23%)] Loss: 20513.023438\n",
      "Train Epoch: 50 [55104/225000 (24%)] Loss: 20588.523438\n",
      "Train Epoch: 50 [57600/225000 (26%)] Loss: 19559.183594\n",
      "Train Epoch: 50 [60096/225000 (27%)] Loss: 20521.988281\n",
      "Train Epoch: 50 [62592/225000 (28%)] Loss: 20103.707031\n",
      "Train Epoch: 50 [65088/225000 (29%)] Loss: 20103.007812\n",
      "Train Epoch: 50 [67584/225000 (30%)] Loss: 20048.804688\n",
      "Train Epoch: 50 [70080/225000 (31%)] Loss: 20121.177734\n",
      "Train Epoch: 50 [72576/225000 (32%)] Loss: 19944.355469\n",
      "Train Epoch: 50 [75072/225000 (33%)] Loss: 19766.480469\n",
      "Train Epoch: 50 [77568/225000 (34%)] Loss: 20191.847656\n",
      "Train Epoch: 50 [80064/225000 (36%)] Loss: 20357.724609\n",
      "Train Epoch: 50 [82560/225000 (37%)] Loss: 20912.898438\n",
      "Train Epoch: 50 [85056/225000 (38%)] Loss: 20755.386719\n",
      "Train Epoch: 50 [87552/225000 (39%)] Loss: 20489.644531\n",
      "Train Epoch: 50 [90048/225000 (40%)] Loss: 20480.242188\n",
      "Train Epoch: 50 [92544/225000 (41%)] Loss: 19788.007812\n",
      "Train Epoch: 50 [95040/225000 (42%)] Loss: 19845.113281\n",
      "Train Epoch: 50 [97536/225000 (43%)] Loss: 19898.949219\n",
      "Train Epoch: 50 [100032/225000 (44%)] Loss: 20200.330078\n",
      "Train Epoch: 50 [102528/225000 (46%)] Loss: 20114.005859\n",
      "Train Epoch: 50 [105024/225000 (47%)] Loss: 19894.138672\n",
      "Train Epoch: 50 [107520/225000 (48%)] Loss: 20261.777344\n",
      "Train Epoch: 50 [110016/225000 (49%)] Loss: 20578.552734\n",
      "Train Epoch: 50 [112512/225000 (50%)] Loss: 20103.324219\n",
      "Train Epoch: 50 [115008/225000 (51%)] Loss: 20828.107422\n",
      "Train Epoch: 50 [117504/225000 (52%)] Loss: 19921.646484\n",
      "Train Epoch: 50 [120000/225000 (53%)] Loss: 19974.710938\n",
      "Train Epoch: 50 [122496/225000 (54%)] Loss: 20338.773438\n",
      "Train Epoch: 50 [124992/225000 (56%)] Loss: 20127.826172\n",
      "Train Epoch: 50 [127488/225000 (57%)] Loss: 20343.355469\n",
      "Train Epoch: 50 [129984/225000 (58%)] Loss: 20158.023438\n",
      "Train Epoch: 50 [132480/225000 (59%)] Loss: 19767.496094\n",
      "Train Epoch: 50 [134976/225000 (60%)] Loss: 19912.677734\n",
      "Train Epoch: 50 [137472/225000 (61%)] Loss: 20275.792969\n",
      "Train Epoch: 50 [139968/225000 (62%)] Loss: 20737.566406\n",
      "Train Epoch: 50 [142464/225000 (63%)] Loss: 20240.023438\n",
      "Train Epoch: 50 [144960/225000 (64%)] Loss: 20155.255859\n",
      "Train Epoch: 50 [147456/225000 (66%)] Loss: 19503.591797\n",
      "Train Epoch: 50 [149952/225000 (67%)] Loss: 20280.455078\n",
      "Train Epoch: 50 [152448/225000 (68%)] Loss: 20432.113281\n",
      "Train Epoch: 50 [154944/225000 (69%)] Loss: 19827.277344\n",
      "Train Epoch: 50 [157440/225000 (70%)] Loss: 19916.337891\n",
      "Train Epoch: 50 [159936/225000 (71%)] Loss: 19819.328125\n",
      "Train Epoch: 50 [162432/225000 (72%)] Loss: 20191.494141\n",
      "Train Epoch: 50 [164928/225000 (73%)] Loss: 19950.421875\n",
      "Train Epoch: 50 [167424/225000 (74%)] Loss: 20448.855469\n",
      "Train Epoch: 50 [169920/225000 (76%)] Loss: 20347.328125\n",
      "Train Epoch: 50 [172416/225000 (77%)] Loss: 20201.091797\n",
      "Train Epoch: 50 [174912/225000 (78%)] Loss: 20323.164062\n",
      "Train Epoch: 50 [177408/225000 (79%)] Loss: 19903.955078\n",
      "Train Epoch: 50 [179904/225000 (80%)] Loss: 20201.642578\n",
      "Train Epoch: 50 [182400/225000 (81%)] Loss: 20460.570312\n",
      "Train Epoch: 50 [184896/225000 (82%)] Loss: 20474.501953\n",
      "Train Epoch: 50 [187392/225000 (83%)] Loss: 20228.046875\n",
      "Train Epoch: 50 [189888/225000 (84%)] Loss: 20807.898438\n",
      "Train Epoch: 50 [192384/225000 (86%)] Loss: 19874.027344\n",
      "Train Epoch: 50 [194880/225000 (87%)] Loss: 20319.558594\n",
      "Train Epoch: 50 [197376/225000 (88%)] Loss: 19786.677734\n",
      "Train Epoch: 50 [199872/225000 (89%)] Loss: 20169.152344\n",
      "Train Epoch: 50 [202368/225000 (90%)] Loss: 20524.343750\n",
      "Train Epoch: 50 [204864/225000 (91%)] Loss: 20504.984375\n",
      "Train Epoch: 50 [207360/225000 (92%)] Loss: 19892.005859\n",
      "Train Epoch: 50 [209856/225000 (93%)] Loss: 20139.855469\n",
      "Train Epoch: 50 [212352/225000 (94%)] Loss: 20145.265625\n",
      "Train Epoch: 50 [214848/225000 (95%)] Loss: 19964.808594\n",
      "Train Epoch: 50 [217344/225000 (97%)] Loss: 20041.277344\n",
      "Train Epoch: 50 [219840/225000 (98%)] Loss: 20078.800781\n",
      "Train Epoch: 50 [222336/225000 (99%)] Loss: 20480.382812\n",
      "Train Epoch: 50 [224832/225000 (100%)] Loss: 20215.558594\n",
      "    epoch          : 50\n",
      "    loss           : 20254.083579418195\n",
      "    val_loss       : 20129.925958857282\n",
      "Saving checkpoint: saved/models/Molecular_VaeCategory/0803_124018/checkpoint-epoch50.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 51 [192/225000 (0%)] Loss: 20347.597656\n",
      "Train Epoch: 51 [2688/225000 (1%)] Loss: 20063.138672\n",
      "Train Epoch: 51 [5184/225000 (2%)] Loss: 20235.945312\n",
      "Train Epoch: 51 [7680/225000 (3%)] Loss: 19951.753906\n",
      "Train Epoch: 51 [10176/225000 (5%)] Loss: 20156.773438\n",
      "Train Epoch: 51 [12672/225000 (6%)] Loss: 20180.980469\n",
      "Train Epoch: 51 [15168/225000 (7%)] Loss: 20418.058594\n",
      "Train Epoch: 51 [17664/225000 (8%)] Loss: 19651.722656\n",
      "Train Epoch: 51 [20160/225000 (9%)] Loss: 20086.281250\n",
      "Train Epoch: 51 [22656/225000 (10%)] Loss: 20030.152344\n",
      "Train Epoch: 51 [25152/225000 (11%)] Loss: 20397.287109\n",
      "Train Epoch: 51 [27648/225000 (12%)] Loss: 20969.035156\n",
      "Train Epoch: 51 [30144/225000 (13%)] Loss: 20599.437500\n",
      "Train Epoch: 51 [32640/225000 (15%)] Loss: 19930.625000\n",
      "Train Epoch: 51 [35136/225000 (16%)] Loss: 19738.427734\n",
      "Train Epoch: 51 [37632/225000 (17%)] Loss: 20063.667969\n",
      "Train Epoch: 51 [40128/225000 (18%)] Loss: 19933.324219\n",
      "Train Epoch: 51 [42624/225000 (19%)] Loss: 20033.933594\n",
      "Train Epoch: 51 [45120/225000 (20%)] Loss: 20342.992188\n",
      "Train Epoch: 51 [47616/225000 (21%)] Loss: 20182.470703\n",
      "Train Epoch: 51 [50112/225000 (22%)] Loss: 20112.572266\n",
      "Train Epoch: 51 [52608/225000 (23%)] Loss: 20160.294922\n",
      "Train Epoch: 51 [55104/225000 (24%)] Loss: 20400.378906\n",
      "Train Epoch: 51 [57600/225000 (26%)] Loss: 19804.386719\n",
      "Train Epoch: 51 [60096/225000 (27%)] Loss: 20283.574219\n",
      "Train Epoch: 51 [62592/225000 (28%)] Loss: 20017.312500\n",
      "Train Epoch: 51 [65088/225000 (29%)] Loss: 20204.060547\n",
      "Train Epoch: 51 [67584/225000 (30%)] Loss: 20773.156250\n",
      "Train Epoch: 51 [70080/225000 (31%)] Loss: 19880.574219\n",
      "Train Epoch: 51 [72576/225000 (32%)] Loss: 19908.435547\n",
      "Train Epoch: 51 [75072/225000 (33%)] Loss: 20049.816406\n",
      "Train Epoch: 51 [77568/225000 (34%)] Loss: 20517.468750\n",
      "Train Epoch: 51 [80064/225000 (36%)] Loss: 20001.341797\n",
      "Train Epoch: 51 [82560/225000 (37%)] Loss: 20462.398438\n",
      "Train Epoch: 51 [85056/225000 (38%)] Loss: 20368.449219\n",
      "Train Epoch: 51 [87552/225000 (39%)] Loss: 20182.919922\n",
      "Train Epoch: 51 [90048/225000 (40%)] Loss: 19571.152344\n",
      "Train Epoch: 51 [92544/225000 (41%)] Loss: 20371.148438\n",
      "Train Epoch: 51 [95040/225000 (42%)] Loss: 20422.992188\n",
      "Train Epoch: 51 [97536/225000 (43%)] Loss: 20180.234375\n",
      "Train Epoch: 51 [100032/225000 (44%)] Loss: 20464.507812\n",
      "Train Epoch: 51 [102528/225000 (46%)] Loss: 20422.484375\n",
      "Train Epoch: 51 [105024/225000 (47%)] Loss: 20112.894531\n",
      "Train Epoch: 51 [107520/225000 (48%)] Loss: 20264.851562\n",
      "Train Epoch: 51 [110016/225000 (49%)] Loss: 19970.710938\n",
      "Train Epoch: 51 [112512/225000 (50%)] Loss: 19770.730469\n",
      "Train Epoch: 51 [115008/225000 (51%)] Loss: 20290.574219\n",
      "Train Epoch: 51 [117504/225000 (52%)] Loss: 20132.660156\n",
      "Train Epoch: 51 [120000/225000 (53%)] Loss: 20346.136719\n",
      "Train Epoch: 51 [122496/225000 (54%)] Loss: 20301.613281\n",
      "Train Epoch: 51 [124992/225000 (56%)] Loss: 20279.269531\n",
      "Train Epoch: 51 [127488/225000 (57%)] Loss: 20052.277344\n",
      "Train Epoch: 51 [129984/225000 (58%)] Loss: 20030.255859\n",
      "Train Epoch: 51 [132480/225000 (59%)] Loss: 20534.773438\n",
      "Train Epoch: 51 [134976/225000 (60%)] Loss: 20271.021484\n",
      "Train Epoch: 51 [137472/225000 (61%)] Loss: 20773.136719\n",
      "Train Epoch: 51 [139968/225000 (62%)] Loss: 20193.867188\n",
      "Train Epoch: 51 [142464/225000 (63%)] Loss: 20429.527344\n",
      "Train Epoch: 51 [144960/225000 (64%)] Loss: 20262.867188\n",
      "Train Epoch: 51 [147456/225000 (66%)] Loss: 20040.101562\n",
      "Train Epoch: 51 [149952/225000 (67%)] Loss: 20314.574219\n",
      "Train Epoch: 51 [152448/225000 (68%)] Loss: 20459.191406\n",
      "Train Epoch: 51 [154944/225000 (69%)] Loss: 20891.392578\n",
      "Train Epoch: 51 [157440/225000 (70%)] Loss: 20203.074219\n",
      "Train Epoch: 51 [159936/225000 (71%)] Loss: 20189.111328\n",
      "Train Epoch: 51 [162432/225000 (72%)] Loss: 20297.826172\n",
      "Train Epoch: 51 [164928/225000 (73%)] Loss: 19871.119141\n",
      "Train Epoch: 51 [167424/225000 (74%)] Loss: 20185.738281\n",
      "Train Epoch: 51 [169920/225000 (76%)] Loss: 20243.341797\n",
      "Train Epoch: 51 [172416/225000 (77%)] Loss: 20220.568359\n",
      "Train Epoch: 51 [174912/225000 (78%)] Loss: 20259.410156\n",
      "Train Epoch: 51 [177408/225000 (79%)] Loss: 20082.740234\n",
      "Train Epoch: 51 [179904/225000 (80%)] Loss: 20084.304688\n",
      "Train Epoch: 51 [182400/225000 (81%)] Loss: 20512.542969\n",
      "Train Epoch: 51 [184896/225000 (82%)] Loss: 20468.500000\n",
      "Train Epoch: 51 [187392/225000 (83%)] Loss: 19858.285156\n",
      "Train Epoch: 51 [189888/225000 (84%)] Loss: 20284.746094\n",
      "Train Epoch: 51 [192384/225000 (86%)] Loss: 20348.748047\n",
      "Train Epoch: 51 [194880/225000 (87%)] Loss: 19874.091797\n",
      "Train Epoch: 51 [197376/225000 (88%)] Loss: 20801.244141\n",
      "Train Epoch: 51 [199872/225000 (89%)] Loss: 20124.263672\n",
      "Train Epoch: 51 [202368/225000 (90%)] Loss: 19853.476562\n",
      "Train Epoch: 51 [204864/225000 (91%)] Loss: 20597.128906\n",
      "Train Epoch: 51 [207360/225000 (92%)] Loss: 20151.263672\n",
      "Train Epoch: 51 [209856/225000 (93%)] Loss: 20568.046875\n",
      "Train Epoch: 51 [212352/225000 (94%)] Loss: 20192.027344\n",
      "Train Epoch: 51 [214848/225000 (95%)] Loss: 20166.355469\n",
      "Train Epoch: 51 [217344/225000 (97%)] Loss: 20743.134766\n",
      "Train Epoch: 51 [219840/225000 (98%)] Loss: 20212.478516\n",
      "Train Epoch: 51 [222336/225000 (99%)] Loss: 19787.089844\n",
      "Train Epoch: 51 [224832/225000 (100%)] Loss: 20204.554688\n",
      "    epoch          : 51\n",
      "    loss           : 20247.78973409503\n",
      "    val_loss       : 20113.9083173457\n",
      "Train Epoch: 52 [192/225000 (0%)] Loss: 19893.181641\n",
      "Train Epoch: 52 [2688/225000 (1%)] Loss: 19746.097656\n",
      "Train Epoch: 52 [5184/225000 (2%)] Loss: 20147.558594\n",
      "Train Epoch: 52 [7680/225000 (3%)] Loss: 20268.755859\n",
      "Train Epoch: 52 [10176/225000 (5%)] Loss: 20461.769531\n",
      "Train Epoch: 52 [12672/225000 (6%)] Loss: 20268.023438\n",
      "Train Epoch: 52 [15168/225000 (7%)] Loss: 20228.222656\n",
      "Train Epoch: 52 [17664/225000 (8%)] Loss: 20103.757812\n",
      "Train Epoch: 52 [20160/225000 (9%)] Loss: 20230.312500\n",
      "Train Epoch: 52 [22656/225000 (10%)] Loss: 20699.263672\n",
      "Train Epoch: 52 [25152/225000 (11%)] Loss: 20338.859375\n",
      "Train Epoch: 52 [27648/225000 (12%)] Loss: 20487.976562\n",
      "Train Epoch: 52 [30144/225000 (13%)] Loss: 20437.541016\n",
      "Train Epoch: 52 [32640/225000 (15%)] Loss: 19764.984375\n",
      "Train Epoch: 52 [35136/225000 (16%)] Loss: 20502.546875\n",
      "Train Epoch: 52 [37632/225000 (17%)] Loss: 20293.593750\n",
      "Train Epoch: 52 [40128/225000 (18%)] Loss: 19974.800781\n",
      "Train Epoch: 52 [42624/225000 (19%)] Loss: 20375.660156\n",
      "Train Epoch: 52 [45120/225000 (20%)] Loss: 20068.687500\n",
      "Train Epoch: 52 [47616/225000 (21%)] Loss: 20183.757812\n",
      "Train Epoch: 52 [50112/225000 (22%)] Loss: 20473.214844\n",
      "Train Epoch: 52 [52608/225000 (23%)] Loss: 20581.464844\n",
      "Train Epoch: 52 [55104/225000 (24%)] Loss: 20055.619141\n",
      "Train Epoch: 52 [57600/225000 (26%)] Loss: 20349.441406\n",
      "Train Epoch: 52 [60096/225000 (27%)] Loss: 19978.394531\n",
      "Train Epoch: 52 [62592/225000 (28%)] Loss: 20226.285156\n",
      "Train Epoch: 52 [65088/225000 (29%)] Loss: 20377.615234\n",
      "Train Epoch: 52 [67584/225000 (30%)] Loss: 20190.078125\n",
      "Train Epoch: 52 [70080/225000 (31%)] Loss: 20164.220703\n",
      "Train Epoch: 52 [72576/225000 (32%)] Loss: 20802.929688\n",
      "Train Epoch: 52 [75072/225000 (33%)] Loss: 20143.951172\n",
      "Train Epoch: 52 [77568/225000 (34%)] Loss: 20298.902344\n",
      "Train Epoch: 52 [80064/225000 (36%)] Loss: 20201.156250\n",
      "Train Epoch: 52 [82560/225000 (37%)] Loss: 20274.621094\n",
      "Train Epoch: 52 [85056/225000 (38%)] Loss: 19991.570312\n",
      "Train Epoch: 52 [87552/225000 (39%)] Loss: 20135.183594\n",
      "Train Epoch: 52 [90048/225000 (40%)] Loss: 20571.144531\n",
      "Train Epoch: 52 [92544/225000 (41%)] Loss: 20638.925781\n",
      "Train Epoch: 52 [95040/225000 (42%)] Loss: 19922.570312\n",
      "Train Epoch: 52 [97536/225000 (43%)] Loss: 20329.371094\n",
      "Train Epoch: 52 [100032/225000 (44%)] Loss: 20200.457031\n",
      "Train Epoch: 52 [102528/225000 (46%)] Loss: 20232.009766\n",
      "Train Epoch: 52 [105024/225000 (47%)] Loss: 19971.802734\n",
      "Train Epoch: 52 [107520/225000 (48%)] Loss: 20025.083984\n",
      "Train Epoch: 52 [110016/225000 (49%)] Loss: 20400.845703\n",
      "Train Epoch: 52 [112512/225000 (50%)] Loss: 20143.990234\n",
      "Train Epoch: 52 [115008/225000 (51%)] Loss: 19935.261719\n",
      "Train Epoch: 52 [117504/225000 (52%)] Loss: 20204.781250\n",
      "Train Epoch: 52 [120000/225000 (53%)] Loss: 19948.539062\n",
      "Train Epoch: 52 [122496/225000 (54%)] Loss: 20069.556641\n",
      "Train Epoch: 52 [124992/225000 (56%)] Loss: 20761.955078\n",
      "Train Epoch: 52 [127488/225000 (57%)] Loss: 19947.017578\n",
      "Train Epoch: 52 [129984/225000 (58%)] Loss: 19827.814453\n",
      "Train Epoch: 52 [132480/225000 (59%)] Loss: 19996.404297\n",
      "Train Epoch: 52 [134976/225000 (60%)] Loss: 20148.183594\n",
      "Train Epoch: 52 [137472/225000 (61%)] Loss: 20260.146484\n",
      "Train Epoch: 52 [139968/225000 (62%)] Loss: 20380.265625\n",
      "Train Epoch: 52 [142464/225000 (63%)] Loss: 20362.121094\n",
      "Train Epoch: 52 [144960/225000 (64%)] Loss: 20273.623047\n",
      "Train Epoch: 52 [147456/225000 (66%)] Loss: 20501.457031\n",
      "Train Epoch: 52 [149952/225000 (67%)] Loss: 20095.060547\n",
      "Train Epoch: 52 [152448/225000 (68%)] Loss: 20188.273438\n",
      "Train Epoch: 52 [154944/225000 (69%)] Loss: 20349.876953\n",
      "Train Epoch: 52 [157440/225000 (70%)] Loss: 19820.894531\n",
      "Train Epoch: 52 [159936/225000 (71%)] Loss: 20302.937500\n",
      "Train Epoch: 52 [162432/225000 (72%)] Loss: 19978.992188\n",
      "Train Epoch: 52 [164928/225000 (73%)] Loss: 20112.412109\n",
      "Train Epoch: 52 [167424/225000 (74%)] Loss: 20319.253906\n",
      "Train Epoch: 52 [169920/225000 (76%)] Loss: 19704.937500\n",
      "Train Epoch: 52 [172416/225000 (77%)] Loss: 20015.412109\n",
      "Train Epoch: 52 [174912/225000 (78%)] Loss: 20230.980469\n",
      "Train Epoch: 52 [177408/225000 (79%)] Loss: 20007.689453\n",
      "Train Epoch: 52 [179904/225000 (80%)] Loss: 19730.462891\n",
      "Train Epoch: 52 [182400/225000 (81%)] Loss: 20319.644531\n",
      "Train Epoch: 52 [184896/225000 (82%)] Loss: 20268.576172\n",
      "Train Epoch: 52 [187392/225000 (83%)] Loss: 20010.080078\n",
      "Train Epoch: 52 [189888/225000 (84%)] Loss: 19964.363281\n",
      "Train Epoch: 52 [192384/225000 (86%)] Loss: 20161.832031\n",
      "Train Epoch: 52 [194880/225000 (87%)] Loss: 20099.210938\n",
      "Train Epoch: 52 [197376/225000 (88%)] Loss: 20295.429688\n",
      "Train Epoch: 52 [199872/225000 (89%)] Loss: 20444.453125\n",
      "Train Epoch: 52 [202368/225000 (90%)] Loss: 20490.281250\n",
      "Train Epoch: 52 [204864/225000 (91%)] Loss: 20407.380859\n",
      "Train Epoch: 52 [207360/225000 (92%)] Loss: 20147.121094\n",
      "Train Epoch: 52 [209856/225000 (93%)] Loss: 19978.796875\n",
      "Train Epoch: 52 [212352/225000 (94%)] Loss: 36379.832031\n",
      "Train Epoch: 52 [214848/225000 (95%)] Loss: 20431.746094\n",
      "Train Epoch: 52 [217344/225000 (97%)] Loss: 20156.992188\n",
      "Train Epoch: 52 [219840/225000 (98%)] Loss: 20352.429688\n",
      "Train Epoch: 52 [222336/225000 (99%)] Loss: 20446.890625\n",
      "Train Epoch: 52 [224832/225000 (100%)] Loss: 20507.429688\n",
      "    epoch          : 52\n",
      "    loss           : 20218.487061380118\n",
      "    val_loss       : 20089.621385434657\n",
      "Train Epoch: 53 [192/225000 (0%)] Loss: 19869.246094\n",
      "Train Epoch: 53 [2688/225000 (1%)] Loss: 19829.312500\n",
      "Train Epoch: 53 [5184/225000 (2%)] Loss: 19985.753906\n",
      "Train Epoch: 53 [7680/225000 (3%)] Loss: 20148.125000\n",
      "Train Epoch: 53 [10176/225000 (5%)] Loss: 20410.035156\n",
      "Train Epoch: 53 [12672/225000 (6%)] Loss: 20323.917969\n",
      "Train Epoch: 53 [15168/225000 (7%)] Loss: 20167.546875\n",
      "Train Epoch: 53 [17664/225000 (8%)] Loss: 20456.355469\n",
      "Train Epoch: 53 [20160/225000 (9%)] Loss: 20475.535156\n",
      "Train Epoch: 53 [22656/225000 (10%)] Loss: 20078.906250\n",
      "Train Epoch: 53 [25152/225000 (11%)] Loss: 20588.242188\n",
      "Train Epoch: 53 [27648/225000 (12%)] Loss: 20294.425781\n",
      "Train Epoch: 53 [30144/225000 (13%)] Loss: 20482.214844\n",
      "Train Epoch: 53 [32640/225000 (15%)] Loss: 20292.824219\n",
      "Train Epoch: 53 [35136/225000 (16%)] Loss: 20254.142578\n",
      "Train Epoch: 53 [37632/225000 (17%)] Loss: 20178.074219\n",
      "Train Epoch: 53 [40128/225000 (18%)] Loss: 19974.218750\n",
      "Train Epoch: 53 [42624/225000 (19%)] Loss: 20140.115234\n",
      "Train Epoch: 53 [45120/225000 (20%)] Loss: 20316.886719\n",
      "Train Epoch: 53 [47616/225000 (21%)] Loss: 20230.910156\n",
      "Train Epoch: 53 [50112/225000 (22%)] Loss: 20153.412109\n",
      "Train Epoch: 53 [52608/225000 (23%)] Loss: 20354.447266\n",
      "Train Epoch: 53 [55104/225000 (24%)] Loss: 20259.582031\n",
      "Train Epoch: 53 [57600/225000 (26%)] Loss: 20462.902344\n",
      "Train Epoch: 53 [60096/225000 (27%)] Loss: 20332.310547\n",
      "Train Epoch: 53 [62592/225000 (28%)] Loss: 20116.832031\n",
      "Train Epoch: 53 [65088/225000 (29%)] Loss: 19921.328125\n",
      "Train Epoch: 53 [67584/225000 (30%)] Loss: 20279.009766\n",
      "Train Epoch: 53 [70080/225000 (31%)] Loss: 20343.697266\n",
      "Train Epoch: 53 [72576/225000 (32%)] Loss: 20515.710938\n",
      "Train Epoch: 53 [75072/225000 (33%)] Loss: 20113.015625\n",
      "Train Epoch: 53 [77568/225000 (34%)] Loss: 19938.722656\n",
      "Train Epoch: 53 [80064/225000 (36%)] Loss: 20126.878906\n",
      "Train Epoch: 53 [82560/225000 (37%)] Loss: 20251.777344\n",
      "Train Epoch: 53 [85056/225000 (38%)] Loss: 20462.089844\n",
      "Train Epoch: 53 [87552/225000 (39%)] Loss: 20036.183594\n",
      "Train Epoch: 53 [90048/225000 (40%)] Loss: 20167.267578\n",
      "Train Epoch: 53 [92544/225000 (41%)] Loss: 20045.093750\n",
      "Train Epoch: 53 [95040/225000 (42%)] Loss: 20945.265625\n",
      "Train Epoch: 53 [97536/225000 (43%)] Loss: 19952.714844\n",
      "Train Epoch: 53 [100032/225000 (44%)] Loss: 20314.074219\n",
      "Train Epoch: 53 [102528/225000 (46%)] Loss: 19783.238281\n",
      "Train Epoch: 53 [105024/225000 (47%)] Loss: 19845.132812\n",
      "Train Epoch: 53 [107520/225000 (48%)] Loss: 20116.498047\n",
      "Train Epoch: 53 [110016/225000 (49%)] Loss: 20055.390625\n",
      "Train Epoch: 53 [112512/225000 (50%)] Loss: 20076.464844\n",
      "Train Epoch: 53 [115008/225000 (51%)] Loss: 19828.742188\n",
      "Train Epoch: 53 [117504/225000 (52%)] Loss: 20771.931641\n",
      "Train Epoch: 53 [120000/225000 (53%)] Loss: 19994.285156\n",
      "Train Epoch: 53 [122496/225000 (54%)] Loss: 20160.406250\n",
      "Train Epoch: 53 [124992/225000 (56%)] Loss: 20067.804688\n",
      "Train Epoch: 53 [127488/225000 (57%)] Loss: 20027.101562\n",
      "Train Epoch: 53 [129984/225000 (58%)] Loss: 20357.296875\n",
      "Train Epoch: 53 [132480/225000 (59%)] Loss: 20137.144531\n",
      "Train Epoch: 53 [134976/225000 (60%)] Loss: 20114.261719\n",
      "Train Epoch: 53 [137472/225000 (61%)] Loss: 20254.187500\n",
      "Train Epoch: 53 [139968/225000 (62%)] Loss: 20297.175781\n",
      "Train Epoch: 53 [142464/225000 (63%)] Loss: 19887.714844\n",
      "Train Epoch: 53 [144960/225000 (64%)] Loss: 20391.214844\n",
      "Train Epoch: 53 [147456/225000 (66%)] Loss: 20137.414062\n",
      "Train Epoch: 53 [149952/225000 (67%)] Loss: 20245.253906\n",
      "Train Epoch: 53 [152448/225000 (68%)] Loss: 20694.826172\n",
      "Train Epoch: 53 [154944/225000 (69%)] Loss: 20376.308594\n",
      "Train Epoch: 53 [157440/225000 (70%)] Loss: 19915.421875\n",
      "Train Epoch: 53 [159936/225000 (71%)] Loss: 19726.666016\n",
      "Train Epoch: 53 [162432/225000 (72%)] Loss: 20390.044922\n",
      "Train Epoch: 53 [164928/225000 (73%)] Loss: 20695.824219\n",
      "Train Epoch: 53 [167424/225000 (74%)] Loss: 19819.078125\n",
      "Train Epoch: 53 [169920/225000 (76%)] Loss: 20055.429688\n",
      "Train Epoch: 53 [172416/225000 (77%)] Loss: 20503.146484\n",
      "Train Epoch: 53 [174912/225000 (78%)] Loss: 20798.679688\n",
      "Train Epoch: 53 [177408/225000 (79%)] Loss: 20270.593750\n",
      "Train Epoch: 53 [179904/225000 (80%)] Loss: 19964.402344\n",
      "Train Epoch: 53 [182400/225000 (81%)] Loss: 19952.039062\n",
      "Train Epoch: 53 [184896/225000 (82%)] Loss: 20089.953125\n",
      "Train Epoch: 53 [187392/225000 (83%)] Loss: 20187.785156\n",
      "Train Epoch: 53 [189888/225000 (84%)] Loss: 20561.410156\n",
      "Train Epoch: 53 [192384/225000 (86%)] Loss: 20353.046875\n",
      "Train Epoch: 53 [194880/225000 (87%)] Loss: 20148.962891\n",
      "Train Epoch: 53 [197376/225000 (88%)] Loss: 20504.582031\n",
      "Train Epoch: 53 [199872/225000 (89%)] Loss: 19991.880859\n",
      "Train Epoch: 53 [202368/225000 (90%)] Loss: 20195.650391\n",
      "Train Epoch: 53 [204864/225000 (91%)] Loss: 20508.896484\n",
      "Train Epoch: 53 [207360/225000 (92%)] Loss: 20919.183594\n",
      "Train Epoch: 53 [209856/225000 (93%)] Loss: 20419.453125\n",
      "Train Epoch: 53 [212352/225000 (94%)] Loss: 20223.257812\n",
      "Train Epoch: 53 [214848/225000 (95%)] Loss: 20272.531250\n",
      "Train Epoch: 53 [217344/225000 (97%)] Loss: 20032.613281\n",
      "Train Epoch: 53 [219840/225000 (98%)] Loss: 20388.046875\n",
      "Train Epoch: 53 [222336/225000 (99%)] Loss: 19716.978516\n",
      "Train Epoch: 53 [224832/225000 (100%)] Loss: 19755.455078\n",
      "    epoch          : 53\n",
      "    loss           : 20183.795281836603\n",
      "    val_loss       : 20076.837777173245\n",
      "Train Epoch: 54 [192/225000 (0%)] Loss: 20114.166016\n",
      "Train Epoch: 54 [2688/225000 (1%)] Loss: 20023.921875\n",
      "Train Epoch: 54 [5184/225000 (2%)] Loss: 20232.378906\n",
      "Train Epoch: 54 [7680/225000 (3%)] Loss: 20570.544922\n",
      "Train Epoch: 54 [10176/225000 (5%)] Loss: 19847.921875\n",
      "Train Epoch: 54 [12672/225000 (6%)] Loss: 20283.574219\n",
      "Train Epoch: 54 [15168/225000 (7%)] Loss: 20243.324219\n",
      "Train Epoch: 54 [17664/225000 (8%)] Loss: 20181.398438\n",
      "Train Epoch: 54 [20160/225000 (9%)] Loss: 20230.656250\n",
      "Train Epoch: 54 [22656/225000 (10%)] Loss: 20260.789062\n",
      "Train Epoch: 54 [25152/225000 (11%)] Loss: 19941.640625\n",
      "Train Epoch: 54 [27648/225000 (12%)] Loss: 20187.166016\n",
      "Train Epoch: 54 [30144/225000 (13%)] Loss: 20030.386719\n",
      "Train Epoch: 54 [32640/225000 (15%)] Loss: 20078.488281\n",
      "Train Epoch: 54 [35136/225000 (16%)] Loss: 20661.226562\n",
      "Train Epoch: 54 [37632/225000 (17%)] Loss: 20479.832031\n",
      "Train Epoch: 54 [40128/225000 (18%)] Loss: 20167.867188\n",
      "Train Epoch: 54 [42624/225000 (19%)] Loss: 20116.691406\n",
      "Train Epoch: 54 [45120/225000 (20%)] Loss: 19896.312500\n",
      "Train Epoch: 54 [47616/225000 (21%)] Loss: 20261.734375\n",
      "Train Epoch: 54 [50112/225000 (22%)] Loss: 19986.746094\n",
      "Train Epoch: 54 [52608/225000 (23%)] Loss: 19829.082031\n",
      "Train Epoch: 54 [55104/225000 (24%)] Loss: 20171.207031\n",
      "Train Epoch: 54 [57600/225000 (26%)] Loss: 20347.394531\n",
      "Train Epoch: 54 [60096/225000 (27%)] Loss: 20132.792969\n",
      "Train Epoch: 54 [62592/225000 (28%)] Loss: 20301.037109\n",
      "Train Epoch: 54 [65088/225000 (29%)] Loss: 20274.572266\n",
      "Train Epoch: 54 [67584/225000 (30%)] Loss: 20510.810547\n",
      "Train Epoch: 54 [70080/225000 (31%)] Loss: 19872.480469\n",
      "Train Epoch: 54 [72576/225000 (32%)] Loss: 20293.265625\n",
      "Train Epoch: 54 [75072/225000 (33%)] Loss: 20423.175781\n",
      "Train Epoch: 54 [77568/225000 (34%)] Loss: 19880.539062\n",
      "Train Epoch: 54 [80064/225000 (36%)] Loss: 19503.371094\n",
      "Train Epoch: 54 [82560/225000 (37%)] Loss: 19924.466797\n",
      "Train Epoch: 54 [85056/225000 (38%)] Loss: 20331.750000\n",
      "Train Epoch: 54 [87552/225000 (39%)] Loss: 20553.277344\n",
      "Train Epoch: 54 [90048/225000 (40%)] Loss: 19884.945312\n",
      "Train Epoch: 54 [92544/225000 (41%)] Loss: 20204.035156\n",
      "Train Epoch: 54 [95040/225000 (42%)] Loss: 20223.826172\n",
      "Train Epoch: 54 [97536/225000 (43%)] Loss: 20193.169922\n",
      "Train Epoch: 54 [100032/225000 (44%)] Loss: 20201.763672\n",
      "Train Epoch: 54 [102528/225000 (46%)] Loss: 19981.281250\n",
      "Train Epoch: 54 [105024/225000 (47%)] Loss: 20261.730469\n",
      "Train Epoch: 54 [107520/225000 (48%)] Loss: 20242.986328\n",
      "Train Epoch: 54 [110016/225000 (49%)] Loss: 20387.738281\n",
      "Train Epoch: 54 [112512/225000 (50%)] Loss: 20259.656250\n",
      "Train Epoch: 54 [115008/225000 (51%)] Loss: 20121.664062\n",
      "Train Epoch: 54 [117504/225000 (52%)] Loss: 19952.519531\n",
      "Train Epoch: 54 [120000/225000 (53%)] Loss: 19935.113281\n",
      "Train Epoch: 54 [122496/225000 (54%)] Loss: 20011.505859\n",
      "Train Epoch: 54 [124992/225000 (56%)] Loss: 19791.621094\n",
      "Train Epoch: 54 [127488/225000 (57%)] Loss: 20186.492188\n",
      "Train Epoch: 54 [129984/225000 (58%)] Loss: 20201.914062\n",
      "Train Epoch: 54 [132480/225000 (59%)] Loss: 20069.968750\n",
      "Train Epoch: 54 [134976/225000 (60%)] Loss: 20201.000000\n",
      "Train Epoch: 54 [137472/225000 (61%)] Loss: 20199.429688\n",
      "Train Epoch: 54 [139968/225000 (62%)] Loss: 19767.349609\n",
      "Train Epoch: 54 [142464/225000 (63%)] Loss: 20454.378906\n",
      "Train Epoch: 54 [144960/225000 (64%)] Loss: 19700.242188\n",
      "Train Epoch: 54 [147456/225000 (66%)] Loss: 19826.714844\n",
      "Train Epoch: 54 [149952/225000 (67%)] Loss: 20264.000000\n",
      "Train Epoch: 54 [152448/225000 (68%)] Loss: 20166.964844\n",
      "Train Epoch: 54 [154944/225000 (69%)] Loss: 20202.701172\n",
      "Train Epoch: 54 [157440/225000 (70%)] Loss: 20024.955078\n",
      "Train Epoch: 54 [159936/225000 (71%)] Loss: 20055.125000\n",
      "Train Epoch: 54 [162432/225000 (72%)] Loss: 20651.582031\n",
      "Train Epoch: 54 [164928/225000 (73%)] Loss: 20222.753906\n",
      "Train Epoch: 54 [167424/225000 (74%)] Loss: 20614.345703\n",
      "Train Epoch: 54 [169920/225000 (76%)] Loss: 20233.574219\n",
      "Train Epoch: 54 [172416/225000 (77%)] Loss: 19987.167969\n",
      "Train Epoch: 54 [174912/225000 (78%)] Loss: 19994.593750\n",
      "Train Epoch: 54 [177408/225000 (79%)] Loss: 20115.609375\n",
      "Train Epoch: 54 [179904/225000 (80%)] Loss: 20329.708984\n",
      "Train Epoch: 54 [182400/225000 (81%)] Loss: 20275.636719\n",
      "Train Epoch: 54 [184896/225000 (82%)] Loss: 19838.570312\n",
      "Train Epoch: 54 [187392/225000 (83%)] Loss: 20340.326172\n",
      "Train Epoch: 54 [189888/225000 (84%)] Loss: 20077.056641\n",
      "Train Epoch: 54 [192384/225000 (86%)] Loss: 20237.769531\n",
      "Train Epoch: 54 [194880/225000 (87%)] Loss: 20416.712891\n",
      "Train Epoch: 54 [197376/225000 (88%)] Loss: 19975.925781\n",
      "Train Epoch: 54 [199872/225000 (89%)] Loss: 20317.484375\n",
      "Train Epoch: 54 [202368/225000 (90%)] Loss: 20114.923828\n",
      "Train Epoch: 54 [204864/225000 (91%)] Loss: 20609.062500\n",
      "Train Epoch: 54 [207360/225000 (92%)] Loss: 20214.500000\n",
      "Train Epoch: 54 [209856/225000 (93%)] Loss: 20064.628906\n",
      "Train Epoch: 54 [212352/225000 (94%)] Loss: 19666.320312\n",
      "Train Epoch: 54 [214848/225000 (95%)] Loss: 20409.169922\n",
      "Train Epoch: 54 [217344/225000 (97%)] Loss: 19963.699219\n",
      "Train Epoch: 54 [219840/225000 (98%)] Loss: 20419.556641\n",
      "Train Epoch: 54 [222336/225000 (99%)] Loss: 19894.609375\n",
      "Train Epoch: 54 [224832/225000 (100%)] Loss: 20117.121094\n",
      "    epoch          : 54\n",
      "    loss           : 20175.495335497548\n",
      "    val_loss       : 20172.30140907255\n",
      "Train Epoch: 55 [192/225000 (0%)] Loss: 20034.769531\n",
      "Train Epoch: 55 [2688/225000 (1%)] Loss: 19988.253906\n",
      "Train Epoch: 55 [5184/225000 (2%)] Loss: 19895.591797\n",
      "Train Epoch: 55 [7680/225000 (3%)] Loss: 20024.285156\n",
      "Train Epoch: 55 [10176/225000 (5%)] Loss: 19996.345703\n",
      "Train Epoch: 55 [12672/225000 (6%)] Loss: 20204.839844\n",
      "Train Epoch: 55 [15168/225000 (7%)] Loss: 20153.062500\n",
      "Train Epoch: 55 [17664/225000 (8%)] Loss: 20204.492188\n",
      "Train Epoch: 55 [20160/225000 (9%)] Loss: 20438.664062\n",
      "Train Epoch: 55 [22656/225000 (10%)] Loss: 20788.876953\n",
      "Train Epoch: 55 [25152/225000 (11%)] Loss: 20391.117188\n",
      "Train Epoch: 55 [27648/225000 (12%)] Loss: 20514.730469\n",
      "Train Epoch: 55 [30144/225000 (13%)] Loss: 20371.035156\n",
      "Train Epoch: 55 [32640/225000 (15%)] Loss: 20380.751953\n",
      "Train Epoch: 55 [35136/225000 (16%)] Loss: 20350.365234\n",
      "Train Epoch: 55 [37632/225000 (17%)] Loss: 19666.765625\n",
      "Train Epoch: 55 [40128/225000 (18%)] Loss: 19911.287109\n",
      "Train Epoch: 55 [42624/225000 (19%)] Loss: 20732.593750\n",
      "Train Epoch: 55 [45120/225000 (20%)] Loss: 20476.820312\n",
      "Train Epoch: 55 [47616/225000 (21%)] Loss: 20194.511719\n",
      "Train Epoch: 55 [50112/225000 (22%)] Loss: 20341.898438\n",
      "Train Epoch: 55 [52608/225000 (23%)] Loss: 20326.492188\n",
      "Train Epoch: 55 [55104/225000 (24%)] Loss: 19986.832031\n",
      "Train Epoch: 55 [57600/225000 (26%)] Loss: 20714.400391\n",
      "Train Epoch: 55 [60096/225000 (27%)] Loss: 20142.312500\n",
      "Train Epoch: 55 [62592/225000 (28%)] Loss: 19956.445312\n",
      "Train Epoch: 55 [65088/225000 (29%)] Loss: 19886.166016\n",
      "Train Epoch: 55 [67584/225000 (30%)] Loss: 20238.330078\n",
      "Train Epoch: 55 [70080/225000 (31%)] Loss: 20144.406250\n",
      "Train Epoch: 55 [72576/225000 (32%)] Loss: 20082.078125\n",
      "Train Epoch: 55 [75072/225000 (33%)] Loss: 20114.023438\n",
      "Train Epoch: 55 [77568/225000 (34%)] Loss: 20774.751953\n",
      "Train Epoch: 55 [80064/225000 (36%)] Loss: 19454.593750\n",
      "Train Epoch: 55 [82560/225000 (37%)] Loss: 20241.437500\n",
      "Train Epoch: 55 [85056/225000 (38%)] Loss: 20068.853516\n",
      "Train Epoch: 55 [87552/225000 (39%)] Loss: 20050.335938\n",
      "Train Epoch: 55 [90048/225000 (40%)] Loss: 19656.917969\n",
      "Train Epoch: 55 [92544/225000 (41%)] Loss: 19730.093750\n",
      "Train Epoch: 55 [95040/225000 (42%)] Loss: 19840.406250\n",
      "Train Epoch: 55 [97536/225000 (43%)] Loss: 19654.273438\n",
      "Train Epoch: 55 [100032/225000 (44%)] Loss: 20438.648438\n",
      "Train Epoch: 55 [102528/225000 (46%)] Loss: 20128.300781\n",
      "Train Epoch: 55 [105024/225000 (47%)] Loss: 20404.693359\n",
      "Train Epoch: 55 [107520/225000 (48%)] Loss: 20055.863281\n",
      "Train Epoch: 55 [110016/225000 (49%)] Loss: 20647.699219\n",
      "Train Epoch: 55 [112512/225000 (50%)] Loss: 20342.070312\n",
      "Train Epoch: 55 [115008/225000 (51%)] Loss: 20191.000000\n",
      "Train Epoch: 55 [117504/225000 (52%)] Loss: 20635.339844\n",
      "Train Epoch: 55 [120000/225000 (53%)] Loss: 20557.210938\n",
      "Train Epoch: 55 [122496/225000 (54%)] Loss: 19832.355469\n",
      "Train Epoch: 55 [124992/225000 (56%)] Loss: 20183.298828\n",
      "Train Epoch: 55 [127488/225000 (57%)] Loss: 20380.160156\n",
      "Train Epoch: 55 [129984/225000 (58%)] Loss: 20167.595703\n",
      "Train Epoch: 55 [132480/225000 (59%)] Loss: 19919.972656\n",
      "Train Epoch: 55 [134976/225000 (60%)] Loss: 20721.183594\n",
      "Train Epoch: 55 [137472/225000 (61%)] Loss: 20283.406250\n",
      "Train Epoch: 55 [139968/225000 (62%)] Loss: 20228.201172\n",
      "Train Epoch: 55 [142464/225000 (63%)] Loss: 20371.546875\n",
      "Train Epoch: 55 [144960/225000 (64%)] Loss: 20024.121094\n",
      "Train Epoch: 55 [147456/225000 (66%)] Loss: 20775.285156\n",
      "Train Epoch: 55 [149952/225000 (67%)] Loss: 19945.824219\n",
      "Train Epoch: 55 [152448/225000 (68%)] Loss: 20132.031250\n",
      "Train Epoch: 55 [154944/225000 (69%)] Loss: 19982.875000\n",
      "Train Epoch: 55 [157440/225000 (70%)] Loss: 19841.289062\n",
      "Train Epoch: 55 [159936/225000 (71%)] Loss: 20575.890625\n",
      "Train Epoch: 55 [162432/225000 (72%)] Loss: 20129.132812\n",
      "Train Epoch: 55 [164928/225000 (73%)] Loss: 20454.955078\n",
      "Train Epoch: 55 [167424/225000 (74%)] Loss: 19679.947266\n",
      "Train Epoch: 55 [169920/225000 (76%)] Loss: 19888.246094\n",
      "Train Epoch: 55 [172416/225000 (77%)] Loss: 19893.734375\n",
      "Train Epoch: 55 [174912/225000 (78%)] Loss: 19838.671875\n",
      "Train Epoch: 55 [177408/225000 (79%)] Loss: 20302.199219\n",
      "Train Epoch: 55 [179904/225000 (80%)] Loss: 20366.597656\n",
      "Train Epoch: 55 [182400/225000 (81%)] Loss: 20517.121094\n",
      "Train Epoch: 55 [184896/225000 (82%)] Loss: 20136.101562\n",
      "Train Epoch: 55 [187392/225000 (83%)] Loss: 20138.046875\n",
      "Train Epoch: 55 [189888/225000 (84%)] Loss: 20097.910156\n",
      "Train Epoch: 55 [192384/225000 (86%)] Loss: 20423.597656\n",
      "Train Epoch: 55 [194880/225000 (87%)] Loss: 19558.750000\n",
      "Train Epoch: 55 [197376/225000 (88%)] Loss: 20519.937500\n",
      "Train Epoch: 55 [199872/225000 (89%)] Loss: 19808.035156\n",
      "Train Epoch: 55 [202368/225000 (90%)] Loss: 19588.035156\n",
      "Train Epoch: 55 [204864/225000 (91%)] Loss: 19925.787109\n",
      "Train Epoch: 55 [207360/225000 (92%)] Loss: 19991.447266\n",
      "Train Epoch: 55 [209856/225000 (93%)] Loss: 19828.503906\n",
      "Train Epoch: 55 [212352/225000 (94%)] Loss: 20521.728516\n",
      "Train Epoch: 55 [214848/225000 (95%)] Loss: 20314.015625\n",
      "Train Epoch: 55 [217344/225000 (97%)] Loss: 20378.707031\n",
      "Train Epoch: 55 [219840/225000 (98%)] Loss: 20564.960938\n",
      "Train Epoch: 55 [222336/225000 (99%)] Loss: 20309.908203\n",
      "Train Epoch: 55 [224832/225000 (100%)] Loss: 20301.117188\n",
      "    epoch          : 55\n",
      "    loss           : 20142.309441992853\n",
      "    val_loss       : 20093.59723822397\n",
      "Train Epoch: 56 [192/225000 (0%)] Loss: 20167.246094\n",
      "Train Epoch: 56 [2688/225000 (1%)] Loss: 19684.398438\n",
      "Train Epoch: 56 [5184/225000 (2%)] Loss: 20475.232422\n",
      "Train Epoch: 56 [7680/225000 (3%)] Loss: 20588.437500\n",
      "Train Epoch: 56 [10176/225000 (5%)] Loss: 20123.076172\n",
      "Train Epoch: 56 [12672/225000 (6%)] Loss: 19963.656250\n",
      "Train Epoch: 56 [15168/225000 (7%)] Loss: 20685.326172\n",
      "Train Epoch: 56 [17664/225000 (8%)] Loss: 20603.287109\n",
      "Train Epoch: 56 [20160/225000 (9%)] Loss: 20258.175781\n",
      "Train Epoch: 56 [22656/225000 (10%)] Loss: 20336.082031\n",
      "Train Epoch: 56 [25152/225000 (11%)] Loss: 20089.792969\n",
      "Train Epoch: 56 [27648/225000 (12%)] Loss: 19633.378906\n",
      "Train Epoch: 56 [30144/225000 (13%)] Loss: 20071.757812\n",
      "Train Epoch: 56 [32640/225000 (15%)] Loss: 20233.669922\n",
      "Train Epoch: 56 [35136/225000 (16%)] Loss: 19686.511719\n",
      "Train Epoch: 56 [37632/225000 (17%)] Loss: 19433.406250\n",
      "Train Epoch: 56 [40128/225000 (18%)] Loss: 20073.222656\n",
      "Train Epoch: 56 [42624/225000 (19%)] Loss: 20124.890625\n",
      "Train Epoch: 56 [45120/225000 (20%)] Loss: 20602.082031\n",
      "Train Epoch: 56 [47616/225000 (21%)] Loss: 20129.367188\n",
      "Train Epoch: 56 [50112/225000 (22%)] Loss: 20433.587891\n",
      "Train Epoch: 56 [52608/225000 (23%)] Loss: 19416.107422\n",
      "Train Epoch: 56 [55104/225000 (24%)] Loss: 20110.562500\n",
      "Train Epoch: 56 [57600/225000 (26%)] Loss: 20201.402344\n",
      "Train Epoch: 56 [60096/225000 (27%)] Loss: 20208.210938\n",
      "Train Epoch: 56 [62592/225000 (28%)] Loss: 20176.519531\n",
      "Train Epoch: 56 [65088/225000 (29%)] Loss: 20001.921875\n",
      "Train Epoch: 56 [67584/225000 (30%)] Loss: 20031.113281\n",
      "Train Epoch: 56 [70080/225000 (31%)] Loss: 19921.347656\n",
      "Train Epoch: 56 [72576/225000 (32%)] Loss: 20430.195312\n",
      "Train Epoch: 56 [75072/225000 (33%)] Loss: 20516.507812\n",
      "Train Epoch: 56 [77568/225000 (34%)] Loss: 19841.984375\n",
      "Train Epoch: 56 [80064/225000 (36%)] Loss: 20479.429688\n",
      "Train Epoch: 56 [82560/225000 (37%)] Loss: 19650.003906\n",
      "Train Epoch: 56 [85056/225000 (38%)] Loss: 20118.613281\n",
      "Train Epoch: 56 [87552/225000 (39%)] Loss: 20298.847656\n",
      "Train Epoch: 56 [90048/225000 (40%)] Loss: 19984.437500\n",
      "Train Epoch: 56 [92544/225000 (41%)] Loss: 19818.597656\n",
      "Train Epoch: 56 [95040/225000 (42%)] Loss: 20246.582031\n",
      "Train Epoch: 56 [97536/225000 (43%)] Loss: 20337.281250\n",
      "Train Epoch: 56 [100032/225000 (44%)] Loss: 20744.357422\n",
      "Train Epoch: 56 [102528/225000 (46%)] Loss: 20056.128906\n",
      "Train Epoch: 56 [105024/225000 (47%)] Loss: 19644.007812\n",
      "Train Epoch: 56 [107520/225000 (48%)] Loss: 20014.566406\n",
      "Train Epoch: 56 [110016/225000 (49%)] Loss: 20268.574219\n",
      "Train Epoch: 56 [112512/225000 (50%)] Loss: 20242.207031\n",
      "Train Epoch: 56 [115008/225000 (51%)] Loss: 19735.121094\n",
      "Train Epoch: 56 [117504/225000 (52%)] Loss: 20301.070312\n",
      "Train Epoch: 56 [120000/225000 (53%)] Loss: 20305.890625\n",
      "Train Epoch: 56 [122496/225000 (54%)] Loss: 19810.642578\n",
      "Train Epoch: 56 [124992/225000 (56%)] Loss: 20149.894531\n",
      "Train Epoch: 56 [127488/225000 (57%)] Loss: 20003.011719\n",
      "Train Epoch: 56 [129984/225000 (58%)] Loss: 20064.099609\n",
      "Train Epoch: 56 [132480/225000 (59%)] Loss: 19934.244141\n",
      "Train Epoch: 56 [134976/225000 (60%)] Loss: 20063.835938\n",
      "Train Epoch: 56 [137472/225000 (61%)] Loss: 19801.101562\n",
      "Train Epoch: 56 [139968/225000 (62%)] Loss: 20175.351562\n",
      "Train Epoch: 56 [142464/225000 (63%)] Loss: 19891.593750\n",
      "Train Epoch: 56 [144960/225000 (64%)] Loss: 20166.390625\n",
      "Train Epoch: 56 [147456/225000 (66%)] Loss: 19847.554688\n",
      "Train Epoch: 56 [149952/225000 (67%)] Loss: 20016.968750\n",
      "Train Epoch: 56 [152448/225000 (68%)] Loss: 20287.480469\n",
      "Train Epoch: 56 [154944/225000 (69%)] Loss: 20270.017578\n",
      "Train Epoch: 56 [157440/225000 (70%)] Loss: 20568.332031\n",
      "Train Epoch: 56 [159936/225000 (71%)] Loss: 19821.082031\n",
      "Train Epoch: 56 [162432/225000 (72%)] Loss: 19936.480469\n",
      "Train Epoch: 56 [164928/225000 (73%)] Loss: 20593.320312\n",
      "Train Epoch: 56 [167424/225000 (74%)] Loss: 19930.902344\n",
      "Train Epoch: 56 [169920/225000 (76%)] Loss: 19522.843750\n",
      "Train Epoch: 56 [172416/225000 (77%)] Loss: 19731.951172\n",
      "Train Epoch: 56 [174912/225000 (78%)] Loss: 19954.400391\n",
      "Train Epoch: 56 [177408/225000 (79%)] Loss: 20055.062500\n",
      "Train Epoch: 56 [179904/225000 (80%)] Loss: 20035.025391\n",
      "Train Epoch: 56 [182400/225000 (81%)] Loss: 20285.472656\n",
      "Train Epoch: 56 [184896/225000 (82%)] Loss: 19941.921875\n",
      "Train Epoch: 56 [187392/225000 (83%)] Loss: 19931.292969\n",
      "Train Epoch: 56 [189888/225000 (84%)] Loss: 20160.111328\n",
      "Train Epoch: 56 [192384/225000 (86%)] Loss: 20474.800781\n",
      "Train Epoch: 56 [194880/225000 (87%)] Loss: 20133.552734\n",
      "Train Epoch: 56 [197376/225000 (88%)] Loss: 20085.312500\n",
      "Train Epoch: 56 [199872/225000 (89%)] Loss: 20387.605469\n",
      "Train Epoch: 56 [202368/225000 (90%)] Loss: 20317.292969\n",
      "Train Epoch: 56 [204864/225000 (91%)] Loss: 20249.761719\n",
      "Train Epoch: 56 [207360/225000 (92%)] Loss: 20299.369141\n",
      "Train Epoch: 56 [209856/225000 (93%)] Loss: 20313.925781\n",
      "Train Epoch: 56 [212352/225000 (94%)] Loss: 20174.173828\n",
      "Train Epoch: 56 [214848/225000 (95%)] Loss: 19800.457031\n",
      "Train Epoch: 56 [217344/225000 (97%)] Loss: 20479.183594\n",
      "Train Epoch: 56 [219840/225000 (98%)] Loss: 20240.257812\n",
      "Train Epoch: 56 [222336/225000 (99%)] Loss: 19620.175781\n",
      "Train Epoch: 56 [224832/225000 (100%)] Loss: 20170.904297\n",
      "    epoch          : 56\n",
      "    loss           : 20126.740346029757\n",
      "    val_loss       : 20021.87927673518\n",
      "Train Epoch: 57 [192/225000 (0%)] Loss: 20167.660156\n",
      "Train Epoch: 57 [2688/225000 (1%)] Loss: 19914.339844\n",
      "Train Epoch: 57 [5184/225000 (2%)] Loss: 20171.285156\n",
      "Train Epoch: 57 [7680/225000 (3%)] Loss: 20190.871094\n",
      "Train Epoch: 57 [10176/225000 (5%)] Loss: 19868.482422\n",
      "Train Epoch: 57 [12672/225000 (6%)] Loss: 19559.710938\n",
      "Train Epoch: 57 [15168/225000 (7%)] Loss: 19988.072266\n",
      "Train Epoch: 57 [17664/225000 (8%)] Loss: 19941.880859\n",
      "Train Epoch: 57 [20160/225000 (9%)] Loss: 20245.964844\n",
      "Train Epoch: 57 [22656/225000 (10%)] Loss: 19779.082031\n",
      "Train Epoch: 57 [25152/225000 (11%)] Loss: 20339.449219\n",
      "Train Epoch: 57 [27648/225000 (12%)] Loss: 20064.923828\n",
      "Train Epoch: 57 [30144/225000 (13%)] Loss: 20514.355469\n",
      "Train Epoch: 57 [32640/225000 (15%)] Loss: 20071.179688\n",
      "Train Epoch: 57 [35136/225000 (16%)] Loss: 20112.806641\n",
      "Train Epoch: 57 [37632/225000 (17%)] Loss: 19712.765625\n",
      "Train Epoch: 57 [40128/225000 (18%)] Loss: 19935.714844\n",
      "Train Epoch: 57 [42624/225000 (19%)] Loss: 20610.492188\n",
      "Train Epoch: 57 [45120/225000 (20%)] Loss: 20478.089844\n",
      "Train Epoch: 57 [47616/225000 (21%)] Loss: 20046.753906\n",
      "Train Epoch: 57 [50112/225000 (22%)] Loss: 19883.898438\n",
      "Train Epoch: 57 [52608/225000 (23%)] Loss: 20246.570312\n",
      "Train Epoch: 57 [55104/225000 (24%)] Loss: 19842.539062\n",
      "Train Epoch: 57 [57600/225000 (26%)] Loss: 19656.312500\n",
      "Train Epoch: 57 [60096/225000 (27%)] Loss: 20035.632812\n",
      "Train Epoch: 57 [62592/225000 (28%)] Loss: 20017.601562\n",
      "Train Epoch: 57 [65088/225000 (29%)] Loss: 20103.689453\n",
      "Train Epoch: 57 [67584/225000 (30%)] Loss: 19965.269531\n",
      "Train Epoch: 57 [70080/225000 (31%)] Loss: 20443.484375\n",
      "Train Epoch: 57 [72576/225000 (32%)] Loss: 20066.064453\n",
      "Train Epoch: 57 [75072/225000 (33%)] Loss: 20426.832031\n",
      "Train Epoch: 57 [77568/225000 (34%)] Loss: 20313.656250\n",
      "Train Epoch: 57 [80064/225000 (36%)] Loss: 19857.289062\n",
      "Train Epoch: 57 [82560/225000 (37%)] Loss: 20175.039062\n",
      "Train Epoch: 57 [85056/225000 (38%)] Loss: 20356.015625\n",
      "Train Epoch: 57 [87552/225000 (39%)] Loss: 20151.130859\n",
      "Train Epoch: 57 [90048/225000 (40%)] Loss: 20285.082031\n",
      "Train Epoch: 57 [92544/225000 (41%)] Loss: 20241.265625\n",
      "Train Epoch: 57 [95040/225000 (42%)] Loss: 20603.824219\n",
      "Train Epoch: 57 [97536/225000 (43%)] Loss: 20436.742188\n",
      "Train Epoch: 57 [100032/225000 (44%)] Loss: 19919.597656\n",
      "Train Epoch: 57 [102528/225000 (46%)] Loss: 20232.074219\n",
      "Train Epoch: 57 [105024/225000 (47%)] Loss: 20636.375000\n",
      "Train Epoch: 57 [107520/225000 (48%)] Loss: 20992.603516\n",
      "Train Epoch: 57 [110016/225000 (49%)] Loss: 20535.597656\n",
      "Train Epoch: 57 [112512/225000 (50%)] Loss: 19662.597656\n",
      "Train Epoch: 57 [115008/225000 (51%)] Loss: 20060.845703\n",
      "Train Epoch: 57 [117504/225000 (52%)] Loss: 19879.382812\n",
      "Train Epoch: 57 [120000/225000 (53%)] Loss: 20327.458984\n",
      "Train Epoch: 57 [122496/225000 (54%)] Loss: 20287.515625\n",
      "Train Epoch: 57 [124992/225000 (56%)] Loss: 20143.875000\n",
      "Train Epoch: 57 [127488/225000 (57%)] Loss: 20328.443359\n",
      "Train Epoch: 57 [129984/225000 (58%)] Loss: 20279.500000\n",
      "Train Epoch: 57 [132480/225000 (59%)] Loss: 19993.966797\n",
      "Train Epoch: 57 [134976/225000 (60%)] Loss: 20345.839844\n",
      "Train Epoch: 57 [137472/225000 (61%)] Loss: 20542.285156\n",
      "Train Epoch: 57 [139968/225000 (62%)] Loss: 20513.691406\n",
      "Train Epoch: 57 [142464/225000 (63%)] Loss: 20134.439453\n",
      "Train Epoch: 57 [144960/225000 (64%)] Loss: 19855.033203\n",
      "Train Epoch: 57 [147456/225000 (66%)] Loss: 20287.031250\n",
      "Train Epoch: 57 [149952/225000 (67%)] Loss: 20188.173828\n",
      "Train Epoch: 57 [152448/225000 (68%)] Loss: 20261.816406\n",
      "Train Epoch: 57 [154944/225000 (69%)] Loss: 20289.226562\n",
      "Train Epoch: 57 [157440/225000 (70%)] Loss: 20129.835938\n",
      "Train Epoch: 57 [159936/225000 (71%)] Loss: 19821.574219\n",
      "Train Epoch: 57 [162432/225000 (72%)] Loss: 20401.574219\n",
      "Train Epoch: 57 [164928/225000 (73%)] Loss: 19465.589844\n",
      "Train Epoch: 57 [167424/225000 (74%)] Loss: 20070.496094\n",
      "Train Epoch: 57 [169920/225000 (76%)] Loss: 20025.640625\n",
      "Train Epoch: 57 [172416/225000 (77%)] Loss: 20303.500000\n",
      "Train Epoch: 57 [174912/225000 (78%)] Loss: 20025.035156\n",
      "Train Epoch: 57 [177408/225000 (79%)] Loss: 19975.484375\n",
      "Train Epoch: 57 [179904/225000 (80%)] Loss: 19902.542969\n",
      "Train Epoch: 57 [182400/225000 (81%)] Loss: 19975.664062\n",
      "Train Epoch: 57 [184896/225000 (82%)] Loss: 20086.859375\n",
      "Train Epoch: 57 [187392/225000 (83%)] Loss: 20319.488281\n",
      "Train Epoch: 57 [189888/225000 (84%)] Loss: 20506.720703\n",
      "Train Epoch: 57 [192384/225000 (86%)] Loss: 20511.240234\n",
      "Train Epoch: 57 [194880/225000 (87%)] Loss: 19890.359375\n",
      "Train Epoch: 57 [197376/225000 (88%)] Loss: 19906.554688\n",
      "Train Epoch: 57 [199872/225000 (89%)] Loss: 19631.892578\n",
      "Train Epoch: 57 [202368/225000 (90%)] Loss: 20425.404297\n",
      "Train Epoch: 57 [204864/225000 (91%)] Loss: 19947.925781\n",
      "Train Epoch: 57 [207360/225000 (92%)] Loss: 19885.941406\n",
      "Train Epoch: 57 [209856/225000 (93%)] Loss: 19988.753906\n",
      "Train Epoch: 57 [212352/225000 (94%)] Loss: 20300.164062\n",
      "Train Epoch: 57 [214848/225000 (95%)] Loss: 20310.421875\n",
      "Train Epoch: 57 [217344/225000 (97%)] Loss: 20284.660156\n",
      "Train Epoch: 57 [219840/225000 (98%)] Loss: 20381.699219\n",
      "Train Epoch: 57 [222336/225000 (99%)] Loss: 20480.175781\n",
      "Train Epoch: 57 [224832/225000 (100%)] Loss: 19905.134766\n",
      "    epoch          : 57\n",
      "    loss           : 20119.744207284555\n",
      "    val_loss       : 20022.737475115835\n",
      "Train Epoch: 58 [192/225000 (0%)] Loss: 19892.968750\n",
      "Train Epoch: 58 [2688/225000 (1%)] Loss: 20238.214844\n",
      "Train Epoch: 58 [5184/225000 (2%)] Loss: 20094.972656\n",
      "Train Epoch: 58 [7680/225000 (3%)] Loss: 19822.640625\n",
      "Train Epoch: 58 [10176/225000 (5%)] Loss: 20202.324219\n",
      "Train Epoch: 58 [12672/225000 (6%)] Loss: 20037.976562\n",
      "Train Epoch: 58 [15168/225000 (7%)] Loss: 20257.359375\n",
      "Train Epoch: 58 [17664/225000 (8%)] Loss: 20095.533203\n",
      "Train Epoch: 58 [20160/225000 (9%)] Loss: 20329.427734\n",
      "Train Epoch: 58 [22656/225000 (10%)] Loss: 19984.488281\n",
      "Train Epoch: 58 [25152/225000 (11%)] Loss: 19991.093750\n",
      "Train Epoch: 58 [27648/225000 (12%)] Loss: 19795.492188\n",
      "Train Epoch: 58 [30144/225000 (13%)] Loss: 20280.945312\n",
      "Train Epoch: 58 [32640/225000 (15%)] Loss: 20536.593750\n",
      "Train Epoch: 58 [35136/225000 (16%)] Loss: 20681.865234\n",
      "Train Epoch: 58 [37632/225000 (17%)] Loss: 19906.726562\n",
      "Train Epoch: 58 [40128/225000 (18%)] Loss: 20158.343750\n",
      "Train Epoch: 58 [42624/225000 (19%)] Loss: 20054.628906\n",
      "Train Epoch: 58 [45120/225000 (20%)] Loss: 20883.160156\n",
      "Train Epoch: 58 [47616/225000 (21%)] Loss: 20257.039062\n",
      "Train Epoch: 58 [50112/225000 (22%)] Loss: 20128.273438\n",
      "Train Epoch: 58 [52608/225000 (23%)] Loss: 20197.833984\n",
      "Train Epoch: 58 [55104/225000 (24%)] Loss: 20009.851562\n",
      "Train Epoch: 58 [57600/225000 (26%)] Loss: 20122.921875\n",
      "Train Epoch: 58 [60096/225000 (27%)] Loss: 20438.656250\n",
      "Train Epoch: 58 [62592/225000 (28%)] Loss: 20291.992188\n",
      "Train Epoch: 58 [65088/225000 (29%)] Loss: 19646.560547\n",
      "Train Epoch: 58 [67584/225000 (30%)] Loss: 20270.658203\n",
      "Train Epoch: 58 [70080/225000 (31%)] Loss: 20289.183594\n",
      "Train Epoch: 58 [72576/225000 (32%)] Loss: 20420.839844\n",
      "Train Epoch: 58 [75072/225000 (33%)] Loss: 19797.480469\n",
      "Train Epoch: 58 [77568/225000 (34%)] Loss: 19781.708984\n",
      "Train Epoch: 58 [80064/225000 (36%)] Loss: 20388.843750\n",
      "Train Epoch: 58 [82560/225000 (37%)] Loss: 20037.050781\n",
      "Train Epoch: 58 [85056/225000 (38%)] Loss: 19648.697266\n",
      "Train Epoch: 58 [87552/225000 (39%)] Loss: 20153.306641\n",
      "Train Epoch: 58 [90048/225000 (40%)] Loss: 19832.878906\n",
      "Train Epoch: 58 [92544/225000 (41%)] Loss: 20063.908203\n",
      "Train Epoch: 58 [95040/225000 (42%)] Loss: 19966.898438\n",
      "Train Epoch: 58 [97536/225000 (43%)] Loss: 20241.980469\n",
      "Train Epoch: 58 [100032/225000 (44%)] Loss: 19980.347656\n",
      "Train Epoch: 58 [102528/225000 (46%)] Loss: 19803.660156\n",
      "Train Epoch: 58 [105024/225000 (47%)] Loss: 20026.574219\n",
      "Train Epoch: 58 [107520/225000 (48%)] Loss: 19884.769531\n",
      "Train Epoch: 58 [110016/225000 (49%)] Loss: 19616.984375\n",
      "Train Epoch: 58 [112512/225000 (50%)] Loss: 20414.726562\n",
      "Train Epoch: 58 [115008/225000 (51%)] Loss: 19985.199219\n",
      "Train Epoch: 58 [117504/225000 (52%)] Loss: 20291.421875\n",
      "Train Epoch: 58 [120000/225000 (53%)] Loss: 19969.667969\n",
      "Train Epoch: 58 [122496/225000 (54%)] Loss: 20299.304688\n",
      "Train Epoch: 58 [124992/225000 (56%)] Loss: 20007.808594\n",
      "Train Epoch: 58 [127488/225000 (57%)] Loss: 19770.425781\n",
      "Train Epoch: 58 [129984/225000 (58%)] Loss: 20311.617188\n",
      "Train Epoch: 58 [132480/225000 (59%)] Loss: 20205.496094\n",
      "Train Epoch: 58 [134976/225000 (60%)] Loss: 20111.029297\n",
      "Train Epoch: 58 [137472/225000 (61%)] Loss: 19932.169922\n",
      "Train Epoch: 58 [139968/225000 (62%)] Loss: 20211.480469\n",
      "Train Epoch: 58 [142464/225000 (63%)] Loss: 20099.062500\n",
      "Train Epoch: 58 [144960/225000 (64%)] Loss: 20262.808594\n",
      "Train Epoch: 58 [147456/225000 (66%)] Loss: 20448.667969\n",
      "Train Epoch: 58 [149952/225000 (67%)] Loss: 20245.007812\n",
      "Train Epoch: 58 [152448/225000 (68%)] Loss: 20046.777344\n",
      "Train Epoch: 58 [154944/225000 (69%)] Loss: 19904.789062\n",
      "Train Epoch: 58 [157440/225000 (70%)] Loss: 19953.835938\n",
      "Train Epoch: 58 [159936/225000 (71%)] Loss: 19790.142578\n",
      "Train Epoch: 58 [162432/225000 (72%)] Loss: 20387.636719\n",
      "Train Epoch: 58 [164928/225000 (73%)] Loss: 20040.656250\n",
      "Train Epoch: 58 [167424/225000 (74%)] Loss: 20415.246094\n",
      "Train Epoch: 58 [169920/225000 (76%)] Loss: 20247.613281\n",
      "Train Epoch: 58 [172416/225000 (77%)] Loss: 20374.246094\n",
      "Train Epoch: 58 [174912/225000 (78%)] Loss: 20390.271484\n",
      "Train Epoch: 58 [177408/225000 (79%)] Loss: 20596.267578\n",
      "Train Epoch: 58 [179904/225000 (80%)] Loss: 19556.378906\n",
      "Train Epoch: 58 [182400/225000 (81%)] Loss: 20367.189453\n",
      "Train Epoch: 58 [184896/225000 (82%)] Loss: 20041.482422\n",
      "Train Epoch: 58 [187392/225000 (83%)] Loss: 19573.906250\n",
      "Train Epoch: 58 [189888/225000 (84%)] Loss: 20354.312500\n",
      "Train Epoch: 58 [192384/225000 (86%)] Loss: 20210.343750\n",
      "Train Epoch: 58 [194880/225000 (87%)] Loss: 20265.222656\n",
      "Train Epoch: 58 [197376/225000 (88%)] Loss: 19938.710938\n",
      "Train Epoch: 58 [199872/225000 (89%)] Loss: 19804.886719\n",
      "Train Epoch: 58 [202368/225000 (90%)] Loss: 20161.111328\n",
      "Train Epoch: 58 [204864/225000 (91%)] Loss: 19925.429688\n",
      "Train Epoch: 58 [207360/225000 (92%)] Loss: 20296.968750\n",
      "Train Epoch: 58 [209856/225000 (93%)] Loss: 19953.457031\n",
      "Train Epoch: 58 [212352/225000 (94%)] Loss: 19305.785156\n",
      "Train Epoch: 58 [214848/225000 (95%)] Loss: 20264.548828\n",
      "Train Epoch: 58 [217344/225000 (97%)] Loss: 20186.525391\n",
      "Train Epoch: 58 [219840/225000 (98%)] Loss: 20111.523438\n",
      "Train Epoch: 58 [222336/225000 (99%)] Loss: 20436.849609\n",
      "Train Epoch: 58 [224832/225000 (100%)] Loss: 20027.039062\n",
      "    epoch          : 58\n",
      "    loss           : 20106.757624186754\n",
      "    val_loss       : 20016.01089705038\n",
      "Train Epoch: 59 [192/225000 (0%)] Loss: 19820.308594\n",
      "Train Epoch: 59 [2688/225000 (1%)] Loss: 20036.183594\n",
      "Train Epoch: 59 [5184/225000 (2%)] Loss: 19812.837891\n",
      "Train Epoch: 59 [7680/225000 (3%)] Loss: 20149.359375\n",
      "Train Epoch: 59 [10176/225000 (5%)] Loss: 20613.091797\n",
      "Train Epoch: 59 [12672/225000 (6%)] Loss: 20003.097656\n",
      "Train Epoch: 59 [15168/225000 (7%)] Loss: 19959.662109\n",
      "Train Epoch: 59 [17664/225000 (8%)] Loss: 19484.359375\n",
      "Train Epoch: 59 [20160/225000 (9%)] Loss: 20020.261719\n",
      "Train Epoch: 59 [22656/225000 (10%)] Loss: 20273.875000\n",
      "Train Epoch: 59 [25152/225000 (11%)] Loss: 19960.816406\n",
      "Train Epoch: 59 [27648/225000 (12%)] Loss: 19918.972656\n",
      "Train Epoch: 59 [30144/225000 (13%)] Loss: 20154.144531\n",
      "Train Epoch: 59 [32640/225000 (15%)] Loss: 20041.875000\n",
      "Train Epoch: 59 [35136/225000 (16%)] Loss: 20224.400391\n",
      "Train Epoch: 59 [37632/225000 (17%)] Loss: 20296.541016\n",
      "Train Epoch: 59 [40128/225000 (18%)] Loss: 19903.656250\n",
      "Train Epoch: 59 [42624/225000 (19%)] Loss: 20397.439453\n",
      "Train Epoch: 59 [45120/225000 (20%)] Loss: 20808.167969\n",
      "Train Epoch: 59 [47616/225000 (21%)] Loss: 19918.785156\n",
      "Train Epoch: 59 [50112/225000 (22%)] Loss: 19971.144531\n",
      "Train Epoch: 59 [52608/225000 (23%)] Loss: 19916.003906\n",
      "Train Epoch: 59 [55104/225000 (24%)] Loss: 20183.378906\n",
      "Train Epoch: 59 [57600/225000 (26%)] Loss: 19851.462891\n",
      "Train Epoch: 59 [60096/225000 (27%)] Loss: 20077.597656\n",
      "Train Epoch: 59 [62592/225000 (28%)] Loss: 20134.066406\n",
      "Train Epoch: 59 [65088/225000 (29%)] Loss: 20212.017578\n",
      "Train Epoch: 59 [67584/225000 (30%)] Loss: 20171.191406\n",
      "Train Epoch: 59 [70080/225000 (31%)] Loss: 20408.470703\n",
      "Train Epoch: 59 [72576/225000 (32%)] Loss: 20029.203125\n",
      "Train Epoch: 59 [75072/225000 (33%)] Loss: 20099.476562\n",
      "Train Epoch: 59 [77568/225000 (34%)] Loss: 20425.613281\n",
      "Train Epoch: 59 [80064/225000 (36%)] Loss: 20001.832031\n",
      "Train Epoch: 59 [82560/225000 (37%)] Loss: 20090.671875\n",
      "Train Epoch: 59 [85056/225000 (38%)] Loss: 20282.388672\n",
      "Train Epoch: 59 [87552/225000 (39%)] Loss: 20392.570312\n",
      "Train Epoch: 59 [90048/225000 (40%)] Loss: 20184.355469\n",
      "Train Epoch: 59 [92544/225000 (41%)] Loss: 20121.816406\n",
      "Train Epoch: 59 [95040/225000 (42%)] Loss: 19734.488281\n",
      "Train Epoch: 59 [97536/225000 (43%)] Loss: 20184.781250\n",
      "Train Epoch: 59 [100032/225000 (44%)] Loss: 20068.251953\n",
      "Train Epoch: 59 [102528/225000 (46%)] Loss: 19961.167969\n",
      "Train Epoch: 59 [105024/225000 (47%)] Loss: 19874.785156\n",
      "Train Epoch: 59 [107520/225000 (48%)] Loss: 20154.062500\n",
      "Train Epoch: 59 [110016/225000 (49%)] Loss: 19282.179688\n",
      "Train Epoch: 59 [112512/225000 (50%)] Loss: 20411.291016\n",
      "Train Epoch: 59 [115008/225000 (51%)] Loss: 20271.986328\n",
      "Train Epoch: 59 [117504/225000 (52%)] Loss: 20197.382812\n",
      "Train Epoch: 59 [120000/225000 (53%)] Loss: 20229.218750\n",
      "Train Epoch: 59 [122496/225000 (54%)] Loss: 19683.457031\n",
      "Train Epoch: 59 [124992/225000 (56%)] Loss: 20320.728516\n",
      "Train Epoch: 59 [127488/225000 (57%)] Loss: 20334.494141\n",
      "Train Epoch: 59 [129984/225000 (58%)] Loss: 20402.378906\n",
      "Train Epoch: 59 [132480/225000 (59%)] Loss: 20247.000000\n",
      "Train Epoch: 59 [134976/225000 (60%)] Loss: 19953.712891\n",
      "Train Epoch: 59 [137472/225000 (61%)] Loss: 19478.804688\n",
      "Train Epoch: 59 [139968/225000 (62%)] Loss: 20210.296875\n",
      "Train Epoch: 59 [142464/225000 (63%)] Loss: 20333.677734\n",
      "Train Epoch: 59 [144960/225000 (64%)] Loss: 19774.236328\n",
      "Train Epoch: 59 [147456/225000 (66%)] Loss: 19695.552734\n",
      "Train Epoch: 59 [149952/225000 (67%)] Loss: 20314.306641\n",
      "Train Epoch: 59 [152448/225000 (68%)] Loss: 19764.445312\n",
      "Train Epoch: 59 [154944/225000 (69%)] Loss: 20019.425781\n",
      "Train Epoch: 59 [157440/225000 (70%)] Loss: 19976.910156\n",
      "Train Epoch: 59 [159936/225000 (71%)] Loss: 19924.339844\n",
      "Train Epoch: 59 [162432/225000 (72%)] Loss: 20017.771484\n",
      "Train Epoch: 59 [164928/225000 (73%)] Loss: 20066.099609\n",
      "Train Epoch: 59 [167424/225000 (74%)] Loss: 19774.707031\n",
      "Train Epoch: 59 [169920/225000 (76%)] Loss: 20040.242188\n",
      "Train Epoch: 59 [172416/225000 (77%)] Loss: 19753.660156\n",
      "Train Epoch: 59 [174912/225000 (78%)] Loss: 20071.818359\n",
      "Train Epoch: 59 [177408/225000 (79%)] Loss: 19926.566406\n",
      "Train Epoch: 59 [179904/225000 (80%)] Loss: 19695.177734\n",
      "Train Epoch: 59 [182400/225000 (81%)] Loss: 19814.398438\n",
      "Train Epoch: 59 [184896/225000 (82%)] Loss: 19849.625000\n",
      "Train Epoch: 59 [187392/225000 (83%)] Loss: 20123.054688\n",
      "Train Epoch: 59 [189888/225000 (84%)] Loss: 20118.152344\n",
      "Train Epoch: 59 [192384/225000 (86%)] Loss: 20043.960938\n",
      "Train Epoch: 59 [194880/225000 (87%)] Loss: 20229.037109\n",
      "Train Epoch: 59 [197376/225000 (88%)] Loss: 20024.496094\n",
      "Train Epoch: 59 [199872/225000 (89%)] Loss: 20205.113281\n",
      "Train Epoch: 59 [202368/225000 (90%)] Loss: 19597.285156\n",
      "Train Epoch: 59 [204864/225000 (91%)] Loss: 20046.533203\n",
      "Train Epoch: 59 [207360/225000 (92%)] Loss: 20006.085938\n",
      "Train Epoch: 59 [209856/225000 (93%)] Loss: 20042.046875\n",
      "Train Epoch: 59 [212352/225000 (94%)] Loss: 19989.871094\n",
      "Train Epoch: 59 [214848/225000 (95%)] Loss: 20540.072266\n",
      "Train Epoch: 59 [217344/225000 (97%)] Loss: 19796.050781\n",
      "Train Epoch: 59 [219840/225000 (98%)] Loss: 20076.929688\n",
      "Train Epoch: 59 [222336/225000 (99%)] Loss: 19925.402344\n",
      "Train Epoch: 59 [224832/225000 (100%)] Loss: 20431.041016\n",
      "    epoch          : 59\n",
      "    loss           : 20093.982126906463\n",
      "    val_loss       : 19989.365207741277\n",
      "Train Epoch: 60 [192/225000 (0%)] Loss: 19803.015625\n",
      "Train Epoch: 60 [2688/225000 (1%)] Loss: 20202.710938\n",
      "Train Epoch: 60 [5184/225000 (2%)] Loss: 20035.632812\n",
      "Train Epoch: 60 [7680/225000 (3%)] Loss: 20105.855469\n",
      "Train Epoch: 60 [10176/225000 (5%)] Loss: 20427.490234\n",
      "Train Epoch: 60 [12672/225000 (6%)] Loss: 19437.035156\n",
      "Train Epoch: 60 [15168/225000 (7%)] Loss: 20188.179688\n",
      "Train Epoch: 60 [17664/225000 (8%)] Loss: 20381.916016\n",
      "Train Epoch: 60 [20160/225000 (9%)] Loss: 20094.988281\n",
      "Train Epoch: 60 [22656/225000 (10%)] Loss: 20256.980469\n",
      "Train Epoch: 60 [25152/225000 (11%)] Loss: 20172.654297\n",
      "Train Epoch: 60 [27648/225000 (12%)] Loss: 19776.070312\n",
      "Train Epoch: 60 [30144/225000 (13%)] Loss: 20087.476562\n",
      "Train Epoch: 60 [32640/225000 (15%)] Loss: 20332.707031\n",
      "Train Epoch: 60 [35136/225000 (16%)] Loss: 20516.703125\n",
      "Train Epoch: 60 [37632/225000 (17%)] Loss: 20188.824219\n",
      "Train Epoch: 60 [40128/225000 (18%)] Loss: 20530.171875\n",
      "Train Epoch: 60 [42624/225000 (19%)] Loss: 19641.792969\n",
      "Train Epoch: 60 [45120/225000 (20%)] Loss: 20049.890625\n",
      "Train Epoch: 60 [47616/225000 (21%)] Loss: 20672.304688\n",
      "Train Epoch: 60 [50112/225000 (22%)] Loss: 20090.226562\n",
      "Train Epoch: 60 [52608/225000 (23%)] Loss: 20397.480469\n",
      "Train Epoch: 60 [55104/225000 (24%)] Loss: 20447.585938\n",
      "Train Epoch: 60 [57600/225000 (26%)] Loss: 19918.453125\n",
      "Train Epoch: 60 [60096/225000 (27%)] Loss: 20016.972656\n",
      "Train Epoch: 60 [62592/225000 (28%)] Loss: 19981.671875\n",
      "Train Epoch: 60 [65088/225000 (29%)] Loss: 20064.578125\n",
      "Train Epoch: 60 [67584/225000 (30%)] Loss: 19595.781250\n",
      "Train Epoch: 60 [70080/225000 (31%)] Loss: 20058.882812\n",
      "Train Epoch: 60 [72576/225000 (32%)] Loss: 20067.740234\n",
      "Train Epoch: 60 [75072/225000 (33%)] Loss: 20392.685547\n",
      "Train Epoch: 60 [77568/225000 (34%)] Loss: 20383.894531\n",
      "Train Epoch: 60 [80064/225000 (36%)] Loss: 20233.921875\n",
      "Train Epoch: 60 [82560/225000 (37%)] Loss: 20529.921875\n",
      "Train Epoch: 60 [85056/225000 (38%)] Loss: 20300.484375\n",
      "Train Epoch: 60 [87552/225000 (39%)] Loss: 19961.685547\n",
      "Train Epoch: 60 [90048/225000 (40%)] Loss: 20160.175781\n",
      "Train Epoch: 60 [92544/225000 (41%)] Loss: 20160.882812\n",
      "Train Epoch: 60 [95040/225000 (42%)] Loss: 19515.197266\n",
      "Train Epoch: 60 [97536/225000 (43%)] Loss: 20395.404297\n",
      "Train Epoch: 60 [100032/225000 (44%)] Loss: 20357.490234\n",
      "Train Epoch: 60 [102528/225000 (46%)] Loss: 20356.099609\n",
      "Train Epoch: 60 [105024/225000 (47%)] Loss: 20057.470703\n",
      "Train Epoch: 60 [107520/225000 (48%)] Loss: 20147.425781\n",
      "Train Epoch: 60 [110016/225000 (49%)] Loss: 20145.371094\n",
      "Train Epoch: 60 [112512/225000 (50%)] Loss: 20073.769531\n",
      "Train Epoch: 60 [115008/225000 (51%)] Loss: 20332.755859\n",
      "Train Epoch: 60 [117504/225000 (52%)] Loss: 20125.443359\n",
      "Train Epoch: 60 [120000/225000 (53%)] Loss: 19957.472656\n",
      "Train Epoch: 60 [122496/225000 (54%)] Loss: 20433.578125\n",
      "Train Epoch: 60 [124992/225000 (56%)] Loss: 20409.941406\n",
      "Train Epoch: 60 [127488/225000 (57%)] Loss: 20115.886719\n",
      "Train Epoch: 60 [129984/225000 (58%)] Loss: 20311.609375\n",
      "Train Epoch: 60 [132480/225000 (59%)] Loss: 20214.953125\n",
      "Train Epoch: 60 [134976/225000 (60%)] Loss: 20257.675781\n",
      "Train Epoch: 60 [137472/225000 (61%)] Loss: 20190.406250\n",
      "Train Epoch: 60 [139968/225000 (62%)] Loss: 20265.035156\n",
      "Train Epoch: 60 [142464/225000 (63%)] Loss: 19757.869141\n",
      "Train Epoch: 60 [144960/225000 (64%)] Loss: 20144.980469\n",
      "Train Epoch: 60 [147456/225000 (66%)] Loss: 19788.416016\n",
      "Train Epoch: 60 [149952/225000 (67%)] Loss: 20325.980469\n",
      "Train Epoch: 60 [152448/225000 (68%)] Loss: 20125.595703\n",
      "Train Epoch: 60 [154944/225000 (69%)] Loss: 19584.828125\n",
      "Train Epoch: 60 [157440/225000 (70%)] Loss: 19919.810547\n",
      "Train Epoch: 60 [159936/225000 (71%)] Loss: 20578.750000\n",
      "Train Epoch: 60 [162432/225000 (72%)] Loss: 19878.099609\n",
      "Train Epoch: 60 [164928/225000 (73%)] Loss: 20245.851562\n",
      "Train Epoch: 60 [167424/225000 (74%)] Loss: 20290.392578\n",
      "Train Epoch: 60 [169920/225000 (76%)] Loss: 20087.820312\n",
      "Train Epoch: 60 [172416/225000 (77%)] Loss: 20619.191406\n",
      "Train Epoch: 60 [174912/225000 (78%)] Loss: 20159.750000\n",
      "Train Epoch: 60 [177408/225000 (79%)] Loss: 20117.406250\n",
      "Train Epoch: 60 [179904/225000 (80%)] Loss: 19974.031250\n",
      "Train Epoch: 60 [182400/225000 (81%)] Loss: 20517.230469\n",
      "Train Epoch: 60 [184896/225000 (82%)] Loss: 20529.417969\n",
      "Train Epoch: 60 [187392/225000 (83%)] Loss: 19601.650391\n",
      "Train Epoch: 60 [189888/225000 (84%)] Loss: 20302.933594\n",
      "Train Epoch: 60 [192384/225000 (86%)] Loss: 19826.154297\n",
      "Train Epoch: 60 [194880/225000 (87%)] Loss: 20143.531250\n",
      "Train Epoch: 60 [197376/225000 (88%)] Loss: 20257.328125\n",
      "Train Epoch: 60 [199872/225000 (89%)] Loss: 19813.996094\n",
      "Train Epoch: 60 [202368/225000 (90%)] Loss: 20020.238281\n",
      "Train Epoch: 60 [204864/225000 (91%)] Loss: 19499.523438\n",
      "Train Epoch: 60 [207360/225000 (92%)] Loss: 19882.648438\n",
      "Train Epoch: 60 [209856/225000 (93%)] Loss: 19971.832031\n",
      "Train Epoch: 60 [212352/225000 (94%)] Loss: 20416.699219\n",
      "Train Epoch: 60 [214848/225000 (95%)] Loss: 20652.808594\n",
      "Train Epoch: 60 [217344/225000 (97%)] Loss: 20131.714844\n",
      "Train Epoch: 60 [219840/225000 (98%)] Loss: 19810.679688\n",
      "Train Epoch: 60 [222336/225000 (99%)] Loss: 19937.939453\n",
      "Train Epoch: 60 [224832/225000 (100%)] Loss: 20587.148438\n",
      "    epoch          : 60\n",
      "    loss           : 20080.79783489761\n",
      "    val_loss       : 19978.880370578692\n",
      "Train Epoch: 61 [192/225000 (0%)] Loss: 19857.302734\n",
      "Train Epoch: 61 [2688/225000 (1%)] Loss: 20169.826172\n",
      "Train Epoch: 61 [5184/225000 (2%)] Loss: 19983.458984\n",
      "Train Epoch: 61 [7680/225000 (3%)] Loss: 19950.464844\n",
      "Train Epoch: 61 [10176/225000 (5%)] Loss: 20553.718750\n",
      "Train Epoch: 61 [12672/225000 (6%)] Loss: 19682.871094\n",
      "Train Epoch: 61 [15168/225000 (7%)] Loss: 19821.566406\n",
      "Train Epoch: 61 [17664/225000 (8%)] Loss: 19950.757812\n",
      "Train Epoch: 61 [20160/225000 (9%)] Loss: 20336.736328\n",
      "Train Epoch: 61 [22656/225000 (10%)] Loss: 19977.414062\n",
      "Train Epoch: 61 [25152/225000 (11%)] Loss: 20322.353516\n",
      "Train Epoch: 61 [27648/225000 (12%)] Loss: 19972.498047\n",
      "Train Epoch: 61 [30144/225000 (13%)] Loss: 20535.308594\n",
      "Train Epoch: 61 [32640/225000 (15%)] Loss: 20549.675781\n",
      "Train Epoch: 61 [35136/225000 (16%)] Loss: 20078.318359\n",
      "Train Epoch: 61 [37632/225000 (17%)] Loss: 20425.193359\n",
      "Train Epoch: 61 [40128/225000 (18%)] Loss: 19531.214844\n",
      "Train Epoch: 61 [42624/225000 (19%)] Loss: 20245.378906\n",
      "Train Epoch: 61 [45120/225000 (20%)] Loss: 20551.667969\n",
      "Train Epoch: 61 [47616/225000 (21%)] Loss: 19885.343750\n",
      "Train Epoch: 61 [50112/225000 (22%)] Loss: 20593.144531\n",
      "Train Epoch: 61 [52608/225000 (23%)] Loss: 19917.105469\n",
      "Train Epoch: 61 [55104/225000 (24%)] Loss: 20473.011719\n",
      "Train Epoch: 61 [57600/225000 (26%)] Loss: 19929.964844\n",
      "Train Epoch: 61 [60096/225000 (27%)] Loss: 20056.826172\n",
      "Train Epoch: 61 [62592/225000 (28%)] Loss: 19911.302734\n",
      "Train Epoch: 61 [65088/225000 (29%)] Loss: 20044.550781\n",
      "Train Epoch: 61 [67584/225000 (30%)] Loss: 20091.468750\n",
      "Train Epoch: 61 [70080/225000 (31%)] Loss: 19597.533203\n",
      "Train Epoch: 61 [72576/225000 (32%)] Loss: 20060.164062\n",
      "Train Epoch: 61 [75072/225000 (33%)] Loss: 19775.226562\n",
      "Train Epoch: 61 [77568/225000 (34%)] Loss: 19990.097656\n",
      "Train Epoch: 61 [80064/225000 (36%)] Loss: 19990.066406\n",
      "Train Epoch: 61 [82560/225000 (37%)] Loss: 20106.138672\n",
      "Train Epoch: 61 [85056/225000 (38%)] Loss: 20239.716797\n",
      "Train Epoch: 61 [87552/225000 (39%)] Loss: 19897.707031\n",
      "Train Epoch: 61 [90048/225000 (40%)] Loss: 19546.646484\n",
      "Train Epoch: 61 [92544/225000 (41%)] Loss: 19841.833984\n",
      "Train Epoch: 61 [95040/225000 (42%)] Loss: 20098.550781\n",
      "Train Epoch: 61 [97536/225000 (43%)] Loss: 20359.683594\n",
      "Train Epoch: 61 [100032/225000 (44%)] Loss: 20136.546875\n",
      "Train Epoch: 61 [102528/225000 (46%)] Loss: 20191.457031\n",
      "Train Epoch: 61 [105024/225000 (47%)] Loss: 20152.957031\n",
      "Train Epoch: 61 [107520/225000 (48%)] Loss: 19583.945312\n",
      "Train Epoch: 61 [110016/225000 (49%)] Loss: 19814.080078\n",
      "Train Epoch: 61 [112512/225000 (50%)] Loss: 19736.468750\n",
      "Train Epoch: 61 [115008/225000 (51%)] Loss: 20250.406250\n",
      "Train Epoch: 61 [117504/225000 (52%)] Loss: 19967.289062\n",
      "Train Epoch: 61 [120000/225000 (53%)] Loss: 19705.871094\n",
      "Train Epoch: 61 [122496/225000 (54%)] Loss: 19931.589844\n",
      "Train Epoch: 61 [124992/225000 (56%)] Loss: 20019.511719\n",
      "Train Epoch: 61 [127488/225000 (57%)] Loss: 19800.066406\n",
      "Train Epoch: 61 [129984/225000 (58%)] Loss: 20207.732422\n",
      "Train Epoch: 61 [132480/225000 (59%)] Loss: 19862.179688\n",
      "Train Epoch: 61 [134976/225000 (60%)] Loss: 19775.125000\n",
      "Train Epoch: 61 [137472/225000 (61%)] Loss: 20348.464844\n",
      "Train Epoch: 61 [139968/225000 (62%)] Loss: 20331.285156\n",
      "Train Epoch: 61 [142464/225000 (63%)] Loss: 20223.917969\n",
      "Train Epoch: 61 [144960/225000 (64%)] Loss: 20300.722656\n",
      "Train Epoch: 61 [147456/225000 (66%)] Loss: 20791.537109\n",
      "Train Epoch: 61 [149952/225000 (67%)] Loss: 20597.281250\n",
      "Train Epoch: 61 [152448/225000 (68%)] Loss: 20288.191406\n",
      "Train Epoch: 61 [154944/225000 (69%)] Loss: 20437.697266\n",
      "Train Epoch: 61 [157440/225000 (70%)] Loss: 19900.195312\n",
      "Train Epoch: 61 [159936/225000 (71%)] Loss: 19708.021484\n",
      "Train Epoch: 61 [162432/225000 (72%)] Loss: 20069.062500\n",
      "Train Epoch: 61 [164928/225000 (73%)] Loss: 20021.550781\n",
      "Train Epoch: 61 [167424/225000 (74%)] Loss: 19994.080078\n",
      "Train Epoch: 61 [169920/225000 (76%)] Loss: 19790.882812\n",
      "Train Epoch: 61 [172416/225000 (77%)] Loss: 19860.105469\n",
      "Train Epoch: 61 [174912/225000 (78%)] Loss: 19424.458984\n",
      "Train Epoch: 61 [177408/225000 (79%)] Loss: 19900.839844\n",
      "Train Epoch: 61 [179904/225000 (80%)] Loss: 19482.972656\n",
      "Train Epoch: 61 [182400/225000 (81%)] Loss: 20527.912109\n",
      "Train Epoch: 61 [184896/225000 (82%)] Loss: 19932.666016\n",
      "Train Epoch: 61 [187392/225000 (83%)] Loss: 19899.601562\n",
      "Train Epoch: 61 [189888/225000 (84%)] Loss: 19948.607422\n",
      "Train Epoch: 61 [192384/225000 (86%)] Loss: 20307.158203\n",
      "Train Epoch: 61 [194880/225000 (87%)] Loss: 19861.863281\n",
      "Train Epoch: 61 [197376/225000 (88%)] Loss: 20082.960938\n",
      "Train Epoch: 61 [199872/225000 (89%)] Loss: 19807.041016\n",
      "Train Epoch: 61 [202368/225000 (90%)] Loss: 19854.175781\n",
      "Train Epoch: 61 [204864/225000 (91%)] Loss: 19763.214844\n",
      "Train Epoch: 61 [207360/225000 (92%)] Loss: 19425.859375\n",
      "Train Epoch: 61 [209856/225000 (93%)] Loss: 20345.910156\n",
      "Train Epoch: 61 [212352/225000 (94%)] Loss: 20066.216797\n",
      "Train Epoch: 61 [214848/225000 (95%)] Loss: 20573.738281\n",
      "Train Epoch: 61 [217344/225000 (97%)] Loss: 19978.839844\n",
      "Train Epoch: 61 [219840/225000 (98%)] Loss: 20291.617188\n",
      "Train Epoch: 61 [222336/225000 (99%)] Loss: 20353.296875\n",
      "Train Epoch: 61 [224832/225000 (100%)] Loss: 19378.429688\n",
      "    epoch          : 61\n",
      "    loss           : 20077.682643851324\n",
      "    val_loss       : 19995.062565055512\n",
      "Train Epoch: 62 [192/225000 (0%)] Loss: 19990.457031\n",
      "Train Epoch: 62 [2688/225000 (1%)] Loss: 19902.531250\n",
      "Train Epoch: 62 [5184/225000 (2%)] Loss: 20104.580078\n",
      "Train Epoch: 62 [7680/225000 (3%)] Loss: 19725.363281\n",
      "Train Epoch: 62 [10176/225000 (5%)] Loss: 20387.572266\n",
      "Train Epoch: 62 [12672/225000 (6%)] Loss: 20277.187500\n",
      "Train Epoch: 62 [15168/225000 (7%)] Loss: 19537.480469\n",
      "Train Epoch: 62 [17664/225000 (8%)] Loss: 19553.181641\n",
      "Train Epoch: 62 [20160/225000 (9%)] Loss: 19966.292969\n",
      "Train Epoch: 62 [22656/225000 (10%)] Loss: 20635.511719\n",
      "Train Epoch: 62 [25152/225000 (11%)] Loss: 20045.443359\n",
      "Train Epoch: 62 [27648/225000 (12%)] Loss: 20258.589844\n",
      "Train Epoch: 62 [30144/225000 (13%)] Loss: 19936.765625\n",
      "Train Epoch: 62 [32640/225000 (15%)] Loss: 20202.027344\n",
      "Train Epoch: 62 [35136/225000 (16%)] Loss: 19665.257812\n",
      "Train Epoch: 62 [37632/225000 (17%)] Loss: 19699.593750\n",
      "Train Epoch: 62 [40128/225000 (18%)] Loss: 20129.296875\n",
      "Train Epoch: 62 [42624/225000 (19%)] Loss: 20200.140625\n",
      "Train Epoch: 62 [45120/225000 (20%)] Loss: 19869.044922\n",
      "Train Epoch: 62 [47616/225000 (21%)] Loss: 20018.492188\n",
      "Train Epoch: 62 [50112/225000 (22%)] Loss: 19985.841797\n",
      "Train Epoch: 62 [52608/225000 (23%)] Loss: 20136.410156\n",
      "Train Epoch: 62 [55104/225000 (24%)] Loss: 19897.658203\n",
      "Train Epoch: 62 [57600/225000 (26%)] Loss: 20063.562500\n",
      "Train Epoch: 62 [60096/225000 (27%)] Loss: 20285.304688\n",
      "Train Epoch: 62 [62592/225000 (28%)] Loss: 20343.714844\n",
      "Train Epoch: 62 [65088/225000 (29%)] Loss: 20317.443359\n",
      "Train Epoch: 62 [67584/225000 (30%)] Loss: 19580.222656\n",
      "Train Epoch: 62 [70080/225000 (31%)] Loss: 20013.375000\n",
      "Train Epoch: 62 [72576/225000 (32%)] Loss: 20354.458984\n",
      "Train Epoch: 62 [75072/225000 (33%)] Loss: 20240.689453\n",
      "Train Epoch: 62 [77568/225000 (34%)] Loss: 20348.449219\n",
      "Train Epoch: 62 [80064/225000 (36%)] Loss: 20036.199219\n",
      "Train Epoch: 62 [82560/225000 (37%)] Loss: 19980.199219\n",
      "Train Epoch: 62 [85056/225000 (38%)] Loss: 20397.152344\n",
      "Train Epoch: 62 [87552/225000 (39%)] Loss: 19879.017578\n",
      "Train Epoch: 62 [90048/225000 (40%)] Loss: 19818.445312\n",
      "Train Epoch: 62 [92544/225000 (41%)] Loss: 20434.513672\n",
      "Train Epoch: 62 [95040/225000 (42%)] Loss: 20609.507812\n",
      "Train Epoch: 62 [97536/225000 (43%)] Loss: 19779.199219\n",
      "Train Epoch: 62 [100032/225000 (44%)] Loss: 20539.679688\n",
      "Train Epoch: 62 [102528/225000 (46%)] Loss: 19906.609375\n",
      "Train Epoch: 62 [105024/225000 (47%)] Loss: 20241.058594\n",
      "Train Epoch: 62 [107520/225000 (48%)] Loss: 19609.839844\n",
      "Train Epoch: 62 [110016/225000 (49%)] Loss: 20234.871094\n",
      "Train Epoch: 62 [112512/225000 (50%)] Loss: 19842.734375\n",
      "Train Epoch: 62 [115008/225000 (51%)] Loss: 20352.781250\n",
      "Train Epoch: 62 [117504/225000 (52%)] Loss: 19717.523438\n",
      "Train Epoch: 62 [120000/225000 (53%)] Loss: 20035.890625\n",
      "Train Epoch: 62 [122496/225000 (54%)] Loss: 20445.091797\n",
      "Train Epoch: 62 [124992/225000 (56%)] Loss: 19736.750000\n",
      "Train Epoch: 62 [127488/225000 (57%)] Loss: 20177.871094\n",
      "Train Epoch: 62 [129984/225000 (58%)] Loss: 20340.113281\n",
      "Train Epoch: 62 [132480/225000 (59%)] Loss: 19841.679688\n",
      "Train Epoch: 62 [134976/225000 (60%)] Loss: 20055.929688\n",
      "Train Epoch: 62 [137472/225000 (61%)] Loss: 20164.714844\n",
      "Train Epoch: 62 [139968/225000 (62%)] Loss: 19803.121094\n",
      "Train Epoch: 62 [142464/225000 (63%)] Loss: 19735.285156\n",
      "Train Epoch: 62 [144960/225000 (64%)] Loss: 19745.105469\n",
      "Train Epoch: 62 [147456/225000 (66%)] Loss: 20168.625000\n",
      "Train Epoch: 62 [149952/225000 (67%)] Loss: 19598.867188\n",
      "Train Epoch: 62 [152448/225000 (68%)] Loss: 20007.695312\n",
      "Train Epoch: 62 [154944/225000 (69%)] Loss: 19599.843750\n",
      "Train Epoch: 62 [157440/225000 (70%)] Loss: 20739.029297\n",
      "Train Epoch: 62 [159936/225000 (71%)] Loss: 20191.197266\n",
      "Train Epoch: 62 [162432/225000 (72%)] Loss: 20518.169922\n",
      "Train Epoch: 62 [164928/225000 (73%)] Loss: 20039.037109\n",
      "Train Epoch: 62 [167424/225000 (74%)] Loss: 19940.687500\n",
      "Train Epoch: 62 [169920/225000 (76%)] Loss: 20285.880859\n",
      "Train Epoch: 62 [172416/225000 (77%)] Loss: 19820.097656\n",
      "Train Epoch: 62 [174912/225000 (78%)] Loss: 20328.775391\n",
      "Train Epoch: 62 [177408/225000 (79%)] Loss: 19931.974609\n",
      "Train Epoch: 62 [179904/225000 (80%)] Loss: 20372.466797\n",
      "Train Epoch: 62 [182400/225000 (81%)] Loss: 20366.042969\n",
      "Train Epoch: 62 [184896/225000 (82%)] Loss: 20217.617188\n",
      "Train Epoch: 62 [187392/225000 (83%)] Loss: 20364.478516\n",
      "Train Epoch: 62 [189888/225000 (84%)] Loss: 20266.720703\n",
      "Train Epoch: 62 [192384/225000 (86%)] Loss: 20016.679688\n",
      "Train Epoch: 62 [194880/225000 (87%)] Loss: 19924.953125\n",
      "Train Epoch: 62 [197376/225000 (88%)] Loss: 20179.972656\n",
      "Train Epoch: 62 [199872/225000 (89%)] Loss: 20427.931641\n",
      "Train Epoch: 62 [202368/225000 (90%)] Loss: 20334.910156\n",
      "Train Epoch: 62 [204864/225000 (91%)] Loss: 19816.953125\n",
      "Train Epoch: 62 [207360/225000 (92%)] Loss: 20137.906250\n",
      "Train Epoch: 62 [209856/225000 (93%)] Loss: 19821.535156\n",
      "Train Epoch: 62 [212352/225000 (94%)] Loss: 19858.236328\n",
      "Train Epoch: 62 [214848/225000 (95%)] Loss: 19705.011719\n",
      "Train Epoch: 62 [217344/225000 (97%)] Loss: 20348.488281\n",
      "Train Epoch: 62 [219840/225000 (98%)] Loss: 19646.404297\n",
      "Train Epoch: 62 [222336/225000 (99%)] Loss: 19832.894531\n",
      "Train Epoch: 62 [224832/225000 (100%)] Loss: 19859.660156\n",
      "    epoch          : 62\n",
      "    loss           : 20055.121793675342\n",
      "    val_loss       : 19971.817452567226\n",
      "Train Epoch: 63 [192/225000 (0%)] Loss: 19855.177734\n",
      "Train Epoch: 63 [2688/225000 (1%)] Loss: 20439.964844\n",
      "Train Epoch: 63 [5184/225000 (2%)] Loss: 19931.265625\n",
      "Train Epoch: 63 [7680/225000 (3%)] Loss: 20034.031250\n",
      "Train Epoch: 63 [10176/225000 (5%)] Loss: 19927.964844\n",
      "Train Epoch: 63 [12672/225000 (6%)] Loss: 20113.371094\n",
      "Train Epoch: 63 [15168/225000 (7%)] Loss: 19852.033203\n",
      "Train Epoch: 63 [17664/225000 (8%)] Loss: 20910.132812\n",
      "Train Epoch: 63 [20160/225000 (9%)] Loss: 19742.421875\n",
      "Train Epoch: 63 [22656/225000 (10%)] Loss: 20293.933594\n",
      "Train Epoch: 63 [25152/225000 (11%)] Loss: 20226.601562\n",
      "Train Epoch: 63 [27648/225000 (12%)] Loss: 20327.796875\n",
      "Train Epoch: 63 [30144/225000 (13%)] Loss: 19777.789062\n",
      "Train Epoch: 63 [32640/225000 (15%)] Loss: 19947.810547\n",
      "Train Epoch: 63 [35136/225000 (16%)] Loss: 20494.162109\n",
      "Train Epoch: 63 [37632/225000 (17%)] Loss: 20025.220703\n",
      "Train Epoch: 63 [40128/225000 (18%)] Loss: 20337.191406\n",
      "Train Epoch: 63 [42624/225000 (19%)] Loss: 20250.435547\n",
      "Train Epoch: 63 [45120/225000 (20%)] Loss: 20235.378906\n",
      "Train Epoch: 63 [47616/225000 (21%)] Loss: 20286.703125\n",
      "Train Epoch: 63 [50112/225000 (22%)] Loss: 20004.535156\n",
      "Train Epoch: 63 [52608/225000 (23%)] Loss: 19705.060547\n",
      "Train Epoch: 63 [55104/225000 (24%)] Loss: 20257.255859\n",
      "Train Epoch: 63 [57600/225000 (26%)] Loss: 20151.785156\n",
      "Train Epoch: 63 [60096/225000 (27%)] Loss: 20012.195312\n",
      "Train Epoch: 63 [62592/225000 (28%)] Loss: 20533.349609\n",
      "Train Epoch: 63 [65088/225000 (29%)] Loss: 20452.781250\n",
      "Train Epoch: 63 [67584/225000 (30%)] Loss: 20289.232422\n",
      "Train Epoch: 63 [70080/225000 (31%)] Loss: 19985.582031\n",
      "Train Epoch: 63 [72576/225000 (32%)] Loss: 20276.960938\n",
      "Train Epoch: 63 [75072/225000 (33%)] Loss: 19935.132812\n",
      "Train Epoch: 63 [77568/225000 (34%)] Loss: 20184.375000\n",
      "Train Epoch: 63 [80064/225000 (36%)] Loss: 19744.728516\n",
      "Train Epoch: 63 [82560/225000 (37%)] Loss: 19585.496094\n",
      "Train Epoch: 63 [85056/225000 (38%)] Loss: 19520.787109\n",
      "Train Epoch: 63 [87552/225000 (39%)] Loss: 20085.628906\n",
      "Train Epoch: 63 [90048/225000 (40%)] Loss: 19689.656250\n",
      "Train Epoch: 63 [92544/225000 (41%)] Loss: 20045.175781\n",
      "Train Epoch: 63 [95040/225000 (42%)] Loss: 19782.921875\n",
      "Train Epoch: 63 [97536/225000 (43%)] Loss: 20379.164062\n",
      "Train Epoch: 63 [100032/225000 (44%)] Loss: 19960.767578\n",
      "Train Epoch: 63 [102528/225000 (46%)] Loss: 19832.578125\n",
      "Train Epoch: 63 [105024/225000 (47%)] Loss: 19977.705078\n",
      "Train Epoch: 63 [107520/225000 (48%)] Loss: 19685.875000\n",
      "Train Epoch: 63 [110016/225000 (49%)] Loss: 20174.126953\n",
      "Train Epoch: 63 [112512/225000 (50%)] Loss: 19851.570312\n",
      "Train Epoch: 63 [115008/225000 (51%)] Loss: 20071.669922\n",
      "Train Epoch: 63 [117504/225000 (52%)] Loss: 19707.757812\n",
      "Train Epoch: 63 [120000/225000 (53%)] Loss: 19993.742188\n",
      "Train Epoch: 63 [122496/225000 (54%)] Loss: 20543.808594\n",
      "Train Epoch: 63 [124992/225000 (56%)] Loss: 19701.519531\n",
      "Train Epoch: 63 [127488/225000 (57%)] Loss: 20029.232422\n",
      "Train Epoch: 63 [129984/225000 (58%)] Loss: 19996.597656\n",
      "Train Epoch: 63 [132480/225000 (59%)] Loss: 20061.960938\n",
      "Train Epoch: 63 [134976/225000 (60%)] Loss: 20027.921875\n",
      "Train Epoch: 63 [137472/225000 (61%)] Loss: 19784.644531\n",
      "Train Epoch: 63 [139968/225000 (62%)] Loss: 19718.486328\n",
      "Train Epoch: 63 [142464/225000 (63%)] Loss: 20125.802734\n",
      "Train Epoch: 63 [144960/225000 (64%)] Loss: 19735.300781\n",
      "Train Epoch: 63 [147456/225000 (66%)] Loss: 20634.175781\n",
      "Train Epoch: 63 [149952/225000 (67%)] Loss: 19726.666016\n",
      "Train Epoch: 63 [152448/225000 (68%)] Loss: 19661.804688\n",
      "Train Epoch: 63 [154944/225000 (69%)] Loss: 20526.904297\n",
      "Train Epoch: 63 [157440/225000 (70%)] Loss: 20134.386719\n",
      "Train Epoch: 63 [159936/225000 (71%)] Loss: 20412.748047\n",
      "Train Epoch: 63 [162432/225000 (72%)] Loss: 20034.876953\n",
      "Train Epoch: 63 [164928/225000 (73%)] Loss: 19866.255859\n",
      "Train Epoch: 63 [167424/225000 (74%)] Loss: 19830.843750\n",
      "Train Epoch: 63 [169920/225000 (76%)] Loss: 20111.134766\n",
      "Train Epoch: 63 [172416/225000 (77%)] Loss: 19669.091797\n",
      "Train Epoch: 63 [174912/225000 (78%)] Loss: 19872.419922\n",
      "Train Epoch: 63 [177408/225000 (79%)] Loss: 19895.910156\n",
      "Train Epoch: 63 [179904/225000 (80%)] Loss: 19637.218750\n",
      "Train Epoch: 63 [182400/225000 (81%)] Loss: 19767.300781\n",
      "Train Epoch: 63 [184896/225000 (82%)] Loss: 19785.466797\n",
      "Train Epoch: 63 [187392/225000 (83%)] Loss: 20118.750000\n",
      "Train Epoch: 63 [189888/225000 (84%)] Loss: 20459.498047\n",
      "Train Epoch: 63 [192384/225000 (86%)] Loss: 20261.437500\n",
      "Train Epoch: 63 [194880/225000 (87%)] Loss: 20121.476562\n",
      "Train Epoch: 63 [197376/225000 (88%)] Loss: 19669.312500\n",
      "Train Epoch: 63 [199872/225000 (89%)] Loss: 19940.816406\n",
      "Train Epoch: 63 [202368/225000 (90%)] Loss: 20052.490234\n",
      "Train Epoch: 63 [204864/225000 (91%)] Loss: 20114.187500\n",
      "Train Epoch: 63 [207360/225000 (92%)] Loss: 20202.728516\n",
      "Train Epoch: 63 [209856/225000 (93%)] Loss: 20032.144531\n",
      "Train Epoch: 63 [212352/225000 (94%)] Loss: 20342.843750\n",
      "Train Epoch: 63 [214848/225000 (95%)] Loss: 20024.816406\n",
      "Train Epoch: 63 [217344/225000 (97%)] Loss: 19515.207031\n",
      "Train Epoch: 63 [219840/225000 (98%)] Loss: 20354.486328\n",
      "Train Epoch: 63 [222336/225000 (99%)] Loss: 20117.925781\n",
      "Train Epoch: 63 [224832/225000 (100%)] Loss: 20380.144531\n",
      "    epoch          : 63\n",
      "    loss           : 20032.782109908276\n",
      "    val_loss       : 19919.032272646444\n",
      "Train Epoch: 64 [192/225000 (0%)] Loss: 19946.203125\n",
      "Train Epoch: 64 [2688/225000 (1%)] Loss: 20438.324219\n",
      "Train Epoch: 64 [5184/225000 (2%)] Loss: 19935.199219\n",
      "Train Epoch: 64 [7680/225000 (3%)] Loss: 19900.957031\n",
      "Train Epoch: 64 [10176/225000 (5%)] Loss: 19809.484375\n",
      "Train Epoch: 64 [12672/225000 (6%)] Loss: 20341.458984\n",
      "Train Epoch: 64 [15168/225000 (7%)] Loss: 20359.070312\n",
      "Train Epoch: 64 [17664/225000 (8%)] Loss: 19901.140625\n",
      "Train Epoch: 64 [20160/225000 (9%)] Loss: 20341.257812\n",
      "Train Epoch: 64 [22656/225000 (10%)] Loss: 19915.128906\n",
      "Train Epoch: 64 [25152/225000 (11%)] Loss: 19796.248047\n",
      "Train Epoch: 64 [27648/225000 (12%)] Loss: 19612.414062\n",
      "Train Epoch: 64 [30144/225000 (13%)] Loss: 20089.451172\n",
      "Train Epoch: 64 [32640/225000 (15%)] Loss: 19642.890625\n",
      "Train Epoch: 64 [35136/225000 (16%)] Loss: 20092.085938\n",
      "Train Epoch: 64 [37632/225000 (17%)] Loss: 20049.292969\n",
      "Train Epoch: 64 [40128/225000 (18%)] Loss: 19962.417969\n",
      "Train Epoch: 64 [42624/225000 (19%)] Loss: 19542.925781\n",
      "Train Epoch: 64 [45120/225000 (20%)] Loss: 19867.031250\n",
      "Train Epoch: 64 [47616/225000 (21%)] Loss: 19443.228516\n",
      "Train Epoch: 64 [50112/225000 (22%)] Loss: 19994.539062\n",
      "Train Epoch: 64 [52608/225000 (23%)] Loss: 20181.082031\n",
      "Train Epoch: 64 [55104/225000 (24%)] Loss: 19625.394531\n",
      "Train Epoch: 64 [57600/225000 (26%)] Loss: 19620.589844\n",
      "Train Epoch: 64 [60096/225000 (27%)] Loss: 20026.488281\n",
      "Train Epoch: 64 [62592/225000 (28%)] Loss: 19911.878906\n",
      "Train Epoch: 64 [65088/225000 (29%)] Loss: 19972.923828\n",
      "Train Epoch: 64 [67584/225000 (30%)] Loss: 19627.062500\n",
      "Train Epoch: 64 [70080/225000 (31%)] Loss: 19616.980469\n",
      "Train Epoch: 64 [72576/225000 (32%)] Loss: 19606.632812\n",
      "Train Epoch: 64 [75072/225000 (33%)] Loss: 20364.593750\n",
      "Train Epoch: 64 [77568/225000 (34%)] Loss: 19864.304688\n",
      "Train Epoch: 64 [80064/225000 (36%)] Loss: 20077.019531\n",
      "Train Epoch: 64 [82560/225000 (37%)] Loss: 19544.714844\n",
      "Train Epoch: 64 [85056/225000 (38%)] Loss: 19756.390625\n",
      "Train Epoch: 64 [87552/225000 (39%)] Loss: 20019.691406\n",
      "Train Epoch: 64 [90048/225000 (40%)] Loss: 19482.548828\n",
      "Train Epoch: 64 [92544/225000 (41%)] Loss: 20185.853516\n",
      "Train Epoch: 64 [95040/225000 (42%)] Loss: 20269.238281\n",
      "Train Epoch: 64 [97536/225000 (43%)] Loss: 34691.203125\n",
      "Train Epoch: 64 [100032/225000 (44%)] Loss: 19784.316406\n",
      "Train Epoch: 64 [102528/225000 (46%)] Loss: 20090.001953\n",
      "Train Epoch: 64 [105024/225000 (47%)] Loss: 20180.005859\n",
      "Train Epoch: 64 [107520/225000 (48%)] Loss: 19755.417969\n",
      "Train Epoch: 64 [110016/225000 (49%)] Loss: 19649.238281\n",
      "Train Epoch: 64 [112512/225000 (50%)] Loss: 19675.828125\n",
      "Train Epoch: 64 [115008/225000 (51%)] Loss: 19979.791016\n",
      "Train Epoch: 64 [117504/225000 (52%)] Loss: 20028.031250\n",
      "Train Epoch: 64 [120000/225000 (53%)] Loss: 19590.751953\n",
      "Train Epoch: 64 [122496/225000 (54%)] Loss: 19891.761719\n",
      "Train Epoch: 64 [124992/225000 (56%)] Loss: 20146.328125\n",
      "Train Epoch: 64 [127488/225000 (57%)] Loss: 19786.921875\n",
      "Train Epoch: 64 [129984/225000 (58%)] Loss: 20030.136719\n",
      "Train Epoch: 64 [132480/225000 (59%)] Loss: 19636.804688\n",
      "Train Epoch: 64 [134976/225000 (60%)] Loss: 19934.349609\n",
      "Train Epoch: 64 [137472/225000 (61%)] Loss: 20107.453125\n",
      "Train Epoch: 64 [139968/225000 (62%)] Loss: 20489.648438\n",
      "Train Epoch: 64 [142464/225000 (63%)] Loss: 20018.847656\n",
      "Train Epoch: 64 [144960/225000 (64%)] Loss: 19710.515625\n",
      "Train Epoch: 64 [147456/225000 (66%)] Loss: 19829.429688\n",
      "Train Epoch: 64 [149952/225000 (67%)] Loss: 19729.843750\n",
      "Train Epoch: 64 [152448/225000 (68%)] Loss: 19856.300781\n",
      "Train Epoch: 64 [154944/225000 (69%)] Loss: 19965.691406\n",
      "Train Epoch: 64 [157440/225000 (70%)] Loss: 20105.406250\n",
      "Train Epoch: 64 [159936/225000 (71%)] Loss: 19631.250000\n",
      "Train Epoch: 64 [162432/225000 (72%)] Loss: 19324.796875\n",
      "Train Epoch: 64 [164928/225000 (73%)] Loss: 19812.597656\n",
      "Train Epoch: 64 [167424/225000 (74%)] Loss: 19898.554688\n",
      "Train Epoch: 64 [169920/225000 (76%)] Loss: 19750.033203\n",
      "Train Epoch: 64 [172416/225000 (77%)] Loss: 19564.808594\n",
      "Train Epoch: 64 [174912/225000 (78%)] Loss: 19910.203125\n",
      "Train Epoch: 64 [177408/225000 (79%)] Loss: 20514.726562\n",
      "Train Epoch: 64 [179904/225000 (80%)] Loss: 20310.136719\n",
      "Train Epoch: 64 [182400/225000 (81%)] Loss: 20101.511719\n",
      "Train Epoch: 64 [184896/225000 (82%)] Loss: 20141.105469\n",
      "Train Epoch: 64 [187392/225000 (83%)] Loss: 20309.949219\n",
      "Train Epoch: 64 [189888/225000 (84%)] Loss: 20526.066406\n",
      "Train Epoch: 64 [192384/225000 (86%)] Loss: 19836.644531\n",
      "Train Epoch: 64 [194880/225000 (87%)] Loss: 20210.078125\n",
      "Train Epoch: 64 [197376/225000 (88%)] Loss: 19441.136719\n",
      "Train Epoch: 64 [199872/225000 (89%)] Loss: 20084.636719\n",
      "Train Epoch: 64 [202368/225000 (90%)] Loss: 19832.630859\n",
      "Train Epoch: 64 [204864/225000 (91%)] Loss: 19652.779297\n",
      "Train Epoch: 64 [207360/225000 (92%)] Loss: 19764.007812\n",
      "Train Epoch: 64 [209856/225000 (93%)] Loss: 19854.447266\n",
      "Train Epoch: 64 [212352/225000 (94%)] Loss: 20167.902344\n",
      "Train Epoch: 64 [214848/225000 (95%)] Loss: 19935.007812\n",
      "Train Epoch: 64 [217344/225000 (97%)] Loss: 19583.732422\n",
      "Train Epoch: 64 [219840/225000 (98%)] Loss: 20051.265625\n",
      "Train Epoch: 64 [222336/225000 (99%)] Loss: 19658.164062\n",
      "Train Epoch: 64 [224832/225000 (100%)] Loss: 19887.880859\n",
      "    epoch          : 64\n",
      "    loss           : 19997.91774044102\n",
      "    val_loss       : 19868.80508492648\n",
      "Train Epoch: 65 [192/225000 (0%)] Loss: 19713.765625\n",
      "Train Epoch: 65 [2688/225000 (1%)] Loss: 20146.679688\n",
      "Train Epoch: 65 [5184/225000 (2%)] Loss: 19966.886719\n",
      "Train Epoch: 65 [7680/225000 (3%)] Loss: 19549.927734\n",
      "Train Epoch: 65 [10176/225000 (5%)] Loss: 20290.464844\n",
      "Train Epoch: 65 [12672/225000 (6%)] Loss: 19842.677734\n",
      "Train Epoch: 65 [15168/225000 (7%)] Loss: 19735.921875\n",
      "Train Epoch: 65 [17664/225000 (8%)] Loss: 20013.656250\n",
      "Train Epoch: 65 [20160/225000 (9%)] Loss: 20293.136719\n",
      "Train Epoch: 65 [22656/225000 (10%)] Loss: 19895.363281\n",
      "Train Epoch: 65 [25152/225000 (11%)] Loss: 19524.242188\n",
      "Train Epoch: 65 [27648/225000 (12%)] Loss: 20294.578125\n",
      "Train Epoch: 65 [30144/225000 (13%)] Loss: 19976.148438\n",
      "Train Epoch: 65 [32640/225000 (15%)] Loss: 20108.273438\n",
      "Train Epoch: 65 [35136/225000 (16%)] Loss: 19711.214844\n",
      "Train Epoch: 65 [37632/225000 (17%)] Loss: 19489.582031\n",
      "Train Epoch: 65 [40128/225000 (18%)] Loss: 20004.109375\n",
      "Train Epoch: 65 [42624/225000 (19%)] Loss: 20153.906250\n",
      "Train Epoch: 65 [45120/225000 (20%)] Loss: 19892.363281\n",
      "Train Epoch: 65 [47616/225000 (21%)] Loss: 20017.800781\n",
      "Train Epoch: 65 [50112/225000 (22%)] Loss: 19765.492188\n",
      "Train Epoch: 65 [52608/225000 (23%)] Loss: 19622.089844\n",
      "Train Epoch: 65 [55104/225000 (24%)] Loss: 19510.484375\n",
      "Train Epoch: 65 [57600/225000 (26%)] Loss: 19963.914062\n",
      "Train Epoch: 65 [60096/225000 (27%)] Loss: 19828.355469\n",
      "Train Epoch: 65 [62592/225000 (28%)] Loss: 19873.080078\n",
      "Train Epoch: 65 [65088/225000 (29%)] Loss: 19756.183594\n",
      "Train Epoch: 65 [67584/225000 (30%)] Loss: 19683.929688\n",
      "Train Epoch: 65 [70080/225000 (31%)] Loss: 19717.937500\n",
      "Train Epoch: 65 [72576/225000 (32%)] Loss: 20009.285156\n",
      "Train Epoch: 65 [75072/225000 (33%)] Loss: 19884.273438\n",
      "Train Epoch: 65 [77568/225000 (34%)] Loss: 19733.148438\n",
      "Train Epoch: 65 [80064/225000 (36%)] Loss: 19839.529297\n",
      "Train Epoch: 65 [82560/225000 (37%)] Loss: 20052.679688\n",
      "Train Epoch: 65 [85056/225000 (38%)] Loss: 19891.410156\n",
      "Train Epoch: 65 [87552/225000 (39%)] Loss: 20511.412109\n",
      "Train Epoch: 65 [90048/225000 (40%)] Loss: 19753.726562\n",
      "Train Epoch: 65 [92544/225000 (41%)] Loss: 19657.355469\n",
      "Train Epoch: 65 [95040/225000 (42%)] Loss: 19365.621094\n",
      "Train Epoch: 65 [97536/225000 (43%)] Loss: 20114.312500\n",
      "Train Epoch: 65 [100032/225000 (44%)] Loss: 19469.597656\n",
      "Train Epoch: 65 [102528/225000 (46%)] Loss: 19784.365234\n",
      "Train Epoch: 65 [105024/225000 (47%)] Loss: 19745.128906\n",
      "Train Epoch: 65 [107520/225000 (48%)] Loss: 19939.388672\n",
      "Train Epoch: 65 [110016/225000 (49%)] Loss: 20242.605469\n",
      "Train Epoch: 65 [112512/225000 (50%)] Loss: 19904.355469\n",
      "Train Epoch: 65 [115008/225000 (51%)] Loss: 19596.796875\n",
      "Train Epoch: 65 [117504/225000 (52%)] Loss: 19674.753906\n",
      "Train Epoch: 65 [120000/225000 (53%)] Loss: 20191.505859\n",
      "Train Epoch: 65 [122496/225000 (54%)] Loss: 20185.699219\n",
      "Train Epoch: 65 [124992/225000 (56%)] Loss: 19634.216797\n",
      "Train Epoch: 65 [127488/225000 (57%)] Loss: 20133.818359\n",
      "Train Epoch: 65 [129984/225000 (58%)] Loss: 19633.902344\n",
      "Train Epoch: 65 [132480/225000 (59%)] Loss: 20357.218750\n",
      "Train Epoch: 65 [134976/225000 (60%)] Loss: 19629.101562\n",
      "Train Epoch: 65 [137472/225000 (61%)] Loss: 20174.763672\n",
      "Train Epoch: 65 [139968/225000 (62%)] Loss: 19924.078125\n",
      "Train Epoch: 65 [142464/225000 (63%)] Loss: 19965.062500\n",
      "Train Epoch: 65 [144960/225000 (64%)] Loss: 19908.640625\n",
      "Train Epoch: 65 [147456/225000 (66%)] Loss: 20148.906250\n",
      "Train Epoch: 65 [149952/225000 (67%)] Loss: 20114.248047\n",
      "Train Epoch: 65 [152448/225000 (68%)] Loss: 20081.070312\n",
      "Train Epoch: 65 [154944/225000 (69%)] Loss: 19584.507812\n",
      "Train Epoch: 65 [157440/225000 (70%)] Loss: 19789.146484\n",
      "Train Epoch: 65 [159936/225000 (71%)] Loss: 19868.105469\n",
      "Train Epoch: 65 [162432/225000 (72%)] Loss: 20462.718750\n",
      "Train Epoch: 65 [164928/225000 (73%)] Loss: 20092.835938\n",
      "Train Epoch: 65 [167424/225000 (74%)] Loss: 19948.503906\n",
      "Train Epoch: 65 [169920/225000 (76%)] Loss: 19895.699219\n",
      "Train Epoch: 65 [172416/225000 (77%)] Loss: 20091.121094\n",
      "Train Epoch: 65 [174912/225000 (78%)] Loss: 19277.398438\n",
      "Train Epoch: 65 [177408/225000 (79%)] Loss: 20085.023438\n",
      "Train Epoch: 65 [179904/225000 (80%)] Loss: 19830.611328\n",
      "Train Epoch: 65 [182400/225000 (81%)] Loss: 19658.339844\n",
      "Train Epoch: 65 [184896/225000 (82%)] Loss: 19815.767578\n",
      "Train Epoch: 65 [187392/225000 (83%)] Loss: 19672.173828\n",
      "Train Epoch: 65 [189888/225000 (84%)] Loss: 19619.972656\n",
      "Train Epoch: 65 [192384/225000 (86%)] Loss: 19605.007812\n",
      "Train Epoch: 65 [194880/225000 (87%)] Loss: 20207.707031\n",
      "Train Epoch: 65 [197376/225000 (88%)] Loss: 20269.675781\n",
      "Train Epoch: 65 [199872/225000 (89%)] Loss: 19821.556641\n",
      "Train Epoch: 65 [202368/225000 (90%)] Loss: 19376.082031\n",
      "Train Epoch: 65 [204864/225000 (91%)] Loss: 20015.453125\n",
      "Train Epoch: 65 [207360/225000 (92%)] Loss: 19670.226562\n",
      "Train Epoch: 65 [209856/225000 (93%)] Loss: 19930.185547\n",
      "Train Epoch: 65 [212352/225000 (94%)] Loss: 20479.539062\n",
      "Train Epoch: 65 [214848/225000 (95%)] Loss: 19830.039062\n",
      "Train Epoch: 65 [217344/225000 (97%)] Loss: 19418.734375\n",
      "Train Epoch: 65 [219840/225000 (98%)] Loss: 20222.660156\n",
      "Train Epoch: 65 [222336/225000 (99%)] Loss: 20625.847656\n",
      "Train Epoch: 65 [224832/225000 (100%)] Loss: 19813.328125\n",
      "    epoch          : 65\n",
      "    loss           : 19952.924701365188\n",
      "    val_loss       : 19829.61776775986\n",
      "Train Epoch: 66 [192/225000 (0%)] Loss: 19130.757812\n",
      "Train Epoch: 66 [2688/225000 (1%)] Loss: 19840.785156\n",
      "Train Epoch: 66 [5184/225000 (2%)] Loss: 19171.095703\n",
      "Train Epoch: 66 [7680/225000 (3%)] Loss: 20024.849609\n",
      "Train Epoch: 66 [10176/225000 (5%)] Loss: 20107.218750\n",
      "Train Epoch: 66 [12672/225000 (6%)] Loss: 19426.093750\n",
      "Train Epoch: 66 [15168/225000 (7%)] Loss: 20007.822266\n",
      "Train Epoch: 66 [17664/225000 (8%)] Loss: 19806.972656\n",
      "Train Epoch: 66 [20160/225000 (9%)] Loss: 20373.304688\n",
      "Train Epoch: 66 [22656/225000 (10%)] Loss: 19543.316406\n",
      "Train Epoch: 66 [25152/225000 (11%)] Loss: 19954.425781\n",
      "Train Epoch: 66 [27648/225000 (12%)] Loss: 19819.150391\n",
      "Train Epoch: 66 [30144/225000 (13%)] Loss: 20040.132812\n",
      "Train Epoch: 66 [32640/225000 (15%)] Loss: 20089.541016\n",
      "Train Epoch: 66 [35136/225000 (16%)] Loss: 20080.078125\n",
      "Train Epoch: 66 [37632/225000 (17%)] Loss: 20076.859375\n",
      "Train Epoch: 66 [40128/225000 (18%)] Loss: 19983.843750\n",
      "Train Epoch: 66 [42624/225000 (19%)] Loss: 19827.111328\n",
      "Train Epoch: 66 [45120/225000 (20%)] Loss: 20056.541016\n",
      "Train Epoch: 66 [47616/225000 (21%)] Loss: 19954.484375\n",
      "Train Epoch: 66 [50112/225000 (22%)] Loss: 19817.578125\n",
      "Train Epoch: 66 [52608/225000 (23%)] Loss: 19881.849609\n",
      "Train Epoch: 66 [55104/225000 (24%)] Loss: 19574.765625\n",
      "Train Epoch: 66 [57600/225000 (26%)] Loss: 19813.500000\n",
      "Train Epoch: 66 [60096/225000 (27%)] Loss: 19494.753906\n",
      "Train Epoch: 66 [62592/225000 (28%)] Loss: 20015.189453\n",
      "Train Epoch: 66 [65088/225000 (29%)] Loss: 19809.513672\n",
      "Train Epoch: 66 [67584/225000 (30%)] Loss: 19708.367188\n",
      "Train Epoch: 66 [70080/225000 (31%)] Loss: 20344.460938\n",
      "Train Epoch: 66 [72576/225000 (32%)] Loss: 19566.083984\n",
      "Train Epoch: 66 [75072/225000 (33%)] Loss: 19600.519531\n",
      "Train Epoch: 66 [77568/225000 (34%)] Loss: 19852.488281\n",
      "Train Epoch: 66 [80064/225000 (36%)] Loss: 19861.031250\n",
      "Train Epoch: 66 [82560/225000 (37%)] Loss: 19973.357422\n",
      "Train Epoch: 66 [85056/225000 (38%)] Loss: 19920.593750\n",
      "Train Epoch: 66 [87552/225000 (39%)] Loss: 19578.580078\n",
      "Train Epoch: 66 [90048/225000 (40%)] Loss: 19919.039062\n",
      "Train Epoch: 66 [92544/225000 (41%)] Loss: 19731.738281\n",
      "Train Epoch: 66 [95040/225000 (42%)] Loss: 20010.355469\n",
      "Train Epoch: 66 [97536/225000 (43%)] Loss: 20006.695312\n",
      "Train Epoch: 66 [100032/225000 (44%)] Loss: 19561.246094\n",
      "Train Epoch: 66 [102528/225000 (46%)] Loss: 19952.753906\n",
      "Train Epoch: 66 [105024/225000 (47%)] Loss: 19429.621094\n",
      "Train Epoch: 66 [107520/225000 (48%)] Loss: 20093.914062\n",
      "Train Epoch: 66 [110016/225000 (49%)] Loss: 19954.734375\n",
      "Train Epoch: 66 [112512/225000 (50%)] Loss: 20052.529297\n",
      "Train Epoch: 66 [115008/225000 (51%)] Loss: 19924.253906\n",
      "Train Epoch: 66 [117504/225000 (52%)] Loss: 20508.486328\n",
      "Train Epoch: 66 [120000/225000 (53%)] Loss: 19823.388672\n",
      "Train Epoch: 66 [122496/225000 (54%)] Loss: 20287.476562\n",
      "Train Epoch: 66 [124992/225000 (56%)] Loss: 20104.828125\n",
      "Train Epoch: 66 [127488/225000 (57%)] Loss: 20109.421875\n",
      "Train Epoch: 66 [129984/225000 (58%)] Loss: 19660.783203\n",
      "Train Epoch: 66 [132480/225000 (59%)] Loss: 19611.441406\n",
      "Train Epoch: 66 [134976/225000 (60%)] Loss: 19988.847656\n",
      "Train Epoch: 66 [137472/225000 (61%)] Loss: 20504.765625\n",
      "Train Epoch: 66 [139968/225000 (62%)] Loss: 19642.324219\n",
      "Train Epoch: 66 [142464/225000 (63%)] Loss: 20145.199219\n",
      "Train Epoch: 66 [144960/225000 (64%)] Loss: 20027.175781\n",
      "Train Epoch: 66 [147456/225000 (66%)] Loss: 20042.957031\n",
      "Train Epoch: 66 [149952/225000 (67%)] Loss: 19473.156250\n",
      "Train Epoch: 66 [152448/225000 (68%)] Loss: 19824.066406\n",
      "Train Epoch: 66 [154944/225000 (69%)] Loss: 19715.066406\n",
      "Train Epoch: 66 [157440/225000 (70%)] Loss: 19774.156250\n",
      "Train Epoch: 66 [159936/225000 (71%)] Loss: 19699.339844\n",
      "Train Epoch: 66 [162432/225000 (72%)] Loss: 19443.191406\n",
      "Train Epoch: 66 [164928/225000 (73%)] Loss: 19884.599609\n",
      "Train Epoch: 66 [167424/225000 (74%)] Loss: 19422.277344\n",
      "Train Epoch: 66 [169920/225000 (76%)] Loss: 19730.105469\n",
      "Train Epoch: 66 [172416/225000 (77%)] Loss: 19569.214844\n",
      "Train Epoch: 66 [174912/225000 (78%)] Loss: 20177.402344\n",
      "Train Epoch: 66 [177408/225000 (79%)] Loss: 19771.554688\n",
      "Train Epoch: 66 [179904/225000 (80%)] Loss: 19654.595703\n",
      "Train Epoch: 66 [182400/225000 (81%)] Loss: 19515.042969\n",
      "Train Epoch: 66 [184896/225000 (82%)] Loss: 20253.230469\n",
      "Train Epoch: 66 [187392/225000 (83%)] Loss: 19861.253906\n",
      "Train Epoch: 66 [189888/225000 (84%)] Loss: 19912.429688\n",
      "Train Epoch: 66 [192384/225000 (86%)] Loss: 19977.429688\n",
      "Train Epoch: 66 [194880/225000 (87%)] Loss: 19675.144531\n",
      "Train Epoch: 66 [197376/225000 (88%)] Loss: 19755.207031\n",
      "Train Epoch: 66 [199872/225000 (89%)] Loss: 20073.074219\n",
      "Train Epoch: 66 [202368/225000 (90%)] Loss: 19710.726562\n",
      "Train Epoch: 66 [204864/225000 (91%)] Loss: 19934.804688\n",
      "Train Epoch: 66 [207360/225000 (92%)] Loss: 19850.343750\n",
      "Train Epoch: 66 [209856/225000 (93%)] Loss: 19703.859375\n",
      "Train Epoch: 66 [212352/225000 (94%)] Loss: 20170.242188\n",
      "Train Epoch: 66 [214848/225000 (95%)] Loss: 19687.671875\n",
      "Train Epoch: 66 [217344/225000 (97%)] Loss: 19984.447266\n",
      "Train Epoch: 66 [219840/225000 (98%)] Loss: 20085.304688\n",
      "Train Epoch: 66 [222336/225000 (99%)] Loss: 19913.796875\n",
      "Train Epoch: 66 [224832/225000 (100%)] Loss: 19334.636719\n",
      "    epoch          : 66\n",
      "    loss           : 19924.58626246534\n",
      "    val_loss       : 19813.64559366139\n",
      "Train Epoch: 67 [192/225000 (0%)] Loss: 19549.060547\n",
      "Train Epoch: 67 [2688/225000 (1%)] Loss: 19973.132812\n",
      "Train Epoch: 67 [5184/225000 (2%)] Loss: 20013.371094\n",
      "Train Epoch: 67 [7680/225000 (3%)] Loss: 20342.640625\n",
      "Train Epoch: 67 [10176/225000 (5%)] Loss: 19903.714844\n",
      "Train Epoch: 67 [12672/225000 (6%)] Loss: 20040.511719\n",
      "Train Epoch: 67 [15168/225000 (7%)] Loss: 20242.636719\n",
      "Train Epoch: 67 [17664/225000 (8%)] Loss: 19762.365234\n",
      "Train Epoch: 67 [20160/225000 (9%)] Loss: 20080.515625\n",
      "Train Epoch: 67 [22656/225000 (10%)] Loss: 20101.347656\n",
      "Train Epoch: 67 [25152/225000 (11%)] Loss: 19940.667969\n",
      "Train Epoch: 67 [27648/225000 (12%)] Loss: 20069.468750\n",
      "Train Epoch: 67 [30144/225000 (13%)] Loss: 20142.515625\n",
      "Train Epoch: 67 [32640/225000 (15%)] Loss: 20156.234375\n",
      "Train Epoch: 67 [35136/225000 (16%)] Loss: 19891.714844\n",
      "Train Epoch: 67 [37632/225000 (17%)] Loss: 20000.261719\n",
      "Train Epoch: 67 [40128/225000 (18%)] Loss: 19839.369141\n",
      "Train Epoch: 67 [42624/225000 (19%)] Loss: 19746.552734\n",
      "Train Epoch: 67 [45120/225000 (20%)] Loss: 20204.816406\n",
      "Train Epoch: 67 [47616/225000 (21%)] Loss: 19705.542969\n",
      "Train Epoch: 67 [50112/225000 (22%)] Loss: 19688.886719\n",
      "Train Epoch: 67 [52608/225000 (23%)] Loss: 20347.609375\n",
      "Train Epoch: 67 [55104/225000 (24%)] Loss: 19567.292969\n",
      "Train Epoch: 67 [57600/225000 (26%)] Loss: 19523.339844\n",
      "Train Epoch: 67 [60096/225000 (27%)] Loss: 19839.285156\n",
      "Train Epoch: 67 [62592/225000 (28%)] Loss: 19906.318359\n",
      "Train Epoch: 67 [65088/225000 (29%)] Loss: 19726.857422\n",
      "Train Epoch: 67 [67584/225000 (30%)] Loss: 19870.550781\n",
      "Train Epoch: 67 [70080/225000 (31%)] Loss: 20893.398438\n",
      "Train Epoch: 67 [72576/225000 (32%)] Loss: 19901.496094\n",
      "Train Epoch: 67 [75072/225000 (33%)] Loss: 19592.726562\n",
      "Train Epoch: 67 [77568/225000 (34%)] Loss: 19965.982422\n",
      "Train Epoch: 67 [80064/225000 (36%)] Loss: 20234.419922\n",
      "Train Epoch: 67 [82560/225000 (37%)] Loss: 19739.480469\n",
      "Train Epoch: 67 [85056/225000 (38%)] Loss: 19689.027344\n",
      "Train Epoch: 67 [87552/225000 (39%)] Loss: 19854.085938\n",
      "Train Epoch: 67 [90048/225000 (40%)] Loss: 20056.562500\n",
      "Train Epoch: 67 [92544/225000 (41%)] Loss: 20389.248047\n",
      "Train Epoch: 67 [95040/225000 (42%)] Loss: 19535.953125\n",
      "Train Epoch: 67 [97536/225000 (43%)] Loss: 20005.781250\n",
      "Train Epoch: 67 [100032/225000 (44%)] Loss: 19955.464844\n",
      "Train Epoch: 67 [102528/225000 (46%)] Loss: 19732.042969\n",
      "Train Epoch: 67 [105024/225000 (47%)] Loss: 20216.765625\n",
      "Train Epoch: 67 [107520/225000 (48%)] Loss: 19689.566406\n",
      "Train Epoch: 67 [110016/225000 (49%)] Loss: 19741.105469\n",
      "Train Epoch: 67 [112512/225000 (50%)] Loss: 20085.765625\n",
      "Train Epoch: 67 [115008/225000 (51%)] Loss: 19437.384766\n",
      "Train Epoch: 67 [117504/225000 (52%)] Loss: 20277.080078\n",
      "Train Epoch: 67 [120000/225000 (53%)] Loss: 19859.041016\n",
      "Train Epoch: 67 [122496/225000 (54%)] Loss: 19769.175781\n",
      "Train Epoch: 67 [124992/225000 (56%)] Loss: 19623.023438\n",
      "Train Epoch: 67 [127488/225000 (57%)] Loss: 19724.291016\n",
      "Train Epoch: 67 [129984/225000 (58%)] Loss: 19990.777344\n",
      "Train Epoch: 67 [132480/225000 (59%)] Loss: 19986.093750\n",
      "Train Epoch: 67 [134976/225000 (60%)] Loss: 20131.542969\n",
      "Train Epoch: 67 [137472/225000 (61%)] Loss: 19864.992188\n",
      "Train Epoch: 67 [139968/225000 (62%)] Loss: 20114.722656\n",
      "Train Epoch: 67 [142464/225000 (63%)] Loss: 19604.507812\n",
      "Train Epoch: 67 [144960/225000 (64%)] Loss: 19605.167969\n",
      "Train Epoch: 67 [147456/225000 (66%)] Loss: 19677.746094\n",
      "Train Epoch: 67 [149952/225000 (67%)] Loss: 20451.882812\n",
      "Train Epoch: 67 [152448/225000 (68%)] Loss: 19815.675781\n",
      "Train Epoch: 67 [154944/225000 (69%)] Loss: 19817.708984\n",
      "Train Epoch: 67 [157440/225000 (70%)] Loss: 19778.761719\n",
      "Train Epoch: 67 [159936/225000 (71%)] Loss: 19753.949219\n",
      "Train Epoch: 67 [162432/225000 (72%)] Loss: 19840.535156\n",
      "Train Epoch: 67 [164928/225000 (73%)] Loss: 20132.062500\n",
      "Train Epoch: 67 [167424/225000 (74%)] Loss: 19884.382812\n",
      "Train Epoch: 67 [169920/225000 (76%)] Loss: 20004.826172\n",
      "Train Epoch: 67 [172416/225000 (77%)] Loss: 20035.580078\n",
      "Train Epoch: 67 [174912/225000 (78%)] Loss: 19866.621094\n",
      "Train Epoch: 67 [177408/225000 (79%)] Loss: 19787.714844\n",
      "Train Epoch: 67 [179904/225000 (80%)] Loss: 19876.394531\n",
      "Train Epoch: 67 [182400/225000 (81%)] Loss: 19754.894531\n",
      "Train Epoch: 67 [184896/225000 (82%)] Loss: 20050.394531\n",
      "Train Epoch: 67 [187392/225000 (83%)] Loss: 19868.226562\n",
      "Train Epoch: 67 [189888/225000 (84%)] Loss: 20150.535156\n",
      "Train Epoch: 67 [192384/225000 (86%)] Loss: 19718.972656\n",
      "Train Epoch: 67 [194880/225000 (87%)] Loss: 19993.664062\n",
      "Train Epoch: 67 [197376/225000 (88%)] Loss: 19898.912109\n",
      "Train Epoch: 67 [199872/225000 (89%)] Loss: 19495.265625\n",
      "Train Epoch: 67 [202368/225000 (90%)] Loss: 20078.273438\n",
      "Train Epoch: 67 [204864/225000 (91%)] Loss: 20097.353516\n",
      "Train Epoch: 67 [207360/225000 (92%)] Loss: 20112.589844\n",
      "Train Epoch: 67 [209856/225000 (93%)] Loss: 19710.775391\n",
      "Train Epoch: 67 [212352/225000 (94%)] Loss: 20064.521484\n",
      "Train Epoch: 67 [214848/225000 (95%)] Loss: 20163.179688\n",
      "Train Epoch: 67 [217344/225000 (97%)] Loss: 24163.988281\n",
      "Train Epoch: 67 [219840/225000 (98%)] Loss: 19694.046875\n",
      "Train Epoch: 67 [222336/225000 (99%)] Loss: 19854.222656\n",
      "Train Epoch: 67 [224832/225000 (100%)] Loss: 19582.105469\n",
      "    epoch          : 67\n",
      "    loss           : 19899.367924088096\n",
      "    val_loss       : 19788.721988060093\n",
      "Train Epoch: 68 [192/225000 (0%)] Loss: 19748.906250\n",
      "Train Epoch: 68 [2688/225000 (1%)] Loss: 19756.958984\n",
      "Train Epoch: 68 [5184/225000 (2%)] Loss: 19624.220703\n",
      "Train Epoch: 68 [7680/225000 (3%)] Loss: 20290.554688\n",
      "Train Epoch: 68 [10176/225000 (5%)] Loss: 20202.896484\n",
      "Train Epoch: 68 [12672/225000 (6%)] Loss: 19800.285156\n",
      "Train Epoch: 68 [15168/225000 (7%)] Loss: 19963.796875\n",
      "Train Epoch: 68 [17664/225000 (8%)] Loss: 19561.353516\n",
      "Train Epoch: 68 [20160/225000 (9%)] Loss: 20028.515625\n",
      "Train Epoch: 68 [22656/225000 (10%)] Loss: 20137.996094\n",
      "Train Epoch: 68 [25152/225000 (11%)] Loss: 19778.833984\n",
      "Train Epoch: 68 [27648/225000 (12%)] Loss: 19707.906250\n",
      "Train Epoch: 68 [30144/225000 (13%)] Loss: 19512.521484\n",
      "Train Epoch: 68 [32640/225000 (15%)] Loss: 20214.187500\n",
      "Train Epoch: 68 [35136/225000 (16%)] Loss: 20366.896484\n",
      "Train Epoch: 68 [37632/225000 (17%)] Loss: 19434.794922\n",
      "Train Epoch: 68 [40128/225000 (18%)] Loss: 19867.500000\n",
      "Train Epoch: 68 [42624/225000 (19%)] Loss: 20198.511719\n",
      "Train Epoch: 68 [45120/225000 (20%)] Loss: 19868.835938\n",
      "Train Epoch: 68 [47616/225000 (21%)] Loss: 19802.251953\n",
      "Train Epoch: 68 [50112/225000 (22%)] Loss: 19479.054688\n",
      "Train Epoch: 68 [52608/225000 (23%)] Loss: 19650.087891\n",
      "Train Epoch: 68 [55104/225000 (24%)] Loss: 19482.550781\n",
      "Train Epoch: 68 [57600/225000 (26%)] Loss: 20271.183594\n",
      "Train Epoch: 68 [60096/225000 (27%)] Loss: 19846.287109\n",
      "Train Epoch: 68 [62592/225000 (28%)] Loss: 20090.845703\n",
      "Train Epoch: 68 [65088/225000 (29%)] Loss: 19524.445312\n",
      "Train Epoch: 68 [67584/225000 (30%)] Loss: 20305.796875\n",
      "Train Epoch: 68 [70080/225000 (31%)] Loss: 20337.904297\n",
      "Train Epoch: 68 [72576/225000 (32%)] Loss: 19860.722656\n",
      "Train Epoch: 68 [75072/225000 (33%)] Loss: 20014.460938\n",
      "Train Epoch: 68 [77568/225000 (34%)] Loss: 19297.697266\n",
      "Train Epoch: 68 [80064/225000 (36%)] Loss: 19848.710938\n",
      "Train Epoch: 68 [82560/225000 (37%)] Loss: 20444.779297\n",
      "Train Epoch: 68 [85056/225000 (38%)] Loss: 19674.062500\n",
      "Train Epoch: 68 [87552/225000 (39%)] Loss: 20209.771484\n",
      "Train Epoch: 68 [90048/225000 (40%)] Loss: 20080.878906\n",
      "Train Epoch: 68 [92544/225000 (41%)] Loss: 19800.859375\n",
      "Train Epoch: 68 [95040/225000 (42%)] Loss: 19778.695312\n",
      "Train Epoch: 68 [97536/225000 (43%)] Loss: 20156.734375\n",
      "Train Epoch: 68 [100032/225000 (44%)] Loss: 20225.324219\n",
      "Train Epoch: 68 [102528/225000 (46%)] Loss: 20062.453125\n",
      "Train Epoch: 68 [105024/225000 (47%)] Loss: 19791.707031\n",
      "Train Epoch: 68 [107520/225000 (48%)] Loss: 19960.076172\n",
      "Train Epoch: 68 [110016/225000 (49%)] Loss: 19839.511719\n",
      "Train Epoch: 68 [112512/225000 (50%)] Loss: 19789.269531\n",
      "Train Epoch: 68 [115008/225000 (51%)] Loss: 19591.226562\n",
      "Train Epoch: 68 [117504/225000 (52%)] Loss: 19626.927734\n",
      "Train Epoch: 68 [120000/225000 (53%)] Loss: 20093.945312\n",
      "Train Epoch: 68 [122496/225000 (54%)] Loss: 19222.611328\n",
      "Train Epoch: 68 [124992/225000 (56%)] Loss: 19894.447266\n",
      "Train Epoch: 68 [127488/225000 (57%)] Loss: 20181.714844\n",
      "Train Epoch: 68 [129984/225000 (58%)] Loss: 19650.847656\n",
      "Train Epoch: 68 [132480/225000 (59%)] Loss: 19965.029297\n",
      "Train Epoch: 68 [134976/225000 (60%)] Loss: 19783.408203\n",
      "Train Epoch: 68 [137472/225000 (61%)] Loss: 19394.105469\n",
      "Train Epoch: 68 [139968/225000 (62%)] Loss: 20148.265625\n",
      "Train Epoch: 68 [142464/225000 (63%)] Loss: 18924.541016\n",
      "Train Epoch: 68 [144960/225000 (64%)] Loss: 20089.210938\n",
      "Train Epoch: 68 [147456/225000 (66%)] Loss: 19421.917969\n",
      "Train Epoch: 68 [149952/225000 (67%)] Loss: 20218.101562\n",
      "Train Epoch: 68 [152448/225000 (68%)] Loss: 19708.136719\n",
      "Train Epoch: 68 [154944/225000 (69%)] Loss: 19743.222656\n",
      "Train Epoch: 68 [157440/225000 (70%)] Loss: 20077.066406\n",
      "Train Epoch: 68 [159936/225000 (71%)] Loss: 19653.306641\n",
      "Train Epoch: 68 [162432/225000 (72%)] Loss: 19925.486328\n",
      "Train Epoch: 68 [164928/225000 (73%)] Loss: 19569.558594\n",
      "Train Epoch: 68 [167424/225000 (74%)] Loss: 19723.685547\n",
      "Train Epoch: 68 [169920/225000 (76%)] Loss: 19530.410156\n",
      "Train Epoch: 68 [172416/225000 (77%)] Loss: 19770.171875\n",
      "Train Epoch: 68 [174912/225000 (78%)] Loss: 19713.550781\n",
      "Train Epoch: 68 [177408/225000 (79%)] Loss: 20573.738281\n",
      "Train Epoch: 68 [179904/225000 (80%)] Loss: 20024.144531\n",
      "Train Epoch: 68 [182400/225000 (81%)] Loss: 19729.201172\n",
      "Train Epoch: 68 [184896/225000 (82%)] Loss: 19822.310547\n",
      "Train Epoch: 68 [187392/225000 (83%)] Loss: 19621.355469\n",
      "Train Epoch: 68 [189888/225000 (84%)] Loss: 20178.289062\n",
      "Train Epoch: 68 [192384/225000 (86%)] Loss: 19580.802734\n",
      "Train Epoch: 68 [194880/225000 (87%)] Loss: 19469.617188\n",
      "Train Epoch: 68 [197376/225000 (88%)] Loss: 20399.671875\n",
      "Train Epoch: 68 [199872/225000 (89%)] Loss: 19435.703125\n",
      "Train Epoch: 68 [202368/225000 (90%)] Loss: 20091.398438\n",
      "Train Epoch: 68 [204864/225000 (91%)] Loss: 19946.246094\n",
      "Train Epoch: 68 [207360/225000 (92%)] Loss: 20466.574219\n",
      "Train Epoch: 68 [209856/225000 (93%)] Loss: 19282.121094\n",
      "Train Epoch: 68 [212352/225000 (94%)] Loss: 20173.195312\n",
      "Train Epoch: 68 [214848/225000 (95%)] Loss: 19241.089844\n",
      "Train Epoch: 68 [217344/225000 (97%)] Loss: 19976.625000\n",
      "Train Epoch: 68 [219840/225000 (98%)] Loss: 20096.679688\n",
      "Train Epoch: 68 [222336/225000 (99%)] Loss: 19910.636719\n",
      "Train Epoch: 68 [224832/225000 (100%)] Loss: 19405.941406\n",
      "    epoch          : 68\n",
      "    loss           : 19868.756464310474\n",
      "    val_loss       : 19814.466197080284\n",
      "Train Epoch: 69 [192/225000 (0%)] Loss: 19979.029297\n",
      "Train Epoch: 69 [2688/225000 (1%)] Loss: 19723.562500\n",
      "Train Epoch: 69 [5184/225000 (2%)] Loss: 19942.212891\n",
      "Train Epoch: 69 [7680/225000 (3%)] Loss: 20221.050781\n",
      "Train Epoch: 69 [10176/225000 (5%)] Loss: 19781.181641\n",
      "Train Epoch: 69 [12672/225000 (6%)] Loss: 19863.750000\n",
      "Train Epoch: 69 [15168/225000 (7%)] Loss: 19835.052734\n",
      "Train Epoch: 69 [17664/225000 (8%)] Loss: 19796.613281\n",
      "Train Epoch: 69 [20160/225000 (9%)] Loss: 19617.304688\n",
      "Train Epoch: 69 [22656/225000 (10%)] Loss: 19836.492188\n",
      "Train Epoch: 69 [25152/225000 (11%)] Loss: 19853.121094\n",
      "Train Epoch: 69 [27648/225000 (12%)] Loss: 19973.164062\n",
      "Train Epoch: 69 [30144/225000 (13%)] Loss: 20134.179688\n",
      "Train Epoch: 69 [32640/225000 (15%)] Loss: 19333.449219\n",
      "Train Epoch: 69 [35136/225000 (16%)] Loss: 19458.089844\n",
      "Train Epoch: 69 [37632/225000 (17%)] Loss: 20000.593750\n",
      "Train Epoch: 69 [40128/225000 (18%)] Loss: 19315.523438\n",
      "Train Epoch: 69 [42624/225000 (19%)] Loss: 19855.941406\n",
      "Train Epoch: 69 [45120/225000 (20%)] Loss: 19530.269531\n",
      "Train Epoch: 69 [47616/225000 (21%)] Loss: 20205.679688\n",
      "Train Epoch: 69 [50112/225000 (22%)] Loss: 19926.152344\n",
      "Train Epoch: 69 [52608/225000 (23%)] Loss: 20059.683594\n",
      "Train Epoch: 69 [55104/225000 (24%)] Loss: 19747.248047\n",
      "Train Epoch: 69 [57600/225000 (26%)] Loss: 19873.886719\n",
      "Train Epoch: 69 [60096/225000 (27%)] Loss: 19435.919922\n",
      "Train Epoch: 69 [62592/225000 (28%)] Loss: 19640.791016\n",
      "Train Epoch: 69 [65088/225000 (29%)] Loss: 20110.855469\n",
      "Train Epoch: 69 [67584/225000 (30%)] Loss: 19717.515625\n",
      "Train Epoch: 69 [70080/225000 (31%)] Loss: 19905.693359\n",
      "Train Epoch: 69 [72576/225000 (32%)] Loss: 19577.279297\n",
      "Train Epoch: 69 [75072/225000 (33%)] Loss: 19704.640625\n",
      "Train Epoch: 69 [77568/225000 (34%)] Loss: 20373.699219\n",
      "Train Epoch: 69 [80064/225000 (36%)] Loss: 19481.875000\n",
      "Train Epoch: 69 [82560/225000 (37%)] Loss: 20324.195312\n",
      "Train Epoch: 69 [85056/225000 (38%)] Loss: 19922.214844\n",
      "Train Epoch: 69 [87552/225000 (39%)] Loss: 19923.140625\n",
      "Train Epoch: 69 [90048/225000 (40%)] Loss: 19651.480469\n",
      "Train Epoch: 69 [92544/225000 (41%)] Loss: 20041.042969\n",
      "Train Epoch: 69 [95040/225000 (42%)] Loss: 19504.625000\n",
      "Train Epoch: 69 [97536/225000 (43%)] Loss: 19639.679688\n",
      "Train Epoch: 69 [100032/225000 (44%)] Loss: 19516.410156\n",
      "Train Epoch: 69 [102528/225000 (46%)] Loss: 19793.414062\n",
      "Train Epoch: 69 [105024/225000 (47%)] Loss: 19665.980469\n",
      "Train Epoch: 69 [107520/225000 (48%)] Loss: 20006.123047\n",
      "Train Epoch: 69 [110016/225000 (49%)] Loss: 19952.070312\n",
      "Train Epoch: 69 [112512/225000 (50%)] Loss: 19796.072266\n",
      "Train Epoch: 69 [115008/225000 (51%)] Loss: 19961.167969\n",
      "Train Epoch: 69 [117504/225000 (52%)] Loss: 19624.957031\n",
      "Train Epoch: 69 [120000/225000 (53%)] Loss: 20131.255859\n",
      "Train Epoch: 69 [122496/225000 (54%)] Loss: 20581.371094\n",
      "Train Epoch: 69 [124992/225000 (56%)] Loss: 19509.839844\n",
      "Train Epoch: 69 [127488/225000 (57%)] Loss: 19565.167969\n",
      "Train Epoch: 69 [129984/225000 (58%)] Loss: 20303.822266\n",
      "Train Epoch: 69 [132480/225000 (59%)] Loss: 19377.634766\n",
      "Train Epoch: 69 [134976/225000 (60%)] Loss: 19521.500000\n",
      "Train Epoch: 69 [137472/225000 (61%)] Loss: 20552.382812\n",
      "Train Epoch: 69 [139968/225000 (62%)] Loss: 19950.929688\n",
      "Train Epoch: 69 [142464/225000 (63%)] Loss: 19403.371094\n",
      "Train Epoch: 69 [144960/225000 (64%)] Loss: 20108.927734\n",
      "Train Epoch: 69 [147456/225000 (66%)] Loss: 20122.894531\n",
      "Train Epoch: 69 [149952/225000 (67%)] Loss: 20139.265625\n",
      "Train Epoch: 69 [152448/225000 (68%)] Loss: 20307.710938\n",
      "Train Epoch: 69 [154944/225000 (69%)] Loss: 20345.128906\n",
      "Train Epoch: 69 [157440/225000 (70%)] Loss: 19964.126953\n",
      "Train Epoch: 69 [159936/225000 (71%)] Loss: 20093.156250\n",
      "Train Epoch: 69 [162432/225000 (72%)] Loss: 20012.070312\n",
      "Train Epoch: 69 [164928/225000 (73%)] Loss: 19800.585938\n",
      "Train Epoch: 69 [167424/225000 (74%)] Loss: 19469.109375\n",
      "Train Epoch: 69 [169920/225000 (76%)] Loss: 20287.859375\n",
      "Train Epoch: 69 [172416/225000 (77%)] Loss: 19895.230469\n",
      "Train Epoch: 69 [174912/225000 (78%)] Loss: 20232.191406\n",
      "Train Epoch: 69 [177408/225000 (79%)] Loss: 19542.181641\n",
      "Train Epoch: 69 [179904/225000 (80%)] Loss: 19291.281250\n",
      "Train Epoch: 69 [182400/225000 (81%)] Loss: 19796.582031\n",
      "Train Epoch: 69 [184896/225000 (82%)] Loss: 19558.216797\n",
      "Train Epoch: 69 [187392/225000 (83%)] Loss: 19703.699219\n",
      "Train Epoch: 69 [189888/225000 (84%)] Loss: 20081.644531\n",
      "Train Epoch: 69 [192384/225000 (86%)] Loss: 19761.351562\n",
      "Train Epoch: 69 [194880/225000 (87%)] Loss: 20299.859375\n",
      "Train Epoch: 69 [197376/225000 (88%)] Loss: 20384.570312\n",
      "Train Epoch: 69 [199872/225000 (89%)] Loss: 19804.789062\n",
      "Train Epoch: 69 [202368/225000 (90%)] Loss: 20168.187500\n",
      "Train Epoch: 69 [204864/225000 (91%)] Loss: 20359.910156\n",
      "Train Epoch: 69 [207360/225000 (92%)] Loss: 20124.589844\n",
      "Train Epoch: 69 [209856/225000 (93%)] Loss: 20371.542969\n",
      "Train Epoch: 69 [212352/225000 (94%)] Loss: 19935.281250\n",
      "Train Epoch: 69 [214848/225000 (95%)] Loss: 19829.363281\n",
      "Train Epoch: 69 [217344/225000 (97%)] Loss: 19894.488281\n",
      "Train Epoch: 69 [219840/225000 (98%)] Loss: 19680.164062\n",
      "Train Epoch: 69 [222336/225000 (99%)] Loss: 19296.712891\n",
      "Train Epoch: 69 [224832/225000 (100%)] Loss: 19957.923828\n",
      "    epoch          : 69\n",
      "    loss           : 19863.595639798423\n",
      "    val_loss       : 19794.74078816949\n",
      "Train Epoch: 70 [192/225000 (0%)] Loss: 19407.058594\n",
      "Train Epoch: 70 [2688/225000 (1%)] Loss: 20210.164062\n",
      "Train Epoch: 70 [5184/225000 (2%)] Loss: 19412.878906\n",
      "Train Epoch: 70 [7680/225000 (3%)] Loss: 19764.781250\n",
      "Train Epoch: 70 [10176/225000 (5%)] Loss: 19776.990234\n",
      "Train Epoch: 70 [12672/225000 (6%)] Loss: 19521.710938\n",
      "Train Epoch: 70 [15168/225000 (7%)] Loss: 19955.654297\n",
      "Train Epoch: 70 [17664/225000 (8%)] Loss: 20053.847656\n",
      "Train Epoch: 70 [20160/225000 (9%)] Loss: 19609.941406\n",
      "Train Epoch: 70 [22656/225000 (10%)] Loss: 19762.371094\n",
      "Train Epoch: 70 [25152/225000 (11%)] Loss: 19676.199219\n",
      "Train Epoch: 70 [27648/225000 (12%)] Loss: 19898.154297\n",
      "Train Epoch: 70 [30144/225000 (13%)] Loss: 19811.718750\n",
      "Train Epoch: 70 [32640/225000 (15%)] Loss: 19783.570312\n",
      "Train Epoch: 70 [35136/225000 (16%)] Loss: 19894.296875\n",
      "Train Epoch: 70 [37632/225000 (17%)] Loss: 19515.664062\n",
      "Train Epoch: 70 [40128/225000 (18%)] Loss: 20277.244141\n",
      "Train Epoch: 70 [42624/225000 (19%)] Loss: 19593.906250\n",
      "Train Epoch: 70 [45120/225000 (20%)] Loss: 19943.843750\n",
      "Train Epoch: 70 [47616/225000 (21%)] Loss: 20276.320312\n",
      "Train Epoch: 70 [50112/225000 (22%)] Loss: 20206.425781\n",
      "Train Epoch: 70 [52608/225000 (23%)] Loss: 19686.718750\n",
      "Train Epoch: 70 [55104/225000 (24%)] Loss: 19782.910156\n",
      "Train Epoch: 70 [57600/225000 (26%)] Loss: 19632.439453\n",
      "Train Epoch: 70 [60096/225000 (27%)] Loss: 19608.914062\n",
      "Train Epoch: 70 [62592/225000 (28%)] Loss: 19573.484375\n",
      "Train Epoch: 70 [65088/225000 (29%)] Loss: 20136.478516\n",
      "Train Epoch: 70 [67584/225000 (30%)] Loss: 19517.390625\n",
      "Train Epoch: 70 [70080/225000 (31%)] Loss: 19523.937500\n",
      "Train Epoch: 70 [72576/225000 (32%)] Loss: 20035.357422\n",
      "Train Epoch: 70 [75072/225000 (33%)] Loss: 19370.636719\n",
      "Train Epoch: 70 [77568/225000 (34%)] Loss: 19792.554688\n",
      "Train Epoch: 70 [80064/225000 (36%)] Loss: 19831.464844\n",
      "Train Epoch: 70 [82560/225000 (37%)] Loss: 19357.011719\n",
      "Train Epoch: 70 [85056/225000 (38%)] Loss: 20051.820312\n",
      "Train Epoch: 70 [87552/225000 (39%)] Loss: 19703.109375\n",
      "Train Epoch: 70 [90048/225000 (40%)] Loss: 19833.933594\n",
      "Train Epoch: 70 [92544/225000 (41%)] Loss: 19375.511719\n",
      "Train Epoch: 70 [95040/225000 (42%)] Loss: 19595.707031\n",
      "Train Epoch: 70 [97536/225000 (43%)] Loss: 20043.894531\n",
      "Train Epoch: 70 [100032/225000 (44%)] Loss: 19646.119141\n",
      "Train Epoch: 70 [102528/225000 (46%)] Loss: 19644.917969\n",
      "Train Epoch: 70 [105024/225000 (47%)] Loss: 20030.042969\n",
      "Train Epoch: 70 [107520/225000 (48%)] Loss: 19827.445312\n",
      "Train Epoch: 70 [110016/225000 (49%)] Loss: 19759.179688\n",
      "Train Epoch: 70 [112512/225000 (50%)] Loss: 19816.951172\n",
      "Train Epoch: 70 [115008/225000 (51%)] Loss: 19810.072266\n",
      "Train Epoch: 70 [117504/225000 (52%)] Loss: 20200.316406\n",
      "Train Epoch: 70 [120000/225000 (53%)] Loss: 19936.164062\n",
      "Train Epoch: 70 [122496/225000 (54%)] Loss: 19489.945312\n",
      "Train Epoch: 70 [124992/225000 (56%)] Loss: 19427.011719\n",
      "Train Epoch: 70 [127488/225000 (57%)] Loss: 20091.597656\n",
      "Train Epoch: 70 [129984/225000 (58%)] Loss: 19846.828125\n",
      "Train Epoch: 70 [132480/225000 (59%)] Loss: 19852.310547\n",
      "Train Epoch: 70 [134976/225000 (60%)] Loss: 19503.914062\n",
      "Train Epoch: 70 [137472/225000 (61%)] Loss: 20031.906250\n",
      "Train Epoch: 70 [139968/225000 (62%)] Loss: 19726.556641\n",
      "Train Epoch: 70 [142464/225000 (63%)] Loss: 20020.289062\n",
      "Train Epoch: 70 [144960/225000 (64%)] Loss: 20196.726562\n",
      "Train Epoch: 70 [147456/225000 (66%)] Loss: 19872.257812\n",
      "Train Epoch: 70 [149952/225000 (67%)] Loss: 20264.664062\n",
      "Train Epoch: 70 [152448/225000 (68%)] Loss: 19447.687500\n",
      "Train Epoch: 70 [154944/225000 (69%)] Loss: 19527.269531\n",
      "Train Epoch: 70 [157440/225000 (70%)] Loss: 20097.933594\n",
      "Train Epoch: 70 [159936/225000 (71%)] Loss: 20583.666016\n",
      "Train Epoch: 70 [162432/225000 (72%)] Loss: 19393.367188\n",
      "Train Epoch: 70 [164928/225000 (73%)] Loss: 20220.199219\n",
      "Train Epoch: 70 [167424/225000 (74%)] Loss: 19604.632812\n",
      "Train Epoch: 70 [169920/225000 (76%)] Loss: 19635.763672\n",
      "Train Epoch: 70 [172416/225000 (77%)] Loss: 19855.507812\n",
      "Train Epoch: 70 [174912/225000 (78%)] Loss: 19722.556641\n",
      "Train Epoch: 70 [177408/225000 (79%)] Loss: 19278.939453\n",
      "Train Epoch: 70 [179904/225000 (80%)] Loss: 19883.283203\n",
      "Train Epoch: 70 [182400/225000 (81%)] Loss: 19310.160156\n",
      "Train Epoch: 70 [184896/225000 (82%)] Loss: 20142.476562\n",
      "Train Epoch: 70 [187392/225000 (83%)] Loss: 19971.212891\n",
      "Train Epoch: 70 [189888/225000 (84%)] Loss: 19856.570312\n",
      "Train Epoch: 70 [192384/225000 (86%)] Loss: 19664.445312\n",
      "Train Epoch: 70 [194880/225000 (87%)] Loss: 20153.763672\n",
      "Train Epoch: 70 [197376/225000 (88%)] Loss: 19505.087891\n",
      "Train Epoch: 70 [199872/225000 (89%)] Loss: 19680.191406\n",
      "Train Epoch: 70 [202368/225000 (90%)] Loss: 19796.117188\n",
      "Train Epoch: 70 [204864/225000 (91%)] Loss: 20004.171875\n",
      "Train Epoch: 70 [207360/225000 (92%)] Loss: 19430.347656\n",
      "Train Epoch: 70 [209856/225000 (93%)] Loss: 20098.550781\n",
      "Train Epoch: 70 [212352/225000 (94%)] Loss: 19781.328125\n",
      "Train Epoch: 70 [214848/225000 (95%)] Loss: 20266.882812\n",
      "Train Epoch: 70 [217344/225000 (97%)] Loss: 19733.572266\n",
      "Train Epoch: 70 [219840/225000 (98%)] Loss: 20312.269531\n",
      "Train Epoch: 70 [222336/225000 (99%)] Loss: 19855.835938\n",
      "Train Epoch: 70 [224832/225000 (100%)] Loss: 19253.039062\n",
      "    epoch          : 70\n",
      "    loss           : 19823.96403383639\n",
      "    val_loss       : 19728.806258915945\n",
      "Train Epoch: 71 [192/225000 (0%)] Loss: 19855.417969\n",
      "Train Epoch: 71 [2688/225000 (1%)] Loss: 19978.226562\n",
      "Train Epoch: 71 [5184/225000 (2%)] Loss: 19910.894531\n",
      "Train Epoch: 71 [7680/225000 (3%)] Loss: 19901.382812\n",
      "Train Epoch: 71 [10176/225000 (5%)] Loss: 19985.025391\n",
      "Train Epoch: 71 [12672/225000 (6%)] Loss: 19615.101562\n",
      "Train Epoch: 71 [15168/225000 (7%)] Loss: 19933.773438\n",
      "Train Epoch: 71 [17664/225000 (8%)] Loss: 19980.363281\n",
      "Train Epoch: 71 [20160/225000 (9%)] Loss: 19652.785156\n",
      "Train Epoch: 71 [22656/225000 (10%)] Loss: 19873.351562\n",
      "Train Epoch: 71 [25152/225000 (11%)] Loss: 19789.365234\n",
      "Train Epoch: 71 [27648/225000 (12%)] Loss: 19468.500000\n",
      "Train Epoch: 71 [30144/225000 (13%)] Loss: 19240.648438\n",
      "Train Epoch: 71 [32640/225000 (15%)] Loss: 20043.828125\n",
      "Train Epoch: 71 [35136/225000 (16%)] Loss: 19719.097656\n",
      "Train Epoch: 71 [37632/225000 (17%)] Loss: 19795.093750\n",
      "Train Epoch: 71 [40128/225000 (18%)] Loss: 20045.269531\n",
      "Train Epoch: 71 [42624/225000 (19%)] Loss: 19746.878906\n",
      "Train Epoch: 71 [45120/225000 (20%)] Loss: 19670.496094\n",
      "Train Epoch: 71 [47616/225000 (21%)] Loss: 19922.638672\n",
      "Train Epoch: 71 [50112/225000 (22%)] Loss: 19865.968750\n",
      "Train Epoch: 71 [52608/225000 (23%)] Loss: 19433.375000\n",
      "Train Epoch: 71 [55104/225000 (24%)] Loss: 19912.671875\n",
      "Train Epoch: 71 [57600/225000 (26%)] Loss: 20039.199219\n",
      "Train Epoch: 71 [60096/225000 (27%)] Loss: 19932.755859\n",
      "Train Epoch: 71 [62592/225000 (28%)] Loss: 20369.582031\n",
      "Train Epoch: 71 [65088/225000 (29%)] Loss: 19576.226562\n",
      "Train Epoch: 71 [67584/225000 (30%)] Loss: 19653.800781\n",
      "Train Epoch: 71 [70080/225000 (31%)] Loss: 19966.515625\n",
      "Train Epoch: 71 [72576/225000 (32%)] Loss: 19574.578125\n",
      "Train Epoch: 71 [75072/225000 (33%)] Loss: 20046.902344\n",
      "Train Epoch: 71 [77568/225000 (34%)] Loss: 19900.109375\n",
      "Train Epoch: 71 [80064/225000 (36%)] Loss: 19810.427734\n",
      "Train Epoch: 71 [82560/225000 (37%)] Loss: 19923.984375\n",
      "Train Epoch: 71 [85056/225000 (38%)] Loss: 19719.320312\n",
      "Train Epoch: 71 [87552/225000 (39%)] Loss: 20111.230469\n",
      "Train Epoch: 71 [90048/225000 (40%)] Loss: 19740.289062\n",
      "Train Epoch: 71 [92544/225000 (41%)] Loss: 20041.375000\n",
      "Train Epoch: 71 [95040/225000 (42%)] Loss: 19856.941406\n",
      "Train Epoch: 71 [97536/225000 (43%)] Loss: 19989.044922\n",
      "Train Epoch: 71 [100032/225000 (44%)] Loss: 19915.257812\n",
      "Train Epoch: 71 [102528/225000 (46%)] Loss: 20048.894531\n",
      "Train Epoch: 71 [105024/225000 (47%)] Loss: 20455.277344\n",
      "Train Epoch: 71 [107520/225000 (48%)] Loss: 19609.734375\n",
      "Train Epoch: 71 [110016/225000 (49%)] Loss: 19616.875000\n",
      "Train Epoch: 71 [112512/225000 (50%)] Loss: 19774.482422\n",
      "Train Epoch: 71 [115008/225000 (51%)] Loss: 20285.511719\n",
      "Train Epoch: 71 [117504/225000 (52%)] Loss: 19096.910156\n",
      "Train Epoch: 71 [120000/225000 (53%)] Loss: 19492.511719\n",
      "Train Epoch: 71 [122496/225000 (54%)] Loss: 20008.433594\n",
      "Train Epoch: 71 [124992/225000 (56%)] Loss: 20087.269531\n",
      "Train Epoch: 71 [127488/225000 (57%)] Loss: 19676.203125\n",
      "Train Epoch: 71 [129984/225000 (58%)] Loss: 19606.351562\n",
      "Train Epoch: 71 [132480/225000 (59%)] Loss: 20085.792969\n",
      "Train Epoch: 71 [134976/225000 (60%)] Loss: 19721.253906\n",
      "Train Epoch: 71 [137472/225000 (61%)] Loss: 19845.519531\n",
      "Train Epoch: 71 [139968/225000 (62%)] Loss: 19319.494141\n",
      "Train Epoch: 71 [142464/225000 (63%)] Loss: 19937.009766\n",
      "Train Epoch: 71 [144960/225000 (64%)] Loss: 19741.974609\n",
      "Train Epoch: 71 [147456/225000 (66%)] Loss: 20098.890625\n",
      "Train Epoch: 71 [149952/225000 (67%)] Loss: 19577.482422\n",
      "Train Epoch: 71 [152448/225000 (68%)] Loss: 19645.679688\n",
      "Train Epoch: 71 [154944/225000 (69%)] Loss: 19565.929688\n",
      "Train Epoch: 71 [157440/225000 (70%)] Loss: 19983.089844\n",
      "Train Epoch: 71 [159936/225000 (71%)] Loss: 19908.105469\n",
      "Train Epoch: 71 [162432/225000 (72%)] Loss: 19816.375000\n",
      "Train Epoch: 71 [164928/225000 (73%)] Loss: 20051.453125\n",
      "Train Epoch: 71 [167424/225000 (74%)] Loss: 19518.121094\n",
      "Train Epoch: 71 [169920/225000 (76%)] Loss: 19694.427734\n",
      "Train Epoch: 71 [172416/225000 (77%)] Loss: 19854.457031\n",
      "Train Epoch: 71 [174912/225000 (78%)] Loss: 19751.750000\n",
      "Train Epoch: 71 [177408/225000 (79%)] Loss: 19873.269531\n",
      "Train Epoch: 71 [179904/225000 (80%)] Loss: 19726.500000\n",
      "Train Epoch: 71 [182400/225000 (81%)] Loss: 20042.925781\n",
      "Train Epoch: 71 [184896/225000 (82%)] Loss: 20067.792969\n",
      "Train Epoch: 71 [187392/225000 (83%)] Loss: 19892.419922\n",
      "Train Epoch: 71 [189888/225000 (84%)] Loss: 19786.105469\n",
      "Train Epoch: 71 [192384/225000 (86%)] Loss: 19930.222656\n",
      "Train Epoch: 71 [194880/225000 (87%)] Loss: 19464.679688\n",
      "Train Epoch: 71 [197376/225000 (88%)] Loss: 19698.529297\n",
      "Train Epoch: 71 [199872/225000 (89%)] Loss: 20159.333984\n",
      "Train Epoch: 71 [202368/225000 (90%)] Loss: 19829.011719\n",
      "Train Epoch: 71 [204864/225000 (91%)] Loss: 19995.023438\n",
      "Train Epoch: 71 [207360/225000 (92%)] Loss: 19895.267578\n",
      "Train Epoch: 71 [209856/225000 (93%)] Loss: 19886.277344\n",
      "Train Epoch: 71 [212352/225000 (94%)] Loss: 19901.285156\n",
      "Train Epoch: 71 [214848/225000 (95%)] Loss: 19737.746094\n",
      "Train Epoch: 71 [217344/225000 (97%)] Loss: 19590.937500\n",
      "Train Epoch: 71 [219840/225000 (98%)] Loss: 19932.251953\n",
      "Train Epoch: 71 [222336/225000 (99%)] Loss: 19482.234375\n",
      "Train Epoch: 71 [224832/225000 (100%)] Loss: 19610.576172\n",
      "    epoch          : 71\n",
      "    loss           : 19818.267603122335\n",
      "    val_loss       : 19747.62282515482\n",
      "Train Epoch: 72 [192/225000 (0%)] Loss: 19408.769531\n",
      "Train Epoch: 72 [2688/225000 (1%)] Loss: 19632.689453\n",
      "Train Epoch: 72 [5184/225000 (2%)] Loss: 20048.457031\n",
      "Train Epoch: 72 [7680/225000 (3%)] Loss: 19990.982422\n",
      "Train Epoch: 72 [10176/225000 (5%)] Loss: 19581.173828\n",
      "Train Epoch: 72 [12672/225000 (6%)] Loss: 20442.800781\n",
      "Train Epoch: 72 [15168/225000 (7%)] Loss: 19243.503906\n",
      "Train Epoch: 72 [17664/225000 (8%)] Loss: 19672.916016\n",
      "Train Epoch: 72 [20160/225000 (9%)] Loss: 20023.507812\n",
      "Train Epoch: 72 [22656/225000 (10%)] Loss: 19700.980469\n",
      "Train Epoch: 72 [25152/225000 (11%)] Loss: 19966.703125\n",
      "Train Epoch: 72 [27648/225000 (12%)] Loss: 19669.687500\n",
      "Train Epoch: 72 [30144/225000 (13%)] Loss: 19758.359375\n",
      "Train Epoch: 72 [32640/225000 (15%)] Loss: 19648.017578\n",
      "Train Epoch: 72 [35136/225000 (16%)] Loss: 19851.787109\n",
      "Train Epoch: 72 [37632/225000 (17%)] Loss: 20142.597656\n",
      "Train Epoch: 72 [40128/225000 (18%)] Loss: 19649.791016\n",
      "Train Epoch: 72 [42624/225000 (19%)] Loss: 19721.988281\n",
      "Train Epoch: 72 [45120/225000 (20%)] Loss: 19577.746094\n",
      "Train Epoch: 72 [47616/225000 (21%)] Loss: 19484.294922\n",
      "Train Epoch: 72 [50112/225000 (22%)] Loss: 20273.986328\n",
      "Train Epoch: 72 [52608/225000 (23%)] Loss: 19555.910156\n",
      "Train Epoch: 72 [55104/225000 (24%)] Loss: 19553.201172\n",
      "Train Epoch: 72 [57600/225000 (26%)] Loss: 19322.828125\n",
      "Train Epoch: 72 [60096/225000 (27%)] Loss: 19417.238281\n",
      "Train Epoch: 72 [62592/225000 (28%)] Loss: 19526.720703\n",
      "Train Epoch: 72 [65088/225000 (29%)] Loss: 19849.238281\n",
      "Train Epoch: 72 [67584/225000 (30%)] Loss: 19605.804688\n",
      "Train Epoch: 72 [70080/225000 (31%)] Loss: 20150.812500\n",
      "Train Epoch: 72 [72576/225000 (32%)] Loss: 19149.039062\n",
      "Train Epoch: 72 [75072/225000 (33%)] Loss: 20033.693359\n",
      "Train Epoch: 72 [77568/225000 (34%)] Loss: 19545.390625\n",
      "Train Epoch: 72 [80064/225000 (36%)] Loss: 19731.744141\n",
      "Train Epoch: 72 [82560/225000 (37%)] Loss: 20050.042969\n",
      "Train Epoch: 72 [85056/225000 (38%)] Loss: 19727.167969\n",
      "Train Epoch: 72 [87552/225000 (39%)] Loss: 19548.906250\n",
      "Train Epoch: 72 [90048/225000 (40%)] Loss: 19788.679688\n",
      "Train Epoch: 72 [92544/225000 (41%)] Loss: 19886.478516\n",
      "Train Epoch: 72 [95040/225000 (42%)] Loss: 20242.287109\n",
      "Train Epoch: 72 [97536/225000 (43%)] Loss: 19932.328125\n",
      "Train Epoch: 72 [100032/225000 (44%)] Loss: 19971.488281\n",
      "Train Epoch: 72 [102528/225000 (46%)] Loss: 19652.007812\n",
      "Train Epoch: 72 [105024/225000 (47%)] Loss: 19889.101562\n",
      "Train Epoch: 72 [107520/225000 (48%)] Loss: 19839.207031\n",
      "Train Epoch: 72 [110016/225000 (49%)] Loss: 19687.230469\n",
      "Train Epoch: 72 [112512/225000 (50%)] Loss: 19360.960938\n",
      "Train Epoch: 72 [115008/225000 (51%)] Loss: 19605.511719\n",
      "Train Epoch: 72 [117504/225000 (52%)] Loss: 19891.044922\n",
      "Train Epoch: 72 [120000/225000 (53%)] Loss: 19746.363281\n",
      "Train Epoch: 72 [122496/225000 (54%)] Loss: 19808.283203\n",
      "Train Epoch: 72 [124992/225000 (56%)] Loss: 19765.320312\n",
      "Train Epoch: 72 [127488/225000 (57%)] Loss: 19539.916016\n",
      "Train Epoch: 72 [129984/225000 (58%)] Loss: 19888.679688\n",
      "Train Epoch: 72 [132480/225000 (59%)] Loss: 19615.164062\n",
      "Train Epoch: 72 [134976/225000 (60%)] Loss: 19959.488281\n",
      "Train Epoch: 72 [137472/225000 (61%)] Loss: 19930.281250\n",
      "Train Epoch: 72 [139968/225000 (62%)] Loss: 19922.519531\n",
      "Train Epoch: 72 [142464/225000 (63%)] Loss: 19780.320312\n",
      "Train Epoch: 72 [144960/225000 (64%)] Loss: 19964.742188\n",
      "Train Epoch: 72 [147456/225000 (66%)] Loss: 19894.158203\n",
      "Train Epoch: 72 [149952/225000 (67%)] Loss: 19861.349609\n",
      "Train Epoch: 72 [152448/225000 (68%)] Loss: 19597.933594\n",
      "Train Epoch: 72 [154944/225000 (69%)] Loss: 19568.441406\n",
      "Train Epoch: 72 [157440/225000 (70%)] Loss: 19378.257812\n",
      "Train Epoch: 72 [159936/225000 (71%)] Loss: 20215.175781\n",
      "Train Epoch: 72 [162432/225000 (72%)] Loss: 19884.685547\n",
      "Train Epoch: 72 [164928/225000 (73%)] Loss: 19512.748047\n",
      "Train Epoch: 72 [167424/225000 (74%)] Loss: 19836.687500\n",
      "Train Epoch: 72 [169920/225000 (76%)] Loss: 20076.449219\n",
      "Train Epoch: 72 [172416/225000 (77%)] Loss: 19860.210938\n",
      "Train Epoch: 72 [174912/225000 (78%)] Loss: 19709.312500\n",
      "Train Epoch: 72 [177408/225000 (79%)] Loss: 19764.121094\n",
      "Train Epoch: 72 [179904/225000 (80%)] Loss: 19905.376953\n",
      "Train Epoch: 72 [182400/225000 (81%)] Loss: 19759.654297\n",
      "Train Epoch: 72 [184896/225000 (82%)] Loss: 19971.007812\n",
      "Train Epoch: 72 [187392/225000 (83%)] Loss: 19409.613281\n",
      "Train Epoch: 72 [189888/225000 (84%)] Loss: 20164.136719\n",
      "Train Epoch: 72 [192384/225000 (86%)] Loss: 20234.406250\n",
      "Train Epoch: 72 [194880/225000 (87%)] Loss: 20007.513672\n",
      "Train Epoch: 72 [197376/225000 (88%)] Loss: 19395.984375\n",
      "Train Epoch: 72 [199872/225000 (89%)] Loss: 20553.125000\n",
      "Train Epoch: 72 [202368/225000 (90%)] Loss: 19759.156250\n",
      "Train Epoch: 72 [204864/225000 (91%)] Loss: 19909.443359\n",
      "Train Epoch: 72 [207360/225000 (92%)] Loss: 19467.808594\n",
      "Train Epoch: 72 [209856/225000 (93%)] Loss: 19690.894531\n",
      "Train Epoch: 72 [212352/225000 (94%)] Loss: 19718.126953\n",
      "Train Epoch: 72 [214848/225000 (95%)] Loss: 19894.531250\n",
      "Train Epoch: 72 [217344/225000 (97%)] Loss: 19815.949219\n",
      "Train Epoch: 72 [219840/225000 (98%)] Loss: 19590.222656\n",
      "Train Epoch: 72 [222336/225000 (99%)] Loss: 19473.220703\n",
      "Train Epoch: 72 [224832/225000 (100%)] Loss: 19419.535156\n",
      "    epoch          : 72\n",
      "    loss           : 19786.9757509199\n",
      "    val_loss       : 19698.377766461774\n",
      "Train Epoch: 73 [192/225000 (0%)] Loss: 19862.748047\n",
      "Train Epoch: 73 [2688/225000 (1%)] Loss: 20092.755859\n",
      "Train Epoch: 73 [5184/225000 (2%)] Loss: 20254.632812\n",
      "Train Epoch: 73 [7680/225000 (3%)] Loss: 19891.988281\n",
      "Train Epoch: 73 [10176/225000 (5%)] Loss: 19699.617188\n",
      "Train Epoch: 73 [12672/225000 (6%)] Loss: 19739.289062\n",
      "Train Epoch: 73 [15168/225000 (7%)] Loss: 20134.792969\n",
      "Train Epoch: 73 [17664/225000 (8%)] Loss: 20035.238281\n",
      "Train Epoch: 73 [20160/225000 (9%)] Loss: 19411.687500\n",
      "Train Epoch: 73 [22656/225000 (10%)] Loss: 19727.625000\n",
      "Train Epoch: 73 [25152/225000 (11%)] Loss: 19879.003906\n",
      "Train Epoch: 73 [27648/225000 (12%)] Loss: 20125.382812\n",
      "Train Epoch: 73 [30144/225000 (13%)] Loss: 20418.968750\n",
      "Train Epoch: 73 [32640/225000 (15%)] Loss: 20044.917969\n",
      "Train Epoch: 73 [35136/225000 (16%)] Loss: 20041.843750\n",
      "Train Epoch: 73 [37632/225000 (17%)] Loss: 19791.994141\n",
      "Train Epoch: 73 [40128/225000 (18%)] Loss: 19614.800781\n",
      "Train Epoch: 73 [42624/225000 (19%)] Loss: 19642.019531\n",
      "Train Epoch: 73 [45120/225000 (20%)] Loss: 19691.132812\n",
      "Train Epoch: 73 [47616/225000 (21%)] Loss: 19747.859375\n",
      "Train Epoch: 73 [50112/225000 (22%)] Loss: 19571.226562\n",
      "Train Epoch: 73 [52608/225000 (23%)] Loss: 19855.226562\n",
      "Train Epoch: 73 [55104/225000 (24%)] Loss: 19779.707031\n",
      "Train Epoch: 73 [57600/225000 (26%)] Loss: 19680.582031\n",
      "Train Epoch: 73 [60096/225000 (27%)] Loss: 20049.806641\n",
      "Train Epoch: 73 [62592/225000 (28%)] Loss: 19522.824219\n",
      "Train Epoch: 73 [65088/225000 (29%)] Loss: 20280.787109\n",
      "Train Epoch: 73 [67584/225000 (30%)] Loss: 19705.593750\n",
      "Train Epoch: 73 [70080/225000 (31%)] Loss: 19669.933594\n",
      "Train Epoch: 73 [72576/225000 (32%)] Loss: 19891.804688\n",
      "Train Epoch: 73 [75072/225000 (33%)] Loss: 19714.861328\n",
      "Train Epoch: 73 [77568/225000 (34%)] Loss: 20111.191406\n",
      "Train Epoch: 73 [80064/225000 (36%)] Loss: 20193.261719\n",
      "Train Epoch: 73 [82560/225000 (37%)] Loss: 19843.019531\n",
      "Train Epoch: 73 [85056/225000 (38%)] Loss: 19807.062500\n",
      "Train Epoch: 73 [87552/225000 (39%)] Loss: 20120.097656\n",
      "Train Epoch: 73 [90048/225000 (40%)] Loss: 19453.710938\n",
      "Train Epoch: 73 [92544/225000 (41%)] Loss: 19358.257812\n",
      "Train Epoch: 73 [95040/225000 (42%)] Loss: 19506.070312\n",
      "Train Epoch: 73 [97536/225000 (43%)] Loss: 20242.226562\n",
      "Train Epoch: 73 [100032/225000 (44%)] Loss: 20126.218750\n",
      "Train Epoch: 73 [102528/225000 (46%)] Loss: 19865.617188\n",
      "Train Epoch: 73 [105024/225000 (47%)] Loss: 19796.498047\n",
      "Train Epoch: 73 [107520/225000 (48%)] Loss: 19847.539062\n",
      "Train Epoch: 73 [110016/225000 (49%)] Loss: 19965.589844\n",
      "Train Epoch: 73 [112512/225000 (50%)] Loss: 19602.435547\n",
      "Train Epoch: 73 [115008/225000 (51%)] Loss: 19860.820312\n",
      "Train Epoch: 73 [117504/225000 (52%)] Loss: 19680.701172\n",
      "Train Epoch: 73 [120000/225000 (53%)] Loss: 19591.230469\n",
      "Train Epoch: 73 [122496/225000 (54%)] Loss: 19565.226562\n",
      "Train Epoch: 73 [124992/225000 (56%)] Loss: 19834.386719\n",
      "Train Epoch: 73 [127488/225000 (57%)] Loss: 19490.164062\n",
      "Train Epoch: 73 [129984/225000 (58%)] Loss: 19234.031250\n",
      "Train Epoch: 73 [132480/225000 (59%)] Loss: 19998.527344\n",
      "Train Epoch: 73 [134976/225000 (60%)] Loss: 19324.136719\n",
      "Train Epoch: 73 [137472/225000 (61%)] Loss: 20141.046875\n",
      "Train Epoch: 73 [139968/225000 (62%)] Loss: 19490.042969\n",
      "Train Epoch: 73 [142464/225000 (63%)] Loss: 19916.027344\n",
      "Train Epoch: 73 [144960/225000 (64%)] Loss: 19690.753906\n",
      "Train Epoch: 73 [147456/225000 (66%)] Loss: 19744.855469\n",
      "Train Epoch: 73 [149952/225000 (67%)] Loss: 19782.587891\n",
      "Train Epoch: 73 [152448/225000 (68%)] Loss: 19809.941406\n",
      "Train Epoch: 73 [154944/225000 (69%)] Loss: 19685.193359\n",
      "Train Epoch: 73 [157440/225000 (70%)] Loss: 19739.421875\n",
      "Train Epoch: 73 [159936/225000 (71%)] Loss: 19739.851562\n",
      "Train Epoch: 73 [162432/225000 (72%)] Loss: 19483.054688\n",
      "Train Epoch: 73 [164928/225000 (73%)] Loss: 19471.945312\n",
      "Train Epoch: 73 [167424/225000 (74%)] Loss: 19455.582031\n",
      "Train Epoch: 73 [169920/225000 (76%)] Loss: 19711.248047\n",
      "Train Epoch: 73 [172416/225000 (77%)] Loss: 19260.357422\n",
      "Train Epoch: 73 [174912/225000 (78%)] Loss: 19725.039062\n",
      "Train Epoch: 73 [177408/225000 (79%)] Loss: 20080.556641\n",
      "Train Epoch: 73 [179904/225000 (80%)] Loss: 19663.914062\n",
      "Train Epoch: 73 [182400/225000 (81%)] Loss: 19922.734375\n",
      "Train Epoch: 73 [184896/225000 (82%)] Loss: 19443.144531\n",
      "Train Epoch: 73 [187392/225000 (83%)] Loss: 19861.263672\n",
      "Train Epoch: 73 [189888/225000 (84%)] Loss: 19847.347656\n",
      "Train Epoch: 73 [192384/225000 (86%)] Loss: 19828.601562\n",
      "Train Epoch: 73 [194880/225000 (87%)] Loss: 19890.798828\n",
      "Train Epoch: 73 [197376/225000 (88%)] Loss: 19974.378906\n",
      "Train Epoch: 73 [199872/225000 (89%)] Loss: 19772.533203\n",
      "Train Epoch: 73 [202368/225000 (90%)] Loss: 20162.726562\n",
      "Train Epoch: 73 [204864/225000 (91%)] Loss: 19848.673828\n",
      "Train Epoch: 73 [207360/225000 (92%)] Loss: 19646.195312\n",
      "Train Epoch: 73 [209856/225000 (93%)] Loss: 19926.189453\n",
      "Train Epoch: 73 [212352/225000 (94%)] Loss: 20211.429688\n",
      "Train Epoch: 73 [214848/225000 (95%)] Loss: 19590.203125\n",
      "Train Epoch: 73 [217344/225000 (97%)] Loss: 19896.837891\n",
      "Train Epoch: 73 [219840/225000 (98%)] Loss: 19868.220703\n",
      "Train Epoch: 73 [222336/225000 (99%)] Loss: 19601.742188\n",
      "Train Epoch: 73 [224832/225000 (100%)] Loss: 19620.382812\n",
      "    epoch          : 73\n",
      "    loss           : 19767.37610154917\n",
      "    val_loss       : 19668.679984868028\n",
      "Train Epoch: 74 [192/225000 (0%)] Loss: 19516.175781\n",
      "Train Epoch: 74 [2688/225000 (1%)] Loss: 19896.027344\n",
      "Train Epoch: 74 [5184/225000 (2%)] Loss: 19978.062500\n",
      "Train Epoch: 74 [7680/225000 (3%)] Loss: 19431.546875\n",
      "Train Epoch: 74 [10176/225000 (5%)] Loss: 19736.773438\n",
      "Train Epoch: 74 [12672/225000 (6%)] Loss: 19094.613281\n",
      "Train Epoch: 74 [15168/225000 (7%)] Loss: 19467.003906\n",
      "Train Epoch: 74 [17664/225000 (8%)] Loss: 19359.503906\n",
      "Train Epoch: 74 [20160/225000 (9%)] Loss: 20234.261719\n",
      "Train Epoch: 74 [22656/225000 (10%)] Loss: 19839.441406\n",
      "Train Epoch: 74 [25152/225000 (11%)] Loss: 20064.320312\n",
      "Train Epoch: 74 [27648/225000 (12%)] Loss: 19626.324219\n",
      "Train Epoch: 74 [30144/225000 (13%)] Loss: 19820.816406\n",
      "Train Epoch: 74 [32640/225000 (15%)] Loss: 19509.761719\n",
      "Train Epoch: 74 [35136/225000 (16%)] Loss: 19409.414062\n",
      "Train Epoch: 74 [37632/225000 (17%)] Loss: 19725.853516\n",
      "Train Epoch: 74 [40128/225000 (18%)] Loss: 19592.039062\n",
      "Train Epoch: 74 [42624/225000 (19%)] Loss: 19827.617188\n",
      "Train Epoch: 74 [45120/225000 (20%)] Loss: 19681.464844\n",
      "Train Epoch: 74 [47616/225000 (21%)] Loss: 19739.753906\n",
      "Train Epoch: 74 [50112/225000 (22%)] Loss: 19447.322266\n",
      "Train Epoch: 74 [52608/225000 (23%)] Loss: 19532.808594\n",
      "Train Epoch: 74 [55104/225000 (24%)] Loss: 19586.113281\n",
      "Train Epoch: 74 [57600/225000 (26%)] Loss: 20143.708984\n",
      "Train Epoch: 74 [60096/225000 (27%)] Loss: 19671.960938\n",
      "Train Epoch: 74 [62592/225000 (28%)] Loss: 19565.027344\n",
      "Train Epoch: 74 [65088/225000 (29%)] Loss: 19364.246094\n",
      "Train Epoch: 74 [67584/225000 (30%)] Loss: 19965.021484\n",
      "Train Epoch: 74 [70080/225000 (31%)] Loss: 20016.775391\n",
      "Train Epoch: 74 [72576/225000 (32%)] Loss: 19824.326172\n",
      "Train Epoch: 74 [75072/225000 (33%)] Loss: 19632.666016\n",
      "Train Epoch: 74 [77568/225000 (34%)] Loss: 20139.283203\n",
      "Train Epoch: 74 [80064/225000 (36%)] Loss: 19431.048828\n",
      "Train Epoch: 74 [82560/225000 (37%)] Loss: 19807.958984\n",
      "Train Epoch: 74 [85056/225000 (38%)] Loss: 19344.369141\n",
      "Train Epoch: 74 [87552/225000 (39%)] Loss: 19293.433594\n",
      "Train Epoch: 74 [90048/225000 (40%)] Loss: 19712.964844\n",
      "Train Epoch: 74 [92544/225000 (41%)] Loss: 19580.886719\n",
      "Train Epoch: 74 [95040/225000 (42%)] Loss: 19571.339844\n",
      "Train Epoch: 74 [97536/225000 (43%)] Loss: 19379.189453\n",
      "Train Epoch: 74 [100032/225000 (44%)] Loss: 19749.261719\n",
      "Train Epoch: 74 [102528/225000 (46%)] Loss: 19540.648438\n",
      "Train Epoch: 74 [105024/225000 (47%)] Loss: 19461.792969\n",
      "Train Epoch: 74 [107520/225000 (48%)] Loss: 19675.675781\n",
      "Train Epoch: 74 [110016/225000 (49%)] Loss: 19602.775391\n",
      "Train Epoch: 74 [112512/225000 (50%)] Loss: 19957.660156\n",
      "Train Epoch: 74 [115008/225000 (51%)] Loss: 19504.707031\n",
      "Train Epoch: 74 [117504/225000 (52%)] Loss: 19710.216797\n",
      "Train Epoch: 74 [120000/225000 (53%)] Loss: 19636.179688\n",
      "Train Epoch: 74 [122496/225000 (54%)] Loss: 19487.828125\n",
      "Train Epoch: 74 [124992/225000 (56%)] Loss: 19687.566406\n",
      "Train Epoch: 74 [127488/225000 (57%)] Loss: 20129.830078\n",
      "Train Epoch: 74 [129984/225000 (58%)] Loss: 19839.519531\n",
      "Train Epoch: 74 [132480/225000 (59%)] Loss: 19705.187500\n",
      "Train Epoch: 74 [134976/225000 (60%)] Loss: 19854.734375\n",
      "Train Epoch: 74 [137472/225000 (61%)] Loss: 19523.732422\n",
      "Train Epoch: 74 [139968/225000 (62%)] Loss: 20019.335938\n",
      "Train Epoch: 74 [142464/225000 (63%)] Loss: 19532.123047\n",
      "Train Epoch: 74 [144960/225000 (64%)] Loss: 19635.917969\n",
      "Train Epoch: 74 [147456/225000 (66%)] Loss: 19889.250000\n",
      "Train Epoch: 74 [149952/225000 (67%)] Loss: 20049.998047\n",
      "Train Epoch: 74 [152448/225000 (68%)] Loss: 19461.804688\n",
      "Train Epoch: 74 [154944/225000 (69%)] Loss: 19595.546875\n",
      "Train Epoch: 74 [157440/225000 (70%)] Loss: 19794.501953\n",
      "Train Epoch: 74 [159936/225000 (71%)] Loss: 20221.791016\n",
      "Train Epoch: 74 [162432/225000 (72%)] Loss: 20034.626953\n",
      "Train Epoch: 74 [164928/225000 (73%)] Loss: 19679.230469\n",
      "Train Epoch: 74 [167424/225000 (74%)] Loss: 19730.880859\n",
      "Train Epoch: 74 [169920/225000 (76%)] Loss: 20334.082031\n",
      "Train Epoch: 74 [172416/225000 (77%)] Loss: 19361.410156\n",
      "Train Epoch: 74 [174912/225000 (78%)] Loss: 19865.791016\n",
      "Train Epoch: 74 [177408/225000 (79%)] Loss: 19807.382812\n",
      "Train Epoch: 74 [179904/225000 (80%)] Loss: 20218.261719\n",
      "Train Epoch: 74 [182400/225000 (81%)] Loss: 19572.503906\n",
      "Train Epoch: 74 [184896/225000 (82%)] Loss: 19497.300781\n",
      "Train Epoch: 74 [187392/225000 (83%)] Loss: 20158.996094\n",
      "Train Epoch: 74 [189888/225000 (84%)] Loss: 20020.587891\n",
      "Train Epoch: 74 [192384/225000 (86%)] Loss: 19988.505859\n",
      "Train Epoch: 74 [194880/225000 (87%)] Loss: 19992.580078\n",
      "Train Epoch: 74 [197376/225000 (88%)] Loss: 19765.585938\n",
      "Train Epoch: 74 [199872/225000 (89%)] Loss: 19800.181641\n",
      "Train Epoch: 74 [202368/225000 (90%)] Loss: 19433.824219\n",
      "Train Epoch: 74 [204864/225000 (91%)] Loss: 19721.980469\n",
      "Train Epoch: 74 [207360/225000 (92%)] Loss: 19264.333984\n",
      "Train Epoch: 74 [209856/225000 (93%)] Loss: 19529.457031\n",
      "Train Epoch: 74 [212352/225000 (94%)] Loss: 19906.248047\n",
      "Train Epoch: 74 [214848/225000 (95%)] Loss: 19126.500000\n",
      "Train Epoch: 74 [217344/225000 (97%)] Loss: 19471.970703\n",
      "Train Epoch: 74 [219840/225000 (98%)] Loss: 19756.441406\n",
      "Train Epoch: 74 [222336/225000 (99%)] Loss: 19955.537109\n",
      "Train Epoch: 74 [224832/225000 (100%)] Loss: 19887.843750\n",
      "    epoch          : 74\n",
      "    loss           : 19755.92770104522\n",
      "    val_loss       : 19744.568580573752\n",
      "Train Epoch: 75 [192/225000 (0%)] Loss: 20053.093750\n",
      "Train Epoch: 75 [2688/225000 (1%)] Loss: 19755.433594\n",
      "Train Epoch: 75 [5184/225000 (2%)] Loss: 20012.753906\n",
      "Train Epoch: 75 [7680/225000 (3%)] Loss: 19344.423828\n",
      "Train Epoch: 75 [10176/225000 (5%)] Loss: 19535.912109\n",
      "Train Epoch: 75 [12672/225000 (6%)] Loss: 19846.433594\n",
      "Train Epoch: 75 [15168/225000 (7%)] Loss: 19919.916016\n",
      "Train Epoch: 75 [17664/225000 (8%)] Loss: 19675.574219\n",
      "Train Epoch: 75 [20160/225000 (9%)] Loss: 19409.998047\n",
      "Train Epoch: 75 [22656/225000 (10%)] Loss: 19622.660156\n",
      "Train Epoch: 75 [25152/225000 (11%)] Loss: 19636.875000\n",
      "Train Epoch: 75 [27648/225000 (12%)] Loss: 19821.923828\n",
      "Train Epoch: 75 [30144/225000 (13%)] Loss: 19547.537109\n",
      "Train Epoch: 75 [32640/225000 (15%)] Loss: 19666.931641\n",
      "Train Epoch: 75 [35136/225000 (16%)] Loss: 19203.958984\n",
      "Train Epoch: 75 [37632/225000 (17%)] Loss: 19631.945312\n",
      "Train Epoch: 75 [40128/225000 (18%)] Loss: 19906.703125\n",
      "Train Epoch: 75 [42624/225000 (19%)] Loss: 19061.617188\n",
      "Train Epoch: 75 [45120/225000 (20%)] Loss: 19706.710938\n",
      "Train Epoch: 75 [47616/225000 (21%)] Loss: 19762.056641\n",
      "Train Epoch: 75 [50112/225000 (22%)] Loss: 19886.580078\n",
      "Train Epoch: 75 [52608/225000 (23%)] Loss: 19887.183594\n",
      "Train Epoch: 75 [55104/225000 (24%)] Loss: 20042.023438\n",
      "Train Epoch: 75 [57600/225000 (26%)] Loss: 20082.052734\n",
      "Train Epoch: 75 [60096/225000 (27%)] Loss: 19823.617188\n",
      "Train Epoch: 75 [62592/225000 (28%)] Loss: 19638.535156\n",
      "Train Epoch: 75 [65088/225000 (29%)] Loss: 19466.640625\n",
      "Train Epoch: 75 [67584/225000 (30%)] Loss: 19598.916016\n",
      "Train Epoch: 75 [70080/225000 (31%)] Loss: 19551.279297\n",
      "Train Epoch: 75 [72576/225000 (32%)] Loss: 19606.324219\n",
      "Train Epoch: 75 [75072/225000 (33%)] Loss: 19828.558594\n",
      "Train Epoch: 75 [77568/225000 (34%)] Loss: 19722.406250\n",
      "Train Epoch: 75 [80064/225000 (36%)] Loss: 19648.960938\n",
      "Train Epoch: 75 [82560/225000 (37%)] Loss: 19711.097656\n",
      "Train Epoch: 75 [85056/225000 (38%)] Loss: 19723.062500\n",
      "Train Epoch: 75 [87552/225000 (39%)] Loss: 19295.214844\n",
      "Train Epoch: 75 [90048/225000 (40%)] Loss: 19945.527344\n",
      "Train Epoch: 75 [92544/225000 (41%)] Loss: 19398.359375\n",
      "Train Epoch: 75 [95040/225000 (42%)] Loss: 19955.142578\n",
      "Train Epoch: 75 [97536/225000 (43%)] Loss: 19444.867188\n",
      "Train Epoch: 75 [100032/225000 (44%)] Loss: 19466.224609\n",
      "Train Epoch: 75 [102528/225000 (46%)] Loss: 19903.175781\n",
      "Train Epoch: 75 [105024/225000 (47%)] Loss: 20147.804688\n",
      "Train Epoch: 75 [107520/225000 (48%)] Loss: 20016.222656\n",
      "Train Epoch: 75 [110016/225000 (49%)] Loss: 20229.347656\n",
      "Train Epoch: 75 [112512/225000 (50%)] Loss: 19633.171875\n",
      "Train Epoch: 75 [115008/225000 (51%)] Loss: 19875.041016\n",
      "Train Epoch: 75 [117504/225000 (52%)] Loss: 19894.224609\n",
      "Train Epoch: 75 [120000/225000 (53%)] Loss: 19779.843750\n",
      "Train Epoch: 75 [122496/225000 (54%)] Loss: 19854.199219\n",
      "Train Epoch: 75 [124992/225000 (56%)] Loss: 20107.484375\n",
      "Train Epoch: 75 [127488/225000 (57%)] Loss: 19649.992188\n",
      "Train Epoch: 75 [129984/225000 (58%)] Loss: 19700.000000\n",
      "Train Epoch: 75 [132480/225000 (59%)] Loss: 19914.570312\n",
      "Train Epoch: 75 [134976/225000 (60%)] Loss: 19886.945312\n",
      "Train Epoch: 75 [137472/225000 (61%)] Loss: 20212.140625\n",
      "Train Epoch: 75 [139968/225000 (62%)] Loss: 20006.625000\n",
      "Train Epoch: 75 [142464/225000 (63%)] Loss: 19559.197266\n",
      "Train Epoch: 75 [144960/225000 (64%)] Loss: 18802.445312\n",
      "Train Epoch: 75 [147456/225000 (66%)] Loss: 19445.562500\n",
      "Train Epoch: 75 [149952/225000 (67%)] Loss: 19934.515625\n",
      "Train Epoch: 75 [152448/225000 (68%)] Loss: 20188.150391\n",
      "Train Epoch: 75 [154944/225000 (69%)] Loss: 19785.828125\n",
      "Train Epoch: 75 [157440/225000 (70%)] Loss: 19768.443359\n",
      "Train Epoch: 75 [159936/225000 (71%)] Loss: 20246.044922\n",
      "Train Epoch: 75 [162432/225000 (72%)] Loss: 19426.496094\n",
      "Train Epoch: 75 [164928/225000 (73%)] Loss: 19651.035156\n",
      "Train Epoch: 75 [167424/225000 (74%)] Loss: 19459.759766\n",
      "Train Epoch: 75 [169920/225000 (76%)] Loss: 19317.847656\n",
      "Train Epoch: 75 [172416/225000 (77%)] Loss: 19567.398438\n",
      "Train Epoch: 75 [174912/225000 (78%)] Loss: 19576.039062\n",
      "Train Epoch: 75 [177408/225000 (79%)] Loss: 20006.378906\n",
      "Train Epoch: 75 [179904/225000 (80%)] Loss: 19301.619141\n",
      "Train Epoch: 75 [182400/225000 (81%)] Loss: 19324.824219\n",
      "Train Epoch: 75 [184896/225000 (82%)] Loss: 20203.214844\n",
      "Train Epoch: 75 [187392/225000 (83%)] Loss: 20607.433594\n",
      "Train Epoch: 75 [189888/225000 (84%)] Loss: 19718.949219\n",
      "Train Epoch: 75 [192384/225000 (86%)] Loss: 19484.535156\n",
      "Train Epoch: 75 [194880/225000 (87%)] Loss: 19412.251953\n",
      "Train Epoch: 75 [197376/225000 (88%)] Loss: 19670.519531\n",
      "Train Epoch: 75 [199872/225000 (89%)] Loss: 19750.261719\n",
      "Train Epoch: 75 [202368/225000 (90%)] Loss: 20197.716797\n",
      "Train Epoch: 75 [204864/225000 (91%)] Loss: 20091.001953\n",
      "Train Epoch: 75 [207360/225000 (92%)] Loss: 20025.724609\n",
      "Train Epoch: 75 [209856/225000 (93%)] Loss: 19643.265625\n",
      "Train Epoch: 75 [212352/225000 (94%)] Loss: 19705.835938\n",
      "Train Epoch: 75 [214848/225000 (95%)] Loss: 19753.507812\n",
      "Train Epoch: 75 [217344/225000 (97%)] Loss: 19862.681641\n",
      "Train Epoch: 75 [219840/225000 (98%)] Loss: 19945.156250\n",
      "Train Epoch: 75 [222336/225000 (99%)] Loss: 19861.554688\n",
      "Train Epoch: 75 [224832/225000 (100%)] Loss: 19515.945312\n",
      "    epoch          : 75\n",
      "    loss           : 19739.779015238375\n",
      "    val_loss       : 19650.450103441268\n",
      "Train Epoch: 76 [192/225000 (0%)] Loss: 20140.707031\n",
      "Train Epoch: 76 [2688/225000 (1%)] Loss: 19377.265625\n",
      "Train Epoch: 76 [5184/225000 (2%)] Loss: 20100.121094\n",
      "Train Epoch: 76 [7680/225000 (3%)] Loss: 19820.625000\n",
      "Train Epoch: 76 [10176/225000 (5%)] Loss: 19995.574219\n",
      "Train Epoch: 76 [12672/225000 (6%)] Loss: 20032.177734\n",
      "Train Epoch: 76 [15168/225000 (7%)] Loss: 19397.583984\n",
      "Train Epoch: 76 [17664/225000 (8%)] Loss: 20105.816406\n",
      "Train Epoch: 76 [20160/225000 (9%)] Loss: 19521.085938\n",
      "Train Epoch: 76 [22656/225000 (10%)] Loss: 19240.185547\n",
      "Train Epoch: 76 [25152/225000 (11%)] Loss: 19825.953125\n",
      "Train Epoch: 76 [27648/225000 (12%)] Loss: 19495.546875\n",
      "Train Epoch: 76 [30144/225000 (13%)] Loss: 19497.156250\n",
      "Train Epoch: 76 [32640/225000 (15%)] Loss: 19340.960938\n",
      "Train Epoch: 76 [35136/225000 (16%)] Loss: 19918.656250\n",
      "Train Epoch: 76 [37632/225000 (17%)] Loss: 20126.156250\n",
      "Train Epoch: 76 [40128/225000 (18%)] Loss: 19761.757812\n",
      "Train Epoch: 76 [42624/225000 (19%)] Loss: 18964.726562\n",
      "Train Epoch: 76 [45120/225000 (20%)] Loss: 19897.238281\n",
      "Train Epoch: 76 [47616/225000 (21%)] Loss: 19766.925781\n",
      "Train Epoch: 76 [50112/225000 (22%)] Loss: 19783.410156\n",
      "Train Epoch: 76 [52608/225000 (23%)] Loss: 20102.144531\n",
      "Train Epoch: 76 [55104/225000 (24%)] Loss: 19777.523438\n",
      "Train Epoch: 76 [57600/225000 (26%)] Loss: 19890.054688\n",
      "Train Epoch: 76 [60096/225000 (27%)] Loss: 19484.605469\n",
      "Train Epoch: 76 [62592/225000 (28%)] Loss: 19519.726562\n",
      "Train Epoch: 76 [65088/225000 (29%)] Loss: 19892.527344\n",
      "Train Epoch: 76 [67584/225000 (30%)] Loss: 19652.755859\n",
      "Train Epoch: 76 [70080/225000 (31%)] Loss: 19975.695312\n",
      "Train Epoch: 76 [72576/225000 (32%)] Loss: 19113.906250\n",
      "Train Epoch: 76 [75072/225000 (33%)] Loss: 19906.021484\n",
      "Train Epoch: 76 [77568/225000 (34%)] Loss: 19600.427734\n",
      "Train Epoch: 76 [80064/225000 (36%)] Loss: 20328.183594\n",
      "Train Epoch: 76 [82560/225000 (37%)] Loss: 19662.898438\n",
      "Train Epoch: 76 [85056/225000 (38%)] Loss: 19432.939453\n",
      "Train Epoch: 76 [87552/225000 (39%)] Loss: 20181.035156\n",
      "Train Epoch: 76 [90048/225000 (40%)] Loss: 19723.984375\n",
      "Train Epoch: 76 [92544/225000 (41%)] Loss: 20111.974609\n",
      "Train Epoch: 76 [95040/225000 (42%)] Loss: 19570.500000\n",
      "Train Epoch: 76 [97536/225000 (43%)] Loss: 19604.960938\n",
      "Train Epoch: 76 [100032/225000 (44%)] Loss: 19881.378906\n",
      "Train Epoch: 76 [102528/225000 (46%)] Loss: 19835.763672\n",
      "Train Epoch: 76 [105024/225000 (47%)] Loss: 19785.644531\n",
      "Train Epoch: 76 [107520/225000 (48%)] Loss: 19610.199219\n",
      "Train Epoch: 76 [110016/225000 (49%)] Loss: 19843.066406\n",
      "Train Epoch: 76 [112512/225000 (50%)] Loss: 20149.041016\n",
      "Train Epoch: 76 [115008/225000 (51%)] Loss: 20086.531250\n",
      "Train Epoch: 76 [117504/225000 (52%)] Loss: 19569.941406\n",
      "Train Epoch: 76 [120000/225000 (53%)] Loss: 19549.410156\n",
      "Train Epoch: 76 [122496/225000 (54%)] Loss: 19645.734375\n",
      "Train Epoch: 76 [124992/225000 (56%)] Loss: 20127.851562\n",
      "Train Epoch: 76 [127488/225000 (57%)] Loss: 18935.802734\n",
      "Train Epoch: 76 [129984/225000 (58%)] Loss: 19501.875000\n",
      "Train Epoch: 76 [132480/225000 (59%)] Loss: 20166.707031\n",
      "Train Epoch: 76 [134976/225000 (60%)] Loss: 19601.759766\n",
      "Train Epoch: 76 [137472/225000 (61%)] Loss: 19708.863281\n",
      "Train Epoch: 76 [139968/225000 (62%)] Loss: 19917.203125\n",
      "Train Epoch: 76 [142464/225000 (63%)] Loss: 20357.689453\n",
      "Train Epoch: 76 [144960/225000 (64%)] Loss: 19808.816406\n",
      "Train Epoch: 76 [147456/225000 (66%)] Loss: 19828.367188\n",
      "Train Epoch: 76 [149952/225000 (67%)] Loss: 19696.386719\n",
      "Train Epoch: 76 [152448/225000 (68%)] Loss: 19639.828125\n",
      "Train Epoch: 76 [154944/225000 (69%)] Loss: 20049.535156\n",
      "Train Epoch: 76 [157440/225000 (70%)] Loss: 19686.931641\n",
      "Train Epoch: 76 [159936/225000 (71%)] Loss: 19309.294922\n",
      "Train Epoch: 76 [162432/225000 (72%)] Loss: 20043.210938\n",
      "Train Epoch: 76 [164928/225000 (73%)] Loss: 19629.601562\n",
      "Train Epoch: 76 [167424/225000 (74%)] Loss: 20164.789062\n",
      "Train Epoch: 76 [169920/225000 (76%)] Loss: 19378.044922\n",
      "Train Epoch: 76 [172416/225000 (77%)] Loss: 19650.195312\n",
      "Train Epoch: 76 [174912/225000 (78%)] Loss: 19973.701172\n",
      "Train Epoch: 76 [177408/225000 (79%)] Loss: 19610.441406\n",
      "Train Epoch: 76 [179904/225000 (80%)] Loss: 19808.351562\n",
      "Train Epoch: 76 [182400/225000 (81%)] Loss: 19333.367188\n",
      "Train Epoch: 76 [184896/225000 (82%)] Loss: 19316.730469\n",
      "Train Epoch: 76 [187392/225000 (83%)] Loss: 20291.046875\n",
      "Train Epoch: 76 [189888/225000 (84%)] Loss: 19896.519531\n",
      "Train Epoch: 76 [192384/225000 (86%)] Loss: 20156.265625\n",
      "Train Epoch: 76 [194880/225000 (87%)] Loss: 19708.550781\n",
      "Train Epoch: 76 [197376/225000 (88%)] Loss: 19548.988281\n",
      "Train Epoch: 76 [199872/225000 (89%)] Loss: 19680.005859\n",
      "Train Epoch: 76 [202368/225000 (90%)] Loss: 19999.708984\n",
      "Train Epoch: 76 [204864/225000 (91%)] Loss: 19653.740234\n",
      "Train Epoch: 76 [207360/225000 (92%)] Loss: 19418.378906\n",
      "Train Epoch: 76 [209856/225000 (93%)] Loss: 19529.601562\n",
      "Train Epoch: 76 [212352/225000 (94%)] Loss: 19667.251953\n",
      "Train Epoch: 76 [214848/225000 (95%)] Loss: 19331.250000\n",
      "Train Epoch: 76 [217344/225000 (97%)] Loss: 19401.148438\n",
      "Train Epoch: 76 [219840/225000 (98%)] Loss: 19472.980469\n",
      "Train Epoch: 76 [222336/225000 (99%)] Loss: 19650.484375\n",
      "Train Epoch: 76 [224832/225000 (100%)] Loss: 20165.357422\n",
      "    epoch          : 76\n",
      "    loss           : 19732.591786876066\n",
      "    val_loss       : 19655.37252277454\n",
      "Train Epoch: 77 [192/225000 (0%)] Loss: 20119.080078\n",
      "Train Epoch: 77 [2688/225000 (1%)] Loss: 19665.054688\n",
      "Train Epoch: 77 [5184/225000 (2%)] Loss: 19763.597656\n",
      "Train Epoch: 77 [7680/225000 (3%)] Loss: 19648.429688\n",
      "Train Epoch: 77 [10176/225000 (5%)] Loss: 20071.808594\n",
      "Train Epoch: 77 [12672/225000 (6%)] Loss: 19513.285156\n",
      "Train Epoch: 77 [15168/225000 (7%)] Loss: 20127.574219\n",
      "Train Epoch: 77 [17664/225000 (8%)] Loss: 20017.007812\n",
      "Train Epoch: 77 [20160/225000 (9%)] Loss: 19903.304688\n",
      "Train Epoch: 77 [22656/225000 (10%)] Loss: 19901.767578\n",
      "Train Epoch: 77 [25152/225000 (11%)] Loss: 19772.458984\n",
      "Train Epoch: 77 [27648/225000 (12%)] Loss: 19566.929688\n",
      "Train Epoch: 77 [30144/225000 (13%)] Loss: 19804.847656\n",
      "Train Epoch: 77 [32640/225000 (15%)] Loss: 19944.023438\n",
      "Train Epoch: 77 [35136/225000 (16%)] Loss: 19458.597656\n",
      "Train Epoch: 77 [37632/225000 (17%)] Loss: 19705.546875\n",
      "Train Epoch: 77 [40128/225000 (18%)] Loss: 19305.238281\n",
      "Train Epoch: 77 [42624/225000 (19%)] Loss: 19559.820312\n",
      "Train Epoch: 77 [45120/225000 (20%)] Loss: 19783.109375\n",
      "Train Epoch: 77 [47616/225000 (21%)] Loss: 20003.810547\n",
      "Train Epoch: 77 [50112/225000 (22%)] Loss: 19779.515625\n",
      "Train Epoch: 77 [52608/225000 (23%)] Loss: 19808.050781\n",
      "Train Epoch: 77 [55104/225000 (24%)] Loss: 19682.015625\n",
      "Train Epoch: 77 [57600/225000 (26%)] Loss: 19314.263672\n",
      "Train Epoch: 77 [60096/225000 (27%)] Loss: 20143.531250\n",
      "Train Epoch: 77 [62592/225000 (28%)] Loss: 19425.500000\n",
      "Train Epoch: 77 [65088/225000 (29%)] Loss: 20174.781250\n",
      "Train Epoch: 77 [67584/225000 (30%)] Loss: 19949.441406\n",
      "Train Epoch: 77 [70080/225000 (31%)] Loss: 19449.613281\n",
      "Train Epoch: 77 [72576/225000 (32%)] Loss: 19689.527344\n",
      "Train Epoch: 77 [75072/225000 (33%)] Loss: 20176.304688\n",
      "Train Epoch: 77 [77568/225000 (34%)] Loss: 19901.351562\n",
      "Train Epoch: 77 [80064/225000 (36%)] Loss: 20105.513672\n",
      "Train Epoch: 77 [82560/225000 (37%)] Loss: 19752.031250\n",
      "Train Epoch: 77 [85056/225000 (38%)] Loss: 19425.091797\n",
      "Train Epoch: 77 [87552/225000 (39%)] Loss: 19684.500000\n",
      "Train Epoch: 77 [90048/225000 (40%)] Loss: 19777.906250\n",
      "Train Epoch: 77 [92544/225000 (41%)] Loss: 19731.769531\n",
      "Train Epoch: 77 [95040/225000 (42%)] Loss: 19660.726562\n",
      "Train Epoch: 77 [97536/225000 (43%)] Loss: 19456.265625\n",
      "Train Epoch: 77 [100032/225000 (44%)] Loss: 19925.480469\n",
      "Train Epoch: 77 [102528/225000 (46%)] Loss: 20043.714844\n",
      "Train Epoch: 77 [105024/225000 (47%)] Loss: 20232.000000\n",
      "Train Epoch: 77 [107520/225000 (48%)] Loss: 19373.082031\n",
      "Train Epoch: 77 [110016/225000 (49%)] Loss: 19918.648438\n",
      "Train Epoch: 77 [112512/225000 (50%)] Loss: 19741.902344\n",
      "Train Epoch: 77 [115008/225000 (51%)] Loss: 19928.523438\n",
      "Train Epoch: 77 [117504/225000 (52%)] Loss: 20030.023438\n",
      "Train Epoch: 77 [120000/225000 (53%)] Loss: 19716.210938\n",
      "Train Epoch: 77 [122496/225000 (54%)] Loss: 19991.351562\n",
      "Train Epoch: 77 [124992/225000 (56%)] Loss: 19406.369141\n",
      "Train Epoch: 77 [127488/225000 (57%)] Loss: 19297.371094\n",
      "Train Epoch: 77 [129984/225000 (58%)] Loss: 20002.611328\n",
      "Train Epoch: 77 [132480/225000 (59%)] Loss: 19917.878906\n",
      "Train Epoch: 77 [134976/225000 (60%)] Loss: 19857.125000\n",
      "Train Epoch: 77 [137472/225000 (61%)] Loss: 20137.751953\n",
      "Train Epoch: 77 [139968/225000 (62%)] Loss: 19551.921875\n",
      "Train Epoch: 77 [142464/225000 (63%)] Loss: 19301.275391\n",
      "Train Epoch: 77 [144960/225000 (64%)] Loss: 19849.007812\n",
      "Train Epoch: 77 [147456/225000 (66%)] Loss: 20105.802734\n",
      "Train Epoch: 77 [149952/225000 (67%)] Loss: 19666.843750\n",
      "Train Epoch: 77 [152448/225000 (68%)] Loss: 19781.851562\n",
      "Train Epoch: 77 [154944/225000 (69%)] Loss: 19749.710938\n",
      "Train Epoch: 77 [157440/225000 (70%)] Loss: 19943.427734\n",
      "Train Epoch: 77 [159936/225000 (71%)] Loss: 19707.902344\n",
      "Train Epoch: 77 [162432/225000 (72%)] Loss: 19749.082031\n",
      "Train Epoch: 77 [164928/225000 (73%)] Loss: 19461.796875\n",
      "Train Epoch: 77 [167424/225000 (74%)] Loss: 19767.042969\n",
      "Train Epoch: 77 [169920/225000 (76%)] Loss: 19682.886719\n",
      "Train Epoch: 77 [172416/225000 (77%)] Loss: 19313.250000\n",
      "Train Epoch: 77 [174912/225000 (78%)] Loss: 19443.238281\n",
      "Train Epoch: 77 [177408/225000 (79%)] Loss: 19451.781250\n",
      "Train Epoch: 77 [179904/225000 (80%)] Loss: 19576.191406\n",
      "Train Epoch: 77 [182400/225000 (81%)] Loss: 19295.925781\n",
      "Train Epoch: 77 [184896/225000 (82%)] Loss: 19570.312500\n",
      "Train Epoch: 77 [187392/225000 (83%)] Loss: 19851.945312\n",
      "Train Epoch: 77 [189888/225000 (84%)] Loss: 19344.927734\n",
      "Train Epoch: 77 [192384/225000 (86%)] Loss: 19961.935547\n",
      "Train Epoch: 77 [194880/225000 (87%)] Loss: 19374.000000\n",
      "Train Epoch: 77 [197376/225000 (88%)] Loss: 19920.371094\n",
      "Train Epoch: 77 [199872/225000 (89%)] Loss: 19262.628906\n",
      "Train Epoch: 77 [202368/225000 (90%)] Loss: 19724.375000\n",
      "Train Epoch: 77 [204864/225000 (91%)] Loss: 19803.847656\n",
      "Train Epoch: 77 [207360/225000 (92%)] Loss: 19618.277344\n",
      "Train Epoch: 77 [209856/225000 (93%)] Loss: 19885.367188\n",
      "Train Epoch: 77 [212352/225000 (94%)] Loss: 19732.718750\n",
      "Train Epoch: 77 [214848/225000 (95%)] Loss: 19741.943359\n",
      "Train Epoch: 77 [217344/225000 (97%)] Loss: 19648.232422\n",
      "Train Epoch: 77 [219840/225000 (98%)] Loss: 19505.750000\n",
      "Train Epoch: 77 [222336/225000 (99%)] Loss: 19783.824219\n",
      "Train Epoch: 77 [224832/225000 (100%)] Loss: 19957.402344\n",
      "    epoch          : 77\n",
      "    loss           : 19710.991762545327\n",
      "    val_loss       : 19610.478863387616\n",
      "Train Epoch: 78 [192/225000 (0%)] Loss: 19884.324219\n",
      "Train Epoch: 78 [2688/225000 (1%)] Loss: 19415.125000\n",
      "Train Epoch: 78 [5184/225000 (2%)] Loss: 19860.849609\n",
      "Train Epoch: 78 [7680/225000 (3%)] Loss: 19441.640625\n",
      "Train Epoch: 78 [10176/225000 (5%)] Loss: 20024.339844\n",
      "Train Epoch: 78 [12672/225000 (6%)] Loss: 20016.191406\n",
      "Train Epoch: 78 [15168/225000 (7%)] Loss: 19886.417969\n",
      "Train Epoch: 78 [17664/225000 (8%)] Loss: 19278.593750\n",
      "Train Epoch: 78 [20160/225000 (9%)] Loss: 19833.937500\n",
      "Train Epoch: 78 [22656/225000 (10%)] Loss: 19730.964844\n",
      "Train Epoch: 78 [25152/225000 (11%)] Loss: 19219.701172\n",
      "Train Epoch: 78 [27648/225000 (12%)] Loss: 20330.718750\n",
      "Train Epoch: 78 [30144/225000 (13%)] Loss: 19564.296875\n",
      "Train Epoch: 78 [32640/225000 (15%)] Loss: 19480.726562\n",
      "Train Epoch: 78 [35136/225000 (16%)] Loss: 19291.679688\n",
      "Train Epoch: 78 [37632/225000 (17%)] Loss: 19778.359375\n",
      "Train Epoch: 78 [40128/225000 (18%)] Loss: 19742.689453\n",
      "Train Epoch: 78 [42624/225000 (19%)] Loss: 19803.808594\n",
      "Train Epoch: 78 [45120/225000 (20%)] Loss: 19926.734375\n",
      "Train Epoch: 78 [47616/225000 (21%)] Loss: 19777.572266\n",
      "Train Epoch: 78 [50112/225000 (22%)] Loss: 19725.652344\n",
      "Train Epoch: 78 [52608/225000 (23%)] Loss: 19850.511719\n",
      "Train Epoch: 78 [55104/225000 (24%)] Loss: 19466.119141\n",
      "Train Epoch: 78 [57600/225000 (26%)] Loss: 19765.078125\n",
      "Train Epoch: 78 [60096/225000 (27%)] Loss: 19818.613281\n",
      "Train Epoch: 78 [62592/225000 (28%)] Loss: 19771.605469\n",
      "Train Epoch: 78 [65088/225000 (29%)] Loss: 19431.152344\n",
      "Train Epoch: 78 [67584/225000 (30%)] Loss: 19745.339844\n",
      "Train Epoch: 78 [70080/225000 (31%)] Loss: 19759.480469\n",
      "Train Epoch: 78 [72576/225000 (32%)] Loss: 19594.726562\n",
      "Train Epoch: 78 [75072/225000 (33%)] Loss: 20358.503906\n",
      "Train Epoch: 78 [77568/225000 (34%)] Loss: 19969.419922\n",
      "Train Epoch: 78 [80064/225000 (36%)] Loss: 19541.037109\n",
      "Train Epoch: 78 [82560/225000 (37%)] Loss: 19725.054688\n",
      "Train Epoch: 78 [85056/225000 (38%)] Loss: 19395.693359\n",
      "Train Epoch: 78 [87552/225000 (39%)] Loss: 19644.046875\n",
      "Train Epoch: 78 [90048/225000 (40%)] Loss: 20052.130859\n",
      "Train Epoch: 78 [92544/225000 (41%)] Loss: 19960.382812\n",
      "Train Epoch: 78 [95040/225000 (42%)] Loss: 19701.119141\n",
      "Train Epoch: 78 [97536/225000 (43%)] Loss: 19432.902344\n",
      "Train Epoch: 78 [100032/225000 (44%)] Loss: 19951.265625\n",
      "Train Epoch: 78 [102528/225000 (46%)] Loss: 19493.453125\n",
      "Train Epoch: 78 [105024/225000 (47%)] Loss: 19956.894531\n",
      "Train Epoch: 78 [107520/225000 (48%)] Loss: 19574.925781\n",
      "Train Epoch: 78 [110016/225000 (49%)] Loss: 19322.011719\n",
      "Train Epoch: 78 [112512/225000 (50%)] Loss: 19978.001953\n",
      "Train Epoch: 78 [115008/225000 (51%)] Loss: 19427.343750\n",
      "Train Epoch: 78 [117504/225000 (52%)] Loss: 19366.207031\n",
      "Train Epoch: 78 [120000/225000 (53%)] Loss: 19643.763672\n",
      "Train Epoch: 78 [122496/225000 (54%)] Loss: 20256.042969\n",
      "Train Epoch: 78 [124992/225000 (56%)] Loss: 19876.697266\n",
      "Train Epoch: 78 [127488/225000 (57%)] Loss: 19400.654297\n",
      "Train Epoch: 78 [129984/225000 (58%)] Loss: 20066.593750\n",
      "Train Epoch: 78 [132480/225000 (59%)] Loss: 19638.093750\n",
      "Train Epoch: 78 [134976/225000 (60%)] Loss: 20075.718750\n",
      "Train Epoch: 78 [137472/225000 (61%)] Loss: 19573.439453\n",
      "Train Epoch: 78 [139968/225000 (62%)] Loss: 20098.685547\n",
      "Train Epoch: 78 [142464/225000 (63%)] Loss: 19497.832031\n",
      "Train Epoch: 78 [144960/225000 (64%)] Loss: 19505.578125\n",
      "Train Epoch: 78 [147456/225000 (66%)] Loss: 19718.308594\n",
      "Train Epoch: 78 [149952/225000 (67%)] Loss: 19845.281250\n",
      "Train Epoch: 78 [152448/225000 (68%)] Loss: 19232.109375\n",
      "Train Epoch: 78 [154944/225000 (69%)] Loss: 20027.955078\n",
      "Train Epoch: 78 [157440/225000 (70%)] Loss: 19210.089844\n",
      "Train Epoch: 78 [159936/225000 (71%)] Loss: 19844.000000\n",
      "Train Epoch: 78 [162432/225000 (72%)] Loss: 19804.210938\n",
      "Train Epoch: 78 [164928/225000 (73%)] Loss: 20107.312500\n",
      "Train Epoch: 78 [167424/225000 (74%)] Loss: 19450.257812\n",
      "Train Epoch: 78 [169920/225000 (76%)] Loss: 19681.726562\n",
      "Train Epoch: 78 [172416/225000 (77%)] Loss: 19455.230469\n",
      "Train Epoch: 78 [174912/225000 (78%)] Loss: 19967.853516\n",
      "Train Epoch: 78 [177408/225000 (79%)] Loss: 19322.121094\n",
      "Train Epoch: 78 [179904/225000 (80%)] Loss: 19986.972656\n",
      "Train Epoch: 78 [182400/225000 (81%)] Loss: 19369.537109\n",
      "Train Epoch: 78 [184896/225000 (82%)] Loss: 19537.173828\n",
      "Train Epoch: 78 [187392/225000 (83%)] Loss: 19527.273438\n",
      "Train Epoch: 78 [189888/225000 (84%)] Loss: 19544.865234\n",
      "Train Epoch: 78 [192384/225000 (86%)] Loss: 19147.519531\n",
      "Train Epoch: 78 [194880/225000 (87%)] Loss: 19715.439453\n",
      "Train Epoch: 78 [197376/225000 (88%)] Loss: 19417.519531\n",
      "Train Epoch: 78 [199872/225000 (89%)] Loss: 19505.892578\n",
      "Train Epoch: 78 [202368/225000 (90%)] Loss: 19544.224609\n",
      "Train Epoch: 78 [204864/225000 (91%)] Loss: 19871.904297\n",
      "Train Epoch: 78 [207360/225000 (92%)] Loss: 19300.085938\n",
      "Train Epoch: 78 [209856/225000 (93%)] Loss: 19178.835938\n",
      "Train Epoch: 78 [212352/225000 (94%)] Loss: 19059.367188\n",
      "Train Epoch: 78 [214848/225000 (95%)] Loss: 19409.699219\n",
      "Train Epoch: 78 [217344/225000 (97%)] Loss: 19322.775391\n",
      "Train Epoch: 78 [219840/225000 (98%)] Loss: 19662.992188\n",
      "Train Epoch: 78 [222336/225000 (99%)] Loss: 20041.933594\n",
      "Train Epoch: 78 [224832/225000 (100%)] Loss: 19630.269531\n",
      "    epoch          : 78\n",
      "    loss           : 19707.813761532103\n",
      "    val_loss       : 19603.871453893094\n",
      "Train Epoch: 79 [192/225000 (0%)] Loss: 20087.480469\n",
      "Train Epoch: 79 [2688/225000 (1%)] Loss: 19670.730469\n",
      "Train Epoch: 79 [5184/225000 (2%)] Loss: 19718.656250\n",
      "Train Epoch: 79 [7680/225000 (3%)] Loss: 19738.308594\n",
      "Train Epoch: 79 [10176/225000 (5%)] Loss: 19761.144531\n",
      "Train Epoch: 79 [12672/225000 (6%)] Loss: 19833.773438\n",
      "Train Epoch: 79 [15168/225000 (7%)] Loss: 19493.832031\n",
      "Train Epoch: 79 [17664/225000 (8%)] Loss: 19854.556641\n",
      "Train Epoch: 79 [20160/225000 (9%)] Loss: 19596.078125\n",
      "Train Epoch: 79 [22656/225000 (10%)] Loss: 19443.259766\n",
      "Train Epoch: 79 [25152/225000 (11%)] Loss: 19673.781250\n",
      "Train Epoch: 79 [27648/225000 (12%)] Loss: 19859.300781\n",
      "Train Epoch: 79 [30144/225000 (13%)] Loss: 19527.755859\n",
      "Train Epoch: 79 [32640/225000 (15%)] Loss: 20026.113281\n",
      "Train Epoch: 79 [35136/225000 (16%)] Loss: 19729.929688\n",
      "Train Epoch: 79 [37632/225000 (17%)] Loss: 19788.281250\n",
      "Train Epoch: 79 [40128/225000 (18%)] Loss: 19526.824219\n",
      "Train Epoch: 79 [42624/225000 (19%)] Loss: 19375.851562\n",
      "Train Epoch: 79 [45120/225000 (20%)] Loss: 19417.181641\n",
      "Train Epoch: 79 [47616/225000 (21%)] Loss: 19536.851562\n",
      "Train Epoch: 79 [50112/225000 (22%)] Loss: 19727.296875\n",
      "Train Epoch: 79 [52608/225000 (23%)] Loss: 19823.171875\n",
      "Train Epoch: 79 [55104/225000 (24%)] Loss: 19440.433594\n",
      "Train Epoch: 79 [57600/225000 (26%)] Loss: 19560.835938\n",
      "Train Epoch: 79 [60096/225000 (27%)] Loss: 19879.687500\n",
      "Train Epoch: 79 [62592/225000 (28%)] Loss: 19693.242188\n",
      "Train Epoch: 79 [65088/225000 (29%)] Loss: 20137.320312\n",
      "Train Epoch: 79 [67584/225000 (30%)] Loss: 19764.343750\n",
      "Train Epoch: 79 [70080/225000 (31%)] Loss: 19495.449219\n",
      "Train Epoch: 79 [72576/225000 (32%)] Loss: 19472.527344\n",
      "Train Epoch: 79 [75072/225000 (33%)] Loss: 19514.638672\n",
      "Train Epoch: 79 [77568/225000 (34%)] Loss: 19523.195312\n",
      "Train Epoch: 79 [80064/225000 (36%)] Loss: 19469.289062\n",
      "Train Epoch: 79 [82560/225000 (37%)] Loss: 19934.406250\n",
      "Train Epoch: 79 [85056/225000 (38%)] Loss: 19499.140625\n",
      "Train Epoch: 79 [87552/225000 (39%)] Loss: 19167.285156\n",
      "Train Epoch: 79 [90048/225000 (40%)] Loss: 20035.156250\n",
      "Train Epoch: 79 [92544/225000 (41%)] Loss: 19867.820312\n",
      "Train Epoch: 79 [95040/225000 (42%)] Loss: 19802.025391\n",
      "Train Epoch: 79 [97536/225000 (43%)] Loss: 19394.781250\n",
      "Train Epoch: 79 [100032/225000 (44%)] Loss: 19669.095703\n",
      "Train Epoch: 79 [102528/225000 (46%)] Loss: 20102.732422\n",
      "Train Epoch: 79 [105024/225000 (47%)] Loss: 19755.351562\n",
      "Train Epoch: 79 [107520/225000 (48%)] Loss: 19984.363281\n",
      "Train Epoch: 79 [110016/225000 (49%)] Loss: 19490.886719\n",
      "Train Epoch: 79 [112512/225000 (50%)] Loss: 19313.625000\n",
      "Train Epoch: 79 [115008/225000 (51%)] Loss: 19917.289062\n",
      "Train Epoch: 79 [117504/225000 (52%)] Loss: 20135.017578\n",
      "Train Epoch: 79 [120000/225000 (53%)] Loss: 19863.542969\n",
      "Train Epoch: 79 [122496/225000 (54%)] Loss: 19408.654297\n",
      "Train Epoch: 79 [124992/225000 (56%)] Loss: 19626.250000\n",
      "Train Epoch: 79 [127488/225000 (57%)] Loss: 19068.937500\n",
      "Train Epoch: 79 [129984/225000 (58%)] Loss: 19725.160156\n",
      "Train Epoch: 79 [132480/225000 (59%)] Loss: 19981.976562\n",
      "Train Epoch: 79 [134976/225000 (60%)] Loss: 19797.416016\n",
      "Train Epoch: 79 [137472/225000 (61%)] Loss: 19371.958984\n",
      "Train Epoch: 79 [139968/225000 (62%)] Loss: 19564.894531\n",
      "Train Epoch: 79 [142464/225000 (63%)] Loss: 19650.230469\n",
      "Train Epoch: 79 [144960/225000 (64%)] Loss: 19826.564453\n",
      "Train Epoch: 79 [147456/225000 (66%)] Loss: 19592.722656\n",
      "Train Epoch: 79 [149952/225000 (67%)] Loss: 19886.564453\n",
      "Train Epoch: 79 [152448/225000 (68%)] Loss: 19485.312500\n",
      "Train Epoch: 79 [154944/225000 (69%)] Loss: 20154.976562\n",
      "Train Epoch: 79 [157440/225000 (70%)] Loss: 19319.675781\n",
      "Train Epoch: 79 [159936/225000 (71%)] Loss: 19618.531250\n",
      "Train Epoch: 79 [162432/225000 (72%)] Loss: 19573.880859\n",
      "Train Epoch: 79 [164928/225000 (73%)] Loss: 20013.902344\n",
      "Train Epoch: 79 [167424/225000 (74%)] Loss: 19790.138672\n",
      "Train Epoch: 79 [169920/225000 (76%)] Loss: 19451.462891\n",
      "Train Epoch: 79 [172416/225000 (77%)] Loss: 19947.515625\n",
      "Train Epoch: 79 [174912/225000 (78%)] Loss: 19256.390625\n",
      "Train Epoch: 79 [177408/225000 (79%)] Loss: 19494.503906\n",
      "Train Epoch: 79 [179904/225000 (80%)] Loss: 19489.810547\n",
      "Train Epoch: 79 [182400/225000 (81%)] Loss: 19670.246094\n",
      "Train Epoch: 79 [184896/225000 (82%)] Loss: 19511.867188\n",
      "Train Epoch: 79 [187392/225000 (83%)] Loss: 19342.023438\n",
      "Train Epoch: 79 [189888/225000 (84%)] Loss: 19730.964844\n",
      "Train Epoch: 79 [192384/225000 (86%)] Loss: 19527.375000\n",
      "Train Epoch: 79 [194880/225000 (87%)] Loss: 19977.511719\n",
      "Train Epoch: 79 [197376/225000 (88%)] Loss: 19722.894531\n",
      "Train Epoch: 79 [199872/225000 (89%)] Loss: 19538.140625\n",
      "Train Epoch: 79 [202368/225000 (90%)] Loss: 19734.152344\n",
      "Train Epoch: 79 [204864/225000 (91%)] Loss: 19713.382812\n",
      "Train Epoch: 79 [207360/225000 (92%)] Loss: 19621.648438\n",
      "Train Epoch: 79 [209856/225000 (93%)] Loss: 20158.041016\n",
      "Train Epoch: 79 [212352/225000 (94%)] Loss: 19611.988281\n",
      "Train Epoch: 79 [214848/225000 (95%)] Loss: 19719.410156\n",
      "Train Epoch: 79 [217344/225000 (97%)] Loss: 19538.363281\n",
      "Train Epoch: 79 [219840/225000 (98%)] Loss: 19524.109375\n",
      "Train Epoch: 79 [222336/225000 (99%)] Loss: 19217.187500\n",
      "Train Epoch: 79 [224832/225000 (100%)] Loss: 19244.644531\n",
      "    epoch          : 79\n",
      "    loss           : 19702.898152530397\n",
      "    val_loss       : 19592.182392959377\n",
      "Train Epoch: 80 [192/225000 (0%)] Loss: 19904.503906\n",
      "Train Epoch: 80 [2688/225000 (1%)] Loss: 19779.847656\n",
      "Train Epoch: 80 [5184/225000 (2%)] Loss: 19787.265625\n",
      "Train Epoch: 80 [7680/225000 (3%)] Loss: 20036.343750\n",
      "Train Epoch: 80 [10176/225000 (5%)] Loss: 19817.578125\n",
      "Train Epoch: 80 [12672/225000 (6%)] Loss: 19720.982422\n",
      "Train Epoch: 80 [15168/225000 (7%)] Loss: 19719.246094\n",
      "Train Epoch: 80 [17664/225000 (8%)] Loss: 19542.398438\n",
      "Train Epoch: 80 [20160/225000 (9%)] Loss: 19397.328125\n",
      "Train Epoch: 80 [22656/225000 (10%)] Loss: 19794.234375\n",
      "Train Epoch: 80 [25152/225000 (11%)] Loss: 19659.033203\n",
      "Train Epoch: 80 [27648/225000 (12%)] Loss: 19554.285156\n",
      "Train Epoch: 80 [30144/225000 (13%)] Loss: 19803.812500\n",
      "Train Epoch: 80 [32640/225000 (15%)] Loss: 19524.439453\n",
      "Train Epoch: 80 [35136/225000 (16%)] Loss: 19833.181641\n",
      "Train Epoch: 80 [37632/225000 (17%)] Loss: 19197.083984\n",
      "Train Epoch: 80 [40128/225000 (18%)] Loss: 19695.863281\n",
      "Train Epoch: 80 [42624/225000 (19%)] Loss: 19423.945312\n",
      "Train Epoch: 80 [45120/225000 (20%)] Loss: 19398.343750\n",
      "Train Epoch: 80 [47616/225000 (21%)] Loss: 19861.419922\n",
      "Train Epoch: 80 [50112/225000 (22%)] Loss: 19646.820312\n",
      "Train Epoch: 80 [52608/225000 (23%)] Loss: 19544.591797\n",
      "Train Epoch: 80 [55104/225000 (24%)] Loss: 19893.378906\n",
      "Train Epoch: 80 [57600/225000 (26%)] Loss: 19812.355469\n",
      "Train Epoch: 80 [60096/225000 (27%)] Loss: 19759.839844\n",
      "Train Epoch: 80 [62592/225000 (28%)] Loss: 19576.916016\n",
      "Train Epoch: 80 [65088/225000 (29%)] Loss: 19744.746094\n",
      "Train Epoch: 80 [67584/225000 (30%)] Loss: 19569.855469\n",
      "Train Epoch: 80 [70080/225000 (31%)] Loss: 19897.660156\n",
      "Train Epoch: 80 [72576/225000 (32%)] Loss: 19953.513672\n",
      "Train Epoch: 80 [75072/225000 (33%)] Loss: 19122.789062\n",
      "Train Epoch: 80 [77568/225000 (34%)] Loss: 19496.740234\n",
      "Train Epoch: 80 [80064/225000 (36%)] Loss: 19643.779297\n",
      "Train Epoch: 80 [82560/225000 (37%)] Loss: 19618.535156\n",
      "Train Epoch: 80 [85056/225000 (38%)] Loss: 19506.902344\n",
      "Train Epoch: 80 [87552/225000 (39%)] Loss: 20203.175781\n",
      "Train Epoch: 80 [90048/225000 (40%)] Loss: 19248.031250\n",
      "Train Epoch: 80 [92544/225000 (41%)] Loss: 19513.507812\n",
      "Train Epoch: 80 [95040/225000 (42%)] Loss: 19602.128906\n",
      "Train Epoch: 80 [97536/225000 (43%)] Loss: 19095.296875\n",
      "Train Epoch: 80 [100032/225000 (44%)] Loss: 19610.582031\n",
      "Train Epoch: 80 [102528/225000 (46%)] Loss: 19272.851562\n",
      "Train Epoch: 80 [105024/225000 (47%)] Loss: 19718.828125\n",
      "Train Epoch: 80 [107520/225000 (48%)] Loss: 19662.402344\n",
      "Train Epoch: 80 [110016/225000 (49%)] Loss: 19881.783203\n",
      "Train Epoch: 80 [112512/225000 (50%)] Loss: 19657.996094\n",
      "Train Epoch: 80 [115008/225000 (51%)] Loss: 19373.421875\n",
      "Train Epoch: 80 [117504/225000 (52%)] Loss: 18886.488281\n",
      "Train Epoch: 80 [120000/225000 (53%)] Loss: 19794.236328\n",
      "Train Epoch: 80 [122496/225000 (54%)] Loss: 19691.998047\n",
      "Train Epoch: 80 [124992/225000 (56%)] Loss: 19285.308594\n",
      "Train Epoch: 80 [127488/225000 (57%)] Loss: 19523.964844\n",
      "Train Epoch: 80 [129984/225000 (58%)] Loss: 19660.703125\n",
      "Train Epoch: 80 [132480/225000 (59%)] Loss: 19359.492188\n",
      "Train Epoch: 80 [134976/225000 (60%)] Loss: 19635.460938\n",
      "Train Epoch: 80 [137472/225000 (61%)] Loss: 19316.126953\n",
      "Train Epoch: 80 [139968/225000 (62%)] Loss: 19500.982422\n",
      "Train Epoch: 80 [142464/225000 (63%)] Loss: 19526.140625\n",
      "Train Epoch: 80 [144960/225000 (64%)] Loss: 19884.984375\n",
      "Train Epoch: 80 [147456/225000 (66%)] Loss: 20169.699219\n",
      "Train Epoch: 80 [149952/225000 (67%)] Loss: 19350.474609\n",
      "Train Epoch: 80 [152448/225000 (68%)] Loss: 19690.783203\n",
      "Train Epoch: 80 [154944/225000 (69%)] Loss: 19755.533203\n",
      "Train Epoch: 80 [157440/225000 (70%)] Loss: 19366.171875\n",
      "Train Epoch: 80 [159936/225000 (71%)] Loss: 19605.669922\n",
      "Train Epoch: 80 [162432/225000 (72%)] Loss: 19560.734375\n",
      "Train Epoch: 80 [164928/225000 (73%)] Loss: 19393.695312\n",
      "Train Epoch: 80 [167424/225000 (74%)] Loss: 19251.933594\n",
      "Train Epoch: 80 [169920/225000 (76%)] Loss: 19923.097656\n",
      "Train Epoch: 80 [172416/225000 (77%)] Loss: 19318.824219\n",
      "Train Epoch: 80 [174912/225000 (78%)] Loss: 19737.320312\n",
      "Train Epoch: 80 [177408/225000 (79%)] Loss: 20075.679688\n",
      "Train Epoch: 80 [179904/225000 (80%)] Loss: 19737.058594\n",
      "Train Epoch: 80 [182400/225000 (81%)] Loss: 19503.238281\n",
      "Train Epoch: 80 [184896/225000 (82%)] Loss: 19472.054688\n",
      "Train Epoch: 80 [187392/225000 (83%)] Loss: 19547.265625\n",
      "Train Epoch: 80 [189888/225000 (84%)] Loss: 19466.160156\n",
      "Train Epoch: 80 [192384/225000 (86%)] Loss: 19365.521484\n",
      "Train Epoch: 80 [194880/225000 (87%)] Loss: 19880.472656\n",
      "Train Epoch: 80 [197376/225000 (88%)] Loss: 19693.078125\n",
      "Train Epoch: 80 [199872/225000 (89%)] Loss: 19009.199219\n",
      "Train Epoch: 80 [202368/225000 (90%)] Loss: 19681.824219\n",
      "Train Epoch: 80 [204864/225000 (91%)] Loss: 20201.750000\n",
      "Train Epoch: 80 [207360/225000 (92%)] Loss: 19684.910156\n",
      "Train Epoch: 80 [209856/225000 (93%)] Loss: 19578.818359\n",
      "Train Epoch: 80 [212352/225000 (94%)] Loss: 18955.724609\n",
      "Train Epoch: 80 [214848/225000 (95%)] Loss: 19458.191406\n",
      "Train Epoch: 80 [217344/225000 (97%)] Loss: 19677.611328\n",
      "Train Epoch: 80 [219840/225000 (98%)] Loss: 19388.251953\n",
      "Train Epoch: 80 [222336/225000 (99%)] Loss: 19431.050781\n",
      "Train Epoch: 80 [224832/225000 (100%)] Loss: 19530.414062\n",
      "    epoch          : 80\n",
      "    loss           : 19694.793463697206\n",
      "    val_loss       : 19582.969044435114\n",
      "Train Epoch: 81 [192/225000 (0%)] Loss: 19008.681641\n",
      "Train Epoch: 81 [2688/225000 (1%)] Loss: 19636.736328\n",
      "Train Epoch: 81 [5184/225000 (2%)] Loss: 20006.800781\n",
      "Train Epoch: 81 [7680/225000 (3%)] Loss: 19615.167969\n",
      "Train Epoch: 81 [10176/225000 (5%)] Loss: 19798.429688\n",
      "Train Epoch: 81 [12672/225000 (6%)] Loss: 19390.000000\n",
      "Train Epoch: 81 [15168/225000 (7%)] Loss: 19461.498047\n",
      "Train Epoch: 81 [17664/225000 (8%)] Loss: 19865.230469\n",
      "Train Epoch: 81 [20160/225000 (9%)] Loss: 19895.234375\n",
      "Train Epoch: 81 [22656/225000 (10%)] Loss: 19559.236328\n",
      "Train Epoch: 81 [25152/225000 (11%)] Loss: 19633.396484\n",
      "Train Epoch: 81 [27648/225000 (12%)] Loss: 19637.787109\n",
      "Train Epoch: 81 [30144/225000 (13%)] Loss: 19365.027344\n",
      "Train Epoch: 81 [32640/225000 (15%)] Loss: 19967.248047\n",
      "Train Epoch: 81 [35136/225000 (16%)] Loss: 19823.972656\n",
      "Train Epoch: 81 [37632/225000 (17%)] Loss: 19760.916016\n",
      "Train Epoch: 81 [40128/225000 (18%)] Loss: 19303.322266\n",
      "Train Epoch: 81 [42624/225000 (19%)] Loss: 19225.078125\n",
      "Train Epoch: 81 [45120/225000 (20%)] Loss: 19777.402344\n",
      "Train Epoch: 81 [47616/225000 (21%)] Loss: 19273.281250\n",
      "Train Epoch: 81 [50112/225000 (22%)] Loss: 19893.492188\n",
      "Train Epoch: 81 [52608/225000 (23%)] Loss: 19953.285156\n",
      "Train Epoch: 81 [55104/225000 (24%)] Loss: 19715.017578\n",
      "Train Epoch: 81 [57600/225000 (26%)] Loss: 19399.275391\n",
      "Train Epoch: 81 [60096/225000 (27%)] Loss: 19293.271484\n",
      "Train Epoch: 81 [62592/225000 (28%)] Loss: 19629.664062\n",
      "Train Epoch: 81 [65088/225000 (29%)] Loss: 19546.888672\n",
      "Train Epoch: 81 [67584/225000 (30%)] Loss: 19385.492188\n",
      "Train Epoch: 81 [70080/225000 (31%)] Loss: 19426.589844\n",
      "Train Epoch: 81 [72576/225000 (32%)] Loss: 19818.716797\n",
      "Train Epoch: 81 [75072/225000 (33%)] Loss: 20020.484375\n",
      "Train Epoch: 81 [77568/225000 (34%)] Loss: 19949.820312\n",
      "Train Epoch: 81 [80064/225000 (36%)] Loss: 19351.583984\n",
      "Train Epoch: 81 [82560/225000 (37%)] Loss: 19452.095703\n",
      "Train Epoch: 81 [85056/225000 (38%)] Loss: 19600.339844\n",
      "Train Epoch: 81 [87552/225000 (39%)] Loss: 19754.966797\n",
      "Train Epoch: 81 [90048/225000 (40%)] Loss: 19012.484375\n",
      "Train Epoch: 81 [92544/225000 (41%)] Loss: 19476.703125\n",
      "Train Epoch: 81 [95040/225000 (42%)] Loss: 19810.117188\n",
      "Train Epoch: 81 [97536/225000 (43%)] Loss: 19933.691406\n",
      "Train Epoch: 81 [100032/225000 (44%)] Loss: 19027.230469\n",
      "Train Epoch: 81 [102528/225000 (46%)] Loss: 19612.992188\n",
      "Train Epoch: 81 [105024/225000 (47%)] Loss: 19036.662109\n",
      "Train Epoch: 81 [107520/225000 (48%)] Loss: 19576.802734\n",
      "Train Epoch: 81 [110016/225000 (49%)] Loss: 19874.394531\n",
      "Train Epoch: 81 [112512/225000 (50%)] Loss: 19569.851562\n",
      "Train Epoch: 81 [115008/225000 (51%)] Loss: 19766.724609\n",
      "Train Epoch: 81 [117504/225000 (52%)] Loss: 19934.873047\n",
      "Train Epoch: 81 [120000/225000 (53%)] Loss: 19771.435547\n",
      "Train Epoch: 81 [122496/225000 (54%)] Loss: 19686.207031\n",
      "Train Epoch: 81 [124992/225000 (56%)] Loss: 19261.515625\n",
      "Train Epoch: 81 [127488/225000 (57%)] Loss: 19371.929688\n",
      "Train Epoch: 81 [129984/225000 (58%)] Loss: 19923.158203\n",
      "Train Epoch: 81 [132480/225000 (59%)] Loss: 20373.794922\n",
      "Train Epoch: 81 [134976/225000 (60%)] Loss: 19708.089844\n",
      "Train Epoch: 81 [137472/225000 (61%)] Loss: 20022.115234\n",
      "Train Epoch: 81 [139968/225000 (62%)] Loss: 19842.611328\n",
      "Train Epoch: 81 [142464/225000 (63%)] Loss: 19617.800781\n",
      "Train Epoch: 81 [144960/225000 (64%)] Loss: 19856.535156\n",
      "Train Epoch: 81 [147456/225000 (66%)] Loss: 19526.322266\n",
      "Train Epoch: 81 [149952/225000 (67%)] Loss: 20246.052734\n",
      "Train Epoch: 81 [152448/225000 (68%)] Loss: 19576.837891\n",
      "Train Epoch: 81 [154944/225000 (69%)] Loss: 19621.269531\n",
      "Train Epoch: 81 [157440/225000 (70%)] Loss: 19870.378906\n",
      "Train Epoch: 81 [159936/225000 (71%)] Loss: 19647.769531\n",
      "Train Epoch: 81 [162432/225000 (72%)] Loss: 19508.242188\n",
      "Train Epoch: 81 [164928/225000 (73%)] Loss: 19413.224609\n",
      "Train Epoch: 81 [167424/225000 (74%)] Loss: 19581.632812\n",
      "Train Epoch: 81 [169920/225000 (76%)] Loss: 19640.601562\n",
      "Train Epoch: 81 [172416/225000 (77%)] Loss: 19152.156250\n",
      "Train Epoch: 81 [174912/225000 (78%)] Loss: 19763.472656\n",
      "Train Epoch: 81 [177408/225000 (79%)] Loss: 19609.042969\n",
      "Train Epoch: 81 [179904/225000 (80%)] Loss: 19461.927734\n",
      "Train Epoch: 81 [182400/225000 (81%)] Loss: 19760.902344\n",
      "Train Epoch: 81 [184896/225000 (82%)] Loss: 19463.535156\n",
      "Train Epoch: 81 [187392/225000 (83%)] Loss: 19214.025391\n",
      "Train Epoch: 81 [189888/225000 (84%)] Loss: 19808.039062\n",
      "Train Epoch: 81 [192384/225000 (86%)] Loss: 19646.183594\n",
      "Train Epoch: 81 [194880/225000 (87%)] Loss: 19753.125000\n",
      "Train Epoch: 81 [197376/225000 (88%)] Loss: 20062.890625\n",
      "Train Epoch: 81 [199872/225000 (89%)] Loss: 19788.093750\n",
      "Train Epoch: 81 [202368/225000 (90%)] Loss: 19214.304688\n",
      "Train Epoch: 81 [204864/225000 (91%)] Loss: 19403.546875\n",
      "Train Epoch: 81 [207360/225000 (92%)] Loss: 19697.912109\n",
      "Train Epoch: 81 [209856/225000 (93%)] Loss: 19723.994141\n",
      "Train Epoch: 81 [212352/225000 (94%)] Loss: 19459.609375\n",
      "Train Epoch: 81 [214848/225000 (95%)] Loss: 19845.628906\n",
      "Train Epoch: 81 [217344/225000 (97%)] Loss: 19418.927734\n",
      "Train Epoch: 81 [219840/225000 (98%)] Loss: 19376.933594\n",
      "Train Epoch: 81 [222336/225000 (99%)] Loss: 19744.732422\n",
      "Train Epoch: 81 [224832/225000 (100%)] Loss: 18891.572266\n",
      "    epoch          : 81\n",
      "    loss           : 19665.750079991467\n",
      "    val_loss       : 19560.757710578786\n",
      "Train Epoch: 82 [192/225000 (0%)] Loss: 19599.642578\n",
      "Train Epoch: 82 [2688/225000 (1%)] Loss: 19583.210938\n",
      "Train Epoch: 82 [5184/225000 (2%)] Loss: 20382.980469\n",
      "Train Epoch: 82 [7680/225000 (3%)] Loss: 19610.417969\n",
      "Train Epoch: 82 [10176/225000 (5%)] Loss: 19544.175781\n",
      "Train Epoch: 82 [12672/225000 (6%)] Loss: 19908.875000\n",
      "Train Epoch: 82 [15168/225000 (7%)] Loss: 19599.730469\n",
      "Train Epoch: 82 [17664/225000 (8%)] Loss: 19512.320312\n",
      "Train Epoch: 82 [20160/225000 (9%)] Loss: 19593.621094\n",
      "Train Epoch: 82 [22656/225000 (10%)] Loss: 19447.167969\n",
      "Train Epoch: 82 [25152/225000 (11%)] Loss: 19853.796875\n",
      "Train Epoch: 82 [27648/225000 (12%)] Loss: 20357.146484\n",
      "Train Epoch: 82 [30144/225000 (13%)] Loss: 19466.001953\n",
      "Train Epoch: 82 [32640/225000 (15%)] Loss: 19713.242188\n",
      "Train Epoch: 82 [35136/225000 (16%)] Loss: 19713.414062\n",
      "Train Epoch: 82 [37632/225000 (17%)] Loss: 19563.429688\n",
      "Train Epoch: 82 [40128/225000 (18%)] Loss: 19746.902344\n",
      "Train Epoch: 82 [42624/225000 (19%)] Loss: 19511.933594\n",
      "Train Epoch: 82 [45120/225000 (20%)] Loss: 19726.144531\n",
      "Train Epoch: 82 [47616/225000 (21%)] Loss: 19503.941406\n",
      "Train Epoch: 82 [50112/225000 (22%)] Loss: 19700.332031\n",
      "Train Epoch: 82 [52608/225000 (23%)] Loss: 19292.410156\n",
      "Train Epoch: 82 [55104/225000 (24%)] Loss: 19623.984375\n",
      "Train Epoch: 82 [57600/225000 (26%)] Loss: 19564.880859\n",
      "Train Epoch: 82 [60096/225000 (27%)] Loss: 20003.369141\n",
      "Train Epoch: 82 [62592/225000 (28%)] Loss: 19482.433594\n",
      "Train Epoch: 82 [65088/225000 (29%)] Loss: 19877.207031\n",
      "Train Epoch: 82 [67584/225000 (30%)] Loss: 19695.917969\n",
      "Train Epoch: 82 [70080/225000 (31%)] Loss: 18918.437500\n",
      "Train Epoch: 82 [72576/225000 (32%)] Loss: 19452.648438\n",
      "Train Epoch: 82 [75072/225000 (33%)] Loss: 19461.816406\n",
      "Train Epoch: 82 [77568/225000 (34%)] Loss: 19060.273438\n",
      "Train Epoch: 82 [80064/225000 (36%)] Loss: 19631.156250\n",
      "Train Epoch: 82 [82560/225000 (37%)] Loss: 19643.373047\n",
      "Train Epoch: 82 [85056/225000 (38%)] Loss: 19468.837891\n",
      "Train Epoch: 82 [87552/225000 (39%)] Loss: 19493.476562\n",
      "Train Epoch: 82 [90048/225000 (40%)] Loss: 19564.164062\n",
      "Train Epoch: 82 [92544/225000 (41%)] Loss: 19622.216797\n",
      "Train Epoch: 82 [95040/225000 (42%)] Loss: 19599.863281\n",
      "Train Epoch: 82 [97536/225000 (43%)] Loss: 19522.814453\n",
      "Train Epoch: 82 [100032/225000 (44%)] Loss: 19694.316406\n",
      "Train Epoch: 82 [102528/225000 (46%)] Loss: 19744.683594\n",
      "Train Epoch: 82 [105024/225000 (47%)] Loss: 19700.265625\n",
      "Train Epoch: 82 [107520/225000 (48%)] Loss: 19711.378906\n",
      "Train Epoch: 82 [110016/225000 (49%)] Loss: 19493.527344\n",
      "Train Epoch: 82 [112512/225000 (50%)] Loss: 19302.875000\n",
      "Train Epoch: 82 [115008/225000 (51%)] Loss: 19844.011719\n",
      "Train Epoch: 82 [117504/225000 (52%)] Loss: 19691.316406\n",
      "Train Epoch: 82 [120000/225000 (53%)] Loss: 19412.007812\n",
      "Train Epoch: 82 [122496/225000 (54%)] Loss: 20019.167969\n",
      "Train Epoch: 82 [124992/225000 (56%)] Loss: 19767.968750\n",
      "Train Epoch: 82 [127488/225000 (57%)] Loss: 19622.494141\n",
      "Train Epoch: 82 [129984/225000 (58%)] Loss: 19851.837891\n",
      "Train Epoch: 82 [132480/225000 (59%)] Loss: 19918.396484\n",
      "Train Epoch: 82 [134976/225000 (60%)] Loss: 19409.058594\n",
      "Train Epoch: 82 [137472/225000 (61%)] Loss: 19779.943359\n",
      "Train Epoch: 82 [139968/225000 (62%)] Loss: 19528.742188\n",
      "Train Epoch: 82 [142464/225000 (63%)] Loss: 19731.117188\n",
      "Train Epoch: 82 [144960/225000 (64%)] Loss: 20128.734375\n",
      "Train Epoch: 82 [147456/225000 (66%)] Loss: 19746.226562\n",
      "Train Epoch: 82 [149952/225000 (67%)] Loss: 19816.828125\n",
      "Train Epoch: 82 [152448/225000 (68%)] Loss: 19366.765625\n",
      "Train Epoch: 82 [154944/225000 (69%)] Loss: 19707.160156\n",
      "Train Epoch: 82 [157440/225000 (70%)] Loss: 19768.529297\n",
      "Train Epoch: 82 [159936/225000 (71%)] Loss: 19389.699219\n",
      "Train Epoch: 82 [162432/225000 (72%)] Loss: 19960.302734\n",
      "Train Epoch: 82 [164928/225000 (73%)] Loss: 20113.578125\n",
      "Train Epoch: 82 [167424/225000 (74%)] Loss: 19894.361328\n",
      "Train Epoch: 82 [169920/225000 (76%)] Loss: 19634.902344\n",
      "Train Epoch: 82 [172416/225000 (77%)] Loss: 19737.066406\n",
      "Train Epoch: 82 [174912/225000 (78%)] Loss: 19537.031250\n",
      "Train Epoch: 82 [177408/225000 (79%)] Loss: 19528.300781\n",
      "Train Epoch: 82 [179904/225000 (80%)] Loss: 19304.513672\n",
      "Train Epoch: 82 [182400/225000 (81%)] Loss: 20015.373047\n",
      "Train Epoch: 82 [184896/225000 (82%)] Loss: 19363.230469\n",
      "Train Epoch: 82 [187392/225000 (83%)] Loss: 19253.562500\n",
      "Train Epoch: 82 [189888/225000 (84%)] Loss: 19506.023438\n",
      "Train Epoch: 82 [192384/225000 (86%)] Loss: 19602.656250\n",
      "Train Epoch: 82 [194880/225000 (87%)] Loss: 19950.750000\n",
      "Train Epoch: 82 [197376/225000 (88%)] Loss: 20262.687500\n",
      "Train Epoch: 82 [199872/225000 (89%)] Loss: 19398.746094\n",
      "Train Epoch: 82 [202368/225000 (90%)] Loss: 19238.033203\n",
      "Train Epoch: 82 [204864/225000 (91%)] Loss: 19777.343750\n",
      "Train Epoch: 82 [207360/225000 (92%)] Loss: 19522.566406\n",
      "Train Epoch: 82 [209856/225000 (93%)] Loss: 19556.257812\n",
      "Train Epoch: 82 [212352/225000 (94%)] Loss: 19624.230469\n",
      "Train Epoch: 82 [214848/225000 (95%)] Loss: 19691.097656\n",
      "Train Epoch: 82 [217344/225000 (97%)] Loss: 19662.644531\n",
      "Train Epoch: 82 [219840/225000 (98%)] Loss: 19536.468750\n",
      "Train Epoch: 82 [222336/225000 (99%)] Loss: 19565.082031\n",
      "Train Epoch: 82 [224832/225000 (100%)] Loss: 19923.839844\n",
      "    epoch          : 82\n",
      "    loss           : 19667.338828858254\n",
      "    val_loss       : 19670.10195211964\n",
      "Train Epoch: 83 [192/225000 (0%)] Loss: 19877.867188\n",
      "Train Epoch: 83 [2688/225000 (1%)] Loss: 19413.466797\n",
      "Train Epoch: 83 [5184/225000 (2%)] Loss: 20110.826172\n",
      "Train Epoch: 83 [7680/225000 (3%)] Loss: 19464.820312\n",
      "Train Epoch: 83 [10176/225000 (5%)] Loss: 19507.339844\n",
      "Train Epoch: 83 [12672/225000 (6%)] Loss: 19602.019531\n",
      "Train Epoch: 83 [15168/225000 (7%)] Loss: 19496.988281\n",
      "Train Epoch: 83 [17664/225000 (8%)] Loss: 19881.722656\n",
      "Train Epoch: 83 [20160/225000 (9%)] Loss: 19799.140625\n",
      "Train Epoch: 83 [22656/225000 (10%)] Loss: 19758.121094\n",
      "Train Epoch: 83 [25152/225000 (11%)] Loss: 19666.992188\n",
      "Train Epoch: 83 [27648/225000 (12%)] Loss: 20272.804688\n",
      "Train Epoch: 83 [30144/225000 (13%)] Loss: 19746.757812\n",
      "Train Epoch: 83 [32640/225000 (15%)] Loss: 20064.765625\n",
      "Train Epoch: 83 [35136/225000 (16%)] Loss: 19849.425781\n",
      "Train Epoch: 83 [37632/225000 (17%)] Loss: 19428.718750\n",
      "Train Epoch: 83 [40128/225000 (18%)] Loss: 19719.988281\n",
      "Train Epoch: 83 [42624/225000 (19%)] Loss: 19110.800781\n",
      "Train Epoch: 83 [45120/225000 (20%)] Loss: 19511.378906\n",
      "Train Epoch: 83 [47616/225000 (21%)] Loss: 19616.425781\n",
      "Train Epoch: 83 [50112/225000 (22%)] Loss: 19430.855469\n",
      "Train Epoch: 83 [52608/225000 (23%)] Loss: 19578.351562\n",
      "Train Epoch: 83 [55104/225000 (24%)] Loss: 19196.582031\n",
      "Train Epoch: 83 [57600/225000 (26%)] Loss: 20051.343750\n",
      "Train Epoch: 83 [60096/225000 (27%)] Loss: 19294.851562\n",
      "Train Epoch: 83 [62592/225000 (28%)] Loss: 20070.960938\n",
      "Train Epoch: 83 [65088/225000 (29%)] Loss: 19969.011719\n",
      "Train Epoch: 83 [67584/225000 (30%)] Loss: 20189.462891\n",
      "Train Epoch: 83 [70080/225000 (31%)] Loss: 19621.378906\n",
      "Train Epoch: 83 [72576/225000 (32%)] Loss: 19658.011719\n",
      "Train Epoch: 83 [75072/225000 (33%)] Loss: 20002.683594\n",
      "Train Epoch: 83 [77568/225000 (34%)] Loss: 19101.933594\n",
      "Train Epoch: 83 [80064/225000 (36%)] Loss: 19572.503906\n",
      "Train Epoch: 83 [82560/225000 (37%)] Loss: 20013.308594\n",
      "Train Epoch: 83 [85056/225000 (38%)] Loss: 19462.585938\n",
      "Train Epoch: 83 [87552/225000 (39%)] Loss: 19821.085938\n",
      "Train Epoch: 83 [90048/225000 (40%)] Loss: 18822.939453\n",
      "Train Epoch: 83 [92544/225000 (41%)] Loss: 19823.332031\n",
      "Train Epoch: 83 [95040/225000 (42%)] Loss: 19549.626953\n",
      "Train Epoch: 83 [97536/225000 (43%)] Loss: 19469.757812\n",
      "Train Epoch: 83 [100032/225000 (44%)] Loss: 19844.265625\n",
      "Train Epoch: 83 [102528/225000 (46%)] Loss: 19549.722656\n",
      "Train Epoch: 83 [105024/225000 (47%)] Loss: 19485.808594\n",
      "Train Epoch: 83 [107520/225000 (48%)] Loss: 19598.218750\n",
      "Train Epoch: 83 [110016/225000 (49%)] Loss: 19439.816406\n",
      "Train Epoch: 83 [112512/225000 (50%)] Loss: 19156.453125\n",
      "Train Epoch: 83 [115008/225000 (51%)] Loss: 19588.601562\n",
      "Train Epoch: 83 [117504/225000 (52%)] Loss: 19787.791016\n",
      "Train Epoch: 83 [120000/225000 (53%)] Loss: 19765.683594\n",
      "Train Epoch: 83 [122496/225000 (54%)] Loss: 19572.925781\n",
      "Train Epoch: 83 [124992/225000 (56%)] Loss: 19659.664062\n",
      "Train Epoch: 83 [127488/225000 (57%)] Loss: 18866.166016\n",
      "Train Epoch: 83 [129984/225000 (58%)] Loss: 19730.402344\n",
      "Train Epoch: 83 [132480/225000 (59%)] Loss: 19853.960938\n",
      "Train Epoch: 83 [134976/225000 (60%)] Loss: 19836.007812\n",
      "Train Epoch: 83 [137472/225000 (61%)] Loss: 19232.238281\n",
      "Train Epoch: 83 [139968/225000 (62%)] Loss: 20035.253906\n",
      "Train Epoch: 83 [142464/225000 (63%)] Loss: 19442.783203\n",
      "Train Epoch: 83 [144960/225000 (64%)] Loss: 19794.355469\n",
      "Train Epoch: 83 [147456/225000 (66%)] Loss: 19870.003906\n",
      "Train Epoch: 83 [149952/225000 (67%)] Loss: 19289.457031\n",
      "Train Epoch: 83 [152448/225000 (68%)] Loss: 19565.230469\n",
      "Train Epoch: 83 [154944/225000 (69%)] Loss: 19741.500000\n",
      "Train Epoch: 83 [157440/225000 (70%)] Loss: 19392.347656\n",
      "Train Epoch: 83 [159936/225000 (71%)] Loss: 19829.410156\n",
      "Train Epoch: 83 [162432/225000 (72%)] Loss: 19862.718750\n",
      "Train Epoch: 83 [164928/225000 (73%)] Loss: 19900.675781\n",
      "Train Epoch: 83 [167424/225000 (74%)] Loss: 19500.425781\n",
      "Train Epoch: 83 [169920/225000 (76%)] Loss: 19497.523438\n",
      "Train Epoch: 83 [172416/225000 (77%)] Loss: 19375.835938\n",
      "Train Epoch: 83 [174912/225000 (78%)] Loss: 19908.359375\n",
      "Train Epoch: 83 [177408/225000 (79%)] Loss: 19798.255859\n",
      "Train Epoch: 83 [179904/225000 (80%)] Loss: 19669.339844\n",
      "Train Epoch: 83 [182400/225000 (81%)] Loss: 19916.441406\n",
      "Train Epoch: 83 [184896/225000 (82%)] Loss: 19619.578125\n",
      "Train Epoch: 83 [187392/225000 (83%)] Loss: 19501.417969\n",
      "Train Epoch: 83 [189888/225000 (84%)] Loss: 19856.824219\n",
      "Train Epoch: 83 [192384/225000 (86%)] Loss: 19563.902344\n",
      "Train Epoch: 83 [194880/225000 (87%)] Loss: 19781.167969\n",
      "Train Epoch: 83 [197376/225000 (88%)] Loss: 19910.535156\n",
      "Train Epoch: 83 [199872/225000 (89%)] Loss: 19244.652344\n",
      "Train Epoch: 83 [202368/225000 (90%)] Loss: 19311.101562\n",
      "Train Epoch: 83 [204864/225000 (91%)] Loss: 19541.843750\n",
      "Train Epoch: 83 [207360/225000 (92%)] Loss: 19314.162109\n",
      "Train Epoch: 83 [209856/225000 (93%)] Loss: 19837.847656\n",
      "Train Epoch: 83 [212352/225000 (94%)] Loss: 19722.250000\n",
      "Train Epoch: 83 [214848/225000 (95%)] Loss: 19443.169922\n",
      "Train Epoch: 83 [217344/225000 (97%)] Loss: 19983.425781\n",
      "Train Epoch: 83 [219840/225000 (98%)] Loss: 20238.478516\n",
      "Train Epoch: 83 [222336/225000 (99%)] Loss: 19442.367188\n",
      "Train Epoch: 83 [224832/225000 (100%)] Loss: 19616.839844\n",
      "    epoch          : 83\n",
      "    loss           : 19651.666927194434\n",
      "    val_loss       : 19544.809414092822\n",
      "Train Epoch: 84 [192/225000 (0%)] Loss: 19403.521484\n",
      "Train Epoch: 84 [2688/225000 (1%)] Loss: 19607.675781\n",
      "Train Epoch: 84 [5184/225000 (2%)] Loss: 19288.324219\n",
      "Train Epoch: 84 [7680/225000 (3%)] Loss: 19480.212891\n",
      "Train Epoch: 84 [10176/225000 (5%)] Loss: 19695.523438\n",
      "Train Epoch: 84 [12672/225000 (6%)] Loss: 19137.585938\n",
      "Train Epoch: 84 [15168/225000 (7%)] Loss: 19583.332031\n",
      "Train Epoch: 84 [17664/225000 (8%)] Loss: 19720.062500\n",
      "Train Epoch: 84 [20160/225000 (9%)] Loss: 19741.777344\n",
      "Train Epoch: 84 [22656/225000 (10%)] Loss: 19253.781250\n",
      "Train Epoch: 84 [25152/225000 (11%)] Loss: 19467.626953\n",
      "Train Epoch: 84 [27648/225000 (12%)] Loss: 19941.406250\n",
      "Train Epoch: 84 [30144/225000 (13%)] Loss: 19586.789062\n",
      "Train Epoch: 84 [32640/225000 (15%)] Loss: 20153.148438\n",
      "Train Epoch: 84 [35136/225000 (16%)] Loss: 19750.134766\n",
      "Train Epoch: 84 [37632/225000 (17%)] Loss: 19185.312500\n",
      "Train Epoch: 84 [40128/225000 (18%)] Loss: 19824.832031\n",
      "Train Epoch: 84 [42624/225000 (19%)] Loss: 20025.000000\n",
      "Train Epoch: 84 [45120/225000 (20%)] Loss: 19524.966797\n",
      "Train Epoch: 84 [47616/225000 (21%)] Loss: 19453.769531\n",
      "Train Epoch: 84 [50112/225000 (22%)] Loss: 19965.277344\n",
      "Train Epoch: 84 [52608/225000 (23%)] Loss: 19383.173828\n",
      "Train Epoch: 84 [55104/225000 (24%)] Loss: 19725.488281\n",
      "Train Epoch: 84 [57600/225000 (26%)] Loss: 19417.626953\n",
      "Train Epoch: 84 [60096/225000 (27%)] Loss: 19772.585938\n",
      "Train Epoch: 84 [62592/225000 (28%)] Loss: 20176.859375\n",
      "Train Epoch: 84 [65088/225000 (29%)] Loss: 19748.111328\n",
      "Train Epoch: 84 [67584/225000 (30%)] Loss: 20080.578125\n",
      "Train Epoch: 84 [70080/225000 (31%)] Loss: 19032.726562\n",
      "Train Epoch: 84 [72576/225000 (32%)] Loss: 19545.621094\n",
      "Train Epoch: 84 [75072/225000 (33%)] Loss: 19911.687500\n",
      "Train Epoch: 84 [77568/225000 (34%)] Loss: 19733.033203\n",
      "Train Epoch: 84 [80064/225000 (36%)] Loss: 18958.839844\n",
      "Train Epoch: 84 [82560/225000 (37%)] Loss: 19748.921875\n",
      "Train Epoch: 84 [85056/225000 (38%)] Loss: 19667.429688\n",
      "Train Epoch: 84 [87552/225000 (39%)] Loss: 19772.277344\n",
      "Train Epoch: 84 [90048/225000 (40%)] Loss: 20327.683594\n",
      "Train Epoch: 84 [92544/225000 (41%)] Loss: 19807.406250\n",
      "Train Epoch: 84 [95040/225000 (42%)] Loss: 19810.828125\n",
      "Train Epoch: 84 [97536/225000 (43%)] Loss: 19053.001953\n",
      "Train Epoch: 84 [100032/225000 (44%)] Loss: 19811.830078\n",
      "Train Epoch: 84 [102528/225000 (46%)] Loss: 19553.242188\n",
      "Train Epoch: 84 [105024/225000 (47%)] Loss: 19751.636719\n",
      "Train Epoch: 84 [107520/225000 (48%)] Loss: 19297.259766\n",
      "Train Epoch: 84 [110016/225000 (49%)] Loss: 19978.193359\n",
      "Train Epoch: 84 [112512/225000 (50%)] Loss: 19512.208984\n",
      "Train Epoch: 84 [115008/225000 (51%)] Loss: 19529.039062\n",
      "Train Epoch: 84 [117504/225000 (52%)] Loss: 19859.396484\n",
      "Train Epoch: 84 [120000/225000 (53%)] Loss: 19725.449219\n",
      "Train Epoch: 84 [122496/225000 (54%)] Loss: 19388.308594\n",
      "Train Epoch: 84 [124992/225000 (56%)] Loss: 19626.867188\n",
      "Train Epoch: 84 [127488/225000 (57%)] Loss: 19407.191406\n",
      "Train Epoch: 84 [129984/225000 (58%)] Loss: 19643.642578\n",
      "Train Epoch: 84 [132480/225000 (59%)] Loss: 19520.921875\n",
      "Train Epoch: 84 [134976/225000 (60%)] Loss: 19734.621094\n",
      "Train Epoch: 84 [137472/225000 (61%)] Loss: 19408.140625\n",
      "Train Epoch: 84 [139968/225000 (62%)] Loss: 19172.861328\n",
      "Train Epoch: 84 [142464/225000 (63%)] Loss: 19559.162109\n",
      "Train Epoch: 84 [144960/225000 (64%)] Loss: 19720.445312\n",
      "Train Epoch: 84 [147456/225000 (66%)] Loss: 19901.494141\n",
      "Train Epoch: 84 [149952/225000 (67%)] Loss: 19059.921875\n",
      "Train Epoch: 84 [152448/225000 (68%)] Loss: 19344.953125\n",
      "Train Epoch: 84 [154944/225000 (69%)] Loss: 19946.445312\n",
      "Train Epoch: 84 [157440/225000 (70%)] Loss: 19390.992188\n",
      "Train Epoch: 84 [159936/225000 (71%)] Loss: 19499.531250\n",
      "Train Epoch: 84 [162432/225000 (72%)] Loss: 19794.996094\n",
      "Train Epoch: 84 [164928/225000 (73%)] Loss: 19511.062500\n",
      "Train Epoch: 84 [167424/225000 (74%)] Loss: 20087.785156\n",
      "Train Epoch: 84 [169920/225000 (76%)] Loss: 19522.041016\n",
      "Train Epoch: 84 [172416/225000 (77%)] Loss: 19783.628906\n",
      "Train Epoch: 84 [174912/225000 (78%)] Loss: 20135.248047\n",
      "Train Epoch: 84 [177408/225000 (79%)] Loss: 19066.666016\n",
      "Train Epoch: 84 [179904/225000 (80%)] Loss: 20111.343750\n",
      "Train Epoch: 84 [182400/225000 (81%)] Loss: 19761.574219\n",
      "Train Epoch: 84 [184896/225000 (82%)] Loss: 19741.722656\n",
      "Train Epoch: 84 [187392/225000 (83%)] Loss: 19376.648438\n",
      "Train Epoch: 84 [189888/225000 (84%)] Loss: 19199.132812\n",
      "Train Epoch: 84 [192384/225000 (86%)] Loss: 19164.876953\n",
      "Train Epoch: 84 [194880/225000 (87%)] Loss: 19233.216797\n",
      "Train Epoch: 84 [197376/225000 (88%)] Loss: 19527.156250\n",
      "Train Epoch: 84 [199872/225000 (89%)] Loss: 19493.521484\n",
      "Train Epoch: 84 [202368/225000 (90%)] Loss: 19634.580078\n",
      "Train Epoch: 84 [204864/225000 (91%)] Loss: 19452.441406\n",
      "Train Epoch: 84 [207360/225000 (92%)] Loss: 19697.056641\n",
      "Train Epoch: 84 [209856/225000 (93%)] Loss: 20035.224609\n",
      "Train Epoch: 84 [212352/225000 (94%)] Loss: 19633.296875\n",
      "Train Epoch: 84 [214848/225000 (95%)] Loss: 20094.707031\n",
      "Train Epoch: 84 [217344/225000 (97%)] Loss: 19834.957031\n",
      "Train Epoch: 84 [219840/225000 (98%)] Loss: 19692.039062\n",
      "Train Epoch: 84 [222336/225000 (99%)] Loss: 19880.925781\n",
      "Train Epoch: 84 [224832/225000 (100%)] Loss: 19822.324219\n",
      "    epoch          : 84\n",
      "    loss           : 19632.04470856442\n",
      "    val_loss       : 19540.946734406567\n",
      "Train Epoch: 85 [192/225000 (0%)] Loss: 19386.960938\n",
      "Train Epoch: 85 [2688/225000 (1%)] Loss: 19677.806641\n",
      "Train Epoch: 85 [5184/225000 (2%)] Loss: 19372.152344\n",
      "Train Epoch: 85 [7680/225000 (3%)] Loss: 19194.117188\n",
      "Train Epoch: 85 [10176/225000 (5%)] Loss: 19407.841797\n",
      "Train Epoch: 85 [12672/225000 (6%)] Loss: 19277.369141\n",
      "Train Epoch: 85 [15168/225000 (7%)] Loss: 19778.486328\n",
      "Train Epoch: 85 [17664/225000 (8%)] Loss: 19770.806641\n",
      "Train Epoch: 85 [20160/225000 (9%)] Loss: 19376.044922\n",
      "Train Epoch: 85 [22656/225000 (10%)] Loss: 19487.269531\n",
      "Train Epoch: 85 [25152/225000 (11%)] Loss: 19446.115234\n",
      "Train Epoch: 85 [27648/225000 (12%)] Loss: 19949.703125\n",
      "Train Epoch: 85 [30144/225000 (13%)] Loss: 19451.796875\n",
      "Train Epoch: 85 [32640/225000 (15%)] Loss: 19499.681641\n",
      "Train Epoch: 85 [35136/225000 (16%)] Loss: 19219.015625\n",
      "Train Epoch: 85 [37632/225000 (17%)] Loss: 19767.378906\n",
      "Train Epoch: 85 [40128/225000 (18%)] Loss: 19410.470703\n",
      "Train Epoch: 85 [42624/225000 (19%)] Loss: 19840.121094\n",
      "Train Epoch: 85 [45120/225000 (20%)] Loss: 19551.164062\n",
      "Train Epoch: 85 [47616/225000 (21%)] Loss: 19444.242188\n",
      "Train Epoch: 85 [50112/225000 (22%)] Loss: 19051.320312\n",
      "Train Epoch: 85 [52608/225000 (23%)] Loss: 19611.207031\n",
      "Train Epoch: 85 [55104/225000 (24%)] Loss: 19581.177734\n",
      "Train Epoch: 85 [57600/225000 (26%)] Loss: 19408.957031\n",
      "Train Epoch: 85 [60096/225000 (27%)] Loss: 19711.742188\n",
      "Train Epoch: 85 [62592/225000 (28%)] Loss: 19259.007812\n",
      "Train Epoch: 85 [65088/225000 (29%)] Loss: 20009.921875\n",
      "Train Epoch: 85 [67584/225000 (30%)] Loss: 19672.476562\n",
      "Train Epoch: 85 [70080/225000 (31%)] Loss: 20251.386719\n",
      "Train Epoch: 85 [72576/225000 (32%)] Loss: 20188.781250\n",
      "Train Epoch: 85 [75072/225000 (33%)] Loss: 19373.882812\n",
      "Train Epoch: 85 [77568/225000 (34%)] Loss: 19913.308594\n",
      "Train Epoch: 85 [80064/225000 (36%)] Loss: 19463.587891\n",
      "Train Epoch: 85 [82560/225000 (37%)] Loss: 20140.992188\n",
      "Train Epoch: 85 [85056/225000 (38%)] Loss: 19803.117188\n",
      "Train Epoch: 85 [87552/225000 (39%)] Loss: 19478.503906\n",
      "Train Epoch: 85 [90048/225000 (40%)] Loss: 19641.080078\n",
      "Train Epoch: 85 [92544/225000 (41%)] Loss: 19288.382812\n",
      "Train Epoch: 85 [95040/225000 (42%)] Loss: 19384.222656\n",
      "Train Epoch: 85 [97536/225000 (43%)] Loss: 19736.582031\n",
      "Train Epoch: 85 [100032/225000 (44%)] Loss: 19473.960938\n",
      "Train Epoch: 85 [102528/225000 (46%)] Loss: 20356.554688\n",
      "Train Epoch: 85 [105024/225000 (47%)] Loss: 19370.205078\n",
      "Train Epoch: 85 [107520/225000 (48%)] Loss: 19760.843750\n",
      "Train Epoch: 85 [110016/225000 (49%)] Loss: 19715.968750\n",
      "Train Epoch: 85 [112512/225000 (50%)] Loss: 20125.478516\n",
      "Train Epoch: 85 [115008/225000 (51%)] Loss: 19569.074219\n",
      "Train Epoch: 85 [117504/225000 (52%)] Loss: 19655.976562\n",
      "Train Epoch: 85 [120000/225000 (53%)] Loss: 19726.343750\n",
      "Train Epoch: 85 [122496/225000 (54%)] Loss: 19430.101562\n",
      "Train Epoch: 85 [124992/225000 (56%)] Loss: 20027.994141\n",
      "Train Epoch: 85 [127488/225000 (57%)] Loss: 20055.949219\n",
      "Train Epoch: 85 [129984/225000 (58%)] Loss: 18770.289062\n",
      "Train Epoch: 85 [132480/225000 (59%)] Loss: 19574.222656\n",
      "Train Epoch: 85 [134976/225000 (60%)] Loss: 20019.076172\n",
      "Train Epoch: 85 [137472/225000 (61%)] Loss: 19485.562500\n",
      "Train Epoch: 85 [139968/225000 (62%)] Loss: 19604.199219\n",
      "Train Epoch: 85 [142464/225000 (63%)] Loss: 19345.050781\n",
      "Train Epoch: 85 [144960/225000 (64%)] Loss: 19514.472656\n",
      "Train Epoch: 85 [147456/225000 (66%)] Loss: 19961.171875\n",
      "Train Epoch: 85 [149952/225000 (67%)] Loss: 19345.105469\n",
      "Train Epoch: 85 [152448/225000 (68%)] Loss: 20279.789062\n",
      "Train Epoch: 85 [154944/225000 (69%)] Loss: 19618.312500\n",
      "Train Epoch: 85 [157440/225000 (70%)] Loss: 19919.496094\n",
      "Train Epoch: 85 [159936/225000 (71%)] Loss: 19522.257812\n",
      "Train Epoch: 85 [162432/225000 (72%)] Loss: 19703.472656\n",
      "Train Epoch: 85 [164928/225000 (73%)] Loss: 19863.425781\n",
      "Train Epoch: 85 [167424/225000 (74%)] Loss: 19978.607422\n",
      "Train Epoch: 85 [169920/225000 (76%)] Loss: 19818.144531\n",
      "Train Epoch: 85 [172416/225000 (77%)] Loss: 19662.378906\n",
      "Train Epoch: 85 [174912/225000 (78%)] Loss: 20414.636719\n",
      "Train Epoch: 85 [177408/225000 (79%)] Loss: 19663.777344\n",
      "Train Epoch: 85 [179904/225000 (80%)] Loss: 19469.664062\n",
      "Train Epoch: 85 [182400/225000 (81%)] Loss: 19987.097656\n",
      "Train Epoch: 85 [184896/225000 (82%)] Loss: 19179.917969\n",
      "Train Epoch: 85 [187392/225000 (83%)] Loss: 19547.144531\n",
      "Train Epoch: 85 [189888/225000 (84%)] Loss: 19347.312500\n",
      "Train Epoch: 85 [192384/225000 (86%)] Loss: 19664.148438\n",
      "Train Epoch: 85 [194880/225000 (87%)] Loss: 19706.408203\n",
      "Train Epoch: 85 [197376/225000 (88%)] Loss: 19341.683594\n",
      "Train Epoch: 85 [199872/225000 (89%)] Loss: 19601.998047\n",
      "Train Epoch: 85 [202368/225000 (90%)] Loss: 19700.964844\n",
      "Train Epoch: 85 [204864/225000 (91%)] Loss: 19504.144531\n",
      "Train Epoch: 85 [207360/225000 (92%)] Loss: 19302.402344\n",
      "Train Epoch: 85 [209856/225000 (93%)] Loss: 19625.781250\n",
      "Train Epoch: 85 [212352/225000 (94%)] Loss: 19866.132812\n",
      "Train Epoch: 85 [214848/225000 (95%)] Loss: 19530.546875\n",
      "Train Epoch: 85 [217344/225000 (97%)] Loss: 19748.095703\n",
      "Train Epoch: 85 [219840/225000 (98%)] Loss: 20104.160156\n",
      "Train Epoch: 85 [222336/225000 (99%)] Loss: 19739.083984\n",
      "Train Epoch: 85 [224832/225000 (100%)] Loss: 19193.517578\n",
      "    epoch          : 85\n",
      "    loss           : 19633.17527463737\n",
      "    val_loss       : 19528.255709533474\n",
      "Train Epoch: 86 [192/225000 (0%)] Loss: 19638.470703\n",
      "Train Epoch: 86 [2688/225000 (1%)] Loss: 19876.089844\n",
      "Train Epoch: 86 [5184/225000 (2%)] Loss: 19271.429688\n",
      "Train Epoch: 86 [7680/225000 (3%)] Loss: 19130.945312\n",
      "Train Epoch: 86 [10176/225000 (5%)] Loss: 19652.921875\n",
      "Train Epoch: 86 [12672/225000 (6%)] Loss: 19534.175781\n",
      "Train Epoch: 86 [15168/225000 (7%)] Loss: 20212.453125\n",
      "Train Epoch: 86 [17664/225000 (8%)] Loss: 19431.242188\n",
      "Train Epoch: 86 [20160/225000 (9%)] Loss: 19339.898438\n",
      "Train Epoch: 86 [22656/225000 (10%)] Loss: 19810.503906\n",
      "Train Epoch: 86 [25152/225000 (11%)] Loss: 19198.835938\n",
      "Train Epoch: 86 [27648/225000 (12%)] Loss: 19708.945312\n",
      "Train Epoch: 86 [30144/225000 (13%)] Loss: 19172.693359\n",
      "Train Epoch: 86 [32640/225000 (15%)] Loss: 19373.316406\n",
      "Train Epoch: 86 [35136/225000 (16%)] Loss: 19644.914062\n",
      "Train Epoch: 86 [37632/225000 (17%)] Loss: 19082.601562\n",
      "Train Epoch: 86 [40128/225000 (18%)] Loss: 20085.726562\n",
      "Train Epoch: 86 [42624/225000 (19%)] Loss: 19558.046875\n",
      "Train Epoch: 86 [45120/225000 (20%)] Loss: 19952.867188\n",
      "Train Epoch: 86 [47616/225000 (21%)] Loss: 19941.746094\n",
      "Train Epoch: 86 [50112/225000 (22%)] Loss: 19962.712891\n",
      "Train Epoch: 86 [52608/225000 (23%)] Loss: 19231.531250\n",
      "Train Epoch: 86 [55104/225000 (24%)] Loss: 19607.515625\n",
      "Train Epoch: 86 [57600/225000 (26%)] Loss: 19794.484375\n",
      "Train Epoch: 86 [60096/225000 (27%)] Loss: 19427.179688\n",
      "Train Epoch: 86 [62592/225000 (28%)] Loss: 19773.421875\n",
      "Train Epoch: 86 [65088/225000 (29%)] Loss: 19706.546875\n",
      "Train Epoch: 86 [67584/225000 (30%)] Loss: 19350.613281\n",
      "Train Epoch: 86 [70080/225000 (31%)] Loss: 19473.367188\n",
      "Train Epoch: 86 [72576/225000 (32%)] Loss: 20079.046875\n",
      "Train Epoch: 86 [75072/225000 (33%)] Loss: 19337.851562\n",
      "Train Epoch: 86 [77568/225000 (34%)] Loss: 19620.863281\n",
      "Train Epoch: 86 [80064/225000 (36%)] Loss: 19133.308594\n",
      "Train Epoch: 86 [82560/225000 (37%)] Loss: 19590.000000\n",
      "Train Epoch: 86 [85056/225000 (38%)] Loss: 19718.664062\n",
      "Train Epoch: 86 [87552/225000 (39%)] Loss: 19151.824219\n",
      "Train Epoch: 86 [90048/225000 (40%)] Loss: 19680.203125\n",
      "Train Epoch: 86 [92544/225000 (41%)] Loss: 19630.226562\n",
      "Train Epoch: 86 [95040/225000 (42%)] Loss: 19330.226562\n",
      "Train Epoch: 86 [97536/225000 (43%)] Loss: 19537.562500\n",
      "Train Epoch: 86 [100032/225000 (44%)] Loss: 19643.960938\n",
      "Train Epoch: 86 [102528/225000 (46%)] Loss: 19480.380859\n",
      "Train Epoch: 86 [105024/225000 (47%)] Loss: 19672.339844\n",
      "Train Epoch: 86 [107520/225000 (48%)] Loss: 19356.984375\n",
      "Train Epoch: 86 [110016/225000 (49%)] Loss: 19411.011719\n",
      "Train Epoch: 86 [112512/225000 (50%)] Loss: 19540.708984\n",
      "Train Epoch: 86 [115008/225000 (51%)] Loss: 19452.166016\n",
      "Train Epoch: 86 [117504/225000 (52%)] Loss: 19870.291016\n",
      "Train Epoch: 86 [120000/225000 (53%)] Loss: 19675.351562\n",
      "Train Epoch: 86 [122496/225000 (54%)] Loss: 19433.384766\n",
      "Train Epoch: 86 [124992/225000 (56%)] Loss: 19346.238281\n",
      "Train Epoch: 86 [127488/225000 (57%)] Loss: 19677.962891\n",
      "Train Epoch: 86 [129984/225000 (58%)] Loss: 19292.878906\n",
      "Train Epoch: 86 [132480/225000 (59%)] Loss: 19602.062500\n",
      "Train Epoch: 86 [134976/225000 (60%)] Loss: 19801.886719\n",
      "Train Epoch: 86 [137472/225000 (61%)] Loss: 20015.570312\n",
      "Train Epoch: 86 [139968/225000 (62%)] Loss: 19573.074219\n",
      "Train Epoch: 86 [142464/225000 (63%)] Loss: 19691.937500\n",
      "Train Epoch: 86 [144960/225000 (64%)] Loss: 19761.816406\n",
      "Train Epoch: 86 [147456/225000 (66%)] Loss: 19287.742188\n",
      "Train Epoch: 86 [149952/225000 (67%)] Loss: 19929.033203\n",
      "Train Epoch: 86 [152448/225000 (68%)] Loss: 19291.347656\n",
      "Train Epoch: 86 [154944/225000 (69%)] Loss: 20195.683594\n",
      "Train Epoch: 86 [157440/225000 (70%)] Loss: 19525.660156\n",
      "Train Epoch: 86 [159936/225000 (71%)] Loss: 19481.921875\n",
      "Train Epoch: 86 [162432/225000 (72%)] Loss: 19456.460938\n",
      "Train Epoch: 86 [164928/225000 (73%)] Loss: 19295.373047\n",
      "Train Epoch: 86 [167424/225000 (74%)] Loss: 19600.722656\n",
      "Train Epoch: 86 [169920/225000 (76%)] Loss: 19548.792969\n",
      "Train Epoch: 86 [172416/225000 (77%)] Loss: 20104.558594\n",
      "Train Epoch: 86 [174912/225000 (78%)] Loss: 19759.363281\n",
      "Train Epoch: 86 [177408/225000 (79%)] Loss: 19765.265625\n",
      "Train Epoch: 86 [179904/225000 (80%)] Loss: 19977.285156\n",
      "Train Epoch: 86 [182400/225000 (81%)] Loss: 19605.617188\n",
      "Train Epoch: 86 [184896/225000 (82%)] Loss: 19187.316406\n",
      "Train Epoch: 86 [187392/225000 (83%)] Loss: 19990.746094\n",
      "Train Epoch: 86 [189888/225000 (84%)] Loss: 19838.873047\n",
      "Train Epoch: 86 [192384/225000 (86%)] Loss: 20057.015625\n",
      "Train Epoch: 86 [194880/225000 (87%)] Loss: 19703.378906\n",
      "Train Epoch: 86 [197376/225000 (88%)] Loss: 19674.312500\n",
      "Train Epoch: 86 [199872/225000 (89%)] Loss: 19316.222656\n",
      "Train Epoch: 86 [202368/225000 (90%)] Loss: 19629.173828\n",
      "Train Epoch: 86 [204864/225000 (91%)] Loss: 19643.511719\n",
      "Train Epoch: 86 [207360/225000 (92%)] Loss: 19819.947266\n",
      "Train Epoch: 86 [209856/225000 (93%)] Loss: 19534.220703\n",
      "Train Epoch: 86 [212352/225000 (94%)] Loss: 19303.609375\n",
      "Train Epoch: 86 [214848/225000 (95%)] Loss: 19508.128906\n",
      "Train Epoch: 86 [217344/225000 (97%)] Loss: 19459.554688\n",
      "Train Epoch: 86 [219840/225000 (98%)] Loss: 19826.871094\n",
      "Train Epoch: 86 [222336/225000 (99%)] Loss: 19293.902344\n",
      "Train Epoch: 86 [224832/225000 (100%)] Loss: 19571.539062\n",
      "    epoch          : 86\n",
      "    loss           : 19613.920755119452\n",
      "    val_loss       : 19517.996763928248\n",
      "Train Epoch: 87 [192/225000 (0%)] Loss: 19408.089844\n",
      "Train Epoch: 87 [2688/225000 (1%)] Loss: 19889.451172\n",
      "Train Epoch: 87 [5184/225000 (2%)] Loss: 19496.527344\n",
      "Train Epoch: 87 [7680/225000 (3%)] Loss: 19224.507812\n",
      "Train Epoch: 87 [10176/225000 (5%)] Loss: 19510.023438\n",
      "Train Epoch: 87 [12672/225000 (6%)] Loss: 19002.517578\n",
      "Train Epoch: 87 [15168/225000 (7%)] Loss: 19078.898438\n",
      "Train Epoch: 87 [17664/225000 (8%)] Loss: 18814.515625\n",
      "Train Epoch: 87 [20160/225000 (9%)] Loss: 19891.556641\n",
      "Train Epoch: 87 [22656/225000 (10%)] Loss: 19896.773438\n",
      "Train Epoch: 87 [25152/225000 (11%)] Loss: 19194.976562\n",
      "Train Epoch: 87 [27648/225000 (12%)] Loss: 18982.292969\n",
      "Train Epoch: 87 [30144/225000 (13%)] Loss: 19348.703125\n",
      "Train Epoch: 87 [32640/225000 (15%)] Loss: 19937.867188\n",
      "Train Epoch: 87 [35136/225000 (16%)] Loss: 19655.468750\n",
      "Train Epoch: 87 [37632/225000 (17%)] Loss: 19626.787109\n",
      "Train Epoch: 87 [40128/225000 (18%)] Loss: 19700.412109\n",
      "Train Epoch: 87 [42624/225000 (19%)] Loss: 19165.632812\n",
      "Train Epoch: 87 [45120/225000 (20%)] Loss: 19583.710938\n",
      "Train Epoch: 87 [47616/225000 (21%)] Loss: 19707.337891\n",
      "Train Epoch: 87 [50112/225000 (22%)] Loss: 19106.453125\n",
      "Train Epoch: 87 [52608/225000 (23%)] Loss: 19555.789062\n",
      "Train Epoch: 87 [55104/225000 (24%)] Loss: 19400.732422\n",
      "Train Epoch: 87 [57600/225000 (26%)] Loss: 19512.746094\n",
      "Train Epoch: 87 [60096/225000 (27%)] Loss: 19737.492188\n",
      "Train Epoch: 87 [62592/225000 (28%)] Loss: 19651.351562\n",
      "Train Epoch: 87 [65088/225000 (29%)] Loss: 19406.550781\n",
      "Train Epoch: 87 [67584/225000 (30%)] Loss: 19943.996094\n",
      "Train Epoch: 87 [70080/225000 (31%)] Loss: 19355.041016\n",
      "Train Epoch: 87 [72576/225000 (32%)] Loss: 19551.085938\n",
      "Train Epoch: 87 [75072/225000 (33%)] Loss: 19779.082031\n",
      "Train Epoch: 87 [77568/225000 (34%)] Loss: 19399.781250\n",
      "Train Epoch: 87 [80064/225000 (36%)] Loss: 19638.962891\n",
      "Train Epoch: 87 [82560/225000 (37%)] Loss: 19718.115234\n",
      "Train Epoch: 87 [85056/225000 (38%)] Loss: 19266.574219\n",
      "Train Epoch: 87 [87552/225000 (39%)] Loss: 20251.382812\n",
      "Train Epoch: 87 [90048/225000 (40%)] Loss: 19570.939453\n",
      "Train Epoch: 87 [92544/225000 (41%)] Loss: 18813.785156\n",
      "Train Epoch: 87 [95040/225000 (42%)] Loss: 19487.906250\n",
      "Train Epoch: 87 [97536/225000 (43%)] Loss: 20149.691406\n",
      "Train Epoch: 87 [100032/225000 (44%)] Loss: 19370.343750\n",
      "Train Epoch: 87 [102528/225000 (46%)] Loss: 19451.308594\n",
      "Train Epoch: 87 [105024/225000 (47%)] Loss: 19217.222656\n",
      "Train Epoch: 87 [107520/225000 (48%)] Loss: 19830.521484\n",
      "Train Epoch: 87 [110016/225000 (49%)] Loss: 19939.328125\n",
      "Train Epoch: 87 [112512/225000 (50%)] Loss: 20137.265625\n",
      "Train Epoch: 87 [115008/225000 (51%)] Loss: 19698.636719\n",
      "Train Epoch: 87 [117504/225000 (52%)] Loss: 19273.460938\n",
      "Train Epoch: 87 [120000/225000 (53%)] Loss: 20178.986328\n",
      "Train Epoch: 87 [122496/225000 (54%)] Loss: 19314.857422\n",
      "Train Epoch: 87 [124992/225000 (56%)] Loss: 19338.621094\n",
      "Train Epoch: 87 [127488/225000 (57%)] Loss: 19500.757812\n",
      "Train Epoch: 87 [129984/225000 (58%)] Loss: 19631.996094\n",
      "Train Epoch: 87 [132480/225000 (59%)] Loss: 19396.037109\n",
      "Train Epoch: 87 [134976/225000 (60%)] Loss: 19469.910156\n",
      "Train Epoch: 87 [137472/225000 (61%)] Loss: 19806.343750\n",
      "Train Epoch: 87 [139968/225000 (62%)] Loss: 19623.230469\n",
      "Train Epoch: 87 [142464/225000 (63%)] Loss: 19602.187500\n",
      "Train Epoch: 87 [144960/225000 (64%)] Loss: 19730.060547\n",
      "Train Epoch: 87 [147456/225000 (66%)] Loss: 19618.867188\n",
      "Train Epoch: 87 [149952/225000 (67%)] Loss: 19696.683594\n",
      "Train Epoch: 87 [152448/225000 (68%)] Loss: 20175.695312\n",
      "Train Epoch: 87 [154944/225000 (69%)] Loss: 19818.828125\n",
      "Train Epoch: 87 [157440/225000 (70%)] Loss: 19656.683594\n",
      "Train Epoch: 87 [159936/225000 (71%)] Loss: 20121.910156\n",
      "Train Epoch: 87 [162432/225000 (72%)] Loss: 19385.359375\n",
      "Train Epoch: 87 [164928/225000 (73%)] Loss: 19480.353516\n",
      "Train Epoch: 87 [167424/225000 (74%)] Loss: 19005.757812\n",
      "Train Epoch: 87 [169920/225000 (76%)] Loss: 19334.429688\n",
      "Train Epoch: 87 [172416/225000 (77%)] Loss: 19814.507812\n",
      "Train Epoch: 87 [174912/225000 (78%)] Loss: 19527.687500\n",
      "Train Epoch: 87 [177408/225000 (79%)] Loss: 19444.621094\n",
      "Train Epoch: 87 [179904/225000 (80%)] Loss: 19149.554688\n",
      "Train Epoch: 87 [182400/225000 (81%)] Loss: 19294.974609\n",
      "Train Epoch: 87 [184896/225000 (82%)] Loss: 19099.253906\n",
      "Train Epoch: 87 [187392/225000 (83%)] Loss: 19407.814453\n",
      "Train Epoch: 87 [189888/225000 (84%)] Loss: 19830.876953\n",
      "Train Epoch: 87 [192384/225000 (86%)] Loss: 19399.925781\n",
      "Train Epoch: 87 [194880/225000 (87%)] Loss: 19336.492188\n",
      "Train Epoch: 87 [197376/225000 (88%)] Loss: 19657.968750\n",
      "Train Epoch: 87 [199872/225000 (89%)] Loss: 19573.277344\n",
      "Train Epoch: 87 [202368/225000 (90%)] Loss: 20253.855469\n",
      "Train Epoch: 87 [204864/225000 (91%)] Loss: 19571.953125\n",
      "Train Epoch: 87 [207360/225000 (92%)] Loss: 19503.789062\n",
      "Train Epoch: 87 [209856/225000 (93%)] Loss: 19743.511719\n",
      "Train Epoch: 87 [212352/225000 (94%)] Loss: 19365.125000\n",
      "Train Epoch: 87 [214848/225000 (95%)] Loss: 19302.324219\n",
      "Train Epoch: 87 [217344/225000 (97%)] Loss: 19616.878906\n",
      "Train Epoch: 87 [219840/225000 (98%)] Loss: 19649.230469\n",
      "Train Epoch: 87 [222336/225000 (99%)] Loss: 19520.800781\n",
      "Train Epoch: 87 [224832/225000 (100%)] Loss: 19017.972656\n",
      "    epoch          : 87\n",
      "    loss           : 19624.15266538236\n",
      "    val_loss       : 19511.055648057514\n",
      "Train Epoch: 88 [192/225000 (0%)] Loss: 19455.080078\n",
      "Train Epoch: 88 [2688/225000 (1%)] Loss: 19860.480469\n",
      "Train Epoch: 88 [5184/225000 (2%)] Loss: 19201.734375\n",
      "Train Epoch: 88 [7680/225000 (3%)] Loss: 19228.464844\n",
      "Train Epoch: 88 [10176/225000 (5%)] Loss: 19892.789062\n",
      "Train Epoch: 88 [12672/225000 (6%)] Loss: 20141.650391\n",
      "Train Epoch: 88 [15168/225000 (7%)] Loss: 19799.718750\n",
      "Train Epoch: 88 [17664/225000 (8%)] Loss: 19836.515625\n",
      "Train Epoch: 88 [20160/225000 (9%)] Loss: 19682.246094\n",
      "Train Epoch: 88 [22656/225000 (10%)] Loss: 19400.269531\n",
      "Train Epoch: 88 [25152/225000 (11%)] Loss: 19323.109375\n",
      "Train Epoch: 88 [27648/225000 (12%)] Loss: 19309.755859\n",
      "Train Epoch: 88 [30144/225000 (13%)] Loss: 19760.136719\n",
      "Train Epoch: 88 [32640/225000 (15%)] Loss: 19939.515625\n",
      "Train Epoch: 88 [35136/225000 (16%)] Loss: 20226.585938\n",
      "Train Epoch: 88 [37632/225000 (17%)] Loss: 19784.742188\n",
      "Train Epoch: 88 [40128/225000 (18%)] Loss: 20196.437500\n",
      "Train Epoch: 88 [42624/225000 (19%)] Loss: 19680.703125\n",
      "Train Epoch: 88 [45120/225000 (20%)] Loss: 19582.777344\n",
      "Train Epoch: 88 [47616/225000 (21%)] Loss: 19361.308594\n",
      "Train Epoch: 88 [50112/225000 (22%)] Loss: 19117.476562\n",
      "Train Epoch: 88 [52608/225000 (23%)] Loss: 19607.865234\n",
      "Train Epoch: 88 [55104/225000 (24%)] Loss: 20053.878906\n",
      "Train Epoch: 88 [57600/225000 (26%)] Loss: 19346.628906\n",
      "Train Epoch: 88 [60096/225000 (27%)] Loss: 19614.191406\n",
      "Train Epoch: 88 [62592/225000 (28%)] Loss: 19551.472656\n",
      "Train Epoch: 88 [65088/225000 (29%)] Loss: 18905.363281\n",
      "Train Epoch: 88 [67584/225000 (30%)] Loss: 19848.802734\n",
      "Train Epoch: 88 [70080/225000 (31%)] Loss: 19816.710938\n",
      "Train Epoch: 88 [72576/225000 (32%)] Loss: 19481.802734\n",
      "Train Epoch: 88 [75072/225000 (33%)] Loss: 19787.410156\n",
      "Train Epoch: 88 [77568/225000 (34%)] Loss: 19576.128906\n",
      "Train Epoch: 88 [80064/225000 (36%)] Loss: 19811.167969\n",
      "Train Epoch: 88 [82560/225000 (37%)] Loss: 19426.156250\n",
      "Train Epoch: 88 [85056/225000 (38%)] Loss: 19329.009766\n",
      "Train Epoch: 88 [87552/225000 (39%)] Loss: 20190.460938\n",
      "Train Epoch: 88 [90048/225000 (40%)] Loss: 19949.625000\n",
      "Train Epoch: 88 [92544/225000 (41%)] Loss: 19410.519531\n",
      "Train Epoch: 88 [95040/225000 (42%)] Loss: 19410.076172\n",
      "Train Epoch: 88 [97536/225000 (43%)] Loss: 19324.121094\n",
      "Train Epoch: 88 [100032/225000 (44%)] Loss: 19682.101562\n",
      "Train Epoch: 88 [102528/225000 (46%)] Loss: 19293.261719\n",
      "Train Epoch: 88 [105024/225000 (47%)] Loss: 19995.234375\n",
      "Train Epoch: 88 [107520/225000 (48%)] Loss: 19990.236328\n",
      "Train Epoch: 88 [110016/225000 (49%)] Loss: 19702.070312\n",
      "Train Epoch: 88 [112512/225000 (50%)] Loss: 19670.273438\n",
      "Train Epoch: 88 [115008/225000 (51%)] Loss: 19776.351562\n",
      "Train Epoch: 88 [117504/225000 (52%)] Loss: 19895.250000\n",
      "Train Epoch: 88 [120000/225000 (53%)] Loss: 19832.169922\n",
      "Train Epoch: 88 [122496/225000 (54%)] Loss: 19554.810547\n",
      "Train Epoch: 88 [124992/225000 (56%)] Loss: 19416.792969\n",
      "Train Epoch: 88 [127488/225000 (57%)] Loss: 19522.050781\n",
      "Train Epoch: 88 [129984/225000 (58%)] Loss: 19147.238281\n",
      "Train Epoch: 88 [132480/225000 (59%)] Loss: 19223.847656\n",
      "Train Epoch: 88 [134976/225000 (60%)] Loss: 19860.851562\n",
      "Train Epoch: 88 [137472/225000 (61%)] Loss: 19928.976562\n",
      "Train Epoch: 88 [139968/225000 (62%)] Loss: 19275.296875\n",
      "Train Epoch: 88 [142464/225000 (63%)] Loss: 19414.011719\n",
      "Train Epoch: 88 [144960/225000 (64%)] Loss: 19263.623047\n",
      "Train Epoch: 88 [147456/225000 (66%)] Loss: 20034.697266\n",
      "Train Epoch: 88 [149952/225000 (67%)] Loss: 19633.863281\n",
      "Train Epoch: 88 [152448/225000 (68%)] Loss: 19192.246094\n",
      "Train Epoch: 88 [154944/225000 (69%)] Loss: 19312.261719\n",
      "Train Epoch: 88 [157440/225000 (70%)] Loss: 19048.298828\n",
      "Train Epoch: 88 [159936/225000 (71%)] Loss: 19682.578125\n",
      "Train Epoch: 88 [162432/225000 (72%)] Loss: 19659.015625\n",
      "Train Epoch: 88 [164928/225000 (73%)] Loss: 19346.562500\n",
      "Train Epoch: 88 [167424/225000 (74%)] Loss: 19633.730469\n",
      "Train Epoch: 88 [169920/225000 (76%)] Loss: 19594.515625\n",
      "Train Epoch: 88 [172416/225000 (77%)] Loss: 19998.460938\n",
      "Train Epoch: 88 [174912/225000 (78%)] Loss: 19578.712891\n",
      "Train Epoch: 88 [177408/225000 (79%)] Loss: 19223.402344\n",
      "Train Epoch: 88 [179904/225000 (80%)] Loss: 19259.007812\n",
      "Train Epoch: 88 [182400/225000 (81%)] Loss: 19985.355469\n",
      "Train Epoch: 88 [184896/225000 (82%)] Loss: 19664.378906\n",
      "Train Epoch: 88 [187392/225000 (83%)] Loss: 19497.656250\n",
      "Train Epoch: 88 [189888/225000 (84%)] Loss: 19373.445312\n",
      "Train Epoch: 88 [192384/225000 (86%)] Loss: 19312.648438\n",
      "Train Epoch: 88 [194880/225000 (87%)] Loss: 19295.646484\n",
      "Train Epoch: 88 [197376/225000 (88%)] Loss: 19209.048828\n",
      "Train Epoch: 88 [199872/225000 (89%)] Loss: 19112.619141\n",
      "Train Epoch: 88 [202368/225000 (90%)] Loss: 19476.865234\n",
      "Train Epoch: 88 [204864/225000 (91%)] Loss: 19560.687500\n",
      "Train Epoch: 88 [207360/225000 (92%)] Loss: 19362.863281\n",
      "Train Epoch: 88 [209856/225000 (93%)] Loss: 20287.914062\n",
      "Train Epoch: 88 [212352/225000 (94%)] Loss: 19171.099609\n",
      "Train Epoch: 88 [214848/225000 (95%)] Loss: 19423.787109\n",
      "Train Epoch: 88 [217344/225000 (97%)] Loss: 19805.234375\n",
      "Train Epoch: 88 [219840/225000 (98%)] Loss: 19233.013672\n",
      "Train Epoch: 88 [222336/225000 (99%)] Loss: 19954.046875\n",
      "Train Epoch: 88 [224832/225000 (100%)] Loss: 20088.671875\n",
      "    epoch          : 88\n",
      "    loss           : 19605.30499580045\n",
      "    val_loss       : 19490.79204581166\n",
      "Train Epoch: 89 [192/225000 (0%)] Loss: 19624.560547\n",
      "Train Epoch: 89 [2688/225000 (1%)] Loss: 19187.859375\n",
      "Train Epoch: 89 [5184/225000 (2%)] Loss: 19939.289062\n",
      "Train Epoch: 89 [7680/225000 (3%)] Loss: 19850.046875\n",
      "Train Epoch: 89 [10176/225000 (5%)] Loss: 19659.683594\n",
      "Train Epoch: 89 [12672/225000 (6%)] Loss: 19540.714844\n",
      "Train Epoch: 89 [15168/225000 (7%)] Loss: 19092.500000\n",
      "Train Epoch: 89 [17664/225000 (8%)] Loss: 19425.855469\n",
      "Train Epoch: 89 [20160/225000 (9%)] Loss: 19268.183594\n",
      "Train Epoch: 89 [22656/225000 (10%)] Loss: 20059.419922\n",
      "Train Epoch: 89 [25152/225000 (11%)] Loss: 19490.988281\n",
      "Train Epoch: 89 [27648/225000 (12%)] Loss: 19042.085938\n",
      "Train Epoch: 89 [30144/225000 (13%)] Loss: 19495.238281\n",
      "Train Epoch: 89 [32640/225000 (15%)] Loss: 19285.566406\n",
      "Train Epoch: 89 [35136/225000 (16%)] Loss: 19188.333984\n",
      "Train Epoch: 89 [37632/225000 (17%)] Loss: 19301.300781\n",
      "Train Epoch: 89 [40128/225000 (18%)] Loss: 19800.589844\n",
      "Train Epoch: 89 [42624/225000 (19%)] Loss: 19237.800781\n",
      "Train Epoch: 89 [45120/225000 (20%)] Loss: 19109.125000\n",
      "Train Epoch: 89 [47616/225000 (21%)] Loss: 19538.195312\n",
      "Train Epoch: 89 [50112/225000 (22%)] Loss: 19454.714844\n",
      "Train Epoch: 89 [52608/225000 (23%)] Loss: 19944.179688\n",
      "Train Epoch: 89 [55104/225000 (24%)] Loss: 19491.132812\n",
      "Train Epoch: 89 [57600/225000 (26%)] Loss: 19773.609375\n",
      "Train Epoch: 89 [60096/225000 (27%)] Loss: 19511.222656\n",
      "Train Epoch: 89 [62592/225000 (28%)] Loss: 19329.800781\n",
      "Train Epoch: 89 [65088/225000 (29%)] Loss: 20086.789062\n",
      "Train Epoch: 89 [67584/225000 (30%)] Loss: 19455.250000\n",
      "Train Epoch: 89 [70080/225000 (31%)] Loss: 19779.542969\n",
      "Train Epoch: 89 [72576/225000 (32%)] Loss: 20081.464844\n",
      "Train Epoch: 89 [75072/225000 (33%)] Loss: 19481.460938\n",
      "Train Epoch: 89 [77568/225000 (34%)] Loss: 19424.894531\n",
      "Train Epoch: 89 [80064/225000 (36%)] Loss: 19244.587891\n",
      "Train Epoch: 89 [82560/225000 (37%)] Loss: 19314.955078\n",
      "Train Epoch: 89 [85056/225000 (38%)] Loss: 19237.886719\n",
      "Train Epoch: 89 [87552/225000 (39%)] Loss: 19656.496094\n",
      "Train Epoch: 89 [90048/225000 (40%)] Loss: 19624.265625\n",
      "Train Epoch: 89 [92544/225000 (41%)] Loss: 19608.035156\n",
      "Train Epoch: 89 [95040/225000 (42%)] Loss: 19387.820312\n",
      "Train Epoch: 89 [97536/225000 (43%)] Loss: 19900.873047\n",
      "Train Epoch: 89 [100032/225000 (44%)] Loss: 19203.042969\n",
      "Train Epoch: 89 [102528/225000 (46%)] Loss: 19466.050781\n",
      "Train Epoch: 89 [105024/225000 (47%)] Loss: 19886.820312\n",
      "Train Epoch: 89 [107520/225000 (48%)] Loss: 20119.054688\n",
      "Train Epoch: 89 [110016/225000 (49%)] Loss: 19377.773438\n",
      "Train Epoch: 89 [112512/225000 (50%)] Loss: 20278.875000\n",
      "Train Epoch: 89 [115008/225000 (51%)] Loss: 19359.792969\n",
      "Train Epoch: 89 [117504/225000 (52%)] Loss: 19945.203125\n",
      "Train Epoch: 89 [120000/225000 (53%)] Loss: 19781.937500\n",
      "Train Epoch: 89 [122496/225000 (54%)] Loss: 19783.890625\n",
      "Train Epoch: 89 [124992/225000 (56%)] Loss: 19795.103516\n",
      "Train Epoch: 89 [127488/225000 (57%)] Loss: 19359.554688\n",
      "Train Epoch: 89 [129984/225000 (58%)] Loss: 19390.984375\n",
      "Train Epoch: 89 [132480/225000 (59%)] Loss: 19432.980469\n",
      "Train Epoch: 89 [134976/225000 (60%)] Loss: 20053.679688\n",
      "Train Epoch: 89 [137472/225000 (61%)] Loss: 19754.648438\n",
      "Train Epoch: 89 [139968/225000 (62%)] Loss: 19475.621094\n",
      "Train Epoch: 89 [142464/225000 (63%)] Loss: 20025.003906\n",
      "Train Epoch: 89 [144960/225000 (64%)] Loss: 19630.472656\n",
      "Train Epoch: 89 [147456/225000 (66%)] Loss: 19761.724609\n",
      "Train Epoch: 89 [149952/225000 (67%)] Loss: 19606.683594\n",
      "Train Epoch: 89 [152448/225000 (68%)] Loss: 19009.820312\n",
      "Train Epoch: 89 [154944/225000 (69%)] Loss: 19764.664062\n",
      "Train Epoch: 89 [157440/225000 (70%)] Loss: 19976.031250\n",
      "Train Epoch: 89 [159936/225000 (71%)] Loss: 19733.197266\n",
      "Train Epoch: 89 [162432/225000 (72%)] Loss: 19657.847656\n",
      "Train Epoch: 89 [164928/225000 (73%)] Loss: 19656.021484\n",
      "Train Epoch: 89 [167424/225000 (74%)] Loss: 19573.189453\n",
      "Train Epoch: 89 [169920/225000 (76%)] Loss: 19692.601562\n",
      "Train Epoch: 89 [172416/225000 (77%)] Loss: 19645.242188\n",
      "Train Epoch: 89 [174912/225000 (78%)] Loss: 19755.847656\n",
      "Train Epoch: 89 [177408/225000 (79%)] Loss: 19702.167969\n",
      "Train Epoch: 89 [179904/225000 (80%)] Loss: 19484.220703\n",
      "Train Epoch: 89 [182400/225000 (81%)] Loss: 19532.027344\n",
      "Train Epoch: 89 [184896/225000 (82%)] Loss: 19599.845703\n",
      "Train Epoch: 89 [187392/225000 (83%)] Loss: 19484.162109\n",
      "Train Epoch: 89 [189888/225000 (84%)] Loss: 20061.894531\n",
      "Train Epoch: 89 [192384/225000 (86%)] Loss: 19491.166016\n",
      "Train Epoch: 89 [194880/225000 (87%)] Loss: 19108.898438\n",
      "Train Epoch: 89 [197376/225000 (88%)] Loss: 19626.720703\n",
      "Train Epoch: 89 [199872/225000 (89%)] Loss: 20005.544922\n",
      "Train Epoch: 89 [202368/225000 (90%)] Loss: 19721.240234\n",
      "Train Epoch: 89 [204864/225000 (91%)] Loss: 20335.730469\n",
      "Train Epoch: 89 [207360/225000 (92%)] Loss: 19764.812500\n",
      "Train Epoch: 89 [209856/225000 (93%)] Loss: 19596.197266\n",
      "Train Epoch: 89 [212352/225000 (94%)] Loss: 19533.736328\n",
      "Train Epoch: 89 [214848/225000 (95%)] Loss: 19460.351562\n",
      "Train Epoch: 89 [217344/225000 (97%)] Loss: 20131.417969\n",
      "Train Epoch: 89 [219840/225000 (98%)] Loss: 19342.732422\n",
      "Train Epoch: 89 [222336/225000 (99%)] Loss: 19512.152344\n",
      "Train Epoch: 89 [224832/225000 (100%)] Loss: 19535.673828\n",
      "    epoch          : 89\n",
      "    loss           : 19585.5663912516\n",
      "    val_loss       : 19485.905604508087\n",
      "Train Epoch: 90 [192/225000 (0%)] Loss: 19491.431641\n",
      "Train Epoch: 90 [2688/225000 (1%)] Loss: 19871.011719\n",
      "Train Epoch: 90 [5184/225000 (2%)] Loss: 19824.953125\n",
      "Train Epoch: 90 [7680/225000 (3%)] Loss: 19159.384766\n",
      "Train Epoch: 90 [10176/225000 (5%)] Loss: 19946.109375\n",
      "Train Epoch: 90 [12672/225000 (6%)] Loss: 19246.720703\n",
      "Train Epoch: 90 [15168/225000 (7%)] Loss: 19381.781250\n",
      "Train Epoch: 90 [17664/225000 (8%)] Loss: 19514.945312\n",
      "Train Epoch: 90 [20160/225000 (9%)] Loss: 19914.082031\n",
      "Train Epoch: 90 [22656/225000 (10%)] Loss: 20026.605469\n",
      "Train Epoch: 90 [25152/225000 (11%)] Loss: 19296.615234\n",
      "Train Epoch: 90 [27648/225000 (12%)] Loss: 19768.908203\n",
      "Train Epoch: 90 [30144/225000 (13%)] Loss: 19446.357422\n",
      "Train Epoch: 90 [32640/225000 (15%)] Loss: 19472.636719\n",
      "Train Epoch: 90 [35136/225000 (16%)] Loss: 19727.785156\n",
      "Train Epoch: 90 [37632/225000 (17%)] Loss: 19294.386719\n",
      "Train Epoch: 90 [40128/225000 (18%)] Loss: 19740.960938\n",
      "Train Epoch: 90 [42624/225000 (19%)] Loss: 19909.451172\n",
      "Train Epoch: 90 [45120/225000 (20%)] Loss: 19488.203125\n",
      "Train Epoch: 90 [47616/225000 (21%)] Loss: 19380.466797\n",
      "Train Epoch: 90 [50112/225000 (22%)] Loss: 19527.171875\n",
      "Train Epoch: 90 [52608/225000 (23%)] Loss: 19541.800781\n",
      "Train Epoch: 90 [55104/225000 (24%)] Loss: 19751.835938\n",
      "Train Epoch: 90 [57600/225000 (26%)] Loss: 19343.140625\n",
      "Train Epoch: 90 [60096/225000 (27%)] Loss: 19705.394531\n",
      "Train Epoch: 90 [62592/225000 (28%)] Loss: 19858.074219\n",
      "Train Epoch: 90 [65088/225000 (29%)] Loss: 19152.585938\n",
      "Train Epoch: 90 [67584/225000 (30%)] Loss: 19596.080078\n",
      "Train Epoch: 90 [70080/225000 (31%)] Loss: 19697.843750\n",
      "Train Epoch: 90 [72576/225000 (32%)] Loss: 20024.640625\n",
      "Train Epoch: 90 [75072/225000 (33%)] Loss: 19332.322266\n",
      "Train Epoch: 90 [77568/225000 (34%)] Loss: 19240.279297\n",
      "Train Epoch: 90 [80064/225000 (36%)] Loss: 19215.664062\n",
      "Train Epoch: 90 [82560/225000 (37%)] Loss: 19563.091797\n",
      "Train Epoch: 90 [85056/225000 (38%)] Loss: 19255.804688\n",
      "Train Epoch: 90 [87552/225000 (39%)] Loss: 20071.748047\n",
      "Train Epoch: 90 [90048/225000 (40%)] Loss: 19393.234375\n",
      "Train Epoch: 90 [92544/225000 (41%)] Loss: 19896.679688\n",
      "Train Epoch: 90 [95040/225000 (42%)] Loss: 19276.859375\n",
      "Train Epoch: 90 [97536/225000 (43%)] Loss: 20020.554688\n",
      "Train Epoch: 90 [100032/225000 (44%)] Loss: 19731.205078\n",
      "Train Epoch: 90 [102528/225000 (46%)] Loss: 19897.990234\n",
      "Train Epoch: 90 [105024/225000 (47%)] Loss: 19120.574219\n",
      "Train Epoch: 90 [107520/225000 (48%)] Loss: 19413.642578\n",
      "Train Epoch: 90 [110016/225000 (49%)] Loss: 19756.587891\n",
      "Train Epoch: 90 [112512/225000 (50%)] Loss: 19193.566406\n",
      "Train Epoch: 90 [115008/225000 (51%)] Loss: 19255.636719\n",
      "Train Epoch: 90 [117504/225000 (52%)] Loss: 19140.808594\n",
      "Train Epoch: 90 [120000/225000 (53%)] Loss: 19714.238281\n",
      "Train Epoch: 90 [122496/225000 (54%)] Loss: 19605.816406\n",
      "Train Epoch: 90 [124992/225000 (56%)] Loss: 19869.078125\n",
      "Train Epoch: 90 [127488/225000 (57%)] Loss: 19665.191406\n",
      "Train Epoch: 90 [129984/225000 (58%)] Loss: 19893.652344\n",
      "Train Epoch: 90 [132480/225000 (59%)] Loss: 19452.539062\n",
      "Train Epoch: 90 [134976/225000 (60%)] Loss: 19592.539062\n",
      "Train Epoch: 90 [137472/225000 (61%)] Loss: 19629.187500\n",
      "Train Epoch: 90 [139968/225000 (62%)] Loss: 19767.460938\n",
      "Train Epoch: 90 [142464/225000 (63%)] Loss: 19287.503906\n",
      "Train Epoch: 90 [144960/225000 (64%)] Loss: 19321.593750\n",
      "Train Epoch: 90 [147456/225000 (66%)] Loss: 19780.605469\n",
      "Train Epoch: 90 [149952/225000 (67%)] Loss: 19535.652344\n",
      "Train Epoch: 90 [152448/225000 (68%)] Loss: 19816.492188\n",
      "Train Epoch: 90 [154944/225000 (69%)] Loss: 19316.777344\n",
      "Train Epoch: 90 [157440/225000 (70%)] Loss: 19644.509766\n",
      "Train Epoch: 90 [159936/225000 (71%)] Loss: 19879.328125\n",
      "Train Epoch: 90 [162432/225000 (72%)] Loss: 19524.050781\n",
      "Train Epoch: 90 [164928/225000 (73%)] Loss: 19976.833984\n",
      "Train Epoch: 90 [167424/225000 (74%)] Loss: 20076.511719\n",
      "Train Epoch: 90 [169920/225000 (76%)] Loss: 19347.148438\n",
      "Train Epoch: 90 [172416/225000 (77%)] Loss: 19743.125000\n",
      "Train Epoch: 90 [174912/225000 (78%)] Loss: 19638.470703\n",
      "Train Epoch: 90 [177408/225000 (79%)] Loss: 19755.902344\n",
      "Train Epoch: 90 [179904/225000 (80%)] Loss: 19682.421875\n",
      "Train Epoch: 90 [182400/225000 (81%)] Loss: 19571.531250\n",
      "Train Epoch: 90 [184896/225000 (82%)] Loss: 19265.714844\n",
      "Train Epoch: 90 [187392/225000 (83%)] Loss: 19776.746094\n",
      "Train Epoch: 90 [189888/225000 (84%)] Loss: 19679.597656\n",
      "Train Epoch: 90 [192384/225000 (86%)] Loss: 19153.761719\n",
      "Train Epoch: 90 [194880/225000 (87%)] Loss: 19443.484375\n",
      "Train Epoch: 90 [197376/225000 (88%)] Loss: 19790.179688\n",
      "Train Epoch: 90 [199872/225000 (89%)] Loss: 24294.128906\n",
      "Train Epoch: 90 [202368/225000 (90%)] Loss: 19886.126953\n",
      "Train Epoch: 90 [204864/225000 (91%)] Loss: 19452.365234\n",
      "Train Epoch: 90 [207360/225000 (92%)] Loss: 19595.089844\n",
      "Train Epoch: 90 [209856/225000 (93%)] Loss: 20133.658203\n",
      "Train Epoch: 90 [212352/225000 (94%)] Loss: 20240.148438\n",
      "Train Epoch: 90 [214848/225000 (95%)] Loss: 19588.128906\n",
      "Train Epoch: 90 [217344/225000 (97%)] Loss: 19360.265625\n",
      "Train Epoch: 90 [219840/225000 (98%)] Loss: 19469.218750\n",
      "Train Epoch: 90 [222336/225000 (99%)] Loss: 19371.453125\n",
      "Train Epoch: 90 [224832/225000 (100%)] Loss: 19419.183594\n",
      "    epoch          : 90\n",
      "    loss           : 19586.190987961283\n",
      "    val_loss       : 19475.924868764767\n",
      "Train Epoch: 91 [192/225000 (0%)] Loss: 19548.363281\n",
      "Train Epoch: 91 [2688/225000 (1%)] Loss: 19724.523438\n",
      "Train Epoch: 91 [5184/225000 (2%)] Loss: 19621.562500\n",
      "Train Epoch: 91 [7680/225000 (3%)] Loss: 19407.367188\n",
      "Train Epoch: 91 [10176/225000 (5%)] Loss: 19726.242188\n",
      "Train Epoch: 91 [12672/225000 (6%)] Loss: 19484.886719\n",
      "Train Epoch: 91 [15168/225000 (7%)] Loss: 19896.781250\n",
      "Train Epoch: 91 [17664/225000 (8%)] Loss: 19667.128906\n",
      "Train Epoch: 91 [20160/225000 (9%)] Loss: 19478.886719\n",
      "Train Epoch: 91 [22656/225000 (10%)] Loss: 19309.394531\n",
      "Train Epoch: 91 [25152/225000 (11%)] Loss: 19447.882812\n",
      "Train Epoch: 91 [27648/225000 (12%)] Loss: 19761.341797\n",
      "Train Epoch: 91 [30144/225000 (13%)] Loss: 19550.755859\n",
      "Train Epoch: 91 [32640/225000 (15%)] Loss: 19994.820312\n",
      "Train Epoch: 91 [35136/225000 (16%)] Loss: 19735.923828\n",
      "Train Epoch: 91 [37632/225000 (17%)] Loss: 19409.632812\n",
      "Train Epoch: 91 [40128/225000 (18%)] Loss: 19742.601562\n",
      "Train Epoch: 91 [42624/225000 (19%)] Loss: 19426.183594\n",
      "Train Epoch: 91 [45120/225000 (20%)] Loss: 19380.931641\n",
      "Train Epoch: 91 [47616/225000 (21%)] Loss: 19546.320312\n",
      "Train Epoch: 91 [50112/225000 (22%)] Loss: 19472.328125\n",
      "Train Epoch: 91 [52608/225000 (23%)] Loss: 19524.199219\n",
      "Train Epoch: 91 [55104/225000 (24%)] Loss: 19512.304688\n",
      "Train Epoch: 91 [57600/225000 (26%)] Loss: 19569.765625\n",
      "Train Epoch: 91 [60096/225000 (27%)] Loss: 19567.623047\n",
      "Train Epoch: 91 [62592/225000 (28%)] Loss: 19437.404297\n",
      "Train Epoch: 91 [65088/225000 (29%)] Loss: 19454.740234\n",
      "Train Epoch: 91 [67584/225000 (30%)] Loss: 19405.435547\n",
      "Train Epoch: 91 [70080/225000 (31%)] Loss: 19793.902344\n",
      "Train Epoch: 91 [72576/225000 (32%)] Loss: 19862.816406\n",
      "Train Epoch: 91 [75072/225000 (33%)] Loss: 19359.539062\n",
      "Train Epoch: 91 [77568/225000 (34%)] Loss: 19543.031250\n",
      "Train Epoch: 91 [80064/225000 (36%)] Loss: 19486.939453\n",
      "Train Epoch: 91 [82560/225000 (37%)] Loss: 19728.148438\n",
      "Train Epoch: 91 [85056/225000 (38%)] Loss: 18855.591797\n",
      "Train Epoch: 91 [87552/225000 (39%)] Loss: 19807.064453\n",
      "Train Epoch: 91 [90048/225000 (40%)] Loss: 19853.878906\n",
      "Train Epoch: 91 [92544/225000 (41%)] Loss: 19572.267578\n",
      "Train Epoch: 91 [95040/225000 (42%)] Loss: 19299.697266\n",
      "Train Epoch: 91 [97536/225000 (43%)] Loss: 19404.226562\n",
      "Train Epoch: 91 [100032/225000 (44%)] Loss: 19681.470703\n",
      "Train Epoch: 91 [102528/225000 (46%)] Loss: 19649.542969\n",
      "Train Epoch: 91 [105024/225000 (47%)] Loss: 20107.125000\n",
      "Train Epoch: 91 [107520/225000 (48%)] Loss: 19121.976562\n",
      "Train Epoch: 91 [110016/225000 (49%)] Loss: 19548.269531\n",
      "Train Epoch: 91 [112512/225000 (50%)] Loss: 19306.695312\n",
      "Train Epoch: 91 [115008/225000 (51%)] Loss: 19464.578125\n",
      "Train Epoch: 91 [117504/225000 (52%)] Loss: 19962.515625\n",
      "Train Epoch: 91 [120000/225000 (53%)] Loss: 19426.708984\n",
      "Train Epoch: 91 [122496/225000 (54%)] Loss: 19411.605469\n",
      "Train Epoch: 91 [124992/225000 (56%)] Loss: 19573.261719\n",
      "Train Epoch: 91 [127488/225000 (57%)] Loss: 19908.212891\n",
      "Train Epoch: 91 [129984/225000 (58%)] Loss: 19154.000000\n",
      "Train Epoch: 91 [132480/225000 (59%)] Loss: 19513.111328\n",
      "Train Epoch: 91 [134976/225000 (60%)] Loss: 19760.988281\n",
      "Train Epoch: 91 [137472/225000 (61%)] Loss: 20131.443359\n",
      "Train Epoch: 91 [139968/225000 (62%)] Loss: 19312.132812\n",
      "Train Epoch: 91 [142464/225000 (63%)] Loss: 19435.376953\n",
      "Train Epoch: 91 [144960/225000 (64%)] Loss: 19581.220703\n",
      "Train Epoch: 91 [147456/225000 (66%)] Loss: 18989.011719\n",
      "Train Epoch: 91 [149952/225000 (67%)] Loss: 19845.140625\n",
      "Train Epoch: 91 [152448/225000 (68%)] Loss: 19356.167969\n",
      "Train Epoch: 91 [154944/225000 (69%)] Loss: 20049.414062\n",
      "Train Epoch: 91 [157440/225000 (70%)] Loss: 19646.658203\n",
      "Train Epoch: 91 [159936/225000 (71%)] Loss: 18892.876953\n",
      "Train Epoch: 91 [162432/225000 (72%)] Loss: 19490.880859\n",
      "Train Epoch: 91 [164928/225000 (73%)] Loss: 19347.761719\n",
      "Train Epoch: 91 [167424/225000 (74%)] Loss: 19584.976562\n",
      "Train Epoch: 91 [169920/225000 (76%)] Loss: 19743.623047\n",
      "Train Epoch: 91 [172416/225000 (77%)] Loss: 19556.820312\n",
      "Train Epoch: 91 [174912/225000 (78%)] Loss: 19706.773438\n",
      "Train Epoch: 91 [177408/225000 (79%)] Loss: 19714.904297\n",
      "Train Epoch: 91 [179904/225000 (80%)] Loss: 20011.804688\n",
      "Train Epoch: 91 [182400/225000 (81%)] Loss: 19822.457031\n",
      "Train Epoch: 91 [184896/225000 (82%)] Loss: 19447.558594\n",
      "Train Epoch: 91 [187392/225000 (83%)] Loss: 19726.410156\n",
      "Train Epoch: 91 [189888/225000 (84%)] Loss: 19738.421875\n",
      "Train Epoch: 91 [192384/225000 (86%)] Loss: 19433.132812\n",
      "Train Epoch: 91 [194880/225000 (87%)] Loss: 20265.683594\n",
      "Train Epoch: 91 [197376/225000 (88%)] Loss: 19664.783203\n",
      "Train Epoch: 91 [199872/225000 (89%)] Loss: 19939.103516\n",
      "Train Epoch: 91 [202368/225000 (90%)] Loss: 19920.777344\n",
      "Train Epoch: 91 [204864/225000 (91%)] Loss: 19452.009766\n",
      "Train Epoch: 91 [207360/225000 (92%)] Loss: 19686.796875\n",
      "Train Epoch: 91 [209856/225000 (93%)] Loss: 19670.796875\n",
      "Train Epoch: 91 [212352/225000 (94%)] Loss: 19196.673828\n",
      "Train Epoch: 91 [214848/225000 (95%)] Loss: 19609.093750\n",
      "Train Epoch: 91 [217344/225000 (97%)] Loss: 19744.214844\n",
      "Train Epoch: 91 [219840/225000 (98%)] Loss: 19702.796875\n",
      "Train Epoch: 91 [222336/225000 (99%)] Loss: 19923.607422\n",
      "Train Epoch: 91 [224832/225000 (100%)] Loss: 19491.062500\n",
      "    epoch          : 91\n",
      "    loss           : 19574.224981002026\n",
      "    val_loss       : 19465.856796714186\n",
      "Train Epoch: 92 [192/225000 (0%)] Loss: 20055.242188\n",
      "Train Epoch: 92 [2688/225000 (1%)] Loss: 19790.695312\n",
      "Train Epoch: 92 [5184/225000 (2%)] Loss: 19528.410156\n",
      "Train Epoch: 92 [7680/225000 (3%)] Loss: 19584.425781\n",
      "Train Epoch: 92 [10176/225000 (5%)] Loss: 20092.056641\n",
      "Train Epoch: 92 [12672/225000 (6%)] Loss: 19609.578125\n",
      "Train Epoch: 92 [15168/225000 (7%)] Loss: 19673.785156\n",
      "Train Epoch: 92 [17664/225000 (8%)] Loss: 19968.419922\n",
      "Train Epoch: 92 [20160/225000 (9%)] Loss: 20026.593750\n",
      "Train Epoch: 92 [22656/225000 (10%)] Loss: 19366.400391\n",
      "Train Epoch: 92 [25152/225000 (11%)] Loss: 19995.871094\n",
      "Train Epoch: 92 [27648/225000 (12%)] Loss: 19625.695312\n",
      "Train Epoch: 92 [30144/225000 (13%)] Loss: 19651.300781\n",
      "Train Epoch: 92 [32640/225000 (15%)] Loss: 19639.736328\n",
      "Train Epoch: 92 [35136/225000 (16%)] Loss: 19727.558594\n",
      "Train Epoch: 92 [37632/225000 (17%)] Loss: 19655.152344\n",
      "Train Epoch: 92 [40128/225000 (18%)] Loss: 19817.039062\n",
      "Train Epoch: 92 [42624/225000 (19%)] Loss: 19907.710938\n",
      "Train Epoch: 92 [45120/225000 (20%)] Loss: 19545.201172\n",
      "Train Epoch: 92 [47616/225000 (21%)] Loss: 19659.689453\n",
      "Train Epoch: 92 [50112/225000 (22%)] Loss: 19265.958984\n",
      "Train Epoch: 92 [52608/225000 (23%)] Loss: 19939.039062\n",
      "Train Epoch: 92 [55104/225000 (24%)] Loss: 19734.160156\n",
      "Train Epoch: 92 [57600/225000 (26%)] Loss: 19286.500000\n",
      "Train Epoch: 92 [60096/225000 (27%)] Loss: 19983.144531\n",
      "Train Epoch: 92 [62592/225000 (28%)] Loss: 19685.021484\n",
      "Train Epoch: 92 [65088/225000 (29%)] Loss: 19225.859375\n",
      "Train Epoch: 92 [67584/225000 (30%)] Loss: 19539.285156\n",
      "Train Epoch: 92 [70080/225000 (31%)] Loss: 19586.906250\n",
      "Train Epoch: 92 [72576/225000 (32%)] Loss: 19316.011719\n",
      "Train Epoch: 92 [75072/225000 (33%)] Loss: 19174.261719\n",
      "Train Epoch: 92 [77568/225000 (34%)] Loss: 19081.958984\n",
      "Train Epoch: 92 [80064/225000 (36%)] Loss: 19753.429688\n",
      "Train Epoch: 92 [82560/225000 (37%)] Loss: 19729.324219\n",
      "Train Epoch: 92 [85056/225000 (38%)] Loss: 19212.714844\n",
      "Train Epoch: 92 [87552/225000 (39%)] Loss: 19826.226562\n",
      "Train Epoch: 92 [90048/225000 (40%)] Loss: 19411.728516\n",
      "Train Epoch: 92 [92544/225000 (41%)] Loss: 19403.425781\n",
      "Train Epoch: 92 [95040/225000 (42%)] Loss: 19990.017578\n",
      "Train Epoch: 92 [97536/225000 (43%)] Loss: 19832.589844\n",
      "Train Epoch: 92 [100032/225000 (44%)] Loss: 19098.921875\n",
      "Train Epoch: 92 [102528/225000 (46%)] Loss: 19697.605469\n",
      "Train Epoch: 92 [105024/225000 (47%)] Loss: 19403.839844\n",
      "Train Epoch: 92 [107520/225000 (48%)] Loss: 19467.367188\n",
      "Train Epoch: 92 [110016/225000 (49%)] Loss: 19459.787109\n",
      "Train Epoch: 92 [112512/225000 (50%)] Loss: 19827.320312\n",
      "Train Epoch: 92 [115008/225000 (51%)] Loss: 19672.746094\n",
      "Train Epoch: 92 [117504/225000 (52%)] Loss: 19733.242188\n",
      "Train Epoch: 92 [120000/225000 (53%)] Loss: 19843.203125\n",
      "Train Epoch: 92 [122496/225000 (54%)] Loss: 19436.417969\n",
      "Train Epoch: 92 [124992/225000 (56%)] Loss: 19801.593750\n",
      "Train Epoch: 92 [127488/225000 (57%)] Loss: 19880.523438\n",
      "Train Epoch: 92 [129984/225000 (58%)] Loss: 19741.093750\n",
      "Train Epoch: 92 [132480/225000 (59%)] Loss: 19182.406250\n",
      "Train Epoch: 92 [134976/225000 (60%)] Loss: 19459.972656\n",
      "Train Epoch: 92 [137472/225000 (61%)] Loss: 19916.609375\n",
      "Train Epoch: 92 [139968/225000 (62%)] Loss: 19240.785156\n",
      "Train Epoch: 92 [142464/225000 (63%)] Loss: 19968.980469\n",
      "Train Epoch: 92 [144960/225000 (64%)] Loss: 19117.218750\n",
      "Train Epoch: 92 [147456/225000 (66%)] Loss: 19588.054688\n",
      "Train Epoch: 92 [149952/225000 (67%)] Loss: 19943.828125\n",
      "Train Epoch: 92 [152448/225000 (68%)] Loss: 19195.214844\n",
      "Train Epoch: 92 [154944/225000 (69%)] Loss: 19480.296875\n",
      "Train Epoch: 92 [157440/225000 (70%)] Loss: 19467.574219\n",
      "Train Epoch: 92 [159936/225000 (71%)] Loss: 19822.687500\n",
      "Train Epoch: 92 [162432/225000 (72%)] Loss: 19474.296875\n",
      "Train Epoch: 92 [164928/225000 (73%)] Loss: 19353.238281\n",
      "Train Epoch: 92 [167424/225000 (74%)] Loss: 19520.761719\n",
      "Train Epoch: 92 [169920/225000 (76%)] Loss: 19691.132812\n",
      "Train Epoch: 92 [172416/225000 (77%)] Loss: 19763.599609\n",
      "Train Epoch: 92 [174912/225000 (78%)] Loss: 19218.884766\n",
      "Train Epoch: 92 [177408/225000 (79%)] Loss: 19023.441406\n",
      "Train Epoch: 92 [179904/225000 (80%)] Loss: 19203.248047\n",
      "Train Epoch: 92 [182400/225000 (81%)] Loss: 19474.695312\n",
      "Train Epoch: 92 [184896/225000 (82%)] Loss: 19097.656250\n",
      "Train Epoch: 92 [187392/225000 (83%)] Loss: 19341.154297\n",
      "Train Epoch: 92 [189888/225000 (84%)] Loss: 19140.332031\n",
      "Train Epoch: 92 [192384/225000 (86%)] Loss: 19693.292969\n",
      "Train Epoch: 92 [194880/225000 (87%)] Loss: 19545.972656\n",
      "Train Epoch: 92 [197376/225000 (88%)] Loss: 19233.978516\n",
      "Train Epoch: 92 [199872/225000 (89%)] Loss: 19612.265625\n",
      "Train Epoch: 92 [202368/225000 (90%)] Loss: 19448.396484\n",
      "Train Epoch: 92 [204864/225000 (91%)] Loss: 19726.847656\n",
      "Train Epoch: 92 [207360/225000 (92%)] Loss: 19888.695312\n",
      "Train Epoch: 92 [209856/225000 (93%)] Loss: 19050.998047\n",
      "Train Epoch: 92 [212352/225000 (94%)] Loss: 19418.386719\n",
      "Train Epoch: 92 [214848/225000 (95%)] Loss: 19221.039062\n",
      "Train Epoch: 92 [217344/225000 (97%)] Loss: 19741.484375\n",
      "Train Epoch: 92 [219840/225000 (98%)] Loss: 19720.000000\n",
      "Train Epoch: 92 [222336/225000 (99%)] Loss: 19986.042969\n",
      "Train Epoch: 92 [224832/225000 (100%)] Loss: 19481.667969\n",
      "    epoch          : 92\n",
      "    loss           : 19559.137425341298\n",
      "    val_loss       : 19470.220948577837\n",
      "Train Epoch: 93 [192/225000 (0%)] Loss: 19573.070312\n",
      "Train Epoch: 93 [2688/225000 (1%)] Loss: 19203.650391\n",
      "Train Epoch: 93 [5184/225000 (2%)] Loss: 18980.742188\n",
      "Train Epoch: 93 [7680/225000 (3%)] Loss: 19430.242188\n",
      "Train Epoch: 93 [10176/225000 (5%)] Loss: 19646.351562\n",
      "Train Epoch: 93 [12672/225000 (6%)] Loss: 19283.521484\n",
      "Train Epoch: 93 [15168/225000 (7%)] Loss: 19850.878906\n",
      "Train Epoch: 93 [17664/225000 (8%)] Loss: 19281.875000\n",
      "Train Epoch: 93 [20160/225000 (9%)] Loss: 19295.556641\n",
      "Train Epoch: 93 [22656/225000 (10%)] Loss: 19708.021484\n",
      "Train Epoch: 93 [25152/225000 (11%)] Loss: 19485.744141\n",
      "Train Epoch: 93 [27648/225000 (12%)] Loss: 19624.289062\n",
      "Train Epoch: 93 [30144/225000 (13%)] Loss: 19333.351562\n",
      "Train Epoch: 93 [32640/225000 (15%)] Loss: 19453.023438\n",
      "Train Epoch: 93 [35136/225000 (16%)] Loss: 19630.851562\n",
      "Train Epoch: 93 [37632/225000 (17%)] Loss: 19546.812500\n",
      "Train Epoch: 93 [40128/225000 (18%)] Loss: 19689.910156\n",
      "Train Epoch: 93 [42624/225000 (19%)] Loss: 20000.314453\n",
      "Train Epoch: 93 [45120/225000 (20%)] Loss: 18948.710938\n",
      "Train Epoch: 93 [47616/225000 (21%)] Loss: 19829.953125\n",
      "Train Epoch: 93 [50112/225000 (22%)] Loss: 20035.550781\n",
      "Train Epoch: 93 [52608/225000 (23%)] Loss: 19320.021484\n",
      "Train Epoch: 93 [55104/225000 (24%)] Loss: 20101.023438\n",
      "Train Epoch: 93 [57600/225000 (26%)] Loss: 19848.015625\n",
      "Train Epoch: 93 [60096/225000 (27%)] Loss: 19627.640625\n",
      "Train Epoch: 93 [62592/225000 (28%)] Loss: 19651.843750\n",
      "Train Epoch: 93 [65088/225000 (29%)] Loss: 19586.324219\n",
      "Train Epoch: 93 [67584/225000 (30%)] Loss: 19753.111328\n",
      "Train Epoch: 93 [70080/225000 (31%)] Loss: 19506.468750\n",
      "Train Epoch: 93 [72576/225000 (32%)] Loss: 19084.722656\n",
      "Train Epoch: 93 [75072/225000 (33%)] Loss: 19668.289062\n",
      "Train Epoch: 93 [77568/225000 (34%)] Loss: 19724.070312\n",
      "Train Epoch: 93 [80064/225000 (36%)] Loss: 19532.003906\n",
      "Train Epoch: 93 [82560/225000 (37%)] Loss: 19996.757812\n",
      "Train Epoch: 93 [85056/225000 (38%)] Loss: 19921.033203\n",
      "Train Epoch: 93 [87552/225000 (39%)] Loss: 19473.691406\n",
      "Train Epoch: 93 [90048/225000 (40%)] Loss: 19557.046875\n",
      "Train Epoch: 93 [92544/225000 (41%)] Loss: 19161.734375\n",
      "Train Epoch: 93 [95040/225000 (42%)] Loss: 19028.519531\n",
      "Train Epoch: 93 [97536/225000 (43%)] Loss: 19522.492188\n",
      "Train Epoch: 93 [100032/225000 (44%)] Loss: 19934.714844\n",
      "Train Epoch: 93 [102528/225000 (46%)] Loss: 19620.234375\n",
      "Train Epoch: 93 [105024/225000 (47%)] Loss: 19907.703125\n",
      "Train Epoch: 93 [107520/225000 (48%)] Loss: 19768.281250\n",
      "Train Epoch: 93 [110016/225000 (49%)] Loss: 19747.070312\n",
      "Train Epoch: 93 [112512/225000 (50%)] Loss: 19389.218750\n",
      "Train Epoch: 93 [115008/225000 (51%)] Loss: 19802.871094\n",
      "Train Epoch: 93 [117504/225000 (52%)] Loss: 19224.464844\n",
      "Train Epoch: 93 [120000/225000 (53%)] Loss: 19027.578125\n",
      "Train Epoch: 93 [122496/225000 (54%)] Loss: 19502.316406\n",
      "Train Epoch: 93 [124992/225000 (56%)] Loss: 19510.359375\n",
      "Train Epoch: 93 [127488/225000 (57%)] Loss: 19718.302734\n",
      "Train Epoch: 93 [129984/225000 (58%)] Loss: 19658.828125\n",
      "Train Epoch: 93 [132480/225000 (59%)] Loss: 19611.363281\n",
      "Train Epoch: 93 [134976/225000 (60%)] Loss: 19580.187500\n",
      "Train Epoch: 93 [137472/225000 (61%)] Loss: 19630.519531\n",
      "Train Epoch: 93 [139968/225000 (62%)] Loss: 19816.539062\n",
      "Train Epoch: 93 [142464/225000 (63%)] Loss: 19526.972656\n",
      "Train Epoch: 93 [144960/225000 (64%)] Loss: 19637.910156\n",
      "Train Epoch: 93 [147456/225000 (66%)] Loss: 19741.445312\n",
      "Train Epoch: 93 [149952/225000 (67%)] Loss: 19489.771484\n",
      "Train Epoch: 93 [152448/225000 (68%)] Loss: 19617.257812\n",
      "Train Epoch: 93 [154944/225000 (69%)] Loss: 19770.316406\n",
      "Train Epoch: 93 [157440/225000 (70%)] Loss: 19593.507812\n",
      "Train Epoch: 93 [159936/225000 (71%)] Loss: 18849.214844\n",
      "Train Epoch: 93 [162432/225000 (72%)] Loss: 19498.750000\n",
      "Train Epoch: 93 [164928/225000 (73%)] Loss: 19758.769531\n",
      "Train Epoch: 93 [167424/225000 (74%)] Loss: 19967.394531\n",
      "Train Epoch: 93 [169920/225000 (76%)] Loss: 19957.703125\n",
      "Train Epoch: 93 [172416/225000 (77%)] Loss: 19365.226562\n",
      "Train Epoch: 93 [174912/225000 (78%)] Loss: 19343.109375\n",
      "Train Epoch: 93 [177408/225000 (79%)] Loss: 19350.410156\n",
      "Train Epoch: 93 [179904/225000 (80%)] Loss: 19043.076172\n",
      "Train Epoch: 93 [182400/225000 (81%)] Loss: 19433.824219\n",
      "Train Epoch: 93 [184896/225000 (82%)] Loss: 19357.070312\n",
      "Train Epoch: 93 [187392/225000 (83%)] Loss: 19318.488281\n",
      "Train Epoch: 93 [189888/225000 (84%)] Loss: 19549.378906\n",
      "Train Epoch: 93 [192384/225000 (86%)] Loss: 19447.367188\n",
      "Train Epoch: 93 [194880/225000 (87%)] Loss: 19289.566406\n",
      "Train Epoch: 93 [197376/225000 (88%)] Loss: 19351.376953\n",
      "Train Epoch: 93 [199872/225000 (89%)] Loss: 19539.964844\n",
      "Train Epoch: 93 [202368/225000 (90%)] Loss: 19424.943359\n",
      "Train Epoch: 93 [204864/225000 (91%)] Loss: 19593.882812\n",
      "Train Epoch: 93 [207360/225000 (92%)] Loss: 19926.230469\n",
      "Train Epoch: 93 [209856/225000 (93%)] Loss: 19312.359375\n",
      "Train Epoch: 93 [212352/225000 (94%)] Loss: 20189.333984\n",
      "Train Epoch: 93 [214848/225000 (95%)] Loss: 19277.367188\n",
      "Train Epoch: 93 [217344/225000 (97%)] Loss: 19636.683594\n",
      "Train Epoch: 93 [219840/225000 (98%)] Loss: 19402.046875\n",
      "Train Epoch: 93 [222336/225000 (99%)] Loss: 19749.132812\n",
      "Train Epoch: 93 [224832/225000 (100%)] Loss: 19986.882812\n",
      "    epoch          : 93\n",
      "    loss           : 19549.839193819327\n",
      "    val_loss       : 19448.58067354901\n",
      "Train Epoch: 94 [192/225000 (0%)] Loss: 19834.421875\n",
      "Train Epoch: 94 [2688/225000 (1%)] Loss: 19685.822266\n",
      "Train Epoch: 94 [5184/225000 (2%)] Loss: 19495.078125\n",
      "Train Epoch: 94 [7680/225000 (3%)] Loss: 19562.843750\n",
      "Train Epoch: 94 [10176/225000 (5%)] Loss: 19573.527344\n",
      "Train Epoch: 94 [12672/225000 (6%)] Loss: 19417.929688\n",
      "Train Epoch: 94 [15168/225000 (7%)] Loss: 20018.791016\n",
      "Train Epoch: 94 [17664/225000 (8%)] Loss: 19362.355469\n",
      "Train Epoch: 94 [20160/225000 (9%)] Loss: 19313.695312\n",
      "Train Epoch: 94 [22656/225000 (10%)] Loss: 19631.255859\n",
      "Train Epoch: 94 [25152/225000 (11%)] Loss: 19486.457031\n",
      "Train Epoch: 94 [27648/225000 (12%)] Loss: 19670.050781\n",
      "Train Epoch: 94 [30144/225000 (13%)] Loss: 19634.359375\n",
      "Train Epoch: 94 [32640/225000 (15%)] Loss: 19561.199219\n",
      "Train Epoch: 94 [35136/225000 (16%)] Loss: 19684.734375\n",
      "Train Epoch: 94 [37632/225000 (17%)] Loss: 19293.714844\n",
      "Train Epoch: 94 [40128/225000 (18%)] Loss: 19534.824219\n",
      "Train Epoch: 94 [42624/225000 (19%)] Loss: 19406.878906\n",
      "Train Epoch: 94 [45120/225000 (20%)] Loss: 19414.042969\n",
      "Train Epoch: 94 [47616/225000 (21%)] Loss: 19893.472656\n",
      "Train Epoch: 94 [50112/225000 (22%)] Loss: 19926.656250\n",
      "Train Epoch: 94 [52608/225000 (23%)] Loss: 19325.371094\n",
      "Train Epoch: 94 [55104/225000 (24%)] Loss: 19511.384766\n",
      "Train Epoch: 94 [57600/225000 (26%)] Loss: 19169.988281\n",
      "Train Epoch: 94 [60096/225000 (27%)] Loss: 19798.265625\n",
      "Train Epoch: 94 [62592/225000 (28%)] Loss: 19477.449219\n",
      "Train Epoch: 94 [65088/225000 (29%)] Loss: 19479.123047\n",
      "Train Epoch: 94 [67584/225000 (30%)] Loss: 19567.341797\n",
      "Train Epoch: 94 [70080/225000 (31%)] Loss: 19785.150391\n",
      "Train Epoch: 94 [72576/225000 (32%)] Loss: 19871.613281\n",
      "Train Epoch: 94 [75072/225000 (33%)] Loss: 19590.595703\n",
      "Train Epoch: 94 [77568/225000 (34%)] Loss: 19095.923828\n",
      "Train Epoch: 94 [80064/225000 (36%)] Loss: 19268.312500\n",
      "Train Epoch: 94 [82560/225000 (37%)] Loss: 19781.121094\n",
      "Train Epoch: 94 [85056/225000 (38%)] Loss: 19570.482422\n",
      "Train Epoch: 94 [87552/225000 (39%)] Loss: 19493.265625\n",
      "Train Epoch: 94 [90048/225000 (40%)] Loss: 20029.255859\n",
      "Train Epoch: 94 [92544/225000 (41%)] Loss: 19394.919922\n",
      "Train Epoch: 94 [95040/225000 (42%)] Loss: 19654.367188\n",
      "Train Epoch: 94 [97536/225000 (43%)] Loss: 19495.703125\n",
      "Train Epoch: 94 [100032/225000 (44%)] Loss: 19604.919922\n",
      "Train Epoch: 94 [102528/225000 (46%)] Loss: 19731.941406\n",
      "Train Epoch: 94 [105024/225000 (47%)] Loss: 19376.527344\n",
      "Train Epoch: 94 [107520/225000 (48%)] Loss: 19666.738281\n",
      "Train Epoch: 94 [110016/225000 (49%)] Loss: 19222.839844\n",
      "Train Epoch: 94 [112512/225000 (50%)] Loss: 20035.417969\n",
      "Train Epoch: 94 [115008/225000 (51%)] Loss: 19391.726562\n",
      "Train Epoch: 94 [117504/225000 (52%)] Loss: 19605.757812\n",
      "Train Epoch: 94 [120000/225000 (53%)] Loss: 19833.300781\n",
      "Train Epoch: 94 [122496/225000 (54%)] Loss: 19514.421875\n",
      "Train Epoch: 94 [124992/225000 (56%)] Loss: 19398.058594\n",
      "Train Epoch: 94 [127488/225000 (57%)] Loss: 19267.123047\n",
      "Train Epoch: 94 [129984/225000 (58%)] Loss: 19445.585938\n",
      "Train Epoch: 94 [132480/225000 (59%)] Loss: 19759.320312\n",
      "Train Epoch: 94 [134976/225000 (60%)] Loss: 19743.386719\n",
      "Train Epoch: 94 [137472/225000 (61%)] Loss: 19016.376953\n",
      "Train Epoch: 94 [139968/225000 (62%)] Loss: 19667.320312\n",
      "Train Epoch: 94 [142464/225000 (63%)] Loss: 19605.998047\n",
      "Train Epoch: 94 [144960/225000 (64%)] Loss: 19833.082031\n",
      "Train Epoch: 94 [147456/225000 (66%)] Loss: 19739.769531\n",
      "Train Epoch: 94 [149952/225000 (67%)] Loss: 19470.880859\n",
      "Train Epoch: 94 [152448/225000 (68%)] Loss: 19479.234375\n",
      "Train Epoch: 94 [154944/225000 (69%)] Loss: 19265.609375\n",
      "Train Epoch: 94 [157440/225000 (70%)] Loss: 19349.023438\n",
      "Train Epoch: 94 [159936/225000 (71%)] Loss: 19130.558594\n",
      "Train Epoch: 94 [162432/225000 (72%)] Loss: 19674.716797\n",
      "Train Epoch: 94 [164928/225000 (73%)] Loss: 19392.185547\n",
      "Train Epoch: 94 [167424/225000 (74%)] Loss: 19479.412109\n",
      "Train Epoch: 94 [169920/225000 (76%)] Loss: 19718.597656\n",
      "Train Epoch: 94 [172416/225000 (77%)] Loss: 19760.304688\n",
      "Train Epoch: 94 [174912/225000 (78%)] Loss: 19991.152344\n",
      "Train Epoch: 94 [177408/225000 (79%)] Loss: 19209.310547\n",
      "Train Epoch: 94 [179904/225000 (80%)] Loss: 19564.605469\n",
      "Train Epoch: 94 [182400/225000 (81%)] Loss: 19101.093750\n",
      "Train Epoch: 94 [184896/225000 (82%)] Loss: 19998.074219\n",
      "Train Epoch: 94 [187392/225000 (83%)] Loss: 18996.789062\n",
      "Train Epoch: 94 [189888/225000 (84%)] Loss: 19161.695312\n",
      "Train Epoch: 94 [192384/225000 (86%)] Loss: 19507.019531\n",
      "Train Epoch: 94 [194880/225000 (87%)] Loss: 19206.101562\n",
      "Train Epoch: 94 [197376/225000 (88%)] Loss: 19618.308594\n",
      "Train Epoch: 94 [199872/225000 (89%)] Loss: 19101.214844\n",
      "Train Epoch: 94 [202368/225000 (90%)] Loss: 19576.871094\n",
      "Train Epoch: 94 [204864/225000 (91%)] Loss: 19815.128906\n",
      "Train Epoch: 94 [207360/225000 (92%)] Loss: 19292.558594\n",
      "Train Epoch: 94 [209856/225000 (93%)] Loss: 19703.955078\n",
      "Train Epoch: 94 [212352/225000 (94%)] Loss: 19717.982422\n",
      "Train Epoch: 94 [214848/225000 (95%)] Loss: 19792.058594\n",
      "Train Epoch: 94 [217344/225000 (97%)] Loss: 19580.785156\n",
      "Train Epoch: 94 [219840/225000 (98%)] Loss: 19536.916016\n",
      "Train Epoch: 94 [222336/225000 (99%)] Loss: 19215.656250\n",
      "Train Epoch: 94 [224832/225000 (100%)] Loss: 20095.000000\n",
      "    epoch          : 94\n",
      "    loss           : 19544.61091650224\n",
      "    val_loss       : 19510.66735934119\n",
      "Train Epoch: 95 [192/225000 (0%)] Loss: 20026.156250\n",
      "Train Epoch: 95 [2688/225000 (1%)] Loss: 19869.453125\n",
      "Train Epoch: 95 [5184/225000 (2%)] Loss: 19261.697266\n",
      "Train Epoch: 95 [7680/225000 (3%)] Loss: 19463.046875\n",
      "Train Epoch: 95 [10176/225000 (5%)] Loss: 20067.376953\n",
      "Train Epoch: 95 [12672/225000 (6%)] Loss: 19476.302734\n",
      "Train Epoch: 95 [15168/225000 (7%)] Loss: 20068.765625\n",
      "Train Epoch: 95 [17664/225000 (8%)] Loss: 19560.070312\n",
      "Train Epoch: 95 [20160/225000 (9%)] Loss: 19493.685547\n",
      "Train Epoch: 95 [22656/225000 (10%)] Loss: 19443.570312\n",
      "Train Epoch: 95 [25152/225000 (11%)] Loss: 19488.714844\n",
      "Train Epoch: 95 [27648/225000 (12%)] Loss: 19034.777344\n",
      "Train Epoch: 95 [30144/225000 (13%)] Loss: 19502.015625\n",
      "Train Epoch: 95 [32640/225000 (15%)] Loss: 19685.890625\n",
      "Train Epoch: 95 [35136/225000 (16%)] Loss: 19379.136719\n",
      "Train Epoch: 95 [37632/225000 (17%)] Loss: 19729.531250\n",
      "Train Epoch: 95 [40128/225000 (18%)] Loss: 19749.011719\n",
      "Train Epoch: 95 [42624/225000 (19%)] Loss: 19499.046875\n",
      "Train Epoch: 95 [45120/225000 (20%)] Loss: 19632.464844\n",
      "Train Epoch: 95 [47616/225000 (21%)] Loss: 19682.164062\n",
      "Train Epoch: 95 [50112/225000 (22%)] Loss: 19079.300781\n",
      "Train Epoch: 95 [52608/225000 (23%)] Loss: 19341.910156\n",
      "Train Epoch: 95 [55104/225000 (24%)] Loss: 19641.656250\n",
      "Train Epoch: 95 [57600/225000 (26%)] Loss: 19817.507812\n",
      "Train Epoch: 95 [60096/225000 (27%)] Loss: 19948.330078\n",
      "Train Epoch: 95 [62592/225000 (28%)] Loss: 19006.935547\n",
      "Train Epoch: 95 [65088/225000 (29%)] Loss: 19056.994141\n",
      "Train Epoch: 95 [67584/225000 (30%)] Loss: 19887.406250\n",
      "Train Epoch: 95 [70080/225000 (31%)] Loss: 19175.906250\n",
      "Train Epoch: 95 [72576/225000 (32%)] Loss: 19289.781250\n",
      "Train Epoch: 95 [75072/225000 (33%)] Loss: 19401.074219\n",
      "Train Epoch: 95 [77568/225000 (34%)] Loss: 19753.007812\n",
      "Train Epoch: 95 [80064/225000 (36%)] Loss: 19532.921875\n",
      "Train Epoch: 95 [82560/225000 (37%)] Loss: 19285.183594\n",
      "Train Epoch: 95 [85056/225000 (38%)] Loss: 19445.402344\n",
      "Train Epoch: 95 [87552/225000 (39%)] Loss: 19676.750000\n",
      "Train Epoch: 95 [90048/225000 (40%)] Loss: 19676.519531\n",
      "Train Epoch: 95 [92544/225000 (41%)] Loss: 19898.421875\n",
      "Train Epoch: 95 [95040/225000 (42%)] Loss: 19416.218750\n",
      "Train Epoch: 95 [97536/225000 (43%)] Loss: 19286.386719\n",
      "Train Epoch: 95 [100032/225000 (44%)] Loss: 19543.429688\n",
      "Train Epoch: 95 [102528/225000 (46%)] Loss: 19281.441406\n",
      "Train Epoch: 95 [105024/225000 (47%)] Loss: 19850.294922\n",
      "Train Epoch: 95 [107520/225000 (48%)] Loss: 19481.593750\n",
      "Train Epoch: 95 [110016/225000 (49%)] Loss: 19508.191406\n",
      "Train Epoch: 95 [112512/225000 (50%)] Loss: 19578.324219\n",
      "Train Epoch: 95 [115008/225000 (51%)] Loss: 20002.539062\n",
      "Train Epoch: 95 [117504/225000 (52%)] Loss: 19514.769531\n",
      "Train Epoch: 95 [120000/225000 (53%)] Loss: 19574.658203\n",
      "Train Epoch: 95 [122496/225000 (54%)] Loss: 19323.818359\n",
      "Train Epoch: 95 [124992/225000 (56%)] Loss: 19775.390625\n",
      "Train Epoch: 95 [127488/225000 (57%)] Loss: 19721.308594\n",
      "Train Epoch: 95 [129984/225000 (58%)] Loss: 19627.447266\n",
      "Train Epoch: 95 [132480/225000 (59%)] Loss: 19525.773438\n",
      "Train Epoch: 95 [134976/225000 (60%)] Loss: 19178.400391\n",
      "Train Epoch: 95 [137472/225000 (61%)] Loss: 19045.949219\n",
      "Train Epoch: 95 [139968/225000 (62%)] Loss: 19096.070312\n",
      "Train Epoch: 95 [142464/225000 (63%)] Loss: 20267.320312\n",
      "Train Epoch: 95 [144960/225000 (64%)] Loss: 19811.332031\n",
      "Train Epoch: 95 [147456/225000 (66%)] Loss: 19368.773438\n",
      "Train Epoch: 95 [149952/225000 (67%)] Loss: 19427.007812\n",
      "Train Epoch: 95 [152448/225000 (68%)] Loss: 19663.628906\n",
      "Train Epoch: 95 [154944/225000 (69%)] Loss: 19650.390625\n",
      "Train Epoch: 95 [157440/225000 (70%)] Loss: 19359.748047\n",
      "Train Epoch: 95 [159936/225000 (71%)] Loss: 19485.710938\n",
      "Train Epoch: 95 [162432/225000 (72%)] Loss: 19683.689453\n",
      "Train Epoch: 95 [164928/225000 (73%)] Loss: 19789.660156\n",
      "Train Epoch: 95 [167424/225000 (74%)] Loss: 20054.666016\n",
      "Train Epoch: 95 [169920/225000 (76%)] Loss: 19541.410156\n",
      "Train Epoch: 95 [172416/225000 (77%)] Loss: 19789.382812\n",
      "Train Epoch: 95 [174912/225000 (78%)] Loss: 19232.050781\n",
      "Train Epoch: 95 [177408/225000 (79%)] Loss: 19498.097656\n",
      "Train Epoch: 95 [179904/225000 (80%)] Loss: 19467.974609\n",
      "Train Epoch: 95 [182400/225000 (81%)] Loss: 20070.535156\n",
      "Train Epoch: 95 [184896/225000 (82%)] Loss: 19459.705078\n",
      "Train Epoch: 95 [187392/225000 (83%)] Loss: 19718.187500\n",
      "Train Epoch: 95 [189888/225000 (84%)] Loss: 19683.667969\n",
      "Train Epoch: 95 [192384/225000 (86%)] Loss: 19379.734375\n",
      "Train Epoch: 95 [194880/225000 (87%)] Loss: 19493.509766\n",
      "Train Epoch: 95 [197376/225000 (88%)] Loss: 19985.203125\n",
      "Train Epoch: 95 [199872/225000 (89%)] Loss: 19295.250000\n",
      "Train Epoch: 95 [202368/225000 (90%)] Loss: 19396.414062\n",
      "Train Epoch: 95 [204864/225000 (91%)] Loss: 19398.289062\n",
      "Train Epoch: 95 [207360/225000 (92%)] Loss: 19258.941406\n",
      "Train Epoch: 95 [209856/225000 (93%)] Loss: 19465.019531\n",
      "Train Epoch: 95 [212352/225000 (94%)] Loss: 19535.869141\n",
      "Train Epoch: 95 [214848/225000 (95%)] Loss: 19478.326172\n",
      "Train Epoch: 95 [217344/225000 (97%)] Loss: 19389.753906\n",
      "Train Epoch: 95 [219840/225000 (98%)] Loss: 19545.234375\n",
      "Train Epoch: 95 [222336/225000 (99%)] Loss: 19521.781250\n",
      "Train Epoch: 95 [224832/225000 (100%)] Loss: 19836.750000\n",
      "    epoch          : 95\n",
      "    loss           : 19535.296715017066\n",
      "    val_loss       : 19429.0050721578\n",
      "Train Epoch: 96 [192/225000 (0%)] Loss: 19516.763672\n",
      "Train Epoch: 96 [2688/225000 (1%)] Loss: 19563.373047\n",
      "Train Epoch: 96 [5184/225000 (2%)] Loss: 20086.660156\n",
      "Train Epoch: 96 [7680/225000 (3%)] Loss: 19341.593750\n",
      "Train Epoch: 96 [10176/225000 (5%)] Loss: 19156.734375\n",
      "Train Epoch: 96 [12672/225000 (6%)] Loss: 19434.292969\n",
      "Train Epoch: 96 [15168/225000 (7%)] Loss: 19462.996094\n",
      "Train Epoch: 96 [17664/225000 (8%)] Loss: 19409.937500\n",
      "Train Epoch: 96 [20160/225000 (9%)] Loss: 19521.636719\n",
      "Train Epoch: 96 [22656/225000 (10%)] Loss: 19768.507812\n",
      "Train Epoch: 96 [25152/225000 (11%)] Loss: 19817.140625\n",
      "Train Epoch: 96 [27648/225000 (12%)] Loss: 19134.798828\n",
      "Train Epoch: 96 [30144/225000 (13%)] Loss: 19311.949219\n",
      "Train Epoch: 96 [32640/225000 (15%)] Loss: 20000.345703\n",
      "Train Epoch: 96 [35136/225000 (16%)] Loss: 19382.480469\n",
      "Train Epoch: 96 [37632/225000 (17%)] Loss: 19561.847656\n",
      "Train Epoch: 96 [40128/225000 (18%)] Loss: 19236.244141\n",
      "Train Epoch: 96 [42624/225000 (19%)] Loss: 19666.337891\n",
      "Train Epoch: 96 [45120/225000 (20%)] Loss: 19504.085938\n",
      "Train Epoch: 96 [47616/225000 (21%)] Loss: 19614.119141\n",
      "Train Epoch: 96 [50112/225000 (22%)] Loss: 19506.304688\n",
      "Train Epoch: 96 [52608/225000 (23%)] Loss: 19431.417969\n",
      "Train Epoch: 96 [55104/225000 (24%)] Loss: 19801.568359\n",
      "Train Epoch: 96 [57600/225000 (26%)] Loss: 19684.751953\n",
      "Train Epoch: 96 [60096/225000 (27%)] Loss: 19683.003906\n",
      "Train Epoch: 96 [62592/225000 (28%)] Loss: 19568.523438\n",
      "Train Epoch: 96 [65088/225000 (29%)] Loss: 19560.125000\n",
      "Train Epoch: 96 [67584/225000 (30%)] Loss: 19549.242188\n",
      "Train Epoch: 96 [70080/225000 (31%)] Loss: 19794.894531\n",
      "Train Epoch: 96 [72576/225000 (32%)] Loss: 19116.523438\n",
      "Train Epoch: 96 [75072/225000 (33%)] Loss: 19701.839844\n",
      "Train Epoch: 96 [77568/225000 (34%)] Loss: 19507.687500\n",
      "Train Epoch: 96 [80064/225000 (36%)] Loss: 19601.050781\n",
      "Train Epoch: 96 [82560/225000 (37%)] Loss: 19267.529297\n",
      "Train Epoch: 96 [85056/225000 (38%)] Loss: 19417.412109\n",
      "Train Epoch: 96 [87552/225000 (39%)] Loss: 19835.412109\n",
      "Train Epoch: 96 [90048/225000 (40%)] Loss: 19642.527344\n",
      "Train Epoch: 96 [92544/225000 (41%)] Loss: 19733.042969\n",
      "Train Epoch: 96 [95040/225000 (42%)] Loss: 19641.070312\n",
      "Train Epoch: 96 [97536/225000 (43%)] Loss: 19471.523438\n",
      "Train Epoch: 96 [100032/225000 (44%)] Loss: 19427.761719\n",
      "Train Epoch: 96 [102528/225000 (46%)] Loss: 19845.484375\n",
      "Train Epoch: 96 [105024/225000 (47%)] Loss: 19516.808594\n",
      "Train Epoch: 96 [107520/225000 (48%)] Loss: 19620.677734\n",
      "Train Epoch: 96 [110016/225000 (49%)] Loss: 19314.730469\n",
      "Train Epoch: 96 [112512/225000 (50%)] Loss: 19087.150391\n",
      "Train Epoch: 96 [115008/225000 (51%)] Loss: 19418.763672\n",
      "Train Epoch: 96 [117504/225000 (52%)] Loss: 19764.937500\n",
      "Train Epoch: 96 [120000/225000 (53%)] Loss: 19816.818359\n",
      "Train Epoch: 96 [122496/225000 (54%)] Loss: 19317.496094\n",
      "Train Epoch: 96 [124992/225000 (56%)] Loss: 19077.410156\n",
      "Train Epoch: 96 [127488/225000 (57%)] Loss: 19300.011719\n",
      "Train Epoch: 96 [129984/225000 (58%)] Loss: 19570.023438\n",
      "Train Epoch: 96 [132480/225000 (59%)] Loss: 19349.777344\n",
      "Train Epoch: 96 [134976/225000 (60%)] Loss: 19545.832031\n",
      "Train Epoch: 96 [137472/225000 (61%)] Loss: 19706.105469\n",
      "Train Epoch: 96 [139968/225000 (62%)] Loss: 19142.986328\n",
      "Train Epoch: 96 [142464/225000 (63%)] Loss: 19677.171875\n",
      "Train Epoch: 96 [144960/225000 (64%)] Loss: 19620.435547\n",
      "Train Epoch: 96 [147456/225000 (66%)] Loss: 19457.820312\n",
      "Train Epoch: 96 [149952/225000 (67%)] Loss: 19766.394531\n",
      "Train Epoch: 96 [152448/225000 (68%)] Loss: 19637.552734\n",
      "Train Epoch: 96 [154944/225000 (69%)] Loss: 19425.031250\n",
      "Train Epoch: 96 [157440/225000 (70%)] Loss: 19197.919922\n",
      "Train Epoch: 96 [159936/225000 (71%)] Loss: 19742.210938\n",
      "Train Epoch: 96 [162432/225000 (72%)] Loss: 19378.960938\n",
      "Train Epoch: 96 [164928/225000 (73%)] Loss: 19726.046875\n",
      "Train Epoch: 96 [167424/225000 (74%)] Loss: 19426.320312\n",
      "Train Epoch: 96 [169920/225000 (76%)] Loss: 19417.283203\n",
      "Train Epoch: 96 [172416/225000 (77%)] Loss: 19140.986328\n",
      "Train Epoch: 96 [174912/225000 (78%)] Loss: 20053.648438\n",
      "Train Epoch: 96 [177408/225000 (79%)] Loss: 19410.601562\n",
      "Train Epoch: 96 [179904/225000 (80%)] Loss: 19510.626953\n",
      "Train Epoch: 96 [182400/225000 (81%)] Loss: 19530.011719\n",
      "Train Epoch: 96 [184896/225000 (82%)] Loss: 19248.220703\n",
      "Train Epoch: 96 [187392/225000 (83%)] Loss: 19806.228516\n",
      "Train Epoch: 96 [189888/225000 (84%)] Loss: 19606.546875\n",
      "Train Epoch: 96 [192384/225000 (86%)] Loss: 19431.246094\n",
      "Train Epoch: 96 [194880/225000 (87%)] Loss: 19893.318359\n",
      "Train Epoch: 96 [197376/225000 (88%)] Loss: 19731.189453\n",
      "Train Epoch: 96 [199872/225000 (89%)] Loss: 19152.927734\n",
      "Train Epoch: 96 [202368/225000 (90%)] Loss: 19193.699219\n",
      "Train Epoch: 96 [204864/225000 (91%)] Loss: 19548.527344\n",
      "Train Epoch: 96 [207360/225000 (92%)] Loss: 19294.519531\n",
      "Train Epoch: 96 [209856/225000 (93%)] Loss: 19789.652344\n",
      "Train Epoch: 96 [212352/225000 (94%)] Loss: 19541.810547\n",
      "Train Epoch: 96 [214848/225000 (95%)] Loss: 18928.818359\n",
      "Train Epoch: 96 [217344/225000 (97%)] Loss: 19536.130859\n",
      "Train Epoch: 96 [219840/225000 (98%)] Loss: 19359.023438\n",
      "Train Epoch: 96 [222336/225000 (99%)] Loss: 19349.710938\n",
      "Train Epoch: 96 [224832/225000 (100%)] Loss: 19605.101562\n",
      "    epoch          : 96\n",
      "    loss           : 19528.649344069967\n",
      "    val_loss       : 19443.82794223578\n",
      "Train Epoch: 97 [192/225000 (0%)] Loss: 19385.853516\n",
      "Train Epoch: 97 [2688/225000 (1%)] Loss: 19750.416016\n",
      "Train Epoch: 97 [5184/225000 (2%)] Loss: 19162.585938\n",
      "Train Epoch: 97 [7680/225000 (3%)] Loss: 19449.158203\n",
      "Train Epoch: 97 [10176/225000 (5%)] Loss: 19447.980469\n",
      "Train Epoch: 97 [12672/225000 (6%)] Loss: 19518.111328\n",
      "Train Epoch: 97 [15168/225000 (7%)] Loss: 19468.566406\n",
      "Train Epoch: 97 [17664/225000 (8%)] Loss: 19467.277344\n",
      "Train Epoch: 97 [20160/225000 (9%)] Loss: 19285.402344\n",
      "Train Epoch: 97 [22656/225000 (10%)] Loss: 19641.824219\n",
      "Train Epoch: 97 [25152/225000 (11%)] Loss: 19619.707031\n",
      "Train Epoch: 97 [27648/225000 (12%)] Loss: 19495.333984\n",
      "Train Epoch: 97 [30144/225000 (13%)] Loss: 19360.048828\n",
      "Train Epoch: 97 [32640/225000 (15%)] Loss: 19036.316406\n",
      "Train Epoch: 97 [35136/225000 (16%)] Loss: 19559.058594\n",
      "Train Epoch: 97 [37632/225000 (17%)] Loss: 19084.113281\n",
      "Train Epoch: 97 [40128/225000 (18%)] Loss: 19368.843750\n",
      "Train Epoch: 97 [42624/225000 (19%)] Loss: 19001.199219\n",
      "Train Epoch: 97 [45120/225000 (20%)] Loss: 19671.132812\n",
      "Train Epoch: 97 [47616/225000 (21%)] Loss: 19306.042969\n",
      "Train Epoch: 97 [50112/225000 (22%)] Loss: 19344.195312\n",
      "Train Epoch: 97 [52608/225000 (23%)] Loss: 19034.347656\n",
      "Train Epoch: 97 [55104/225000 (24%)] Loss: 19652.537109\n",
      "Train Epoch: 97 [57600/225000 (26%)] Loss: 19086.427734\n",
      "Train Epoch: 97 [60096/225000 (27%)] Loss: 19359.296875\n",
      "Train Epoch: 97 [62592/225000 (28%)] Loss: 19711.140625\n",
      "Train Epoch: 97 [65088/225000 (29%)] Loss: 19657.628906\n",
      "Train Epoch: 97 [67584/225000 (30%)] Loss: 19387.937500\n",
      "Train Epoch: 97 [70080/225000 (31%)] Loss: 19487.443359\n",
      "Train Epoch: 97 [72576/225000 (32%)] Loss: 19179.160156\n",
      "Train Epoch: 97 [75072/225000 (33%)] Loss: 19600.777344\n",
      "Train Epoch: 97 [77568/225000 (34%)] Loss: 19404.007812\n",
      "Train Epoch: 97 [80064/225000 (36%)] Loss: 18781.863281\n",
      "Train Epoch: 97 [82560/225000 (37%)] Loss: 18976.308594\n",
      "Train Epoch: 97 [85056/225000 (38%)] Loss: 19764.646484\n",
      "Train Epoch: 97 [87552/225000 (39%)] Loss: 19362.496094\n",
      "Train Epoch: 97 [90048/225000 (40%)] Loss: 19308.402344\n",
      "Train Epoch: 97 [92544/225000 (41%)] Loss: 19306.347656\n",
      "Train Epoch: 97 [95040/225000 (42%)] Loss: 19537.625000\n",
      "Train Epoch: 97 [97536/225000 (43%)] Loss: 19796.537109\n",
      "Train Epoch: 97 [100032/225000 (44%)] Loss: 19650.324219\n",
      "Train Epoch: 97 [102528/225000 (46%)] Loss: 19455.742188\n",
      "Train Epoch: 97 [105024/225000 (47%)] Loss: 19957.527344\n",
      "Train Epoch: 97 [107520/225000 (48%)] Loss: 19484.224609\n",
      "Train Epoch: 97 [110016/225000 (49%)] Loss: 19692.300781\n",
      "Train Epoch: 97 [112512/225000 (50%)] Loss: 19785.914062\n",
      "Train Epoch: 97 [115008/225000 (51%)] Loss: 19343.500000\n",
      "Train Epoch: 97 [117504/225000 (52%)] Loss: 19564.902344\n",
      "Train Epoch: 97 [120000/225000 (53%)] Loss: 19584.794922\n",
      "Train Epoch: 97 [122496/225000 (54%)] Loss: 19758.542969\n",
      "Train Epoch: 97 [124992/225000 (56%)] Loss: 19664.328125\n",
      "Train Epoch: 97 [127488/225000 (57%)] Loss: 19122.679688\n",
      "Train Epoch: 97 [129984/225000 (58%)] Loss: 19579.199219\n",
      "Train Epoch: 97 [132480/225000 (59%)] Loss: 19932.300781\n",
      "Train Epoch: 97 [134976/225000 (60%)] Loss: 19317.328125\n",
      "Train Epoch: 97 [137472/225000 (61%)] Loss: 19274.261719\n",
      "Train Epoch: 97 [139968/225000 (62%)] Loss: 19484.320312\n",
      "Train Epoch: 97 [142464/225000 (63%)] Loss: 19571.039062\n",
      "Train Epoch: 97 [144960/225000 (64%)] Loss: 19485.421875\n",
      "Train Epoch: 97 [147456/225000 (66%)] Loss: 19499.626953\n",
      "Train Epoch: 97 [149952/225000 (67%)] Loss: 20147.355469\n",
      "Train Epoch: 97 [152448/225000 (68%)] Loss: 19459.578125\n",
      "Train Epoch: 97 [154944/225000 (69%)] Loss: 19571.023438\n",
      "Train Epoch: 97 [157440/225000 (70%)] Loss: 19434.324219\n",
      "Train Epoch: 97 [159936/225000 (71%)] Loss: 19490.361328\n",
      "Train Epoch: 97 [162432/225000 (72%)] Loss: 19699.888672\n",
      "Train Epoch: 97 [164928/225000 (73%)] Loss: 19862.695312\n",
      "Train Epoch: 97 [167424/225000 (74%)] Loss: 19749.222656\n",
      "Train Epoch: 97 [169920/225000 (76%)] Loss: 19457.042969\n",
      "Train Epoch: 97 [172416/225000 (77%)] Loss: 19733.750000\n",
      "Train Epoch: 97 [174912/225000 (78%)] Loss: 19016.285156\n",
      "Train Epoch: 97 [177408/225000 (79%)] Loss: 19265.984375\n",
      "Train Epoch: 97 [179904/225000 (80%)] Loss: 19401.562500\n",
      "Train Epoch: 97 [182400/225000 (81%)] Loss: 19219.390625\n",
      "Train Epoch: 97 [184896/225000 (82%)] Loss: 19630.185547\n",
      "Train Epoch: 97 [187392/225000 (83%)] Loss: 19582.320312\n",
      "Train Epoch: 97 [189888/225000 (84%)] Loss: 19468.812500\n",
      "Train Epoch: 97 [192384/225000 (86%)] Loss: 19685.341797\n",
      "Train Epoch: 97 [194880/225000 (87%)] Loss: 19861.035156\n",
      "Train Epoch: 97 [197376/225000 (88%)] Loss: 19253.966797\n",
      "Train Epoch: 97 [199872/225000 (89%)] Loss: 19094.378906\n",
      "Train Epoch: 97 [202368/225000 (90%)] Loss: 19821.191406\n",
      "Train Epoch: 97 [204864/225000 (91%)] Loss: 20193.138672\n",
      "Train Epoch: 97 [207360/225000 (92%)] Loss: 19350.691406\n",
      "Train Epoch: 97 [209856/225000 (93%)] Loss: 19615.232422\n",
      "Train Epoch: 97 [212352/225000 (94%)] Loss: 19153.966797\n",
      "Train Epoch: 97 [214848/225000 (95%)] Loss: 19066.402344\n",
      "Train Epoch: 97 [217344/225000 (97%)] Loss: 19628.589844\n",
      "Train Epoch: 97 [219840/225000 (98%)] Loss: 19276.406250\n",
      "Train Epoch: 97 [222336/225000 (99%)] Loss: 19258.195312\n",
      "Train Epoch: 97 [224832/225000 (100%)] Loss: 19360.339844\n",
      "    epoch          : 97\n",
      "    loss           : 19516.722711244132\n",
      "    val_loss       : 19412.407438615806\n",
      "Train Epoch: 98 [192/225000 (0%)] Loss: 19165.921875\n",
      "Train Epoch: 98 [2688/225000 (1%)] Loss: 19373.101562\n",
      "Train Epoch: 98 [5184/225000 (2%)] Loss: 19378.363281\n",
      "Train Epoch: 98 [7680/225000 (3%)] Loss: 19754.576172\n",
      "Train Epoch: 98 [10176/225000 (5%)] Loss: 19346.968750\n",
      "Train Epoch: 98 [12672/225000 (6%)] Loss: 19121.640625\n",
      "Train Epoch: 98 [15168/225000 (7%)] Loss: 19258.292969\n",
      "Train Epoch: 98 [17664/225000 (8%)] Loss: 19217.974609\n",
      "Train Epoch: 98 [20160/225000 (9%)] Loss: 19832.960938\n",
      "Train Epoch: 98 [22656/225000 (10%)] Loss: 19522.914062\n",
      "Train Epoch: 98 [25152/225000 (11%)] Loss: 19479.316406\n",
      "Train Epoch: 98 [27648/225000 (12%)] Loss: 19123.025391\n",
      "Train Epoch: 98 [30144/225000 (13%)] Loss: 19631.296875\n",
      "Train Epoch: 98 [32640/225000 (15%)] Loss: 19379.851562\n",
      "Train Epoch: 98 [35136/225000 (16%)] Loss: 20008.394531\n",
      "Train Epoch: 98 [37632/225000 (17%)] Loss: 19355.587891\n",
      "Train Epoch: 98 [40128/225000 (18%)] Loss: 19327.742188\n",
      "Train Epoch: 98 [42624/225000 (19%)] Loss: 19349.636719\n",
      "Train Epoch: 98 [45120/225000 (20%)] Loss: 19604.957031\n",
      "Train Epoch: 98 [47616/225000 (21%)] Loss: 19423.156250\n",
      "Train Epoch: 98 [50112/225000 (22%)] Loss: 19939.160156\n",
      "Train Epoch: 98 [52608/225000 (23%)] Loss: 19559.324219\n",
      "Train Epoch: 98 [55104/225000 (24%)] Loss: 19156.472656\n",
      "Train Epoch: 98 [57600/225000 (26%)] Loss: 18804.738281\n",
      "Train Epoch: 98 [60096/225000 (27%)] Loss: 19807.537109\n",
      "Train Epoch: 98 [62592/225000 (28%)] Loss: 19698.804688\n",
      "Train Epoch: 98 [65088/225000 (29%)] Loss: 19570.093750\n",
      "Train Epoch: 98 [67584/225000 (30%)] Loss: 19436.019531\n",
      "Train Epoch: 98 [70080/225000 (31%)] Loss: 19441.625000\n",
      "Train Epoch: 98 [72576/225000 (32%)] Loss: 20115.269531\n",
      "Train Epoch: 98 [75072/225000 (33%)] Loss: 19636.109375\n",
      "Train Epoch: 98 [77568/225000 (34%)] Loss: 19181.027344\n",
      "Train Epoch: 98 [80064/225000 (36%)] Loss: 19602.828125\n",
      "Train Epoch: 98 [82560/225000 (37%)] Loss: 19382.281250\n",
      "Train Epoch: 98 [85056/225000 (38%)] Loss: 19821.761719\n",
      "Train Epoch: 98 [87552/225000 (39%)] Loss: 19773.279297\n",
      "Train Epoch: 98 [90048/225000 (40%)] Loss: 19377.453125\n",
      "Train Epoch: 98 [92544/225000 (41%)] Loss: 19244.753906\n",
      "Train Epoch: 98 [95040/225000 (42%)] Loss: 19531.183594\n",
      "Train Epoch: 98 [97536/225000 (43%)] Loss: 19199.199219\n",
      "Train Epoch: 98 [100032/225000 (44%)] Loss: 19428.369141\n",
      "Train Epoch: 98 [102528/225000 (46%)] Loss: 19078.734375\n",
      "Train Epoch: 98 [105024/225000 (47%)] Loss: 19362.070312\n",
      "Train Epoch: 98 [107520/225000 (48%)] Loss: 18865.035156\n",
      "Train Epoch: 98 [110016/225000 (49%)] Loss: 19267.755859\n",
      "Train Epoch: 98 [112512/225000 (50%)] Loss: 18481.757812\n",
      "Train Epoch: 98 [115008/225000 (51%)] Loss: 19268.367188\n",
      "Train Epoch: 98 [117504/225000 (52%)] Loss: 19460.251953\n",
      "Train Epoch: 98 [120000/225000 (53%)] Loss: 19728.466797\n",
      "Train Epoch: 98 [122496/225000 (54%)] Loss: 19778.642578\n",
      "Train Epoch: 98 [124992/225000 (56%)] Loss: 19662.015625\n",
      "Train Epoch: 98 [127488/225000 (57%)] Loss: 19771.371094\n",
      "Train Epoch: 98 [129984/225000 (58%)] Loss: 19883.285156\n",
      "Train Epoch: 98 [132480/225000 (59%)] Loss: 18827.853516\n",
      "Train Epoch: 98 [134976/225000 (60%)] Loss: 19436.417969\n",
      "Train Epoch: 98 [137472/225000 (61%)] Loss: 19685.617188\n",
      "Train Epoch: 98 [139968/225000 (62%)] Loss: 19594.058594\n",
      "Train Epoch: 98 [142464/225000 (63%)] Loss: 19232.585938\n",
      "Train Epoch: 98 [144960/225000 (64%)] Loss: 19160.839844\n",
      "Train Epoch: 98 [147456/225000 (66%)] Loss: 19756.628906\n",
      "Train Epoch: 98 [149952/225000 (67%)] Loss: 19400.128906\n",
      "Train Epoch: 98 [152448/225000 (68%)] Loss: 19493.195312\n",
      "Train Epoch: 98 [154944/225000 (69%)] Loss: 19686.222656\n",
      "Train Epoch: 98 [157440/225000 (70%)] Loss: 19744.523438\n",
      "Train Epoch: 98 [159936/225000 (71%)] Loss: 19464.277344\n",
      "Train Epoch: 98 [162432/225000 (72%)] Loss: 19819.902344\n",
      "Train Epoch: 98 [164928/225000 (73%)] Loss: 19441.769531\n",
      "Train Epoch: 98 [167424/225000 (74%)] Loss: 19352.308594\n",
      "Train Epoch: 98 [169920/225000 (76%)] Loss: 19351.601562\n",
      "Train Epoch: 98 [172416/225000 (77%)] Loss: 19626.453125\n",
      "Train Epoch: 98 [174912/225000 (78%)] Loss: 19471.503906\n",
      "Train Epoch: 98 [177408/225000 (79%)] Loss: 19388.095703\n",
      "Train Epoch: 98 [179904/225000 (80%)] Loss: 19440.472656\n",
      "Train Epoch: 98 [182400/225000 (81%)] Loss: 19387.265625\n",
      "Train Epoch: 98 [184896/225000 (82%)] Loss: 19376.792969\n",
      "Train Epoch: 98 [187392/225000 (83%)] Loss: 19623.890625\n",
      "Train Epoch: 98 [189888/225000 (84%)] Loss: 19225.664062\n",
      "Train Epoch: 98 [192384/225000 (86%)] Loss: 19646.398438\n",
      "Train Epoch: 98 [194880/225000 (87%)] Loss: 19693.843750\n",
      "Train Epoch: 98 [197376/225000 (88%)] Loss: 19715.361328\n",
      "Train Epoch: 98 [199872/225000 (89%)] Loss: 19632.882812\n",
      "Train Epoch: 98 [202368/225000 (90%)] Loss: 19499.357422\n",
      "Train Epoch: 98 [204864/225000 (91%)] Loss: 19426.285156\n",
      "Train Epoch: 98 [207360/225000 (92%)] Loss: 19481.050781\n",
      "Train Epoch: 98 [209856/225000 (93%)] Loss: 19476.000000\n",
      "Train Epoch: 98 [212352/225000 (94%)] Loss: 19601.976562\n",
      "Train Epoch: 98 [214848/225000 (95%)] Loss: 19355.835938\n",
      "Train Epoch: 98 [217344/225000 (97%)] Loss: 19203.601562\n",
      "Train Epoch: 98 [219840/225000 (98%)] Loss: 19747.296875\n",
      "Train Epoch: 98 [222336/225000 (99%)] Loss: 19453.107422\n",
      "Train Epoch: 98 [224832/225000 (100%)] Loss: 19247.978516\n",
      "    epoch          : 98\n",
      "    loss           : 19520.043865321033\n",
      "    val_loss       : 19409.7286094418\n",
      "Train Epoch: 99 [192/225000 (0%)] Loss: 19373.677734\n",
      "Train Epoch: 99 [2688/225000 (1%)] Loss: 19688.349609\n",
      "Train Epoch: 99 [5184/225000 (2%)] Loss: 19900.468750\n",
      "Train Epoch: 99 [7680/225000 (3%)] Loss: 19528.113281\n",
      "Train Epoch: 99 [10176/225000 (5%)] Loss: 19680.671875\n",
      "Train Epoch: 99 [12672/225000 (6%)] Loss: 19581.417969\n",
      "Train Epoch: 99 [15168/225000 (7%)] Loss: 19037.257812\n",
      "Train Epoch: 99 [17664/225000 (8%)] Loss: 19764.759766\n",
      "Train Epoch: 99 [20160/225000 (9%)] Loss: 20276.236328\n",
      "Train Epoch: 99 [22656/225000 (10%)] Loss: 19136.119141\n",
      "Train Epoch: 99 [25152/225000 (11%)] Loss: 19771.558594\n",
      "Train Epoch: 99 [27648/225000 (12%)] Loss: 19370.380859\n",
      "Train Epoch: 99 [30144/225000 (13%)] Loss: 18883.792969\n",
      "Train Epoch: 99 [32640/225000 (15%)] Loss: 19915.820312\n",
      "Train Epoch: 99 [35136/225000 (16%)] Loss: 19842.748047\n",
      "Train Epoch: 99 [37632/225000 (17%)] Loss: 19655.320312\n",
      "Train Epoch: 99 [40128/225000 (18%)] Loss: 19801.232422\n",
      "Train Epoch: 99 [42624/225000 (19%)] Loss: 19587.595703\n",
      "Train Epoch: 99 [45120/225000 (20%)] Loss: 18988.566406\n",
      "Train Epoch: 99 [47616/225000 (21%)] Loss: 19903.808594\n",
      "Train Epoch: 99 [50112/225000 (22%)] Loss: 19287.148438\n",
      "Train Epoch: 99 [52608/225000 (23%)] Loss: 19150.863281\n",
      "Train Epoch: 99 [55104/225000 (24%)] Loss: 20006.773438\n",
      "Train Epoch: 99 [57600/225000 (26%)] Loss: 20066.542969\n",
      "Train Epoch: 99 [60096/225000 (27%)] Loss: 19676.417969\n",
      "Train Epoch: 99 [62592/225000 (28%)] Loss: 19990.941406\n",
      "Train Epoch: 99 [65088/225000 (29%)] Loss: 19367.126953\n",
      "Train Epoch: 99 [67584/225000 (30%)] Loss: 19572.820312\n",
      "Train Epoch: 99 [70080/225000 (31%)] Loss: 19542.281250\n",
      "Train Epoch: 99 [72576/225000 (32%)] Loss: 19623.445312\n",
      "Train Epoch: 99 [75072/225000 (33%)] Loss: 19781.226562\n",
      "Train Epoch: 99 [77568/225000 (34%)] Loss: 19595.242188\n",
      "Train Epoch: 99 [80064/225000 (36%)] Loss: 20168.560547\n",
      "Train Epoch: 99 [82560/225000 (37%)] Loss: 19942.117188\n",
      "Train Epoch: 99 [85056/225000 (38%)] Loss: 19486.113281\n",
      "Train Epoch: 99 [87552/225000 (39%)] Loss: 19845.931641\n",
      "Train Epoch: 99 [90048/225000 (40%)] Loss: 19258.640625\n",
      "Train Epoch: 99 [92544/225000 (41%)] Loss: 20008.140625\n",
      "Train Epoch: 99 [95040/225000 (42%)] Loss: 19716.238281\n",
      "Train Epoch: 99 [97536/225000 (43%)] Loss: 18971.132812\n",
      "Train Epoch: 99 [100032/225000 (44%)] Loss: 19590.767578\n",
      "Train Epoch: 99 [102528/225000 (46%)] Loss: 19843.945312\n",
      "Train Epoch: 99 [105024/225000 (47%)] Loss: 19434.964844\n",
      "Train Epoch: 99 [107520/225000 (48%)] Loss: 19526.742188\n",
      "Train Epoch: 99 [110016/225000 (49%)] Loss: 19605.878906\n",
      "Train Epoch: 99 [112512/225000 (50%)] Loss: 19638.822266\n",
      "Train Epoch: 99 [115008/225000 (51%)] Loss: 19426.843750\n",
      "Train Epoch: 99 [117504/225000 (52%)] Loss: 19968.378906\n",
      "Train Epoch: 99 [120000/225000 (53%)] Loss: 19590.046875\n",
      "Train Epoch: 99 [122496/225000 (54%)] Loss: 19918.531250\n",
      "Train Epoch: 99 [124992/225000 (56%)] Loss: 19095.117188\n",
      "Train Epoch: 99 [127488/225000 (57%)] Loss: 19386.824219\n",
      "Train Epoch: 99 [129984/225000 (58%)] Loss: 19359.312500\n",
      "Train Epoch: 99 [132480/225000 (59%)] Loss: 19791.824219\n",
      "Train Epoch: 99 [134976/225000 (60%)] Loss: 19544.683594\n",
      "Train Epoch: 99 [137472/225000 (61%)] Loss: 19600.781250\n",
      "Train Epoch: 99 [139968/225000 (62%)] Loss: 19002.539062\n",
      "Train Epoch: 99 [142464/225000 (63%)] Loss: 19970.962891\n",
      "Train Epoch: 99 [144960/225000 (64%)] Loss: 18979.566406\n",
      "Train Epoch: 99 [147456/225000 (66%)] Loss: 19684.613281\n",
      "Train Epoch: 99 [149952/225000 (67%)] Loss: 20218.417969\n",
      "Train Epoch: 99 [152448/225000 (68%)] Loss: 19368.451172\n",
      "Train Epoch: 99 [154944/225000 (69%)] Loss: 19540.304688\n",
      "Train Epoch: 99 [157440/225000 (70%)] Loss: 19332.437500\n",
      "Train Epoch: 99 [159936/225000 (71%)] Loss: 19559.789062\n",
      "Train Epoch: 99 [162432/225000 (72%)] Loss: 19114.339844\n",
      "Train Epoch: 99 [164928/225000 (73%)] Loss: 19557.968750\n",
      "Train Epoch: 99 [167424/225000 (74%)] Loss: 19145.347656\n",
      "Train Epoch: 99 [169920/225000 (76%)] Loss: 19760.964844\n",
      "Train Epoch: 99 [172416/225000 (77%)] Loss: 19554.544922\n",
      "Train Epoch: 99 [174912/225000 (78%)] Loss: 19818.285156\n",
      "Train Epoch: 99 [177408/225000 (79%)] Loss: 19814.425781\n",
      "Train Epoch: 99 [179904/225000 (80%)] Loss: 19824.835938\n",
      "Train Epoch: 99 [182400/225000 (81%)] Loss: 19781.570312\n",
      "Train Epoch: 99 [184896/225000 (82%)] Loss: 19166.980469\n",
      "Train Epoch: 99 [187392/225000 (83%)] Loss: 19058.517578\n",
      "Train Epoch: 99 [189888/225000 (84%)] Loss: 19228.687500\n",
      "Train Epoch: 99 [192384/225000 (86%)] Loss: 19252.490234\n",
      "Train Epoch: 99 [194880/225000 (87%)] Loss: 19431.142578\n",
      "Train Epoch: 99 [197376/225000 (88%)] Loss: 19545.386719\n",
      "Train Epoch: 99 [199872/225000 (89%)] Loss: 19973.828125\n",
      "Train Epoch: 99 [202368/225000 (90%)] Loss: 19370.265625\n",
      "Train Epoch: 99 [204864/225000 (91%)] Loss: 19635.091797\n",
      "Train Epoch: 99 [207360/225000 (92%)] Loss: 19481.607422\n",
      "Train Epoch: 99 [209856/225000 (93%)] Loss: 20022.328125\n",
      "Train Epoch: 99 [212352/225000 (94%)] Loss: 20128.503906\n",
      "Train Epoch: 99 [214848/225000 (95%)] Loss: 19634.445312\n",
      "Train Epoch: 99 [217344/225000 (97%)] Loss: 19826.875000\n",
      "Train Epoch: 99 [219840/225000 (98%)] Loss: 19844.097656\n",
      "Train Epoch: 99 [222336/225000 (99%)] Loss: 19364.546875\n",
      "Train Epoch: 99 [224832/225000 (100%)] Loss: 19292.218750\n",
      "    epoch          : 99\n",
      "    loss           : 19504.862939619772\n",
      "    val_loss       : 19411.33794424552\n",
      "Train Epoch: 100 [192/225000 (0%)] Loss: 19240.906250\n",
      "Train Epoch: 100 [2688/225000 (1%)] Loss: 19211.369141\n",
      "Train Epoch: 100 [5184/225000 (2%)] Loss: 19946.859375\n",
      "Train Epoch: 100 [7680/225000 (3%)] Loss: 19665.564453\n",
      "Train Epoch: 100 [10176/225000 (5%)] Loss: 19430.906250\n",
      "Train Epoch: 100 [12672/225000 (6%)] Loss: 19498.531250\n",
      "Train Epoch: 100 [15168/225000 (7%)] Loss: 19194.312500\n",
      "Train Epoch: 100 [17664/225000 (8%)] Loss: 19321.378906\n",
      "Train Epoch: 100 [20160/225000 (9%)] Loss: 19617.486328\n",
      "Train Epoch: 100 [22656/225000 (10%)] Loss: 20149.066406\n",
      "Train Epoch: 100 [25152/225000 (11%)] Loss: 19594.996094\n",
      "Train Epoch: 100 [27648/225000 (12%)] Loss: 20091.261719\n",
      "Train Epoch: 100 [30144/225000 (13%)] Loss: 19774.841797\n",
      "Train Epoch: 100 [32640/225000 (15%)] Loss: 20188.820312\n",
      "Train Epoch: 100 [35136/225000 (16%)] Loss: 20188.919922\n",
      "Train Epoch: 100 [37632/225000 (17%)] Loss: 19217.255859\n",
      "Train Epoch: 100 [40128/225000 (18%)] Loss: 19608.296875\n",
      "Train Epoch: 100 [42624/225000 (19%)] Loss: 19467.712891\n",
      "Train Epoch: 100 [45120/225000 (20%)] Loss: 19343.279297\n",
      "Train Epoch: 100 [47616/225000 (21%)] Loss: 19031.316406\n",
      "Train Epoch: 100 [50112/225000 (22%)] Loss: 19045.070312\n",
      "Train Epoch: 100 [52608/225000 (23%)] Loss: 19660.447266\n",
      "Train Epoch: 100 [55104/225000 (24%)] Loss: 19134.011719\n",
      "Train Epoch: 100 [57600/225000 (26%)] Loss: 19962.271484\n",
      "Train Epoch: 100 [60096/225000 (27%)] Loss: 19246.458984\n",
      "Train Epoch: 100 [62592/225000 (28%)] Loss: 19098.546875\n",
      "Train Epoch: 100 [65088/225000 (29%)] Loss: 19671.949219\n",
      "Train Epoch: 100 [67584/225000 (30%)] Loss: 19653.412109\n",
      "Train Epoch: 100 [70080/225000 (31%)] Loss: 19344.199219\n",
      "Train Epoch: 100 [72576/225000 (32%)] Loss: 19899.210938\n",
      "Train Epoch: 100 [75072/225000 (33%)] Loss: 19840.960938\n",
      "Train Epoch: 100 [77568/225000 (34%)] Loss: 19461.328125\n",
      "Train Epoch: 100 [80064/225000 (36%)] Loss: 19421.476562\n",
      "Train Epoch: 100 [82560/225000 (37%)] Loss: 19081.050781\n",
      "Train Epoch: 100 [85056/225000 (38%)] Loss: 19569.412109\n",
      "Train Epoch: 100 [87552/225000 (39%)] Loss: 19468.105469\n",
      "Train Epoch: 100 [90048/225000 (40%)] Loss: 19340.042969\n",
      "Train Epoch: 100 [92544/225000 (41%)] Loss: 19468.187500\n",
      "Train Epoch: 100 [95040/225000 (42%)] Loss: 19714.421875\n",
      "Train Epoch: 100 [97536/225000 (43%)] Loss: 19733.468750\n",
      "Train Epoch: 100 [100032/225000 (44%)] Loss: 19398.546875\n",
      "Train Epoch: 100 [102528/225000 (46%)] Loss: 19898.861328\n",
      "Train Epoch: 100 [105024/225000 (47%)] Loss: 19705.478516\n",
      "Train Epoch: 100 [107520/225000 (48%)] Loss: 19578.970703\n",
      "Train Epoch: 100 [110016/225000 (49%)] Loss: 19668.675781\n",
      "Train Epoch: 100 [112512/225000 (50%)] Loss: 20037.171875\n",
      "Train Epoch: 100 [115008/225000 (51%)] Loss: 19434.373047\n",
      "Train Epoch: 100 [117504/225000 (52%)] Loss: 19311.337891\n",
      "Train Epoch: 100 [120000/225000 (53%)] Loss: 19613.744141\n",
      "Train Epoch: 100 [122496/225000 (54%)] Loss: 19516.253906\n",
      "Train Epoch: 100 [124992/225000 (56%)] Loss: 19823.843750\n",
      "Train Epoch: 100 [127488/225000 (57%)] Loss: 19539.375000\n",
      "Train Epoch: 100 [129984/225000 (58%)] Loss: 19631.714844\n",
      "Train Epoch: 100 [132480/225000 (59%)] Loss: 19102.078125\n",
      "Train Epoch: 100 [134976/225000 (60%)] Loss: 19011.410156\n",
      "Train Epoch: 100 [137472/225000 (61%)] Loss: 19765.640625\n",
      "Train Epoch: 100 [139968/225000 (62%)] Loss: 19943.246094\n",
      "Train Epoch: 100 [142464/225000 (63%)] Loss: 19083.183594\n",
      "Train Epoch: 100 [144960/225000 (64%)] Loss: 19277.787109\n",
      "Train Epoch: 100 [147456/225000 (66%)] Loss: 19376.093750\n",
      "Train Epoch: 100 [149952/225000 (67%)] Loss: 19539.863281\n",
      "Train Epoch: 100 [152448/225000 (68%)] Loss: 19486.382812\n",
      "Train Epoch: 100 [154944/225000 (69%)] Loss: 19899.832031\n",
      "Train Epoch: 100 [157440/225000 (70%)] Loss: 19511.283203\n",
      "Train Epoch: 100 [159936/225000 (71%)] Loss: 19802.914062\n",
      "Train Epoch: 100 [162432/225000 (72%)] Loss: 19411.916016\n",
      "Train Epoch: 100 [164928/225000 (73%)] Loss: 19800.695312\n",
      "Train Epoch: 100 [167424/225000 (74%)] Loss: 19550.488281\n",
      "Train Epoch: 100 [169920/225000 (76%)] Loss: 19493.068359\n",
      "Train Epoch: 100 [172416/225000 (77%)] Loss: 19416.394531\n",
      "Train Epoch: 100 [174912/225000 (78%)] Loss: 19490.398438\n",
      "Train Epoch: 100 [177408/225000 (79%)] Loss: 19345.794922\n",
      "Train Epoch: 100 [179904/225000 (80%)] Loss: 19488.261719\n",
      "Train Epoch: 100 [182400/225000 (81%)] Loss: 19199.433594\n",
      "Train Epoch: 100 [184896/225000 (82%)] Loss: 18821.605469\n",
      "Train Epoch: 100 [187392/225000 (83%)] Loss: 19421.523438\n",
      "Train Epoch: 100 [189888/225000 (84%)] Loss: 19210.712891\n",
      "Train Epoch: 100 [192384/225000 (86%)] Loss: 18839.384766\n",
      "Train Epoch: 100 [194880/225000 (87%)] Loss: 18711.996094\n",
      "Train Epoch: 100 [197376/225000 (88%)] Loss: 19132.126953\n",
      "Train Epoch: 100 [199872/225000 (89%)] Loss: 19695.097656\n",
      "Train Epoch: 100 [202368/225000 (90%)] Loss: 19814.613281\n",
      "Train Epoch: 100 [204864/225000 (91%)] Loss: 19350.035156\n",
      "Train Epoch: 100 [207360/225000 (92%)] Loss: 19484.388672\n",
      "Train Epoch: 100 [209856/225000 (93%)] Loss: 19325.986328\n",
      "Train Epoch: 100 [212352/225000 (94%)] Loss: 19067.287109\n",
      "Train Epoch: 100 [214848/225000 (95%)] Loss: 19713.566406\n",
      "Train Epoch: 100 [217344/225000 (97%)] Loss: 19527.246094\n",
      "Train Epoch: 100 [219840/225000 (98%)] Loss: 19398.656250\n",
      "Train Epoch: 100 [222336/225000 (99%)] Loss: 19434.796875\n",
      "Train Epoch: 100 [224832/225000 (100%)] Loss: 20035.662109\n",
      "    epoch          : 100\n",
      "    loss           : 19493.053155996695\n",
      "    val_loss       : 19406.047886959015\n",
      "Saving checkpoint: saved/models/Molecular_VaeCategory/0803_124018/checkpoint-epoch100.pth ...\n",
      "Saving current best: model_best.pth ...\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MolecularVaeCategoryModel(\n",
       "  (_category): FreeCategory(\n",
       "    (generator_0): MolecularDecoder(\n",
       "      (pre_recurrence_linear): Sequential(\n",
       "        (0): Linear(in_features=196, out_features=196, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (recurrence): GRU(196, 50, num_layers=3, batch_first=True)\n",
       "      (decoder): Sequential(\n",
       "        (0): Linear(in_features=50, out_features=34, bias=True)\n",
       "        (1): LogSoftmax(dim=-1)\n",
       "      )\n",
       "    )\n",
       "    (generator_0_dagger): ConvMolecularEncoder(\n",
       "      (smiles_conv): Sequential(\n",
       "        (0): Conv1d(120, 9, kernel_size=(9,), stride=(1,))\n",
       "        (1): ReLU()\n",
       "        (2): Conv1d(9, 9, kernel_size=(9,), stride=(1,))\n",
       "        (3): ReLU()\n",
       "        (4): Conv1d(9, 10, kernel_size=(11,), stride=(1,))\n",
       "        (5): ReLU()\n",
       "      )\n",
       "      (smiles_linear): Sequential(\n",
       "        (0): Linear(in_features=80, out_features=196, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (embedding_loc): Linear(in_features=196, out_features=196, bias=True)\n",
       "      (embedding_log_scale): Linear(in_features=196, out_features=196, bias=True)\n",
       "      (embedding_dist): DiagonalGaussian()\n",
       "    )\n",
       "    (generator_1): MolecularDecoder(\n",
       "      (pre_recurrence_linear): Sequential(\n",
       "        (0): Linear(in_features=196, out_features=196, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (recurrence): GRU(196, 50, num_layers=3, batch_first=True)\n",
       "      (decoder): Sequential(\n",
       "        (0): Linear(in_features=50, out_features=34, bias=True)\n",
       "        (1): LogSoftmax(dim=-1)\n",
       "      )\n",
       "    )\n",
       "    (generator_1_dagger): RecurrentMolecularEncoder(\n",
       "      (encoder_linear): Sequential(\n",
       "        (0): Linear(in_features=34, out_features=50, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (recurrence): GRU(50, 196, num_layers=3, batch_first=True)\n",
       "      (postrecurrence_linear): Sequential(\n",
       "        (0): Linear(in_features=196, out_features=196, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (embedding_loc): Linear(in_features=196, out_features=196, bias=True)\n",
       "      (embedding_log_scale): Linear(in_features=196, out_features=196, bias=True)\n",
       "      (embedding_dist): DiagonalGaussian()\n",
       "    )\n",
       "    (generator_2): MolecularDecoder(\n",
       "      (pre_recurrence_linear): Sequential(\n",
       "        (0): Linear(in_features=196, out_features=196, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (recurrence): GRU(196, 488, num_layers=3, batch_first=True)\n",
       "      (decoder): Sequential(\n",
       "        (0): Linear(in_features=488, out_features=34, bias=True)\n",
       "        (1): LogSoftmax(dim=-1)\n",
       "      )\n",
       "    )\n",
       "    (generator_2_dagger): ConvMolecularEncoder(\n",
       "      (smiles_conv): Sequential(\n",
       "        (0): Conv1d(120, 9, kernel_size=(9,), stride=(1,))\n",
       "        (1): ReLU()\n",
       "        (2): Conv1d(9, 9, kernel_size=(9,), stride=(1,))\n",
       "        (3): ReLU()\n",
       "        (4): Conv1d(9, 10, kernel_size=(11,), stride=(1,))\n",
       "        (5): ReLU()\n",
       "      )\n",
       "      (smiles_linear): Sequential(\n",
       "        (0): Linear(in_features=80, out_features=196, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (embedding_loc): Linear(in_features=196, out_features=196, bias=True)\n",
       "      (embedding_log_scale): Linear(in_features=196, out_features=196, bias=True)\n",
       "      (embedding_dist): DiagonalGaussian()\n",
       "    )\n",
       "    (generator_3): MolecularDecoder(\n",
       "      (pre_recurrence_linear): Sequential(\n",
       "        (0): Linear(in_features=196, out_features=196, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (recurrence): GRU(196, 488, num_layers=3, batch_first=True)\n",
       "      (decoder): Sequential(\n",
       "        (0): Linear(in_features=488, out_features=34, bias=True)\n",
       "        (1): LogSoftmax(dim=-1)\n",
       "      )\n",
       "    )\n",
       "    (generator_3_dagger): RecurrentMolecularEncoder(\n",
       "      (encoder_linear): Sequential(\n",
       "        (0): Linear(in_features=34, out_features=488, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (recurrence): GRU(488, 196, num_layers=3, batch_first=True)\n",
       "      (postrecurrence_linear): Sequential(\n",
       "        (0): Linear(in_features=196, out_features=196, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (embedding_loc): Linear(in_features=196, out_features=196, bias=True)\n",
       "      (embedding_log_scale): Linear(in_features=196, out_features=196, bias=True)\n",
       "      (embedding_dist): DiagonalGaussian()\n",
       "    )\n",
       "    (generator_4): MolecularDecoder(\n",
       "      (pre_recurrence_linear): Sequential(\n",
       "        (0): Linear(in_features=196, out_features=196, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (recurrence): GRU(196, 501, num_layers=3, batch_first=True)\n",
       "      (decoder): Sequential(\n",
       "        (0): Linear(in_features=501, out_features=34, bias=True)\n",
       "        (1): LogSoftmax(dim=-1)\n",
       "      )\n",
       "    )\n",
       "    (generator_4_dagger): ConvMolecularEncoder(\n",
       "      (smiles_conv): Sequential(\n",
       "        (0): Conv1d(120, 9, kernel_size=(9,), stride=(1,))\n",
       "        (1): ReLU()\n",
       "        (2): Conv1d(9, 9, kernel_size=(9,), stride=(1,))\n",
       "        (3): ReLU()\n",
       "        (4): Conv1d(9, 10, kernel_size=(11,), stride=(1,))\n",
       "        (5): ReLU()\n",
       "      )\n",
       "      (smiles_linear): Sequential(\n",
       "        (0): Linear(in_features=80, out_features=196, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (embedding_loc): Linear(in_features=196, out_features=196, bias=True)\n",
       "      (embedding_log_scale): Linear(in_features=196, out_features=196, bias=True)\n",
       "      (embedding_dist): DiagonalGaussian()\n",
       "    )\n",
       "    (generator_5): MolecularDecoder(\n",
       "      (pre_recurrence_linear): Sequential(\n",
       "        (0): Linear(in_features=196, out_features=196, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (recurrence): GRU(196, 501, num_layers=3, batch_first=True)\n",
       "      (decoder): Sequential(\n",
       "        (0): Linear(in_features=501, out_features=34, bias=True)\n",
       "        (1): LogSoftmax(dim=-1)\n",
       "      )\n",
       "    )\n",
       "    (generator_5_dagger): RecurrentMolecularEncoder(\n",
       "      (encoder_linear): Sequential(\n",
       "        (0): Linear(in_features=34, out_features=501, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (recurrence): GRU(501, 196, num_layers=3, batch_first=True)\n",
       "      (postrecurrence_linear): Sequential(\n",
       "        (0): Linear(in_features=196, out_features=196, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (embedding_loc): Linear(in_features=196, out_features=196, bias=True)\n",
       "      (embedding_log_scale): Linear(in_features=196, out_features=196, bias=True)\n",
       "      (embedding_dist): DiagonalGaussian()\n",
       "    )\n",
       "    (generator_6): MolecularDecoder(\n",
       "      (pre_recurrence_linear): Sequential(\n",
       "        (0): Linear(in_features=292, out_features=292, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (recurrence): GRU(292, 50, num_layers=3, batch_first=True)\n",
       "      (decoder): Sequential(\n",
       "        (0): Linear(in_features=50, out_features=34, bias=True)\n",
       "        (1): LogSoftmax(dim=-1)\n",
       "      )\n",
       "    )\n",
       "    (generator_6_dagger): ConvMolecularEncoder(\n",
       "      (smiles_conv): Sequential(\n",
       "        (0): Conv1d(120, 9, kernel_size=(9,), stride=(1,))\n",
       "        (1): ReLU()\n",
       "        (2): Conv1d(9, 9, kernel_size=(9,), stride=(1,))\n",
       "        (3): ReLU()\n",
       "        (4): Conv1d(9, 10, kernel_size=(11,), stride=(1,))\n",
       "        (5): ReLU()\n",
       "      )\n",
       "      (smiles_linear): Sequential(\n",
       "        (0): Linear(in_features=80, out_features=292, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (embedding_loc): Linear(in_features=292, out_features=292, bias=True)\n",
       "      (embedding_log_scale): Linear(in_features=292, out_features=292, bias=True)\n",
       "      (embedding_dist): DiagonalGaussian()\n",
       "    )\n",
       "    (generator_7): MolecularDecoder(\n",
       "      (pre_recurrence_linear): Sequential(\n",
       "        (0): Linear(in_features=292, out_features=292, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (recurrence): GRU(292, 50, num_layers=3, batch_first=True)\n",
       "      (decoder): Sequential(\n",
       "        (0): Linear(in_features=50, out_features=34, bias=True)\n",
       "        (1): LogSoftmax(dim=-1)\n",
       "      )\n",
       "    )\n",
       "    (generator_7_dagger): RecurrentMolecularEncoder(\n",
       "      (encoder_linear): Sequential(\n",
       "        (0): Linear(in_features=34, out_features=50, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (recurrence): GRU(50, 292, num_layers=3, batch_first=True)\n",
       "      (postrecurrence_linear): Sequential(\n",
       "        (0): Linear(in_features=292, out_features=292, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (embedding_loc): Linear(in_features=292, out_features=292, bias=True)\n",
       "      (embedding_log_scale): Linear(in_features=292, out_features=292, bias=True)\n",
       "      (embedding_dist): DiagonalGaussian()\n",
       "    )\n",
       "    (generator_8): MolecularDecoder(\n",
       "      (pre_recurrence_linear): Sequential(\n",
       "        (0): Linear(in_features=292, out_features=292, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (recurrence): GRU(292, 488, num_layers=3, batch_first=True)\n",
       "      (decoder): Sequential(\n",
       "        (0): Linear(in_features=488, out_features=34, bias=True)\n",
       "        (1): LogSoftmax(dim=-1)\n",
       "      )\n",
       "    )\n",
       "    (generator_8_dagger): ConvMolecularEncoder(\n",
       "      (smiles_conv): Sequential(\n",
       "        (0): Conv1d(120, 9, kernel_size=(9,), stride=(1,))\n",
       "        (1): ReLU()\n",
       "        (2): Conv1d(9, 9, kernel_size=(9,), stride=(1,))\n",
       "        (3): ReLU()\n",
       "        (4): Conv1d(9, 10, kernel_size=(11,), stride=(1,))\n",
       "        (5): ReLU()\n",
       "      )\n",
       "      (smiles_linear): Sequential(\n",
       "        (0): Linear(in_features=80, out_features=292, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (embedding_loc): Linear(in_features=292, out_features=292, bias=True)\n",
       "      (embedding_log_scale): Linear(in_features=292, out_features=292, bias=True)\n",
       "      (embedding_dist): DiagonalGaussian()\n",
       "    )\n",
       "    (generator_9): MolecularDecoder(\n",
       "      (pre_recurrence_linear): Sequential(\n",
       "        (0): Linear(in_features=292, out_features=292, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (recurrence): GRU(292, 488, num_layers=3, batch_first=True)\n",
       "      (decoder): Sequential(\n",
       "        (0): Linear(in_features=488, out_features=34, bias=True)\n",
       "        (1): LogSoftmax(dim=-1)\n",
       "      )\n",
       "    )\n",
       "    (generator_9_dagger): RecurrentMolecularEncoder(\n",
       "      (encoder_linear): Sequential(\n",
       "        (0): Linear(in_features=34, out_features=488, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (recurrence): GRU(488, 292, num_layers=3, batch_first=True)\n",
       "      (postrecurrence_linear): Sequential(\n",
       "        (0): Linear(in_features=292, out_features=292, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (embedding_loc): Linear(in_features=292, out_features=292, bias=True)\n",
       "      (embedding_log_scale): Linear(in_features=292, out_features=292, bias=True)\n",
       "      (embedding_dist): DiagonalGaussian()\n",
       "    )\n",
       "    (generator_10): MolecularDecoder(\n",
       "      (pre_recurrence_linear): Sequential(\n",
       "        (0): Linear(in_features=292, out_features=292, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (recurrence): GRU(292, 501, num_layers=3, batch_first=True)\n",
       "      (decoder): Sequential(\n",
       "        (0): Linear(in_features=501, out_features=34, bias=True)\n",
       "        (1): LogSoftmax(dim=-1)\n",
       "      )\n",
       "    )\n",
       "    (generator_10_dagger): ConvMolecularEncoder(\n",
       "      (smiles_conv): Sequential(\n",
       "        (0): Conv1d(120, 9, kernel_size=(9,), stride=(1,))\n",
       "        (1): ReLU()\n",
       "        (2): Conv1d(9, 9, kernel_size=(9,), stride=(1,))\n",
       "        (3): ReLU()\n",
       "        (4): Conv1d(9, 10, kernel_size=(11,), stride=(1,))\n",
       "        (5): ReLU()\n",
       "      )\n",
       "      (smiles_linear): Sequential(\n",
       "        (0): Linear(in_features=80, out_features=292, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (embedding_loc): Linear(in_features=292, out_features=292, bias=True)\n",
       "      (embedding_log_scale): Linear(in_features=292, out_features=292, bias=True)\n",
       "      (embedding_dist): DiagonalGaussian()\n",
       "    )\n",
       "    (generator_11): MolecularDecoder(\n",
       "      (pre_recurrence_linear): Sequential(\n",
       "        (0): Linear(in_features=292, out_features=292, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (recurrence): GRU(292, 501, num_layers=3, batch_first=True)\n",
       "      (decoder): Sequential(\n",
       "        (0): Linear(in_features=501, out_features=34, bias=True)\n",
       "        (1): LogSoftmax(dim=-1)\n",
       "      )\n",
       "    )\n",
       "    (generator_11_dagger): RecurrentMolecularEncoder(\n",
       "      (encoder_linear): Sequential(\n",
       "        (0): Linear(in_features=34, out_features=501, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (recurrence): GRU(501, 292, num_layers=3, batch_first=True)\n",
       "      (postrecurrence_linear): Sequential(\n",
       "        (0): Linear(in_features=292, out_features=292, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (embedding_loc): Linear(in_features=292, out_features=292, bias=True)\n",
       "      (embedding_log_scale): Linear(in_features=292, out_features=292, bias=True)\n",
       "      (embedding_dist): DiagonalGaussian()\n",
       "    )\n",
       "    (generator_12): MolecularDecoder(\n",
       "      (pre_recurrence_linear): Sequential(\n",
       "        (0): Linear(in_features=435, out_features=435, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (recurrence): GRU(435, 50, num_layers=3, batch_first=True)\n",
       "      (decoder): Sequential(\n",
       "        (0): Linear(in_features=50, out_features=34, bias=True)\n",
       "        (1): LogSoftmax(dim=-1)\n",
       "      )\n",
       "    )\n",
       "    (generator_12_dagger): ConvMolecularEncoder(\n",
       "      (smiles_conv): Sequential(\n",
       "        (0): Conv1d(120, 9, kernel_size=(9,), stride=(1,))\n",
       "        (1): ReLU()\n",
       "        (2): Conv1d(9, 9, kernel_size=(9,), stride=(1,))\n",
       "        (3): ReLU()\n",
       "        (4): Conv1d(9, 10, kernel_size=(11,), stride=(1,))\n",
       "        (5): ReLU()\n",
       "      )\n",
       "      (smiles_linear): Sequential(\n",
       "        (0): Linear(in_features=80, out_features=435, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (embedding_loc): Linear(in_features=435, out_features=435, bias=True)\n",
       "      (embedding_log_scale): Linear(in_features=435, out_features=435, bias=True)\n",
       "      (embedding_dist): DiagonalGaussian()\n",
       "    )\n",
       "    (generator_13): MolecularDecoder(\n",
       "      (pre_recurrence_linear): Sequential(\n",
       "        (0): Linear(in_features=435, out_features=435, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (recurrence): GRU(435, 50, num_layers=3, batch_first=True)\n",
       "      (decoder): Sequential(\n",
       "        (0): Linear(in_features=50, out_features=34, bias=True)\n",
       "        (1): LogSoftmax(dim=-1)\n",
       "      )\n",
       "    )\n",
       "    (generator_13_dagger): RecurrentMolecularEncoder(\n",
       "      (encoder_linear): Sequential(\n",
       "        (0): Linear(in_features=34, out_features=50, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (recurrence): GRU(50, 435, num_layers=3, batch_first=True)\n",
       "      (postrecurrence_linear): Sequential(\n",
       "        (0): Linear(in_features=435, out_features=435, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (embedding_loc): Linear(in_features=435, out_features=435, bias=True)\n",
       "      (embedding_log_scale): Linear(in_features=435, out_features=435, bias=True)\n",
       "      (embedding_dist): DiagonalGaussian()\n",
       "    )\n",
       "    (generator_14): MolecularDecoder(\n",
       "      (pre_recurrence_linear): Sequential(\n",
       "        (0): Linear(in_features=435, out_features=435, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (recurrence): GRU(435, 488, num_layers=3, batch_first=True)\n",
       "      (decoder): Sequential(\n",
       "        (0): Linear(in_features=488, out_features=34, bias=True)\n",
       "        (1): LogSoftmax(dim=-1)\n",
       "      )\n",
       "    )\n",
       "    (generator_14_dagger): ConvMolecularEncoder(\n",
       "      (smiles_conv): Sequential(\n",
       "        (0): Conv1d(120, 9, kernel_size=(9,), stride=(1,))\n",
       "        (1): ReLU()\n",
       "        (2): Conv1d(9, 9, kernel_size=(9,), stride=(1,))\n",
       "        (3): ReLU()\n",
       "        (4): Conv1d(9, 10, kernel_size=(11,), stride=(1,))\n",
       "        (5): ReLU()\n",
       "      )\n",
       "      (smiles_linear): Sequential(\n",
       "        (0): Linear(in_features=80, out_features=435, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (embedding_loc): Linear(in_features=435, out_features=435, bias=True)\n",
       "      (embedding_log_scale): Linear(in_features=435, out_features=435, bias=True)\n",
       "      (embedding_dist): DiagonalGaussian()\n",
       "    )\n",
       "    (generator_15): MolecularDecoder(\n",
       "      (pre_recurrence_linear): Sequential(\n",
       "        (0): Linear(in_features=435, out_features=435, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (recurrence): GRU(435, 488, num_layers=3, batch_first=True)\n",
       "      (decoder): Sequential(\n",
       "        (0): Linear(in_features=488, out_features=34, bias=True)\n",
       "        (1): LogSoftmax(dim=-1)\n",
       "      )\n",
       "    )\n",
       "    (generator_15_dagger): RecurrentMolecularEncoder(\n",
       "      (encoder_linear): Sequential(\n",
       "        (0): Linear(in_features=34, out_features=488, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (recurrence): GRU(488, 435, num_layers=3, batch_first=True)\n",
       "      (postrecurrence_linear): Sequential(\n",
       "        (0): Linear(in_features=435, out_features=435, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (embedding_loc): Linear(in_features=435, out_features=435, bias=True)\n",
       "      (embedding_log_scale): Linear(in_features=435, out_features=435, bias=True)\n",
       "      (embedding_dist): DiagonalGaussian()\n",
       "    )\n",
       "    (generator_16): MolecularDecoder(\n",
       "      (pre_recurrence_linear): Sequential(\n",
       "        (0): Linear(in_features=435, out_features=435, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (recurrence): GRU(435, 501, num_layers=3, batch_first=True)\n",
       "      (decoder): Sequential(\n",
       "        (0): Linear(in_features=501, out_features=34, bias=True)\n",
       "        (1): LogSoftmax(dim=-1)\n",
       "      )\n",
       "    )\n",
       "    (generator_16_dagger): ConvMolecularEncoder(\n",
       "      (smiles_conv): Sequential(\n",
       "        (0): Conv1d(120, 9, kernel_size=(9,), stride=(1,))\n",
       "        (1): ReLU()\n",
       "        (2): Conv1d(9, 9, kernel_size=(9,), stride=(1,))\n",
       "        (3): ReLU()\n",
       "        (4): Conv1d(9, 10, kernel_size=(11,), stride=(1,))\n",
       "        (5): ReLU()\n",
       "      )\n",
       "      (smiles_linear): Sequential(\n",
       "        (0): Linear(in_features=80, out_features=435, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (embedding_loc): Linear(in_features=435, out_features=435, bias=True)\n",
       "      (embedding_log_scale): Linear(in_features=435, out_features=435, bias=True)\n",
       "      (embedding_dist): DiagonalGaussian()\n",
       "    )\n",
       "    (generator_17): MolecularDecoder(\n",
       "      (pre_recurrence_linear): Sequential(\n",
       "        (0): Linear(in_features=435, out_features=435, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (recurrence): GRU(435, 501, num_layers=3, batch_first=True)\n",
       "      (decoder): Sequential(\n",
       "        (0): Linear(in_features=501, out_features=34, bias=True)\n",
       "        (1): LogSoftmax(dim=-1)\n",
       "      )\n",
       "    )\n",
       "    (generator_17_dagger): RecurrentMolecularEncoder(\n",
       "      (encoder_linear): Sequential(\n",
       "        (0): Linear(in_features=34, out_features=501, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (recurrence): GRU(501, 435, num_layers=3, batch_first=True)\n",
       "      (postrecurrence_linear): Sequential(\n",
       "        (0): Linear(in_features=435, out_features=435, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (embedding_loc): Linear(in_features=435, out_features=435, bias=True)\n",
       "      (embedding_log_scale): Linear(in_features=435, out_features=435, bias=True)\n",
       "      (embedding_dist): DiagonalGaussian()\n",
       "    )\n",
       "    (global_element_0): StandardNormal()\n",
       "    (global_element_1): StandardNormal()\n",
       "    (global_element_2): StandardNormal()\n",
       "    (global_element_3): StandardNormal()\n",
       "  )\n",
       "  (guide_temperatures): Sequential(\n",
       "    (0): Linear(in_features=4080, out_features=256, bias=True)\n",
       "    (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    (2): PReLU(num_parameters=1)\n",
       "    (3): Linear(in_features=256, out_features=2, bias=True)\n",
       "    (4): Softplus(beta=1, threshold=20)\n",
       "  )\n",
       "  (guide_arrow_weights): Sequential(\n",
       "    (0): Linear(in_features=4080, out_features=256, bias=True)\n",
       "    (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    (2): PReLU(num_parameters=1)\n",
       "    (3): Linear(in_features=256, out_features=44, bias=True)\n",
       "    (4): Softplus(beta=1, threshold=20)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_xs, valid_ys = list(valid_data_loader)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "m, recons = model(observations=valid_xs, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7010)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(recons == valid_xs).all(dim=-1).flatten().to(dtype=torch.float).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:categorical_bpl] *",
   "language": "python",
   "name": "conda-env-categorical_bpl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
