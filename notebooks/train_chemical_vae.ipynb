{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/eli/AnacondaProjects/categorical_bpl\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import collections\n",
    "import pyro\n",
    "import torch\n",
    "import numpy as np\n",
    "import data_loader.data_loaders as module_data\n",
    "import model.model as module_arch\n",
    "from parse_config import ConfigParser\n",
    "from trainer import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyro.enable_validation(True)\n",
    "# torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seeds for reproducibility\n",
    "SEED = 123\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Args = collections.namedtuple('Args', 'config resume device')\n",
    "config = ConfigParser.from_args(Args(config='chemical_config.json', resume=None, device=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = config.get_logger('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup data_loader instances\n",
    "data_loader = config.init_obj('data_loader', module_data)\n",
    "valid_data_loader = data_loader.split_validation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model architecture, then print to console\n",
    "model = config.init_obj('arch', module_arch, len(data_loader.dataset.alphabet), data_loader.dataset.max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = pyro.optim.ReduceLROnPlateau({\n",
    "    'optimizer': torch.optim.Adam,\n",
    "    'optim_args': {\n",
    "        \"lr\": 1e-3,\n",
    "        \"weight_decay\": 0,\n",
    "        \"amsgrad\": True\n",
    "    },\n",
    "    \"patience\": 500,\n",
    "    \"factor\": 0.1,\n",
    "    \"verbose\": True,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = config.init_obj('optimizer', pyro.optim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model, [], optimizer, config=config,\n",
    "                  data_loader=data_loader,\n",
    "                  valid_data_loader=valid_data_loader,\n",
    "                  lr_scheduler=optimizer, log_images=False, log_step=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [256/118836 (0%)] Loss: 15535.135742\n",
      "Train Epoch: 1 [33024/118836 (28%)] Loss: 13563.041992\n",
      "Train Epoch: 1 [65792/118836 (55%)] Loss: 13118.084961\n",
      "Train Epoch: 1 [98560/118836 (83%)] Loss: 12886.484375\n",
      "    epoch          : 1\n",
      "    loss           : 13418.745990681864\n",
      "    val_loss       : 12718.411792219049\n",
      "    val_log_likelihood: -12618.686537653795\n",
      "    val_log_marginal: -12650.827778787123\n",
      "Train Epoch: 2 [256/118836 (0%)] Loss: 12673.580078\n",
      "Train Epoch: 2 [33024/118836 (28%)] Loss: 12660.777344\n",
      "Train Epoch: 2 [65792/118836 (55%)] Loss: 12710.605469\n",
      "Train Epoch: 2 [98560/118836 (83%)] Loss: 12652.155273\n",
      "    epoch          : 2\n",
      "    loss           : 12646.914833572424\n",
      "    val_loss       : 12624.462029577533\n",
      "    val_log_likelihood: -12579.842377804489\n",
      "    val_log_marginal: -12604.848000515178\n",
      "Train Epoch: 3 [256/118836 (0%)] Loss: 12658.320312\n",
      "Train Epoch: 3 [33024/118836 (28%)] Loss: 12622.830078\n",
      "Train Epoch: 3 [65792/118836 (55%)] Loss: 12603.634766\n",
      "Train Epoch: 3 [98560/118836 (83%)] Loss: 12597.532227\n",
      "    epoch          : 3\n",
      "    loss           : 12601.996177916926\n",
      "    val_loss       : 12597.795398216438\n",
      "    val_log_likelihood: -12570.41093329973\n",
      "    val_log_marginal: -12587.031005963363\n",
      "Train Epoch: 4 [256/118836 (0%)] Loss: 12626.812500\n",
      "Train Epoch: 4 [33024/118836 (28%)] Loss: 12655.790039\n",
      "Train Epoch: 4 [65792/118836 (55%)] Loss: 12619.391602\n",
      "Train Epoch: 4 [98560/118836 (83%)] Loss: 12607.807617\n",
      "    epoch          : 4\n",
      "    loss           : 12589.571507961125\n",
      "    val_loss       : 12586.704332123823\n",
      "    val_log_likelihood: -12566.672066919975\n",
      "    val_log_marginal: -12579.676780043637\n",
      "Train Epoch: 5 [256/118836 (0%)] Loss: 12633.724609\n",
      "Train Epoch: 5 [33024/118836 (28%)] Loss: 12660.907227\n",
      "Train Epoch: 5 [65792/118836 (55%)] Loss: 12626.052734\n",
      "Train Epoch: 5 [98560/118836 (83%)] Loss: 12631.189453\n",
      "    epoch          : 5\n",
      "    loss           : 12583.912012607268\n",
      "    val_loss       : 12581.685472945263\n",
      "    val_log_likelihood: -12565.249053647125\n",
      "    val_log_marginal: -12576.256063537705\n",
      "Train Epoch: 6 [256/118836 (0%)] Loss: 12580.491211\n",
      "Train Epoch: 6 [33024/118836 (28%)] Loss: 12603.118164\n",
      "Train Epoch: 6 [65792/118836 (55%)] Loss: 12622.938477\n",
      "Train Epoch: 6 [98560/118836 (83%)] Loss: 12565.015625\n",
      "    epoch          : 6\n",
      "    loss           : 12579.288262671887\n",
      "    val_loss       : 12577.863366634836\n",
      "    val_log_likelihood: -12564.574400169302\n",
      "    val_log_marginal: -12574.525118565887\n",
      "Train Epoch: 7 [256/118836 (0%)] Loss: 12576.500000\n",
      "Train Epoch: 7 [33024/118836 (28%)] Loss: 12621.142578\n",
      "Train Epoch: 7 [65792/118836 (55%)] Loss: 12554.373047\n",
      "Train Epoch: 7 [98560/118836 (83%)] Loss: 12604.125977\n",
      "    epoch          : 7\n",
      "    loss           : 12576.918913164289\n",
      "    val_loss       : 12578.482718305338\n",
      "    val_log_likelihood: -12564.414621943495\n",
      "    val_log_marginal: -12572.94508660908\n",
      "Train Epoch: 8 [256/118836 (0%)] Loss: 12532.810547\n",
      "Train Epoch: 8 [33024/118836 (28%)] Loss: 12635.342773\n",
      "Train Epoch: 8 [65792/118836 (55%)] Loss: 12614.140625\n",
      "Train Epoch: 8 [98560/118836 (83%)] Loss: 12613.689453\n",
      "    epoch          : 8\n",
      "    loss           : 12577.432775666874\n",
      "    val_loss       : 12577.35345144807\n",
      "    val_log_likelihood: -12564.814877029054\n",
      "    val_log_marginal: -12572.888160064242\n",
      "Train Epoch: 9 [256/118836 (0%)] Loss: 12566.771484\n",
      "Train Epoch: 9 [33024/118836 (28%)] Loss: 12591.110352\n",
      "Train Epoch: 9 [65792/118836 (55%)] Loss: 12639.455078\n",
      "Train Epoch: 9 [98560/118836 (83%)] Loss: 12549.063477\n",
      "    epoch          : 9\n",
      "    loss           : 12577.342424492092\n",
      "    val_loss       : 12576.894697667158\n",
      "    val_log_likelihood: -12564.838843439826\n",
      "    val_log_marginal: -12572.495183693542\n",
      "Train Epoch: 10 [256/118836 (0%)] Loss: 12641.734375\n",
      "Train Epoch: 10 [33024/118836 (28%)] Loss: 12618.191406\n",
      "Train Epoch: 10 [65792/118836 (55%)] Loss: 12599.734375\n",
      "Train Epoch: 10 [98560/118836 (83%)] Loss: 12596.083008\n",
      "    epoch          : 10\n",
      "    loss           : 12573.607574700165\n",
      "    val_loss       : 12572.549739813234\n",
      "    val_log_likelihood: -12563.697309404726\n",
      "    val_log_marginal: -12570.5384970658\n",
      "Train Epoch: 11 [256/118836 (0%)] Loss: 12586.051758\n",
      "Train Epoch: 11 [33024/118836 (28%)] Loss: 12621.141602\n",
      "Train Epoch: 11 [65792/118836 (55%)] Loss: 12596.248047\n",
      "Train Epoch: 11 [98560/118836 (83%)] Loss: 12582.415039\n",
      "    epoch          : 11\n",
      "    loss           : 12572.570604257133\n",
      "    val_loss       : 12572.188481770278\n",
      "    val_log_likelihood: -12563.714196747052\n",
      "    val_log_marginal: -12570.239508120025\n",
      "Train Epoch: 12 [256/118836 (0%)] Loss: 12584.359375\n",
      "Train Epoch: 12 [33024/118836 (28%)] Loss: 12561.737305\n",
      "Train Epoch: 12 [65792/118836 (55%)] Loss: 12611.595703\n",
      "Train Epoch: 12 [98560/118836 (83%)] Loss: 12636.261719\n",
      "    epoch          : 12\n",
      "    loss           : 12572.183306677782\n",
      "    val_loss       : 12571.095084496154\n",
      "    val_log_likelihood: -12563.54143710582\n",
      "    val_log_marginal: -12569.619986212789\n",
      "Train Epoch: 13 [256/118836 (0%)] Loss: 12589.873047\n",
      "Train Epoch: 13 [33024/118836 (28%)] Loss: 12603.400391\n",
      "Train Epoch: 13 [65792/118836 (55%)] Loss: 12576.044922\n",
      "Train Epoch: 13 [98560/118836 (83%)] Loss: 12614.158203\n",
      "    epoch          : 13\n",
      "    loss           : 12570.855319802007\n",
      "    val_loss       : 12570.640284778885\n",
      "    val_log_likelihood: -12563.436182246433\n",
      "    val_log_marginal: -12569.093176924409\n",
      "Train Epoch: 14 [256/118836 (0%)] Loss: 12661.560547\n",
      "Train Epoch: 14 [33024/118836 (28%)] Loss: 12582.779297\n",
      "Train Epoch: 14 [65792/118836 (55%)] Loss: 12623.416016\n",
      "Train Epoch: 14 [98560/118836 (83%)] Loss: 12590.125000\n",
      "    epoch          : 14\n",
      "    loss           : 12571.40802655216\n",
      "    val_loss       : 12570.337996644861\n",
      "    val_log_likelihood: -12563.38477095611\n",
      "    val_log_marginal: -12568.743151328039\n",
      "Train Epoch: 15 [256/118836 (0%)] Loss: 12620.716797\n",
      "Train Epoch: 15 [33024/118836 (28%)] Loss: 12616.645508\n",
      "Train Epoch: 15 [65792/118836 (55%)] Loss: 12580.394531\n",
      "Train Epoch: 15 [98560/118836 (83%)] Loss: 12548.313477\n",
      "    epoch          : 15\n",
      "    loss           : 12572.532861772384\n",
      "    val_loss       : 12584.142093156623\n",
      "    val_log_likelihood: -12553.469007024141\n",
      "    val_log_marginal: -12559.92333353165\n",
      "Train Epoch: 16 [256/118836 (0%)] Loss: 12646.280273\n",
      "Train Epoch: 16 [33024/118836 (28%)] Loss: 12566.739258\n",
      "Train Epoch: 16 [65792/118836 (55%)] Loss: 12551.579102\n",
      "Train Epoch: 16 [98560/118836 (83%)] Loss: 12624.929688\n",
      "    epoch          : 16\n",
      "    loss           : 12572.927379613835\n",
      "    val_loss       : 12608.356067803934\n",
      "    val_log_likelihood: -12558.692457609595\n",
      "    val_log_marginal: -12565.169154688701\n",
      "Train Epoch: 17 [256/118836 (0%)] Loss: 12677.740234\n",
      "Train Epoch: 17 [33024/118836 (28%)] Loss: 12596.175781\n",
      "Train Epoch: 17 [65792/118836 (55%)] Loss: 12584.005859\n",
      "Train Epoch: 17 [98560/118836 (83%)] Loss: 12600.422852\n",
      "    epoch          : 17\n",
      "    loss           : 12581.407206368898\n",
      "    val_loss       : 12576.350731010754\n",
      "    val_log_likelihood: -12552.425946191326\n",
      "    val_log_marginal: -12558.848578008132\n",
      "Train Epoch: 18 [256/118836 (0%)] Loss: 12641.725586\n",
      "Train Epoch: 18 [33024/118836 (28%)] Loss: 12590.368164\n",
      "Train Epoch: 18 [65792/118836 (55%)] Loss: 12510.344727\n",
      "Train Epoch: 18 [98560/118836 (83%)] Loss: 12592.023438\n",
      "    epoch          : 18\n",
      "    loss           : 12564.358146582921\n",
      "    val_loss       : 12580.161765888068\n",
      "    val_log_likelihood: -12531.197905196703\n",
      "    val_log_marginal: -12537.831508688829\n",
      "Train Epoch: 19 [256/118836 (0%)] Loss: 12589.601562\n",
      "Train Epoch: 19 [33024/118836 (28%)] Loss: 12583.904297\n",
      "Train Epoch: 19 [65792/118836 (55%)] Loss: 12646.408203\n",
      "Train Epoch: 19 [98560/118836 (83%)] Loss: 12622.658203\n",
      "    epoch          : 19\n",
      "    loss           : 12564.066562306141\n",
      "    val_loss       : 12592.539796623565\n",
      "    val_log_likelihood: -12522.084238491263\n",
      "    val_log_marginal: -12528.108796835042\n",
      "Train Epoch: 20 [256/118836 (0%)] Loss: 12536.911133\n",
      "Train Epoch: 20 [33024/118836 (28%)] Loss: 12610.974609\n",
      "Train Epoch: 20 [65792/118836 (55%)] Loss: 12523.816406\n",
      "Train Epoch: 20 [98560/118836 (83%)] Loss: 12599.888672\n",
      "    epoch          : 20\n",
      "    loss           : 12560.115531786343\n",
      "    val_loss       : 12562.422745944128\n",
      "    val_log_likelihood: -12510.354244048543\n",
      "    val_log_marginal: -12516.075539332114\n",
      "Train Epoch: 21 [256/118836 (0%)] Loss: 12537.950195\n",
      "Train Epoch: 21 [33024/118836 (28%)] Loss: 12505.538086\n",
      "Train Epoch: 21 [65792/118836 (55%)] Loss: 12546.549805\n",
      "Train Epoch: 21 [98560/118836 (83%)] Loss: 12550.267578\n",
      "    epoch          : 21\n",
      "    loss           : 12549.823994520264\n",
      "    val_loss       : 12557.358010349264\n",
      "    val_log_likelihood: -12488.037268985216\n",
      "    val_log_marginal: -12493.933973414678\n",
      "Train Epoch: 22 [256/118836 (0%)] Loss: 12556.595703\n",
      "Train Epoch: 22 [33024/118836 (28%)] Loss: 12569.835938\n",
      "Train Epoch: 22 [65792/118836 (55%)] Loss: 12611.931641\n",
      "Train Epoch: 22 [98560/118836 (83%)] Loss: 12618.775391\n",
      "    epoch          : 22\n",
      "    loss           : 12547.057979056814\n",
      "    val_loss       : 12540.449999018578\n",
      "    val_log_likelihood: -12479.370282128826\n",
      "    val_log_marginal: -12484.780016351762\n",
      "Train Epoch: 23 [256/118836 (0%)] Loss: 12558.134766\n",
      "Train Epoch: 23 [33024/118836 (28%)] Loss: 12569.519531\n",
      "Train Epoch: 23 [65792/118836 (55%)] Loss: 12554.500000\n",
      "Train Epoch: 23 [98560/118836 (83%)] Loss: 12728.852539\n",
      "    epoch          : 23\n",
      "    loss           : 12550.93898576432\n",
      "    val_loss       : 12549.807796424155\n",
      "    val_log_likelihood: -12495.333573233302\n",
      "    val_log_marginal: -12500.532085775802\n",
      "Train Epoch: 24 [256/118836 (0%)] Loss: 12597.666016\n",
      "Train Epoch: 24 [33024/118836 (28%)] Loss: 12521.800781\n",
      "Train Epoch: 24 [65792/118836 (55%)] Loss: 12609.078125\n",
      "Train Epoch: 24 [98560/118836 (83%)] Loss: 12607.335938\n",
      "    epoch          : 24\n",
      "    loss           : 12538.05569104115\n",
      "    val_loss       : 12519.991296226219\n",
      "    val_log_likelihood: -12434.133135274504\n",
      "    val_log_marginal: -12439.97231556896\n",
      "Train Epoch: 25 [256/118836 (0%)] Loss: 12555.900391\n",
      "Train Epoch: 25 [33024/118836 (28%)] Loss: 12598.979492\n",
      "Train Epoch: 25 [65792/118836 (55%)] Loss: 12532.867188\n",
      "Train Epoch: 25 [98560/118836 (83%)] Loss: 12559.889648\n",
      "    epoch          : 25\n",
      "    loss           : 12530.472612147178\n",
      "    val_loss       : 12530.092845939142\n",
      "    val_log_likelihood: -12451.846073556399\n",
      "    val_log_marginal: -12457.144400659148\n",
      "Train Epoch: 26 [256/118836 (0%)] Loss: 12538.250977\n",
      "Train Epoch: 26 [33024/118836 (28%)] Loss: 12496.438477\n",
      "Train Epoch: 26 [65792/118836 (55%)] Loss: 12567.591797\n",
      "Train Epoch: 26 [98560/118836 (83%)] Loss: 12560.916016\n",
      "    epoch          : 26\n",
      "    loss           : 12529.496572903741\n",
      "    val_loss       : 12523.368102589082\n",
      "    val_log_likelihood: -12445.590885416666\n",
      "    val_log_marginal: -12451.096933224431\n",
      "Train Epoch: 27 [256/118836 (0%)] Loss: 12529.094727\n",
      "Train Epoch: 27 [33024/118836 (28%)] Loss: 12532.824219\n",
      "Train Epoch: 27 [65792/118836 (55%)] Loss: 12630.028320\n",
      "Train Epoch: 27 [98560/118836 (83%)] Loss: 12579.821289\n",
      "    epoch          : 27\n",
      "    loss           : 12521.648283059347\n",
      "    val_loss       : 12519.236283847376\n",
      "    val_log_likelihood: -12438.10752704327\n",
      "    val_log_marginal: -12443.270775002235\n",
      "Train Epoch: 28 [256/118836 (0%)] Loss: 12543.600586\n",
      "Train Epoch: 28 [33024/118836 (28%)] Loss: 12467.503906\n",
      "Train Epoch: 28 [65792/118836 (55%)] Loss: 12570.800781\n",
      "Train Epoch: 28 [98560/118836 (83%)] Loss: 12593.843750\n",
      "    epoch          : 28\n",
      "    loss           : 12518.231595714435\n",
      "    val_loss       : 12514.301967817404\n",
      "    val_log_likelihood: -12430.293604767628\n",
      "    val_log_marginal: -12435.447014895715\n",
      "Train Epoch: 29 [256/118836 (0%)] Loss: 12538.505859\n",
      "Train Epoch: 29 [33024/118836 (28%)] Loss: 12554.410156\n",
      "Train Epoch: 29 [65792/118836 (55%)] Loss: 12520.045898\n",
      "Train Epoch: 29 [98560/118836 (83%)] Loss: 12573.322266\n",
      "    epoch          : 29\n",
      "    loss           : 12520.285179028382\n",
      "    val_loss       : 12535.224454665253\n",
      "    val_log_likelihood: -12448.826526959265\n",
      "    val_log_marginal: -12453.865135801216\n",
      "Train Epoch: 30 [256/118836 (0%)] Loss: 12574.085938\n",
      "Train Epoch: 30 [33024/118836 (28%)] Loss: 12477.404297\n",
      "Train Epoch: 30 [65792/118836 (55%)] Loss: 12595.889648\n",
      "Train Epoch: 30 [98560/118836 (83%)] Loss: 12415.364258\n",
      "    epoch          : 30\n",
      "    loss           : 12533.730376828733\n",
      "    val_loss       : 12515.81376745355\n",
      "    val_log_likelihood: -12432.542428046165\n",
      "    val_log_marginal: -12437.858655473987\n",
      "Train Epoch: 31 [256/118836 (0%)] Loss: 12587.337891\n",
      "Train Epoch: 31 [33024/118836 (28%)] Loss: 12533.773438\n",
      "Train Epoch: 31 [65792/118836 (55%)] Loss: 12598.373047\n",
      "Train Epoch: 31 [98560/118836 (83%)] Loss: 12545.742188\n",
      "    epoch          : 31\n",
      "    loss           : 12522.181052264268\n",
      "    val_loss       : 12544.414698484283\n",
      "    val_log_likelihood: -12473.013677529207\n",
      "    val_log_marginal: -12477.572641319184\n",
      "Train Epoch: 32 [256/118836 (0%)] Loss: 12551.416016\n",
      "Train Epoch: 32 [33024/118836 (28%)] Loss: 12492.299805\n",
      "Train Epoch: 32 [65792/118836 (55%)] Loss: 12584.884766\n",
      "Train Epoch: 32 [98560/118836 (83%)] Loss: 12459.949219\n",
      "    epoch          : 32\n",
      "    loss           : 12519.225892234026\n",
      "    val_loss       : 12529.245690322052\n",
      "    val_log_likelihood: -12436.09393594267\n",
      "    val_log_marginal: -12440.883307969614\n",
      "Train Epoch: 33 [256/118836 (0%)] Loss: 12517.742188\n",
      "Train Epoch: 33 [33024/118836 (28%)] Loss: 12623.767578\n",
      "Train Epoch: 33 [65792/118836 (55%)] Loss: 12524.071289\n",
      "Train Epoch: 33 [98560/118836 (83%)] Loss: 12492.090820\n",
      "    epoch          : 33\n",
      "    loss           : 12518.62528287195\n",
      "    val_loss       : 12520.384765296487\n",
      "    val_log_likelihood: -12434.505626583177\n",
      "    val_log_marginal: -12439.276761117031\n",
      "Train Epoch: 34 [256/118836 (0%)] Loss: 12585.220703\n",
      "Train Epoch: 34 [33024/118836 (28%)] Loss: 12554.905273\n",
      "Train Epoch: 34 [65792/118836 (55%)] Loss: 12584.637695\n",
      "Train Epoch: 34 [98560/118836 (83%)] Loss: 12584.837891\n",
      "    epoch          : 34\n",
      "    loss           : 12518.767953564413\n",
      "    val_loss       : 12519.692774136594\n",
      "    val_log_likelihood: -12440.218796526055\n",
      "    val_log_marginal: -12444.778348608812\n",
      "Train Epoch: 35 [256/118836 (0%)] Loss: 12554.920898\n",
      "Train Epoch: 35 [33024/118836 (28%)] Loss: 12561.036133\n",
      "Train Epoch: 35 [65792/118836 (55%)] Loss: 12586.922852\n",
      "Train Epoch: 35 [98560/118836 (83%)] Loss: 12528.880859\n",
      "    epoch          : 35\n",
      "    loss           : 12523.495566777812\n",
      "    val_loss       : 12549.357668841272\n",
      "    val_log_likelihood: -12479.50824076587\n",
      "    val_log_marginal: -12483.840132352543\n",
      "Train Epoch: 36 [256/118836 (0%)] Loss: 12605.324219\n",
      "Train Epoch: 36 [33024/118836 (28%)] Loss: 12580.436523\n",
      "Train Epoch: 36 [65792/118836 (55%)] Loss: 12548.654297\n",
      "Train Epoch: 36 [98560/118836 (83%)] Loss: 12549.889648\n",
      "    epoch          : 36\n",
      "    loss           : 12524.324268183933\n",
      "    val_loss       : 12510.193879014163\n",
      "    val_log_likelihood: -12427.11853061673\n",
      "    val_log_marginal: -12431.678236757973\n",
      "Train Epoch: 37 [256/118836 (0%)] Loss: 12473.286133\n",
      "Train Epoch: 37 [33024/118836 (28%)] Loss: 12622.593750\n",
      "Train Epoch: 37 [65792/118836 (55%)] Loss: 12532.827148\n",
      "Train Epoch: 37 [98560/118836 (83%)] Loss: 12497.532227\n",
      "    epoch          : 37\n",
      "    loss           : 12514.899774962521\n",
      "    val_loss       : 12500.33208598074\n",
      "    val_log_likelihood: -12410.253950999018\n",
      "    val_log_marginal: -12414.815822833689\n",
      "Train Epoch: 38 [256/118836 (0%)] Loss: 12621.191406\n",
      "Train Epoch: 38 [33024/118836 (28%)] Loss: 12439.685547\n",
      "Train Epoch: 38 [65792/118836 (55%)] Loss: 12521.354492\n",
      "Train Epoch: 38 [98560/118836 (83%)] Loss: 12509.401367\n",
      "    epoch          : 38\n",
      "    loss           : 12511.579450346362\n",
      "    val_loss       : 12512.12515261767\n",
      "    val_log_likelihood: -12414.627800125363\n",
      "    val_log_marginal: -12419.267854535636\n",
      "Train Epoch: 39 [256/118836 (0%)] Loss: 12539.392578\n",
      "Train Epoch: 39 [33024/118836 (28%)] Loss: 12480.292969\n",
      "Train Epoch: 39 [65792/118836 (55%)] Loss: 12622.139648\n",
      "Train Epoch: 39 [98560/118836 (83%)] Loss: 12543.531250\n",
      "    epoch          : 39\n",
      "    loss           : 12507.953884440913\n",
      "    val_loss       : 12500.49503409048\n",
      "    val_log_likelihood: -12414.997467561\n",
      "    val_log_marginal: -12419.621538555453\n",
      "Train Epoch: 40 [256/118836 (0%)] Loss: 12619.380859\n",
      "Train Epoch: 40 [33024/118836 (28%)] Loss: 12624.470703\n",
      "Train Epoch: 40 [65792/118836 (55%)] Loss: 12501.589844\n",
      "Train Epoch: 40 [98560/118836 (83%)] Loss: 12512.661133\n",
      "    epoch          : 40\n",
      "    loss           : 12505.699860744933\n",
      "    val_loss       : 12494.075286177558\n",
      "    val_log_likelihood: -12411.302882192153\n",
      "    val_log_marginal: -12415.93478389523\n",
      "Train Epoch: 41 [256/118836 (0%)] Loss: 12501.751953\n",
      "Train Epoch: 41 [33024/118836 (28%)] Loss: 12563.048828\n",
      "Train Epoch: 41 [65792/118836 (55%)] Loss: 12510.660156\n",
      "Train Epoch: 41 [98560/118836 (83%)] Loss: 12513.814453\n",
      "    epoch          : 41\n",
      "    loss           : 12504.790655371175\n",
      "    val_loss       : 12491.019142537894\n",
      "    val_log_likelihood: -12404.26130680056\n",
      "    val_log_marginal: -12408.841098627227\n",
      "Train Epoch: 42 [256/118836 (0%)] Loss: 12576.548828\n",
      "Train Epoch: 42 [33024/118836 (28%)] Loss: 12551.691406\n",
      "Train Epoch: 42 [65792/118836 (55%)] Loss: 12567.389648\n",
      "Train Epoch: 42 [98560/118836 (83%)] Loss: 12585.492188\n",
      "    epoch          : 42\n",
      "    loss           : 12493.105835788876\n",
      "    val_loss       : 12490.373670484694\n",
      "    val_log_likelihood: -12399.422326044252\n",
      "    val_log_marginal: -12403.809571024483\n",
      "Train Epoch: 43 [256/118836 (0%)] Loss: 12495.713867\n",
      "Train Epoch: 43 [33024/118836 (28%)] Loss: 12511.319336\n",
      "Train Epoch: 43 [65792/118836 (55%)] Loss: 12605.968750\n",
      "Train Epoch: 43 [98560/118836 (83%)] Loss: 12486.933594\n",
      "    epoch          : 43\n",
      "    loss           : 12506.876445538668\n",
      "    val_loss       : 12496.994373001298\n",
      "    val_log_likelihood: -12411.111216171681\n",
      "    val_log_marginal: -12415.704938424407\n",
      "Train Epoch: 44 [256/118836 (0%)] Loss: 12517.978516\n",
      "Train Epoch: 44 [33024/118836 (28%)] Loss: 12504.875977\n",
      "Train Epoch: 44 [65792/118836 (55%)] Loss: 12492.508789\n",
      "Train Epoch: 44 [98560/118836 (83%)] Loss: 12580.334961\n",
      "    epoch          : 44\n",
      "    loss           : 12496.437079326923\n",
      "    val_loss       : 12495.112051766775\n",
      "    val_log_likelihood: -12410.17971173232\n",
      "    val_log_marginal: -12415.830227640325\n",
      "Train Epoch: 45 [256/118836 (0%)] Loss: 12564.424805\n",
      "Train Epoch: 45 [33024/118836 (28%)] Loss: 12550.516602\n",
      "Train Epoch: 45 [65792/118836 (55%)] Loss: 12498.941406\n",
      "Train Epoch: 45 [98560/118836 (83%)] Loss: 12535.296875\n",
      "    epoch          : 45\n",
      "    loss           : 12479.60455406069\n",
      "    val_loss       : 12474.814940916605\n",
      "    val_log_likelihood: -12394.234334289704\n",
      "    val_log_marginal: -12401.482567470724\n",
      "Train Epoch: 46 [256/118836 (0%)] Loss: 12467.658203\n",
      "Train Epoch: 46 [33024/118836 (28%)] Loss: 12541.055664\n",
      "Train Epoch: 46 [65792/118836 (55%)] Loss: 12548.632812\n",
      "Train Epoch: 46 [98560/118836 (83%)] Loss: 12500.974609\n",
      "    epoch          : 46\n",
      "    loss           : 12468.023253495916\n",
      "    val_loss       : 12463.776342694231\n",
      "    val_log_likelihood: -12397.077417416254\n",
      "    val_log_marginal: -12404.092313237354\n",
      "Train Epoch: 47 [256/118836 (0%)] Loss: 12524.123047\n",
      "Train Epoch: 47 [33024/118836 (28%)] Loss: 12450.859375\n",
      "Train Epoch: 47 [65792/118836 (55%)] Loss: 12487.280273\n",
      "Train Epoch: 47 [98560/118836 (83%)] Loss: 12482.567383\n",
      "    epoch          : 47\n",
      "    loss           : 12459.296643015923\n",
      "    val_loss       : 12445.450654228125\n",
      "    val_log_likelihood: -12363.537217774247\n",
      "    val_log_marginal: -12370.16897543851\n",
      "Train Epoch: 48 [256/118836 (0%)] Loss: 12439.857422\n",
      "Train Epoch: 48 [33024/118836 (28%)] Loss: 12529.656250\n",
      "Train Epoch: 48 [65792/118836 (55%)] Loss: 12405.062500\n",
      "Train Epoch: 48 [98560/118836 (83%)] Loss: 12463.354492\n",
      "    epoch          : 48\n",
      "    loss           : 12453.263825831007\n",
      "    val_loss       : 12449.125606503614\n",
      "    val_log_likelihood: -12369.258593911549\n",
      "    val_log_marginal: -12375.838047943787\n",
      "Train Epoch: 49 [256/118836 (0%)] Loss: 12452.260742\n",
      "Train Epoch: 49 [33024/118836 (28%)] Loss: 12528.133789\n",
      "Train Epoch: 49 [65792/118836 (55%)] Loss: 12413.033203\n",
      "Train Epoch: 49 [98560/118836 (83%)] Loss: 12464.835938\n",
      "    epoch          : 49\n",
      "    loss           : 12455.186581110422\n",
      "    val_loss       : 12455.795198963198\n",
      "    val_log_likelihood: -12375.7286639268\n",
      "    val_log_marginal: -12382.76863605192\n",
      "Train Epoch: 50 [256/118836 (0%)] Loss: 12460.711914\n",
      "Train Epoch: 50 [33024/118836 (28%)] Loss: 12416.798828\n",
      "Train Epoch: 50 [65792/118836 (55%)] Loss: 12441.960938\n",
      "Train Epoch: 50 [98560/118836 (83%)] Loss: 12469.681641\n",
      "    epoch          : 50\n",
      "    loss           : 12451.257850625516\n",
      "    val_loss       : 12449.979981908178\n",
      "    val_log_likelihood: -12374.902275899503\n",
      "    val_log_marginal: -12381.526167856882\n",
      "Train Epoch: 51 [256/118836 (0%)] Loss: 12455.157227\n",
      "Train Epoch: 51 [33024/118836 (28%)] Loss: 12517.357422\n",
      "Train Epoch: 51 [65792/118836 (55%)] Loss: 12427.856445\n",
      "Train Epoch: 51 [98560/118836 (83%)] Loss: 12480.435547\n",
      "    epoch          : 51\n",
      "    loss           : 12448.645337216967\n",
      "    val_loss       : 12438.136991703372\n",
      "    val_log_likelihood: -12358.884276293682\n",
      "    val_log_marginal: -12365.643963407943\n",
      "Train Epoch: 52 [256/118836 (0%)] Loss: 12402.685547\n",
      "Train Epoch: 52 [33024/118836 (28%)] Loss: 12392.120117\n",
      "Train Epoch: 52 [65792/118836 (55%)] Loss: 12504.519531\n",
      "Train Epoch: 52 [98560/118836 (83%)] Loss: 12447.187500\n",
      "    epoch          : 52\n",
      "    loss           : 12442.110987095482\n",
      "    val_loss       : 12455.57968799085\n",
      "    val_log_likelihood: -12389.267540645678\n",
      "    val_log_marginal: -12395.842539802916\n",
      "Train Epoch: 53 [256/118836 (0%)] Loss: 12424.046875\n",
      "Train Epoch: 53 [33024/118836 (28%)] Loss: 12454.592773\n",
      "Train Epoch: 53 [65792/118836 (55%)] Loss: 12526.177734\n",
      "Train Epoch: 53 [98560/118836 (83%)] Loss: 12497.912109\n",
      "    epoch          : 53\n",
      "    loss           : 12442.25998516982\n",
      "    val_loss       : 12437.019632177084\n",
      "    val_log_likelihood: -12358.980763576561\n",
      "    val_log_marginal: -12365.25041819582\n",
      "Train Epoch: 54 [256/118836 (0%)] Loss: 12457.233398\n",
      "Train Epoch: 54 [33024/118836 (28%)] Loss: 12525.189453\n",
      "Train Epoch: 54 [65792/118836 (55%)] Loss: 12510.708008\n",
      "Train Epoch: 54 [98560/118836 (83%)] Loss: 12417.671875\n",
      "    epoch          : 54\n",
      "    loss           : 12434.93583507806\n",
      "    val_loss       : 12432.226873817142\n",
      "    val_log_likelihood: -12352.735490171372\n",
      "    val_log_marginal: -12358.595055873098\n",
      "Train Epoch: 55 [256/118836 (0%)] Loss: 12430.982422\n",
      "Train Epoch: 55 [33024/118836 (28%)] Loss: 12525.580078\n",
      "Train Epoch: 55 [65792/118836 (55%)] Loss: 12437.612305\n",
      "Train Epoch: 55 [98560/118836 (83%)] Loss: 12403.636719\n",
      "    epoch          : 55\n",
      "    loss           : 12431.003985893558\n",
      "    val_loss       : 12432.18735219391\n",
      "    val_log_likelihood: -12350.52876618719\n",
      "    val_log_marginal: -12356.255465788461\n",
      "Train Epoch: 56 [256/118836 (0%)] Loss: 12451.711914\n",
      "Train Epoch: 56 [33024/118836 (28%)] Loss: 12483.197266\n",
      "Train Epoch: 56 [65792/118836 (55%)] Loss: 12568.402344\n",
      "Train Epoch: 56 [98560/118836 (83%)] Loss: 12466.226562\n",
      "    epoch          : 56\n",
      "    loss           : 12430.886533453526\n",
      "    val_loss       : 12430.412424978067\n",
      "    val_log_likelihood: -12352.22664618228\n",
      "    val_log_marginal: -12357.983525815871\n",
      "Train Epoch: 57 [256/118836 (0%)] Loss: 12361.668945\n",
      "Train Epoch: 57 [33024/118836 (28%)] Loss: 12475.388672\n",
      "Train Epoch: 57 [65792/118836 (55%)] Loss: 12454.758789\n",
      "Train Epoch: 57 [98560/118836 (83%)] Loss: 12520.031250\n",
      "    epoch          : 57\n",
      "    loss           : 12433.249658001188\n",
      "    val_loss       : 12436.871815820496\n",
      "    val_log_likelihood: -12362.996073879498\n",
      "    val_log_marginal: -12368.868590944478\n",
      "Train Epoch: 58 [256/118836 (0%)] Loss: 12458.669922\n",
      "Train Epoch: 58 [33024/118836 (28%)] Loss: 12424.873047\n",
      "Train Epoch: 58 [65792/118836 (55%)] Loss: 12456.695312\n",
      "Train Epoch: 58 [98560/118836 (83%)] Loss: 12426.650391\n",
      "    epoch          : 58\n",
      "    loss           : 12431.118081672612\n",
      "    val_loss       : 12427.275566620103\n",
      "    val_log_likelihood: -12347.586127481389\n",
      "    val_log_marginal: -12353.15954220941\n",
      "Train Epoch: 59 [256/118836 (0%)] Loss: 12537.974609\n",
      "Train Epoch: 59 [33024/118836 (28%)] Loss: 12411.643555\n",
      "Train Epoch: 59 [65792/118836 (55%)] Loss: 12521.755859\n",
      "Train Epoch: 59 [98560/118836 (83%)] Loss: 12466.232422\n",
      "    epoch          : 59\n",
      "    loss           : 12433.259001176075\n",
      "    val_loss       : 12432.940678165904\n",
      "    val_log_likelihood: -12350.988796590673\n",
      "    val_log_marginal: -12356.50477342591\n",
      "Train Epoch: 60 [256/118836 (0%)] Loss: 12399.208984\n",
      "Train Epoch: 60 [33024/118836 (28%)] Loss: 12529.989258\n",
      "Train Epoch: 60 [65792/118836 (55%)] Loss: 12508.907227\n",
      "Train Epoch: 60 [98560/118836 (83%)] Loss: 12426.833984\n",
      "    epoch          : 60\n",
      "    loss           : 12430.878493815913\n",
      "    val_loss       : 12427.63406296364\n",
      "    val_log_likelihood: -12348.600515502223\n",
      "    val_log_marginal: -12354.022132671991\n",
      "Train Epoch: 61 [256/118836 (0%)] Loss: 12501.893555\n",
      "Train Epoch: 61 [33024/118836 (28%)] Loss: 12348.633789\n",
      "Train Epoch: 61 [65792/118836 (55%)] Loss: 12453.542969\n",
      "Train Epoch: 61 [98560/118836 (83%)] Loss: 12412.368164\n",
      "    epoch          : 61\n",
      "    loss           : 12429.841387994986\n",
      "    val_loss       : 12427.602564976947\n",
      "    val_log_likelihood: -12349.010782897796\n",
      "    val_log_marginal: -12354.35982353484\n",
      "Train Epoch: 62 [256/118836 (0%)] Loss: 12410.235352\n",
      "Train Epoch: 62 [33024/118836 (28%)] Loss: 12457.913086\n",
      "Train Epoch: 62 [65792/118836 (55%)] Loss: 12500.933594\n",
      "Train Epoch: 62 [98560/118836 (83%)] Loss: 12370.816406\n",
      "    epoch          : 62\n",
      "    loss           : 12430.596783886478\n",
      "    val_loss       : 12430.288928838561\n",
      "    val_log_likelihood: -12351.577119520265\n",
      "    val_log_marginal: -12357.023167780831\n",
      "Train Epoch: 63 [256/118836 (0%)] Loss: 12474.323242\n",
      "Train Epoch: 63 [33024/118836 (28%)] Loss: 12452.396484\n",
      "Train Epoch: 63 [65792/118836 (55%)] Loss: 12442.721680\n",
      "Train Epoch: 63 [98560/118836 (83%)] Loss: 12447.179688\n",
      "    epoch          : 63\n",
      "    loss           : 12432.34282190214\n",
      "    val_loss       : 12432.27880534917\n",
      "    val_log_likelihood: -12353.952213703216\n",
      "    val_log_marginal: -12359.255728562033\n",
      "Train Epoch: 64 [256/118836 (0%)] Loss: 12486.979492\n",
      "Train Epoch: 64 [33024/118836 (28%)] Loss: 12402.627930\n",
      "Train Epoch: 64 [65792/118836 (55%)] Loss: 12403.075195\n",
      "Train Epoch: 64 [98560/118836 (83%)] Loss: 12436.733398\n",
      "    epoch          : 64\n",
      "    loss           : 12429.302896408446\n",
      "    val_loss       : 12427.824188135393\n",
      "    val_log_likelihood: -12347.75994478262\n",
      "    val_log_marginal: -12353.07311166826\n",
      "Train Epoch: 65 [256/118836 (0%)] Loss: 12436.650391\n",
      "Train Epoch: 65 [33024/118836 (28%)] Loss: 12441.882812\n",
      "Train Epoch: 65 [65792/118836 (55%)] Loss: 12413.013672\n",
      "Train Epoch: 65 [98560/118836 (83%)] Loss: 12460.282227\n",
      "    epoch          : 65\n",
      "    loss           : 12430.916583630582\n",
      "    val_loss       : 12429.914766737662\n",
      "    val_log_likelihood: -12347.874330057124\n",
      "    val_log_marginal: -12353.319729944977\n",
      "Train Epoch: 66 [256/118836 (0%)] Loss: 12547.235352\n",
      "Train Epoch: 66 [33024/118836 (28%)] Loss: 12502.429688\n",
      "Train Epoch: 66 [65792/118836 (55%)] Loss: 12489.304688\n",
      "Train Epoch: 66 [98560/118836 (83%)] Loss: 12415.267578\n",
      "    epoch          : 66\n",
      "    loss           : 12431.378357791822\n",
      "    val_loss       : 12427.679665254387\n",
      "    val_log_likelihood: -12349.410506164702\n",
      "    val_log_marginal: -12354.49543545142\n",
      "Train Epoch: 67 [256/118836 (0%)] Loss: 12422.593750\n",
      "Train Epoch: 67 [33024/118836 (28%)] Loss: 12462.939453\n",
      "Train Epoch: 67 [65792/118836 (55%)] Loss: 12467.097656\n",
      "Train Epoch: 67 [98560/118836 (83%)] Loss: 12529.249023\n",
      "    epoch          : 67\n",
      "    loss           : 12437.71432259357\n",
      "    val_loss       : 12481.446026750054\n",
      "    val_log_likelihood: -12395.708163060897\n",
      "    val_log_marginal: -12401.358067383897\n",
      "Train Epoch: 68 [256/118836 (0%)] Loss: 12447.695312\n",
      "Train Epoch: 68 [33024/118836 (28%)] Loss: 12452.875977\n",
      "Train Epoch: 68 [65792/118836 (55%)] Loss: 12530.666992\n",
      "Train Epoch: 68 [98560/118836 (83%)] Loss: 12371.478516\n",
      "    epoch          : 68\n",
      "    loss           : 12443.21514681555\n",
      "    val_loss       : 12442.914048117696\n",
      "    val_log_likelihood: -12361.028304803816\n",
      "    val_log_marginal: -12366.757109297921\n",
      "Train Epoch: 69 [256/118836 (0%)] Loss: 12465.498047\n",
      "Train Epoch: 69 [33024/118836 (28%)] Loss: 12529.284180\n",
      "Train Epoch: 69 [65792/118836 (55%)] Loss: 12466.290039\n",
      "Train Epoch: 69 [98560/118836 (83%)] Loss: 12483.252930\n",
      "    epoch          : 69\n",
      "    loss           : 12442.713989318392\n",
      "    val_loss       : 12435.824918045062\n",
      "    val_log_likelihood: -12357.825271725082\n",
      "    val_log_marginal: -12363.560164671413\n",
      "Train Epoch: 70 [256/118836 (0%)] Loss: 12560.860352\n",
      "Train Epoch: 70 [33024/118836 (28%)] Loss: 12404.739258\n",
      "Train Epoch: 70 [65792/118836 (55%)] Loss: 12493.885742\n",
      "Train Epoch: 70 [98560/118836 (83%)] Loss: 12448.424805\n",
      "    epoch          : 70\n",
      "    loss           : 12435.66622305366\n",
      "    val_loss       : 12432.870131100624\n",
      "    val_log_likelihood: -12350.862157354995\n",
      "    val_log_marginal: -12356.37792146655\n",
      "Train Epoch: 71 [256/118836 (0%)] Loss: 12519.989258\n",
      "Train Epoch: 71 [33024/118836 (28%)] Loss: 12361.352539\n",
      "Train Epoch: 71 [65792/118836 (55%)] Loss: 12469.609375\n",
      "Train Epoch: 71 [98560/118836 (83%)] Loss: 12574.652344\n",
      "    epoch          : 71\n",
      "    loss           : 12434.396369190705\n",
      "    val_loss       : 12487.057777172065\n",
      "    val_log_likelihood: -12375.774821650124\n",
      "    val_log_marginal: -12381.330323760929\n",
      "Train Epoch: 72 [256/118836 (0%)] Loss: 12669.510742\n",
      "Train Epoch: 72 [33024/118836 (28%)] Loss: 12448.293945\n",
      "Train Epoch: 72 [65792/118836 (55%)] Loss: 12562.457031\n",
      "Train Epoch: 72 [98560/118836 (83%)] Loss: 12451.916016\n",
      "    epoch          : 72\n",
      "    loss           : 12448.767464394645\n",
      "    val_loss       : 12434.887325974436\n",
      "    val_log_likelihood: -12352.710868680211\n",
      "    val_log_marginal: -12358.81778726031\n",
      "Train Epoch: 73 [256/118836 (0%)] Loss: 12413.025391\n",
      "Train Epoch: 73 [33024/118836 (28%)] Loss: 12373.322266\n",
      "Train Epoch: 73 [65792/118836 (55%)] Loss: 12473.993164\n",
      "Train Epoch: 73 [98560/118836 (83%)] Loss: 12356.993164\n",
      "    epoch          : 73\n",
      "    loss           : 12431.89191674421\n",
      "    val_loss       : 12430.128258492066\n",
      "    val_log_likelihood: -12349.384813766543\n",
      "    val_log_marginal: -12354.554832977517\n",
      "Train Epoch: 74 [256/118836 (0%)] Loss: 12416.280273\n",
      "Train Epoch: 74 [33024/118836 (28%)] Loss: 12380.626953\n",
      "Train Epoch: 74 [65792/118836 (55%)] Loss: 12415.365234\n",
      "Train Epoch: 74 [98560/118836 (83%)] Loss: 12418.094727\n",
      "    epoch          : 74\n",
      "    loss           : 12430.571176301437\n",
      "    val_loss       : 12429.433996203716\n",
      "    val_log_likelihood: -12349.900424711797\n",
      "    val_log_marginal: -12354.817496467509\n",
      "Train Epoch: 75 [256/118836 (0%)] Loss: 12385.436523\n",
      "Train Epoch: 75 [33024/118836 (28%)] Loss: 12481.591797\n",
      "Train Epoch: 75 [65792/118836 (55%)] Loss: 12423.613281\n",
      "Train Epoch: 75 [98560/118836 (83%)] Loss: 12478.450195\n",
      "    epoch          : 75\n",
      "    loss           : 12428.30593627223\n",
      "    val_loss       : 12427.662282249981\n",
      "    val_log_likelihood: -12347.063950223584\n",
      "    val_log_marginal: -12351.992600609245\n",
      "Train Epoch: 76 [256/118836 (0%)] Loss: 12480.167969\n",
      "Train Epoch: 76 [33024/118836 (28%)] Loss: 12356.408203\n",
      "Train Epoch: 76 [65792/118836 (55%)] Loss: 12458.257812\n",
      "Train Epoch: 76 [98560/118836 (83%)] Loss: 12488.078125\n",
      "    epoch          : 76\n",
      "    loss           : 12428.67264946495\n",
      "    val_loss       : 12433.988245906601\n",
      "    val_log_likelihood: -12349.546056432227\n",
      "    val_log_marginal: -12354.327799171973\n",
      "Train Epoch: 77 [256/118836 (0%)] Loss: 12452.874023\n",
      "Train Epoch: 77 [33024/118836 (28%)] Loss: 12405.940430\n",
      "Train Epoch: 77 [65792/118836 (55%)] Loss: 12444.069336\n",
      "Train Epoch: 77 [98560/118836 (83%)] Loss: 12448.728516\n",
      "    epoch          : 77\n",
      "    loss           : 12424.336640560381\n",
      "    val_loss       : 12430.57321636952\n",
      "    val_log_likelihood: -12347.419224468827\n",
      "    val_log_marginal: -12352.139602940724\n",
      "Train Epoch: 78 [256/118836 (0%)] Loss: 12486.910156\n",
      "Train Epoch: 78 [33024/118836 (28%)] Loss: 12368.023438\n",
      "Train Epoch: 78 [65792/118836 (55%)] Loss: 12456.464844\n",
      "Train Epoch: 78 [98560/118836 (83%)] Loss: 12465.337891\n",
      "    epoch          : 78\n",
      "    loss           : 12429.098728772487\n",
      "    val_loss       : 12429.082878041652\n",
      "    val_log_likelihood: -12349.265839375259\n",
      "    val_log_marginal: -12353.997044187045\n",
      "Train Epoch: 79 [256/118836 (0%)] Loss: 12471.254883\n",
      "Train Epoch: 79 [33024/118836 (28%)] Loss: 12428.258789\n",
      "Train Epoch: 79 [65792/118836 (55%)] Loss: 12438.679688\n",
      "Train Epoch: 79 [98560/118836 (83%)] Loss: 12477.558594\n",
      "    epoch          : 79\n",
      "    loss           : 12426.289708695202\n",
      "    val_loss       : 12431.32392166818\n",
      "    val_log_likelihood: -12346.755838535206\n",
      "    val_log_marginal: -12351.493214668311\n",
      "Train Epoch: 80 [256/118836 (0%)] Loss: 12420.211914\n",
      "Train Epoch: 80 [33024/118836 (28%)] Loss: 12459.246094\n",
      "Train Epoch: 80 [65792/118836 (55%)] Loss: 12467.995117\n",
      "Train Epoch: 80 [98560/118836 (83%)] Loss: 12397.208984\n",
      "    epoch          : 80\n",
      "    loss           : 12426.534706821236\n",
      "    val_loss       : 12429.694955323423\n",
      "    val_log_likelihood: -12351.017031443858\n",
      "    val_log_marginal: -12355.723483343041\n",
      "Train Epoch: 81 [256/118836 (0%)] Loss: 12412.242188\n",
      "Train Epoch: 81 [33024/118836 (28%)] Loss: 12431.062500\n",
      "Train Epoch: 81 [65792/118836 (55%)] Loss: 12479.638672\n",
      "Train Epoch: 81 [98560/118836 (83%)] Loss: 12495.791992\n",
      "    epoch          : 81\n",
      "    loss           : 12425.311603565704\n",
      "    val_loss       : 12430.34440192612\n",
      "    val_log_likelihood: -12347.485919729632\n",
      "    val_log_marginal: -12352.154356969988\n",
      "Train Epoch: 82 [256/118836 (0%)] Loss: 12504.070312\n",
      "Train Epoch: 82 [33024/118836 (28%)] Loss: 12495.492188\n",
      "Train Epoch: 82 [65792/118836 (55%)] Loss: 12422.222656\n",
      "Train Epoch: 82 [98560/118836 (83%)] Loss: 12489.506836\n",
      "    epoch          : 82\n",
      "    loss           : 12424.96426330516\n",
      "    val_loss       : 12426.157644640698\n",
      "    val_log_likelihood: -12347.248924408086\n",
      "    val_log_marginal: -12351.888985177226\n",
      "Train Epoch: 83 [256/118836 (0%)] Loss: 12447.165039\n",
      "Train Epoch: 83 [33024/118836 (28%)] Loss: 12493.117188\n",
      "Train Epoch: 83 [65792/118836 (55%)] Loss: 12507.457031\n",
      "Train Epoch: 83 [98560/118836 (83%)] Loss: 12492.315430\n",
      "    epoch          : 83\n",
      "    loss           : 12422.245451916615\n",
      "    val_loss       : 12429.627122277427\n",
      "    val_log_likelihood: -12349.187840383323\n",
      "    val_log_marginal: -12353.85723940973\n",
      "Train Epoch: 84 [256/118836 (0%)] Loss: 12444.780273\n",
      "Train Epoch: 84 [33024/118836 (28%)] Loss: 12444.786133\n",
      "Train Epoch: 84 [65792/118836 (55%)] Loss: 12380.440430\n",
      "Train Epoch: 84 [98560/118836 (83%)] Loss: 12464.628906\n",
      "    epoch          : 84\n",
      "    loss           : 12426.690118221411\n",
      "    val_loss       : 12428.316611168762\n",
      "    val_log_likelihood: -12349.904208507805\n",
      "    val_log_marginal: -12354.534724681247\n",
      "Train Epoch: 85 [256/118836 (0%)] Loss: 12491.961914\n",
      "Train Epoch: 85 [33024/118836 (28%)] Loss: 12447.183594\n",
      "Train Epoch: 85 [65792/118836 (55%)] Loss: 12394.928711\n",
      "Train Epoch: 85 [98560/118836 (83%)] Loss: 12437.722656\n",
      "    epoch          : 85\n",
      "    loss           : 12426.847223137665\n",
      "    val_loss       : 12428.46078489643\n",
      "    val_log_likelihood: -12349.586435716501\n",
      "    val_log_marginal: -12354.260142389254\n",
      "Train Epoch: 86 [256/118836 (0%)] Loss: 12417.919922\n",
      "Train Epoch: 86 [33024/118836 (28%)] Loss: 12443.489258\n",
      "Train Epoch: 86 [65792/118836 (55%)] Loss: 12409.323242\n",
      "Train Epoch: 86 [98560/118836 (83%)] Loss: 12441.949219\n",
      "    epoch          : 86\n",
      "    loss           : 12426.936549608405\n",
      "    val_loss       : 12428.70211593908\n",
      "    val_log_likelihood: -12345.752325818083\n",
      "    val_log_marginal: -12350.368056058285\n",
      "Train Epoch: 87 [256/118836 (0%)] Loss: 12457.439453\n",
      "Train Epoch: 87 [33024/118836 (28%)] Loss: 12451.043945\n",
      "Train Epoch: 87 [65792/118836 (55%)] Loss: 12511.894531\n",
      "Train Epoch: 87 [98560/118836 (83%)] Loss: 12375.197266\n",
      "    epoch          : 87\n",
      "    loss           : 12428.801947955439\n",
      "    val_loss       : 12425.491395895306\n",
      "    val_log_likelihood: -12348.90825578991\n",
      "    val_log_marginal: -12353.552124853893\n",
      "Train Epoch: 88 [256/118836 (0%)] Loss: 12418.228516\n",
      "Train Epoch: 88 [33024/118836 (28%)] Loss: 12496.328125\n",
      "Train Epoch: 88 [65792/118836 (55%)] Loss: 12414.546875\n",
      "Train Epoch: 88 [98560/118836 (83%)] Loss: 12542.327148\n",
      "    epoch          : 88\n",
      "    loss           : 12426.972010054798\n",
      "    val_loss       : 12426.342606560822\n",
      "    val_log_likelihood: -12347.157451761528\n",
      "    val_log_marginal: -12351.82671735898\n",
      "Train Epoch: 89 [256/118836 (0%)] Loss: 12451.218750\n",
      "Train Epoch: 89 [33024/118836 (28%)] Loss: 12437.830078\n",
      "Train Epoch: 89 [65792/118836 (55%)] Loss: 12361.162109\n",
      "Train Epoch: 89 [98560/118836 (83%)] Loss: 12418.281250\n",
      "    epoch          : 89\n",
      "    loss           : 12424.62658673232\n",
      "    val_loss       : 12425.499040610375\n",
      "    val_log_likelihood: -12345.336851704664\n",
      "    val_log_marginal: -12350.031482119128\n",
      "Train Epoch: 90 [256/118836 (0%)] Loss: 12348.189453\n",
      "Train Epoch: 90 [33024/118836 (28%)] Loss: 12445.005859\n",
      "Train Epoch: 90 [65792/118836 (55%)] Loss: 12501.934570\n",
      "Train Epoch: 90 [98560/118836 (83%)] Loss: 12437.129883\n",
      "    epoch          : 90\n",
      "    loss           : 12424.88442750336\n",
      "    val_loss       : 12428.141782215123\n",
      "    val_log_likelihood: -12345.539793508324\n",
      "    val_log_marginal: -12350.252311247448\n",
      "Train Epoch: 91 [256/118836 (0%)] Loss: 12386.150391\n",
      "Train Epoch: 91 [33024/118836 (28%)] Loss: 12452.966797\n",
      "Train Epoch: 91 [65792/118836 (55%)] Loss: 12480.621094\n",
      "Train Epoch: 91 [98560/118836 (83%)] Loss: 12432.880859\n",
      "    epoch          : 91\n",
      "    loss           : 12424.683103287842\n",
      "    val_loss       : 12426.340032215177\n",
      "    val_log_likelihood: -12345.729595740282\n",
      "    val_log_marginal: -12350.831031934702\n",
      "Train Epoch: 92 [256/118836 (0%)] Loss: 12531.627930\n",
      "Train Epoch: 92 [33024/118836 (28%)] Loss: 12454.022461\n",
      "Train Epoch: 92 [65792/118836 (55%)] Loss: 12366.054688\n",
      "Train Epoch: 92 [98560/118836 (83%)] Loss: 12380.329102\n",
      "    epoch          : 92\n",
      "    loss           : 12425.172250277863\n",
      "    val_loss       : 12426.467942779094\n",
      "    val_log_likelihood: -12341.158982436415\n",
      "    val_log_marginal: -12346.291519152794\n",
      "Train Epoch: 93 [256/118836 (0%)] Loss: 12491.500977\n",
      "Train Epoch: 93 [33024/118836 (28%)] Loss: 12431.375977\n",
      "Train Epoch: 93 [65792/118836 (55%)] Loss: 12415.895508\n",
      "Train Epoch: 93 [98560/118836 (83%)] Loss: 12453.071289\n",
      "    epoch          : 93\n",
      "    loss           : 12420.996473228131\n",
      "    val_loss       : 12424.605659594801\n",
      "    val_log_likelihood: -12340.191197367401\n",
      "    val_log_marginal: -12345.3681810808\n",
      "Train Epoch: 94 [256/118836 (0%)] Loss: 12425.667969\n",
      "Train Epoch: 94 [33024/118836 (28%)] Loss: 12430.873047\n",
      "Train Epoch: 94 [65792/118836 (55%)] Loss: 12500.262695\n",
      "Train Epoch: 94 [98560/118836 (83%)] Loss: 12480.250000\n",
      "    epoch          : 94\n",
      "    loss           : 12424.934212481907\n",
      "    val_loss       : 12425.041085031095\n",
      "    val_log_likelihood: -12344.108928479114\n",
      "    val_log_marginal: -12349.191573734268\n",
      "Train Epoch: 95 [256/118836 (0%)] Loss: 12390.086914\n",
      "Train Epoch: 95 [33024/118836 (28%)] Loss: 12457.197266\n",
      "Train Epoch: 95 [65792/118836 (55%)] Loss: 12485.346680\n",
      "Train Epoch: 95 [98560/118836 (83%)] Loss: 12434.333008\n",
      "    epoch          : 95\n",
      "    loss           : 12426.252482197322\n",
      "    val_loss       : 12426.965188240312\n",
      "    val_log_likelihood: -12341.806835129757\n",
      "    val_log_marginal: -12346.945052233064\n",
      "Train Epoch: 96 [256/118836 (0%)] Loss: 12585.425781\n",
      "Train Epoch: 96 [33024/118836 (28%)] Loss: 12504.972656\n",
      "Train Epoch: 96 [65792/118836 (55%)] Loss: 12522.043945\n",
      "Train Epoch: 96 [98560/118836 (83%)] Loss: 12413.378906\n",
      "    epoch          : 96\n",
      "    loss           : 12425.780659054488\n",
      "    val_loss       : 12426.474253167966\n",
      "    val_log_likelihood: -12340.899126505636\n",
      "    val_log_marginal: -12346.107849087035\n",
      "Train Epoch: 97 [256/118836 (0%)] Loss: 12403.820312\n",
      "Train Epoch: 97 [33024/118836 (28%)] Loss: 12407.214844\n",
      "Train Epoch: 97 [65792/118836 (55%)] Loss: 12433.987305\n",
      "Train Epoch: 97 [98560/118836 (83%)] Loss: 12440.081055\n",
      "    epoch          : 97\n",
      "    loss           : 12425.206896033655\n",
      "    val_loss       : 12426.806364536234\n",
      "    val_log_likelihood: -12341.34549036523\n",
      "    val_log_marginal: -12346.539618105084\n",
      "Train Epoch: 98 [256/118836 (0%)] Loss: 12560.970703\n",
      "Train Epoch: 98 [33024/118836 (28%)] Loss: 12478.588867\n",
      "Train Epoch: 98 [65792/118836 (55%)] Loss: 12485.659180\n",
      "Train Epoch: 98 [98560/118836 (83%)] Loss: 12357.590820\n",
      "    epoch          : 98\n",
      "    loss           : 12427.860300674627\n",
      "    val_loss       : 12422.923513385007\n",
      "    val_log_likelihood: -12341.003121122829\n",
      "    val_log_marginal: -12346.19317954356\n",
      "Train Epoch: 99 [256/118836 (0%)] Loss: 12389.909180\n",
      "Train Epoch: 99 [33024/118836 (28%)] Loss: 12479.980469\n",
      "Train Epoch: 99 [65792/118836 (55%)] Loss: 12451.776367\n",
      "Train Epoch: 99 [98560/118836 (83%)] Loss: 12420.460938\n",
      "    epoch          : 99\n",
      "    loss           : 12425.749716320306\n",
      "    val_loss       : 12424.108899645613\n",
      "    val_log_likelihood: -12341.942210924575\n",
      "    val_log_marginal: -12347.175698371751\n",
      "Train Epoch: 100 [256/118836 (0%)] Loss: 12493.565430\n",
      "Train Epoch: 100 [33024/118836 (28%)] Loss: 12434.426758\n",
      "Train Epoch: 100 [65792/118836 (55%)] Loss: 12577.406250\n",
      "Train Epoch: 100 [98560/118836 (83%)] Loss: 12490.666992\n",
      "    epoch          : 100\n",
      "    loss           : 12422.626530674886\n",
      "    val_loss       : 12424.277678276727\n",
      "    val_log_likelihood: -12339.089340202388\n",
      "    val_log_marginal: -12344.338470083945\n",
      "Saving checkpoint: saved/models/SelfiesAutoencodingOperad/0905_154251/checkpoint-epoch100.pth ...\n",
      "Train Epoch: 101 [256/118836 (0%)] Loss: 12449.125000\n",
      "Train Epoch: 101 [33024/118836 (28%)] Loss: 12370.231445\n",
      "Train Epoch: 101 [65792/118836 (55%)] Loss: 12504.361328\n",
      "Train Epoch: 101 [98560/118836 (83%)] Loss: 12541.175781\n",
      "    epoch          : 101\n",
      "    loss           : 12422.468706543374\n",
      "    val_loss       : 12426.01833680551\n",
      "    val_log_likelihood: -12341.489146828473\n",
      "    val_log_marginal: -12346.686354081212\n",
      "Train Epoch: 102 [256/118836 (0%)] Loss: 12338.705078\n",
      "Train Epoch: 102 [33024/118836 (28%)] Loss: 12375.992188\n",
      "Train Epoch: 102 [65792/118836 (55%)] Loss: 12417.717773\n",
      "Train Epoch: 102 [98560/118836 (83%)] Loss: 12407.082031\n",
      "    epoch          : 102\n",
      "    loss           : 12423.114644075682\n",
      "    val_loss       : 12424.848704773513\n",
      "    val_log_likelihood: -12347.697066919975\n",
      "    val_log_marginal: -12353.005020820456\n",
      "Train Epoch: 103 [256/118836 (0%)] Loss: 12463.556641\n",
      "Train Epoch: 103 [33024/118836 (28%)] Loss: 12499.908203\n",
      "Train Epoch: 103 [65792/118836 (55%)] Loss: 12391.729492\n",
      "Train Epoch: 103 [98560/118836 (83%)] Loss: 12462.223633\n",
      "    epoch          : 103\n",
      "    loss           : 12421.312556218983\n",
      "    val_loss       : 12423.231582268854\n",
      "    val_log_likelihood: -12340.282742064723\n",
      "    val_log_marginal: -12345.68851693663\n",
      "Train Epoch: 104 [256/118836 (0%)] Loss: 12401.111328\n",
      "Train Epoch: 104 [33024/118836 (28%)] Loss: 12466.095703\n",
      "Train Epoch: 104 [65792/118836 (55%)] Loss: 12516.914062\n",
      "Train Epoch: 104 [98560/118836 (83%)] Loss: 12396.163086\n",
      "    epoch          : 104\n",
      "    loss           : 12432.915309333643\n",
      "    val_loss       : 12427.555729418207\n",
      "    val_log_likelihood: -12349.681666311259\n",
      "    val_log_marginal: -12355.265234485303\n",
      "Train Epoch: 105 [256/118836 (0%)] Loss: 12498.576172\n",
      "Train Epoch: 105 [33024/118836 (28%)] Loss: 12491.340820\n",
      "Train Epoch: 105 [65792/118836 (55%)] Loss: 12397.637695\n",
      "Train Epoch: 105 [98560/118836 (83%)] Loss: 12390.751953\n",
      "    epoch          : 105\n",
      "    loss           : 12418.834258361765\n",
      "    val_loss       : 12414.475456228483\n",
      "    val_log_likelihood: -12336.321494229476\n",
      "    val_log_marginal: -12341.847355881187\n",
      "Train Epoch: 106 [256/118836 (0%)] Loss: 12361.639648\n",
      "Train Epoch: 106 [33024/118836 (28%)] Loss: 12383.380859\n",
      "Train Epoch: 106 [65792/118836 (55%)] Loss: 12427.217773\n",
      "Train Epoch: 106 [98560/118836 (83%)] Loss: 12408.514648\n",
      "    epoch          : 106\n",
      "    loss           : 12413.730990714175\n",
      "    val_loss       : 12413.855725028125\n",
      "    val_log_likelihood: -12332.429149057849\n",
      "    val_log_marginal: -12338.064435036478\n",
      "Train Epoch: 107 [256/118836 (0%)] Loss: 12502.103516\n",
      "Train Epoch: 107 [33024/118836 (28%)] Loss: 12481.841797\n",
      "Train Epoch: 107 [65792/118836 (55%)] Loss: 12560.802734\n",
      "Train Epoch: 107 [98560/118836 (83%)] Loss: 12462.697266\n",
      "    epoch          : 107\n",
      "    loss           : 12415.181197658188\n",
      "    val_loss       : 12418.187513542041\n",
      "    val_log_likelihood: -12332.040653594138\n",
      "    val_log_marginal: -12337.550526266008\n",
      "Train Epoch: 108 [256/118836 (0%)] Loss: 12483.838867\n",
      "Train Epoch: 108 [33024/118836 (28%)] Loss: 12377.492188\n",
      "Train Epoch: 108 [65792/118836 (55%)] Loss: 12490.994141\n",
      "Train Epoch: 108 [98560/118836 (83%)] Loss: 12441.316406\n",
      "    epoch          : 108\n",
      "    loss           : 12416.256505893301\n",
      "    val_loss       : 12417.236367373129\n",
      "    val_log_likelihood: -12329.505278607061\n",
      "    val_log_marginal: -12335.050610872006\n",
      "Train Epoch: 109 [256/118836 (0%)] Loss: 12453.728516\n",
      "Train Epoch: 109 [33024/118836 (28%)] Loss: 12475.561523\n",
      "Train Epoch: 109 [65792/118836 (55%)] Loss: 12372.397461\n",
      "Train Epoch: 109 [98560/118836 (83%)] Loss: 12486.910156\n",
      "    epoch          : 109\n",
      "    loss           : 12414.503371200371\n",
      "    val_loss       : 12418.430341545813\n",
      "    val_log_likelihood: -12333.490561026676\n",
      "    val_log_marginal: -12338.964399980225\n",
      "Train Epoch: 110 [256/118836 (0%)] Loss: 12540.149414\n",
      "Train Epoch: 110 [33024/118836 (28%)] Loss: 12414.856445\n",
      "Train Epoch: 110 [65792/118836 (55%)] Loss: 12431.946289\n",
      "Train Epoch: 110 [98560/118836 (83%)] Loss: 12512.560547\n",
      "    epoch          : 110\n",
      "    loss           : 12416.930305585713\n",
      "    val_loss       : 12415.088728992308\n",
      "    val_log_likelihood: -12332.604283143351\n",
      "    val_log_marginal: -12338.122128298002\n",
      "Train Epoch: 111 [256/118836 (0%)] Loss: 12381.871094\n",
      "Train Epoch: 111 [33024/118836 (28%)] Loss: 12417.893555\n",
      "Train Epoch: 111 [65792/118836 (55%)] Loss: 12417.764648\n",
      "Train Epoch: 111 [98560/118836 (83%)] Loss: 12399.243164\n",
      "    epoch          : 111\n",
      "    loss           : 12414.1912311311\n",
      "    val_loss       : 12414.70486350183\n",
      "    val_log_likelihood: -12333.277118550972\n",
      "    val_log_marginal: -12338.75652174271\n",
      "Train Epoch: 112 [256/118836 (0%)] Loss: 12419.306641\n",
      "Train Epoch: 112 [33024/118836 (28%)] Loss: 12415.989258\n",
      "Train Epoch: 112 [65792/118836 (55%)] Loss: 12411.316406\n",
      "Train Epoch: 112 [98560/118836 (83%)] Loss: 12403.712891\n",
      "    epoch          : 112\n",
      "    loss           : 12415.814006604114\n",
      "    val_loss       : 12414.045451561113\n",
      "    val_log_likelihood: -12332.160883381152\n",
      "    val_log_marginal: -12337.90149626256\n",
      "Train Epoch: 113 [256/118836 (0%)] Loss: 12426.383789\n",
      "Train Epoch: 113 [33024/118836 (28%)] Loss: 12425.570312\n",
      "Train Epoch: 113 [65792/118836 (55%)] Loss: 12459.898438\n",
      "Train Epoch: 113 [98560/118836 (83%)] Loss: 12448.840820\n",
      "    epoch          : 113\n",
      "    loss           : 12414.815895271144\n",
      "    val_loss       : 12414.635648394105\n",
      "    val_log_likelihood: -12332.87915131953\n",
      "    val_log_marginal: -12338.91626761499\n",
      "Train Epoch: 114 [256/118836 (0%)] Loss: 12393.816406\n",
      "Train Epoch: 114 [33024/118836 (28%)] Loss: 12505.699219\n",
      "Train Epoch: 114 [65792/118836 (55%)] Loss: 12371.117188\n",
      "Train Epoch: 114 [98560/118836 (83%)] Loss: 12466.474609\n",
      "    epoch          : 114\n",
      "    loss           : 12405.89719825915\n",
      "    val_loss       : 12402.731548788166\n",
      "    val_log_likelihood: -12323.06933868383\n",
      "    val_log_marginal: -12328.767051367488\n",
      "Train Epoch: 115 [256/118836 (0%)] Loss: 12484.166016\n",
      "Train Epoch: 115 [33024/118836 (28%)] Loss: 12400.645508\n",
      "Train Epoch: 115 [65792/118836 (55%)] Loss: 12358.566406\n",
      "Train Epoch: 115 [98560/118836 (83%)] Loss: 12475.492188\n",
      "    epoch          : 115\n",
      "    loss           : 12405.656777133736\n",
      "    val_loss       : 12404.505344526378\n",
      "    val_log_likelihood: -12321.147999541201\n",
      "    val_log_marginal: -12327.084656502493\n",
      "Train Epoch: 116 [256/118836 (0%)] Loss: 12500.611328\n",
      "Train Epoch: 116 [33024/118836 (28%)] Loss: 12393.413086\n",
      "Train Epoch: 116 [65792/118836 (55%)] Loss: 12370.801758\n",
      "Train Epoch: 116 [98560/118836 (83%)] Loss: 12335.636719\n",
      "    epoch          : 116\n",
      "    loss           : 12400.662403555367\n",
      "    val_loss       : 12403.711425165526\n",
      "    val_log_likelihood: -12318.784701490125\n",
      "    val_log_marginal: -12324.505700587797\n",
      "Train Epoch: 117 [256/118836 (0%)] Loss: 12398.720703\n",
      "Train Epoch: 117 [33024/118836 (28%)] Loss: 12491.301758\n",
      "Train Epoch: 117 [65792/118836 (55%)] Loss: 12470.741211\n",
      "Train Epoch: 117 [98560/118836 (83%)] Loss: 12417.953125\n",
      "    epoch          : 117\n",
      "    loss           : 12399.774011482888\n",
      "    val_loss       : 12402.251947018885\n",
      "    val_log_likelihood: -12319.288524865591\n",
      "    val_log_marginal: -12325.043116241806\n",
      "Train Epoch: 118 [256/118836 (0%)] Loss: 12395.695312\n",
      "Train Epoch: 118 [33024/118836 (28%)] Loss: 12429.016602\n",
      "Train Epoch: 118 [65792/118836 (55%)] Loss: 12450.520508\n",
      "Train Epoch: 118 [98560/118836 (83%)] Loss: 12416.740234\n",
      "    epoch          : 118\n",
      "    loss           : 12401.630113181089\n",
      "    val_loss       : 12400.165423222155\n",
      "    val_log_likelihood: -12319.31082716217\n",
      "    val_log_marginal: -12325.123519105686\n",
      "Train Epoch: 119 [256/118836 (0%)] Loss: 12413.002930\n",
      "Train Epoch: 119 [33024/118836 (28%)] Loss: 12418.949219\n",
      "Train Epoch: 119 [65792/118836 (55%)] Loss: 12434.593750\n",
      "Train Epoch: 119 [98560/118836 (83%)] Loss: 12416.500000\n",
      "    epoch          : 119\n",
      "    loss           : 12393.780024813897\n",
      "    val_loss       : 12402.182430905525\n",
      "    val_log_likelihood: -12317.533516691223\n",
      "    val_log_marginal: -12323.284003685372\n",
      "Train Epoch: 120 [256/118836 (0%)] Loss: 12456.478516\n",
      "Train Epoch: 120 [33024/118836 (28%)] Loss: 12425.445312\n",
      "Train Epoch: 120 [65792/118836 (55%)] Loss: 12461.598633\n",
      "Train Epoch: 120 [98560/118836 (83%)] Loss: 12433.263672\n",
      "    epoch          : 120\n",
      "    loss           : 12398.425755240643\n",
      "    val_loss       : 12402.92779022746\n",
      "    val_log_likelihood: -12318.432142234027\n",
      "    val_log_marginal: -12324.072416850373\n",
      "Train Epoch: 121 [256/118836 (0%)] Loss: 12508.616211\n",
      "Train Epoch: 121 [33024/118836 (28%)] Loss: 12512.474609\n",
      "Train Epoch: 121 [65792/118836 (55%)] Loss: 12361.371094\n",
      "Train Epoch: 121 [98560/118836 (83%)] Loss: 12452.449219\n",
      "    epoch          : 121\n",
      "    loss           : 12409.283096825888\n",
      "    val_loss       : 12410.665203944025\n",
      "    val_log_likelihood: -12324.43526788022\n",
      "    val_log_marginal: -12330.807014920987\n",
      "Train Epoch: 122 [256/118836 (0%)] Loss: 12467.490234\n",
      "Train Epoch: 122 [33024/118836 (28%)] Loss: 12430.081055\n",
      "Train Epoch: 122 [65792/118836 (55%)] Loss: 12388.006836\n",
      "Train Epoch: 122 [98560/118836 (83%)] Loss: 12438.279297\n",
      "    epoch          : 122\n",
      "    loss           : 12403.915963283189\n",
      "    val_loss       : 12400.755984261084\n",
      "    val_log_likelihood: -12319.279003663925\n",
      "    val_log_marginal: -12324.97886314223\n",
      "Train Epoch: 123 [256/118836 (0%)] Loss: 12429.204102\n",
      "Train Epoch: 123 [33024/118836 (28%)] Loss: 12428.775391\n",
      "Train Epoch: 123 [65792/118836 (55%)] Loss: 12409.429688\n",
      "Train Epoch: 123 [98560/118836 (83%)] Loss: 12503.503906\n",
      "    epoch          : 123\n",
      "    loss           : 12397.296927988007\n",
      "    val_loss       : 12398.97187692502\n",
      "    val_log_likelihood: -12319.671408770162\n",
      "    val_log_marginal: -12325.292341942675\n",
      "Train Epoch: 124 [256/118836 (0%)] Loss: 12409.690430\n",
      "Train Epoch: 124 [33024/118836 (28%)] Loss: 12343.240234\n",
      "Train Epoch: 124 [65792/118836 (55%)] Loss: 12477.437500\n",
      "Train Epoch: 124 [98560/118836 (83%)] Loss: 12519.639648\n",
      "    epoch          : 124\n",
      "    loss           : 12399.394349992244\n",
      "    val_loss       : 12401.062613297174\n",
      "    val_log_likelihood: -12317.908430747259\n",
      "    val_log_marginal: -12323.544805462237\n",
      "Train Epoch: 125 [256/118836 (0%)] Loss: 12310.701172\n",
      "Train Epoch: 125 [33024/118836 (28%)] Loss: 12417.234375\n",
      "Train Epoch: 125 [65792/118836 (55%)] Loss: 12352.923828\n",
      "Train Epoch: 125 [98560/118836 (83%)] Loss: 12433.577148\n",
      "    epoch          : 125\n",
      "    loss           : 12401.490644385856\n",
      "    val_loss       : 12400.758192899215\n",
      "    val_log_likelihood: -12320.417438546836\n",
      "    val_log_marginal: -12326.017575752965\n",
      "Train Epoch: 126 [256/118836 (0%)] Loss: 12424.761719\n",
      "Train Epoch: 126 [33024/118836 (28%)] Loss: 12433.177734\n",
      "Train Epoch: 126 [65792/118836 (55%)] Loss: 12505.224609\n",
      "Train Epoch: 126 [98560/118836 (83%)] Loss: 12424.820312\n",
      "    epoch          : 126\n",
      "    loss           : 12401.001888828576\n",
      "    val_loss       : 12398.397834495161\n",
      "    val_log_likelihood: -12317.15650734724\n",
      "    val_log_marginal: -12322.828489826079\n",
      "Train Epoch: 127 [256/118836 (0%)] Loss: 12347.574219\n",
      "Train Epoch: 127 [33024/118836 (28%)] Loss: 12397.166016\n",
      "Train Epoch: 127 [65792/118836 (55%)] Loss: 12477.603516\n",
      "Train Epoch: 127 [98560/118836 (83%)] Loss: 12405.667969\n",
      "    epoch          : 127\n",
      "    loss           : 12399.392587010183\n",
      "    val_loss       : 12395.88208805713\n",
      "    val_log_likelihood: -12316.383881468413\n",
      "    val_log_marginal: -12322.107620346353\n",
      "Train Epoch: 128 [256/118836 (0%)] Loss: 12410.352539\n",
      "Train Epoch: 128 [33024/118836 (28%)] Loss: 12455.776367\n",
      "Train Epoch: 128 [65792/118836 (55%)] Loss: 12420.029297\n",
      "Train Epoch: 128 [98560/118836 (83%)] Loss: 12414.540039\n",
      "    epoch          : 128\n",
      "    loss           : 12399.736307123656\n",
      "    val_loss       : 12400.373036943809\n",
      "    val_log_likelihood: -12319.344982132703\n",
      "    val_log_marginal: -12325.012235165823\n",
      "Train Epoch: 129 [256/118836 (0%)] Loss: 12401.638672\n",
      "Train Epoch: 129 [33024/118836 (28%)] Loss: 12423.476562\n",
      "Train Epoch: 129 [65792/118836 (55%)] Loss: 12445.784180\n",
      "Train Epoch: 129 [98560/118836 (83%)] Loss: 12394.297852\n",
      "    epoch          : 129\n",
      "    loss           : 12394.329966333231\n",
      "    val_loss       : 12397.546907586351\n",
      "    val_log_likelihood: -12317.401308545286\n",
      "    val_log_marginal: -12322.993849195951\n",
      "Train Epoch: 130 [256/118836 (0%)] Loss: 12382.316406\n",
      "Train Epoch: 130 [33024/118836 (28%)] Loss: 12386.195312\n",
      "Train Epoch: 130 [65792/118836 (55%)] Loss: 12456.167969\n",
      "Train Epoch: 130 [98560/118836 (83%)] Loss: 12394.628906\n",
      "    epoch          : 130\n",
      "    loss           : 12396.3926251357\n",
      "    val_loss       : 12397.805913995755\n",
      "    val_log_likelihood: -12315.56498655914\n",
      "    val_log_marginal: -12321.412319161847\n",
      "Train Epoch: 131 [256/118836 (0%)] Loss: 12383.614258\n",
      "Train Epoch: 131 [33024/118836 (28%)] Loss: 12494.204102\n",
      "Train Epoch: 131 [65792/118836 (55%)] Loss: 12433.917969\n",
      "Train Epoch: 131 [98560/118836 (83%)] Loss: 12482.618164\n",
      "    epoch          : 131\n",
      "    loss           : 12398.706840299319\n",
      "    val_loss       : 12396.428980839959\n",
      "    val_log_likelihood: -12313.72132266465\n",
      "    val_log_marginal: -12320.095176809884\n",
      "Train Epoch: 132 [256/118836 (0%)] Loss: 12459.711914\n",
      "Train Epoch: 132 [33024/118836 (28%)] Loss: 12352.389648\n",
      "Train Epoch: 132 [65792/118836 (55%)] Loss: 12392.164062\n",
      "Train Epoch: 132 [98560/118836 (83%)] Loss: 12486.275391\n",
      "    epoch          : 132\n",
      "    loss           : 12394.614743266646\n",
      "    val_loss       : 12396.555490493103\n",
      "    val_log_likelihood: -12312.111319562913\n",
      "    val_log_marginal: -12318.272225853158\n",
      "Train Epoch: 133 [256/118836 (0%)] Loss: 12377.350586\n",
      "Train Epoch: 133 [33024/118836 (28%)] Loss: 12366.535156\n",
      "Train Epoch: 133 [65792/118836 (55%)] Loss: 12415.692383\n",
      "Train Epoch: 133 [98560/118836 (83%)] Loss: 12394.502930\n",
      "    epoch          : 133\n",
      "    loss           : 12404.429014326148\n",
      "    val_loss       : 12394.266770796165\n",
      "    val_log_likelihood: -12319.977868298956\n",
      "    val_log_marginal: -12326.109714749482\n",
      "Train Epoch: 134 [256/118836 (0%)] Loss: 12385.370117\n",
      "Train Epoch: 134 [33024/118836 (28%)] Loss: 12464.410156\n",
      "Train Epoch: 134 [65792/118836 (55%)] Loss: 12442.491211\n",
      "Train Epoch: 134 [98560/118836 (83%)] Loss: 12465.593750\n",
      "    epoch          : 134\n",
      "    loss           : 12393.257989557485\n",
      "    val_loss       : 12392.013519379405\n",
      "    val_log_likelihood: -12313.348122156742\n",
      "    val_log_marginal: -12319.435008015718\n",
      "Train Epoch: 135 [256/118836 (0%)] Loss: 12336.047852\n",
      "Train Epoch: 135 [33024/118836 (28%)] Loss: 12447.951172\n",
      "Train Epoch: 135 [65792/118836 (55%)] Loss: 12380.333984\n",
      "Train Epoch: 135 [98560/118836 (83%)] Loss: 12382.037109\n",
      "    epoch          : 135\n",
      "    loss           : 12390.234937512925\n",
      "    val_loss       : 12390.293084121604\n",
      "    val_log_likelihood: -12312.809050286909\n",
      "    val_log_marginal: -12318.879556057087\n",
      "Train Epoch: 136 [256/118836 (0%)] Loss: 12437.832031\n",
      "Train Epoch: 136 [33024/118836 (28%)] Loss: 12385.255859\n",
      "Train Epoch: 136 [65792/118836 (55%)] Loss: 12375.712891\n",
      "Train Epoch: 136 [98560/118836 (83%)] Loss: 12377.615234\n",
      "    epoch          : 136\n",
      "    loss           : 12392.313159603753\n",
      "    val_loss       : 12391.071174117302\n",
      "    val_log_likelihood: -12312.14825688844\n",
      "    val_log_marginal: -12318.184992211747\n",
      "Train Epoch: 137 [256/118836 (0%)] Loss: 12401.931641\n",
      "Train Epoch: 137 [33024/118836 (28%)] Loss: 12386.862305\n",
      "Train Epoch: 137 [65792/118836 (55%)] Loss: 12399.568359\n",
      "Train Epoch: 137 [98560/118836 (83%)] Loss: 12434.177734\n",
      "    epoch          : 137\n",
      "    loss           : 12393.564457486818\n",
      "    val_loss       : 12391.918606251633\n",
      "    val_log_likelihood: -12311.57367449209\n",
      "    val_log_marginal: -12317.522076470517\n",
      "Train Epoch: 138 [256/118836 (0%)] Loss: 12360.352539\n",
      "Train Epoch: 138 [33024/118836 (28%)] Loss: 12445.193359\n",
      "Train Epoch: 138 [65792/118836 (55%)] Loss: 12447.125977\n",
      "Train Epoch: 138 [98560/118836 (83%)] Loss: 12525.462891\n",
      "    epoch          : 138\n",
      "    loss           : 12392.005364389475\n",
      "    val_loss       : 12388.268479180624\n",
      "    val_log_likelihood: -12311.785907128826\n",
      "    val_log_marginal: -12317.823381481232\n",
      "Train Epoch: 139 [256/118836 (0%)] Loss: 12511.353516\n",
      "Train Epoch: 139 [33024/118836 (28%)] Loss: 12475.877930\n",
      "Train Epoch: 139 [65792/118836 (55%)] Loss: 12491.461914\n",
      "Train Epoch: 139 [98560/118836 (83%)] Loss: 12311.348633\n",
      "    epoch          : 139\n",
      "    loss           : 12391.796732675506\n",
      "    val_loss       : 12393.861206840353\n",
      "    val_log_likelihood: -12317.894419296681\n",
      "    val_log_marginal: -12324.088135543534\n",
      "Train Epoch: 140 [256/118836 (0%)] Loss: 12473.348633\n",
      "Train Epoch: 140 [33024/118836 (28%)] Loss: 12437.232422\n",
      "Train Epoch: 140 [65792/118836 (55%)] Loss: 12424.789062\n",
      "Train Epoch: 140 [98560/118836 (83%)] Loss: 12433.585938\n",
      "    epoch          : 140\n",
      "    loss           : 12392.961583049006\n",
      "    val_loss       : 12389.536622940523\n",
      "    val_log_likelihood: -12314.124317617867\n",
      "    val_log_marginal: -12320.131771756178\n",
      "Train Epoch: 141 [256/118836 (0%)] Loss: 12402.493164\n",
      "Train Epoch: 141 [33024/118836 (28%)] Loss: 12420.046875\n",
      "Train Epoch: 141 [65792/118836 (55%)] Loss: 12439.123047\n",
      "Train Epoch: 141 [98560/118836 (83%)] Loss: 12410.820312\n",
      "    epoch          : 141\n",
      "    loss           : 12395.191673936362\n",
      "    val_loss       : 12390.046190706571\n",
      "    val_log_likelihood: -12313.807074545079\n",
      "    val_log_marginal: -12319.788421598707\n",
      "Train Epoch: 142 [256/118836 (0%)] Loss: 12343.311523\n",
      "Train Epoch: 142 [33024/118836 (28%)] Loss: 12396.992188\n",
      "Train Epoch: 142 [65792/118836 (55%)] Loss: 12411.093750\n",
      "Train Epoch: 142 [98560/118836 (83%)] Loss: 12361.358398\n",
      "    epoch          : 142\n",
      "    loss           : 12390.906826890767\n",
      "    val_loss       : 12388.119045545202\n",
      "    val_log_likelihood: -12312.637902418064\n",
      "    val_log_marginal: -12318.649397915713\n",
      "Train Epoch: 143 [256/118836 (0%)] Loss: 12415.109375\n",
      "Train Epoch: 143 [33024/118836 (28%)] Loss: 12403.801758\n",
      "Train Epoch: 143 [65792/118836 (55%)] Loss: 12396.863281\n",
      "Train Epoch: 143 [98560/118836 (83%)] Loss: 12477.238281\n",
      "    epoch          : 143\n",
      "    loss           : 12388.578404156327\n",
      "    val_loss       : 12387.360220015194\n",
      "    val_log_likelihood: -12310.986199693703\n",
      "    val_log_marginal: -12317.063787182768\n",
      "Train Epoch: 144 [256/118836 (0%)] Loss: 12433.971680\n",
      "Train Epoch: 144 [33024/118836 (28%)] Loss: 12375.059570\n",
      "Train Epoch: 144 [65792/118836 (55%)] Loss: 12346.889648\n",
      "Train Epoch: 144 [98560/118836 (83%)] Loss: 12406.516602\n",
      "    epoch          : 144\n",
      "    loss           : 12387.257632211538\n",
      "    val_loss       : 12386.276533561488\n",
      "    val_log_likelihood: -12314.587176256204\n",
      "    val_log_marginal: -12320.580973020065\n",
      "Train Epoch: 145 [256/118836 (0%)] Loss: 12454.916016\n",
      "Train Epoch: 145 [33024/118836 (28%)] Loss: 12517.255859\n",
      "Train Epoch: 145 [65792/118836 (55%)] Loss: 12336.264648\n",
      "Train Epoch: 145 [98560/118836 (83%)] Loss: 12518.568359\n",
      "    epoch          : 145\n",
      "    loss           : 12388.362009537841\n",
      "    val_loss       : 12391.13844091073\n",
      "    val_log_likelihood: -12307.035573045905\n",
      "    val_log_marginal: -12312.962065814978\n",
      "Train Epoch: 146 [256/118836 (0%)] Loss: 12464.204102\n",
      "Train Epoch: 146 [33024/118836 (28%)] Loss: 12415.154297\n",
      "Train Epoch: 146 [65792/118836 (55%)] Loss: 12402.187500\n",
      "Train Epoch: 146 [98560/118836 (83%)] Loss: 12441.026367\n",
      "    epoch          : 146\n",
      "    loss           : 12389.345086493227\n",
      "    val_loss       : 12385.333468266563\n",
      "    val_log_likelihood: -12308.6313847317\n",
      "    val_log_marginal: -12314.549806579074\n",
      "Train Epoch: 147 [256/118836 (0%)] Loss: 12400.392578\n",
      "Train Epoch: 147 [33024/118836 (28%)] Loss: 12368.517578\n",
      "Train Epoch: 147 [65792/118836 (55%)] Loss: 12381.453125\n",
      "Train Epoch: 147 [98560/118836 (83%)] Loss: 12361.336914\n",
      "    epoch          : 147\n",
      "    loss           : 12382.894780681348\n",
      "    val_loss       : 12385.806997429301\n",
      "    val_log_likelihood: -12307.271222504394\n",
      "    val_log_marginal: -12313.282337784189\n",
      "Train Epoch: 148 [256/118836 (0%)] Loss: 12324.248047\n",
      "Train Epoch: 148 [33024/118836 (28%)] Loss: 12388.661133\n",
      "Train Epoch: 148 [65792/118836 (55%)] Loss: 12472.173828\n",
      "Train Epoch: 148 [98560/118836 (83%)] Loss: 12341.951172\n",
      "    epoch          : 148\n",
      "    loss           : 12385.471890993333\n",
      "    val_loss       : 12383.03502449033\n",
      "    val_log_likelihood: -12306.61543921888\n",
      "    val_log_marginal: -12312.643618474913\n",
      "Train Epoch: 149 [256/118836 (0%)] Loss: 12363.605469\n",
      "Train Epoch: 149 [33024/118836 (28%)] Loss: 12381.339844\n",
      "Train Epoch: 149 [65792/118836 (55%)] Loss: 12432.176758\n",
      "Train Epoch: 149 [98560/118836 (83%)] Loss: 12397.631836\n",
      "    epoch          : 149\n",
      "    loss           : 12390.166708346258\n",
      "    val_loss       : 12382.674049925\n",
      "    val_log_likelihood: -12309.582791175559\n",
      "    val_log_marginal: -12315.532675366188\n",
      "Train Epoch: 150 [256/118836 (0%)] Loss: 12387.205078\n",
      "Train Epoch: 150 [33024/118836 (28%)] Loss: 12390.103516\n",
      "Train Epoch: 150 [65792/118836 (55%)] Loss: 12459.653320\n",
      "Train Epoch: 150 [98560/118836 (83%)] Loss: 12462.344727\n",
      "    epoch          : 150\n",
      "    loss           : 12386.26483405707\n",
      "    val_loss       : 12384.130606553015\n",
      "    val_log_likelihood: -12305.856008161447\n",
      "    val_log_marginal: -12311.856455198114\n",
      "Train Epoch: 151 [256/118836 (0%)] Loss: 12365.224609\n",
      "Train Epoch: 151 [33024/118836 (28%)] Loss: 12361.615234\n",
      "Train Epoch: 151 [65792/118836 (55%)] Loss: 12429.730469\n",
      "Train Epoch: 151 [98560/118836 (83%)] Loss: 12408.333008\n",
      "    epoch          : 151\n",
      "    loss           : 12382.694018171009\n",
      "    val_loss       : 12385.318179398271\n",
      "    val_log_likelihood: -12305.800667519645\n",
      "    val_log_marginal: -12311.76261890195\n",
      "Train Epoch: 152 [256/118836 (0%)] Loss: 12379.425781\n",
      "Train Epoch: 152 [33024/118836 (28%)] Loss: 12429.516602\n",
      "Train Epoch: 152 [65792/118836 (55%)] Loss: 12449.589844\n",
      "Train Epoch: 152 [98560/118836 (83%)] Loss: 12469.802734\n",
      "    epoch          : 152\n",
      "    loss           : 12384.373347678868\n",
      "    val_loss       : 12385.094458655516\n",
      "    val_log_likelihood: -12303.953990416925\n",
      "    val_log_marginal: -12309.82470859627\n",
      "Train Epoch: 153 [256/118836 (0%)] Loss: 12409.908203\n",
      "Train Epoch: 153 [33024/118836 (28%)] Loss: 12398.775391\n",
      "Train Epoch: 153 [65792/118836 (55%)] Loss: 12395.437500\n",
      "Train Epoch: 153 [98560/118836 (83%)] Loss: 12440.408203\n",
      "    epoch          : 153\n",
      "    loss           : 12384.651548122156\n",
      "    val_loss       : 12384.767012382757\n",
      "    val_log_likelihood: -12304.694449829405\n",
      "    val_log_marginal: -12310.599361477494\n",
      "Train Epoch: 154 [256/118836 (0%)] Loss: 12360.564453\n",
      "Train Epoch: 154 [33024/118836 (28%)] Loss: 12397.584961\n",
      "Train Epoch: 154 [65792/118836 (55%)] Loss: 12439.350586\n",
      "Train Epoch: 154 [98560/118836 (83%)] Loss: 12426.379883\n",
      "    epoch          : 154\n",
      "    loss           : 12383.604791052781\n",
      "    val_loss       : 12384.669327525866\n",
      "    val_log_likelihood: -12305.073860919407\n",
      "    val_log_marginal: -12310.956531384076\n",
      "Train Epoch: 155 [256/118836 (0%)] Loss: 12343.792969\n",
      "Train Epoch: 155 [33024/118836 (28%)] Loss: 12338.054688\n",
      "Train Epoch: 155 [65792/118836 (55%)] Loss: 12390.457031\n",
      "Train Epoch: 155 [98560/118836 (83%)] Loss: 12343.148438\n",
      "    epoch          : 155\n",
      "    loss           : 12385.09011563663\n",
      "    val_loss       : 12384.359855728113\n",
      "    val_log_likelihood: -12303.886491450838\n",
      "    val_log_marginal: -12309.745509078764\n",
      "Train Epoch: 156 [256/118836 (0%)] Loss: 12426.413086\n",
      "Train Epoch: 156 [33024/118836 (28%)] Loss: 12482.927734\n",
      "Train Epoch: 156 [65792/118836 (55%)] Loss: 12438.536133\n",
      "Train Epoch: 156 [98560/118836 (83%)] Loss: 12478.053711\n",
      "    epoch          : 156\n",
      "    loss           : 12382.030428201251\n",
      "    val_loss       : 12382.957063087002\n",
      "    val_log_likelihood: -12305.076837294511\n",
      "    val_log_marginal: -12310.977608818741\n",
      "Train Epoch: 157 [256/118836 (0%)] Loss: 12545.609375\n",
      "Train Epoch: 157 [33024/118836 (28%)] Loss: 12405.534180\n",
      "Train Epoch: 157 [65792/118836 (55%)] Loss: 12411.267578\n",
      "Train Epoch: 157 [98560/118836 (83%)] Loss: 12352.943359\n",
      "    epoch          : 157\n",
      "    loss           : 12384.584915542286\n",
      "    val_loss       : 12385.386285196048\n",
      "    val_log_likelihood: -12301.00093084419\n",
      "    val_log_marginal: -12306.856477263873\n",
      "Train Epoch: 158 [256/118836 (0%)] Loss: 12496.662109\n",
      "Train Epoch: 158 [33024/118836 (28%)] Loss: 12347.682617\n",
      "Train Epoch: 158 [65792/118836 (55%)] Loss: 12435.777344\n",
      "Train Epoch: 158 [98560/118836 (83%)] Loss: 12323.193359\n",
      "    epoch          : 158\n",
      "    loss           : 12387.11133620244\n",
      "    val_loss       : 12386.161493512684\n",
      "    val_log_likelihood: -12302.489704656482\n",
      "    val_log_marginal: -12309.155347135216\n",
      "Train Epoch: 159 [256/118836 (0%)] Loss: 12347.111328\n",
      "Train Epoch: 159 [33024/118836 (28%)] Loss: 12362.598633\n",
      "Train Epoch: 159 [65792/118836 (55%)] Loss: 12369.351562\n",
      "Train Epoch: 159 [98560/118836 (83%)] Loss: 12448.250000\n",
      "    epoch          : 159\n",
      "    loss           : 12383.665096735422\n",
      "    val_loss       : 12384.068940547237\n",
      "    val_log_likelihood: -12298.420227525332\n",
      "    val_log_marginal: -12304.983559613094\n",
      "Train Epoch: 160 [256/118836 (0%)] Loss: 12321.395508\n",
      "Train Epoch: 160 [33024/118836 (28%)] Loss: 12504.598633\n",
      "Train Epoch: 160 [65792/118836 (55%)] Loss: 12421.812500\n",
      "Train Epoch: 160 [98560/118836 (83%)] Loss: 12425.181641\n",
      "    epoch          : 160\n",
      "    loss           : 12384.187045240125\n",
      "    val_loss       : 12384.787121237156\n",
      "    val_log_likelihood: -12298.576512419872\n",
      "    val_log_marginal: -12305.071521486025\n",
      "Train Epoch: 161 [256/118836 (0%)] Loss: 12525.355469\n",
      "Train Epoch: 161 [33024/118836 (28%)] Loss: 12480.338867\n",
      "Train Epoch: 161 [65792/118836 (55%)] Loss: 12465.525391\n",
      "Train Epoch: 161 [98560/118836 (83%)] Loss: 12317.500977\n",
      "    epoch          : 161\n",
      "    loss           : 12382.573623765767\n",
      "    val_loss       : 12385.512417970906\n",
      "    val_log_likelihood: -12296.198258019283\n",
      "    val_log_marginal: -12302.444660713474\n",
      "Train Epoch: 162 [256/118836 (0%)] Loss: 12471.465820\n",
      "Train Epoch: 162 [33024/118836 (28%)] Loss: 12383.019531\n",
      "Train Epoch: 162 [65792/118836 (55%)] Loss: 12434.640625\n",
      "Train Epoch: 162 [98560/118836 (83%)] Loss: 12396.613281\n",
      "    epoch          : 162\n",
      "    loss           : 12382.706617846618\n",
      "    val_loss       : 12384.079586727408\n",
      "    val_log_likelihood: -12296.581516393973\n",
      "    val_log_marginal: -12302.933708621189\n",
      "Train Epoch: 163 [256/118836 (0%)] Loss: 12382.926758\n",
      "Train Epoch: 163 [33024/118836 (28%)] Loss: 12446.773438\n",
      "Train Epoch: 163 [65792/118836 (55%)] Loss: 12404.512695\n",
      "Train Epoch: 163 [98560/118836 (83%)] Loss: 12379.345703\n",
      "    epoch          : 163\n",
      "    loss           : 12382.309505208334\n",
      "    val_loss       : 12384.929947470537\n",
      "    val_log_likelihood: -12307.089992697993\n",
      "    val_log_marginal: -12313.702918703144\n",
      "Train Epoch: 164 [256/118836 (0%)] Loss: 12406.684570\n",
      "Train Epoch: 164 [33024/118836 (28%)] Loss: 12425.234375\n",
      "Train Epoch: 164 [65792/118836 (55%)] Loss: 12403.634766\n",
      "Train Epoch: 164 [98560/118836 (83%)] Loss: 12409.839844\n",
      "    epoch          : 164\n",
      "    loss           : 12383.169375840054\n",
      "    val_loss       : 12385.486620771066\n",
      "    val_log_likelihood: -12305.181537879964\n",
      "    val_log_marginal: -12311.642718167179\n",
      "Train Epoch: 165 [256/118836 (0%)] Loss: 12418.029297\n",
      "Train Epoch: 165 [33024/118836 (28%)] Loss: 12420.864258\n",
      "Train Epoch: 165 [65792/118836 (55%)] Loss: 12470.843750\n",
      "Train Epoch: 165 [98560/118836 (83%)] Loss: 12391.878906\n",
      "    epoch          : 165\n",
      "    loss           : 12386.811135720378\n",
      "    val_loss       : 12382.37956710467\n",
      "    val_log_likelihood: -12302.230265844706\n",
      "    val_log_marginal: -12308.322352182044\n",
      "Train Epoch: 166 [256/118836 (0%)] Loss: 12462.163086\n",
      "Train Epoch: 166 [33024/118836 (28%)] Loss: 12325.793945\n",
      "Train Epoch: 166 [65792/118836 (55%)] Loss: 12338.756836\n",
      "Train Epoch: 166 [98560/118836 (83%)] Loss: 12460.110352\n",
      "    epoch          : 166\n",
      "    loss           : 12381.804812700322\n",
      "    val_loss       : 12381.760867038442\n",
      "    val_log_likelihood: -12298.587191118693\n",
      "    val_log_marginal: -12304.840001661234\n",
      "Train Epoch: 167 [256/118836 (0%)] Loss: 12422.527344\n",
      "Train Epoch: 167 [33024/118836 (28%)] Loss: 12448.479492\n",
      "Train Epoch: 167 [65792/118836 (55%)] Loss: 12450.903320\n",
      "Train Epoch: 167 [98560/118836 (83%)] Loss: 12447.100586\n",
      "    epoch          : 167\n",
      "    loss           : 12382.864345856597\n",
      "    val_loss       : 12384.516613512264\n",
      "    val_log_likelihood: -12298.13022626525\n",
      "    val_log_marginal: -12304.392982594944\n",
      "Train Epoch: 168 [256/118836 (0%)] Loss: 12398.002930\n",
      "Train Epoch: 168 [33024/118836 (28%)] Loss: 12412.166992\n",
      "Train Epoch: 168 [65792/118836 (55%)] Loss: 12423.630859\n",
      "Train Epoch: 168 [98560/118836 (83%)] Loss: 12420.311523\n",
      "    epoch          : 168\n",
      "    loss           : 12382.389237295802\n",
      "    val_loss       : 12382.602334941244\n",
      "    val_log_likelihood: -12296.527269760649\n",
      "    val_log_marginal: -12302.8108409852\n",
      "Train Epoch: 169 [256/118836 (0%)] Loss: 12417.875977\n",
      "Train Epoch: 169 [33024/118836 (28%)] Loss: 12354.940430\n",
      "Train Epoch: 169 [65792/118836 (55%)] Loss: 12416.224609\n",
      "Train Epoch: 169 [98560/118836 (83%)] Loss: 12432.093750\n",
      "    epoch          : 169\n",
      "    loss           : 12379.908159022178\n",
      "    val_loss       : 12379.60527014084\n",
      "    val_log_likelihood: -12298.13537967199\n",
      "    val_log_marginal: -12304.442213764038\n",
      "Train Epoch: 170 [256/118836 (0%)] Loss: 12433.815430\n",
      "Train Epoch: 170 [33024/118836 (28%)] Loss: 12457.866211\n",
      "Train Epoch: 170 [65792/118836 (55%)] Loss: 12363.252930\n",
      "Train Epoch: 170 [98560/118836 (83%)] Loss: 12447.332031\n",
      "    epoch          : 170\n",
      "    loss           : 12382.522134770472\n",
      "    val_loss       : 12385.752695706198\n",
      "    val_log_likelihood: -12297.830367620452\n",
      "    val_log_marginal: -12304.228941514615\n",
      "Train Epoch: 171 [256/118836 (0%)] Loss: 12397.154297\n",
      "Train Epoch: 171 [33024/118836 (28%)] Loss: 12430.226562\n",
      "Train Epoch: 171 [65792/118836 (55%)] Loss: 12415.046875\n",
      "Train Epoch: 171 [98560/118836 (83%)] Loss: 12357.106445\n",
      "    epoch          : 171\n",
      "    loss           : 12381.730564225341\n",
      "    val_loss       : 12381.019666235574\n",
      "    val_log_likelihood: -12302.37033818626\n",
      "    val_log_marginal: -12308.94700972148\n",
      "Train Epoch: 172 [256/118836 (0%)] Loss: 12387.720703\n",
      "Train Epoch: 172 [33024/118836 (28%)] Loss: 12421.825195\n",
      "Train Epoch: 172 [65792/118836 (55%)] Loss: 12386.907227\n",
      "Train Epoch: 172 [98560/118836 (83%)] Loss: 12422.341797\n",
      "    epoch          : 172\n",
      "    loss           : 12384.5866717393\n",
      "    val_loss       : 12382.822166438209\n",
      "    val_log_likelihood: -12293.771002313379\n",
      "    val_log_marginal: -12300.088310504843\n",
      "Train Epoch: 173 [256/118836 (0%)] Loss: 12379.392578\n",
      "Train Epoch: 173 [33024/118836 (28%)] Loss: 12445.074219\n",
      "Train Epoch: 173 [65792/118836 (55%)] Loss: 12340.132812\n",
      "Train Epoch: 173 [98560/118836 (83%)] Loss: 12428.115234\n",
      "    epoch          : 173\n",
      "    loss           : 12388.009548180315\n",
      "    val_loss       : 12387.018660620743\n",
      "    val_log_likelihood: -12294.60137138777\n",
      "    val_log_marginal: -12301.774355232154\n",
      "Train Epoch: 174 [256/118836 (0%)] Loss: 12448.595703\n",
      "Train Epoch: 174 [33024/118836 (28%)] Loss: 12379.096680\n",
      "Train Epoch: 174 [65792/118836 (55%)] Loss: 12554.300781\n",
      "Train Epoch: 174 [98560/118836 (83%)] Loss: 12380.476562\n",
      "    epoch          : 174\n",
      "    loss           : 12383.851141826923\n",
      "    val_loss       : 12386.061739007224\n",
      "    val_log_likelihood: -12302.026761851219\n",
      "    val_log_marginal: -12309.022494021425\n",
      "Train Epoch: 175 [256/118836 (0%)] Loss: 12388.106445\n",
      "Train Epoch: 175 [33024/118836 (28%)] Loss: 12343.296875\n",
      "Train Epoch: 175 [65792/118836 (55%)] Loss: 12406.498047\n",
      "Train Epoch: 175 [98560/118836 (83%)] Loss: 12362.937500\n",
      "    epoch          : 175\n",
      "    loss           : 12381.450217606236\n",
      "    val_loss       : 12381.811725578673\n",
      "    val_log_likelihood: -12296.959573543476\n",
      "    val_log_marginal: -12303.444842045514\n",
      "Train Epoch: 176 [256/118836 (0%)] Loss: 12395.303711\n",
      "Train Epoch: 176 [33024/118836 (28%)] Loss: 12376.585938\n",
      "Train Epoch: 176 [65792/118836 (55%)] Loss: 12298.860352\n",
      "Train Epoch: 176 [98560/118836 (83%)] Loss: 12411.396484\n",
      "    epoch          : 176\n",
      "    loss           : 12381.587269954507\n",
      "    val_loss       : 12382.820078860816\n",
      "    val_log_likelihood: -12301.320508297145\n",
      "    val_log_marginal: -12307.754171903656\n",
      "Train Epoch: 177 [256/118836 (0%)] Loss: 12466.628906\n",
      "Train Epoch: 177 [33024/118836 (28%)] Loss: 12412.202148\n",
      "Train Epoch: 177 [65792/118836 (55%)] Loss: 12432.364258\n",
      "Train Epoch: 177 [98560/118836 (83%)] Loss: 12452.769531\n",
      "    epoch          : 177\n",
      "    loss           : 12383.23280700734\n",
      "    val_loss       : 12386.471117911451\n",
      "    val_log_likelihood: -12297.819086829248\n",
      "    val_log_marginal: -12304.608000284572\n",
      "Train Epoch: 178 [256/118836 (0%)] Loss: 12322.743164\n",
      "Train Epoch: 178 [33024/118836 (28%)] Loss: 12369.009766\n",
      "Train Epoch: 178 [65792/118836 (55%)] Loss: 12392.878906\n",
      "Train Epoch: 178 [98560/118836 (83%)] Loss: 12341.070312\n",
      "    epoch          : 178\n",
      "    loss           : 12384.426494972602\n",
      "    val_loss       : 12379.625211736557\n",
      "    val_log_likelihood: -12299.293458565964\n",
      "    val_log_marginal: -12305.937455066512\n",
      "Train Epoch: 179 [256/118836 (0%)] Loss: 12400.293945\n",
      "Train Epoch: 179 [33024/118836 (28%)] Loss: 12386.322266\n",
      "Train Epoch: 179 [65792/118836 (55%)] Loss: 12457.098633\n",
      "Train Epoch: 179 [98560/118836 (83%)] Loss: 12467.453125\n",
      "    epoch          : 179\n",
      "    loss           : 12382.186908892938\n",
      "    val_loss       : 12376.915617432302\n",
      "    val_log_likelihood: -12294.821281954353\n",
      "    val_log_marginal: -12301.377083501764\n",
      "Train Epoch: 180 [256/118836 (0%)] Loss: 12271.850586\n",
      "Train Epoch: 180 [33024/118836 (28%)] Loss: 12372.863281\n",
      "Train Epoch: 180 [65792/118836 (55%)] Loss: 12424.389648\n",
      "Train Epoch: 180 [98560/118836 (83%)] Loss: 12401.475586\n",
      "    epoch          : 180\n",
      "    loss           : 12379.999565918373\n",
      "    val_loss       : 12378.731098177217\n",
      "    val_log_likelihood: -12294.16837165271\n",
      "    val_log_marginal: -12300.9599204703\n",
      "Train Epoch: 181 [256/118836 (0%)] Loss: 12360.681641\n",
      "Train Epoch: 181 [33024/118836 (28%)] Loss: 12450.529297\n",
      "Train Epoch: 181 [65792/118836 (55%)] Loss: 12406.958984\n",
      "Train Epoch: 181 [98560/118836 (83%)] Loss: 12372.500977\n",
      "    epoch          : 181\n",
      "    loss           : 12382.395824771247\n",
      "    val_loss       : 12380.815335857154\n",
      "    val_log_likelihood: -12293.69675916951\n",
      "    val_log_marginal: -12300.24772296406\n",
      "Train Epoch: 182 [256/118836 (0%)] Loss: 12395.981445\n",
      "Train Epoch: 182 [33024/118836 (28%)] Loss: 12316.778320\n",
      "Train Epoch: 182 [65792/118836 (55%)] Loss: 12447.054688\n",
      "Train Epoch: 182 [98560/118836 (83%)] Loss: 12425.945312\n",
      "    epoch          : 182\n",
      "    loss           : 12381.543775363163\n",
      "    val_loss       : 12378.92345020667\n",
      "    val_log_likelihood: -12292.827667655345\n",
      "    val_log_marginal: -12299.725736370685\n",
      "Train Epoch: 183 [256/118836 (0%)] Loss: 12436.333008\n",
      "Train Epoch: 183 [33024/118836 (28%)] Loss: 12450.130859\n",
      "Train Epoch: 183 [65792/118836 (55%)] Loss: 12438.644531\n",
      "Train Epoch: 183 [98560/118836 (83%)] Loss: 12420.486328\n",
      "    epoch          : 183\n",
      "    loss           : 12383.255877953114\n",
      "    val_loss       : 12380.31433066379\n",
      "    val_log_likelihood: -12295.206034493898\n",
      "    val_log_marginal: -12302.053615221594\n",
      "Train Epoch: 184 [256/118836 (0%)] Loss: 12393.773438\n",
      "Train Epoch: 184 [33024/118836 (28%)] Loss: 12361.720703\n",
      "Train Epoch: 184 [65792/118836 (55%)] Loss: 12356.758789\n",
      "Train Epoch: 184 [98560/118836 (83%)] Loss: 12443.357422\n",
      "    epoch          : 184\n",
      "    loss           : 12381.186772868848\n",
      "    val_loss       : 12381.311998781688\n",
      "    val_log_likelihood: -12297.481756455489\n",
      "    val_log_marginal: -12304.2477655993\n",
      "Train Epoch: 185 [256/118836 (0%)] Loss: 12450.140625\n",
      "Train Epoch: 185 [33024/118836 (28%)] Loss: 12284.613281\n",
      "Train Epoch: 185 [65792/118836 (55%)] Loss: 12416.610352\n",
      "Train Epoch: 185 [98560/118836 (83%)] Loss: 12432.647461\n",
      "    epoch          : 185\n",
      "    loss           : 12381.53151138596\n",
      "    val_loss       : 12385.030215211793\n",
      "    val_log_likelihood: -12293.48795540607\n",
      "    val_log_marginal: -12300.433579606497\n",
      "Train Epoch: 186 [256/118836 (0%)] Loss: 12343.365234\n",
      "Train Epoch: 186 [33024/118836 (28%)] Loss: 12401.489258\n",
      "Train Epoch: 186 [65792/118836 (55%)] Loss: 12433.294922\n",
      "Train Epoch: 186 [98560/118836 (83%)] Loss: 12391.700195\n",
      "    epoch          : 186\n",
      "    loss           : 12378.147728785412\n",
      "    val_loss       : 12379.647568658454\n",
      "    val_log_likelihood: -12287.736443793941\n",
      "    val_log_marginal: -12294.91087081433\n",
      "Train Epoch: 187 [256/118836 (0%)] Loss: 12424.294922\n",
      "Train Epoch: 187 [33024/118836 (28%)] Loss: 12385.399414\n",
      "Train Epoch: 187 [65792/118836 (55%)] Loss: 12421.954102\n",
      "Train Epoch: 187 [98560/118836 (83%)] Loss: 12422.045898\n",
      "    epoch          : 187\n",
      "    loss           : 12377.631302826458\n",
      "    val_loss       : 12378.631120355129\n",
      "    val_log_likelihood: -12292.439393028846\n",
      "    val_log_marginal: -12299.566784069342\n",
      "Train Epoch: 188 [256/118836 (0%)] Loss: 12396.632812\n",
      "Train Epoch: 188 [33024/118836 (28%)] Loss: 12362.777344\n",
      "Train Epoch: 188 [65792/118836 (55%)] Loss: 12354.750977\n",
      "Train Epoch: 188 [98560/118836 (83%)] Loss: 12367.324219\n",
      "    epoch          : 188\n",
      "    loss           : 12374.971861268352\n",
      "    val_loss       : 12378.265515224886\n",
      "    val_log_likelihood: -12291.211045576147\n",
      "    val_log_marginal: -12298.245777135484\n",
      "Train Epoch: 189 [256/118836 (0%)] Loss: 12459.407227\n",
      "Train Epoch: 189 [33024/118836 (28%)] Loss: 12365.423828\n",
      "Train Epoch: 189 [65792/118836 (55%)] Loss: 12452.775391\n",
      "Train Epoch: 189 [98560/118836 (83%)] Loss: 12359.850586\n",
      "    epoch          : 189\n",
      "    loss           : 12380.48368906379\n",
      "    val_loss       : 12378.133730460017\n",
      "    val_log_likelihood: -12287.196800202904\n",
      "    val_log_marginal: -12294.217840538673\n",
      "Train Epoch: 190 [256/118836 (0%)] Loss: 12376.083008\n",
      "Train Epoch: 190 [33024/118836 (28%)] Loss: 12345.280273\n",
      "Train Epoch: 190 [65792/118836 (55%)] Loss: 12413.720703\n",
      "Train Epoch: 190 [98560/118836 (83%)] Loss: 12370.166016\n",
      "    epoch          : 190\n",
      "    loss           : 12379.759119591345\n",
      "    val_loss       : 12377.653317957516\n",
      "    val_log_likelihood: -12294.912968491522\n",
      "    val_log_marginal: -12302.21810711709\n",
      "Train Epoch: 191 [256/118836 (0%)] Loss: 12347.645508\n",
      "Train Epoch: 191 [33024/118836 (28%)] Loss: 12437.781250\n",
      "Train Epoch: 191 [65792/118836 (55%)] Loss: 12310.993164\n",
      "Train Epoch: 191 [98560/118836 (83%)] Loss: 12431.060547\n",
      "    epoch          : 191\n",
      "    loss           : 12382.050869617195\n",
      "    val_loss       : 12379.544972101548\n",
      "    val_log_likelihood: -12292.414179622881\n",
      "    val_log_marginal: -12299.867524851912\n",
      "Train Epoch: 192 [256/118836 (0%)] Loss: 12360.210938\n",
      "Train Epoch: 192 [33024/118836 (28%)] Loss: 12410.894531\n",
      "Train Epoch: 192 [65792/118836 (55%)] Loss: 12458.397461\n",
      "Train Epoch: 192 [98560/118836 (83%)] Loss: 12439.064453\n",
      "    epoch          : 192\n",
      "    loss           : 12380.01550900796\n",
      "    val_loss       : 12378.240120888993\n",
      "    val_log_likelihood: -12288.675714368796\n",
      "    val_log_marginal: -12295.93696991133\n",
      "Train Epoch: 193 [256/118836 (0%)] Loss: 12433.329102\n",
      "Train Epoch: 193 [33024/118836 (28%)] Loss: 12430.510742\n",
      "Train Epoch: 193 [65792/118836 (55%)] Loss: 12286.871094\n",
      "Train Epoch: 193 [98560/118836 (83%)] Loss: 12475.396484\n",
      "    epoch          : 193\n",
      "    loss           : 12378.523594686983\n",
      "    val_loss       : 12379.927455172445\n",
      "    val_log_likelihood: -12289.124557194737\n",
      "    val_log_marginal: -12296.605728450471\n",
      "Train Epoch: 194 [256/118836 (0%)] Loss: 12432.462891\n",
      "Train Epoch: 194 [33024/118836 (28%)] Loss: 12378.585938\n",
      "Train Epoch: 194 [65792/118836 (55%)] Loss: 12415.061523\n",
      "Train Epoch: 194 [98560/118836 (83%)] Loss: 12371.919922\n",
      "    epoch          : 194\n",
      "    loss           : 12378.726183183415\n",
      "    val_loss       : 12378.808454491354\n",
      "    val_log_likelihood: -12287.048498403898\n",
      "    val_log_marginal: -12294.344008811317\n",
      "Train Epoch: 195 [256/118836 (0%)] Loss: 12449.674805\n",
      "Train Epoch: 195 [33024/118836 (28%)] Loss: 12319.775391\n",
      "Train Epoch: 195 [65792/118836 (55%)] Loss: 12409.817383\n",
      "Train Epoch: 195 [98560/118836 (83%)] Loss: 12328.688477\n",
      "    epoch          : 195\n",
      "    loss           : 12375.003688320669\n",
      "    val_loss       : 12378.012752314877\n",
      "    val_log_likelihood: -12288.218048555107\n",
      "    val_log_marginal: -12295.25911655272\n",
      "Train Epoch: 196 [256/118836 (0%)] Loss: 12405.294922\n",
      "Train Epoch: 196 [33024/118836 (28%)] Loss: 12375.119141\n",
      "Train Epoch: 196 [65792/118836 (55%)] Loss: 12357.621094\n",
      "Train Epoch: 196 [98560/118836 (83%)] Loss: 12368.236328\n",
      "    epoch          : 196\n",
      "    loss           : 12376.46029243564\n",
      "    val_loss       : 12379.743113664728\n",
      "    val_log_likelihood: -12288.887154931761\n",
      "    val_log_marginal: -12296.307266160684\n",
      "Train Epoch: 197 [256/118836 (0%)] Loss: 12452.645508\n",
      "Train Epoch: 197 [33024/118836 (28%)] Loss: 12370.268555\n",
      "Train Epoch: 197 [65792/118836 (55%)] Loss: 12407.740234\n",
      "Train Epoch: 197 [98560/118836 (83%)] Loss: 12400.733398\n",
      "    epoch          : 197\n",
      "    loss           : 12377.977868137406\n",
      "    val_loss       : 12377.806034551106\n",
      "    val_log_likelihood: -12294.48227890431\n",
      "    val_log_marginal: -12301.903886092528\n",
      "Train Epoch: 198 [256/118836 (0%)] Loss: 12402.940430\n",
      "Train Epoch: 198 [33024/118836 (28%)] Loss: 12401.502930\n",
      "Train Epoch: 198 [65792/118836 (55%)] Loss: 12439.878906\n",
      "Train Epoch: 198 [98560/118836 (83%)] Loss: 12447.267578\n",
      "    epoch          : 198\n",
      "    loss           : 12377.221708927833\n",
      "    val_loss       : 12378.175141500316\n",
      "    val_log_likelihood: -12292.200184650279\n",
      "    val_log_marginal: -12299.383966424106\n",
      "Train Epoch: 199 [256/118836 (0%)] Loss: 12470.308594\n",
      "Train Epoch: 199 [33024/118836 (28%)] Loss: 12415.978516\n",
      "Train Epoch: 199 [65792/118836 (55%)] Loss: 12355.417969\n",
      "Train Epoch: 199 [98560/118836 (83%)] Loss: 12390.495117\n",
      "    epoch          : 199\n",
      "    loss           : 12376.228421603599\n",
      "    val_loss       : 12375.03121176315\n",
      "    val_log_likelihood: -12286.533450617764\n",
      "    val_log_marginal: -12293.64937249306\n",
      "Train Epoch: 200 [256/118836 (0%)] Loss: 12395.152344\n",
      "Train Epoch: 200 [33024/118836 (28%)] Loss: 12390.202148\n",
      "Train Epoch: 200 [65792/118836 (55%)] Loss: 12350.771484\n",
      "Train Epoch: 200 [98560/118836 (83%)] Loss: 12428.424805\n",
      "    epoch          : 200\n",
      "    loss           : 12376.429269573253\n",
      "    val_loss       : 12374.783032886124\n",
      "    val_log_likelihood: -12289.876804500103\n",
      "    val_log_marginal: -12297.103778600833\n",
      "Saving checkpoint: saved/models/SelfiesAutoencodingOperad/0905_154251/checkpoint-epoch200.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 201 [256/118836 (0%)] Loss: 12401.462891\n",
      "Train Epoch: 201 [33024/118836 (28%)] Loss: 12426.666016\n",
      "Train Epoch: 201 [65792/118836 (55%)] Loss: 12395.249023\n",
      "Train Epoch: 201 [98560/118836 (83%)] Loss: 12401.314453\n",
      "    epoch          : 201\n",
      "    loss           : 12378.451194653382\n",
      "    val_loss       : 12375.19772030011\n",
      "    val_log_likelihood: -12288.638182705232\n",
      "    val_log_marginal: -12295.841116891472\n",
      "Train Epoch: 202 [256/118836 (0%)] Loss: 12479.839844\n",
      "Train Epoch: 202 [33024/118836 (28%)] Loss: 12430.801758\n",
      "Train Epoch: 202 [65792/118836 (55%)] Loss: 12363.765625\n",
      "Train Epoch: 202 [98560/118836 (83%)] Loss: 12362.472656\n",
      "    epoch          : 202\n",
      "    loss           : 12374.073531521402\n",
      "    val_loss       : 12377.374530422667\n",
      "    val_log_likelihood: -12289.913755718828\n",
      "    val_log_marginal: -12297.117554114086\n",
      "Train Epoch: 203 [256/118836 (0%)] Loss: 12430.557617\n",
      "Train Epoch: 203 [33024/118836 (28%)] Loss: 12372.465820\n",
      "Train Epoch: 203 [65792/118836 (55%)] Loss: 12451.023438\n",
      "Train Epoch: 203 [98560/118836 (83%)] Loss: 12332.965820\n",
      "    epoch          : 203\n",
      "    loss           : 12373.843061155914\n",
      "    val_loss       : 12373.55265950422\n",
      "    val_log_likelihood: -12289.91440062164\n",
      "    val_log_marginal: -12297.156886248144\n",
      "Train Epoch: 204 [256/118836 (0%)] Loss: 12451.238281\n",
      "Train Epoch: 204 [33024/118836 (28%)] Loss: 12382.488281\n",
      "Train Epoch: 204 [65792/118836 (55%)] Loss: 12364.042969\n",
      "Train Epoch: 204 [98560/118836 (83%)] Loss: 12391.541992\n",
      "    epoch          : 204\n",
      "    loss           : 12374.265129691377\n",
      "    val_loss       : 12375.366727283761\n",
      "    val_log_likelihood: -12285.792436123604\n",
      "    val_log_marginal: -12292.998078752806\n",
      "Train Epoch: 205 [256/118836 (0%)] Loss: 12380.759766\n",
      "Train Epoch: 205 [33024/118836 (28%)] Loss: 12400.181641\n",
      "Train Epoch: 205 [65792/118836 (55%)] Loss: 12382.119141\n",
      "Train Epoch: 205 [98560/118836 (83%)] Loss: 12439.259766\n",
      "    epoch          : 205\n",
      "    loss           : 12376.837016807536\n",
      "    val_loss       : 12373.099909801524\n",
      "    val_log_likelihood: -12289.355685225393\n",
      "    val_log_marginal: -12296.660174607985\n",
      "Train Epoch: 206 [256/118836 (0%)] Loss: 12396.337891\n",
      "Train Epoch: 206 [33024/118836 (28%)] Loss: 12432.165039\n",
      "Train Epoch: 206 [65792/118836 (55%)] Loss: 12394.813477\n",
      "Train Epoch: 206 [98560/118836 (83%)] Loss: 12365.593750\n",
      "    epoch          : 206\n",
      "    loss           : 12373.36540157801\n",
      "    val_loss       : 12369.804282108378\n",
      "    val_log_likelihood: -12285.792536930056\n",
      "    val_log_marginal: -12293.253106269904\n",
      "Train Epoch: 207 [256/118836 (0%)] Loss: 12408.050781\n",
      "Train Epoch: 207 [33024/118836 (28%)] Loss: 12419.533203\n",
      "Train Epoch: 207 [65792/118836 (55%)] Loss: 12432.542969\n",
      "Train Epoch: 207 [98560/118836 (83%)] Loss: 12403.849609\n",
      "    epoch          : 207\n",
      "    loss           : 12370.405424647177\n",
      "    val_loss       : 12364.77441182082\n",
      "    val_log_likelihood: -12286.311211325215\n",
      "    val_log_marginal: -12293.695851816643\n",
      "Train Epoch: 208 [256/118836 (0%)] Loss: 12343.534180\n",
      "Train Epoch: 208 [33024/118836 (28%)] Loss: 12406.023438\n",
      "Train Epoch: 208 [65792/118836 (55%)] Loss: 12454.806641\n",
      "Train Epoch: 208 [98560/118836 (83%)] Loss: 12328.791992\n",
      "    epoch          : 208\n",
      "    loss           : 12368.967981835453\n",
      "    val_loss       : 12369.239518553706\n",
      "    val_log_likelihood: -12282.811567701872\n",
      "    val_log_marginal: -12290.07913449659\n",
      "Train Epoch: 209 [256/118836 (0%)] Loss: 12362.993164\n",
      "Train Epoch: 209 [33024/118836 (28%)] Loss: 12400.028320\n",
      "Train Epoch: 209 [65792/118836 (55%)] Loss: 12324.158203\n",
      "Train Epoch: 209 [98560/118836 (83%)] Loss: 12431.731445\n",
      "    epoch          : 209\n",
      "    loss           : 12370.10061146221\n",
      "    val_loss       : 12367.798710716956\n",
      "    val_log_likelihood: -12283.950901765404\n",
      "    val_log_marginal: -12291.279830819329\n",
      "Train Epoch: 210 [256/118836 (0%)] Loss: 12318.327148\n",
      "Train Epoch: 210 [33024/118836 (28%)] Loss: 12378.226562\n",
      "Train Epoch: 210 [65792/118836 (55%)] Loss: 12454.217773\n",
      "Train Epoch: 210 [98560/118836 (83%)] Loss: 12391.382812\n",
      "    epoch          : 210\n",
      "    loss           : 12369.584360622155\n",
      "    val_loss       : 12367.817844225812\n",
      "    val_log_likelihood: -12281.713768319634\n",
      "    val_log_marginal: -12289.056217148367\n",
      "Train Epoch: 211 [256/118836 (0%)] Loss: 12324.947266\n",
      "Train Epoch: 211 [33024/118836 (28%)] Loss: 12415.246094\n",
      "Train Epoch: 211 [65792/118836 (55%)] Loss: 12447.904297\n",
      "Train Epoch: 211 [98560/118836 (83%)] Loss: 12415.028320\n",
      "    epoch          : 211\n",
      "    loss           : 12364.792594926075\n",
      "    val_loss       : 12366.90554239417\n",
      "    val_log_likelihood: -12286.272329921423\n",
      "    val_log_marginal: -12293.592922561698\n",
      "Train Epoch: 212 [256/118836 (0%)] Loss: 12360.734375\n",
      "Train Epoch: 212 [33024/118836 (28%)] Loss: 12337.884766\n",
      "Train Epoch: 212 [65792/118836 (55%)] Loss: 12390.125000\n",
      "Train Epoch: 212 [98560/118836 (83%)] Loss: 12413.492188\n",
      "    epoch          : 212\n",
      "    loss           : 12370.217300422612\n",
      "    val_loss       : 12367.675981731181\n",
      "    val_log_likelihood: -12279.713804668114\n",
      "    val_log_marginal: -12287.232187846035\n",
      "Train Epoch: 213 [256/118836 (0%)] Loss: 12372.948242\n",
      "Train Epoch: 213 [33024/118836 (28%)] Loss: 12314.202148\n",
      "Train Epoch: 213 [65792/118836 (55%)] Loss: 12362.862305\n",
      "Train Epoch: 213 [98560/118836 (83%)] Loss: 12352.070312\n",
      "    epoch          : 213\n",
      "    loss           : 12364.002201587056\n",
      "    val_loss       : 12367.823661425453\n",
      "    val_log_likelihood: -12281.239974927626\n",
      "    val_log_marginal: -12288.722205039905\n",
      "Train Epoch: 214 [256/118836 (0%)] Loss: 12401.937500\n",
      "Train Epoch: 214 [33024/118836 (28%)] Loss: 12448.697266\n",
      "Train Epoch: 214 [65792/118836 (55%)] Loss: 12407.704102\n",
      "Train Epoch: 214 [98560/118836 (83%)] Loss: 12437.232422\n",
      "    epoch          : 214\n",
      "    loss           : 12365.650281256461\n",
      "    val_loss       : 12371.311955946161\n",
      "    val_log_likelihood: -12289.18709322012\n",
      "    val_log_marginal: -12296.854559530362\n",
      "Train Epoch: 215 [256/118836 (0%)] Loss: 12363.565430\n",
      "Train Epoch: 215 [33024/118836 (28%)] Loss: 12339.875000\n",
      "Train Epoch: 215 [65792/118836 (55%)] Loss: 12404.525391\n",
      "Train Epoch: 215 [98560/118836 (83%)] Loss: 12490.519531\n",
      "    epoch          : 215\n",
      "    loss           : 12371.966722562553\n",
      "    val_loss       : 12373.099174478242\n",
      "    val_log_likelihood: -12287.881422372571\n",
      "    val_log_marginal: -12295.586815609178\n",
      "Train Epoch: 216 [256/118836 (0%)] Loss: 12349.195312\n",
      "Train Epoch: 216 [33024/118836 (28%)] Loss: 12305.560547\n",
      "Train Epoch: 216 [65792/118836 (55%)] Loss: 12417.617188\n",
      "Train Epoch: 216 [98560/118836 (83%)] Loss: 12419.062500\n",
      "    epoch          : 216\n",
      "    loss           : 12363.976182375673\n",
      "    val_loss       : 12363.509191340769\n",
      "    val_log_likelihood: -12275.368746769023\n",
      "    val_log_marginal: -12283.23307825122\n",
      "Train Epoch: 217 [256/118836 (0%)] Loss: 12404.791016\n",
      "Train Epoch: 217 [33024/118836 (28%)] Loss: 12321.341797\n",
      "Train Epoch: 217 [65792/118836 (55%)] Loss: 12297.571289\n",
      "Train Epoch: 217 [98560/118836 (83%)] Loss: 12384.477539\n",
      "    epoch          : 217\n",
      "    loss           : 12363.465731137563\n",
      "    val_loss       : 12362.865114218503\n",
      "    val_log_likelihood: -12271.180116735162\n",
      "    val_log_marginal: -12279.001055818047\n",
      "Train Epoch: 218 [256/118836 (0%)] Loss: 12306.644531\n",
      "Train Epoch: 218 [33024/118836 (28%)] Loss: 12412.191406\n",
      "Train Epoch: 218 [65792/118836 (55%)] Loss: 12384.554688\n",
      "Train Epoch: 218 [98560/118836 (83%)] Loss: 12332.322266\n",
      "    epoch          : 218\n",
      "    loss           : 12358.801683500053\n",
      "    val_loss       : 12359.873202397632\n",
      "    val_log_likelihood: -12270.408481796681\n",
      "    val_log_marginal: -12278.31841228843\n",
      "Train Epoch: 219 [256/118836 (0%)] Loss: 12358.278320\n",
      "Train Epoch: 219 [33024/118836 (28%)] Loss: 12362.317383\n",
      "Train Epoch: 219 [65792/118836 (55%)] Loss: 12345.157227\n",
      "Train Epoch: 219 [98560/118836 (83%)] Loss: 12292.613281\n",
      "    epoch          : 219\n",
      "    loss           : 12364.461309546887\n",
      "    val_loss       : 12359.580455358655\n",
      "    val_log_likelihood: -12272.3000337637\n",
      "    val_log_marginal: -12279.96562690631\n",
      "Train Epoch: 220 [256/118836 (0%)] Loss: 12371.125000\n",
      "Train Epoch: 220 [33024/118836 (28%)] Loss: 12384.162109\n",
      "Train Epoch: 220 [65792/118836 (55%)] Loss: 12238.306641\n",
      "Train Epoch: 220 [98560/118836 (83%)] Loss: 12398.747070\n",
      "    epoch          : 220\n",
      "    loss           : 12358.924555256152\n",
      "    val_loss       : 12356.454050256149\n",
      "    val_log_likelihood: -12271.193619953216\n",
      "    val_log_marginal: -12278.862422325543\n",
      "Train Epoch: 221 [256/118836 (0%)] Loss: 12359.583008\n",
      "Train Epoch: 221 [33024/118836 (28%)] Loss: 12326.848633\n",
      "Train Epoch: 221 [65792/118836 (55%)] Loss: 12371.317383\n",
      "Train Epoch: 221 [98560/118836 (83%)] Loss: 12343.445312\n",
      "    epoch          : 221\n",
      "    loss           : 12358.662368660825\n",
      "    val_loss       : 12359.68935407347\n",
      "    val_log_likelihood: -12271.117323847187\n",
      "    val_log_marginal: -12278.864938370025\n",
      "Train Epoch: 222 [256/118836 (0%)] Loss: 12421.031250\n",
      "Train Epoch: 222 [33024/118836 (28%)] Loss: 12348.306641\n",
      "Train Epoch: 222 [65792/118836 (55%)] Loss: 12393.582031\n",
      "Train Epoch: 222 [98560/118836 (83%)] Loss: 12366.234375\n",
      "    epoch          : 222\n",
      "    loss           : 12358.349400007755\n",
      "    val_loss       : 12355.440686215958\n",
      "    val_log_likelihood: -12267.24537178841\n",
      "    val_log_marginal: -12274.975624146435\n",
      "Train Epoch: 223 [256/118836 (0%)] Loss: 12337.912109\n",
      "Train Epoch: 223 [33024/118836 (28%)] Loss: 12372.031250\n",
      "Train Epoch: 223 [65792/118836 (55%)] Loss: 12355.365234\n",
      "Train Epoch: 223 [98560/118836 (83%)] Loss: 12399.354492\n",
      "    epoch          : 223\n",
      "    loss           : 12353.023786606958\n",
      "    val_loss       : 12354.754025943334\n",
      "    val_log_likelihood: -12268.962086758167\n",
      "    val_log_marginal: -12276.84523681613\n",
      "Train Epoch: 224 [256/118836 (0%)] Loss: 12323.717773\n",
      "Train Epoch: 224 [33024/118836 (28%)] Loss: 12395.466797\n",
      "Train Epoch: 224 [65792/118836 (55%)] Loss: 12359.778320\n",
      "Train Epoch: 224 [98560/118836 (83%)] Loss: 12381.162109\n",
      "    epoch          : 224\n",
      "    loss           : 12352.414131642887\n",
      "    val_loss       : 12354.536180768424\n",
      "    val_log_likelihood: -12266.614899645885\n",
      "    val_log_marginal: -12274.389729918536\n",
      "Train Epoch: 225 [256/118836 (0%)] Loss: 12340.310547\n",
      "Train Epoch: 225 [33024/118836 (28%)] Loss: 12436.519531\n",
      "Train Epoch: 225 [65792/118836 (55%)] Loss: 12339.275391\n",
      "Train Epoch: 225 [98560/118836 (83%)] Loss: 12358.507812\n",
      "    epoch          : 225\n",
      "    loss           : 12355.744615740023\n",
      "    val_loss       : 12356.38791963385\n",
      "    val_log_likelihood: -12270.185113924215\n",
      "    val_log_marginal: -12277.84102839865\n",
      "Train Epoch: 226 [256/118836 (0%)] Loss: 12320.544922\n",
      "Train Epoch: 226 [33024/118836 (28%)] Loss: 12372.652344\n",
      "Train Epoch: 226 [65792/118836 (55%)] Loss: 12396.394531\n",
      "Train Epoch: 226 [98560/118836 (83%)] Loss: 12469.933594\n",
      "    epoch          : 226\n",
      "    loss           : 12354.756910734595\n",
      "    val_loss       : 12353.372628385696\n",
      "    val_log_likelihood: -12265.086681755323\n",
      "    val_log_marginal: -12272.786191022127\n",
      "Train Epoch: 227 [256/118836 (0%)] Loss: 12329.545898\n",
      "Train Epoch: 227 [33024/118836 (28%)] Loss: 12436.023438\n",
      "Train Epoch: 227 [65792/118836 (55%)] Loss: 12503.221680\n",
      "Train Epoch: 227 [98560/118836 (83%)] Loss: 12442.426758\n",
      "    epoch          : 227\n",
      "    loss           : 12357.230714950372\n",
      "    val_loss       : 12356.008959865514\n",
      "    val_log_likelihood: -12269.02550790943\n",
      "    val_log_marginal: -12276.618902905118\n",
      "Train Epoch: 228 [256/118836 (0%)] Loss: 12565.633789\n",
      "Train Epoch: 228 [33024/118836 (28%)] Loss: 12353.459961\n",
      "Train Epoch: 228 [65792/118836 (55%)] Loss: 12398.767578\n",
      "Train Epoch: 228 [98560/118836 (83%)] Loss: 12351.466797\n",
      "    epoch          : 228\n",
      "    loss           : 12354.924425855563\n",
      "    val_loss       : 12352.982771484974\n",
      "    val_log_likelihood: -12264.849151707249\n",
      "    val_log_marginal: -12272.449778124572\n",
      "Train Epoch: 229 [256/118836 (0%)] Loss: 12362.265625\n",
      "Train Epoch: 229 [33024/118836 (28%)] Loss: 12276.519531\n",
      "Train Epoch: 229 [65792/118836 (55%)] Loss: 12383.820312\n",
      "Train Epoch: 229 [98560/118836 (83%)] Loss: 12419.892578\n",
      "    epoch          : 229\n",
      "    loss           : 12355.004447923127\n",
      "    val_loss       : 12353.00137989773\n",
      "    val_log_likelihood: -12264.383582926232\n",
      "    val_log_marginal: -12271.93680293857\n",
      "Train Epoch: 230 [256/118836 (0%)] Loss: 12337.552734\n",
      "Train Epoch: 230 [33024/118836 (28%)] Loss: 12435.449219\n",
      "Train Epoch: 230 [65792/118836 (55%)] Loss: 12340.229492\n",
      "Train Epoch: 230 [98560/118836 (83%)] Loss: 12316.912109\n",
      "    epoch          : 230\n",
      "    loss           : 12354.39707305883\n",
      "    val_loss       : 12355.908054845328\n",
      "    val_log_likelihood: -12266.21124977383\n",
      "    val_log_marginal: -12273.865690042625\n",
      "Train Epoch: 231 [256/118836 (0%)] Loss: 12340.521484\n",
      "Train Epoch: 231 [33024/118836 (28%)] Loss: 12339.474609\n",
      "Train Epoch: 231 [65792/118836 (55%)] Loss: 12329.584961\n",
      "Train Epoch: 231 [98560/118836 (83%)] Loss: 12363.627930\n",
      "    epoch          : 231\n",
      "    loss           : 12356.10253647772\n",
      "    val_loss       : 12351.428235659369\n",
      "    val_log_likelihood: -12265.016724824234\n",
      "    val_log_marginal: -12272.556409491961\n",
      "Train Epoch: 232 [256/118836 (0%)] Loss: 12359.429688\n",
      "Train Epoch: 232 [33024/118836 (28%)] Loss: 12414.345703\n",
      "Train Epoch: 232 [65792/118836 (55%)] Loss: 12318.095703\n",
      "Train Epoch: 232 [98560/118836 (83%)] Loss: 12352.066406\n",
      "    epoch          : 232\n",
      "    loss           : 12353.851046513131\n",
      "    val_loss       : 12354.687159012778\n",
      "    val_log_likelihood: -12265.423194692152\n",
      "    val_log_marginal: -12272.995581853655\n",
      "Train Epoch: 233 [256/118836 (0%)] Loss: 12485.569336\n",
      "Train Epoch: 233 [33024/118836 (28%)] Loss: 12418.516602\n",
      "Train Epoch: 233 [65792/118836 (55%)] Loss: 12414.173828\n",
      "Train Epoch: 233 [98560/118836 (83%)] Loss: 12389.514648\n",
      "    epoch          : 233\n",
      "    loss           : 12353.496279208024\n",
      "    val_loss       : 12355.86928809756\n",
      "    val_log_likelihood: -12264.134744623656\n",
      "    val_log_marginal: -12271.758127546993\n",
      "Train Epoch: 234 [256/118836 (0%)] Loss: 12331.770508\n",
      "Train Epoch: 234 [33024/118836 (28%)] Loss: 12389.281250\n",
      "Train Epoch: 234 [65792/118836 (55%)] Loss: 12348.936523\n",
      "Train Epoch: 234 [98560/118836 (83%)] Loss: 12378.294922\n",
      "    epoch          : 234\n",
      "    loss           : 12354.620480349204\n",
      "    val_loss       : 12351.672062757882\n",
      "    val_log_likelihood: -12268.370062745555\n",
      "    val_log_marginal: -12275.858935828694\n",
      "Train Epoch: 235 [256/118836 (0%)] Loss: 12282.949219\n",
      "Train Epoch: 235 [33024/118836 (28%)] Loss: 12374.656250\n",
      "Train Epoch: 235 [65792/118836 (55%)] Loss: 12304.679688\n",
      "Train Epoch: 235 [98560/118836 (83%)] Loss: 12385.232422\n",
      "    epoch          : 235\n",
      "    loss           : 12354.274666563275\n",
      "    val_loss       : 12356.22156715303\n",
      "    val_log_likelihood: -12264.571185832818\n",
      "    val_log_marginal: -12272.142507422543\n",
      "Train Epoch: 236 [256/118836 (0%)] Loss: 12349.390625\n",
      "Train Epoch: 236 [33024/118836 (28%)] Loss: 12423.458984\n",
      "Train Epoch: 236 [65792/118836 (55%)] Loss: 12436.471680\n",
      "Train Epoch: 236 [98560/118836 (83%)] Loss: 12347.103516\n",
      "    epoch          : 236\n",
      "    loss           : 12356.495250303711\n",
      "    val_loss       : 12356.155677603312\n",
      "    val_log_likelihood: -12263.116264733251\n",
      "    val_log_marginal: -12270.599772625763\n",
      "Train Epoch: 237 [256/118836 (0%)] Loss: 12275.663086\n",
      "Train Epoch: 237 [33024/118836 (28%)] Loss: 12392.968750\n",
      "Train Epoch: 237 [65792/118836 (55%)] Loss: 12446.229492\n",
      "Train Epoch: 237 [98560/118836 (83%)] Loss: 12331.167969\n",
      "    epoch          : 237\n",
      "    loss           : 12354.24337827621\n",
      "    val_loss       : 12354.258668321556\n",
      "    val_log_likelihood: -12263.65345649814\n",
      "    val_log_marginal: -12271.348166269856\n",
      "Train Epoch: 238 [256/118836 (0%)] Loss: 12445.390625\n",
      "Train Epoch: 238 [33024/118836 (28%)] Loss: 12337.666016\n",
      "Train Epoch: 238 [65792/118836 (55%)] Loss: 12279.669922\n",
      "Train Epoch: 238 [98560/118836 (83%)] Loss: 12364.335938\n",
      "    epoch          : 238\n",
      "    loss           : 12351.514001757652\n",
      "    val_loss       : 12352.854774858646\n",
      "    val_log_likelihood: -12266.281003476532\n",
      "    val_log_marginal: -12273.75948593221\n",
      "Train Epoch: 239 [256/118836 (0%)] Loss: 12293.303711\n",
      "Train Epoch: 239 [33024/118836 (28%)] Loss: 12350.868164\n",
      "Train Epoch: 239 [65792/118836 (55%)] Loss: 12370.642578\n",
      "Train Epoch: 239 [98560/118836 (83%)] Loss: 12441.847656\n",
      "    epoch          : 239\n",
      "    loss           : 12353.159002953113\n",
      "    val_loss       : 12352.100616256246\n",
      "    val_log_likelihood: -12261.87539078655\n",
      "    val_log_marginal: -12269.520301555474\n",
      "Train Epoch: 240 [256/118836 (0%)] Loss: 12338.300781\n",
      "Train Epoch: 240 [33024/118836 (28%)] Loss: 12321.214844\n",
      "Train Epoch: 240 [65792/118836 (55%)] Loss: 12449.164062\n",
      "Train Epoch: 240 [98560/118836 (83%)] Loss: 12319.584961\n",
      "    epoch          : 240\n",
      "    loss           : 12352.918691680883\n",
      "    val_loss       : 12353.09949605795\n",
      "    val_log_likelihood: -12263.557098131205\n",
      "    val_log_marginal: -12271.213067296552\n",
      "Train Epoch: 241 [256/118836 (0%)] Loss: 12364.065430\n",
      "Train Epoch: 241 [33024/118836 (28%)] Loss: 12484.142578\n",
      "Train Epoch: 241 [65792/118836 (55%)] Loss: 12492.421875\n",
      "Train Epoch: 241 [98560/118836 (83%)] Loss: 12405.440430\n",
      "    epoch          : 241\n",
      "    loss           : 12349.574696126707\n",
      "    val_loss       : 12355.179656452921\n",
      "    val_log_likelihood: -12260.028823213916\n",
      "    val_log_marginal: -12267.560693724878\n",
      "Train Epoch: 242 [256/118836 (0%)] Loss: 12353.833984\n",
      "Train Epoch: 242 [33024/118836 (28%)] Loss: 12351.781250\n",
      "Train Epoch: 242 [65792/118836 (55%)] Loss: 12505.000977\n",
      "Train Epoch: 242 [98560/118836 (83%)] Loss: 12413.720703\n",
      "    epoch          : 242\n",
      "    loss           : 12350.890042455027\n",
      "    val_loss       : 12354.826518448204\n",
      "    val_log_likelihood: -12264.814076716295\n",
      "    val_log_marginal: -12272.454881856658\n",
      "Train Epoch: 243 [256/118836 (0%)] Loss: 12368.069336\n",
      "Train Epoch: 243 [33024/118836 (28%)] Loss: 12423.038086\n",
      "Train Epoch: 243 [65792/118836 (55%)] Loss: 12342.249023\n",
      "Train Epoch: 243 [98560/118836 (83%)] Loss: 12391.637695\n",
      "    epoch          : 243\n",
      "    loss           : 12350.843293463091\n",
      "    val_loss       : 12345.903161776236\n",
      "    val_log_likelihood: -12259.88723312138\n",
      "    val_log_marginal: -12267.647729712091\n",
      "Train Epoch: 244 [256/118836 (0%)] Loss: 12352.557617\n",
      "Train Epoch: 244 [33024/118836 (28%)] Loss: 12333.660156\n",
      "Train Epoch: 244 [65792/118836 (55%)] Loss: 12384.601562\n",
      "Train Epoch: 244 [98560/118836 (83%)] Loss: 12379.576172\n",
      "    epoch          : 244\n",
      "    loss           : 12344.986627798025\n",
      "    val_loss       : 12346.053636834014\n",
      "    val_log_likelihood: -12261.16031796035\n",
      "    val_log_marginal: -12268.750614550318\n",
      "Train Epoch: 245 [256/118836 (0%)] Loss: 12356.165039\n",
      "Train Epoch: 245 [33024/118836 (28%)] Loss: 12346.253906\n",
      "Train Epoch: 245 [65792/118836 (55%)] Loss: 12433.636719\n",
      "Train Epoch: 245 [98560/118836 (83%)] Loss: 12382.114258\n",
      "    epoch          : 245\n",
      "    loss           : 12347.276401435845\n",
      "    val_loss       : 12345.566814238113\n",
      "    val_log_likelihood: -12257.765889616936\n",
      "    val_log_marginal: -12265.419523373334\n",
      "Train Epoch: 246 [256/118836 (0%)] Loss: 12268.890625\n",
      "Train Epoch: 246 [33024/118836 (28%)] Loss: 12392.775391\n",
      "Train Epoch: 246 [65792/118836 (55%)] Loss: 12407.792969\n",
      "Train Epoch: 246 [98560/118836 (83%)] Loss: 12337.474609\n",
      "    epoch          : 246\n",
      "    loss           : 12342.239792377482\n",
      "    val_loss       : 12338.986264252091\n",
      "    val_log_likelihood: -12248.459749470121\n",
      "    val_log_marginal: -12256.283198902875\n",
      "Train Epoch: 247 [256/118836 (0%)] Loss: 12299.732422\n",
      "Train Epoch: 247 [33024/118836 (28%)] Loss: 12291.753906\n",
      "Train Epoch: 247 [65792/118836 (55%)] Loss: 12318.198242\n",
      "Train Epoch: 247 [98560/118836 (83%)] Loss: 12355.629883\n",
      "    epoch          : 247\n",
      "    loss           : 12338.48658127197\n",
      "    val_loss       : 12333.117176543796\n",
      "    val_log_likelihood: -12241.849906786343\n",
      "    val_log_marginal: -12249.531858495997\n",
      "Train Epoch: 248 [256/118836 (0%)] Loss: 12295.560547\n",
      "Train Epoch: 248 [33024/118836 (28%)] Loss: 12331.091797\n",
      "Train Epoch: 248 [65792/118836 (55%)] Loss: 12417.125977\n",
      "Train Epoch: 248 [98560/118836 (83%)] Loss: 12324.085938\n",
      "    epoch          : 248\n",
      "    loss           : 12330.727347142525\n",
      "    val_loss       : 12333.819484239228\n",
      "    val_log_likelihood: -12231.841218045647\n",
      "    val_log_marginal: -12239.539660010072\n",
      "Train Epoch: 249 [256/118836 (0%)] Loss: 12482.921875\n",
      "Train Epoch: 249 [33024/118836 (28%)] Loss: 12360.882812\n",
      "Train Epoch: 249 [65792/118836 (55%)] Loss: 12320.745117\n",
      "Train Epoch: 249 [98560/118836 (83%)] Loss: 12360.311523\n",
      "    epoch          : 249\n",
      "    loss           : 12330.109581297818\n",
      "    val_loss       : 12334.380239463706\n",
      "    val_log_likelihood: -12235.525305488782\n",
      "    val_log_marginal: -12243.799335194495\n",
      "Train Epoch: 250 [256/118836 (0%)] Loss: 12343.223633\n",
      "Train Epoch: 250 [33024/118836 (28%)] Loss: 12350.289062\n",
      "Train Epoch: 250 [65792/118836 (55%)] Loss: 12424.050781\n",
      "Train Epoch: 250 [98560/118836 (83%)] Loss: 12262.232422\n",
      "    epoch          : 250\n",
      "    loss           : 12327.387409048024\n",
      "    val_loss       : 12325.89749380876\n",
      "    val_log_likelihood: -12220.983623959624\n",
      "    val_log_marginal: -12228.812799361827\n",
      "Train Epoch: 251 [256/118836 (0%)] Loss: 12370.851562\n",
      "Train Epoch: 251 [33024/118836 (28%)] Loss: 12392.616211\n",
      "Train Epoch: 251 [65792/118836 (55%)] Loss: 12219.803711\n",
      "Train Epoch: 251 [98560/118836 (83%)] Loss: 12344.070312\n",
      "    epoch          : 251\n",
      "    loss           : 12319.063845863058\n",
      "    val_loss       : 12321.847208949413\n",
      "    val_log_likelihood: -12221.394763072529\n",
      "    val_log_marginal: -12229.34930632367\n",
      "Train Epoch: 252 [256/118836 (0%)] Loss: 12421.267578\n",
      "Train Epoch: 252 [33024/118836 (28%)] Loss: 12418.189453\n",
      "Train Epoch: 252 [65792/118836 (55%)] Loss: 12396.196289\n",
      "Train Epoch: 252 [98560/118836 (83%)] Loss: 12363.756836\n",
      "    epoch          : 252\n",
      "    loss           : 12323.584878709162\n",
      "    val_loss       : 12323.08341205051\n",
      "    val_log_likelihood: -12218.4989088994\n",
      "    val_log_marginal: -12226.38842494471\n",
      "Train Epoch: 253 [256/118836 (0%)] Loss: 12326.843750\n",
      "Train Epoch: 253 [33024/118836 (28%)] Loss: 12237.789062\n",
      "Train Epoch: 253 [65792/118836 (55%)] Loss: 12423.548828\n",
      "Train Epoch: 253 [98560/118836 (83%)] Loss: 12307.882812\n",
      "    epoch          : 253\n",
      "    loss           : 12319.600851846826\n",
      "    val_loss       : 12323.37008386129\n",
      "    val_log_likelihood: -12222.772406657103\n",
      "    val_log_marginal: -12230.711187404286\n",
      "Train Epoch: 254 [256/118836 (0%)] Loss: 12301.654297\n",
      "Train Epoch: 254 [33024/118836 (28%)] Loss: 12405.918945\n",
      "Train Epoch: 254 [65792/118836 (55%)] Loss: 12402.102539\n",
      "Train Epoch: 254 [98560/118836 (83%)] Loss: 12390.700195\n",
      "    epoch          : 254\n",
      "    loss           : 12317.867541776519\n",
      "    val_loss       : 12318.67612238405\n",
      "    val_log_likelihood: -12219.644244500878\n",
      "    val_log_marginal: -12227.254267001677\n",
      "Train Epoch: 255 [256/118836 (0%)] Loss: 12284.185547\n",
      "Train Epoch: 255 [33024/118836 (28%)] Loss: 12294.970703\n",
      "Train Epoch: 255 [65792/118836 (55%)] Loss: 12370.655273\n",
      "Train Epoch: 255 [98560/118836 (83%)] Loss: 12356.330078\n",
      "    epoch          : 255\n",
      "    loss           : 12317.928898818755\n",
      "    val_loss       : 12316.73283664462\n",
      "    val_log_likelihood: -12215.077796894386\n",
      "    val_log_marginal: -12222.760591537104\n",
      "Train Epoch: 256 [256/118836 (0%)] Loss: 12369.094727\n",
      "Train Epoch: 256 [33024/118836 (28%)] Loss: 12364.347656\n",
      "Train Epoch: 256 [65792/118836 (55%)] Loss: 12331.203125\n",
      "Train Epoch: 256 [98560/118836 (83%)] Loss: 12332.505859\n",
      "    epoch          : 256\n",
      "    loss           : 12319.736025544096\n",
      "    val_loss       : 12321.461354432553\n",
      "    val_log_likelihood: -12216.91076512743\n",
      "    val_log_marginal: -12224.632481703808\n",
      "Train Epoch: 257 [256/118836 (0%)] Loss: 12385.050781\n",
      "Train Epoch: 257 [33024/118836 (28%)] Loss: 12340.699219\n",
      "Train Epoch: 257 [65792/118836 (55%)] Loss: 12369.956055\n",
      "Train Epoch: 257 [98560/118836 (83%)] Loss: 12222.119141\n",
      "    epoch          : 257\n",
      "    loss           : 12320.91575827776\n",
      "    val_loss       : 12319.745321207856\n",
      "    val_log_likelihood: -12219.786671416201\n",
      "    val_log_marginal: -12227.691101065415\n",
      "Train Epoch: 258 [256/118836 (0%)] Loss: 12456.182617\n",
      "Train Epoch: 258 [33024/118836 (28%)] Loss: 12427.664062\n",
      "Train Epoch: 258 [65792/118836 (55%)] Loss: 12450.023438\n",
      "Train Epoch: 258 [98560/118836 (83%)] Loss: 12302.911133\n",
      "    epoch          : 258\n",
      "    loss           : 12324.547912627948\n",
      "    val_loss       : 12322.445461698806\n",
      "    val_log_likelihood: -12223.175056380533\n",
      "    val_log_marginal: -12230.965114730503\n",
      "Train Epoch: 259 [256/118836 (0%)] Loss: 12466.844727\n",
      "Train Epoch: 259 [33024/118836 (28%)] Loss: 12314.762695\n",
      "Train Epoch: 259 [65792/118836 (55%)] Loss: 12287.642578\n",
      "Train Epoch: 259 [98560/118836 (83%)] Loss: 12366.234375\n",
      "    epoch          : 259\n",
      "    loss           : 12321.613265256668\n",
      "    val_loss       : 12320.89109611639\n",
      "    val_log_likelihood: -12220.261652030345\n",
      "    val_log_marginal: -12228.098958958808\n",
      "Train Epoch: 260 [256/118836 (0%)] Loss: 12337.462891\n",
      "Train Epoch: 260 [33024/118836 (28%)] Loss: 12356.688477\n",
      "Train Epoch: 260 [65792/118836 (55%)] Loss: 12379.230469\n",
      "Train Epoch: 260 [98560/118836 (83%)] Loss: 12336.107422\n",
      "    epoch          : 260\n",
      "    loss           : 12320.683716042442\n",
      "    val_loss       : 12316.537000346541\n",
      "    val_log_likelihood: -12221.44232110086\n",
      "    val_log_marginal: -12229.08582463523\n",
      "Train Epoch: 261 [256/118836 (0%)] Loss: 12320.130859\n",
      "Train Epoch: 261 [33024/118836 (28%)] Loss: 12253.892578\n",
      "Train Epoch: 261 [65792/118836 (55%)] Loss: 12282.273438\n",
      "Train Epoch: 261 [98560/118836 (83%)] Loss: 12330.643555\n",
      "    epoch          : 261\n",
      "    loss           : 12314.732331246123\n",
      "    val_loss       : 12319.794336976696\n",
      "    val_log_likelihood: -12221.273573039443\n",
      "    val_log_marginal: -12228.798068947222\n",
      "Train Epoch: 262 [256/118836 (0%)] Loss: 12347.231445\n",
      "Train Epoch: 262 [33024/118836 (28%)] Loss: 12308.144531\n",
      "Train Epoch: 262 [65792/118836 (55%)] Loss: 12292.710938\n",
      "Train Epoch: 262 [98560/118836 (83%)] Loss: 12355.193359\n",
      "    epoch          : 262\n",
      "    loss           : 12319.145548684346\n",
      "    val_loss       : 12318.548910162805\n",
      "    val_log_likelihood: -12223.569544173903\n",
      "    val_log_marginal: -12231.107183360904\n",
      "Train Epoch: 263 [256/118836 (0%)] Loss: 12354.255859\n",
      "Train Epoch: 263 [33024/118836 (28%)] Loss: 12391.206055\n",
      "Train Epoch: 263 [65792/118836 (55%)] Loss: 12388.382812\n",
      "Train Epoch: 263 [98560/118836 (83%)] Loss: 12341.130859\n",
      "    epoch          : 263\n",
      "    loss           : 12319.967531760494\n",
      "    val_loss       : 12317.86692377662\n",
      "    val_log_likelihood: -12218.794966139372\n",
      "    val_log_marginal: -12226.44661214724\n",
      "Train Epoch: 264 [256/118836 (0%)] Loss: 12267.795898\n",
      "Train Epoch: 264 [33024/118836 (28%)] Loss: 12299.067383\n",
      "Train Epoch: 264 [65792/118836 (55%)] Loss: 12237.009766\n",
      "Train Epoch: 264 [98560/118836 (83%)] Loss: 12411.527344\n",
      "    epoch          : 264\n",
      "    loss           : 12314.708688579145\n",
      "    val_loss       : 12315.821152957846\n",
      "    val_log_likelihood: -12220.945936563015\n",
      "    val_log_marginal: -12228.534775999291\n",
      "Train Epoch: 265 [256/118836 (0%)] Loss: 12318.552734\n",
      "Train Epoch: 265 [33024/118836 (28%)] Loss: 12250.174805\n",
      "Train Epoch: 265 [65792/118836 (55%)] Loss: 12263.920898\n",
      "Train Epoch: 265 [98560/118836 (83%)] Loss: 12292.808594\n",
      "    epoch          : 265\n",
      "    loss           : 12319.766048904054\n",
      "    val_loss       : 12318.241280362856\n",
      "    val_log_likelihood: -12223.282465493176\n",
      "    val_log_marginal: -12231.013910780188\n",
      "Train Epoch: 266 [256/118836 (0%)] Loss: 12259.406250\n",
      "Train Epoch: 266 [33024/118836 (28%)] Loss: 12364.609375\n",
      "Train Epoch: 266 [65792/118836 (55%)] Loss: 12299.748047\n",
      "Train Epoch: 266 [98560/118836 (83%)] Loss: 12464.777344\n",
      "    epoch          : 266\n",
      "    loss           : 12318.874409054488\n",
      "    val_loss       : 12320.381729367191\n",
      "    val_log_likelihood: -12227.070311046062\n",
      "    val_log_marginal: -12235.030457337007\n",
      "Train Epoch: 267 [256/118836 (0%)] Loss: 12258.227539\n",
      "Train Epoch: 267 [33024/118836 (28%)] Loss: 12459.761719\n",
      "Train Epoch: 267 [65792/118836 (55%)] Loss: 12352.850586\n",
      "Train Epoch: 267 [98560/118836 (83%)] Loss: 12380.285156\n",
      "    epoch          : 267\n",
      "    loss           : 12322.164989951665\n",
      "    val_loss       : 12335.521053533717\n",
      "    val_log_likelihood: -12220.605497182589\n",
      "    val_log_marginal: -12228.327592283575\n",
      "Train Epoch: 268 [256/118836 (0%)] Loss: 12384.474609\n",
      "Train Epoch: 268 [33024/118836 (28%)] Loss: 12244.716797\n",
      "Train Epoch: 268 [65792/118836 (55%)] Loss: 12302.157227\n",
      "Train Epoch: 268 [98560/118836 (83%)] Loss: 12299.360352\n",
      "    epoch          : 268\n",
      "    loss           : 12317.637801450062\n",
      "    val_loss       : 12316.650424221358\n",
      "    val_log_likelihood: -12222.491500109852\n",
      "    val_log_marginal: -12230.467923578863\n",
      "Train Epoch: 269 [256/118836 (0%)] Loss: 12278.693359\n",
      "Train Epoch: 269 [33024/118836 (28%)] Loss: 12301.791992\n",
      "Train Epoch: 269 [65792/118836 (55%)] Loss: 12391.564453\n",
      "Train Epoch: 269 [98560/118836 (83%)] Loss: 12286.860352\n",
      "    epoch          : 269\n",
      "    loss           : 12318.699154776676\n",
      "    val_loss       : 12320.725090327205\n",
      "    val_log_likelihood: -12214.884202627429\n",
      "    val_log_marginal: -12222.399669541364\n",
      "Train Epoch: 270 [256/118836 (0%)] Loss: 12398.068359\n",
      "Train Epoch: 270 [33024/118836 (28%)] Loss: 12236.348633\n",
      "Train Epoch: 270 [65792/118836 (55%)] Loss: 12288.157227\n",
      "Train Epoch: 270 [98560/118836 (83%)] Loss: 12407.035156\n",
      "    epoch          : 270\n",
      "    loss           : 12321.568007683261\n",
      "    val_loss       : 12320.774354494419\n",
      "    val_log_likelihood: -12217.341208029622\n",
      "    val_log_marginal: -12225.013207591963\n",
      "Train Epoch: 271 [256/118836 (0%)] Loss: 12327.805664\n",
      "Train Epoch: 271 [33024/118836 (28%)] Loss: 12326.180664\n",
      "Train Epoch: 271 [65792/118836 (55%)] Loss: 12399.808594\n",
      "Train Epoch: 271 [98560/118836 (83%)] Loss: 12360.631836\n",
      "    epoch          : 271\n",
      "    loss           : 12318.462388692877\n",
      "    val_loss       : 12317.860002575702\n",
      "    val_log_likelihood: -12219.71096173232\n",
      "    val_log_marginal: -12227.315815058244\n",
      "Train Epoch: 272 [256/118836 (0%)] Loss: 12325.715820\n",
      "Train Epoch: 272 [33024/118836 (28%)] Loss: 12396.178711\n",
      "Train Epoch: 272 [65792/118836 (55%)] Loss: 12246.910156\n",
      "Train Epoch: 272 [98560/118836 (83%)] Loss: 12392.729492\n",
      "    epoch          : 272\n",
      "    loss           : 12321.379332254188\n",
      "    val_loss       : 12320.158249404394\n",
      "    val_log_likelihood: -12220.791332906845\n",
      "    val_log_marginal: -12228.585407813609\n",
      "Train Epoch: 273 [256/118836 (0%)] Loss: 12324.029297\n",
      "Train Epoch: 273 [33024/118836 (28%)] Loss: 12338.227539\n",
      "Train Epoch: 273 [65792/118836 (55%)] Loss: 12379.749023\n",
      "Train Epoch: 273 [98560/118836 (83%)] Loss: 12358.629883\n",
      "    epoch          : 273\n",
      "    loss           : 12323.378181057433\n",
      "    val_loss       : 12316.631809460354\n",
      "    val_log_likelihood: -12224.003397532826\n",
      "    val_log_marginal: -12231.603759190419\n",
      "Train Epoch: 274 [256/118836 (0%)] Loss: 12349.291016\n",
      "Train Epoch: 274 [33024/118836 (28%)] Loss: 12439.166016\n",
      "Train Epoch: 274 [65792/118836 (55%)] Loss: 12315.461914\n",
      "Train Epoch: 274 [98560/118836 (83%)] Loss: 12389.953125\n",
      "    epoch          : 274\n",
      "    loss           : 12319.631294910565\n",
      "    val_loss       : 12315.033501627953\n",
      "    val_log_likelihood: -12216.789599326665\n",
      "    val_log_marginal: -12224.55277975724\n",
      "Train Epoch: 275 [256/118836 (0%)] Loss: 12342.725586\n",
      "Train Epoch: 275 [33024/118836 (28%)] Loss: 12297.690430\n",
      "Train Epoch: 275 [65792/118836 (55%)] Loss: 12414.642578\n",
      "Train Epoch: 275 [98560/118836 (83%)] Loss: 12370.304688\n",
      "    epoch          : 275\n",
      "    loss           : 12319.20084861585\n",
      "    val_loss       : 12319.075010891149\n",
      "    val_log_likelihood: -12224.084674834574\n",
      "    val_log_marginal: -12231.885219322172\n",
      "Train Epoch: 276 [256/118836 (0%)] Loss: 12349.349609\n",
      "Train Epoch: 276 [33024/118836 (28%)] Loss: 12357.430664\n",
      "Train Epoch: 276 [65792/118836 (55%)] Loss: 12276.207031\n",
      "Train Epoch: 276 [98560/118836 (83%)] Loss: 12281.378906\n",
      "    epoch          : 276\n",
      "    loss           : 12312.556103313687\n",
      "    val_loss       : 12306.299764491629\n",
      "    val_log_likelihood: -12216.730525938276\n",
      "    val_log_marginal: -12224.387962163333\n",
      "Train Epoch: 277 [256/118836 (0%)] Loss: 12265.729492\n",
      "Train Epoch: 277 [33024/118836 (28%)] Loss: 12332.022461\n",
      "Train Epoch: 277 [65792/118836 (55%)] Loss: 12327.186523\n",
      "Train Epoch: 277 [98560/118836 (83%)] Loss: 12320.037109\n",
      "    epoch          : 277\n",
      "    loss           : 12301.517819640458\n",
      "    val_loss       : 12304.970175438937\n",
      "    val_log_likelihood: -12213.252029376034\n",
      "    val_log_marginal: -12220.96557644589\n",
      "Train Epoch: 278 [256/118836 (0%)] Loss: 12421.116211\n",
      "Train Epoch: 278 [33024/118836 (28%)] Loss: 12393.111328\n",
      "Train Epoch: 278 [65792/118836 (55%)] Loss: 12394.422852\n",
      "Train Epoch: 278 [98560/118836 (83%)] Loss: 12297.743164\n",
      "    epoch          : 278\n",
      "    loss           : 12302.38589162014\n",
      "    val_loss       : 12304.170231883367\n",
      "    val_log_likelihood: -12214.16552273961\n",
      "    val_log_marginal: -12221.909611698275\n",
      "Train Epoch: 279 [256/118836 (0%)] Loss: 12296.464844\n",
      "Train Epoch: 279 [33024/118836 (28%)] Loss: 12309.532227\n",
      "Train Epoch: 279 [65792/118836 (55%)] Loss: 12368.434570\n",
      "Train Epoch: 279 [98560/118836 (83%)] Loss: 12234.501953\n",
      "    epoch          : 279\n",
      "    loss           : 12299.546166285412\n",
      "    val_loss       : 12302.100943461097\n",
      "    val_log_likelihood: -12216.00665936466\n",
      "    val_log_marginal: -12223.875544448309\n",
      "Train Epoch: 280 [256/118836 (0%)] Loss: 12413.327148\n",
      "Train Epoch: 280 [33024/118836 (28%)] Loss: 12258.869141\n",
      "Train Epoch: 280 [65792/118836 (55%)] Loss: 12311.570312\n",
      "Train Epoch: 280 [98560/118836 (83%)] Loss: 12257.436523\n",
      "    epoch          : 280\n",
      "    loss           : 12304.299153322736\n",
      "    val_loss       : 12303.398221139098\n",
      "    val_log_likelihood: -12218.098081607992\n",
      "    val_log_marginal: -12225.703925226264\n",
      "Train Epoch: 281 [256/118836 (0%)] Loss: 12339.541992\n",
      "Train Epoch: 281 [33024/118836 (28%)] Loss: 12284.177734\n",
      "Train Epoch: 281 [65792/118836 (55%)] Loss: 12425.855469\n",
      "Train Epoch: 281 [98560/118836 (83%)] Loss: 12339.070312\n",
      "    epoch          : 281\n",
      "    loss           : 12304.59260106493\n",
      "    val_loss       : 12306.436470185326\n",
      "    val_log_likelihood: -12213.92492601065\n",
      "    val_log_marginal: -12221.583123019207\n",
      "Train Epoch: 282 [256/118836 (0%)] Loss: 12259.869141\n",
      "Train Epoch: 282 [33024/118836 (28%)] Loss: 12305.347656\n",
      "Train Epoch: 282 [65792/118836 (55%)] Loss: 12280.439453\n",
      "Train Epoch: 282 [98560/118836 (83%)] Loss: 12352.474609\n",
      "    epoch          : 282\n",
      "    loss           : 12305.757056451614\n",
      "    val_loss       : 12304.440141493858\n",
      "    val_log_likelihood: -12214.042574570927\n",
      "    val_log_marginal: -12221.673985898602\n",
      "Train Epoch: 283 [256/118836 (0%)] Loss: 12253.197266\n",
      "Train Epoch: 283 [33024/118836 (28%)] Loss: 12243.343750\n",
      "Train Epoch: 283 [65792/118836 (55%)] Loss: 12269.164062\n",
      "Train Epoch: 283 [98560/118836 (83%)] Loss: 12365.826172\n",
      "    epoch          : 283\n",
      "    loss           : 12303.647511340725\n",
      "    val_loss       : 12303.25464492988\n",
      "    val_log_likelihood: -12216.744757256773\n",
      "    val_log_marginal: -12224.331084361673\n",
      "Train Epoch: 284 [256/118836 (0%)] Loss: 12338.235352\n",
      "Train Epoch: 284 [33024/118836 (28%)] Loss: 12362.755859\n",
      "Train Epoch: 284 [65792/118836 (55%)] Loss: 12367.757812\n",
      "Train Epoch: 284 [98560/118836 (83%)] Loss: 12277.269531\n",
      "    epoch          : 284\n",
      "    loss           : 12306.410872234284\n",
      "    val_loss       : 12305.312567152067\n",
      "    val_log_likelihood: -12225.94154243564\n",
      "    val_log_marginal: -12233.763218918702\n",
      "Train Epoch: 285 [256/118836 (0%)] Loss: 12364.779297\n",
      "Train Epoch: 285 [33024/118836 (28%)] Loss: 12334.597656\n",
      "Train Epoch: 285 [65792/118836 (55%)] Loss: 12272.369141\n",
      "Train Epoch: 285 [98560/118836 (83%)] Loss: 12329.298828\n",
      "    epoch          : 285\n",
      "    loss           : 12303.083150298544\n",
      "    val_loss       : 12302.5354492807\n",
      "    val_log_likelihood: -12214.871713612747\n",
      "    val_log_marginal: -12222.612773780957\n",
      "Train Epoch: 286 [256/118836 (0%)] Loss: 12363.821289\n",
      "Train Epoch: 286 [33024/118836 (28%)] Loss: 12352.678711\n",
      "Train Epoch: 286 [65792/118836 (55%)] Loss: 12385.413086\n",
      "Train Epoch: 286 [98560/118836 (83%)] Loss: 12295.401367\n",
      "    epoch          : 286\n",
      "    loss           : 12306.085972879187\n",
      "    val_loss       : 12305.020481724068\n",
      "    val_log_likelihood: -12215.75497974178\n",
      "    val_log_marginal: -12223.459517543384\n",
      "Train Epoch: 287 [256/118836 (0%)] Loss: 12327.556641\n",
      "Train Epoch: 287 [33024/118836 (28%)] Loss: 12377.242188\n",
      "Train Epoch: 287 [65792/118836 (55%)] Loss: 12330.453125\n",
      "Train Epoch: 287 [98560/118836 (83%)] Loss: 12299.714844\n",
      "    epoch          : 287\n",
      "    loss           : 12302.946215557795\n",
      "    val_loss       : 12301.234008401725\n",
      "    val_log_likelihood: -12214.860643481183\n",
      "    val_log_marginal: -12222.593558008644\n",
      "Train Epoch: 288 [256/118836 (0%)] Loss: 12273.437500\n",
      "Train Epoch: 288 [33024/118836 (28%)] Loss: 12354.293945\n",
      "Train Epoch: 288 [65792/118836 (55%)] Loss: 12368.585938\n",
      "Train Epoch: 288 [98560/118836 (83%)] Loss: 12467.430664\n",
      "    epoch          : 288\n",
      "    loss           : 12305.698569162272\n",
      "    val_loss       : 12305.44802240452\n",
      "    val_log_likelihood: -12215.159101013234\n",
      "    val_log_marginal: -12222.673574059629\n",
      "Train Epoch: 289 [256/118836 (0%)] Loss: 12292.702148\n",
      "Train Epoch: 289 [33024/118836 (28%)] Loss: 12270.074219\n",
      "Train Epoch: 289 [65792/118836 (55%)] Loss: 12260.258789\n",
      "Train Epoch: 289 [98560/118836 (83%)] Loss: 12335.368164\n",
      "    epoch          : 289\n",
      "    loss           : 12294.885767389113\n",
      "    val_loss       : 12303.201156471896\n",
      "    val_log_likelihood: -12215.045030435793\n",
      "    val_log_marginal: -12222.603057089742\n",
      "Train Epoch: 290 [256/118836 (0%)] Loss: 12282.093750\n",
      "Train Epoch: 290 [33024/118836 (28%)] Loss: 12348.613281\n",
      "Train Epoch: 290 [65792/118836 (55%)] Loss: 12270.019531\n",
      "Train Epoch: 290 [98560/118836 (83%)] Loss: 12333.291992\n",
      "    epoch          : 290\n",
      "    loss           : 12304.331184411187\n",
      "    val_loss       : 12332.201541032413\n",
      "    val_log_likelihood: -12229.490895917339\n",
      "    val_log_marginal: -12237.558312465017\n",
      "Train Epoch: 291 [256/118836 (0%)] Loss: 12346.397461\n",
      "Train Epoch: 291 [33024/118836 (28%)] Loss: 12455.948242\n",
      "Train Epoch: 291 [65792/118836 (55%)] Loss: 12220.800781\n",
      "Train Epoch: 291 [98560/118836 (83%)] Loss: 12384.701172\n",
      "    epoch          : 291\n",
      "    loss           : 12310.238734879033\n",
      "    val_loss       : 12304.542903734822\n",
      "    val_log_likelihood: -12221.071118466967\n",
      "    val_log_marginal: -12228.847244101215\n",
      "Train Epoch: 292 [256/118836 (0%)] Loss: 12342.902344\n",
      "Train Epoch: 292 [33024/118836 (28%)] Loss: 12211.238281\n",
      "Train Epoch: 292 [65792/118836 (55%)] Loss: 12399.345703\n",
      "Train Epoch: 292 [98560/118836 (83%)] Loss: 12296.560547\n",
      "    epoch          : 292\n",
      "    loss           : 12303.841571837522\n",
      "    val_loss       : 12302.958648846483\n",
      "    val_log_likelihood: -12219.399169477616\n",
      "    val_log_marginal: -12227.05633348488\n",
      "Train Epoch: 293 [256/118836 (0%)] Loss: 12372.861328\n",
      "Train Epoch: 293 [33024/118836 (28%)] Loss: 12346.878906\n",
      "Train Epoch: 293 [65792/118836 (55%)] Loss: 12297.011719\n",
      "Train Epoch: 293 [98560/118836 (83%)] Loss: 12288.311523\n",
      "    epoch          : 293\n",
      "    loss           : 12301.130623836849\n",
      "    val_loss       : 12303.393508338298\n",
      "    val_log_likelihood: -12215.482792306399\n",
      "    val_log_marginal: -12223.248144248939\n",
      "Train Epoch: 294 [256/118836 (0%)] Loss: 12285.344727\n",
      "Train Epoch: 294 [33024/118836 (28%)] Loss: 12332.150391\n",
      "Train Epoch: 294 [65792/118836 (55%)] Loss: 12246.214844\n",
      "Train Epoch: 294 [98560/118836 (83%)] Loss: 12348.568359\n",
      "    epoch          : 294\n",
      "    loss           : 12307.709464174937\n",
      "    val_loss       : 12299.567945464209\n",
      "    val_log_likelihood: -12215.262021654002\n",
      "    val_log_marginal: -12222.800191872448\n",
      "Train Epoch: 295 [256/118836 (0%)] Loss: 12309.921875\n",
      "Train Epoch: 295 [33024/118836 (28%)] Loss: 12279.985352\n",
      "Train Epoch: 295 [65792/118836 (55%)] Loss: 12395.000977\n",
      "Train Epoch: 295 [98560/118836 (83%)] Loss: 12340.347656\n",
      "    epoch          : 295\n",
      "    loss           : 12303.625956045802\n",
      "    val_loss       : 12305.756922132856\n",
      "    val_log_likelihood: -12216.812410663513\n",
      "    val_log_marginal: -12224.35519267105\n",
      "Train Epoch: 296 [256/118836 (0%)] Loss: 12377.625000\n",
      "Train Epoch: 296 [33024/118836 (28%)] Loss: 12351.109375\n",
      "Train Epoch: 296 [65792/118836 (55%)] Loss: 12294.644531\n",
      "Train Epoch: 296 [98560/118836 (83%)] Loss: 12403.982422\n",
      "    epoch          : 296\n",
      "    loss           : 12305.950040064103\n",
      "    val_loss       : 12306.026001658041\n",
      "    val_log_likelihood: -12216.253349391285\n",
      "    val_log_marginal: -12223.72951999781\n",
      "Train Epoch: 297 [256/118836 (0%)] Loss: 12326.150391\n",
      "Train Epoch: 297 [33024/118836 (28%)] Loss: 12242.597656\n",
      "Train Epoch: 297 [65792/118836 (55%)] Loss: 12388.729492\n",
      "Train Epoch: 297 [98560/118836 (83%)] Loss: 12342.259766\n",
      "    epoch          : 297\n",
      "    loss           : 12305.293807672922\n",
      "    val_loss       : 12298.124481857216\n",
      "    val_log_likelihood: -12217.54527195125\n",
      "    val_log_marginal: -12225.13493130424\n",
      "Train Epoch: 298 [256/118836 (0%)] Loss: 12328.082031\n",
      "Train Epoch: 298 [33024/118836 (28%)] Loss: 12406.076172\n",
      "Train Epoch: 298 [65792/118836 (55%)] Loss: 12363.353516\n",
      "Train Epoch: 298 [98560/118836 (83%)] Loss: 12375.180664\n",
      "    epoch          : 298\n",
      "    loss           : 12304.821495198768\n",
      "    val_loss       : 12300.202041711076\n",
      "    val_log_likelihood: -12214.161786438948\n",
      "    val_log_marginal: -12221.728577641263\n",
      "Train Epoch: 299 [256/118836 (0%)] Loss: 12283.184570\n",
      "Train Epoch: 299 [33024/118836 (28%)] Loss: 12179.792969\n",
      "Train Epoch: 299 [65792/118836 (55%)] Loss: 12283.804688\n",
      "Train Epoch: 299 [98560/118836 (83%)] Loss: 12262.110352\n",
      "    epoch          : 299\n",
      "    loss           : 12302.395453209005\n",
      "    val_loss       : 12300.896597375871\n",
      "    val_log_likelihood: -12216.0615638247\n",
      "    val_log_marginal: -12223.608067092486\n",
      "Train Epoch: 300 [256/118836 (0%)] Loss: 12324.873047\n",
      "Train Epoch: 300 [33024/118836 (28%)] Loss: 12376.930664\n",
      "Train Epoch: 300 [65792/118836 (55%)] Loss: 12363.561523\n",
      "Train Epoch: 300 [98560/118836 (83%)] Loss: 12352.868164\n",
      "    epoch          : 300\n",
      "    loss           : 12299.805388460247\n",
      "    val_loss       : 12300.69065230488\n",
      "    val_log_likelihood: -12217.015767486044\n",
      "    val_log_marginal: -12224.58127278996\n",
      "Saving checkpoint: saved/models/SelfiesAutoencodingOperad/0905_154251/checkpoint-epoch300.pth ...\n",
      "Train Epoch: 301 [256/118836 (0%)] Loss: 12297.738281\n",
      "Train Epoch: 301 [33024/118836 (28%)] Loss: 12264.920898\n",
      "Train Epoch: 301 [65792/118836 (55%)] Loss: 12366.823242\n",
      "Train Epoch: 301 [98560/118836 (83%)] Loss: 12224.079102\n",
      "    epoch          : 301\n",
      "    loss           : 12299.20318719629\n",
      "    val_loss       : 12298.331527022216\n",
      "    val_log_likelihood: -12215.197940737438\n",
      "    val_log_marginal: -12222.821994675864\n",
      "Train Epoch: 302 [256/118836 (0%)] Loss: 12398.076172\n",
      "Train Epoch: 302 [33024/118836 (28%)] Loss: 12260.306641\n",
      "Train Epoch: 302 [65792/118836 (55%)] Loss: 12282.738281\n",
      "Train Epoch: 302 [98560/118836 (83%)] Loss: 12284.251953\n",
      "    epoch          : 302\n",
      "    loss           : 12300.876163151366\n",
      "    val_loss       : 12301.251529585485\n",
      "    val_log_likelihood: -12216.248751066223\n",
      "    val_log_marginal: -12223.785077559995\n",
      "Train Epoch: 303 [256/118836 (0%)] Loss: 12348.302734\n",
      "Train Epoch: 303 [33024/118836 (28%)] Loss: 12267.106445\n",
      "Train Epoch: 303 [65792/118836 (55%)] Loss: 12267.087891\n",
      "Train Epoch: 303 [98560/118836 (83%)] Loss: 12406.730469\n",
      "    epoch          : 303\n",
      "    loss           : 12300.829997673696\n",
      "    val_loss       : 12304.577560394053\n",
      "    val_log_likelihood: -12217.776718879239\n",
      "    val_log_marginal: -12225.3696206194\n",
      "Train Epoch: 304 [256/118836 (0%)] Loss: 12354.392578\n",
      "Train Epoch: 304 [33024/118836 (28%)] Loss: 12285.425781\n",
      "Train Epoch: 304 [65792/118836 (55%)] Loss: 12315.716797\n",
      "Train Epoch: 304 [98560/118836 (83%)] Loss: 12427.465820\n",
      "    epoch          : 304\n",
      "    loss           : 12304.731386831834\n",
      "    val_loss       : 12302.006780740561\n",
      "    val_log_likelihood: -12213.186805340158\n",
      "    val_log_marginal: -12220.700325249583\n",
      "Train Epoch: 305 [256/118836 (0%)] Loss: 12298.113281\n",
      "Train Epoch: 305 [33024/118836 (28%)] Loss: 12319.672852\n",
      "Train Epoch: 305 [65792/118836 (55%)] Loss: 12243.738281\n",
      "Train Epoch: 305 [98560/118836 (83%)] Loss: 12263.881836\n",
      "    epoch          : 305\n",
      "    loss           : 12299.323252849721\n",
      "    val_loss       : 12305.701180748212\n",
      "    val_log_likelihood: -12218.954864880583\n",
      "    val_log_marginal: -12226.62035538675\n",
      "Train Epoch: 306 [256/118836 (0%)] Loss: 12313.209961\n",
      "Train Epoch: 306 [33024/118836 (28%)] Loss: 12270.277344\n",
      "Train Epoch: 306 [65792/118836 (55%)] Loss: 12233.039062\n",
      "Train Epoch: 306 [98560/118836 (83%)] Loss: 12350.303711\n",
      "    epoch          : 306\n",
      "    loss           : 12300.58435609879\n",
      "    val_loss       : 12299.59677940424\n",
      "    val_log_likelihood: -12215.664015973945\n",
      "    val_log_marginal: -12223.200656931609\n",
      "Train Epoch: 307 [256/118836 (0%)] Loss: 12291.701172\n",
      "Train Epoch: 307 [33024/118836 (28%)] Loss: 12308.562500\n",
      "Train Epoch: 307 [65792/118836 (55%)] Loss: 12337.838867\n",
      "Train Epoch: 307 [98560/118836 (83%)] Loss: 12230.400391\n",
      "    epoch          : 307\n",
      "    loss           : 12302.93361006643\n",
      "    val_loss       : 12307.096583291519\n",
      "    val_log_likelihood: -12214.181556619624\n",
      "    val_log_marginal: -12221.732121789462\n",
      "Train Epoch: 308 [256/118836 (0%)] Loss: 12329.424805\n",
      "Train Epoch: 308 [33024/118836 (28%)] Loss: 12305.248047\n",
      "Train Epoch: 308 [65792/118836 (55%)] Loss: 12349.213867\n",
      "Train Epoch: 308 [98560/118836 (83%)] Loss: 12249.544922\n",
      "    epoch          : 308\n",
      "    loss           : 12300.804304306244\n",
      "    val_loss       : 12297.914779622146\n",
      "    val_log_likelihood: -12212.704298490487\n",
      "    val_log_marginal: -12220.330318969849\n",
      "Train Epoch: 309 [256/118836 (0%)] Loss: 12334.238281\n",
      "Train Epoch: 309 [33024/118836 (28%)] Loss: 12306.826172\n",
      "Train Epoch: 309 [65792/118836 (55%)] Loss: 12299.868164\n",
      "Train Epoch: 309 [98560/118836 (83%)] Loss: 12320.014648\n",
      "    epoch          : 309\n",
      "    loss           : 12299.2365032439\n",
      "    val_loss       : 12302.745916865739\n",
      "    val_log_likelihood: -12210.120294568083\n",
      "    val_log_marginal: -12217.817133599185\n",
      "Train Epoch: 310 [256/118836 (0%)] Loss: 12384.367188\n",
      "Train Epoch: 310 [33024/118836 (28%)] Loss: 12293.005859\n",
      "Train Epoch: 310 [65792/118836 (55%)] Loss: 12261.543945\n",
      "Train Epoch: 310 [98560/118836 (83%)] Loss: 12345.356445\n",
      "    epoch          : 310\n",
      "    loss           : 12296.234505208333\n",
      "    val_loss       : 12297.861003097187\n",
      "    val_log_likelihood: -12208.795720733819\n",
      "    val_log_marginal: -12216.508226276974\n",
      "Train Epoch: 311 [256/118836 (0%)] Loss: 12258.591797\n",
      "Train Epoch: 311 [33024/118836 (28%)] Loss: 12294.786133\n",
      "Train Epoch: 311 [65792/118836 (55%)] Loss: 12422.826172\n",
      "Train Epoch: 311 [98560/118836 (83%)] Loss: 12288.295898\n",
      "    epoch          : 311\n",
      "    loss           : 12302.232823162221\n",
      "    val_loss       : 12301.130046655408\n",
      "    val_log_likelihood: -12210.443146453681\n",
      "    val_log_marginal: -12217.953883246222\n",
      "Train Epoch: 312 [256/118836 (0%)] Loss: 12350.453125\n",
      "Train Epoch: 312 [33024/118836 (28%)] Loss: 12250.626953\n",
      "Train Epoch: 312 [65792/118836 (55%)] Loss: 12265.000000\n",
      "Train Epoch: 312 [98560/118836 (83%)] Loss: 12350.630859\n",
      "    epoch          : 312\n",
      "    loss           : 12298.455027237127\n",
      "    val_loss       : 12304.044038205499\n",
      "    val_log_likelihood: -12218.517495088916\n",
      "    val_log_marginal: -12226.122119738344\n",
      "Train Epoch: 313 [256/118836 (0%)] Loss: 12342.223633\n",
      "Train Epoch: 313 [33024/118836 (28%)] Loss: 12419.640625\n",
      "Train Epoch: 313 [65792/118836 (55%)] Loss: 12315.154297\n",
      "Train Epoch: 313 [98560/118836 (83%)] Loss: 12378.043945\n",
      "    epoch          : 313\n",
      "    loss           : 12296.734455289754\n",
      "    val_loss       : 12298.008027622867\n",
      "    val_log_likelihood: -12212.987717767783\n",
      "    val_log_marginal: -12220.814610167194\n",
      "Train Epoch: 314 [256/118836 (0%)] Loss: 12313.379883\n",
      "Train Epoch: 314 [33024/118836 (28%)] Loss: 12302.239258\n",
      "Train Epoch: 314 [65792/118836 (55%)] Loss: 12225.755859\n",
      "Train Epoch: 314 [98560/118836 (83%)] Loss: 12283.543945\n",
      "    epoch          : 314\n",
      "    loss           : 12302.643490391076\n",
      "    val_loss       : 12301.232965046023\n",
      "    val_log_likelihood: -12207.511768830129\n",
      "    val_log_marginal: -12215.213867857303\n",
      "Train Epoch: 315 [256/118836 (0%)] Loss: 12255.165039\n",
      "Train Epoch: 315 [33024/118836 (28%)] Loss: 12246.682617\n",
      "Train Epoch: 315 [65792/118836 (55%)] Loss: 12377.573242\n",
      "Train Epoch: 315 [98560/118836 (83%)] Loss: 12291.949219\n",
      "    epoch          : 315\n",
      "    loss           : 12299.580254213193\n",
      "    val_loss       : 12313.345262195779\n",
      "    val_log_likelihood: -12210.314544884719\n",
      "    val_log_marginal: -12218.136562470374\n",
      "Train Epoch: 316 [256/118836 (0%)] Loss: 12312.687500\n",
      "Train Epoch: 316 [33024/118836 (28%)] Loss: 12386.669922\n",
      "Train Epoch: 316 [65792/118836 (55%)] Loss: 12264.166016\n",
      "Train Epoch: 316 [98560/118836 (83%)] Loss: 12291.030273\n",
      "    epoch          : 316\n",
      "    loss           : 12306.096385668683\n",
      "    val_loss       : 12300.172042789272\n",
      "    val_log_likelihood: -12208.11668912195\n",
      "    val_log_marginal: -12215.810974613149\n",
      "Train Epoch: 317 [256/118836 (0%)] Loss: 12348.308594\n",
      "Train Epoch: 317 [33024/118836 (28%)] Loss: 12326.283203\n",
      "Train Epoch: 317 [65792/118836 (55%)] Loss: 12292.902344\n",
      "Train Epoch: 317 [98560/118836 (83%)] Loss: 12293.154297\n",
      "    epoch          : 317\n",
      "    loss           : 12302.664308377276\n",
      "    val_loss       : 12302.047093183812\n",
      "    val_log_likelihood: -12216.706863239247\n",
      "    val_log_marginal: -12224.567883087711\n",
      "Train Epoch: 318 [256/118836 (0%)] Loss: 12401.921875\n",
      "Train Epoch: 318 [33024/118836 (28%)] Loss: 12251.128906\n",
      "Train Epoch: 318 [65792/118836 (55%)] Loss: 12377.576172\n",
      "Train Epoch: 318 [98560/118836 (83%)] Loss: 12372.234375\n",
      "    epoch          : 318\n",
      "    loss           : 12299.554314483818\n",
      "    val_loss       : 12301.748558896452\n",
      "    val_log_likelihood: -12211.452203848738\n",
      "    val_log_marginal: -12219.077171053106\n",
      "Train Epoch: 319 [256/118836 (0%)] Loss: 12304.501953\n",
      "Train Epoch: 319 [33024/118836 (28%)] Loss: 12321.171875\n",
      "Train Epoch: 319 [65792/118836 (55%)] Loss: 12353.317383\n",
      "Train Epoch: 319 [98560/118836 (83%)] Loss: 12318.903320\n",
      "    epoch          : 319\n",
      "    loss           : 12302.768380053247\n",
      "    val_loss       : 12302.752182302112\n",
      "    val_log_likelihood: -12212.624244920906\n",
      "    val_log_marginal: -12220.442129287838\n",
      "Train Epoch: 320 [256/118836 (0%)] Loss: 12351.865234\n",
      "Train Epoch: 320 [33024/118836 (28%)] Loss: 12368.892578\n",
      "Train Epoch: 320 [65792/118836 (55%)] Loss: 12278.248047\n",
      "Train Epoch: 320 [98560/118836 (83%)] Loss: 12308.322266\n",
      "    epoch          : 320\n",
      "    loss           : 12299.797914243436\n",
      "    val_loss       : 12301.49702329145\n",
      "    val_log_likelihood: -12209.00991925791\n",
      "    val_log_marginal: -12216.56155298098\n",
      "Train Epoch: 321 [256/118836 (0%)] Loss: 12263.799805\n",
      "Train Epoch: 321 [33024/118836 (28%)] Loss: 12294.931641\n",
      "Train Epoch: 321 [65792/118836 (55%)] Loss: 12245.947266\n",
      "Train Epoch: 321 [98560/118836 (83%)] Loss: 12398.221680\n",
      "    epoch          : 321\n",
      "    loss           : 12298.473823601635\n",
      "    val_loss       : 12304.359259791458\n",
      "    val_log_likelihood: -12209.309592121586\n",
      "    val_log_marginal: -12216.88577668951\n",
      "Train Epoch: 322 [256/118836 (0%)] Loss: 12369.496094\n",
      "Train Epoch: 322 [33024/118836 (28%)] Loss: 12333.802734\n",
      "Train Epoch: 322 [65792/118836 (55%)] Loss: 12317.923828\n",
      "Train Epoch: 322 [98560/118836 (83%)] Loss: 12322.943359\n",
      "    epoch          : 322\n",
      "    loss           : 12302.865694142885\n",
      "    val_loss       : 12301.255717000144\n",
      "    val_log_likelihood: -12208.384391639525\n",
      "    val_log_marginal: -12216.016113466629\n",
      "Train Epoch: 323 [256/118836 (0%)] Loss: 12271.450195\n",
      "Train Epoch: 323 [33024/118836 (28%)] Loss: 12289.091797\n",
      "Train Epoch: 323 [65792/118836 (55%)] Loss: 12252.557617\n",
      "Train Epoch: 323 [98560/118836 (83%)] Loss: 12395.506836\n",
      "    epoch          : 323\n",
      "    loss           : 12302.20056978262\n",
      "    val_loss       : 12299.473275758985\n",
      "    val_log_likelihood: -12209.807936892576\n",
      "    val_log_marginal: -12217.6915677253\n",
      "Train Epoch: 324 [256/118836 (0%)] Loss: 12329.282227\n",
      "Train Epoch: 324 [33024/118836 (28%)] Loss: 12329.642578\n",
      "Train Epoch: 324 [65792/118836 (55%)] Loss: 12332.376953\n",
      "Train Epoch: 324 [98560/118836 (83%)] Loss: 12354.281250\n",
      "    epoch          : 324\n",
      "    loss           : 12304.698595979373\n",
      "    val_loss       : 12302.334252246941\n",
      "    val_log_likelihood: -12209.03490859569\n",
      "    val_log_marginal: -12216.675049136951\n",
      "Train Epoch: 325 [256/118836 (0%)] Loss: 12295.062500\n",
      "Train Epoch: 325 [33024/118836 (28%)] Loss: 12266.907227\n",
      "Train Epoch: 325 [65792/118836 (55%)] Loss: 12344.125977\n",
      "Train Epoch: 325 [98560/118836 (83%)] Loss: 12334.512695\n",
      "    epoch          : 325\n",
      "    loss           : 12302.015600444583\n",
      "    val_loss       : 12299.660326255975\n",
      "    val_log_likelihood: -12211.114842942257\n",
      "    val_log_marginal: -12218.64553077267\n",
      "Train Epoch: 326 [256/118836 (0%)] Loss: 12303.114258\n",
      "Train Epoch: 326 [33024/118836 (28%)] Loss: 12307.428711\n",
      "Train Epoch: 326 [65792/118836 (55%)] Loss: 12244.343750\n",
      "Train Epoch: 326 [98560/118836 (83%)] Loss: 12402.395508\n",
      "    epoch          : 326\n",
      "    loss           : 12299.519835931038\n",
      "    val_loss       : 12300.117440572823\n",
      "    val_log_likelihood: -12209.023603733714\n",
      "    val_log_marginal: -12216.756120324235\n",
      "Train Epoch: 327 [256/118836 (0%)] Loss: 12278.435547\n",
      "Train Epoch: 327 [33024/118836 (28%)] Loss: 12377.843750\n",
      "Train Epoch: 327 [65792/118836 (55%)] Loss: 12313.193359\n",
      "Train Epoch: 327 [98560/118836 (83%)] Loss: 12298.368164\n",
      "    epoch          : 327\n",
      "    loss           : 12301.964714995605\n",
      "    val_loss       : 12298.427215952106\n",
      "    val_log_likelihood: -12207.814748920855\n",
      "    val_log_marginal: -12215.4567646452\n",
      "Train Epoch: 328 [256/118836 (0%)] Loss: 12308.988281\n",
      "Train Epoch: 328 [33024/118836 (28%)] Loss: 12315.806641\n",
      "Train Epoch: 328 [65792/118836 (55%)] Loss: 12374.678711\n",
      "Train Epoch: 328 [98560/118836 (83%)] Loss: 12298.345703\n",
      "    epoch          : 328\n",
      "    loss           : 12301.653028070721\n",
      "    val_loss       : 12299.995274517936\n",
      "    val_log_likelihood: -12211.56112602745\n",
      "    val_log_marginal: -12219.171582442672\n",
      "Train Epoch: 329 [256/118836 (0%)] Loss: 12295.337891\n",
      "Train Epoch: 329 [33024/118836 (28%)] Loss: 12382.226562\n",
      "Train Epoch: 329 [65792/118836 (55%)] Loss: 12297.669922\n",
      "Train Epoch: 329 [98560/118836 (83%)] Loss: 12325.366211\n",
      "    epoch          : 329\n",
      "    loss           : 12298.345162098065\n",
      "    val_loss       : 12297.438422577095\n",
      "    val_log_likelihood: -12210.92049569634\n",
      "    val_log_marginal: -12218.639932929573\n",
      "Train Epoch: 330 [256/118836 (0%)] Loss: 12253.523438\n",
      "Train Epoch: 330 [33024/118836 (28%)] Loss: 12244.555664\n",
      "Train Epoch: 330 [65792/118836 (55%)] Loss: 12339.638672\n",
      "Train Epoch: 330 [98560/118836 (83%)] Loss: 12354.036133\n",
      "    epoch          : 330\n",
      "    loss           : 12299.93608273237\n",
      "    val_loss       : 12301.704218032119\n",
      "    val_log_likelihood: -12210.347453829354\n",
      "    val_log_marginal: -12217.974621766905\n",
      "Train Epoch: 331 [256/118836 (0%)] Loss: 12361.150391\n",
      "Train Epoch: 331 [33024/118836 (28%)] Loss: 12365.287109\n",
      "Train Epoch: 331 [65792/118836 (55%)] Loss: 12380.509766\n",
      "Train Epoch: 331 [98560/118836 (83%)] Loss: 12200.056641\n",
      "    epoch          : 331\n",
      "    loss           : 12296.836053976685\n",
      "    val_loss       : 12300.134391865718\n",
      "    val_log_likelihood: -12210.116119662427\n",
      "    val_log_marginal: -12217.695443886076\n",
      "Train Epoch: 332 [256/118836 (0%)] Loss: 12281.494141\n",
      "Train Epoch: 332 [33024/118836 (28%)] Loss: 12278.333008\n",
      "Train Epoch: 332 [65792/118836 (55%)] Loss: 12370.023438\n",
      "Train Epoch: 332 [98560/118836 (83%)] Loss: 12268.791016\n",
      "    epoch          : 332\n",
      "    loss           : 12298.07688705154\n",
      "    val_loss       : 12304.194663218883\n",
      "    val_log_likelihood: -12206.823683700371\n",
      "    val_log_marginal: -12214.465443855992\n",
      "Train Epoch: 333 [256/118836 (0%)] Loss: 12318.531250\n",
      "Train Epoch: 333 [33024/118836 (28%)] Loss: 12374.488281\n",
      "Train Epoch: 333 [65792/118836 (55%)] Loss: 12326.245117\n",
      "Train Epoch: 333 [98560/118836 (83%)] Loss: 12319.978516\n",
      "    epoch          : 333\n",
      "    loss           : 12295.267571663047\n",
      "    val_loss       : 12301.115986043791\n",
      "    val_log_likelihood: -12211.205192986197\n",
      "    val_log_marginal: -12218.877991700465\n",
      "Train Epoch: 334 [256/118836 (0%)] Loss: 12385.541016\n",
      "Train Epoch: 334 [33024/118836 (28%)] Loss: 12334.076172\n",
      "Train Epoch: 334 [65792/118836 (55%)] Loss: 12363.259766\n",
      "Train Epoch: 334 [98560/118836 (83%)] Loss: 12299.932617\n",
      "    epoch          : 334\n",
      "    loss           : 12298.022942352925\n",
      "    val_loss       : 12300.570689821949\n",
      "    val_log_likelihood: -12206.875793043064\n",
      "    val_log_marginal: -12214.419575507216\n",
      "Train Epoch: 335 [256/118836 (0%)] Loss: 12362.722656\n",
      "Train Epoch: 335 [33024/118836 (28%)] Loss: 12241.847656\n",
      "Train Epoch: 335 [65792/118836 (55%)] Loss: 12223.970703\n",
      "Train Epoch: 335 [98560/118836 (83%)] Loss: 12326.220703\n",
      "    epoch          : 335\n",
      "    loss           : 12303.128342929333\n",
      "    val_loss       : 12305.61893386055\n",
      "    val_log_likelihood: -12211.569441267317\n",
      "    val_log_marginal: -12219.249703281836\n",
      "Train Epoch: 336 [256/118836 (0%)] Loss: 12306.047852\n",
      "Train Epoch: 336 [33024/118836 (28%)] Loss: 12376.443359\n",
      "Train Epoch: 336 [65792/118836 (55%)] Loss: 12333.048828\n",
      "Train Epoch: 336 [98560/118836 (83%)] Loss: 12246.253906\n",
      "    epoch          : 336\n",
      "    loss           : 12299.089685755273\n",
      "    val_loss       : 12302.100860668706\n",
      "    val_log_likelihood: -12206.829343239506\n",
      "    val_log_marginal: -12214.469526489444\n",
      "Train Epoch: 337 [256/118836 (0%)] Loss: 12408.951172\n",
      "Train Epoch: 337 [33024/118836 (28%)] Loss: 12403.824219\n",
      "Train Epoch: 337 [65792/118836 (55%)] Loss: 12374.083984\n",
      "Train Epoch: 337 [98560/118836 (83%)] Loss: 12306.742188\n",
      "    epoch          : 337\n",
      "    loss           : 12298.557103946961\n",
      "    val_loss       : 12298.427439354942\n",
      "    val_log_likelihood: -12209.03700986094\n",
      "    val_log_marginal: -12216.74100957279\n",
      "Train Epoch: 338 [256/118836 (0%)] Loss: 12383.711914\n",
      "Train Epoch: 338 [33024/118836 (28%)] Loss: 12246.687500\n",
      "Train Epoch: 338 [65792/118836 (55%)] Loss: 12267.556641\n",
      "Train Epoch: 338 [98560/118836 (83%)] Loss: 12320.888672\n",
      "    epoch          : 338\n",
      "    loss           : 12296.342256965985\n",
      "    val_loss       : 12303.039596136876\n",
      "    val_log_likelihood: -12210.804204792183\n",
      "    val_log_marginal: -12218.612375147755\n",
      "Train Epoch: 339 [256/118836 (0%)] Loss: 12356.328125\n",
      "Train Epoch: 339 [33024/118836 (28%)] Loss: 12289.841797\n",
      "Train Epoch: 339 [65792/118836 (55%)] Loss: 12350.261719\n",
      "Train Epoch: 339 [98560/118836 (83%)] Loss: 12252.615234\n",
      "    epoch          : 339\n",
      "    loss           : 12299.121006836745\n",
      "    val_loss       : 12297.275330718494\n",
      "    val_log_likelihood: -12206.96459351091\n",
      "    val_log_marginal: -12214.869650339066\n",
      "Train Epoch: 340 [256/118836 (0%)] Loss: 12267.015625\n",
      "Train Epoch: 340 [33024/118836 (28%)] Loss: 12335.415039\n",
      "Train Epoch: 340 [65792/118836 (55%)] Loss: 12273.912109\n",
      "Train Epoch: 340 [98560/118836 (83%)] Loss: 12369.484375\n",
      "    epoch          : 340\n",
      "    loss           : 12300.789607727203\n",
      "    val_loss       : 12297.657839264228\n",
      "    val_log_likelihood: -12209.154571184865\n",
      "    val_log_marginal: -12216.920031898338\n",
      "Train Epoch: 341 [256/118836 (0%)] Loss: 12284.680664\n",
      "Train Epoch: 341 [33024/118836 (28%)] Loss: 12286.750977\n",
      "Train Epoch: 341 [65792/118836 (55%)] Loss: 12336.881836\n",
      "Train Epoch: 341 [98560/118836 (83%)] Loss: 12331.131836\n",
      "    epoch          : 341\n",
      "    loss           : 12298.788147487594\n",
      "    val_loss       : 12297.814174195577\n",
      "    val_log_likelihood: -12211.89170931555\n",
      "    val_log_marginal: -12219.518138677175\n",
      "Train Epoch: 342 [256/118836 (0%)] Loss: 12331.800781\n",
      "Train Epoch: 342 [33024/118836 (28%)] Loss: 12386.161133\n",
      "Train Epoch: 342 [65792/118836 (55%)] Loss: 12377.351562\n",
      "Train Epoch: 342 [98560/118836 (83%)] Loss: 12347.966797\n",
      "    epoch          : 342\n",
      "    loss           : 12299.70788406612\n",
      "    val_loss       : 12298.415816039185\n",
      "    val_log_likelihood: -12209.670185684192\n",
      "    val_log_marginal: -12217.33999368405\n",
      "Train Epoch: 343 [256/118836 (0%)] Loss: 12271.835938\n",
      "Train Epoch: 343 [33024/118836 (28%)] Loss: 12314.474609\n",
      "Train Epoch: 343 [65792/118836 (55%)] Loss: 12419.990234\n",
      "Train Epoch: 343 [98560/118836 (83%)] Loss: 12368.206055\n",
      "    epoch          : 343\n",
      "    loss           : 12298.205077478804\n",
      "    val_loss       : 12297.552244216295\n",
      "    val_log_likelihood: -12209.16192359388\n",
      "    val_log_marginal: -12216.77083720281\n",
      "Train Epoch: 344 [256/118836 (0%)] Loss: 12323.445312\n",
      "Train Epoch: 344 [33024/118836 (28%)] Loss: 12326.057617\n",
      "Train Epoch: 344 [65792/118836 (55%)] Loss: 12305.878906\n",
      "Train Epoch: 344 [98560/118836 (83%)] Loss: 12385.042969\n",
      "    epoch          : 344\n",
      "    loss           : 12299.40360576923\n",
      "    val_loss       : 12301.901628826103\n",
      "    val_log_likelihood: -12211.342086370452\n",
      "    val_log_marginal: -12219.633920833563\n",
      "Train Epoch: 345 [256/118836 (0%)] Loss: 12317.442383\n",
      "Train Epoch: 345 [33024/118836 (28%)] Loss: 12360.552734\n",
      "Train Epoch: 345 [65792/118836 (55%)] Loss: 12388.025391\n",
      "Train Epoch: 345 [98560/118836 (83%)] Loss: 12287.656250\n",
      "    epoch          : 345\n",
      "    loss           : 12305.531708152397\n",
      "    val_loss       : 12296.965114972963\n",
      "    val_log_likelihood: -12209.100810651882\n",
      "    val_log_marginal: -12216.889157639835\n",
      "Train Epoch: 346 [256/118836 (0%)] Loss: 12379.126953\n",
      "Train Epoch: 346 [33024/118836 (28%)] Loss: 12282.222656\n",
      "Train Epoch: 346 [65792/118836 (55%)] Loss: 12304.475586\n",
      "Train Epoch: 346 [98560/118836 (83%)] Loss: 12360.539062\n",
      "    epoch          : 346\n",
      "    loss           : 12298.654891051488\n",
      "    val_loss       : 12297.550695483254\n",
      "    val_log_likelihood: -12209.52373119572\n",
      "    val_log_marginal: -12217.410289533984\n",
      "Train Epoch: 347 [256/118836 (0%)] Loss: 12226.722656\n",
      "Train Epoch: 347 [33024/118836 (28%)] Loss: 12318.197266\n",
      "Train Epoch: 347 [65792/118836 (55%)] Loss: 12233.833984\n",
      "Train Epoch: 347 [98560/118836 (83%)] Loss: 12326.651367\n",
      "    epoch          : 347\n",
      "    loss           : 12298.29947076613\n",
      "    val_loss       : 12296.83583519792\n",
      "    val_log_likelihood: -12207.995665968776\n",
      "    val_log_marginal: -12215.668527247073\n",
      "Train Epoch: 348 [256/118836 (0%)] Loss: 12371.021484\n",
      "Train Epoch: 348 [33024/118836 (28%)] Loss: 12367.795898\n",
      "Train Epoch: 348 [65792/118836 (55%)] Loss: 12370.166016\n",
      "Train Epoch: 348 [98560/118836 (83%)] Loss: 12307.422852\n",
      "    epoch          : 348\n",
      "    loss           : 12300.11900460091\n",
      "    val_loss       : 12299.06889796759\n",
      "    val_log_likelihood: -12212.135424582559\n",
      "    val_log_marginal: -12220.004910663207\n",
      "Train Epoch: 349 [256/118836 (0%)] Loss: 12305.313477\n",
      "Train Epoch: 349 [33024/118836 (28%)] Loss: 12338.349609\n",
      "Train Epoch: 349 [65792/118836 (55%)] Loss: 12316.589844\n",
      "Train Epoch: 349 [98560/118836 (83%)] Loss: 12326.011719\n",
      "    epoch          : 349\n",
      "    loss           : 12297.77360987257\n",
      "    val_loss       : 12302.501997293262\n",
      "    val_log_likelihood: -12208.56251340855\n",
      "    val_log_marginal: -12216.223100858666\n",
      "Train Epoch: 350 [256/118836 (0%)] Loss: 12448.176758\n",
      "Train Epoch: 350 [33024/118836 (28%)] Loss: 12421.057617\n",
      "Train Epoch: 350 [65792/118836 (55%)] Loss: 12243.951172\n",
      "Train Epoch: 350 [98560/118836 (83%)] Loss: 12370.155273\n",
      "    epoch          : 350\n",
      "    loss           : 12301.928351006773\n",
      "    val_loss       : 12300.709649903\n",
      "    val_log_likelihood: -12208.088392072477\n",
      "    val_log_marginal: -12215.705450189584\n",
      "Train Epoch: 351 [256/118836 (0%)] Loss: 12380.540039\n",
      "Train Epoch: 351 [33024/118836 (28%)] Loss: 12270.068359\n",
      "Train Epoch: 351 [65792/118836 (55%)] Loss: 12393.363281\n",
      "Train Epoch: 351 [98560/118836 (83%)] Loss: 12355.655273\n",
      "    epoch          : 351\n",
      "    loss           : 12298.01654889759\n",
      "    val_loss       : 12301.93928295987\n",
      "    val_log_likelihood: -12207.942543553558\n",
      "    val_log_marginal: -12215.72598833168\n",
      "Train Epoch: 352 [256/118836 (0%)] Loss: 12395.689453\n",
      "Train Epoch: 352 [33024/118836 (28%)] Loss: 12371.941406\n",
      "Train Epoch: 352 [65792/118836 (55%)] Loss: 12354.587891\n",
      "Train Epoch: 352 [98560/118836 (83%)] Loss: 12375.685547\n",
      "    epoch          : 352\n",
      "    loss           : 12299.148803084936\n",
      "    val_loss       : 12305.124944230476\n",
      "    val_log_likelihood: -12212.626917584264\n",
      "    val_log_marginal: -12220.594994085928\n",
      "Train Epoch: 353 [256/118836 (0%)] Loss: 12312.330078\n",
      "Train Epoch: 353 [33024/118836 (28%)] Loss: 12309.137695\n",
      "Train Epoch: 353 [65792/118836 (55%)] Loss: 12449.992188\n",
      "Train Epoch: 353 [98560/118836 (83%)] Loss: 12282.047852\n",
      "    epoch          : 353\n",
      "    loss           : 12298.710657859026\n",
      "    val_loss       : 12297.600748390561\n",
      "    val_log_likelihood: -12213.395215247621\n",
      "    val_log_marginal: -12221.029942789197\n",
      "Train Epoch: 354 [256/118836 (0%)] Loss: 12348.945312\n",
      "Train Epoch: 354 [33024/118836 (28%)] Loss: 12286.575195\n",
      "Train Epoch: 354 [65792/118836 (55%)] Loss: 12315.718750\n",
      "Train Epoch: 354 [98560/118836 (83%)] Loss: 12345.636719\n",
      "    epoch          : 354\n",
      "    loss           : 12298.278751809346\n",
      "    val_loss       : 12299.869897258975\n",
      "    val_log_likelihood: -12207.445183907155\n",
      "    val_log_marginal: -12215.240403322896\n",
      "Train Epoch: 355 [256/118836 (0%)] Loss: 12313.031250\n",
      "Train Epoch: 355 [33024/118836 (28%)] Loss: 12295.148438\n",
      "Train Epoch: 355 [65792/118836 (55%)] Loss: 12340.257812\n",
      "Train Epoch: 355 [98560/118836 (83%)] Loss: 12358.173828\n",
      "    epoch          : 355\n",
      "    loss           : 12295.149788694167\n",
      "    val_loss       : 12299.282544768097\n",
      "    val_log_likelihood: -12209.36757279389\n",
      "    val_log_marginal: -12216.923047434819\n",
      "Train Epoch: 356 [256/118836 (0%)] Loss: 12271.986328\n",
      "Train Epoch: 356 [33024/118836 (28%)] Loss: 12337.672852\n",
      "Train Epoch: 356 [65792/118836 (55%)] Loss: 12353.124023\n",
      "Train Epoch: 356 [98560/118836 (83%)] Loss: 12343.531250\n",
      "    epoch          : 356\n",
      "    loss           : 12296.744821553195\n",
      "    val_loss       : 12294.143796286135\n",
      "    val_log_likelihood: -12210.249247990332\n",
      "    val_log_marginal: -12217.861036452665\n",
      "Train Epoch: 357 [256/118836 (0%)] Loss: 12345.392578\n",
      "Train Epoch: 357 [33024/118836 (28%)] Loss: 12364.360352\n",
      "Train Epoch: 357 [65792/118836 (55%)] Loss: 12328.247070\n",
      "Train Epoch: 357 [98560/118836 (83%)] Loss: 12403.279297\n",
      "    epoch          : 357\n",
      "    loss           : 12298.627753760857\n",
      "    val_loss       : 12298.323664047288\n",
      "    val_log_likelihood: -12208.40800635856\n",
      "    val_log_marginal: -12215.909103121065\n",
      "Train Epoch: 358 [256/118836 (0%)] Loss: 12372.660156\n",
      "Train Epoch: 358 [33024/118836 (28%)] Loss: 12295.369141\n",
      "Train Epoch: 358 [65792/118836 (55%)] Loss: 12319.241211\n",
      "Train Epoch: 358 [98560/118836 (83%)] Loss: 12453.328125\n",
      "    epoch          : 358\n",
      "    loss           : 12298.610984995348\n",
      "    val_loss       : 12298.739007434802\n",
      "    val_log_likelihood: -12207.590930488781\n",
      "    val_log_marginal: -12215.38579358836\n",
      "Train Epoch: 359 [256/118836 (0%)] Loss: 12255.665039\n",
      "Train Epoch: 359 [33024/118836 (28%)] Loss: 12363.505859\n",
      "Train Epoch: 359 [65792/118836 (55%)] Loss: 12400.312500\n",
      "Train Epoch: 359 [98560/118836 (83%)] Loss: 12284.052734\n",
      "    epoch          : 359\n",
      "    loss           : 12298.93762132315\n",
      "    val_loss       : 12298.203486149489\n",
      "    val_log_likelihood: -12209.09574367375\n",
      "    val_log_marginal: -12216.76803612354\n",
      "Train Epoch: 360 [256/118836 (0%)] Loss: 12260.857422\n",
      "Train Epoch: 360 [33024/118836 (28%)] Loss: 12365.260742\n",
      "Train Epoch: 360 [65792/118836 (55%)] Loss: 12357.348633\n",
      "Train Epoch: 360 [98560/118836 (83%)] Loss: 12350.127930\n",
      "    epoch          : 360\n",
      "    loss           : 12298.364542946134\n",
      "    val_loss       : 12300.796289311096\n",
      "    val_log_likelihood: -12209.926330192824\n",
      "    val_log_marginal: -12217.48918887591\n",
      "Train Epoch: 361 [256/118836 (0%)] Loss: 12379.830078\n",
      "Train Epoch: 361 [33024/118836 (28%)] Loss: 12246.232422\n",
      "Train Epoch: 361 [65792/118836 (55%)] Loss: 12293.250000\n",
      "Train Epoch: 361 [98560/118836 (83%)] Loss: 12318.337891\n",
      "    epoch          : 361\n",
      "    loss           : 12299.009611184347\n",
      "    val_loss       : 12295.628915147347\n",
      "    val_log_likelihood: -12210.723711325216\n",
      "    val_log_marginal: -12218.611435788573\n",
      "Train Epoch: 362 [256/118836 (0%)] Loss: 12359.101562\n",
      "Train Epoch: 362 [33024/118836 (28%)] Loss: 12277.691406\n",
      "Train Epoch: 362 [65792/118836 (55%)] Loss: 12272.968750\n",
      "Train Epoch: 362 [98560/118836 (83%)] Loss: 12393.691406\n",
      "    epoch          : 362\n",
      "    loss           : 12300.060336053815\n",
      "    val_loss       : 12295.217066453633\n",
      "    val_log_likelihood: -12209.932086822788\n",
      "    val_log_marginal: -12217.680371555447\n",
      "Train Epoch: 363 [256/118836 (0%)] Loss: 12308.401367\n",
      "Train Epoch: 363 [33024/118836 (28%)] Loss: 12348.492188\n",
      "Train Epoch: 363 [65792/118836 (55%)] Loss: 12366.761719\n",
      "Train Epoch: 363 [98560/118836 (83%)] Loss: 12322.082031\n",
      "    epoch          : 363\n",
      "    loss           : 12301.001620819117\n",
      "    val_loss       : 12295.177772050203\n",
      "    val_log_likelihood: -12211.812194834316\n",
      "    val_log_marginal: -12219.5393862517\n",
      "Train Epoch: 364 [256/118836 (0%)] Loss: 12431.935547\n",
      "Train Epoch: 364 [33024/118836 (28%)] Loss: 12463.357422\n",
      "Train Epoch: 364 [65792/118836 (55%)] Loss: 12248.750977\n",
      "Train Epoch: 364 [98560/118836 (83%)] Loss: 12421.266602\n",
      "    epoch          : 364\n",
      "    loss           : 12297.88106680366\n",
      "    val_loss       : 12294.549408817531\n",
      "    val_log_likelihood: -12208.967041136788\n",
      "    val_log_marginal: -12216.638388715204\n",
      "Train Epoch: 365 [256/118836 (0%)] Loss: 12334.118164\n",
      "Train Epoch: 365 [33024/118836 (28%)] Loss: 12289.936523\n",
      "Train Epoch: 365 [65792/118836 (55%)] Loss: 12352.560547\n",
      "Train Epoch: 365 [98560/118836 (83%)] Loss: 12346.341797\n",
      "    epoch          : 365\n",
      "    loss           : 12296.791560852203\n",
      "    val_loss       : 12300.044741432099\n",
      "    val_log_likelihood: -12207.965102228081\n",
      "    val_log_marginal: -12215.72322151333\n",
      "Train Epoch: 366 [256/118836 (0%)] Loss: 12362.946289\n",
      "Train Epoch: 366 [33024/118836 (28%)] Loss: 12381.323242\n",
      "Train Epoch: 366 [65792/118836 (55%)] Loss: 12315.486328\n",
      "Train Epoch: 366 [98560/118836 (83%)] Loss: 12352.705078\n",
      "    epoch          : 366\n",
      "    loss           : 12296.667928039704\n",
      "    val_loss       : 12298.33650596668\n",
      "    val_log_likelihood: -12213.091398980305\n",
      "    val_log_marginal: -12220.789773188282\n",
      "Train Epoch: 367 [256/118836 (0%)] Loss: 12317.703125\n",
      "Train Epoch: 367 [33024/118836 (28%)] Loss: 12358.826172\n",
      "Train Epoch: 367 [65792/118836 (55%)] Loss: 12298.612305\n",
      "Train Epoch: 367 [98560/118836 (83%)] Loss: 12353.447266\n",
      "    epoch          : 367\n",
      "    loss           : 12297.320383258375\n",
      "    val_loss       : 12299.69666945722\n",
      "    val_log_likelihood: -12207.376448769644\n",
      "    val_log_marginal: -12215.310048882515\n",
      "Train Epoch: 368 [256/118836 (0%)] Loss: 12242.413086\n",
      "Train Epoch: 368 [33024/118836 (28%)] Loss: 12334.761719\n",
      "Train Epoch: 368 [65792/118836 (55%)] Loss: 12325.824219\n",
      "Train Epoch: 368 [98560/118836 (83%)] Loss: 12255.270508\n",
      "    epoch          : 368\n",
      "    loss           : 12301.759322173542\n",
      "    val_loss       : 12298.991762560538\n",
      "    val_log_likelihood: -12208.28984100367\n",
      "    val_log_marginal: -12216.122175994497\n",
      "Train Epoch: 369 [256/118836 (0%)] Loss: 12219.860352\n",
      "Train Epoch: 369 [33024/118836 (28%)] Loss: 12414.415039\n",
      "Train Epoch: 369 [65792/118836 (55%)] Loss: 12308.740234\n",
      "Train Epoch: 369 [98560/118836 (83%)] Loss: 12251.267578\n",
      "    epoch          : 369\n",
      "    loss           : 12300.795313630842\n",
      "    val_loss       : 12297.152413656038\n",
      "    val_log_likelihood: -12210.085935884512\n",
      "    val_log_marginal: -12217.94308138993\n",
      "Train Epoch: 370 [256/118836 (0%)] Loss: 12285.657227\n",
      "Train Epoch: 370 [33024/118836 (28%)] Loss: 12310.578125\n",
      "Train Epoch: 370 [65792/118836 (55%)] Loss: 12290.274414\n",
      "Train Epoch: 370 [98560/118836 (83%)] Loss: 12370.149414\n",
      "    epoch          : 370\n",
      "    loss           : 12293.840970068239\n",
      "    val_loss       : 12304.463241505911\n",
      "    val_log_likelihood: -12207.327360551075\n",
      "    val_log_marginal: -12215.165041680952\n",
      "Train Epoch: 371 [256/118836 (0%)] Loss: 12289.857422\n",
      "Train Epoch: 371 [33024/118836 (28%)] Loss: 12317.595703\n",
      "Train Epoch: 371 [65792/118836 (55%)] Loss: 12407.897461\n",
      "Train Epoch: 371 [98560/118836 (83%)] Loss: 12397.121094\n",
      "    epoch          : 371\n",
      "    loss           : 12300.508799724721\n",
      "    val_loss       : 12296.286517694323\n",
      "    val_log_likelihood: -12206.816109484853\n",
      "    val_log_marginal: -12214.793639294863\n",
      "Train Epoch: 372 [256/118836 (0%)] Loss: 12306.660156\n",
      "Train Epoch: 372 [33024/118836 (28%)] Loss: 12316.432617\n",
      "Train Epoch: 372 [65792/118836 (55%)] Loss: 12287.045898\n",
      "Train Epoch: 372 [98560/118836 (83%)] Loss: 12289.463867\n",
      "    epoch          : 372\n",
      "    loss           : 12302.02773695978\n",
      "    val_loss       : 12295.845514007906\n",
      "    val_log_likelihood: -12211.164099656224\n",
      "    val_log_marginal: -12219.03132687147\n",
      "Train Epoch: 373 [256/118836 (0%)] Loss: 12248.634766\n",
      "Train Epoch: 373 [33024/118836 (28%)] Loss: 12241.009766\n",
      "Train Epoch: 373 [65792/118836 (55%)] Loss: 12289.621094\n",
      "Train Epoch: 373 [98560/118836 (83%)] Loss: 12321.762695\n",
      "    epoch          : 373\n",
      "    loss           : 12298.270648844602\n",
      "    val_loss       : 12298.125998218338\n",
      "    val_log_likelihood: -12210.695260481287\n",
      "    val_log_marginal: -12218.444969234248\n",
      "Train Epoch: 374 [256/118836 (0%)] Loss: 12372.319336\n",
      "Train Epoch: 374 [33024/118836 (28%)] Loss: 12286.338867\n",
      "Train Epoch: 374 [65792/118836 (55%)] Loss: 12262.201172\n",
      "Train Epoch: 374 [98560/118836 (83%)] Loss: 12336.189453\n",
      "    epoch          : 374\n",
      "    loss           : 12295.24149655578\n",
      "    val_loss       : 12300.087873283146\n",
      "    val_log_likelihood: -12209.73561424085\n",
      "    val_log_marginal: -12217.602985535264\n",
      "Train Epoch: 375 [256/118836 (0%)] Loss: 12363.859375\n",
      "Train Epoch: 375 [33024/118836 (28%)] Loss: 12277.275391\n",
      "Train Epoch: 375 [65792/118836 (55%)] Loss: 12312.095703\n",
      "Train Epoch: 375 [98560/118836 (83%)] Loss: 12321.500977\n",
      "    epoch          : 375\n",
      "    loss           : 12294.172663519696\n",
      "    val_loss       : 12298.753337786406\n",
      "    val_log_likelihood: -12204.66595762898\n",
      "    val_log_marginal: -12212.802483134836\n",
      "Train Epoch: 376 [256/118836 (0%)] Loss: 12326.236328\n",
      "Train Epoch: 376 [33024/118836 (28%)] Loss: 12298.690430\n",
      "Train Epoch: 376 [65792/118836 (55%)] Loss: 12319.651367\n",
      "Train Epoch: 376 [98560/118836 (83%)] Loss: 12344.560547\n",
      "    epoch          : 376\n",
      "    loss           : 12296.541933706834\n",
      "    val_loss       : 12299.033049450063\n",
      "    val_log_likelihood: -12209.049569795543\n",
      "    val_log_marginal: -12216.970064201525\n",
      "Train Epoch: 377 [256/118836 (0%)] Loss: 12357.818359\n",
      "Train Epoch: 377 [33024/118836 (28%)] Loss: 12231.396484\n",
      "Train Epoch: 377 [65792/118836 (55%)] Loss: 12318.869141\n",
      "Train Epoch: 377 [98560/118836 (83%)] Loss: 12171.606445\n",
      "    epoch          : 377\n",
      "    loss           : 12301.207022364817\n",
      "    val_loss       : 12297.283244824688\n",
      "    val_log_likelihood: -12208.945414114194\n",
      "    val_log_marginal: -12216.772735107032\n",
      "Train Epoch: 378 [256/118836 (0%)] Loss: 12350.467773\n",
      "Train Epoch: 378 [33024/118836 (28%)] Loss: 12320.203125\n",
      "Train Epoch: 378 [65792/118836 (55%)] Loss: 12182.049805\n",
      "Train Epoch: 378 [98560/118836 (83%)] Loss: 12325.103516\n",
      "    epoch          : 378\n",
      "    loss           : 12299.04534077104\n",
      "    val_loss       : 12300.17865379325\n",
      "    val_log_likelihood: -12209.006463082867\n",
      "    val_log_marginal: -12216.888470047881\n",
      "Train Epoch: 379 [256/118836 (0%)] Loss: 12333.062500\n",
      "Train Epoch: 379 [33024/118836 (28%)] Loss: 12296.261719\n",
      "Train Epoch: 379 [65792/118836 (55%)] Loss: 12339.343750\n",
      "Train Epoch: 379 [98560/118836 (83%)] Loss: 12308.710938\n",
      "    epoch          : 379\n",
      "    loss           : 12300.104021595844\n",
      "    val_loss       : 12301.156943157512\n",
      "    val_log_likelihood: -12210.03919997803\n",
      "    val_log_marginal: -12217.880167478383\n",
      "Train Epoch: 380 [256/118836 (0%)] Loss: 12331.313477\n",
      "Train Epoch: 380 [33024/118836 (28%)] Loss: 12331.164062\n",
      "Train Epoch: 380 [65792/118836 (55%)] Loss: 12360.207031\n",
      "Train Epoch: 380 [98560/118836 (83%)] Loss: 12365.554688\n",
      "    epoch          : 380\n",
      "    loss           : 12301.183792131927\n",
      "    val_loss       : 12298.383410140083\n",
      "    val_log_likelihood: -12210.606101375104\n",
      "    val_log_marginal: -12218.74516873171\n",
      "Train Epoch: 381 [256/118836 (0%)] Loss: 12240.045898\n",
      "Train Epoch: 381 [33024/118836 (28%)] Loss: 12356.750000\n",
      "Train Epoch: 381 [65792/118836 (55%)] Loss: 12403.052734\n",
      "Train Epoch: 381 [98560/118836 (83%)] Loss: 12283.058594\n",
      "    epoch          : 381\n",
      "    loss           : 12296.43280296862\n",
      "    val_loss       : 12293.606008825047\n",
      "    val_log_likelihood: -12207.481463405966\n",
      "    val_log_marginal: -12215.359588131054\n",
      "Train Epoch: 382 [256/118836 (0%)] Loss: 12231.132812\n",
      "Train Epoch: 382 [33024/118836 (28%)] Loss: 12343.242188\n",
      "Train Epoch: 382 [65792/118836 (55%)] Loss: 12306.855469\n",
      "Train Epoch: 382 [98560/118836 (83%)] Loss: 12368.208984\n",
      "    epoch          : 382\n",
      "    loss           : 12300.216055204457\n",
      "    val_loss       : 12296.200433723234\n",
      "    val_log_likelihood: -12208.05112744908\n",
      "    val_log_marginal: -12215.892044864124\n",
      "Train Epoch: 383 [256/118836 (0%)] Loss: 12248.169922\n",
      "Train Epoch: 383 [33024/118836 (28%)] Loss: 12352.114258\n",
      "Train Epoch: 383 [65792/118836 (55%)] Loss: 12341.913086\n",
      "Train Epoch: 383 [98560/118836 (83%)] Loss: 12355.716797\n",
      "    epoch          : 383\n",
      "    loss           : 12294.362022784842\n",
      "    val_loss       : 12297.074108517823\n",
      "    val_log_likelihood: -12215.515471690189\n",
      "    val_log_marginal: -12223.363834471133\n",
      "Train Epoch: 384 [256/118836 (0%)] Loss: 12324.222656\n",
      "Train Epoch: 384 [33024/118836 (28%)] Loss: 12316.837891\n",
      "Train Epoch: 384 [65792/118836 (55%)] Loss: 12262.093750\n",
      "Train Epoch: 384 [98560/118836 (83%)] Loss: 12374.223633\n",
      "    epoch          : 384\n",
      "    loss           : 12297.00068286678\n",
      "    val_loss       : 12293.4681810936\n",
      "    val_log_likelihood: -12206.102688333593\n",
      "    val_log_marginal: -12214.019944663443\n",
      "Train Epoch: 385 [256/118836 (0%)] Loss: 12282.410156\n",
      "Train Epoch: 385 [33024/118836 (28%)] Loss: 12366.945312\n",
      "Train Epoch: 385 [65792/118836 (55%)] Loss: 12258.486328\n",
      "Train Epoch: 385 [98560/118836 (83%)] Loss: 12330.757812\n",
      "    epoch          : 385\n",
      "    loss           : 12293.902196255945\n",
      "    val_loss       : 12304.947414116992\n",
      "    val_log_likelihood: -12211.197066758426\n",
      "    val_log_marginal: -12219.230789258394\n",
      "Train Epoch: 386 [256/118836 (0%)] Loss: 12408.525391\n",
      "Train Epoch: 386 [33024/118836 (28%)] Loss: 12259.455078\n",
      "Train Epoch: 386 [65792/118836 (55%)] Loss: 12293.494141\n",
      "Train Epoch: 386 [98560/118836 (83%)] Loss: 12362.324219\n",
      "    epoch          : 386\n",
      "    loss           : 12295.638612263494\n",
      "    val_loss       : 12294.298522471727\n",
      "    val_log_likelihood: -12204.212712921319\n",
      "    val_log_marginal: -12212.017769193699\n",
      "Train Epoch: 387 [256/118836 (0%)] Loss: 12295.582031\n",
      "Train Epoch: 387 [33024/118836 (28%)] Loss: 12296.525391\n",
      "Train Epoch: 387 [65792/118836 (55%)] Loss: 12302.137695\n",
      "Train Epoch: 387 [98560/118836 (83%)] Loss: 12333.226562\n",
      "    epoch          : 387\n",
      "    loss           : 12296.44754591217\n",
      "    val_loss       : 12294.692962562816\n",
      "    val_log_likelihood: -12206.825037317773\n",
      "    val_log_marginal: -12214.565892471051\n",
      "Train Epoch: 388 [256/118836 (0%)] Loss: 12297.472656\n",
      "Train Epoch: 388 [33024/118836 (28%)] Loss: 12251.243164\n",
      "Train Epoch: 388 [65792/118836 (55%)] Loss: 12382.863281\n",
      "Train Epoch: 388 [98560/118836 (83%)] Loss: 12389.671875\n",
      "    epoch          : 388\n",
      "    loss           : 12296.084302464587\n",
      "    val_loss       : 12296.741401754942\n",
      "    val_log_likelihood: -12207.625994655966\n",
      "    val_log_marginal: -12215.790674328424\n",
      "Train Epoch: 389 [256/118836 (0%)] Loss: 12333.015625\n",
      "Train Epoch: 389 [33024/118836 (28%)] Loss: 12249.593750\n",
      "Train Epoch: 389 [65792/118836 (55%)] Loss: 12355.889648\n",
      "Train Epoch: 389 [98560/118836 (83%)] Loss: 12284.763672\n",
      "    epoch          : 389\n",
      "    loss           : 12297.832939800455\n",
      "    val_loss       : 12294.030112509763\n",
      "    val_log_likelihood: -12206.925621316688\n",
      "    val_log_marginal: -12214.878466321634\n",
      "Train Epoch: 390 [256/118836 (0%)] Loss: 12224.951172\n",
      "Train Epoch: 390 [33024/118836 (28%)] Loss: 12291.147461\n",
      "Train Epoch: 390 [65792/118836 (55%)] Loss: 12242.388672\n",
      "Train Epoch: 390 [98560/118836 (83%)] Loss: 12316.743164\n",
      "    epoch          : 390\n",
      "    loss           : 12295.845571624275\n",
      "    val_loss       : 12304.291350215852\n",
      "    val_log_likelihood: -12221.363333268713\n",
      "    val_log_marginal: -12229.759378676416\n",
      "Train Epoch: 391 [256/118836 (0%)] Loss: 12382.423828\n",
      "Train Epoch: 391 [33024/118836 (28%)] Loss: 12365.923828\n",
      "Train Epoch: 391 [65792/118836 (55%)] Loss: 12391.538086\n",
      "Train Epoch: 391 [98560/118836 (83%)] Loss: 12338.959961\n",
      "    epoch          : 391\n",
      "    loss           : 12295.762977215158\n",
      "    val_loss       : 12295.892453218217\n",
      "    val_log_likelihood: -12208.63567627559\n",
      "    val_log_marginal: -12216.523467209103\n",
      "Train Epoch: 392 [256/118836 (0%)] Loss: 12406.640625\n",
      "Train Epoch: 392 [33024/118836 (28%)] Loss: 12406.888672\n",
      "Train Epoch: 392 [65792/118836 (55%)] Loss: 12315.246094\n",
      "Train Epoch: 392 [98560/118836 (83%)] Loss: 12256.638672\n",
      "    epoch          : 392\n",
      "    loss           : 12298.406808635753\n",
      "    val_loss       : 12298.229617211342\n",
      "    val_log_likelihood: -12212.436467380066\n",
      "    val_log_marginal: -12220.292689068374\n",
      "Train Epoch: 393 [256/118836 (0%)] Loss: 12342.176758\n",
      "Train Epoch: 393 [33024/118836 (28%)] Loss: 12301.226562\n",
      "Train Epoch: 393 [65792/118836 (55%)] Loss: 12274.655273\n",
      "Train Epoch: 393 [98560/118836 (83%)] Loss: 12370.498047\n",
      "    epoch          : 393\n",
      "    loss           : 12295.668680534016\n",
      "    val_loss       : 12298.209981682297\n",
      "    val_log_likelihood: -12206.805628037118\n",
      "    val_log_marginal: -12214.669889209476\n",
      "Train Epoch: 394 [256/118836 (0%)] Loss: 12330.586914\n",
      "Train Epoch: 394 [33024/118836 (28%)] Loss: 12283.634766\n",
      "Train Epoch: 394 [65792/118836 (55%)] Loss: 12383.750000\n",
      "Train Epoch: 394 [98560/118836 (83%)] Loss: 12254.449219\n",
      "    epoch          : 394\n",
      "    loss           : 12295.00053472653\n",
      "    val_loss       : 12293.161955648759\n",
      "    val_log_likelihood: -12205.941435328785\n",
      "    val_log_marginal: -12213.77201673349\n",
      "Train Epoch: 395 [256/118836 (0%)] Loss: 12388.418945\n",
      "Train Epoch: 395 [33024/118836 (28%)] Loss: 12266.239258\n",
      "Train Epoch: 395 [65792/118836 (55%)] Loss: 12262.052734\n",
      "Train Epoch: 395 [98560/118836 (83%)] Loss: 12266.912109\n",
      "    epoch          : 395\n",
      "    loss           : 12295.220389558777\n",
      "    val_loss       : 12295.494629812067\n",
      "    val_log_likelihood: -12212.467985066429\n",
      "    val_log_marginal: -12220.44545496888\n",
      "Train Epoch: 396 [256/118836 (0%)] Loss: 12278.891602\n",
      "Train Epoch: 396 [33024/118836 (28%)] Loss: 12343.625977\n",
      "Train Epoch: 396 [65792/118836 (55%)] Loss: 12314.372070\n",
      "Train Epoch: 396 [98560/118836 (83%)] Loss: 12300.475586\n",
      "    epoch          : 396\n",
      "    loss           : 12301.724335226685\n",
      "    val_loss       : 12293.021336340313\n",
      "    val_log_likelihood: -12208.85198284998\n",
      "    val_log_marginal: -12216.873349405641\n",
      "Train Epoch: 397 [256/118836 (0%)] Loss: 12319.376953\n",
      "Train Epoch: 397 [33024/118836 (28%)] Loss: 12299.271484\n",
      "Train Epoch: 397 [65792/118836 (55%)] Loss: 12274.443359\n",
      "Train Epoch: 397 [98560/118836 (83%)] Loss: 12367.723633\n",
      "    epoch          : 397\n",
      "    loss           : 12293.097888557177\n",
      "    val_loss       : 12296.479995602585\n",
      "    val_log_likelihood: -12215.160259964328\n",
      "    val_log_marginal: -12223.21857977644\n",
      "Train Epoch: 398 [256/118836 (0%)] Loss: 12312.742188\n",
      "Train Epoch: 398 [33024/118836 (28%)] Loss: 12324.577148\n",
      "Train Epoch: 398 [65792/118836 (55%)] Loss: 12314.099609\n",
      "Train Epoch: 398 [98560/118836 (83%)] Loss: 12321.948242\n",
      "    epoch          : 398\n",
      "    loss           : 12293.896902463297\n",
      "    val_loss       : 12295.50776258505\n",
      "    val_log_likelihood: -12208.304423044614\n",
      "    val_log_marginal: -12216.271685721036\n",
      "Train Epoch: 399 [256/118836 (0%)] Loss: 12289.446289\n",
      "Train Epoch: 399 [33024/118836 (28%)] Loss: 12312.765625\n",
      "Train Epoch: 399 [65792/118836 (55%)] Loss: 12285.486328\n",
      "Train Epoch: 399 [98560/118836 (83%)] Loss: 12310.208984\n",
      "    epoch          : 399\n",
      "    loss           : 12291.918070041098\n",
      "    val_loss       : 12309.415490720097\n",
      "    val_log_likelihood: -12225.666944530603\n",
      "    val_log_marginal: -12234.296116542484\n",
      "Train Epoch: 400 [256/118836 (0%)] Loss: 12328.969727\n",
      "Train Epoch: 400 [33024/118836 (28%)] Loss: 12291.244141\n",
      "Train Epoch: 400 [65792/118836 (55%)] Loss: 12300.110352\n",
      "Train Epoch: 400 [98560/118836 (83%)] Loss: 12303.449219\n",
      "    epoch          : 400\n",
      "    loss           : 12298.73245289237\n",
      "    val_loss       : 12296.811077347922\n",
      "    val_log_likelihood: -12208.84779905914\n",
      "    val_log_marginal: -12216.910097998118\n",
      "Saving checkpoint: saved/models/SelfiesAutoencodingOperad/0905_154251/checkpoint-epoch400.pth ...\n",
      "Train Epoch: 401 [256/118836 (0%)] Loss: 12284.039062\n",
      "Train Epoch: 401 [33024/118836 (28%)] Loss: 12415.045898\n",
      "Train Epoch: 401 [65792/118836 (55%)] Loss: 12268.283203\n",
      "Train Epoch: 401 [98560/118836 (83%)] Loss: 12358.696289\n",
      "    epoch          : 401\n",
      "    loss           : 12297.836406637716\n",
      "    val_loss       : 12295.603819080467\n",
      "    val_log_likelihood: -12208.561759944945\n",
      "    val_log_marginal: -12216.565276701118\n",
      "Train Epoch: 402 [256/118836 (0%)] Loss: 12434.114258\n",
      "Train Epoch: 402 [33024/118836 (28%)] Loss: 12291.358398\n",
      "Train Epoch: 402 [65792/118836 (55%)] Loss: 12275.165039\n",
      "Train Epoch: 402 [98560/118836 (83%)] Loss: 12274.046875\n",
      "    epoch          : 402\n",
      "    loss           : 12294.121909894542\n",
      "    val_loss       : 12293.64160592589\n",
      "    val_log_likelihood: -12206.606662434087\n",
      "    val_log_marginal: -12214.347655659865\n",
      "Train Epoch: 403 [256/118836 (0%)] Loss: 12348.325195\n",
      "Train Epoch: 403 [33024/118836 (28%)] Loss: 12359.340820\n",
      "Train Epoch: 403 [65792/118836 (55%)] Loss: 12353.035156\n",
      "Train Epoch: 403 [98560/118836 (83%)] Loss: 12227.976562\n",
      "    epoch          : 403\n",
      "    loss           : 12297.427621290839\n",
      "    val_loss       : 12291.673222357862\n",
      "    val_log_likelihood: -12208.316431613162\n",
      "    val_log_marginal: -12216.317184132833\n",
      "Train Epoch: 404 [256/118836 (0%)] Loss: 12330.367188\n",
      "Train Epoch: 404 [33024/118836 (28%)] Loss: 12357.786133\n",
      "Train Epoch: 404 [65792/118836 (55%)] Loss: 12281.460938\n",
      "Train Epoch: 404 [98560/118836 (83%)] Loss: 12389.485352\n",
      "    epoch          : 404\n",
      "    loss           : 12294.02970882444\n",
      "    val_loss       : 12296.34591628811\n",
      "    val_log_likelihood: -12209.073816493486\n",
      "    val_log_marginal: -12217.356474189393\n",
      "Train Epoch: 405 [256/118836 (0%)] Loss: 12294.456055\n",
      "Train Epoch: 405 [33024/118836 (28%)] Loss: 12338.583984\n",
      "Train Epoch: 405 [65792/118836 (55%)] Loss: 12405.039062\n",
      "Train Epoch: 405 [98560/118836 (83%)] Loss: 12308.713867\n",
      "    epoch          : 405\n",
      "    loss           : 12296.202896408446\n",
      "    val_loss       : 12304.713251340701\n",
      "    val_log_likelihood: -12214.155188462832\n",
      "    val_log_marginal: -12222.585474412637\n",
      "Train Epoch: 406 [256/118836 (0%)] Loss: 12267.757812\n",
      "Train Epoch: 406 [33024/118836 (28%)] Loss: 12215.401367\n",
      "Train Epoch: 406 [65792/118836 (55%)] Loss: 12273.497070\n",
      "Train Epoch: 406 [98560/118836 (83%)] Loss: 12296.062500\n",
      "    epoch          : 406\n",
      "    loss           : 12297.695034797613\n",
      "    val_loss       : 12299.221292538437\n",
      "    val_log_likelihood: -12206.922249631667\n",
      "    val_log_marginal: -12215.139105727643\n",
      "Train Epoch: 407 [256/118836 (0%)] Loss: 12349.719727\n",
      "Train Epoch: 407 [33024/118836 (28%)] Loss: 12257.734375\n",
      "Train Epoch: 407 [65792/118836 (55%)] Loss: 12358.904297\n",
      "Train Epoch: 407 [98560/118836 (83%)] Loss: 12329.569336\n",
      "    epoch          : 407\n",
      "    loss           : 12298.064284144955\n",
      "    val_loss       : 12295.306539993884\n",
      "    val_log_likelihood: -12205.256849992245\n",
      "    val_log_marginal: -12213.205198623742\n",
      "Train Epoch: 408 [256/118836 (0%)] Loss: 12373.302734\n",
      "Train Epoch: 408 [33024/118836 (28%)] Loss: 12435.070312\n",
      "Train Epoch: 408 [65792/118836 (55%)] Loss: 12368.975586\n",
      "Train Epoch: 408 [98560/118836 (83%)] Loss: 12307.101562\n",
      "    epoch          : 408\n",
      "    loss           : 12295.584922004238\n",
      "    val_loss       : 12299.997609177319\n",
      "    val_log_likelihood: -12207.298776267835\n",
      "    val_log_marginal: -12215.33493108485\n",
      "Train Epoch: 409 [256/118836 (0%)] Loss: 12277.876953\n",
      "Train Epoch: 409 [33024/118836 (28%)] Loss: 12406.487305\n",
      "Train Epoch: 409 [65792/118836 (55%)] Loss: 12304.980469\n",
      "Train Epoch: 409 [98560/118836 (83%)] Loss: 12353.818359\n",
      "    epoch          : 409\n",
      "    loss           : 12295.65238688353\n",
      "    val_loss       : 12295.824315118803\n",
      "    val_log_likelihood: -12204.737478029363\n",
      "    val_log_marginal: -12212.848347690477\n",
      "Train Epoch: 410 [256/118836 (0%)] Loss: 12311.226562\n",
      "Train Epoch: 410 [33024/118836 (28%)] Loss: 12267.156250\n",
      "Train Epoch: 410 [65792/118836 (55%)] Loss: 12295.484375\n",
      "Train Epoch: 410 [98560/118836 (83%)] Loss: 12307.226562\n",
      "    epoch          : 410\n",
      "    loss           : 12294.081270839795\n",
      "    val_loss       : 12293.802501792878\n",
      "    val_log_likelihood: -12204.67947474023\n",
      "    val_log_marginal: -12212.604208405715\n",
      "Train Epoch: 411 [256/118836 (0%)] Loss: 12331.417969\n",
      "Train Epoch: 411 [33024/118836 (28%)] Loss: 12303.411133\n",
      "Train Epoch: 411 [65792/118836 (55%)] Loss: 12287.804688\n",
      "Train Epoch: 411 [98560/118836 (83%)] Loss: 12330.955078\n",
      "    epoch          : 411\n",
      "    loss           : 12293.562383200217\n",
      "    val_loss       : 12300.549261158374\n",
      "    val_log_likelihood: -12204.770967418839\n",
      "    val_log_marginal: -12212.802696324437\n",
      "Train Epoch: 412 [256/118836 (0%)] Loss: 12383.625000\n",
      "Train Epoch: 412 [33024/118836 (28%)] Loss: 12228.509766\n",
      "Train Epoch: 412 [65792/118836 (55%)] Loss: 12348.279297\n",
      "Train Epoch: 412 [98560/118836 (83%)] Loss: 12268.114258\n",
      "    epoch          : 412\n",
      "    loss           : 12294.577746168063\n",
      "    val_loss       : 12293.829831046953\n",
      "    val_log_likelihood: -12209.347606654517\n",
      "    val_log_marginal: -12217.55160447714\n",
      "Train Epoch: 413 [256/118836 (0%)] Loss: 12315.965820\n",
      "Train Epoch: 413 [33024/118836 (28%)] Loss: 12294.389648\n",
      "Train Epoch: 413 [65792/118836 (55%)] Loss: 12456.642578\n",
      "Train Epoch: 413 [98560/118836 (83%)] Loss: 12258.841797\n",
      "    epoch          : 413\n",
      "    loss           : 12296.759330250981\n",
      "    val_loss       : 12295.678279260805\n",
      "    val_log_likelihood: -12205.00582028019\n",
      "    val_log_marginal: -12213.289013869127\n",
      "Train Epoch: 414 [256/118836 (0%)] Loss: 12270.463867\n",
      "Train Epoch: 414 [33024/118836 (28%)] Loss: 12350.835938\n",
      "Train Epoch: 414 [65792/118836 (55%)] Loss: 12293.046875\n",
      "Train Epoch: 414 [98560/118836 (83%)] Loss: 12328.383789\n",
      "    epoch          : 414\n",
      "    loss           : 12296.122288403381\n",
      "    val_loss       : 12294.961082652171\n",
      "    val_log_likelihood: -12204.163417758737\n",
      "    val_log_marginal: -12212.208128684462\n",
      "Train Epoch: 415 [256/118836 (0%)] Loss: 12262.811523\n",
      "Train Epoch: 415 [33024/118836 (28%)] Loss: 12223.563477\n",
      "Train Epoch: 415 [65792/118836 (55%)] Loss: 12311.863281\n",
      "Train Epoch: 415 [98560/118836 (83%)] Loss: 12346.384766\n",
      "    epoch          : 415\n",
      "    loss           : 12294.74666757134\n",
      "    val_loss       : 12297.467572284268\n",
      "    val_log_likelihood: -12215.768431102666\n",
      "    val_log_marginal: -12224.438683915248\n",
      "Train Epoch: 416 [256/118836 (0%)] Loss: 12249.670898\n",
      "Train Epoch: 416 [33024/118836 (28%)] Loss: 12362.024414\n",
      "Train Epoch: 416 [65792/118836 (55%)] Loss: 12309.875000\n",
      "Train Epoch: 416 [98560/118836 (83%)] Loss: 12338.898438\n",
      "    epoch          : 416\n",
      "    loss           : 12294.88072448175\n",
      "    val_loss       : 12294.167201438853\n",
      "    val_log_likelihood: -12204.157576315654\n",
      "    val_log_marginal: -12212.392322873666\n",
      "Train Epoch: 417 [256/118836 (0%)] Loss: 12322.162109\n",
      "Train Epoch: 417 [33024/118836 (28%)] Loss: 12237.504883\n",
      "Train Epoch: 417 [65792/118836 (55%)] Loss: 12340.684570\n",
      "Train Epoch: 417 [98560/118836 (83%)] Loss: 12434.692383\n",
      "    epoch          : 417\n",
      "    loss           : 12293.35901248449\n",
      "    val_loss       : 12292.717907863924\n",
      "    val_log_likelihood: -12199.29434530733\n",
      "    val_log_marginal: -12207.295715263215\n",
      "Train Epoch: 418 [256/118836 (0%)] Loss: 12413.362305\n",
      "Train Epoch: 418 [33024/118836 (28%)] Loss: 12366.022461\n",
      "Train Epoch: 418 [65792/118836 (55%)] Loss: 12280.065430\n",
      "Train Epoch: 418 [98560/118836 (83%)] Loss: 12268.460938\n",
      "    epoch          : 418\n",
      "    loss           : 12292.094896673387\n",
      "    val_loss       : 12292.32472483307\n",
      "    val_log_likelihood: -12202.912395154828\n",
      "    val_log_marginal: -12210.823458771305\n",
      "Train Epoch: 419 [256/118836 (0%)] Loss: 12375.582031\n",
      "Train Epoch: 419 [33024/118836 (28%)] Loss: 12346.605469\n",
      "Train Epoch: 419 [65792/118836 (55%)] Loss: 12272.698242\n",
      "Train Epoch: 419 [98560/118836 (83%)] Loss: 12273.222656\n",
      "    epoch          : 419\n",
      "    loss           : 12292.046534616677\n",
      "    val_loss       : 12295.100499167094\n",
      "    val_log_likelihood: -12203.69204194453\n",
      "    val_log_marginal: -12211.486289186894\n",
      "Train Epoch: 420 [256/118836 (0%)] Loss: 12399.241211\n",
      "Train Epoch: 420 [33024/118836 (28%)] Loss: 12301.150391\n",
      "Train Epoch: 420 [65792/118836 (55%)] Loss: 12354.618164\n",
      "Train Epoch: 420 [98560/118836 (83%)] Loss: 12403.099609\n",
      "    epoch          : 420\n",
      "    loss           : 12293.735086137822\n",
      "    val_loss       : 12293.606481729503\n",
      "    val_log_likelihood: -12200.676060890974\n",
      "    val_log_marginal: -12208.576566013862\n",
      "Train Epoch: 421 [256/118836 (0%)] Loss: 12307.866211\n",
      "Train Epoch: 421 [33024/118836 (28%)] Loss: 12260.039062\n",
      "Train Epoch: 421 [65792/118836 (55%)] Loss: 12393.028320\n",
      "Train Epoch: 421 [98560/118836 (83%)] Loss: 12376.344727\n",
      "    epoch          : 421\n",
      "    loss           : 12290.906183764992\n",
      "    val_loss       : 12290.402913536214\n",
      "    val_log_likelihood: -12200.593260022488\n",
      "    val_log_marginal: -12208.50289077058\n",
      "Train Epoch: 422 [256/118836 (0%)] Loss: 12216.725586\n",
      "Train Epoch: 422 [33024/118836 (28%)] Loss: 12294.759766\n",
      "Train Epoch: 422 [65792/118836 (55%)] Loss: 12348.662109\n",
      "Train Epoch: 422 [98560/118836 (83%)] Loss: 12177.268555\n",
      "    epoch          : 422\n",
      "    loss           : 12291.781432873244\n",
      "    val_loss       : 12295.511529771924\n",
      "    val_log_likelihood: -12202.462216320306\n",
      "    val_log_marginal: -12210.484238501751\n",
      "Train Epoch: 423 [256/118836 (0%)] Loss: 12266.847656\n",
      "Train Epoch: 423 [33024/118836 (28%)] Loss: 12287.117188\n",
      "Train Epoch: 423 [65792/118836 (55%)] Loss: 12300.537109\n",
      "Train Epoch: 423 [98560/118836 (83%)] Loss: 12352.335938\n",
      "    epoch          : 423\n",
      "    loss           : 12290.505767453733\n",
      "    val_loss       : 12294.614138214632\n",
      "    val_log_likelihood: -12202.259154324338\n",
      "    val_log_marginal: -12209.97183098678\n",
      "Train Epoch: 424 [256/118836 (0%)] Loss: 12364.284180\n",
      "Train Epoch: 424 [33024/118836 (28%)] Loss: 12363.540039\n",
      "Train Epoch: 424 [65792/118836 (55%)] Loss: 12286.326172\n",
      "Train Epoch: 424 [98560/118836 (83%)] Loss: 12233.585938\n",
      "    epoch          : 424\n",
      "    loss           : 12293.548644444014\n",
      "    val_loss       : 12292.15471371849\n",
      "    val_log_likelihood: -12205.10525308235\n",
      "    val_log_marginal: -12213.286453871058\n",
      "Train Epoch: 425 [256/118836 (0%)] Loss: 12292.255859\n",
      "Train Epoch: 425 [33024/118836 (28%)] Loss: 12338.802734\n",
      "Train Epoch: 425 [65792/118836 (55%)] Loss: 12261.950195\n",
      "Train Epoch: 425 [98560/118836 (83%)] Loss: 12251.549805\n",
      "    epoch          : 425\n",
      "    loss           : 12291.967886037015\n",
      "    val_loss       : 12286.587402502215\n",
      "    val_log_likelihood: -12205.192611404054\n",
      "    val_log_marginal: -12212.968697579692\n",
      "Train Epoch: 426 [256/118836 (0%)] Loss: 12383.066406\n",
      "Train Epoch: 426 [33024/118836 (28%)] Loss: 12328.929688\n",
      "Train Epoch: 426 [65792/118836 (55%)] Loss: 12340.424805\n",
      "Train Epoch: 426 [98560/118836 (83%)] Loss: 12267.294922\n",
      "    epoch          : 426\n",
      "    loss           : 12292.621703273624\n",
      "    val_loss       : 12290.023742658524\n",
      "    val_log_likelihood: -12208.791997033964\n",
      "    val_log_marginal: -12216.817793547894\n",
      "Train Epoch: 427 [256/118836 (0%)] Loss: 12390.371094\n",
      "Train Epoch: 427 [33024/118836 (28%)] Loss: 12223.677734\n",
      "Train Epoch: 427 [65792/118836 (55%)] Loss: 12406.875977\n",
      "Train Epoch: 427 [98560/118836 (83%)] Loss: 12361.544922\n",
      "    epoch          : 427\n",
      "    loss           : 12288.944629310121\n",
      "    val_loss       : 12296.224591845457\n",
      "    val_log_likelihood: -12201.679758258375\n",
      "    val_log_marginal: -12209.734378539526\n",
      "Train Epoch: 428 [256/118836 (0%)] Loss: 12337.291016\n",
      "Train Epoch: 428 [33024/118836 (28%)] Loss: 12234.581055\n",
      "Train Epoch: 428 [65792/118836 (55%)] Loss: 12346.886719\n",
      "Train Epoch: 428 [98560/118836 (83%)] Loss: 12328.375000\n",
      "    epoch          : 428\n",
      "    loss           : 12293.758289715157\n",
      "    val_loss       : 12298.147765494683\n",
      "    val_log_likelihood: -12209.627275253308\n",
      "    val_log_marginal: -12218.452182976605\n",
      "Train Epoch: 429 [256/118836 (0%)] Loss: 12383.943359\n",
      "Train Epoch: 429 [33024/118836 (28%)] Loss: 12401.749023\n",
      "Train Epoch: 429 [65792/118836 (55%)] Loss: 12267.197266\n",
      "Train Epoch: 429 [98560/118836 (83%)] Loss: 12338.115234\n",
      "    epoch          : 429\n",
      "    loss           : 12292.472957053868\n",
      "    val_loss       : 12288.328658424618\n",
      "    val_log_likelihood: -12199.000044749018\n",
      "    val_log_marginal: -12206.800396029494\n",
      "Train Epoch: 430 [256/118836 (0%)] Loss: 12344.121094\n",
      "Train Epoch: 430 [33024/118836 (28%)] Loss: 12333.052734\n",
      "Train Epoch: 430 [65792/118836 (55%)] Loss: 12298.808594\n",
      "Train Epoch: 430 [98560/118836 (83%)] Loss: 12284.055664\n",
      "    epoch          : 430\n",
      "    loss           : 12285.367345817824\n",
      "    val_loss       : 12289.135033130608\n",
      "    val_log_likelihood: -12203.48359391155\n",
      "    val_log_marginal: -12211.278216945746\n",
      "Train Epoch: 431 [256/118836 (0%)] Loss: 12217.361328\n",
      "Train Epoch: 431 [33024/118836 (28%)] Loss: 12286.746094\n",
      "Train Epoch: 431 [65792/118836 (55%)] Loss: 12283.463867\n",
      "Train Epoch: 431 [98560/118836 (83%)] Loss: 12345.382812\n",
      "    epoch          : 431\n",
      "    loss           : 12289.965656825112\n",
      "    val_loss       : 12290.233524456058\n",
      "    val_log_likelihood: -12199.996939619521\n",
      "    val_log_marginal: -12208.063259934344\n",
      "Train Epoch: 432 [256/118836 (0%)] Loss: 12371.140625\n",
      "Train Epoch: 432 [33024/118836 (28%)] Loss: 12409.003906\n",
      "Train Epoch: 432 [65792/118836 (55%)] Loss: 12269.565430\n",
      "Train Epoch: 432 [98560/118836 (83%)] Loss: 12328.001953\n",
      "    epoch          : 432\n",
      "    loss           : 12291.654663752326\n",
      "    val_loss       : 12288.285074518908\n",
      "    val_log_likelihood: -12198.682762096774\n",
      "    val_log_marginal: -12206.461384402044\n",
      "Train Epoch: 433 [256/118836 (0%)] Loss: 12318.947266\n",
      "Train Epoch: 433 [33024/118836 (28%)] Loss: 12322.857422\n",
      "Train Epoch: 433 [65792/118836 (55%)] Loss: 12233.247070\n",
      "Train Epoch: 433 [98560/118836 (83%)] Loss: 12234.320312\n",
      "    epoch          : 433\n",
      "    loss           : 12296.37664731312\n",
      "    val_loss       : 12295.882448963368\n",
      "    val_log_likelihood: -12198.583869513803\n",
      "    val_log_marginal: -12206.784669907356\n",
      "Train Epoch: 434 [256/118836 (0%)] Loss: 12334.640625\n",
      "Train Epoch: 434 [33024/118836 (28%)] Loss: 12273.066406\n",
      "Train Epoch: 434 [65792/118836 (55%)] Loss: 12288.996094\n",
      "Train Epoch: 434 [98560/118836 (83%)] Loss: 12387.592773\n",
      "    epoch          : 434\n",
      "    loss           : 12290.169142725135\n",
      "    val_loss       : 12288.995002549185\n",
      "    val_log_likelihood: -12206.122071927988\n",
      "    val_log_marginal: -12213.959446620747\n",
      "Train Epoch: 435 [256/118836 (0%)] Loss: 12273.400391\n",
      "Train Epoch: 435 [33024/118836 (28%)] Loss: 12340.710938\n",
      "Train Epoch: 435 [65792/118836 (55%)] Loss: 12241.230469\n",
      "Train Epoch: 435 [98560/118836 (83%)] Loss: 12377.137695\n",
      "    epoch          : 435\n",
      "    loss           : 12288.055922217483\n",
      "    val_loss       : 12294.332144324451\n",
      "    val_log_likelihood: -12199.550693367451\n",
      "    val_log_marginal: -12207.36736820309\n",
      "Train Epoch: 436 [256/118836 (0%)] Loss: 12313.154297\n",
      "Train Epoch: 436 [33024/118836 (28%)] Loss: 12299.375000\n",
      "Train Epoch: 436 [65792/118836 (55%)] Loss: 12310.976562\n",
      "Train Epoch: 436 [98560/118836 (83%)] Loss: 12288.429688\n",
      "    epoch          : 436\n",
      "    loss           : 12294.354504303661\n",
      "    val_loss       : 12289.259059076443\n",
      "    val_log_likelihood: -12208.498933777915\n",
      "    val_log_marginal: -12216.635220896545\n",
      "Train Epoch: 437 [256/118836 (0%)] Loss: 12289.492188\n",
      "Train Epoch: 437 [33024/118836 (28%)] Loss: 12230.985352\n",
      "Train Epoch: 437 [65792/118836 (55%)] Loss: 12332.874023\n",
      "Train Epoch: 437 [98560/118836 (83%)] Loss: 12344.716797\n",
      "    epoch          : 437\n",
      "    loss           : 12292.922905035153\n",
      "    val_loss       : 12290.085068506967\n",
      "    val_log_likelihood: -12200.97642227564\n",
      "    val_log_marginal: -12209.018927100964\n",
      "Train Epoch: 438 [256/118836 (0%)] Loss: 12307.696289\n",
      "Train Epoch: 438 [33024/118836 (28%)] Loss: 12376.335938\n",
      "Train Epoch: 438 [65792/118836 (55%)] Loss: 12296.140625\n",
      "Train Epoch: 438 [98560/118836 (83%)] Loss: 12330.719727\n",
      "    epoch          : 438\n",
      "    loss           : 12295.709164501914\n",
      "    val_loss       : 12290.93651295451\n",
      "    val_log_likelihood: -12200.181334974668\n",
      "    val_log_marginal: -12208.113495777183\n",
      "Train Epoch: 439 [256/118836 (0%)] Loss: 12332.506836\n",
      "Train Epoch: 439 [33024/118836 (28%)] Loss: 12270.982422\n",
      "Train Epoch: 439 [65792/118836 (55%)] Loss: 12289.431641\n",
      "Train Epoch: 439 [98560/118836 (83%)] Loss: 12192.532227\n",
      "    epoch          : 439\n",
      "    loss           : 12294.0216727409\n",
      "    val_loss       : 12288.678679691111\n",
      "    val_log_likelihood: -12198.592192346465\n",
      "    val_log_marginal: -12206.549846498163\n",
      "Train Epoch: 440 [256/118836 (0%)] Loss: 12264.097656\n",
      "Train Epoch: 440 [33024/118836 (28%)] Loss: 12294.746094\n",
      "Train Epoch: 440 [65792/118836 (55%)] Loss: 12258.885742\n",
      "Train Epoch: 440 [98560/118836 (83%)] Loss: 12413.484375\n",
      "    epoch          : 440\n",
      "    loss           : 12292.338887219552\n",
      "    val_loss       : 12290.350735035328\n",
      "    val_log_likelihood: -12202.424336195978\n",
      "    val_log_marginal: -12210.430994915916\n",
      "Train Epoch: 441 [256/118836 (0%)] Loss: 12257.333008\n",
      "Train Epoch: 441 [33024/118836 (28%)] Loss: 12252.959961\n",
      "Train Epoch: 441 [65792/118836 (55%)] Loss: 12294.837891\n",
      "Train Epoch: 441 [98560/118836 (83%)] Loss: 12330.751953\n",
      "    epoch          : 441\n",
      "    loss           : 12291.409795834625\n",
      "    val_loss       : 12292.452367477457\n",
      "    val_log_likelihood: -12202.591476846826\n",
      "    val_log_marginal: -12210.536603946237\n",
      "Train Epoch: 442 [256/118836 (0%)] Loss: 12386.709961\n",
      "Train Epoch: 442 [33024/118836 (28%)] Loss: 12290.670898\n",
      "Train Epoch: 442 [65792/118836 (55%)] Loss: 12389.674805\n",
      "Train Epoch: 442 [98560/118836 (83%)] Loss: 12349.144531\n",
      "    epoch          : 442\n",
      "    loss           : 12293.54060626034\n",
      "    val_loss       : 12290.130796852887\n",
      "    val_log_likelihood: -12199.434157878413\n",
      "    val_log_marginal: -12207.228771480799\n",
      "Train Epoch: 443 [256/118836 (0%)] Loss: 12430.163086\n",
      "Train Epoch: 443 [33024/118836 (28%)] Loss: 12340.258789\n",
      "Train Epoch: 443 [65792/118836 (55%)] Loss: 12336.708984\n",
      "Train Epoch: 443 [98560/118836 (83%)] Loss: 12327.175781\n",
      "    epoch          : 443\n",
      "    loss           : 12290.688915813687\n",
      "    val_loss       : 12291.011088798992\n",
      "    val_log_likelihood: -12198.361908246743\n",
      "    val_log_marginal: -12206.23044661205\n",
      "Train Epoch: 444 [256/118836 (0%)] Loss: 12293.330078\n",
      "Train Epoch: 444 [33024/118836 (28%)] Loss: 12306.804688\n",
      "Train Epoch: 444 [65792/118836 (55%)] Loss: 12304.601562\n",
      "Train Epoch: 444 [98560/118836 (83%)] Loss: 12353.835938\n",
      "    epoch          : 444\n",
      "    loss           : 12286.183686640561\n",
      "    val_loss       : 12293.798883988366\n",
      "    val_log_likelihood: -12199.339005796372\n",
      "    val_log_marginal: -12207.14423065429\n",
      "Train Epoch: 445 [256/118836 (0%)] Loss: 12258.250000\n",
      "Train Epoch: 445 [33024/118836 (28%)] Loss: 12357.339844\n",
      "Train Epoch: 445 [65792/118836 (55%)] Loss: 12401.441406\n",
      "Train Epoch: 445 [98560/118836 (83%)] Loss: 12332.209961\n",
      "    epoch          : 445\n",
      "    loss           : 12289.013278019023\n",
      "    val_loss       : 12288.596152760612\n",
      "    val_log_likelihood: -12201.13499728598\n",
      "    val_log_marginal: -12209.213268599839\n",
      "Train Epoch: 446 [256/118836 (0%)] Loss: 12324.312500\n",
      "Train Epoch: 446 [33024/118836 (28%)] Loss: 12300.910156\n",
      "Train Epoch: 446 [65792/118836 (55%)] Loss: 12386.470703\n",
      "Train Epoch: 446 [98560/118836 (83%)] Loss: 12245.929688\n",
      "    epoch          : 446\n",
      "    loss           : 12288.849947173543\n",
      "    val_loss       : 12292.78038385802\n",
      "    val_log_likelihood: -12203.235454630636\n",
      "    val_log_marginal: -12211.284867207443\n",
      "Train Epoch: 447 [256/118836 (0%)] Loss: 12260.515625\n",
      "Train Epoch: 447 [33024/118836 (28%)] Loss: 12280.765625\n",
      "Train Epoch: 447 [65792/118836 (55%)] Loss: 12331.056641\n",
      "Train Epoch: 447 [98560/118836 (83%)] Loss: 12391.743164\n",
      "    epoch          : 447\n",
      "    loss           : 12292.979096877585\n",
      "    val_loss       : 12289.263196531663\n",
      "    val_log_likelihood: -12202.279684592122\n",
      "    val_log_marginal: -12210.158402458637\n",
      "Train Epoch: 448 [256/118836 (0%)] Loss: 12368.044922\n",
      "Train Epoch: 448 [33024/118836 (28%)] Loss: 12256.058594\n",
      "Train Epoch: 448 [65792/118836 (55%)] Loss: 12315.058594\n",
      "Train Epoch: 448 [98560/118836 (83%)] Loss: 12267.741211\n",
      "    epoch          : 448\n",
      "    loss           : 12291.578681858715\n",
      "    val_loss       : 12293.243076310366\n",
      "    val_log_likelihood: -12202.811097917958\n",
      "    val_log_marginal: -12210.9240048503\n",
      "Train Epoch: 449 [256/118836 (0%)] Loss: 12301.054688\n",
      "Train Epoch: 449 [33024/118836 (28%)] Loss: 12347.171875\n",
      "Train Epoch: 449 [65792/118836 (55%)] Loss: 12256.568359\n",
      "Train Epoch: 449 [98560/118836 (83%)] Loss: 12320.854492\n",
      "    epoch          : 449\n",
      "    loss           : 12295.385257218\n",
      "    val_loss       : 12290.296776788242\n",
      "    val_log_likelihood: -12203.567408014113\n",
      "    val_log_marginal: -12211.832626334564\n",
      "Train Epoch: 450 [256/118836 (0%)] Loss: 12217.964844\n",
      "Train Epoch: 450 [33024/118836 (28%)] Loss: 12333.507812\n",
      "Train Epoch: 450 [65792/118836 (55%)] Loss: 12312.370117\n",
      "Train Epoch: 450 [98560/118836 (83%)] Loss: 12259.795898\n",
      "    epoch          : 450\n",
      "    loss           : 12293.108505382805\n",
      "    val_loss       : 12289.782676844772\n",
      "    val_log_likelihood: -12202.064145212986\n",
      "    val_log_marginal: -12210.12485163994\n",
      "Train Epoch: 451 [256/118836 (0%)] Loss: 12325.365234\n",
      "Train Epoch: 451 [33024/118836 (28%)] Loss: 12370.246094\n",
      "Train Epoch: 451 [65792/118836 (55%)] Loss: 12367.663086\n",
      "Train Epoch: 451 [98560/118836 (83%)] Loss: 12299.438477\n",
      "    epoch          : 451\n",
      "    loss           : 12291.776694646918\n",
      "    val_loss       : 12286.666911133392\n",
      "    val_log_likelihood: -12199.381071488575\n",
      "    val_log_marginal: -12207.229838158702\n",
      "Train Epoch: 452 [256/118836 (0%)] Loss: 12423.224609\n",
      "Train Epoch: 452 [33024/118836 (28%)] Loss: 12248.254883\n",
      "Train Epoch: 452 [65792/118836 (55%)] Loss: 12362.367188\n",
      "Train Epoch: 452 [98560/118836 (83%)] Loss: 12272.287109\n",
      "    epoch          : 452\n",
      "    loss           : 12292.867643875363\n",
      "    val_loss       : 12292.065801754572\n",
      "    val_log_likelihood: -12199.040525647488\n",
      "    val_log_marginal: -12206.88916930448\n",
      "Train Epoch: 453 [256/118836 (0%)] Loss: 12320.384766\n",
      "Train Epoch: 453 [33024/118836 (28%)] Loss: 12243.873047\n",
      "Train Epoch: 453 [65792/118836 (55%)] Loss: 12320.847656\n",
      "Train Epoch: 453 [98560/118836 (83%)] Loss: 12279.703125\n",
      "    epoch          : 453\n",
      "    loss           : 12293.15036639268\n",
      "    val_loss       : 12290.095201325183\n",
      "    val_log_likelihood: -12199.823601148935\n",
      "    val_log_marginal: -12207.754887610397\n",
      "Train Epoch: 454 [256/118836 (0%)] Loss: 12331.210938\n",
      "Train Epoch: 454 [33024/118836 (28%)] Loss: 12260.891602\n",
      "Train Epoch: 454 [65792/118836 (55%)] Loss: 12333.397461\n",
      "Train Epoch: 454 [98560/118836 (83%)] Loss: 12266.470703\n",
      "    epoch          : 454\n",
      "    loss           : 12291.293450650071\n",
      "    val_loss       : 12292.408702264947\n",
      "    val_log_likelihood: -12199.517558739144\n",
      "    val_log_marginal: -12207.409173323866\n",
      "Train Epoch: 455 [256/118836 (0%)] Loss: 12308.746094\n",
      "Train Epoch: 455 [33024/118836 (28%)] Loss: 12283.766602\n",
      "Train Epoch: 455 [65792/118836 (55%)] Loss: 12395.130859\n",
      "Train Epoch: 455 [98560/118836 (83%)] Loss: 12277.754883\n",
      "    epoch          : 455\n",
      "    loss           : 12290.274677387044\n",
      "    val_loss       : 12292.532205106296\n",
      "    val_log_likelihood: -12202.75993799757\n",
      "    val_log_marginal: -12210.940395863323\n",
      "Train Epoch: 456 [256/118836 (0%)] Loss: 12245.439453\n",
      "Train Epoch: 456 [33024/118836 (28%)] Loss: 12319.937500\n",
      "Train Epoch: 456 [65792/118836 (55%)] Loss: 12277.519531\n",
      "Train Epoch: 456 [98560/118836 (83%)] Loss: 12256.007812\n",
      "    epoch          : 456\n",
      "    loss           : 12293.53595623966\n",
      "    val_loss       : 12290.530877556666\n",
      "    val_log_likelihood: -12203.015706905242\n",
      "    val_log_marginal: -12210.812958527333\n",
      "Train Epoch: 457 [256/118836 (0%)] Loss: 12432.882812\n",
      "Train Epoch: 457 [33024/118836 (28%)] Loss: 12271.517578\n",
      "Train Epoch: 457 [65792/118836 (55%)] Loss: 12318.622070\n",
      "Train Epoch: 457 [98560/118836 (83%)] Loss: 12313.436523\n",
      "    epoch          : 457\n",
      "    loss           : 12292.38846428479\n",
      "    val_loss       : 12289.637329185736\n",
      "    val_log_likelihood: -12198.294415742608\n",
      "    val_log_marginal: -12206.138444263604\n",
      "Train Epoch: 458 [256/118836 (0%)] Loss: 12305.425781\n",
      "Train Epoch: 458 [33024/118836 (28%)] Loss: 12380.803711\n",
      "Train Epoch: 458 [65792/118836 (55%)] Loss: 12297.296875\n",
      "Train Epoch: 458 [98560/118836 (83%)] Loss: 12267.442383\n",
      "    epoch          : 458\n",
      "    loss           : 12290.302454572477\n",
      "    val_loss       : 12295.91300098521\n",
      "    val_log_likelihood: -12208.872623294044\n",
      "    val_log_marginal: -12217.0494578374\n",
      "Train Epoch: 459 [256/118836 (0%)] Loss: 12226.257812\n",
      "Train Epoch: 459 [33024/118836 (28%)] Loss: 12356.405273\n",
      "Train Epoch: 459 [65792/118836 (55%)] Loss: 12255.937500\n",
      "Train Epoch: 459 [98560/118836 (83%)] Loss: 12340.499023\n",
      "    epoch          : 459\n",
      "    loss           : 12295.2163592393\n",
      "    val_loss       : 12290.0088509972\n",
      "    val_log_likelihood: -12202.646403115954\n",
      "    val_log_marginal: -12210.803467874359\n",
      "Train Epoch: 460 [256/118836 (0%)] Loss: 12267.478516\n",
      "Train Epoch: 460 [33024/118836 (28%)] Loss: 12242.900391\n",
      "Train Epoch: 460 [65792/118836 (55%)] Loss: 12327.722656\n",
      "Train Epoch: 460 [98560/118836 (83%)] Loss: 12291.605469\n",
      "    epoch          : 460\n",
      "    loss           : 12290.804840648263\n",
      "    val_loss       : 12294.432341331376\n",
      "    val_log_likelihood: -12202.337271893093\n",
      "    val_log_marginal: -12210.302614000668\n",
      "Train Epoch: 461 [256/118836 (0%)] Loss: 12252.412109\n",
      "Train Epoch: 461 [33024/118836 (28%)] Loss: 12227.894531\n",
      "Train Epoch: 461 [65792/118836 (55%)] Loss: 12236.412109\n",
      "Train Epoch: 461 [98560/118836 (83%)] Loss: 12260.712891\n",
      "    epoch          : 461\n",
      "    loss           : 12288.173857526881\n",
      "    val_loss       : 12290.07330186773\n",
      "    val_log_likelihood: -12199.942707687138\n",
      "    val_log_marginal: -12207.93649035145\n",
      "Train Epoch: 462 [256/118836 (0%)] Loss: 12337.816406\n",
      "Train Epoch: 462 [33024/118836 (28%)] Loss: 12256.969727\n",
      "Train Epoch: 462 [65792/118836 (55%)] Loss: 12296.511719\n",
      "Train Epoch: 462 [98560/118836 (83%)] Loss: 12229.916992\n",
      "    epoch          : 462\n",
      "    loss           : 12289.777387206626\n",
      "    val_loss       : 12293.427912895902\n",
      "    val_log_likelihood: -12201.935423451716\n",
      "    val_log_marginal: -12209.926160858353\n",
      "Train Epoch: 463 [256/118836 (0%)] Loss: 12278.773438\n",
      "Train Epoch: 463 [33024/118836 (28%)] Loss: 12399.292969\n",
      "Train Epoch: 463 [65792/118836 (55%)] Loss: 12205.533203\n",
      "Train Epoch: 463 [98560/118836 (83%)] Loss: 12351.551758\n",
      "    epoch          : 463\n",
      "    loss           : 12292.554289605305\n",
      "    val_loss       : 12293.566948968497\n",
      "    val_log_likelihood: -12200.1834388247\n",
      "    val_log_marginal: -12208.315628000588\n",
      "Train Epoch: 464 [256/118836 (0%)] Loss: 12286.255859\n",
      "Train Epoch: 464 [33024/118836 (28%)] Loss: 12197.431641\n",
      "Train Epoch: 464 [65792/118836 (55%)] Loss: 12202.523438\n",
      "Train Epoch: 464 [98560/118836 (83%)] Loss: 12267.166992\n",
      "    epoch          : 464\n",
      "    loss           : 12290.347407626397\n",
      "    val_loss       : 12287.40091759757\n",
      "    val_log_likelihood: -12201.43808577595\n",
      "    val_log_marginal: -12209.402955199084\n",
      "Train Epoch: 465 [256/118836 (0%)] Loss: 12306.763672\n",
      "Train Epoch: 465 [33024/118836 (28%)] Loss: 12300.313477\n",
      "Train Epoch: 465 [65792/118836 (55%)] Loss: 12384.216797\n",
      "Train Epoch: 465 [98560/118836 (83%)] Loss: 12260.650391\n",
      "    epoch          : 465\n",
      "    loss           : 12294.333722665942\n",
      "    val_loss       : 12291.729761412156\n",
      "    val_log_likelihood: -12199.540244067928\n",
      "    val_log_marginal: -12207.51136201248\n",
      "Train Epoch: 466 [256/118836 (0%)] Loss: 12285.106445\n",
      "Train Epoch: 466 [33024/118836 (28%)] Loss: 12260.402344\n",
      "Train Epoch: 466 [65792/118836 (55%)] Loss: 12325.433594\n",
      "Train Epoch: 466 [98560/118836 (83%)] Loss: 12289.858398\n",
      "    epoch          : 466\n",
      "    loss           : 12290.971446087935\n",
      "    val_loss       : 12293.61864324638\n",
      "    val_log_likelihood: -12200.482949170286\n",
      "    val_log_marginal: -12208.442066858102\n",
      "Train Epoch: 467 [256/118836 (0%)] Loss: 12371.623047\n",
      "Train Epoch: 467 [33024/118836 (28%)] Loss: 12278.302734\n",
      "Train Epoch: 467 [65792/118836 (55%)] Loss: 12274.498047\n",
      "Train Epoch: 467 [98560/118836 (83%)] Loss: 12328.366211\n",
      "    epoch          : 467\n",
      "    loss           : 12296.311383051592\n",
      "    val_loss       : 12292.782643617833\n",
      "    val_log_likelihood: -12203.27626880428\n",
      "    val_log_marginal: -12211.268724747679\n",
      "Train Epoch: 468 [256/118836 (0%)] Loss: 12327.560547\n",
      "Train Epoch: 468 [33024/118836 (28%)] Loss: 12361.118164\n",
      "Train Epoch: 468 [65792/118836 (55%)] Loss: 12271.485352\n",
      "Train Epoch: 468 [98560/118836 (83%)] Loss: 12331.552734\n",
      "    epoch          : 468\n",
      "    loss           : 12294.236235395989\n",
      "    val_loss       : 12289.618263618207\n",
      "    val_log_likelihood: -12197.208997622001\n",
      "    val_log_marginal: -12205.088175350193\n",
      "Train Epoch: 469 [256/118836 (0%)] Loss: 12314.857422\n",
      "Train Epoch: 469 [33024/118836 (28%)] Loss: 12322.818359\n",
      "Train Epoch: 469 [65792/118836 (55%)] Loss: 12429.092773\n",
      "Train Epoch: 469 [98560/118836 (83%)] Loss: 12284.041992\n",
      "    epoch          : 469\n",
      "    loss           : 12290.406432550144\n",
      "    val_loss       : 12293.500715377966\n",
      "    val_log_likelihood: -12202.867805262613\n",
      "    val_log_marginal: -12210.702891950235\n",
      "Train Epoch: 470 [256/118836 (0%)] Loss: 12253.837891\n",
      "Train Epoch: 470 [33024/118836 (28%)] Loss: 12264.417969\n",
      "Train Epoch: 470 [65792/118836 (55%)] Loss: 12236.189453\n",
      "Train Epoch: 470 [98560/118836 (83%)] Loss: 12264.868164\n",
      "    epoch          : 470\n",
      "    loss           : 12294.043343866317\n",
      "    val_loss       : 12292.678892856151\n",
      "    val_log_likelihood: -12203.154260041872\n",
      "    val_log_marginal: -12211.133071366721\n",
      "Train Epoch: 471 [256/118836 (0%)] Loss: 12240.948242\n",
      "Train Epoch: 471 [33024/118836 (28%)] Loss: 12300.800781\n",
      "Train Epoch: 471 [65792/118836 (55%)] Loss: 12362.083984\n",
      "Train Epoch: 471 [98560/118836 (83%)] Loss: 12278.003906\n",
      "    epoch          : 471\n",
      "    loss           : 12290.181683112334\n",
      "    val_loss       : 12292.702761174822\n",
      "    val_log_likelihood: -12207.320530429331\n",
      "    val_log_marginal: -12215.298217557993\n",
      "Train Epoch: 472 [256/118836 (0%)] Loss: 12326.251953\n",
      "Train Epoch: 472 [33024/118836 (28%)] Loss: 12254.488281\n",
      "Train Epoch: 472 [65792/118836 (55%)] Loss: 12359.238281\n",
      "Train Epoch: 472 [98560/118836 (83%)] Loss: 12324.518555\n",
      "    epoch          : 472\n",
      "    loss           : 12289.940431464538\n",
      "    val_loss       : 12298.06676010018\n",
      "    val_log_likelihood: -12199.46750155087\n",
      "    val_log_marginal: -12207.536654924113\n",
      "Train Epoch: 473 [256/118836 (0%)] Loss: 12351.062500\n",
      "Train Epoch: 473 [33024/118836 (28%)] Loss: 12277.189453\n",
      "Train Epoch: 473 [65792/118836 (55%)] Loss: 12391.091797\n",
      "Train Epoch: 473 [98560/118836 (83%)] Loss: 12333.837891\n",
      "    epoch          : 473\n",
      "    loss           : 12289.352094964846\n",
      "    val_loss       : 12290.826587834601\n",
      "    val_log_likelihood: -12200.545454178298\n",
      "    val_log_marginal: -12208.35116699319\n",
      "Train Epoch: 474 [256/118836 (0%)] Loss: 12314.595703\n",
      "Train Epoch: 474 [33024/118836 (28%)] Loss: 12386.989258\n",
      "Train Epoch: 474 [65792/118836 (55%)] Loss: 12245.258789\n",
      "Train Epoch: 474 [98560/118836 (83%)] Loss: 12317.564453\n",
      "    epoch          : 474\n",
      "    loss           : 12290.581652094965\n",
      "    val_loss       : 12293.427256422203\n",
      "    val_log_likelihood: -12199.476453939207\n",
      "    val_log_marginal: -12207.320450666986\n",
      "Train Epoch: 475 [256/118836 (0%)] Loss: 12273.313477\n",
      "Train Epoch: 475 [33024/118836 (28%)] Loss: 12341.675781\n",
      "Train Epoch: 475 [65792/118836 (55%)] Loss: 12276.904297\n",
      "Train Epoch: 475 [98560/118836 (83%)] Loss: 12254.490234\n",
      "    epoch          : 475\n",
      "    loss           : 12292.229145019126\n",
      "    val_loss       : 12291.911047748628\n",
      "    val_log_likelihood: -12199.762124075942\n",
      "    val_log_marginal: -12207.89203275309\n",
      "Train Epoch: 476 [256/118836 (0%)] Loss: 12364.671875\n",
      "Train Epoch: 476 [33024/118836 (28%)] Loss: 12324.369141\n",
      "Train Epoch: 476 [65792/118836 (55%)] Loss: 12275.212891\n",
      "Train Epoch: 476 [98560/118836 (83%)] Loss: 12298.636719\n",
      "    epoch          : 476\n",
      "    loss           : 12293.02972804875\n",
      "    val_loss       : 12290.744802546096\n",
      "    val_log_likelihood: -12202.233976620659\n",
      "    val_log_marginal: -12210.130703452063\n",
      "Train Epoch: 477 [256/118836 (0%)] Loss: 12323.144531\n",
      "Train Epoch: 477 [33024/118836 (28%)] Loss: 12338.340820\n",
      "Train Epoch: 477 [65792/118836 (55%)] Loss: 12445.209961\n",
      "Train Epoch: 477 [98560/118836 (83%)] Loss: 12278.874023\n",
      "    epoch          : 477\n",
      "    loss           : 12291.291678944377\n",
      "    val_loss       : 12290.408846612545\n",
      "    val_log_likelihood: -12198.153395432693\n",
      "    val_log_marginal: -12206.026197073616\n",
      "Train Epoch: 478 [256/118836 (0%)] Loss: 12403.548828\n",
      "Train Epoch: 478 [33024/118836 (28%)] Loss: 12230.315430\n",
      "Train Epoch: 478 [65792/118836 (55%)] Loss: 12327.458008\n",
      "Train Epoch: 478 [98560/118836 (83%)] Loss: 12329.345703\n",
      "    epoch          : 478\n",
      "    loss           : 12291.508833003772\n",
      "    val_loss       : 12294.010727817878\n",
      "    val_log_likelihood: -12199.752252959574\n",
      "    val_log_marginal: -12207.820051260607\n",
      "Train Epoch: 479 [256/118836 (0%)] Loss: 12332.023438\n",
      "Train Epoch: 479 [33024/118836 (28%)] Loss: 12360.728516\n",
      "Train Epoch: 479 [65792/118836 (55%)] Loss: 12276.228516\n",
      "Train Epoch: 479 [98560/118836 (83%)] Loss: 12297.363281\n",
      "    epoch          : 479\n",
      "    loss           : 12288.336713418888\n",
      "    val_loss       : 12288.873895534352\n",
      "    val_log_likelihood: -12201.138120508944\n",
      "    val_log_marginal: -12209.004694112466\n",
      "Train Epoch: 480 [256/118836 (0%)] Loss: 12255.519531\n",
      "Train Epoch: 480 [33024/118836 (28%)] Loss: 12315.105469\n",
      "Train Epoch: 480 [65792/118836 (55%)] Loss: 12301.344727\n",
      "Train Epoch: 480 [98560/118836 (83%)] Loss: 12264.661133\n",
      "    epoch          : 480\n",
      "    loss           : 12292.109696805212\n",
      "    val_loss       : 12286.495050082454\n",
      "    val_log_likelihood: -12200.079684430573\n",
      "    val_log_marginal: -12207.97216466626\n",
      "Train Epoch: 481 [256/118836 (0%)] Loss: 12259.640625\n",
      "Train Epoch: 481 [33024/118836 (28%)] Loss: 12323.450195\n",
      "Train Epoch: 481 [65792/118836 (55%)] Loss: 12328.189453\n",
      "Train Epoch: 481 [98560/118836 (83%)] Loss: 12359.177734\n",
      "    epoch          : 481\n",
      "    loss           : 12292.228780080386\n",
      "    val_loss       : 12295.357561981105\n",
      "    val_log_likelihood: -12201.85195441739\n",
      "    val_log_marginal: -12210.154692710455\n",
      "Train Epoch: 482 [256/118836 (0%)] Loss: 12306.273438\n",
      "Train Epoch: 482 [33024/118836 (28%)] Loss: 12334.515625\n",
      "Train Epoch: 482 [65792/118836 (55%)] Loss: 12329.946289\n",
      "Train Epoch: 482 [98560/118836 (83%)] Loss: 12343.759766\n",
      "    epoch          : 482\n",
      "    loss           : 12290.561777069117\n",
      "    val_loss       : 12292.308036978848\n",
      "    val_log_likelihood: -12199.095534629601\n",
      "    val_log_marginal: -12206.946283667205\n",
      "Train Epoch: 483 [256/118836 (0%)] Loss: 12334.253906\n",
      "Train Epoch: 483 [33024/118836 (28%)] Loss: 12290.510742\n",
      "Train Epoch: 483 [65792/118836 (55%)] Loss: 12248.296875\n",
      "Train Epoch: 483 [98560/118836 (83%)] Loss: 12382.873047\n",
      "    epoch          : 483\n",
      "    loss           : 12292.1029432576\n",
      "    val_loss       : 12288.628462090006\n",
      "    val_log_likelihood: -12200.77824212288\n",
      "    val_log_marginal: -12208.715486655325\n",
      "Train Epoch: 484 [256/118836 (0%)] Loss: 12318.432617\n",
      "Train Epoch: 484 [33024/118836 (28%)] Loss: 12310.160156\n",
      "Train Epoch: 484 [65792/118836 (55%)] Loss: 12239.550781\n",
      "Train Epoch: 484 [98560/118836 (83%)] Loss: 12231.791016\n",
      "    epoch          : 484\n",
      "    loss           : 12287.43426724695\n",
      "    val_loss       : 12287.681962184224\n",
      "    val_log_likelihood: -12200.98771970637\n",
      "    val_log_marginal: -12208.84080333048\n",
      "Train Epoch: 485 [256/118836 (0%)] Loss: 12304.680664\n",
      "Train Epoch: 485 [33024/118836 (28%)] Loss: 12225.802734\n",
      "Train Epoch: 485 [65792/118836 (55%)] Loss: 12340.476562\n",
      "Train Epoch: 485 [98560/118836 (83%)] Loss: 12297.348633\n",
      "    epoch          : 485\n",
      "    loss           : 12286.8929349863\n",
      "    val_loss       : 12288.080969506274\n",
      "    val_log_likelihood: -12201.441338561053\n",
      "    val_log_marginal: -12209.272773874885\n",
      "Train Epoch: 486 [256/118836 (0%)] Loss: 12288.042969\n",
      "Train Epoch: 486 [33024/118836 (28%)] Loss: 12389.495117\n",
      "Train Epoch: 486 [65792/118836 (55%)] Loss: 12235.033203\n",
      "Train Epoch: 486 [98560/118836 (83%)] Loss: 12322.736328\n",
      "    epoch          : 486\n",
      "    loss           : 12292.463293689258\n",
      "    val_loss       : 12298.455194109782\n",
      "    val_log_likelihood: -12203.597081620916\n",
      "    val_log_marginal: -12211.590621717109\n",
      "Train Epoch: 487 [256/118836 (0%)] Loss: 12268.326172\n",
      "Train Epoch: 487 [33024/118836 (28%)] Loss: 12284.462891\n",
      "Train Epoch: 487 [65792/118836 (55%)] Loss: 12318.457031\n",
      "Train Epoch: 487 [98560/118836 (83%)] Loss: 12340.625000\n",
      "    epoch          : 487\n",
      "    loss           : 12293.965299479167\n",
      "    val_loss       : 12295.69034867346\n",
      "    val_log_likelihood: -12202.287417448562\n",
      "    val_log_marginal: -12210.447514783225\n",
      "Train Epoch: 488 [256/118836 (0%)] Loss: 12198.000000\n",
      "Train Epoch: 488 [33024/118836 (28%)] Loss: 12259.495117\n",
      "Train Epoch: 488 [65792/118836 (55%)] Loss: 12317.820312\n",
      "Train Epoch: 488 [98560/118836 (83%)] Loss: 12326.833984\n",
      "    epoch          : 488\n",
      "    loss           : 12291.028781534327\n",
      "    val_loss       : 12289.810011723284\n",
      "    val_log_likelihood: -12198.68063595301\n",
      "    val_log_marginal: -12206.59571707584\n",
      "Train Epoch: 489 [256/118836 (0%)] Loss: 12244.365234\n",
      "Train Epoch: 489 [33024/118836 (28%)] Loss: 12362.849609\n",
      "Train Epoch: 489 [65792/118836 (55%)] Loss: 12313.983398\n",
      "Train Epoch: 489 [98560/118836 (83%)] Loss: 12269.776367\n",
      "    epoch          : 489\n",
      "    loss           : 12286.21894676644\n",
      "    val_loss       : 12288.301102131823\n",
      "    val_log_likelihood: -12198.240609491317\n",
      "    val_log_marginal: -12206.393592118926\n",
      "Train Epoch: 490 [256/118836 (0%)] Loss: 12327.879883\n",
      "Train Epoch: 490 [33024/118836 (28%)] Loss: 12334.953125\n",
      "Train Epoch: 490 [65792/118836 (55%)] Loss: 12240.404297\n",
      "Train Epoch: 490 [98560/118836 (83%)] Loss: 12284.775391\n",
      "    epoch          : 490\n",
      "    loss           : 12291.612648786446\n",
      "    val_loss       : 12291.007122083793\n",
      "    val_log_likelihood: -12200.355863575269\n",
      "    val_log_marginal: -12208.35787845004\n",
      "Train Epoch: 491 [256/118836 (0%)] Loss: 12309.541992\n",
      "Train Epoch: 491 [33024/118836 (28%)] Loss: 12384.255859\n",
      "Train Epoch: 491 [65792/118836 (55%)] Loss: 12331.757812\n",
      "Train Epoch: 491 [98560/118836 (83%)] Loss: 12318.982422\n",
      "    epoch          : 491\n",
      "    loss           : 12291.005796370968\n",
      "    val_loss       : 12291.091323385794\n",
      "    val_log_likelihood: -12198.657625911135\n",
      "    val_log_marginal: -12206.54786828278\n",
      "Train Epoch: 492 [256/118836 (0%)] Loss: 12240.287109\n",
      "Train Epoch: 492 [33024/118836 (28%)] Loss: 12303.231445\n",
      "Train Epoch: 492 [65792/118836 (55%)] Loss: 12335.540039\n",
      "Train Epoch: 492 [98560/118836 (83%)] Loss: 12275.874023\n",
      "    epoch          : 492\n",
      "    loss           : 12288.883017990076\n",
      "    val_loss       : 12290.005157071511\n",
      "    val_log_likelihood: -12198.254154873603\n",
      "    val_log_marginal: -12206.155307573417\n",
      "Train Epoch: 493 [256/118836 (0%)] Loss: 12288.812500\n",
      "Train Epoch: 493 [33024/118836 (28%)] Loss: 12296.856445\n",
      "Train Epoch: 493 [65792/118836 (55%)] Loss: 12299.648438\n",
      "Train Epoch: 493 [98560/118836 (83%)] Loss: 12351.944336\n",
      "    epoch          : 493\n",
      "    loss           : 12289.576442146143\n",
      "    val_loss       : 12289.813134342357\n",
      "    val_log_likelihood: -12200.387419387149\n",
      "    val_log_marginal: -12208.212856680751\n",
      "Train Epoch: 494 [256/118836 (0%)] Loss: 12261.164062\n",
      "Train Epoch: 494 [33024/118836 (28%)] Loss: 12360.986328\n",
      "Train Epoch: 494 [65792/118836 (55%)] Loss: 12293.922852\n",
      "Train Epoch: 494 [98560/118836 (83%)] Loss: 12304.478516\n",
      "    epoch          : 494\n",
      "    loss           : 12287.527495282775\n",
      "    val_loss       : 12299.036934224703\n",
      "    val_log_likelihood: -12201.645167590726\n",
      "    val_log_marginal: -12209.92886016262\n",
      "Train Epoch: 495 [256/118836 (0%)] Loss: 12365.862305\n",
      "Train Epoch: 495 [33024/118836 (28%)] Loss: 12286.144531\n",
      "Train Epoch: 495 [65792/118836 (55%)] Loss: 12283.537109\n",
      "Train Epoch: 495 [98560/118836 (83%)] Loss: 12306.303711\n",
      "    epoch          : 495\n",
      "    loss           : 12291.64570732527\n",
      "    val_loss       : 12292.011984588664\n",
      "    val_log_likelihood: -12207.658177277191\n",
      "    val_log_marginal: -12215.549592767873\n",
      "Train Epoch: 496 [256/118836 (0%)] Loss: 12364.479492\n",
      "Train Epoch: 496 [33024/118836 (28%)] Loss: 12249.900391\n",
      "Train Epoch: 496 [65792/118836 (55%)] Loss: 12368.397461\n",
      "Train Epoch: 496 [98560/118836 (83%)] Loss: 12316.181641\n",
      "    epoch          : 496\n",
      "    loss           : 12287.076747796475\n",
      "    val_loss       : 12288.67268653696\n",
      "    val_log_likelihood: -12201.583331717846\n",
      "    val_log_marginal: -12209.573003379854\n",
      "Train Epoch: 497 [256/118836 (0%)] Loss: 12269.663086\n",
      "Train Epoch: 497 [33024/118836 (28%)] Loss: 12316.477539\n",
      "Train Epoch: 497 [65792/118836 (55%)] Loss: 12262.679688\n",
      "Train Epoch: 497 [98560/118836 (83%)] Loss: 12242.022461\n",
      "    epoch          : 497\n",
      "    loss           : 12287.417979896867\n",
      "    val_loss       : 12285.932222971704\n",
      "    val_log_likelihood: -12198.704033873553\n",
      "    val_log_marginal: -12206.499438432971\n",
      "Train Epoch: 498 [256/118836 (0%)] Loss: 12375.795898\n",
      "Train Epoch: 498 [33024/118836 (28%)] Loss: 12341.276367\n",
      "Train Epoch: 498 [65792/118836 (55%)] Loss: 12312.218750\n",
      "Train Epoch: 498 [98560/118836 (83%)] Loss: 12327.677734\n",
      "    epoch          : 498\n",
      "    loss           : 12289.235554144696\n",
      "    val_loss       : 12286.936493545658\n",
      "    val_log_likelihood: -12200.481267124173\n",
      "    val_log_marginal: -12208.339931368071\n",
      "Train Epoch: 499 [256/118836 (0%)] Loss: 12270.386719\n",
      "Train Epoch: 499 [33024/118836 (28%)] Loss: 12319.317383\n",
      "Train Epoch: 499 [65792/118836 (55%)] Loss: 12297.701172\n",
      "Train Epoch: 499 [98560/118836 (83%)] Loss: 12344.935547\n",
      "    epoch          : 499\n",
      "    loss           : 12290.099658647385\n",
      "    val_loss       : 12288.727622886146\n",
      "    val_log_likelihood: -12200.800013893198\n",
      "    val_log_marginal: -12208.737660865325\n",
      "Train Epoch: 500 [256/118836 (0%)] Loss: 12377.516602\n",
      "Train Epoch: 500 [33024/118836 (28%)] Loss: 12337.258789\n",
      "Train Epoch: 500 [65792/118836 (55%)] Loss: 12394.432617\n",
      "Train Epoch: 500 [98560/118836 (83%)] Loss: 12306.115234\n",
      "    epoch          : 500\n",
      "    loss           : 12293.244238685122\n",
      "    val_loss       : 12290.749073249504\n",
      "    val_log_likelihood: -12199.502842451147\n",
      "    val_log_marginal: -12207.819772933024\n",
      "Saving checkpoint: saved/models/SelfiesAutoencodingOperad/0905_154251/checkpoint-epoch500.pth ...\n",
      "Train Epoch: 501 [256/118836 (0%)] Loss: 12350.436523\n",
      "Train Epoch: 501 [33024/118836 (28%)] Loss: 12274.942383\n",
      "Train Epoch: 501 [65792/118836 (55%)] Loss: 12318.958008\n",
      "Train Epoch: 501 [98560/118836 (83%)] Loss: 12297.621094\n",
      "    epoch          : 501\n",
      "    loss           : 12291.340319672767\n",
      "    val_loss       : 12290.952625845433\n",
      "    val_log_likelihood: -12201.807881481338\n",
      "    val_log_marginal: -12209.986146285884\n",
      "Train Epoch: 502 [256/118836 (0%)] Loss: 12226.025391\n",
      "Train Epoch: 502 [33024/118836 (28%)] Loss: 12261.003906\n",
      "Train Epoch: 502 [65792/118836 (55%)] Loss: 12256.817383\n",
      "Train Epoch: 502 [98560/118836 (83%)] Loss: 12355.401367\n",
      "    epoch          : 502\n",
      "    loss           : 12287.849486436362\n",
      "    val_loss       : 12289.51610136933\n",
      "    val_log_likelihood: -12197.128198343155\n",
      "    val_log_marginal: -12205.208658145424\n",
      "Train Epoch: 503 [256/118836 (0%)] Loss: 12304.927734\n",
      "Train Epoch: 503 [33024/118836 (28%)] Loss: 12305.917969\n",
      "Train Epoch: 503 [65792/118836 (55%)] Loss: 12245.311523\n",
      "Train Epoch: 503 [98560/118836 (83%)] Loss: 12348.886719\n",
      "    epoch          : 503\n",
      "    loss           : 12286.687621000052\n",
      "    val_loss       : 12303.757628382851\n",
      "    val_log_likelihood: -12201.722971270161\n",
      "    val_log_marginal: -12209.752703628183\n",
      "Train Epoch: 504 [256/118836 (0%)] Loss: 12328.980469\n",
      "Train Epoch: 504 [33024/118836 (28%)] Loss: 12366.553711\n",
      "Train Epoch: 504 [65792/118836 (55%)] Loss: 12343.529297\n",
      "Train Epoch: 504 [98560/118836 (83%)] Loss: 12312.063477\n",
      "    epoch          : 504\n",
      "    loss           : 12293.406798458178\n",
      "    val_loss       : 12289.670072189187\n",
      "    val_log_likelihood: -12199.212684165632\n",
      "    val_log_marginal: -12207.194943997392\n",
      "Train Epoch: 505 [256/118836 (0%)] Loss: 12372.931641\n",
      "Train Epoch: 505 [33024/118836 (28%)] Loss: 12366.196289\n",
      "Train Epoch: 505 [65792/118836 (55%)] Loss: 12339.255859\n",
      "Train Epoch: 505 [98560/118836 (83%)] Loss: 12239.822266\n",
      "    epoch          : 505\n",
      "    loss           : 12287.051913383995\n",
      "    val_loss       : 12290.232193247013\n",
      "    val_log_likelihood: -12199.454816577492\n",
      "    val_log_marginal: -12207.465753713992\n",
      "Train Epoch: 506 [256/118836 (0%)] Loss: 12323.222656\n",
      "Train Epoch: 506 [33024/118836 (28%)] Loss: 12303.018555\n",
      "Train Epoch: 506 [65792/118836 (55%)] Loss: 12305.820312\n",
      "Train Epoch: 506 [98560/118836 (83%)] Loss: 12342.087891\n",
      "    epoch          : 506\n",
      "    loss           : 12287.119026409999\n",
      "    val_loss       : 12287.81047687502\n",
      "    val_log_likelihood: -12195.69188992711\n",
      "    val_log_marginal: -12203.680483061631\n",
      "Train Epoch: 507 [256/118836 (0%)] Loss: 12372.782227\n",
      "Train Epoch: 507 [33024/118836 (28%)] Loss: 12224.981445\n",
      "Train Epoch: 507 [65792/118836 (55%)] Loss: 12265.012695\n",
      "Train Epoch: 507 [98560/118836 (83%)] Loss: 12341.456055\n",
      "    epoch          : 507\n",
      "    loss           : 12287.436841850187\n",
      "    val_loss       : 12287.433616040655\n",
      "    val_log_likelihood: -12198.8262122622\n",
      "    val_log_marginal: -12206.676522056941\n",
      "Train Epoch: 508 [256/118836 (0%)] Loss: 12280.856445\n",
      "Train Epoch: 508 [33024/118836 (28%)] Loss: 12273.308594\n",
      "Train Epoch: 508 [65792/118836 (55%)] Loss: 12327.479492\n",
      "Train Epoch: 508 [98560/118836 (83%)] Loss: 12368.172852\n",
      "    epoch          : 508\n",
      "    loss           : 12288.398507289081\n",
      "    val_loss       : 12287.79965065506\n",
      "    val_log_likelihood: -12198.971391807536\n",
      "    val_log_marginal: -12206.92219142509\n",
      "Train Epoch: 509 [256/118836 (0%)] Loss: 12294.880859\n",
      "Train Epoch: 509 [33024/118836 (28%)] Loss: 12334.150391\n",
      "Train Epoch: 509 [65792/118836 (55%)] Loss: 12277.700195\n",
      "Train Epoch: 509 [98560/118836 (83%)] Loss: 12334.715820\n",
      "    epoch          : 509\n",
      "    loss           : 12288.868569873088\n",
      "    val_loss       : 12287.470885920977\n",
      "    val_log_likelihood: -12195.791598654623\n",
      "    val_log_marginal: -12203.693158650574\n",
      "Train Epoch: 510 [256/118836 (0%)] Loss: 12338.803711\n",
      "Train Epoch: 510 [33024/118836 (28%)] Loss: 12271.912109\n",
      "Train Epoch: 510 [65792/118836 (55%)] Loss: 12269.613281\n",
      "Train Epoch: 510 [98560/118836 (83%)] Loss: 12296.665039\n",
      "    epoch          : 510\n",
      "    loss           : 12287.449549440395\n",
      "    val_loss       : 12295.79332653717\n",
      "    val_log_likelihood: -12211.057444007187\n",
      "    val_log_marginal: -12219.32534619603\n",
      "Train Epoch: 511 [256/118836 (0%)] Loss: 12309.548828\n",
      "Train Epoch: 511 [33024/118836 (28%)] Loss: 12202.763672\n",
      "Train Epoch: 511 [65792/118836 (55%)] Loss: 12227.505859\n",
      "Train Epoch: 511 [98560/118836 (83%)] Loss: 12417.916016\n",
      "    epoch          : 511\n",
      "    loss           : 12290.92542018843\n",
      "    val_loss       : 12286.331695748078\n",
      "    val_log_likelihood: -12196.542928039704\n",
      "    val_log_marginal: -12204.398750747288\n",
      "Train Epoch: 512 [256/118836 (0%)] Loss: 12272.667969\n",
      "Train Epoch: 512 [33024/118836 (28%)] Loss: 12302.408203\n",
      "Train Epoch: 512 [65792/118836 (55%)] Loss: 12450.555664\n",
      "Train Epoch: 512 [98560/118836 (83%)] Loss: 12340.254883\n",
      "    epoch          : 512\n",
      "    loss           : 12288.499437648625\n",
      "    val_loss       : 12285.494167539688\n",
      "    val_log_likelihood: -12198.659603268456\n",
      "    val_log_marginal: -12206.649931805303\n",
      "Train Epoch: 513 [256/118836 (0%)] Loss: 12327.917969\n",
      "Train Epoch: 513 [33024/118836 (28%)] Loss: 12277.436523\n",
      "Train Epoch: 513 [65792/118836 (55%)] Loss: 12346.188477\n",
      "Train Epoch: 513 [98560/118836 (83%)] Loss: 12353.023438\n",
      "    epoch          : 513\n",
      "    loss           : 12284.50228155371\n",
      "    val_loss       : 12288.237449174012\n",
      "    val_log_likelihood: -12201.524067055676\n",
      "    val_log_marginal: -12209.58003575757\n",
      "Train Epoch: 514 [256/118836 (0%)] Loss: 12266.295898\n",
      "Train Epoch: 514 [33024/118836 (28%)] Loss: 12324.958984\n",
      "Train Epoch: 514 [65792/118836 (55%)] Loss: 12279.136719\n",
      "Train Epoch: 514 [98560/118836 (83%)] Loss: 12373.651367\n",
      "    epoch          : 514\n",
      "    loss           : 12288.660207137873\n",
      "    val_loss       : 12288.551789052108\n",
      "    val_log_likelihood: -12200.317470210402\n",
      "    val_log_marginal: -12208.4472921656\n",
      "Train Epoch: 515 [256/118836 (0%)] Loss: 12402.292969\n",
      "Train Epoch: 515 [33024/118836 (28%)] Loss: 12381.298828\n",
      "Train Epoch: 515 [65792/118836 (55%)] Loss: 12333.845703\n",
      "Train Epoch: 515 [98560/118836 (83%)] Loss: 12413.143555\n",
      "    epoch          : 515\n",
      "    loss           : 12284.366072328628\n",
      "    val_loss       : 12286.20777561337\n",
      "    val_log_likelihood: -12199.782090861507\n",
      "    val_log_marginal: -12207.572208400934\n",
      "Train Epoch: 516 [256/118836 (0%)] Loss: 12228.250977\n",
      "Train Epoch: 516 [33024/118836 (28%)] Loss: 12388.608398\n",
      "Train Epoch: 516 [65792/118836 (55%)] Loss: 12287.136719\n",
      "Train Epoch: 516 [98560/118836 (83%)] Loss: 12338.166992\n",
      "    epoch          : 516\n",
      "    loss           : 12290.512209373708\n",
      "    val_loss       : 12287.759323689577\n",
      "    val_log_likelihood: -12199.44468633685\n",
      "    val_log_marginal: -12207.428674877625\n",
      "Train Epoch: 517 [256/118836 (0%)] Loss: 12308.889648\n",
      "Train Epoch: 517 [33024/118836 (28%)] Loss: 12328.806641\n",
      "Train Epoch: 517 [65792/118836 (55%)] Loss: 12290.042969\n",
      "Train Epoch: 517 [98560/118836 (83%)] Loss: 12332.927734\n",
      "    epoch          : 517\n",
      "    loss           : 12285.89991389449\n",
      "    val_loss       : 12289.664051117043\n",
      "    val_log_likelihood: -12200.332506365023\n",
      "    val_log_marginal: -12208.14947004331\n",
      "Train Epoch: 518 [256/118836 (0%)] Loss: 12282.840820\n",
      "Train Epoch: 518 [33024/118836 (28%)] Loss: 12276.776367\n",
      "Train Epoch: 518 [65792/118836 (55%)] Loss: 12317.773438\n",
      "Train Epoch: 518 [98560/118836 (83%)] Loss: 12380.419922\n",
      "    epoch          : 518\n",
      "    loss           : 12291.838732132703\n",
      "    val_loss       : 12283.37052138962\n",
      "    val_log_likelihood: -12204.985032018973\n",
      "    val_log_marginal: -12212.893098339946\n",
      "Train Epoch: 519 [256/118836 (0%)] Loss: 12275.290039\n",
      "Train Epoch: 519 [33024/118836 (28%)] Loss: 12335.828125\n",
      "Train Epoch: 519 [65792/118836 (55%)] Loss: 12304.015625\n",
      "Train Epoch: 519 [98560/118836 (83%)] Loss: 12287.399414\n",
      "    epoch          : 519\n",
      "    loss           : 12293.00068965183\n",
      "    val_loss       : 12286.665683289993\n",
      "    val_log_likelihood: -12199.94331640302\n",
      "    val_log_marginal: -12207.916453163121\n",
      "Train Epoch: 520 [256/118836 (0%)] Loss: 12356.323242\n",
      "Train Epoch: 520 [33024/118836 (28%)] Loss: 12391.449219\n",
      "Train Epoch: 520 [65792/118836 (55%)] Loss: 12310.968750\n",
      "Train Epoch: 520 [98560/118836 (83%)] Loss: 12376.976562\n",
      "    epoch          : 520\n",
      "    loss           : 12290.58497030733\n",
      "    val_loss       : 12289.91190359748\n",
      "    val_log_likelihood: -12203.98937105821\n",
      "    val_log_marginal: -12211.797927728796\n",
      "Train Epoch: 521 [256/118836 (0%)] Loss: 12369.143555\n",
      "Train Epoch: 521 [33024/118836 (28%)] Loss: 12350.412109\n",
      "Train Epoch: 521 [65792/118836 (55%)] Loss: 12421.947266\n",
      "Train Epoch: 521 [98560/118836 (83%)] Loss: 12335.206055\n",
      "    epoch          : 521\n",
      "    loss           : 12291.669327213865\n",
      "    val_loss       : 12285.386882384657\n",
      "    val_log_likelihood: -12197.768030138544\n",
      "    val_log_marginal: -12205.53462051663\n",
      "Train Epoch: 522 [256/118836 (0%)] Loss: 12162.488281\n",
      "Train Epoch: 522 [33024/118836 (28%)] Loss: 12357.250977\n",
      "Train Epoch: 522 [65792/118836 (55%)] Loss: 12276.202148\n",
      "Train Epoch: 522 [98560/118836 (83%)] Loss: 12306.221680\n",
      "    epoch          : 522\n",
      "    loss           : 12292.600361707764\n",
      "    val_loss       : 12288.304097332717\n",
      "    val_log_likelihood: -12197.970009596\n",
      "    val_log_marginal: -12206.41382157233\n",
      "Train Epoch: 523 [256/118836 (0%)] Loss: 12282.171875\n",
      "Train Epoch: 523 [33024/118836 (28%)] Loss: 12244.511719\n",
      "Train Epoch: 523 [65792/118836 (55%)] Loss: 12256.267578\n",
      "Train Epoch: 523 [98560/118836 (83%)] Loss: 12279.741211\n",
      "    epoch          : 523\n",
      "    loss           : 12291.26716342923\n",
      "    val_loss       : 12289.613998311022\n",
      "    val_log_likelihood: -12198.862415509977\n",
      "    val_log_marginal: -12207.064055469707\n",
      "Train Epoch: 524 [256/118836 (0%)] Loss: 12312.311523\n",
      "Train Epoch: 524 [33024/118836 (28%)] Loss: 12278.331055\n",
      "Train Epoch: 524 [65792/118836 (55%)] Loss: 12363.214844\n",
      "Train Epoch: 524 [98560/118836 (83%)] Loss: 12397.153320\n",
      "    epoch          : 524\n",
      "    loss           : 12285.680885707456\n",
      "    val_loss       : 12287.717678592498\n",
      "    val_log_likelihood: -12199.052664909015\n",
      "    val_log_marginal: -12206.946951839715\n",
      "Train Epoch: 525 [256/118836 (0%)] Loss: 12373.484375\n",
      "Train Epoch: 525 [33024/118836 (28%)] Loss: 12264.593750\n",
      "Train Epoch: 525 [65792/118836 (55%)] Loss: 12227.524414\n",
      "Train Epoch: 525 [98560/118836 (83%)] Loss: 12285.281250\n",
      "    epoch          : 525\n",
      "    loss           : 12283.0669518003\n",
      "    val_loss       : 12292.099231870707\n",
      "    val_log_likelihood: -12195.920923800662\n",
      "    val_log_marginal: -12203.73999474873\n",
      "Train Epoch: 526 [256/118836 (0%)] Loss: 12344.692383\n",
      "Train Epoch: 526 [33024/118836 (28%)] Loss: 12355.257812\n",
      "Train Epoch: 526 [65792/118836 (55%)] Loss: 12229.127930\n",
      "Train Epoch: 526 [98560/118836 (83%)] Loss: 12274.158203\n",
      "    epoch          : 526\n",
      "    loss           : 12291.714379781844\n",
      "    val_loss       : 12286.174518491902\n",
      "    val_log_likelihood: -12197.382290374275\n",
      "    val_log_marginal: -12205.346883767983\n",
      "Train Epoch: 527 [256/118836 (0%)] Loss: 12319.893555\n",
      "Train Epoch: 527 [33024/118836 (28%)] Loss: 12229.595703\n",
      "Train Epoch: 527 [65792/118836 (55%)] Loss: 12298.938477\n",
      "Train Epoch: 527 [98560/118836 (83%)] Loss: 12359.178711\n",
      "    epoch          : 527\n",
      "    loss           : 12287.496260306814\n",
      "    val_loss       : 12282.444877406266\n",
      "    val_log_likelihood: -12199.351892382652\n",
      "    val_log_marginal: -12207.29688557951\n",
      "Train Epoch: 528 [256/118836 (0%)] Loss: 12215.529297\n",
      "Train Epoch: 528 [33024/118836 (28%)] Loss: 12251.717773\n",
      "Train Epoch: 528 [65792/118836 (55%)] Loss: 12320.297852\n",
      "Train Epoch: 528 [98560/118836 (83%)] Loss: 12402.341797\n",
      "    epoch          : 528\n",
      "    loss           : 12287.54955961797\n",
      "    val_loss       : 12289.773185070075\n",
      "    val_log_likelihood: -12199.044901681398\n",
      "    val_log_marginal: -12206.789774838833\n",
      "Train Epoch: 529 [256/118836 (0%)] Loss: 12430.531250\n",
      "Train Epoch: 529 [33024/118836 (28%)] Loss: 12288.558594\n",
      "Train Epoch: 529 [65792/118836 (55%)] Loss: 12303.402344\n",
      "Train Epoch: 529 [98560/118836 (83%)] Loss: 12323.692383\n",
      "    epoch          : 529\n",
      "    loss           : 12282.027974921164\n",
      "    val_loss       : 12289.456993453758\n",
      "    val_log_likelihood: -12195.861353811259\n",
      "    val_log_marginal: -12203.924732043077\n",
      "Train Epoch: 530 [256/118836 (0%)] Loss: 12324.084961\n",
      "Train Epoch: 530 [33024/118836 (28%)] Loss: 12297.792969\n",
      "Train Epoch: 530 [65792/118836 (55%)] Loss: 12309.626953\n",
      "Train Epoch: 530 [98560/118836 (83%)] Loss: 12327.081055\n",
      "    epoch          : 530\n",
      "    loss           : 12289.973466578786\n",
      "    val_loss       : 12287.117972148748\n",
      "    val_log_likelihood: -12196.090076703369\n",
      "    val_log_marginal: -12204.057174696738\n",
      "Train Epoch: 531 [256/118836 (0%)] Loss: 12346.230469\n",
      "Train Epoch: 531 [33024/118836 (28%)] Loss: 12336.498047\n",
      "Train Epoch: 531 [65792/118836 (55%)] Loss: 12250.744141\n",
      "Train Epoch: 531 [98560/118836 (83%)] Loss: 12356.958984\n",
      "    epoch          : 531\n",
      "    loss           : 12287.413006132392\n",
      "    val_loss       : 12285.704811056243\n",
      "    val_log_likelihood: -12196.73673619727\n",
      "    val_log_marginal: -12204.530701323265\n",
      "Train Epoch: 532 [256/118836 (0%)] Loss: 12344.945312\n",
      "Train Epoch: 532 [33024/118836 (28%)] Loss: 12259.689453\n",
      "Train Epoch: 532 [65792/118836 (55%)] Loss: 12334.911133\n",
      "Train Epoch: 532 [98560/118836 (83%)] Loss: 12306.517578\n",
      "    epoch          : 532\n",
      "    loss           : 12284.478848900175\n",
      "    val_loss       : 12289.564158273788\n",
      "    val_log_likelihood: -12197.161878521765\n",
      "    val_log_marginal: -12204.920753241973\n",
      "Train Epoch: 533 [256/118836 (0%)] Loss: 12361.080078\n",
      "Train Epoch: 533 [33024/118836 (28%)] Loss: 12446.647461\n",
      "Train Epoch: 533 [65792/118836 (55%)] Loss: 12261.636719\n",
      "Train Epoch: 533 [98560/118836 (83%)] Loss: 12206.628906\n",
      "    epoch          : 533\n",
      "    loss           : 12289.929527728236\n",
      "    val_loss       : 12288.566810669423\n",
      "    val_log_likelihood: -12199.266067805263\n",
      "    val_log_marginal: -12207.096195377773\n",
      "Train Epoch: 534 [256/118836 (0%)] Loss: 12226.058594\n",
      "Train Epoch: 534 [33024/118836 (28%)] Loss: 12315.971680\n",
      "Train Epoch: 534 [65792/118836 (55%)] Loss: 12225.648438\n",
      "Train Epoch: 534 [98560/118836 (83%)] Loss: 12333.688477\n",
      "    epoch          : 534\n",
      "    loss           : 12286.123404867141\n",
      "    val_loss       : 12285.057182275646\n",
      "    val_log_likelihood: -12198.451140696081\n",
      "    val_log_marginal: -12206.181102753522\n",
      "Train Epoch: 535 [256/118836 (0%)] Loss: 12313.984375\n",
      "Train Epoch: 535 [33024/118836 (28%)] Loss: 12300.748047\n",
      "Train Epoch: 535 [65792/118836 (55%)] Loss: 12333.697266\n",
      "Train Epoch: 535 [98560/118836 (83%)] Loss: 12260.568359\n",
      "    epoch          : 535\n",
      "    loss           : 12284.997539288668\n",
      "    val_loss       : 12286.250388032546\n",
      "    val_log_likelihood: -12194.661207448045\n",
      "    val_log_marginal: -12202.481579173305\n",
      "Train Epoch: 536 [256/118836 (0%)] Loss: 12334.806641\n",
      "Train Epoch: 536 [33024/118836 (28%)] Loss: 12314.501953\n",
      "Train Epoch: 536 [65792/118836 (55%)] Loss: 12265.898438\n",
      "Train Epoch: 536 [98560/118836 (83%)] Loss: 12208.717773\n",
      "    epoch          : 536\n",
      "    loss           : 12289.225905804125\n",
      "    val_loss       : 12308.925524986902\n",
      "    val_log_likelihood: -12218.647298580954\n",
      "    val_log_marginal: -12227.180307217623\n",
      "Train Epoch: 537 [256/118836 (0%)] Loss: 12439.677734\n",
      "Train Epoch: 537 [33024/118836 (28%)] Loss: 12322.382812\n",
      "Train Epoch: 537 [65792/118836 (55%)] Loss: 12230.623047\n",
      "Train Epoch: 537 [98560/118836 (83%)] Loss: 12311.062500\n",
      "    epoch          : 537\n",
      "    loss           : 12292.424814541977\n",
      "    val_loss       : 12287.154822064109\n",
      "    val_log_likelihood: -12207.439184792442\n",
      "    val_log_marginal: -12215.295856272822\n",
      "Train Epoch: 538 [256/118836 (0%)] Loss: 12246.732422\n",
      "Train Epoch: 538 [33024/118836 (28%)] Loss: 12335.052734\n",
      "Train Epoch: 538 [65792/118836 (55%)] Loss: 12308.693359\n",
      "Train Epoch: 538 [98560/118836 (83%)] Loss: 12383.417969\n",
      "    epoch          : 538\n",
      "    loss           : 12290.366589930985\n",
      "    val_loss       : 12287.740829431259\n",
      "    val_log_likelihood: -12202.721377268144\n",
      "    val_log_marginal: -12210.511043081975\n",
      "Train Epoch: 539 [256/118836 (0%)] Loss: 12409.697266\n",
      "Train Epoch: 539 [33024/118836 (28%)] Loss: 12233.569336\n",
      "Train Epoch: 539 [65792/118836 (55%)] Loss: 12343.177734\n",
      "Train Epoch: 539 [98560/118836 (83%)] Loss: 12236.961914\n",
      "    epoch          : 539\n",
      "    loss           : 12290.369242239194\n",
      "    val_loss       : 12290.721738361533\n",
      "    val_log_likelihood: -12205.222833953681\n",
      "    val_log_marginal: -12213.070212153734\n",
      "Train Epoch: 540 [256/118836 (0%)] Loss: 12303.007812\n",
      "Train Epoch: 540 [33024/118836 (28%)] Loss: 12248.230469\n",
      "Train Epoch: 540 [65792/118836 (55%)] Loss: 12396.303711\n",
      "Train Epoch: 540 [98560/118836 (83%)] Loss: 12337.076172\n",
      "    epoch          : 540\n",
      "    loss           : 12289.675298703733\n",
      "    val_loss       : 12289.024412331613\n",
      "    val_log_likelihood: -12206.321515069272\n",
      "    val_log_marginal: -12214.22768902824\n",
      "Train Epoch: 541 [256/118836 (0%)] Loss: 12319.101562\n",
      "Train Epoch: 541 [33024/118836 (28%)] Loss: 12278.890625\n",
      "Train Epoch: 541 [65792/118836 (55%)] Loss: 12355.263672\n",
      "Train Epoch: 541 [98560/118836 (83%)] Loss: 12222.766602\n",
      "    epoch          : 541\n",
      "    loss           : 12289.603625155087\n",
      "    val_loss       : 12284.945900265337\n",
      "    val_log_likelihood: -12195.232432052575\n",
      "    val_log_marginal: -12203.024743905653\n",
      "Train Epoch: 542 [256/118836 (0%)] Loss: 12267.697266\n",
      "Train Epoch: 542 [33024/118836 (28%)] Loss: 12276.687500\n",
      "Train Epoch: 542 [65792/118836 (55%)] Loss: 12289.778320\n",
      "Train Epoch: 542 [98560/118836 (83%)] Loss: 12295.289062\n",
      "    epoch          : 542\n",
      "    loss           : 12288.170347717638\n",
      "    val_loss       : 12290.986865974452\n",
      "    val_log_likelihood: -12200.583751583177\n",
      "    val_log_marginal: -12208.866626753885\n",
      "Train Epoch: 543 [256/118836 (0%)] Loss: 12215.505859\n",
      "Train Epoch: 543 [33024/118836 (28%)] Loss: 12302.900391\n",
      "Train Epoch: 543 [65792/118836 (55%)] Loss: 12309.781250\n",
      "Train Epoch: 543 [98560/118836 (83%)] Loss: 12191.058594\n",
      "    epoch          : 543\n",
      "    loss           : 12283.092973273366\n",
      "    val_loss       : 12286.580553159156\n",
      "    val_log_likelihood: -12194.834510862542\n",
      "    val_log_marginal: -12202.703106023066\n",
      "Train Epoch: 544 [256/118836 (0%)] Loss: 12307.317383\n",
      "Train Epoch: 544 [33024/118836 (28%)] Loss: 12419.856445\n",
      "Train Epoch: 544 [65792/118836 (55%)] Loss: 12336.326172\n",
      "Train Epoch: 544 [98560/118836 (83%)] Loss: 12408.230469\n",
      "    epoch          : 544\n",
      "    loss           : 12290.094479392836\n",
      "    val_loss       : 12284.425338129879\n",
      "    val_log_likelihood: -12197.17061960427\n",
      "    val_log_marginal: -12205.06562574357\n",
      "Train Epoch: 545 [256/118836 (0%)] Loss: 12412.814453\n",
      "Train Epoch: 545 [33024/118836 (28%)] Loss: 12368.086914\n",
      "Train Epoch: 545 [65792/118836 (55%)] Loss: 12259.427734\n",
      "Train Epoch: 545 [98560/118836 (83%)] Loss: 12244.447266\n",
      "    epoch          : 545\n",
      "    loss           : 12287.856832868074\n",
      "    val_loss       : 12290.056481861624\n",
      "    val_log_likelihood: -12195.612328273624\n",
      "    val_log_marginal: -12203.498142997481\n",
      "Train Epoch: 546 [256/118836 (0%)] Loss: 12320.106445\n",
      "Train Epoch: 546 [33024/118836 (28%)] Loss: 12265.606445\n",
      "Train Epoch: 546 [65792/118836 (55%)] Loss: 12309.131836\n",
      "Train Epoch: 546 [98560/118836 (83%)] Loss: 12431.996094\n",
      "    epoch          : 546\n",
      "    loss           : 12288.469258232526\n",
      "    val_loss       : 12287.594553865334\n",
      "    val_log_likelihood: -12195.78224287893\n",
      "    val_log_marginal: -12203.542852542565\n",
      "Train Epoch: 547 [256/118836 (0%)] Loss: 12269.085938\n",
      "Train Epoch: 547 [33024/118836 (28%)] Loss: 12241.342773\n",
      "Train Epoch: 547 [65792/118836 (55%)] Loss: 12222.937500\n",
      "Train Epoch: 547 [98560/118836 (83%)] Loss: 12330.888672\n",
      "    epoch          : 547\n",
      "    loss           : 12285.365162001137\n",
      "    val_loss       : 12285.090834323546\n",
      "    val_log_likelihood: -12198.163095468879\n",
      "    val_log_marginal: -12206.19464323602\n",
      "Train Epoch: 548 [256/118836 (0%)] Loss: 12270.185547\n",
      "Train Epoch: 548 [33024/118836 (28%)] Loss: 12308.337891\n",
      "Train Epoch: 548 [65792/118836 (55%)] Loss: 12202.090820\n",
      "Train Epoch: 548 [98560/118836 (83%)] Loss: 12296.628906\n",
      "    epoch          : 548\n",
      "    loss           : 12287.707907490694\n",
      "    val_loss       : 12288.511134460961\n",
      "    val_log_likelihood: -12199.8748520213\n",
      "    val_log_marginal: -12207.910633175381\n",
      "Train Epoch: 549 [256/118836 (0%)] Loss: 12310.018555\n",
      "Train Epoch: 549 [33024/118836 (28%)] Loss: 12291.389648\n",
      "Train Epoch: 549 [65792/118836 (55%)] Loss: 12430.350586\n",
      "Train Epoch: 549 [98560/118836 (83%)] Loss: 12371.361328\n",
      "    epoch          : 549\n",
      "    loss           : 12290.970290367814\n",
      "    val_loss       : 12284.589855773784\n",
      "    val_log_likelihood: -12195.111904854219\n",
      "    val_log_marginal: -12203.024035962831\n",
      "Train Epoch: 550 [256/118836 (0%)] Loss: 12291.470703\n",
      "Train Epoch: 550 [33024/118836 (28%)] Loss: 12317.210938\n",
      "Train Epoch: 550 [65792/118836 (55%)] Loss: 12290.018555\n",
      "Train Epoch: 550 [98560/118836 (83%)] Loss: 12288.365234\n",
      "    epoch          : 550\n",
      "    loss           : 12282.732042396869\n",
      "    val_loss       : 12286.840750986317\n",
      "    val_log_likelihood: -12200.742425784481\n",
      "    val_log_marginal: -12208.58240596494\n",
      "Train Epoch: 551 [256/118836 (0%)] Loss: 12232.476562\n",
      "Train Epoch: 551 [33024/118836 (28%)] Loss: 12239.310547\n",
      "Train Epoch: 551 [65792/118836 (55%)] Loss: 12300.315430\n",
      "Train Epoch: 551 [98560/118836 (83%)] Loss: 12242.207031\n",
      "    epoch          : 551\n",
      "    loss           : 12286.446241405603\n",
      "    val_loss       : 12284.946970627252\n",
      "    val_log_likelihood: -12197.267785069014\n",
      "    val_log_marginal: -12205.186829099384\n",
      "Train Epoch: 552 [256/118836 (0%)] Loss: 12309.089844\n",
      "Train Epoch: 552 [33024/118836 (28%)] Loss: 12416.013672\n",
      "Train Epoch: 552 [65792/118836 (55%)] Loss: 12272.977539\n",
      "Train Epoch: 552 [98560/118836 (83%)] Loss: 12375.557617\n",
      "    epoch          : 552\n",
      "    loss           : 12289.021932349824\n",
      "    val_loss       : 12288.208007462968\n",
      "    val_log_likelihood: -12197.09853442928\n",
      "    val_log_marginal: -12204.92963729324\n",
      "Train Epoch: 553 [256/118836 (0%)] Loss: 12384.238281\n",
      "Train Epoch: 553 [33024/118836 (28%)] Loss: 12371.652344\n",
      "Train Epoch: 553 [65792/118836 (55%)] Loss: 12326.588867\n",
      "Train Epoch: 553 [98560/118836 (83%)] Loss: 12228.952148\n",
      "    epoch          : 553\n",
      "    loss           : 12287.480712688688\n",
      "    val_loss       : 12285.71972760063\n",
      "    val_log_likelihood: -12200.223736042182\n",
      "    val_log_marginal: -12207.947254578641\n",
      "Train Epoch: 554 [256/118836 (0%)] Loss: 12205.267578\n",
      "Train Epoch: 554 [33024/118836 (28%)] Loss: 12354.439453\n",
      "Train Epoch: 554 [65792/118836 (55%)] Loss: 12304.647461\n",
      "Train Epoch: 554 [98560/118836 (83%)] Loss: 12341.086914\n",
      "    epoch          : 554\n",
      "    loss           : 12284.622301004189\n",
      "    val_loss       : 12294.856989034712\n",
      "    val_log_likelihood: -12200.136375458798\n",
      "    val_log_marginal: -12208.284011457074\n",
      "Train Epoch: 555 [256/118836 (0%)] Loss: 12379.554688\n",
      "Train Epoch: 555 [33024/118836 (28%)] Loss: 12324.389648\n",
      "Train Epoch: 555 [65792/118836 (55%)] Loss: 12289.517578\n",
      "Train Epoch: 555 [98560/118836 (83%)] Loss: 12432.380859\n",
      "    epoch          : 555\n",
      "    loss           : 12289.601873642989\n",
      "    val_loss       : 12286.372330272032\n",
      "    val_log_likelihood: -12195.25354373449\n",
      "    val_log_marginal: -12203.157863753908\n",
      "Train Epoch: 556 [256/118836 (0%)] Loss: 12371.213867\n",
      "Train Epoch: 556 [33024/118836 (28%)] Loss: 12341.583008\n",
      "Train Epoch: 556 [65792/118836 (55%)] Loss: 12344.222656\n",
      "Train Epoch: 556 [98560/118836 (83%)] Loss: 12272.741211\n",
      "    epoch          : 556\n",
      "    loss           : 12288.258146906017\n",
      "    val_loss       : 12286.20888410081\n",
      "    val_log_likelihood: -12193.196541078629\n",
      "    val_log_marginal: -12201.075701721145\n",
      "Train Epoch: 557 [256/118836 (0%)] Loss: 12282.531250\n",
      "Train Epoch: 557 [33024/118836 (28%)] Loss: 12427.013672\n",
      "Train Epoch: 557 [65792/118836 (55%)] Loss: 12332.764648\n",
      "Train Epoch: 557 [98560/118836 (83%)] Loss: 12269.025391\n",
      "    epoch          : 557\n",
      "    loss           : 12288.041945338347\n",
      "    val_loss       : 12285.39257038565\n",
      "    val_log_likelihood: -12198.340807065499\n",
      "    val_log_marginal: -12206.196803602701\n",
      "Train Epoch: 558 [256/118836 (0%)] Loss: 12379.341797\n",
      "Train Epoch: 558 [33024/118836 (28%)] Loss: 12296.937500\n",
      "Train Epoch: 558 [65792/118836 (55%)] Loss: 12320.903320\n",
      "Train Epoch: 558 [98560/118836 (83%)] Loss: 12271.548828\n",
      "    epoch          : 558\n",
      "    loss           : 12288.260802283654\n",
      "    val_loss       : 12286.204691962841\n",
      "    val_log_likelihood: -12195.969349669149\n",
      "    val_log_marginal: -12203.874505983615\n",
      "Train Epoch: 559 [256/118836 (0%)] Loss: 12288.597656\n",
      "Train Epoch: 559 [33024/118836 (28%)] Loss: 12314.017578\n",
      "Train Epoch: 559 [65792/118836 (55%)] Loss: 12371.788086\n",
      "Train Epoch: 559 [98560/118836 (83%)] Loss: 12297.501953\n",
      "    epoch          : 559\n",
      "    loss           : 12294.278435819893\n",
      "    val_loss       : 12289.794795469319\n",
      "    val_log_likelihood: -12199.298563184968\n",
      "    val_log_marginal: -12206.98131426845\n",
      "Train Epoch: 560 [256/118836 (0%)] Loss: 12312.706055\n",
      "Train Epoch: 560 [33024/118836 (28%)] Loss: 12370.950195\n",
      "Train Epoch: 560 [65792/118836 (55%)] Loss: 12436.787109\n",
      "Train Epoch: 560 [98560/118836 (83%)] Loss: 12231.732422\n",
      "    epoch          : 560\n",
      "    loss           : 12285.3961609543\n",
      "    val_loss       : 12289.979473950183\n",
      "    val_log_likelihood: -12196.980324810018\n",
      "    val_log_marginal: -12204.703538163689\n",
      "Train Epoch: 561 [256/118836 (0%)] Loss: 12200.551758\n",
      "Train Epoch: 561 [33024/118836 (28%)] Loss: 12313.993164\n",
      "Train Epoch: 561 [65792/118836 (55%)] Loss: 12329.820312\n",
      "Train Epoch: 561 [98560/118836 (83%)] Loss: 12288.226562\n",
      "    epoch          : 561\n",
      "    loss           : 12287.788456368899\n",
      "    val_loss       : 12286.939057104828\n",
      "    val_log_likelihood: -12198.217132411859\n",
      "    val_log_marginal: -12206.045359868562\n",
      "Train Epoch: 562 [256/118836 (0%)] Loss: 12321.131836\n",
      "Train Epoch: 562 [33024/118836 (28%)] Loss: 12248.322266\n",
      "Train Epoch: 562 [65792/118836 (55%)] Loss: 12263.570312\n",
      "Train Epoch: 562 [98560/118836 (83%)] Loss: 12256.112305\n",
      "    epoch          : 562\n",
      "    loss           : 12289.004133710712\n",
      "    val_loss       : 12286.663150611528\n",
      "    val_log_likelihood: -12196.69793492168\n",
      "    val_log_marginal: -12204.830273601108\n",
      "Train Epoch: 563 [256/118836 (0%)] Loss: 12301.724609\n",
      "Train Epoch: 563 [33024/118836 (28%)] Loss: 12290.027344\n",
      "Train Epoch: 563 [65792/118836 (55%)] Loss: 12344.810547\n",
      "Train Epoch: 563 [98560/118836 (83%)] Loss: 12325.768555\n",
      "    epoch          : 563\n",
      "    loss           : 12284.105395729943\n",
      "    val_loss       : 12286.483100813575\n",
      "    val_log_likelihood: -12191.928545349978\n",
      "    val_log_marginal: -12199.827126479535\n",
      "Train Epoch: 564 [256/118836 (0%)] Loss: 12304.746094\n",
      "Train Epoch: 564 [33024/118836 (28%)] Loss: 12281.851562\n",
      "Train Epoch: 564 [65792/118836 (55%)] Loss: 12250.384766\n",
      "Train Epoch: 564 [98560/118836 (83%)] Loss: 12245.655273\n",
      "    epoch          : 564\n",
      "    loss           : 12285.39443561311\n",
      "    val_loss       : 12289.273133717006\n",
      "    val_log_likelihood: -12195.317900899503\n",
      "    val_log_marginal: -12203.632928318411\n",
      "Train Epoch: 565 [256/118836 (0%)] Loss: 12239.735352\n",
      "Train Epoch: 565 [33024/118836 (28%)] Loss: 12298.117188\n",
      "Train Epoch: 565 [65792/118836 (55%)] Loss: 12287.063477\n",
      "Train Epoch: 565 [98560/118836 (83%)] Loss: 12430.479492\n",
      "    epoch          : 565\n",
      "    loss           : 12286.649641523212\n",
      "    val_loss       : 12288.794890725983\n",
      "    val_log_likelihood: -12191.834739292544\n",
      "    val_log_marginal: -12199.785360627091\n",
      "Train Epoch: 566 [256/118836 (0%)] Loss: 12252.326172\n",
      "Train Epoch: 566 [33024/118836 (28%)] Loss: 12338.303711\n",
      "Train Epoch: 566 [65792/118836 (55%)] Loss: 12263.939453\n",
      "Train Epoch: 566 [98560/118836 (83%)] Loss: 12402.149414\n",
      "    epoch          : 566\n",
      "    loss           : 12289.09252836797\n",
      "    val_loss       : 12279.83798856913\n",
      "    val_log_likelihood: -12193.54954071676\n",
      "    val_log_marginal: -12201.227487167296\n",
      "Train Epoch: 567 [256/118836 (0%)] Loss: 12196.606445\n",
      "Train Epoch: 567 [33024/118836 (28%)] Loss: 12354.064453\n",
      "Train Epoch: 567 [65792/118836 (55%)] Loss: 12291.550781\n",
      "Train Epoch: 567 [98560/118836 (83%)] Loss: 12271.459961\n",
      "    epoch          : 567\n",
      "    loss           : 12288.93197454637\n",
      "    val_loss       : 12289.20451115717\n",
      "    val_log_likelihood: -12196.535539120658\n",
      "    val_log_marginal: -12204.348975636605\n",
      "Train Epoch: 568 [256/118836 (0%)] Loss: 12273.596680\n",
      "Train Epoch: 568 [33024/118836 (28%)] Loss: 12292.171875\n",
      "Train Epoch: 568 [65792/118836 (55%)] Loss: 12347.261719\n",
      "Train Epoch: 568 [98560/118836 (83%)] Loss: 12349.512695\n",
      "    epoch          : 568\n",
      "    loss           : 12281.769720262097\n",
      "    val_loss       : 12291.316752774635\n",
      "    val_log_likelihood: -12206.429046635909\n",
      "    val_log_marginal: -12214.3940720987\n",
      "Train Epoch: 569 [256/118836 (0%)] Loss: 12280.433594\n",
      "Train Epoch: 569 [33024/118836 (28%)] Loss: 12268.179688\n",
      "Train Epoch: 569 [65792/118836 (55%)] Loss: 12292.095703\n",
      "Train Epoch: 569 [98560/118836 (83%)] Loss: 12247.436523\n",
      "    epoch          : 569\n",
      "    loss           : 12291.014235841863\n",
      "    val_loss       : 12288.469075771593\n",
      "    val_log_likelihood: -12196.90016429513\n",
      "    val_log_marginal: -12204.715022988123\n",
      "Train Epoch: 570 [256/118836 (0%)] Loss: 12309.595703\n",
      "Train Epoch: 570 [33024/118836 (28%)] Loss: 12372.240234\n",
      "Train Epoch: 570 [65792/118836 (55%)] Loss: 12349.784180\n",
      "Train Epoch: 570 [98560/118836 (83%)] Loss: 12357.612305\n",
      "    epoch          : 570\n",
      "    loss           : 12291.99940453112\n",
      "    val_loss       : 12285.4062287152\n",
      "    val_log_likelihood: -12198.59450685613\n",
      "    val_log_marginal: -12206.360763042432\n",
      "Train Epoch: 571 [256/118836 (0%)] Loss: 12422.063477\n",
      "Train Epoch: 571 [33024/118836 (28%)] Loss: 12386.382812\n",
      "Train Epoch: 571 [65792/118836 (55%)] Loss: 12314.998047\n",
      "Train Epoch: 571 [98560/118836 (83%)] Loss: 12348.169922\n",
      "    epoch          : 571\n",
      "    loss           : 12285.019599746693\n",
      "    val_loss       : 12282.346031550243\n",
      "    val_log_likelihood: -12194.998478533396\n",
      "    val_log_marginal: -12202.834957015704\n",
      "Train Epoch: 572 [256/118836 (0%)] Loss: 12284.241211\n",
      "Train Epoch: 572 [33024/118836 (28%)] Loss: 12280.283203\n",
      "Train Epoch: 572 [65792/118836 (55%)] Loss: 12328.718750\n",
      "Train Epoch: 572 [98560/118836 (83%)] Loss: 12352.732422\n",
      "    epoch          : 572\n",
      "    loss           : 12287.674094034326\n",
      "    val_loss       : 12284.263828693269\n",
      "    val_log_likelihood: -12195.803916266026\n",
      "    val_log_marginal: -12203.52364284737\n",
      "Train Epoch: 573 [256/118836 (0%)] Loss: 12378.041016\n",
      "Train Epoch: 573 [33024/118836 (28%)] Loss: 12315.910156\n",
      "Train Epoch: 573 [65792/118836 (55%)] Loss: 12388.264648\n",
      "Train Epoch: 573 [98560/118836 (83%)] Loss: 12254.090820\n",
      "    epoch          : 573\n",
      "    loss           : 12283.647756571805\n",
      "    val_loss       : 12288.562664186371\n",
      "    val_log_likelihood: -12202.108950934398\n",
      "    val_log_marginal: -12210.276877790391\n",
      "Train Epoch: 574 [256/118836 (0%)] Loss: 12348.562500\n",
      "Train Epoch: 574 [33024/118836 (28%)] Loss: 12320.261719\n",
      "Train Epoch: 574 [65792/118836 (55%)] Loss: 12290.291016\n",
      "Train Epoch: 574 [98560/118836 (83%)] Loss: 12337.058594\n",
      "    epoch          : 574\n",
      "    loss           : 12293.083671454973\n",
      "    val_loss       : 12286.361540947993\n",
      "    val_log_likelihood: -12196.780330302678\n",
      "    val_log_marginal: -12204.785038145608\n",
      "Train Epoch: 575 [256/118836 (0%)] Loss: 12311.017578\n",
      "Train Epoch: 575 [33024/118836 (28%)] Loss: 12361.652344\n",
      "Train Epoch: 575 [65792/118836 (55%)] Loss: 12272.604492\n",
      "Train Epoch: 575 [98560/118836 (83%)] Loss: 12303.681641\n",
      "    epoch          : 575\n",
      "    loss           : 12284.605508329458\n",
      "    val_loss       : 12286.589318183644\n",
      "    val_log_likelihood: -12199.192817055677\n",
      "    val_log_marginal: -12207.091849620836\n",
      "Train Epoch: 576 [256/118836 (0%)] Loss: 12274.298828\n",
      "Train Epoch: 576 [33024/118836 (28%)] Loss: 12294.822266\n",
      "Train Epoch: 576 [65792/118836 (55%)] Loss: 12356.283203\n",
      "Train Epoch: 576 [98560/118836 (83%)] Loss: 12277.629883\n",
      "    epoch          : 576\n",
      "    loss           : 12285.92540677988\n",
      "    val_loss       : 12285.427382445494\n",
      "    val_log_likelihood: -12196.141503502378\n",
      "    val_log_marginal: -12203.908458529\n",
      "Train Epoch: 577 [256/118836 (0%)] Loss: 12328.053711\n",
      "Train Epoch: 577 [33024/118836 (28%)] Loss: 12278.167969\n",
      "Train Epoch: 577 [65792/118836 (55%)] Loss: 12269.158203\n",
      "Train Epoch: 577 [98560/118836 (83%)] Loss: 12288.499023\n",
      "    epoch          : 577\n",
      "    loss           : 12288.009111513906\n",
      "    val_loss       : 12286.103263746869\n",
      "    val_log_likelihood: -12198.267991689929\n",
      "    val_log_marginal: -12206.068292299475\n",
      "Train Epoch: 578 [256/118836 (0%)] Loss: 12254.371094\n",
      "Train Epoch: 578 [33024/118836 (28%)] Loss: 12362.449219\n",
      "Train Epoch: 578 [65792/118836 (55%)] Loss: 12305.873047\n",
      "Train Epoch: 578 [98560/118836 (83%)] Loss: 12296.972656\n",
      "    epoch          : 578\n",
      "    loss           : 12287.730504129187\n",
      "    val_loss       : 12287.875546629006\n",
      "    val_log_likelihood: -12196.865058609905\n",
      "    val_log_marginal: -12204.80101872975\n",
      "Train Epoch: 579 [256/118836 (0%)] Loss: 12309.782227\n",
      "Train Epoch: 579 [33024/118836 (28%)] Loss: 12339.779297\n",
      "Train Epoch: 579 [65792/118836 (55%)] Loss: 12355.597656\n",
      "Train Epoch: 579 [98560/118836 (83%)] Loss: 12270.417969\n",
      "    epoch          : 579\n",
      "    loss           : 12288.069946915064\n",
      "    val_loss       : 12288.632839970993\n",
      "    val_log_likelihood: -12197.88540406586\n",
      "    val_log_marginal: -12205.710496097614\n",
      "Train Epoch: 580 [256/118836 (0%)] Loss: 12271.738281\n",
      "Train Epoch: 580 [33024/118836 (28%)] Loss: 12229.650391\n",
      "Train Epoch: 580 [65792/118836 (55%)] Loss: 12238.576172\n",
      "Train Epoch: 580 [98560/118836 (83%)] Loss: 12264.250000\n",
      "    epoch          : 580\n",
      "    loss           : 12287.00137801127\n",
      "    val_loss       : 12287.087776104492\n",
      "    val_log_likelihood: -12194.77458498113\n",
      "    val_log_marginal: -12202.51769614836\n",
      "Train Epoch: 581 [256/118836 (0%)] Loss: 12285.533203\n",
      "Train Epoch: 581 [33024/118836 (28%)] Loss: 12308.553711\n",
      "Train Epoch: 581 [65792/118836 (55%)] Loss: 12314.609375\n",
      "Train Epoch: 581 [98560/118836 (83%)] Loss: 12301.791016\n",
      "    epoch          : 581\n",
      "    loss           : 12288.337626977356\n",
      "    val_loss       : 12286.575153887476\n",
      "    val_log_likelihood: -12196.395879213194\n",
      "    val_log_marginal: -12204.433006878153\n",
      "Train Epoch: 582 [256/118836 (0%)] Loss: 12284.950195\n",
      "Train Epoch: 582 [33024/118836 (28%)] Loss: 12381.125977\n",
      "Train Epoch: 582 [65792/118836 (55%)] Loss: 12290.365234\n",
      "Train Epoch: 582 [98560/118836 (83%)] Loss: 12219.197266\n",
      "    epoch          : 582\n",
      "    loss           : 12284.79207166951\n",
      "    val_loss       : 12286.938654863334\n",
      "    val_log_likelihood: -12194.749598228133\n",
      "    val_log_marginal: -12202.412014772\n",
      "Train Epoch: 583 [256/118836 (0%)] Loss: 12331.529297\n",
      "Train Epoch: 583 [33024/118836 (28%)] Loss: 12336.578125\n",
      "Train Epoch: 583 [65792/118836 (55%)] Loss: 12334.597656\n",
      "Train Epoch: 583 [98560/118836 (83%)] Loss: 12320.255859\n",
      "    epoch          : 583\n",
      "    loss           : 12283.289307892628\n",
      "    val_loss       : 12290.300174555185\n",
      "    val_log_likelihood: -12193.661370289237\n",
      "    val_log_marginal: -12201.310678710144\n",
      "Train Epoch: 584 [256/118836 (0%)] Loss: 12302.424805\n",
      "Train Epoch: 584 [33024/118836 (28%)] Loss: 12282.240234\n",
      "Train Epoch: 584 [65792/118836 (55%)] Loss: 12254.170898\n",
      "Train Epoch: 584 [98560/118836 (83%)] Loss: 12280.027344\n",
      "    epoch          : 584\n",
      "    loss           : 12283.34050787712\n",
      "    val_loss       : 12284.335798108483\n",
      "    val_log_likelihood: -12195.149871084059\n",
      "    val_log_marginal: -12203.26198329062\n",
      "Train Epoch: 585 [256/118836 (0%)] Loss: 12392.771484\n",
      "Train Epoch: 585 [33024/118836 (28%)] Loss: 12291.000977\n",
      "Train Epoch: 585 [65792/118836 (55%)] Loss: 12310.398438\n",
      "Train Epoch: 585 [98560/118836 (83%)] Loss: 12351.913086\n",
      "    epoch          : 585\n",
      "    loss           : 12289.91071391646\n",
      "    val_loss       : 12289.801707270042\n",
      "    val_log_likelihood: -12198.1976092393\n",
      "    val_log_marginal: -12206.301958442698\n",
      "Train Epoch: 586 [256/118836 (0%)] Loss: 12318.951172\n",
      "Train Epoch: 586 [33024/118836 (28%)] Loss: 12331.057617\n",
      "Train Epoch: 586 [65792/118836 (55%)] Loss: 12362.029297\n",
      "Train Epoch: 586 [98560/118836 (83%)] Loss: 12378.526367\n",
      "    epoch          : 586\n",
      "    loss           : 12285.509584690344\n",
      "    val_loss       : 12290.296748237124\n",
      "    val_log_likelihood: -12195.75581349514\n",
      "    val_log_marginal: -12203.47313755118\n",
      "Train Epoch: 587 [256/118836 (0%)] Loss: 12390.042969\n",
      "Train Epoch: 587 [33024/118836 (28%)] Loss: 12356.880859\n",
      "Train Epoch: 587 [65792/118836 (55%)] Loss: 12309.624023\n",
      "Train Epoch: 587 [98560/118836 (83%)] Loss: 12260.779297\n",
      "    epoch          : 587\n",
      "    loss           : 12283.644231900073\n",
      "    val_loss       : 12286.607870960317\n",
      "    val_log_likelihood: -12195.137070603289\n",
      "    val_log_marginal: -12202.942541408182\n",
      "Train Epoch: 588 [256/118836 (0%)] Loss: 12293.645508\n",
      "Train Epoch: 588 [33024/118836 (28%)] Loss: 12245.507812\n",
      "Train Epoch: 588 [65792/118836 (55%)] Loss: 12170.438477\n",
      "Train Epoch: 588 [98560/118836 (83%)] Loss: 12296.039062\n",
      "    epoch          : 588\n",
      "    loss           : 12284.856242407206\n",
      "    val_loss       : 12290.138515794792\n",
      "    val_log_likelihood: -12197.482469531897\n",
      "    val_log_marginal: -12205.376999331836\n",
      "Train Epoch: 589 [256/118836 (0%)] Loss: 12210.596680\n",
      "Train Epoch: 589 [33024/118836 (28%)] Loss: 12346.574219\n",
      "Train Epoch: 589 [65792/118836 (55%)] Loss: 12294.532227\n",
      "Train Epoch: 589 [98560/118836 (83%)] Loss: 12269.783203\n",
      "    epoch          : 589\n",
      "    loss           : 12290.173286774969\n",
      "    val_loss       : 12287.965134443877\n",
      "    val_log_likelihood: -12201.87844680521\n",
      "    val_log_marginal: -12209.772201091355\n",
      "Train Epoch: 590 [256/118836 (0%)] Loss: 12394.908203\n",
      "Train Epoch: 590 [33024/118836 (28%)] Loss: 12477.292969\n",
      "Train Epoch: 590 [65792/118836 (55%)] Loss: 12385.227539\n",
      "Train Epoch: 590 [98560/118836 (83%)] Loss: 12286.487305\n",
      "    epoch          : 590\n",
      "    loss           : 12284.177191894127\n",
      "    val_loss       : 12287.906786956799\n",
      "    val_log_likelihood: -12194.811635552367\n",
      "    val_log_marginal: -12202.780441096113\n",
      "Train Epoch: 591 [256/118836 (0%)] Loss: 12288.877930\n",
      "Train Epoch: 591 [33024/118836 (28%)] Loss: 12349.335938\n",
      "Train Epoch: 591 [65792/118836 (55%)] Loss: 12435.300781\n",
      "Train Epoch: 591 [98560/118836 (83%)] Loss: 12216.654297\n",
      "    epoch          : 591\n",
      "    loss           : 12287.677477350859\n",
      "    val_loss       : 12283.062267238955\n",
      "    val_log_likelihood: -12194.943098312138\n",
      "    val_log_marginal: -12202.615733725876\n",
      "Train Epoch: 592 [256/118836 (0%)] Loss: 12282.033203\n",
      "Train Epoch: 592 [33024/118836 (28%)] Loss: 12220.099609\n",
      "Train Epoch: 592 [65792/118836 (55%)] Loss: 12310.318359\n",
      "Train Epoch: 592 [98560/118836 (83%)] Loss: 12320.202148\n",
      "    epoch          : 592\n",
      "    loss           : 12283.456797811983\n",
      "    val_loss       : 12290.909243933414\n",
      "    val_log_likelihood: -12194.081804597034\n",
      "    val_log_marginal: -12201.871847344135\n",
      "Train Epoch: 593 [256/118836 (0%)] Loss: 12312.292969\n",
      "Train Epoch: 593 [33024/118836 (28%)] Loss: 12303.241211\n",
      "Train Epoch: 593 [65792/118836 (55%)] Loss: 12345.513672\n",
      "Train Epoch: 593 [98560/118836 (83%)] Loss: 12285.384766\n",
      "    epoch          : 593\n",
      "    loss           : 12287.45995560639\n",
      "    val_loss       : 12289.324332497938\n",
      "    val_log_likelihood: -12195.84267392344\n",
      "    val_log_marginal: -12203.707538715062\n",
      "Train Epoch: 594 [256/118836 (0%)] Loss: 12376.117188\n",
      "Train Epoch: 594 [33024/118836 (28%)] Loss: 12323.136719\n",
      "Train Epoch: 594 [65792/118836 (55%)] Loss: 12246.968750\n",
      "Train Epoch: 594 [98560/118836 (83%)] Loss: 12228.564453\n",
      "    epoch          : 594\n",
      "    loss           : 12284.525931167285\n",
      "    val_loss       : 12284.220360906918\n",
      "    val_log_likelihood: -12190.47558044484\n",
      "    val_log_marginal: -12198.379178607973\n",
      "Train Epoch: 595 [256/118836 (0%)] Loss: 12238.349609\n",
      "Train Epoch: 595 [33024/118836 (28%)] Loss: 12340.839844\n",
      "Train Epoch: 595 [65792/118836 (55%)] Loss: 12277.595703\n",
      "Train Epoch: 595 [98560/118836 (83%)] Loss: 12330.739258\n",
      "    epoch          : 595\n",
      "    loss           : 12283.898295983252\n",
      "    val_loss       : 12285.076717227968\n",
      "    val_log_likelihood: -12193.334239622105\n",
      "    val_log_marginal: -12201.460875593593\n",
      "Train Epoch: 596 [256/118836 (0%)] Loss: 12254.945312\n",
      "Train Epoch: 596 [33024/118836 (28%)] Loss: 12256.112305\n",
      "Train Epoch: 596 [65792/118836 (55%)] Loss: 12342.713867\n",
      "Train Epoch: 596 [98560/118836 (83%)] Loss: 12345.798828\n",
      "    epoch          : 596\n",
      "    loss           : 12286.618772616832\n",
      "    val_loss       : 12285.20179118355\n",
      "    val_log_likelihood: -12194.347814244727\n",
      "    val_log_marginal: -12202.209096258895\n",
      "Train Epoch: 597 [256/118836 (0%)] Loss: 12289.887695\n",
      "Train Epoch: 597 [33024/118836 (28%)] Loss: 12225.964844\n",
      "Train Epoch: 597 [65792/118836 (55%)] Loss: 12389.325195\n",
      "Train Epoch: 597 [98560/118836 (83%)] Loss: 12264.158203\n",
      "    epoch          : 597\n",
      "    loss           : 12283.614831310742\n",
      "    val_loss       : 12282.856899171797\n",
      "    val_log_likelihood: -12193.409331381823\n",
      "    val_log_marginal: -12201.314795648119\n",
      "Train Epoch: 598 [256/118836 (0%)] Loss: 12354.029297\n",
      "Train Epoch: 598 [33024/118836 (28%)] Loss: 12299.266602\n",
      "Train Epoch: 598 [65792/118836 (55%)] Loss: 12322.374023\n",
      "Train Epoch: 598 [98560/118836 (83%)] Loss: 12258.082031\n",
      "    epoch          : 598\n",
      "    loss           : 12285.754037750725\n",
      "    val_loss       : 12280.111947471454\n",
      "    val_log_likelihood: -12191.804682976634\n",
      "    val_log_marginal: -12199.54642920838\n",
      "Train Epoch: 599 [256/118836 (0%)] Loss: 12328.833984\n",
      "Train Epoch: 599 [33024/118836 (28%)] Loss: 12280.827148\n",
      "Train Epoch: 599 [65792/118836 (55%)] Loss: 12276.582031\n",
      "Train Epoch: 599 [98560/118836 (83%)] Loss: 12315.638672\n",
      "    epoch          : 599\n",
      "    loss           : 12288.248184514578\n",
      "    val_loss       : 12283.626140276767\n",
      "    val_log_likelihood: -12195.787408240281\n",
      "    val_log_marginal: -12203.616335436784\n",
      "Train Epoch: 600 [256/118836 (0%)] Loss: 12381.319336\n",
      "Train Epoch: 600 [33024/118836 (28%)] Loss: 12281.763672\n",
      "Train Epoch: 600 [65792/118836 (55%)] Loss: 12310.278320\n",
      "Train Epoch: 600 [98560/118836 (83%)] Loss: 12330.663086\n",
      "    epoch          : 600\n",
      "    loss           : 12286.071446411032\n",
      "    val_loss       : 12285.629522115492\n",
      "    val_log_likelihood: -12195.015577020005\n",
      "    val_log_marginal: -12203.113239038521\n",
      "Saving checkpoint: saved/models/SelfiesAutoencodingOperad/0905_154251/checkpoint-epoch600.pth ...\n",
      "Train Epoch: 601 [256/118836 (0%)] Loss: 12275.675781\n",
      "Train Epoch: 601 [33024/118836 (28%)] Loss: 12353.292969\n",
      "Train Epoch: 601 [65792/118836 (55%)] Loss: 12271.415039\n",
      "Train Epoch: 601 [98560/118836 (83%)] Loss: 12275.169922\n",
      "    epoch          : 601\n",
      "    loss           : 12297.380292661806\n",
      "    val_loss       : 12284.793098053135\n",
      "    val_log_likelihood: -12192.972449305986\n",
      "    val_log_marginal: -12200.78080485587\n",
      "Train Epoch: 602 [256/118836 (0%)] Loss: 12362.082031\n",
      "Train Epoch: 602 [33024/118836 (28%)] Loss: 12322.637695\n",
      "Train Epoch: 602 [65792/118836 (55%)] Loss: 12303.573242\n",
      "Train Epoch: 602 [98560/118836 (83%)] Loss: 12291.038086\n",
      "    epoch          : 602\n",
      "    loss           : 12290.787182879705\n",
      "    val_loss       : 12288.085613117692\n",
      "    val_log_likelihood: -12196.61425248139\n",
      "    val_log_marginal: -12204.643140357168\n",
      "Train Epoch: 603 [256/118836 (0%)] Loss: 12346.199219\n",
      "Train Epoch: 603 [33024/118836 (28%)] Loss: 12475.808594\n",
      "Train Epoch: 603 [65792/118836 (55%)] Loss: 12275.971680\n",
      "Train Epoch: 603 [98560/118836 (83%)] Loss: 12271.990234\n",
      "    epoch          : 603\n",
      "    loss           : 12287.122293249844\n",
      "    val_loss       : 12285.36900917153\n",
      "    val_log_likelihood: -12194.934897933468\n",
      "    val_log_marginal: -12202.803476204277\n",
      "Train Epoch: 604 [256/118836 (0%)] Loss: 12242.689453\n",
      "Train Epoch: 604 [33024/118836 (28%)] Loss: 12350.644531\n",
      "Train Epoch: 604 [65792/118836 (55%)] Loss: 12437.019531\n",
      "Train Epoch: 604 [98560/118836 (83%)] Loss: 12235.241211\n",
      "    epoch          : 604\n",
      "    loss           : 12283.509580651622\n",
      "    val_loss       : 12286.578864768737\n",
      "    val_log_likelihood: -12195.67684149478\n",
      "    val_log_marginal: -12203.545800577875\n",
      "Train Epoch: 605 [256/118836 (0%)] Loss: 12245.076172\n",
      "Train Epoch: 605 [33024/118836 (28%)] Loss: 12280.677734\n",
      "Train Epoch: 605 [65792/118836 (55%)] Loss: 12296.947266\n",
      "Train Epoch: 605 [98560/118836 (83%)] Loss: 12348.947266\n",
      "    epoch          : 605\n",
      "    loss           : 12281.868534655448\n",
      "    val_loss       : 12288.952329925643\n",
      "    val_log_likelihood: -12192.267968426902\n",
      "    val_log_marginal: -12200.153675178244\n",
      "Train Epoch: 606 [256/118836 (0%)] Loss: 12290.053711\n",
      "Train Epoch: 606 [33024/118836 (28%)] Loss: 12330.595703\n",
      "Train Epoch: 606 [65792/118836 (55%)] Loss: 12331.535156\n",
      "Train Epoch: 606 [98560/118836 (83%)] Loss: 12375.033203\n",
      "    epoch          : 606\n",
      "    loss           : 12286.178009492607\n",
      "    val_loss       : 12287.729795966534\n",
      "    val_log_likelihood: -12192.07429564723\n",
      "    val_log_marginal: -12199.872159726323\n",
      "Train Epoch: 607 [256/118836 (0%)] Loss: 12408.728516\n",
      "Train Epoch: 607 [33024/118836 (28%)] Loss: 12271.066406\n",
      "Train Epoch: 607 [65792/118836 (55%)] Loss: 12393.292969\n",
      "Train Epoch: 607 [98560/118836 (83%)] Loss: 12355.202148\n",
      "    epoch          : 607\n",
      "    loss           : 12287.248669160981\n",
      "    val_loss       : 12281.72345730217\n",
      "    val_log_likelihood: -12195.415373468517\n",
      "    val_log_marginal: -12203.081885615704\n",
      "Train Epoch: 608 [256/118836 (0%)] Loss: 12304.980469\n",
      "Train Epoch: 608 [33024/118836 (28%)] Loss: 12304.077148\n",
      "Train Epoch: 608 [65792/118836 (55%)] Loss: 12252.951172\n",
      "Train Epoch: 608 [98560/118836 (83%)] Loss: 12313.826172\n",
      "    epoch          : 608\n",
      "    loss           : 12283.161435070306\n",
      "    val_loss       : 12288.889798555916\n",
      "    val_log_likelihood: -12191.90588376887\n",
      "    val_log_marginal: -12199.500331295589\n",
      "Train Epoch: 609 [256/118836 (0%)] Loss: 12247.536133\n",
      "Train Epoch: 609 [33024/118836 (28%)] Loss: 12236.771484\n",
      "Train Epoch: 609 [65792/118836 (55%)] Loss: 12349.126953\n",
      "Train Epoch: 609 [98560/118836 (83%)] Loss: 12254.853516\n",
      "    epoch          : 609\n",
      "    loss           : 12287.082763712262\n",
      "    val_loss       : 12286.71000863325\n",
      "    val_log_likelihood: -12191.192524813896\n",
      "    val_log_marginal: -12198.91271325752\n",
      "Train Epoch: 610 [256/118836 (0%)] Loss: 12288.367188\n",
      "Train Epoch: 610 [33024/118836 (28%)] Loss: 12379.111328\n",
      "Train Epoch: 610 [65792/118836 (55%)] Loss: 12343.290039\n",
      "Train Epoch: 610 [98560/118836 (83%)] Loss: 12242.928711\n",
      "    epoch          : 610\n",
      "    loss           : 12286.559497130893\n",
      "    val_loss       : 12285.308135828818\n",
      "    val_log_likelihood: -12191.373973357371\n",
      "    val_log_marginal: -12199.110215812232\n",
      "Train Epoch: 611 [256/118836 (0%)] Loss: 12334.273438\n",
      "Train Epoch: 611 [33024/118836 (28%)] Loss: 12227.140625\n",
      "Train Epoch: 611 [65792/118836 (55%)] Loss: 12248.209961\n",
      "Train Epoch: 611 [98560/118836 (83%)] Loss: 12367.690430\n",
      "    epoch          : 611\n",
      "    loss           : 12283.170793753876\n",
      "    val_loss       : 12285.337393802947\n",
      "    val_log_likelihood: -12190.718680210919\n",
      "    val_log_marginal: -12198.60297864705\n",
      "Train Epoch: 612 [256/118836 (0%)] Loss: 12214.849609\n",
      "Train Epoch: 612 [33024/118836 (28%)] Loss: 12403.883789\n",
      "Train Epoch: 612 [65792/118836 (55%)] Loss: 12302.640625\n",
      "Train Epoch: 612 [98560/118836 (83%)] Loss: 12269.222656\n",
      "    epoch          : 612\n",
      "    loss           : 12286.994473253979\n",
      "    val_loss       : 12291.931066784937\n",
      "    val_log_likelihood: -12190.916358270006\n",
      "    val_log_marginal: -12198.784011830085\n",
      "Train Epoch: 613 [256/118836 (0%)] Loss: 12343.123047\n",
      "Train Epoch: 613 [33024/118836 (28%)] Loss: 12324.111328\n",
      "Train Epoch: 613 [65792/118836 (55%)] Loss: 12359.967773\n",
      "Train Epoch: 613 [98560/118836 (83%)] Loss: 12363.000977\n",
      "    epoch          : 613\n",
      "    loss           : 12286.63748529906\n",
      "    val_loss       : 12287.377147864489\n",
      "    val_log_likelihood: -12194.115205134667\n",
      "    val_log_marginal: -12201.809503584682\n",
      "Train Epoch: 614 [256/118836 (0%)] Loss: 12309.609375\n",
      "Train Epoch: 614 [33024/118836 (28%)] Loss: 12302.088867\n",
      "Train Epoch: 614 [65792/118836 (55%)] Loss: 12305.074219\n",
      "Train Epoch: 614 [98560/118836 (83%)] Loss: 12332.763672\n",
      "    epoch          : 614\n",
      "    loss           : 12285.093552102719\n",
      "    val_loss       : 12283.966739316349\n",
      "    val_log_likelihood: -12193.006874224566\n",
      "    val_log_marginal: -12200.77484849266\n",
      "Train Epoch: 615 [256/118836 (0%)] Loss: 12322.233398\n",
      "Train Epoch: 615 [33024/118836 (28%)] Loss: 12332.517578\n",
      "Train Epoch: 615 [65792/118836 (55%)] Loss: 12251.487305\n",
      "Train Epoch: 615 [98560/118836 (83%)] Loss: 12322.013672\n",
      "    epoch          : 615\n",
      "    loss           : 12287.740719182952\n",
      "    val_loss       : 12286.39015809368\n",
      "    val_log_likelihood: -12193.144481977615\n",
      "    val_log_marginal: -12201.207649595199\n",
      "Train Epoch: 616 [256/118836 (0%)] Loss: 12253.103516\n",
      "Train Epoch: 616 [33024/118836 (28%)] Loss: 12326.871094\n",
      "Train Epoch: 616 [65792/118836 (55%)] Loss: 12296.746094\n",
      "Train Epoch: 616 [98560/118836 (83%)] Loss: 12323.619141\n",
      "    epoch          : 616\n",
      "    loss           : 12287.436440239866\n",
      "    val_loss       : 12281.814407620182\n",
      "    val_log_likelihood: -12192.404841456007\n",
      "    val_log_marginal: -12200.172783737118\n",
      "Train Epoch: 617 [256/118836 (0%)] Loss: 12406.007812\n",
      "Train Epoch: 617 [33024/118836 (28%)] Loss: 12306.062500\n",
      "Train Epoch: 617 [65792/118836 (55%)] Loss: 12279.027344\n",
      "Train Epoch: 617 [98560/118836 (83%)] Loss: 12274.351562\n",
      "    epoch          : 617\n",
      "    loss           : 12285.622598900176\n",
      "    val_loss       : 12287.851880337153\n",
      "    val_log_likelihood: -12193.836102764422\n",
      "    val_log_marginal: -12201.676560446456\n",
      "Train Epoch: 618 [256/118836 (0%)] Loss: 12288.896484\n",
      "Train Epoch: 618 [33024/118836 (28%)] Loss: 12313.347656\n",
      "Train Epoch: 618 [65792/118836 (55%)] Loss: 12392.679688\n",
      "Train Epoch: 618 [98560/118836 (83%)] Loss: 12341.028320\n",
      "    epoch          : 618\n",
      "    loss           : 12283.25327459419\n",
      "    val_loss       : 12287.954706561553\n",
      "    val_log_likelihood: -12191.498728610939\n",
      "    val_log_marginal: -12199.250578233054\n",
      "Train Epoch: 619 [256/118836 (0%)] Loss: 12296.184570\n",
      "Train Epoch: 619 [33024/118836 (28%)] Loss: 12212.671875\n",
      "Train Epoch: 619 [65792/118836 (55%)] Loss: 12381.488281\n",
      "Train Epoch: 619 [98560/118836 (83%)] Loss: 12203.765625\n",
      "    epoch          : 619\n",
      "    loss           : 12282.364272836538\n",
      "    val_loss       : 12284.66500137009\n",
      "    val_log_likelihood: -12189.794903619986\n",
      "    val_log_marginal: -12197.534180080878\n",
      "Train Epoch: 620 [256/118836 (0%)] Loss: 12413.024414\n",
      "Train Epoch: 620 [33024/118836 (28%)] Loss: 12334.467773\n",
      "Train Epoch: 620 [65792/118836 (55%)] Loss: 12308.748047\n",
      "Train Epoch: 620 [98560/118836 (83%)] Loss: 12357.917969\n",
      "    epoch          : 620\n",
      "    loss           : 12285.359370315085\n",
      "    val_loss       : 12285.220125604184\n",
      "    val_log_likelihood: -12193.098745735111\n",
      "    val_log_marginal: -12201.014668641377\n",
      "Train Epoch: 621 [256/118836 (0%)] Loss: 12336.952148\n",
      "Train Epoch: 621 [33024/118836 (28%)] Loss: 12343.509766\n",
      "Train Epoch: 621 [65792/118836 (55%)] Loss: 12377.947266\n",
      "Train Epoch: 621 [98560/118836 (83%)] Loss: 12254.950195\n",
      "    epoch          : 621\n",
      "    loss           : 12285.116160857371\n",
      "    val_loss       : 12283.802798616587\n",
      "    val_log_likelihood: -12190.628814328733\n",
      "    val_log_marginal: -12198.507283619336\n",
      "Train Epoch: 622 [256/118836 (0%)] Loss: 12330.357422\n",
      "Train Epoch: 622 [33024/118836 (28%)] Loss: 12309.205078\n",
      "Train Epoch: 622 [65792/118836 (55%)] Loss: 12253.873047\n",
      "Train Epoch: 622 [98560/118836 (83%)] Loss: 12251.976562\n",
      "    epoch          : 622\n",
      "    loss           : 12285.498951709833\n",
      "    val_loss       : 12287.933031872213\n",
      "    val_log_likelihood: -12191.540999793217\n",
      "    val_log_marginal: -12199.316640305606\n",
      "Train Epoch: 623 [256/118836 (0%)] Loss: 12438.458008\n",
      "Train Epoch: 623 [33024/118836 (28%)] Loss: 12298.386719\n",
      "Train Epoch: 623 [65792/118836 (55%)] Loss: 12266.281250\n",
      "Train Epoch: 623 [98560/118836 (83%)] Loss: 12279.869141\n",
      "    epoch          : 623\n",
      "    loss           : 12288.252541001086\n",
      "    val_loss       : 12286.693423704959\n",
      "    val_log_likelihood: -12194.38440327104\n",
      "    val_log_marginal: -12202.463921916707\n",
      "Train Epoch: 624 [256/118836 (0%)] Loss: 12275.708984\n",
      "Train Epoch: 624 [33024/118836 (28%)] Loss: 12301.496094\n",
      "Train Epoch: 624 [65792/118836 (55%)] Loss: 12221.289062\n",
      "Train Epoch: 624 [98560/118836 (83%)] Loss: 12246.730469\n",
      "    epoch          : 624\n",
      "    loss           : 12286.369956769542\n",
      "    val_loss       : 12282.00930933303\n",
      "    val_log_likelihood: -12189.821435910359\n",
      "    val_log_marginal: -12197.648374285649\n",
      "Train Epoch: 625 [256/118836 (0%)] Loss: 12318.427734\n",
      "Train Epoch: 625 [33024/118836 (28%)] Loss: 12305.269531\n",
      "Train Epoch: 625 [65792/118836 (55%)] Loss: 12307.782227\n",
      "Train Epoch: 625 [98560/118836 (83%)] Loss: 12364.287109\n",
      "    epoch          : 625\n",
      "    loss           : 12283.693990546164\n",
      "    val_loss       : 12287.26188299845\n",
      "    val_log_likelihood: -12192.196075818083\n",
      "    val_log_marginal: -12199.899904712005\n",
      "Train Epoch: 626 [256/118836 (0%)] Loss: 12292.975586\n",
      "Train Epoch: 626 [33024/118836 (28%)] Loss: 12254.650391\n",
      "Train Epoch: 626 [65792/118836 (55%)] Loss: 12396.594727\n",
      "Train Epoch: 626 [98560/118836 (83%)] Loss: 12335.477539\n",
      "    epoch          : 626\n",
      "    loss           : 12283.641182989557\n",
      "    val_loss       : 12282.143647891513\n",
      "    val_log_likelihood: -12193.701563307743\n",
      "    val_log_marginal: -12201.672017397696\n",
      "Train Epoch: 627 [256/118836 (0%)] Loss: 12256.430664\n",
      "Train Epoch: 627 [33024/118836 (28%)] Loss: 12253.464844\n",
      "Train Epoch: 627 [65792/118836 (55%)] Loss: 12227.983398\n",
      "Train Epoch: 627 [98560/118836 (83%)] Loss: 12292.810547\n",
      "    epoch          : 627\n",
      "    loss           : 12280.24637936828\n",
      "    val_loss       : 12288.52564736302\n",
      "    val_log_likelihood: -12194.335312306142\n",
      "    val_log_marginal: -12202.111184389094\n",
      "Train Epoch: 628 [256/118836 (0%)] Loss: 12198.737305\n",
      "Train Epoch: 628 [33024/118836 (28%)] Loss: 12321.257812\n",
      "Train Epoch: 628 [65792/118836 (55%)] Loss: 12224.428711\n",
      "Train Epoch: 628 [98560/118836 (83%)] Loss: 12249.833008\n",
      "    epoch          : 628\n",
      "    loss           : 12284.771701981235\n",
      "    val_loss       : 12282.379659170085\n",
      "    val_log_likelihood: -12190.796673548646\n",
      "    val_log_marginal: -12198.554734822166\n",
      "Train Epoch: 629 [256/118836 (0%)] Loss: 12306.156250\n",
      "Train Epoch: 629 [33024/118836 (28%)] Loss: 12327.492188\n",
      "Train Epoch: 629 [65792/118836 (55%)] Loss: 12292.819336\n",
      "Train Epoch: 629 [98560/118836 (83%)] Loss: 12257.101562\n",
      "    epoch          : 629\n",
      "    loss           : 12285.992270051438\n",
      "    val_loss       : 12280.612888377553\n",
      "    val_log_likelihood: -12192.027571372259\n",
      "    val_log_marginal: -12199.720648239263\n",
      "Train Epoch: 630 [256/118836 (0%)] Loss: 12330.615234\n",
      "Train Epoch: 630 [33024/118836 (28%)] Loss: 12350.338867\n",
      "Train Epoch: 630 [65792/118836 (55%)] Loss: 12293.208984\n",
      "Train Epoch: 630 [98560/118836 (83%)] Loss: 12222.308594\n",
      "    epoch          : 630\n",
      "    loss           : 12287.462111636683\n",
      "    val_loss       : 12282.393494375143\n",
      "    val_log_likelihood: -12190.446826212263\n",
      "    val_log_marginal: -12198.296866807372\n",
      "Train Epoch: 631 [256/118836 (0%)] Loss: 12306.947266\n",
      "Train Epoch: 631 [33024/118836 (28%)] Loss: 12215.509766\n",
      "Train Epoch: 631 [65792/118836 (55%)] Loss: 12368.014648\n",
      "Train Epoch: 631 [98560/118836 (83%)] Loss: 12368.709961\n",
      "    epoch          : 631\n",
      "    loss           : 12286.08789337133\n",
      "    val_loss       : 12288.809366537824\n",
      "    val_log_likelihood: -12192.976683338504\n",
      "    val_log_marginal: -12201.053945222036\n",
      "Train Epoch: 632 [256/118836 (0%)] Loss: 12333.462891\n",
      "Train Epoch: 632 [33024/118836 (28%)] Loss: 12304.234375\n",
      "Train Epoch: 632 [65792/118836 (55%)] Loss: 12299.720703\n",
      "Train Epoch: 632 [98560/118836 (83%)] Loss: 12295.275391\n",
      "    epoch          : 632\n",
      "    loss           : 12280.118112205335\n",
      "    val_loss       : 12283.963655891537\n",
      "    val_log_likelihood: -12193.766940814981\n",
      "    val_log_marginal: -12201.516406949815\n",
      "Train Epoch: 633 [256/118836 (0%)] Loss: 12341.146484\n",
      "Train Epoch: 633 [33024/118836 (28%)] Loss: 12295.230469\n",
      "Train Epoch: 633 [65792/118836 (55%)] Loss: 12314.062500\n",
      "Train Epoch: 633 [98560/118836 (83%)] Loss: 12460.289062\n",
      "    epoch          : 633\n",
      "    loss           : 12282.540998662374\n",
      "    val_loss       : 12283.038190840241\n",
      "    val_log_likelihood: -12188.598548322478\n",
      "    val_log_marginal: -12196.522794346234\n",
      "Train Epoch: 634 [256/118836 (0%)] Loss: 12404.696289\n",
      "Train Epoch: 634 [33024/118836 (28%)] Loss: 12363.628906\n",
      "Train Epoch: 634 [65792/118836 (55%)] Loss: 12306.580078\n",
      "Train Epoch: 634 [98560/118836 (83%)] Loss: 12387.928711\n",
      "    epoch          : 634\n",
      "    loss           : 12282.944649180623\n",
      "    val_loss       : 12287.552024651068\n",
      "    val_log_likelihood: -12192.943064063791\n",
      "    val_log_marginal: -12200.775603512137\n",
      "Train Epoch: 635 [256/118836 (0%)] Loss: 12346.522461\n",
      "Train Epoch: 635 [33024/118836 (28%)] Loss: 12293.155273\n",
      "Train Epoch: 635 [65792/118836 (55%)] Loss: 12306.236328\n",
      "Train Epoch: 635 [98560/118836 (83%)] Loss: 12260.808594\n",
      "    epoch          : 635\n",
      "    loss           : 12285.074959935897\n",
      "    val_loss       : 12283.549530435972\n",
      "    val_log_likelihood: -12192.50118641439\n",
      "    val_log_marginal: -12200.220902839865\n",
      "Train Epoch: 636 [256/118836 (0%)] Loss: 12308.443359\n",
      "Train Epoch: 636 [33024/118836 (28%)] Loss: 12363.855469\n",
      "Train Epoch: 636 [65792/118836 (55%)] Loss: 12273.929688\n",
      "Train Epoch: 636 [98560/118836 (83%)] Loss: 12297.917969\n",
      "    epoch          : 636\n",
      "    loss           : 12284.113996264992\n",
      "    val_loss       : 12297.881273478406\n",
      "    val_log_likelihood: -12200.061509382755\n",
      "    val_log_marginal: -12208.056024821864\n",
      "Train Epoch: 637 [256/118836 (0%)] Loss: 12333.348633\n",
      "Train Epoch: 637 [33024/118836 (28%)] Loss: 12357.841797\n",
      "Train Epoch: 637 [65792/118836 (55%)] Loss: 12308.195312\n",
      "Train Epoch: 637 [98560/118836 (83%)] Loss: 12255.577148\n",
      "    epoch          : 637\n",
      "    loss           : 12287.126592548077\n",
      "    val_loss       : 12283.117258081158\n",
      "    val_log_likelihood: -12194.333990352307\n",
      "    val_log_marginal: -12202.044270973338\n",
      "Train Epoch: 638 [256/118836 (0%)] Loss: 12282.902344\n",
      "Train Epoch: 638 [33024/118836 (28%)] Loss: 12371.744141\n",
      "Train Epoch: 638 [65792/118836 (55%)] Loss: 12279.351562\n",
      "Train Epoch: 638 [98560/118836 (83%)] Loss: 12304.364258\n",
      "    epoch          : 638\n",
      "    loss           : 12288.002646007806\n",
      "    val_loss       : 12286.110887988913\n",
      "    val_log_likelihood: -12190.651042797508\n",
      "    val_log_marginal: -12198.65451347736\n",
      "Train Epoch: 639 [256/118836 (0%)] Loss: 12377.116211\n",
      "Train Epoch: 639 [33024/118836 (28%)] Loss: 12272.130859\n",
      "Train Epoch: 639 [65792/118836 (55%)] Loss: 12250.834961\n",
      "Train Epoch: 639 [98560/118836 (83%)] Loss: 12291.350586\n",
      "    epoch          : 639\n",
      "    loss           : 12286.349796448512\n",
      "    val_loss       : 12282.912857642992\n",
      "    val_log_likelihood: -12193.237864615645\n",
      "    val_log_marginal: -12200.969818880876\n",
      "Train Epoch: 640 [256/118836 (0%)] Loss: 12292.534180\n",
      "Train Epoch: 640 [33024/118836 (28%)] Loss: 12266.393555\n",
      "Train Epoch: 640 [65792/118836 (55%)] Loss: 12344.638672\n",
      "Train Epoch: 640 [98560/118836 (83%)] Loss: 12216.992188\n",
      "    epoch          : 640\n",
      "    loss           : 12288.178181218982\n",
      "    val_loss       : 12283.443432522132\n",
      "    val_log_likelihood: -12190.234319265663\n",
      "    val_log_marginal: -12198.109535243657\n",
      "Train Epoch: 641 [256/118836 (0%)] Loss: 12213.085938\n",
      "Train Epoch: 641 [33024/118836 (28%)] Loss: 12304.900391\n",
      "Train Epoch: 641 [65792/118836 (55%)] Loss: 12217.190430\n",
      "Train Epoch: 641 [98560/118836 (83%)] Loss: 12355.259766\n",
      "    epoch          : 641\n",
      "    loss           : 12287.205712204042\n",
      "    val_loss       : 12285.409273764908\n",
      "    val_log_likelihood: -12193.37058325579\n",
      "    val_log_marginal: -12201.122906015527\n",
      "Train Epoch: 642 [256/118836 (0%)] Loss: 12283.739258\n",
      "Train Epoch: 642 [33024/118836 (28%)] Loss: 12268.126953\n",
      "Train Epoch: 642 [65792/118836 (55%)] Loss: 12255.684570\n",
      "Train Epoch: 642 [98560/118836 (83%)] Loss: 12312.110352\n",
      "    epoch          : 642\n",
      "    loss           : 12285.353061188225\n",
      "    val_loss       : 12285.047830640073\n",
      "    val_log_likelihood: -12191.274934411187\n",
      "    val_log_marginal: -12199.003475950318\n",
      "Train Epoch: 643 [256/118836 (0%)] Loss: 12270.059570\n",
      "Train Epoch: 643 [33024/118836 (28%)] Loss: 12268.709961\n",
      "Train Epoch: 643 [65792/118836 (55%)] Loss: 12365.263672\n",
      "Train Epoch: 643 [98560/118836 (83%)] Loss: 12392.277344\n",
      "    epoch          : 643\n",
      "    loss           : 12282.157050797405\n",
      "    val_loss       : 12283.01963403627\n",
      "    val_log_likelihood: -12190.784034616676\n",
      "    val_log_marginal: -12198.534127393335\n",
      "Train Epoch: 644 [256/118836 (0%)] Loss: 12231.855469\n",
      "Train Epoch: 644 [33024/118836 (28%)] Loss: 12285.566406\n",
      "Train Epoch: 644 [65792/118836 (55%)] Loss: 12324.966797\n",
      "Train Epoch: 644 [98560/118836 (83%)] Loss: 12281.514648\n",
      "    epoch          : 644\n",
      "    loss           : 12286.128243092173\n",
      "    val_loss       : 12285.276266966512\n",
      "    val_log_likelihood: -12188.343496529933\n",
      "    val_log_marginal: -12196.289571522013\n",
      "Train Epoch: 645 [256/118836 (0%)] Loss: 12299.859375\n",
      "Train Epoch: 645 [33024/118836 (28%)] Loss: 12348.556641\n",
      "Train Epoch: 645 [65792/118836 (55%)] Loss: 12209.788086\n",
      "Train Epoch: 645 [98560/118836 (83%)] Loss: 12284.882812\n",
      "    epoch          : 645\n",
      "    loss           : 12285.238755718827\n",
      "    val_loss       : 12284.965423491007\n",
      "    val_log_likelihood: -12193.917025143455\n",
      "    val_log_marginal: -12201.883136734652\n",
      "Train Epoch: 646 [256/118836 (0%)] Loss: 12335.583008\n",
      "Train Epoch: 646 [33024/118836 (28%)] Loss: 12357.140625\n",
      "Train Epoch: 646 [65792/118836 (55%)] Loss: 12343.722656\n",
      "Train Epoch: 646 [98560/118836 (83%)] Loss: 12305.355469\n",
      "    epoch          : 646\n",
      "    loss           : 12288.096998584833\n",
      "    val_loss       : 12285.689237505234\n",
      "    val_log_likelihood: -12191.41521434295\n",
      "    val_log_marginal: -12199.257443850833\n",
      "Train Epoch: 647 [256/118836 (0%)] Loss: 12264.640625\n",
      "Train Epoch: 647 [33024/118836 (28%)] Loss: 12233.029297\n",
      "Train Epoch: 647 [65792/118836 (55%)] Loss: 12176.848633\n",
      "Train Epoch: 647 [98560/118836 (83%)] Loss: 12325.091797\n",
      "    epoch          : 647\n",
      "    loss           : 12282.441292842743\n",
      "    val_loss       : 12278.979035532555\n",
      "    val_log_likelihood: -12191.028058441894\n",
      "    val_log_marginal: -12198.835389573878\n",
      "Train Epoch: 648 [256/118836 (0%)] Loss: 12244.747070\n",
      "Train Epoch: 648 [33024/118836 (28%)] Loss: 12330.514648\n",
      "Train Epoch: 648 [65792/118836 (55%)] Loss: 12358.404297\n",
      "Train Epoch: 648 [98560/118836 (83%)] Loss: 12226.275391\n",
      "    epoch          : 648\n",
      "    loss           : 12286.981800558311\n",
      "    val_loss       : 12287.144846885003\n",
      "    val_log_likelihood: -12194.837987877378\n",
      "    val_log_marginal: -12202.704632637722\n",
      "Train Epoch: 649 [256/118836 (0%)] Loss: 12331.650391\n",
      "Train Epoch: 649 [33024/118836 (28%)] Loss: 12338.421875\n",
      "Train Epoch: 649 [65792/118836 (55%)] Loss: 12278.144531\n",
      "Train Epoch: 649 [98560/118836 (83%)] Loss: 12223.215820\n",
      "    epoch          : 649\n",
      "    loss           : 12283.426946016854\n",
      "    val_loss       : 12287.372812886266\n",
      "    val_log_likelihood: -12189.87851966372\n",
      "    val_log_marginal: -12197.791030180599\n",
      "Train Epoch: 650 [256/118836 (0%)] Loss: 12377.086914\n",
      "Train Epoch: 650 [33024/118836 (28%)] Loss: 12318.433594\n",
      "Train Epoch: 650 [65792/118836 (55%)] Loss: 12302.595703\n",
      "Train Epoch: 650 [98560/118836 (83%)] Loss: 12232.765625\n",
      "    epoch          : 650\n",
      "    loss           : 12287.853260377895\n",
      "    val_loss       : 12283.785200214917\n",
      "    val_log_likelihood: -12190.970370819117\n",
      "    val_log_marginal: -12198.837027854424\n",
      "Train Epoch: 651 [256/118836 (0%)] Loss: 12312.893555\n",
      "Train Epoch: 651 [33024/118836 (28%)] Loss: 12399.564453\n",
      "Train Epoch: 651 [65792/118836 (55%)] Loss: 12370.082031\n",
      "Train Epoch: 651 [98560/118836 (83%)] Loss: 12276.423828\n",
      "    epoch          : 651\n",
      "    loss           : 12283.858643830128\n",
      "    val_loss       : 12284.880680210308\n",
      "    val_log_likelihood: -12196.278740824027\n",
      "    val_log_marginal: -12204.152401533296\n",
      "Train Epoch: 652 [256/118836 (0%)] Loss: 12293.368164\n",
      "Train Epoch: 652 [33024/118836 (28%)] Loss: 12291.312500\n",
      "Train Epoch: 652 [65792/118836 (55%)] Loss: 12378.573242\n",
      "Train Epoch: 652 [98560/118836 (83%)] Loss: 12298.708984\n",
      "    epoch          : 652\n",
      "    loss           : 12288.798019896349\n",
      "    val_loss       : 12290.214461026775\n",
      "    val_log_likelihood: -12195.09127959574\n",
      "    val_log_marginal: -12202.94849976291\n",
      "Train Epoch: 653 [256/118836 (0%)] Loss: 12352.312500\n",
      "Train Epoch: 653 [33024/118836 (28%)] Loss: 12360.324219\n",
      "Train Epoch: 653 [65792/118836 (55%)] Loss: 12255.605469\n",
      "Train Epoch: 653 [98560/118836 (83%)] Loss: 12286.526367\n",
      "    epoch          : 653\n",
      "    loss           : 12286.223750743124\n",
      "    val_loss       : 12287.593237587864\n",
      "    val_log_likelihood: -12192.483465318704\n",
      "    val_log_marginal: -12200.367963201481\n",
      "Train Epoch: 654 [256/118836 (0%)] Loss: 12222.421875\n",
      "Train Epoch: 654 [33024/118836 (28%)] Loss: 12260.169922\n",
      "Train Epoch: 654 [65792/118836 (55%)] Loss: 12408.592773\n",
      "Train Epoch: 654 [98560/118836 (83%)] Loss: 12305.172852\n",
      "    epoch          : 654\n",
      "    loss           : 12285.560600186103\n",
      "    val_loss       : 12285.259147094666\n",
      "    val_log_likelihood: -12194.31473195823\n",
      "    val_log_marginal: -12202.583879010164\n",
      "Train Epoch: 655 [256/118836 (0%)] Loss: 12423.458008\n",
      "Train Epoch: 655 [33024/118836 (28%)] Loss: 12417.656250\n",
      "Train Epoch: 655 [65792/118836 (55%)] Loss: 12275.010742\n",
      "Train Epoch: 655 [98560/118836 (83%)] Loss: 12270.171875\n",
      "    epoch          : 655\n",
      "    loss           : 12288.839796416201\n",
      "    val_loss       : 12281.39435324671\n",
      "    val_log_likelihood: -12191.163495948356\n",
      "    val_log_marginal: -12198.852533803081\n",
      "Train Epoch: 656 [256/118836 (0%)] Loss: 12281.791016\n",
      "Train Epoch: 656 [33024/118836 (28%)] Loss: 12268.144531\n",
      "Train Epoch: 656 [65792/118836 (55%)] Loss: 12295.724609\n",
      "Train Epoch: 656 [98560/118836 (83%)] Loss: 12418.592773\n",
      "    epoch          : 656\n",
      "    loss           : 12287.581510739763\n",
      "    val_loss       : 12283.681195290093\n",
      "    val_log_likelihood: -12190.26121229451\n",
      "    val_log_marginal: -12198.127057443591\n",
      "Train Epoch: 657 [256/118836 (0%)] Loss: 12296.945312\n",
      "Train Epoch: 657 [33024/118836 (28%)] Loss: 12231.762695\n",
      "Train Epoch: 657 [65792/118836 (55%)] Loss: 12232.295898\n",
      "Train Epoch: 657 [98560/118836 (83%)] Loss: 12335.789062\n",
      "    epoch          : 657\n",
      "    loss           : 12283.345811685793\n",
      "    val_loss       : 12282.00351108726\n",
      "    val_log_likelihood: -12189.713354270058\n",
      "    val_log_marginal: -12197.407087557529\n",
      "Train Epoch: 658 [256/118836 (0%)] Loss: 12183.382812\n",
      "Train Epoch: 658 [33024/118836 (28%)] Loss: 12213.060547\n",
      "Train Epoch: 658 [65792/118836 (55%)] Loss: 12294.339844\n",
      "Train Epoch: 658 [98560/118836 (83%)] Loss: 12341.949219\n",
      "    epoch          : 658\n",
      "    loss           : 12283.527495282775\n",
      "    val_loss       : 12283.600830940753\n",
      "    val_log_likelihood: -12190.741996710865\n",
      "    val_log_marginal: -12198.437157679411\n",
      "Train Epoch: 659 [256/118836 (0%)] Loss: 12234.318359\n",
      "Train Epoch: 659 [33024/118836 (28%)] Loss: 12224.716797\n",
      "Train Epoch: 659 [65792/118836 (55%)] Loss: 12396.825195\n",
      "Train Epoch: 659 [98560/118836 (83%)] Loss: 12292.068359\n",
      "    epoch          : 659\n",
      "    loss           : 12284.572110215055\n",
      "    val_loss       : 12282.26068934567\n",
      "    val_log_likelihood: -12191.293242736765\n",
      "    val_log_marginal: -12198.925929372532\n",
      "Train Epoch: 660 [256/118836 (0%)] Loss: 12309.234375\n",
      "Train Epoch: 660 [33024/118836 (28%)] Loss: 12393.770508\n",
      "Train Epoch: 660 [65792/118836 (55%)] Loss: 12444.961914\n",
      "Train Epoch: 660 [98560/118836 (83%)] Loss: 12235.243164\n",
      "    epoch          : 660\n",
      "    loss           : 12285.198049944427\n",
      "    val_loss       : 12286.506375794934\n",
      "    val_log_likelihood: -12192.931436265766\n",
      "    val_log_marginal: -12200.60740359551\n",
      "Train Epoch: 661 [256/118836 (0%)] Loss: 12205.226562\n",
      "Train Epoch: 661 [33024/118836 (28%)] Loss: 12236.121094\n",
      "Train Epoch: 661 [65792/118836 (55%)] Loss: 12288.089844\n",
      "Train Epoch: 661 [98560/118836 (83%)] Loss: 12287.552734\n",
      "    epoch          : 661\n",
      "    loss           : 12279.708104095585\n",
      "    val_loss       : 12286.233229640064\n",
      "    val_log_likelihood: -12194.218171978391\n",
      "    val_log_marginal: -12202.021019763562\n",
      "Train Epoch: 662 [256/118836 (0%)] Loss: 12423.757812\n",
      "Train Epoch: 662 [33024/118836 (28%)] Loss: 12323.970703\n",
      "Train Epoch: 662 [65792/118836 (55%)] Loss: 12243.841797\n",
      "Train Epoch: 662 [98560/118836 (83%)] Loss: 12353.049805\n",
      "    epoch          : 662\n",
      "    loss           : 12281.762635216346\n",
      "    val_loss       : 12282.94926703283\n",
      "    val_log_likelihood: -12193.257582292958\n",
      "    val_log_marginal: -12201.066228135543\n",
      "Train Epoch: 663 [256/118836 (0%)] Loss: 12313.999023\n",
      "Train Epoch: 663 [33024/118836 (28%)] Loss: 12325.445312\n",
      "Train Epoch: 663 [65792/118836 (55%)] Loss: 12273.135742\n",
      "Train Epoch: 663 [98560/118836 (83%)] Loss: 12273.700195\n",
      "    epoch          : 663\n",
      "    loss           : 12284.484221851737\n",
      "    val_loss       : 12284.731802502958\n",
      "    val_log_likelihood: -12193.563014856027\n",
      "    val_log_marginal: -12201.219195336598\n",
      "Train Epoch: 664 [256/118836 (0%)] Loss: 12254.294922\n",
      "Train Epoch: 664 [33024/118836 (28%)] Loss: 12324.891602\n",
      "Train Epoch: 664 [65792/118836 (55%)] Loss: 12327.852539\n",
      "Train Epoch: 664 [98560/118836 (83%)] Loss: 12334.068359\n",
      "    epoch          : 664\n",
      "    loss           : 12285.79908805702\n",
      "    val_loss       : 12285.560507010754\n",
      "    val_log_likelihood: -12195.26223328293\n",
      "    val_log_marginal: -12203.14125944013\n",
      "Train Epoch: 665 [256/118836 (0%)] Loss: 12376.352539\n",
      "Train Epoch: 665 [33024/118836 (28%)] Loss: 12340.730469\n",
      "Train Epoch: 665 [65792/118836 (55%)] Loss: 12228.737305\n",
      "Train Epoch: 665 [98560/118836 (83%)] Loss: 12373.792969\n",
      "    epoch          : 665\n",
      "    loss           : 12286.197769334161\n",
      "    val_loss       : 12284.460594656475\n",
      "    val_log_likelihood: -12195.810979018042\n",
      "    val_log_marginal: -12203.605116531056\n",
      "Train Epoch: 666 [256/118836 (0%)] Loss: 12349.925781\n",
      "Train Epoch: 666 [33024/118836 (28%)] Loss: 12284.517578\n",
      "Train Epoch: 666 [65792/118836 (55%)] Loss: 12293.195312\n",
      "Train Epoch: 666 [98560/118836 (83%)] Loss: 12285.758789\n",
      "    epoch          : 666\n",
      "    loss           : 12286.366006739816\n",
      "    val_loss       : 12286.24850133134\n",
      "    val_log_likelihood: -12191.314170737696\n",
      "    val_log_marginal: -12199.08397465626\n",
      "Train Epoch: 667 [256/118836 (0%)] Loss: 12386.115234\n",
      "Train Epoch: 667 [33024/118836 (28%)] Loss: 12441.317383\n",
      "Train Epoch: 667 [65792/118836 (55%)] Loss: 12337.394531\n",
      "Train Epoch: 667 [98560/118836 (83%)] Loss: 12323.942383\n",
      "    epoch          : 667\n",
      "    loss           : 12278.8784616677\n",
      "    val_loss       : 12287.004416900834\n",
      "    val_log_likelihood: -12194.04928320797\n",
      "    val_log_marginal: -12202.124104981958\n",
      "Train Epoch: 668 [256/118836 (0%)] Loss: 12303.306641\n",
      "Train Epoch: 668 [33024/118836 (28%)] Loss: 12352.657227\n",
      "Train Epoch: 668 [65792/118836 (55%)] Loss: 12281.304688\n",
      "Train Epoch: 668 [98560/118836 (83%)] Loss: 12343.870117\n",
      "    epoch          : 668\n",
      "    loss           : 12281.545523159637\n",
      "    val_loss       : 12284.09077399406\n",
      "    val_log_likelihood: -12192.847242846618\n",
      "    val_log_marginal: -12200.509509009213\n",
      "Train Epoch: 669 [256/118836 (0%)] Loss: 12281.916016\n",
      "Train Epoch: 669 [33024/118836 (28%)] Loss: 12228.588867\n",
      "Train Epoch: 669 [65792/118836 (55%)] Loss: 12358.058594\n",
      "Train Epoch: 669 [98560/118836 (83%)] Loss: 12333.912109\n",
      "    epoch          : 669\n",
      "    loss           : 12284.56308060639\n",
      "    val_loss       : 12288.74454883788\n",
      "    val_log_likelihood: -12191.361405183778\n",
      "    val_log_marginal: -12199.405536862201\n",
      "Train Epoch: 670 [256/118836 (0%)] Loss: 12272.272461\n",
      "Train Epoch: 670 [33024/118836 (28%)] Loss: 12295.986328\n",
      "Train Epoch: 670 [65792/118836 (55%)] Loss: 12361.494141\n",
      "Train Epoch: 670 [98560/118836 (83%)] Loss: 12354.835938\n",
      "    epoch          : 670\n",
      "    loss           : 12287.370887613732\n",
      "    val_loss       : 12283.845817301972\n",
      "    val_log_likelihood: -12190.487402262976\n",
      "    val_log_marginal: -12198.187418213485\n",
      "Train Epoch: 671 [256/118836 (0%)] Loss: 12226.412109\n",
      "Train Epoch: 671 [33024/118836 (28%)] Loss: 12263.628906\n",
      "Train Epoch: 671 [65792/118836 (55%)] Loss: 12240.242188\n",
      "Train Epoch: 671 [98560/118836 (83%)] Loss: 12248.041016\n",
      "    epoch          : 671\n",
      "    loss           : 12282.197462552987\n",
      "    val_loss       : 12285.947984186512\n",
      "    val_log_likelihood: -12189.606306218982\n",
      "    val_log_marginal: -12197.506796364274\n",
      "Train Epoch: 672 [256/118836 (0%)] Loss: 12286.474609\n",
      "Train Epoch: 672 [33024/118836 (28%)] Loss: 12325.763672\n",
      "Train Epoch: 672 [65792/118836 (55%)] Loss: 12334.424805\n",
      "Train Epoch: 672 [98560/118836 (83%)] Loss: 12332.201172\n",
      "    epoch          : 672\n",
      "    loss           : 12286.129006894902\n",
      "    val_loss       : 12287.086570633895\n",
      "    val_log_likelihood: -12191.002617898315\n",
      "    val_log_marginal: -12198.922345743957\n",
      "Train Epoch: 673 [256/118836 (0%)] Loss: 12292.661133\n",
      "Train Epoch: 673 [33024/118836 (28%)] Loss: 12306.235352\n",
      "Train Epoch: 673 [65792/118836 (55%)] Loss: 12285.619141\n",
      "Train Epoch: 673 [98560/118836 (83%)] Loss: 12308.279297\n",
      "    epoch          : 673\n",
      "    loss           : 12283.84037443781\n",
      "    val_loss       : 12283.496806524907\n",
      "    val_log_likelihood: -12194.870635436053\n",
      "    val_log_marginal: -12202.704290867423\n",
      "Train Epoch: 674 [256/118836 (0%)] Loss: 12276.819336\n",
      "Train Epoch: 674 [33024/118836 (28%)] Loss: 12162.436523\n",
      "Train Epoch: 674 [65792/118836 (55%)] Loss: 12328.716797\n",
      "Train Epoch: 674 [98560/118836 (83%)] Loss: 12366.616211\n",
      "    epoch          : 674\n",
      "    loss           : 12285.56260500672\n",
      "    val_loss       : 12283.756381208983\n",
      "    val_log_likelihood: -12193.744777773469\n",
      "    val_log_marginal: -12201.474176436754\n",
      "Train Epoch: 675 [256/118836 (0%)] Loss: 12317.513672\n",
      "Train Epoch: 675 [33024/118836 (28%)] Loss: 12409.497070\n",
      "Train Epoch: 675 [65792/118836 (55%)] Loss: 12256.470703\n",
      "Train Epoch: 675 [98560/118836 (83%)] Loss: 12333.884766\n",
      "    epoch          : 675\n",
      "    loss           : 12288.08937364299\n",
      "    val_loss       : 12285.728460229015\n",
      "    val_log_likelihood: -12190.805017544199\n",
      "    val_log_marginal: -12198.609128428428\n",
      "Train Epoch: 676 [256/118836 (0%)] Loss: 12376.013672\n",
      "Train Epoch: 676 [33024/118836 (28%)] Loss: 12342.783203\n",
      "Train Epoch: 676 [65792/118836 (55%)] Loss: 12293.220703\n",
      "Train Epoch: 676 [98560/118836 (83%)] Loss: 12212.347656\n",
      "    epoch          : 676\n",
      "    loss           : 12284.980035960762\n",
      "    val_loss       : 12285.312584485533\n",
      "    val_log_likelihood: -12192.133393429489\n",
      "    val_log_marginal: -12199.922132813112\n",
      "Train Epoch: 677 [256/118836 (0%)] Loss: 12300.976562\n",
      "Train Epoch: 677 [33024/118836 (28%)] Loss: 12290.530273\n",
      "Train Epoch: 677 [65792/118836 (55%)] Loss: 12391.477539\n",
      "Train Epoch: 677 [98560/118836 (83%)] Loss: 12271.439453\n",
      "    epoch          : 677\n",
      "    loss           : 12283.545961603082\n",
      "    val_loss       : 12283.30232762269\n",
      "    val_log_likelihood: -12194.687201457817\n",
      "    val_log_marginal: -12202.497383175709\n",
      "Train Epoch: 678 [256/118836 (0%)] Loss: 12301.398438\n",
      "Train Epoch: 678 [33024/118836 (28%)] Loss: 12329.203125\n",
      "Train Epoch: 678 [65792/118836 (55%)] Loss: 12290.445312\n",
      "Train Epoch: 678 [98560/118836 (83%)] Loss: 12263.828125\n",
      "    epoch          : 678\n",
      "    loss           : 12290.080710265456\n",
      "    val_loss       : 12282.740298530212\n",
      "    val_log_likelihood: -12191.105372305366\n",
      "    val_log_marginal: -12198.982024712584\n",
      "Train Epoch: 679 [256/118836 (0%)] Loss: 12196.503906\n",
      "Train Epoch: 679 [33024/118836 (28%)] Loss: 12375.125000\n",
      "Train Epoch: 679 [65792/118836 (55%)] Loss: 12285.491211\n",
      "Train Epoch: 679 [98560/118836 (83%)] Loss: 12298.593750\n",
      "    epoch          : 679\n",
      "    loss           : 12280.222488400797\n",
      "    val_loss       : 12286.39661631046\n",
      "    val_log_likelihood: -12190.810295828163\n",
      "    val_log_marginal: -12198.526282730763\n",
      "Train Epoch: 680 [256/118836 (0%)] Loss: 12275.580078\n",
      "Train Epoch: 680 [33024/118836 (28%)] Loss: 12335.135742\n",
      "Train Epoch: 680 [65792/118836 (55%)] Loss: 12344.002930\n",
      "Train Epoch: 680 [98560/118836 (83%)] Loss: 12336.412109\n",
      "    epoch          : 680\n",
      "    loss           : 12286.53817188146\n",
      "    val_loss       : 12285.193038945243\n",
      "    val_log_likelihood: -12198.283290361353\n",
      "    val_log_marginal: -12206.018306844633\n",
      "Train Epoch: 681 [256/118836 (0%)] Loss: 12324.171875\n",
      "Train Epoch: 681 [33024/118836 (28%)] Loss: 12380.065430\n",
      "Train Epoch: 681 [65792/118836 (55%)] Loss: 12367.416016\n",
      "Train Epoch: 681 [98560/118836 (83%)] Loss: 12294.974609\n",
      "    epoch          : 681\n",
      "    loss           : 12286.003442120296\n",
      "    val_loss       : 12287.317341277087\n",
      "    val_log_likelihood: -12193.1477035838\n",
      "    val_log_marginal: -12201.059909371827\n",
      "Train Epoch: 682 [256/118836 (0%)] Loss: 12246.689453\n",
      "Train Epoch: 682 [33024/118836 (28%)] Loss: 12328.312500\n",
      "Train Epoch: 682 [65792/118836 (55%)] Loss: 12370.068359\n",
      "Train Epoch: 682 [98560/118836 (83%)] Loss: 12209.145508\n",
      "    epoch          : 682\n",
      "    loss           : 12284.483428647125\n",
      "    val_loss       : 12282.529952571085\n",
      "    val_log_likelihood: -12193.325022778381\n",
      "    val_log_marginal: -12201.011203221819\n",
      "Train Epoch: 683 [256/118836 (0%)] Loss: 12286.041992\n",
      "Train Epoch: 683 [33024/118836 (28%)] Loss: 12400.796875\n",
      "Train Epoch: 683 [65792/118836 (55%)] Loss: 12250.001953\n",
      "Train Epoch: 683 [98560/118836 (83%)] Loss: 12269.360352\n",
      "    epoch          : 683\n",
      "    loss           : 12284.917810270626\n",
      "    val_loss       : 12283.674719652881\n",
      "    val_log_likelihood: -12191.404940808521\n",
      "    val_log_marginal: -12199.162451449192\n",
      "Train Epoch: 684 [256/118836 (0%)] Loss: 12244.681641\n",
      "Train Epoch: 684 [33024/118836 (28%)] Loss: 12427.979492\n",
      "Train Epoch: 684 [65792/118836 (55%)] Loss: 12290.930664\n",
      "Train Epoch: 684 [98560/118836 (83%)] Loss: 12263.856445\n",
      "    epoch          : 684\n",
      "    loss           : 12281.427283330748\n",
      "    val_loss       : 12283.278359197073\n",
      "    val_log_likelihood: -12193.584033001189\n",
      "    val_log_marginal: -12201.39424682273\n",
      "Train Epoch: 685 [256/118836 (0%)] Loss: 12348.082031\n",
      "Train Epoch: 685 [33024/118836 (28%)] Loss: 12258.294922\n",
      "Train Epoch: 685 [65792/118836 (55%)] Loss: 12306.645508\n",
      "Train Epoch: 685 [98560/118836 (83%)] Loss: 12296.441406\n",
      "    epoch          : 685\n",
      "    loss           : 12286.981560173697\n",
      "    val_loss       : 12280.1689222051\n",
      "    val_log_likelihood: -12189.777152799319\n",
      "    val_log_marginal: -12197.579544966868\n",
      "Train Epoch: 686 [256/118836 (0%)] Loss: 12295.622070\n",
      "Train Epoch: 686 [33024/118836 (28%)] Loss: 12277.204102\n",
      "Train Epoch: 686 [65792/118836 (55%)] Loss: 12352.678711\n",
      "Train Epoch: 686 [98560/118836 (83%)] Loss: 12220.279297\n",
      "    epoch          : 686\n",
      "    loss           : 12285.856355491367\n",
      "    val_loss       : 12284.343286409165\n",
      "    val_log_likelihood: -12187.827445848843\n",
      "    val_log_marginal: -12195.556572491223\n",
      "Train Epoch: 687 [256/118836 (0%)] Loss: 12306.677734\n",
      "Train Epoch: 687 [33024/118836 (28%)] Loss: 12320.810547\n",
      "Train Epoch: 687 [65792/118836 (55%)] Loss: 12295.983398\n",
      "Train Epoch: 687 [98560/118836 (83%)] Loss: 12221.516602\n",
      "    epoch          : 687\n",
      "    loss           : 12287.086425862024\n",
      "    val_loss       : 12288.622238478587\n",
      "    val_log_likelihood: -12190.268165193342\n",
      "    val_log_marginal: -12198.183956324603\n",
      "Train Epoch: 688 [256/118836 (0%)] Loss: 12305.742188\n",
      "Train Epoch: 688 [33024/118836 (28%)] Loss: 12298.625000\n",
      "Train Epoch: 688 [65792/118836 (55%)] Loss: 12313.431641\n",
      "Train Epoch: 688 [98560/118836 (83%)] Loss: 12358.742188\n",
      "    epoch          : 688\n",
      "    loss           : 12280.374739421784\n",
      "    val_loss       : 12282.83762261077\n",
      "    val_log_likelihood: -12191.580531269386\n",
      "    val_log_marginal: -12199.329513638164\n",
      "Train Epoch: 689 [256/118836 (0%)] Loss: 12375.370117\n",
      "Train Epoch: 689 [33024/118836 (28%)] Loss: 12291.816406\n",
      "Train Epoch: 689 [65792/118836 (55%)] Loss: 12268.336914\n",
      "Train Epoch: 689 [98560/118836 (83%)] Loss: 12272.287109\n",
      "    epoch          : 689\n",
      "    loss           : 12285.312214866366\n",
      "    val_loss       : 12285.762279037825\n",
      "    val_log_likelihood: -12191.344645465002\n",
      "    val_log_marginal: -12199.219268268973\n",
      "Train Epoch: 690 [256/118836 (0%)] Loss: 12386.285156\n",
      "Train Epoch: 690 [33024/118836 (28%)] Loss: 12267.945312\n",
      "Train Epoch: 690 [65792/118836 (55%)] Loss: 12370.713867\n",
      "Train Epoch: 690 [98560/118836 (83%)] Loss: 12373.679688\n",
      "    epoch          : 690\n",
      "    loss           : 12291.145596018145\n",
      "    val_loss       : 12280.220964143266\n",
      "    val_log_likelihood: -12191.86360450915\n",
      "    val_log_marginal: -12199.637963847923\n",
      "Train Epoch: 691 [256/118836 (0%)] Loss: 12315.097656\n",
      "Train Epoch: 691 [33024/118836 (28%)] Loss: 12336.356445\n",
      "Train Epoch: 691 [65792/118836 (55%)] Loss: 12203.087891\n",
      "Train Epoch: 691 [98560/118836 (83%)] Loss: 12366.437500\n",
      "    epoch          : 691\n",
      "    loss           : 12285.380545001035\n",
      "    val_loss       : 12283.761258695455\n",
      "    val_log_likelihood: -12190.958699726012\n",
      "    val_log_marginal: -12198.737757329072\n",
      "Train Epoch: 692 [256/118836 (0%)] Loss: 12278.187500\n",
      "Train Epoch: 692 [33024/118836 (28%)] Loss: 12248.078125\n",
      "Train Epoch: 692 [65792/118836 (55%)] Loss: 12296.217773\n",
      "Train Epoch: 692 [98560/118836 (83%)] Loss: 12309.394531\n",
      "    epoch          : 692\n",
      "    loss           : 12286.028950514372\n",
      "    val_loss       : 12282.956069891543\n",
      "    val_log_likelihood: -12189.214984459006\n",
      "    val_log_marginal: -12197.0878443713\n",
      "Train Epoch: 693 [256/118836 (0%)] Loss: 12373.706055\n",
      "Train Epoch: 693 [33024/118836 (28%)] Loss: 12259.375000\n",
      "Train Epoch: 693 [65792/118836 (55%)] Loss: 12443.952148\n",
      "Train Epoch: 693 [98560/118836 (83%)] Loss: 12382.052734\n",
      "    epoch          : 693\n",
      "    loss           : 12286.360420705387\n",
      "    val_loss       : 12283.560279722777\n",
      "    val_log_likelihood: -12193.174243628517\n",
      "    val_log_marginal: -12201.003641825506\n",
      "Train Epoch: 694 [256/118836 (0%)] Loss: 12322.261719\n",
      "Train Epoch: 694 [33024/118836 (28%)] Loss: 12434.679688\n",
      "Train Epoch: 694 [65792/118836 (55%)] Loss: 12213.078125\n",
      "Train Epoch: 694 [98560/118836 (83%)] Loss: 12234.165039\n",
      "    epoch          : 694\n",
      "    loss           : 12284.438713231493\n",
      "    val_loss       : 12286.998546115961\n",
      "    val_log_likelihood: -12192.391275072374\n",
      "    val_log_marginal: -12200.269663674317\n",
      "Train Epoch: 695 [256/118836 (0%)] Loss: 12298.521484\n",
      "Train Epoch: 695 [33024/118836 (28%)] Loss: 12327.572266\n",
      "Train Epoch: 695 [65792/118836 (55%)] Loss: 12256.286133\n",
      "Train Epoch: 695 [98560/118836 (83%)] Loss: 12327.138672\n",
      "    epoch          : 695\n",
      "    loss           : 12288.87824761554\n",
      "    val_loss       : 12287.667064881822\n",
      "    val_log_likelihood: -12193.521423471102\n",
      "    val_log_marginal: -12201.296768967128\n",
      "Train Epoch: 696 [256/118836 (0%)] Loss: 12264.925781\n",
      "Train Epoch: 696 [33024/118836 (28%)] Loss: 12239.198242\n",
      "Train Epoch: 696 [65792/118836 (55%)] Loss: 12271.693359\n",
      "Train Epoch: 696 [98560/118836 (83%)] Loss: 12379.885742\n",
      "    epoch          : 696\n",
      "    loss           : 12291.399170123812\n",
      "    val_loss       : 12289.100615273846\n",
      "    val_log_likelihood: -12195.43201913384\n",
      "    val_log_marginal: -12203.819771373628\n",
      "Train Epoch: 697 [256/118836 (0%)] Loss: 12356.068359\n",
      "Train Epoch: 697 [33024/118836 (28%)] Loss: 12418.382812\n",
      "Train Epoch: 697 [65792/118836 (55%)] Loss: 12292.293945\n",
      "Train Epoch: 697 [98560/118836 (83%)] Loss: 12235.802734\n",
      "    epoch          : 697\n",
      "    loss           : 12284.042146951251\n",
      "    val_loss       : 12285.028273803264\n",
      "    val_log_likelihood: -12195.204723686931\n",
      "    val_log_marginal: -12203.110672406116\n",
      "Train Epoch: 698 [256/118836 (0%)] Loss: 12344.065430\n",
      "Train Epoch: 698 [33024/118836 (28%)] Loss: 12251.724609\n",
      "Train Epoch: 698 [65792/118836 (55%)] Loss: 12205.926758\n",
      "Train Epoch: 698 [98560/118836 (83%)] Loss: 12293.730469\n",
      "    epoch          : 698\n",
      "    loss           : 12283.31671852383\n",
      "    val_loss       : 12282.654857081263\n",
      "    val_log_likelihood: -12190.574085956887\n",
      "    val_log_marginal: -12198.494093068914\n",
      "Train Epoch: 699 [256/118836 (0%)] Loss: 12270.078125\n",
      "Train Epoch: 699 [33024/118836 (28%)] Loss: 12310.330078\n",
      "Train Epoch: 699 [65792/118836 (55%)] Loss: 12384.028320\n",
      "Train Epoch: 699 [98560/118836 (83%)] Loss: 12280.569336\n",
      "    epoch          : 699\n",
      "    loss           : 12283.644801682693\n",
      "    val_loss       : 12286.041558779121\n",
      "    val_log_likelihood: -12191.639464594964\n",
      "    val_log_marginal: -12199.550266578619\n",
      "Train Epoch: 700 [256/118836 (0%)] Loss: 12286.142578\n",
      "Train Epoch: 700 [33024/118836 (28%)] Loss: 12354.291016\n",
      "Train Epoch: 700 [65792/118836 (55%)] Loss: 12237.894531\n",
      "Train Epoch: 700 [98560/118836 (83%)] Loss: 12296.197266\n",
      "    epoch          : 700\n",
      "    loss           : 12287.009554642267\n",
      "    val_loss       : 12289.33751782337\n",
      "    val_log_likelihood: -12194.85272468207\n",
      "    val_log_marginal: -12202.94336912918\n",
      "Saving checkpoint: saved/models/SelfiesAutoencodingOperad/0905_154251/checkpoint-epoch700.pth ...\n",
      "Train Epoch: 701 [256/118836 (0%)] Loss: 12263.420898\n",
      "Train Epoch: 701 [33024/118836 (28%)] Loss: 12358.265625\n",
      "Train Epoch: 701 [65792/118836 (55%)] Loss: 12237.187500\n",
      "Train Epoch: 701 [98560/118836 (83%)] Loss: 12307.523438\n",
      "    epoch          : 701\n",
      "    loss           : 12289.73164870244\n",
      "    val_loss       : 12284.703681354395\n",
      "    val_log_likelihood: -12191.610718762924\n",
      "    val_log_marginal: -12199.590420415101\n",
      "Train Epoch: 702 [256/118836 (0%)] Loss: 12357.458008\n",
      "Train Epoch: 702 [33024/118836 (28%)] Loss: 12239.740234\n",
      "Train Epoch: 702 [65792/118836 (55%)] Loss: 12291.111328\n",
      "Train Epoch: 702 [98560/118836 (83%)] Loss: 12381.332031\n",
      "    epoch          : 702\n",
      "    loss           : 12283.301179952441\n",
      "    val_loss       : 12285.262606861703\n",
      "    val_log_likelihood: -12188.962916634357\n",
      "    val_log_marginal: -12196.86324414189\n",
      "Train Epoch: 703 [256/118836 (0%)] Loss: 12348.555664\n",
      "Train Epoch: 703 [33024/118836 (28%)] Loss: 12310.858398\n",
      "Train Epoch: 703 [65792/118836 (55%)] Loss: 12298.890625\n",
      "Train Epoch: 703 [98560/118836 (83%)] Loss: 12333.691406\n",
      "    epoch          : 703\n",
      "    loss           : 12284.13990966191\n",
      "    val_loss       : 12285.374157449118\n",
      "    val_log_likelihood: -12193.057818315758\n",
      "    val_log_marginal: -12201.293642909424\n",
      "Train Epoch: 704 [256/118836 (0%)] Loss: 12246.912109\n",
      "Train Epoch: 704 [33024/118836 (28%)] Loss: 12291.092773\n",
      "Train Epoch: 704 [65792/118836 (55%)] Loss: 12390.410156\n",
      "Train Epoch: 704 [98560/118836 (83%)] Loss: 12303.107422\n",
      "    epoch          : 704\n",
      "    loss           : 12286.916774096619\n",
      "    val_loss       : 12282.674578261636\n",
      "    val_log_likelihood: -12194.271898424575\n",
      "    val_log_marginal: -12202.23126999339\n",
      "Train Epoch: 705 [256/118836 (0%)] Loss: 12418.465820\n",
      "Train Epoch: 705 [33024/118836 (28%)] Loss: 12397.050781\n",
      "Train Epoch: 705 [65792/118836 (55%)] Loss: 12351.337891\n",
      "Train Epoch: 705 [98560/118836 (83%)] Loss: 12300.234375\n",
      "    epoch          : 705\n",
      "    loss           : 12286.342807524297\n",
      "    val_loss       : 12287.044936796518\n",
      "    val_log_likelihood: -12192.086395813947\n",
      "    val_log_marginal: -12200.06417859908\n",
      "Train Epoch: 706 [256/118836 (0%)] Loss: 12249.689453\n",
      "Train Epoch: 706 [33024/118836 (28%)] Loss: 12336.113281\n",
      "Train Epoch: 706 [65792/118836 (55%)] Loss: 12224.964844\n",
      "Train Epoch: 706 [98560/118836 (83%)] Loss: 12305.943359\n",
      "    epoch          : 706\n",
      "    loss           : 12283.03002012898\n",
      "    val_loss       : 12284.212309014787\n",
      "    val_log_likelihood: -12190.906348706318\n",
      "    val_log_marginal: -12198.783831954246\n",
      "Train Epoch: 707 [256/118836 (0%)] Loss: 12347.342773\n",
      "Train Epoch: 707 [33024/118836 (28%)] Loss: 12301.971680\n",
      "Train Epoch: 707 [65792/118836 (55%)] Loss: 12342.113281\n",
      "Train Epoch: 707 [98560/118836 (83%)] Loss: 12307.668945\n",
      "    epoch          : 707\n",
      "    loss           : 12282.301239725497\n",
      "    val_loss       : 12281.306004629834\n",
      "    val_log_likelihood: -12192.275133923957\n",
      "    val_log_marginal: -12200.310649783392\n",
      "Train Epoch: 708 [256/118836 (0%)] Loss: 12292.283203\n",
      "Train Epoch: 708 [33024/118836 (28%)] Loss: 12361.086914\n",
      "Train Epoch: 708 [65792/118836 (55%)] Loss: 12292.580078\n",
      "Train Epoch: 708 [98560/118836 (83%)] Loss: 12276.583008\n",
      "    epoch          : 708\n",
      "    loss           : 12286.58670647229\n",
      "    val_loss       : 12288.034802966635\n",
      "    val_log_likelihood: -12193.470199092742\n",
      "    val_log_marginal: -12201.642602615011\n",
      "Train Epoch: 709 [256/118836 (0%)] Loss: 12299.850586\n",
      "Train Epoch: 709 [33024/118836 (28%)] Loss: 12334.563477\n",
      "Train Epoch: 709 [65792/118836 (55%)] Loss: 12270.014648\n",
      "Train Epoch: 709 [98560/118836 (83%)] Loss: 12394.321289\n",
      "    epoch          : 709\n",
      "    loss           : 12285.266057143042\n",
      "    val_loss       : 12281.05711376633\n",
      "    val_log_likelihood: -12193.903498662376\n",
      "    val_log_marginal: -12201.815903548822\n",
      "Train Epoch: 710 [256/118836 (0%)] Loss: 12268.830078\n",
      "Train Epoch: 710 [33024/118836 (28%)] Loss: 12205.724609\n",
      "Train Epoch: 710 [65792/118836 (55%)] Loss: 12290.953125\n",
      "Train Epoch: 710 [98560/118836 (83%)] Loss: 12297.638672\n",
      "    epoch          : 710\n",
      "    loss           : 12283.556339982682\n",
      "    val_loss       : 12285.658627237959\n",
      "    val_log_likelihood: -12192.211308092948\n",
      "    val_log_marginal: -12200.232539775527\n",
      "Train Epoch: 711 [256/118836 (0%)] Loss: 12334.064453\n",
      "Train Epoch: 711 [33024/118836 (28%)] Loss: 12243.833984\n",
      "Train Epoch: 711 [65792/118836 (55%)] Loss: 12225.720703\n",
      "Train Epoch: 711 [98560/118836 (83%)] Loss: 12234.063477\n",
      "    epoch          : 711\n",
      "    loss           : 12287.942392666977\n",
      "    val_loss       : 12286.83645669661\n",
      "    val_log_likelihood: -12193.11748523444\n",
      "    val_log_marginal: -12201.022093167136\n",
      "Train Epoch: 712 [256/118836 (0%)] Loss: 12262.115234\n",
      "Train Epoch: 712 [33024/118836 (28%)] Loss: 12301.863281\n",
      "Train Epoch: 712 [65792/118836 (55%)] Loss: 12299.498047\n",
      "Train Epoch: 712 [98560/118836 (83%)] Loss: 12405.363281\n",
      "    epoch          : 712\n",
      "    loss           : 12284.375600961537\n",
      "    val_loss       : 12284.151445055712\n",
      "    val_log_likelihood: -12191.939207247724\n",
      "    val_log_marginal: -12200.08255927291\n",
      "Train Epoch: 713 [256/118836 (0%)] Loss: 12300.699219\n",
      "Train Epoch: 713 [33024/118836 (28%)] Loss: 12305.277344\n",
      "Train Epoch: 713 [65792/118836 (55%)] Loss: 12256.572266\n",
      "Train Epoch: 713 [98560/118836 (83%)] Loss: 12322.474609\n",
      "    epoch          : 713\n",
      "    loss           : 12281.423812616316\n",
      "    val_loss       : 12282.478321564427\n",
      "    val_log_likelihood: -12190.745119287634\n",
      "    val_log_marginal: -12198.664578009913\n",
      "Train Epoch: 714 [256/118836 (0%)] Loss: 12262.988281\n",
      "Train Epoch: 714 [33024/118836 (28%)] Loss: 12249.369141\n",
      "Train Epoch: 714 [65792/118836 (55%)] Loss: 12405.794922\n",
      "Train Epoch: 714 [98560/118836 (83%)] Loss: 12333.995117\n",
      "    epoch          : 714\n",
      "    loss           : 12286.816195428815\n",
      "    val_loss       : 12284.345287299268\n",
      "    val_log_likelihood: -12190.713217115126\n",
      "    val_log_marginal: -12198.849969538222\n",
      "Train Epoch: 715 [256/118836 (0%)] Loss: 12312.182617\n",
      "Train Epoch: 715 [33024/118836 (28%)] Loss: 12304.496094\n",
      "Train Epoch: 715 [65792/118836 (55%)] Loss: 12355.642578\n",
      "Train Epoch: 715 [98560/118836 (83%)] Loss: 12242.932617\n",
      "    epoch          : 715\n",
      "    loss           : 12284.328256662273\n",
      "    val_loss       : 12286.707716717123\n",
      "    val_log_likelihood: -12190.968280377636\n",
      "    val_log_marginal: -12199.06336428185\n",
      "Train Epoch: 716 [256/118836 (0%)] Loss: 12281.188477\n",
      "Train Epoch: 716 [33024/118836 (28%)] Loss: 12274.136719\n",
      "Train Epoch: 716 [65792/118836 (55%)] Loss: 12337.933594\n",
      "Train Epoch: 716 [98560/118836 (83%)] Loss: 12258.429688\n",
      "    epoch          : 716\n",
      "    loss           : 12287.00811976582\n",
      "    val_loss       : 12283.127463886114\n",
      "    val_log_likelihood: -12193.014882360163\n",
      "    val_log_marginal: -12201.073597641778\n",
      "Train Epoch: 717 [256/118836 (0%)] Loss: 12304.529297\n",
      "Train Epoch: 717 [33024/118836 (28%)] Loss: 12256.207031\n",
      "Train Epoch: 717 [65792/118836 (55%)] Loss: 12336.674805\n",
      "Train Epoch: 717 [98560/118836 (83%)] Loss: 12294.614258\n",
      "    epoch          : 717\n",
      "    loss           : 12284.762542648883\n",
      "    val_loss       : 12297.70497524231\n",
      "    val_log_likelihood: -12208.66329611249\n",
      "    val_log_marginal: -12216.8948967716\n",
      "Train Epoch: 718 [256/118836 (0%)] Loss: 12267.344727\n",
      "Train Epoch: 718 [33024/118836 (28%)] Loss: 12261.222656\n",
      "Train Epoch: 718 [65792/118836 (55%)] Loss: 12319.770508\n",
      "Train Epoch: 718 [98560/118836 (83%)] Loss: 12283.562500\n",
      "    epoch          : 718\n",
      "    loss           : 12283.225280610268\n",
      "    val_loss       : 12286.115881936128\n",
      "    val_log_likelihood: -12192.5553002546\n",
      "    val_log_marginal: -12200.652152556937\n",
      "Train Epoch: 719 [256/118836 (0%)] Loss: 12287.043945\n",
      "Train Epoch: 719 [33024/118836 (28%)] Loss: 12304.556641\n",
      "Train Epoch: 719 [65792/118836 (55%)] Loss: 12272.083008\n",
      "Train Epoch: 719 [98560/118836 (83%)] Loss: 12218.094727\n",
      "    epoch          : 719\n",
      "    loss           : 12286.902416285411\n",
      "    val_loss       : 12283.526864700447\n",
      "    val_log_likelihood: -12190.902138098378\n",
      "    val_log_marginal: -12198.960424111447\n",
      "Train Epoch: 720 [256/118836 (0%)] Loss: 12353.892578\n",
      "Train Epoch: 720 [33024/118836 (28%)] Loss: 12279.492188\n",
      "Train Epoch: 720 [65792/118836 (55%)] Loss: 12279.556641\n",
      "Train Epoch: 720 [98560/118836 (83%)] Loss: 12241.674805\n",
      "    epoch          : 720\n",
      "    loss           : 12286.361532484234\n",
      "    val_loss       : 12287.694049378611\n",
      "    val_log_likelihood: -12192.455601866212\n",
      "    val_log_marginal: -12200.458989794628\n",
      "Train Epoch: 721 [256/118836 (0%)] Loss: 12306.509766\n",
      "Train Epoch: 721 [33024/118836 (28%)] Loss: 12291.083984\n",
      "Train Epoch: 721 [65792/118836 (55%)] Loss: 12234.774414\n",
      "Train Epoch: 721 [98560/118836 (83%)] Loss: 12261.575195\n",
      "    epoch          : 721\n",
      "    loss           : 12290.292633859337\n",
      "    val_loss       : 12284.249329115099\n",
      "    val_log_likelihood: -12189.573380473274\n",
      "    val_log_marginal: -12197.623392981812\n",
      "Train Epoch: 722 [256/118836 (0%)] Loss: 12317.308594\n",
      "Train Epoch: 722 [33024/118836 (28%)] Loss: 12345.489258\n",
      "Train Epoch: 722 [65792/118836 (55%)] Loss: 12205.556641\n",
      "Train Epoch: 722 [98560/118836 (83%)] Loss: 12266.717773\n",
      "    epoch          : 722\n",
      "    loss           : 12281.614783330748\n",
      "    val_loss       : 12283.861706975475\n",
      "    val_log_likelihood: -12188.912285140095\n",
      "    val_log_marginal: -12196.923576543008\n",
      "Train Epoch: 723 [256/118836 (0%)] Loss: 12293.935547\n",
      "Train Epoch: 723 [33024/118836 (28%)] Loss: 12247.134766\n",
      "Train Epoch: 723 [65792/118836 (55%)] Loss: 12316.894531\n",
      "Train Epoch: 723 [98560/118836 (83%)] Loss: 12308.423828\n",
      "    epoch          : 723\n",
      "    loss           : 12287.266547928299\n",
      "    val_loss       : 12285.698587946034\n",
      "    val_log_likelihood: -12194.97941932899\n",
      "    val_log_marginal: -12203.13899383613\n",
      "Train Epoch: 724 [256/118836 (0%)] Loss: 12251.139648\n",
      "Train Epoch: 724 [33024/118836 (28%)] Loss: 12263.269531\n",
      "Train Epoch: 724 [65792/118836 (55%)] Loss: 12301.625977\n",
      "Train Epoch: 724 [98560/118836 (83%)] Loss: 12390.006836\n",
      "    epoch          : 724\n",
      "    loss           : 12283.176518397177\n",
      "    val_loss       : 12282.2414896588\n",
      "    val_log_likelihood: -12192.798013919046\n",
      "    val_log_marginal: -12200.791972640509\n",
      "Train Epoch: 725 [256/118836 (0%)] Loss: 12347.945312\n",
      "Train Epoch: 725 [33024/118836 (28%)] Loss: 12274.488281\n",
      "Train Epoch: 725 [65792/118836 (55%)] Loss: 12237.050781\n",
      "Train Epoch: 725 [98560/118836 (83%)] Loss: 12226.973633\n",
      "    epoch          : 725\n",
      "    loss           : 12274.515223228133\n",
      "    val_loss       : 12271.979641752056\n",
      "    val_log_likelihood: -12187.346752384461\n",
      "    val_log_marginal: -12195.270354446297\n",
      "Train Epoch: 726 [256/118836 (0%)] Loss: 12260.212891\n",
      "Train Epoch: 726 [33024/118836 (28%)] Loss: 12365.713867\n",
      "Train Epoch: 726 [65792/118836 (55%)] Loss: 12351.561523\n",
      "Train Epoch: 726 [98560/118836 (83%)] Loss: 12232.801758\n",
      "    epoch          : 726\n",
      "    loss           : 12274.338453622571\n",
      "    val_loss       : 12273.025374549516\n",
      "    val_log_likelihood: -12185.132610725548\n",
      "    val_log_marginal: -12193.55285292974\n",
      "Train Epoch: 727 [256/118836 (0%)] Loss: 12234.916016\n",
      "Train Epoch: 727 [33024/118836 (28%)] Loss: 12299.751953\n",
      "Train Epoch: 727 [65792/118836 (55%)] Loss: 12355.574219\n",
      "Train Epoch: 727 [98560/118836 (83%)] Loss: 12278.792969\n",
      "    epoch          : 727\n",
      "    loss           : 12274.895614111612\n",
      "    val_loss       : 12266.647203470311\n",
      "    val_log_likelihood: -12185.469763880274\n",
      "    val_log_marginal: -12193.572935874996\n",
      "Train Epoch: 728 [256/118836 (0%)] Loss: 12255.281250\n",
      "Train Epoch: 728 [33024/118836 (28%)] Loss: 12400.354492\n",
      "Train Epoch: 728 [65792/118836 (55%)] Loss: 12292.886719\n",
      "Train Epoch: 728 [98560/118836 (83%)] Loss: 12297.754883\n",
      "    epoch          : 728\n",
      "    loss           : 12271.792674569633\n",
      "    val_loss       : 12268.613299057442\n",
      "    val_log_likelihood: -12183.201826309192\n",
      "    val_log_marginal: -12191.248082368065\n",
      "Train Epoch: 729 [256/118836 (0%)] Loss: 12256.292969\n",
      "Train Epoch: 729 [33024/118836 (28%)] Loss: 12404.291016\n",
      "Train Epoch: 729 [65792/118836 (55%)] Loss: 12430.590820\n",
      "Train Epoch: 729 [98560/118836 (83%)] Loss: 12325.221680\n",
      "    epoch          : 729\n",
      "    loss           : 12269.949524238782\n",
      "    val_loss       : 12273.570950359197\n",
      "    val_log_likelihood: -12185.416715292855\n",
      "    val_log_marginal: -12193.415160083723\n",
      "Train Epoch: 730 [256/118836 (0%)] Loss: 12307.245117\n",
      "Train Epoch: 730 [33024/118836 (28%)] Loss: 12301.761719\n",
      "Train Epoch: 730 [65792/118836 (55%)] Loss: 12430.136719\n",
      "Train Epoch: 730 [98560/118836 (83%)] Loss: 12330.820312\n",
      "    epoch          : 730\n",
      "    loss           : 12273.667961803401\n",
      "    val_loss       : 12269.547064295331\n",
      "    val_log_likelihood: -12186.40601833902\n",
      "    val_log_marginal: -12194.52144181023\n",
      "Train Epoch: 731 [256/118836 (0%)] Loss: 12454.304688\n",
      "Train Epoch: 731 [33024/118836 (28%)] Loss: 12245.609375\n",
      "Train Epoch: 731 [65792/118836 (55%)] Loss: 12225.935547\n",
      "Train Epoch: 731 [98560/118836 (83%)] Loss: 12308.746094\n",
      "    epoch          : 731\n",
      "    loss           : 12272.53905733044\n",
      "    val_loss       : 12269.147321205564\n",
      "    val_log_likelihood: -12185.891847924422\n",
      "    val_log_marginal: -12193.986061999982\n",
      "Train Epoch: 732 [256/118836 (0%)] Loss: 12223.058594\n",
      "Train Epoch: 732 [33024/118836 (28%)] Loss: 12337.726562\n",
      "Train Epoch: 732 [65792/118836 (55%)] Loss: 12375.113281\n",
      "Train Epoch: 732 [98560/118836 (83%)] Loss: 12290.697266\n",
      "    epoch          : 732\n",
      "    loss           : 12270.99313159119\n",
      "    val_loss       : 12274.698019285144\n",
      "    val_log_likelihood: -12186.603033240282\n",
      "    val_log_marginal: -12194.97036920088\n",
      "Train Epoch: 733 [256/118836 (0%)] Loss: 12235.581055\n",
      "Train Epoch: 733 [33024/118836 (28%)] Loss: 12270.666016\n",
      "Train Epoch: 733 [65792/118836 (55%)] Loss: 12256.230469\n",
      "Train Epoch: 733 [98560/118836 (83%)] Loss: 12344.003906\n",
      "    epoch          : 733\n",
      "    loss           : 12272.521757554023\n",
      "    val_loss       : 12275.203738654942\n",
      "    val_log_likelihood: -12184.868951128257\n",
      "    val_log_marginal: -12193.216016244705\n",
      "Train Epoch: 734 [256/118836 (0%)] Loss: 12257.220703\n",
      "Train Epoch: 734 [33024/118836 (28%)] Loss: 12258.375977\n",
      "Train Epoch: 734 [65792/118836 (55%)] Loss: 12204.798828\n",
      "Train Epoch: 734 [98560/118836 (83%)] Loss: 12272.624023\n",
      "    epoch          : 734\n",
      "    loss           : 12275.632932530758\n",
      "    val_loss       : 12271.370842265198\n",
      "    val_log_likelihood: -12183.78425771557\n",
      "    val_log_marginal: -12191.97848296768\n",
      "Train Epoch: 735 [256/118836 (0%)] Loss: 12208.333984\n",
      "Train Epoch: 735 [33024/118836 (28%)] Loss: 12214.023438\n",
      "Train Epoch: 735 [65792/118836 (55%)] Loss: 12208.565430\n",
      "Train Epoch: 735 [98560/118836 (83%)] Loss: 12408.607422\n",
      "    epoch          : 735\n",
      "    loss           : 12273.871504083952\n",
      "    val_loss       : 12268.878499280125\n",
      "    val_log_likelihood: -12185.21937373992\n",
      "    val_log_marginal: -12193.581019888368\n",
      "Train Epoch: 736 [256/118836 (0%)] Loss: 12252.887695\n",
      "Train Epoch: 736 [33024/118836 (28%)] Loss: 12292.463867\n",
      "Train Epoch: 736 [65792/118836 (55%)] Loss: 12257.298828\n",
      "Train Epoch: 736 [98560/118836 (83%)] Loss: 12319.849609\n",
      "    epoch          : 736\n",
      "    loss           : 12271.76423648806\n",
      "    val_loss       : 12271.056974383104\n",
      "    val_log_likelihood: -12184.644086506152\n",
      "    val_log_marginal: -12193.015313902455\n",
      "Train Epoch: 737 [256/118836 (0%)] Loss: 12333.128906\n",
      "Train Epoch: 737 [33024/118836 (28%)] Loss: 12362.273438\n",
      "Train Epoch: 737 [65792/118836 (55%)] Loss: 12271.730469\n",
      "Train Epoch: 737 [98560/118836 (83%)] Loss: 12329.626953\n",
      "    epoch          : 737\n",
      "    loss           : 12267.578384285825\n",
      "    val_loss       : 12274.056882389312\n",
      "    val_log_likelihood: -12185.034793411394\n",
      "    val_log_marginal: -12193.278486300045\n",
      "Train Epoch: 738 [256/118836 (0%)] Loss: 12263.880859\n",
      "Train Epoch: 738 [33024/118836 (28%)] Loss: 12319.025391\n",
      "Train Epoch: 738 [65792/118836 (55%)] Loss: 12427.284180\n",
      "Train Epoch: 738 [98560/118836 (83%)] Loss: 12275.727539\n",
      "    epoch          : 738\n",
      "    loss           : 12271.418656301696\n",
      "    val_loss       : 12272.09735915043\n",
      "    val_log_likelihood: -12185.850533918787\n",
      "    val_log_marginal: -12193.945896962778\n",
      "Train Epoch: 739 [256/118836 (0%)] Loss: 12292.721680\n",
      "Train Epoch: 739 [33024/118836 (28%)] Loss: 12292.556641\n",
      "Train Epoch: 739 [65792/118836 (55%)] Loss: 12220.386719\n",
      "Train Epoch: 739 [98560/118836 (83%)] Loss: 12445.310547\n",
      "    epoch          : 739\n",
      "    loss           : 12271.355544516387\n",
      "    val_loss       : 12268.153263863425\n",
      "    val_log_likelihood: -12184.517901707248\n",
      "    val_log_marginal: -12192.485026029823\n",
      "Train Epoch: 740 [256/118836 (0%)] Loss: 12400.027344\n",
      "Train Epoch: 740 [33024/118836 (28%)] Loss: 12254.502930\n",
      "Train Epoch: 740 [65792/118836 (55%)] Loss: 12230.082031\n",
      "Train Epoch: 740 [98560/118836 (83%)] Loss: 12287.572266\n",
      "    epoch          : 740\n",
      "    loss           : 12274.106936743952\n",
      "    val_loss       : 12268.767907759266\n",
      "    val_log_likelihood: -12187.662576251034\n",
      "    val_log_marginal: -12195.814965131189\n",
      "Train Epoch: 741 [256/118836 (0%)] Loss: 12149.262695\n",
      "Train Epoch: 741 [33024/118836 (28%)] Loss: 12275.718750\n",
      "Train Epoch: 741 [65792/118836 (55%)] Loss: 12392.851562\n",
      "Train Epoch: 741 [98560/118836 (83%)] Loss: 12196.348633\n",
      "    epoch          : 741\n",
      "    loss           : 12267.236257689723\n",
      "    val_loss       : 12269.445105520312\n",
      "    val_log_likelihood: -12182.191184281948\n",
      "    val_log_marginal: -12190.397369528464\n",
      "Train Epoch: 742 [256/118836 (0%)] Loss: 12263.732422\n",
      "Train Epoch: 742 [33024/118836 (28%)] Loss: 12326.758789\n",
      "Train Epoch: 742 [65792/118836 (55%)] Loss: 12293.686523\n",
      "Train Epoch: 742 [98560/118836 (83%)] Loss: 12223.958984\n",
      "    epoch          : 742\n",
      "    loss           : 12276.754401073977\n",
      "    val_loss       : 12273.239225223726\n",
      "    val_log_likelihood: -12186.206017854372\n",
      "    val_log_marginal: -12194.750566672301\n",
      "Train Epoch: 743 [256/118836 (0%)] Loss: 12250.194336\n",
      "Train Epoch: 743 [33024/118836 (28%)] Loss: 12233.265625\n",
      "Train Epoch: 743 [65792/118836 (55%)] Loss: 12244.322266\n",
      "Train Epoch: 743 [98560/118836 (83%)] Loss: 12348.331055\n",
      "    epoch          : 743\n",
      "    loss           : 12270.408424769956\n",
      "    val_loss       : 12269.541567123508\n",
      "    val_log_likelihood: -12186.895297475963\n",
      "    val_log_marginal: -12195.1159534957\n",
      "Train Epoch: 744 [256/118836 (0%)] Loss: 12327.763672\n",
      "Train Epoch: 744 [33024/118836 (28%)] Loss: 12293.239258\n",
      "Train Epoch: 744 [65792/118836 (55%)] Loss: 12302.474609\n",
      "Train Epoch: 744 [98560/118836 (83%)] Loss: 12263.388672\n",
      "    epoch          : 744\n",
      "    loss           : 12273.372998733457\n",
      "    val_loss       : 12266.859353236436\n",
      "    val_log_likelihood: -12186.171543017213\n",
      "    val_log_marginal: -12194.257285062422\n",
      "Train Epoch: 745 [256/118836 (0%)] Loss: 12404.797852\n",
      "Train Epoch: 745 [33024/118836 (28%)] Loss: 12297.234375\n",
      "Train Epoch: 745 [65792/118836 (55%)] Loss: 12285.063477\n",
      "Train Epoch: 745 [98560/118836 (83%)] Loss: 12352.779297\n",
      "    epoch          : 745\n",
      "    loss           : 12271.316450029726\n",
      "    val_loss       : 12275.93113226848\n",
      "    val_log_likelihood: -12184.331862431503\n",
      "    val_log_marginal: -12192.780490301433\n",
      "Train Epoch: 746 [256/118836 (0%)] Loss: 12345.852539\n",
      "Train Epoch: 746 [33024/118836 (28%)] Loss: 12261.837891\n",
      "Train Epoch: 746 [65792/118836 (55%)] Loss: 12207.457031\n",
      "Train Epoch: 746 [98560/118836 (83%)] Loss: 12259.173828\n",
      "    epoch          : 746\n",
      "    loss           : 12272.029600586746\n",
      "    val_loss       : 12269.666812647763\n",
      "    val_log_likelihood: -12187.126132295543\n",
      "    val_log_marginal: -12195.330445065356\n",
      "Train Epoch: 747 [256/118836 (0%)] Loss: 12246.423828\n",
      "Train Epoch: 747 [33024/118836 (28%)] Loss: 12308.531250\n",
      "Train Epoch: 747 [65792/118836 (55%)] Loss: 12357.316406\n",
      "Train Epoch: 747 [98560/118836 (83%)] Loss: 12277.878906\n",
      "    epoch          : 747\n",
      "    loss           : 12272.075694336747\n",
      "    val_loss       : 12271.240239389406\n",
      "    val_log_likelihood: -12185.977876537943\n",
      "    val_log_marginal: -12193.953090364808\n",
      "Train Epoch: 748 [256/118836 (0%)] Loss: 12326.967773\n",
      "Train Epoch: 748 [33024/118836 (28%)] Loss: 12295.758789\n",
      "Train Epoch: 748 [65792/118836 (55%)] Loss: 12292.905273\n",
      "Train Epoch: 748 [98560/118836 (83%)] Loss: 12290.558594\n",
      "    epoch          : 748\n",
      "    loss           : 12271.99987867685\n",
      "    val_loss       : 12266.740027810967\n",
      "    val_log_likelihood: -12185.631979715932\n",
      "    val_log_marginal: -12193.74826670237\n",
      "Train Epoch: 749 [256/118836 (0%)] Loss: 12345.158203\n",
      "Train Epoch: 749 [33024/118836 (28%)] Loss: 12192.891602\n",
      "Train Epoch: 749 [65792/118836 (55%)] Loss: 12375.082031\n",
      "Train Epoch: 749 [98560/118836 (83%)] Loss: 12266.378906\n",
      "    epoch          : 749\n",
      "    loss           : 12268.965624515355\n",
      "    val_loss       : 12269.46997436331\n",
      "    val_log_likelihood: -12184.68171202957\n",
      "    val_log_marginal: -12192.662883955712\n",
      "Train Epoch: 750 [256/118836 (0%)] Loss: 12297.316406\n",
      "Train Epoch: 750 [33024/118836 (28%)] Loss: 12219.849609\n",
      "Train Epoch: 750 [65792/118836 (55%)] Loss: 12265.767578\n",
      "Train Epoch: 750 [98560/118836 (83%)] Loss: 12341.114258\n",
      "    epoch          : 750\n",
      "    loss           : 12270.287425687553\n",
      "    val_loss       : 12275.403261956772\n",
      "    val_log_likelihood: -12187.122912304849\n",
      "    val_log_marginal: -12195.593548880373\n",
      "Train Epoch: 751 [256/118836 (0%)] Loss: 12380.548828\n",
      "Train Epoch: 751 [33024/118836 (28%)] Loss: 12235.796875\n",
      "Train Epoch: 751 [65792/118836 (55%)] Loss: 12366.116211\n",
      "Train Epoch: 751 [98560/118836 (83%)] Loss: 12290.013672\n",
      "    epoch          : 751\n",
      "    loss           : 12273.730784254807\n",
      "    val_loss       : 12264.949435338418\n",
      "    val_log_likelihood: -12186.879816092845\n",
      "    val_log_marginal: -12195.134718528929\n",
      "Train Epoch: 752 [256/118836 (0%)] Loss: 12244.445312\n",
      "Train Epoch: 752 [33024/118836 (28%)] Loss: 12336.471680\n",
      "Train Epoch: 752 [65792/118836 (55%)] Loss: 12312.261719\n",
      "Train Epoch: 752 [98560/118836 (83%)] Loss: 12429.986328\n",
      "    epoch          : 752\n",
      "    loss           : 12267.989110479995\n",
      "    val_loss       : 12277.740896007524\n",
      "    val_log_likelihood: -12185.125399348635\n",
      "    val_log_marginal: -12193.437416840829\n",
      "Train Epoch: 753 [256/118836 (0%)] Loss: 12246.382812\n",
      "Train Epoch: 753 [33024/118836 (28%)] Loss: 12253.879883\n",
      "Train Epoch: 753 [65792/118836 (55%)] Loss: 12246.731445\n",
      "Train Epoch: 753 [98560/118836 (83%)] Loss: 12283.517578\n",
      "    epoch          : 753\n",
      "    loss           : 12271.319852570565\n",
      "    val_loss       : 12269.95177353631\n",
      "    val_log_likelihood: -12184.744644011062\n",
      "    val_log_marginal: -12193.03403768968\n",
      "Train Epoch: 754 [256/118836 (0%)] Loss: 12384.097656\n",
      "Train Epoch: 754 [33024/118836 (28%)] Loss: 12320.844727\n",
      "Train Epoch: 754 [65792/118836 (55%)] Loss: 12300.853516\n",
      "Train Epoch: 754 [98560/118836 (83%)] Loss: 12388.521484\n",
      "    epoch          : 754\n",
      "    loss           : 12269.99821391646\n",
      "    val_loss       : 12270.042292213611\n",
      "    val_log_likelihood: -12185.292049375776\n",
      "    val_log_marginal: -12193.283787916638\n",
      "Train Epoch: 755 [256/118836 (0%)] Loss: 12316.158203\n",
      "Train Epoch: 755 [33024/118836 (28%)] Loss: 12361.464844\n",
      "Train Epoch: 755 [65792/118836 (55%)] Loss: 12256.610352\n",
      "Train Epoch: 755 [98560/118836 (83%)] Loss: 12257.765625\n",
      "    epoch          : 755\n",
      "    loss           : 12266.215736307124\n",
      "    val_loss       : 12273.40998485728\n",
      "    val_log_likelihood: -12186.29386195332\n",
      "    val_log_marginal: -12194.305690434921\n",
      "Train Epoch: 756 [256/118836 (0%)] Loss: 12303.424805\n",
      "Train Epoch: 756 [33024/118836 (28%)] Loss: 12254.460938\n",
      "Train Epoch: 756 [65792/118836 (55%)] Loss: 12274.220703\n",
      "Train Epoch: 756 [98560/118836 (83%)] Loss: 12272.474609\n",
      "    epoch          : 756\n",
      "    loss           : 12270.324934411186\n",
      "    val_loss       : 12269.143997152196\n",
      "    val_log_likelihood: -12185.388702084625\n",
      "    val_log_marginal: -12193.746790488209\n",
      "Train Epoch: 757 [256/118836 (0%)] Loss: 12250.256836\n",
      "Train Epoch: 757 [33024/118836 (28%)] Loss: 12301.848633\n",
      "Train Epoch: 757 [65792/118836 (55%)] Loss: 12247.312500\n",
      "Train Epoch: 757 [98560/118836 (83%)] Loss: 12310.919922\n",
      "    epoch          : 757\n",
      "    loss           : 12273.206012200166\n",
      "    val_loss       : 12269.808393358708\n",
      "    val_log_likelihood: -12186.567506397334\n",
      "    val_log_marginal: -12194.885195813753\n",
      "Train Epoch: 758 [256/118836 (0%)] Loss: 12265.348633\n",
      "Train Epoch: 758 [33024/118836 (28%)] Loss: 12378.830078\n",
      "Train Epoch: 758 [65792/118836 (55%)] Loss: 12309.757812\n",
      "Train Epoch: 758 [98560/118836 (83%)] Loss: 12309.874023\n",
      "    epoch          : 758\n",
      "    loss           : 12272.33904359879\n",
      "    val_loss       : 12272.56372238823\n",
      "    val_log_likelihood: -12184.370420899246\n",
      "    val_log_marginal: -12192.571870965368\n",
      "Train Epoch: 759 [256/118836 (0%)] Loss: 12310.482422\n",
      "Train Epoch: 759 [33024/118836 (28%)] Loss: 12333.340820\n",
      "Train Epoch: 759 [65792/118836 (55%)] Loss: 12214.187500\n",
      "Train Epoch: 759 [98560/118836 (83%)] Loss: 12267.746094\n",
      "    epoch          : 759\n",
      "    loss           : 12268.091803983147\n",
      "    val_loss       : 12267.383832514271\n",
      "    val_log_likelihood: -12183.256162602098\n",
      "    val_log_marginal: -12191.332808720857\n",
      "Train Epoch: 760 [256/118836 (0%)] Loss: 12204.934570\n",
      "Train Epoch: 760 [33024/118836 (28%)] Loss: 12244.372070\n",
      "Train Epoch: 760 [65792/118836 (55%)] Loss: 12222.517578\n",
      "Train Epoch: 760 [98560/118836 (83%)] Loss: 12299.522461\n",
      "    epoch          : 760\n",
      "    loss           : 12268.2714171707\n",
      "    val_loss       : 12266.607787650122\n",
      "    val_log_likelihood: -12181.7819842393\n",
      "    val_log_marginal: -12189.939270978557\n",
      "Train Epoch: 761 [256/118836 (0%)] Loss: 12305.791016\n",
      "Train Epoch: 761 [33024/118836 (28%)] Loss: 12339.763672\n",
      "Train Epoch: 761 [65792/118836 (55%)] Loss: 12330.708984\n",
      "Train Epoch: 761 [98560/118836 (83%)] Loss: 12219.264648\n",
      "    epoch          : 761\n",
      "    loss           : 12269.877490274763\n",
      "    val_loss       : 12267.083065934794\n",
      "    val_log_likelihood: -12183.570843995554\n",
      "    val_log_marginal: -12191.737785708461\n",
      "Train Epoch: 762 [256/118836 (0%)] Loss: 12251.011719\n",
      "Train Epoch: 762 [33024/118836 (28%)] Loss: 12263.539062\n",
      "Train Epoch: 762 [65792/118836 (55%)] Loss: 12189.195312\n",
      "Train Epoch: 762 [98560/118836 (83%)] Loss: 12249.613281\n",
      "    epoch          : 762\n",
      "    loss           : 12270.61370289237\n",
      "    val_loss       : 12268.74111834405\n",
      "    val_log_likelihood: -12187.234093581988\n",
      "    val_log_marginal: -12195.312035034438\n",
      "Train Epoch: 763 [256/118836 (0%)] Loss: 12346.916992\n",
      "Train Epoch: 763 [33024/118836 (28%)] Loss: 12271.507812\n",
      "Train Epoch: 763 [65792/118836 (55%)] Loss: 12198.594727\n",
      "Train Epoch: 763 [98560/118836 (83%)] Loss: 12277.732422\n",
      "    epoch          : 763\n",
      "    loss           : 12267.15138204999\n",
      "    val_loss       : 12272.71668807296\n",
      "    val_log_likelihood: -12184.10940456343\n",
      "    val_log_marginal: -12192.235802420491\n",
      "Train Epoch: 764 [256/118836 (0%)] Loss: 12247.076172\n",
      "Train Epoch: 764 [33024/118836 (28%)] Loss: 12293.001953\n",
      "Train Epoch: 764 [65792/118836 (55%)] Loss: 12284.068359\n",
      "Train Epoch: 764 [98560/118836 (83%)] Loss: 12318.396484\n",
      "    epoch          : 764\n",
      "    loss           : 12271.595627358613\n",
      "    val_loss       : 12267.66764151\n",
      "    val_log_likelihood: -12184.038266225962\n",
      "    val_log_marginal: -12192.24208630603\n",
      "Train Epoch: 765 [256/118836 (0%)] Loss: 12253.489258\n",
      "Train Epoch: 765 [33024/118836 (28%)] Loss: 12242.320312\n",
      "Train Epoch: 765 [65792/118836 (55%)] Loss: 12208.207031\n",
      "Train Epoch: 765 [98560/118836 (83%)] Loss: 12222.056641\n",
      "    epoch          : 765\n",
      "    loss           : 12269.8283540762\n",
      "    val_loss       : 12271.482249159215\n",
      "    val_log_likelihood: -12185.909338166874\n",
      "    val_log_marginal: -12193.872379344459\n",
      "Train Epoch: 766 [256/118836 (0%)] Loss: 12271.232422\n",
      "Train Epoch: 766 [33024/118836 (28%)] Loss: 12232.929688\n",
      "Train Epoch: 766 [65792/118836 (55%)] Loss: 12301.087891\n",
      "Train Epoch: 766 [98560/118836 (83%)] Loss: 12243.825195\n",
      "    epoch          : 766\n",
      "    loss           : 12267.503447128307\n",
      "    val_loss       : 12273.979048735628\n",
      "    val_log_likelihood: -12185.62629319815\n",
      "    val_log_marginal: -12193.974027177397\n",
      "Train Epoch: 767 [256/118836 (0%)] Loss: 12305.507812\n",
      "Train Epoch: 767 [33024/118836 (28%)] Loss: 12379.958984\n",
      "Train Epoch: 767 [65792/118836 (55%)] Loss: 12265.345703\n",
      "Train Epoch: 767 [98560/118836 (83%)] Loss: 12324.182617\n",
      "    epoch          : 767\n",
      "    loss           : 12270.20863704508\n",
      "    val_loss       : 12263.869562210635\n",
      "    val_log_likelihood: -12184.833749321495\n",
      "    val_log_marginal: -12192.956176074778\n",
      "Train Epoch: 768 [256/118836 (0%)] Loss: 12267.189453\n",
      "Train Epoch: 768 [33024/118836 (28%)] Loss: 12357.912109\n",
      "Train Epoch: 768 [65792/118836 (55%)] Loss: 12254.440430\n",
      "Train Epoch: 768 [98560/118836 (83%)] Loss: 12290.652344\n",
      "    epoch          : 768\n",
      "    loss           : 12267.53029750827\n",
      "    val_loss       : 12266.976834959445\n",
      "    val_log_likelihood: -12183.163809029933\n",
      "    val_log_marginal: -12191.266556612449\n",
      "Train Epoch: 769 [256/118836 (0%)] Loss: 12315.963867\n",
      "Train Epoch: 769 [33024/118836 (28%)] Loss: 12213.486328\n",
      "Train Epoch: 769 [65792/118836 (55%)] Loss: 12284.458008\n",
      "Train Epoch: 769 [98560/118836 (83%)] Loss: 12341.866211\n",
      "    epoch          : 769\n",
      "    loss           : 12269.247573375465\n",
      "    val_loss       : 12266.388173212034\n",
      "    val_log_likelihood: -12185.849522300197\n",
      "    val_log_marginal: -12194.066595483555\n",
      "Train Epoch: 770 [256/118836 (0%)] Loss: 12162.923828\n",
      "Train Epoch: 770 [33024/118836 (28%)] Loss: 12344.419922\n",
      "Train Epoch: 770 [65792/118836 (55%)] Loss: 12322.365234\n",
      "Train Epoch: 770 [98560/118836 (83%)] Loss: 12269.527344\n",
      "    epoch          : 770\n",
      "    loss           : 12265.999663816945\n",
      "    val_loss       : 12269.547920525443\n",
      "    val_log_likelihood: -12184.96263602409\n",
      "    val_log_marginal: -12193.145864218632\n",
      "Train Epoch: 771 [256/118836 (0%)] Loss: 12258.138672\n",
      "Train Epoch: 771 [33024/118836 (28%)] Loss: 12355.228516\n",
      "Train Epoch: 771 [65792/118836 (55%)] Loss: 12277.657227\n",
      "Train Epoch: 771 [98560/118836 (83%)] Loss: 12271.346680\n",
      "    epoch          : 771\n",
      "    loss           : 12267.566795097962\n",
      "    val_loss       : 12269.773789650717\n",
      "    val_log_likelihood: -12185.462544749018\n",
      "    val_log_marginal: -12193.817906413538\n",
      "Train Epoch: 772 [256/118836 (0%)] Loss: 12252.696289\n",
      "Train Epoch: 772 [33024/118836 (28%)] Loss: 12279.914062\n",
      "Train Epoch: 772 [65792/118836 (55%)] Loss: 12353.611328\n",
      "Train Epoch: 772 [98560/118836 (83%)] Loss: 12336.385742\n",
      "    epoch          : 772\n",
      "    loss           : 12273.534047540581\n",
      "    val_loss       : 12273.5959336885\n",
      "    val_log_likelihood: -12182.778107229633\n",
      "    val_log_marginal: -12190.857367760695\n",
      "Train Epoch: 773 [256/118836 (0%)] Loss: 12290.955078\n",
      "Train Epoch: 773 [33024/118836 (28%)] Loss: 12253.667969\n",
      "Train Epoch: 773 [65792/118836 (55%)] Loss: 12286.833008\n",
      "Train Epoch: 773 [98560/118836 (83%)] Loss: 12267.970703\n",
      "    epoch          : 773\n",
      "    loss           : 12271.061438139732\n",
      "    val_loss       : 12269.26470777789\n",
      "    val_log_likelihood: -12182.614889145214\n",
      "    val_log_marginal: -12190.72657958298\n",
      "Train Epoch: 774 [256/118836 (0%)] Loss: 12347.039062\n",
      "Train Epoch: 774 [33024/118836 (28%)] Loss: 12329.646484\n",
      "Train Epoch: 774 [65792/118836 (55%)] Loss: 12271.446289\n",
      "Train Epoch: 774 [98560/118836 (83%)] Loss: 12356.677734\n",
      "    epoch          : 774\n",
      "    loss           : 12264.241000439413\n",
      "    val_loss       : 12268.24606753514\n",
      "    val_log_likelihood: -12184.854566499947\n",
      "    val_log_marginal: -12192.91477762008\n",
      "Train Epoch: 775 [256/118836 (0%)] Loss: 12318.721680\n",
      "Train Epoch: 775 [33024/118836 (28%)] Loss: 12389.724609\n",
      "Train Epoch: 775 [65792/118836 (55%)] Loss: 12343.458984\n",
      "Train Epoch: 775 [98560/118836 (83%)] Loss: 12275.514648\n",
      "    epoch          : 775\n",
      "    loss           : 12270.491021279207\n",
      "    val_loss       : 12270.653029333089\n",
      "    val_log_likelihood: -12186.645244811052\n",
      "    val_log_marginal: -12194.811323291422\n",
      "Train Epoch: 776 [256/118836 (0%)] Loss: 12347.956055\n",
      "Train Epoch: 776 [33024/118836 (28%)] Loss: 12364.015625\n",
      "Train Epoch: 776 [65792/118836 (55%)] Loss: 12310.386719\n",
      "Train Epoch: 776 [98560/118836 (83%)] Loss: 12357.255859\n",
      "    epoch          : 776\n",
      "    loss           : 12266.25544031741\n",
      "    val_loss       : 12268.49412199793\n",
      "    val_log_likelihood: -12188.0679349863\n",
      "    val_log_marginal: -12196.065447989327\n",
      "Train Epoch: 777 [256/118836 (0%)] Loss: 12308.675781\n",
      "Train Epoch: 777 [33024/118836 (28%)] Loss: 12354.887695\n",
      "Train Epoch: 777 [65792/118836 (55%)] Loss: 12183.541016\n",
      "Train Epoch: 777 [98560/118836 (83%)] Loss: 12290.333984\n",
      "    epoch          : 777\n",
      "    loss           : 12270.158878075888\n",
      "    val_loss       : 12268.987961247109\n",
      "    val_log_likelihood: -12186.2664668308\n",
      "    val_log_marginal: -12194.615664902361\n",
      "Train Epoch: 778 [256/118836 (0%)] Loss: 12333.277344\n",
      "Train Epoch: 778 [33024/118836 (28%)] Loss: 12285.877930\n",
      "Train Epoch: 778 [65792/118836 (55%)] Loss: 12321.441406\n",
      "Train Epoch: 778 [98560/118836 (83%)] Loss: 12265.953125\n",
      "    epoch          : 778\n",
      "    loss           : 12266.725901603857\n",
      "    val_loss       : 12271.05975193425\n",
      "    val_log_likelihood: -12182.261379659069\n",
      "    val_log_marginal: -12190.165472489301\n",
      "Train Epoch: 779 [256/118836 (0%)] Loss: 12220.968750\n",
      "Train Epoch: 779 [33024/118836 (28%)] Loss: 12236.891602\n",
      "Train Epoch: 779 [65792/118836 (55%)] Loss: 12286.245117\n",
      "Train Epoch: 779 [98560/118836 (83%)] Loss: 12297.439453\n",
      "    epoch          : 779\n",
      "    loss           : 12269.418318180054\n",
      "    val_loss       : 12275.260284132388\n",
      "    val_log_likelihood: -12187.710083391492\n",
      "    val_log_marginal: -12195.818121810451\n",
      "Train Epoch: 780 [256/118836 (0%)] Loss: 12294.300781\n",
      "Train Epoch: 780 [33024/118836 (28%)] Loss: 12272.492188\n",
      "Train Epoch: 780 [65792/118836 (55%)] Loss: 12272.648438\n",
      "Train Epoch: 780 [98560/118836 (83%)] Loss: 12270.354492\n",
      "    epoch          : 780\n",
      "    loss           : 12267.900954591863\n",
      "    val_loss       : 12269.129838997229\n",
      "    val_log_likelihood: -12188.038549097912\n",
      "    val_log_marginal: -12195.985131726642\n",
      "Train Epoch: 781 [256/118836 (0%)] Loss: 12305.364258\n",
      "Train Epoch: 781 [33024/118836 (28%)] Loss: 12238.673828\n",
      "Train Epoch: 781 [65792/118836 (55%)] Loss: 12307.083008\n",
      "Train Epoch: 781 [98560/118836 (83%)] Loss: 12323.283203\n",
      "    epoch          : 781\n",
      "    loss           : 12270.807477609336\n",
      "    val_loss       : 12265.973129609185\n",
      "    val_log_likelihood: -12181.698614557487\n",
      "    val_log_marginal: -12189.54024479413\n",
      "Train Epoch: 782 [256/118836 (0%)] Loss: 12295.896484\n",
      "Train Epoch: 782 [33024/118836 (28%)] Loss: 12217.454102\n",
      "Train Epoch: 782 [65792/118836 (55%)] Loss: 12233.631836\n",
      "Train Epoch: 782 [98560/118836 (83%)] Loss: 12218.019531\n",
      "    epoch          : 782\n",
      "    loss           : 12266.42940188172\n",
      "    val_loss       : 12271.335945895089\n",
      "    val_log_likelihood: -12185.250164779776\n",
      "    val_log_marginal: -12193.624205642802\n",
      "Train Epoch: 783 [256/118836 (0%)] Loss: 12284.422852\n",
      "Train Epoch: 783 [33024/118836 (28%)] Loss: 12297.523438\n",
      "Train Epoch: 783 [65792/118836 (55%)] Loss: 12277.500000\n",
      "Train Epoch: 783 [98560/118836 (83%)] Loss: 12315.715820\n",
      "    epoch          : 783\n",
      "    loss           : 12265.981292164237\n",
      "    val_loss       : 12268.04537202345\n",
      "    val_log_likelihood: -12184.902170408137\n",
      "    val_log_marginal: -12192.95987121053\n",
      "Train Epoch: 784 [256/118836 (0%)] Loss: 12319.780273\n",
      "Train Epoch: 784 [33024/118836 (28%)] Loss: 12206.783203\n",
      "Train Epoch: 784 [65792/118836 (55%)] Loss: 12238.192383\n",
      "Train Epoch: 784 [98560/118836 (83%)] Loss: 12337.190430\n",
      "    epoch          : 784\n",
      "    loss           : 12265.594448698563\n",
      "    val_loss       : 12267.69026699065\n",
      "    val_log_likelihood: -12185.567605749844\n",
      "    val_log_marginal: -12193.91154540256\n",
      "Train Epoch: 785 [256/118836 (0%)] Loss: 12302.528320\n",
      "Train Epoch: 785 [33024/118836 (28%)] Loss: 12300.944336\n",
      "Train Epoch: 785 [65792/118836 (55%)] Loss: 12240.646484\n",
      "Train Epoch: 785 [98560/118836 (83%)] Loss: 12221.943359\n",
      "    epoch          : 785\n",
      "    loss           : 12266.390497699544\n",
      "    val_loss       : 12272.388094183909\n",
      "    val_log_likelihood: -12183.8015151662\n",
      "    val_log_marginal: -12192.01938023593\n",
      "Train Epoch: 786 [256/118836 (0%)] Loss: 12260.761719\n",
      "Train Epoch: 786 [33024/118836 (28%)] Loss: 12257.620117\n",
      "Train Epoch: 786 [65792/118836 (55%)] Loss: 12251.589844\n",
      "Train Epoch: 786 [98560/118836 (83%)] Loss: 12385.937500\n",
      "    epoch          : 786\n",
      "    loss           : 12273.63370311854\n",
      "    val_loss       : 12273.307740963155\n",
      "    val_log_likelihood: -12185.578266193652\n",
      "    val_log_marginal: -12193.956387983484\n",
      "Train Epoch: 787 [256/118836 (0%)] Loss: 12278.548828\n",
      "Train Epoch: 787 [33024/118836 (28%)] Loss: 12308.135742\n",
      "Train Epoch: 787 [65792/118836 (55%)] Loss: 12267.272461\n",
      "Train Epoch: 787 [98560/118836 (83%)] Loss: 12330.788086\n",
      "    epoch          : 787\n",
      "    loss           : 12269.79968094112\n",
      "    val_loss       : 12268.44721982909\n",
      "    val_log_likelihood: -12183.157526720172\n",
      "    val_log_marginal: -12191.503814024307\n",
      "Train Epoch: 788 [256/118836 (0%)] Loss: 12203.331055\n",
      "Train Epoch: 788 [33024/118836 (28%)] Loss: 12396.990234\n",
      "Train Epoch: 788 [65792/118836 (55%)] Loss: 12319.554688\n",
      "Train Epoch: 788 [98560/118836 (83%)] Loss: 12252.192383\n",
      "    epoch          : 788\n",
      "    loss           : 12268.46388625026\n",
      "    val_loss       : 12276.445355172149\n",
      "    val_log_likelihood: -12191.70681283602\n",
      "    val_log_marginal: -12199.901725885107\n",
      "Train Epoch: 789 [256/118836 (0%)] Loss: 12305.035156\n",
      "Train Epoch: 789 [33024/118836 (28%)] Loss: 12255.552734\n",
      "Train Epoch: 789 [65792/118836 (55%)] Loss: 12335.360352\n",
      "Train Epoch: 789 [98560/118836 (83%)] Loss: 12245.547852\n",
      "    epoch          : 789\n",
      "    loss           : 12272.491274749274\n",
      "    val_loss       : 12270.6366191479\n",
      "    val_log_likelihood: -12183.43928882987\n",
      "    val_log_marginal: -12191.756574619823\n",
      "Train Epoch: 790 [256/118836 (0%)] Loss: 12355.103516\n",
      "Train Epoch: 790 [33024/118836 (28%)] Loss: 12400.010742\n",
      "Train Epoch: 790 [65792/118836 (55%)] Loss: 12348.005859\n",
      "Train Epoch: 790 [98560/118836 (83%)] Loss: 12310.056641\n",
      "    epoch          : 790\n",
      "    loss           : 12268.637840060224\n",
      "    val_loss       : 12268.478307390475\n",
      "    val_log_likelihood: -12184.922148179023\n",
      "    val_log_marginal: -12192.875113654607\n",
      "Train Epoch: 791 [256/118836 (0%)] Loss: 12217.052734\n",
      "Train Epoch: 791 [33024/118836 (28%)] Loss: 12323.961914\n",
      "Train Epoch: 791 [65792/118836 (55%)] Loss: 12223.549805\n",
      "Train Epoch: 791 [98560/118836 (83%)] Loss: 12327.423828\n",
      "    epoch          : 791\n",
      "    loss           : 12265.780374567048\n",
      "    val_loss       : 12267.219576678683\n",
      "    val_log_likelihood: -12184.150182388597\n",
      "    val_log_marginal: -12192.295587519524\n",
      "Train Epoch: 792 [256/118836 (0%)] Loss: 12245.907227\n",
      "Train Epoch: 792 [33024/118836 (28%)] Loss: 12239.689453\n",
      "Train Epoch: 792 [65792/118836 (55%)] Loss: 12319.575195\n",
      "Train Epoch: 792 [98560/118836 (83%)] Loss: 12329.383789\n",
      "    epoch          : 792\n",
      "    loss           : 12270.254457939154\n",
      "    val_loss       : 12266.512553869345\n",
      "    val_log_likelihood: -12184.271649800972\n",
      "    val_log_marginal: -12192.53816385633\n",
      "Train Epoch: 793 [256/118836 (0%)] Loss: 12417.931641\n",
      "Train Epoch: 793 [33024/118836 (28%)] Loss: 12322.194336\n",
      "Train Epoch: 793 [65792/118836 (55%)] Loss: 12374.288086\n",
      "Train Epoch: 793 [98560/118836 (83%)] Loss: 12270.389648\n",
      "    epoch          : 793\n",
      "    loss           : 12273.260964801748\n",
      "    val_loss       : 12270.829818746808\n",
      "    val_log_likelihood: -12184.288108069686\n",
      "    val_log_marginal: -12192.489288980345\n",
      "Train Epoch: 794 [256/118836 (0%)] Loss: 12329.956055\n",
      "Train Epoch: 794 [33024/118836 (28%)] Loss: 12298.735352\n",
      "Train Epoch: 794 [65792/118836 (55%)] Loss: 12325.983398\n",
      "Train Epoch: 794 [98560/118836 (83%)] Loss: 12264.016602\n",
      "    epoch          : 794\n",
      "    loss           : 12268.214667015613\n",
      "    val_loss       : 12266.569531605139\n",
      "    val_log_likelihood: -12182.427225819376\n",
      "    val_log_marginal: -12190.711414138199\n",
      "Train Epoch: 795 [256/118836 (0%)] Loss: 12245.320312\n",
      "Train Epoch: 795 [33024/118836 (28%)] Loss: 12281.026367\n",
      "Train Epoch: 795 [65792/118836 (55%)] Loss: 12229.250000\n",
      "Train Epoch: 795 [98560/118836 (83%)] Loss: 12353.343750\n",
      "    epoch          : 795\n",
      "    loss           : 12261.315476859749\n",
      "    val_loss       : 12271.982488015863\n",
      "    val_log_likelihood: -12183.24490442773\n",
      "    val_log_marginal: -12191.361693497081\n",
      "Train Epoch: 796 [256/118836 (0%)] Loss: 12400.416992\n",
      "Train Epoch: 796 [33024/118836 (28%)] Loss: 12351.263672\n",
      "Train Epoch: 796 [65792/118836 (55%)] Loss: 12300.958984\n",
      "Train Epoch: 796 [98560/118836 (83%)] Loss: 12269.422852\n",
      "    epoch          : 796\n",
      "    loss           : 12266.911009389216\n",
      "    val_loss       : 12266.23008578727\n",
      "    val_log_likelihood: -12182.794341753257\n",
      "    val_log_marginal: -12190.83104019241\n",
      "Train Epoch: 797 [256/118836 (0%)] Loss: 12252.320312\n",
      "Train Epoch: 797 [33024/118836 (28%)] Loss: 12359.541016\n",
      "Train Epoch: 797 [65792/118836 (55%)] Loss: 12189.152344\n",
      "Train Epoch: 797 [98560/118836 (83%)] Loss: 12260.370117\n",
      "    epoch          : 797\n",
      "    loss           : 12270.80339155552\n",
      "    val_loss       : 12268.899639831196\n",
      "    val_log_likelihood: -12185.422966908343\n",
      "    val_log_marginal: -12193.433480948952\n",
      "Train Epoch: 798 [256/118836 (0%)] Loss: 12271.900391\n",
      "Train Epoch: 798 [33024/118836 (28%)] Loss: 12252.758789\n",
      "Train Epoch: 798 [65792/118836 (55%)] Loss: 12339.810547\n",
      "Train Epoch: 798 [98560/118836 (83%)] Loss: 12300.598633\n",
      "    epoch          : 798\n",
      "    loss           : 12271.843090880893\n",
      "    val_loss       : 12270.637580431341\n",
      "    val_log_likelihood: -12185.961113749741\n",
      "    val_log_marginal: -12193.906926293941\n",
      "Train Epoch: 799 [256/118836 (0%)] Loss: 12353.286133\n",
      "Train Epoch: 799 [33024/118836 (28%)] Loss: 12309.563477\n",
      "Train Epoch: 799 [65792/118836 (55%)] Loss: 12317.893555\n",
      "Train Epoch: 799 [98560/118836 (83%)] Loss: 12268.773438\n",
      "    epoch          : 799\n",
      "    loss           : 12267.137964129704\n",
      "    val_loss       : 12267.06359071382\n",
      "    val_log_likelihood: -12186.447038972034\n",
      "    val_log_marginal: -12194.766889123737\n",
      "Train Epoch: 800 [256/118836 (0%)] Loss: 12306.958984\n",
      "Train Epoch: 800 [33024/118836 (28%)] Loss: 12244.868164\n",
      "Train Epoch: 800 [65792/118836 (55%)] Loss: 12249.515625\n",
      "Train Epoch: 800 [98560/118836 (83%)] Loss: 12232.251953\n",
      "    epoch          : 800\n",
      "    loss           : 12271.195443516077\n",
      "    val_loss       : 12265.902750006644\n",
      "    val_log_likelihood: -12184.411582079714\n",
      "    val_log_marginal: -12192.749754574757\n",
      "Saving checkpoint: saved/models/SelfiesAutoencodingOperad/0905_154251/checkpoint-epoch800.pth ...\n",
      "Train Epoch: 801 [256/118836 (0%)] Loss: 12265.861328\n",
      "Train Epoch: 801 [33024/118836 (28%)] Loss: 12241.434570\n",
      "Train Epoch: 801 [65792/118836 (55%)] Loss: 12275.253906\n",
      "Train Epoch: 801 [98560/118836 (83%)] Loss: 12325.550781\n",
      "    epoch          : 801\n",
      "    loss           : 12269.259266439207\n",
      "    val_loss       : 12272.493025375486\n",
      "    val_log_likelihood: -12184.223760436053\n",
      "    val_log_marginal: -12192.48335405659\n",
      "Train Epoch: 802 [256/118836 (0%)] Loss: 12240.998047\n",
      "Train Epoch: 802 [33024/118836 (28%)] Loss: 12290.672852\n",
      "Train Epoch: 802 [65792/118836 (55%)] Loss: 12214.302734\n",
      "Train Epoch: 802 [98560/118836 (83%)] Loss: 12230.251953\n",
      "    epoch          : 802\n",
      "    loss           : 12270.793550810327\n",
      "    val_loss       : 12269.049184940617\n",
      "    val_log_likelihood: -12185.01766439206\n",
      "    val_log_marginal: -12193.022954483391\n",
      "Train Epoch: 803 [256/118836 (0%)] Loss: 12255.983398\n",
      "Train Epoch: 803 [33024/118836 (28%)] Loss: 12308.780273\n",
      "Train Epoch: 803 [65792/118836 (55%)] Loss: 12261.006836\n",
      "Train Epoch: 803 [98560/118836 (83%)] Loss: 12182.327148\n",
      "    epoch          : 803\n",
      "    loss           : 12269.39170673077\n",
      "    val_loss       : 12263.291994324709\n",
      "    val_log_likelihood: -12181.866466669251\n",
      "    val_log_marginal: -12189.971177881042\n",
      "Train Epoch: 804 [256/118836 (0%)] Loss: 12242.227539\n",
      "Train Epoch: 804 [33024/118836 (28%)] Loss: 12304.916016\n",
      "Train Epoch: 804 [65792/118836 (55%)] Loss: 12274.877930\n",
      "Train Epoch: 804 [98560/118836 (83%)] Loss: 12280.562500\n",
      "    epoch          : 804\n",
      "    loss           : 12267.941127739867\n",
      "    val_loss       : 12267.072784588876\n",
      "    val_log_likelihood: -12181.701732449337\n",
      "    val_log_marginal: -12189.825017869824\n",
      "Train Epoch: 805 [256/118836 (0%)] Loss: 12362.750000\n",
      "Train Epoch: 805 [33024/118836 (28%)] Loss: 12345.383789\n",
      "Train Epoch: 805 [65792/118836 (55%)] Loss: 12382.643555\n",
      "Train Epoch: 805 [98560/118836 (83%)] Loss: 12374.923828\n",
      "    epoch          : 805\n",
      "    loss           : 12268.164906107837\n",
      "    val_loss       : 12272.877832209264\n",
      "    val_log_likelihood: -12183.512711952026\n",
      "    val_log_marginal: -12192.100924036858\n",
      "Train Epoch: 806 [256/118836 (0%)] Loss: 12257.915039\n",
      "Train Epoch: 806 [33024/118836 (28%)] Loss: 12320.876953\n",
      "Train Epoch: 806 [65792/118836 (55%)] Loss: 12280.815430\n",
      "Train Epoch: 806 [98560/118836 (83%)] Loss: 12182.838867\n",
      "    epoch          : 806\n",
      "    loss           : 12270.737127953113\n",
      "    val_loss       : 12271.056208408716\n",
      "    val_log_likelihood: -12183.586938941016\n",
      "    val_log_marginal: -12191.824860191646\n",
      "Train Epoch: 807 [256/118836 (0%)] Loss: 12227.070312\n",
      "Train Epoch: 807 [33024/118836 (28%)] Loss: 12233.414062\n",
      "Train Epoch: 807 [65792/118836 (55%)] Loss: 12241.405273\n",
      "Train Epoch: 807 [98560/118836 (83%)] Loss: 12266.005859\n",
      "    epoch          : 807\n",
      "    loss           : 12265.01621643016\n",
      "    val_loss       : 12265.551650545742\n",
      "    val_log_likelihood: -12182.34295001034\n",
      "    val_log_marginal: -12190.211986616136\n",
      "Train Epoch: 808 [256/118836 (0%)] Loss: 12320.003906\n",
      "Train Epoch: 808 [33024/118836 (28%)] Loss: 12283.085938\n",
      "Train Epoch: 808 [65792/118836 (55%)] Loss: 12352.199219\n",
      "Train Epoch: 808 [98560/118836 (83%)] Loss: 12347.169922\n",
      "    epoch          : 808\n",
      "    loss           : 12266.338389164597\n",
      "    val_loss       : 12266.994363477901\n",
      "    val_log_likelihood: -12188.492758251912\n",
      "    val_log_marginal: -12196.617296534465\n",
      "Train Epoch: 809 [256/118836 (0%)] Loss: 12258.680664\n",
      "Train Epoch: 809 [33024/118836 (28%)] Loss: 12313.625977\n",
      "Train Epoch: 809 [65792/118836 (55%)] Loss: 12268.469727\n",
      "Train Epoch: 809 [98560/118836 (83%)] Loss: 12266.046875\n",
      "    epoch          : 809\n",
      "    loss           : 12267.787240229529\n",
      "    val_loss       : 12265.829620843593\n",
      "    val_log_likelihood: -12182.898545899247\n",
      "    val_log_marginal: -12190.966100172973\n",
      "Train Epoch: 810 [256/118836 (0%)] Loss: 12250.819336\n",
      "Train Epoch: 810 [33024/118836 (28%)] Loss: 12324.466797\n",
      "Train Epoch: 810 [65792/118836 (55%)] Loss: 12240.753906\n",
      "Train Epoch: 810 [98560/118836 (83%)] Loss: 12274.444336\n",
      "    epoch          : 810\n",
      "    loss           : 12272.213047973532\n",
      "    val_loss       : 12266.642918864072\n",
      "    val_log_likelihood: -12184.274553317566\n",
      "    val_log_marginal: -12192.237552602226\n",
      "Train Epoch: 811 [256/118836 (0%)] Loss: 12305.661133\n",
      "Train Epoch: 811 [33024/118836 (28%)] Loss: 12249.279297\n",
      "Train Epoch: 811 [65792/118836 (55%)] Loss: 12269.381836\n",
      "Train Epoch: 811 [98560/118836 (83%)] Loss: 12439.354492\n",
      "    epoch          : 811\n",
      "    loss           : 12271.138618240799\n",
      "    val_loss       : 12269.313140095535\n",
      "    val_log_likelihood: -12183.33405997984\n",
      "    val_log_marginal: -12191.240437765233\n",
      "Train Epoch: 812 [256/118836 (0%)] Loss: 12196.904297\n",
      "Train Epoch: 812 [33024/118836 (28%)] Loss: 12340.505859\n",
      "Train Epoch: 812 [65792/118836 (55%)] Loss: 12369.649414\n",
      "Train Epoch: 812 [98560/118836 (83%)] Loss: 12272.091797\n",
      "    epoch          : 812\n",
      "    loss           : 12272.13541747441\n",
      "    val_loss       : 12272.475463940136\n",
      "    val_log_likelihood: -12183.38304141465\n",
      "    val_log_marginal: -12191.305211868052\n",
      "Train Epoch: 813 [256/118836 (0%)] Loss: 12270.708008\n",
      "Train Epoch: 813 [33024/118836 (28%)] Loss: 12194.208008\n",
      "Train Epoch: 813 [65792/118836 (55%)] Loss: 12299.248047\n",
      "Train Epoch: 813 [98560/118836 (83%)] Loss: 12374.920898\n",
      "    epoch          : 813\n",
      "    loss           : 12267.235177089795\n",
      "    val_loss       : 12271.366442191535\n",
      "    val_log_likelihood: -12182.486789669923\n",
      "    val_log_marginal: -12190.400262757783\n",
      "Train Epoch: 814 [256/118836 (0%)] Loss: 12306.832031\n",
      "Train Epoch: 814 [33024/118836 (28%)] Loss: 12240.889648\n",
      "Train Epoch: 814 [65792/118836 (55%)] Loss: 12273.152344\n",
      "Train Epoch: 814 [98560/118836 (83%)] Loss: 12247.553711\n",
      "    epoch          : 814\n",
      "    loss           : 12267.861202763132\n",
      "    val_loss       : 12268.142774918295\n",
      "    val_log_likelihood: -12180.769626563791\n",
      "    val_log_marginal: -12188.707537625129\n",
      "Train Epoch: 815 [256/118836 (0%)] Loss: 12185.839844\n",
      "Train Epoch: 815 [33024/118836 (28%)] Loss: 12391.023438\n",
      "Train Epoch: 815 [65792/118836 (55%)] Loss: 12242.609375\n",
      "Train Epoch: 815 [98560/118836 (83%)] Loss: 12312.762695\n",
      "    epoch          : 815\n",
      "    loss           : 12270.460427490436\n",
      "    val_loss       : 12270.270832843158\n",
      "    val_log_likelihood: -12184.42569110577\n",
      "    val_log_marginal: -12192.627054280607\n",
      "Train Epoch: 816 [256/118836 (0%)] Loss: 12302.121094\n",
      "Train Epoch: 816 [33024/118836 (28%)] Loss: 12368.734375\n",
      "Train Epoch: 816 [65792/118836 (55%)] Loss: 12304.535156\n",
      "Train Epoch: 816 [98560/118836 (83%)] Loss: 12221.494141\n",
      "    epoch          : 816\n",
      "    loss           : 12270.144244177782\n",
      "    val_loss       : 12266.623058868061\n",
      "    val_log_likelihood: -12183.577038261219\n",
      "    val_log_marginal: -12191.616785224105\n",
      "Train Epoch: 817 [256/118836 (0%)] Loss: 12234.633789\n",
      "Train Epoch: 817 [33024/118836 (28%)] Loss: 12285.190430\n",
      "Train Epoch: 817 [65792/118836 (55%)] Loss: 12244.863281\n",
      "Train Epoch: 817 [98560/118836 (83%)] Loss: 12288.170898\n",
      "    epoch          : 817\n",
      "    loss           : 12269.514509020886\n",
      "    val_loss       : 12268.876012666598\n",
      "    val_log_likelihood: -12182.839874282723\n",
      "    val_log_marginal: -12190.791373808543\n",
      "Train Epoch: 818 [256/118836 (0%)] Loss: 12300.187500\n",
      "Train Epoch: 818 [33024/118836 (28%)] Loss: 12286.356445\n",
      "Train Epoch: 818 [65792/118836 (55%)] Loss: 12277.656250\n",
      "Train Epoch: 818 [98560/118836 (83%)] Loss: 12299.524414\n",
      "    epoch          : 818\n",
      "    loss           : 12265.960147526366\n",
      "    val_loss       : 12268.047759980764\n",
      "    val_log_likelihood: -12180.395372434605\n",
      "    val_log_marginal: -12188.368673619894\n",
      "Train Epoch: 819 [256/118836 (0%)] Loss: 12263.358398\n",
      "Train Epoch: 819 [33024/118836 (28%)] Loss: 12310.984375\n",
      "Train Epoch: 819 [65792/118836 (55%)] Loss: 12370.982422\n",
      "Train Epoch: 819 [98560/118836 (83%)] Loss: 12252.021484\n",
      "    epoch          : 819\n",
      "    loss           : 12268.559345598118\n",
      "    val_loss       : 12266.819776162949\n",
      "    val_log_likelihood: -12182.466887826975\n",
      "    val_log_marginal: -12190.402259396136\n",
      "Train Epoch: 820 [256/118836 (0%)] Loss: 12279.243164\n",
      "Train Epoch: 820 [33024/118836 (28%)] Loss: 12371.623047\n",
      "Train Epoch: 820 [65792/118836 (55%)] Loss: 12330.236328\n",
      "Train Epoch: 820 [98560/118836 (83%)] Loss: 12335.859375\n",
      "    epoch          : 820\n",
      "    loss           : 12271.2716796875\n",
      "    val_loss       : 12268.961677307923\n",
      "    val_log_likelihood: -12184.657286820202\n",
      "    val_log_marginal: -12192.790960390097\n",
      "Train Epoch: 821 [256/118836 (0%)] Loss: 12337.204102\n",
      "Train Epoch: 821 [33024/118836 (28%)] Loss: 12347.690430\n",
      "Train Epoch: 821 [65792/118836 (55%)] Loss: 12231.171875\n",
      "Train Epoch: 821 [98560/118836 (83%)] Loss: 12401.940430\n",
      "    epoch          : 821\n",
      "    loss           : 12269.542256965984\n",
      "    val_loss       : 12267.314170659862\n",
      "    val_log_likelihood: -12184.64348473687\n",
      "    val_log_marginal: -12192.638867143078\n",
      "Train Epoch: 822 [256/118836 (0%)] Loss: 12252.464844\n",
      "Train Epoch: 822 [33024/118836 (28%)] Loss: 12217.103516\n",
      "Train Epoch: 822 [65792/118836 (55%)] Loss: 12286.725586\n",
      "Train Epoch: 822 [98560/118836 (83%)] Loss: 12364.837891\n",
      "    epoch          : 822\n",
      "    loss           : 12267.638409035102\n",
      "    val_loss       : 12270.763865948791\n",
      "    val_log_likelihood: -12186.625815498346\n",
      "    val_log_marginal: -12194.906510759562\n",
      "Train Epoch: 823 [256/118836 (0%)] Loss: 12251.535156\n",
      "Train Epoch: 823 [33024/118836 (28%)] Loss: 12313.250000\n",
      "Train Epoch: 823 [65792/118836 (55%)] Loss: 12285.066406\n",
      "Train Epoch: 823 [98560/118836 (83%)] Loss: 12338.854492\n",
      "    epoch          : 823\n",
      "    loss           : 12267.393176340209\n",
      "    val_loss       : 12268.851209043767\n",
      "    val_log_likelihood: -12183.630579572477\n",
      "    val_log_marginal: -12191.53843086902\n",
      "Train Epoch: 824 [256/118836 (0%)] Loss: 12285.000000\n",
      "Train Epoch: 824 [33024/118836 (28%)] Loss: 12272.785156\n",
      "Train Epoch: 824 [65792/118836 (55%)] Loss: 12310.248047\n",
      "Train Epoch: 824 [98560/118836 (83%)] Loss: 12231.510742\n",
      "    epoch          : 824\n",
      "    loss           : 12270.90197719577\n",
      "    val_loss       : 12267.010930452083\n",
      "    val_log_likelihood: -12181.884081627379\n",
      "    val_log_marginal: -12189.918509955682\n",
      "Train Epoch: 825 [256/118836 (0%)] Loss: 12247.749023\n",
      "Train Epoch: 825 [33024/118836 (28%)] Loss: 12225.109375\n",
      "Train Epoch: 825 [65792/118836 (55%)] Loss: 12200.323242\n",
      "Train Epoch: 825 [98560/118836 (83%)] Loss: 12331.534180\n",
      "    epoch          : 825\n",
      "    loss           : 12267.507773566738\n",
      "    val_loss       : 12267.89472970208\n",
      "    val_log_likelihood: -12183.405843866316\n",
      "    val_log_marginal: -12191.424106341594\n",
      "Train Epoch: 826 [256/118836 (0%)] Loss: 12396.611328\n",
      "Train Epoch: 826 [33024/118836 (28%)] Loss: 12310.666016\n",
      "Train Epoch: 826 [65792/118836 (55%)] Loss: 12270.726562\n",
      "Train Epoch: 826 [98560/118836 (83%)] Loss: 12228.425781\n",
      "    epoch          : 826\n",
      "    loss           : 12267.136341210453\n",
      "    val_loss       : 12268.213745846155\n",
      "    val_log_likelihood: -12182.193102835505\n",
      "    val_log_marginal: -12190.156268758952\n",
      "Train Epoch: 827 [256/118836 (0%)] Loss: 12213.535156\n",
      "Train Epoch: 827 [33024/118836 (28%)] Loss: 12209.652344\n",
      "Train Epoch: 827 [65792/118836 (55%)] Loss: 12275.628906\n",
      "Train Epoch: 827 [98560/118836 (83%)] Loss: 12193.405273\n",
      "    epoch          : 827\n",
      "    loss           : 12265.122049634252\n",
      "    val_loss       : 12270.161658937452\n",
      "    val_log_likelihood: -12185.982730594758\n",
      "    val_log_marginal: -12194.215368968893\n",
      "Train Epoch: 828 [256/118836 (0%)] Loss: 12210.298828\n",
      "Train Epoch: 828 [33024/118836 (28%)] Loss: 12378.378906\n",
      "Train Epoch: 828 [65792/118836 (55%)] Loss: 12358.109375\n",
      "Train Epoch: 828 [98560/118836 (83%)] Loss: 12246.962891\n",
      "    epoch          : 828\n",
      "    loss           : 12270.352328402863\n",
      "    val_loss       : 12264.611140761695\n",
      "    val_log_likelihood: -12183.504424498553\n",
      "    val_log_marginal: -12191.663316669203\n",
      "Train Epoch: 829 [256/118836 (0%)] Loss: 12289.482422\n",
      "Train Epoch: 829 [33024/118836 (28%)] Loss: 12267.840820\n",
      "Train Epoch: 829 [65792/118836 (55%)] Loss: 12233.693359\n",
      "Train Epoch: 829 [98560/118836 (83%)] Loss: 12255.056641\n",
      "    epoch          : 829\n",
      "    loss           : 12267.766142440807\n",
      "    val_loss       : 12265.94790718479\n",
      "    val_log_likelihood: -12182.461672062396\n",
      "    val_log_marginal: -12190.418077603315\n",
      "Train Epoch: 830 [256/118836 (0%)] Loss: 12309.709961\n",
      "Train Epoch: 830 [33024/118836 (28%)] Loss: 12268.558594\n",
      "Train Epoch: 830 [65792/118836 (55%)] Loss: 12295.979492\n",
      "Train Epoch: 830 [98560/118836 (83%)] Loss: 12280.930664\n",
      "    epoch          : 830\n",
      "    loss           : 12270.194894088607\n",
      "    val_loss       : 12271.08567286892\n",
      "    val_log_likelihood: -12184.60392515121\n",
      "    val_log_marginal: -12192.856701204537\n",
      "Train Epoch: 831 [256/118836 (0%)] Loss: 12305.313477\n",
      "Train Epoch: 831 [33024/118836 (28%)] Loss: 12268.267578\n",
      "Train Epoch: 831 [65792/118836 (55%)] Loss: 12385.683594\n",
      "Train Epoch: 831 [98560/118836 (83%)] Loss: 12250.036133\n",
      "    epoch          : 831\n",
      "    loss           : 12267.883412169149\n",
      "    val_loss       : 12271.65396651106\n",
      "    val_log_likelihood: -12182.711478365385\n",
      "    val_log_marginal: -12191.070929479527\n",
      "Train Epoch: 832 [256/118836 (0%)] Loss: 12168.125000\n",
      "Train Epoch: 832 [33024/118836 (28%)] Loss: 12316.900391\n",
      "Train Epoch: 832 [65792/118836 (55%)] Loss: 12285.105469\n",
      "Train Epoch: 832 [98560/118836 (83%)] Loss: 12306.875000\n",
      "    epoch          : 832\n",
      "    loss           : 12270.9860858018\n",
      "    val_loss       : 12273.982591845064\n",
      "    val_log_likelihood: -12184.934200204198\n",
      "    val_log_marginal: -12193.040131776654\n",
      "Train Epoch: 833 [256/118836 (0%)] Loss: 12239.679688\n",
      "Train Epoch: 833 [33024/118836 (28%)] Loss: 12242.083008\n",
      "Train Epoch: 833 [65792/118836 (55%)] Loss: 12243.509766\n",
      "Train Epoch: 833 [98560/118836 (83%)] Loss: 12183.264648\n",
      "    epoch          : 833\n",
      "    loss           : 12267.85566810122\n",
      "    val_loss       : 12270.282271057602\n",
      "    val_log_likelihood: -12194.819743848222\n",
      "    val_log_marginal: -12203.176835680963\n",
      "Train Epoch: 834 [256/118836 (0%)] Loss: 12324.518555\n",
      "Train Epoch: 834 [33024/118836 (28%)] Loss: 12317.847656\n",
      "Train Epoch: 834 [65792/118836 (55%)] Loss: 12339.293945\n",
      "Train Epoch: 834 [98560/118836 (83%)] Loss: 12333.387695\n",
      "    epoch          : 834\n",
      "    loss           : 12269.962943128361\n",
      "    val_loss       : 12270.864437740907\n",
      "    val_log_likelihood: -12184.566731447736\n",
      "    val_log_marginal: -12192.662300425845\n",
      "Train Epoch: 835 [256/118836 (0%)] Loss: 12331.906250\n",
      "Train Epoch: 835 [33024/118836 (28%)] Loss: 12185.837891\n",
      "Train Epoch: 835 [65792/118836 (55%)] Loss: 12266.133789\n",
      "Train Epoch: 835 [98560/118836 (83%)] Loss: 12317.426758\n",
      "    epoch          : 835\n",
      "    loss           : 12270.26350499509\n",
      "    val_loss       : 12268.676043491309\n",
      "    val_log_likelihood: -12185.614670246587\n",
      "    val_log_marginal: -12193.465857858622\n",
      "Train Epoch: 836 [256/118836 (0%)] Loss: 12260.998047\n",
      "Train Epoch: 836 [33024/118836 (28%)] Loss: 12305.558594\n",
      "Train Epoch: 836 [65792/118836 (55%)] Loss: 12197.908203\n",
      "Train Epoch: 836 [98560/118836 (83%)] Loss: 12260.764648\n",
      "    epoch          : 836\n",
      "    loss           : 12267.902262490954\n",
      "    val_loss       : 12268.73229760557\n",
      "    val_log_likelihood: -12182.860542028535\n",
      "    val_log_marginal: -12191.245540688396\n",
      "Train Epoch: 837 [256/118836 (0%)] Loss: 12299.917969\n",
      "Train Epoch: 837 [33024/118836 (28%)] Loss: 12306.551758\n",
      "Train Epoch: 837 [65792/118836 (55%)] Loss: 12266.276367\n",
      "Train Epoch: 837 [98560/118836 (83%)] Loss: 12318.791016\n",
      "    epoch          : 837\n",
      "    loss           : 12268.440895594242\n",
      "    val_loss       : 12267.506399804979\n",
      "    val_log_likelihood: -12186.230739505789\n",
      "    val_log_marginal: -12194.383778958061\n",
      "Train Epoch: 838 [256/118836 (0%)] Loss: 12260.463867\n",
      "Train Epoch: 838 [33024/118836 (28%)] Loss: 12247.304688\n",
      "Train Epoch: 838 [65792/118836 (55%)] Loss: 12351.833984\n",
      "Train Epoch: 838 [98560/118836 (83%)] Loss: 12212.626953\n",
      "    epoch          : 838\n",
      "    loss           : 12267.412973984181\n",
      "    val_loss       : 12275.04209144827\n",
      "    val_log_likelihood: -12187.271609736868\n",
      "    val_log_marginal: -12195.53567816516\n",
      "Train Epoch: 839 [256/118836 (0%)] Loss: 12288.427734\n",
      "Train Epoch: 839 [33024/118836 (28%)] Loss: 12292.501953\n",
      "Train Epoch: 839 [65792/118836 (55%)] Loss: 12342.947266\n",
      "Train Epoch: 839 [98560/118836 (83%)] Loss: 12311.653320\n",
      "    epoch          : 839\n",
      "    loss           : 12268.456510739763\n",
      "    val_loss       : 12264.689546921209\n",
      "    val_log_likelihood: -12184.93777334057\n",
      "    val_log_marginal: -12192.965222473647\n",
      "Train Epoch: 840 [256/118836 (0%)] Loss: 12403.740234\n",
      "Train Epoch: 840 [33024/118836 (28%)] Loss: 12262.939453\n",
      "Train Epoch: 840 [65792/118836 (55%)] Loss: 12269.111328\n",
      "Train Epoch: 840 [98560/118836 (83%)] Loss: 12305.875977\n",
      "    epoch          : 840\n",
      "    loss           : 12266.884453835815\n",
      "    val_loss       : 12267.32059878283\n",
      "    val_log_likelihood: -12180.460301320823\n",
      "    val_log_marginal: -12188.478464641456\n",
      "Train Epoch: 841 [256/118836 (0%)] Loss: 12175.134766\n",
      "Train Epoch: 841 [33024/118836 (28%)] Loss: 12348.387695\n",
      "Train Epoch: 841 [65792/118836 (55%)] Loss: 12271.947266\n",
      "Train Epoch: 841 [98560/118836 (83%)] Loss: 12225.853516\n",
      "    epoch          : 841\n",
      "    loss           : 12267.370652721775\n",
      "    val_loss       : 12266.044497818652\n",
      "    val_log_likelihood: -12185.020958695202\n",
      "    val_log_marginal: -12192.933315417193\n",
      "Train Epoch: 842 [256/118836 (0%)] Loss: 12249.180664\n",
      "Train Epoch: 842 [33024/118836 (28%)] Loss: 12335.423828\n",
      "Train Epoch: 842 [65792/118836 (55%)] Loss: 12243.322266\n",
      "Train Epoch: 842 [98560/118836 (83%)] Loss: 12277.160156\n",
      "    epoch          : 842\n",
      "    loss           : 12268.274115843415\n",
      "    val_loss       : 12270.37714760846\n",
      "    val_log_likelihood: -12184.911189193032\n",
      "    val_log_marginal: -12192.931394741629\n",
      "Train Epoch: 843 [256/118836 (0%)] Loss: 12284.181641\n",
      "Train Epoch: 843 [33024/118836 (28%)] Loss: 12267.712891\n",
      "Train Epoch: 843 [65792/118836 (55%)] Loss: 12312.989258\n",
      "Train Epoch: 843 [98560/118836 (83%)] Loss: 12347.813477\n",
      "    epoch          : 843\n",
      "    loss           : 12269.29497987102\n",
      "    val_loss       : 12260.539819599564\n",
      "    val_log_likelihood: -12184.782864680263\n",
      "    val_log_marginal: -12192.95292003457\n",
      "Train Epoch: 844 [256/118836 (0%)] Loss: 12256.412109\n",
      "Train Epoch: 844 [33024/118836 (28%)] Loss: 12233.476562\n",
      "Train Epoch: 844 [65792/118836 (55%)] Loss: 12267.197266\n",
      "Train Epoch: 844 [98560/118836 (83%)] Loss: 12383.699219\n",
      "    epoch          : 844\n",
      "    loss           : 12271.094597646557\n",
      "    val_loss       : 12269.30369980627\n",
      "    val_log_likelihood: -12186.598939270574\n",
      "    val_log_marginal: -12194.63024724676\n",
      "Train Epoch: 845 [256/118836 (0%)] Loss: 12213.707031\n",
      "Train Epoch: 845 [33024/118836 (28%)] Loss: 12231.653320\n",
      "Train Epoch: 845 [65792/118836 (55%)] Loss: 12359.037109\n",
      "Train Epoch: 845 [98560/118836 (83%)] Loss: 12275.777344\n",
      "    epoch          : 845\n",
      "    loss           : 12265.774523592587\n",
      "    val_loss       : 12263.880262289973\n",
      "    val_log_likelihood: -12184.347953822891\n",
      "    val_log_marginal: -12192.735620442583\n",
      "Train Epoch: 846 [256/118836 (0%)] Loss: 12278.255859\n",
      "Train Epoch: 846 [33024/118836 (28%)] Loss: 12252.739258\n",
      "Train Epoch: 846 [65792/118836 (55%)] Loss: 12323.960938\n",
      "Train Epoch: 846 [98560/118836 (83%)] Loss: 12194.590820\n",
      "    epoch          : 846\n",
      "    loss           : 12273.820787938119\n",
      "    val_loss       : 12273.591681266458\n",
      "    val_log_likelihood: -12187.058000704354\n",
      "    val_log_marginal: -12195.305430693972\n",
      "Train Epoch: 847 [256/118836 (0%)] Loss: 12247.305664\n",
      "Train Epoch: 847 [33024/118836 (28%)] Loss: 12311.933594\n",
      "Train Epoch: 847 [65792/118836 (55%)] Loss: 12264.038086\n",
      "Train Epoch: 847 [98560/118836 (83%)] Loss: 12341.486328\n",
      "    epoch          : 847\n",
      "    loss           : 12268.719829469086\n",
      "    val_loss       : 12266.429120634844\n",
      "    val_log_likelihood: -12185.162001460401\n",
      "    val_log_marginal: -12193.353278502907\n",
      "Train Epoch: 848 [256/118836 (0%)] Loss: 12318.215820\n",
      "Train Epoch: 848 [33024/118836 (28%)] Loss: 12261.244141\n",
      "Train Epoch: 848 [65792/118836 (55%)] Loss: 12230.689453\n",
      "Train Epoch: 848 [98560/118836 (83%)] Loss: 12325.896484\n",
      "    epoch          : 848\n",
      "    loss           : 12270.770886159791\n",
      "    val_loss       : 12277.176543042457\n",
      "    val_log_likelihood: -12184.324782716863\n",
      "    val_log_marginal: -12192.461181046952\n",
      "Train Epoch: 849 [256/118836 (0%)] Loss: 12348.066406\n",
      "Train Epoch: 849 [33024/118836 (28%)] Loss: 12471.430664\n",
      "Train Epoch: 849 [65792/118836 (55%)] Loss: 12259.974609\n",
      "Train Epoch: 849 [98560/118836 (83%)] Loss: 12218.246094\n",
      "    epoch          : 849\n",
      "    loss           : 12270.566172973531\n",
      "    val_loss       : 12267.741011927179\n",
      "    val_log_likelihood: -12181.907961447994\n",
      "    val_log_marginal: -12190.067774081337\n",
      "Train Epoch: 850 [256/118836 (0%)] Loss: 12243.781250\n",
      "Train Epoch: 850 [33024/118836 (28%)] Loss: 12328.758789\n",
      "Train Epoch: 850 [65792/118836 (55%)] Loss: 12237.830078\n",
      "Train Epoch: 850 [98560/118836 (83%)] Loss: 12300.341797\n",
      "    epoch          : 850\n",
      "    loss           : 12268.598769482785\n",
      "    val_loss       : 12268.217305289325\n",
      "    val_log_likelihood: -12184.806365830489\n",
      "    val_log_marginal: -12192.834632711294\n",
      "Train Epoch: 851 [256/118836 (0%)] Loss: 12205.451172\n",
      "Train Epoch: 851 [33024/118836 (28%)] Loss: 12321.949219\n",
      "Train Epoch: 851 [65792/118836 (55%)] Loss: 12283.734375\n",
      "Train Epoch: 851 [98560/118836 (83%)] Loss: 12274.485352\n",
      "    epoch          : 851\n",
      "    loss           : 12269.643291847602\n",
      "    val_loss       : 12267.250022875663\n",
      "    val_log_likelihood: -12184.011891445667\n",
      "    val_log_marginal: -12192.0501539476\n",
      "Train Epoch: 852 [256/118836 (0%)] Loss: 12336.438477\n",
      "Train Epoch: 852 [33024/118836 (28%)] Loss: 12464.806641\n",
      "Train Epoch: 852 [65792/118836 (55%)] Loss: 12291.894531\n",
      "Train Epoch: 852 [98560/118836 (83%)] Loss: 12303.029297\n",
      "    epoch          : 852\n",
      "    loss           : 12272.055309462881\n",
      "    val_loss       : 12270.359047841286\n",
      "    val_log_likelihood: -12182.962846522178\n",
      "    val_log_marginal: -12191.220712454771\n",
      "Train Epoch: 853 [256/118836 (0%)] Loss: 12302.694336\n",
      "Train Epoch: 853 [33024/118836 (28%)] Loss: 12256.221680\n",
      "Train Epoch: 853 [65792/118836 (55%)] Loss: 12322.065430\n",
      "Train Epoch: 853 [98560/118836 (83%)] Loss: 12319.280273\n",
      "    epoch          : 853\n",
      "    loss           : 12268.656155170855\n",
      "    val_loss       : 12266.178833017198\n",
      "    val_log_likelihood: -12185.38273560277\n",
      "    val_log_marginal: -12193.243153884358\n",
      "Train Epoch: 854 [256/118836 (0%)] Loss: 12391.347656\n",
      "Train Epoch: 854 [33024/118836 (28%)] Loss: 12358.564453\n",
      "Train Epoch: 854 [65792/118836 (55%)] Loss: 12267.152344\n",
      "Train Epoch: 854 [98560/118836 (83%)] Loss: 12304.706055\n",
      "    epoch          : 854\n",
      "    loss           : 12268.511317624329\n",
      "    val_loss       : 12269.579917496896\n",
      "    val_log_likelihood: -12183.451824209058\n",
      "    val_log_marginal: -12191.5153437919\n",
      "Train Epoch: 855 [256/118836 (0%)] Loss: 12358.058594\n",
      "Train Epoch: 855 [33024/118836 (28%)] Loss: 12328.961914\n",
      "Train Epoch: 855 [65792/118836 (55%)] Loss: 12220.968750\n",
      "Train Epoch: 855 [98560/118836 (83%)] Loss: 12255.228516\n",
      "    epoch          : 855\n",
      "    loss           : 12270.596017822065\n",
      "    val_loss       : 12265.165063928702\n",
      "    val_log_likelihood: -12181.87720643352\n",
      "    val_log_marginal: -12189.862939221734\n",
      "Train Epoch: 856 [256/118836 (0%)] Loss: 12291.285156\n",
      "Train Epoch: 856 [33024/118836 (28%)] Loss: 12294.761719\n",
      "Train Epoch: 856 [65792/118836 (55%)] Loss: 12305.299805\n",
      "Train Epoch: 856 [98560/118836 (83%)] Loss: 12269.279297\n",
      "    epoch          : 856\n",
      "    loss           : 12262.448122641388\n",
      "    val_loss       : 12266.278162573044\n",
      "    val_log_likelihood: -12185.014596095689\n",
      "    val_log_marginal: -12192.823702495607\n",
      "Train Epoch: 857 [256/118836 (0%)] Loss: 12303.293945\n",
      "Train Epoch: 857 [33024/118836 (28%)] Loss: 12209.689453\n",
      "Train Epoch: 857 [65792/118836 (55%)] Loss: 12277.347656\n",
      "Train Epoch: 857 [98560/118836 (83%)] Loss: 12288.205078\n",
      "    epoch          : 857\n",
      "    loss           : 12267.54362609207\n",
      "    val_loss       : 12266.46713047997\n",
      "    val_log_likelihood: -12181.57976439723\n",
      "    val_log_marginal: -12189.411878885008\n",
      "Train Epoch: 858 [256/118836 (0%)] Loss: 12331.130859\n",
      "Train Epoch: 858 [33024/118836 (28%)] Loss: 12242.644531\n",
      "Train Epoch: 858 [65792/118836 (55%)] Loss: 12380.429688\n",
      "Train Epoch: 858 [98560/118836 (83%)] Loss: 12284.904297\n",
      "    epoch          : 858\n",
      "    loss           : 12266.89852360551\n",
      "    val_loss       : 12268.656164743856\n",
      "    val_log_likelihood: -12182.789540361353\n",
      "    val_log_marginal: -12190.847647873095\n",
      "Train Epoch: 859 [256/118836 (0%)] Loss: 12365.951172\n",
      "Train Epoch: 859 [33024/118836 (28%)] Loss: 12259.906250\n",
      "Train Epoch: 859 [65792/118836 (55%)] Loss: 12445.527344\n",
      "Train Epoch: 859 [98560/118836 (83%)] Loss: 12336.357422\n",
      "    epoch          : 859\n",
      "    loss           : 12267.995822186465\n",
      "    val_loss       : 12269.443039868753\n",
      "    val_log_likelihood: -12182.099136037015\n",
      "    val_log_marginal: -12190.059971609047\n",
      "Train Epoch: 860 [256/118836 (0%)] Loss: 12286.975586\n",
      "Train Epoch: 860 [33024/118836 (28%)] Loss: 12308.556641\n",
      "Train Epoch: 860 [65792/118836 (55%)] Loss: 12249.227539\n",
      "Train Epoch: 860 [98560/118836 (83%)] Loss: 12388.020508\n",
      "    epoch          : 860\n",
      "    loss           : 12268.010059966915\n",
      "    val_loss       : 12266.19770350115\n",
      "    val_log_likelihood: -12184.149395484386\n",
      "    val_log_marginal: -12192.278073654756\n",
      "Train Epoch: 861 [256/118836 (0%)] Loss: 12264.652344\n",
      "Train Epoch: 861 [33024/118836 (28%)] Loss: 12250.488281\n",
      "Train Epoch: 861 [65792/118836 (55%)] Loss: 12320.259766\n",
      "Train Epoch: 861 [98560/118836 (83%)] Loss: 12363.056641\n",
      "    epoch          : 861\n",
      "    loss           : 12264.771205218673\n",
      "    val_loss       : 12269.188821707801\n",
      "    val_log_likelihood: -12179.79496242375\n",
      "    val_log_marginal: -12187.935859829391\n",
      "Train Epoch: 862 [256/118836 (0%)] Loss: 12341.511719\n",
      "Train Epoch: 862 [33024/118836 (28%)] Loss: 12300.758789\n",
      "Train Epoch: 862 [65792/118836 (55%)] Loss: 12263.478516\n",
      "Train Epoch: 862 [98560/118836 (83%)] Loss: 12294.535156\n",
      "    epoch          : 862\n",
      "    loss           : 12270.803059411188\n",
      "    val_loss       : 12268.435446842534\n",
      "    val_log_likelihood: -12183.654772959315\n",
      "    val_log_marginal: -12191.702743189293\n",
      "Train Epoch: 863 [256/118836 (0%)] Loss: 12194.817383\n",
      "Train Epoch: 863 [33024/118836 (28%)] Loss: 12279.205078\n",
      "Train Epoch: 863 [65792/118836 (55%)] Loss: 12382.982422\n",
      "Train Epoch: 863 [98560/118836 (83%)] Loss: 12273.314453\n",
      "    epoch          : 863\n",
      "    loss           : 12267.823740242451\n",
      "    val_loss       : 12263.785556492638\n",
      "    val_log_likelihood: -12184.649775447167\n",
      "    val_log_marginal: -12192.630401038623\n",
      "Train Epoch: 864 [256/118836 (0%)] Loss: 12293.568359\n",
      "Train Epoch: 864 [33024/118836 (28%)] Loss: 12327.161133\n",
      "Train Epoch: 864 [65792/118836 (55%)] Loss: 12253.899414\n",
      "Train Epoch: 864 [98560/118836 (83%)] Loss: 12279.607422\n",
      "    epoch          : 864\n",
      "    loss           : 12266.241738071236\n",
      "    val_loss       : 12265.459112362605\n",
      "    val_log_likelihood: -12180.087473990645\n",
      "    val_log_marginal: -12188.043482196594\n",
      "Train Epoch: 865 [256/118836 (0%)] Loss: 12361.250977\n",
      "Train Epoch: 865 [33024/118836 (28%)] Loss: 12315.740234\n",
      "Train Epoch: 865 [65792/118836 (55%)] Loss: 12273.746094\n",
      "Train Epoch: 865 [98560/118836 (83%)] Loss: 12199.888672\n",
      "    epoch          : 865\n",
      "    loss           : 12267.701311130066\n",
      "    val_loss       : 12266.92673639295\n",
      "    val_log_likelihood: -12182.674378037118\n",
      "    val_log_marginal: -12190.587504507095\n",
      "Train Epoch: 866 [256/118836 (0%)] Loss: 12243.197266\n",
      "Train Epoch: 866 [33024/118836 (28%)] Loss: 12279.140625\n",
      "Train Epoch: 866 [65792/118836 (55%)] Loss: 12198.887695\n",
      "Train Epoch: 866 [98560/118836 (83%)] Loss: 12302.416992\n",
      "    epoch          : 866\n",
      "    loss           : 12269.48310764966\n",
      "    val_loss       : 12271.438126593568\n",
      "    val_log_likelihood: -12183.150302257805\n",
      "    val_log_marginal: -12191.223164320414\n",
      "Train Epoch: 867 [256/118836 (0%)] Loss: 12346.488281\n",
      "Train Epoch: 867 [33024/118836 (28%)] Loss: 12256.870117\n",
      "Train Epoch: 867 [65792/118836 (55%)] Loss: 12225.363281\n",
      "Train Epoch: 867 [98560/118836 (83%)] Loss: 12270.250977\n",
      "    epoch          : 867\n",
      "    loss           : 12271.769204921424\n",
      "    val_loss       : 12271.42989173799\n",
      "    val_log_likelihood: -12186.097985163358\n",
      "    val_log_marginal: -12194.29002232592\n",
      "Train Epoch: 868 [256/118836 (0%)] Loss: 12324.585938\n",
      "Train Epoch: 868 [33024/118836 (28%)] Loss: 12345.794922\n",
      "Train Epoch: 868 [65792/118836 (55%)] Loss: 12277.573242\n",
      "Train Epoch: 868 [98560/118836 (83%)] Loss: 12201.594727\n",
      "    epoch          : 868\n",
      "    loss           : 12266.061077401262\n",
      "    val_loss       : 12269.831769641345\n",
      "    val_log_likelihood: -12183.74403028717\n",
      "    val_log_marginal: -12191.80050031169\n",
      "Train Epoch: 869 [256/118836 (0%)] Loss: 12332.876953\n",
      "Train Epoch: 869 [33024/118836 (28%)] Loss: 12398.458984\n",
      "Train Epoch: 869 [65792/118836 (55%)] Loss: 12271.673828\n",
      "Train Epoch: 869 [98560/118836 (83%)] Loss: 12298.086914\n",
      "    epoch          : 869\n",
      "    loss           : 12270.759919904105\n",
      "    val_loss       : 12270.665097964606\n",
      "    val_log_likelihood: -12183.056101375103\n",
      "    val_log_marginal: -12191.103125856742\n",
      "Train Epoch: 870 [256/118836 (0%)] Loss: 12306.376953\n",
      "Train Epoch: 870 [33024/118836 (28%)] Loss: 12292.282227\n",
      "Train Epoch: 870 [65792/118836 (55%)] Loss: 12350.457031\n",
      "Train Epoch: 870 [98560/118836 (83%)] Loss: 12410.070312\n",
      "    epoch          : 870\n",
      "    loss           : 12268.781620916046\n",
      "    val_loss       : 12271.713447418066\n",
      "    val_log_likelihood: -12184.867378935329\n",
      "    val_log_marginal: -12193.20514991567\n",
      "Train Epoch: 871 [256/118836 (0%)] Loss: 12340.904297\n",
      "Train Epoch: 871 [33024/118836 (28%)] Loss: 12180.869141\n",
      "Train Epoch: 871 [65792/118836 (55%)] Loss: 12230.810547\n",
      "Train Epoch: 871 [98560/118836 (83%)] Loss: 12281.229492\n",
      "    epoch          : 871\n",
      "    loss           : 12266.035273695978\n",
      "    val_loss       : 12270.102564773026\n",
      "    val_log_likelihood: -12186.308358858043\n",
      "    val_log_marginal: -12194.39465486468\n",
      "Train Epoch: 872 [256/118836 (0%)] Loss: 12200.109375\n",
      "Train Epoch: 872 [33024/118836 (28%)] Loss: 12274.564453\n",
      "Train Epoch: 872 [65792/118836 (55%)] Loss: 12275.740234\n",
      "Train Epoch: 872 [98560/118836 (83%)] Loss: 12292.716797\n",
      "    epoch          : 872\n",
      "    loss           : 12269.099906624793\n",
      "    val_loss       : 12266.5947030465\n",
      "    val_log_likelihood: -12182.856055656792\n",
      "    val_log_marginal: -12191.235129077191\n",
      "Train Epoch: 873 [256/118836 (0%)] Loss: 12181.126953\n",
      "Train Epoch: 873 [33024/118836 (28%)] Loss: 12327.984375\n",
      "Train Epoch: 873 [65792/118836 (55%)] Loss: 12221.761719\n",
      "Train Epoch: 873 [98560/118836 (83%)] Loss: 12246.678711\n",
      "    epoch          : 873\n",
      "    loss           : 12267.805002358611\n",
      "    val_loss       : 12269.150762424017\n",
      "    val_log_likelihood: -12186.416269902813\n",
      "    val_log_marginal: -12194.512517992502\n",
      "Train Epoch: 874 [256/118836 (0%)] Loss: 12296.339844\n",
      "Train Epoch: 874 [33024/118836 (28%)] Loss: 12193.269531\n",
      "Train Epoch: 874 [65792/118836 (55%)] Loss: 12282.835938\n",
      "Train Epoch: 874 [98560/118836 (83%)] Loss: 12334.761719\n",
      "    epoch          : 874\n",
      "    loss           : 12269.49261867375\n",
      "    val_loss       : 12268.766931582215\n",
      "    val_log_likelihood: -12182.72739899969\n",
      "    val_log_marginal: -12190.833165297716\n",
      "Train Epoch: 875 [256/118836 (0%)] Loss: 12296.223633\n",
      "Train Epoch: 875 [33024/118836 (28%)] Loss: 12215.748047\n",
      "Train Epoch: 875 [65792/118836 (55%)] Loss: 12339.853516\n",
      "Train Epoch: 875 [98560/118836 (83%)] Loss: 12310.680664\n",
      "    epoch          : 875\n",
      "    loss           : 12271.416176204508\n",
      "    val_loss       : 12268.373685517869\n",
      "    val_log_likelihood: -12182.041619009771\n",
      "    val_log_marginal: -12190.057336497315\n",
      "Train Epoch: 876 [256/118836 (0%)] Loss: 12338.977539\n",
      "Train Epoch: 876 [33024/118836 (28%)] Loss: 12290.327148\n",
      "Train Epoch: 876 [65792/118836 (55%)] Loss: 12239.107422\n",
      "Train Epoch: 876 [98560/118836 (83%)] Loss: 12292.486328\n",
      "    epoch          : 876\n",
      "    loss           : 12270.554345985835\n",
      "    val_loss       : 12267.337876037613\n",
      "    val_log_likelihood: -12182.134480814464\n",
      "    val_log_marginal: -12190.229351108559\n",
      "Train Epoch: 877 [256/118836 (0%)] Loss: 12265.292969\n",
      "Train Epoch: 877 [33024/118836 (28%)] Loss: 12406.988281\n",
      "Train Epoch: 877 [65792/118836 (55%)] Loss: 12313.706055\n",
      "Train Epoch: 877 [98560/118836 (83%)] Loss: 12277.338867\n",
      "    epoch          : 877\n",
      "    loss           : 12265.222600838762\n",
      "    val_loss       : 12268.280399096984\n",
      "    val_log_likelihood: -12183.795182130118\n",
      "    val_log_marginal: -12191.769501513243\n",
      "Train Epoch: 878 [256/118836 (0%)] Loss: 12346.365234\n",
      "Train Epoch: 878 [33024/118836 (28%)] Loss: 12309.257812\n",
      "Train Epoch: 878 [65792/118836 (55%)] Loss: 12279.601562\n",
      "Train Epoch: 878 [98560/118836 (83%)] Loss: 12267.316406\n",
      "    epoch          : 878\n",
      "    loss           : 12268.473536690963\n",
      "    val_loss       : 12270.295188199483\n",
      "    val_log_likelihood: -12183.258308454817\n",
      "    val_log_marginal: -12191.35060092789\n",
      "Train Epoch: 879 [256/118836 (0%)] Loss: 12290.625000\n",
      "Train Epoch: 879 [33024/118836 (28%)] Loss: 12380.949219\n",
      "Train Epoch: 879 [65792/118836 (55%)] Loss: 12283.235352\n",
      "Train Epoch: 879 [98560/118836 (83%)] Loss: 12263.638672\n",
      "    epoch          : 879\n",
      "    loss           : 12266.824328441635\n",
      "    val_loss       : 12269.842011066388\n",
      "    val_log_likelihood: -12182.255264713865\n",
      "    val_log_marginal: -12190.20226076137\n",
      "Train Epoch: 880 [256/118836 (0%)] Loss: 12300.494141\n",
      "Train Epoch: 880 [33024/118836 (28%)] Loss: 12205.905273\n",
      "Train Epoch: 880 [65792/118836 (55%)] Loss: 12186.891602\n",
      "Train Epoch: 880 [98560/118836 (83%)] Loss: 12286.896484\n",
      "    epoch          : 880\n",
      "    loss           : 12263.597892272797\n",
      "    val_loss       : 12264.448091727954\n",
      "    val_log_likelihood: -12181.834402624843\n",
      "    val_log_marginal: -12189.629180459271\n",
      "Train Epoch: 881 [256/118836 (0%)] Loss: 12279.747070\n",
      "Train Epoch: 881 [33024/118836 (28%)] Loss: 12304.327148\n",
      "Train Epoch: 881 [65792/118836 (55%)] Loss: 12300.267578\n",
      "Train Epoch: 881 [98560/118836 (83%)] Loss: 12280.427734\n",
      "    epoch          : 881\n",
      "    loss           : 12268.048516982011\n",
      "    val_loss       : 12268.359381742914\n",
      "    val_log_likelihood: -12183.584693897334\n",
      "    val_log_marginal: -12191.564397488566\n",
      "Train Epoch: 882 [256/118836 (0%)] Loss: 12333.744141\n",
      "Train Epoch: 882 [33024/118836 (28%)] Loss: 12295.087891\n",
      "Train Epoch: 882 [65792/118836 (55%)] Loss: 12280.273438\n",
      "Train Epoch: 882 [98560/118836 (83%)] Loss: 12381.087891\n",
      "    epoch          : 882\n",
      "    loss           : 12271.123428776365\n",
      "    val_loss       : 12265.806290749466\n",
      "    val_log_likelihood: -12181.640727098842\n",
      "    val_log_marginal: -12189.832946988741\n",
      "Train Epoch: 883 [256/118836 (0%)] Loss: 12248.481445\n",
      "Train Epoch: 883 [33024/118836 (28%)] Loss: 12272.523438\n",
      "Train Epoch: 883 [65792/118836 (55%)] Loss: 12302.796875\n",
      "Train Epoch: 883 [98560/118836 (83%)] Loss: 12290.785156\n",
      "    epoch          : 883\n",
      "    loss           : 12271.562233767576\n",
      "    val_loss       : 12273.166588894395\n",
      "    val_log_likelihood: -12181.336593065033\n",
      "    val_log_marginal: -12189.310933670986\n",
      "Train Epoch: 884 [256/118836 (0%)] Loss: 12281.710938\n",
      "Train Epoch: 884 [33024/118836 (28%)] Loss: 12335.650391\n",
      "Train Epoch: 884 [65792/118836 (55%)] Loss: 12343.938477\n",
      "Train Epoch: 884 [98560/118836 (83%)] Loss: 12326.433594\n",
      "    epoch          : 884\n",
      "    loss           : 12266.88313979787\n",
      "    val_loss       : 12266.769486231049\n",
      "    val_log_likelihood: -12183.757103139216\n",
      "    val_log_marginal: -12191.814781169602\n",
      "Train Epoch: 885 [256/118836 (0%)] Loss: 12223.483398\n",
      "Train Epoch: 885 [33024/118836 (28%)] Loss: 12232.764648\n",
      "Train Epoch: 885 [65792/118836 (55%)] Loss: 12309.543945\n",
      "Train Epoch: 885 [98560/118836 (83%)] Loss: 12243.869141\n",
      "    epoch          : 885\n",
      "    loss           : 12269.100491269903\n",
      "    val_loss       : 12269.83965905518\n",
      "    val_log_likelihood: -12183.863971386478\n",
      "    val_log_marginal: -12191.837091037989\n",
      "Train Epoch: 886 [256/118836 (0%)] Loss: 12245.356445\n",
      "Train Epoch: 886 [33024/118836 (28%)] Loss: 12205.352539\n",
      "Train Epoch: 886 [65792/118836 (55%)] Loss: 12234.215820\n",
      "Train Epoch: 886 [98560/118836 (83%)] Loss: 12355.222656\n",
      "    epoch          : 886\n",
      "    loss           : 12271.59337552988\n",
      "    val_loss       : 12270.934300024099\n",
      "    val_log_likelihood: -12185.421416847603\n",
      "    val_log_marginal: -12193.508977451695\n",
      "Train Epoch: 887 [256/118836 (0%)] Loss: 12269.445312\n",
      "Train Epoch: 887 [33024/118836 (28%)] Loss: 12234.364258\n",
      "Train Epoch: 887 [65792/118836 (55%)] Loss: 12284.968750\n",
      "Train Epoch: 887 [98560/118836 (83%)] Loss: 12295.963867\n",
      "    epoch          : 887\n",
      "    loss           : 12271.504426921783\n",
      "    val_loss       : 12271.171078939808\n",
      "    val_log_likelihood: -12185.309541395265\n",
      "    val_log_marginal: -12193.678067383189\n",
      "Train Epoch: 888 [256/118836 (0%)] Loss: 12304.455078\n",
      "Train Epoch: 888 [33024/118836 (28%)] Loss: 12218.382812\n",
      "Train Epoch: 888 [65792/118836 (55%)] Loss: 12378.825195\n",
      "Train Epoch: 888 [98560/118836 (83%)] Loss: 12256.395508\n",
      "    epoch          : 888\n",
      "    loss           : 12265.633957880997\n",
      "    val_loss       : 12265.971691383407\n",
      "    val_log_likelihood: -12182.444476969602\n",
      "    val_log_marginal: -12190.660251430058\n",
      "Train Epoch: 889 [256/118836 (0%)] Loss: 12210.581055\n",
      "Train Epoch: 889 [33024/118836 (28%)] Loss: 12199.755859\n",
      "Train Epoch: 889 [65792/118836 (55%)] Loss: 12224.136719\n",
      "Train Epoch: 889 [98560/118836 (83%)] Loss: 12262.742188\n",
      "    epoch          : 889\n",
      "    loss           : 12268.734812474153\n",
      "    val_loss       : 12268.570263645113\n",
      "    val_log_likelihood: -12184.25012649271\n",
      "    val_log_marginal: -12192.314889902438\n",
      "Train Epoch: 890 [256/118836 (0%)] Loss: 12282.460938\n",
      "Train Epoch: 890 [33024/118836 (28%)] Loss: 12333.251953\n",
      "Train Epoch: 890 [65792/118836 (55%)] Loss: 12218.431641\n",
      "Train Epoch: 890 [98560/118836 (83%)] Loss: 12295.065430\n",
      "    epoch          : 890\n",
      "    loss           : 12273.779724656224\n",
      "    val_loss       : 12277.481552953222\n",
      "    val_log_likelihood: -12184.696537363006\n",
      "    val_log_marginal: -12192.821504027843\n",
      "Train Epoch: 891 [256/118836 (0%)] Loss: 12250.332031\n",
      "Train Epoch: 891 [33024/118836 (28%)] Loss: 12330.117188\n",
      "Train Epoch: 891 [65792/118836 (55%)] Loss: 12201.390625\n",
      "Train Epoch: 891 [98560/118836 (83%)] Loss: 12322.402344\n",
      "    epoch          : 891\n",
      "    loss           : 12267.344819937707\n",
      "    val_loss       : 12265.700129626888\n",
      "    val_log_likelihood: -12182.546009583075\n",
      "    val_log_marginal: -12190.56749936504\n",
      "Train Epoch: 892 [256/118836 (0%)] Loss: 12201.629883\n",
      "Train Epoch: 892 [33024/118836 (28%)] Loss: 12363.652344\n",
      "Train Epoch: 892 [65792/118836 (55%)] Loss: 12229.327148\n",
      "Train Epoch: 892 [98560/118836 (83%)] Loss: 12290.043945\n",
      "    epoch          : 892\n",
      "    loss           : 12264.645141096722\n",
      "    val_loss       : 12270.76074409483\n",
      "    val_log_likelihood: -12181.573758335919\n",
      "    val_log_marginal: -12189.64621870881\n",
      "Train Epoch: 893 [256/118836 (0%)] Loss: 12331.042969\n",
      "Train Epoch: 893 [33024/118836 (28%)] Loss: 12299.990234\n",
      "Train Epoch: 893 [65792/118836 (55%)] Loss: 12336.914062\n",
      "Train Epoch: 893 [98560/118836 (83%)] Loss: 12270.455078\n",
      "    epoch          : 893\n",
      "    loss           : 12266.820143196855\n",
      "    val_loss       : 12266.880951151\n",
      "    val_log_likelihood: -12185.109568535463\n",
      "    val_log_marginal: -12192.990440770329\n",
      "Train Epoch: 894 [256/118836 (0%)] Loss: 12228.663086\n",
      "Train Epoch: 894 [33024/118836 (28%)] Loss: 12320.751953\n",
      "Train Epoch: 894 [65792/118836 (55%)] Loss: 12348.883789\n",
      "Train Epoch: 894 [98560/118836 (83%)] Loss: 12256.570312\n",
      "    epoch          : 894\n",
      "    loss           : 12268.581645471464\n",
      "    val_loss       : 12268.264321547049\n",
      "    val_log_likelihood: -12183.373210039288\n",
      "    val_log_marginal: -12191.550886666912\n",
      "Train Epoch: 895 [256/118836 (0%)] Loss: 12258.513672\n",
      "Train Epoch: 895 [33024/118836 (28%)] Loss: 12211.839844\n",
      "Train Epoch: 895 [65792/118836 (55%)] Loss: 12231.218750\n",
      "Train Epoch: 895 [98560/118836 (83%)] Loss: 12205.405273\n",
      "    epoch          : 895\n",
      "    loss           : 12270.576136495813\n",
      "    val_loss       : 12267.568542586921\n",
      "    val_log_likelihood: -12184.575195797146\n",
      "    val_log_marginal: -12192.59843656608\n",
      "Train Epoch: 896 [256/118836 (0%)] Loss: 12286.997070\n",
      "Train Epoch: 896 [33024/118836 (28%)] Loss: 12248.325195\n",
      "Train Epoch: 896 [65792/118836 (55%)] Loss: 12250.452148\n",
      "Train Epoch: 896 [98560/118836 (83%)] Loss: 12249.896484\n",
      "    epoch          : 896\n",
      "    loss           : 12264.72687251215\n",
      "    val_loss       : 12264.46506395712\n",
      "    val_log_likelihood: -12180.404790568135\n",
      "    val_log_marginal: -12188.489049719077\n",
      "Train Epoch: 897 [256/118836 (0%)] Loss: 12340.390625\n",
      "Train Epoch: 897 [33024/118836 (28%)] Loss: 12290.055664\n",
      "Train Epoch: 897 [65792/118836 (55%)] Loss: 12264.078125\n",
      "Train Epoch: 897 [98560/118836 (83%)] Loss: 12239.992188\n",
      "    epoch          : 897\n",
      "    loss           : 12268.19315194634\n",
      "    val_loss       : 12269.220232917678\n",
      "    val_log_likelihood: -12182.059301495296\n",
      "    val_log_marginal: -12189.992061840892\n",
      "Train Epoch: 898 [256/118836 (0%)] Loss: 12217.170898\n",
      "Train Epoch: 898 [33024/118836 (28%)] Loss: 12312.605469\n",
      "Train Epoch: 898 [65792/118836 (55%)] Loss: 12348.160156\n",
      "Train Epoch: 898 [98560/118836 (83%)] Loss: 12252.386719\n",
      "    epoch          : 898\n",
      "    loss           : 12268.47001476556\n",
      "    val_loss       : 12266.96867342165\n",
      "    val_log_likelihood: -12183.294555159222\n",
      "    val_log_marginal: -12191.335978650004\n",
      "Train Epoch: 899 [256/118836 (0%)] Loss: 12241.949219\n",
      "Train Epoch: 899 [33024/118836 (28%)] Loss: 12293.825195\n",
      "Train Epoch: 899 [65792/118836 (55%)] Loss: 12352.643555\n",
      "Train Epoch: 899 [98560/118836 (83%)] Loss: 12329.695312\n",
      "    epoch          : 899\n",
      "    loss           : 12268.991450191274\n",
      "    val_loss       : 12265.932413625605\n",
      "    val_log_likelihood: -12184.866066028226\n",
      "    val_log_marginal: -12192.93371092266\n",
      "Train Epoch: 900 [256/118836 (0%)] Loss: 12291.069336\n",
      "Train Epoch: 900 [33024/118836 (28%)] Loss: 12251.909180\n",
      "Train Epoch: 900 [65792/118836 (55%)] Loss: 12328.462891\n",
      "Train Epoch: 900 [98560/118836 (83%)] Loss: 12351.440430\n",
      "    epoch          : 900\n",
      "    loss           : 12264.307353539856\n",
      "    val_loss       : 12268.724533242908\n",
      "    val_log_likelihood: -12182.802935664806\n",
      "    val_log_marginal: -12190.62930928848\n",
      "Saving checkpoint: saved/models/SelfiesAutoencodingOperad/0905_154251/checkpoint-epoch900.pth ...\n",
      "Train Epoch: 901 [256/118836 (0%)] Loss: 12311.830078\n",
      "Train Epoch: 901 [33024/118836 (28%)] Loss: 12361.392578\n",
      "Train Epoch: 901 [65792/118836 (55%)] Loss: 12203.211914\n",
      "Train Epoch: 901 [98560/118836 (83%)] Loss: 12216.908203\n",
      "    epoch          : 901\n",
      "    loss           : 12265.441878457144\n",
      "    val_loss       : 12269.385604372712\n",
      "    val_log_likelihood: -12183.18868932227\n",
      "    val_log_marginal: -12191.229782302966\n",
      "Train Epoch: 902 [256/118836 (0%)] Loss: 12307.630859\n",
      "Train Epoch: 902 [33024/118836 (28%)] Loss: 12239.512695\n",
      "Train Epoch: 902 [65792/118836 (55%)] Loss: 12386.336914\n",
      "Train Epoch: 902 [98560/118836 (83%)] Loss: 12236.720703\n",
      "    epoch          : 902\n",
      "    loss           : 12269.174636838297\n",
      "    val_loss       : 12266.762389906316\n",
      "    val_log_likelihood: -12183.508026390613\n",
      "    val_log_marginal: -12191.607718086394\n",
      "Train Epoch: 903 [256/118836 (0%)] Loss: 12270.416992\n",
      "Train Epoch: 903 [33024/118836 (28%)] Loss: 12293.591797\n",
      "Train Epoch: 903 [65792/118836 (55%)] Loss: 12240.501953\n",
      "Train Epoch: 903 [98560/118836 (83%)] Loss: 12367.389648\n",
      "    epoch          : 903\n",
      "    loss           : 12264.977313055728\n",
      "    val_loss       : 12263.750105262574\n",
      "    val_log_likelihood: -12184.824665755532\n",
      "    val_log_marginal: -12192.950703191507\n",
      "Train Epoch: 904 [256/118836 (0%)] Loss: 12266.442383\n",
      "Train Epoch: 904 [33024/118836 (28%)] Loss: 12385.744141\n",
      "Train Epoch: 904 [65792/118836 (55%)] Loss: 12306.121094\n",
      "Train Epoch: 904 [98560/118836 (83%)] Loss: 12203.933594\n",
      "    epoch          : 904\n",
      "    loss           : 12268.282677606752\n",
      "    val_loss       : 12273.235316244529\n",
      "    val_log_likelihood: -12183.461979489763\n",
      "    val_log_marginal: -12191.9699384633\n",
      "Train Epoch: 905 [256/118836 (0%)] Loss: 12193.300781\n",
      "Train Epoch: 905 [33024/118836 (28%)] Loss: 12247.679688\n",
      "Train Epoch: 905 [65792/118836 (55%)] Loss: 12427.917969\n",
      "Train Epoch: 905 [98560/118836 (83%)] Loss: 12255.128906\n",
      "    epoch          : 905\n",
      "    loss           : 12268.79256600884\n",
      "    val_loss       : 12266.165576982747\n",
      "    val_log_likelihood: -12186.184412156224\n",
      "    val_log_marginal: -12194.301454528815\n",
      "Train Epoch: 906 [256/118836 (0%)] Loss: 12270.125000\n",
      "Train Epoch: 906 [33024/118836 (28%)] Loss: 12303.029297\n",
      "Train Epoch: 906 [65792/118836 (55%)] Loss: 12216.681641\n",
      "Train Epoch: 906 [98560/118836 (83%)] Loss: 12344.164062\n",
      "    epoch          : 906\n",
      "    loss           : 12274.97307805392\n",
      "    val_loss       : 12268.775901822242\n",
      "    val_log_likelihood: -12182.683901500466\n",
      "    val_log_marginal: -12190.807290433677\n",
      "Train Epoch: 907 [256/118836 (0%)] Loss: 12250.296875\n",
      "Train Epoch: 907 [33024/118836 (28%)] Loss: 12338.529297\n",
      "Train Epoch: 907 [65792/118836 (55%)] Loss: 12293.362305\n",
      "Train Epoch: 907 [98560/118836 (83%)] Loss: 12235.412109\n",
      "    epoch          : 907\n",
      "    loss           : 12272.216961654776\n",
      "    val_loss       : 12270.133849654643\n",
      "    val_log_likelihood: -12184.187489337779\n",
      "    val_log_marginal: -12192.488622107603\n",
      "Train Epoch: 908 [256/118836 (0%)] Loss: 12306.612305\n",
      "Train Epoch: 908 [33024/118836 (28%)] Loss: 12222.110352\n",
      "Train Epoch: 908 [65792/118836 (55%)] Loss: 12269.658203\n",
      "Train Epoch: 908 [98560/118836 (83%)] Loss: 12316.800781\n",
      "    epoch          : 908\n",
      "    loss           : 12264.908851743436\n",
      "    val_loss       : 12270.428446227788\n",
      "    val_log_likelihood: -12187.099810018612\n",
      "    val_log_marginal: -12194.962901015564\n",
      "Train Epoch: 909 [256/118836 (0%)] Loss: 12243.798828\n",
      "Train Epoch: 909 [33024/118836 (28%)] Loss: 12313.134766\n",
      "Train Epoch: 909 [65792/118836 (55%)] Loss: 12251.105469\n",
      "Train Epoch: 909 [98560/118836 (83%)] Loss: 12280.335938\n",
      "    epoch          : 909\n",
      "    loss           : 12269.732882450631\n",
      "    val_loss       : 12271.380511765608\n",
      "    val_log_likelihood: -12181.87360050274\n",
      "    val_log_marginal: -12189.972618291433\n",
      "Train Epoch: 910 [256/118836 (0%)] Loss: 12242.013672\n",
      "Train Epoch: 910 [33024/118836 (28%)] Loss: 12251.769531\n",
      "Train Epoch: 910 [65792/118836 (55%)] Loss: 12270.913086\n",
      "Train Epoch: 910 [98560/118836 (83%)] Loss: 12346.343750\n",
      "    epoch          : 910\n",
      "    loss           : 12266.209964653122\n",
      "    val_loss       : 12267.58325098419\n",
      "    val_log_likelihood: -12181.083049168992\n",
      "    val_log_marginal: -12189.182632838203\n",
      "Train Epoch: 911 [256/118836 (0%)] Loss: 12300.833984\n",
      "Train Epoch: 911 [33024/118836 (28%)] Loss: 12383.850586\n",
      "Train Epoch: 911 [65792/118836 (55%)] Loss: 12305.562500\n",
      "Train Epoch: 911 [98560/118836 (83%)] Loss: 12260.250000\n",
      "    epoch          : 911\n",
      "    loss           : 12267.733130104942\n",
      "    val_loss       : 12266.147269334488\n",
      "    val_log_likelihood: -12180.572598415529\n",
      "    val_log_marginal: -12188.474288110883\n",
      "Train Epoch: 912 [256/118836 (0%)] Loss: 12314.421875\n",
      "Train Epoch: 912 [33024/118836 (28%)] Loss: 12311.995117\n",
      "Train Epoch: 912 [65792/118836 (55%)] Loss: 12263.323242\n",
      "Train Epoch: 912 [98560/118836 (83%)] Loss: 12278.025391\n",
      "    epoch          : 912\n",
      "    loss           : 12263.342825294665\n",
      "    val_loss       : 12266.653044158482\n",
      "    val_log_likelihood: -12180.071217173283\n",
      "    val_log_marginal: -12187.975632066402\n",
      "Train Epoch: 913 [256/118836 (0%)] Loss: 12335.165039\n",
      "Train Epoch: 913 [33024/118836 (28%)] Loss: 12198.378906\n",
      "Train Epoch: 913 [65792/118836 (55%)] Loss: 12258.436523\n",
      "Train Epoch: 913 [98560/118836 (83%)] Loss: 12264.826172\n",
      "    epoch          : 913\n",
      "    loss           : 12266.010547682743\n",
      "    val_loss       : 12265.451282682803\n",
      "    val_log_likelihood: -12183.27239227926\n",
      "    val_log_marginal: -12191.390306891279\n",
      "Train Epoch: 914 [256/118836 (0%)] Loss: 12351.873047\n",
      "Train Epoch: 914 [33024/118836 (28%)] Loss: 12265.042969\n",
      "Train Epoch: 914 [65792/118836 (55%)] Loss: 12268.704102\n",
      "Train Epoch: 914 [98560/118836 (83%)] Loss: 12330.582031\n",
      "    epoch          : 914\n",
      "    loss           : 12269.166075236506\n",
      "    val_loss       : 12263.894173038356\n",
      "    val_log_likelihood: -12182.01749185794\n",
      "    val_log_marginal: -12189.977525968105\n",
      "Train Epoch: 915 [256/118836 (0%)] Loss: 12379.615234\n",
      "Train Epoch: 915 [33024/118836 (28%)] Loss: 12335.705078\n",
      "Train Epoch: 915 [65792/118836 (55%)] Loss: 12241.721680\n",
      "Train Epoch: 915 [98560/118836 (83%)] Loss: 12235.003906\n",
      "    epoch          : 915\n",
      "    loss           : 12266.786268028845\n",
      "    val_loss       : 12271.021267238944\n",
      "    val_log_likelihood: -12179.426370418476\n",
      "    val_log_marginal: -12187.6092122054\n",
      "Train Epoch: 916 [256/118836 (0%)] Loss: 12255.747070\n",
      "Train Epoch: 916 [33024/118836 (28%)] Loss: 12196.358398\n",
      "Train Epoch: 916 [65792/118836 (55%)] Loss: 12374.420898\n",
      "Train Epoch: 916 [98560/118836 (83%)] Loss: 12287.155273\n",
      "    epoch          : 916\n",
      "    loss           : 12271.48653296888\n",
      "    val_loss       : 12269.668469651257\n",
      "    val_log_likelihood: -12182.518038700631\n",
      "    val_log_marginal: -12191.145324923726\n",
      "Train Epoch: 917 [256/118836 (0%)] Loss: 12279.621094\n",
      "Train Epoch: 917 [33024/118836 (28%)] Loss: 12342.257812\n",
      "Train Epoch: 917 [65792/118836 (55%)] Loss: 12345.156250\n",
      "Train Epoch: 917 [98560/118836 (83%)] Loss: 12355.572266\n",
      "    epoch          : 917\n",
      "    loss           : 12268.843536270937\n",
      "    val_loss       : 12266.256696139699\n",
      "    val_log_likelihood: -12180.094039818548\n",
      "    val_log_marginal: -12188.080042680254\n",
      "Train Epoch: 918 [256/118836 (0%)] Loss: 12289.376953\n",
      "Train Epoch: 918 [33024/118836 (28%)] Loss: 12245.130859\n",
      "Train Epoch: 918 [65792/118836 (55%)] Loss: 12364.423828\n",
      "Train Epoch: 918 [98560/118836 (83%)] Loss: 12270.174805\n",
      "    epoch          : 918\n",
      "    loss           : 12265.661674970273\n",
      "    val_loss       : 12266.703048667978\n",
      "    val_log_likelihood: -12178.419892796215\n",
      "    val_log_marginal: -12186.749715220622\n",
      "Train Epoch: 919 [256/118836 (0%)] Loss: 12285.130859\n",
      "Train Epoch: 919 [33024/118836 (28%)] Loss: 12313.250000\n",
      "Train Epoch: 919 [65792/118836 (55%)] Loss: 12258.890625\n",
      "Train Epoch: 919 [98560/118836 (83%)] Loss: 12345.775391\n",
      "    epoch          : 919\n",
      "    loss           : 12263.953186226994\n",
      "    val_loss       : 12263.8202328103\n",
      "    val_log_likelihood: -12179.99822990979\n",
      "    val_log_marginal: -12188.245343857088\n",
      "Train Epoch: 920 [256/118836 (0%)] Loss: 12276.148438\n",
      "Train Epoch: 920 [33024/118836 (28%)] Loss: 12243.816406\n",
      "Train Epoch: 920 [65792/118836 (55%)] Loss: 12210.492188\n",
      "Train Epoch: 920 [98560/118836 (83%)] Loss: 12322.272461\n",
      "    epoch          : 920\n",
      "    loss           : 12268.801454262304\n",
      "    val_loss       : 12269.546643950698\n",
      "    val_log_likelihood: -12183.481292648883\n",
      "    val_log_marginal: -12191.617506816623\n",
      "Train Epoch: 921 [256/118836 (0%)] Loss: 12270.105469\n",
      "Train Epoch: 921 [33024/118836 (28%)] Loss: 12241.780273\n",
      "Train Epoch: 921 [65792/118836 (55%)] Loss: 12302.453125\n",
      "Train Epoch: 921 [98560/118836 (83%)] Loss: 12202.103516\n",
      "    epoch          : 921\n",
      "    loss           : 12273.12853194143\n",
      "    val_loss       : 12263.795030262852\n",
      "    val_log_likelihood: -12181.32485848325\n",
      "    val_log_marginal: -12189.52051245498\n",
      "Train Epoch: 922 [256/118836 (0%)] Loss: 12339.486328\n",
      "Train Epoch: 922 [33024/118836 (28%)] Loss: 12411.382812\n",
      "Train Epoch: 922 [65792/118836 (55%)] Loss: 12391.664062\n",
      "Train Epoch: 922 [98560/118836 (83%)] Loss: 12307.960938\n",
      "    epoch          : 922\n",
      "    loss           : 12270.20494323175\n",
      "    val_loss       : 12271.594104501279\n",
      "    val_log_likelihood: -12180.344002500775\n",
      "    val_log_marginal: -12188.386995142488\n",
      "Train Epoch: 923 [256/118836 (0%)] Loss: 12374.374023\n",
      "Train Epoch: 923 [33024/118836 (28%)] Loss: 12250.349609\n",
      "Train Epoch: 923 [65792/118836 (55%)] Loss: 12338.076172\n",
      "Train Epoch: 923 [98560/118836 (83%)] Loss: 12301.231445\n",
      "    epoch          : 923\n",
      "    loss           : 12268.41519269541\n",
      "    val_loss       : 12267.30307026196\n",
      "    val_log_likelihood: -12178.926025188688\n",
      "    val_log_marginal: -12186.927259218757\n",
      "Train Epoch: 924 [256/118836 (0%)] Loss: 12312.574219\n",
      "Train Epoch: 924 [33024/118836 (28%)] Loss: 12294.849609\n",
      "Train Epoch: 924 [65792/118836 (55%)] Loss: 12222.977539\n",
      "Train Epoch: 924 [98560/118836 (83%)] Loss: 12244.291992\n",
      "    epoch          : 924\n",
      "    loss           : 12264.343406870348\n",
      "    val_loss       : 12262.519738694777\n",
      "    val_log_likelihood: -12183.284975961538\n",
      "    val_log_marginal: -12191.294144320715\n",
      "Train Epoch: 925 [256/118836 (0%)] Loss: 12300.204102\n",
      "Train Epoch: 925 [33024/118836 (28%)] Loss: 12331.404297\n",
      "Train Epoch: 925 [65792/118836 (55%)] Loss: 12284.477539\n",
      "Train Epoch: 925 [98560/118836 (83%)] Loss: 12204.349609\n",
      "    epoch          : 925\n",
      "    loss           : 12263.495398928608\n",
      "    val_loss       : 12265.408260114842\n",
      "    val_log_likelihood: -12182.342362295802\n",
      "    val_log_marginal: -12190.43824438758\n",
      "Train Epoch: 926 [256/118836 (0%)] Loss: 12260.452148\n",
      "Train Epoch: 926 [33024/118836 (28%)] Loss: 12183.657227\n",
      "Train Epoch: 926 [65792/118836 (55%)] Loss: 12278.372070\n",
      "Train Epoch: 926 [98560/118836 (83%)] Loss: 12216.143555\n",
      "    epoch          : 926\n",
      "    loss           : 12269.27521679849\n",
      "    val_loss       : 12266.670900299672\n",
      "    val_log_likelihood: -12182.177771046578\n",
      "    val_log_marginal: -12190.160802109618\n",
      "Train Epoch: 927 [256/118836 (0%)] Loss: 12317.246094\n",
      "Train Epoch: 927 [33024/118836 (28%)] Loss: 12265.068359\n",
      "Train Epoch: 927 [65792/118836 (55%)] Loss: 12271.376953\n",
      "Train Epoch: 927 [98560/118836 (83%)] Loss: 12253.414062\n",
      "    epoch          : 927\n",
      "    loss           : 12265.866523695977\n",
      "    val_loss       : 12268.776091958725\n",
      "    val_log_likelihood: -12180.88882260003\n",
      "    val_log_marginal: -12188.958729905306\n",
      "Train Epoch: 928 [256/118836 (0%)] Loss: 12270.853516\n",
      "Train Epoch: 928 [33024/118836 (28%)] Loss: 12228.169922\n",
      "Train Epoch: 928 [65792/118836 (55%)] Loss: 12316.070312\n",
      "Train Epoch: 928 [98560/118836 (83%)] Loss: 12320.851562\n",
      "    epoch          : 928\n",
      "    loss           : 12266.539986720689\n",
      "    val_loss       : 12267.218887982059\n",
      "    val_log_likelihood: -12180.967793146452\n",
      "    val_log_marginal: -12188.96198386433\n",
      "Train Epoch: 929 [256/118836 (0%)] Loss: 12279.483398\n",
      "Train Epoch: 929 [33024/118836 (28%)] Loss: 12327.178711\n",
      "Train Epoch: 929 [65792/118836 (55%)] Loss: 12277.742188\n",
      "Train Epoch: 929 [98560/118836 (83%)] Loss: 12231.488281\n",
      "    epoch          : 929\n",
      "    loss           : 12265.165940989455\n",
      "    val_loss       : 12266.328267676703\n",
      "    val_log_likelihood: -12181.853610777243\n",
      "    val_log_marginal: -12190.14893251664\n",
      "Train Epoch: 930 [256/118836 (0%)] Loss: 12310.987305\n",
      "Train Epoch: 930 [33024/118836 (28%)] Loss: 12367.844727\n",
      "Train Epoch: 930 [65792/118836 (55%)] Loss: 12244.179688\n",
      "Train Epoch: 930 [98560/118836 (83%)] Loss: 12242.041016\n",
      "    epoch          : 930\n",
      "    loss           : 12267.044315582352\n",
      "    val_loss       : 12270.493998580774\n",
      "    val_log_likelihood: -12179.962396285671\n",
      "    val_log_marginal: -12188.229910828542\n",
      "Train Epoch: 931 [256/118836 (0%)] Loss: 12370.824219\n",
      "Train Epoch: 931 [33024/118836 (28%)] Loss: 12262.869141\n",
      "Train Epoch: 931 [65792/118836 (55%)] Loss: 12267.760742\n",
      "Train Epoch: 931 [98560/118836 (83%)] Loss: 12245.627930\n",
      "    epoch          : 931\n",
      "    loss           : 12265.950225522125\n",
      "    val_loss       : 12263.877686366812\n",
      "    val_log_likelihood: -12181.398067876344\n",
      "    val_log_marginal: -12189.693994685798\n",
      "Train Epoch: 932 [256/118836 (0%)] Loss: 12295.443359\n",
      "Train Epoch: 932 [33024/118836 (28%)] Loss: 12278.821289\n",
      "Train Epoch: 932 [65792/118836 (55%)] Loss: 12230.155273\n",
      "Train Epoch: 932 [98560/118836 (83%)] Loss: 12301.865234\n",
      "    epoch          : 932\n",
      "    loss           : 12266.056738038926\n",
      "    val_loss       : 12266.011327740467\n",
      "    val_log_likelihood: -12182.878616431452\n",
      "    val_log_marginal: -12190.981919915315\n",
      "Train Epoch: 933 [256/118836 (0%)] Loss: 12243.718750\n",
      "Train Epoch: 933 [33024/118836 (28%)] Loss: 12381.050781\n",
      "Train Epoch: 933 [65792/118836 (55%)] Loss: 12302.279297\n",
      "Train Epoch: 933 [98560/118836 (83%)] Loss: 12300.146484\n",
      "    epoch          : 933\n",
      "    loss           : 12264.247567559709\n",
      "    val_loss       : 12265.929092746015\n",
      "    val_log_likelihood: -12180.771989861198\n",
      "    val_log_marginal: -12188.718915067931\n",
      "Train Epoch: 934 [256/118836 (0%)] Loss: 12325.841797\n",
      "Train Epoch: 934 [33024/118836 (28%)] Loss: 12306.857422\n",
      "Train Epoch: 934 [65792/118836 (55%)] Loss: 12235.509766\n",
      "Train Epoch: 934 [98560/118836 (83%)] Loss: 12252.883789\n",
      "    epoch          : 934\n",
      "    loss           : 12272.473567708334\n",
      "    val_loss       : 12267.199762814254\n",
      "    val_log_likelihood: -12183.917084431865\n",
      "    val_log_marginal: -12192.361803448977\n",
      "Train Epoch: 935 [256/118836 (0%)] Loss: 12295.880859\n",
      "Train Epoch: 935 [33024/118836 (28%)] Loss: 12330.567383\n",
      "Train Epoch: 935 [65792/118836 (55%)] Loss: 12300.184570\n",
      "Train Epoch: 935 [98560/118836 (83%)] Loss: 12218.580078\n",
      "    epoch          : 935\n",
      "    loss           : 12269.79708485189\n",
      "    val_loss       : 12265.732567498893\n",
      "    val_log_likelihood: -12180.425984155294\n",
      "    val_log_marginal: -12188.440274893788\n",
      "Train Epoch: 936 [256/118836 (0%)] Loss: 12308.900391\n",
      "Train Epoch: 936 [33024/118836 (28%)] Loss: 12297.353516\n",
      "Train Epoch: 936 [65792/118836 (55%)] Loss: 12239.186523\n",
      "Train Epoch: 936 [98560/118836 (83%)] Loss: 12322.968750\n",
      "    epoch          : 936\n",
      "    loss           : 12266.907423167391\n",
      "    val_loss       : 12272.454189461378\n",
      "    val_log_likelihood: -12184.188970255635\n",
      "    val_log_marginal: -12192.395122251153\n",
      "Train Epoch: 937 [256/118836 (0%)] Loss: 12259.900391\n",
      "Train Epoch: 937 [33024/118836 (28%)] Loss: 12336.859375\n",
      "Train Epoch: 937 [65792/118836 (55%)] Loss: 12298.614258\n",
      "Train Epoch: 937 [98560/118836 (83%)] Loss: 12373.240234\n",
      "    epoch          : 937\n",
      "    loss           : 12269.226386896453\n",
      "    val_loss       : 12268.036514231377\n",
      "    val_log_likelihood: -12181.219155325942\n",
      "    val_log_marginal: -12189.521641525522\n",
      "Train Epoch: 938 [256/118836 (0%)] Loss: 12277.316406\n",
      "Train Epoch: 938 [33024/118836 (28%)] Loss: 12343.032227\n",
      "Train Epoch: 938 [65792/118836 (55%)] Loss: 12342.962891\n",
      "Train Epoch: 938 [98560/118836 (83%)] Loss: 12207.374023\n",
      "    epoch          : 938\n",
      "    loss           : 12264.29596305702\n",
      "    val_loss       : 12268.88544529858\n",
      "    val_log_likelihood: -12184.361793223998\n",
      "    val_log_marginal: -12192.568101964418\n",
      "Train Epoch: 939 [256/118836 (0%)] Loss: 12311.394531\n",
      "Train Epoch: 939 [33024/118836 (28%)] Loss: 12256.136719\n",
      "Train Epoch: 939 [65792/118836 (55%)] Loss: 12347.269531\n",
      "Train Epoch: 939 [98560/118836 (83%)] Loss: 12330.198242\n",
      "    epoch          : 939\n",
      "    loss           : 12266.711825695305\n",
      "    val_loss       : 12268.204087013894\n",
      "    val_log_likelihood: -12180.09942601711\n",
      "    val_log_marginal: -12188.279767234231\n",
      "Train Epoch: 940 [256/118836 (0%)] Loss: 12330.375000\n",
      "Train Epoch: 940 [33024/118836 (28%)] Loss: 12349.400391\n",
      "Train Epoch: 940 [65792/118836 (55%)] Loss: 12321.536133\n",
      "Train Epoch: 940 [98560/118836 (83%)] Loss: 12283.126953\n",
      "    epoch          : 940\n",
      "    loss           : 12262.014719034327\n",
      "    val_loss       : 12263.688508155981\n",
      "    val_log_likelihood: -12177.780168915426\n",
      "    val_log_marginal: -12186.07630209045\n",
      "Train Epoch: 941 [256/118836 (0%)] Loss: 12384.776367\n",
      "Train Epoch: 941 [33024/118836 (28%)] Loss: 12339.367188\n",
      "Train Epoch: 941 [65792/118836 (55%)] Loss: 12295.088867\n",
      "Train Epoch: 941 [98560/118836 (83%)] Loss: 12369.153320\n",
      "    epoch          : 941\n",
      "    loss           : 12270.263969447891\n",
      "    val_loss       : 12267.521691391521\n",
      "    val_log_likelihood: -12180.378068619468\n",
      "    val_log_marginal: -12188.662385632013\n",
      "Train Epoch: 942 [256/118836 (0%)] Loss: 12300.350586\n",
      "Train Epoch: 942 [33024/118836 (28%)] Loss: 12323.176758\n",
      "Train Epoch: 942 [65792/118836 (55%)] Loss: 12302.465820\n",
      "Train Epoch: 942 [98560/118836 (83%)] Loss: 12214.595703\n",
      "    epoch          : 942\n",
      "    loss           : 12269.145237379807\n",
      "    val_loss       : 12267.42539479758\n",
      "    val_log_likelihood: -12179.615152146662\n",
      "    val_log_marginal: -12187.936272951178\n",
      "Train Epoch: 943 [256/118836 (0%)] Loss: 12301.039062\n",
      "Train Epoch: 943 [33024/118836 (28%)] Loss: 12365.358398\n",
      "Train Epoch: 943 [65792/118836 (55%)] Loss: 12297.876953\n",
      "Train Epoch: 943 [98560/118836 (83%)] Loss: 12218.832031\n",
      "    epoch          : 943\n",
      "    loss           : 12269.512887232475\n",
      "    val_loss       : 12267.23081768759\n",
      "    val_log_likelihood: -12176.062499030708\n",
      "    val_log_marginal: -12184.224651046006\n",
      "Train Epoch: 944 [256/118836 (0%)] Loss: 12254.848633\n",
      "Train Epoch: 944 [33024/118836 (28%)] Loss: 12273.240234\n",
      "Train Epoch: 944 [65792/118836 (55%)] Loss: 12376.235352\n",
      "Train Epoch: 944 [98560/118836 (83%)] Loss: 12249.677734\n",
      "    epoch          : 944\n",
      "    loss           : 12265.881236752997\n",
      "    val_loss       : 12267.429451029497\n",
      "    val_log_likelihood: -12178.72219018171\n",
      "    val_log_marginal: -12186.745069749793\n",
      "Train Epoch: 945 [256/118836 (0%)] Loss: 12204.554688\n",
      "Train Epoch: 945 [33024/118836 (28%)] Loss: 12328.748047\n",
      "Train Epoch: 945 [65792/118836 (55%)] Loss: 12313.802734\n",
      "Train Epoch: 945 [98560/118836 (83%)] Loss: 12225.537109\n",
      "    epoch          : 945\n",
      "    loss           : 12265.857197322168\n",
      "    val_loss       : 12265.906644970093\n",
      "    val_log_likelihood: -12178.697017486043\n",
      "    val_log_marginal: -12186.791876705905\n",
      "Train Epoch: 946 [256/118836 (0%)] Loss: 12238.509766\n",
      "Train Epoch: 946 [33024/118836 (28%)] Loss: 12346.926758\n",
      "Train Epoch: 946 [65792/118836 (55%)] Loss: 12296.291016\n",
      "Train Epoch: 946 [98560/118836 (83%)] Loss: 12359.048828\n",
      "    epoch          : 946\n",
      "    loss           : 12266.914178653587\n",
      "    val_loss       : 12267.089278785712\n",
      "    val_log_likelihood: -12179.348715202388\n",
      "    val_log_marginal: -12187.57013469802\n",
      "Train Epoch: 947 [256/118836 (0%)] Loss: 12360.156250\n",
      "Train Epoch: 947 [33024/118836 (28%)] Loss: 12303.465820\n",
      "Train Epoch: 947 [65792/118836 (55%)] Loss: 12344.154297\n",
      "Train Epoch: 947 [98560/118836 (83%)] Loss: 12287.326172\n",
      "    epoch          : 947\n",
      "    loss           : 12264.170471140922\n",
      "    val_loss       : 12269.88222461678\n",
      "    val_log_likelihood: -12180.474076425506\n",
      "    val_log_marginal: -12188.56498499544\n",
      "Train Epoch: 948 [256/118836 (0%)] Loss: 12336.250000\n",
      "Train Epoch: 948 [33024/118836 (28%)] Loss: 12271.205078\n",
      "Train Epoch: 948 [65792/118836 (55%)] Loss: 12318.591797\n",
      "Train Epoch: 948 [98560/118836 (83%)] Loss: 12247.868164\n",
      "    epoch          : 948\n",
      "    loss           : 12269.165189141335\n",
      "    val_loss       : 12266.559071088013\n",
      "    val_log_likelihood: -12180.503823537016\n",
      "    val_log_marginal: -12188.63002052837\n",
      "Train Epoch: 949 [256/118836 (0%)] Loss: 12199.535156\n",
      "Train Epoch: 949 [33024/118836 (28%)] Loss: 12302.039062\n",
      "Train Epoch: 949 [65792/118836 (55%)] Loss: 12278.583008\n",
      "Train Epoch: 949 [98560/118836 (83%)] Loss: 12260.253906\n",
      "    epoch          : 949\n",
      "    loss           : 12266.19522639449\n",
      "    val_loss       : 12265.576335932414\n",
      "    val_log_likelihood: -12179.09320315731\n",
      "    val_log_marginal: -12187.337561998705\n",
      "Train Epoch: 950 [256/118836 (0%)] Loss: 12191.816406\n",
      "Train Epoch: 950 [33024/118836 (28%)] Loss: 12254.495117\n",
      "Train Epoch: 950 [65792/118836 (55%)] Loss: 12417.956055\n",
      "Train Epoch: 950 [98560/118836 (83%)] Loss: 12342.044922\n",
      "    epoch          : 950\n",
      "    loss           : 12263.877697057227\n",
      "    val_loss       : 12265.861930075844\n",
      "    val_log_likelihood: -12178.41566829508\n",
      "    val_log_marginal: -12186.29361394672\n",
      "Train Epoch: 951 [256/118836 (0%)] Loss: 12239.082031\n",
      "Train Epoch: 951 [33024/118836 (28%)] Loss: 12271.709961\n",
      "Train Epoch: 951 [65792/118836 (55%)] Loss: 12301.341797\n",
      "Train Epoch: 951 [98560/118836 (83%)] Loss: 12227.469727\n",
      "    epoch          : 951\n",
      "    loss           : 12263.477068470844\n",
      "    val_loss       : 12265.988583175007\n",
      "    val_log_likelihood: -12180.255012374637\n",
      "    val_log_marginal: -12188.171981931344\n",
      "Train Epoch: 952 [256/118836 (0%)] Loss: 12432.899414\n",
      "Train Epoch: 952 [33024/118836 (28%)] Loss: 12324.011719\n",
      "Train Epoch: 952 [65792/118836 (55%)] Loss: 12306.702148\n",
      "Train Epoch: 952 [98560/118836 (83%)] Loss: 12250.116211\n",
      "    epoch          : 952\n",
      "    loss           : 12265.696129129188\n",
      "    val_loss       : 12267.357797665252\n",
      "    val_log_likelihood: -12181.630331756618\n",
      "    val_log_marginal: -12189.979957596724\n",
      "Train Epoch: 953 [256/118836 (0%)] Loss: 12311.261719\n",
      "Train Epoch: 953 [33024/118836 (28%)] Loss: 12230.466797\n",
      "Train Epoch: 953 [65792/118836 (55%)] Loss: 12294.170898\n",
      "Train Epoch: 953 [98560/118836 (83%)] Loss: 12196.376953\n",
      "    epoch          : 953\n",
      "    loss           : 12268.624933603442\n",
      "    val_loss       : 12266.54282694132\n",
      "    val_log_likelihood: -12178.75305634176\n",
      "    val_log_marginal: -12186.77320856268\n",
      "Train Epoch: 954 [256/118836 (0%)] Loss: 12212.187500\n",
      "Train Epoch: 954 [33024/118836 (28%)] Loss: 12263.456055\n",
      "Train Epoch: 954 [65792/118836 (55%)] Loss: 12181.966797\n",
      "Train Epoch: 954 [98560/118836 (83%)] Loss: 12367.042969\n",
      "    epoch          : 954\n",
      "    loss           : 12261.475854916254\n",
      "    val_loss       : 12262.781467458042\n",
      "    val_log_likelihood: -12180.164309023468\n",
      "    val_log_marginal: -12188.255988677924\n",
      "Train Epoch: 955 [256/118836 (0%)] Loss: 12364.010742\n",
      "Train Epoch: 955 [33024/118836 (28%)] Loss: 12271.684570\n",
      "Train Epoch: 955 [65792/118836 (55%)] Loss: 12244.412109\n",
      "Train Epoch: 955 [98560/118836 (83%)] Loss: 12333.640625\n",
      "    epoch          : 955\n",
      "    loss           : 12263.826569446599\n",
      "    val_loss       : 12260.815627674534\n",
      "    val_log_likelihood: -12177.30001486249\n",
      "    val_log_marginal: -12185.131680708473\n",
      "Train Epoch: 956 [256/118836 (0%)] Loss: 12441.799805\n",
      "Train Epoch: 956 [33024/118836 (28%)] Loss: 12332.779297\n",
      "Train Epoch: 956 [65792/118836 (55%)] Loss: 12267.692383\n",
      "Train Epoch: 956 [98560/118836 (83%)] Loss: 12292.679688\n",
      "    epoch          : 956\n",
      "    loss           : 12263.956839653123\n",
      "    val_loss       : 12262.797641435374\n",
      "    val_log_likelihood: -12178.119428504964\n",
      "    val_log_marginal: -12186.04820993168\n",
      "Train Epoch: 957 [256/118836 (0%)] Loss: 12297.465820\n",
      "Train Epoch: 957 [33024/118836 (28%)] Loss: 12242.886719\n",
      "Train Epoch: 957 [65792/118836 (55%)] Loss: 12300.939453\n",
      "Train Epoch: 957 [98560/118836 (83%)] Loss: 12270.055664\n",
      "    epoch          : 957\n",
      "    loss           : 12266.433462249275\n",
      "    val_loss       : 12265.701478948176\n",
      "    val_log_likelihood: -12178.504697677576\n",
      "    val_log_marginal: -12186.678048945707\n",
      "Train Epoch: 958 [256/118836 (0%)] Loss: 12252.134766\n",
      "Train Epoch: 958 [33024/118836 (28%)] Loss: 12323.958008\n",
      "Train Epoch: 958 [65792/118836 (55%)] Loss: 12277.359375\n",
      "Train Epoch: 958 [98560/118836 (83%)] Loss: 12306.259766\n",
      "    epoch          : 958\n",
      "    loss           : 12262.39465531948\n",
      "    val_loss       : 12260.466629130384\n",
      "    val_log_likelihood: -12178.788474462366\n",
      "    val_log_marginal: -12186.766070880454\n",
      "Train Epoch: 959 [256/118836 (0%)] Loss: 12255.840820\n",
      "Train Epoch: 959 [33024/118836 (28%)] Loss: 12220.661133\n",
      "Train Epoch: 959 [65792/118836 (55%)] Loss: 12329.058594\n",
      "Train Epoch: 959 [98560/118836 (83%)] Loss: 12270.648438\n",
      "    epoch          : 959\n",
      "    loss           : 12266.938606124637\n",
      "    val_loss       : 12265.86945208034\n",
      "    val_log_likelihood: -12176.582755473275\n",
      "    val_log_marginal: -12184.530079878652\n",
      "Train Epoch: 960 [256/118836 (0%)] Loss: 12255.877930\n",
      "Train Epoch: 960 [33024/118836 (28%)] Loss: 12221.961914\n",
      "Train Epoch: 960 [65792/118836 (55%)] Loss: 12314.240234\n",
      "Train Epoch: 960 [98560/118836 (83%)] Loss: 12225.220703\n",
      "    epoch          : 960\n",
      "    loss           : 12264.098164482526\n",
      "    val_loss       : 12263.574086257895\n",
      "    val_log_likelihood: -12181.576528090107\n",
      "    val_log_marginal: -12189.777262291556\n",
      "Train Epoch: 961 [256/118836 (0%)] Loss: 12332.020508\n",
      "Train Epoch: 961 [33024/118836 (28%)] Loss: 12249.579102\n",
      "Train Epoch: 961 [65792/118836 (55%)] Loss: 12297.162109\n",
      "Train Epoch: 961 [98560/118836 (83%)] Loss: 12235.267578\n",
      "    epoch          : 961\n",
      "    loss           : 12267.689218879239\n",
      "    val_loss       : 12263.057277646176\n",
      "    val_log_likelihood: -12178.713866864404\n",
      "    val_log_marginal: -12187.010626455902\n",
      "Train Epoch: 962 [256/118836 (0%)] Loss: 12294.317383\n",
      "Train Epoch: 962 [33024/118836 (28%)] Loss: 12297.854492\n",
      "Train Epoch: 962 [65792/118836 (55%)] Loss: 12382.730469\n",
      "Train Epoch: 962 [98560/118836 (83%)] Loss: 12371.714844\n",
      "    epoch          : 962\n",
      "    loss           : 12267.460598893715\n",
      "    val_loss       : 12265.772226413012\n",
      "    val_log_likelihood: -12178.150788358147\n",
      "    val_log_marginal: -12186.284847641575\n",
      "Train Epoch: 963 [256/118836 (0%)] Loss: 12300.302734\n",
      "Train Epoch: 963 [33024/118836 (28%)] Loss: 12321.944336\n",
      "Train Epoch: 963 [65792/118836 (55%)] Loss: 12288.876953\n",
      "Train Epoch: 963 [98560/118836 (83%)] Loss: 12305.966797\n",
      "    epoch          : 963\n",
      "    loss           : 12266.668497014578\n",
      "    val_loss       : 12263.571579161431\n",
      "    val_log_likelihood: -12178.41709202466\n",
      "    val_log_marginal: -12186.657675664917\n",
      "Train Epoch: 964 [256/118836 (0%)] Loss: 12315.922852\n",
      "Train Epoch: 964 [33024/118836 (28%)] Loss: 12303.411133\n",
      "Train Epoch: 964 [65792/118836 (55%)] Loss: 12314.085938\n",
      "Train Epoch: 964 [98560/118836 (83%)] Loss: 12313.570312\n",
      "    epoch          : 964\n",
      "    loss           : 12267.78676172198\n",
      "    val_loss       : 12267.786216376839\n",
      "    val_log_likelihood: -12180.519898127326\n",
      "    val_log_marginal: -12188.983440212738\n",
      "Train Epoch: 965 [256/118836 (0%)] Loss: 12223.755859\n",
      "Train Epoch: 965 [33024/118836 (28%)] Loss: 12254.404297\n",
      "Train Epoch: 965 [65792/118836 (55%)] Loss: 12312.890625\n",
      "Train Epoch: 965 [98560/118836 (83%)] Loss: 12336.015625\n",
      "    epoch          : 965\n",
      "    loss           : 12264.761333133012\n",
      "    val_loss       : 12259.527571067056\n",
      "    val_log_likelihood: -12180.026024865592\n",
      "    val_log_marginal: -12188.083399023179\n",
      "Train Epoch: 966 [256/118836 (0%)] Loss: 12339.070312\n",
      "Train Epoch: 966 [33024/118836 (28%)] Loss: 12271.797852\n",
      "Train Epoch: 966 [65792/118836 (55%)] Loss: 12218.312500\n",
      "Train Epoch: 966 [98560/118836 (83%)] Loss: 12238.466797\n",
      "    epoch          : 966\n",
      "    loss           : 12270.425151532774\n",
      "    val_loss       : 12263.781535549819\n",
      "    val_log_likelihood: -12180.156183603442\n",
      "    val_log_marginal: -12188.387142149695\n",
      "Train Epoch: 967 [256/118836 (0%)] Loss: 12177.655273\n",
      "Train Epoch: 967 [33024/118836 (28%)] Loss: 12304.933594\n",
      "Train Epoch: 967 [65792/118836 (55%)] Loss: 12200.884766\n",
      "Train Epoch: 967 [98560/118836 (83%)] Loss: 12313.167969\n",
      "    epoch          : 967\n",
      "    loss           : 12263.460261741368\n",
      "    val_loss       : 12260.703110560678\n",
      "    val_log_likelihood: -12180.632576315653\n",
      "    val_log_marginal: -12188.89088899351\n",
      "Train Epoch: 968 [256/118836 (0%)] Loss: 12304.372070\n",
      "Train Epoch: 968 [33024/118836 (28%)] Loss: 12323.718750\n",
      "Train Epoch: 968 [65792/118836 (55%)] Loss: 12348.437500\n",
      "Train Epoch: 968 [98560/118836 (83%)] Loss: 12258.240234\n",
      "    epoch          : 968\n",
      "    loss           : 12264.469112677058\n",
      "    val_loss       : 12263.666574314733\n",
      "    val_log_likelihood: -12178.906933997621\n",
      "    val_log_marginal: -12187.380115713742\n",
      "Train Epoch: 969 [256/118836 (0%)] Loss: 12302.410156\n",
      "Train Epoch: 969 [33024/118836 (28%)] Loss: 12225.417969\n",
      "Train Epoch: 969 [65792/118836 (55%)] Loss: 12258.740234\n",
      "Train Epoch: 969 [98560/118836 (83%)] Loss: 12251.791992\n",
      "    epoch          : 969\n",
      "    loss           : 12266.33651810639\n",
      "    val_loss       : 12264.739561894512\n",
      "    val_log_likelihood: -12179.013218730614\n",
      "    val_log_marginal: -12187.112513787422\n",
      "Train Epoch: 970 [256/118836 (0%)] Loss: 12203.908203\n",
      "Train Epoch: 970 [33024/118836 (28%)] Loss: 12376.962891\n",
      "Train Epoch: 970 [65792/118836 (55%)] Loss: 12364.404297\n",
      "Train Epoch: 970 [98560/118836 (83%)] Loss: 12327.984375\n",
      "    epoch          : 970\n",
      "    loss           : 12262.5389009512\n",
      "    val_loss       : 12261.041746748391\n",
      "    val_log_likelihood: -12179.86635100031\n",
      "    val_log_marginal: -12187.921111334947\n",
      "Train Epoch: 971 [256/118836 (0%)] Loss: 12256.532227\n",
      "Train Epoch: 971 [33024/118836 (28%)] Loss: 12179.052734\n",
      "Train Epoch: 971 [65792/118836 (55%)] Loss: 12227.522461\n",
      "Train Epoch: 971 [98560/118836 (83%)] Loss: 12298.589844\n",
      "    epoch          : 971\n",
      "    loss           : 12260.689009027346\n",
      "    val_loss       : 12264.726030389003\n",
      "    val_log_likelihood: -12178.423647998086\n",
      "    val_log_marginal: -12186.507307018861\n",
      "Train Epoch: 972 [256/118836 (0%)] Loss: 12217.744141\n",
      "Train Epoch: 972 [33024/118836 (28%)] Loss: 12280.664062\n",
      "Train Epoch: 972 [65792/118836 (55%)] Loss: 12268.794922\n",
      "Train Epoch: 972 [98560/118836 (83%)] Loss: 12248.525391\n",
      "    epoch          : 972\n",
      "    loss           : 12265.987993531586\n",
      "    val_loss       : 12266.010557813304\n",
      "    val_log_likelihood: -12177.876578331783\n",
      "    val_log_marginal: -12186.076853486062\n",
      "Train Epoch: 973 [256/118836 (0%)] Loss: 12220.615234\n",
      "Train Epoch: 973 [33024/118836 (28%)] Loss: 12316.906250\n",
      "Train Epoch: 973 [65792/118836 (55%)] Loss: 12285.996094\n",
      "Train Epoch: 973 [98560/118836 (83%)] Loss: 12282.470703\n",
      "    epoch          : 973\n",
      "    loss           : 12265.454125310174\n",
      "    val_loss       : 12269.317671612336\n",
      "    val_log_likelihood: -12179.920958049006\n",
      "    val_log_marginal: -12188.320085787624\n",
      "Train Epoch: 974 [256/118836 (0%)] Loss: 12297.535156\n",
      "Train Epoch: 974 [33024/118836 (28%)] Loss: 12237.556641\n",
      "Train Epoch: 974 [65792/118836 (55%)] Loss: 12293.378906\n",
      "Train Epoch: 974 [98560/118836 (83%)] Loss: 12262.270508\n",
      "    epoch          : 974\n",
      "    loss           : 12266.715061033137\n",
      "    val_loss       : 12281.3374325774\n",
      "    val_log_likelihood: -12181.072569336746\n",
      "    val_log_marginal: -12189.422857984253\n",
      "Train Epoch: 975 [256/118836 (0%)] Loss: 12295.223633\n",
      "Train Epoch: 975 [33024/118836 (28%)] Loss: 12347.316406\n",
      "Train Epoch: 975 [65792/118836 (55%)] Loss: 12273.041992\n",
      "Train Epoch: 975 [98560/118836 (83%)] Loss: 12340.689453\n",
      "    epoch          : 975\n",
      "    loss           : 12269.443210911653\n",
      "    val_loss       : 12264.95812183714\n",
      "    val_log_likelihood: -12180.159721199081\n",
      "    val_log_marginal: -12188.207004172617\n",
      "Train Epoch: 976 [256/118836 (0%)] Loss: 12399.027344\n",
      "Train Epoch: 976 [33024/118836 (28%)] Loss: 12291.347656\n",
      "Train Epoch: 976 [65792/118836 (55%)] Loss: 12311.948242\n",
      "Train Epoch: 976 [98560/118836 (83%)] Loss: 12311.957031\n",
      "    epoch          : 976\n",
      "    loss           : 12270.587013415014\n",
      "    val_loss       : 12264.142484970547\n",
      "    val_log_likelihood: -12178.085634919096\n",
      "    val_log_marginal: -12186.434706293534\n",
      "Train Epoch: 977 [256/118836 (0%)] Loss: 12230.362305\n",
      "Train Epoch: 977 [33024/118836 (28%)] Loss: 12266.074219\n",
      "Train Epoch: 977 [65792/118836 (55%)] Loss: 12329.567383\n",
      "Train Epoch: 977 [98560/118836 (83%)] Loss: 12304.247070\n",
      "    epoch          : 977\n",
      "    loss           : 12265.435943154207\n",
      "    val_loss       : 12261.157268111223\n",
      "    val_log_likelihood: -12179.819796836227\n",
      "    val_log_marginal: -12187.890557236064\n",
      "Train Epoch: 978 [256/118836 (0%)] Loss: 12315.666992\n",
      "Train Epoch: 978 [33024/118836 (28%)] Loss: 12293.847656\n",
      "Train Epoch: 978 [65792/118836 (55%)] Loss: 12242.731445\n",
      "Train Epoch: 978 [98560/118836 (83%)] Loss: 12246.687500\n",
      "    epoch          : 978\n",
      "    loss           : 12265.145356441273\n",
      "    val_loss       : 12262.401489293063\n",
      "    val_log_likelihood: -12176.297610693238\n",
      "    val_log_marginal: -12184.455488350079\n",
      "Train Epoch: 979 [256/118836 (0%)] Loss: 12263.056641\n",
      "Train Epoch: 979 [33024/118836 (28%)] Loss: 12354.623047\n",
      "Train Epoch: 979 [65792/118836 (55%)] Loss: 12210.511719\n",
      "Train Epoch: 979 [98560/118836 (83%)] Loss: 12264.840820\n",
      "    epoch          : 979\n",
      "    loss           : 12261.181495877276\n",
      "    val_loss       : 12262.871161775909\n",
      "    val_log_likelihood: -12176.180046461435\n",
      "    val_log_marginal: -12184.238446421568\n",
      "Train Epoch: 980 [256/118836 (0%)] Loss: 12248.046875\n",
      "Train Epoch: 980 [33024/118836 (28%)] Loss: 12255.365234\n",
      "Train Epoch: 980 [65792/118836 (55%)] Loss: 12243.542969\n",
      "Train Epoch: 980 [98560/118836 (83%)] Loss: 12311.726562\n",
      "    epoch          : 980\n",
      "    loss           : 12265.051846341243\n",
      "    val_loss       : 12262.154624636501\n",
      "    val_log_likelihood: -12176.64888482863\n",
      "    val_log_marginal: -12184.935887336902\n",
      "Train Epoch: 981 [256/118836 (0%)] Loss: 12308.911133\n",
      "Train Epoch: 981 [33024/118836 (28%)] Loss: 12334.623047\n",
      "Train Epoch: 981 [65792/118836 (55%)] Loss: 12279.495117\n",
      "Train Epoch: 981 [98560/118836 (83%)] Loss: 12241.940430\n",
      "    epoch          : 981\n",
      "    loss           : 12264.680429816739\n",
      "    val_loss       : 12264.994581755609\n",
      "    val_log_likelihood: -12176.751883820565\n",
      "    val_log_marginal: -12185.024541142073\n",
      "Train Epoch: 982 [256/118836 (0%)] Loss: 12335.697266\n",
      "Train Epoch: 982 [33024/118836 (28%)] Loss: 12360.864258\n",
      "Train Epoch: 982 [65792/118836 (55%)] Loss: 12211.451172\n",
      "Train Epoch: 982 [98560/118836 (83%)] Loss: 12342.243164\n",
      "    epoch          : 982\n",
      "    loss           : 12265.522662388854\n",
      "    val_loss       : 12265.035896596724\n",
      "    val_log_likelihood: -12177.672569659842\n",
      "    val_log_marginal: -12186.03638622907\n",
      "Train Epoch: 983 [256/118836 (0%)] Loss: 12249.745117\n",
      "Train Epoch: 983 [33024/118836 (28%)] Loss: 12298.251953\n",
      "Train Epoch: 983 [65792/118836 (55%)] Loss: 12376.497070\n",
      "Train Epoch: 983 [98560/118836 (83%)] Loss: 12328.072266\n",
      "    epoch          : 983\n",
      "    loss           : 12263.504416421112\n",
      "    val_loss       : 12259.960510153034\n",
      "    val_log_likelihood: -12178.890842929331\n",
      "    val_log_marginal: -12187.316639737479\n",
      "Train Epoch: 984 [256/118836 (0%)] Loss: 12255.425781\n",
      "Train Epoch: 984 [33024/118836 (28%)] Loss: 12326.044922\n",
      "Train Epoch: 984 [65792/118836 (55%)] Loss: 12290.021484\n",
      "Train Epoch: 984 [98560/118836 (83%)] Loss: 12377.982422\n",
      "    epoch          : 984\n",
      "    loss           : 12265.052511437656\n",
      "    val_loss       : 12265.121227975631\n",
      "    val_log_likelihood: -12181.163186420854\n",
      "    val_log_marginal: -12189.44861386429\n",
      "Train Epoch: 985 [256/118836 (0%)] Loss: 12258.283203\n",
      "Train Epoch: 985 [33024/118836 (28%)] Loss: 12229.762695\n",
      "Train Epoch: 985 [65792/118836 (55%)] Loss: 12391.955078\n",
      "Train Epoch: 985 [98560/118836 (83%)] Loss: 12241.591797\n",
      "    epoch          : 985\n",
      "    loss           : 12270.649904847756\n",
      "    val_loss       : 12262.848504503416\n",
      "    val_log_likelihood: -12178.903501247156\n",
      "    val_log_marginal: -12187.118556981863\n",
      "Train Epoch: 986 [256/118836 (0%)] Loss: 12234.104492\n",
      "Train Epoch: 986 [33024/118836 (28%)] Loss: 12321.482422\n",
      "Train Epoch: 986 [65792/118836 (55%)] Loss: 12346.938477\n",
      "Train Epoch: 986 [98560/118836 (83%)] Loss: 12249.439453\n",
      "    epoch          : 986\n",
      "    loss           : 12263.88530148237\n",
      "    val_loss       : 12259.90589897505\n",
      "    val_log_likelihood: -12176.984440588813\n",
      "    val_log_marginal: -12185.335890289798\n",
      "Train Epoch: 987 [256/118836 (0%)] Loss: 12345.384766\n",
      "Train Epoch: 987 [33024/118836 (28%)] Loss: 12292.039062\n",
      "Train Epoch: 987 [65792/118836 (55%)] Loss: 12212.364258\n",
      "Train Epoch: 987 [98560/118836 (83%)] Loss: 12311.454102\n",
      "    epoch          : 987\n",
      "    loss           : 12264.251532936569\n",
      "    val_loss       : 12267.19096118089\n",
      "    val_log_likelihood: -12178.777951658136\n",
      "    val_log_marginal: -12187.001366001758\n",
      "Train Epoch: 988 [256/118836 (0%)] Loss: 12256.286133\n",
      "Train Epoch: 988 [33024/118836 (28%)] Loss: 12325.490234\n",
      "Train Epoch: 988 [65792/118836 (55%)] Loss: 12378.602539\n",
      "Train Epoch: 988 [98560/118836 (83%)] Loss: 12226.688477\n",
      "    epoch          : 988\n",
      "    loss           : 12268.532704100753\n",
      "    val_loss       : 12265.959490316263\n",
      "    val_log_likelihood: -12176.467257935277\n",
      "    val_log_marginal: -12184.569899954256\n",
      "Train Epoch: 989 [256/118836 (0%)] Loss: 12300.171875\n",
      "Train Epoch: 989 [33024/118836 (28%)] Loss: 12353.166992\n",
      "Train Epoch: 989 [65792/118836 (55%)] Loss: 12316.052734\n",
      "Train Epoch: 989 [98560/118836 (83%)] Loss: 12273.592773\n",
      "    epoch          : 989\n",
      "    loss           : 12265.854341624019\n",
      "    val_loss       : 12262.384067008217\n",
      "    val_log_likelihood: -12177.802784616677\n",
      "    val_log_marginal: -12185.929671280683\n",
      "Train Epoch: 990 [256/118836 (0%)] Loss: 12433.999023\n",
      "Train Epoch: 990 [33024/118836 (28%)] Loss: 12179.263672\n",
      "Train Epoch: 990 [65792/118836 (55%)] Loss: 12234.703125\n",
      "Train Epoch: 990 [98560/118836 (83%)] Loss: 12257.720703\n",
      "    epoch          : 990\n",
      "    loss           : 12261.978820952232\n",
      "    val_loss       : 12264.695939738163\n",
      "    val_log_likelihood: -12178.388046196496\n",
      "    val_log_marginal: -12186.824490999967\n",
      "Train Epoch: 991 [256/118836 (0%)] Loss: 12247.544922\n",
      "Train Epoch: 991 [33024/118836 (28%)] Loss: 12299.122070\n",
      "Train Epoch: 991 [65792/118836 (55%)] Loss: 12225.360352\n",
      "Train Epoch: 991 [98560/118836 (83%)] Loss: 12216.115234\n",
      "    epoch          : 991\n",
      "    loss           : 12261.847949461075\n",
      "    val_loss       : 12270.13504689056\n",
      "    val_log_likelihood: -12177.820316377172\n",
      "    val_log_marginal: -12186.149142884415\n",
      "Train Epoch: 992 [256/118836 (0%)] Loss: 12302.993164\n",
      "Train Epoch: 992 [33024/118836 (28%)] Loss: 12285.788086\n",
      "Train Epoch: 992 [65792/118836 (55%)] Loss: 12337.498047\n",
      "Train Epoch: 992 [98560/118836 (83%)] Loss: 12239.051758\n",
      "    epoch          : 992\n",
      "    loss           : 12264.774345242711\n",
      "    val_loss       : 12262.921432777486\n",
      "    val_log_likelihood: -12178.768644993279\n",
      "    val_log_marginal: -12187.141716790942\n",
      "Train Epoch: 993 [256/118836 (0%)] Loss: 12246.497070\n",
      "Train Epoch: 993 [33024/118836 (28%)] Loss: 12404.701172\n",
      "Train Epoch: 993 [65792/118836 (55%)] Loss: 12241.160156\n",
      "Train Epoch: 993 [98560/118836 (83%)] Loss: 12292.687500\n",
      "    epoch          : 993\n",
      "    loss           : 12266.075532464847\n",
      "    val_loss       : 12265.317341459853\n",
      "    val_log_likelihood: -12176.308827349565\n",
      "    val_log_marginal: -12184.630881987063\n",
      "Train Epoch: 994 [256/118836 (0%)] Loss: 12255.406250\n",
      "Train Epoch: 994 [33024/118836 (28%)] Loss: 12271.929688\n",
      "Train Epoch: 994 [65792/118836 (55%)] Loss: 12253.468750\n",
      "Train Epoch: 994 [98560/118836 (83%)] Loss: 12312.751953\n",
      "    epoch          : 994\n",
      "    loss           : 12268.92466187836\n",
      "    val_loss       : 12265.824970630636\n",
      "    val_log_likelihood: -12179.523230394436\n",
      "    val_log_marginal: -12187.864153338553\n",
      "Train Epoch: 995 [256/118836 (0%)] Loss: 12272.755859\n",
      "Train Epoch: 995 [33024/118836 (28%)] Loss: 12214.313477\n",
      "Train Epoch: 995 [65792/118836 (55%)] Loss: 12237.866211\n",
      "Train Epoch: 995 [98560/118836 (83%)] Loss: 12363.439453\n",
      "    epoch          : 995\n",
      "    loss           : 12267.524951050713\n",
      "    val_loss       : 12263.643765850273\n",
      "    val_log_likelihood: -12179.903698013597\n",
      "    val_log_marginal: -12188.258530673593\n",
      "Train Epoch: 996 [256/118836 (0%)] Loss: 12321.587891\n",
      "Train Epoch: 996 [33024/118836 (28%)] Loss: 12277.783203\n",
      "Train Epoch: 996 [65792/118836 (55%)] Loss: 12256.127930\n",
      "Train Epoch: 996 [98560/118836 (83%)] Loss: 12356.496094\n",
      "    epoch          : 996\n",
      "    loss           : 12261.4496563857\n",
      "    val_loss       : 12268.623209384947\n",
      "    val_log_likelihood: -12175.962074642008\n",
      "    val_log_marginal: -12184.444192763565\n",
      "Train Epoch: 997 [256/118836 (0%)] Loss: 12248.084961\n",
      "Train Epoch: 997 [33024/118836 (28%)] Loss: 12288.639648\n",
      "Train Epoch: 997 [65792/118836 (55%)] Loss: 12260.515625\n",
      "Train Epoch: 997 [98560/118836 (83%)] Loss: 12276.933594\n",
      "    epoch          : 997\n",
      "    loss           : 12267.376576716295\n",
      "    val_loss       : 12267.680497889532\n",
      "    val_log_likelihood: -12180.468807188276\n",
      "    val_log_marginal: -12188.448839631485\n",
      "Train Epoch: 998 [256/118836 (0%)] Loss: 12298.184570\n",
      "Train Epoch: 998 [33024/118836 (28%)] Loss: 12380.989258\n",
      "Train Epoch: 998 [65792/118836 (55%)] Loss: 12206.563477\n",
      "Train Epoch: 998 [98560/118836 (83%)] Loss: 12288.476562\n",
      "    epoch          : 998\n",
      "    loss           : 12261.568867607526\n",
      "    val_loss       : 12262.392225207383\n",
      "    val_log_likelihood: -12175.668140476375\n",
      "    val_log_marginal: -12183.639397327834\n",
      "Train Epoch: 999 [256/118836 (0%)] Loss: 12257.389648\n",
      "Train Epoch: 999 [33024/118836 (28%)] Loss: 12263.111328\n",
      "Train Epoch: 999 [65792/118836 (55%)] Loss: 12303.126953\n",
      "Train Epoch: 999 [98560/118836 (83%)] Loss: 12248.903320\n",
      "    epoch          : 999\n",
      "    loss           : 12264.43891694453\n",
      "    val_loss       : 12265.746130144034\n",
      "    val_log_likelihood: -12179.643393784894\n",
      "    val_log_marginal: -12188.120627437791\n",
      "Train Epoch: 1000 [256/118836 (0%)] Loss: 12237.599609\n",
      "Train Epoch: 1000 [33024/118836 (28%)] Loss: 12230.997070\n",
      "Train Epoch: 1000 [65792/118836 (55%)] Loss: 12325.847656\n",
      "Train Epoch: 1000 [98560/118836 (83%)] Loss: 12327.193359\n",
      "    epoch          : 1000\n",
      "    loss           : 12263.622860447684\n",
      "    val_loss       : 12265.173757603008\n",
      "    val_log_likelihood: -12176.922245754498\n",
      "    val_log_marginal: -12185.096981241986\n",
      "Saving checkpoint: saved/models/SelfiesAutoencodingOperad/0905_154251/checkpoint-epoch1000.pth ...\n",
      "Train Epoch: 1001 [256/118836 (0%)] Loss: 12302.240234\n",
      "Train Epoch: 1001 [33024/118836 (28%)] Loss: 12211.125977\n",
      "Train Epoch: 1001 [65792/118836 (55%)] Loss: 12261.953125\n",
      "Train Epoch: 1001 [98560/118836 (83%)] Loss: 12374.759766\n",
      "    epoch          : 1001\n",
      "    loss           : 12263.068389907723\n",
      "    val_loss       : 12261.350301374096\n",
      "    val_log_likelihood: -12177.56611271583\n",
      "    val_log_marginal: -12185.661109829718\n",
      "Train Epoch: 1002 [256/118836 (0%)] Loss: 12358.149414\n",
      "Train Epoch: 1002 [33024/118836 (28%)] Loss: 12229.100586\n",
      "Train Epoch: 1002 [65792/118836 (55%)] Loss: 12269.435547\n",
      "Train Epoch: 1002 [98560/118836 (83%)] Loss: 12248.407227\n",
      "    epoch          : 1002\n",
      "    loss           : 12263.38141445668\n",
      "    val_loss       : 12261.132063484634\n",
      "    val_log_likelihood: -12178.004118848221\n",
      "    val_log_marginal: -12186.260206284032\n",
      "Train Epoch: 1003 [256/118836 (0%)] Loss: 12303.901367\n",
      "Train Epoch: 1003 [33024/118836 (28%)] Loss: 12312.237305\n",
      "Train Epoch: 1003 [65792/118836 (55%)] Loss: 12308.712891\n",
      "Train Epoch: 1003 [98560/118836 (83%)] Loss: 12313.971680\n",
      "    epoch          : 1003\n",
      "    loss           : 12261.713653296887\n",
      "    val_loss       : 12261.256973213305\n",
      "    val_log_likelihood: -12176.798215531948\n",
      "    val_log_marginal: -12184.73496701874\n",
      "Train Epoch: 1004 [256/118836 (0%)] Loss: 12315.425781\n",
      "Train Epoch: 1004 [33024/118836 (28%)] Loss: 12217.627930\n",
      "Train Epoch: 1004 [65792/118836 (55%)] Loss: 12301.708008\n",
      "Train Epoch: 1004 [98560/118836 (83%)] Loss: 12207.052734\n",
      "    epoch          : 1004\n",
      "    loss           : 12267.228323705025\n",
      "    val_loss       : 12259.586520729747\n",
      "    val_log_likelihood: -12174.413794975188\n",
      "    val_log_marginal: -12182.488032617415\n",
      "Train Epoch: 1005 [256/118836 (0%)] Loss: 12354.098633\n",
      "Train Epoch: 1005 [33024/118836 (28%)] Loss: 12260.954102\n",
      "Train Epoch: 1005 [65792/118836 (55%)] Loss: 12253.148438\n",
      "Train Epoch: 1005 [98560/118836 (83%)] Loss: 12334.065430\n",
      "    epoch          : 1005\n",
      "    loss           : 12261.356903141801\n",
      "    val_loss       : 12266.53903359754\n",
      "    val_log_likelihood: -12177.55760103262\n",
      "    val_log_marginal: -12186.103945628978\n",
      "Train Epoch: 1006 [256/118836 (0%)] Loss: 12262.246094\n",
      "Train Epoch: 1006 [33024/118836 (28%)] Loss: 12223.533203\n",
      "Train Epoch: 1006 [65792/118836 (55%)] Loss: 12351.438477\n",
      "Train Epoch: 1006 [98560/118836 (83%)] Loss: 12187.130859\n",
      "    epoch          : 1006\n",
      "    loss           : 12272.215052309502\n",
      "    val_loss       : 12261.562510187769\n",
      "    val_log_likelihood: -12175.712557834471\n",
      "    val_log_marginal: -12183.935821394696\n",
      "Train Epoch: 1007 [256/118836 (0%)] Loss: 12359.300781\n",
      "Train Epoch: 1007 [33024/118836 (28%)] Loss: 12245.472656\n",
      "Train Epoch: 1007 [65792/118836 (55%)] Loss: 12217.834961\n",
      "Train Epoch: 1007 [98560/118836 (83%)] Loss: 12205.362305\n",
      "    epoch          : 1007\n",
      "    loss           : 12262.227822419096\n",
      "    val_loss       : 12263.331560573995\n",
      "    val_log_likelihood: -12175.954624819065\n",
      "    val_log_marginal: -12184.082684024625\n",
      "Train Epoch: 1008 [256/118836 (0%)] Loss: 12269.566406\n",
      "Train Epoch: 1008 [33024/118836 (28%)] Loss: 12201.994141\n",
      "Train Epoch: 1008 [65792/118836 (55%)] Loss: 12320.712891\n",
      "Train Epoch: 1008 [98560/118836 (83%)] Loss: 12244.488281\n",
      "    epoch          : 1008\n",
      "    loss           : 12268.35385520058\n",
      "    val_loss       : 12267.959516520117\n",
      "    val_log_likelihood: -12185.812675765095\n",
      "    val_log_marginal: -12194.70449263669\n",
      "Train Epoch: 1009 [256/118836 (0%)] Loss: 12279.537109\n",
      "Train Epoch: 1009 [33024/118836 (28%)] Loss: 12248.773438\n",
      "Train Epoch: 1009 [65792/118836 (55%)] Loss: 12266.458984\n",
      "Train Epoch: 1009 [98560/118836 (83%)] Loss: 12244.325195\n",
      "    epoch          : 1009\n",
      "    loss           : 12265.782804907205\n",
      "    val_loss       : 12266.713507935974\n",
      "    val_log_likelihood: -12177.148230879086\n",
      "    val_log_marginal: -12185.456519699548\n",
      "Train Epoch: 1010 [256/118836 (0%)] Loss: 12309.303711\n",
      "Train Epoch: 1010 [33024/118836 (28%)] Loss: 12230.812500\n",
      "Train Epoch: 1010 [65792/118836 (55%)] Loss: 12329.244141\n",
      "Train Epoch: 1010 [98560/118836 (83%)] Loss: 12229.445312\n",
      "    epoch          : 1010\n",
      "    loss           : 12266.407477286237\n",
      "    val_loss       : 12269.597753513755\n",
      "    val_log_likelihood: -12180.75534209574\n",
      "    val_log_marginal: -12189.131968762105\n",
      "Train Epoch: 1011 [256/118836 (0%)] Loss: 12252.625000\n",
      "Train Epoch: 1011 [33024/118836 (28%)] Loss: 12274.386719\n",
      "Train Epoch: 1011 [65792/118836 (55%)] Loss: 12238.148438\n",
      "Train Epoch: 1011 [98560/118836 (83%)] Loss: 12295.783203\n",
      "    epoch          : 1011\n",
      "    loss           : 12266.658763214691\n",
      "    val_loss       : 12257.706849537715\n",
      "    val_log_likelihood: -12178.960636857682\n",
      "    val_log_marginal: -12186.946194238668\n",
      "Train Epoch: 1012 [256/118836 (0%)] Loss: 12333.605469\n",
      "Train Epoch: 1012 [33024/118836 (28%)] Loss: 12298.605469\n",
      "Train Epoch: 1012 [65792/118836 (55%)] Loss: 12189.396484\n",
      "Train Epoch: 1012 [98560/118836 (83%)] Loss: 12333.531250\n",
      "    epoch          : 1012\n",
      "    loss           : 12267.732375025847\n",
      "    val_loss       : 12263.60023839837\n",
      "    val_log_likelihood: -12174.846681626084\n",
      "    val_log_marginal: -12183.226456257318\n",
      "Train Epoch: 1013 [256/118836 (0%)] Loss: 12248.780273\n",
      "Train Epoch: 1013 [33024/118836 (28%)] Loss: 12302.448242\n",
      "Train Epoch: 1013 [65792/118836 (55%)] Loss: 12229.053711\n",
      "Train Epoch: 1013 [98560/118836 (83%)] Loss: 12395.998047\n",
      "    epoch          : 1013\n",
      "    loss           : 12263.13046891155\n",
      "    val_loss       : 12263.462272942457\n",
      "    val_log_likelihood: -12177.563911451873\n",
      "    val_log_marginal: -12185.576264900194\n",
      "Train Epoch: 1014 [256/118836 (0%)] Loss: 12418.079102\n",
      "Train Epoch: 1014 [33024/118836 (28%)] Loss: 12279.557617\n",
      "Train Epoch: 1014 [65792/118836 (55%)] Loss: 12288.105469\n",
      "Train Epoch: 1014 [98560/118836 (83%)] Loss: 12280.761719\n",
      "    epoch          : 1014\n",
      "    loss           : 12266.99929031612\n",
      "    val_loss       : 12265.141962438845\n",
      "    val_log_likelihood: -12178.89454611249\n",
      "    val_log_marginal: -12186.948863648837\n",
      "Train Epoch: 1015 [256/118836 (0%)] Loss: 12197.883789\n",
      "Train Epoch: 1015 [33024/118836 (28%)] Loss: 12282.692383\n",
      "Train Epoch: 1015 [65792/118836 (55%)] Loss: 12346.420898\n",
      "Train Epoch: 1015 [98560/118836 (83%)] Loss: 12237.431641\n",
      "    epoch          : 1015\n",
      "    loss           : 12262.713418889578\n",
      "    val_loss       : 12264.384526913733\n",
      "    val_log_likelihood: -12177.846226381565\n",
      "    val_log_marginal: -12186.087413418893\n",
      "Train Epoch: 1016 [256/118836 (0%)] Loss: 12359.089844\n",
      "Train Epoch: 1016 [33024/118836 (28%)] Loss: 12256.201172\n",
      "Train Epoch: 1016 [65792/118836 (55%)] Loss: 12412.699219\n",
      "Train Epoch: 1016 [98560/118836 (83%)] Loss: 12212.868164\n",
      "    epoch          : 1016\n",
      "    loss           : 12264.331339659584\n",
      "    val_loss       : 12263.966109213798\n",
      "    val_log_likelihood: -12181.744846431711\n",
      "    val_log_marginal: -12189.888080418685\n",
      "Train Epoch: 1017 [256/118836 (0%)] Loss: 12263.419922\n",
      "Train Epoch: 1017 [33024/118836 (28%)] Loss: 12367.367188\n",
      "Train Epoch: 1017 [65792/118836 (55%)] Loss: 12210.134766\n",
      "Train Epoch: 1017 [98560/118836 (83%)] Loss: 12309.388672\n",
      "    epoch          : 1017\n",
      "    loss           : 12263.619889242142\n",
      "    val_loss       : 12266.770566850624\n",
      "    val_log_likelihood: -12178.377761676747\n",
      "    val_log_marginal: -12186.688768079252\n",
      "Train Epoch: 1018 [256/118836 (0%)] Loss: 12200.554688\n",
      "Train Epoch: 1018 [33024/118836 (28%)] Loss: 12299.467773\n",
      "Train Epoch: 1018 [65792/118836 (55%)] Loss: 12238.958008\n",
      "Train Epoch: 1018 [98560/118836 (83%)] Loss: 12354.264648\n",
      "    epoch          : 1018\n",
      "    loss           : 12261.081107837055\n",
      "    val_loss       : 12261.251113514778\n",
      "    val_log_likelihood: -12175.40821120244\n",
      "    val_log_marginal: -12183.791503442846\n",
      "Train Epoch: 1019 [256/118836 (0%)] Loss: 12239.028320\n",
      "Train Epoch: 1019 [33024/118836 (28%)] Loss: 12194.708984\n",
      "Train Epoch: 1019 [65792/118836 (55%)] Loss: 12319.312500\n",
      "Train Epoch: 1019 [98560/118836 (83%)] Loss: 12305.086914\n",
      "    epoch          : 1019\n",
      "    loss           : 12268.459375646196\n",
      "    val_loss       : 12262.154070216095\n",
      "    val_log_likelihood: -12179.080580218673\n",
      "    val_log_marginal: -12187.213636264576\n",
      "Train Epoch: 1020 [256/118836 (0%)] Loss: 12225.568359\n",
      "Train Epoch: 1020 [33024/118836 (28%)] Loss: 12256.277344\n",
      "Train Epoch: 1020 [65792/118836 (55%)] Loss: 12217.574219\n",
      "Train Epoch: 1020 [98560/118836 (83%)] Loss: 12304.852539\n",
      "    epoch          : 1020\n",
      "    loss           : 12261.995397151572\n",
      "    val_loss       : 12265.302775921344\n",
      "    val_log_likelihood: -12175.769127377998\n",
      "    val_log_marginal: -12183.960059415112\n",
      "Train Epoch: 1021 [256/118836 (0%)] Loss: 12244.882812\n",
      "Train Epoch: 1021 [33024/118836 (28%)] Loss: 12301.566406\n",
      "Train Epoch: 1021 [65792/118836 (55%)] Loss: 12286.877930\n",
      "Train Epoch: 1021 [98560/118836 (83%)] Loss: 12272.877930\n",
      "    epoch          : 1021\n",
      "    loss           : 12263.535330238059\n",
      "    val_loss       : 12261.71701508372\n",
      "    val_log_likelihood: -12177.612692081524\n",
      "    val_log_marginal: -12186.008923539182\n",
      "Train Epoch: 1022 [256/118836 (0%)] Loss: 12329.789062\n",
      "Train Epoch: 1022 [33024/118836 (28%)] Loss: 12305.730469\n",
      "Train Epoch: 1022 [65792/118836 (55%)] Loss: 12373.765625\n",
      "Train Epoch: 1022 [98560/118836 (83%)] Loss: 12240.366211\n",
      "    epoch          : 1022\n",
      "    loss           : 12266.143105904932\n",
      "    val_loss       : 12262.180201127761\n",
      "    val_log_likelihood: -12179.488165096413\n",
      "    val_log_marginal: -12187.794255002696\n",
      "Train Epoch: 1023 [256/118836 (0%)] Loss: 12247.789062\n",
      "Train Epoch: 1023 [33024/118836 (28%)] Loss: 12324.333008\n",
      "Train Epoch: 1023 [65792/118836 (55%)] Loss: 12248.246094\n",
      "Train Epoch: 1023 [98560/118836 (83%)] Loss: 12352.132812\n",
      "    epoch          : 1023\n",
      "    loss           : 12263.78197632341\n",
      "    val_loss       : 12265.09120002467\n",
      "    val_log_likelihood: -12175.550169464692\n",
      "    val_log_marginal: -12183.58689292303\n",
      "Train Epoch: 1024 [256/118836 (0%)] Loss: 12305.437500\n",
      "Train Epoch: 1024 [33024/118836 (28%)] Loss: 12287.849609\n",
      "Train Epoch: 1024 [65792/118836 (55%)] Loss: 12216.375000\n",
      "Train Epoch: 1024 [98560/118836 (83%)] Loss: 12269.246094\n",
      "    epoch          : 1024\n",
      "    loss           : 12260.850854431608\n",
      "    val_loss       : 12268.83220553289\n",
      "    val_log_likelihood: -12177.294623817463\n",
      "    val_log_marginal: -12185.29696766939\n",
      "Train Epoch: 1025 [256/118836 (0%)] Loss: 12283.645508\n",
      "Train Epoch: 1025 [33024/118836 (28%)] Loss: 12264.822266\n",
      "Train Epoch: 1025 [65792/118836 (55%)] Loss: 12416.640625\n",
      "Train Epoch: 1025 [98560/118836 (83%)] Loss: 12328.291992\n",
      "    epoch          : 1025\n",
      "    loss           : 12268.649238620503\n",
      "    val_loss       : 12270.474213022058\n",
      "    val_log_likelihood: -12179.280175700475\n",
      "    val_log_marginal: -12187.686472789843\n",
      "Train Epoch: 1026 [256/118836 (0%)] Loss: 12320.650391\n",
      "Train Epoch: 1026 [33024/118836 (28%)] Loss: 12316.351562\n",
      "Train Epoch: 1026 [65792/118836 (55%)] Loss: 12335.165039\n",
      "Train Epoch: 1026 [98560/118836 (83%)] Loss: 12254.148438\n",
      "    epoch          : 1026\n",
      "    loss           : 12267.597648011011\n",
      "    val_loss       : 12264.40936701907\n",
      "    val_log_likelihood: -12179.45794335453\n",
      "    val_log_marginal: -12187.926739171999\n",
      "Train Epoch: 1027 [256/118836 (0%)] Loss: 12288.703125\n",
      "Train Epoch: 1027 [33024/118836 (28%)] Loss: 12332.106445\n",
      "Train Epoch: 1027 [65792/118836 (55%)] Loss: 12263.138672\n",
      "Train Epoch: 1027 [98560/118836 (83%)] Loss: 12309.984375\n",
      "    epoch          : 1027\n",
      "    loss           : 12269.328473945408\n",
      "    val_loss       : 12269.149582666016\n",
      "    val_log_likelihood: -12177.754781198306\n",
      "    val_log_marginal: -12186.102992730857\n",
      "Train Epoch: 1028 [256/118836 (0%)] Loss: 12407.139648\n",
      "Train Epoch: 1028 [33024/118836 (28%)] Loss: 12197.703125\n",
      "Train Epoch: 1028 [65792/118836 (55%)] Loss: 12266.124023\n",
      "Train Epoch: 1028 [98560/118836 (83%)] Loss: 12344.072266\n",
      "    epoch          : 1028\n",
      "    loss           : 12265.381530610268\n",
      "    val_loss       : 12266.501872116283\n",
      "    val_log_likelihood: -12177.651170097963\n",
      "    val_log_marginal: -12185.926348911973\n",
      "Train Epoch: 1029 [256/118836 (0%)] Loss: 12350.000000\n",
      "Train Epoch: 1029 [33024/118836 (28%)] Loss: 12241.056641\n",
      "Train Epoch: 1029 [65792/118836 (55%)] Loss: 12371.855469\n",
      "Train Epoch: 1029 [98560/118836 (83%)] Loss: 12358.654297\n",
      "    epoch          : 1029\n",
      "    loss           : 12264.220104748243\n",
      "    val_loss       : 12260.644644182557\n",
      "    val_log_likelihood: -12175.718956459368\n",
      "    val_log_marginal: -12183.82779973821\n",
      "Train Epoch: 1030 [256/118836 (0%)] Loss: 12364.077148\n",
      "Train Epoch: 1030 [33024/118836 (28%)] Loss: 12280.888672\n",
      "Train Epoch: 1030 [65792/118836 (55%)] Loss: 12364.597656\n",
      "Train Epoch: 1030 [98560/118836 (83%)] Loss: 12243.310547\n",
      "    epoch          : 1030\n",
      "    loss           : 12263.376357333023\n",
      "    val_loss       : 12265.71146429738\n",
      "    val_log_likelihood: -12175.650067042752\n",
      "    val_log_marginal: -12183.899992004803\n",
      "Train Epoch: 1031 [256/118836 (0%)] Loss: 12336.000000\n",
      "Train Epoch: 1031 [33024/118836 (28%)] Loss: 12226.737305\n",
      "Train Epoch: 1031 [65792/118836 (55%)] Loss: 12254.216797\n",
      "Train Epoch: 1031 [98560/118836 (83%)] Loss: 12240.609375\n",
      "    epoch          : 1031\n",
      "    loss           : 12265.84814929694\n",
      "    val_loss       : 12263.481939061114\n",
      "    val_log_likelihood: -12175.397327336641\n",
      "    val_log_marginal: -12183.618626395832\n",
      "Train Epoch: 1032 [256/118836 (0%)] Loss: 12281.160156\n",
      "Train Epoch: 1032 [33024/118836 (28%)] Loss: 12251.602539\n",
      "Train Epoch: 1032 [65792/118836 (55%)] Loss: 12224.230469\n",
      "Train Epoch: 1032 [98560/118836 (83%)] Loss: 12389.754883\n",
      "    epoch          : 1032\n",
      "    loss           : 12264.148989512252\n",
      "    val_loss       : 12266.500974879002\n",
      "    val_log_likelihood: -12178.223767382651\n",
      "    val_log_marginal: -12186.314780674411\n",
      "Train Epoch: 1033 [256/118836 (0%)] Loss: 12185.072266\n",
      "Train Epoch: 1033 [33024/118836 (28%)] Loss: 12205.247070\n",
      "Train Epoch: 1033 [65792/118836 (55%)] Loss: 12318.500000\n",
      "Train Epoch: 1033 [98560/118836 (83%)] Loss: 12269.900391\n",
      "    epoch          : 1033\n",
      "    loss           : 12257.023035243486\n",
      "    val_loss       : 12261.293522203\n",
      "    val_log_likelihood: -12175.882448207454\n",
      "    val_log_marginal: -12183.869516688213\n",
      "Train Epoch: 1034 [256/118836 (0%)] Loss: 12312.171875\n",
      "Train Epoch: 1034 [33024/118836 (28%)] Loss: 12326.861328\n",
      "Train Epoch: 1034 [65792/118836 (55%)] Loss: 12283.135742\n",
      "Train Epoch: 1034 [98560/118836 (83%)] Loss: 12217.629883\n",
      "    epoch          : 1034\n",
      "    loss           : 12261.879145826872\n",
      "    val_loss       : 12262.787253295452\n",
      "    val_log_likelihood: -12177.666312713243\n",
      "    val_log_marginal: -12185.610402836803\n",
      "Train Epoch: 1035 [256/118836 (0%)] Loss: 12263.803711\n",
      "Train Epoch: 1035 [33024/118836 (28%)] Loss: 12230.533203\n",
      "Train Epoch: 1035 [65792/118836 (55%)] Loss: 12214.028320\n",
      "Train Epoch: 1035 [98560/118836 (83%)] Loss: 12308.445312\n",
      "    epoch          : 1035\n",
      "    loss           : 12263.611440562965\n",
      "    val_loss       : 12265.130928542116\n",
      "    val_log_likelihood: -12176.215124198718\n",
      "    val_log_marginal: -12184.103083051776\n",
      "Train Epoch: 1036 [256/118836 (0%)] Loss: 12268.958984\n",
      "Train Epoch: 1036 [33024/118836 (28%)] Loss: 12263.255859\n",
      "Train Epoch: 1036 [65792/118836 (55%)] Loss: 12280.376953\n",
      "Train Epoch: 1036 [98560/118836 (83%)] Loss: 12242.125977\n",
      "    epoch          : 1036\n",
      "    loss           : 12276.76708249328\n",
      "    val_loss       : 12263.469310963026\n",
      "    val_log_likelihood: -12176.348225709522\n",
      "    val_log_marginal: -12184.903548973358\n",
      "Train Epoch: 1037 [256/118836 (0%)] Loss: 12313.984375\n",
      "Train Epoch: 1037 [33024/118836 (28%)] Loss: 12397.049805\n",
      "Train Epoch: 1037 [65792/118836 (55%)] Loss: 12365.298828\n",
      "Train Epoch: 1037 [98560/118836 (83%)] Loss: 12273.251953\n",
      "    epoch          : 1037\n",
      "    loss           : 12263.852547301489\n",
      "    val_loss       : 12266.50435297731\n",
      "    val_log_likelihood: -12177.072226368642\n",
      "    val_log_marginal: -12185.16567837162\n",
      "Train Epoch: 1038 [256/118836 (0%)] Loss: 12213.534180\n",
      "Train Epoch: 1038 [33024/118836 (28%)] Loss: 12258.576172\n",
      "Train Epoch: 1038 [65792/118836 (55%)] Loss: 12318.035156\n",
      "Train Epoch: 1038 [98560/118836 (83%)] Loss: 12359.350586\n",
      "    epoch          : 1038\n",
      "    loss           : 12263.79970226556\n",
      "    val_loss       : 12261.416417042292\n",
      "    val_log_likelihood: -12174.628668611715\n",
      "    val_log_marginal: -12182.618762937445\n",
      "Train Epoch: 1039 [256/118836 (0%)] Loss: 12345.056641\n",
      "Train Epoch: 1039 [33024/118836 (28%)] Loss: 12332.020508\n",
      "Train Epoch: 1039 [65792/118836 (55%)] Loss: 12264.856445\n",
      "Train Epoch: 1039 [98560/118836 (83%)] Loss: 12219.591797\n",
      "    epoch          : 1039\n",
      "    loss           : 12263.67841449545\n",
      "    val_loss       : 12265.071047114856\n",
      "    val_log_likelihood: -12176.968280216088\n",
      "    val_log_marginal: -12184.928887037528\n",
      "Train Epoch: 1040 [256/118836 (0%)] Loss: 12260.459961\n",
      "Train Epoch: 1040 [33024/118836 (28%)] Loss: 12123.199219\n",
      "Train Epoch: 1040 [65792/118836 (55%)] Loss: 12242.267578\n",
      "Train Epoch: 1040 [98560/118836 (83%)] Loss: 12243.822266\n",
      "    epoch          : 1040\n",
      "    loss           : 12262.882476640045\n",
      "    val_loss       : 12262.917654652572\n",
      "    val_log_likelihood: -12175.259125407103\n",
      "    val_log_marginal: -12183.49306585438\n",
      "Train Epoch: 1041 [256/118836 (0%)] Loss: 12391.224609\n",
      "Train Epoch: 1041 [33024/118836 (28%)] Loss: 12278.175781\n",
      "Train Epoch: 1041 [65792/118836 (55%)] Loss: 12190.445312\n",
      "Train Epoch: 1041 [98560/118836 (83%)] Loss: 12189.311523\n",
      "    epoch          : 1041\n",
      "    loss           : 12262.755414146506\n",
      "    val_loss       : 12262.578069017498\n",
      "    val_log_likelihood: -12175.897518287326\n",
      "    val_log_marginal: -12183.882716963244\n",
      "Train Epoch: 1042 [256/118836 (0%)] Loss: 12461.123047\n",
      "Train Epoch: 1042 [33024/118836 (28%)] Loss: 12366.824219\n",
      "Train Epoch: 1042 [65792/118836 (55%)] Loss: 12360.355469\n",
      "Train Epoch: 1042 [98560/118836 (83%)] Loss: 12192.845703\n",
      "    epoch          : 1042\n",
      "    loss           : 12262.148987250568\n",
      "    val_loss       : 12263.158129381833\n",
      "    val_log_likelihood: -12176.208234788566\n",
      "    val_log_marginal: -12184.161022299333\n",
      "Train Epoch: 1043 [256/118836 (0%)] Loss: 12300.831055\n",
      "Train Epoch: 1043 [33024/118836 (28%)] Loss: 12292.732422\n",
      "Train Epoch: 1043 [65792/118836 (55%)] Loss: 12362.957031\n",
      "Train Epoch: 1043 [98560/118836 (83%)] Loss: 12205.417969\n",
      "    epoch          : 1043\n",
      "    loss           : 12258.975733108458\n",
      "    val_loss       : 12263.302598685113\n",
      "    val_log_likelihood: -12176.886291614972\n",
      "    val_log_marginal: -12184.812539941557\n",
      "Train Epoch: 1044 [256/118836 (0%)] Loss: 12324.581055\n",
      "Train Epoch: 1044 [33024/118836 (28%)] Loss: 12347.414062\n",
      "Train Epoch: 1044 [65792/118836 (55%)] Loss: 12270.448242\n",
      "Train Epoch: 1044 [98560/118836 (83%)] Loss: 12228.390625\n",
      "    epoch          : 1044\n",
      "    loss           : 12265.440430818342\n",
      "    val_loss       : 12263.632661192381\n",
      "    val_log_likelihood: -12176.95202194479\n",
      "    val_log_marginal: -12185.135788058815\n",
      "Train Epoch: 1045 [256/118836 (0%)] Loss: 12240.250977\n",
      "Train Epoch: 1045 [33024/118836 (28%)] Loss: 12290.449219\n",
      "Train Epoch: 1045 [65792/118836 (55%)] Loss: 12356.408203\n",
      "Train Epoch: 1045 [98560/118836 (83%)] Loss: 12310.351562\n",
      "    epoch          : 1045\n",
      "    loss           : 12266.024075294665\n",
      "    val_loss       : 12259.755509550434\n",
      "    val_log_likelihood: -12179.185985964641\n",
      "    val_log_marginal: -12187.642751865107\n",
      "Train Epoch: 1046 [256/118836 (0%)] Loss: 12230.913086\n",
      "Train Epoch: 1046 [33024/118836 (28%)] Loss: 12291.845703\n",
      "Train Epoch: 1046 [65792/118836 (55%)] Loss: 12311.559570\n",
      "Train Epoch: 1046 [98560/118836 (83%)] Loss: 12320.413086\n",
      "    epoch          : 1046\n",
      "    loss           : 12269.802582196031\n",
      "    val_loss       : 12265.451076871204\n",
      "    val_log_likelihood: -12176.571130421578\n",
      "    val_log_marginal: -12185.01113419565\n",
      "Train Epoch: 1047 [256/118836 (0%)] Loss: 12248.437500\n",
      "Train Epoch: 1047 [33024/118836 (28%)] Loss: 12258.275391\n",
      "Train Epoch: 1047 [65792/118836 (55%)] Loss: 12285.442383\n",
      "Train Epoch: 1047 [98560/118836 (83%)] Loss: 12297.757812\n",
      "    epoch          : 1047\n",
      "    loss           : 12257.694329960193\n",
      "    val_loss       : 12252.914765630623\n",
      "    val_log_likelihood: -12175.908136243796\n",
      "    val_log_marginal: -12184.353949944474\n",
      "Train Epoch: 1048 [256/118836 (0%)] Loss: 12328.105469\n",
      "Train Epoch: 1048 [33024/118836 (28%)] Loss: 12228.414062\n",
      "Train Epoch: 1048 [65792/118836 (55%)] Loss: 12292.791992\n",
      "Train Epoch: 1048 [98560/118836 (83%)] Loss: 12239.900391\n",
      "    epoch          : 1048\n",
      "    loss           : 12255.248614719034\n",
      "    val_loss       : 12249.631059693\n",
      "    val_log_likelihood: -12172.973536852513\n",
      "    val_log_marginal: -12181.272599606482\n",
      "Train Epoch: 1049 [256/118836 (0%)] Loss: 12196.073242\n",
      "Train Epoch: 1049 [33024/118836 (28%)] Loss: 12246.439453\n",
      "Train Epoch: 1049 [65792/118836 (55%)] Loss: 12228.954102\n",
      "Train Epoch: 1049 [98560/118836 (83%)] Loss: 12331.088867\n",
      "    epoch          : 1049\n",
      "    loss           : 12248.217798800662\n",
      "    val_loss       : 12251.017921367906\n",
      "    val_log_likelihood: -12172.05837549757\n",
      "    val_log_marginal: -12180.16558358407\n",
      "Train Epoch: 1050 [256/118836 (0%)] Loss: 12296.789062\n",
      "Train Epoch: 1050 [33024/118836 (28%)] Loss: 12263.126953\n",
      "Train Epoch: 1050 [65792/118836 (55%)] Loss: 12230.375000\n",
      "Train Epoch: 1050 [98560/118836 (83%)] Loss: 12279.864258\n",
      "    epoch          : 1050\n",
      "    loss           : 12252.3785828293\n",
      "    val_loss       : 12248.431146592433\n",
      "    val_log_likelihood: -12173.537208242866\n",
      "    val_log_marginal: -12181.892676641466\n",
      "Train Epoch: 1051 [256/118836 (0%)] Loss: 12299.490234\n",
      "Train Epoch: 1051 [33024/118836 (28%)] Loss: 12273.309570\n",
      "Train Epoch: 1051 [65792/118836 (55%)] Loss: 12199.650391\n",
      "Train Epoch: 1051 [98560/118836 (83%)] Loss: 12231.320312\n",
      "    epoch          : 1051\n",
      "    loss           : 12246.632515734853\n",
      "    val_loss       : 12250.951151990661\n",
      "    val_log_likelihood: -12174.094895542545\n",
      "    val_log_marginal: -12182.316440957558\n",
      "Train Epoch: 1052 [256/118836 (0%)] Loss: 12200.855469\n",
      "Train Epoch: 1052 [33024/118836 (28%)] Loss: 12219.721680\n",
      "Train Epoch: 1052 [65792/118836 (55%)] Loss: 12423.978516\n",
      "Train Epoch: 1052 [98560/118836 (83%)] Loss: 12286.133789\n",
      "    epoch          : 1052\n",
      "    loss           : 12250.457064044407\n",
      "    val_loss       : 12250.959902881594\n",
      "    val_log_likelihood: -12172.114084632187\n",
      "    val_log_marginal: -12180.507166998495\n",
      "Train Epoch: 1053 [256/118836 (0%)] Loss: 12253.269531\n",
      "Train Epoch: 1053 [33024/118836 (28%)] Loss: 12281.554688\n",
      "Train Epoch: 1053 [65792/118836 (55%)] Loss: 12341.951172\n",
      "Train Epoch: 1053 [98560/118836 (83%)] Loss: 12301.328125\n",
      "    epoch          : 1053\n",
      "    loss           : 12250.047457868073\n",
      "    val_loss       : 12252.548471475331\n",
      "    val_log_likelihood: -12171.53420391982\n",
      "    val_log_marginal: -12180.001066210238\n",
      "Train Epoch: 1054 [256/118836 (0%)] Loss: 12328.684570\n",
      "Train Epoch: 1054 [33024/118836 (28%)] Loss: 12297.835938\n",
      "Train Epoch: 1054 [65792/118836 (55%)] Loss: 12377.410156\n",
      "Train Epoch: 1054 [98560/118836 (83%)] Loss: 12242.335938\n",
      "    epoch          : 1054\n",
      "    loss           : 12247.958903923696\n",
      "    val_loss       : 12251.66108517232\n",
      "    val_log_likelihood: -12171.72791062474\n",
      "    val_log_marginal: -12180.05630022083\n",
      "Train Epoch: 1055 [256/118836 (0%)] Loss: 12182.401367\n",
      "Train Epoch: 1055 [33024/118836 (28%)] Loss: 12249.271484\n",
      "Train Epoch: 1055 [65792/118836 (55%)] Loss: 12201.390625\n",
      "Train Epoch: 1055 [98560/118836 (83%)] Loss: 12243.260742\n",
      "    epoch          : 1055\n",
      "    loss           : 12251.196339788823\n",
      "    val_loss       : 12253.077594806678\n",
      "    val_log_likelihood: -12172.973245741574\n",
      "    val_log_marginal: -12181.274500915539\n",
      "Train Epoch: 1056 [256/118836 (0%)] Loss: 12415.949219\n",
      "Train Epoch: 1056 [33024/118836 (28%)] Loss: 12248.519531\n",
      "Train Epoch: 1056 [65792/118836 (55%)] Loss: 12286.812500\n",
      "Train Epoch: 1056 [98560/118836 (83%)] Loss: 12279.651367\n",
      "    epoch          : 1056\n",
      "    loss           : 12249.117104302366\n",
      "    val_loss       : 12250.88082992402\n",
      "    val_log_likelihood: -12174.412213573978\n",
      "    val_log_marginal: -12182.886592516596\n",
      "Train Epoch: 1057 [256/118836 (0%)] Loss: 12359.716797\n",
      "Train Epoch: 1057 [33024/118836 (28%)] Loss: 12288.222656\n",
      "Train Epoch: 1057 [65792/118836 (55%)] Loss: 12346.492188\n",
      "Train Epoch: 1057 [98560/118836 (83%)] Loss: 12347.384766\n",
      "    epoch          : 1057\n",
      "    loss           : 12251.13846170001\n",
      "    val_loss       : 12245.089501022327\n",
      "    val_log_likelihood: -12172.294826561209\n",
      "    val_log_marginal: -12180.534394384038\n",
      "Train Epoch: 1058 [256/118836 (0%)] Loss: 12279.401367\n",
      "Train Epoch: 1058 [33024/118836 (28%)] Loss: 12210.571289\n",
      "Train Epoch: 1058 [65792/118836 (55%)] Loss: 12316.821289\n",
      "Train Epoch: 1058 [98560/118836 (83%)] Loss: 12317.990234\n",
      "    epoch          : 1058\n",
      "    loss           : 12250.76000940214\n",
      "    val_loss       : 12281.76160950585\n",
      "    val_log_likelihood: -12174.705986837003\n",
      "    val_log_marginal: -12182.997655115187\n",
      "Train Epoch: 1059 [256/118836 (0%)] Loss: 12299.065430\n",
      "Train Epoch: 1059 [33024/118836 (28%)] Loss: 12291.029297\n",
      "Train Epoch: 1059 [65792/118836 (55%)] Loss: 12284.402344\n",
      "Train Epoch: 1059 [98560/118836 (83%)] Loss: 12228.715820\n",
      "    epoch          : 1059\n",
      "    loss           : 12256.645560315861\n",
      "    val_loss       : 12249.914952864443\n",
      "    val_log_likelihood: -12175.304331446443\n",
      "    val_log_marginal: -12183.458767951579\n",
      "Train Epoch: 1060 [256/118836 (0%)] Loss: 12193.977539\n",
      "Train Epoch: 1060 [33024/118836 (28%)] Loss: 12291.390625\n",
      "Train Epoch: 1060 [65792/118836 (55%)] Loss: 12291.115234\n",
      "Train Epoch: 1060 [98560/118836 (83%)] Loss: 12226.141602\n",
      "    epoch          : 1060\n",
      "    loss           : 12253.429502526622\n",
      "    val_loss       : 12255.309205402677\n",
      "    val_log_likelihood: -12172.48010219577\n",
      "    val_log_marginal: -12180.926958635491\n",
      "Train Epoch: 1061 [256/118836 (0%)] Loss: 12270.882812\n",
      "Train Epoch: 1061 [33024/118836 (28%)] Loss: 12271.313477\n",
      "Train Epoch: 1061 [65792/118836 (55%)] Loss: 12357.194336\n",
      "Train Epoch: 1061 [98560/118836 (83%)] Loss: 12231.645508\n",
      "    epoch          : 1061\n",
      "    loss           : 12248.757925584161\n",
      "    val_loss       : 12250.520305167207\n",
      "    val_log_likelihood: -12173.207111216658\n",
      "    val_log_marginal: -12181.450292057494\n",
      "Train Epoch: 1062 [256/118836 (0%)] Loss: 12294.253906\n",
      "Train Epoch: 1062 [33024/118836 (28%)] Loss: 12215.425781\n",
      "Train Epoch: 1062 [65792/118836 (55%)] Loss: 12280.325195\n",
      "Train Epoch: 1062 [98560/118836 (83%)] Loss: 12299.474609\n",
      "    epoch          : 1062\n",
      "    loss           : 12256.148538306452\n",
      "    val_loss       : 12246.326288528688\n",
      "    val_log_likelihood: -12174.279041950993\n",
      "    val_log_marginal: -12182.680700098563\n",
      "Train Epoch: 1063 [256/118836 (0%)] Loss: 12301.812500\n",
      "Train Epoch: 1063 [33024/118836 (28%)] Loss: 12354.992188\n",
      "Train Epoch: 1063 [65792/118836 (55%)] Loss: 12244.041016\n",
      "Train Epoch: 1063 [98560/118836 (83%)] Loss: 12279.507812\n",
      "    epoch          : 1063\n",
      "    loss           : 12247.536915193343\n",
      "    val_loss       : 12249.07839548855\n",
      "    val_log_likelihood: -12172.56972252378\n",
      "    val_log_marginal: -12180.851127506632\n",
      "Train Epoch: 1064 [256/118836 (0%)] Loss: 12284.060547\n",
      "Train Epoch: 1064 [33024/118836 (28%)] Loss: 12288.884766\n",
      "Train Epoch: 1064 [65792/118836 (55%)] Loss: 12237.247070\n",
      "Train Epoch: 1064 [98560/118836 (83%)] Loss: 12279.069336\n",
      "    epoch          : 1064\n",
      "    loss           : 12247.929293644023\n",
      "    val_loss       : 12249.881953342909\n",
      "    val_log_likelihood: -12177.380100095637\n",
      "    val_log_marginal: -12185.454497996405\n",
      "Train Epoch: 1065 [256/118836 (0%)] Loss: 12233.185547\n",
      "Train Epoch: 1065 [33024/118836 (28%)] Loss: 12206.198242\n",
      "Train Epoch: 1065 [65792/118836 (55%)] Loss: 12296.580078\n",
      "Train Epoch: 1065 [98560/118836 (83%)] Loss: 12288.010742\n",
      "    epoch          : 1065\n",
      "    loss           : 12244.74606127869\n",
      "    val_loss       : 12244.904341890035\n",
      "    val_log_likelihood: -12172.770267104786\n",
      "    val_log_marginal: -12180.781763945542\n",
      "Train Epoch: 1066 [256/118836 (0%)] Loss: 12282.283203\n",
      "Train Epoch: 1066 [33024/118836 (28%)] Loss: 12272.737305\n",
      "Train Epoch: 1066 [65792/118836 (55%)] Loss: 12209.310547\n",
      "Train Epoch: 1066 [98560/118836 (83%)] Loss: 12218.152344\n",
      "    epoch          : 1066\n",
      "    loss           : 12243.888157180521\n",
      "    val_loss       : 12250.134982071362\n",
      "    val_log_likelihood: -12171.28643862438\n",
      "    val_log_marginal: -12179.336151138705\n",
      "Train Epoch: 1067 [256/118836 (0%)] Loss: 12198.734375\n",
      "Train Epoch: 1067 [33024/118836 (28%)] Loss: 12280.183594\n",
      "Train Epoch: 1067 [65792/118836 (55%)] Loss: 12275.630859\n",
      "Train Epoch: 1067 [98560/118836 (83%)] Loss: 12222.633789\n",
      "    epoch          : 1067\n",
      "    loss           : 12245.798337178194\n",
      "    val_loss       : 12250.554305074522\n",
      "    val_log_likelihood: -12174.261171099566\n",
      "    val_log_marginal: -12182.255046385088\n",
      "Train Epoch: 1068 [256/118836 (0%)] Loss: 12327.636719\n",
      "Train Epoch: 1068 [33024/118836 (28%)] Loss: 12186.601562\n",
      "Train Epoch: 1068 [65792/118836 (55%)] Loss: 12298.987305\n",
      "Train Epoch: 1068 [98560/118836 (83%)] Loss: 12246.123047\n",
      "    epoch          : 1068\n",
      "    loss           : 12248.583576787376\n",
      "    val_loss       : 12249.172028808212\n",
      "    val_log_likelihood: -12173.291139048284\n",
      "    val_log_marginal: -12181.403321554355\n",
      "Train Epoch: 1069 [256/118836 (0%)] Loss: 12204.542969\n",
      "Train Epoch: 1069 [33024/118836 (28%)] Loss: 12300.184570\n",
      "Train Epoch: 1069 [65792/118836 (55%)] Loss: 12327.754883\n",
      "Train Epoch: 1069 [98560/118836 (83%)] Loss: 12235.576172\n",
      "    epoch          : 1069\n",
      "    loss           : 12251.903934197942\n",
      "    val_loss       : 12248.970733449874\n",
      "    val_log_likelihood: -12171.478119991989\n",
      "    val_log_marginal: -12179.519782747344\n",
      "Train Epoch: 1070 [256/118836 (0%)] Loss: 12306.187500\n",
      "Train Epoch: 1070 [33024/118836 (28%)] Loss: 12317.634766\n",
      "Train Epoch: 1070 [65792/118836 (55%)] Loss: 12160.016602\n",
      "Train Epoch: 1070 [98560/118836 (83%)] Loss: 12198.913086\n",
      "    epoch          : 1070\n",
      "    loss           : 12246.000481576975\n",
      "    val_loss       : 12249.70012341335\n",
      "    val_log_likelihood: -12171.348100347654\n",
      "    val_log_marginal: -12179.486300002074\n",
      "Train Epoch: 1071 [256/118836 (0%)] Loss: 12211.645508\n",
      "Train Epoch: 1071 [33024/118836 (28%)] Loss: 12309.314453\n",
      "Train Epoch: 1071 [65792/118836 (55%)] Loss: 12252.390625\n",
      "Train Epoch: 1071 [98560/118836 (83%)] Loss: 12232.432617\n",
      "    epoch          : 1071\n",
      "    loss           : 12251.070880667132\n",
      "    val_loss       : 12250.093210701767\n",
      "    val_log_likelihood: -12175.213850547974\n",
      "    val_log_marginal: -12183.503085876282\n",
      "Train Epoch: 1072 [256/118836 (0%)] Loss: 12279.316406\n",
      "Train Epoch: 1072 [33024/118836 (28%)] Loss: 12171.443359\n",
      "Train Epoch: 1072 [65792/118836 (55%)] Loss: 12206.550781\n",
      "Train Epoch: 1072 [98560/118836 (83%)] Loss: 12235.736328\n",
      "    epoch          : 1072\n",
      "    loss           : 12250.608690517733\n",
      "    val_loss       : 12247.385759102073\n",
      "    val_log_likelihood: -12176.447917797508\n",
      "    val_log_marginal: -12184.495450808767\n",
      "Train Epoch: 1073 [256/118836 (0%)] Loss: 12352.372070\n",
      "Train Epoch: 1073 [33024/118836 (28%)] Loss: 12343.047852\n",
      "Train Epoch: 1073 [65792/118836 (55%)] Loss: 12225.141602\n",
      "Train Epoch: 1073 [98560/118836 (83%)] Loss: 12296.309570\n",
      "    epoch          : 1073\n",
      "    loss           : 12250.842289275744\n",
      "    val_loss       : 12253.573618929067\n",
      "    val_log_likelihood: -12176.382342554538\n",
      "    val_log_marginal: -12184.889483825253\n",
      "Train Epoch: 1074 [256/118836 (0%)] Loss: 12300.264648\n",
      "Train Epoch: 1074 [33024/118836 (28%)] Loss: 12342.854492\n",
      "Train Epoch: 1074 [65792/118836 (55%)] Loss: 12298.447266\n",
      "Train Epoch: 1074 [98560/118836 (83%)] Loss: 12288.937500\n",
      "    epoch          : 1074\n",
      "    loss           : 12247.2148705671\n",
      "    val_loss       : 12247.887512972131\n",
      "    val_log_likelihood: -12172.824394515095\n",
      "    val_log_marginal: -12180.945109808466\n",
      "Train Epoch: 1075 [256/118836 (0%)] Loss: 12214.955078\n",
      "Train Epoch: 1075 [33024/118836 (28%)] Loss: 12290.695312\n",
      "Train Epoch: 1075 [65792/118836 (55%)] Loss: 12202.869141\n",
      "Train Epoch: 1075 [98560/118836 (83%)] Loss: 12260.299805\n",
      "    epoch          : 1075\n",
      "    loss           : 12251.853765540995\n",
      "    val_loss       : 12250.068237820227\n",
      "    val_log_likelihood: -12172.77681047741\n",
      "    val_log_marginal: -12180.871961372819\n",
      "Train Epoch: 1076 [256/118836 (0%)] Loss: 12191.947266\n",
      "Train Epoch: 1076 [33024/118836 (28%)] Loss: 12339.584961\n",
      "Train Epoch: 1076 [65792/118836 (55%)] Loss: 12172.485352\n",
      "Train Epoch: 1076 [98560/118836 (83%)] Loss: 12344.821289\n",
      "    epoch          : 1076\n",
      "    loss           : 12247.541562790788\n",
      "    val_loss       : 12247.314784764225\n",
      "    val_log_likelihood: -12172.557265657311\n",
      "    val_log_marginal: -12180.590810535912\n",
      "Train Epoch: 1077 [256/118836 (0%)] Loss: 12214.166016\n",
      "Train Epoch: 1077 [33024/118836 (28%)] Loss: 12309.097656\n",
      "Train Epoch: 1077 [65792/118836 (55%)] Loss: 12349.078125\n",
      "Train Epoch: 1077 [98560/118836 (83%)] Loss: 12294.720703\n",
      "    epoch          : 1077\n",
      "    loss           : 12253.338372686621\n",
      "    val_loss       : 12247.90698917627\n",
      "    val_log_likelihood: -12174.049336680624\n",
      "    val_log_marginal: -12182.2060298614\n",
      "Train Epoch: 1078 [256/118836 (0%)] Loss: 12324.264648\n",
      "Train Epoch: 1078 [33024/118836 (28%)] Loss: 12322.455078\n",
      "Train Epoch: 1078 [65792/118836 (55%)] Loss: 12350.945312\n",
      "Train Epoch: 1078 [98560/118836 (83%)] Loss: 12244.442383\n",
      "    epoch          : 1078\n",
      "    loss           : 12250.095495211694\n",
      "    val_loss       : 12250.818668298914\n",
      "    val_log_likelihood: -12173.748584024763\n",
      "    val_log_marginal: -12181.868298094736\n",
      "Train Epoch: 1079 [256/118836 (0%)] Loss: 12214.455078\n",
      "Train Epoch: 1079 [33024/118836 (28%)] Loss: 12386.274414\n",
      "Train Epoch: 1079 [65792/118836 (55%)] Loss: 12298.125000\n",
      "Train Epoch: 1079 [98560/118836 (83%)] Loss: 12353.076172\n",
      "    epoch          : 1079\n",
      "    loss           : 12248.221212488368\n",
      "    val_loss       : 12250.737364200182\n",
      "    val_log_likelihood: -12172.323448485318\n",
      "    val_log_marginal: -12180.520445615146\n",
      "Train Epoch: 1080 [256/118836 (0%)] Loss: 12279.747070\n",
      "Train Epoch: 1080 [33024/118836 (28%)] Loss: 12328.418945\n",
      "Train Epoch: 1080 [65792/118836 (55%)] Loss: 12207.515625\n",
      "Train Epoch: 1080 [98560/118836 (83%)] Loss: 12299.066406\n",
      "    epoch          : 1080\n",
      "    loss           : 12249.389934378876\n",
      "    val_loss       : 12248.439654134756\n",
      "    val_log_likelihood: -12172.056388124225\n",
      "    val_log_marginal: -12180.290059782747\n",
      "Train Epoch: 1081 [256/118836 (0%)] Loss: 12308.313477\n",
      "Train Epoch: 1081 [33024/118836 (28%)] Loss: 12209.902344\n",
      "Train Epoch: 1081 [65792/118836 (55%)] Loss: 12240.974609\n",
      "Train Epoch: 1081 [98560/118836 (83%)] Loss: 12252.383789\n",
      "    epoch          : 1081\n",
      "    loss           : 12247.636460271919\n",
      "    val_loss       : 12249.69775579801\n",
      "    val_log_likelihood: -12170.22440469267\n",
      "    val_log_marginal: -12178.323970053629\n",
      "Train Epoch: 1082 [256/118836 (0%)] Loss: 12348.291016\n",
      "Train Epoch: 1082 [33024/118836 (28%)] Loss: 12238.337891\n",
      "Train Epoch: 1082 [65792/118836 (55%)] Loss: 12220.808594\n",
      "Train Epoch: 1082 [98560/118836 (83%)] Loss: 12336.663086\n",
      "    epoch          : 1082\n",
      "    loss           : 12252.320692785877\n",
      "    val_loss       : 12248.150019713677\n",
      "    val_log_likelihood: -12172.850571559657\n",
      "    val_log_marginal: -12181.092204069166\n",
      "Train Epoch: 1083 [256/118836 (0%)] Loss: 12282.933594\n",
      "Train Epoch: 1083 [33024/118836 (28%)] Loss: 12293.957031\n",
      "Train Epoch: 1083 [65792/118836 (55%)] Loss: 12319.785156\n",
      "Train Epoch: 1083 [98560/118836 (83%)] Loss: 12231.521484\n",
      "    epoch          : 1083\n",
      "    loss           : 12249.244909112644\n",
      "    val_loss       : 12246.221945300771\n",
      "    val_log_likelihood: -12170.515151662015\n",
      "    val_log_marginal: -12178.8291830952\n",
      "Train Epoch: 1084 [256/118836 (0%)] Loss: 12308.975586\n",
      "Train Epoch: 1084 [33024/118836 (28%)] Loss: 12230.130859\n",
      "Train Epoch: 1084 [65792/118836 (55%)] Loss: 12317.511719\n",
      "Train Epoch: 1084 [98560/118836 (83%)] Loss: 12284.390625\n",
      "    epoch          : 1084\n",
      "    loss           : 12249.206853869417\n",
      "    val_loss       : 12250.366746109989\n",
      "    val_log_likelihood: -12172.510628457145\n",
      "    val_log_marginal: -12180.618384617152\n",
      "Train Epoch: 1085 [256/118836 (0%)] Loss: 12279.892578\n",
      "Train Epoch: 1085 [33024/118836 (28%)] Loss: 12293.172852\n",
      "Train Epoch: 1085 [65792/118836 (55%)] Loss: 12276.093750\n",
      "Train Epoch: 1085 [98560/118836 (83%)] Loss: 12314.994141\n",
      "    epoch          : 1085\n",
      "    loss           : 12245.503800435536\n",
      "    val_loss       : 12244.561013645056\n",
      "    val_log_likelihood: -12170.801833740436\n",
      "    val_log_marginal: -12179.018168994524\n",
      "Train Epoch: 1086 [256/118836 (0%)] Loss: 12278.255859\n",
      "Train Epoch: 1086 [33024/118836 (28%)] Loss: 12243.247070\n",
      "Train Epoch: 1086 [65792/118836 (55%)] Loss: 12289.268555\n",
      "Train Epoch: 1086 [98560/118836 (83%)] Loss: 12308.993164\n",
      "    epoch          : 1086\n",
      "    loss           : 12248.86170663384\n",
      "    val_loss       : 12246.825327816026\n",
      "    val_log_likelihood: -12172.733287776571\n",
      "    val_log_marginal: -12180.722119549371\n",
      "Train Epoch: 1087 [256/118836 (0%)] Loss: 12225.044922\n",
      "Train Epoch: 1087 [33024/118836 (28%)] Loss: 12227.801758\n",
      "Train Epoch: 1087 [65792/118836 (55%)] Loss: 12223.841797\n",
      "Train Epoch: 1087 [98560/118836 (83%)] Loss: 12323.078125\n",
      "    epoch          : 1087\n",
      "    loss           : 12246.799774962521\n",
      "    val_loss       : 12246.540426801825\n",
      "    val_log_likelihood: -12172.057146595844\n",
      "    val_log_marginal: -12180.078476054177\n",
      "Train Epoch: 1088 [256/118836 (0%)] Loss: 12248.658203\n",
      "Train Epoch: 1088 [33024/118836 (28%)] Loss: 12222.921875\n",
      "Train Epoch: 1088 [65792/118836 (55%)] Loss: 12223.158203\n",
      "Train Epoch: 1088 [98560/118836 (83%)] Loss: 12352.825195\n",
      "    epoch          : 1088\n",
      "    loss           : 12247.459582590209\n",
      "    val_loss       : 12250.015311834553\n",
      "    val_log_likelihood: -12172.312498384512\n",
      "    val_log_marginal: -12180.761261670163\n",
      "Train Epoch: 1089 [256/118836 (0%)] Loss: 12277.232422\n",
      "Train Epoch: 1089 [33024/118836 (28%)] Loss: 12216.562500\n",
      "Train Epoch: 1089 [65792/118836 (55%)] Loss: 12243.732422\n",
      "Train Epoch: 1089 [98560/118836 (83%)] Loss: 12282.518555\n",
      "    epoch          : 1089\n",
      "    loss           : 12245.740554726272\n",
      "    val_loss       : 12247.234810287462\n",
      "    val_log_likelihood: -12171.529098331524\n",
      "    val_log_marginal: -12179.545932805187\n",
      "Train Epoch: 1090 [256/118836 (0%)] Loss: 12260.775391\n",
      "Train Epoch: 1090 [33024/118836 (28%)] Loss: 12325.220703\n",
      "Train Epoch: 1090 [65792/118836 (55%)] Loss: 12258.186523\n",
      "Train Epoch: 1090 [98560/118836 (83%)] Loss: 12281.073242\n",
      "    epoch          : 1090\n",
      "    loss           : 12247.428943729323\n",
      "    val_loss       : 12252.594571612215\n",
      "    val_log_likelihood: -12173.491903012562\n",
      "    val_log_marginal: -12181.642337646252\n",
      "Train Epoch: 1091 [256/118836 (0%)] Loss: 12261.561523\n",
      "Train Epoch: 1091 [33024/118836 (28%)] Loss: 12275.861328\n",
      "Train Epoch: 1091 [65792/118836 (55%)] Loss: 12193.144531\n",
      "Train Epoch: 1091 [98560/118836 (83%)] Loss: 12399.063477\n",
      "    epoch          : 1091\n",
      "    loss           : 12248.093943373915\n",
      "    val_loss       : 12251.36394725388\n",
      "    val_log_likelihood: -12171.981867439516\n",
      "    val_log_marginal: -12180.219544924355\n",
      "Train Epoch: 1092 [256/118836 (0%)] Loss: 12316.615234\n",
      "Train Epoch: 1092 [33024/118836 (28%)] Loss: 12352.035156\n",
      "Train Epoch: 1092 [65792/118836 (55%)] Loss: 12276.930664\n",
      "Train Epoch: 1092 [98560/118836 (83%)] Loss: 12297.747070\n",
      "    epoch          : 1092\n",
      "    loss           : 12248.451647151573\n",
      "    val_loss       : 12251.606755874258\n",
      "    val_log_likelihood: -12171.98396822012\n",
      "    val_log_marginal: -12180.380369940107\n",
      "Train Epoch: 1093 [256/118836 (0%)] Loss: 12258.697266\n",
      "Train Epoch: 1093 [33024/118836 (28%)] Loss: 12271.113281\n",
      "Train Epoch: 1093 [65792/118836 (55%)] Loss: 12386.628906\n",
      "Train Epoch: 1093 [98560/118836 (83%)] Loss: 12388.955078\n",
      "    epoch          : 1093\n",
      "    loss           : 12245.782501841657\n",
      "    val_loss       : 12250.618013732894\n",
      "    val_log_likelihood: -12172.010725386424\n",
      "    val_log_marginal: -12180.183589307628\n",
      "Train Epoch: 1094 [256/118836 (0%)] Loss: 12262.671875\n",
      "Train Epoch: 1094 [33024/118836 (28%)] Loss: 12319.226562\n",
      "Train Epoch: 1094 [65792/118836 (55%)] Loss: 12204.219727\n",
      "Train Epoch: 1094 [98560/118836 (83%)] Loss: 12281.365234\n",
      "    epoch          : 1094\n",
      "    loss           : 12248.161262536187\n",
      "    val_loss       : 12250.837137708515\n",
      "    val_log_likelihood: -12170.96327850367\n",
      "    val_log_marginal: -12179.387630344962\n",
      "Train Epoch: 1095 [256/118836 (0%)] Loss: 12289.264648\n",
      "Train Epoch: 1095 [33024/118836 (28%)] Loss: 12299.224609\n",
      "Train Epoch: 1095 [65792/118836 (55%)] Loss: 12190.571289\n",
      "Train Epoch: 1095 [98560/118836 (83%)] Loss: 12206.432617\n",
      "    epoch          : 1095\n",
      "    loss           : 12248.40186960427\n",
      "    val_loss       : 12246.945032327409\n",
      "    val_log_likelihood: -12170.978854877481\n",
      "    val_log_marginal: -12179.003076700714\n",
      "Train Epoch: 1096 [256/118836 (0%)] Loss: 12197.874023\n",
      "Train Epoch: 1096 [33024/118836 (28%)] Loss: 12200.855469\n",
      "Train Epoch: 1096 [65792/118836 (55%)] Loss: 12340.703125\n",
      "Train Epoch: 1096 [98560/118836 (83%)] Loss: 12229.030273\n",
      "    epoch          : 1096\n",
      "    loss           : 12249.73726155397\n",
      "    val_loss       : 12246.980950228353\n",
      "    val_log_likelihood: -12172.495447393248\n",
      "    val_log_marginal: -12180.694311088411\n",
      "Train Epoch: 1097 [256/118836 (0%)] Loss: 12317.810547\n",
      "Train Epoch: 1097 [33024/118836 (28%)] Loss: 12331.269531\n",
      "Train Epoch: 1097 [65792/118836 (55%)] Loss: 12229.523438\n",
      "Train Epoch: 1097 [98560/118836 (83%)] Loss: 12280.829102\n",
      "    epoch          : 1097\n",
      "    loss           : 12245.598656075528\n",
      "    val_loss       : 12247.524262378503\n",
      "    val_log_likelihood: -12171.530053246484\n",
      "    val_log_marginal: -12179.6075297456\n",
      "Train Epoch: 1098 [256/118836 (0%)] Loss: 12224.580078\n",
      "Train Epoch: 1098 [33024/118836 (28%)] Loss: 12250.615234\n",
      "Train Epoch: 1098 [65792/118836 (55%)] Loss: 12222.138672\n",
      "Train Epoch: 1098 [98560/118836 (83%)] Loss: 12264.397461\n",
      "    epoch          : 1098\n",
      "    loss           : 12243.995707809914\n",
      "    val_loss       : 12249.766019355011\n",
      "    val_log_likelihood: -12170.97133478081\n",
      "    val_log_marginal: -12179.176798579441\n",
      "Train Epoch: 1099 [256/118836 (0%)] Loss: 12213.302734\n",
      "Train Epoch: 1099 [33024/118836 (28%)] Loss: 12229.379883\n",
      "Train Epoch: 1099 [65792/118836 (55%)] Loss: 12234.441406\n",
      "Train Epoch: 1099 [98560/118836 (83%)] Loss: 12316.926758\n",
      "    epoch          : 1099\n",
      "    loss           : 12249.328799143144\n",
      "    val_loss       : 12248.32798704089\n",
      "    val_log_likelihood: -12171.275679312706\n",
      "    val_log_marginal: -12179.408566393096\n",
      "Train Epoch: 1100 [256/118836 (0%)] Loss: 12253.789062\n",
      "Train Epoch: 1100 [33024/118836 (28%)] Loss: 12286.502930\n",
      "Train Epoch: 1100 [65792/118836 (55%)] Loss: 12234.337891\n",
      "Train Epoch: 1100 [98560/118836 (83%)] Loss: 12277.527344\n",
      "    epoch          : 1100\n",
      "    loss           : 12248.178953906896\n",
      "    val_loss       : 12249.280956192932\n",
      "    val_log_likelihood: -12170.593974229736\n",
      "    val_log_marginal: -12178.721368069817\n",
      "Saving checkpoint: saved/models/SelfiesAutoencodingOperad/0905_154251/checkpoint-epoch1100.pth ...\n",
      "Train Epoch: 1101 [256/118836 (0%)] Loss: 12214.909180\n",
      "Train Epoch: 1101 [33024/118836 (28%)] Loss: 12268.334961\n",
      "Train Epoch: 1101 [65792/118836 (55%)] Loss: 12283.359375\n",
      "Train Epoch: 1101 [98560/118836 (83%)] Loss: 12220.015625\n",
      "    epoch          : 1101\n",
      "    loss           : 12250.628729192515\n",
      "    val_loss       : 12249.33892149698\n",
      "    val_log_likelihood: -12170.470226717585\n",
      "    val_log_marginal: -12178.612718361197\n",
      "Train Epoch: 1102 [256/118836 (0%)] Loss: 12217.203125\n",
      "Train Epoch: 1102 [33024/118836 (28%)] Loss: 12404.088867\n",
      "Train Epoch: 1102 [65792/118836 (55%)] Loss: 12195.820312\n",
      "Train Epoch: 1102 [98560/118836 (83%)] Loss: 12308.708008\n",
      "    epoch          : 1102\n",
      "    loss           : 12251.566729832248\n",
      "    val_loss       : 12248.656858848264\n",
      "    val_log_likelihood: -12172.760748649453\n",
      "    val_log_marginal: -12181.135872848967\n",
      "Train Epoch: 1103 [256/118836 (0%)] Loss: 12264.229492\n",
      "Train Epoch: 1103 [33024/118836 (28%)] Loss: 12272.934570\n",
      "Train Epoch: 1103 [65792/118836 (55%)] Loss: 12398.921875\n",
      "Train Epoch: 1103 [98560/118836 (83%)] Loss: 12200.085938\n",
      "    epoch          : 1103\n",
      "    loss           : 12246.771504407052\n",
      "    val_loss       : 12249.264537857041\n",
      "    val_log_likelihood: -12173.131539010805\n",
      "    val_log_marginal: -12181.17318694207\n",
      "Train Epoch: 1104 [256/118836 (0%)] Loss: 12250.017578\n",
      "Train Epoch: 1104 [33024/118836 (28%)] Loss: 12326.051758\n",
      "Train Epoch: 1104 [65792/118836 (55%)] Loss: 12312.557617\n",
      "Train Epoch: 1104 [98560/118836 (83%)] Loss: 12290.566406\n",
      "    epoch          : 1104\n",
      "    loss           : 12250.37766313198\n",
      "    val_loss       : 12246.692572790564\n",
      "    val_log_likelihood: -12172.067211732321\n",
      "    val_log_marginal: -12180.066374502672\n",
      "Train Epoch: 1105 [256/118836 (0%)] Loss: 12400.007812\n",
      "Train Epoch: 1105 [33024/118836 (28%)] Loss: 12213.093750\n",
      "Train Epoch: 1105 [65792/118836 (55%)] Loss: 12245.912109\n",
      "Train Epoch: 1105 [98560/118836 (83%)] Loss: 12239.496094\n",
      "    epoch          : 1105\n",
      "    loss           : 12245.821887600807\n",
      "    val_loss       : 12250.917685572944\n",
      "    val_log_likelihood: -12171.937629723687\n",
      "    val_log_marginal: -12179.969277621818\n",
      "Train Epoch: 1106 [256/118836 (0%)] Loss: 12245.805664\n",
      "Train Epoch: 1106 [33024/118836 (28%)] Loss: 12344.593750\n",
      "Train Epoch: 1106 [65792/118836 (55%)] Loss: 12297.222656\n",
      "Train Epoch: 1106 [98560/118836 (83%)] Loss: 12301.665039\n",
      "    epoch          : 1106\n",
      "    loss           : 12249.913686899037\n",
      "    val_loss       : 12249.613194124215\n",
      "    val_log_likelihood: -12173.5945918308\n",
      "    val_log_marginal: -12181.612472843688\n",
      "Train Epoch: 1107 [256/118836 (0%)] Loss: 12297.450195\n",
      "Train Epoch: 1107 [33024/118836 (28%)] Loss: 12292.794922\n",
      "Train Epoch: 1107 [65792/118836 (55%)] Loss: 12287.705078\n",
      "Train Epoch: 1107 [98560/118836 (83%)] Loss: 12212.902344\n",
      "    epoch          : 1107\n",
      "    loss           : 12243.904888466708\n",
      "    val_loss       : 12245.273048466152\n",
      "    val_log_likelihood: -12169.360479186053\n",
      "    val_log_marginal: -12177.390684096372\n",
      "Train Epoch: 1108 [256/118836 (0%)] Loss: 12283.335938\n",
      "Train Epoch: 1108 [33024/118836 (28%)] Loss: 12308.140625\n",
      "Train Epoch: 1108 [65792/118836 (55%)] Loss: 12243.375000\n",
      "Train Epoch: 1108 [98560/118836 (83%)] Loss: 12228.666992\n",
      "    epoch          : 1108\n",
      "    loss           : 12246.9793438857\n",
      "    val_loss       : 12247.370633631754\n",
      "    val_log_likelihood: -12171.124920356442\n",
      "    val_log_marginal: -12179.32888296889\n",
      "Train Epoch: 1109 [256/118836 (0%)] Loss: 12353.624023\n",
      "Train Epoch: 1109 [33024/118836 (28%)] Loss: 12263.461914\n",
      "Train Epoch: 1109 [65792/118836 (55%)] Loss: 12394.995117\n",
      "Train Epoch: 1109 [98560/118836 (83%)] Loss: 12256.230469\n",
      "    epoch          : 1109\n",
      "    loss           : 12249.33223463994\n",
      "    val_loss       : 12249.028787729098\n",
      "    val_log_likelihood: -12171.56091197529\n",
      "    val_log_marginal: -12179.887757441717\n",
      "Train Epoch: 1110 [256/118836 (0%)] Loss: 12185.861328\n",
      "Train Epoch: 1110 [33024/118836 (28%)] Loss: 12284.068359\n",
      "Train Epoch: 1110 [65792/118836 (55%)] Loss: 12177.641602\n",
      "Train Epoch: 1110 [98560/118836 (83%)] Loss: 12240.777344\n",
      "    epoch          : 1110\n",
      "    loss           : 12249.397687590466\n",
      "    val_loss       : 12249.346780794234\n",
      "    val_log_likelihood: -12174.469540296734\n",
      "    val_log_marginal: -12182.72532060836\n",
      "Train Epoch: 1111 [256/118836 (0%)] Loss: 12228.855469\n",
      "Train Epoch: 1111 [33024/118836 (28%)] Loss: 12326.965820\n",
      "Train Epoch: 1111 [65792/118836 (55%)] Loss: 12266.313477\n",
      "Train Epoch: 1111 [98560/118836 (83%)] Loss: 12299.548828\n",
      "    epoch          : 1111\n",
      "    loss           : 12249.603495431398\n",
      "    val_loss       : 12253.351026349457\n",
      "    val_log_likelihood: -12180.960340577181\n",
      "    val_log_marginal: -12189.425177643117\n",
      "Train Epoch: 1112 [256/118836 (0%)] Loss: 12258.728516\n",
      "Train Epoch: 1112 [33024/118836 (28%)] Loss: 12254.853516\n",
      "Train Epoch: 1112 [65792/118836 (55%)] Loss: 12240.507812\n",
      "Train Epoch: 1112 [98560/118836 (83%)] Loss: 12398.150391\n",
      "    epoch          : 1112\n",
      "    loss           : 12251.341521434295\n",
      "    val_loss       : 12248.697676313666\n",
      "    val_log_likelihood: -12171.17738704508\n",
      "    val_log_marginal: -12179.45716850541\n",
      "Train Epoch: 1113 [256/118836 (0%)] Loss: 12194.113281\n",
      "Train Epoch: 1113 [33024/118836 (28%)] Loss: 12332.427734\n",
      "Train Epoch: 1113 [65792/118836 (55%)] Loss: 12254.798828\n",
      "Train Epoch: 1113 [98560/118836 (83%)] Loss: 12251.761719\n",
      "    epoch          : 1113\n",
      "    loss           : 12252.054099300816\n",
      "    val_loss       : 12248.029352430684\n",
      "    val_log_likelihood: -12170.352875407103\n",
      "    val_log_marginal: -12178.36114426771\n",
      "Train Epoch: 1114 [256/118836 (0%)] Loss: 12254.245117\n",
      "Train Epoch: 1114 [33024/118836 (28%)] Loss: 12294.599609\n",
      "Train Epoch: 1114 [65792/118836 (55%)] Loss: 12251.909180\n",
      "Train Epoch: 1114 [98560/118836 (83%)] Loss: 12248.137695\n",
      "    epoch          : 1114\n",
      "    loss           : 12248.383309585659\n",
      "    val_loss       : 12248.46297550644\n",
      "    val_log_likelihood: -12170.196479528535\n",
      "    val_log_marginal: -12178.385308758312\n",
      "Train Epoch: 1115 [256/118836 (0%)] Loss: 12258.832031\n",
      "Train Epoch: 1115 [33024/118836 (28%)] Loss: 12239.790039\n",
      "Train Epoch: 1115 [65792/118836 (55%)] Loss: 12174.806641\n",
      "Train Epoch: 1115 [98560/118836 (83%)] Loss: 12188.989258\n",
      "    epoch          : 1115\n",
      "    loss           : 12250.301280758893\n",
      "    val_loss       : 12249.90394228649\n",
      "    val_log_likelihood: -12171.79771424602\n",
      "    val_log_marginal: -12180.05985508134\n",
      "Train Epoch: 1116 [256/118836 (0%)] Loss: 12219.922852\n",
      "Train Epoch: 1116 [33024/118836 (28%)] Loss: 12292.337891\n",
      "Train Epoch: 1116 [65792/118836 (55%)] Loss: 12267.210938\n",
      "Train Epoch: 1116 [98560/118836 (83%)] Loss: 12212.765625\n",
      "    epoch          : 1116\n",
      "    loss           : 12247.147906489092\n",
      "    val_loss       : 12246.214971374833\n",
      "    val_log_likelihood: -12174.046870153536\n",
      "    val_log_marginal: -12181.978184204412\n",
      "Train Epoch: 1117 [256/118836 (0%)] Loss: 12267.128906\n",
      "Train Epoch: 1117 [33024/118836 (28%)] Loss: 12300.973633\n",
      "Train Epoch: 1117 [65792/118836 (55%)] Loss: 12291.169922\n",
      "Train Epoch: 1117 [98560/118836 (83%)] Loss: 12224.540039\n",
      "    epoch          : 1117\n",
      "    loss           : 12249.730019321236\n",
      "    val_loss       : 12247.283428402325\n",
      "    val_log_likelihood: -12171.166240339382\n",
      "    val_log_marginal: -12179.376014264517\n",
      "Train Epoch: 1118 [256/118836 (0%)] Loss: 12327.026367\n",
      "Train Epoch: 1118 [33024/118836 (28%)] Loss: 12256.628906\n",
      "Train Epoch: 1118 [65792/118836 (55%)] Loss: 12280.719727\n",
      "Train Epoch: 1118 [98560/118836 (83%)] Loss: 12246.849609\n",
      "    epoch          : 1118\n",
      "    loss           : 12247.987637801129\n",
      "    val_loss       : 12244.72122387332\n",
      "    val_log_likelihood: -12171.383441247932\n",
      "    val_log_marginal: -12179.398174167474\n",
      "Train Epoch: 1119 [256/118836 (0%)] Loss: 12204.757812\n",
      "Train Epoch: 1119 [33024/118836 (28%)] Loss: 12251.548828\n",
      "Train Epoch: 1119 [65792/118836 (55%)] Loss: 12253.109375\n",
      "Train Epoch: 1119 [98560/118836 (83%)] Loss: 12347.273438\n",
      "    epoch          : 1119\n",
      "    loss           : 12249.637434895832\n",
      "    val_loss       : 12248.661230977978\n",
      "    val_log_likelihood: -12172.499369959678\n",
      "    val_log_marginal: -12180.889497605769\n",
      "Train Epoch: 1120 [256/118836 (0%)] Loss: 12269.970703\n",
      "Train Epoch: 1120 [33024/118836 (28%)] Loss: 12316.227539\n",
      "Train Epoch: 1120 [65792/118836 (55%)] Loss: 12259.188477\n",
      "Train Epoch: 1120 [98560/118836 (83%)] Loss: 12307.134766\n",
      "    epoch          : 1120\n",
      "    loss           : 12245.947595669199\n",
      "    val_loss       : 12250.051464381802\n",
      "    val_log_likelihood: -12170.519072936053\n",
      "    val_log_marginal: -12178.509782721489\n",
      "Train Epoch: 1121 [256/118836 (0%)] Loss: 12301.845703\n",
      "Train Epoch: 1121 [33024/118836 (28%)] Loss: 12211.813477\n",
      "Train Epoch: 1121 [65792/118836 (55%)] Loss: 12326.695312\n",
      "Train Epoch: 1121 [98560/118836 (83%)] Loss: 12276.221680\n",
      "    epoch          : 1121\n",
      "    loss           : 12246.805081840623\n",
      "    val_loss       : 12253.168624882392\n",
      "    val_log_likelihood: -12172.362803550197\n",
      "    val_log_marginal: -12180.571151771059\n",
      "Train Epoch: 1122 [256/118836 (0%)] Loss: 12294.210938\n",
      "Train Epoch: 1122 [33024/118836 (28%)] Loss: 12213.904297\n",
      "Train Epoch: 1122 [65792/118836 (55%)] Loss: 12295.596680\n",
      "Train Epoch: 1122 [98560/118836 (83%)] Loss: 12268.067383\n",
      "    epoch          : 1122\n",
      "    loss           : 12244.884110867712\n",
      "    val_loss       : 12249.13516273226\n",
      "    val_log_likelihood: -12172.030471173231\n",
      "    val_log_marginal: -12180.220949821947\n",
      "Train Epoch: 1123 [256/118836 (0%)] Loss: 12246.824219\n",
      "Train Epoch: 1123 [33024/118836 (28%)] Loss: 12350.249023\n",
      "Train Epoch: 1123 [65792/118836 (55%)] Loss: 12245.419922\n",
      "Train Epoch: 1123 [98560/118836 (83%)] Loss: 12310.175781\n",
      "    epoch          : 1123\n",
      "    loss           : 12244.261757198616\n",
      "    val_loss       : 12247.979395777833\n",
      "    val_log_likelihood: -12171.443301055882\n",
      "    val_log_marginal: -12179.767606704021\n",
      "Train Epoch: 1124 [256/118836 (0%)] Loss: 12173.186523\n",
      "Train Epoch: 1124 [33024/118836 (28%)] Loss: 12272.710938\n",
      "Train Epoch: 1124 [65792/118836 (55%)] Loss: 12302.556641\n",
      "Train Epoch: 1124 [98560/118836 (83%)] Loss: 12207.386719\n",
      "    epoch          : 1124\n",
      "    loss           : 12247.21007127533\n",
      "    val_loss       : 12250.020363924541\n",
      "    val_log_likelihood: -12173.057737702904\n",
      "    val_log_marginal: -12181.144021255908\n",
      "Train Epoch: 1125 [256/118836 (0%)] Loss: 12241.116211\n",
      "Train Epoch: 1125 [33024/118836 (28%)] Loss: 12236.303711\n",
      "Train Epoch: 1125 [65792/118836 (55%)] Loss: 12239.843750\n",
      "Train Epoch: 1125 [98560/118836 (83%)] Loss: 12256.266602\n",
      "    epoch          : 1125\n",
      "    loss           : 12249.234439296424\n",
      "    val_loss       : 12248.526313779208\n",
      "    val_log_likelihood: -12170.5142240488\n",
      "    val_log_marginal: -12178.51269511431\n",
      "Train Epoch: 1126 [256/118836 (0%)] Loss: 12267.459961\n",
      "Train Epoch: 1126 [33024/118836 (28%)] Loss: 12258.822266\n",
      "Train Epoch: 1126 [65792/118836 (55%)] Loss: 12275.099609\n",
      "Train Epoch: 1126 [98560/118836 (83%)] Loss: 12379.728516\n",
      "    epoch          : 1126\n",
      "    loss           : 12250.680252597705\n",
      "    val_loss       : 12248.129225884175\n",
      "    val_log_likelihood: -12172.939146666926\n",
      "    val_log_marginal: -12180.9438692522\n",
      "Train Epoch: 1127 [256/118836 (0%)] Loss: 12325.459961\n",
      "Train Epoch: 1127 [33024/118836 (28%)] Loss: 12249.791016\n",
      "Train Epoch: 1127 [65792/118836 (55%)] Loss: 12286.978516\n",
      "Train Epoch: 1127 [98560/118836 (83%)] Loss: 12218.848633\n",
      "    epoch          : 1127\n",
      "    loss           : 12249.036893545803\n",
      "    val_loss       : 12249.630324106187\n",
      "    val_log_likelihood: -12172.018681826406\n",
      "    val_log_marginal: -12180.345621073106\n",
      "Train Epoch: 1128 [256/118836 (0%)] Loss: 12252.009766\n",
      "Train Epoch: 1128 [33024/118836 (28%)] Loss: 12201.450195\n",
      "Train Epoch: 1128 [65792/118836 (55%)] Loss: 12286.112305\n",
      "Train Epoch: 1128 [98560/118836 (83%)] Loss: 12359.023438\n",
      "    epoch          : 1128\n",
      "    loss           : 12245.40432498449\n",
      "    val_loss       : 12247.15465964509\n",
      "    val_log_likelihood: -12170.683476304022\n",
      "    val_log_marginal: -12179.025605990468\n",
      "Train Epoch: 1129 [256/118836 (0%)] Loss: 12254.494141\n",
      "Train Epoch: 1129 [33024/118836 (28%)] Loss: 12316.717773\n",
      "Train Epoch: 1129 [65792/118836 (55%)] Loss: 12339.051758\n",
      "Train Epoch: 1129 [98560/118836 (83%)] Loss: 12259.512695\n",
      "    epoch          : 1129\n",
      "    loss           : 12245.37655313017\n",
      "    val_loss       : 12250.611301057996\n",
      "    val_log_likelihood: -12173.084490668942\n",
      "    val_log_marginal: -12181.31714257182\n",
      "Train Epoch: 1130 [256/118836 (0%)] Loss: 12323.773438\n",
      "Train Epoch: 1130 [33024/118836 (28%)] Loss: 12232.167969\n",
      "Train Epoch: 1130 [65792/118836 (55%)] Loss: 12290.156250\n",
      "Train Epoch: 1130 [98560/118836 (83%)] Loss: 12279.074219\n",
      "    epoch          : 1130\n",
      "    loss           : 12248.235335730717\n",
      "    val_loss       : 12246.931252634497\n",
      "    val_log_likelihood: -12171.994612347498\n",
      "    val_log_marginal: -12180.079844908785\n",
      "Train Epoch: 1131 [256/118836 (0%)] Loss: 12255.008789\n",
      "Train Epoch: 1131 [33024/118836 (28%)] Loss: 12314.200195\n",
      "Train Epoch: 1131 [65792/118836 (55%)] Loss: 12222.818359\n",
      "Train Epoch: 1131 [98560/118836 (83%)] Loss: 12274.691406\n",
      "    epoch          : 1131\n",
      "    loss           : 12249.830111565601\n",
      "    val_loss       : 12247.68391568658\n",
      "    val_log_likelihood: -12171.380863413719\n",
      "    val_log_marginal: -12179.528919337654\n",
      "Train Epoch: 1132 [256/118836 (0%)] Loss: 12266.341797\n",
      "Train Epoch: 1132 [33024/118836 (28%)] Loss: 12282.432617\n",
      "Train Epoch: 1132 [65792/118836 (55%)] Loss: 12345.077148\n",
      "Train Epoch: 1132 [98560/118836 (83%)] Loss: 12260.755859\n",
      "    epoch          : 1132\n",
      "    loss           : 12245.96102764423\n",
      "    val_loss       : 12246.056278085036\n",
      "    val_log_likelihood: -12172.174975121485\n",
      "    val_log_marginal: -12180.451270753823\n",
      "Train Epoch: 1133 [256/118836 (0%)] Loss: 12284.155273\n",
      "Train Epoch: 1133 [33024/118836 (28%)] Loss: 12198.155273\n",
      "Train Epoch: 1133 [65792/118836 (55%)] Loss: 12187.401367\n",
      "Train Epoch: 1133 [98560/118836 (83%)] Loss: 12262.513672\n",
      "    epoch          : 1133\n",
      "    loss           : 12249.815711105512\n",
      "    val_loss       : 12247.723259253513\n",
      "    val_log_likelihood: -12170.278736300663\n",
      "    val_log_marginal: -12178.389845017538\n",
      "Train Epoch: 1134 [256/118836 (0%)] Loss: 12270.150391\n",
      "Train Epoch: 1134 [33024/118836 (28%)] Loss: 12247.692383\n",
      "Train Epoch: 1134 [65792/118836 (55%)] Loss: 12215.954102\n",
      "Train Epoch: 1134 [98560/118836 (83%)] Loss: 12225.939453\n",
      "    epoch          : 1134\n",
      "    loss           : 12250.374383852875\n",
      "    val_loss       : 12253.729889569098\n",
      "    val_log_likelihood: -12170.511621336074\n",
      "    val_log_marginal: -12178.70815413848\n",
      "Train Epoch: 1135 [256/118836 (0%)] Loss: 12315.783203\n",
      "Train Epoch: 1135 [33024/118836 (28%)] Loss: 12266.255859\n",
      "Train Epoch: 1135 [65792/118836 (55%)] Loss: 12219.527344\n",
      "Train Epoch: 1135 [98560/118836 (83%)] Loss: 12200.773438\n",
      "    epoch          : 1135\n",
      "    loss           : 12246.91105720766\n",
      "    val_loss       : 12249.188291480717\n",
      "    val_log_likelihood: -12172.917979250673\n",
      "    val_log_marginal: -12181.073646278077\n",
      "Train Epoch: 1136 [256/118836 (0%)] Loss: 12255.291016\n",
      "Train Epoch: 1136 [33024/118836 (28%)] Loss: 12358.666992\n",
      "Train Epoch: 1136 [65792/118836 (55%)] Loss: 12280.443359\n",
      "Train Epoch: 1136 [98560/118836 (83%)] Loss: 12198.281250\n",
      "    epoch          : 1136\n",
      "    loss           : 12247.824787078682\n",
      "    val_loss       : 12251.875404404536\n",
      "    val_log_likelihood: -12173.975754755997\n",
      "    val_log_marginal: -12182.188789577314\n",
      "Train Epoch: 1137 [256/118836 (0%)] Loss: 12212.126953\n",
      "Train Epoch: 1137 [33024/118836 (28%)] Loss: 12351.346680\n",
      "Train Epoch: 1137 [65792/118836 (55%)] Loss: 12297.385742\n",
      "Train Epoch: 1137 [98560/118836 (83%)] Loss: 12349.089844\n",
      "    epoch          : 1137\n",
      "    loss           : 12247.993737076096\n",
      "    val_loss       : 12247.559346406511\n",
      "    val_log_likelihood: -12170.019041272488\n",
      "    val_log_marginal: -12178.10489730055\n",
      "Train Epoch: 1138 [256/118836 (0%)] Loss: 12226.404297\n",
      "Train Epoch: 1138 [33024/118836 (28%)] Loss: 12338.016602\n",
      "Train Epoch: 1138 [65792/118836 (55%)] Loss: 12261.071289\n",
      "Train Epoch: 1138 [98560/118836 (83%)] Loss: 12200.326172\n",
      "    epoch          : 1138\n",
      "    loss           : 12246.128511586281\n",
      "    val_loss       : 12251.285739615692\n",
      "    val_log_likelihood: -12171.797406495554\n",
      "    val_log_marginal: -12179.78797042437\n",
      "Train Epoch: 1139 [256/118836 (0%)] Loss: 12295.938477\n",
      "Train Epoch: 1139 [33024/118836 (28%)] Loss: 12217.090820\n",
      "Train Epoch: 1139 [65792/118836 (55%)] Loss: 12207.185547\n",
      "Train Epoch: 1139 [98560/118836 (83%)] Loss: 12322.251953\n",
      "    epoch          : 1139\n",
      "    loss           : 12249.639237780448\n",
      "    val_loss       : 12250.322648103564\n",
      "    val_log_likelihood: -12172.32315608199\n",
      "    val_log_marginal: -12180.394640687678\n",
      "Train Epoch: 1140 [256/118836 (0%)] Loss: 12272.059570\n",
      "Train Epoch: 1140 [33024/118836 (28%)] Loss: 12258.917969\n",
      "Train Epoch: 1140 [65792/118836 (55%)] Loss: 12313.506836\n",
      "Train Epoch: 1140 [98560/118836 (83%)] Loss: 12211.028320\n",
      "    epoch          : 1140\n",
      "    loss           : 12250.106201696908\n",
      "    val_loss       : 12248.37921417073\n",
      "    val_log_likelihood: -12173.218346774194\n",
      "    val_log_marginal: -12181.193093946573\n",
      "Train Epoch: 1141 [256/118836 (0%)] Loss: 12301.419922\n",
      "Train Epoch: 1141 [33024/118836 (28%)] Loss: 12181.976562\n",
      "Train Epoch: 1141 [65792/118836 (55%)] Loss: 12262.820312\n",
      "Train Epoch: 1141 [98560/118836 (83%)] Loss: 12285.696289\n",
      "    epoch          : 1141\n",
      "    loss           : 12245.523085162065\n",
      "    val_loss       : 12243.89090691884\n",
      "    val_log_likelihood: -12171.847371924112\n",
      "    val_log_marginal: -12179.901720740958\n",
      "Train Epoch: 1142 [256/118836 (0%)] Loss: 12247.160156\n",
      "Train Epoch: 1142 [33024/118836 (28%)] Loss: 12233.397461\n",
      "Train Epoch: 1142 [65792/118836 (55%)] Loss: 12271.430664\n",
      "Train Epoch: 1142 [98560/118836 (83%)] Loss: 12223.148438\n",
      "    epoch          : 1142\n",
      "    loss           : 12247.080162938119\n",
      "    val_loss       : 12246.948181834832\n",
      "    val_log_likelihood: -12170.684199073356\n",
      "    val_log_marginal: -12178.62078867337\n",
      "Train Epoch: 1143 [256/118836 (0%)] Loss: 12165.009766\n",
      "Train Epoch: 1143 [33024/118836 (28%)] Loss: 12305.652344\n",
      "Train Epoch: 1143 [65792/118836 (55%)] Loss: 12259.124023\n",
      "Train Epoch: 1143 [98560/118836 (83%)] Loss: 12300.494141\n",
      "    epoch          : 1143\n",
      "    loss           : 12251.585240255376\n",
      "    val_loss       : 12246.292235954581\n",
      "    val_log_likelihood: -12169.982427690757\n",
      "    val_log_marginal: -12178.123653718316\n",
      "Train Epoch: 1144 [256/118836 (0%)] Loss: 12185.653320\n",
      "Train Epoch: 1144 [33024/118836 (28%)] Loss: 12297.976562\n",
      "Train Epoch: 1144 [65792/118836 (55%)] Loss: 12243.033203\n",
      "Train Epoch: 1144 [98560/118836 (83%)] Loss: 12260.583984\n",
      "    epoch          : 1144\n",
      "    loss           : 12242.704525305004\n",
      "    val_loss       : 12243.258592117942\n",
      "    val_log_likelihood: -12170.50178220637\n",
      "    val_log_marginal: -12178.5022030484\n",
      "Train Epoch: 1145 [256/118836 (0%)] Loss: 12284.150391\n",
      "Train Epoch: 1145 [33024/118836 (28%)] Loss: 12328.680664\n",
      "Train Epoch: 1145 [65792/118836 (55%)] Loss: 12221.038086\n",
      "Train Epoch: 1145 [98560/118836 (83%)] Loss: 12362.547852\n",
      "    epoch          : 1145\n",
      "    loss           : 12247.378316112232\n",
      "    val_loss       : 12249.585658113512\n",
      "    val_log_likelihood: -12171.023612295801\n",
      "    val_log_marginal: -12179.024154180432\n",
      "Train Epoch: 1146 [256/118836 (0%)] Loss: 12205.608398\n",
      "Train Epoch: 1146 [33024/118836 (28%)] Loss: 12352.250000\n",
      "Train Epoch: 1146 [65792/118836 (55%)] Loss: 12332.354492\n",
      "Train Epoch: 1146 [98560/118836 (83%)] Loss: 12204.484375\n",
      "    epoch          : 1146\n",
      "    loss           : 12251.187150893042\n",
      "    val_loss       : 12245.666773893738\n",
      "    val_log_likelihood: -12170.081126253619\n",
      "    val_log_marginal: -12178.044434554095\n",
      "Train Epoch: 1147 [256/118836 (0%)] Loss: 12265.009766\n",
      "Train Epoch: 1147 [33024/118836 (28%)] Loss: 12187.241211\n",
      "Train Epoch: 1147 [65792/118836 (55%)] Loss: 12206.242188\n",
      "Train Epoch: 1147 [98560/118836 (83%)] Loss: 12233.043945\n",
      "    epoch          : 1147\n",
      "    loss           : 12244.821148030398\n",
      "    val_loss       : 12249.968847213193\n",
      "    val_log_likelihood: -12172.197913274142\n",
      "    val_log_marginal: -12180.266377141363\n",
      "Train Epoch: 1148 [256/118836 (0%)] Loss: 12297.909180\n",
      "Train Epoch: 1148 [33024/118836 (28%)] Loss: 12339.228516\n",
      "Train Epoch: 1148 [65792/118836 (55%)] Loss: 12237.167969\n",
      "Train Epoch: 1148 [98560/118836 (83%)] Loss: 12305.617188\n",
      "    epoch          : 1148\n",
      "    loss           : 12247.868633846412\n",
      "    val_loss       : 12248.91404653126\n",
      "    val_log_likelihood: -12169.99114357165\n",
      "    val_log_marginal: -12177.940715349083\n",
      "Train Epoch: 1149 [256/118836 (0%)] Loss: 12342.342773\n",
      "Train Epoch: 1149 [33024/118836 (28%)] Loss: 12266.093750\n",
      "Train Epoch: 1149 [65792/118836 (55%)] Loss: 12234.061523\n",
      "Train Epoch: 1149 [98560/118836 (83%)] Loss: 12279.263672\n",
      "    epoch          : 1149\n",
      "    loss           : 12249.31796632677\n",
      "    val_loss       : 12262.989245160114\n",
      "    val_log_likelihood: -12175.519377455543\n",
      "    val_log_marginal: -12183.938178738095\n",
      "Train Epoch: 1150 [256/118836 (0%)] Loss: 12333.689453\n",
      "Train Epoch: 1150 [33024/118836 (28%)] Loss: 12231.564453\n",
      "Train Epoch: 1150 [65792/118836 (55%)] Loss: 12237.074219\n",
      "Train Epoch: 1150 [98560/118836 (83%)] Loss: 12255.755859\n",
      "    epoch          : 1150\n",
      "    loss           : 12250.285734433159\n",
      "    val_loss       : 12246.040576420593\n",
      "    val_log_likelihood: -12170.647394864041\n",
      "    val_log_marginal: -12178.788927617707\n",
      "Train Epoch: 1151 [256/118836 (0%)] Loss: 12253.337891\n",
      "Train Epoch: 1151 [33024/118836 (28%)] Loss: 12312.495117\n",
      "Train Epoch: 1151 [65792/118836 (55%)] Loss: 12304.128906\n",
      "Train Epoch: 1151 [98560/118836 (83%)] Loss: 12323.098633\n",
      "    epoch          : 1151\n",
      "    loss           : 12254.459045278898\n",
      "    val_loss       : 12249.77063973375\n",
      "    val_log_likelihood: -12171.041133878722\n",
      "    val_log_marginal: -12179.097951572661\n",
      "Train Epoch: 1152 [256/118836 (0%)] Loss: 12323.130859\n",
      "Train Epoch: 1152 [33024/118836 (28%)] Loss: 12229.578125\n",
      "Train Epoch: 1152 [65792/118836 (55%)] Loss: 12282.263672\n",
      "Train Epoch: 1152 [98560/118836 (83%)] Loss: 12182.298828\n",
      "    epoch          : 1152\n",
      "    loss           : 12247.258035598894\n",
      "    val_loss       : 12247.224262878313\n",
      "    val_log_likelihood: -12172.263055566325\n",
      "    val_log_marginal: -12180.198772693013\n",
      "Train Epoch: 1153 [256/118836 (0%)] Loss: 12293.065430\n",
      "Train Epoch: 1153 [33024/118836 (28%)] Loss: 12239.742188\n",
      "Train Epoch: 1153 [65792/118836 (55%)] Loss: 12379.336914\n",
      "Train Epoch: 1153 [98560/118836 (83%)] Loss: 12382.148438\n",
      "    epoch          : 1153\n",
      "    loss           : 12245.009551734387\n",
      "    val_loss       : 12247.5526736977\n",
      "    val_log_likelihood: -12172.038633749484\n",
      "    val_log_marginal: -12180.009184778979\n",
      "Train Epoch: 1154 [256/118836 (0%)] Loss: 12209.456055\n",
      "Train Epoch: 1154 [33024/118836 (28%)] Loss: 12333.291992\n",
      "Train Epoch: 1154 [65792/118836 (55%)] Loss: 12318.748047\n",
      "Train Epoch: 1154 [98560/118836 (83%)] Loss: 12193.945312\n",
      "    epoch          : 1154\n",
      "    loss           : 12245.103109329766\n",
      "    val_loss       : 12250.750922417637\n",
      "    val_log_likelihood: -12172.139306923335\n",
      "    val_log_marginal: -12180.111685145615\n",
      "Train Epoch: 1155 [256/118836 (0%)] Loss: 12274.869141\n",
      "Train Epoch: 1155 [33024/118836 (28%)] Loss: 12271.613281\n",
      "Train Epoch: 1155 [65792/118836 (55%)] Loss: 12329.775391\n",
      "Train Epoch: 1155 [98560/118836 (83%)] Loss: 12321.765625\n",
      "    epoch          : 1155\n",
      "    loss           : 12245.98254820616\n",
      "    val_loss       : 12246.418865718388\n",
      "    val_log_likelihood: -12174.061024251707\n",
      "    val_log_marginal: -12182.420554231247\n",
      "Train Epoch: 1156 [256/118836 (0%)] Loss: 12223.740234\n",
      "Train Epoch: 1156 [33024/118836 (28%)] Loss: 12265.634766\n",
      "Train Epoch: 1156 [65792/118836 (55%)] Loss: 12362.478516\n",
      "Train Epoch: 1156 [98560/118836 (83%)] Loss: 12239.768555\n",
      "    epoch          : 1156\n",
      "    loss           : 12249.260170950942\n",
      "    val_loss       : 12247.66073135419\n",
      "    val_log_likelihood: -12170.253297857218\n",
      "    val_log_marginal: -12178.372774685153\n",
      "Train Epoch: 1157 [256/118836 (0%)] Loss: 12235.185547\n",
      "Train Epoch: 1157 [33024/118836 (28%)] Loss: 12269.353516\n",
      "Train Epoch: 1157 [65792/118836 (55%)] Loss: 12208.734375\n",
      "Train Epoch: 1157 [98560/118836 (83%)] Loss: 12314.126953\n",
      "    epoch          : 1157\n",
      "    loss           : 12247.931136592742\n",
      "    val_loss       : 12249.808717929189\n",
      "    val_log_likelihood: -12168.710838470586\n",
      "    val_log_marginal: -12176.75453505468\n",
      "Train Epoch: 1158 [256/118836 (0%)] Loss: 12184.197266\n",
      "Train Epoch: 1158 [33024/118836 (28%)] Loss: 12235.339844\n",
      "Train Epoch: 1158 [65792/118836 (55%)] Loss: 12252.853516\n",
      "Train Epoch: 1158 [98560/118836 (83%)] Loss: 12290.332031\n",
      "    epoch          : 1158\n",
      "    loss           : 12245.96962171733\n",
      "    val_loss       : 12248.23968278868\n",
      "    val_log_likelihood: -12175.291251970895\n",
      "    val_log_marginal: -12183.634946492743\n",
      "Train Epoch: 1159 [256/118836 (0%)] Loss: 12267.308594\n",
      "Train Epoch: 1159 [33024/118836 (28%)] Loss: 12229.583008\n",
      "Train Epoch: 1159 [65792/118836 (55%)] Loss: 12358.835938\n",
      "Train Epoch: 1159 [98560/118836 (83%)] Loss: 12358.224609\n",
      "    epoch          : 1159\n",
      "    loss           : 12249.09440201096\n",
      "    val_loss       : 12248.056220740786\n",
      "    val_log_likelihood: -12170.325562351376\n",
      "    val_log_marginal: -12178.701751359384\n",
      "Train Epoch: 1160 [256/118836 (0%)] Loss: 12242.513672\n",
      "Train Epoch: 1160 [33024/118836 (28%)] Loss: 12279.904297\n",
      "Train Epoch: 1160 [65792/118836 (55%)] Loss: 12252.177734\n",
      "Train Epoch: 1160 [98560/118836 (83%)] Loss: 12313.268555\n",
      "    epoch          : 1160\n",
      "    loss           : 12252.201083669355\n",
      "    val_loss       : 12248.249879119481\n",
      "    val_log_likelihood: -12170.501981557589\n",
      "    val_log_marginal: -12178.599678300734\n",
      "Train Epoch: 1161 [256/118836 (0%)] Loss: 12236.679688\n",
      "Train Epoch: 1161 [33024/118836 (28%)] Loss: 12195.202148\n",
      "Train Epoch: 1161 [65792/118836 (55%)] Loss: 12274.957031\n",
      "Train Epoch: 1161 [98560/118836 (83%)] Loss: 12317.694336\n",
      "    epoch          : 1161\n",
      "    loss           : 12251.623566739041\n",
      "    val_loss       : 12248.439166884587\n",
      "    val_log_likelihood: -12172.046581950475\n",
      "    val_log_marginal: -12180.152583556046\n",
      "Train Epoch: 1162 [256/118836 (0%)] Loss: 12214.155273\n",
      "Train Epoch: 1162 [33024/118836 (28%)] Loss: 12245.458008\n",
      "Train Epoch: 1162 [65792/118836 (55%)] Loss: 12286.734375\n",
      "Train Epoch: 1162 [98560/118836 (83%)] Loss: 12260.899414\n",
      "    epoch          : 1162\n",
      "    loss           : 12247.899762038616\n",
      "    val_loss       : 12248.805256430593\n",
      "    val_log_likelihood: -12171.796473066584\n",
      "    val_log_marginal: -12179.93173214651\n",
      "Train Epoch: 1163 [256/118836 (0%)] Loss: 12268.269531\n",
      "Train Epoch: 1163 [33024/118836 (28%)] Loss: 12277.522461\n",
      "Train Epoch: 1163 [65792/118836 (55%)] Loss: 12250.084961\n",
      "Train Epoch: 1163 [98560/118836 (83%)] Loss: 12315.417969\n",
      "    epoch          : 1163\n",
      "    loss           : 12246.817765198512\n",
      "    val_loss       : 12249.664733587184\n",
      "    val_log_likelihood: -12172.972078228391\n",
      "    val_log_marginal: -12181.046564790086\n",
      "Train Epoch: 1164 [256/118836 (0%)] Loss: 12276.681641\n",
      "Train Epoch: 1164 [33024/118836 (28%)] Loss: 12252.529297\n",
      "Train Epoch: 1164 [65792/118836 (55%)] Loss: 12263.602539\n",
      "Train Epoch: 1164 [98560/118836 (83%)] Loss: 12251.139648\n",
      "    epoch          : 1164\n",
      "    loss           : 12249.378122253669\n",
      "    val_loss       : 12249.091799691669\n",
      "    val_log_likelihood: -12171.640479121434\n",
      "    val_log_marginal: -12179.763898841973\n",
      "Train Epoch: 1165 [256/118836 (0%)] Loss: 12218.703125\n",
      "Train Epoch: 1165 [33024/118836 (28%)] Loss: 12250.828125\n",
      "Train Epoch: 1165 [65792/118836 (55%)] Loss: 12214.954102\n",
      "Train Epoch: 1165 [98560/118836 (83%)] Loss: 12259.418945\n",
      "    epoch          : 1165\n",
      "    loss           : 12245.905918340313\n",
      "    val_loss       : 12249.427304283992\n",
      "    val_log_likelihood: -12172.340206427058\n",
      "    val_log_marginal: -12180.33227578606\n",
      "Train Epoch: 1166 [256/118836 (0%)] Loss: 12343.289062\n",
      "Train Epoch: 1166 [33024/118836 (28%)] Loss: 12205.548828\n",
      "Train Epoch: 1166 [65792/118836 (55%)] Loss: 12234.902344\n",
      "Train Epoch: 1166 [98560/118836 (83%)] Loss: 12267.674805\n",
      "    epoch          : 1166\n",
      "    loss           : 12249.416097691792\n",
      "    val_loss       : 12250.680604559137\n",
      "    val_log_likelihood: -12170.670038836332\n",
      "    val_log_marginal: -12178.84488471029\n",
      "Train Epoch: 1167 [256/118836 (0%)] Loss: 12318.072266\n",
      "Train Epoch: 1167 [33024/118836 (28%)] Loss: 12251.162109\n",
      "Train Epoch: 1167 [65792/118836 (55%)] Loss: 12216.392578\n",
      "Train Epoch: 1167 [98560/118836 (83%)] Loss: 12351.660156\n",
      "    epoch          : 1167\n",
      "    loss           : 12248.217342102203\n",
      "    val_loss       : 12247.867794330185\n",
      "    val_log_likelihood: -12171.475596115075\n",
      "    val_log_marginal: -12179.494573882223\n",
      "Train Epoch: 1168 [256/118836 (0%)] Loss: 12278.441406\n",
      "Train Epoch: 1168 [33024/118836 (28%)] Loss: 12332.587891\n",
      "Train Epoch: 1168 [65792/118836 (55%)] Loss: 12240.546875\n",
      "Train Epoch: 1168 [98560/118836 (83%)] Loss: 12251.199219\n",
      "    epoch          : 1168\n",
      "    loss           : 12244.104024503722\n",
      "    val_loss       : 12246.12244153372\n",
      "    val_log_likelihood: -12171.885998403897\n",
      "    val_log_marginal: -12179.829819625185\n",
      "Train Epoch: 1169 [256/118836 (0%)] Loss: 12393.802734\n",
      "Train Epoch: 1169 [33024/118836 (28%)] Loss: 12272.424805\n",
      "Train Epoch: 1169 [65792/118836 (55%)] Loss: 12202.488281\n",
      "Train Epoch: 1169 [98560/118836 (83%)] Loss: 12298.912109\n",
      "    epoch          : 1169\n",
      "    loss           : 12252.62563585608\n",
      "    val_loss       : 12249.141530529381\n",
      "    val_log_likelihood: -12172.757050474307\n",
      "    val_log_marginal: -12181.103518728947\n",
      "Train Epoch: 1170 [256/118836 (0%)] Loss: 12335.779297\n",
      "Train Epoch: 1170 [33024/118836 (28%)] Loss: 12248.492188\n",
      "Train Epoch: 1170 [65792/118836 (55%)] Loss: 12313.541016\n",
      "Train Epoch: 1170 [98560/118836 (83%)] Loss: 12301.734375\n",
      "    epoch          : 1170\n",
      "    loss           : 12249.997741870864\n",
      "    val_loss       : 12249.241363568704\n",
      "    val_log_likelihood: -12173.121000859439\n",
      "    val_log_marginal: -12181.238170751049\n",
      "Train Epoch: 1171 [256/118836 (0%)] Loss: 12300.447266\n",
      "Train Epoch: 1171 [33024/118836 (28%)] Loss: 12305.246094\n",
      "Train Epoch: 1171 [65792/118836 (55%)] Loss: 12329.133789\n",
      "Train Epoch: 1171 [98560/118836 (83%)] Loss: 12229.628906\n",
      "    epoch          : 1171\n",
      "    loss           : 12251.858489227925\n",
      "    val_loss       : 12245.39668096546\n",
      "    val_log_likelihood: -12172.161916647281\n",
      "    val_log_marginal: -12180.17392786414\n",
      "Train Epoch: 1172 [256/118836 (0%)] Loss: 12208.930664\n",
      "Train Epoch: 1172 [33024/118836 (28%)] Loss: 12223.022461\n",
      "Train Epoch: 1172 [65792/118836 (55%)] Loss: 12262.045898\n",
      "Train Epoch: 1172 [98560/118836 (83%)] Loss: 12194.362305\n",
      "    epoch          : 1172\n",
      "    loss           : 12245.509857546267\n",
      "    val_loss       : 12248.170963949287\n",
      "    val_log_likelihood: -12173.335868195565\n",
      "    val_log_marginal: -12181.596520629833\n",
      "Train Epoch: 1173 [256/118836 (0%)] Loss: 12257.185547\n",
      "Train Epoch: 1173 [33024/118836 (28%)] Loss: 12302.118164\n",
      "Train Epoch: 1173 [65792/118836 (55%)] Loss: 12260.375977\n",
      "Train Epoch: 1173 [98560/118836 (83%)] Loss: 12317.710938\n",
      "    epoch          : 1173\n",
      "    loss           : 12245.834149962522\n",
      "    val_loss       : 12249.264739616709\n",
      "    val_log_likelihood: -12171.014680101065\n",
      "    val_log_marginal: -12178.940830846697\n",
      "Train Epoch: 1174 [256/118836 (0%)] Loss: 12194.255859\n",
      "Train Epoch: 1174 [33024/118836 (28%)] Loss: 12307.262695\n",
      "Train Epoch: 1174 [65792/118836 (55%)] Loss: 12297.766602\n",
      "Train Epoch: 1174 [98560/118836 (83%)] Loss: 12192.773438\n",
      "    epoch          : 1174\n",
      "    loss           : 12246.64243515431\n",
      "    val_loss       : 12245.971451094578\n",
      "    val_log_likelihood: -12172.323379988627\n",
      "    val_log_marginal: -12180.293126547806\n",
      "Train Epoch: 1175 [256/118836 (0%)] Loss: 12407.271484\n",
      "Train Epoch: 1175 [33024/118836 (28%)] Loss: 12190.054688\n",
      "Train Epoch: 1175 [65792/118836 (55%)] Loss: 12205.060547\n",
      "Train Epoch: 1175 [98560/118836 (83%)] Loss: 12318.494141\n",
      "    epoch          : 1175\n",
      "    loss           : 12246.613272203267\n",
      "    val_loss       : 12246.535793918421\n",
      "    val_log_likelihood: -12168.861475134408\n",
      "    val_log_marginal: -12177.140867386035\n",
      "Train Epoch: 1176 [256/118836 (0%)] Loss: 12254.988281\n",
      "Train Epoch: 1176 [33024/118836 (28%)] Loss: 12258.436523\n",
      "Train Epoch: 1176 [65792/118836 (55%)] Loss: 12285.979492\n",
      "Train Epoch: 1176 [98560/118836 (83%)] Loss: 12325.543945\n",
      "    epoch          : 1176\n",
      "    loss           : 12246.911504213194\n",
      "    val_loss       : 12250.483507368148\n",
      "    val_log_likelihood: -12171.779196068548\n",
      "    val_log_marginal: -12179.686900578408\n",
      "Train Epoch: 1177 [256/118836 (0%)] Loss: 12217.566406\n",
      "Train Epoch: 1177 [33024/118836 (28%)] Loss: 12238.245117\n",
      "Train Epoch: 1177 [65792/118836 (55%)] Loss: 12305.551758\n",
      "Train Epoch: 1177 [98560/118836 (83%)] Loss: 12309.255859\n",
      "    epoch          : 1177\n",
      "    loss           : 12249.484866593\n",
      "    val_loss       : 12249.908702432369\n",
      "    val_log_likelihood: -12171.996452711435\n",
      "    val_log_marginal: -12180.132438493274\n",
      "Train Epoch: 1178 [256/118836 (0%)] Loss: 12226.380859\n",
      "Train Epoch: 1178 [33024/118836 (28%)] Loss: 12320.897461\n",
      "Train Epoch: 1178 [65792/118836 (55%)] Loss: 12293.238281\n",
      "Train Epoch: 1178 [98560/118836 (83%)] Loss: 12292.981445\n",
      "    epoch          : 1178\n",
      "    loss           : 12247.017752436155\n",
      "    val_loss       : 12248.558466469434\n",
      "    val_log_likelihood: -12171.21984788565\n",
      "    val_log_marginal: -12179.339434547644\n",
      "Train Epoch: 1179 [256/118836 (0%)] Loss: 12228.191406\n",
      "Train Epoch: 1179 [33024/118836 (28%)] Loss: 12285.013672\n",
      "Train Epoch: 1179 [65792/118836 (55%)] Loss: 12321.564453\n",
      "Train Epoch: 1179 [98560/118836 (83%)] Loss: 12207.441406\n",
      "    epoch          : 1179\n",
      "    loss           : 12250.651200792236\n",
      "    val_loss       : 12246.879993203436\n",
      "    val_log_likelihood: -12169.006046933158\n",
      "    val_log_marginal: -12177.213011725678\n",
      "Train Epoch: 1180 [256/118836 (0%)] Loss: 12302.211914\n",
      "Train Epoch: 1180 [33024/118836 (28%)] Loss: 12171.416016\n",
      "Train Epoch: 1180 [65792/118836 (55%)] Loss: 12274.248047\n",
      "Train Epoch: 1180 [98560/118836 (83%)] Loss: 12222.241211\n",
      "    epoch          : 1180\n",
      "    loss           : 12244.979045828164\n",
      "    val_loss       : 12246.671048327671\n",
      "    val_log_likelihood: -12170.218953066842\n",
      "    val_log_marginal: -12178.450567280881\n",
      "Train Epoch: 1181 [256/118836 (0%)] Loss: 12222.712891\n",
      "Train Epoch: 1181 [33024/118836 (28%)] Loss: 12290.940430\n",
      "Train Epoch: 1181 [65792/118836 (55%)] Loss: 12252.331055\n",
      "Train Epoch: 1181 [98560/118836 (83%)] Loss: 12262.765625\n",
      "    epoch          : 1181\n",
      "    loss           : 12247.30293647255\n",
      "    val_loss       : 12248.487263261397\n",
      "    val_log_likelihood: -12172.209574835866\n",
      "    val_log_marginal: -12180.146245854783\n",
      "Train Epoch: 1182 [256/118836 (0%)] Loss: 12240.476562\n",
      "Train Epoch: 1182 [33024/118836 (28%)] Loss: 12301.176758\n",
      "Train Epoch: 1182 [65792/118836 (55%)] Loss: 12223.386719\n",
      "Train Epoch: 1182 [98560/118836 (83%)] Loss: 12231.461914\n",
      "    epoch          : 1182\n",
      "    loss           : 12250.94235583385\n",
      "    val_loss       : 12254.166776067988\n",
      "    val_log_likelihood: -12174.08124596128\n",
      "    val_log_marginal: -12182.504661978386\n",
      "Train Epoch: 1183 [256/118836 (0%)] Loss: 12226.945312\n",
      "Train Epoch: 1183 [33024/118836 (28%)] Loss: 12219.399414\n",
      "Train Epoch: 1183 [65792/118836 (55%)] Loss: 12202.025391\n",
      "Train Epoch: 1183 [98560/118836 (83%)] Loss: 12194.507812\n",
      "    epoch          : 1183\n",
      "    loss           : 12242.126635358509\n",
      "    val_loss       : 12247.268613950695\n",
      "    val_log_likelihood: -12172.271598590001\n",
      "    val_log_marginal: -12180.255644163013\n",
      "Train Epoch: 1184 [256/118836 (0%)] Loss: 12246.503906\n",
      "Train Epoch: 1184 [33024/118836 (28%)] Loss: 12274.637695\n",
      "Train Epoch: 1184 [65792/118836 (55%)] Loss: 12235.803711\n",
      "Train Epoch: 1184 [98560/118836 (83%)] Loss: 12280.903320\n",
      "    epoch          : 1184\n",
      "    loss           : 12250.419127377998\n",
      "    val_loss       : 12252.92678517146\n",
      "    val_log_likelihood: -12172.460507618642\n",
      "    val_log_marginal: -12180.798210418245\n",
      "Train Epoch: 1185 [256/118836 (0%)] Loss: 12256.087891\n",
      "Train Epoch: 1185 [33024/118836 (28%)] Loss: 12204.354492\n",
      "Train Epoch: 1185 [65792/118836 (55%)] Loss: 12310.792969\n",
      "Train Epoch: 1185 [98560/118836 (83%)] Loss: 12223.499023\n",
      "    epoch          : 1185\n",
      "    loss           : 12247.662208565964\n",
      "    val_loss       : 12254.416657180622\n",
      "    val_log_likelihood: -12174.065204650022\n",
      "    val_log_marginal: -12182.144307963948\n",
      "Train Epoch: 1186 [256/118836 (0%)] Loss: 12315.790039\n",
      "Train Epoch: 1186 [33024/118836 (28%)] Loss: 12290.994141\n",
      "Train Epoch: 1186 [65792/118836 (55%)] Loss: 12140.847656\n",
      "Train Epoch: 1186 [98560/118836 (83%)] Loss: 12188.430664\n",
      "    epoch          : 1186\n",
      "    loss           : 12245.267643552263\n",
      "    val_loss       : 12249.93026174309\n",
      "    val_log_likelihood: -12170.372883710712\n",
      "    val_log_marginal: -12178.402300490316\n",
      "Train Epoch: 1187 [256/118836 (0%)] Loss: 12230.437500\n",
      "Train Epoch: 1187 [33024/118836 (28%)] Loss: 12207.015625\n",
      "Train Epoch: 1187 [65792/118836 (55%)] Loss: 12189.314453\n",
      "Train Epoch: 1187 [98560/118836 (83%)] Loss: 12227.199219\n",
      "    epoch          : 1187\n",
      "    loss           : 12247.868871646246\n",
      "    val_loss       : 12252.799768297089\n",
      "    val_log_likelihood: -12170.791441790736\n",
      "    val_log_marginal: -12178.999964668164\n",
      "Train Epoch: 1188 [256/118836 (0%)] Loss: 12183.632812\n",
      "Train Epoch: 1188 [33024/118836 (28%)] Loss: 12271.031250\n",
      "Train Epoch: 1188 [65792/118836 (55%)] Loss: 12275.241211\n",
      "Train Epoch: 1188 [98560/118836 (83%)] Loss: 12150.401367\n",
      "    epoch          : 1188\n",
      "    loss           : 12244.441680721411\n",
      "    val_loss       : 12255.443365447522\n",
      "    val_log_likelihood: -12170.67135917468\n",
      "    val_log_marginal: -12178.933173482717\n",
      "Train Epoch: 1189 [256/118836 (0%)] Loss: 12190.585938\n",
      "Train Epoch: 1189 [33024/118836 (28%)] Loss: 12268.093750\n",
      "Train Epoch: 1189 [65792/118836 (55%)] Loss: 12289.802734\n",
      "Train Epoch: 1189 [98560/118836 (83%)] Loss: 12289.572266\n",
      "    epoch          : 1189\n",
      "    loss           : 12246.701227932434\n",
      "    val_loss       : 12246.153194523517\n",
      "    val_log_likelihood: -12169.751314522591\n",
      "    val_log_marginal: -12177.898110026259\n",
      "Train Epoch: 1190 [256/118836 (0%)] Loss: 12226.765625\n",
      "Train Epoch: 1190 [33024/118836 (28%)] Loss: 12277.988281\n",
      "Train Epoch: 1190 [65792/118836 (55%)] Loss: 12298.203125\n",
      "Train Epoch: 1190 [98560/118836 (83%)] Loss: 12232.433594\n",
      "    epoch          : 1190\n",
      "    loss           : 12248.579776513388\n",
      "    val_loss       : 12244.60349397892\n",
      "    val_log_likelihood: -12169.936912608562\n",
      "    val_log_marginal: -12178.078104663111\n",
      "Train Epoch: 1191 [256/118836 (0%)] Loss: 12355.048828\n",
      "Train Epoch: 1191 [33024/118836 (28%)] Loss: 12291.475586\n",
      "Train Epoch: 1191 [65792/118836 (55%)] Loss: 12269.190430\n",
      "Train Epoch: 1191 [98560/118836 (83%)] Loss: 12214.949219\n",
      "    epoch          : 1191\n",
      "    loss           : 12245.504932731079\n",
      "    val_loss       : 12244.55385440316\n",
      "    val_log_likelihood: -12171.87787993047\n",
      "    val_log_marginal: -12180.164351007379\n",
      "Train Epoch: 1192 [256/118836 (0%)] Loss: 12288.008789\n",
      "Train Epoch: 1192 [33024/118836 (28%)] Loss: 12251.463867\n",
      "Train Epoch: 1192 [65792/118836 (55%)] Loss: 12364.455078\n",
      "Train Epoch: 1192 [98560/118836 (83%)] Loss: 12227.906250\n",
      "    epoch          : 1192\n",
      "    loss           : 12252.560409073873\n",
      "    val_loss       : 12248.625338081836\n",
      "    val_log_likelihood: -12170.958962081264\n",
      "    val_log_marginal: -12179.326306396335\n",
      "Train Epoch: 1193 [256/118836 (0%)] Loss: 12239.407227\n",
      "Train Epoch: 1193 [33024/118836 (28%)] Loss: 12237.333984\n",
      "Train Epoch: 1193 [65792/118836 (55%)] Loss: 12245.552734\n",
      "Train Epoch: 1193 [98560/118836 (83%)] Loss: 12255.296875\n",
      "    epoch          : 1193\n",
      "    loss           : 12248.562088212106\n",
      "    val_loss       : 12246.74292176655\n",
      "    val_log_likelihood: -12169.961533453526\n",
      "    val_log_marginal: -12178.047784822742\n",
      "Train Epoch: 1194 [256/118836 (0%)] Loss: 12211.257812\n",
      "Train Epoch: 1194 [33024/118836 (28%)] Loss: 12221.722656\n",
      "Train Epoch: 1194 [65792/118836 (55%)] Loss: 12315.438477\n",
      "Train Epoch: 1194 [98560/118836 (83%)] Loss: 12349.605469\n",
      "    epoch          : 1194\n",
      "    loss           : 12252.29749179332\n",
      "    val_loss       : 12251.778130854855\n",
      "    val_log_likelihood: -12171.7546404893\n",
      "    val_log_marginal: -12180.042910375534\n",
      "Train Epoch: 1195 [256/118836 (0%)] Loss: 12243.699219\n",
      "Train Epoch: 1195 [33024/118836 (28%)] Loss: 12179.121094\n",
      "Train Epoch: 1195 [65792/118836 (55%)] Loss: 12176.003906\n",
      "Train Epoch: 1195 [98560/118836 (83%)] Loss: 12365.804688\n",
      "    epoch          : 1195\n",
      "    loss           : 12251.295459670959\n",
      "    val_loss       : 12248.982899128452\n",
      "    val_log_likelihood: -12170.80945561285\n",
      "    val_log_marginal: -12179.066618255563\n",
      "Train Epoch: 1196 [256/118836 (0%)] Loss: 12245.802734\n",
      "Train Epoch: 1196 [33024/118836 (28%)] Loss: 12168.918945\n",
      "Train Epoch: 1196 [65792/118836 (55%)] Loss: 12358.423828\n",
      "Train Epoch: 1196 [98560/118836 (83%)] Loss: 12262.562500\n",
      "    epoch          : 1196\n",
      "    loss           : 12251.022016678298\n",
      "    val_loss       : 12252.92339620623\n",
      "    val_log_likelihood: -12172.837447173542\n",
      "    val_log_marginal: -12181.27205174563\n",
      "Train Epoch: 1197 [256/118836 (0%)] Loss: 12318.814453\n",
      "Train Epoch: 1197 [33024/118836 (28%)] Loss: 12369.598633\n",
      "Train Epoch: 1197 [65792/118836 (55%)] Loss: 12202.019531\n",
      "Train Epoch: 1197 [98560/118836 (83%)] Loss: 12345.267578\n",
      "    epoch          : 1197\n",
      "    loss           : 12246.161339433414\n",
      "    val_loss       : 12251.477163933143\n",
      "    val_log_likelihood: -12170.76983851582\n",
      "    val_log_marginal: -12178.753987138361\n",
      "Train Epoch: 1198 [256/118836 (0%)] Loss: 12275.766602\n",
      "Train Epoch: 1198 [33024/118836 (28%)] Loss: 12322.115234\n",
      "Train Epoch: 1198 [65792/118836 (55%)] Loss: 12323.789062\n",
      "Train Epoch: 1198 [98560/118836 (83%)] Loss: 12266.861328\n",
      "    epoch          : 1198\n",
      "    loss           : 12246.265052309502\n",
      "    val_loss       : 12247.757086274723\n",
      "    val_log_likelihood: -12169.590082680676\n",
      "    val_log_marginal: -12177.539155875831\n",
      "Train Epoch: 1199 [256/118836 (0%)] Loss: 12186.164062\n",
      "Train Epoch: 1199 [33024/118836 (28%)] Loss: 12297.914062\n",
      "Train Epoch: 1199 [65792/118836 (55%)] Loss: 12370.145508\n",
      "Train Epoch: 1199 [98560/118836 (83%)] Loss: 12277.294922\n",
      "    epoch          : 1199\n",
      "    loss           : 12246.62948249457\n",
      "    val_loss       : 12249.102581444029\n",
      "    val_log_likelihood: -12171.253175887872\n",
      "    val_log_marginal: -12179.380754671642\n",
      "Train Epoch: 1200 [256/118836 (0%)] Loss: 12224.468750\n",
      "Train Epoch: 1200 [33024/118836 (28%)] Loss: 12258.348633\n",
      "Train Epoch: 1200 [65792/118836 (55%)] Loss: 12220.623047\n",
      "Train Epoch: 1200 [98560/118836 (83%)] Loss: 12261.615234\n",
      "    epoch          : 1200\n",
      "    loss           : 12248.214469926075\n",
      "    val_loss       : 12248.820019377032\n",
      "    val_log_likelihood: -12170.007727202232\n",
      "    val_log_marginal: -12178.218556089932\n",
      "Saving checkpoint: saved/models/SelfiesAutoencodingOperad/0905_154251/checkpoint-epoch1200.pth ...\n",
      "Train Epoch: 1201 [256/118836 (0%)] Loss: 12305.269531\n",
      "Train Epoch: 1201 [33024/118836 (28%)] Loss: 12145.664062\n",
      "Train Epoch: 1201 [65792/118836 (55%)] Loss: 12333.567383\n",
      "Train Epoch: 1201 [98560/118836 (83%)] Loss: 12254.557617\n",
      "    epoch          : 1201\n",
      "    loss           : 12248.123714071546\n",
      "    val_loss       : 12245.611048764868\n",
      "    val_log_likelihood: -12169.792787492244\n",
      "    val_log_marginal: -12177.763620922145\n",
      "Train Epoch: 1202 [256/118836 (0%)] Loss: 12227.789062\n",
      "Train Epoch: 1202 [33024/118836 (28%)] Loss: 12294.381836\n",
      "Train Epoch: 1202 [65792/118836 (55%)] Loss: 12319.743164\n",
      "Train Epoch: 1202 [98560/118836 (83%)] Loss: 12256.909180\n",
      "    epoch          : 1202\n",
      "    loss           : 12249.837615022747\n",
      "    val_loss       : 12250.097151410531\n",
      "    val_log_likelihood: -12174.136590964898\n",
      "    val_log_marginal: -12182.309744497179\n",
      "Train Epoch: 1203 [256/118836 (0%)] Loss: 12318.295898\n",
      "Train Epoch: 1203 [33024/118836 (28%)] Loss: 12261.871094\n",
      "Train Epoch: 1203 [65792/118836 (55%)] Loss: 12355.003906\n",
      "Train Epoch: 1203 [98560/118836 (83%)] Loss: 12242.638672\n",
      "    epoch          : 1203\n",
      "    loss           : 12245.306523179022\n",
      "    val_loss       : 12246.539234005291\n",
      "    val_log_likelihood: -12170.51515101582\n",
      "    val_log_marginal: -12178.645540686144\n",
      "Train Epoch: 1204 [256/118836 (0%)] Loss: 12275.666016\n",
      "Train Epoch: 1204 [33024/118836 (28%)] Loss: 12292.258789\n",
      "Train Epoch: 1204 [65792/118836 (55%)] Loss: 12280.892578\n",
      "Train Epoch: 1204 [98560/118836 (83%)] Loss: 12239.470703\n",
      "    epoch          : 1204\n",
      "    loss           : 12247.815718375206\n",
      "    val_loss       : 12245.777491475323\n",
      "    val_log_likelihood: -12170.414077200941\n",
      "    val_log_marginal: -12178.437693170905\n",
      "Train Epoch: 1205 [256/118836 (0%)] Loss: 12223.163086\n",
      "Train Epoch: 1205 [33024/118836 (28%)] Loss: 12270.589844\n",
      "Train Epoch: 1205 [65792/118836 (55%)] Loss: 12200.656250\n",
      "Train Epoch: 1205 [98560/118836 (83%)] Loss: 12167.464844\n",
      "    epoch          : 1205\n",
      "    loss           : 12247.608944310898\n",
      "    val_loss       : 12247.032286639967\n",
      "    val_log_likelihood: -12171.226723887252\n",
      "    val_log_marginal: -12179.538655597684\n",
      "Train Epoch: 1206 [256/118836 (0%)] Loss: 12190.064453\n",
      "Train Epoch: 1206 [33024/118836 (28%)] Loss: 12215.882812\n",
      "Train Epoch: 1206 [65792/118836 (55%)] Loss: 12236.296875\n",
      "Train Epoch: 1206 [98560/118836 (83%)] Loss: 12292.429688\n",
      "    epoch          : 1206\n",
      "    loss           : 12247.532304267474\n",
      "    val_loss       : 12250.012565888459\n",
      "    val_log_likelihood: -12171.858381474874\n",
      "    val_log_marginal: -12180.197662377528\n",
      "Train Epoch: 1207 [256/118836 (0%)] Loss: 12326.149414\n",
      "Train Epoch: 1207 [33024/118836 (28%)] Loss: 12205.263672\n",
      "Train Epoch: 1207 [65792/118836 (55%)] Loss: 12306.659180\n",
      "Train Epoch: 1207 [98560/118836 (83%)] Loss: 12269.056641\n",
      "    epoch          : 1207\n",
      "    loss           : 12248.315173471103\n",
      "    val_loss       : 12249.209613710442\n",
      "    val_log_likelihood: -12169.599238458954\n",
      "    val_log_marginal: -12177.972480626646\n",
      "Train Epoch: 1208 [256/118836 (0%)] Loss: 12225.310547\n",
      "Train Epoch: 1208 [33024/118836 (28%)] Loss: 12295.310547\n",
      "Train Epoch: 1208 [65792/118836 (55%)] Loss: 12236.496094\n",
      "Train Epoch: 1208 [98560/118836 (83%)] Loss: 12368.825195\n",
      "    epoch          : 1208\n",
      "    loss           : 12247.725395956111\n",
      "    val_loss       : 12246.726062898006\n",
      "    val_log_likelihood: -12172.43210669329\n",
      "    val_log_marginal: -12180.51317425683\n",
      "Train Epoch: 1209 [256/118836 (0%)] Loss: 12265.385742\n",
      "Train Epoch: 1209 [33024/118836 (28%)] Loss: 12298.681641\n",
      "Train Epoch: 1209 [65792/118836 (55%)] Loss: 12252.264648\n",
      "Train Epoch: 1209 [98560/118836 (83%)] Loss: 12297.061523\n",
      "    epoch          : 1209\n",
      "    loss           : 12247.183257243849\n",
      "    val_loss       : 12249.760550156898\n",
      "    val_log_likelihood: -12172.067038228908\n",
      "    val_log_marginal: -12180.194314284105\n",
      "Train Epoch: 1210 [256/118836 (0%)] Loss: 12295.791016\n",
      "Train Epoch: 1210 [33024/118836 (28%)] Loss: 12178.282227\n",
      "Train Epoch: 1210 [65792/118836 (55%)] Loss: 12249.447266\n",
      "Train Epoch: 1210 [98560/118836 (83%)] Loss: 12180.233398\n",
      "    epoch          : 1210\n",
      "    loss           : 12249.55708391491\n",
      "    val_loss       : 12246.812439512489\n",
      "    val_log_likelihood: -12170.878912065757\n",
      "    val_log_marginal: -12179.09784490325\n",
      "Train Epoch: 1211 [256/118836 (0%)] Loss: 12263.193359\n",
      "Train Epoch: 1211 [33024/118836 (28%)] Loss: 12372.366211\n",
      "Train Epoch: 1211 [65792/118836 (55%)] Loss: 12326.238281\n",
      "Train Epoch: 1211 [98560/118836 (83%)] Loss: 12251.752930\n",
      "    epoch          : 1211\n",
      "    loss           : 12247.979333385028\n",
      "    val_loss       : 12248.387367162399\n",
      "    val_log_likelihood: -12172.867245172922\n",
      "    val_log_marginal: -12180.932416870986\n",
      "Train Epoch: 1212 [256/118836 (0%)] Loss: 12330.779297\n",
      "Train Epoch: 1212 [33024/118836 (28%)] Loss: 12210.133789\n",
      "Train Epoch: 1212 [65792/118836 (55%)] Loss: 12321.896484\n",
      "Train Epoch: 1212 [98560/118836 (83%)] Loss: 12299.167969\n",
      "    epoch          : 1212\n",
      "    loss           : 12245.659442527398\n",
      "    val_loss       : 12248.911803202249\n",
      "    val_log_likelihood: -12171.510976756357\n",
      "    val_log_marginal: -12179.426136255375\n",
      "Train Epoch: 1213 [256/118836 (0%)] Loss: 12290.867188\n",
      "Train Epoch: 1213 [33024/118836 (28%)] Loss: 12311.580078\n",
      "Train Epoch: 1213 [65792/118836 (55%)] Loss: 12278.753906\n",
      "Train Epoch: 1213 [98560/118836 (83%)] Loss: 12298.759766\n",
      "    epoch          : 1213\n",
      "    loss           : 12248.689633090364\n",
      "    val_loss       : 12250.40007883096\n",
      "    val_log_likelihood: -12171.927633406998\n",
      "    val_log_marginal: -12180.030531909006\n",
      "Train Epoch: 1214 [256/118836 (0%)] Loss: 12253.767578\n",
      "Train Epoch: 1214 [33024/118836 (28%)] Loss: 12293.572266\n",
      "Train Epoch: 1214 [65792/118836 (55%)] Loss: 12261.420898\n",
      "Train Epoch: 1214 [98560/118836 (83%)] Loss: 12223.642578\n",
      "    epoch          : 1214\n",
      "    loss           : 12248.667380389268\n",
      "    val_loss       : 12244.057354304954\n",
      "    val_log_likelihood: -12171.091887180779\n",
      "    val_log_marginal: -12179.392557668472\n",
      "Train Epoch: 1215 [256/118836 (0%)] Loss: 12305.662109\n",
      "Train Epoch: 1215 [33024/118836 (28%)] Loss: 12322.886719\n",
      "Train Epoch: 1215 [65792/118836 (55%)] Loss: 12233.314453\n",
      "Train Epoch: 1215 [98560/118836 (83%)] Loss: 12313.946289\n",
      "    epoch          : 1215\n",
      "    loss           : 12247.752541970378\n",
      "    val_loss       : 12247.93274593072\n",
      "    val_log_likelihood: -12172.85868647901\n",
      "    val_log_marginal: -12181.096953592607\n",
      "Train Epoch: 1216 [256/118836 (0%)] Loss: 12218.621094\n",
      "Train Epoch: 1216 [33024/118836 (28%)] Loss: 12432.473633\n",
      "Train Epoch: 1216 [65792/118836 (55%)] Loss: 12272.157227\n",
      "Train Epoch: 1216 [98560/118836 (83%)] Loss: 12340.679688\n",
      "    epoch          : 1216\n",
      "    loss           : 12247.157005886838\n",
      "    val_loss       : 12246.387536003478\n",
      "    val_log_likelihood: -12169.751536975291\n",
      "    val_log_marginal: -12177.747416843751\n",
      "Train Epoch: 1217 [256/118836 (0%)] Loss: 12275.009766\n",
      "Train Epoch: 1217 [33024/118836 (28%)] Loss: 12217.341797\n",
      "Train Epoch: 1217 [65792/118836 (55%)] Loss: 12264.996094\n",
      "Train Epoch: 1217 [98560/118836 (83%)] Loss: 12320.453125\n",
      "    epoch          : 1217\n",
      "    loss           : 12248.055986352358\n",
      "    val_loss       : 12246.406293997525\n",
      "    val_log_likelihood: -12171.779966010134\n",
      "    val_log_marginal: -12179.801763391619\n",
      "Train Epoch: 1218 [256/118836 (0%)] Loss: 12268.570312\n",
      "Train Epoch: 1218 [33024/118836 (28%)] Loss: 12282.367188\n",
      "Train Epoch: 1218 [65792/118836 (55%)] Loss: 12291.396484\n",
      "Train Epoch: 1218 [98560/118836 (83%)] Loss: 12294.530273\n",
      "    epoch          : 1218\n",
      "    loss           : 12245.747711822787\n",
      "    val_loss       : 12250.507788345985\n",
      "    val_log_likelihood: -12171.694296358042\n",
      "    val_log_marginal: -12179.870814441943\n",
      "Train Epoch: 1219 [256/118836 (0%)] Loss: 12230.835938\n",
      "Train Epoch: 1219 [33024/118836 (28%)] Loss: 12253.744141\n",
      "Train Epoch: 1219 [65792/118836 (55%)] Loss: 12262.771484\n",
      "Train Epoch: 1219 [98560/118836 (83%)] Loss: 12225.998047\n",
      "    epoch          : 1219\n",
      "    loss           : 12248.644573252688\n",
      "    val_loss       : 12249.422881665654\n",
      "    val_log_likelihood: -12169.887976407414\n",
      "    val_log_marginal: -12178.084058600525\n",
      "Train Epoch: 1220 [256/118836 (0%)] Loss: 12217.533203\n",
      "Train Epoch: 1220 [33024/118836 (28%)] Loss: 12201.148438\n",
      "Train Epoch: 1220 [65792/118836 (55%)] Loss: 12279.191406\n",
      "Train Epoch: 1220 [98560/118836 (83%)] Loss: 12233.649414\n",
      "    epoch          : 1220\n",
      "    loss           : 12250.201324700165\n",
      "    val_loss       : 12251.438324041155\n",
      "    val_log_likelihood: -12173.744846916357\n",
      "    val_log_marginal: -12182.287791372855\n",
      "Train Epoch: 1221 [256/118836 (0%)] Loss: 12217.126953\n",
      "Train Epoch: 1221 [33024/118836 (28%)] Loss: 12348.016602\n",
      "Train Epoch: 1221 [65792/118836 (55%)] Loss: 12294.084961\n",
      "Train Epoch: 1221 [98560/118836 (83%)] Loss: 12326.621094\n",
      "    epoch          : 1221\n",
      "    loss           : 12247.029369410411\n",
      "    val_loss       : 12246.64062341179\n",
      "    val_log_likelihood: -12168.826192553248\n",
      "    val_log_marginal: -12176.8603090954\n",
      "Train Epoch: 1222 [256/118836 (0%)] Loss: 12247.400391\n",
      "Train Epoch: 1222 [33024/118836 (28%)] Loss: 12236.957031\n",
      "Train Epoch: 1222 [65792/118836 (55%)] Loss: 12286.816406\n",
      "Train Epoch: 1222 [98560/118836 (83%)] Loss: 12209.642578\n",
      "    epoch          : 1222\n",
      "    loss           : 12248.134626369934\n",
      "    val_loss       : 12247.166520354202\n",
      "    val_log_likelihood: -12169.44902747622\n",
      "    val_log_marginal: -12177.395025336124\n",
      "Train Epoch: 1223 [256/118836 (0%)] Loss: 12279.271484\n",
      "Train Epoch: 1223 [33024/118836 (28%)] Loss: 12285.506836\n",
      "Train Epoch: 1223 [65792/118836 (55%)] Loss: 12292.440430\n",
      "Train Epoch: 1223 [98560/118836 (83%)] Loss: 12282.035156\n",
      "    epoch          : 1223\n",
      "    loss           : 12248.055269237231\n",
      "    val_loss       : 12247.926395131428\n",
      "    val_log_likelihood: -12171.46322890819\n",
      "    val_log_marginal: -12179.515292571505\n",
      "Train Epoch: 1224 [256/118836 (0%)] Loss: 12328.308594\n",
      "Train Epoch: 1224 [33024/118836 (28%)] Loss: 12196.399414\n",
      "Train Epoch: 1224 [65792/118836 (55%)] Loss: 12215.710938\n",
      "Train Epoch: 1224 [98560/118836 (83%)] Loss: 12265.468750\n",
      "    epoch          : 1224\n",
      "    loss           : 12246.574256229322\n",
      "    val_loss       : 12247.12122642871\n",
      "    val_log_likelihood: -12170.195447554797\n",
      "    val_log_marginal: -12178.305036297234\n",
      "Train Epoch: 1225 [256/118836 (0%)] Loss: 12332.275391\n",
      "Train Epoch: 1225 [33024/118836 (28%)] Loss: 12302.000977\n",
      "Train Epoch: 1225 [65792/118836 (55%)] Loss: 12355.534180\n",
      "Train Epoch: 1225 [98560/118836 (83%)] Loss: 12284.685547\n",
      "    epoch          : 1225\n",
      "    loss           : 12250.174620521868\n",
      "    val_loss       : 12246.409902198693\n",
      "    val_log_likelihood: -12169.119136586281\n",
      "    val_log_marginal: -12177.155737606783\n",
      "Train Epoch: 1226 [256/118836 (0%)] Loss: 12393.392578\n",
      "Train Epoch: 1226 [33024/118836 (28%)] Loss: 12225.000977\n",
      "Train Epoch: 1226 [65792/118836 (55%)] Loss: 12316.915039\n",
      "Train Epoch: 1226 [98560/118836 (83%)] Loss: 12228.059570\n",
      "    epoch          : 1226\n",
      "    loss           : 12247.459728145677\n",
      "    val_loss       : 12248.89152577438\n",
      "    val_log_likelihood: -12171.766198498242\n",
      "    val_log_marginal: -12179.771988862574\n",
      "Train Epoch: 1227 [256/118836 (0%)] Loss: 12222.570312\n",
      "Train Epoch: 1227 [33024/118836 (28%)] Loss: 12261.046875\n",
      "Train Epoch: 1227 [65792/118836 (55%)] Loss: 12214.283203\n",
      "Train Epoch: 1227 [98560/118836 (83%)] Loss: 12307.130859\n",
      "    epoch          : 1227\n",
      "    loss           : 12246.536686924886\n",
      "    val_loss       : 12247.965956820639\n",
      "    val_log_likelihood: -12170.139325501448\n",
      "    val_log_marginal: -12178.136116159276\n",
      "Train Epoch: 1228 [256/118836 (0%)] Loss: 12252.164062\n",
      "Train Epoch: 1228 [33024/118836 (28%)] Loss: 12319.982422\n",
      "Train Epoch: 1228 [65792/118836 (55%)] Loss: 12225.161133\n",
      "Train Epoch: 1228 [98560/118836 (83%)] Loss: 12209.381836\n",
      "    epoch          : 1228\n",
      "    loss           : 12247.883714265405\n",
      "    val_loss       : 12245.046273822472\n",
      "    val_log_likelihood: -12170.511945564516\n",
      "    val_log_marginal: -12178.583294897138\n",
      "Train Epoch: 1229 [256/118836 (0%)] Loss: 12246.882812\n",
      "Train Epoch: 1229 [33024/118836 (28%)] Loss: 12220.664062\n",
      "Train Epoch: 1229 [65792/118836 (55%)] Loss: 12378.453125\n",
      "Train Epoch: 1229 [98560/118836 (83%)] Loss: 12253.364258\n",
      "    epoch          : 1229\n",
      "    loss           : 12248.450763318082\n",
      "    val_loss       : 12247.160913359525\n",
      "    val_log_likelihood: -12170.743442734181\n",
      "    val_log_marginal: -12178.821786077673\n",
      "Train Epoch: 1230 [256/118836 (0%)] Loss: 12322.878906\n",
      "Train Epoch: 1230 [33024/118836 (28%)] Loss: 12259.536133\n",
      "Train Epoch: 1230 [65792/118836 (55%)] Loss: 12364.535156\n",
      "Train Epoch: 1230 [98560/118836 (83%)] Loss: 12276.514648\n",
      "    epoch          : 1230\n",
      "    loss           : 12251.85062874793\n",
      "    val_loss       : 12258.124091459322\n",
      "    val_log_likelihood: -12172.454668275694\n",
      "    val_log_marginal: -12180.749918056545\n",
      "Train Epoch: 1231 [256/118836 (0%)] Loss: 12264.862305\n",
      "Train Epoch: 1231 [33024/118836 (28%)] Loss: 12297.220703\n",
      "Train Epoch: 1231 [65792/118836 (55%)] Loss: 12291.670898\n",
      "Train Epoch: 1231 [98560/118836 (83%)] Loss: 12234.049805\n",
      "    epoch          : 1231\n",
      "    loss           : 12248.960569976478\n",
      "    val_loss       : 12245.646149517619\n",
      "    val_log_likelihood: -12169.294194097653\n",
      "    val_log_marginal: -12177.330323807115\n",
      "Train Epoch: 1232 [256/118836 (0%)] Loss: 12306.620117\n",
      "Train Epoch: 1232 [33024/118836 (28%)] Loss: 12160.759766\n",
      "Train Epoch: 1232 [65792/118836 (55%)] Loss: 12271.052734\n",
      "Train Epoch: 1232 [98560/118836 (83%)] Loss: 12226.747070\n",
      "    epoch          : 1232\n",
      "    loss           : 12247.83716720947\n",
      "    val_loss       : 12246.299651550265\n",
      "    val_log_likelihood: -12171.818983761115\n",
      "    val_log_marginal: -12179.902018826384\n",
      "Train Epoch: 1233 [256/118836 (0%)] Loss: 12329.256836\n",
      "Train Epoch: 1233 [33024/118836 (28%)] Loss: 12197.418945\n",
      "Train Epoch: 1233 [65792/118836 (55%)] Loss: 12249.492188\n",
      "Train Epoch: 1233 [98560/118836 (83%)] Loss: 12241.129883\n",
      "    epoch          : 1233\n",
      "    loss           : 12246.955452110475\n",
      "    val_loss       : 12250.362742929692\n",
      "    val_log_likelihood: -12172.152433086487\n",
      "    val_log_marginal: -12180.303404936936\n",
      "Train Epoch: 1234 [256/118836 (0%)] Loss: 12262.585938\n",
      "Train Epoch: 1234 [33024/118836 (28%)] Loss: 12240.387695\n",
      "Train Epoch: 1234 [65792/118836 (55%)] Loss: 12179.177734\n",
      "Train Epoch: 1234 [98560/118836 (83%)] Loss: 12254.592773\n",
      "    epoch          : 1234\n",
      "    loss           : 12253.429826431968\n",
      "    val_loss       : 12247.70926283563\n",
      "    val_log_likelihood: -12170.251546991316\n",
      "    val_log_marginal: -12178.3921480502\n",
      "Train Epoch: 1235 [256/118836 (0%)] Loss: 12231.510742\n",
      "Train Epoch: 1235 [33024/118836 (28%)] Loss: 12296.840820\n",
      "Train Epoch: 1235 [65792/118836 (55%)] Loss: 12329.015625\n",
      "Train Epoch: 1235 [98560/118836 (83%)] Loss: 12262.488281\n",
      "    epoch          : 1235\n",
      "    loss           : 12245.639162821806\n",
      "    val_loss       : 12241.451820055134\n",
      "    val_log_likelihood: -12172.19756206705\n",
      "    val_log_marginal: -12180.276264483624\n",
      "Train Epoch: 1236 [256/118836 (0%)] Loss: 12280.094727\n",
      "Train Epoch: 1236 [33024/118836 (28%)] Loss: 12280.065430\n",
      "Train Epoch: 1236 [65792/118836 (55%)] Loss: 12211.871094\n",
      "Train Epoch: 1236 [98560/118836 (83%)] Loss: 12199.318359\n",
      "    epoch          : 1236\n",
      "    loss           : 12250.257840124845\n",
      "    val_loss       : 12258.23008955445\n",
      "    val_log_likelihood: -12172.91958116858\n",
      "    val_log_marginal: -12180.92691081031\n",
      "Train Epoch: 1237 [256/118836 (0%)] Loss: 12231.557617\n",
      "Train Epoch: 1237 [33024/118836 (28%)] Loss: 12253.463867\n",
      "Train Epoch: 1237 [65792/118836 (55%)] Loss: 12308.572266\n",
      "Train Epoch: 1237 [98560/118836 (83%)] Loss: 12269.931641\n",
      "    epoch          : 1237\n",
      "    loss           : 12248.225624386116\n",
      "    val_loss       : 12264.163518720605\n",
      "    val_log_likelihood: -12172.14095359026\n",
      "    val_log_marginal: -12180.403741925695\n",
      "Train Epoch: 1238 [256/118836 (0%)] Loss: 12315.047852\n",
      "Train Epoch: 1238 [33024/118836 (28%)] Loss: 12254.797852\n",
      "Train Epoch: 1238 [65792/118836 (55%)] Loss: 12363.389648\n",
      "Train Epoch: 1238 [98560/118836 (83%)] Loss: 12203.754883\n",
      "    epoch          : 1238\n",
      "    loss           : 12248.10936708411\n",
      "    val_loss       : 12247.691756243881\n",
      "    val_log_likelihood: -12169.228613846672\n",
      "    val_log_marginal: -12177.47246598572\n",
      "Train Epoch: 1239 [256/118836 (0%)] Loss: 12300.593750\n",
      "Train Epoch: 1239 [33024/118836 (28%)] Loss: 12262.201172\n",
      "Train Epoch: 1239 [65792/118836 (55%)] Loss: 12240.074219\n",
      "Train Epoch: 1239 [98560/118836 (83%)] Loss: 12282.263672\n",
      "    epoch          : 1239\n",
      "    loss           : 12247.908325417442\n",
      "    val_loss       : 12245.985529619076\n",
      "    val_log_likelihood: -12172.638480439671\n",
      "    val_log_marginal: -12180.627944507734\n",
      "Train Epoch: 1240 [256/118836 (0%)] Loss: 12285.183594\n",
      "Train Epoch: 1240 [33024/118836 (28%)] Loss: 12313.912109\n",
      "Train Epoch: 1240 [65792/118836 (55%)] Loss: 12290.232422\n",
      "Train Epoch: 1240 [98560/118836 (83%)] Loss: 12222.297852\n",
      "    epoch          : 1240\n",
      "    loss           : 12244.518996361921\n",
      "    val_loss       : 12249.27845005992\n",
      "    val_log_likelihood: -12170.678985893559\n",
      "    val_log_marginal: -12178.710799206468\n",
      "Train Epoch: 1241 [256/118836 (0%)] Loss: 12359.497070\n",
      "Train Epoch: 1241 [33024/118836 (28%)] Loss: 12248.509766\n",
      "Train Epoch: 1241 [65792/118836 (55%)] Loss: 12307.117188\n",
      "Train Epoch: 1241 [98560/118836 (83%)] Loss: 12330.493164\n",
      "    epoch          : 1241\n",
      "    loss           : 12242.30186023444\n",
      "    val_loss       : 12248.760549002573\n",
      "    val_log_likelihood: -12175.88307130118\n",
      "    val_log_marginal: -12183.887150798535\n",
      "Train Epoch: 1242 [256/118836 (0%)] Loss: 12318.888672\n",
      "Train Epoch: 1242 [33024/118836 (28%)] Loss: 12207.465820\n",
      "Train Epoch: 1242 [65792/118836 (55%)] Loss: 12330.984375\n",
      "Train Epoch: 1242 [98560/118836 (83%)] Loss: 12289.105469\n",
      "    epoch          : 1242\n",
      "    loss           : 12247.16921719913\n",
      "    val_loss       : 12246.453573381734\n",
      "    val_log_likelihood: -12168.225169787791\n",
      "    val_log_marginal: -12176.183011346271\n",
      "Train Epoch: 1243 [256/118836 (0%)] Loss: 12310.727539\n",
      "Train Epoch: 1243 [33024/118836 (28%)] Loss: 12239.193359\n",
      "Train Epoch: 1243 [65792/118836 (55%)] Loss: 12318.499023\n",
      "Train Epoch: 1243 [98560/118836 (83%)] Loss: 12297.706055\n",
      "    epoch          : 1243\n",
      "    loss           : 12245.613737625363\n",
      "    val_loss       : 12245.439760037849\n",
      "    val_log_likelihood: -12171.90572868202\n",
      "    val_log_marginal: -12179.732459868335\n",
      "Train Epoch: 1244 [256/118836 (0%)] Loss: 12203.898438\n",
      "Train Epoch: 1244 [33024/118836 (28%)] Loss: 12387.777344\n",
      "Train Epoch: 1244 [65792/118836 (55%)] Loss: 12231.920898\n",
      "Train Epoch: 1244 [98560/118836 (83%)] Loss: 12204.009766\n",
      "    epoch          : 1244\n",
      "    loss           : 12245.17441810122\n",
      "    val_loss       : 12251.222813837441\n",
      "    val_log_likelihood: -12170.545361287737\n",
      "    val_log_marginal: -12178.450678029567\n",
      "Train Epoch: 1245 [256/118836 (0%)] Loss: 12221.381836\n",
      "Train Epoch: 1245 [33024/118836 (28%)] Loss: 12155.399414\n",
      "Train Epoch: 1245 [65792/118836 (55%)] Loss: 12192.105469\n",
      "Train Epoch: 1245 [98560/118836 (83%)] Loss: 12298.769531\n",
      "    epoch          : 1245\n",
      "    loss           : 12250.084033970483\n",
      "    val_loss       : 12248.813846346471\n",
      "    val_log_likelihood: -12170.423754135649\n",
      "    val_log_marginal: -12178.566857815345\n",
      "Train Epoch: 1246 [256/118836 (0%)] Loss: 12255.780273\n",
      "Train Epoch: 1246 [33024/118836 (28%)] Loss: 12206.314453\n",
      "Train Epoch: 1246 [65792/118836 (55%)] Loss: 12254.403320\n",
      "Train Epoch: 1246 [98560/118836 (83%)] Loss: 12238.944336\n",
      "    epoch          : 1246\n",
      "    loss           : 12246.217906553711\n",
      "    val_loss       : 12249.150199864032\n",
      "    val_log_likelihood: -12171.198762374637\n",
      "    val_log_marginal: -12179.300902874083\n",
      "Train Epoch: 1247 [256/118836 (0%)] Loss: 12189.421875\n",
      "Train Epoch: 1247 [33024/118836 (28%)] Loss: 12266.223633\n",
      "Train Epoch: 1247 [65792/118836 (55%)] Loss: 12342.158203\n",
      "Train Epoch: 1247 [98560/118836 (83%)] Loss: 12284.540039\n",
      "    epoch          : 1247\n",
      "    loss           : 12250.607582939154\n",
      "    val_loss       : 12246.95674557671\n",
      "    val_log_likelihood: -12171.594245954817\n",
      "    val_log_marginal: -12179.593339265892\n",
      "Train Epoch: 1248 [256/118836 (0%)] Loss: 12330.524414\n",
      "Train Epoch: 1248 [33024/118836 (28%)] Loss: 12275.771484\n",
      "Train Epoch: 1248 [65792/118836 (55%)] Loss: 12278.936523\n",
      "Train Epoch: 1248 [98560/118836 (83%)] Loss: 12233.988281\n",
      "    epoch          : 1248\n",
      "    loss           : 12248.65140240514\n",
      "    val_loss       : 12247.916436945301\n",
      "    val_log_likelihood: -12169.97345753205\n",
      "    val_log_marginal: -12178.172061716174\n",
      "Train Epoch: 1249 [256/118836 (0%)] Loss: 12267.760742\n",
      "Train Epoch: 1249 [33024/118836 (28%)] Loss: 12236.748047\n",
      "Train Epoch: 1249 [65792/118836 (55%)] Loss: 12258.132812\n",
      "Train Epoch: 1249 [98560/118836 (83%)] Loss: 12314.968750\n",
      "    epoch          : 1249\n",
      "    loss           : 12250.855540316119\n",
      "    val_loss       : 12249.113098144668\n",
      "    val_log_likelihood: -12168.651237625363\n",
      "    val_log_marginal: -12176.722182582389\n",
      "Train Epoch: 1250 [256/118836 (0%)] Loss: 12277.448242\n",
      "Train Epoch: 1250 [33024/118836 (28%)] Loss: 12259.985352\n",
      "Train Epoch: 1250 [65792/118836 (55%)] Loss: 12388.035156\n",
      "Train Epoch: 1250 [98560/118836 (83%)] Loss: 12246.508789\n",
      "    epoch          : 1250\n",
      "    loss           : 12245.686999521815\n",
      "    val_loss       : 12242.80047758893\n",
      "    val_log_likelihood: -12169.241613194014\n",
      "    val_log_marginal: -12177.214367312952\n",
      "Train Epoch: 1251 [256/118836 (0%)] Loss: 12217.632812\n",
      "Train Epoch: 1251 [33024/118836 (28%)] Loss: 12257.926758\n",
      "Train Epoch: 1251 [65792/118836 (55%)] Loss: 12206.342773\n",
      "Train Epoch: 1251 [98560/118836 (83%)] Loss: 12284.968750\n",
      "    epoch          : 1251\n",
      "    loss           : 12244.951194653382\n",
      "    val_loss       : 12248.799504600503\n",
      "    val_log_likelihood: -12173.877841158757\n",
      "    val_log_marginal: -12182.01270922655\n",
      "Train Epoch: 1252 [256/118836 (0%)] Loss: 12254.234375\n",
      "Train Epoch: 1252 [33024/118836 (28%)] Loss: 12204.974609\n",
      "Train Epoch: 1252 [65792/118836 (55%)] Loss: 12223.589844\n",
      "Train Epoch: 1252 [98560/118836 (83%)] Loss: 12233.192383\n",
      "    epoch          : 1252\n",
      "    loss           : 12248.22262394024\n",
      "    val_loss       : 12249.082387595503\n",
      "    val_log_likelihood: -12171.251933092948\n",
      "    val_log_marginal: -12179.55783467173\n",
      "Train Epoch: 1253 [256/118836 (0%)] Loss: 12245.395508\n",
      "Train Epoch: 1253 [33024/118836 (28%)] Loss: 12316.892578\n",
      "Train Epoch: 1253 [65792/118836 (55%)] Loss: 12327.003906\n",
      "Train Epoch: 1253 [98560/118836 (83%)] Loss: 12344.385742\n",
      "    epoch          : 1253\n",
      "    loss           : 12249.052779124018\n",
      "    val_loss       : 12245.826638396466\n",
      "    val_log_likelihood: -12173.060581446443\n",
      "    val_log_marginal: -12181.170387682998\n",
      "Train Epoch: 1254 [256/118836 (0%)] Loss: 12145.351562\n",
      "Train Epoch: 1254 [33024/118836 (28%)] Loss: 12281.388672\n",
      "Train Epoch: 1254 [65792/118836 (55%)] Loss: 12365.317383\n",
      "Train Epoch: 1254 [98560/118836 (83%)] Loss: 12276.264648\n",
      "    epoch          : 1254\n",
      "    loss           : 12248.082391826923\n",
      "    val_loss       : 12245.265723306342\n",
      "    val_log_likelihood: -12172.322136062863\n",
      "    val_log_marginal: -12180.285115402367\n",
      "Train Epoch: 1255 [256/118836 (0%)] Loss: 12283.023438\n",
      "Train Epoch: 1255 [33024/118836 (28%)] Loss: 12209.402344\n",
      "Train Epoch: 1255 [65792/118836 (55%)] Loss: 12242.000000\n",
      "Train Epoch: 1255 [98560/118836 (83%)] Loss: 12268.885742\n",
      "    epoch          : 1255\n",
      "    loss           : 12252.6828462637\n",
      "    val_loss       : 12243.241634656699\n",
      "    val_log_likelihood: -12172.687121006515\n",
      "    val_log_marginal: -12180.918448593531\n",
      "Train Epoch: 1256 [256/118836 (0%)] Loss: 12207.644531\n",
      "Train Epoch: 1256 [33024/118836 (28%)] Loss: 12265.275391\n",
      "Train Epoch: 1256 [65792/118836 (55%)] Loss: 12210.955078\n",
      "Train Epoch: 1256 [98560/118836 (83%)] Loss: 12229.378906\n",
      "    epoch          : 1256\n",
      "    loss           : 12245.892859543012\n",
      "    val_loss       : 12251.165874971433\n",
      "    val_log_likelihood: -12172.712878670389\n",
      "    val_log_marginal: -12181.13582161959\n",
      "Train Epoch: 1257 [256/118836 (0%)] Loss: 12228.968750\n",
      "Train Epoch: 1257 [33024/118836 (28%)] Loss: 12295.450195\n",
      "Train Epoch: 1257 [65792/118836 (55%)] Loss: 12258.765625\n",
      "Train Epoch: 1257 [98560/118836 (83%)] Loss: 12239.049805\n",
      "    epoch          : 1257\n",
      "    loss           : 12248.44946381953\n",
      "    val_loss       : 12246.549004203265\n",
      "    val_log_likelihood: -12171.024859775642\n",
      "    val_log_marginal: -12179.278305835227\n",
      "Train Epoch: 1258 [256/118836 (0%)] Loss: 12359.032227\n",
      "Train Epoch: 1258 [33024/118836 (28%)] Loss: 12233.793945\n",
      "Train Epoch: 1258 [65792/118836 (55%)] Loss: 12344.111328\n",
      "Train Epoch: 1258 [98560/118836 (83%)] Loss: 12265.269531\n",
      "    epoch          : 1258\n",
      "    loss           : 12247.831199112128\n",
      "    val_loss       : 12244.77303255423\n",
      "    val_log_likelihood: -12171.897664812088\n",
      "    val_log_marginal: -12179.973014818639\n",
      "Train Epoch: 1259 [256/118836 (0%)] Loss: 12339.391602\n",
      "Train Epoch: 1259 [33024/118836 (28%)] Loss: 12296.164062\n",
      "Train Epoch: 1259 [65792/118836 (55%)] Loss: 12260.640625\n",
      "Train Epoch: 1259 [98560/118836 (83%)] Loss: 12299.959961\n",
      "    epoch          : 1259\n",
      "    loss           : 12248.904601879136\n",
      "    val_loss       : 12247.883956190171\n",
      "    val_log_likelihood: -12171.692213670905\n",
      "    val_log_marginal: -12179.806824895162\n",
      "Train Epoch: 1260 [256/118836 (0%)] Loss: 12265.726562\n",
      "Train Epoch: 1260 [33024/118836 (28%)] Loss: 12243.359375\n",
      "Train Epoch: 1260 [65792/118836 (55%)] Loss: 12283.496094\n",
      "Train Epoch: 1260 [98560/118836 (83%)] Loss: 12230.874023\n",
      "    epoch          : 1260\n",
      "    loss           : 12247.645604257134\n",
      "    val_loss       : 12248.837056746255\n",
      "    val_log_likelihood: -12169.670514759098\n",
      "    val_log_marginal: -12177.72474930386\n",
      "Train Epoch: 1261 [256/118836 (0%)] Loss: 12276.068359\n",
      "Train Epoch: 1261 [33024/118836 (28%)] Loss: 12328.589844\n",
      "Train Epoch: 1261 [65792/118836 (55%)] Loss: 12242.630859\n",
      "Train Epoch: 1261 [98560/118836 (83%)] Loss: 12257.238281\n",
      "    epoch          : 1261\n",
      "    loss           : 12246.067260843154\n",
      "    val_loss       : 12245.332501547378\n",
      "    val_log_likelihood: -12170.419920421062\n",
      "    val_log_marginal: -12178.386666751301\n",
      "Train Epoch: 1262 [256/118836 (0%)] Loss: 12204.921875\n",
      "Train Epoch: 1262 [33024/118836 (28%)] Loss: 12185.349609\n",
      "Train Epoch: 1262 [65792/118836 (55%)] Loss: 12218.507812\n",
      "Train Epoch: 1262 [98560/118836 (83%)] Loss: 12225.740234\n",
      "    epoch          : 1262\n",
      "    loss           : 12245.462027631307\n",
      "    val_loss       : 12246.623937171162\n",
      "    val_log_likelihood: -12170.182477609336\n",
      "    val_log_marginal: -12178.210956799792\n",
      "Train Epoch: 1263 [256/118836 (0%)] Loss: 12246.724609\n",
      "Train Epoch: 1263 [33024/118836 (28%)] Loss: 12220.539062\n",
      "Train Epoch: 1263 [65792/118836 (55%)] Loss: 12250.849609\n",
      "Train Epoch: 1263 [98560/118836 (83%)] Loss: 12297.240234\n",
      "    epoch          : 1263\n",
      "    loss           : 12250.290880570203\n",
      "    val_loss       : 12245.51464100087\n",
      "    val_log_likelihood: -12173.070433500052\n",
      "    val_log_marginal: -12181.558147943746\n",
      "Train Epoch: 1264 [256/118836 (0%)] Loss: 12220.000000\n",
      "Train Epoch: 1264 [33024/118836 (28%)] Loss: 12344.825195\n",
      "Train Epoch: 1264 [65792/118836 (55%)] Loss: 12213.902344\n",
      "Train Epoch: 1264 [98560/118836 (83%)] Loss: 12248.919922\n",
      "    epoch          : 1264\n",
      "    loss           : 12242.24119187474\n",
      "    val_loss       : 12246.103775830814\n",
      "    val_log_likelihood: -12168.697425558312\n",
      "    val_log_marginal: -12176.611077893556\n",
      "Train Epoch: 1265 [256/118836 (0%)] Loss: 12303.000000\n",
      "Train Epoch: 1265 [33024/118836 (28%)] Loss: 12296.380859\n",
      "Train Epoch: 1265 [65792/118836 (55%)] Loss: 12301.195312\n",
      "Train Epoch: 1265 [98560/118836 (83%)] Loss: 12152.314453\n",
      "    epoch          : 1265\n",
      "    loss           : 12248.172613601117\n",
      "    val_loss       : 12244.922338424\n",
      "    val_log_likelihood: -12170.757430113988\n",
      "    val_log_marginal: -12178.983241052096\n",
      "Train Epoch: 1266 [256/118836 (0%)] Loss: 12208.644531\n",
      "Train Epoch: 1266 [33024/118836 (28%)] Loss: 12226.022461\n",
      "Train Epoch: 1266 [65792/118836 (55%)] Loss: 12215.407227\n",
      "Train Epoch: 1266 [98560/118836 (83%)] Loss: 12290.149414\n",
      "    epoch          : 1266\n",
      "    loss           : 12247.956339982682\n",
      "    val_loss       : 12247.91043983198\n",
      "    val_log_likelihood: -12169.38583669355\n",
      "    val_log_marginal: -12177.487489827254\n",
      "Train Epoch: 1267 [256/118836 (0%)] Loss: 12303.857422\n",
      "Train Epoch: 1267 [33024/118836 (28%)] Loss: 12223.473633\n",
      "Train Epoch: 1267 [65792/118836 (55%)] Loss: 12181.412109\n",
      "Train Epoch: 1267 [98560/118836 (83%)] Loss: 12240.409180\n",
      "    epoch          : 1267\n",
      "    loss           : 12244.950462514216\n",
      "    val_loss       : 12245.647034972704\n",
      "    val_log_likelihood: -12171.64911228934\n",
      "    val_log_marginal: -12179.6184774446\n",
      "Train Epoch: 1268 [256/118836 (0%)] Loss: 12230.408203\n",
      "Train Epoch: 1268 [33024/118836 (28%)] Loss: 12186.631836\n",
      "Train Epoch: 1268 [65792/118836 (55%)] Loss: 12394.373047\n",
      "Train Epoch: 1268 [98560/118836 (83%)] Loss: 12285.775391\n",
      "    epoch          : 1268\n",
      "    loss           : 12250.86579058752\n",
      "    val_loss       : 12247.76629950171\n",
      "    val_log_likelihood: -12171.44429264242\n",
      "    val_log_marginal: -12179.435398813628\n",
      "Train Epoch: 1269 [256/118836 (0%)] Loss: 12272.649414\n",
      "Train Epoch: 1269 [33024/118836 (28%)] Loss: 12225.114258\n",
      "Train Epoch: 1269 [65792/118836 (55%)] Loss: 12262.057617\n",
      "Train Epoch: 1269 [98560/118836 (83%)] Loss: 12227.917969\n",
      "    epoch          : 1269\n",
      "    loss           : 12251.712761062863\n",
      "    val_loss       : 12246.391315237854\n",
      "    val_log_likelihood: -12170.505823026519\n",
      "    val_log_marginal: -12178.448785648705\n",
      "Train Epoch: 1270 [256/118836 (0%)] Loss: 12350.215820\n",
      "Train Epoch: 1270 [33024/118836 (28%)] Loss: 12244.292969\n",
      "Train Epoch: 1270 [65792/118836 (55%)] Loss: 12213.765625\n",
      "Train Epoch: 1270 [98560/118836 (83%)] Loss: 12316.000000\n",
      "    epoch          : 1270\n",
      "    loss           : 12249.804836286447\n",
      "    val_loss       : 12251.736153851562\n",
      "    val_log_likelihood: -12172.968828997364\n",
      "    val_log_marginal: -12181.008334038415\n",
      "Train Epoch: 1271 [256/118836 (0%)] Loss: 12298.708008\n",
      "Train Epoch: 1271 [33024/118836 (28%)] Loss: 12237.408203\n",
      "Train Epoch: 1271 [65792/118836 (55%)] Loss: 12293.012695\n",
      "Train Epoch: 1271 [98560/118836 (83%)] Loss: 12218.600586\n",
      "    epoch          : 1271\n",
      "    loss           : 12249.744245954817\n",
      "    val_loss       : 12249.491824482724\n",
      "    val_log_likelihood: -12170.169326083023\n",
      "    val_log_marginal: -12178.292460036744\n",
      "Train Epoch: 1272 [256/118836 (0%)] Loss: 12182.146484\n",
      "Train Epoch: 1272 [33024/118836 (28%)] Loss: 12214.291992\n",
      "Train Epoch: 1272 [65792/118836 (55%)] Loss: 12337.550781\n",
      "Train Epoch: 1272 [98560/118836 (83%)] Loss: 12323.099609\n",
      "    epoch          : 1272\n",
      "    loss           : 12250.275601284637\n",
      "    val_loss       : 12245.122025195511\n",
      "    val_log_likelihood: -12171.267744358714\n",
      "    val_log_marginal: -12179.607913226693\n",
      "Train Epoch: 1273 [256/118836 (0%)] Loss: 12305.892578\n",
      "Train Epoch: 1273 [33024/118836 (28%)] Loss: 12288.610352\n",
      "Train Epoch: 1273 [65792/118836 (55%)] Loss: 12239.857422\n",
      "Train Epoch: 1273 [98560/118836 (83%)] Loss: 12374.394531\n",
      "    epoch          : 1273\n",
      "    loss           : 12246.244950630686\n",
      "    val_loss       : 12246.485530697786\n",
      "    val_log_likelihood: -12170.82438546836\n",
      "    val_log_marginal: -12178.85567095092\n",
      "Train Epoch: 1274 [256/118836 (0%)] Loss: 12216.116211\n",
      "Train Epoch: 1274 [33024/118836 (28%)] Loss: 12277.679688\n",
      "Train Epoch: 1274 [65792/118836 (55%)] Loss: 12179.647461\n",
      "Train Epoch: 1274 [98560/118836 (83%)] Loss: 12312.327148\n",
      "    epoch          : 1274\n",
      "    loss           : 12248.770379865851\n",
      "    val_loss       : 12249.84470651089\n",
      "    val_log_likelihood: -12172.788018894747\n",
      "    val_log_marginal: -12181.231124327564\n",
      "Train Epoch: 1275 [256/118836 (0%)] Loss: 12164.474609\n",
      "Train Epoch: 1275 [33024/118836 (28%)] Loss: 12247.125977\n",
      "Train Epoch: 1275 [65792/118836 (55%)] Loss: 12199.476562\n",
      "Train Epoch: 1275 [98560/118836 (83%)] Loss: 12271.877930\n",
      "    epoch          : 1275\n",
      "    loss           : 12249.227079940807\n",
      "    val_loss       : 12245.217961795419\n",
      "    val_log_likelihood: -12171.658473557693\n",
      "    val_log_marginal: -12179.765066386908\n",
      "Train Epoch: 1276 [256/118836 (0%)] Loss: 12258.500000\n",
      "Train Epoch: 1276 [33024/118836 (28%)] Loss: 12238.195312\n",
      "Train Epoch: 1276 [65792/118836 (55%)] Loss: 12258.299805\n",
      "Train Epoch: 1276 [98560/118836 (83%)] Loss: 12311.253906\n",
      "    epoch          : 1276\n",
      "    loss           : 12248.084975315343\n",
      "    val_loss       : 12248.928501906708\n",
      "    val_log_likelihood: -12168.172467884098\n",
      "    val_log_marginal: -12176.083247495046\n",
      "Train Epoch: 1277 [256/118836 (0%)] Loss: 12277.664062\n",
      "Train Epoch: 1277 [33024/118836 (28%)] Loss: 12206.135742\n",
      "Train Epoch: 1277 [65792/118836 (55%)] Loss: 12328.400391\n",
      "Train Epoch: 1277 [98560/118836 (83%)] Loss: 12304.550781\n",
      "    epoch          : 1277\n",
      "    loss           : 12244.538496917648\n",
      "    val_loss       : 12250.20205467884\n",
      "    val_log_likelihood: -12171.02097662712\n",
      "    val_log_marginal: -12179.27753994768\n",
      "Train Epoch: 1278 [256/118836 (0%)] Loss: 12313.984375\n",
      "Train Epoch: 1278 [33024/118836 (28%)] Loss: 12269.117188\n",
      "Train Epoch: 1278 [65792/118836 (55%)] Loss: 12298.138672\n",
      "Train Epoch: 1278 [98560/118836 (83%)] Loss: 12295.564453\n",
      "    epoch          : 1278\n",
      "    loss           : 12248.382668398468\n",
      "    val_loss       : 12246.060666065125\n",
      "    val_log_likelihood: -12174.425353468776\n",
      "    val_log_marginal: -12182.808602783973\n",
      "Train Epoch: 1279 [256/118836 (0%)] Loss: 12299.821289\n",
      "Train Epoch: 1279 [33024/118836 (28%)] Loss: 12373.637695\n",
      "Train Epoch: 1279 [65792/118836 (55%)] Loss: 12346.252930\n",
      "Train Epoch: 1279 [98560/118836 (83%)] Loss: 12262.527344\n",
      "    epoch          : 1279\n",
      "    loss           : 12249.85346441403\n",
      "    val_loss       : 12246.131793382137\n",
      "    val_log_likelihood: -12172.524493867608\n",
      "    val_log_marginal: -12180.81138562487\n",
      "Train Epoch: 1280 [256/118836 (0%)] Loss: 12304.621094\n",
      "Train Epoch: 1280 [33024/118836 (28%)] Loss: 12268.276367\n",
      "Train Epoch: 1280 [65792/118836 (55%)] Loss: 12384.113281\n",
      "Train Epoch: 1280 [98560/118836 (83%)] Loss: 12192.436523\n",
      "    epoch          : 1280\n",
      "    loss           : 12245.866990572013\n",
      "    val_loss       : 12250.436421978471\n",
      "    val_log_likelihood: -12170.01497686621\n",
      "    val_log_marginal: -12177.991960009615\n",
      "Train Epoch: 1281 [256/118836 (0%)] Loss: 12182.632812\n",
      "Train Epoch: 1281 [33024/118836 (28%)] Loss: 12315.984375\n",
      "Train Epoch: 1281 [65792/118836 (55%)] Loss: 12306.816406\n",
      "Train Epoch: 1281 [98560/118836 (83%)] Loss: 12365.272461\n",
      "    epoch          : 1281\n",
      "    loss           : 12248.795727357321\n",
      "    val_loss       : 12244.863520163315\n",
      "    val_log_likelihood: -12174.461047191635\n",
      "    val_log_marginal: -12182.585102165785\n",
      "Train Epoch: 1282 [256/118836 (0%)] Loss: 12343.927734\n",
      "Train Epoch: 1282 [33024/118836 (28%)] Loss: 12440.417969\n",
      "Train Epoch: 1282 [65792/118836 (55%)] Loss: 12245.158203\n",
      "Train Epoch: 1282 [98560/118836 (83%)] Loss: 12335.783203\n",
      "    epoch          : 1282\n",
      "    loss           : 12249.673070299576\n",
      "    val_loss       : 12250.10720324065\n",
      "    val_log_likelihood: -12169.787204204145\n",
      "    val_log_marginal: -12177.997475480757\n",
      "Train Epoch: 1283 [256/118836 (0%)] Loss: 12261.643555\n",
      "Train Epoch: 1283 [33024/118836 (28%)] Loss: 12280.561523\n",
      "Train Epoch: 1283 [65792/118836 (55%)] Loss: 12267.549805\n",
      "Train Epoch: 1283 [98560/118836 (83%)] Loss: 12170.498047\n",
      "    epoch          : 1283\n",
      "    loss           : 12248.1656922043\n",
      "    val_loss       : 12247.486183879077\n",
      "    val_log_likelihood: -12168.824448149297\n",
      "    val_log_marginal: -12177.070050273052\n",
      "Train Epoch: 1284 [256/118836 (0%)] Loss: 12190.002930\n",
      "Train Epoch: 1284 [33024/118836 (28%)] Loss: 12300.071289\n",
      "Train Epoch: 1284 [65792/118836 (55%)] Loss: 12304.903320\n",
      "Train Epoch: 1284 [98560/118836 (83%)] Loss: 12222.519531\n",
      "    epoch          : 1284\n",
      "    loss           : 12247.73831646764\n",
      "    val_loss       : 12251.308115716645\n",
      "    val_log_likelihood: -12170.925955561155\n",
      "    val_log_marginal: -12179.104419085254\n",
      "Train Epoch: 1285 [256/118836 (0%)] Loss: 12279.240234\n",
      "Train Epoch: 1285 [33024/118836 (28%)] Loss: 12342.488281\n",
      "Train Epoch: 1285 [65792/118836 (55%)] Loss: 12266.756836\n",
      "Train Epoch: 1285 [98560/118836 (83%)] Loss: 12228.890625\n",
      "    epoch          : 1285\n",
      "    loss           : 12247.744373739919\n",
      "    val_loss       : 12245.391936111659\n",
      "    val_log_likelihood: -12170.900771072425\n",
      "    val_log_marginal: -12179.026498135116\n",
      "Train Epoch: 1286 [256/118836 (0%)] Loss: 12352.368164\n",
      "Train Epoch: 1286 [33024/118836 (28%)] Loss: 12306.511719\n",
      "Train Epoch: 1286 [65792/118836 (55%)] Loss: 12251.771484\n",
      "Train Epoch: 1286 [98560/118836 (83%)] Loss: 12226.835938\n",
      "    epoch          : 1286\n",
      "    loss           : 12243.0863751357\n",
      "    val_loss       : 12245.99401435791\n",
      "    val_log_likelihood: -12173.452232927522\n",
      "    val_log_marginal: -12181.410385970974\n",
      "Train Epoch: 1287 [256/118836 (0%)] Loss: 12305.176758\n",
      "Train Epoch: 1287 [33024/118836 (28%)] Loss: 12222.887695\n",
      "Train Epoch: 1287 [65792/118836 (55%)] Loss: 12401.762695\n",
      "Train Epoch: 1287 [98560/118836 (83%)] Loss: 12330.872070\n",
      "    epoch          : 1287\n",
      "    loss           : 12246.218820758375\n",
      "    val_loss       : 12247.095117381517\n",
      "    val_log_likelihood: -12168.937795472755\n",
      "    val_log_marginal: -12176.905119487132\n",
      "Train Epoch: 1288 [256/118836 (0%)] Loss: 12346.031250\n",
      "Train Epoch: 1288 [33024/118836 (28%)] Loss: 12248.014648\n",
      "Train Epoch: 1288 [65792/118836 (55%)] Loss: 12287.341797\n",
      "Train Epoch: 1288 [98560/118836 (83%)] Loss: 12371.900391\n",
      "    epoch          : 1288\n",
      "    loss           : 12246.110948323769\n",
      "    val_loss       : 12244.722319009039\n",
      "    val_log_likelihood: -12168.813047811984\n",
      "    val_log_marginal: -12176.778427079376\n",
      "Train Epoch: 1289 [256/118836 (0%)] Loss: 12299.319336\n",
      "Train Epoch: 1289 [33024/118836 (28%)] Loss: 12307.636719\n",
      "Train Epoch: 1289 [65792/118836 (55%)] Loss: 12351.018555\n",
      "Train Epoch: 1289 [98560/118836 (83%)] Loss: 12198.826172\n",
      "    epoch          : 1289\n",
      "    loss           : 12247.51721189387\n",
      "    val_loss       : 12244.875739282075\n",
      "    val_log_likelihood: -12172.30746080826\n",
      "    val_log_marginal: -12180.370677806493\n",
      "Train Epoch: 1290 [256/118836 (0%)] Loss: 12290.825195\n",
      "Train Epoch: 1290 [33024/118836 (28%)] Loss: 12339.583984\n",
      "Train Epoch: 1290 [65792/118836 (55%)] Loss: 12248.653320\n",
      "Train Epoch: 1290 [98560/118836 (83%)] Loss: 12274.210938\n",
      "    epoch          : 1290\n",
      "    loss           : 12246.367363749741\n",
      "    val_loss       : 12251.182593628128\n",
      "    val_log_likelihood: -12172.033443186518\n",
      "    val_log_marginal: -12180.043609275514\n",
      "Train Epoch: 1291 [256/118836 (0%)] Loss: 12233.446289\n",
      "Train Epoch: 1291 [33024/118836 (28%)] Loss: 12314.220703\n",
      "Train Epoch: 1291 [65792/118836 (55%)] Loss: 12280.365234\n",
      "Train Epoch: 1291 [98560/118836 (83%)] Loss: 12285.291016\n",
      "    epoch          : 1291\n",
      "    loss           : 12246.511912123915\n",
      "    val_loss       : 12248.033039496633\n",
      "    val_log_likelihood: -12171.00806290064\n",
      "    val_log_marginal: -12178.925273185658\n",
      "Train Epoch: 1292 [256/118836 (0%)] Loss: 12242.218750\n",
      "Train Epoch: 1292 [33024/118836 (28%)] Loss: 12251.688477\n",
      "Train Epoch: 1292 [65792/118836 (55%)] Loss: 12360.182617\n",
      "Train Epoch: 1292 [98560/118836 (83%)] Loss: 12236.054688\n",
      "    epoch          : 1292\n",
      "    loss           : 12249.582636573356\n",
      "    val_loss       : 12250.73099680401\n",
      "    val_log_likelihood: -12170.967089762975\n",
      "    val_log_marginal: -12178.911551970208\n",
      "Train Epoch: 1293 [256/118836 (0%)] Loss: 12249.025391\n",
      "Train Epoch: 1293 [33024/118836 (28%)] Loss: 12162.705078\n",
      "Train Epoch: 1293 [65792/118836 (55%)] Loss: 12244.375000\n",
      "Train Epoch: 1293 [98560/118836 (83%)] Loss: 12319.078125\n",
      "    epoch          : 1293\n",
      "    loss           : 12249.339147151572\n",
      "    val_loss       : 12245.916183828678\n",
      "    val_log_likelihood: -12170.465557311052\n",
      "    val_log_marginal: -12178.279861385903\n",
      "Train Epoch: 1294 [256/118836 (0%)] Loss: 12233.916016\n",
      "Train Epoch: 1294 [33024/118836 (28%)] Loss: 12324.241211\n",
      "Train Epoch: 1294 [65792/118836 (55%)] Loss: 12254.716797\n",
      "Train Epoch: 1294 [98560/118836 (83%)] Loss: 12249.796875\n",
      "    epoch          : 1294\n",
      "    loss           : 12247.561447348015\n",
      "    val_loss       : 12247.237648161268\n",
      "    val_log_likelihood: -12172.003471360627\n",
      "    val_log_marginal: -12180.020541298152\n",
      "Train Epoch: 1295 [256/118836 (0%)] Loss: 12240.810547\n",
      "Train Epoch: 1295 [33024/118836 (28%)] Loss: 12318.251953\n",
      "Train Epoch: 1295 [65792/118836 (55%)] Loss: 12273.746094\n",
      "Train Epoch: 1295 [98560/118836 (83%)] Loss: 12346.996094\n",
      "    epoch          : 1295\n",
      "    loss           : 12248.308083901986\n",
      "    val_loss       : 12246.290059006826\n",
      "    val_log_likelihood: -12171.127642292184\n",
      "    val_log_marginal: -12179.23548353051\n",
      "Train Epoch: 1296 [256/118836 (0%)] Loss: 12275.141602\n",
      "Train Epoch: 1296 [33024/118836 (28%)] Loss: 12263.693359\n",
      "Train Epoch: 1296 [65792/118836 (55%)] Loss: 12241.625000\n",
      "Train Epoch: 1296 [98560/118836 (83%)] Loss: 12325.373047\n",
      "    epoch          : 1296\n",
      "    loss           : 12244.293541440498\n",
      "    val_loss       : 12246.754209078494\n",
      "    val_log_likelihood: -12171.304168120605\n",
      "    val_log_marginal: -12179.484010536502\n",
      "Train Epoch: 1297 [256/118836 (0%)] Loss: 12387.073242\n",
      "Train Epoch: 1297 [33024/118836 (28%)] Loss: 12281.416992\n",
      "Train Epoch: 1297 [65792/118836 (55%)] Loss: 12286.617188\n",
      "Train Epoch: 1297 [98560/118836 (83%)] Loss: 12335.898438\n",
      "    epoch          : 1297\n",
      "    loss           : 12245.476536652191\n",
      "    val_loss       : 12243.021543334926\n",
      "    val_log_likelihood: -12169.446997777088\n",
      "    val_log_marginal: -12177.2688318872\n",
      "Train Epoch: 1298 [256/118836 (0%)] Loss: 12203.330078\n",
      "Train Epoch: 1298 [33024/118836 (28%)] Loss: 12207.455078\n",
      "Train Epoch: 1298 [65792/118836 (55%)] Loss: 12315.924805\n",
      "Train Epoch: 1298 [98560/118836 (83%)] Loss: 12196.297852\n",
      "    epoch          : 1298\n",
      "    loss           : 12246.750500155085\n",
      "    val_loss       : 12248.106551644112\n",
      "    val_log_likelihood: -12170.071154815447\n",
      "    val_log_marginal: -12178.067651006239\n",
      "Train Epoch: 1299 [256/118836 (0%)] Loss: 12297.436523\n",
      "Train Epoch: 1299 [33024/118836 (28%)] Loss: 12190.248047\n",
      "Train Epoch: 1299 [65792/118836 (55%)] Loss: 12219.439453\n",
      "Train Epoch: 1299 [98560/118836 (83%)] Loss: 12271.964844\n",
      "    epoch          : 1299\n",
      "    loss           : 12249.491458107164\n",
      "    val_loss       : 12248.663073160951\n",
      "    val_log_likelihood: -12170.343166970377\n",
      "    val_log_marginal: -12178.230591237132\n",
      "Train Epoch: 1300 [256/118836 (0%)] Loss: 12221.306641\n",
      "Train Epoch: 1300 [33024/118836 (28%)] Loss: 12286.433594\n",
      "Train Epoch: 1300 [65792/118836 (55%)] Loss: 12264.357422\n",
      "Train Epoch: 1300 [98560/118836 (83%)] Loss: 12276.802734\n",
      "    epoch          : 1300\n",
      "    loss           : 12248.551278012563\n",
      "    val_loss       : 12247.17046746081\n",
      "    val_log_likelihood: -12169.02957586978\n",
      "    val_log_marginal: -12176.932270984937\n",
      "Saving checkpoint: saved/models/SelfiesAutoencodingOperad/0905_154251/checkpoint-epoch1300.pth ...\n",
      "Train Epoch: 1301 [256/118836 (0%)] Loss: 12239.109375\n",
      "Train Epoch: 1301 [33024/118836 (28%)] Loss: 12216.957031\n",
      "Train Epoch: 1301 [65792/118836 (55%)] Loss: 12306.365234\n",
      "Train Epoch: 1301 [98560/118836 (83%)] Loss: 12315.804688\n",
      "    epoch          : 1301\n",
      "    loss           : 12248.824277069118\n",
      "    val_loss       : 12243.219970613825\n",
      "    val_log_likelihood: -12167.76829863265\n",
      "    val_log_marginal: -12175.629426041405\n",
      "Train Epoch: 1302 [256/118836 (0%)] Loss: 12302.392578\n",
      "Train Epoch: 1302 [33024/118836 (28%)] Loss: 12193.250000\n",
      "Train Epoch: 1302 [65792/118836 (55%)] Loss: 12214.924805\n",
      "Train Epoch: 1302 [98560/118836 (83%)] Loss: 12238.251953\n",
      "    epoch          : 1302\n",
      "    loss           : 12243.615019191999\n",
      "    val_loss       : 12248.821169487612\n",
      "    val_log_likelihood: -12170.970931716554\n",
      "    val_log_marginal: -12179.02560080703\n",
      "Train Epoch: 1303 [256/118836 (0%)] Loss: 12250.966797\n",
      "Train Epoch: 1303 [33024/118836 (28%)] Loss: 12199.494141\n",
      "Train Epoch: 1303 [65792/118836 (55%)] Loss: 12239.624023\n",
      "Train Epoch: 1303 [98560/118836 (83%)] Loss: 12190.200195\n",
      "    epoch          : 1303\n",
      "    loss           : 12247.320652883323\n",
      "    val_loss       : 12249.174297431917\n",
      "    val_log_likelihood: -12171.323013757496\n",
      "    val_log_marginal: -12179.332191158403\n",
      "Train Epoch: 1304 [256/118836 (0%)] Loss: 12295.742188\n",
      "Train Epoch: 1304 [33024/118836 (28%)] Loss: 12312.105469\n",
      "Train Epoch: 1304 [65792/118836 (55%)] Loss: 12323.703125\n",
      "Train Epoch: 1304 [98560/118836 (83%)] Loss: 12291.356445\n",
      "    epoch          : 1304\n",
      "    loss           : 12253.688387226013\n",
      "    val_loss       : 12248.942007947484\n",
      "    val_log_likelihood: -12170.221817650176\n",
      "    val_log_marginal: -12178.345682873187\n",
      "Train Epoch: 1305 [256/118836 (0%)] Loss: 12203.597656\n",
      "Train Epoch: 1305 [33024/118836 (28%)] Loss: 12213.131836\n",
      "Train Epoch: 1305 [65792/118836 (55%)] Loss: 12373.291992\n",
      "Train Epoch: 1305 [98560/118836 (83%)] Loss: 12205.812500\n",
      "    epoch          : 1305\n",
      "    loss           : 12243.038613717432\n",
      "    val_loss       : 12247.504866711832\n",
      "    val_log_likelihood: -12169.32901804177\n",
      "    val_log_marginal: -12177.189241778624\n",
      "Train Epoch: 1306 [256/118836 (0%)] Loss: 12196.419922\n",
      "Train Epoch: 1306 [33024/118836 (28%)] Loss: 12344.813477\n",
      "Train Epoch: 1306 [65792/118836 (55%)] Loss: 12368.502930\n",
      "Train Epoch: 1306 [98560/118836 (83%)] Loss: 12267.983398\n",
      "    epoch          : 1306\n",
      "    loss           : 12245.835136541047\n",
      "    val_loss       : 12246.249622039291\n",
      "    val_log_likelihood: -12169.280971812965\n",
      "    val_log_marginal: -12177.33834890684\n",
      "Train Epoch: 1307 [256/118836 (0%)] Loss: 12266.828125\n",
      "Train Epoch: 1307 [33024/118836 (28%)] Loss: 12312.271484\n",
      "Train Epoch: 1307 [65792/118836 (55%)] Loss: 12287.691406\n",
      "Train Epoch: 1307 [98560/118836 (83%)] Loss: 12205.283203\n",
      "    epoch          : 1307\n",
      "    loss           : 12247.060131209937\n",
      "    val_loss       : 12248.522871956722\n",
      "    val_log_likelihood: -12170.129214000466\n",
      "    val_log_marginal: -12178.256248775164\n",
      "Train Epoch: 1308 [256/118836 (0%)] Loss: 12253.827148\n",
      "Train Epoch: 1308 [33024/118836 (28%)] Loss: 12314.977539\n",
      "Train Epoch: 1308 [65792/118836 (55%)] Loss: 12232.878906\n",
      "Train Epoch: 1308 [98560/118836 (83%)] Loss: 12211.210938\n",
      "    epoch          : 1308\n",
      "    loss           : 12245.503635009565\n",
      "    val_loss       : 12245.181270032434\n",
      "    val_log_likelihood: -12170.017584425403\n",
      "    val_log_marginal: -12177.897063869566\n",
      "Train Epoch: 1309 [256/118836 (0%)] Loss: 12218.056641\n",
      "Train Epoch: 1309 [33024/118836 (28%)] Loss: 12246.054688\n",
      "Train Epoch: 1309 [65792/118836 (55%)] Loss: 12241.232422\n",
      "Train Epoch: 1309 [98560/118836 (83%)] Loss: 12298.497070\n",
      "    epoch          : 1309\n",
      "    loss           : 12247.949833766284\n",
      "    val_loss       : 12254.055906903719\n",
      "    val_log_likelihood: -12171.141314005636\n",
      "    val_log_marginal: -12179.376247994936\n",
      "Train Epoch: 1310 [256/118836 (0%)] Loss: 12325.584961\n",
      "Train Epoch: 1310 [33024/118836 (28%)] Loss: 12273.320312\n",
      "Train Epoch: 1310 [65792/118836 (55%)] Loss: 12214.878906\n",
      "Train Epoch: 1310 [98560/118836 (83%)] Loss: 12307.316406\n",
      "    epoch          : 1310\n",
      "    loss           : 12250.298023450425\n",
      "    val_loss       : 12247.34244773396\n",
      "    val_log_likelihood: -12170.103755848066\n",
      "    val_log_marginal: -12178.096609954926\n",
      "Train Epoch: 1311 [256/118836 (0%)] Loss: 12291.169922\n",
      "Train Epoch: 1311 [33024/118836 (28%)] Loss: 12329.121094\n",
      "Train Epoch: 1311 [65792/118836 (55%)] Loss: 12361.652344\n",
      "Train Epoch: 1311 [98560/118836 (83%)] Loss: 12212.844727\n",
      "    epoch          : 1311\n",
      "    loss           : 12250.278915296733\n",
      "    val_loss       : 12241.38548590374\n",
      "    val_log_likelihood: -12168.4807852241\n",
      "    val_log_marginal: -12176.421990930843\n",
      "Train Epoch: 1312 [256/118836 (0%)] Loss: 12281.504883\n",
      "Train Epoch: 1312 [33024/118836 (28%)] Loss: 12231.480469\n",
      "Train Epoch: 1312 [65792/118836 (55%)] Loss: 12249.561523\n",
      "Train Epoch: 1312 [98560/118836 (83%)] Loss: 12218.067383\n",
      "    epoch          : 1312\n",
      "    loss           : 12245.424624399038\n",
      "    val_loss       : 12248.79918579153\n",
      "    val_log_likelihood: -12172.213650873657\n",
      "    val_log_marginal: -12180.3019221857\n",
      "Train Epoch: 1313 [256/118836 (0%)] Loss: 12190.113281\n",
      "Train Epoch: 1313 [33024/118836 (28%)] Loss: 12254.663086\n",
      "Train Epoch: 1313 [65792/118836 (55%)] Loss: 12198.871094\n",
      "Train Epoch: 1313 [98560/118836 (83%)] Loss: 12237.608398\n",
      "    epoch          : 1313\n",
      "    loss           : 12247.98732375026\n",
      "    val_loss       : 12246.646424469798\n",
      "    val_log_likelihood: -12169.501034881618\n",
      "    val_log_marginal: -12177.44741845093\n",
      "Train Epoch: 1314 [256/118836 (0%)] Loss: 12275.242188\n",
      "Train Epoch: 1314 [33024/118836 (28%)] Loss: 12191.050781\n",
      "Train Epoch: 1314 [65792/118836 (55%)] Loss: 12290.682617\n",
      "Train Epoch: 1314 [98560/118836 (83%)] Loss: 12337.365234\n",
      "    epoch          : 1314\n",
      "    loss           : 12248.151620980667\n",
      "    val_loss       : 12245.38424975652\n",
      "    val_log_likelihood: -12171.727617575216\n",
      "    val_log_marginal: -12179.893387168135\n",
      "Train Epoch: 1315 [256/118836 (0%)] Loss: 12334.322266\n",
      "Train Epoch: 1315 [33024/118836 (28%)] Loss: 12271.896484\n",
      "Train Epoch: 1315 [65792/118836 (55%)] Loss: 12285.853516\n",
      "Train Epoch: 1315 [98560/118836 (83%)] Loss: 12263.062500\n",
      "    epoch          : 1315\n",
      "    loss           : 12247.48909480976\n",
      "    val_loss       : 12247.901218769499\n",
      "    val_log_likelihood: -12169.57620143843\n",
      "    val_log_marginal: -12177.553712407642\n",
      "Train Epoch: 1316 [256/118836 (0%)] Loss: 12257.879883\n",
      "Train Epoch: 1316 [33024/118836 (28%)] Loss: 12229.514648\n",
      "Train Epoch: 1316 [65792/118836 (55%)] Loss: 12184.464844\n",
      "Train Epoch: 1316 [98560/118836 (83%)] Loss: 12235.316406\n",
      "    epoch          : 1316\n",
      "    loss           : 12243.883011043476\n",
      "    val_loss       : 12249.048709450935\n",
      "    val_log_likelihood: -12169.025620185846\n",
      "    val_log_marginal: -12177.007877915576\n",
      "Train Epoch: 1317 [256/118836 (0%)] Loss: 12252.048828\n",
      "Train Epoch: 1317 [33024/118836 (28%)] Loss: 12275.066406\n",
      "Train Epoch: 1317 [65792/118836 (55%)] Loss: 12238.602539\n",
      "Train Epoch: 1317 [98560/118836 (83%)] Loss: 12280.190430\n",
      "    epoch          : 1317\n",
      "    loss           : 12244.591284765302\n",
      "    val_loss       : 12244.660973779397\n",
      "    val_log_likelihood: -12169.025955399606\n",
      "    val_log_marginal: -12177.020204816363\n",
      "Train Epoch: 1318 [256/118836 (0%)] Loss: 12193.504883\n",
      "Train Epoch: 1318 [33024/118836 (28%)] Loss: 12324.307617\n",
      "Train Epoch: 1318 [65792/118836 (55%)] Loss: 12198.896484\n",
      "Train Epoch: 1318 [98560/118836 (83%)] Loss: 12201.912109\n",
      "    epoch          : 1318\n",
      "    loss           : 12245.753059411187\n",
      "    val_loss       : 12244.425972048368\n",
      "    val_log_likelihood: -12170.534248184193\n",
      "    val_log_marginal: -12178.717948151238\n",
      "Train Epoch: 1319 [256/118836 (0%)] Loss: 12276.448242\n",
      "Train Epoch: 1319 [33024/118836 (28%)] Loss: 12227.397461\n",
      "Train Epoch: 1319 [65792/118836 (55%)] Loss: 12277.429688\n",
      "Train Epoch: 1319 [98560/118836 (83%)] Loss: 12270.517578\n",
      "    epoch          : 1319\n",
      "    loss           : 12246.166671674679\n",
      "    val_loss       : 12244.874005809712\n",
      "    val_log_likelihood: -12170.052548109234\n",
      "    val_log_marginal: -12177.876207015786\n",
      "Train Epoch: 1320 [256/118836 (0%)] Loss: 12196.723633\n",
      "Train Epoch: 1320 [33024/118836 (28%)] Loss: 12325.855469\n",
      "Train Epoch: 1320 [65792/118836 (55%)] Loss: 12224.216797\n",
      "Train Epoch: 1320 [98560/118836 (83%)] Loss: 12271.336914\n",
      "    epoch          : 1320\n",
      "    loss           : 12245.45141177497\n",
      "    val_loss       : 12250.701643572093\n",
      "    val_log_likelihood: -12170.390923057537\n",
      "    val_log_marginal: -12178.401458339527\n",
      "Train Epoch: 1321 [256/118836 (0%)] Loss: 12333.138672\n",
      "Train Epoch: 1321 [33024/118836 (28%)] Loss: 12214.523438\n",
      "Train Epoch: 1321 [65792/118836 (55%)] Loss: 12254.567383\n",
      "Train Epoch: 1321 [98560/118836 (83%)] Loss: 12353.637695\n",
      "    epoch          : 1321\n",
      "    loss           : 12243.020658860629\n",
      "    val_loss       : 12246.440002679365\n",
      "    val_log_likelihood: -12172.132767912532\n",
      "    val_log_marginal: -12180.148743776981\n",
      "Train Epoch: 1322 [256/118836 (0%)] Loss: 12220.574219\n",
      "Train Epoch: 1322 [33024/118836 (28%)] Loss: 12354.110352\n",
      "Train Epoch: 1322 [65792/118836 (55%)] Loss: 12200.825195\n",
      "Train Epoch: 1322 [98560/118836 (83%)] Loss: 12282.916992\n",
      "    epoch          : 1322\n",
      "    loss           : 12244.951358463866\n",
      "    val_loss       : 12247.943591278821\n",
      "    val_log_likelihood: -12170.251343439826\n",
      "    val_log_marginal: -12178.206749875295\n",
      "Train Epoch: 1323 [256/118836 (0%)] Loss: 12250.451172\n",
      "Train Epoch: 1323 [33024/118836 (28%)] Loss: 12249.222656\n",
      "Train Epoch: 1323 [65792/118836 (55%)] Loss: 12302.113281\n",
      "Train Epoch: 1323 [98560/118836 (83%)] Loss: 12281.908203\n",
      "    epoch          : 1323\n",
      "    loss           : 12247.642513828576\n",
      "    val_loss       : 12244.598957256261\n",
      "    val_log_likelihood: -12169.38182220585\n",
      "    val_log_marginal: -12177.263216912754\n",
      "Train Epoch: 1324 [256/118836 (0%)] Loss: 12210.017578\n",
      "Train Epoch: 1324 [33024/118836 (28%)] Loss: 12229.602539\n",
      "Train Epoch: 1324 [65792/118836 (55%)] Loss: 12257.221680\n",
      "Train Epoch: 1324 [98560/118836 (83%)] Loss: 12265.630859\n",
      "    epoch          : 1324\n",
      "    loss           : 12249.522121038823\n",
      "    val_loss       : 12248.300258658444\n",
      "    val_log_likelihood: -12169.798997105045\n",
      "    val_log_marginal: -12177.92471949175\n",
      "Train Epoch: 1325 [256/118836 (0%)] Loss: 12229.299805\n",
      "Train Epoch: 1325 [33024/118836 (28%)] Loss: 12236.541016\n",
      "Train Epoch: 1325 [65792/118836 (55%)] Loss: 12253.402344\n",
      "Train Epoch: 1325 [98560/118836 (83%)] Loss: 12259.851562\n",
      "    epoch          : 1325\n",
      "    loss           : 12246.991952931143\n",
      "    val_loss       : 12245.01031728207\n",
      "    val_log_likelihood: -12170.155661639268\n",
      "    val_log_marginal: -12178.40804043727\n",
      "Train Epoch: 1326 [256/118836 (0%)] Loss: 12241.714844\n",
      "Train Epoch: 1326 [33024/118836 (28%)] Loss: 12339.371094\n",
      "Train Epoch: 1326 [65792/118836 (55%)] Loss: 12270.565430\n",
      "Train Epoch: 1326 [98560/118836 (83%)] Loss: 12246.533203\n",
      "    epoch          : 1326\n",
      "    loss           : 12248.451171875\n",
      "    val_loss       : 12250.257297663096\n",
      "    val_log_likelihood: -12168.787546364507\n",
      "    val_log_marginal: -12177.175664001585\n",
      "Train Epoch: 1327 [256/118836 (0%)] Loss: 12237.205078\n",
      "Train Epoch: 1327 [33024/118836 (28%)] Loss: 12229.131836\n",
      "Train Epoch: 1327 [65792/118836 (55%)] Loss: 12324.996094\n",
      "Train Epoch: 1327 [98560/118836 (83%)] Loss: 12215.491211\n",
      "    epoch          : 1327\n",
      "    loss           : 12247.589558454818\n",
      "    val_loss       : 12247.787316554566\n",
      "    val_log_likelihood: -12167.204598001963\n",
      "    val_log_marginal: -12175.25020111209\n",
      "Train Epoch: 1328 [256/118836 (0%)] Loss: 12283.201172\n",
      "Train Epoch: 1328 [33024/118836 (28%)] Loss: 12349.257812\n",
      "Train Epoch: 1328 [65792/118836 (55%)] Loss: 12247.826172\n",
      "Train Epoch: 1328 [98560/118836 (83%)] Loss: 12256.003906\n",
      "    epoch          : 1328\n",
      "    loss           : 12247.980664547145\n",
      "    val_loss       : 12247.215229653579\n",
      "    val_log_likelihood: -12172.979483140767\n",
      "    val_log_marginal: -12181.150821498219\n",
      "Train Epoch: 1329 [256/118836 (0%)] Loss: 12316.854492\n",
      "Train Epoch: 1329 [33024/118836 (28%)] Loss: 12233.731445\n",
      "Train Epoch: 1329 [65792/118836 (55%)] Loss: 12249.558594\n",
      "Train Epoch: 1329 [98560/118836 (83%)] Loss: 12251.697266\n",
      "    epoch          : 1329\n",
      "    loss           : 12249.038114370089\n",
      "    val_loss       : 12247.700461211918\n",
      "    val_log_likelihood: -12170.594733186\n",
      "    val_log_marginal: -12178.595601624496\n",
      "Train Epoch: 1330 [256/118836 (0%)] Loss: 12286.937500\n",
      "Train Epoch: 1330 [33024/118836 (28%)] Loss: 12264.619141\n",
      "Train Epoch: 1330 [65792/118836 (55%)] Loss: 12299.353516\n",
      "Train Epoch: 1330 [98560/118836 (83%)] Loss: 12249.326172\n",
      "    epoch          : 1330\n",
      "    loss           : 12246.670265650848\n",
      "    val_loss       : 12249.989881289763\n",
      "    val_log_likelihood: -12170.219136909378\n",
      "    val_log_marginal: -12178.230275448497\n",
      "Train Epoch: 1331 [256/118836 (0%)] Loss: 12198.960938\n",
      "Train Epoch: 1331 [33024/118836 (28%)] Loss: 12204.311523\n",
      "Train Epoch: 1331 [65792/118836 (55%)] Loss: 12247.498047\n",
      "Train Epoch: 1331 [98560/118836 (83%)] Loss: 12227.465820\n",
      "    epoch          : 1331\n",
      "    loss           : 12250.544169380686\n",
      "    val_loss       : 12251.708974623838\n",
      "    val_log_likelihood: -12170.34534206343\n",
      "    val_log_marginal: -12178.525507377091\n",
      "Train Epoch: 1332 [256/118836 (0%)] Loss: 12362.879883\n",
      "Train Epoch: 1332 [33024/118836 (28%)] Loss: 12309.260742\n",
      "Train Epoch: 1332 [65792/118836 (55%)] Loss: 12315.790039\n",
      "Train Epoch: 1332 [98560/118836 (83%)] Loss: 12214.137695\n",
      "    epoch          : 1332\n",
      "    loss           : 12248.569655965674\n",
      "    val_loss       : 12250.147644740862\n",
      "    val_log_likelihood: -12169.700745386166\n",
      "    val_log_marginal: -12177.65424876643\n",
      "Train Epoch: 1333 [256/118836 (0%)] Loss: 12275.097656\n",
      "Train Epoch: 1333 [33024/118836 (28%)] Loss: 12176.183594\n",
      "Train Epoch: 1333 [65792/118836 (55%)] Loss: 12198.854492\n",
      "Train Epoch: 1333 [98560/118836 (83%)] Loss: 12280.276367\n",
      "    epoch          : 1333\n",
      "    loss           : 12246.832955793787\n",
      "    val_loss       : 12243.128275725254\n",
      "    val_log_likelihood: -12169.550850877533\n",
      "    val_log_marginal: -12177.523337392857\n",
      "Train Epoch: 1334 [256/118836 (0%)] Loss: 12221.069336\n",
      "Train Epoch: 1334 [33024/118836 (28%)] Loss: 12375.129883\n",
      "Train Epoch: 1334 [65792/118836 (55%)] Loss: 12268.990234\n",
      "Train Epoch: 1334 [98560/118836 (83%)] Loss: 12299.518555\n",
      "    epoch          : 1334\n",
      "    loss           : 12253.056676811932\n",
      "    val_loss       : 12249.436220802867\n",
      "    val_log_likelihood: -12171.650239576871\n",
      "    val_log_marginal: -12179.50338553007\n",
      "Train Epoch: 1335 [256/118836 (0%)] Loss: 12218.130859\n",
      "Train Epoch: 1335 [33024/118836 (28%)] Loss: 12206.381836\n",
      "Train Epoch: 1335 [65792/118836 (55%)] Loss: 12279.748047\n",
      "Train Epoch: 1335 [98560/118836 (83%)] Loss: 12318.105469\n",
      "    epoch          : 1335\n",
      "    loss           : 12248.414844719293\n",
      "    val_loss       : 12247.207807443318\n",
      "    val_log_likelihood: -12169.586833934296\n",
      "    val_log_marginal: -12177.372183892696\n",
      "Train Epoch: 1336 [256/118836 (0%)] Loss: 12326.927734\n",
      "Train Epoch: 1336 [33024/118836 (28%)] Loss: 12221.687500\n",
      "Train Epoch: 1336 [65792/118836 (55%)] Loss: 12368.425781\n",
      "Train Epoch: 1336 [98560/118836 (83%)] Loss: 12287.351562\n",
      "    epoch          : 1336\n",
      "    loss           : 12247.954544206214\n",
      "    val_loss       : 12245.311853522246\n",
      "    val_log_likelihood: -12170.45837291279\n",
      "    val_log_marginal: -12178.291669378628\n",
      "Train Epoch: 1337 [256/118836 (0%)] Loss: 12263.558594\n",
      "Train Epoch: 1337 [33024/118836 (28%)] Loss: 12269.371094\n",
      "Train Epoch: 1337 [65792/118836 (55%)] Loss: 12226.553711\n",
      "Train Epoch: 1337 [98560/118836 (83%)] Loss: 12289.612305\n",
      "    epoch          : 1337\n",
      "    loss           : 12244.987975599668\n",
      "    val_loss       : 12245.993129511131\n",
      "    val_log_likelihood: -12167.77115045363\n",
      "    val_log_marginal: -12175.709395956637\n",
      "Train Epoch: 1338 [256/118836 (0%)] Loss: 12265.367188\n",
      "Train Epoch: 1338 [33024/118836 (28%)] Loss: 12252.632812\n",
      "Train Epoch: 1338 [65792/118836 (55%)] Loss: 12244.886719\n",
      "Train Epoch: 1338 [98560/118836 (83%)] Loss: 12268.648438\n",
      "    epoch          : 1338\n",
      "    loss           : 12246.807551921784\n",
      "    val_loss       : 12242.691959056774\n",
      "    val_log_likelihood: -12168.807313475754\n",
      "    val_log_marginal: -12176.778770747871\n",
      "Train Epoch: 1339 [256/118836 (0%)] Loss: 12258.822266\n",
      "Train Epoch: 1339 [33024/118836 (28%)] Loss: 12213.806641\n",
      "Train Epoch: 1339 [65792/118836 (55%)] Loss: 12321.500000\n",
      "Train Epoch: 1339 [98560/118836 (83%)] Loss: 12332.254883\n",
      "    epoch          : 1339\n",
      "    loss           : 12247.059521524763\n",
      "    val_loss       : 12243.957765918169\n",
      "    val_log_likelihood: -12168.65429929823\n",
      "    val_log_marginal: -12176.586355277066\n",
      "Train Epoch: 1340 [256/118836 (0%)] Loss: 12335.333984\n",
      "Train Epoch: 1340 [33024/118836 (28%)] Loss: 12285.616211\n",
      "Train Epoch: 1340 [65792/118836 (55%)] Loss: 12223.241211\n",
      "Train Epoch: 1340 [98560/118836 (83%)] Loss: 12282.574219\n",
      "    epoch          : 1340\n",
      "    loss           : 12246.66099000336\n",
      "    val_loss       : 12248.236035472377\n",
      "    val_log_likelihood: -12171.53861274814\n",
      "    val_log_marginal: -12179.54336768577\n",
      "Train Epoch: 1341 [256/118836 (0%)] Loss: 12315.896484\n",
      "Train Epoch: 1341 [33024/118836 (28%)] Loss: 12208.371094\n",
      "Train Epoch: 1341 [65792/118836 (55%)] Loss: 12273.975586\n",
      "Train Epoch: 1341 [98560/118836 (83%)] Loss: 12268.159180\n",
      "    epoch          : 1341\n",
      "    loss           : 12248.324756869055\n",
      "    val_loss       : 12248.48915425608\n",
      "    val_log_likelihood: -12171.42573843957\n",
      "    val_log_marginal: -12179.374574964595\n",
      "Train Epoch: 1342 [256/118836 (0%)] Loss: 12341.289062\n",
      "Train Epoch: 1342 [33024/118836 (28%)] Loss: 12223.421875\n",
      "Train Epoch: 1342 [65792/118836 (55%)] Loss: 12205.972656\n",
      "Train Epoch: 1342 [98560/118836 (83%)] Loss: 12311.129883\n",
      "    epoch          : 1342\n",
      "    loss           : 12246.647848331524\n",
      "    val_loss       : 12249.154622550655\n",
      "    val_log_likelihood: -12173.272985971102\n",
      "    val_log_marginal: -12181.414848715436\n",
      "Train Epoch: 1343 [256/118836 (0%)] Loss: 12254.698242\n",
      "Train Epoch: 1343 [33024/118836 (28%)] Loss: 12273.395508\n",
      "Train Epoch: 1343 [65792/118836 (55%)] Loss: 12243.462891\n",
      "Train Epoch: 1343 [98560/118836 (83%)] Loss: 12328.117188\n",
      "    epoch          : 1343\n",
      "    loss           : 12246.716774742814\n",
      "    val_loss       : 12249.118736838233\n",
      "    val_log_likelihood: -12170.32370163229\n",
      "    val_log_marginal: -12178.324827954073\n",
      "Train Epoch: 1344 [256/118836 (0%)] Loss: 12228.778320\n",
      "Train Epoch: 1344 [33024/118836 (28%)] Loss: 12191.830078\n",
      "Train Epoch: 1344 [65792/118836 (55%)] Loss: 12253.152344\n",
      "Train Epoch: 1344 [98560/118836 (83%)] Loss: 12359.332031\n",
      "    epoch          : 1344\n",
      "    loss           : 12248.057524458489\n",
      "    val_loss       : 12247.730370085266\n",
      "    val_log_likelihood: -12168.473655752428\n",
      "    val_log_marginal: -12176.478119157917\n",
      "Train Epoch: 1345 [256/118836 (0%)] Loss: 12272.070312\n",
      "Train Epoch: 1345 [33024/118836 (28%)] Loss: 12192.272461\n",
      "Train Epoch: 1345 [65792/118836 (55%)] Loss: 12316.726562\n",
      "Train Epoch: 1345 [98560/118836 (83%)] Loss: 12334.657227\n",
      "    epoch          : 1345\n",
      "    loss           : 12247.305093633684\n",
      "    val_loss       : 12245.207175075646\n",
      "    val_log_likelihood: -12168.71765356829\n",
      "    val_log_marginal: -12176.71436018219\n",
      "Train Epoch: 1346 [256/118836 (0%)] Loss: 12368.056641\n",
      "Train Epoch: 1346 [33024/118836 (28%)] Loss: 12245.895508\n",
      "Train Epoch: 1346 [65792/118836 (55%)] Loss: 12239.328125\n",
      "Train Epoch: 1346 [98560/118836 (83%)] Loss: 12271.263672\n",
      "    epoch          : 1346\n",
      "    loss           : 12251.206877940189\n",
      "    val_loss       : 12245.648107807601\n",
      "    val_log_likelihood: -12171.467769075682\n",
      "    val_log_marginal: -12179.373409969443\n",
      "Train Epoch: 1347 [256/118836 (0%)] Loss: 12259.502930\n",
      "Train Epoch: 1347 [33024/118836 (28%)] Loss: 12248.947266\n",
      "Train Epoch: 1347 [65792/118836 (55%)] Loss: 12249.287109\n",
      "Train Epoch: 1347 [98560/118836 (83%)] Loss: 12246.708008\n",
      "    epoch          : 1347\n",
      "    loss           : 12243.484575320512\n",
      "    val_loss       : 12247.775145113965\n",
      "    val_log_likelihood: -12168.999526338916\n",
      "    val_log_marginal: -12177.057980860129\n",
      "Train Epoch: 1348 [256/118836 (0%)] Loss: 12264.498047\n",
      "Train Epoch: 1348 [33024/118836 (28%)] Loss: 12267.736328\n",
      "Train Epoch: 1348 [65792/118836 (55%)] Loss: 12243.409180\n",
      "Train Epoch: 1348 [98560/118836 (83%)] Loss: 12270.557617\n",
      "    epoch          : 1348\n",
      "    loss           : 12246.615568781017\n",
      "    val_loss       : 12245.653166558217\n",
      "    val_log_likelihood: -12170.448474333127\n",
      "    val_log_marginal: -12178.326260450986\n",
      "Train Epoch: 1349 [256/118836 (0%)] Loss: 12319.682617\n",
      "Train Epoch: 1349 [33024/118836 (28%)] Loss: 12261.395508\n",
      "Train Epoch: 1349 [65792/118836 (55%)] Loss: 12308.225586\n",
      "Train Epoch: 1349 [98560/118836 (83%)] Loss: 12263.636719\n",
      "    epoch          : 1349\n",
      "    loss           : 12248.15158689387\n",
      "    val_loss       : 12243.537792445575\n",
      "    val_log_likelihood: -12168.927837120036\n",
      "    val_log_marginal: -12176.860808613419\n",
      "Train Epoch: 1350 [256/118836 (0%)] Loss: 12321.636719\n",
      "Train Epoch: 1350 [33024/118836 (28%)] Loss: 12261.113281\n",
      "Train Epoch: 1350 [65792/118836 (55%)] Loss: 12287.595703\n",
      "Train Epoch: 1350 [98560/118836 (83%)] Loss: 12253.828125\n",
      "    epoch          : 1350\n",
      "    loss           : 12242.941717392989\n",
      "    val_loss       : 12248.756287591501\n",
      "    val_log_likelihood: -12171.606232229633\n",
      "    val_log_marginal: -12179.520841540707\n",
      "Train Epoch: 1351 [256/118836 (0%)] Loss: 12232.636719\n",
      "Train Epoch: 1351 [33024/118836 (28%)] Loss: 12182.814453\n",
      "Train Epoch: 1351 [65792/118836 (55%)] Loss: 12338.150391\n",
      "Train Epoch: 1351 [98560/118836 (83%)] Loss: 12212.367188\n",
      "    epoch          : 1351\n",
      "    loss           : 12244.015952459418\n",
      "    val_loss       : 12244.79503928818\n",
      "    val_log_likelihood: -12173.843192656639\n",
      "    val_log_marginal: -12181.914369936081\n",
      "Train Epoch: 1352 [256/118836 (0%)] Loss: 12194.116211\n",
      "Train Epoch: 1352 [33024/118836 (28%)] Loss: 12340.442383\n",
      "Train Epoch: 1352 [65792/118836 (55%)] Loss: 12263.273438\n",
      "Train Epoch: 1352 [98560/118836 (83%)] Loss: 12289.859375\n",
      "    epoch          : 1352\n",
      "    loss           : 12247.494660327491\n",
      "    val_loss       : 12248.746597185456\n",
      "    val_log_likelihood: -12168.279879419973\n",
      "    val_log_marginal: -12176.330386690683\n",
      "Train Epoch: 1353 [256/118836 (0%)] Loss: 12208.460938\n",
      "Train Epoch: 1353 [33024/118836 (28%)] Loss: 12230.861328\n",
      "Train Epoch: 1353 [65792/118836 (55%)] Loss: 12246.281250\n",
      "Train Epoch: 1353 [98560/118836 (83%)] Loss: 12214.096680\n",
      "    epoch          : 1353\n",
      "    loss           : 12244.733281476168\n",
      "    val_loss       : 12251.648996763884\n",
      "    val_log_likelihood: -12168.713341992348\n",
      "    val_log_marginal: -12176.652445426427\n",
      "Train Epoch: 1354 [256/118836 (0%)] Loss: 12285.152344\n",
      "Train Epoch: 1354 [33024/118836 (28%)] Loss: 12332.173828\n",
      "Train Epoch: 1354 [65792/118836 (55%)] Loss: 12209.963867\n",
      "Train Epoch: 1354 [98560/118836 (83%)] Loss: 12330.515625\n",
      "    epoch          : 1354\n",
      "    loss           : 12249.116104638388\n",
      "    val_loss       : 12246.734482178616\n",
      "    val_log_likelihood: -12171.103781695874\n",
      "    val_log_marginal: -12178.993313752695\n",
      "Train Epoch: 1355 [256/118836 (0%)] Loss: 12373.611328\n",
      "Train Epoch: 1355 [33024/118836 (28%)] Loss: 12285.897461\n",
      "Train Epoch: 1355 [65792/118836 (55%)] Loss: 12324.993164\n",
      "Train Epoch: 1355 [98560/118836 (83%)] Loss: 12254.136719\n",
      "    epoch          : 1355\n",
      "    loss           : 12245.772193897334\n",
      "    val_loss       : 12245.068455069459\n",
      "    val_log_likelihood: -12170.363546028484\n",
      "    val_log_marginal: -12178.417124680744\n",
      "Train Epoch: 1356 [256/118836 (0%)] Loss: 12208.156250\n",
      "Train Epoch: 1356 [33024/118836 (28%)] Loss: 12263.972656\n",
      "Train Epoch: 1356 [65792/118836 (55%)] Loss: 12206.999023\n",
      "Train Epoch: 1356 [98560/118836 (83%)] Loss: 12245.654297\n",
      "    epoch          : 1356\n",
      "    loss           : 12250.125217121587\n",
      "    val_loss       : 12247.859117729324\n",
      "    val_log_likelihood: -12172.12937086435\n",
      "    val_log_marginal: -12180.132934864245\n",
      "Train Epoch: 1357 [256/118836 (0%)] Loss: 12315.550781\n",
      "Train Epoch: 1357 [33024/118836 (28%)] Loss: 12249.333008\n",
      "Train Epoch: 1357 [65792/118836 (55%)] Loss: 12339.931641\n",
      "Train Epoch: 1357 [98560/118836 (83%)] Loss: 12240.111328\n",
      "    epoch          : 1357\n",
      "    loss           : 12245.325890780086\n",
      "    val_loss       : 12249.781955948587\n",
      "    val_log_likelihood: -12172.597286464794\n",
      "    val_log_marginal: -12180.536153213518\n",
      "Train Epoch: 1358 [256/118836 (0%)] Loss: 12335.831055\n",
      "Train Epoch: 1358 [33024/118836 (28%)] Loss: 12259.507812\n",
      "Train Epoch: 1358 [65792/118836 (55%)] Loss: 12311.365234\n",
      "Train Epoch: 1358 [98560/118836 (83%)] Loss: 12238.226562\n",
      "    epoch          : 1358\n",
      "    loss           : 12246.819237231182\n",
      "    val_loss       : 12246.389567971244\n",
      "    val_log_likelihood: -12170.517418514784\n",
      "    val_log_marginal: -12178.790874834882\n",
      "Train Epoch: 1359 [256/118836 (0%)] Loss: 12330.107422\n",
      "Train Epoch: 1359 [33024/118836 (28%)] Loss: 12298.880859\n",
      "Train Epoch: 1359 [65792/118836 (55%)] Loss: 12357.262695\n",
      "Train Epoch: 1359 [98560/118836 (83%)] Loss: 12252.190430\n",
      "    epoch          : 1359\n",
      "    loss           : 12249.696846244315\n",
      "    val_loss       : 12251.082577969422\n",
      "    val_log_likelihood: -12170.913808545287\n",
      "    val_log_marginal: -12178.91591558774\n",
      "Train Epoch: 1360 [256/118836 (0%)] Loss: 12248.497070\n",
      "Train Epoch: 1360 [33024/118836 (28%)] Loss: 12308.467773\n",
      "Train Epoch: 1360 [65792/118836 (55%)] Loss: 12219.716797\n",
      "Train Epoch: 1360 [98560/118836 (83%)] Loss: 12201.921875\n",
      "    epoch          : 1360\n",
      "    loss           : 12248.543400085297\n",
      "    val_loss       : 12245.553247485097\n",
      "    val_log_likelihood: -12168.92030716889\n",
      "    val_log_marginal: -12176.809665931045\n",
      "Train Epoch: 1361 [256/118836 (0%)] Loss: 12280.027344\n",
      "Train Epoch: 1361 [33024/118836 (28%)] Loss: 12284.469727\n",
      "Train Epoch: 1361 [65792/118836 (55%)] Loss: 12206.464844\n",
      "Train Epoch: 1361 [98560/118836 (83%)] Loss: 12238.070312\n",
      "    epoch          : 1361\n",
      "    loss           : 12243.85159351737\n",
      "    val_loss       : 12244.729001014004\n",
      "    val_log_likelihood: -12170.44660279027\n",
      "    val_log_marginal: -12178.34801890113\n",
      "Train Epoch: 1362 [256/118836 (0%)] Loss: 12274.107422\n",
      "Train Epoch: 1362 [33024/118836 (28%)] Loss: 12228.669922\n",
      "Train Epoch: 1362 [65792/118836 (55%)] Loss: 12274.940430\n",
      "Train Epoch: 1362 [98560/118836 (83%)] Loss: 12215.539062\n",
      "    epoch          : 1362\n",
      "    loss           : 12246.967274736353\n",
      "    val_loss       : 12248.30216026233\n",
      "    val_log_likelihood: -12168.687005337571\n",
      "    val_log_marginal: -12176.779608767425\n",
      "Train Epoch: 1363 [256/118836 (0%)] Loss: 12230.693359\n",
      "Train Epoch: 1363 [33024/118836 (28%)] Loss: 12179.677734\n",
      "Train Epoch: 1363 [65792/118836 (55%)] Loss: 12176.808594\n",
      "Train Epoch: 1363 [98560/118836 (83%)] Loss: 12260.779297\n",
      "    epoch          : 1363\n",
      "    loss           : 12248.945466779105\n",
      "    val_loss       : 12243.642896451647\n",
      "    val_log_likelihood: -12170.741159403433\n",
      "    val_log_marginal: -12178.959068064702\n",
      "Train Epoch: 1364 [256/118836 (0%)] Loss: 12304.757812\n",
      "Train Epoch: 1364 [33024/118836 (28%)] Loss: 12311.190430\n",
      "Train Epoch: 1364 [65792/118836 (55%)] Loss: 12247.705078\n",
      "Train Epoch: 1364 [98560/118836 (83%)] Loss: 12192.314453\n",
      "    epoch          : 1364\n",
      "    loss           : 12249.601090292856\n",
      "    val_loss       : 12247.107196928138\n",
      "    val_log_likelihood: -12169.361691609802\n",
      "    val_log_marginal: -12177.628746876559\n",
      "Train Epoch: 1365 [256/118836 (0%)] Loss: 12205.813477\n",
      "Train Epoch: 1365 [33024/118836 (28%)] Loss: 12197.456055\n",
      "Train Epoch: 1365 [65792/118836 (55%)] Loss: 12245.414062\n",
      "Train Epoch: 1365 [98560/118836 (83%)] Loss: 12207.869141\n",
      "    epoch          : 1365\n",
      "    loss           : 12247.799114066376\n",
      "    val_loss       : 12248.52227832287\n",
      "    val_log_likelihood: -12167.274519392317\n",
      "    val_log_marginal: -12175.251998198122\n",
      "Train Epoch: 1366 [256/118836 (0%)] Loss: 12278.145508\n",
      "Train Epoch: 1366 [33024/118836 (28%)] Loss: 12376.312500\n",
      "Train Epoch: 1366 [65792/118836 (55%)] Loss: 12204.621094\n",
      "Train Epoch: 1366 [98560/118836 (83%)] Loss: 12295.507812\n",
      "    epoch          : 1366\n",
      "    loss           : 12245.060522158034\n",
      "    val_loss       : 12245.69101671692\n",
      "    val_log_likelihood: -12169.511805178608\n",
      "    val_log_marginal: -12177.394729725112\n",
      "Train Epoch: 1367 [256/118836 (0%)] Loss: 12334.227539\n",
      "Train Epoch: 1367 [33024/118836 (28%)] Loss: 12303.104492\n",
      "Train Epoch: 1367 [65792/118836 (55%)] Loss: 12246.565430\n",
      "Train Epoch: 1367 [98560/118836 (83%)] Loss: 12409.436523\n",
      "    epoch          : 1367\n",
      "    loss           : 12244.244608308778\n",
      "    val_loss       : 12250.957343008693\n",
      "    val_log_likelihood: -12170.298471586797\n",
      "    val_log_marginal: -12178.092151312063\n",
      "Train Epoch: 1368 [256/118836 (0%)] Loss: 12254.324219\n",
      "Train Epoch: 1368 [33024/118836 (28%)] Loss: 12265.132812\n",
      "Train Epoch: 1368 [65792/118836 (55%)] Loss: 12190.339844\n",
      "Train Epoch: 1368 [98560/118836 (83%)] Loss: 12201.701172\n",
      "    epoch          : 1368\n",
      "    loss           : 12249.123339762975\n",
      "    val_loss       : 12245.101074858749\n",
      "    val_log_likelihood: -12172.08480471981\n",
      "    val_log_marginal: -12180.195589588044\n",
      "Train Epoch: 1369 [256/118836 (0%)] Loss: 12178.082031\n",
      "Train Epoch: 1369 [33024/118836 (28%)] Loss: 12273.564453\n",
      "Train Epoch: 1369 [65792/118836 (55%)] Loss: 12287.341797\n",
      "Train Epoch: 1369 [98560/118836 (83%)] Loss: 12237.303711\n",
      "    epoch          : 1369\n",
      "    loss           : 12245.439826302729\n",
      "    val_loss       : 12244.237137948687\n",
      "    val_log_likelihood: -12170.149871730251\n",
      "    val_log_marginal: -12178.09492115384\n",
      "Train Epoch: 1370 [256/118836 (0%)] Loss: 12216.412109\n",
      "Train Epoch: 1370 [33024/118836 (28%)] Loss: 12266.002930\n",
      "Train Epoch: 1370 [65792/118836 (55%)] Loss: 12320.365234\n",
      "Train Epoch: 1370 [98560/118836 (83%)] Loss: 12214.419922\n",
      "    epoch          : 1370\n",
      "    loss           : 12247.949840228235\n",
      "    val_loss       : 12249.968281666896\n",
      "    val_log_likelihood: -12169.612044432382\n",
      "    val_log_marginal: -12177.836988056732\n",
      "Train Epoch: 1371 [256/118836 (0%)] Loss: 12308.925781\n",
      "Train Epoch: 1371 [33024/118836 (28%)] Loss: 12325.916016\n",
      "Train Epoch: 1371 [65792/118836 (55%)] Loss: 12266.584961\n",
      "Train Epoch: 1371 [98560/118836 (83%)] Loss: 12336.412109\n",
      "    epoch          : 1371\n",
      "    loss           : 12246.971324764785\n",
      "    val_loss       : 12249.143866960925\n",
      "    val_log_likelihood: -12170.496264507083\n",
      "    val_log_marginal: -12178.765030340952\n",
      "Train Epoch: 1372 [256/118836 (0%)] Loss: 12304.749023\n",
      "Train Epoch: 1372 [33024/118836 (28%)] Loss: 12347.097656\n",
      "Train Epoch: 1372 [65792/118836 (55%)] Loss: 12246.692383\n",
      "Train Epoch: 1372 [98560/118836 (83%)] Loss: 12308.299805\n",
      "    epoch          : 1372\n",
      "    loss           : 12249.469380201872\n",
      "    val_loss       : 12249.407647045282\n",
      "    val_log_likelihood: -12174.107039650538\n",
      "    val_log_marginal: -12182.173045967858\n",
      "Train Epoch: 1373 [256/118836 (0%)] Loss: 12311.867188\n",
      "Train Epoch: 1373 [33024/118836 (28%)] Loss: 12333.257812\n",
      "Train Epoch: 1373 [65792/118836 (55%)] Loss: 12217.360352\n",
      "Train Epoch: 1373 [98560/118836 (83%)] Loss: 12165.421875\n",
      "    epoch          : 1373\n",
      "    loss           : 12250.752228404157\n",
      "    val_loss       : 12245.06218092528\n",
      "    val_log_likelihood: -12169.36735454146\n",
      "    val_log_marginal: -12177.318149597626\n",
      "Train Epoch: 1374 [256/118836 (0%)] Loss: 12215.587891\n",
      "Train Epoch: 1374 [33024/118836 (28%)] Loss: 12243.750977\n",
      "Train Epoch: 1374 [65792/118836 (55%)] Loss: 12262.759766\n",
      "Train Epoch: 1374 [98560/118836 (83%)] Loss: 12213.595703\n",
      "    epoch          : 1374\n",
      "    loss           : 12249.529488633427\n",
      "    val_loss       : 12246.89183042211\n",
      "    val_log_likelihood: -12169.944691829507\n",
      "    val_log_marginal: -12178.07374751811\n",
      "Train Epoch: 1375 [256/118836 (0%)] Loss: 12292.108398\n",
      "Train Epoch: 1375 [33024/118836 (28%)] Loss: 12215.501953\n",
      "Train Epoch: 1375 [65792/118836 (55%)] Loss: 12383.659180\n",
      "Train Epoch: 1375 [98560/118836 (83%)] Loss: 12212.687500\n",
      "    epoch          : 1375\n",
      "    loss           : 12248.338302089795\n",
      "    val_loss       : 12246.053919713431\n",
      "    val_log_likelihood: -12169.78868253722\n",
      "    val_log_marginal: -12177.83667828238\n",
      "Train Epoch: 1376 [256/118836 (0%)] Loss: 12254.825195\n",
      "Train Epoch: 1376 [33024/118836 (28%)] Loss: 12196.328125\n",
      "Train Epoch: 1376 [65792/118836 (55%)] Loss: 12297.685547\n",
      "Train Epoch: 1376 [98560/118836 (83%)] Loss: 12232.259766\n",
      "    epoch          : 1376\n",
      "    loss           : 12243.370398443962\n",
      "    val_loss       : 12246.174596989336\n",
      "    val_log_likelihood: -12170.382455154053\n",
      "    val_log_marginal: -12178.552442215441\n",
      "Train Epoch: 1377 [256/118836 (0%)] Loss: 12272.108398\n",
      "Train Epoch: 1377 [33024/118836 (28%)] Loss: 12223.077148\n",
      "Train Epoch: 1377 [65792/118836 (55%)] Loss: 12268.051758\n",
      "Train Epoch: 1377 [98560/118836 (83%)] Loss: 12282.832031\n",
      "    epoch          : 1377\n",
      "    loss           : 12249.190611914548\n",
      "    val_loss       : 12248.49806180394\n",
      "    val_log_likelihood: -12169.85719845301\n",
      "    val_log_marginal: -12177.992793835005\n",
      "Train Epoch: 1378 [256/118836 (0%)] Loss: 12204.235352\n",
      "Train Epoch: 1378 [33024/118836 (28%)] Loss: 12195.255859\n",
      "Train Epoch: 1378 [65792/118836 (55%)] Loss: 12301.529297\n",
      "Train Epoch: 1378 [98560/118836 (83%)] Loss: 12310.445312\n",
      "    epoch          : 1378\n",
      "    loss           : 12249.012921965466\n",
      "    val_loss       : 12246.139336206039\n",
      "    val_log_likelihood: -12169.777730659378\n",
      "    val_log_marginal: -12177.76771098566\n",
      "Train Epoch: 1379 [256/118836 (0%)] Loss: 12242.492188\n",
      "Train Epoch: 1379 [33024/118836 (28%)] Loss: 12384.841797\n",
      "Train Epoch: 1379 [65792/118836 (55%)] Loss: 12309.507812\n",
      "Train Epoch: 1379 [98560/118836 (83%)] Loss: 12177.960938\n",
      "    epoch          : 1379\n",
      "    loss           : 12245.197562228597\n",
      "    val_loss       : 12250.379952863494\n",
      "    val_log_likelihood: -12171.257719286343\n",
      "    val_log_marginal: -12179.337933679763\n",
      "Train Epoch: 1380 [256/118836 (0%)] Loss: 12298.987305\n",
      "Train Epoch: 1380 [33024/118836 (28%)] Loss: 12212.213867\n",
      "Train Epoch: 1380 [65792/118836 (55%)] Loss: 12359.943359\n",
      "Train Epoch: 1380 [98560/118836 (83%)] Loss: 12274.285156\n",
      "    epoch          : 1380\n",
      "    loss           : 12247.016068936104\n",
      "    val_loss       : 12244.365621902993\n",
      "    val_log_likelihood: -12169.687120521869\n",
      "    val_log_marginal: -12177.793324257631\n",
      "Train Epoch: 1381 [256/118836 (0%)] Loss: 12299.908203\n",
      "Train Epoch: 1381 [33024/118836 (28%)] Loss: 12279.913086\n",
      "Train Epoch: 1381 [65792/118836 (55%)] Loss: 12274.126953\n",
      "Train Epoch: 1381 [98560/118836 (83%)] Loss: 12312.182617\n",
      "    epoch          : 1381\n",
      "    loss           : 12250.264468472136\n",
      "    val_loss       : 12248.451613480776\n",
      "    val_log_likelihood: -12170.13117875698\n",
      "    val_log_marginal: -12178.370175977234\n",
      "Train Epoch: 1382 [256/118836 (0%)] Loss: 12370.538086\n",
      "Train Epoch: 1382 [33024/118836 (28%)] Loss: 12282.100586\n",
      "Train Epoch: 1382 [65792/118836 (55%)] Loss: 12379.719727\n",
      "Train Epoch: 1382 [98560/118836 (83%)] Loss: 12236.478516\n",
      "    epoch          : 1382\n",
      "    loss           : 12244.39142111249\n",
      "    val_loss       : 12247.406577271406\n",
      "    val_log_likelihood: -12170.570626066223\n",
      "    val_log_marginal: -12178.494535401265\n",
      "Train Epoch: 1383 [256/118836 (0%)] Loss: 12198.315430\n",
      "Train Epoch: 1383 [33024/118836 (28%)] Loss: 12263.730469\n",
      "Train Epoch: 1383 [65792/118836 (55%)] Loss: 12245.755859\n",
      "Train Epoch: 1383 [98560/118836 (83%)] Loss: 12277.744141\n",
      "    epoch          : 1383\n",
      "    loss           : 12245.44097539935\n",
      "    val_loss       : 12244.481098591297\n",
      "    val_log_likelihood: -12170.761570286653\n",
      "    val_log_marginal: -12178.823482249107\n",
      "Train Epoch: 1384 [256/118836 (0%)] Loss: 12315.700195\n",
      "Train Epoch: 1384 [33024/118836 (28%)] Loss: 12220.298828\n",
      "Train Epoch: 1384 [65792/118836 (55%)] Loss: 12260.345703\n",
      "Train Epoch: 1384 [98560/118836 (83%)] Loss: 12209.566406\n",
      "    epoch          : 1384\n",
      "    loss           : 12245.827634537842\n",
      "    val_loss       : 12247.24264316214\n",
      "    val_log_likelihood: -12170.965706420595\n",
      "    val_log_marginal: -12179.085965603697\n",
      "Train Epoch: 1385 [256/118836 (0%)] Loss: 12205.766602\n",
      "Train Epoch: 1385 [33024/118836 (28%)] Loss: 12190.547852\n",
      "Train Epoch: 1385 [65792/118836 (55%)] Loss: 12245.085938\n",
      "Train Epoch: 1385 [98560/118836 (83%)] Loss: 12221.221680\n",
      "    epoch          : 1385\n",
      "    loss           : 12247.058732035774\n",
      "    val_loss       : 12244.535398827942\n",
      "    val_log_likelihood: -12171.60124053324\n",
      "    val_log_marginal: -12179.731502553936\n",
      "Train Epoch: 1386 [256/118836 (0%)] Loss: 12306.105469\n",
      "Train Epoch: 1386 [33024/118836 (28%)] Loss: 12227.375977\n",
      "Train Epoch: 1386 [65792/118836 (55%)] Loss: 12341.977539\n",
      "Train Epoch: 1386 [98560/118836 (83%)] Loss: 12247.767578\n",
      "    epoch          : 1386\n",
      "    loss           : 12245.331459851892\n",
      "    val_loss       : 12246.848054398584\n",
      "    val_log_likelihood: -12170.493179248087\n",
      "    val_log_marginal: -12178.498021433601\n",
      "Train Epoch: 1387 [256/118836 (0%)] Loss: 12174.964844\n",
      "Train Epoch: 1387 [33024/118836 (28%)] Loss: 12325.787109\n",
      "Train Epoch: 1387 [65792/118836 (55%)] Loss: 12269.009766\n",
      "Train Epoch: 1387 [98560/118836 (83%)] Loss: 12372.785156\n",
      "    epoch          : 1387\n",
      "    loss           : 12247.710155442257\n",
      "    val_loss       : 12248.568222310263\n",
      "    val_log_likelihood: -12170.167281198304\n",
      "    val_log_marginal: -12178.034706333237\n",
      "Train Epoch: 1388 [256/118836 (0%)] Loss: 12173.736328\n",
      "Train Epoch: 1388 [33024/118836 (28%)] Loss: 12354.462891\n",
      "Train Epoch: 1388 [65792/118836 (55%)] Loss: 12172.628906\n",
      "Train Epoch: 1388 [98560/118836 (83%)] Loss: 12226.380859\n",
      "    epoch          : 1388\n",
      "    loss           : 12249.07352780578\n",
      "    val_loss       : 12249.989300373483\n",
      "    val_log_likelihood: -12170.411471741883\n",
      "    val_log_marginal: -12178.50128774533\n",
      "Train Epoch: 1389 [256/118836 (0%)] Loss: 12228.033203\n",
      "Train Epoch: 1389 [33024/118836 (28%)] Loss: 12332.289062\n",
      "Train Epoch: 1389 [65792/118836 (55%)] Loss: 12319.556641\n",
      "Train Epoch: 1389 [98560/118836 (83%)] Loss: 12256.828125\n",
      "    epoch          : 1389\n",
      "    loss           : 12249.304288636013\n",
      "    val_loss       : 12245.618328501494\n",
      "    val_log_likelihood: -12170.25495147074\n",
      "    val_log_marginal: -12178.400775580194\n",
      "Train Epoch: 1390 [256/118836 (0%)] Loss: 12187.705078\n",
      "Train Epoch: 1390 [33024/118836 (28%)] Loss: 12329.209961\n",
      "Train Epoch: 1390 [65792/118836 (55%)] Loss: 12323.572266\n",
      "Train Epoch: 1390 [98560/118836 (83%)] Loss: 12256.171875\n",
      "    epoch          : 1390\n",
      "    loss           : 12246.213090783964\n",
      "    val_loss       : 12240.473084155725\n",
      "    val_log_likelihood: -12168.057388919045\n",
      "    val_log_marginal: -12175.839390370358\n",
      "Train Epoch: 1391 [256/118836 (0%)] Loss: 12266.228516\n",
      "Train Epoch: 1391 [33024/118836 (28%)] Loss: 12254.870117\n",
      "Train Epoch: 1391 [65792/118836 (55%)] Loss: 12274.860352\n",
      "Train Epoch: 1391 [98560/118836 (83%)] Loss: 12241.979492\n",
      "    epoch          : 1391\n",
      "    loss           : 12245.83202333411\n",
      "    val_loss       : 12245.089600598169\n",
      "    val_log_likelihood: -12170.402810141388\n",
      "    val_log_marginal: -12178.24636345763\n",
      "Train Epoch: 1392 [256/118836 (0%)] Loss: 12317.746094\n",
      "Train Epoch: 1392 [33024/118836 (28%)] Loss: 12347.539062\n",
      "Train Epoch: 1392 [65792/118836 (55%)] Loss: 12210.601562\n",
      "Train Epoch: 1392 [98560/118836 (83%)] Loss: 12246.267578\n",
      "    epoch          : 1392\n",
      "    loss           : 12248.252340195926\n",
      "    val_loss       : 12250.289926897902\n",
      "    val_log_likelihood: -12167.553841953577\n",
      "    val_log_marginal: -12175.49836661892\n",
      "Train Epoch: 1393 [256/118836 (0%)] Loss: 12206.029297\n",
      "Train Epoch: 1393 [33024/118836 (28%)] Loss: 12257.535156\n",
      "Train Epoch: 1393 [65792/118836 (55%)] Loss: 12262.016602\n",
      "Train Epoch: 1393 [98560/118836 (83%)] Loss: 12327.852539\n",
      "    epoch          : 1393\n",
      "    loss           : 12243.312405978599\n",
      "    val_loss       : 12248.56907721937\n",
      "    val_log_likelihood: -12170.846653839691\n",
      "    val_log_marginal: -12179.179626071169\n",
      "Train Epoch: 1394 [256/118836 (0%)] Loss: 12260.923828\n",
      "Train Epoch: 1394 [33024/118836 (28%)] Loss: 12271.595703\n",
      "Train Epoch: 1394 [65792/118836 (55%)] Loss: 12291.939453\n",
      "Train Epoch: 1394 [98560/118836 (83%)] Loss: 12219.626953\n",
      "    epoch          : 1394\n",
      "    loss           : 12246.591407542392\n",
      "    val_loss       : 12247.909624077893\n",
      "    val_log_likelihood: -12171.321348027814\n",
      "    val_log_marginal: -12179.460695497144\n",
      "Train Epoch: 1395 [256/118836 (0%)] Loss: 12324.942383\n",
      "Train Epoch: 1395 [33024/118836 (28%)] Loss: 12342.018555\n",
      "Train Epoch: 1395 [65792/118836 (55%)] Loss: 12262.227539\n",
      "Train Epoch: 1395 [98560/118836 (83%)] Loss: 12314.074219\n",
      "    epoch          : 1395\n",
      "    loss           : 12246.691392033705\n",
      "    val_loss       : 12246.209353138696\n",
      "    val_log_likelihood: -12170.418721405862\n",
      "    val_log_marginal: -12178.4531491845\n",
      "Train Epoch: 1396 [256/118836 (0%)] Loss: 12206.498047\n",
      "Train Epoch: 1396 [33024/118836 (28%)] Loss: 12223.681641\n",
      "Train Epoch: 1396 [65792/118836 (55%)] Loss: 12303.281250\n",
      "Train Epoch: 1396 [98560/118836 (83%)] Loss: 12203.514648\n",
      "    epoch          : 1396\n",
      "    loss           : 12248.60288655397\n",
      "    val_loss       : 12244.492951932187\n",
      "    val_log_likelihood: -12169.227953112075\n",
      "    val_log_marginal: -12177.135995106973\n",
      "Train Epoch: 1397 [256/118836 (0%)] Loss: 12211.720703\n",
      "Train Epoch: 1397 [33024/118836 (28%)] Loss: 12345.409180\n",
      "Train Epoch: 1397 [65792/118836 (55%)] Loss: 12384.617188\n",
      "Train Epoch: 1397 [98560/118836 (83%)] Loss: 12255.144531\n",
      "    epoch          : 1397\n",
      "    loss           : 12246.128565705128\n",
      "    val_loss       : 12242.609193061755\n",
      "    val_log_likelihood: -12171.158689225342\n",
      "    val_log_marginal: -12179.040008114489\n",
      "Train Epoch: 1398 [256/118836 (0%)] Loss: 12230.407227\n",
      "Train Epoch: 1398 [33024/118836 (28%)] Loss: 12279.517578\n",
      "Train Epoch: 1398 [65792/118836 (55%)] Loss: 12245.148438\n",
      "Train Epoch: 1398 [98560/118836 (83%)] Loss: 12239.783203\n",
      "    epoch          : 1398\n",
      "    loss           : 12245.374424563171\n",
      "    val_loss       : 12243.44716670416\n",
      "    val_log_likelihood: -12170.358755944995\n",
      "    val_log_marginal: -12178.353317385354\n",
      "Train Epoch: 1399 [256/118836 (0%)] Loss: 12293.797852\n",
      "Train Epoch: 1399 [33024/118836 (28%)] Loss: 12230.495117\n",
      "Train Epoch: 1399 [65792/118836 (55%)] Loss: 12266.697266\n",
      "Train Epoch: 1399 [98560/118836 (83%)] Loss: 12204.256836\n",
      "    epoch          : 1399\n",
      "    loss           : 12247.693487806297\n",
      "    val_loss       : 12245.344160814491\n",
      "    val_log_likelihood: -12173.15260788229\n",
      "    val_log_marginal: -12181.196535414218\n",
      "Train Epoch: 1400 [256/118836 (0%)] Loss: 12286.600586\n",
      "Train Epoch: 1400 [33024/118836 (28%)] Loss: 12227.013672\n",
      "Train Epoch: 1400 [65792/118836 (55%)] Loss: 12363.011719\n",
      "Train Epoch: 1400 [98560/118836 (83%)] Loss: 12187.312500\n",
      "    epoch          : 1400\n",
      "    loss           : 12242.86824209057\n",
      "    val_loss       : 12246.572432869485\n",
      "    val_log_likelihood: -12170.433896169356\n",
      "    val_log_marginal: -12178.492639684506\n",
      "Saving checkpoint: saved/models/SelfiesAutoencodingOperad/0905_154251/checkpoint-epoch1400.pth ...\n",
      "Train Epoch: 1401 [256/118836 (0%)] Loss: 12194.812500\n",
      "Train Epoch: 1401 [33024/118836 (28%)] Loss: 12230.146484\n",
      "Train Epoch: 1401 [65792/118836 (55%)] Loss: 12249.994141\n",
      "Train Epoch: 1401 [98560/118836 (83%)] Loss: 12243.652344\n",
      "    epoch          : 1401\n",
      "    loss           : 12245.576054752119\n",
      "    val_loss       : 12247.971192602676\n",
      "    val_log_likelihood: -12169.757989880583\n",
      "    val_log_marginal: -12177.787173808836\n",
      "Train Epoch: 1402 [256/118836 (0%)] Loss: 12258.566406\n",
      "Train Epoch: 1402 [33024/118836 (28%)] Loss: 12271.750000\n",
      "Train Epoch: 1402 [65792/118836 (55%)] Loss: 12308.998047\n",
      "Train Epoch: 1402 [98560/118836 (83%)] Loss: 12381.746094\n",
      "    epoch          : 1402\n",
      "    loss           : 12249.418744991988\n",
      "    val_loss       : 12246.37891843856\n",
      "    val_log_likelihood: -12171.128525802575\n",
      "    val_log_marginal: -12179.138279941571\n",
      "Train Epoch: 1403 [256/118836 (0%)] Loss: 12200.935547\n",
      "Train Epoch: 1403 [33024/118836 (28%)] Loss: 12299.685547\n",
      "Train Epoch: 1403 [65792/118836 (55%)] Loss: 12422.380859\n",
      "Train Epoch: 1403 [98560/118836 (83%)] Loss: 12195.960938\n",
      "    epoch          : 1403\n",
      "    loss           : 12253.491817391698\n",
      "    val_loss       : 12250.595019672965\n",
      "    val_log_likelihood: -12171.466092683777\n",
      "    val_log_marginal: -12179.738180987924\n",
      "Train Epoch: 1404 [256/118836 (0%)] Loss: 12264.780273\n",
      "Train Epoch: 1404 [33024/118836 (28%)] Loss: 12251.213867\n",
      "Train Epoch: 1404 [65792/118836 (55%)] Loss: 12243.583984\n",
      "Train Epoch: 1404 [98560/118836 (83%)] Loss: 12199.392578\n",
      "    epoch          : 1404\n",
      "    loss           : 12251.011777069118\n",
      "    val_loss       : 12245.641257893933\n",
      "    val_log_likelihood: -12168.74777353443\n",
      "    val_log_marginal: -12176.70499201478\n",
      "Train Epoch: 1405 [256/118836 (0%)] Loss: 12251.448242\n",
      "Train Epoch: 1405 [33024/118836 (28%)] Loss: 12246.741211\n",
      "Train Epoch: 1405 [65792/118836 (55%)] Loss: 12214.203125\n",
      "Train Epoch: 1405 [98560/118836 (83%)] Loss: 12276.356445\n",
      "    epoch          : 1405\n",
      "    loss           : 12246.997575152502\n",
      "    val_loss       : 12245.938881284013\n",
      "    val_log_likelihood: -12169.469350315345\n",
      "    val_log_marginal: -12177.53148283282\n",
      "Train Epoch: 1406 [256/118836 (0%)] Loss: 12243.461914\n",
      "Train Epoch: 1406 [33024/118836 (28%)] Loss: 12221.041016\n",
      "Train Epoch: 1406 [65792/118836 (55%)] Loss: 12245.446289\n",
      "Train Epoch: 1406 [98560/118836 (83%)] Loss: 12293.736328\n",
      "    epoch          : 1406\n",
      "    loss           : 12248.6547345107\n",
      "    val_loss       : 12251.457628639599\n",
      "    val_log_likelihood: -12172.159788403382\n",
      "    val_log_marginal: -12180.623320060391\n",
      "Train Epoch: 1407 [256/118836 (0%)] Loss: 12296.238281\n",
      "Train Epoch: 1407 [33024/118836 (28%)] Loss: 12230.576172\n",
      "Train Epoch: 1407 [65792/118836 (55%)] Loss: 12222.476562\n",
      "Train Epoch: 1407 [98560/118836 (83%)] Loss: 12269.744141\n",
      "    epoch          : 1407\n",
      "    loss           : 12246.697358515561\n",
      "    val_loss       : 12253.997768774529\n",
      "    val_log_likelihood: -12169.488779789597\n",
      "    val_log_marginal: -12177.734684443489\n",
      "Train Epoch: 1408 [256/118836 (0%)] Loss: 12278.351562\n",
      "Train Epoch: 1408 [33024/118836 (28%)] Loss: 12201.393555\n",
      "Train Epoch: 1408 [65792/118836 (55%)] Loss: 12341.670898\n",
      "Train Epoch: 1408 [98560/118836 (83%)] Loss: 12376.921875\n",
      "    epoch          : 1408\n",
      "    loss           : 12245.133997945099\n",
      "    val_loss       : 12245.395309744667\n",
      "    val_log_likelihood: -12169.96892657284\n",
      "    val_log_marginal: -12177.921237941126\n",
      "Train Epoch: 1409 [256/118836 (0%)] Loss: 12279.343750\n",
      "Train Epoch: 1409 [33024/118836 (28%)] Loss: 12241.437500\n",
      "Train Epoch: 1409 [65792/118836 (55%)] Loss: 12294.554688\n",
      "Train Epoch: 1409 [98560/118836 (83%)] Loss: 12292.922852\n",
      "    epoch          : 1409\n",
      "    loss           : 12244.320182453215\n",
      "    val_loss       : 12246.13719977106\n",
      "    val_log_likelihood: -12169.916776842949\n",
      "    val_log_marginal: -12177.942957376756\n",
      "Train Epoch: 1410 [256/118836 (0%)] Loss: 12241.717773\n",
      "Train Epoch: 1410 [33024/118836 (28%)] Loss: 12251.738281\n",
      "Train Epoch: 1410 [65792/118836 (55%)] Loss: 12314.071289\n",
      "Train Epoch: 1410 [98560/118836 (83%)] Loss: 12388.432617\n",
      "    epoch          : 1410\n",
      "    loss           : 12251.678383478082\n",
      "    val_loss       : 12244.645056139874\n",
      "    val_log_likelihood: -12171.338792228857\n",
      "    val_log_marginal: -12179.5310690598\n",
      "Train Epoch: 1411 [256/118836 (0%)] Loss: 12189.344727\n",
      "Train Epoch: 1411 [33024/118836 (28%)] Loss: 12239.844727\n",
      "Train Epoch: 1411 [65792/118836 (55%)] Loss: 12249.345703\n",
      "Train Epoch: 1411 [98560/118836 (83%)] Loss: 12305.841797\n",
      "    epoch          : 1411\n",
      "    loss           : 12246.282572438482\n",
      "    val_loss       : 12244.288613260383\n",
      "    val_log_likelihood: -12171.68066939361\n",
      "    val_log_marginal: -12179.97279210261\n",
      "Train Epoch: 1412 [256/118836 (0%)] Loss: 12280.294922\n",
      "Train Epoch: 1412 [33024/118836 (28%)] Loss: 12327.033203\n",
      "Train Epoch: 1412 [65792/118836 (55%)] Loss: 12251.945312\n",
      "Train Epoch: 1412 [98560/118836 (83%)] Loss: 12212.971680\n",
      "    epoch          : 1412\n",
      "    loss           : 12247.326278174112\n",
      "    val_loss       : 12247.98951817698\n",
      "    val_log_likelihood: -12171.1885507134\n",
      "    val_log_marginal: -12179.103976105293\n",
      "Train Epoch: 1413 [256/118836 (0%)] Loss: 12248.762695\n",
      "Train Epoch: 1413 [33024/118836 (28%)] Loss: 12332.159180\n",
      "Train Epoch: 1413 [65792/118836 (55%)] Loss: 12205.750000\n",
      "Train Epoch: 1413 [98560/118836 (83%)] Loss: 12243.151367\n",
      "    epoch          : 1413\n",
      "    loss           : 12247.83259844784\n",
      "    val_loss       : 12244.158941750948\n",
      "    val_log_likelihood: -12170.490136637975\n",
      "    val_log_marginal: -12178.602034829333\n",
      "Train Epoch: 1414 [256/118836 (0%)] Loss: 12284.132812\n",
      "Train Epoch: 1414 [33024/118836 (28%)] Loss: 12189.859375\n",
      "Train Epoch: 1414 [65792/118836 (55%)] Loss: 12194.060547\n",
      "Train Epoch: 1414 [98560/118836 (83%)] Loss: 12252.609375\n",
      "    epoch          : 1414\n",
      "    loss           : 12244.987443296372\n",
      "    val_loss       : 12259.936260462131\n",
      "    val_log_likelihood: -12170.39774897901\n",
      "    val_log_marginal: -12178.675886210622\n",
      "Train Epoch: 1415 [256/118836 (0%)] Loss: 12293.470703\n",
      "Train Epoch: 1415 [33024/118836 (28%)] Loss: 12218.715820\n",
      "Train Epoch: 1415 [65792/118836 (55%)] Loss: 12307.516602\n",
      "Train Epoch: 1415 [98560/118836 (83%)] Loss: 12274.733398\n",
      "    epoch          : 1415\n",
      "    loss           : 12246.905343549679\n",
      "    val_loss       : 12242.2156046501\n",
      "    val_log_likelihood: -12172.212038939722\n",
      "    val_log_marginal: -12180.250911737647\n",
      "Train Epoch: 1416 [256/118836 (0%)] Loss: 12244.660156\n",
      "Train Epoch: 1416 [33024/118836 (28%)] Loss: 12281.244141\n",
      "Train Epoch: 1416 [65792/118836 (55%)] Loss: 12243.006836\n",
      "Train Epoch: 1416 [98560/118836 (83%)] Loss: 12349.532227\n",
      "    epoch          : 1416\n",
      "    loss           : 12247.080881991833\n",
      "    val_loss       : 12258.131980885357\n",
      "    val_log_likelihood: -12172.190981699752\n",
      "    val_log_marginal: -12180.543991740535\n",
      "Train Epoch: 1417 [256/118836 (0%)] Loss: 12243.425781\n",
      "Train Epoch: 1417 [33024/118836 (28%)] Loss: 12202.471680\n",
      "Train Epoch: 1417 [65792/118836 (55%)] Loss: 12302.675781\n",
      "Train Epoch: 1417 [98560/118836 (83%)] Loss: 12204.121094\n",
      "    epoch          : 1417\n",
      "    loss           : 12245.414809501654\n",
      "    val_loss       : 12244.155926252712\n",
      "    val_log_likelihood: -12171.354029511735\n",
      "    val_log_marginal: -12179.358400337956\n",
      "Train Epoch: 1418 [256/118836 (0%)] Loss: 12233.863281\n",
      "Train Epoch: 1418 [33024/118836 (28%)] Loss: 12300.228516\n",
      "Train Epoch: 1418 [65792/118836 (55%)] Loss: 12294.912109\n",
      "Train Epoch: 1418 [98560/118836 (83%)] Loss: 12234.923828\n",
      "    epoch          : 1418\n",
      "    loss           : 12247.778082674215\n",
      "    val_loss       : 12245.925574601666\n",
      "    val_log_likelihood: -12169.410395342225\n",
      "    val_log_marginal: -12177.378785476272\n",
      "Train Epoch: 1419 [256/118836 (0%)] Loss: 12378.571289\n",
      "Train Epoch: 1419 [33024/118836 (28%)] Loss: 12323.638672\n",
      "Train Epoch: 1419 [65792/118836 (55%)] Loss: 12223.632812\n",
      "Train Epoch: 1419 [98560/118836 (83%)] Loss: 12207.018555\n",
      "    epoch          : 1419\n",
      "    loss           : 12254.518063740694\n",
      "    val_loss       : 12253.741107247912\n",
      "    val_log_likelihood: -12170.294115908033\n",
      "    val_log_marginal: -12178.808717407881\n",
      "Train Epoch: 1420 [256/118836 (0%)] Loss: 12412.804688\n",
      "Train Epoch: 1420 [33024/118836 (28%)] Loss: 12202.594727\n",
      "Train Epoch: 1420 [65792/118836 (55%)] Loss: 12291.155273\n",
      "Train Epoch: 1420 [98560/118836 (83%)] Loss: 12382.878906\n",
      "    epoch          : 1420\n",
      "    loss           : 12250.424096296008\n",
      "    val_loss       : 12243.955229766785\n",
      "    val_log_likelihood: -12166.971549317617\n",
      "    val_log_marginal: -12175.035392477768\n",
      "Train Epoch: 1421 [256/118836 (0%)] Loss: 12230.538086\n",
      "Train Epoch: 1421 [33024/118836 (28%)] Loss: 12209.608398\n",
      "Train Epoch: 1421 [65792/118836 (55%)] Loss: 12251.841797\n",
      "Train Epoch: 1421 [98560/118836 (83%)] Loss: 12191.397461\n",
      "    epoch          : 1421\n",
      "    loss           : 12249.56358156922\n",
      "    val_loss       : 12248.506947010643\n",
      "    val_log_likelihood: -12170.132423490488\n",
      "    val_log_marginal: -12178.220524167069\n",
      "Train Epoch: 1422 [256/118836 (0%)] Loss: 12268.183594\n",
      "Train Epoch: 1422 [33024/118836 (28%)] Loss: 12303.849609\n",
      "Train Epoch: 1422 [65792/118836 (55%)] Loss: 12228.039062\n",
      "Train Epoch: 1422 [98560/118836 (83%)] Loss: 12241.798828\n",
      "    epoch          : 1422\n",
      "    loss           : 12245.704411897746\n",
      "    val_loss       : 12245.007198576935\n",
      "    val_log_likelihood: -12170.465607229633\n",
      "    val_log_marginal: -12178.902003646532\n",
      "Train Epoch: 1423 [256/118836 (0%)] Loss: 12297.791016\n",
      "Train Epoch: 1423 [33024/118836 (28%)] Loss: 12270.162109\n",
      "Train Epoch: 1423 [65792/118836 (55%)] Loss: 12207.904297\n",
      "Train Epoch: 1423 [98560/118836 (83%)] Loss: 12183.601562\n",
      "    epoch          : 1423\n",
      "    loss           : 12248.811620205232\n",
      "    val_loss       : 12248.057965786029\n",
      "    val_log_likelihood: -12169.291968601376\n",
      "    val_log_marginal: -12177.454241700649\n",
      "Train Epoch: 1424 [256/118836 (0%)] Loss: 12262.392578\n",
      "Train Epoch: 1424 [33024/118836 (28%)] Loss: 12180.549805\n",
      "Train Epoch: 1424 [65792/118836 (55%)] Loss: 12320.580078\n",
      "Train Epoch: 1424 [98560/118836 (83%)] Loss: 12263.472656\n",
      "    epoch          : 1424\n",
      "    loss           : 12246.62882531405\n",
      "    val_loss       : 12251.17224112679\n",
      "    val_log_likelihood: -12170.3513671875\n",
      "    val_log_marginal: -12178.452832349874\n",
      "Train Epoch: 1425 [256/118836 (0%)] Loss: 12178.123047\n",
      "Train Epoch: 1425 [33024/118836 (28%)] Loss: 12239.538086\n",
      "Train Epoch: 1425 [65792/118836 (55%)] Loss: 12288.083984\n",
      "Train Epoch: 1425 [98560/118836 (83%)] Loss: 12302.713867\n",
      "    epoch          : 1425\n",
      "    loss           : 12247.013635849618\n",
      "    val_loss       : 12245.95817763815\n",
      "    val_log_likelihood: -12169.135674498553\n",
      "    val_log_marginal: -12176.9950986965\n",
      "Train Epoch: 1426 [256/118836 (0%)] Loss: 12237.808594\n",
      "Train Epoch: 1426 [33024/118836 (28%)] Loss: 12299.570312\n",
      "Train Epoch: 1426 [65792/118836 (55%)] Loss: 12347.492188\n",
      "Train Epoch: 1426 [98560/118836 (83%)] Loss: 12214.175781\n",
      "    epoch          : 1426\n",
      "    loss           : 12240.77632163074\n",
      "    val_loss       : 12247.61521180186\n",
      "    val_log_likelihood: -12170.618930288463\n",
      "    val_log_marginal: -12178.812110342604\n",
      "Train Epoch: 1427 [256/118836 (0%)] Loss: 12217.490234\n",
      "Train Epoch: 1427 [33024/118836 (28%)] Loss: 12256.381836\n",
      "Train Epoch: 1427 [65792/118836 (55%)] Loss: 12229.380859\n",
      "Train Epoch: 1427 [98560/118836 (83%)] Loss: 12301.840820\n",
      "    epoch          : 1427\n",
      "    loss           : 12247.092529175712\n",
      "    val_loss       : 12246.622438529648\n",
      "    val_log_likelihood: -12169.782568561312\n",
      "    val_log_marginal: -12177.78405049825\n",
      "Train Epoch: 1428 [256/118836 (0%)] Loss: 12282.998047\n",
      "Train Epoch: 1428 [33024/118836 (28%)] Loss: 12229.529297\n",
      "Train Epoch: 1428 [65792/118836 (55%)] Loss: 12195.078125\n",
      "Train Epoch: 1428 [98560/118836 (83%)] Loss: 12278.981445\n",
      "    epoch          : 1428\n",
      "    loss           : 12244.201169774866\n",
      "    val_loss       : 12245.186191395265\n",
      "    val_log_likelihood: -12169.881489899968\n",
      "    val_log_marginal: -12177.866128841924\n",
      "Train Epoch: 1429 [256/118836 (0%)] Loss: 12302.960938\n",
      "Train Epoch: 1429 [33024/118836 (28%)] Loss: 12149.669922\n",
      "Train Epoch: 1429 [65792/118836 (55%)] Loss: 12319.525391\n",
      "Train Epoch: 1429 [98560/118836 (83%)] Loss: 12235.419922\n",
      "    epoch          : 1429\n",
      "    loss           : 12242.238994164856\n",
      "    val_loss       : 12248.113945042933\n",
      "    val_log_likelihood: -12170.543360505842\n",
      "    val_log_marginal: -12178.491029009901\n",
      "Train Epoch: 1430 [256/118836 (0%)] Loss: 12304.336914\n",
      "Train Epoch: 1430 [33024/118836 (28%)] Loss: 12440.326172\n",
      "Train Epoch: 1430 [65792/118836 (55%)] Loss: 12238.548828\n",
      "Train Epoch: 1430 [98560/118836 (83%)] Loss: 12254.116211\n",
      "    epoch          : 1430\n",
      "    loss           : 12247.706093620762\n",
      "    val_loss       : 12245.896759607744\n",
      "    val_log_likelihood: -12170.803262801128\n",
      "    val_log_marginal: -12178.694199914968\n",
      "Train Epoch: 1431 [256/118836 (0%)] Loss: 12313.416992\n",
      "Train Epoch: 1431 [33024/118836 (28%)] Loss: 12288.600586\n",
      "Train Epoch: 1431 [65792/118836 (55%)] Loss: 12271.151367\n",
      "Train Epoch: 1431 [98560/118836 (83%)] Loss: 12261.407227\n",
      "    epoch          : 1431\n",
      "    loss           : 12244.672436220533\n",
      "    val_loss       : 12242.755952841577\n",
      "    val_log_likelihood: -12170.413253463606\n",
      "    val_log_marginal: -12178.397818237765\n",
      "Train Epoch: 1432 [256/118836 (0%)] Loss: 12261.977539\n",
      "Train Epoch: 1432 [33024/118836 (28%)] Loss: 12271.333008\n",
      "Train Epoch: 1432 [65792/118836 (55%)] Loss: 12255.792969\n",
      "Train Epoch: 1432 [98560/118836 (83%)] Loss: 12295.825195\n",
      "    epoch          : 1432\n",
      "    loss           : 12245.012416640819\n",
      "    val_loss       : 12248.199706996418\n",
      "    val_log_likelihood: -12168.563194013648\n",
      "    val_log_marginal: -12176.48156678413\n",
      "Train Epoch: 1433 [256/118836 (0%)] Loss: 12226.087891\n",
      "Train Epoch: 1433 [33024/118836 (28%)] Loss: 12220.806641\n",
      "Train Epoch: 1433 [65792/118836 (55%)] Loss: 12274.267578\n",
      "Train Epoch: 1433 [98560/118836 (83%)] Loss: 12165.910156\n",
      "    epoch          : 1433\n",
      "    loss           : 12248.343767124172\n",
      "    val_loss       : 12250.360697752729\n",
      "    val_log_likelihood: -12171.456186349773\n",
      "    val_log_marginal: -12179.929020599451\n",
      "Train Epoch: 1434 [256/118836 (0%)] Loss: 12242.332031\n",
      "Train Epoch: 1434 [33024/118836 (28%)] Loss: 12265.431641\n",
      "Train Epoch: 1434 [65792/118836 (55%)] Loss: 12296.903320\n",
      "Train Epoch: 1434 [98560/118836 (83%)] Loss: 12273.652344\n",
      "    epoch          : 1434\n",
      "    loss           : 12242.295722187759\n",
      "    val_loss       : 12244.639997708717\n",
      "    val_log_likelihood: -12169.740802703682\n",
      "    val_log_marginal: -12177.90091789914\n",
      "Train Epoch: 1435 [256/118836 (0%)] Loss: 12274.545898\n",
      "Train Epoch: 1435 [33024/118836 (28%)] Loss: 12302.949219\n",
      "Train Epoch: 1435 [65792/118836 (55%)] Loss: 12353.040039\n",
      "Train Epoch: 1435 [98560/118836 (83%)] Loss: 12207.514648\n",
      "    epoch          : 1435\n",
      "    loss           : 12247.830163422768\n",
      "    val_loss       : 12246.033973628017\n",
      "    val_log_likelihood: -12170.489656838037\n",
      "    val_log_marginal: -12178.5254940436\n",
      "Train Epoch: 1436 [256/118836 (0%)] Loss: 12315.452148\n",
      "Train Epoch: 1436 [33024/118836 (28%)] Loss: 12350.655273\n",
      "Train Epoch: 1436 [65792/118836 (55%)] Loss: 12312.072266\n",
      "Train Epoch: 1436 [98560/118836 (83%)] Loss: 12271.664062\n",
      "    epoch          : 1436\n",
      "    loss           : 12250.480920763544\n",
      "    val_loss       : 12250.613125207285\n",
      "    val_log_likelihood: -12172.810198737334\n",
      "    val_log_marginal: -12181.021434338601\n",
      "Train Epoch: 1437 [256/118836 (0%)] Loss: 12212.589844\n",
      "Train Epoch: 1437 [33024/118836 (28%)] Loss: 12233.533203\n",
      "Train Epoch: 1437 [65792/118836 (55%)] Loss: 12218.798828\n",
      "Train Epoch: 1437 [98560/118836 (83%)] Loss: 12242.074219\n",
      "    epoch          : 1437\n",
      "    loss           : 12247.466536296784\n",
      "    val_loss       : 12243.005833577487\n",
      "    val_log_likelihood: -12170.453466191067\n",
      "    val_log_marginal: -12178.531203066896\n",
      "Train Epoch: 1438 [256/118836 (0%)] Loss: 12255.045898\n",
      "Train Epoch: 1438 [33024/118836 (28%)] Loss: 12228.726562\n",
      "Train Epoch: 1438 [65792/118836 (55%)] Loss: 12254.853516\n",
      "Train Epoch: 1438 [98560/118836 (83%)] Loss: 12216.190430\n",
      "    epoch          : 1438\n",
      "    loss           : 12245.206975515663\n",
      "    val_loss       : 12247.153742733319\n",
      "    val_log_likelihood: -12168.998602279777\n",
      "    val_log_marginal: -12176.961886325475\n",
      "Train Epoch: 1439 [256/118836 (0%)] Loss: 12343.519531\n",
      "Train Epoch: 1439 [33024/118836 (28%)] Loss: 12242.467773\n",
      "Train Epoch: 1439 [65792/118836 (55%)] Loss: 12215.413086\n",
      "Train Epoch: 1439 [98560/118836 (83%)] Loss: 12294.746094\n",
      "    epoch          : 1439\n",
      "    loss           : 12248.970760313276\n",
      "    val_loss       : 12247.812637244962\n",
      "    val_log_likelihood: -12169.51982236094\n",
      "    val_log_marginal: -12177.57308051646\n",
      "Train Epoch: 1440 [256/118836 (0%)] Loss: 12374.978516\n",
      "Train Epoch: 1440 [33024/118836 (28%)] Loss: 12312.345703\n",
      "Train Epoch: 1440 [65792/118836 (55%)] Loss: 12273.653320\n",
      "Train Epoch: 1440 [98560/118836 (83%)] Loss: 12273.529297\n",
      "    epoch          : 1440\n",
      "    loss           : 12244.500287879964\n",
      "    val_loss       : 12246.200421033805\n",
      "    val_log_likelihood: -12168.505958242866\n",
      "    val_log_marginal: -12176.79087100531\n",
      "Train Epoch: 1441 [256/118836 (0%)] Loss: 12220.607422\n",
      "Train Epoch: 1441 [33024/118836 (28%)] Loss: 12322.069336\n",
      "Train Epoch: 1441 [65792/118836 (55%)] Loss: 12295.369141\n",
      "Train Epoch: 1441 [98560/118836 (83%)] Loss: 12287.371094\n",
      "    epoch          : 1441\n",
      "    loss           : 12244.884040270887\n",
      "    val_loss       : 12251.14196603751\n",
      "    val_log_likelihood: -12169.08363171397\n",
      "    val_log_marginal: -12177.169223354818\n",
      "Train Epoch: 1442 [256/118836 (0%)] Loss: 12307.617188\n",
      "Train Epoch: 1442 [33024/118836 (28%)] Loss: 12335.835938\n",
      "Train Epoch: 1442 [65792/118836 (55%)] Loss: 12181.322266\n",
      "Train Epoch: 1442 [98560/118836 (83%)] Loss: 12237.361328\n",
      "    epoch          : 1442\n",
      "    loss           : 12247.186311647021\n",
      "    val_loss       : 12247.141413249961\n",
      "    val_log_likelihood: -12168.80262403717\n",
      "    val_log_marginal: -12176.857780445316\n",
      "Train Epoch: 1443 [256/118836 (0%)] Loss: 12247.901367\n",
      "Train Epoch: 1443 [33024/118836 (28%)] Loss: 12242.765625\n",
      "Train Epoch: 1443 [65792/118836 (55%)] Loss: 12266.437500\n",
      "Train Epoch: 1443 [98560/118836 (83%)] Loss: 12213.706055\n",
      "    epoch          : 1443\n",
      "    loss           : 12246.064468633684\n",
      "    val_loss       : 12246.686559566999\n",
      "    val_log_likelihood: -12170.59942617866\n",
      "    val_log_marginal: -12178.583237809255\n",
      "Train Epoch: 1444 [256/118836 (0%)] Loss: 12272.226562\n",
      "Train Epoch: 1444 [33024/118836 (28%)] Loss: 12315.431641\n",
      "Train Epoch: 1444 [65792/118836 (55%)] Loss: 12385.178711\n",
      "Train Epoch: 1444 [98560/118836 (83%)] Loss: 12354.458984\n",
      "    epoch          : 1444\n",
      "    loss           : 12249.0059133323\n",
      "    val_loss       : 12244.865509880305\n",
      "    val_log_likelihood: -12170.026445054022\n",
      "    val_log_marginal: -12178.250586188007\n",
      "Train Epoch: 1445 [256/118836 (0%)] Loss: 12244.781250\n",
      "Train Epoch: 1445 [33024/118836 (28%)] Loss: 12196.639648\n",
      "Train Epoch: 1445 [65792/118836 (55%)] Loss: 12320.699219\n",
      "Train Epoch: 1445 [98560/118836 (83%)] Loss: 12293.789062\n",
      "    epoch          : 1445\n",
      "    loss           : 12249.649796448512\n",
      "    val_loss       : 12250.135368303774\n",
      "    val_log_likelihood: -12169.920540122259\n",
      "    val_log_marginal: -12178.00594818979\n",
      "Train Epoch: 1446 [256/118836 (0%)] Loss: 12281.469727\n",
      "Train Epoch: 1446 [33024/118836 (28%)] Loss: 12217.845703\n",
      "Train Epoch: 1446 [65792/118836 (55%)] Loss: 12206.251953\n",
      "Train Epoch: 1446 [98560/118836 (83%)] Loss: 12245.743164\n",
      "    epoch          : 1446\n",
      "    loss           : 12248.75035702285\n",
      "    val_loss       : 12242.686527227812\n",
      "    val_log_likelihood: -12167.527187693859\n",
      "    val_log_marginal: -12175.590041363259\n",
      "Train Epoch: 1447 [256/118836 (0%)] Loss: 12191.556641\n",
      "Train Epoch: 1447 [33024/118836 (28%)] Loss: 12287.155273\n",
      "Train Epoch: 1447 [65792/118836 (55%)] Loss: 12265.696289\n",
      "Train Epoch: 1447 [98560/118836 (83%)] Loss: 12290.175781\n",
      "    epoch          : 1447\n",
      "    loss           : 12246.607797960609\n",
      "    val_loss       : 12247.874689932756\n",
      "    val_log_likelihood: -12167.89217813017\n",
      "    val_log_marginal: -12175.9806539378\n",
      "Train Epoch: 1448 [256/118836 (0%)] Loss: 12346.296875\n",
      "Train Epoch: 1448 [33024/118836 (28%)] Loss: 12168.818359\n",
      "Train Epoch: 1448 [65792/118836 (55%)] Loss: 12282.946289\n",
      "Train Epoch: 1448 [98560/118836 (83%)] Loss: 12342.278320\n",
      "    epoch          : 1448\n",
      "    loss           : 12245.842792015614\n",
      "    val_loss       : 12248.15884191216\n",
      "    val_log_likelihood: -12170.338093530294\n",
      "    val_log_marginal: -12178.56304107644\n",
      "Train Epoch: 1449 [256/118836 (0%)] Loss: 12223.496094\n",
      "Train Epoch: 1449 [33024/118836 (28%)] Loss: 12331.215820\n",
      "Train Epoch: 1449 [65792/118836 (55%)] Loss: 12257.399414\n",
      "Train Epoch: 1449 [98560/118836 (83%)] Loss: 12270.222656\n",
      "    epoch          : 1449\n",
      "    loss           : 12246.733237696442\n",
      "    val_loss       : 12247.752475638259\n",
      "    val_log_likelihood: -12170.888240055056\n",
      "    val_log_marginal: -12179.115275453089\n",
      "Train Epoch: 1450 [256/118836 (0%)] Loss: 12248.942383\n",
      "Train Epoch: 1450 [33024/118836 (28%)] Loss: 12261.744141\n",
      "Train Epoch: 1450 [65792/118836 (55%)] Loss: 12358.653320\n",
      "Train Epoch: 1450 [98560/118836 (83%)] Loss: 12307.335938\n",
      "    epoch          : 1450\n",
      "    loss           : 12240.851981719139\n",
      "    val_loss       : 12244.752756537004\n",
      "    val_log_likelihood: -12168.944609924265\n",
      "    val_log_marginal: -12176.93538908704\n",
      "Train Epoch: 1451 [256/118836 (0%)] Loss: 12213.746094\n",
      "Train Epoch: 1451 [33024/118836 (28%)] Loss: 12234.572266\n",
      "Train Epoch: 1451 [65792/118836 (55%)] Loss: 12237.093750\n",
      "Train Epoch: 1451 [98560/118836 (83%)] Loss: 12232.928711\n",
      "    epoch          : 1451\n",
      "    loss           : 12241.379797999381\n",
      "    val_loss       : 12239.815851878833\n",
      "    val_log_likelihood: -12168.68524510184\n",
      "    val_log_marginal: -12176.638398700297\n",
      "Train Epoch: 1452 [256/118836 (0%)] Loss: 12246.061523\n",
      "Train Epoch: 1452 [33024/118836 (28%)] Loss: 12256.587891\n",
      "Train Epoch: 1452 [65792/118836 (55%)] Loss: 12268.515625\n",
      "Train Epoch: 1452 [98560/118836 (83%)] Loss: 12241.652344\n",
      "    epoch          : 1452\n",
      "    loss           : 12242.726328900435\n",
      "    val_loss       : 12247.674212690223\n",
      "    val_log_likelihood: -12169.435226523728\n",
      "    val_log_marginal: -12177.54199981017\n",
      "Train Epoch: 1453 [256/118836 (0%)] Loss: 12274.683594\n",
      "Train Epoch: 1453 [33024/118836 (28%)] Loss: 12222.603516\n",
      "Train Epoch: 1453 [65792/118836 (55%)] Loss: 12243.741211\n",
      "Train Epoch: 1453 [98560/118836 (83%)] Loss: 12215.718750\n",
      "    epoch          : 1453\n",
      "    loss           : 12247.83530051308\n",
      "    val_loss       : 12240.823167047352\n",
      "    val_log_likelihood: -12170.264395613627\n",
      "    val_log_marginal: -12178.480150784222\n",
      "Train Epoch: 1454 [256/118836 (0%)] Loss: 12281.746094\n",
      "Train Epoch: 1454 [33024/118836 (28%)] Loss: 12233.210938\n",
      "Train Epoch: 1454 [65792/118836 (55%)] Loss: 12219.229492\n",
      "Train Epoch: 1454 [98560/118836 (83%)] Loss: 12366.961914\n",
      "    epoch          : 1454\n",
      "    loss           : 12243.75086622467\n",
      "    val_loss       : 12244.841671319742\n",
      "    val_log_likelihood: -12168.247677412894\n",
      "    val_log_marginal: -12176.367163885441\n",
      "Train Epoch: 1455 [256/118836 (0%)] Loss: 12240.834961\n",
      "Train Epoch: 1455 [33024/118836 (28%)] Loss: 12239.082031\n",
      "Train Epoch: 1455 [65792/118836 (55%)] Loss: 12245.358398\n",
      "Train Epoch: 1455 [98560/118836 (83%)] Loss: 12297.280273\n",
      "    epoch          : 1455\n",
      "    loss           : 12245.903703667804\n",
      "    val_loss       : 12246.04328720683\n",
      "    val_log_likelihood: -12168.241869087313\n",
      "    val_log_marginal: -12176.427242489175\n",
      "Train Epoch: 1456 [256/118836 (0%)] Loss: 12220.698242\n",
      "Train Epoch: 1456 [33024/118836 (28%)] Loss: 12313.641602\n",
      "Train Epoch: 1456 [65792/118836 (55%)] Loss: 12240.231445\n",
      "Train Epoch: 1456 [98560/118836 (83%)] Loss: 12259.073242\n",
      "    epoch          : 1456\n",
      "    loss           : 12243.711883368227\n",
      "    val_loss       : 12247.144871546576\n",
      "    val_log_likelihood: -12167.261553485578\n",
      "    val_log_marginal: -12175.393368006147\n",
      "Train Epoch: 1457 [256/118836 (0%)] Loss: 12138.040039\n",
      "Train Epoch: 1457 [33024/118836 (28%)] Loss: 12250.058594\n",
      "Train Epoch: 1457 [65792/118836 (55%)] Loss: 12224.199219\n",
      "Train Epoch: 1457 [98560/118836 (83%)] Loss: 12222.410156\n",
      "    epoch          : 1457\n",
      "    loss           : 12245.07398725057\n",
      "    val_loss       : 12254.958246581376\n",
      "    val_log_likelihood: -12167.952612728754\n",
      "    val_log_marginal: -12176.179539339842\n",
      "Train Epoch: 1458 [256/118836 (0%)] Loss: 12194.192383\n",
      "Train Epoch: 1458 [33024/118836 (28%)] Loss: 12281.478516\n",
      "Train Epoch: 1458 [65792/118836 (55%)] Loss: 12306.836914\n",
      "Train Epoch: 1458 [98560/118836 (83%)] Loss: 12204.499023\n",
      "    epoch          : 1458\n",
      "    loss           : 12245.1730806387\n",
      "    val_loss       : 12242.827714725543\n",
      "    val_log_likelihood: -12170.726849087572\n",
      "    val_log_marginal: -12178.715505096738\n",
      "Train Epoch: 1459 [256/118836 (0%)] Loss: 12197.506836\n",
      "Train Epoch: 1459 [33024/118836 (28%)] Loss: 12310.216797\n",
      "Train Epoch: 1459 [65792/118836 (55%)] Loss: 12295.769531\n",
      "Train Epoch: 1459 [98560/118836 (83%)] Loss: 12180.314453\n",
      "    epoch          : 1459\n",
      "    loss           : 12243.124035553661\n",
      "    val_loss       : 12246.98433862871\n",
      "    val_log_likelihood: -12168.969684559812\n",
      "    val_log_marginal: -12177.15475261163\n",
      "Train Epoch: 1460 [256/118836 (0%)] Loss: 12169.365234\n",
      "Train Epoch: 1460 [33024/118836 (28%)] Loss: 12254.978516\n",
      "Train Epoch: 1460 [65792/118836 (55%)] Loss: 12266.246094\n",
      "Train Epoch: 1460 [98560/118836 (83%)] Loss: 12234.855469\n",
      "    epoch          : 1460\n",
      "    loss           : 12243.988999334419\n",
      "    val_loss       : 12245.019783449818\n",
      "    val_log_likelihood: -12169.609591475393\n",
      "    val_log_marginal: -12177.824439883812\n",
      "Train Epoch: 1461 [256/118836 (0%)] Loss: 12221.095703\n",
      "Train Epoch: 1461 [33024/118836 (28%)] Loss: 12342.072266\n",
      "Train Epoch: 1461 [65792/118836 (55%)] Loss: 12227.181641\n",
      "Train Epoch: 1461 [98560/118836 (83%)] Loss: 12230.574219\n",
      "    epoch          : 1461\n",
      "    loss           : 12243.070636889992\n",
      "    val_loss       : 12245.156857318834\n",
      "    val_log_likelihood: -12170.149928272333\n",
      "    val_log_marginal: -12178.074952221004\n",
      "Train Epoch: 1462 [256/118836 (0%)] Loss: 12276.037109\n",
      "Train Epoch: 1462 [33024/118836 (28%)] Loss: 12269.498047\n",
      "Train Epoch: 1462 [65792/118836 (55%)] Loss: 12284.503906\n",
      "Train Epoch: 1462 [98560/118836 (83%)] Loss: 12347.996094\n",
      "    epoch          : 1462\n",
      "    loss           : 12247.696588573977\n",
      "    val_loss       : 12244.616250647478\n",
      "    val_log_likelihood: -12168.884225728907\n",
      "    val_log_marginal: -12177.09747847959\n",
      "Train Epoch: 1463 [256/118836 (0%)] Loss: 12281.876953\n",
      "Train Epoch: 1463 [33024/118836 (28%)] Loss: 12187.572266\n",
      "Train Epoch: 1463 [65792/118836 (55%)] Loss: 12271.252930\n",
      "Train Epoch: 1463 [98560/118836 (83%)] Loss: 12292.462891\n",
      "    epoch          : 1463\n",
      "    loss           : 12243.879379426438\n",
      "    val_loss       : 12241.0590137316\n",
      "    val_log_likelihood: -12170.239418876654\n",
      "    val_log_marginal: -12178.176706186237\n",
      "Train Epoch: 1464 [256/118836 (0%)] Loss: 12323.478516\n",
      "Train Epoch: 1464 [33024/118836 (28%)] Loss: 12254.466797\n",
      "Train Epoch: 1464 [65792/118836 (55%)] Loss: 12191.928711\n",
      "Train Epoch: 1464 [98560/118836 (83%)] Loss: 12229.192383\n",
      "    epoch          : 1464\n",
      "    loss           : 12245.369672928298\n",
      "    val_loss       : 12247.271617351538\n",
      "    val_log_likelihood: -12172.780579410928\n",
      "    val_log_marginal: -12181.08591180152\n",
      "Train Epoch: 1465 [256/118836 (0%)] Loss: 12261.556641\n",
      "Train Epoch: 1465 [33024/118836 (28%)] Loss: 12242.049805\n",
      "Train Epoch: 1465 [65792/118836 (55%)] Loss: 12266.722656\n",
      "Train Epoch: 1465 [98560/118836 (83%)] Loss: 12203.714844\n",
      "    epoch          : 1465\n",
      "    loss           : 12245.08580260675\n",
      "    val_loss       : 12246.433570481571\n",
      "    val_log_likelihood: -12169.280521576457\n",
      "    val_log_marginal: -12177.290047361634\n",
      "Train Epoch: 1466 [256/118836 (0%)] Loss: 12263.986328\n",
      "Train Epoch: 1466 [33024/118836 (28%)] Loss: 12206.561523\n",
      "Train Epoch: 1466 [65792/118836 (55%)] Loss: 12234.268555\n",
      "Train Epoch: 1466 [98560/118836 (83%)] Loss: 12247.101562\n",
      "    epoch          : 1466\n",
      "    loss           : 12241.98469292804\n",
      "    val_loss       : 12245.567602056073\n",
      "    val_log_likelihood: -12167.35317734181\n",
      "    val_log_marginal: -12175.242627981404\n",
      "Train Epoch: 1467 [256/118836 (0%)] Loss: 12188.341797\n",
      "Train Epoch: 1467 [33024/118836 (28%)] Loss: 12354.951172\n",
      "Train Epoch: 1467 [65792/118836 (55%)] Loss: 12343.367188\n",
      "Train Epoch: 1467 [98560/118836 (83%)] Loss: 12246.247070\n",
      "    epoch          : 1467\n",
      "    loss           : 12243.2497305366\n",
      "    val_loss       : 12239.712132453224\n",
      "    val_log_likelihood: -12168.295182614764\n",
      "    val_log_marginal: -12176.196812942208\n",
      "Train Epoch: 1468 [256/118836 (0%)] Loss: 12209.494141\n",
      "Train Epoch: 1468 [33024/118836 (28%)] Loss: 12275.900391\n",
      "Train Epoch: 1468 [65792/118836 (55%)] Loss: 12269.796875\n",
      "Train Epoch: 1468 [98560/118836 (83%)] Loss: 12274.529297\n",
      "    epoch          : 1468\n",
      "    loss           : 12241.005609782102\n",
      "    val_loss       : 12244.816822696914\n",
      "    val_log_likelihood: -12168.753024032\n",
      "    val_log_marginal: -12176.734862906067\n",
      "Train Epoch: 1469 [256/118836 (0%)] Loss: 12250.722656\n",
      "Train Epoch: 1469 [33024/118836 (28%)] Loss: 12179.767578\n",
      "Train Epoch: 1469 [65792/118836 (55%)] Loss: 12175.517578\n",
      "Train Epoch: 1469 [98560/118836 (83%)] Loss: 12224.134766\n",
      "    epoch          : 1469\n",
      "    loss           : 12249.698598241057\n",
      "    val_loss       : 12247.061873338627\n",
      "    val_log_likelihood: -12168.667036290322\n",
      "    val_log_marginal: -12176.839605658774\n",
      "Train Epoch: 1470 [256/118836 (0%)] Loss: 12325.244141\n",
      "Train Epoch: 1470 [33024/118836 (28%)] Loss: 12271.800781\n",
      "Train Epoch: 1470 [65792/118836 (55%)] Loss: 12359.243164\n",
      "Train Epoch: 1470 [98560/118836 (83%)] Loss: 12214.513672\n",
      "    epoch          : 1470\n",
      "    loss           : 12246.18518177471\n",
      "    val_loss       : 12246.12913726963\n",
      "    val_log_likelihood: -12169.139554900745\n",
      "    val_log_marginal: -12177.249091922034\n",
      "Train Epoch: 1471 [256/118836 (0%)] Loss: 12217.593750\n",
      "Train Epoch: 1471 [33024/118836 (28%)] Loss: 12279.287109\n",
      "Train Epoch: 1471 [65792/118836 (55%)] Loss: 12260.020508\n",
      "Train Epoch: 1471 [98560/118836 (83%)] Loss: 12162.127930\n",
      "    epoch          : 1471\n",
      "    loss           : 12239.191659720067\n",
      "    val_loss       : 12243.504971184824\n",
      "    val_log_likelihood: -12169.441079275228\n",
      "    val_log_marginal: -12177.416752321193\n",
      "Train Epoch: 1472 [256/118836 (0%)] Loss: 12272.977539\n",
      "Train Epoch: 1472 [33024/118836 (28%)] Loss: 12226.423828\n",
      "Train Epoch: 1472 [65792/118836 (55%)] Loss: 12277.492188\n",
      "Train Epoch: 1472 [98560/118836 (83%)] Loss: 12248.824219\n",
      "    epoch          : 1472\n",
      "    loss           : 12243.813408712003\n",
      "    val_loss       : 12245.393866542472\n",
      "    val_log_likelihood: -12167.560013763958\n",
      "    val_log_marginal: -12175.87204495923\n",
      "Train Epoch: 1473 [256/118836 (0%)] Loss: 12225.625977\n",
      "Train Epoch: 1473 [33024/118836 (28%)] Loss: 12225.504883\n",
      "Train Epoch: 1473 [65792/118836 (55%)] Loss: 12291.878906\n",
      "Train Epoch: 1473 [98560/118836 (83%)] Loss: 12230.851562\n",
      "    epoch          : 1473\n",
      "    loss           : 12239.73604396066\n",
      "    val_loss       : 12243.046880934777\n",
      "    val_log_likelihood: -12168.718382638028\n",
      "    val_log_marginal: -12177.147373652315\n",
      "Train Epoch: 1474 [256/118836 (0%)] Loss: 12258.052734\n",
      "Train Epoch: 1474 [33024/118836 (28%)] Loss: 12204.916992\n",
      "Train Epoch: 1474 [65792/118836 (55%)] Loss: 12202.621094\n",
      "Train Epoch: 1474 [98560/118836 (83%)] Loss: 12263.905273\n",
      "    epoch          : 1474\n",
      "    loss           : 12248.502423555108\n",
      "    val_loss       : 12241.509631976485\n",
      "    val_log_likelihood: -12167.700120838503\n",
      "    val_log_marginal: -12175.808879198654\n",
      "Train Epoch: 1475 [256/118836 (0%)] Loss: 12304.401367\n",
      "Train Epoch: 1475 [33024/118836 (28%)] Loss: 12312.932617\n",
      "Train Epoch: 1475 [65792/118836 (55%)] Loss: 12259.318359\n",
      "Train Epoch: 1475 [98560/118836 (83%)] Loss: 12285.390625\n",
      "    epoch          : 1475\n",
      "    loss           : 12243.295192469242\n",
      "    val_loss       : 12240.55218899387\n",
      "    val_log_likelihood: -12166.507948039443\n",
      "    val_log_marginal: -12174.574053486158\n",
      "Train Epoch: 1476 [256/118836 (0%)] Loss: 12224.806641\n",
      "Train Epoch: 1476 [33024/118836 (28%)] Loss: 12250.212891\n",
      "Train Epoch: 1476 [65792/118836 (55%)] Loss: 12239.493164\n",
      "Train Epoch: 1476 [98560/118836 (83%)] Loss: 12267.811523\n",
      "    epoch          : 1476\n",
      "    loss           : 12241.087933112334\n",
      "    val_loss       : 12243.00623539688\n",
      "    val_log_likelihood: -12165.372424104373\n",
      "    val_log_marginal: -12173.598771301235\n",
      "Train Epoch: 1477 [256/118836 (0%)] Loss: 12236.600586\n",
      "Train Epoch: 1477 [33024/118836 (28%)] Loss: 12420.649414\n",
      "Train Epoch: 1477 [65792/118836 (55%)] Loss: 12252.498047\n",
      "Train Epoch: 1477 [98560/118836 (83%)] Loss: 12229.121094\n",
      "    epoch          : 1477\n",
      "    loss           : 12246.176701593517\n",
      "    val_loss       : 12250.851995066456\n",
      "    val_log_likelihood: -12170.020937209212\n",
      "    val_log_marginal: -12178.309146986376\n",
      "Train Epoch: 1478 [256/118836 (0%)] Loss: 12258.363281\n",
      "Train Epoch: 1478 [33024/118836 (28%)] Loss: 12384.579102\n",
      "Train Epoch: 1478 [65792/118836 (55%)] Loss: 12259.835938\n",
      "Train Epoch: 1478 [98560/118836 (83%)] Loss: 12230.201172\n",
      "    epoch          : 1478\n",
      "    loss           : 12244.798595817823\n",
      "    val_loss       : 12244.10067669071\n",
      "    val_log_likelihood: -12170.978824183208\n",
      "    val_log_marginal: -12179.273613017893\n",
      "Train Epoch: 1479 [256/118836 (0%)] Loss: 12187.295898\n",
      "Train Epoch: 1479 [33024/118836 (28%)] Loss: 12230.208984\n",
      "Train Epoch: 1479 [65792/118836 (55%)] Loss: 12168.244141\n",
      "Train Epoch: 1479 [98560/118836 (83%)] Loss: 12232.500000\n",
      "    epoch          : 1479\n",
      "    loss           : 12242.299195325424\n",
      "    val_loss       : 12248.408215449686\n",
      "    val_log_likelihood: -12168.724163984956\n",
      "    val_log_marginal: -12176.99882365874\n",
      "Train Epoch: 1480 [256/118836 (0%)] Loss: 12246.860352\n",
      "Train Epoch: 1480 [33024/118836 (28%)] Loss: 12256.490234\n",
      "Train Epoch: 1480 [65792/118836 (55%)] Loss: 12245.700195\n",
      "Train Epoch: 1480 [98560/118836 (83%)] Loss: 12254.184570\n",
      "    epoch          : 1480\n",
      "    loss           : 12247.509178556658\n",
      "    val_loss       : 12243.378397068469\n",
      "    val_log_likelihood: -12166.357082137873\n",
      "    val_log_marginal: -12174.592116391274\n",
      "Train Epoch: 1481 [256/118836 (0%)] Loss: 12269.101562\n",
      "Train Epoch: 1481 [33024/118836 (28%)] Loss: 12280.185547\n",
      "Train Epoch: 1481 [65792/118836 (55%)] Loss: 12203.276367\n",
      "Train Epoch: 1481 [98560/118836 (83%)] Loss: 12222.412109\n",
      "    epoch          : 1481\n",
      "    loss           : 12240.164055391853\n",
      "    val_loss       : 12245.922553150382\n",
      "    val_log_likelihood: -12168.473980627068\n",
      "    val_log_marginal: -12176.64079630894\n",
      "Train Epoch: 1482 [256/118836 (0%)] Loss: 12190.770508\n",
      "Train Epoch: 1482 [33024/118836 (28%)] Loss: 12257.323242\n",
      "Train Epoch: 1482 [65792/118836 (55%)] Loss: 12166.997070\n",
      "Train Epoch: 1482 [98560/118836 (83%)] Loss: 12302.339844\n",
      "    epoch          : 1482\n",
      "    loss           : 12240.09926592225\n",
      "    val_loss       : 12245.48689991368\n",
      "    val_log_likelihood: -12169.301625342483\n",
      "    val_log_marginal: -12177.643820734886\n",
      "Train Epoch: 1483 [256/118836 (0%)] Loss: 12274.830078\n",
      "Train Epoch: 1483 [33024/118836 (28%)] Loss: 12243.767578\n",
      "Train Epoch: 1483 [65792/118836 (55%)] Loss: 12183.130859\n",
      "Train Epoch: 1483 [98560/118836 (83%)] Loss: 12285.203125\n",
      "    epoch          : 1483\n",
      "    loss           : 12247.012640385909\n",
      "    val_loss       : 12241.591119992738\n",
      "    val_log_likelihood: -12168.912412925196\n",
      "    val_log_marginal: -12177.245548766743\n",
      "Train Epoch: 1484 [256/118836 (0%)] Loss: 12165.739258\n",
      "Train Epoch: 1484 [33024/118836 (28%)] Loss: 12223.010742\n",
      "Train Epoch: 1484 [65792/118836 (55%)] Loss: 12381.735352\n",
      "Train Epoch: 1484 [98560/118836 (83%)] Loss: 12203.975586\n",
      "    epoch          : 1484\n",
      "    loss           : 12244.416057627688\n",
      "    val_loss       : 12246.465472175041\n",
      "    val_log_likelihood: -12167.679273935071\n",
      "    val_log_marginal: -12176.109682928422\n",
      "Train Epoch: 1485 [256/118836 (0%)] Loss: 12231.165039\n",
      "Train Epoch: 1485 [33024/118836 (28%)] Loss: 12237.397461\n",
      "Train Epoch: 1485 [65792/118836 (55%)] Loss: 12375.929688\n",
      "Train Epoch: 1485 [98560/118836 (83%)] Loss: 12228.188477\n",
      "    epoch          : 1485\n",
      "    loss           : 12242.167041621433\n",
      "    val_loss       : 12242.8182486672\n",
      "    val_log_likelihood: -12168.376485925868\n",
      "    val_log_marginal: -12176.639721555382\n",
      "Train Epoch: 1486 [256/118836 (0%)] Loss: 12300.295898\n",
      "Train Epoch: 1486 [33024/118836 (28%)] Loss: 12306.318359\n",
      "Train Epoch: 1486 [65792/118836 (55%)] Loss: 12205.153320\n",
      "Train Epoch: 1486 [98560/118836 (83%)] Loss: 12295.702148\n",
      "    epoch          : 1486\n",
      "    loss           : 12247.58636592742\n",
      "    val_loss       : 12244.640502846867\n",
      "    val_log_likelihood: -12168.044418812035\n",
      "    val_log_marginal: -12176.187210276761\n",
      "Train Epoch: 1487 [256/118836 (0%)] Loss: 12269.762695\n",
      "Train Epoch: 1487 [33024/118836 (28%)] Loss: 12233.808594\n",
      "Train Epoch: 1487 [65792/118836 (55%)] Loss: 12250.901367\n",
      "Train Epoch: 1487 [98560/118836 (83%)] Loss: 12184.185547\n",
      "    epoch          : 1487\n",
      "    loss           : 12244.743122706008\n",
      "    val_loss       : 12245.056725190156\n",
      "    val_log_likelihood: -12167.127070086332\n",
      "    val_log_marginal: -12175.362038757694\n",
      "Train Epoch: 1488 [256/118836 (0%)] Loss: 12221.589844\n",
      "Train Epoch: 1488 [33024/118836 (28%)] Loss: 12292.994141\n",
      "Train Epoch: 1488 [65792/118836 (55%)] Loss: 12267.487305\n",
      "Train Epoch: 1488 [98560/118836 (83%)] Loss: 12273.610352\n",
      "    epoch          : 1488\n",
      "    loss           : 12246.92170553531\n",
      "    val_loss       : 12241.664440536251\n",
      "    val_log_likelihood: -12167.014779615125\n",
      "    val_log_marginal: -12175.22808471377\n",
      "Train Epoch: 1489 [256/118836 (0%)] Loss: 12320.277344\n",
      "Train Epoch: 1489 [33024/118836 (28%)] Loss: 12340.536133\n",
      "Train Epoch: 1489 [65792/118836 (55%)] Loss: 12314.634766\n",
      "Train Epoch: 1489 [98560/118836 (83%)] Loss: 12244.118164\n",
      "    epoch          : 1489\n",
      "    loss           : 12242.701743596206\n",
      "    val_loss       : 12248.320065145874\n",
      "    val_log_likelihood: -12168.226644889888\n",
      "    val_log_marginal: -12176.466990711486\n",
      "Train Epoch: 1490 [256/118836 (0%)] Loss: 12254.969727\n",
      "Train Epoch: 1490 [33024/118836 (28%)] Loss: 12247.507812\n",
      "Train Epoch: 1490 [65792/118836 (55%)] Loss: 12332.254883\n",
      "Train Epoch: 1490 [98560/118836 (83%)] Loss: 12285.354492\n",
      "    epoch          : 1490\n",
      "    loss           : 12241.998753812553\n",
      "    val_loss       : 12240.244287182079\n",
      "    val_log_likelihood: -12171.16339837288\n",
      "    val_log_marginal: -12179.21557839677\n",
      "Train Epoch: 1491 [256/118836 (0%)] Loss: 12293.026367\n",
      "Train Epoch: 1491 [33024/118836 (28%)] Loss: 12274.160156\n",
      "Train Epoch: 1491 [65792/118836 (55%)] Loss: 12200.018555\n",
      "Train Epoch: 1491 [98560/118836 (83%)] Loss: 12215.456055\n",
      "    epoch          : 1491\n",
      "    loss           : 12241.21876486249\n",
      "    val_loss       : 12243.901617553962\n",
      "    val_log_likelihood: -12167.397577091087\n",
      "    val_log_marginal: -12175.383847291483\n",
      "Train Epoch: 1492 [256/118836 (0%)] Loss: 12315.549805\n",
      "Train Epoch: 1492 [33024/118836 (28%)] Loss: 12212.395508\n",
      "Train Epoch: 1492 [65792/118836 (55%)] Loss: 12260.633789\n",
      "Train Epoch: 1492 [98560/118836 (83%)] Loss: 12230.268555\n",
      "    epoch          : 1492\n",
      "    loss           : 12242.860409396972\n",
      "    val_loss       : 12242.381877452735\n",
      "    val_log_likelihood: -12165.962426979942\n",
      "    val_log_marginal: -12173.953396027333\n",
      "Train Epoch: 1493 [256/118836 (0%)] Loss: 12250.685547\n",
      "Train Epoch: 1493 [33024/118836 (28%)] Loss: 12220.502930\n",
      "Train Epoch: 1493 [65792/118836 (55%)] Loss: 12226.312500\n",
      "Train Epoch: 1493 [98560/118836 (83%)] Loss: 12238.533203\n",
      "    epoch          : 1493\n",
      "    loss           : 12239.466920136734\n",
      "    val_loss       : 12241.586097191604\n",
      "    val_log_likelihood: -12164.004751150227\n",
      "    val_log_marginal: -12172.058912641134\n",
      "Train Epoch: 1494 [256/118836 (0%)] Loss: 12236.710938\n",
      "Train Epoch: 1494 [33024/118836 (28%)] Loss: 12183.993164\n",
      "Train Epoch: 1494 [65792/118836 (55%)] Loss: 12279.093750\n",
      "Train Epoch: 1494 [98560/118836 (83%)] Loss: 12189.681641\n",
      "    epoch          : 1494\n",
      "    loss           : 12238.48409487438\n",
      "    val_loss       : 12238.668482644567\n",
      "    val_log_likelihood: -12166.091810929745\n",
      "    val_log_marginal: -12174.1177408719\n",
      "Train Epoch: 1495 [256/118836 (0%)] Loss: 12250.664062\n",
      "Train Epoch: 1495 [33024/118836 (28%)] Loss: 12193.417969\n",
      "Train Epoch: 1495 [65792/118836 (55%)] Loss: 12309.039062\n",
      "Train Epoch: 1495 [98560/118836 (83%)] Loss: 12328.493164\n",
      "    epoch          : 1495\n",
      "    loss           : 12241.930934818289\n",
      "    val_loss       : 12243.109123186778\n",
      "    val_log_likelihood: -12165.732172282102\n",
      "    val_log_marginal: -12173.683190514543\n",
      "Train Epoch: 1496 [256/118836 (0%)] Loss: 12242.971680\n",
      "Train Epoch: 1496 [33024/118836 (28%)] Loss: 12218.179688\n",
      "Train Epoch: 1496 [65792/118836 (55%)] Loss: 12292.433594\n",
      "Train Epoch: 1496 [98560/118836 (83%)] Loss: 12328.674805\n",
      "    epoch          : 1496\n",
      "    loss           : 12240.842270374535\n",
      "    val_loss       : 12242.522081598512\n",
      "    val_log_likelihood: -12165.350997563844\n",
      "    val_log_marginal: -12173.58546556028\n",
      "Train Epoch: 1497 [256/118836 (0%)] Loss: 12213.509766\n",
      "Train Epoch: 1497 [33024/118836 (28%)] Loss: 12161.463867\n",
      "Train Epoch: 1497 [65792/118836 (55%)] Loss: 12309.373047\n",
      "Train Epoch: 1497 [98560/118836 (83%)] Loss: 12331.701172\n",
      "    epoch          : 1497\n",
      "    loss           : 12239.830227234543\n",
      "    val_loss       : 12241.273957994692\n",
      "    val_log_likelihood: -12164.50728326613\n",
      "    val_log_marginal: -12172.579879669134\n",
      "Train Epoch: 1498 [256/118836 (0%)] Loss: 12235.484375\n",
      "Train Epoch: 1498 [33024/118836 (28%)] Loss: 12278.017578\n",
      "Train Epoch: 1498 [65792/118836 (55%)] Loss: 12285.564453\n",
      "Train Epoch: 1498 [98560/118836 (83%)] Loss: 12366.187500\n",
      "    epoch          : 1498\n",
      "    loss           : 12240.884950113732\n",
      "    val_loss       : 12243.385200649382\n",
      "    val_log_likelihood: -12165.944736901623\n",
      "    val_log_marginal: -12174.107532001899\n",
      "Train Epoch: 1499 [256/118836 (0%)] Loss: 12300.950195\n",
      "Train Epoch: 1499 [33024/118836 (28%)] Loss: 12289.677734\n",
      "Train Epoch: 1499 [65792/118836 (55%)] Loss: 12347.158203\n",
      "Train Epoch: 1499 [98560/118836 (83%)] Loss: 12258.390625\n",
      "    epoch          : 1499\n",
      "    loss           : 12245.494472284687\n",
      "    val_loss       : 12241.512232575327\n",
      "    val_log_likelihood: -12163.362348305676\n",
      "    val_log_marginal: -12171.496620451\n",
      "Train Epoch: 1500 [256/118836 (0%)] Loss: 12259.753906\n",
      "Train Epoch: 1500 [33024/118836 (28%)] Loss: 12216.405273\n",
      "Train Epoch: 1500 [65792/118836 (55%)] Loss: 12248.865234\n",
      "Train Epoch: 1500 [98560/118836 (83%)] Loss: 12211.410156\n",
      "    epoch          : 1500\n",
      "    loss           : 12241.634601652966\n",
      "    val_loss       : 12251.316769692929\n",
      "    val_log_likelihood: -12167.399987237644\n",
      "    val_log_marginal: -12175.748211207781\n",
      "Saving checkpoint: saved/models/SelfiesAutoencodingOperad/0905_154251/checkpoint-epoch1500.pth ...\n",
      "Train Epoch: 1501 [256/118836 (0%)] Loss: 12256.133789\n",
      "Train Epoch: 1501 [33024/118836 (28%)] Loss: 12184.331055\n",
      "Train Epoch: 1501 [65792/118836 (55%)] Loss: 12273.041016\n",
      "Train Epoch: 1501 [98560/118836 (83%)] Loss: 12207.567383\n",
      "    epoch          : 1501\n",
      "    loss           : 12243.954166989763\n",
      "    val_loss       : 12242.15449266042\n",
      "    val_log_likelihood: -12164.418466966501\n",
      "    val_log_marginal: -12172.569735658835\n",
      "Train Epoch: 1502 [256/118836 (0%)] Loss: 12271.938477\n",
      "Train Epoch: 1502 [33024/118836 (28%)] Loss: 12213.078125\n",
      "Train Epoch: 1502 [65792/118836 (55%)] Loss: 12203.426758\n",
      "Train Epoch: 1502 [98560/118836 (83%)] Loss: 12245.691406\n",
      "    epoch          : 1502\n",
      "    loss           : 12238.854513350394\n",
      "    val_loss       : 12243.66627071701\n",
      "    val_log_likelihood: -12164.009181302989\n",
      "    val_log_marginal: -12172.155142162163\n",
      "Train Epoch: 1503 [256/118836 (0%)] Loss: 12202.265625\n",
      "Train Epoch: 1503 [33024/118836 (28%)] Loss: 12246.344727\n",
      "Train Epoch: 1503 [65792/118836 (55%)] Loss: 12277.583008\n",
      "Train Epoch: 1503 [98560/118836 (83%)] Loss: 12312.537109\n",
      "    epoch          : 1503\n",
      "    loss           : 12241.417379096878\n",
      "    val_loss       : 12243.004547938815\n",
      "    val_log_likelihood: -12174.343948705025\n",
      "    val_log_marginal: -12182.58161640976\n",
      "Train Epoch: 1504 [256/118836 (0%)] Loss: 12314.828125\n",
      "Train Epoch: 1504 [33024/118836 (28%)] Loss: 12265.162109\n",
      "Train Epoch: 1504 [65792/118836 (55%)] Loss: 12241.542969\n",
      "Train Epoch: 1504 [98560/118836 (83%)] Loss: 12265.803711\n",
      "    epoch          : 1504\n",
      "    loss           : 12241.32207709755\n",
      "    val_loss       : 12241.234032672928\n",
      "    val_log_likelihood: -12165.018331911704\n",
      "    val_log_marginal: -12173.011684796185\n",
      "Train Epoch: 1505 [256/118836 (0%)] Loss: 12301.415039\n",
      "Train Epoch: 1505 [33024/118836 (28%)] Loss: 12248.449219\n",
      "Train Epoch: 1505 [65792/118836 (55%)] Loss: 12296.166016\n",
      "Train Epoch: 1505 [98560/118836 (83%)] Loss: 12287.054688\n",
      "    epoch          : 1505\n",
      "    loss           : 12241.284890986868\n",
      "    val_loss       : 12245.840599156516\n",
      "    val_log_likelihood: -12165.580578926281\n",
      "    val_log_marginal: -12173.866203683392\n",
      "Train Epoch: 1506 [256/118836 (0%)] Loss: 12273.965820\n",
      "Train Epoch: 1506 [33024/118836 (28%)] Loss: 12244.926758\n",
      "Train Epoch: 1506 [65792/118836 (55%)] Loss: 12300.259766\n",
      "Train Epoch: 1506 [98560/118836 (83%)] Loss: 12356.710938\n",
      "    epoch          : 1506\n",
      "    loss           : 12246.147300681088\n",
      "    val_loss       : 12237.79989646517\n",
      "    val_log_likelihood: -12165.897228630323\n",
      "    val_log_marginal: -12173.897186116057\n",
      "Train Epoch: 1507 [256/118836 (0%)] Loss: 12235.246094\n",
      "Train Epoch: 1507 [33024/118836 (28%)] Loss: 12301.352539\n",
      "Train Epoch: 1507 [65792/118836 (55%)] Loss: 12356.243164\n",
      "Train Epoch: 1507 [98560/118836 (83%)] Loss: 12308.586914\n",
      "    epoch          : 1507\n",
      "    loss           : 12243.360994526725\n",
      "    val_loss       : 12238.758903024593\n",
      "    val_log_likelihood: -12166.790992523522\n",
      "    val_log_marginal: -12174.86553725058\n",
      "Train Epoch: 1508 [256/118836 (0%)] Loss: 12279.386719\n",
      "Train Epoch: 1508 [33024/118836 (28%)] Loss: 12188.796875\n",
      "Train Epoch: 1508 [65792/118836 (55%)] Loss: 12365.624023\n",
      "Train Epoch: 1508 [98560/118836 (83%)] Loss: 12281.472656\n",
      "    epoch          : 1508\n",
      "    loss           : 12240.105186039598\n",
      "    val_loss       : 12243.868575262011\n",
      "    val_log_likelihood: -12165.741665212729\n",
      "    val_log_marginal: -12174.088883454693\n",
      "Train Epoch: 1509 [256/118836 (0%)] Loss: 12160.983398\n",
      "Train Epoch: 1509 [33024/118836 (28%)] Loss: 12292.317383\n",
      "Train Epoch: 1509 [65792/118836 (55%)] Loss: 12361.084961\n",
      "Train Epoch: 1509 [98560/118836 (83%)] Loss: 12286.611328\n",
      "    epoch          : 1509\n",
      "    loss           : 12238.481222859802\n",
      "    val_loss       : 12244.42782477887\n",
      "    val_log_likelihood: -12166.885825223584\n",
      "    val_log_marginal: -12175.165892395593\n",
      "Train Epoch: 1510 [256/118836 (0%)] Loss: 12283.857422\n",
      "Train Epoch: 1510 [33024/118836 (28%)] Loss: 12275.662109\n",
      "Train Epoch: 1510 [65792/118836 (55%)] Loss: 12200.047852\n",
      "Train Epoch: 1510 [98560/118836 (83%)] Loss: 12280.212891\n",
      "    epoch          : 1510\n",
      "    loss           : 12244.025228268454\n",
      "    val_loss       : 12243.847449644945\n",
      "    val_log_likelihood: -12163.59771812319\n",
      "    val_log_marginal: -12171.677954889445\n",
      "Train Epoch: 1511 [256/118836 (0%)] Loss: 12263.111328\n",
      "Train Epoch: 1511 [33024/118836 (28%)] Loss: 12293.708984\n",
      "Train Epoch: 1511 [65792/118836 (55%)] Loss: 12317.541992\n",
      "Train Epoch: 1511 [98560/118836 (83%)] Loss: 12284.805664\n",
      "    epoch          : 1511\n",
      "    loss           : 12244.261286930056\n",
      "    val_loss       : 12245.594772516057\n",
      "    val_log_likelihood: -12163.415641962625\n",
      "    val_log_marginal: -12171.6182264847\n",
      "Train Epoch: 1512 [256/118836 (0%)] Loss: 12182.638672\n",
      "Train Epoch: 1512 [33024/118836 (28%)] Loss: 12295.790039\n",
      "Train Epoch: 1512 [65792/118836 (55%)] Loss: 12278.000000\n",
      "Train Epoch: 1512 [98560/118836 (83%)] Loss: 12294.547852\n",
      "    epoch          : 1512\n",
      "    loss           : 12242.768597174834\n",
      "    val_loss       : 12241.441154974435\n",
      "    val_log_likelihood: -12164.675141032103\n",
      "    val_log_marginal: -12172.895363841868\n",
      "Train Epoch: 1513 [256/118836 (0%)] Loss: 12176.556641\n",
      "Train Epoch: 1513 [33024/118836 (28%)] Loss: 12345.851562\n",
      "Train Epoch: 1513 [65792/118836 (55%)] Loss: 12197.386719\n",
      "Train Epoch: 1513 [98560/118836 (83%)] Loss: 12397.553711\n",
      "    epoch          : 1513\n",
      "    loss           : 12243.237143300248\n",
      "    val_loss       : 12240.209299846618\n",
      "    val_log_likelihood: -12169.053798496949\n",
      "    val_log_marginal: -12177.17944360425\n",
      "Train Epoch: 1514 [256/118836 (0%)] Loss: 12204.015625\n",
      "Train Epoch: 1514 [33024/118836 (28%)] Loss: 12207.588867\n",
      "Train Epoch: 1514 [65792/118836 (55%)] Loss: 12430.566406\n",
      "Train Epoch: 1514 [98560/118836 (83%)] Loss: 12203.639648\n",
      "    epoch          : 1514\n",
      "    loss           : 12242.671706504601\n",
      "    val_loss       : 12244.075231946155\n",
      "    val_log_likelihood: -12166.021506345636\n",
      "    val_log_marginal: -12174.216133392914\n",
      "Train Epoch: 1515 [256/118836 (0%)] Loss: 12246.586914\n",
      "Train Epoch: 1515 [33024/118836 (28%)] Loss: 12301.765625\n",
      "Train Epoch: 1515 [65792/118836 (55%)] Loss: 12254.963867\n",
      "Train Epoch: 1515 [98560/118836 (83%)] Loss: 12292.060547\n",
      "    epoch          : 1515\n",
      "    loss           : 12244.223240087365\n",
      "    val_loss       : 12244.016480144597\n",
      "    val_log_likelihood: -12163.911860589847\n",
      "    val_log_marginal: -12172.052525939724\n",
      "Train Epoch: 1516 [256/118836 (0%)] Loss: 12190.378906\n",
      "Train Epoch: 1516 [33024/118836 (28%)] Loss: 12396.900391\n",
      "Train Epoch: 1516 [65792/118836 (55%)] Loss: 12190.459961\n",
      "Train Epoch: 1516 [98560/118836 (83%)] Loss: 12331.544922\n",
      "    epoch          : 1516\n",
      "    loss           : 12244.312323265613\n",
      "    val_loss       : 12242.121815734894\n",
      "    val_log_likelihood: -12161.118410909068\n",
      "    val_log_marginal: -12169.254709623576\n",
      "Train Epoch: 1517 [256/118836 (0%)] Loss: 12201.781250\n",
      "Train Epoch: 1517 [33024/118836 (28%)] Loss: 12228.929688\n",
      "Train Epoch: 1517 [65792/118836 (55%)] Loss: 12344.867188\n",
      "Train Epoch: 1517 [98560/118836 (83%)] Loss: 12284.742188\n",
      "    epoch          : 1517\n",
      "    loss           : 12244.759543495398\n",
      "    val_loss       : 12240.729562477038\n",
      "    val_log_likelihood: -12163.18684928143\n",
      "    val_log_marginal: -12171.392315124753\n",
      "Train Epoch: 1518 [256/118836 (0%)] Loss: 12329.111328\n",
      "Train Epoch: 1518 [33024/118836 (28%)] Loss: 12226.467773\n",
      "Train Epoch: 1518 [65792/118836 (55%)] Loss: 12336.505859\n",
      "Train Epoch: 1518 [98560/118836 (83%)] Loss: 12245.621094\n",
      "    epoch          : 1518\n",
      "    loss           : 12244.495418152916\n",
      "    val_loss       : 12241.07246369613\n",
      "    val_log_likelihood: -12169.352081556295\n",
      "    val_log_marginal: -12177.417664840304\n",
      "Train Epoch: 1519 [256/118836 (0%)] Loss: 12246.117188\n",
      "Train Epoch: 1519 [33024/118836 (28%)] Loss: 12248.406250\n",
      "Train Epoch: 1519 [65792/118836 (55%)] Loss: 12246.466797\n",
      "Train Epoch: 1519 [98560/118836 (83%)] Loss: 12238.496094\n",
      "    epoch          : 1519\n",
      "    loss           : 12242.446160469655\n",
      "    val_loss       : 12243.89600563254\n",
      "    val_log_likelihood: -12163.512974953474\n",
      "    val_log_marginal: -12171.506163543307\n",
      "Train Epoch: 1520 [256/118836 (0%)] Loss: 12221.001953\n",
      "Train Epoch: 1520 [33024/118836 (28%)] Loss: 12208.802734\n",
      "Train Epoch: 1520 [65792/118836 (55%)] Loss: 12317.347656\n",
      "Train Epoch: 1520 [98560/118836 (83%)] Loss: 12238.253906\n",
      "    epoch          : 1520\n",
      "    loss           : 12238.50977079456\n",
      "    val_loss       : 12242.433702248984\n",
      "    val_log_likelihood: -12163.3017442424\n",
      "    val_log_marginal: -12171.563397138021\n",
      "Train Epoch: 1521 [256/118836 (0%)] Loss: 12214.656250\n",
      "Train Epoch: 1521 [33024/118836 (28%)] Loss: 12232.407227\n",
      "Train Epoch: 1521 [65792/118836 (55%)] Loss: 12260.218750\n",
      "Train Epoch: 1521 [98560/118836 (83%)] Loss: 12317.449219\n",
      "    epoch          : 1521\n",
      "    loss           : 12241.543043547095\n",
      "    val_loss       : 12251.709937010712\n",
      "    val_log_likelihood: -12176.76344554513\n",
      "    val_log_marginal: -12185.061381090458\n",
      "Train Epoch: 1522 [256/118836 (0%)] Loss: 12276.167969\n",
      "Train Epoch: 1522 [33024/118836 (28%)] Loss: 12274.572266\n",
      "Train Epoch: 1522 [65792/118836 (55%)] Loss: 12215.080078\n",
      "Train Epoch: 1522 [98560/118836 (83%)] Loss: 12261.592773\n",
      "    epoch          : 1522\n",
      "    loss           : 12244.098873843312\n",
      "    val_loss       : 12244.865151468553\n",
      "    val_log_likelihood: -12164.830578764733\n",
      "    val_log_marginal: -12173.201392259582\n",
      "Train Epoch: 1523 [256/118836 (0%)] Loss: 12277.760742\n",
      "Train Epoch: 1523 [33024/118836 (28%)] Loss: 12355.914062\n",
      "Train Epoch: 1523 [65792/118836 (55%)] Loss: 12215.359375\n",
      "Train Epoch: 1523 [98560/118836 (83%)] Loss: 12168.260742\n",
      "    epoch          : 1523\n",
      "    loss           : 12243.102001589641\n",
      "    val_loss       : 12239.71037547466\n",
      "    val_log_likelihood: -12165.539779615126\n",
      "    val_log_marginal: -12173.829158959712\n",
      "Train Epoch: 1524 [256/118836 (0%)] Loss: 12296.652344\n",
      "Train Epoch: 1524 [33024/118836 (28%)] Loss: 12199.369141\n",
      "Train Epoch: 1524 [65792/118836 (55%)] Loss: 12229.125977\n",
      "Train Epoch: 1524 [98560/118836 (83%)] Loss: 12230.781250\n",
      "    epoch          : 1524\n",
      "    loss           : 12239.727714827595\n",
      "    val_loss       : 12241.521087300067\n",
      "    val_log_likelihood: -12162.542161005997\n",
      "    val_log_marginal: -12170.594159196025\n",
      "Train Epoch: 1525 [256/118836 (0%)] Loss: 12228.354492\n",
      "Train Epoch: 1525 [33024/118836 (28%)] Loss: 12352.587891\n",
      "Train Epoch: 1525 [65792/118836 (55%)] Loss: 12217.064453\n",
      "Train Epoch: 1525 [98560/118836 (83%)] Loss: 12269.003906\n",
      "    epoch          : 1525\n",
      "    loss           : 12244.39625271402\n",
      "    val_loss       : 12240.17891785039\n",
      "    val_log_likelihood: -12164.701880104942\n",
      "    val_log_marginal: -12172.77771713714\n",
      "Train Epoch: 1526 [256/118836 (0%)] Loss: 12232.219727\n",
      "Train Epoch: 1526 [33024/118836 (28%)] Loss: 12214.442383\n",
      "Train Epoch: 1526 [65792/118836 (55%)] Loss: 12248.496094\n",
      "Train Epoch: 1526 [98560/118836 (83%)] Loss: 12202.080078\n",
      "    epoch          : 1526\n",
      "    loss           : 12241.837087727461\n",
      "    val_loss       : 12248.461568302293\n",
      "    val_log_likelihood: -12164.203342444685\n",
      "    val_log_marginal: -12172.439138587537\n",
      "Train Epoch: 1527 [256/118836 (0%)] Loss: 12298.758789\n",
      "Train Epoch: 1527 [33024/118836 (28%)] Loss: 12318.387695\n",
      "Train Epoch: 1527 [65792/118836 (55%)] Loss: 12245.995117\n",
      "Train Epoch: 1527 [98560/118836 (83%)] Loss: 12382.990234\n",
      "    epoch          : 1527\n",
      "    loss           : 12245.741215299318\n",
      "    val_loss       : 12240.173321131322\n",
      "    val_log_likelihood: -12162.61138078991\n",
      "    val_log_marginal: -12170.755402553745\n",
      "Train Epoch: 1528 [256/118836 (0%)] Loss: 12198.101562\n",
      "Train Epoch: 1528 [33024/118836 (28%)] Loss: 12252.441406\n",
      "Train Epoch: 1528 [65792/118836 (55%)] Loss: 12258.909180\n",
      "Train Epoch: 1528 [98560/118836 (83%)] Loss: 12259.314453\n",
      "    epoch          : 1528\n",
      "    loss           : 12244.28914343595\n",
      "    val_loss       : 12245.095486094562\n",
      "    val_log_likelihood: -12165.40254310122\n",
      "    val_log_marginal: -12173.602170548394\n",
      "Train Epoch: 1529 [256/118836 (0%)] Loss: 12250.951172\n",
      "Train Epoch: 1529 [33024/118836 (28%)] Loss: 12325.373047\n",
      "Train Epoch: 1529 [65792/118836 (55%)] Loss: 12290.679688\n",
      "Train Epoch: 1529 [98560/118836 (83%)] Loss: 12178.230469\n",
      "    epoch          : 1529\n",
      "    loss           : 12246.19954734026\n",
      "    val_loss       : 12240.23084692972\n",
      "    val_log_likelihood: -12165.224081918166\n",
      "    val_log_marginal: -12173.43050917549\n",
      "Train Epoch: 1530 [256/118836 (0%)] Loss: 12237.552734\n",
      "Train Epoch: 1530 [33024/118836 (28%)] Loss: 12229.500000\n",
      "Train Epoch: 1530 [65792/118836 (55%)] Loss: 12236.919922\n",
      "Train Epoch: 1530 [98560/118836 (83%)] Loss: 12299.618164\n",
      "    epoch          : 1530\n",
      "    loss           : 12243.883392137097\n",
      "    val_loss       : 12241.932647785283\n",
      "    val_log_likelihood: -12161.633921532517\n",
      "    val_log_marginal: -12170.037618178414\n",
      "Train Epoch: 1531 [256/118836 (0%)] Loss: 12284.093750\n",
      "Train Epoch: 1531 [33024/118836 (28%)] Loss: 12312.070312\n",
      "Train Epoch: 1531 [65792/118836 (55%)] Loss: 12243.576172\n",
      "Train Epoch: 1531 [98560/118836 (83%)] Loss: 12220.228516\n",
      "    epoch          : 1531\n",
      "    loss           : 12242.846802626138\n",
      "    val_loss       : 12241.230561745002\n",
      "    val_log_likelihood: -12164.138376725341\n",
      "    val_log_marginal: -12172.241227226292\n",
      "Train Epoch: 1532 [256/118836 (0%)] Loss: 12244.310547\n",
      "Train Epoch: 1532 [33024/118836 (28%)] Loss: 12285.538086\n",
      "Train Epoch: 1532 [65792/118836 (55%)] Loss: 12262.994141\n",
      "Train Epoch: 1532 [98560/118836 (83%)] Loss: 12294.683594\n",
      "    epoch          : 1532\n",
      "    loss           : 12244.421439787531\n",
      "    val_loss       : 12249.348530676567\n",
      "    val_log_likelihood: -12164.013800144749\n",
      "    val_log_marginal: -12172.412856354616\n",
      "Train Epoch: 1533 [256/118836 (0%)] Loss: 12192.847656\n",
      "Train Epoch: 1533 [33024/118836 (28%)] Loss: 12212.105469\n",
      "Train Epoch: 1533 [65792/118836 (55%)] Loss: 12291.197266\n",
      "Train Epoch: 1533 [98560/118836 (83%)] Loss: 12328.544922\n",
      "    epoch          : 1533\n",
      "    loss           : 12247.788432621226\n",
      "    val_loss       : 12243.819919707103\n",
      "    val_log_likelihood: -12162.931024477875\n",
      "    val_log_marginal: -12171.05988516682\n",
      "Train Epoch: 1534 [256/118836 (0%)] Loss: 12238.085938\n",
      "Train Epoch: 1534 [33024/118836 (28%)] Loss: 12257.781250\n",
      "Train Epoch: 1534 [65792/118836 (55%)] Loss: 12243.621094\n",
      "Train Epoch: 1534 [98560/118836 (83%)] Loss: 12240.058594\n",
      "    epoch          : 1534\n",
      "    loss           : 12241.690185425712\n",
      "    val_loss       : 12243.106383712471\n",
      "    val_log_likelihood: -12164.318212365592\n",
      "    val_log_marginal: -12172.567799701397\n",
      "Train Epoch: 1535 [256/118836 (0%)] Loss: 12319.380859\n",
      "Train Epoch: 1535 [33024/118836 (28%)] Loss: 12260.193359\n",
      "Train Epoch: 1535 [65792/118836 (55%)] Loss: 12250.647461\n",
      "Train Epoch: 1535 [98560/118836 (83%)] Loss: 12281.580078\n",
      "    epoch          : 1535\n",
      "    loss           : 12245.928061834418\n",
      "    val_loss       : 12240.912061384088\n",
      "    val_log_likelihood: -12163.124521330905\n",
      "    val_log_marginal: -12171.41921922563\n",
      "Train Epoch: 1536 [256/118836 (0%)] Loss: 12319.061523\n",
      "Train Epoch: 1536 [33024/118836 (28%)] Loss: 12274.132812\n",
      "Train Epoch: 1536 [65792/118836 (55%)] Loss: 12235.904297\n",
      "Train Epoch: 1536 [98560/118836 (83%)] Loss: 12299.732422\n",
      "    epoch          : 1536\n",
      "    loss           : 12243.605021744468\n",
      "    val_loss       : 12241.958970239228\n",
      "    val_log_likelihood: -12165.26290548749\n",
      "    val_log_marginal: -12173.406602039655\n",
      "Train Epoch: 1537 [256/118836 (0%)] Loss: 12391.624023\n",
      "Train Epoch: 1537 [33024/118836 (28%)] Loss: 12218.863281\n",
      "Train Epoch: 1537 [65792/118836 (55%)] Loss: 12329.549805\n",
      "Train Epoch: 1537 [98560/118836 (83%)] Loss: 12329.279297\n",
      "    epoch          : 1537\n",
      "    loss           : 12241.58754022565\n",
      "    val_loss       : 12239.306561273259\n",
      "    val_log_likelihood: -12165.2556975031\n",
      "    val_log_marginal: -12173.532943865606\n",
      "Train Epoch: 1538 [256/118836 (0%)] Loss: 12228.710938\n",
      "Train Epoch: 1538 [33024/118836 (28%)] Loss: 12158.962891\n",
      "Train Epoch: 1538 [65792/118836 (55%)] Loss: 12207.891602\n",
      "Train Epoch: 1538 [98560/118836 (83%)] Loss: 12291.326172\n",
      "    epoch          : 1538\n",
      "    loss           : 12250.305481350806\n",
      "    val_loss       : 12258.080071001812\n",
      "    val_log_likelihood: -12164.361655745968\n",
      "    val_log_marginal: -12172.760510434951\n",
      "Train Epoch: 1539 [256/118836 (0%)] Loss: 12347.770508\n",
      "Train Epoch: 1539 [33024/118836 (28%)] Loss: 12316.412109\n",
      "Train Epoch: 1539 [65792/118836 (55%)] Loss: 12258.987305\n",
      "Train Epoch: 1539 [98560/118836 (83%)] Loss: 12299.728516\n",
      "    epoch          : 1539\n",
      "    loss           : 12248.202492536446\n",
      "    val_loss       : 12244.422412642614\n",
      "    val_log_likelihood: -12164.442049052679\n",
      "    val_log_marginal: -12172.926040360066\n",
      "Train Epoch: 1540 [256/118836 (0%)] Loss: 12244.810547\n",
      "Train Epoch: 1540 [33024/118836 (28%)] Loss: 12297.922852\n",
      "Train Epoch: 1540 [65792/118836 (55%)] Loss: 12247.989258\n",
      "Train Epoch: 1540 [98560/118836 (83%)] Loss: 12294.773438\n",
      "    epoch          : 1540\n",
      "    loss           : 12242.705593304127\n",
      "    val_loss       : 12242.716159362933\n",
      "    val_log_likelihood: -12166.275063488678\n",
      "    val_log_marginal: -12174.38124942276\n",
      "Train Epoch: 1541 [256/118836 (0%)] Loss: 12228.411133\n",
      "Train Epoch: 1541 [33024/118836 (28%)] Loss: 12222.014648\n",
      "Train Epoch: 1541 [65792/118836 (55%)] Loss: 12332.646484\n",
      "Train Epoch: 1541 [98560/118836 (83%)] Loss: 12250.892578\n",
      "    epoch          : 1541\n",
      "    loss           : 12240.83355465519\n",
      "    val_loss       : 12239.189444544147\n",
      "    val_log_likelihood: -12166.606088774297\n",
      "    val_log_marginal: -12174.706293095871\n",
      "Train Epoch: 1542 [256/118836 (0%)] Loss: 12245.541016\n",
      "Train Epoch: 1542 [33024/118836 (28%)] Loss: 12258.275391\n",
      "Train Epoch: 1542 [65792/118836 (55%)] Loss: 12263.153320\n",
      "Train Epoch: 1542 [98560/118836 (83%)] Loss: 12213.752930\n",
      "    epoch          : 1542\n",
      "    loss           : 12238.441012070927\n",
      "    val_loss       : 12246.234120439518\n",
      "    val_log_likelihood: -12164.82375801282\n",
      "    val_log_marginal: -12172.994632741102\n",
      "Train Epoch: 1543 [256/118836 (0%)] Loss: 12231.950195\n",
      "Train Epoch: 1543 [33024/118836 (28%)] Loss: 12261.130859\n",
      "Train Epoch: 1543 [65792/118836 (55%)] Loss: 12284.792969\n",
      "Train Epoch: 1543 [98560/118836 (83%)] Loss: 12289.552734\n",
      "    epoch          : 1543\n",
      "    loss           : 12238.549267860835\n",
      "    val_loss       : 12244.461398220164\n",
      "    val_log_likelihood: -12163.799366082505\n",
      "    val_log_marginal: -12172.051802450638\n",
      "Train Epoch: 1544 [256/118836 (0%)] Loss: 12151.396484\n",
      "Train Epoch: 1544 [33024/118836 (28%)] Loss: 12241.827148\n",
      "Train Epoch: 1544 [65792/118836 (55%)] Loss: 12322.316406\n",
      "Train Epoch: 1544 [98560/118836 (83%)] Loss: 12247.427734\n",
      "    epoch          : 1544\n",
      "    loss           : 12243.212698058831\n",
      "    val_loss       : 12242.918852673987\n",
      "    val_log_likelihood: -12165.512632793114\n",
      "    val_log_marginal: -12173.906010383205\n",
      "Train Epoch: 1545 [256/118836 (0%)] Loss: 12262.712891\n",
      "Train Epoch: 1545 [33024/118836 (28%)] Loss: 12248.144531\n",
      "Train Epoch: 1545 [65792/118836 (55%)] Loss: 12244.610352\n",
      "Train Epoch: 1545 [98560/118836 (83%)] Loss: 12286.463867\n",
      "    epoch          : 1545\n",
      "    loss           : 12243.631786665115\n",
      "    val_loss       : 12240.279650364027\n",
      "    val_log_likelihood: -12161.88252413539\n",
      "    val_log_marginal: -12169.908397463352\n",
      "Train Epoch: 1546 [256/118836 (0%)] Loss: 12241.505859\n",
      "Train Epoch: 1546 [33024/118836 (28%)] Loss: 12187.154297\n",
      "Train Epoch: 1546 [65792/118836 (55%)] Loss: 12215.468750\n",
      "Train Epoch: 1546 [98560/118836 (83%)] Loss: 12273.031250\n",
      "    epoch          : 1546\n",
      "    loss           : 12241.03094693445\n",
      "    val_loss       : 12242.561940807313\n",
      "    val_log_likelihood: -12162.886215040839\n",
      "    val_log_marginal: -12171.125253185708\n",
      "Train Epoch: 1547 [256/118836 (0%)] Loss: 12288.136719\n",
      "Train Epoch: 1547 [33024/118836 (28%)] Loss: 12230.290039\n",
      "Train Epoch: 1547 [65792/118836 (55%)] Loss: 12288.676758\n",
      "Train Epoch: 1547 [98560/118836 (83%)] Loss: 12205.930664\n",
      "    epoch          : 1547\n",
      "    loss           : 12239.740546325735\n",
      "    val_loss       : 12241.876055750863\n",
      "    val_log_likelihood: -12164.060000840054\n",
      "    val_log_marginal: -12172.260586502513\n",
      "Train Epoch: 1548 [256/118836 (0%)] Loss: 12275.155273\n",
      "Train Epoch: 1548 [33024/118836 (28%)] Loss: 12394.388672\n",
      "Train Epoch: 1548 [65792/118836 (55%)] Loss: 12212.813477\n",
      "Train Epoch: 1548 [98560/118836 (83%)] Loss: 12211.478516\n",
      "    epoch          : 1548\n",
      "    loss           : 12241.091357623813\n",
      "    val_loss       : 12250.029876728435\n",
      "    val_log_likelihood: -12166.60213906767\n",
      "    val_log_marginal: -12174.850443679894\n",
      "Train Epoch: 1549 [256/118836 (0%)] Loss: 12199.015625\n",
      "Train Epoch: 1549 [33024/118836 (28%)] Loss: 12188.573242\n",
      "Train Epoch: 1549 [65792/118836 (55%)] Loss: 12344.706055\n",
      "Train Epoch: 1549 [98560/118836 (83%)] Loss: 12332.078125\n",
      "    epoch          : 1549\n",
      "    loss           : 12244.102255544354\n",
      "    val_loss       : 12245.073177221286\n",
      "    val_log_likelihood: -12168.157610079354\n",
      "    val_log_marginal: -12176.386195484778\n",
      "Train Epoch: 1550 [256/118836 (0%)] Loss: 12294.869141\n",
      "Train Epoch: 1550 [33024/118836 (28%)] Loss: 12286.048828\n",
      "Train Epoch: 1550 [65792/118836 (55%)] Loss: 12218.493164\n",
      "Train Epoch: 1550 [98560/118836 (83%)] Loss: 12349.891602\n",
      "    epoch          : 1550\n",
      "    loss           : 12240.092294283759\n",
      "    val_loss       : 12236.218362916547\n",
      "    val_log_likelihood: -12162.562639739714\n",
      "    val_log_marginal: -12170.583288512418\n",
      "Train Epoch: 1551 [256/118836 (0%)] Loss: 12190.104492\n",
      "Train Epoch: 1551 [33024/118836 (28%)] Loss: 12287.422852\n",
      "Train Epoch: 1551 [65792/118836 (55%)] Loss: 12249.645508\n",
      "Train Epoch: 1551 [98560/118836 (83%)] Loss: 12344.235352\n",
      "    epoch          : 1551\n",
      "    loss           : 12240.166612547819\n",
      "    val_loss       : 12238.088229111312\n",
      "    val_log_likelihood: -12164.45121242375\n",
      "    val_log_marginal: -12172.595699255931\n",
      "Train Epoch: 1552 [256/118836 (0%)] Loss: 12232.316406\n",
      "Train Epoch: 1552 [33024/118836 (28%)] Loss: 12387.631836\n",
      "Train Epoch: 1552 [65792/118836 (55%)] Loss: 12225.380859\n",
      "Train Epoch: 1552 [98560/118836 (83%)] Loss: 12222.856445\n",
      "    epoch          : 1552\n",
      "    loss           : 12240.449501298852\n",
      "    val_loss       : 12242.557643776212\n",
      "    val_log_likelihood: -12164.440234536549\n",
      "    val_log_marginal: -12172.738656671681\n",
      "Train Epoch: 1553 [256/118836 (0%)] Loss: 12226.773438\n",
      "Train Epoch: 1553 [33024/118836 (28%)] Loss: 12212.289062\n",
      "Train Epoch: 1553 [65792/118836 (55%)] Loss: 12200.322266\n",
      "Train Epoch: 1553 [98560/118836 (83%)] Loss: 12239.886719\n",
      "    epoch          : 1553\n",
      "    loss           : 12243.82478077828\n",
      "    val_loss       : 12243.472388958035\n",
      "    val_log_likelihood: -12165.17425897565\n",
      "    val_log_marginal: -12173.475935643526\n",
      "Train Epoch: 1554 [256/118836 (0%)] Loss: 12293.457031\n",
      "Train Epoch: 1554 [33024/118836 (28%)] Loss: 12317.914062\n",
      "Train Epoch: 1554 [65792/118836 (55%)] Loss: 12252.456055\n",
      "Train Epoch: 1554 [98560/118836 (83%)] Loss: 12365.830078\n",
      "    epoch          : 1554\n",
      "    loss           : 12242.87180343388\n",
      "    val_loss       : 12238.810728343706\n",
      "    val_log_likelihood: -12163.304331607993\n",
      "    val_log_marginal: -12171.473892860626\n",
      "Train Epoch: 1555 [256/118836 (0%)] Loss: 12369.931641\n",
      "Train Epoch: 1555 [33024/118836 (28%)] Loss: 12330.390625\n",
      "Train Epoch: 1555 [65792/118836 (55%)] Loss: 12348.529297\n",
      "Train Epoch: 1555 [98560/118836 (83%)] Loss: 12300.329102\n",
      "    epoch          : 1555\n",
      "    loss           : 12239.610325230045\n",
      "    val_loss       : 12239.90240186659\n",
      "    val_log_likelihood: -12162.714183500053\n",
      "    val_log_marginal: -12170.861456974544\n",
      "Train Epoch: 1556 [256/118836 (0%)] Loss: 12307.722656\n",
      "Train Epoch: 1556 [33024/118836 (28%)] Loss: 12293.400391\n",
      "Train Epoch: 1556 [65792/118836 (55%)] Loss: 12244.285156\n",
      "Train Epoch: 1556 [98560/118836 (83%)] Loss: 12280.669922\n",
      "    epoch          : 1556\n",
      "    loss           : 12242.807257741419\n",
      "    val_loss       : 12237.989575668604\n",
      "    val_log_likelihood: -12168.200586906793\n",
      "    val_log_marginal: -12176.36568171614\n",
      "Train Epoch: 1557 [256/118836 (0%)] Loss: 12231.048828\n",
      "Train Epoch: 1557 [33024/118836 (28%)] Loss: 12237.831055\n",
      "Train Epoch: 1557 [65792/118836 (55%)] Loss: 12228.079102\n",
      "Train Epoch: 1557 [98560/118836 (83%)] Loss: 12285.466797\n",
      "    epoch          : 1557\n",
      "    loss           : 12246.886795001034\n",
      "    val_loss       : 12243.165681471313\n",
      "    val_log_likelihood: -12162.762797088244\n",
      "    val_log_marginal: -12170.927723603032\n",
      "Train Epoch: 1558 [256/118836 (0%)] Loss: 12289.873047\n",
      "Train Epoch: 1558 [33024/118836 (28%)] Loss: 12388.121094\n",
      "Train Epoch: 1558 [65792/118836 (55%)] Loss: 12249.062500\n",
      "Train Epoch: 1558 [98560/118836 (83%)] Loss: 12193.552734\n",
      "    epoch          : 1558\n",
      "    loss           : 12242.86186689025\n",
      "    val_loss       : 12241.326610936796\n",
      "    val_log_likelihood: -12161.21847245916\n",
      "    val_log_marginal: -12169.237210697605\n",
      "Train Epoch: 1559 [256/118836 (0%)] Loss: 12331.595703\n",
      "Train Epoch: 1559 [33024/118836 (28%)] Loss: 12358.927734\n",
      "Train Epoch: 1559 [65792/118836 (55%)] Loss: 12252.447266\n",
      "Train Epoch: 1559 [98560/118836 (83%)] Loss: 12219.931641\n",
      "    epoch          : 1559\n",
      "    loss           : 12243.847934275485\n",
      "    val_loss       : 12244.655992210182\n",
      "    val_log_likelihood: -12165.01570852073\n",
      "    val_log_marginal: -12173.254264862697\n",
      "Train Epoch: 1560 [256/118836 (0%)] Loss: 12150.786133\n",
      "Train Epoch: 1560 [33024/118836 (28%)] Loss: 12259.393555\n",
      "Train Epoch: 1560 [65792/118836 (55%)] Loss: 12303.110352\n",
      "Train Epoch: 1560 [98560/118836 (83%)] Loss: 12251.277344\n",
      "    epoch          : 1560\n",
      "    loss           : 12239.764975250724\n",
      "    val_loss       : 12244.082854940754\n",
      "    val_log_likelihood: -12162.372828137924\n",
      "    val_log_marginal: -12170.533671930949\n",
      "Train Epoch: 1561 [256/118836 (0%)] Loss: 12333.281250\n",
      "Train Epoch: 1561 [33024/118836 (28%)] Loss: 12184.916016\n",
      "Train Epoch: 1561 [65792/118836 (55%)] Loss: 12282.593750\n",
      "Train Epoch: 1561 [98560/118836 (83%)] Loss: 12179.332031\n",
      "    epoch          : 1561\n",
      "    loss           : 12243.215674433934\n",
      "    val_loss       : 12243.311046585919\n",
      "    val_log_likelihood: -12164.467617866005\n",
      "    val_log_marginal: -12172.662171220736\n",
      "Train Epoch: 1562 [256/118836 (0%)] Loss: 12253.051758\n",
      "Train Epoch: 1562 [33024/118836 (28%)] Loss: 12192.540039\n",
      "Train Epoch: 1562 [65792/118836 (55%)] Loss: 12295.013672\n",
      "Train Epoch: 1562 [98560/118836 (83%)] Loss: 12273.312500\n",
      "    epoch          : 1562\n",
      "    loss           : 12239.363090783965\n",
      "    val_loss       : 12241.035455869222\n",
      "    val_log_likelihood: -12163.105095733818\n",
      "    val_log_marginal: -12171.245426171237\n",
      "Train Epoch: 1563 [256/118836 (0%)] Loss: 12223.372070\n",
      "Train Epoch: 1563 [33024/118836 (28%)] Loss: 12240.564453\n",
      "Train Epoch: 1563 [65792/118836 (55%)] Loss: 12268.375000\n",
      "Train Epoch: 1563 [98560/118836 (83%)] Loss: 12213.913086\n",
      "    epoch          : 1563\n",
      "    loss           : 12242.155147429436\n",
      "    val_loss       : 12239.297056030317\n",
      "    val_log_likelihood: -12163.219683105874\n",
      "    val_log_marginal: -12171.743858726188\n",
      "Train Epoch: 1564 [256/118836 (0%)] Loss: 12205.769531\n",
      "Train Epoch: 1564 [33024/118836 (28%)] Loss: 12216.509766\n",
      "Train Epoch: 1564 [65792/118836 (55%)] Loss: 12234.658203\n",
      "Train Epoch: 1564 [98560/118836 (83%)] Loss: 12208.222656\n",
      "    epoch          : 1564\n",
      "    loss           : 12241.445289721618\n",
      "    val_loss       : 12237.877566654704\n",
      "    val_log_likelihood: -12162.465470559346\n",
      "    val_log_marginal: -12170.779584203554\n",
      "Train Epoch: 1565 [256/118836 (0%)] Loss: 12230.166016\n",
      "Train Epoch: 1565 [33024/118836 (28%)] Loss: 12194.072266\n",
      "Train Epoch: 1565 [65792/118836 (55%)] Loss: 12255.125000\n",
      "Train Epoch: 1565 [98560/118836 (83%)] Loss: 12245.884766\n",
      "    epoch          : 1565\n",
      "    loss           : 12240.881667765198\n",
      "    val_loss       : 12241.485704718914\n",
      "    val_log_likelihood: -12162.090637923904\n",
      "    val_log_marginal: -12170.315275624633\n",
      "Train Epoch: 1566 [256/118836 (0%)] Loss: 12290.880859\n",
      "Train Epoch: 1566 [33024/118836 (28%)] Loss: 12225.484375\n",
      "Train Epoch: 1566 [65792/118836 (55%)] Loss: 12262.246094\n",
      "Train Epoch: 1566 [98560/118836 (83%)] Loss: 12187.184570\n",
      "    epoch          : 1566\n",
      "    loss           : 12241.878293656948\n",
      "    val_loss       : 12240.014588465616\n",
      "    val_log_likelihood: -12162.47038245063\n",
      "    val_log_marginal: -12170.489858439325\n",
      "Train Epoch: 1567 [256/118836 (0%)] Loss: 12189.868164\n",
      "Train Epoch: 1567 [33024/118836 (28%)] Loss: 12284.588867\n",
      "Train Epoch: 1567 [65792/118836 (55%)] Loss: 12230.141602\n",
      "Train Epoch: 1567 [98560/118836 (83%)] Loss: 12241.623047\n",
      "    epoch          : 1567\n",
      "    loss           : 12245.300252985422\n",
      "    val_loss       : 12241.856850896329\n",
      "    val_log_likelihood: -12163.49739615643\n",
      "    val_log_marginal: -12171.69169675585\n",
      "Train Epoch: 1568 [256/118836 (0%)] Loss: 12231.339844\n",
      "Train Epoch: 1568 [33024/118836 (28%)] Loss: 12247.771484\n",
      "Train Epoch: 1568 [65792/118836 (55%)] Loss: 12449.678711\n",
      "Train Epoch: 1568 [98560/118836 (83%)] Loss: 12266.552734\n",
      "    epoch          : 1568\n",
      "    loss           : 12239.110672398418\n",
      "    val_loss       : 12243.604663464797\n",
      "    val_log_likelihood: -12165.1670057576\n",
      "    val_log_marginal: -12173.359379457463\n",
      "Train Epoch: 1569 [256/118836 (0%)] Loss: 12231.149414\n",
      "Train Epoch: 1569 [33024/118836 (28%)] Loss: 12247.148438\n",
      "Train Epoch: 1569 [65792/118836 (55%)] Loss: 12297.755859\n",
      "Train Epoch: 1569 [98560/118836 (83%)] Loss: 12222.457031\n",
      "    epoch          : 1569\n",
      "    loss           : 12244.079352770887\n",
      "    val_loss       : 12243.984955663747\n",
      "    val_log_likelihood: -12162.912296933158\n",
      "    val_log_marginal: -12171.044194510167\n",
      "Train Epoch: 1570 [256/118836 (0%)] Loss: 12288.301758\n",
      "Train Epoch: 1570 [33024/118836 (28%)] Loss: 12182.602539\n",
      "Train Epoch: 1570 [65792/118836 (55%)] Loss: 12243.351562\n",
      "Train Epoch: 1570 [98560/118836 (83%)] Loss: 12291.424805\n",
      "    epoch          : 1570\n",
      "    loss           : 12240.701962010184\n",
      "    val_loss       : 12240.221632867197\n",
      "    val_log_likelihood: -12163.33726026158\n",
      "    val_log_marginal: -12171.426951815569\n",
      "Train Epoch: 1571 [256/118836 (0%)] Loss: 12197.881836\n",
      "Train Epoch: 1571 [33024/118836 (28%)] Loss: 12199.123047\n",
      "Train Epoch: 1571 [65792/118836 (55%)] Loss: 12338.776367\n",
      "Train Epoch: 1571 [98560/118836 (83%)] Loss: 12294.317383\n",
      "    epoch          : 1571\n",
      "    loss           : 12244.350126977357\n",
      "    val_loss       : 12244.185919549482\n",
      "    val_log_likelihood: -12164.292112702904\n",
      "    val_log_marginal: -12172.482942194634\n",
      "Train Epoch: 1572 [256/118836 (0%)] Loss: 12301.210938\n",
      "Train Epoch: 1572 [33024/118836 (28%)] Loss: 12252.269531\n",
      "Train Epoch: 1572 [65792/118836 (55%)] Loss: 12214.554688\n",
      "Train Epoch: 1572 [98560/118836 (83%)] Loss: 12281.796875\n",
      "    epoch          : 1572\n",
      "    loss           : 12242.789934701976\n",
      "    val_loss       : 12238.541159216646\n",
      "    val_log_likelihood: -12159.292153413204\n",
      "    val_log_marginal: -12167.37417357721\n",
      "Train Epoch: 1573 [256/118836 (0%)] Loss: 12237.846680\n",
      "Train Epoch: 1573 [33024/118836 (28%)] Loss: 12356.146484\n",
      "Train Epoch: 1573 [65792/118836 (55%)] Loss: 12192.548828\n",
      "Train Epoch: 1573 [98560/118836 (83%)] Loss: 12271.445312\n",
      "    epoch          : 1573\n",
      "    loss           : 12243.33931580852\n",
      "    val_loss       : 12241.107297088878\n",
      "    val_log_likelihood: -12167.084389377844\n",
      "    val_log_marginal: -12175.158345737924\n",
      "Train Epoch: 1574 [256/118836 (0%)] Loss: 12217.294922\n",
      "Train Epoch: 1574 [33024/118836 (28%)] Loss: 12354.578125\n",
      "Train Epoch: 1574 [65792/118836 (55%)] Loss: 12273.376953\n",
      "Train Epoch: 1574 [98560/118836 (83%)] Loss: 12191.947266\n",
      "    epoch          : 1574\n",
      "    loss           : 12240.573332008633\n",
      "    val_loss       : 12242.436823882108\n",
      "    val_log_likelihood: -12163.656915581058\n",
      "    val_log_marginal: -12171.873548114103\n",
      "Train Epoch: 1575 [256/118836 (0%)] Loss: 12326.105469\n",
      "Train Epoch: 1575 [33024/118836 (28%)] Loss: 12256.265625\n",
      "Train Epoch: 1575 [65792/118836 (55%)] Loss: 12244.871094\n",
      "Train Epoch: 1575 [98560/118836 (83%)] Loss: 12188.509766\n",
      "    epoch          : 1575\n",
      "    loss           : 12240.322484523625\n",
      "    val_loss       : 12242.030909642357\n",
      "    val_log_likelihood: -12162.620899406793\n",
      "    val_log_marginal: -12170.960667707177\n",
      "Train Epoch: 1576 [256/118836 (0%)] Loss: 12239.256836\n",
      "Train Epoch: 1576 [33024/118836 (28%)] Loss: 12342.202148\n",
      "Train Epoch: 1576 [65792/118836 (55%)] Loss: 12319.488281\n",
      "Train Epoch: 1576 [98560/118836 (83%)] Loss: 12233.511719\n",
      "    epoch          : 1576\n",
      "    loss           : 12242.387628915942\n",
      "    val_loss       : 12237.474239210094\n",
      "    val_log_likelihood: -12164.900850715985\n",
      "    val_log_marginal: -12173.042007207092\n",
      "Train Epoch: 1577 [256/118836 (0%)] Loss: 12334.029297\n",
      "Train Epoch: 1577 [33024/118836 (28%)] Loss: 12294.941406\n",
      "Train Epoch: 1577 [65792/118836 (55%)] Loss: 12254.495117\n",
      "Train Epoch: 1577 [98560/118836 (83%)] Loss: 12265.440430\n",
      "    epoch          : 1577\n",
      "    loss           : 12242.876202246174\n",
      "    val_loss       : 12240.659454634624\n",
      "    val_log_likelihood: -12164.431183603441\n",
      "    val_log_marginal: -12172.701824265994\n",
      "Train Epoch: 1578 [256/118836 (0%)] Loss: 12313.623047\n",
      "Train Epoch: 1578 [33024/118836 (28%)] Loss: 12192.885742\n",
      "Train Epoch: 1578 [65792/118836 (55%)] Loss: 12275.392578\n",
      "Train Epoch: 1578 [98560/118836 (83%)] Loss: 12295.264648\n",
      "    epoch          : 1578\n",
      "    loss           : 12241.63083805056\n",
      "    val_loss       : 12239.221169963712\n",
      "    val_log_likelihood: -12163.947787427625\n",
      "    val_log_marginal: -12172.052261445515\n",
      "Train Epoch: 1579 [256/118836 (0%)] Loss: 12210.851562\n",
      "Train Epoch: 1579 [33024/118836 (28%)] Loss: 12263.771484\n",
      "Train Epoch: 1579 [65792/118836 (55%)] Loss: 12238.943359\n",
      "Train Epoch: 1579 [98560/118836 (83%)] Loss: 12275.269531\n",
      "    epoch          : 1579\n",
      "    loss           : 12242.852524038462\n",
      "    val_loss       : 12243.369484219751\n",
      "    val_log_likelihood: -12164.302482197321\n",
      "    val_log_marginal: -12172.321704030885\n",
      "Train Epoch: 1580 [256/118836 (0%)] Loss: 12414.762695\n",
      "Train Epoch: 1580 [33024/118836 (28%)] Loss: 12329.727539\n",
      "Train Epoch: 1580 [65792/118836 (55%)] Loss: 12347.682617\n",
      "Train Epoch: 1580 [98560/118836 (83%)] Loss: 12246.774414\n",
      "    epoch          : 1580\n",
      "    loss           : 12241.27559546888\n",
      "    val_loss       : 12244.174148695747\n",
      "    val_log_likelihood: -12165.83929286859\n",
      "    val_log_marginal: -12174.055172261395\n",
      "Train Epoch: 1581 [256/118836 (0%)] Loss: 12278.210938\n",
      "Train Epoch: 1581 [33024/118836 (28%)] Loss: 12188.825195\n",
      "Train Epoch: 1581 [65792/118836 (55%)] Loss: 12307.302734\n",
      "Train Epoch: 1581 [98560/118836 (83%)] Loss: 12225.949219\n",
      "    epoch          : 1581\n",
      "    loss           : 12241.851579139526\n",
      "    val_loss       : 12240.91881667143\n",
      "    val_log_likelihood: -12161.776886728441\n",
      "    val_log_marginal: -12169.891923266392\n",
      "Train Epoch: 1582 [256/118836 (0%)] Loss: 12267.937500\n",
      "Train Epoch: 1582 [33024/118836 (28%)] Loss: 12181.572266\n",
      "Train Epoch: 1582 [65792/118836 (55%)] Loss: 12218.608398\n",
      "Train Epoch: 1582 [98560/118836 (83%)] Loss: 12323.587891\n",
      "    epoch          : 1582\n",
      "    loss           : 12241.09841197529\n",
      "    val_loss       : 12244.724269341079\n",
      "    val_log_likelihood: -12164.06539204663\n",
      "    val_log_marginal: -12172.141050700928\n",
      "Train Epoch: 1583 [256/118836 (0%)] Loss: 12239.951172\n",
      "Train Epoch: 1583 [33024/118836 (28%)] Loss: 12403.884766\n",
      "Train Epoch: 1583 [65792/118836 (55%)] Loss: 12196.426758\n",
      "Train Epoch: 1583 [98560/118836 (83%)] Loss: 12277.732422\n",
      "    epoch          : 1583\n",
      "    loss           : 12238.866630802831\n",
      "    val_loss       : 12240.467983375633\n",
      "    val_log_likelihood: -12163.468162447012\n",
      "    val_log_marginal: -12171.50547610614\n",
      "Train Epoch: 1584 [256/118836 (0%)] Loss: 12333.178711\n",
      "Train Epoch: 1584 [33024/118836 (28%)] Loss: 12150.019531\n",
      "Train Epoch: 1584 [65792/118836 (55%)] Loss: 12252.287109\n",
      "Train Epoch: 1584 [98560/118836 (83%)] Loss: 12288.019531\n",
      "    epoch          : 1584\n",
      "    loss           : 12243.654357778898\n",
      "    val_loss       : 12244.542620224547\n",
      "    val_log_likelihood: -12163.428835653172\n",
      "    val_log_marginal: -12171.53333403842\n",
      "Train Epoch: 1585 [256/118836 (0%)] Loss: 12226.515625\n",
      "Train Epoch: 1585 [33024/118836 (28%)] Loss: 12299.045898\n",
      "Train Epoch: 1585 [65792/118836 (55%)] Loss: 12220.104492\n",
      "Train Epoch: 1585 [98560/118836 (83%)] Loss: 12242.734375\n",
      "    epoch          : 1585\n",
      "    loss           : 12243.648590648263\n",
      "    val_loss       : 12239.582637524612\n",
      "    val_log_likelihood: -12162.720355310432\n",
      "    val_log_marginal: -12170.77797294477\n",
      "Train Epoch: 1586 [256/118836 (0%)] Loss: 12390.817383\n",
      "Train Epoch: 1586 [33024/118836 (28%)] Loss: 12306.558594\n",
      "Train Epoch: 1586 [65792/118836 (55%)] Loss: 12226.251953\n",
      "Train Epoch: 1586 [98560/118836 (83%)] Loss: 12208.856445\n",
      "    epoch          : 1586\n",
      "    loss           : 12240.079863426645\n",
      "    val_loss       : 12239.84040362443\n",
      "    val_log_likelihood: -12163.63079992504\n",
      "    val_log_marginal: -12171.969099776603\n",
      "Train Epoch: 1587 [256/118836 (0%)] Loss: 12175.537109\n",
      "Train Epoch: 1587 [33024/118836 (28%)] Loss: 12328.660156\n",
      "Train Epoch: 1587 [65792/118836 (55%)] Loss: 12202.273438\n",
      "Train Epoch: 1587 [98560/118836 (83%)] Loss: 12254.867188\n",
      "    epoch          : 1587\n",
      "    loss           : 12242.238588838916\n",
      "    val_loss       : 12244.673425884223\n",
      "    val_log_likelihood: -12163.945234795026\n",
      "    val_log_marginal: -12172.070816404585\n",
      "Train Epoch: 1588 [256/118836 (0%)] Loss: 12231.587891\n",
      "Train Epoch: 1588 [33024/118836 (28%)] Loss: 12234.018555\n",
      "Train Epoch: 1588 [65792/118836 (55%)] Loss: 12300.080078\n",
      "Train Epoch: 1588 [98560/118836 (83%)] Loss: 12166.360352\n",
      "    epoch          : 1588\n",
      "    loss           : 12240.512952013543\n",
      "    val_loss       : 12243.696601828437\n",
      "    val_log_likelihood: -12164.119594900229\n",
      "    val_log_marginal: -12172.241124377408\n",
      "Train Epoch: 1589 [256/118836 (0%)] Loss: 12252.888672\n",
      "Train Epoch: 1589 [33024/118836 (28%)] Loss: 12355.886719\n",
      "Train Epoch: 1589 [65792/118836 (55%)] Loss: 12230.490234\n",
      "Train Epoch: 1589 [98560/118836 (83%)] Loss: 12256.001953\n",
      "    epoch          : 1589\n",
      "    loss           : 12241.595859019593\n",
      "    val_loss       : 12238.330655032196\n",
      "    val_log_likelihood: -12161.915961990799\n",
      "    val_log_marginal: -12169.997524240194\n",
      "Train Epoch: 1590 [256/118836 (0%)] Loss: 12323.398438\n",
      "Train Epoch: 1590 [33024/118836 (28%)] Loss: 12252.216797\n",
      "Train Epoch: 1590 [65792/118836 (55%)] Loss: 12375.674805\n",
      "Train Epoch: 1590 [98560/118836 (83%)] Loss: 12300.991211\n",
      "    epoch          : 1590\n",
      "    loss           : 12240.24743137407\n",
      "    val_loss       : 12236.813387343142\n",
      "    val_log_likelihood: -12161.666387833437\n",
      "    val_log_marginal: -12169.707193536264\n",
      "Train Epoch: 1591 [256/118836 (0%)] Loss: 12223.062500\n",
      "Train Epoch: 1591 [33024/118836 (28%)] Loss: 12308.369141\n",
      "Train Epoch: 1591 [65792/118836 (55%)] Loss: 12264.677734\n",
      "Train Epoch: 1591 [98560/118836 (83%)] Loss: 12215.128906\n",
      "    epoch          : 1591\n",
      "    loss           : 12242.294884880324\n",
      "    val_loss       : 12242.718823201953\n",
      "    val_log_likelihood: -12160.858213302576\n",
      "    val_log_marginal: -12168.997495992004\n",
      "Train Epoch: 1592 [256/118836 (0%)] Loss: 12224.638672\n",
      "Train Epoch: 1592 [33024/118836 (28%)] Loss: 12184.548828\n",
      "Train Epoch: 1592 [65792/118836 (55%)] Loss: 12238.173828\n",
      "Train Epoch: 1592 [98560/118836 (83%)] Loss: 12290.277344\n",
      "    epoch          : 1592\n",
      "    loss           : 12241.924329087831\n",
      "    val_loss       : 12238.997474350012\n",
      "    val_log_likelihood: -12164.184754478132\n",
      "    val_log_marginal: -12172.294062007124\n",
      "Train Epoch: 1593 [256/118836 (0%)] Loss: 12259.460938\n",
      "Train Epoch: 1593 [33024/118836 (28%)] Loss: 12214.077148\n",
      "Train Epoch: 1593 [65792/118836 (55%)] Loss: 12297.744141\n",
      "Train Epoch: 1593 [98560/118836 (83%)] Loss: 12247.503906\n",
      "    epoch          : 1593\n",
      "    loss           : 12243.046463696754\n",
      "    val_loss       : 12241.480345424308\n",
      "    val_log_likelihood: -12161.205760507133\n",
      "    val_log_marginal: -12169.414993317809\n",
      "Train Epoch: 1594 [256/118836 (0%)] Loss: 12260.832031\n",
      "Train Epoch: 1594 [33024/118836 (28%)] Loss: 12221.060547\n",
      "Train Epoch: 1594 [65792/118836 (55%)] Loss: 12202.341797\n",
      "Train Epoch: 1594 [98560/118836 (83%)] Loss: 12346.640625\n",
      "    epoch          : 1594\n",
      "    loss           : 12242.654217554538\n",
      "    val_loss       : 12243.429296490822\n",
      "    val_log_likelihood: -12164.313032141748\n",
      "    val_log_marginal: -12172.659894760049\n",
      "Train Epoch: 1595 [256/118836 (0%)] Loss: 12295.861328\n",
      "Train Epoch: 1595 [33024/118836 (28%)] Loss: 12238.646484\n",
      "Train Epoch: 1595 [65792/118836 (55%)] Loss: 12307.474609\n",
      "Train Epoch: 1595 [98560/118836 (83%)] Loss: 12321.692383\n",
      "    epoch          : 1595\n",
      "    loss           : 12239.876869119624\n",
      "    val_loss       : 12246.889441258583\n",
      "    val_log_likelihood: -12164.771154492348\n",
      "    val_log_marginal: -12173.171980523011\n",
      "Train Epoch: 1596 [256/118836 (0%)] Loss: 12190.021484\n",
      "Train Epoch: 1596 [33024/118836 (28%)] Loss: 12240.544922\n",
      "Train Epoch: 1596 [65792/118836 (55%)] Loss: 12213.722656\n",
      "Train Epoch: 1596 [98560/118836 (83%)] Loss: 12261.864258\n",
      "    epoch          : 1596\n",
      "    loss           : 12243.830896531224\n",
      "    val_loss       : 12243.71486686775\n",
      "    val_log_likelihood: -12165.229517227563\n",
      "    val_log_marginal: -12173.50417636041\n",
      "Train Epoch: 1597 [256/118836 (0%)] Loss: 12275.471680\n",
      "Train Epoch: 1597 [33024/118836 (28%)] Loss: 12156.132812\n",
      "Train Epoch: 1597 [65792/118836 (55%)] Loss: 12282.080078\n",
      "Train Epoch: 1597 [98560/118836 (83%)] Loss: 12270.498047\n",
      "    epoch          : 1597\n",
      "    loss           : 12244.14485967871\n",
      "    val_loss       : 12243.928239907613\n",
      "    val_log_likelihood: -12163.83416773289\n",
      "    val_log_marginal: -12172.128236757493\n",
      "Train Epoch: 1598 [256/118836 (0%)] Loss: 12262.034180\n",
      "Train Epoch: 1598 [33024/118836 (28%)] Loss: 12305.267578\n",
      "Train Epoch: 1598 [65792/118836 (55%)] Loss: 12324.351562\n",
      "Train Epoch: 1598 [98560/118836 (83%)] Loss: 12177.865234\n",
      "    epoch          : 1598\n",
      "    loss           : 12242.455345165166\n",
      "    val_loss       : 12245.738615855897\n",
      "    val_log_likelihood: -12162.093906540787\n",
      "    val_log_marginal: -12170.115187854177\n",
      "Train Epoch: 1599 [256/118836 (0%)] Loss: 12272.602539\n",
      "Train Epoch: 1599 [33024/118836 (28%)] Loss: 12304.792969\n",
      "Train Epoch: 1599 [65792/118836 (55%)] Loss: 12358.423828\n",
      "Train Epoch: 1599 [98560/118836 (83%)] Loss: 12270.439453\n",
      "    epoch          : 1599\n",
      "    loss           : 12242.125964123243\n",
      "    val_loss       : 12238.741133018755\n",
      "    val_log_likelihood: -12165.235880150176\n",
      "    val_log_marginal: -12173.411555821156\n",
      "Train Epoch: 1600 [256/118836 (0%)] Loss: 12319.892578\n",
      "Train Epoch: 1600 [33024/118836 (28%)] Loss: 12211.183594\n",
      "Train Epoch: 1600 [65792/118836 (55%)] Loss: 12165.627930\n",
      "Train Epoch: 1600 [98560/118836 (83%)] Loss: 12330.582031\n",
      "    epoch          : 1600\n",
      "    loss           : 12242.809793572944\n",
      "    val_loss       : 12244.783120681865\n",
      "    val_log_likelihood: -12164.400181903951\n",
      "    val_log_marginal: -12172.787756950709\n",
      "Saving checkpoint: saved/models/SelfiesAutoencodingOperad/0905_154251/checkpoint-epoch1600.pth ...\n",
      "Train Epoch: 1601 [256/118836 (0%)] Loss: 12322.479492\n",
      "Train Epoch: 1601 [33024/118836 (28%)] Loss: 12210.414062\n",
      "Train Epoch: 1601 [65792/118836 (55%)] Loss: 12273.242188\n",
      "Train Epoch: 1601 [98560/118836 (83%)] Loss: 12224.867188\n",
      "    epoch          : 1601\n",
      "    loss           : 12240.190326134718\n",
      "    val_loss       : 12244.024021140656\n",
      "    val_log_likelihood: -12160.994520910877\n",
      "    val_log_marginal: -12169.228077975262\n",
      "Train Epoch: 1602 [256/118836 (0%)] Loss: 12207.955078\n",
      "Train Epoch: 1602 [33024/118836 (28%)] Loss: 12221.728516\n",
      "Train Epoch: 1602 [65792/118836 (55%)] Loss: 12235.373047\n",
      "Train Epoch: 1602 [98560/118836 (83%)] Loss: 12213.953125\n",
      "    epoch          : 1602\n",
      "    loss           : 12246.571476782205\n",
      "    val_loss       : 12240.547577776373\n",
      "    val_log_likelihood: -12164.194086667701\n",
      "    val_log_marginal: -12172.422071827892\n",
      "Train Epoch: 1603 [256/118836 (0%)] Loss: 12244.740234\n",
      "Train Epoch: 1603 [33024/118836 (28%)] Loss: 12331.672852\n",
      "Train Epoch: 1603 [65792/118836 (55%)] Loss: 12208.886719\n",
      "Train Epoch: 1603 [98560/118836 (83%)] Loss: 12225.781250\n",
      "    epoch          : 1603\n",
      "    loss           : 12239.681039178817\n",
      "    val_loss       : 12241.562299442276\n",
      "    val_log_likelihood: -12162.44141561983\n",
      "    val_log_marginal: -12170.810318682818\n",
      "Train Epoch: 1604 [256/118836 (0%)] Loss: 12316.744141\n",
      "Train Epoch: 1604 [33024/118836 (28%)] Loss: 12313.912109\n",
      "Train Epoch: 1604 [65792/118836 (55%)] Loss: 12314.886719\n",
      "Train Epoch: 1604 [98560/118836 (83%)] Loss: 12230.021484\n",
      "    epoch          : 1604\n",
      "    loss           : 12237.90304018688\n",
      "    val_loss       : 12239.930920920855\n",
      "    val_log_likelihood: -12161.853327582196\n",
      "    val_log_marginal: -12169.953559564054\n",
      "Train Epoch: 1605 [256/118836 (0%)] Loss: 12312.557617\n",
      "Train Epoch: 1605 [33024/118836 (28%)] Loss: 12405.415039\n",
      "Train Epoch: 1605 [65792/118836 (55%)] Loss: 12224.267578\n",
      "Train Epoch: 1605 [98560/118836 (83%)] Loss: 12351.935547\n",
      "    epoch          : 1605\n",
      "    loss           : 12242.804864880583\n",
      "    val_loss       : 12237.510177850734\n",
      "    val_log_likelihood: -12165.995686485474\n",
      "    val_log_marginal: -12174.335273520232\n",
      "Train Epoch: 1606 [256/118836 (0%)] Loss: 12302.485352\n",
      "Train Epoch: 1606 [33024/118836 (28%)] Loss: 12325.972656\n",
      "Train Epoch: 1606 [65792/118836 (55%)] Loss: 12265.251953\n",
      "Train Epoch: 1606 [98560/118836 (83%)] Loss: 12260.223633\n",
      "    epoch          : 1606\n",
      "    loss           : 12244.285933138182\n",
      "    val_loss       : 12240.000700087929\n",
      "    val_log_likelihood: -12163.232718478597\n",
      "    val_log_marginal: -12171.516912711875\n",
      "Train Epoch: 1607 [256/118836 (0%)] Loss: 12257.455078\n",
      "Train Epoch: 1607 [33024/118836 (28%)] Loss: 12289.375000\n",
      "Train Epoch: 1607 [65792/118836 (55%)] Loss: 12231.501953\n",
      "Train Epoch: 1607 [98560/118836 (83%)] Loss: 12267.958008\n",
      "    epoch          : 1607\n",
      "    loss           : 12242.044739647952\n",
      "    val_loss       : 12238.0204482364\n",
      "    val_log_likelihood: -12165.07706249354\n",
      "    val_log_marginal: -12173.253783782917\n",
      "Train Epoch: 1608 [256/118836 (0%)] Loss: 12275.862305\n",
      "Train Epoch: 1608 [33024/118836 (28%)] Loss: 12249.638672\n",
      "Train Epoch: 1608 [65792/118836 (55%)] Loss: 12272.258789\n",
      "Train Epoch: 1608 [98560/118836 (83%)] Loss: 12327.255859\n",
      "    epoch          : 1608\n",
      "    loss           : 12240.549959289703\n",
      "    val_loss       : 12244.106094234685\n",
      "    val_log_likelihood: -12164.392316577492\n",
      "    val_log_marginal: -12172.57890636698\n",
      "Train Epoch: 1609 [256/118836 (0%)] Loss: 12289.761719\n",
      "Train Epoch: 1609 [33024/118836 (28%)] Loss: 12271.805664\n",
      "Train Epoch: 1609 [65792/118836 (55%)] Loss: 12217.487305\n",
      "Train Epoch: 1609 [98560/118836 (83%)] Loss: 12191.455078\n",
      "    epoch          : 1609\n",
      "    loss           : 12246.720627843259\n",
      "    val_loss       : 12242.84195089476\n",
      "    val_log_likelihood: -12162.015459897124\n",
      "    val_log_marginal: -12170.092523852614\n",
      "Train Epoch: 1610 [256/118836 (0%)] Loss: 12162.414062\n",
      "Train Epoch: 1610 [33024/118836 (28%)] Loss: 12228.880859\n",
      "Train Epoch: 1610 [65792/118836 (55%)] Loss: 12331.646484\n",
      "Train Epoch: 1610 [98560/118836 (83%)] Loss: 12321.372070\n",
      "    epoch          : 1610\n",
      "    loss           : 12238.451043282155\n",
      "    val_loss       : 12241.737392363784\n",
      "    val_log_likelihood: -12164.05504710763\n",
      "    val_log_marginal: -12172.181744212494\n",
      "Train Epoch: 1611 [256/118836 (0%)] Loss: 12326.698242\n",
      "Train Epoch: 1611 [33024/118836 (28%)] Loss: 12264.737305\n",
      "Train Epoch: 1611 [65792/118836 (55%)] Loss: 12277.119141\n",
      "Train Epoch: 1611 [98560/118836 (83%)] Loss: 12385.649414\n",
      "    epoch          : 1611\n",
      "    loss           : 12242.538459276779\n",
      "    val_loss       : 12242.482146351738\n",
      "    val_log_likelihood: -12163.89953797043\n",
      "    val_log_marginal: -12171.992676111993\n",
      "Train Epoch: 1612 [256/118836 (0%)] Loss: 12305.414062\n",
      "Train Epoch: 1612 [33024/118836 (28%)] Loss: 12328.857422\n",
      "Train Epoch: 1612 [65792/118836 (55%)] Loss: 12294.375977\n",
      "Train Epoch: 1612 [98560/118836 (83%)] Loss: 12285.916016\n",
      "    epoch          : 1612\n",
      "    loss           : 12241.369977609336\n",
      "    val_loss       : 12243.988597837164\n",
      "    val_log_likelihood: -12164.872457868074\n",
      "    val_log_marginal: -12172.973378083667\n",
      "Train Epoch: 1613 [256/118836 (0%)] Loss: 12260.801758\n",
      "Train Epoch: 1613 [33024/118836 (28%)] Loss: 12189.212891\n",
      "Train Epoch: 1613 [65792/118836 (55%)] Loss: 12287.667969\n",
      "Train Epoch: 1613 [98560/118836 (83%)] Loss: 12307.063477\n",
      "    epoch          : 1613\n",
      "    loss           : 12240.07323976427\n",
      "    val_loss       : 12241.30685243341\n",
      "    val_log_likelihood: -12164.145391335815\n",
      "    val_log_marginal: -12172.207476304962\n",
      "Train Epoch: 1614 [256/118836 (0%)] Loss: 12268.324219\n",
      "Train Epoch: 1614 [33024/118836 (28%)] Loss: 12189.132812\n",
      "Train Epoch: 1614 [65792/118836 (55%)] Loss: 12374.082031\n",
      "Train Epoch: 1614 [98560/118836 (83%)] Loss: 12290.273438\n",
      "    epoch          : 1614\n",
      "    loss           : 12243.186060115539\n",
      "    val_loss       : 12242.20281686497\n",
      "    val_log_likelihood: -12163.309707305883\n",
      "    val_log_marginal: -12171.377574858787\n",
      "Train Epoch: 1615 [256/118836 (0%)] Loss: 12272.716797\n",
      "Train Epoch: 1615 [33024/118836 (28%)] Loss: 12278.187500\n",
      "Train Epoch: 1615 [65792/118836 (55%)] Loss: 12338.156250\n",
      "Train Epoch: 1615 [98560/118836 (83%)] Loss: 12316.213867\n",
      "    epoch          : 1615\n",
      "    loss           : 12243.69918353236\n",
      "    val_loss       : 12244.513686311571\n",
      "    val_log_likelihood: -12163.778821113781\n",
      "    val_log_marginal: -12171.911848033427\n",
      "Train Epoch: 1616 [256/118836 (0%)] Loss: 12213.388672\n",
      "Train Epoch: 1616 [33024/118836 (28%)] Loss: 12230.035156\n",
      "Train Epoch: 1616 [65792/118836 (55%)] Loss: 12297.706055\n",
      "Train Epoch: 1616 [98560/118836 (83%)] Loss: 12191.674805\n",
      "    epoch          : 1616\n",
      "    loss           : 12241.572971431711\n",
      "    val_loss       : 12240.214955623565\n",
      "    val_log_likelihood: -12163.184009415063\n",
      "    val_log_marginal: -12171.373814779085\n",
      "Train Epoch: 1617 [256/118836 (0%)] Loss: 12216.144531\n",
      "Train Epoch: 1617 [33024/118836 (28%)] Loss: 12275.881836\n",
      "Train Epoch: 1617 [65792/118836 (55%)] Loss: 12195.188477\n",
      "Train Epoch: 1617 [98560/118836 (83%)] Loss: 12260.798828\n",
      "    epoch          : 1617\n",
      "    loss           : 12243.34855478443\n",
      "    val_loss       : 12241.9267925135\n",
      "    val_log_likelihood: -12163.49625675274\n",
      "    val_log_marginal: -12171.795795372725\n",
      "Train Epoch: 1618 [256/118836 (0%)] Loss: 12222.554688\n",
      "Train Epoch: 1618 [33024/118836 (28%)] Loss: 12232.277344\n",
      "Train Epoch: 1618 [65792/118836 (55%)] Loss: 12203.171875\n",
      "Train Epoch: 1618 [98560/118836 (83%)] Loss: 12156.436523\n",
      "    epoch          : 1618\n",
      "    loss           : 12241.225025040063\n",
      "    val_loss       : 12244.549533537496\n",
      "    val_log_likelihood: -12163.817792015612\n",
      "    val_log_marginal: -12171.890043759331\n",
      "Train Epoch: 1619 [256/118836 (0%)] Loss: 12295.908203\n",
      "Train Epoch: 1619 [33024/118836 (28%)] Loss: 12238.691406\n",
      "Train Epoch: 1619 [65792/118836 (55%)] Loss: 12315.516602\n",
      "Train Epoch: 1619 [98560/118836 (83%)] Loss: 12345.047852\n",
      "    epoch          : 1619\n",
      "    loss           : 12248.931435134924\n",
      "    val_loss       : 12240.43406277831\n",
      "    val_log_likelihood: -12164.197301650382\n",
      "    val_log_marginal: -12172.490859117926\n",
      "Train Epoch: 1620 [256/118836 (0%)] Loss: 12239.417969\n",
      "Train Epoch: 1620 [33024/118836 (28%)] Loss: 12212.753906\n",
      "Train Epoch: 1620 [65792/118836 (55%)] Loss: 12245.425781\n",
      "Train Epoch: 1620 [98560/118836 (83%)] Loss: 12411.109375\n",
      "    epoch          : 1620\n",
      "    loss           : 12240.270186815033\n",
      "    val_loss       : 12243.1973616407\n",
      "    val_log_likelihood: -12163.090981053558\n",
      "    val_log_marginal: -12171.299700497906\n",
      "Train Epoch: 1621 [256/118836 (0%)] Loss: 12211.753906\n",
      "Train Epoch: 1621 [33024/118836 (28%)] Loss: 12273.937500\n",
      "Train Epoch: 1621 [65792/118836 (55%)] Loss: 12338.254883\n",
      "Train Epoch: 1621 [98560/118836 (83%)] Loss: 12270.651367\n",
      "    epoch          : 1621\n",
      "    loss           : 12240.071331711384\n",
      "    val_loss       : 12239.921398558736\n",
      "    val_log_likelihood: -12162.275424227151\n",
      "    val_log_marginal: -12170.396294205755\n",
      "Train Epoch: 1622 [256/118836 (0%)] Loss: 12247.859375\n",
      "Train Epoch: 1622 [33024/118836 (28%)] Loss: 12312.620117\n",
      "Train Epoch: 1622 [65792/118836 (55%)] Loss: 12217.780273\n",
      "Train Epoch: 1622 [98560/118836 (83%)] Loss: 12246.167969\n",
      "    epoch          : 1622\n",
      "    loss           : 12243.705656631255\n",
      "    val_loss       : 12245.047171392733\n",
      "    val_log_likelihood: -12163.449379975704\n",
      "    val_log_marginal: -12171.590331477108\n",
      "Train Epoch: 1623 [256/118836 (0%)] Loss: 12259.287109\n",
      "Train Epoch: 1623 [33024/118836 (28%)] Loss: 12251.631836\n",
      "Train Epoch: 1623 [65792/118836 (55%)] Loss: 12188.964844\n",
      "Train Epoch: 1623 [98560/118836 (83%)] Loss: 12223.962891\n",
      "    epoch          : 1623\n",
      "    loss           : 12242.503019508633\n",
      "    val_loss       : 12239.181432780628\n",
      "    val_log_likelihood: -12162.4492995244\n",
      "    val_log_marginal: -12170.635345615185\n",
      "Train Epoch: 1624 [256/118836 (0%)] Loss: 12275.110352\n",
      "Train Epoch: 1624 [33024/118836 (28%)] Loss: 12203.845703\n",
      "Train Epoch: 1624 [65792/118836 (55%)] Loss: 12318.179688\n",
      "Train Epoch: 1624 [98560/118836 (83%)] Loss: 12214.090820\n",
      "    epoch          : 1624\n",
      "    loss           : 12243.721119113163\n",
      "    val_loss       : 12241.715355318709\n",
      "    val_log_likelihood: -12161.87052929849\n",
      "    val_log_marginal: -12169.892339560707\n",
      "Train Epoch: 1625 [256/118836 (0%)] Loss: 12358.435547\n",
      "Train Epoch: 1625 [33024/118836 (28%)] Loss: 12229.303711\n",
      "Train Epoch: 1625 [65792/118836 (55%)] Loss: 12287.396484\n",
      "Train Epoch: 1625 [98560/118836 (83%)] Loss: 12247.678711\n",
      "    epoch          : 1625\n",
      "    loss           : 12242.643766154879\n",
      "    val_loss       : 12241.419875723772\n",
      "    val_log_likelihood: -12163.200175603548\n",
      "    val_log_marginal: -12171.3519346483\n",
      "Train Epoch: 1626 [256/118836 (0%)] Loss: 12298.240234\n",
      "Train Epoch: 1626 [33024/118836 (28%)] Loss: 12224.561523\n",
      "Train Epoch: 1626 [65792/118836 (55%)] Loss: 12308.512695\n",
      "Train Epoch: 1626 [98560/118836 (83%)] Loss: 12255.360352\n",
      "    epoch          : 1626\n",
      "    loss           : 12241.692660030241\n",
      "    val_loss       : 12241.40422455458\n",
      "    val_log_likelihood: -12160.490345843673\n",
      "    val_log_marginal: -12168.532074891147\n",
      "Train Epoch: 1627 [256/118836 (0%)] Loss: 12207.237305\n",
      "Train Epoch: 1627 [33024/118836 (28%)] Loss: 12283.748047\n",
      "Train Epoch: 1627 [65792/118836 (55%)] Loss: 12193.297852\n",
      "Train Epoch: 1627 [98560/118836 (83%)] Loss: 12169.873047\n",
      "    epoch          : 1627\n",
      "    loss           : 12241.978356014784\n",
      "    val_loss       : 12240.68201531432\n",
      "    val_log_likelihood: -12162.285145910877\n",
      "    val_log_marginal: -12170.322005901156\n",
      "Train Epoch: 1628 [256/118836 (0%)] Loss: 12271.970703\n",
      "Train Epoch: 1628 [33024/118836 (28%)] Loss: 12281.876953\n",
      "Train Epoch: 1628 [65792/118836 (55%)] Loss: 12299.285156\n",
      "Train Epoch: 1628 [98560/118836 (83%)] Loss: 12316.120117\n",
      "    epoch          : 1628\n",
      "    loss           : 12246.920958856752\n",
      "    val_loss       : 12239.928411477336\n",
      "    val_log_likelihood: -12163.69651555392\n",
      "    val_log_marginal: -12171.871439174096\n",
      "Train Epoch: 1629 [256/118836 (0%)] Loss: 12258.447266\n",
      "Train Epoch: 1629 [33024/118836 (28%)] Loss: 12304.606445\n",
      "Train Epoch: 1629 [65792/118836 (55%)] Loss: 12265.754883\n",
      "Train Epoch: 1629 [98560/118836 (83%)] Loss: 12274.523438\n",
      "    epoch          : 1629\n",
      "    loss           : 12241.635223131205\n",
      "    val_loss       : 12239.834658672078\n",
      "    val_log_likelihood: -12161.080592819479\n",
      "    val_log_marginal: -12169.133408562897\n",
      "Train Epoch: 1630 [256/118836 (0%)] Loss: 12187.269531\n",
      "Train Epoch: 1630 [33024/118836 (28%)] Loss: 12214.703125\n",
      "Train Epoch: 1630 [65792/118836 (55%)] Loss: 12356.202148\n",
      "Train Epoch: 1630 [98560/118836 (83%)] Loss: 12296.765625\n",
      "    epoch          : 1630\n",
      "    loss           : 12246.916016271196\n",
      "    val_loss       : 12242.953036012601\n",
      "    val_log_likelihood: -12164.945222840415\n",
      "    val_log_marginal: -12173.240182610203\n",
      "Train Epoch: 1631 [256/118836 (0%)] Loss: 12268.673828\n",
      "Train Epoch: 1631 [33024/118836 (28%)] Loss: 12300.940430\n",
      "Train Epoch: 1631 [65792/118836 (55%)] Loss: 12323.818359\n",
      "Train Epoch: 1631 [98560/118836 (83%)] Loss: 12240.035156\n",
      "    epoch          : 1631\n",
      "    loss           : 12243.314567016905\n",
      "    val_loss       : 12240.247903377169\n",
      "    val_log_likelihood: -12161.855476181245\n",
      "    val_log_marginal: -12170.353269645397\n",
      "Train Epoch: 1632 [256/118836 (0%)] Loss: 12261.111328\n",
      "Train Epoch: 1632 [33024/118836 (28%)] Loss: 12196.869141\n",
      "Train Epoch: 1632 [65792/118836 (55%)] Loss: 12216.004883\n",
      "Train Epoch: 1632 [98560/118836 (83%)] Loss: 12189.046875\n",
      "    epoch          : 1632\n",
      "    loss           : 12241.689024212934\n",
      "    val_loss       : 12249.000700529497\n",
      "    val_log_likelihood: -12164.945275505324\n",
      "    val_log_marginal: -12173.293913887477\n",
      "Train Epoch: 1633 [256/118836 (0%)] Loss: 12340.160156\n",
      "Train Epoch: 1633 [33024/118836 (28%)] Loss: 12289.491211\n",
      "Train Epoch: 1633 [65792/118836 (55%)] Loss: 12261.134766\n",
      "Train Epoch: 1633 [98560/118836 (83%)] Loss: 12280.608398\n",
      "    epoch          : 1633\n",
      "    loss           : 12242.742553408034\n",
      "    val_loss       : 12237.223858724597\n",
      "    val_log_likelihood: -12163.752906747572\n",
      "    val_log_marginal: -12171.944507606171\n",
      "Train Epoch: 1634 [256/118836 (0%)] Loss: 12321.018555\n",
      "Train Epoch: 1634 [33024/118836 (28%)] Loss: 12261.089844\n",
      "Train Epoch: 1634 [65792/118836 (55%)] Loss: 12257.806641\n",
      "Train Epoch: 1634 [98560/118836 (83%)] Loss: 12282.957031\n",
      "    epoch          : 1634\n",
      "    loss           : 12240.926773321184\n",
      "    val_loss       : 12243.197893274137\n",
      "    val_log_likelihood: -12164.057150311466\n",
      "    val_log_marginal: -12172.10102941134\n",
      "Train Epoch: 1635 [256/118836 (0%)] Loss: 12268.990234\n",
      "Train Epoch: 1635 [33024/118836 (28%)] Loss: 12207.532227\n",
      "Train Epoch: 1635 [65792/118836 (55%)] Loss: 12209.412109\n",
      "Train Epoch: 1635 [98560/118836 (83%)] Loss: 12257.463867\n",
      "    epoch          : 1635\n",
      "    loss           : 12242.25384405371\n",
      "    val_loss       : 12240.135681880665\n",
      "    val_log_likelihood: -12166.184280978598\n",
      "    val_log_marginal: -12174.404064241131\n",
      "Train Epoch: 1636 [256/118836 (0%)] Loss: 12263.512695\n",
      "Train Epoch: 1636 [33024/118836 (28%)] Loss: 12291.778320\n",
      "Train Epoch: 1636 [65792/118836 (55%)] Loss: 12346.771484\n",
      "Train Epoch: 1636 [98560/118836 (83%)] Loss: 12224.007812\n",
      "    epoch          : 1636\n",
      "    loss           : 12242.290090111921\n",
      "    val_loss       : 12240.34203327606\n",
      "    val_log_likelihood: -12158.999453318858\n",
      "    val_log_marginal: -12167.163086397855\n",
      "Train Epoch: 1637 [256/118836 (0%)] Loss: 12229.981445\n",
      "Train Epoch: 1637 [33024/118836 (28%)] Loss: 12296.472656\n",
      "Train Epoch: 1637 [65792/118836 (55%)] Loss: 12152.236328\n",
      "Train Epoch: 1637 [98560/118836 (83%)] Loss: 12207.335938\n",
      "    epoch          : 1637\n",
      "    loss           : 12241.859686466089\n",
      "    val_loss       : 12243.525647721215\n",
      "    val_log_likelihood: -12162.044843200734\n",
      "    val_log_marginal: -12170.322144098684\n",
      "Train Epoch: 1638 [256/118836 (0%)] Loss: 12215.648438\n",
      "Train Epoch: 1638 [33024/118836 (28%)] Loss: 12228.264648\n",
      "Train Epoch: 1638 [65792/118836 (55%)] Loss: 12233.538086\n",
      "Train Epoch: 1638 [98560/118836 (83%)] Loss: 12216.101562\n",
      "    epoch          : 1638\n",
      "    loss           : 12237.864890599152\n",
      "    val_loss       : 12239.560147194947\n",
      "    val_log_likelihood: -12162.252418385546\n",
      "    val_log_marginal: -12170.518197486184\n",
      "Train Epoch: 1639 [256/118836 (0%)] Loss: 12307.984375\n",
      "Train Epoch: 1639 [33024/118836 (28%)] Loss: 12286.430664\n",
      "Train Epoch: 1639 [65792/118836 (55%)] Loss: 12251.350586\n",
      "Train Epoch: 1639 [98560/118836 (83%)] Loss: 12441.888672\n",
      "    epoch          : 1639\n",
      "    loss           : 12241.612306626084\n",
      "    val_loss       : 12243.468886884319\n",
      "    val_log_likelihood: -12164.99442091217\n",
      "    val_log_marginal: -12173.302274855949\n",
      "Train Epoch: 1640 [256/118836 (0%)] Loss: 12257.375977\n",
      "Train Epoch: 1640 [33024/118836 (28%)] Loss: 12402.880859\n",
      "Train Epoch: 1640 [65792/118836 (55%)] Loss: 12217.260742\n",
      "Train Epoch: 1640 [98560/118836 (83%)] Loss: 12312.337891\n",
      "    epoch          : 1640\n",
      "    loss           : 12243.160090499638\n",
      "    val_loss       : 12242.557717290521\n",
      "    val_log_likelihood: -12163.578483153691\n",
      "    val_log_marginal: -12171.820412729518\n",
      "Train Epoch: 1641 [256/118836 (0%)] Loss: 12337.097656\n",
      "Train Epoch: 1641 [33024/118836 (28%)] Loss: 12237.577148\n",
      "Train Epoch: 1641 [65792/118836 (55%)] Loss: 12259.679688\n",
      "Train Epoch: 1641 [98560/118836 (83%)] Loss: 12314.284180\n",
      "    epoch          : 1641\n",
      "    loss           : 12242.627036968826\n",
      "    val_loss       : 12239.577360680889\n",
      "    val_log_likelihood: -12164.757776636166\n",
      "    val_log_marginal: -12173.047182797454\n",
      "Train Epoch: 1642 [256/118836 (0%)] Loss: 12371.816406\n",
      "Train Epoch: 1642 [33024/118836 (28%)] Loss: 12269.943359\n",
      "Train Epoch: 1642 [65792/118836 (55%)] Loss: 12303.556641\n",
      "Train Epoch: 1642 [98560/118836 (83%)] Loss: 12210.686523\n",
      "    epoch          : 1642\n",
      "    loss           : 12242.681876809347\n",
      "    val_loss       : 12238.964753630366\n",
      "    val_log_likelihood: -12163.804069091191\n",
      "    val_log_marginal: -12171.880730776771\n",
      "Train Epoch: 1643 [256/118836 (0%)] Loss: 12217.050781\n",
      "Train Epoch: 1643 [33024/118836 (28%)] Loss: 12260.980469\n",
      "Train Epoch: 1643 [65792/118836 (55%)] Loss: 12283.015625\n",
      "Train Epoch: 1643 [98560/118836 (83%)] Loss: 12290.643555\n",
      "    epoch          : 1643\n",
      "    loss           : 12242.20886046707\n",
      "    val_loss       : 12244.25370038403\n",
      "    val_log_likelihood: -12164.455892169408\n",
      "    val_log_marginal: -12172.665027523068\n",
      "Train Epoch: 1644 [256/118836 (0%)] Loss: 12313.505859\n",
      "Train Epoch: 1644 [33024/118836 (28%)] Loss: 12178.840820\n",
      "Train Epoch: 1644 [65792/118836 (55%)] Loss: 12376.226562\n",
      "Train Epoch: 1644 [98560/118836 (83%)] Loss: 12214.983398\n",
      "    epoch          : 1644\n",
      "    loss           : 12239.572526526314\n",
      "    val_loss       : 12239.639447648698\n",
      "    val_log_likelihood: -12164.35175797405\n",
      "    val_log_marginal: -12172.44479365056\n",
      "Train Epoch: 1645 [256/118836 (0%)] Loss: 12299.470703\n",
      "Train Epoch: 1645 [33024/118836 (28%)] Loss: 12179.310547\n",
      "Train Epoch: 1645 [65792/118836 (55%)] Loss: 12135.610352\n",
      "Train Epoch: 1645 [98560/118836 (83%)] Loss: 12209.562500\n",
      "    epoch          : 1645\n",
      "    loss           : 12240.583947218776\n",
      "    val_loss       : 12242.515899033737\n",
      "    val_log_likelihood: -12162.946706827697\n",
      "    val_log_marginal: -12171.271215874816\n",
      "Train Epoch: 1646 [256/118836 (0%)] Loss: 12293.638672\n",
      "Train Epoch: 1646 [33024/118836 (28%)] Loss: 12213.492188\n",
      "Train Epoch: 1646 [65792/118836 (55%)] Loss: 12193.167969\n",
      "Train Epoch: 1646 [98560/118836 (83%)] Loss: 12234.418945\n",
      "    epoch          : 1646\n",
      "    loss           : 12240.937970753204\n",
      "    val_loss       : 12243.639472502182\n",
      "    val_log_likelihood: -12160.21714436647\n",
      "    val_log_marginal: -12168.49220275286\n",
      "Train Epoch: 1647 [256/118836 (0%)] Loss: 12221.703125\n",
      "Train Epoch: 1647 [33024/118836 (28%)] Loss: 12258.218750\n",
      "Train Epoch: 1647 [65792/118836 (55%)] Loss: 12216.109375\n",
      "Train Epoch: 1647 [98560/118836 (83%)] Loss: 12246.614258\n",
      "    epoch          : 1647\n",
      "    loss           : 12247.749188863472\n",
      "    val_loss       : 12243.110293373133\n",
      "    val_log_likelihood: -12163.20765482837\n",
      "    val_log_marginal: -12171.664144813458\n",
      "Train Epoch: 1648 [256/118836 (0%)] Loss: 12252.450195\n",
      "Train Epoch: 1648 [33024/118836 (28%)] Loss: 12289.208008\n",
      "Train Epoch: 1648 [65792/118836 (55%)] Loss: 12233.570312\n",
      "Train Epoch: 1648 [98560/118836 (83%)] Loss: 12309.180664\n",
      "    epoch          : 1648\n",
      "    loss           : 12244.001194653381\n",
      "    val_loss       : 12238.946376171414\n",
      "    val_log_likelihood: -12161.285803414494\n",
      "    val_log_marginal: -12169.599070184047\n",
      "Train Epoch: 1649 [256/118836 (0%)] Loss: 12204.482422\n",
      "Train Epoch: 1649 [33024/118836 (28%)] Loss: 12235.816406\n",
      "Train Epoch: 1649 [65792/118836 (55%)] Loss: 12179.785156\n",
      "Train Epoch: 1649 [98560/118836 (83%)] Loss: 12246.289062\n",
      "    epoch          : 1649\n",
      "    loss           : 12243.7278893003\n",
      "    val_loss       : 12240.518652718769\n",
      "    val_log_likelihood: -12161.113434559811\n",
      "    val_log_marginal: -12169.225903279723\n",
      "Train Epoch: 1650 [256/118836 (0%)] Loss: 12260.921875\n",
      "Train Epoch: 1650 [33024/118836 (28%)] Loss: 12241.232422\n",
      "Train Epoch: 1650 [65792/118836 (55%)] Loss: 12239.187500\n",
      "Train Epoch: 1650 [98560/118836 (83%)] Loss: 12302.939453\n",
      "    epoch          : 1650\n",
      "    loss           : 12242.275624870761\n",
      "    val_loss       : 12241.110770710593\n",
      "    val_log_likelihood: -12163.792681193136\n",
      "    val_log_marginal: -12172.106062459856\n",
      "Train Epoch: 1651 [256/118836 (0%)] Loss: 12227.599609\n",
      "Train Epoch: 1651 [33024/118836 (28%)] Loss: 12227.208008\n",
      "Train Epoch: 1651 [65792/118836 (55%)] Loss: 12256.455078\n",
      "Train Epoch: 1651 [98560/118836 (83%)] Loss: 12261.495117\n",
      "    epoch          : 1651\n",
      "    loss           : 12241.718983438017\n",
      "    val_loss       : 12236.320561332624\n",
      "    val_log_likelihood: -12161.817626104994\n",
      "    val_log_marginal: -12170.026639692875\n",
      "Train Epoch: 1652 [256/118836 (0%)] Loss: 12232.396484\n",
      "Train Epoch: 1652 [33024/118836 (28%)] Loss: 12252.486328\n",
      "Train Epoch: 1652 [65792/118836 (55%)] Loss: 12232.679688\n",
      "Train Epoch: 1652 [98560/118836 (83%)] Loss: 12220.484375\n",
      "    epoch          : 1652\n",
      "    loss           : 12241.829704947271\n",
      "    val_loss       : 12244.205199425653\n",
      "    val_log_likelihood: -12165.522321843982\n",
      "    val_log_marginal: -12173.832409852961\n",
      "Train Epoch: 1653 [256/118836 (0%)] Loss: 12220.982422\n",
      "Train Epoch: 1653 [33024/118836 (28%)] Loss: 12193.000977\n",
      "Train Epoch: 1653 [65792/118836 (55%)] Loss: 12228.580078\n",
      "Train Epoch: 1653 [98560/118836 (83%)] Loss: 12310.968750\n",
      "    epoch          : 1653\n",
      "    loss           : 12241.125435535565\n",
      "    val_loss       : 12241.653025617084\n",
      "    val_log_likelihood: -12162.098643959367\n",
      "    val_log_marginal: -12170.357496460361\n",
      "Train Epoch: 1654 [256/118836 (0%)] Loss: 12350.605469\n",
      "Train Epoch: 1654 [33024/118836 (28%)] Loss: 12209.241211\n",
      "Train Epoch: 1654 [65792/118836 (55%)] Loss: 12269.107422\n",
      "Train Epoch: 1654 [98560/118836 (83%)] Loss: 12322.441406\n",
      "    epoch          : 1654\n",
      "    loss           : 12243.306958391491\n",
      "    val_loss       : 12239.340078428439\n",
      "    val_log_likelihood: -12161.471062409533\n",
      "    val_log_marginal: -12169.986484671648\n",
      "Train Epoch: 1655 [256/118836 (0%)] Loss: 12299.999023\n",
      "Train Epoch: 1655 [33024/118836 (28%)] Loss: 12295.262695\n",
      "Train Epoch: 1655 [65792/118836 (55%)] Loss: 12258.816406\n",
      "Train Epoch: 1655 [98560/118836 (83%)] Loss: 12202.703125\n",
      "    epoch          : 1655\n",
      "    loss           : 12239.200020516699\n",
      "    val_loss       : 12237.253533766332\n",
      "    val_log_likelihood: -12159.590461189517\n",
      "    val_log_marginal: -12167.773107359237\n",
      "Train Epoch: 1656 [256/118836 (0%)] Loss: 12264.250000\n",
      "Train Epoch: 1656 [33024/118836 (28%)] Loss: 12216.178711\n",
      "Train Epoch: 1656 [65792/118836 (55%)] Loss: 12225.103516\n",
      "Train Epoch: 1656 [98560/118836 (83%)] Loss: 12265.349609\n",
      "    epoch          : 1656\n",
      "    loss           : 12242.16973867866\n",
      "    val_loss       : 12242.699130730383\n",
      "    val_log_likelihood: -12161.34497970947\n",
      "    val_log_marginal: -12169.564083398673\n",
      "Train Epoch: 1657 [256/118836 (0%)] Loss: 12271.626953\n",
      "Train Epoch: 1657 [33024/118836 (28%)] Loss: 12281.230469\n",
      "Train Epoch: 1657 [65792/118836 (55%)] Loss: 12291.910156\n",
      "Train Epoch: 1657 [98560/118836 (83%)] Loss: 12266.860352\n",
      "    epoch          : 1657\n",
      "    loss           : 12239.924195971618\n",
      "    val_loss       : 12245.291702661292\n",
      "    val_log_likelihood: -12161.507386980458\n",
      "    val_log_marginal: -12169.854535110433\n",
      "Train Epoch: 1658 [256/118836 (0%)] Loss: 12279.335938\n",
      "Train Epoch: 1658 [33024/118836 (28%)] Loss: 12171.859375\n",
      "Train Epoch: 1658 [65792/118836 (55%)] Loss: 12269.907227\n",
      "Train Epoch: 1658 [98560/118836 (83%)] Loss: 12206.330078\n",
      "    epoch          : 1658\n",
      "    loss           : 12241.167992497674\n",
      "    val_loss       : 12247.287574065633\n",
      "    val_log_likelihood: -12174.038269456936\n",
      "    val_log_marginal: -12182.69931286582\n",
      "Train Epoch: 1659 [256/118836 (0%)] Loss: 12230.936523\n",
      "Train Epoch: 1659 [33024/118836 (28%)] Loss: 12304.114258\n",
      "Train Epoch: 1659 [65792/118836 (55%)] Loss: 12286.775391\n",
      "Train Epoch: 1659 [98560/118836 (83%)] Loss: 12357.359375\n",
      "    epoch          : 1659\n",
      "    loss           : 12243.783557886165\n",
      "    val_loss       : 12243.150923674913\n",
      "    val_log_likelihood: -12163.700286426023\n",
      "    val_log_marginal: -12172.475461234728\n",
      "Train Epoch: 1660 [256/118836 (0%)] Loss: 12282.253906\n",
      "Train Epoch: 1660 [33024/118836 (28%)] Loss: 12192.642578\n",
      "Train Epoch: 1660 [65792/118836 (55%)] Loss: 12234.281250\n",
      "Train Epoch: 1660 [98560/118836 (83%)] Loss: 12240.259766\n",
      "    epoch          : 1660\n",
      "    loss           : 12244.885950747002\n",
      "    val_loss       : 12240.591387163886\n",
      "    val_log_likelihood: -12164.001642143558\n",
      "    val_log_marginal: -12172.393842655569\n",
      "Train Epoch: 1661 [256/118836 (0%)] Loss: 12306.933594\n",
      "Train Epoch: 1661 [33024/118836 (28%)] Loss: 12247.753906\n",
      "Train Epoch: 1661 [65792/118836 (55%)] Loss: 12245.317383\n",
      "Train Epoch: 1661 [98560/118836 (83%)] Loss: 12375.562500\n",
      "    epoch          : 1661\n",
      "    loss           : 12241.888362509046\n",
      "    val_loss       : 12248.91448705842\n",
      "    val_log_likelihood: -12170.428827252636\n",
      "    val_log_marginal: -12178.906493596123\n",
      "Train Epoch: 1662 [256/118836 (0%)] Loss: 12245.640625\n",
      "Train Epoch: 1662 [33024/118836 (28%)] Loss: 12340.636719\n",
      "Train Epoch: 1662 [65792/118836 (55%)] Loss: 12188.718750\n",
      "Train Epoch: 1662 [98560/118836 (83%)] Loss: 12387.158203\n",
      "    epoch          : 1662\n",
      "    loss           : 12251.452987198873\n",
      "    val_loss       : 12252.070384763536\n",
      "    val_log_likelihood: -12164.605150498863\n",
      "    val_log_marginal: -12173.055541673242\n",
      "Train Epoch: 1663 [256/118836 (0%)] Loss: 12292.635742\n",
      "Train Epoch: 1663 [33024/118836 (28%)] Loss: 12272.361328\n",
      "Train Epoch: 1663 [65792/118836 (55%)] Loss: 12276.524414\n",
      "Train Epoch: 1663 [98560/118836 (83%)] Loss: 12276.538086\n",
      "    epoch          : 1663\n",
      "    loss           : 12247.572130247105\n",
      "    val_loss       : 12238.58151356002\n",
      "    val_log_likelihood: -12163.203822406173\n",
      "    val_log_marginal: -12171.624456861102\n",
      "Train Epoch: 1664 [256/118836 (0%)] Loss: 12313.996094\n",
      "Train Epoch: 1664 [33024/118836 (28%)] Loss: 12209.242188\n",
      "Train Epoch: 1664 [65792/118836 (55%)] Loss: 12221.864258\n",
      "Train Epoch: 1664 [98560/118836 (83%)] Loss: 12263.574219\n",
      "    epoch          : 1664\n",
      "    loss           : 12240.19053453267\n",
      "    val_loss       : 12240.180893012763\n",
      "    val_log_likelihood: -12161.914820971619\n",
      "    val_log_marginal: -12170.180342705931\n",
      "Train Epoch: 1665 [256/118836 (0%)] Loss: 12287.164062\n",
      "Train Epoch: 1665 [33024/118836 (28%)] Loss: 12166.693359\n",
      "Train Epoch: 1665 [65792/118836 (55%)] Loss: 12244.084961\n",
      "Train Epoch: 1665 [98560/118836 (83%)] Loss: 12243.302734\n",
      "    epoch          : 1665\n",
      "    loss           : 12240.496886793064\n",
      "    val_loss       : 12243.484882392258\n",
      "    val_log_likelihood: -12163.146549802263\n",
      "    val_log_marginal: -12171.633396651232\n",
      "Train Epoch: 1666 [256/118836 (0%)] Loss: 12166.011719\n",
      "Train Epoch: 1666 [33024/118836 (28%)] Loss: 12246.080078\n",
      "Train Epoch: 1666 [65792/118836 (55%)] Loss: 12358.212891\n",
      "Train Epoch: 1666 [98560/118836 (83%)] Loss: 12316.491211\n",
      "    epoch          : 1666\n",
      "    loss           : 12245.975674143145\n",
      "    val_loss       : 12240.865714774229\n",
      "    val_log_likelihood: -12163.036679978288\n",
      "    val_log_marginal: -12171.235751690761\n",
      "Train Epoch: 1667 [256/118836 (0%)] Loss: 12245.115234\n",
      "Train Epoch: 1667 [33024/118836 (28%)] Loss: 12345.593750\n",
      "Train Epoch: 1667 [65792/118836 (55%)] Loss: 12326.002930\n",
      "Train Epoch: 1667 [98560/118836 (83%)] Loss: 12287.666016\n",
      "    epoch          : 1667\n",
      "    loss           : 12242.570598602926\n",
      "    val_loss       : 12242.49950031886\n",
      "    val_log_likelihood: -12164.18345497958\n",
      "    val_log_marginal: -12172.403330756353\n",
      "Train Epoch: 1668 [256/118836 (0%)] Loss: 12275.486328\n",
      "Train Epoch: 1668 [33024/118836 (28%)] Loss: 12203.888672\n",
      "Train Epoch: 1668 [65792/118836 (55%)] Loss: 12233.175781\n",
      "Train Epoch: 1668 [98560/118836 (83%)] Loss: 12480.896484\n",
      "    epoch          : 1668\n",
      "    loss           : 12250.826240210143\n",
      "    val_loss       : 12250.487952051939\n",
      "    val_log_likelihood: -12163.293715428557\n",
      "    val_log_marginal: -12171.814725432645\n",
      "Train Epoch: 1669 [256/118836 (0%)] Loss: 12273.302734\n",
      "Train Epoch: 1669 [33024/118836 (28%)] Loss: 12293.158203\n",
      "Train Epoch: 1669 [65792/118836 (55%)] Loss: 12240.049805\n",
      "Train Epoch: 1669 [98560/118836 (83%)] Loss: 12341.107422\n",
      "    epoch          : 1669\n",
      "    loss           : 12243.451811446703\n",
      "    val_loss       : 12246.587411607661\n",
      "    val_log_likelihood: -12162.70071646893\n",
      "    val_log_marginal: -12170.971392774116\n",
      "Train Epoch: 1670 [256/118836 (0%)] Loss: 12237.944336\n",
      "Train Epoch: 1670 [33024/118836 (28%)] Loss: 12362.874023\n",
      "Train Epoch: 1670 [65792/118836 (55%)] Loss: 12255.077148\n",
      "Train Epoch: 1670 [98560/118836 (83%)] Loss: 12184.191406\n",
      "    epoch          : 1670\n",
      "    loss           : 12247.038848124741\n",
      "    val_loss       : 12245.040797512682\n",
      "    val_log_likelihood: -12160.866794936415\n",
      "    val_log_marginal: -12169.292716680293\n",
      "Train Epoch: 1671 [256/118836 (0%)] Loss: 12223.107422\n",
      "Train Epoch: 1671 [33024/118836 (28%)] Loss: 12188.105469\n",
      "Train Epoch: 1671 [65792/118836 (55%)] Loss: 12267.380859\n",
      "Train Epoch: 1671 [98560/118836 (83%)] Loss: 12239.685547\n",
      "    epoch          : 1671\n",
      "    loss           : 12245.770625904674\n",
      "    val_loss       : 12246.54019201313\n",
      "    val_log_likelihood: -12161.680883445772\n",
      "    val_log_marginal: -12170.065237408338\n",
      "Train Epoch: 1672 [256/118836 (0%)] Loss: 12388.875000\n",
      "Train Epoch: 1672 [33024/118836 (28%)] Loss: 12337.574219\n",
      "Train Epoch: 1672 [65792/118836 (55%)] Loss: 12260.687500\n",
      "Train Epoch: 1672 [98560/118836 (83%)] Loss: 12315.770508\n",
      "    epoch          : 1672\n",
      "    loss           : 12249.456185865125\n",
      "    val_loss       : 12244.507646237078\n",
      "    val_log_likelihood: -12166.24001612257\n",
      "    val_log_marginal: -12174.622989077085\n",
      "Train Epoch: 1673 [256/118836 (0%)] Loss: 12218.683594\n",
      "Train Epoch: 1673 [33024/118836 (28%)] Loss: 12246.701172\n",
      "Train Epoch: 1673 [65792/118836 (55%)] Loss: 12344.826172\n",
      "Train Epoch: 1673 [98560/118836 (83%)] Loss: 12287.096680\n",
      "    epoch          : 1673\n",
      "    loss           : 12241.359958998915\n",
      "    val_loss       : 12243.194835096527\n",
      "    val_log_likelihood: -12164.882813469292\n",
      "    val_log_marginal: -12173.174259527326\n",
      "Train Epoch: 1674 [256/118836 (0%)] Loss: 12148.183594\n",
      "Train Epoch: 1674 [33024/118836 (28%)] Loss: 12284.804688\n",
      "Train Epoch: 1674 [65792/118836 (55%)] Loss: 12208.248047\n",
      "Train Epoch: 1674 [98560/118836 (83%)] Loss: 12243.379883\n",
      "    epoch          : 1674\n",
      "    loss           : 12237.991289934864\n",
      "    val_loss       : 12239.916092857924\n",
      "    val_log_likelihood: -12163.073200831008\n",
      "    val_log_marginal: -12171.401876052407\n",
      "Train Epoch: 1675 [256/118836 (0%)] Loss: 12214.923828\n",
      "Train Epoch: 1675 [33024/118836 (28%)] Loss: 12288.439453\n",
      "Train Epoch: 1675 [65792/118836 (55%)] Loss: 12299.758789\n",
      "Train Epoch: 1675 [98560/118836 (83%)] Loss: 12294.039062\n",
      "    epoch          : 1675\n",
      "    loss           : 12242.186468510909\n",
      "    val_loss       : 12236.592930359979\n",
      "    val_log_likelihood: -12164.159863362025\n",
      "    val_log_marginal: -12172.478927976883\n",
      "Train Epoch: 1676 [256/118836 (0%)] Loss: 12197.926758\n",
      "Train Epoch: 1676 [33024/118836 (28%)] Loss: 12202.159180\n",
      "Train Epoch: 1676 [65792/118836 (55%)] Loss: 12177.563477\n",
      "Train Epoch: 1676 [98560/118836 (83%)] Loss: 12252.582031\n",
      "    epoch          : 1676\n",
      "    loss           : 12236.564635352048\n",
      "    val_loss       : 12236.424818700614\n",
      "    val_log_likelihood: -12163.793552748915\n",
      "    val_log_marginal: -12172.111067017559\n",
      "Train Epoch: 1677 [256/118836 (0%)] Loss: 12251.448242\n",
      "Train Epoch: 1677 [33024/118836 (28%)] Loss: 12323.810547\n",
      "Train Epoch: 1677 [65792/118836 (55%)] Loss: 12306.892578\n",
      "Train Epoch: 1677 [98560/118836 (83%)] Loss: 12139.357422\n",
      "    epoch          : 1677\n",
      "    loss           : 12237.281043540632\n",
      "    val_loss       : 12239.899964179234\n",
      "    val_log_likelihood: -12161.185881604115\n",
      "    val_log_marginal: -12169.433515266399\n",
      "Train Epoch: 1678 [256/118836 (0%)] Loss: 12236.315430\n",
      "Train Epoch: 1678 [33024/118836 (28%)] Loss: 12307.561523\n",
      "Train Epoch: 1678 [65792/118836 (55%)] Loss: 12268.743164\n",
      "Train Epoch: 1678 [98560/118836 (83%)] Loss: 12223.473633\n",
      "    epoch          : 1678\n",
      "    loss           : 12238.075775272693\n",
      "    val_loss       : 12239.976783934946\n",
      "    val_log_likelihood: -12161.417796054333\n",
      "    val_log_marginal: -12169.630250684762\n",
      "Train Epoch: 1679 [256/118836 (0%)] Loss: 12173.335938\n",
      "Train Epoch: 1679 [33024/118836 (28%)] Loss: 12231.000977\n",
      "Train Epoch: 1679 [65792/118836 (55%)] Loss: 12236.975586\n",
      "Train Epoch: 1679 [98560/118836 (83%)] Loss: 12244.511719\n",
      "    epoch          : 1679\n",
      "    loss           : 12236.279941616263\n",
      "    val_loss       : 12240.081182273212\n",
      "    val_log_likelihood: -12162.272730562447\n",
      "    val_log_marginal: -12170.474121094874\n",
      "Train Epoch: 1680 [256/118836 (0%)] Loss: 12239.675781\n",
      "Train Epoch: 1680 [33024/118836 (28%)] Loss: 12258.468750\n",
      "Train Epoch: 1680 [65792/118836 (55%)] Loss: 12274.312500\n",
      "Train Epoch: 1680 [98560/118836 (83%)] Loss: 12359.422852\n",
      "    epoch          : 1680\n",
      "    loss           : 12242.170743835297\n",
      "    val_loss       : 12238.999461774398\n",
      "    val_log_likelihood: -12162.350783188585\n",
      "    val_log_marginal: -12170.483190570605\n",
      "Train Epoch: 1681 [256/118836 (0%)] Loss: 12332.955078\n",
      "Train Epoch: 1681 [33024/118836 (28%)] Loss: 12251.171875\n",
      "Train Epoch: 1681 [65792/118836 (55%)] Loss: 12249.877930\n",
      "Train Epoch: 1681 [98560/118836 (83%)] Loss: 12258.615234\n",
      "    epoch          : 1681\n",
      "    loss           : 12236.699597905035\n",
      "    val_loss       : 12242.145576926985\n",
      "    val_log_likelihood: -12162.281488769127\n",
      "    val_log_marginal: -12170.503392279617\n",
      "Train Epoch: 1682 [256/118836 (0%)] Loss: 12341.057617\n",
      "Train Epoch: 1682 [33024/118836 (28%)] Loss: 12139.337891\n",
      "Train Epoch: 1682 [65792/118836 (55%)] Loss: 12204.509766\n",
      "Train Epoch: 1682 [98560/118836 (83%)] Loss: 12363.550781\n",
      "    epoch          : 1682\n",
      "    loss           : 12239.13897881772\n",
      "    val_loss       : 12236.57368759994\n",
      "    val_log_likelihood: -12166.306609930727\n",
      "    val_log_marginal: -12174.389823661566\n",
      "Train Epoch: 1683 [256/118836 (0%)] Loss: 12234.647461\n",
      "Train Epoch: 1683 [33024/118836 (28%)] Loss: 12218.481445\n",
      "Train Epoch: 1683 [65792/118836 (55%)] Loss: 12237.129883\n",
      "Train Epoch: 1683 [98560/118836 (83%)] Loss: 12310.716797\n",
      "    epoch          : 1683\n",
      "    loss           : 12243.547946391645\n",
      "    val_loss       : 12242.567520411705\n",
      "    val_log_likelihood: -12162.610819246278\n",
      "    val_log_marginal: -12170.91367563292\n",
      "Train Epoch: 1684 [256/118836 (0%)] Loss: 12277.502930\n",
      "Train Epoch: 1684 [33024/118836 (28%)] Loss: 12317.712891\n",
      "Train Epoch: 1684 [65792/118836 (55%)] Loss: 12304.570312\n",
      "Train Epoch: 1684 [98560/118836 (83%)] Loss: 12280.763672\n",
      "    epoch          : 1684\n",
      "    loss           : 12240.472659804072\n",
      "    val_loss       : 12243.838178957983\n",
      "    val_log_likelihood: -12161.380100580283\n",
      "    val_log_marginal: -12169.6071439656\n",
      "Train Epoch: 1685 [256/118836 (0%)] Loss: 12190.944336\n",
      "Train Epoch: 1685 [33024/118836 (28%)] Loss: 12233.636719\n",
      "Train Epoch: 1685 [65792/118836 (55%)] Loss: 12349.061523\n",
      "Train Epoch: 1685 [98560/118836 (83%)] Loss: 12299.843750\n",
      "    epoch          : 1685\n",
      "    loss           : 12238.672347853339\n",
      "    val_loss       : 12242.19635563089\n",
      "    val_log_likelihood: -12162.666892834986\n",
      "    val_log_marginal: -12170.925645652776\n",
      "Train Epoch: 1686 [256/118836 (0%)] Loss: 12333.578125\n",
      "Train Epoch: 1686 [33024/118836 (28%)] Loss: 12243.611328\n",
      "Train Epoch: 1686 [65792/118836 (55%)] Loss: 12260.949219\n",
      "Train Epoch: 1686 [98560/118836 (83%)] Loss: 12385.267578\n",
      "    epoch          : 1686\n",
      "    loss           : 12241.639717418839\n",
      "    val_loss       : 12245.118866377197\n",
      "    val_log_likelihood: -12163.074452672663\n",
      "    val_log_marginal: -12171.32150539669\n",
      "Train Epoch: 1687 [256/118836 (0%)] Loss: 12320.505859\n",
      "Train Epoch: 1687 [33024/118836 (28%)] Loss: 12228.299805\n",
      "Train Epoch: 1687 [65792/118836 (55%)] Loss: 12293.670898\n",
      "Train Epoch: 1687 [98560/118836 (83%)] Loss: 12197.002930\n",
      "    epoch          : 1687\n",
      "    loss           : 12237.361853643248\n",
      "    val_loss       : 12238.613307249352\n",
      "    val_log_likelihood: -12163.677914017268\n",
      "    val_log_marginal: -12171.864916274033\n",
      "Train Epoch: 1688 [256/118836 (0%)] Loss: 12289.136719\n",
      "Train Epoch: 1688 [33024/118836 (28%)] Loss: 12172.024414\n",
      "Train Epoch: 1688 [65792/118836 (55%)] Loss: 12369.484375\n",
      "Train Epoch: 1688 [98560/118836 (83%)] Loss: 12278.992188\n",
      "    epoch          : 1688\n",
      "    loss           : 12241.914441493485\n",
      "    val_loss       : 12236.012400494983\n",
      "    val_log_likelihood: -12160.257490048594\n",
      "    val_log_marginal: -12168.478987348313\n",
      "Train Epoch: 1689 [256/118836 (0%)] Loss: 12294.846680\n",
      "Train Epoch: 1689 [33024/118836 (28%)] Loss: 12261.211914\n",
      "Train Epoch: 1689 [65792/118836 (55%)] Loss: 12245.135742\n",
      "Train Epoch: 1689 [98560/118836 (83%)] Loss: 12246.014648\n",
      "    epoch          : 1689\n",
      "    loss           : 12238.55464436647\n",
      "    val_loss       : 12243.92444520027\n",
      "    val_log_likelihood: -12160.86312503231\n",
      "    val_log_marginal: -12169.010386836597\n",
      "Train Epoch: 1690 [256/118836 (0%)] Loss: 12325.946289\n",
      "Train Epoch: 1690 [33024/118836 (28%)] Loss: 12162.738281\n",
      "Train Epoch: 1690 [65792/118836 (55%)] Loss: 12268.357422\n",
      "Train Epoch: 1690 [98560/118836 (83%)] Loss: 12273.578125\n",
      "    epoch          : 1690\n",
      "    loss           : 12242.114042791047\n",
      "    val_loss       : 12240.822208167516\n",
      "    val_log_likelihood: -12162.340051663306\n",
      "    val_log_marginal: -12170.654409205108\n",
      "Train Epoch: 1691 [256/118836 (0%)] Loss: 12194.785156\n",
      "Train Epoch: 1691 [33024/118836 (28%)] Loss: 12304.783203\n",
      "Train Epoch: 1691 [65792/118836 (55%)] Loss: 12272.060547\n",
      "Train Epoch: 1691 [98560/118836 (83%)] Loss: 12213.550781\n",
      "    epoch          : 1691\n",
      "    loss           : 12239.310488232786\n",
      "    val_loss       : 12240.918980906057\n",
      "    val_log_likelihood: -12163.689643752585\n",
      "    val_log_marginal: -12171.891461551975\n",
      "Train Epoch: 1692 [256/118836 (0%)] Loss: 12231.917969\n",
      "Train Epoch: 1692 [33024/118836 (28%)] Loss: 12239.939453\n",
      "Train Epoch: 1692 [65792/118836 (55%)] Loss: 12294.695312\n",
      "Train Epoch: 1692 [98560/118836 (83%)] Loss: 12363.414062\n",
      "    epoch          : 1692\n",
      "    loss           : 12239.259248184193\n",
      "    val_loss       : 12241.292477612822\n",
      "    val_log_likelihood: -12162.942203816428\n",
      "    val_log_marginal: -12171.141031112644\n",
      "Train Epoch: 1693 [256/118836 (0%)] Loss: 12240.478516\n",
      "Train Epoch: 1693 [33024/118836 (28%)] Loss: 12168.496094\n",
      "Train Epoch: 1693 [65792/118836 (55%)] Loss: 12221.814453\n",
      "Train Epoch: 1693 [98560/118836 (83%)] Loss: 12248.267578\n",
      "    epoch          : 1693\n",
      "    loss           : 12237.644908627997\n",
      "    val_loss       : 12237.719318751278\n",
      "    val_log_likelihood: -12161.502628722084\n",
      "    val_log_marginal: -12169.688052961272\n",
      "Train Epoch: 1694 [256/118836 (0%)] Loss: 12186.423828\n",
      "Train Epoch: 1694 [33024/118836 (28%)] Loss: 12275.109375\n",
      "Train Epoch: 1694 [65792/118836 (55%)] Loss: 12223.613281\n",
      "Train Epoch: 1694 [98560/118836 (83%)] Loss: 12219.614258\n",
      "    epoch          : 1694\n",
      "    loss           : 12241.926393681504\n",
      "    val_loss       : 12240.322196108891\n",
      "    val_log_likelihood: -12161.889739551023\n",
      "    val_log_marginal: -12170.22177227486\n",
      "Train Epoch: 1695 [256/118836 (0%)] Loss: 12210.461914\n",
      "Train Epoch: 1695 [33024/118836 (28%)] Loss: 12299.539062\n",
      "Train Epoch: 1695 [65792/118836 (55%)] Loss: 12249.396484\n",
      "Train Epoch: 1695 [98560/118836 (83%)] Loss: 12264.130859\n",
      "    epoch          : 1695\n",
      "    loss           : 12242.800620993588\n",
      "    val_loss       : 12237.943174918159\n",
      "    val_log_likelihood: -12162.668603475238\n",
      "    val_log_marginal: -12170.92645433941\n",
      "Train Epoch: 1696 [256/118836 (0%)] Loss: 12277.074219\n",
      "Train Epoch: 1696 [33024/118836 (28%)] Loss: 12263.973633\n",
      "Train Epoch: 1696 [65792/118836 (55%)] Loss: 12235.820312\n",
      "Train Epoch: 1696 [98560/118836 (83%)] Loss: 12290.617188\n",
      "    epoch          : 1696\n",
      "    loss           : 12239.762821320564\n",
      "    val_loss       : 12240.143247033193\n",
      "    val_log_likelihood: -12162.033438016957\n",
      "    val_log_marginal: -12170.46186332218\n",
      "Train Epoch: 1697 [256/118836 (0%)] Loss: 12264.148438\n",
      "Train Epoch: 1697 [33024/118836 (28%)] Loss: 12274.123047\n",
      "Train Epoch: 1697 [65792/118836 (55%)] Loss: 12293.832031\n",
      "Train Epoch: 1697 [98560/118836 (83%)] Loss: 12325.908203\n",
      "    epoch          : 1697\n",
      "    loss           : 12237.026188191428\n",
      "    val_loss       : 12235.161389839011\n",
      "    val_log_likelihood: -12164.182170343518\n",
      "    val_log_marginal: -12172.464658392342\n",
      "Train Epoch: 1698 [256/118836 (0%)] Loss: 12256.945312\n",
      "Train Epoch: 1698 [33024/118836 (28%)] Loss: 12318.512695\n",
      "Train Epoch: 1698 [65792/118836 (55%)] Loss: 12290.855469\n",
      "Train Epoch: 1698 [98560/118836 (83%)] Loss: 12352.113281\n",
      "    epoch          : 1698\n",
      "    loss           : 12239.106605407362\n",
      "    val_loss       : 12238.365540070663\n",
      "    val_log_likelihood: -12160.440976045544\n",
      "    val_log_marginal: -12168.594599757284\n",
      "Train Epoch: 1699 [256/118836 (0%)] Loss: 12193.795898\n",
      "Train Epoch: 1699 [33024/118836 (28%)] Loss: 12316.266602\n",
      "Train Epoch: 1699 [65792/118836 (55%)] Loss: 12173.575195\n",
      "Train Epoch: 1699 [98560/118836 (83%)] Loss: 12226.046875\n",
      "    epoch          : 1699\n",
      "    loss           : 12242.972380647747\n",
      "    val_loss       : 12239.639670187487\n",
      "    val_log_likelihood: -12162.568701696908\n",
      "    val_log_marginal: -12170.861001056699\n",
      "Train Epoch: 1700 [256/118836 (0%)] Loss: 12280.051758\n",
      "Train Epoch: 1700 [33024/118836 (28%)] Loss: 12237.875000\n",
      "Train Epoch: 1700 [65792/118836 (55%)] Loss: 12165.170898\n",
      "Train Epoch: 1700 [98560/118836 (83%)] Loss: 12221.824219\n",
      "    epoch          : 1700\n",
      "    loss           : 12238.270656598947\n",
      "    val_loss       : 12235.997577247224\n",
      "    val_log_likelihood: -12164.214083824441\n",
      "    val_log_marginal: -12172.269011455393\n",
      "Saving checkpoint: saved/models/SelfiesAutoencodingOperad/0905_154251/checkpoint-epoch1700.pth ...\n",
      "Train Epoch: 1701 [256/118836 (0%)] Loss: 12185.038086\n",
      "Train Epoch: 1701 [33024/118836 (28%)] Loss: 12207.063477\n",
      "Train Epoch: 1701 [65792/118836 (55%)] Loss: 12225.253906\n",
      "Train Epoch: 1701 [98560/118836 (83%)] Loss: 12201.357422\n",
      "    epoch          : 1701\n",
      "    loss           : 12239.33624718905\n",
      "    val_loss       : 12236.895843072938\n",
      "    val_log_likelihood: -12163.408118311881\n",
      "    val_log_marginal: -12171.660968508144\n",
      "Train Epoch: 1702 [256/118836 (0%)] Loss: 12216.561523\n",
      "Train Epoch: 1702 [33024/118836 (28%)] Loss: 12221.681641\n",
      "Train Epoch: 1702 [65792/118836 (55%)] Loss: 12249.658203\n",
      "Train Epoch: 1702 [98560/118836 (83%)] Loss: 12189.206055\n",
      "    epoch          : 1702\n",
      "    loss           : 12234.510608425093\n",
      "    val_loss       : 12239.29985578142\n",
      "    val_log_likelihood: -12162.743184094552\n",
      "    val_log_marginal: -12171.164453045694\n",
      "Train Epoch: 1703 [256/118836 (0%)] Loss: 12273.700195\n",
      "Train Epoch: 1703 [33024/118836 (28%)] Loss: 12234.585938\n",
      "Train Epoch: 1703 [65792/118836 (55%)] Loss: 12315.140625\n",
      "Train Epoch: 1703 [98560/118836 (83%)] Loss: 12320.742188\n",
      "    epoch          : 1703\n",
      "    loss           : 12237.547632663875\n",
      "    val_loss       : 12238.075862719723\n",
      "    val_log_likelihood: -12160.520799892733\n",
      "    val_log_marginal: -12168.710238109777\n",
      "Train Epoch: 1704 [256/118836 (0%)] Loss: 12181.281250\n",
      "Train Epoch: 1704 [33024/118836 (28%)] Loss: 12211.701172\n",
      "Train Epoch: 1704 [65792/118836 (55%)] Loss: 12287.566406\n",
      "Train Epoch: 1704 [98560/118836 (83%)] Loss: 12320.976562\n",
      "    epoch          : 1704\n",
      "    loss           : 12239.111456394749\n",
      "    val_loss       : 12236.653142130443\n",
      "    val_log_likelihood: -12163.411359788566\n",
      "    val_log_marginal: -12171.491771860805\n",
      "Train Epoch: 1705 [256/118836 (0%)] Loss: 12201.480469\n",
      "Train Epoch: 1705 [33024/118836 (28%)] Loss: 12194.997070\n",
      "Train Epoch: 1705 [65792/118836 (55%)] Loss: 12193.908203\n",
      "Train Epoch: 1705 [98560/118836 (83%)] Loss: 12222.183594\n",
      "    epoch          : 1705\n",
      "    loss           : 12236.211240242452\n",
      "    val_loss       : 12237.81545654179\n",
      "    val_log_likelihood: -12160.383130912687\n",
      "    val_log_marginal: -12168.536982392852\n",
      "Train Epoch: 1706 [256/118836 (0%)] Loss: 12162.972656\n",
      "Train Epoch: 1706 [33024/118836 (28%)] Loss: 12185.265625\n",
      "Train Epoch: 1706 [65792/118836 (55%)] Loss: 12379.764648\n",
      "Train Epoch: 1706 [98560/118836 (83%)] Loss: 12208.744141\n",
      "    epoch          : 1706\n",
      "    loss           : 12235.494463722602\n",
      "    val_loss       : 12236.333953656274\n",
      "    val_log_likelihood: -12160.8875807744\n",
      "    val_log_marginal: -12169.095492617342\n",
      "Train Epoch: 1707 [256/118836 (0%)] Loss: 12305.422852\n",
      "Train Epoch: 1707 [33024/118836 (28%)] Loss: 12289.817383\n",
      "Train Epoch: 1707 [65792/118836 (55%)] Loss: 12326.898438\n",
      "Train Epoch: 1707 [98560/118836 (83%)] Loss: 12234.414062\n",
      "    epoch          : 1707\n",
      "    loss           : 12238.155795078577\n",
      "    val_loss       : 12237.918189633632\n",
      "    val_log_likelihood: -12161.151436168839\n",
      "    val_log_marginal: -12169.278139434406\n",
      "Train Epoch: 1708 [256/118836 (0%)] Loss: 12358.339844\n",
      "Train Epoch: 1708 [33024/118836 (28%)] Loss: 12197.787109\n",
      "Train Epoch: 1708 [65792/118836 (55%)] Loss: 12264.849609\n",
      "Train Epoch: 1708 [98560/118836 (83%)] Loss: 12277.708984\n",
      "    epoch          : 1708\n",
      "    loss           : 12238.317871982268\n",
      "    val_loss       : 12235.76291205643\n",
      "    val_log_likelihood: -12161.658139797872\n",
      "    val_log_marginal: -12169.909778581468\n",
      "Train Epoch: 1709 [256/118836 (0%)] Loss: 12312.725586\n",
      "Train Epoch: 1709 [33024/118836 (28%)] Loss: 12199.835938\n",
      "Train Epoch: 1709 [65792/118836 (55%)] Loss: 12342.306641\n",
      "Train Epoch: 1709 [98560/118836 (83%)] Loss: 12330.947266\n",
      "    epoch          : 1709\n",
      "    loss           : 12235.532466785566\n",
      "    val_loss       : 12236.330875522197\n",
      "    val_log_likelihood: -12162.453988155243\n",
      "    val_log_marginal: -12170.602091001485\n",
      "Train Epoch: 1710 [256/118836 (0%)] Loss: 12212.188477\n",
      "Train Epoch: 1710 [33024/118836 (28%)] Loss: 12255.466797\n",
      "Train Epoch: 1710 [65792/118836 (55%)] Loss: 12216.519531\n",
      "Train Epoch: 1710 [98560/118836 (83%)] Loss: 12201.658203\n",
      "    epoch          : 1710\n",
      "    loss           : 12234.158905377635\n",
      "    val_loss       : 12240.082358436255\n",
      "    val_log_likelihood: -12165.049330380221\n",
      "    val_log_marginal: -12173.17505382072\n",
      "Train Epoch: 1711 [256/118836 (0%)] Loss: 12317.484375\n",
      "Train Epoch: 1711 [33024/118836 (28%)] Loss: 12331.073242\n",
      "Train Epoch: 1711 [65792/118836 (55%)] Loss: 12269.947266\n",
      "Train Epoch: 1711 [98560/118836 (83%)] Loss: 12263.381836\n",
      "    epoch          : 1711\n",
      "    loss           : 12238.402480581834\n",
      "    val_loss       : 12239.070035018029\n",
      "    val_log_likelihood: -12162.316123701148\n",
      "    val_log_marginal: -12170.547465580239\n",
      "Train Epoch: 1712 [256/118836 (0%)] Loss: 12213.992188\n",
      "Train Epoch: 1712 [33024/118836 (28%)] Loss: 12370.994141\n",
      "Train Epoch: 1712 [65792/118836 (55%)] Loss: 12316.714844\n",
      "Train Epoch: 1712 [98560/118836 (83%)] Loss: 12326.168945\n",
      "    epoch          : 1712\n",
      "    loss           : 12238.770781637717\n",
      "    val_loss       : 12234.943395288565\n",
      "    val_log_likelihood: -12160.77886327802\n",
      "    val_log_marginal: -12168.896470229876\n",
      "Train Epoch: 1713 [256/118836 (0%)] Loss: 12206.886719\n",
      "Train Epoch: 1713 [33024/118836 (28%)] Loss: 12199.253906\n",
      "Train Epoch: 1713 [65792/118836 (55%)] Loss: 12257.328125\n",
      "Train Epoch: 1713 [98560/118836 (83%)] Loss: 12323.329102\n",
      "    epoch          : 1713\n",
      "    loss           : 12243.40665936466\n",
      "    val_loss       : 12235.087003246428\n",
      "    val_log_likelihood: -12161.864142628205\n",
      "    val_log_marginal: -12170.167950763453\n",
      "Train Epoch: 1714 [256/118836 (0%)] Loss: 12246.202148\n",
      "Train Epoch: 1714 [33024/118836 (28%)] Loss: 12200.965820\n",
      "Train Epoch: 1714 [65792/118836 (55%)] Loss: 12179.220703\n",
      "Train Epoch: 1714 [98560/118836 (83%)] Loss: 12233.038086\n",
      "    epoch          : 1714\n",
      "    loss           : 12236.707853048749\n",
      "    val_loss       : 12237.008694060676\n",
      "    val_log_likelihood: -12161.281979554384\n",
      "    val_log_marginal: -12169.430856312681\n",
      "Train Epoch: 1715 [256/118836 (0%)] Loss: 12224.617188\n",
      "Train Epoch: 1715 [33024/118836 (28%)] Loss: 12316.863281\n",
      "Train Epoch: 1715 [65792/118836 (55%)] Loss: 12331.261719\n",
      "Train Epoch: 1715 [98560/118836 (83%)] Loss: 12345.804688\n",
      "    epoch          : 1715\n",
      "    loss           : 12238.891566991057\n",
      "    val_loss       : 12235.54895834138\n",
      "    val_log_likelihood: -12163.857450307589\n",
      "    val_log_marginal: -12172.04054541115\n",
      "Train Epoch: 1716 [256/118836 (0%)] Loss: 12231.751953\n",
      "Train Epoch: 1716 [33024/118836 (28%)] Loss: 12257.359375\n",
      "Train Epoch: 1716 [65792/118836 (55%)] Loss: 12339.333984\n",
      "Train Epoch: 1716 [98560/118836 (83%)] Loss: 12398.179688\n",
      "    epoch          : 1716\n",
      "    loss           : 12233.963682698768\n",
      "    val_loss       : 12236.852598664682\n",
      "    val_log_likelihood: -12160.018645962573\n",
      "    val_log_marginal: -12168.290924842833\n",
      "Train Epoch: 1717 [256/118836 (0%)] Loss: 12194.902344\n",
      "Train Epoch: 1717 [33024/118836 (28%)] Loss: 12284.127930\n",
      "Train Epoch: 1717 [65792/118836 (55%)] Loss: 12285.129883\n",
      "Train Epoch: 1717 [98560/118836 (83%)] Loss: 12358.480469\n",
      "    epoch          : 1717\n",
      "    loss           : 12236.824141206576\n",
      "    val_loss       : 12236.102938289428\n",
      "    val_log_likelihood: -12162.627650531173\n",
      "    val_log_marginal: -12170.860380662547\n",
      "Train Epoch: 1718 [256/118836 (0%)] Loss: 12198.616211\n",
      "Train Epoch: 1718 [33024/118836 (28%)] Loss: 12370.916016\n",
      "Train Epoch: 1718 [65792/118836 (55%)] Loss: 12235.743164\n",
      "Train Epoch: 1718 [98560/118836 (83%)] Loss: 12354.567383\n",
      "    epoch          : 1718\n",
      "    loss           : 12241.45355197348\n",
      "    val_loss       : 12238.754270202378\n",
      "    val_log_likelihood: -12163.53759014423\n",
      "    val_log_marginal: -12171.945736698453\n",
      "Train Epoch: 1719 [256/118836 (0%)] Loss: 12266.927734\n",
      "Train Epoch: 1719 [33024/118836 (28%)] Loss: 12259.236328\n",
      "Train Epoch: 1719 [65792/118836 (55%)] Loss: 12215.765625\n",
      "Train Epoch: 1719 [98560/118836 (83%)] Loss: 12312.891602\n",
      "    epoch          : 1719\n",
      "    loss           : 12239.413992387821\n",
      "    val_loss       : 12236.535595676714\n",
      "    val_log_likelihood: -12163.01816277011\n",
      "    val_log_marginal: -12171.2285773355\n",
      "Train Epoch: 1720 [256/118836 (0%)] Loss: 12229.690430\n",
      "Train Epoch: 1720 [33024/118836 (28%)] Loss: 12148.067383\n",
      "Train Epoch: 1720 [65792/118836 (55%)] Loss: 12324.206055\n",
      "Train Epoch: 1720 [98560/118836 (83%)] Loss: 12398.501953\n",
      "    epoch          : 1720\n",
      "    loss           : 12236.071390676694\n",
      "    val_loss       : 12240.433853843628\n",
      "    val_log_likelihood: -12161.365209658034\n",
      "    val_log_marginal: -12169.57267632221\n",
      "Train Epoch: 1721 [256/118836 (0%)] Loss: 12359.666016\n",
      "Train Epoch: 1721 [33024/118836 (28%)] Loss: 12253.783203\n",
      "Train Epoch: 1721 [65792/118836 (55%)] Loss: 12259.715820\n",
      "Train Epoch: 1721 [98560/118836 (83%)] Loss: 12314.369141\n",
      "    epoch          : 1721\n",
      "    loss           : 12236.10354793476\n",
      "    val_loss       : 12236.313269922666\n",
      "    val_log_likelihood: -12162.613147649141\n",
      "    val_log_marginal: -12170.795288475601\n",
      "Train Epoch: 1722 [256/118836 (0%)] Loss: 12266.206055\n",
      "Train Epoch: 1722 [33024/118836 (28%)] Loss: 12241.597656\n",
      "Train Epoch: 1722 [65792/118836 (55%)] Loss: 12187.293945\n",
      "Train Epoch: 1722 [98560/118836 (83%)] Loss: 12265.208984\n",
      "    epoch          : 1722\n",
      "    loss           : 12232.53034888079\n",
      "    val_loss       : 12236.301107813837\n",
      "    val_log_likelihood: -12162.515497861094\n",
      "    val_log_marginal: -12170.691197432436\n",
      "Train Epoch: 1723 [256/118836 (0%)] Loss: 12379.805664\n",
      "Train Epoch: 1723 [33024/118836 (28%)] Loss: 12184.191406\n",
      "Train Epoch: 1723 [65792/118836 (55%)] Loss: 12168.671875\n",
      "Train Epoch: 1723 [98560/118836 (83%)] Loss: 12272.845703\n",
      "    epoch          : 1723\n",
      "    loss           : 12241.934007638029\n",
      "    val_loss       : 12236.150604558308\n",
      "    val_log_likelihood: -12161.954976510806\n",
      "    val_log_marginal: -12170.298258132647\n",
      "Train Epoch: 1724 [256/118836 (0%)] Loss: 12229.821289\n",
      "Train Epoch: 1724 [33024/118836 (28%)] Loss: 12338.958008\n",
      "Train Epoch: 1724 [65792/118836 (55%)] Loss: 12235.730469\n",
      "Train Epoch: 1724 [98560/118836 (83%)] Loss: 12273.321289\n",
      "    epoch          : 1724\n",
      "    loss           : 12237.970700217122\n",
      "    val_loss       : 12240.626878715359\n",
      "    val_log_likelihood: -12166.390574112127\n",
      "    val_log_marginal: -12174.852389264053\n",
      "Train Epoch: 1725 [256/118836 (0%)] Loss: 12202.575195\n",
      "Train Epoch: 1725 [33024/118836 (28%)] Loss: 12224.194336\n",
      "Train Epoch: 1725 [65792/118836 (55%)] Loss: 12300.937500\n",
      "Train Epoch: 1725 [98560/118836 (83%)] Loss: 12199.183594\n",
      "    epoch          : 1725\n",
      "    loss           : 12241.178192850497\n",
      "    val_loss       : 12236.670186388379\n",
      "    val_log_likelihood: -12161.929406243538\n",
      "    val_log_marginal: -12170.077763718105\n",
      "Train Epoch: 1726 [256/118836 (0%)] Loss: 12250.759766\n",
      "Train Epoch: 1726 [33024/118836 (28%)] Loss: 12199.119141\n",
      "Train Epoch: 1726 [65792/118836 (55%)] Loss: 12362.059570\n",
      "Train Epoch: 1726 [98560/118836 (83%)] Loss: 12184.314453\n",
      "    epoch          : 1726\n",
      "    loss           : 12233.78829352771\n",
      "    val_loss       : 12234.744146699211\n",
      "    val_log_likelihood: -12162.199178847446\n",
      "    val_log_marginal: -12170.468524185117\n",
      "Train Epoch: 1727 [256/118836 (0%)] Loss: 12298.358398\n",
      "Train Epoch: 1727 [33024/118836 (28%)] Loss: 12234.897461\n",
      "Train Epoch: 1727 [65792/118836 (55%)] Loss: 12324.345703\n",
      "Train Epoch: 1727 [98560/118836 (83%)] Loss: 12287.611328\n",
      "    epoch          : 1727\n",
      "    loss           : 12239.283459664495\n",
      "    val_loss       : 12237.742413173437\n",
      "    val_log_likelihood: -12160.965822412634\n",
      "    val_log_marginal: -12169.146756287479\n",
      "Train Epoch: 1728 [256/118836 (0%)] Loss: 12195.104492\n",
      "Train Epoch: 1728 [33024/118836 (28%)] Loss: 12366.345703\n",
      "Train Epoch: 1728 [65792/118836 (55%)] Loss: 12224.298828\n",
      "Train Epoch: 1728 [98560/118836 (83%)] Loss: 12256.404297\n",
      "    epoch          : 1728\n",
      "    loss           : 12233.533086486766\n",
      "    val_loss       : 12241.186257017665\n",
      "    val_log_likelihood: -12159.925754755996\n",
      "    val_log_marginal: -12167.993379852052\n",
      "Train Epoch: 1729 [256/118836 (0%)] Loss: 12215.968750\n",
      "Train Epoch: 1729 [33024/118836 (28%)] Loss: 12280.477539\n",
      "Train Epoch: 1729 [65792/118836 (55%)] Loss: 12255.641602\n",
      "Train Epoch: 1729 [98560/118836 (83%)] Loss: 12265.128906\n",
      "    epoch          : 1729\n",
      "    loss           : 12238.079494126085\n",
      "    val_loss       : 12236.246047420766\n",
      "    val_log_likelihood: -12162.137262038616\n",
      "    val_log_marginal: -12170.253202092483\n",
      "Train Epoch: 1730 [256/118836 (0%)] Loss: 12274.735352\n",
      "Train Epoch: 1730 [33024/118836 (28%)] Loss: 12191.710938\n",
      "Train Epoch: 1730 [65792/118836 (55%)] Loss: 12397.975586\n",
      "Train Epoch: 1730 [98560/118836 (83%)] Loss: 12328.937500\n",
      "    epoch          : 1730\n",
      "    loss           : 12240.54792845973\n",
      "    val_loss       : 12236.224166538526\n",
      "    val_log_likelihood: -12161.984379523366\n",
      "    val_log_marginal: -12170.120354915618\n",
      "Train Epoch: 1731 [256/118836 (0%)] Loss: 12311.850586\n",
      "Train Epoch: 1731 [33024/118836 (28%)] Loss: 12306.925781\n",
      "Train Epoch: 1731 [65792/118836 (55%)] Loss: 12310.659180\n",
      "Train Epoch: 1731 [98560/118836 (83%)] Loss: 12379.259766\n",
      "    epoch          : 1731\n",
      "    loss           : 12238.401485441222\n",
      "    val_loss       : 12242.001382970095\n",
      "    val_log_likelihood: -12161.239472672405\n",
      "    val_log_marginal: -12169.600724734732\n",
      "Train Epoch: 1732 [256/118836 (0%)] Loss: 12291.911133\n",
      "Train Epoch: 1732 [33024/118836 (28%)] Loss: 12227.947266\n",
      "Train Epoch: 1732 [65792/118836 (55%)] Loss: 12243.644531\n",
      "Train Epoch: 1732 [98560/118836 (83%)] Loss: 12165.996094\n",
      "    epoch          : 1732\n",
      "    loss           : 12237.247429112387\n",
      "    val_loss       : 12235.419692678255\n",
      "    val_log_likelihood: -12162.908670324132\n",
      "    val_log_marginal: -12171.108319801064\n",
      "Train Epoch: 1733 [256/118836 (0%)] Loss: 12303.932617\n",
      "Train Epoch: 1733 [33024/118836 (28%)] Loss: 12199.951172\n",
      "Train Epoch: 1733 [65792/118836 (55%)] Loss: 12240.948242\n",
      "Train Epoch: 1733 [98560/118836 (83%)] Loss: 12281.767578\n",
      "    epoch          : 1733\n",
      "    loss           : 12234.33864618874\n",
      "    val_loss       : 12240.652584972731\n",
      "    val_log_likelihood: -12161.9811016982\n",
      "    val_log_marginal: -12170.277400694886\n",
      "Train Epoch: 1734 [256/118836 (0%)] Loss: 12194.824219\n",
      "Train Epoch: 1734 [33024/118836 (28%)] Loss: 12293.898438\n",
      "Train Epoch: 1734 [65792/118836 (55%)] Loss: 12165.482422\n",
      "Train Epoch: 1734 [98560/118836 (83%)] Loss: 12176.105469\n",
      "    epoch          : 1734\n",
      "    loss           : 12242.71674421009\n",
      "    val_loss       : 12236.783596629062\n",
      "    val_log_likelihood: -12159.841471677264\n",
      "    val_log_marginal: -12168.007039998281\n",
      "Train Epoch: 1735 [256/118836 (0%)] Loss: 12291.533203\n",
      "Train Epoch: 1735 [33024/118836 (28%)] Loss: 12311.690430\n",
      "Train Epoch: 1735 [65792/118836 (55%)] Loss: 12254.422852\n",
      "Train Epoch: 1735 [98560/118836 (83%)] Loss: 12218.250000\n",
      "    epoch          : 1735\n",
      "    loss           : 12237.93013999819\n",
      "    val_loss       : 12239.296460113965\n",
      "    val_log_likelihood: -12161.637281424471\n",
      "    val_log_marginal: -12169.845760486853\n",
      "Train Epoch: 1736 [256/118836 (0%)] Loss: 12309.424805\n",
      "Train Epoch: 1736 [33024/118836 (28%)] Loss: 12269.671875\n",
      "Train Epoch: 1736 [65792/118836 (55%)] Loss: 12283.771484\n",
      "Train Epoch: 1736 [98560/118836 (83%)] Loss: 12328.214844\n",
      "    epoch          : 1736\n",
      "    loss           : 12237.454960679022\n",
      "    val_loss       : 12237.411537830267\n",
      "    val_log_likelihood: -12163.919868563897\n",
      "    val_log_marginal: -12172.112735222681\n",
      "Train Epoch: 1737 [256/118836 (0%)] Loss: 12335.328125\n",
      "Train Epoch: 1737 [33024/118836 (28%)] Loss: 12284.072266\n",
      "Train Epoch: 1737 [65792/118836 (55%)] Loss: 12244.477539\n",
      "Train Epoch: 1737 [98560/118836 (83%)] Loss: 12375.985352\n",
      "    epoch          : 1737\n",
      "    loss           : 12241.833980982474\n",
      "    val_loss       : 12239.606740585099\n",
      "    val_log_likelihood: -12164.002020975497\n",
      "    val_log_marginal: -12172.219845026131\n",
      "Train Epoch: 1738 [256/118836 (0%)] Loss: 12224.226562\n",
      "Train Epoch: 1738 [33024/118836 (28%)] Loss: 12239.219727\n",
      "Train Epoch: 1738 [65792/118836 (55%)] Loss: 12232.221680\n",
      "Train Epoch: 1738 [98560/118836 (83%)] Loss: 12231.334961\n",
      "    epoch          : 1738\n",
      "    loss           : 12241.139202401262\n",
      "    val_loss       : 12237.002753445486\n",
      "    val_log_likelihood: -12165.364404014166\n",
      "    val_log_marginal: -12173.622623999121\n",
      "Train Epoch: 1739 [256/118836 (0%)] Loss: 12215.070312\n",
      "Train Epoch: 1739 [33024/118836 (28%)] Loss: 12173.629883\n",
      "Train Epoch: 1739 [65792/118836 (55%)] Loss: 12226.447266\n",
      "Train Epoch: 1739 [98560/118836 (83%)] Loss: 12369.480469\n",
      "    epoch          : 1739\n",
      "    loss           : 12242.084826690447\n",
      "    val_loss       : 12240.804746269938\n",
      "    val_log_likelihood: -12161.898689193033\n",
      "    val_log_marginal: -12170.006980143542\n",
      "Train Epoch: 1740 [256/118836 (0%)] Loss: 12244.960938\n",
      "Train Epoch: 1740 [33024/118836 (28%)] Loss: 12200.718750\n",
      "Train Epoch: 1740 [65792/118836 (55%)] Loss: 12262.870117\n",
      "Train Epoch: 1740 [98560/118836 (83%)] Loss: 12211.664062\n",
      "    epoch          : 1740\n",
      "    loss           : 12235.12995567101\n",
      "    val_loss       : 12240.789698530221\n",
      "    val_log_likelihood: -12163.191445021712\n",
      "    val_log_marginal: -12171.574159987138\n",
      "Train Epoch: 1741 [256/118836 (0%)] Loss: 12226.412109\n",
      "Train Epoch: 1741 [33024/118836 (28%)] Loss: 12273.062500\n",
      "Train Epoch: 1741 [65792/118836 (55%)] Loss: 12266.061523\n",
      "Train Epoch: 1741 [98560/118836 (83%)] Loss: 12337.792969\n",
      "    epoch          : 1741\n",
      "    loss           : 12237.095741412066\n",
      "    val_loss       : 12245.998261198412\n",
      "    val_log_likelihood: -12163.676539721619\n",
      "    val_log_marginal: -12172.029089247895\n",
      "Train Epoch: 1742 [256/118836 (0%)] Loss: 12243.451172\n",
      "Train Epoch: 1742 [33024/118836 (28%)] Loss: 12323.049805\n",
      "Train Epoch: 1742 [65792/118836 (55%)] Loss: 12249.869141\n",
      "Train Epoch: 1742 [98560/118836 (83%)] Loss: 12210.664062\n",
      "    epoch          : 1742\n",
      "    loss           : 12240.236800493692\n",
      "    val_loss       : 12241.035572448509\n",
      "    val_log_likelihood: -12162.101693516077\n",
      "    val_log_marginal: -12170.42426461394\n",
      "Train Epoch: 1743 [256/118836 (0%)] Loss: 12247.053711\n",
      "Train Epoch: 1743 [33024/118836 (28%)] Loss: 12229.523438\n",
      "Train Epoch: 1743 [65792/118836 (55%)] Loss: 12243.663086\n",
      "Train Epoch: 1743 [98560/118836 (83%)] Loss: 12197.644531\n",
      "    epoch          : 1743\n",
      "    loss           : 12239.195039320977\n",
      "    val_loss       : 12239.244854525601\n",
      "    val_log_likelihood: -12162.18308470973\n",
      "    val_log_marginal: -12170.403395242733\n",
      "Train Epoch: 1744 [256/118836 (0%)] Loss: 12265.615234\n",
      "Train Epoch: 1744 [33024/118836 (28%)] Loss: 12163.017578\n",
      "Train Epoch: 1744 [65792/118836 (55%)] Loss: 12301.550781\n",
      "Train Epoch: 1744 [98560/118836 (83%)] Loss: 12255.566406\n",
      "    epoch          : 1744\n",
      "    loss           : 12237.830408492298\n",
      "    val_loss       : 12238.316992540558\n",
      "    val_log_likelihood: -12160.02976148935\n",
      "    val_log_marginal: -12168.269995777662\n",
      "Train Epoch: 1745 [256/118836 (0%)] Loss: 12247.861328\n",
      "Train Epoch: 1745 [33024/118836 (28%)] Loss: 12186.203125\n",
      "Train Epoch: 1745 [65792/118836 (55%)] Loss: 12337.697266\n",
      "Train Epoch: 1745 [98560/118836 (83%)] Loss: 12158.385742\n",
      "    epoch          : 1745\n",
      "    loss           : 12237.223015696081\n",
      "    val_loss       : 12236.366541149902\n",
      "    val_log_likelihood: -12160.962650240384\n",
      "    val_log_marginal: -12169.045051973448\n",
      "Train Epoch: 1746 [256/118836 (0%)] Loss: 12349.417969\n",
      "Train Epoch: 1746 [33024/118836 (28%)] Loss: 12196.489258\n",
      "Train Epoch: 1746 [65792/118836 (55%)] Loss: 12207.090820\n",
      "Train Epoch: 1746 [98560/118836 (83%)] Loss: 12183.565430\n",
      "    epoch          : 1746\n",
      "    loss           : 12240.938748126035\n",
      "    val_loss       : 12239.681410899164\n",
      "    val_log_likelihood: -12164.45823155759\n",
      "    val_log_marginal: -12172.72283889169\n",
      "Train Epoch: 1747 [256/118836 (0%)] Loss: 12209.224609\n",
      "Train Epoch: 1747 [33024/118836 (28%)] Loss: 12221.271484\n",
      "Train Epoch: 1747 [65792/118836 (55%)] Loss: 12209.218750\n",
      "Train Epoch: 1747 [98560/118836 (83%)] Loss: 12307.866211\n",
      "    epoch          : 1747\n",
      "    loss           : 12241.311557685845\n",
      "    val_loss       : 12237.149922489878\n",
      "    val_log_likelihood: -12162.508742859543\n",
      "    val_log_marginal: -12170.654037313812\n",
      "Train Epoch: 1748 [256/118836 (0%)] Loss: 12276.457031\n",
      "Train Epoch: 1748 [33024/118836 (28%)] Loss: 12174.848633\n",
      "Train Epoch: 1748 [65792/118836 (55%)] Loss: 12231.752930\n",
      "Train Epoch: 1748 [98560/118836 (83%)] Loss: 12222.567383\n",
      "    epoch          : 1748\n",
      "    loss           : 12236.911373520214\n",
      "    val_loss       : 12238.10207077804\n",
      "    val_log_likelihood: -12162.717536768507\n",
      "    val_log_marginal: -12171.012879469212\n",
      "Train Epoch: 1749 [256/118836 (0%)] Loss: 12264.472656\n",
      "Train Epoch: 1749 [33024/118836 (28%)] Loss: 12276.681641\n",
      "Train Epoch: 1749 [65792/118836 (55%)] Loss: 12178.150391\n",
      "Train Epoch: 1749 [98560/118836 (83%)] Loss: 12210.712891\n",
      "    epoch          : 1749\n",
      "    loss           : 12239.484122014579\n",
      "    val_loss       : 12235.137669525937\n",
      "    val_log_likelihood: -12161.968683441895\n",
      "    val_log_marginal: -12170.206732593437\n",
      "Train Epoch: 1750 [256/118836 (0%)] Loss: 12292.056641\n",
      "Train Epoch: 1750 [33024/118836 (28%)] Loss: 12227.308594\n",
      "Train Epoch: 1750 [65792/118836 (55%)] Loss: 12270.567383\n",
      "Train Epoch: 1750 [98560/118836 (83%)] Loss: 12270.486328\n",
      "    epoch          : 1750\n",
      "    loss           : 12235.820679215778\n",
      "    val_loss       : 12234.877987786422\n",
      "    val_log_likelihood: -12161.821438172043\n",
      "    val_log_marginal: -12170.072032387701\n",
      "Train Epoch: 1751 [256/118836 (0%)] Loss: 12209.365234\n",
      "Train Epoch: 1751 [33024/118836 (28%)] Loss: 12280.593750\n",
      "Train Epoch: 1751 [65792/118836 (55%)] Loss: 12326.429688\n",
      "Train Epoch: 1751 [98560/118836 (83%)] Loss: 12322.459961\n",
      "    epoch          : 1751\n",
      "    loss           : 12240.740741153588\n",
      "    val_loss       : 12241.278335563635\n",
      "    val_log_likelihood: -12158.607134802782\n",
      "    val_log_marginal: -12166.728609473246\n",
      "Train Epoch: 1752 [256/118836 (0%)] Loss: 12271.113281\n",
      "Train Epoch: 1752 [33024/118836 (28%)] Loss: 12220.303711\n",
      "Train Epoch: 1752 [65792/118836 (55%)] Loss: 12202.909180\n",
      "Train Epoch: 1752 [98560/118836 (83%)] Loss: 12260.578125\n",
      "    epoch          : 1752\n",
      "    loss           : 12242.906679881358\n",
      "    val_loss       : 12237.798941997382\n",
      "    val_log_likelihood: -12162.808308616366\n",
      "    val_log_marginal: -12170.983830029329\n",
      "Train Epoch: 1753 [256/118836 (0%)] Loss: 12187.765625\n",
      "Train Epoch: 1753 [33024/118836 (28%)] Loss: 12219.728516\n",
      "Train Epoch: 1753 [65792/118836 (55%)] Loss: 12261.298828\n",
      "Train Epoch: 1753 [98560/118836 (83%)] Loss: 12197.720703\n",
      "    epoch          : 1753\n",
      "    loss           : 12239.103288972034\n",
      "    val_loss       : 12237.50778761209\n",
      "    val_log_likelihood: -12161.921764177523\n",
      "    val_log_marginal: -12170.262148367105\n",
      "Train Epoch: 1754 [256/118836 (0%)] Loss: 12290.484375\n",
      "Train Epoch: 1754 [33024/118836 (28%)] Loss: 12176.123047\n",
      "Train Epoch: 1754 [65792/118836 (55%)] Loss: 12273.222656\n",
      "Train Epoch: 1754 [98560/118836 (83%)] Loss: 12279.265625\n",
      "    epoch          : 1754\n",
      "    loss           : 12238.672249631667\n",
      "    val_loss       : 12242.208149648348\n",
      "    val_log_likelihood: -12160.918569549991\n",
      "    val_log_marginal: -12169.231149170655\n",
      "Train Epoch: 1755 [256/118836 (0%)] Loss: 12308.142578\n",
      "Train Epoch: 1755 [33024/118836 (28%)] Loss: 12219.880859\n",
      "Train Epoch: 1755 [65792/118836 (55%)] Loss: 12268.701172\n",
      "Train Epoch: 1755 [98560/118836 (83%)] Loss: 12229.126953\n",
      "    epoch          : 1755\n",
      "    loss           : 12236.929394288925\n",
      "    val_loss       : 12236.796131268507\n",
      "    val_log_likelihood: -12163.945760797922\n",
      "    val_log_marginal: -12172.190989182085\n",
      "Train Epoch: 1756 [256/118836 (0%)] Loss: 12181.536133\n",
      "Train Epoch: 1756 [33024/118836 (28%)] Loss: 12333.585938\n",
      "Train Epoch: 1756 [65792/118836 (55%)] Loss: 12159.250977\n",
      "Train Epoch: 1756 [98560/118836 (83%)] Loss: 12219.375000\n",
      "    epoch          : 1756\n",
      "    loss           : 12237.884252222912\n",
      "    val_loss       : 12234.862754728445\n",
      "    val_log_likelihood: -12162.56745017835\n",
      "    val_log_marginal: -12170.7790470413\n",
      "Train Epoch: 1757 [256/118836 (0%)] Loss: 12278.083984\n",
      "Train Epoch: 1757 [33024/118836 (28%)] Loss: 12226.152344\n",
      "Train Epoch: 1757 [65792/118836 (55%)] Loss: 12238.608398\n",
      "Train Epoch: 1757 [98560/118836 (83%)] Loss: 12351.799805\n",
      "    epoch          : 1757\n",
      "    loss           : 12235.41487460582\n",
      "    val_loss       : 12236.299586039147\n",
      "    val_log_likelihood: -12162.630800894334\n",
      "    val_log_marginal: -12170.887772969501\n",
      "Train Epoch: 1758 [256/118836 (0%)] Loss: 12212.090820\n",
      "Train Epoch: 1758 [33024/118836 (28%)] Loss: 12373.005859\n",
      "Train Epoch: 1758 [65792/118836 (55%)] Loss: 12331.409180\n",
      "Train Epoch: 1758 [98560/118836 (83%)] Loss: 12329.585938\n",
      "    epoch          : 1758\n",
      "    loss           : 12239.939241657621\n",
      "    val_loss       : 12239.98233446424\n",
      "    val_log_likelihood: -12161.266287188535\n",
      "    val_log_marginal: -12169.47323143232\n",
      "Train Epoch: 1759 [256/118836 (0%)] Loss: 12294.472656\n",
      "Train Epoch: 1759 [33024/118836 (28%)] Loss: 12280.443359\n",
      "Train Epoch: 1759 [65792/118836 (55%)] Loss: 12241.160156\n",
      "Train Epoch: 1759 [98560/118836 (83%)] Loss: 12156.929688\n",
      "    epoch          : 1759\n",
      "    loss           : 12237.590959890664\n",
      "    val_loss       : 12244.909897856043\n",
      "    val_log_likelihood: -12176.392673277243\n",
      "    val_log_marginal: -12184.860752184153\n",
      "Train Epoch: 1760 [256/118836 (0%)] Loss: 12216.541992\n",
      "Train Epoch: 1760 [33024/118836 (28%)] Loss: 12246.166016\n",
      "Train Epoch: 1760 [65792/118836 (55%)] Loss: 12276.564453\n",
      "Train Epoch: 1760 [98560/118836 (83%)] Loss: 12366.060547\n",
      "    epoch          : 1760\n",
      "    loss           : 12240.691480885545\n",
      "    val_loss       : 12240.737883014646\n",
      "    val_log_likelihood: -12162.194756933673\n",
      "    val_log_marginal: -12170.60548469391\n",
      "Train Epoch: 1761 [256/118836 (0%)] Loss: 12225.612305\n",
      "Train Epoch: 1761 [33024/118836 (28%)] Loss: 12269.009766\n",
      "Train Epoch: 1761 [65792/118836 (55%)] Loss: 12249.241211\n",
      "Train Epoch: 1761 [98560/118836 (83%)] Loss: 12275.738281\n",
      "    epoch          : 1761\n",
      "    loss           : 12236.473507612178\n",
      "    val_loss       : 12236.248224251622\n",
      "    val_log_likelihood: -12160.764665561672\n",
      "    val_log_marginal: -12168.984360951556\n",
      "Train Epoch: 1762 [256/118836 (0%)] Loss: 12207.886719\n",
      "Train Epoch: 1762 [33024/118836 (28%)] Loss: 12260.497070\n",
      "Train Epoch: 1762 [65792/118836 (55%)] Loss: 12249.339844\n",
      "Train Epoch: 1762 [98560/118836 (83%)] Loss: 12281.626953\n",
      "    epoch          : 1762\n",
      "    loss           : 12238.4558259344\n",
      "    val_loss       : 12245.31139743286\n",
      "    val_log_likelihood: -12163.382058551748\n",
      "    val_log_marginal: -12171.8957414844\n",
      "Train Epoch: 1763 [256/118836 (0%)] Loss: 12252.068359\n",
      "Train Epoch: 1763 [33024/118836 (28%)] Loss: 12289.380859\n",
      "Train Epoch: 1763 [65792/118836 (55%)] Loss: 12298.311523\n",
      "Train Epoch: 1763 [98560/118836 (83%)] Loss: 12257.291016\n",
      "    epoch          : 1763\n",
      "    loss           : 12241.785934430573\n",
      "    val_loss       : 12235.886570261195\n",
      "    val_log_likelihood: -12163.38256743047\n",
      "    val_log_marginal: -12171.555747286298\n",
      "Train Epoch: 1764 [256/118836 (0%)] Loss: 12302.166016\n",
      "Train Epoch: 1764 [33024/118836 (28%)] Loss: 12307.208984\n",
      "Train Epoch: 1764 [65792/118836 (55%)] Loss: 12265.362305\n",
      "Train Epoch: 1764 [98560/118836 (83%)] Loss: 12320.753906\n",
      "    epoch          : 1764\n",
      "    loss           : 12237.339355064878\n",
      "    val_loss       : 12237.953183206822\n",
      "    val_log_likelihood: -12161.16666892835\n",
      "    val_log_marginal: -12169.324729000193\n",
      "Train Epoch: 1765 [256/118836 (0%)] Loss: 12268.783203\n",
      "Train Epoch: 1765 [33024/118836 (28%)] Loss: 12266.988281\n",
      "Train Epoch: 1765 [65792/118836 (55%)] Loss: 12208.465820\n",
      "Train Epoch: 1765 [98560/118836 (83%)] Loss: 12261.964844\n",
      "    epoch          : 1765\n",
      "    loss           : 12238.759596806503\n",
      "    val_loss       : 12240.898741332028\n",
      "    val_log_likelihood: -12165.933530745968\n",
      "    val_log_marginal: -12174.040326094351\n",
      "Train Epoch: 1766 [256/118836 (0%)] Loss: 12223.458984\n",
      "Train Epoch: 1766 [33024/118836 (28%)] Loss: 12307.787109\n",
      "Train Epoch: 1766 [65792/118836 (55%)] Loss: 12203.997070\n",
      "Train Epoch: 1766 [98560/118836 (83%)] Loss: 12206.564453\n",
      "    epoch          : 1766\n",
      "    loss           : 12239.433122027502\n",
      "    val_loss       : 12240.49139911867\n",
      "    val_log_likelihood: -12161.69471024607\n",
      "    val_log_marginal: -12169.989875960064\n",
      "Train Epoch: 1767 [256/118836 (0%)] Loss: 12207.334961\n",
      "Train Epoch: 1767 [33024/118836 (28%)] Loss: 12192.886719\n",
      "Train Epoch: 1767 [65792/118836 (55%)] Loss: 12277.772461\n",
      "Train Epoch: 1767 [98560/118836 (83%)] Loss: 12223.408203\n",
      "    epoch          : 1767\n",
      "    loss           : 12240.113739725497\n",
      "    val_loss       : 12236.879310649541\n",
      "    val_log_likelihood: -12162.916107707817\n",
      "    val_log_marginal: -12171.32577039423\n",
      "Train Epoch: 1768 [256/118836 (0%)] Loss: 12359.251953\n",
      "Train Epoch: 1768 [33024/118836 (28%)] Loss: 12232.808594\n",
      "Train Epoch: 1768 [65792/118836 (55%)] Loss: 12306.510742\n",
      "Train Epoch: 1768 [98560/118836 (83%)] Loss: 12261.794922\n",
      "    epoch          : 1768\n",
      "    loss           : 12241.640498184192\n",
      "    val_loss       : 12238.273405634427\n",
      "    val_log_likelihood: -12161.398732649659\n",
      "    val_log_marginal: -12169.760367376219\n",
      "Train Epoch: 1769 [256/118836 (0%)] Loss: 12215.873047\n",
      "Train Epoch: 1769 [33024/118836 (28%)] Loss: 12314.761719\n",
      "Train Epoch: 1769 [65792/118836 (55%)] Loss: 12271.654297\n",
      "Train Epoch: 1769 [98560/118836 (83%)] Loss: 12259.832031\n",
      "    epoch          : 1769\n",
      "    loss           : 12234.11378625155\n",
      "    val_loss       : 12240.44480342229\n",
      "    val_log_likelihood: -12159.918924795802\n",
      "    val_log_marginal: -12168.227430633764\n",
      "Train Epoch: 1770 [256/118836 (0%)] Loss: 12266.283203\n",
      "Train Epoch: 1770 [33024/118836 (28%)] Loss: 12335.095703\n",
      "Train Epoch: 1770 [65792/118836 (55%)] Loss: 12265.985352\n",
      "Train Epoch: 1770 [98560/118836 (83%)] Loss: 12270.439453\n",
      "    epoch          : 1770\n",
      "    loss           : 12237.151730672302\n",
      "    val_loss       : 12238.071023432254\n",
      "    val_log_likelihood: -12162.28179538875\n",
      "    val_log_marginal: -12170.636966818105\n",
      "Train Epoch: 1771 [256/118836 (0%)] Loss: 12367.686523\n",
      "Train Epoch: 1771 [33024/118836 (28%)] Loss: 12210.394531\n",
      "Train Epoch: 1771 [65792/118836 (55%)] Loss: 12307.423828\n",
      "Train Epoch: 1771 [98560/118836 (83%)] Loss: 12242.476562\n",
      "    epoch          : 1771\n",
      "    loss           : 12240.588843601376\n",
      "    val_loss       : 12239.929348405769\n",
      "    val_log_likelihood: -12162.662973176437\n",
      "    val_log_marginal: -12171.188765222103\n",
      "Train Epoch: 1772 [256/118836 (0%)] Loss: 12228.339844\n",
      "Train Epoch: 1772 [33024/118836 (28%)] Loss: 12337.439453\n",
      "Train Epoch: 1772 [65792/118836 (55%)] Loss: 12196.792969\n",
      "Train Epoch: 1772 [98560/118836 (83%)] Loss: 12299.550781\n",
      "    epoch          : 1772\n",
      "    loss           : 12238.073794199752\n",
      "    val_loss       : 12235.47801736915\n",
      "    val_log_likelihood: -12167.124794994572\n",
      "    val_log_marginal: -12175.706462224513\n",
      "Train Epoch: 1773 [256/118836 (0%)] Loss: 12224.015625\n",
      "Train Epoch: 1773 [33024/118836 (28%)] Loss: 12375.772461\n",
      "Train Epoch: 1773 [65792/118836 (55%)] Loss: 12175.427734\n",
      "Train Epoch: 1773 [98560/118836 (83%)] Loss: 12346.429688\n",
      "    epoch          : 1773\n",
      "    loss           : 12241.46867439516\n",
      "    val_loss       : 12234.93888393709\n",
      "    val_log_likelihood: -12162.176418075373\n",
      "    val_log_marginal: -12170.47604270134\n",
      "Train Epoch: 1774 [256/118836 (0%)] Loss: 12308.261719\n",
      "Train Epoch: 1774 [33024/118836 (28%)] Loss: 12324.001953\n",
      "Train Epoch: 1774 [65792/118836 (55%)] Loss: 12251.509766\n",
      "Train Epoch: 1774 [98560/118836 (83%)] Loss: 12354.524414\n",
      "    epoch          : 1774\n",
      "    loss           : 12239.50906094913\n",
      "    val_loss       : 12240.20615310238\n",
      "    val_log_likelihood: -12164.395784545595\n",
      "    val_log_marginal: -12172.888476335482\n",
      "Train Epoch: 1775 [256/118836 (0%)] Loss: 12259.198242\n",
      "Train Epoch: 1775 [33024/118836 (28%)] Loss: 12274.910156\n",
      "Train Epoch: 1775 [65792/118836 (55%)] Loss: 12222.798828\n",
      "Train Epoch: 1775 [98560/118836 (83%)] Loss: 12234.523438\n",
      "    epoch          : 1775\n",
      "    loss           : 12239.469860486455\n",
      "    val_loss       : 12237.862661874404\n",
      "    val_log_likelihood: -12162.145370657568\n",
      "    val_log_marginal: -12170.57638899824\n",
      "Train Epoch: 1776 [256/118836 (0%)] Loss: 12274.964844\n",
      "Train Epoch: 1776 [33024/118836 (28%)] Loss: 12242.372070\n",
      "Train Epoch: 1776 [65792/118836 (55%)] Loss: 12275.846680\n",
      "Train Epoch: 1776 [98560/118836 (83%)] Loss: 12325.878906\n",
      "    epoch          : 1776\n",
      "    loss           : 12237.582817508011\n",
      "    val_loss       : 12240.489851001756\n",
      "    val_log_likelihood: -12160.77347530242\n",
      "    val_log_marginal: -12169.108594329475\n",
      "Train Epoch: 1777 [256/118836 (0%)] Loss: 12214.050781\n",
      "Train Epoch: 1777 [33024/118836 (28%)] Loss: 12131.488281\n",
      "Train Epoch: 1777 [65792/118836 (55%)] Loss: 12363.440430\n",
      "Train Epoch: 1777 [98560/118836 (83%)] Loss: 12335.948242\n",
      "    epoch          : 1777\n",
      "    loss           : 12233.486632967586\n",
      "    val_loss       : 12240.102121305228\n",
      "    val_log_likelihood: -12162.252068793941\n",
      "    val_log_marginal: -12170.643042081329\n",
      "Train Epoch: 1778 [256/118836 (0%)] Loss: 12296.544922\n",
      "Train Epoch: 1778 [33024/118836 (28%)] Loss: 12287.081055\n",
      "Train Epoch: 1778 [65792/118836 (55%)] Loss: 12218.731445\n",
      "Train Epoch: 1778 [98560/118836 (83%)] Loss: 12329.830078\n",
      "    epoch          : 1778\n",
      "    loss           : 12234.175280610267\n",
      "    val_loss       : 12238.079373908167\n",
      "    val_log_likelihood: -12162.569510087107\n",
      "    val_log_marginal: -12170.873344820027\n",
      "Train Epoch: 1779 [256/118836 (0%)] Loss: 12234.960938\n",
      "Train Epoch: 1779 [33024/118836 (28%)] Loss: 12213.024414\n",
      "Train Epoch: 1779 [65792/118836 (55%)] Loss: 12285.389648\n",
      "Train Epoch: 1779 [98560/118836 (83%)] Loss: 12304.041016\n",
      "    epoch          : 1779\n",
      "    loss           : 12239.829964071547\n",
      "    val_loss       : 12238.333028193387\n",
      "    val_log_likelihood: -12162.241665051179\n",
      "    val_log_marginal: -12170.816775395753\n",
      "Train Epoch: 1780 [256/118836 (0%)] Loss: 12215.542969\n",
      "Train Epoch: 1780 [33024/118836 (28%)] Loss: 12268.685547\n",
      "Train Epoch: 1780 [65792/118836 (55%)] Loss: 12311.231445\n",
      "Train Epoch: 1780 [98560/118836 (83%)] Loss: 12300.117188\n",
      "    epoch          : 1780\n",
      "    loss           : 12237.662569627531\n",
      "    val_loss       : 12241.421812963747\n",
      "    val_log_likelihood: -12161.162316480564\n",
      "    val_log_marginal: -12169.617271177174\n",
      "Train Epoch: 1781 [256/118836 (0%)] Loss: 12350.453125\n",
      "Train Epoch: 1781 [33024/118836 (28%)] Loss: 12233.540039\n",
      "Train Epoch: 1781 [65792/118836 (55%)] Loss: 12246.906250\n",
      "Train Epoch: 1781 [98560/118836 (83%)] Loss: 12231.238281\n",
      "    epoch          : 1781\n",
      "    loss           : 12240.014810632496\n",
      "    val_loss       : 12234.812832509053\n",
      "    val_log_likelihood: -12158.3596580335\n",
      "    val_log_marginal: -12166.682763345778\n",
      "Train Epoch: 1782 [256/118836 (0%)] Loss: 12144.329102\n",
      "Train Epoch: 1782 [33024/118836 (28%)] Loss: 12289.698242\n",
      "Train Epoch: 1782 [65792/118836 (55%)] Loss: 12246.421875\n",
      "Train Epoch: 1782 [98560/118836 (83%)] Loss: 12279.870117\n",
      "    epoch          : 1782\n",
      "    loss           : 12235.407808784377\n",
      "    val_loss       : 12236.773228762782\n",
      "    val_log_likelihood: -12159.70871636554\n",
      "    val_log_marginal: -12168.015604993552\n",
      "Train Epoch: 1783 [256/118836 (0%)] Loss: 12256.039062\n",
      "Train Epoch: 1783 [33024/118836 (28%)] Loss: 12146.681641\n",
      "Train Epoch: 1783 [65792/118836 (55%)] Loss: 12239.042969\n",
      "Train Epoch: 1783 [98560/118836 (83%)] Loss: 12227.492188\n",
      "    epoch          : 1783\n",
      "    loss           : 12239.245998920855\n",
      "    val_loss       : 12236.587447754582\n",
      "    val_log_likelihood: -12160.735615210144\n",
      "    val_log_marginal: -12169.10407205807\n",
      "Train Epoch: 1784 [256/118836 (0%)] Loss: 12263.350586\n",
      "Train Epoch: 1784 [33024/118836 (28%)] Loss: 12355.177734\n",
      "Train Epoch: 1784 [65792/118836 (55%)] Loss: 12208.401367\n",
      "Train Epoch: 1784 [98560/118836 (83%)] Loss: 12236.784180\n",
      "    epoch          : 1784\n",
      "    loss           : 12237.949424886268\n",
      "    val_loss       : 12241.094688124354\n",
      "    val_log_likelihood: -12160.885652689463\n",
      "    val_log_marginal: -12169.21492223703\n",
      "Train Epoch: 1785 [256/118836 (0%)] Loss: 12181.869141\n",
      "Train Epoch: 1785 [33024/118836 (28%)] Loss: 12277.849609\n",
      "Train Epoch: 1785 [65792/118836 (55%)] Loss: 12436.916016\n",
      "Train Epoch: 1785 [98560/118836 (83%)] Loss: 12218.941406\n",
      "    epoch          : 1785\n",
      "    loss           : 12236.98600486585\n",
      "    val_loss       : 12238.1897581287\n",
      "    val_log_likelihood: -12160.989049576097\n",
      "    val_log_marginal: -12169.422115157491\n",
      "Train Epoch: 1786 [256/118836 (0%)] Loss: 12326.717773\n",
      "Train Epoch: 1786 [33024/118836 (28%)] Loss: 12301.085938\n",
      "Train Epoch: 1786 [65792/118836 (55%)] Loss: 12335.886719\n",
      "Train Epoch: 1786 [98560/118836 (83%)] Loss: 12322.804688\n",
      "    epoch          : 1786\n",
      "    loss           : 12236.372387109699\n",
      "    val_loss       : 12237.275389737313\n",
      "    val_log_likelihood: -12160.649565433727\n",
      "    val_log_marginal: -12169.034740234858\n",
      "Train Epoch: 1787 [256/118836 (0%)] Loss: 12283.344727\n",
      "Train Epoch: 1787 [33024/118836 (28%)] Loss: 12246.427734\n",
      "Train Epoch: 1787 [65792/118836 (55%)] Loss: 12203.729492\n",
      "Train Epoch: 1787 [98560/118836 (83%)] Loss: 12317.761719\n",
      "    epoch          : 1787\n",
      "    loss           : 12243.780777469758\n",
      "    val_loss       : 12241.513269528798\n",
      "    val_log_likelihood: -12163.314693509616\n",
      "    val_log_marginal: -12171.856445176012\n",
      "Train Epoch: 1788 [256/118836 (0%)] Loss: 12295.675781\n",
      "Train Epoch: 1788 [33024/118836 (28%)] Loss: 12287.958984\n",
      "Train Epoch: 1788 [65792/118836 (55%)] Loss: 12231.121094\n",
      "Train Epoch: 1788 [98560/118836 (83%)] Loss: 12185.791016\n",
      "    epoch          : 1788\n",
      "    loss           : 12240.86771673387\n",
      "    val_loss       : 12236.92967038959\n",
      "    val_log_likelihood: -12164.710618441119\n",
      "    val_log_marginal: -12173.009737878941\n",
      "Train Epoch: 1789 [256/118836 (0%)] Loss: 12163.401367\n",
      "Train Epoch: 1789 [33024/118836 (28%)] Loss: 12356.427734\n",
      "Train Epoch: 1789 [65792/118836 (55%)] Loss: 12382.464844\n",
      "Train Epoch: 1789 [98560/118836 (83%)] Loss: 12291.105469\n",
      "    epoch          : 1789\n",
      "    loss           : 12237.34178879756\n",
      "    val_loss       : 12240.884949792598\n",
      "    val_log_likelihood: -12163.219331414135\n",
      "    val_log_marginal: -12171.539386175691\n",
      "Train Epoch: 1790 [256/118836 (0%)] Loss: 12317.836914\n",
      "Train Epoch: 1790 [33024/118836 (28%)] Loss: 12200.732422\n",
      "Train Epoch: 1790 [65792/118836 (55%)] Loss: 12281.390625\n",
      "Train Epoch: 1790 [98560/118836 (83%)] Loss: 12281.173828\n",
      "    epoch          : 1790\n",
      "    loss           : 12238.07390873785\n",
      "    val_loss       : 12238.708543128983\n",
      "    val_log_likelihood: -12163.781831898781\n",
      "    val_log_marginal: -12172.101326197964\n",
      "Train Epoch: 1791 [256/118836 (0%)] Loss: 12347.547852\n",
      "Train Epoch: 1791 [33024/118836 (28%)] Loss: 12216.683594\n",
      "Train Epoch: 1791 [65792/118836 (55%)] Loss: 12235.976562\n",
      "Train Epoch: 1791 [98560/118836 (83%)] Loss: 12202.291992\n",
      "    epoch          : 1791\n",
      "    loss           : 12240.152334218621\n",
      "    val_loss       : 12241.345956473751\n",
      "    val_log_likelihood: -12163.976186414391\n",
      "    val_log_marginal: -12172.287254353882\n",
      "Train Epoch: 1792 [256/118836 (0%)] Loss: 12264.898438\n",
      "Train Epoch: 1792 [33024/118836 (28%)] Loss: 12217.952148\n",
      "Train Epoch: 1792 [65792/118836 (55%)] Loss: 12287.998047\n",
      "Train Epoch: 1792 [98560/118836 (83%)] Loss: 12246.542969\n",
      "    epoch          : 1792\n",
      "    loss           : 12240.450031986662\n",
      "    val_loss       : 12241.716396950353\n",
      "    val_log_likelihood: -12163.29096732191\n",
      "    val_log_marginal: -12171.66674301821\n",
      "Train Epoch: 1793 [256/118836 (0%)] Loss: 12263.615234\n",
      "Train Epoch: 1793 [33024/118836 (28%)] Loss: 12270.249023\n",
      "Train Epoch: 1793 [65792/118836 (55%)] Loss: 12165.000000\n",
      "Train Epoch: 1793 [98560/118836 (83%)] Loss: 12232.277344\n",
      "    epoch          : 1793\n",
      "    loss           : 12238.546976129548\n",
      "    val_loss       : 12241.37092711234\n",
      "    val_log_likelihood: -12163.188983502636\n",
      "    val_log_marginal: -12171.554783951153\n",
      "Train Epoch: 1794 [256/118836 (0%)] Loss: 12345.087891\n",
      "Train Epoch: 1794 [33024/118836 (28%)] Loss: 12299.511719\n",
      "Train Epoch: 1794 [65792/118836 (55%)] Loss: 12301.520508\n",
      "Train Epoch: 1794 [98560/118836 (83%)] Loss: 12279.261719\n",
      "    epoch          : 1794\n",
      "    loss           : 12239.251972672406\n",
      "    val_loss       : 12236.197151152071\n",
      "    val_log_likelihood: -12162.439802231958\n",
      "    val_log_marginal: -12170.659727900107\n",
      "Train Epoch: 1795 [256/118836 (0%)] Loss: 12202.463867\n",
      "Train Epoch: 1795 [33024/118836 (28%)] Loss: 12277.996094\n",
      "Train Epoch: 1795 [65792/118836 (55%)] Loss: 12233.560547\n",
      "Train Epoch: 1795 [98560/118836 (83%)] Loss: 12244.039062\n",
      "    epoch          : 1795\n",
      "    loss           : 12239.05449073356\n",
      "    val_loss       : 12236.863992584438\n",
      "    val_log_likelihood: -12161.222708430263\n",
      "    val_log_marginal: -12169.469406250904\n",
      "Train Epoch: 1796 [256/118836 (0%)] Loss: 12253.121094\n",
      "Train Epoch: 1796 [33024/118836 (28%)] Loss: 12232.138672\n",
      "Train Epoch: 1796 [65792/118836 (55%)] Loss: 12276.595703\n",
      "Train Epoch: 1796 [98560/118836 (83%)] Loss: 12232.652344\n",
      "    epoch          : 1796\n",
      "    loss           : 12238.244871471774\n",
      "    val_loss       : 12236.927263384168\n",
      "    val_log_likelihood: -12162.809668372622\n",
      "    val_log_marginal: -12171.032694449\n",
      "Train Epoch: 1797 [256/118836 (0%)] Loss: 12223.226562\n",
      "Train Epoch: 1797 [33024/118836 (28%)] Loss: 12311.453125\n",
      "Train Epoch: 1797 [65792/118836 (55%)] Loss: 12252.747070\n",
      "Train Epoch: 1797 [98560/118836 (83%)] Loss: 12302.932617\n",
      "    epoch          : 1797\n",
      "    loss           : 12238.384680327232\n",
      "    val_loss       : 12235.928142492463\n",
      "    val_log_likelihood: -12163.612342005274\n",
      "    val_log_marginal: -12171.868580917622\n",
      "Train Epoch: 1798 [256/118836 (0%)] Loss: 12204.823242\n",
      "Train Epoch: 1798 [33024/118836 (28%)] Loss: 12232.547852\n",
      "Train Epoch: 1798 [65792/118836 (55%)] Loss: 12239.475586\n",
      "Train Epoch: 1798 [98560/118836 (83%)] Loss: 12217.126953\n",
      "    epoch          : 1798\n",
      "    loss           : 12235.393870030759\n",
      "    val_loss       : 12240.026436952143\n",
      "    val_log_likelihood: -12163.40048642344\n",
      "    val_log_marginal: -12171.672729242691\n",
      "Train Epoch: 1799 [256/118836 (0%)] Loss: 12360.992188\n",
      "Train Epoch: 1799 [33024/118836 (28%)] Loss: 12311.995117\n",
      "Train Epoch: 1799 [65792/118836 (55%)] Loss: 12242.266602\n",
      "Train Epoch: 1799 [98560/118836 (83%)] Loss: 12187.725586\n",
      "    epoch          : 1799\n",
      "    loss           : 12238.810182420906\n",
      "    val_loss       : 12245.214041130126\n",
      "    val_log_likelihood: -12171.111962688688\n",
      "    val_log_marginal: -12179.782649418026\n",
      "Train Epoch: 1800 [256/118836 (0%)] Loss: 12313.218750\n",
      "Train Epoch: 1800 [33024/118836 (28%)] Loss: 12222.787109\n",
      "Train Epoch: 1800 [65792/118836 (55%)] Loss: 12249.769531\n",
      "Train Epoch: 1800 [98560/118836 (83%)] Loss: 12250.984375\n",
      "    epoch          : 1800\n",
      "    loss           : 12240.09029220947\n",
      "    val_loss       : 12239.351693378681\n",
      "    val_log_likelihood: -12161.014848434916\n",
      "    val_log_marginal: -12169.288574504282\n",
      "Saving checkpoint: saved/models/SelfiesAutoencodingOperad/0905_154251/checkpoint-epoch1800.pth ...\n",
      "Train Epoch: 1801 [256/118836 (0%)] Loss: 12365.614258\n",
      "Train Epoch: 1801 [33024/118836 (28%)] Loss: 12274.063477\n",
      "Train Epoch: 1801 [65792/118836 (55%)] Loss: 12236.623047\n",
      "Train Epoch: 1801 [98560/118836 (83%)] Loss: 12215.328125\n",
      "    epoch          : 1801\n",
      "    loss           : 12236.569717677316\n",
      "    val_loss       : 12240.789695001382\n",
      "    val_log_likelihood: -12163.563317275382\n",
      "    val_log_marginal: -12172.164306293862\n",
      "Train Epoch: 1802 [256/118836 (0%)] Loss: 12253.964844\n",
      "Train Epoch: 1802 [33024/118836 (28%)] Loss: 12144.465820\n",
      "Train Epoch: 1802 [65792/118836 (55%)] Loss: 12352.123047\n",
      "Train Epoch: 1802 [98560/118836 (83%)] Loss: 12233.599609\n",
      "    epoch          : 1802\n",
      "    loss           : 12239.176055075217\n",
      "    val_loss       : 12241.718898320336\n",
      "    val_log_likelihood: -12163.2550307912\n",
      "    val_log_marginal: -12171.53742292125\n",
      "Train Epoch: 1803 [256/118836 (0%)] Loss: 12231.664062\n",
      "Train Epoch: 1803 [33024/118836 (28%)] Loss: 12310.007812\n",
      "Train Epoch: 1803 [65792/118836 (55%)] Loss: 12185.368164\n",
      "Train Epoch: 1803 [98560/118836 (83%)] Loss: 12284.102539\n",
      "    epoch          : 1803\n",
      "    loss           : 12236.61137368176\n",
      "    val_loss       : 12236.051408578944\n",
      "    val_log_likelihood: -12159.368414786237\n",
      "    val_log_marginal: -12167.754142252703\n",
      "Train Epoch: 1804 [256/118836 (0%)] Loss: 12298.073242\n",
      "Train Epoch: 1804 [33024/118836 (28%)] Loss: 12218.071289\n",
      "Train Epoch: 1804 [65792/118836 (55%)] Loss: 12306.042969\n",
      "Train Epoch: 1804 [98560/118836 (83%)] Loss: 12307.349609\n",
      "    epoch          : 1804\n",
      "    loss           : 12236.928852454248\n",
      "    val_loss       : 12236.267520422936\n",
      "    val_log_likelihood: -12158.369117361972\n",
      "    val_log_marginal: -12166.51418828793\n",
      "Train Epoch: 1805 [256/118836 (0%)] Loss: 12346.352539\n",
      "Train Epoch: 1805 [33024/118836 (28%)] Loss: 12249.865234\n",
      "Train Epoch: 1805 [65792/118836 (55%)] Loss: 12289.910156\n",
      "Train Epoch: 1805 [98560/118836 (83%)] Loss: 12209.062500\n",
      "    epoch          : 1805\n",
      "    loss           : 12234.920291983302\n",
      "    val_loss       : 12232.799641249543\n",
      "    val_log_likelihood: -12162.911697587106\n",
      "    val_log_marginal: -12171.221599973122\n",
      "Train Epoch: 1806 [256/118836 (0%)] Loss: 12259.955078\n",
      "Train Epoch: 1806 [33024/118836 (28%)] Loss: 12319.406250\n",
      "Train Epoch: 1806 [65792/118836 (55%)] Loss: 12259.372070\n",
      "Train Epoch: 1806 [98560/118836 (83%)] Loss: 12295.584961\n",
      "    epoch          : 1806\n",
      "    loss           : 12237.97565879601\n",
      "    val_loss       : 12239.190074621421\n",
      "    val_log_likelihood: -12159.533171299887\n",
      "    val_log_marginal: -12168.01698242879\n",
      "Train Epoch: 1807 [256/118836 (0%)] Loss: 12216.712891\n",
      "Train Epoch: 1807 [33024/118836 (28%)] Loss: 12284.586914\n",
      "Train Epoch: 1807 [65792/118836 (55%)] Loss: 12312.251953\n",
      "Train Epoch: 1807 [98560/118836 (83%)] Loss: 12192.021484\n",
      "    epoch          : 1807\n",
      "    loss           : 12238.199673671423\n",
      "    val_loss       : 12239.669865091451\n",
      "    val_log_likelihood: -12161.210037026985\n",
      "    val_log_marginal: -12169.763975755834\n",
      "Train Epoch: 1808 [256/118836 (0%)] Loss: 12179.278320\n",
      "Train Epoch: 1808 [33024/118836 (28%)] Loss: 12336.022461\n",
      "Train Epoch: 1808 [65792/118836 (55%)] Loss: 12266.344727\n",
      "Train Epoch: 1808 [98560/118836 (83%)] Loss: 12324.958984\n",
      "    epoch          : 1808\n",
      "    loss           : 12237.564937771402\n",
      "    val_loss       : 12239.714070225373\n",
      "    val_log_likelihood: -12159.879696223634\n",
      "    val_log_marginal: -12168.471005235831\n",
      "Train Epoch: 1809 [256/118836 (0%)] Loss: 12211.242188\n",
      "Train Epoch: 1809 [33024/118836 (28%)] Loss: 12242.217773\n",
      "Train Epoch: 1809 [65792/118836 (55%)] Loss: 12208.107422\n",
      "Train Epoch: 1809 [98560/118836 (83%)] Loss: 12185.206055\n",
      "    epoch          : 1809\n",
      "    loss           : 12231.879950662997\n",
      "    val_loss       : 12235.903698186517\n",
      "    val_log_likelihood: -12160.095838664443\n",
      "    val_log_marginal: -12168.395222457262\n",
      "Train Epoch: 1810 [256/118836 (0%)] Loss: 12184.231445\n",
      "Train Epoch: 1810 [33024/118836 (28%)] Loss: 12251.023438\n",
      "Train Epoch: 1810 [65792/118836 (55%)] Loss: 12307.603516\n",
      "Train Epoch: 1810 [98560/118836 (83%)] Loss: 12228.985352\n",
      "    epoch          : 1810\n",
      "    loss           : 12242.2872977409\n",
      "    val_loss       : 12239.20317728626\n",
      "    val_log_likelihood: -12164.03557659998\n",
      "    val_log_marginal: -12172.658644094812\n",
      "Train Epoch: 1811 [256/118836 (0%)] Loss: 12246.827148\n",
      "Train Epoch: 1811 [33024/118836 (28%)] Loss: 12287.556641\n",
      "Train Epoch: 1811 [65792/118836 (55%)] Loss: 12285.121094\n",
      "Train Epoch: 1811 [98560/118836 (83%)] Loss: 12240.261719\n",
      "    epoch          : 1811\n",
      "    loss           : 12240.382354509149\n",
      "    val_loss       : 12245.203641312892\n",
      "    val_log_likelihood: -12165.823202769592\n",
      "    val_log_marginal: -12174.601816884091\n",
      "Train Epoch: 1812 [256/118836 (0%)] Loss: 12221.568359\n",
      "Train Epoch: 1812 [33024/118836 (28%)] Loss: 12228.901367\n",
      "Train Epoch: 1812 [65792/118836 (55%)] Loss: 12239.558594\n",
      "Train Epoch: 1812 [98560/118836 (83%)] Loss: 12223.225586\n",
      "    epoch          : 1812\n",
      "    loss           : 12239.636553000932\n",
      "    val_loss       : 12239.604623300196\n",
      "    val_log_likelihood: -12164.918130783446\n",
      "    val_log_marginal: -12173.547143585924\n",
      "Train Epoch: 1813 [256/118836 (0%)] Loss: 12196.221680\n",
      "Train Epoch: 1813 [33024/118836 (28%)] Loss: 12203.822266\n",
      "Train Epoch: 1813 [65792/118836 (55%)] Loss: 12250.158203\n",
      "Train Epoch: 1813 [98560/118836 (83%)] Loss: 12142.054688\n",
      "    epoch          : 1813\n",
      "    loss           : 12239.631169548697\n",
      "    val_loss       : 12236.950079683082\n",
      "    val_log_likelihood: -12162.201256526572\n",
      "    val_log_marginal: -12170.75748429531\n",
      "Train Epoch: 1814 [256/118836 (0%)] Loss: 12215.431641\n",
      "Train Epoch: 1814 [33024/118836 (28%)] Loss: 12222.795898\n",
      "Train Epoch: 1814 [65792/118836 (55%)] Loss: 12288.825195\n",
      "Train Epoch: 1814 [98560/118836 (83%)] Loss: 12437.108398\n",
      "    epoch          : 1814\n",
      "    loss           : 12237.059615546164\n",
      "    val_loss       : 12242.822040024186\n",
      "    val_log_likelihood: -12163.226116463762\n",
      "    val_log_marginal: -12171.811120427192\n",
      "Train Epoch: 1815 [256/118836 (0%)] Loss: 12249.004883\n",
      "Train Epoch: 1815 [33024/118836 (28%)] Loss: 12331.077148\n",
      "Train Epoch: 1815 [65792/118836 (55%)] Loss: 12267.715820\n",
      "Train Epoch: 1815 [98560/118836 (83%)] Loss: 12275.753906\n",
      "    epoch          : 1815\n",
      "    loss           : 12239.397182427367\n",
      "    val_loss       : 12236.191919322031\n",
      "    val_log_likelihood: -12161.436468349359\n",
      "    val_log_marginal: -12169.902413083239\n",
      "Train Epoch: 1816 [256/118836 (0%)] Loss: 12270.339844\n",
      "Train Epoch: 1816 [33024/118836 (28%)] Loss: 12209.092773\n",
      "Train Epoch: 1816 [65792/118836 (55%)] Loss: 12207.375000\n",
      "Train Epoch: 1816 [98560/118836 (83%)] Loss: 12272.030273\n",
      "    epoch          : 1816\n",
      "    loss           : 12237.624255421577\n",
      "    val_loss       : 12237.111366227498\n",
      "    val_log_likelihood: -12161.153531133685\n",
      "    val_log_marginal: -12169.532621274313\n",
      "Train Epoch: 1817 [256/118836 (0%)] Loss: 12222.628906\n",
      "Train Epoch: 1817 [33024/118836 (28%)] Loss: 12307.882812\n",
      "Train Epoch: 1817 [65792/118836 (55%)] Loss: 12334.168945\n",
      "Train Epoch: 1817 [98560/118836 (83%)] Loss: 12229.518555\n",
      "    epoch          : 1817\n",
      "    loss           : 12241.484316196236\n",
      "    val_loss       : 12238.732033335727\n",
      "    val_log_likelihood: -12160.542388951353\n",
      "    val_log_marginal: -12168.92605203949\n",
      "Train Epoch: 1818 [256/118836 (0%)] Loss: 12216.185547\n",
      "Train Epoch: 1818 [33024/118836 (28%)] Loss: 12226.132812\n",
      "Train Epoch: 1818 [65792/118836 (55%)] Loss: 12250.741211\n",
      "Train Epoch: 1818 [98560/118836 (83%)] Loss: 12253.775391\n",
      "    epoch          : 1818\n",
      "    loss           : 12241.485290173956\n",
      "    val_loss       : 12235.27807946748\n",
      "    val_log_likelihood: -12159.861133297147\n",
      "    val_log_marginal: -12168.31244503009\n",
      "Train Epoch: 1819 [256/118836 (0%)] Loss: 12292.179688\n",
      "Train Epoch: 1819 [33024/118836 (28%)] Loss: 12205.123047\n",
      "Train Epoch: 1819 [65792/118836 (55%)] Loss: 12293.684570\n",
      "Train Epoch: 1819 [98560/118836 (83%)] Loss: 12252.686523\n",
      "    epoch          : 1819\n",
      "    loss           : 12236.341963108714\n",
      "    val_loss       : 12237.49276117154\n",
      "    val_log_likelihood: -12162.273112463812\n",
      "    val_log_marginal: -12170.664580153298\n",
      "Train Epoch: 1820 [256/118836 (0%)] Loss: 12328.482422\n",
      "Train Epoch: 1820 [33024/118836 (28%)] Loss: 12251.392578\n",
      "Train Epoch: 1820 [65792/118836 (55%)] Loss: 12296.809570\n",
      "Train Epoch: 1820 [98560/118836 (83%)] Loss: 12355.664062\n",
      "    epoch          : 1820\n",
      "    loss           : 12239.371366121277\n",
      "    val_loss       : 12239.502604743999\n",
      "    val_log_likelihood: -12160.511563340055\n",
      "    val_log_marginal: -12168.915985260835\n",
      "Train Epoch: 1821 [256/118836 (0%)] Loss: 12212.696289\n",
      "Train Epoch: 1821 [33024/118836 (28%)] Loss: 12196.535156\n",
      "Train Epoch: 1821 [65792/118836 (55%)] Loss: 12208.075195\n",
      "Train Epoch: 1821 [98560/118836 (83%)] Loss: 12253.467773\n",
      "    epoch          : 1821\n",
      "    loss           : 12238.687638447322\n",
      "    val_loss       : 12236.686507236662\n",
      "    val_log_likelihood: -12158.893938042804\n",
      "    val_log_marginal: -12167.249056822811\n",
      "Train Epoch: 1822 [256/118836 (0%)] Loss: 12284.005859\n",
      "Train Epoch: 1822 [33024/118836 (28%)] Loss: 12260.758789\n",
      "Train Epoch: 1822 [65792/118836 (55%)] Loss: 12189.556641\n",
      "Train Epoch: 1822 [98560/118836 (83%)] Loss: 12362.134766\n",
      "    epoch          : 1822\n",
      "    loss           : 12242.623873197115\n",
      "    val_loss       : 12240.429075647382\n",
      "    val_log_likelihood: -12161.60959874509\n",
      "    val_log_marginal: -12170.051932849115\n",
      "Train Epoch: 1823 [256/118836 (0%)] Loss: 12236.294922\n",
      "Train Epoch: 1823 [33024/118836 (28%)] Loss: 12271.177734\n",
      "Train Epoch: 1823 [65792/118836 (55%)] Loss: 12302.000000\n",
      "Train Epoch: 1823 [98560/118836 (83%)] Loss: 12266.789062\n",
      "    epoch          : 1823\n",
      "    loss           : 12235.217808816687\n",
      "    val_loss       : 12239.032300219027\n",
      "    val_log_likelihood: -12160.461653161186\n",
      "    val_log_marginal: -12169.069020031478\n",
      "Train Epoch: 1824 [256/118836 (0%)] Loss: 12223.763672\n",
      "Train Epoch: 1824 [33024/118836 (28%)] Loss: 12279.920898\n",
      "Train Epoch: 1824 [65792/118836 (55%)] Loss: 12279.349609\n",
      "Train Epoch: 1824 [98560/118836 (83%)] Loss: 12224.435547\n",
      "    epoch          : 1824\n",
      "    loss           : 12237.95289867013\n",
      "    val_loss       : 12243.29021738051\n",
      "    val_log_likelihood: -12163.551377688173\n",
      "    val_log_marginal: -12172.229589313483\n",
      "Train Epoch: 1825 [256/118836 (0%)] Loss: 12247.989258\n",
      "Train Epoch: 1825 [33024/118836 (28%)] Loss: 12253.724609\n",
      "Train Epoch: 1825 [65792/118836 (55%)] Loss: 12332.757812\n",
      "Train Epoch: 1825 [98560/118836 (83%)] Loss: 12320.520508\n",
      "    epoch          : 1825\n",
      "    loss           : 12237.704872796474\n",
      "    val_loss       : 12238.907183429643\n",
      "    val_log_likelihood: -12161.42029343724\n",
      "    val_log_marginal: -12169.80444191848\n",
      "Train Epoch: 1826 [256/118836 (0%)] Loss: 12280.328125\n",
      "Train Epoch: 1826 [33024/118836 (28%)] Loss: 12323.817383\n",
      "Train Epoch: 1826 [65792/118836 (55%)] Loss: 12294.018555\n",
      "Train Epoch: 1826 [98560/118836 (83%)] Loss: 12328.945312\n",
      "    epoch          : 1826\n",
      "    loss           : 12238.550470430107\n",
      "    val_loss       : 12239.333557593647\n",
      "    val_log_likelihood: -12160.470659506824\n",
      "    val_log_marginal: -12169.0535158006\n",
      "Train Epoch: 1827 [256/118836 (0%)] Loss: 12211.683594\n",
      "Train Epoch: 1827 [33024/118836 (28%)] Loss: 12225.285156\n",
      "Train Epoch: 1827 [65792/118836 (55%)] Loss: 12194.193359\n",
      "Train Epoch: 1827 [98560/118836 (83%)] Loss: 12148.992188\n",
      "    epoch          : 1827\n",
      "    loss           : 12236.236014720327\n",
      "    val_loss       : 12237.151040930306\n",
      "    val_log_likelihood: -12163.524971244315\n",
      "    val_log_marginal: -12172.072165068752\n",
      "Train Epoch: 1828 [256/118836 (0%)] Loss: 12269.097656\n",
      "Train Epoch: 1828 [33024/118836 (28%)] Loss: 12265.936523\n",
      "Train Epoch: 1828 [65792/118836 (55%)] Loss: 12312.177734\n",
      "Train Epoch: 1828 [98560/118836 (83%)] Loss: 12304.604492\n",
      "    epoch          : 1828\n",
      "    loss           : 12241.04555110758\n",
      "    val_loss       : 12237.789314128388\n",
      "    val_log_likelihood: -12161.80573546707\n",
      "    val_log_marginal: -12170.267700208984\n",
      "Train Epoch: 1829 [256/118836 (0%)] Loss: 12235.332031\n",
      "Train Epoch: 1829 [33024/118836 (28%)] Loss: 12308.201172\n",
      "Train Epoch: 1829 [65792/118836 (55%)] Loss: 12230.624023\n",
      "Train Epoch: 1829 [98560/118836 (83%)] Loss: 12284.486328\n",
      "    epoch          : 1829\n",
      "    loss           : 12239.343860822477\n",
      "    val_loss       : 12237.157527406232\n",
      "    val_log_likelihood: -12160.680708973066\n",
      "    val_log_marginal: -12169.00169455976\n",
      "Train Epoch: 1830 [256/118836 (0%)] Loss: 12228.867188\n",
      "Train Epoch: 1830 [33024/118836 (28%)] Loss: 12215.585938\n",
      "Train Epoch: 1830 [65792/118836 (55%)] Loss: 12289.896484\n",
      "Train Epoch: 1830 [98560/118836 (83%)] Loss: 12247.465820\n",
      "    epoch          : 1830\n",
      "    loss           : 12238.818043547095\n",
      "    val_loss       : 12234.414235376411\n",
      "    val_log_likelihood: -12160.695220740281\n",
      "    val_log_marginal: -12169.14520263898\n",
      "Train Epoch: 1831 [256/118836 (0%)] Loss: 12255.966797\n",
      "Train Epoch: 1831 [33024/118836 (28%)] Loss: 12250.667969\n",
      "Train Epoch: 1831 [65792/118836 (55%)] Loss: 12275.519531\n",
      "Train Epoch: 1831 [98560/118836 (83%)] Loss: 12319.212891\n",
      "    epoch          : 1831\n",
      "    loss           : 12238.497484200529\n",
      "    val_loss       : 12237.28303041404\n",
      "    val_log_likelihood: -12161.113656527863\n",
      "    val_log_marginal: -12169.630147028085\n",
      "Train Epoch: 1832 [256/118836 (0%)] Loss: 12220.460938\n",
      "Train Epoch: 1832 [33024/118836 (28%)] Loss: 12302.501953\n",
      "Train Epoch: 1832 [65792/118836 (55%)] Loss: 12209.857422\n",
      "Train Epoch: 1832 [98560/118836 (83%)] Loss: 12221.724609\n",
      "    epoch          : 1832\n",
      "    loss           : 12237.622872725393\n",
      "    val_loss       : 12240.644762680391\n",
      "    val_log_likelihood: -12162.024878515302\n",
      "    val_log_marginal: -12170.537567765166\n",
      "Train Epoch: 1833 [256/118836 (0%)] Loss: 12229.519531\n",
      "Train Epoch: 1833 [33024/118836 (28%)] Loss: 12240.435547\n",
      "Train Epoch: 1833 [65792/118836 (55%)] Loss: 12313.394531\n",
      "Train Epoch: 1833 [98560/118836 (83%)] Loss: 12237.232422\n",
      "    epoch          : 1833\n",
      "    loss           : 12237.054235324906\n",
      "    val_loss       : 12242.598345354983\n",
      "    val_log_likelihood: -12161.208497305366\n",
      "    val_log_marginal: -12169.633671889183\n",
      "Train Epoch: 1834 [256/118836 (0%)] Loss: 12232.953125\n",
      "Train Epoch: 1834 [33024/118836 (28%)] Loss: 12240.662109\n",
      "Train Epoch: 1834 [65792/118836 (55%)] Loss: 12248.791016\n",
      "Train Epoch: 1834 [98560/118836 (83%)] Loss: 12314.596680\n",
      "    epoch          : 1834\n",
      "    loss           : 12237.4916419497\n",
      "    val_loss       : 12238.876402789889\n",
      "    val_log_likelihood: -12160.754681845792\n",
      "    val_log_marginal: -12169.149752984971\n",
      "Train Epoch: 1835 [256/118836 (0%)] Loss: 12206.226562\n",
      "Train Epoch: 1835 [33024/118836 (28%)] Loss: 12266.285156\n",
      "Train Epoch: 1835 [65792/118836 (55%)] Loss: 12264.057617\n",
      "Train Epoch: 1835 [98560/118836 (83%)] Loss: 12303.589844\n",
      "    epoch          : 1835\n",
      "    loss           : 12236.727835666097\n",
      "    val_loss       : 12238.141565105618\n",
      "    val_log_likelihood: -12160.909826528898\n",
      "    val_log_marginal: -12169.252263709343\n",
      "Train Epoch: 1836 [256/118836 (0%)] Loss: 12200.466797\n",
      "Train Epoch: 1836 [33024/118836 (28%)] Loss: 12223.014648\n",
      "Train Epoch: 1836 [65792/118836 (55%)] Loss: 12332.525391\n",
      "Train Epoch: 1836 [98560/118836 (83%)] Loss: 12265.878906\n",
      "    epoch          : 1836\n",
      "    loss           : 12241.96256995063\n",
      "    val_loss       : 12240.30216208767\n",
      "    val_log_likelihood: -12160.814250219706\n",
      "    val_log_marginal: -12169.426235707806\n",
      "Train Epoch: 1837 [256/118836 (0%)] Loss: 12266.997070\n",
      "Train Epoch: 1837 [33024/118836 (28%)] Loss: 12267.500977\n",
      "Train Epoch: 1837 [65792/118836 (55%)] Loss: 12205.021484\n",
      "Train Epoch: 1837 [98560/118836 (83%)] Loss: 12156.889648\n",
      "    epoch          : 1837\n",
      "    loss           : 12237.854957124948\n",
      "    val_loss       : 12241.098177180093\n",
      "    val_log_likelihood: -12161.277539708695\n",
      "    val_log_marginal: -12169.841670995198\n",
      "Train Epoch: 1838 [256/118836 (0%)] Loss: 12314.461914\n",
      "Train Epoch: 1838 [33024/118836 (28%)] Loss: 12279.000000\n",
      "Train Epoch: 1838 [65792/118836 (55%)] Loss: 12272.654297\n",
      "Train Epoch: 1838 [98560/118836 (83%)] Loss: 12292.844727\n",
      "    epoch          : 1838\n",
      "    loss           : 12237.29120673723\n",
      "    val_loss       : 12238.522515332104\n",
      "    val_log_likelihood: -12159.443858399247\n",
      "    val_log_marginal: -12168.026188210557\n",
      "Train Epoch: 1839 [256/118836 (0%)] Loss: 12289.021484\n",
      "Train Epoch: 1839 [33024/118836 (28%)] Loss: 12264.347656\n",
      "Train Epoch: 1839 [65792/118836 (55%)] Loss: 12295.681641\n",
      "Train Epoch: 1839 [98560/118836 (83%)] Loss: 12266.599609\n",
      "    epoch          : 1839\n",
      "    loss           : 12243.276908052885\n",
      "    val_loss       : 12239.023365263998\n",
      "    val_log_likelihood: -12162.214423238473\n",
      "    val_log_marginal: -12170.752351591986\n",
      "Train Epoch: 1840 [256/118836 (0%)] Loss: 12189.828125\n",
      "Train Epoch: 1840 [33024/118836 (28%)] Loss: 12253.523438\n",
      "Train Epoch: 1840 [65792/118836 (55%)] Loss: 12177.374023\n",
      "Train Epoch: 1840 [98560/118836 (83%)] Loss: 12200.191406\n",
      "    epoch          : 1840\n",
      "    loss           : 12235.357207499741\n",
      "    val_loss       : 12236.468895086517\n",
      "    val_log_likelihood: -12160.560097607786\n",
      "    val_log_marginal: -12169.006464980072\n",
      "Train Epoch: 1841 [256/118836 (0%)] Loss: 12378.878906\n",
      "Train Epoch: 1841 [33024/118836 (28%)] Loss: 12378.071289\n",
      "Train Epoch: 1841 [65792/118836 (55%)] Loss: 12281.901367\n",
      "Train Epoch: 1841 [98560/118836 (83%)] Loss: 12364.484375\n",
      "    epoch          : 1841\n",
      "    loss           : 12236.48052141491\n",
      "    val_loss       : 12235.794036794114\n",
      "    val_log_likelihood: -12160.606193134821\n",
      "    val_log_marginal: -12168.9041174972\n",
      "Train Epoch: 1842 [256/118836 (0%)] Loss: 12201.514648\n",
      "Train Epoch: 1842 [33024/118836 (28%)] Loss: 12160.283203\n",
      "Train Epoch: 1842 [65792/118836 (55%)] Loss: 12276.011719\n",
      "Train Epoch: 1842 [98560/118836 (83%)] Loss: 12335.538086\n",
      "    epoch          : 1842\n",
      "    loss           : 12238.854664398521\n",
      "    val_loss       : 12234.729551708759\n",
      "    val_log_likelihood: -12158.344606531742\n",
      "    val_log_marginal: -12166.785200462115\n",
      "Train Epoch: 1843 [256/118836 (0%)] Loss: 12257.744141\n",
      "Train Epoch: 1843 [33024/118836 (28%)] Loss: 12158.320312\n",
      "Train Epoch: 1843 [65792/118836 (55%)] Loss: 12240.754883\n",
      "Train Epoch: 1843 [98560/118836 (83%)] Loss: 12234.135742\n",
      "    epoch          : 1843\n",
      "    loss           : 12238.53630227719\n",
      "    val_loss       : 12243.50481487714\n",
      "    val_log_likelihood: -12162.01344053712\n",
      "    val_log_marginal: -12170.437116374533\n",
      "Train Epoch: 1844 [256/118836 (0%)] Loss: 12181.080078\n",
      "Train Epoch: 1844 [33024/118836 (28%)] Loss: 12334.656250\n",
      "Train Epoch: 1844 [65792/118836 (55%)] Loss: 12187.666016\n",
      "Train Epoch: 1844 [98560/118836 (83%)] Loss: 12197.883789\n",
      "    epoch          : 1844\n",
      "    loss           : 12237.088601762822\n",
      "    val_loss       : 12240.44389666128\n",
      "    val_log_likelihood: -12160.069257263234\n",
      "    val_log_marginal: -12168.326113391382\n",
      "Train Epoch: 1845 [256/118836 (0%)] Loss: 12227.557617\n",
      "Train Epoch: 1845 [33024/118836 (28%)] Loss: 12203.089844\n",
      "Train Epoch: 1845 [65792/118836 (55%)] Loss: 12262.436523\n",
      "Train Epoch: 1845 [98560/118836 (83%)] Loss: 12289.790039\n",
      "    epoch          : 1845\n",
      "    loss           : 12238.584586952025\n",
      "    val_loss       : 12236.009853498519\n",
      "    val_log_likelihood: -12158.810161419562\n",
      "    val_log_marginal: -12167.10695495278\n",
      "Train Epoch: 1846 [256/118836 (0%)] Loss: 12231.281250\n",
      "Train Epoch: 1846 [33024/118836 (28%)] Loss: 12178.215820\n",
      "Train Epoch: 1846 [65792/118836 (55%)] Loss: 12198.850586\n",
      "Train Epoch: 1846 [98560/118836 (83%)] Loss: 12199.166016\n",
      "    epoch          : 1846\n",
      "    loss           : 12234.382363717432\n",
      "    val_loss       : 12240.591888649633\n",
      "    val_log_likelihood: -12163.638912744262\n",
      "    val_log_marginal: -12171.967097166324\n",
      "Train Epoch: 1847 [256/118836 (0%)] Loss: 12243.981445\n",
      "Train Epoch: 1847 [33024/118836 (28%)] Loss: 12248.366211\n",
      "Train Epoch: 1847 [65792/118836 (55%)] Loss: 12289.265625\n",
      "Train Epoch: 1847 [98560/118836 (83%)] Loss: 12274.706055\n",
      "    epoch          : 1847\n",
      "    loss           : 12241.585543482473\n",
      "    val_loss       : 12236.883243054712\n",
      "    val_log_likelihood: -12158.525253954715\n",
      "    val_log_marginal: -12166.87687990412\n",
      "Train Epoch: 1848 [256/118836 (0%)] Loss: 12244.833984\n",
      "Train Epoch: 1848 [33024/118836 (28%)] Loss: 12185.869141\n",
      "Train Epoch: 1848 [65792/118836 (55%)] Loss: 12274.679688\n",
      "Train Epoch: 1848 [98560/118836 (83%)] Loss: 12327.009766\n",
      "    epoch          : 1848\n",
      "    loss           : 12238.414852473634\n",
      "    val_loss       : 12236.154220983144\n",
      "    val_log_likelihood: -12160.77380405423\n",
      "    val_log_marginal: -12169.169305250678\n",
      "Train Epoch: 1849 [256/118836 (0%)] Loss: 12300.748047\n",
      "Train Epoch: 1849 [33024/118836 (28%)] Loss: 12273.563477\n",
      "Train Epoch: 1849 [65792/118836 (55%)] Loss: 12298.781250\n",
      "Train Epoch: 1849 [98560/118836 (83%)] Loss: 12186.875000\n",
      "    epoch          : 1849\n",
      "    loss           : 12236.496076948924\n",
      "    val_loss       : 12235.785581396127\n",
      "    val_log_likelihood: -12162.187437319064\n",
      "    val_log_marginal: -12170.689554524584\n",
      "Train Epoch: 1850 [256/118836 (0%)] Loss: 12258.284180\n",
      "Train Epoch: 1850 [33024/118836 (28%)] Loss: 12194.816406\n",
      "Train Epoch: 1850 [65792/118836 (55%)] Loss: 12339.628906\n",
      "Train Epoch: 1850 [98560/118836 (83%)] Loss: 12384.904297\n",
      "    epoch          : 1850\n",
      "    loss           : 12238.385068367452\n",
      "    val_loss       : 12238.942976994134\n",
      "    val_log_likelihood: -12157.535136541048\n",
      "    val_log_marginal: -12165.769223914986\n",
      "Train Epoch: 1851 [256/118836 (0%)] Loss: 12201.482422\n",
      "Train Epoch: 1851 [33024/118836 (28%)] Loss: 12261.329102\n",
      "Train Epoch: 1851 [65792/118836 (55%)] Loss: 12225.932617\n",
      "Train Epoch: 1851 [98560/118836 (83%)] Loss: 12276.898438\n",
      "    epoch          : 1851\n",
      "    loss           : 12237.332381810897\n",
      "    val_loss       : 12234.144360947237\n",
      "    val_log_likelihood: -12159.358723473688\n",
      "    val_log_marginal: -12167.760600122363\n",
      "Train Epoch: 1852 [256/118836 (0%)] Loss: 12186.221680\n",
      "Train Epoch: 1852 [33024/118836 (28%)] Loss: 12243.917969\n",
      "Train Epoch: 1852 [65792/118836 (55%)] Loss: 12329.918945\n",
      "Train Epoch: 1852 [98560/118836 (83%)] Loss: 12196.824219\n",
      "    epoch          : 1852\n",
      "    loss           : 12234.504913668321\n",
      "    val_loss       : 12236.619133799002\n",
      "    val_log_likelihood: -12162.319504594449\n",
      "    val_log_marginal: -12170.808129180727\n",
      "Train Epoch: 1853 [256/118836 (0%)] Loss: 12244.821289\n",
      "Train Epoch: 1853 [33024/118836 (28%)] Loss: 12377.546875\n",
      "Train Epoch: 1853 [65792/118836 (55%)] Loss: 12214.201172\n",
      "Train Epoch: 1853 [98560/118836 (83%)] Loss: 12297.360352\n",
      "    epoch          : 1853\n",
      "    loss           : 12238.50325827776\n",
      "    val_loss       : 12237.69330021568\n",
      "    val_log_likelihood: -12160.13660291951\n",
      "    val_log_marginal: -12168.54015666276\n",
      "Train Epoch: 1854 [256/118836 (0%)] Loss: 12353.231445\n",
      "Train Epoch: 1854 [33024/118836 (28%)] Loss: 12266.064453\n",
      "Train Epoch: 1854 [65792/118836 (55%)] Loss: 12250.253906\n",
      "Train Epoch: 1854 [98560/118836 (83%)] Loss: 12326.658203\n",
      "    epoch          : 1854\n",
      "    loss           : 12240.595106202181\n",
      "    val_loss       : 12239.730752159094\n",
      "    val_log_likelihood: -12164.117848557693\n",
      "    val_log_marginal: -12172.787398707615\n",
      "Train Epoch: 1855 [256/118836 (0%)] Loss: 12263.522461\n",
      "Train Epoch: 1855 [33024/118836 (28%)] Loss: 12236.550781\n",
      "Train Epoch: 1855 [65792/118836 (55%)] Loss: 12196.715820\n",
      "Train Epoch: 1855 [98560/118836 (83%)] Loss: 12272.957031\n",
      "    epoch          : 1855\n",
      "    loss           : 12237.223534752378\n",
      "    val_loss       : 12233.808521392357\n",
      "    val_log_likelihood: -12158.964872182589\n",
      "    val_log_marginal: -12167.39932399911\n",
      "Train Epoch: 1856 [256/118836 (0%)] Loss: 12327.921875\n",
      "Train Epoch: 1856 [33024/118836 (28%)] Loss: 12201.088867\n",
      "Train Epoch: 1856 [65792/118836 (55%)] Loss: 12270.247070\n",
      "Train Epoch: 1856 [98560/118836 (83%)] Loss: 12239.970703\n",
      "    epoch          : 1856\n",
      "    loss           : 12238.550120676953\n",
      "    val_loss       : 12238.909676294968\n",
      "    val_log_likelihood: -12157.156983270006\n",
      "    val_log_marginal: -12165.738597524427\n",
      "Train Epoch: 1857 [256/118836 (0%)] Loss: 12258.763672\n",
      "Train Epoch: 1857 [33024/118836 (28%)] Loss: 12251.193359\n",
      "Train Epoch: 1857 [65792/118836 (55%)] Loss: 12186.738281\n",
      "Train Epoch: 1857 [98560/118836 (83%)] Loss: 12266.160156\n",
      "    epoch          : 1857\n",
      "    loss           : 12241.352693826251\n",
      "    val_loss       : 12237.623856424085\n",
      "    val_log_likelihood: -12158.99138331007\n",
      "    val_log_marginal: -12167.594944533916\n",
      "Train Epoch: 1858 [256/118836 (0%)] Loss: 12230.303711\n",
      "Train Epoch: 1858 [33024/118836 (28%)] Loss: 12274.989258\n",
      "Train Epoch: 1858 [65792/118836 (55%)] Loss: 12269.374023\n",
      "Train Epoch: 1858 [98560/118836 (83%)] Loss: 12277.672852\n",
      "    epoch          : 1858\n",
      "    loss           : 12242.78395868874\n",
      "    val_loss       : 12238.102477467273\n",
      "    val_log_likelihood: -12160.400487069634\n",
      "    val_log_marginal: -12169.04514724005\n",
      "Train Epoch: 1859 [256/118836 (0%)] Loss: 12197.642578\n",
      "Train Epoch: 1859 [33024/118836 (28%)] Loss: 12219.206055\n",
      "Train Epoch: 1859 [65792/118836 (55%)] Loss: 12257.295898\n",
      "Train Epoch: 1859 [98560/118836 (83%)] Loss: 12236.708984\n",
      "    epoch          : 1859\n",
      "    loss           : 12237.899239428247\n",
      "    val_loss       : 12235.09828180191\n",
      "    val_log_likelihood: -12160.770173083385\n",
      "    val_log_marginal: -12169.254663087515\n",
      "Train Epoch: 1860 [256/118836 (0%)] Loss: 12283.894531\n",
      "Train Epoch: 1860 [33024/118836 (28%)] Loss: 12165.875000\n",
      "Train Epoch: 1860 [65792/118836 (55%)] Loss: 12245.352539\n",
      "Train Epoch: 1860 [98560/118836 (83%)] Loss: 12223.734375\n",
      "    epoch          : 1860\n",
      "    loss           : 12236.457353701406\n",
      "    val_loss       : 12236.92785093014\n",
      "    val_log_likelihood: -12155.036665115798\n",
      "    val_log_marginal: -12163.433053100229\n",
      "Train Epoch: 1861 [256/118836 (0%)] Loss: 12263.327148\n",
      "Train Epoch: 1861 [33024/118836 (28%)] Loss: 12246.089844\n",
      "Train Epoch: 1861 [65792/118836 (55%)] Loss: 12118.748047\n",
      "Train Epoch: 1861 [98560/118836 (83%)] Loss: 12328.250000\n",
      "    epoch          : 1861\n",
      "    loss           : 12239.469798774813\n",
      "    val_loss       : 12234.740160188512\n",
      "    val_log_likelihood: -12158.126555068755\n",
      "    val_log_marginal: -12166.420871136384\n",
      "Train Epoch: 1862 [256/118836 (0%)] Loss: 12207.858398\n",
      "Train Epoch: 1862 [33024/118836 (28%)] Loss: 12211.061523\n",
      "Train Epoch: 1862 [65792/118836 (55%)] Loss: 12291.290039\n",
      "Train Epoch: 1862 [98560/118836 (83%)] Loss: 12301.363281\n",
      "    epoch          : 1862\n",
      "    loss           : 12237.465267169408\n",
      "    val_loss       : 12233.641268284451\n",
      "    val_log_likelihood: -12159.474118912842\n",
      "    val_log_marginal: -12167.878855498388\n",
      "Train Epoch: 1863 [256/118836 (0%)] Loss: 12275.208984\n",
      "Train Epoch: 1863 [33024/118836 (28%)] Loss: 12210.611328\n",
      "Train Epoch: 1863 [65792/118836 (55%)] Loss: 12302.335938\n",
      "Train Epoch: 1863 [98560/118836 (83%)] Loss: 12396.799805\n",
      "    epoch          : 1863\n",
      "    loss           : 12238.615700281742\n",
      "    val_loss       : 12239.664107975635\n",
      "    val_log_likelihood: -12159.872199874637\n",
      "    val_log_marginal: -12168.154898229332\n",
      "Train Epoch: 1864 [256/118836 (0%)] Loss: 12411.652344\n",
      "Train Epoch: 1864 [33024/118836 (28%)] Loss: 12325.110352\n",
      "Train Epoch: 1864 [65792/118836 (55%)] Loss: 12251.019531\n",
      "Train Epoch: 1864 [98560/118836 (83%)] Loss: 12209.485352\n",
      "    epoch          : 1864\n",
      "    loss           : 12242.0524582881\n",
      "    val_loss       : 12237.884756434463\n",
      "    val_log_likelihood: -12158.450577375414\n",
      "    val_log_marginal: -12167.002763679704\n",
      "Train Epoch: 1865 [256/118836 (0%)] Loss: 12186.385742\n",
      "Train Epoch: 1865 [33024/118836 (28%)] Loss: 12263.267578\n",
      "Train Epoch: 1865 [65792/118836 (55%)] Loss: 12290.527344\n",
      "Train Epoch: 1865 [98560/118836 (83%)] Loss: 12208.312500\n",
      "    epoch          : 1865\n",
      "    loss           : 12238.046275815497\n",
      "    val_loss       : 12239.02929884614\n",
      "    val_log_likelihood: -12161.297554474257\n",
      "    val_log_marginal: -12169.707117345633\n",
      "Train Epoch: 1866 [256/118836 (0%)] Loss: 12191.630859\n",
      "Train Epoch: 1866 [33024/118836 (28%)] Loss: 12265.002930\n",
      "Train Epoch: 1866 [65792/118836 (55%)] Loss: 12209.091797\n",
      "Train Epoch: 1866 [98560/118836 (83%)] Loss: 12306.754883\n",
      "    epoch          : 1866\n",
      "    loss           : 12237.312808719758\n",
      "    val_loss       : 12240.352519819235\n",
      "    val_log_likelihood: -12157.12540936466\n",
      "    val_log_marginal: -12165.600113956923\n",
      "Train Epoch: 1867 [256/118836 (0%)] Loss: 12247.490234\n",
      "Train Epoch: 1867 [33024/118836 (28%)] Loss: 12251.708984\n",
      "Train Epoch: 1867 [65792/118836 (55%)] Loss: 12221.894531\n",
      "Train Epoch: 1867 [98560/118836 (83%)] Loss: 12195.754883\n",
      "    epoch          : 1867\n",
      "    loss           : 12237.443124644593\n",
      "    val_loss       : 12229.270609695232\n",
      "    val_log_likelihood: -12156.344842716087\n",
      "    val_log_marginal: -12164.709450610193\n",
      "Train Epoch: 1868 [256/118836 (0%)] Loss: 12198.865234\n",
      "Train Epoch: 1868 [33024/118836 (28%)] Loss: 12184.026367\n",
      "Train Epoch: 1868 [65792/118836 (55%)] Loss: 12241.746094\n",
      "Train Epoch: 1868 [98560/118836 (83%)] Loss: 12234.523438\n",
      "    epoch          : 1868\n",
      "    loss           : 12237.353341475393\n",
      "    val_loss       : 12235.999965529458\n",
      "    val_log_likelihood: -12160.257699092743\n",
      "    val_log_marginal: -12168.641947238793\n",
      "Train Epoch: 1869 [256/118836 (0%)] Loss: 12369.296875\n",
      "Train Epoch: 1869 [33024/118836 (28%)] Loss: 12286.878906\n",
      "Train Epoch: 1869 [65792/118836 (55%)] Loss: 12243.018555\n",
      "Train Epoch: 1869 [98560/118836 (83%)] Loss: 12270.570312\n",
      "    epoch          : 1869\n",
      "    loss           : 12232.596427348275\n",
      "    val_loss       : 12236.749906604708\n",
      "    val_log_likelihood: -12160.658334302625\n",
      "    val_log_marginal: -12169.03630980896\n",
      "Train Epoch: 1870 [256/118836 (0%)] Loss: 12232.334961\n",
      "Train Epoch: 1870 [33024/118836 (28%)] Loss: 12287.802734\n",
      "Train Epoch: 1870 [65792/118836 (55%)] Loss: 12251.439453\n",
      "Train Epoch: 1870 [98560/118836 (83%)] Loss: 12207.691406\n",
      "    epoch          : 1870\n",
      "    loss           : 12236.94266035334\n",
      "    val_loss       : 12238.110651077839\n",
      "    val_log_likelihood: -12158.783681632549\n",
      "    val_log_marginal: -12167.384280318794\n",
      "Train Epoch: 1871 [256/118836 (0%)] Loss: 12320.921875\n",
      "Train Epoch: 1871 [33024/118836 (28%)] Loss: 12270.033203\n",
      "Train Epoch: 1871 [65792/118836 (55%)] Loss: 12311.573242\n",
      "Train Epoch: 1871 [98560/118836 (83%)] Loss: 12241.227539\n",
      "    epoch          : 1871\n",
      "    loss           : 12240.3077721128\n",
      "    val_loss       : 12231.824328507117\n",
      "    val_log_likelihood: -12159.835115701251\n",
      "    val_log_marginal: -12168.257746382395\n",
      "Train Epoch: 1872 [256/118836 (0%)] Loss: 12354.517578\n",
      "Train Epoch: 1872 [33024/118836 (28%)] Loss: 12220.096680\n",
      "Train Epoch: 1872 [65792/118836 (55%)] Loss: 12195.616211\n",
      "Train Epoch: 1872 [98560/118836 (83%)] Loss: 12218.736328\n",
      "    epoch          : 1872\n",
      "    loss           : 12236.056406702337\n",
      "    val_loss       : 12235.452200867596\n",
      "    val_log_likelihood: -12159.239391898005\n",
      "    val_log_marginal: -12167.452912064102\n",
      "Train Epoch: 1873 [256/118836 (0%)] Loss: 12319.361328\n",
      "Train Epoch: 1873 [33024/118836 (28%)] Loss: 12240.269531\n",
      "Train Epoch: 1873 [65792/118836 (55%)] Loss: 12197.695312\n",
      "Train Epoch: 1873 [98560/118836 (83%)] Loss: 12242.410156\n",
      "    epoch          : 1873\n",
      "    loss           : 12234.546275815497\n",
      "    val_loss       : 12232.846555911938\n",
      "    val_log_likelihood: -12159.216070228495\n",
      "    val_log_marginal: -12167.642158480776\n",
      "Train Epoch: 1874 [256/118836 (0%)] Loss: 12190.775391\n",
      "Train Epoch: 1874 [33024/118836 (28%)] Loss: 12278.264648\n",
      "Train Epoch: 1874 [65792/118836 (55%)] Loss: 12205.638672\n",
      "Train Epoch: 1874 [98560/118836 (83%)] Loss: 12268.229492\n",
      "    epoch          : 1874\n",
      "    loss           : 12236.331017369726\n",
      "    val_loss       : 12234.271745889166\n",
      "    val_log_likelihood: -12156.605350980924\n",
      "    val_log_marginal: -12164.961892356047\n",
      "Train Epoch: 1875 [256/118836 (0%)] Loss: 12256.138672\n",
      "Train Epoch: 1875 [33024/118836 (28%)] Loss: 12245.540039\n",
      "Train Epoch: 1875 [65792/118836 (55%)] Loss: 12264.718750\n",
      "Train Epoch: 1875 [98560/118836 (83%)] Loss: 12243.471680\n",
      "    epoch          : 1875\n",
      "    loss           : 12235.304356486506\n",
      "    val_loss       : 12236.516035809933\n",
      "    val_log_likelihood: -12161.365260384357\n",
      "    val_log_marginal: -12170.057865373361\n",
      "Train Epoch: 1876 [256/118836 (0%)] Loss: 12331.519531\n",
      "Train Epoch: 1876 [33024/118836 (28%)] Loss: 12241.813477\n",
      "Train Epoch: 1876 [65792/118836 (55%)] Loss: 12285.294922\n",
      "Train Epoch: 1876 [98560/118836 (83%)] Loss: 12371.723633\n",
      "    epoch          : 1876\n",
      "    loss           : 12238.73053870063\n",
      "    val_loss       : 12238.237945031584\n",
      "    val_log_likelihood: -12159.571355135959\n",
      "    val_log_marginal: -12168.136910975065\n",
      "Train Epoch: 1877 [256/118836 (0%)] Loss: 12276.646484\n",
      "Train Epoch: 1877 [33024/118836 (28%)] Loss: 12232.983398\n",
      "Train Epoch: 1877 [65792/118836 (55%)] Loss: 12263.912109\n",
      "Train Epoch: 1877 [98560/118836 (83%)] Loss: 12216.408203\n",
      "    epoch          : 1877\n",
      "    loss           : 12232.653382831886\n",
      "    val_loss       : 12239.643478558672\n",
      "    val_log_likelihood: -12160.679088153951\n",
      "    val_log_marginal: -12169.050393494812\n",
      "Train Epoch: 1878 [256/118836 (0%)] Loss: 12271.668945\n",
      "Train Epoch: 1878 [33024/118836 (28%)] Loss: 12270.924805\n",
      "Train Epoch: 1878 [65792/118836 (55%)] Loss: 12311.887695\n",
      "Train Epoch: 1878 [98560/118836 (83%)] Loss: 12272.637695\n",
      "    epoch          : 1878\n",
      "    loss           : 12236.677421454973\n",
      "    val_loss       : 12237.691387509796\n",
      "    val_log_likelihood: -12158.23451102409\n",
      "    val_log_marginal: -12166.664181539078\n",
      "Train Epoch: 1879 [256/118836 (0%)] Loss: 12285.728516\n",
      "Train Epoch: 1879 [33024/118836 (28%)] Loss: 12230.045898\n",
      "Train Epoch: 1879 [65792/118836 (55%)] Loss: 12216.378906\n",
      "Train Epoch: 1879 [98560/118836 (83%)] Loss: 12274.155273\n",
      "    epoch          : 1879\n",
      "    loss           : 12237.064458133013\n",
      "    val_loss       : 12239.538382518784\n",
      "    val_log_likelihood: -12158.634200365746\n",
      "    val_log_marginal: -12167.160915818758\n",
      "Train Epoch: 1880 [256/118836 (0%)] Loss: 12292.999023\n",
      "Train Epoch: 1880 [33024/118836 (28%)] Loss: 12207.894531\n",
      "Train Epoch: 1880 [65792/118836 (55%)] Loss: 12241.065430\n",
      "Train Epoch: 1880 [98560/118836 (83%)] Loss: 12297.583984\n",
      "    epoch          : 1880\n",
      "    loss           : 12233.000455729167\n",
      "    val_loss       : 12235.772868758451\n",
      "    val_log_likelihood: -12160.690097381617\n",
      "    val_log_marginal: -12169.052210358472\n",
      "Train Epoch: 1881 [256/118836 (0%)] Loss: 12280.012695\n",
      "Train Epoch: 1881 [33024/118836 (28%)] Loss: 12272.966797\n",
      "Train Epoch: 1881 [65792/118836 (55%)] Loss: 12262.782227\n",
      "Train Epoch: 1881 [98560/118836 (83%)] Loss: 12238.955078\n",
      "    epoch          : 1881\n",
      "    loss           : 12237.19239088994\n",
      "    val_loss       : 12235.191240211128\n",
      "    val_log_likelihood: -12159.991922398418\n",
      "    val_log_marginal: -12168.451139883662\n",
      "Train Epoch: 1882 [256/118836 (0%)] Loss: 12152.147461\n",
      "Train Epoch: 1882 [33024/118836 (28%)] Loss: 12154.105469\n",
      "Train Epoch: 1882 [65792/118836 (55%)] Loss: 12215.568359\n",
      "Train Epoch: 1882 [98560/118836 (83%)] Loss: 12225.991211\n",
      "    epoch          : 1882\n",
      "    loss           : 12232.433096502791\n",
      "    val_loss       : 12231.925507591955\n",
      "    val_log_likelihood: -12160.144637872208\n",
      "    val_log_marginal: -12168.4181224726\n",
      "Train Epoch: 1883 [256/118836 (0%)] Loss: 12203.651367\n",
      "Train Epoch: 1883 [33024/118836 (28%)] Loss: 12259.830078\n",
      "Train Epoch: 1883 [65792/118836 (55%)] Loss: 12239.089844\n",
      "Train Epoch: 1883 [98560/118836 (83%)] Loss: 12179.612305\n",
      "    epoch          : 1883\n",
      "    loss           : 12239.132810399866\n",
      "    val_loss       : 12239.543860084925\n",
      "    val_log_likelihood: -12160.080165845999\n",
      "    val_log_marginal: -12168.455056248751\n",
      "Train Epoch: 1884 [256/118836 (0%)] Loss: 12286.271484\n",
      "Train Epoch: 1884 [33024/118836 (28%)] Loss: 12218.785156\n",
      "Train Epoch: 1884 [65792/118836 (55%)] Loss: 12352.233398\n",
      "Train Epoch: 1884 [98560/118836 (83%)] Loss: 12285.971680\n",
      "    epoch          : 1884\n",
      "    loss           : 12243.659732345946\n",
      "    val_loss       : 12237.492543994487\n",
      "    val_log_likelihood: -12160.314109187604\n",
      "    val_log_marginal: -12168.758185118826\n",
      "Train Epoch: 1885 [256/118836 (0%)] Loss: 12269.487305\n",
      "Train Epoch: 1885 [33024/118836 (28%)] Loss: 12186.858398\n",
      "Train Epoch: 1885 [65792/118836 (55%)] Loss: 12293.562500\n",
      "Train Epoch: 1885 [98560/118836 (83%)] Loss: 12222.750000\n",
      "    epoch          : 1885\n",
      "    loss           : 12236.81403406741\n",
      "    val_loss       : 12239.790681935105\n",
      "    val_log_likelihood: -12164.102398676592\n",
      "    val_log_marginal: -12172.761005593406\n",
      "Train Epoch: 1886 [256/118836 (0%)] Loss: 12326.771484\n",
      "Train Epoch: 1886 [33024/118836 (28%)] Loss: 12254.235352\n",
      "Train Epoch: 1886 [65792/118836 (55%)] Loss: 12270.691406\n",
      "Train Epoch: 1886 [98560/118836 (83%)] Loss: 12325.059570\n",
      "    epoch          : 1886\n",
      "    loss           : 12234.304071029776\n",
      "    val_loss       : 12235.191603040168\n",
      "    val_log_likelihood: -12157.821552225496\n",
      "    val_log_marginal: -12166.355249522712\n",
      "Train Epoch: 1887 [256/118836 (0%)] Loss: 12240.849609\n",
      "Train Epoch: 1887 [33024/118836 (28%)] Loss: 12267.457031\n",
      "Train Epoch: 1887 [65792/118836 (55%)] Loss: 12283.087891\n",
      "Train Epoch: 1887 [98560/118836 (83%)] Loss: 12199.562500\n",
      "    epoch          : 1887\n",
      "    loss           : 12235.700670912169\n",
      "    val_loss       : 12238.986292723772\n",
      "    val_log_likelihood: -12162.022058519437\n",
      "    val_log_marginal: -12170.256346162749\n",
      "Train Epoch: 1888 [256/118836 (0%)] Loss: 12308.314453\n",
      "Train Epoch: 1888 [33024/118836 (28%)] Loss: 12263.423828\n",
      "Train Epoch: 1888 [65792/118836 (55%)] Loss: 12281.762695\n",
      "Train Epoch: 1888 [98560/118836 (83%)] Loss: 12413.915039\n",
      "    epoch          : 1888\n",
      "    loss           : 12239.798617626913\n",
      "    val_loss       : 12235.823840237501\n",
      "    val_log_likelihood: -12157.473796622984\n",
      "    val_log_marginal: -12165.840626963847\n",
      "Train Epoch: 1889 [256/118836 (0%)] Loss: 12242.036133\n",
      "Train Epoch: 1889 [33024/118836 (28%)] Loss: 12318.021484\n",
      "Train Epoch: 1889 [65792/118836 (55%)] Loss: 12333.407227\n",
      "Train Epoch: 1889 [98560/118836 (83%)] Loss: 12201.049805\n",
      "    epoch          : 1889\n",
      "    loss           : 12234.970198446546\n",
      "    val_loss       : 12236.353961182414\n",
      "    val_log_likelihood: -12158.32066532258\n",
      "    val_log_marginal: -12166.69590960082\n",
      "Train Epoch: 1890 [256/118836 (0%)] Loss: 12212.970703\n",
      "Train Epoch: 1890 [33024/118836 (28%)] Loss: 12348.129883\n",
      "Train Epoch: 1890 [65792/118836 (55%)] Loss: 12274.386719\n",
      "Train Epoch: 1890 [98560/118836 (83%)] Loss: 12368.316406\n",
      "    epoch          : 1890\n",
      "    loss           : 12236.45561285153\n",
      "    val_loss       : 12247.133332739071\n",
      "    val_log_likelihood: -12162.119018978754\n",
      "    val_log_marginal: -12170.49844533865\n",
      "Train Epoch: 1891 [256/118836 (0%)] Loss: 12325.265625\n",
      "Train Epoch: 1891 [33024/118836 (28%)] Loss: 12196.373047\n",
      "Train Epoch: 1891 [65792/118836 (55%)] Loss: 12168.490234\n",
      "Train Epoch: 1891 [98560/118836 (83%)] Loss: 12179.402344\n",
      "    epoch          : 1891\n",
      "    loss           : 12237.682618802988\n",
      "    val_loss       : 12235.964153947765\n",
      "    val_log_likelihood: -12164.39905445487\n",
      "    val_log_marginal: -12172.895298231371\n",
      "Train Epoch: 1892 [256/118836 (0%)] Loss: 12327.687500\n",
      "Train Epoch: 1892 [33024/118836 (28%)] Loss: 12278.799805\n",
      "Train Epoch: 1892 [65792/118836 (55%)] Loss: 12287.029297\n",
      "Train Epoch: 1892 [98560/118836 (83%)] Loss: 12264.884766\n",
      "    epoch          : 1892\n",
      "    loss           : 12240.73584460944\n",
      "    val_loss       : 12233.962701151275\n",
      "    val_log_likelihood: -12159.949341203992\n",
      "    val_log_marginal: -12168.27364401257\n",
      "Train Epoch: 1893 [256/118836 (0%)] Loss: 12233.445312\n",
      "Train Epoch: 1893 [33024/118836 (28%)] Loss: 12191.638672\n",
      "Train Epoch: 1893 [65792/118836 (55%)] Loss: 12238.179688\n",
      "Train Epoch: 1893 [98560/118836 (83%)] Loss: 12178.909180\n",
      "    epoch          : 1893\n",
      "    loss           : 12236.66044719939\n",
      "    val_loss       : 12235.51567243029\n",
      "    val_log_likelihood: -12163.439040529363\n",
      "    val_log_marginal: -12171.863118112826\n",
      "Train Epoch: 1894 [256/118836 (0%)] Loss: 12214.159180\n",
      "Train Epoch: 1894 [33024/118836 (28%)] Loss: 12273.044922\n",
      "Train Epoch: 1894 [65792/118836 (55%)] Loss: 12155.492188\n",
      "Train Epoch: 1894 [98560/118836 (83%)] Loss: 12217.329102\n",
      "    epoch          : 1894\n",
      "    loss           : 12236.23416773289\n",
      "    val_loss       : 12239.066383157526\n",
      "    val_log_likelihood: -12162.889300622932\n",
      "    val_log_marginal: -12171.403214338177\n",
      "Train Epoch: 1895 [256/118836 (0%)] Loss: 12284.231445\n",
      "Train Epoch: 1895 [33024/118836 (28%)] Loss: 12345.009766\n",
      "Train Epoch: 1895 [65792/118836 (55%)] Loss: 12179.103516\n",
      "Train Epoch: 1895 [98560/118836 (83%)] Loss: 12266.092773\n",
      "    epoch          : 1895\n",
      "    loss           : 12236.979568923181\n",
      "    val_loss       : 12236.495723538756\n",
      "    val_log_likelihood: -12159.748722148986\n",
      "    val_log_marginal: -12168.309309794713\n",
      "Train Epoch: 1896 [256/118836 (0%)] Loss: 12234.911133\n",
      "Train Epoch: 1896 [33024/118836 (28%)] Loss: 12282.416016\n",
      "Train Epoch: 1896 [65792/118836 (55%)] Loss: 12285.909180\n",
      "Train Epoch: 1896 [98560/118836 (83%)] Loss: 12252.229492\n",
      "    epoch          : 1896\n",
      "    loss           : 12233.658986959781\n",
      "    val_loss       : 12234.70285883883\n",
      "    val_log_likelihood: -12162.835985641543\n",
      "    val_log_marginal: -12171.272388176601\n",
      "Train Epoch: 1897 [256/118836 (0%)] Loss: 12385.371094\n",
      "Train Epoch: 1897 [33024/118836 (28%)] Loss: 12334.625000\n",
      "Train Epoch: 1897 [65792/118836 (55%)] Loss: 12195.601562\n",
      "Train Epoch: 1897 [98560/118836 (83%)] Loss: 12384.657227\n",
      "    epoch          : 1897\n",
      "    loss           : 12237.035114085762\n",
      "    val_loss       : 12239.082657004546\n",
      "    val_log_likelihood: -12159.561419884718\n",
      "    val_log_marginal: -12167.974475547237\n",
      "Train Epoch: 1898 [256/118836 (0%)] Loss: 12332.985352\n",
      "Train Epoch: 1898 [33024/118836 (28%)] Loss: 12306.537109\n",
      "Train Epoch: 1898 [65792/118836 (55%)] Loss: 12246.423828\n",
      "Train Epoch: 1898 [98560/118836 (83%)] Loss: 12281.607422\n",
      "    epoch          : 1898\n",
      "    loss           : 12235.736494035618\n",
      "    val_loss       : 12236.607800643735\n",
      "    val_log_likelihood: -12161.5884361753\n",
      "    val_log_marginal: -12170.117273311016\n",
      "Train Epoch: 1899 [256/118836 (0%)] Loss: 12280.982422\n",
      "Train Epoch: 1899 [33024/118836 (28%)] Loss: 12292.253906\n",
      "Train Epoch: 1899 [65792/118836 (55%)] Loss: 12394.485352\n",
      "Train Epoch: 1899 [98560/118836 (83%)] Loss: 12200.981445\n",
      "    epoch          : 1899\n",
      "    loss           : 12236.758418469552\n",
      "    val_loss       : 12244.358287379067\n",
      "    val_log_likelihood: -12161.922614085763\n",
      "    val_log_marginal: -12170.482564596114\n",
      "Train Epoch: 1900 [256/118836 (0%)] Loss: 12191.670898\n",
      "Train Epoch: 1900 [33024/118836 (28%)] Loss: 12360.628906\n",
      "Train Epoch: 1900 [65792/118836 (55%)] Loss: 12272.936523\n",
      "Train Epoch: 1900 [98560/118836 (83%)] Loss: 12160.543945\n",
      "    epoch          : 1900\n",
      "    loss           : 12241.04866108354\n",
      "    val_loss       : 12238.915539278587\n",
      "    val_log_likelihood: -12160.675801282052\n",
      "    val_log_marginal: -12169.229974000134\n",
      "Saving checkpoint: saved/models/SelfiesAutoencodingOperad/0905_154251/checkpoint-epoch1900.pth ...\n",
      "Train Epoch: 1901 [256/118836 (0%)] Loss: 12214.051758\n",
      "Train Epoch: 1901 [33024/118836 (28%)] Loss: 12237.972656\n",
      "Train Epoch: 1901 [65792/118836 (55%)] Loss: 12297.717773\n",
      "Train Epoch: 1901 [98560/118836 (83%)] Loss: 12260.605469\n",
      "    epoch          : 1901\n",
      "    loss           : 12237.460869003307\n",
      "    val_loss       : 12232.569343920592\n",
      "    val_log_likelihood: -12160.724550571236\n",
      "    val_log_marginal: -12169.001465694882\n",
      "Train Epoch: 1902 [256/118836 (0%)] Loss: 12217.738281\n",
      "Train Epoch: 1902 [33024/118836 (28%)] Loss: 12254.162109\n",
      "Train Epoch: 1902 [65792/118836 (55%)] Loss: 12249.106445\n",
      "Train Epoch: 1902 [98560/118836 (83%)] Loss: 12252.614258\n",
      "    epoch          : 1902\n",
      "    loss           : 12237.680539831474\n",
      "    val_loss       : 12235.859356853838\n",
      "    val_log_likelihood: -12160.773637174318\n",
      "    val_log_marginal: -12169.062757803043\n",
      "Train Epoch: 1903 [256/118836 (0%)] Loss: 12270.912109\n",
      "Train Epoch: 1903 [33024/118836 (28%)] Loss: 12293.368164\n",
      "Train Epoch: 1903 [65792/118836 (55%)] Loss: 12336.314453\n",
      "Train Epoch: 1903 [98560/118836 (83%)] Loss: 12200.879883\n",
      "    epoch          : 1903\n",
      "    loss           : 12233.240251822272\n",
      "    val_loss       : 12236.737070178675\n",
      "    val_log_likelihood: -12160.867745974203\n",
      "    val_log_marginal: -12169.32361005322\n",
      "Train Epoch: 1904 [256/118836 (0%)] Loss: 12342.711914\n",
      "Train Epoch: 1904 [33024/118836 (28%)] Loss: 12199.765625\n",
      "Train Epoch: 1904 [65792/118836 (55%)] Loss: 12203.624023\n",
      "Train Epoch: 1904 [98560/118836 (83%)] Loss: 12233.648438\n",
      "    epoch          : 1904\n",
      "    loss           : 12233.965045524452\n",
      "    val_loss       : 12236.310409334625\n",
      "    val_log_likelihood: -12155.692515120967\n",
      "    val_log_marginal: -12163.944756129373\n",
      "Train Epoch: 1905 [256/118836 (0%)] Loss: 12352.458984\n",
      "Train Epoch: 1905 [33024/118836 (28%)] Loss: 12422.068359\n",
      "Train Epoch: 1905 [65792/118836 (55%)] Loss: 12312.267578\n",
      "Train Epoch: 1905 [98560/118836 (83%)] Loss: 12157.106445\n",
      "    epoch          : 1905\n",
      "    loss           : 12231.87073672715\n",
      "    val_loss       : 12232.508466311432\n",
      "    val_log_likelihood: -12154.460539766853\n",
      "    val_log_marginal: -12162.804171312435\n",
      "Train Epoch: 1906 [256/118836 (0%)] Loss: 12344.182617\n",
      "Train Epoch: 1906 [33024/118836 (28%)] Loss: 12242.844727\n",
      "Train Epoch: 1906 [65792/118836 (55%)] Loss: 12360.287109\n",
      "Train Epoch: 1906 [98560/118836 (83%)] Loss: 12171.151367\n",
      "    epoch          : 1906\n",
      "    loss           : 12236.578758594396\n",
      "    val_loss       : 12237.3538127687\n",
      "    val_log_likelihood: -12155.600434243177\n",
      "    val_log_marginal: -12164.040323007635\n",
      "Train Epoch: 1907 [256/118836 (0%)] Loss: 12178.281250\n",
      "Train Epoch: 1907 [33024/118836 (28%)] Loss: 12243.242188\n",
      "Train Epoch: 1907 [65792/118836 (55%)] Loss: 12220.769531\n",
      "Train Epoch: 1907 [98560/118836 (83%)] Loss: 12272.187500\n",
      "    epoch          : 1907\n",
      "    loss           : 12232.765391400435\n",
      "    val_loss       : 12230.579817873853\n",
      "    val_log_likelihood: -12155.52978992194\n",
      "    val_log_marginal: -12163.865627179372\n",
      "Train Epoch: 1908 [256/118836 (0%)] Loss: 12358.109375\n",
      "Train Epoch: 1908 [33024/118836 (28%)] Loss: 12250.273438\n",
      "Train Epoch: 1908 [65792/118836 (55%)] Loss: 12336.730469\n",
      "Train Epoch: 1908 [98560/118836 (83%)] Loss: 12353.440430\n",
      "    epoch          : 1908\n",
      "    loss           : 12238.294024309864\n",
      "    val_loss       : 12237.394254206245\n",
      "    val_log_likelihood: -12155.47577155707\n",
      "    val_log_marginal: -12163.770655247152\n",
      "Train Epoch: 1909 [256/118836 (0%)] Loss: 12325.064453\n",
      "Train Epoch: 1909 [33024/118836 (28%)] Loss: 12299.705078\n",
      "Train Epoch: 1909 [65792/118836 (55%)] Loss: 12229.883789\n",
      "Train Epoch: 1909 [98560/118836 (83%)] Loss: 12327.421875\n",
      "    epoch          : 1909\n",
      "    loss           : 12237.852501583178\n",
      "    val_loss       : 12234.92916060533\n",
      "    val_log_likelihood: -12156.38576625827\n",
      "    val_log_marginal: -12164.76707804655\n",
      "Train Epoch: 1910 [256/118836 (0%)] Loss: 12316.392578\n",
      "Train Epoch: 1910 [33024/118836 (28%)] Loss: 12221.053711\n",
      "Train Epoch: 1910 [65792/118836 (55%)] Loss: 12219.256836\n",
      "Train Epoch: 1910 [98560/118836 (83%)] Loss: 12249.750000\n",
      "    epoch          : 1910\n",
      "    loss           : 12238.2716055366\n",
      "    val_loss       : 12234.771679147638\n",
      "    val_log_likelihood: -12155.317437577543\n",
      "    val_log_marginal: -12163.730192134577\n",
      "Train Epoch: 1911 [256/118836 (0%)] Loss: 12287.620117\n",
      "Train Epoch: 1911 [33024/118836 (28%)] Loss: 12221.763672\n",
      "Train Epoch: 1911 [65792/118836 (55%)] Loss: 12335.124023\n",
      "Train Epoch: 1911 [98560/118836 (83%)] Loss: 12273.423828\n",
      "    epoch          : 1911\n",
      "    loss           : 12233.327096580335\n",
      "    val_loss       : 12233.668269072277\n",
      "    val_log_likelihood: -12155.829410928454\n",
      "    val_log_marginal: -12164.100226418477\n",
      "Train Epoch: 1912 [256/118836 (0%)] Loss: 12286.496094\n",
      "Train Epoch: 1912 [33024/118836 (28%)] Loss: 12219.082031\n",
      "Train Epoch: 1912 [65792/118836 (55%)] Loss: 12275.975586\n",
      "Train Epoch: 1912 [98560/118836 (83%)] Loss: 12171.297852\n",
      "    epoch          : 1912\n",
      "    loss           : 12232.210790005945\n",
      "    val_loss       : 12233.20844382763\n",
      "    val_log_likelihood: -12152.20259027347\n",
      "    val_log_marginal: -12160.456085543578\n",
      "Train Epoch: 1913 [256/118836 (0%)] Loss: 12347.185547\n",
      "Train Epoch: 1913 [33024/118836 (28%)] Loss: 12319.423828\n",
      "Train Epoch: 1913 [65792/118836 (55%)] Loss: 12244.513672\n",
      "Train Epoch: 1913 [98560/118836 (83%)] Loss: 12283.218750\n",
      "    epoch          : 1913\n",
      "    loss           : 12235.153852777346\n",
      "    val_loss       : 12237.336480350174\n",
      "    val_log_likelihood: -12156.26724662686\n",
      "    val_log_marginal: -12164.681171531316\n",
      "Train Epoch: 1914 [256/118836 (0%)] Loss: 12249.005859\n",
      "Train Epoch: 1914 [33024/118836 (28%)] Loss: 12226.048828\n",
      "Train Epoch: 1914 [65792/118836 (55%)] Loss: 12240.240234\n",
      "Train Epoch: 1914 [98560/118836 (83%)] Loss: 12252.657227\n",
      "    epoch          : 1914\n",
      "    loss           : 12235.668486998553\n",
      "    val_loss       : 12236.111152253541\n",
      "    val_log_likelihood: -12154.672040102876\n",
      "    val_log_marginal: -12162.9630610574\n",
      "Train Epoch: 1915 [256/118836 (0%)] Loss: 12280.166992\n",
      "Train Epoch: 1915 [33024/118836 (28%)] Loss: 12233.415039\n",
      "Train Epoch: 1915 [65792/118836 (55%)] Loss: 12244.679688\n",
      "Train Epoch: 1915 [98560/118836 (83%)] Loss: 12235.360352\n",
      "    epoch          : 1915\n",
      "    loss           : 12234.64354531767\n",
      "    val_loss       : 12244.843899134934\n",
      "    val_log_likelihood: -12157.055463903536\n",
      "    val_log_marginal: -12165.46490686813\n",
      "Train Epoch: 1916 [256/118836 (0%)] Loss: 12259.122070\n",
      "Train Epoch: 1916 [33024/118836 (28%)] Loss: 12276.324219\n",
      "Train Epoch: 1916 [65792/118836 (55%)] Loss: 12184.640625\n",
      "Train Epoch: 1916 [98560/118836 (83%)] Loss: 12324.227539\n",
      "    epoch          : 1916\n",
      "    loss           : 12234.52153009331\n",
      "    val_loss       : 12234.01603845604\n",
      "    val_log_likelihood: -12153.758201671062\n",
      "    val_log_marginal: -12162.106869451722\n",
      "Train Epoch: 1917 [256/118836 (0%)] Loss: 12258.278320\n",
      "Train Epoch: 1917 [33024/118836 (28%)] Loss: 12228.685547\n",
      "Train Epoch: 1917 [65792/118836 (55%)] Loss: 12214.583984\n",
      "Train Epoch: 1917 [98560/118836 (83%)] Loss: 12169.232422\n",
      "    epoch          : 1917\n",
      "    loss           : 12233.629530474565\n",
      "    val_loss       : 12236.344818652773\n",
      "    val_log_likelihood: -12154.909318296372\n",
      "    val_log_marginal: -12163.324586439308\n",
      "Train Epoch: 1918 [256/118836 (0%)] Loss: 12309.850586\n",
      "Train Epoch: 1918 [33024/118836 (28%)] Loss: 12335.017578\n",
      "Train Epoch: 1918 [65792/118836 (55%)] Loss: 12258.209961\n",
      "Train Epoch: 1918 [98560/118836 (83%)] Loss: 12196.081055\n",
      "    epoch          : 1918\n",
      "    loss           : 12236.128579598324\n",
      "    val_loss       : 12228.771944587219\n",
      "    val_log_likelihood: -12155.532988426645\n",
      "    val_log_marginal: -12163.984749694137\n",
      "Train Epoch: 1919 [256/118836 (0%)] Loss: 12251.675781\n",
      "Train Epoch: 1919 [33024/118836 (28%)] Loss: 12196.530273\n",
      "Train Epoch: 1919 [65792/118836 (55%)] Loss: 12232.870117\n",
      "Train Epoch: 1919 [98560/118836 (83%)] Loss: 12250.336914\n",
      "    epoch          : 1919\n",
      "    loss           : 12232.433567740643\n",
      "    val_loss       : 12235.581866569528\n",
      "    val_log_likelihood: -12155.020278574753\n",
      "    val_log_marginal: -12163.51123771894\n",
      "Train Epoch: 1920 [256/118836 (0%)] Loss: 12324.375000\n",
      "Train Epoch: 1920 [33024/118836 (28%)] Loss: 12283.906250\n",
      "Train Epoch: 1920 [65792/118836 (55%)] Loss: 12190.202148\n",
      "Train Epoch: 1920 [98560/118836 (83%)] Loss: 12266.140625\n",
      "    epoch          : 1920\n",
      "    loss           : 12236.890464258942\n",
      "    val_loss       : 12235.843888642225\n",
      "    val_log_likelihood: -12158.405975205489\n",
      "    val_log_marginal: -12166.954408482457\n",
      "Train Epoch: 1921 [256/118836 (0%)] Loss: 12255.785156\n",
      "Train Epoch: 1921 [33024/118836 (28%)] Loss: 12187.142578\n",
      "Train Epoch: 1921 [65792/118836 (55%)] Loss: 12376.819336\n",
      "Train Epoch: 1921 [98560/118836 (83%)] Loss: 12250.220703\n",
      "    epoch          : 1921\n",
      "    loss           : 12232.167998151881\n",
      "    val_loss       : 12236.827480435652\n",
      "    val_log_likelihood: -12159.235521834937\n",
      "    val_log_marginal: -12167.696155774927\n",
      "Train Epoch: 1922 [256/118836 (0%)] Loss: 12224.250000\n",
      "Train Epoch: 1922 [33024/118836 (28%)] Loss: 12280.662109\n",
      "Train Epoch: 1922 [65792/118836 (55%)] Loss: 12291.061523\n",
      "Train Epoch: 1922 [98560/118836 (83%)] Loss: 12350.873047\n",
      "    epoch          : 1922\n",
      "    loss           : 12234.9501817424\n",
      "    val_loss       : 12236.585932109898\n",
      "    val_log_likelihood: -12155.370516536135\n",
      "    val_log_marginal: -12163.856484218426\n",
      "Train Epoch: 1923 [256/118836 (0%)] Loss: 12223.861328\n",
      "Train Epoch: 1923 [33024/118836 (28%)] Loss: 12271.095703\n",
      "Train Epoch: 1923 [65792/118836 (55%)] Loss: 12284.343750\n",
      "Train Epoch: 1923 [98560/118836 (83%)] Loss: 12250.414062\n",
      "    epoch          : 1923\n",
      "    loss           : 12235.539644398781\n",
      "    val_loss       : 12238.7252152921\n",
      "    val_log_likelihood: -12153.722966746796\n",
      "    val_log_marginal: -12162.114995805063\n",
      "Train Epoch: 1924 [256/118836 (0%)] Loss: 12243.686523\n",
      "Train Epoch: 1924 [33024/118836 (28%)] Loss: 12276.231445\n",
      "Train Epoch: 1924 [65792/118836 (55%)] Loss: 12220.855469\n",
      "Train Epoch: 1924 [98560/118836 (83%)] Loss: 12284.839844\n",
      "    epoch          : 1924\n",
      "    loss           : 12240.559046571288\n",
      "    val_loss       : 12239.273302586369\n",
      "    val_log_likelihood: -12157.165394469861\n",
      "    val_log_marginal: -12165.627562072423\n",
      "Train Epoch: 1925 [256/118836 (0%)] Loss: 12340.255859\n",
      "Train Epoch: 1925 [33024/118836 (28%)] Loss: 12206.184570\n",
      "Train Epoch: 1925 [65792/118836 (55%)] Loss: 12230.261719\n",
      "Train Epoch: 1925 [98560/118836 (83%)] Loss: 12235.348633\n",
      "    epoch          : 1925\n",
      "    loss           : 12237.905116573615\n",
      "    val_loss       : 12231.841738696343\n",
      "    val_log_likelihood: -12152.540894786496\n",
      "    val_log_marginal: -12160.989428288649\n",
      "Train Epoch: 1926 [256/118836 (0%)] Loss: 12250.238281\n",
      "Train Epoch: 1926 [33024/118836 (28%)] Loss: 12181.437500\n",
      "Train Epoch: 1926 [65792/118836 (55%)] Loss: 12225.737305\n",
      "Train Epoch: 1926 [98560/118836 (83%)] Loss: 12234.845703\n",
      "    epoch          : 1926\n",
      "    loss           : 12234.234543172302\n",
      "    val_loss       : 12239.38648540148\n",
      "    val_log_likelihood: -12155.781155817049\n",
      "    val_log_marginal: -12164.191816519153\n",
      "Train Epoch: 1927 [256/118836 (0%)] Loss: 12207.189453\n",
      "Train Epoch: 1927 [33024/118836 (28%)] Loss: 12194.201172\n",
      "Train Epoch: 1927 [65792/118836 (55%)] Loss: 12175.308594\n",
      "Train Epoch: 1927 [98560/118836 (83%)] Loss: 12191.331055\n",
      "    epoch          : 1927\n",
      "    loss           : 12234.794490216604\n",
      "    val_loss       : 12236.530754150028\n",
      "    val_log_likelihood: -12155.777658285515\n",
      "    val_log_marginal: -12164.136409650533\n",
      "Train Epoch: 1928 [256/118836 (0%)] Loss: 12310.003906\n",
      "Train Epoch: 1928 [33024/118836 (28%)] Loss: 12170.772461\n",
      "Train Epoch: 1928 [65792/118836 (55%)] Loss: 12262.896484\n",
      "Train Epoch: 1928 [98560/118836 (83%)] Loss: 12185.454102\n",
      "    epoch          : 1928\n",
      "    loss           : 12233.614962003723\n",
      "    val_loss       : 12233.713765400671\n",
      "    val_log_likelihood: -12155.225230853235\n",
      "    val_log_marginal: -12163.467281545123\n",
      "Train Epoch: 1929 [256/118836 (0%)] Loss: 12250.530273\n",
      "Train Epoch: 1929 [33024/118836 (28%)] Loss: 12196.818359\n",
      "Train Epoch: 1929 [65792/118836 (55%)] Loss: 12179.044922\n",
      "Train Epoch: 1929 [98560/118836 (83%)] Loss: 12242.576172\n",
      "    epoch          : 1929\n",
      "    loss           : 12235.6903082028\n",
      "    val_loss       : 12238.214478108763\n",
      "    val_log_likelihood: -12155.692787976892\n",
      "    val_log_marginal: -12164.03113252028\n",
      "Train Epoch: 1930 [256/118836 (0%)] Loss: 12286.043945\n",
      "Train Epoch: 1930 [33024/118836 (28%)] Loss: 12268.410156\n",
      "Train Epoch: 1930 [65792/118836 (55%)] Loss: 12177.099609\n",
      "Train Epoch: 1930 [98560/118836 (83%)] Loss: 12228.947266\n",
      "    epoch          : 1930\n",
      "    loss           : 12232.515255053248\n",
      "    val_loss       : 12233.511613986462\n",
      "    val_log_likelihood: -12158.640057479064\n",
      "    val_log_marginal: -12166.995977373605\n",
      "Train Epoch: 1931 [256/118836 (0%)] Loss: 12197.292969\n",
      "Train Epoch: 1931 [33024/118836 (28%)] Loss: 12169.589844\n",
      "Train Epoch: 1931 [65792/118836 (55%)] Loss: 12296.201172\n",
      "Train Epoch: 1931 [98560/118836 (83%)] Loss: 12166.973633\n",
      "    epoch          : 1931\n",
      "    loss           : 12238.146457073253\n",
      "    val_loss       : 12233.00519874121\n",
      "    val_log_likelihood: -12156.464156521402\n",
      "    val_log_marginal: -12164.9856424243\n",
      "Train Epoch: 1932 [256/118836 (0%)] Loss: 12274.049805\n",
      "Train Epoch: 1932 [33024/118836 (28%)] Loss: 12266.637695\n",
      "Train Epoch: 1932 [65792/118836 (55%)] Loss: 12220.916016\n",
      "Train Epoch: 1932 [98560/118836 (83%)] Loss: 12310.516602\n",
      "    epoch          : 1932\n",
      "    loss           : 12239.371178240022\n",
      "    val_loss       : 12243.01479104757\n",
      "    val_log_likelihood: -12165.007410405036\n",
      "    val_log_marginal: -12173.513201724452\n",
      "Train Epoch: 1933 [256/118836 (0%)] Loss: 12205.411133\n",
      "Train Epoch: 1933 [33024/118836 (28%)] Loss: 12162.682617\n",
      "Train Epoch: 1933 [65792/118836 (55%)] Loss: 12273.896484\n",
      "Train Epoch: 1933 [98560/118836 (83%)] Loss: 12292.892578\n",
      "    epoch          : 1933\n",
      "    loss           : 12235.441427412894\n",
      "    val_loss       : 12234.979285631181\n",
      "    val_log_likelihood: -12153.940229043888\n",
      "    val_log_marginal: -12162.347985467257\n",
      "Train Epoch: 1934 [256/118836 (0%)] Loss: 12199.384766\n",
      "Train Epoch: 1934 [33024/118836 (28%)] Loss: 12226.593750\n",
      "Train Epoch: 1934 [65792/118836 (55%)] Loss: 12189.796875\n",
      "Train Epoch: 1934 [98560/118836 (83%)] Loss: 12319.955078\n",
      "    epoch          : 1934\n",
      "    loss           : 12236.761682401519\n",
      "    val_loss       : 12235.1768718733\n",
      "    val_log_likelihood: -12153.587237644748\n",
      "    val_log_marginal: -12162.251443995063\n",
      "Train Epoch: 1935 [256/118836 (0%)] Loss: 12260.334961\n",
      "Train Epoch: 1935 [33024/118836 (28%)] Loss: 12245.935547\n",
      "Train Epoch: 1935 [65792/118836 (55%)] Loss: 12274.638672\n",
      "Train Epoch: 1935 [98560/118836 (83%)] Loss: 12238.980469\n",
      "    epoch          : 1935\n",
      "    loss           : 12238.10146023961\n",
      "    val_loss       : 12237.029125084327\n",
      "    val_log_likelihood: -12154.690089142628\n",
      "    val_log_marginal: -12163.191805440683\n",
      "Train Epoch: 1936 [256/118836 (0%)] Loss: 12273.415039\n",
      "Train Epoch: 1936 [33024/118836 (28%)] Loss: 12236.267578\n",
      "Train Epoch: 1936 [65792/118836 (55%)] Loss: 12215.243164\n",
      "Train Epoch: 1936 [98560/118836 (83%)] Loss: 12262.757812\n",
      "    epoch          : 1936\n",
      "    loss           : 12234.069102822581\n",
      "    val_loss       : 12236.647200721978\n",
      "    val_log_likelihood: -12156.901317107371\n",
      "    val_log_marginal: -12165.271195629293\n",
      "Train Epoch: 1937 [256/118836 (0%)] Loss: 12305.762695\n",
      "Train Epoch: 1937 [33024/118836 (28%)] Loss: 12231.140625\n",
      "Train Epoch: 1937 [65792/118836 (55%)] Loss: 12253.115234\n",
      "Train Epoch: 1937 [98560/118836 (83%)] Loss: 12244.481445\n",
      "    epoch          : 1937\n",
      "    loss           : 12233.194302335349\n",
      "    val_loss       : 12236.259086976317\n",
      "    val_log_likelihood: -12155.187252507236\n",
      "    val_log_marginal: -12163.685027789883\n",
      "Train Epoch: 1938 [256/118836 (0%)] Loss: 12205.381836\n",
      "Train Epoch: 1938 [33024/118836 (28%)] Loss: 12209.583984\n",
      "Train Epoch: 1938 [65792/118836 (55%)] Loss: 12313.199219\n",
      "Train Epoch: 1938 [98560/118836 (83%)] Loss: 12213.077148\n",
      "    epoch          : 1938\n",
      "    loss           : 12234.137070764838\n",
      "    val_loss       : 12234.004221953272\n",
      "    val_log_likelihood: -12153.052891400434\n",
      "    val_log_marginal: -12161.425727638554\n",
      "Train Epoch: 1939 [256/118836 (0%)] Loss: 12185.082031\n",
      "Train Epoch: 1939 [33024/118836 (28%)] Loss: 12233.733398\n",
      "Train Epoch: 1939 [65792/118836 (55%)] Loss: 12209.031250\n",
      "Train Epoch: 1939 [98560/118836 (83%)] Loss: 12179.552734\n",
      "    epoch          : 1939\n",
      "    loss           : 12233.381276978651\n",
      "    val_loss       : 12232.985138180824\n",
      "    val_log_likelihood: -12156.263777689464\n",
      "    val_log_marginal: -12164.753946167244\n",
      "Train Epoch: 1940 [256/118836 (0%)] Loss: 12245.757812\n",
      "Train Epoch: 1940 [33024/118836 (28%)] Loss: 12244.853516\n",
      "Train Epoch: 1940 [65792/118836 (55%)] Loss: 12232.140625\n",
      "Train Epoch: 1940 [98560/118836 (83%)] Loss: 12227.269531\n",
      "    epoch          : 1940\n",
      "    loss           : 12234.016584276778\n",
      "    val_loss       : 12235.201615945856\n",
      "    val_log_likelihood: -12154.107282296836\n",
      "    val_log_marginal: -12162.571931422224\n",
      "Train Epoch: 1941 [256/118836 (0%)] Loss: 12298.972656\n",
      "Train Epoch: 1941 [33024/118836 (28%)] Loss: 12348.025391\n",
      "Train Epoch: 1941 [65792/118836 (55%)] Loss: 12204.133789\n",
      "Train Epoch: 1941 [98560/118836 (83%)] Loss: 12257.458008\n",
      "    epoch          : 1941\n",
      "    loss           : 12235.427069601685\n",
      "    val_loss       : 12236.74932698116\n",
      "    val_log_likelihood: -12153.818306063897\n",
      "    val_log_marginal: -12162.192896387707\n",
      "Train Epoch: 1942 [256/118836 (0%)] Loss: 12392.616211\n",
      "Train Epoch: 1942 [33024/118836 (28%)] Loss: 12189.219727\n",
      "Train Epoch: 1942 [65792/118836 (55%)] Loss: 12298.800781\n",
      "Train Epoch: 1942 [98560/118836 (83%)] Loss: 12337.391602\n",
      "    epoch          : 1942\n",
      "    loss           : 12238.227262167855\n",
      "    val_loss       : 12235.217568918259\n",
      "    val_log_likelihood: -12157.535609717483\n",
      "    val_log_marginal: -12166.30355518208\n",
      "Train Epoch: 1943 [256/118836 (0%)] Loss: 12258.546875\n",
      "Train Epoch: 1943 [33024/118836 (28%)] Loss: 12323.917969\n",
      "Train Epoch: 1943 [65792/118836 (55%)] Loss: 12165.770508\n",
      "Train Epoch: 1943 [98560/118836 (83%)] Loss: 12194.210938\n",
      "    epoch          : 1943\n",
      "    loss           : 12235.198019088606\n",
      "    val_loss       : 12237.259028020637\n",
      "    val_log_likelihood: -12157.461663338763\n",
      "    val_log_marginal: -12165.997762730076\n",
      "Train Epoch: 1944 [256/118836 (0%)] Loss: 12258.463867\n",
      "Train Epoch: 1944 [33024/118836 (28%)] Loss: 12199.923828\n",
      "Train Epoch: 1944 [65792/118836 (55%)] Loss: 12372.074219\n",
      "Train Epoch: 1944 [98560/118836 (83%)] Loss: 12287.310547\n",
      "    epoch          : 1944\n",
      "    loss           : 12237.698372072737\n",
      "    val_loss       : 12231.648637204436\n",
      "    val_log_likelihood: -12151.256691189776\n",
      "    val_log_marginal: -12159.577107905889\n",
      "Train Epoch: 1945 [256/118836 (0%)] Loss: 12258.531250\n",
      "Train Epoch: 1945 [33024/118836 (28%)] Loss: 12184.726562\n",
      "Train Epoch: 1945 [65792/118836 (55%)] Loss: 12252.483398\n",
      "Train Epoch: 1945 [98560/118836 (83%)] Loss: 12342.177734\n",
      "    epoch          : 1945\n",
      "    loss           : 12233.402610143972\n",
      "    val_loss       : 12231.920349739075\n",
      "    val_log_likelihood: -12155.099646531224\n",
      "    val_log_marginal: -12163.558714023931\n",
      "Train Epoch: 1946 [256/118836 (0%)] Loss: 12311.679688\n",
      "Train Epoch: 1946 [33024/118836 (28%)] Loss: 12202.991211\n",
      "Train Epoch: 1946 [65792/118836 (55%)] Loss: 12340.477539\n",
      "Train Epoch: 1946 [98560/118836 (83%)] Loss: 12199.281250\n",
      "    epoch          : 1946\n",
      "    loss           : 12235.105480866161\n",
      "    val_loss       : 12239.02166409164\n",
      "    val_log_likelihood: -12156.70985576923\n",
      "    val_log_marginal: -12165.086054144313\n",
      "Train Epoch: 1947 [256/118836 (0%)] Loss: 12287.988281\n",
      "Train Epoch: 1947 [33024/118836 (28%)] Loss: 12215.231445\n",
      "Train Epoch: 1947 [65792/118836 (55%)] Loss: 12200.929688\n",
      "Train Epoch: 1947 [98560/118836 (83%)] Loss: 12189.025391\n",
      "    epoch          : 1947\n",
      "    loss           : 12235.441931768248\n",
      "    val_loss       : 12233.198479472438\n",
      "    val_log_likelihood: -12154.028027262975\n",
      "    val_log_marginal: -12162.464794827056\n",
      "Train Epoch: 1948 [256/118836 (0%)] Loss: 12214.054688\n",
      "Train Epoch: 1948 [33024/118836 (28%)] Loss: 12236.303711\n",
      "Train Epoch: 1948 [65792/118836 (55%)] Loss: 12320.291016\n",
      "Train Epoch: 1948 [98560/118836 (83%)] Loss: 12174.013672\n",
      "    epoch          : 1948\n",
      "    loss           : 12233.72071685665\n",
      "    val_loss       : 12232.985261230258\n",
      "    val_log_likelihood: -12156.741419658549\n",
      "    val_log_marginal: -12165.097604313898\n",
      "Train Epoch: 1949 [256/118836 (0%)] Loss: 12206.219727\n",
      "Train Epoch: 1949 [33024/118836 (28%)] Loss: 12188.860352\n",
      "Train Epoch: 1949 [65792/118836 (55%)] Loss: 12300.234375\n",
      "Train Epoch: 1949 [98560/118836 (83%)] Loss: 12302.144531\n",
      "    epoch          : 1949\n",
      "    loss           : 12235.14001483018\n",
      "    val_loss       : 12233.454964026016\n",
      "    val_log_likelihood: -12154.445702317256\n",
      "    val_log_marginal: -12162.74693766143\n",
      "Train Epoch: 1950 [256/118836 (0%)] Loss: 12336.928711\n",
      "Train Epoch: 1950 [33024/118836 (28%)] Loss: 12265.442383\n",
      "Train Epoch: 1950 [65792/118836 (55%)] Loss: 12159.176758\n",
      "Train Epoch: 1950 [98560/118836 (83%)] Loss: 12297.234375\n",
      "    epoch          : 1950\n",
      "    loss           : 12232.66387639578\n",
      "    val_loss       : 12235.653678323002\n",
      "    val_log_likelihood: -12152.835679829663\n",
      "    val_log_marginal: -12161.098738896739\n",
      "Train Epoch: 1951 [256/118836 (0%)] Loss: 12209.637695\n",
      "Train Epoch: 1951 [33024/118836 (28%)] Loss: 12273.870117\n",
      "Train Epoch: 1951 [65792/118836 (55%)] Loss: 12178.121094\n",
      "Train Epoch: 1951 [98560/118836 (83%)] Loss: 12216.428711\n",
      "    epoch          : 1951\n",
      "    loss           : 12235.66846163539\n",
      "    val_loss       : 12235.411276921663\n",
      "    val_log_likelihood: -12158.26018597498\n",
      "    val_log_marginal: -12166.710349872865\n",
      "Train Epoch: 1952 [256/118836 (0%)] Loss: 12253.598633\n",
      "Train Epoch: 1952 [33024/118836 (28%)] Loss: 12407.885742\n",
      "Train Epoch: 1952 [65792/118836 (55%)] Loss: 12208.365234\n",
      "Train Epoch: 1952 [98560/118836 (83%)] Loss: 12213.912109\n",
      "    epoch          : 1952\n",
      "    loss           : 12239.570426068807\n",
      "    val_loss       : 12237.193044793557\n",
      "    val_log_likelihood: -12153.690585582093\n",
      "    val_log_marginal: -12162.3628609486\n",
      "Train Epoch: 1953 [256/118836 (0%)] Loss: 12155.298828\n",
      "Train Epoch: 1953 [33024/118836 (28%)] Loss: 12278.798828\n",
      "Train Epoch: 1953 [65792/118836 (55%)] Loss: 12343.715820\n",
      "Train Epoch: 1953 [98560/118836 (83%)] Loss: 12222.395508\n",
      "    epoch          : 1953\n",
      "    loss           : 12236.784639940031\n",
      "    val_loss       : 12232.816053481876\n",
      "    val_log_likelihood: -12154.107199422302\n",
      "    val_log_marginal: -12162.42471858493\n",
      "Train Epoch: 1954 [256/118836 (0%)] Loss: 12256.350586\n",
      "Train Epoch: 1954 [33024/118836 (28%)] Loss: 12265.721680\n",
      "Train Epoch: 1954 [65792/118836 (55%)] Loss: 12443.355469\n",
      "Train Epoch: 1954 [98560/118836 (83%)] Loss: 12228.893555\n",
      "    epoch          : 1954\n",
      "    loss           : 12237.411012458642\n",
      "    val_loss       : 12235.859774889563\n",
      "    val_log_likelihood: -12152.54834186311\n",
      "    val_log_marginal: -12160.92191519021\n",
      "Train Epoch: 1955 [256/118836 (0%)] Loss: 12157.853516\n",
      "Train Epoch: 1955 [33024/118836 (28%)] Loss: 12110.794922\n",
      "Train Epoch: 1955 [65792/118836 (55%)] Loss: 12212.951172\n",
      "Train Epoch: 1955 [98560/118836 (83%)] Loss: 12239.563477\n",
      "    epoch          : 1955\n",
      "    loss           : 12232.030717696702\n",
      "    val_loss       : 12234.047058326274\n",
      "    val_log_likelihood: -12154.078911904207\n",
      "    val_log_marginal: -12162.432568199232\n",
      "Train Epoch: 1956 [256/118836 (0%)] Loss: 12273.255859\n",
      "Train Epoch: 1956 [33024/118836 (28%)] Loss: 12240.257812\n",
      "Train Epoch: 1956 [65792/118836 (55%)] Loss: 12226.728516\n",
      "Train Epoch: 1956 [98560/118836 (83%)] Loss: 12292.328125\n",
      "    epoch          : 1956\n",
      "    loss           : 12236.66570044329\n",
      "    val_loss       : 12235.698578276573\n",
      "    val_log_likelihood: -12155.94562493538\n",
      "    val_log_marginal: -12164.382731419393\n",
      "Train Epoch: 1957 [256/118836 (0%)] Loss: 12224.826172\n",
      "Train Epoch: 1957 [33024/118836 (28%)] Loss: 12234.347656\n",
      "Train Epoch: 1957 [65792/118836 (55%)] Loss: 12273.105469\n",
      "Train Epoch: 1957 [98560/118836 (83%)] Loss: 12205.660156\n",
      "    epoch          : 1957\n",
      "    loss           : 12234.961354295905\n",
      "    val_loss       : 12233.333637616364\n",
      "    val_log_likelihood: -12155.660883219602\n",
      "    val_log_marginal: -12164.191234544012\n",
      "Train Epoch: 1958 [256/118836 (0%)] Loss: 12292.119141\n",
      "Train Epoch: 1958 [33024/118836 (28%)] Loss: 12223.327148\n",
      "Train Epoch: 1958 [65792/118836 (55%)] Loss: 12354.285156\n",
      "Train Epoch: 1958 [98560/118836 (83%)] Loss: 12252.921875\n",
      "    epoch          : 1958\n",
      "    loss           : 12237.427308047714\n",
      "    val_loss       : 12237.309234052706\n",
      "    val_log_likelihood: -12155.59408828319\n",
      "    val_log_marginal: -12164.125240236805\n",
      "Train Epoch: 1959 [256/118836 (0%)] Loss: 12321.109375\n",
      "Train Epoch: 1959 [33024/118836 (28%)] Loss: 12207.272461\n",
      "Train Epoch: 1959 [65792/118836 (55%)] Loss: 12301.797852\n",
      "Train Epoch: 1959 [98560/118836 (83%)] Loss: 12288.213867\n",
      "    epoch          : 1959\n",
      "    loss           : 12238.907213961693\n",
      "    val_loss       : 12236.863442798858\n",
      "    val_log_likelihood: -12155.097241069583\n",
      "    val_log_marginal: -12163.63676129581\n",
      "Train Epoch: 1960 [256/118836 (0%)] Loss: 12321.792969\n",
      "Train Epoch: 1960 [33024/118836 (28%)] Loss: 12287.425781\n",
      "Train Epoch: 1960 [65792/118836 (55%)] Loss: 12307.974609\n",
      "Train Epoch: 1960 [98560/118836 (83%)] Loss: 12237.144531\n",
      "    epoch          : 1960\n",
      "    loss           : 12236.604744365179\n",
      "    val_loss       : 12233.40566964544\n",
      "    val_log_likelihood: -12155.666140340672\n",
      "    val_log_marginal: -12164.1143930539\n",
      "Train Epoch: 1961 [256/118836 (0%)] Loss: 12175.903320\n",
      "Train Epoch: 1961 [33024/118836 (28%)] Loss: 12297.451172\n",
      "Train Epoch: 1961 [65792/118836 (55%)] Loss: 12229.250000\n",
      "Train Epoch: 1961 [98560/118836 (83%)] Loss: 12233.340820\n",
      "    epoch          : 1961\n",
      "    loss           : 12236.594747563844\n",
      "    val_loss       : 12235.827819336218\n",
      "    val_log_likelihood: -12153.765232274865\n",
      "    val_log_marginal: -12162.13346129551\n",
      "Train Epoch: 1962 [256/118836 (0%)] Loss: 12275.873047\n",
      "Train Epoch: 1962 [33024/118836 (28%)] Loss: 12282.739258\n",
      "Train Epoch: 1962 [65792/118836 (55%)] Loss: 12248.599609\n",
      "Train Epoch: 1962 [98560/118836 (83%)] Loss: 12344.114258\n",
      "    epoch          : 1962\n",
      "    loss           : 12236.164511282568\n",
      "    val_loss       : 12235.71505532569\n",
      "    val_log_likelihood: -12153.347314897384\n",
      "    val_log_marginal: -12161.88465292811\n",
      "Train Epoch: 1963 [256/118836 (0%)] Loss: 12290.203125\n",
      "Train Epoch: 1963 [33024/118836 (28%)] Loss: 12285.165039\n",
      "Train Epoch: 1963 [65792/118836 (55%)] Loss: 12229.519531\n",
      "Train Epoch: 1963 [98560/118836 (83%)] Loss: 12286.011719\n",
      "    epoch          : 1963\n",
      "    loss           : 12237.381507670336\n",
      "    val_loss       : 12234.85950885143\n",
      "    val_log_likelihood: -12151.657677122106\n",
      "    val_log_marginal: -12159.987486692346\n",
      "Train Epoch: 1964 [256/118836 (0%)] Loss: 12278.807617\n",
      "Train Epoch: 1964 [33024/118836 (28%)] Loss: 12192.433594\n",
      "Train Epoch: 1964 [65792/118836 (55%)] Loss: 12207.749023\n",
      "Train Epoch: 1964 [98560/118836 (83%)] Loss: 12245.043945\n",
      "    epoch          : 1964\n",
      "    loss           : 12233.460608263544\n",
      "    val_loss       : 12237.88084608702\n",
      "    val_log_likelihood: -12154.472796959006\n",
      "    val_log_marginal: -12163.16668176079\n",
      "Train Epoch: 1965 [256/118836 (0%)] Loss: 12206.522461\n",
      "Train Epoch: 1965 [33024/118836 (28%)] Loss: 12306.304688\n",
      "Train Epoch: 1965 [65792/118836 (55%)] Loss: 12262.824219\n",
      "Train Epoch: 1965 [98560/118836 (83%)] Loss: 12314.314453\n",
      "    epoch          : 1965\n",
      "    loss           : 12234.393477305624\n",
      "    val_loss       : 12235.305697044021\n",
      "    val_log_likelihood: -12154.795226879136\n",
      "    val_log_marginal: -12163.295953878618\n",
      "Train Epoch: 1966 [256/118836 (0%)] Loss: 12308.605469\n",
      "Train Epoch: 1966 [33024/118836 (28%)] Loss: 12204.894531\n",
      "Train Epoch: 1966 [65792/118836 (55%)] Loss: 12341.314453\n",
      "Train Epoch: 1966 [98560/118836 (83%)] Loss: 12205.554688\n",
      "    epoch          : 1966\n",
      "    loss           : 12236.548422152864\n",
      "    val_loss       : 12234.899260683349\n",
      "    val_log_likelihood: -12153.523587094189\n",
      "    val_log_marginal: -12161.875039499882\n",
      "Train Epoch: 1967 [256/118836 (0%)] Loss: 12180.528320\n",
      "Train Epoch: 1967 [33024/118836 (28%)] Loss: 12299.912109\n",
      "Train Epoch: 1967 [65792/118836 (55%)] Loss: 12252.724609\n",
      "Train Epoch: 1967 [98560/118836 (83%)] Loss: 12217.433594\n",
      "    epoch          : 1967\n",
      "    loss           : 12233.972361261891\n",
      "    val_loss       : 12235.479414770976\n",
      "    val_log_likelihood: -12152.9764817256\n",
      "    val_log_marginal: -12161.314921568583\n",
      "Train Epoch: 1968 [256/118836 (0%)] Loss: 12284.623047\n",
      "Train Epoch: 1968 [33024/118836 (28%)] Loss: 12259.647461\n",
      "Train Epoch: 1968 [65792/118836 (55%)] Loss: 12199.345703\n",
      "Train Epoch: 1968 [98560/118836 (83%)] Loss: 12131.630859\n",
      "    epoch          : 1968\n",
      "    loss           : 12237.385196152554\n",
      "    val_loss       : 12237.719154737277\n",
      "    val_log_likelihood: -12154.279516742918\n",
      "    val_log_marginal: -12162.629201879055\n",
      "Train Epoch: 1969 [256/118836 (0%)] Loss: 12249.887695\n",
      "Train Epoch: 1969 [33024/118836 (28%)] Loss: 12269.278320\n",
      "Train Epoch: 1969 [65792/118836 (55%)] Loss: 12215.472656\n",
      "Train Epoch: 1969 [98560/118836 (83%)] Loss: 12260.842773\n",
      "    epoch          : 1969\n",
      "    loss           : 12234.850757340779\n",
      "    val_loss       : 12233.064164635329\n",
      "    val_log_likelihood: -12154.941414973635\n",
      "    val_log_marginal: -12163.205648402587\n",
      "Train Epoch: 1970 [256/118836 (0%)] Loss: 12206.972656\n",
      "Train Epoch: 1970 [33024/118836 (28%)] Loss: 12217.995117\n",
      "Train Epoch: 1970 [65792/118836 (55%)] Loss: 12213.324219\n",
      "Train Epoch: 1970 [98560/118836 (83%)] Loss: 12313.338867\n",
      "    epoch          : 1970\n",
      "    loss           : 12235.684579036135\n",
      "    val_loss       : 12235.846511474812\n",
      "    val_log_likelihood: -12156.468564865076\n",
      "    val_log_marginal: -12164.831259208771\n",
      "Train Epoch: 1971 [256/118836 (0%)] Loss: 12229.639648\n",
      "Train Epoch: 1971 [33024/118836 (28%)] Loss: 12409.005859\n",
      "Train Epoch: 1971 [65792/118836 (55%)] Loss: 12244.822266\n",
      "Train Epoch: 1971 [98560/118836 (83%)] Loss: 12273.988281\n",
      "    epoch          : 1971\n",
      "    loss           : 12234.51401678169\n",
      "    val_loss       : 12237.248276711347\n",
      "    val_log_likelihood: -12154.2558123643\n",
      "    val_log_marginal: -12162.646329963987\n",
      "Train Epoch: 1972 [256/118836 (0%)] Loss: 12173.458008\n",
      "Train Epoch: 1972 [33024/118836 (28%)] Loss: 12270.313477\n",
      "Train Epoch: 1972 [65792/118836 (55%)] Loss: 12265.693359\n",
      "Train Epoch: 1972 [98560/118836 (83%)] Loss: 12297.292969\n",
      "    epoch          : 1972\n",
      "    loss           : 12233.94210527166\n",
      "    val_loss       : 12231.986443330277\n",
      "    val_log_likelihood: -12152.795794400072\n",
      "    val_log_marginal: -12161.151175350446\n",
      "Train Epoch: 1973 [256/118836 (0%)] Loss: 12435.361328\n",
      "Train Epoch: 1973 [33024/118836 (28%)] Loss: 12310.103516\n",
      "Train Epoch: 1973 [65792/118836 (55%)] Loss: 12267.859375\n",
      "Train Epoch: 1973 [98560/118836 (83%)] Loss: 12234.563477\n",
      "    epoch          : 1973\n",
      "    loss           : 12233.240559411188\n",
      "    val_loss       : 12232.541182482422\n",
      "    val_log_likelihood: -12153.290496245605\n",
      "    val_log_marginal: -12161.682806082988\n",
      "Train Epoch: 1974 [256/118836 (0%)] Loss: 12252.603516\n",
      "Train Epoch: 1974 [33024/118836 (28%)] Loss: 12311.314453\n",
      "Train Epoch: 1974 [65792/118836 (55%)] Loss: 12212.062500\n",
      "Train Epoch: 1974 [98560/118836 (83%)] Loss: 12277.026367\n",
      "    epoch          : 1974\n",
      "    loss           : 12233.519625109853\n",
      "    val_loss       : 12232.217587690686\n",
      "    val_log_likelihood: -12154.56065204327\n",
      "    val_log_marginal: -12162.743587161078\n",
      "Train Epoch: 1975 [256/118836 (0%)] Loss: 12342.056641\n",
      "Train Epoch: 1975 [33024/118836 (28%)] Loss: 12330.485352\n",
      "Train Epoch: 1975 [65792/118836 (55%)] Loss: 12285.647461\n",
      "Train Epoch: 1975 [98560/118836 (83%)] Loss: 12236.498047\n",
      "    epoch          : 1975\n",
      "    loss           : 12233.669867433055\n",
      "    val_loss       : 12239.602128179788\n",
      "    val_log_likelihood: -12154.606482468724\n",
      "    val_log_marginal: -12162.918422125173\n",
      "Train Epoch: 1976 [256/118836 (0%)] Loss: 12267.675781\n",
      "Train Epoch: 1976 [33024/118836 (28%)] Loss: 12182.083984\n",
      "Train Epoch: 1976 [65792/118836 (55%)] Loss: 12277.938477\n",
      "Train Epoch: 1976 [98560/118836 (83%)] Loss: 12259.359375\n",
      "    epoch          : 1976\n",
      "    loss           : 12233.181241437913\n",
      "    val_loss       : 12236.997246651152\n",
      "    val_log_likelihood: -12164.034493738369\n",
      "    val_log_marginal: -12172.821140982163\n",
      "Train Epoch: 1977 [256/118836 (0%)] Loss: 12238.244141\n",
      "Train Epoch: 1977 [33024/118836 (28%)] Loss: 12335.692383\n",
      "Train Epoch: 1977 [65792/118836 (55%)] Loss: 12252.275391\n",
      "Train Epoch: 1977 [98560/118836 (83%)] Loss: 12317.397461\n",
      "    epoch          : 1977\n",
      "    loss           : 12233.156331097498\n",
      "    val_loss       : 12233.060833781024\n",
      "    val_log_likelihood: -12157.180587649918\n",
      "    val_log_marginal: -12165.701878586518\n",
      "Train Epoch: 1978 [256/118836 (0%)] Loss: 12310.621094\n",
      "Train Epoch: 1978 [33024/118836 (28%)] Loss: 12196.833984\n",
      "Train Epoch: 1978 [65792/118836 (55%)] Loss: 12285.386719\n",
      "Train Epoch: 1978 [98560/118836 (83%)] Loss: 12260.425781\n",
      "    epoch          : 1978\n",
      "    loss           : 12232.842734181142\n",
      "    val_loss       : 12237.179546878351\n",
      "    val_log_likelihood: -12153.984653671681\n",
      "    val_log_marginal: -12162.547140675582\n",
      "Train Epoch: 1979 [256/118836 (0%)] Loss: 12192.667969\n",
      "Train Epoch: 1979 [33024/118836 (28%)] Loss: 12225.685547\n",
      "Train Epoch: 1979 [65792/118836 (55%)] Loss: 12159.747070\n",
      "Train Epoch: 1979 [98560/118836 (83%)] Loss: 12174.880859\n",
      "    epoch          : 1979\n",
      "    loss           : 12230.31474682072\n",
      "    val_loss       : 12236.661623215059\n",
      "    val_log_likelihood: -12153.642480549524\n",
      "    val_log_marginal: -12162.008639586484\n",
      "Train Epoch: 1980 [256/118836 (0%)] Loss: 12177.252930\n",
      "Train Epoch: 1980 [33024/118836 (28%)] Loss: 12243.649414\n",
      "Train Epoch: 1980 [65792/118836 (55%)] Loss: 12274.495117\n",
      "Train Epoch: 1980 [98560/118836 (83%)] Loss: 12280.040039\n",
      "    epoch          : 1980\n",
      "    loss           : 12233.208862567204\n",
      "    val_loss       : 12239.130920572006\n",
      "    val_log_likelihood: -12157.290215958437\n",
      "    val_log_marginal: -12165.701464303118\n",
      "Train Epoch: 1981 [256/118836 (0%)] Loss: 12304.170898\n",
      "Train Epoch: 1981 [33024/118836 (28%)] Loss: 12325.372070\n",
      "Train Epoch: 1981 [65792/118836 (55%)] Loss: 12199.713867\n",
      "Train Epoch: 1981 [98560/118836 (83%)] Loss: 12277.413086\n",
      "    epoch          : 1981\n",
      "    loss           : 12238.493358728805\n",
      "    val_loss       : 12235.334629972145\n",
      "    val_log_likelihood: -12155.142111248966\n",
      "    val_log_marginal: -12163.578611785922\n",
      "Train Epoch: 1982 [256/118836 (0%)] Loss: 12257.432617\n",
      "Train Epoch: 1982 [33024/118836 (28%)] Loss: 12201.863281\n",
      "Train Epoch: 1982 [65792/118836 (55%)] Loss: 12256.471680\n",
      "Train Epoch: 1982 [98560/118836 (83%)] Loss: 12227.994141\n",
      "    epoch          : 1982\n",
      "    loss           : 12232.679734026055\n",
      "    val_loss       : 12235.621591352985\n",
      "    val_log_likelihood: -12154.23054564723\n",
      "    val_log_marginal: -12162.465295667367\n",
      "Train Epoch: 1983 [256/118836 (0%)] Loss: 12267.925781\n",
      "Train Epoch: 1983 [33024/118836 (28%)] Loss: 12192.549805\n",
      "Train Epoch: 1983 [65792/118836 (55%)] Loss: 12215.708008\n",
      "Train Epoch: 1983 [98560/118836 (83%)] Loss: 12335.486328\n",
      "    epoch          : 1983\n",
      "    loss           : 12232.346647054643\n",
      "    val_loss       : 12232.157997645183\n",
      "    val_log_likelihood: -12152.8567617866\n",
      "    val_log_marginal: -12161.230321233526\n",
      "Train Epoch: 1984 [256/118836 (0%)] Loss: 12331.681641\n",
      "Train Epoch: 1984 [33024/118836 (28%)] Loss: 12317.362305\n",
      "Train Epoch: 1984 [65792/118836 (55%)] Loss: 12331.288086\n",
      "Train Epoch: 1984 [98560/118836 (83%)] Loss: 12164.240234\n",
      "    epoch          : 1984\n",
      "    loss           : 12235.092306561466\n",
      "    val_loss       : 12229.719680879432\n",
      "    val_log_likelihood: -12154.782577769593\n",
      "    val_log_marginal: -12163.106350324666\n",
      "Train Epoch: 1985 [256/118836 (0%)] Loss: 12301.083984\n",
      "Train Epoch: 1985 [33024/118836 (28%)] Loss: 12296.369141\n",
      "Train Epoch: 1985 [65792/118836 (55%)] Loss: 12364.243164\n",
      "Train Epoch: 1985 [98560/118836 (83%)] Loss: 12266.779297\n",
      "    epoch          : 1985\n",
      "    loss           : 12233.057156288773\n",
      "    val_loss       : 12233.357526000022\n",
      "    val_log_likelihood: -12155.024705496537\n",
      "    val_log_marginal: -12163.344656622394\n",
      "Train Epoch: 1986 [256/118836 (0%)] Loss: 12311.674805\n",
      "Train Epoch: 1986 [33024/118836 (28%)] Loss: 12267.738281\n",
      "Train Epoch: 1986 [65792/118836 (55%)] Loss: 12202.715820\n",
      "Train Epoch: 1986 [98560/118836 (83%)] Loss: 12267.968750\n",
      "    epoch          : 1986\n",
      "    loss           : 12233.678947121847\n",
      "    val_loss       : 12234.748460325729\n",
      "    val_log_likelihood: -12152.354020465002\n",
      "    val_log_marginal: -12160.801695425194\n",
      "Train Epoch: 1987 [256/118836 (0%)] Loss: 12274.182617\n",
      "Train Epoch: 1987 [33024/118836 (28%)] Loss: 12222.677734\n",
      "Train Epoch: 1987 [65792/118836 (55%)] Loss: 12360.783203\n",
      "Train Epoch: 1987 [98560/118836 (83%)] Loss: 12213.787109\n",
      "    epoch          : 1987\n",
      "    loss           : 12233.058056277141\n",
      "    val_loss       : 12235.737342921766\n",
      "    val_log_likelihood: -12155.555297023624\n",
      "    val_log_marginal: -12163.88989636556\n",
      "Train Epoch: 1988 [256/118836 (0%)] Loss: 12217.888672\n",
      "Train Epoch: 1988 [33024/118836 (28%)] Loss: 12234.718750\n",
      "Train Epoch: 1988 [65792/118836 (55%)] Loss: 12327.943359\n",
      "Train Epoch: 1988 [98560/118836 (83%)] Loss: 12288.671875\n",
      "    epoch          : 1988\n",
      "    loss           : 12232.330964220171\n",
      "    val_loss       : 12237.67176591393\n",
      "    val_log_likelihood: -12152.646127190601\n",
      "    val_log_marginal: -12160.960982470398\n",
      "Train Epoch: 1989 [256/118836 (0%)] Loss: 12263.607422\n",
      "Train Epoch: 1989 [33024/118836 (28%)] Loss: 12301.308594\n",
      "Train Epoch: 1989 [65792/118836 (55%)] Loss: 12165.861328\n",
      "Train Epoch: 1989 [98560/118836 (83%)] Loss: 12210.584961\n",
      "    epoch          : 1989\n",
      "    loss           : 12232.499893862438\n",
      "    val_loss       : 12234.67097163196\n",
      "    val_log_likelihood: -12155.040659894541\n",
      "    val_log_marginal: -12163.228302581634\n",
      "Train Epoch: 1990 [256/118836 (0%)] Loss: 12265.399414\n",
      "Train Epoch: 1990 [33024/118836 (28%)] Loss: 12221.417969\n",
      "Train Epoch: 1990 [65792/118836 (55%)] Loss: 12313.059570\n",
      "Train Epoch: 1990 [98560/118836 (83%)] Loss: 12286.314453\n",
      "    epoch          : 1990\n",
      "    loss           : 12235.118942081524\n",
      "    val_loss       : 12232.63643630707\n",
      "    val_log_likelihood: -12155.662858799888\n",
      "    val_log_marginal: -12163.810298782799\n",
      "Train Epoch: 1991 [256/118836 (0%)] Loss: 12297.370117\n",
      "Train Epoch: 1991 [33024/118836 (28%)] Loss: 12272.742188\n",
      "Train Epoch: 1991 [65792/118836 (55%)] Loss: 12292.389648\n",
      "Train Epoch: 1991 [98560/118836 (83%)] Loss: 12272.688477\n",
      "    epoch          : 1991\n",
      "    loss           : 12235.54439797224\n",
      "    val_loss       : 12239.878905922213\n",
      "    val_log_likelihood: -12156.475969292804\n",
      "    val_log_marginal: -12164.8272007255\n",
      "Train Epoch: 1992 [256/118836 (0%)] Loss: 12311.478516\n",
      "Train Epoch: 1992 [33024/118836 (28%)] Loss: 12202.251953\n",
      "Train Epoch: 1992 [65792/118836 (55%)] Loss: 12277.947266\n",
      "Train Epoch: 1992 [98560/118836 (83%)] Loss: 12226.300781\n",
      "    epoch          : 1992\n",
      "    loss           : 12232.097259163047\n",
      "    val_loss       : 12231.691238521176\n",
      "    val_log_likelihood: -12153.444025763803\n",
      "    val_log_marginal: -12161.748140591406\n",
      "Train Epoch: 1993 [256/118836 (0%)] Loss: 12201.143555\n",
      "Train Epoch: 1993 [33024/118836 (28%)] Loss: 12161.423828\n",
      "Train Epoch: 1993 [65792/118836 (55%)] Loss: 12287.453125\n",
      "Train Epoch: 1993 [98560/118836 (83%)] Loss: 12270.099609\n",
      "    epoch          : 1993\n",
      "    loss           : 12238.41305782801\n",
      "    val_loss       : 12233.060626461644\n",
      "    val_log_likelihood: -12155.083380020937\n",
      "    val_log_marginal: -12163.46668404298\n",
      "Train Epoch: 1994 [256/118836 (0%)] Loss: 12224.931641\n",
      "Train Epoch: 1994 [33024/118836 (28%)] Loss: 12209.679688\n",
      "Train Epoch: 1994 [65792/118836 (55%)] Loss: 12182.696289\n",
      "Train Epoch: 1994 [98560/118836 (83%)] Loss: 12175.471680\n",
      "    epoch          : 1994\n",
      "    loss           : 12238.265050209367\n",
      "    val_loss       : 12235.0216996116\n",
      "    val_log_likelihood: -12154.235419251447\n",
      "    val_log_marginal: -12162.687370858173\n",
      "Train Epoch: 1995 [256/118836 (0%)] Loss: 12204.106445\n",
      "Train Epoch: 1995 [33024/118836 (28%)] Loss: 12218.237305\n",
      "Train Epoch: 1995 [65792/118836 (55%)] Loss: 12256.499023\n",
      "Train Epoch: 1995 [98560/118836 (83%)] Loss: 12225.093750\n",
      "    epoch          : 1995\n",
      "    loss           : 12230.637587882547\n",
      "    val_loss       : 12236.652767826316\n",
      "    val_log_likelihood: -12167.172207144333\n",
      "    val_log_marginal: -12175.50208767704\n",
      "Train Epoch: 1996 [256/118836 (0%)] Loss: 12224.870117\n",
      "Train Epoch: 1996 [33024/118836 (28%)] Loss: 12291.423828\n",
      "Train Epoch: 1996 [65792/118836 (55%)] Loss: 12242.064453\n",
      "Train Epoch: 1996 [98560/118836 (83%)] Loss: 12166.519531\n",
      "    epoch          : 1996\n",
      "    loss           : 12236.596037369467\n",
      "    val_loss       : 12240.00123129123\n",
      "    val_log_likelihood: -12156.00451383504\n",
      "    val_log_marginal: -12164.556916363355\n",
      "Train Epoch: 1997 [256/118836 (0%)] Loss: 12220.075195\n",
      "Train Epoch: 1997 [33024/118836 (28%)] Loss: 12251.874023\n",
      "Train Epoch: 1997 [65792/118836 (55%)] Loss: 12286.480469\n",
      "Train Epoch: 1997 [98560/118836 (83%)] Loss: 12203.494141\n",
      "    epoch          : 1997\n",
      "    loss           : 12234.44086328448\n",
      "    val_loss       : 12238.030639382705\n",
      "    val_log_likelihood: -12155.378731938845\n",
      "    val_log_marginal: -12163.679224911042\n",
      "Train Epoch: 1998 [256/118836 (0%)] Loss: 12281.372070\n",
      "Train Epoch: 1998 [33024/118836 (28%)] Loss: 12209.679688\n",
      "Train Epoch: 1998 [65792/118836 (55%)] Loss: 12237.248047\n",
      "Train Epoch: 1998 [98560/118836 (83%)] Loss: 12257.726562\n",
      "    epoch          : 1998\n",
      "    loss           : 12238.442040167494\n",
      "    val_loss       : 12245.97122655947\n",
      "    val_log_likelihood: -12158.984128314982\n",
      "    val_log_marginal: -12167.37814937383\n",
      "Train Epoch: 1999 [256/118836 (0%)] Loss: 12321.706055\n",
      "Train Epoch: 1999 [33024/118836 (28%)] Loss: 12337.092773\n",
      "Train Epoch: 1999 [65792/118836 (55%)] Loss: 12221.347656\n",
      "Train Epoch: 1999 [98560/118836 (83%)] Loss: 12283.501953\n",
      "    epoch          : 1999\n",
      "    loss           : 12236.988155565032\n",
      "    val_loss       : 12237.644146188797\n",
      "    val_log_likelihood: -12161.133577433571\n",
      "    val_log_marginal: -12169.536951089776\n",
      "Train Epoch: 2000 [256/118836 (0%)] Loss: 12253.518555\n",
      "Train Epoch: 2000 [33024/118836 (28%)] Loss: 12317.614258\n",
      "Train Epoch: 2000 [65792/118836 (55%)] Loss: 12280.936523\n",
      "Train Epoch: 2000 [98560/118836 (83%)] Loss: 12281.795898\n",
      "    epoch          : 2000\n",
      "    loss           : 12235.938862017938\n",
      "    val_loss       : 12231.787482244821\n",
      "    val_log_likelihood: -12154.273872389373\n",
      "    val_log_marginal: -12162.678493559602\n",
      "Saving checkpoint: saved/models/SelfiesAutoencodingOperad/0905_154251/checkpoint-epoch2000.pth ...\n",
      "Train Epoch: 2001 [256/118836 (0%)] Loss: 12163.231445\n",
      "Train Epoch: 2001 [33024/118836 (28%)] Loss: 12262.273438\n",
      "Train Epoch: 2001 [65792/118836 (55%)] Loss: 12308.126953\n",
      "Train Epoch: 2001 [98560/118836 (83%)] Loss: 12280.958008\n",
      "    epoch          : 2001\n",
      "    loss           : 12235.620831717844\n",
      "    val_loss       : 12236.90884447609\n",
      "    val_log_likelihood: -12153.845502158292\n",
      "    val_log_marginal: -12162.21357394638\n",
      "Train Epoch: 2002 [256/118836 (0%)] Loss: 12351.353516\n",
      "Train Epoch: 2002 [33024/118836 (28%)] Loss: 12280.895508\n",
      "Train Epoch: 2002 [65792/118836 (55%)] Loss: 12249.010742\n",
      "Train Epoch: 2002 [98560/118836 (83%)] Loss: 12312.691406\n",
      "    epoch          : 2002\n",
      "    loss           : 12234.640709166926\n",
      "    val_loss       : 12233.314754373705\n",
      "    val_log_likelihood: -12153.646581627378\n",
      "    val_log_marginal: -12161.937744128545\n",
      "Train Epoch: 2003 [256/118836 (0%)] Loss: 12205.933594\n",
      "Train Epoch: 2003 [33024/118836 (28%)] Loss: 12419.851562\n",
      "Train Epoch: 2003 [65792/118836 (55%)] Loss: 12267.020508\n",
      "Train Epoch: 2003 [98560/118836 (83%)] Loss: 12198.427734\n",
      "    epoch          : 2003\n",
      "    loss           : 12235.318144999741\n",
      "    val_loss       : 12231.23908107441\n",
      "    val_log_likelihood: -12152.252505137252\n",
      "    val_log_marginal: -12160.730401025172\n",
      "Train Epoch: 2004 [256/118836 (0%)] Loss: 12261.330078\n",
      "Train Epoch: 2004 [33024/118836 (28%)] Loss: 12291.662109\n",
      "Train Epoch: 2004 [65792/118836 (55%)] Loss: 12221.045898\n",
      "Train Epoch: 2004 [98560/118836 (83%)] Loss: 12306.080078\n",
      "    epoch          : 2004\n",
      "    loss           : 12231.32880786678\n",
      "    val_loss       : 12233.05722994046\n",
      "    val_log_likelihood: -12152.989594964847\n",
      "    val_log_marginal: -12161.387068859449\n",
      "Train Epoch: 2005 [256/118836 (0%)] Loss: 12286.373047\n",
      "Train Epoch: 2005 [33024/118836 (28%)] Loss: 12332.326172\n",
      "Train Epoch: 2005 [65792/118836 (55%)] Loss: 12313.592773\n",
      "Train Epoch: 2005 [98560/118836 (83%)] Loss: 12259.472656\n",
      "    epoch          : 2005\n",
      "    loss           : 12232.242893629807\n",
      "    val_loss       : 12234.949811377095\n",
      "    val_log_likelihood: -12154.229151642628\n",
      "    val_log_marginal: -12162.712971166244\n",
      "Train Epoch: 2006 [256/118836 (0%)] Loss: 12301.363281\n",
      "Train Epoch: 2006 [33024/118836 (28%)] Loss: 12245.702148\n",
      "Train Epoch: 2006 [65792/118836 (55%)] Loss: 12294.469727\n",
      "Train Epoch: 2006 [98560/118836 (83%)] Loss: 12238.089844\n",
      "    epoch          : 2006\n",
      "    loss           : 12232.323466094138\n",
      "    val_loss       : 12228.598265140508\n",
      "    val_log_likelihood: -12150.412063172043\n",
      "    val_log_marginal: -12158.764856292406\n",
      "Train Epoch: 2007 [256/118836 (0%)] Loss: 12185.819336\n",
      "Train Epoch: 2007 [33024/118836 (28%)] Loss: 12296.233398\n",
      "Train Epoch: 2007 [65792/118836 (55%)] Loss: 12231.589844\n",
      "Train Epoch: 2007 [98560/118836 (83%)] Loss: 12330.104492\n",
      "    epoch          : 2007\n",
      "    loss           : 12236.194694091191\n",
      "    val_loss       : 12233.370774097657\n",
      "    val_log_likelihood: -12152.797085659637\n",
      "    val_log_marginal: -12161.183604772265\n",
      "Train Epoch: 2008 [256/118836 (0%)] Loss: 12301.361328\n",
      "Train Epoch: 2008 [33024/118836 (28%)] Loss: 12245.837891\n",
      "Train Epoch: 2008 [65792/118836 (55%)] Loss: 12264.819336\n",
      "Train Epoch: 2008 [98560/118836 (83%)] Loss: 12235.140625\n",
      "    epoch          : 2008\n",
      "    loss           : 12232.98401539237\n",
      "    val_loss       : 12239.469436702677\n",
      "    val_log_likelihood: -12154.483002966035\n",
      "    val_log_marginal: -12163.113998276829\n",
      "Train Epoch: 2009 [256/118836 (0%)] Loss: 12333.313477\n",
      "Train Epoch: 2009 [33024/118836 (28%)] Loss: 12339.670898\n",
      "Train Epoch: 2009 [65792/118836 (55%)] Loss: 12252.325195\n",
      "Train Epoch: 2009 [98560/118836 (83%)] Loss: 12301.728516\n",
      "    epoch          : 2009\n",
      "    loss           : 12233.32350486585\n",
      "    val_loss       : 12235.260266822908\n",
      "    val_log_likelihood: -12153.795248365126\n",
      "    val_log_marginal: -12162.412107727365\n",
      "Train Epoch: 2010 [256/118836 (0%)] Loss: 12177.241211\n",
      "Train Epoch: 2010 [33024/118836 (28%)] Loss: 12279.082031\n",
      "Train Epoch: 2010 [65792/118836 (55%)] Loss: 12352.966797\n",
      "Train Epoch: 2010 [98560/118836 (83%)] Loss: 12227.891602\n",
      "    epoch          : 2010\n",
      "    loss           : 12234.417796862075\n",
      "    val_loss       : 12230.934573328495\n",
      "    val_log_likelihood: -12153.840850683675\n",
      "    val_log_marginal: -12162.3473108065\n",
      "Train Epoch: 2011 [256/118836 (0%)] Loss: 12212.514648\n",
      "Train Epoch: 2011 [33024/118836 (28%)] Loss: 12343.664062\n",
      "Train Epoch: 2011 [65792/118836 (55%)] Loss: 12364.149414\n",
      "Train Epoch: 2011 [98560/118836 (83%)] Loss: 12229.635742\n",
      "    epoch          : 2011\n",
      "    loss           : 12234.067752920802\n",
      "    val_loss       : 12231.881390060436\n",
      "    val_log_likelihood: -12153.32020474695\n",
      "    val_log_marginal: -12161.888282590013\n",
      "Train Epoch: 2012 [256/118836 (0%)] Loss: 12413.587891\n",
      "Train Epoch: 2012 [33024/118836 (28%)] Loss: 12247.187500\n",
      "Train Epoch: 2012 [65792/118836 (55%)] Loss: 12190.438477\n",
      "Train Epoch: 2012 [98560/118836 (83%)] Loss: 12225.875977\n",
      "    epoch          : 2012\n",
      "    loss           : 12231.311100664288\n",
      "    val_loss       : 12233.093778023445\n",
      "    val_log_likelihood: -12152.946789056039\n",
      "    val_log_marginal: -12161.356894671235\n",
      "Train Epoch: 2013 [256/118836 (0%)] Loss: 12212.482422\n",
      "Train Epoch: 2013 [33024/118836 (28%)] Loss: 12328.103516\n",
      "Train Epoch: 2013 [65792/118836 (55%)] Loss: 12224.145508\n",
      "Train Epoch: 2013 [98560/118836 (83%)] Loss: 12278.367188\n",
      "    epoch          : 2013\n",
      "    loss           : 12232.38405594112\n",
      "    val_loss       : 12232.409490754451\n",
      "    val_log_likelihood: -12154.105538054435\n",
      "    val_log_marginal: -12162.490514656749\n",
      "Train Epoch: 2014 [256/118836 (0%)] Loss: 12186.361328\n",
      "Train Epoch: 2014 [33024/118836 (28%)] Loss: 12195.783203\n",
      "Train Epoch: 2014 [65792/118836 (55%)] Loss: 12276.865234\n",
      "Train Epoch: 2014 [98560/118836 (83%)] Loss: 12199.914062\n",
      "    epoch          : 2014\n",
      "    loss           : 12233.52797411342\n",
      "    val_loss       : 12236.957194562881\n",
      "    val_log_likelihood: -12152.831175526004\n",
      "    val_log_marginal: -12161.376080461963\n",
      "Train Epoch: 2015 [256/118836 (0%)] Loss: 12209.991211\n",
      "Train Epoch: 2015 [33024/118836 (28%)] Loss: 12198.263672\n",
      "Train Epoch: 2015 [65792/118836 (55%)] Loss: 12231.552734\n",
      "Train Epoch: 2015 [98560/118836 (83%)] Loss: 12262.381836\n",
      "    epoch          : 2015\n",
      "    loss           : 12235.18899804203\n",
      "    val_loss       : 12236.372024411203\n",
      "    val_log_likelihood: -12158.411976097239\n",
      "    val_log_marginal: -12166.815325275393\n",
      "Train Epoch: 2016 [256/118836 (0%)] Loss: 12329.284180\n",
      "Train Epoch: 2016 [33024/118836 (28%)] Loss: 12185.355469\n",
      "Train Epoch: 2016 [65792/118836 (55%)] Loss: 12190.692383\n",
      "Train Epoch: 2016 [98560/118836 (83%)] Loss: 12284.919922\n",
      "    epoch          : 2016\n",
      "    loss           : 12231.802889784945\n",
      "    val_loss       : 12230.249868629031\n",
      "    val_log_likelihood: -12151.047844939\n",
      "    val_log_marginal: -12159.373531913814\n",
      "Train Epoch: 2017 [256/118836 (0%)] Loss: 12178.812500\n",
      "Train Epoch: 2017 [33024/118836 (28%)] Loss: 12244.293945\n",
      "Train Epoch: 2017 [65792/118836 (55%)] Loss: 12246.168945\n",
      "Train Epoch: 2017 [98560/118836 (83%)] Loss: 12309.366211\n",
      "    epoch          : 2017\n",
      "    loss           : 12237.501831317204\n",
      "    val_loss       : 12234.087262915373\n",
      "    val_log_likelihood: -12153.45570428815\n",
      "    val_log_marginal: -12162.086947465737\n",
      "Train Epoch: 2018 [256/118836 (0%)] Loss: 12270.063477\n",
      "Train Epoch: 2018 [33024/118836 (28%)] Loss: 12249.275391\n",
      "Train Epoch: 2018 [65792/118836 (55%)] Loss: 12210.923828\n",
      "Train Epoch: 2018 [98560/118836 (83%)] Loss: 12271.628906\n",
      "    epoch          : 2018\n",
      "    loss           : 12233.29766594293\n",
      "    val_loss       : 12231.812821826865\n",
      "    val_log_likelihood: -12154.092802839381\n",
      "    val_log_marginal: -12162.670517048507\n",
      "Train Epoch: 2019 [256/118836 (0%)] Loss: 12277.109375\n",
      "Train Epoch: 2019 [33024/118836 (28%)] Loss: 12220.710938\n",
      "Train Epoch: 2019 [65792/118836 (55%)] Loss: 12319.570312\n",
      "Train Epoch: 2019 [98560/118836 (83%)] Loss: 12183.748047\n",
      "    epoch          : 2019\n",
      "    loss           : 12232.258901338917\n",
      "    val_loss       : 12236.172464485\n",
      "    val_log_likelihood: -12156.987892725134\n",
      "    val_log_marginal: -12165.483311187374\n",
      "Train Epoch: 2020 [256/118836 (0%)] Loss: 12290.666992\n",
      "Train Epoch: 2020 [33024/118836 (28%)] Loss: 12332.776367\n",
      "Train Epoch: 2020 [65792/118836 (55%)] Loss: 12323.240234\n",
      "Train Epoch: 2020 [98560/118836 (83%)] Loss: 12295.511719\n",
      "    epoch          : 2020\n",
      "    loss           : 12236.498838302576\n",
      "    val_loss       : 12229.403862751984\n",
      "    val_log_likelihood: -12153.62331488446\n",
      "    val_log_marginal: -12162.188741198885\n",
      "Train Epoch: 2021 [256/118836 (0%)] Loss: 12229.292969\n",
      "Train Epoch: 2021 [33024/118836 (28%)] Loss: 12240.113281\n",
      "Train Epoch: 2021 [65792/118836 (55%)] Loss: 12245.956055\n",
      "Train Epoch: 2021 [98560/118836 (83%)] Loss: 12253.791992\n",
      "    epoch          : 2021\n",
      "    loss           : 12234.466526280758\n",
      "    val_loss       : 12232.24081707557\n",
      "    val_log_likelihood: -12153.825223260443\n",
      "    val_log_marginal: -12162.503957068344\n",
      "Train Epoch: 2022 [256/118836 (0%)] Loss: 12210.470703\n",
      "Train Epoch: 2022 [33024/118836 (28%)] Loss: 12244.443359\n",
      "Train Epoch: 2022 [65792/118836 (55%)] Loss: 12327.750977\n",
      "Train Epoch: 2022 [98560/118836 (83%)] Loss: 12281.528320\n",
      "    epoch          : 2022\n",
      "    loss           : 12228.479354547922\n",
      "    val_loss       : 12230.837115163355\n",
      "    val_log_likelihood: -12153.295541253101\n",
      "    val_log_marginal: -12161.727839680505\n",
      "Train Epoch: 2023 [256/118836 (0%)] Loss: 12279.239258\n",
      "Train Epoch: 2023 [33024/118836 (28%)] Loss: 12216.625000\n",
      "Train Epoch: 2023 [65792/118836 (55%)] Loss: 12324.538086\n",
      "Train Epoch: 2023 [98560/118836 (83%)] Loss: 12248.705078\n",
      "    epoch          : 2023\n",
      "    loss           : 12233.916004155035\n",
      "    val_loss       : 12230.771383770922\n",
      "    val_log_likelihood: -12156.371462565912\n",
      "    val_log_marginal: -12164.834354961991\n",
      "Train Epoch: 2024 [256/118836 (0%)] Loss: 12248.377930\n",
      "Train Epoch: 2024 [33024/118836 (28%)] Loss: 12233.943359\n",
      "Train Epoch: 2024 [65792/118836 (55%)] Loss: 12280.319336\n",
      "Train Epoch: 2024 [98560/118836 (83%)] Loss: 12193.069336\n",
      "    epoch          : 2024\n",
      "    loss           : 12230.082744487956\n",
      "    val_loss       : 12236.265286638018\n",
      "    val_log_likelihood: -12153.370999567049\n",
      "    val_log_marginal: -12161.813817263826\n",
      "Train Epoch: 2025 [256/118836 (0%)] Loss: 12153.447266\n",
      "Train Epoch: 2025 [33024/118836 (28%)] Loss: 12216.156250\n",
      "Train Epoch: 2025 [65792/118836 (55%)] Loss: 12203.324219\n",
      "Train Epoch: 2025 [98560/118836 (83%)] Loss: 12226.328125\n",
      "    epoch          : 2025\n",
      "    loss           : 12236.987814858612\n",
      "    val_loss       : 12235.09541904972\n",
      "    val_log_likelihood: -12155.657783421215\n",
      "    val_log_marginal: -12164.101393409843\n",
      "Train Epoch: 2026 [256/118836 (0%)] Loss: 12408.115234\n",
      "Train Epoch: 2026 [33024/118836 (28%)] Loss: 12215.950195\n",
      "Train Epoch: 2026 [65792/118836 (55%)] Loss: 12378.735352\n",
      "Train Epoch: 2026 [98560/118836 (83%)] Loss: 12218.370117\n",
      "    epoch          : 2026\n",
      "    loss           : 12235.939177522747\n",
      "    val_loss       : 12230.252997547606\n",
      "    val_log_likelihood: -12153.837123591295\n",
      "    val_log_marginal: -12162.121714860396\n",
      "Train Epoch: 2027 [256/118836 (0%)] Loss: 12191.195312\n",
      "Train Epoch: 2027 [33024/118836 (28%)] Loss: 12223.542969\n",
      "Train Epoch: 2027 [65792/118836 (55%)] Loss: 12325.087891\n",
      "Train Epoch: 2027 [98560/118836 (83%)] Loss: 12319.120117\n",
      "    epoch          : 2027\n",
      "    loss           : 12232.846551740851\n",
      "    val_loss       : 12230.236437448715\n",
      "    val_log_likelihood: -12152.440385423128\n",
      "    val_log_marginal: -12160.958532339146\n",
      "Train Epoch: 2028 [256/118836 (0%)] Loss: 12268.281250\n",
      "Train Epoch: 2028 [33024/118836 (28%)] Loss: 12336.757812\n",
      "Train Epoch: 2028 [65792/118836 (55%)] Loss: 12299.944336\n",
      "Train Epoch: 2028 [98560/118836 (83%)] Loss: 12213.392578\n",
      "    epoch          : 2028\n",
      "    loss           : 12234.759673219087\n",
      "    val_loss       : 12232.397010992445\n",
      "    val_log_likelihood: -12150.465159739453\n",
      "    val_log_marginal: -12158.896169419584\n",
      "Train Epoch: 2029 [256/118836 (0%)] Loss: 12297.966797\n",
      "Train Epoch: 2029 [33024/118836 (28%)] Loss: 12141.921875\n",
      "Train Epoch: 2029 [65792/118836 (55%)] Loss: 12236.987305\n",
      "Train Epoch: 2029 [98560/118836 (83%)] Loss: 12261.101562\n",
      "    epoch          : 2029\n",
      "    loss           : 12232.685862702905\n",
      "    val_loss       : 12239.469827324152\n",
      "    val_log_likelihood: -12156.62252571857\n",
      "    val_log_marginal: -12165.285788341505\n",
      "Train Epoch: 2030 [256/118836 (0%)] Loss: 12322.491211\n",
      "Train Epoch: 2030 [33024/118836 (28%)] Loss: 12215.613281\n",
      "Train Epoch: 2030 [65792/118836 (55%)] Loss: 12207.710938\n",
      "Train Epoch: 2030 [98560/118836 (83%)] Loss: 12253.359375\n",
      "    epoch          : 2030\n",
      "    loss           : 12229.8396888247\n",
      "    val_loss       : 12231.530030158332\n",
      "    val_log_likelihood: -12152.384526371226\n",
      "    val_log_marginal: -12160.776363033247\n",
      "Train Epoch: 2031 [256/118836 (0%)] Loss: 12218.186523\n",
      "Train Epoch: 2031 [33024/118836 (28%)] Loss: 12287.269531\n",
      "Train Epoch: 2031 [65792/118836 (55%)] Loss: 12325.610352\n",
      "Train Epoch: 2031 [98560/118836 (83%)] Loss: 12298.522461\n",
      "    epoch          : 2031\n",
      "    loss           : 12236.245214924525\n",
      "    val_loss       : 12241.739353332458\n",
      "    val_log_likelihood: -12153.012437480615\n",
      "    val_log_marginal: -12161.55520047248\n",
      "Train Epoch: 2032 [256/118836 (0%)] Loss: 12279.835938\n",
      "Train Epoch: 2032 [33024/118836 (28%)] Loss: 12300.352539\n",
      "Train Epoch: 2032 [65792/118836 (55%)] Loss: 12317.203125\n",
      "Train Epoch: 2032 [98560/118836 (83%)] Loss: 12244.103516\n",
      "    epoch          : 2032\n",
      "    loss           : 12234.225869778742\n",
      "    val_loss       : 12235.352584380733\n",
      "    val_log_likelihood: -12157.478132108146\n",
      "    val_log_marginal: -12166.062791456392\n",
      "Train Epoch: 2033 [256/118836 (0%)] Loss: 12200.400391\n",
      "Train Epoch: 2033 [33024/118836 (28%)] Loss: 12189.018555\n",
      "Train Epoch: 2033 [65792/118836 (55%)] Loss: 12153.354492\n",
      "Train Epoch: 2033 [98560/118836 (83%)] Loss: 12246.595703\n",
      "    epoch          : 2033\n",
      "    loss           : 12234.434194711537\n",
      "    val_loss       : 12233.320834377564\n",
      "    val_log_likelihood: -12155.491788312913\n",
      "    val_log_marginal: -12163.87958071608\n",
      "Train Epoch: 2034 [256/118836 (0%)] Loss: 12187.095703\n",
      "Train Epoch: 2034 [33024/118836 (28%)] Loss: 12247.412109\n",
      "Train Epoch: 2034 [65792/118836 (55%)] Loss: 12216.418945\n",
      "Train Epoch: 2034 [98560/118836 (83%)] Loss: 12293.179688\n",
      "    epoch          : 2034\n",
      "    loss           : 12230.135364486403\n",
      "    val_loss       : 12236.584854571627\n",
      "    val_log_likelihood: -12152.49639406922\n",
      "    val_log_marginal: -12161.051135309812\n",
      "Train Epoch: 2035 [256/118836 (0%)] Loss: 12179.960938\n",
      "Train Epoch: 2035 [33024/118836 (28%)] Loss: 12162.910156\n",
      "Train Epoch: 2035 [65792/118836 (55%)] Loss: 12375.366211\n",
      "Train Epoch: 2035 [98560/118836 (83%)] Loss: 12231.847656\n",
      "    epoch          : 2035\n",
      "    loss           : 12233.852182847393\n",
      "    val_loss       : 12238.167385959367\n",
      "    val_log_likelihood: -12154.024199364145\n",
      "    val_log_marginal: -12162.87059677987\n",
      "Train Epoch: 2036 [256/118836 (0%)] Loss: 12238.652344\n",
      "Train Epoch: 2036 [33024/118836 (28%)] Loss: 12240.451172\n",
      "Train Epoch: 2036 [65792/118836 (55%)] Loss: 12261.409180\n",
      "Train Epoch: 2036 [98560/118836 (83%)] Loss: 12194.991211\n",
      "    epoch          : 2036\n",
      "    loss           : 12238.46504713994\n",
      "    val_loss       : 12250.702387062443\n",
      "    val_log_likelihood: -12156.365518862438\n",
      "    val_log_marginal: -12165.105706569755\n",
      "Train Epoch: 2037 [256/118836 (0%)] Loss: 12218.433594\n",
      "Train Epoch: 2037 [33024/118836 (28%)] Loss: 12270.277344\n",
      "Train Epoch: 2037 [65792/118836 (55%)] Loss: 12223.077148\n",
      "Train Epoch: 2037 [98560/118836 (83%)] Loss: 12367.145508\n",
      "    epoch          : 2037\n",
      "    loss           : 12235.676784144955\n",
      "    val_loss       : 12234.80027937114\n",
      "    val_log_likelihood: -12152.27997699545\n",
      "    val_log_marginal: -12160.790191335731\n",
      "Train Epoch: 2038 [256/118836 (0%)] Loss: 12234.123047\n",
      "Train Epoch: 2038 [33024/118836 (28%)] Loss: 12232.429688\n",
      "Train Epoch: 2038 [65792/118836 (55%)] Loss: 12243.234375\n",
      "Train Epoch: 2038 [98560/118836 (83%)] Loss: 12233.035156\n",
      "    epoch          : 2038\n",
      "    loss           : 12233.925653787997\n",
      "    val_loss       : 12232.25146352094\n",
      "    val_log_likelihood: -12155.309049317617\n",
      "    val_log_marginal: -12163.974978432041\n",
      "Train Epoch: 2039 [256/118836 (0%)] Loss: 12202.673828\n",
      "Train Epoch: 2039 [33024/118836 (28%)] Loss: 12445.307617\n",
      "Train Epoch: 2039 [65792/118836 (55%)] Loss: 12179.494141\n",
      "Train Epoch: 2039 [98560/118836 (83%)] Loss: 12231.763672\n",
      "    epoch          : 2039\n",
      "    loss           : 12235.428847284687\n",
      "    val_loss       : 12239.35930074293\n",
      "    val_log_likelihood: -12155.71397623294\n",
      "    val_log_marginal: -12164.186486096987\n",
      "Train Epoch: 2040 [256/118836 (0%)] Loss: 12308.949219\n",
      "Train Epoch: 2040 [33024/118836 (28%)] Loss: 12144.138672\n",
      "Train Epoch: 2040 [65792/118836 (55%)] Loss: 12316.828125\n",
      "Train Epoch: 2040 [98560/118836 (83%)] Loss: 12256.389648\n",
      "    epoch          : 2040\n",
      "    loss           : 12231.880920278898\n",
      "    val_loss       : 12234.133387694792\n",
      "    val_log_likelihood: -12151.799656062603\n",
      "    val_log_marginal: -12160.3147285063\n",
      "Train Epoch: 2041 [256/118836 (0%)] Loss: 12222.539062\n",
      "Train Epoch: 2041 [33024/118836 (28%)] Loss: 12218.217773\n",
      "Train Epoch: 2041 [65792/118836 (55%)] Loss: 12186.013672\n",
      "Train Epoch: 2041 [98560/118836 (83%)] Loss: 12201.323242\n",
      "    epoch          : 2041\n",
      "    loss           : 12229.119019624948\n",
      "    val_loss       : 12234.108260460034\n",
      "    val_log_likelihood: -12155.078957299422\n",
      "    val_log_marginal: -12163.66429801426\n",
      "Train Epoch: 2042 [256/118836 (0%)] Loss: 12190.416016\n",
      "Train Epoch: 2042 [33024/118836 (28%)] Loss: 12258.462891\n",
      "Train Epoch: 2042 [65792/118836 (55%)] Loss: 12274.397461\n",
      "Train Epoch: 2042 [98560/118836 (83%)] Loss: 12182.591797\n",
      "    epoch          : 2042\n",
      "    loss           : 12229.353398663668\n",
      "    val_loss       : 12233.162901128328\n",
      "    val_log_likelihood: -12154.233509906173\n",
      "    val_log_marginal: -12162.675154188591\n",
      "Train Epoch: 2043 [256/118836 (0%)] Loss: 12256.296875\n",
      "Train Epoch: 2043 [33024/118836 (28%)] Loss: 12231.454102\n",
      "Train Epoch: 2043 [65792/118836 (55%)] Loss: 12348.939453\n",
      "Train Epoch: 2043 [98560/118836 (83%)] Loss: 12194.299805\n",
      "    epoch          : 2043\n",
      "    loss           : 12232.457246756101\n",
      "    val_loss       : 12232.082090241578\n",
      "    val_log_likelihood: -12152.475687228598\n",
      "    val_log_marginal: -12160.914108036326\n",
      "Train Epoch: 2044 [256/118836 (0%)] Loss: 12331.083008\n",
      "Train Epoch: 2044 [33024/118836 (28%)] Loss: 12297.101562\n",
      "Train Epoch: 2044 [65792/118836 (55%)] Loss: 12285.083984\n",
      "Train Epoch: 2044 [98560/118836 (83%)] Loss: 12259.658203\n",
      "    epoch          : 2044\n",
      "    loss           : 12231.004562945875\n",
      "    val_loss       : 12234.661145702541\n",
      "    val_log_likelihood: -12151.907277611921\n",
      "    val_log_marginal: -12160.231463840979\n",
      "Train Epoch: 2045 [256/118836 (0%)] Loss: 12244.799805\n",
      "Train Epoch: 2045 [33024/118836 (28%)] Loss: 12236.369141\n",
      "Train Epoch: 2045 [65792/118836 (55%)] Loss: 12231.871094\n",
      "Train Epoch: 2045 [98560/118836 (83%)] Loss: 12184.995117\n",
      "    epoch          : 2045\n",
      "    loss           : 12233.083762730044\n",
      "    val_loss       : 12235.710436283634\n",
      "    val_log_likelihood: -12154.283739951665\n",
      "    val_log_marginal: -12162.71324290198\n",
      "Train Epoch: 2046 [256/118836 (0%)] Loss: 12280.480469\n",
      "Train Epoch: 2046 [33024/118836 (28%)] Loss: 12239.953125\n",
      "Train Epoch: 2046 [65792/118836 (55%)] Loss: 12369.314453\n",
      "Train Epoch: 2046 [98560/118836 (83%)] Loss: 12290.701172\n",
      "    epoch          : 2046\n",
      "    loss           : 12233.49066667959\n",
      "    val_loss       : 12230.58091001956\n",
      "    val_log_likelihood: -12151.202393345482\n",
      "    val_log_marginal: -12159.567568575372\n",
      "Train Epoch: 2047 [256/118836 (0%)] Loss: 12322.791992\n",
      "Train Epoch: 2047 [33024/118836 (28%)] Loss: 12254.467773\n",
      "Train Epoch: 2047 [65792/118836 (55%)] Loss: 12251.711914\n",
      "Train Epoch: 2047 [98560/118836 (83%)] Loss: 12212.535156\n",
      "    epoch          : 2047\n",
      "    loss           : 12235.258568871484\n",
      "    val_loss       : 12232.831168360748\n",
      "    val_log_likelihood: -12154.180162776573\n",
      "    val_log_marginal: -12162.45661159669\n",
      "Train Epoch: 2048 [256/118836 (0%)] Loss: 12139.716797\n",
      "Train Epoch: 2048 [33024/118836 (28%)] Loss: 12231.242188\n",
      "Train Epoch: 2048 [65792/118836 (55%)] Loss: 12183.023438\n",
      "Train Epoch: 2048 [98560/118836 (83%)] Loss: 12216.387695\n",
      "    epoch          : 2048\n",
      "    loss           : 12232.08894004601\n",
      "    val_loss       : 12230.889995800928\n",
      "    val_log_likelihood: -12153.202616121278\n",
      "    val_log_marginal: -12161.624127171066\n",
      "Train Epoch: 2049 [256/118836 (0%)] Loss: 12201.914062\n",
      "Train Epoch: 2049 [33024/118836 (28%)] Loss: 12162.359375\n",
      "Train Epoch: 2049 [65792/118836 (55%)] Loss: 12165.133789\n",
      "Train Epoch: 2049 [98560/118836 (83%)] Loss: 12220.494141\n",
      "    epoch          : 2049\n",
      "    loss           : 12233.380403322737\n",
      "    val_loss       : 12232.62686391064\n",
      "    val_log_likelihood: -12153.731201212262\n",
      "    val_log_marginal: -12162.090720362114\n",
      "Train Epoch: 2050 [256/118836 (0%)] Loss: 12233.579102\n",
      "Train Epoch: 2050 [33024/118836 (28%)] Loss: 12324.772461\n",
      "Train Epoch: 2050 [65792/118836 (55%)] Loss: 12266.582031\n",
      "Train Epoch: 2050 [98560/118836 (83%)] Loss: 12211.671875\n",
      "    epoch          : 2050\n",
      "    loss           : 12234.439711441531\n",
      "    val_loss       : 12232.393576584089\n",
      "    val_log_likelihood: -12155.614631797975\n",
      "    val_log_marginal: -12163.99468614179\n",
      "Train Epoch: 2051 [256/118836 (0%)] Loss: 12276.895508\n",
      "Train Epoch: 2051 [33024/118836 (28%)] Loss: 12304.564453\n",
      "Train Epoch: 2051 [65792/118836 (55%)] Loss: 12265.408203\n",
      "Train Epoch: 2051 [98560/118836 (83%)] Loss: 12236.654297\n",
      "    epoch          : 2051\n",
      "    loss           : 12234.26137255092\n",
      "    val_loss       : 12236.052151100777\n",
      "    val_log_likelihood: -12153.074950889166\n",
      "    val_log_marginal: -12161.581268932885\n",
      "Train Epoch: 2052 [256/118836 (0%)] Loss: 12236.673828\n",
      "Train Epoch: 2052 [33024/118836 (28%)] Loss: 12269.503906\n",
      "Train Epoch: 2052 [65792/118836 (55%)] Loss: 12292.868164\n",
      "Train Epoch: 2052 [98560/118836 (83%)] Loss: 12276.567383\n",
      "    epoch          : 2052\n",
      "    loss           : 12229.770482610887\n",
      "    val_loss       : 12230.814108765075\n",
      "    val_log_likelihood: -12151.76669606855\n",
      "    val_log_marginal: -12160.360126875987\n",
      "Train Epoch: 2053 [256/118836 (0%)] Loss: 12367.625000\n",
      "Train Epoch: 2053 [33024/118836 (28%)] Loss: 12243.017578\n",
      "Train Epoch: 2053 [65792/118836 (55%)] Loss: 12313.916992\n",
      "Train Epoch: 2053 [98560/118836 (83%)] Loss: 12263.912109\n",
      "    epoch          : 2053\n",
      "    loss           : 12232.920219447891\n",
      "    val_loss       : 12233.639014175322\n",
      "    val_log_likelihood: -12151.263165904156\n",
      "    val_log_marginal: -12159.62837530364\n",
      "Train Epoch: 2054 [256/118836 (0%)] Loss: 12211.230469\n",
      "Train Epoch: 2054 [33024/118836 (28%)] Loss: 12176.777344\n",
      "Train Epoch: 2054 [65792/118836 (55%)] Loss: 12216.597656\n",
      "Train Epoch: 2054 [98560/118836 (83%)] Loss: 12201.006836\n",
      "    epoch          : 2054\n",
      "    loss           : 12230.467833372106\n",
      "    val_loss       : 12234.347853224446\n",
      "    val_log_likelihood: -12153.41881607346\n",
      "    val_log_marginal: -12161.8272154761\n",
      "Train Epoch: 2055 [256/118836 (0%)] Loss: 12236.177734\n",
      "Train Epoch: 2055 [33024/118836 (28%)] Loss: 12216.974609\n",
      "Train Epoch: 2055 [65792/118836 (55%)] Loss: 12291.160156\n",
      "Train Epoch: 2055 [98560/118836 (83%)] Loss: 12339.068359\n",
      "    epoch          : 2055\n",
      "    loss           : 12243.082155481026\n",
      "    val_loss       : 12232.743856975449\n",
      "    val_log_likelihood: -12152.042882159843\n",
      "    val_log_marginal: -12160.719243676976\n",
      "Train Epoch: 2056 [256/118836 (0%)] Loss: 12277.734375\n",
      "Train Epoch: 2056 [33024/118836 (28%)] Loss: 12152.227539\n",
      "Train Epoch: 2056 [65792/118836 (55%)] Loss: 12299.772461\n",
      "Train Epoch: 2056 [98560/118836 (83%)] Loss: 12336.885742\n",
      "    epoch          : 2056\n",
      "    loss           : 12232.600833268714\n",
      "    val_loss       : 12233.122456203966\n",
      "    val_log_likelihood: -12154.074021175817\n",
      "    val_log_marginal: -12162.662731283584\n",
      "Train Epoch: 2057 [256/118836 (0%)] Loss: 12251.621094\n",
      "Train Epoch: 2057 [33024/118836 (28%)] Loss: 12206.406250\n",
      "Train Epoch: 2057 [65792/118836 (55%)] Loss: 12205.210938\n",
      "Train Epoch: 2057 [98560/118836 (83%)] Loss: 12189.714844\n",
      "    epoch          : 2057\n",
      "    loss           : 12236.800233276468\n",
      "    val_loss       : 12235.790838302948\n",
      "    val_log_likelihood: -12152.656226252326\n",
      "    val_log_marginal: -12161.072504772892\n",
      "Train Epoch: 2058 [256/118836 (0%)] Loss: 12348.817383\n",
      "Train Epoch: 2058 [33024/118836 (28%)] Loss: 12323.925781\n",
      "Train Epoch: 2058 [65792/118836 (55%)] Loss: 12249.039062\n",
      "Train Epoch: 2058 [98560/118836 (83%)] Loss: 12219.113281\n",
      "    epoch          : 2058\n",
      "    loss           : 12233.772796797455\n",
      "    val_loss       : 12230.962149067394\n",
      "    val_log_likelihood: -12151.058873552523\n",
      "    val_log_marginal: -12159.486868564652\n",
      "Train Epoch: 2059 [256/118836 (0%)] Loss: 12190.872070\n",
      "Train Epoch: 2059 [33024/118836 (28%)] Loss: 12280.498047\n",
      "Train Epoch: 2059 [65792/118836 (55%)] Loss: 12405.042969\n",
      "Train Epoch: 2059 [98560/118836 (83%)] Loss: 12249.705078\n",
      "    epoch          : 2059\n",
      "    loss           : 12230.049483205386\n",
      "    val_loss       : 12231.575455383485\n",
      "    val_log_likelihood: -12155.342285237024\n",
      "    val_log_marginal: -12163.978978656345\n",
      "Train Epoch: 2060 [256/118836 (0%)] Loss: 12200.138672\n",
      "Train Epoch: 2060 [33024/118836 (28%)] Loss: 12210.148438\n",
      "Train Epoch: 2060 [65792/118836 (55%)] Loss: 12237.595703\n",
      "Train Epoch: 2060 [98560/118836 (83%)] Loss: 12261.777344\n",
      "    epoch          : 2060\n",
      "    loss           : 12232.780211079664\n",
      "    val_loss       : 12232.318887509186\n",
      "    val_log_likelihood: -12154.824814865075\n",
      "    val_log_marginal: -12163.230585644733\n",
      "Train Epoch: 2061 [256/118836 (0%)] Loss: 12236.907227\n",
      "Train Epoch: 2061 [33024/118836 (28%)] Loss: 12237.600586\n",
      "Train Epoch: 2061 [65792/118836 (55%)] Loss: 12191.025391\n",
      "Train Epoch: 2061 [98560/118836 (83%)] Loss: 12197.927734\n",
      "    epoch          : 2061\n",
      "    loss           : 12229.644859032516\n",
      "    val_loss       : 12235.250766769936\n",
      "    val_log_likelihood: -12152.690730329818\n",
      "    val_log_marginal: -12161.03291165659\n",
      "Train Epoch: 2062 [256/118836 (0%)] Loss: 12259.453125\n",
      "Train Epoch: 2062 [33024/118836 (28%)] Loss: 12281.070312\n",
      "Train Epoch: 2062 [65792/118836 (55%)] Loss: 12244.875977\n",
      "Train Epoch: 2062 [98560/118836 (83%)] Loss: 12229.758789\n",
      "    epoch          : 2062\n",
      "    loss           : 12231.014990113214\n",
      "    val_loss       : 12238.24344657568\n",
      "    val_log_likelihood: -12151.070572916668\n",
      "    val_log_marginal: -12159.432496543814\n",
      "Train Epoch: 2063 [256/118836 (0%)] Loss: 12249.445312\n",
      "Train Epoch: 2063 [33024/118836 (28%)] Loss: 12395.980469\n",
      "Train Epoch: 2063 [65792/118836 (55%)] Loss: 12273.235352\n",
      "Train Epoch: 2063 [98560/118836 (83%)] Loss: 12247.234375\n",
      "    epoch          : 2063\n",
      "    loss           : 12227.342719964847\n",
      "    val_loss       : 12233.321576362609\n",
      "    val_log_likelihood: -12151.474131675197\n",
      "    val_log_marginal: -12159.86696420473\n",
      "Train Epoch: 2064 [256/118836 (0%)] Loss: 12200.884766\n",
      "Train Epoch: 2064 [33024/118836 (28%)] Loss: 12334.343750\n",
      "Train Epoch: 2064 [65792/118836 (55%)] Loss: 12257.932617\n",
      "Train Epoch: 2064 [98560/118836 (83%)] Loss: 12204.697266\n",
      "    epoch          : 2064\n",
      "    loss           : 12235.063660566584\n",
      "    val_loss       : 12234.04724657412\n",
      "    val_log_likelihood: -12152.323797592277\n",
      "    val_log_marginal: -12160.762357089516\n",
      "Train Epoch: 2065 [256/118836 (0%)] Loss: 12210.081055\n",
      "Train Epoch: 2065 [33024/118836 (28%)] Loss: 12220.975586\n",
      "Train Epoch: 2065 [65792/118836 (55%)] Loss: 12297.182617\n",
      "Train Epoch: 2065 [98560/118836 (83%)] Loss: 12277.709961\n",
      "    epoch          : 2065\n",
      "    loss           : 12235.49121626861\n",
      "    val_loss       : 12233.235272032412\n",
      "    val_log_likelihood: -12156.697183235112\n",
      "    val_log_marginal: -12165.070643794474\n",
      "Train Epoch: 2066 [256/118836 (0%)] Loss: 12351.359375\n",
      "Train Epoch: 2066 [33024/118836 (28%)] Loss: 12151.841797\n",
      "Train Epoch: 2066 [65792/118836 (55%)] Loss: 12325.356445\n",
      "Train Epoch: 2066 [98560/118836 (83%)] Loss: 12263.153320\n",
      "    epoch          : 2066\n",
      "    loss           : 12234.99663655397\n",
      "    val_loss       : 12232.81389244041\n",
      "    val_log_likelihood: -12152.075242969397\n",
      "    val_log_marginal: -12160.566752798044\n",
      "Train Epoch: 2067 [256/118836 (0%)] Loss: 12229.954102\n",
      "Train Epoch: 2067 [33024/118836 (28%)] Loss: 12311.669922\n",
      "Train Epoch: 2067 [65792/118836 (55%)] Loss: 12304.289062\n",
      "Train Epoch: 2067 [98560/118836 (83%)] Loss: 12183.728516\n",
      "    epoch          : 2067\n",
      "    loss           : 12230.645631397334\n",
      "    val_loss       : 12238.976030565396\n",
      "    val_log_likelihood: -12156.312975922767\n",
      "    val_log_marginal: -12164.916268138617\n",
      "Train Epoch: 2068 [256/118836 (0%)] Loss: 12246.325195\n",
      "Train Epoch: 2068 [33024/118836 (28%)] Loss: 12259.353516\n",
      "Train Epoch: 2068 [65792/118836 (55%)] Loss: 12229.382812\n",
      "Train Epoch: 2068 [98560/118836 (83%)] Loss: 12260.964844\n",
      "    epoch          : 2068\n",
      "    loss           : 12229.956091843724\n",
      "    val_loss       : 12232.924366494099\n",
      "    val_log_likelihood: -12154.268098796783\n",
      "    val_log_marginal: -12162.86150009896\n",
      "Train Epoch: 2069 [256/118836 (0%)] Loss: 12208.760742\n",
      "Train Epoch: 2069 [33024/118836 (28%)] Loss: 12246.613281\n",
      "Train Epoch: 2069 [65792/118836 (55%)] Loss: 12314.621094\n",
      "Train Epoch: 2069 [98560/118836 (83%)] Loss: 12247.653320\n",
      "    epoch          : 2069\n",
      "    loss           : 12233.71030584419\n",
      "    val_loss       : 12232.87523714754\n",
      "    val_log_likelihood: -12151.445533175662\n",
      "    val_log_marginal: -12159.846781539742\n",
      "Train Epoch: 2070 [256/118836 (0%)] Loss: 12214.556641\n",
      "Train Epoch: 2070 [33024/118836 (28%)] Loss: 12323.106445\n",
      "Train Epoch: 2070 [65792/118836 (55%)] Loss: 12285.446289\n",
      "Train Epoch: 2070 [98560/118836 (83%)] Loss: 12284.595703\n",
      "    epoch          : 2070\n",
      "    loss           : 12234.037587882549\n",
      "    val_loss       : 12229.58739988567\n",
      "    val_log_likelihood: -12150.54191658266\n",
      "    val_log_marginal: -12158.905892793087\n",
      "Train Epoch: 2071 [256/118836 (0%)] Loss: 12210.029297\n",
      "Train Epoch: 2071 [33024/118836 (28%)] Loss: 12240.361328\n",
      "Train Epoch: 2071 [65792/118836 (55%)] Loss: 12196.054688\n",
      "Train Epoch: 2071 [98560/118836 (83%)] Loss: 12222.029297\n",
      "    epoch          : 2071\n",
      "    loss           : 12232.127409823459\n",
      "    val_loss       : 12234.636897544673\n",
      "    val_log_likelihood: -12151.573827801903\n",
      "    val_log_marginal: -12160.00662717459\n",
      "Train Epoch: 2072 [256/118836 (0%)] Loss: 12283.716797\n",
      "Train Epoch: 2072 [33024/118836 (28%)] Loss: 12172.303711\n",
      "Train Epoch: 2072 [65792/118836 (55%)] Loss: 12178.821289\n",
      "Train Epoch: 2072 [98560/118836 (83%)] Loss: 12210.779297\n",
      "    epoch          : 2072\n",
      "    loss           : 12235.35843607837\n",
      "    val_loss       : 12235.009573817806\n",
      "    val_log_likelihood: -12157.334142854374\n",
      "    val_log_marginal: -12166.08145837229\n",
      "Train Epoch: 2073 [256/118836 (0%)] Loss: 12285.746094\n",
      "Train Epoch: 2073 [33024/118836 (28%)] Loss: 12235.062500\n",
      "Train Epoch: 2073 [65792/118836 (55%)] Loss: 12263.726562\n",
      "Train Epoch: 2073 [98560/118836 (83%)] Loss: 12332.529297\n",
      "    epoch          : 2073\n",
      "    loss           : 12236.234964006926\n",
      "    val_loss       : 12233.65864588661\n",
      "    val_log_likelihood: -12154.575131985372\n",
      "    val_log_marginal: -12163.062562369207\n",
      "Train Epoch: 2074 [256/118836 (0%)] Loss: 12261.270508\n",
      "Train Epoch: 2074 [33024/118836 (28%)] Loss: 12224.324219\n",
      "Train Epoch: 2074 [65792/118836 (55%)] Loss: 12193.257812\n",
      "Train Epoch: 2074 [98560/118836 (83%)] Loss: 12182.689453\n",
      "    epoch          : 2074\n",
      "    loss           : 12230.847749140561\n",
      "    val_loss       : 12235.523293447477\n",
      "    val_log_likelihood: -12152.019450960246\n",
      "    val_log_marginal: -12160.321015608235\n",
      "Train Epoch: 2075 [256/118836 (0%)] Loss: 12280.612305\n",
      "Train Epoch: 2075 [33024/118836 (28%)] Loss: 12254.367188\n",
      "Train Epoch: 2075 [65792/118836 (55%)] Loss: 12229.241211\n",
      "Train Epoch: 2075 [98560/118836 (83%)] Loss: 12207.878906\n",
      "    epoch          : 2075\n",
      "    loss           : 12235.31852609336\n",
      "    val_loss       : 12232.910591403162\n",
      "    val_log_likelihood: -12154.190332273574\n",
      "    val_log_marginal: -12162.974877155157\n",
      "Train Epoch: 2076 [256/118836 (0%)] Loss: 12257.902344\n",
      "Train Epoch: 2076 [33024/118836 (28%)] Loss: 12222.741211\n",
      "Train Epoch: 2076 [65792/118836 (55%)] Loss: 12280.596680\n",
      "Train Epoch: 2076 [98560/118836 (83%)] Loss: 12189.708984\n",
      "    epoch          : 2076\n",
      "    loss           : 12234.235411335556\n",
      "    val_loss       : 12232.201661269948\n",
      "    val_log_likelihood: -12149.612496122829\n",
      "    val_log_marginal: -12158.08295178533\n",
      "Train Epoch: 2077 [256/118836 (0%)] Loss: 12255.604492\n",
      "Train Epoch: 2077 [33024/118836 (28%)] Loss: 12240.599609\n",
      "Train Epoch: 2077 [65792/118836 (55%)] Loss: 12241.742188\n",
      "Train Epoch: 2077 [98560/118836 (83%)] Loss: 12244.001953\n",
      "    epoch          : 2077\n",
      "    loss           : 12233.180847743486\n",
      "    val_loss       : 12231.97767822369\n",
      "    val_log_likelihood: -12155.151393681504\n",
      "    val_log_marginal: -12163.633592639242\n",
      "Train Epoch: 2078 [256/118836 (0%)] Loss: 12275.165039\n",
      "Train Epoch: 2078 [33024/118836 (28%)] Loss: 12231.462891\n",
      "Train Epoch: 2078 [65792/118836 (55%)] Loss: 12258.640625\n",
      "Train Epoch: 2078 [98560/118836 (83%)] Loss: 12210.054688\n",
      "    epoch          : 2078\n",
      "    loss           : 12231.237820997469\n",
      "    val_loss       : 12229.451478506724\n",
      "    val_log_likelihood: -12152.29740827259\n",
      "    val_log_marginal: -12160.743246208602\n",
      "Train Epoch: 2079 [256/118836 (0%)] Loss: 12184.706055\n",
      "Train Epoch: 2079 [33024/118836 (28%)] Loss: 12424.728516\n",
      "Train Epoch: 2079 [65792/118836 (55%)] Loss: 12181.484375\n",
      "Train Epoch: 2079 [98560/118836 (83%)] Loss: 12240.509766\n",
      "    epoch          : 2079\n",
      "    loss           : 12230.97124738291\n",
      "    val_loss       : 12232.193117974879\n",
      "    val_log_likelihood: -12154.483748190654\n",
      "    val_log_marginal: -12162.874713209569\n",
      "Train Epoch: 2080 [256/118836 (0%)] Loss: 12189.680664\n",
      "Train Epoch: 2080 [33024/118836 (28%)] Loss: 12223.786133\n",
      "Train Epoch: 2080 [65792/118836 (55%)] Loss: 12198.697266\n",
      "Train Epoch: 2080 [98560/118836 (83%)] Loss: 12258.850586\n",
      "    epoch          : 2080\n",
      "    loss           : 12228.314057330439\n",
      "    val_loss       : 12235.849223862991\n",
      "    val_log_likelihood: -12158.736720203939\n",
      "    val_log_marginal: -12167.377802133109\n",
      "Train Epoch: 2081 [256/118836 (0%)] Loss: 12215.860352\n",
      "Train Epoch: 2081 [33024/118836 (28%)] Loss: 12284.853516\n",
      "Train Epoch: 2081 [65792/118836 (55%)] Loss: 12179.529297\n",
      "Train Epoch: 2081 [98560/118836 (83%)] Loss: 12344.622070\n",
      "    epoch          : 2081\n",
      "    loss           : 12230.028107714279\n",
      "    val_loss       : 12232.053195967632\n",
      "    val_log_likelihood: -12150.007284073872\n",
      "    val_log_marginal: -12158.498424316911\n",
      "Train Epoch: 2082 [256/118836 (0%)] Loss: 12227.052734\n",
      "Train Epoch: 2082 [33024/118836 (28%)] Loss: 12259.011719\n",
      "Train Epoch: 2082 [65792/118836 (55%)] Loss: 12263.016602\n",
      "Train Epoch: 2082 [98560/118836 (83%)] Loss: 12296.494141\n",
      "    epoch          : 2082\n",
      "    loss           : 12230.933162091604\n",
      "    val_loss       : 12230.591640500195\n",
      "    val_log_likelihood: -12152.209106021246\n",
      "    val_log_marginal: -12160.672027932409\n",
      "Train Epoch: 2083 [256/118836 (0%)] Loss: 12216.688477\n",
      "Train Epoch: 2083 [33024/118836 (28%)] Loss: 12164.661133\n",
      "Train Epoch: 2083 [65792/118836 (55%)] Loss: 12179.015625\n",
      "Train Epoch: 2083 [98560/118836 (83%)] Loss: 12280.617188\n",
      "    epoch          : 2083\n",
      "    loss           : 12232.691889119365\n",
      "    val_loss       : 12234.190999595108\n",
      "    val_log_likelihood: -12154.631432065498\n",
      "    val_log_marginal: -12163.299802639272\n",
      "Train Epoch: 2084 [256/118836 (0%)] Loss: 12275.639648\n",
      "Train Epoch: 2084 [33024/118836 (28%)] Loss: 12245.292969\n",
      "Train Epoch: 2084 [65792/118836 (55%)] Loss: 12323.061523\n",
      "Train Epoch: 2084 [98560/118836 (83%)] Loss: 12345.104492\n",
      "    epoch          : 2084\n",
      "    loss           : 12236.660214730666\n",
      "    val_loss       : 12229.146398029245\n",
      "    val_log_likelihood: -12152.414283175662\n",
      "    val_log_marginal: -12160.98712658153\n",
      "Train Epoch: 2085 [256/118836 (0%)] Loss: 12299.040039\n",
      "Train Epoch: 2085 [33024/118836 (28%)] Loss: 12256.497070\n",
      "Train Epoch: 2085 [65792/118836 (55%)] Loss: 12194.750000\n",
      "Train Epoch: 2085 [98560/118836 (83%)] Loss: 12270.165039\n",
      "    epoch          : 2085\n",
      "    loss           : 12231.521014914186\n",
      "    val_loss       : 12227.62325790664\n",
      "    val_log_likelihood: -12150.00949632315\n",
      "    val_log_marginal: -12158.32549213356\n",
      "Train Epoch: 2086 [256/118836 (0%)] Loss: 12324.144531\n",
      "Train Epoch: 2086 [33024/118836 (28%)] Loss: 12357.986328\n",
      "Train Epoch: 2086 [65792/118836 (55%)] Loss: 12165.015625\n",
      "Train Epoch: 2086 [98560/118836 (83%)] Loss: 12239.060547\n",
      "    epoch          : 2086\n",
      "    loss           : 12231.881406702338\n",
      "    val_loss       : 12231.055550959594\n",
      "    val_log_likelihood: -12152.36778555366\n",
      "    val_log_marginal: -12161.025843630816\n",
      "Train Epoch: 2087 [256/118836 (0%)] Loss: 12285.931641\n",
      "Train Epoch: 2087 [33024/118836 (28%)] Loss: 12235.591797\n",
      "Train Epoch: 2087 [65792/118836 (55%)] Loss: 12260.707031\n",
      "Train Epoch: 2087 [98560/118836 (83%)] Loss: 12194.777344\n",
      "    epoch          : 2087\n",
      "    loss           : 12233.106611061568\n",
      "    val_loss       : 12228.78506234726\n",
      "    val_log_likelihood: -12152.913244578422\n",
      "    val_log_marginal: -12161.468726123625\n",
      "Train Epoch: 2088 [256/118836 (0%)] Loss: 12194.685547\n",
      "Train Epoch: 2088 [33024/118836 (28%)] Loss: 12279.606445\n",
      "Train Epoch: 2088 [65792/118836 (55%)] Loss: 12198.693359\n",
      "Train Epoch: 2088 [98560/118836 (83%)] Loss: 12183.752930\n",
      "    epoch          : 2088\n",
      "    loss           : 12235.856217851788\n",
      "    val_loss       : 12233.293561603636\n",
      "    val_log_likelihood: -12159.257992303816\n",
      "    val_log_marginal: -12167.832243850926\n",
      "Train Epoch: 2089 [256/118836 (0%)] Loss: 12241.520508\n",
      "Train Epoch: 2089 [33024/118836 (28%)] Loss: 12217.566406\n",
      "Train Epoch: 2089 [65792/118836 (55%)] Loss: 12266.990234\n",
      "Train Epoch: 2089 [98560/118836 (83%)] Loss: 12242.974609\n",
      "    epoch          : 2089\n",
      "    loss           : 12234.119939483819\n",
      "    val_loss       : 12232.56338005576\n",
      "    val_log_likelihood: -12154.513068167133\n",
      "    val_log_marginal: -12163.127308493222\n",
      "Train Epoch: 2090 [256/118836 (0%)] Loss: 12191.424805\n",
      "Train Epoch: 2090 [33024/118836 (28%)] Loss: 12279.178711\n",
      "Train Epoch: 2090 [65792/118836 (55%)] Loss: 12240.388672\n",
      "Train Epoch: 2090 [98560/118836 (83%)] Loss: 12177.186523\n",
      "    epoch          : 2090\n",
      "    loss           : 12231.168428356339\n",
      "    val_loss       : 12230.410258776334\n",
      "    val_log_likelihood: -12152.338912582714\n",
      "    val_log_marginal: -12160.84472158875\n",
      "Train Epoch: 2091 [256/118836 (0%)] Loss: 12382.408203\n",
      "Train Epoch: 2091 [33024/118836 (28%)] Loss: 12306.437500\n",
      "Train Epoch: 2091 [65792/118836 (55%)] Loss: 12229.653320\n",
      "Train Epoch: 2091 [98560/118836 (83%)] Loss: 12215.436523\n",
      "    epoch          : 2091\n",
      "    loss           : 12231.713384964329\n",
      "    val_loss       : 12231.003487952148\n",
      "    val_log_likelihood: -12151.465370075994\n",
      "    val_log_marginal: -12160.016786129527\n",
      "Train Epoch: 2092 [256/118836 (0%)] Loss: 12163.162109\n",
      "Train Epoch: 2092 [33024/118836 (28%)] Loss: 12199.687500\n",
      "Train Epoch: 2092 [65792/118836 (55%)] Loss: 12265.472656\n",
      "Train Epoch: 2092 [98560/118836 (83%)] Loss: 12264.628906\n",
      "    epoch          : 2092\n",
      "    loss           : 12229.535056897486\n",
      "    val_loss       : 12227.061687284844\n",
      "    val_log_likelihood: -12150.331329643559\n",
      "    val_log_marginal: -12158.820934664196\n",
      "Train Epoch: 2093 [256/118836 (0%)] Loss: 12234.287109\n",
      "Train Epoch: 2093 [33024/118836 (28%)] Loss: 12286.869141\n",
      "Train Epoch: 2093 [65792/118836 (55%)] Loss: 12150.287109\n",
      "Train Epoch: 2093 [98560/118836 (83%)] Loss: 12241.754883\n",
      "    epoch          : 2093\n",
      "    loss           : 12230.738782374381\n",
      "    val_loss       : 12228.682438526306\n",
      "    val_log_likelihood: -12151.757385203422\n",
      "    val_log_marginal: -12160.235972835679\n",
      "Train Epoch: 2094 [256/118836 (0%)] Loss: 12188.118164\n",
      "Train Epoch: 2094 [33024/118836 (28%)] Loss: 12217.708008\n",
      "Train Epoch: 2094 [65792/118836 (55%)] Loss: 12233.134766\n",
      "Train Epoch: 2094 [98560/118836 (83%)] Loss: 12310.134766\n",
      "    epoch          : 2094\n",
      "    loss           : 12231.482413636011\n",
      "    val_loss       : 12231.38998998364\n",
      "    val_log_likelihood: -12150.943233528486\n",
      "    val_log_marginal: -12159.521211499909\n",
      "Train Epoch: 2095 [256/118836 (0%)] Loss: 12365.451172\n",
      "Train Epoch: 2095 [33024/118836 (28%)] Loss: 12251.756836\n",
      "Train Epoch: 2095 [65792/118836 (55%)] Loss: 12219.806641\n",
      "Train Epoch: 2095 [98560/118836 (83%)] Loss: 12210.507812\n",
      "    epoch          : 2095\n",
      "    loss           : 12239.087114383012\n",
      "    val_loss       : 12233.451197851804\n",
      "    val_log_likelihood: -12151.599355904933\n",
      "    val_log_marginal: -12160.238733810076\n",
      "Train Epoch: 2096 [256/118836 (0%)] Loss: 12273.581055\n",
      "Train Epoch: 2096 [33024/118836 (28%)] Loss: 12322.387695\n",
      "Train Epoch: 2096 [65792/118836 (55%)] Loss: 12252.601562\n",
      "Train Epoch: 2096 [98560/118836 (83%)] Loss: 12230.209961\n",
      "    epoch          : 2096\n",
      "    loss           : 12232.67710401158\n",
      "    val_loss       : 12232.43449702128\n",
      "    val_log_likelihood: -12156.72269534481\n",
      "    val_log_marginal: -12165.526929246871\n",
      "Train Epoch: 2097 [256/118836 (0%)] Loss: 12238.937500\n",
      "Train Epoch: 2097 [33024/118836 (28%)] Loss: 12198.748047\n",
      "Train Epoch: 2097 [65792/118836 (55%)] Loss: 12319.801758\n",
      "Train Epoch: 2097 [98560/118836 (83%)] Loss: 12276.147461\n",
      "    epoch          : 2097\n",
      "    loss           : 12232.21942608173\n",
      "    val_loss       : 12234.383297855165\n",
      "    val_log_likelihood: -12152.020620896661\n",
      "    val_log_marginal: -12160.553506066604\n",
      "Train Epoch: 2098 [256/118836 (0%)] Loss: 12243.781250\n",
      "Train Epoch: 2098 [33024/118836 (28%)] Loss: 12266.061523\n",
      "Train Epoch: 2098 [65792/118836 (55%)] Loss: 12233.641602\n",
      "Train Epoch: 2098 [98560/118836 (83%)] Loss: 12247.516602\n",
      "    epoch          : 2098\n",
      "    loss           : 12232.45293889578\n",
      "    val_loss       : 12238.397072852611\n",
      "    val_log_likelihood: -12152.053964892213\n",
      "    val_log_marginal: -12160.942364182678\n",
      "Train Epoch: 2099 [256/118836 (0%)] Loss: 12239.003906\n",
      "Train Epoch: 2099 [33024/118836 (28%)] Loss: 12260.649414\n",
      "Train Epoch: 2099 [65792/118836 (55%)] Loss: 12280.320312\n",
      "Train Epoch: 2099 [98560/118836 (83%)] Loss: 12382.547852\n",
      "    epoch          : 2099\n",
      "    loss           : 12233.784686789186\n",
      "    val_loss       : 12226.59797707739\n",
      "    val_log_likelihood: -12154.704410282258\n",
      "    val_log_marginal: -12163.342801604656\n",
      "Train Epoch: 2100 [256/118836 (0%)] Loss: 12219.261719\n",
      "Train Epoch: 2100 [33024/118836 (28%)] Loss: 12300.066406\n",
      "Train Epoch: 2100 [65792/118836 (55%)] Loss: 12193.523438\n",
      "Train Epoch: 2100 [98560/118836 (83%)] Loss: 12274.433594\n",
      "    epoch          : 2100\n",
      "    loss           : 12230.030620444324\n",
      "    val_loss       : 12228.116825307077\n",
      "    val_log_likelihood: -12150.716488639888\n",
      "    val_log_marginal: -12159.248930360265\n",
      "Saving checkpoint: saved/models/SelfiesAutoencodingOperad/0905_154251/checkpoint-epoch2100.pth ...\n",
      "Train Epoch: 2101 [256/118836 (0%)] Loss: 12219.224609\n",
      "Train Epoch: 2101 [33024/118836 (28%)] Loss: 12271.888672\n",
      "Train Epoch: 2101 [65792/118836 (55%)] Loss: 12296.365234\n",
      "Train Epoch: 2101 [98560/118836 (83%)] Loss: 12288.710938\n",
      "    epoch          : 2101\n",
      "    loss           : 12228.198528128876\n",
      "    val_loss       : 12232.418935003236\n",
      "    val_log_likelihood: -12150.709262723583\n",
      "    val_log_marginal: -12159.111633161656\n",
      "Train Epoch: 2102 [256/118836 (0%)] Loss: 12208.780273\n",
      "Train Epoch: 2102 [33024/118836 (28%)] Loss: 12305.501953\n",
      "Train Epoch: 2102 [65792/118836 (55%)] Loss: 12311.030273\n",
      "Train Epoch: 2102 [98560/118836 (83%)] Loss: 12223.774414\n",
      "    epoch          : 2102\n",
      "    loss           : 12231.035995657568\n",
      "    val_loss       : 12230.567471625338\n",
      "    val_log_likelihood: -12150.041456491675\n",
      "    val_log_marginal: -12158.36793652186\n",
      "Train Epoch: 2103 [256/118836 (0%)] Loss: 12315.048828\n",
      "Train Epoch: 2103 [33024/118836 (28%)] Loss: 12249.474609\n",
      "Train Epoch: 2103 [65792/118836 (55%)] Loss: 12232.919922\n",
      "Train Epoch: 2103 [98560/118836 (83%)] Loss: 12238.700195\n",
      "    epoch          : 2103\n",
      "    loss           : 12228.195300383839\n",
      "    val_loss       : 12228.345968240896\n",
      "    val_log_likelihood: -12155.337206788927\n",
      "    val_log_marginal: -12163.82133347617\n",
      "Train Epoch: 2104 [256/118836 (0%)] Loss: 12383.927734\n",
      "Train Epoch: 2104 [33024/118836 (28%)] Loss: 12224.087891\n",
      "Train Epoch: 2104 [65792/118836 (55%)] Loss: 12236.925781\n",
      "Train Epoch: 2104 [98560/118836 (83%)] Loss: 12175.497070\n",
      "    epoch          : 2104\n",
      "    loss           : 12231.617412537478\n",
      "    val_loss       : 12229.60338750444\n",
      "    val_log_likelihood: -12152.132274865591\n",
      "    val_log_marginal: -12160.60361440163\n",
      "Train Epoch: 2105 [256/118836 (0%)] Loss: 12167.278320\n",
      "Train Epoch: 2105 [33024/118836 (28%)] Loss: 12205.382812\n",
      "Train Epoch: 2105 [65792/118836 (55%)] Loss: 12240.875977\n",
      "Train Epoch: 2105 [98560/118836 (83%)] Loss: 12304.500000\n",
      "    epoch          : 2105\n",
      "    loss           : 12233.475746517008\n",
      "    val_loss       : 12233.087981747336\n",
      "    val_log_likelihood: -12152.39867465364\n",
      "    val_log_marginal: -12161.162614999068\n",
      "Train Epoch: 2106 [256/118836 (0%)] Loss: 12226.419922\n",
      "Train Epoch: 2106 [33024/118836 (28%)] Loss: 12313.005859\n",
      "Train Epoch: 2106 [65792/118836 (55%)] Loss: 12222.982422\n",
      "Train Epoch: 2106 [98560/118836 (83%)] Loss: 12342.985352\n",
      "    epoch          : 2106\n",
      "    loss           : 12230.369839485113\n",
      "    val_loss       : 12227.589886117337\n",
      "    val_log_likelihood: -12149.176372841708\n",
      "    val_log_marginal: -12157.595185268392\n",
      "Train Epoch: 2107 [256/118836 (0%)] Loss: 12215.143555\n",
      "Train Epoch: 2107 [33024/118836 (28%)] Loss: 12296.506836\n",
      "Train Epoch: 2107 [65792/118836 (55%)] Loss: 12197.023438\n",
      "Train Epoch: 2107 [98560/118836 (83%)] Loss: 12298.657227\n",
      "    epoch          : 2107\n",
      "    loss           : 12235.318486837003\n",
      "    val_loss       : 12229.67608505314\n",
      "    val_log_likelihood: -12151.3940194634\n",
      "    val_log_marginal: -12159.987882995767\n",
      "Train Epoch: 2108 [256/118836 (0%)] Loss: 12275.521484\n",
      "Train Epoch: 2108 [33024/118836 (28%)] Loss: 12196.352539\n",
      "Train Epoch: 2108 [65792/118836 (55%)] Loss: 12346.884766\n",
      "Train Epoch: 2108 [98560/118836 (83%)] Loss: 12246.366211\n",
      "    epoch          : 2108\n",
      "    loss           : 12235.074558971774\n",
      "    val_loss       : 12231.043186227926\n",
      "    val_log_likelihood: -12152.533202801904\n",
      "    val_log_marginal: -12161.031892896324\n",
      "Train Epoch: 2109 [256/118836 (0%)] Loss: 12249.370117\n",
      "Train Epoch: 2109 [33024/118836 (28%)] Loss: 12377.164062\n",
      "Train Epoch: 2109 [65792/118836 (55%)] Loss: 12199.641602\n",
      "Train Epoch: 2109 [98560/118836 (83%)] Loss: 12256.871094\n",
      "    epoch          : 2109\n",
      "    loss           : 12236.33405028691\n",
      "    val_loss       : 12230.121866006855\n",
      "    val_log_likelihood: -12153.498840887356\n",
      "    val_log_marginal: -12161.953011903073\n",
      "Train Epoch: 2110 [256/118836 (0%)] Loss: 12166.944336\n",
      "Train Epoch: 2110 [33024/118836 (28%)] Loss: 12313.072266\n",
      "Train Epoch: 2110 [65792/118836 (55%)] Loss: 12238.616211\n",
      "Train Epoch: 2110 [98560/118836 (83%)] Loss: 12187.690430\n",
      "    epoch          : 2110\n",
      "    loss           : 12232.82482100393\n",
      "    val_loss       : 12230.588696680423\n",
      "    val_log_likelihood: -12150.356907018973\n",
      "    val_log_marginal: -12158.802363623958\n",
      "Train Epoch: 2111 [256/118836 (0%)] Loss: 12315.818359\n",
      "Train Epoch: 2111 [33024/118836 (28%)] Loss: 12304.053711\n",
      "Train Epoch: 2111 [65792/118836 (55%)] Loss: 12338.539062\n",
      "Train Epoch: 2111 [98560/118836 (83%)] Loss: 12307.430664\n",
      "    epoch          : 2111\n",
      "    loss           : 12230.404089123243\n",
      "    val_loss       : 12226.814225523196\n",
      "    val_log_likelihood: -12150.517080554695\n",
      "    val_log_marginal: -12159.017510194055\n",
      "Train Epoch: 2112 [256/118836 (0%)] Loss: 12210.601562\n",
      "Train Epoch: 2112 [33024/118836 (28%)] Loss: 12185.164062\n",
      "Train Epoch: 2112 [65792/118836 (55%)] Loss: 12315.978516\n",
      "Train Epoch: 2112 [98560/118836 (83%)] Loss: 12327.041016\n",
      "    epoch          : 2112\n",
      "    loss           : 12230.24277101427\n",
      "    val_loss       : 12231.868453849094\n",
      "    val_log_likelihood: -12157.27676023573\n",
      "    val_log_marginal: -12165.757843424126\n",
      "Train Epoch: 2113 [256/118836 (0%)] Loss: 12256.643555\n",
      "Train Epoch: 2113 [33024/118836 (28%)] Loss: 12272.543945\n",
      "Train Epoch: 2113 [65792/118836 (55%)] Loss: 12473.936523\n",
      "Train Epoch: 2113 [98560/118836 (83%)] Loss: 12309.039062\n",
      "    epoch          : 2113\n",
      "    loss           : 12229.298427160877\n",
      "    val_loss       : 12233.35021811667\n",
      "    val_log_likelihood: -12154.873724087573\n",
      "    val_log_marginal: -12163.511498341091\n",
      "Train Epoch: 2114 [256/118836 (0%)] Loss: 12249.610352\n",
      "Train Epoch: 2114 [33024/118836 (28%)] Loss: 12225.119141\n",
      "Train Epoch: 2114 [65792/118836 (55%)] Loss: 12221.608398\n",
      "Train Epoch: 2114 [98560/118836 (83%)] Loss: 12330.181641\n",
      "    epoch          : 2114\n",
      "    loss           : 12233.077526300143\n",
      "    val_loss       : 12227.877091007427\n",
      "    val_log_likelihood: -12151.294233838657\n",
      "    val_log_marginal: -12159.97273221479\n",
      "Train Epoch: 2115 [256/118836 (0%)] Loss: 12193.746094\n",
      "Train Epoch: 2115 [33024/118836 (28%)] Loss: 12293.538086\n",
      "Train Epoch: 2115 [65792/118836 (55%)] Loss: 12290.714844\n",
      "Train Epoch: 2115 [98560/118836 (83%)] Loss: 12274.953125\n",
      "    epoch          : 2115\n",
      "    loss           : 12230.401729379912\n",
      "    val_loss       : 12234.421038614795\n",
      "    val_log_likelihood: -12153.984533156276\n",
      "    val_log_marginal: -12162.859744920448\n",
      "Train Epoch: 2116 [256/118836 (0%)] Loss: 12284.492188\n",
      "Train Epoch: 2116 [33024/118836 (28%)] Loss: 12194.011719\n",
      "Train Epoch: 2116 [65792/118836 (55%)] Loss: 12386.390625\n",
      "Train Epoch: 2116 [98560/118836 (83%)] Loss: 12231.094727\n",
      "    epoch          : 2116\n",
      "    loss           : 12229.53609226375\n",
      "    val_loss       : 12231.565411770662\n",
      "    val_log_likelihood: -12151.989984297456\n",
      "    val_log_marginal: -12160.597539560418\n",
      "Train Epoch: 2117 [256/118836 (0%)] Loss: 12325.910156\n",
      "Train Epoch: 2117 [33024/118836 (28%)] Loss: 12280.981445\n",
      "Train Epoch: 2117 [65792/118836 (55%)] Loss: 12295.511719\n",
      "Train Epoch: 2117 [98560/118836 (83%)] Loss: 12235.208984\n",
      "    epoch          : 2117\n",
      "    loss           : 12232.244811214072\n",
      "    val_loss       : 12231.928181850404\n",
      "    val_log_likelihood: -12150.784758032205\n",
      "    val_log_marginal: -12159.341062125339\n",
      "Train Epoch: 2118 [256/118836 (0%)] Loss: 12284.123047\n",
      "Train Epoch: 2118 [33024/118836 (28%)] Loss: 12208.608398\n",
      "Train Epoch: 2118 [65792/118836 (55%)] Loss: 12240.230469\n",
      "Train Epoch: 2118 [98560/118836 (83%)] Loss: 12209.795898\n",
      "    epoch          : 2118\n",
      "    loss           : 12234.044312028278\n",
      "    val_loss       : 12230.405518267447\n",
      "    val_log_likelihood: -12151.581474068185\n",
      "    val_log_marginal: -12159.972226235812\n",
      "Train Epoch: 2119 [256/118836 (0%)] Loss: 12349.140625\n",
      "Train Epoch: 2119 [33024/118836 (28%)] Loss: 12231.889648\n",
      "Train Epoch: 2119 [65792/118836 (55%)] Loss: 12175.747070\n",
      "Train Epoch: 2119 [98560/118836 (83%)] Loss: 12217.219727\n",
      "    epoch          : 2119\n",
      "    loss           : 12232.988156211228\n",
      "    val_loss       : 12238.993959803875\n",
      "    val_log_likelihood: -12153.76567087986\n",
      "    val_log_marginal: -12162.29726595914\n",
      "Train Epoch: 2120 [256/118836 (0%)] Loss: 12268.589844\n",
      "Train Epoch: 2120 [33024/118836 (28%)] Loss: 12284.348633\n",
      "Train Epoch: 2120 [65792/118836 (55%)] Loss: 12325.532227\n",
      "Train Epoch: 2120 [98560/118836 (83%)] Loss: 12212.306641\n",
      "    epoch          : 2120\n",
      "    loss           : 12230.322904873603\n",
      "    val_loss       : 12235.4063708337\n",
      "    val_log_likelihood: -12153.063708546577\n",
      "    val_log_marginal: -12161.547634796774\n",
      "Train Epoch: 2121 [256/118836 (0%)] Loss: 12307.241211\n",
      "Train Epoch: 2121 [33024/118836 (28%)] Loss: 12314.388672\n",
      "Train Epoch: 2121 [65792/118836 (55%)] Loss: 12253.150391\n",
      "Train Epoch: 2121 [98560/118836 (83%)] Loss: 12226.291992\n",
      "    epoch          : 2121\n",
      "    loss           : 12234.06645471464\n",
      "    val_loss       : 12233.302049358948\n",
      "    val_log_likelihood: -12153.074493221411\n",
      "    val_log_marginal: -12161.566455096437\n",
      "Train Epoch: 2122 [256/118836 (0%)] Loss: 12296.056641\n",
      "Train Epoch: 2122 [33024/118836 (28%)] Loss: 12319.940430\n",
      "Train Epoch: 2122 [65792/118836 (55%)] Loss: 12277.854492\n",
      "Train Epoch: 2122 [98560/118836 (83%)] Loss: 12273.541992\n",
      "    epoch          : 2122\n",
      "    loss           : 12236.001190291563\n",
      "    val_loss       : 12233.896053369814\n",
      "    val_log_likelihood: -12153.020825417441\n",
      "    val_log_marginal: -12161.507268671396\n",
      "Train Epoch: 2123 [256/118836 (0%)] Loss: 12147.936523\n",
      "Train Epoch: 2123 [33024/118836 (28%)] Loss: 12277.294922\n",
      "Train Epoch: 2123 [65792/118836 (55%)] Loss: 12332.981445\n",
      "Train Epoch: 2123 [98560/118836 (83%)] Loss: 12294.020508\n",
      "    epoch          : 2123\n",
      "    loss           : 12231.717340163616\n",
      "    val_loss       : 12229.681341081658\n",
      "    val_log_likelihood: -12151.736677231958\n",
      "    val_log_marginal: -12160.09590600536\n",
      "Train Epoch: 2124 [256/118836 (0%)] Loss: 12306.983398\n",
      "Train Epoch: 2124 [33024/118836 (28%)] Loss: 12284.595703\n",
      "Train Epoch: 2124 [65792/118836 (55%)] Loss: 12215.795898\n",
      "Train Epoch: 2124 [98560/118836 (83%)] Loss: 12163.239258\n",
      "    epoch          : 2124\n",
      "    loss           : 12231.077708042545\n",
      "    val_loss       : 12225.988620459331\n",
      "    val_log_likelihood: -12149.81099549602\n",
      "    val_log_marginal: -12158.214292867331\n",
      "Train Epoch: 2125 [256/118836 (0%)] Loss: 12295.741211\n",
      "Train Epoch: 2125 [33024/118836 (28%)] Loss: 12291.269531\n",
      "Train Epoch: 2125 [65792/118836 (55%)] Loss: 12320.415039\n",
      "Train Epoch: 2125 [98560/118836 (83%)] Loss: 12248.929688\n",
      "    epoch          : 2125\n",
      "    loss           : 12231.35473079508\n",
      "    val_loss       : 12232.145891908232\n",
      "    val_log_likelihood: -12151.041122570305\n",
      "    val_log_marginal: -12159.520511661589\n",
      "Train Epoch: 2126 [256/118836 (0%)] Loss: 12274.984375\n",
      "Train Epoch: 2126 [33024/118836 (28%)] Loss: 12280.335938\n",
      "Train Epoch: 2126 [65792/118836 (55%)] Loss: 12195.225586\n",
      "Train Epoch: 2126 [98560/118836 (83%)] Loss: 12173.879883\n",
      "    epoch          : 2126\n",
      "    loss           : 12230.829282335608\n",
      "    val_loss       : 12232.375782582028\n",
      "    val_log_likelihood: -12150.307930107527\n",
      "    val_log_marginal: -12158.797380281172\n",
      "Train Epoch: 2127 [256/118836 (0%)] Loss: 12187.198242\n",
      "Train Epoch: 2127 [33024/118836 (28%)] Loss: 12350.734375\n",
      "Train Epoch: 2127 [65792/118836 (55%)] Loss: 12216.836914\n",
      "Train Epoch: 2127 [98560/118836 (83%)] Loss: 12215.036133\n",
      "    epoch          : 2127\n",
      "    loss           : 12231.737425364454\n",
      "    val_loss       : 12228.202356725313\n",
      "    val_log_likelihood: -12149.811743466968\n",
      "    val_log_marginal: -12158.510336560124\n",
      "Train Epoch: 2128 [256/118836 (0%)] Loss: 12279.862305\n",
      "Train Epoch: 2128 [33024/118836 (28%)] Loss: 12167.144531\n",
      "Train Epoch: 2128 [65792/118836 (55%)] Loss: 12258.193359\n",
      "Train Epoch: 2128 [98560/118836 (83%)] Loss: 12324.577148\n",
      "    epoch          : 2128\n",
      "    loss           : 12234.516540173956\n",
      "    val_loss       : 12261.524347982342\n",
      "    val_log_likelihood: -12153.22162023754\n",
      "    val_log_marginal: -12161.787027085806\n",
      "Train Epoch: 2129 [256/118836 (0%)] Loss: 12269.139648\n",
      "Train Epoch: 2129 [33024/118836 (28%)] Loss: 12163.435547\n",
      "Train Epoch: 2129 [65792/118836 (55%)] Loss: 12315.791016\n",
      "Train Epoch: 2129 [98560/118836 (83%)] Loss: 12186.295898\n",
      "    epoch          : 2129\n",
      "    loss           : 12237.600088205645\n",
      "    val_loss       : 12229.897557810618\n",
      "    val_log_likelihood: -12154.960914075426\n",
      "    val_log_marginal: -12163.523149915678\n",
      "Train Epoch: 2130 [256/118836 (0%)] Loss: 12182.676758\n",
      "Train Epoch: 2130 [33024/118836 (28%)] Loss: 12218.123047\n",
      "Train Epoch: 2130 [65792/118836 (55%)] Loss: 12158.536133\n",
      "Train Epoch: 2130 [98560/118836 (83%)] Loss: 12268.937500\n",
      "    epoch          : 2130\n",
      "    loss           : 12232.426133264838\n",
      "    val_loss       : 12235.114758586871\n",
      "    val_log_likelihood: -12157.406541757133\n",
      "    val_log_marginal: -12165.971210646128\n",
      "Train Epoch: 2131 [256/118836 (0%)] Loss: 12263.679688\n",
      "Train Epoch: 2131 [33024/118836 (28%)] Loss: 12252.800781\n",
      "Train Epoch: 2131 [65792/118836 (55%)] Loss: 12283.374023\n",
      "Train Epoch: 2131 [98560/118836 (83%)] Loss: 12209.484375\n",
      "    epoch          : 2131\n",
      "    loss           : 12232.569247570305\n",
      "    val_loss       : 12229.823644817774\n",
      "    val_log_likelihood: -12149.56826228417\n",
      "    val_log_marginal: -12158.047689764911\n",
      "Train Epoch: 2132 [256/118836 (0%)] Loss: 12249.714844\n",
      "Train Epoch: 2132 [33024/118836 (28%)] Loss: 12289.554688\n",
      "Train Epoch: 2132 [65792/118836 (55%)] Loss: 12302.922852\n",
      "Train Epoch: 2132 [98560/118836 (83%)] Loss: 12273.110352\n",
      "    epoch          : 2132\n",
      "    loss           : 12230.165924349927\n",
      "    val_loss       : 12231.702601343726\n",
      "    val_log_likelihood: -12151.769478908189\n",
      "    val_log_marginal: -12160.362467467274\n",
      "Train Epoch: 2133 [256/118836 (0%)] Loss: 12310.164062\n",
      "Train Epoch: 2133 [33024/118836 (28%)] Loss: 12353.236328\n",
      "Train Epoch: 2133 [65792/118836 (55%)] Loss: 12269.123047\n",
      "Train Epoch: 2133 [98560/118836 (83%)] Loss: 12206.702148\n",
      "    epoch          : 2133\n",
      "    loss           : 12234.374352673956\n",
      "    val_loss       : 12236.247438698143\n",
      "    val_log_likelihood: -12149.960956078114\n",
      "    val_log_marginal: -12158.392888970317\n",
      "Train Epoch: 2134 [256/118836 (0%)] Loss: 12350.396484\n",
      "Train Epoch: 2134 [33024/118836 (28%)] Loss: 12237.691406\n",
      "Train Epoch: 2134 [65792/118836 (55%)] Loss: 12244.001953\n",
      "Train Epoch: 2134 [98560/118836 (83%)] Loss: 12190.267578\n",
      "    epoch          : 2134\n",
      "    loss           : 12233.028649710506\n",
      "    val_loss       : 12228.390602091096\n",
      "    val_log_likelihood: -12152.226163151365\n",
      "    val_log_marginal: -12160.765211031365\n",
      "Train Epoch: 2135 [256/118836 (0%)] Loss: 12317.067383\n",
      "Train Epoch: 2135 [33024/118836 (28%)] Loss: 12265.589844\n",
      "Train Epoch: 2135 [65792/118836 (55%)] Loss: 12180.388672\n",
      "Train Epoch: 2135 [98560/118836 (83%)] Loss: 12263.663086\n",
      "    epoch          : 2135\n",
      "    loss           : 12234.017240488007\n",
      "    val_loss       : 12229.506133075989\n",
      "    val_log_likelihood: -12149.590923057536\n",
      "    val_log_marginal: -12158.03915719541\n",
      "Train Epoch: 2136 [256/118836 (0%)] Loss: 12260.632812\n",
      "Train Epoch: 2136 [33024/118836 (28%)] Loss: 12237.776367\n",
      "Train Epoch: 2136 [65792/118836 (55%)] Loss: 12373.800781\n",
      "Train Epoch: 2136 [98560/118836 (83%)] Loss: 12243.781250\n",
      "    epoch          : 2136\n",
      "    loss           : 12227.871670963865\n",
      "    val_loss       : 12240.207881318085\n",
      "    val_log_likelihood: -12166.282243202026\n",
      "    val_log_marginal: -12174.910552880783\n",
      "Train Epoch: 2137 [256/118836 (0%)] Loss: 12347.470703\n",
      "Train Epoch: 2137 [33024/118836 (28%)] Loss: 12239.269531\n",
      "Train Epoch: 2137 [65792/118836 (55%)] Loss: 12254.531250\n",
      "Train Epoch: 2137 [98560/118836 (83%)] Loss: 12227.523438\n",
      "    epoch          : 2137\n",
      "    loss           : 12231.675816790736\n",
      "    val_loss       : 12225.496095340652\n",
      "    val_log_likelihood: -12149.011162375931\n",
      "    val_log_marginal: -12157.611059883737\n",
      "Train Epoch: 2138 [256/118836 (0%)] Loss: 12260.965820\n",
      "Train Epoch: 2138 [33024/118836 (28%)] Loss: 12274.335938\n",
      "Train Epoch: 2138 [65792/118836 (55%)] Loss: 12272.518555\n",
      "Train Epoch: 2138 [98560/118836 (83%)] Loss: 12177.179688\n",
      "    epoch          : 2138\n",
      "    loss           : 12229.971370967742\n",
      "    val_loss       : 12232.935307720043\n",
      "    val_log_likelihood: -12151.464710633789\n",
      "    val_log_marginal: -12159.974554811299\n",
      "Train Epoch: 2139 [256/118836 (0%)] Loss: 12227.638672\n",
      "Train Epoch: 2139 [33024/118836 (28%)] Loss: 12357.321289\n",
      "Train Epoch: 2139 [65792/118836 (55%)] Loss: 12256.720703\n",
      "Train Epoch: 2139 [98560/118836 (83%)] Loss: 12390.495117\n",
      "    epoch          : 2139\n",
      "    loss           : 12234.338196113782\n",
      "    val_loss       : 12233.814903956834\n",
      "    val_log_likelihood: -12158.422291311259\n",
      "    val_log_marginal: -12167.04235719549\n",
      "Train Epoch: 2140 [256/118836 (0%)] Loss: 12286.984375\n",
      "Train Epoch: 2140 [33024/118836 (28%)] Loss: 12203.075195\n",
      "Train Epoch: 2140 [65792/118836 (55%)] Loss: 12467.053711\n",
      "Train Epoch: 2140 [98560/118836 (83%)] Loss: 12311.149414\n",
      "    epoch          : 2140\n",
      "    loss           : 12231.488589000466\n",
      "    val_loss       : 12234.5243234868\n",
      "    val_log_likelihood: -12150.832208630583\n",
      "    val_log_marginal: -12159.261637262382\n",
      "Train Epoch: 2141 [256/118836 (0%)] Loss: 12421.899414\n",
      "Train Epoch: 2141 [33024/118836 (28%)] Loss: 12246.039062\n",
      "Train Epoch: 2141 [65792/118836 (55%)] Loss: 12168.457031\n",
      "Train Epoch: 2141 [98560/118836 (83%)] Loss: 12229.732422\n",
      "    epoch          : 2141\n",
      "    loss           : 12231.502250213243\n",
      "    val_loss       : 12230.029065731787\n",
      "    val_log_likelihood: -12150.829247441066\n",
      "    val_log_marginal: -12159.257213707226\n",
      "Train Epoch: 2142 [256/118836 (0%)] Loss: 12198.154297\n",
      "Train Epoch: 2142 [33024/118836 (28%)] Loss: 12232.007812\n",
      "Train Epoch: 2142 [65792/118836 (55%)] Loss: 12213.833984\n",
      "Train Epoch: 2142 [98560/118836 (83%)] Loss: 12249.309570\n",
      "    epoch          : 2142\n",
      "    loss           : 12231.984602622259\n",
      "    val_loss       : 12227.290272101356\n",
      "    val_log_likelihood: -12150.95346457558\n",
      "    val_log_marginal: -12159.544022795499\n",
      "Train Epoch: 2143 [256/118836 (0%)] Loss: 12189.197266\n",
      "Train Epoch: 2143 [33024/118836 (28%)] Loss: 12166.203125\n",
      "Train Epoch: 2143 [65792/118836 (55%)] Loss: 12248.509766\n",
      "Train Epoch: 2143 [98560/118836 (83%)] Loss: 12229.361328\n",
      "    epoch          : 2143\n",
      "    loss           : 12228.178923535721\n",
      "    val_loss       : 12225.141162626349\n",
      "    val_log_likelihood: -12151.686473195823\n",
      "    val_log_marginal: -12160.074840610994\n",
      "Train Epoch: 2144 [256/118836 (0%)] Loss: 12226.707031\n",
      "Train Epoch: 2144 [33024/118836 (28%)] Loss: 12189.956055\n",
      "Train Epoch: 2144 [65792/118836 (55%)] Loss: 12242.702148\n",
      "Train Epoch: 2144 [98560/118836 (83%)] Loss: 12211.948242\n",
      "    epoch          : 2144\n",
      "    loss           : 12227.208396014268\n",
      "    val_loss       : 12233.8173120537\n",
      "    val_log_likelihood: -12149.688051366056\n",
      "    val_log_marginal: -12158.073695188705\n",
      "Train Epoch: 2145 [256/118836 (0%)] Loss: 12237.935547\n",
      "Train Epoch: 2145 [33024/118836 (28%)] Loss: 12224.263672\n",
      "Train Epoch: 2145 [65792/118836 (55%)] Loss: 12265.966797\n",
      "Train Epoch: 2145 [98560/118836 (83%)] Loss: 12292.280273\n",
      "    epoch          : 2145\n",
      "    loss           : 12233.224328280086\n",
      "    val_loss       : 12231.981712207153\n",
      "    val_log_likelihood: -12152.56676731157\n",
      "    val_log_marginal: -12160.926644851566\n",
      "Train Epoch: 2146 [256/118836 (0%)] Loss: 12205.567383\n",
      "Train Epoch: 2146 [33024/118836 (28%)] Loss: 12162.785156\n",
      "Train Epoch: 2146 [65792/118836 (55%)] Loss: 12253.117188\n",
      "Train Epoch: 2146 [98560/118836 (83%)] Loss: 12234.331055\n",
      "    epoch          : 2146\n",
      "    loss           : 12229.063471554487\n",
      "    val_loss       : 12230.880447244721\n",
      "    val_log_likelihood: -12149.029516096722\n",
      "    val_log_marginal: -12157.319980019145\n",
      "Train Epoch: 2147 [256/118836 (0%)] Loss: 12250.623047\n",
      "Train Epoch: 2147 [33024/118836 (28%)] Loss: 12319.973633\n",
      "Train Epoch: 2147 [65792/118836 (55%)] Loss: 12291.268555\n",
      "Train Epoch: 2147 [98560/118836 (83%)] Loss: 12245.623047\n",
      "    epoch          : 2147\n",
      "    loss           : 12234.12117177807\n",
      "    val_loss       : 12226.086342412727\n",
      "    val_log_likelihood: -12151.119329475547\n",
      "    val_log_marginal: -12159.477540758695\n",
      "Train Epoch: 2148 [256/118836 (0%)] Loss: 12191.967773\n",
      "Train Epoch: 2148 [33024/118836 (28%)] Loss: 12243.072266\n",
      "Train Epoch: 2148 [65792/118836 (55%)] Loss: 12252.798828\n",
      "Train Epoch: 2148 [98560/118836 (83%)] Loss: 12205.839844\n",
      "    epoch          : 2148\n",
      "    loss           : 12233.592926908861\n",
      "    val_loss       : 12227.791616978793\n",
      "    val_log_likelihood: -12152.259123953163\n",
      "    val_log_marginal: -12160.68280167127\n",
      "Train Epoch: 2149 [256/118836 (0%)] Loss: 12258.789062\n",
      "Train Epoch: 2149 [33024/118836 (28%)] Loss: 12192.824219\n",
      "Train Epoch: 2149 [65792/118836 (55%)] Loss: 12229.337891\n",
      "Train Epoch: 2149 [98560/118836 (83%)] Loss: 12254.207031\n",
      "    epoch          : 2149\n",
      "    loss           : 12230.3321527347\n",
      "    val_loss       : 12231.649747908486\n",
      "    val_log_likelihood: -12152.65546196495\n",
      "    val_log_marginal: -12161.107477998643\n",
      "Train Epoch: 2150 [256/118836 (0%)] Loss: 12250.850586\n",
      "Train Epoch: 2150 [33024/118836 (28%)] Loss: 12270.159180\n",
      "Train Epoch: 2150 [65792/118836 (55%)] Loss: 12197.000000\n",
      "Train Epoch: 2150 [98560/118836 (83%)] Loss: 12142.994141\n",
      "    epoch          : 2150\n",
      "    loss           : 12227.257767104786\n",
      "    val_loss       : 12229.370310918182\n",
      "    val_log_likelihood: -12151.660669005892\n",
      "    val_log_marginal: -12160.168336896537\n",
      "Train Epoch: 2151 [256/118836 (0%)] Loss: 12283.441406\n",
      "Train Epoch: 2151 [33024/118836 (28%)] Loss: 12251.789062\n",
      "Train Epoch: 2151 [65792/118836 (55%)] Loss: 12194.964844\n",
      "Train Epoch: 2151 [98560/118836 (83%)] Loss: 12156.677734\n",
      "    epoch          : 2151\n",
      "    loss           : 12233.05568958721\n",
      "    val_loss       : 12229.656916985721\n",
      "    val_log_likelihood: -12150.221618137406\n",
      "    val_log_marginal: -12158.608528829696\n",
      "Train Epoch: 2152 [256/118836 (0%)] Loss: 12230.445312\n",
      "Train Epoch: 2152 [33024/118836 (28%)] Loss: 12219.640625\n",
      "Train Epoch: 2152 [65792/118836 (55%)] Loss: 12240.974609\n",
      "Train Epoch: 2152 [98560/118836 (83%)] Loss: 12345.593750\n",
      "    epoch          : 2152\n",
      "    loss           : 12230.481473745089\n",
      "    val_loss       : 12229.483801262215\n",
      "    val_log_likelihood: -12153.148203254239\n",
      "    val_log_marginal: -12161.708101599246\n",
      "Train Epoch: 2153 [256/118836 (0%)] Loss: 12239.600586\n",
      "Train Epoch: 2153 [33024/118836 (28%)] Loss: 12184.812500\n",
      "Train Epoch: 2153 [65792/118836 (55%)] Loss: 12281.581055\n",
      "Train Epoch: 2153 [98560/118836 (83%)] Loss: 12302.291992\n",
      "    epoch          : 2153\n",
      "    loss           : 12233.97176563146\n",
      "    val_loss       : 12230.765372625745\n",
      "    val_log_likelihood: -12152.059113937137\n",
      "    val_log_marginal: -12160.496050606322\n",
      "Train Epoch: 2154 [256/118836 (0%)] Loss: 12309.951172\n",
      "Train Epoch: 2154 [33024/118836 (28%)] Loss: 12284.250000\n",
      "Train Epoch: 2154 [65792/118836 (55%)] Loss: 12332.962891\n",
      "Train Epoch: 2154 [98560/118836 (83%)] Loss: 12221.335938\n",
      "    epoch          : 2154\n",
      "    loss           : 12230.79337811466\n",
      "    val_loss       : 12231.171143164886\n",
      "    val_log_likelihood: -12152.218094434967\n",
      "    val_log_marginal: -12160.750315634983\n",
      "Train Epoch: 2155 [256/118836 (0%)] Loss: 12366.550781\n",
      "Train Epoch: 2155 [33024/118836 (28%)] Loss: 12142.410156\n",
      "Train Epoch: 2155 [65792/118836 (55%)] Loss: 12222.234375\n",
      "Train Epoch: 2155 [98560/118836 (83%)] Loss: 12292.035156\n",
      "    epoch          : 2155\n",
      "    loss           : 12231.25301579301\n",
      "    val_loss       : 12234.679537167329\n",
      "    val_log_likelihood: -12152.192494442721\n",
      "    val_log_marginal: -12160.836821408482\n",
      "Train Epoch: 2156 [256/118836 (0%)] Loss: 12352.461914\n",
      "Train Epoch: 2156 [33024/118836 (28%)] Loss: 12369.371094\n",
      "Train Epoch: 2156 [65792/118836 (55%)] Loss: 12297.282227\n",
      "Train Epoch: 2156 [98560/118836 (83%)] Loss: 12170.384766\n",
      "    epoch          : 2156\n",
      "    loss           : 12231.680306878101\n",
      "    val_loss       : 12236.30915017354\n",
      "    val_log_likelihood: -12150.396697619417\n",
      "    val_log_marginal: -12158.901206124105\n",
      "Train Epoch: 2157 [256/118836 (0%)] Loss: 12147.142578\n",
      "Train Epoch: 2157 [33024/118836 (28%)] Loss: 12299.754883\n",
      "Train Epoch: 2157 [65792/118836 (55%)] Loss: 12271.803711\n",
      "Train Epoch: 2157 [98560/118836 (83%)] Loss: 12236.105469\n",
      "    epoch          : 2157\n",
      "    loss           : 12237.054803815136\n",
      "    val_loss       : 12232.229366254276\n",
      "    val_log_likelihood: -12154.14607484879\n",
      "    val_log_marginal: -12162.603208514302\n",
      "Train Epoch: 2158 [256/118836 (0%)] Loss: 12204.169922\n",
      "Train Epoch: 2158 [33024/118836 (28%)] Loss: 12275.709961\n",
      "Train Epoch: 2158 [65792/118836 (55%)] Loss: 12268.172852\n",
      "Train Epoch: 2158 [98560/118836 (83%)] Loss: 12268.996094\n",
      "    epoch          : 2158\n",
      "    loss           : 12229.040783479373\n",
      "    val_loss       : 12234.369522208292\n",
      "    val_log_likelihood: -12152.86617329663\n",
      "    val_log_marginal: -12161.53230940314\n",
      "Train Epoch: 2159 [256/118836 (0%)] Loss: 12283.372070\n",
      "Train Epoch: 2159 [33024/118836 (28%)] Loss: 12320.000000\n",
      "Train Epoch: 2159 [65792/118836 (55%)] Loss: 12212.432617\n",
      "Train Epoch: 2159 [98560/118836 (83%)] Loss: 12426.747070\n",
      "    epoch          : 2159\n",
      "    loss           : 12232.86921752223\n",
      "    val_loss       : 12227.178776500821\n",
      "    val_log_likelihood: -12149.199508891645\n",
      "    val_log_marginal: -12157.652965830206\n",
      "Train Epoch: 2160 [256/118836 (0%)] Loss: 12248.215820\n",
      "Train Epoch: 2160 [33024/118836 (28%)] Loss: 12352.057617\n",
      "Train Epoch: 2160 [65792/118836 (55%)] Loss: 12248.041016\n",
      "Train Epoch: 2160 [98560/118836 (83%)] Loss: 12198.244141\n",
      "    epoch          : 2160\n",
      "    loss           : 12233.054686692258\n",
      "    val_loss       : 12229.380042384291\n",
      "    val_log_likelihood: -12151.467323039444\n",
      "    val_log_marginal: -12159.870691812948\n",
      "Train Epoch: 2161 [256/118836 (0%)] Loss: 12264.876953\n",
      "Train Epoch: 2161 [33024/118836 (28%)] Loss: 12270.111328\n",
      "Train Epoch: 2161 [65792/118836 (55%)] Loss: 12328.740234\n",
      "Train Epoch: 2161 [98560/118836 (83%)] Loss: 12209.934570\n",
      "    epoch          : 2161\n",
      "    loss           : 12232.54704446469\n",
      "    val_loss       : 12227.693736911333\n",
      "    val_log_likelihood: -12152.179865526778\n",
      "    val_log_marginal: -12160.590736046232\n",
      "Train Epoch: 2162 [256/118836 (0%)] Loss: 12230.596680\n",
      "Train Epoch: 2162 [33024/118836 (28%)] Loss: 12273.511719\n",
      "Train Epoch: 2162 [65792/118836 (55%)] Loss: 12254.168945\n",
      "Train Epoch: 2162 [98560/118836 (83%)] Loss: 12272.551758\n",
      "    epoch          : 2162\n",
      "    loss           : 12230.992238549421\n",
      "    val_loss       : 12228.46075810068\n",
      "    val_log_likelihood: -12149.883004258427\n",
      "    val_log_marginal: -12158.181994362116\n",
      "Train Epoch: 2163 [256/118836 (0%)] Loss: 12245.762695\n",
      "Train Epoch: 2163 [33024/118836 (28%)] Loss: 12257.985352\n",
      "Train Epoch: 2163 [65792/118836 (55%)] Loss: 12190.635742\n",
      "Train Epoch: 2163 [98560/118836 (83%)] Loss: 12253.280273\n",
      "    epoch          : 2163\n",
      "    loss           : 12234.34324225212\n",
      "    val_loss       : 12230.645691885733\n",
      "    val_log_likelihood: -12150.48921984853\n",
      "    val_log_marginal: -12158.961824784737\n",
      "Train Epoch: 2164 [256/118836 (0%)] Loss: 12319.433594\n",
      "Train Epoch: 2164 [33024/118836 (28%)] Loss: 12307.254883\n",
      "Train Epoch: 2164 [65792/118836 (55%)] Loss: 12274.175781\n",
      "Train Epoch: 2164 [98560/118836 (83%)] Loss: 12273.842773\n",
      "    epoch          : 2164\n",
      "    loss           : 12230.66949360913\n",
      "    val_loss       : 12235.655577732405\n",
      "    val_log_likelihood: -12151.660745741574\n",
      "    val_log_marginal: -12160.243594233885\n",
      "Train Epoch: 2165 [256/118836 (0%)] Loss: 12158.026367\n",
      "Train Epoch: 2165 [33024/118836 (28%)] Loss: 12201.451172\n",
      "Train Epoch: 2165 [65792/118836 (55%)] Loss: 12210.203125\n",
      "Train Epoch: 2165 [98560/118836 (83%)] Loss: 12222.505859\n",
      "    epoch          : 2165\n",
      "    loss           : 12230.210729586694\n",
      "    val_loss       : 12234.313207653207\n",
      "    val_log_likelihood: -12155.577722420388\n",
      "    val_log_marginal: -12164.032124657686\n",
      "Train Epoch: 2166 [256/118836 (0%)] Loss: 12304.726562\n",
      "Train Epoch: 2166 [33024/118836 (28%)] Loss: 12288.473633\n",
      "Train Epoch: 2166 [65792/118836 (55%)] Loss: 12323.972656\n",
      "Train Epoch: 2166 [98560/118836 (83%)] Loss: 12219.156250\n",
      "    epoch          : 2166\n",
      "    loss           : 12233.66096318626\n",
      "    val_loss       : 12230.015889609555\n",
      "    val_log_likelihood: -12150.758767899606\n",
      "    val_log_marginal: -12159.147653758884\n",
      "Train Epoch: 2167 [256/118836 (0%)] Loss: 12198.921875\n",
      "Train Epoch: 2167 [33024/118836 (28%)] Loss: 12223.597656\n",
      "Train Epoch: 2167 [65792/118836 (55%)] Loss: 12343.643555\n",
      "Train Epoch: 2167 [98560/118836 (83%)] Loss: 12201.256836\n",
      "    epoch          : 2167\n",
      "    loss           : 12231.863613878979\n",
      "    val_loss       : 12237.149887298641\n",
      "    val_log_likelihood: -12152.986184669664\n",
      "    val_log_marginal: -12161.71540448232\n",
      "Train Epoch: 2168 [256/118836 (0%)] Loss: 12297.463867\n",
      "Train Epoch: 2168 [33024/118836 (28%)] Loss: 12265.164062\n",
      "Train Epoch: 2168 [65792/118836 (55%)] Loss: 12203.376953\n",
      "Train Epoch: 2168 [98560/118836 (83%)] Loss: 12443.417969\n",
      "    epoch          : 2168\n",
      "    loss           : 12230.843951774452\n",
      "    val_loss       : 12234.057849397193\n",
      "    val_log_likelihood: -12151.706353552781\n",
      "    val_log_marginal: -12160.333295205293\n",
      "Train Epoch: 2169 [256/118836 (0%)] Loss: 12214.404297\n",
      "Train Epoch: 2169 [33024/118836 (28%)] Loss: 12300.346680\n",
      "Train Epoch: 2169 [65792/118836 (55%)] Loss: 12187.684570\n",
      "Train Epoch: 2169 [98560/118836 (83%)] Loss: 12231.943359\n",
      "    epoch          : 2169\n",
      "    loss           : 12232.473558015405\n",
      "    val_loss       : 12231.785402720896\n",
      "    val_log_likelihood: -12149.621937842483\n",
      "    val_log_marginal: -12158.078808630338\n",
      "Train Epoch: 2170 [256/118836 (0%)] Loss: 12232.876953\n",
      "Train Epoch: 2170 [33024/118836 (28%)] Loss: 12282.834961\n",
      "Train Epoch: 2170 [65792/118836 (55%)] Loss: 12262.216797\n",
      "Train Epoch: 2170 [98560/118836 (83%)] Loss: 12278.085938\n",
      "    epoch          : 2170\n",
      "    loss           : 12235.897058842536\n",
      "    val_loss       : 12231.724080146032\n",
      "    val_log_likelihood: -12153.484191480564\n",
      "    val_log_marginal: -12161.821198315609\n",
      "Train Epoch: 2171 [256/118836 (0%)] Loss: 12302.476562\n",
      "Train Epoch: 2171 [33024/118836 (28%)] Loss: 12255.935547\n",
      "Train Epoch: 2171 [65792/118836 (55%)] Loss: 12315.729492\n",
      "Train Epoch: 2171 [98560/118836 (83%)] Loss: 12269.546875\n",
      "    epoch          : 2171\n",
      "    loss           : 12235.237683680985\n",
      "    val_loss       : 12233.595664790804\n",
      "    val_log_likelihood: -12149.375934559812\n",
      "    val_log_marginal: -12157.877610069598\n",
      "Train Epoch: 2172 [256/118836 (0%)] Loss: 12281.668945\n",
      "Train Epoch: 2172 [33024/118836 (28%)] Loss: 12277.367188\n",
      "Train Epoch: 2172 [65792/118836 (55%)] Loss: 12330.433594\n",
      "Train Epoch: 2172 [98560/118836 (83%)] Loss: 12192.541992\n",
      "    epoch          : 2172\n",
      "    loss           : 12233.993839174938\n",
      "    val_loss       : 12233.084721346368\n",
      "    val_log_likelihood: -12150.307081976323\n",
      "    val_log_marginal: -12158.792993051713\n",
      "Train Epoch: 2173 [256/118836 (0%)] Loss: 12236.402344\n",
      "Train Epoch: 2173 [33024/118836 (28%)] Loss: 12190.078125\n",
      "Train Epoch: 2173 [65792/118836 (55%)] Loss: 12340.588867\n",
      "Train Epoch: 2173 [98560/118836 (83%)] Loss: 12196.120117\n",
      "    epoch          : 2173\n",
      "    loss           : 12230.822294542235\n",
      "    val_loss       : 12231.086199370879\n",
      "    val_log_likelihood: -12151.858108134305\n",
      "    val_log_marginal: -12160.312742835826\n",
      "Train Epoch: 2174 [256/118836 (0%)] Loss: 12353.919922\n",
      "Train Epoch: 2174 [33024/118836 (28%)] Loss: 12356.757812\n",
      "Train Epoch: 2174 [65792/118836 (55%)] Loss: 12184.080078\n",
      "Train Epoch: 2174 [98560/118836 (83%)] Loss: 12288.688477\n",
      "    epoch          : 2174\n",
      "    loss           : 12237.448272074029\n",
      "    val_loss       : 12231.272184588872\n",
      "    val_log_likelihood: -12150.910684514578\n",
      "    val_log_marginal: -12159.378769559837\n",
      "Train Epoch: 2175 [256/118836 (0%)] Loss: 12342.429688\n",
      "Train Epoch: 2175 [33024/118836 (28%)] Loss: 12283.130859\n",
      "Train Epoch: 2175 [65792/118836 (55%)] Loss: 12299.363281\n",
      "Train Epoch: 2175 [98560/118836 (83%)] Loss: 12244.302734\n",
      "    epoch          : 2175\n",
      "    loss           : 12231.49153678143\n",
      "    val_loss       : 12231.668926524364\n",
      "    val_log_likelihood: -12152.03130654208\n",
      "    val_log_marginal: -12160.462185021339\n",
      "Train Epoch: 2176 [256/118836 (0%)] Loss: 12269.878906\n",
      "Train Epoch: 2176 [33024/118836 (28%)] Loss: 12171.982422\n",
      "Train Epoch: 2176 [65792/118836 (55%)] Loss: 12195.543945\n",
      "Train Epoch: 2176 [98560/118836 (83%)] Loss: 12174.510742\n",
      "    epoch          : 2176\n",
      "    loss           : 12235.095795207817\n",
      "    val_loss       : 12238.5369922412\n",
      "    val_log_likelihood: -12163.943134014422\n",
      "    val_log_marginal: -12172.619440457122\n",
      "Train Epoch: 2177 [256/118836 (0%)] Loss: 12198.647461\n",
      "Train Epoch: 2177 [33024/118836 (28%)] Loss: 12242.463867\n",
      "Train Epoch: 2177 [65792/118836 (55%)] Loss: 12215.120117\n",
      "Train Epoch: 2177 [98560/118836 (83%)] Loss: 12292.182617\n",
      "    epoch          : 2177\n",
      "    loss           : 12235.844467438224\n",
      "    val_loss       : 12248.630763484949\n",
      "    val_log_likelihood: -12157.408237696443\n",
      "    val_log_marginal: -12166.06440802477\n",
      "Train Epoch: 2178 [256/118836 (0%)] Loss: 12281.164062\n",
      "Train Epoch: 2178 [33024/118836 (28%)] Loss: 12212.619141\n",
      "Train Epoch: 2178 [65792/118836 (55%)] Loss: 12348.783203\n",
      "Train Epoch: 2178 [98560/118836 (83%)] Loss: 12262.745117\n",
      "    epoch          : 2178\n",
      "    loss           : 12232.952965551334\n",
      "    val_loss       : 12234.346341432361\n",
      "    val_log_likelihood: -12151.398408098119\n",
      "    val_log_marginal: -12160.027994639184\n",
      "Train Epoch: 2179 [256/118836 (0%)] Loss: 12375.504883\n",
      "Train Epoch: 2179 [33024/118836 (28%)] Loss: 12389.588867\n",
      "Train Epoch: 2179 [65792/118836 (55%)] Loss: 12267.517578\n",
      "Train Epoch: 2179 [98560/118836 (83%)] Loss: 12273.210938\n",
      "    epoch          : 2179\n",
      "    loss           : 12233.341467476994\n",
      "    val_loss       : 12232.688996771874\n",
      "    val_log_likelihood: -12157.48916217561\n",
      "    val_log_marginal: -12165.935260250691\n",
      "Train Epoch: 2180 [256/118836 (0%)] Loss: 12327.546875\n",
      "Train Epoch: 2180 [33024/118836 (28%)] Loss: 12187.919922\n",
      "Train Epoch: 2180 [65792/118836 (55%)] Loss: 12280.115234\n",
      "Train Epoch: 2180 [98560/118836 (83%)] Loss: 12250.175781\n",
      "    epoch          : 2180\n",
      "    loss           : 12235.005194924785\n",
      "    val_loss       : 12237.220121674962\n",
      "    val_log_likelihood: -12149.760310044458\n",
      "    val_log_marginal: -12158.275036621306\n",
      "Train Epoch: 2181 [256/118836 (0%)] Loss: 12113.580078\n",
      "Train Epoch: 2181 [33024/118836 (28%)] Loss: 12236.143555\n",
      "Train Epoch: 2181 [65792/118836 (55%)] Loss: 12216.000977\n",
      "Train Epoch: 2181 [98560/118836 (83%)] Loss: 12254.335938\n",
      "    epoch          : 2181\n",
      "    loss           : 12231.517561323924\n",
      "    val_loss       : 12230.046416380721\n",
      "    val_log_likelihood: -12150.43117859543\n",
      "    val_log_marginal: -12158.876157175118\n",
      "Train Epoch: 2182 [256/118836 (0%)] Loss: 12273.970703\n",
      "Train Epoch: 2182 [33024/118836 (28%)] Loss: 12311.676758\n",
      "Train Epoch: 2182 [65792/118836 (55%)] Loss: 12300.150391\n",
      "Train Epoch: 2182 [98560/118836 (83%)] Loss: 12256.413086\n",
      "    epoch          : 2182\n",
      "    loss           : 12232.417814470895\n",
      "    val_loss       : 12229.512043787376\n",
      "    val_log_likelihood: -12153.506029485887\n",
      "    val_log_marginal: -12162.01505796147\n",
      "Train Epoch: 2183 [256/118836 (0%)] Loss: 12277.501953\n",
      "Train Epoch: 2183 [33024/118836 (28%)] Loss: 12302.358398\n",
      "Train Epoch: 2183 [65792/118836 (55%)] Loss: 12287.108398\n",
      "Train Epoch: 2183 [98560/118836 (83%)] Loss: 12254.101562\n",
      "    epoch          : 2183\n",
      "    loss           : 12230.43462297741\n",
      "    val_loss       : 12227.14362677719\n",
      "    val_log_likelihood: -12150.97884405371\n",
      "    val_log_marginal: -12159.283771128776\n",
      "Train Epoch: 2184 [256/118836 (0%)] Loss: 12204.005859\n",
      "Train Epoch: 2184 [33024/118836 (28%)] Loss: 12257.880859\n",
      "Train Epoch: 2184 [65792/118836 (55%)] Loss: 12208.200195\n",
      "Train Epoch: 2184 [98560/118836 (83%)] Loss: 12196.617188\n",
      "    epoch          : 2184\n",
      "    loss           : 12232.863683668063\n",
      "    val_loss       : 12230.733146086852\n",
      "    val_log_likelihood: -12150.34305227073\n",
      "    val_log_marginal: -12158.749734636685\n",
      "Train Epoch: 2185 [256/118836 (0%)] Loss: 12221.106445\n",
      "Train Epoch: 2185 [33024/118836 (28%)] Loss: 12266.328125\n",
      "Train Epoch: 2185 [65792/118836 (55%)] Loss: 12312.807617\n",
      "Train Epoch: 2185 [98560/118836 (83%)] Loss: 12216.500000\n",
      "    epoch          : 2185\n",
      "    loss           : 12231.462126983819\n",
      "    val_loss       : 12236.826580773944\n",
      "    val_log_likelihood: -12151.77466187836\n",
      "    val_log_marginal: -12160.244325724185\n",
      "Train Epoch: 2186 [256/118836 (0%)] Loss: 12159.490234\n",
      "Train Epoch: 2186 [33024/118836 (28%)] Loss: 12274.523438\n",
      "Train Epoch: 2186 [65792/118836 (55%)] Loss: 12262.185547\n",
      "Train Epoch: 2186 [98560/118836 (83%)] Loss: 12335.400391\n",
      "    epoch          : 2186\n",
      "    loss           : 12228.797661419561\n",
      "    val_loss       : 12234.15691682481\n",
      "    val_log_likelihood: -12151.650404518197\n",
      "    val_log_marginal: -12160.200502222555\n",
      "Train Epoch: 2187 [256/118836 (0%)] Loss: 12232.965820\n",
      "Train Epoch: 2187 [33024/118836 (28%)] Loss: 12206.784180\n",
      "Train Epoch: 2187 [65792/118836 (55%)] Loss: 12286.993164\n",
      "Train Epoch: 2187 [98560/118836 (83%)] Loss: 12211.109375\n",
      "    epoch          : 2187\n",
      "    loss           : 12231.475001453939\n",
      "    val_loss       : 12226.789444449403\n",
      "    val_log_likelihood: -12150.297649949596\n",
      "    val_log_marginal: -12158.682515163478\n",
      "Train Epoch: 2188 [256/118836 (0%)] Loss: 12282.556641\n",
      "Train Epoch: 2188 [33024/118836 (28%)] Loss: 12172.575195\n",
      "Train Epoch: 2188 [65792/118836 (55%)] Loss: 12258.876953\n",
      "Train Epoch: 2188 [98560/118836 (83%)] Loss: 12287.568359\n",
      "    epoch          : 2188\n",
      "    loss           : 12230.265481221568\n",
      "    val_loss       : 12233.686231084424\n",
      "    val_log_likelihood: -12151.97595362257\n",
      "    val_log_marginal: -12160.365483092157\n",
      "Train Epoch: 2189 [256/118836 (0%)] Loss: 12262.156250\n",
      "Train Epoch: 2189 [33024/118836 (28%)] Loss: 12327.767578\n",
      "Train Epoch: 2189 [65792/118836 (55%)] Loss: 12246.445312\n",
      "Train Epoch: 2189 [98560/118836 (83%)] Loss: 12257.353516\n",
      "    epoch          : 2189\n",
      "    loss           : 12232.713287388853\n",
      "    val_loss       : 12234.697112410124\n",
      "    val_log_likelihood: -12153.155213341346\n",
      "    val_log_marginal: -12161.624188334308\n",
      "Train Epoch: 2190 [256/118836 (0%)] Loss: 12315.195312\n",
      "Train Epoch: 2190 [33024/118836 (28%)] Loss: 12260.363281\n",
      "Train Epoch: 2190 [65792/118836 (55%)] Loss: 12273.540039\n",
      "Train Epoch: 2190 [98560/118836 (83%)] Loss: 12180.208008\n",
      "    epoch          : 2190\n",
      "    loss           : 12229.932908621537\n",
      "    val_loss       : 12229.606654554524\n",
      "    val_log_likelihood: -12149.789985751397\n",
      "    val_log_marginal: -12158.308403099518\n",
      "Train Epoch: 2191 [256/118836 (0%)] Loss: 12258.553711\n",
      "Train Epoch: 2191 [33024/118836 (28%)] Loss: 12235.628906\n",
      "Train Epoch: 2191 [65792/118836 (55%)] Loss: 12229.508789\n",
      "Train Epoch: 2191 [98560/118836 (83%)] Loss: 12312.730469\n",
      "    epoch          : 2191\n",
      "    loss           : 12228.689188184968\n",
      "    val_loss       : 12230.60106446895\n",
      "    val_log_likelihood: -12152.150417926747\n",
      "    val_log_marginal: -12160.508188461621\n",
      "Train Epoch: 2192 [256/118836 (0%)] Loss: 12225.699219\n",
      "Train Epoch: 2192 [33024/118836 (28%)] Loss: 12226.195312\n",
      "Train Epoch: 2192 [65792/118836 (55%)] Loss: 12327.076172\n",
      "Train Epoch: 2192 [98560/118836 (83%)] Loss: 12374.605469\n",
      "    epoch          : 2192\n",
      "    loss           : 12231.0816340015\n",
      "    val_loss       : 12229.241239078032\n",
      "    val_log_likelihood: -12151.196135752689\n",
      "    val_log_marginal: -12159.624603353182\n",
      "Train Epoch: 2193 [256/118836 (0%)] Loss: 12280.089844\n",
      "Train Epoch: 2193 [33024/118836 (28%)] Loss: 12255.564453\n",
      "Train Epoch: 2193 [65792/118836 (55%)] Loss: 12277.979492\n",
      "Train Epoch: 2193 [98560/118836 (83%)] Loss: 12265.902344\n",
      "    epoch          : 2193\n",
      "    loss           : 12231.172264494158\n",
      "    val_loss       : 12229.936845024915\n",
      "    val_log_likelihood: -12150.268982468724\n",
      "    val_log_marginal: -12158.655277217833\n",
      "Train Epoch: 2194 [256/118836 (0%)] Loss: 12202.322266\n",
      "Train Epoch: 2194 [33024/118836 (28%)] Loss: 12138.678711\n",
      "Train Epoch: 2194 [65792/118836 (55%)] Loss: 12171.773438\n",
      "Train Epoch: 2194 [98560/118836 (83%)] Loss: 12217.908203\n",
      "    epoch          : 2194\n",
      "    loss           : 12230.04569100884\n",
      "    val_loss       : 12232.27522058249\n",
      "    val_log_likelihood: -12151.182712662841\n",
      "    val_log_marginal: -12159.627985548028\n",
      "Train Epoch: 2195 [256/118836 (0%)] Loss: 12283.473633\n",
      "Train Epoch: 2195 [33024/118836 (28%)] Loss: 12293.457031\n",
      "Train Epoch: 2195 [65792/118836 (55%)] Loss: 12242.170898\n",
      "Train Epoch: 2195 [98560/118836 (83%)] Loss: 12336.598633\n",
      "    epoch          : 2195\n",
      "    loss           : 12228.849776739557\n",
      "    val_loss       : 12230.221758989901\n",
      "    val_log_likelihood: -12152.538412427626\n",
      "    val_log_marginal: -12160.982548869664\n",
      "Train Epoch: 2196 [256/118836 (0%)] Loss: 12339.767578\n",
      "Train Epoch: 2196 [33024/118836 (28%)] Loss: 12187.067383\n",
      "Train Epoch: 2196 [65792/118836 (55%)] Loss: 12270.500000\n",
      "Train Epoch: 2196 [98560/118836 (83%)] Loss: 12209.966797\n",
      "    epoch          : 2196\n",
      "    loss           : 12230.22871643016\n",
      "    val_loss       : 12233.866994363822\n",
      "    val_log_likelihood: -12149.699808241574\n",
      "    val_log_marginal: -12157.983828042321\n",
      "Train Epoch: 2197 [256/118836 (0%)] Loss: 12300.643555\n",
      "Train Epoch: 2197 [33024/118836 (28%)] Loss: 12187.893555\n",
      "Train Epoch: 2197 [65792/118836 (55%)] Loss: 12224.958984\n",
      "Train Epoch: 2197 [98560/118836 (83%)] Loss: 12307.299805\n",
      "    epoch          : 2197\n",
      "    loss           : 12231.622903742764\n",
      "    val_loss       : 12233.03304706143\n",
      "    val_log_likelihood: -12149.827664424369\n",
      "    val_log_marginal: -12158.113205264737\n",
      "Train Epoch: 2198 [256/118836 (0%)] Loss: 12269.156250\n",
      "Train Epoch: 2198 [33024/118836 (28%)] Loss: 12266.815430\n",
      "Train Epoch: 2198 [65792/118836 (55%)] Loss: 12186.832031\n",
      "Train Epoch: 2198 [98560/118836 (83%)] Loss: 12164.150391\n",
      "    epoch          : 2198\n",
      "    loss           : 12228.617469725754\n",
      "    val_loss       : 12231.291560675738\n",
      "    val_log_likelihood: -12153.73871210065\n",
      "    val_log_marginal: -12162.19217918145\n",
      "Train Epoch: 2199 [256/118836 (0%)] Loss: 12202.285156\n",
      "Train Epoch: 2199 [33024/118836 (28%)] Loss: 12290.478516\n",
      "Train Epoch: 2199 [65792/118836 (55%)] Loss: 12240.069336\n",
      "Train Epoch: 2199 [98560/118836 (83%)] Loss: 12239.619141\n",
      "    epoch          : 2199\n",
      "    loss           : 12240.452548270781\n",
      "    val_loss       : 12234.150111084147\n",
      "    val_log_likelihood: -12151.762850883995\n",
      "    val_log_marginal: -12160.353597940972\n",
      "Train Epoch: 2200 [256/118836 (0%)] Loss: 12206.783203\n",
      "Train Epoch: 2200 [33024/118836 (28%)] Loss: 12394.121094\n",
      "Train Epoch: 2200 [65792/118836 (55%)] Loss: 12140.649414\n",
      "Train Epoch: 2200 [98560/118836 (83%)] Loss: 12360.550781\n",
      "    epoch          : 2200\n",
      "    loss           : 12233.997490177831\n",
      "    val_loss       : 12231.60589295155\n",
      "    val_log_likelihood: -12152.463028264578\n",
      "    val_log_marginal: -12161.261101649463\n",
      "Saving checkpoint: saved/models/SelfiesAutoencodingOperad/0905_154251/checkpoint-epoch2200.pth ...\n",
      "Train Epoch: 2201 [256/118836 (0%)] Loss: 12260.385742\n",
      "Train Epoch: 2201 [33024/118836 (28%)] Loss: 12275.783203\n",
      "Train Epoch: 2201 [65792/118836 (55%)] Loss: 12227.582031\n",
      "Train Epoch: 2201 [98560/118836 (83%)] Loss: 12242.707031\n",
      "    epoch          : 2201\n",
      "    loss           : 12233.883867898316\n",
      "    val_loss       : 12234.918509461655\n",
      "    val_log_likelihood: -12152.103636140404\n",
      "    val_log_marginal: -12160.634491971678\n",
      "Train Epoch: 2202 [256/118836 (0%)] Loss: 12202.753906\n",
      "Train Epoch: 2202 [33024/118836 (28%)] Loss: 12264.058594\n",
      "Train Epoch: 2202 [65792/118836 (55%)] Loss: 12242.823242\n",
      "Train Epoch: 2202 [98560/118836 (83%)] Loss: 12211.393555\n",
      "    epoch          : 2202\n",
      "    loss           : 12233.857451761529\n",
      "    val_loss       : 12240.47643897035\n",
      "    val_log_likelihood: -12153.055558571134\n",
      "    val_log_marginal: -12161.744055868887\n",
      "Train Epoch: 2203 [256/118836 (0%)] Loss: 12373.785156\n",
      "Train Epoch: 2203 [33024/118836 (28%)] Loss: 12256.535156\n",
      "Train Epoch: 2203 [65792/118836 (55%)] Loss: 12300.855469\n",
      "Train Epoch: 2203 [98560/118836 (83%)] Loss: 12286.250000\n",
      "    epoch          : 2203\n",
      "    loss           : 12233.77771822012\n",
      "    val_loss       : 12231.157407848457\n",
      "    val_log_likelihood: -12151.479235163359\n",
      "    val_log_marginal: -12160.069157720838\n",
      "Train Epoch: 2204 [256/118836 (0%)] Loss: 12197.722656\n",
      "Train Epoch: 2204 [33024/118836 (28%)] Loss: 12193.310547\n",
      "Train Epoch: 2204 [65792/118836 (55%)] Loss: 12225.679688\n",
      "Train Epoch: 2204 [98560/118836 (83%)] Loss: 12286.937500\n",
      "    epoch          : 2204\n",
      "    loss           : 12230.115019838193\n",
      "    val_loss       : 12228.814827656808\n",
      "    val_log_likelihood: -12149.226757327853\n",
      "    val_log_marginal: -12157.684934986903\n",
      "Train Epoch: 2205 [256/118836 (0%)] Loss: 12215.676758\n",
      "Train Epoch: 2205 [33024/118836 (28%)] Loss: 12240.683594\n",
      "Train Epoch: 2205 [65792/118836 (55%)] Loss: 12217.925781\n",
      "Train Epoch: 2205 [98560/118836 (83%)] Loss: 12300.005859\n",
      "    epoch          : 2205\n",
      "    loss           : 12238.748712940704\n",
      "    val_loss       : 12235.321134217329\n",
      "    val_log_likelihood: -12154.33109248992\n",
      "    val_log_marginal: -12163.11251225644\n",
      "Train Epoch: 2206 [256/118836 (0%)] Loss: 12224.533203\n",
      "Train Epoch: 2206 [33024/118836 (28%)] Loss: 12215.845703\n",
      "Train Epoch: 2206 [65792/118836 (55%)] Loss: 12212.874023\n",
      "Train Epoch: 2206 [98560/118836 (83%)] Loss: 12205.677734\n",
      "    epoch          : 2206\n",
      "    loss           : 12230.77574764785\n",
      "    val_loss       : 12232.288492510705\n",
      "    val_log_likelihood: -12151.087756054849\n",
      "    val_log_marginal: -12159.570672874119\n",
      "Train Epoch: 2207 [256/118836 (0%)] Loss: 12323.179688\n",
      "Train Epoch: 2207 [33024/118836 (28%)] Loss: 12181.668945\n",
      "Train Epoch: 2207 [65792/118836 (55%)] Loss: 12360.106445\n",
      "Train Epoch: 2207 [98560/118836 (83%)] Loss: 12253.980469\n",
      "    epoch          : 2207\n",
      "    loss           : 12234.218076341502\n",
      "    val_loss       : 12237.703409444961\n",
      "    val_log_likelihood: -12157.465201903691\n",
      "    val_log_marginal: -12166.351567976659\n",
      "Train Epoch: 2208 [256/118836 (0%)] Loss: 12418.518555\n",
      "Train Epoch: 2208 [33024/118836 (28%)] Loss: 12206.740234\n",
      "Train Epoch: 2208 [65792/118836 (55%)] Loss: 12322.837891\n",
      "Train Epoch: 2208 [98560/118836 (83%)] Loss: 12239.301758\n",
      "    epoch          : 2208\n",
      "    loss           : 12238.70048884667\n",
      "    val_loss       : 12234.659598139575\n",
      "    val_log_likelihood: -12153.2883620244\n",
      "    val_log_marginal: -12161.924559101726\n",
      "Train Epoch: 2209 [256/118836 (0%)] Loss: 12304.938477\n",
      "Train Epoch: 2209 [33024/118836 (28%)] Loss: 12317.013672\n",
      "Train Epoch: 2209 [65792/118836 (55%)] Loss: 12250.640625\n",
      "Train Epoch: 2209 [98560/118836 (83%)] Loss: 12268.533203\n",
      "    epoch          : 2209\n",
      "    loss           : 12230.756960976272\n",
      "    val_loss       : 12231.667045940445\n",
      "    val_log_likelihood: -12149.064128735008\n",
      "    val_log_marginal: -12157.482681208168\n",
      "Train Epoch: 2210 [256/118836 (0%)] Loss: 12187.504883\n",
      "Train Epoch: 2210 [33024/118836 (28%)] Loss: 12156.932617\n",
      "Train Epoch: 2210 [65792/118836 (55%)] Loss: 12240.628906\n",
      "Train Epoch: 2210 [98560/118836 (83%)] Loss: 12314.601562\n",
      "    epoch          : 2210\n",
      "    loss           : 12229.41104266827\n",
      "    val_loss       : 12232.816223908318\n",
      "    val_log_likelihood: -12151.81635213115\n",
      "    val_log_marginal: -12160.134511351042\n",
      "Train Epoch: 2211 [256/118836 (0%)] Loss: 12253.527344\n",
      "Train Epoch: 2211 [33024/118836 (28%)] Loss: 12315.714844\n",
      "Train Epoch: 2211 [65792/118836 (55%)] Loss: 12222.415039\n",
      "Train Epoch: 2211 [98560/118836 (83%)] Loss: 12263.151367\n",
      "    epoch          : 2211\n",
      "    loss           : 12228.239566047612\n",
      "    val_loss       : 12229.825503369668\n",
      "    val_log_likelihood: -12154.280571979683\n",
      "    val_log_marginal: -12162.747607678535\n",
      "Train Epoch: 2212 [256/118836 (0%)] Loss: 12229.923828\n",
      "Train Epoch: 2212 [33024/118836 (28%)] Loss: 12306.136719\n",
      "Train Epoch: 2212 [65792/118836 (55%)] Loss: 12175.669922\n",
      "Train Epoch: 2212 [98560/118836 (83%)] Loss: 12230.612305\n",
      "    epoch          : 2212\n",
      "    loss           : 12234.322476446185\n",
      "    val_loss       : 12227.93229907269\n",
      "    val_log_likelihood: -12152.829142434346\n",
      "    val_log_marginal: -12161.220161625508\n",
      "Train Epoch: 2213 [256/118836 (0%)] Loss: 12284.012695\n",
      "Train Epoch: 2213 [33024/118836 (28%)] Loss: 12355.531250\n",
      "Train Epoch: 2213 [65792/118836 (55%)] Loss: 12275.998047\n",
      "Train Epoch: 2213 [98560/118836 (83%)] Loss: 12196.094727\n",
      "    epoch          : 2213\n",
      "    loss           : 12233.873100347653\n",
      "    val_loss       : 12232.786710385919\n",
      "    val_log_likelihood: -12149.730241773934\n",
      "    val_log_marginal: -12158.081151232998\n",
      "Train Epoch: 2214 [256/118836 (0%)] Loss: 12178.172852\n",
      "Train Epoch: 2214 [33024/118836 (28%)] Loss: 12343.101562\n",
      "Train Epoch: 2214 [65792/118836 (55%)] Loss: 12248.737305\n",
      "Train Epoch: 2214 [98560/118836 (83%)] Loss: 12304.425781\n",
      "    epoch          : 2214\n",
      "    loss           : 12230.359224759615\n",
      "    val_loss       : 12231.288898354389\n",
      "    val_log_likelihood: -12150.396799718259\n",
      "    val_log_marginal: -12158.803366110335\n",
      "Train Epoch: 2215 [256/118836 (0%)] Loss: 12324.712891\n",
      "Train Epoch: 2215 [33024/118836 (28%)] Loss: 12355.217773\n",
      "Train Epoch: 2215 [65792/118836 (55%)] Loss: 12253.541992\n",
      "Train Epoch: 2215 [98560/118836 (83%)] Loss: 12286.531250\n",
      "    epoch          : 2215\n",
      "    loss           : 12228.039139235681\n",
      "    val_loss       : 12230.544000811995\n",
      "    val_log_likelihood: -12150.511744597809\n",
      "    val_log_marginal: -12159.00074188375\n",
      "Train Epoch: 2216 [256/118836 (0%)] Loss: 12239.609375\n",
      "Train Epoch: 2216 [33024/118836 (28%)] Loss: 12311.970703\n",
      "Train Epoch: 2216 [65792/118836 (55%)] Loss: 12202.708984\n",
      "Train Epoch: 2216 [98560/118836 (83%)] Loss: 12198.423828\n",
      "    epoch          : 2216\n",
      "    loss           : 12228.3952651662\n",
      "    val_loss       : 12231.336872517692\n",
      "    val_log_likelihood: -12150.81723192592\n",
      "    val_log_marginal: -12159.140815384386\n",
      "Train Epoch: 2217 [256/118836 (0%)] Loss: 12270.636719\n",
      "Train Epoch: 2217 [33024/118836 (28%)] Loss: 12255.703125\n",
      "Train Epoch: 2217 [65792/118836 (55%)] Loss: 12228.334961\n",
      "Train Epoch: 2217 [98560/118836 (83%)] Loss: 12172.323242\n",
      "    epoch          : 2217\n",
      "    loss           : 12231.09586208902\n",
      "    val_loss       : 12226.635201824156\n",
      "    val_log_likelihood: -12153.020992297354\n",
      "    val_log_marginal: -12161.411907297712\n",
      "Train Epoch: 2218 [256/118836 (0%)] Loss: 12246.928711\n",
      "Train Epoch: 2218 [33024/118836 (28%)] Loss: 12248.875000\n",
      "Train Epoch: 2218 [65792/118836 (55%)] Loss: 12329.986328\n",
      "Train Epoch: 2218 [98560/118836 (83%)] Loss: 12203.358398\n",
      "    epoch          : 2218\n",
      "    loss           : 12235.384709244468\n",
      "    val_loss       : 12233.809832069624\n",
      "    val_log_likelihood: -12149.329047766749\n",
      "    val_log_marginal: -12158.033162415222\n",
      "Train Epoch: 2219 [256/118836 (0%)] Loss: 12246.417969\n",
      "Train Epoch: 2219 [33024/118836 (28%)] Loss: 12290.961914\n",
      "Train Epoch: 2219 [65792/118836 (55%)] Loss: 12222.339844\n",
      "Train Epoch: 2219 [98560/118836 (83%)] Loss: 12270.978516\n",
      "    epoch          : 2219\n",
      "    loss           : 12235.412342974565\n",
      "    val_loss       : 12229.322473261765\n",
      "    val_log_likelihood: -12150.870150143455\n",
      "    val_log_marginal: -12159.370491127262\n",
      "Train Epoch: 2220 [256/118836 (0%)] Loss: 12220.654297\n",
      "Train Epoch: 2220 [33024/118836 (28%)] Loss: 12383.797852\n",
      "Train Epoch: 2220 [65792/118836 (55%)] Loss: 12300.992188\n",
      "Train Epoch: 2220 [98560/118836 (83%)] Loss: 12227.369141\n",
      "    epoch          : 2220\n",
      "    loss           : 12232.226848926022\n",
      "    val_loss       : 12233.148723100041\n",
      "    val_log_likelihood: -12149.045168883116\n",
      "    val_log_marginal: -12157.35842387915\n",
      "Train Epoch: 2221 [256/118836 (0%)] Loss: 12185.145508\n",
      "Train Epoch: 2221 [33024/118836 (28%)] Loss: 12206.449219\n",
      "Train Epoch: 2221 [65792/118836 (55%)] Loss: 12263.151367\n",
      "Train Epoch: 2221 [98560/118836 (83%)] Loss: 12258.026367\n",
      "    epoch          : 2221\n",
      "    loss           : 12231.760358024452\n",
      "    val_loss       : 12232.900482325816\n",
      "    val_log_likelihood: -12150.264615804643\n",
      "    val_log_marginal: -12158.816659215614\n",
      "Train Epoch: 2222 [256/118836 (0%)] Loss: 12283.454102\n",
      "Train Epoch: 2222 [33024/118836 (28%)] Loss: 12299.689453\n",
      "Train Epoch: 2222 [65792/118836 (55%)] Loss: 12241.637695\n",
      "Train Epoch: 2222 [98560/118836 (83%)] Loss: 12262.546875\n",
      "    epoch          : 2222\n",
      "    loss           : 12233.763673328938\n",
      "    val_loss       : 12229.68552210059\n",
      "    val_log_likelihood: -12150.185553336953\n",
      "    val_log_marginal: -12158.639499295963\n",
      "Train Epoch: 2223 [256/118836 (0%)] Loss: 12202.382812\n",
      "Train Epoch: 2223 [33024/118836 (28%)] Loss: 12289.792969\n",
      "Train Epoch: 2223 [65792/118836 (55%)] Loss: 12162.408203\n",
      "Train Epoch: 2223 [98560/118836 (83%)] Loss: 12210.787109\n",
      "    epoch          : 2223\n",
      "    loss           : 12232.407176320823\n",
      "    val_loss       : 12237.348041320514\n",
      "    val_log_likelihood: -12152.910441222084\n",
      "    val_log_marginal: -12161.382065641996\n",
      "Train Epoch: 2224 [256/118836 (0%)] Loss: 12222.931641\n",
      "Train Epoch: 2224 [33024/118836 (28%)] Loss: 12198.444336\n",
      "Train Epoch: 2224 [65792/118836 (55%)] Loss: 12264.533203\n",
      "Train Epoch: 2224 [98560/118836 (83%)] Loss: 12240.904297\n",
      "    epoch          : 2224\n",
      "    loss           : 12229.86792157775\n",
      "    val_loss       : 12233.11872877774\n",
      "    val_log_likelihood: -12148.727973628773\n",
      "    val_log_marginal: -12157.090199869233\n",
      "Train Epoch: 2225 [256/118836 (0%)] Loss: 12196.972656\n",
      "Train Epoch: 2225 [33024/118836 (28%)] Loss: 12267.969727\n",
      "Train Epoch: 2225 [65792/118836 (55%)] Loss: 12200.919922\n",
      "Train Epoch: 2225 [98560/118836 (83%)] Loss: 12365.789062\n",
      "    epoch          : 2225\n",
      "    loss           : 12230.877475573821\n",
      "    val_loss       : 12230.228323907495\n",
      "    val_log_likelihood: -12152.429917383943\n",
      "    val_log_marginal: -12160.69098230769\n",
      "Train Epoch: 2226 [256/118836 (0%)] Loss: 12180.459961\n",
      "Train Epoch: 2226 [33024/118836 (28%)] Loss: 12237.263672\n",
      "Train Epoch: 2226 [65792/118836 (55%)] Loss: 12219.595703\n",
      "Train Epoch: 2226 [98560/118836 (83%)] Loss: 12221.693359\n",
      "    epoch          : 2226\n",
      "    loss           : 12229.78848609388\n",
      "    val_loss       : 12231.662957120834\n",
      "    val_log_likelihood: -12152.70962006953\n",
      "    val_log_marginal: -12161.215379577052\n",
      "Train Epoch: 2227 [256/118836 (0%)] Loss: 12209.973633\n",
      "Train Epoch: 2227 [33024/118836 (28%)] Loss: 12189.582031\n",
      "Train Epoch: 2227 [65792/118836 (55%)] Loss: 12316.681641\n",
      "Train Epoch: 2227 [98560/118836 (83%)] Loss: 12350.602539\n",
      "    epoch          : 2227\n",
      "    loss           : 12234.826827601582\n",
      "    val_loss       : 12231.40250049536\n",
      "    val_log_likelihood: -12152.595233502636\n",
      "    val_log_marginal: -12161.026717047927\n",
      "Train Epoch: 2228 [256/118836 (0%)] Loss: 12235.022461\n",
      "Train Epoch: 2228 [33024/118836 (28%)] Loss: 12185.878906\n",
      "Train Epoch: 2228 [65792/118836 (55%)] Loss: 12251.383789\n",
      "Train Epoch: 2228 [98560/118836 (83%)] Loss: 12238.075195\n",
      "    epoch          : 2228\n",
      "    loss           : 12232.943819950631\n",
      "    val_loss       : 12234.453932942619\n",
      "    val_log_likelihood: -12151.530769876963\n",
      "    val_log_marginal: -12160.043871888774\n",
      "Train Epoch: 2229 [256/118836 (0%)] Loss: 12244.779297\n",
      "Train Epoch: 2229 [33024/118836 (28%)] Loss: 12286.758789\n",
      "Train Epoch: 2229 [65792/118836 (55%)] Loss: 12229.000977\n",
      "Train Epoch: 2229 [98560/118836 (83%)] Loss: 12284.554688\n",
      "    epoch          : 2229\n",
      "    loss           : 12230.395196831058\n",
      "    val_loss       : 12233.910096417721\n",
      "    val_log_likelihood: -12153.27281650641\n",
      "    val_log_marginal: -12161.786506791464\n",
      "Train Epoch: 2230 [256/118836 (0%)] Loss: 12224.117188\n",
      "Train Epoch: 2230 [33024/118836 (28%)] Loss: 12203.964844\n",
      "Train Epoch: 2230 [65792/118836 (55%)] Loss: 12257.605469\n",
      "Train Epoch: 2230 [98560/118836 (83%)] Loss: 12206.284180\n",
      "    epoch          : 2230\n",
      "    loss           : 12234.194582945616\n",
      "    val_loss       : 12228.886149073087\n",
      "    val_log_likelihood: -12150.077663778173\n",
      "    val_log_marginal: -12158.61391829592\n",
      "Train Epoch: 2231 [256/118836 (0%)] Loss: 12222.558594\n",
      "Train Epoch: 2231 [33024/118836 (28%)] Loss: 12218.320312\n",
      "Train Epoch: 2231 [65792/118836 (55%)] Loss: 12290.337891\n",
      "Train Epoch: 2231 [98560/118836 (83%)] Loss: 12304.429688\n",
      "    epoch          : 2231\n",
      "    loss           : 12224.194820583902\n",
      "    val_loss       : 12226.53440406787\n",
      "    val_log_likelihood: -12152.76270759021\n",
      "    val_log_marginal: -12161.095587537637\n",
      "Train Epoch: 2232 [256/118836 (0%)] Loss: 12302.415039\n",
      "Train Epoch: 2232 [33024/118836 (28%)] Loss: 12311.898438\n",
      "Train Epoch: 2232 [65792/118836 (55%)] Loss: 12249.206055\n",
      "Train Epoch: 2232 [98560/118836 (83%)] Loss: 12205.505859\n",
      "    epoch          : 2232\n",
      "    loss           : 12233.491608832195\n",
      "    val_loss       : 12230.905195911777\n",
      "    val_log_likelihood: -12151.623905829973\n",
      "    val_log_marginal: -12160.23910381997\n",
      "Train Epoch: 2233 [256/118836 (0%)] Loss: 12153.079102\n",
      "Train Epoch: 2233 [33024/118836 (28%)] Loss: 12250.269531\n",
      "Train Epoch: 2233 [65792/118836 (55%)] Loss: 12190.000977\n",
      "Train Epoch: 2233 [98560/118836 (83%)] Loss: 12200.651367\n",
      "    epoch          : 2233\n",
      "    loss           : 12237.69735431529\n",
      "    val_loss       : 12231.31839260912\n",
      "    val_log_likelihood: -12152.387652986716\n",
      "    val_log_marginal: -12160.951405429738\n",
      "Train Epoch: 2234 [256/118836 (0%)] Loss: 12255.597656\n",
      "Train Epoch: 2234 [33024/118836 (28%)] Loss: 12155.881836\n",
      "Train Epoch: 2234 [65792/118836 (55%)] Loss: 12302.759766\n",
      "Train Epoch: 2234 [98560/118836 (83%)] Loss: 12214.103516\n",
      "    epoch          : 2234\n",
      "    loss           : 12232.808836719396\n",
      "    val_loss       : 12235.078556429235\n",
      "    val_log_likelihood: -12150.658064677678\n",
      "    val_log_marginal: -12159.147599240445\n",
      "Train Epoch: 2235 [256/118836 (0%)] Loss: 12270.419922\n",
      "Train Epoch: 2235 [33024/118836 (28%)] Loss: 12184.658203\n",
      "Train Epoch: 2235 [65792/118836 (55%)] Loss: 12249.721680\n",
      "Train Epoch: 2235 [98560/118836 (83%)] Loss: 12196.658203\n",
      "    epoch          : 2235\n",
      "    loss           : 12231.973833133012\n",
      "    val_loss       : 12231.847354320318\n",
      "    val_log_likelihood: -12151.55855061647\n",
      "    val_log_marginal: -12159.842413205179\n",
      "Train Epoch: 2236 [256/118836 (0%)] Loss: 12175.807617\n",
      "Train Epoch: 2236 [33024/118836 (28%)] Loss: 12320.660156\n",
      "Train Epoch: 2236 [65792/118836 (55%)] Loss: 12239.052734\n",
      "Train Epoch: 2236 [98560/118836 (83%)] Loss: 12148.243164\n",
      "    epoch          : 2236\n",
      "    loss           : 12230.57325559605\n",
      "    val_loss       : 12229.66752545895\n",
      "    val_log_likelihood: -12151.136987082558\n",
      "    val_log_marginal: -12159.52716441044\n",
      "Train Epoch: 2237 [256/118836 (0%)] Loss: 12202.767578\n",
      "Train Epoch: 2237 [33024/118836 (28%)] Loss: 12363.433594\n",
      "Train Epoch: 2237 [65792/118836 (55%)] Loss: 12221.098633\n",
      "Train Epoch: 2237 [98560/118836 (83%)] Loss: 12180.494141\n",
      "    epoch          : 2237\n",
      "    loss           : 12231.241908989867\n",
      "    val_loss       : 12237.66678107287\n",
      "    val_log_likelihood: -12156.803439373965\n",
      "    val_log_marginal: -12165.312607524647\n",
      "Train Epoch: 2238 [256/118836 (0%)] Loss: 12208.508789\n",
      "Train Epoch: 2238 [33024/118836 (28%)] Loss: 12314.121094\n",
      "Train Epoch: 2238 [65792/118836 (55%)] Loss: 12217.333984\n",
      "Train Epoch: 2238 [98560/118836 (83%)] Loss: 12216.063477\n",
      "    epoch          : 2238\n",
      "    loss           : 12232.064437131668\n",
      "    val_loss       : 12233.565248729703\n",
      "    val_log_likelihood: -12151.97438595301\n",
      "    val_log_marginal: -12160.398849276962\n",
      "Train Epoch: 2239 [256/118836 (0%)] Loss: 12221.177734\n",
      "Train Epoch: 2239 [33024/118836 (28%)] Loss: 12211.437500\n",
      "Train Epoch: 2239 [65792/118836 (55%)] Loss: 12235.840820\n",
      "Train Epoch: 2239 [98560/118836 (83%)] Loss: 12304.968750\n",
      "    epoch          : 2239\n",
      "    loss           : 12228.819531573097\n",
      "    val_loss       : 12232.20390508433\n",
      "    val_log_likelihood: -12153.605666162635\n",
      "    val_log_marginal: -12161.968478789699\n",
      "Train Epoch: 2240 [256/118836 (0%)] Loss: 12186.275391\n",
      "Train Epoch: 2240 [33024/118836 (28%)] Loss: 12214.843750\n",
      "Train Epoch: 2240 [65792/118836 (55%)] Loss: 12255.447266\n",
      "Train Epoch: 2240 [98560/118836 (83%)] Loss: 12181.576172\n",
      "    epoch          : 2240\n",
      "    loss           : 12228.293481667442\n",
      "    val_loss       : 12233.772324955373\n",
      "    val_log_likelihood: -12153.013166065704\n",
      "    val_log_marginal: -12161.527070804368\n",
      "Train Epoch: 2241 [256/118836 (0%)] Loss: 12207.595703\n",
      "Train Epoch: 2241 [33024/118836 (28%)] Loss: 12236.411133\n",
      "Train Epoch: 2241 [65792/118836 (55%)] Loss: 12245.574219\n",
      "Train Epoch: 2241 [98560/118836 (83%)] Loss: 12228.613281\n",
      "    epoch          : 2241\n",
      "    loss           : 12232.18326257496\n",
      "    val_loss       : 12234.824671036205\n",
      "    val_log_likelihood: -12150.190421933157\n",
      "    val_log_marginal: -12158.648878406868\n",
      "Train Epoch: 2242 [256/118836 (0%)] Loss: 12355.856445\n",
      "Train Epoch: 2242 [33024/118836 (28%)] Loss: 12162.177734\n",
      "Train Epoch: 2242 [65792/118836 (55%)] Loss: 12226.615234\n",
      "Train Epoch: 2242 [98560/118836 (83%)] Loss: 12210.791016\n",
      "    epoch          : 2242\n",
      "    loss           : 12232.373038312913\n",
      "    val_loss       : 12227.886162558023\n",
      "    val_log_likelihood: -12149.412851045543\n",
      "    val_log_marginal: -12157.72779332299\n",
      "Train Epoch: 2243 [256/118836 (0%)] Loss: 12238.826172\n",
      "Train Epoch: 2243 [33024/118836 (28%)] Loss: 12185.220703\n",
      "Train Epoch: 2243 [65792/118836 (55%)] Loss: 12229.026367\n",
      "Train Epoch: 2243 [98560/118836 (83%)] Loss: 12217.927734\n",
      "    epoch          : 2243\n",
      "    loss           : 12232.159423949288\n",
      "    val_loss       : 12235.188774568041\n",
      "    val_log_likelihood: -12153.6652681387\n",
      "    val_log_marginal: -12162.114564166262\n",
      "Train Epoch: 2244 [256/118836 (0%)] Loss: 12222.108398\n",
      "Train Epoch: 2244 [33024/118836 (28%)] Loss: 12334.504883\n",
      "Train Epoch: 2244 [65792/118836 (55%)] Loss: 12188.521484\n",
      "Train Epoch: 2244 [98560/118836 (83%)] Loss: 12196.960938\n",
      "    epoch          : 2244\n",
      "    loss           : 12229.181191357786\n",
      "    val_loss       : 12234.979329368638\n",
      "    val_log_likelihood: -12154.984422172249\n",
      "    val_log_marginal: -12163.423993804858\n",
      "Train Epoch: 2245 [256/118836 (0%)] Loss: 12212.499023\n",
      "Train Epoch: 2245 [33024/118836 (28%)] Loss: 12319.707031\n",
      "Train Epoch: 2245 [65792/118836 (55%)] Loss: 12170.239258\n",
      "Train Epoch: 2245 [98560/118836 (83%)] Loss: 12228.012695\n",
      "    epoch          : 2245\n",
      "    loss           : 12236.08131203474\n",
      "    val_loss       : 12232.12373743623\n",
      "    val_log_likelihood: -12153.933925571237\n",
      "    val_log_marginal: -12162.532463007165\n",
      "Train Epoch: 2246 [256/118836 (0%)] Loss: 12345.948242\n",
      "Train Epoch: 2246 [33024/118836 (28%)] Loss: 12190.695312\n",
      "Train Epoch: 2246 [65792/118836 (55%)] Loss: 12190.319336\n",
      "Train Epoch: 2246 [98560/118836 (83%)] Loss: 12234.230469\n",
      "    epoch          : 2246\n",
      "    loss           : 12229.638294497003\n",
      "    val_loss       : 12229.570155139085\n",
      "    val_log_likelihood: -12151.375260416668\n",
      "    val_log_marginal: -12159.90346255702\n",
      "Train Epoch: 2247 [256/118836 (0%)] Loss: 12339.041016\n",
      "Train Epoch: 2247 [33024/118836 (28%)] Loss: 12262.675781\n",
      "Train Epoch: 2247 [65792/118836 (55%)] Loss: 12259.378906\n",
      "Train Epoch: 2247 [98560/118836 (83%)] Loss: 12246.087891\n",
      "    epoch          : 2247\n",
      "    loss           : 12234.092836926178\n",
      "    val_loss       : 12230.34618108686\n",
      "    val_log_likelihood: -12150.498774813897\n",
      "    val_log_marginal: -12159.003655968361\n",
      "Train Epoch: 2248 [256/118836 (0%)] Loss: 12184.010742\n",
      "Train Epoch: 2248 [33024/118836 (28%)] Loss: 12190.647461\n",
      "Train Epoch: 2248 [65792/118836 (55%)] Loss: 12237.429688\n",
      "Train Epoch: 2248 [98560/118836 (83%)] Loss: 12239.990234\n",
      "    epoch          : 2248\n",
      "    loss           : 12227.101146834937\n",
      "    val_loss       : 12227.627295380385\n",
      "    val_log_likelihood: -12149.806979715931\n",
      "    val_log_marginal: -12158.215515118438\n",
      "Train Epoch: 2249 [256/118836 (0%)] Loss: 12215.496094\n",
      "Train Epoch: 2249 [33024/118836 (28%)] Loss: 12179.220703\n",
      "Train Epoch: 2249 [65792/118836 (55%)] Loss: 12251.742188\n",
      "Train Epoch: 2249 [98560/118836 (83%)] Loss: 12243.941406\n",
      "    epoch          : 2249\n",
      "    loss           : 12227.147753340829\n",
      "    val_loss       : 12228.272868692638\n",
      "    val_log_likelihood: -12149.712616476685\n",
      "    val_log_marginal: -12157.980793487843\n",
      "Train Epoch: 2250 [256/118836 (0%)] Loss: 12306.304688\n",
      "Train Epoch: 2250 [33024/118836 (28%)] Loss: 12339.802734\n",
      "Train Epoch: 2250 [65792/118836 (55%)] Loss: 12226.640625\n",
      "Train Epoch: 2250 [98560/118836 (83%)] Loss: 12188.314453\n",
      "    epoch          : 2250\n",
      "    loss           : 12229.399942973274\n",
      "    val_loss       : 12230.9468158234\n",
      "    val_log_likelihood: -12150.886400498863\n",
      "    val_log_marginal: -12159.379062075346\n",
      "Train Epoch: 2251 [256/118836 (0%)] Loss: 12147.818359\n",
      "Train Epoch: 2251 [33024/118836 (28%)] Loss: 12364.103516\n",
      "Train Epoch: 2251 [65792/118836 (55%)] Loss: 12341.003906\n",
      "Train Epoch: 2251 [98560/118836 (83%)] Loss: 12187.509766\n",
      "    epoch          : 2251\n",
      "    loss           : 12232.524877869108\n",
      "    val_loss       : 12231.21741783102\n",
      "    val_log_likelihood: -12154.86017918993\n",
      "    val_log_marginal: -12163.294060866281\n",
      "Train Epoch: 2252 [256/118836 (0%)] Loss: 12315.773438\n",
      "Train Epoch: 2252 [33024/118836 (28%)] Loss: 12253.456055\n",
      "Train Epoch: 2252 [65792/118836 (55%)] Loss: 12270.067383\n",
      "Train Epoch: 2252 [98560/118836 (83%)] Loss: 12285.375977\n",
      "    epoch          : 2252\n",
      "    loss           : 12233.170667261165\n",
      "    val_loss       : 12230.329088872553\n",
      "    val_log_likelihood: -12149.2306306219\n",
      "    val_log_marginal: -12157.738294518576\n",
      "Train Epoch: 2253 [256/118836 (0%)] Loss: 12431.840820\n",
      "Train Epoch: 2253 [33024/118836 (28%)] Loss: 12309.968750\n",
      "Train Epoch: 2253 [65792/118836 (55%)] Loss: 12295.992188\n",
      "Train Epoch: 2253 [98560/118836 (83%)] Loss: 12262.313477\n",
      "    epoch          : 2253\n",
      "    loss           : 12231.664878321442\n",
      "    val_loss       : 12230.126153249987\n",
      "    val_log_likelihood: -12149.799981744985\n",
      "    val_log_marginal: -12158.357269021548\n",
      "Train Epoch: 2254 [256/118836 (0%)] Loss: 12307.627930\n",
      "Train Epoch: 2254 [33024/118836 (28%)] Loss: 12279.277344\n",
      "Train Epoch: 2254 [65792/118836 (55%)] Loss: 12232.406250\n",
      "Train Epoch: 2254 [98560/118836 (83%)] Loss: 12157.299805\n",
      "    epoch          : 2254\n",
      "    loss           : 12234.075693044355\n",
      "    val_loss       : 12232.160853671548\n",
      "    val_log_likelihood: -12150.546252229373\n",
      "    val_log_marginal: -12158.965765070918\n",
      "Train Epoch: 2255 [256/118836 (0%)] Loss: 12356.816406\n",
      "Train Epoch: 2255 [33024/118836 (28%)] Loss: 12314.774414\n",
      "Train Epoch: 2255 [65792/118836 (55%)] Loss: 12191.351562\n",
      "Train Epoch: 2255 [98560/118836 (83%)] Loss: 12199.029297\n",
      "    epoch          : 2255\n",
      "    loss           : 12231.311964304175\n",
      "    val_loss       : 12232.544482631258\n",
      "    val_log_likelihood: -12149.28025469784\n",
      "    val_log_marginal: -12157.622249344418\n",
      "Train Epoch: 2256 [256/118836 (0%)] Loss: 12214.677734\n",
      "Train Epoch: 2256 [33024/118836 (28%)] Loss: 12280.912109\n",
      "Train Epoch: 2256 [65792/118836 (55%)] Loss: 12199.015625\n",
      "Train Epoch: 2256 [98560/118836 (83%)] Loss: 12232.971680\n",
      "    epoch          : 2256\n",
      "    loss           : 12227.491625148625\n",
      "    val_loss       : 12231.279966298669\n",
      "    val_log_likelihood: -12153.210023941532\n",
      "    val_log_marginal: -12161.79398010272\n",
      "Train Epoch: 2257 [256/118836 (0%)] Loss: 12224.997070\n",
      "Train Epoch: 2257 [33024/118836 (28%)] Loss: 12275.605469\n",
      "Train Epoch: 2257 [65792/118836 (55%)] Loss: 12277.963867\n",
      "Train Epoch: 2257 [98560/118836 (83%)] Loss: 12270.093750\n",
      "    epoch          : 2257\n",
      "    loss           : 12229.379955994107\n",
      "    val_loss       : 12235.453511821752\n",
      "    val_log_likelihood: -12150.299792894437\n",
      "    val_log_marginal: -12158.726207756808\n",
      "Train Epoch: 2258 [256/118836 (0%)] Loss: 12244.422852\n",
      "Train Epoch: 2258 [33024/118836 (28%)] Loss: 12386.304688\n",
      "Train Epoch: 2258 [65792/118836 (55%)] Loss: 12125.395508\n",
      "Train Epoch: 2258 [98560/118836 (83%)] Loss: 12242.887695\n",
      "    epoch          : 2258\n",
      "    loss           : 12229.871968859852\n",
      "    val_loss       : 12230.302993076768\n",
      "    val_log_likelihood: -12151.332971302472\n",
      "    val_log_marginal: -12159.575083279333\n",
      "Train Epoch: 2259 [256/118836 (0%)] Loss: 12293.013672\n",
      "Train Epoch: 2259 [33024/118836 (28%)] Loss: 12208.456055\n",
      "Train Epoch: 2259 [65792/118836 (55%)] Loss: 12290.397461\n",
      "Train Epoch: 2259 [98560/118836 (83%)] Loss: 12223.773438\n",
      "    epoch          : 2259\n",
      "    loss           : 12233.385238639888\n",
      "    val_loss       : 12229.049205063822\n",
      "    val_log_likelihood: -12152.715932912015\n",
      "    val_log_marginal: -12161.039531975352\n",
      "Train Epoch: 2260 [256/118836 (0%)] Loss: 12346.029297\n",
      "Train Epoch: 2260 [33024/118836 (28%)] Loss: 12206.992188\n",
      "Train Epoch: 2260 [65792/118836 (55%)] Loss: 12178.945312\n",
      "Train Epoch: 2260 [98560/118836 (83%)] Loss: 12212.018555\n",
      "    epoch          : 2260\n",
      "    loss           : 12227.525644579713\n",
      "    val_loss       : 12227.274344251597\n",
      "    val_log_likelihood: -12150.795840603028\n",
      "    val_log_marginal: -12159.074931508116\n",
      "Train Epoch: 2261 [256/118836 (0%)] Loss: 12196.817383\n",
      "Train Epoch: 2261 [33024/118836 (28%)] Loss: 12200.164062\n",
      "Train Epoch: 2261 [65792/118836 (55%)] Loss: 12269.462891\n",
      "Train Epoch: 2261 [98560/118836 (83%)] Loss: 12176.195312\n",
      "    epoch          : 2261\n",
      "    loss           : 12230.145106848377\n",
      "    val_loss       : 12229.15858059095\n",
      "    val_log_likelihood: -12150.788465577181\n",
      "    val_log_marginal: -12159.208076713772\n",
      "Train Epoch: 2262 [256/118836 (0%)] Loss: 12181.718750\n",
      "Train Epoch: 2262 [33024/118836 (28%)] Loss: 12253.074219\n",
      "Train Epoch: 2262 [65792/118836 (55%)] Loss: 12301.072266\n",
      "Train Epoch: 2262 [98560/118836 (83%)] Loss: 12281.736328\n",
      "    epoch          : 2262\n",
      "    loss           : 12231.385931522693\n",
      "    val_loss       : 12232.496603921332\n",
      "    val_log_likelihood: -12149.678602376707\n",
      "    val_log_marginal: -12158.021290927329\n",
      "Train Epoch: 2263 [256/118836 (0%)] Loss: 12332.465820\n",
      "Train Epoch: 2263 [33024/118836 (28%)] Loss: 12142.626953\n",
      "Train Epoch: 2263 [65792/118836 (55%)] Loss: 12313.046875\n",
      "Train Epoch: 2263 [98560/118836 (83%)] Loss: 12331.873047\n",
      "    epoch          : 2263\n",
      "    loss           : 12228.079909629601\n",
      "    val_loss       : 12229.230474377986\n",
      "    val_log_likelihood: -12150.928334367245\n",
      "    val_log_marginal: -12159.427852416771\n",
      "Train Epoch: 2264 [256/118836 (0%)] Loss: 12257.264648\n",
      "Train Epoch: 2264 [33024/118836 (28%)] Loss: 12276.679688\n",
      "Train Epoch: 2264 [65792/118836 (55%)] Loss: 12294.024414\n",
      "Train Epoch: 2264 [98560/118836 (83%)] Loss: 12260.900391\n",
      "    epoch          : 2264\n",
      "    loss           : 12230.37322328629\n",
      "    val_loss       : 12232.369327462235\n",
      "    val_log_likelihood: -12146.581641432744\n",
      "    val_log_marginal: -12155.023764233161\n",
      "Train Epoch: 2265 [256/118836 (0%)] Loss: 12199.955078\n",
      "Train Epoch: 2265 [33024/118836 (28%)] Loss: 12197.592773\n",
      "Train Epoch: 2265 [65792/118836 (55%)] Loss: 12179.709961\n",
      "Train Epoch: 2265 [98560/118836 (83%)] Loss: 12279.126953\n",
      "    epoch          : 2265\n",
      "    loss           : 12227.777565879602\n",
      "    val_loss       : 12234.771339007992\n",
      "    val_log_likelihood: -12153.6732084238\n",
      "    val_log_marginal: -12162.180070015564\n",
      "Train Epoch: 2266 [256/118836 (0%)] Loss: 12184.244141\n",
      "Train Epoch: 2266 [33024/118836 (28%)] Loss: 12190.634766\n",
      "Train Epoch: 2266 [65792/118836 (55%)] Loss: 12173.235352\n",
      "Train Epoch: 2266 [98560/118836 (83%)] Loss: 12216.330078\n",
      "    epoch          : 2266\n",
      "    loss           : 12230.27003625155\n",
      "    val_loss       : 12227.828417052397\n",
      "    val_log_likelihood: -12149.877429047767\n",
      "    val_log_marginal: -12158.35217997553\n",
      "Train Epoch: 2267 [256/118836 (0%)] Loss: 12273.875000\n",
      "Train Epoch: 2267 [33024/118836 (28%)] Loss: 12298.990234\n",
      "Train Epoch: 2267 [65792/118836 (55%)] Loss: 12287.846680\n",
      "Train Epoch: 2267 [98560/118836 (83%)] Loss: 12250.721680\n",
      "    epoch          : 2267\n",
      "    loss           : 12230.252035999534\n",
      "    val_loss       : 12230.3878371604\n",
      "    val_log_likelihood: -12139.880920440448\n",
      "    val_log_marginal: -12148.24932270208\n",
      "Train Epoch: 2268 [256/118836 (0%)] Loss: 12324.117188\n",
      "Train Epoch: 2268 [33024/118836 (28%)] Loss: 12212.779297\n",
      "Train Epoch: 2268 [65792/118836 (55%)] Loss: 12298.664062\n",
      "Train Epoch: 2268 [98560/118836 (83%)] Loss: 12258.617188\n",
      "    epoch          : 2268\n",
      "    loss           : 12222.878913681245\n",
      "    val_loss       : 12229.117921402887\n",
      "    val_log_likelihood: -12148.121548509875\n",
      "    val_log_marginal: -12156.66838737243\n",
      "Train Epoch: 2269 [256/118836 (0%)] Loss: 12197.735352\n",
      "Train Epoch: 2269 [33024/118836 (28%)] Loss: 12208.458008\n",
      "Train Epoch: 2269 [65792/118836 (55%)] Loss: 12185.192383\n",
      "Train Epoch: 2269 [98560/118836 (83%)] Loss: 12241.595703\n",
      "    epoch          : 2269\n",
      "    loss           : 12226.936019082144\n",
      "    val_loss       : 12230.227645454552\n",
      "    val_log_likelihood: -12144.978614977514\n",
      "    val_log_marginal: -12153.455308264498\n",
      "Train Epoch: 2270 [256/118836 (0%)] Loss: 12303.899414\n",
      "Train Epoch: 2270 [33024/118836 (28%)] Loss: 12210.121094\n",
      "Train Epoch: 2270 [65792/118836 (55%)] Loss: 12275.166016\n",
      "Train Epoch: 2270 [98560/118836 (83%)] Loss: 12225.958984\n",
      "    epoch          : 2270\n",
      "    loss           : 12229.12660272565\n",
      "    val_loss       : 12227.564001890794\n",
      "    val_log_likelihood: -12143.985763996587\n",
      "    val_log_marginal: -12152.354205640799\n",
      "Train Epoch: 2271 [256/118836 (0%)] Loss: 12221.019531\n",
      "Train Epoch: 2271 [33024/118836 (28%)] Loss: 12211.122070\n",
      "Train Epoch: 2271 [65792/118836 (55%)] Loss: 12167.546875\n",
      "Train Epoch: 2271 [98560/118836 (83%)] Loss: 12305.224609\n",
      "    epoch          : 2271\n",
      "    loss           : 12230.42231150486\n",
      "    val_loss       : 12226.987407793373\n",
      "    val_log_likelihood: -12143.866558105874\n",
      "    val_log_marginal: -12152.416830194865\n",
      "Train Epoch: 2272 [256/118836 (0%)] Loss: 12297.981445\n",
      "Train Epoch: 2272 [33024/118836 (28%)] Loss: 12193.972656\n",
      "Train Epoch: 2272 [65792/118836 (55%)] Loss: 12212.080078\n",
      "Train Epoch: 2272 [98560/118836 (83%)] Loss: 12242.344727\n",
      "    epoch          : 2272\n",
      "    loss           : 12237.052766523211\n",
      "    val_loss       : 12228.506948199112\n",
      "    val_log_likelihood: -12148.886722950268\n",
      "    val_log_marginal: -12157.470745486484\n",
      "Train Epoch: 2273 [256/118836 (0%)] Loss: 12211.766602\n",
      "Train Epoch: 2273 [33024/118836 (28%)] Loss: 12238.312500\n",
      "Train Epoch: 2273 [65792/118836 (55%)] Loss: 12186.002930\n",
      "Train Epoch: 2273 [98560/118836 (83%)] Loss: 12185.256836\n",
      "    epoch          : 2273\n",
      "    loss           : 12231.180605258736\n",
      "    val_loss       : 12228.599965148424\n",
      "    val_log_likelihood: -12146.900815175248\n",
      "    val_log_marginal: -12155.425153189506\n",
      "Train Epoch: 2274 [256/118836 (0%)] Loss: 12301.146484\n",
      "Train Epoch: 2274 [33024/118836 (28%)] Loss: 12210.223633\n",
      "Train Epoch: 2274 [65792/118836 (55%)] Loss: 12209.975586\n",
      "Train Epoch: 2274 [98560/118836 (83%)] Loss: 12233.152344\n",
      "    epoch          : 2274\n",
      "    loss           : 12231.702122105045\n",
      "    val_loss       : 12228.296930970984\n",
      "    val_log_likelihood: -12145.083346580335\n",
      "    val_log_marginal: -12153.532908188421\n",
      "Train Epoch: 2275 [256/118836 (0%)] Loss: 12161.769531\n",
      "Train Epoch: 2275 [33024/118836 (28%)] Loss: 12261.826172\n",
      "Train Epoch: 2275 [65792/118836 (55%)] Loss: 12335.103516\n",
      "Train Epoch: 2275 [98560/118836 (83%)] Loss: 12192.641602\n",
      "    epoch          : 2275\n",
      "    loss           : 12229.627302716604\n",
      "    val_loss       : 12231.52209852138\n",
      "    val_log_likelihood: -12150.592982643198\n",
      "    val_log_marginal: -12159.196218578498\n",
      "Train Epoch: 2276 [256/118836 (0%)] Loss: 12192.009766\n",
      "Train Epoch: 2276 [33024/118836 (28%)] Loss: 12220.031250\n",
      "Train Epoch: 2276 [65792/118836 (55%)] Loss: 12208.261719\n",
      "Train Epoch: 2276 [98560/118836 (83%)] Loss: 12241.767578\n",
      "    epoch          : 2276\n",
      "    loss           : 12228.048822309243\n",
      "    val_loss       : 12227.999486985796\n",
      "    val_log_likelihood: -12145.805854851635\n",
      "    val_log_marginal: -12154.227055898948\n",
      "Train Epoch: 2277 [256/118836 (0%)] Loss: 12206.001953\n",
      "Train Epoch: 2277 [33024/118836 (28%)] Loss: 12232.618164\n",
      "Train Epoch: 2277 [65792/118836 (55%)] Loss: 12266.046875\n",
      "Train Epoch: 2277 [98560/118836 (83%)] Loss: 12141.137695\n",
      "    epoch          : 2277\n",
      "    loss           : 12227.253528710453\n",
      "    val_loss       : 12234.985949808046\n",
      "    val_log_likelihood: -12157.269342561\n",
      "    val_log_marginal: -12165.815467943201\n",
      "Train Epoch: 2278 [256/118836 (0%)] Loss: 12222.904297\n",
      "Train Epoch: 2278 [33024/118836 (28%)] Loss: 12205.904297\n",
      "Train Epoch: 2278 [65792/118836 (55%)] Loss: 12118.933594\n",
      "Train Epoch: 2278 [98560/118836 (83%)] Loss: 12116.725586\n",
      "    epoch          : 2278\n",
      "    loss           : 12230.759855123037\n",
      "    val_loss       : 12229.295972758155\n",
      "    val_log_likelihood: -12148.141677975082\n",
      "    val_log_marginal: -12156.761212267817\n",
      "Train Epoch: 2279 [256/118836 (0%)] Loss: 12267.347656\n",
      "Train Epoch: 2279 [33024/118836 (28%)] Loss: 12341.757812\n",
      "Train Epoch: 2279 [65792/118836 (55%)] Loss: 12364.591797\n",
      "Train Epoch: 2279 [98560/118836 (83%)] Loss: 12212.488281\n",
      "    epoch          : 2279\n",
      "    loss           : 12231.392485234439\n",
      "    val_loss       : 12225.599694284023\n",
      "    val_log_likelihood: -12141.837783195047\n",
      "    val_log_marginal: -12150.37751926182\n",
      "Train Epoch: 2280 [256/118836 (0%)] Loss: 12306.760742\n",
      "Train Epoch: 2280 [33024/118836 (28%)] Loss: 12218.843750\n",
      "Train Epoch: 2280 [65792/118836 (55%)] Loss: 12219.380859\n",
      "Train Epoch: 2280 [98560/118836 (83%)] Loss: 12381.266602\n",
      "    epoch          : 2280\n",
      "    loss           : 12231.237251376397\n",
      "    val_loss       : 12234.9124894293\n",
      "    val_log_likelihood: -12153.554341139372\n",
      "    val_log_marginal: -12162.04659906605\n",
      "Train Epoch: 2281 [256/118836 (0%)] Loss: 12203.544922\n",
      "Train Epoch: 2281 [33024/118836 (28%)] Loss: 12247.855469\n",
      "Train Epoch: 2281 [65792/118836 (55%)] Loss: 12278.061523\n",
      "Train Epoch: 2281 [98560/118836 (83%)] Loss: 12265.108398\n",
      "    epoch          : 2281\n",
      "    loss           : 12232.991557782774\n",
      "    val_loss       : 12233.077139505844\n",
      "    val_log_likelihood: -12146.667671661757\n",
      "    val_log_marginal: -12155.35027132333\n",
      "Train Epoch: 2282 [256/118836 (0%)] Loss: 12316.024414\n",
      "Train Epoch: 2282 [33024/118836 (28%)] Loss: 12232.085938\n",
      "Train Epoch: 2282 [65792/118836 (55%)] Loss: 12230.124023\n",
      "Train Epoch: 2282 [98560/118836 (83%)] Loss: 12253.493164\n",
      "    epoch          : 2282\n",
      "    loss           : 12226.153637432795\n",
      "    val_loss       : 12228.207734319869\n",
      "    val_log_likelihood: -12142.699669794252\n",
      "    val_log_marginal: -12151.172816711241\n",
      "Train Epoch: 2283 [256/118836 (0%)] Loss: 12235.450195\n",
      "Train Epoch: 2283 [33024/118836 (28%)] Loss: 12230.132812\n",
      "Train Epoch: 2283 [65792/118836 (55%)] Loss: 12271.366211\n",
      "Train Epoch: 2283 [98560/118836 (83%)] Loss: 12260.591797\n",
      "    epoch          : 2283\n",
      "    loss           : 12228.406334651572\n",
      "    val_loss       : 12231.92971596221\n",
      "    val_log_likelihood: -12145.225380124328\n",
      "    val_log_marginal: -12153.541807054457\n",
      "Train Epoch: 2284 [256/118836 (0%)] Loss: 12202.936523\n",
      "Train Epoch: 2284 [33024/118836 (28%)] Loss: 12223.666016\n",
      "Train Epoch: 2284 [65792/118836 (55%)] Loss: 12258.935547\n",
      "Train Epoch: 2284 [98560/118836 (83%)] Loss: 12270.718750\n",
      "    epoch          : 2284\n",
      "    loss           : 12232.024614221464\n",
      "    val_loss       : 12226.371278137329\n",
      "    val_log_likelihood: -12144.075005654207\n",
      "    val_log_marginal: -12152.477845801097\n",
      "Train Epoch: 2285 [256/118836 (0%)] Loss: 12170.278320\n",
      "Train Epoch: 2285 [33024/118836 (28%)] Loss: 12145.163086\n",
      "Train Epoch: 2285 [65792/118836 (55%)] Loss: 12200.788086\n",
      "Train Epoch: 2285 [98560/118836 (83%)] Loss: 12399.989258\n",
      "    epoch          : 2285\n",
      "    loss           : 12230.822079036134\n",
      "    val_loss       : 12232.89252413793\n",
      "    val_log_likelihood: -12148.590622576769\n",
      "    val_log_marginal: -12157.234974715906\n",
      "Train Epoch: 2286 [256/118836 (0%)] Loss: 12245.189453\n",
      "Train Epoch: 2286 [33024/118836 (28%)] Loss: 12252.794922\n",
      "Train Epoch: 2286 [65792/118836 (55%)] Loss: 12246.389648\n",
      "Train Epoch: 2286 [98560/118836 (83%)] Loss: 12283.223633\n",
      "    epoch          : 2286\n",
      "    loss           : 12234.343805734337\n",
      "    val_loss       : 12224.278315086274\n",
      "    val_log_likelihood: -12145.652215480251\n",
      "    val_log_marginal: -12154.307394981262\n",
      "Train Epoch: 2287 [256/118836 (0%)] Loss: 12253.146484\n",
      "Train Epoch: 2287 [33024/118836 (28%)] Loss: 12284.904297\n",
      "Train Epoch: 2287 [65792/118836 (55%)] Loss: 12329.470703\n",
      "Train Epoch: 2287 [98560/118836 (83%)] Loss: 12214.060547\n",
      "    epoch          : 2287\n",
      "    loss           : 12231.740492691531\n",
      "    val_loss       : 12229.897703903967\n",
      "    val_log_likelihood: -12145.294465984283\n",
      "    val_log_marginal: -12154.075403728748\n",
      "Train Epoch: 2288 [256/118836 (0%)] Loss: 12326.013672\n",
      "Train Epoch: 2288 [33024/118836 (28%)] Loss: 12215.875000\n",
      "Train Epoch: 2288 [65792/118836 (55%)] Loss: 12210.285156\n",
      "Train Epoch: 2288 [98560/118836 (83%)] Loss: 12363.213867\n",
      "    epoch          : 2288\n",
      "    loss           : 12232.849821488575\n",
      "    val_loss       : 12230.717214304874\n",
      "    val_log_likelihood: -12147.831710898728\n",
      "    val_log_marginal: -12156.466863344816\n",
      "Train Epoch: 2289 [256/118836 (0%)] Loss: 12270.536133\n",
      "Train Epoch: 2289 [33024/118836 (28%)] Loss: 12251.845703\n",
      "Train Epoch: 2289 [65792/118836 (55%)] Loss: 12230.637695\n",
      "Train Epoch: 2289 [98560/118836 (83%)] Loss: 12232.513672\n",
      "    epoch          : 2289\n",
      "    loss           : 12231.624700488523\n",
      "    val_loss       : 12233.515469221456\n",
      "    val_log_likelihood: -12147.258754814155\n",
      "    val_log_marginal: -12155.877467196924\n",
      "Train Epoch: 2290 [256/118836 (0%)] Loss: 12206.718750\n",
      "Train Epoch: 2290 [33024/118836 (28%)] Loss: 12261.054688\n",
      "Train Epoch: 2290 [65792/118836 (55%)] Loss: 12268.451172\n",
      "Train Epoch: 2290 [98560/118836 (83%)] Loss: 12294.337891\n",
      "    epoch          : 2290\n",
      "    loss           : 12231.512932950785\n",
      "    val_loss       : 12227.201919440267\n",
      "    val_log_likelihood: -12146.574068348065\n",
      "    val_log_marginal: -12155.095520936004\n",
      "Train Epoch: 2291 [256/118836 (0%)] Loss: 12278.639648\n",
      "Train Epoch: 2291 [33024/118836 (28%)] Loss: 12244.222656\n",
      "Train Epoch: 2291 [65792/118836 (55%)] Loss: 12323.821289\n",
      "Train Epoch: 2291 [98560/118836 (83%)] Loss: 12294.108398\n",
      "    epoch          : 2291\n",
      "    loss           : 12231.70401141827\n",
      "    val_loss       : 12228.771565296789\n",
      "    val_log_likelihood: -12144.74639810794\n",
      "    val_log_marginal: -12153.42358288195\n",
      "Train Epoch: 2292 [256/118836 (0%)] Loss: 12208.133789\n",
      "Train Epoch: 2292 [33024/118836 (28%)] Loss: 12181.684570\n",
      "Train Epoch: 2292 [65792/118836 (55%)] Loss: 12195.197266\n",
      "Train Epoch: 2292 [98560/118836 (83%)] Loss: 12325.314453\n",
      "    epoch          : 2292\n",
      "    loss           : 12228.738294497001\n",
      "    val_loss       : 12233.887788329903\n",
      "    val_log_likelihood: -12151.733504413512\n",
      "    val_log_marginal: -12160.266682898648\n",
      "Train Epoch: 2293 [256/118836 (0%)] Loss: 12331.530273\n",
      "Train Epoch: 2293 [33024/118836 (28%)] Loss: 12209.558594\n",
      "Train Epoch: 2293 [65792/118836 (55%)] Loss: 12206.520508\n",
      "Train Epoch: 2293 [98560/118836 (83%)] Loss: 12289.949219\n",
      "    epoch          : 2293\n",
      "    loss           : 12229.587294509925\n",
      "    val_loss       : 12227.775792508137\n",
      "    val_log_likelihood: -12143.889820486973\n",
      "    val_log_marginal: -12152.382874176856\n",
      "Train Epoch: 2294 [256/118836 (0%)] Loss: 12269.447266\n",
      "Train Epoch: 2294 [33024/118836 (28%)] Loss: 12305.426758\n",
      "Train Epoch: 2294 [65792/118836 (55%)] Loss: 12337.333008\n",
      "Train Epoch: 2294 [98560/118836 (83%)] Loss: 12355.265625\n",
      "    epoch          : 2294\n",
      "    loss           : 12229.050904027088\n",
      "    val_loss       : 12231.68048990265\n",
      "    val_log_likelihood: -12145.729896544148\n",
      "    val_log_marginal: -12154.299640978956\n",
      "Train Epoch: 2295 [256/118836 (0%)] Loss: 12242.972656\n",
      "Train Epoch: 2295 [33024/118836 (28%)] Loss: 12274.364258\n",
      "Train Epoch: 2295 [65792/118836 (55%)] Loss: 12295.957031\n",
      "Train Epoch: 2295 [98560/118836 (83%)] Loss: 12330.861328\n",
      "    epoch          : 2295\n",
      "    loss           : 12229.384487599515\n",
      "    val_loss       : 12225.547179404803\n",
      "    val_log_likelihood: -12146.99230882315\n",
      "    val_log_marginal: -12155.35658037109\n",
      "Train Epoch: 2296 [256/118836 (0%)] Loss: 12244.948242\n",
      "Train Epoch: 2296 [33024/118836 (28%)] Loss: 12239.872070\n",
      "Train Epoch: 2296 [65792/118836 (55%)] Loss: 12234.662109\n",
      "Train Epoch: 2296 [98560/118836 (83%)] Loss: 12214.199219\n",
      "    epoch          : 2296\n",
      "    loss           : 12226.539217748397\n",
      "    val_loss       : 12227.789562788259\n",
      "    val_log_likelihood: -12142.489722911498\n",
      "    val_log_marginal: -12151.012266970134\n",
      "Train Epoch: 2297 [256/118836 (0%)] Loss: 12223.142578\n",
      "Train Epoch: 2297 [33024/118836 (28%)] Loss: 12301.889648\n",
      "Train Epoch: 2297 [65792/118836 (55%)] Loss: 12205.086914\n",
      "Train Epoch: 2297 [98560/118836 (83%)] Loss: 12255.768555\n",
      "    epoch          : 2297\n",
      "    loss           : 12231.060917467948\n",
      "    val_loss       : 12230.011075342232\n",
      "    val_log_likelihood: -12145.964548115695\n",
      "    val_log_marginal: -12154.363296944834\n",
      "Train Epoch: 2298 [256/118836 (0%)] Loss: 12182.926758\n",
      "Train Epoch: 2298 [33024/118836 (28%)] Loss: 12209.297852\n",
      "Train Epoch: 2298 [65792/118836 (55%)] Loss: 12310.713867\n",
      "Train Epoch: 2298 [98560/118836 (83%)] Loss: 12197.782227\n",
      "    epoch          : 2298\n",
      "    loss           : 12236.222490824028\n",
      "    val_loss       : 12232.853543785139\n",
      "    val_log_likelihood: -12151.88152867168\n",
      "    val_log_marginal: -12160.57876082547\n",
      "Train Epoch: 2299 [256/118836 (0%)] Loss: 12285.462891\n",
      "Train Epoch: 2299 [33024/118836 (28%)] Loss: 12224.656250\n",
      "Train Epoch: 2299 [65792/118836 (55%)] Loss: 12324.537109\n",
      "Train Epoch: 2299 [98560/118836 (83%)] Loss: 12292.447266\n",
      "    epoch          : 2299\n",
      "    loss           : 12231.693348228133\n",
      "    val_loss       : 12232.289108700232\n",
      "    val_log_likelihood: -12146.299284985009\n",
      "    val_log_marginal: -12154.852722077094\n",
      "Train Epoch: 2300 [256/118836 (0%)] Loss: 12273.016602\n",
      "Train Epoch: 2300 [33024/118836 (28%)] Loss: 12293.484375\n",
      "Train Epoch: 2300 [65792/118836 (55%)] Loss: 12240.874023\n",
      "Train Epoch: 2300 [98560/118836 (83%)] Loss: 12244.175781\n",
      "    epoch          : 2300\n",
      "    loss           : 12227.410364163306\n",
      "    val_loss       : 12229.247681773339\n",
      "    val_log_likelihood: -12141.201393843052\n",
      "    val_log_marginal: -12149.642807759938\n",
      "Saving checkpoint: saved/models/SelfiesAutoencodingOperad/0905_154251/checkpoint-epoch2300.pth ...\n",
      "Train Epoch: 2301 [256/118836 (0%)] Loss: 12289.524414\n",
      "Train Epoch: 2301 [33024/118836 (28%)] Loss: 12244.488281\n",
      "Train Epoch: 2301 [65792/118836 (55%)] Loss: 12327.641602\n",
      "Train Epoch: 2301 [98560/118836 (83%)] Loss: 12225.750000\n",
      "    epoch          : 2301\n",
      "    loss           : 12228.627906909118\n",
      "    val_loss       : 12230.230975973782\n",
      "    val_log_likelihood: -12143.94646434295\n",
      "    val_log_marginal: -12152.332661514723\n",
      "Train Epoch: 2302 [256/118836 (0%)] Loss: 12354.236328\n",
      "Train Epoch: 2302 [33024/118836 (28%)] Loss: 12299.848633\n",
      "Train Epoch: 2302 [65792/118836 (55%)] Loss: 12203.998047\n",
      "Train Epoch: 2302 [98560/118836 (83%)] Loss: 12288.213867\n",
      "    epoch          : 2302\n",
      "    loss           : 12248.79306567928\n",
      "    val_loss       : 12235.437985441466\n",
      "    val_log_likelihood: -12150.452749237491\n",
      "    val_log_marginal: -12159.132112610774\n",
      "Train Epoch: 2303 [256/118836 (0%)] Loss: 12356.041992\n",
      "Train Epoch: 2303 [33024/118836 (28%)] Loss: 12241.627930\n",
      "Train Epoch: 2303 [65792/118836 (55%)] Loss: 12284.458008\n",
      "Train Epoch: 2303 [98560/118836 (83%)] Loss: 12162.967773\n",
      "    epoch          : 2303\n",
      "    loss           : 12236.924505337573\n",
      "    val_loss       : 12228.254991260905\n",
      "    val_log_likelihood: -12145.159014584624\n",
      "    val_log_marginal: -12153.775779462367\n",
      "Train Epoch: 2304 [256/118836 (0%)] Loss: 12198.561523\n",
      "Train Epoch: 2304 [33024/118836 (28%)] Loss: 12299.959961\n",
      "Train Epoch: 2304 [65792/118836 (55%)] Loss: 12210.648438\n",
      "Train Epoch: 2304 [98560/118836 (83%)] Loss: 12198.975586\n",
      "    epoch          : 2304\n",
      "    loss           : 12229.380147267886\n",
      "    val_loss       : 12230.293576977474\n",
      "    val_log_likelihood: -12149.277935341708\n",
      "    val_log_marginal: -12157.710292338663\n",
      "Train Epoch: 2305 [256/118836 (0%)] Loss: 12205.991211\n",
      "Train Epoch: 2305 [33024/118836 (28%)] Loss: 12250.368164\n",
      "Train Epoch: 2305 [65792/118836 (55%)] Loss: 12284.582031\n",
      "Train Epoch: 2305 [98560/118836 (83%)] Loss: 12179.807617\n",
      "    epoch          : 2305\n",
      "    loss           : 12229.368252268145\n",
      "    val_loss       : 12229.839059607646\n",
      "    val_log_likelihood: -12146.41905306555\n",
      "    val_log_marginal: -12154.768181876761\n",
      "Train Epoch: 2306 [256/118836 (0%)] Loss: 12161.306641\n",
      "Train Epoch: 2306 [33024/118836 (28%)] Loss: 12262.736328\n",
      "Train Epoch: 2306 [65792/118836 (55%)] Loss: 12154.998047\n",
      "Train Epoch: 2306 [98560/118836 (83%)] Loss: 12230.529297\n",
      "    epoch          : 2306\n",
      "    loss           : 12227.589435031534\n",
      "    val_loss       : 12227.503453341355\n",
      "    val_log_likelihood: -12146.819954346309\n",
      "    val_log_marginal: -12155.22439992712\n",
      "Train Epoch: 2307 [256/118836 (0%)] Loss: 12210.477539\n",
      "Train Epoch: 2307 [33024/118836 (28%)] Loss: 12241.096680\n",
      "Train Epoch: 2307 [65792/118836 (55%)] Loss: 12276.115234\n",
      "Train Epoch: 2307 [98560/118836 (83%)] Loss: 12262.392578\n",
      "    epoch          : 2307\n",
      "    loss           : 12225.047597123139\n",
      "    val_loss       : 12227.157134333173\n",
      "    val_log_likelihood: -12144.11992316739\n",
      "    val_log_marginal: -12152.564704311102\n",
      "Train Epoch: 2308 [256/118836 (0%)] Loss: 12205.291992\n",
      "Train Epoch: 2308 [33024/118836 (28%)] Loss: 12256.597656\n",
      "Train Epoch: 2308 [65792/118836 (55%)] Loss: 12256.179688\n",
      "Train Epoch: 2308 [98560/118836 (83%)] Loss: 12220.106445\n",
      "    epoch          : 2308\n",
      "    loss           : 12226.743038215986\n",
      "    val_loss       : 12228.881836689785\n",
      "    val_log_likelihood: -12143.883027521453\n",
      "    val_log_marginal: -12152.24355730724\n",
      "Train Epoch: 2309 [256/118836 (0%)] Loss: 12328.219727\n",
      "Train Epoch: 2309 [33024/118836 (28%)] Loss: 12229.380859\n",
      "Train Epoch: 2309 [65792/118836 (55%)] Loss: 12263.590820\n",
      "Train Epoch: 2309 [98560/118836 (83%)] Loss: 12188.900391\n",
      "    epoch          : 2309\n",
      "    loss           : 12227.555925125362\n",
      "    val_loss       : 12230.15792603187\n",
      "    val_log_likelihood: -12142.684864331317\n",
      "    val_log_marginal: -12150.95289721299\n",
      "Train Epoch: 2310 [256/118836 (0%)] Loss: 12229.871094\n",
      "Train Epoch: 2310 [33024/118836 (28%)] Loss: 12209.748047\n",
      "Train Epoch: 2310 [65792/118836 (55%)] Loss: 12245.820312\n",
      "Train Epoch: 2310 [98560/118836 (83%)] Loss: 12146.299805\n",
      "    epoch          : 2310\n",
      "    loss           : 12230.696610544614\n",
      "    val_loss       : 12228.915842927867\n",
      "    val_log_likelihood: -12146.124805818343\n",
      "    val_log_marginal: -12154.824505301774\n",
      "Train Epoch: 2311 [256/118836 (0%)] Loss: 12200.333984\n",
      "Train Epoch: 2311 [33024/118836 (28%)] Loss: 12252.292969\n",
      "Train Epoch: 2311 [65792/118836 (55%)] Loss: 12253.817383\n",
      "Train Epoch: 2311 [98560/118836 (83%)] Loss: 12208.373047\n",
      "    epoch          : 2311\n",
      "    loss           : 12229.268857429952\n",
      "    val_loss       : 12230.031797992375\n",
      "    val_log_likelihood: -12144.54827998992\n",
      "    val_log_marginal: -12153.138881752115\n",
      "Train Epoch: 2312 [256/118836 (0%)] Loss: 12271.261719\n",
      "Train Epoch: 2312 [33024/118836 (28%)] Loss: 12246.502930\n",
      "Train Epoch: 2312 [65792/118836 (55%)] Loss: 12281.084961\n",
      "Train Epoch: 2312 [98560/118836 (83%)] Loss: 12264.794922\n",
      "    epoch          : 2312\n",
      "    loss           : 12233.342825133117\n",
      "    val_loss       : 12228.974677918297\n",
      "    val_log_likelihood: -12149.086122958024\n",
      "    val_log_marginal: -12157.569996641723\n",
      "Train Epoch: 2313 [256/118836 (0%)] Loss: 12325.771484\n",
      "Train Epoch: 2313 [33024/118836 (28%)] Loss: 12286.433594\n",
      "Train Epoch: 2313 [65792/118836 (55%)] Loss: 12302.485352\n",
      "Train Epoch: 2313 [98560/118836 (83%)] Loss: 12217.141602\n",
      "    epoch          : 2313\n",
      "    loss           : 12231.802397061103\n",
      "    val_loss       : 12231.37419933201\n",
      "    val_log_likelihood: -12144.4944167119\n",
      "    val_log_marginal: -12152.777327933773\n",
      "Train Epoch: 2314 [256/118836 (0%)] Loss: 12211.380859\n",
      "Train Epoch: 2314 [33024/118836 (28%)] Loss: 12210.563477\n",
      "Train Epoch: 2314 [65792/118836 (55%)] Loss: 12285.311523\n",
      "Train Epoch: 2314 [98560/118836 (83%)] Loss: 12223.948242\n",
      "    epoch          : 2314\n",
      "    loss           : 12232.119868886994\n",
      "    val_loss       : 12227.20609183481\n",
      "    val_log_likelihood: -12147.314498197115\n",
      "    val_log_marginal: -12155.852677269826\n",
      "Train Epoch: 2315 [256/118836 (0%)] Loss: 12217.743164\n",
      "Train Epoch: 2315 [33024/118836 (28%)] Loss: 12179.130859\n",
      "Train Epoch: 2315 [65792/118836 (55%)] Loss: 12345.722656\n",
      "Train Epoch: 2315 [98560/118836 (83%)] Loss: 12303.198242\n",
      "    epoch          : 2315\n",
      "    loss           : 12234.243423509874\n",
      "    val_loss       : 12232.464102820139\n",
      "    val_log_likelihood: -12144.338900628101\n",
      "    val_log_marginal: -12152.694601243526\n",
      "Train Epoch: 2316 [256/118836 (0%)] Loss: 12319.945312\n",
      "Train Epoch: 2316 [33024/118836 (28%)] Loss: 12303.542969\n",
      "Train Epoch: 2316 [65792/118836 (55%)] Loss: 12196.527344\n",
      "Train Epoch: 2316 [98560/118836 (83%)] Loss: 12350.655273\n",
      "    epoch          : 2316\n",
      "    loss           : 12232.620785030242\n",
      "    val_loss       : 12232.356540887042\n",
      "    val_log_likelihood: -12144.249501137303\n",
      "    val_log_marginal: -12152.668693467442\n",
      "Train Epoch: 2317 [256/118836 (0%)] Loss: 12294.171875\n",
      "Train Epoch: 2317 [33024/118836 (28%)] Loss: 12222.060547\n",
      "Train Epoch: 2317 [65792/118836 (55%)] Loss: 12283.666992\n",
      "Train Epoch: 2317 [98560/118836 (83%)] Loss: 12246.442383\n",
      "    epoch          : 2317\n",
      "    loss           : 12231.16723725703\n",
      "    val_loss       : 12230.426345798922\n",
      "    val_log_likelihood: -12144.193843536756\n",
      "    val_log_marginal: -12152.697552328747\n",
      "Train Epoch: 2318 [256/118836 (0%)] Loss: 12224.120117\n",
      "Train Epoch: 2318 [33024/118836 (28%)] Loss: 12210.750977\n",
      "Train Epoch: 2318 [65792/118836 (55%)] Loss: 12199.087891\n",
      "Train Epoch: 2318 [98560/118836 (83%)] Loss: 12227.079102\n",
      "    epoch          : 2318\n",
      "    loss           : 12230.154579423852\n",
      "    val_loss       : 12229.380639283576\n",
      "    val_log_likelihood: -12144.583034306504\n",
      "    val_log_marginal: -12152.985601095654\n",
      "Train Epoch: 2319 [256/118836 (0%)] Loss: 12151.416016\n",
      "Train Epoch: 2319 [33024/118836 (28%)] Loss: 12226.501953\n",
      "Train Epoch: 2319 [65792/118836 (55%)] Loss: 12337.239258\n",
      "Train Epoch: 2319 [98560/118836 (83%)] Loss: 12272.894531\n",
      "    epoch          : 2319\n",
      "    loss           : 12230.478252623552\n",
      "    val_loss       : 12229.090648706064\n",
      "    val_log_likelihood: -12143.938307744003\n",
      "    val_log_marginal: -12152.449160613949\n",
      "Train Epoch: 2320 [256/118836 (0%)] Loss: 12329.641602\n",
      "Train Epoch: 2320 [33024/118836 (28%)] Loss: 12263.603516\n",
      "Train Epoch: 2320 [65792/118836 (55%)] Loss: 12189.255859\n",
      "Train Epoch: 2320 [98560/118836 (83%)] Loss: 12189.155273\n",
      "    epoch          : 2320\n",
      "    loss           : 12232.154284274193\n",
      "    val_loss       : 12230.991545144563\n",
      "    val_log_likelihood: -12145.769227699804\n",
      "    val_log_marginal: -12154.229991647677\n",
      "Train Epoch: 2321 [256/118836 (0%)] Loss: 12190.851562\n",
      "Train Epoch: 2321 [33024/118836 (28%)] Loss: 12320.916992\n",
      "Train Epoch: 2321 [65792/118836 (55%)] Loss: 12205.085938\n",
      "Train Epoch: 2321 [98560/118836 (83%)] Loss: 12202.995117\n",
      "    epoch          : 2321\n",
      "    loss           : 12229.367234187603\n",
      "    val_loss       : 12229.086135027019\n",
      "    val_log_likelihood: -12145.633986152037\n",
      "    val_log_marginal: -12154.126679993122\n",
      "Train Epoch: 2322 [256/118836 (0%)] Loss: 12292.589844\n",
      "Train Epoch: 2322 [33024/118836 (28%)] Loss: 12280.564453\n",
      "Train Epoch: 2322 [65792/118836 (55%)] Loss: 12312.756836\n",
      "Train Epoch: 2322 [98560/118836 (83%)] Loss: 12223.517578\n",
      "    epoch          : 2322\n",
      "    loss           : 12231.405813010493\n",
      "    val_loss       : 12234.250552244033\n",
      "    val_log_likelihood: -12156.442890883478\n",
      "    val_log_marginal: -12164.923939102202\n",
      "Train Epoch: 2323 [256/118836 (0%)] Loss: 12225.427734\n",
      "Train Epoch: 2323 [33024/118836 (28%)] Loss: 12248.382812\n",
      "Train Epoch: 2323 [65792/118836 (55%)] Loss: 12350.638672\n",
      "Train Epoch: 2323 [98560/118836 (83%)] Loss: 12293.051758\n",
      "    epoch          : 2323\n",
      "    loss           : 12230.256622854633\n",
      "    val_loss       : 12227.213355571479\n",
      "    val_log_likelihood: -12143.964797223945\n",
      "    val_log_marginal: -12152.344337321707\n",
      "Train Epoch: 2324 [256/118836 (0%)] Loss: 12331.447266\n",
      "Train Epoch: 2324 [33024/118836 (28%)] Loss: 12250.013672\n",
      "Train Epoch: 2324 [65792/118836 (55%)] Loss: 12200.324219\n",
      "Train Epoch: 2324 [98560/118836 (83%)] Loss: 12293.176758\n",
      "    epoch          : 2324\n",
      "    loss           : 12230.612625200321\n",
      "    val_loss       : 12234.440565845409\n",
      "    val_log_likelihood: -12148.615119029157\n",
      "    val_log_marginal: -12157.30058765094\n",
      "Train Epoch: 2325 [256/118836 (0%)] Loss: 12282.605469\n",
      "Train Epoch: 2325 [33024/118836 (28%)] Loss: 12262.983398\n",
      "Train Epoch: 2325 [65792/118836 (55%)] Loss: 12239.633789\n",
      "Train Epoch: 2325 [98560/118836 (83%)] Loss: 12339.273438\n",
      "    epoch          : 2325\n",
      "    loss           : 12231.105791201406\n",
      "    val_loss       : 12229.508131158575\n",
      "    val_log_likelihood: -12153.422410695825\n",
      "    val_log_marginal: -12162.130411495811\n",
      "Train Epoch: 2326 [256/118836 (0%)] Loss: 12213.591797\n",
      "Train Epoch: 2326 [33024/118836 (28%)] Loss: 12207.992188\n",
      "Train Epoch: 2326 [65792/118836 (55%)] Loss: 12188.307617\n",
      "Train Epoch: 2326 [98560/118836 (83%)] Loss: 12236.315430\n",
      "    epoch          : 2326\n",
      "    loss           : 12229.221933642213\n",
      "    val_loss       : 12231.197501823397\n",
      "    val_log_likelihood: -12143.425253470068\n",
      "    val_log_marginal: -12151.978211632253\n",
      "Train Epoch: 2327 [256/118836 (0%)] Loss: 12165.583984\n",
      "Train Epoch: 2327 [33024/118836 (28%)] Loss: 12254.056641\n",
      "Train Epoch: 2327 [65792/118836 (55%)] Loss: 12324.382812\n",
      "Train Epoch: 2327 [98560/118836 (83%)] Loss: 12201.602539\n",
      "    epoch          : 2327\n",
      "    loss           : 12233.067426430676\n",
      "    val_loss       : 12231.518486280858\n",
      "    val_log_likelihood: -12155.850605969552\n",
      "    val_log_marginal: -12164.445411897022\n",
      "Train Epoch: 2328 [256/118836 (0%)] Loss: 12239.103516\n",
      "Train Epoch: 2328 [33024/118836 (28%)] Loss: 12292.501953\n",
      "Train Epoch: 2328 [65792/118836 (55%)] Loss: 12284.924805\n",
      "Train Epoch: 2328 [98560/118836 (83%)] Loss: 12367.852539\n",
      "    epoch          : 2328\n",
      "    loss           : 12234.133960142679\n",
      "    val_loss       : 12227.77019557703\n",
      "    val_log_likelihood: -12146.951029712056\n",
      "    val_log_marginal: -12155.855167227857\n",
      "Train Epoch: 2329 [256/118836 (0%)] Loss: 12271.945312\n",
      "Train Epoch: 2329 [33024/118836 (28%)] Loss: 12279.689453\n",
      "Train Epoch: 2329 [65792/118836 (55%)] Loss: 12188.767578\n",
      "Train Epoch: 2329 [98560/118836 (83%)] Loss: 12318.254883\n",
      "    epoch          : 2329\n",
      "    loss           : 12230.456034332352\n",
      "    val_loss       : 12230.203690236565\n",
      "    val_log_likelihood: -12142.699042661807\n",
      "    val_log_marginal: -12151.474994416807\n",
      "Train Epoch: 2330 [256/118836 (0%)] Loss: 12276.027344\n",
      "Train Epoch: 2330 [33024/118836 (28%)] Loss: 12199.509766\n",
      "Train Epoch: 2330 [65792/118836 (55%)] Loss: 12223.403320\n",
      "Train Epoch: 2330 [98560/118836 (83%)] Loss: 12284.875000\n",
      "    epoch          : 2330\n",
      "    loss           : 12229.881803950837\n",
      "    val_loss       : 12226.90681860721\n",
      "    val_log_likelihood: -12147.959561750413\n",
      "    val_log_marginal: -12156.518672884962\n",
      "Train Epoch: 2331 [256/118836 (0%)] Loss: 12308.670898\n",
      "Train Epoch: 2331 [33024/118836 (28%)] Loss: 12267.493164\n",
      "Train Epoch: 2331 [65792/118836 (55%)] Loss: 12242.422852\n",
      "Train Epoch: 2331 [98560/118836 (83%)] Loss: 12206.554688\n",
      "    epoch          : 2331\n",
      "    loss           : 12226.662451858458\n",
      "    val_loss       : 12226.858763466924\n",
      "    val_log_likelihood: -12145.866471838814\n",
      "    val_log_marginal: -12154.598010099757\n",
      "Train Epoch: 2332 [256/118836 (0%)] Loss: 12218.936523\n",
      "Train Epoch: 2332 [33024/118836 (28%)] Loss: 12291.980469\n",
      "Train Epoch: 2332 [65792/118836 (55%)] Loss: 12323.046875\n",
      "Train Epoch: 2332 [98560/118836 (83%)] Loss: 12258.153320\n",
      "    epoch          : 2332\n",
      "    loss           : 12231.77011460272\n",
      "    val_loss       : 12228.942337771547\n",
      "    val_log_likelihood: -12145.146789217586\n",
      "    val_log_marginal: -12153.678723544957\n",
      "Train Epoch: 2333 [256/118836 (0%)] Loss: 12351.711914\n",
      "Train Epoch: 2333 [33024/118836 (28%)] Loss: 12244.133789\n",
      "Train Epoch: 2333 [65792/118836 (55%)] Loss: 12191.710938\n",
      "Train Epoch: 2333 [98560/118836 (83%)] Loss: 12184.332031\n",
      "    epoch          : 2333\n",
      "    loss           : 12223.679359232836\n",
      "    val_loss       : 12227.46155552417\n",
      "    val_log_likelihood: -12144.984029608664\n",
      "    val_log_marginal: -12153.432444978647\n",
      "Train Epoch: 2334 [256/118836 (0%)] Loss: 12340.238281\n",
      "Train Epoch: 2334 [33024/118836 (28%)] Loss: 12248.270508\n",
      "Train Epoch: 2334 [65792/118836 (55%)] Loss: 12350.520508\n",
      "Train Epoch: 2334 [98560/118836 (83%)] Loss: 12196.691406\n",
      "    epoch          : 2334\n",
      "    loss           : 12232.765772332505\n",
      "    val_loss       : 12226.015004670235\n",
      "    val_log_likelihood: -12146.24349136037\n",
      "    val_log_marginal: -12154.550294148443\n",
      "Train Epoch: 2335 [256/118836 (0%)] Loss: 12246.724609\n",
      "Train Epoch: 2335 [33024/118836 (28%)] Loss: 12221.579102\n",
      "Train Epoch: 2335 [65792/118836 (55%)] Loss: 12297.652344\n",
      "Train Epoch: 2335 [98560/118836 (83%)] Loss: 12238.092773\n",
      "    epoch          : 2335\n",
      "    loss           : 12227.583850612593\n",
      "    val_loss       : 12227.648319417796\n",
      "    val_log_likelihood: -12144.193198310846\n",
      "    val_log_marginal: -12152.806178641618\n",
      "Train Epoch: 2336 [256/118836 (0%)] Loss: 12332.615234\n",
      "Train Epoch: 2336 [33024/118836 (28%)] Loss: 12295.736328\n",
      "Train Epoch: 2336 [65792/118836 (55%)] Loss: 12220.192383\n",
      "Train Epoch: 2336 [98560/118836 (83%)] Loss: 12239.280273\n",
      "    epoch          : 2336\n",
      "    loss           : 12226.355674240076\n",
      "    val_loss       : 12226.791902098188\n",
      "    val_log_likelihood: -12144.0841459238\n",
      "    val_log_marginal: -12152.65612413144\n",
      "Train Epoch: 2337 [256/118836 (0%)] Loss: 12209.486328\n",
      "Train Epoch: 2337 [33024/118836 (28%)] Loss: 12226.746094\n",
      "Train Epoch: 2337 [65792/118836 (55%)] Loss: 12197.531250\n",
      "Train Epoch: 2337 [98560/118836 (83%)] Loss: 12225.613281\n",
      "    epoch          : 2337\n",
      "    loss           : 12228.671242213348\n",
      "    val_loss       : 12231.908548537076\n",
      "    val_log_likelihood: -12143.947433151106\n",
      "    val_log_marginal: -12152.352752299004\n",
      "Train Epoch: 2338 [256/118836 (0%)] Loss: 12286.771484\n",
      "Train Epoch: 2338 [33024/118836 (28%)] Loss: 12238.006836\n",
      "Train Epoch: 2338 [65792/118836 (55%)] Loss: 12177.205078\n",
      "Train Epoch: 2338 [98560/118836 (83%)] Loss: 12154.796875\n",
      "    epoch          : 2338\n",
      "    loss           : 12229.124747983871\n",
      "    val_loss       : 12228.906959246542\n",
      "    val_log_likelihood: -12148.95725483354\n",
      "    val_log_marginal: -12157.414061097135\n",
      "Train Epoch: 2339 [256/118836 (0%)] Loss: 12271.425781\n",
      "Train Epoch: 2339 [33024/118836 (28%)] Loss: 12258.405273\n",
      "Train Epoch: 2339 [65792/118836 (55%)] Loss: 12236.033203\n",
      "Train Epoch: 2339 [98560/118836 (83%)] Loss: 12295.943359\n",
      "    epoch          : 2339\n",
      "    loss           : 12233.127122105045\n",
      "    val_loss       : 12226.172624463468\n",
      "    val_log_likelihood: -12146.063372686622\n",
      "    val_log_marginal: -12154.499297201883\n",
      "Train Epoch: 2340 [256/118836 (0%)] Loss: 12172.503906\n",
      "Train Epoch: 2340 [33024/118836 (28%)] Loss: 12194.724609\n",
      "Train Epoch: 2340 [65792/118836 (55%)] Loss: 12216.412109\n",
      "Train Epoch: 2340 [98560/118836 (83%)] Loss: 12233.937500\n",
      "    epoch          : 2340\n",
      "    loss           : 12230.38197212314\n",
      "    val_loss       : 12231.188021642865\n",
      "    val_log_likelihood: -12145.703862147177\n",
      "    val_log_marginal: -12154.106797644421\n",
      "Train Epoch: 2341 [256/118836 (0%)] Loss: 12251.350586\n",
      "Train Epoch: 2341 [33024/118836 (28%)] Loss: 12147.828125\n",
      "Train Epoch: 2341 [65792/118836 (55%)] Loss: 12150.105469\n",
      "Train Epoch: 2341 [98560/118836 (83%)] Loss: 12206.846680\n",
      "    epoch          : 2341\n",
      "    loss           : 12230.583329617712\n",
      "    val_loss       : 12230.192195155636\n",
      "    val_log_likelihood: -12159.921922979995\n",
      "    val_log_marginal: -12168.524761527466\n",
      "Train Epoch: 2342 [256/118836 (0%)] Loss: 12290.234375\n",
      "Train Epoch: 2342 [33024/118836 (28%)] Loss: 12255.069336\n",
      "Train Epoch: 2342 [65792/118836 (55%)] Loss: 12331.331055\n",
      "Train Epoch: 2342 [98560/118836 (83%)] Loss: 12269.233398\n",
      "    epoch          : 2342\n",
      "    loss           : 12229.90382563715\n",
      "    val_loss       : 12232.595854414441\n",
      "    val_log_likelihood: -12144.151835194376\n",
      "    val_log_marginal: -12152.60113462094\n",
      "Train Epoch: 2343 [256/118836 (0%)] Loss: 12147.377930\n",
      "Train Epoch: 2343 [33024/118836 (28%)] Loss: 12292.548828\n",
      "Train Epoch: 2343 [65792/118836 (55%)] Loss: 12238.845703\n",
      "Train Epoch: 2343 [98560/118836 (83%)] Loss: 12182.641602\n",
      "    epoch          : 2343\n",
      "    loss           : 12227.45704756643\n",
      "    val_loss       : 12224.60012377208\n",
      "    val_log_likelihood: -12144.382910398574\n",
      "    val_log_marginal: -12152.776932086585\n",
      "Train Epoch: 2344 [256/118836 (0%)] Loss: 12320.502930\n",
      "Train Epoch: 2344 [33024/118836 (28%)] Loss: 12287.894531\n",
      "Train Epoch: 2344 [65792/118836 (55%)] Loss: 12196.170898\n",
      "Train Epoch: 2344 [98560/118836 (83%)] Loss: 12292.510742\n",
      "    epoch          : 2344\n",
      "    loss           : 12232.255991521919\n",
      "    val_loss       : 12229.346425207215\n",
      "    val_log_likelihood: -12141.695010080644\n",
      "    val_log_marginal: -12149.978216209187\n",
      "Train Epoch: 2345 [256/118836 (0%)] Loss: 12178.591797\n",
      "Train Epoch: 2345 [33024/118836 (28%)] Loss: 12318.177734\n",
      "Train Epoch: 2345 [65792/118836 (55%)] Loss: 12231.028320\n",
      "Train Epoch: 2345 [98560/118836 (83%)] Loss: 12264.653320\n",
      "    epoch          : 2345\n",
      "    loss           : 12230.08622570306\n",
      "    val_loss       : 12229.795648573485\n",
      "    val_log_likelihood: -12144.335929261011\n",
      "    val_log_marginal: -12152.743706006164\n",
      "Train Epoch: 2346 [256/118836 (0%)] Loss: 12255.269531\n",
      "Train Epoch: 2346 [33024/118836 (28%)] Loss: 12272.030273\n",
      "Train Epoch: 2346 [65792/118836 (55%)] Loss: 12291.841797\n",
      "Train Epoch: 2346 [98560/118836 (83%)] Loss: 12182.722656\n",
      "    epoch          : 2346\n",
      "    loss           : 12235.06521547379\n",
      "    val_loss       : 12229.159125262884\n",
      "    val_log_likelihood: -12143.938074629084\n",
      "    val_log_marginal: -12152.459517517875\n",
      "Train Epoch: 2347 [256/118836 (0%)] Loss: 12271.871094\n",
      "Train Epoch: 2347 [33024/118836 (28%)] Loss: 12216.490234\n",
      "Train Epoch: 2347 [65792/118836 (55%)] Loss: 12271.182617\n",
      "Train Epoch: 2347 [98560/118836 (83%)] Loss: 12334.538086\n",
      "    epoch          : 2347\n",
      "    loss           : 12233.86063976556\n",
      "    val_loss       : 12235.166788193195\n",
      "    val_log_likelihood: -12148.427623714071\n",
      "    val_log_marginal: -12157.034301911706\n",
      "Train Epoch: 2348 [256/118836 (0%)] Loss: 12161.644531\n",
      "Train Epoch: 2348 [33024/118836 (28%)] Loss: 12298.654297\n",
      "Train Epoch: 2348 [65792/118836 (55%)] Loss: 12218.799805\n",
      "Train Epoch: 2348 [98560/118836 (83%)] Loss: 12298.740234\n",
      "    epoch          : 2348\n",
      "    loss           : 12230.323147843\n",
      "    val_loss       : 12230.43054475712\n",
      "    val_log_likelihood: -12143.61470497958\n",
      "    val_log_marginal: -12152.12174923834\n",
      "Train Epoch: 2349 [256/118836 (0%)] Loss: 12245.023438\n",
      "Train Epoch: 2349 [33024/118836 (28%)] Loss: 12197.140625\n",
      "Train Epoch: 2349 [65792/118836 (55%)] Loss: 12248.023438\n",
      "Train Epoch: 2349 [98560/118836 (83%)] Loss: 12400.017578\n",
      "    epoch          : 2349\n",
      "    loss           : 12234.14497453991\n",
      "    val_loss       : 12230.108506009787\n",
      "    val_log_likelihood: -12150.039309831214\n",
      "    val_log_marginal: -12158.643094464049\n",
      "Train Epoch: 2350 [256/118836 (0%)] Loss: 12277.462891\n",
      "Train Epoch: 2350 [33024/118836 (28%)] Loss: 12220.124023\n",
      "Train Epoch: 2350 [65792/118836 (55%)] Loss: 12202.666016\n",
      "Train Epoch: 2350 [98560/118836 (83%)] Loss: 12282.676758\n",
      "    epoch          : 2350\n",
      "    loss           : 12234.188132786652\n",
      "    val_loss       : 12239.768933745278\n",
      "    val_log_likelihood: -12157.586964627275\n",
      "    val_log_marginal: -12166.341578844987\n",
      "Train Epoch: 2351 [256/118836 (0%)] Loss: 12220.705078\n",
      "Train Epoch: 2351 [33024/118836 (28%)] Loss: 12236.808594\n",
      "Train Epoch: 2351 [65792/118836 (55%)] Loss: 12356.986328\n",
      "Train Epoch: 2351 [98560/118836 (83%)] Loss: 12177.637695\n",
      "    epoch          : 2351\n",
      "    loss           : 12233.775217121587\n",
      "    val_loss       : 12228.201249808608\n",
      "    val_log_likelihood: -12142.998529259718\n",
      "    val_log_marginal: -12151.551277519524\n",
      "Train Epoch: 2352 [256/118836 (0%)] Loss: 12161.368164\n",
      "Train Epoch: 2352 [33024/118836 (28%)] Loss: 12241.337891\n",
      "Train Epoch: 2352 [65792/118836 (55%)] Loss: 12334.674805\n",
      "Train Epoch: 2352 [98560/118836 (83%)] Loss: 12201.053711\n",
      "    epoch          : 2352\n",
      "    loss           : 12230.123901468154\n",
      "    val_loss       : 12227.296242156874\n",
      "    val_log_likelihood: -12143.232391826923\n",
      "    val_log_marginal: -12151.569528984\n",
      "Train Epoch: 2353 [256/118836 (0%)] Loss: 12334.888672\n",
      "Train Epoch: 2353 [33024/118836 (28%)] Loss: 12187.614258\n",
      "Train Epoch: 2353 [65792/118836 (55%)] Loss: 12214.916016\n",
      "Train Epoch: 2353 [98560/118836 (83%)] Loss: 12263.668945\n",
      "    epoch          : 2353\n",
      "    loss           : 12232.335552044562\n",
      "    val_loss       : 12229.050650889154\n",
      "    val_log_likelihood: -12147.268640308364\n",
      "    val_log_marginal: -12155.765382368343\n",
      "Train Epoch: 2354 [256/118836 (0%)] Loss: 12285.655273\n",
      "Train Epoch: 2354 [33024/118836 (28%)] Loss: 12177.615234\n",
      "Train Epoch: 2354 [65792/118836 (55%)] Loss: 12183.156250\n",
      "Train Epoch: 2354 [98560/118836 (83%)] Loss: 12248.739258\n",
      "    epoch          : 2354\n",
      "    loss           : 12234.465413047974\n",
      "    val_loss       : 12229.808857045291\n",
      "    val_log_likelihood: -12148.518474882392\n",
      "    val_log_marginal: -12156.970815113531\n",
      "Train Epoch: 2355 [256/118836 (0%)] Loss: 12138.586914\n",
      "Train Epoch: 2355 [33024/118836 (28%)] Loss: 12204.317383\n",
      "Train Epoch: 2355 [65792/118836 (55%)] Loss: 12264.870117\n",
      "Train Epoch: 2355 [98560/118836 (83%)] Loss: 12289.670898\n",
      "    epoch          : 2355\n",
      "    loss           : 12230.805143067617\n",
      "    val_loss       : 12230.409533092854\n",
      "    val_log_likelihood: -12144.652074771246\n",
      "    val_log_marginal: -12153.318273770168\n",
      "Train Epoch: 2356 [256/118836 (0%)] Loss: 12246.757812\n",
      "Train Epoch: 2356 [33024/118836 (28%)] Loss: 12266.054688\n",
      "Train Epoch: 2356 [65792/118836 (55%)] Loss: 12249.222656\n",
      "Train Epoch: 2356 [98560/118836 (83%)] Loss: 12185.917969\n",
      "    epoch          : 2356\n",
      "    loss           : 12231.503926443602\n",
      "    val_loss       : 12231.890507557378\n",
      "    val_log_likelihood: -12145.636363504189\n",
      "    val_log_marginal: -12154.151960074934\n",
      "Train Epoch: 2357 [256/118836 (0%)] Loss: 12367.083008\n",
      "Train Epoch: 2357 [33024/118836 (28%)] Loss: 12303.755859\n",
      "Train Epoch: 2357 [65792/118836 (55%)] Loss: 12256.424805\n",
      "Train Epoch: 2357 [98560/118836 (83%)] Loss: 12320.552734\n",
      "    epoch          : 2357\n",
      "    loss           : 12233.348746704405\n",
      "    val_loss       : 12233.12908260957\n",
      "    val_log_likelihood: -12142.723197761581\n",
      "    val_log_marginal: -12151.210154644557\n",
      "Train Epoch: 2358 [256/118836 (0%)] Loss: 12257.500000\n",
      "Train Epoch: 2358 [33024/118836 (28%)] Loss: 12216.064453\n",
      "Train Epoch: 2358 [65792/118836 (55%)] Loss: 12346.219727\n",
      "Train Epoch: 2358 [98560/118836 (83%)] Loss: 12214.398438\n",
      "    epoch          : 2358\n",
      "    loss           : 12231.294439813379\n",
      "    val_loss       : 12230.555134580934\n",
      "    val_log_likelihood: -12145.803889610474\n",
      "    val_log_marginal: -12154.29071940289\n",
      "Train Epoch: 2359 [256/118836 (0%)] Loss: 12185.818359\n",
      "Train Epoch: 2359 [33024/118836 (28%)] Loss: 12297.946289\n",
      "Train Epoch: 2359 [65792/118836 (55%)] Loss: 12317.933594\n",
      "Train Epoch: 2359 [98560/118836 (83%)] Loss: 12293.805664\n",
      "    epoch          : 2359\n",
      "    loss           : 12227.37682937862\n",
      "    val_loss       : 12235.991171574718\n",
      "    val_log_likelihood: -12157.538602409015\n",
      "    val_log_marginal: -12166.195017941282\n",
      "Train Epoch: 2360 [256/118836 (0%)] Loss: 12185.154297\n",
      "Train Epoch: 2360 [33024/118836 (28%)] Loss: 12194.373047\n",
      "Train Epoch: 2360 [65792/118836 (55%)] Loss: 12249.180664\n",
      "Train Epoch: 2360 [98560/118836 (83%)] Loss: 12286.507812\n",
      "    epoch          : 2360\n",
      "    loss           : 12230.888663636011\n",
      "    val_loss       : 12235.031386935163\n",
      "    val_log_likelihood: -12145.238075759924\n",
      "    val_log_marginal: -12153.604544770777\n",
      "Train Epoch: 2361 [256/118836 (0%)] Loss: 12184.279297\n",
      "Train Epoch: 2361 [33024/118836 (28%)] Loss: 12331.262695\n",
      "Train Epoch: 2361 [65792/118836 (55%)] Loss: 12255.243164\n",
      "Train Epoch: 2361 [98560/118836 (83%)] Loss: 12203.294922\n",
      "    epoch          : 2361\n",
      "    loss           : 12232.710872395834\n",
      "    val_loss       : 12227.854970339076\n",
      "    val_log_likelihood: -12144.524936026675\n",
      "    val_log_marginal: -12153.06567523676\n",
      "Train Epoch: 2362 [256/118836 (0%)] Loss: 12243.748047\n",
      "Train Epoch: 2362 [33024/118836 (28%)] Loss: 12244.358398\n",
      "Train Epoch: 2362 [65792/118836 (55%)] Loss: 12190.817383\n",
      "Train Epoch: 2362 [98560/118836 (83%)] Loss: 12255.055664\n",
      "    epoch          : 2362\n",
      "    loss           : 12231.475947160618\n",
      "    val_loss       : 12228.848807972206\n",
      "    val_log_likelihood: -12143.12122040426\n",
      "    val_log_marginal: -12151.618295281361\n",
      "Train Epoch: 2363 [256/118836 (0%)] Loss: 12225.566406\n",
      "Train Epoch: 2363 [33024/118836 (28%)] Loss: 12273.495117\n",
      "Train Epoch: 2363 [65792/118836 (55%)] Loss: 12287.260742\n",
      "Train Epoch: 2363 [98560/118836 (83%)] Loss: 12178.457031\n",
      "    epoch          : 2363\n",
      "    loss           : 12233.46939797224\n",
      "    val_loss       : 12231.61848719418\n",
      "    val_log_likelihood: -12144.062760416668\n",
      "    val_log_marginal: -12152.544297077251\n",
      "Train Epoch: 2364 [256/118836 (0%)] Loss: 12217.690430\n",
      "Train Epoch: 2364 [33024/118836 (28%)] Loss: 12212.111328\n",
      "Train Epoch: 2364 [65792/118836 (55%)] Loss: 12292.130859\n",
      "Train Epoch: 2364 [98560/118836 (83%)] Loss: 12214.252930\n",
      "    epoch          : 2364\n",
      "    loss           : 12227.08797931529\n",
      "    val_loss       : 12234.497747458883\n",
      "    val_log_likelihood: -12152.880563740695\n",
      "    val_log_marginal: -12161.571541345234\n",
      "Train Epoch: 2365 [256/118836 (0%)] Loss: 12411.186523\n",
      "Train Epoch: 2365 [33024/118836 (28%)] Loss: 12189.886719\n",
      "Train Epoch: 2365 [65792/118836 (55%)] Loss: 12280.191406\n",
      "Train Epoch: 2365 [98560/118836 (83%)] Loss: 12256.364258\n",
      "    epoch          : 2365\n",
      "    loss           : 12230.394594900228\n",
      "    val_loss       : 12231.337595501305\n",
      "    val_log_likelihood: -12143.739019689569\n",
      "    val_log_marginal: -12152.139323773\n",
      "Train Epoch: 2366 [256/118836 (0%)] Loss: 12283.811523\n",
      "Train Epoch: 2366 [33024/118836 (28%)] Loss: 12248.323242\n",
      "Train Epoch: 2366 [65792/118836 (55%)] Loss: 12356.118164\n",
      "Train Epoch: 2366 [98560/118836 (83%)] Loss: 12270.606445\n",
      "    epoch          : 2366\n",
      "    loss           : 12232.313099830697\n",
      "    val_loss       : 12229.008200426488\n",
      "    val_log_likelihood: -12144.437828267164\n",
      "    val_log_marginal: -12152.928525107676\n",
      "Train Epoch: 2367 [256/118836 (0%)] Loss: 12227.958984\n",
      "Train Epoch: 2367 [33024/118836 (28%)] Loss: 12153.289062\n",
      "Train Epoch: 2367 [65792/118836 (55%)] Loss: 12169.038086\n",
      "Train Epoch: 2367 [98560/118836 (83%)] Loss: 12234.343750\n",
      "    epoch          : 2367\n",
      "    loss           : 12230.751104670699\n",
      "    val_loss       : 12229.99784998834\n",
      "    val_log_likelihood: -12146.880913978495\n",
      "    val_log_marginal: -12155.428733042394\n",
      "Train Epoch: 2368 [256/118836 (0%)] Loss: 12259.278320\n",
      "Train Epoch: 2368 [33024/118836 (28%)] Loss: 12236.859375\n",
      "Train Epoch: 2368 [65792/118836 (55%)] Loss: 12291.466797\n",
      "Train Epoch: 2368 [98560/118836 (83%)] Loss: 12191.879883\n",
      "    epoch          : 2368\n",
      "    loss           : 12232.058925409687\n",
      "    val_loss       : 12231.574876144343\n",
      "    val_log_likelihood: -12144.366916582661\n",
      "    val_log_marginal: -12152.945826854673\n",
      "Train Epoch: 2369 [256/118836 (0%)] Loss: 12239.506836\n",
      "Train Epoch: 2369 [33024/118836 (28%)] Loss: 12165.707031\n",
      "Train Epoch: 2369 [65792/118836 (55%)] Loss: 12180.022461\n",
      "Train Epoch: 2369 [98560/118836 (83%)] Loss: 12250.425781\n",
      "    epoch          : 2369\n",
      "    loss           : 12229.704695254342\n",
      "    val_loss       : 12231.553579686482\n",
      "    val_log_likelihood: -12153.154864719034\n",
      "    val_log_marginal: -12161.808708208013\n",
      "Train Epoch: 2370 [256/118836 (0%)] Loss: 12172.810547\n",
      "Train Epoch: 2370 [33024/118836 (28%)] Loss: 12187.724609\n",
      "Train Epoch: 2370 [65792/118836 (55%)] Loss: 12229.908203\n",
      "Train Epoch: 2370 [98560/118836 (83%)] Loss: 12212.118164\n",
      "    epoch          : 2370\n",
      "    loss           : 12227.020578247777\n",
      "    val_loss       : 12230.40648707169\n",
      "    val_log_likelihood: -12144.023435884512\n",
      "    val_log_marginal: -12152.447331248759\n",
      "Train Epoch: 2371 [256/118836 (0%)] Loss: 12248.595703\n",
      "Train Epoch: 2371 [33024/118836 (28%)] Loss: 12338.646484\n",
      "Train Epoch: 2371 [65792/118836 (55%)] Loss: 12291.028320\n",
      "Train Epoch: 2371 [98560/118836 (83%)] Loss: 12237.599609\n",
      "    epoch          : 2371\n",
      "    loss           : 12230.618384091968\n",
      "    val_loss       : 12230.700960456632\n",
      "    val_log_likelihood: -12141.876997874018\n",
      "    val_log_marginal: -12150.190404947247\n",
      "Train Epoch: 2372 [256/118836 (0%)] Loss: 12235.289062\n",
      "Train Epoch: 2372 [33024/118836 (28%)] Loss: 12315.830078\n",
      "Train Epoch: 2372 [65792/118836 (55%)] Loss: 12330.258789\n",
      "Train Epoch: 2372 [98560/118836 (83%)] Loss: 12250.247070\n",
      "    epoch          : 2372\n",
      "    loss           : 12232.566440336797\n",
      "    val_loss       : 12230.832458524574\n",
      "    val_log_likelihood: -12145.404750827129\n",
      "    val_log_marginal: -12154.097639264006\n",
      "Train Epoch: 2373 [256/118836 (0%)] Loss: 12244.666016\n",
      "Train Epoch: 2373 [33024/118836 (28%)] Loss: 12424.286133\n",
      "Train Epoch: 2373 [65792/118836 (55%)] Loss: 12231.854492\n",
      "Train Epoch: 2373 [98560/118836 (83%)] Loss: 12129.631836\n",
      "    epoch          : 2373\n",
      "    loss           : 12230.671391161342\n",
      "    val_loss       : 12232.581502059877\n",
      "    val_log_likelihood: -12147.357485202128\n",
      "    val_log_marginal: -12155.969475591859\n",
      "Train Epoch: 2374 [256/118836 (0%)] Loss: 12203.631836\n",
      "Train Epoch: 2374 [33024/118836 (28%)] Loss: 12177.885742\n",
      "Train Epoch: 2374 [65792/118836 (55%)] Loss: 12303.450195\n",
      "Train Epoch: 2374 [98560/118836 (83%)] Loss: 12235.798828\n",
      "    epoch          : 2374\n",
      "    loss           : 12231.53906766956\n",
      "    val_loss       : 12229.167648077044\n",
      "    val_log_likelihood: -12145.717101879136\n",
      "    val_log_marginal: -12154.564609470423\n",
      "Train Epoch: 2375 [256/118836 (0%)] Loss: 12338.570312\n",
      "Train Epoch: 2375 [33024/118836 (28%)] Loss: 12234.716797\n",
      "Train Epoch: 2375 [65792/118836 (55%)] Loss: 12304.615234\n",
      "Train Epoch: 2375 [98560/118836 (83%)] Loss: 12215.723633\n",
      "    epoch          : 2375\n",
      "    loss           : 12241.031466475393\n",
      "    val_loss       : 12232.828370929656\n",
      "    val_log_likelihood: -12144.342107694893\n",
      "    val_log_marginal: -12153.089667275503\n",
      "Train Epoch: 2376 [256/118836 (0%)] Loss: 12234.175781\n",
      "Train Epoch: 2376 [33024/118836 (28%)] Loss: 12295.529297\n",
      "Train Epoch: 2376 [65792/118836 (55%)] Loss: 12090.626953\n",
      "Train Epoch: 2376 [98560/118836 (83%)] Loss: 12173.922852\n",
      "    epoch          : 2376\n",
      "    loss           : 12234.250279964072\n",
      "    val_loss       : 12227.625525869551\n",
      "    val_log_likelihood: -12145.667698801954\n",
      "    val_log_marginal: -12154.101836579988\n",
      "Train Epoch: 2377 [256/118836 (0%)] Loss: 12232.336914\n",
      "Train Epoch: 2377 [33024/118836 (28%)] Loss: 12170.604492\n",
      "Train Epoch: 2377 [65792/118836 (55%)] Loss: 12245.481445\n",
      "Train Epoch: 2377 [98560/118836 (83%)] Loss: 12259.419922\n",
      "    epoch          : 2377\n",
      "    loss           : 12228.912477221618\n",
      "    val_loss       : 12229.265634851477\n",
      "    val_log_likelihood: -12141.948152851013\n",
      "    val_log_marginal: -12150.322023981918\n",
      "Train Epoch: 2378 [256/118836 (0%)] Loss: 12254.339844\n",
      "Train Epoch: 2378 [33024/118836 (28%)] Loss: 12292.509766\n",
      "Train Epoch: 2378 [65792/118836 (55%)] Loss: 12292.344727\n",
      "Train Epoch: 2378 [98560/118836 (83%)] Loss: 12202.899414\n",
      "    epoch          : 2378\n",
      "    loss           : 12223.52492051799\n",
      "    val_loss       : 12229.397787020253\n",
      "    val_log_likelihood: -12141.806167771661\n",
      "    val_log_marginal: -12150.211092660245\n",
      "Train Epoch: 2379 [256/118836 (0%)] Loss: 12193.686523\n",
      "Train Epoch: 2379 [33024/118836 (28%)] Loss: 12174.644531\n",
      "Train Epoch: 2379 [65792/118836 (55%)] Loss: 12260.563477\n",
      "Train Epoch: 2379 [98560/118836 (83%)] Loss: 12289.135742\n",
      "    epoch          : 2379\n",
      "    loss           : 12230.306080858405\n",
      "    val_loss       : 12228.815853622044\n",
      "    val_log_likelihood: -12146.095869358714\n",
      "    val_log_marginal: -12154.830710322254\n",
      "Train Epoch: 2380 [256/118836 (0%)] Loss: 12305.653320\n",
      "Train Epoch: 2380 [33024/118836 (28%)] Loss: 12269.088867\n",
      "Train Epoch: 2380 [65792/118836 (55%)] Loss: 12254.227539\n",
      "Train Epoch: 2380 [98560/118836 (83%)] Loss: 12247.144531\n",
      "    epoch          : 2380\n",
      "    loss           : 12229.217503004807\n",
      "    val_loss       : 12229.041800337007\n",
      "    val_log_likelihood: -12145.076610156895\n",
      "    val_log_marginal: -12153.64643602135\n",
      "Train Epoch: 2381 [256/118836 (0%)] Loss: 12353.669922\n",
      "Train Epoch: 2381 [33024/118836 (28%)] Loss: 12158.835938\n",
      "Train Epoch: 2381 [65792/118836 (55%)] Loss: 12307.561523\n",
      "Train Epoch: 2381 [98560/118836 (83%)] Loss: 12184.518555\n",
      "    epoch          : 2381\n",
      "    loss           : 12231.914590279932\n",
      "    val_loss       : 12228.653586539462\n",
      "    val_log_likelihood: -12139.655754691377\n",
      "    val_log_marginal: -12148.097139335649\n",
      "Train Epoch: 2382 [256/118836 (0%)] Loss: 12139.880859\n",
      "Train Epoch: 2382 [33024/118836 (28%)] Loss: 12234.618164\n",
      "Train Epoch: 2382 [65792/118836 (55%)] Loss: 12190.698242\n",
      "Train Epoch: 2382 [98560/118836 (83%)] Loss: 12284.538086\n",
      "    epoch          : 2382\n",
      "    loss           : 12230.473485156896\n",
      "    val_loss       : 12226.68315472166\n",
      "    val_log_likelihood: -12144.979592347756\n",
      "    val_log_marginal: -12153.743166614042\n",
      "Train Epoch: 2383 [256/118836 (0%)] Loss: 12267.984375\n",
      "Train Epoch: 2383 [33024/118836 (28%)] Loss: 12292.592773\n",
      "Train Epoch: 2383 [65792/118836 (55%)] Loss: 12344.240234\n",
      "Train Epoch: 2383 [98560/118836 (83%)] Loss: 12206.830078\n",
      "    epoch          : 2383\n",
      "    loss           : 12237.262514377844\n",
      "    val_loss       : 12232.405402522238\n",
      "    val_log_likelihood: -12149.041456653225\n",
      "    val_log_marginal: -12157.765295299423\n",
      "Train Epoch: 2384 [256/118836 (0%)] Loss: 12220.445312\n",
      "Train Epoch: 2384 [33024/118836 (28%)] Loss: 12227.402344\n",
      "Train Epoch: 2384 [65792/118836 (55%)] Loss: 12211.703125\n",
      "Train Epoch: 2384 [98560/118836 (83%)] Loss: 12172.728516\n",
      "    epoch          : 2384\n",
      "    loss           : 12230.504068444996\n",
      "    val_loss       : 12229.089161301747\n",
      "    val_log_likelihood: -12144.350533595689\n",
      "    val_log_marginal: -12152.952009473795\n",
      "Train Epoch: 2385 [256/118836 (0%)] Loss: 12201.439453\n",
      "Train Epoch: 2385 [33024/118836 (28%)] Loss: 12182.314453\n",
      "Train Epoch: 2385 [65792/118836 (55%)] Loss: 12183.568359\n",
      "Train Epoch: 2385 [98560/118836 (83%)] Loss: 12196.062500\n",
      "    epoch          : 2385\n",
      "    loss           : 12225.98032060975\n",
      "    val_loss       : 12229.09473455943\n",
      "    val_log_likelihood: -12141.478188004032\n",
      "    val_log_marginal: -12150.168987882442\n",
      "Train Epoch: 2386 [256/118836 (0%)] Loss: 12299.089844\n",
      "Train Epoch: 2386 [33024/118836 (28%)] Loss: 12217.517578\n",
      "Train Epoch: 2386 [65792/118836 (55%)] Loss: 12250.822266\n",
      "Train Epoch: 2386 [98560/118836 (83%)] Loss: 12322.383789\n",
      "    epoch          : 2386\n",
      "    loss           : 12223.892542745813\n",
      "    val_loss       : 12227.903023316667\n",
      "    val_log_likelihood: -12139.834283886477\n",
      "    val_log_marginal: -12148.30545531976\n",
      "Train Epoch: 2387 [256/118836 (0%)] Loss: 12186.057617\n",
      "Train Epoch: 2387 [33024/118836 (28%)] Loss: 12266.674805\n",
      "Train Epoch: 2387 [65792/118836 (55%)] Loss: 12226.263672\n",
      "Train Epoch: 2387 [98560/118836 (83%)] Loss: 12292.838867\n",
      "    epoch          : 2387\n",
      "    loss           : 12227.937533117505\n",
      "    val_loss       : 12224.846869090678\n",
      "    val_log_likelihood: -12143.823481764372\n",
      "    val_log_marginal: -12152.364423409168\n",
      "Train Epoch: 2388 [256/118836 (0%)] Loss: 12236.897461\n",
      "Train Epoch: 2388 [33024/118836 (28%)] Loss: 12229.883789\n",
      "Train Epoch: 2388 [65792/118836 (55%)] Loss: 12193.500000\n",
      "Train Epoch: 2388 [98560/118836 (83%)] Loss: 12276.197266\n",
      "    epoch          : 2388\n",
      "    loss           : 12230.176405636115\n",
      "    val_loss       : 12225.524985409236\n",
      "    val_log_likelihood: -12141.79265647617\n",
      "    val_log_marginal: -12150.258406330451\n",
      "Train Epoch: 2389 [256/118836 (0%)] Loss: 12175.679688\n",
      "Train Epoch: 2389 [33024/118836 (28%)] Loss: 12146.134766\n",
      "Train Epoch: 2389 [65792/118836 (55%)] Loss: 12358.893555\n",
      "Train Epoch: 2389 [98560/118836 (83%)] Loss: 12204.617188\n",
      "    epoch          : 2389\n",
      "    loss           : 12229.016756164703\n",
      "    val_loss       : 12229.766181734025\n",
      "    val_log_likelihood: -12139.58756865824\n",
      "    val_log_marginal: -12148.060244925204\n",
      "Train Epoch: 2390 [256/118836 (0%)] Loss: 12208.892578\n",
      "Train Epoch: 2390 [33024/118836 (28%)] Loss: 12300.046875\n",
      "Train Epoch: 2390 [65792/118836 (55%)] Loss: 12166.480469\n",
      "Train Epoch: 2390 [98560/118836 (83%)] Loss: 12335.955078\n",
      "    epoch          : 2390\n",
      "    loss           : 12230.35300109207\n",
      "    val_loss       : 12231.271023710187\n",
      "    val_log_likelihood: -12139.658078570874\n",
      "    val_log_marginal: -12148.174333338944\n",
      "Train Epoch: 2391 [256/118836 (0%)] Loss: 12302.247070\n",
      "Train Epoch: 2391 [33024/118836 (28%)] Loss: 12192.337891\n",
      "Train Epoch: 2391 [65792/118836 (55%)] Loss: 12225.608398\n",
      "Train Epoch: 2391 [98560/118836 (83%)] Loss: 12266.148438\n",
      "    epoch          : 2391\n",
      "    loss           : 12232.771629284274\n",
      "    val_loss       : 12232.361068738483\n",
      "    val_log_likelihood: -12145.107584231546\n",
      "    val_log_marginal: -12153.742377367513\n",
      "Train Epoch: 2392 [256/118836 (0%)] Loss: 12181.080078\n",
      "Train Epoch: 2392 [33024/118836 (28%)] Loss: 12267.141602\n",
      "Train Epoch: 2392 [65792/118836 (55%)] Loss: 12292.661133\n",
      "Train Epoch: 2392 [98560/118836 (83%)] Loss: 12211.279297\n",
      "    epoch          : 2392\n",
      "    loss           : 12232.350885772074\n",
      "    val_loss       : 12234.68931291282\n",
      "    val_log_likelihood: -12147.834319588763\n",
      "    val_log_marginal: -12156.584561144258\n",
      "Train Epoch: 2393 [256/118836 (0%)] Loss: 12331.392578\n",
      "Train Epoch: 2393 [33024/118836 (28%)] Loss: 12307.955078\n",
      "Train Epoch: 2393 [65792/118836 (55%)] Loss: 12206.617188\n",
      "Train Epoch: 2393 [98560/118836 (83%)] Loss: 12229.851562\n",
      "    epoch          : 2393\n",
      "    loss           : 12226.57516429513\n",
      "    val_loss       : 12228.792520372308\n",
      "    val_log_likelihood: -12139.15265069272\n",
      "    val_log_marginal: -12147.725227793038\n",
      "Train Epoch: 2394 [256/118836 (0%)] Loss: 12321.657227\n",
      "Train Epoch: 2394 [33024/118836 (28%)] Loss: 12327.500000\n",
      "Train Epoch: 2394 [65792/118836 (55%)] Loss: 12240.610352\n",
      "Train Epoch: 2394 [98560/118836 (83%)] Loss: 12158.461914\n",
      "    epoch          : 2394\n",
      "    loss           : 12227.095676954095\n",
      "    val_loss       : 12236.357444479148\n",
      "    val_log_likelihood: -12138.958645607165\n",
      "    val_log_marginal: -12147.61150414344\n",
      "Train Epoch: 2395 [256/118836 (0%)] Loss: 12228.554688\n",
      "Train Epoch: 2395 [33024/118836 (28%)] Loss: 12231.164062\n",
      "Train Epoch: 2395 [65792/118836 (55%)] Loss: 12295.765625\n",
      "Train Epoch: 2395 [98560/118836 (83%)] Loss: 12223.543945\n",
      "    epoch          : 2395\n",
      "    loss           : 12230.027131151779\n",
      "    val_loss       : 12236.761701676643\n",
      "    val_log_likelihood: -12143.88714055392\n",
      "    val_log_marginal: -12152.674163689137\n",
      "Train Epoch: 2396 [256/118836 (0%)] Loss: 12343.130859\n",
      "Train Epoch: 2396 [33024/118836 (28%)] Loss: 12272.998047\n",
      "Train Epoch: 2396 [65792/118836 (55%)] Loss: 12334.039062\n",
      "Train Epoch: 2396 [98560/118836 (83%)] Loss: 12215.704102\n",
      "    epoch          : 2396\n",
      "    loss           : 12256.871581142732\n",
      "    val_loss       : 12265.677242197627\n",
      "    val_log_likelihood: -12147.055059708437\n",
      "    val_log_marginal: -12155.819829328835\n",
      "Train Epoch: 2397 [256/118836 (0%)] Loss: 12309.130859\n",
      "Train Epoch: 2397 [33024/118836 (28%)] Loss: 12205.413086\n",
      "Train Epoch: 2397 [65792/118836 (55%)] Loss: 12405.791016\n",
      "Train Epoch: 2397 [98560/118836 (83%)] Loss: 12350.841797\n",
      "    epoch          : 2397\n",
      "    loss           : 12253.424868822374\n",
      "    val_loss       : 12239.585701476157\n",
      "    val_log_likelihood: -12144.286825049112\n",
      "    val_log_marginal: -12152.96757231096\n",
      "Train Epoch: 2398 [256/118836 (0%)] Loss: 12307.148438\n",
      "Train Epoch: 2398 [33024/118836 (28%)] Loss: 12338.093750\n",
      "Train Epoch: 2398 [65792/118836 (55%)] Loss: 12245.731445\n",
      "Train Epoch: 2398 [98560/118836 (83%)] Loss: 12212.564453\n",
      "    epoch          : 2398\n",
      "    loss           : 12239.604871180985\n",
      "    val_loss       : 12234.570853516358\n",
      "    val_log_likelihood: -12149.389107572115\n",
      "    val_log_marginal: -12158.119496564572\n",
      "Train Epoch: 2399 [256/118836 (0%)] Loss: 12310.431641\n",
      "Train Epoch: 2399 [33024/118836 (28%)] Loss: 12390.723633\n",
      "Train Epoch: 2399 [65792/118836 (55%)] Loss: 12224.706055\n",
      "Train Epoch: 2399 [98560/118836 (83%)] Loss: 12159.956055\n",
      "    epoch          : 2399\n",
      "    loss           : 12231.958804894282\n",
      "    val_loss       : 12231.854598198912\n",
      "    val_log_likelihood: -12143.71287834729\n",
      "    val_log_marginal: -12152.362262002705\n",
      "Train Epoch: 2400 [256/118836 (0%)] Loss: 12319.737305\n",
      "Train Epoch: 2400 [33024/118836 (28%)] Loss: 12198.605469\n",
      "Train Epoch: 2400 [65792/118836 (55%)] Loss: 12289.167969\n",
      "Train Epoch: 2400 [98560/118836 (83%)] Loss: 12310.875977\n",
      "    epoch          : 2400\n",
      "    loss           : 12234.900509686466\n",
      "    val_loss       : 12226.685947703345\n",
      "    val_log_likelihood: -12142.943866638234\n",
      "    val_log_marginal: -12151.37326797104\n",
      "Saving checkpoint: saved/models/SelfiesAutoencodingOperad/0905_154251/checkpoint-epoch2400.pth ...\n",
      "Train Epoch: 2401 [256/118836 (0%)] Loss: 12171.545898\n",
      "Train Epoch: 2401 [33024/118836 (28%)] Loss: 12229.582031\n",
      "Train Epoch: 2401 [65792/118836 (55%)] Loss: 12254.112305\n",
      "Train Epoch: 2401 [98560/118836 (83%)] Loss: 12152.440430\n",
      "    epoch          : 2401\n",
      "    loss           : 12227.706215105458\n",
      "    val_loss       : 12236.7333544729\n",
      "    val_log_likelihood: -12160.02512390793\n",
      "    val_log_marginal: -12168.82655127753\n",
      "Train Epoch: 2402 [256/118836 (0%)] Loss: 12243.071289\n",
      "Train Epoch: 2402 [33024/118836 (28%)] Loss: 12287.276367\n",
      "Train Epoch: 2402 [65792/118836 (55%)] Loss: 12210.575195\n",
      "Train Epoch: 2402 [98560/118836 (83%)] Loss: 12175.133789\n",
      "    epoch          : 2402\n",
      "    loss           : 12229.357681322374\n",
      "    val_loss       : 12228.01848017347\n",
      "    val_log_likelihood: -12142.29563705154\n",
      "    val_log_marginal: -12150.771747460176\n",
      "Train Epoch: 2403 [256/118836 (0%)] Loss: 12260.500000\n",
      "Train Epoch: 2403 [33024/118836 (28%)] Loss: 12227.500977\n",
      "Train Epoch: 2403 [65792/118836 (55%)] Loss: 12256.516602\n",
      "Train Epoch: 2403 [98560/118836 (83%)] Loss: 12284.000977\n",
      "    epoch          : 2403\n",
      "    loss           : 12231.523346224927\n",
      "    val_loss       : 12230.354296925345\n",
      "    val_log_likelihood: -12143.502508852875\n",
      "    val_log_marginal: -12152.075176339098\n",
      "Train Epoch: 2404 [256/118836 (0%)] Loss: 12263.699219\n",
      "Train Epoch: 2404 [33024/118836 (28%)] Loss: 12188.441406\n",
      "Train Epoch: 2404 [65792/118836 (55%)] Loss: 12276.943359\n",
      "Train Epoch: 2404 [98560/118836 (83%)] Loss: 12278.979492\n",
      "    epoch          : 2404\n",
      "    loss           : 12227.416942268921\n",
      "    val_loss       : 12228.015258164522\n",
      "    val_log_likelihood: -12140.227598027814\n",
      "    val_log_marginal: -12148.742452997758\n",
      "Train Epoch: 2405 [256/118836 (0%)] Loss: 12221.255859\n",
      "Train Epoch: 2405 [33024/118836 (28%)] Loss: 12160.903320\n",
      "Train Epoch: 2405 [65792/118836 (55%)] Loss: 12258.509766\n",
      "Train Epoch: 2405 [98560/118836 (83%)] Loss: 12304.093750\n",
      "    epoch          : 2405\n",
      "    loss           : 12227.990017253413\n",
      "    val_loss       : 12228.408888676648\n",
      "    val_log_likelihood: -12139.374249282724\n",
      "    val_log_marginal: -12148.047400987283\n",
      "Train Epoch: 2406 [256/118836 (0%)] Loss: 12255.109375\n",
      "Train Epoch: 2406 [33024/118836 (28%)] Loss: 12257.051758\n",
      "Train Epoch: 2406 [65792/118836 (55%)] Loss: 12365.782227\n",
      "Train Epoch: 2406 [98560/118836 (83%)] Loss: 12338.922852\n",
      "    epoch          : 2406\n",
      "    loss           : 12223.77674828112\n",
      "    val_loss       : 12230.800504716844\n",
      "    val_log_likelihood: -12151.201820978082\n",
      "    val_log_marginal: -12159.597598151784\n",
      "Train Epoch: 2407 [256/118836 (0%)] Loss: 12238.386719\n",
      "Train Epoch: 2407 [33024/118836 (28%)] Loss: 12287.050781\n",
      "Train Epoch: 2407 [65792/118836 (55%)] Loss: 12186.798828\n",
      "Train Epoch: 2407 [98560/118836 (83%)] Loss: 12246.099609\n",
      "    epoch          : 2407\n",
      "    loss           : 12230.78636431193\n",
      "    val_loss       : 12228.855550390232\n",
      "    val_log_likelihood: -12146.818586997259\n",
      "    val_log_marginal: -12155.435514464447\n",
      "Train Epoch: 2408 [256/118836 (0%)] Loss: 12369.317383\n",
      "Train Epoch: 2408 [33024/118836 (28%)] Loss: 12184.012695\n",
      "Train Epoch: 2408 [65792/118836 (55%)] Loss: 12178.746094\n",
      "Train Epoch: 2408 [98560/118836 (83%)] Loss: 12298.785156\n",
      "    epoch          : 2408\n",
      "    loss           : 12229.715742445978\n",
      "    val_loss       : 12228.639741923902\n",
      "    val_log_likelihood: -12141.465072018455\n",
      "    val_log_marginal: -12150.020830093474\n",
      "Train Epoch: 2409 [256/118836 (0%)] Loss: 12234.300781\n",
      "Train Epoch: 2409 [33024/118836 (28%)] Loss: 12345.441406\n",
      "Train Epoch: 2409 [65792/118836 (55%)] Loss: 12291.253906\n",
      "Train Epoch: 2409 [98560/118836 (83%)] Loss: 12230.538086\n",
      "    epoch          : 2409\n",
      "    loss           : 12232.999402754085\n",
      "    val_loss       : 12240.431827155819\n",
      "    val_log_likelihood: -12147.881947567721\n",
      "    val_log_marginal: -12156.632091953114\n",
      "Train Epoch: 2410 [256/118836 (0%)] Loss: 12297.908203\n",
      "Train Epoch: 2410 [33024/118836 (28%)] Loss: 12243.744141\n",
      "Train Epoch: 2410 [65792/118836 (55%)] Loss: 12181.371094\n",
      "Train Epoch: 2410 [98560/118836 (83%)] Loss: 12305.527344\n",
      "    epoch          : 2410\n",
      "    loss           : 12232.847241877325\n",
      "    val_loss       : 12226.922029930472\n",
      "    val_log_likelihood: -12141.579478778951\n",
      "    val_log_marginal: -12150.13004791229\n",
      "Train Epoch: 2411 [256/118836 (0%)] Loss: 12274.883789\n",
      "Train Epoch: 2411 [33024/118836 (28%)] Loss: 12273.474609\n",
      "Train Epoch: 2411 [65792/118836 (55%)] Loss: 12244.041992\n",
      "Train Epoch: 2411 [98560/118836 (83%)] Loss: 12230.521484\n",
      "    epoch          : 2411\n",
      "    loss           : 12226.129629988627\n",
      "    val_loss       : 12226.404002035617\n",
      "    val_log_likelihood: -12142.720768713813\n",
      "    val_log_marginal: -12151.164141501267\n",
      "Train Epoch: 2412 [256/118836 (0%)] Loss: 12336.969727\n",
      "Train Epoch: 2412 [33024/118836 (28%)] Loss: 12162.657227\n",
      "Train Epoch: 2412 [65792/118836 (55%)] Loss: 12166.623047\n",
      "Train Epoch: 2412 [98560/118836 (83%)] Loss: 12176.005859\n",
      "    epoch          : 2412\n",
      "    loss           : 12226.790783640923\n",
      "    val_loss       : 12229.213494223972\n",
      "    val_log_likelihood: -12140.870597148987\n",
      "    val_log_marginal: -12149.31652231585\n",
      "Train Epoch: 2413 [256/118836 (0%)] Loss: 12239.401367\n",
      "Train Epoch: 2413 [33024/118836 (28%)] Loss: 12280.800781\n",
      "Train Epoch: 2413 [65792/118836 (55%)] Loss: 12175.305664\n",
      "Train Epoch: 2413 [98560/118836 (83%)] Loss: 12252.765625\n",
      "    epoch          : 2413\n",
      "    loss           : 12227.523250426488\n",
      "    val_loss       : 12225.310325518327\n",
      "    val_log_likelihood: -12141.697991302213\n",
      "    val_log_marginal: -12150.052137916531\n",
      "Train Epoch: 2414 [256/118836 (0%)] Loss: 12356.208984\n",
      "Train Epoch: 2414 [33024/118836 (28%)] Loss: 12395.129883\n",
      "Train Epoch: 2414 [65792/118836 (55%)] Loss: 12259.579102\n",
      "Train Epoch: 2414 [98560/118836 (83%)] Loss: 12280.001953\n",
      "    epoch          : 2414\n",
      "    loss           : 12232.394156618333\n",
      "    val_loss       : 12226.581510551054\n",
      "    val_log_likelihood: -12138.70860990488\n",
      "    val_log_marginal: -12147.132945947833\n",
      "Train Epoch: 2415 [256/118836 (0%)] Loss: 12207.275391\n",
      "Train Epoch: 2415 [33024/118836 (28%)] Loss: 12265.608398\n",
      "Train Epoch: 2415 [65792/118836 (55%)] Loss: 12256.731445\n",
      "Train Epoch: 2415 [98560/118836 (83%)] Loss: 12304.567383\n",
      "    epoch          : 2415\n",
      "    loss           : 12227.52499757677\n",
      "    val_loss       : 12229.60136586452\n",
      "    val_log_likelihood: -12141.354320299575\n",
      "    val_log_marginal: -12149.68176633949\n",
      "Train Epoch: 2416 [256/118836 (0%)] Loss: 12265.705078\n",
      "Train Epoch: 2416 [33024/118836 (28%)] Loss: 12242.750000\n",
      "Train Epoch: 2416 [65792/118836 (55%)] Loss: 12302.337891\n",
      "Train Epoch: 2416 [98560/118836 (83%)] Loss: 12220.533203\n",
      "    epoch          : 2416\n",
      "    loss           : 12231.125857339484\n",
      "    val_loss       : 12233.834968404452\n",
      "    val_log_likelihood: -12156.002757476479\n",
      "    val_log_marginal: -12164.480944692792\n",
      "Train Epoch: 2417 [256/118836 (0%)] Loss: 12204.708984\n",
      "Train Epoch: 2417 [33024/118836 (28%)] Loss: 12329.076172\n",
      "Train Epoch: 2417 [65792/118836 (55%)] Loss: 12202.230469\n",
      "Train Epoch: 2417 [98560/118836 (83%)] Loss: 12159.679688\n",
      "    epoch          : 2417\n",
      "    loss           : 12232.335305197994\n",
      "    val_loss       : 12229.547180660486\n",
      "    val_log_likelihood: -12140.618247098584\n",
      "    val_log_marginal: -12149.043094603396\n",
      "Train Epoch: 2418 [256/118836 (0%)] Loss: 12134.189453\n",
      "Train Epoch: 2418 [33024/118836 (28%)] Loss: 12181.913086\n",
      "Train Epoch: 2418 [65792/118836 (55%)] Loss: 12268.068359\n",
      "Train Epoch: 2418 [98560/118836 (83%)] Loss: 12247.996094\n",
      "    epoch          : 2418\n",
      "    loss           : 12227.306272293736\n",
      "    val_loss       : 12230.597909739894\n",
      "    val_log_likelihood: -12141.512481906533\n",
      "    val_log_marginal: -12150.24917507776\n",
      "Train Epoch: 2419 [256/118836 (0%)] Loss: 12298.283203\n",
      "Train Epoch: 2419 [33024/118836 (28%)] Loss: 12240.320312\n",
      "Train Epoch: 2419 [65792/118836 (55%)] Loss: 12218.965820\n",
      "Train Epoch: 2419 [98560/118836 (83%)] Loss: 12233.291016\n",
      "    epoch          : 2419\n",
      "    loss           : 12230.52379985396\n",
      "    val_loss       : 12228.62164458284\n",
      "    val_log_likelihood: -12141.62092283137\n",
      "    val_log_marginal: -12150.044361623726\n",
      "Train Epoch: 2420 [256/118836 (0%)] Loss: 12197.269531\n",
      "Train Epoch: 2420 [33024/118836 (28%)] Loss: 12269.003906\n",
      "Train Epoch: 2420 [65792/118836 (55%)] Loss: 12257.583984\n",
      "Train Epoch: 2420 [98560/118836 (83%)] Loss: 12268.351562\n",
      "    epoch          : 2420\n",
      "    loss           : 12227.586464633736\n",
      "    val_loss       : 12230.933205364776\n",
      "    val_log_likelihood: -12149.111476588347\n",
      "    val_log_marginal: -12157.798416810667\n",
      "Train Epoch: 2421 [256/118836 (0%)] Loss: 12213.900391\n",
      "Train Epoch: 2421 [33024/118836 (28%)] Loss: 12223.311523\n",
      "Train Epoch: 2421 [65792/118836 (55%)] Loss: 12183.704102\n",
      "Train Epoch: 2421 [98560/118836 (83%)] Loss: 12172.251953\n",
      "    epoch          : 2421\n",
      "    loss           : 12225.97096321857\n",
      "    val_loss       : 12226.610446718094\n",
      "    val_log_likelihood: -12137.687463813068\n",
      "    val_log_marginal: -12146.191473919607\n",
      "Train Epoch: 2422 [256/118836 (0%)] Loss: 12237.216797\n",
      "Train Epoch: 2422 [33024/118836 (28%)] Loss: 12339.062500\n",
      "Train Epoch: 2422 [65792/118836 (55%)] Loss: 12325.589844\n",
      "Train Epoch: 2422 [98560/118836 (83%)] Loss: 12294.336914\n",
      "    epoch          : 2422\n",
      "    loss           : 12230.53774506953\n",
      "    val_loss       : 12232.61031177037\n",
      "    val_log_likelihood: -12142.441006739817\n",
      "    val_log_marginal: -12151.043080420804\n",
      "Train Epoch: 2423 [256/118836 (0%)] Loss: 12180.786133\n",
      "Train Epoch: 2423 [33024/118836 (28%)] Loss: 12274.854492\n",
      "Train Epoch: 2423 [65792/118836 (55%)] Loss: 12249.983398\n",
      "Train Epoch: 2423 [98560/118836 (83%)] Loss: 12235.458008\n",
      "    epoch          : 2423\n",
      "    loss           : 12232.095767421424\n",
      "    val_loss       : 12227.499558704747\n",
      "    val_log_likelihood: -12141.909936866728\n",
      "    val_log_marginal: -12150.315854983754\n",
      "Train Epoch: 2424 [256/118836 (0%)] Loss: 12299.470703\n",
      "Train Epoch: 2424 [33024/118836 (28%)] Loss: 12258.877930\n",
      "Train Epoch: 2424 [65792/118836 (55%)] Loss: 12238.378906\n",
      "Train Epoch: 2424 [98560/118836 (83%)] Loss: 12157.558594\n",
      "    epoch          : 2424\n",
      "    loss           : 12226.411868505738\n",
      "    val_loss       : 12223.810190424816\n",
      "    val_log_likelihood: -12138.534835252533\n",
      "    val_log_marginal: -12146.898119377103\n",
      "Train Epoch: 2425 [256/118836 (0%)] Loss: 12236.855469\n",
      "Train Epoch: 2425 [33024/118836 (28%)] Loss: 12215.931641\n",
      "Train Epoch: 2425 [65792/118836 (55%)] Loss: 12189.744141\n",
      "Train Epoch: 2425 [98560/118836 (83%)] Loss: 12252.945312\n",
      "    epoch          : 2425\n",
      "    loss           : 12228.761939264114\n",
      "    val_loss       : 12226.05362804842\n",
      "    val_log_likelihood: -12143.931651125673\n",
      "    val_log_marginal: -12152.291777739825\n",
      "Train Epoch: 2426 [256/118836 (0%)] Loss: 12182.427734\n",
      "Train Epoch: 2426 [33024/118836 (28%)] Loss: 12360.013672\n",
      "Train Epoch: 2426 [65792/118836 (55%)] Loss: 12321.128906\n",
      "Train Epoch: 2426 [98560/118836 (83%)] Loss: 12248.125000\n",
      "    epoch          : 2426\n",
      "    loss           : 12227.202435671268\n",
      "    val_loss       : 12228.84144557097\n",
      "    val_log_likelihood: -12141.101584955282\n",
      "    val_log_marginal: -12149.60988374288\n",
      "Train Epoch: 2427 [256/118836 (0%)] Loss: 12302.543945\n",
      "Train Epoch: 2427 [33024/118836 (28%)] Loss: 12162.902344\n",
      "Train Epoch: 2427 [65792/118836 (55%)] Loss: 12333.566406\n",
      "Train Epoch: 2427 [98560/118836 (83%)] Loss: 12224.709961\n",
      "    epoch          : 2427\n",
      "    loss           : 12230.109602622259\n",
      "    val_loss       : 12228.167011157744\n",
      "    val_log_likelihood: -12143.753678143092\n",
      "    val_log_marginal: -12152.191094881262\n",
      "Train Epoch: 2428 [256/118836 (0%)] Loss: 12392.051758\n",
      "Train Epoch: 2428 [33024/118836 (28%)] Loss: 12297.730469\n",
      "Train Epoch: 2428 [65792/118836 (55%)] Loss: 12290.740234\n",
      "Train Epoch: 2428 [98560/118836 (83%)] Loss: 12295.030273\n",
      "    epoch          : 2428\n",
      "    loss           : 12231.235056735939\n",
      "    val_loss       : 12229.306157981271\n",
      "    val_log_likelihood: -12140.70529653898\n",
      "    val_log_marginal: -12149.33107035833\n",
      "Train Epoch: 2429 [256/118836 (0%)] Loss: 12252.517578\n",
      "Train Epoch: 2429 [33024/118836 (28%)] Loss: 12268.256836\n",
      "Train Epoch: 2429 [65792/118836 (55%)] Loss: 12335.894531\n",
      "Train Epoch: 2429 [98560/118836 (83%)] Loss: 12188.630859\n",
      "    epoch          : 2429\n",
      "    loss           : 12223.42604134357\n",
      "    val_loss       : 12231.396486976533\n",
      "    val_log_likelihood: -12141.646264022436\n",
      "    val_log_marginal: -12150.071592630637\n",
      "Train Epoch: 2430 [256/118836 (0%)] Loss: 12200.114258\n",
      "Train Epoch: 2430 [33024/118836 (28%)] Loss: 12189.048828\n",
      "Train Epoch: 2430 [65792/118836 (55%)] Loss: 12238.524414\n",
      "Train Epoch: 2430 [98560/118836 (83%)] Loss: 12236.643555\n",
      "    epoch          : 2430\n",
      "    loss           : 12230.27138857656\n",
      "    val_loss       : 12230.359587232271\n",
      "    val_log_likelihood: -12141.696749961227\n",
      "    val_log_marginal: -12150.377975613288\n",
      "Train Epoch: 2431 [256/118836 (0%)] Loss: 12231.039062\n",
      "Train Epoch: 2431 [33024/118836 (28%)] Loss: 12148.568359\n",
      "Train Epoch: 2431 [65792/118836 (55%)] Loss: 12466.029297\n",
      "Train Epoch: 2431 [98560/118836 (83%)] Loss: 12321.601562\n",
      "    epoch          : 2431\n",
      "    loss           : 12233.318007198615\n",
      "    val_loss       : 12229.884783203555\n",
      "    val_log_likelihood: -12140.570604257133\n",
      "    val_log_marginal: -12149.120401568793\n",
      "Train Epoch: 2432 [256/118836 (0%)] Loss: 12359.323242\n",
      "Train Epoch: 2432 [33024/118836 (28%)] Loss: 12233.178711\n",
      "Train Epoch: 2432 [65792/118836 (55%)] Loss: 12323.744141\n",
      "Train Epoch: 2432 [98560/118836 (83%)] Loss: 12190.166016\n",
      "    epoch          : 2432\n",
      "    loss           : 12231.436963011787\n",
      "    val_loss       : 12236.486553781446\n",
      "    val_log_likelihood: -12145.23899788048\n",
      "    val_log_marginal: -12154.09659227429\n",
      "Train Epoch: 2433 [256/118836 (0%)] Loss: 12186.723633\n",
      "Train Epoch: 2433 [33024/118836 (28%)] Loss: 12250.655273\n",
      "Train Epoch: 2433 [65792/118836 (55%)] Loss: 12290.713867\n",
      "Train Epoch: 2433 [98560/118836 (83%)] Loss: 12243.882812\n",
      "    epoch          : 2433\n",
      "    loss           : 12238.11061553324\n",
      "    val_loss       : 12229.21306035678\n",
      "    val_log_likelihood: -12141.560663836332\n",
      "    val_log_marginal: -12150.193821491024\n",
      "Train Epoch: 2434 [256/118836 (0%)] Loss: 12207.303711\n",
      "Train Epoch: 2434 [33024/118836 (28%)] Loss: 12234.921875\n",
      "Train Epoch: 2434 [65792/118836 (55%)] Loss: 12253.349609\n",
      "Train Epoch: 2434 [98560/118836 (83%)] Loss: 12290.191406\n",
      "    epoch          : 2434\n",
      "    loss           : 12229.960861248966\n",
      "    val_loss       : 12229.00440910323\n",
      "    val_log_likelihood: -12141.549111320048\n",
      "    val_log_marginal: -12150.117278017595\n",
      "Train Epoch: 2435 [256/118836 (0%)] Loss: 12373.023438\n",
      "Train Epoch: 2435 [33024/118836 (28%)] Loss: 12356.457031\n",
      "Train Epoch: 2435 [65792/118836 (55%)] Loss: 12323.542969\n",
      "Train Epoch: 2435 [98560/118836 (83%)] Loss: 12244.145508\n",
      "    epoch          : 2435\n",
      "    loss           : 12229.064340687035\n",
      "    val_loss       : 12230.187051895427\n",
      "    val_log_likelihood: -12142.261799039754\n",
      "    val_log_marginal: -12150.75624401953\n",
      "Train Epoch: 2436 [256/118836 (0%)] Loss: 12241.487305\n",
      "Train Epoch: 2436 [33024/118836 (28%)] Loss: 12291.611328\n",
      "Train Epoch: 2436 [65792/118836 (55%)] Loss: 12314.368164\n",
      "Train Epoch: 2436 [98560/118836 (83%)] Loss: 12353.925781\n",
      "    epoch          : 2436\n",
      "    loss           : 12228.844107992141\n",
      "    val_loss       : 12228.077433949418\n",
      "    val_log_likelihood: -12142.555304939517\n",
      "    val_log_marginal: -12151.06733786229\n",
      "Train Epoch: 2437 [256/118836 (0%)] Loss: 12302.878906\n",
      "Train Epoch: 2437 [33024/118836 (28%)] Loss: 12267.757812\n",
      "Train Epoch: 2437 [65792/118836 (55%)] Loss: 12298.723633\n",
      "Train Epoch: 2437 [98560/118836 (83%)] Loss: 12215.693359\n",
      "    epoch          : 2437\n",
      "    loss           : 12231.571131552419\n",
      "    val_loss       : 12232.468408948858\n",
      "    val_log_likelihood: -12141.583211363988\n",
      "    val_log_marginal: -12150.043595798388\n",
      "Train Epoch: 2438 [256/118836 (0%)] Loss: 12229.921875\n",
      "Train Epoch: 2438 [33024/118836 (28%)] Loss: 12278.912109\n",
      "Train Epoch: 2438 [65792/118836 (55%)] Loss: 12327.660156\n",
      "Train Epoch: 2438 [98560/118836 (83%)] Loss: 12158.629883\n",
      "    epoch          : 2438\n",
      "    loss           : 12229.608770645937\n",
      "    val_loss       : 12230.946416152956\n",
      "    val_log_likelihood: -12141.31549559941\n",
      "    val_log_marginal: -12149.959673126858\n",
      "Train Epoch: 2439 [256/118836 (0%)] Loss: 12316.867188\n",
      "Train Epoch: 2439 [33024/118836 (28%)] Loss: 12262.267578\n",
      "Train Epoch: 2439 [65792/118836 (55%)] Loss: 12298.609375\n",
      "Train Epoch: 2439 [98560/118836 (83%)] Loss: 12295.446289\n",
      "    epoch          : 2439\n",
      "    loss           : 12230.624051385443\n",
      "    val_loss       : 12225.363356333835\n",
      "    val_log_likelihood: -12145.746060309399\n",
      "    val_log_marginal: -12154.56287186285\n",
      "Train Epoch: 2440 [256/118836 (0%)] Loss: 12249.648438\n",
      "Train Epoch: 2440 [33024/118836 (28%)] Loss: 12305.848633\n",
      "Train Epoch: 2440 [65792/118836 (55%)] Loss: 12264.124023\n",
      "Train Epoch: 2440 [98560/118836 (83%)] Loss: 12186.317383\n",
      "    epoch          : 2440\n",
      "    loss           : 12231.363587708074\n",
      "    val_loss       : 12231.809578334785\n",
      "    val_log_likelihood: -12142.066420143197\n",
      "    val_log_marginal: -12150.65281391197\n",
      "Train Epoch: 2441 [256/118836 (0%)] Loss: 12276.292969\n",
      "Train Epoch: 2441 [33024/118836 (28%)] Loss: 12225.375000\n",
      "Train Epoch: 2441 [65792/118836 (55%)] Loss: 12297.426758\n",
      "Train Epoch: 2441 [98560/118836 (83%)] Loss: 12303.244141\n",
      "    epoch          : 2441\n",
      "    loss           : 12234.439004342432\n",
      "    val_loss       : 12235.13986714458\n",
      "    val_log_likelihood: -12156.122599869468\n",
      "    val_log_marginal: -12164.731984455362\n",
      "Train Epoch: 2442 [256/118836 (0%)] Loss: 12319.161133\n",
      "Train Epoch: 2442 [33024/118836 (28%)] Loss: 12278.723633\n",
      "Train Epoch: 2442 [65792/118836 (55%)] Loss: 12218.154297\n",
      "Train Epoch: 2442 [98560/118836 (83%)] Loss: 12266.001953\n",
      "    epoch          : 2442\n",
      "    loss           : 12227.375886579817\n",
      "    val_loss       : 12227.194371739226\n",
      "    val_log_likelihood: -12144.572367239194\n",
      "    val_log_marginal: -12152.961574991921\n",
      "Train Epoch: 2443 [256/118836 (0%)] Loss: 12140.679688\n",
      "Train Epoch: 2443 [33024/118836 (28%)] Loss: 12181.854492\n",
      "Train Epoch: 2443 [65792/118836 (55%)] Loss: 12247.488281\n",
      "Train Epoch: 2443 [98560/118836 (83%)] Loss: 12243.650391\n",
      "    epoch          : 2443\n",
      "    loss           : 12229.91273295337\n",
      "    val_loss       : 12229.589315972264\n",
      "    val_log_likelihood: -12140.246891477978\n",
      "    val_log_marginal: -12148.548665450468\n",
      "Train Epoch: 2444 [256/118836 (0%)] Loss: 12197.793945\n",
      "Train Epoch: 2444 [33024/118836 (28%)] Loss: 12194.985352\n",
      "Train Epoch: 2444 [65792/118836 (55%)] Loss: 12273.840820\n",
      "Train Epoch: 2444 [98560/118836 (83%)] Loss: 12271.667969\n",
      "    epoch          : 2444\n",
      "    loss           : 12229.364813540375\n",
      "    val_loss       : 12229.655266175218\n",
      "    val_log_likelihood: -12142.679831763078\n",
      "    val_log_marginal: -12151.06492958148\n",
      "Train Epoch: 2445 [256/118836 (0%)] Loss: 12254.025391\n",
      "Train Epoch: 2445 [33024/118836 (28%)] Loss: 12177.080078\n",
      "Train Epoch: 2445 [65792/118836 (55%)] Loss: 12232.062500\n",
      "Train Epoch: 2445 [98560/118836 (83%)] Loss: 12350.872070\n",
      "    epoch          : 2445\n",
      "    loss           : 12225.652455864867\n",
      "    val_loss       : 12229.851797081046\n",
      "    val_log_likelihood: -12145.031524794511\n",
      "    val_log_marginal: -12153.581131505982\n",
      "Train Epoch: 2446 [256/118836 (0%)] Loss: 12260.675781\n",
      "Train Epoch: 2446 [33024/118836 (28%)] Loss: 12231.149414\n",
      "Train Epoch: 2446 [65792/118836 (55%)] Loss: 12210.628906\n",
      "Train Epoch: 2446 [98560/118836 (83%)] Loss: 12327.197266\n",
      "    epoch          : 2446\n",
      "    loss           : 12232.3507074222\n",
      "    val_loss       : 12232.81464067856\n",
      "    val_log_likelihood: -12144.51332971464\n",
      "    val_log_marginal: -12153.06167422504\n",
      "Train Epoch: 2447 [256/118836 (0%)] Loss: 12239.044922\n",
      "Train Epoch: 2447 [33024/118836 (28%)] Loss: 12284.053711\n",
      "Train Epoch: 2447 [65792/118836 (55%)] Loss: 12336.058594\n",
      "Train Epoch: 2447 [98560/118836 (83%)] Loss: 12298.109375\n",
      "    epoch          : 2447\n",
      "    loss           : 12233.765400447168\n",
      "    val_loss       : 12235.459026892364\n",
      "    val_log_likelihood: -12140.407063075112\n",
      "    val_log_marginal: -12149.167143720584\n",
      "Train Epoch: 2448 [256/118836 (0%)] Loss: 12265.178711\n",
      "Train Epoch: 2448 [33024/118836 (28%)] Loss: 12204.013672\n",
      "Train Epoch: 2448 [65792/118836 (55%)] Loss: 12214.823242\n",
      "Train Epoch: 2448 [98560/118836 (83%)] Loss: 12202.281250\n",
      "    epoch          : 2448\n",
      "    loss           : 12229.286107772437\n",
      "    val_loss       : 12230.021163257878\n",
      "    val_log_likelihood: -12141.315027754084\n",
      "    val_log_marginal: -12149.96125558452\n",
      "Train Epoch: 2449 [256/118836 (0%)] Loss: 12190.288086\n",
      "Train Epoch: 2449 [33024/118836 (28%)] Loss: 12231.996094\n",
      "Train Epoch: 2449 [65792/118836 (55%)] Loss: 12221.269531\n",
      "Train Epoch: 2449 [98560/118836 (83%)] Loss: 12251.355469\n",
      "    epoch          : 2449\n",
      "    loss           : 12230.11369578422\n",
      "    val_loss       : 12230.799254299465\n",
      "    val_log_likelihood: -12145.378783472912\n",
      "    val_log_marginal: -12154.056057565045\n",
      "Train Epoch: 2450 [256/118836 (0%)] Loss: 12266.911133\n",
      "Train Epoch: 2450 [33024/118836 (28%)] Loss: 12261.730469\n",
      "Train Epoch: 2450 [65792/118836 (55%)] Loss: 12238.815430\n",
      "Train Epoch: 2450 [98560/118836 (83%)] Loss: 12402.776367\n",
      "    epoch          : 2450\n",
      "    loss           : 12230.667278936622\n",
      "    val_loss       : 12233.283262313385\n",
      "    val_log_likelihood: -12145.472108761114\n",
      "    val_log_marginal: -12154.17088421721\n",
      "Train Epoch: 2451 [256/118836 (0%)] Loss: 12252.488281\n",
      "Train Epoch: 2451 [33024/118836 (28%)] Loss: 12224.712891\n",
      "Train Epoch: 2451 [65792/118836 (55%)] Loss: 12257.431641\n",
      "Train Epoch: 2451 [98560/118836 (83%)] Loss: 12275.001953\n",
      "    epoch          : 2451\n",
      "    loss           : 12229.567384751084\n",
      "    val_loss       : 12227.091338276314\n",
      "    val_log_likelihood: -12135.228517402038\n",
      "    val_log_marginal: -12143.822127487614\n",
      "Train Epoch: 2452 [256/118836 (0%)] Loss: 12221.462891\n",
      "Train Epoch: 2452 [33024/118836 (28%)] Loss: 12411.165039\n",
      "Train Epoch: 2452 [65792/118836 (55%)] Loss: 12179.936523\n",
      "Train Epoch: 2452 [98560/118836 (83%)] Loss: 12204.875000\n",
      "    epoch          : 2452\n",
      "    loss           : 12227.79016813999\n",
      "    val_loss       : 12228.331425063636\n",
      "    val_log_likelihood: -12140.747286787893\n",
      "    val_log_marginal: -12149.308355967903\n",
      "Train Epoch: 2453 [256/118836 (0%)] Loss: 12195.012695\n",
      "Train Epoch: 2453 [33024/118836 (28%)] Loss: 12172.403320\n",
      "Train Epoch: 2453 [65792/118836 (55%)] Loss: 12312.519531\n",
      "Train Epoch: 2453 [98560/118836 (83%)] Loss: 12301.697266\n",
      "    epoch          : 2453\n",
      "    loss           : 12227.260173212624\n",
      "    val_loss       : 12226.00829234997\n",
      "    val_log_likelihood: -12139.74788257987\n",
      "    val_log_marginal: -12148.338466205912\n",
      "Train Epoch: 2454 [256/118836 (0%)] Loss: 12197.704102\n",
      "Train Epoch: 2454 [33024/118836 (28%)] Loss: 12288.974609\n",
      "Train Epoch: 2454 [65792/118836 (55%)] Loss: 12242.841797\n",
      "Train Epoch: 2454 [98560/118836 (83%)] Loss: 12254.718750\n",
      "    epoch          : 2454\n",
      "    loss           : 12233.75090095766\n",
      "    val_loss       : 12225.737476706066\n",
      "    val_log_likelihood: -12135.452355381514\n",
      "    val_log_marginal: -12144.087650097412\n",
      "Train Epoch: 2455 [256/118836 (0%)] Loss: 12324.601562\n",
      "Train Epoch: 2455 [33024/118836 (28%)] Loss: 12185.807617\n",
      "Train Epoch: 2455 [65792/118836 (55%)] Loss: 12270.828125\n",
      "Train Epoch: 2455 [98560/118836 (83%)] Loss: 12321.713867\n",
      "    epoch          : 2455\n",
      "    loss           : 12227.352391891542\n",
      "    val_loss       : 12229.991876248561\n",
      "    val_log_likelihood: -12132.946668863731\n",
      "    val_log_marginal: -12141.394270641802\n",
      "Train Epoch: 2456 [256/118836 (0%)] Loss: 12203.668945\n",
      "Train Epoch: 2456 [33024/118836 (28%)] Loss: 12233.578125\n",
      "Train Epoch: 2456 [65792/118836 (55%)] Loss: 12284.497070\n",
      "Train Epoch: 2456 [98560/118836 (83%)] Loss: 12340.505859\n",
      "    epoch          : 2456\n",
      "    loss           : 12224.821480497829\n",
      "    val_loss       : 12227.872153257013\n",
      "    val_log_likelihood: -12139.237756216398\n",
      "    val_log_marginal: -12147.678368931714\n",
      "Train Epoch: 2457 [256/118836 (0%)] Loss: 12300.097656\n",
      "Train Epoch: 2457 [33024/118836 (28%)] Loss: 12232.003906\n",
      "Train Epoch: 2457 [65792/118836 (55%)] Loss: 12273.390625\n",
      "Train Epoch: 2457 [98560/118836 (83%)] Loss: 12306.848633\n",
      "    epoch          : 2457\n",
      "    loss           : 12230.50949874638\n",
      "    val_loss       : 12225.861864201757\n",
      "    val_log_likelihood: -12135.413761049938\n",
      "    val_log_marginal: -12143.850544549383\n",
      "Train Epoch: 2458 [256/118836 (0%)] Loss: 12345.338867\n",
      "Train Epoch: 2458 [33024/118836 (28%)] Loss: 12246.853516\n",
      "Train Epoch: 2458 [65792/118836 (55%)] Loss: 12189.894531\n",
      "Train Epoch: 2458 [98560/118836 (83%)] Loss: 12267.638672\n",
      "    epoch          : 2458\n",
      "    loss           : 12224.92022914082\n",
      "    val_loss       : 12224.913431662697\n",
      "    val_log_likelihood: -12135.716376040375\n",
      "    val_log_marginal: -12144.206048613556\n",
      "Train Epoch: 2459 [256/118836 (0%)] Loss: 12211.533203\n",
      "Train Epoch: 2459 [33024/118836 (28%)] Loss: 12277.917969\n",
      "Train Epoch: 2459 [65792/118836 (55%)] Loss: 12174.002930\n",
      "Train Epoch: 2459 [98560/118836 (83%)] Loss: 12187.657227\n",
      "    epoch          : 2459\n",
      "    loss           : 12225.355480866161\n",
      "    val_loss       : 12222.143515400703\n",
      "    val_log_likelihood: -12137.020354987335\n",
      "    val_log_marginal: -12145.510631564284\n",
      "Train Epoch: 2460 [256/118836 (0%)] Loss: 12346.804688\n",
      "Train Epoch: 2460 [33024/118836 (28%)] Loss: 12205.187500\n",
      "Train Epoch: 2460 [65792/118836 (55%)] Loss: 12234.404297\n",
      "Train Epoch: 2460 [98560/118836 (83%)] Loss: 12178.296875\n",
      "    epoch          : 2460\n",
      "    loss           : 12228.12757928815\n",
      "    val_loss       : 12225.269221534976\n",
      "    val_log_likelihood: -12133.078091397849\n",
      "    val_log_marginal: -12141.544821410043\n",
      "Train Epoch: 2461 [256/118836 (0%)] Loss: 12302.855469\n",
      "Train Epoch: 2461 [33024/118836 (28%)] Loss: 12297.611328\n",
      "Train Epoch: 2461 [65792/118836 (55%)] Loss: 12205.808594\n",
      "Train Epoch: 2461 [98560/118836 (83%)] Loss: 12253.069336\n",
      "    epoch          : 2461\n",
      "    loss           : 12231.585412951044\n",
      "    val_loss       : 12230.553955582805\n",
      "    val_log_likelihood: -12139.194001208385\n",
      "    val_log_marginal: -12147.735882917039\n",
      "Train Epoch: 2462 [256/118836 (0%)] Loss: 12268.958984\n",
      "Train Epoch: 2462 [33024/118836 (28%)] Loss: 12198.639648\n",
      "Train Epoch: 2462 [65792/118836 (55%)] Loss: 12216.796875\n",
      "Train Epoch: 2462 [98560/118836 (83%)] Loss: 12161.179688\n",
      "    epoch          : 2462\n",
      "    loss           : 12228.674700650072\n",
      "    val_loss       : 12228.106421620707\n",
      "    val_log_likelihood: -12139.905690233405\n",
      "    val_log_marginal: -12148.570431114198\n",
      "Train Epoch: 2463 [256/118836 (0%)] Loss: 12254.083984\n",
      "Train Epoch: 2463 [33024/118836 (28%)] Loss: 12293.722656\n",
      "Train Epoch: 2463 [65792/118836 (55%)] Loss: 12269.469727\n",
      "Train Epoch: 2463 [98560/118836 (83%)] Loss: 12210.052734\n",
      "    epoch          : 2463\n",
      "    loss           : 12228.008198763182\n",
      "    val_loss       : 12228.569616577312\n",
      "    val_log_likelihood: -12136.476347155449\n",
      "    val_log_marginal: -12144.951277384509\n",
      "Train Epoch: 2464 [256/118836 (0%)] Loss: 12308.188477\n",
      "Train Epoch: 2464 [33024/118836 (28%)] Loss: 12231.427734\n",
      "Train Epoch: 2464 [65792/118836 (55%)] Loss: 12252.429688\n",
      "Train Epoch: 2464 [98560/118836 (83%)] Loss: 12200.013672\n",
      "    epoch          : 2464\n",
      "    loss           : 12227.982138518404\n",
      "    val_loss       : 12228.951531319564\n",
      "    val_log_likelihood: -12136.865317249534\n",
      "    val_log_marginal: -12145.405396897897\n",
      "Train Epoch: 2465 [256/118836 (0%)] Loss: 12416.322266\n",
      "Train Epoch: 2465 [33024/118836 (28%)] Loss: 12171.623047\n",
      "Train Epoch: 2465 [65792/118836 (55%)] Loss: 12328.859375\n",
      "Train Epoch: 2465 [98560/118836 (83%)] Loss: 12230.583984\n",
      "    epoch          : 2465\n",
      "    loss           : 12233.545085200838\n",
      "    val_loss       : 12229.963476849258\n",
      "    val_log_likelihood: -12137.946368059864\n",
      "    val_log_marginal: -12146.567638702674\n",
      "Train Epoch: 2466 [256/118836 (0%)] Loss: 12286.366211\n",
      "Train Epoch: 2466 [33024/118836 (28%)] Loss: 12151.472656\n",
      "Train Epoch: 2466 [65792/118836 (55%)] Loss: 12312.277344\n",
      "Train Epoch: 2466 [98560/118836 (83%)] Loss: 12303.178711\n",
      "    epoch          : 2466\n",
      "    loss           : 12231.29150317928\n",
      "    val_loss       : 12232.230494868676\n",
      "    val_log_likelihood: -12134.834265793012\n",
      "    val_log_marginal: -12143.322674215911\n",
      "Train Epoch: 2467 [256/118836 (0%)] Loss: 12265.589844\n",
      "Train Epoch: 2467 [33024/118836 (28%)] Loss: 12303.288086\n",
      "Train Epoch: 2467 [65792/118836 (55%)] Loss: 12192.294922\n",
      "Train Epoch: 2467 [98560/118836 (83%)] Loss: 12264.183594\n",
      "    epoch          : 2467\n",
      "    loss           : 12228.765065879601\n",
      "    val_loss       : 12232.1645576897\n",
      "    val_log_likelihood: -12139.332068567774\n",
      "    val_log_marginal: -12147.857571386416\n",
      "Train Epoch: 2468 [256/118836 (0%)] Loss: 12263.942383\n",
      "Train Epoch: 2468 [33024/118836 (28%)] Loss: 12305.947266\n",
      "Train Epoch: 2468 [65792/118836 (55%)] Loss: 12347.278320\n",
      "Train Epoch: 2468 [98560/118836 (83%)] Loss: 12352.090820\n",
      "    epoch          : 2468\n",
      "    loss           : 12227.62524119236\n",
      "    val_loss       : 12226.38912560803\n",
      "    val_log_likelihood: -12136.437307756927\n",
      "    val_log_marginal: -12144.986824273403\n",
      "Train Epoch: 2469 [256/118836 (0%)] Loss: 12313.089844\n",
      "Train Epoch: 2469 [33024/118836 (28%)] Loss: 12236.099609\n",
      "Train Epoch: 2469 [65792/118836 (55%)] Loss: 12231.400391\n",
      "Train Epoch: 2469 [98560/118836 (83%)] Loss: 12264.857422\n",
      "    epoch          : 2469\n",
      "    loss           : 12224.423400666874\n",
      "    val_loss       : 12229.68184116846\n",
      "    val_log_likelihood: -12133.906261793063\n",
      "    val_log_marginal: -12142.50138248775\n",
      "Train Epoch: 2470 [256/118836 (0%)] Loss: 12252.804688\n",
      "Train Epoch: 2470 [33024/118836 (28%)] Loss: 12227.266602\n",
      "Train Epoch: 2470 [65792/118836 (55%)] Loss: 12204.771484\n",
      "Train Epoch: 2470 [98560/118836 (83%)] Loss: 12346.403320\n",
      "    epoch          : 2470\n",
      "    loss           : 12227.072007793115\n",
      "    val_loss       : 12228.915738297104\n",
      "    val_log_likelihood: -12134.599270607165\n",
      "    val_log_marginal: -12143.149200593703\n",
      "Train Epoch: 2471 [256/118836 (0%)] Loss: 12197.730469\n",
      "Train Epoch: 2471 [33024/118836 (28%)] Loss: 12252.191406\n",
      "Train Epoch: 2471 [65792/118836 (55%)] Loss: 12242.270508\n",
      "Train Epoch: 2471 [98560/118836 (83%)] Loss: 12262.411133\n",
      "    epoch          : 2471\n",
      "    loss           : 12230.829298813585\n",
      "    val_loss       : 12229.608097680473\n",
      "    val_log_likelihood: -12139.472021524762\n",
      "    val_log_marginal: -12148.11772502473\n",
      "Train Epoch: 2472 [256/118836 (0%)] Loss: 12378.451172\n",
      "Train Epoch: 2472 [33024/118836 (28%)] Loss: 12301.748047\n",
      "Train Epoch: 2472 [65792/118836 (55%)] Loss: 12216.335938\n",
      "Train Epoch: 2472 [98560/118836 (83%)] Loss: 12187.972656\n",
      "    epoch          : 2472\n",
      "    loss           : 12227.487204042598\n",
      "    val_loss       : 12229.76721601756\n",
      "    val_log_likelihood: -12137.896227835505\n",
      "    val_log_marginal: -12146.682099376516\n",
      "Train Epoch: 2473 [256/118836 (0%)] Loss: 12257.970703\n",
      "Train Epoch: 2473 [33024/118836 (28%)] Loss: 12283.660156\n",
      "Train Epoch: 2473 [65792/118836 (55%)] Loss: 12239.417969\n",
      "Train Epoch: 2473 [98560/118836 (83%)] Loss: 12184.147461\n",
      "    epoch          : 2473\n",
      "    loss           : 12227.649785463194\n",
      "    val_loss       : 12225.731994545971\n",
      "    val_log_likelihood: -12134.90685467716\n",
      "    val_log_marginal: -12143.730755224522\n",
      "Train Epoch: 2474 [256/118836 (0%)] Loss: 12241.270508\n",
      "Train Epoch: 2474 [33024/118836 (28%)] Loss: 12223.960938\n",
      "Train Epoch: 2474 [65792/118836 (55%)] Loss: 12353.580078\n",
      "Train Epoch: 2474 [98560/118836 (83%)] Loss: 12250.764648\n",
      "    epoch          : 2474\n",
      "    loss           : 12229.001447315704\n",
      "    val_loss       : 12224.395277284886\n",
      "    val_log_likelihood: -12139.237044432382\n",
      "    val_log_marginal: -12147.867561783301\n",
      "Train Epoch: 2475 [256/118836 (0%)] Loss: 12254.845703\n",
      "Train Epoch: 2475 [33024/118836 (28%)] Loss: 12246.000000\n",
      "Train Epoch: 2475 [65792/118836 (55%)] Loss: 12224.669922\n",
      "Train Epoch: 2475 [98560/118836 (83%)] Loss: 12271.128906\n",
      "    epoch          : 2475\n",
      "    loss           : 12226.059399878515\n",
      "    val_loss       : 12226.093255288524\n",
      "    val_log_likelihood: -12136.98454737257\n",
      "    val_log_marginal: -12145.593325177662\n",
      "Train Epoch: 2476 [256/118836 (0%)] Loss: 12335.632812\n",
      "Train Epoch: 2476 [33024/118836 (28%)] Loss: 12203.994141\n",
      "Train Epoch: 2476 [65792/118836 (55%)] Loss: 12229.796875\n",
      "Train Epoch: 2476 [98560/118836 (83%)] Loss: 12234.902344\n",
      "    epoch          : 2476\n",
      "    loss           : 12229.185197606492\n",
      "    val_loss       : 12229.021558905748\n",
      "    val_log_likelihood: -12134.955969066636\n",
      "    val_log_marginal: -12143.469740513547\n",
      "Train Epoch: 2477 [256/118836 (0%)] Loss: 12207.304688\n",
      "Train Epoch: 2477 [33024/118836 (28%)] Loss: 12239.194336\n",
      "Train Epoch: 2477 [65792/118836 (55%)] Loss: 12225.333008\n",
      "Train Epoch: 2477 [98560/118836 (83%)] Loss: 12294.214844\n",
      "    epoch          : 2477\n",
      "    loss           : 12225.6473397759\n",
      "    val_loss       : 12227.256418076095\n",
      "    val_log_likelihood: -12135.528237114866\n",
      "    val_log_marginal: -12144.149277990247\n",
      "Train Epoch: 2478 [256/118836 (0%)] Loss: 12189.805664\n",
      "Train Epoch: 2478 [33024/118836 (28%)] Loss: 12232.048828\n",
      "Train Epoch: 2478 [65792/118836 (55%)] Loss: 12143.067383\n",
      "Train Epoch: 2478 [98560/118836 (83%)] Loss: 12324.658203\n",
      "    epoch          : 2478\n",
      "    loss           : 12229.0675307912\n",
      "    val_loss       : 12226.632113950613\n",
      "    val_log_likelihood: -12139.272588237956\n",
      "    val_log_marginal: -12147.914302037148\n",
      "Train Epoch: 2479 [256/118836 (0%)] Loss: 12217.248047\n",
      "Train Epoch: 2479 [33024/118836 (28%)] Loss: 12205.430664\n",
      "Train Epoch: 2479 [65792/118836 (55%)] Loss: 12307.830078\n",
      "Train Epoch: 2479 [98560/118836 (83%)] Loss: 12246.687500\n",
      "    epoch          : 2479\n",
      "    loss           : 12226.964045537376\n",
      "    val_loss       : 12228.90812749416\n",
      "    val_log_likelihood: -12137.433069362594\n",
      "    val_log_marginal: -12145.93126761706\n",
      "Train Epoch: 2480 [256/118836 (0%)] Loss: 12218.512695\n",
      "Train Epoch: 2480 [33024/118836 (28%)] Loss: 12160.062500\n",
      "Train Epoch: 2480 [65792/118836 (55%)] Loss: 12212.323242\n",
      "Train Epoch: 2480 [98560/118836 (83%)] Loss: 12226.205078\n",
      "    epoch          : 2480\n",
      "    loss           : 12231.314506597653\n",
      "    val_loss       : 12228.431769862247\n",
      "    val_log_likelihood: -12136.285397119262\n",
      "    val_log_marginal: -12144.759647351359\n",
      "Train Epoch: 2481 [256/118836 (0%)] Loss: 12178.708008\n",
      "Train Epoch: 2481 [33024/118836 (28%)] Loss: 12181.667969\n",
      "Train Epoch: 2481 [65792/118836 (55%)] Loss: 12266.002930\n",
      "Train Epoch: 2481 [98560/118836 (83%)] Loss: 12210.509766\n",
      "    epoch          : 2481\n",
      "    loss           : 12225.300471076303\n",
      "    val_loss       : 12226.11268600128\n",
      "    val_log_likelihood: -12131.669289572994\n",
      "    val_log_marginal: -12140.221126359054\n",
      "Train Epoch: 2482 [256/118836 (0%)] Loss: 12237.125000\n",
      "Train Epoch: 2482 [33024/118836 (28%)] Loss: 12265.900391\n",
      "Train Epoch: 2482 [65792/118836 (55%)] Loss: 12187.509766\n",
      "Train Epoch: 2482 [98560/118836 (83%)] Loss: 12283.539062\n",
      "    epoch          : 2482\n",
      "    loss           : 12229.103120961281\n",
      "    val_loss       : 12229.24219709881\n",
      "    val_log_likelihood: -12135.682112993692\n",
      "    val_log_marginal: -12144.250068581285\n",
      "Train Epoch: 2483 [256/118836 (0%)] Loss: 12228.376953\n",
      "Train Epoch: 2483 [33024/118836 (28%)] Loss: 12251.947266\n",
      "Train Epoch: 2483 [65792/118836 (55%)] Loss: 12189.463867\n",
      "Train Epoch: 2483 [98560/118836 (83%)] Loss: 12192.798828\n",
      "    epoch          : 2483\n",
      "    loss           : 12230.202159099721\n",
      "    val_loss       : 12223.984873739979\n",
      "    val_log_likelihood: -12136.99368812681\n",
      "    val_log_marginal: -12145.480632867855\n",
      "Train Epoch: 2484 [256/118836 (0%)] Loss: 12293.412109\n",
      "Train Epoch: 2484 [33024/118836 (28%)] Loss: 12223.221680\n",
      "Train Epoch: 2484 [65792/118836 (55%)] Loss: 12184.837891\n",
      "Train Epoch: 2484 [98560/118836 (83%)] Loss: 12255.291992\n",
      "    epoch          : 2484\n",
      "    loss           : 12227.577849720843\n",
      "    val_loss       : 12227.838046251412\n",
      "    val_log_likelihood: -12136.537095320255\n",
      "    val_log_marginal: -12145.188706341878\n",
      "Train Epoch: 2485 [256/118836 (0%)] Loss: 12227.691406\n",
      "Train Epoch: 2485 [33024/118836 (28%)] Loss: 12286.259766\n",
      "Train Epoch: 2485 [65792/118836 (55%)] Loss: 12327.424805\n",
      "Train Epoch: 2485 [98560/118836 (83%)] Loss: 12174.968750\n",
      "    epoch          : 2485\n",
      "    loss           : 12227.30678618047\n",
      "    val_loss       : 12221.518193775792\n",
      "    val_log_likelihood: -12136.382347239454\n",
      "    val_log_marginal: -12144.799962151055\n",
      "Train Epoch: 2486 [256/118836 (0%)] Loss: 12143.138672\n",
      "Train Epoch: 2486 [33024/118836 (28%)] Loss: 12124.945312\n",
      "Train Epoch: 2486 [65792/118836 (55%)] Loss: 12306.011719\n",
      "Train Epoch: 2486 [98560/118836 (83%)] Loss: 12279.838867\n",
      "    epoch          : 2486\n",
      "    loss           : 12223.193349358975\n",
      "    val_loss       : 12231.798336629416\n",
      "    val_log_likelihood: -12137.070211693548\n",
      "    val_log_marginal: -12145.736117522245\n",
      "Train Epoch: 2487 [256/118836 (0%)] Loss: 12341.244141\n",
      "Train Epoch: 2487 [33024/118836 (28%)] Loss: 12340.195312\n",
      "Train Epoch: 2487 [65792/118836 (55%)] Loss: 12319.554688\n",
      "Train Epoch: 2487 [98560/118836 (83%)] Loss: 12285.660156\n",
      "    epoch          : 2487\n",
      "    loss           : 12228.59434530733\n",
      "    val_loss       : 12228.01354266215\n",
      "    val_log_likelihood: -12135.681680689104\n",
      "    val_log_marginal: -12144.193609753469\n",
      "Train Epoch: 2488 [256/118836 (0%)] Loss: 12365.837891\n",
      "Train Epoch: 2488 [33024/118836 (28%)] Loss: 12136.461914\n",
      "Train Epoch: 2488 [65792/118836 (55%)] Loss: 12270.824219\n",
      "Train Epoch: 2488 [98560/118836 (83%)] Loss: 12270.769531\n",
      "    epoch          : 2488\n",
      "    loss           : 12228.042414799162\n",
      "    val_loss       : 12243.99941858351\n",
      "    val_log_likelihood: -12139.387951528897\n",
      "    val_log_marginal: -12148.254048705101\n",
      "Train Epoch: 2489 [256/118836 (0%)] Loss: 12429.130859\n",
      "Train Epoch: 2489 [33024/118836 (28%)] Loss: 12202.039062\n",
      "Train Epoch: 2489 [65792/118836 (55%)] Loss: 12314.023438\n",
      "Train Epoch: 2489 [98560/118836 (83%)] Loss: 12274.997070\n",
      "    epoch          : 2489\n",
      "    loss           : 12233.815265069274\n",
      "    val_loss       : 12230.274980598015\n",
      "    val_log_likelihood: -12135.884037524556\n",
      "    val_log_marginal: -12144.72192218275\n",
      "Train Epoch: 2490 [256/118836 (0%)] Loss: 12263.726562\n",
      "Train Epoch: 2490 [33024/118836 (28%)] Loss: 12181.781250\n",
      "Train Epoch: 2490 [65792/118836 (55%)] Loss: 12379.070312\n",
      "Train Epoch: 2490 [98560/118836 (83%)] Loss: 12182.780273\n",
      "    epoch          : 2490\n",
      "    loss           : 12231.328204320462\n",
      "    val_loss       : 12228.994398734414\n",
      "    val_log_likelihood: -12137.917454701716\n",
      "    val_log_marginal: -12146.670626352834\n",
      "Train Epoch: 2491 [256/118836 (0%)] Loss: 12296.302734\n",
      "Train Epoch: 2491 [33024/118836 (28%)] Loss: 12262.457031\n",
      "Train Epoch: 2491 [65792/118836 (55%)] Loss: 12241.808594\n",
      "Train Epoch: 2491 [98560/118836 (83%)] Loss: 12360.978516\n",
      "    epoch          : 2491\n",
      "    loss           : 12234.595377927264\n",
      "    val_loss       : 12230.174349989007\n",
      "    val_log_likelihood: -12139.44098315369\n",
      "    val_log_marginal: -12148.00275048211\n",
      "Train Epoch: 2492 [256/118836 (0%)] Loss: 12236.517578\n",
      "Train Epoch: 2492 [33024/118836 (28%)] Loss: 12256.846680\n",
      "Train Epoch: 2492 [65792/118836 (55%)] Loss: 12214.455078\n",
      "Train Epoch: 2492 [98560/118836 (83%)] Loss: 12148.906250\n",
      "    epoch          : 2492\n",
      "    loss           : 12226.288071721205\n",
      "    val_loss       : 12229.096362774993\n",
      "    val_log_likelihood: -12136.034471606183\n",
      "    val_log_marginal: -12144.475387084669\n",
      "Train Epoch: 2493 [256/118836 (0%)] Loss: 12344.474609\n",
      "Train Epoch: 2493 [33024/118836 (28%)] Loss: 12255.488281\n",
      "Train Epoch: 2493 [65792/118836 (55%)] Loss: 12352.515625\n",
      "Train Epoch: 2493 [98560/118836 (83%)] Loss: 12247.878906\n",
      "    epoch          : 2493\n",
      "    loss           : 12233.392580225134\n",
      "    val_loss       : 12233.968320092346\n",
      "    val_log_likelihood: -12141.726544083436\n",
      "    val_log_marginal: -12150.568709715288\n",
      "Train Epoch: 2494 [256/118836 (0%)] Loss: 12286.071289\n",
      "Train Epoch: 2494 [33024/118836 (28%)] Loss: 12314.328125\n",
      "Train Epoch: 2494 [65792/118836 (55%)] Loss: 12292.771484\n",
      "Train Epoch: 2494 [98560/118836 (83%)] Loss: 12194.017578\n",
      "    epoch          : 2494\n",
      "    loss           : 12231.542954049059\n",
      "    val_loss       : 12229.929572816525\n",
      "    val_log_likelihood: -12135.159623946702\n",
      "    val_log_marginal: -12143.746353964483\n",
      "Train Epoch: 2495 [256/118836 (0%)] Loss: 12263.642578\n",
      "Train Epoch: 2495 [33024/118836 (28%)] Loss: 12201.812500\n",
      "Train Epoch: 2495 [65792/118836 (55%)] Loss: 12302.737305\n",
      "Train Epoch: 2495 [98560/118836 (83%)] Loss: 12260.624023\n",
      "    epoch          : 2495\n",
      "    loss           : 12224.248180960505\n",
      "    val_loss       : 12228.283564021094\n",
      "    val_log_likelihood: -12134.487332958539\n",
      "    val_log_marginal: -12143.003458365896\n",
      "Train Epoch: 2496 [256/118836 (0%)] Loss: 12190.239258\n",
      "Train Epoch: 2496 [33024/118836 (28%)] Loss: 12277.195312\n",
      "Train Epoch: 2496 [65792/118836 (55%)] Loss: 12211.267578\n",
      "Train Epoch: 2496 [98560/118836 (83%)] Loss: 12276.925781\n",
      "    epoch          : 2496\n",
      "    loss           : 12224.181386670287\n",
      "    val_loss       : 12228.75893461129\n",
      "    val_log_likelihood: -12133.43939787531\n",
      "    val_log_marginal: -12141.952377917998\n",
      "Train Epoch: 2497 [256/118836 (0%)] Loss: 12343.484375\n",
      "Train Epoch: 2497 [33024/118836 (28%)] Loss: 12204.796875\n",
      "Train Epoch: 2497 [65792/118836 (55%)] Loss: 12237.166016\n",
      "Train Epoch: 2497 [98560/118836 (83%)] Loss: 12326.917969\n",
      "    epoch          : 2497\n",
      "    loss           : 12228.876008549163\n",
      "    val_loss       : 12228.332046213756\n",
      "    val_log_likelihood: -12134.252514345533\n",
      "    val_log_marginal: -12142.779441298104\n",
      "Train Epoch: 2498 [256/118836 (0%)] Loss: 12306.578125\n",
      "Train Epoch: 2498 [33024/118836 (28%)] Loss: 12241.751953\n",
      "Train Epoch: 2498 [65792/118836 (55%)] Loss: 12284.037109\n",
      "Train Epoch: 2498 [98560/118836 (83%)] Loss: 12287.916016\n",
      "    epoch          : 2498\n",
      "    loss           : 12229.390375245555\n",
      "    val_loss       : 12227.561135422895\n",
      "    val_log_likelihood: -12137.99489069608\n",
      "    val_log_marginal: -12146.759919861359\n",
      "Train Epoch: 2499 [256/118836 (0%)] Loss: 12280.070312\n",
      "Train Epoch: 2499 [33024/118836 (28%)] Loss: 12255.771484\n",
      "Train Epoch: 2499 [65792/118836 (55%)] Loss: 12173.801758\n",
      "Train Epoch: 2499 [98560/118836 (83%)] Loss: 12220.401367\n",
      "    epoch          : 2499\n",
      "    loss           : 12232.844932214122\n",
      "    val_loss       : 12233.372252887511\n",
      "    val_log_likelihood: -12136.68271282439\n",
      "    val_log_marginal: -12145.61976532455\n",
      "Train Epoch: 2500 [256/118836 (0%)] Loss: 12233.698242\n",
      "Train Epoch: 2500 [33024/118836 (28%)] Loss: 12320.337891\n",
      "Train Epoch: 2500 [65792/118836 (55%)] Loss: 12244.081055\n",
      "Train Epoch: 2500 [98560/118836 (83%)] Loss: 12169.703125\n",
      "    epoch          : 2500\n",
      "    loss           : 12228.123553168942\n",
      "    val_loss       : 12231.585794848272\n",
      "    val_log_likelihood: -12135.877159099722\n",
      "    val_log_marginal: -12144.478136323312\n",
      "Saving checkpoint: saved/models/SelfiesAutoencodingOperad/0905_154251/checkpoint-epoch2500.pth ...\n",
      "Train Epoch: 2501 [256/118836 (0%)] Loss: 12259.793945\n",
      "Train Epoch: 2501 [33024/118836 (28%)] Loss: 12315.138672\n",
      "Train Epoch: 2501 [65792/118836 (55%)] Loss: 12222.875000\n",
      "Train Epoch: 2501 [98560/118836 (83%)] Loss: 12267.324219\n",
      "    epoch          : 2501\n",
      "    loss           : 12227.8713628903\n",
      "    val_loss       : 12230.521959903268\n",
      "    val_log_likelihood: -12140.183175177057\n",
      "    val_log_marginal: -12148.947952603372\n",
      "Train Epoch: 2502 [256/118836 (0%)] Loss: 12182.617188\n",
      "Train Epoch: 2502 [33024/118836 (28%)] Loss: 12174.023438\n",
      "Train Epoch: 2502 [65792/118836 (55%)] Loss: 12151.686523\n",
      "Train Epoch: 2502 [98560/118836 (83%)] Loss: 12255.807617\n",
      "    epoch          : 2502\n",
      "    loss           : 12229.311682724618\n",
      "    val_loss       : 12227.274216563177\n",
      "    val_log_likelihood: -12137.951420821702\n",
      "    val_log_marginal: -12146.568268805611\n",
      "Train Epoch: 2503 [256/118836 (0%)] Loss: 12136.621094\n",
      "Train Epoch: 2503 [33024/118836 (28%)] Loss: 12208.998047\n",
      "Train Epoch: 2503 [65792/118836 (55%)] Loss: 12291.768555\n",
      "Train Epoch: 2503 [98560/118836 (83%)] Loss: 12240.490234\n",
      "    epoch          : 2503\n",
      "    loss           : 12229.397332829301\n",
      "    val_loss       : 12226.794630418466\n",
      "    val_log_likelihood: -12136.86879054875\n",
      "    val_log_marginal: -12145.421776307672\n",
      "Train Epoch: 2504 [256/118836 (0%)] Loss: 12285.684570\n",
      "Train Epoch: 2504 [33024/118836 (28%)] Loss: 12403.265625\n",
      "Train Epoch: 2504 [65792/118836 (55%)] Loss: 12274.406250\n",
      "Train Epoch: 2504 [98560/118836 (83%)] Loss: 12246.701172\n",
      "    epoch          : 2504\n",
      "    loss           : 12228.4669180366\n",
      "    val_loss       : 12229.613600006453\n",
      "    val_log_likelihood: -12135.461810671268\n",
      "    val_log_marginal: -12143.931734646663\n",
      "Train Epoch: 2505 [256/118836 (0%)] Loss: 12179.724609\n",
      "Train Epoch: 2505 [33024/118836 (28%)] Loss: 12156.042969\n",
      "Train Epoch: 2505 [65792/118836 (55%)] Loss: 12218.213867\n",
      "Train Epoch: 2505 [98560/118836 (83%)] Loss: 12171.534180\n",
      "    epoch          : 2505\n",
      "    loss           : 12229.536168999432\n",
      "    val_loss       : 12224.618640250523\n",
      "    val_log_likelihood: -12140.284138492554\n",
      "    val_log_marginal: -12148.958306341186\n",
      "Train Epoch: 2506 [256/118836 (0%)] Loss: 12266.109375\n",
      "Train Epoch: 2506 [33024/118836 (28%)] Loss: 12238.066406\n",
      "Train Epoch: 2506 [65792/118836 (55%)] Loss: 12219.471680\n",
      "Train Epoch: 2506 [98560/118836 (83%)] Loss: 12340.368164\n",
      "    epoch          : 2506\n",
      "    loss           : 12228.367529175714\n",
      "    val_loss       : 12236.149820207398\n",
      "    val_log_likelihood: -12146.463991741626\n",
      "    val_log_marginal: -12155.324893365285\n",
      "Train Epoch: 2507 [256/118836 (0%)] Loss: 12248.444336\n",
      "Train Epoch: 2507 [33024/118836 (28%)] Loss: 12251.523438\n",
      "Train Epoch: 2507 [65792/118836 (55%)] Loss: 12278.270508\n",
      "Train Epoch: 2507 [98560/118836 (83%)] Loss: 12245.754883\n",
      "    epoch          : 2507\n",
      "    loss           : 12230.918437079974\n",
      "    val_loss       : 12225.494996986248\n",
      "    val_log_likelihood: -12136.915838244417\n",
      "    val_log_marginal: -12145.667378778482\n",
      "Train Epoch: 2508 [256/118836 (0%)] Loss: 12225.948242\n",
      "Train Epoch: 2508 [33024/118836 (28%)] Loss: 12230.076172\n",
      "Train Epoch: 2508 [65792/118836 (55%)] Loss: 12174.943359\n",
      "Train Epoch: 2508 [98560/118836 (83%)] Loss: 12295.561523\n",
      "    epoch          : 2508\n",
      "    loss           : 12225.377202233252\n",
      "    val_loss       : 12228.324154320693\n",
      "    val_log_likelihood: -12145.054320622674\n",
      "    val_log_marginal: -12153.862087321706\n",
      "Train Epoch: 2509 [256/118836 (0%)] Loss: 12154.358398\n",
      "Train Epoch: 2509 [33024/118836 (28%)] Loss: 12181.906250\n",
      "Train Epoch: 2509 [65792/118836 (55%)] Loss: 12239.412109\n",
      "Train Epoch: 2509 [98560/118836 (83%)] Loss: 12319.169922\n",
      "    epoch          : 2509\n",
      "    loss           : 12227.769898611972\n",
      "    val_loss       : 12227.187788561865\n",
      "    val_log_likelihood: -12133.902295123811\n",
      "    val_log_marginal: -12142.497188040792\n",
      "Train Epoch: 2510 [256/118836 (0%)] Loss: 12232.757812\n",
      "Train Epoch: 2510 [33024/118836 (28%)] Loss: 12294.197266\n",
      "Train Epoch: 2510 [65792/118836 (55%)] Loss: 12251.939453\n",
      "Train Epoch: 2510 [98560/118836 (83%)] Loss: 12165.792969\n",
      "    epoch          : 2510\n",
      "    loss           : 12227.32894534481\n",
      "    val_loss       : 12227.058774664958\n",
      "    val_log_likelihood: -12136.327495444324\n",
      "    val_log_marginal: -12145.048407411097\n",
      "Train Epoch: 2511 [256/118836 (0%)] Loss: 12217.452148\n",
      "Train Epoch: 2511 [33024/118836 (28%)] Loss: 12290.689453\n",
      "Train Epoch: 2511 [65792/118836 (55%)] Loss: 12221.827148\n",
      "Train Epoch: 2511 [98560/118836 (83%)] Loss: 12303.903320\n",
      "    epoch          : 2511\n",
      "    loss           : 12228.769019140302\n",
      "    val_loss       : 12230.10343839529\n",
      "    val_log_likelihood: -12140.239496904725\n",
      "    val_log_marginal: -12148.868652057443\n",
      "Train Epoch: 2512 [256/118836 (0%)] Loss: 12269.838867\n",
      "Train Epoch: 2512 [33024/118836 (28%)] Loss: 12268.148438\n",
      "Train Epoch: 2512 [65792/118836 (55%)] Loss: 12354.580078\n",
      "Train Epoch: 2512 [98560/118836 (83%)] Loss: 12278.316406\n",
      "    epoch          : 2512\n",
      "    loss           : 12229.941914967174\n",
      "    val_loss       : 12224.10844899568\n",
      "    val_log_likelihood: -12139.003007554022\n",
      "    val_log_marginal: -12147.583734821967\n",
      "Train Epoch: 2513 [256/118836 (0%)] Loss: 12255.179688\n",
      "Train Epoch: 2513 [33024/118836 (28%)] Loss: 12318.853516\n",
      "Train Epoch: 2513 [65792/118836 (55%)] Loss: 12236.725586\n",
      "Train Epoch: 2513 [98560/118836 (83%)] Loss: 12218.533203\n",
      "    epoch          : 2513\n",
      "    loss           : 12228.58679677807\n",
      "    val_loss       : 12231.99842030599\n",
      "    val_log_likelihood: -12141.324002274607\n",
      "    val_log_marginal: -12149.914103500807\n",
      "Train Epoch: 2514 [256/118836 (0%)] Loss: 12383.699219\n",
      "Train Epoch: 2514 [33024/118836 (28%)] Loss: 12176.888672\n",
      "Train Epoch: 2514 [65792/118836 (55%)] Loss: 12234.454102\n",
      "Train Epoch: 2514 [98560/118836 (83%)] Loss: 12274.925781\n",
      "    epoch          : 2514\n",
      "    loss           : 12234.50896967406\n",
      "    val_loss       : 12226.381275273341\n",
      "    val_log_likelihood: -12135.656731253877\n",
      "    val_log_marginal: -12144.32552238072\n",
      "Train Epoch: 2515 [256/118836 (0%)] Loss: 12348.307617\n",
      "Train Epoch: 2515 [33024/118836 (28%)] Loss: 12303.190430\n",
      "Train Epoch: 2515 [65792/118836 (55%)] Loss: 12308.080078\n",
      "Train Epoch: 2515 [98560/118836 (83%)] Loss: 12238.933594\n",
      "    epoch          : 2515\n",
      "    loss           : 12227.93760258349\n",
      "    val_loss       : 12228.339297077135\n",
      "    val_log_likelihood: -12135.300283518145\n",
      "    val_log_marginal: -12143.83626496975\n",
      "Train Epoch: 2516 [256/118836 (0%)] Loss: 12199.315430\n",
      "Train Epoch: 2516 [33024/118836 (28%)] Loss: 12250.207031\n",
      "Train Epoch: 2516 [65792/118836 (55%)] Loss: 12157.743164\n",
      "Train Epoch: 2516 [98560/118836 (83%)] Loss: 12269.058594\n",
      "    epoch          : 2516\n",
      "    loss           : 12221.384957383427\n",
      "    val_loss       : 12226.74094634363\n",
      "    val_log_likelihood: -12134.063483993745\n",
      "    val_log_marginal: -12142.495670960441\n",
      "Train Epoch: 2517 [256/118836 (0%)] Loss: 12251.431641\n",
      "Train Epoch: 2517 [33024/118836 (28%)] Loss: 12214.462891\n",
      "Train Epoch: 2517 [65792/118836 (55%)] Loss: 12260.135742\n",
      "Train Epoch: 2517 [98560/118836 (83%)] Loss: 12232.263672\n",
      "    epoch          : 2517\n",
      "    loss           : 12225.161914870243\n",
      "    val_loss       : 12227.936134749998\n",
      "    val_log_likelihood: -12134.21792981674\n",
      "    val_log_marginal: -12142.806946611214\n",
      "Train Epoch: 2518 [256/118836 (0%)] Loss: 12269.012695\n",
      "Train Epoch: 2518 [33024/118836 (28%)] Loss: 12117.395508\n",
      "Train Epoch: 2518 [65792/118836 (55%)] Loss: 12298.994141\n",
      "Train Epoch: 2518 [98560/118836 (83%)] Loss: 12317.901367\n",
      "    epoch          : 2518\n",
      "    loss           : 12229.535350108561\n",
      "    val_loss       : 12229.774551458473\n",
      "    val_log_likelihood: -12134.693088780758\n",
      "    val_log_marginal: -12143.303020480738\n",
      "Train Epoch: 2519 [256/118836 (0%)] Loss: 12285.412109\n",
      "Train Epoch: 2519 [33024/118836 (28%)] Loss: 12215.353516\n",
      "Train Epoch: 2519 [65792/118836 (55%)] Loss: 12179.319336\n",
      "Train Epoch: 2519 [98560/118836 (83%)] Loss: 12229.791992\n",
      "    epoch          : 2519\n",
      "    loss           : 12226.561456394747\n",
      "    val_loss       : 12228.05569174139\n",
      "    val_log_likelihood: -12136.056023993227\n",
      "    val_log_marginal: -12144.584616782795\n",
      "Train Epoch: 2520 [256/118836 (0%)] Loss: 12259.078125\n",
      "Train Epoch: 2520 [33024/118836 (28%)] Loss: 12271.689453\n",
      "Train Epoch: 2520 [65792/118836 (55%)] Loss: 12325.065430\n",
      "Train Epoch: 2520 [98560/118836 (83%)] Loss: 12228.833984\n",
      "    epoch          : 2520\n",
      "    loss           : 12228.859061433777\n",
      "    val_loss       : 12232.01540476203\n",
      "    val_log_likelihood: -12139.370116379758\n",
      "    val_log_marginal: -12147.916824970322\n",
      "Train Epoch: 2521 [256/118836 (0%)] Loss: 12237.299805\n",
      "Train Epoch: 2521 [33024/118836 (28%)] Loss: 12273.807617\n",
      "Train Epoch: 2521 [65792/118836 (55%)] Loss: 12244.355469\n",
      "Train Epoch: 2521 [98560/118836 (83%)] Loss: 12210.179688\n",
      "    epoch          : 2521\n",
      "    loss           : 12230.998315853754\n",
      "    val_loss       : 12227.929498741383\n",
      "    val_log_likelihood: -12137.581505085556\n",
      "    val_log_marginal: -12146.005869376504\n",
      "Train Epoch: 2522 [256/118836 (0%)] Loss: 12158.054688\n",
      "Train Epoch: 2522 [33024/118836 (28%)] Loss: 12186.804688\n",
      "Train Epoch: 2522 [65792/118836 (55%)] Loss: 12231.990234\n",
      "Train Epoch: 2522 [98560/118836 (83%)] Loss: 12241.849609\n",
      "    epoch          : 2522\n",
      "    loss           : 12224.595244972603\n",
      "    val_loss       : 12224.206983674429\n",
      "    val_log_likelihood: -12135.973843633685\n",
      "    val_log_marginal: -12144.497838816478\n",
      "Train Epoch: 2523 [256/118836 (0%)] Loss: 12223.351562\n",
      "Train Epoch: 2523 [33024/118836 (28%)] Loss: 12187.004883\n",
      "Train Epoch: 2523 [65792/118836 (55%)] Loss: 12344.029297\n",
      "Train Epoch: 2523 [98560/118836 (83%)] Loss: 12326.494141\n",
      "    epoch          : 2523\n",
      "    loss           : 12229.086850896918\n",
      "    val_loss       : 12222.453997131073\n",
      "    val_log_likelihood: -12138.38487063172\n",
      "    val_log_marginal: -12147.055464137711\n",
      "Train Epoch: 2524 [256/118836 (0%)] Loss: 12377.215820\n",
      "Train Epoch: 2524 [33024/118836 (28%)] Loss: 12275.031250\n",
      "Train Epoch: 2524 [65792/118836 (55%)] Loss: 12265.302734\n",
      "Train Epoch: 2524 [98560/118836 (83%)] Loss: 12169.269531\n",
      "    epoch          : 2524\n",
      "    loss           : 12230.005395568392\n",
      "    val_loss       : 12234.402850478102\n",
      "    val_log_likelihood: -12138.42100619055\n",
      "    val_log_marginal: -12147.124787097104\n",
      "Train Epoch: 2525 [256/118836 (0%)] Loss: 12213.474609\n",
      "Train Epoch: 2525 [33024/118836 (28%)] Loss: 12187.916016\n",
      "Train Epoch: 2525 [65792/118836 (55%)] Loss: 12238.866211\n",
      "Train Epoch: 2525 [98560/118836 (83%)] Loss: 12298.868164\n",
      "    epoch          : 2525\n",
      "    loss           : 12227.115914656999\n",
      "    val_loss       : 12227.203754326505\n",
      "    val_log_likelihood: -12131.000115668941\n",
      "    val_log_marginal: -12139.63933152177\n",
      "Train Epoch: 2526 [256/118836 (0%)] Loss: 12241.500977\n",
      "Train Epoch: 2526 [33024/118836 (28%)] Loss: 12209.861328\n",
      "Train Epoch: 2526 [65792/118836 (55%)] Loss: 12297.887695\n",
      "Train Epoch: 2526 [98560/118836 (83%)] Loss: 12260.925781\n",
      "    epoch          : 2526\n",
      "    loss           : 12224.95765224359\n",
      "    val_loss       : 12232.815283973145\n",
      "    val_log_likelihood: -12137.528682181814\n",
      "    val_log_marginal: -12146.251475429819\n",
      "Train Epoch: 2527 [256/118836 (0%)] Loss: 12260.592773\n",
      "Train Epoch: 2527 [33024/118836 (28%)] Loss: 12226.410156\n",
      "Train Epoch: 2527 [65792/118836 (55%)] Loss: 12316.123047\n",
      "Train Epoch: 2527 [98560/118836 (83%)] Loss: 12173.985352\n",
      "    epoch          : 2527\n",
      "    loss           : 12227.609305695565\n",
      "    val_loss       : 12226.379084036784\n",
      "    val_log_likelihood: -12137.42337546526\n",
      "    val_log_marginal: -12146.220858087325\n",
      "Train Epoch: 2528 [256/118836 (0%)] Loss: 12231.529297\n",
      "Train Epoch: 2528 [33024/118836 (28%)] Loss: 12384.938477\n",
      "Train Epoch: 2528 [65792/118836 (55%)] Loss: 12349.734375\n",
      "Train Epoch: 2528 [98560/118836 (83%)] Loss: 12222.214844\n",
      "    epoch          : 2528\n",
      "    loss           : 12229.812208565963\n",
      "    val_loss       : 12226.712419440606\n",
      "    val_log_likelihood: -12132.73236242504\n",
      "    val_log_marginal: -12141.321919817981\n",
      "Train Epoch: 2529 [256/118836 (0%)] Loss: 12173.425781\n",
      "Train Epoch: 2529 [33024/118836 (28%)] Loss: 12222.372070\n",
      "Train Epoch: 2529 [65792/118836 (55%)] Loss: 12303.129883\n",
      "Train Epoch: 2529 [98560/118836 (83%)] Loss: 12310.780273\n",
      "    epoch          : 2529\n",
      "    loss           : 12228.363008878723\n",
      "    val_loss       : 12229.334883205696\n",
      "    val_log_likelihood: -12135.999750730201\n",
      "    val_log_marginal: -12144.597139454692\n",
      "Train Epoch: 2530 [256/118836 (0%)] Loss: 12230.746094\n",
      "Train Epoch: 2530 [33024/118836 (28%)] Loss: 12361.781250\n",
      "Train Epoch: 2530 [65792/118836 (55%)] Loss: 12244.318359\n",
      "Train Epoch: 2530 [98560/118836 (83%)] Loss: 12193.817383\n",
      "    epoch          : 2530\n",
      "    loss           : 12230.729971825887\n",
      "    val_loss       : 12229.2624895744\n",
      "    val_log_likelihood: -12137.814058945927\n",
      "    val_log_marginal: -12146.358986961048\n",
      "Train Epoch: 2531 [256/118836 (0%)] Loss: 12165.260742\n",
      "Train Epoch: 2531 [33024/118836 (28%)] Loss: 12280.814453\n",
      "Train Epoch: 2531 [65792/118836 (55%)] Loss: 12253.644531\n",
      "Train Epoch: 2531 [98560/118836 (83%)] Loss: 12242.119141\n",
      "    epoch          : 2531\n",
      "    loss           : 12227.407348531846\n",
      "    val_loss       : 12227.629010616034\n",
      "    val_log_likelihood: -12134.505401061053\n",
      "    val_log_marginal: -12143.129787165759\n",
      "Train Epoch: 2532 [256/118836 (0%)] Loss: 12233.930664\n",
      "Train Epoch: 2532 [33024/118836 (28%)] Loss: 12202.472656\n",
      "Train Epoch: 2532 [65792/118836 (55%)] Loss: 12283.367188\n",
      "Train Epoch: 2532 [98560/118836 (83%)] Loss: 12276.396484\n",
      "    epoch          : 2532\n",
      "    loss           : 12226.880530138544\n",
      "    val_loss       : 12223.929151994309\n",
      "    val_log_likelihood: -12133.104242594602\n",
      "    val_log_marginal: -12141.682113796154\n",
      "Train Epoch: 2533 [256/118836 (0%)] Loss: 12256.863281\n",
      "Train Epoch: 2533 [33024/118836 (28%)] Loss: 12417.349609\n",
      "Train Epoch: 2533 [65792/118836 (55%)] Loss: 12176.969727\n",
      "Train Epoch: 2533 [98560/118836 (83%)] Loss: 12232.125977\n",
      "    epoch          : 2533\n",
      "    loss           : 12226.953832745296\n",
      "    val_loss       : 12225.434382950836\n",
      "    val_log_likelihood: -12133.264809663204\n",
      "    val_log_marginal: -12141.826831824445\n",
      "Train Epoch: 2534 [256/118836 (0%)] Loss: 12194.437500\n",
      "Train Epoch: 2534 [33024/118836 (28%)] Loss: 12365.695312\n",
      "Train Epoch: 2534 [65792/118836 (55%)] Loss: 12204.309570\n",
      "Train Epoch: 2534 [98560/118836 (83%)] Loss: 12213.501953\n",
      "    epoch          : 2534\n",
      "    loss           : 12225.039500781895\n",
      "    val_loss       : 12226.51298815948\n",
      "    val_log_likelihood: -12134.791192844034\n",
      "    val_log_marginal: -12143.302129891934\n",
      "Train Epoch: 2535 [256/118836 (0%)] Loss: 12175.145508\n",
      "Train Epoch: 2535 [33024/118836 (28%)] Loss: 12256.981445\n",
      "Train Epoch: 2535 [65792/118836 (55%)] Loss: 12312.010742\n",
      "Train Epoch: 2535 [98560/118836 (83%)] Loss: 12304.246094\n",
      "    epoch          : 2535\n",
      "    loss           : 12226.447710853494\n",
      "    val_loss       : 12231.12778927762\n",
      "    val_log_likelihood: -12138.258956750156\n",
      "    val_log_marginal: -12146.786651697284\n",
      "Train Epoch: 2536 [256/118836 (0%)] Loss: 12267.195312\n",
      "Train Epoch: 2536 [33024/118836 (28%)] Loss: 12221.660156\n",
      "Train Epoch: 2536 [65792/118836 (55%)] Loss: 12409.741211\n",
      "Train Epoch: 2536 [98560/118836 (83%)] Loss: 12269.193359\n",
      "    epoch          : 2536\n",
      "    loss           : 12226.880014313225\n",
      "    val_loss       : 12235.757886829404\n",
      "    val_log_likelihood: -12150.631099598066\n",
      "    val_log_marginal: -12159.376117853797\n",
      "Train Epoch: 2537 [256/118836 (0%)] Loss: 12340.707031\n",
      "Train Epoch: 2537 [33024/118836 (28%)] Loss: 12283.649414\n",
      "Train Epoch: 2537 [65792/118836 (55%)] Loss: 12272.734375\n",
      "Train Epoch: 2537 [98560/118836 (83%)] Loss: 12124.870117\n",
      "    epoch          : 2537\n",
      "    loss           : 12231.298297598738\n",
      "    val_loss       : 12229.097142870416\n",
      "    val_log_likelihood: -12140.099000820668\n",
      "    val_log_marginal: -12148.64263833966\n",
      "Train Epoch: 2538 [256/118836 (0%)] Loss: 12318.207031\n",
      "Train Epoch: 2538 [33024/118836 (28%)] Loss: 12242.881836\n",
      "Train Epoch: 2538 [65792/118836 (55%)] Loss: 12205.841797\n",
      "Train Epoch: 2538 [98560/118836 (83%)] Loss: 12256.410156\n",
      "    epoch          : 2538\n",
      "    loss           : 12228.403356337882\n",
      "    val_loss       : 12226.9709422016\n",
      "    val_log_likelihood: -12135.367728042285\n",
      "    val_log_marginal: -12143.98293543084\n",
      "Train Epoch: 2539 [256/118836 (0%)] Loss: 12186.818359\n",
      "Train Epoch: 2539 [33024/118836 (28%)] Loss: 12267.676758\n",
      "Train Epoch: 2539 [65792/118836 (55%)] Loss: 12183.977539\n",
      "Train Epoch: 2539 [98560/118836 (83%)] Loss: 12294.868164\n",
      "    epoch          : 2539\n",
      "    loss           : 12227.183168553556\n",
      "    val_loss       : 12234.102065038178\n",
      "    val_log_likelihood: -12141.13399374483\n",
      "    val_log_marginal: -12149.743538737643\n",
      "Train Epoch: 2540 [256/118836 (0%)] Loss: 12254.798828\n",
      "Train Epoch: 2540 [33024/118836 (28%)] Loss: 12408.064453\n",
      "Train Epoch: 2540 [65792/118836 (55%)] Loss: 12202.958008\n",
      "Train Epoch: 2540 [98560/118836 (83%)] Loss: 12222.259766\n",
      "    epoch          : 2540\n",
      "    loss           : 12235.445651752481\n",
      "    val_loss       : 12228.04986354802\n",
      "    val_log_likelihood: -12136.073885636371\n",
      "    val_log_marginal: -12145.044324278877\n",
      "Train Epoch: 2541 [256/118836 (0%)] Loss: 12252.046875\n",
      "Train Epoch: 2541 [33024/118836 (28%)] Loss: 12236.800781\n",
      "Train Epoch: 2541 [65792/118836 (55%)] Loss: 12244.033203\n",
      "Train Epoch: 2541 [98560/118836 (83%)] Loss: 12353.760742\n",
      "    epoch          : 2541\n",
      "    loss           : 12229.447161587572\n",
      "    val_loss       : 12232.478715580814\n",
      "    val_log_likelihood: -12137.824613090623\n",
      "    val_log_marginal: -12146.462310653462\n",
      "Train Epoch: 2542 [256/118836 (0%)] Loss: 12251.022461\n",
      "Train Epoch: 2542 [33024/118836 (28%)] Loss: 12177.386719\n",
      "Train Epoch: 2542 [65792/118836 (55%)] Loss: 12340.454102\n",
      "Train Epoch: 2542 [98560/118836 (83%)] Loss: 12262.289062\n",
      "    epoch          : 2542\n",
      "    loss           : 12227.076424052679\n",
      "    val_loss       : 12228.294113486476\n",
      "    val_log_likelihood: -12141.38420117349\n",
      "    val_log_marginal: -12149.969710600313\n",
      "Train Epoch: 2543 [256/118836 (0%)] Loss: 12199.897461\n",
      "Train Epoch: 2543 [33024/118836 (28%)] Loss: 12178.454102\n",
      "Train Epoch: 2543 [65792/118836 (55%)] Loss: 12191.615234\n",
      "Train Epoch: 2543 [98560/118836 (83%)] Loss: 12240.710938\n",
      "    epoch          : 2543\n",
      "    loss           : 12226.311948310846\n",
      "    val_loss       : 12224.446507611941\n",
      "    val_log_likelihood: -12143.572799220688\n",
      "    val_log_marginal: -12152.246315221857\n",
      "Train Epoch: 2544 [256/118836 (0%)] Loss: 12248.611328\n",
      "Train Epoch: 2544 [33024/118836 (28%)] Loss: 12146.626953\n",
      "Train Epoch: 2544 [65792/118836 (55%)] Loss: 12199.883789\n",
      "Train Epoch: 2544 [98560/118836 (83%)] Loss: 12252.875000\n",
      "    epoch          : 2544\n",
      "    loss           : 12230.089161529415\n",
      "    val_loss       : 12223.659081237549\n",
      "    val_log_likelihood: -12136.396973706318\n",
      "    val_log_marginal: -12145.136146634439\n",
      "Train Epoch: 2545 [256/118836 (0%)] Loss: 12133.292969\n",
      "Train Epoch: 2545 [33024/118836 (28%)] Loss: 12177.736328\n",
      "Train Epoch: 2545 [65792/118836 (55%)] Loss: 12258.235352\n",
      "Train Epoch: 2545 [98560/118836 (83%)] Loss: 12239.135742\n",
      "    epoch          : 2545\n",
      "    loss           : 12228.178728223222\n",
      "    val_loss       : 12225.613600245522\n",
      "    val_log_likelihood: -12132.940726452647\n",
      "    val_log_marginal: -12141.565398490886\n",
      "Train Epoch: 2546 [256/118836 (0%)] Loss: 12358.768555\n",
      "Train Epoch: 2546 [33024/118836 (28%)] Loss: 12265.389648\n",
      "Train Epoch: 2546 [65792/118836 (55%)] Loss: 12263.061523\n",
      "Train Epoch: 2546 [98560/118836 (83%)] Loss: 12204.449219\n",
      "    epoch          : 2546\n",
      "    loss           : 12226.976747150278\n",
      "    val_loss       : 12229.696143997357\n",
      "    val_log_likelihood: -12133.113946831058\n",
      "    val_log_marginal: -12141.590820158362\n",
      "Train Epoch: 2547 [256/118836 (0%)] Loss: 12276.138672\n",
      "Train Epoch: 2547 [33024/118836 (28%)] Loss: 12353.487305\n",
      "Train Epoch: 2547 [65792/118836 (55%)] Loss: 12260.658203\n",
      "Train Epoch: 2547 [98560/118836 (83%)] Loss: 12206.939453\n",
      "    epoch          : 2547\n",
      "    loss           : 12234.540013053143\n",
      "    val_loss       : 12229.396501830906\n",
      "    val_log_likelihood: -12141.43956362438\n",
      "    val_log_marginal: -12150.013430464158\n",
      "Train Epoch: 2548 [256/118836 (0%)] Loss: 12211.114258\n",
      "Train Epoch: 2548 [33024/118836 (28%)] Loss: 12235.827148\n",
      "Train Epoch: 2548 [65792/118836 (55%)] Loss: 12297.212891\n",
      "Train Epoch: 2548 [98560/118836 (83%)] Loss: 12167.105469\n",
      "    epoch          : 2548\n",
      "    loss           : 12228.260566583953\n",
      "    val_loss       : 12227.639917620263\n",
      "    val_log_likelihood: -12137.072812790788\n",
      "    val_log_marginal: -12145.727367404605\n",
      "Train Epoch: 2549 [256/118836 (0%)] Loss: 12253.967773\n",
      "Train Epoch: 2549 [33024/118836 (28%)] Loss: 12260.820312\n",
      "Train Epoch: 2549 [65792/118836 (55%)] Loss: 12266.663086\n",
      "Train Epoch: 2549 [98560/118836 (83%)] Loss: 12264.552734\n",
      "    epoch          : 2549\n",
      "    loss           : 12229.202679286858\n",
      "    val_loss       : 12230.9216842068\n",
      "    val_log_likelihood: -12139.326525020677\n",
      "    val_log_marginal: -12148.059768713489\n",
      "Train Epoch: 2550 [256/118836 (0%)] Loss: 12236.498047\n",
      "Train Epoch: 2550 [33024/118836 (28%)] Loss: 12177.788086\n",
      "Train Epoch: 2550 [65792/118836 (55%)] Loss: 12243.279297\n",
      "Train Epoch: 2550 [98560/118836 (83%)] Loss: 12233.911133\n",
      "    epoch          : 2550\n",
      "    loss           : 12228.102814180107\n",
      "    val_loss       : 12227.884429328757\n",
      "    val_log_likelihood: -12138.966983302316\n",
      "    val_log_marginal: -12147.588262393794\n",
      "Train Epoch: 2551 [256/118836 (0%)] Loss: 12212.355469\n",
      "Train Epoch: 2551 [33024/118836 (28%)] Loss: 12210.387695\n",
      "Train Epoch: 2551 [65792/118836 (55%)] Loss: 12176.007812\n",
      "Train Epoch: 2551 [98560/118836 (83%)] Loss: 12231.973633\n",
      "    epoch          : 2551\n",
      "    loss           : 12228.295708294561\n",
      "    val_loss       : 12226.031653606777\n",
      "    val_log_likelihood: -12137.953071527347\n",
      "    val_log_marginal: -12146.514429719575\n",
      "Train Epoch: 2552 [256/118836 (0%)] Loss: 12299.774414\n",
      "Train Epoch: 2552 [33024/118836 (28%)] Loss: 12195.850586\n",
      "Train Epoch: 2552 [65792/118836 (55%)] Loss: 12343.947266\n",
      "Train Epoch: 2552 [98560/118836 (83%)] Loss: 12169.751953\n",
      "    epoch          : 2552\n",
      "    loss           : 12224.489469926075\n",
      "    val_loss       : 12227.375106636222\n",
      "    val_log_likelihood: -12133.737042493796\n",
      "    val_log_marginal: -12142.401141287328\n",
      "Train Epoch: 2553 [256/118836 (0%)] Loss: 12251.448242\n",
      "Train Epoch: 2553 [33024/118836 (28%)] Loss: 12245.482422\n",
      "Train Epoch: 2553 [65792/118836 (55%)] Loss: 12256.365234\n",
      "Train Epoch: 2553 [98560/118836 (83%)] Loss: 12244.697266\n",
      "    epoch          : 2553\n",
      "    loss           : 12224.160191144541\n",
      "    val_loss       : 12225.424478215584\n",
      "    val_log_likelihood: -12136.30386037014\n",
      "    val_log_marginal: -12144.84599042059\n",
      "Train Epoch: 2554 [256/118836 (0%)] Loss: 12305.076172\n",
      "Train Epoch: 2554 [33024/118836 (28%)] Loss: 12107.439453\n",
      "Train Epoch: 2554 [65792/118836 (55%)] Loss: 12245.294922\n",
      "Train Epoch: 2554 [98560/118836 (83%)] Loss: 12192.647461\n",
      "    epoch          : 2554\n",
      "    loss           : 12227.662790787841\n",
      "    val_loss       : 12227.429862476602\n",
      "    val_log_likelihood: -12136.107534636063\n",
      "    val_log_marginal: -12144.703458900283\n",
      "Train Epoch: 2555 [256/118836 (0%)] Loss: 12190.154297\n",
      "Train Epoch: 2555 [33024/118836 (28%)] Loss: 12198.579102\n",
      "Train Epoch: 2555 [65792/118836 (55%)] Loss: 12135.099609\n",
      "Train Epoch: 2555 [98560/118836 (83%)] Loss: 12298.224609\n",
      "    epoch          : 2555\n",
      "    loss           : 12224.582024788047\n",
      "    val_loss       : 12227.317324076688\n",
      "    val_log_likelihood: -12136.50142631436\n",
      "    val_log_marginal: -12145.055971830157\n",
      "Train Epoch: 2556 [256/118836 (0%)] Loss: 12217.660156\n",
      "Train Epoch: 2556 [33024/118836 (28%)] Loss: 12230.822266\n",
      "Train Epoch: 2556 [65792/118836 (55%)] Loss: 12281.501953\n",
      "Train Epoch: 2556 [98560/118836 (83%)] Loss: 12234.867188\n",
      "    epoch          : 2556\n",
      "    loss           : 12233.580596858199\n",
      "    val_loss       : 12228.572298933483\n",
      "    val_log_likelihood: -12142.063275918888\n",
      "    val_log_marginal: -12150.859475430818\n",
      "Train Epoch: 2557 [256/118836 (0%)] Loss: 12287.278320\n",
      "Train Epoch: 2557 [33024/118836 (28%)] Loss: 12270.104492\n",
      "Train Epoch: 2557 [65792/118836 (55%)] Loss: 12246.899414\n",
      "Train Epoch: 2557 [98560/118836 (83%)] Loss: 12233.732422\n",
      "    epoch          : 2557\n",
      "    loss           : 12229.350718730613\n",
      "    val_loss       : 12228.456049842764\n",
      "    val_log_likelihood: -12137.635289366212\n",
      "    val_log_marginal: -12146.244787056474\n",
      "Train Epoch: 2558 [256/118836 (0%)] Loss: 12226.480469\n",
      "Train Epoch: 2558 [33024/118836 (28%)] Loss: 12263.035156\n",
      "Train Epoch: 2558 [65792/118836 (55%)] Loss: 12158.419922\n",
      "Train Epoch: 2558 [98560/118836 (83%)] Loss: 12390.904297\n",
      "    epoch          : 2558\n",
      "    loss           : 12227.29788920337\n",
      "    val_loss       : 12227.732237944832\n",
      "    val_log_likelihood: -12135.844849662688\n",
      "    val_log_marginal: -12144.415068582615\n",
      "Train Epoch: 2559 [256/118836 (0%)] Loss: 12222.565430\n",
      "Train Epoch: 2559 [33024/118836 (28%)] Loss: 12277.054688\n",
      "Train Epoch: 2559 [65792/118836 (55%)] Loss: 12339.670898\n",
      "Train Epoch: 2559 [98560/118836 (83%)] Loss: 12352.791992\n",
      "    epoch          : 2559\n",
      "    loss           : 12227.652742129341\n",
      "    val_loss       : 12225.820434319741\n",
      "    val_log_likelihood: -12140.955721573871\n",
      "    val_log_marginal: -12149.43116912575\n",
      "Train Epoch: 2560 [256/118836 (0%)] Loss: 12239.633789\n",
      "Train Epoch: 2560 [33024/118836 (28%)] Loss: 12378.498047\n",
      "Train Epoch: 2560 [65792/118836 (55%)] Loss: 12286.444336\n",
      "Train Epoch: 2560 [98560/118836 (83%)] Loss: 12361.988281\n",
      "    epoch          : 2560\n",
      "    loss           : 12228.460819407826\n",
      "    val_loss       : 12229.437012438184\n",
      "    val_log_likelihood: -12139.614495773883\n",
      "    val_log_marginal: -12148.06126624675\n",
      "Train Epoch: 2561 [256/118836 (0%)] Loss: 12272.568359\n",
      "Train Epoch: 2561 [33024/118836 (28%)] Loss: 12169.666016\n",
      "Train Epoch: 2561 [65792/118836 (55%)] Loss: 12231.892578\n",
      "Train Epoch: 2561 [98560/118836 (83%)] Loss: 12293.416016\n",
      "    epoch          : 2561\n",
      "    loss           : 12227.046825081421\n",
      "    val_loss       : 12222.218262397277\n",
      "    val_log_likelihood: -12135.502556348221\n",
      "    val_log_marginal: -12143.870465496939\n",
      "Train Epoch: 2562 [256/118836 (0%)] Loss: 12233.333984\n",
      "Train Epoch: 2562 [33024/118836 (28%)] Loss: 12152.696289\n",
      "Train Epoch: 2562 [65792/118836 (55%)] Loss: 12324.416992\n",
      "Train Epoch: 2562 [98560/118836 (83%)] Loss: 12245.424805\n",
      "    epoch          : 2562\n",
      "    loss           : 12227.122438966864\n",
      "    val_loss       : 12230.764658183582\n",
      "    val_log_likelihood: -12136.427159422818\n",
      "    val_log_marginal: -12144.814078034857\n",
      "Train Epoch: 2563 [256/118836 (0%)] Loss: 12191.213867\n",
      "Train Epoch: 2563 [33024/118836 (28%)] Loss: 12212.261719\n",
      "Train Epoch: 2563 [65792/118836 (55%)] Loss: 12283.664062\n",
      "Train Epoch: 2563 [98560/118836 (83%)] Loss: 12250.947266\n",
      "    epoch          : 2563\n",
      "    loss           : 12218.772135901312\n",
      "    val_loss       : 12226.541472356168\n",
      "    val_log_likelihood: -12132.465229528536\n",
      "    val_log_marginal: -12140.920822010434\n",
      "Train Epoch: 2564 [256/118836 (0%)] Loss: 12335.804688\n",
      "Train Epoch: 2564 [33024/118836 (28%)] Loss: 12199.648438\n",
      "Train Epoch: 2564 [65792/118836 (55%)] Loss: 12325.378906\n",
      "Train Epoch: 2564 [98560/118836 (83%)] Loss: 12218.132812\n",
      "    epoch          : 2564\n",
      "    loss           : 12225.533687125206\n",
      "    val_loss       : 12228.05685449203\n",
      "    val_log_likelihood: -12137.2605538216\n",
      "    val_log_marginal: -12145.651853447915\n",
      "Train Epoch: 2565 [256/118836 (0%)] Loss: 12236.366211\n",
      "Train Epoch: 2565 [33024/118836 (28%)] Loss: 12251.580078\n",
      "Train Epoch: 2565 [65792/118836 (55%)] Loss: 12217.657227\n",
      "Train Epoch: 2565 [98560/118836 (83%)] Loss: 12418.521484\n",
      "    epoch          : 2565\n",
      "    loss           : 12228.01551595456\n",
      "    val_loss       : 12232.857330740664\n",
      "    val_log_likelihood: -12139.72838654751\n",
      "    val_log_marginal: -12148.270962344579\n",
      "Train Epoch: 2566 [256/118836 (0%)] Loss: 12206.113281\n",
      "Train Epoch: 2566 [33024/118836 (28%)] Loss: 12195.773438\n",
      "Train Epoch: 2566 [65792/118836 (55%)] Loss: 12199.191406\n",
      "Train Epoch: 2566 [98560/118836 (83%)] Loss: 12263.888672\n",
      "    epoch          : 2566\n",
      "    loss           : 12225.381436911963\n",
      "    val_loss       : 12224.320766649627\n",
      "    val_log_likelihood: -12137.490690911909\n",
      "    val_log_marginal: -12146.083607345594\n",
      "Train Epoch: 2567 [256/118836 (0%)] Loss: 12232.447266\n",
      "Train Epoch: 2567 [33024/118836 (28%)] Loss: 12300.276367\n",
      "Train Epoch: 2567 [65792/118836 (55%)] Loss: 12268.464844\n",
      "Train Epoch: 2567 [98560/118836 (83%)] Loss: 12304.216797\n",
      "    epoch          : 2567\n",
      "    loss           : 12229.436357203786\n",
      "    val_loss       : 12226.225134975144\n",
      "    val_log_likelihood: -12135.311526506926\n",
      "    val_log_marginal: -12143.948877047898\n",
      "Train Epoch: 2568 [256/118836 (0%)] Loss: 12367.664062\n",
      "Train Epoch: 2568 [33024/118836 (28%)] Loss: 12208.435547\n",
      "Train Epoch: 2568 [65792/118836 (55%)] Loss: 12296.742188\n",
      "Train Epoch: 2568 [98560/118836 (83%)] Loss: 12197.315430\n",
      "    epoch          : 2568\n",
      "    loss           : 12229.178347614248\n",
      "    val_loss       : 12224.592620682142\n",
      "    val_log_likelihood: -12137.476833740435\n",
      "    val_log_marginal: -12146.21616110784\n",
      "Train Epoch: 2569 [256/118836 (0%)] Loss: 12248.016602\n",
      "Train Epoch: 2569 [33024/118836 (28%)] Loss: 12274.726562\n",
      "Train Epoch: 2569 [65792/118836 (55%)] Loss: 12246.806641\n",
      "Train Epoch: 2569 [98560/118836 (83%)] Loss: 12243.843750\n",
      "    epoch          : 2569\n",
      "    loss           : 12227.98192608173\n",
      "    val_loss       : 12230.482346102275\n",
      "    val_log_likelihood: -12134.304217877636\n",
      "    val_log_marginal: -12142.823088790461\n",
      "Train Epoch: 2570 [256/118836 (0%)] Loss: 12173.657227\n",
      "Train Epoch: 2570 [33024/118836 (28%)] Loss: 12293.378906\n",
      "Train Epoch: 2570 [65792/118836 (55%)] Loss: 12363.113281\n",
      "Train Epoch: 2570 [98560/118836 (83%)] Loss: 12192.731445\n",
      "    epoch          : 2570\n",
      "    loss           : 12229.36553210944\n",
      "    val_loss       : 12222.958084178717\n",
      "    val_log_likelihood: -12137.115796564825\n",
      "    val_log_marginal: -12145.4736672787\n",
      "Train Epoch: 2571 [256/118836 (0%)] Loss: 12217.649414\n",
      "Train Epoch: 2571 [33024/118836 (28%)] Loss: 12156.688477\n",
      "Train Epoch: 2571 [65792/118836 (55%)] Loss: 12321.803711\n",
      "Train Epoch: 2571 [98560/118836 (83%)] Loss: 12287.204102\n",
      "    epoch          : 2571\n",
      "    loss           : 12230.17408547224\n",
      "    val_loss       : 12227.896413305049\n",
      "    val_log_likelihood: -12136.739665723222\n",
      "    val_log_marginal: -12145.224412365664\n",
      "Train Epoch: 2572 [256/118836 (0%)] Loss: 12218.184570\n",
      "Train Epoch: 2572 [33024/118836 (28%)] Loss: 12245.552734\n",
      "Train Epoch: 2572 [65792/118836 (55%)] Loss: 12196.355469\n",
      "Train Epoch: 2572 [98560/118836 (83%)] Loss: 12180.194336\n",
      "    epoch          : 2572\n",
      "    loss           : 12226.075132954664\n",
      "    val_loss       : 12223.875621686515\n",
      "    val_log_likelihood: -12138.607523973842\n",
      "    val_log_marginal: -12146.939988834616\n",
      "Train Epoch: 2573 [256/118836 (0%)] Loss: 12212.312500\n",
      "Train Epoch: 2573 [33024/118836 (28%)] Loss: 12245.681641\n",
      "Train Epoch: 2573 [65792/118836 (55%)] Loss: 12322.521484\n",
      "Train Epoch: 2573 [98560/118836 (83%)] Loss: 12265.135742\n",
      "    epoch          : 2573\n",
      "    loss           : 12224.278926928248\n",
      "    val_loss       : 12225.656412643155\n",
      "    val_log_likelihood: -12131.030501221308\n",
      "    val_log_marginal: -12139.539379677022\n",
      "Train Epoch: 2574 [256/118836 (0%)] Loss: 12161.066406\n",
      "Train Epoch: 2574 [33024/118836 (28%)] Loss: 12202.735352\n",
      "Train Epoch: 2574 [65792/118836 (55%)] Loss: 12244.666016\n",
      "Train Epoch: 2574 [98560/118836 (83%)] Loss: 12280.708984\n",
      "    epoch          : 2574\n",
      "    loss           : 12225.536803724668\n",
      "    val_loss       : 12227.486249169782\n",
      "    val_log_likelihood: -12145.176044412996\n",
      "    val_log_marginal: -12153.764524087026\n",
      "Train Epoch: 2575 [256/118836 (0%)] Loss: 12236.633789\n",
      "Train Epoch: 2575 [33024/118836 (28%)] Loss: 12208.241211\n",
      "Train Epoch: 2575 [65792/118836 (55%)] Loss: 12196.026367\n",
      "Train Epoch: 2575 [98560/118836 (83%)] Loss: 12261.741211\n",
      "    epoch          : 2575\n",
      "    loss           : 12228.420475018092\n",
      "    val_loss       : 12233.645268085475\n",
      "    val_log_likelihood: -12136.474208895524\n",
      "    val_log_marginal: -12145.094400020136\n",
      "Train Epoch: 2576 [256/118836 (0%)] Loss: 12181.564453\n",
      "Train Epoch: 2576 [33024/118836 (28%)] Loss: 12174.750977\n",
      "Train Epoch: 2576 [65792/118836 (55%)] Loss: 12248.922852\n",
      "Train Epoch: 2576 [98560/118836 (83%)] Loss: 12314.249023\n",
      "    epoch          : 2576\n",
      "    loss           : 12230.182787459937\n",
      "    val_loss       : 12226.589012994129\n",
      "    val_log_likelihood: -12137.032632857734\n",
      "    val_log_marginal: -12145.700318648856\n",
      "Train Epoch: 2577 [256/118836 (0%)] Loss: 12241.267578\n",
      "Train Epoch: 2577 [33024/118836 (28%)] Loss: 12213.939453\n",
      "Train Epoch: 2577 [65792/118836 (55%)] Loss: 12327.498047\n",
      "Train Epoch: 2577 [98560/118836 (83%)] Loss: 12247.912109\n",
      "    epoch          : 2577\n",
      "    loss           : 12227.975306296526\n",
      "    val_loss       : 12224.494058846016\n",
      "    val_log_likelihood: -12137.410315698666\n",
      "    val_log_marginal: -12146.236498276474\n",
      "Train Epoch: 2578 [256/118836 (0%)] Loss: 12238.165039\n",
      "Train Epoch: 2578 [33024/118836 (28%)] Loss: 12271.323242\n",
      "Train Epoch: 2578 [65792/118836 (55%)] Loss: 12157.493164\n",
      "Train Epoch: 2578 [98560/118836 (83%)] Loss: 12301.136719\n",
      "    epoch          : 2578\n",
      "    loss           : 12222.201272358354\n",
      "    val_loss       : 12225.922738812742\n",
      "    val_log_likelihood: -12137.606266477978\n",
      "    val_log_marginal: -12146.226700204243\n",
      "Train Epoch: 2579 [256/118836 (0%)] Loss: 12260.637695\n",
      "Train Epoch: 2579 [33024/118836 (28%)] Loss: 12333.048828\n",
      "Train Epoch: 2579 [65792/118836 (55%)] Loss: 12305.493164\n",
      "Train Epoch: 2579 [98560/118836 (83%)] Loss: 12268.745117\n",
      "    epoch          : 2579\n",
      "    loss           : 12227.047368208488\n",
      "    val_loss       : 12224.753319657117\n",
      "    val_log_likelihood: -12137.608757075837\n",
      "    val_log_marginal: -12146.22208993256\n",
      "Train Epoch: 2580 [256/118836 (0%)] Loss: 12130.896484\n",
      "Train Epoch: 2580 [33024/118836 (28%)] Loss: 12239.274414\n",
      "Train Epoch: 2580 [65792/118836 (55%)] Loss: 12319.555664\n",
      "Train Epoch: 2580 [98560/118836 (83%)] Loss: 12262.772461\n",
      "    epoch          : 2580\n",
      "    loss           : 12229.358061769799\n",
      "    val_loss       : 12235.552214109746\n",
      "    val_log_likelihood: -12145.491996064671\n",
      "    val_log_marginal: -12154.225799873935\n",
      "Train Epoch: 2581 [256/118836 (0%)] Loss: 12255.895508\n",
      "Train Epoch: 2581 [33024/118836 (28%)] Loss: 12207.416992\n",
      "Train Epoch: 2581 [65792/118836 (55%)] Loss: 12302.546875\n",
      "Train Epoch: 2581 [98560/118836 (83%)] Loss: 12275.480469\n",
      "    epoch          : 2581\n",
      "    loss           : 12228.681803950838\n",
      "    val_loss       : 12229.154094075038\n",
      "    val_log_likelihood: -12142.0246431387\n",
      "    val_log_marginal: -12150.956610563779\n",
      "Train Epoch: 2582 [256/118836 (0%)] Loss: 12201.542969\n",
      "Train Epoch: 2582 [33024/118836 (28%)] Loss: 12177.574219\n",
      "Train Epoch: 2582 [65792/118836 (55%)] Loss: 12181.920898\n",
      "Train Epoch: 2582 [98560/118836 (83%)] Loss: 12235.511719\n",
      "    epoch          : 2582\n",
      "    loss           : 12222.789359588243\n",
      "    val_loss       : 12230.125743079496\n",
      "    val_log_likelihood: -12142.711667377482\n",
      "    val_log_marginal: -12151.467579953938\n",
      "Train Epoch: 2583 [256/118836 (0%)] Loss: 12302.974609\n",
      "Train Epoch: 2583 [33024/118836 (28%)] Loss: 12289.034180\n",
      "Train Epoch: 2583 [65792/118836 (55%)] Loss: 12198.243164\n",
      "Train Epoch: 2583 [98560/118836 (83%)] Loss: 12254.964844\n",
      "    epoch          : 2583\n",
      "    loss           : 12230.194116069582\n",
      "    val_loss       : 12231.05385947659\n",
      "    val_log_likelihood: -12136.376704662944\n",
      "    val_log_marginal: -12144.979807541635\n",
      "Train Epoch: 2584 [256/118836 (0%)] Loss: 12260.609375\n",
      "Train Epoch: 2584 [33024/118836 (28%)] Loss: 12206.324219\n",
      "Train Epoch: 2584 [65792/118836 (55%)] Loss: 12184.525391\n",
      "Train Epoch: 2584 [98560/118836 (83%)] Loss: 12167.289062\n",
      "    epoch          : 2584\n",
      "    loss           : 12225.883217341294\n",
      "    val_loss       : 12225.909095037772\n",
      "    val_log_likelihood: -12135.2287850884\n",
      "    val_log_marginal: -12143.714087961616\n",
      "Train Epoch: 2585 [256/118836 (0%)] Loss: 12167.470703\n",
      "Train Epoch: 2585 [33024/118836 (28%)] Loss: 12269.201172\n",
      "Train Epoch: 2585 [65792/118836 (55%)] Loss: 12238.435547\n",
      "Train Epoch: 2585 [98560/118836 (83%)] Loss: 12190.125000\n",
      "    epoch          : 2585\n",
      "    loss           : 12225.33770726711\n",
      "    val_loss       : 12227.215347056734\n",
      "    val_log_likelihood: -12133.118681826407\n",
      "    val_log_marginal: -12141.71157759218\n",
      "Train Epoch: 2586 [256/118836 (0%)] Loss: 12333.267578\n",
      "Train Epoch: 2586 [33024/118836 (28%)] Loss: 12241.568359\n",
      "Train Epoch: 2586 [65792/118836 (55%)] Loss: 12149.578125\n",
      "Train Epoch: 2586 [98560/118836 (83%)] Loss: 12252.900391\n",
      "    epoch          : 2586\n",
      "    loss           : 12226.77925778019\n",
      "    val_loss       : 12227.08620677414\n",
      "    val_log_likelihood: -12135.15501463632\n",
      "    val_log_marginal: -12143.574868833812\n",
      "Train Epoch: 2587 [256/118836 (0%)] Loss: 12244.764648\n",
      "Train Epoch: 2587 [33024/118836 (28%)] Loss: 12306.257812\n",
      "Train Epoch: 2587 [65792/118836 (55%)] Loss: 12350.146484\n",
      "Train Epoch: 2587 [98560/118836 (83%)] Loss: 12282.078125\n",
      "    epoch          : 2587\n",
      "    loss           : 12222.982823000671\n",
      "    val_loss       : 12225.984639471602\n",
      "    val_log_likelihood: -12135.435621833643\n",
      "    val_log_marginal: -12143.862436134246\n",
      "Train Epoch: 2588 [256/118836 (0%)] Loss: 12340.449219\n",
      "Train Epoch: 2588 [33024/118836 (28%)] Loss: 12250.307617\n",
      "Train Epoch: 2588 [65792/118836 (55%)] Loss: 12214.546875\n",
      "Train Epoch: 2588 [98560/118836 (83%)] Loss: 12217.057617\n",
      "    epoch          : 2588\n",
      "    loss           : 12226.534654479427\n",
      "    val_loss       : 12229.427775645438\n",
      "    val_log_likelihood: -12138.59693574235\n",
      "    val_log_marginal: -12147.124771216724\n",
      "Train Epoch: 2589 [256/118836 (0%)] Loss: 12243.830078\n",
      "Train Epoch: 2589 [33024/118836 (28%)] Loss: 12156.519531\n",
      "Train Epoch: 2589 [65792/118836 (55%)] Loss: 12281.035156\n",
      "Train Epoch: 2589 [98560/118836 (83%)] Loss: 12281.972656\n",
      "    epoch          : 2589\n",
      "    loss           : 12226.74349265276\n",
      "    val_loss       : 12229.340350547973\n",
      "    val_log_likelihood: -12137.32662695797\n",
      "    val_log_marginal: -12145.789428934342\n",
      "Train Epoch: 2590 [256/118836 (0%)] Loss: 12249.486328\n",
      "Train Epoch: 2590 [33024/118836 (28%)] Loss: 12254.629883\n",
      "Train Epoch: 2590 [65792/118836 (55%)] Loss: 12335.507812\n",
      "Train Epoch: 2590 [98560/118836 (83%)] Loss: 12254.691406\n",
      "    epoch          : 2590\n",
      "    loss           : 12225.647863194014\n",
      "    val_loss       : 12232.192477813092\n",
      "    val_log_likelihood: -12136.504162627947\n",
      "    val_log_marginal: -12144.882629244883\n",
      "Train Epoch: 2591 [256/118836 (0%)] Loss: 12195.616211\n",
      "Train Epoch: 2591 [33024/118836 (28%)] Loss: 12186.499023\n",
      "Train Epoch: 2591 [65792/118836 (55%)] Loss: 12182.802734\n",
      "Train Epoch: 2591 [98560/118836 (83%)] Loss: 12333.098633\n",
      "    epoch          : 2591\n",
      "    loss           : 12228.9094087637\n",
      "    val_loss       : 12227.11759798312\n",
      "    val_log_likelihood: -12136.735511011166\n",
      "    val_log_marginal: -12145.348481238696\n",
      "Train Epoch: 2592 [256/118836 (0%)] Loss: 12160.625977\n",
      "Train Epoch: 2592 [33024/118836 (28%)] Loss: 12311.636719\n",
      "Train Epoch: 2592 [65792/118836 (55%)] Loss: 12216.389648\n",
      "Train Epoch: 2592 [98560/118836 (83%)] Loss: 12277.964844\n",
      "    epoch          : 2592\n",
      "    loss           : 12229.292499127636\n",
      "    val_loss       : 12225.210744491826\n",
      "    val_log_likelihood: -12135.14615319996\n",
      "    val_log_marginal: -12143.763101667288\n",
      "Train Epoch: 2593 [256/118836 (0%)] Loss: 12173.466797\n",
      "Train Epoch: 2593 [33024/118836 (28%)] Loss: 12140.413086\n",
      "Train Epoch: 2593 [65792/118836 (55%)] Loss: 12278.367188\n",
      "Train Epoch: 2593 [98560/118836 (83%)] Loss: 12300.087891\n",
      "    epoch          : 2593\n",
      "    loss           : 12228.1374261722\n",
      "    val_loss       : 12227.244773747674\n",
      "    val_log_likelihood: -12136.540597859803\n",
      "    val_log_marginal: -12145.092645001223\n",
      "Train Epoch: 2594 [256/118836 (0%)] Loss: 12352.498047\n",
      "Train Epoch: 2594 [33024/118836 (28%)] Loss: 12232.360352\n",
      "Train Epoch: 2594 [65792/118836 (55%)] Loss: 12287.654297\n",
      "Train Epoch: 2594 [98560/118836 (83%)] Loss: 12223.822266\n",
      "    epoch          : 2594\n",
      "    loss           : 12226.583537531018\n",
      "    val_loss       : 12224.190905772324\n",
      "    val_log_likelihood: -12133.787092250828\n",
      "    val_log_marginal: -12142.371280141993\n",
      "Train Epoch: 2595 [256/118836 (0%)] Loss: 12267.250977\n",
      "Train Epoch: 2595 [33024/118836 (28%)] Loss: 12187.869141\n",
      "Train Epoch: 2595 [65792/118836 (55%)] Loss: 12227.333984\n",
      "Train Epoch: 2595 [98560/118836 (83%)] Loss: 12237.536133\n",
      "    epoch          : 2595\n",
      "    loss           : 12223.633819918321\n",
      "    val_loss       : 12228.211372049005\n",
      "    val_log_likelihood: -12133.551643435949\n",
      "    val_log_marginal: -12141.980191964454\n",
      "Train Epoch: 2596 [256/118836 (0%)] Loss: 12193.801758\n",
      "Train Epoch: 2596 [33024/118836 (28%)] Loss: 12239.636719\n",
      "Train Epoch: 2596 [65792/118836 (55%)] Loss: 12288.875000\n",
      "Train Epoch: 2596 [98560/118836 (83%)] Loss: 12104.328125\n",
      "    epoch          : 2596\n",
      "    loss           : 12226.406252907878\n",
      "    val_loss       : 12228.786208248228\n",
      "    val_log_likelihood: -12138.543865184296\n",
      "    val_log_marginal: -12146.907191704602\n",
      "Train Epoch: 2597 [256/118836 (0%)] Loss: 12305.020508\n",
      "Train Epoch: 2597 [33024/118836 (28%)] Loss: 12238.569336\n",
      "Train Epoch: 2597 [65792/118836 (55%)] Loss: 12295.027344\n",
      "Train Epoch: 2597 [98560/118836 (83%)] Loss: 12314.423828\n",
      "    epoch          : 2597\n",
      "    loss           : 12226.667033059346\n",
      "    val_loss       : 12250.680556370358\n",
      "    val_log_likelihood: -12136.595524775124\n",
      "    val_log_marginal: -12145.130462163046\n",
      "Train Epoch: 2598 [256/118836 (0%)] Loss: 12269.254883\n",
      "Train Epoch: 2598 [33024/118836 (28%)] Loss: 12252.642578\n",
      "Train Epoch: 2598 [65792/118836 (55%)] Loss: 12261.660156\n",
      "Train Epoch: 2598 [98560/118836 (83%)] Loss: 12247.531250\n",
      "    epoch          : 2598\n",
      "    loss           : 12226.469716061827\n",
      "    val_loss       : 12228.571236211583\n",
      "    val_log_likelihood: -12133.635439929694\n",
      "    val_log_marginal: -12142.299927514137\n",
      "Train Epoch: 2599 [256/118836 (0%)] Loss: 12236.645508\n",
      "Train Epoch: 2599 [33024/118836 (28%)] Loss: 12262.407227\n",
      "Train Epoch: 2599 [65792/118836 (55%)] Loss: 12202.060547\n",
      "Train Epoch: 2599 [98560/118836 (83%)] Loss: 12225.970703\n",
      "    epoch          : 2599\n",
      "    loss           : 12225.273737334574\n",
      "    val_loss       : 12223.596865375212\n",
      "    val_log_likelihood: -12135.93506594422\n",
      "    val_log_marginal: -12144.406920340074\n",
      "Train Epoch: 2600 [256/118836 (0%)] Loss: 12246.483398\n",
      "Train Epoch: 2600 [33024/118836 (28%)] Loss: 12250.980469\n",
      "Train Epoch: 2600 [65792/118836 (55%)] Loss: 12257.247070\n",
      "Train Epoch: 2600 [98560/118836 (83%)] Loss: 12186.283203\n",
      "    epoch          : 2600\n",
      "    loss           : 12225.965531463244\n",
      "    val_loss       : 12226.282458040088\n",
      "    val_log_likelihood: -12137.544814929695\n",
      "    val_log_marginal: -12146.13559690526\n",
      "Saving checkpoint: saved/models/SelfiesAutoencodingOperad/0905_154251/checkpoint-epoch2600.pth ...\n",
      "Train Epoch: 2601 [256/118836 (0%)] Loss: 12320.510742\n",
      "Train Epoch: 2601 [33024/118836 (28%)] Loss: 12207.640625\n",
      "Train Epoch: 2601 [65792/118836 (55%)] Loss: 12255.693359\n",
      "Train Epoch: 2601 [98560/118836 (83%)] Loss: 12254.837891\n",
      "    epoch          : 2601\n",
      "    loss           : 12227.94144130609\n",
      "    val_loss       : 12229.027712944284\n",
      "    val_log_likelihood: -12134.665518862437\n",
      "    val_log_marginal: -12143.30468046232\n",
      "Train Epoch: 2602 [256/118836 (0%)] Loss: 12335.703125\n",
      "Train Epoch: 2602 [33024/118836 (28%)] Loss: 12359.605469\n",
      "Train Epoch: 2602 [65792/118836 (55%)] Loss: 12230.404297\n",
      "Train Epoch: 2602 [98560/118836 (83%)] Loss: 12206.935547\n",
      "    epoch          : 2602\n",
      "    loss           : 12228.469350638441\n",
      "    val_loss       : 12228.566271293832\n",
      "    val_log_likelihood: -12133.776077368952\n",
      "    val_log_marginal: -12142.374831552781\n",
      "Train Epoch: 2603 [256/118836 (0%)] Loss: 12322.285156\n",
      "Train Epoch: 2603 [33024/118836 (28%)] Loss: 12183.073242\n",
      "Train Epoch: 2603 [65792/118836 (55%)] Loss: 12304.878906\n",
      "Train Epoch: 2603 [98560/118836 (83%)] Loss: 12200.808594\n",
      "    epoch          : 2603\n",
      "    loss           : 12222.201758781792\n",
      "    val_loss       : 12228.335272953731\n",
      "    val_log_likelihood: -12134.826651674937\n",
      "    val_log_marginal: -12143.466649236114\n",
      "Train Epoch: 2604 [256/118836 (0%)] Loss: 12254.145508\n",
      "Train Epoch: 2604 [33024/118836 (28%)] Loss: 12245.341797\n",
      "Train Epoch: 2604 [65792/118836 (55%)] Loss: 12262.707031\n",
      "Train Epoch: 2604 [98560/118836 (83%)] Loss: 12284.492188\n",
      "    epoch          : 2604\n",
      "    loss           : 12227.995920085039\n",
      "    val_loss       : 12227.347654926132\n",
      "    val_log_likelihood: -12136.82647881772\n",
      "    val_log_marginal: -12145.580709096794\n",
      "Train Epoch: 2605 [256/118836 (0%)] Loss: 12182.546875\n",
      "Train Epoch: 2605 [33024/118836 (28%)] Loss: 12159.259766\n",
      "Train Epoch: 2605 [65792/118836 (55%)] Loss: 12305.251953\n",
      "Train Epoch: 2605 [98560/118836 (83%)] Loss: 12244.589844\n",
      "    epoch          : 2605\n",
      "    loss           : 12231.869544497002\n",
      "    val_loss       : 12230.148944585839\n",
      "    val_log_likelihood: -12133.675600315344\n",
      "    val_log_marginal: -12142.275403933556\n",
      "Train Epoch: 2606 [256/118836 (0%)] Loss: 12242.870117\n",
      "Train Epoch: 2606 [33024/118836 (28%)] Loss: 12263.869141\n",
      "Train Epoch: 2606 [65792/118836 (55%)] Loss: 12177.074219\n",
      "Train Epoch: 2606 [98560/118836 (83%)] Loss: 12212.202148\n",
      "    epoch          : 2606\n",
      "    loss           : 12225.119203467482\n",
      "    val_loss       : 12223.545644344425\n",
      "    val_log_likelihood: -12137.68147762226\n",
      "    val_log_marginal: -12146.258658776424\n",
      "Train Epoch: 2607 [256/118836 (0%)] Loss: 12235.497070\n",
      "Train Epoch: 2607 [33024/118836 (28%)] Loss: 12180.456055\n",
      "Train Epoch: 2607 [65792/118836 (55%)] Loss: 12260.474609\n",
      "Train Epoch: 2607 [98560/118836 (83%)] Loss: 12233.225586\n",
      "    epoch          : 2607\n",
      "    loss           : 12226.074076263956\n",
      "    val_loss       : 12231.44595781947\n",
      "    val_log_likelihood: -12138.511260759149\n",
      "    val_log_marginal: -12147.120714341883\n",
      "Train Epoch: 2608 [256/118836 (0%)] Loss: 12205.082031\n",
      "Train Epoch: 2608 [33024/118836 (28%)] Loss: 12259.013672\n",
      "Train Epoch: 2608 [65792/118836 (55%)] Loss: 12296.701172\n",
      "Train Epoch: 2608 [98560/118836 (83%)] Loss: 12241.697266\n",
      "    epoch          : 2608\n",
      "    loss           : 12228.714351510805\n",
      "    val_loss       : 12228.412690199884\n",
      "    val_log_likelihood: -12139.143804441945\n",
      "    val_log_marginal: -12147.725853069149\n",
      "Train Epoch: 2609 [256/118836 (0%)] Loss: 12363.344727\n",
      "Train Epoch: 2609 [33024/118836 (28%)] Loss: 12246.268555\n",
      "Train Epoch: 2609 [65792/118836 (55%)] Loss: 12241.219727\n",
      "Train Epoch: 2609 [98560/118836 (83%)] Loss: 12218.778320\n",
      "    epoch          : 2609\n",
      "    loss           : 12227.294997156741\n",
      "    val_loss       : 12224.851461044074\n",
      "    val_log_likelihood: -12135.979404466501\n",
      "    val_log_marginal: -12144.717090351065\n",
      "Train Epoch: 2610 [256/118836 (0%)] Loss: 12359.408203\n",
      "Train Epoch: 2610 [33024/118836 (28%)] Loss: 12264.920898\n",
      "Train Epoch: 2610 [65792/118836 (55%)] Loss: 12326.189453\n",
      "Train Epoch: 2610 [98560/118836 (83%)] Loss: 12220.007812\n",
      "    epoch          : 2610\n",
      "    loss           : 12224.545589233096\n",
      "    val_loss       : 12226.162376393087\n",
      "    val_log_likelihood: -12136.364091901882\n",
      "    val_log_marginal: -12144.979402532226\n",
      "Train Epoch: 2611 [256/118836 (0%)] Loss: 12184.267578\n",
      "Train Epoch: 2611 [33024/118836 (28%)] Loss: 12260.786133\n",
      "Train Epoch: 2611 [65792/118836 (55%)] Loss: 12203.050781\n",
      "Train Epoch: 2611 [98560/118836 (83%)] Loss: 12194.289062\n",
      "    epoch          : 2611\n",
      "    loss           : 12229.025425196443\n",
      "    val_loss       : 12226.615437899243\n",
      "    val_log_likelihood: -12136.969389087057\n",
      "    val_log_marginal: -12145.553199689246\n",
      "Train Epoch: 2612 [256/118836 (0%)] Loss: 12256.015625\n",
      "Train Epoch: 2612 [33024/118836 (28%)] Loss: 12250.354492\n",
      "Train Epoch: 2612 [65792/118836 (55%)] Loss: 12265.974609\n",
      "Train Epoch: 2612 [98560/118836 (83%)] Loss: 12244.406250\n",
      "    epoch          : 2612\n",
      "    loss           : 12226.859081627379\n",
      "    val_loss       : 12231.63052926891\n",
      "    val_log_likelihood: -12146.879371187448\n",
      "    val_log_marginal: -12155.536982841659\n",
      "Train Epoch: 2613 [256/118836 (0%)] Loss: 12263.914062\n",
      "Train Epoch: 2613 [33024/118836 (28%)] Loss: 12181.887695\n",
      "Train Epoch: 2613 [65792/118836 (55%)] Loss: 12193.209961\n",
      "Train Epoch: 2613 [98560/118836 (83%)] Loss: 12318.170898\n",
      "    epoch          : 2613\n",
      "    loss           : 12225.96307624457\n",
      "    val_loss       : 12228.148211605689\n",
      "    val_log_likelihood: -12133.311470934139\n",
      "    val_log_marginal: -12141.817776387417\n",
      "Train Epoch: 2614 [256/118836 (0%)] Loss: 12308.202148\n",
      "Train Epoch: 2614 [33024/118836 (28%)] Loss: 12207.618164\n",
      "Train Epoch: 2614 [65792/118836 (55%)] Loss: 12214.147461\n",
      "Train Epoch: 2614 [98560/118836 (83%)] Loss: 12299.445312\n",
      "    epoch          : 2614\n",
      "    loss           : 12225.056071327026\n",
      "    val_loss       : 12223.387817761886\n",
      "    val_log_likelihood: -12135.201462178195\n",
      "    val_log_marginal: -12143.661998594978\n",
      "Train Epoch: 2615 [256/118836 (0%)] Loss: 12281.671875\n",
      "Train Epoch: 2615 [33024/118836 (28%)] Loss: 12267.325195\n",
      "Train Epoch: 2615 [65792/118836 (55%)] Loss: 12189.522461\n",
      "Train Epoch: 2615 [98560/118836 (83%)] Loss: 12357.121094\n",
      "    epoch          : 2615\n",
      "    loss           : 12225.34832021557\n",
      "    val_loss       : 12226.652996947658\n",
      "    val_log_likelihood: -12133.154070868228\n",
      "    val_log_marginal: -12141.710638242392\n",
      "Train Epoch: 2616 [256/118836 (0%)] Loss: 12231.667969\n",
      "Train Epoch: 2616 [33024/118836 (28%)] Loss: 12274.837891\n",
      "Train Epoch: 2616 [65792/118836 (55%)] Loss: 12213.890625\n",
      "Train Epoch: 2616 [98560/118836 (83%)] Loss: 12274.619141\n",
      "    epoch          : 2616\n",
      "    loss           : 12223.780447910205\n",
      "    val_loss       : 12226.977524422964\n",
      "    val_log_likelihood: -12133.836736520369\n",
      "    val_log_marginal: -12142.278687879065\n",
      "Train Epoch: 2617 [256/118836 (0%)] Loss: 12270.148438\n",
      "Train Epoch: 2617 [33024/118836 (28%)] Loss: 12276.170898\n",
      "Train Epoch: 2617 [65792/118836 (55%)] Loss: 12231.699219\n",
      "Train Epoch: 2617 [98560/118836 (83%)] Loss: 12300.788086\n",
      "    epoch          : 2617\n",
      "    loss           : 12225.120109594705\n",
      "    val_loss       : 12226.075354807588\n",
      "    val_log_likelihood: -12136.656186026676\n",
      "    val_log_marginal: -12144.992117706079\n",
      "Train Epoch: 2618 [256/118836 (0%)] Loss: 12404.103516\n",
      "Train Epoch: 2618 [33024/118836 (28%)] Loss: 12279.279297\n",
      "Train Epoch: 2618 [65792/118836 (55%)] Loss: 12325.749023\n",
      "Train Epoch: 2618 [98560/118836 (83%)] Loss: 12210.819336\n",
      "    epoch          : 2618\n",
      "    loss           : 12226.14056296526\n",
      "    val_loss       : 12227.205950581812\n",
      "    val_log_likelihood: -12134.190445357734\n",
      "    val_log_marginal: -12142.7009029289\n",
      "Train Epoch: 2619 [256/118836 (0%)] Loss: 12153.312500\n",
      "Train Epoch: 2619 [33024/118836 (28%)] Loss: 12197.689453\n",
      "Train Epoch: 2619 [65792/118836 (55%)] Loss: 12186.685547\n",
      "Train Epoch: 2619 [98560/118836 (83%)] Loss: 12225.527344\n",
      "    epoch          : 2619\n",
      "    loss           : 12224.879422721515\n",
      "    val_loss       : 12220.021481301184\n",
      "    val_log_likelihood: -12137.380286199856\n",
      "    val_log_marginal: -12145.823777636813\n",
      "Train Epoch: 2620 [256/118836 (0%)] Loss: 12238.183594\n",
      "Train Epoch: 2620 [33024/118836 (28%)] Loss: 12268.358398\n",
      "Train Epoch: 2620 [65792/118836 (55%)] Loss: 12229.108398\n",
      "Train Epoch: 2620 [98560/118836 (83%)] Loss: 12212.572266\n",
      "    epoch          : 2620\n",
      "    loss           : 12225.9535695823\n",
      "    val_loss       : 12223.367065482262\n",
      "    val_log_likelihood: -12133.732317191376\n",
      "    val_log_marginal: -12142.194407868985\n",
      "Train Epoch: 2621 [256/118836 (0%)] Loss: 12468.475586\n",
      "Train Epoch: 2621 [33024/118836 (28%)] Loss: 12232.366211\n",
      "Train Epoch: 2621 [65792/118836 (55%)] Loss: 12166.798828\n",
      "Train Epoch: 2621 [98560/118836 (83%)] Loss: 12267.419922\n",
      "    epoch          : 2621\n",
      "    loss           : 12225.486185638956\n",
      "    val_loss       : 12230.266197662531\n",
      "    val_log_likelihood: -12132.47433183416\n",
      "    val_log_marginal: -12141.00738795953\n",
      "Train Epoch: 2622 [256/118836 (0%)] Loss: 12203.836914\n",
      "Train Epoch: 2622 [33024/118836 (28%)] Loss: 12203.352539\n",
      "Train Epoch: 2622 [65792/118836 (55%)] Loss: 12337.300781\n",
      "Train Epoch: 2622 [98560/118836 (83%)] Loss: 12361.683594\n",
      "    epoch          : 2622\n",
      "    loss           : 12224.251923723119\n",
      "    val_loss       : 12225.101643966413\n",
      "    val_log_likelihood: -12133.30363533266\n",
      "    val_log_marginal: -12141.677544648583\n",
      "Train Epoch: 2623 [256/118836 (0%)] Loss: 12418.323242\n",
      "Train Epoch: 2623 [33024/118836 (28%)] Loss: 12233.936523\n",
      "Train Epoch: 2623 [65792/118836 (55%)] Loss: 12185.479492\n",
      "Train Epoch: 2623 [98560/118836 (83%)] Loss: 12172.770508\n",
      "    epoch          : 2623\n",
      "    loss           : 12227.404763589486\n",
      "    val_loss       : 12219.95552908013\n",
      "    val_log_likelihood: -12132.589618389422\n",
      "    val_log_marginal: -12141.182921160533\n",
      "Train Epoch: 2624 [256/118836 (0%)] Loss: 12266.638672\n",
      "Train Epoch: 2624 [33024/118836 (28%)] Loss: 12333.460938\n",
      "Train Epoch: 2624 [65792/118836 (55%)] Loss: 12169.243164\n",
      "Train Epoch: 2624 [98560/118836 (83%)] Loss: 12245.558594\n",
      "    epoch          : 2624\n",
      "    loss           : 12227.985543967123\n",
      "    val_loss       : 12227.786285581064\n",
      "    val_log_likelihood: -12133.464043437241\n",
      "    val_log_marginal: -12141.96569860154\n",
      "Train Epoch: 2625 [256/118836 (0%)] Loss: 12187.168945\n",
      "Train Epoch: 2625 [33024/118836 (28%)] Loss: 12272.824219\n",
      "Train Epoch: 2625 [65792/118836 (55%)] Loss: 12191.514648\n",
      "Train Epoch: 2625 [98560/118836 (83%)] Loss: 12193.531250\n",
      "    epoch          : 2625\n",
      "    loss           : 12223.400830037737\n",
      "    val_loss       : 12225.07230075665\n",
      "    val_log_likelihood: -12133.125535534275\n",
      "    val_log_marginal: -12141.611754430198\n",
      "Train Epoch: 2626 [256/118836 (0%)] Loss: 12247.529297\n",
      "Train Epoch: 2626 [33024/118836 (28%)] Loss: 12237.688477\n",
      "Train Epoch: 2626 [65792/118836 (55%)] Loss: 12293.136719\n",
      "Train Epoch: 2626 [98560/118836 (83%)] Loss: 12235.041016\n",
      "    epoch          : 2626\n",
      "    loss           : 12220.377875084005\n",
      "    val_loss       : 12223.202589263596\n",
      "    val_log_likelihood: -12134.00912039909\n",
      "    val_log_marginal: -12142.44653001323\n",
      "Train Epoch: 2627 [256/118836 (0%)] Loss: 12320.807617\n",
      "Train Epoch: 2627 [33024/118836 (28%)] Loss: 12134.099609\n",
      "Train Epoch: 2627 [65792/118836 (55%)] Loss: 12272.578125\n",
      "Train Epoch: 2627 [98560/118836 (83%)] Loss: 12185.473633\n",
      "    epoch          : 2627\n",
      "    loss           : 12223.758329133065\n",
      "    val_loss       : 12224.03762462392\n",
      "    val_log_likelihood: -12134.244070835919\n",
      "    val_log_marginal: -12142.639212465698\n",
      "Train Epoch: 2628 [256/118836 (0%)] Loss: 12190.513672\n",
      "Train Epoch: 2628 [33024/118836 (28%)] Loss: 12301.229492\n",
      "Train Epoch: 2628 [65792/118836 (55%)] Loss: 12256.838867\n",
      "Train Epoch: 2628 [98560/118836 (83%)] Loss: 12180.451172\n",
      "    epoch          : 2628\n",
      "    loss           : 12226.606959522333\n",
      "    val_loss       : 12223.84195833233\n",
      "    val_log_likelihood: -12136.295146912478\n",
      "    val_log_marginal: -12144.753423897297\n",
      "Train Epoch: 2629 [256/118836 (0%)] Loss: 12251.119141\n",
      "Train Epoch: 2629 [33024/118836 (28%)] Loss: 12243.924805\n",
      "Train Epoch: 2629 [65792/118836 (55%)] Loss: 12262.464844\n",
      "Train Epoch: 2629 [98560/118836 (83%)] Loss: 12225.166016\n",
      "    epoch          : 2629\n",
      "    loss           : 12228.269684559811\n",
      "    val_loss       : 12224.95270137817\n",
      "    val_log_likelihood: -12130.625544742556\n",
      "    val_log_marginal: -12139.023705949749\n",
      "Train Epoch: 2630 [256/118836 (0%)] Loss: 12283.722656\n",
      "Train Epoch: 2630 [33024/118836 (28%)] Loss: 12196.693359\n",
      "Train Epoch: 2630 [65792/118836 (55%)] Loss: 12140.176758\n",
      "Train Epoch: 2630 [98560/118836 (83%)] Loss: 12231.689453\n",
      "    epoch          : 2630\n",
      "    loss           : 12222.732330599927\n",
      "    val_loss       : 12224.104945187042\n",
      "    val_log_likelihood: -12139.67208517499\n",
      "    val_log_marginal: -12148.234318210645\n",
      "Train Epoch: 2631 [256/118836 (0%)] Loss: 12210.841797\n",
      "Train Epoch: 2631 [33024/118836 (28%)] Loss: 12227.424805\n",
      "Train Epoch: 2631 [65792/118836 (55%)] Loss: 12188.542969\n",
      "Train Epoch: 2631 [98560/118836 (83%)] Loss: 12234.684570\n",
      "    epoch          : 2631\n",
      "    loss           : 12219.837577543423\n",
      "    val_loss       : 12225.938247053306\n",
      "    val_log_likelihood: -12133.87453134693\n",
      "    val_log_marginal: -12142.380010096764\n",
      "Train Epoch: 2632 [256/118836 (0%)] Loss: 12180.774414\n",
      "Train Epoch: 2632 [33024/118836 (28%)] Loss: 12333.029297\n",
      "Train Epoch: 2632 [65792/118836 (55%)] Loss: 12250.094727\n",
      "Train Epoch: 2632 [98560/118836 (83%)] Loss: 12261.846680\n",
      "    epoch          : 2632\n",
      "    loss           : 12225.515423387096\n",
      "    val_loss       : 12223.783854406618\n",
      "    val_log_likelihood: -12135.055340964898\n",
      "    val_log_marginal: -12143.47713921992\n",
      "Train Epoch: 2633 [256/118836 (0%)] Loss: 12290.265625\n",
      "Train Epoch: 2633 [33024/118836 (28%)] Loss: 12106.638672\n",
      "Train Epoch: 2633 [65792/118836 (55%)] Loss: 12320.329102\n",
      "Train Epoch: 2633 [98560/118836 (83%)] Loss: 12222.466797\n",
      "    epoch          : 2633\n",
      "    loss           : 12224.702813049265\n",
      "    val_loss       : 12223.12954732368\n",
      "    val_log_likelihood: -12137.056698297922\n",
      "    val_log_marginal: -12145.44444694353\n",
      "Train Epoch: 2634 [256/118836 (0%)] Loss: 12250.892578\n",
      "Train Epoch: 2634 [33024/118836 (28%)] Loss: 12201.250000\n",
      "Train Epoch: 2634 [65792/118836 (55%)] Loss: 12212.461914\n",
      "Train Epoch: 2634 [98560/118836 (83%)] Loss: 12414.642578\n",
      "    epoch          : 2634\n",
      "    loss           : 12226.077497382908\n",
      "    val_loss       : 12226.557050409674\n",
      "    val_log_likelihood: -12133.169100722445\n",
      "    val_log_marginal: -12141.622710228565\n",
      "Train Epoch: 2635 [256/118836 (0%)] Loss: 12231.478516\n",
      "Train Epoch: 2635 [33024/118836 (28%)] Loss: 12214.006836\n",
      "Train Epoch: 2635 [65792/118836 (55%)] Loss: 12261.934570\n",
      "Train Epoch: 2635 [98560/118836 (83%)] Loss: 12202.505859\n",
      "    epoch          : 2635\n",
      "    loss           : 12226.385926837778\n",
      "    val_loss       : 12221.60066904365\n",
      "    val_log_likelihood: -12132.663474623914\n",
      "    val_log_marginal: -12140.984454118194\n",
      "Train Epoch: 2636 [256/118836 (0%)] Loss: 12439.644531\n",
      "Train Epoch: 2636 [33024/118836 (28%)] Loss: 12261.619141\n",
      "Train Epoch: 2636 [65792/118836 (55%)] Loss: 12296.970703\n",
      "Train Epoch: 2636 [98560/118836 (83%)] Loss: 12440.486328\n",
      "    epoch          : 2636\n",
      "    loss           : 12227.159627177678\n",
      "    val_loss       : 12224.670839407665\n",
      "    val_log_likelihood: -12134.887232475186\n",
      "    val_log_marginal: -12143.32853411455\n",
      "Train Epoch: 2637 [256/118836 (0%)] Loss: 12258.007812\n",
      "Train Epoch: 2637 [33024/118836 (28%)] Loss: 12310.862305\n",
      "Train Epoch: 2637 [65792/118836 (55%)] Loss: 12144.750000\n",
      "Train Epoch: 2637 [98560/118836 (83%)] Loss: 12230.220703\n",
      "    epoch          : 2637\n",
      "    loss           : 12225.346576296268\n",
      "    val_loss       : 12221.583624090114\n",
      "    val_log_likelihood: -12133.155874237491\n",
      "    val_log_marginal: -12141.62437065\n",
      "Train Epoch: 2638 [256/118836 (0%)] Loss: 12276.627930\n",
      "Train Epoch: 2638 [33024/118836 (28%)] Loss: 12250.927734\n",
      "Train Epoch: 2638 [65792/118836 (55%)] Loss: 12192.613281\n",
      "Train Epoch: 2638 [98560/118836 (83%)] Loss: 12174.135742\n",
      "    epoch          : 2638\n",
      "    loss           : 12225.461197108923\n",
      "    val_loss       : 12225.07680054212\n",
      "    val_log_likelihood: -12138.814468310587\n",
      "    val_log_marginal: -12147.381576427651\n",
      "Train Epoch: 2639 [256/118836 (0%)] Loss: 12218.132812\n",
      "Train Epoch: 2639 [33024/118836 (28%)] Loss: 12277.779297\n",
      "Train Epoch: 2639 [65792/118836 (55%)] Loss: 12213.086914\n",
      "Train Epoch: 2639 [98560/118836 (83%)] Loss: 12211.067383\n",
      "    epoch          : 2639\n",
      "    loss           : 12225.720884867402\n",
      "    val_loss       : 12222.710163769247\n",
      "    val_log_likelihood: -12134.003854069737\n",
      "    val_log_marginal: -12142.468020736756\n",
      "Train Epoch: 2640 [256/118836 (0%)] Loss: 12303.580078\n",
      "Train Epoch: 2640 [33024/118836 (28%)] Loss: 12293.806641\n",
      "Train Epoch: 2640 [65792/118836 (55%)] Loss: 12257.783203\n",
      "Train Epoch: 2640 [98560/118836 (83%)] Loss: 12237.830078\n",
      "    epoch          : 2640\n",
      "    loss           : 12228.258714265405\n",
      "    val_loss       : 12229.344903832121\n",
      "    val_log_likelihood: -12137.954911568186\n",
      "    val_log_marginal: -12146.544871241018\n",
      "Train Epoch: 2641 [256/118836 (0%)] Loss: 12226.667969\n",
      "Train Epoch: 2641 [33024/118836 (28%)] Loss: 12197.423828\n",
      "Train Epoch: 2641 [65792/118836 (55%)] Loss: 12296.273438\n",
      "Train Epoch: 2641 [98560/118836 (83%)] Loss: 12152.907227\n",
      "    epoch          : 2641\n",
      "    loss           : 12225.143963405966\n",
      "    val_loss       : 12221.795409519911\n",
      "    val_log_likelihood: -12133.244964846981\n",
      "    val_log_marginal: -12141.6788867208\n",
      "Train Epoch: 2642 [256/118836 (0%)] Loss: 12341.745117\n",
      "Train Epoch: 2642 [33024/118836 (28%)] Loss: 12248.553711\n",
      "Train Epoch: 2642 [65792/118836 (55%)] Loss: 12225.250000\n",
      "Train Epoch: 2642 [98560/118836 (83%)] Loss: 12319.738281\n",
      "    epoch          : 2642\n",
      "    loss           : 12220.518760662222\n",
      "    val_loss       : 12219.94100594985\n",
      "    val_log_likelihood: -12130.432875342483\n",
      "    val_log_marginal: -12138.925848559898\n",
      "Train Epoch: 2643 [256/118836 (0%)] Loss: 12241.178711\n",
      "Train Epoch: 2643 [33024/118836 (28%)] Loss: 12220.773438\n",
      "Train Epoch: 2643 [65792/118836 (55%)] Loss: 12296.664062\n",
      "Train Epoch: 2643 [98560/118836 (83%)] Loss: 12194.611328\n",
      "    epoch          : 2643\n",
      "    loss           : 12227.420546584211\n",
      "    val_loss       : 12223.510433285164\n",
      "    val_log_likelihood: -12132.927487689982\n",
      "    val_log_marginal: -12141.303400392164\n",
      "Train Epoch: 2644 [256/118836 (0%)] Loss: 12193.066406\n",
      "Train Epoch: 2644 [33024/118836 (28%)] Loss: 12241.283203\n",
      "Train Epoch: 2644 [65792/118836 (55%)] Loss: 12219.162109\n",
      "Train Epoch: 2644 [98560/118836 (83%)] Loss: 12234.856445\n",
      "    epoch          : 2644\n",
      "    loss           : 12223.187612114867\n",
      "    val_loss       : 12226.085563897524\n",
      "    val_log_likelihood: -12133.391309805367\n",
      "    val_log_marginal: -12141.749330135213\n",
      "Train Epoch: 2645 [256/118836 (0%)] Loss: 12206.726562\n",
      "Train Epoch: 2645 [33024/118836 (28%)] Loss: 12165.923828\n",
      "Train Epoch: 2645 [65792/118836 (55%)] Loss: 12158.663086\n",
      "Train Epoch: 2645 [98560/118836 (83%)] Loss: 12290.648438\n",
      "    epoch          : 2645\n",
      "    loss           : 12220.162433603442\n",
      "    val_loss       : 12225.229287428067\n",
      "    val_log_likelihood: -12134.288431975032\n",
      "    val_log_marginal: -12142.776226949545\n",
      "Train Epoch: 2646 [256/118836 (0%)] Loss: 12197.176758\n",
      "Train Epoch: 2646 [33024/118836 (28%)] Loss: 12227.412109\n",
      "Train Epoch: 2646 [65792/118836 (55%)] Loss: 12180.013672\n",
      "Train Epoch: 2646 [98560/118836 (83%)] Loss: 12332.900391\n",
      "    epoch          : 2646\n",
      "    loss           : 12228.887688689\n",
      "    val_loss       : 12222.904888125331\n",
      "    val_log_likelihood: -12134.851979295905\n",
      "    val_log_marginal: -12143.301099779359\n",
      "Train Epoch: 2647 [256/118836 (0%)] Loss: 12380.427734\n",
      "Train Epoch: 2647 [33024/118836 (28%)] Loss: 12285.023438\n",
      "Train Epoch: 2647 [65792/118836 (55%)] Loss: 12277.884766\n",
      "Train Epoch: 2647 [98560/118836 (83%)] Loss: 12177.802734\n",
      "    epoch          : 2647\n",
      "    loss           : 12226.35813979787\n",
      "    val_loss       : 12229.149148372679\n",
      "    val_log_likelihood: -12137.094305243227\n",
      "    val_log_marginal: -12145.543291987417\n",
      "Train Epoch: 2648 [256/118836 (0%)] Loss: 12259.985352\n",
      "Train Epoch: 2648 [33024/118836 (28%)] Loss: 12243.876953\n",
      "Train Epoch: 2648 [65792/118836 (55%)] Loss: 12186.723633\n",
      "Train Epoch: 2648 [98560/118836 (83%)] Loss: 12374.469727\n",
      "    epoch          : 2648\n",
      "    loss           : 12226.381760655759\n",
      "    val_loss       : 12224.702946218764\n",
      "    val_log_likelihood: -12136.215760216346\n",
      "    val_log_marginal: -12144.588959042872\n",
      "Train Epoch: 2649 [256/118836 (0%)] Loss: 12228.642578\n",
      "Train Epoch: 2649 [33024/118836 (28%)] Loss: 12339.814453\n",
      "Train Epoch: 2649 [65792/118836 (55%)] Loss: 12280.021484\n",
      "Train Epoch: 2649 [98560/118836 (83%)] Loss: 12163.354492\n",
      "    epoch          : 2649\n",
      "    loss           : 12223.139327924679\n",
      "    val_loss       : 12225.120051153735\n",
      "    val_log_likelihood: -12135.310800668167\n",
      "    val_log_marginal: -12143.767784970214\n",
      "Train Epoch: 2650 [256/118836 (0%)] Loss: 12252.490234\n",
      "Train Epoch: 2650 [33024/118836 (28%)] Loss: 12245.816406\n",
      "Train Epoch: 2650 [65792/118836 (55%)] Loss: 12182.128906\n",
      "Train Epoch: 2650 [98560/118836 (83%)] Loss: 12290.927734\n",
      "    epoch          : 2650\n",
      "    loss           : 12224.026260242195\n",
      "    val_loss       : 12230.32415973645\n",
      "    val_log_likelihood: -12132.752532923647\n",
      "    val_log_marginal: -12141.166190713775\n",
      "Train Epoch: 2651 [256/118836 (0%)] Loss: 12293.764648\n",
      "Train Epoch: 2651 [33024/118836 (28%)] Loss: 12232.483398\n",
      "Train Epoch: 2651 [65792/118836 (55%)] Loss: 12224.167969\n",
      "Train Epoch: 2651 [98560/118836 (83%)] Loss: 12212.652344\n",
      "    epoch          : 2651\n",
      "    loss           : 12223.865803026778\n",
      "    val_loss       : 12224.989294880917\n",
      "    val_log_likelihood: -12133.03897639449\n",
      "    val_log_marginal: -12141.420456455318\n",
      "Train Epoch: 2652 [256/118836 (0%)] Loss: 12221.522461\n",
      "Train Epoch: 2652 [33024/118836 (28%)] Loss: 12307.860352\n",
      "Train Epoch: 2652 [65792/118836 (55%)] Loss: 12314.615234\n",
      "Train Epoch: 2652 [98560/118836 (83%)] Loss: 12332.721680\n",
      "    epoch          : 2652\n",
      "    loss           : 12231.786271744468\n",
      "    val_loss       : 12226.10507633245\n",
      "    val_log_likelihood: -12139.213292396867\n",
      "    val_log_marginal: -12148.101747531759\n",
      "Train Epoch: 2653 [256/118836 (0%)] Loss: 12212.233398\n",
      "Train Epoch: 2653 [33024/118836 (28%)] Loss: 12250.011719\n",
      "Train Epoch: 2653 [65792/118836 (55%)] Loss: 12334.783203\n",
      "Train Epoch: 2653 [98560/118836 (83%)] Loss: 12286.316406\n",
      "    epoch          : 2653\n",
      "    loss           : 12230.365178317566\n",
      "    val_loss       : 12225.201091674431\n",
      "    val_log_likelihood: -12142.845079708177\n",
      "    val_log_marginal: -12151.949668836249\n",
      "Train Epoch: 2654 [256/118836 (0%)] Loss: 12147.144531\n",
      "Train Epoch: 2654 [33024/118836 (28%)] Loss: 12287.722656\n",
      "Train Epoch: 2654 [65792/118836 (55%)] Loss: 12211.825195\n",
      "Train Epoch: 2654 [98560/118836 (83%)] Loss: 12247.875000\n",
      "    epoch          : 2654\n",
      "    loss           : 12223.998789353289\n",
      "    val_loss       : 12221.768173056453\n",
      "    val_log_likelihood: -12134.178494785205\n",
      "    val_log_marginal: -12142.867171636075\n",
      "Train Epoch: 2655 [256/118836 (0%)] Loss: 12232.523438\n",
      "Train Epoch: 2655 [33024/118836 (28%)] Loss: 12207.158203\n",
      "Train Epoch: 2655 [65792/118836 (55%)] Loss: 12192.648438\n",
      "Train Epoch: 2655 [98560/118836 (83%)] Loss: 12254.957031\n",
      "    epoch          : 2655\n",
      "    loss           : 12222.75253663927\n",
      "    val_loss       : 12230.316226363911\n",
      "    val_log_likelihood: -12134.864200624224\n",
      "    val_log_marginal: -12143.657692555651\n",
      "Train Epoch: 2656 [256/118836 (0%)] Loss: 12277.506836\n",
      "Train Epoch: 2656 [33024/118836 (28%)] Loss: 12215.017578\n",
      "Train Epoch: 2656 [65792/118836 (55%)] Loss: 12193.676758\n",
      "Train Epoch: 2656 [98560/118836 (83%)] Loss: 12375.935547\n",
      "    epoch          : 2656\n",
      "    loss           : 12227.696818781018\n",
      "    val_loss       : 12223.883049052023\n",
      "    val_log_likelihood: -12135.773385642835\n",
      "    val_log_marginal: -12144.337519012175\n",
      "Train Epoch: 2657 [256/118836 (0%)] Loss: 12283.046875\n",
      "Train Epoch: 2657 [33024/118836 (28%)] Loss: 12205.170898\n",
      "Train Epoch: 2657 [65792/118836 (55%)] Loss: 12197.842773\n",
      "Train Epoch: 2657 [98560/118836 (83%)] Loss: 12305.533203\n",
      "    epoch          : 2657\n",
      "    loss           : 12224.048585963348\n",
      "    val_loss       : 12222.187989433869\n",
      "    val_log_likelihood: -12134.028333074855\n",
      "    val_log_marginal: -12142.587719913538\n",
      "Train Epoch: 2658 [256/118836 (0%)] Loss: 12307.280273\n",
      "Train Epoch: 2658 [33024/118836 (28%)] Loss: 12274.412109\n",
      "Train Epoch: 2658 [65792/118836 (55%)] Loss: 12314.191406\n",
      "Train Epoch: 2658 [98560/118836 (83%)] Loss: 12346.306641\n",
      "    epoch          : 2658\n",
      "    loss           : 12227.530291854064\n",
      "    val_loss       : 12224.594333751766\n",
      "    val_log_likelihood: -12134.796085187912\n",
      "    val_log_marginal: -12143.326018211552\n",
      "Train Epoch: 2659 [256/118836 (0%)] Loss: 12283.278320\n",
      "Train Epoch: 2659 [33024/118836 (28%)] Loss: 12228.330078\n",
      "Train Epoch: 2659 [65792/118836 (55%)] Loss: 12196.378906\n",
      "Train Epoch: 2659 [98560/118836 (83%)] Loss: 12201.667969\n",
      "    epoch          : 2659\n",
      "    loss           : 12225.789368958074\n",
      "    val_loss       : 12226.58989606406\n",
      "    val_log_likelihood: -12138.384583074856\n",
      "    val_log_marginal: -12146.893594782025\n",
      "Train Epoch: 2660 [256/118836 (0%)] Loss: 12266.427734\n",
      "Train Epoch: 2660 [33024/118836 (28%)] Loss: 12293.022461\n",
      "Train Epoch: 2660 [65792/118836 (55%)] Loss: 12314.419922\n",
      "Train Epoch: 2660 [98560/118836 (83%)] Loss: 12323.431641\n",
      "    epoch          : 2660\n",
      "    loss           : 12229.509702620968\n",
      "    val_loss       : 12226.283602106585\n",
      "    val_log_likelihood: -12138.97717800093\n",
      "    val_log_marginal: -12147.46765592209\n",
      "Train Epoch: 2661 [256/118836 (0%)] Loss: 12413.127930\n",
      "Train Epoch: 2661 [33024/118836 (28%)] Loss: 12201.247070\n",
      "Train Epoch: 2661 [65792/118836 (55%)] Loss: 12231.291992\n",
      "Train Epoch: 2661 [98560/118836 (83%)] Loss: 12198.750000\n",
      "    epoch          : 2661\n",
      "    loss           : 12225.161088709678\n",
      "    val_loss       : 12228.93633194198\n",
      "    val_log_likelihood: -12140.698242672146\n",
      "    val_log_marginal: -12149.210069948047\n",
      "Train Epoch: 2662 [256/118836 (0%)] Loss: 12190.506836\n",
      "Train Epoch: 2662 [33024/118836 (28%)] Loss: 12253.597656\n",
      "Train Epoch: 2662 [65792/118836 (55%)] Loss: 12277.527344\n",
      "Train Epoch: 2662 [98560/118836 (83%)] Loss: 12181.902344\n",
      "    epoch          : 2662\n",
      "    loss           : 12227.637308887768\n",
      "    val_loss       : 12225.42098794092\n",
      "    val_log_likelihood: -12134.55494613963\n",
      "    val_log_marginal: -12142.96871168192\n",
      "Train Epoch: 2663 [256/118836 (0%)] Loss: 12254.132812\n",
      "Train Epoch: 2663 [33024/118836 (28%)] Loss: 12215.386719\n",
      "Train Epoch: 2663 [65792/118836 (55%)] Loss: 12227.708984\n",
      "Train Epoch: 2663 [98560/118836 (83%)] Loss: 12199.364258\n",
      "    epoch          : 2663\n",
      "    loss           : 12224.237605329818\n",
      "    val_loss       : 12223.499913495363\n",
      "    val_log_likelihood: -12133.55634159817\n",
      "    val_log_marginal: -12141.976708791484\n",
      "Train Epoch: 2664 [256/118836 (0%)] Loss: 12240.104492\n",
      "Train Epoch: 2664 [33024/118836 (28%)] Loss: 12261.994141\n",
      "Train Epoch: 2664 [65792/118836 (55%)] Loss: 12298.189453\n",
      "Train Epoch: 2664 [98560/118836 (83%)] Loss: 12137.907227\n",
      "    epoch          : 2664\n",
      "    loss           : 12221.695868227875\n",
      "    val_loss       : 12223.540760177913\n",
      "    val_log_likelihood: -12136.358819433673\n",
      "    val_log_marginal: -12144.886391563368\n",
      "Train Epoch: 2665 [256/118836 (0%)] Loss: 12288.102539\n",
      "Train Epoch: 2665 [33024/118836 (28%)] Loss: 12249.845703\n",
      "Train Epoch: 2665 [65792/118836 (55%)] Loss: 12223.755859\n",
      "Train Epoch: 2665 [98560/118836 (83%)] Loss: 12254.528320\n",
      "    epoch          : 2665\n",
      "    loss           : 12222.95179561492\n",
      "    val_loss       : 12225.239888480768\n",
      "    val_log_likelihood: -12133.266012717122\n",
      "    val_log_marginal: -12141.791530006974\n",
      "Train Epoch: 2666 [256/118836 (0%)] Loss: 12213.075195\n",
      "Train Epoch: 2666 [33024/118836 (28%)] Loss: 12262.789062\n",
      "Train Epoch: 2666 [65792/118836 (55%)] Loss: 12188.235352\n",
      "Train Epoch: 2666 [98560/118836 (83%)] Loss: 12287.468750\n",
      "    epoch          : 2666\n",
      "    loss           : 12226.209331220274\n",
      "    val_loss       : 12225.925228903474\n",
      "    val_log_likelihood: -12133.299407600547\n",
      "    val_log_marginal: -12141.69857727197\n",
      "Train Epoch: 2667 [256/118836 (0%)] Loss: 12288.205078\n",
      "Train Epoch: 2667 [33024/118836 (28%)] Loss: 12216.465820\n",
      "Train Epoch: 2667 [65792/118836 (55%)] Loss: 12236.738281\n",
      "Train Epoch: 2667 [98560/118836 (83%)] Loss: 12317.471680\n",
      "    epoch          : 2667\n",
      "    loss           : 12227.001544568082\n",
      "    val_loss       : 12223.04635844433\n",
      "    val_log_likelihood: -12138.027526623244\n",
      "    val_log_marginal: -12146.343223618034\n",
      "Train Epoch: 2668 [256/118836 (0%)] Loss: 12264.486328\n",
      "Train Epoch: 2668 [33024/118836 (28%)] Loss: 12186.316406\n",
      "Train Epoch: 2668 [65792/118836 (55%)] Loss: 12293.763672\n",
      "Train Epoch: 2668 [98560/118836 (83%)] Loss: 12280.891602\n",
      "    epoch          : 2668\n",
      "    loss           : 12227.11847649788\n",
      "    val_loss       : 12228.185929816344\n",
      "    val_log_likelihood: -12143.459558519437\n",
      "    val_log_marginal: -12152.025296769756\n",
      "Train Epoch: 2669 [256/118836 (0%)] Loss: 12245.621094\n",
      "Train Epoch: 2669 [33024/118836 (28%)] Loss: 12289.095703\n",
      "Train Epoch: 2669 [65792/118836 (55%)] Loss: 12426.689453\n",
      "Train Epoch: 2669 [98560/118836 (83%)] Loss: 12275.408203\n",
      "    epoch          : 2669\n",
      "    loss           : 12225.33665267654\n",
      "    val_loss       : 12224.997216402664\n",
      "    val_log_likelihood: -12135.007561291613\n",
      "    val_log_marginal: -12143.609835381416\n",
      "Train Epoch: 2670 [256/118836 (0%)] Loss: 12281.558594\n",
      "Train Epoch: 2670 [33024/118836 (28%)] Loss: 12229.923828\n",
      "Train Epoch: 2670 [65792/118836 (55%)] Loss: 12162.703125\n",
      "Train Epoch: 2670 [98560/118836 (83%)] Loss: 12223.339844\n",
      "    epoch          : 2670\n",
      "    loss           : 12221.234038493849\n",
      "    val_loss       : 12223.138962701496\n",
      "    val_log_likelihood: -12133.450373339278\n",
      "    val_log_marginal: -12141.928609778475\n",
      "Train Epoch: 2671 [256/118836 (0%)] Loss: 12262.655273\n",
      "Train Epoch: 2671 [33024/118836 (28%)] Loss: 12270.993164\n",
      "Train Epoch: 2671 [65792/118836 (55%)] Loss: 12385.910156\n",
      "Train Epoch: 2671 [98560/118836 (83%)] Loss: 12242.131836\n",
      "    epoch          : 2671\n",
      "    loss           : 12225.450402418064\n",
      "    val_loss       : 12222.650231619275\n",
      "    val_log_likelihood: -12131.08945296345\n",
      "    val_log_marginal: -12139.641306908223\n",
      "Train Epoch: 2672 [256/118836 (0%)] Loss: 12247.351562\n",
      "Train Epoch: 2672 [33024/118836 (28%)] Loss: 12270.869141\n",
      "Train Epoch: 2672 [65792/118836 (55%)] Loss: 12127.452148\n",
      "Train Epoch: 2672 [98560/118836 (83%)] Loss: 12317.558594\n",
      "    epoch          : 2672\n",
      "    loss           : 12224.09539585918\n",
      "    val_loss       : 12240.82909569037\n",
      "    val_log_likelihood: -12149.929868919302\n",
      "    val_log_marginal: -12158.48311117087\n",
      "Train Epoch: 2673 [256/118836 (0%)] Loss: 12199.664062\n",
      "Train Epoch: 2673 [33024/118836 (28%)] Loss: 12251.351562\n",
      "Train Epoch: 2673 [65792/118836 (55%)] Loss: 12275.704102\n",
      "Train Epoch: 2673 [98560/118836 (83%)] Loss: 12257.412109\n",
      "    epoch          : 2673\n",
      "    loss           : 12231.921386476426\n",
      "    val_loss       : 12228.489120474136\n",
      "    val_log_likelihood: -12134.267235479994\n",
      "    val_log_marginal: -12143.019403033217\n",
      "Train Epoch: 2674 [256/118836 (0%)] Loss: 12397.273438\n",
      "Train Epoch: 2674 [33024/118836 (28%)] Loss: 12290.732422\n",
      "Train Epoch: 2674 [65792/118836 (55%)] Loss: 12199.324219\n",
      "Train Epoch: 2674 [98560/118836 (83%)] Loss: 12265.674805\n",
      "    epoch          : 2674\n",
      "    loss           : 12227.531378431297\n",
      "    val_loss       : 12219.153800470172\n",
      "    val_log_likelihood: -12130.892681839328\n",
      "    val_log_marginal: -12139.463806804111\n",
      "Train Epoch: 2675 [256/118836 (0%)] Loss: 12218.471680\n",
      "Train Epoch: 2675 [33024/118836 (28%)] Loss: 12320.097656\n",
      "Train Epoch: 2675 [65792/118836 (55%)] Loss: 12237.251953\n",
      "Train Epoch: 2675 [98560/118836 (83%)] Loss: 12231.537109\n",
      "    epoch          : 2675\n",
      "    loss           : 12221.880022229114\n",
      "    val_loss       : 12229.928464802259\n",
      "    val_log_likelihood: -12136.06814241496\n",
      "    val_log_marginal: -12144.651996159702\n",
      "Train Epoch: 2676 [256/118836 (0%)] Loss: 12254.103516\n",
      "Train Epoch: 2676 [33024/118836 (28%)] Loss: 12202.926758\n",
      "Train Epoch: 2676 [65792/118836 (55%)] Loss: 12256.504883\n",
      "Train Epoch: 2676 [98560/118836 (83%)] Loss: 12262.206055\n",
      "    epoch          : 2676\n",
      "    loss           : 12231.620801508221\n",
      "    val_loss       : 12227.789902590092\n",
      "    val_log_likelihood: -12133.718738691585\n",
      "    val_log_marginal: -12142.257903795291\n",
      "Train Epoch: 2677 [256/118836 (0%)] Loss: 12242.308594\n",
      "Train Epoch: 2677 [33024/118836 (28%)] Loss: 12246.079102\n",
      "Train Epoch: 2677 [65792/118836 (55%)] Loss: 12154.914062\n",
      "Train Epoch: 2677 [98560/118836 (83%)] Loss: 12175.453125\n",
      "    epoch          : 2677\n",
      "    loss           : 12223.628479114972\n",
      "    val_loss       : 12222.626752200602\n",
      "    val_log_likelihood: -12133.118676333746\n",
      "    val_log_marginal: -12141.601066630927\n",
      "Train Epoch: 2678 [256/118836 (0%)] Loss: 12273.962891\n",
      "Train Epoch: 2678 [33024/118836 (28%)] Loss: 12269.443359\n",
      "Train Epoch: 2678 [65792/118836 (55%)] Loss: 12404.998047\n",
      "Train Epoch: 2678 [98560/118836 (83%)] Loss: 12203.208008\n",
      "    epoch          : 2678\n",
      "    loss           : 12225.398309876447\n",
      "    val_loss       : 12223.051662132857\n",
      "    val_log_likelihood: -12132.997841061828\n",
      "    val_log_marginal: -12141.450047555238\n",
      "Train Epoch: 2679 [256/118836 (0%)] Loss: 12200.375000\n",
      "Train Epoch: 2679 [33024/118836 (28%)] Loss: 12334.351562\n",
      "Train Epoch: 2679 [65792/118836 (55%)] Loss: 12242.803711\n",
      "Train Epoch: 2679 [98560/118836 (83%)] Loss: 12215.790039\n",
      "    epoch          : 2679\n",
      "    loss           : 12223.956644340622\n",
      "    val_loss       : 12224.15246734266\n",
      "    val_log_likelihood: -12138.337192572633\n",
      "    val_log_marginal: -12146.76969630243\n",
      "Train Epoch: 2680 [256/118836 (0%)] Loss: 12237.549805\n",
      "Train Epoch: 2680 [33024/118836 (28%)] Loss: 12241.208984\n",
      "Train Epoch: 2680 [65792/118836 (55%)] Loss: 12183.992188\n",
      "Train Epoch: 2680 [98560/118836 (83%)] Loss: 12356.270508\n",
      "    epoch          : 2680\n",
      "    loss           : 12226.483018636269\n",
      "    val_loss       : 12221.350631492378\n",
      "    val_log_likelihood: -12135.072966423697\n",
      "    val_log_marginal: -12143.487712089847\n",
      "Train Epoch: 2681 [256/118836 (0%)] Loss: 12340.908203\n",
      "Train Epoch: 2681 [33024/118836 (28%)] Loss: 12230.568359\n",
      "Train Epoch: 2681 [65792/118836 (55%)] Loss: 12225.676758\n",
      "Train Epoch: 2681 [98560/118836 (83%)] Loss: 12249.289062\n",
      "    epoch          : 2681\n",
      "    loss           : 12228.146847859802\n",
      "    val_loss       : 12226.148472682398\n",
      "    val_log_likelihood: -12149.187769948046\n",
      "    val_log_marginal: -12157.92643766162\n",
      "Train Epoch: 2682 [256/118836 (0%)] Loss: 12193.577148\n",
      "Train Epoch: 2682 [33024/118836 (28%)] Loss: 12325.037109\n",
      "Train Epoch: 2682 [65792/118836 (55%)] Loss: 12183.087891\n",
      "Train Epoch: 2682 [98560/118836 (83%)] Loss: 12170.484375\n",
      "    epoch          : 2682\n",
      "    loss           : 12227.484397778382\n",
      "    val_loss       : 12223.41970559002\n",
      "    val_log_likelihood: -12134.43369067928\n",
      "    val_log_marginal: -12142.838056181547\n",
      "Train Epoch: 2683 [256/118836 (0%)] Loss: 12313.026367\n",
      "Train Epoch: 2683 [33024/118836 (28%)] Loss: 12316.965820\n",
      "Train Epoch: 2683 [65792/118836 (55%)] Loss: 12414.976562\n",
      "Train Epoch: 2683 [98560/118836 (83%)] Loss: 12208.751953\n",
      "    epoch          : 2683\n",
      "    loss           : 12222.96118806219\n",
      "    val_loss       : 12223.667103670114\n",
      "    val_log_likelihood: -12133.687705328526\n",
      "    val_log_marginal: -12142.14621103803\n",
      "Train Epoch: 2684 [256/118836 (0%)] Loss: 12157.375977\n",
      "Train Epoch: 2684 [33024/118836 (28%)] Loss: 12229.489258\n",
      "Train Epoch: 2684 [65792/118836 (55%)] Loss: 12291.684570\n",
      "Train Epoch: 2684 [98560/118836 (83%)] Loss: 12244.923828\n",
      "    epoch          : 2684\n",
      "    loss           : 12221.811299207764\n",
      "    val_loss       : 12219.996720224884\n",
      "    val_log_likelihood: -12132.042479418682\n",
      "    val_log_marginal: -12140.433633292598\n",
      "Train Epoch: 2685 [256/118836 (0%)] Loss: 12191.958984\n",
      "Train Epoch: 2685 [33024/118836 (28%)] Loss: 12209.849609\n",
      "Train Epoch: 2685 [65792/118836 (55%)] Loss: 12195.947266\n",
      "Train Epoch: 2685 [98560/118836 (83%)] Loss: 12267.304688\n",
      "    epoch          : 2685\n",
      "    loss           : 12221.83322477254\n",
      "    val_loss       : 12222.615848509806\n",
      "    val_log_likelihood: -12130.631686181761\n",
      "    val_log_marginal: -12139.031979150235\n",
      "Train Epoch: 2686 [256/118836 (0%)] Loss: 12295.363281\n",
      "Train Epoch: 2686 [33024/118836 (28%)] Loss: 12425.382812\n",
      "Train Epoch: 2686 [65792/118836 (55%)] Loss: 12223.404297\n",
      "Train Epoch: 2686 [98560/118836 (83%)] Loss: 12199.218750\n",
      "    epoch          : 2686\n",
      "    loss           : 12224.417860027657\n",
      "    val_loss       : 12221.965686765121\n",
      "    val_log_likelihood: -12131.911303892679\n",
      "    val_log_marginal: -12140.32285424901\n",
      "Train Epoch: 2687 [256/118836 (0%)] Loss: 12280.281250\n",
      "Train Epoch: 2687 [33024/118836 (28%)] Loss: 12363.162109\n",
      "Train Epoch: 2687 [65792/118836 (55%)] Loss: 12377.042969\n",
      "Train Epoch: 2687 [98560/118836 (83%)] Loss: 12202.531250\n",
      "    epoch          : 2687\n",
      "    loss           : 12225.299293708644\n",
      "    val_loss       : 12222.95639292756\n",
      "    val_log_likelihood: -12134.166038080282\n",
      "    val_log_marginal: -12142.457316427846\n",
      "Train Epoch: 2688 [256/118836 (0%)] Loss: 12172.714844\n",
      "Train Epoch: 2688 [33024/118836 (28%)] Loss: 12301.098633\n",
      "Train Epoch: 2688 [65792/118836 (55%)] Loss: 12265.376953\n",
      "Train Epoch: 2688 [98560/118836 (83%)] Loss: 12243.576172\n",
      "    epoch          : 2688\n",
      "    loss           : 12228.738508064516\n",
      "    val_loss       : 12227.16326595266\n",
      "    val_log_likelihood: -12130.322326690448\n",
      "    val_log_marginal: -12138.704563520365\n",
      "Train Epoch: 2689 [256/118836 (0%)] Loss: 12370.823242\n",
      "Train Epoch: 2689 [33024/118836 (28%)] Loss: 12307.407227\n",
      "Train Epoch: 2689 [65792/118836 (55%)] Loss: 12275.984375\n",
      "Train Epoch: 2689 [98560/118836 (83%)] Loss: 12327.511719\n",
      "    epoch          : 2689\n",
      "    loss           : 12221.461060277088\n",
      "    val_loss       : 12221.714458742294\n",
      "    val_log_likelihood: -12131.097547366107\n",
      "    val_log_marginal: -12139.397729294198\n",
      "Train Epoch: 2690 [256/118836 (0%)] Loss: 12315.816406\n",
      "Train Epoch: 2690 [33024/118836 (28%)] Loss: 12199.738281\n",
      "Train Epoch: 2690 [65792/118836 (55%)] Loss: 12147.051758\n",
      "Train Epoch: 2690 [98560/118836 (83%)] Loss: 12252.048828\n",
      "    epoch          : 2690\n",
      "    loss           : 12220.885021356751\n",
      "    val_loss       : 12218.357666296155\n",
      "    val_log_likelihood: -12135.241902366366\n",
      "    val_log_marginal: -12143.63278229957\n",
      "Train Epoch: 2691 [256/118836 (0%)] Loss: 12323.208984\n",
      "Train Epoch: 2691 [33024/118836 (28%)] Loss: 12187.500000\n",
      "Train Epoch: 2691 [65792/118836 (55%)] Loss: 12219.339844\n",
      "Train Epoch: 2691 [98560/118836 (83%)] Loss: 12289.388672\n",
      "    epoch          : 2691\n",
      "    loss           : 12229.804403174112\n",
      "    val_loss       : 12222.181640128692\n",
      "    val_log_likelihood: -12132.544327213865\n",
      "    val_log_marginal: -12140.839455262347\n",
      "Train Epoch: 2692 [256/118836 (0%)] Loss: 12298.568359\n",
      "Train Epoch: 2692 [33024/118836 (28%)] Loss: 12283.895508\n",
      "Train Epoch: 2692 [65792/118836 (55%)] Loss: 12253.297852\n",
      "Train Epoch: 2692 [98560/118836 (83%)] Loss: 12333.029297\n",
      "    epoch          : 2692\n",
      "    loss           : 12228.981181826406\n",
      "    val_loss       : 12223.202688000723\n",
      "    val_log_likelihood: -12134.483948995812\n",
      "    val_log_marginal: -12142.88425859573\n",
      "Train Epoch: 2693 [256/118836 (0%)] Loss: 12317.017578\n",
      "Train Epoch: 2693 [33024/118836 (28%)] Loss: 12293.539062\n",
      "Train Epoch: 2693 [65792/118836 (55%)] Loss: 12147.317383\n",
      "Train Epoch: 2693 [98560/118836 (83%)] Loss: 12385.717773\n",
      "    epoch          : 2693\n",
      "    loss           : 12224.872444944167\n",
      "    val_loss       : 12230.200954639788\n",
      "    val_log_likelihood: -12133.404169089898\n",
      "    val_log_marginal: -12141.805215697077\n",
      "Train Epoch: 2694 [256/118836 (0%)] Loss: 12215.257812\n",
      "Train Epoch: 2694 [33024/118836 (28%)] Loss: 12219.315430\n",
      "Train Epoch: 2694 [65792/118836 (55%)] Loss: 12248.375000\n",
      "Train Epoch: 2694 [98560/118836 (83%)] Loss: 12283.563477\n",
      "    epoch          : 2694\n",
      "    loss           : 12220.864020335763\n",
      "    val_loss       : 12222.28213104938\n",
      "    val_log_likelihood: -12132.071001990282\n",
      "    val_log_marginal: -12140.509075022139\n",
      "Train Epoch: 2695 [256/118836 (0%)] Loss: 12287.864258\n",
      "Train Epoch: 2695 [33024/118836 (28%)] Loss: 12313.887695\n",
      "Train Epoch: 2695 [65792/118836 (55%)] Loss: 12370.699219\n",
      "Train Epoch: 2695 [98560/118836 (83%)] Loss: 12262.603516\n",
      "    epoch          : 2695\n",
      "    loss           : 12227.658198116987\n",
      "    val_loss       : 12224.244222803392\n",
      "    val_log_likelihood: -12132.38695008788\n",
      "    val_log_marginal: -12140.895135505421\n",
      "Train Epoch: 2696 [256/118836 (0%)] Loss: 12119.833008\n",
      "Train Epoch: 2696 [33024/118836 (28%)] Loss: 12282.597656\n",
      "Train Epoch: 2696 [65792/118836 (55%)] Loss: 12267.273438\n",
      "Train Epoch: 2696 [98560/118836 (83%)] Loss: 12163.290039\n",
      "    epoch          : 2696\n",
      "    loss           : 12224.692250988679\n",
      "    val_loss       : 12224.70097508541\n",
      "    val_log_likelihood: -12133.032890366523\n",
      "    val_log_marginal: -12141.4783605734\n",
      "Train Epoch: 2697 [256/118836 (0%)] Loss: 12284.294922\n",
      "Train Epoch: 2697 [33024/118836 (28%)] Loss: 12226.026367\n",
      "Train Epoch: 2697 [65792/118836 (55%)] Loss: 12208.012695\n",
      "Train Epoch: 2697 [98560/118836 (83%)] Loss: 12220.035156\n",
      "    epoch          : 2697\n",
      "    loss           : 12226.122850593207\n",
      "    val_loss       : 12224.67507146485\n",
      "    val_log_likelihood: -12134.301875581576\n",
      "    val_log_marginal: -12142.825437518219\n",
      "Train Epoch: 2698 [256/118836 (0%)] Loss: 12282.340820\n",
      "Train Epoch: 2698 [33024/118836 (28%)] Loss: 12223.552734\n",
      "Train Epoch: 2698 [65792/118836 (55%)] Loss: 12160.327148\n",
      "Train Epoch: 2698 [98560/118836 (83%)] Loss: 12346.447266\n",
      "    epoch          : 2698\n",
      "    loss           : 12224.923374819065\n",
      "    val_loss       : 12223.559456400224\n",
      "    val_log_likelihood: -12135.33446126706\n",
      "    val_log_marginal: -12143.872701587843\n",
      "Train Epoch: 2699 [256/118836 (0%)] Loss: 12178.533203\n",
      "Train Epoch: 2699 [33024/118836 (28%)] Loss: 12299.803711\n",
      "Train Epoch: 2699 [65792/118836 (55%)] Loss: 12216.070312\n",
      "Train Epoch: 2699 [98560/118836 (83%)] Loss: 12207.908203\n",
      "    epoch          : 2699\n",
      "    loss           : 12222.25928469422\n",
      "    val_loss       : 12226.349167836053\n",
      "    val_log_likelihood: -12133.811055107526\n",
      "    val_log_marginal: -12142.260413272998\n",
      "Train Epoch: 2700 [256/118836 (0%)] Loss: 12207.023438\n",
      "Train Epoch: 2700 [33024/118836 (28%)] Loss: 12159.708984\n",
      "Train Epoch: 2700 [65792/118836 (55%)] Loss: 12286.444336\n",
      "Train Epoch: 2700 [98560/118836 (83%)] Loss: 12232.685547\n",
      "    epoch          : 2700\n",
      "    loss           : 12229.876319853702\n",
      "    val_loss       : 12248.80910769603\n",
      "    val_log_likelihood: -12150.08499599359\n",
      "    val_log_marginal: -12158.784561022117\n",
      "Saving checkpoint: saved/models/SelfiesAutoencodingOperad/0905_154251/checkpoint-epoch2700.pth ...\n",
      "Train Epoch: 2701 [256/118836 (0%)] Loss: 12333.042969\n",
      "Train Epoch: 2701 [33024/118836 (28%)] Loss: 12226.363281\n",
      "Train Epoch: 2701 [65792/118836 (55%)] Loss: 12299.319336\n",
      "Train Epoch: 2701 [98560/118836 (83%)] Loss: 12266.558594\n",
      "    epoch          : 2701\n",
      "    loss           : 12229.805315763286\n",
      "    val_loss       : 12225.041867877588\n",
      "    val_log_likelihood: -12133.462497899865\n",
      "    val_log_marginal: -12142.077982165987\n",
      "Train Epoch: 2702 [256/118836 (0%)] Loss: 12226.501953\n",
      "Train Epoch: 2702 [33024/118836 (28%)] Loss: 12296.383789\n",
      "Train Epoch: 2702 [65792/118836 (55%)] Loss: 12151.459961\n",
      "Train Epoch: 2702 [98560/118836 (83%)] Loss: 12187.503906\n",
      "    epoch          : 2702\n",
      "    loss           : 12230.576181891025\n",
      "    val_loss       : 12222.451240585198\n",
      "    val_log_likelihood: -12131.277896893092\n",
      "    val_log_marginal: -12139.710682196242\n",
      "Train Epoch: 2703 [256/118836 (0%)] Loss: 12220.755859\n",
      "Train Epoch: 2703 [33024/118836 (28%)] Loss: 12210.527344\n",
      "Train Epoch: 2703 [65792/118836 (55%)] Loss: 12151.611328\n",
      "Train Epoch: 2703 [98560/118836 (83%)] Loss: 12241.033203\n",
      "    epoch          : 2703\n",
      "    loss           : 12229.046377752791\n",
      "    val_loss       : 12222.385367012945\n",
      "    val_log_likelihood: -12133.888611132652\n",
      "    val_log_marginal: -12142.411237840357\n",
      "Train Epoch: 2704 [256/118836 (0%)] Loss: 12221.083984\n",
      "Train Epoch: 2704 [33024/118836 (28%)] Loss: 12187.160156\n",
      "Train Epoch: 2704 [65792/118836 (55%)] Loss: 12219.933594\n",
      "Train Epoch: 2704 [98560/118836 (83%)] Loss: 12232.818359\n",
      "    epoch          : 2704\n",
      "    loss           : 12224.273911968827\n",
      "    val_loss       : 12228.70164876483\n",
      "    val_log_likelihood: -12141.126668314464\n",
      "    val_log_marginal: -12149.633547427198\n",
      "Train Epoch: 2705 [256/118836 (0%)] Loss: 12335.667969\n",
      "Train Epoch: 2705 [33024/118836 (28%)] Loss: 12237.439453\n",
      "Train Epoch: 2705 [65792/118836 (55%)] Loss: 12324.977539\n",
      "Train Epoch: 2705 [98560/118836 (83%)] Loss: 12204.412109\n",
      "    epoch          : 2705\n",
      "    loss           : 12220.498963179798\n",
      "    val_loss       : 12223.931099585163\n",
      "    val_log_likelihood: -12133.42984646402\n",
      "    val_log_marginal: -12142.005495439013\n",
      "Train Epoch: 2706 [256/118836 (0%)] Loss: 12248.088867\n",
      "Train Epoch: 2706 [33024/118836 (28%)] Loss: 12261.856445\n",
      "Train Epoch: 2706 [65792/118836 (55%)] Loss: 12301.474609\n",
      "Train Epoch: 2706 [98560/118836 (83%)] Loss: 12169.560547\n",
      "    epoch          : 2706\n",
      "    loss           : 12221.15158802471\n",
      "    val_loss       : 12225.721766329094\n",
      "    val_log_likelihood: -12133.242195254343\n",
      "    val_log_marginal: -12141.672710121811\n",
      "Train Epoch: 2707 [256/118836 (0%)] Loss: 12153.552734\n",
      "Train Epoch: 2707 [33024/118836 (28%)] Loss: 12203.495117\n",
      "Train Epoch: 2707 [65792/118836 (55%)] Loss: 12179.271484\n",
      "Train Epoch: 2707 [98560/118836 (83%)] Loss: 12175.168945\n",
      "    epoch          : 2707\n",
      "    loss           : 12228.573260119418\n",
      "    val_loss       : 12225.326913831588\n",
      "    val_log_likelihood: -12132.65721283085\n",
      "    val_log_marginal: -12141.214020256295\n",
      "Train Epoch: 2708 [256/118836 (0%)] Loss: 12276.840820\n",
      "Train Epoch: 2708 [33024/118836 (28%)] Loss: 12355.265625\n",
      "Train Epoch: 2708 [65792/118836 (55%)] Loss: 12276.722656\n",
      "Train Epoch: 2708 [98560/118836 (83%)] Loss: 12354.507812\n",
      "    epoch          : 2708\n",
      "    loss           : 12223.961494520265\n",
      "    val_loss       : 12224.323740534703\n",
      "    val_log_likelihood: -12135.463333430263\n",
      "    val_log_marginal: -12143.79978795256\n",
      "Train Epoch: 2709 [256/118836 (0%)] Loss: 12233.241211\n",
      "Train Epoch: 2709 [33024/118836 (28%)] Loss: 12132.043945\n",
      "Train Epoch: 2709 [65792/118836 (55%)] Loss: 12197.187500\n",
      "Train Epoch: 2709 [98560/118836 (83%)] Loss: 12283.622070\n",
      "    epoch          : 2709\n",
      "    loss           : 12224.48732358871\n",
      "    val_loss       : 12217.888140728657\n",
      "    val_log_likelihood: -12134.259886301954\n",
      "    val_log_marginal: -12142.995025592403\n",
      "Train Epoch: 2710 [256/118836 (0%)] Loss: 12219.831055\n",
      "Train Epoch: 2710 [33024/118836 (28%)] Loss: 12207.331055\n",
      "Train Epoch: 2710 [65792/118836 (55%)] Loss: 12325.665039\n",
      "Train Epoch: 2710 [98560/118836 (83%)] Loss: 12203.279297\n",
      "    epoch          : 2710\n",
      "    loss           : 12227.209198911807\n",
      "    val_loss       : 12224.242076722847\n",
      "    val_log_likelihood: -12129.821923626188\n",
      "    val_log_marginal: -12138.266982917929\n",
      "Train Epoch: 2711 [256/118836 (0%)] Loss: 12163.066406\n",
      "Train Epoch: 2711 [33024/118836 (28%)] Loss: 12261.630859\n",
      "Train Epoch: 2711 [65792/118836 (55%)] Loss: 12278.748047\n",
      "Train Epoch: 2711 [98560/118836 (83%)] Loss: 12211.916992\n",
      "    epoch          : 2711\n",
      "    loss           : 12229.261821656586\n",
      "    val_loss       : 12221.818995737854\n",
      "    val_log_likelihood: -12133.81623533137\n",
      "    val_log_marginal: -12142.324824111944\n",
      "Train Epoch: 2712 [256/118836 (0%)] Loss: 12207.173828\n",
      "Train Epoch: 2712 [33024/118836 (28%)] Loss: 12222.339844\n",
      "Train Epoch: 2712 [65792/118836 (55%)] Loss: 12316.098633\n",
      "Train Epoch: 2712 [98560/118836 (83%)] Loss: 12265.722656\n",
      "    epoch          : 2712\n",
      "    loss           : 12223.978519825268\n",
      "    val_loss       : 12225.832709133452\n",
      "    val_log_likelihood: -12136.623375142164\n",
      "    val_log_marginal: -12145.065381434952\n",
      "Train Epoch: 2713 [256/118836 (0%)] Loss: 12156.817383\n",
      "Train Epoch: 2713 [33024/118836 (28%)] Loss: 12226.800781\n",
      "Train Epoch: 2713 [65792/118836 (55%)] Loss: 12189.914062\n",
      "Train Epoch: 2713 [98560/118836 (83%)] Loss: 12282.317383\n",
      "    epoch          : 2713\n",
      "    loss           : 12225.579698646869\n",
      "    val_loss       : 12225.989021261432\n",
      "    val_log_likelihood: -12133.7203595107\n",
      "    val_log_marginal: -12142.162023573208\n",
      "Train Epoch: 2714 [256/118836 (0%)] Loss: 12194.537109\n",
      "Train Epoch: 2714 [33024/118836 (28%)] Loss: 12112.255859\n",
      "Train Epoch: 2714 [65792/118836 (55%)] Loss: 12286.126953\n",
      "Train Epoch: 2714 [98560/118836 (83%)] Loss: 12257.428711\n",
      "    epoch          : 2714\n",
      "    loss           : 12221.709080819634\n",
      "    val_loss       : 12223.257558516398\n",
      "    val_log_likelihood: -12138.179909144956\n",
      "    val_log_marginal: -12146.650646048183\n",
      "Train Epoch: 2715 [256/118836 (0%)] Loss: 12272.869141\n",
      "Train Epoch: 2715 [33024/118836 (28%)] Loss: 12241.322266\n",
      "Train Epoch: 2715 [65792/118836 (55%)] Loss: 12209.705078\n",
      "Train Epoch: 2715 [98560/118836 (83%)] Loss: 12254.210938\n",
      "    epoch          : 2715\n",
      "    loss           : 12221.584776933416\n",
      "    val_loss       : 12225.743577724608\n",
      "    val_log_likelihood: -12130.80747453991\n",
      "    val_log_marginal: -12139.242379979862\n",
      "Train Epoch: 2716 [256/118836 (0%)] Loss: 12204.580078\n",
      "Train Epoch: 2716 [33024/118836 (28%)] Loss: 12229.672852\n",
      "Train Epoch: 2716 [65792/118836 (55%)] Loss: 12207.439453\n",
      "Train Epoch: 2716 [98560/118836 (83%)] Loss: 12279.771484\n",
      "    epoch          : 2716\n",
      "    loss           : 12222.001061860268\n",
      "    val_loss       : 12219.621901503246\n",
      "    val_log_likelihood: -12135.963719370347\n",
      "    val_log_marginal: -12144.340815122334\n",
      "Train Epoch: 2717 [256/118836 (0%)] Loss: 12132.898438\n",
      "Train Epoch: 2717 [33024/118836 (28%)] Loss: 12221.583008\n",
      "Train Epoch: 2717 [65792/118836 (55%)] Loss: 12209.921875\n",
      "Train Epoch: 2717 [98560/118836 (83%)] Loss: 12182.187500\n",
      "    epoch          : 2717\n",
      "    loss           : 12226.855959535256\n",
      "    val_loss       : 12229.501575222295\n",
      "    val_log_likelihood: -12133.03708498113\n",
      "    val_log_marginal: -12141.359434739197\n",
      "Train Epoch: 2718 [256/118836 (0%)] Loss: 12232.441406\n",
      "Train Epoch: 2718 [33024/118836 (28%)] Loss: 12268.069336\n",
      "Train Epoch: 2718 [65792/118836 (55%)] Loss: 12229.336914\n",
      "Train Epoch: 2718 [98560/118836 (83%)] Loss: 12232.359375\n",
      "    epoch          : 2718\n",
      "    loss           : 12223.333979528536\n",
      "    val_loss       : 12225.190793702815\n",
      "    val_log_likelihood: -12131.71864757806\n",
      "    val_log_marginal: -12140.162022039854\n",
      "Train Epoch: 2719 [256/118836 (0%)] Loss: 12213.008789\n",
      "Train Epoch: 2719 [33024/118836 (28%)] Loss: 12278.730469\n",
      "Train Epoch: 2719 [65792/118836 (55%)] Loss: 12222.997070\n",
      "Train Epoch: 2719 [98560/118836 (83%)] Loss: 12188.960938\n",
      "    epoch          : 2719\n",
      "    loss           : 12222.236103733716\n",
      "    val_loss       : 12226.760303988636\n",
      "    val_log_likelihood: -12133.93391846309\n",
      "    val_log_marginal: -12142.277881334225\n",
      "Train Epoch: 2720 [256/118836 (0%)] Loss: 12170.419922\n",
      "Train Epoch: 2720 [33024/118836 (28%)] Loss: 12248.535156\n",
      "Train Epoch: 2720 [65792/118836 (55%)] Loss: 12180.756836\n",
      "Train Epoch: 2720 [98560/118836 (83%)] Loss: 12181.230469\n",
      "    epoch          : 2720\n",
      "    loss           : 12221.880453079766\n",
      "    val_loss       : 12225.219262925108\n",
      "    val_log_likelihood: -12131.434817482164\n",
      "    val_log_marginal: -12139.819018755978\n",
      "Train Epoch: 2721 [256/118836 (0%)] Loss: 12257.550781\n",
      "Train Epoch: 2721 [33024/118836 (28%)] Loss: 12300.753906\n",
      "Train Epoch: 2721 [65792/118836 (55%)] Loss: 12312.598633\n",
      "Train Epoch: 2721 [98560/118836 (83%)] Loss: 12368.671875\n",
      "    epoch          : 2721\n",
      "    loss           : 12222.189413383996\n",
      "    val_loss       : 12218.616840297085\n",
      "    val_log_likelihood: -12132.884973538306\n",
      "    val_log_marginal: -12141.253881244542\n",
      "Train Epoch: 2722 [256/118836 (0%)] Loss: 12295.743164\n",
      "Train Epoch: 2722 [33024/118836 (28%)] Loss: 12206.689453\n",
      "Train Epoch: 2722 [65792/118836 (55%)] Loss: 12273.809570\n",
      "Train Epoch: 2722 [98560/118836 (83%)] Loss: 12322.073242\n",
      "    epoch          : 2722\n",
      "    loss           : 12227.086537976891\n",
      "    val_loss       : 12222.206403233347\n",
      "    val_log_likelihood: -12133.516430805417\n",
      "    val_log_marginal: -12141.80558061767\n",
      "Train Epoch: 2723 [256/118836 (0%)] Loss: 12212.177734\n",
      "Train Epoch: 2723 [33024/118836 (28%)] Loss: 12230.374023\n",
      "Train Epoch: 2723 [65792/118836 (55%)] Loss: 12204.087891\n",
      "Train Epoch: 2723 [98560/118836 (83%)] Loss: 12289.357422\n",
      "    epoch          : 2723\n",
      "    loss           : 12224.50330124974\n",
      "    val_loss       : 12223.138875638619\n",
      "    val_log_likelihood: -12135.109429926591\n",
      "    val_log_marginal: -12143.453227927737\n",
      "Train Epoch: 2724 [256/118836 (0%)] Loss: 12246.268555\n",
      "Train Epoch: 2724 [33024/118836 (28%)] Loss: 12282.213867\n",
      "Train Epoch: 2724 [65792/118836 (55%)] Loss: 12244.834961\n",
      "Train Epoch: 2724 [98560/118836 (83%)] Loss: 12215.979492\n",
      "    epoch          : 2724\n",
      "    loss           : 12223.233801017112\n",
      "    val_loss       : 12223.094795463188\n",
      "    val_log_likelihood: -12134.207414928402\n",
      "    val_log_marginal: -12142.559280156876\n",
      "Train Epoch: 2725 [256/118836 (0%)] Loss: 12177.850586\n",
      "Train Epoch: 2725 [33024/118836 (28%)] Loss: 12230.808594\n",
      "Train Epoch: 2725 [65792/118836 (55%)] Loss: 12263.427734\n",
      "Train Epoch: 2725 [98560/118836 (83%)] Loss: 12245.942383\n",
      "    epoch          : 2725\n",
      "    loss           : 12223.405928194788\n",
      "    val_loss       : 12223.84899136908\n",
      "    val_log_likelihood: -12136.221200210659\n",
      "    val_log_marginal: -12144.657141103566\n",
      "Train Epoch: 2726 [256/118836 (0%)] Loss: 12196.656250\n",
      "Train Epoch: 2726 [33024/118836 (28%)] Loss: 12293.541016\n",
      "Train Epoch: 2726 [65792/118836 (55%)] Loss: 12178.796875\n",
      "Train Epoch: 2726 [98560/118836 (83%)] Loss: 12176.295898\n",
      "    epoch          : 2726\n",
      "    loss           : 12225.564783169199\n",
      "    val_loss       : 12228.235857536873\n",
      "    val_log_likelihood: -12132.505777469758\n",
      "    val_log_marginal: -12140.93790699644\n",
      "Train Epoch: 2727 [256/118836 (0%)] Loss: 12171.852539\n",
      "Train Epoch: 2727 [33024/118836 (28%)] Loss: 12268.347656\n",
      "Train Epoch: 2727 [65792/118836 (55%)] Loss: 12304.836914\n",
      "Train Epoch: 2727 [98560/118836 (83%)] Loss: 12231.739258\n",
      "    epoch          : 2727\n",
      "    loss           : 12228.12405865514\n",
      "    val_loss       : 12224.788374684069\n",
      "    val_log_likelihood: -12131.000160902606\n",
      "    val_log_marginal: -12139.43297006348\n",
      "Train Epoch: 2728 [256/118836 (0%)] Loss: 12221.398438\n",
      "Train Epoch: 2728 [33024/118836 (28%)] Loss: 12186.710938\n",
      "Train Epoch: 2728 [65792/118836 (55%)] Loss: 12295.498047\n",
      "Train Epoch: 2728 [98560/118836 (83%)] Loss: 12202.684570\n",
      "    epoch          : 2728\n",
      "    loss           : 12222.06640899633\n",
      "    val_loss       : 12226.075173775587\n",
      "    val_log_likelihood: -12134.97168227228\n",
      "    val_log_marginal: -12143.478778168428\n",
      "Train Epoch: 2729 [256/118836 (0%)] Loss: 12218.824219\n",
      "Train Epoch: 2729 [33024/118836 (28%)] Loss: 12161.609375\n",
      "Train Epoch: 2729 [65792/118836 (55%)] Loss: 12242.696289\n",
      "Train Epoch: 2729 [98560/118836 (83%)] Loss: 12273.979492\n",
      "    epoch          : 2729\n",
      "    loss           : 12224.262111636684\n",
      "    val_loss       : 12224.14612216619\n",
      "    val_log_likelihood: -12133.534915865384\n",
      "    val_log_marginal: -12141.913080207943\n",
      "Train Epoch: 2730 [256/118836 (0%)] Loss: 12259.299805\n",
      "Train Epoch: 2730 [33024/118836 (28%)] Loss: 12294.509766\n",
      "Train Epoch: 2730 [65792/118836 (55%)] Loss: 12364.722656\n",
      "Train Epoch: 2730 [98560/118836 (83%)] Loss: 12412.289062\n",
      "    epoch          : 2730\n",
      "    loss           : 12224.540902540839\n",
      "    val_loss       : 12221.32881142063\n",
      "    val_log_likelihood: -12137.140475405811\n",
      "    val_log_marginal: -12145.757425560649\n",
      "Train Epoch: 2731 [256/118836 (0%)] Loss: 12354.007812\n",
      "Train Epoch: 2731 [33024/118836 (28%)] Loss: 12303.793945\n",
      "Train Epoch: 2731 [65792/118836 (55%)] Loss: 12292.681641\n",
      "Train Epoch: 2731 [98560/118836 (83%)] Loss: 12178.820312\n",
      "    epoch          : 2731\n",
      "    loss           : 12225.181447412635\n",
      "    val_loss       : 12221.197447170607\n",
      "    val_log_likelihood: -12132.380329010288\n",
      "    val_log_marginal: -12140.842193247388\n",
      "Train Epoch: 2732 [256/118836 (0%)] Loss: 12291.496094\n",
      "Train Epoch: 2732 [33024/118836 (28%)] Loss: 12196.825195\n",
      "Train Epoch: 2732 [65792/118836 (55%)] Loss: 12244.843750\n",
      "Train Epoch: 2732 [98560/118836 (83%)] Loss: 12221.141602\n",
      "    epoch          : 2732\n",
      "    loss           : 12226.030623029104\n",
      "    val_loss       : 12224.67365365361\n",
      "    val_log_likelihood: -12136.418173755428\n",
      "    val_log_marginal: -12144.938097458673\n",
      "Train Epoch: 2733 [256/118836 (0%)] Loss: 12218.171875\n",
      "Train Epoch: 2733 [33024/118836 (28%)] Loss: 12219.466797\n",
      "Train Epoch: 2733 [65792/118836 (55%)] Loss: 12202.377930\n",
      "Train Epoch: 2733 [98560/118836 (83%)] Loss: 12173.783203\n",
      "    epoch          : 2733\n",
      "    loss           : 12220.715347459161\n",
      "    val_loss       : 12225.962163015452\n",
      "    val_log_likelihood: -12132.468126906277\n",
      "    val_log_marginal: -12140.911373036997\n",
      "Train Epoch: 2734 [256/118836 (0%)] Loss: 12273.467773\n",
      "Train Epoch: 2734 [33024/118836 (28%)] Loss: 12178.327148\n",
      "Train Epoch: 2734 [65792/118836 (55%)] Loss: 12376.729492\n",
      "Train Epoch: 2734 [98560/118836 (83%)] Loss: 12234.606445\n",
      "    epoch          : 2734\n",
      "    loss           : 12225.248000025847\n",
      "    val_loss       : 12226.04599331321\n",
      "    val_log_likelihood: -12137.402302393508\n",
      "    val_log_marginal: -12145.722829050359\n",
      "Train Epoch: 2735 [256/118836 (0%)] Loss: 12292.585938\n",
      "Train Epoch: 2735 [33024/118836 (28%)] Loss: 12328.761719\n",
      "Train Epoch: 2735 [65792/118836 (55%)] Loss: 12275.027344\n",
      "Train Epoch: 2735 [98560/118836 (83%)] Loss: 12252.038086\n",
      "    epoch          : 2735\n",
      "    loss           : 12226.3457435122\n",
      "    val_loss       : 12224.721616395984\n",
      "    val_log_likelihood: -12134.70720362257\n",
      "    val_log_marginal: -12143.143207604446\n",
      "Train Epoch: 2736 [256/118836 (0%)] Loss: 12345.869141\n",
      "Train Epoch: 2736 [33024/118836 (28%)] Loss: 12384.142578\n",
      "Train Epoch: 2736 [65792/118836 (55%)] Loss: 12118.526367\n",
      "Train Epoch: 2736 [98560/118836 (83%)] Loss: 12260.380859\n",
      "    epoch          : 2736\n",
      "    loss           : 12224.439498035566\n",
      "    val_loss       : 12222.814607863991\n",
      "    val_log_likelihood: -12130.688772843001\n",
      "    val_log_marginal: -12139.133756099083\n",
      "Train Epoch: 2737 [256/118836 (0%)] Loss: 12290.127930\n",
      "Train Epoch: 2737 [33024/118836 (28%)] Loss: 12191.476562\n",
      "Train Epoch: 2737 [65792/118836 (55%)] Loss: 12306.880859\n",
      "Train Epoch: 2737 [98560/118836 (83%)] Loss: 12181.327148\n",
      "    epoch          : 2737\n",
      "    loss           : 12227.16688314206\n",
      "    val_loss       : 12221.254446288922\n",
      "    val_log_likelihood: -12133.64107087469\n",
      "    val_log_marginal: -12141.918384919038\n",
      "Train Epoch: 2738 [256/118836 (0%)] Loss: 12231.708984\n",
      "Train Epoch: 2738 [33024/118836 (28%)] Loss: 12164.551758\n",
      "Train Epoch: 2738 [65792/118836 (55%)] Loss: 12256.924805\n",
      "Train Epoch: 2738 [98560/118836 (83%)] Loss: 12348.310547\n",
      "    epoch          : 2738\n",
      "    loss           : 12224.157692953888\n",
      "    val_loss       : 12225.854693509318\n",
      "    val_log_likelihood: -12134.580854690084\n",
      "    val_log_marginal: -12142.931663183092\n",
      "Train Epoch: 2739 [256/118836 (0%)] Loss: 12223.601562\n",
      "Train Epoch: 2739 [33024/118836 (28%)] Loss: 12160.542969\n",
      "Train Epoch: 2739 [65792/118836 (55%)] Loss: 12254.772461\n",
      "Train Epoch: 2739 [98560/118836 (83%)] Loss: 12244.964844\n",
      "    epoch          : 2739\n",
      "    loss           : 12225.839749728599\n",
      "    val_loss       : 12224.065456319258\n",
      "    val_log_likelihood: -12131.410222485008\n",
      "    val_log_marginal: -12139.800222914011\n",
      "Train Epoch: 2740 [256/118836 (0%)] Loss: 12248.416016\n",
      "Train Epoch: 2740 [33024/118836 (28%)] Loss: 12196.384766\n",
      "Train Epoch: 2740 [65792/118836 (55%)] Loss: 12204.314453\n",
      "Train Epoch: 2740 [98560/118836 (83%)] Loss: 12080.335938\n",
      "    epoch          : 2740\n",
      "    loss           : 12222.094990048594\n",
      "    val_loss       : 12218.844592852716\n",
      "    val_log_likelihood: -12135.720325908549\n",
      "    val_log_marginal: -12144.021406296344\n",
      "Train Epoch: 2741 [256/118836 (0%)] Loss: 12230.285156\n",
      "Train Epoch: 2741 [33024/118836 (28%)] Loss: 12245.562500\n",
      "Train Epoch: 2741 [65792/118836 (55%)] Loss: 12219.095703\n",
      "Train Epoch: 2741 [98560/118836 (83%)] Loss: 12306.654297\n",
      "    epoch          : 2741\n",
      "    loss           : 12217.320550622931\n",
      "    val_loss       : 12226.780098471445\n",
      "    val_log_likelihood: -12130.379487341035\n",
      "    val_log_marginal: -12138.984858564036\n",
      "Train Epoch: 2742 [256/118836 (0%)] Loss: 12174.191406\n",
      "Train Epoch: 2742 [33024/118836 (28%)] Loss: 12192.370117\n",
      "Train Epoch: 2742 [65792/118836 (55%)] Loss: 12233.433594\n",
      "Train Epoch: 2742 [98560/118836 (83%)] Loss: 12261.753906\n",
      "    epoch          : 2742\n",
      "    loss           : 12221.429646143508\n",
      "    val_loss       : 12224.237368601665\n",
      "    val_log_likelihood: -12132.67743389423\n",
      "    val_log_marginal: -12141.268512005763\n",
      "Train Epoch: 2743 [256/118836 (0%)] Loss: 12272.811523\n",
      "Train Epoch: 2743 [33024/118836 (28%)] Loss: 12210.125000\n",
      "Train Epoch: 2743 [65792/118836 (55%)] Loss: 12245.254883\n",
      "Train Epoch: 2743 [98560/118836 (83%)] Loss: 12216.265625\n",
      "    epoch          : 2743\n",
      "    loss           : 12225.125477699803\n",
      "    val_loss       : 12224.604969024422\n",
      "    val_log_likelihood: -12133.017702356026\n",
      "    val_log_marginal: -12141.439767188722\n",
      "Train Epoch: 2744 [256/118836 (0%)] Loss: 12270.574219\n",
      "Train Epoch: 2744 [33024/118836 (28%)] Loss: 12288.191406\n",
      "Train Epoch: 2744 [65792/118836 (55%)] Loss: 12278.466797\n",
      "Train Epoch: 2744 [98560/118836 (83%)] Loss: 12174.416016\n",
      "    epoch          : 2744\n",
      "    loss           : 12223.513043773262\n",
      "    val_loss       : 12226.880810832454\n",
      "    val_log_likelihood: -12132.810832008634\n",
      "    val_log_marginal: -12141.286104090726\n",
      "Train Epoch: 2745 [256/118836 (0%)] Loss: 12306.790039\n",
      "Train Epoch: 2745 [33024/118836 (28%)] Loss: 12280.358398\n",
      "Train Epoch: 2745 [65792/118836 (55%)] Loss: 12287.210938\n",
      "Train Epoch: 2745 [98560/118836 (83%)] Loss: 12329.046875\n",
      "    epoch          : 2745\n",
      "    loss           : 12228.656585859955\n",
      "    val_loss       : 12222.609663215277\n",
      "    val_log_likelihood: -12132.953930159221\n",
      "    val_log_marginal: -12141.374881527283\n",
      "Train Epoch: 2746 [256/118836 (0%)] Loss: 12161.044922\n",
      "Train Epoch: 2746 [33024/118836 (28%)] Loss: 12315.721680\n",
      "Train Epoch: 2746 [65792/118836 (55%)] Loss: 12202.052734\n",
      "Train Epoch: 2746 [98560/118836 (83%)] Loss: 12254.490234\n",
      "    epoch          : 2746\n",
      "    loss           : 12227.00300513079\n",
      "    val_loss       : 12225.384969573575\n",
      "    val_log_likelihood: -12129.5628972485\n",
      "    val_log_marginal: -12137.960560594447\n",
      "Train Epoch: 2747 [256/118836 (0%)] Loss: 12249.222656\n",
      "Train Epoch: 2747 [33024/118836 (28%)] Loss: 12279.874023\n",
      "Train Epoch: 2747 [65792/118836 (55%)] Loss: 12258.459961\n",
      "Train Epoch: 2747 [98560/118836 (83%)] Loss: 12276.709961\n",
      "    epoch          : 2747\n",
      "    loss           : 12223.879513188844\n",
      "    val_loss       : 12222.842656410177\n",
      "    val_log_likelihood: -12125.668439826302\n",
      "    val_log_marginal: -12134.1321582002\n",
      "Train Epoch: 2748 [256/118836 (0%)] Loss: 12204.410156\n",
      "Train Epoch: 2748 [33024/118836 (28%)] Loss: 12162.015625\n",
      "Train Epoch: 2748 [65792/118836 (55%)] Loss: 12292.785156\n",
      "Train Epoch: 2748 [98560/118836 (83%)] Loss: 12211.023438\n",
      "    epoch          : 2748\n",
      "    loss           : 12225.566764726787\n",
      "    val_loss       : 12229.429628154034\n",
      "    val_log_likelihood: -12137.23759289056\n",
      "    val_log_marginal: -12145.665440814802\n",
      "Train Epoch: 2749 [256/118836 (0%)] Loss: 12207.658203\n",
      "Train Epoch: 2749 [33024/118836 (28%)] Loss: 12196.917969\n",
      "Train Epoch: 2749 [65792/118836 (55%)] Loss: 12170.600586\n",
      "Train Epoch: 2749 [98560/118836 (83%)] Loss: 12198.449219\n",
      "    epoch          : 2749\n",
      "    loss           : 12224.235570299576\n",
      "    val_loss       : 12224.0696544503\n",
      "    val_log_likelihood: -12134.719099430054\n",
      "    val_log_marginal: -12143.010015101303\n",
      "Train Epoch: 2750 [256/118836 (0%)] Loss: 12356.792969\n",
      "Train Epoch: 2750 [33024/118836 (28%)] Loss: 12212.188477\n",
      "Train Epoch: 2750 [65792/118836 (55%)] Loss: 12267.798828\n",
      "Train Epoch: 2750 [98560/118836 (83%)] Loss: 12331.519531\n",
      "    epoch          : 2750\n",
      "    loss           : 12222.856093136115\n",
      "    val_loss       : 12225.06107522935\n",
      "    val_log_likelihood: -12134.623924084986\n",
      "    val_log_marginal: -12143.097626406558\n",
      "Train Epoch: 2751 [256/118836 (0%)] Loss: 12218.659180\n",
      "Train Epoch: 2751 [33024/118836 (28%)] Loss: 12245.404297\n",
      "Train Epoch: 2751 [65792/118836 (55%)] Loss: 12174.480469\n",
      "Train Epoch: 2751 [98560/118836 (83%)] Loss: 12369.962891\n",
      "    epoch          : 2751\n",
      "    loss           : 12220.699837643455\n",
      "    val_loss       : 12224.609492743337\n",
      "    val_log_likelihood: -12133.989797062397\n",
      "    val_log_marginal: -12142.313511636181\n",
      "Train Epoch: 2752 [256/118836 (0%)] Loss: 12228.332031\n",
      "Train Epoch: 2752 [33024/118836 (28%)] Loss: 12264.167969\n",
      "Train Epoch: 2752 [65792/118836 (55%)] Loss: 12149.694336\n",
      "Train Epoch: 2752 [98560/118836 (83%)] Loss: 12266.856445\n",
      "    epoch          : 2752\n",
      "    loss           : 12223.201761689672\n",
      "    val_loss       : 12226.899405911408\n",
      "    val_log_likelihood: -12135.653060542028\n",
      "    val_log_marginal: -12143.929298191097\n",
      "Train Epoch: 2753 [256/118836 (0%)] Loss: 12165.148438\n",
      "Train Epoch: 2753 [33024/118836 (28%)] Loss: 12216.978516\n",
      "Train Epoch: 2753 [65792/118836 (55%)] Loss: 12295.458984\n",
      "Train Epoch: 2753 [98560/118836 (83%)] Loss: 12240.900391\n",
      "    epoch          : 2753\n",
      "    loss           : 12225.255057446753\n",
      "    val_loss       : 12226.371504125926\n",
      "    val_log_likelihood: -12131.229035004395\n",
      "    val_log_marginal: -12139.63165884579\n",
      "Train Epoch: 2754 [256/118836 (0%)] Loss: 12257.709961\n",
      "Train Epoch: 2754 [33024/118836 (28%)] Loss: 12275.322266\n",
      "Train Epoch: 2754 [65792/118836 (55%)] Loss: 12263.515625\n",
      "Train Epoch: 2754 [98560/118836 (83%)] Loss: 12358.176758\n",
      "    epoch          : 2754\n",
      "    loss           : 12224.241743563896\n",
      "    val_loss       : 12222.703824182094\n",
      "    val_log_likelihood: -12135.0523371265\n",
      "    val_log_marginal: -12143.394777677364\n",
      "Train Epoch: 2755 [256/118836 (0%)] Loss: 12186.681641\n",
      "Train Epoch: 2755 [33024/118836 (28%)] Loss: 12215.946289\n",
      "Train Epoch: 2755 [65792/118836 (55%)] Loss: 12240.931641\n",
      "Train Epoch: 2755 [98560/118836 (83%)] Loss: 12261.824219\n",
      "    epoch          : 2755\n",
      "    loss           : 12223.953389455386\n",
      "    val_loss       : 12225.470542186538\n",
      "    val_log_likelihood: -12135.655714465725\n",
      "    val_log_marginal: -12143.966805633041\n",
      "Train Epoch: 2756 [256/118836 (0%)] Loss: 12156.210938\n",
      "Train Epoch: 2756 [33024/118836 (28%)] Loss: 12296.541992\n",
      "Train Epoch: 2756 [65792/118836 (55%)] Loss: 12252.509766\n",
      "Train Epoch: 2756 [98560/118836 (83%)] Loss: 12262.798828\n",
      "    epoch          : 2756\n",
      "    loss           : 12224.04444369055\n",
      "    val_loss       : 12223.908258391011\n",
      "    val_log_likelihood: -12138.175114861197\n",
      "    val_log_marginal: -12146.51928163032\n",
      "Train Epoch: 2757 [256/118836 (0%)] Loss: 12245.929688\n",
      "Train Epoch: 2757 [33024/118836 (28%)] Loss: 12305.734375\n",
      "Train Epoch: 2757 [65792/118836 (55%)] Loss: 12253.756836\n",
      "Train Epoch: 2757 [98560/118836 (83%)] Loss: 12271.386719\n",
      "    epoch          : 2757\n",
      "    loss           : 12224.440978953422\n",
      "    val_loss       : 12225.34168067577\n",
      "    val_log_likelihood: -12131.870093601376\n",
      "    val_log_marginal: -12140.265782490147\n",
      "Train Epoch: 2758 [256/118836 (0%)] Loss: 12152.371094\n",
      "Train Epoch: 2758 [33024/118836 (28%)] Loss: 12209.863281\n",
      "Train Epoch: 2758 [65792/118836 (55%)] Loss: 12352.421875\n",
      "Train Epoch: 2758 [98560/118836 (83%)] Loss: 12178.669922\n",
      "    epoch          : 2758\n",
      "    loss           : 12222.726343439826\n",
      "    val_loss       : 12221.331710940342\n",
      "    val_log_likelihood: -12130.862209212159\n",
      "    val_log_marginal: -12139.103786556747\n",
      "Train Epoch: 2759 [256/118836 (0%)] Loss: 12210.382812\n",
      "Train Epoch: 2759 [33024/118836 (28%)] Loss: 12142.176758\n",
      "Train Epoch: 2759 [65792/118836 (55%)] Loss: 12258.694336\n",
      "Train Epoch: 2759 [98560/118836 (83%)] Loss: 12220.274414\n",
      "    epoch          : 2759\n",
      "    loss           : 12220.939561685793\n",
      "    val_loss       : 12226.790669237249\n",
      "    val_log_likelihood: -12135.604346470484\n",
      "    val_log_marginal: -12143.919543621574\n",
      "Train Epoch: 2760 [256/118836 (0%)] Loss: 12320.464844\n",
      "Train Epoch: 2760 [33024/118836 (28%)] Loss: 12215.882812\n",
      "Train Epoch: 2760 [65792/118836 (55%)] Loss: 12198.501953\n",
      "Train Epoch: 2760 [98560/118836 (83%)] Loss: 12210.898438\n",
      "    epoch          : 2760\n",
      "    loss           : 12221.705321417494\n",
      "    val_loss       : 12220.950932290702\n",
      "    val_log_likelihood: -12130.795883090363\n",
      "    val_log_marginal: -12139.090397398644\n",
      "Train Epoch: 2761 [256/118836 (0%)] Loss: 12194.368164\n",
      "Train Epoch: 2761 [33024/118836 (28%)] Loss: 12226.820312\n",
      "Train Epoch: 2761 [65792/118836 (55%)] Loss: 12238.296875\n",
      "Train Epoch: 2761 [98560/118836 (83%)] Loss: 12159.726562\n",
      "    epoch          : 2761\n",
      "    loss           : 12221.316850670752\n",
      "    val_loss       : 12230.998225024066\n",
      "    val_log_likelihood: -12139.747408918785\n",
      "    val_log_marginal: -12147.98718536906\n",
      "Train Epoch: 2762 [256/118836 (0%)] Loss: 12266.987305\n",
      "Train Epoch: 2762 [33024/118836 (28%)] Loss: 12180.748047\n",
      "Train Epoch: 2762 [65792/118836 (55%)] Loss: 12265.662109\n",
      "Train Epoch: 2762 [98560/118836 (83%)] Loss: 12252.550781\n",
      "    epoch          : 2762\n",
      "    loss           : 12223.11601142473\n",
      "    val_loss       : 12227.115515792715\n",
      "    val_log_likelihood: -12129.477551501757\n",
      "    val_log_marginal: -12138.09637479583\n",
      "Train Epoch: 2763 [256/118836 (0%)] Loss: 12332.939453\n",
      "Train Epoch: 2763 [33024/118836 (28%)] Loss: 12307.412109\n",
      "Train Epoch: 2763 [65792/118836 (55%)] Loss: 12254.800781\n",
      "Train Epoch: 2763 [98560/118836 (83%)] Loss: 12211.087891\n",
      "    epoch          : 2763\n",
      "    loss           : 12222.74210801799\n",
      "    val_loss       : 12224.94115142082\n",
      "    val_log_likelihood: -12132.612987069633\n",
      "    val_log_marginal: -12141.00803947572\n",
      "Train Epoch: 2764 [256/118836 (0%)] Loss: 12191.237305\n",
      "Train Epoch: 2764 [33024/118836 (28%)] Loss: 12183.319336\n",
      "Train Epoch: 2764 [65792/118836 (55%)] Loss: 12212.489258\n",
      "Train Epoch: 2764 [98560/118836 (83%)] Loss: 12286.393555\n",
      "    epoch          : 2764\n",
      "    loss           : 12223.686608250619\n",
      "    val_loss       : 12224.726762182689\n",
      "    val_log_likelihood: -12133.555048723118\n",
      "    val_log_marginal: -12142.011380583981\n",
      "Train Epoch: 2765 [256/118836 (0%)] Loss: 12231.188477\n",
      "Train Epoch: 2765 [33024/118836 (28%)] Loss: 12232.512695\n",
      "Train Epoch: 2765 [65792/118836 (55%)] Loss: 12351.011719\n",
      "Train Epoch: 2765 [98560/118836 (83%)] Loss: 12259.979492\n",
      "    epoch          : 2765\n",
      "    loss           : 12223.949671732837\n",
      "    val_loss       : 12228.064397519145\n",
      "    val_log_likelihood: -12132.617162621484\n",
      "    val_log_marginal: -12140.882152054424\n",
      "Train Epoch: 2766 [256/118836 (0%)] Loss: 12244.890625\n",
      "Train Epoch: 2766 [33024/118836 (28%)] Loss: 12203.359375\n",
      "Train Epoch: 2766 [65792/118836 (55%)] Loss: 12356.688477\n",
      "Train Epoch: 2766 [98560/118836 (83%)] Loss: 12477.212891\n",
      "    epoch          : 2766\n",
      "    loss           : 12234.173888867348\n",
      "    val_loss       : 12235.48381191736\n",
      "    val_log_likelihood: -12133.535855594759\n",
      "    val_log_marginal: -12142.227047819895\n",
      "Train Epoch: 2767 [256/118836 (0%)] Loss: 12290.881836\n",
      "Train Epoch: 2767 [33024/118836 (28%)] Loss: 12298.269531\n",
      "Train Epoch: 2767 [65792/118836 (55%)] Loss: 12274.939453\n",
      "Train Epoch: 2767 [98560/118836 (83%)] Loss: 12143.370117\n",
      "    epoch          : 2767\n",
      "    loss           : 12233.623120541253\n",
      "    val_loss       : 12226.57933514724\n",
      "    val_log_likelihood: -12134.035551559915\n",
      "    val_log_marginal: -12142.644832089936\n",
      "Train Epoch: 2768 [256/118836 (0%)] Loss: 12248.463867\n",
      "Train Epoch: 2768 [33024/118836 (28%)] Loss: 12290.732422\n",
      "Train Epoch: 2768 [65792/118836 (55%)] Loss: 12251.547852\n",
      "Train Epoch: 2768 [98560/118836 (83%)] Loss: 12275.638672\n",
      "    epoch          : 2768\n",
      "    loss           : 12229.157653697528\n",
      "    val_loss       : 12223.57435914834\n",
      "    val_log_likelihood: -12134.42606412195\n",
      "    val_log_marginal: -12142.937897851472\n",
      "Train Epoch: 2769 [256/118836 (0%)] Loss: 12210.234375\n",
      "Train Epoch: 2769 [33024/118836 (28%)] Loss: 12190.768555\n",
      "Train Epoch: 2769 [65792/118836 (55%)] Loss: 12241.213867\n",
      "Train Epoch: 2769 [98560/118836 (83%)] Loss: 12285.221680\n",
      "    epoch          : 2769\n",
      "    loss           : 12223.151628088814\n",
      "    val_loss       : 12225.401337886427\n",
      "    val_log_likelihood: -12133.204617549369\n",
      "    val_log_marginal: -12141.6966384314\n",
      "Train Epoch: 2770 [256/118836 (0%)] Loss: 12134.053711\n",
      "Train Epoch: 2770 [33024/118836 (28%)] Loss: 12281.216797\n",
      "Train Epoch: 2770 [65792/118836 (55%)] Loss: 12184.648438\n",
      "Train Epoch: 2770 [98560/118836 (83%)] Loss: 12165.211914\n",
      "    epoch          : 2770\n",
      "    loss           : 12226.645829617712\n",
      "    val_loss       : 12221.939536709007\n",
      "    val_log_likelihood: -12133.913610486456\n",
      "    val_log_marginal: -12142.315841379836\n",
      "Train Epoch: 2771 [256/118836 (0%)] Loss: 12281.816406\n",
      "Train Epoch: 2771 [33024/118836 (28%)] Loss: 12216.841797\n",
      "Train Epoch: 2771 [65792/118836 (55%)] Loss: 12356.250000\n",
      "Train Epoch: 2771 [98560/118836 (83%)] Loss: 12181.903320\n",
      "    epoch          : 2771\n",
      "    loss           : 12226.640504807692\n",
      "    val_loss       : 12227.56211908699\n",
      "    val_log_likelihood: -12131.948121348996\n",
      "    val_log_marginal: -12140.427466261754\n",
      "Train Epoch: 2772 [256/118836 (0%)] Loss: 12402.142578\n",
      "Train Epoch: 2772 [33024/118836 (28%)] Loss: 12245.004883\n",
      "Train Epoch: 2772 [65792/118836 (55%)] Loss: 12266.125977\n",
      "Train Epoch: 2772 [98560/118836 (83%)] Loss: 12272.638672\n",
      "    epoch          : 2772\n",
      "    loss           : 12225.409243983924\n",
      "    val_loss       : 12223.048641629639\n",
      "    val_log_likelihood: -12131.2952314025\n",
      "    val_log_marginal: -12139.76611276796\n",
      "Train Epoch: 2773 [256/118836 (0%)] Loss: 12186.806641\n",
      "Train Epoch: 2773 [33024/118836 (28%)] Loss: 12183.355469\n",
      "Train Epoch: 2773 [65792/118836 (55%)] Loss: 12214.793945\n",
      "Train Epoch: 2773 [98560/118836 (83%)] Loss: 12199.955078\n",
      "    epoch          : 2773\n",
      "    loss           : 12227.710708100703\n",
      "    val_loss       : 12224.34032847821\n",
      "    val_log_likelihood: -12133.309867562293\n",
      "    val_log_marginal: -12141.65403332974\n",
      "Train Epoch: 2774 [256/118836 (0%)] Loss: 12323.733398\n",
      "Train Epoch: 2774 [33024/118836 (28%)] Loss: 12184.746094\n",
      "Train Epoch: 2774 [65792/118836 (55%)] Loss: 12306.140625\n",
      "Train Epoch: 2774 [98560/118836 (83%)] Loss: 12211.214844\n",
      "    epoch          : 2774\n",
      "    loss           : 12227.346033653845\n",
      "    val_loss       : 12223.96186008647\n",
      "    val_log_likelihood: -12134.37291068936\n",
      "    val_log_marginal: -12142.679666970313\n",
      "Train Epoch: 2775 [256/118836 (0%)] Loss: 12292.802734\n",
      "Train Epoch: 2775 [33024/118836 (28%)] Loss: 12170.890625\n",
      "Train Epoch: 2775 [65792/118836 (55%)] Loss: 12272.488281\n",
      "Train Epoch: 2775 [98560/118836 (83%)] Loss: 12183.507812\n",
      "    epoch          : 2775\n",
      "    loss           : 12223.942629820616\n",
      "    val_loss       : 12225.401693000496\n",
      "    val_log_likelihood: -12136.105081840622\n",
      "    val_log_marginal: -12144.504085529246\n",
      "Train Epoch: 2776 [256/118836 (0%)] Loss: 12225.034180\n",
      "Train Epoch: 2776 [33024/118836 (28%)] Loss: 12167.093750\n",
      "Train Epoch: 2776 [65792/118836 (55%)] Loss: 12211.793945\n",
      "Train Epoch: 2776 [98560/118836 (83%)] Loss: 12145.108398\n",
      "    epoch          : 2776\n",
      "    loss           : 12219.006596360628\n",
      "    val_loss       : 12229.97687717852\n",
      "    val_log_likelihood: -12132.221663694168\n",
      "    val_log_marginal: -12140.70795570971\n",
      "Train Epoch: 2777 [256/118836 (0%)] Loss: 12186.841797\n",
      "Train Epoch: 2777 [33024/118836 (28%)] Loss: 12315.899414\n",
      "Train Epoch: 2777 [65792/118836 (55%)] Loss: 12287.961914\n",
      "Train Epoch: 2777 [98560/118836 (83%)] Loss: 12184.166992\n",
      "    epoch          : 2777\n",
      "    loss           : 12223.94400750879\n",
      "    val_loss       : 12225.479524154936\n",
      "    val_log_likelihood: -12132.2233093918\n",
      "    val_log_marginal: -12140.5291948754\n",
      "Train Epoch: 2778 [256/118836 (0%)] Loss: 12237.144531\n",
      "Train Epoch: 2778 [33024/118836 (28%)] Loss: 12274.757812\n",
      "Train Epoch: 2778 [65792/118836 (55%)] Loss: 12198.131836\n",
      "Train Epoch: 2778 [98560/118836 (83%)] Loss: 12222.037109\n",
      "    epoch          : 2778\n",
      "    loss           : 12220.514739551023\n",
      "    val_loss       : 12221.506859556996\n",
      "    val_log_likelihood: -12134.028459406018\n",
      "    val_log_marginal: -12142.512722588164\n",
      "Train Epoch: 2779 [256/118836 (0%)] Loss: 12175.938477\n",
      "Train Epoch: 2779 [33024/118836 (28%)] Loss: 12190.115234\n",
      "Train Epoch: 2779 [65792/118836 (55%)] Loss: 12217.726562\n",
      "Train Epoch: 2779 [98560/118836 (83%)] Loss: 12228.431641\n",
      "    epoch          : 2779\n",
      "    loss           : 12225.285219254032\n",
      "    val_loss       : 12236.707802872801\n",
      "    val_log_likelihood: -12149.177748914391\n",
      "    val_log_marginal: -12157.533159033177\n",
      "Train Epoch: 2780 [256/118836 (0%)] Loss: 12271.448242\n",
      "Train Epoch: 2780 [33024/118836 (28%)] Loss: 12187.730469\n",
      "Train Epoch: 2780 [65792/118836 (55%)] Loss: 12305.400391\n",
      "Train Epoch: 2780 [98560/118836 (83%)] Loss: 12237.257812\n",
      "    epoch          : 2780\n",
      "    loss           : 12228.199433448355\n",
      "    val_loss       : 12221.503805365337\n",
      "    val_log_likelihood: -12134.74121885339\n",
      "    val_log_marginal: -12143.000279486521\n",
      "Train Epoch: 2781 [256/118836 (0%)] Loss: 12306.345703\n",
      "Train Epoch: 2781 [33024/118836 (28%)] Loss: 12337.791016\n",
      "Train Epoch: 2781 [65792/118836 (55%)] Loss: 12317.125977\n",
      "Train Epoch: 2781 [98560/118836 (83%)] Loss: 12250.620117\n",
      "    epoch          : 2781\n",
      "    loss           : 12224.708049007446\n",
      "    val_loss       : 12223.364623170346\n",
      "    val_log_likelihood: -12129.718047424265\n",
      "    val_log_marginal: -12138.102722699743\n",
      "Train Epoch: 2782 [256/118836 (0%)] Loss: 12173.257812\n",
      "Train Epoch: 2782 [33024/118836 (28%)] Loss: 12254.267578\n",
      "Train Epoch: 2782 [65792/118836 (55%)] Loss: 12233.361328\n",
      "Train Epoch: 2782 [98560/118836 (83%)] Loss: 12357.826172\n",
      "    epoch          : 2782\n",
      "    loss           : 12222.856860977563\n",
      "    val_loss       : 12225.716548763465\n",
      "    val_log_likelihood: -12133.640130176023\n",
      "    val_log_marginal: -12142.267782599029\n",
      "Train Epoch: 2783 [256/118836 (0%)] Loss: 12134.256836\n",
      "Train Epoch: 2783 [33024/118836 (28%)] Loss: 12261.671875\n",
      "Train Epoch: 2783 [65792/118836 (55%)] Loss: 12216.947266\n",
      "Train Epoch: 2783 [98560/118836 (83%)] Loss: 12177.649414\n",
      "    epoch          : 2783\n",
      "    loss           : 12223.345422191636\n",
      "    val_loss       : 12229.334549232035\n",
      "    val_log_likelihood: -12133.27649109543\n",
      "    val_log_marginal: -12141.620991917192\n",
      "Train Epoch: 2784 [256/118836 (0%)] Loss: 12236.203125\n",
      "Train Epoch: 2784 [33024/118836 (28%)] Loss: 12172.277344\n",
      "Train Epoch: 2784 [65792/118836 (55%)] Loss: 12249.083984\n",
      "Train Epoch: 2784 [98560/118836 (83%)] Loss: 12216.416992\n",
      "    epoch          : 2784\n",
      "    loss           : 12225.781184895834\n",
      "    val_loss       : 12221.556107593622\n",
      "    val_log_likelihood: -12129.973382896505\n",
      "    val_log_marginal: -12138.289219677205\n",
      "Train Epoch: 2785 [256/118836 (0%)] Loss: 12261.003906\n",
      "Train Epoch: 2785 [33024/118836 (28%)] Loss: 12172.853516\n",
      "Train Epoch: 2785 [65792/118836 (55%)] Loss: 12129.021484\n",
      "Train Epoch: 2785 [98560/118836 (83%)] Loss: 12356.939453\n",
      "    epoch          : 2785\n",
      "    loss           : 12226.060079029674\n",
      "    val_loss       : 12222.174784412939\n",
      "    val_log_likelihood: -12133.41914611766\n",
      "    val_log_marginal: -12141.715685957703\n",
      "Train Epoch: 2786 [256/118836 (0%)] Loss: 12188.972656\n",
      "Train Epoch: 2786 [33024/118836 (28%)] Loss: 12299.447266\n",
      "Train Epoch: 2786 [65792/118836 (55%)] Loss: 12242.814453\n",
      "Train Epoch: 2786 [98560/118836 (83%)] Loss: 12280.400391\n",
      "    epoch          : 2786\n",
      "    loss           : 12227.854817869882\n",
      "    val_loss       : 12227.770568879268\n",
      "    val_log_likelihood: -12133.277770561932\n",
      "    val_log_marginal: -12141.720317636344\n",
      "Train Epoch: 2787 [256/118836 (0%)] Loss: 12204.677734\n",
      "Train Epoch: 2787 [33024/118836 (28%)] Loss: 12149.920898\n",
      "Train Epoch: 2787 [65792/118836 (55%)] Loss: 12191.687500\n",
      "Train Epoch: 2787 [98560/118836 (83%)] Loss: 12229.992188\n",
      "    epoch          : 2787\n",
      "    loss           : 12218.899512284172\n",
      "    val_loss       : 12225.70387257279\n",
      "    val_log_likelihood: -12131.641303181865\n",
      "    val_log_marginal: -12139.992514091333\n",
      "Train Epoch: 2788 [256/118836 (0%)] Loss: 12196.845703\n",
      "Train Epoch: 2788 [33024/118836 (28%)] Loss: 12283.995117\n",
      "Train Epoch: 2788 [65792/118836 (55%)] Loss: 12223.466797\n",
      "Train Epoch: 2788 [98560/118836 (83%)] Loss: 12252.114258\n",
      "    epoch          : 2788\n",
      "    loss           : 12220.673524897902\n",
      "    val_loss       : 12226.28766592892\n",
      "    val_log_likelihood: -12130.625317281845\n",
      "    val_log_marginal: -12139.087876063664\n",
      "Train Epoch: 2789 [256/118836 (0%)] Loss: 12250.786133\n",
      "Train Epoch: 2789 [33024/118836 (28%)] Loss: 12300.359375\n",
      "Train Epoch: 2789 [65792/118836 (55%)] Loss: 12335.488281\n",
      "Train Epoch: 2789 [98560/118836 (83%)] Loss: 12273.744141\n",
      "    epoch          : 2789\n",
      "    loss           : 12222.974499198719\n",
      "    val_loss       : 12224.852837178541\n",
      "    val_log_likelihood: -12134.07686152683\n",
      "    val_log_marginal: -12142.475245775364\n",
      "Train Epoch: 2790 [256/118836 (0%)] Loss: 12195.810547\n",
      "Train Epoch: 2790 [33024/118836 (28%)] Loss: 12266.914062\n",
      "Train Epoch: 2790 [65792/118836 (55%)] Loss: 12189.888672\n",
      "Train Epoch: 2790 [98560/118836 (83%)] Loss: 12278.670898\n",
      "    epoch          : 2790\n",
      "    loss           : 12223.367224656224\n",
      "    val_loss       : 12224.559395606979\n",
      "    val_log_likelihood: -12132.923600341192\n",
      "    val_log_marginal: -12141.305741193752\n",
      "Train Epoch: 2791 [256/118836 (0%)] Loss: 12191.650391\n",
      "Train Epoch: 2791 [33024/118836 (28%)] Loss: 12284.376953\n",
      "Train Epoch: 2791 [65792/118836 (55%)] Loss: 12205.025391\n",
      "Train Epoch: 2791 [98560/118836 (83%)] Loss: 12281.121094\n",
      "    epoch          : 2791\n",
      "    loss           : 12222.498402120811\n",
      "    val_loss       : 12223.279984370198\n",
      "    val_log_likelihood: -12128.810610040582\n",
      "    val_log_marginal: -12137.223724749607\n",
      "Train Epoch: 2792 [256/118836 (0%)] Loss: 12185.495117\n",
      "Train Epoch: 2792 [33024/118836 (28%)] Loss: 12211.675781\n",
      "Train Epoch: 2792 [65792/118836 (55%)] Loss: 12272.526367\n",
      "Train Epoch: 2792 [98560/118836 (83%)] Loss: 12296.850586\n",
      "    epoch          : 2792\n",
      "    loss           : 12221.725895303454\n",
      "    val_loss       : 12220.672403748214\n",
      "    val_log_likelihood: -12132.716177012253\n",
      "    val_log_marginal: -12141.014198443027\n",
      "Train Epoch: 2793 [256/118836 (0%)] Loss: 12284.033203\n",
      "Train Epoch: 2793 [33024/118836 (28%)] Loss: 12247.618164\n",
      "Train Epoch: 2793 [65792/118836 (55%)] Loss: 12283.238281\n",
      "Train Epoch: 2793 [98560/118836 (83%)] Loss: 12273.376953\n",
      "    epoch          : 2793\n",
      "    loss           : 12224.574405015766\n",
      "    val_loss       : 12224.809582227266\n",
      "    val_log_likelihood: -12136.199097103754\n",
      "    val_log_marginal: -12144.526502455645\n",
      "Train Epoch: 2794 [256/118836 (0%)] Loss: 12280.620117\n",
      "Train Epoch: 2794 [33024/118836 (28%)] Loss: 12173.618164\n",
      "Train Epoch: 2794 [65792/118836 (55%)] Loss: 12167.834961\n",
      "Train Epoch: 2794 [98560/118836 (83%)] Loss: 12144.120117\n",
      "    epoch          : 2794\n",
      "    loss           : 12220.507618641439\n",
      "    val_loss       : 12227.30981030769\n",
      "    val_log_likelihood: -12129.838968317048\n",
      "    val_log_marginal: -12138.20433199035\n",
      "Train Epoch: 2795 [256/118836 (0%)] Loss: 12360.304688\n",
      "Train Epoch: 2795 [33024/118836 (28%)] Loss: 12266.876953\n",
      "Train Epoch: 2795 [65792/118836 (55%)] Loss: 12231.392578\n",
      "Train Epoch: 2795 [98560/118836 (83%)] Loss: 12242.195312\n",
      "    epoch          : 2795\n",
      "    loss           : 12226.165756339175\n",
      "    val_loss       : 12224.185589202914\n",
      "    val_log_likelihood: -12134.026012910981\n",
      "    val_log_marginal: -12142.429325422656\n",
      "Train Epoch: 2796 [256/118836 (0%)] Loss: 12228.271484\n",
      "Train Epoch: 2796 [33024/118836 (28%)] Loss: 12257.670898\n",
      "Train Epoch: 2796 [65792/118836 (55%)] Loss: 12330.843750\n",
      "Train Epoch: 2796 [98560/118836 (83%)] Loss: 12315.264648\n",
      "    epoch          : 2796\n",
      "    loss           : 12230.690156185381\n",
      "    val_loss       : 12223.24845463494\n",
      "    val_log_likelihood: -12134.783001350548\n",
      "    val_log_marginal: -12143.089333813648\n",
      "Train Epoch: 2797 [256/118836 (0%)] Loss: 12274.678711\n",
      "Train Epoch: 2797 [33024/118836 (28%)] Loss: 12302.143555\n",
      "Train Epoch: 2797 [65792/118836 (55%)] Loss: 12166.269531\n",
      "Train Epoch: 2797 [98560/118836 (83%)] Loss: 12270.990234\n",
      "    epoch          : 2797\n",
      "    loss           : 12226.688448614557\n",
      "    val_loss       : 12223.049128545452\n",
      "    val_log_likelihood: -12134.857882127531\n",
      "    val_log_marginal: -12143.338958345334\n",
      "Train Epoch: 2798 [256/118836 (0%)] Loss: 12244.871094\n",
      "Train Epoch: 2798 [33024/118836 (28%)] Loss: 12281.875977\n",
      "Train Epoch: 2798 [65792/118836 (55%)] Loss: 12311.194336\n",
      "Train Epoch: 2798 [98560/118836 (83%)] Loss: 12205.304688\n",
      "    epoch          : 2798\n",
      "    loss           : 12222.243050009047\n",
      "    val_loss       : 12224.416067212956\n",
      "    val_log_likelihood: -12135.162730853235\n",
      "    val_log_marginal: -12143.505472053836\n",
      "Train Epoch: 2799 [256/118836 (0%)] Loss: 12268.570312\n",
      "Train Epoch: 2799 [33024/118836 (28%)] Loss: 12184.908203\n",
      "Train Epoch: 2799 [65792/118836 (55%)] Loss: 12230.273438\n",
      "Train Epoch: 2799 [98560/118836 (83%)] Loss: 12256.299805\n",
      "    epoch          : 2799\n",
      "    loss           : 12230.640818858561\n",
      "    val_loss       : 12224.593530678043\n",
      "    val_log_likelihood: -12133.843451296269\n",
      "    val_log_marginal: -12142.466998383137\n",
      "Train Epoch: 2800 [256/118836 (0%)] Loss: 12234.918945\n",
      "Train Epoch: 2800 [33024/118836 (28%)] Loss: 12235.225586\n",
      "Train Epoch: 2800 [65792/118836 (55%)] Loss: 12238.433594\n",
      "Train Epoch: 2800 [98560/118836 (83%)] Loss: 12334.412109\n",
      "    epoch          : 2800\n",
      "    loss           : 12228.203833714588\n",
      "    val_loss       : 12225.34424041699\n",
      "    val_log_likelihood: -12134.247813921631\n",
      "    val_log_marginal: -12142.733232285782\n",
      "Saving checkpoint: saved/models/SelfiesAutoencodingOperad/0905_154251/checkpoint-epoch2800.pth ...\n",
      "Train Epoch: 2801 [256/118836 (0%)] Loss: 12249.011719\n",
      "Train Epoch: 2801 [33024/118836 (28%)] Loss: 12273.859375\n",
      "Train Epoch: 2801 [65792/118836 (55%)] Loss: 12174.182617\n",
      "Train Epoch: 2801 [98560/118836 (83%)] Loss: 12240.435547\n",
      "    epoch          : 2801\n",
      "    loss           : 12225.003660534274\n",
      "    val_loss       : 12226.522253526244\n",
      "    val_log_likelihood: -12133.70370964511\n",
      "    val_log_marginal: -12142.118535752723\n",
      "Train Epoch: 2802 [256/118836 (0%)] Loss: 12155.557617\n",
      "Train Epoch: 2802 [33024/118836 (28%)] Loss: 12243.502930\n",
      "Train Epoch: 2802 [65792/118836 (55%)] Loss: 12220.146484\n",
      "Train Epoch: 2802 [98560/118836 (83%)] Loss: 12173.117188\n",
      "    epoch          : 2802\n",
      "    loss           : 12224.045323000671\n",
      "    val_loss       : 12225.330600977386\n",
      "    val_log_likelihood: -12130.707807653536\n",
      "    val_log_marginal: -12139.14420166954\n",
      "Train Epoch: 2803 [256/118836 (0%)] Loss: 12200.727539\n",
      "Train Epoch: 2803 [33024/118836 (28%)] Loss: 12167.700195\n",
      "Train Epoch: 2803 [65792/118836 (55%)] Loss: 12318.122070\n",
      "Train Epoch: 2803 [98560/118836 (83%)] Loss: 12173.515625\n",
      "    epoch          : 2803\n",
      "    loss           : 12223.932668236921\n",
      "    val_loss       : 12229.841652100831\n",
      "    val_log_likelihood: -12132.941657296837\n",
      "    val_log_marginal: -12141.38112738853\n",
      "Train Epoch: 2804 [256/118836 (0%)] Loss: 12317.178711\n",
      "Train Epoch: 2804 [33024/118836 (28%)] Loss: 12236.983398\n",
      "Train Epoch: 2804 [65792/118836 (55%)] Loss: 12344.439453\n",
      "Train Epoch: 2804 [98560/118836 (83%)] Loss: 12151.085938\n",
      "    epoch          : 2804\n",
      "    loss           : 12220.0591796875\n",
      "    val_loss       : 12221.98042118092\n",
      "    val_log_likelihood: -12128.88812761709\n",
      "    val_log_marginal: -12137.277358100548\n",
      "Train Epoch: 2805 [256/118836 (0%)] Loss: 12288.633789\n",
      "Train Epoch: 2805 [33024/118836 (28%)] Loss: 12157.534180\n",
      "Train Epoch: 2805 [65792/118836 (55%)] Loss: 12287.638672\n",
      "Train Epoch: 2805 [98560/118836 (83%)] Loss: 12225.162109\n",
      "    epoch          : 2805\n",
      "    loss           : 12227.196944627533\n",
      "    val_loss       : 12230.281761313234\n",
      "    val_log_likelihood: -12130.651058144646\n",
      "    val_log_marginal: -12139.015626924958\n",
      "Train Epoch: 2806 [256/118836 (0%)] Loss: 12214.189453\n",
      "Train Epoch: 2806 [33024/118836 (28%)] Loss: 12211.843750\n",
      "Train Epoch: 2806 [65792/118836 (55%)] Loss: 12280.231445\n",
      "Train Epoch: 2806 [98560/118836 (83%)] Loss: 12189.473633\n",
      "    epoch          : 2806\n",
      "    loss           : 12227.060971425248\n",
      "    val_loss       : 12223.767766177434\n",
      "    val_log_likelihood: -12133.3757474863\n",
      "    val_log_marginal: -12142.01872973352\n",
      "Train Epoch: 2807 [256/118836 (0%)] Loss: 12285.771484\n",
      "Train Epoch: 2807 [33024/118836 (28%)] Loss: 12263.443359\n",
      "Train Epoch: 2807 [65792/118836 (55%)] Loss: 12230.874023\n",
      "Train Epoch: 2807 [98560/118836 (83%)] Loss: 12351.478516\n",
      "    epoch          : 2807\n",
      "    loss           : 12230.094404757288\n",
      "    val_loss       : 12223.717208067397\n",
      "    val_log_likelihood: -12134.670594241108\n",
      "    val_log_marginal: -12143.178039778539\n",
      "Train Epoch: 2808 [256/118836 (0%)] Loss: 12256.037109\n",
      "Train Epoch: 2808 [33024/118836 (28%)] Loss: 12204.226562\n",
      "Train Epoch: 2808 [65792/118836 (55%)] Loss: 12300.776367\n",
      "Train Epoch: 2808 [98560/118836 (83%)] Loss: 12360.126953\n",
      "    epoch          : 2808\n",
      "    loss           : 12228.963583346258\n",
      "    val_loss       : 12222.984636221208\n",
      "    val_log_likelihood: -12134.751747150278\n",
      "    val_log_marginal: -12143.132269679758\n",
      "Train Epoch: 2809 [256/118836 (0%)] Loss: 12202.078125\n",
      "Train Epoch: 2809 [33024/118836 (28%)] Loss: 12217.493164\n",
      "Train Epoch: 2809 [65792/118836 (55%)] Loss: 12240.794922\n",
      "Train Epoch: 2809 [98560/118836 (83%)] Loss: 12198.388672\n",
      "    epoch          : 2809\n",
      "    loss           : 12221.237600160255\n",
      "    val_loss       : 12222.016089207698\n",
      "    val_log_likelihood: -12132.05528959238\n",
      "    val_log_marginal: -12140.531046257556\n",
      "Train Epoch: 2810 [256/118836 (0%)] Loss: 12189.896484\n",
      "Train Epoch: 2810 [33024/118836 (28%)] Loss: 12251.516602\n",
      "Train Epoch: 2810 [65792/118836 (55%)] Loss: 12347.953125\n",
      "Train Epoch: 2810 [98560/118836 (83%)] Loss: 12305.667969\n",
      "    epoch          : 2810\n",
      "    loss           : 12223.874573672714\n",
      "    val_loss       : 12226.846086309215\n",
      "    val_log_likelihood: -12132.241309966914\n",
      "    val_log_marginal: -12140.66308042635\n",
      "Train Epoch: 2811 [256/118836 (0%)] Loss: 12206.268555\n",
      "Train Epoch: 2811 [33024/118836 (28%)] Loss: 12233.898438\n",
      "Train Epoch: 2811 [65792/118836 (55%)] Loss: 12270.625000\n",
      "Train Epoch: 2811 [98560/118836 (83%)] Loss: 12233.662109\n",
      "    epoch          : 2811\n",
      "    loss           : 12219.973411005996\n",
      "    val_loss       : 12225.405650651948\n",
      "    val_log_likelihood: -12133.435537343621\n",
      "    val_log_marginal: -12142.01187699707\n",
      "Train Epoch: 2812 [256/118836 (0%)] Loss: 12242.542969\n",
      "Train Epoch: 2812 [33024/118836 (28%)] Loss: 12191.152344\n",
      "Train Epoch: 2812 [65792/118836 (55%)] Loss: 12258.814453\n",
      "Train Epoch: 2812 [98560/118836 (83%)] Loss: 12305.728516\n",
      "    epoch          : 2812\n",
      "    loss           : 12224.053499954767\n",
      "    val_loss       : 12227.203278437571\n",
      "    val_log_likelihood: -12132.271025737957\n",
      "    val_log_marginal: -12140.974969530609\n",
      "Train Epoch: 2813 [256/118836 (0%)] Loss: 12237.694336\n",
      "Train Epoch: 2813 [33024/118836 (28%)] Loss: 12271.639648\n",
      "Train Epoch: 2813 [65792/118836 (55%)] Loss: 12189.552734\n",
      "Train Epoch: 2813 [98560/118836 (83%)] Loss: 12318.968750\n",
      "    epoch          : 2813\n",
      "    loss           : 12225.428377339225\n",
      "    val_loss       : 12225.125127725281\n",
      "    val_log_likelihood: -12135.539747305367\n",
      "    val_log_marginal: -12143.910976306539\n",
      "Train Epoch: 2814 [256/118836 (0%)] Loss: 12230.527344\n",
      "Train Epoch: 2814 [33024/118836 (28%)] Loss: 12204.363281\n",
      "Train Epoch: 2814 [65792/118836 (55%)] Loss: 12215.307617\n",
      "Train Epoch: 2814 [98560/118836 (83%)] Loss: 12320.074219\n",
      "    epoch          : 2814\n",
      "    loss           : 12224.993394754189\n",
      "    val_loss       : 12227.946587643806\n",
      "    val_log_likelihood: -12138.709840906742\n",
      "    val_log_marginal: -12147.148406056695\n",
      "Train Epoch: 2815 [256/118836 (0%)] Loss: 12341.054688\n",
      "Train Epoch: 2815 [33024/118836 (28%)] Loss: 12251.396484\n",
      "Train Epoch: 2815 [65792/118836 (55%)] Loss: 12309.627930\n",
      "Train Epoch: 2815 [98560/118836 (83%)] Loss: 12232.618164\n",
      "    epoch          : 2815\n",
      "    loss           : 12242.703050687553\n",
      "    val_loss       : 12234.3306674627\n",
      "    val_log_likelihood: -12137.223600179643\n",
      "    val_log_marginal: -12145.880138336352\n",
      "Train Epoch: 2816 [256/118836 (0%)] Loss: 12246.749023\n",
      "Train Epoch: 2816 [33024/118836 (28%)] Loss: 12231.089844\n",
      "Train Epoch: 2816 [65792/118836 (55%)] Loss: 12290.815430\n",
      "Train Epoch: 2816 [98560/118836 (83%)] Loss: 12126.645508\n",
      "    epoch          : 2816\n",
      "    loss           : 12226.604332577284\n",
      "    val_loss       : 12229.430585413216\n",
      "    val_log_likelihood: -12133.447392925456\n",
      "    val_log_marginal: -12141.947033939974\n",
      "Train Epoch: 2817 [256/118836 (0%)] Loss: 12277.504883\n",
      "Train Epoch: 2817 [33024/118836 (28%)] Loss: 12282.382812\n",
      "Train Epoch: 2817 [65792/118836 (55%)] Loss: 12157.290039\n",
      "Train Epoch: 2817 [98560/118836 (83%)] Loss: 12213.606445\n",
      "    epoch          : 2817\n",
      "    loss           : 12225.201830671009\n",
      "    val_loss       : 12222.140511877471\n",
      "    val_log_likelihood: -12130.012973661083\n",
      "    val_log_marginal: -12138.521413594715\n",
      "Train Epoch: 2818 [256/118836 (0%)] Loss: 12189.128906\n",
      "Train Epoch: 2818 [33024/118836 (28%)] Loss: 12202.849609\n",
      "Train Epoch: 2818 [65792/118836 (55%)] Loss: 12145.443359\n",
      "Train Epoch: 2818 [98560/118836 (83%)] Loss: 12228.162109\n",
      "    epoch          : 2818\n",
      "    loss           : 12226.481515909327\n",
      "    val_loss       : 12220.050029849433\n",
      "    val_log_likelihood: -12132.849233774037\n",
      "    val_log_marginal: -12141.179112522672\n",
      "Train Epoch: 2819 [256/118836 (0%)] Loss: 12236.328125\n",
      "Train Epoch: 2819 [33024/118836 (28%)] Loss: 12188.999023\n",
      "Train Epoch: 2819 [65792/118836 (55%)] Loss: 12237.812500\n",
      "Train Epoch: 2819 [98560/118836 (83%)] Loss: 12226.110352\n",
      "    epoch          : 2819\n",
      "    loss           : 12224.740319672768\n",
      "    val_loss       : 12228.66956582061\n",
      "    val_log_likelihood: -12131.166336460918\n",
      "    val_log_marginal: -12139.522161651214\n",
      "Train Epoch: 2820 [256/118836 (0%)] Loss: 12230.843750\n",
      "Train Epoch: 2820 [33024/118836 (28%)] Loss: 12286.469727\n",
      "Train Epoch: 2820 [65792/118836 (55%)] Loss: 12279.382812\n",
      "Train Epoch: 2820 [98560/118836 (83%)] Loss: 12317.683594\n",
      "    epoch          : 2820\n",
      "    loss           : 12222.066813999172\n",
      "    val_loss       : 12222.372922016639\n",
      "    val_log_likelihood: -12133.636165445358\n",
      "    val_log_marginal: -12141.951014418826\n",
      "Train Epoch: 2821 [256/118836 (0%)] Loss: 12182.637695\n",
      "Train Epoch: 2821 [33024/118836 (28%)] Loss: 12254.442383\n",
      "Train Epoch: 2821 [65792/118836 (55%)] Loss: 12220.487305\n",
      "Train Epoch: 2821 [98560/118836 (83%)] Loss: 12341.276367\n",
      "    epoch          : 2821\n",
      "    loss           : 12227.022711661237\n",
      "    val_loss       : 12232.154887623428\n",
      "    val_log_likelihood: -12133.60568571004\n",
      "    val_log_marginal: -12142.045791593056\n",
      "Train Epoch: 2822 [256/118836 (0%)] Loss: 12233.106445\n",
      "Train Epoch: 2822 [33024/118836 (28%)] Loss: 12173.150391\n",
      "Train Epoch: 2822 [65792/118836 (55%)] Loss: 12157.287109\n",
      "Train Epoch: 2822 [98560/118836 (83%)] Loss: 12136.925781\n",
      "    epoch          : 2822\n",
      "    loss           : 12220.992780061\n",
      "    val_loss       : 12235.519820633648\n",
      "    val_log_likelihood: -12139.268799110834\n",
      "    val_log_marginal: -12147.72473934041\n",
      "Train Epoch: 2823 [256/118836 (0%)] Loss: 12236.401367\n",
      "Train Epoch: 2823 [33024/118836 (28%)] Loss: 12295.482422\n",
      "Train Epoch: 2823 [65792/118836 (55%)] Loss: 12169.712891\n",
      "Train Epoch: 2823 [98560/118836 (83%)] Loss: 12193.754883\n",
      "    epoch          : 2823\n",
      "    loss           : 12223.994798613265\n",
      "    val_loss       : 12221.525631298755\n",
      "    val_log_likelihood: -12133.202270729942\n",
      "    val_log_marginal: -12141.698359797749\n",
      "Train Epoch: 2824 [256/118836 (0%)] Loss: 12315.081055\n",
      "Train Epoch: 2824 [33024/118836 (28%)] Loss: 12286.142578\n",
      "Train Epoch: 2824 [65792/118836 (55%)] Loss: 12201.730469\n",
      "Train Epoch: 2824 [98560/118836 (83%)] Loss: 12261.859375\n",
      "    epoch          : 2824\n",
      "    loss           : 12232.216995580025\n",
      "    val_loss       : 12227.02255231255\n",
      "    val_log_likelihood: -12137.435266264732\n",
      "    val_log_marginal: -12146.167855695621\n",
      "Train Epoch: 2825 [256/118836 (0%)] Loss: 12321.085938\n",
      "Train Epoch: 2825 [33024/118836 (28%)] Loss: 12216.820312\n",
      "Train Epoch: 2825 [65792/118836 (55%)] Loss: 12200.042969\n",
      "Train Epoch: 2825 [98560/118836 (83%)] Loss: 12328.285156\n",
      "    epoch          : 2825\n",
      "    loss           : 12226.479216908343\n",
      "    val_loss       : 12230.94383625776\n",
      "    val_log_likelihood: -12131.927525977047\n",
      "    val_log_marginal: -12140.435053838222\n",
      "Train Epoch: 2826 [256/118836 (0%)] Loss: 12241.654297\n",
      "Train Epoch: 2826 [33024/118836 (28%)] Loss: 12207.509766\n",
      "Train Epoch: 2826 [65792/118836 (55%)] Loss: 12256.618164\n",
      "Train Epoch: 2826 [98560/118836 (83%)] Loss: 12165.033203\n",
      "    epoch          : 2826\n",
      "    loss           : 12222.118033369521\n",
      "    val_loss       : 12225.144821153792\n",
      "    val_log_likelihood: -12135.504703977978\n",
      "    val_log_marginal: -12144.022071252346\n",
      "Train Epoch: 2827 [256/118836 (0%)] Loss: 12260.214844\n",
      "Train Epoch: 2827 [33024/118836 (28%)] Loss: 12241.406250\n",
      "Train Epoch: 2827 [65792/118836 (55%)] Loss: 12167.454102\n",
      "Train Epoch: 2827 [98560/118836 (83%)] Loss: 12149.847656\n",
      "    epoch          : 2827\n",
      "    loss           : 12224.064729050351\n",
      "    val_loss       : 12224.557881974648\n",
      "    val_log_likelihood: -12132.941045673077\n",
      "    val_log_marginal: -12141.352791804702\n",
      "Train Epoch: 2828 [256/118836 (0%)] Loss: 12346.217773\n",
      "Train Epoch: 2828 [33024/118836 (28%)] Loss: 12294.721680\n",
      "Train Epoch: 2828 [65792/118836 (55%)] Loss: 12253.643555\n",
      "Train Epoch: 2828 [98560/118836 (83%)] Loss: 12229.215820\n",
      "    epoch          : 2828\n",
      "    loss           : 12222.666363601116\n",
      "    val_loss       : 12218.842495840889\n",
      "    val_log_likelihood: -12132.095896014269\n",
      "    val_log_marginal: -12140.565184822713\n",
      "Train Epoch: 2829 [256/118836 (0%)] Loss: 12211.537109\n",
      "Train Epoch: 2829 [33024/118836 (28%)] Loss: 12356.857422\n",
      "Train Epoch: 2829 [65792/118836 (55%)] Loss: 12248.810547\n",
      "Train Epoch: 2829 [98560/118836 (83%)] Loss: 12270.714844\n",
      "    epoch          : 2829\n",
      "    loss           : 12226.21953674266\n",
      "    val_loss       : 12223.011941861256\n",
      "    val_log_likelihood: -12135.595790522902\n",
      "    val_log_marginal: -12143.977333407995\n",
      "Train Epoch: 2830 [256/118836 (0%)] Loss: 12207.096680\n",
      "Train Epoch: 2830 [33024/118836 (28%)] Loss: 12158.781250\n",
      "Train Epoch: 2830 [65792/118836 (55%)] Loss: 12302.912109\n",
      "Train Epoch: 2830 [98560/118836 (83%)] Loss: 12237.187500\n",
      "    epoch          : 2830\n",
      "    loss           : 12223.975150401935\n",
      "    val_loss       : 12225.290391148472\n",
      "    val_log_likelihood: -12136.75863397565\n",
      "    val_log_marginal: -12145.231609241733\n",
      "Train Epoch: 2831 [256/118836 (0%)] Loss: 12254.905273\n",
      "Train Epoch: 2831 [33024/118836 (28%)] Loss: 12252.534180\n",
      "Train Epoch: 2831 [65792/118836 (55%)] Loss: 12330.445312\n",
      "Train Epoch: 2831 [98560/118836 (83%)] Loss: 12248.904297\n",
      "    epoch          : 2831\n",
      "    loss           : 12221.367553246484\n",
      "    val_loss       : 12223.811351644057\n",
      "    val_log_likelihood: -12133.152008051591\n",
      "    val_log_marginal: -12141.713579026293\n",
      "Train Epoch: 2832 [256/118836 (0%)] Loss: 12183.916016\n",
      "Train Epoch: 2832 [33024/118836 (28%)] Loss: 12205.867188\n",
      "Train Epoch: 2832 [65792/118836 (55%)] Loss: 12154.146484\n",
      "Train Epoch: 2832 [98560/118836 (83%)] Loss: 12294.303711\n",
      "    epoch          : 2832\n",
      "    loss           : 12224.090257153382\n",
      "    val_loss       : 12224.074077090761\n",
      "    val_log_likelihood: -12135.690697212312\n",
      "    val_log_marginal: -12144.117137662777\n",
      "Train Epoch: 2833 [256/118836 (0%)] Loss: 12232.296875\n",
      "Train Epoch: 2833 [33024/118836 (28%)] Loss: 12241.355469\n",
      "Train Epoch: 2833 [65792/118836 (55%)] Loss: 12245.021484\n",
      "Train Epoch: 2833 [98560/118836 (83%)] Loss: 12179.718750\n",
      "    epoch          : 2833\n",
      "    loss           : 12223.625086751706\n",
      "    val_loss       : 12223.818362589873\n",
      "    val_log_likelihood: -12130.719938352979\n",
      "    val_log_marginal: -12139.217676218112\n",
      "Train Epoch: 2834 [256/118836 (0%)] Loss: 12276.750000\n",
      "Train Epoch: 2834 [33024/118836 (28%)] Loss: 12345.184570\n",
      "Train Epoch: 2834 [65792/118836 (55%)] Loss: 12326.860352\n",
      "Train Epoch: 2834 [98560/118836 (83%)] Loss: 12276.759766\n",
      "    epoch          : 2834\n",
      "    loss           : 12224.247140747777\n",
      "    val_loss       : 12224.362013673144\n",
      "    val_log_likelihood: -12134.403456659687\n",
      "    val_log_marginal: -12142.889398927287\n",
      "Train Epoch: 2835 [256/118836 (0%)] Loss: 12215.779297\n",
      "Train Epoch: 2835 [33024/118836 (28%)] Loss: 12230.765625\n",
      "Train Epoch: 2835 [65792/118836 (55%)] Loss: 12181.980469\n",
      "Train Epoch: 2835 [98560/118836 (83%)] Loss: 12144.466797\n",
      "    epoch          : 2835\n",
      "    loss           : 12226.213904666822\n",
      "    val_loss       : 12225.360452463356\n",
      "    val_log_likelihood: -12134.066200275278\n",
      "    val_log_marginal: -12142.6770719477\n",
      "Train Epoch: 2836 [256/118836 (0%)] Loss: 12331.845703\n",
      "Train Epoch: 2836 [33024/118836 (28%)] Loss: 12255.333984\n",
      "Train Epoch: 2836 [65792/118836 (55%)] Loss: 12218.191406\n",
      "Train Epoch: 2836 [98560/118836 (83%)] Loss: 12244.480469\n",
      "    epoch          : 2836\n",
      "    loss           : 12224.520180676178\n",
      "    val_loss       : 12225.619363147487\n",
      "    val_log_likelihood: -12132.844782619934\n",
      "    val_log_marginal: -12141.265543918678\n",
      "Train Epoch: 2837 [256/118836 (0%)] Loss: 12234.677734\n",
      "Train Epoch: 2837 [33024/118836 (28%)] Loss: 12218.056641\n",
      "Train Epoch: 2837 [65792/118836 (55%)] Loss: 12267.305664\n",
      "Train Epoch: 2837 [98560/118836 (83%)] Loss: 12274.714844\n",
      "    epoch          : 2837\n",
      "    loss           : 12216.521687441842\n",
      "    val_loss       : 12226.795030231293\n",
      "    val_log_likelihood: -12131.207065336797\n",
      "    val_log_marginal: -12139.59071528057\n",
      "Train Epoch: 2838 [256/118836 (0%)] Loss: 12377.978516\n",
      "Train Epoch: 2838 [33024/118836 (28%)] Loss: 12343.820312\n",
      "Train Epoch: 2838 [65792/118836 (55%)] Loss: 12272.776367\n",
      "Train Epoch: 2838 [98560/118836 (83%)] Loss: 12203.499023\n",
      "    epoch          : 2838\n",
      "    loss           : 12223.45063601763\n",
      "    val_loss       : 12220.333188954168\n",
      "    val_log_likelihood: -12131.975767356802\n",
      "    val_log_marginal: -12140.269645756387\n",
      "Train Epoch: 2839 [256/118836 (0%)] Loss: 12253.585938\n",
      "Train Epoch: 2839 [33024/118836 (28%)] Loss: 12174.292969\n",
      "Train Epoch: 2839 [65792/118836 (55%)] Loss: 12170.550781\n",
      "Train Epoch: 2839 [98560/118836 (83%)] Loss: 12265.401367\n",
      "    epoch          : 2839\n",
      "    loss           : 12220.860038480923\n",
      "    val_loss       : 12227.862856733598\n",
      "    val_log_likelihood: -12130.401021473066\n",
      "    val_log_marginal: -12138.852741576036\n",
      "Train Epoch: 2840 [256/118836 (0%)] Loss: 12241.337891\n",
      "Train Epoch: 2840 [33024/118836 (28%)] Loss: 12201.044922\n",
      "Train Epoch: 2840 [65792/118836 (55%)] Loss: 12397.789062\n",
      "Train Epoch: 2840 [98560/118836 (83%)] Loss: 12266.511719\n",
      "    epoch          : 2840\n",
      "    loss           : 12225.792767460194\n",
      "    val_loss       : 12223.49925860784\n",
      "    val_log_likelihood: -12136.832685199544\n",
      "    val_log_marginal: -12145.232245326513\n",
      "Train Epoch: 2841 [256/118836 (0%)] Loss: 12321.399414\n",
      "Train Epoch: 2841 [33024/118836 (28%)] Loss: 12225.601562\n",
      "Train Epoch: 2841 [65792/118836 (55%)] Loss: 12262.139648\n",
      "Train Epoch: 2841 [98560/118836 (83%)] Loss: 12226.892578\n",
      "    epoch          : 2841\n",
      "    loss           : 12228.113276241987\n",
      "    val_loss       : 12221.056241225908\n",
      "    val_log_likelihood: -12135.508352880739\n",
      "    val_log_marginal: -12144.055095289266\n",
      "Train Epoch: 2842 [256/118836 (0%)] Loss: 12263.279297\n",
      "Train Epoch: 2842 [33024/118836 (28%)] Loss: 12245.976562\n",
      "Train Epoch: 2842 [65792/118836 (55%)] Loss: 12168.721680\n",
      "Train Epoch: 2842 [98560/118836 (83%)] Loss: 12145.893555\n",
      "    epoch          : 2842\n",
      "    loss           : 12221.991520465\n",
      "    val_loss       : 12229.91782621003\n",
      "    val_log_likelihood: -12130.52762791434\n",
      "    val_log_marginal: -12138.893377308475\n",
      "Train Epoch: 2843 [256/118836 (0%)] Loss: 12242.607422\n",
      "Train Epoch: 2843 [33024/118836 (28%)] Loss: 12272.111328\n",
      "Train Epoch: 2843 [65792/118836 (55%)] Loss: 12258.696289\n",
      "Train Epoch: 2843 [98560/118836 (83%)] Loss: 12230.130859\n",
      "    epoch          : 2843\n",
      "    loss           : 12224.753145193601\n",
      "    val_loss       : 12224.4925673075\n",
      "    val_log_likelihood: -12133.05906644179\n",
      "    val_log_marginal: -12141.382162844031\n",
      "Train Epoch: 2844 [256/118836 (0%)] Loss: 12299.886719\n",
      "Train Epoch: 2844 [33024/118836 (28%)] Loss: 12193.794922\n",
      "Train Epoch: 2844 [65792/118836 (55%)] Loss: 12333.578125\n",
      "Train Epoch: 2844 [98560/118836 (83%)] Loss: 12284.713867\n",
      "    epoch          : 2844\n",
      "    loss           : 12228.269753379602\n",
      "    val_loss       : 12223.018264076787\n",
      "    val_log_likelihood: -12130.337144431089\n",
      "    val_log_marginal: -12138.756045384596\n",
      "Train Epoch: 2845 [256/118836 (0%)] Loss: 12197.136719\n",
      "Train Epoch: 2845 [33024/118836 (28%)] Loss: 12258.921875\n",
      "Train Epoch: 2845 [65792/118836 (55%)] Loss: 12229.194336\n",
      "Train Epoch: 2845 [98560/118836 (83%)] Loss: 12335.416992\n",
      "    epoch          : 2845\n",
      "    loss           : 12222.64436404699\n",
      "    val_loss       : 12223.513568959159\n",
      "    val_log_likelihood: -12135.469787789494\n",
      "    val_log_marginal: -12143.920320881436\n",
      "Train Epoch: 2846 [256/118836 (0%)] Loss: 12307.648438\n",
      "Train Epoch: 2846 [33024/118836 (28%)] Loss: 12243.833008\n",
      "Train Epoch: 2846 [65792/118836 (55%)] Loss: 12127.761719\n",
      "Train Epoch: 2846 [98560/118836 (83%)] Loss: 12303.724609\n",
      "    epoch          : 2846\n",
      "    loss           : 12224.36950168657\n",
      "    val_loss       : 12218.530630717141\n",
      "    val_log_likelihood: -12136.55300367685\n",
      "    val_log_marginal: -12144.838238760498\n",
      "Train Epoch: 2847 [256/118836 (0%)] Loss: 12201.382812\n",
      "Train Epoch: 2847 [33024/118836 (28%)] Loss: 12359.676758\n",
      "Train Epoch: 2847 [65792/118836 (55%)] Loss: 12206.141602\n",
      "Train Epoch: 2847 [98560/118836 (83%)] Loss: 12323.639648\n",
      "    epoch          : 2847\n",
      "    loss           : 12220.50056849023\n",
      "    val_loss       : 12221.509663884503\n",
      "    val_log_likelihood: -12134.812845229786\n",
      "    val_log_marginal: -12143.049677604447\n",
      "Train Epoch: 2848 [256/118836 (0%)] Loss: 12352.395508\n",
      "Train Epoch: 2848 [33024/118836 (28%)] Loss: 12267.137695\n",
      "Train Epoch: 2848 [65792/118836 (55%)] Loss: 12344.667969\n",
      "Train Epoch: 2848 [98560/118836 (83%)] Loss: 12362.425781\n",
      "    epoch          : 2848\n",
      "    loss           : 12224.753440989454\n",
      "    val_loss       : 12223.934506445436\n",
      "    val_log_likelihood: -12132.029942585556\n",
      "    val_log_marginal: -12140.257515251384\n",
      "Train Epoch: 2849 [256/118836 (0%)] Loss: 12198.440430\n",
      "Train Epoch: 2849 [33024/118836 (28%)] Loss: 12403.451172\n",
      "Train Epoch: 2849 [65792/118836 (55%)] Loss: 12213.882812\n",
      "Train Epoch: 2849 [98560/118836 (83%)] Loss: 12226.935547\n",
      "    epoch          : 2849\n",
      "    loss           : 12226.051022119262\n",
      "    val_loss       : 12221.963904499158\n",
      "    val_log_likelihood: -12130.428872324752\n",
      "    val_log_marginal: -12138.696058089472\n",
      "Train Epoch: 2850 [256/118836 (0%)] Loss: 12237.139648\n",
      "Train Epoch: 2850 [33024/118836 (28%)] Loss: 12208.649414\n",
      "Train Epoch: 2850 [65792/118836 (55%)] Loss: 12253.320312\n",
      "Train Epoch: 2850 [98560/118836 (83%)] Loss: 12235.380859\n",
      "    epoch          : 2850\n",
      "    loss           : 12221.74743541279\n",
      "    val_loss       : 12225.522687519795\n",
      "    val_log_likelihood: -12136.665414986559\n",
      "    val_log_marginal: -12144.977642851454\n",
      "Train Epoch: 2851 [256/118836 (0%)] Loss: 12259.527344\n",
      "Train Epoch: 2851 [33024/118836 (28%)] Loss: 12240.708008\n",
      "Train Epoch: 2851 [65792/118836 (55%)] Loss: 12243.077148\n",
      "Train Epoch: 2851 [98560/118836 (83%)] Loss: 12198.594727\n",
      "    epoch          : 2851\n",
      "    loss           : 12224.014944718001\n",
      "    val_loss       : 12222.756313507814\n",
      "    val_log_likelihood: -12131.877144883427\n",
      "    val_log_marginal: -12140.200669179823\n",
      "Train Epoch: 2852 [256/118836 (0%)] Loss: 12337.879883\n",
      "Train Epoch: 2852 [33024/118836 (28%)] Loss: 12143.865234\n",
      "Train Epoch: 2852 [65792/118836 (55%)] Loss: 12150.498047\n",
      "Train Epoch: 2852 [98560/118836 (83%)] Loss: 12216.589844\n",
      "    epoch          : 2852\n",
      "    loss           : 12221.243277631307\n",
      "    val_loss       : 12222.678512261276\n",
      "    val_log_likelihood: -12127.955983929125\n",
      "    val_log_marginal: -12136.294219237303\n",
      "Train Epoch: 2853 [256/118836 (0%)] Loss: 12142.624023\n",
      "Train Epoch: 2853 [33024/118836 (28%)] Loss: 12251.706055\n",
      "Train Epoch: 2853 [65792/118836 (55%)] Loss: 12181.968750\n",
      "Train Epoch: 2853 [98560/118836 (83%)] Loss: 12235.177734\n",
      "    epoch          : 2853\n",
      "    loss           : 12224.228988962985\n",
      "    val_loss       : 12224.373225536256\n",
      "    val_log_likelihood: -12130.3397765457\n",
      "    val_log_marginal: -12138.764819820028\n",
      "Train Epoch: 2854 [256/118836 (0%)] Loss: 12179.194336\n",
      "Train Epoch: 2854 [33024/118836 (28%)] Loss: 12249.314453\n",
      "Train Epoch: 2854 [65792/118836 (55%)] Loss: 12261.112305\n",
      "Train Epoch: 2854 [98560/118836 (83%)] Loss: 12199.881836\n",
      "    epoch          : 2854\n",
      "    loss           : 12222.51911090002\n",
      "    val_loss       : 12223.696508412188\n",
      "    val_log_likelihood: -12132.518515269592\n",
      "    val_log_marginal: -12140.928065383987\n",
      "Train Epoch: 2855 [256/118836 (0%)] Loss: 12229.973633\n",
      "Train Epoch: 2855 [33024/118836 (28%)] Loss: 12380.685547\n",
      "Train Epoch: 2855 [65792/118836 (55%)] Loss: 12237.736328\n",
      "Train Epoch: 2855 [98560/118836 (83%)] Loss: 12243.352539\n",
      "    epoch          : 2855\n",
      "    loss           : 12223.255089756514\n",
      "    val_loss       : 12221.976954057045\n",
      "    val_log_likelihood: -12129.35104942101\n",
      "    val_log_marginal: -12137.626615317075\n",
      "Train Epoch: 2856 [256/118836 (0%)] Loss: 12253.093750\n",
      "Train Epoch: 2856 [33024/118836 (28%)] Loss: 12149.808594\n",
      "Train Epoch: 2856 [65792/118836 (55%)] Loss: 12198.734375\n",
      "Train Epoch: 2856 [98560/118836 (83%)] Loss: 12160.982422\n",
      "    epoch          : 2856\n",
      "    loss           : 12226.628958753361\n",
      "    val_loss       : 12222.217017175064\n",
      "    val_log_likelihood: -12131.650222452698\n",
      "    val_log_marginal: -12139.921684687091\n",
      "Train Epoch: 2857 [256/118836 (0%)] Loss: 12231.472656\n",
      "Train Epoch: 2857 [33024/118836 (28%)] Loss: 12175.444336\n",
      "Train Epoch: 2857 [65792/118836 (55%)] Loss: 12143.646484\n",
      "Train Epoch: 2857 [98560/118836 (83%)] Loss: 12137.671875\n",
      "    epoch          : 2857\n",
      "    loss           : 12224.00308057408\n",
      "    val_loss       : 12225.936826939143\n",
      "    val_log_likelihood: -12130.906307834472\n",
      "    val_log_marginal: -12139.2611246092\n",
      "Train Epoch: 2858 [256/118836 (0%)] Loss: 12204.271484\n",
      "Train Epoch: 2858 [33024/118836 (28%)] Loss: 12135.207031\n",
      "Train Epoch: 2858 [65792/118836 (55%)] Loss: 12254.100586\n",
      "Train Epoch: 2858 [98560/118836 (83%)] Loss: 12247.888672\n",
      "    epoch          : 2858\n",
      "    loss           : 12221.681105413823\n",
      "    val_loss       : 12225.317883183416\n",
      "    val_log_likelihood: -12129.586842334833\n",
      "    val_log_marginal: -12137.920151502665\n",
      "Train Epoch: 2859 [256/118836 (0%)] Loss: 12316.601562\n",
      "Train Epoch: 2859 [33024/118836 (28%)] Loss: 12166.723633\n",
      "Train Epoch: 2859 [65792/118836 (55%)] Loss: 12271.706055\n",
      "Train Epoch: 2859 [98560/118836 (83%)] Loss: 12223.238281\n",
      "    epoch          : 2859\n",
      "    loss           : 12219.272492601065\n",
      "    val_loss       : 12222.093617903369\n",
      "    val_log_likelihood: -12129.700524548956\n",
      "    val_log_marginal: -12137.985433806076\n",
      "Train Epoch: 2860 [256/118836 (0%)] Loss: 12244.285156\n",
      "Train Epoch: 2860 [33024/118836 (28%)] Loss: 12212.112305\n",
      "Train Epoch: 2860 [65792/118836 (55%)] Loss: 12279.630859\n",
      "Train Epoch: 2860 [98560/118836 (83%)] Loss: 12365.991211\n",
      "    epoch          : 2860\n",
      "    loss           : 12223.440873785154\n",
      "    val_loss       : 12224.409173573835\n",
      "    val_log_likelihood: -12134.064607565653\n",
      "    val_log_marginal: -12142.420675195352\n",
      "Train Epoch: 2861 [256/118836 (0%)] Loss: 12273.362305\n",
      "Train Epoch: 2861 [33024/118836 (28%)] Loss: 12189.636719\n",
      "Train Epoch: 2861 [65792/118836 (55%)] Loss: 12227.985352\n",
      "Train Epoch: 2861 [98560/118836 (83%)] Loss: 12173.246094\n",
      "    epoch          : 2861\n",
      "    loss           : 12224.77969283111\n",
      "    val_loss       : 12227.510509793712\n",
      "    val_log_likelihood: -12144.01311000827\n",
      "    val_log_marginal: -12152.456570530549\n",
      "Train Epoch: 2862 [256/118836 (0%)] Loss: 12257.141602\n",
      "Train Epoch: 2862 [33024/118836 (28%)] Loss: 12270.246094\n",
      "Train Epoch: 2862 [65792/118836 (55%)] Loss: 12205.841797\n",
      "Train Epoch: 2862 [98560/118836 (83%)] Loss: 12228.076172\n",
      "    epoch          : 2862\n",
      "    loss           : 12228.902129859387\n",
      "    val_loss       : 12242.838897441197\n",
      "    val_log_likelihood: -12137.403688320668\n",
      "    val_log_marginal: -12146.039521591529\n",
      "Train Epoch: 2863 [256/118836 (0%)] Loss: 12231.160156\n",
      "Train Epoch: 2863 [33024/118836 (28%)] Loss: 12328.871094\n",
      "Train Epoch: 2863 [65792/118836 (55%)] Loss: 12253.552734\n",
      "Train Epoch: 2863 [98560/118836 (83%)] Loss: 12273.738281\n",
      "    epoch          : 2863\n",
      "    loss           : 12227.459424110835\n",
      "    val_loss       : 12223.88303745356\n",
      "    val_log_likelihood: -12131.287772855923\n",
      "    val_log_marginal: -12139.775415359098\n",
      "Train Epoch: 2864 [256/118836 (0%)] Loss: 12194.043945\n",
      "Train Epoch: 2864 [33024/118836 (28%)] Loss: 12327.385742\n",
      "Train Epoch: 2864 [65792/118836 (55%)] Loss: 12263.061523\n",
      "Train Epoch: 2864 [98560/118836 (83%)] Loss: 12198.570312\n",
      "    epoch          : 2864\n",
      "    loss           : 12221.925411464794\n",
      "    val_loss       : 12224.604871954769\n",
      "    val_log_likelihood: -12127.31842157129\n",
      "    val_log_marginal: -12135.834739441258\n",
      "Train Epoch: 2865 [256/118836 (0%)] Loss: 12218.667969\n",
      "Train Epoch: 2865 [33024/118836 (28%)] Loss: 12170.685547\n",
      "Train Epoch: 2865 [65792/118836 (55%)] Loss: 12166.031250\n",
      "Train Epoch: 2865 [98560/118836 (83%)] Loss: 12297.156250\n",
      "    epoch          : 2865\n",
      "    loss           : 12220.475731008324\n",
      "    val_loss       : 12223.089662524695\n",
      "    val_log_likelihood: -12135.694943037894\n",
      "    val_log_marginal: -12144.194862664943\n",
      "Train Epoch: 2866 [256/118836 (0%)] Loss: 12275.944336\n",
      "Train Epoch: 2866 [33024/118836 (28%)] Loss: 12215.632812\n",
      "Train Epoch: 2866 [65792/118836 (55%)] Loss: 12183.535156\n",
      "Train Epoch: 2866 [98560/118836 (83%)] Loss: 12290.416992\n",
      "    epoch          : 2866\n",
      "    loss           : 12222.316801883011\n",
      "    val_loss       : 12221.486701991036\n",
      "    val_log_likelihood: -12135.3279770213\n",
      "    val_log_marginal: -12143.879712453256\n",
      "Train Epoch: 2867 [256/118836 (0%)] Loss: 12281.165039\n",
      "Train Epoch: 2867 [33024/118836 (28%)] Loss: 12251.474609\n",
      "Train Epoch: 2867 [65792/118836 (55%)] Loss: 12213.897461\n",
      "Train Epoch: 2867 [98560/118836 (83%)] Loss: 12238.097656\n",
      "    epoch          : 2867\n",
      "    loss           : 12223.076165897693\n",
      "    val_loss       : 12222.00642358014\n",
      "    val_log_likelihood: -12133.5050711784\n",
      "    val_log_marginal: -12141.901754221864\n",
      "Train Epoch: 2868 [256/118836 (0%)] Loss: 12206.619141\n",
      "Train Epoch: 2868 [33024/118836 (28%)] Loss: 12215.106445\n",
      "Train Epoch: 2868 [65792/118836 (55%)] Loss: 12185.003906\n",
      "Train Epoch: 2868 [98560/118836 (83%)] Loss: 12248.437500\n",
      "    epoch          : 2868\n",
      "    loss           : 12224.882265980408\n",
      "    val_loss       : 12224.017000897948\n",
      "    val_log_likelihood: -12133.066346315394\n",
      "    val_log_marginal: -12141.456227242661\n",
      "Train Epoch: 2869 [256/118836 (0%)] Loss: 12250.996094\n",
      "Train Epoch: 2869 [33024/118836 (28%)] Loss: 12348.510742\n",
      "Train Epoch: 2869 [65792/118836 (55%)] Loss: 12320.247070\n",
      "Train Epoch: 2869 [98560/118836 (83%)] Loss: 12257.863281\n",
      "    epoch          : 2869\n",
      "    loss           : 12225.254803168942\n",
      "    val_loss       : 12222.881157072907\n",
      "    val_log_likelihood: -12131.26431031586\n",
      "    val_log_marginal: -12139.889390004359\n",
      "Train Epoch: 2870 [256/118836 (0%)] Loss: 12161.393555\n",
      "Train Epoch: 2870 [33024/118836 (28%)] Loss: 12212.284180\n",
      "Train Epoch: 2870 [65792/118836 (55%)] Loss: 12259.455078\n",
      "Train Epoch: 2870 [98560/118836 (83%)] Loss: 12267.943359\n",
      "    epoch          : 2870\n",
      "    loss           : 12226.726752481389\n",
      "    val_loss       : 12219.45617163166\n",
      "    val_log_likelihood: -12128.337413571393\n",
      "    val_log_marginal: -12136.75511517138\n",
      "Train Epoch: 2871 [256/118836 (0%)] Loss: 12190.603516\n",
      "Train Epoch: 2871 [33024/118836 (28%)] Loss: 12301.257812\n",
      "Train Epoch: 2871 [65792/118836 (55%)] Loss: 12171.821289\n",
      "Train Epoch: 2871 [98560/118836 (83%)] Loss: 12220.978516\n",
      "    epoch          : 2871\n",
      "    loss           : 12228.916471515717\n",
      "    val_loss       : 12221.244811112669\n",
      "    val_log_likelihood: -12134.022421681142\n",
      "    val_log_marginal: -12142.798619047771\n",
      "Train Epoch: 2872 [256/118836 (0%)] Loss: 12204.746094\n",
      "Train Epoch: 2872 [33024/118836 (28%)] Loss: 12201.697266\n",
      "Train Epoch: 2872 [65792/118836 (55%)] Loss: 12255.968750\n",
      "Train Epoch: 2872 [98560/118836 (83%)] Loss: 12231.446289\n",
      "    epoch          : 2872\n",
      "    loss           : 12226.642014481235\n",
      "    val_loss       : 12221.335549677862\n",
      "    val_log_likelihood: -12132.403261993382\n",
      "    val_log_marginal: -12140.881426879467\n",
      "Train Epoch: 2873 [256/118836 (0%)] Loss: 12250.485352\n",
      "Train Epoch: 2873 [33024/118836 (28%)] Loss: 12243.144531\n",
      "Train Epoch: 2873 [65792/118836 (55%)] Loss: 12227.792969\n",
      "Train Epoch: 2873 [98560/118836 (83%)] Loss: 12179.913086\n",
      "    epoch          : 2873\n",
      "    loss           : 12228.599316487025\n",
      "    val_loss       : 12222.806853731103\n",
      "    val_log_likelihood: -12131.581679719811\n",
      "    val_log_marginal: -12140.010014756608\n",
      "Train Epoch: 2874 [256/118836 (0%)] Loss: 12239.979492\n",
      "Train Epoch: 2874 [33024/118836 (28%)] Loss: 12142.973633\n",
      "Train Epoch: 2874 [65792/118836 (55%)] Loss: 12142.291016\n",
      "Train Epoch: 2874 [98560/118836 (83%)] Loss: 12271.644531\n",
      "    epoch          : 2874\n",
      "    loss           : 12227.493686834418\n",
      "    val_loss       : 12221.709682576524\n",
      "    val_log_likelihood: -12127.345396505376\n",
      "    val_log_marginal: -12135.749760148723\n",
      "Train Epoch: 2875 [256/118836 (0%)] Loss: 12355.668945\n",
      "Train Epoch: 2875 [33024/118836 (28%)] Loss: 12169.325195\n",
      "Train Epoch: 2875 [65792/118836 (55%)] Loss: 12198.302734\n",
      "Train Epoch: 2875 [98560/118836 (83%)] Loss: 12259.903320\n",
      "    epoch          : 2875\n",
      "    loss           : 12225.009577743745\n",
      "    val_loss       : 12224.646506771553\n",
      "    val_log_likelihood: -12134.846255944996\n",
      "    val_log_marginal: -12143.24631941501\n",
      "Train Epoch: 2876 [256/118836 (0%)] Loss: 12237.966797\n",
      "Train Epoch: 2876 [33024/118836 (28%)] Loss: 12347.052734\n",
      "Train Epoch: 2876 [65792/118836 (55%)] Loss: 12241.193359\n",
      "Train Epoch: 2876 [98560/118836 (83%)] Loss: 12314.653320\n",
      "    epoch          : 2876\n",
      "    loss           : 12223.505233696496\n",
      "    val_loss       : 12222.722609300346\n",
      "    val_log_likelihood: -12130.321037854113\n",
      "    val_log_marginal: -12138.695384362472\n",
      "Train Epoch: 2877 [256/118836 (0%)] Loss: 12253.480469\n",
      "Train Epoch: 2877 [33024/118836 (28%)] Loss: 12326.330078\n",
      "Train Epoch: 2877 [65792/118836 (55%)] Loss: 12375.011719\n",
      "Train Epoch: 2877 [98560/118836 (83%)] Loss: 12274.958984\n",
      "    epoch          : 2877\n",
      "    loss           : 12226.076866373294\n",
      "    val_loss       : 12223.468057225897\n",
      "    val_log_likelihood: -12128.018620437862\n",
      "    val_log_marginal: -12136.39436014628\n",
      "Train Epoch: 2878 [256/118836 (0%)] Loss: 12111.968750\n",
      "Train Epoch: 2878 [33024/118836 (28%)] Loss: 12266.334961\n",
      "Train Epoch: 2878 [65792/118836 (55%)] Loss: 12226.871094\n",
      "Train Epoch: 2878 [98560/118836 (83%)] Loss: 12315.619141\n",
      "    epoch          : 2878\n",
      "    loss           : 12222.970529136941\n",
      "    val_loss       : 12220.347459975881\n",
      "    val_log_likelihood: -12131.007566945824\n",
      "    val_log_marginal: -12139.331150029662\n",
      "Train Epoch: 2879 [256/118836 (0%)] Loss: 12228.375000\n",
      "Train Epoch: 2879 [33024/118836 (28%)] Loss: 12169.221680\n",
      "Train Epoch: 2879 [65792/118836 (55%)] Loss: 12158.781250\n",
      "Train Epoch: 2879 [98560/118836 (83%)] Loss: 12149.277344\n",
      "    epoch          : 2879\n",
      "    loss           : 12219.966344861456\n",
      "    val_loss       : 12223.135707332372\n",
      "    val_log_likelihood: -12131.081910411496\n",
      "    val_log_marginal: -12139.474657519559\n",
      "Train Epoch: 2880 [256/118836 (0%)] Loss: 12285.052734\n",
      "Train Epoch: 2880 [33024/118836 (28%)] Loss: 12239.470703\n",
      "Train Epoch: 2880 [65792/118836 (55%)] Loss: 12164.126953\n",
      "Train Epoch: 2880 [98560/118836 (83%)] Loss: 12228.414062\n",
      "    epoch          : 2880\n",
      "    loss           : 12222.904583301022\n",
      "    val_loss       : 12223.518780504732\n",
      "    val_log_likelihood: -12131.8668236921\n",
      "    val_log_marginal: -12140.308170803715\n",
      "Train Epoch: 2881 [256/118836 (0%)] Loss: 12188.523438\n",
      "Train Epoch: 2881 [33024/118836 (28%)] Loss: 12169.027344\n",
      "Train Epoch: 2881 [65792/118836 (55%)] Loss: 12299.462891\n",
      "Train Epoch: 2881 [98560/118836 (83%)] Loss: 12245.664062\n",
      "    epoch          : 2881\n",
      "    loss           : 12220.011669154517\n",
      "    val_loss       : 12218.442959227956\n",
      "    val_log_likelihood: -12129.422942029829\n",
      "    val_log_marginal: -12137.682198633243\n",
      "Train Epoch: 2882 [256/118836 (0%)] Loss: 12215.416016\n",
      "Train Epoch: 2882 [33024/118836 (28%)] Loss: 12222.861328\n",
      "Train Epoch: 2882 [65792/118836 (55%)] Loss: 12235.110352\n",
      "Train Epoch: 2882 [98560/118836 (83%)] Loss: 12215.493164\n",
      "    epoch          : 2882\n",
      "    loss           : 12220.359364499327\n",
      "    val_loss       : 12225.888750469845\n",
      "    val_log_likelihood: -12132.738173820047\n",
      "    val_log_marginal: -12141.078681404908\n",
      "Train Epoch: 2883 [256/118836 (0%)] Loss: 12255.576172\n",
      "Train Epoch: 2883 [33024/118836 (28%)] Loss: 12200.228516\n",
      "Train Epoch: 2883 [65792/118836 (55%)] Loss: 12196.086914\n",
      "Train Epoch: 2883 [98560/118836 (83%)] Loss: 12171.264648\n",
      "    epoch          : 2883\n",
      "    loss           : 12219.958676786084\n",
      "    val_loss       : 12220.248185090113\n",
      "    val_log_likelihood: -12129.739820648521\n",
      "    val_log_marginal: -12138.169125612229\n",
      "Train Epoch: 2884 [256/118836 (0%)] Loss: 12247.922852\n",
      "Train Epoch: 2884 [33024/118836 (28%)] Loss: 12204.132812\n",
      "Train Epoch: 2884 [65792/118836 (55%)] Loss: 12246.393555\n",
      "Train Epoch: 2884 [98560/118836 (83%)] Loss: 12206.646484\n",
      "    epoch          : 2884\n",
      "    loss           : 12223.120840279933\n",
      "    val_loss       : 12224.510617740076\n",
      "    val_log_likelihood: -12130.831168740953\n",
      "    val_log_marginal: -12139.38159393491\n",
      "Train Epoch: 2885 [256/118836 (0%)] Loss: 12303.247070\n",
      "Train Epoch: 2885 [33024/118836 (28%)] Loss: 12159.466797\n",
      "Train Epoch: 2885 [65792/118836 (55%)] Loss: 12259.968750\n",
      "Train Epoch: 2885 [98560/118836 (83%)] Loss: 12258.420898\n",
      "    epoch          : 2885\n",
      "    loss           : 12224.505373274658\n",
      "    val_loss       : 12222.639838149053\n",
      "    val_log_likelihood: -12131.453188165582\n",
      "    val_log_marginal: -12139.814034092842\n",
      "Train Epoch: 2886 [256/118836 (0%)] Loss: 12245.761719\n",
      "Train Epoch: 2886 [33024/118836 (28%)] Loss: 12298.924805\n",
      "Train Epoch: 2886 [65792/118836 (55%)] Loss: 12267.385742\n",
      "Train Epoch: 2886 [98560/118836 (83%)] Loss: 12266.097656\n",
      "    epoch          : 2886\n",
      "    loss           : 12220.216648411653\n",
      "    val_loss       : 12229.625712783181\n",
      "    val_log_likelihood: -12131.53055372467\n",
      "    val_log_marginal: -12139.919349309519\n",
      "Train Epoch: 2887 [256/118836 (0%)] Loss: 12219.393555\n",
      "Train Epoch: 2887 [33024/118836 (28%)] Loss: 12197.576172\n",
      "Train Epoch: 2887 [65792/118836 (55%)] Loss: 12255.879883\n",
      "Train Epoch: 2887 [98560/118836 (83%)] Loss: 12165.795898\n",
      "    epoch          : 2887\n",
      "    loss           : 12222.84096037531\n",
      "    val_loss       : 12220.363589724297\n",
      "    val_log_likelihood: -12132.945224294355\n",
      "    val_log_marginal: -12141.24112467762\n",
      "Train Epoch: 2888 [256/118836 (0%)] Loss: 12278.603516\n",
      "Train Epoch: 2888 [33024/118836 (28%)] Loss: 12264.634766\n",
      "Train Epoch: 2888 [65792/118836 (55%)] Loss: 12295.886719\n",
      "Train Epoch: 2888 [98560/118836 (83%)] Loss: 12426.641602\n",
      "    epoch          : 2888\n",
      "    loss           : 12224.318282962418\n",
      "    val_loss       : 12220.38020940203\n",
      "    val_log_likelihood: -12131.917600580282\n",
      "    val_log_marginal: -12140.268455900803\n",
      "Train Epoch: 2889 [256/118836 (0%)] Loss: 12270.728516\n",
      "Train Epoch: 2889 [33024/118836 (28%)] Loss: 12193.238281\n",
      "Train Epoch: 2889 [65792/118836 (55%)] Loss: 12215.933594\n",
      "Train Epoch: 2889 [98560/118836 (83%)] Loss: 12270.099609\n",
      "    epoch          : 2889\n",
      "    loss           : 12221.579950501447\n",
      "    val_loss       : 12221.26254181651\n",
      "    val_log_likelihood: -12127.914134712313\n",
      "    val_log_marginal: -12136.235696116326\n",
      "Train Epoch: 2890 [256/118836 (0%)] Loss: 12171.952148\n",
      "Train Epoch: 2890 [33024/118836 (28%)] Loss: 12229.597656\n",
      "Train Epoch: 2890 [65792/118836 (55%)] Loss: 12169.592773\n",
      "Train Epoch: 2890 [98560/118836 (83%)] Loss: 12418.585938\n",
      "    epoch          : 2890\n",
      "    loss           : 12222.945567747105\n",
      "    val_loss       : 12221.667456660194\n",
      "    val_log_likelihood: -12128.13461489997\n",
      "    val_log_marginal: -12136.426476037663\n",
      "Train Epoch: 2891 [256/118836 (0%)] Loss: 12347.785156\n",
      "Train Epoch: 2891 [33024/118836 (28%)] Loss: 12174.507812\n",
      "Train Epoch: 2891 [65792/118836 (55%)] Loss: 12189.067383\n",
      "Train Epoch: 2891 [98560/118836 (83%)] Loss: 12374.578125\n",
      "    epoch          : 2891\n",
      "    loss           : 12220.571102150538\n",
      "    val_loss       : 12219.856818845756\n",
      "    val_log_likelihood: -12131.642965519024\n",
      "    val_log_marginal: -12139.92836896369\n",
      "Train Epoch: 2892 [256/118836 (0%)] Loss: 12218.262695\n",
      "Train Epoch: 2892 [33024/118836 (28%)] Loss: 12222.487305\n",
      "Train Epoch: 2892 [65792/118836 (55%)] Loss: 12289.652344\n",
      "Train Epoch: 2892 [98560/118836 (83%)] Loss: 12240.055664\n",
      "    epoch          : 2892\n",
      "    loss           : 12220.794356777295\n",
      "    val_loss       : 12222.139940605277\n",
      "    val_log_likelihood: -12134.318104935639\n",
      "    val_log_marginal: -12142.88646036893\n",
      "Train Epoch: 2893 [256/118836 (0%)] Loss: 12259.841797\n",
      "Train Epoch: 2893 [33024/118836 (28%)] Loss: 12199.520508\n",
      "Train Epoch: 2893 [65792/118836 (55%)] Loss: 12312.399414\n",
      "Train Epoch: 2893 [98560/118836 (83%)] Loss: 12273.836914\n",
      "    epoch          : 2893\n",
      "    loss           : 12224.072635410206\n",
      "    val_loss       : 12227.051902895115\n",
      "    val_log_likelihood: -12128.896459011838\n",
      "    val_log_marginal: -12137.263961907054\n",
      "Train Epoch: 2894 [256/118836 (0%)] Loss: 12243.103516\n",
      "Train Epoch: 2894 [33024/118836 (28%)] Loss: 12237.626953\n",
      "Train Epoch: 2894 [65792/118836 (55%)] Loss: 12260.244141\n",
      "Train Epoch: 2894 [98560/118836 (83%)] Loss: 12165.741211\n",
      "    epoch          : 2894\n",
      "    loss           : 12223.504959063534\n",
      "    val_loss       : 12220.840991115061\n",
      "    val_log_likelihood: -12129.093737399193\n",
      "    val_log_marginal: -12137.455636069575\n",
      "Train Epoch: 2895 [256/118836 (0%)] Loss: 12206.798828\n",
      "Train Epoch: 2895 [33024/118836 (28%)] Loss: 12258.904297\n",
      "Train Epoch: 2895 [65792/118836 (55%)] Loss: 12172.875977\n",
      "Train Epoch: 2895 [98560/118836 (83%)] Loss: 12233.566406\n",
      "    epoch          : 2895\n",
      "    loss           : 12222.359123468517\n",
      "    val_loss       : 12226.819666889243\n",
      "    val_log_likelihood: -12138.705122227822\n",
      "    val_log_marginal: -12147.30390801927\n",
      "Train Epoch: 2896 [256/118836 (0%)] Loss: 12202.906250\n",
      "Train Epoch: 2896 [33024/118836 (28%)] Loss: 12134.966797\n",
      "Train Epoch: 2896 [65792/118836 (55%)] Loss: 12296.147461\n",
      "Train Epoch: 2896 [98560/118836 (83%)] Loss: 12288.119141\n",
      "    epoch          : 2896\n",
      "    loss           : 12226.384594383271\n",
      "    val_loss       : 12230.435265181473\n",
      "    val_log_likelihood: -12128.05873381281\n",
      "    val_log_marginal: -12136.765247170086\n",
      "Train Epoch: 2897 [256/118836 (0%)] Loss: 12114.910156\n",
      "Train Epoch: 2897 [33024/118836 (28%)] Loss: 12224.736328\n",
      "Train Epoch: 2897 [65792/118836 (55%)] Loss: 12243.462891\n",
      "Train Epoch: 2897 [98560/118836 (83%)] Loss: 12141.314453\n",
      "    epoch          : 2897\n",
      "    loss           : 12222.395444162272\n",
      "    val_loss       : 12225.209698692865\n",
      "    val_log_likelihood: -12128.774719389732\n",
      "    val_log_marginal: -12137.180064770795\n",
      "Train Epoch: 2898 [256/118836 (0%)] Loss: 12247.476562\n",
      "Train Epoch: 2898 [33024/118836 (28%)] Loss: 12220.482422\n",
      "Train Epoch: 2898 [65792/118836 (55%)] Loss: 12227.166016\n",
      "Train Epoch: 2898 [98560/118836 (83%)] Loss: 12293.304688\n",
      "    epoch          : 2898\n",
      "    loss           : 12225.713998203577\n",
      "    val_loss       : 12224.69218922222\n",
      "    val_log_likelihood: -12133.070776791254\n",
      "    val_log_marginal: -12141.48629346854\n",
      "Train Epoch: 2899 [256/118836 (0%)] Loss: 12222.598633\n",
      "Train Epoch: 2899 [33024/118836 (28%)] Loss: 12365.878906\n",
      "Train Epoch: 2899 [65792/118836 (55%)] Loss: 12247.260742\n",
      "Train Epoch: 2899 [98560/118836 (83%)] Loss: 12226.370117\n",
      "    epoch          : 2899\n",
      "    loss           : 12218.811838942307\n",
      "    val_loss       : 12226.701370827928\n",
      "    val_log_likelihood: -12131.776312099359\n",
      "    val_log_marginal: -12140.341476713244\n",
      "Train Epoch: 2900 [256/118836 (0%)] Loss: 12233.791016\n",
      "Train Epoch: 2900 [33024/118836 (28%)] Loss: 12230.714844\n",
      "Train Epoch: 2900 [65792/118836 (55%)] Loss: 12367.400391\n",
      "Train Epoch: 2900 [98560/118836 (83%)] Loss: 12303.151367\n",
      "    epoch          : 2900\n",
      "    loss           : 12224.298929739194\n",
      "    val_loss       : 12221.485474969597\n",
      "    val_log_likelihood: -12131.373781275848\n",
      "    val_log_marginal: -12139.923643184307\n",
      "Saving checkpoint: saved/models/SelfiesAutoencodingOperad/0905_154251/checkpoint-epoch2900.pth ...\n",
      "Train Epoch: 2901 [256/118836 (0%)] Loss: 12282.672852\n",
      "Train Epoch: 2901 [33024/118836 (28%)] Loss: 12246.975586\n",
      "Train Epoch: 2901 [65792/118836 (55%)] Loss: 12235.155273\n",
      "Train Epoch: 2901 [98560/118836 (83%)] Loss: 12287.808594\n",
      "    epoch          : 2901\n",
      "    loss           : 12226.747401972187\n",
      "    val_loss       : 12224.274940559055\n",
      "    val_log_likelihood: -12131.56446685665\n",
      "    val_log_marginal: -12139.948533204688\n",
      "Train Epoch: 2902 [256/118836 (0%)] Loss: 12247.675781\n",
      "Train Epoch: 2902 [33024/118836 (28%)] Loss: 12351.984375\n",
      "Train Epoch: 2902 [65792/118836 (55%)] Loss: 12183.882812\n",
      "Train Epoch: 2902 [98560/118836 (83%)] Loss: 12300.453125\n",
      "    epoch          : 2902\n",
      "    loss           : 12226.233673070461\n",
      "    val_loss       : 12221.542416087823\n",
      "    val_log_likelihood: -12131.926832771143\n",
      "    val_log_marginal: -12140.28223501005\n",
      "Train Epoch: 2903 [256/118836 (0%)] Loss: 12175.162109\n",
      "Train Epoch: 2903 [33024/118836 (28%)] Loss: 12298.767578\n",
      "Train Epoch: 2903 [65792/118836 (55%)] Loss: 12238.564453\n",
      "Train Epoch: 2903 [98560/118836 (83%)] Loss: 12253.472656\n",
      "    epoch          : 2903\n",
      "    loss           : 12227.755223357372\n",
      "    val_loss       : 12219.769185910174\n",
      "    val_log_likelihood: -12132.410147849463\n",
      "    val_log_marginal: -12140.759408150045\n",
      "Train Epoch: 2904 [256/118836 (0%)] Loss: 12141.280273\n",
      "Train Epoch: 2904 [33024/118836 (28%)] Loss: 12228.533203\n",
      "Train Epoch: 2904 [65792/118836 (55%)] Loss: 12175.215820\n",
      "Train Epoch: 2904 [98560/118836 (83%)] Loss: 12283.839844\n",
      "    epoch          : 2904\n",
      "    loss           : 12225.729648243641\n",
      "    val_loss       : 12223.096275758988\n",
      "    val_log_likelihood: -12136.269752894956\n",
      "    val_log_marginal: -12144.61916850995\n",
      "Train Epoch: 2905 [256/118836 (0%)] Loss: 12169.539062\n",
      "Train Epoch: 2905 [33024/118836 (28%)] Loss: 12196.411133\n",
      "Train Epoch: 2905 [65792/118836 (55%)] Loss: 12220.652344\n",
      "Train Epoch: 2905 [98560/118836 (83%)] Loss: 12219.606445\n",
      "    epoch          : 2905\n",
      "    loss           : 12217.740691235009\n",
      "    val_loss       : 12222.277901402871\n",
      "    val_log_likelihood: -12130.16021424602\n",
      "    val_log_marginal: -12138.60134601631\n",
      "Train Epoch: 2906 [256/118836 (0%)] Loss: 12191.423828\n",
      "Train Epoch: 2906 [33024/118836 (28%)] Loss: 12223.670898\n",
      "Train Epoch: 2906 [65792/118836 (55%)] Loss: 12249.023438\n",
      "Train Epoch: 2906 [98560/118836 (83%)] Loss: 12270.956055\n",
      "    epoch          : 2906\n",
      "    loss           : 12223.213396918942\n",
      "    val_loss       : 12225.60050231405\n",
      "    val_log_likelihood: -12132.248725056865\n",
      "    val_log_marginal: -12140.536630844395\n",
      "Train Epoch: 2907 [256/118836 (0%)] Loss: 12281.848633\n",
      "Train Epoch: 2907 [33024/118836 (28%)] Loss: 12158.943359\n",
      "Train Epoch: 2907 [65792/118836 (55%)] Loss: 12255.059570\n",
      "Train Epoch: 2907 [98560/118836 (83%)] Loss: 12335.829102\n",
      "    epoch          : 2907\n",
      "    loss           : 12227.549697419096\n",
      "    val_loss       : 12223.17927207591\n",
      "    val_log_likelihood: -12131.266085252531\n",
      "    val_log_marginal: -12139.665932102684\n",
      "Train Epoch: 2908 [256/118836 (0%)] Loss: 12180.907227\n",
      "Train Epoch: 2908 [33024/118836 (28%)] Loss: 12203.648438\n",
      "Train Epoch: 2908 [65792/118836 (55%)] Loss: 12357.832031\n",
      "Train Epoch: 2908 [98560/118836 (83%)] Loss: 12188.288086\n",
      "    epoch          : 2908\n",
      "    loss           : 12221.95900052988\n",
      "    val_loss       : 12225.973001632505\n",
      "    val_log_likelihood: -12133.01011570125\n",
      "    val_log_marginal: -12141.467945602668\n",
      "Train Epoch: 2909 [256/118836 (0%)] Loss: 12174.565430\n",
      "Train Epoch: 2909 [33024/118836 (28%)] Loss: 12281.197266\n",
      "Train Epoch: 2909 [65792/118836 (55%)] Loss: 12231.638672\n",
      "Train Epoch: 2909 [98560/118836 (83%)] Loss: 12219.835938\n",
      "    epoch          : 2909\n",
      "    loss           : 12225.91363423413\n",
      "    val_loss       : 12223.593414994015\n",
      "    val_log_likelihood: -12132.762010830233\n",
      "    val_log_marginal: -12141.137921197322\n",
      "Train Epoch: 2910 [256/118836 (0%)] Loss: 12220.076172\n",
      "Train Epoch: 2910 [33024/118836 (28%)] Loss: 12221.205078\n",
      "Train Epoch: 2910 [65792/118836 (55%)] Loss: 12393.171875\n",
      "Train Epoch: 2910 [98560/118836 (83%)] Loss: 12214.179688\n",
      "    epoch          : 2910\n",
      "    loss           : 12224.425002423231\n",
      "    val_loss       : 12220.180555440676\n",
      "    val_log_likelihood: -12131.333206194427\n",
      "    val_log_marginal: -12139.669077410976\n",
      "Train Epoch: 2911 [256/118836 (0%)] Loss: 12179.565430\n",
      "Train Epoch: 2911 [33024/118836 (28%)] Loss: 12147.066406\n",
      "Train Epoch: 2911 [65792/118836 (55%)] Loss: 12184.621094\n",
      "Train Epoch: 2911 [98560/118836 (83%)] Loss: 12249.068359\n",
      "    epoch          : 2911\n",
      "    loss           : 12218.545072438481\n",
      "    val_loss       : 12217.04445950205\n",
      "    val_log_likelihood: -12130.628611100341\n",
      "    val_log_marginal: -12138.97369971354\n",
      "Train Epoch: 2912 [256/118836 (0%)] Loss: 12263.550781\n",
      "Train Epoch: 2912 [33024/118836 (28%)] Loss: 12194.179688\n",
      "Train Epoch: 2912 [65792/118836 (55%)] Loss: 12351.755859\n",
      "Train Epoch: 2912 [98560/118836 (83%)] Loss: 12244.846680\n",
      "    epoch          : 2912\n",
      "    loss           : 12223.509912957505\n",
      "    val_loss       : 12221.156757608309\n",
      "    val_log_likelihood: -12129.753040671527\n",
      "    val_log_marginal: -12138.113172784768\n",
      "Train Epoch: 2913 [256/118836 (0%)] Loss: 12352.609375\n",
      "Train Epoch: 2913 [33024/118836 (28%)] Loss: 12255.154297\n",
      "Train Epoch: 2913 [65792/118836 (55%)] Loss: 12297.164062\n",
      "Train Epoch: 2913 [98560/118836 (83%)] Loss: 12254.609375\n",
      "    epoch          : 2913\n",
      "    loss           : 12222.966584438327\n",
      "    val_loss       : 12220.193949242504\n",
      "    val_log_likelihood: -12129.634307311053\n",
      "    val_log_marginal: -12138.076679254322\n",
      "Train Epoch: 2914 [256/118836 (0%)] Loss: 12237.486328\n",
      "Train Epoch: 2914 [33024/118836 (28%)] Loss: 12167.200195\n",
      "Train Epoch: 2914 [65792/118836 (55%)] Loss: 12263.883789\n",
      "Train Epoch: 2914 [98560/118836 (83%)] Loss: 12198.526367\n",
      "    epoch          : 2914\n",
      "    loss           : 12224.216362470273\n",
      "    val_loss       : 12220.007815011588\n",
      "    val_log_likelihood: -12130.744830761478\n",
      "    val_log_marginal: -12139.017047600999\n",
      "Train Epoch: 2915 [256/118836 (0%)] Loss: 12257.359375\n",
      "Train Epoch: 2915 [33024/118836 (28%)] Loss: 12294.973633\n",
      "Train Epoch: 2915 [65792/118836 (55%)] Loss: 12237.398438\n",
      "Train Epoch: 2915 [98560/118836 (83%)] Loss: 12186.245117\n",
      "    epoch          : 2915\n",
      "    loss           : 12223.723037828267\n",
      "    val_loss       : 12224.490141515162\n",
      "    val_log_likelihood: -12130.618395885029\n",
      "    val_log_marginal: -12138.854019536457\n",
      "Train Epoch: 2916 [256/118836 (0%)] Loss: 12308.665039\n",
      "Train Epoch: 2916 [33024/118836 (28%)] Loss: 12351.082031\n",
      "Train Epoch: 2916 [65792/118836 (55%)] Loss: 12289.650391\n",
      "Train Epoch: 2916 [98560/118836 (83%)] Loss: 12156.173828\n",
      "    epoch          : 2916\n",
      "    loss           : 12221.788823730873\n",
      "    val_loss       : 12221.537026312273\n",
      "    val_log_likelihood: -12131.236373358664\n",
      "    val_log_marginal: -12139.561426877975\n",
      "Train Epoch: 2917 [256/118836 (0%)] Loss: 12228.427734\n",
      "Train Epoch: 2917 [33024/118836 (28%)] Loss: 12268.639648\n",
      "Train Epoch: 2917 [65792/118836 (55%)] Loss: 12166.943359\n",
      "Train Epoch: 2917 [98560/118836 (83%)] Loss: 12267.257812\n",
      "    epoch          : 2917\n",
      "    loss           : 12222.515476213553\n",
      "    val_loss       : 12220.8376205915\n",
      "    val_log_likelihood: -12132.165412240229\n",
      "    val_log_marginal: -12140.44272159388\n",
      "Train Epoch: 2918 [256/118836 (0%)] Loss: 12311.761719\n",
      "Train Epoch: 2918 [33024/118836 (28%)] Loss: 12325.069336\n",
      "Train Epoch: 2918 [65792/118836 (55%)] Loss: 12179.191406\n",
      "Train Epoch: 2918 [98560/118836 (83%)] Loss: 12293.080078\n",
      "    epoch          : 2918\n",
      "    loss           : 12221.798259150124\n",
      "    val_loss       : 12219.142148338944\n",
      "    val_log_likelihood: -12131.770293760339\n",
      "    val_log_marginal: -12140.070342520703\n",
      "Train Epoch: 2919 [256/118836 (0%)] Loss: 12353.116211\n",
      "Train Epoch: 2919 [33024/118836 (28%)] Loss: 12206.425781\n",
      "Train Epoch: 2919 [65792/118836 (55%)] Loss: 12211.400391\n",
      "Train Epoch: 2919 [98560/118836 (83%)] Loss: 12206.581055\n",
      "    epoch          : 2919\n",
      "    loss           : 12222.486774484336\n",
      "    val_loss       : 12221.243942921856\n",
      "    val_log_likelihood: -12134.74021531224\n",
      "    val_log_marginal: -12143.116076396891\n",
      "Train Epoch: 2920 [256/118836 (0%)] Loss: 12243.435547\n",
      "Train Epoch: 2920 [33024/118836 (28%)] Loss: 12277.026367\n",
      "Train Epoch: 2920 [65792/118836 (55%)] Loss: 12233.652344\n",
      "Train Epoch: 2920 [98560/118836 (83%)] Loss: 12209.522461\n",
      "    epoch          : 2920\n",
      "    loss           : 12224.478355691688\n",
      "    val_loss       : 12224.88713003408\n",
      "    val_log_likelihood: -12127.492663745865\n",
      "    val_log_marginal: -12135.879019946546\n",
      "Train Epoch: 2921 [256/118836 (0%)] Loss: 12241.800781\n",
      "Train Epoch: 2921 [33024/118836 (28%)] Loss: 12358.347656\n",
      "Train Epoch: 2921 [65792/118836 (55%)] Loss: 12277.583984\n",
      "Train Epoch: 2921 [98560/118836 (83%)] Loss: 12291.171875\n",
      "    epoch          : 2921\n",
      "    loss           : 12220.275088205644\n",
      "    val_loss       : 12223.429496662153\n",
      "    val_log_likelihood: -12132.432685684193\n",
      "    val_log_marginal: -12140.831439822805\n",
      "Train Epoch: 2922 [256/118836 (0%)] Loss: 12211.650391\n",
      "Train Epoch: 2922 [33024/118836 (28%)] Loss: 12252.580078\n",
      "Train Epoch: 2922 [65792/118836 (55%)] Loss: 12252.603516\n",
      "Train Epoch: 2922 [98560/118836 (83%)] Loss: 12324.170898\n",
      "    epoch          : 2922\n",
      "    loss           : 12221.15875271402\n",
      "    val_loss       : 12225.513819372947\n",
      "    val_log_likelihood: -12134.082384880323\n",
      "    val_log_marginal: -12142.47667260666\n",
      "Train Epoch: 2923 [256/118836 (0%)] Loss: 12199.681641\n",
      "Train Epoch: 2923 [33024/118836 (28%)] Loss: 12174.795898\n",
      "Train Epoch: 2923 [65792/118836 (55%)] Loss: 12125.492188\n",
      "Train Epoch: 2923 [98560/118836 (83%)] Loss: 12205.321289\n",
      "    epoch          : 2923\n",
      "    loss           : 12223.81341178143\n",
      "    val_loss       : 12221.448978540724\n",
      "    val_log_likelihood: -12127.748971903433\n",
      "    val_log_marginal: -12136.068375971887\n",
      "Train Epoch: 2924 [256/118836 (0%)] Loss: 12231.575195\n",
      "Train Epoch: 2924 [33024/118836 (28%)] Loss: 12224.650391\n",
      "Train Epoch: 2924 [65792/118836 (55%)] Loss: 12249.478516\n",
      "Train Epoch: 2924 [98560/118836 (83%)] Loss: 12262.486328\n",
      "    epoch          : 2924\n",
      "    loss           : 12219.769347084368\n",
      "    val_loss       : 12228.117820154772\n",
      "    val_log_likelihood: -12133.229087023108\n",
      "    val_log_marginal: -12141.621614653997\n",
      "Train Epoch: 2925 [256/118836 (0%)] Loss: 12292.525391\n",
      "Train Epoch: 2925 [33024/118836 (28%)] Loss: 12319.869141\n",
      "Train Epoch: 2925 [65792/118836 (55%)] Loss: 12191.387695\n",
      "Train Epoch: 2925 [98560/118836 (83%)] Loss: 12185.028320\n",
      "    epoch          : 2925\n",
      "    loss           : 12222.138347969654\n",
      "    val_loss       : 12218.623122792858\n",
      "    val_log_likelihood: -12132.342548076922\n",
      "    val_log_marginal: -12140.658646286578\n",
      "Train Epoch: 2926 [256/118836 (0%)] Loss: 12334.303711\n",
      "Train Epoch: 2926 [33024/118836 (28%)] Loss: 12179.471680\n",
      "Train Epoch: 2926 [65792/118836 (55%)] Loss: 12340.532227\n",
      "Train Epoch: 2926 [98560/118836 (83%)] Loss: 12275.583984\n",
      "    epoch          : 2926\n",
      "    loss           : 12221.360583385029\n",
      "    val_loss       : 12221.860159499503\n",
      "    val_log_likelihood: -12132.241141633065\n",
      "    val_log_marginal: -12140.702463167587\n",
      "Train Epoch: 2927 [256/118836 (0%)] Loss: 12241.691406\n",
      "Train Epoch: 2927 [33024/118836 (28%)] Loss: 12181.228516\n",
      "Train Epoch: 2927 [65792/118836 (55%)] Loss: 12198.666016\n",
      "Train Epoch: 2927 [98560/118836 (83%)] Loss: 12164.896484\n",
      "    epoch          : 2927\n",
      "    loss           : 12222.104392188792\n",
      "    val_loss       : 12220.973795298909\n",
      "    val_log_likelihood: -12128.814390605614\n",
      "    val_log_marginal: -12137.068833146555\n",
      "Train Epoch: 2928 [256/118836 (0%)] Loss: 12059.807617\n",
      "Train Epoch: 2928 [33024/118836 (28%)] Loss: 12284.113281\n",
      "Train Epoch: 2928 [65792/118836 (55%)] Loss: 12283.085938\n",
      "Train Epoch: 2928 [98560/118836 (83%)] Loss: 12348.853516\n",
      "    epoch          : 2928\n",
      "    loss           : 12222.572019586178\n",
      "    val_loss       : 12222.846887550284\n",
      "    val_log_likelihood: -12129.731952575734\n",
      "    val_log_marginal: -12137.998991195876\n",
      "Train Epoch: 2929 [256/118836 (0%)] Loss: 12229.166992\n",
      "Train Epoch: 2929 [33024/118836 (28%)] Loss: 12193.003906\n",
      "Train Epoch: 2929 [65792/118836 (55%)] Loss: 12303.806641\n",
      "Train Epoch: 2929 [98560/118836 (83%)] Loss: 12302.577148\n",
      "    epoch          : 2929\n",
      "    loss           : 12221.411162860577\n",
      "    val_loss       : 12225.213836836127\n",
      "    val_log_likelihood: -12128.20115572012\n",
      "    val_log_marginal: -12136.482246584628\n",
      "Train Epoch: 2930 [256/118836 (0%)] Loss: 12224.581055\n",
      "Train Epoch: 2930 [33024/118836 (28%)] Loss: 12314.326172\n",
      "Train Epoch: 2930 [65792/118836 (55%)] Loss: 12293.791016\n",
      "Train Epoch: 2930 [98560/118836 (83%)] Loss: 12167.841797\n",
      "    epoch          : 2930\n",
      "    loss           : 12223.141525149918\n",
      "    val_loss       : 12218.867894419958\n",
      "    val_log_likelihood: -12129.297526041666\n",
      "    val_log_marginal: -12137.601421158242\n",
      "Train Epoch: 2931 [256/118836 (0%)] Loss: 12211.003906\n",
      "Train Epoch: 2931 [33024/118836 (28%)] Loss: 12283.766602\n",
      "Train Epoch: 2931 [65792/118836 (55%)] Loss: 12230.723633\n",
      "Train Epoch: 2931 [98560/118836 (83%)] Loss: 12229.126953\n",
      "    epoch          : 2931\n",
      "    loss           : 12228.081228837107\n",
      "    val_loss       : 12221.919119178256\n",
      "    val_log_likelihood: -12132.458647384203\n",
      "    val_log_marginal: -12140.867592247314\n",
      "Train Epoch: 2932 [256/118836 (0%)] Loss: 12201.929688\n",
      "Train Epoch: 2932 [33024/118836 (28%)] Loss: 12171.435547\n",
      "Train Epoch: 2932 [65792/118836 (55%)] Loss: 12236.292969\n",
      "Train Epoch: 2932 [98560/118836 (83%)] Loss: 12245.695312\n",
      "    epoch          : 2932\n",
      "    loss           : 12224.843246937035\n",
      "    val_loss       : 12218.577100577346\n",
      "    val_log_likelihood: -12127.298529744365\n",
      "    val_log_marginal: -12135.827612334973\n",
      "Train Epoch: 2933 [256/118836 (0%)] Loss: 12278.884766\n",
      "Train Epoch: 2933 [33024/118836 (28%)] Loss: 12306.347656\n",
      "Train Epoch: 2933 [65792/118836 (55%)] Loss: 12262.075195\n",
      "Train Epoch: 2933 [98560/118836 (83%)] Loss: 12235.820312\n",
      "    epoch          : 2933\n",
      "    loss           : 12220.590998016181\n",
      "    val_loss       : 12222.85996253916\n",
      "    val_log_likelihood: -12131.822140586228\n",
      "    val_log_marginal: -12140.279049369003\n",
      "Train Epoch: 2934 [256/118836 (0%)] Loss: 12200.331055\n",
      "Train Epoch: 2934 [33024/118836 (28%)] Loss: 12159.946289\n",
      "Train Epoch: 2934 [65792/118836 (55%)] Loss: 12198.521484\n",
      "Train Epoch: 2934 [98560/118836 (83%)] Loss: 12284.908203\n",
      "    epoch          : 2934\n",
      "    loss           : 12220.15446359336\n",
      "    val_loss       : 12221.063108817567\n",
      "    val_log_likelihood: -12127.153230652915\n",
      "    val_log_marginal: -12135.566398049443\n",
      "Train Epoch: 2935 [256/118836 (0%)] Loss: 12200.264648\n",
      "Train Epoch: 2935 [33024/118836 (28%)] Loss: 12283.424805\n",
      "Train Epoch: 2935 [65792/118836 (55%)] Loss: 12182.957031\n",
      "Train Epoch: 2935 [98560/118836 (83%)] Loss: 12175.751953\n",
      "    epoch          : 2935\n",
      "    loss           : 12220.884097943808\n",
      "    val_loss       : 12224.390984122634\n",
      "    val_log_likelihood: -12130.223718594914\n",
      "    val_log_marginal: -12138.72610709765\n",
      "Train Epoch: 2936 [256/118836 (0%)] Loss: 12195.307617\n",
      "Train Epoch: 2936 [33024/118836 (28%)] Loss: 12241.147461\n",
      "Train Epoch: 2936 [65792/118836 (55%)] Loss: 12342.965820\n",
      "Train Epoch: 2936 [98560/118836 (83%)] Loss: 12202.506836\n",
      "    epoch          : 2936\n",
      "    loss           : 12218.684377907877\n",
      "    val_loss       : 12226.299391097355\n",
      "    val_log_likelihood: -12131.236765437603\n",
      "    val_log_marginal: -12139.934463953598\n",
      "Train Epoch: 2937 [256/118836 (0%)] Loss: 12291.006836\n",
      "Train Epoch: 2937 [33024/118836 (28%)] Loss: 12195.477539\n",
      "Train Epoch: 2937 [65792/118836 (55%)] Loss: 12253.668945\n",
      "Train Epoch: 2937 [98560/118836 (83%)] Loss: 12293.879883\n",
      "    epoch          : 2937\n",
      "    loss           : 12224.469423335402\n",
      "    val_loss       : 12219.842972265222\n",
      "    val_log_likelihood: -12129.487606945306\n",
      "    val_log_marginal: -12138.098644153928\n",
      "Train Epoch: 2938 [256/118836 (0%)] Loss: 12297.903320\n",
      "Train Epoch: 2938 [33024/118836 (28%)] Loss: 12222.410156\n",
      "Train Epoch: 2938 [65792/118836 (55%)] Loss: 12239.064453\n",
      "Train Epoch: 2938 [98560/118836 (83%)] Loss: 12153.381836\n",
      "    epoch          : 2938\n",
      "    loss           : 12222.638438760081\n",
      "    val_loss       : 12221.720284151228\n",
      "    val_log_likelihood: -12129.82060070306\n",
      "    val_log_marginal: -12138.393133819385\n",
      "Train Epoch: 2939 [256/118836 (0%)] Loss: 12195.580078\n",
      "Train Epoch: 2939 [33024/118836 (28%)] Loss: 12168.667969\n",
      "Train Epoch: 2939 [65792/118836 (55%)] Loss: 12318.173828\n",
      "Train Epoch: 2939 [98560/118836 (83%)] Loss: 12230.488281\n",
      "    epoch          : 2939\n",
      "    loss           : 12222.419266794614\n",
      "    val_loss       : 12221.69835240668\n",
      "    val_log_likelihood: -12131.26868101866\n",
      "    val_log_marginal: -12139.79981085278\n",
      "Train Epoch: 2940 [256/118836 (0%)] Loss: 12282.902344\n",
      "Train Epoch: 2940 [33024/118836 (28%)] Loss: 12200.010742\n",
      "Train Epoch: 2940 [65792/118836 (55%)] Loss: 12407.671875\n",
      "Train Epoch: 2940 [98560/118836 (83%)] Loss: 12218.801758\n",
      "    epoch          : 2940\n",
      "    loss           : 12223.258229134355\n",
      "    val_loss       : 12224.318649353181\n",
      "    val_log_likelihood: -12127.078481699753\n",
      "    val_log_marginal: -12135.562804459412\n",
      "Train Epoch: 2941 [256/118836 (0%)] Loss: 12265.998047\n",
      "Train Epoch: 2941 [33024/118836 (28%)] Loss: 12329.645508\n",
      "Train Epoch: 2941 [65792/118836 (55%)] Loss: 12355.621094\n",
      "Train Epoch: 2941 [98560/118836 (83%)] Loss: 12186.525391\n",
      "    epoch          : 2941\n",
      "    loss           : 12218.351455070047\n",
      "    val_loss       : 12219.266902182368\n",
      "    val_log_likelihood: -12125.821194071805\n",
      "    val_log_marginal: -12134.313104342102\n",
      "Train Epoch: 2942 [256/118836 (0%)] Loss: 12323.683594\n",
      "Train Epoch: 2942 [33024/118836 (28%)] Loss: 12285.231445\n",
      "Train Epoch: 2942 [65792/118836 (55%)] Loss: 12227.689453\n",
      "Train Epoch: 2942 [98560/118836 (83%)] Loss: 12245.044922\n",
      "    epoch          : 2942\n",
      "    loss           : 12222.294391348738\n",
      "    val_loss       : 12221.36653125749\n",
      "    val_log_likelihood: -12127.547856408964\n",
      "    val_log_marginal: -12136.096356629434\n",
      "Train Epoch: 2943 [256/118836 (0%)] Loss: 12207.406250\n",
      "Train Epoch: 2943 [33024/118836 (28%)] Loss: 12276.095703\n",
      "Train Epoch: 2943 [65792/118836 (55%)] Loss: 12167.404297\n",
      "Train Epoch: 2943 [98560/118836 (83%)] Loss: 12240.049805\n",
      "    epoch          : 2943\n",
      "    loss           : 12220.942024335713\n",
      "    val_loss       : 12220.808638825416\n",
      "    val_log_likelihood: -12130.632993434656\n",
      "    val_log_marginal: -12139.143135742283\n",
      "Train Epoch: 2944 [256/118836 (0%)] Loss: 12289.017578\n",
      "Train Epoch: 2944 [33024/118836 (28%)] Loss: 12280.519531\n",
      "Train Epoch: 2944 [65792/118836 (55%)] Loss: 12234.788086\n",
      "Train Epoch: 2944 [98560/118836 (83%)] Loss: 12462.449219\n",
      "    epoch          : 2944\n",
      "    loss           : 12219.372714084471\n",
      "    val_loss       : 12222.892689939268\n",
      "    val_log_likelihood: -12127.97845084393\n",
      "    val_log_marginal: -12136.470134814701\n",
      "Train Epoch: 2945 [256/118836 (0%)] Loss: 12236.731445\n",
      "Train Epoch: 2945 [33024/118836 (28%)] Loss: 12133.430664\n",
      "Train Epoch: 2945 [65792/118836 (55%)] Loss: 12224.432617\n",
      "Train Epoch: 2945 [98560/118836 (83%)] Loss: 12338.281250\n",
      "    epoch          : 2945\n",
      "    loss           : 12220.50002552471\n",
      "    val_loss       : 12219.493542710143\n",
      "    val_log_likelihood: -12126.960456084575\n",
      "    val_log_marginal: -12135.544088678667\n",
      "Train Epoch: 2946 [256/118836 (0%)] Loss: 12187.744141\n",
      "Train Epoch: 2946 [33024/118836 (28%)] Loss: 12186.484375\n",
      "Train Epoch: 2946 [65792/118836 (55%)] Loss: 12330.111328\n",
      "Train Epoch: 2946 [98560/118836 (83%)] Loss: 12208.126953\n",
      "    epoch          : 2946\n",
      "    loss           : 12222.39650343776\n",
      "    val_loss       : 12218.13760915599\n",
      "    val_log_likelihood: -12130.948671099566\n",
      "    val_log_marginal: -12139.532710316238\n",
      "Train Epoch: 2947 [256/118836 (0%)] Loss: 12140.653320\n",
      "Train Epoch: 2947 [33024/118836 (28%)] Loss: 12221.252930\n",
      "Train Epoch: 2947 [65792/118836 (55%)] Loss: 12144.211914\n",
      "Train Epoch: 2947 [98560/118836 (83%)] Loss: 12270.049805\n",
      "    epoch          : 2947\n",
      "    loss           : 12221.404014487696\n",
      "    val_loss       : 12221.208087205134\n",
      "    val_log_likelihood: -12125.830404615126\n",
      "    val_log_marginal: -12134.377532918894\n",
      "Train Epoch: 2948 [256/118836 (0%)] Loss: 12199.883789\n",
      "Train Epoch: 2948 [33024/118836 (28%)] Loss: 12207.828125\n",
      "Train Epoch: 2948 [65792/118836 (55%)] Loss: 12188.334961\n",
      "Train Epoch: 2948 [98560/118836 (83%)] Loss: 12228.116211\n",
      "    epoch          : 2948\n",
      "    loss           : 12225.48643054694\n",
      "    val_loss       : 12223.869994157334\n",
      "    val_log_likelihood: -12125.534943167133\n",
      "    val_log_marginal: -12134.042448169472\n",
      "Train Epoch: 2949 [256/118836 (0%)] Loss: 12155.867188\n",
      "Train Epoch: 2949 [33024/118836 (28%)] Loss: 12232.576172\n",
      "Train Epoch: 2949 [65792/118836 (55%)] Loss: 12208.105469\n",
      "Train Epoch: 2949 [98560/118836 (83%)] Loss: 12177.588867\n",
      "    epoch          : 2949\n",
      "    loss           : 12220.29337552988\n",
      "    val_loss       : 12221.482307846463\n",
      "    val_log_likelihood: -12128.15356150486\n",
      "    val_log_marginal: -12136.639184433603\n",
      "Train Epoch: 2950 [256/118836 (0%)] Loss: 12268.787109\n",
      "Train Epoch: 2950 [33024/118836 (28%)] Loss: 12227.100586\n",
      "Train Epoch: 2950 [65792/118836 (55%)] Loss: 12331.483398\n",
      "Train Epoch: 2950 [98560/118836 (83%)] Loss: 12267.265625\n",
      "    epoch          : 2950\n",
      "    loss           : 12221.27740546164\n",
      "    val_loss       : 12220.224473007262\n",
      "    val_log_likelihood: -12128.5473060122\n",
      "    val_log_marginal: -12137.1282615133\n",
      "Train Epoch: 2951 [256/118836 (0%)] Loss: 12132.165039\n",
      "Train Epoch: 2951 [33024/118836 (28%)] Loss: 12200.775391\n",
      "Train Epoch: 2951 [65792/118836 (55%)] Loss: 12234.559570\n",
      "Train Epoch: 2951 [98560/118836 (83%)] Loss: 12276.382812\n",
      "    epoch          : 2951\n",
      "    loss           : 12222.896477266853\n",
      "    val_loss       : 12223.955992629019\n",
      "    val_log_likelihood: -12129.999767046631\n",
      "    val_log_marginal: -12138.593035628914\n",
      "Train Epoch: 2952 [256/118836 (0%)] Loss: 12358.298828\n",
      "Train Epoch: 2952 [33024/118836 (28%)] Loss: 12214.561523\n",
      "Train Epoch: 2952 [65792/118836 (55%)] Loss: 12287.331055\n",
      "Train Epoch: 2952 [98560/118836 (83%)] Loss: 12243.361328\n",
      "    epoch          : 2952\n",
      "    loss           : 12220.859335258996\n",
      "    val_loss       : 12223.026698598867\n",
      "    val_log_likelihood: -12126.722277094965\n",
      "    val_log_marginal: -12135.141602727215\n",
      "Train Epoch: 2953 [256/118836 (0%)] Loss: 12202.379883\n",
      "Train Epoch: 2953 [33024/118836 (28%)] Loss: 12256.943359\n",
      "Train Epoch: 2953 [65792/118836 (55%)] Loss: 12207.298828\n",
      "Train Epoch: 2953 [98560/118836 (83%)] Loss: 12288.366211\n",
      "    epoch          : 2953\n",
      "    loss           : 12220.45009030578\n",
      "    val_loss       : 12222.425124126034\n",
      "    val_log_likelihood: -12129.669563398213\n",
      "    val_log_marginal: -12138.265956734162\n",
      "Train Epoch: 2954 [256/118836 (0%)] Loss: 12273.101562\n",
      "Train Epoch: 2954 [33024/118836 (28%)] Loss: 12276.687500\n",
      "Train Epoch: 2954 [65792/118836 (55%)] Loss: 12204.162109\n",
      "Train Epoch: 2954 [98560/118836 (83%)] Loss: 12261.585938\n",
      "    epoch          : 2954\n",
      "    loss           : 12218.384290671527\n",
      "    val_loss       : 12224.843588903694\n",
      "    val_log_likelihood: -12126.722935890974\n",
      "    val_log_marginal: -12135.355171640145\n",
      "Train Epoch: 2955 [256/118836 (0%)] Loss: 12290.643555\n",
      "Train Epoch: 2955 [33024/118836 (28%)] Loss: 12311.517578\n",
      "Train Epoch: 2955 [65792/118836 (55%)] Loss: 12228.559570\n",
      "Train Epoch: 2955 [98560/118836 (83%)] Loss: 12304.646484\n",
      "    epoch          : 2955\n",
      "    loss           : 12220.957482294252\n",
      "    val_loss       : 12221.450884152855\n",
      "    val_log_likelihood: -12126.168223027813\n",
      "    val_log_marginal: -12134.692805806855\n",
      "Train Epoch: 2956 [256/118836 (0%)] Loss: 12172.255859\n",
      "Train Epoch: 2956 [33024/118836 (28%)] Loss: 12239.192383\n",
      "Train Epoch: 2956 [65792/118836 (55%)] Loss: 12270.259766\n",
      "Train Epoch: 2956 [98560/118836 (83%)] Loss: 12280.380859\n",
      "    epoch          : 2956\n",
      "    loss           : 12223.263103223222\n",
      "    val_loss       : 12219.476875533659\n",
      "    val_log_likelihood: -12129.23262930366\n",
      "    val_log_marginal: -12137.868431001676\n",
      "Train Epoch: 2957 [256/118836 (0%)] Loss: 12275.370117\n",
      "Train Epoch: 2957 [33024/118836 (28%)] Loss: 12230.103516\n",
      "Train Epoch: 2957 [65792/118836 (55%)] Loss: 12245.295898\n",
      "Train Epoch: 2957 [98560/118836 (83%)] Loss: 12248.576172\n",
      "    epoch          : 2957\n",
      "    loss           : 12219.36716585246\n",
      "    val_loss       : 12224.572963092087\n",
      "    val_log_likelihood: -12131.304005279415\n",
      "    val_log_marginal: -12139.935973311935\n",
      "Train Epoch: 2958 [256/118836 (0%)] Loss: 12294.303711\n",
      "Train Epoch: 2958 [33024/118836 (28%)] Loss: 12224.010742\n",
      "Train Epoch: 2958 [65792/118836 (55%)] Loss: 12254.606445\n",
      "Train Epoch: 2958 [98560/118836 (83%)] Loss: 12246.472656\n",
      "    epoch          : 2958\n",
      "    loss           : 12223.134010222808\n",
      "    val_loss       : 12222.288097707917\n",
      "    val_log_likelihood: -12127.79473205516\n",
      "    val_log_marginal: -12136.434818557787\n",
      "Train Epoch: 2959 [256/118836 (0%)] Loss: 12196.738281\n",
      "Train Epoch: 2959 [33024/118836 (28%)] Loss: 12302.248047\n",
      "Train Epoch: 2959 [65792/118836 (55%)] Loss: 12219.652344\n",
      "Train Epoch: 2959 [98560/118836 (83%)] Loss: 12199.238281\n",
      "    epoch          : 2959\n",
      "    loss           : 12221.363676721465\n",
      "    val_loss       : 12223.676793874918\n",
      "    val_log_likelihood: -12131.975158317824\n",
      "    val_log_marginal: -12140.523529187421\n",
      "Train Epoch: 2960 [256/118836 (0%)] Loss: 12146.564453\n",
      "Train Epoch: 2960 [33024/118836 (28%)] Loss: 12324.270508\n",
      "Train Epoch: 2960 [65792/118836 (55%)] Loss: 12189.267578\n",
      "Train Epoch: 2960 [98560/118836 (83%)] Loss: 12217.706055\n",
      "    epoch          : 2960\n",
      "    loss           : 12221.282023980304\n",
      "    val_loss       : 12221.92803550849\n",
      "    val_log_likelihood: -12126.74039608535\n",
      "    val_log_marginal: -12135.440590063527\n",
      "Train Epoch: 2961 [256/118836 (0%)] Loss: 12157.425781\n",
      "Train Epoch: 2961 [33024/118836 (28%)] Loss: 12296.997070\n",
      "Train Epoch: 2961 [65792/118836 (55%)] Loss: 12249.103516\n",
      "Train Epoch: 2961 [98560/118836 (83%)] Loss: 12106.250000\n",
      "    epoch          : 2961\n",
      "    loss           : 12220.254277004498\n",
      "    val_loss       : 12219.871134072835\n",
      "    val_log_likelihood: -12126.553757302006\n",
      "    val_log_marginal: -12135.162870609513\n",
      "Train Epoch: 2962 [256/118836 (0%)] Loss: 12259.075195\n",
      "Train Epoch: 2962 [33024/118836 (28%)] Loss: 12156.094727\n",
      "Train Epoch: 2962 [65792/118836 (55%)] Loss: 12248.708984\n",
      "Train Epoch: 2962 [98560/118836 (83%)] Loss: 12240.541016\n",
      "    epoch          : 2962\n",
      "    loss           : 12222.308887607267\n",
      "    val_loss       : 12225.607516097809\n",
      "    val_log_likelihood: -12129.615330819634\n",
      "    val_log_marginal: -12138.381309037122\n",
      "Train Epoch: 2963 [256/118836 (0%)] Loss: 12244.081055\n",
      "Train Epoch: 2963 [33024/118836 (28%)] Loss: 12289.962891\n",
      "Train Epoch: 2963 [65792/118836 (55%)] Loss: 12170.988281\n",
      "Train Epoch: 2963 [98560/118836 (83%)] Loss: 12226.828125\n",
      "    epoch          : 2963\n",
      "    loss           : 12222.36399642654\n",
      "    val_loss       : 12224.590271605812\n",
      "    val_log_likelihood: -12127.053041156172\n",
      "    val_log_marginal: -12135.667983174724\n",
      "Train Epoch: 2964 [256/118836 (0%)] Loss: 12174.328125\n",
      "Train Epoch: 2964 [33024/118836 (28%)] Loss: 12233.425781\n",
      "Train Epoch: 2964 [65792/118836 (55%)] Loss: 12323.553711\n",
      "Train Epoch: 2964 [98560/118836 (83%)] Loss: 12293.186523\n",
      "    epoch          : 2964\n",
      "    loss           : 12220.392131927212\n",
      "    val_loss       : 12221.517713761485\n",
      "    val_log_likelihood: -12125.760043004291\n",
      "    val_log_marginal: -12134.355603129074\n",
      "Train Epoch: 2965 [256/118836 (0%)] Loss: 12206.567383\n",
      "Train Epoch: 2965 [33024/118836 (28%)] Loss: 12179.913086\n",
      "Train Epoch: 2965 [65792/118836 (55%)] Loss: 12226.974609\n",
      "Train Epoch: 2965 [98560/118836 (83%)] Loss: 12245.019531\n",
      "    epoch          : 2965\n",
      "    loss           : 12220.07173622958\n",
      "    val_loss       : 12215.859306773396\n",
      "    val_log_likelihood: -12128.447223945408\n",
      "    val_log_marginal: -12137.03945347071\n",
      "Train Epoch: 2966 [256/118836 (0%)] Loss: 12200.905273\n",
      "Train Epoch: 2966 [33024/118836 (28%)] Loss: 12304.158203\n",
      "Train Epoch: 2966 [65792/118836 (55%)] Loss: 12234.507812\n",
      "Train Epoch: 2966 [98560/118836 (83%)] Loss: 12236.936523\n",
      "    epoch          : 2966\n",
      "    loss           : 12220.6079608018\n",
      "    val_loss       : 12219.448464776695\n",
      "    val_log_likelihood: -12128.545910069013\n",
      "    val_log_marginal: -12137.071796182761\n",
      "Train Epoch: 2967 [256/118836 (0%)] Loss: 12293.494141\n",
      "Train Epoch: 2967 [33024/118836 (28%)] Loss: 12292.453125\n",
      "Train Epoch: 2967 [65792/118836 (55%)] Loss: 12313.495117\n",
      "Train Epoch: 2967 [98560/118836 (83%)] Loss: 12337.013672\n",
      "    epoch          : 2967\n",
      "    loss           : 12217.283159506824\n",
      "    val_loss       : 12220.532271370117\n",
      "    val_log_likelihood: -12130.673128457145\n",
      "    val_log_marginal: -12139.42889390371\n",
      "Train Epoch: 2968 [256/118836 (0%)] Loss: 12271.155273\n",
      "Train Epoch: 2968 [33024/118836 (28%)] Loss: 12217.861328\n",
      "Train Epoch: 2968 [65792/118836 (55%)] Loss: 12167.261719\n",
      "Train Epoch: 2968 [98560/118836 (83%)] Loss: 12193.349609\n",
      "    epoch          : 2968\n",
      "    loss           : 12223.633209586953\n",
      "    val_loss       : 12223.2436474189\n",
      "    val_log_likelihood: -12129.557170666614\n",
      "    val_log_marginal: -12138.266994297288\n",
      "Train Epoch: 2969 [256/118836 (0%)] Loss: 12191.482422\n",
      "Train Epoch: 2969 [33024/118836 (28%)] Loss: 12283.077148\n",
      "Train Epoch: 2969 [65792/118836 (55%)] Loss: 12317.604492\n",
      "Train Epoch: 2969 [98560/118836 (83%)] Loss: 12292.921875\n",
      "    epoch          : 2969\n",
      "    loss           : 12219.642397028794\n",
      "    val_loss       : 12224.256203809398\n",
      "    val_log_likelihood: -12122.78182382134\n",
      "    val_log_marginal: -12131.404358883005\n",
      "Train Epoch: 2970 [256/118836 (0%)] Loss: 12160.052734\n",
      "Train Epoch: 2970 [33024/118836 (28%)] Loss: 12271.905273\n",
      "Train Epoch: 2970 [65792/118836 (55%)] Loss: 12236.243164\n",
      "Train Epoch: 2970 [98560/118836 (83%)] Loss: 12346.720703\n",
      "    epoch          : 2970\n",
      "    loss           : 12223.319923975134\n",
      "    val_loss       : 12219.200995937528\n",
      "    val_log_likelihood: -12129.50129449054\n",
      "    val_log_marginal: -12138.196931660254\n",
      "Train Epoch: 2971 [256/118836 (0%)] Loss: 12216.507812\n",
      "Train Epoch: 2971 [33024/118836 (28%)] Loss: 12320.950195\n",
      "Train Epoch: 2971 [65792/118836 (55%)] Loss: 12314.500000\n",
      "Train Epoch: 2971 [98560/118836 (83%)] Loss: 12230.918945\n",
      "    epoch          : 2971\n",
      "    loss           : 12223.129102047145\n",
      "    val_loss       : 12221.99703336046\n",
      "    val_log_likelihood: -12126.8362811143\n",
      "    val_log_marginal: -12135.547529968797\n",
      "Train Epoch: 2972 [256/118836 (0%)] Loss: 12188.174805\n",
      "Train Epoch: 2972 [33024/118836 (28%)] Loss: 12173.869141\n",
      "Train Epoch: 2972 [65792/118836 (55%)] Loss: 12230.726562\n",
      "Train Epoch: 2972 [98560/118836 (83%)] Loss: 12251.921875\n",
      "    epoch          : 2972\n",
      "    loss           : 12220.764776061053\n",
      "    val_loss       : 12218.928556236373\n",
      "    val_log_likelihood: -12129.310270141905\n",
      "    val_log_marginal: -12138.161635308898\n",
      "Train Epoch: 2973 [256/118836 (0%)] Loss: 12276.218750\n",
      "Train Epoch: 2973 [33024/118836 (28%)] Loss: 12211.215820\n",
      "Train Epoch: 2973 [65792/118836 (55%)] Loss: 12152.554688\n",
      "Train Epoch: 2973 [98560/118836 (83%)] Loss: 12198.989258\n",
      "    epoch          : 2973\n",
      "    loss           : 12217.104652443912\n",
      "    val_loss       : 12217.052501181643\n",
      "    val_log_likelihood: -12130.083133982114\n",
      "    val_log_marginal: -12138.802389193972\n",
      "Train Epoch: 2974 [256/118836 (0%)] Loss: 12222.091797\n",
      "Train Epoch: 2974 [33024/118836 (28%)] Loss: 12279.125000\n",
      "Train Epoch: 2974 [65792/118836 (55%)] Loss: 12279.847656\n",
      "Train Epoch: 2974 [98560/118836 (83%)] Loss: 12232.607422\n",
      "    epoch          : 2974\n",
      "    loss           : 12220.066987179489\n",
      "    val_loss       : 12228.94857390301\n",
      "    val_log_likelihood: -12126.177220326716\n",
      "    val_log_marginal: -12134.820959163331\n",
      "Train Epoch: 2975 [256/118836 (0%)] Loss: 12330.378906\n",
      "Train Epoch: 2975 [33024/118836 (28%)] Loss: 12199.484375\n",
      "Train Epoch: 2975 [65792/118836 (55%)] Loss: 12297.474609\n",
      "Train Epoch: 2975 [98560/118836 (83%)] Loss: 12227.687500\n",
      "    epoch          : 2975\n",
      "    loss           : 12221.878313365902\n",
      "    val_loss       : 12218.004975049398\n",
      "    val_log_likelihood: -12127.902499321495\n",
      "    val_log_marginal: -12136.565431632229\n",
      "Train Epoch: 2976 [256/118836 (0%)] Loss: 12238.994141\n",
      "Train Epoch: 2976 [33024/118836 (28%)] Loss: 12205.046875\n",
      "Train Epoch: 2976 [65792/118836 (55%)] Loss: 12268.003906\n",
      "Train Epoch: 2976 [98560/118836 (83%)] Loss: 12258.407227\n",
      "    epoch          : 2976\n",
      "    loss           : 12217.854075068495\n",
      "    val_loss       : 12216.718008795637\n",
      "    val_log_likelihood: -12127.206388285775\n",
      "    val_log_marginal: -12135.846479095877\n",
      "Train Epoch: 2977 [256/118836 (0%)] Loss: 12360.668945\n",
      "Train Epoch: 2977 [33024/118836 (28%)] Loss: 12262.156250\n",
      "Train Epoch: 2977 [65792/118836 (55%)] Loss: 12238.348633\n",
      "Train Epoch: 2977 [98560/118836 (83%)] Loss: 12170.417969\n",
      "    epoch          : 2977\n",
      "    loss           : 12221.489113872518\n",
      "    val_loss       : 12222.56036047032\n",
      "    val_log_likelihood: -12128.474940065395\n",
      "    val_log_marginal: -12137.278203404805\n",
      "Train Epoch: 2978 [256/118836 (0%)] Loss: 12196.706055\n",
      "Train Epoch: 2978 [33024/118836 (28%)] Loss: 12257.395508\n",
      "Train Epoch: 2978 [65792/118836 (55%)] Loss: 12255.076172\n",
      "Train Epoch: 2978 [98560/118836 (83%)] Loss: 12229.083984\n",
      "    epoch          : 2978\n",
      "    loss           : 12220.238050396765\n",
      "    val_loss       : 12221.095538703268\n",
      "    val_log_likelihood: -12130.44774251706\n",
      "    val_log_marginal: -12138.971208736031\n",
      "Train Epoch: 2979 [256/118836 (0%)] Loss: 12301.875977\n",
      "Train Epoch: 2979 [33024/118836 (28%)] Loss: 12272.507812\n",
      "Train Epoch: 2979 [65792/118836 (55%)] Loss: 12366.623047\n",
      "Train Epoch: 2979 [98560/118836 (83%)] Loss: 12238.158203\n",
      "    epoch          : 2979\n",
      "    loss           : 12219.360853333073\n",
      "    val_loss       : 12220.795677355269\n",
      "    val_log_likelihood: -12129.435520542545\n",
      "    val_log_marginal: -12138.003218113507\n",
      "Train Epoch: 2980 [256/118836 (0%)] Loss: 12309.102539\n",
      "Train Epoch: 2980 [33024/118836 (28%)] Loss: 12194.517578\n",
      "Train Epoch: 2980 [65792/118836 (55%)] Loss: 12277.589844\n",
      "Train Epoch: 2980 [98560/118836 (83%)] Loss: 12193.271484\n",
      "    epoch          : 2980\n",
      "    loss           : 12220.186460595018\n",
      "    val_loss       : 12219.919900571564\n",
      "    val_log_likelihood: -12125.231917842742\n",
      "    val_log_marginal: -12133.775327615653\n",
      "Train Epoch: 2981 [256/118836 (0%)] Loss: 12153.174805\n",
      "Train Epoch: 2981 [33024/118836 (28%)] Loss: 12196.791016\n",
      "Train Epoch: 2981 [65792/118836 (55%)] Loss: 12335.376953\n",
      "Train Epoch: 2981 [98560/118836 (83%)] Loss: 12252.832031\n",
      "    epoch          : 2981\n",
      "    loss           : 12216.854704624173\n",
      "    val_loss       : 12222.870075967305\n",
      "    val_log_likelihood: -12126.15620977435\n",
      "    val_log_marginal: -12134.774427845392\n",
      "Train Epoch: 2982 [256/118836 (0%)] Loss: 12229.290039\n",
      "Train Epoch: 2982 [33024/118836 (28%)] Loss: 12144.155273\n",
      "Train Epoch: 2982 [65792/118836 (55%)] Loss: 12254.397461\n",
      "Train Epoch: 2982 [98560/118836 (83%)] Loss: 12328.967773\n",
      "    epoch          : 2982\n",
      "    loss           : 12221.261294199752\n",
      "    val_loss       : 12220.119442452993\n",
      "    val_log_likelihood: -12128.228020801023\n",
      "    val_log_marginal: -12136.868037531236\n",
      "Train Epoch: 2983 [256/118836 (0%)] Loss: 12310.271484\n",
      "Train Epoch: 2983 [33024/118836 (28%)] Loss: 12174.781250\n",
      "Train Epoch: 2983 [65792/118836 (55%)] Loss: 12177.978516\n",
      "Train Epoch: 2983 [98560/118836 (83%)] Loss: 12178.268555\n",
      "    epoch          : 2983\n",
      "    loss           : 12217.177789140043\n",
      "    val_loss       : 12219.042421214692\n",
      "    val_log_likelihood: -12129.237785133633\n",
      "    val_log_marginal: -12137.843037738337\n",
      "Train Epoch: 2984 [256/118836 (0%)] Loss: 12146.246094\n",
      "Train Epoch: 2984 [33024/118836 (28%)] Loss: 12179.201172\n",
      "Train Epoch: 2984 [65792/118836 (55%)] Loss: 12204.168945\n",
      "Train Epoch: 2984 [98560/118836 (83%)] Loss: 12161.768555\n",
      "    epoch          : 2984\n",
      "    loss           : 12219.14094825915\n",
      "    val_loss       : 12217.095720003828\n",
      "    val_log_likelihood: -12130.274782393764\n",
      "    val_log_marginal: -12139.002977534434\n",
      "Train Epoch: 2985 [256/118836 (0%)] Loss: 12207.909180\n",
      "Train Epoch: 2985 [33024/118836 (28%)] Loss: 12223.009766\n",
      "Train Epoch: 2985 [65792/118836 (55%)] Loss: 12233.501953\n",
      "Train Epoch: 2985 [98560/118836 (83%)] Loss: 12258.382812\n",
      "    epoch          : 2985\n",
      "    loss           : 12222.109712152347\n",
      "    val_loss       : 12222.0840483803\n",
      "    val_log_likelihood: -12138.22983030914\n",
      "    val_log_marginal: -12146.746052744073\n",
      "Train Epoch: 2986 [256/118836 (0%)] Loss: 12281.334961\n",
      "Train Epoch: 2986 [33024/118836 (28%)] Loss: 12366.453125\n",
      "Train Epoch: 2986 [65792/118836 (55%)] Loss: 12238.958008\n",
      "Train Epoch: 2986 [98560/118836 (83%)] Loss: 12253.750000\n",
      "    epoch          : 2986\n",
      "    loss           : 12222.517445331887\n",
      "    val_loss       : 12218.333935467861\n",
      "    val_log_likelihood: -12126.642259389217\n",
      "    val_log_marginal: -12135.32346471592\n",
      "Train Epoch: 2987 [256/118836 (0%)] Loss: 12330.832031\n",
      "Train Epoch: 2987 [33024/118836 (28%)] Loss: 12208.272461\n",
      "Train Epoch: 2987 [65792/118836 (55%)] Loss: 12225.375000\n",
      "Train Epoch: 2987 [98560/118836 (83%)] Loss: 12334.451172\n",
      "    epoch          : 2987\n",
      "    loss           : 12222.27191554875\n",
      "    val_loss       : 12217.053156805776\n",
      "    val_log_likelihood: -12129.279617872467\n",
      "    val_log_marginal: -12137.873213691626\n",
      "Train Epoch: 2988 [256/118836 (0%)] Loss: 12236.412109\n",
      "Train Epoch: 2988 [33024/118836 (28%)] Loss: 12217.374023\n",
      "Train Epoch: 2988 [65792/118836 (55%)] Loss: 12277.441406\n",
      "Train Epoch: 2988 [98560/118836 (83%)] Loss: 12247.680664\n",
      "    epoch          : 2988\n",
      "    loss           : 12219.348121833644\n",
      "    val_loss       : 12218.115165513746\n",
      "    val_log_likelihood: -12126.42627413539\n",
      "    val_log_marginal: -12134.898539839403\n",
      "Train Epoch: 2989 [256/118836 (0%)] Loss: 12193.778320\n",
      "Train Epoch: 2989 [33024/118836 (28%)] Loss: 12181.419922\n",
      "Train Epoch: 2989 [65792/118836 (55%)] Loss: 12218.710938\n",
      "Train Epoch: 2989 [98560/118836 (83%)] Loss: 12227.625000\n",
      "    epoch          : 2989\n",
      "    loss           : 12217.582727848428\n",
      "    val_loss       : 12219.85856369517\n",
      "    val_log_likelihood: -12128.100699021661\n",
      "    val_log_marginal: -12136.656537828796\n",
      "Train Epoch: 2990 [256/118836 (0%)] Loss: 12353.384766\n",
      "Train Epoch: 2990 [33024/118836 (28%)] Loss: 12276.981445\n",
      "Train Epoch: 2990 [65792/118836 (55%)] Loss: 12188.978516\n",
      "Train Epoch: 2990 [98560/118836 (83%)] Loss: 12371.334961\n",
      "    epoch          : 2990\n",
      "    loss           : 12222.330841604633\n",
      "    val_loss       : 12217.477000393174\n",
      "    val_log_likelihood: -12128.28313850548\n",
      "    val_log_marginal: -12136.854781914955\n",
      "Train Epoch: 2991 [256/118836 (0%)] Loss: 12333.926758\n",
      "Train Epoch: 2991 [33024/118836 (28%)] Loss: 12350.082031\n",
      "Train Epoch: 2991 [65792/118836 (55%)] Loss: 12174.738281\n",
      "Train Epoch: 2991 [98560/118836 (83%)] Loss: 12210.646484\n",
      "    epoch          : 2991\n",
      "    loss           : 12216.31620156767\n",
      "    val_loss       : 12219.96175677927\n",
      "    val_log_likelihood: -12126.247620224618\n",
      "    val_log_marginal: -12134.98740289204\n",
      "Train Epoch: 2992 [256/118836 (0%)] Loss: 12248.252930\n",
      "Train Epoch: 2992 [33024/118836 (28%)] Loss: 12251.676758\n",
      "Train Epoch: 2992 [65792/118836 (55%)] Loss: 12300.867188\n",
      "Train Epoch: 2992 [98560/118836 (83%)] Loss: 12204.058594\n",
      "    epoch          : 2992\n",
      "    loss           : 12221.174606467122\n",
      "    val_loss       : 12217.521212236483\n",
      "    val_log_likelihood: -12128.015010306814\n",
      "    val_log_marginal: -12136.753094929807\n",
      "Train Epoch: 2993 [256/118836 (0%)] Loss: 12314.511719\n",
      "Train Epoch: 2993 [33024/118836 (28%)] Loss: 12289.522461\n",
      "Train Epoch: 2993 [65792/118836 (55%)] Loss: 12332.118164\n",
      "Train Epoch: 2993 [98560/118836 (83%)] Loss: 12270.951172\n",
      "    epoch          : 2993\n",
      "    loss           : 12223.269006054848\n",
      "    val_loss       : 12221.011367131696\n",
      "    val_log_likelihood: -12126.209466921267\n",
      "    val_log_marginal: -12134.834117051583\n",
      "Train Epoch: 2994 [256/118836 (0%)] Loss: 12247.576172\n",
      "Train Epoch: 2994 [33024/118836 (28%)] Loss: 12260.451172\n",
      "Train Epoch: 2994 [65792/118836 (55%)] Loss: 12250.822266\n",
      "Train Epoch: 2994 [98560/118836 (83%)] Loss: 12211.399414\n",
      "    epoch          : 2994\n",
      "    loss           : 12215.560015702544\n",
      "    val_loss       : 12220.438042957921\n",
      "    val_log_likelihood: -12127.194301366057\n",
      "    val_log_marginal: -12135.88901447467\n",
      "Train Epoch: 2995 [256/118836 (0%)] Loss: 12213.407227\n",
      "Train Epoch: 2995 [33024/118836 (28%)] Loss: 12274.060547\n",
      "Train Epoch: 2995 [65792/118836 (55%)] Loss: 12217.688477\n",
      "Train Epoch: 2995 [98560/118836 (83%)] Loss: 12230.105469\n",
      "    epoch          : 2995\n",
      "    loss           : 12221.859688404673\n",
      "    val_loss       : 12219.395176792494\n",
      "    val_log_likelihood: -12126.541975547974\n",
      "    val_log_marginal: -12135.272827245648\n",
      "Train Epoch: 2996 [256/118836 (0%)] Loss: 12229.350586\n",
      "Train Epoch: 2996 [33024/118836 (28%)] Loss: 12280.317383\n",
      "Train Epoch: 2996 [65792/118836 (55%)] Loss: 12130.392578\n",
      "Train Epoch: 2996 [98560/118836 (83%)] Loss: 12235.920898\n",
      "    epoch          : 2996\n",
      "    loss           : 12221.602056031586\n",
      "    val_loss       : 12215.307335345467\n",
      "    val_log_likelihood: -12127.244795543838\n",
      "    val_log_marginal: -12135.816048425466\n",
      "Train Epoch: 2997 [256/118836 (0%)] Loss: 12305.947266\n",
      "Train Epoch: 2997 [33024/118836 (28%)] Loss: 12307.865234\n",
      "Train Epoch: 2997 [65792/118836 (55%)] Loss: 12196.569336\n",
      "Train Epoch: 2997 [98560/118836 (83%)] Loss: 12223.700195\n",
      "    epoch          : 2997\n",
      "    loss           : 12219.849658808933\n",
      "    val_loss       : 12215.168835801196\n",
      "    val_log_likelihood: -12126.210774012612\n",
      "    val_log_marginal: -12134.820159075556\n",
      "Train Epoch: 2998 [256/118836 (0%)] Loss: 12231.370117\n",
      "Train Epoch: 2998 [33024/118836 (28%)] Loss: 12258.801758\n",
      "Train Epoch: 2998 [65792/118836 (55%)] Loss: 12197.139648\n",
      "Train Epoch: 2998 [98560/118836 (83%)] Loss: 12265.689453\n",
      "    epoch          : 2998\n",
      "    loss           : 12216.505224488214\n",
      "    val_loss       : 12216.169290234373\n",
      "    val_log_likelihood: -12127.694787951044\n",
      "    val_log_marginal: -12136.392199364831\n",
      "Train Epoch: 2999 [256/118836 (0%)] Loss: 12244.860352\n",
      "Train Epoch: 2999 [33024/118836 (28%)] Loss: 12276.055664\n",
      "Train Epoch: 2999 [65792/118836 (55%)] Loss: 12309.334961\n",
      "Train Epoch: 2999 [98560/118836 (83%)] Loss: 12223.472656\n",
      "    epoch          : 2999\n",
      "    loss           : 12214.119842231441\n",
      "    val_loss       : 12218.675930915742\n",
      "    val_log_likelihood: -12123.70220497958\n",
      "    val_log_marginal: -12132.357338733224\n",
      "Train Epoch: 3000 [256/118836 (0%)] Loss: 12344.902344\n",
      "Train Epoch: 3000 [33024/118836 (28%)] Loss: 12228.806641\n",
      "Train Epoch: 3000 [65792/118836 (55%)] Loss: 12240.892578\n",
      "Train Epoch: 3000 [98560/118836 (83%)] Loss: 12192.412109\n",
      "    epoch          : 3000\n",
      "    loss           : 12219.529669729633\n",
      "    val_loss       : 12220.434560148538\n",
      "    val_log_likelihood: -12127.750393532877\n",
      "    val_log_marginal: -12136.29415151667\n",
      "Saving checkpoint: saved/models/SelfiesAutoencodingOperad/0905_154251/checkpoint-epoch3000.pth ...\n",
      "Train Epoch: 3001 [256/118836 (0%)] Loss: 12292.699219\n",
      "Train Epoch: 3001 [33024/118836 (28%)] Loss: 12174.363281\n",
      "Train Epoch: 3001 [65792/118836 (55%)] Loss: 12261.705078\n",
      "Train Epoch: 3001 [98560/118836 (83%)] Loss: 12259.445312\n",
      "    epoch          : 3001\n",
      "    loss           : 12221.300658311362\n",
      "    val_loss       : 12219.34352357047\n",
      "    val_log_likelihood: -12127.870917500259\n",
      "    val_log_marginal: -12136.453054293792\n",
      "Train Epoch: 3002 [256/118836 (0%)] Loss: 12270.765625\n",
      "Train Epoch: 3002 [33024/118836 (28%)] Loss: 12278.008789\n",
      "Train Epoch: 3002 [65792/118836 (55%)] Loss: 12254.390625\n",
      "Train Epoch: 3002 [98560/118836 (83%)] Loss: 12155.956055\n",
      "    epoch          : 3002\n",
      "    loss           : 12225.529857772437\n",
      "    val_loss       : 12221.055379804433\n",
      "    val_log_likelihood: -12127.476792060846\n",
      "    val_log_marginal: -12136.222850309725\n",
      "Train Epoch: 3003 [256/118836 (0%)] Loss: 12248.438477\n",
      "Train Epoch: 3003 [33024/118836 (28%)] Loss: 12272.631836\n",
      "Train Epoch: 3003 [65792/118836 (55%)] Loss: 12372.552734\n",
      "Train Epoch: 3003 [98560/118836 (83%)] Loss: 12222.195312\n",
      "    epoch          : 3003\n",
      "    loss           : 12218.772845746744\n",
      "    val_loss       : 12221.806284444787\n",
      "    val_log_likelihood: -12128.706489899969\n",
      "    val_log_marginal: -12137.412988434604\n",
      "Train Epoch: 3004 [256/118836 (0%)] Loss: 12194.213867\n",
      "Train Epoch: 3004 [33024/118836 (28%)] Loss: 12382.309570\n",
      "Train Epoch: 3004 [65792/118836 (55%)] Loss: 12199.152344\n",
      "Train Epoch: 3004 [98560/118836 (83%)] Loss: 12347.632812\n",
      "    epoch          : 3004\n",
      "    loss           : 12223.50993945151\n",
      "    val_loss       : 12223.157626584401\n",
      "    val_log_likelihood: -12128.484195357732\n",
      "    val_log_marginal: -12137.104764109048\n",
      "Train Epoch: 3005 [256/118836 (0%)] Loss: 12215.857422\n",
      "Train Epoch: 3005 [33024/118836 (28%)] Loss: 12263.682617\n",
      "Train Epoch: 3005 [65792/118836 (55%)] Loss: 12303.614258\n",
      "Train Epoch: 3005 [98560/118836 (83%)] Loss: 12182.455078\n",
      "    epoch          : 3005\n",
      "    loss           : 12219.897387432795\n",
      "    val_loss       : 12220.31331211641\n",
      "    val_log_likelihood: -12125.965348590002\n",
      "    val_log_marginal: -12134.553183677639\n",
      "Train Epoch: 3006 [256/118836 (0%)] Loss: 12183.759766\n",
      "Train Epoch: 3006 [33024/118836 (28%)] Loss: 12257.412109\n",
      "Train Epoch: 3006 [65792/118836 (55%)] Loss: 12210.378906\n",
      "Train Epoch: 3006 [98560/118836 (83%)] Loss: 12219.781250\n",
      "    epoch          : 3006\n",
      "    loss           : 12218.20366925791\n",
      "    val_loss       : 12220.240390755931\n",
      "    val_log_likelihood: -12128.117880382806\n",
      "    val_log_marginal: -12136.853703146882\n",
      "Train Epoch: 3007 [256/118836 (0%)] Loss: 12205.218750\n",
      "Train Epoch: 3007 [33024/118836 (28%)] Loss: 12271.671875\n",
      "Train Epoch: 3007 [65792/118836 (55%)] Loss: 12351.993164\n",
      "Train Epoch: 3007 [98560/118836 (83%)] Loss: 12228.318359\n",
      "    epoch          : 3007\n",
      "    loss           : 12224.147142040167\n",
      "    val_loss       : 12220.237489558953\n",
      "    val_log_likelihood: -12129.301331646764\n",
      "    val_log_marginal: -12138.110859611614\n",
      "Train Epoch: 3008 [256/118836 (0%)] Loss: 12259.765625\n",
      "Train Epoch: 3008 [33024/118836 (28%)] Loss: 12333.069336\n",
      "Train Epoch: 3008 [65792/118836 (55%)] Loss: 12245.138672\n",
      "Train Epoch: 3008 [98560/118836 (83%)] Loss: 12244.557617\n",
      "    epoch          : 3008\n",
      "    loss           : 12221.016747441066\n",
      "    val_loss       : 12218.046618748624\n",
      "    val_log_likelihood: -12127.372400518248\n",
      "    val_log_marginal: -12136.035939294115\n",
      "Train Epoch: 3009 [256/118836 (0%)] Loss: 12256.355469\n",
      "Train Epoch: 3009 [33024/118836 (28%)] Loss: 12294.655273\n",
      "Train Epoch: 3009 [65792/118836 (55%)] Loss: 12192.072266\n",
      "Train Epoch: 3009 [98560/118836 (83%)] Loss: 12309.874023\n",
      "    epoch          : 3009\n",
      "    loss           : 12219.159646563534\n",
      "    val_loss       : 12217.963337883131\n",
      "    val_log_likelihood: -12128.507135933623\n",
      "    val_log_marginal: -12137.245506760146\n",
      "Train Epoch: 3010 [256/118836 (0%)] Loss: 12166.588867\n",
      "Train Epoch: 3010 [33024/118836 (28%)] Loss: 12295.619141\n",
      "Train Epoch: 3010 [65792/118836 (55%)] Loss: 12222.065430\n",
      "Train Epoch: 3010 [98560/118836 (83%)] Loss: 12169.179688\n",
      "    epoch          : 3010\n",
      "    loss           : 12217.448194369055\n",
      "    val_loss       : 12223.472109545852\n",
      "    val_log_likelihood: -12127.167490727097\n",
      "    val_log_marginal: -12135.923679143243\n",
      "Train Epoch: 3011 [256/118836 (0%)] Loss: 12364.548828\n",
      "Train Epoch: 3011 [33024/118836 (28%)] Loss: 12276.277344\n",
      "Train Epoch: 3011 [65792/118836 (55%)] Loss: 12304.729492\n",
      "Train Epoch: 3011 [98560/118836 (83%)] Loss: 12293.553711\n",
      "    epoch          : 3011\n",
      "    loss           : 12224.219605885546\n",
      "    val_loss       : 12218.152849014043\n",
      "    val_log_likelihood: -12124.591317398159\n",
      "    val_log_marginal: -12133.250217628018\n",
      "Train Epoch: 3012 [256/118836 (0%)] Loss: 12187.228516\n",
      "Train Epoch: 3012 [33024/118836 (28%)] Loss: 12259.471680\n",
      "Train Epoch: 3012 [65792/118836 (55%)] Loss: 12288.618164\n",
      "Train Epoch: 3012 [98560/118836 (83%)] Loss: 12212.628906\n",
      "    epoch          : 3012\n",
      "    loss           : 12222.672032994727\n",
      "    val_loss       : 12219.387491728454\n",
      "    val_log_likelihood: -12128.237869946754\n",
      "    val_log_marginal: -12136.867197953912\n",
      "Train Epoch: 3013 [256/118836 (0%)] Loss: 12165.571289\n",
      "Train Epoch: 3013 [33024/118836 (28%)] Loss: 12203.965820\n",
      "Train Epoch: 3013 [65792/118836 (55%)] Loss: 12244.228516\n",
      "Train Epoch: 3013 [98560/118836 (83%)] Loss: 12251.933594\n",
      "    epoch          : 3013\n",
      "    loss           : 12220.986859782102\n",
      "    val_loss       : 12225.014752662586\n",
      "    val_log_likelihood: -12126.945721703112\n",
      "    val_log_marginal: -12135.495125095755\n",
      "Train Epoch: 3014 [256/118836 (0%)] Loss: 12165.412109\n",
      "Train Epoch: 3014 [33024/118836 (28%)] Loss: 12133.524414\n",
      "Train Epoch: 3014 [65792/118836 (55%)] Loss: 12226.085938\n",
      "Train Epoch: 3014 [98560/118836 (83%)] Loss: 12287.991211\n",
      "    epoch          : 3014\n",
      "    loss           : 12216.069693283447\n",
      "    val_loss       : 12221.850959714213\n",
      "    val_log_likelihood: -12127.838466384925\n",
      "    val_log_marginal: -12136.512548706432\n",
      "Train Epoch: 3015 [256/118836 (0%)] Loss: 12250.399414\n",
      "Train Epoch: 3015 [33024/118836 (28%)] Loss: 12213.711914\n",
      "Train Epoch: 3015 [65792/118836 (55%)] Loss: 12213.479492\n",
      "Train Epoch: 3015 [98560/118836 (83%)] Loss: 12181.415039\n",
      "    epoch          : 3015\n",
      "    loss           : 12217.56533388906\n",
      "    val_loss       : 12219.700371827535\n",
      "    val_log_likelihood: -12124.994856286186\n",
      "    val_log_marginal: -12133.637389267624\n",
      "Train Epoch: 3016 [256/118836 (0%)] Loss: 12167.623047\n",
      "Train Epoch: 3016 [33024/118836 (28%)] Loss: 12241.108398\n",
      "Train Epoch: 3016 [65792/118836 (55%)] Loss: 12107.792969\n",
      "Train Epoch: 3016 [98560/118836 (83%)] Loss: 12244.527344\n",
      "    epoch          : 3016\n",
      "    loss           : 12216.354235648005\n",
      "    val_loss       : 12219.560352915078\n",
      "    val_log_likelihood: -12130.294242723843\n",
      "    val_log_marginal: -12139.052489460113\n",
      "Train Epoch: 3017 [256/118836 (0%)] Loss: 12199.485352\n",
      "Train Epoch: 3017 [33024/118836 (28%)] Loss: 12257.994141\n",
      "Train Epoch: 3017 [65792/118836 (55%)] Loss: 12291.246094\n",
      "Train Epoch: 3017 [98560/118836 (83%)] Loss: 12303.916992\n",
      "    epoch          : 3017\n",
      "    loss           : 12216.960545421061\n",
      "    val_loss       : 12223.958000302784\n",
      "    val_log_likelihood: -12125.894410573046\n",
      "    val_log_marginal: -12134.450181295197\n",
      "Train Epoch: 3018 [256/118836 (0%)] Loss: 12142.953125\n",
      "Train Epoch: 3018 [33024/118836 (28%)] Loss: 12391.640625\n",
      "Train Epoch: 3018 [65792/118836 (55%)] Loss: 12284.238281\n",
      "Train Epoch: 3018 [98560/118836 (83%)] Loss: 12232.887695\n",
      "    epoch          : 3018\n",
      "    loss           : 12218.2893789741\n",
      "    val_loss       : 12220.589776870424\n",
      "    val_log_likelihood: -12128.260236216656\n",
      "    val_log_marginal: -12136.851270657986\n",
      "Train Epoch: 3019 [256/118836 (0%)] Loss: 12192.697266\n",
      "Train Epoch: 3019 [33024/118836 (28%)] Loss: 12257.451172\n",
      "Train Epoch: 3019 [65792/118836 (55%)] Loss: 12176.455078\n",
      "Train Epoch: 3019 [98560/118836 (83%)] Loss: 12153.595703\n",
      "    epoch          : 3019\n",
      "    loss           : 12219.219864525176\n",
      "    val_loss       : 12219.286871651067\n",
      "    val_log_likelihood: -12127.931697005532\n",
      "    val_log_marginal: -12136.357013450684\n",
      "Train Epoch: 3020 [256/118836 (0%)] Loss: 12256.181641\n",
      "Train Epoch: 3020 [33024/118836 (28%)] Loss: 12261.564453\n",
      "Train Epoch: 3020 [65792/118836 (55%)] Loss: 12233.707031\n",
      "Train Epoch: 3020 [98560/118836 (83%)] Loss: 12279.709961\n",
      "    epoch          : 3020\n",
      "    loss           : 12216.746677910462\n",
      "    val_loss       : 12219.877202365988\n",
      "    val_log_likelihood: -12128.567096709574\n",
      "    val_log_marginal: -12137.085433992717\n",
      "Train Epoch: 3021 [256/118836 (0%)] Loss: 12346.066406\n",
      "Train Epoch: 3021 [33024/118836 (28%)] Loss: 12172.627930\n",
      "Train Epoch: 3021 [65792/118836 (55%)] Loss: 12306.017578\n",
      "Train Epoch: 3021 [98560/118836 (83%)] Loss: 12247.523438\n",
      "    epoch          : 3021\n",
      "    loss           : 12223.916902851013\n",
      "    val_loss       : 12220.484793440028\n",
      "    val_log_likelihood: -12129.447885810847\n",
      "    val_log_marginal: -12138.104401688095\n",
      "Train Epoch: 3022 [256/118836 (0%)] Loss: 12124.772461\n",
      "Train Epoch: 3022 [33024/118836 (28%)] Loss: 12212.877930\n",
      "Train Epoch: 3022 [65792/118836 (55%)] Loss: 12197.753906\n",
      "Train Epoch: 3022 [98560/118836 (83%)] Loss: 12233.318359\n",
      "    epoch          : 3022\n",
      "    loss           : 12218.594749179332\n",
      "    val_loss       : 12217.426521322946\n",
      "    val_log_likelihood: -12127.37499192256\n",
      "    val_log_marginal: -12136.052544508688\n",
      "Train Epoch: 3023 [256/118836 (0%)] Loss: 12167.578125\n",
      "Train Epoch: 3023 [33024/118836 (28%)] Loss: 12229.141602\n",
      "Train Epoch: 3023 [65792/118836 (55%)] Loss: 12187.003906\n",
      "Train Epoch: 3023 [98560/118836 (83%)] Loss: 12259.291992\n",
      "    epoch          : 3023\n",
      "    loss           : 12216.62850883995\n",
      "    val_loss       : 12221.610280720723\n",
      "    val_log_likelihood: -12127.148267550663\n",
      "    val_log_marginal: -12135.855429510917\n",
      "Train Epoch: 3024 [256/118836 (0%)] Loss: 12266.942383\n",
      "Train Epoch: 3024 [33024/118836 (28%)] Loss: 12326.767578\n",
      "Train Epoch: 3024 [65792/118836 (55%)] Loss: 12225.170898\n",
      "Train Epoch: 3024 [98560/118836 (83%)] Loss: 12239.635742\n",
      "    epoch          : 3024\n",
      "    loss           : 12213.766706246124\n",
      "    val_loss       : 12220.845567961345\n",
      "    val_log_likelihood: -12127.981798458177\n",
      "    val_log_marginal: -12136.542203629944\n",
      "Train Epoch: 3025 [256/118836 (0%)] Loss: 12228.574219\n",
      "Train Epoch: 3025 [33024/118836 (28%)] Loss: 12286.545898\n",
      "Train Epoch: 3025 [65792/118836 (55%)] Loss: 12334.681641\n",
      "Train Epoch: 3025 [98560/118836 (83%)] Loss: 12239.095703\n",
      "    epoch          : 3025\n",
      "    loss           : 12219.474097749948\n",
      "    val_loss       : 12217.62545311947\n",
      "    val_log_likelihood: -12132.128909157878\n",
      "    val_log_marginal: -12140.871987473602\n",
      "Train Epoch: 3026 [256/118836 (0%)] Loss: 12328.804688\n",
      "Train Epoch: 3026 [33024/118836 (28%)] Loss: 12177.261719\n",
      "Train Epoch: 3026 [65792/118836 (55%)] Loss: 12275.344727\n",
      "Train Epoch: 3026 [98560/118836 (83%)] Loss: 12219.419922\n",
      "    epoch          : 3026\n",
      "    loss           : 12220.316346315394\n",
      "    val_loss       : 12223.705844259799\n",
      "    val_log_likelihood: -12130.52608964666\n",
      "    val_log_marginal: -12139.333819895486\n",
      "Train Epoch: 3027 [256/118836 (0%)] Loss: 12418.825195\n",
      "Train Epoch: 3027 [33024/118836 (28%)] Loss: 12267.737305\n",
      "Train Epoch: 3027 [65792/118836 (55%)] Loss: 12152.753906\n",
      "Train Epoch: 3027 [98560/118836 (83%)] Loss: 12249.615234\n",
      "    epoch          : 3027\n",
      "    loss           : 12218.9737539741\n",
      "    val_loss       : 12219.409231439138\n",
      "    val_log_likelihood: -12127.452407400227\n",
      "    val_log_marginal: -12136.055582810077\n",
      "Train Epoch: 3028 [256/118836 (0%)] Loss: 12164.833008\n",
      "Train Epoch: 3028 [33024/118836 (28%)] Loss: 12201.253906\n",
      "Train Epoch: 3028 [65792/118836 (55%)] Loss: 12222.563477\n",
      "Train Epoch: 3028 [98560/118836 (83%)] Loss: 12291.365234\n",
      "    epoch          : 3028\n",
      "    loss           : 12221.391526926955\n",
      "    val_loss       : 12223.438544692579\n",
      "    val_log_likelihood: -12126.476248610681\n",
      "    val_log_marginal: -12135.134830229616\n",
      "Train Epoch: 3029 [256/118836 (0%)] Loss: 12227.470703\n",
      "Train Epoch: 3029 [33024/118836 (28%)] Loss: 12223.726562\n",
      "Train Epoch: 3029 [65792/118836 (55%)] Loss: 12180.451172\n",
      "Train Epoch: 3029 [98560/118836 (83%)] Loss: 12174.638672\n",
      "    epoch          : 3029\n",
      "    loss           : 12214.837830044198\n",
      "    val_loss       : 12214.86052418135\n",
      "    val_log_likelihood: -12127.13782164366\n",
      "    val_log_marginal: -12135.628853730454\n",
      "Train Epoch: 3030 [256/118836 (0%)] Loss: 12154.680664\n",
      "Train Epoch: 3030 [33024/118836 (28%)] Loss: 12187.987305\n",
      "Train Epoch: 3030 [65792/118836 (55%)] Loss: 12325.758789\n",
      "Train Epoch: 3030 [98560/118836 (83%)] Loss: 12248.221680\n",
      "    epoch          : 3030\n",
      "    loss           : 12218.592846942205\n",
      "    val_loss       : 12222.294107664165\n",
      "    val_log_likelihood: -12126.648513266387\n",
      "    val_log_marginal: -12135.165642004533\n",
      "Train Epoch: 3031 [256/118836 (0%)] Loss: 12166.952148\n",
      "Train Epoch: 3031 [33024/118836 (28%)] Loss: 12219.364258\n",
      "Train Epoch: 3031 [65792/118836 (55%)] Loss: 12174.424805\n",
      "Train Epoch: 3031 [98560/118836 (83%)] Loss: 12191.543945\n",
      "    epoch          : 3031\n",
      "    loss           : 12218.48015906095\n",
      "    val_loss       : 12218.332972015496\n",
      "    val_log_likelihood: -12129.958954973119\n",
      "    val_log_marginal: -12138.768353002182\n",
      "Train Epoch: 3032 [256/118836 (0%)] Loss: 12183.742188\n",
      "Train Epoch: 3032 [33024/118836 (28%)] Loss: 12168.197266\n",
      "Train Epoch: 3032 [65792/118836 (55%)] Loss: 12381.598633\n",
      "Train Epoch: 3032 [98560/118836 (83%)] Loss: 12263.578125\n",
      "    epoch          : 3032\n",
      "    loss           : 12219.507870011372\n",
      "    val_loss       : 12221.2919258955\n",
      "    val_log_likelihood: -12128.696178078473\n",
      "    val_log_marginal: -12137.37498291702\n",
      "Train Epoch: 3033 [256/118836 (0%)] Loss: 12252.561523\n",
      "Train Epoch: 3033 [33024/118836 (28%)] Loss: 12268.069336\n",
      "Train Epoch: 3033 [65792/118836 (55%)] Loss: 12265.148438\n",
      "Train Epoch: 3033 [98560/118836 (83%)] Loss: 12260.564453\n",
      "    epoch          : 3033\n",
      "    loss           : 12224.480913655398\n",
      "    val_loss       : 12214.47431931592\n",
      "    val_log_likelihood: -12125.536015689619\n",
      "    val_log_marginal: -12134.107434910698\n",
      "Train Epoch: 3034 [256/118836 (0%)] Loss: 12307.215820\n",
      "Train Epoch: 3034 [33024/118836 (28%)] Loss: 12258.938477\n",
      "Train Epoch: 3034 [65792/118836 (55%)] Loss: 12296.850586\n",
      "Train Epoch: 3034 [98560/118836 (83%)] Loss: 12242.419922\n",
      "    epoch          : 3034\n",
      "    loss           : 12220.507779867143\n",
      "    val_loss       : 12218.525288815308\n",
      "    val_log_likelihood: -12120.743509776934\n",
      "    val_log_marginal: -12129.516879228939\n",
      "Train Epoch: 3035 [256/118836 (0%)] Loss: 12162.473633\n",
      "Train Epoch: 3035 [33024/118836 (28%)] Loss: 12195.855469\n",
      "Train Epoch: 3035 [65792/118836 (55%)] Loss: 12137.247070\n",
      "Train Epoch: 3035 [98560/118836 (83%)] Loss: 12217.482422\n",
      "    epoch          : 3035\n",
      "    loss           : 12219.977703034534\n",
      "    val_loss       : 12216.503397492443\n",
      "    val_log_likelihood: -12122.386688055727\n",
      "    val_log_marginal: -12131.090432587718\n",
      "Train Epoch: 3036 [256/118836 (0%)] Loss: 12250.995117\n",
      "Train Epoch: 3036 [33024/118836 (28%)] Loss: 12198.824219\n",
      "Train Epoch: 3036 [65792/118836 (55%)] Loss: 12362.527344\n",
      "Train Epoch: 3036 [98560/118836 (83%)] Loss: 12335.083008\n",
      "    epoch          : 3036\n",
      "    loss           : 12218.65860457377\n",
      "    val_loss       : 12217.21000422147\n",
      "    val_log_likelihood: -12125.285905836434\n",
      "    val_log_marginal: -12134.067466925662\n",
      "Train Epoch: 3037 [256/118836 (0%)] Loss: 12265.520508\n",
      "Train Epoch: 3037 [33024/118836 (28%)] Loss: 12291.695312\n",
      "Train Epoch: 3037 [65792/118836 (55%)] Loss: 12196.131836\n",
      "Train Epoch: 3037 [98560/118836 (83%)] Loss: 12349.333008\n",
      "    epoch          : 3037\n",
      "    loss           : 12221.676490772334\n",
      "    val_loss       : 12226.831957662465\n",
      "    val_log_likelihood: -12126.833828965055\n",
      "    val_log_marginal: -12135.565388689094\n",
      "Train Epoch: 3038 [256/118836 (0%)] Loss: 12277.717773\n",
      "Train Epoch: 3038 [33024/118836 (28%)] Loss: 12219.328125\n",
      "Train Epoch: 3038 [65792/118836 (55%)] Loss: 12213.209961\n",
      "Train Epoch: 3038 [98560/118836 (83%)] Loss: 12220.970703\n",
      "    epoch          : 3038\n",
      "    loss           : 12224.788178828061\n",
      "    val_loss       : 12234.524323255404\n",
      "    val_log_likelihood: -12125.927732597962\n",
      "    val_log_marginal: -12134.612183697804\n",
      "Train Epoch: 3039 [256/118836 (0%)] Loss: 12268.731445\n",
      "Train Epoch: 3039 [33024/118836 (28%)] Loss: 12136.375977\n",
      "Train Epoch: 3039 [65792/118836 (55%)] Loss: 12318.277344\n",
      "Train Epoch: 3039 [98560/118836 (83%)] Loss: 12173.666992\n",
      "    epoch          : 3039\n",
      "    loss           : 12220.321224927626\n",
      "    val_loss       : 12217.26282196941\n",
      "    val_log_likelihood: -12126.921725244261\n",
      "    val_log_marginal: -12135.716144792394\n",
      "Train Epoch: 3040 [256/118836 (0%)] Loss: 12240.884766\n",
      "Train Epoch: 3040 [33024/118836 (28%)] Loss: 12246.431641\n",
      "Train Epoch: 3040 [65792/118836 (55%)] Loss: 12153.031250\n",
      "Train Epoch: 3040 [98560/118836 (83%)] Loss: 12318.728516\n",
      "    epoch          : 3040\n",
      "    loss           : 12217.8995352241\n",
      "    val_loss       : 12217.862552431894\n",
      "    val_log_likelihood: -12123.156122214898\n",
      "    val_log_marginal: -12131.719805259729\n",
      "Train Epoch: 3041 [256/118836 (0%)] Loss: 12135.045898\n",
      "Train Epoch: 3041 [33024/118836 (28%)] Loss: 12205.632812\n",
      "Train Epoch: 3041 [65792/118836 (55%)] Loss: 12143.900391\n",
      "Train Epoch: 3041 [98560/118836 (83%)] Loss: 12255.519531\n",
      "    epoch          : 3041\n",
      "    loss           : 12216.609129445824\n",
      "    val_loss       : 12216.037308032288\n",
      "    val_log_likelihood: -12126.979948885959\n",
      "    val_log_marginal: -12135.753989725139\n",
      "Train Epoch: 3042 [256/118836 (0%)] Loss: 12264.390625\n",
      "Train Epoch: 3042 [33024/118836 (28%)] Loss: 12313.708984\n",
      "Train Epoch: 3042 [65792/118836 (55%)] Loss: 12162.619141\n",
      "Train Epoch: 3042 [98560/118836 (83%)] Loss: 12292.797852\n",
      "    epoch          : 3042\n",
      "    loss           : 12220.966360208593\n",
      "    val_loss       : 12220.937024441737\n",
      "    val_log_likelihood: -12127.98784765302\n",
      "    val_log_marginal: -12136.782367145346\n",
      "Train Epoch: 3043 [256/118836 (0%)] Loss: 12209.166992\n",
      "Train Epoch: 3043 [33024/118836 (28%)] Loss: 12172.010742\n",
      "Train Epoch: 3043 [65792/118836 (55%)] Loss: 12169.676758\n",
      "Train Epoch: 3043 [98560/118836 (83%)] Loss: 12225.140625\n",
      "    epoch          : 3043\n",
      "    loss           : 12219.262305010598\n",
      "    val_loss       : 12216.98707900033\n",
      "    val_log_likelihood: -12122.07569110577\n",
      "    val_log_marginal: -12131.066011932318\n",
      "Train Epoch: 3044 [256/118836 (0%)] Loss: 12264.160156\n",
      "Train Epoch: 3044 [33024/118836 (28%)] Loss: 12333.739258\n",
      "Train Epoch: 3044 [65792/118836 (55%)] Loss: 12277.327148\n",
      "Train Epoch: 3044 [98560/118836 (83%)] Loss: 12215.437500\n",
      "    epoch          : 3044\n",
      "    loss           : 12224.272022332505\n",
      "    val_loss       : 12214.583145681596\n",
      "    val_log_likelihood: -12120.446549317618\n",
      "    val_log_marginal: -12129.32725646591\n",
      "Train Epoch: 3045 [256/118836 (0%)] Loss: 12260.220703\n",
      "Train Epoch: 3045 [33024/118836 (28%)] Loss: 12201.175781\n",
      "Train Epoch: 3045 [65792/118836 (55%)] Loss: 12157.747070\n",
      "Train Epoch: 3045 [98560/118836 (83%)] Loss: 12129.119141\n",
      "    epoch          : 3045\n",
      "    loss           : 12219.090185425714\n",
      "    val_loss       : 12223.82301314317\n",
      "    val_log_likelihood: -12122.088381894902\n",
      "    val_log_marginal: -12130.974811016544\n",
      "Train Epoch: 3046 [256/118836 (0%)] Loss: 12263.281250\n",
      "Train Epoch: 3046 [33024/118836 (28%)] Loss: 12195.471680\n",
      "Train Epoch: 3046 [65792/118836 (55%)] Loss: 12299.468750\n",
      "Train Epoch: 3046 [98560/118836 (83%)] Loss: 12183.300781\n",
      "    epoch          : 3046\n",
      "    loss           : 12226.947511825372\n",
      "    val_loss       : 12219.246016130151\n",
      "    val_log_likelihood: -12127.387329242918\n",
      "    val_log_marginal: -12136.346123763204\n",
      "Train Epoch: 3047 [256/118836 (0%)] Loss: 12165.258789\n",
      "Train Epoch: 3047 [33024/118836 (28%)] Loss: 12145.162109\n",
      "Train Epoch: 3047 [65792/118836 (55%)] Loss: 12232.849609\n",
      "Train Epoch: 3047 [98560/118836 (83%)] Loss: 12237.957031\n",
      "    epoch          : 3047\n",
      "    loss           : 12221.863266225962\n",
      "    val_loss       : 12220.921186201062\n",
      "    val_log_likelihood: -12121.456967922872\n",
      "    val_log_marginal: -12130.432536101353\n",
      "Train Epoch: 3048 [256/118836 (0%)] Loss: 12245.018555\n",
      "Train Epoch: 3048 [33024/118836 (28%)] Loss: 12204.966797\n",
      "Train Epoch: 3048 [65792/118836 (55%)] Loss: 12221.705078\n",
      "Train Epoch: 3048 [98560/118836 (83%)] Loss: 12230.978516\n",
      "    epoch          : 3048\n",
      "    loss           : 12219.360345585193\n",
      "    val_loss       : 12215.467122086313\n",
      "    val_log_likelihood: -12121.416788959108\n",
      "    val_log_marginal: -12130.294323730328\n",
      "Train Epoch: 3049 [256/118836 (0%)] Loss: 12274.438477\n",
      "Train Epoch: 3049 [33024/118836 (28%)] Loss: 12240.906250\n",
      "Train Epoch: 3049 [65792/118836 (55%)] Loss: 12311.455078\n",
      "Train Epoch: 3049 [98560/118836 (83%)] Loss: 12232.697266\n",
      "    epoch          : 3049\n",
      "    loss           : 12214.36809265793\n",
      "    val_loss       : 12219.403940741366\n",
      "    val_log_likelihood: -12125.297032994727\n",
      "    val_log_marginal: -12134.276692603531\n",
      "Train Epoch: 3050 [256/118836 (0%)] Loss: 12382.964844\n",
      "Train Epoch: 3050 [33024/118836 (28%)] Loss: 12437.436523\n",
      "Train Epoch: 3050 [65792/118836 (55%)] Loss: 12150.657227\n",
      "Train Epoch: 3050 [98560/118836 (83%)] Loss: 12160.010742\n",
      "    epoch          : 3050\n",
      "    loss           : 12214.961227318548\n",
      "    val_loss       : 12220.09670390039\n",
      "    val_log_likelihood: -12122.826647636219\n",
      "    val_log_marginal: -12131.810473126889\n",
      "Train Epoch: 3051 [256/118836 (0%)] Loss: 12284.399414\n",
      "Train Epoch: 3051 [33024/118836 (28%)] Loss: 12265.543945\n",
      "Train Epoch: 3051 [65792/118836 (55%)] Loss: 12197.641602\n",
      "Train Epoch: 3051 [98560/118836 (83%)] Loss: 12258.775391\n",
      "    epoch          : 3051\n",
      "    loss           : 12223.508766284118\n",
      "    val_loss       : 12215.346485863889\n",
      "    val_log_likelihood: -12123.105048884669\n",
      "    val_log_marginal: -12131.996383275602\n",
      "Train Epoch: 3052 [256/118836 (0%)] Loss: 12151.983398\n",
      "Train Epoch: 3052 [33024/118836 (28%)] Loss: 12135.883789\n",
      "Train Epoch: 3052 [65792/118836 (55%)] Loss: 12202.316406\n",
      "Train Epoch: 3052 [98560/118836 (83%)] Loss: 12207.251953\n",
      "    epoch          : 3052\n",
      "    loss           : 12223.594557905551\n",
      "    val_loss       : 12221.861830974198\n",
      "    val_log_likelihood: -12125.477343103805\n",
      "    val_log_marginal: -12134.46728868975\n",
      "Train Epoch: 3053 [256/118836 (0%)] Loss: 12412.494141\n",
      "Train Epoch: 3053 [33024/118836 (28%)] Loss: 12291.691406\n",
      "Train Epoch: 3053 [65792/118836 (55%)] Loss: 12143.350586\n",
      "Train Epoch: 3053 [98560/118836 (83%)] Loss: 12248.140625\n",
      "    epoch          : 3053\n",
      "    loss           : 12222.752474119883\n",
      "    val_loss       : 12218.959839411888\n",
      "    val_log_likelihood: -12121.444645465\n",
      "    val_log_marginal: -12130.51245629449\n",
      "Train Epoch: 3054 [256/118836 (0%)] Loss: 12336.704102\n",
      "Train Epoch: 3054 [33024/118836 (28%)] Loss: 12265.039062\n",
      "Train Epoch: 3054 [65792/118836 (55%)] Loss: 12256.349609\n",
      "Train Epoch: 3054 [98560/118836 (83%)] Loss: 12183.179688\n",
      "    epoch          : 3054\n",
      "    loss           : 12221.620624450734\n",
      "    val_loss       : 12219.191403696312\n",
      "    val_log_likelihood: -12120.439973635237\n",
      "    val_log_marginal: -12129.309146489748\n",
      "Train Epoch: 3055 [256/118836 (0%)] Loss: 12298.736328\n",
      "Train Epoch: 3055 [33024/118836 (28%)] Loss: 12312.271484\n",
      "Train Epoch: 3055 [65792/118836 (55%)] Loss: 12122.651367\n",
      "Train Epoch: 3055 [98560/118836 (83%)] Loss: 12300.361328\n",
      "    epoch          : 3055\n",
      "    loss           : 12224.185309559813\n",
      "    val_loss       : 12221.157870090456\n",
      "    val_log_likelihood: -12117.731871801334\n",
      "    val_log_marginal: -12126.71364663615\n",
      "Train Epoch: 3056 [256/118836 (0%)] Loss: 12239.417969\n",
      "Train Epoch: 3056 [33024/118836 (28%)] Loss: 12303.683594\n",
      "Train Epoch: 3056 [65792/118836 (55%)] Loss: 12258.855469\n",
      "Train Epoch: 3056 [98560/118836 (83%)] Loss: 12286.144531\n",
      "    epoch          : 3056\n",
      "    loss           : 12223.56071407801\n",
      "    val_loss       : 12233.517353517234\n",
      "    val_log_likelihood: -12145.581652256515\n",
      "    val_log_marginal: -12154.590761686357\n",
      "Train Epoch: 3057 [256/118836 (0%)] Loss: 12249.708984\n",
      "Train Epoch: 3057 [33024/118836 (28%)] Loss: 12322.408203\n",
      "Train Epoch: 3057 [65792/118836 (55%)] Loss: 12183.345703\n",
      "Train Epoch: 3057 [98560/118836 (83%)] Loss: 12272.592773\n",
      "    epoch          : 3057\n",
      "    loss           : 12220.164921616522\n",
      "    val_loss       : 12216.829979880134\n",
      "    val_log_likelihood: -12133.252502229374\n",
      "    val_log_marginal: -12142.300150433075\n",
      "Train Epoch: 3058 [256/118836 (0%)] Loss: 12184.174805\n",
      "Train Epoch: 3058 [33024/118836 (28%)] Loss: 12135.824219\n",
      "Train Epoch: 3058 [65792/118836 (55%)] Loss: 12189.674805\n",
      "Train Epoch: 3058 [98560/118836 (83%)] Loss: 12269.082031\n",
      "    epoch          : 3058\n",
      "    loss           : 12223.056946598428\n",
      "    val_loss       : 12222.91034431405\n",
      "    val_log_likelihood: -12121.559033162737\n",
      "    val_log_marginal: -12130.549015949433\n",
      "Train Epoch: 3059 [256/118836 (0%)] Loss: 12330.635742\n",
      "Train Epoch: 3059 [33024/118836 (28%)] Loss: 12329.129883\n",
      "Train Epoch: 3059 [65792/118836 (55%)] Loss: 12192.833008\n",
      "Train Epoch: 3059 [98560/118836 (83%)] Loss: 12250.142578\n",
      "    epoch          : 3059\n",
      "    loss           : 12219.468920433985\n",
      "    val_loss       : 12218.636818888903\n",
      "    val_log_likelihood: -12126.977047792598\n",
      "    val_log_marginal: -12135.954620991068\n",
      "Train Epoch: 3060 [256/118836 (0%)] Loss: 12309.278320\n",
      "Train Epoch: 3060 [33024/118836 (28%)] Loss: 12195.558594\n",
      "Train Epoch: 3060 [65792/118836 (55%)] Loss: 12270.827148\n",
      "Train Epoch: 3060 [98560/118836 (83%)] Loss: 12160.156250\n",
      "    epoch          : 3060\n",
      "    loss           : 12221.550711137821\n",
      "    val_loss       : 12220.79768098525\n",
      "    val_log_likelihood: -12123.192454540167\n",
      "    val_log_marginal: -12132.103705240419\n",
      "Train Epoch: 3061 [256/118836 (0%)] Loss: 12176.279297\n",
      "Train Epoch: 3061 [33024/118836 (28%)] Loss: 12295.023438\n",
      "Train Epoch: 3061 [65792/118836 (55%)] Loss: 12324.603516\n",
      "Train Epoch: 3061 [98560/118836 (83%)] Loss: 12204.593750\n",
      "    epoch          : 3061\n",
      "    loss           : 12217.89449603236\n",
      "    val_loss       : 12221.331153138186\n",
      "    val_log_likelihood: -12121.930012536188\n",
      "    val_log_marginal: -12130.763302452768\n",
      "Train Epoch: 3062 [256/118836 (0%)] Loss: 12144.470703\n",
      "Train Epoch: 3062 [33024/118836 (28%)] Loss: 12277.648438\n",
      "Train Epoch: 3062 [65792/118836 (55%)] Loss: 12195.386719\n",
      "Train Epoch: 3062 [98560/118836 (83%)] Loss: 12213.330078\n",
      "    epoch          : 3062\n",
      "    loss           : 12215.147699060431\n",
      "    val_loss       : 12219.100008564908\n",
      "    val_log_likelihood: -12125.303649548956\n",
      "    val_log_marginal: -12134.232303898727\n",
      "Train Epoch: 3063 [256/118836 (0%)] Loss: 12198.395508\n",
      "Train Epoch: 3063 [33024/118836 (28%)] Loss: 12244.504883\n",
      "Train Epoch: 3063 [65792/118836 (55%)] Loss: 12256.703125\n",
      "Train Epoch: 3063 [98560/118836 (83%)] Loss: 12200.162109\n",
      "    epoch          : 3063\n",
      "    loss           : 12215.153386547508\n",
      "    val_loss       : 12215.235176548975\n",
      "    val_log_likelihood: -12119.327259744623\n",
      "    val_log_marginal: -12128.136693979517\n",
      "Train Epoch: 3064 [256/118836 (0%)] Loss: 12149.830078\n",
      "Train Epoch: 3064 [33024/118836 (28%)] Loss: 12256.980469\n",
      "Train Epoch: 3064 [65792/118836 (55%)] Loss: 12265.236328\n",
      "Train Epoch: 3064 [98560/118836 (83%)] Loss: 12287.717773\n",
      "    epoch          : 3064\n",
      "    loss           : 12219.68099539909\n",
      "    val_loss       : 12220.4814393271\n",
      "    val_log_likelihood: -12119.540987030861\n",
      "    val_log_marginal: -12128.343954830827\n",
      "Train Epoch: 3065 [256/118836 (0%)] Loss: 12332.156250\n",
      "Train Epoch: 3065 [33024/118836 (28%)] Loss: 12239.733398\n",
      "Train Epoch: 3065 [65792/118836 (55%)] Loss: 12209.332031\n",
      "Train Epoch: 3065 [98560/118836 (83%)] Loss: 12167.970703\n",
      "    epoch          : 3065\n",
      "    loss           : 12225.700923251397\n",
      "    val_loss       : 12245.44107246313\n",
      "    val_log_likelihood: -12151.00266846309\n",
      "    val_log_marginal: -12160.097446586235\n",
      "Train Epoch: 3066 [256/118836 (0%)] Loss: 12178.533203\n",
      "Train Epoch: 3066 [33024/118836 (28%)] Loss: 12157.945312\n",
      "Train Epoch: 3066 [65792/118836 (55%)] Loss: 12226.226562\n",
      "Train Epoch: 3066 [98560/118836 (83%)] Loss: 12247.390625\n",
      "    epoch          : 3066\n",
      "    loss           : 12225.542463102254\n",
      "    val_loss       : 12215.399739309787\n",
      "    val_log_likelihood: -12118.737612437966\n",
      "    val_log_marginal: -12127.756142908987\n",
      "Train Epoch: 3067 [256/118836 (0%)] Loss: 12227.192383\n",
      "Train Epoch: 3067 [33024/118836 (28%)] Loss: 12285.771484\n",
      "Train Epoch: 3067 [65792/118836 (55%)] Loss: 12272.031250\n",
      "Train Epoch: 3067 [98560/118836 (83%)] Loss: 12275.281250\n",
      "    epoch          : 3067\n",
      "    loss           : 12221.052770238834\n",
      "    val_loss       : 12214.818117092262\n",
      "    val_log_likelihood: -12122.012963483508\n",
      "    val_log_marginal: -12130.947695313025\n",
      "Train Epoch: 3068 [256/118836 (0%)] Loss: 12178.262695\n",
      "Train Epoch: 3068 [33024/118836 (28%)] Loss: 12202.085938\n",
      "Train Epoch: 3068 [65792/118836 (55%)] Loss: 12227.406250\n",
      "Train Epoch: 3068 [98560/118836 (83%)] Loss: 12182.349609\n",
      "    epoch          : 3068\n",
      "    loss           : 12215.188125516957\n",
      "    val_loss       : 12220.877052848531\n",
      "    val_log_likelihood: -12119.801665245037\n",
      "    val_log_marginal: -12128.84972823415\n",
      "Train Epoch: 3069 [256/118836 (0%)] Loss: 12220.151367\n",
      "Train Epoch: 3069 [33024/118836 (28%)] Loss: 12189.516602\n",
      "Train Epoch: 3069 [65792/118836 (55%)] Loss: 12278.734375\n",
      "Train Epoch: 3069 [98560/118836 (83%)] Loss: 12313.172852\n",
      "    epoch          : 3069\n",
      "    loss           : 12217.525260901313\n",
      "    val_loss       : 12215.342755148447\n",
      "    val_log_likelihood: -12121.564780907516\n",
      "    val_log_marginal: -12130.615316455845\n",
      "Train Epoch: 3070 [256/118836 (0%)] Loss: 12220.468750\n",
      "Train Epoch: 3070 [33024/118836 (28%)] Loss: 12201.207031\n",
      "Train Epoch: 3070 [65792/118836 (55%)] Loss: 12381.462891\n",
      "Train Epoch: 3070 [98560/118836 (83%)] Loss: 12201.253906\n",
      "    epoch          : 3070\n",
      "    loss           : 12221.580382806038\n",
      "    val_loss       : 12218.762016652094\n",
      "    val_log_likelihood: -12122.754175228754\n",
      "    val_log_marginal: -12131.60378398139\n",
      "Train Epoch: 3071 [256/118836 (0%)] Loss: 12226.566406\n",
      "Train Epoch: 3071 [33024/118836 (28%)] Loss: 12250.429688\n",
      "Train Epoch: 3071 [65792/118836 (55%)] Loss: 12349.458008\n",
      "Train Epoch: 3071 [98560/118836 (83%)] Loss: 12218.523438\n",
      "    epoch          : 3071\n",
      "    loss           : 12219.123271750932\n",
      "    val_loss       : 12215.549453270834\n",
      "    val_log_likelihood: -12122.374540393661\n",
      "    val_log_marginal: -12131.257602887925\n",
      "Train Epoch: 3072 [256/118836 (0%)] Loss: 12275.782227\n",
      "Train Epoch: 3072 [33024/118836 (28%)] Loss: 12258.188477\n",
      "Train Epoch: 3072 [65792/118836 (55%)] Loss: 12192.155273\n",
      "Train Epoch: 3072 [98560/118836 (83%)] Loss: 12243.939453\n",
      "    epoch          : 3072\n",
      "    loss           : 12220.133044807177\n",
      "    val_loss       : 12217.667808802404\n",
      "    val_log_likelihood: -12119.200254277814\n",
      "    val_log_marginal: -12128.020847297239\n",
      "Train Epoch: 3073 [256/118836 (0%)] Loss: 12187.213867\n",
      "Train Epoch: 3073 [33024/118836 (28%)] Loss: 12263.628906\n",
      "Train Epoch: 3073 [65792/118836 (55%)] Loss: 12097.216797\n",
      "Train Epoch: 3073 [98560/118836 (83%)] Loss: 12213.475586\n",
      "    epoch          : 3073\n",
      "    loss           : 12215.679464885752\n",
      "    val_loss       : 12216.02447299899\n",
      "    val_log_likelihood: -12122.65911781431\n",
      "    val_log_marginal: -12131.638418452798\n",
      "Train Epoch: 3074 [256/118836 (0%)] Loss: 12162.535156\n",
      "Train Epoch: 3074 [33024/118836 (28%)] Loss: 12250.909180\n",
      "Train Epoch: 3074 [65792/118836 (55%)] Loss: 12295.912109\n",
      "Train Epoch: 3074 [98560/118836 (83%)] Loss: 12235.939453\n",
      "    epoch          : 3074\n",
      "    loss           : 12215.24629827078\n",
      "    val_loss       : 12218.40972171498\n",
      "    val_log_likelihood: -12124.194107507496\n",
      "    val_log_marginal: -12132.994958284818\n",
      "Train Epoch: 3075 [256/118836 (0%)] Loss: 12132.984375\n",
      "Train Epoch: 3075 [33024/118836 (28%)] Loss: 12271.821289\n",
      "Train Epoch: 3075 [65792/118836 (55%)] Loss: 12256.766602\n",
      "Train Epoch: 3075 [98560/118836 (83%)] Loss: 12225.276367\n",
      "    epoch          : 3075\n",
      "    loss           : 12226.24445435277\n",
      "    val_loss       : 12221.585505553981\n",
      "    val_log_likelihood: -12122.827817572634\n",
      "    val_log_marginal: -12131.639796481642\n",
      "Train Epoch: 3076 [256/118836 (0%)] Loss: 12178.503906\n",
      "Train Epoch: 3076 [33024/118836 (28%)] Loss: 12407.794922\n",
      "Train Epoch: 3076 [65792/118836 (55%)] Loss: 12273.704102\n",
      "Train Epoch: 3076 [98560/118836 (83%)] Loss: 12165.485352\n",
      "    epoch          : 3076\n",
      "    loss           : 12220.229585078061\n",
      "    val_loss       : 12220.338897046391\n",
      "    val_log_likelihood: -12121.825107753051\n",
      "    val_log_marginal: -12130.729150784777\n",
      "Train Epoch: 3077 [256/118836 (0%)] Loss: 12239.839844\n",
      "Train Epoch: 3077 [33024/118836 (28%)] Loss: 12341.925781\n",
      "Train Epoch: 3077 [65792/118836 (55%)] Loss: 12267.966797\n",
      "Train Epoch: 3077 [98560/118836 (83%)] Loss: 12212.996094\n",
      "    epoch          : 3077\n",
      "    loss           : 12222.7366783628\n",
      "    val_loss       : 12223.443679159307\n",
      "    val_log_likelihood: -12118.185159804074\n",
      "    val_log_marginal: -12127.165771667138\n",
      "Train Epoch: 3078 [256/118836 (0%)] Loss: 12196.351562\n",
      "Train Epoch: 3078 [33024/118836 (28%)] Loss: 12188.539062\n",
      "Train Epoch: 3078 [65792/118836 (55%)] Loss: 12169.140625\n",
      "Train Epoch: 3078 [98560/118836 (83%)] Loss: 12340.185547\n",
      "    epoch          : 3078\n",
      "    loss           : 12219.934464659584\n",
      "    val_loss       : 12213.220286673268\n",
      "    val_log_likelihood: -12122.732355155345\n",
      "    val_log_marginal: -12131.594332267225\n",
      "Train Epoch: 3079 [256/118836 (0%)] Loss: 12343.900391\n",
      "Train Epoch: 3079 [33024/118836 (28%)] Loss: 12308.658203\n",
      "Train Epoch: 3079 [65792/118836 (55%)] Loss: 12155.480469\n",
      "Train Epoch: 3079 [98560/118836 (83%)] Loss: 12311.571289\n",
      "    epoch          : 3079\n",
      "    loss           : 12218.998201315653\n",
      "    val_loss       : 12218.983767583983\n",
      "    val_log_likelihood: -12118.27167047922\n",
      "    val_log_marginal: -12127.10892854314\n",
      "Train Epoch: 3080 [256/118836 (0%)] Loss: 12186.301758\n",
      "Train Epoch: 3080 [33024/118836 (28%)] Loss: 12268.142578\n",
      "Train Epoch: 3080 [65792/118836 (55%)] Loss: 12153.051758\n",
      "Train Epoch: 3080 [98560/118836 (83%)] Loss: 12223.220703\n",
      "    epoch          : 3080\n",
      "    loss           : 12218.211114395937\n",
      "    val_loss       : 12222.777704099935\n",
      "    val_log_likelihood: -12120.560479024503\n",
      "    val_log_marginal: -12129.463294706662\n",
      "Train Epoch: 3081 [256/118836 (0%)] Loss: 12398.552734\n",
      "Train Epoch: 3081 [33024/118836 (28%)] Loss: 12173.796875\n",
      "Train Epoch: 3081 [65792/118836 (55%)] Loss: 12359.323242\n",
      "Train Epoch: 3081 [98560/118836 (83%)] Loss: 12329.742188\n",
      "    epoch          : 3081\n",
      "    loss           : 12220.734241237593\n",
      "    val_loss       : 12221.371072165977\n",
      "    val_log_likelihood: -12124.496164831473\n",
      "    val_log_marginal: -12133.393667669508\n",
      "Train Epoch: 3082 [256/118836 (0%)] Loss: 12214.443359\n",
      "Train Epoch: 3082 [33024/118836 (28%)] Loss: 12306.538086\n",
      "Train Epoch: 3082 [65792/118836 (55%)] Loss: 12339.376953\n",
      "Train Epoch: 3082 [98560/118836 (83%)] Loss: 12190.179688\n",
      "    epoch          : 3082\n",
      "    loss           : 12216.279401073978\n",
      "    val_loss       : 12218.868385318614\n",
      "    val_log_likelihood: -12121.206501046836\n",
      "    val_log_marginal: -12130.006572218306\n",
      "Train Epoch: 3083 [256/118836 (0%)] Loss: 12184.857422\n",
      "Train Epoch: 3083 [33024/118836 (28%)] Loss: 12164.849609\n",
      "Train Epoch: 3083 [65792/118836 (55%)] Loss: 12251.685547\n",
      "Train Epoch: 3083 [98560/118836 (83%)] Loss: 12202.500000\n",
      "    epoch          : 3083\n",
      "    loss           : 12220.508425739248\n",
      "    val_loss       : 12220.48129352815\n",
      "    val_log_likelihood: -12125.715113859596\n",
      "    val_log_marginal: -12134.45595501378\n",
      "Train Epoch: 3084 [256/118836 (0%)] Loss: 12152.951172\n",
      "Train Epoch: 3084 [33024/118836 (28%)] Loss: 12237.185547\n",
      "Train Epoch: 3084 [65792/118836 (55%)] Loss: 12164.074219\n",
      "Train Epoch: 3084 [98560/118836 (83%)] Loss: 12265.165039\n",
      "    epoch          : 3084\n",
      "    loss           : 12221.69124987076\n",
      "    val_loss       : 12214.775103868194\n",
      "    val_log_likelihood: -12120.907857249018\n",
      "    val_log_marginal: -12129.837549450458\n",
      "Train Epoch: 3085 [256/118836 (0%)] Loss: 12344.075195\n",
      "Train Epoch: 3085 [33024/118836 (28%)] Loss: 12192.267578\n",
      "Train Epoch: 3085 [65792/118836 (55%)] Loss: 12210.957031\n",
      "Train Epoch: 3085 [98560/118836 (83%)] Loss: 12150.246094\n",
      "    epoch          : 3085\n",
      "    loss           : 12214.591172650435\n",
      "    val_loss       : 12216.748386342237\n",
      "    val_log_likelihood: -12120.89147749302\n",
      "    val_log_marginal: -12129.799462322428\n",
      "Train Epoch: 3086 [256/118836 (0%)] Loss: 12221.561523\n",
      "Train Epoch: 3086 [33024/118836 (28%)] Loss: 12286.403320\n",
      "Train Epoch: 3086 [65792/118836 (55%)] Loss: 12358.896484\n",
      "Train Epoch: 3086 [98560/118836 (83%)] Loss: 12210.061523\n",
      "    epoch          : 3086\n",
      "    loss           : 12217.502521938328\n",
      "    val_loss       : 12216.158010458577\n",
      "    val_log_likelihood: -12119.991071682434\n",
      "    val_log_marginal: -12128.938408588554\n",
      "Train Epoch: 3087 [256/118836 (0%)] Loss: 12323.859375\n",
      "Train Epoch: 3087 [33024/118836 (28%)] Loss: 12193.823242\n",
      "Train Epoch: 3087 [65792/118836 (55%)] Loss: 12253.596680\n",
      "Train Epoch: 3087 [98560/118836 (83%)] Loss: 12214.308594\n",
      "    epoch          : 3087\n",
      "    loss           : 12220.383126389319\n",
      "    val_loss       : 12225.007763411993\n",
      "    val_log_likelihood: -12124.472485977563\n",
      "    val_log_marginal: -12133.419623370039\n",
      "Train Epoch: 3088 [256/118836 (0%)] Loss: 12271.828125\n",
      "Train Epoch: 3088 [33024/118836 (28%)] Loss: 12333.255859\n",
      "Train Epoch: 3088 [65792/118836 (55%)] Loss: 12155.855469\n",
      "Train Epoch: 3088 [98560/118836 (83%)] Loss: 12308.974609\n",
      "    epoch          : 3088\n",
      "    loss           : 12219.125068819789\n",
      "    val_loss       : 12219.15902382051\n",
      "    val_log_likelihood: -12122.429351801591\n",
      "    val_log_marginal: -12131.16833312597\n",
      "Train Epoch: 3089 [256/118836 (0%)] Loss: 12243.532227\n",
      "Train Epoch: 3089 [33024/118836 (28%)] Loss: 12229.937500\n",
      "Train Epoch: 3089 [65792/118836 (55%)] Loss: 12329.364258\n",
      "Train Epoch: 3089 [98560/118836 (83%)] Loss: 12153.817383\n",
      "    epoch          : 3089\n",
      "    loss           : 12220.16589155552\n",
      "    val_loss       : 12221.243952420742\n",
      "    val_log_likelihood: -12120.86093507677\n",
      "    val_log_marginal: -12129.587697291081\n",
      "Train Epoch: 3090 [256/118836 (0%)] Loss: 12143.757812\n",
      "Train Epoch: 3090 [33024/118836 (28%)] Loss: 12222.904297\n",
      "Train Epoch: 3090 [65792/118836 (55%)] Loss: 12351.621094\n",
      "Train Epoch: 3090 [98560/118836 (83%)] Loss: 12182.249023\n",
      "    epoch          : 3090\n",
      "    loss           : 12216.10510235732\n",
      "    val_loss       : 12217.646744397054\n",
      "    val_log_likelihood: -12121.525953299471\n",
      "    val_log_marginal: -12130.24646487377\n",
      "Train Epoch: 3091 [256/118836 (0%)] Loss: 12167.171875\n",
      "Train Epoch: 3091 [33024/118836 (28%)] Loss: 12109.727539\n",
      "Train Epoch: 3091 [65792/118836 (55%)] Loss: 12188.419922\n",
      "Train Epoch: 3091 [98560/118836 (83%)] Loss: 12380.339844\n",
      "    epoch          : 3091\n",
      "    loss           : 12220.917055029982\n",
      "    val_loss       : 12220.849965728788\n",
      "    val_log_likelihood: -12122.797850754758\n",
      "    val_log_marginal: -12131.645801443925\n",
      "Train Epoch: 3092 [256/118836 (0%)] Loss: 12204.996094\n",
      "Train Epoch: 3092 [33024/118836 (28%)] Loss: 12216.453125\n",
      "Train Epoch: 3092 [65792/118836 (55%)] Loss: 12311.073242\n",
      "Train Epoch: 3092 [98560/118836 (83%)] Loss: 12231.838867\n",
      "    epoch          : 3092\n",
      "    loss           : 12220.076766536135\n",
      "    val_loss       : 12221.320754584332\n",
      "    val_log_likelihood: -12121.599179170544\n",
      "    val_log_marginal: -12130.495924726803\n",
      "Train Epoch: 3093 [256/118836 (0%)] Loss: 12176.433594\n",
      "Train Epoch: 3093 [33024/118836 (28%)] Loss: 12186.916992\n",
      "Train Epoch: 3093 [65792/118836 (55%)] Loss: 12224.809570\n",
      "Train Epoch: 3093 [98560/118836 (83%)] Loss: 12212.243164\n",
      "    epoch          : 3093\n",
      "    loss           : 12216.422584199234\n",
      "    val_loss       : 12220.878280221408\n",
      "    val_log_likelihood: -12122.13919319298\n",
      "    val_log_marginal: -12130.891939688358\n",
      "Train Epoch: 3094 [256/118836 (0%)] Loss: 12235.458008\n",
      "Train Epoch: 3094 [33024/118836 (28%)] Loss: 12313.434570\n",
      "Train Epoch: 3094 [65792/118836 (55%)] Loss: 12171.660156\n",
      "Train Epoch: 3094 [98560/118836 (83%)] Loss: 12261.941406\n",
      "    epoch          : 3094\n",
      "    loss           : 12219.67557915245\n",
      "    val_loss       : 12216.21862426632\n",
      "    val_log_likelihood: -12119.41107336254\n",
      "    val_log_marginal: -12128.38051030305\n",
      "Train Epoch: 3095 [256/118836 (0%)] Loss: 12292.021484\n",
      "Train Epoch: 3095 [33024/118836 (28%)] Loss: 12331.002930\n",
      "Train Epoch: 3095 [65792/118836 (55%)] Loss: 12388.455078\n",
      "Train Epoch: 3095 [98560/118836 (83%)] Loss: 12201.515625\n",
      "    epoch          : 3095\n",
      "    loss           : 12226.096212973014\n",
      "    val_loss       : 12219.800609534055\n",
      "    val_log_likelihood: -12121.793220766129\n",
      "    val_log_marginal: -12130.665120841595\n",
      "Train Epoch: 3096 [256/118836 (0%)] Loss: 12223.453125\n",
      "Train Epoch: 3096 [33024/118836 (28%)] Loss: 12234.893555\n",
      "Train Epoch: 3096 [65792/118836 (55%)] Loss: 12267.464844\n",
      "Train Epoch: 3096 [98560/118836 (83%)] Loss: 12220.552734\n",
      "    epoch          : 3096\n",
      "    loss           : 12221.201877358611\n",
      "    val_loss       : 12218.338420430315\n",
      "    val_log_likelihood: -12120.383528161186\n",
      "    val_log_marginal: -12129.378989570572\n",
      "Train Epoch: 3097 [256/118836 (0%)] Loss: 12217.710938\n",
      "Train Epoch: 3097 [33024/118836 (28%)] Loss: 12273.776367\n",
      "Train Epoch: 3097 [65792/118836 (55%)] Loss: 12169.434570\n",
      "Train Epoch: 3097 [98560/118836 (83%)] Loss: 12233.687500\n",
      "    epoch          : 3097\n",
      "    loss           : 12217.569889726788\n",
      "    val_loss       : 12218.31340841035\n",
      "    val_log_likelihood: -12120.380300416151\n",
      "    val_log_marginal: -12129.175506923119\n",
      "Train Epoch: 3098 [256/118836 (0%)] Loss: 12302.675781\n",
      "Train Epoch: 3098 [33024/118836 (28%)] Loss: 12319.252930\n",
      "Train Epoch: 3098 [65792/118836 (55%)] Loss: 12234.094727\n",
      "Train Epoch: 3098 [98560/118836 (83%)] Loss: 12197.082031\n",
      "    epoch          : 3098\n",
      "    loss           : 12213.520196346411\n",
      "    val_loss       : 12216.832020512737\n",
      "    val_log_likelihood: -12121.861718265354\n",
      "    val_log_marginal: -12130.81164528028\n",
      "Train Epoch: 3099 [256/118836 (0%)] Loss: 12214.322266\n",
      "Train Epoch: 3099 [33024/118836 (28%)] Loss: 12239.782227\n",
      "Train Epoch: 3099 [65792/118836 (55%)] Loss: 12253.231445\n",
      "Train Epoch: 3099 [98560/118836 (83%)] Loss: 12354.579102\n",
      "    epoch          : 3099\n",
      "    loss           : 12215.720202646815\n",
      "    val_loss       : 12218.209156237168\n",
      "    val_log_likelihood: -12121.533599404207\n",
      "    val_log_marginal: -12130.318363560336\n",
      "Train Epoch: 3100 [256/118836 (0%)] Loss: 12216.912109\n",
      "Train Epoch: 3100 [33024/118836 (28%)] Loss: 12287.215820\n",
      "Train Epoch: 3100 [65792/118836 (55%)] Loss: 12283.095703\n",
      "Train Epoch: 3100 [98560/118836 (83%)] Loss: 12129.978516\n",
      "    epoch          : 3100\n",
      "    loss           : 12216.082392150021\n",
      "    val_loss       : 12216.548397513398\n",
      "    val_log_likelihood: -12124.480463095793\n",
      "    val_log_marginal: -12133.474916871834\n",
      "Saving checkpoint: saved/models/SelfiesAutoencodingOperad/0905_154251/checkpoint-epoch3100.pth ...\n",
      "Train Epoch: 3101 [256/118836 (0%)] Loss: 12222.292969\n",
      "Train Epoch: 3101 [33024/118836 (28%)] Loss: 12265.322266\n",
      "Train Epoch: 3101 [65792/118836 (55%)] Loss: 12179.571289\n",
      "Train Epoch: 3101 [98560/118836 (83%)] Loss: 12262.046875\n",
      "    epoch          : 3101\n",
      "    loss           : 12220.70781104606\n",
      "    val_loss       : 12224.417450313755\n",
      "    val_log_likelihood: -12119.10441415943\n",
      "    val_log_marginal: -12128.08133966088\n",
      "Train Epoch: 3102 [256/118836 (0%)] Loss: 12156.937500\n",
      "Train Epoch: 3102 [33024/118836 (28%)] Loss: 12327.507812\n",
      "Train Epoch: 3102 [65792/118836 (55%)] Loss: 12267.469727\n",
      "Train Epoch: 3102 [98560/118836 (83%)] Loss: 12192.382812\n",
      "    epoch          : 3102\n",
      "    loss           : 12216.260760280966\n",
      "    val_loss       : 12212.742029199122\n",
      "    val_log_likelihood: -12118.060910036704\n",
      "    val_log_marginal: -12126.973477689493\n",
      "Train Epoch: 3103 [256/118836 (0%)] Loss: 12159.717773\n",
      "Train Epoch: 3103 [33024/118836 (28%)] Loss: 12223.802734\n",
      "Train Epoch: 3103 [65792/118836 (55%)] Loss: 12291.205078\n",
      "Train Epoch: 3103 [98560/118836 (83%)] Loss: 12183.968750\n",
      "    epoch          : 3103\n",
      "    loss           : 12215.655628521765\n",
      "    val_loss       : 12216.09792298607\n",
      "    val_log_likelihood: -12121.488494979063\n",
      "    val_log_marginal: -12130.32496646067\n",
      "Train Epoch: 3104 [256/118836 (0%)] Loss: 12154.246094\n",
      "Train Epoch: 3104 [33024/118836 (28%)] Loss: 12214.781250\n",
      "Train Epoch: 3104 [65792/118836 (55%)] Loss: 12241.275391\n",
      "Train Epoch: 3104 [98560/118836 (83%)] Loss: 12384.978516\n",
      "    epoch          : 3104\n",
      "    loss           : 12215.05269124147\n",
      "    val_loss       : 12215.554168561277\n",
      "    val_log_likelihood: -12119.343425933106\n",
      "    val_log_marginal: -12128.113899898337\n",
      "Train Epoch: 3105 [256/118836 (0%)] Loss: 12308.377930\n",
      "Train Epoch: 3105 [33024/118836 (28%)] Loss: 12255.009766\n",
      "Train Epoch: 3105 [65792/118836 (55%)] Loss: 12271.422852\n",
      "Train Epoch: 3105 [98560/118836 (83%)] Loss: 12200.648438\n",
      "    epoch          : 3105\n",
      "    loss           : 12217.960108431555\n",
      "    val_loss       : 12218.338594033037\n",
      "    val_log_likelihood: -12124.049502268144\n",
      "    val_log_marginal: -12132.919778704647\n",
      "Train Epoch: 3106 [256/118836 (0%)] Loss: 12133.447266\n",
      "Train Epoch: 3106 [33024/118836 (28%)] Loss: 12219.502930\n",
      "Train Epoch: 3106 [65792/118836 (55%)] Loss: 12350.669922\n",
      "Train Epoch: 3106 [98560/118836 (83%)] Loss: 12249.394531\n",
      "    epoch          : 3106\n",
      "    loss           : 12221.13798884667\n",
      "    val_loss       : 12218.542714775474\n",
      "    val_log_likelihood: -12122.171889700941\n",
      "    val_log_marginal: -12131.122897004923\n",
      "Train Epoch: 3107 [256/118836 (0%)] Loss: 12196.689453\n",
      "Train Epoch: 3107 [33024/118836 (28%)] Loss: 12262.704102\n",
      "Train Epoch: 3107 [65792/118836 (55%)] Loss: 12265.260742\n",
      "Train Epoch: 3107 [98560/118836 (83%)] Loss: 12231.287109\n",
      "    epoch          : 3107\n",
      "    loss           : 12218.673113433106\n",
      "    val_loss       : 12222.847778283363\n",
      "    val_log_likelihood: -12127.011684340107\n",
      "    val_log_marginal: -12136.09783028419\n",
      "Train Epoch: 3108 [256/118836 (0%)] Loss: 12249.553711\n",
      "Train Epoch: 3108 [33024/118836 (28%)] Loss: 12244.596680\n",
      "Train Epoch: 3108 [65792/118836 (55%)] Loss: 12174.630859\n",
      "Train Epoch: 3108 [98560/118836 (83%)] Loss: 12269.929688\n",
      "    epoch          : 3108\n",
      "    loss           : 12218.447397933467\n",
      "    val_loss       : 12216.79773994947\n",
      "    val_log_likelihood: -12120.265412724875\n",
      "    val_log_marginal: -12129.219458251304\n",
      "Train Epoch: 3109 [256/118836 (0%)] Loss: 12237.596680\n",
      "Train Epoch: 3109 [33024/118836 (28%)] Loss: 12253.648438\n",
      "Train Epoch: 3109 [65792/118836 (55%)] Loss: 12228.690430\n",
      "Train Epoch: 3109 [98560/118836 (83%)] Loss: 12182.371094\n",
      "    epoch          : 3109\n",
      "    loss           : 12218.602310794045\n",
      "    val_loss       : 12224.897810564005\n",
      "    val_log_likelihood: -12128.839254419974\n",
      "    val_log_marginal: -12137.95773112069\n",
      "Train Epoch: 3110 [256/118836 (0%)] Loss: 12268.462891\n",
      "Train Epoch: 3110 [33024/118836 (28%)] Loss: 12257.808594\n",
      "Train Epoch: 3110 [65792/118836 (55%)] Loss: 12190.744141\n",
      "Train Epoch: 3110 [98560/118836 (83%)] Loss: 12190.099609\n",
      "    epoch          : 3110\n",
      "    loss           : 12217.219456129807\n",
      "    val_loss       : 12219.85711058197\n",
      "    val_log_likelihood: -12124.488344415582\n",
      "    val_log_marginal: -12133.401526702271\n",
      "Train Epoch: 3111 [256/118836 (0%)] Loss: 12253.521484\n",
      "Train Epoch: 3111 [33024/118836 (28%)] Loss: 12220.776367\n",
      "Train Epoch: 3111 [65792/118836 (55%)] Loss: 12199.357422\n",
      "Train Epoch: 3111 [98560/118836 (83%)] Loss: 12181.539062\n",
      "    epoch          : 3111\n",
      "    loss           : 12218.755720927678\n",
      "    val_loss       : 12215.870936773932\n",
      "    val_log_likelihood: -12119.789651506926\n",
      "    val_log_marginal: -12128.630426094074\n",
      "Train Epoch: 3112 [256/118836 (0%)] Loss: 12203.385742\n",
      "Train Epoch: 3112 [33024/118836 (28%)] Loss: 12186.072266\n",
      "Train Epoch: 3112 [65792/118836 (55%)] Loss: 12205.691406\n",
      "Train Epoch: 3112 [98560/118836 (83%)] Loss: 12180.684570\n",
      "    epoch          : 3112\n",
      "    loss           : 12219.153550357993\n",
      "    val_loss       : 12216.695784152776\n",
      "    val_log_likelihood: -12122.166163280604\n",
      "    val_log_marginal: -12130.997814654605\n",
      "Train Epoch: 3113 [256/118836 (0%)] Loss: 12356.405273\n",
      "Train Epoch: 3113 [33024/118836 (28%)] Loss: 12247.076172\n",
      "Train Epoch: 3113 [65792/118836 (55%)] Loss: 12290.666016\n",
      "Train Epoch: 3113 [98560/118836 (83%)] Loss: 12231.970703\n",
      "    epoch          : 3113\n",
      "    loss           : 12215.715308202802\n",
      "    val_loss       : 12219.703262072073\n",
      "    val_log_likelihood: -12121.151850056865\n",
      "    val_log_marginal: -12130.056397037593\n",
      "Train Epoch: 3114 [256/118836 (0%)] Loss: 12282.232422\n",
      "Train Epoch: 3114 [33024/118836 (28%)] Loss: 12270.613281\n",
      "Train Epoch: 3114 [65792/118836 (55%)] Loss: 12182.032227\n",
      "Train Epoch: 3114 [98560/118836 (83%)] Loss: 12201.293945\n",
      "    epoch          : 3114\n",
      "    loss           : 12221.353495269852\n",
      "    val_loss       : 12227.06647390317\n",
      "    val_log_likelihood: -12126.78116906405\n",
      "    val_log_marginal: -12135.922690145833\n",
      "Train Epoch: 3115 [256/118836 (0%)] Loss: 12177.508789\n",
      "Train Epoch: 3115 [33024/118836 (28%)] Loss: 12265.693359\n",
      "Train Epoch: 3115 [65792/118836 (55%)] Loss: 12158.651367\n",
      "Train Epoch: 3115 [98560/118836 (83%)] Loss: 12239.511719\n",
      "    epoch          : 3115\n",
      "    loss           : 12221.54809921681\n",
      "    val_loss       : 12221.359440613125\n",
      "    val_log_likelihood: -12126.3523771906\n",
      "    val_log_marginal: -12135.409371747399\n",
      "Train Epoch: 3116 [256/118836 (0%)] Loss: 12320.964844\n",
      "Train Epoch: 3116 [33024/118836 (28%)] Loss: 12187.551758\n",
      "Train Epoch: 3116 [65792/118836 (55%)] Loss: 12424.069336\n",
      "Train Epoch: 3116 [98560/118836 (83%)] Loss: 12207.125977\n",
      "    epoch          : 3116\n",
      "    loss           : 12223.431435134924\n",
      "    val_loss       : 12231.25756021262\n",
      "    val_log_likelihood: -12125.19446243021\n",
      "    val_log_marginal: -12134.370352388196\n",
      "Train Epoch: 3117 [256/118836 (0%)] Loss: 12257.500000\n",
      "Train Epoch: 3117 [33024/118836 (28%)] Loss: 12312.096680\n",
      "Train Epoch: 3117 [65792/118836 (55%)] Loss: 12207.629883\n",
      "Train Epoch: 3117 [98560/118836 (83%)] Loss: 12235.766602\n",
      "    epoch          : 3117\n",
      "    loss           : 12221.869919774865\n",
      "    val_loss       : 12224.998350443033\n",
      "    val_log_likelihood: -12121.322701322115\n",
      "    val_log_marginal: -12130.495017618725\n",
      "Train Epoch: 3118 [256/118836 (0%)] Loss: 12307.523438\n",
      "Train Epoch: 3118 [33024/118836 (28%)] Loss: 12151.773438\n",
      "Train Epoch: 3118 [65792/118836 (55%)] Loss: 12204.208008\n",
      "Train Epoch: 3118 [98560/118836 (83%)] Loss: 12153.539062\n",
      "    epoch          : 3118\n",
      "    loss           : 12217.810206491677\n",
      "    val_loss       : 12221.009789689926\n",
      "    val_log_likelihood: -12121.81636602435\n",
      "    val_log_marginal: -12130.78224777194\n",
      "Train Epoch: 3119 [256/118836 (0%)] Loss: 12169.795898\n",
      "Train Epoch: 3119 [33024/118836 (28%)] Loss: 12241.390625\n",
      "Train Epoch: 3119 [65792/118836 (55%)] Loss: 12204.227539\n",
      "Train Epoch: 3119 [98560/118836 (83%)] Loss: 12249.478516\n",
      "    epoch          : 3119\n",
      "    loss           : 12220.651808538823\n",
      "    val_loss       : 12219.418516672735\n",
      "    val_log_likelihood: -12122.251528251654\n",
      "    val_log_marginal: -12131.048873047695\n",
      "Train Epoch: 3120 [256/118836 (0%)] Loss: 12236.427734\n",
      "Train Epoch: 3120 [33024/118836 (28%)] Loss: 12306.369141\n",
      "Train Epoch: 3120 [65792/118836 (55%)] Loss: 12212.615234\n",
      "Train Epoch: 3120 [98560/118836 (83%)] Loss: 12229.915039\n",
      "    epoch          : 3120\n",
      "    loss           : 12221.027421293424\n",
      "    val_loss       : 12219.448155396176\n",
      "    val_log_likelihood: -12121.815023069168\n",
      "    val_log_marginal: -12130.819483729754\n",
      "Train Epoch: 3121 [256/118836 (0%)] Loss: 12182.595703\n",
      "Train Epoch: 3121 [33024/118836 (28%)] Loss: 12325.124023\n",
      "Train Epoch: 3121 [65792/118836 (55%)] Loss: 12335.750000\n",
      "Train Epoch: 3121 [98560/118836 (83%)] Loss: 12191.255859\n",
      "    epoch          : 3121\n",
      "    loss           : 12221.007171797455\n",
      "    val_loss       : 12215.605869616824\n",
      "    val_log_likelihood: -12119.454590732268\n",
      "    val_log_marginal: -12128.566344625815\n",
      "Train Epoch: 3122 [256/118836 (0%)] Loss: 12204.210938\n",
      "Train Epoch: 3122 [33024/118836 (28%)] Loss: 12229.335938\n",
      "Train Epoch: 3122 [65792/118836 (55%)] Loss: 12265.769531\n",
      "Train Epoch: 3122 [98560/118836 (83%)] Loss: 12271.666016\n",
      "    epoch          : 3122\n",
      "    loss           : 12220.338061058985\n",
      "    val_loss       : 12220.58781717513\n",
      "    val_log_likelihood: -12124.100939729373\n",
      "    val_log_marginal: -12133.041384533273\n",
      "Train Epoch: 3123 [256/118836 (0%)] Loss: 12116.096680\n",
      "Train Epoch: 3123 [33024/118836 (28%)] Loss: 12150.883789\n",
      "Train Epoch: 3123 [65792/118836 (55%)] Loss: 12378.116211\n",
      "Train Epoch: 3123 [98560/118836 (83%)] Loss: 12207.235352\n",
      "    epoch          : 3123\n",
      "    loss           : 12218.785282258064\n",
      "    val_loss       : 12218.352220191025\n",
      "    val_log_likelihood: -12125.862043786186\n",
      "    val_log_marginal: -12134.978649062487\n",
      "Train Epoch: 3124 [256/118836 (0%)] Loss: 12131.189453\n",
      "Train Epoch: 3124 [33024/118836 (28%)] Loss: 12130.968750\n",
      "Train Epoch: 3124 [65792/118836 (55%)] Loss: 12215.060547\n",
      "Train Epoch: 3124 [98560/118836 (83%)] Loss: 12309.676758\n",
      "    epoch          : 3124\n",
      "    loss           : 12219.398803084936\n",
      "    val_loss       : 12221.02449838606\n",
      "    val_log_likelihood: -12122.504099947011\n",
      "    val_log_marginal: -12131.47634131098\n",
      "Train Epoch: 3125 [256/118836 (0%)] Loss: 12168.732422\n",
      "Train Epoch: 3125 [33024/118836 (28%)] Loss: 12306.173828\n",
      "Train Epoch: 3125 [65792/118836 (55%)] Loss: 12394.718750\n",
      "Train Epoch: 3125 [98560/118836 (83%)] Loss: 12228.865234\n",
      "    epoch          : 3125\n",
      "    loss           : 12216.646912479322\n",
      "    val_loss       : 12217.152959238152\n",
      "    val_log_likelihood: -12118.697916020472\n",
      "    val_log_marginal: -12127.556797323536\n",
      "Train Epoch: 3126 [256/118836 (0%)] Loss: 12208.683594\n",
      "Train Epoch: 3126 [33024/118836 (28%)] Loss: 12239.958008\n",
      "Train Epoch: 3126 [65792/118836 (55%)] Loss: 12172.829102\n",
      "Train Epoch: 3126 [98560/118836 (83%)] Loss: 12162.036133\n",
      "    epoch          : 3126\n",
      "    loss           : 12221.276251841657\n",
      "    val_loss       : 12219.851526996445\n",
      "    val_log_likelihood: -12119.476543114144\n",
      "    val_log_marginal: -12128.426146255943\n",
      "Train Epoch: 3127 [256/118836 (0%)] Loss: 12187.106445\n",
      "Train Epoch: 3127 [33024/118836 (28%)] Loss: 12202.800781\n",
      "Train Epoch: 3127 [65792/118836 (55%)] Loss: 12149.573242\n",
      "Train Epoch: 3127 [98560/118836 (83%)] Loss: 12196.797852\n",
      "    epoch          : 3127\n",
      "    loss           : 12218.121278238732\n",
      "    val_loss       : 12215.628851512509\n",
      "    val_log_likelihood: -12118.050195958696\n",
      "    val_log_marginal: -12126.827835282225\n",
      "Train Epoch: 3128 [256/118836 (0%)] Loss: 12350.511719\n",
      "Train Epoch: 3128 [33024/118836 (28%)] Loss: 12286.717773\n",
      "Train Epoch: 3128 [65792/118836 (55%)] Loss: 12214.094727\n",
      "Train Epoch: 3128 [98560/118836 (83%)] Loss: 12279.053711\n",
      "    epoch          : 3128\n",
      "    loss           : 12220.01282438999\n",
      "    val_loss       : 12221.72102232386\n",
      "    val_log_likelihood: -12123.05308445125\n",
      "    val_log_marginal: -12131.918646390217\n",
      "Train Epoch: 3129 [256/118836 (0%)] Loss: 12150.129883\n",
      "Train Epoch: 3129 [33024/118836 (28%)] Loss: 12160.214844\n",
      "Train Epoch: 3129 [65792/118836 (55%)] Loss: 12187.091797\n",
      "Train Epoch: 3129 [98560/118836 (83%)] Loss: 12276.933594\n",
      "    epoch          : 3129\n",
      "    loss           : 12214.622571921527\n",
      "    val_loss       : 12215.569810672985\n",
      "    val_log_likelihood: -12123.288569937706\n",
      "    val_log_marginal: -12132.320535078039\n",
      "Train Epoch: 3130 [256/118836 (0%)] Loss: 12350.593750\n",
      "Train Epoch: 3130 [33024/118836 (28%)] Loss: 12234.068359\n",
      "Train Epoch: 3130 [65792/118836 (55%)] Loss: 12229.087891\n",
      "Train Epoch: 3130 [98560/118836 (83%)] Loss: 12220.689453\n",
      "    epoch          : 3130\n",
      "    loss           : 12219.87766571676\n",
      "    val_loss       : 12227.224819350438\n",
      "    val_log_likelihood: -12125.104651797716\n",
      "    val_log_marginal: -12134.231399838041\n",
      "Train Epoch: 3131 [256/118836 (0%)] Loss: 12229.543945\n",
      "Train Epoch: 3131 [33024/118836 (28%)] Loss: 12177.494141\n",
      "Train Epoch: 3131 [65792/118836 (55%)] Loss: 12197.065430\n",
      "Train Epoch: 3131 [98560/118836 (83%)] Loss: 12165.564453\n",
      "    epoch          : 3131\n",
      "    loss           : 12218.445294406534\n",
      "    val_loss       : 12218.41533171005\n",
      "    val_log_likelihood: -12119.057708139475\n",
      "    val_log_marginal: -12128.215911161771\n",
      "Train Epoch: 3132 [256/118836 (0%)] Loss: 12176.985352\n",
      "Train Epoch: 3132 [33024/118836 (28%)] Loss: 12185.453125\n",
      "Train Epoch: 3132 [65792/118836 (55%)] Loss: 12284.527344\n",
      "Train Epoch: 3132 [98560/118836 (83%)] Loss: 12261.753906\n",
      "    epoch          : 3132\n",
      "    loss           : 12224.485539282205\n",
      "    val_loss       : 12220.65544607806\n",
      "    val_log_likelihood: -12126.428470068238\n",
      "    val_log_marginal: -12135.506138186729\n",
      "Train Epoch: 3133 [256/118836 (0%)] Loss: 12301.092773\n",
      "Train Epoch: 3133 [33024/118836 (28%)] Loss: 12393.802734\n",
      "Train Epoch: 3133 [65792/118836 (55%)] Loss: 12335.563477\n",
      "Train Epoch: 3133 [98560/118836 (83%)] Loss: 12209.331055\n",
      "    epoch          : 3133\n",
      "    loss           : 12216.71388350393\n",
      "    val_loss       : 12219.432852216869\n",
      "    val_log_likelihood: -12119.717412699029\n",
      "    val_log_marginal: -12128.889079280641\n",
      "Train Epoch: 3134 [256/118836 (0%)] Loss: 12163.775391\n",
      "Train Epoch: 3134 [33024/118836 (28%)] Loss: 12200.357422\n",
      "Train Epoch: 3134 [65792/118836 (55%)] Loss: 12232.758789\n",
      "Train Epoch: 3134 [98560/118836 (83%)] Loss: 12250.099609\n",
      "    epoch          : 3134\n",
      "    loss           : 12216.133160314568\n",
      "    val_loss       : 12219.744025308737\n",
      "    val_log_likelihood: -12116.645657406689\n",
      "    val_log_marginal: -12125.645865864055\n",
      "Train Epoch: 3135 [256/118836 (0%)] Loss: 12255.085938\n",
      "Train Epoch: 3135 [33024/118836 (28%)] Loss: 12208.636719\n",
      "Train Epoch: 3135 [65792/118836 (55%)] Loss: 12249.250000\n",
      "Train Epoch: 3135 [98560/118836 (83%)] Loss: 12262.672852\n",
      "    epoch          : 3135\n",
      "    loss           : 12215.186625536342\n",
      "    val_loss       : 12221.544548824793\n",
      "    val_log_likelihood: -12124.732712178195\n",
      "    val_log_marginal: -12133.850665371225\n",
      "Train Epoch: 3136 [256/118836 (0%)] Loss: 12309.437500\n",
      "Train Epoch: 3136 [33024/118836 (28%)] Loss: 12197.486328\n",
      "Train Epoch: 3136 [65792/118836 (55%)] Loss: 12268.677734\n",
      "Train Epoch: 3136 [98560/118836 (83%)] Loss: 12355.447266\n",
      "    epoch          : 3136\n",
      "    loss           : 12224.383273883373\n",
      "    val_loss       : 12219.283820875817\n",
      "    val_log_likelihood: -12121.394233838657\n",
      "    val_log_marginal: -12130.385046915937\n",
      "Train Epoch: 3137 [256/118836 (0%)] Loss: 12256.138672\n",
      "Train Epoch: 3137 [33024/118836 (28%)] Loss: 12307.109375\n",
      "Train Epoch: 3137 [65792/118836 (55%)] Loss: 12248.291016\n",
      "Train Epoch: 3137 [98560/118836 (83%)] Loss: 12316.717773\n",
      "    epoch          : 3137\n",
      "    loss           : 12223.046941396558\n",
      "    val_loss       : 12219.266184511314\n",
      "    val_log_likelihood: -12122.364244727047\n",
      "    val_log_marginal: -12131.198807905075\n",
      "Train Epoch: 3138 [256/118836 (0%)] Loss: 12344.875977\n",
      "Train Epoch: 3138 [33024/118836 (28%)] Loss: 12188.541016\n",
      "Train Epoch: 3138 [65792/118836 (55%)] Loss: 12195.309570\n",
      "Train Epoch: 3138 [98560/118836 (83%)] Loss: 12147.597656\n",
      "    epoch          : 3138\n",
      "    loss           : 12217.597857216708\n",
      "    val_loss       : 12215.427046831375\n",
      "    val_log_likelihood: -12118.188352008374\n",
      "    val_log_marginal: -12127.059447561209\n",
      "Train Epoch: 3139 [256/118836 (0%)] Loss: 12270.453125\n",
      "Train Epoch: 3139 [33024/118836 (28%)] Loss: 12350.215820\n",
      "Train Epoch: 3139 [65792/118836 (55%)] Loss: 12271.979492\n",
      "Train Epoch: 3139 [98560/118836 (83%)] Loss: 12238.973633\n",
      "    epoch          : 3139\n",
      "    loss           : 12217.378773133789\n",
      "    val_loss       : 12215.07063899195\n",
      "    val_log_likelihood: -12120.579254064569\n",
      "    val_log_marginal: -12129.31596928057\n",
      "Train Epoch: 3140 [256/118836 (0%)] Loss: 12319.436523\n",
      "Train Epoch: 3140 [33024/118836 (28%)] Loss: 12312.264648\n",
      "Train Epoch: 3140 [65792/118836 (55%)] Loss: 12173.923828\n",
      "Train Epoch: 3140 [98560/118836 (83%)] Loss: 12099.642578\n",
      "    epoch          : 3140\n",
      "    loss           : 12218.042381358562\n",
      "    val_loss       : 12214.162321419246\n",
      "    val_log_likelihood: -12116.496023476271\n",
      "    val_log_marginal: -12125.18850148316\n",
      "Train Epoch: 3141 [256/118836 (0%)] Loss: 12314.279297\n",
      "Train Epoch: 3141 [33024/118836 (28%)] Loss: 12283.943359\n",
      "Train Epoch: 3141 [65792/118836 (55%)] Loss: 12171.681641\n",
      "Train Epoch: 3141 [98560/118836 (83%)] Loss: 12217.432617\n",
      "    epoch          : 3141\n",
      "    loss           : 12214.946230904932\n",
      "    val_loss       : 12215.885529409405\n",
      "    val_log_likelihood: -12115.357264041822\n",
      "    val_log_marginal: -12124.223199769702\n",
      "Train Epoch: 3142 [256/118836 (0%)] Loss: 12133.387695\n",
      "Train Epoch: 3142 [33024/118836 (28%)] Loss: 12179.104492\n",
      "Train Epoch: 3142 [65792/118836 (55%)] Loss: 12283.744141\n",
      "Train Epoch: 3142 [98560/118836 (83%)] Loss: 12210.167969\n",
      "    epoch          : 3142\n",
      "    loss           : 12221.244644011062\n",
      "    val_loss       : 12218.136575139462\n",
      "    val_log_likelihood: -12119.540660863835\n",
      "    val_log_marginal: -12128.402489796421\n",
      "Train Epoch: 3143 [256/118836 (0%)] Loss: 12270.003906\n",
      "Train Epoch: 3143 [33024/118836 (28%)] Loss: 12241.697266\n",
      "Train Epoch: 3143 [65792/118836 (55%)] Loss: 12231.619141\n",
      "Train Epoch: 3143 [98560/118836 (83%)] Loss: 12244.887695\n",
      "    epoch          : 3143\n",
      "    loss           : 12216.818174240076\n",
      "    val_loss       : 12211.909299231755\n",
      "    val_log_likelihood: -12112.121081956937\n",
      "    val_log_marginal: -12121.01083148367\n",
      "Train Epoch: 3144 [256/118836 (0%)] Loss: 12375.312500\n",
      "Train Epoch: 3144 [33024/118836 (28%)] Loss: 12154.976562\n",
      "Train Epoch: 3144 [65792/118836 (55%)] Loss: 12253.130859\n",
      "Train Epoch: 3144 [98560/118836 (83%)] Loss: 12191.095703\n",
      "    epoch          : 3144\n",
      "    loss           : 12211.835595985835\n",
      "    val_loss       : 12220.128916943493\n",
      "    val_log_likelihood: -12120.041424666564\n",
      "    val_log_marginal: -12128.965713123409\n",
      "Train Epoch: 3145 [256/118836 (0%)] Loss: 12274.260742\n",
      "Train Epoch: 3145 [33024/118836 (28%)] Loss: 12299.712891\n",
      "Train Epoch: 3145 [65792/118836 (55%)] Loss: 12168.631836\n",
      "Train Epoch: 3145 [98560/118836 (83%)] Loss: 12262.534180\n",
      "    epoch          : 3145\n",
      "    loss           : 12214.388656204766\n",
      "    val_loss       : 12214.185938821769\n",
      "    val_log_likelihood: -12117.352831142733\n",
      "    val_log_marginal: -12126.116810657604\n",
      "Train Epoch: 3146 [256/118836 (0%)] Loss: 12289.369141\n",
      "Train Epoch: 3146 [33024/118836 (28%)] Loss: 12240.164062\n",
      "Train Epoch: 3146 [65792/118836 (55%)] Loss: 12228.721680\n",
      "Train Epoch: 3146 [98560/118836 (83%)] Loss: 12171.775391\n",
      "    epoch          : 3146\n",
      "    loss           : 12219.319257424784\n",
      "    val_loss       : 12218.039392061624\n",
      "    val_log_likelihood: -12118.354676676232\n",
      "    val_log_marginal: -12127.31709714125\n",
      "Train Epoch: 3147 [256/118836 (0%)] Loss: 12309.352539\n",
      "Train Epoch: 3147 [33024/118836 (28%)] Loss: 12272.960938\n",
      "Train Epoch: 3147 [65792/118836 (55%)] Loss: 12220.804688\n",
      "Train Epoch: 3147 [98560/118836 (83%)] Loss: 12168.783203\n",
      "    epoch          : 3147\n",
      "    loss           : 12217.174831019955\n",
      "    val_loss       : 12212.487116462813\n",
      "    val_log_likelihood: -12119.129587178195\n",
      "    val_log_marginal: -12127.925934076702\n",
      "Train Epoch: 3148 [256/118836 (0%)] Loss: 12284.852539\n",
      "Train Epoch: 3148 [33024/118836 (28%)] Loss: 12248.679688\n",
      "Train Epoch: 3148 [65792/118836 (55%)] Loss: 12178.240234\n",
      "Train Epoch: 3148 [98560/118836 (83%)] Loss: 12235.602539\n",
      "    epoch          : 3148\n",
      "    loss           : 12215.761011973997\n",
      "    val_loss       : 12212.74158719675\n",
      "    val_log_likelihood: -12115.840849229735\n",
      "    val_log_marginal: -12124.83133582291\n",
      "Train Epoch: 3149 [256/118836 (0%)] Loss: 12358.312500\n",
      "Train Epoch: 3149 [33024/118836 (28%)] Loss: 12183.297852\n",
      "Train Epoch: 3149 [65792/118836 (55%)] Loss: 12324.125000\n",
      "Train Epoch: 3149 [98560/118836 (83%)] Loss: 12239.468750\n",
      "    epoch          : 3149\n",
      "    loss           : 12218.897333152398\n",
      "    val_loss       : 12211.605974593938\n",
      "    val_log_likelihood: -12116.688981402502\n",
      "    val_log_marginal: -12125.433537018387\n",
      "Train Epoch: 3150 [256/118836 (0%)] Loss: 12248.866211\n",
      "Train Epoch: 3150 [33024/118836 (28%)] Loss: 12165.530273\n",
      "Train Epoch: 3150 [65792/118836 (55%)] Loss: 12240.952148\n",
      "Train Epoch: 3150 [98560/118836 (83%)] Loss: 12263.990234\n",
      "    epoch          : 3150\n",
      "    loss           : 12215.5307650305\n",
      "    val_loss       : 12223.549313045482\n",
      "    val_log_likelihood: -12121.42397885003\n",
      "    val_log_marginal: -12130.258872282546\n",
      "Train Epoch: 3151 [256/118836 (0%)] Loss: 12199.033203\n",
      "Train Epoch: 3151 [33024/118836 (28%)] Loss: 12140.035156\n",
      "Train Epoch: 3151 [65792/118836 (55%)] Loss: 12254.157227\n",
      "Train Epoch: 3151 [98560/118836 (83%)] Loss: 12175.892578\n",
      "    epoch          : 3151\n",
      "    loss           : 12218.265267330955\n",
      "    val_loss       : 12214.566486973265\n",
      "    val_log_likelihood: -12115.277490597859\n",
      "    val_log_marginal: -12124.293467947191\n",
      "Train Epoch: 3152 [256/118836 (0%)] Loss: 12227.281250\n",
      "Train Epoch: 3152 [33024/118836 (28%)] Loss: 12110.586914\n",
      "Train Epoch: 3152 [65792/118836 (55%)] Loss: 12289.050781\n",
      "Train Epoch: 3152 [98560/118836 (83%)] Loss: 12315.358398\n",
      "    epoch          : 3152\n",
      "    loss           : 12217.224729567308\n",
      "    val_loss       : 12221.111869155553\n",
      "    val_log_likelihood: -12119.780491205283\n",
      "    val_log_marginal: -12128.627456798193\n",
      "Train Epoch: 3153 [256/118836 (0%)] Loss: 12265.772461\n",
      "Train Epoch: 3153 [33024/118836 (28%)] Loss: 12389.250000\n",
      "Train Epoch: 3153 [65792/118836 (55%)] Loss: 12214.218750\n",
      "Train Epoch: 3153 [98560/118836 (83%)] Loss: 12166.158203\n",
      "    epoch          : 3153\n",
      "    loss           : 12223.334288409844\n",
      "    val_loss       : 12218.444230395455\n",
      "    val_log_likelihood: -12118.540382353702\n",
      "    val_log_marginal: -12127.70816824214\n",
      "Train Epoch: 3154 [256/118836 (0%)] Loss: 12270.084961\n",
      "Train Epoch: 3154 [33024/118836 (28%)] Loss: 12256.304688\n",
      "Train Epoch: 3154 [65792/118836 (55%)] Loss: 12281.165039\n",
      "Train Epoch: 3154 [98560/118836 (83%)] Loss: 12268.107422\n",
      "    epoch          : 3154\n",
      "    loss           : 12217.341357785359\n",
      "    val_loss       : 12219.21118513913\n",
      "    val_log_likelihood: -12120.01056836099\n",
      "    val_log_marginal: -12128.906725478568\n",
      "Train Epoch: 3155 [256/118836 (0%)] Loss: 12246.657227\n",
      "Train Epoch: 3155 [33024/118836 (28%)] Loss: 12256.066406\n",
      "Train Epoch: 3155 [65792/118836 (55%)] Loss: 12217.214844\n",
      "Train Epoch: 3155 [98560/118836 (83%)] Loss: 12172.033203\n",
      "    epoch          : 3155\n",
      "    loss           : 12219.086002765716\n",
      "    val_loss       : 12215.301635168824\n",
      "    val_log_likelihood: -12122.940622576769\n",
      "    val_log_marginal: -12131.675714969622\n",
      "Train Epoch: 3156 [256/118836 (0%)] Loss: 12181.582031\n",
      "Train Epoch: 3156 [33024/118836 (28%)] Loss: 12280.501953\n",
      "Train Epoch: 3156 [65792/118836 (55%)] Loss: 12281.105469\n",
      "Train Epoch: 3156 [98560/118836 (83%)] Loss: 12255.316406\n",
      "    epoch          : 3156\n",
      "    loss           : 12212.04561039599\n",
      "    val_loss       : 12217.080801000535\n",
      "    val_log_likelihood: -12114.847981932382\n",
      "    val_log_marginal: -12123.685673199849\n",
      "Train Epoch: 3157 [256/118836 (0%)] Loss: 12259.664062\n",
      "Train Epoch: 3157 [33024/118836 (28%)] Loss: 12332.842773\n",
      "Train Epoch: 3157 [65792/118836 (55%)] Loss: 12127.207031\n",
      "Train Epoch: 3157 [98560/118836 (83%)] Loss: 12267.037109\n",
      "    epoch          : 3157\n",
      "    loss           : 12212.801313068652\n",
      "    val_loss       : 12213.880326083025\n",
      "    val_log_likelihood: -12116.089006927214\n",
      "    val_log_marginal: -12124.95532023157\n",
      "Train Epoch: 3158 [256/118836 (0%)] Loss: 12232.158203\n",
      "Train Epoch: 3158 [33024/118836 (28%)] Loss: 12272.124023\n",
      "Train Epoch: 3158 [65792/118836 (55%)] Loss: 12346.175781\n",
      "Train Epoch: 3158 [98560/118836 (83%)] Loss: 12239.887695\n",
      "    epoch          : 3158\n",
      "    loss           : 12218.245302322424\n",
      "    val_loss       : 12215.212546218292\n",
      "    val_log_likelihood: -12124.494874379652\n",
      "    val_log_marginal: -12133.433794494804\n",
      "Train Epoch: 3159 [256/118836 (0%)] Loss: 12324.071289\n",
      "Train Epoch: 3159 [33024/118836 (28%)] Loss: 12158.804688\n",
      "Train Epoch: 3159 [65792/118836 (55%)] Loss: 12165.204102\n",
      "Train Epoch: 3159 [98560/118836 (83%)] Loss: 12208.296875\n",
      "    epoch          : 3159\n",
      "    loss           : 12216.619363077698\n",
      "    val_loss       : 12212.791186504683\n",
      "    val_log_likelihood: -12117.945508297145\n",
      "    val_log_marginal: -12126.680319595685\n",
      "Train Epoch: 3160 [256/118836 (0%)] Loss: 12277.410156\n",
      "Train Epoch: 3160 [33024/118836 (28%)] Loss: 12132.565430\n",
      "Train Epoch: 3160 [65792/118836 (55%)] Loss: 12236.933594\n",
      "Train Epoch: 3160 [98560/118836 (83%)] Loss: 12172.245117\n",
      "    epoch          : 3160\n",
      "    loss           : 12218.028777010959\n",
      "    val_loss       : 12219.206540946505\n",
      "    val_log_likelihood: -12122.14406114299\n",
      "    val_log_marginal: -12131.062766264997\n",
      "Train Epoch: 3161 [256/118836 (0%)] Loss: 12232.278320\n",
      "Train Epoch: 3161 [33024/118836 (28%)] Loss: 12248.167969\n",
      "Train Epoch: 3161 [65792/118836 (55%)] Loss: 12273.402344\n",
      "Train Epoch: 3161 [98560/118836 (83%)] Loss: 12196.658203\n",
      "    epoch          : 3161\n",
      "    loss           : 12215.028082997313\n",
      "    val_loss       : 12216.928523857674\n",
      "    val_log_likelihood: -12118.294533188586\n",
      "    val_log_marginal: -12127.051581950762\n",
      "Train Epoch: 3162 [256/118836 (0%)] Loss: 12247.477539\n",
      "Train Epoch: 3162 [33024/118836 (28%)] Loss: 12289.103516\n",
      "Train Epoch: 3162 [65792/118836 (55%)] Loss: 12176.384766\n",
      "Train Epoch: 3162 [98560/118836 (83%)] Loss: 12144.009766\n",
      "    epoch          : 3162\n",
      "    loss           : 12208.595801669768\n",
      "    val_loss       : 12197.224091718832\n",
      "    val_log_likelihood: -12113.765467813017\n",
      "    val_log_marginal: -12122.614111901603\n",
      "Train Epoch: 3163 [256/118836 (0%)] Loss: 12281.850586\n",
      "Train Epoch: 3163 [33024/118836 (28%)] Loss: 12206.602539\n",
      "Train Epoch: 3163 [65792/118836 (55%)] Loss: 12178.666992\n",
      "Train Epoch: 3163 [98560/118836 (83%)] Loss: 12180.638672\n",
      "    epoch          : 3163\n",
      "    loss           : 12198.482988749742\n",
      "    val_loss       : 12199.7523960479\n",
      "    val_log_likelihood: -12114.789922747364\n",
      "    val_log_marginal: -12123.613891477591\n",
      "Train Epoch: 3164 [256/118836 (0%)] Loss: 12215.199219\n",
      "Train Epoch: 3164 [33024/118836 (28%)] Loss: 12185.979492\n",
      "Train Epoch: 3164 [65792/118836 (55%)] Loss: 12224.159180\n",
      "Train Epoch: 3164 [98560/118836 (83%)] Loss: 12209.690430\n",
      "    epoch          : 3164\n",
      "    loss           : 12203.944461137822\n",
      "    val_loss       : 12200.938942866267\n",
      "    val_log_likelihood: -12114.244352900125\n",
      "    val_log_marginal: -12123.065830783655\n",
      "Train Epoch: 3165 [256/118836 (0%)] Loss: 12199.197266\n",
      "Train Epoch: 3165 [33024/118836 (28%)] Loss: 12165.046875\n",
      "Train Epoch: 3165 [65792/118836 (55%)] Loss: 12303.250000\n",
      "Train Epoch: 3165 [98560/118836 (83%)] Loss: 12215.275391\n",
      "    epoch          : 3165\n",
      "    loss           : 12199.83445835918\n",
      "    val_loss       : 12200.660960094376\n",
      "    val_log_likelihood: -12120.877409338813\n",
      "    val_log_marginal: -12129.792411526196\n",
      "Train Epoch: 3166 [256/118836 (0%)] Loss: 12177.584961\n",
      "Train Epoch: 3166 [33024/118836 (28%)] Loss: 12160.174805\n",
      "Train Epoch: 3166 [65792/118836 (55%)] Loss: 12177.793945\n",
      "Train Epoch: 3166 [98560/118836 (83%)] Loss: 12191.417969\n",
      "    epoch          : 3166\n",
      "    loss           : 12197.529896382599\n",
      "    val_loss       : 12199.76095729066\n",
      "    val_log_likelihood: -12114.298185806967\n",
      "    val_log_marginal: -12123.15582455313\n",
      "Train Epoch: 3167 [256/118836 (0%)] Loss: 12203.705078\n",
      "Train Epoch: 3167 [33024/118836 (28%)] Loss: 12217.716797\n",
      "Train Epoch: 3167 [65792/118836 (55%)] Loss: 12241.771484\n",
      "Train Epoch: 3167 [98560/118836 (83%)] Loss: 12124.510742\n",
      "    epoch          : 3167\n",
      "    loss           : 12202.2670057576\n",
      "    val_loss       : 12201.58694889983\n",
      "    val_log_likelihood: -12118.699574480459\n",
      "    val_log_marginal: -12127.551695861986\n",
      "Train Epoch: 3168 [256/118836 (0%)] Loss: 12248.355469\n",
      "Train Epoch: 3168 [33024/118836 (28%)] Loss: 12218.660156\n",
      "Train Epoch: 3168 [65792/118836 (55%)] Loss: 12208.920898\n",
      "Train Epoch: 3168 [98560/118836 (83%)] Loss: 12292.043945\n",
      "    epoch          : 3168\n",
      "    loss           : 12200.193685057382\n",
      "    val_loss       : 12197.299881941697\n",
      "    val_log_likelihood: -12117.046842367143\n",
      "    val_log_marginal: -12125.971557194882\n",
      "Train Epoch: 3169 [256/118836 (0%)] Loss: 12204.779297\n",
      "Train Epoch: 3169 [33024/118836 (28%)] Loss: 12149.069336\n",
      "Train Epoch: 3169 [65792/118836 (55%)] Loss: 12224.558594\n",
      "Train Epoch: 3169 [98560/118836 (83%)] Loss: 12176.472656\n",
      "    epoch          : 3169\n",
      "    loss           : 12196.179059721362\n",
      "    val_loss       : 12200.462246357172\n",
      "    val_log_likelihood: -12116.334348990644\n",
      "    val_log_marginal: -12125.23547619094\n",
      "Train Epoch: 3170 [256/118836 (0%)] Loss: 12188.702148\n",
      "Train Epoch: 3170 [33024/118836 (28%)] Loss: 12170.600586\n",
      "Train Epoch: 3170 [65792/118836 (55%)] Loss: 12288.734375\n",
      "Train Epoch: 3170 [98560/118836 (83%)] Loss: 12293.703125\n",
      "    epoch          : 3170\n",
      "    loss           : 12196.965182679383\n",
      "    val_loss       : 12199.977177346627\n",
      "    val_log_likelihood: -12115.06342131281\n",
      "    val_log_marginal: -12123.97453105535\n",
      "Train Epoch: 3171 [256/118836 (0%)] Loss: 12200.491211\n",
      "Train Epoch: 3171 [33024/118836 (28%)] Loss: 12306.458984\n",
      "Train Epoch: 3171 [65792/118836 (55%)] Loss: 12265.725586\n",
      "Train Epoch: 3171 [98560/118836 (83%)] Loss: 12195.935547\n",
      "    epoch          : 3171\n",
      "    loss           : 12200.390292532567\n",
      "    val_loss       : 12197.913192915485\n",
      "    val_log_likelihood: -12115.547263524866\n",
      "    val_log_marginal: -12124.438421082838\n",
      "Train Epoch: 3172 [256/118836 (0%)] Loss: 12218.677734\n",
      "Train Epoch: 3172 [33024/118836 (28%)] Loss: 12264.589844\n",
      "Train Epoch: 3172 [65792/118836 (55%)] Loss: 12250.140625\n",
      "Train Epoch: 3172 [98560/118836 (83%)] Loss: 12186.176758\n",
      "    epoch          : 3172\n",
      "    loss           : 12198.498686769799\n",
      "    val_loss       : 12198.045022993803\n",
      "    val_log_likelihood: -12115.378746962882\n",
      "    val_log_marginal: -12124.146110568458\n",
      "Train Epoch: 3173 [256/118836 (0%)] Loss: 12246.035156\n",
      "Train Epoch: 3173 [33024/118836 (28%)] Loss: 12223.761719\n",
      "Train Epoch: 3173 [65792/118836 (55%)] Loss: 12306.840820\n",
      "Train Epoch: 3173 [98560/118836 (83%)] Loss: 12138.634766\n",
      "    epoch          : 3173\n",
      "    loss           : 12195.65162033447\n",
      "    val_loss       : 12199.004026652163\n",
      "    val_log_likelihood: -12114.313149103082\n",
      "    val_log_marginal: -12123.107298328241\n",
      "Train Epoch: 3174 [256/118836 (0%)] Loss: 12212.242188\n",
      "Train Epoch: 3174 [33024/118836 (28%)] Loss: 12165.502930\n",
      "Train Epoch: 3174 [65792/118836 (55%)] Loss: 12178.594727\n",
      "Train Epoch: 3174 [98560/118836 (83%)] Loss: 12236.376953\n",
      "    epoch          : 3174\n",
      "    loss           : 12197.588432944323\n",
      "    val_loss       : 12197.50395602167\n",
      "    val_log_likelihood: -12114.281756778588\n",
      "    val_log_marginal: -12122.987752095843\n",
      "Train Epoch: 3175 [256/118836 (0%)] Loss: 12291.085938\n",
      "Train Epoch: 3175 [33024/118836 (28%)] Loss: 12167.963867\n",
      "Train Epoch: 3175 [65792/118836 (55%)] Loss: 12220.073242\n",
      "Train Epoch: 3175 [98560/118836 (83%)] Loss: 12195.689453\n",
      "    epoch          : 3175\n",
      "    loss           : 12199.429125148625\n",
      "    val_loss       : 12196.56271362654\n",
      "    val_log_likelihood: -12116.414785269333\n",
      "    val_log_marginal: -12125.1887281224\n",
      "Train Epoch: 3176 [256/118836 (0%)] Loss: 12300.836914\n",
      "Train Epoch: 3176 [33024/118836 (28%)] Loss: 12209.946289\n",
      "Train Epoch: 3176 [65792/118836 (55%)] Loss: 12251.788086\n",
      "Train Epoch: 3176 [98560/118836 (83%)] Loss: 12153.108398\n",
      "    epoch          : 3176\n",
      "    loss           : 12199.241440982993\n",
      "    val_loss       : 12199.455998626296\n",
      "    val_log_likelihood: -12122.439211124896\n",
      "    val_log_marginal: -12131.209750774926\n",
      "Train Epoch: 3177 [256/118836 (0%)] Loss: 12242.858398\n",
      "Train Epoch: 3177 [33024/118836 (28%)] Loss: 12265.329102\n",
      "Train Epoch: 3177 [65792/118836 (55%)] Loss: 12196.584961\n",
      "Train Epoch: 3177 [98560/118836 (83%)] Loss: 12215.994141\n",
      "    epoch          : 3177\n",
      "    loss           : 12197.158280345328\n",
      "    val_loss       : 12196.177147493485\n",
      "    val_log_likelihood: -12118.948337662841\n",
      "    val_log_marginal: -12127.71184519409\n",
      "Train Epoch: 3178 [256/118836 (0%)] Loss: 12312.698242\n",
      "Train Epoch: 3178 [33024/118836 (28%)] Loss: 12301.441406\n",
      "Train Epoch: 3178 [65792/118836 (55%)] Loss: 12150.325195\n",
      "Train Epoch: 3178 [98560/118836 (83%)] Loss: 12288.717773\n",
      "    epoch          : 3178\n",
      "    loss           : 12201.438803052626\n",
      "    val_loss       : 12199.485923126178\n",
      "    val_log_likelihood: -12116.499822780966\n",
      "    val_log_marginal: -12125.416918019506\n",
      "Train Epoch: 3179 [256/118836 (0%)] Loss: 12341.423828\n",
      "Train Epoch: 3179 [33024/118836 (28%)] Loss: 12192.099609\n",
      "Train Epoch: 3179 [65792/118836 (55%)] Loss: 12182.107422\n",
      "Train Epoch: 3179 [98560/118836 (83%)] Loss: 12198.250977\n",
      "    epoch          : 3179\n",
      "    loss           : 12195.256951606441\n",
      "    val_loss       : 12204.83238063954\n",
      "    val_log_likelihood: -12117.545587940704\n",
      "    val_log_marginal: -12126.438268201147\n",
      "Train Epoch: 3180 [256/118836 (0%)] Loss: 12279.841797\n",
      "Train Epoch: 3180 [33024/118836 (28%)] Loss: 12142.789062\n",
      "Train Epoch: 3180 [65792/118836 (55%)] Loss: 12241.368164\n",
      "Train Epoch: 3180 [98560/118836 (83%)] Loss: 12199.596680\n",
      "    epoch          : 3180\n",
      "    loss           : 12204.555577149245\n",
      "    val_loss       : 12200.33560992066\n",
      "    val_log_likelihood: -12116.622996148677\n",
      "    val_log_marginal: -12125.665618606752\n",
      "Train Epoch: 3181 [256/118836 (0%)] Loss: 12234.541992\n",
      "Train Epoch: 3181 [33024/118836 (28%)] Loss: 12137.552734\n",
      "Train Epoch: 3181 [65792/118836 (55%)] Loss: 12143.856445\n",
      "Train Epoch: 3181 [98560/118836 (83%)] Loss: 12213.245117\n",
      "    epoch          : 3181\n",
      "    loss           : 12199.069641426282\n",
      "    val_loss       : 12198.088295010506\n",
      "    val_log_likelihood: -12116.956315265716\n",
      "    val_log_marginal: -12125.706821284772\n",
      "Train Epoch: 3182 [256/118836 (0%)] Loss: 12275.398438\n",
      "Train Epoch: 3182 [33024/118836 (28%)] Loss: 12261.166016\n",
      "Train Epoch: 3182 [65792/118836 (55%)] Loss: 12207.885742\n",
      "Train Epoch: 3182 [98560/118836 (83%)] Loss: 12209.562500\n",
      "    epoch          : 3182\n",
      "    loss           : 12196.795816855354\n",
      "    val_loss       : 12200.42924792206\n",
      "    val_log_likelihood: -12115.311894838194\n",
      "    val_log_marginal: -12124.193550749016\n",
      "Train Epoch: 3183 [256/118836 (0%)] Loss: 12197.525391\n",
      "Train Epoch: 3183 [33024/118836 (28%)] Loss: 12245.077148\n",
      "Train Epoch: 3183 [65792/118836 (55%)] Loss: 12189.896484\n",
      "Train Epoch: 3183 [98560/118836 (83%)] Loss: 12130.403320\n",
      "    epoch          : 3183\n",
      "    loss           : 12194.912888040219\n",
      "    val_loss       : 12198.903107457947\n",
      "    val_log_likelihood: -12114.339117265044\n",
      "    val_log_marginal: -12123.112752152414\n",
      "Train Epoch: 3184 [256/118836 (0%)] Loss: 12215.703125\n",
      "Train Epoch: 3184 [33024/118836 (28%)] Loss: 12221.910156\n",
      "Train Epoch: 3184 [65792/118836 (55%)] Loss: 12270.425781\n",
      "Train Epoch: 3184 [98560/118836 (83%)] Loss: 12311.841797\n",
      "    epoch          : 3184\n",
      "    loss           : 12197.049445887613\n",
      "    val_loss       : 12198.02089485592\n",
      "    val_log_likelihood: -12117.363570099256\n",
      "    val_log_marginal: -12126.152792260946\n",
      "Train Epoch: 3185 [256/118836 (0%)] Loss: 12229.415039\n",
      "Train Epoch: 3185 [33024/118836 (28%)] Loss: 12271.468750\n",
      "Train Epoch: 3185 [65792/118836 (55%)] Loss: 12273.812500\n",
      "Train Epoch: 3185 [98560/118836 (83%)] Loss: 12161.904297\n",
      "    epoch          : 3185\n",
      "    loss           : 12203.353908027038\n",
      "    val_loss       : 12202.379866891899\n",
      "    val_log_likelihood: -12114.76110858018\n",
      "    val_log_marginal: -12123.589078145287\n",
      "Train Epoch: 3186 [256/118836 (0%)] Loss: 12303.121094\n",
      "Train Epoch: 3186 [33024/118836 (28%)] Loss: 12247.312500\n",
      "Train Epoch: 3186 [65792/118836 (55%)] Loss: 12122.662109\n",
      "Train Epoch: 3186 [98560/118836 (83%)] Loss: 12235.193359\n",
      "    epoch          : 3186\n",
      "    loss           : 12199.760485001809\n",
      "    val_loss       : 12196.625654363068\n",
      "    val_log_likelihood: -12120.286054299784\n",
      "    val_log_marginal: -12129.135677674283\n",
      "Train Epoch: 3187 [256/118836 (0%)] Loss: 12238.449219\n",
      "Train Epoch: 3187 [33024/118836 (28%)] Loss: 12220.520508\n",
      "Train Epoch: 3187 [65792/118836 (55%)] Loss: 12210.301758\n",
      "Train Epoch: 3187 [98560/118836 (83%)] Loss: 12209.290039\n",
      "    epoch          : 3187\n",
      "    loss           : 12201.605871006514\n",
      "    val_loss       : 12196.759067142528\n",
      "    val_log_likelihood: -12117.386574810018\n",
      "    val_log_marginal: -12126.145398351326\n",
      "Train Epoch: 3188 [256/118836 (0%)] Loss: 12320.668945\n",
      "Train Epoch: 3188 [33024/118836 (28%)] Loss: 12178.707031\n",
      "Train Epoch: 3188 [65792/118836 (55%)] Loss: 12274.083984\n",
      "Train Epoch: 3188 [98560/118836 (83%)] Loss: 12285.919922\n",
      "    epoch          : 3188\n",
      "    loss           : 12200.346602144076\n",
      "    val_loss       : 12198.951342739501\n",
      "    val_log_likelihood: -12114.850608231236\n",
      "    val_log_marginal: -12123.673007332529\n",
      "Train Epoch: 3189 [256/118836 (0%)] Loss: 12181.917969\n",
      "Train Epoch: 3189 [33024/118836 (28%)] Loss: 12287.007812\n",
      "Train Epoch: 3189 [65792/118836 (55%)] Loss: 12120.560547\n",
      "Train Epoch: 3189 [98560/118836 (83%)] Loss: 12312.799805\n",
      "    epoch          : 3189\n",
      "    loss           : 12198.633381474876\n",
      "    val_loss       : 12199.990081498834\n",
      "    val_log_likelihood: -12117.643073433623\n",
      "    val_log_marginal: -12126.443598581698\n",
      "Train Epoch: 3190 [256/118836 (0%)] Loss: 12284.929688\n",
      "Train Epoch: 3190 [33024/118836 (28%)] Loss: 12242.101562\n",
      "Train Epoch: 3190 [65792/118836 (55%)] Loss: 12237.675781\n",
      "Train Epoch: 3190 [98560/118836 (83%)] Loss: 12201.294922\n",
      "    epoch          : 3190\n",
      "    loss           : 12201.840513531328\n",
      "    val_loss       : 12200.675972336472\n",
      "    val_log_likelihood: -12114.599295162581\n",
      "    val_log_marginal: -12123.580142597571\n",
      "Train Epoch: 3191 [256/118836 (0%)] Loss: 12301.375000\n",
      "Train Epoch: 3191 [33024/118836 (28%)] Loss: 12139.937500\n",
      "Train Epoch: 3191 [65792/118836 (55%)] Loss: 12245.277344\n",
      "Train Epoch: 3191 [98560/118836 (83%)] Loss: 12149.634766\n",
      "    epoch          : 3191\n",
      "    loss           : 12203.811771738006\n",
      "    val_loss       : 12196.75342841786\n",
      "    val_log_likelihood: -12119.053435173697\n",
      "    val_log_marginal: -12127.963208234656\n",
      "Train Epoch: 3192 [256/118836 (0%)] Loss: 12176.609375\n",
      "Train Epoch: 3192 [33024/118836 (28%)] Loss: 12216.248047\n",
      "Train Epoch: 3192 [65792/118836 (55%)] Loss: 12159.622070\n",
      "Train Epoch: 3192 [98560/118836 (83%)] Loss: 12128.224609\n",
      "    epoch          : 3192\n",
      "    loss           : 12197.685563837626\n",
      "    val_loss       : 12195.327431980195\n",
      "    val_log_likelihood: -12120.730320125103\n",
      "    val_log_marginal: -12129.530016320503\n",
      "Train Epoch: 3193 [256/118836 (0%)] Loss: 12327.602539\n",
      "Train Epoch: 3193 [33024/118836 (28%)] Loss: 12271.551758\n",
      "Train Epoch: 3193 [65792/118836 (55%)] Loss: 12258.106445\n",
      "Train Epoch: 3193 [98560/118836 (83%)] Loss: 12198.224609\n",
      "    epoch          : 3193\n",
      "    loss           : 12198.488840370399\n",
      "    val_loss       : 12200.749721159578\n",
      "    val_log_likelihood: -12118.466380402191\n",
      "    val_log_marginal: -12127.331421568006\n",
      "Train Epoch: 3194 [256/118836 (0%)] Loss: 12262.972656\n",
      "Train Epoch: 3194 [33024/118836 (28%)] Loss: 12484.226562\n",
      "Train Epoch: 3194 [65792/118836 (55%)] Loss: 12181.491211\n",
      "Train Epoch: 3194 [98560/118836 (83%)] Loss: 12247.983398\n",
      "    epoch          : 3194\n",
      "    loss           : 12211.950137801128\n",
      "    val_loss       : 12205.020620955736\n",
      "    val_log_likelihood: -12115.66164993021\n",
      "    val_log_marginal: -12124.491846068886\n",
      "Train Epoch: 3195 [256/118836 (0%)] Loss: 12186.202148\n",
      "Train Epoch: 3195 [33024/118836 (28%)] Loss: 12220.468750\n",
      "Train Epoch: 3195 [65792/118836 (55%)] Loss: 12170.701172\n",
      "Train Epoch: 3195 [98560/118836 (83%)] Loss: 12251.105469\n",
      "    epoch          : 3195\n",
      "    loss           : 12198.56087546526\n",
      "    val_loss       : 12204.31678623807\n",
      "    val_log_likelihood: -12115.90850102099\n",
      "    val_log_marginal: -12124.66427607355\n",
      "Train Epoch: 3196 [256/118836 (0%)] Loss: 12176.640625\n",
      "Train Epoch: 3196 [33024/118836 (28%)] Loss: 12275.044922\n",
      "Train Epoch: 3196 [65792/118836 (55%)] Loss: 12257.230469\n",
      "Train Epoch: 3196 [98560/118836 (83%)] Loss: 12222.494141\n",
      "    epoch          : 3196\n",
      "    loss           : 12199.236572709884\n",
      "    val_loss       : 12197.372272839491\n",
      "    val_log_likelihood: -12118.77490694789\n",
      "    val_log_marginal: -12127.50176460573\n",
      "Train Epoch: 3197 [256/118836 (0%)] Loss: 12191.128906\n",
      "Train Epoch: 3197 [33024/118836 (28%)] Loss: 12210.849609\n",
      "Train Epoch: 3197 [65792/118836 (55%)] Loss: 12196.427734\n",
      "Train Epoch: 3197 [98560/118836 (83%)] Loss: 12292.252930\n",
      "    epoch          : 3197\n",
      "    loss           : 12202.131105736922\n",
      "    val_loss       : 12200.724881107264\n",
      "    val_log_likelihood: -12117.051746342535\n",
      "    val_log_marginal: -12125.714597113776\n",
      "Train Epoch: 3198 [256/118836 (0%)] Loss: 12189.767578\n",
      "Train Epoch: 3198 [33024/118836 (28%)] Loss: 12187.243164\n",
      "Train Epoch: 3198 [65792/118836 (55%)] Loss: 12205.001953\n",
      "Train Epoch: 3198 [98560/118836 (83%)] Loss: 12333.884766\n",
      "    epoch          : 3198\n",
      "    loss           : 12201.197177096257\n",
      "    val_loss       : 12196.475133331873\n",
      "    val_log_likelihood: -12118.545845934139\n",
      "    val_log_marginal: -12127.343862774313\n",
      "Train Epoch: 3199 [256/118836 (0%)] Loss: 12166.659180\n",
      "Train Epoch: 3199 [33024/118836 (28%)] Loss: 12141.022461\n",
      "Train Epoch: 3199 [65792/118836 (55%)] Loss: 12146.580078\n",
      "Train Epoch: 3199 [98560/118836 (83%)] Loss: 12252.316406\n",
      "    epoch          : 3199\n",
      "    loss           : 12196.685678052625\n",
      "    val_loss       : 12198.03697702547\n",
      "    val_log_likelihood: -12117.289703848737\n",
      "    val_log_marginal: -12126.08250021482\n",
      "Train Epoch: 3200 [256/118836 (0%)] Loss: 12186.220703\n",
      "Train Epoch: 3200 [33024/118836 (28%)] Loss: 12219.674805\n",
      "Train Epoch: 3200 [65792/118836 (55%)] Loss: 12177.611328\n",
      "Train Epoch: 3200 [98560/118836 (83%)] Loss: 12303.333984\n",
      "    epoch          : 3200\n",
      "    loss           : 12195.337743615592\n",
      "    val_loss       : 12201.303394210532\n",
      "    val_log_likelihood: -12116.632386011166\n",
      "    val_log_marginal: -12125.468259170815\n",
      "Saving checkpoint: saved/models/SelfiesAutoencodingOperad/0905_154251/checkpoint-epoch3200.pth ...\n",
      "Train Epoch: 3201 [256/118836 (0%)] Loss: 12205.213867\n",
      "Train Epoch: 3201 [33024/118836 (28%)] Loss: 12265.251953\n",
      "Train Epoch: 3201 [65792/118836 (55%)] Loss: 12234.648438\n",
      "Train Epoch: 3201 [98560/118836 (83%)] Loss: 12209.649414\n",
      "    epoch          : 3201\n",
      "    loss           : 12192.777891400434\n",
      "    val_loss       : 12199.59051933758\n",
      "    val_log_likelihood: -12114.157708462571\n",
      "    val_log_marginal: -12122.919709684646\n",
      "Train Epoch: 3202 [256/118836 (0%)] Loss: 12167.581055\n",
      "Train Epoch: 3202 [33024/118836 (28%)] Loss: 12193.430664\n",
      "Train Epoch: 3202 [65792/118836 (55%)] Loss: 12185.803711\n",
      "Train Epoch: 3202 [98560/118836 (83%)] Loss: 12124.667969\n",
      "    epoch          : 3202\n",
      "    loss           : 12196.950657665167\n",
      "    val_loss       : 12196.615595732814\n",
      "    val_log_likelihood: -12117.10972798413\n",
      "    val_log_marginal: -12125.884151461132\n",
      "Train Epoch: 3203 [256/118836 (0%)] Loss: 12243.585938\n",
      "Train Epoch: 3203 [33024/118836 (28%)] Loss: 12190.294922\n",
      "Train Epoch: 3203 [65792/118836 (55%)] Loss: 12311.757812\n",
      "Train Epoch: 3203 [98560/118836 (83%)] Loss: 12188.355469\n",
      "    epoch          : 3203\n",
      "    loss           : 12200.668365675403\n",
      "    val_loss       : 12197.666343031427\n",
      "    val_log_likelihood: -12114.936122958024\n",
      "    val_log_marginal: -12123.764932541304\n",
      "Train Epoch: 3204 [256/118836 (0%)] Loss: 12246.292969\n",
      "Train Epoch: 3204 [33024/118836 (28%)] Loss: 12271.527344\n",
      "Train Epoch: 3204 [65792/118836 (55%)] Loss: 12256.530273\n",
      "Train Epoch: 3204 [98560/118836 (83%)] Loss: 12226.354492\n",
      "    epoch          : 3204\n",
      "    loss           : 12195.579994119624\n",
      "    val_loss       : 12196.254280299625\n",
      "    val_log_likelihood: -12117.921755938534\n",
      "    val_log_marginal: -12126.578053728817\n",
      "Train Epoch: 3205 [256/118836 (0%)] Loss: 12262.057617\n",
      "Train Epoch: 3205 [33024/118836 (28%)] Loss: 12295.810547\n",
      "Train Epoch: 3205 [65792/118836 (55%)] Loss: 12165.888672\n",
      "Train Epoch: 3205 [98560/118836 (83%)] Loss: 12172.388672\n",
      "    epoch          : 3205\n",
      "    loss           : 12196.252172023625\n",
      "    val_loss       : 12193.974876461109\n",
      "    val_log_likelihood: -12118.710312144593\n",
      "    val_log_marginal: -12127.544944347579\n",
      "Train Epoch: 3206 [256/118836 (0%)] Loss: 12175.562500\n",
      "Train Epoch: 3206 [33024/118836 (28%)] Loss: 12265.145508\n",
      "Train Epoch: 3206 [65792/118836 (55%)] Loss: 12199.451172\n",
      "Train Epoch: 3206 [98560/118836 (83%)] Loss: 12270.790039\n",
      "    epoch          : 3206\n",
      "    loss           : 12194.594436259305\n",
      "    val_loss       : 12199.775034720826\n",
      "    val_log_likelihood: -12115.717397190345\n",
      "    val_log_marginal: -12124.507390918208\n",
      "Train Epoch: 3207 [256/118836 (0%)] Loss: 12249.775391\n",
      "Train Epoch: 3207 [33024/118836 (28%)] Loss: 12299.198242\n",
      "Train Epoch: 3207 [65792/118836 (55%)] Loss: 12322.952148\n",
      "Train Epoch: 3207 [98560/118836 (83%)] Loss: 12256.166016\n",
      "    epoch          : 3207\n",
      "    loss           : 12198.713405965673\n",
      "    val_loss       : 12199.206392969832\n",
      "    val_log_likelihood: -12114.693806380532\n",
      "    val_log_marginal: -12123.536372952583\n",
      "Train Epoch: 3208 [256/118836 (0%)] Loss: 12192.041992\n",
      "Train Epoch: 3208 [33024/118836 (28%)] Loss: 12254.978516\n",
      "Train Epoch: 3208 [65792/118836 (55%)] Loss: 12188.128906\n",
      "Train Epoch: 3208 [98560/118836 (83%)] Loss: 12215.531250\n",
      "    epoch          : 3208\n",
      "    loss           : 12193.66290952621\n",
      "    val_loss       : 12197.781727318797\n",
      "    val_log_likelihood: -12113.706714291253\n",
      "    val_log_marginal: -12122.633739990091\n",
      "Train Epoch: 3209 [256/118836 (0%)] Loss: 12266.408203\n",
      "Train Epoch: 3209 [33024/118836 (28%)] Loss: 12279.390625\n",
      "Train Epoch: 3209 [65792/118836 (55%)] Loss: 12157.210938\n",
      "Train Epoch: 3209 [98560/118836 (83%)] Loss: 12207.083984\n",
      "    epoch          : 3209\n",
      "    loss           : 12198.79063453138\n",
      "    val_loss       : 12196.596110299315\n",
      "    val_log_likelihood: -12114.783361281276\n",
      "    val_log_marginal: -12123.575540699623\n",
      "Train Epoch: 3210 [256/118836 (0%)] Loss: 12183.135742\n",
      "Train Epoch: 3210 [33024/118836 (28%)] Loss: 12233.287109\n",
      "Train Epoch: 3210 [65792/118836 (55%)] Loss: 12261.794922\n",
      "Train Epoch: 3210 [98560/118836 (83%)] Loss: 12193.214844\n",
      "    epoch          : 3210\n",
      "    loss           : 12196.099050900797\n",
      "    val_loss       : 12195.567450138338\n",
      "    val_log_likelihood: -12113.754396873708\n",
      "    val_log_marginal: -12122.658421188606\n",
      "Train Epoch: 3211 [256/118836 (0%)] Loss: 12249.866211\n",
      "Train Epoch: 3211 [33024/118836 (28%)] Loss: 12184.825195\n",
      "Train Epoch: 3211 [65792/118836 (55%)] Loss: 12204.460938\n",
      "Train Epoch: 3211 [98560/118836 (83%)] Loss: 12201.253906\n",
      "    epoch          : 3211\n",
      "    loss           : 12199.54270219448\n",
      "    val_loss       : 12199.807510583076\n",
      "    val_log_likelihood: -12119.048253819014\n",
      "    val_log_marginal: -12127.929351138335\n",
      "Train Epoch: 3212 [256/118836 (0%)] Loss: 12164.281250\n",
      "Train Epoch: 3212 [33024/118836 (28%)] Loss: 12172.667969\n",
      "Train Epoch: 3212 [65792/118836 (55%)] Loss: 12284.995117\n",
      "Train Epoch: 3212 [98560/118836 (83%)] Loss: 12225.421875\n",
      "    epoch          : 3212\n",
      "    loss           : 12200.258447709884\n",
      "    val_loss       : 12197.138717906755\n",
      "    val_log_likelihood: -12116.045632528174\n",
      "    val_log_marginal: -12124.944197788094\n",
      "Train Epoch: 3213 [256/118836 (0%)] Loss: 12180.863281\n",
      "Train Epoch: 3213 [33024/118836 (28%)] Loss: 12309.653320\n",
      "Train Epoch: 3213 [65792/118836 (55%)] Loss: 12170.721680\n",
      "Train Epoch: 3213 [98560/118836 (83%)] Loss: 12274.002930\n",
      "    epoch          : 3213\n",
      "    loss           : 12198.13594024633\n",
      "    val_loss       : 12199.424278765833\n",
      "    val_log_likelihood: -12114.934007961125\n",
      "    val_log_marginal: -12123.791167414814\n",
      "Train Epoch: 3214 [256/118836 (0%)] Loss: 12163.895508\n",
      "Train Epoch: 3214 [33024/118836 (28%)] Loss: 12171.415039\n",
      "Train Epoch: 3214 [65792/118836 (55%)] Loss: 12256.694336\n",
      "Train Epoch: 3214 [98560/118836 (83%)] Loss: 12251.650391\n",
      "    epoch          : 3214\n",
      "    loss           : 12200.442752597706\n",
      "    val_loss       : 12196.853275552698\n",
      "    val_log_likelihood: -12115.093774555417\n",
      "    val_log_marginal: -12123.938970047953\n",
      "Train Epoch: 3215 [256/118836 (0%)] Loss: 12241.066406\n",
      "Train Epoch: 3215 [33024/118836 (28%)] Loss: 12209.621094\n",
      "Train Epoch: 3215 [65792/118836 (55%)] Loss: 12273.869141\n",
      "Train Epoch: 3215 [98560/118836 (83%)] Loss: 12154.367188\n",
      "    epoch          : 3215\n",
      "    loss           : 12197.421787117451\n",
      "    val_loss       : 12196.98179835603\n",
      "    val_log_likelihood: -12110.423776590933\n",
      "    val_log_marginal: -12119.193045160668\n",
      "Train Epoch: 3216 [256/118836 (0%)] Loss: 12182.388672\n",
      "Train Epoch: 3216 [33024/118836 (28%)] Loss: 12142.525391\n",
      "Train Epoch: 3216 [65792/118836 (55%)] Loss: 12140.757812\n",
      "Train Epoch: 3216 [98560/118836 (83%)] Loss: 12233.879883\n",
      "    epoch          : 3216\n",
      "    loss           : 12197.368923826509\n",
      "    val_loss       : 12198.487985513893\n",
      "    val_log_likelihood: -12118.13830289754\n",
      "    val_log_marginal: -12127.068249611693\n",
      "Train Epoch: 3217 [256/118836 (0%)] Loss: 12155.152344\n",
      "Train Epoch: 3217 [33024/118836 (28%)] Loss: 12164.939453\n",
      "Train Epoch: 3217 [65792/118836 (55%)] Loss: 12199.557617\n",
      "Train Epoch: 3217 [98560/118836 (83%)] Loss: 12237.189453\n",
      "    epoch          : 3217\n",
      "    loss           : 12194.931567604943\n",
      "    val_loss       : 12198.952252347337\n",
      "    val_log_likelihood: -12113.662267692824\n",
      "    val_log_marginal: -12122.460255878997\n",
      "Train Epoch: 3218 [256/118836 (0%)] Loss: 12231.182617\n",
      "Train Epoch: 3218 [33024/118836 (28%)] Loss: 12241.808594\n",
      "Train Epoch: 3218 [65792/118836 (55%)] Loss: 12207.316406\n",
      "Train Epoch: 3218 [98560/118836 (83%)] Loss: 12179.633789\n",
      "    epoch          : 3218\n",
      "    loss           : 12199.53101155397\n",
      "    val_loss       : 12196.470682271382\n",
      "    val_log_likelihood: -12113.504878935328\n",
      "    val_log_marginal: -12122.11913875748\n",
      "Train Epoch: 3219 [256/118836 (0%)] Loss: 12292.572266\n",
      "Train Epoch: 3219 [33024/118836 (28%)] Loss: 12262.146484\n",
      "Train Epoch: 3219 [65792/118836 (55%)] Loss: 12312.474609\n",
      "Train Epoch: 3219 [98560/118836 (83%)] Loss: 12217.839844\n",
      "    epoch          : 3219\n",
      "    loss           : 12195.902076548284\n",
      "    val_loss       : 12200.641389283557\n",
      "    val_log_likelihood: -12110.79143726737\n",
      "    val_log_marginal: -12119.655228764237\n",
      "Train Epoch: 3220 [256/118836 (0%)] Loss: 12258.754883\n",
      "Train Epoch: 3220 [33024/118836 (28%)] Loss: 12114.894531\n",
      "Train Epoch: 3220 [65792/118836 (55%)] Loss: 12323.155273\n",
      "Train Epoch: 3220 [98560/118836 (83%)] Loss: 12203.310547\n",
      "    epoch          : 3220\n",
      "    loss           : 12202.135627003205\n",
      "    val_loss       : 12197.62502450568\n",
      "    val_log_likelihood: -12116.16009421526\n",
      "    val_log_marginal: -12124.933873648664\n",
      "Train Epoch: 3221 [256/118836 (0%)] Loss: 12273.710938\n",
      "Train Epoch: 3221 [33024/118836 (28%)] Loss: 12195.076172\n",
      "Train Epoch: 3221 [65792/118836 (55%)] Loss: 12189.701172\n",
      "Train Epoch: 3221 [98560/118836 (83%)] Loss: 12267.703125\n",
      "    epoch          : 3221\n",
      "    loss           : 12201.177938249588\n",
      "    val_loss       : 12193.977468346242\n",
      "    val_log_likelihood: -12114.77423345094\n",
      "    val_log_marginal: -12123.597009085417\n",
      "Train Epoch: 3222 [256/118836 (0%)] Loss: 12167.507812\n",
      "Train Epoch: 3222 [33024/118836 (28%)] Loss: 12194.591797\n",
      "Train Epoch: 3222 [65792/118836 (55%)] Loss: 12168.872070\n",
      "Train Epoch: 3222 [98560/118836 (83%)] Loss: 12152.044922\n",
      "    epoch          : 3222\n",
      "    loss           : 12195.36054558261\n",
      "    val_loss       : 12198.81393131962\n",
      "    val_log_likelihood: -12112.674519553866\n",
      "    val_log_marginal: -12121.285047810552\n",
      "Train Epoch: 3223 [256/118836 (0%)] Loss: 12136.216797\n",
      "Train Epoch: 3223 [33024/118836 (28%)] Loss: 12354.326172\n",
      "Train Epoch: 3223 [65792/118836 (55%)] Loss: 12151.962891\n",
      "Train Epoch: 3223 [98560/118836 (83%)] Loss: 12196.382812\n",
      "    epoch          : 3223\n",
      "    loss           : 12200.800477538254\n",
      "    val_loss       : 12195.736875177112\n",
      "    val_log_likelihood: -12115.75053618047\n",
      "    val_log_marginal: -12124.640193457617\n",
      "Train Epoch: 3224 [256/118836 (0%)] Loss: 12242.818359\n",
      "Train Epoch: 3224 [33024/118836 (28%)] Loss: 12252.673828\n",
      "Train Epoch: 3224 [65792/118836 (55%)] Loss: 12339.492188\n",
      "Train Epoch: 3224 [98560/118836 (83%)] Loss: 12199.817383\n",
      "    epoch          : 3224\n",
      "    loss           : 12202.134633801179\n",
      "    val_loss       : 12199.169447349283\n",
      "    val_log_likelihood: -12114.709795996174\n",
      "    val_log_marginal: -12123.537986426976\n",
      "Train Epoch: 3225 [256/118836 (0%)] Loss: 12269.051758\n",
      "Train Epoch: 3225 [33024/118836 (28%)] Loss: 12172.349609\n",
      "Train Epoch: 3225 [65792/118836 (55%)] Loss: 12173.350586\n",
      "Train Epoch: 3225 [98560/118836 (83%)] Loss: 12182.512695\n",
      "    epoch          : 3225\n",
      "    loss           : 12197.911834742039\n",
      "    val_loss       : 12197.406992677681\n",
      "    val_log_likelihood: -12115.138132786653\n",
      "    val_log_marginal: -12123.895679319854\n",
      "Train Epoch: 3226 [256/118836 (0%)] Loss: 12168.864258\n",
      "Train Epoch: 3226 [33024/118836 (28%)] Loss: 12202.607422\n",
      "Train Epoch: 3226 [65792/118836 (55%)] Loss: 12276.725586\n",
      "Train Epoch: 3226 [98560/118836 (83%)] Loss: 12149.314453\n",
      "    epoch          : 3226\n",
      "    loss           : 12201.27930769877\n",
      "    val_loss       : 12195.38859876196\n",
      "    val_log_likelihood: -12111.259235260288\n",
      "    val_log_marginal: -12120.28558843075\n",
      "Train Epoch: 3227 [256/118836 (0%)] Loss: 12209.010742\n",
      "Train Epoch: 3227 [33024/118836 (28%)] Loss: 12252.709961\n",
      "Train Epoch: 3227 [65792/118836 (55%)] Loss: 12170.968750\n",
      "Train Epoch: 3227 [98560/118836 (83%)] Loss: 12226.563477\n",
      "    epoch          : 3227\n",
      "    loss           : 12197.99066797198\n",
      "    val_loss       : 12201.171110305015\n",
      "    val_log_likelihood: -12116.337551210969\n",
      "    val_log_marginal: -12125.229941649932\n",
      "Train Epoch: 3228 [256/118836 (0%)] Loss: 12268.864258\n",
      "Train Epoch: 3228 [33024/118836 (28%)] Loss: 12211.659180\n",
      "Train Epoch: 3228 [65792/118836 (55%)] Loss: 12213.701172\n",
      "Train Epoch: 3228 [98560/118836 (83%)] Loss: 12243.126953\n",
      "    epoch          : 3228\n",
      "    loss           : 12198.14601701432\n",
      "    val_loss       : 12192.922664132917\n",
      "    val_log_likelihood: -12114.699079010286\n",
      "    val_log_marginal: -12123.467061401869\n",
      "Train Epoch: 3229 [256/118836 (0%)] Loss: 12203.578125\n",
      "Train Epoch: 3229 [33024/118836 (28%)] Loss: 12260.089844\n",
      "Train Epoch: 3229 [65792/118836 (55%)] Loss: 12134.160156\n",
      "Train Epoch: 3229 [98560/118836 (83%)] Loss: 12108.928711\n",
      "    epoch          : 3229\n",
      "    loss           : 12192.272853016439\n",
      "    val_loss       : 12200.10436834684\n",
      "    val_log_likelihood: -12115.065065556504\n",
      "    val_log_marginal: -12123.906480362242\n",
      "Train Epoch: 3230 [256/118836 (0%)] Loss: 12152.654297\n",
      "Train Epoch: 3230 [33024/118836 (28%)] Loss: 12140.149414\n",
      "Train Epoch: 3230 [65792/118836 (55%)] Loss: 12295.384766\n",
      "Train Epoch: 3230 [98560/118836 (83%)] Loss: 12268.152344\n",
      "    epoch          : 3230\n",
      "    loss           : 12197.917270697633\n",
      "    val_loss       : 12206.849826089438\n",
      "    val_log_likelihood: -12136.293153238732\n",
      "    val_log_marginal: -12145.037783534051\n",
      "Train Epoch: 3231 [256/118836 (0%)] Loss: 12202.901367\n",
      "Train Epoch: 3231 [33024/118836 (28%)] Loss: 12200.498047\n",
      "Train Epoch: 3231 [65792/118836 (55%)] Loss: 12231.694336\n",
      "Train Epoch: 3231 [98560/118836 (83%)] Loss: 12220.285156\n",
      "    epoch          : 3231\n",
      "    loss           : 12196.579914799162\n",
      "    val_loss       : 12196.695083953558\n",
      "    val_log_likelihood: -12113.138123093724\n",
      "    val_log_marginal: -12122.014159980925\n",
      "Train Epoch: 3232 [256/118836 (0%)] Loss: 12177.255859\n",
      "Train Epoch: 3232 [33024/118836 (28%)] Loss: 12248.217773\n",
      "Train Epoch: 3232 [65792/118836 (55%)] Loss: 12205.333008\n",
      "Train Epoch: 3232 [98560/118836 (83%)] Loss: 12155.412109\n",
      "    epoch          : 3232\n",
      "    loss           : 12196.261937325527\n",
      "    val_loss       : 12196.715453816305\n",
      "    val_log_likelihood: -12116.21157997958\n",
      "    val_log_marginal: -12125.103249957047\n",
      "Train Epoch: 3233 [256/118836 (0%)] Loss: 12181.374023\n",
      "Train Epoch: 3233 [33024/118836 (28%)] Loss: 12198.899414\n",
      "Train Epoch: 3233 [65792/118836 (55%)] Loss: 12251.986328\n",
      "Train Epoch: 3233 [98560/118836 (83%)] Loss: 12235.074219\n",
      "    epoch          : 3233\n",
      "    loss           : 12196.557116063119\n",
      "    val_loss       : 12194.510226437229\n",
      "    val_log_likelihood: -12116.854033712003\n",
      "    val_log_marginal: -12125.569814493418\n",
      "Train Epoch: 3234 [256/118836 (0%)] Loss: 12257.213867\n",
      "Train Epoch: 3234 [33024/118836 (28%)] Loss: 12211.441406\n",
      "Train Epoch: 3234 [65792/118836 (55%)] Loss: 12215.790039\n",
      "Train Epoch: 3234 [98560/118836 (83%)] Loss: 12284.538086\n",
      "    epoch          : 3234\n",
      "    loss           : 12195.467793308002\n",
      "    val_loss       : 12198.845296164922\n",
      "    val_log_likelihood: -12114.926519528019\n",
      "    val_log_marginal: -12123.897747690935\n",
      "Train Epoch: 3235 [256/118836 (0%)] Loss: 12239.291992\n",
      "Train Epoch: 3235 [33024/118836 (28%)] Loss: 12164.869141\n",
      "Train Epoch: 3235 [65792/118836 (55%)] Loss: 12239.583008\n",
      "Train Epoch: 3235 [98560/118836 (83%)] Loss: 12250.975586\n",
      "    epoch          : 3235\n",
      "    loss           : 12197.244926559915\n",
      "    val_loss       : 12197.921847619771\n",
      "    val_log_likelihood: -12118.752321779364\n",
      "    val_log_marginal: -12127.685970316228\n",
      "Train Epoch: 3236 [256/118836 (0%)] Loss: 12218.841797\n",
      "Train Epoch: 3236 [33024/118836 (28%)] Loss: 12372.376953\n",
      "Train Epoch: 3236 [65792/118836 (55%)] Loss: 12245.102539\n",
      "Train Epoch: 3236 [98560/118836 (83%)] Loss: 12154.639648\n",
      "    epoch          : 3236\n",
      "    loss           : 12195.88896007806\n",
      "    val_loss       : 12196.95493364943\n",
      "    val_log_likelihood: -12113.63673248165\n",
      "    val_log_marginal: -12122.482702024765\n",
      "Train Epoch: 3237 [256/118836 (0%)] Loss: 12276.091797\n",
      "Train Epoch: 3237 [33024/118836 (28%)] Loss: 12158.653320\n",
      "Train Epoch: 3237 [65792/118836 (55%)] Loss: 12073.533203\n",
      "Train Epoch: 3237 [98560/118836 (83%)] Loss: 12242.875000\n",
      "    epoch          : 3237\n",
      "    loss           : 12195.376253295595\n",
      "    val_loss       : 12197.10219673533\n",
      "    val_log_likelihood: -12117.441510610524\n",
      "    val_log_marginal: -12126.312081412672\n",
      "Train Epoch: 3238 [256/118836 (0%)] Loss: 12205.618164\n",
      "Train Epoch: 3238 [33024/118836 (28%)] Loss: 12218.926758\n",
      "Train Epoch: 3238 [65792/118836 (55%)] Loss: 12161.738281\n",
      "Train Epoch: 3238 [98560/118836 (83%)] Loss: 12137.305664\n",
      "    epoch          : 3238\n",
      "    loss           : 12197.240586874485\n",
      "    val_loss       : 12209.234909733139\n",
      "    val_log_likelihood: -12115.510485001809\n",
      "    val_log_marginal: -12124.421517446692\n",
      "Train Epoch: 3239 [256/118836 (0%)] Loss: 12319.928711\n",
      "Train Epoch: 3239 [33024/118836 (28%)] Loss: 12336.590820\n",
      "Train Epoch: 3239 [65792/118836 (55%)] Loss: 12250.197266\n",
      "Train Epoch: 3239 [98560/118836 (83%)] Loss: 12130.859375\n",
      "    epoch          : 3239\n",
      "    loss           : 12205.757990042131\n",
      "    val_loss       : 12197.715252201944\n",
      "    val_log_likelihood: -12115.008466287996\n",
      "    val_log_marginal: -12123.905089172302\n",
      "Train Epoch: 3240 [256/118836 (0%)] Loss: 12226.465820\n",
      "Train Epoch: 3240 [33024/118836 (28%)] Loss: 12244.560547\n",
      "Train Epoch: 3240 [65792/118836 (55%)] Loss: 12165.258789\n",
      "Train Epoch: 3240 [98560/118836 (83%)] Loss: 12205.246094\n",
      "    epoch          : 3240\n",
      "    loss           : 12200.863840208849\n",
      "    val_loss       : 12205.548594064554\n",
      "    val_log_likelihood: -12118.016386056399\n",
      "    val_log_marginal: -12126.889908336752\n",
      "Train Epoch: 3241 [256/118836 (0%)] Loss: 12301.982422\n",
      "Train Epoch: 3241 [33024/118836 (28%)] Loss: 12188.382812\n",
      "Train Epoch: 3241 [65792/118836 (55%)] Loss: 12165.071289\n",
      "Train Epoch: 3241 [98560/118836 (83%)] Loss: 12298.581055\n",
      "    epoch          : 3241\n",
      "    loss           : 12197.47330406069\n",
      "    val_loss       : 12195.052031092855\n",
      "    val_log_likelihood: -12112.84171852383\n",
      "    val_log_marginal: -12121.805100415044\n",
      "Train Epoch: 3242 [256/118836 (0%)] Loss: 12183.422852\n",
      "Train Epoch: 3242 [33024/118836 (28%)] Loss: 12205.902344\n",
      "Train Epoch: 3242 [65792/118836 (55%)] Loss: 12210.535156\n",
      "Train Epoch: 3242 [98560/118836 (83%)] Loss: 12199.264648\n",
      "    epoch          : 3242\n",
      "    loss           : 12199.845438184968\n",
      "    val_loss       : 12197.179178561542\n",
      "    val_log_likelihood: -12115.43219554513\n",
      "    val_log_marginal: -12124.330069812915\n",
      "Train Epoch: 3243 [256/118836 (0%)] Loss: 12225.976562\n",
      "Train Epoch: 3243 [33024/118836 (28%)] Loss: 12166.129883\n",
      "Train Epoch: 3243 [65792/118836 (55%)] Loss: 12220.886719\n",
      "Train Epoch: 3243 [98560/118836 (83%)] Loss: 12232.921875\n",
      "    epoch          : 3243\n",
      "    loss           : 12198.960069659843\n",
      "    val_loss       : 12201.740621878358\n",
      "    val_log_likelihood: -12115.94932908783\n",
      "    val_log_marginal: -12124.995413167171\n",
      "Train Epoch: 3244 [256/118836 (0%)] Loss: 12143.947266\n",
      "Train Epoch: 3244 [33024/118836 (28%)] Loss: 12138.820312\n",
      "Train Epoch: 3244 [65792/118836 (55%)] Loss: 12200.382812\n",
      "Train Epoch: 3244 [98560/118836 (83%)] Loss: 12180.609375\n",
      "    epoch          : 3244\n",
      "    loss           : 12196.417978927575\n",
      "    val_loss       : 12197.288185662286\n",
      "    val_log_likelihood: -12115.247690659893\n",
      "    val_log_marginal: -12124.068220519659\n",
      "Train Epoch: 3245 [256/118836 (0%)] Loss: 12268.145508\n",
      "Train Epoch: 3245 [33024/118836 (28%)] Loss: 12221.432617\n",
      "Train Epoch: 3245 [65792/118836 (55%)] Loss: 12262.694336\n",
      "Train Epoch: 3245 [98560/118836 (83%)] Loss: 12140.037109\n",
      "    epoch          : 3245\n",
      "    loss           : 12200.35735596309\n",
      "    val_loss       : 12199.445512543922\n",
      "    val_log_likelihood: -12115.366215460866\n",
      "    val_log_marginal: -12124.38782935957\n",
      "Train Epoch: 3246 [256/118836 (0%)] Loss: 12206.924805\n",
      "Train Epoch: 3246 [33024/118836 (28%)] Loss: 12160.714844\n",
      "Train Epoch: 3246 [65792/118836 (55%)] Loss: 12365.496094\n",
      "Train Epoch: 3246 [98560/118836 (83%)] Loss: 12141.099609\n",
      "    epoch          : 3246\n",
      "    loss           : 12197.924088541668\n",
      "    val_loss       : 12195.779301787552\n",
      "    val_log_likelihood: -12120.217018035308\n",
      "    val_log_marginal: -12129.086192706976\n",
      "Train Epoch: 3247 [256/118836 (0%)] Loss: 12174.398438\n",
      "Train Epoch: 3247 [33024/118836 (28%)] Loss: 12208.908203\n",
      "Train Epoch: 3247 [65792/118836 (55%)] Loss: 12222.518555\n",
      "Train Epoch: 3247 [98560/118836 (83%)] Loss: 12340.416016\n",
      "    epoch          : 3247\n",
      "    loss           : 12196.972787427625\n",
      "    val_loss       : 12197.249430296772\n",
      "    val_log_likelihood: -12114.481413972033\n",
      "    val_log_marginal: -12123.111017326275\n",
      "Train Epoch: 3248 [256/118836 (0%)] Loss: 12146.390625\n",
      "Train Epoch: 3248 [33024/118836 (28%)] Loss: 12230.069336\n",
      "Train Epoch: 3248 [65792/118836 (55%)] Loss: 12253.296875\n",
      "Train Epoch: 3248 [98560/118836 (83%)] Loss: 12171.607422\n",
      "    epoch          : 3248\n",
      "    loss           : 12196.459660295182\n",
      "    val_loss       : 12200.285248614631\n",
      "    val_log_likelihood: -12112.234744785206\n",
      "    val_log_marginal: -12121.027070495602\n",
      "Train Epoch: 3249 [256/118836 (0%)] Loss: 12269.669922\n",
      "Train Epoch: 3249 [33024/118836 (28%)] Loss: 12224.781250\n",
      "Train Epoch: 3249 [65792/118836 (55%)] Loss: 12220.317383\n",
      "Train Epoch: 3249 [98560/118836 (83%)] Loss: 12189.539062\n",
      "    epoch          : 3249\n",
      "    loss           : 12195.271942204301\n",
      "    val_loss       : 12201.076070169238\n",
      "    val_log_likelihood: -12115.092925293373\n",
      "    val_log_marginal: -12123.970381440806\n",
      "Train Epoch: 3250 [256/118836 (0%)] Loss: 12244.745117\n",
      "Train Epoch: 3250 [33024/118836 (28%)] Loss: 12214.960938\n",
      "Train Epoch: 3250 [65792/118836 (55%)] Loss: 12207.888672\n",
      "Train Epoch: 3250 [98560/118836 (83%)] Loss: 12158.095703\n",
      "    epoch          : 3250\n",
      "    loss           : 12194.176944401366\n",
      "    val_loss       : 12199.545878507279\n",
      "    val_log_likelihood: -12115.719303950838\n",
      "    val_log_marginal: -12124.567208672868\n",
      "Train Epoch: 3251 [256/118836 (0%)] Loss: 12187.051758\n",
      "Train Epoch: 3251 [33024/118836 (28%)] Loss: 12178.789062\n",
      "Train Epoch: 3251 [65792/118836 (55%)] Loss: 12255.134766\n",
      "Train Epoch: 3251 [98560/118836 (83%)] Loss: 12157.528320\n",
      "    epoch          : 3251\n",
      "    loss           : 12194.038778012562\n",
      "    val_loss       : 12197.37317390236\n",
      "    val_log_likelihood: -12116.930923348325\n",
      "    val_log_marginal: -12125.77637777139\n",
      "Train Epoch: 3252 [256/118836 (0%)] Loss: 12268.233398\n",
      "Train Epoch: 3252 [33024/118836 (28%)] Loss: 12179.601562\n",
      "Train Epoch: 3252 [65792/118836 (55%)] Loss: 12207.197266\n",
      "Train Epoch: 3252 [98560/118836 (83%)] Loss: 12104.507812\n",
      "    epoch          : 3252\n",
      "    loss           : 12198.448000833592\n",
      "    val_loss       : 12198.55455577359\n",
      "    val_log_likelihood: -12113.81830137898\n",
      "    val_log_marginal: -12122.548610368014\n",
      "Train Epoch: 3253 [256/118836 (0%)] Loss: 12127.983398\n",
      "Train Epoch: 3253 [33024/118836 (28%)] Loss: 12221.677734\n",
      "Train Epoch: 3253 [65792/118836 (55%)] Loss: 12132.444336\n",
      "Train Epoch: 3253 [98560/118836 (83%)] Loss: 12219.733398\n",
      "    epoch          : 3253\n",
      "    loss           : 12196.037861061568\n",
      "    val_loss       : 12197.807870255272\n",
      "    val_log_likelihood: -12114.895377604167\n",
      "    val_log_marginal: -12123.54469838506\n",
      "Train Epoch: 3254 [256/118836 (0%)] Loss: 12152.070312\n",
      "Train Epoch: 3254 [33024/118836 (28%)] Loss: 12162.749023\n",
      "Train Epoch: 3254 [65792/118836 (55%)] Loss: 12180.244141\n",
      "Train Epoch: 3254 [98560/118836 (83%)] Loss: 12254.208984\n",
      "    epoch          : 3254\n",
      "    loss           : 12195.99432252895\n",
      "    val_loss       : 12198.105944513612\n",
      "    val_log_likelihood: -12114.139725496278\n",
      "    val_log_marginal: -12122.94321038383\n",
      "Train Epoch: 3255 [256/118836 (0%)] Loss: 12190.333984\n",
      "Train Epoch: 3255 [33024/118836 (28%)] Loss: 12191.272461\n",
      "Train Epoch: 3255 [65792/118836 (55%)] Loss: 12270.817383\n",
      "Train Epoch: 3255 [98560/118836 (83%)] Loss: 12186.125000\n",
      "    epoch          : 3255\n",
      "    loss           : 12197.411043314463\n",
      "    val_loss       : 12193.06853212075\n",
      "    val_log_likelihood: -12114.338953777657\n",
      "    val_log_marginal: -12123.131355348623\n",
      "Train Epoch: 3256 [256/118836 (0%)] Loss: 12196.133789\n",
      "Train Epoch: 3256 [33024/118836 (28%)] Loss: 12214.102539\n",
      "Train Epoch: 3256 [65792/118836 (55%)] Loss: 12217.010742\n",
      "Train Epoch: 3256 [98560/118836 (83%)] Loss: 12172.088867\n",
      "    epoch          : 3256\n",
      "    loss           : 12199.793036277399\n",
      "    val_loss       : 12194.188945674872\n",
      "    val_log_likelihood: -12116.38515883478\n",
      "    val_log_marginal: -12125.209354579118\n",
      "Train Epoch: 3257 [256/118836 (0%)] Loss: 12255.548828\n",
      "Train Epoch: 3257 [33024/118836 (28%)] Loss: 12303.699219\n",
      "Train Epoch: 3257 [65792/118836 (55%)] Loss: 12269.397461\n",
      "Train Epoch: 3257 [98560/118836 (83%)] Loss: 12177.298828\n",
      "    epoch          : 3257\n",
      "    loss           : 12197.958742374896\n",
      "    val_loss       : 12198.327770435091\n",
      "    val_log_likelihood: -12116.09501072684\n",
      "    val_log_marginal: -12124.855197276442\n",
      "Train Epoch: 3258 [256/118836 (0%)] Loss: 12200.345703\n",
      "Train Epoch: 3258 [33024/118836 (28%)] Loss: 12175.117188\n",
      "Train Epoch: 3258 [65792/118836 (55%)] Loss: 12183.802734\n",
      "Train Epoch: 3258 [98560/118836 (83%)] Loss: 12168.156250\n",
      "    epoch          : 3258\n",
      "    loss           : 12195.49109623785\n",
      "    val_loss       : 12199.22488666875\n",
      "    val_log_likelihood: -12113.81558865152\n",
      "    val_log_marginal: -12122.524176445217\n",
      "Train Epoch: 3259 [256/118836 (0%)] Loss: 12158.827148\n",
      "Train Epoch: 3259 [33024/118836 (28%)] Loss: 12253.513672\n",
      "Train Epoch: 3259 [65792/118836 (55%)] Loss: 12153.219727\n",
      "Train Epoch: 3259 [98560/118836 (83%)] Loss: 12188.808594\n",
      "    epoch          : 3259\n",
      "    loss           : 12199.512743130945\n",
      "    val_loss       : 12197.340075093283\n",
      "    val_log_likelihood: -12115.262500969293\n",
      "    val_log_marginal: -12123.954643981775\n",
      "Train Epoch: 3260 [256/118836 (0%)] Loss: 12141.316406\n",
      "Train Epoch: 3260 [33024/118836 (28%)] Loss: 12217.299805\n",
      "Train Epoch: 3260 [65792/118836 (55%)] Loss: 12194.256836\n",
      "Train Epoch: 3260 [98560/118836 (83%)] Loss: 12231.408203\n",
      "    epoch          : 3260\n",
      "    loss           : 12200.440183810224\n",
      "    val_loss       : 12196.530242299432\n",
      "    val_log_likelihood: -12114.395496342535\n",
      "    val_log_marginal: -12123.19340961622\n",
      "Train Epoch: 3261 [256/118836 (0%)] Loss: 12298.000000\n",
      "Train Epoch: 3261 [33024/118836 (28%)] Loss: 12135.402344\n",
      "Train Epoch: 3261 [65792/118836 (55%)] Loss: 12185.723633\n",
      "Train Epoch: 3261 [98560/118836 (83%)] Loss: 12135.564453\n",
      "    epoch          : 3261\n",
      "    loss           : 12194.403042610113\n",
      "    val_loss       : 12192.512316323591\n",
      "    val_log_likelihood: -12115.378192527398\n",
      "    val_log_marginal: -12124.046568026046\n",
      "Train Epoch: 3262 [256/118836 (0%)] Loss: 12258.610352\n",
      "Train Epoch: 3262 [33024/118836 (28%)] Loss: 12220.536133\n",
      "Train Epoch: 3262 [65792/118836 (55%)] Loss: 12232.968750\n",
      "Train Epoch: 3262 [98560/118836 (83%)] Loss: 12251.376953\n",
      "    epoch          : 3262\n",
      "    loss           : 12199.915447619418\n",
      "    val_loss       : 12202.528545564059\n",
      "    val_log_likelihood: -12121.407217515767\n",
      "    val_log_marginal: -12130.129276398446\n",
      "Train Epoch: 3263 [256/118836 (0%)] Loss: 12204.185547\n",
      "Train Epoch: 3263 [33024/118836 (28%)] Loss: 12139.277344\n",
      "Train Epoch: 3263 [65792/118836 (55%)] Loss: 12274.381836\n",
      "Train Epoch: 3263 [98560/118836 (83%)] Loss: 12318.963867\n",
      "    epoch          : 3263\n",
      "    loss           : 12197.898251072684\n",
      "    val_loss       : 12193.532256457054\n",
      "    val_log_likelihood: -12113.184870308623\n",
      "    val_log_marginal: -12121.941509030605\n",
      "Train Epoch: 3264 [256/118836 (0%)] Loss: 12205.397461\n",
      "Train Epoch: 3264 [33024/118836 (28%)] Loss: 12182.706055\n",
      "Train Epoch: 3264 [65792/118836 (55%)] Loss: 12179.083984\n",
      "Train Epoch: 3264 [98560/118836 (83%)] Loss: 12211.980469\n",
      "    epoch          : 3264\n",
      "    loss           : 12194.332894405243\n",
      "    val_loss       : 12194.278877941557\n",
      "    val_log_likelihood: -12113.106144023986\n",
      "    val_log_marginal: -12121.805622452397\n",
      "Train Epoch: 3265 [256/118836 (0%)] Loss: 12164.464844\n",
      "Train Epoch: 3265 [33024/118836 (28%)] Loss: 12169.505859\n",
      "Train Epoch: 3265 [65792/118836 (55%)] Loss: 12212.437500\n",
      "Train Epoch: 3265 [98560/118836 (83%)] Loss: 12146.762695\n",
      "    epoch          : 3265\n",
      "    loss           : 12196.155931587313\n",
      "    val_loss       : 12194.159049673224\n",
      "    val_log_likelihood: -12116.190610783706\n",
      "    val_log_marginal: -12124.937411415882\n",
      "Train Epoch: 3266 [256/118836 (0%)] Loss: 12169.672852\n",
      "Train Epoch: 3266 [33024/118836 (28%)] Loss: 12149.730469\n",
      "Train Epoch: 3266 [65792/118836 (55%)] Loss: 12308.375977\n",
      "Train Epoch: 3266 [98560/118836 (83%)] Loss: 12255.360352\n",
      "    epoch          : 3266\n",
      "    loss           : 12196.588684637356\n",
      "    val_loss       : 12195.651846375025\n",
      "    val_log_likelihood: -12115.308088909998\n",
      "    val_log_marginal: -12124.106917873112\n",
      "Train Epoch: 3267 [256/118836 (0%)] Loss: 12240.728516\n",
      "Train Epoch: 3267 [33024/118836 (28%)] Loss: 12302.531250\n",
      "Train Epoch: 3267 [65792/118836 (55%)] Loss: 12289.467773\n",
      "Train Epoch: 3267 [98560/118836 (83%)] Loss: 12206.266602\n",
      "    epoch          : 3267\n",
      "    loss           : 12200.027756830283\n",
      "    val_loss       : 12199.389853798728\n",
      "    val_log_likelihood: -12112.469655319479\n",
      "    val_log_marginal: -12121.204002655946\n",
      "Train Epoch: 3268 [256/118836 (0%)] Loss: 12267.156250\n",
      "Train Epoch: 3268 [33024/118836 (28%)] Loss: 12168.373047\n",
      "Train Epoch: 3268 [65792/118836 (55%)] Loss: 12167.871094\n",
      "Train Epoch: 3268 [98560/118836 (83%)] Loss: 12158.626953\n",
      "    epoch          : 3268\n",
      "    loss           : 12197.230476342795\n",
      "    val_loss       : 12195.640904229806\n",
      "    val_log_likelihood: -12115.122037518093\n",
      "    val_log_marginal: -12123.927130115851\n",
      "Train Epoch: 3269 [256/118836 (0%)] Loss: 12249.499023\n",
      "Train Epoch: 3269 [33024/118836 (28%)] Loss: 12270.128906\n",
      "Train Epoch: 3269 [65792/118836 (55%)] Loss: 12227.567383\n",
      "Train Epoch: 3269 [98560/118836 (83%)] Loss: 12145.310547\n",
      "    epoch          : 3269\n",
      "    loss           : 12196.552267337418\n",
      "    val_loss       : 12200.66201374325\n",
      "    val_log_likelihood: -12114.938886250258\n",
      "    val_log_marginal: -12123.70540044553\n",
      "Train Epoch: 3270 [256/118836 (0%)] Loss: 12159.240234\n",
      "Train Epoch: 3270 [33024/118836 (28%)] Loss: 12204.019531\n",
      "Train Epoch: 3270 [65792/118836 (55%)] Loss: 12301.320312\n",
      "Train Epoch: 3270 [98560/118836 (83%)] Loss: 12226.861328\n",
      "    epoch          : 3270\n",
      "    loss           : 12198.473450585452\n",
      "    val_loss       : 12197.432581640222\n",
      "    val_log_likelihood: -12118.05837032801\n",
      "    val_log_marginal: -12127.048465076634\n",
      "Train Epoch: 3271 [256/118836 (0%)] Loss: 12289.570312\n",
      "Train Epoch: 3271 [33024/118836 (28%)] Loss: 12368.852539\n",
      "Train Epoch: 3271 [65792/118836 (55%)] Loss: 12166.318359\n",
      "Train Epoch: 3271 [98560/118836 (83%)] Loss: 12263.382812\n",
      "    epoch          : 3271\n",
      "    loss           : 12200.254650828423\n",
      "    val_loss       : 12198.632020926088\n",
      "    val_log_likelihood: -12116.30107203784\n",
      "    val_log_marginal: -12125.128909035275\n",
      "Train Epoch: 3272 [256/118836 (0%)] Loss: 12216.481445\n",
      "Train Epoch: 3272 [33024/118836 (28%)] Loss: 12262.540039\n",
      "Train Epoch: 3272 [65792/118836 (55%)] Loss: 12136.402344\n",
      "Train Epoch: 3272 [98560/118836 (83%)] Loss: 12361.450195\n",
      "    epoch          : 3272\n",
      "    loss           : 12202.077258613781\n",
      "    val_loss       : 12197.969764319503\n",
      "    val_log_likelihood: -12114.187716152295\n",
      "    val_log_marginal: -12123.100865539158\n",
      "Train Epoch: 3273 [256/118836 (0%)] Loss: 12212.584961\n",
      "Train Epoch: 3273 [33024/118836 (28%)] Loss: 12155.365234\n",
      "Train Epoch: 3273 [65792/118836 (55%)] Loss: 12243.603516\n",
      "Train Epoch: 3273 [98560/118836 (83%)] Loss: 12208.791016\n",
      "    epoch          : 3273\n",
      "    loss           : 12195.720015896402\n",
      "    val_loss       : 12195.755226072079\n",
      "    val_log_likelihood: -12110.125410010856\n",
      "    val_log_marginal: -12118.860147245885\n",
      "Train Epoch: 3274 [256/118836 (0%)] Loss: 12244.994141\n",
      "Train Epoch: 3274 [33024/118836 (28%)] Loss: 12225.769531\n",
      "Train Epoch: 3274 [65792/118836 (55%)] Loss: 12245.521484\n",
      "Train Epoch: 3274 [98560/118836 (83%)] Loss: 12119.684570\n",
      "    epoch          : 3274\n",
      "    loss           : 12201.654952440033\n",
      "    val_loss       : 12196.413158551124\n",
      "    val_log_likelihood: -12110.800911296785\n",
      "    val_log_marginal: -12119.62193517792\n",
      "Train Epoch: 3275 [256/118836 (0%)] Loss: 12251.567383\n",
      "Train Epoch: 3275 [33024/118836 (28%)] Loss: 12337.377930\n",
      "Train Epoch: 3275 [65792/118836 (55%)] Loss: 12260.568359\n",
      "Train Epoch: 3275 [98560/118836 (83%)] Loss: 12249.667969\n",
      "    epoch          : 3275\n",
      "    loss           : 12194.94655594112\n",
      "    val_loss       : 12198.53616003805\n",
      "    val_log_likelihood: -12114.417192184916\n",
      "    val_log_marginal: -12123.121106044564\n",
      "Train Epoch: 3276 [256/118836 (0%)] Loss: 12314.841797\n",
      "Train Epoch: 3276 [33024/118836 (28%)] Loss: 12199.667969\n",
      "Train Epoch: 3276 [65792/118836 (55%)] Loss: 12317.432617\n",
      "Train Epoch: 3276 [98560/118836 (83%)] Loss: 12280.911133\n",
      "    epoch          : 3276\n",
      "    loss           : 12197.74711312293\n",
      "    val_loss       : 12199.559159758837\n",
      "    val_log_likelihood: -12114.075112437966\n",
      "    val_log_marginal: -12122.81270256933\n",
      "Train Epoch: 3277 [256/118836 (0%)] Loss: 12197.132812\n",
      "Train Epoch: 3277 [33024/118836 (28%)] Loss: 12237.769531\n",
      "Train Epoch: 3277 [65792/118836 (55%)] Loss: 12276.080078\n",
      "Train Epoch: 3277 [98560/118836 (83%)] Loss: 12346.659180\n",
      "    epoch          : 3277\n",
      "    loss           : 12197.404085730717\n",
      "    val_loss       : 12193.286631206394\n",
      "    val_log_likelihood: -12117.53808076794\n",
      "    val_log_marginal: -12126.340253804019\n",
      "Train Epoch: 3278 [256/118836 (0%)] Loss: 12235.051758\n",
      "Train Epoch: 3278 [33024/118836 (28%)] Loss: 12271.631836\n",
      "Train Epoch: 3278 [65792/118836 (55%)] Loss: 12178.500000\n",
      "Train Epoch: 3278 [98560/118836 (83%)] Loss: 12291.191406\n",
      "    epoch          : 3278\n",
      "    loss           : 12197.316794613316\n",
      "    val_loss       : 12195.484579583912\n",
      "    val_log_likelihood: -12112.615195603288\n",
      "    val_log_marginal: -12121.569939870025\n",
      "Train Epoch: 3279 [256/118836 (0%)] Loss: 12151.470703\n",
      "Train Epoch: 3279 [33024/118836 (28%)] Loss: 12358.820312\n",
      "Train Epoch: 3279 [65792/118836 (55%)] Loss: 12288.253906\n",
      "Train Epoch: 3279 [98560/118836 (83%)] Loss: 12183.958984\n",
      "    epoch          : 3279\n",
      "    loss           : 12200.602078486869\n",
      "    val_loss       : 12195.41881048931\n",
      "    val_log_likelihood: -12114.643815427264\n",
      "    val_log_marginal: -12123.313096999198\n",
      "Train Epoch: 3280 [256/118836 (0%)] Loss: 12244.313477\n",
      "Train Epoch: 3280 [33024/118836 (28%)] Loss: 12291.478516\n",
      "Train Epoch: 3280 [65792/118836 (55%)] Loss: 12228.623047\n",
      "Train Epoch: 3280 [98560/118836 (83%)] Loss: 12238.820312\n",
      "    epoch          : 3280\n",
      "    loss           : 12196.541116916098\n",
      "    val_loss       : 12200.217142135414\n",
      "    val_log_likelihood: -12113.812732791823\n",
      "    val_log_marginal: -12122.691045071024\n",
      "Train Epoch: 3281 [256/118836 (0%)] Loss: 12233.612305\n",
      "Train Epoch: 3281 [33024/118836 (28%)] Loss: 12186.695312\n",
      "Train Epoch: 3281 [65792/118836 (55%)] Loss: 12241.204102\n",
      "Train Epoch: 3281 [98560/118836 (83%)] Loss: 12180.178711\n",
      "    epoch          : 3281\n",
      "    loss           : 12200.69542849204\n",
      "    val_loss       : 12194.989284493615\n",
      "    val_log_likelihood: -12115.219704268764\n",
      "    val_log_marginal: -12124.03598521842\n",
      "Train Epoch: 3282 [256/118836 (0%)] Loss: 12191.883789\n",
      "Train Epoch: 3282 [33024/118836 (28%)] Loss: 12201.957031\n",
      "Train Epoch: 3282 [65792/118836 (55%)] Loss: 12214.947266\n",
      "Train Epoch: 3282 [98560/118836 (83%)] Loss: 12207.905273\n",
      "    epoch          : 3282\n",
      "    loss           : 12195.361334263855\n",
      "    val_loss       : 12195.184303375932\n",
      "    val_log_likelihood: -12114.389238749742\n",
      "    val_log_marginal: -12123.098133677679\n",
      "Train Epoch: 3283 [256/118836 (0%)] Loss: 12114.474609\n",
      "Train Epoch: 3283 [33024/118836 (28%)] Loss: 12221.398438\n",
      "Train Epoch: 3283 [65792/118836 (55%)] Loss: 12231.230469\n",
      "Train Epoch: 3283 [98560/118836 (83%)] Loss: 12209.271484\n",
      "    epoch          : 3283\n",
      "    loss           : 12196.177065562966\n",
      "    val_loss       : 12197.908209384648\n",
      "    val_log_likelihood: -12113.392631436103\n",
      "    val_log_marginal: -12122.060533646434\n",
      "Train Epoch: 3284 [256/118836 (0%)] Loss: 12210.837891\n",
      "Train Epoch: 3284 [33024/118836 (28%)] Loss: 12275.463867\n",
      "Train Epoch: 3284 [65792/118836 (55%)] Loss: 12250.439453\n",
      "Train Epoch: 3284 [98560/118836 (83%)] Loss: 12302.802734\n",
      "    epoch          : 3284\n",
      "    loss           : 12200.611221664341\n",
      "    val_loss       : 12198.614007652008\n",
      "    val_log_likelihood: -12115.80323420699\n",
      "    val_log_marginal: -12124.466538521445\n",
      "Train Epoch: 3285 [256/118836 (0%)] Loss: 12191.958008\n",
      "Train Epoch: 3285 [33024/118836 (28%)] Loss: 12175.907227\n",
      "Train Epoch: 3285 [65792/118836 (55%)] Loss: 12221.096680\n",
      "Train Epoch: 3285 [98560/118836 (83%)] Loss: 12154.591797\n",
      "    epoch          : 3285\n",
      "    loss           : 12197.6203194466\n",
      "    val_loss       : 12197.934623209332\n",
      "    val_log_likelihood: -12110.619762587881\n",
      "    val_log_marginal: -12119.260895858493\n",
      "Train Epoch: 3286 [256/118836 (0%)] Loss: 12245.123047\n",
      "Train Epoch: 3286 [33024/118836 (28%)] Loss: 12183.979492\n",
      "Train Epoch: 3286 [65792/118836 (55%)] Loss: 12356.529297\n",
      "Train Epoch: 3286 [98560/118836 (83%)] Loss: 12186.087891\n",
      "    epoch          : 3286\n",
      "    loss           : 12196.696357236093\n",
      "    val_loss       : 12201.065243529618\n",
      "    val_log_likelihood: -12114.101272681452\n",
      "    val_log_marginal: -12122.782369250515\n",
      "Train Epoch: 3287 [256/118836 (0%)] Loss: 12206.099609\n",
      "Train Epoch: 3287 [33024/118836 (28%)] Loss: 12206.428711\n",
      "Train Epoch: 3287 [65792/118836 (55%)] Loss: 12212.113281\n",
      "Train Epoch: 3287 [98560/118836 (83%)] Loss: 12274.120117\n",
      "    epoch          : 3287\n",
      "    loss           : 12197.393145484388\n",
      "    val_loss       : 12202.494605090436\n",
      "    val_log_likelihood: -12114.295084716192\n",
      "    val_log_marginal: -12123.187417527784\n",
      "Train Epoch: 3288 [256/118836 (0%)] Loss: 12344.099609\n",
      "Train Epoch: 3288 [33024/118836 (28%)] Loss: 12232.507812\n",
      "Train Epoch: 3288 [65792/118836 (55%)] Loss: 12315.678711\n",
      "Train Epoch: 3288 [98560/118836 (83%)] Loss: 12219.206055\n",
      "    epoch          : 3288\n",
      "    loss           : 12198.248256403795\n",
      "    val_loss       : 12198.997964076058\n",
      "    val_log_likelihood: -12116.475198381926\n",
      "    val_log_marginal: -12125.291096553778\n",
      "Train Epoch: 3289 [256/118836 (0%)] Loss: 12283.525391\n",
      "Train Epoch: 3289 [33024/118836 (28%)] Loss: 12158.568359\n",
      "Train Epoch: 3289 [65792/118836 (55%)] Loss: 12312.383789\n",
      "Train Epoch: 3289 [98560/118836 (83%)] Loss: 12241.429688\n",
      "    epoch          : 3289\n",
      "    loss           : 12197.73838092561\n",
      "    val_loss       : 12197.62765459046\n",
      "    val_log_likelihood: -12119.96773821986\n",
      "    val_log_marginal: -12128.848567539642\n",
      "Train Epoch: 3290 [256/118836 (0%)] Loss: 12226.611328\n",
      "Train Epoch: 3290 [33024/118836 (28%)] Loss: 12261.257812\n",
      "Train Epoch: 3290 [65792/118836 (55%)] Loss: 12174.846680\n",
      "Train Epoch: 3290 [98560/118836 (83%)] Loss: 12272.111328\n",
      "    epoch          : 3290\n",
      "    loss           : 12197.59946123475\n",
      "    val_loss       : 12203.266897906211\n",
      "    val_log_likelihood: -12117.955265521608\n",
      "    val_log_marginal: -12126.899300516063\n",
      "Train Epoch: 3291 [256/118836 (0%)] Loss: 12344.948242\n",
      "Train Epoch: 3291 [33024/118836 (28%)] Loss: 12240.481445\n",
      "Train Epoch: 3291 [65792/118836 (55%)] Loss: 12246.311523\n",
      "Train Epoch: 3291 [98560/118836 (83%)] Loss: 12238.054688\n",
      "    epoch          : 3291\n",
      "    loss           : 12198.506761140405\n",
      "    val_loss       : 12195.543371534612\n",
      "    val_log_likelihood: -12114.926261857683\n",
      "    val_log_marginal: -12123.778205589902\n",
      "Train Epoch: 3292 [256/118836 (0%)] Loss: 12295.282227\n",
      "Train Epoch: 3292 [33024/118836 (28%)] Loss: 12237.103516\n",
      "Train Epoch: 3292 [65792/118836 (55%)] Loss: 12175.279297\n",
      "Train Epoch: 3292 [98560/118836 (83%)] Loss: 12181.550781\n",
      "    epoch          : 3292\n",
      "    loss           : 12196.202608043839\n",
      "    val_loss       : 12196.997245642437\n",
      "    val_log_likelihood: -12111.461540077025\n",
      "    val_log_marginal: -12120.31451980968\n",
      "Train Epoch: 3293 [256/118836 (0%)] Loss: 12272.664062\n",
      "Train Epoch: 3293 [33024/118836 (28%)] Loss: 12201.867188\n",
      "Train Epoch: 3293 [65792/118836 (55%)] Loss: 12196.300781\n",
      "Train Epoch: 3293 [98560/118836 (83%)] Loss: 12331.841797\n",
      "    epoch          : 3293\n",
      "    loss           : 12199.962443134822\n",
      "    val_loss       : 12199.943757430152\n",
      "    val_log_likelihood: -12116.004600748294\n",
      "    val_log_marginal: -12124.739257684441\n",
      "Train Epoch: 3294 [256/118836 (0%)] Loss: 12219.163086\n",
      "Train Epoch: 3294 [33024/118836 (28%)] Loss: 12332.906250\n",
      "Train Epoch: 3294 [65792/118836 (55%)] Loss: 12251.251953\n",
      "Train Epoch: 3294 [98560/118836 (83%)] Loss: 12201.014648\n",
      "    epoch          : 3294\n",
      "    loss           : 12198.715385423127\n",
      "    val_loss       : 12196.823591680884\n",
      "    val_log_likelihood: -12114.397849300816\n",
      "    val_log_marginal: -12123.403465513\n",
      "Train Epoch: 3295 [256/118836 (0%)] Loss: 12317.420898\n",
      "Train Epoch: 3295 [33024/118836 (28%)] Loss: 12182.518555\n",
      "Train Epoch: 3295 [65792/118836 (55%)] Loss: 12162.721680\n",
      "Train Epoch: 3295 [98560/118836 (83%)] Loss: 12201.405273\n",
      "    epoch          : 3295\n",
      "    loss           : 12197.518634007962\n",
      "    val_loss       : 12194.752623557382\n",
      "    val_log_likelihood: -12114.718347905036\n",
      "    val_log_marginal: -12123.525895028564\n",
      "Train Epoch: 3296 [256/118836 (0%)] Loss: 12240.488281\n",
      "Train Epoch: 3296 [33024/118836 (28%)] Loss: 12223.627930\n",
      "Train Epoch: 3296 [65792/118836 (55%)] Loss: 12253.318359\n",
      "Train Epoch: 3296 [98560/118836 (83%)] Loss: 12080.843750\n",
      "    epoch          : 3296\n",
      "    loss           : 12197.544960323616\n",
      "    val_loss       : 12200.610098721614\n",
      "    val_log_likelihood: -12111.621827181554\n",
      "    val_log_marginal: -12120.444563077128\n",
      "Train Epoch: 3297 [256/118836 (0%)] Loss: 12225.152344\n",
      "Train Epoch: 3297 [33024/118836 (28%)] Loss: 12195.810547\n",
      "Train Epoch: 3297 [65792/118836 (55%)] Loss: 12166.771484\n",
      "Train Epoch: 3297 [98560/118836 (83%)] Loss: 12242.894531\n",
      "    epoch          : 3297\n",
      "    loss           : 12201.024149607114\n",
      "    val_loss       : 12199.655092437426\n",
      "    val_log_likelihood: -12117.425583029622\n",
      "    val_log_marginal: -12126.21078575131\n",
      "Train Epoch: 3298 [256/118836 (0%)] Loss: 12197.966797\n",
      "Train Epoch: 3298 [33024/118836 (28%)] Loss: 12289.123047\n",
      "Train Epoch: 3298 [65792/118836 (55%)] Loss: 12198.711914\n",
      "Train Epoch: 3298 [98560/118836 (83%)] Loss: 12158.605469\n",
      "    epoch          : 3298\n",
      "    loss           : 12198.886753482993\n",
      "    val_loss       : 12198.991997676068\n",
      "    val_log_likelihood: -12118.149715512562\n",
      "    val_log_marginal: -12127.005581234365\n",
      "Train Epoch: 3299 [256/118836 (0%)] Loss: 12131.634766\n",
      "Train Epoch: 3299 [33024/118836 (28%)] Loss: 12247.544922\n",
      "Train Epoch: 3299 [65792/118836 (55%)] Loss: 12208.396484\n",
      "Train Epoch: 3299 [98560/118836 (83%)] Loss: 12227.421875\n",
      "    epoch          : 3299\n",
      "    loss           : 12202.906130938534\n",
      "    val_loss       : 12196.55603403083\n",
      "    val_log_likelihood: -12112.356655810587\n",
      "    val_log_marginal: -12121.172131168085\n",
      "Train Epoch: 3300 [256/118836 (0%)] Loss: 12208.379883\n",
      "Train Epoch: 3300 [33024/118836 (28%)] Loss: 12179.548828\n",
      "Train Epoch: 3300 [65792/118836 (55%)] Loss: 12305.201172\n",
      "Train Epoch: 3300 [98560/118836 (83%)] Loss: 12159.608398\n",
      "    epoch          : 3300\n",
      "    loss           : 12196.90660282258\n",
      "    val_loss       : 12197.230564232248\n",
      "    val_log_likelihood: -12118.655604289444\n",
      "    val_log_marginal: -12127.492988206468\n",
      "Saving checkpoint: saved/models/SelfiesAutoencodingOperad/0905_154251/checkpoint-epoch3300.pth ...\n",
      "Train Epoch: 3301 [256/118836 (0%)] Loss: 12370.720703\n",
      "Train Epoch: 3301 [33024/118836 (28%)] Loss: 12153.728516\n",
      "Train Epoch: 3301 [65792/118836 (55%)] Loss: 12168.216797\n",
      "Train Epoch: 3301 [98560/118836 (83%)] Loss: 12265.673828\n",
      "    epoch          : 3301\n",
      "    loss           : 12197.81210679022\n",
      "    val_loss       : 12195.337451698242\n",
      "    val_log_likelihood: -12113.95121500853\n",
      "    val_log_marginal: -12122.797010316419\n",
      "Train Epoch: 3302 [256/118836 (0%)] Loss: 12343.472656\n",
      "Train Epoch: 3302 [33024/118836 (28%)] Loss: 12340.367188\n",
      "Train Epoch: 3302 [65792/118836 (55%)] Loss: 12250.093750\n",
      "Train Epoch: 3302 [98560/118836 (83%)] Loss: 12285.849609\n",
      "    epoch          : 3302\n",
      "    loss           : 12192.989485273212\n",
      "    val_loss       : 12201.095946078769\n",
      "    val_log_likelihood: -12116.158042545492\n",
      "    val_log_marginal: -12124.983514843962\n",
      "Train Epoch: 3303 [256/118836 (0%)] Loss: 12157.824219\n",
      "Train Epoch: 3303 [33024/118836 (28%)] Loss: 12171.764648\n",
      "Train Epoch: 3303 [65792/118836 (55%)] Loss: 12187.086914\n",
      "Train Epoch: 3303 [98560/118836 (83%)] Loss: 12166.490234\n",
      "    epoch          : 3303\n",
      "    loss           : 12194.044634318136\n",
      "    val_loss       : 12193.037898835526\n",
      "    val_log_likelihood: -12112.242077323719\n",
      "    val_log_marginal: -12120.950177080113\n",
      "Train Epoch: 3304 [256/118836 (0%)] Loss: 12189.544922\n",
      "Train Epoch: 3304 [33024/118836 (28%)] Loss: 12265.199219\n",
      "Train Epoch: 3304 [65792/118836 (55%)] Loss: 12147.669922\n",
      "Train Epoch: 3304 [98560/118836 (83%)] Loss: 12220.576172\n",
      "    epoch          : 3304\n",
      "    loss           : 12192.841171519593\n",
      "    val_loss       : 12198.747019655124\n",
      "    val_log_likelihood: -12115.0890694466\n",
      "    val_log_marginal: -12123.905503595035\n",
      "Train Epoch: 3305 [256/118836 (0%)] Loss: 12131.076172\n",
      "Train Epoch: 3305 [33024/118836 (28%)] Loss: 12207.847656\n",
      "Train Epoch: 3305 [65792/118836 (55%)] Loss: 12260.785156\n",
      "Train Epoch: 3305 [98560/118836 (83%)] Loss: 12297.915039\n",
      "    epoch          : 3305\n",
      "    loss           : 12195.85015234052\n",
      "    val_loss       : 12197.337009135086\n",
      "    val_log_likelihood: -12112.484764655708\n",
      "    val_log_marginal: -12121.120455427392\n",
      "Train Epoch: 3306 [256/118836 (0%)] Loss: 12136.306641\n",
      "Train Epoch: 3306 [33024/118836 (28%)] Loss: 12254.875000\n",
      "Train Epoch: 3306 [65792/118836 (55%)] Loss: 12269.564453\n",
      "Train Epoch: 3306 [98560/118836 (83%)] Loss: 12183.477539\n",
      "    epoch          : 3306\n",
      "    loss           : 12194.852033091656\n",
      "    val_loss       : 12197.074207447076\n",
      "    val_log_likelihood: -12116.755957596672\n",
      "    val_log_marginal: -12125.636486669066\n",
      "Train Epoch: 3307 [256/118836 (0%)] Loss: 12161.212891\n",
      "Train Epoch: 3307 [33024/118836 (28%)] Loss: 12242.890625\n",
      "Train Epoch: 3307 [65792/118836 (55%)] Loss: 12180.132812\n",
      "Train Epoch: 3307 [98560/118836 (83%)] Loss: 12188.862305\n",
      "    epoch          : 3307\n",
      "    loss           : 12194.679615126137\n",
      "    val_loss       : 12194.807220001649\n",
      "    val_log_likelihood: -12110.56145057899\n",
      "    val_log_marginal: -12119.271313911653\n",
      "Train Epoch: 3308 [256/118836 (0%)] Loss: 12153.016602\n",
      "Train Epoch: 3308 [33024/118836 (28%)] Loss: 12339.101562\n",
      "Train Epoch: 3308 [65792/118836 (55%)] Loss: 12280.971680\n",
      "Train Epoch: 3308 [98560/118836 (83%)] Loss: 12289.277344\n",
      "    epoch          : 3308\n",
      "    loss           : 12196.32477496252\n",
      "    val_loss       : 12195.173325474272\n",
      "    val_log_likelihood: -12113.18669435613\n",
      "    val_log_marginal: -12121.984637649732\n",
      "Train Epoch: 3309 [256/118836 (0%)] Loss: 12235.502930\n",
      "Train Epoch: 3309 [33024/118836 (28%)] Loss: 12180.677734\n",
      "Train Epoch: 3309 [65792/118836 (55%)] Loss: 12280.302734\n",
      "Train Epoch: 3309 [98560/118836 (83%)] Loss: 12129.234375\n",
      "    epoch          : 3309\n",
      "    loss           : 12195.532422521195\n",
      "    val_loss       : 12196.604918787998\n",
      "    val_log_likelihood: -12113.420298606803\n",
      "    val_log_marginal: -12122.263473944953\n",
      "Train Epoch: 3310 [256/118836 (0%)] Loss: 12242.373047\n",
      "Train Epoch: 3310 [33024/118836 (28%)] Loss: 12259.006836\n",
      "Train Epoch: 3310 [65792/118836 (55%)] Loss: 12217.847656\n",
      "Train Epoch: 3310 [98560/118836 (83%)] Loss: 12196.508789\n",
      "    epoch          : 3310\n",
      "    loss           : 12192.830622221361\n",
      "    val_loss       : 12198.935082046295\n",
      "    val_log_likelihood: -12111.672598738627\n",
      "    val_log_marginal: -12120.360693436263\n",
      "Train Epoch: 3311 [256/118836 (0%)] Loss: 12200.528320\n",
      "Train Epoch: 3311 [33024/118836 (28%)] Loss: 12233.882812\n",
      "Train Epoch: 3311 [65792/118836 (55%)] Loss: 12243.861328\n",
      "Train Epoch: 3311 [98560/118836 (83%)] Loss: 12295.123047\n",
      "    epoch          : 3311\n",
      "    loss           : 12193.463718077957\n",
      "    val_loss       : 12196.383805149735\n",
      "    val_log_likelihood: -12115.511946049162\n",
      "    val_log_marginal: -12124.170696629373\n",
      "Train Epoch: 3312 [256/118836 (0%)] Loss: 12235.683594\n",
      "Train Epoch: 3312 [33024/118836 (28%)] Loss: 12207.702148\n",
      "Train Epoch: 3312 [65792/118836 (55%)] Loss: 12168.770508\n",
      "Train Epoch: 3312 [98560/118836 (83%)] Loss: 12219.208984\n",
      "    epoch          : 3312\n",
      "    loss           : 12193.00031243538\n",
      "    val_loss       : 12198.608637618572\n",
      "    val_log_likelihood: -12116.168094111868\n",
      "    val_log_marginal: -12124.907557471104\n",
      "Train Epoch: 3313 [256/118836 (0%)] Loss: 12303.943359\n",
      "Train Epoch: 3313 [33024/118836 (28%)] Loss: 12243.326172\n",
      "Train Epoch: 3313 [65792/118836 (55%)] Loss: 12201.060547\n",
      "Train Epoch: 3313 [98560/118836 (83%)] Loss: 12320.521484\n",
      "    epoch          : 3313\n",
      "    loss           : 12199.101315976532\n",
      "    val_loss       : 12197.698547335007\n",
      "    val_log_likelihood: -12112.278788157826\n",
      "    val_log_marginal: -12121.14159970449\n",
      "Train Epoch: 3314 [256/118836 (0%)] Loss: 12157.571289\n",
      "Train Epoch: 3314 [33024/118836 (28%)] Loss: 12201.510742\n",
      "Train Epoch: 3314 [65792/118836 (55%)] Loss: 12250.714844\n",
      "Train Epoch: 3314 [98560/118836 (83%)] Loss: 12221.628906\n",
      "    epoch          : 3314\n",
      "    loss           : 12196.176222924421\n",
      "    val_loss       : 12195.759901609128\n",
      "    val_log_likelihood: -12111.039518390717\n",
      "    val_log_marginal: -12119.80170862205\n",
      "Train Epoch: 3315 [256/118836 (0%)] Loss: 12223.783203\n",
      "Train Epoch: 3315 [33024/118836 (28%)] Loss: 12200.240234\n",
      "Train Epoch: 3315 [65792/118836 (55%)] Loss: 12250.080078\n",
      "Train Epoch: 3315 [98560/118836 (83%)] Loss: 12236.240234\n",
      "    epoch          : 3315\n",
      "    loss           : 12197.158703280085\n",
      "    val_loss       : 12196.254538651905\n",
      "    val_log_likelihood: -12112.234365468621\n",
      "    val_log_marginal: -12120.921139380542\n",
      "Train Epoch: 3316 [256/118836 (0%)] Loss: 12223.839844\n",
      "Train Epoch: 3316 [33024/118836 (28%)] Loss: 12136.164062\n",
      "Train Epoch: 3316 [65792/118836 (55%)] Loss: 12200.879883\n",
      "Train Epoch: 3316 [98560/118836 (83%)] Loss: 12198.895508\n",
      "    epoch          : 3316\n",
      "    loss           : 12198.051175752173\n",
      "    val_loss       : 12195.416503213522\n",
      "    val_log_likelihood: -12116.662443134821\n",
      "    val_log_marginal: -12125.397571088011\n",
      "Train Epoch: 3317 [256/118836 (0%)] Loss: 12270.616211\n",
      "Train Epoch: 3317 [33024/118836 (28%)] Loss: 12147.232422\n",
      "Train Epoch: 3317 [65792/118836 (55%)] Loss: 12358.761719\n",
      "Train Epoch: 3317 [98560/118836 (83%)] Loss: 12209.481445\n",
      "    epoch          : 3317\n",
      "    loss           : 12197.211645891492\n",
      "    val_loss       : 12194.738268827865\n",
      "    val_log_likelihood: -12113.779642104786\n",
      "    val_log_marginal: -12122.511633154289\n",
      "Train Epoch: 3318 [256/118836 (0%)] Loss: 12166.414062\n",
      "Train Epoch: 3318 [33024/118836 (28%)] Loss: 12165.518555\n",
      "Train Epoch: 3318 [65792/118836 (55%)] Loss: 12204.815430\n",
      "Train Epoch: 3318 [98560/118836 (83%)] Loss: 12222.198242\n",
      "    epoch          : 3318\n",
      "    loss           : 12197.472792758737\n",
      "    val_loss       : 12204.135623002689\n",
      "    val_log_likelihood: -12118.880381998293\n",
      "    val_log_marginal: -12127.799738260012\n",
      "Train Epoch: 3319 [256/118836 (0%)] Loss: 12261.442383\n",
      "Train Epoch: 3319 [33024/118836 (28%)] Loss: 12205.234375\n",
      "Train Epoch: 3319 [65792/118836 (55%)] Loss: 12247.176758\n",
      "Train Epoch: 3319 [98560/118836 (83%)] Loss: 12270.818359\n",
      "    epoch          : 3319\n",
      "    loss           : 12199.13626899814\n",
      "    val_loss       : 12196.358497193556\n",
      "    val_log_likelihood: -12116.945981312034\n",
      "    val_log_marginal: -12125.930799289848\n",
      "Train Epoch: 3320 [256/118836 (0%)] Loss: 12140.205078\n",
      "Train Epoch: 3320 [33024/118836 (28%)] Loss: 12268.474609\n",
      "Train Epoch: 3320 [65792/118836 (55%)] Loss: 12171.447266\n",
      "Train Epoch: 3320 [98560/118836 (83%)] Loss: 12203.898438\n",
      "    epoch          : 3320\n",
      "    loss           : 12198.316302535672\n",
      "    val_loss       : 12197.819767881554\n",
      "    val_log_likelihood: -12112.849324079818\n",
      "    val_log_marginal: -12121.82607133675\n",
      "Train Epoch: 3321 [256/118836 (0%)] Loss: 12161.736328\n",
      "Train Epoch: 3321 [33024/118836 (28%)] Loss: 12262.386719\n",
      "Train Epoch: 3321 [65792/118836 (55%)] Loss: 12102.583984\n",
      "Train Epoch: 3321 [98560/118836 (83%)] Loss: 12178.862305\n",
      "    epoch          : 3321\n",
      "    loss           : 12198.261273036858\n",
      "    val_loss       : 12195.971233123959\n",
      "    val_log_likelihood: -12117.82094173258\n",
      "    val_log_marginal: -12126.50409528723\n",
      "Train Epoch: 3322 [256/118836 (0%)] Loss: 12186.104492\n",
      "Train Epoch: 3322 [33024/118836 (28%)] Loss: 12181.017578\n",
      "Train Epoch: 3322 [65792/118836 (55%)] Loss: 12286.587891\n",
      "Train Epoch: 3322 [98560/118836 (83%)] Loss: 12232.841797\n",
      "    epoch          : 3322\n",
      "    loss           : 12194.907365494468\n",
      "    val_loss       : 12194.821079070422\n",
      "    val_log_likelihood: -12116.794247731856\n",
      "    val_log_marginal: -12125.770815894504\n",
      "Train Epoch: 3323 [256/118836 (0%)] Loss: 12193.794922\n",
      "Train Epoch: 3323 [33024/118836 (28%)] Loss: 12186.982422\n",
      "Train Epoch: 3323 [65792/118836 (55%)] Loss: 12301.212891\n",
      "Train Epoch: 3323 [98560/118836 (83%)] Loss: 12171.075195\n",
      "    epoch          : 3323\n",
      "    loss           : 12204.203359407311\n",
      "    val_loss       : 12196.424550899052\n",
      "    val_log_likelihood: -12113.815206427056\n",
      "    val_log_marginal: -12122.733512992354\n",
      "Train Epoch: 3324 [256/118836 (0%)] Loss: 12224.386719\n",
      "Train Epoch: 3324 [33024/118836 (28%)] Loss: 12245.338867\n",
      "Train Epoch: 3324 [65792/118836 (55%)] Loss: 12221.809570\n",
      "Train Epoch: 3324 [98560/118836 (83%)] Loss: 12239.851562\n",
      "    epoch          : 3324\n",
      "    loss           : 12194.775692721258\n",
      "    val_loss       : 12198.474780943992\n",
      "    val_log_likelihood: -12110.022876925663\n",
      "    val_log_marginal: -12118.843072203232\n",
      "Train Epoch: 3325 [256/118836 (0%)] Loss: 12139.786133\n",
      "Train Epoch: 3325 [33024/118836 (28%)] Loss: 12197.955078\n",
      "Train Epoch: 3325 [65792/118836 (55%)] Loss: 12171.111328\n",
      "Train Epoch: 3325 [98560/118836 (83%)] Loss: 12283.093750\n",
      "    epoch          : 3325\n",
      "    loss           : 12198.387768817205\n",
      "    val_loss       : 12193.116399781245\n",
      "    val_log_likelihood: -12117.529739841812\n",
      "    val_log_marginal: -12126.177899840564\n",
      "Train Epoch: 3326 [256/118836 (0%)] Loss: 12118.215820\n",
      "Train Epoch: 3326 [33024/118836 (28%)] Loss: 12201.573242\n",
      "Train Epoch: 3326 [65792/118836 (55%)] Loss: 12125.492188\n",
      "Train Epoch: 3326 [98560/118836 (83%)] Loss: 12230.480469\n",
      "    epoch          : 3326\n",
      "    loss           : 12196.342375865901\n",
      "    val_loss       : 12195.920052293728\n",
      "    val_log_likelihood: -12116.10128221283\n",
      "    val_log_marginal: -12124.874411996045\n",
      "Train Epoch: 3327 [256/118836 (0%)] Loss: 12191.993164\n",
      "Train Epoch: 3327 [33024/118836 (28%)] Loss: 12195.386719\n",
      "Train Epoch: 3327 [65792/118836 (55%)] Loss: 12236.631836\n",
      "Train Epoch: 3327 [98560/118836 (83%)] Loss: 12172.768555\n",
      "    epoch          : 3327\n",
      "    loss           : 12193.052978636788\n",
      "    val_loss       : 12196.395978012968\n",
      "    val_log_likelihood: -12115.084702459419\n",
      "    val_log_marginal: -12123.749497971396\n",
      "Train Epoch: 3328 [256/118836 (0%)] Loss: 12265.812500\n",
      "Train Epoch: 3328 [33024/118836 (28%)] Loss: 12256.734375\n",
      "Train Epoch: 3328 [65792/118836 (55%)] Loss: 12245.794922\n",
      "Train Epoch: 3328 [98560/118836 (83%)] Loss: 12246.424805\n",
      "    epoch          : 3328\n",
      "    loss           : 12195.774383206679\n",
      "    val_loss       : 12194.331665110969\n",
      "    val_log_likelihood: -12111.109610376603\n",
      "    val_log_marginal: -12119.833866682493\n",
      "Train Epoch: 3329 [256/118836 (0%)] Loss: 12313.792969\n",
      "Train Epoch: 3329 [33024/118836 (28%)] Loss: 12302.722656\n",
      "Train Epoch: 3329 [65792/118836 (55%)] Loss: 12282.645508\n",
      "Train Epoch: 3329 [98560/118836 (83%)] Loss: 12198.603516\n",
      "    epoch          : 3329\n",
      "    loss           : 12197.396018468258\n",
      "    val_loss       : 12197.721313033138\n",
      "    val_log_likelihood: -12113.602006597654\n",
      "    val_log_marginal: -12122.424466249568\n",
      "Train Epoch: 3330 [256/118836 (0%)] Loss: 12319.154297\n",
      "Train Epoch: 3330 [33024/118836 (28%)] Loss: 12205.168945\n",
      "Train Epoch: 3330 [65792/118836 (55%)] Loss: 12223.277344\n",
      "Train Epoch: 3330 [98560/118836 (83%)] Loss: 12253.119141\n",
      "    epoch          : 3330\n",
      "    loss           : 12196.818039508375\n",
      "    val_loss       : 12195.111482046086\n",
      "    val_log_likelihood: -12113.592430146298\n",
      "    val_log_marginal: -12122.37467788756\n",
      "Train Epoch: 3331 [256/118836 (0%)] Loss: 12177.686523\n",
      "Train Epoch: 3331 [33024/118836 (28%)] Loss: 12184.825195\n",
      "Train Epoch: 3331 [65792/118836 (55%)] Loss: 12206.701172\n",
      "Train Epoch: 3331 [98560/118836 (83%)] Loss: 12163.465820\n",
      "    epoch          : 3331\n",
      "    loss           : 12199.919404918839\n",
      "    val_loss       : 12196.323043705639\n",
      "    val_log_likelihood: -12117.123982565654\n",
      "    val_log_marginal: -12125.970098944812\n",
      "Train Epoch: 3332 [256/118836 (0%)] Loss: 12245.492188\n",
      "Train Epoch: 3332 [33024/118836 (28%)] Loss: 12300.740234\n",
      "Train Epoch: 3332 [65792/118836 (55%)] Loss: 12236.168945\n",
      "Train Epoch: 3332 [98560/118836 (83%)] Loss: 12152.849609\n",
      "    epoch          : 3332\n",
      "    loss           : 12196.265453273625\n",
      "    val_loss       : 12198.887327980416\n",
      "    val_log_likelihood: -12113.732444491832\n",
      "    val_log_marginal: -12122.492151154138\n",
      "Train Epoch: 3333 [256/118836 (0%)] Loss: 12147.018555\n",
      "Train Epoch: 3333 [33024/118836 (28%)] Loss: 12276.685547\n",
      "Train Epoch: 3333 [65792/118836 (55%)] Loss: 12160.201172\n",
      "Train Epoch: 3333 [98560/118836 (83%)] Loss: 12200.880859\n",
      "    epoch          : 3333\n",
      "    loss           : 12195.359735092276\n",
      "    val_loss       : 12198.81539676431\n",
      "    val_log_likelihood: -12115.542674569633\n",
      "    val_log_marginal: -12124.540192712015\n",
      "Train Epoch: 3334 [256/118836 (0%)] Loss: 12207.500000\n",
      "Train Epoch: 3334 [33024/118836 (28%)] Loss: 12161.601562\n",
      "Train Epoch: 3334 [65792/118836 (55%)] Loss: 12242.766602\n",
      "Train Epoch: 3334 [98560/118836 (83%)] Loss: 12215.701172\n",
      "    epoch          : 3334\n",
      "    loss           : 12197.042931916872\n",
      "    val_loss       : 12191.77284483474\n",
      "    val_log_likelihood: -12114.03945554823\n",
      "    val_log_marginal: -12122.675729142098\n",
      "Train Epoch: 3335 [256/118836 (0%)] Loss: 12260.520508\n",
      "Train Epoch: 3335 [33024/118836 (28%)] Loss: 12347.405273\n",
      "Train Epoch: 3335 [65792/118836 (55%)] Loss: 12256.386719\n",
      "Train Epoch: 3335 [98560/118836 (83%)] Loss: 12316.287109\n",
      "    epoch          : 3335\n",
      "    loss           : 12199.680659862232\n",
      "    val_loss       : 12213.332336079004\n",
      "    val_log_likelihood: -12116.426516458592\n",
      "    val_log_marginal: -12125.298834827225\n",
      "Train Epoch: 3336 [256/118836 (0%)] Loss: 12311.345703\n",
      "Train Epoch: 3336 [33024/118836 (28%)] Loss: 12207.088867\n",
      "Train Epoch: 3336 [65792/118836 (55%)] Loss: 12258.074219\n",
      "Train Epoch: 3336 [98560/118836 (83%)] Loss: 12204.904297\n",
      "    epoch          : 3336\n",
      "    loss           : 12200.597571759978\n",
      "    val_loss       : 12198.531293589827\n",
      "    val_log_likelihood: -12118.996538493848\n",
      "    val_log_marginal: -12127.846674492337\n",
      "Train Epoch: 3337 [256/118836 (0%)] Loss: 12194.210938\n",
      "Train Epoch: 3337 [33024/118836 (28%)] Loss: 12224.529297\n",
      "Train Epoch: 3337 [65792/118836 (55%)] Loss: 12174.449219\n",
      "Train Epoch: 3337 [98560/118836 (83%)] Loss: 12235.694336\n",
      "    epoch          : 3337\n",
      "    loss           : 12194.614861843467\n",
      "    val_loss       : 12198.449080033344\n",
      "    val_log_likelihood: -12114.85137268016\n",
      "    val_log_marginal: -12123.70533496906\n",
      "Train Epoch: 3338 [256/118836 (0%)] Loss: 12358.100586\n",
      "Train Epoch: 3338 [33024/118836 (28%)] Loss: 12246.185547\n",
      "Train Epoch: 3338 [65792/118836 (55%)] Loss: 12158.333984\n",
      "Train Epoch: 3338 [98560/118836 (83%)] Loss: 12260.833984\n",
      "    epoch          : 3338\n",
      "    loss           : 12197.156163248294\n",
      "    val_loss       : 12196.68798054717\n",
      "    val_log_likelihood: -12114.942881352097\n",
      "    val_log_marginal: -12123.834304435253\n",
      "Train Epoch: 3339 [256/118836 (0%)] Loss: 12258.083008\n",
      "Train Epoch: 3339 [33024/118836 (28%)] Loss: 12211.660156\n",
      "Train Epoch: 3339 [65792/118836 (55%)] Loss: 12253.011719\n",
      "Train Epoch: 3339 [98560/118836 (83%)] Loss: 12220.930664\n",
      "    epoch          : 3339\n",
      "    loss           : 12194.709182595378\n",
      "    val_loss       : 12198.53616793245\n",
      "    val_log_likelihood: -12113.6255859375\n",
      "    val_log_marginal: -12122.535746660544\n",
      "Train Epoch: 3340 [256/118836 (0%)] Loss: 12203.360352\n",
      "Train Epoch: 3340 [33024/118836 (28%)] Loss: 12129.051758\n",
      "Train Epoch: 3340 [65792/118836 (55%)] Loss: 12262.473633\n",
      "Train Epoch: 3340 [98560/118836 (83%)] Loss: 12172.877930\n",
      "    epoch          : 3340\n",
      "    loss           : 12192.420266458592\n",
      "    val_loss       : 12193.552321648582\n",
      "    val_log_likelihood: -12115.867554700424\n",
      "    val_log_marginal: -12124.650846149192\n",
      "Train Epoch: 3341 [256/118836 (0%)] Loss: 12127.976562\n",
      "Train Epoch: 3341 [33024/118836 (28%)] Loss: 12274.322266\n",
      "Train Epoch: 3341 [65792/118836 (55%)] Loss: 12235.158203\n",
      "Train Epoch: 3341 [98560/118836 (83%)] Loss: 12341.378906\n",
      "    epoch          : 3341\n",
      "    loss           : 12196.952536639268\n",
      "    val_loss       : 12197.437090192272\n",
      "    val_log_likelihood: -12117.260146233974\n",
      "    val_log_marginal: -12126.310158392755\n",
      "Train Epoch: 3342 [256/118836 (0%)] Loss: 12211.010742\n",
      "Train Epoch: 3342 [33024/118836 (28%)] Loss: 12169.651367\n",
      "Train Epoch: 3342 [65792/118836 (55%)] Loss: 12230.388672\n",
      "Train Epoch: 3342 [98560/118836 (83%)] Loss: 12287.575195\n",
      "    epoch          : 3342\n",
      "    loss           : 12198.37564247958\n",
      "    val_loss       : 12195.662326117445\n",
      "    val_log_likelihood: -12115.542981512355\n",
      "    val_log_marginal: -12124.457917865782\n",
      "Train Epoch: 3343 [256/118836 (0%)] Loss: 12244.261719\n",
      "Train Epoch: 3343 [33024/118836 (28%)] Loss: 12239.765625\n",
      "Train Epoch: 3343 [65792/118836 (55%)] Loss: 12176.571289\n",
      "Train Epoch: 3343 [98560/118836 (83%)] Loss: 12197.224609\n",
      "    epoch          : 3343\n",
      "    loss           : 12197.883611520369\n",
      "    val_loss       : 12199.483072391416\n",
      "    val_log_likelihood: -12116.017245819117\n",
      "    val_log_marginal: -12124.758852490673\n",
      "Train Epoch: 3344 [256/118836 (0%)] Loss: 12202.238281\n",
      "Train Epoch: 3344 [33024/118836 (28%)] Loss: 12227.242188\n",
      "Train Epoch: 3344 [65792/118836 (55%)] Loss: 12232.262695\n",
      "Train Epoch: 3344 [98560/118836 (83%)] Loss: 12132.176758\n",
      "    epoch          : 3344\n",
      "    loss           : 12197.204979418682\n",
      "    val_loss       : 12196.553645964517\n",
      "    val_log_likelihood: -12111.208517498966\n",
      "    val_log_marginal: -12120.040249352218\n",
      "Train Epoch: 3345 [256/118836 (0%)] Loss: 12272.099609\n",
      "Train Epoch: 3345 [33024/118836 (28%)] Loss: 12147.027344\n",
      "Train Epoch: 3345 [65792/118836 (55%)] Loss: 12137.564453\n",
      "Train Epoch: 3345 [98560/118836 (83%)] Loss: 12175.601562\n",
      "    epoch          : 3345\n",
      "    loss           : 12198.025861055108\n",
      "    val_loss       : 12200.532473110974\n",
      "    val_log_likelihood: -12115.964519360008\n",
      "    val_log_marginal: -12125.067490926984\n",
      "Train Epoch: 3346 [256/118836 (0%)] Loss: 12241.894531\n",
      "Train Epoch: 3346 [33024/118836 (28%)] Loss: 12249.780273\n",
      "Train Epoch: 3346 [65792/118836 (55%)] Loss: 12162.506836\n",
      "Train Epoch: 3346 [98560/118836 (83%)] Loss: 12138.642578\n",
      "    epoch          : 3346\n",
      "    loss           : 12198.633544962262\n",
      "    val_loss       : 12196.934747098245\n",
      "    val_log_likelihood: -12114.952472827492\n",
      "    val_log_marginal: -12123.7766667262\n",
      "Train Epoch: 3347 [256/118836 (0%)] Loss: 12248.457031\n",
      "Train Epoch: 3347 [33024/118836 (28%)] Loss: 12196.807617\n",
      "Train Epoch: 3347 [65792/118836 (55%)] Loss: 12288.439453\n",
      "Train Epoch: 3347 [98560/118836 (83%)] Loss: 12275.892578\n",
      "    epoch          : 3347\n",
      "    loss           : 12195.260655758892\n",
      "    val_loss       : 12197.864784726518\n",
      "    val_log_likelihood: -12109.156742723842\n",
      "    val_log_marginal: -12118.122791756956\n",
      "Train Epoch: 3348 [256/118836 (0%)] Loss: 12243.037109\n",
      "Train Epoch: 3348 [33024/118836 (28%)] Loss: 12197.804688\n",
      "Train Epoch: 3348 [65792/118836 (55%)] Loss: 12129.099609\n",
      "Train Epoch: 3348 [98560/118836 (83%)] Loss: 12178.833984\n",
      "    epoch          : 3348\n",
      "    loss           : 12198.116002701097\n",
      "    val_loss       : 12198.04593743836\n",
      "    val_log_likelihood: -12114.407995211694\n",
      "    val_log_marginal: -12123.25196099557\n",
      "Train Epoch: 3349 [256/118836 (0%)] Loss: 12264.016602\n",
      "Train Epoch: 3349 [33024/118836 (28%)] Loss: 12213.819336\n",
      "Train Epoch: 3349 [65792/118836 (55%)] Loss: 12202.864258\n",
      "Train Epoch: 3349 [98560/118836 (83%)] Loss: 12169.402344\n",
      "    epoch          : 3349\n",
      "    loss           : 12196.723801630997\n",
      "    val_loss       : 12200.637982568633\n",
      "    val_log_likelihood: -12116.724982068083\n",
      "    val_log_marginal: -12125.723323660468\n",
      "Train Epoch: 3350 [256/118836 (0%)] Loss: 12276.583984\n",
      "Train Epoch: 3350 [33024/118836 (28%)] Loss: 12169.643555\n",
      "Train Epoch: 3350 [65792/118836 (55%)] Loss: 12203.749023\n",
      "Train Epoch: 3350 [98560/118836 (83%)] Loss: 12264.686523\n",
      "    epoch          : 3350\n",
      "    loss           : 12200.222173380635\n",
      "    val_loss       : 12192.708698238443\n",
      "    val_log_likelihood: -12112.299608567257\n",
      "    val_log_marginal: -12121.154139767666\n",
      "Train Epoch: 3351 [256/118836 (0%)] Loss: 12148.594727\n",
      "Train Epoch: 3351 [33024/118836 (28%)] Loss: 12196.115234\n",
      "Train Epoch: 3351 [65792/118836 (55%)] Loss: 12264.801758\n",
      "Train Epoch: 3351 [98560/118836 (83%)] Loss: 12197.460938\n",
      "    epoch          : 3351\n",
      "    loss           : 12197.554331123347\n",
      "    val_loss       : 12194.122328901069\n",
      "    val_log_likelihood: -12112.671678395109\n",
      "    val_log_marginal: -12121.473809014022\n",
      "Train Epoch: 3352 [256/118836 (0%)] Loss: 12215.447266\n",
      "Train Epoch: 3352 [33024/118836 (28%)] Loss: 12173.145508\n",
      "Train Epoch: 3352 [65792/118836 (55%)] Loss: 12162.640625\n",
      "Train Epoch: 3352 [98560/118836 (83%)] Loss: 12365.417969\n",
      "    epoch          : 3352\n",
      "    loss           : 12196.966066997518\n",
      "    val_loss       : 12196.841809279067\n",
      "    val_log_likelihood: -12113.734094551282\n",
      "    val_log_marginal: -12122.481978422313\n",
      "Train Epoch: 3353 [256/118836 (0%)] Loss: 12254.382812\n",
      "Train Epoch: 3353 [33024/118836 (28%)] Loss: 12186.316406\n",
      "Train Epoch: 3353 [65792/118836 (55%)] Loss: 12202.164062\n",
      "Train Epoch: 3353 [98560/118836 (83%)] Loss: 12291.673828\n",
      "    epoch          : 3353\n",
      "    loss           : 12199.121613937137\n",
      "    val_loss       : 12197.240630472194\n",
      "    val_log_likelihood: -12113.040139222756\n",
      "    val_log_marginal: -12121.979166802626\n",
      "Train Epoch: 3354 [256/118836 (0%)] Loss: 12177.031250\n",
      "Train Epoch: 3354 [33024/118836 (28%)] Loss: 12251.330078\n",
      "Train Epoch: 3354 [65792/118836 (55%)] Loss: 12285.787109\n",
      "Train Epoch: 3354 [98560/118836 (83%)] Loss: 12202.048828\n",
      "    epoch          : 3354\n",
      "    loss           : 12196.523224901779\n",
      "    val_loss       : 12203.722315009058\n",
      "    val_log_likelihood: -12117.761644276003\n",
      "    val_log_marginal: -12126.614695337388\n",
      "Train Epoch: 3355 [256/118836 (0%)] Loss: 12252.283203\n",
      "Train Epoch: 3355 [33024/118836 (28%)] Loss: 12311.710938\n",
      "Train Epoch: 3355 [65792/118836 (55%)] Loss: 12191.805664\n",
      "Train Epoch: 3355 [98560/118836 (83%)] Loss: 12241.130859\n",
      "    epoch          : 3355\n",
      "    loss           : 12199.484506662273\n",
      "    val_loss       : 12195.324188901512\n",
      "    val_log_likelihood: -12115.063140702545\n",
      "    val_log_marginal: -12124.160991918285\n",
      "Train Epoch: 3356 [256/118836 (0%)] Loss: 12165.919922\n",
      "Train Epoch: 3356 [33024/118836 (28%)] Loss: 12238.123047\n",
      "Train Epoch: 3356 [65792/118836 (55%)] Loss: 12280.771484\n",
      "Train Epoch: 3356 [98560/118836 (83%)] Loss: 12312.913086\n",
      "    epoch          : 3356\n",
      "    loss           : 12197.846952866523\n",
      "    val_loss       : 12196.220735272416\n",
      "    val_log_likelihood: -12113.5686020213\n",
      "    val_log_marginal: -12122.605674184528\n",
      "Train Epoch: 3357 [256/118836 (0%)] Loss: 12153.408203\n",
      "Train Epoch: 3357 [33024/118836 (28%)] Loss: 12314.287109\n",
      "Train Epoch: 3357 [65792/118836 (55%)] Loss: 12181.178711\n",
      "Train Epoch: 3357 [98560/118836 (83%)] Loss: 12218.872070\n",
      "    epoch          : 3357\n",
      "    loss           : 12197.132768881824\n",
      "    val_loss       : 12193.185835548034\n",
      "    val_log_likelihood: -12114.5720633659\n",
      "    val_log_marginal: -12123.613488278237\n",
      "Train Epoch: 3358 [256/118836 (0%)] Loss: 12174.959961\n",
      "Train Epoch: 3358 [33024/118836 (28%)] Loss: 12227.953125\n",
      "Train Epoch: 3358 [65792/118836 (55%)] Loss: 12252.469727\n",
      "Train Epoch: 3358 [98560/118836 (83%)] Loss: 12169.492188\n",
      "    epoch          : 3358\n",
      "    loss           : 12196.078866347447\n",
      "    val_loss       : 12195.084635989344\n",
      "    val_log_likelihood: -12114.141178143092\n",
      "    val_log_marginal: -12123.090511809567\n",
      "Train Epoch: 3359 [256/118836 (0%)] Loss: 12251.656250\n",
      "Train Epoch: 3359 [33024/118836 (28%)] Loss: 12209.315430\n",
      "Train Epoch: 3359 [65792/118836 (55%)] Loss: 12237.513672\n",
      "Train Epoch: 3359 [98560/118836 (83%)] Loss: 12283.821289\n",
      "    epoch          : 3359\n",
      "    loss           : 12194.04715657956\n",
      "    val_loss       : 12197.229000016392\n",
      "    val_log_likelihood: -12112.859201335039\n",
      "    val_log_marginal: -12121.802655495067\n",
      "Train Epoch: 3360 [256/118836 (0%)] Loss: 12202.198242\n",
      "Train Epoch: 3360 [33024/118836 (28%)] Loss: 12259.875000\n",
      "Train Epoch: 3360 [65792/118836 (55%)] Loss: 12263.489258\n",
      "Train Epoch: 3360 [98560/118836 (83%)] Loss: 12256.325195\n",
      "    epoch          : 3360\n",
      "    loss           : 12196.004106732062\n",
      "    val_loss       : 12195.257573730656\n",
      "    val_log_likelihood: -12115.044793120605\n",
      "    val_log_marginal: -12123.894533301316\n",
      "Train Epoch: 3361 [256/118836 (0%)] Loss: 12206.482422\n",
      "Train Epoch: 3361 [33024/118836 (28%)] Loss: 12341.881836\n",
      "Train Epoch: 3361 [65792/118836 (55%)] Loss: 12168.508789\n",
      "Train Epoch: 3361 [98560/118836 (83%)] Loss: 12221.502930\n",
      "    epoch          : 3361\n",
      "    loss           : 12192.330191047611\n",
      "    val_loss       : 12195.798759162983\n",
      "    val_log_likelihood: -12113.222700514372\n",
      "    val_log_marginal: -12122.079916902716\n",
      "Train Epoch: 3362 [256/118836 (0%)] Loss: 12184.197266\n",
      "Train Epoch: 3362 [33024/118836 (28%)] Loss: 12224.008789\n",
      "Train Epoch: 3362 [65792/118836 (55%)] Loss: 12165.326172\n",
      "Train Epoch: 3362 [98560/118836 (83%)] Loss: 12204.423828\n",
      "    epoch          : 3362\n",
      "    loss           : 12196.628601245864\n",
      "    val_loss       : 12194.283520833547\n",
      "    val_log_likelihood: -12116.69997156741\n",
      "    val_log_marginal: -12125.536566744016\n",
      "Train Epoch: 3363 [256/118836 (0%)] Loss: 12190.661133\n",
      "Train Epoch: 3363 [33024/118836 (28%)] Loss: 12144.822266\n",
      "Train Epoch: 3363 [65792/118836 (55%)] Loss: 12192.992188\n",
      "Train Epoch: 3363 [98560/118836 (83%)] Loss: 12155.511719\n",
      "    epoch          : 3363\n",
      "    loss           : 12200.988900143455\n",
      "    val_loss       : 12195.517893396061\n",
      "    val_log_likelihood: -12112.71342002042\n",
      "    val_log_marginal: -12121.629802664844\n",
      "Train Epoch: 3364 [256/118836 (0%)] Loss: 12219.643555\n",
      "Train Epoch: 3364 [33024/118836 (28%)] Loss: 12219.013672\n",
      "Train Epoch: 3364 [65792/118836 (55%)] Loss: 12273.035156\n",
      "Train Epoch: 3364 [98560/118836 (83%)] Loss: 12209.041016\n",
      "    epoch          : 3364\n",
      "    loss           : 12197.770891490902\n",
      "    val_loss       : 12196.74139245777\n",
      "    val_log_likelihood: -12112.350624063016\n",
      "    val_log_marginal: -12121.261423043921\n",
      "Train Epoch: 3365 [256/118836 (0%)] Loss: 12249.177734\n",
      "Train Epoch: 3365 [33024/118836 (28%)] Loss: 12243.736328\n",
      "Train Epoch: 3365 [65792/118836 (55%)] Loss: 12155.092773\n",
      "Train Epoch: 3365 [98560/118836 (83%)] Loss: 12238.636719\n",
      "    epoch          : 3365\n",
      "    loss           : 12192.446863691584\n",
      "    val_loss       : 12197.850118854674\n",
      "    val_log_likelihood: -12110.63186550093\n",
      "    val_log_marginal: -12119.42787074535\n",
      "Train Epoch: 3366 [256/118836 (0%)] Loss: 12171.425781\n",
      "Train Epoch: 3366 [33024/118836 (28%)] Loss: 12180.742188\n",
      "Train Epoch: 3366 [65792/118836 (55%)] Loss: 12143.156250\n",
      "Train Epoch: 3366 [98560/118836 (83%)] Loss: 12119.805664\n",
      "    epoch          : 3366\n",
      "    loss           : 12196.637980446134\n",
      "    val_loss       : 12195.663826856073\n",
      "    val_log_likelihood: -12115.546879200268\n",
      "    val_log_marginal: -12124.458687191516\n",
      "Train Epoch: 3367 [256/118836 (0%)] Loss: 12209.175781\n",
      "Train Epoch: 3367 [33024/118836 (28%)] Loss: 12215.906250\n",
      "Train Epoch: 3367 [65792/118836 (55%)] Loss: 12206.878906\n",
      "Train Epoch: 3367 [98560/118836 (83%)] Loss: 12155.650391\n",
      "    epoch          : 3367\n",
      "    loss           : 12195.25819375517\n",
      "    val_loss       : 12194.99586078261\n",
      "    val_log_likelihood: -12115.32816021764\n",
      "    val_log_marginal: -12123.977454599948\n",
      "Train Epoch: 3368 [256/118836 (0%)] Loss: 12214.613281\n",
      "Train Epoch: 3368 [33024/118836 (28%)] Loss: 12167.464844\n",
      "Train Epoch: 3368 [65792/118836 (55%)] Loss: 12195.589844\n",
      "Train Epoch: 3368 [98560/118836 (83%)] Loss: 12211.519531\n",
      "    epoch          : 3368\n",
      "    loss           : 12198.22595782284\n",
      "    val_loss       : 12196.795668377308\n",
      "    val_log_likelihood: -12115.956183118797\n",
      "    val_log_marginal: -12124.772184205374\n",
      "Train Epoch: 3369 [256/118836 (0%)] Loss: 12144.722656\n",
      "Train Epoch: 3369 [33024/118836 (28%)] Loss: 12250.236328\n",
      "Train Epoch: 3369 [65792/118836 (55%)] Loss: 12377.789062\n",
      "Train Epoch: 3369 [98560/118836 (83%)] Loss: 12243.158203\n",
      "    epoch          : 3369\n",
      "    loss           : 12193.547854793476\n",
      "    val_loss       : 12194.796731783845\n",
      "    val_log_likelihood: -12112.837938281897\n",
      "    val_log_marginal: -12121.499807639735\n",
      "Train Epoch: 3370 [256/118836 (0%)] Loss: 12290.635742\n",
      "Train Epoch: 3370 [33024/118836 (28%)] Loss: 12192.716797\n",
      "Train Epoch: 3370 [65792/118836 (55%)] Loss: 12245.548828\n",
      "Train Epoch: 3370 [98560/118836 (83%)] Loss: 12150.109375\n",
      "    epoch          : 3370\n",
      "    loss           : 12194.692086531999\n",
      "    val_loss       : 12195.931137230926\n",
      "    val_log_likelihood: -12112.798023127325\n",
      "    val_log_marginal: -12121.683437347618\n",
      "Train Epoch: 3371 [256/118836 (0%)] Loss: 12200.630859\n",
      "Train Epoch: 3371 [33024/118836 (28%)] Loss: 12101.639648\n",
      "Train Epoch: 3371 [65792/118836 (55%)] Loss: 12261.114258\n",
      "Train Epoch: 3371 [98560/118836 (83%)] Loss: 12171.105469\n",
      "    epoch          : 3371\n",
      "    loss           : 12195.63575559605\n",
      "    val_loss       : 12195.665166566057\n",
      "    val_log_likelihood: -12117.162035870295\n",
      "    val_log_marginal: -12126.196215597356\n",
      "Train Epoch: 3372 [256/118836 (0%)] Loss: 12359.577148\n",
      "Train Epoch: 3372 [33024/118836 (28%)] Loss: 12199.431641\n",
      "Train Epoch: 3372 [65792/118836 (55%)] Loss: 12222.476562\n",
      "Train Epoch: 3372 [98560/118836 (83%)] Loss: 12181.222656\n",
      "    epoch          : 3372\n",
      "    loss           : 12202.670417991367\n",
      "    val_loss       : 12198.592524749245\n",
      "    val_log_likelihood: -12109.083761437656\n",
      "    val_log_marginal: -12118.27049636915\n",
      "Train Epoch: 3373 [256/118836 (0%)] Loss: 12247.753906\n",
      "Train Epoch: 3373 [33024/118836 (28%)] Loss: 12205.093750\n",
      "Train Epoch: 3373 [65792/118836 (55%)] Loss: 12205.208984\n",
      "Train Epoch: 3373 [98560/118836 (83%)] Loss: 12257.847656\n",
      "    epoch          : 3373\n",
      "    loss           : 12196.329524820358\n",
      "    val_loss       : 12197.653983435355\n",
      "    val_log_likelihood: -12114.448695331886\n",
      "    val_log_marginal: -12123.444429608073\n",
      "Train Epoch: 3374 [256/118836 (0%)] Loss: 12249.287109\n",
      "Train Epoch: 3374 [33024/118836 (28%)] Loss: 12151.712891\n",
      "Train Epoch: 3374 [65792/118836 (55%)] Loss: 12320.352539\n",
      "Train Epoch: 3374 [98560/118836 (83%)] Loss: 12162.689453\n",
      "    epoch          : 3374\n",
      "    loss           : 12199.06639542623\n",
      "    val_loss       : 12193.44108367888\n",
      "    val_log_likelihood: -12114.326889151675\n",
      "    val_log_marginal: -12123.262962752771\n",
      "Train Epoch: 3375 [256/118836 (0%)] Loss: 12321.760742\n",
      "Train Epoch: 3375 [33024/118836 (28%)] Loss: 12231.324219\n",
      "Train Epoch: 3375 [65792/118836 (55%)] Loss: 12216.361328\n",
      "Train Epoch: 3375 [98560/118836 (83%)] Loss: 12187.568359\n",
      "    epoch          : 3375\n",
      "    loss           : 12192.225340383324\n",
      "    val_loss       : 12197.50250543841\n",
      "    val_log_likelihood: -12114.440853753102\n",
      "    val_log_marginal: -12123.331845067974\n",
      "Train Epoch: 3376 [256/118836 (0%)] Loss: 12141.718750\n",
      "Train Epoch: 3376 [33024/118836 (28%)] Loss: 12199.640625\n",
      "Train Epoch: 3376 [65792/118836 (55%)] Loss: 12188.206055\n",
      "Train Epoch: 3376 [98560/118836 (83%)] Loss: 12317.009766\n",
      "    epoch          : 3376\n",
      "    loss           : 12196.74829485241\n",
      "    val_loss       : 12192.400898012744\n",
      "    val_log_likelihood: -12117.73388873811\n",
      "    val_log_marginal: -12126.467588549358\n",
      "Train Epoch: 3377 [256/118836 (0%)] Loss: 12243.750977\n",
      "Train Epoch: 3377 [33024/118836 (28%)] Loss: 12200.022461\n",
      "Train Epoch: 3377 [65792/118836 (55%)] Loss: 12188.209961\n",
      "Train Epoch: 3377 [98560/118836 (83%)] Loss: 12301.236328\n",
      "    epoch          : 3377\n",
      "    loss           : 12192.772260616988\n",
      "    val_loss       : 12196.978006522591\n",
      "    val_log_likelihood: -12115.974230543063\n",
      "    val_log_marginal: -12124.819109824068\n",
      "Train Epoch: 3378 [256/118836 (0%)] Loss: 12162.959961\n",
      "Train Epoch: 3378 [33024/118836 (28%)] Loss: 12240.158203\n",
      "Train Epoch: 3378 [65792/118836 (55%)] Loss: 12232.187500\n",
      "Train Epoch: 3378 [98560/118836 (83%)] Loss: 12188.140625\n",
      "    epoch          : 3378\n",
      "    loss           : 12192.478015631461\n",
      "    val_loss       : 12197.240106907402\n",
      "    val_log_likelihood: -12111.627674763493\n",
      "    val_log_marginal: -12120.427515173582\n",
      "Train Epoch: 3379 [256/118836 (0%)] Loss: 12206.871094\n",
      "Train Epoch: 3379 [33024/118836 (28%)] Loss: 12263.869141\n",
      "Train Epoch: 3379 [65792/118836 (55%)] Loss: 12175.007812\n",
      "Train Epoch: 3379 [98560/118836 (83%)] Loss: 12169.135742\n",
      "    epoch          : 3379\n",
      "    loss           : 12199.062168340313\n",
      "    val_loss       : 12193.697256673146\n",
      "    val_log_likelihood: -12117.689163791098\n",
      "    val_log_marginal: -12126.590681716692\n",
      "Train Epoch: 3380 [256/118836 (0%)] Loss: 12206.089844\n",
      "Train Epoch: 3380 [33024/118836 (28%)] Loss: 12173.088867\n",
      "Train Epoch: 3380 [65792/118836 (55%)] Loss: 12255.995117\n",
      "Train Epoch: 3380 [98560/118836 (83%)] Loss: 12160.797852\n",
      "    epoch          : 3380\n",
      "    loss           : 12195.800912750725\n",
      "    val_loss       : 12193.612910628806\n",
      "    val_log_likelihood: -12111.881985854787\n",
      "    val_log_marginal: -12120.656391907925\n",
      "Train Epoch: 3381 [256/118836 (0%)] Loss: 12342.650391\n",
      "Train Epoch: 3381 [33024/118836 (28%)] Loss: 12342.514648\n",
      "Train Epoch: 3381 [65792/118836 (55%)] Loss: 12205.309570\n",
      "Train Epoch: 3381 [98560/118836 (83%)] Loss: 12122.202148\n",
      "    epoch          : 3381\n",
      "    loss           : 12191.634094712832\n",
      "    val_loss       : 12193.70370710673\n",
      "    val_log_likelihood: -12114.87626347317\n",
      "    val_log_marginal: -12123.579203654537\n",
      "Train Epoch: 3382 [256/118836 (0%)] Loss: 12214.133789\n",
      "Train Epoch: 3382 [33024/118836 (28%)] Loss: 12247.187500\n",
      "Train Epoch: 3382 [65792/118836 (55%)] Loss: 12096.960938\n",
      "Train Epoch: 3382 [98560/118836 (83%)] Loss: 12313.509766\n",
      "    epoch          : 3382\n",
      "    loss           : 12192.169247731856\n",
      "    val_loss       : 12194.71250903681\n",
      "    val_log_likelihood: -12116.164201108872\n",
      "    val_log_marginal: -12124.997267133693\n",
      "Train Epoch: 3383 [256/118836 (0%)] Loss: 12253.401367\n",
      "Train Epoch: 3383 [33024/118836 (28%)] Loss: 12191.282227\n",
      "Train Epoch: 3383 [65792/118836 (55%)] Loss: 12166.460938\n",
      "Train Epoch: 3383 [98560/118836 (83%)] Loss: 12254.865234\n",
      "    epoch          : 3383\n",
      "    loss           : 12197.433792616574\n",
      "    val_loss       : 12191.477943026344\n",
      "    val_log_likelihood: -12111.027124851375\n",
      "    val_log_marginal: -12120.018825150746\n",
      "Train Epoch: 3384 [256/118836 (0%)] Loss: 12218.679688\n",
      "Train Epoch: 3384 [33024/118836 (28%)] Loss: 12248.292969\n",
      "Train Epoch: 3384 [65792/118836 (55%)] Loss: 12180.460938\n",
      "Train Epoch: 3384 [98560/118836 (83%)] Loss: 12195.808594\n",
      "    epoch          : 3384\n",
      "    loss           : 12190.344868725444\n",
      "    val_loss       : 12195.578014094348\n",
      "    val_log_likelihood: -12108.735388234078\n",
      "    val_log_marginal: -12117.682350999574\n",
      "Train Epoch: 3385 [256/118836 (0%)] Loss: 12232.788086\n",
      "Train Epoch: 3385 [33024/118836 (28%)] Loss: 12240.993164\n",
      "Train Epoch: 3385 [65792/118836 (55%)] Loss: 12172.840820\n",
      "Train Epoch: 3385 [98560/118836 (83%)] Loss: 12185.297852\n",
      "    epoch          : 3385\n",
      "    loss           : 12197.3594018171\n",
      "    val_loss       : 12192.331041212825\n",
      "    val_log_likelihood: -12113.688401603857\n",
      "    val_log_marginal: -12122.620667169775\n",
      "Train Epoch: 3386 [256/118836 (0%)] Loss: 12161.750000\n",
      "Train Epoch: 3386 [33024/118836 (28%)] Loss: 12245.291016\n",
      "Train Epoch: 3386 [65792/118836 (55%)] Loss: 12177.756836\n",
      "Train Epoch: 3386 [98560/118836 (83%)] Loss: 12193.716797\n",
      "    epoch          : 3386\n",
      "    loss           : 12194.721495683416\n",
      "    val_loss       : 12191.497535484077\n",
      "    val_log_likelihood: -12110.889048606803\n",
      "    val_log_marginal: -12119.76886195405\n",
      "Train Epoch: 3387 [256/118836 (0%)] Loss: 12188.416016\n",
      "Train Epoch: 3387 [33024/118836 (28%)] Loss: 12178.047852\n",
      "Train Epoch: 3387 [65792/118836 (55%)] Loss: 12198.910156\n",
      "Train Epoch: 3387 [98560/118836 (83%)] Loss: 12154.552734\n",
      "    epoch          : 3387\n",
      "    loss           : 12193.806078112075\n",
      "    val_loss       : 12196.810052323159\n",
      "    val_log_likelihood: -12114.537647655605\n",
      "    val_log_marginal: -12123.477760866363\n",
      "Train Epoch: 3388 [256/118836 (0%)] Loss: 12249.402344\n",
      "Train Epoch: 3388 [33024/118836 (28%)] Loss: 12174.744141\n",
      "Train Epoch: 3388 [65792/118836 (55%)] Loss: 12233.707031\n",
      "Train Epoch: 3388 [98560/118836 (83%)] Loss: 12147.797852\n",
      "    epoch          : 3388\n",
      "    loss           : 12192.096190033086\n",
      "    val_loss       : 12196.05653394224\n",
      "    val_log_likelihood: -12110.498181929797\n",
      "    val_log_marginal: -12119.41677221011\n",
      "Train Epoch: 3389 [256/118836 (0%)] Loss: 12256.496094\n",
      "Train Epoch: 3389 [33024/118836 (28%)] Loss: 12240.540039\n",
      "Train Epoch: 3389 [65792/118836 (55%)] Loss: 12201.060547\n",
      "Train Epoch: 3389 [98560/118836 (83%)] Loss: 12160.465820\n",
      "    epoch          : 3389\n",
      "    loss           : 12195.766373617142\n",
      "    val_loss       : 12191.961163690832\n",
      "    val_log_likelihood: -12118.109677257806\n",
      "    val_log_marginal: -12126.913777491063\n",
      "Train Epoch: 3390 [256/118836 (0%)] Loss: 12159.725586\n",
      "Train Epoch: 3390 [33024/118836 (28%)] Loss: 12248.962891\n",
      "Train Epoch: 3390 [65792/118836 (55%)] Loss: 12192.648438\n",
      "Train Epoch: 3390 [98560/118836 (83%)] Loss: 12302.849609\n",
      "    epoch          : 3390\n",
      "    loss           : 12196.299010998244\n",
      "    val_loss       : 12194.60747840713\n",
      "    val_log_likelihood: -12109.782848040735\n",
      "    val_log_marginal: -12118.626895781454\n",
      "Train Epoch: 3391 [256/118836 (0%)] Loss: 12196.189453\n",
      "Train Epoch: 3391 [33024/118836 (28%)] Loss: 12352.689453\n",
      "Train Epoch: 3391 [65792/118836 (55%)] Loss: 12185.754883\n",
      "Train Epoch: 3391 [98560/118836 (83%)] Loss: 12318.800781\n",
      "    epoch          : 3391\n",
      "    loss           : 12194.305216249224\n",
      "    val_loss       : 12190.722768182584\n",
      "    val_log_likelihood: -12110.457396996484\n",
      "    val_log_marginal: -12119.277469842493\n",
      "Train Epoch: 3392 [256/118836 (0%)] Loss: 12190.684570\n",
      "Train Epoch: 3392 [33024/118836 (28%)] Loss: 12182.782227\n",
      "Train Epoch: 3392 [65792/118836 (55%)] Loss: 12313.841797\n",
      "Train Epoch: 3392 [98560/118836 (83%)] Loss: 12189.553711\n",
      "    epoch          : 3392\n",
      "    loss           : 12194.433105549524\n",
      "    val_loss       : 12193.756030541768\n",
      "    val_log_likelihood: -12111.849623591295\n",
      "    val_log_marginal: -12120.468207791584\n",
      "Train Epoch: 3393 [256/118836 (0%)] Loss: 12274.171875\n",
      "Train Epoch: 3393 [33024/118836 (28%)] Loss: 12241.059570\n",
      "Train Epoch: 3393 [65792/118836 (55%)] Loss: 12253.754883\n",
      "Train Epoch: 3393 [98560/118836 (83%)] Loss: 12222.052734\n",
      "    epoch          : 3393\n",
      "    loss           : 12195.98767237257\n",
      "    val_loss       : 12192.319929942085\n",
      "    val_log_likelihood: -12112.519476484957\n",
      "    val_log_marginal: -12121.318884879687\n",
      "Train Epoch: 3394 [256/118836 (0%)] Loss: 12214.480469\n",
      "Train Epoch: 3394 [33024/118836 (28%)] Loss: 12240.410156\n",
      "Train Epoch: 3394 [65792/118836 (55%)] Loss: 12128.368164\n",
      "Train Epoch: 3394 [98560/118836 (83%)] Loss: 12190.933594\n",
      "    epoch          : 3394\n",
      "    loss           : 12193.469744332868\n",
      "    val_loss       : 12192.051948239543\n",
      "    val_log_likelihood: -12113.640636469965\n",
      "    val_log_marginal: -12122.49547113542\n",
      "Train Epoch: 3395 [256/118836 (0%)] Loss: 12175.107422\n",
      "Train Epoch: 3395 [33024/118836 (28%)] Loss: 12218.921875\n",
      "Train Epoch: 3395 [65792/118836 (55%)] Loss: 12181.437500\n",
      "Train Epoch: 3395 [98560/118836 (83%)] Loss: 12201.248047\n",
      "    epoch          : 3395\n",
      "    loss           : 12198.382041104476\n",
      "    val_loss       : 12204.198211339533\n",
      "    val_log_likelihood: -12113.99611281276\n",
      "    val_log_marginal: -12123.049760977206\n",
      "Train Epoch: 3396 [256/118836 (0%)] Loss: 12169.570312\n",
      "Train Epoch: 3396 [33024/118836 (28%)] Loss: 12332.391602\n",
      "Train Epoch: 3396 [65792/118836 (55%)] Loss: 12234.512695\n",
      "Train Epoch: 3396 [98560/118836 (83%)] Loss: 12225.353516\n",
      "    epoch          : 3396\n",
      "    loss           : 12190.045164844396\n",
      "    val_loss       : 12197.60161982733\n",
      "    val_log_likelihood: -12113.361607927523\n",
      "    val_log_marginal: -12122.392558152964\n",
      "Train Epoch: 3397 [256/118836 (0%)] Loss: 12193.850586\n",
      "Train Epoch: 3397 [33024/118836 (28%)] Loss: 12171.361328\n",
      "Train Epoch: 3397 [65792/118836 (55%)] Loss: 12219.014648\n",
      "Train Epoch: 3397 [98560/118836 (83%)] Loss: 12236.820312\n",
      "    epoch          : 3397\n",
      "    loss           : 12193.853761986922\n",
      "    val_loss       : 12193.130561898073\n",
      "    val_log_likelihood: -12109.456244991989\n",
      "    val_log_marginal: -12118.424860634668\n",
      "Train Epoch: 3398 [256/118836 (0%)] Loss: 12202.107422\n",
      "Train Epoch: 3398 [33024/118836 (28%)] Loss: 12180.375000\n",
      "Train Epoch: 3398 [65792/118836 (55%)] Loss: 12188.266602\n",
      "Train Epoch: 3398 [98560/118836 (83%)] Loss: 12275.694336\n",
      "    epoch          : 3398\n",
      "    loss           : 12192.67897506979\n",
      "    val_loss       : 12195.540513491063\n",
      "    val_log_likelihood: -12111.924322948977\n",
      "    val_log_marginal: -12120.758495884973\n",
      "Train Epoch: 3399 [256/118836 (0%)] Loss: 12173.851562\n",
      "Train Epoch: 3399 [33024/118836 (28%)] Loss: 12168.015625\n",
      "Train Epoch: 3399 [65792/118836 (55%)] Loss: 12279.003906\n",
      "Train Epoch: 3399 [98560/118836 (83%)] Loss: 12222.375000\n",
      "    epoch          : 3399\n",
      "    loss           : 12200.441130809295\n",
      "    val_loss       : 12200.368764949117\n",
      "    val_log_likelihood: -12114.41136172715\n",
      "    val_log_marginal: -12123.35710438667\n",
      "Train Epoch: 3400 [256/118836 (0%)] Loss: 12180.906250\n",
      "Train Epoch: 3400 [33024/118836 (28%)] Loss: 12206.175781\n",
      "Train Epoch: 3400 [65792/118836 (55%)] Loss: 12310.914062\n",
      "Train Epoch: 3400 [98560/118836 (83%)] Loss: 12180.857422\n",
      "    epoch          : 3400\n",
      "    loss           : 12194.187576251034\n",
      "    val_loss       : 12192.203573465154\n",
      "    val_log_likelihood: -12114.0458646738\n",
      "    val_log_marginal: -12122.938256161588\n",
      "Saving checkpoint: saved/models/SelfiesAutoencodingOperad/0905_154251/checkpoint-epoch3400.pth ...\n",
      "Train Epoch: 3401 [256/118836 (0%)] Loss: 12200.578125\n",
      "Train Epoch: 3401 [33024/118836 (28%)] Loss: 12162.986328\n",
      "Train Epoch: 3401 [65792/118836 (55%)] Loss: 12190.830078\n",
      "Train Epoch: 3401 [98560/118836 (83%)] Loss: 12163.893555\n",
      "    epoch          : 3401\n",
      "    loss           : 12194.0432517835\n",
      "    val_loss       : 12191.367779504115\n",
      "    val_log_likelihood: -12110.473943955489\n",
      "    val_log_marginal: -12119.34951151455\n",
      "Train Epoch: 3402 [256/118836 (0%)] Loss: 12228.326172\n",
      "Train Epoch: 3402 [33024/118836 (28%)] Loss: 12295.864258\n",
      "Train Epoch: 3402 [65792/118836 (55%)] Loss: 12237.638672\n",
      "Train Epoch: 3402 [98560/118836 (83%)] Loss: 12179.522461\n",
      "    epoch          : 3402\n",
      "    loss           : 12195.110514242142\n",
      "    val_loss       : 12195.194175477398\n",
      "    val_log_likelihood: -12115.365788487386\n",
      "    val_log_marginal: -12124.203365418687\n",
      "Train Epoch: 3403 [256/118836 (0%)] Loss: 12164.765625\n",
      "Train Epoch: 3403 [33024/118836 (28%)] Loss: 12332.429688\n",
      "Train Epoch: 3403 [65792/118836 (55%)] Loss: 12191.078125\n",
      "Train Epoch: 3403 [98560/118836 (83%)] Loss: 12173.447266\n",
      "    epoch          : 3403\n",
      "    loss           : 12193.782400712107\n",
      "    val_loss       : 12193.849214117652\n",
      "    val_log_likelihood: -12117.184798580955\n",
      "    val_log_marginal: -12126.186317284159\n",
      "Train Epoch: 3404 [256/118836 (0%)] Loss: 12206.848633\n",
      "Train Epoch: 3404 [33024/118836 (28%)] Loss: 12189.446289\n",
      "Train Epoch: 3404 [65792/118836 (55%)] Loss: 12194.185547\n",
      "Train Epoch: 3404 [98560/118836 (83%)] Loss: 12168.653320\n",
      "    epoch          : 3404\n",
      "    loss           : 12189.93424172224\n",
      "    val_loss       : 12193.956360918377\n",
      "    val_log_likelihood: -12117.085046235268\n",
      "    val_log_marginal: -12125.844957503092\n",
      "Train Epoch: 3405 [256/118836 (0%)] Loss: 12262.710938\n",
      "Train Epoch: 3405 [33024/118836 (28%)] Loss: 12253.545898\n",
      "Train Epoch: 3405 [65792/118836 (55%)] Loss: 12207.724609\n",
      "Train Epoch: 3405 [98560/118836 (83%)] Loss: 12247.572266\n",
      "    epoch          : 3405\n",
      "    loss           : 12195.016488801437\n",
      "    val_loss       : 12194.064442664523\n",
      "    val_log_likelihood: -12116.918403154727\n",
      "    val_log_marginal: -12125.619246814365\n",
      "Train Epoch: 3406 [256/118836 (0%)] Loss: 12163.097656\n",
      "Train Epoch: 3406 [33024/118836 (28%)] Loss: 12175.490234\n",
      "Train Epoch: 3406 [65792/118836 (55%)] Loss: 12317.035156\n",
      "Train Epoch: 3406 [98560/118836 (83%)] Loss: 12294.321289\n",
      "    epoch          : 3406\n",
      "    loss           : 12190.846792610111\n",
      "    val_loss       : 12190.641298668437\n",
      "    val_log_likelihood: -12113.540914010806\n",
      "    val_log_marginal: -12122.351015283517\n",
      "Train Epoch: 3407 [256/118836 (0%)] Loss: 12273.617188\n",
      "Train Epoch: 3407 [33024/118836 (28%)] Loss: 12177.002930\n",
      "Train Epoch: 3407 [65792/118836 (55%)] Loss: 12149.635742\n",
      "Train Epoch: 3407 [98560/118836 (83%)] Loss: 12269.878906\n",
      "    epoch          : 3407\n",
      "    loss           : 12190.514090124843\n",
      "    val_loss       : 12192.744137246242\n",
      "    val_log_likelihood: -12115.244737870915\n",
      "    val_log_marginal: -12124.11325978381\n",
      "Train Epoch: 3408 [256/118836 (0%)] Loss: 12170.305664\n",
      "Train Epoch: 3408 [33024/118836 (28%)] Loss: 12212.009766\n",
      "Train Epoch: 3408 [65792/118836 (55%)] Loss: 12177.708984\n",
      "Train Epoch: 3408 [98560/118836 (83%)] Loss: 12381.389648\n",
      "    epoch          : 3408\n",
      "    loss           : 12193.479065860214\n",
      "    val_loss       : 12203.519121956439\n",
      "    val_log_likelihood: -12112.837860900021\n",
      "    val_log_marginal: -12121.729320735762\n",
      "Train Epoch: 3409 [256/118836 (0%)] Loss: 12217.347656\n",
      "Train Epoch: 3409 [33024/118836 (28%)] Loss: 12256.443359\n",
      "Train Epoch: 3409 [65792/118836 (55%)] Loss: 12136.558594\n",
      "Train Epoch: 3409 [98560/118836 (83%)] Loss: 12168.644531\n",
      "    epoch          : 3409\n",
      "    loss           : 12192.128991870864\n",
      "    val_loss       : 12192.817744819991\n",
      "    val_log_likelihood: -12108.891172811984\n",
      "    val_log_marginal: -12117.639303095346\n",
      "Train Epoch: 3410 [256/118836 (0%)] Loss: 12277.271484\n",
      "Train Epoch: 3410 [33024/118836 (28%)] Loss: 12182.238281\n",
      "Train Epoch: 3410 [65792/118836 (55%)] Loss: 12303.234375\n",
      "Train Epoch: 3410 [98560/118836 (83%)] Loss: 12241.323242\n",
      "    epoch          : 3410\n",
      "    loss           : 12197.576952640355\n",
      "    val_loss       : 12191.100451323653\n",
      "    val_log_likelihood: -12114.277161522952\n",
      "    val_log_marginal: -12123.098053531588\n",
      "Train Epoch: 3411 [256/118836 (0%)] Loss: 12200.213867\n",
      "Train Epoch: 3411 [33024/118836 (28%)] Loss: 12187.086914\n",
      "Train Epoch: 3411 [65792/118836 (55%)] Loss: 12153.463867\n",
      "Train Epoch: 3411 [98560/118836 (83%)] Loss: 12212.968750\n",
      "    epoch          : 3411\n",
      "    loss           : 12194.865853591553\n",
      "    val_loss       : 12196.120082596422\n",
      "    val_log_likelihood: -12112.30926595456\n",
      "    val_log_marginal: -12121.177258473577\n",
      "Train Epoch: 3412 [256/118836 (0%)] Loss: 12217.032227\n",
      "Train Epoch: 3412 [33024/118836 (28%)] Loss: 12210.129883\n",
      "Train Epoch: 3412 [65792/118836 (55%)] Loss: 12244.525391\n",
      "Train Epoch: 3412 [98560/118836 (83%)] Loss: 12108.604492\n",
      "    epoch          : 3412\n",
      "    loss           : 12195.6090651494\n",
      "    val_loss       : 12206.524124820802\n",
      "    val_log_likelihood: -12115.271014914186\n",
      "    val_log_marginal: -12124.204493075133\n",
      "Train Epoch: 3413 [256/118836 (0%)] Loss: 12209.324219\n",
      "Train Epoch: 3413 [33024/118836 (28%)] Loss: 12240.164062\n",
      "Train Epoch: 3413 [65792/118836 (55%)] Loss: 12190.858398\n",
      "Train Epoch: 3413 [98560/118836 (83%)] Loss: 12209.480469\n",
      "    epoch          : 3413\n",
      "    loss           : 12189.083736236043\n",
      "    val_loss       : 12196.293284065621\n",
      "    val_log_likelihood: -12112.784894540942\n",
      "    val_log_marginal: -12121.599213745663\n",
      "Train Epoch: 3414 [256/118836 (0%)] Loss: 12222.220703\n",
      "Train Epoch: 3414 [33024/118836 (28%)] Loss: 12174.712891\n",
      "Train Epoch: 3414 [65792/118836 (55%)] Loss: 12265.892578\n",
      "Train Epoch: 3414 [98560/118836 (83%)] Loss: 12254.124023\n",
      "    epoch          : 3414\n",
      "    loss           : 12193.276337139423\n",
      "    val_loss       : 12192.540889594975\n",
      "    val_log_likelihood: -12114.576246510545\n",
      "    val_log_marginal: -12123.367334109458\n",
      "Train Epoch: 3415 [256/118836 (0%)] Loss: 12223.376953\n",
      "Train Epoch: 3415 [33024/118836 (28%)] Loss: 12188.173828\n",
      "Train Epoch: 3415 [65792/118836 (55%)] Loss: 12251.036133\n",
      "Train Epoch: 3415 [98560/118836 (83%)] Loss: 12182.878906\n",
      "    epoch          : 3415\n",
      "    loss           : 12194.580659862231\n",
      "    val_loss       : 12194.192539456515\n",
      "    val_log_likelihood: -12114.460460284843\n",
      "    val_log_marginal: -12123.225994542874\n",
      "Train Epoch: 3416 [256/118836 (0%)] Loss: 12195.792969\n",
      "Train Epoch: 3416 [33024/118836 (28%)] Loss: 12254.751953\n",
      "Train Epoch: 3416 [65792/118836 (55%)] Loss: 12181.671875\n",
      "Train Epoch: 3416 [98560/118836 (83%)] Loss: 12224.627930\n",
      "    epoch          : 3416\n",
      "    loss           : 12199.039158459987\n",
      "    val_loss       : 12198.684545616594\n",
      "    val_log_likelihood: -12112.799969467276\n",
      "    val_log_marginal: -12121.757402403195\n",
      "Train Epoch: 3417 [256/118836 (0%)] Loss: 12100.239258\n",
      "Train Epoch: 3417 [33024/118836 (28%)] Loss: 12298.687500\n",
      "Train Epoch: 3417 [65792/118836 (55%)] Loss: 12191.894531\n",
      "Train Epoch: 3417 [98560/118836 (83%)] Loss: 12215.656250\n",
      "    epoch          : 3417\n",
      "    loss           : 12194.91678233561\n",
      "    val_loss       : 12197.536722048666\n",
      "    val_log_likelihood: -12116.55150046526\n",
      "    val_log_marginal: -12125.45161275727\n",
      "Train Epoch: 3418 [256/118836 (0%)] Loss: 12265.911133\n",
      "Train Epoch: 3418 [33024/118836 (28%)] Loss: 12263.474609\n",
      "Train Epoch: 3418 [65792/118836 (55%)] Loss: 12145.060547\n",
      "Train Epoch: 3418 [98560/118836 (83%)] Loss: 12212.117188\n",
      "    epoch          : 3418\n",
      "    loss           : 12195.420997790014\n",
      "    val_loss       : 12197.501196510306\n",
      "    val_log_likelihood: -12117.443402023884\n",
      "    val_log_marginal: -12126.372436627356\n",
      "Train Epoch: 3419 [256/118836 (0%)] Loss: 12190.187500\n",
      "Train Epoch: 3419 [33024/118836 (28%)] Loss: 12200.050781\n",
      "Train Epoch: 3419 [65792/118836 (55%)] Loss: 12171.439453\n",
      "Train Epoch: 3419 [98560/118836 (83%)] Loss: 12210.776367\n",
      "    epoch          : 3419\n",
      "    loss           : 12194.620913784636\n",
      "    val_loss       : 12196.492524874138\n",
      "    val_log_likelihood: -12109.233634944945\n",
      "    val_log_marginal: -12118.200771664595\n",
      "Train Epoch: 3420 [256/118836 (0%)] Loss: 12213.055664\n",
      "Train Epoch: 3420 [33024/118836 (28%)] Loss: 12248.800781\n",
      "Train Epoch: 3420 [65792/118836 (55%)] Loss: 12181.337891\n",
      "Train Epoch: 3420 [98560/118836 (83%)] Loss: 12233.209961\n",
      "    epoch          : 3420\n",
      "    loss           : 12189.242037098065\n",
      "    val_loss       : 12193.548118232236\n",
      "    val_log_likelihood: -12111.126284797612\n",
      "    val_log_marginal: -12120.025742171072\n",
      "Train Epoch: 3421 [256/118836 (0%)] Loss: 12206.609375\n",
      "Train Epoch: 3421 [33024/118836 (28%)] Loss: 12238.437500\n",
      "Train Epoch: 3421 [65792/118836 (55%)] Loss: 12212.238281\n",
      "Train Epoch: 3421 [98560/118836 (83%)] Loss: 12278.523438\n",
      "    epoch          : 3421\n",
      "    loss           : 12191.824966882496\n",
      "    val_loss       : 12193.5371441705\n",
      "    val_log_likelihood: -12113.386454294614\n",
      "    val_log_marginal: -12122.112442054804\n",
      "Train Epoch: 3422 [256/118836 (0%)] Loss: 12371.520508\n",
      "Train Epoch: 3422 [33024/118836 (28%)] Loss: 12232.814453\n",
      "Train Epoch: 3422 [65792/118836 (55%)] Loss: 12204.459961\n",
      "Train Epoch: 3422 [98560/118836 (83%)] Loss: 12242.082031\n",
      "    epoch          : 3422\n",
      "    loss           : 12195.515248106649\n",
      "    val_loss       : 12194.4530719867\n",
      "    val_log_likelihood: -12113.987545718312\n",
      "    val_log_marginal: -12122.586490154135\n",
      "Train Epoch: 3423 [256/118836 (0%)] Loss: 12252.232422\n",
      "Train Epoch: 3423 [33024/118836 (28%)] Loss: 12207.739258\n",
      "Train Epoch: 3423 [65792/118836 (55%)] Loss: 12223.208008\n",
      "Train Epoch: 3423 [98560/118836 (83%)] Loss: 12217.045898\n",
      "    epoch          : 3423\n",
      "    loss           : 12189.821015883477\n",
      "    val_loss       : 12191.650432320343\n",
      "    val_log_likelihood: -12110.520320092795\n",
      "    val_log_marginal: -12119.250972511538\n",
      "Train Epoch: 3424 [256/118836 (0%)] Loss: 12235.150391\n",
      "Train Epoch: 3424 [33024/118836 (28%)] Loss: 12159.665039\n",
      "Train Epoch: 3424 [65792/118836 (55%)] Loss: 12244.980469\n",
      "Train Epoch: 3424 [98560/118836 (83%)] Loss: 12158.300781\n",
      "    epoch          : 3424\n",
      "    loss           : 12188.68782584393\n",
      "    val_loss       : 12199.30788408364\n",
      "    val_log_likelihood: -12127.844178104322\n",
      "    val_log_marginal: -12136.70871002025\n",
      "Train Epoch: 3425 [256/118836 (0%)] Loss: 12277.183594\n",
      "Train Epoch: 3425 [33024/118836 (28%)] Loss: 12318.195312\n",
      "Train Epoch: 3425 [65792/118836 (55%)] Loss: 12160.458984\n",
      "Train Epoch: 3425 [98560/118836 (83%)] Loss: 12117.332031\n",
      "    epoch          : 3425\n",
      "    loss           : 12190.998707609595\n",
      "    val_loss       : 12197.19054055422\n",
      "    val_log_likelihood: -12115.248084192774\n",
      "    val_log_marginal: -12123.969881255434\n",
      "Train Epoch: 3426 [256/118836 (0%)] Loss: 12238.328125\n",
      "Train Epoch: 3426 [33024/118836 (28%)] Loss: 12212.508789\n",
      "Train Epoch: 3426 [65792/118836 (55%)] Loss: 12235.605469\n",
      "Train Epoch: 3426 [98560/118836 (83%)] Loss: 12346.935547\n",
      "    epoch          : 3426\n",
      "    loss           : 12194.97346334781\n",
      "    val_loss       : 12190.841043270668\n",
      "    val_log_likelihood: -12109.475792558414\n",
      "    val_log_marginal: -12118.129954703574\n",
      "Train Epoch: 3427 [256/118836 (0%)] Loss: 12223.528320\n",
      "Train Epoch: 3427 [33024/118836 (28%)] Loss: 12175.186523\n",
      "Train Epoch: 3427 [65792/118836 (55%)] Loss: 12211.159180\n",
      "Train Epoch: 3427 [98560/118836 (83%)] Loss: 12118.111328\n",
      "    epoch          : 3427\n",
      "    loss           : 12193.686088225031\n",
      "    val_loss       : 12194.175531918254\n",
      "    val_log_likelihood: -12113.177001104994\n",
      "    val_log_marginal: -12122.187713555259\n",
      "Train Epoch: 3428 [256/118836 (0%)] Loss: 12242.477539\n",
      "Train Epoch: 3428 [33024/118836 (28%)] Loss: 12220.057617\n",
      "Train Epoch: 3428 [65792/118836 (55%)] Loss: 12215.850586\n",
      "Train Epoch: 3428 [98560/118836 (83%)] Loss: 12304.770508\n",
      "    epoch          : 3428\n",
      "    loss           : 12195.296690349722\n",
      "    val_loss       : 12190.753910237905\n",
      "    val_log_likelihood: -12113.662700320512\n",
      "    val_log_marginal: -12122.571219731963\n",
      "Train Epoch: 3429 [256/118836 (0%)] Loss: 12198.114258\n",
      "Train Epoch: 3429 [33024/118836 (28%)] Loss: 12190.619141\n",
      "Train Epoch: 3429 [65792/118836 (55%)] Loss: 12260.880859\n",
      "Train Epoch: 3429 [98560/118836 (83%)] Loss: 12136.433594\n",
      "    epoch          : 3429\n",
      "    loss           : 12194.959023631358\n",
      "    val_loss       : 12195.761060356634\n",
      "    val_log_likelihood: -12110.384320881152\n",
      "    val_log_marginal: -12119.192760032718\n",
      "Train Epoch: 3430 [256/118836 (0%)] Loss: 12199.019531\n",
      "Train Epoch: 3430 [33024/118836 (28%)] Loss: 12233.020508\n",
      "Train Epoch: 3430 [65792/118836 (55%)] Loss: 12207.019531\n",
      "Train Epoch: 3430 [98560/118836 (83%)] Loss: 12301.316406\n",
      "    epoch          : 3430\n",
      "    loss           : 12190.742941286704\n",
      "    val_loss       : 12196.663693626533\n",
      "    val_log_likelihood: -12112.7245756113\n",
      "    val_log_marginal: -12121.748409929562\n",
      "Train Epoch: 3431 [256/118836 (0%)] Loss: 12196.206055\n",
      "Train Epoch: 3431 [33024/118836 (28%)] Loss: 12196.335938\n",
      "Train Epoch: 3431 [65792/118836 (55%)] Loss: 12193.925781\n",
      "Train Epoch: 3431 [98560/118836 (83%)] Loss: 12178.750977\n",
      "    epoch          : 3431\n",
      "    loss           : 12192.000347006824\n",
      "    val_loss       : 12194.904950292086\n",
      "    val_log_likelihood: -12114.319250316636\n",
      "    val_log_marginal: -12123.175270419955\n",
      "Train Epoch: 3432 [256/118836 (0%)] Loss: 12163.792969\n",
      "Train Epoch: 3432 [33024/118836 (28%)] Loss: 12201.441406\n",
      "Train Epoch: 3432 [65792/118836 (55%)] Loss: 12125.787109\n",
      "Train Epoch: 3432 [98560/118836 (83%)] Loss: 12209.028320\n",
      "    epoch          : 3432\n",
      "    loss           : 12196.697272571599\n",
      "    val_loss       : 12192.404132363326\n",
      "    val_log_likelihood: -12114.476939877997\n",
      "    val_log_marginal: -12123.301642840981\n",
      "Train Epoch: 3433 [256/118836 (0%)] Loss: 12212.548828\n",
      "Train Epoch: 3433 [33024/118836 (28%)] Loss: 12142.395508\n",
      "Train Epoch: 3433 [65792/118836 (55%)] Loss: 12170.130859\n",
      "Train Epoch: 3433 [98560/118836 (83%)] Loss: 12238.074219\n",
      "    epoch          : 3433\n",
      "    loss           : 12194.038369132548\n",
      "    val_loss       : 12201.370906736223\n",
      "    val_log_likelihood: -12116.913135532983\n",
      "    val_log_marginal: -12125.853675690716\n",
      "Train Epoch: 3434 [256/118836 (0%)] Loss: 12275.675781\n",
      "Train Epoch: 3434 [33024/118836 (28%)] Loss: 12210.056641\n",
      "Train Epoch: 3434 [65792/118836 (55%)] Loss: 12217.892578\n",
      "Train Epoch: 3434 [98560/118836 (83%)] Loss: 12275.915039\n",
      "    epoch          : 3434\n",
      "    loss           : 12195.221909571443\n",
      "    val_loss       : 12193.318377947668\n",
      "    val_log_likelihood: -12115.758096179694\n",
      "    val_log_marginal: -12124.914892091034\n",
      "Train Epoch: 3435 [256/118836 (0%)] Loss: 12229.331055\n",
      "Train Epoch: 3435 [33024/118836 (28%)] Loss: 12190.063477\n",
      "Train Epoch: 3435 [65792/118836 (55%)] Loss: 12204.416992\n",
      "Train Epoch: 3435 [98560/118836 (83%)] Loss: 12147.614258\n",
      "    epoch          : 3435\n",
      "    loss           : 12194.193102997053\n",
      "    val_loss       : 12190.351140769257\n",
      "    val_log_likelihood: -12111.626680430623\n",
      "    val_log_marginal: -12120.557639695353\n",
      "Train Epoch: 3436 [256/118836 (0%)] Loss: 12225.631836\n",
      "Train Epoch: 3436 [33024/118836 (28%)] Loss: 12223.005859\n",
      "Train Epoch: 3436 [65792/118836 (55%)] Loss: 12217.410156\n",
      "Train Epoch: 3436 [98560/118836 (83%)] Loss: 12148.153320\n",
      "    epoch          : 3436\n",
      "    loss           : 12191.970180837729\n",
      "    val_loss       : 12191.202647200314\n",
      "    val_log_likelihood: -12114.030185716501\n",
      "    val_log_marginal: -12123.093109522304\n",
      "Train Epoch: 3437 [256/118836 (0%)] Loss: 12182.088867\n",
      "Train Epoch: 3437 [33024/118836 (28%)] Loss: 12256.534180\n",
      "Train Epoch: 3437 [65792/118836 (55%)] Loss: 12326.180664\n",
      "Train Epoch: 3437 [98560/118836 (83%)] Loss: 12293.535156\n",
      "    epoch          : 3437\n",
      "    loss           : 12195.706239822424\n",
      "    val_loss       : 12193.165112460032\n",
      "    val_log_likelihood: -12114.201666537429\n",
      "    val_log_marginal: -12123.032927155931\n",
      "Train Epoch: 3438 [256/118836 (0%)] Loss: 12255.297852\n",
      "Train Epoch: 3438 [33024/118836 (28%)] Loss: 12163.322266\n",
      "Train Epoch: 3438 [65792/118836 (55%)] Loss: 12225.027344\n",
      "Train Epoch: 3438 [98560/118836 (83%)] Loss: 12199.972656\n",
      "    epoch          : 3438\n",
      "    loss           : 12192.406965661186\n",
      "    val_loss       : 12193.236250353504\n",
      "    val_log_likelihood: -12110.316049550247\n",
      "    val_log_marginal: -12119.254872221072\n",
      "Train Epoch: 3439 [256/118836 (0%)] Loss: 12195.766602\n",
      "Train Epoch: 3439 [33024/118836 (28%)] Loss: 12126.101562\n",
      "Train Epoch: 3439 [65792/118836 (55%)] Loss: 12246.796875\n",
      "Train Epoch: 3439 [98560/118836 (83%)] Loss: 12210.227539\n",
      "    epoch          : 3439\n",
      "    loss           : 12192.429121433002\n",
      "    val_loss       : 12195.222927340648\n",
      "    val_log_likelihood: -12108.766524988368\n",
      "    val_log_marginal: -12117.517127669757\n",
      "Train Epoch: 3440 [256/118836 (0%)] Loss: 12222.847656\n",
      "Train Epoch: 3440 [33024/118836 (28%)] Loss: 12261.298828\n",
      "Train Epoch: 3440 [65792/118836 (55%)] Loss: 12180.921875\n",
      "Train Epoch: 3440 [98560/118836 (83%)] Loss: 12161.906250\n",
      "    epoch          : 3440\n",
      "    loss           : 12196.231587475444\n",
      "    val_loss       : 12211.343197527876\n",
      "    val_log_likelihood: -12118.213608063224\n",
      "    val_log_marginal: -12127.05490940609\n",
      "Train Epoch: 3441 [256/118836 (0%)] Loss: 12375.478516\n",
      "Train Epoch: 3441 [33024/118836 (28%)] Loss: 12227.125000\n",
      "Train Epoch: 3441 [65792/118836 (55%)] Loss: 12232.994141\n",
      "Train Epoch: 3441 [98560/118836 (83%)] Loss: 12272.901367\n",
      "    epoch          : 3441\n",
      "    loss           : 12200.288422928297\n",
      "    val_loss       : 12191.08010181629\n",
      "    val_log_likelihood: -12114.49857627042\n",
      "    val_log_marginal: -12123.540077991955\n",
      "Train Epoch: 3442 [256/118836 (0%)] Loss: 12216.101562\n",
      "Train Epoch: 3442 [33024/118836 (28%)] Loss: 12155.319336\n",
      "Train Epoch: 3442 [65792/118836 (55%)] Loss: 12260.635742\n",
      "Train Epoch: 3442 [98560/118836 (83%)] Loss: 12250.468750\n",
      "    epoch          : 3442\n",
      "    loss           : 12195.075687551695\n",
      "    val_loss       : 12192.162592749999\n",
      "    val_log_likelihood: -12115.76792303169\n",
      "    val_log_marginal: -12124.671966667936\n",
      "Train Epoch: 3443 [256/118836 (0%)] Loss: 12106.478516\n",
      "Train Epoch: 3443 [33024/118836 (28%)] Loss: 12166.875000\n",
      "Train Epoch: 3443 [65792/118836 (55%)] Loss: 12258.544922\n",
      "Train Epoch: 3443 [98560/118836 (83%)] Loss: 12242.425781\n",
      "    epoch          : 3443\n",
      "    loss           : 12194.23328002223\n",
      "    val_loss       : 12196.975242999033\n",
      "    val_log_likelihood: -12109.380663577855\n",
      "    val_log_marginal: -12118.218971030914\n",
      "Train Epoch: 3444 [256/118836 (0%)] Loss: 12179.725586\n",
      "Train Epoch: 3444 [33024/118836 (28%)] Loss: 12218.666992\n",
      "Train Epoch: 3444 [65792/118836 (55%)] Loss: 12354.787109\n",
      "Train Epoch: 3444 [98560/118836 (83%)] Loss: 12264.849609\n",
      "    epoch          : 3444\n",
      "    loss           : 12194.435409881617\n",
      "    val_loss       : 12191.764574660016\n",
      "    val_log_likelihood: -12115.801187868332\n",
      "    val_log_marginal: -12124.587248569425\n",
      "Train Epoch: 3445 [256/118836 (0%)] Loss: 12210.402344\n",
      "Train Epoch: 3445 [33024/118836 (28%)] Loss: 12251.758789\n",
      "Train Epoch: 3445 [65792/118836 (55%)] Loss: 12248.301758\n",
      "Train Epoch: 3445 [98560/118836 (83%)] Loss: 12151.938477\n",
      "    epoch          : 3445\n",
      "    loss           : 12201.699811311\n",
      "    val_loss       : 12199.978064356448\n",
      "    val_log_likelihood: -12113.915260869004\n",
      "    val_log_marginal: -12123.223709843798\n",
      "Train Epoch: 3446 [256/118836 (0%)] Loss: 12252.458008\n",
      "Train Epoch: 3446 [33024/118836 (28%)] Loss: 12207.393555\n",
      "Train Epoch: 3446 [65792/118836 (55%)] Loss: 12194.598633\n",
      "Train Epoch: 3446 [98560/118836 (83%)] Loss: 12159.135742\n",
      "    epoch          : 3446\n",
      "    loss           : 12198.02933968543\n",
      "    val_loss       : 12198.098550955787\n",
      "    val_log_likelihood: -12111.021487929072\n",
      "    val_log_marginal: -12120.229971443636\n",
      "Train Epoch: 3447 [256/118836 (0%)] Loss: 12173.654297\n",
      "Train Epoch: 3447 [33024/118836 (28%)] Loss: 12236.964844\n",
      "Train Epoch: 3447 [65792/118836 (55%)] Loss: 12179.036133\n",
      "Train Epoch: 3447 [98560/118836 (83%)] Loss: 12190.675781\n",
      "    epoch          : 3447\n",
      "    loss           : 12194.377720643351\n",
      "    val_loss       : 12189.713614933931\n",
      "    val_log_likelihood: -12112.235353501084\n",
      "    val_log_marginal: -12121.266831929031\n",
      "Train Epoch: 3448 [256/118836 (0%)] Loss: 12182.833984\n",
      "Train Epoch: 3448 [33024/118836 (28%)] Loss: 12261.360352\n",
      "Train Epoch: 3448 [65792/118836 (55%)] Loss: 12257.372070\n",
      "Train Epoch: 3448 [98560/118836 (83%)] Loss: 12289.951172\n",
      "    epoch          : 3448\n",
      "    loss           : 12192.411424246537\n",
      "    val_loss       : 12193.041607720714\n",
      "    val_log_likelihood: -12110.721807795699\n",
      "    val_log_marginal: -12119.748635612668\n",
      "Train Epoch: 3449 [256/118836 (0%)] Loss: 12247.021484\n",
      "Train Epoch: 3449 [33024/118836 (28%)] Loss: 12189.625000\n",
      "Train Epoch: 3449 [65792/118836 (55%)] Loss: 12276.193359\n",
      "Train Epoch: 3449 [98560/118836 (83%)] Loss: 12224.150391\n",
      "    epoch          : 3449\n",
      "    loss           : 12195.576703532102\n",
      "    val_loss       : 12191.698717907919\n",
      "    val_log_likelihood: -12114.549034099722\n",
      "    val_log_marginal: -12123.511029433505\n",
      "Train Epoch: 3450 [256/118836 (0%)] Loss: 12265.752930\n",
      "Train Epoch: 3450 [33024/118836 (28%)] Loss: 12250.858398\n",
      "Train Epoch: 3450 [65792/118836 (55%)] Loss: 12195.606445\n",
      "Train Epoch: 3450 [98560/118836 (83%)] Loss: 12194.721680\n",
      "    epoch          : 3450\n",
      "    loss           : 12194.806568412687\n",
      "    val_loss       : 12197.235338001288\n",
      "    val_log_likelihood: -12112.45068415917\n",
      "    val_log_marginal: -12121.546596171906\n",
      "Train Epoch: 3451 [256/118836 (0%)] Loss: 12162.052734\n",
      "Train Epoch: 3451 [33024/118836 (28%)] Loss: 12282.217773\n",
      "Train Epoch: 3451 [65792/118836 (55%)] Loss: 12195.294922\n",
      "Train Epoch: 3451 [98560/118836 (83%)] Loss: 12196.750977\n",
      "    epoch          : 3451\n",
      "    loss           : 12194.3250807744\n",
      "    val_loss       : 12196.031038679446\n",
      "    val_log_likelihood: -12113.431967438224\n",
      "    val_log_marginal: -12122.474048941858\n",
      "Train Epoch: 3452 [256/118836 (0%)] Loss: 12189.802734\n",
      "Train Epoch: 3452 [33024/118836 (28%)] Loss: 12166.911133\n",
      "Train Epoch: 3452 [65792/118836 (55%)] Loss: 12302.978516\n",
      "Train Epoch: 3452 [98560/118836 (83%)] Loss: 12220.117188\n",
      "    epoch          : 3452\n",
      "    loss           : 12192.353521925403\n",
      "    val_loss       : 12192.837106073759\n",
      "    val_log_likelihood: -12115.898395335762\n",
      "    val_log_marginal: -12124.900860863616\n",
      "Train Epoch: 3453 [256/118836 (0%)] Loss: 12152.755859\n",
      "Train Epoch: 3453 [33024/118836 (28%)] Loss: 12126.078125\n",
      "Train Epoch: 3453 [65792/118836 (55%)] Loss: 12190.690430\n",
      "Train Epoch: 3453 [98560/118836 (83%)] Loss: 12258.000000\n",
      "    epoch          : 3453\n",
      "    loss           : 12196.082122686621\n",
      "    val_loss       : 12191.379291680914\n",
      "    val_log_likelihood: -12115.168105420285\n",
      "    val_log_marginal: -12124.13842589996\n",
      "Train Epoch: 3454 [256/118836 (0%)] Loss: 12227.042969\n",
      "Train Epoch: 3454 [33024/118836 (28%)] Loss: 12211.380859\n",
      "Train Epoch: 3454 [65792/118836 (55%)] Loss: 12340.984375\n",
      "Train Epoch: 3454 [98560/118836 (83%)] Loss: 12192.703125\n",
      "    epoch          : 3454\n",
      "    loss           : 12193.389560878051\n",
      "    val_loss       : 12190.508612161344\n",
      "    val_log_likelihood: -12109.801510642836\n",
      "    val_log_marginal: -12118.635103502787\n",
      "Train Epoch: 3455 [256/118836 (0%)] Loss: 12197.177734\n",
      "Train Epoch: 3455 [33024/118836 (28%)] Loss: 12132.744141\n",
      "Train Epoch: 3455 [65792/118836 (55%)] Loss: 12273.641602\n",
      "Train Epoch: 3455 [98560/118836 (83%)] Loss: 12192.948242\n",
      "    epoch          : 3455\n",
      "    loss           : 12196.90918905733\n",
      "    val_loss       : 12193.308686259797\n",
      "    val_log_likelihood: -12111.506990216605\n",
      "    val_log_marginal: -12120.351303831152\n",
      "Train Epoch: 3456 [256/118836 (0%)] Loss: 12175.917969\n",
      "Train Epoch: 3456 [33024/118836 (28%)] Loss: 12203.482422\n",
      "Train Epoch: 3456 [65792/118836 (55%)] Loss: 12199.444336\n",
      "Train Epoch: 3456 [98560/118836 (83%)] Loss: 12181.241211\n",
      "    epoch          : 3456\n",
      "    loss           : 12190.967274413253\n",
      "    val_loss       : 12195.564814953892\n",
      "    val_log_likelihood: -12116.28613297405\n",
      "    val_log_marginal: -12125.283436726955\n",
      "Train Epoch: 3457 [256/118836 (0%)] Loss: 12302.750977\n",
      "Train Epoch: 3457 [33024/118836 (28%)] Loss: 12258.822266\n",
      "Train Epoch: 3457 [65792/118836 (55%)] Loss: 12192.922852\n",
      "Train Epoch: 3457 [98560/118836 (83%)] Loss: 12265.570312\n",
      "    epoch          : 3457\n",
      "    loss           : 12193.041237754602\n",
      "    val_loss       : 12191.393836246756\n",
      "    val_log_likelihood: -12114.895059676128\n",
      "    val_log_marginal: -12123.950865709186\n",
      "Train Epoch: 3458 [256/118836 (0%)] Loss: 12178.022461\n",
      "Train Epoch: 3458 [33024/118836 (28%)] Loss: 12164.058594\n",
      "Train Epoch: 3458 [65792/118836 (55%)] Loss: 12212.395508\n",
      "Train Epoch: 3458 [98560/118836 (83%)] Loss: 12278.982422\n",
      "    epoch          : 3458\n",
      "    loss           : 12191.15851539883\n",
      "    val_loss       : 12199.607348261752\n",
      "    val_log_likelihood: -12112.380094441429\n",
      "    val_log_marginal: -12121.319926902568\n",
      "Train Epoch: 3459 [256/118836 (0%)] Loss: 12101.255859\n",
      "Train Epoch: 3459 [33024/118836 (28%)] Loss: 12198.832031\n",
      "Train Epoch: 3459 [65792/118836 (55%)] Loss: 12184.308594\n",
      "Train Epoch: 3459 [98560/118836 (83%)] Loss: 12112.213867\n",
      "    epoch          : 3459\n",
      "    loss           : 12189.767124819065\n",
      "    val_loss       : 12190.091344708662\n",
      "    val_log_likelihood: -12118.256747731855\n",
      "    val_log_marginal: -12127.180058776825\n",
      "Train Epoch: 3460 [256/118836 (0%)] Loss: 12121.300781\n",
      "Train Epoch: 3460 [33024/118836 (28%)] Loss: 12168.971680\n",
      "Train Epoch: 3460 [65792/118836 (55%)] Loss: 12138.372070\n",
      "Train Epoch: 3460 [98560/118836 (83%)] Loss: 12195.270508\n",
      "    epoch          : 3460\n",
      "    loss           : 12192.96166883142\n",
      "    val_loss       : 12191.03745097495\n",
      "    val_log_likelihood: -12114.418658563378\n",
      "    val_log_marginal: -12123.420757325826\n",
      "Train Epoch: 3461 [256/118836 (0%)] Loss: 12210.373047\n",
      "Train Epoch: 3461 [33024/118836 (28%)] Loss: 12260.546875\n",
      "Train Epoch: 3461 [65792/118836 (55%)] Loss: 12194.768555\n",
      "Train Epoch: 3461 [98560/118836 (83%)] Loss: 12183.062500\n",
      "    epoch          : 3461\n",
      "    loss           : 12191.463930837728\n",
      "    val_loss       : 12190.841691843016\n",
      "    val_log_likelihood: -12113.160907775022\n",
      "    val_log_marginal: -12121.915899955446\n",
      "Train Epoch: 3462 [256/118836 (0%)] Loss: 12166.455078\n",
      "Train Epoch: 3462 [33024/118836 (28%)] Loss: 12148.853516\n",
      "Train Epoch: 3462 [65792/118836 (55%)] Loss: 12316.702148\n",
      "Train Epoch: 3462 [98560/118836 (83%)] Loss: 12230.969727\n",
      "    epoch          : 3462\n",
      "    loss           : 12191.117595410722\n",
      "    val_loss       : 12194.266570085003\n",
      "    val_log_likelihood: -12116.136956388285\n",
      "    val_log_marginal: -12124.984674706782\n",
      "Train Epoch: 3463 [256/118836 (0%)] Loss: 12179.846680\n",
      "Train Epoch: 3463 [33024/118836 (28%)] Loss: 12259.902344\n",
      "Train Epoch: 3463 [65792/118836 (55%)] Loss: 12168.715820\n",
      "Train Epoch: 3463 [98560/118836 (83%)] Loss: 12245.044922\n",
      "    epoch          : 3463\n",
      "    loss           : 12190.974642654053\n",
      "    val_loss       : 12195.1184720004\n",
      "    val_log_likelihood: -12113.67854001887\n",
      "    val_log_marginal: -12122.632649853269\n",
      "Train Epoch: 3464 [256/118836 (0%)] Loss: 12122.655273\n",
      "Train Epoch: 3464 [33024/118836 (28%)] Loss: 12226.434570\n",
      "Train Epoch: 3464 [65792/118836 (55%)] Loss: 12155.153320\n",
      "Train Epoch: 3464 [98560/118836 (83%)] Loss: 12247.318359\n",
      "    epoch          : 3464\n",
      "    loss           : 12194.694055973428\n",
      "    val_loss       : 12191.427662738055\n",
      "    val_log_likelihood: -12116.201928084936\n",
      "    val_log_marginal: -12125.10771619798\n",
      "Train Epoch: 3465 [256/118836 (0%)] Loss: 12201.343750\n",
      "Train Epoch: 3465 [33024/118836 (28%)] Loss: 12148.113281\n",
      "Train Epoch: 3465 [65792/118836 (55%)] Loss: 12142.571289\n",
      "Train Epoch: 3465 [98560/118836 (83%)] Loss: 12227.805664\n",
      "    epoch          : 3465\n",
      "    loss           : 12188.253849061724\n",
      "    val_loss       : 12190.415639167488\n",
      "    val_log_likelihood: -12114.558565802057\n",
      "    val_log_marginal: -12123.330032422295\n",
      "Train Epoch: 3466 [256/118836 (0%)] Loss: 12270.156250\n",
      "Train Epoch: 3466 [33024/118836 (28%)] Loss: 12143.937500\n",
      "Train Epoch: 3466 [65792/118836 (55%)] Loss: 12260.876953\n",
      "Train Epoch: 3466 [98560/118836 (83%)] Loss: 12194.353516\n",
      "    epoch          : 3466\n",
      "    loss           : 12191.459701328577\n",
      "    val_loss       : 12193.362560263886\n",
      "    val_log_likelihood: -12112.332498933778\n",
      "    val_log_marginal: -12121.405706750567\n",
      "Train Epoch: 3467 [256/118836 (0%)] Loss: 12161.113281\n",
      "Train Epoch: 3467 [33024/118836 (28%)] Loss: 12196.754883\n",
      "Train Epoch: 3467 [65792/118836 (55%)] Loss: 12182.698242\n",
      "Train Epoch: 3467 [98560/118836 (83%)] Loss: 12142.017578\n",
      "    epoch          : 3467\n",
      "    loss           : 12192.832837701613\n",
      "    val_loss       : 12188.794268946978\n",
      "    val_log_likelihood: -12110.128648256565\n",
      "    val_log_marginal: -12118.99478783886\n",
      "Train Epoch: 3468 [256/118836 (0%)] Loss: 12247.776367\n",
      "Train Epoch: 3468 [33024/118836 (28%)] Loss: 12213.994141\n",
      "Train Epoch: 3468 [65792/118836 (55%)] Loss: 12213.964844\n",
      "Train Epoch: 3468 [98560/118836 (83%)] Loss: 12146.292969\n",
      "    epoch          : 3468\n",
      "    loss           : 12189.961773515044\n",
      "    val_loss       : 12190.741644457226\n",
      "    val_log_likelihood: -12116.056092813016\n",
      "    val_log_marginal: -12124.776539450042\n",
      "Train Epoch: 3469 [256/118836 (0%)] Loss: 12162.654297\n",
      "Train Epoch: 3469 [33024/118836 (28%)] Loss: 12202.228516\n",
      "Train Epoch: 3469 [65792/118836 (55%)] Loss: 12232.248047\n",
      "Train Epoch: 3469 [98560/118836 (83%)] Loss: 12197.318359\n",
      "    epoch          : 3469\n",
      "    loss           : 12192.01050228753\n",
      "    val_loss       : 12192.014842627514\n",
      "    val_log_likelihood: -12114.052004659068\n",
      "    val_log_marginal: -12123.099785076613\n",
      "Train Epoch: 3470 [256/118836 (0%)] Loss: 12183.284180\n",
      "Train Epoch: 3470 [33024/118836 (28%)] Loss: 12236.286133\n",
      "Train Epoch: 3470 [65792/118836 (55%)] Loss: 12163.638672\n",
      "Train Epoch: 3470 [98560/118836 (83%)] Loss: 12199.745117\n",
      "    epoch          : 3470\n",
      "    loss           : 12194.593479890404\n",
      "    val_loss       : 12193.649570639225\n",
      "    val_log_likelihood: -12113.952392537738\n",
      "    val_log_marginal: -12122.818586949754\n",
      "Train Epoch: 3471 [256/118836 (0%)] Loss: 12171.232422\n",
      "Train Epoch: 3471 [33024/118836 (28%)] Loss: 12241.467773\n",
      "Train Epoch: 3471 [65792/118836 (55%)] Loss: 12225.887695\n",
      "Train Epoch: 3471 [98560/118836 (83%)] Loss: 12280.437500\n",
      "    epoch          : 3471\n",
      "    loss           : 12192.41970233018\n",
      "    val_loss       : 12194.71883006146\n",
      "    val_log_likelihood: -12114.433416692515\n",
      "    val_log_marginal: -12123.177989203916\n",
      "Train Epoch: 3472 [256/118836 (0%)] Loss: 12179.935547\n",
      "Train Epoch: 3472 [33024/118836 (28%)] Loss: 12179.146484\n",
      "Train Epoch: 3472 [65792/118836 (55%)] Loss: 12183.318359\n",
      "Train Epoch: 3472 [98560/118836 (83%)] Loss: 12191.411133\n",
      "    epoch          : 3472\n",
      "    loss           : 12190.626447638802\n",
      "    val_loss       : 12194.507421719469\n",
      "    val_log_likelihood: -12114.958284707145\n",
      "    val_log_marginal: -12123.95993962751\n",
      "Train Epoch: 3473 [256/118836 (0%)] Loss: 12271.456055\n",
      "Train Epoch: 3473 [33024/118836 (28%)] Loss: 12203.248047\n",
      "Train Epoch: 3473 [65792/118836 (55%)] Loss: 12152.866211\n",
      "Train Epoch: 3473 [98560/118836 (83%)] Loss: 12263.309570\n",
      "    epoch          : 3473\n",
      "    loss           : 12192.166615778795\n",
      "    val_loss       : 12191.25117478815\n",
      "    val_log_likelihood: -12117.097224753154\n",
      "    val_log_marginal: -12126.230769687805\n",
      "Train Epoch: 3474 [256/118836 (0%)] Loss: 12178.638672\n",
      "Train Epoch: 3474 [33024/118836 (28%)] Loss: 12250.816406\n",
      "Train Epoch: 3474 [65792/118836 (55%)] Loss: 12241.234375\n",
      "Train Epoch: 3474 [98560/118836 (83%)] Loss: 12193.303711\n",
      "    epoch          : 3474\n",
      "    loss           : 12193.568324803557\n",
      "    val_loss       : 12189.546993922339\n",
      "    val_log_likelihood: -12110.28014290607\n",
      "    val_log_marginal: -12119.177197140598\n",
      "Train Epoch: 3475 [256/118836 (0%)] Loss: 12227.007812\n",
      "Train Epoch: 3475 [33024/118836 (28%)] Loss: 12230.919922\n",
      "Train Epoch: 3475 [65792/118836 (55%)] Loss: 12220.154297\n",
      "Train Epoch: 3475 [98560/118836 (83%)] Loss: 12190.782227\n",
      "    epoch          : 3475\n",
      "    loss           : 12192.141404311415\n",
      "    val_loss       : 12187.487413513796\n",
      "    val_log_likelihood: -12115.063051366056\n",
      "    val_log_marginal: -12123.86534751607\n",
      "Train Epoch: 3476 [256/118836 (0%)] Loss: 12220.752930\n",
      "Train Epoch: 3476 [33024/118836 (28%)] Loss: 12288.663086\n",
      "Train Epoch: 3476 [65792/118836 (55%)] Loss: 12258.154297\n",
      "Train Epoch: 3476 [98560/118836 (83%)] Loss: 12231.675781\n",
      "    epoch          : 3476\n",
      "    loss           : 12194.117439031483\n",
      "    val_loss       : 12192.309480219386\n",
      "    val_log_likelihood: -12109.175548296631\n",
      "    val_log_marginal: -12117.891907655305\n",
      "Train Epoch: 3477 [256/118836 (0%)] Loss: 12224.254883\n",
      "Train Epoch: 3477 [33024/118836 (28%)] Loss: 12220.136719\n",
      "Train Epoch: 3477 [65792/118836 (55%)] Loss: 12228.168945\n",
      "Train Epoch: 3477 [98560/118836 (83%)] Loss: 12197.887695\n",
      "    epoch          : 3477\n",
      "    loss           : 12192.822663681245\n",
      "    val_loss       : 12190.745749406628\n",
      "    val_log_likelihood: -12114.453374754445\n",
      "    val_log_marginal: -12123.300843162133\n",
      "Train Epoch: 3478 [256/118836 (0%)] Loss: 12223.535156\n",
      "Train Epoch: 3478 [33024/118836 (28%)] Loss: 12134.867188\n",
      "Train Epoch: 3478 [65792/118836 (55%)] Loss: 12226.355469\n",
      "Train Epoch: 3478 [98560/118836 (83%)] Loss: 12229.312500\n",
      "    epoch          : 3478\n",
      "    loss           : 12190.585682575993\n",
      "    val_loss       : 12190.218624435855\n",
      "    val_log_likelihood: -12116.573730387976\n",
      "    val_log_marginal: -12125.277505592143\n",
      "Train Epoch: 3479 [256/118836 (0%)] Loss: 12191.345703\n",
      "Train Epoch: 3479 [33024/118836 (28%)] Loss: 12231.488281\n",
      "Train Epoch: 3479 [65792/118836 (55%)] Loss: 12179.871094\n",
      "Train Epoch: 3479 [98560/118836 (83%)] Loss: 12140.013672\n",
      "    epoch          : 3479\n",
      "    loss           : 12187.869680359543\n",
      "    val_loss       : 12193.329181188394\n",
      "    val_log_likelihood: -12110.535346716035\n",
      "    val_log_marginal: -12119.371556020222\n",
      "Train Epoch: 3480 [256/118836 (0%)] Loss: 12249.333008\n",
      "Train Epoch: 3480 [33024/118836 (28%)] Loss: 12170.378906\n",
      "Train Epoch: 3480 [65792/118836 (55%)] Loss: 12149.188477\n",
      "Train Epoch: 3480 [98560/118836 (83%)] Loss: 12152.159180\n",
      "    epoch          : 3480\n",
      "    loss           : 12193.638936815032\n",
      "    val_loss       : 12193.87123174676\n",
      "    val_log_likelihood: -12115.32552648754\n",
      "    val_log_marginal: -12124.236452593412\n",
      "Train Epoch: 3481 [256/118836 (0%)] Loss: 12196.166016\n",
      "Train Epoch: 3481 [33024/118836 (28%)] Loss: 12219.620117\n",
      "Train Epoch: 3481 [65792/118836 (55%)] Loss: 12280.537109\n",
      "Train Epoch: 3481 [98560/118836 (83%)] Loss: 12102.564453\n",
      "    epoch          : 3481\n",
      "    loss           : 12192.13640502223\n",
      "    val_loss       : 12190.983183803888\n",
      "    val_log_likelihood: -12112.753109491316\n",
      "    val_log_marginal: -12121.534981247834\n",
      "Train Epoch: 3482 [256/118836 (0%)] Loss: 12227.916992\n",
      "Train Epoch: 3482 [33024/118836 (28%)] Loss: 12217.107422\n",
      "Train Epoch: 3482 [65792/118836 (55%)] Loss: 12202.703125\n",
      "Train Epoch: 3482 [98560/118836 (83%)] Loss: 12233.548828\n",
      "    epoch          : 3482\n",
      "    loss           : 12195.501859265147\n",
      "    val_loss       : 12190.534918913361\n",
      "    val_log_likelihood: -12115.53606819298\n",
      "    val_log_marginal: -12124.45342428318\n",
      "Train Epoch: 3483 [256/118836 (0%)] Loss: 12258.855469\n",
      "Train Epoch: 3483 [33024/118836 (28%)] Loss: 12206.315430\n",
      "Train Epoch: 3483 [65792/118836 (55%)] Loss: 12145.290039\n",
      "Train Epoch: 3483 [98560/118836 (83%)] Loss: 12126.536133\n",
      "    epoch          : 3483\n",
      "    loss           : 12191.765099158654\n",
      "    val_loss       : 12190.379194950414\n",
      "    val_log_likelihood: -12113.33635251887\n",
      "    val_log_marginal: -12122.20197798436\n",
      "Train Epoch: 3484 [256/118836 (0%)] Loss: 12127.653320\n",
      "Train Epoch: 3484 [33024/118836 (28%)] Loss: 12240.789062\n",
      "Train Epoch: 3484 [65792/118836 (55%)] Loss: 12220.080078\n",
      "Train Epoch: 3484 [98560/118836 (83%)] Loss: 12215.867188\n",
      "    epoch          : 3484\n",
      "    loss           : 12188.207007663876\n",
      "    val_loss       : 12189.517515390931\n",
      "    val_log_likelihood: -12114.941887988523\n",
      "    val_log_marginal: -12123.824231328133\n",
      "Train Epoch: 3485 [256/118836 (0%)] Loss: 12253.275391\n",
      "Train Epoch: 3485 [33024/118836 (28%)] Loss: 12162.660156\n",
      "Train Epoch: 3485 [65792/118836 (55%)] Loss: 12262.984375\n",
      "Train Epoch: 3485 [98560/118836 (83%)] Loss: 12227.964844\n",
      "    epoch          : 3485\n",
      "    loss           : 12191.48609678712\n",
      "    val_loss       : 12193.936604932329\n",
      "    val_log_likelihood: -12111.130675855564\n",
      "    val_log_marginal: -12120.048830162277\n",
      "Train Epoch: 3486 [256/118836 (0%)] Loss: 12160.577148\n",
      "Train Epoch: 3486 [33024/118836 (28%)] Loss: 12261.820312\n",
      "Train Epoch: 3486 [65792/118836 (55%)] Loss: 12212.939453\n",
      "Train Epoch: 3486 [98560/118836 (83%)] Loss: 12190.510742\n",
      "    epoch          : 3486\n",
      "    loss           : 12191.541204637097\n",
      "    val_loss       : 12191.699146530198\n",
      "    val_log_likelihood: -12117.003163448615\n",
      "    val_log_marginal: -12125.773339265226\n",
      "Train Epoch: 3487 [256/118836 (0%)] Loss: 12207.085938\n",
      "Train Epoch: 3487 [33024/118836 (28%)] Loss: 12215.139648\n",
      "Train Epoch: 3487 [65792/118836 (55%)] Loss: 12210.287109\n",
      "Train Epoch: 3487 [98560/118836 (83%)] Loss: 12196.301758\n",
      "    epoch          : 3487\n",
      "    loss           : 12191.381897164494\n",
      "    val_loss       : 12198.955701544566\n",
      "    val_log_likelihood: -12115.15400883349\n",
      "    val_log_marginal: -12124.010691810523\n",
      "Train Epoch: 3488 [256/118836 (0%)] Loss: 12181.880859\n",
      "Train Epoch: 3488 [33024/118836 (28%)] Loss: 12271.334961\n",
      "Train Epoch: 3488 [65792/118836 (55%)] Loss: 12183.907227\n",
      "Train Epoch: 3488 [98560/118836 (83%)] Loss: 12266.062500\n",
      "    epoch          : 3488\n",
      "    loss           : 12189.021235266748\n",
      "    val_loss       : 12189.353592428306\n",
      "    val_log_likelihood: -12111.421765308365\n",
      "    val_log_marginal: -12120.15522748179\n",
      "Train Epoch: 3489 [256/118836 (0%)] Loss: 12164.414062\n",
      "Train Epoch: 3489 [33024/118836 (28%)] Loss: 12361.615234\n",
      "Train Epoch: 3489 [65792/118836 (55%)] Loss: 12163.178711\n",
      "Train Epoch: 3489 [98560/118836 (83%)] Loss: 12204.789062\n",
      "    epoch          : 3489\n",
      "    loss           : 12194.79123516982\n",
      "    val_loss       : 12190.236693905392\n",
      "    val_log_likelihood: -12117.523916007549\n",
      "    val_log_marginal: -12126.427438575043\n",
      "Train Epoch: 3490 [256/118836 (0%)] Loss: 12333.524414\n",
      "Train Epoch: 3490 [33024/118836 (28%)] Loss: 12398.424805\n",
      "Train Epoch: 3490 [65792/118836 (55%)] Loss: 12229.231445\n",
      "Train Epoch: 3490 [98560/118836 (83%)] Loss: 12228.984375\n",
      "    epoch          : 3490\n",
      "    loss           : 12196.719362108406\n",
      "    val_loss       : 12196.489820255912\n",
      "    val_log_likelihood: -12117.612895309914\n",
      "    val_log_marginal: -12126.580281419336\n",
      "Train Epoch: 3491 [256/118836 (0%)] Loss: 12267.360352\n",
      "Train Epoch: 3491 [33024/118836 (28%)] Loss: 12212.958984\n",
      "Train Epoch: 3491 [65792/118836 (55%)] Loss: 12113.842773\n",
      "Train Epoch: 3491 [98560/118836 (83%)] Loss: 12302.151367\n",
      "    epoch          : 3491\n",
      "    loss           : 12192.567182168888\n",
      "    val_loss       : 12194.387411479125\n",
      "    val_log_likelihood: -12111.94215648263\n",
      "    val_log_marginal: -12120.858393544791\n",
      "Train Epoch: 3492 [256/118836 (0%)] Loss: 12153.103516\n",
      "Train Epoch: 3492 [33024/118836 (28%)] Loss: 12284.746094\n",
      "Train Epoch: 3492 [65792/118836 (55%)] Loss: 12230.215820\n",
      "Train Epoch: 3492 [98560/118836 (83%)] Loss: 12281.710938\n",
      "    epoch          : 3492\n",
      "    loss           : 12192.854768597499\n",
      "    val_loss       : 12192.985336288864\n",
      "    val_log_likelihood: -12110.369763234077\n",
      "    val_log_marginal: -12119.098607440417\n",
      "Train Epoch: 3493 [256/118836 (0%)] Loss: 12244.806641\n",
      "Train Epoch: 3493 [33024/118836 (28%)] Loss: 12325.853516\n",
      "Train Epoch: 3493 [65792/118836 (55%)] Loss: 12348.820312\n",
      "Train Epoch: 3493 [98560/118836 (83%)] Loss: 12180.347656\n",
      "    epoch          : 3493\n",
      "    loss           : 12190.373086939104\n",
      "    val_loss       : 12193.186506427903\n",
      "    val_log_likelihood: -12112.054715286393\n",
      "    val_log_marginal: -12120.916062127691\n",
      "Train Epoch: 3494 [256/118836 (0%)] Loss: 12250.526367\n",
      "Train Epoch: 3494 [33024/118836 (28%)] Loss: 12150.764648\n",
      "Train Epoch: 3494 [65792/118836 (55%)] Loss: 12196.218750\n",
      "Train Epoch: 3494 [98560/118836 (83%)] Loss: 12222.262695\n",
      "    epoch          : 3494\n",
      "    loss           : 12192.46077304332\n",
      "    val_loss       : 12193.626869521024\n",
      "    val_log_likelihood: -12113.856010100031\n",
      "    val_log_marginal: -12122.732022328593\n",
      "Train Epoch: 3495 [256/118836 (0%)] Loss: 12180.330078\n",
      "Train Epoch: 3495 [33024/118836 (28%)] Loss: 12189.802734\n",
      "Train Epoch: 3495 [65792/118836 (55%)] Loss: 12251.093750\n",
      "Train Epoch: 3495 [98560/118836 (83%)] Loss: 12275.453125\n",
      "    epoch          : 3495\n",
      "    loss           : 12191.435693399762\n",
      "    val_loss       : 12190.750265426419\n",
      "    val_log_likelihood: -12111.121172424266\n",
      "    val_log_marginal: -12120.007538456934\n",
      "Train Epoch: 3496 [256/118836 (0%)] Loss: 12150.332031\n",
      "Train Epoch: 3496 [33024/118836 (28%)] Loss: 12163.193359\n",
      "Train Epoch: 3496 [65792/118836 (55%)] Loss: 12205.136719\n",
      "Train Epoch: 3496 [98560/118836 (83%)] Loss: 12137.912109\n",
      "    epoch          : 3496\n",
      "    loss           : 12194.671420563225\n",
      "    val_loss       : 12193.069593267368\n",
      "    val_log_likelihood: -12113.454640166201\n",
      "    val_log_marginal: -12122.294410851628\n",
      "Train Epoch: 3497 [256/118836 (0%)] Loss: 12188.494141\n",
      "Train Epoch: 3497 [33024/118836 (28%)] Loss: 12220.792969\n",
      "Train Epoch: 3497 [65792/118836 (55%)] Loss: 12235.320312\n",
      "Train Epoch: 3497 [98560/118836 (83%)] Loss: 12207.078125\n",
      "    epoch          : 3497\n",
      "    loss           : 12193.058242542907\n",
      "    val_loss       : 12193.680359694199\n",
      "    val_log_likelihood: -12111.788024548956\n",
      "    val_log_marginal: -12120.607424378697\n",
      "Train Epoch: 3498 [256/118836 (0%)] Loss: 12235.172852\n",
      "Train Epoch: 3498 [33024/118836 (28%)] Loss: 12150.045898\n",
      "Train Epoch: 3498 [65792/118836 (55%)] Loss: 12302.738281\n",
      "Train Epoch: 3498 [98560/118836 (83%)] Loss: 12223.396484\n",
      "    epoch          : 3498\n",
      "    loss           : 12191.576833740435\n",
      "    val_loss       : 12193.8575406975\n",
      "    val_log_likelihood: -12111.726926630996\n",
      "    val_log_marginal: -12120.540841865784\n",
      "Train Epoch: 3499 [256/118836 (0%)] Loss: 12133.134766\n",
      "Train Epoch: 3499 [33024/118836 (28%)] Loss: 12179.973633\n",
      "Train Epoch: 3499 [65792/118836 (55%)] Loss: 12259.635742\n",
      "Train Epoch: 3499 [98560/118836 (83%)] Loss: 12226.267578\n",
      "    epoch          : 3499\n",
      "    loss           : 12193.293060671267\n",
      "    val_loss       : 12195.55050183221\n",
      "    val_log_likelihood: -12111.350177057486\n",
      "    val_log_marginal: -12120.129811340159\n",
      "Train Epoch: 3500 [256/118836 (0%)] Loss: 12309.434570\n",
      "Train Epoch: 3500 [33024/118836 (28%)] Loss: 12236.952148\n",
      "Train Epoch: 3500 [65792/118836 (55%)] Loss: 12173.692383\n",
      "Train Epoch: 3500 [98560/118836 (83%)] Loss: 12153.458984\n",
      "    epoch          : 3500\n",
      "    loss           : 12197.28655590881\n",
      "    val_loss       : 12197.438161269825\n",
      "    val_log_likelihood: -12109.233145452079\n",
      "    val_log_marginal: -12118.225558432065\n",
      "Saving checkpoint: saved/models/SelfiesAutoencodingOperad/0905_154251/checkpoint-epoch3500.pth ...\n",
      "Train Epoch: 3501 [256/118836 (0%)] Loss: 12115.186523\n",
      "Train Epoch: 3501 [33024/118836 (28%)] Loss: 12226.617188\n",
      "Train Epoch: 3501 [65792/118836 (55%)] Loss: 12223.241211\n",
      "Train Epoch: 3501 [98560/118836 (83%)] Loss: 12263.970703\n",
      "    epoch          : 3501\n",
      "    loss           : 12187.715942766492\n",
      "    val_loss       : 12197.236046447682\n",
      "    val_log_likelihood: -12114.800056057433\n",
      "    val_log_marginal: -12123.646740914613\n",
      "Train Epoch: 3502 [256/118836 (0%)] Loss: 12295.690430\n",
      "Train Epoch: 3502 [33024/118836 (28%)] Loss: 12210.052734\n",
      "Train Epoch: 3502 [65792/118836 (55%)] Loss: 12177.672852\n",
      "Train Epoch: 3502 [98560/118836 (83%)] Loss: 12182.580078\n",
      "    epoch          : 3502\n",
      "    loss           : 12193.285934915219\n",
      "    val_loss       : 12192.592367290124\n",
      "    val_log_likelihood: -12112.498596140922\n",
      "    val_log_marginal: -12121.281103301733\n",
      "Train Epoch: 3503 [256/118836 (0%)] Loss: 12227.065430\n",
      "Train Epoch: 3503 [33024/118836 (28%)] Loss: 12290.280273\n",
      "Train Epoch: 3503 [65792/118836 (55%)] Loss: 12205.208008\n",
      "Train Epoch: 3503 [98560/118836 (83%)] Loss: 12182.661133\n",
      "    epoch          : 3503\n",
      "    loss           : 12192.089044729631\n",
      "    val_loss       : 12191.909431314441\n",
      "    val_log_likelihood: -12113.007275350237\n",
      "    val_log_marginal: -12121.772328570332\n",
      "Train Epoch: 3504 [256/118836 (0%)] Loss: 12170.592773\n",
      "Train Epoch: 3504 [33024/118836 (28%)] Loss: 12211.596680\n",
      "Train Epoch: 3504 [65792/118836 (55%)] Loss: 12246.666016\n",
      "Train Epoch: 3504 [98560/118836 (83%)] Loss: 12186.202148\n",
      "    epoch          : 3504\n",
      "    loss           : 12194.864839065085\n",
      "    val_loss       : 12196.745874854914\n",
      "    val_log_likelihood: -12116.16833514268\n",
      "    val_log_marginal: -12124.933994810564\n",
      "Train Epoch: 3505 [256/118836 (0%)] Loss: 12313.209961\n",
      "Train Epoch: 3505 [33024/118836 (28%)] Loss: 12134.539062\n",
      "Train Epoch: 3505 [65792/118836 (55%)] Loss: 12259.195312\n",
      "Train Epoch: 3505 [98560/118836 (83%)] Loss: 12150.969727\n",
      "    epoch          : 3505\n",
      "    loss           : 12191.802724843621\n",
      "    val_loss       : 12191.10558197634\n",
      "    val_log_likelihood: -12112.352543585866\n",
      "    val_log_marginal: -12121.100000185888\n",
      "Train Epoch: 3506 [256/118836 (0%)] Loss: 12200.527344\n",
      "Train Epoch: 3506 [33024/118836 (28%)] Loss: 12243.594727\n",
      "Train Epoch: 3506 [65792/118836 (55%)] Loss: 12222.720703\n",
      "Train Epoch: 3506 [98560/118836 (83%)] Loss: 12170.217773\n",
      "    epoch          : 3506\n",
      "    loss           : 12191.718787317774\n",
      "    val_loss       : 12193.296772858122\n",
      "    val_log_likelihood: -12113.879512704198\n",
      "    val_log_marginal: -12122.68257478313\n",
      "Train Epoch: 3507 [256/118836 (0%)] Loss: 12215.764648\n",
      "Train Epoch: 3507 [33024/118836 (28%)] Loss: 12170.404297\n",
      "Train Epoch: 3507 [65792/118836 (55%)] Loss: 12167.410156\n",
      "Train Epoch: 3507 [98560/118836 (83%)] Loss: 12263.169922\n",
      "    epoch          : 3507\n",
      "    loss           : 12193.608547062397\n",
      "    val_loss       : 12189.7757873432\n",
      "    val_log_likelihood: -12114.370790845998\n",
      "    val_log_marginal: -12123.190106852508\n",
      "Train Epoch: 3508 [256/118836 (0%)] Loss: 12274.943359\n",
      "Train Epoch: 3508 [33024/118836 (28%)] Loss: 12267.635742\n",
      "Train Epoch: 3508 [65792/118836 (55%)] Loss: 12341.420898\n",
      "Train Epoch: 3508 [98560/118836 (83%)] Loss: 12189.304688\n",
      "    epoch          : 3508\n",
      "    loss           : 12189.77622970947\n",
      "    val_loss       : 12196.543770241871\n",
      "    val_log_likelihood: -12112.62467399452\n",
      "    val_log_marginal: -12121.431063466736\n",
      "Train Epoch: 3509 [256/118836 (0%)] Loss: 12153.324219\n",
      "Train Epoch: 3509 [33024/118836 (28%)] Loss: 12225.028320\n",
      "Train Epoch: 3509 [65792/118836 (55%)] Loss: 12165.052734\n",
      "Train Epoch: 3509 [98560/118836 (83%)] Loss: 12235.064453\n",
      "    epoch          : 3509\n",
      "    loss           : 12194.179469893765\n",
      "    val_loss       : 12191.604225470302\n",
      "    val_log_likelihood: -12116.869688598532\n",
      "    val_log_marginal: -12125.970609899821\n",
      "Train Epoch: 3510 [256/118836 (0%)] Loss: 12286.086914\n",
      "Train Epoch: 3510 [33024/118836 (28%)] Loss: 12187.593750\n",
      "Train Epoch: 3510 [65792/118836 (55%)] Loss: 12293.727539\n",
      "Train Epoch: 3510 [98560/118836 (83%)] Loss: 12180.708984\n",
      "    epoch          : 3510\n",
      "    loss           : 12192.362521809087\n",
      "    val_loss       : 12190.696651901577\n",
      "    val_log_likelihood: -12109.035497925714\n",
      "    val_log_marginal: -12118.035889125347\n",
      "Train Epoch: 3511 [256/118836 (0%)] Loss: 12131.375977\n",
      "Train Epoch: 3511 [33024/118836 (28%)] Loss: 12161.132812\n",
      "Train Epoch: 3511 [65792/118836 (55%)] Loss: 12226.271484\n",
      "Train Epoch: 3511 [98560/118836 (83%)] Loss: 12251.558594\n",
      "    epoch          : 3511\n",
      "    loss           : 12193.556244345793\n",
      "    val_loss       : 12192.693193452084\n",
      "    val_log_likelihood: -12114.361906792805\n",
      "    val_log_marginal: -12123.260797548804\n",
      "Train Epoch: 3512 [256/118836 (0%)] Loss: 12227.670898\n",
      "Train Epoch: 3512 [33024/118836 (28%)] Loss: 12224.720703\n",
      "Train Epoch: 3512 [65792/118836 (55%)] Loss: 12204.275391\n",
      "Train Epoch: 3512 [98560/118836 (83%)] Loss: 12166.274414\n",
      "    epoch          : 3512\n",
      "    loss           : 12190.804640812397\n",
      "    val_loss       : 12192.57500404192\n",
      "    val_log_likelihood: -12106.325163487387\n",
      "    val_log_marginal: -12115.192897024093\n",
      "Train Epoch: 3513 [256/118836 (0%)] Loss: 12176.355469\n",
      "Train Epoch: 3513 [33024/118836 (28%)] Loss: 12170.116211\n",
      "Train Epoch: 3513 [65792/118836 (55%)] Loss: 12222.107422\n",
      "Train Epoch: 3513 [98560/118836 (83%)] Loss: 12273.905273\n",
      "    epoch          : 3513\n",
      "    loss           : 12190.657552083334\n",
      "    val_loss       : 12190.595473214475\n",
      "    val_log_likelihood: -12111.271085995659\n",
      "    val_log_marginal: -12120.20531246436\n",
      "Train Epoch: 3514 [256/118836 (0%)] Loss: 12211.720703\n",
      "Train Epoch: 3514 [33024/118836 (28%)] Loss: 12222.608398\n",
      "Train Epoch: 3514 [65792/118836 (55%)] Loss: 12218.045898\n",
      "Train Epoch: 3514 [98560/118836 (83%)] Loss: 12333.038086\n",
      "    epoch          : 3514\n",
      "    loss           : 12197.783299731183\n",
      "    val_loss       : 12195.855263957084\n",
      "    val_log_likelihood: -12114.10943671164\n",
      "    val_log_marginal: -12122.997547751913\n",
      "Train Epoch: 3515 [256/118836 (0%)] Loss: 12168.169922\n",
      "Train Epoch: 3515 [33024/118836 (28%)] Loss: 12148.635742\n",
      "Train Epoch: 3515 [65792/118836 (55%)] Loss: 12145.385742\n",
      "Train Epoch: 3515 [98560/118836 (83%)] Loss: 12185.389648\n",
      "    epoch          : 3515\n",
      "    loss           : 12193.287807912015\n",
      "    val_loss       : 12191.960830500317\n",
      "    val_log_likelihood: -12117.898664152966\n",
      "    val_log_marginal: -12127.134698405021\n",
      "Train Epoch: 3516 [256/118836 (0%)] Loss: 12299.178711\n",
      "Train Epoch: 3516 [33024/118836 (28%)] Loss: 12264.968750\n",
      "Train Epoch: 3516 [65792/118836 (55%)] Loss: 12202.699219\n",
      "Train Epoch: 3516 [98560/118836 (83%)] Loss: 12236.708008\n",
      "    epoch          : 3516\n",
      "    loss           : 12191.669420589073\n",
      "    val_loss       : 12201.93522732915\n",
      "    val_log_likelihood: -12116.232122040426\n",
      "    val_log_marginal: -12125.357361180433\n",
      "Train Epoch: 3517 [256/118836 (0%)] Loss: 12252.279297\n",
      "Train Epoch: 3517 [33024/118836 (28%)] Loss: 12209.036133\n",
      "Train Epoch: 3517 [65792/118836 (55%)] Loss: 12257.134766\n",
      "Train Epoch: 3517 [98560/118836 (83%)] Loss: 12128.831055\n",
      "    epoch          : 3517\n",
      "    loss           : 12195.749848951871\n",
      "    val_loss       : 12189.885020081196\n",
      "    val_log_likelihood: -12114.875779634513\n",
      "    val_log_marginal: -12123.876715975312\n",
      "Train Epoch: 3518 [256/118836 (0%)] Loss: 12187.048828\n",
      "Train Epoch: 3518 [33024/118836 (28%)] Loss: 12270.220703\n",
      "Train Epoch: 3518 [65792/118836 (55%)] Loss: 12152.453125\n",
      "Train Epoch: 3518 [98560/118836 (83%)] Loss: 12201.891602\n",
      "    epoch          : 3518\n",
      "    loss           : 12189.020652398678\n",
      "    val_loss       : 12191.979422612409\n",
      "    val_log_likelihood: -12112.426771867245\n",
      "    val_log_marginal: -12121.331981143683\n",
      "Train Epoch: 3519 [256/118836 (0%)] Loss: 12204.005859\n",
      "Train Epoch: 3519 [33024/118836 (28%)] Loss: 12186.001953\n",
      "Train Epoch: 3519 [65792/118836 (55%)] Loss: 12169.253906\n",
      "Train Epoch: 3519 [98560/118836 (83%)] Loss: 12228.251953\n",
      "    epoch          : 3519\n",
      "    loss           : 12191.320070661446\n",
      "    val_loss       : 12189.803455322033\n",
      "    val_log_likelihood: -12113.312676895937\n",
      "    val_log_marginal: -12122.038106859805\n",
      "Train Epoch: 3520 [256/118836 (0%)] Loss: 12211.590820\n",
      "Train Epoch: 3520 [33024/118836 (28%)] Loss: 12273.074219\n",
      "Train Epoch: 3520 [65792/118836 (55%)] Loss: 12161.205078\n",
      "Train Epoch: 3520 [98560/118836 (83%)] Loss: 12177.042969\n",
      "    epoch          : 3520\n",
      "    loss           : 12192.501225024556\n",
      "    val_loss       : 12189.678400432336\n",
      "    val_log_likelihood: -12116.616510448977\n",
      "    val_log_marginal: -12125.384295739444\n",
      "Train Epoch: 3521 [256/118836 (0%)] Loss: 12303.871094\n",
      "Train Epoch: 3521 [33024/118836 (28%)] Loss: 12187.492188\n",
      "Train Epoch: 3521 [65792/118836 (55%)] Loss: 12202.178711\n",
      "Train Epoch: 3521 [98560/118836 (83%)] Loss: 12218.542969\n",
      "    epoch          : 3521\n",
      "    loss           : 12192.022399387406\n",
      "    val_loss       : 12193.309788642096\n",
      "    val_log_likelihood: -12114.111372066272\n",
      "    val_log_marginal: -12122.912449295001\n",
      "Train Epoch: 3522 [256/118836 (0%)] Loss: 12205.097656\n",
      "Train Epoch: 3522 [33024/118836 (28%)] Loss: 12234.086914\n",
      "Train Epoch: 3522 [65792/118836 (55%)] Loss: 12176.827148\n",
      "Train Epoch: 3522 [98560/118836 (83%)] Loss: 12241.871094\n",
      "    epoch          : 3522\n",
      "    loss           : 12193.345078092689\n",
      "    val_loss       : 12194.380024632337\n",
      "    val_log_likelihood: -12111.296800364455\n",
      "    val_log_marginal: -12120.147575223165\n",
      "Train Epoch: 3523 [256/118836 (0%)] Loss: 12247.221680\n",
      "Train Epoch: 3523 [33024/118836 (28%)] Loss: 12176.017578\n",
      "Train Epoch: 3523 [65792/118836 (55%)] Loss: 12201.400391\n",
      "Train Epoch: 3523 [98560/118836 (83%)] Loss: 12213.534180\n",
      "    epoch          : 3523\n",
      "    loss           : 12191.828054564723\n",
      "    val_loss       : 12188.147949591694\n",
      "    val_log_likelihood: -12111.548793392007\n",
      "    val_log_marginal: -12120.364878076118\n",
      "Train Epoch: 3524 [256/118836 (0%)] Loss: 12306.759766\n",
      "Train Epoch: 3524 [33024/118836 (28%)] Loss: 12280.088867\n",
      "Train Epoch: 3524 [65792/118836 (55%)] Loss: 12270.557617\n",
      "Train Epoch: 3524 [98560/118836 (83%)] Loss: 12151.460938\n",
      "    epoch          : 3524\n",
      "    loss           : 12193.615395439154\n",
      "    val_loss       : 12190.143551666988\n",
      "    val_log_likelihood: -12111.048241541304\n",
      "    val_log_marginal: -12119.885909902985\n",
      "Train Epoch: 3525 [256/118836 (0%)] Loss: 12183.896484\n",
      "Train Epoch: 3525 [33024/118836 (28%)] Loss: 12205.867188\n",
      "Train Epoch: 3525 [65792/118836 (55%)] Loss: 12218.028320\n",
      "Train Epoch: 3525 [98560/118836 (83%)] Loss: 12240.287109\n",
      "    epoch          : 3525\n",
      "    loss           : 12193.79229913022\n",
      "    val_loss       : 12195.760242602068\n",
      "    val_log_likelihood: -12114.26015899633\n",
      "    val_log_marginal: -12123.462283943178\n",
      "Train Epoch: 3526 [256/118836 (0%)] Loss: 12219.450195\n",
      "Train Epoch: 3526 [33024/118836 (28%)] Loss: 12217.861328\n",
      "Train Epoch: 3526 [65792/118836 (55%)] Loss: 12197.582031\n",
      "Train Epoch: 3526 [98560/118836 (83%)] Loss: 12237.751953\n",
      "    epoch          : 3526\n",
      "    loss           : 12192.712962998863\n",
      "    val_loss       : 12192.009240153144\n",
      "    val_log_likelihood: -12110.373598402606\n",
      "    val_log_marginal: -12119.300607233032\n",
      "Train Epoch: 3527 [256/118836 (0%)] Loss: 12126.715820\n",
      "Train Epoch: 3527 [33024/118836 (28%)] Loss: 12247.140625\n",
      "Train Epoch: 3527 [65792/118836 (55%)] Loss: 12235.829102\n",
      "Train Epoch: 3527 [98560/118836 (83%)] Loss: 12181.292969\n",
      "    epoch          : 3527\n",
      "    loss           : 12191.818288455077\n",
      "    val_loss       : 12192.342920532748\n",
      "    val_log_likelihood: -12116.780077801903\n",
      "    val_log_marginal: -12125.801993698075\n",
      "Train Epoch: 3528 [256/118836 (0%)] Loss: 12109.142578\n",
      "Train Epoch: 3528 [33024/118836 (28%)] Loss: 12190.995117\n",
      "Train Epoch: 3528 [65792/118836 (55%)] Loss: 12256.297852\n",
      "Train Epoch: 3528 [98560/118836 (83%)] Loss: 12247.895508\n",
      "    epoch          : 3528\n",
      "    loss           : 12190.459980323356\n",
      "    val_loss       : 12187.175611087294\n",
      "    val_log_likelihood: -12113.119889726788\n",
      "    val_log_marginal: -12122.02802320947\n",
      "Train Epoch: 3529 [256/118836 (0%)] Loss: 12253.939453\n",
      "Train Epoch: 3529 [33024/118836 (28%)] Loss: 12203.717773\n",
      "Train Epoch: 3529 [65792/118836 (55%)] Loss: 12215.869141\n",
      "Train Epoch: 3529 [98560/118836 (83%)] Loss: 12206.704102\n",
      "    epoch          : 3529\n",
      "    loss           : 12198.017593795234\n",
      "    val_loss       : 12192.102565652005\n",
      "    val_log_likelihood: -12113.041425474306\n",
      "    val_log_marginal: -12122.01788760132\n",
      "Train Epoch: 3530 [256/118836 (0%)] Loss: 12218.791016\n",
      "Train Epoch: 3530 [33024/118836 (28%)] Loss: 12151.599609\n",
      "Train Epoch: 3530 [65792/118836 (55%)] Loss: 12267.212891\n",
      "Train Epoch: 3530 [98560/118836 (83%)] Loss: 12206.630859\n",
      "    epoch          : 3530\n",
      "    loss           : 12195.098534752378\n",
      "    val_loss       : 12190.586057905859\n",
      "    val_log_likelihood: -12111.285211015043\n",
      "    val_log_marginal: -12120.278837574733\n",
      "Train Epoch: 3531 [256/118836 (0%)] Loss: 12197.138672\n",
      "Train Epoch: 3531 [33024/118836 (28%)] Loss: 12171.742188\n",
      "Train Epoch: 3531 [65792/118836 (55%)] Loss: 12275.581055\n",
      "Train Epoch: 3531 [98560/118836 (83%)] Loss: 12179.644531\n",
      "    epoch          : 3531\n",
      "    loss           : 12190.160216023056\n",
      "    val_loss       : 12194.170767154696\n",
      "    val_log_likelihood: -12114.524248151882\n",
      "    val_log_marginal: -12123.591163921104\n",
      "Train Epoch: 3532 [256/118836 (0%)] Loss: 12336.513672\n",
      "Train Epoch: 3532 [33024/118836 (28%)] Loss: 12161.070312\n",
      "Train Epoch: 3532 [65792/118836 (55%)] Loss: 12254.392578\n",
      "Train Epoch: 3532 [98560/118836 (83%)] Loss: 12193.212891\n",
      "    epoch          : 3532\n",
      "    loss           : 12189.120040613368\n",
      "    val_loss       : 12192.192638486502\n",
      "    val_log_likelihood: -12111.438749741523\n",
      "    val_log_marginal: -12120.268838047323\n",
      "Train Epoch: 3533 [256/118836 (0%)] Loss: 12196.069336\n",
      "Train Epoch: 3533 [33024/118836 (28%)] Loss: 12262.398438\n",
      "Train Epoch: 3533 [65792/118836 (55%)] Loss: 12203.339844\n",
      "Train Epoch: 3533 [98560/118836 (83%)] Loss: 12270.097656\n",
      "    epoch          : 3533\n",
      "    loss           : 12193.854903652295\n",
      "    val_loss       : 12193.860794216485\n",
      "    val_log_likelihood: -12114.407353378308\n",
      "    val_log_marginal: -12123.453624057784\n",
      "Train Epoch: 3534 [256/118836 (0%)] Loss: 12114.499023\n",
      "Train Epoch: 3534 [33024/118836 (28%)] Loss: 12236.523438\n",
      "Train Epoch: 3534 [65792/118836 (55%)] Loss: 12286.890625\n",
      "Train Epoch: 3534 [98560/118836 (83%)] Loss: 12137.830078\n",
      "    epoch          : 3534\n",
      "    loss           : 12189.987131668735\n",
      "    val_loss       : 12192.007315572528\n",
      "    val_log_likelihood: -12112.128591714485\n",
      "    val_log_marginal: -12120.9782080297\n",
      "Train Epoch: 3535 [256/118836 (0%)] Loss: 12167.058594\n",
      "Train Epoch: 3535 [33024/118836 (28%)] Loss: 12139.531250\n",
      "Train Epoch: 3535 [65792/118836 (55%)] Loss: 12278.038086\n",
      "Train Epoch: 3535 [98560/118836 (83%)] Loss: 12204.779297\n",
      "    epoch          : 3535\n",
      "    loss           : 12191.636453809968\n",
      "    val_loss       : 12189.876043511851\n",
      "    val_log_likelihood: -12112.288961208902\n",
      "    val_log_marginal: -12121.155164686857\n",
      "Train Epoch: 3536 [256/118836 (0%)] Loss: 12177.828125\n",
      "Train Epoch: 3536 [33024/118836 (28%)] Loss: 12183.318359\n",
      "Train Epoch: 3536 [65792/118836 (55%)] Loss: 12180.424805\n",
      "Train Epoch: 3536 [98560/118836 (83%)] Loss: 12278.798828\n",
      "    epoch          : 3536\n",
      "    loss           : 12192.555671816843\n",
      "    val_loss       : 12197.396691801283\n",
      "    val_log_likelihood: -12112.229744526725\n",
      "    val_log_marginal: -12121.291848424553\n",
      "Train Epoch: 3537 [256/118836 (0%)] Loss: 12301.494141\n",
      "Train Epoch: 3537 [33024/118836 (28%)] Loss: 12189.857422\n",
      "Train Epoch: 3537 [65792/118836 (55%)] Loss: 12250.505859\n",
      "Train Epoch: 3537 [98560/118836 (83%)] Loss: 12264.203125\n",
      "    epoch          : 3537\n",
      "    loss           : 12189.516602047146\n",
      "    val_loss       : 12192.329784257327\n",
      "    val_log_likelihood: -12117.218834166926\n",
      "    val_log_marginal: -12126.100213336013\n",
      "Train Epoch: 3538 [256/118836 (0%)] Loss: 12200.078125\n",
      "Train Epoch: 3538 [33024/118836 (28%)] Loss: 12192.476562\n",
      "Train Epoch: 3538 [65792/118836 (55%)] Loss: 12298.187500\n",
      "Train Epoch: 3538 [98560/118836 (83%)] Loss: 12287.158203\n",
      "    epoch          : 3538\n",
      "    loss           : 12191.340304325631\n",
      "    val_loss       : 12189.890233995508\n",
      "    val_log_likelihood: -12113.393984891956\n",
      "    val_log_marginal: -12122.301503445206\n",
      "Train Epoch: 3539 [256/118836 (0%)] Loss: 12160.866211\n",
      "Train Epoch: 3539 [33024/118836 (28%)] Loss: 12233.791992\n",
      "Train Epoch: 3539 [65792/118836 (55%)] Loss: 12171.731445\n",
      "Train Epoch: 3539 [98560/118836 (83%)] Loss: 12345.089844\n",
      "    epoch          : 3539\n",
      "    loss           : 12189.76569640457\n",
      "    val_loss       : 12191.912709580118\n",
      "    val_log_likelihood: -12113.894060658344\n",
      "    val_log_marginal: -12122.7918455791\n",
      "Train Epoch: 3540 [256/118836 (0%)] Loss: 12191.830078\n",
      "Train Epoch: 3540 [33024/118836 (28%)] Loss: 12141.580078\n",
      "Train Epoch: 3540 [65792/118836 (55%)] Loss: 12258.025391\n",
      "Train Epoch: 3540 [98560/118836 (83%)] Loss: 12202.283203\n",
      "    epoch          : 3540\n",
      "    loss           : 12193.901300790942\n",
      "    val_loss       : 12192.399953808354\n",
      "    val_log_likelihood: -12113.72176595456\n",
      "    val_log_marginal: -12122.789494623197\n",
      "Train Epoch: 3541 [256/118836 (0%)] Loss: 12245.437500\n",
      "Train Epoch: 3541 [33024/118836 (28%)] Loss: 12259.073242\n",
      "Train Epoch: 3541 [65792/118836 (55%)] Loss: 12181.914062\n",
      "Train Epoch: 3541 [98560/118836 (83%)] Loss: 12128.039062\n",
      "    epoch          : 3541\n",
      "    loss           : 12188.43690340028\n",
      "    val_loss       : 12193.809815181206\n",
      "    val_log_likelihood: -12112.551954740487\n",
      "    val_log_marginal: -12121.438171625046\n",
      "Train Epoch: 3542 [256/118836 (0%)] Loss: 12144.355469\n",
      "Train Epoch: 3542 [33024/118836 (28%)] Loss: 12254.339844\n",
      "Train Epoch: 3542 [65792/118836 (55%)] Loss: 12127.021484\n",
      "Train Epoch: 3542 [98560/118836 (83%)] Loss: 12209.630859\n",
      "    epoch          : 3542\n",
      "    loss           : 12192.402447948978\n",
      "    val_loss       : 12192.335819864025\n",
      "    val_log_likelihood: -12114.245261127482\n",
      "    val_log_marginal: -12123.257376078811\n",
      "Train Epoch: 3543 [256/118836 (0%)] Loss: 12198.492188\n",
      "Train Epoch: 3543 [33024/118836 (28%)] Loss: 12187.447266\n",
      "Train Epoch: 3543 [65792/118836 (55%)] Loss: 12168.839844\n",
      "Train Epoch: 3543 [98560/118836 (83%)] Loss: 12195.321289\n",
      "    epoch          : 3543\n",
      "    loss           : 12192.056481984078\n",
      "    val_loss       : 12188.871852354301\n",
      "    val_log_likelihood: -12115.323227648109\n",
      "    val_log_marginal: -12124.196483224723\n",
      "Train Epoch: 3544 [256/118836 (0%)] Loss: 12269.852539\n",
      "Train Epoch: 3544 [33024/118836 (28%)] Loss: 12208.409180\n",
      "Train Epoch: 3544 [65792/118836 (55%)] Loss: 12180.365234\n",
      "Train Epoch: 3544 [98560/118836 (83%)] Loss: 12190.259766\n",
      "    epoch          : 3544\n",
      "    loss           : 12189.008002642939\n",
      "    val_loss       : 12190.399166039224\n",
      "    val_log_likelihood: -12111.941836939102\n",
      "    val_log_marginal: -12120.78466337421\n",
      "Train Epoch: 3545 [256/118836 (0%)] Loss: 12159.885742\n",
      "Train Epoch: 3545 [33024/118836 (28%)] Loss: 12161.679688\n",
      "Train Epoch: 3545 [65792/118836 (55%)] Loss: 12258.184570\n",
      "Train Epoch: 3545 [98560/118836 (83%)] Loss: 12256.189453\n",
      "    epoch          : 3545\n",
      "    loss           : 12190.264732765972\n",
      "    val_loss       : 12190.342735388764\n",
      "    val_log_likelihood: -12110.959875639732\n",
      "    val_log_marginal: -12119.832620136842\n",
      "Train Epoch: 3546 [256/118836 (0%)] Loss: 12124.830078\n",
      "Train Epoch: 3546 [33024/118836 (28%)] Loss: 12176.587891\n",
      "Train Epoch: 3546 [65792/118836 (55%)] Loss: 12133.742188\n",
      "Train Epoch: 3546 [98560/118836 (83%)] Loss: 12212.708984\n",
      "    epoch          : 3546\n",
      "    loss           : 12192.456541595586\n",
      "    val_loss       : 12192.16266626046\n",
      "    val_log_likelihood: -12110.857762258323\n",
      "    val_log_marginal: -12119.598912792315\n",
      "Train Epoch: 3547 [256/118836 (0%)] Loss: 12284.958008\n",
      "Train Epoch: 3547 [33024/118836 (28%)] Loss: 12147.957031\n",
      "Train Epoch: 3547 [65792/118836 (55%)] Loss: 12265.928711\n",
      "Train Epoch: 3547 [98560/118836 (83%)] Loss: 12253.505859\n",
      "    epoch          : 3547\n",
      "    loss           : 12189.318190394955\n",
      "    val_loss       : 12190.98383250135\n",
      "    val_log_likelihood: -12111.355557763389\n",
      "    val_log_marginal: -12120.139903611542\n",
      "Train Epoch: 3548 [256/118836 (0%)] Loss: 12181.566406\n",
      "Train Epoch: 3548 [33024/118836 (28%)] Loss: 12170.559570\n",
      "Train Epoch: 3548 [65792/118836 (55%)] Loss: 12174.597656\n",
      "Train Epoch: 3548 [98560/118836 (83%)] Loss: 12337.130859\n",
      "    epoch          : 3548\n",
      "    loss           : 12193.200950068496\n",
      "    val_loss       : 12192.982579686382\n",
      "    val_log_likelihood: -12112.513419535775\n",
      "    val_log_marginal: -12121.494870015566\n",
      "Train Epoch: 3549 [256/118836 (0%)] Loss: 12223.582031\n",
      "Train Epoch: 3549 [33024/118836 (28%)] Loss: 12190.250977\n",
      "Train Epoch: 3549 [65792/118836 (55%)] Loss: 12192.540039\n",
      "Train Epoch: 3549 [98560/118836 (83%)] Loss: 12190.222656\n",
      "    epoch          : 3549\n",
      "    loss           : 12191.295001195462\n",
      "    val_loss       : 12191.509046268073\n",
      "    val_log_likelihood: -12112.017574570928\n",
      "    val_log_marginal: -12120.944708678084\n",
      "Train Epoch: 3550 [256/118836 (0%)] Loss: 12146.569336\n",
      "Train Epoch: 3550 [33024/118836 (28%)] Loss: 12113.615234\n",
      "Train Epoch: 3550 [65792/118836 (55%)] Loss: 12168.775391\n",
      "Train Epoch: 3550 [98560/118836 (83%)] Loss: 12217.873047\n",
      "    epoch          : 3550\n",
      "    loss           : 12189.167044044665\n",
      "    val_loss       : 12187.446183475686\n",
      "    val_log_likelihood: -12112.444745948356\n",
      "    val_log_marginal: -12121.37043308265\n",
      "Train Epoch: 3551 [256/118836 (0%)] Loss: 12273.324219\n",
      "Train Epoch: 3551 [33024/118836 (28%)] Loss: 12213.332031\n",
      "Train Epoch: 3551 [65792/118836 (55%)] Loss: 12161.916016\n",
      "Train Epoch: 3551 [98560/118836 (83%)] Loss: 12148.283203\n",
      "    epoch          : 3551\n",
      "    loss           : 12188.699309378877\n",
      "    val_loss       : 12189.52697356115\n",
      "    val_log_likelihood: -12110.183005550816\n",
      "    val_log_marginal: -12119.065601640752\n",
      "Train Epoch: 3552 [256/118836 (0%)] Loss: 12139.703125\n",
      "Train Epoch: 3552 [33024/118836 (28%)] Loss: 12178.196289\n",
      "Train Epoch: 3552 [65792/118836 (55%)] Loss: 12265.104492\n",
      "Train Epoch: 3552 [98560/118836 (83%)] Loss: 12234.670898\n",
      "    epoch          : 3552\n",
      "    loss           : 12190.130136605667\n",
      "    val_loss       : 12193.407018414617\n",
      "    val_log_likelihood: -12110.599278361506\n",
      "    val_log_marginal: -12119.415736083332\n",
      "Train Epoch: 3553 [256/118836 (0%)] Loss: 12341.563477\n",
      "Train Epoch: 3553 [33024/118836 (28%)] Loss: 12317.388672\n",
      "Train Epoch: 3553 [65792/118836 (55%)] Loss: 12151.467773\n",
      "Train Epoch: 3553 [98560/118836 (83%)] Loss: 12168.164062\n",
      "    epoch          : 3553\n",
      "    loss           : 12193.800940052472\n",
      "    val_loss       : 12190.081062843105\n",
      "    val_log_likelihood: -12110.396570803608\n",
      "    val_log_marginal: -12119.202357155646\n",
      "Train Epoch: 3554 [256/118836 (0%)] Loss: 12168.689453\n",
      "Train Epoch: 3554 [33024/118836 (28%)] Loss: 12175.347656\n",
      "Train Epoch: 3554 [65792/118836 (55%)] Loss: 12114.160156\n",
      "Train Epoch: 3554 [98560/118836 (83%)] Loss: 12284.751953\n",
      "    epoch          : 3554\n",
      "    loss           : 12186.935633465157\n",
      "    val_loss       : 12191.62272714481\n",
      "    val_log_likelihood: -12112.450428265869\n",
      "    val_log_marginal: -12121.345333469213\n",
      "Train Epoch: 3555 [256/118836 (0%)] Loss: 12181.305664\n",
      "Train Epoch: 3555 [33024/118836 (28%)] Loss: 12261.720703\n",
      "Train Epoch: 3555 [65792/118836 (55%)] Loss: 12224.595703\n",
      "Train Epoch: 3555 [98560/118836 (83%)] Loss: 12299.210938\n",
      "    epoch          : 3555\n",
      "    loss           : 12192.275893364867\n",
      "    val_loss       : 12188.427758078426\n",
      "    val_log_likelihood: -12113.471840105458\n",
      "    val_log_marginal: -12122.465771336301\n",
      "Train Epoch: 3556 [256/118836 (0%)] Loss: 12188.599609\n",
      "Train Epoch: 3556 [33024/118836 (28%)] Loss: 12198.112305\n",
      "Train Epoch: 3556 [65792/118836 (55%)] Loss: 12218.690430\n",
      "Train Epoch: 3556 [98560/118836 (83%)] Loss: 12258.020508\n",
      "    epoch          : 3556\n",
      "    loss           : 12188.03570583902\n",
      "    val_loss       : 12194.248830605013\n",
      "    val_log_likelihood: -12112.400465422095\n",
      "    val_log_marginal: -12121.321293620887\n",
      "Train Epoch: 3557 [256/118836 (0%)] Loss: 12166.234375\n",
      "Train Epoch: 3557 [33024/118836 (28%)] Loss: 12191.167969\n",
      "Train Epoch: 3557 [65792/118836 (55%)] Loss: 12255.277344\n",
      "Train Epoch: 3557 [98560/118836 (83%)] Loss: 12236.586914\n",
      "    epoch          : 3557\n",
      "    loss           : 12186.953125646196\n",
      "    val_loss       : 12192.571852805504\n",
      "    val_log_likelihood: -12108.718286678039\n",
      "    val_log_marginal: -12117.543796896027\n",
      "Train Epoch: 3558 [256/118836 (0%)] Loss: 12154.400391\n",
      "Train Epoch: 3558 [33024/118836 (28%)] Loss: 12129.703125\n",
      "Train Epoch: 3558 [65792/118836 (55%)] Loss: 12164.473633\n",
      "Train Epoch: 3558 [98560/118836 (83%)] Loss: 12212.322266\n",
      "    epoch          : 3558\n",
      "    loss           : 12189.582404427729\n",
      "    val_loss       : 12196.969116700824\n",
      "    val_log_likelihood: -12110.712655733043\n",
      "    val_log_marginal: -12119.66639868628\n",
      "Train Epoch: 3559 [256/118836 (0%)] Loss: 12242.962891\n",
      "Train Epoch: 3559 [33024/118836 (28%)] Loss: 12170.657227\n",
      "Train Epoch: 3559 [65792/118836 (55%)] Loss: 12130.245117\n",
      "Train Epoch: 3559 [98560/118836 (83%)] Loss: 12312.234375\n",
      "    epoch          : 3559\n",
      "    loss           : 12192.26786228934\n",
      "    val_loss       : 12188.288211099023\n",
      "    val_log_likelihood: -12114.100816467639\n",
      "    val_log_marginal: -12123.045212962132\n",
      "Train Epoch: 3560 [256/118836 (0%)] Loss: 12177.098633\n",
      "Train Epoch: 3560 [33024/118836 (28%)] Loss: 12220.155273\n",
      "Train Epoch: 3560 [65792/118836 (55%)] Loss: 12203.292969\n",
      "Train Epoch: 3560 [98560/118836 (83%)] Loss: 12219.148438\n",
      "    epoch          : 3560\n",
      "    loss           : 12189.812445396505\n",
      "    val_loss       : 12195.745350628822\n",
      "    val_log_likelihood: -12114.846341727409\n",
      "    val_log_marginal: -12123.815751088889\n",
      "Train Epoch: 3561 [256/118836 (0%)] Loss: 12204.637695\n",
      "Train Epoch: 3561 [33024/118836 (28%)] Loss: 12281.260742\n",
      "Train Epoch: 3561 [65792/118836 (55%)] Loss: 12150.161133\n",
      "Train Epoch: 3561 [98560/118836 (83%)] Loss: 12252.838867\n",
      "    epoch          : 3561\n",
      "    loss           : 12191.835206814776\n",
      "    val_loss       : 12190.365087046766\n",
      "    val_log_likelihood: -12113.39505240643\n",
      "    val_log_marginal: -12122.270262993045\n",
      "Train Epoch: 3562 [256/118836 (0%)] Loss: 12149.385742\n",
      "Train Epoch: 3562 [33024/118836 (28%)] Loss: 12165.125977\n",
      "Train Epoch: 3562 [65792/118836 (55%)] Loss: 12164.421875\n",
      "Train Epoch: 3562 [98560/118836 (83%)] Loss: 12311.392578\n",
      "    epoch          : 3562\n",
      "    loss           : 12191.85011712288\n",
      "    val_loss       : 12194.032712781009\n",
      "    val_log_likelihood: -12115.089935348171\n",
      "    val_log_marginal: -12124.058715291298\n",
      "Train Epoch: 3563 [256/118836 (0%)] Loss: 12148.982422\n",
      "Train Epoch: 3563 [33024/118836 (28%)] Loss: 12207.442383\n",
      "Train Epoch: 3563 [65792/118836 (55%)] Loss: 12277.247070\n",
      "Train Epoch: 3563 [98560/118836 (83%)] Loss: 12144.635742\n",
      "    epoch          : 3563\n",
      "    loss           : 12196.437744907982\n",
      "    val_loss       : 12193.966995067307\n",
      "    val_log_likelihood: -12109.24055101065\n",
      "    val_log_marginal: -12118.19443905567\n",
      "Train Epoch: 3564 [256/118836 (0%)] Loss: 12143.705078\n",
      "Train Epoch: 3564 [33024/118836 (28%)] Loss: 12190.611328\n",
      "Train Epoch: 3564 [65792/118836 (55%)] Loss: 12276.824219\n",
      "Train Epoch: 3564 [98560/118836 (83%)] Loss: 12222.780273\n",
      "    epoch          : 3564\n",
      "    loss           : 12194.254253418374\n",
      "    val_loss       : 12192.84140356261\n",
      "    val_log_likelihood: -12112.81196672741\n",
      "    val_log_marginal: -12121.641006415543\n",
      "Train Epoch: 3565 [256/118836 (0%)] Loss: 12194.586914\n",
      "Train Epoch: 3565 [33024/118836 (28%)] Loss: 12200.367188\n",
      "Train Epoch: 3565 [65792/118836 (55%)] Loss: 12281.255859\n",
      "Train Epoch: 3565 [98560/118836 (83%)] Loss: 12269.708008\n",
      "    epoch          : 3565\n",
      "    loss           : 12187.922582583746\n",
      "    val_loss       : 12190.802425781878\n",
      "    val_log_likelihood: -12113.588497402294\n",
      "    val_log_marginal: -12122.382485388449\n",
      "Train Epoch: 3566 [256/118836 (0%)] Loss: 12193.354492\n",
      "Train Epoch: 3566 [33024/118836 (28%)] Loss: 12185.037109\n",
      "Train Epoch: 3566 [65792/118836 (55%)] Loss: 12201.027344\n",
      "Train Epoch: 3566 [98560/118836 (83%)] Loss: 12154.798828\n",
      "    epoch          : 3566\n",
      "    loss           : 12187.26777359905\n",
      "    val_loss       : 12189.862493900739\n",
      "    val_log_likelihood: -12114.020982765973\n",
      "    val_log_marginal: -12122.906908907198\n",
      "Train Epoch: 3567 [256/118836 (0%)] Loss: 12243.736328\n",
      "Train Epoch: 3567 [33024/118836 (28%)] Loss: 12168.789062\n",
      "Train Epoch: 3567 [65792/118836 (55%)] Loss: 12266.050781\n",
      "Train Epoch: 3567 [98560/118836 (83%)] Loss: 12206.498047\n",
      "    epoch          : 3567\n",
      "    loss           : 12187.84548083385\n",
      "    val_loss       : 12190.716769484368\n",
      "    val_log_likelihood: -12110.804110770781\n",
      "    val_log_marginal: -12119.564814483603\n",
      "Train Epoch: 3568 [256/118836 (0%)] Loss: 12128.648438\n",
      "Train Epoch: 3568 [33024/118836 (28%)] Loss: 12163.707031\n",
      "Train Epoch: 3568 [65792/118836 (55%)] Loss: 12276.687500\n",
      "Train Epoch: 3568 [98560/118836 (83%)] Loss: 12167.231445\n",
      "    epoch          : 3568\n",
      "    loss           : 12186.039320170337\n",
      "    val_loss       : 12189.934388055528\n",
      "    val_log_likelihood: -12112.237228921113\n",
      "    val_log_marginal: -12120.97495193761\n",
      "Train Epoch: 3569 [256/118836 (0%)] Loss: 12150.926758\n",
      "Train Epoch: 3569 [33024/118836 (28%)] Loss: 12101.874023\n",
      "Train Epoch: 3569 [65792/118836 (55%)] Loss: 12205.624023\n",
      "Train Epoch: 3569 [98560/118836 (83%)] Loss: 12210.818359\n",
      "    epoch          : 3569\n",
      "    loss           : 12193.753695913463\n",
      "    val_loss       : 12191.67830267799\n",
      "    val_log_likelihood: -12112.353464898677\n",
      "    val_log_marginal: -12121.019241356275\n",
      "Train Epoch: 3570 [256/118836 (0%)] Loss: 12201.384766\n",
      "Train Epoch: 3570 [33024/118836 (28%)] Loss: 12148.574219\n",
      "Train Epoch: 3570 [65792/118836 (55%)] Loss: 12262.933594\n",
      "Train Epoch: 3570 [98560/118836 (83%)] Loss: 12151.227539\n",
      "    epoch          : 3570\n",
      "    loss           : 12189.411905015766\n",
      "    val_loss       : 12192.111666128912\n",
      "    val_log_likelihood: -12114.171924595483\n",
      "    val_log_marginal: -12122.865993413534\n",
      "Train Epoch: 3571 [256/118836 (0%)] Loss: 12169.273438\n",
      "Train Epoch: 3571 [33024/118836 (28%)] Loss: 12278.556641\n",
      "Train Epoch: 3571 [65792/118836 (55%)] Loss: 12132.664062\n",
      "Train Epoch: 3571 [98560/118836 (83%)] Loss: 12187.888672\n",
      "    epoch          : 3571\n",
      "    loss           : 12189.490667487335\n",
      "    val_loss       : 12187.577185554357\n",
      "    val_log_likelihood: -12115.15066235008\n",
      "    val_log_marginal: -12123.99000437812\n",
      "Train Epoch: 3572 [256/118836 (0%)] Loss: 12273.867188\n",
      "Train Epoch: 3572 [33024/118836 (28%)] Loss: 12176.027344\n",
      "Train Epoch: 3572 [65792/118836 (55%)] Loss: 12145.207031\n",
      "Train Epoch: 3572 [98560/118836 (83%)] Loss: 12137.181641\n",
      "    epoch          : 3572\n",
      "    loss           : 12190.846262083849\n",
      "    val_loss       : 12193.297855126213\n",
      "    val_log_likelihood: -12115.017511728442\n",
      "    val_log_marginal: -12123.96705253187\n",
      "Train Epoch: 3573 [256/118836 (0%)] Loss: 12290.916016\n",
      "Train Epoch: 3573 [33024/118836 (28%)] Loss: 12182.497070\n",
      "Train Epoch: 3573 [65792/118836 (55%)] Loss: 12254.062500\n",
      "Train Epoch: 3573 [98560/118836 (83%)] Loss: 12258.180664\n",
      "    epoch          : 3573\n",
      "    loss           : 12191.91708103934\n",
      "    val_loss       : 12188.39669057707\n",
      "    val_log_likelihood: -12115.417298968672\n",
      "    val_log_marginal: -12124.450143897267\n",
      "Train Epoch: 3574 [256/118836 (0%)] Loss: 12161.369141\n",
      "Train Epoch: 3574 [33024/118836 (28%)] Loss: 12280.501953\n",
      "Train Epoch: 3574 [65792/118836 (55%)] Loss: 12180.257812\n",
      "Train Epoch: 3574 [98560/118836 (83%)] Loss: 12154.321289\n",
      "    epoch          : 3574\n",
      "    loss           : 12193.21563986249\n",
      "    val_loss       : 12194.39042082983\n",
      "    val_log_likelihood: -12108.683014112903\n",
      "    val_log_marginal: -12117.545159568226\n",
      "Train Epoch: 3575 [256/118836 (0%)] Loss: 12158.375000\n",
      "Train Epoch: 3575 [33024/118836 (28%)] Loss: 12161.822266\n",
      "Train Epoch: 3575 [65792/118836 (55%)] Loss: 12334.635742\n",
      "Train Epoch: 3575 [98560/118836 (83%)] Loss: 12203.287109\n",
      "    epoch          : 3575\n",
      "    loss           : 12193.00104118202\n",
      "    val_loss       : 12186.897821181088\n",
      "    val_log_likelihood: -12112.732582939154\n",
      "    val_log_marginal: -12121.517213854617\n",
      "Train Epoch: 3576 [256/118836 (0%)] Loss: 12194.652344\n",
      "Train Epoch: 3576 [33024/118836 (28%)] Loss: 12161.510742\n",
      "Train Epoch: 3576 [65792/118836 (55%)] Loss: 12160.076172\n",
      "Train Epoch: 3576 [98560/118836 (83%)] Loss: 12190.533203\n",
      "    epoch          : 3576\n",
      "    loss           : 12191.750547488886\n",
      "    val_loss       : 12192.662031916154\n",
      "    val_log_likelihood: -12111.632872111506\n",
      "    val_log_marginal: -12120.383356274848\n",
      "Train Epoch: 3577 [256/118836 (0%)] Loss: 12146.651367\n",
      "Train Epoch: 3577 [33024/118836 (28%)] Loss: 12256.188477\n",
      "Train Epoch: 3577 [65792/118836 (55%)] Loss: 12188.656250\n",
      "Train Epoch: 3577 [98560/118836 (83%)] Loss: 12268.154297\n",
      "    epoch          : 3577\n",
      "    loss           : 12190.360009240592\n",
      "    val_loss       : 12189.862898042096\n",
      "    val_log_likelihood: -12113.543161639269\n",
      "    val_log_marginal: -12122.32955923753\n",
      "Train Epoch: 3578 [256/118836 (0%)] Loss: 12123.887695\n",
      "Train Epoch: 3578 [33024/118836 (28%)] Loss: 12268.595703\n",
      "Train Epoch: 3578 [65792/118836 (55%)] Loss: 12268.880859\n",
      "Train Epoch: 3578 [98560/118836 (83%)] Loss: 12173.904297\n",
      "    epoch          : 3578\n",
      "    loss           : 12192.549407600547\n",
      "    val_loss       : 12190.803082452001\n",
      "    val_log_likelihood: -12115.507800545389\n",
      "    val_log_marginal: -12124.323394878978\n",
      "Train Epoch: 3579 [256/118836 (0%)] Loss: 12210.876953\n",
      "Train Epoch: 3579 [33024/118836 (28%)] Loss: 12212.923828\n",
      "Train Epoch: 3579 [65792/118836 (55%)] Loss: 12294.939453\n",
      "Train Epoch: 3579 [98560/118836 (83%)] Loss: 12214.650391\n",
      "    epoch          : 3579\n",
      "    loss           : 12193.351061052523\n",
      "    val_loss       : 12188.322024482979\n",
      "    val_log_likelihood: -12112.312049440394\n",
      "    val_log_marginal: -12121.172079980031\n",
      "Train Epoch: 3580 [256/118836 (0%)] Loss: 12118.391602\n",
      "Train Epoch: 3580 [33024/118836 (28%)] Loss: 12260.083984\n",
      "Train Epoch: 3580 [65792/118836 (55%)] Loss: 12322.232422\n",
      "Train Epoch: 3580 [98560/118836 (83%)] Loss: 12213.922852\n",
      "    epoch          : 3580\n",
      "    loss           : 12191.724930534016\n",
      "    val_loss       : 12185.462504195046\n",
      "    val_log_likelihood: -12116.260526681399\n",
      "    val_log_marginal: -12124.960161917435\n",
      "Train Epoch: 3581 [256/118836 (0%)] Loss: 12261.425781\n",
      "Train Epoch: 3581 [33024/118836 (28%)] Loss: 12250.830078\n",
      "Train Epoch: 3581 [65792/118836 (55%)] Loss: 12176.147461\n",
      "Train Epoch: 3581 [98560/118836 (83%)] Loss: 12182.523438\n",
      "    epoch          : 3581\n",
      "    loss           : 12188.223396789703\n",
      "    val_loss       : 12188.676583732531\n",
      "    val_log_likelihood: -12111.072757541098\n",
      "    val_log_marginal: -12119.789724201759\n",
      "Train Epoch: 3582 [256/118836 (0%)] Loss: 12159.364258\n",
      "Train Epoch: 3582 [33024/118836 (28%)] Loss: 12282.834961\n",
      "Train Epoch: 3582 [65792/118836 (55%)] Loss: 12254.007812\n",
      "Train Epoch: 3582 [98560/118836 (83%)] Loss: 12192.915039\n",
      "    epoch          : 3582\n",
      "    loss           : 12187.527600289495\n",
      "    val_loss       : 12190.099959095887\n",
      "    val_log_likelihood: -12111.18379584755\n",
      "    val_log_marginal: -12120.035476315332\n",
      "Train Epoch: 3583 [256/118836 (0%)] Loss: 12223.627930\n",
      "Train Epoch: 3583 [33024/118836 (28%)] Loss: 12267.990234\n",
      "Train Epoch: 3583 [65792/118836 (55%)] Loss: 12274.887695\n",
      "Train Epoch: 3583 [98560/118836 (83%)] Loss: 12197.320312\n",
      "    epoch          : 3583\n",
      "    loss           : 12187.126362825682\n",
      "    val_loss       : 12185.545118011878\n",
      "    val_log_likelihood: -12114.064041821754\n",
      "    val_log_marginal: -12122.852932262189\n",
      "Train Epoch: 3584 [256/118836 (0%)] Loss: 12207.761719\n",
      "Train Epoch: 3584 [33024/118836 (28%)] Loss: 12186.361328\n",
      "Train Epoch: 3584 [65792/118836 (55%)] Loss: 12210.600586\n",
      "Train Epoch: 3584 [98560/118836 (83%)] Loss: 12260.925781\n",
      "    epoch          : 3584\n",
      "    loss           : 12192.403934197942\n",
      "    val_loss       : 12186.160459571534\n",
      "    val_log_likelihood: -12115.420882444168\n",
      "    val_log_marginal: -12124.32678742983\n",
      "Train Epoch: 3585 [256/118836 (0%)] Loss: 12173.917969\n",
      "Train Epoch: 3585 [33024/118836 (28%)] Loss: 12160.217773\n",
      "Train Epoch: 3585 [65792/118836 (55%)] Loss: 12195.164062\n",
      "Train Epoch: 3585 [98560/118836 (83%)] Loss: 12175.457031\n",
      "    epoch          : 3585\n",
      "    loss           : 12187.357384718776\n",
      "    val_loss       : 12187.641713799989\n",
      "    val_log_likelihood: -12111.066276203215\n",
      "    val_log_marginal: -12119.965279966418\n",
      "Train Epoch: 3586 [256/118836 (0%)] Loss: 12158.558594\n",
      "Train Epoch: 3586 [33024/118836 (28%)] Loss: 12351.974609\n",
      "Train Epoch: 3586 [65792/118836 (55%)] Loss: 12216.128906\n",
      "Train Epoch: 3586 [98560/118836 (83%)] Loss: 12285.691406\n",
      "    epoch          : 3586\n",
      "    loss           : 12188.685551075268\n",
      "    val_loss       : 12196.348677881919\n",
      "    val_log_likelihood: -12113.373345094085\n",
      "    val_log_marginal: -12122.127997874974\n",
      "Train Epoch: 3587 [256/118836 (0%)] Loss: 12231.358398\n",
      "Train Epoch: 3587 [33024/118836 (28%)] Loss: 12171.229492\n",
      "Train Epoch: 3587 [65792/118836 (55%)] Loss: 12222.240234\n",
      "Train Epoch: 3587 [98560/118836 (83%)] Loss: 12249.975586\n",
      "    epoch          : 3587\n",
      "    loss           : 12193.089041821753\n",
      "    val_loss       : 12192.359725585817\n",
      "    val_log_likelihood: -12111.37406624793\n",
      "    val_log_marginal: -12120.082324574538\n",
      "Train Epoch: 3588 [256/118836 (0%)] Loss: 12253.611328\n",
      "Train Epoch: 3588 [33024/118836 (28%)] Loss: 12236.840820\n",
      "Train Epoch: 3588 [65792/118836 (55%)] Loss: 12116.276367\n",
      "Train Epoch: 3588 [98560/118836 (83%)] Loss: 12223.559570\n",
      "    epoch          : 3588\n",
      "    loss           : 12186.180665354892\n",
      "    val_loss       : 12190.047971013619\n",
      "    val_log_likelihood: -12113.461129419975\n",
      "    val_log_marginal: -12122.286172058064\n",
      "Train Epoch: 3589 [256/118836 (0%)] Loss: 12150.429688\n",
      "Train Epoch: 3589 [33024/118836 (28%)] Loss: 12206.688477\n",
      "Train Epoch: 3589 [65792/118836 (55%)] Loss: 12285.391602\n",
      "Train Epoch: 3589 [98560/118836 (83%)] Loss: 12213.096680\n",
      "    epoch          : 3589\n",
      "    loss           : 12188.356670996174\n",
      "    val_loss       : 12191.772166420524\n",
      "    val_log_likelihood: -12110.867669076975\n",
      "    val_log_marginal: -12119.569490765101\n",
      "Train Epoch: 3590 [256/118836 (0%)] Loss: 12238.914062\n",
      "Train Epoch: 3590 [33024/118836 (28%)] Loss: 12201.771484\n",
      "Train Epoch: 3590 [65792/118836 (55%)] Loss: 12267.310547\n",
      "Train Epoch: 3590 [98560/118836 (83%)] Loss: 12212.441406\n",
      "    epoch          : 3590\n",
      "    loss           : 12189.681275201612\n",
      "    val_loss       : 12192.135860657854\n",
      "    val_log_likelihood: -12109.65605872622\n",
      "    val_log_marginal: -12118.45556298903\n",
      "Train Epoch: 3591 [256/118836 (0%)] Loss: 12251.453125\n",
      "Train Epoch: 3591 [33024/118836 (28%)] Loss: 12200.483398\n",
      "Train Epoch: 3591 [65792/118836 (55%)] Loss: 12160.775391\n",
      "Train Epoch: 3591 [98560/118836 (83%)] Loss: 12218.488281\n",
      "    epoch          : 3591\n",
      "    loss           : 12186.676382211537\n",
      "    val_loss       : 12188.531130265586\n",
      "    val_log_likelihood: -12114.241826599979\n",
      "    val_log_marginal: -12122.9367109076\n",
      "Train Epoch: 3592 [256/118836 (0%)] Loss: 12222.123047\n",
      "Train Epoch: 3592 [33024/118836 (28%)] Loss: 12277.654297\n",
      "Train Epoch: 3592 [65792/118836 (55%)] Loss: 12276.954102\n",
      "Train Epoch: 3592 [98560/118836 (83%)] Loss: 12253.955078\n",
      "    epoch          : 3592\n",
      "    loss           : 12191.508990513854\n",
      "    val_loss       : 12191.491628253329\n",
      "    val_log_likelihood: -12110.87353039056\n",
      "    val_log_marginal: -12119.77300467205\n",
      "Train Epoch: 3593 [256/118836 (0%)] Loss: 12275.394531\n",
      "Train Epoch: 3593 [33024/118836 (28%)] Loss: 12145.840820\n",
      "Train Epoch: 3593 [65792/118836 (55%)] Loss: 12224.669922\n",
      "Train Epoch: 3593 [98560/118836 (83%)] Loss: 12200.396484\n",
      "    epoch          : 3593\n",
      "    loss           : 12189.52929945978\n",
      "    val_loss       : 12190.987772833727\n",
      "    val_log_likelihood: -12112.975169141595\n",
      "    val_log_marginal: -12121.758118666923\n",
      "Train Epoch: 3594 [256/118836 (0%)] Loss: 12129.465820\n",
      "Train Epoch: 3594 [33024/118836 (28%)] Loss: 12213.189453\n",
      "Train Epoch: 3594 [65792/118836 (55%)] Loss: 12184.267578\n",
      "Train Epoch: 3594 [98560/118836 (83%)] Loss: 12142.314453\n",
      "    epoch          : 3594\n",
      "    loss           : 12191.129965848584\n",
      "    val_loss       : 12194.943927452468\n",
      "    val_log_likelihood: -12115.718885700993\n",
      "    val_log_marginal: -12124.532418571087\n",
      "Train Epoch: 3595 [256/118836 (0%)] Loss: 12343.357422\n",
      "Train Epoch: 3595 [33024/118836 (28%)] Loss: 12168.555664\n",
      "Train Epoch: 3595 [65792/118836 (55%)] Loss: 12255.815430\n",
      "Train Epoch: 3595 [98560/118836 (83%)] Loss: 12132.422852\n",
      "    epoch          : 3595\n",
      "    loss           : 12190.96518461797\n",
      "    val_loss       : 12195.439041362864\n",
      "    val_log_likelihood: -12106.942394605563\n",
      "    val_log_marginal: -12115.738831939378\n",
      "Train Epoch: 3596 [256/118836 (0%)] Loss: 12213.081055\n",
      "Train Epoch: 3596 [33024/118836 (28%)] Loss: 12159.399414\n",
      "Train Epoch: 3596 [65792/118836 (55%)] Loss: 12259.910156\n",
      "Train Epoch: 3596 [98560/118836 (83%)] Loss: 12283.503906\n",
      "    epoch          : 3596\n",
      "    loss           : 12189.787810012149\n",
      "    val_loss       : 12193.363537853887\n",
      "    val_log_likelihood: -12112.681800719862\n",
      "    val_log_marginal: -12121.454123634127\n",
      "Train Epoch: 3597 [256/118836 (0%)] Loss: 12182.318359\n",
      "Train Epoch: 3597 [33024/118836 (28%)] Loss: 12235.109375\n",
      "Train Epoch: 3597 [65792/118836 (55%)] Loss: 12223.938477\n",
      "Train Epoch: 3597 [98560/118836 (83%)] Loss: 12353.853516\n",
      "    epoch          : 3597\n",
      "    loss           : 12186.531864854736\n",
      "    val_loss       : 12187.158131449818\n",
      "    val_log_likelihood: -12113.499752668786\n",
      "    val_log_marginal: -12122.41899180958\n",
      "Train Epoch: 3598 [256/118836 (0%)] Loss: 12195.916992\n",
      "Train Epoch: 3598 [33024/118836 (28%)] Loss: 12231.236328\n",
      "Train Epoch: 3598 [65792/118836 (55%)] Loss: 12108.452148\n",
      "Train Epoch: 3598 [98560/118836 (83%)] Loss: 12296.761719\n",
      "    epoch          : 3598\n",
      "    loss           : 12194.43561165607\n",
      "    val_loss       : 12189.449710119627\n",
      "    val_log_likelihood: -12114.231102667494\n",
      "    val_log_marginal: -12123.084913630513\n",
      "Train Epoch: 3599 [256/118836 (0%)] Loss: 12191.656250\n",
      "Train Epoch: 3599 [33024/118836 (28%)] Loss: 12398.540039\n",
      "Train Epoch: 3599 [65792/118836 (55%)] Loss: 12146.932617\n",
      "Train Epoch: 3599 [98560/118836 (83%)] Loss: 12260.638672\n",
      "    epoch          : 3599\n",
      "    loss           : 12190.660249140561\n",
      "    val_loss       : 12192.749652059389\n",
      "    val_log_likelihood: -12115.025806128517\n",
      "    val_log_marginal: -12123.77474915231\n",
      "Train Epoch: 3600 [256/118836 (0%)] Loss: 12259.485352\n",
      "Train Epoch: 3600 [33024/118836 (28%)] Loss: 12173.161133\n",
      "Train Epoch: 3600 [65792/118836 (55%)] Loss: 12156.515625\n",
      "Train Epoch: 3600 [98560/118836 (83%)] Loss: 12175.010742\n",
      "    epoch          : 3600\n",
      "    loss           : 12189.753256823822\n",
      "    val_loss       : 12190.69771554496\n",
      "    val_log_likelihood: -12112.688019864041\n",
      "    val_log_marginal: -12121.383213325847\n",
      "Saving checkpoint: saved/models/SelfiesAutoencodingOperad/0905_154251/checkpoint-epoch3600.pth ...\n",
      "Train Epoch: 3601 [256/118836 (0%)] Loss: 12094.712891\n",
      "Train Epoch: 3601 [33024/118836 (28%)] Loss: 12242.904297\n",
      "Train Epoch: 3601 [65792/118836 (55%)] Loss: 12218.034180\n",
      "Train Epoch: 3601 [98560/118836 (83%)] Loss: 12232.306641\n",
      "    epoch          : 3601\n",
      "    loss           : 12189.956527217742\n",
      "    val_loss       : 12191.760070347182\n",
      "    val_log_likelihood: -12114.503907542392\n",
      "    val_log_marginal: -12123.237659725775\n",
      "Train Epoch: 3602 [256/118836 (0%)] Loss: 12278.757812\n",
      "Train Epoch: 3602 [33024/118836 (28%)] Loss: 12278.707031\n",
      "Train Epoch: 3602 [65792/118836 (55%)] Loss: 12219.783203\n",
      "Train Epoch: 3602 [98560/118836 (83%)] Loss: 12133.622070\n",
      "    epoch          : 3602\n",
      "    loss           : 12190.342461809865\n",
      "    val_loss       : 12192.42208894787\n",
      "    val_log_likelihood: -12111.137419387149\n",
      "    val_log_marginal: -12119.807964890542\n",
      "Train Epoch: 3603 [256/118836 (0%)] Loss: 12251.602539\n",
      "Train Epoch: 3603 [33024/118836 (28%)] Loss: 12142.526367\n",
      "Train Epoch: 3603 [65792/118836 (55%)] Loss: 12300.065430\n",
      "Train Epoch: 3603 [98560/118836 (83%)] Loss: 12148.401367\n",
      "    epoch          : 3603\n",
      "    loss           : 12191.920254342433\n",
      "    val_loss       : 12187.112705807931\n",
      "    val_log_likelihood: -12110.948336532\n",
      "    val_log_marginal: -12119.619538512312\n",
      "Train Epoch: 3604 [256/118836 (0%)] Loss: 12255.550781\n",
      "Train Epoch: 3604 [33024/118836 (28%)] Loss: 12257.128906\n",
      "Train Epoch: 3604 [65792/118836 (55%)] Loss: 12200.303711\n",
      "Train Epoch: 3604 [98560/118836 (83%)] Loss: 12275.225586\n",
      "    epoch          : 3604\n",
      "    loss           : 12191.742081847084\n",
      "    val_loss       : 12187.40935168201\n",
      "    val_log_likelihood: -12111.904252287532\n",
      "    val_log_marginal: -12120.618415917945\n",
      "Train Epoch: 3605 [256/118836 (0%)] Loss: 12137.483398\n",
      "Train Epoch: 3605 [33024/118836 (28%)] Loss: 12152.619141\n",
      "Train Epoch: 3605 [65792/118836 (55%)] Loss: 12179.925781\n",
      "Train Epoch: 3605 [98560/118836 (83%)] Loss: 12133.628906\n",
      "    epoch          : 3605\n",
      "    loss           : 12190.133102803195\n",
      "    val_loss       : 12193.641020455418\n",
      "    val_log_likelihood: -12114.271409577905\n",
      "    val_log_marginal: -12123.077337920282\n",
      "Train Epoch: 3606 [256/118836 (0%)] Loss: 12169.315430\n",
      "Train Epoch: 3606 [33024/118836 (28%)] Loss: 12206.735352\n",
      "Train Epoch: 3606 [65792/118836 (55%)] Loss: 12238.574219\n",
      "Train Epoch: 3606 [98560/118836 (83%)] Loss: 12214.325195\n",
      "    epoch          : 3606\n",
      "    loss           : 12188.565759085506\n",
      "    val_loss       : 12193.230619855563\n",
      "    val_log_likelihood: -12115.680461641854\n",
      "    val_log_marginal: -12124.598421250328\n",
      "Train Epoch: 3607 [256/118836 (0%)] Loss: 12237.873047\n",
      "Train Epoch: 3607 [33024/118836 (28%)] Loss: 12166.278320\n",
      "Train Epoch: 3607 [65792/118836 (55%)] Loss: 12183.314453\n",
      "Train Epoch: 3607 [98560/118836 (83%)] Loss: 12242.518555\n",
      "    epoch          : 3607\n",
      "    loss           : 12190.170758697786\n",
      "    val_loss       : 12189.800049531048\n",
      "    val_log_likelihood: -12111.491901073978\n",
      "    val_log_marginal: -12120.186915322496\n",
      "Train Epoch: 3608 [256/118836 (0%)] Loss: 12187.552734\n",
      "Train Epoch: 3608 [33024/118836 (28%)] Loss: 12233.577148\n",
      "Train Epoch: 3608 [65792/118836 (55%)] Loss: 12234.195312\n",
      "Train Epoch: 3608 [98560/118836 (83%)] Loss: 12266.989258\n",
      "    epoch          : 3608\n",
      "    loss           : 12189.742846942205\n",
      "    val_loss       : 12191.811084908002\n",
      "    val_log_likelihood: -12114.14437212443\n",
      "    val_log_marginal: -12122.916156165675\n",
      "Train Epoch: 3609 [256/118836 (0%)] Loss: 12157.675781\n",
      "Train Epoch: 3609 [33024/118836 (28%)] Loss: 12256.762695\n",
      "Train Epoch: 3609 [65792/118836 (55%)] Loss: 12158.550781\n",
      "Train Epoch: 3609 [98560/118836 (83%)] Loss: 12192.542969\n",
      "    epoch          : 3609\n",
      "    loss           : 12188.501115817566\n",
      "    val_loss       : 12190.654309334666\n",
      "    val_log_likelihood: -12109.270622835245\n",
      "    val_log_marginal: -12118.014473514286\n",
      "Train Epoch: 3610 [256/118836 (0%)] Loss: 12224.921875\n",
      "Train Epoch: 3610 [33024/118836 (28%)] Loss: 12143.354492\n",
      "Train Epoch: 3610 [65792/118836 (55%)] Loss: 12165.040039\n",
      "Train Epoch: 3610 [98560/118836 (83%)] Loss: 12261.132812\n",
      "    epoch          : 3610\n",
      "    loss           : 12191.37698268843\n",
      "    val_loss       : 12193.648234618771\n",
      "    val_log_likelihood: -12111.950030048078\n",
      "    val_log_marginal: -12120.684158395474\n",
      "Train Epoch: 3611 [256/118836 (0%)] Loss: 12150.537109\n",
      "Train Epoch: 3611 [33024/118836 (28%)] Loss: 12187.103516\n",
      "Train Epoch: 3611 [65792/118836 (55%)] Loss: 12226.336914\n",
      "Train Epoch: 3611 [98560/118836 (83%)] Loss: 12129.498047\n",
      "    epoch          : 3611\n",
      "    loss           : 12191.590179609955\n",
      "    val_loss       : 12194.757984580572\n",
      "    val_log_likelihood: -12116.522337352666\n",
      "    val_log_marginal: -12125.459038393927\n",
      "Train Epoch: 3612 [256/118836 (0%)] Loss: 12184.633789\n",
      "Train Epoch: 3612 [33024/118836 (28%)] Loss: 12203.042969\n",
      "Train Epoch: 3612 [65792/118836 (55%)] Loss: 12334.364258\n",
      "Train Epoch: 3612 [98560/118836 (83%)] Loss: 12303.396484\n",
      "    epoch          : 3612\n",
      "    loss           : 12191.093941596877\n",
      "    val_loss       : 12192.966314789237\n",
      "    val_log_likelihood: -12115.036646860784\n",
      "    val_log_marginal: -12123.766508280743\n",
      "Train Epoch: 3613 [256/118836 (0%)] Loss: 12124.326172\n",
      "Train Epoch: 3613 [33024/118836 (28%)] Loss: 12191.191406\n",
      "Train Epoch: 3613 [65792/118836 (55%)] Loss: 12162.088867\n",
      "Train Epoch: 3613 [98560/118836 (83%)] Loss: 12254.481445\n",
      "    epoch          : 3613\n",
      "    loss           : 12191.779295097962\n",
      "    val_loss       : 12191.069912071385\n",
      "    val_log_likelihood: -12113.85344276649\n",
      "    val_log_marginal: -12122.527208171236\n",
      "Train Epoch: 3614 [256/118836 (0%)] Loss: 12208.525391\n",
      "Train Epoch: 3614 [33024/118836 (28%)] Loss: 12210.828125\n",
      "Train Epoch: 3614 [65792/118836 (55%)] Loss: 12160.430664\n",
      "Train Epoch: 3614 [98560/118836 (83%)] Loss: 12120.667969\n",
      "    epoch          : 3614\n",
      "    loss           : 12188.792176353132\n",
      "    val_loss       : 12187.278913877317\n",
      "    val_log_likelihood: -12111.511558655138\n",
      "    val_log_marginal: -12120.269009174446\n",
      "Train Epoch: 3615 [256/118836 (0%)] Loss: 12180.809570\n",
      "Train Epoch: 3615 [33024/118836 (28%)] Loss: 12192.592773\n",
      "Train Epoch: 3615 [65792/118836 (55%)] Loss: 12140.535156\n",
      "Train Epoch: 3615 [98560/118836 (83%)] Loss: 12165.544922\n",
      "    epoch          : 3615\n",
      "    loss           : 12194.33442217225\n",
      "    val_loss       : 12191.637056997897\n",
      "    val_log_likelihood: -12109.525581252585\n",
      "    val_log_marginal: -12118.176547625795\n",
      "Train Epoch: 3616 [256/118836 (0%)] Loss: 12258.302734\n",
      "Train Epoch: 3616 [33024/118836 (28%)] Loss: 12179.996094\n",
      "Train Epoch: 3616 [65792/118836 (55%)] Loss: 12207.481445\n",
      "Train Epoch: 3616 [98560/118836 (83%)] Loss: 12214.238281\n",
      "    epoch          : 3616\n",
      "    loss           : 12188.306832706523\n",
      "    val_loss       : 12188.798803512997\n",
      "    val_log_likelihood: -12110.613397888234\n",
      "    val_log_marginal: -12119.467896706405\n",
      "Train Epoch: 3617 [256/118836 (0%)] Loss: 12138.440430\n",
      "Train Epoch: 3617 [33024/118836 (28%)] Loss: 12237.584961\n",
      "Train Epoch: 3617 [65792/118836 (55%)] Loss: 12203.503906\n",
      "Train Epoch: 3617 [98560/118836 (83%)] Loss: 12212.776367\n",
      "    epoch          : 3617\n",
      "    loss           : 12192.899317294768\n",
      "    val_loss       : 12189.988817620691\n",
      "    val_log_likelihood: -12114.095974365435\n",
      "    val_log_marginal: -12122.985188022498\n",
      "Train Epoch: 3618 [256/118836 (0%)] Loss: 12209.924805\n",
      "Train Epoch: 3618 [33024/118836 (28%)] Loss: 12186.330078\n",
      "Train Epoch: 3618 [65792/118836 (55%)] Loss: 12194.312500\n",
      "Train Epoch: 3618 [98560/118836 (83%)] Loss: 12250.793945\n",
      "    epoch          : 3618\n",
      "    loss           : 12188.712908233818\n",
      "    val_loss       : 12188.009422677647\n",
      "    val_log_likelihood: -12115.629412059296\n",
      "    val_log_marginal: -12124.445024926707\n",
      "Train Epoch: 3619 [256/118836 (0%)] Loss: 12178.317383\n",
      "Train Epoch: 3619 [33024/118836 (28%)] Loss: 12203.113281\n",
      "Train Epoch: 3619 [65792/118836 (55%)] Loss: 12185.164062\n",
      "Train Epoch: 3619 [98560/118836 (83%)] Loss: 12212.255859\n",
      "    epoch          : 3619\n",
      "    loss           : 12190.536623920854\n",
      "    val_loss       : 12193.275027667692\n",
      "    val_log_likelihood: -12114.317025466553\n",
      "    val_log_marginal: -12123.11901921352\n",
      "Train Epoch: 3620 [256/118836 (0%)] Loss: 12248.409180\n",
      "Train Epoch: 3620 [33024/118836 (28%)] Loss: 12136.438477\n",
      "Train Epoch: 3620 [65792/118836 (55%)] Loss: 12283.229492\n",
      "Train Epoch: 3620 [98560/118836 (83%)] Loss: 12195.127930\n",
      "    epoch          : 3620\n",
      "    loss           : 12195.90544031741\n",
      "    val_loss       : 12186.254005961873\n",
      "    val_log_likelihood: -12110.881492000104\n",
      "    val_log_marginal: -12119.605152149112\n",
      "Train Epoch: 3621 [256/118836 (0%)] Loss: 12154.081055\n",
      "Train Epoch: 3621 [33024/118836 (28%)] Loss: 12172.758789\n",
      "Train Epoch: 3621 [65792/118836 (55%)] Loss: 12137.166016\n",
      "Train Epoch: 3621 [98560/118836 (83%)] Loss: 12154.371094\n",
      "    epoch          : 3621\n",
      "    loss           : 12188.247372731856\n",
      "    val_loss       : 12189.312257436208\n",
      "    val_log_likelihood: -12111.274382722033\n",
      "    val_log_marginal: -12119.980431349584\n",
      "Train Epoch: 3622 [256/118836 (0%)] Loss: 12132.896484\n",
      "Train Epoch: 3622 [33024/118836 (28%)] Loss: 12156.394531\n",
      "Train Epoch: 3622 [65792/118836 (55%)] Loss: 12184.293945\n",
      "Train Epoch: 3622 [98560/118836 (83%)] Loss: 12155.643555\n",
      "    epoch          : 3622\n",
      "    loss           : 12190.832484555935\n",
      "    val_loss       : 12194.926642389339\n",
      "    val_log_likelihood: -12110.42823695332\n",
      "    val_log_marginal: -12119.1549541461\n",
      "Train Epoch: 3623 [256/118836 (0%)] Loss: 12248.606445\n",
      "Train Epoch: 3623 [33024/118836 (28%)] Loss: 12253.295898\n",
      "Train Epoch: 3623 [65792/118836 (55%)] Loss: 12248.812500\n",
      "Train Epoch: 3623 [98560/118836 (83%)] Loss: 12191.315430\n",
      "    epoch          : 3623\n",
      "    loss           : 12187.849496452389\n",
      "    val_loss       : 12190.436067508937\n",
      "    val_log_likelihood: -12111.560850425196\n",
      "    val_log_marginal: -12120.404729528793\n",
      "Train Epoch: 3624 [256/118836 (0%)] Loss: 12296.496094\n",
      "Train Epoch: 3624 [33024/118836 (28%)] Loss: 12189.454102\n",
      "Train Epoch: 3624 [65792/118836 (55%)] Loss: 12278.633789\n",
      "Train Epoch: 3624 [98560/118836 (83%)] Loss: 12200.041992\n",
      "    epoch          : 3624\n",
      "    loss           : 12188.984956575681\n",
      "    val_loss       : 12186.318888726724\n",
      "    val_log_likelihood: -12114.834516193652\n",
      "    val_log_marginal: -12123.64733490814\n",
      "Train Epoch: 3625 [256/118836 (0%)] Loss: 12183.435547\n",
      "Train Epoch: 3625 [33024/118836 (28%)] Loss: 12325.250000\n",
      "Train Epoch: 3625 [65792/118836 (55%)] Loss: 12233.161133\n",
      "Train Epoch: 3625 [98560/118836 (83%)] Loss: 12153.514648\n",
      "    epoch          : 3625\n",
      "    loss           : 12191.964188831162\n",
      "    val_loss       : 12192.099888159288\n",
      "    val_log_likelihood: -12116.746271776778\n",
      "    val_log_marginal: -12125.577361632724\n",
      "Train Epoch: 3626 [256/118836 (0%)] Loss: 12291.904297\n",
      "Train Epoch: 3626 [33024/118836 (28%)] Loss: 12140.808594\n",
      "Train Epoch: 3626 [65792/118836 (55%)] Loss: 12159.009766\n",
      "Train Epoch: 3626 [98560/118836 (83%)] Loss: 12152.762695\n",
      "    epoch          : 3626\n",
      "    loss           : 12188.016350838763\n",
      "    val_loss       : 12193.72263959474\n",
      "    val_log_likelihood: -12113.402569756772\n",
      "    val_log_marginal: -12122.039856947746\n",
      "Train Epoch: 3627 [256/118836 (0%)] Loss: 12196.340820\n",
      "Train Epoch: 3627 [33024/118836 (28%)] Loss: 12173.923828\n",
      "Train Epoch: 3627 [65792/118836 (55%)] Loss: 12221.708984\n",
      "Train Epoch: 3627 [98560/118836 (83%)] Loss: 12367.654297\n",
      "    epoch          : 3627\n",
      "    loss           : 12193.35305359543\n",
      "    val_loss       : 12191.821415533319\n",
      "    val_log_likelihood: -12115.0201913384\n",
      "    val_log_marginal: -12123.851382266552\n",
      "Train Epoch: 3628 [256/118836 (0%)] Loss: 12302.240234\n",
      "Train Epoch: 3628 [33024/118836 (28%)] Loss: 12173.296875\n",
      "Train Epoch: 3628 [65792/118836 (55%)] Loss: 12286.376953\n",
      "Train Epoch: 3628 [98560/118836 (83%)] Loss: 12260.974609\n",
      "    epoch          : 3628\n",
      "    loss           : 12196.045080677472\n",
      "    val_loss       : 12188.367435109834\n",
      "    val_log_likelihood: -12110.853427580903\n",
      "    val_log_marginal: -12119.722213577063\n",
      "Train Epoch: 3629 [256/118836 (0%)] Loss: 12220.018555\n",
      "Train Epoch: 3629 [33024/118836 (28%)] Loss: 12375.144531\n",
      "Train Epoch: 3629 [65792/118836 (55%)] Loss: 12246.675781\n",
      "Train Epoch: 3629 [98560/118836 (83%)] Loss: 12230.605469\n",
      "    epoch          : 3629\n",
      "    loss           : 12193.195825255892\n",
      "    val_loss       : 12190.584191174636\n",
      "    val_log_likelihood: -12112.656130776984\n",
      "    val_log_marginal: -12121.48245685973\n",
      "Train Epoch: 3630 [256/118836 (0%)] Loss: 12132.746094\n",
      "Train Epoch: 3630 [33024/118836 (28%)] Loss: 12181.655273\n",
      "Train Epoch: 3630 [65792/118836 (55%)] Loss: 12146.009766\n",
      "Train Epoch: 3630 [98560/118836 (83%)] Loss: 12214.865234\n",
      "    epoch          : 3630\n",
      "    loss           : 12192.966231938844\n",
      "    val_loss       : 12193.419480800274\n",
      "    val_log_likelihood: -12112.448033627998\n",
      "    val_log_marginal: -12121.355459719533\n",
      "Train Epoch: 3631 [256/118836 (0%)] Loss: 12243.507812\n",
      "Train Epoch: 3631 [33024/118836 (28%)] Loss: 12237.033203\n",
      "Train Epoch: 3631 [65792/118836 (55%)] Loss: 12274.587891\n",
      "Train Epoch: 3631 [98560/118836 (83%)] Loss: 12180.531250\n",
      "    epoch          : 3631\n",
      "    loss           : 12191.680862605976\n",
      "    val_loss       : 12189.236122313974\n",
      "    val_log_likelihood: -12114.059962391439\n",
      "    val_log_marginal: -12122.867332307922\n",
      "Train Epoch: 3632 [256/118836 (0%)] Loss: 12194.280273\n",
      "Train Epoch: 3632 [33024/118836 (28%)] Loss: 12224.455078\n",
      "Train Epoch: 3632 [65792/118836 (55%)] Loss: 12220.647461\n",
      "Train Epoch: 3632 [98560/118836 (83%)] Loss: 12191.466797\n",
      "    epoch          : 3632\n",
      "    loss           : 12191.627957150797\n",
      "    val_loss       : 12190.558620465055\n",
      "    val_log_likelihood: -12117.312291925144\n",
      "    val_log_marginal: -12126.127606872646\n",
      "Train Epoch: 3633 [256/118836 (0%)] Loss: 12220.971680\n",
      "Train Epoch: 3633 [33024/118836 (28%)] Loss: 12194.015625\n",
      "Train Epoch: 3633 [65792/118836 (55%)] Loss: 12139.322266\n",
      "Train Epoch: 3633 [98560/118836 (83%)] Loss: 12205.882812\n",
      "    epoch          : 3633\n",
      "    loss           : 12189.056349029413\n",
      "    val_loss       : 12192.568072155354\n",
      "    val_log_likelihood: -12115.106503954714\n",
      "    val_log_marginal: -12124.019040436087\n",
      "Train Epoch: 3634 [256/118836 (0%)] Loss: 12220.883789\n",
      "Train Epoch: 3634 [33024/118836 (28%)] Loss: 12127.450195\n",
      "Train Epoch: 3634 [65792/118836 (55%)] Loss: 12183.604492\n",
      "Train Epoch: 3634 [98560/118836 (83%)] Loss: 12171.800781\n",
      "    epoch          : 3634\n",
      "    loss           : 12186.821102312088\n",
      "    val_loss       : 12189.626702546484\n",
      "    val_log_likelihood: -12114.656056464537\n",
      "    val_log_marginal: -12123.537147600731\n",
      "Train Epoch: 3635 [256/118836 (0%)] Loss: 12158.383789\n",
      "Train Epoch: 3635 [33024/118836 (28%)] Loss: 12206.344727\n",
      "Train Epoch: 3635 [65792/118836 (55%)] Loss: 12212.086914\n",
      "Train Epoch: 3635 [98560/118836 (83%)] Loss: 12173.705078\n",
      "    epoch          : 3635\n",
      "    loss           : 12186.223595979372\n",
      "    val_loss       : 12190.808902692208\n",
      "    val_log_likelihood: -12115.734870147075\n",
      "    val_log_marginal: -12124.451745563585\n",
      "Train Epoch: 3636 [256/118836 (0%)] Loss: 12176.098633\n",
      "Train Epoch: 3636 [33024/118836 (28%)] Loss: 12150.275391\n",
      "Train Epoch: 3636 [65792/118836 (55%)] Loss: 12262.099609\n",
      "Train Epoch: 3636 [98560/118836 (83%)] Loss: 12216.877930\n",
      "    epoch          : 3636\n",
      "    loss           : 12192.605822380323\n",
      "    val_loss       : 12186.272560610181\n",
      "    val_log_likelihood: -12114.14012920673\n",
      "    val_log_marginal: -12122.947734984013\n",
      "Train Epoch: 3637 [256/118836 (0%)] Loss: 12162.642578\n",
      "Train Epoch: 3637 [33024/118836 (28%)] Loss: 12183.093750\n",
      "Train Epoch: 3637 [65792/118836 (55%)] Loss: 12162.081055\n",
      "Train Epoch: 3637 [98560/118836 (83%)] Loss: 12210.826172\n",
      "    epoch          : 3637\n",
      "    loss           : 12188.272583553038\n",
      "    val_loss       : 12190.97100350683\n",
      "    val_log_likelihood: -12113.247314574288\n",
      "    val_log_marginal: -12122.155921339949\n",
      "Train Epoch: 3638 [256/118836 (0%)] Loss: 12138.403320\n",
      "Train Epoch: 3638 [33024/118836 (28%)] Loss: 12250.719727\n",
      "Train Epoch: 3638 [65792/118836 (55%)] Loss: 12145.124023\n",
      "Train Epoch: 3638 [98560/118836 (83%)] Loss: 12183.650391\n",
      "    epoch          : 3638\n",
      "    loss           : 12191.824319071806\n",
      "    val_loss       : 12187.914332341154\n",
      "    val_log_likelihood: -12112.64792442101\n",
      "    val_log_marginal: -12121.475612801489\n",
      "Train Epoch: 3639 [256/118836 (0%)] Loss: 12247.991211\n",
      "Train Epoch: 3639 [33024/118836 (28%)] Loss: 12243.914062\n",
      "Train Epoch: 3639 [65792/118836 (55%)] Loss: 12289.476562\n",
      "Train Epoch: 3639 [98560/118836 (83%)] Loss: 12145.110352\n",
      "    epoch          : 3639\n",
      "    loss           : 12187.097270794562\n",
      "    val_loss       : 12192.84243652615\n",
      "    val_log_likelihood: -12113.132402489144\n",
      "    val_log_marginal: -12122.0487874227\n",
      "Train Epoch: 3640 [256/118836 (0%)] Loss: 12167.875977\n",
      "Train Epoch: 3640 [33024/118836 (28%)] Loss: 12230.980469\n",
      "Train Epoch: 3640 [65792/118836 (55%)] Loss: 12127.640625\n",
      "Train Epoch: 3640 [98560/118836 (83%)] Loss: 12306.242188\n",
      "    epoch          : 3640\n",
      "    loss           : 12190.222708753361\n",
      "    val_loss       : 12191.263260765696\n",
      "    val_log_likelihood: -12110.917121103443\n",
      "    val_log_marginal: -12119.72473809837\n",
      "Train Epoch: 3641 [256/118836 (0%)] Loss: 12237.345703\n",
      "Train Epoch: 3641 [33024/118836 (28%)] Loss: 12205.763672\n",
      "Train Epoch: 3641 [65792/118836 (55%)] Loss: 12166.037109\n",
      "Train Epoch: 3641 [98560/118836 (83%)] Loss: 12178.573242\n",
      "    epoch          : 3641\n",
      "    loss           : 12191.31810073537\n",
      "    val_loss       : 12188.534432848477\n",
      "    val_log_likelihood: -12112.44942617866\n",
      "    val_log_marginal: -12121.418025051105\n",
      "Train Epoch: 3642 [256/118836 (0%)] Loss: 12285.126953\n",
      "Train Epoch: 3642 [33024/118836 (28%)] Loss: 12203.860352\n",
      "Train Epoch: 3642 [65792/118836 (55%)] Loss: 12241.696289\n",
      "Train Epoch: 3642 [98560/118836 (83%)] Loss: 12129.926758\n",
      "    epoch          : 3642\n",
      "    loss           : 12191.747217321908\n",
      "    val_loss       : 12192.090278884014\n",
      "    val_log_likelihood: -12109.748688546837\n",
      "    val_log_marginal: -12118.574205516574\n",
      "Train Epoch: 3643 [256/118836 (0%)] Loss: 12171.256836\n",
      "Train Epoch: 3643 [33024/118836 (28%)] Loss: 12243.942383\n",
      "Train Epoch: 3643 [65792/118836 (55%)] Loss: 12175.780273\n",
      "Train Epoch: 3643 [98560/118836 (83%)] Loss: 12240.052734\n",
      "    epoch          : 3643\n",
      "    loss           : 12191.765489137459\n",
      "    val_loss       : 12189.38016634813\n",
      "    val_log_likelihood: -12110.091316751963\n",
      "    val_log_marginal: -12118.920732948995\n",
      "Train Epoch: 3644 [256/118836 (0%)] Loss: 12170.720703\n",
      "Train Epoch: 3644 [33024/118836 (28%)] Loss: 12139.525391\n",
      "Train Epoch: 3644 [65792/118836 (55%)] Loss: 12224.733398\n",
      "Train Epoch: 3644 [98560/118836 (83%)] Loss: 12248.116211\n",
      "    epoch          : 3644\n",
      "    loss           : 12191.817784584367\n",
      "    val_loss       : 12189.488193919718\n",
      "    val_log_likelihood: -12109.064885752688\n",
      "    val_log_marginal: -12117.82850567216\n",
      "Train Epoch: 3645 [256/118836 (0%)] Loss: 12131.500000\n",
      "Train Epoch: 3645 [33024/118836 (28%)] Loss: 12171.011719\n",
      "Train Epoch: 3645 [65792/118836 (55%)] Loss: 12287.594727\n",
      "Train Epoch: 3645 [98560/118836 (83%)] Loss: 12260.578125\n",
      "    epoch          : 3645\n",
      "    loss           : 12188.976761366574\n",
      "    val_loss       : 12191.459879373486\n",
      "    val_log_likelihood: -12112.669306212521\n",
      "    val_log_marginal: -12121.609606765742\n",
      "Train Epoch: 3646 [256/118836 (0%)] Loss: 12203.553711\n",
      "Train Epoch: 3646 [33024/118836 (28%)] Loss: 12209.425781\n",
      "Train Epoch: 3646 [65792/118836 (55%)] Loss: 12226.877930\n",
      "Train Epoch: 3646 [98560/118836 (83%)] Loss: 12270.276367\n",
      "    epoch          : 3646\n",
      "    loss           : 12189.113913552006\n",
      "    val_loss       : 12189.490944211526\n",
      "    val_log_likelihood: -12112.069369378101\n",
      "    val_log_marginal: -12121.03925781292\n",
      "Train Epoch: 3647 [256/118836 (0%)] Loss: 12188.325195\n",
      "Train Epoch: 3647 [33024/118836 (28%)] Loss: 12191.291992\n",
      "Train Epoch: 3647 [65792/118836 (55%)] Loss: 12203.722656\n",
      "Train Epoch: 3647 [98560/118836 (83%)] Loss: 12239.078125\n",
      "    epoch          : 3647\n",
      "    loss           : 12190.601574131513\n",
      "    val_loss       : 12192.774133348596\n",
      "    val_log_likelihood: -12111.300700960246\n",
      "    val_log_marginal: -12120.121630719223\n",
      "Train Epoch: 3648 [256/118836 (0%)] Loss: 12232.175781\n",
      "Train Epoch: 3648 [33024/118836 (28%)] Loss: 12266.648438\n",
      "Train Epoch: 3648 [65792/118836 (55%)] Loss: 12164.309570\n",
      "Train Epoch: 3648 [98560/118836 (83%)] Loss: 12156.150391\n",
      "    epoch          : 3648\n",
      "    loss           : 12190.208309747208\n",
      "    val_loss       : 12190.458731935061\n",
      "    val_log_likelihood: -12108.397472730563\n",
      "    val_log_marginal: -12117.1730344045\n",
      "Train Epoch: 3649 [256/118836 (0%)] Loss: 12175.723633\n",
      "Train Epoch: 3649 [33024/118836 (28%)] Loss: 12184.867188\n",
      "Train Epoch: 3649 [65792/118836 (55%)] Loss: 12218.363281\n",
      "Train Epoch: 3649 [98560/118836 (83%)] Loss: 12215.283203\n",
      "    epoch          : 3649\n",
      "    loss           : 12189.4935076768\n",
      "    val_loss       : 12188.96038782539\n",
      "    val_log_likelihood: -12115.266111100342\n",
      "    val_log_marginal: -12124.025776801447\n",
      "Train Epoch: 3650 [256/118836 (0%)] Loss: 12168.511719\n",
      "Train Epoch: 3650 [33024/118836 (28%)] Loss: 12235.134766\n",
      "Train Epoch: 3650 [65792/118836 (55%)] Loss: 12193.958984\n",
      "Train Epoch: 3650 [98560/118836 (83%)] Loss: 12188.992188\n",
      "    epoch          : 3650\n",
      "    loss           : 12191.159026216139\n",
      "    val_loss       : 12191.067657888047\n",
      "    val_log_likelihood: -12114.628457467432\n",
      "    val_log_marginal: -12123.566161970906\n",
      "Train Epoch: 3651 [256/118836 (0%)] Loss: 12232.000000\n",
      "Train Epoch: 3651 [33024/118836 (28%)] Loss: 12234.728516\n",
      "Train Epoch: 3651 [65792/118836 (55%)] Loss: 12172.003906\n",
      "Train Epoch: 3651 [98560/118836 (83%)] Loss: 12261.231445\n",
      "    epoch          : 3651\n",
      "    loss           : 12192.227997861093\n",
      "    val_loss       : 12190.741156966498\n",
      "    val_log_likelihood: -12110.843109297455\n",
      "    val_log_marginal: -12119.782107471363\n",
      "Train Epoch: 3652 [256/118836 (0%)] Loss: 12185.884766\n",
      "Train Epoch: 3652 [33024/118836 (28%)] Loss: 12197.847656\n",
      "Train Epoch: 3652 [65792/118836 (55%)] Loss: 12235.145508\n",
      "Train Epoch: 3652 [98560/118836 (83%)] Loss: 12209.154297\n",
      "    epoch          : 3652\n",
      "    loss           : 12186.69458617659\n",
      "    val_loss       : 12190.309220481311\n",
      "    val_log_likelihood: -12110.812153154726\n",
      "    val_log_marginal: -12119.544694082915\n",
      "Train Epoch: 3653 [256/118836 (0%)] Loss: 12192.995117\n",
      "Train Epoch: 3653 [33024/118836 (28%)] Loss: 12151.507812\n",
      "Train Epoch: 3653 [65792/118836 (55%)] Loss: 12196.590820\n",
      "Train Epoch: 3653 [98560/118836 (83%)] Loss: 12176.583984\n",
      "    epoch          : 3653\n",
      "    loss           : 12195.169128185744\n",
      "    val_loss       : 12189.948768227594\n",
      "    val_log_likelihood: -12112.804098493074\n",
      "    val_log_marginal: -12121.496832095034\n",
      "Train Epoch: 3654 [256/118836 (0%)] Loss: 12307.655273\n",
      "Train Epoch: 3654 [33024/118836 (28%)] Loss: 12271.279297\n",
      "Train Epoch: 3654 [65792/118836 (55%)] Loss: 12179.892578\n",
      "Train Epoch: 3654 [98560/118836 (83%)] Loss: 12240.294922\n",
      "    epoch          : 3654\n",
      "    loss           : 12188.7804214162\n",
      "    val_loss       : 12188.654879358248\n",
      "    val_log_likelihood: -12113.406354522074\n",
      "    val_log_marginal: -12122.107307181113\n",
      "Train Epoch: 3655 [256/118836 (0%)] Loss: 12263.363281\n",
      "Train Epoch: 3655 [33024/118836 (28%)] Loss: 12214.454102\n",
      "Train Epoch: 3655 [65792/118836 (55%)] Loss: 12350.316406\n",
      "Train Epoch: 3655 [98560/118836 (83%)] Loss: 12175.023438\n",
      "    epoch          : 3655\n",
      "    loss           : 12193.002781224153\n",
      "    val_loss       : 12191.29574864546\n",
      "    val_log_likelihood: -12109.749715351012\n",
      "    val_log_marginal: -12118.578382396021\n",
      "Train Epoch: 3656 [256/118836 (0%)] Loss: 12111.154297\n",
      "Train Epoch: 3656 [33024/118836 (28%)] Loss: 12228.343750\n",
      "Train Epoch: 3656 [65792/118836 (55%)] Loss: 12207.250977\n",
      "Train Epoch: 3656 [98560/118836 (83%)] Loss: 12279.770508\n",
      "    epoch          : 3656\n",
      "    loss           : 12188.744254355355\n",
      "    val_loss       : 12193.255016988496\n",
      "    val_log_likelihood: -12114.551295459833\n",
      "    val_log_marginal: -12123.449333530665\n",
      "Train Epoch: 3657 [256/118836 (0%)] Loss: 12192.995117\n",
      "Train Epoch: 3657 [33024/118836 (28%)] Loss: 12184.935547\n",
      "Train Epoch: 3657 [65792/118836 (55%)] Loss: 12304.269531\n",
      "Train Epoch: 3657 [98560/118836 (83%)] Loss: 12123.613281\n",
      "    epoch          : 3657\n",
      "    loss           : 12191.274861068032\n",
      "    val_loss       : 12189.140260567352\n",
      "    val_log_likelihood: -12110.30716485086\n",
      "    val_log_marginal: -12119.236139297998\n",
      "Train Epoch: 3658 [256/118836 (0%)] Loss: 12265.725586\n",
      "Train Epoch: 3658 [33024/118836 (28%)] Loss: 12195.690430\n",
      "Train Epoch: 3658 [65792/118836 (55%)] Loss: 12256.765625\n",
      "Train Epoch: 3658 [98560/118836 (83%)] Loss: 12195.646484\n",
      "    epoch          : 3658\n",
      "    loss           : 12194.062870431399\n",
      "    val_loss       : 12192.103243697844\n",
      "    val_log_likelihood: -12124.521691157464\n",
      "    val_log_marginal: -12133.435852533743\n",
      "Train Epoch: 3659 [256/118836 (0%)] Loss: 12273.536133\n",
      "Train Epoch: 3659 [33024/118836 (28%)] Loss: 12231.353516\n",
      "Train Epoch: 3659 [65792/118836 (55%)] Loss: 12170.068359\n",
      "Train Epoch: 3659 [98560/118836 (83%)] Loss: 12246.487305\n",
      "    epoch          : 3659\n",
      "    loss           : 12190.560841540013\n",
      "    val_loss       : 12190.463671253732\n",
      "    val_log_likelihood: -12110.986272713762\n",
      "    val_log_marginal: -12119.819403207337\n",
      "Train Epoch: 3660 [256/118836 (0%)] Loss: 12230.320312\n",
      "Train Epoch: 3660 [33024/118836 (28%)] Loss: 12209.100586\n",
      "Train Epoch: 3660 [65792/118836 (55%)] Loss: 12235.128906\n",
      "Train Epoch: 3660 [98560/118836 (83%)] Loss: 12322.815430\n",
      "    epoch          : 3660\n",
      "    loss           : 12193.170396182279\n",
      "    val_loss       : 12192.022330201999\n",
      "    val_log_likelihood: -12114.942417060845\n",
      "    val_log_marginal: -12123.750623924849\n",
      "Train Epoch: 3661 [256/118836 (0%)] Loss: 12179.114258\n",
      "Train Epoch: 3661 [33024/118836 (28%)] Loss: 12203.398438\n",
      "Train Epoch: 3661 [65792/118836 (55%)] Loss: 12176.515625\n",
      "Train Epoch: 3661 [98560/118836 (83%)] Loss: 12187.158203\n",
      "    epoch          : 3661\n",
      "    loss           : 12189.30206475522\n",
      "    val_loss       : 12190.318383804673\n",
      "    val_log_likelihood: -12113.183268713812\n",
      "    val_log_marginal: -12121.866577684359\n",
      "Train Epoch: 3662 [256/118836 (0%)] Loss: 12282.241211\n",
      "Train Epoch: 3662 [33024/118836 (28%)] Loss: 12185.596680\n",
      "Train Epoch: 3662 [65792/118836 (55%)] Loss: 12282.954102\n",
      "Train Epoch: 3662 [98560/118836 (83%)] Loss: 12187.474609\n",
      "    epoch          : 3662\n",
      "    loss           : 12190.447879348894\n",
      "    val_loss       : 12193.601020289185\n",
      "    val_log_likelihood: -12111.606991185898\n",
      "    val_log_marginal: -12120.441943628737\n",
      "Train Epoch: 3663 [256/118836 (0%)] Loss: 12288.198242\n",
      "Train Epoch: 3663 [33024/118836 (28%)] Loss: 12181.821289\n",
      "Train Epoch: 3663 [65792/118836 (55%)] Loss: 12170.083008\n",
      "Train Epoch: 3663 [98560/118836 (83%)] Loss: 12189.306641\n",
      "    epoch          : 3663\n",
      "    loss           : 12190.656192488628\n",
      "    val_loss       : 12186.402199552957\n",
      "    val_log_likelihood: -12111.432332700062\n",
      "    val_log_marginal: -12120.377634289765\n",
      "Train Epoch: 3664 [256/118836 (0%)] Loss: 12181.501953\n",
      "Train Epoch: 3664 [33024/118836 (28%)] Loss: 12191.210938\n",
      "Train Epoch: 3664 [65792/118836 (55%)] Loss: 12178.789062\n",
      "Train Epoch: 3664 [98560/118836 (83%)] Loss: 12240.938477\n",
      "    epoch          : 3664\n",
      "    loss           : 12193.042989589794\n",
      "    val_loss       : 12192.13280016047\n",
      "    val_log_likelihood: -12114.092391051488\n",
      "    val_log_marginal: -12123.041804663615\n",
      "Train Epoch: 3665 [256/118836 (0%)] Loss: 12242.096680\n",
      "Train Epoch: 3665 [33024/118836 (28%)] Loss: 12178.498047\n",
      "Train Epoch: 3665 [65792/118836 (55%)] Loss: 12140.695312\n",
      "Train Epoch: 3665 [98560/118836 (83%)] Loss: 12188.814453\n",
      "    epoch          : 3665\n",
      "    loss           : 12191.98498533137\n",
      "    val_loss       : 12191.25717686091\n",
      "    val_log_likelihood: -12110.507282943032\n",
      "    val_log_marginal: -12119.30593917697\n",
      "Train Epoch: 3666 [256/118836 (0%)] Loss: 12219.363281\n",
      "Train Epoch: 3666 [33024/118836 (28%)] Loss: 12174.322266\n",
      "Train Epoch: 3666 [65792/118836 (55%)] Loss: 12218.645508\n",
      "Train Epoch: 3666 [98560/118836 (83%)] Loss: 12167.380859\n",
      "    epoch          : 3666\n",
      "    loss           : 12187.1249731829\n",
      "    val_loss       : 12188.050088212205\n",
      "    val_log_likelihood: -12112.122650272693\n",
      "    val_log_marginal: -12120.900181934996\n",
      "Train Epoch: 3667 [256/118836 (0%)] Loss: 12277.947266\n",
      "Train Epoch: 3667 [33024/118836 (28%)] Loss: 12242.671875\n",
      "Train Epoch: 3667 [65792/118836 (55%)] Loss: 12224.628906\n",
      "Train Epoch: 3667 [98560/118836 (83%)] Loss: 12249.959961\n",
      "    epoch          : 3667\n",
      "    loss           : 12191.95209997286\n",
      "    val_loss       : 12190.51598148653\n",
      "    val_log_likelihood: -12113.595629297199\n",
      "    val_log_marginal: -12122.417537274387\n",
      "Train Epoch: 3668 [256/118836 (0%)] Loss: 12187.858398\n",
      "Train Epoch: 3668 [33024/118836 (28%)] Loss: 12173.181641\n",
      "Train Epoch: 3668 [65792/118836 (55%)] Loss: 12282.128906\n",
      "Train Epoch: 3668 [98560/118836 (83%)] Loss: 12274.591797\n",
      "    epoch          : 3668\n",
      "    loss           : 12192.458421538979\n",
      "    val_loss       : 12189.83904262786\n",
      "    val_log_likelihood: -12112.353524348635\n",
      "    val_log_marginal: -12121.384657997362\n",
      "Train Epoch: 3669 [256/118836 (0%)] Loss: 12146.400391\n",
      "Train Epoch: 3669 [33024/118836 (28%)] Loss: 12129.154297\n",
      "Train Epoch: 3669 [65792/118836 (55%)] Loss: 12166.641602\n",
      "Train Epoch: 3669 [98560/118836 (83%)] Loss: 12161.794922\n",
      "    epoch          : 3669\n",
      "    loss           : 12193.920406682952\n",
      "    val_loss       : 12192.524884441606\n",
      "    val_log_likelihood: -12113.513752972498\n",
      "    val_log_marginal: -12122.364036748622\n",
      "Train Epoch: 3670 [256/118836 (0%)] Loss: 12164.876953\n",
      "Train Epoch: 3670 [33024/118836 (28%)] Loss: 12179.367188\n",
      "Train Epoch: 3670 [65792/118836 (55%)] Loss: 12206.323242\n",
      "Train Epoch: 3670 [98560/118836 (83%)] Loss: 12190.287109\n",
      "    epoch          : 3670\n",
      "    loss           : 12190.588603539856\n",
      "    val_loss       : 12190.63240758258\n",
      "    val_log_likelihood: -12109.50108156922\n",
      "    val_log_marginal: -12118.42245399583\n",
      "Train Epoch: 3671 [256/118836 (0%)] Loss: 12387.403320\n",
      "Train Epoch: 3671 [33024/118836 (28%)] Loss: 12173.488281\n",
      "Train Epoch: 3671 [65792/118836 (55%)] Loss: 12360.033203\n",
      "Train Epoch: 3671 [98560/118836 (83%)] Loss: 12165.319336\n",
      "    epoch          : 3671\n",
      "    loss           : 12190.640533078733\n",
      "    val_loss       : 12192.615582259383\n",
      "    val_log_likelihood: -12113.137416156173\n",
      "    val_log_marginal: -12122.04718696026\n",
      "Train Epoch: 3672 [256/118836 (0%)] Loss: 12205.886719\n",
      "Train Epoch: 3672 [33024/118836 (28%)] Loss: 12227.410156\n",
      "Train Epoch: 3672 [65792/118836 (55%)] Loss: 12198.455078\n",
      "Train Epoch: 3672 [98560/118836 (83%)] Loss: 12246.467773\n",
      "    epoch          : 3672\n",
      "    loss           : 12188.816193813327\n",
      "    val_loss       : 12191.95675324343\n",
      "    val_log_likelihood: -12113.24208911678\n",
      "    val_log_marginal: -12122.045661097285\n",
      "Train Epoch: 3673 [256/118836 (0%)] Loss: 12201.328125\n",
      "Train Epoch: 3673 [33024/118836 (28%)] Loss: 12229.679688\n",
      "Train Epoch: 3673 [65792/118836 (55%)] Loss: 12315.941406\n",
      "Train Epoch: 3673 [98560/118836 (83%)] Loss: 12318.254883\n",
      "    epoch          : 3673\n",
      "    loss           : 12193.396056755324\n",
      "    val_loss       : 12187.384519793066\n",
      "    val_log_likelihood: -12111.19627032284\n",
      "    val_log_marginal: -12120.004281377525\n",
      "Train Epoch: 3674 [256/118836 (0%)] Loss: 12164.925781\n",
      "Train Epoch: 3674 [33024/118836 (28%)] Loss: 12234.473633\n",
      "Train Epoch: 3674 [65792/118836 (55%)] Loss: 12154.888672\n",
      "Train Epoch: 3674 [98560/118836 (83%)] Loss: 12212.452148\n",
      "    epoch          : 3674\n",
      "    loss           : 12186.165487198872\n",
      "    val_loss       : 12188.433572696717\n",
      "    val_log_likelihood: -12116.759783556918\n",
      "    val_log_marginal: -12125.626559272216\n",
      "Train Epoch: 3675 [256/118836 (0%)] Loss: 12173.238281\n",
      "Train Epoch: 3675 [33024/118836 (28%)] Loss: 12169.250000\n",
      "Train Epoch: 3675 [65792/118836 (55%)] Loss: 12127.750000\n",
      "Train Epoch: 3675 [98560/118836 (83%)] Loss: 12139.371094\n",
      "    epoch          : 3675\n",
      "    loss           : 12189.456268093467\n",
      "    val_loss       : 12188.769084082784\n",
      "    val_log_likelihood: -12110.180092664392\n",
      "    val_log_marginal: -12118.945942381444\n",
      "Train Epoch: 3676 [256/118836 (0%)] Loss: 12215.611328\n",
      "Train Epoch: 3676 [33024/118836 (28%)] Loss: 12419.207031\n",
      "Train Epoch: 3676 [65792/118836 (55%)] Loss: 12274.654297\n",
      "Train Epoch: 3676 [98560/118836 (83%)] Loss: 12333.700195\n",
      "    epoch          : 3676\n",
      "    loss           : 12194.808021059502\n",
      "    val_loss       : 12183.873576724764\n",
      "    val_log_likelihood: -12109.397203105615\n",
      "    val_log_marginal: -12118.193224147853\n",
      "Train Epoch: 3677 [256/118836 (0%)] Loss: 12181.969727\n",
      "Train Epoch: 3677 [33024/118836 (28%)] Loss: 12159.876953\n",
      "Train Epoch: 3677 [65792/118836 (55%)] Loss: 12240.595703\n",
      "Train Epoch: 3677 [98560/118836 (83%)] Loss: 12234.422852\n",
      "    epoch          : 3677\n",
      "    loss           : 12189.591737909686\n",
      "    val_loss       : 12189.102599741902\n",
      "    val_log_likelihood: -12109.823338793683\n",
      "    val_log_marginal: -12118.685382260663\n",
      "Train Epoch: 3678 [256/118836 (0%)] Loss: 12188.783203\n",
      "Train Epoch: 3678 [33024/118836 (28%)] Loss: 12274.875000\n",
      "Train Epoch: 3678 [65792/118836 (55%)] Loss: 12259.384766\n",
      "Train Epoch: 3678 [98560/118836 (83%)] Loss: 12220.261719\n",
      "    epoch          : 3678\n",
      "    loss           : 12189.495106686827\n",
      "    val_loss       : 12191.995707444941\n",
      "    val_log_likelihood: -12107.951680430624\n",
      "    val_log_marginal: -12116.752807708854\n",
      "Train Epoch: 3679 [256/118836 (0%)] Loss: 12238.722656\n",
      "Train Epoch: 3679 [33024/118836 (28%)] Loss: 12169.224609\n",
      "Train Epoch: 3679 [65792/118836 (55%)] Loss: 12068.570312\n",
      "Train Epoch: 3679 [98560/118836 (83%)] Loss: 12278.870117\n",
      "    epoch          : 3679\n",
      "    loss           : 12188.658212979477\n",
      "    val_loss       : 12191.331889042314\n",
      "    val_log_likelihood: -12113.039204178298\n",
      "    val_log_marginal: -12121.88388565306\n",
      "Train Epoch: 3680 [256/118836 (0%)] Loss: 12272.669922\n",
      "Train Epoch: 3680 [33024/118836 (28%)] Loss: 12253.433594\n",
      "Train Epoch: 3680 [65792/118836 (55%)] Loss: 12212.390625\n",
      "Train Epoch: 3680 [98560/118836 (83%)] Loss: 12231.957031\n",
      "    epoch          : 3680\n",
      "    loss           : 12190.547309404727\n",
      "    val_loss       : 12187.851757225098\n",
      "    val_log_likelihood: -12112.089305469395\n",
      "    val_log_marginal: -12120.898924028197\n",
      "Train Epoch: 3681 [256/118836 (0%)] Loss: 12204.875000\n",
      "Train Epoch: 3681 [33024/118836 (28%)] Loss: 12216.668945\n",
      "Train Epoch: 3681 [65792/118836 (55%)] Loss: 12190.124023\n",
      "Train Epoch: 3681 [98560/118836 (83%)] Loss: 12214.246094\n",
      "    epoch          : 3681\n",
      "    loss           : 12188.149415677988\n",
      "    val_loss       : 12190.968719897966\n",
      "    val_log_likelihood: -12112.140677180263\n",
      "    val_log_marginal: -12120.83400253625\n",
      "Train Epoch: 3682 [256/118836 (0%)] Loss: 12234.648438\n",
      "Train Epoch: 3682 [33024/118836 (28%)] Loss: 12203.152344\n",
      "Train Epoch: 3682 [65792/118836 (55%)] Loss: 12183.212891\n",
      "Train Epoch: 3682 [98560/118836 (83%)] Loss: 12253.747070\n",
      "    epoch          : 3682\n",
      "    loss           : 12188.419390056348\n",
      "    val_loss       : 12188.314751504686\n",
      "    val_log_likelihood: -12112.660741218207\n",
      "    val_log_marginal: -12121.407752864574\n",
      "Train Epoch: 3683 [256/118836 (0%)] Loss: 12271.490234\n",
      "Train Epoch: 3683 [33024/118836 (28%)] Loss: 12177.206055\n",
      "Train Epoch: 3683 [65792/118836 (55%)] Loss: 12220.775391\n",
      "Train Epoch: 3683 [98560/118836 (83%)] Loss: 12208.759766\n",
      "    epoch          : 3683\n",
      "    loss           : 12187.222568690551\n",
      "    val_loss       : 12188.939170719916\n",
      "    val_log_likelihood: -12105.607115740022\n",
      "    val_log_marginal: -12114.317500735344\n",
      "Train Epoch: 3684 [256/118836 (0%)] Loss: 12267.346680\n",
      "Train Epoch: 3684 [33024/118836 (28%)] Loss: 12220.725586\n",
      "Train Epoch: 3684 [65792/118836 (55%)] Loss: 12168.681641\n",
      "Train Epoch: 3684 [98560/118836 (83%)] Loss: 12194.284180\n",
      "    epoch          : 3684\n",
      "    loss           : 12192.369256132393\n",
      "    val_loss       : 12191.979933346667\n",
      "    val_log_likelihood: -12111.895485195668\n",
      "    val_log_marginal: -12120.710400993043\n",
      "Train Epoch: 3685 [256/118836 (0%)] Loss: 12214.531250\n",
      "Train Epoch: 3685 [33024/118836 (28%)] Loss: 12150.804688\n",
      "Train Epoch: 3685 [65792/118836 (55%)] Loss: 12228.035156\n",
      "Train Epoch: 3685 [98560/118836 (83%)] Loss: 12135.909180\n",
      "    epoch          : 3685\n",
      "    loss           : 12191.606428188328\n",
      "    val_loss       : 12189.886451748933\n",
      "    val_log_likelihood: -12112.074736837003\n",
      "    val_log_marginal: -12121.167606571427\n",
      "Train Epoch: 3686 [256/118836 (0%)] Loss: 12259.523438\n",
      "Train Epoch: 3686 [33024/118836 (28%)] Loss: 12196.701172\n",
      "Train Epoch: 3686 [65792/118836 (55%)] Loss: 12161.978516\n",
      "Train Epoch: 3686 [98560/118836 (83%)] Loss: 12288.185547\n",
      "    epoch          : 3686\n",
      "    loss           : 12192.855003651002\n",
      "    val_loss       : 12189.249205358241\n",
      "    val_log_likelihood: -12110.668547256255\n",
      "    val_log_marginal: -12119.461395769336\n",
      "Train Epoch: 3687 [256/118836 (0%)] Loss: 12265.965820\n",
      "Train Epoch: 3687 [33024/118836 (28%)] Loss: 12123.120117\n",
      "Train Epoch: 3687 [65792/118836 (55%)] Loss: 12153.720703\n",
      "Train Epoch: 3687 [98560/118836 (83%)] Loss: 12192.771484\n",
      "    epoch          : 3687\n",
      "    loss           : 12192.98355481674\n",
      "    val_loss       : 12187.003051769452\n",
      "    val_log_likelihood: -12111.87331860008\n",
      "    val_log_marginal: -12120.62806791775\n",
      "Train Epoch: 3688 [256/118836 (0%)] Loss: 12254.701172\n",
      "Train Epoch: 3688 [33024/118836 (28%)] Loss: 12336.464844\n",
      "Train Epoch: 3688 [65792/118836 (55%)] Loss: 12210.793945\n",
      "Train Epoch: 3688 [98560/118836 (83%)] Loss: 12208.189453\n",
      "    epoch          : 3688\n",
      "    loss           : 12191.050769456937\n",
      "    val_loss       : 12189.594933143435\n",
      "    val_log_likelihood: -12108.91844273418\n",
      "    val_log_marginal: -12117.698091044087\n",
      "Train Epoch: 3689 [256/118836 (0%)] Loss: 12186.610352\n",
      "Train Epoch: 3689 [33024/118836 (28%)] Loss: 12186.324219\n",
      "Train Epoch: 3689 [65792/118836 (55%)] Loss: 12195.876953\n",
      "Train Epoch: 3689 [98560/118836 (83%)] Loss: 12168.994141\n",
      "    epoch          : 3689\n",
      "    loss           : 12189.598225386424\n",
      "    val_loss       : 12182.020916427135\n",
      "    val_log_likelihood: -12110.584530894592\n",
      "    val_log_marginal: -12119.404272126878\n",
      "Train Epoch: 3690 [256/118836 (0%)] Loss: 12457.205078\n",
      "Train Epoch: 3690 [33024/118836 (28%)] Loss: 12137.288086\n",
      "Train Epoch: 3690 [65792/118836 (55%)] Loss: 12140.159180\n",
      "Train Epoch: 3690 [98560/118836 (83%)] Loss: 12127.400391\n",
      "    epoch          : 3690\n",
      "    loss           : 12187.472536703888\n",
      "    val_loss       : 12189.385971878148\n",
      "    val_log_likelihood: -12111.205527230666\n",
      "    val_log_marginal: -12119.951835948836\n",
      "Train Epoch: 3691 [256/118836 (0%)] Loss: 12226.700195\n",
      "Train Epoch: 3691 [33024/118836 (28%)] Loss: 12250.849609\n",
      "Train Epoch: 3691 [65792/118836 (55%)] Loss: 12134.332031\n",
      "Train Epoch: 3691 [98560/118836 (83%)] Loss: 12204.509766\n",
      "    epoch          : 3691\n",
      "    loss           : 12188.162448789031\n",
      "    val_loss       : 12190.348144371648\n",
      "    val_log_likelihood: -12111.958871775485\n",
      "    val_log_marginal: -12120.851282993823\n",
      "Train Epoch: 3692 [256/118836 (0%)] Loss: 12267.569336\n",
      "Train Epoch: 3692 [33024/118836 (28%)] Loss: 12153.855469\n",
      "Train Epoch: 3692 [65792/118836 (55%)] Loss: 12262.921875\n",
      "Train Epoch: 3692 [98560/118836 (83%)] Loss: 12197.791992\n",
      "    epoch          : 3692\n",
      "    loss           : 12184.075275763804\n",
      "    val_loss       : 12190.144814163956\n",
      "    val_log_likelihood: -12109.875533595688\n",
      "    val_log_marginal: -12118.64905880097\n",
      "Train Epoch: 3693 [256/118836 (0%)] Loss: 12273.908203\n",
      "Train Epoch: 3693 [33024/118836 (28%)] Loss: 12248.560547\n",
      "Train Epoch: 3693 [65792/118836 (55%)] Loss: 12214.626953\n",
      "Train Epoch: 3693 [98560/118836 (83%)] Loss: 12187.402344\n",
      "    epoch          : 3693\n",
      "    loss           : 12188.361387736506\n",
      "    val_loss       : 12186.830437369685\n",
      "    val_log_likelihood: -12111.14398440731\n",
      "    val_log_marginal: -12119.890286462429\n",
      "Train Epoch: 3694 [256/118836 (0%)] Loss: 12211.500000\n",
      "Train Epoch: 3694 [33024/118836 (28%)] Loss: 12283.927734\n",
      "Train Epoch: 3694 [65792/118836 (55%)] Loss: 12325.089844\n",
      "Train Epoch: 3694 [98560/118836 (83%)] Loss: 12151.766602\n",
      "    epoch          : 3694\n",
      "    loss           : 12192.456681819946\n",
      "    val_loss       : 12188.512116098824\n",
      "    val_log_likelihood: -12108.930572302781\n",
      "    val_log_marginal: -12117.895133227275\n",
      "Train Epoch: 3695 [256/118836 (0%)] Loss: 12219.043945\n",
      "Train Epoch: 3695 [33024/118836 (28%)] Loss: 12218.096680\n",
      "Train Epoch: 3695 [65792/118836 (55%)] Loss: 12246.226562\n",
      "Train Epoch: 3695 [98560/118836 (83%)] Loss: 12300.909180\n",
      "    epoch          : 3695\n",
      "    loss           : 12194.08376062991\n",
      "    val_loss       : 12199.07859878242\n",
      "    val_log_likelihood: -12115.834740746484\n",
      "    val_log_marginal: -12125.034030202985\n",
      "Train Epoch: 3696 [256/118836 (0%)] Loss: 12268.535156\n",
      "Train Epoch: 3696 [33024/118836 (28%)] Loss: 12317.355469\n",
      "Train Epoch: 3696 [65792/118836 (55%)] Loss: 12179.677734\n",
      "Train Epoch: 3696 [98560/118836 (83%)] Loss: 12257.381836\n",
      "    epoch          : 3696\n",
      "    loss           : 12196.24834735577\n",
      "    val_loss       : 12189.781965559388\n",
      "    val_log_likelihood: -12111.394689567824\n",
      "    val_log_marginal: -12120.694457043186\n",
      "Train Epoch: 3697 [256/118836 (0%)] Loss: 12243.673828\n",
      "Train Epoch: 3697 [33024/118836 (28%)] Loss: 12169.029297\n",
      "Train Epoch: 3697 [65792/118836 (55%)] Loss: 12224.509766\n",
      "Train Epoch: 3697 [98560/118836 (83%)] Loss: 12193.804688\n",
      "    epoch          : 3697\n",
      "    loss           : 12192.201467347755\n",
      "    val_loss       : 12199.257541131232\n",
      "    val_log_likelihood: -12111.375758471619\n",
      "    val_log_marginal: -12120.603259828995\n",
      "Train Epoch: 3698 [256/118836 (0%)] Loss: 12251.788086\n",
      "Train Epoch: 3698 [33024/118836 (28%)] Loss: 12105.719727\n",
      "Train Epoch: 3698 [65792/118836 (55%)] Loss: 12187.735352\n",
      "Train Epoch: 3698 [98560/118836 (83%)] Loss: 12207.572266\n",
      "    epoch          : 3698\n",
      "    loss           : 12192.98213108716\n",
      "    val_loss       : 12195.675300768718\n",
      "    val_log_likelihood: -12111.871156592482\n",
      "    val_log_marginal: -12121.09558143666\n",
      "Train Epoch: 3699 [256/118836 (0%)] Loss: 12145.051758\n",
      "Train Epoch: 3699 [33024/118836 (28%)] Loss: 12232.080078\n",
      "Train Epoch: 3699 [65792/118836 (55%)] Loss: 12191.237305\n",
      "Train Epoch: 3699 [98560/118836 (83%)] Loss: 12176.852539\n",
      "    epoch          : 3699\n",
      "    loss           : 12188.904046797456\n",
      "    val_loss       : 12187.267681409223\n",
      "    val_log_likelihood: -12110.33805782801\n",
      "    val_log_marginal: -12119.466499798968\n",
      "Train Epoch: 3700 [256/118836 (0%)] Loss: 12221.147461\n",
      "Train Epoch: 3700 [33024/118836 (28%)] Loss: 12184.212891\n",
      "Train Epoch: 3700 [65792/118836 (55%)] Loss: 12269.168945\n",
      "Train Epoch: 3700 [98560/118836 (83%)] Loss: 12176.562500\n",
      "    epoch          : 3700\n",
      "    loss           : 12194.04621216527\n",
      "    val_loss       : 12188.822749322992\n",
      "    val_log_likelihood: -12109.586740074441\n",
      "    val_log_marginal: -12118.514419699008\n",
      "Saving checkpoint: saved/models/SelfiesAutoencodingOperad/0905_154251/checkpoint-epoch3700.pth ...\n",
      "Train Epoch: 3701 [256/118836 (0%)] Loss: 12143.736328\n",
      "Train Epoch: 3701 [33024/118836 (28%)] Loss: 12237.110352\n",
      "Train Epoch: 3701 [65792/118836 (55%)] Loss: 12186.572266\n",
      "Train Epoch: 3701 [98560/118836 (83%)] Loss: 12201.583008\n",
      "    epoch          : 3701\n",
      "    loss           : 12190.954806884565\n",
      "    val_loss       : 12188.782929954135\n",
      "    val_log_likelihood: -12109.959204242918\n",
      "    val_log_marginal: -12118.962318503114\n",
      "Train Epoch: 3702 [256/118836 (0%)] Loss: 12222.492188\n",
      "Train Epoch: 3702 [33024/118836 (28%)] Loss: 12191.863281\n",
      "Train Epoch: 3702 [65792/118836 (55%)] Loss: 12248.983398\n",
      "Train Epoch: 3702 [98560/118836 (83%)] Loss: 12229.172852\n",
      "    epoch          : 3702\n",
      "    loss           : 12190.444845623966\n",
      "    val_loss       : 12187.530073944181\n",
      "    val_log_likelihood: -12111.628307873243\n",
      "    val_log_marginal: -12120.522004479417\n",
      "Train Epoch: 3703 [256/118836 (0%)] Loss: 12167.589844\n",
      "Train Epoch: 3703 [33024/118836 (28%)] Loss: 12257.993164\n",
      "Train Epoch: 3703 [65792/118836 (55%)] Loss: 12173.857422\n",
      "Train Epoch: 3703 [98560/118836 (83%)] Loss: 12262.978516\n",
      "    epoch          : 3703\n",
      "    loss           : 12190.489681393456\n",
      "    val_loss       : 12191.694345194164\n",
      "    val_log_likelihood: -12111.262502584781\n",
      "    val_log_marginal: -12120.269634945336\n",
      "Train Epoch: 3704 [256/118836 (0%)] Loss: 12245.894531\n",
      "Train Epoch: 3704 [33024/118836 (28%)] Loss: 12181.464844\n",
      "Train Epoch: 3704 [65792/118836 (55%)] Loss: 12230.086914\n",
      "Train Epoch: 3704 [98560/118836 (83%)] Loss: 12277.176758\n",
      "    epoch          : 3704\n",
      "    loss           : 12188.25552819996\n",
      "    val_loss       : 12187.407499293791\n",
      "    val_log_likelihood: -12113.526752966036\n",
      "    val_log_marginal: -12122.460882891968\n",
      "Train Epoch: 3705 [256/118836 (0%)] Loss: 12260.662109\n",
      "Train Epoch: 3705 [33024/118836 (28%)] Loss: 12134.297852\n",
      "Train Epoch: 3705 [65792/118836 (55%)] Loss: 12273.391602\n",
      "Train Epoch: 3705 [98560/118836 (83%)] Loss: 12350.082031\n",
      "    epoch          : 3705\n",
      "    loss           : 12191.488373171267\n",
      "    val_loss       : 12194.30840116497\n",
      "    val_log_likelihood: -12110.427002074288\n",
      "    val_log_marginal: -12119.236605534279\n",
      "Train Epoch: 3706 [256/118836 (0%)] Loss: 12177.714844\n",
      "Train Epoch: 3706 [33024/118836 (28%)] Loss: 12275.843750\n",
      "Train Epoch: 3706 [65792/118836 (55%)] Loss: 12172.100586\n",
      "Train Epoch: 3706 [98560/118836 (83%)] Loss: 12133.222656\n",
      "    epoch          : 3706\n",
      "    loss           : 12185.566235492917\n",
      "    val_loss       : 12188.819160155239\n",
      "    val_log_likelihood: -12107.812009214744\n",
      "    val_log_marginal: -12116.618089900028\n",
      "Train Epoch: 3707 [256/118836 (0%)] Loss: 12144.190430\n",
      "Train Epoch: 3707 [33024/118836 (28%)] Loss: 12168.812500\n",
      "Train Epoch: 3707 [65792/118836 (55%)] Loss: 12194.736328\n",
      "Train Epoch: 3707 [98560/118836 (83%)] Loss: 12182.830078\n",
      "    epoch          : 3707\n",
      "    loss           : 12191.255098964795\n",
      "    val_loss       : 12189.460860042247\n",
      "    val_log_likelihood: -12109.54626466863\n",
      "    val_log_marginal: -12118.29540575086\n",
      "Train Epoch: 3708 [256/118836 (0%)] Loss: 12258.124023\n",
      "Train Epoch: 3708 [33024/118836 (28%)] Loss: 12197.800781\n",
      "Train Epoch: 3708 [65792/118836 (55%)] Loss: 12258.668945\n",
      "Train Epoch: 3708 [98560/118836 (83%)] Loss: 12279.325195\n",
      "    epoch          : 3708\n",
      "    loss           : 12191.343801049421\n",
      "    val_loss       : 12190.573693515642\n",
      "    val_log_likelihood: -12110.770075184812\n",
      "    val_log_marginal: -12119.490532621168\n",
      "Train Epoch: 3709 [256/118836 (0%)] Loss: 12191.626953\n",
      "Train Epoch: 3709 [33024/118836 (28%)] Loss: 12211.760742\n",
      "Train Epoch: 3709 [65792/118836 (55%)] Loss: 12301.790039\n",
      "Train Epoch: 3709 [98560/118836 (83%)] Loss: 12150.945312\n",
      "    epoch          : 3709\n",
      "    loss           : 12191.205096056918\n",
      "    val_loss       : 12192.901004340683\n",
      "    val_log_likelihood: -12110.369588599824\n",
      "    val_log_marginal: -12119.181458680208\n",
      "Train Epoch: 3710 [256/118836 (0%)] Loss: 12290.450195\n",
      "Train Epoch: 3710 [33024/118836 (28%)] Loss: 12257.465820\n",
      "Train Epoch: 3710 [65792/118836 (55%)] Loss: 12207.722656\n",
      "Train Epoch: 3710 [98560/118836 (83%)] Loss: 12266.412109\n",
      "    epoch          : 3710\n",
      "    loss           : 12205.470240449235\n",
      "    val_loss       : 12197.10283976035\n",
      "    val_log_likelihood: -12112.302091087675\n",
      "    val_log_marginal: -12121.163883431087\n",
      "Train Epoch: 3711 [256/118836 (0%)] Loss: 12223.006836\n",
      "Train Epoch: 3711 [33024/118836 (28%)] Loss: 12243.019531\n",
      "Train Epoch: 3711 [65792/118836 (55%)] Loss: 12209.845703\n",
      "Train Epoch: 3711 [98560/118836 (83%)] Loss: 12245.297852\n",
      "    epoch          : 3711\n",
      "    loss           : 12197.817727072994\n",
      "    val_loss       : 12193.22257513064\n",
      "    val_log_likelihood: -12111.57079359233\n",
      "    val_log_marginal: -12120.431856763522\n",
      "Train Epoch: 3712 [256/118836 (0%)] Loss: 12186.206055\n",
      "Train Epoch: 3712 [33024/118836 (28%)] Loss: 12207.708008\n",
      "Train Epoch: 3712 [65792/118836 (55%)] Loss: 12244.001953\n",
      "Train Epoch: 3712 [98560/118836 (83%)] Loss: 12232.698242\n",
      "    epoch          : 3712\n",
      "    loss           : 12190.143183771454\n",
      "    val_loss       : 12187.986895494309\n",
      "    val_log_likelihood: -12112.93443412686\n",
      "    val_log_marginal: -12121.82327626229\n",
      "Train Epoch: 3713 [256/118836 (0%)] Loss: 12221.815430\n",
      "Train Epoch: 3713 [33024/118836 (28%)] Loss: 12272.791016\n",
      "Train Epoch: 3713 [65792/118836 (55%)] Loss: 12283.013672\n",
      "Train Epoch: 3713 [98560/118836 (83%)] Loss: 12209.644531\n",
      "    epoch          : 3713\n",
      "    loss           : 12189.718149038463\n",
      "    val_loss       : 12190.955306644084\n",
      "    val_log_likelihood: -12114.726539398522\n",
      "    val_log_marginal: -12123.635712535142\n",
      "Train Epoch: 3714 [256/118836 (0%)] Loss: 12275.043945\n",
      "Train Epoch: 3714 [33024/118836 (28%)] Loss: 12153.451172\n",
      "Train Epoch: 3714 [65792/118836 (55%)] Loss: 12266.577148\n",
      "Train Epoch: 3714 [98560/118836 (83%)] Loss: 12220.232422\n",
      "    epoch          : 3714\n",
      "    loss           : 12189.05121468543\n",
      "    val_loss       : 12187.36247231018\n",
      "    val_log_likelihood: -12110.941788636012\n",
      "    val_log_marginal: -12119.848285917285\n",
      "Train Epoch: 3715 [256/118836 (0%)] Loss: 12181.019531\n",
      "Train Epoch: 3715 [33024/118836 (28%)] Loss: 12213.535156\n",
      "Train Epoch: 3715 [65792/118836 (55%)] Loss: 12162.197266\n",
      "Train Epoch: 3715 [98560/118836 (83%)] Loss: 12246.866211\n",
      "    epoch          : 3715\n",
      "    loss           : 12190.8940058933\n",
      "    val_loss       : 12188.788454820222\n",
      "    val_log_likelihood: -12110.290581704921\n",
      "    val_log_marginal: -12119.274515332247\n",
      "Train Epoch: 3716 [256/118836 (0%)] Loss: 12210.870117\n",
      "Train Epoch: 3716 [33024/118836 (28%)] Loss: 12186.379883\n",
      "Train Epoch: 3716 [65792/118836 (55%)] Loss: 12170.845703\n",
      "Train Epoch: 3716 [98560/118836 (83%)] Loss: 12150.118164\n",
      "    epoch          : 3716\n",
      "    loss           : 12187.755877953114\n",
      "    val_loss       : 12192.47344385565\n",
      "    val_log_likelihood: -12107.643900078836\n",
      "    val_log_marginal: -12116.50499935709\n",
      "Train Epoch: 3717 [256/118836 (0%)] Loss: 12201.332031\n",
      "Train Epoch: 3717 [33024/118836 (28%)] Loss: 12180.822266\n",
      "Train Epoch: 3717 [65792/118836 (55%)] Loss: 12270.048828\n",
      "Train Epoch: 3717 [98560/118836 (83%)] Loss: 12219.470703\n",
      "    epoch          : 3717\n",
      "    loss           : 12189.562094189412\n",
      "    val_loss       : 12187.996811332536\n",
      "    val_log_likelihood: -12107.703293980045\n",
      "    val_log_marginal: -12116.518876421385\n",
      "Train Epoch: 3718 [256/118836 (0%)] Loss: 12179.014648\n",
      "Train Epoch: 3718 [33024/118836 (28%)] Loss: 12177.785156\n",
      "Train Epoch: 3718 [65792/118836 (55%)] Loss: 12243.348633\n",
      "Train Epoch: 3718 [98560/118836 (83%)] Loss: 12203.360352\n",
      "    epoch          : 3718\n",
      "    loss           : 12187.47119197167\n",
      "    val_loss       : 12190.404403674998\n",
      "    val_log_likelihood: -12109.572664812087\n",
      "    val_log_marginal: -12118.336932832586\n",
      "Train Epoch: 3719 [256/118836 (0%)] Loss: 12289.973633\n",
      "Train Epoch: 3719 [33024/118836 (28%)] Loss: 12204.208008\n",
      "Train Epoch: 3719 [65792/118836 (55%)] Loss: 12272.362305\n",
      "Train Epoch: 3719 [98560/118836 (83%)] Loss: 12178.250000\n",
      "    epoch          : 3719\n",
      "    loss           : 12187.323776267835\n",
      "    val_loss       : 12189.596066665023\n",
      "    val_log_likelihood: -12111.595376150228\n",
      "    val_log_marginal: -12120.314973186782\n",
      "Train Epoch: 3720 [256/118836 (0%)] Loss: 12229.636719\n",
      "Train Epoch: 3720 [33024/118836 (28%)] Loss: 12185.198242\n",
      "Train Epoch: 3720 [65792/118836 (55%)] Loss: 12274.388672\n",
      "Train Epoch: 3720 [98560/118836 (83%)] Loss: 12231.876953\n",
      "    epoch          : 3720\n",
      "    loss           : 12188.306412194996\n",
      "    val_loss       : 12190.453257111716\n",
      "    val_log_likelihood: -12111.463157826716\n",
      "    val_log_marginal: -12120.221799678286\n",
      "Train Epoch: 3721 [256/118836 (0%)] Loss: 12151.774414\n",
      "Train Epoch: 3721 [33024/118836 (28%)] Loss: 12177.193359\n",
      "Train Epoch: 3721 [65792/118836 (55%)] Loss: 12224.818359\n",
      "Train Epoch: 3721 [98560/118836 (83%)] Loss: 12166.184570\n",
      "    epoch          : 3721\n",
      "    loss           : 12193.08332719448\n",
      "    val_loss       : 12192.065767914535\n",
      "    val_log_likelihood: -12111.293499922456\n",
      "    val_log_marginal: -12120.23978573409\n",
      "Train Epoch: 3722 [256/118836 (0%)] Loss: 12181.445312\n",
      "Train Epoch: 3722 [33024/118836 (28%)] Loss: 12252.988281\n",
      "Train Epoch: 3722 [65792/118836 (55%)] Loss: 12257.655273\n",
      "Train Epoch: 3722 [98560/118836 (83%)] Loss: 12193.861328\n",
      "    epoch          : 3722\n",
      "    loss           : 12193.199091449544\n",
      "    val_loss       : 12192.164200167692\n",
      "    val_log_likelihood: -12110.98283640922\n",
      "    val_log_marginal: -12119.876787487992\n",
      "Train Epoch: 3723 [256/118836 (0%)] Loss: 12237.865234\n",
      "Train Epoch: 3723 [33024/118836 (28%)] Loss: 12174.582031\n",
      "Train Epoch: 3723 [65792/118836 (55%)] Loss: 12136.666992\n",
      "Train Epoch: 3723 [98560/118836 (83%)] Loss: 12167.245117\n",
      "    epoch          : 3723\n",
      "    loss           : 12190.032932692307\n",
      "    val_loss       : 12183.719416822296\n",
      "    val_log_likelihood: -12108.447279841295\n",
      "    val_log_marginal: -12117.244813683781\n",
      "Train Epoch: 3724 [256/118836 (0%)] Loss: 12235.422852\n",
      "Train Epoch: 3724 [33024/118836 (28%)] Loss: 12220.905273\n",
      "Train Epoch: 3724 [65792/118836 (55%)] Loss: 12163.701172\n",
      "Train Epoch: 3724 [98560/118836 (83%)] Loss: 12186.842773\n",
      "    epoch          : 3724\n",
      "    loss           : 12186.955216410774\n",
      "    val_loss       : 12191.13334761602\n",
      "    val_log_likelihood: -12110.933073239763\n",
      "    val_log_marginal: -12119.644005339042\n",
      "Train Epoch: 3725 [256/118836 (0%)] Loss: 12323.951172\n",
      "Train Epoch: 3725 [33024/118836 (28%)] Loss: 12197.703125\n",
      "Train Epoch: 3725 [65792/118836 (55%)] Loss: 12139.368164\n",
      "Train Epoch: 3725 [98560/118836 (83%)] Loss: 12303.500977\n",
      "    epoch          : 3725\n",
      "    loss           : 12187.179813346514\n",
      "    val_loss       : 12189.141069348107\n",
      "    val_log_likelihood: -12113.173463347808\n",
      "    val_log_marginal: -12121.862277220212\n",
      "Train Epoch: 3726 [256/118836 (0%)] Loss: 12170.346680\n",
      "Train Epoch: 3726 [33024/118836 (28%)] Loss: 12172.758789\n",
      "Train Epoch: 3726 [65792/118836 (55%)] Loss: 12162.486328\n",
      "Train Epoch: 3726 [98560/118836 (83%)] Loss: 12170.318359\n",
      "    epoch          : 3726\n",
      "    loss           : 12191.625934236716\n",
      "    val_loss       : 12189.20830422051\n",
      "    val_log_likelihood: -12112.960732333024\n",
      "    val_log_marginal: -12121.754447625337\n",
      "Train Epoch: 3727 [256/118836 (0%)] Loss: 12218.666992\n",
      "Train Epoch: 3727 [33024/118836 (28%)] Loss: 12265.789062\n",
      "Train Epoch: 3727 [65792/118836 (55%)] Loss: 12171.862305\n",
      "Train Epoch: 3727 [98560/118836 (83%)] Loss: 12260.375000\n",
      "    epoch          : 3727\n",
      "    loss           : 12189.756605407361\n",
      "    val_loss       : 12186.678318975972\n",
      "    val_log_likelihood: -12111.252669270832\n",
      "    val_log_marginal: -12120.215296940642\n",
      "Train Epoch: 3728 [256/118836 (0%)] Loss: 12296.423828\n",
      "Train Epoch: 3728 [33024/118836 (28%)] Loss: 12169.281250\n",
      "Train Epoch: 3728 [65792/118836 (55%)] Loss: 12227.646484\n",
      "Train Epoch: 3728 [98560/118836 (83%)] Loss: 12163.552734\n",
      "    epoch          : 3728\n",
      "    loss           : 12188.00980471981\n",
      "    val_loss       : 12189.718816927369\n",
      "    val_log_likelihood: -12113.333664508375\n",
      "    val_log_marginal: -12122.247798532428\n",
      "Train Epoch: 3729 [256/118836 (0%)] Loss: 12189.276367\n",
      "Train Epoch: 3729 [33024/118836 (28%)] Loss: 12248.374023\n",
      "Train Epoch: 3729 [65792/118836 (55%)] Loss: 12145.400391\n",
      "Train Epoch: 3729 [98560/118836 (83%)] Loss: 12142.994141\n",
      "    epoch          : 3729\n",
      "    loss           : 12187.681947083074\n",
      "    val_loss       : 12189.197618710894\n",
      "    val_log_likelihood: -12109.494285534274\n",
      "    val_log_marginal: -12118.169152424296\n",
      "Train Epoch: 3730 [256/118836 (0%)] Loss: 12169.018555\n",
      "Train Epoch: 3730 [33024/118836 (28%)] Loss: 12243.402344\n",
      "Train Epoch: 3730 [65792/118836 (55%)] Loss: 12152.189453\n",
      "Train Epoch: 3730 [98560/118836 (83%)] Loss: 12160.848633\n",
      "    epoch          : 3730\n",
      "    loss           : 12186.6824152515\n",
      "    val_loss       : 12184.870877041976\n",
      "    val_log_likelihood: -12110.625933105874\n",
      "    val_log_marginal: -12119.358594869467\n",
      "Train Epoch: 3731 [256/118836 (0%)] Loss: 12198.638672\n",
      "Train Epoch: 3731 [33024/118836 (28%)] Loss: 12206.084961\n",
      "Train Epoch: 3731 [65792/118836 (55%)] Loss: 12131.916016\n",
      "Train Epoch: 3731 [98560/118836 (83%)] Loss: 12222.827148\n",
      "    epoch          : 3731\n",
      "    loss           : 12187.148349294355\n",
      "    val_loss       : 12185.581971702146\n",
      "    val_log_likelihood: -12108.501517912531\n",
      "    val_log_marginal: -12117.175820239556\n",
      "Train Epoch: 3732 [256/118836 (0%)] Loss: 12204.400391\n",
      "Train Epoch: 3732 [33024/118836 (28%)] Loss: 12131.359375\n",
      "Train Epoch: 3732 [65792/118836 (55%)] Loss: 12234.969727\n",
      "Train Epoch: 3732 [98560/118836 (83%)] Loss: 12207.840820\n",
      "    epoch          : 3732\n",
      "    loss           : 12186.437170601994\n",
      "    val_loss       : 12185.492550195568\n",
      "    val_log_likelihood: -12106.75739764268\n",
      "    val_log_marginal: -12115.375762254738\n",
      "Train Epoch: 3733 [256/118836 (0%)] Loss: 12261.880859\n",
      "Train Epoch: 3733 [33024/118836 (28%)] Loss: 12161.776367\n",
      "Train Epoch: 3733 [65792/118836 (55%)] Loss: 12266.777344\n",
      "Train Epoch: 3733 [98560/118836 (83%)] Loss: 12135.250977\n",
      "    epoch          : 3733\n",
      "    loss           : 12184.680004620295\n",
      "    val_loss       : 12186.067986809576\n",
      "    val_log_likelihood: -12105.994261301954\n",
      "    val_log_marginal: -12114.689142581428\n",
      "Train Epoch: 3734 [256/118836 (0%)] Loss: 12176.968750\n",
      "Train Epoch: 3734 [33024/118836 (28%)] Loss: 12144.015625\n",
      "Train Epoch: 3734 [65792/118836 (55%)] Loss: 12166.402344\n",
      "Train Epoch: 3734 [98560/118836 (83%)] Loss: 12175.136719\n",
      "    epoch          : 3734\n",
      "    loss           : 12187.037483198925\n",
      "    val_loss       : 12187.794840052324\n",
      "    val_log_likelihood: -12107.199484013132\n",
      "    val_log_marginal: -12115.934594523807\n",
      "Train Epoch: 3735 [256/118836 (0%)] Loss: 12266.625000\n",
      "Train Epoch: 3735 [33024/118836 (28%)] Loss: 12276.194336\n",
      "Train Epoch: 3735 [65792/118836 (55%)] Loss: 12147.821289\n",
      "Train Epoch: 3735 [98560/118836 (83%)] Loss: 12262.966797\n",
      "    epoch          : 3735\n",
      "    loss           : 12186.537339258943\n",
      "    val_loss       : 12182.36981795585\n",
      "    val_log_likelihood: -12110.693324480459\n",
      "    val_log_marginal: -12119.449682551449\n",
      "Train Epoch: 3736 [256/118836 (0%)] Loss: 12250.604492\n",
      "Train Epoch: 3736 [33024/118836 (28%)] Loss: 12297.777344\n",
      "Train Epoch: 3736 [65792/118836 (55%)] Loss: 12217.347656\n",
      "Train Epoch: 3736 [98560/118836 (83%)] Loss: 12213.543945\n",
      "    epoch          : 3736\n",
      "    loss           : 12193.219940453113\n",
      "    val_loss       : 12186.619610126334\n",
      "    val_log_likelihood: -12103.611865759409\n",
      "    val_log_marginal: -12112.326487475435\n",
      "Train Epoch: 3737 [256/118836 (0%)] Loss: 12237.452148\n",
      "Train Epoch: 3737 [33024/118836 (28%)] Loss: 12180.361328\n",
      "Train Epoch: 3737 [65792/118836 (55%)] Loss: 12336.063477\n",
      "Train Epoch: 3737 [98560/118836 (83%)] Loss: 12223.947266\n",
      "    epoch          : 3737\n",
      "    loss           : 12188.360485486455\n",
      "    val_loss       : 12192.595156015921\n",
      "    val_log_likelihood: -12108.810072083073\n",
      "    val_log_marginal: -12117.82023383448\n",
      "Train Epoch: 3738 [256/118836 (0%)] Loss: 12150.423828\n",
      "Train Epoch: 3738 [33024/118836 (28%)] Loss: 12214.956055\n",
      "Train Epoch: 3738 [65792/118836 (55%)] Loss: 12208.712891\n",
      "Train Epoch: 3738 [98560/118836 (83%)] Loss: 12342.816406\n",
      "    epoch          : 3738\n",
      "    loss           : 12195.400321805211\n",
      "    val_loss       : 12202.906749290987\n",
      "    val_log_likelihood: -12111.927789140043\n",
      "    val_log_marginal: -12120.904812080133\n",
      "Train Epoch: 3739 [256/118836 (0%)] Loss: 12137.305664\n",
      "Train Epoch: 3739 [33024/118836 (28%)] Loss: 12183.964844\n",
      "Train Epoch: 3739 [65792/118836 (55%)] Loss: 12206.884766\n",
      "Train Epoch: 3739 [98560/118836 (83%)] Loss: 12210.642578\n",
      "    epoch          : 3739\n",
      "    loss           : 12193.010435567876\n",
      "    val_loss       : 12186.974373895924\n",
      "    val_log_likelihood: -12111.026058952388\n",
      "    val_log_marginal: -12119.95757363172\n",
      "Train Epoch: 3740 [256/118836 (0%)] Loss: 12202.991211\n",
      "Train Epoch: 3740 [33024/118836 (28%)] Loss: 12178.679688\n",
      "Train Epoch: 3740 [65792/118836 (55%)] Loss: 12237.732422\n",
      "Train Epoch: 3740 [98560/118836 (83%)] Loss: 12307.920898\n",
      "    epoch          : 3740\n",
      "    loss           : 12192.12458110396\n",
      "    val_loss       : 12188.32458638792\n",
      "    val_log_likelihood: -12109.509376615488\n",
      "    val_log_marginal: -12118.347271761766\n",
      "Train Epoch: 3741 [256/118836 (0%)] Loss: 12165.032227\n",
      "Train Epoch: 3741 [33024/118836 (28%)] Loss: 12223.154297\n",
      "Train Epoch: 3741 [65792/118836 (55%)] Loss: 12279.370117\n",
      "Train Epoch: 3741 [98560/118836 (83%)] Loss: 12147.785156\n",
      "    epoch          : 3741\n",
      "    loss           : 12191.404940162325\n",
      "    val_loss       : 12189.997469982789\n",
      "    val_log_likelihood: -12110.262326819686\n",
      "    val_log_marginal: -12119.092994525017\n",
      "Train Epoch: 3742 [256/118836 (0%)] Loss: 12249.274414\n",
      "Train Epoch: 3742 [33024/118836 (28%)] Loss: 12213.415039\n",
      "Train Epoch: 3742 [65792/118836 (55%)] Loss: 12270.839844\n",
      "Train Epoch: 3742 [98560/118836 (83%)] Loss: 12184.720703\n",
      "    epoch          : 3742\n",
      "    loss           : 12186.05657471309\n",
      "    val_loss       : 12187.640994738216\n",
      "    val_log_likelihood: -12110.524654285566\n",
      "    val_log_marginal: -12119.448228091855\n",
      "Train Epoch: 3743 [256/118836 (0%)] Loss: 12204.409180\n",
      "Train Epoch: 3743 [33024/118836 (28%)] Loss: 12324.347656\n",
      "Train Epoch: 3743 [65792/118836 (55%)] Loss: 12160.630859\n",
      "Train Epoch: 3743 [98560/118836 (83%)] Loss: 12210.998047\n",
      "    epoch          : 3743\n",
      "    loss           : 12183.740576373812\n",
      "    val_loss       : 12186.30919507538\n",
      "    val_log_likelihood: -12104.6737473506\n",
      "    val_log_marginal: -12113.36741009681\n",
      "Train Epoch: 3744 [256/118836 (0%)] Loss: 12194.972656\n",
      "Train Epoch: 3744 [33024/118836 (28%)] Loss: 12219.648438\n",
      "Train Epoch: 3744 [65792/118836 (55%)] Loss: 12108.835938\n",
      "Train Epoch: 3744 [98560/118836 (83%)] Loss: 12100.068359\n",
      "    epoch          : 3744\n",
      "    loss           : 12184.99091998811\n",
      "    val_loss       : 12189.667174650844\n",
      "    val_log_likelihood: -12105.69867190731\n",
      "    val_log_marginal: -12114.358834361668\n",
      "Train Epoch: 3745 [256/118836 (0%)] Loss: 12291.503906\n",
      "Train Epoch: 3745 [33024/118836 (28%)] Loss: 12251.046875\n",
      "Train Epoch: 3745 [65792/118836 (55%)] Loss: 12298.075195\n",
      "Train Epoch: 3745 [98560/118836 (83%)] Loss: 12123.213867\n",
      "    epoch          : 3745\n",
      "    loss           : 12189.220361126188\n",
      "    val_loss       : 12189.21057664469\n",
      "    val_log_likelihood: -12107.7006600884\n",
      "    val_log_marginal: -12116.505762570105\n",
      "Train Epoch: 3746 [256/118836 (0%)] Loss: 12316.314453\n",
      "Train Epoch: 3746 [33024/118836 (28%)] Loss: 12191.398438\n",
      "Train Epoch: 3746 [65792/118836 (55%)] Loss: 12115.618164\n",
      "Train Epoch: 3746 [98560/118836 (83%)] Loss: 12258.613281\n",
      "    epoch          : 3746\n",
      "    loss           : 12187.2328528872\n",
      "    val_loss       : 12188.432872663034\n",
      "    val_log_likelihood: -12106.59302803841\n",
      "    val_log_marginal: -12115.276990327775\n",
      "Train Epoch: 3747 [256/118836 (0%)] Loss: 12216.958984\n",
      "Train Epoch: 3747 [33024/118836 (28%)] Loss: 12203.002930\n",
      "Train Epoch: 3747 [65792/118836 (55%)] Loss: 12236.043945\n",
      "Train Epoch: 3747 [98560/118836 (83%)] Loss: 12248.720703\n",
      "    epoch          : 3747\n",
      "    loss           : 12190.956300403226\n",
      "    val_loss       : 12192.102505564742\n",
      "    val_log_likelihood: -12112.141165542285\n",
      "    val_log_marginal: -12120.8461716579\n",
      "Train Epoch: 3748 [256/118836 (0%)] Loss: 12126.044922\n",
      "Train Epoch: 3748 [33024/118836 (28%)] Loss: 12184.997070\n",
      "Train Epoch: 3748 [65792/118836 (55%)] Loss: 12220.774414\n",
      "Train Epoch: 3748 [98560/118836 (83%)] Loss: 12184.646484\n",
      "    epoch          : 3748\n",
      "    loss           : 12187.31111795001\n",
      "    val_loss       : 12189.560197830531\n",
      "    val_log_likelihood: -12110.229711570772\n",
      "    val_log_marginal: -12119.003322355604\n",
      "Train Epoch: 3749 [256/118836 (0%)] Loss: 12156.547852\n",
      "Train Epoch: 3749 [33024/118836 (28%)] Loss: 12246.116211\n",
      "Train Epoch: 3749 [65792/118836 (55%)] Loss: 12273.071289\n",
      "Train Epoch: 3749 [98560/118836 (83%)] Loss: 12206.984375\n",
      "    epoch          : 3749\n",
      "    loss           : 12190.099898547352\n",
      "    val_loss       : 12189.080882087555\n",
      "    val_log_likelihood: -12109.45199205826\n",
      "    val_log_marginal: -12118.314995040284\n",
      "Train Epoch: 3750 [256/118836 (0%)] Loss: 12202.541992\n",
      "Train Epoch: 3750 [33024/118836 (28%)] Loss: 12170.225586\n",
      "Train Epoch: 3750 [65792/118836 (55%)] Loss: 12166.742188\n",
      "Train Epoch: 3750 [98560/118836 (83%)] Loss: 12203.303711\n",
      "    epoch          : 3750\n",
      "    loss           : 12191.390734691635\n",
      "    val_loss       : 12191.469581645704\n",
      "    val_log_likelihood: -12110.82580548232\n",
      "    val_log_marginal: -12119.727940559087\n",
      "Train Epoch: 3751 [256/118836 (0%)] Loss: 12175.218750\n",
      "Train Epoch: 3751 [33024/118836 (28%)] Loss: 12184.928711\n",
      "Train Epoch: 3751 [65792/118836 (55%)] Loss: 12218.241211\n",
      "Train Epoch: 3751 [98560/118836 (83%)] Loss: 12227.789062\n",
      "    epoch          : 3751\n",
      "    loss           : 12188.862579643559\n",
      "    val_loss       : 12188.14574610399\n",
      "    val_log_likelihood: -12109.133825895628\n",
      "    val_log_marginal: -12117.867916947096\n",
      "Train Epoch: 3752 [256/118836 (0%)] Loss: 12249.652344\n",
      "Train Epoch: 3752 [33024/118836 (28%)] Loss: 12174.130859\n",
      "Train Epoch: 3752 [65792/118836 (55%)] Loss: 12218.307617\n",
      "Train Epoch: 3752 [98560/118836 (83%)] Loss: 12228.767578\n",
      "    epoch          : 3752\n",
      "    loss           : 12186.149891600753\n",
      "    val_loss       : 12188.52702766241\n",
      "    val_log_likelihood: -12107.587603229684\n",
      "    val_log_marginal: -12116.405382125244\n",
      "Train Epoch: 3753 [256/118836 (0%)] Loss: 12193.140625\n",
      "Train Epoch: 3753 [33024/118836 (28%)] Loss: 12213.162109\n",
      "Train Epoch: 3753 [65792/118836 (55%)] Loss: 12251.244141\n",
      "Train Epoch: 3753 [98560/118836 (83%)] Loss: 12214.542969\n",
      "    epoch          : 3753\n",
      "    loss           : 12185.267946133168\n",
      "    val_loss       : 12188.711431388065\n",
      "    val_log_likelihood: -12108.411728442929\n",
      "    val_log_marginal: -12117.146579607232\n",
      "Train Epoch: 3754 [256/118836 (0%)] Loss: 12178.716797\n",
      "Train Epoch: 3754 [33024/118836 (28%)] Loss: 12177.669922\n",
      "Train Epoch: 3754 [65792/118836 (55%)] Loss: 12262.017578\n",
      "Train Epoch: 3754 [98560/118836 (83%)] Loss: 12138.213867\n",
      "    epoch          : 3754\n",
      "    loss           : 12183.119075359284\n",
      "    val_loss       : 12186.417555566104\n",
      "    val_log_likelihood: -12108.240881701044\n",
      "    val_log_marginal: -12116.983666658592\n",
      "Train Epoch: 3755 [256/118836 (0%)] Loss: 12138.188477\n",
      "Train Epoch: 3755 [33024/118836 (28%)] Loss: 12171.458984\n",
      "Train Epoch: 3755 [65792/118836 (55%)] Loss: 12214.223633\n",
      "Train Epoch: 3755 [98560/118836 (83%)] Loss: 12268.592773\n",
      "    epoch          : 3755\n",
      "    loss           : 12189.974505337572\n",
      "    val_loss       : 12188.551828275042\n",
      "    val_log_likelihood: -12110.201823239764\n",
      "    val_log_marginal: -12118.975019733964\n",
      "Train Epoch: 3756 [256/118836 (0%)] Loss: 12194.644531\n",
      "Train Epoch: 3756 [33024/118836 (28%)] Loss: 12301.284180\n",
      "Train Epoch: 3756 [65792/118836 (55%)] Loss: 12163.936523\n",
      "Train Epoch: 3756 [98560/118836 (83%)] Loss: 12233.761719\n",
      "    epoch          : 3756\n",
      "    loss           : 12187.62048358018\n",
      "    val_loss       : 12188.40226870504\n",
      "    val_log_likelihood: -12111.004965848584\n",
      "    val_log_marginal: -12119.864443820326\n",
      "Train Epoch: 3757 [256/118836 (0%)] Loss: 12351.205078\n",
      "Train Epoch: 3757 [33024/118836 (28%)] Loss: 12154.474609\n",
      "Train Epoch: 3757 [65792/118836 (55%)] Loss: 12310.469727\n",
      "Train Epoch: 3757 [98560/118836 (83%)] Loss: 12265.353516\n",
      "    epoch          : 3757\n",
      "    loss           : 12187.159217813016\n",
      "    val_loss       : 12191.453622648345\n",
      "    val_log_likelihood: -12105.89466065059\n",
      "    val_log_marginal: -12114.730471327865\n",
      "Train Epoch: 3758 [256/118836 (0%)] Loss: 12250.910156\n",
      "Train Epoch: 3758 [33024/118836 (28%)] Loss: 12163.728516\n",
      "Train Epoch: 3758 [65792/118836 (55%)] Loss: 12266.974609\n",
      "Train Epoch: 3758 [98560/118836 (83%)] Loss: 12191.875000\n",
      "    epoch          : 3758\n",
      "    loss           : 12186.615209658034\n",
      "    val_loss       : 12189.47897940962\n",
      "    val_log_likelihood: -12107.726908052884\n",
      "    val_log_marginal: -12116.650868510216\n",
      "Train Epoch: 3759 [256/118836 (0%)] Loss: 12164.809570\n",
      "Train Epoch: 3759 [33024/118836 (28%)] Loss: 12217.641602\n",
      "Train Epoch: 3759 [65792/118836 (55%)] Loss: 12202.199219\n",
      "Train Epoch: 3759 [98560/118836 (83%)] Loss: 12102.937500\n",
      "    epoch          : 3759\n",
      "    loss           : 12187.552791401726\n",
      "    val_loss       : 12185.571875458245\n",
      "    val_log_likelihood: -12109.012475444582\n",
      "    val_log_marginal: -12117.84020198129\n",
      "Train Epoch: 3760 [256/118836 (0%)] Loss: 12207.331055\n",
      "Train Epoch: 3760 [33024/118836 (28%)] Loss: 12183.719727\n",
      "Train Epoch: 3760 [65792/118836 (55%)] Loss: 12172.884766\n",
      "Train Epoch: 3760 [98560/118836 (83%)] Loss: 12215.312500\n",
      "    epoch          : 3760\n",
      "    loss           : 12189.187752985421\n",
      "    val_loss       : 12200.239740107145\n",
      "    val_log_likelihood: -12107.226555391853\n",
      "    val_log_marginal: -12116.085234186068\n",
      "Train Epoch: 3761 [256/118836 (0%)] Loss: 12172.105469\n",
      "Train Epoch: 3761 [33024/118836 (28%)] Loss: 12223.224609\n",
      "Train Epoch: 3761 [65792/118836 (55%)] Loss: 12157.125000\n",
      "Train Epoch: 3761 [98560/118836 (83%)] Loss: 12252.396484\n",
      "    epoch          : 3761\n",
      "    loss           : 12185.163447483716\n",
      "    val_loss       : 12191.187101839287\n",
      "    val_log_likelihood: -12111.818612198873\n",
      "    val_log_marginal: -12120.73398333483\n",
      "Train Epoch: 3762 [256/118836 (0%)] Loss: 12208.095703\n",
      "Train Epoch: 3762 [33024/118836 (28%)] Loss: 12132.611328\n",
      "Train Epoch: 3762 [65792/118836 (55%)] Loss: 12230.154297\n",
      "Train Epoch: 3762 [98560/118836 (83%)] Loss: 12194.933594\n",
      "    epoch          : 3762\n",
      "    loss           : 12183.004254064568\n",
      "    val_loss       : 12196.423137022402\n",
      "    val_log_likelihood: -12121.274571249483\n",
      "    val_log_marginal: -12130.288269889981\n",
      "Train Epoch: 3763 [256/118836 (0%)] Loss: 12316.586914\n",
      "Train Epoch: 3763 [33024/118836 (28%)] Loss: 12264.876953\n",
      "Train Epoch: 3763 [65792/118836 (55%)] Loss: 12222.142578\n",
      "Train Epoch: 3763 [98560/118836 (83%)] Loss: 12308.966797\n",
      "    epoch          : 3763\n",
      "    loss           : 12187.444310735887\n",
      "    val_loss       : 12186.44409158979\n",
      "    val_log_likelihood: -12112.715452788978\n",
      "    val_log_marginal: -12121.631210334433\n",
      "Train Epoch: 3764 [256/118836 (0%)] Loss: 12101.189453\n",
      "Train Epoch: 3764 [33024/118836 (28%)] Loss: 12268.908203\n",
      "Train Epoch: 3764 [65792/118836 (55%)] Loss: 12245.197266\n",
      "Train Epoch: 3764 [98560/118836 (83%)] Loss: 12183.041016\n",
      "    epoch          : 3764\n",
      "    loss           : 12188.214672669821\n",
      "    val_loss       : 12189.995702550108\n",
      "    val_log_likelihood: -12111.754139688017\n",
      "    val_log_marginal: -12120.540002591062\n",
      "Train Epoch: 3765 [256/118836 (0%)] Loss: 12198.431641\n",
      "Train Epoch: 3765 [33024/118836 (28%)] Loss: 12262.871094\n",
      "Train Epoch: 3765 [65792/118836 (55%)] Loss: 12179.049805\n",
      "Train Epoch: 3765 [98560/118836 (83%)] Loss: 12239.290039\n",
      "    epoch          : 3765\n",
      "    loss           : 12187.556710252533\n",
      "    val_loss       : 12189.210602486044\n",
      "    val_log_likelihood: -12109.289483334625\n",
      "    val_log_marginal: -12118.042773359422\n",
      "Train Epoch: 3766 [256/118836 (0%)] Loss: 12263.783203\n",
      "Train Epoch: 3766 [33024/118836 (28%)] Loss: 12135.434570\n",
      "Train Epoch: 3766 [65792/118836 (55%)] Loss: 12240.113281\n",
      "Train Epoch: 3766 [98560/118836 (83%)] Loss: 12239.187500\n",
      "    epoch          : 3766\n",
      "    loss           : 12186.190399154777\n",
      "    val_loss       : 12192.109932021734\n",
      "    val_log_likelihood: -12106.178998171268\n",
      "    val_log_marginal: -12114.901140794957\n",
      "Train Epoch: 3767 [256/118836 (0%)] Loss: 12223.134766\n",
      "Train Epoch: 3767 [33024/118836 (28%)] Loss: 12146.697266\n",
      "Train Epoch: 3767 [65792/118836 (55%)] Loss: 12288.931641\n",
      "Train Epoch: 3767 [98560/118836 (83%)] Loss: 12277.003906\n",
      "    epoch          : 3767\n",
      "    loss           : 12190.833183739143\n",
      "    val_loss       : 12189.841400639612\n",
      "    val_log_likelihood: -12111.820421706989\n",
      "    val_log_marginal: -12120.621360606749\n",
      "Train Epoch: 3768 [256/118836 (0%)] Loss: 12183.460938\n",
      "Train Epoch: 3768 [33024/118836 (28%)] Loss: 12191.816406\n",
      "Train Epoch: 3768 [65792/118836 (55%)] Loss: 12212.490234\n",
      "Train Epoch: 3768 [98560/118836 (83%)] Loss: 12197.216797\n",
      "    epoch          : 3768\n",
      "    loss           : 12188.74918789418\n",
      "    val_loss       : 12189.009356641152\n",
      "    val_log_likelihood: -12105.834478068135\n",
      "    val_log_marginal: -12114.777613525659\n",
      "Train Epoch: 3769 [256/118836 (0%)] Loss: 12267.499023\n",
      "Train Epoch: 3769 [33024/118836 (28%)] Loss: 12166.935547\n",
      "Train Epoch: 3769 [65792/118836 (55%)] Loss: 12248.785156\n",
      "Train Epoch: 3769 [98560/118836 (83%)] Loss: 12157.787109\n",
      "    epoch          : 3769\n",
      "    loss           : 12184.046130744677\n",
      "    val_loss       : 12186.751371777733\n",
      "    val_log_likelihood: -12109.48012788203\n",
      "    val_log_marginal: -12118.344485719874\n",
      "Train Epoch: 3770 [256/118836 (0%)] Loss: 12171.595703\n",
      "Train Epoch: 3770 [33024/118836 (28%)] Loss: 12159.515625\n",
      "Train Epoch: 3770 [65792/118836 (55%)] Loss: 12183.249023\n",
      "Train Epoch: 3770 [98560/118836 (83%)] Loss: 12133.870117\n",
      "    epoch          : 3770\n",
      "    loss           : 12191.202163138441\n",
      "    val_loss       : 12189.73966638823\n",
      "    val_log_likelihood: -12109.52526429384\n",
      "    val_log_marginal: -12118.425569639441\n",
      "Train Epoch: 3771 [256/118836 (0%)] Loss: 12227.183594\n",
      "Train Epoch: 3771 [33024/118836 (28%)] Loss: 12220.051758\n",
      "Train Epoch: 3771 [65792/118836 (55%)] Loss: 12179.009766\n",
      "Train Epoch: 3771 [98560/118836 (83%)] Loss: 12209.794922\n",
      "    epoch          : 3771\n",
      "    loss           : 12196.027785909067\n",
      "    val_loss       : 12186.961201278626\n",
      "    val_log_likelihood: -12108.51129969241\n",
      "    val_log_marginal: -12117.465669299787\n",
      "Train Epoch: 3772 [256/118836 (0%)] Loss: 12141.202148\n",
      "Train Epoch: 3772 [33024/118836 (28%)] Loss: 12254.729492\n",
      "Train Epoch: 3772 [65792/118836 (55%)] Loss: 12169.628906\n",
      "Train Epoch: 3772 [98560/118836 (83%)] Loss: 12118.832031\n",
      "    epoch          : 3772\n",
      "    loss           : 12184.167639836642\n",
      "    val_loss       : 12183.830319259181\n",
      "    val_log_likelihood: -12110.586773676592\n",
      "    val_log_marginal: -12119.27813309114\n",
      "Train Epoch: 3773 [256/118836 (0%)] Loss: 12127.880859\n",
      "Train Epoch: 3773 [33024/118836 (28%)] Loss: 12164.344727\n",
      "Train Epoch: 3773 [65792/118836 (55%)] Loss: 12209.076172\n",
      "Train Epoch: 3773 [98560/118836 (83%)] Loss: 12193.985352\n",
      "    epoch          : 3773\n",
      "    loss           : 12186.660965124844\n",
      "    val_loss       : 12188.110784067461\n",
      "    val_log_likelihood: -12107.349748791614\n",
      "    val_log_marginal: -12116.1353321865\n",
      "Train Epoch: 3774 [256/118836 (0%)] Loss: 12159.291992\n",
      "Train Epoch: 3774 [33024/118836 (28%)] Loss: 12214.566406\n",
      "Train Epoch: 3774 [65792/118836 (55%)] Loss: 12129.912109\n",
      "Train Epoch: 3774 [98560/118836 (83%)] Loss: 12138.556641\n",
      "    epoch          : 3774\n",
      "    loss           : 12184.803703344705\n",
      "    val_loss       : 12187.10390812447\n",
      "    val_log_likelihood: -12108.1385775305\n",
      "    val_log_marginal: -12116.923841251297\n",
      "Train Epoch: 3775 [256/118836 (0%)] Loss: 12244.453125\n",
      "Train Epoch: 3775 [33024/118836 (28%)] Loss: 12277.851562\n",
      "Train Epoch: 3775 [65792/118836 (55%)] Loss: 12317.183594\n",
      "Train Epoch: 3775 [98560/118836 (83%)] Loss: 12249.791016\n",
      "    epoch          : 3775\n",
      "    loss           : 12186.266976678817\n",
      "    val_loss       : 12188.02363799579\n",
      "    val_log_likelihood: -12112.734104244211\n",
      "    val_log_marginal: -12121.58498453398\n",
      "Train Epoch: 3776 [256/118836 (0%)] Loss: 12265.389648\n",
      "Train Epoch: 3776 [33024/118836 (28%)] Loss: 12251.828125\n",
      "Train Epoch: 3776 [65792/118836 (55%)] Loss: 12250.552734\n",
      "Train Epoch: 3776 [98560/118836 (83%)] Loss: 12084.647461\n",
      "    epoch          : 3776\n",
      "    loss           : 12186.715853430005\n",
      "    val_loss       : 12191.466008316873\n",
      "    val_log_likelihood: -12108.576242148729\n",
      "    val_log_marginal: -12117.297717028257\n",
      "Train Epoch: 3777 [256/118836 (0%)] Loss: 12226.775391\n",
      "Train Epoch: 3777 [33024/118836 (28%)] Loss: 12214.182617\n",
      "Train Epoch: 3777 [65792/118836 (55%)] Loss: 12147.673828\n",
      "Train Epoch: 3777 [98560/118836 (83%)] Loss: 12197.275391\n",
      "    epoch          : 3777\n",
      "    loss           : 12184.554560199544\n",
      "    val_loss       : 12184.047189885723\n",
      "    val_log_likelihood: -12110.11353165064\n",
      "    val_log_marginal: -12118.923246803173\n",
      "Train Epoch: 3778 [256/118836 (0%)] Loss: 12252.859375\n",
      "Train Epoch: 3778 [33024/118836 (28%)] Loss: 12248.765625\n",
      "Train Epoch: 3778 [65792/118836 (55%)] Loss: 12171.302734\n",
      "Train Epoch: 3778 [98560/118836 (83%)] Loss: 12190.389648\n",
      "    epoch          : 3778\n",
      "    loss           : 12184.147658834781\n",
      "    val_loss       : 12188.057727009143\n",
      "    val_log_likelihood: -12111.464858774038\n",
      "    val_log_marginal: -12120.21219326504\n",
      "Train Epoch: 3779 [256/118836 (0%)] Loss: 12121.034180\n",
      "Train Epoch: 3779 [33024/118836 (28%)] Loss: 12193.594727\n",
      "Train Epoch: 3779 [65792/118836 (55%)] Loss: 12175.443359\n",
      "Train Epoch: 3779 [98560/118836 (83%)] Loss: 12110.605469\n",
      "    epoch          : 3779\n",
      "    loss           : 12189.317345979372\n",
      "    val_loss       : 12193.2402180643\n",
      "    val_log_likelihood: -12112.764665400126\n",
      "    val_log_marginal: -12121.645338864384\n",
      "Train Epoch: 3780 [256/118836 (0%)] Loss: 12161.315430\n",
      "Train Epoch: 3780 [33024/118836 (28%)] Loss: 12179.749023\n",
      "Train Epoch: 3780 [65792/118836 (55%)] Loss: 12272.035156\n",
      "Train Epoch: 3780 [98560/118836 (83%)] Loss: 12190.837891\n",
      "    epoch          : 3780\n",
      "    loss           : 12189.15301983173\n",
      "    val_loss       : 12185.575394686288\n",
      "    val_log_likelihood: -12105.999856544664\n",
      "    val_log_marginal: -12114.96318330734\n",
      "Train Epoch: 3781 [256/118836 (0%)] Loss: 12095.220703\n",
      "Train Epoch: 3781 [33024/118836 (28%)] Loss: 12267.442383\n",
      "Train Epoch: 3781 [65792/118836 (55%)] Loss: 12215.851562\n",
      "Train Epoch: 3781 [98560/118836 (83%)] Loss: 12120.451172\n",
      "    epoch          : 3781\n",
      "    loss           : 12188.058511683208\n",
      "    val_loss       : 12184.624898575288\n",
      "    val_log_likelihood: -12111.528355045493\n",
      "    val_log_marginal: -12120.286086991557\n",
      "Train Epoch: 3782 [256/118836 (0%)] Loss: 12151.142578\n",
      "Train Epoch: 3782 [33024/118836 (28%)] Loss: 12279.334961\n",
      "Train Epoch: 3782 [65792/118836 (55%)] Loss: 12320.272461\n",
      "Train Epoch: 3782 [98560/118836 (83%)] Loss: 12228.656250\n",
      "    epoch          : 3782\n",
      "    loss           : 12186.5969895381\n",
      "    val_loss       : 12189.92047035118\n",
      "    val_log_likelihood: -12107.699656224153\n",
      "    val_log_marginal: -12116.466691627096\n",
      "Train Epoch: 3783 [256/118836 (0%)] Loss: 12208.729492\n",
      "Train Epoch: 3783 [33024/118836 (28%)] Loss: 12169.611328\n",
      "Train Epoch: 3783 [65792/118836 (55%)] Loss: 12123.356445\n",
      "Train Epoch: 3783 [98560/118836 (83%)] Loss: 12173.155273\n",
      "    epoch          : 3783\n",
      "    loss           : 12184.829956155654\n",
      "    val_loss       : 12187.041359602115\n",
      "    val_log_likelihood: -12107.535031534328\n",
      "    val_log_marginal: -12116.341208701848\n",
      "Train Epoch: 3784 [256/118836 (0%)] Loss: 12258.358398\n",
      "Train Epoch: 3784 [33024/118836 (28%)] Loss: 12265.077148\n",
      "Train Epoch: 3784 [65792/118836 (55%)] Loss: 12139.014648\n",
      "Train Epoch: 3784 [98560/118836 (83%)] Loss: 12149.145508\n",
      "    epoch          : 3784\n",
      "    loss           : 12188.131029485887\n",
      "    val_loss       : 12192.647610399314\n",
      "    val_log_likelihood: -12113.38026422922\n",
      "    val_log_marginal: -12122.169568492964\n",
      "Train Epoch: 3785 [256/118836 (0%)] Loss: 12150.626953\n",
      "Train Epoch: 3785 [33024/118836 (28%)] Loss: 12244.501953\n",
      "Train Epoch: 3785 [65792/118836 (55%)] Loss: 12232.535156\n",
      "Train Epoch: 3785 [98560/118836 (83%)] Loss: 12213.756836\n",
      "    epoch          : 3785\n",
      "    loss           : 12189.686770930264\n",
      "    val_loss       : 12187.419949901545\n",
      "    val_log_likelihood: -12111.486541530967\n",
      "    val_log_marginal: -12120.403841437988\n",
      "Train Epoch: 3786 [256/118836 (0%)] Loss: 12201.034180\n",
      "Train Epoch: 3786 [33024/118836 (28%)] Loss: 12124.912109\n",
      "Train Epoch: 3786 [65792/118836 (55%)] Loss: 12157.302734\n",
      "Train Epoch: 3786 [98560/118836 (83%)] Loss: 12199.386719\n",
      "    epoch          : 3786\n",
      "    loss           : 12190.149233935586\n",
      "    val_loss       : 12188.853348776209\n",
      "    val_log_likelihood: -12110.481549188378\n",
      "    val_log_marginal: -12119.409958408973\n",
      "Train Epoch: 3787 [256/118836 (0%)] Loss: 12272.054688\n",
      "Train Epoch: 3787 [33024/118836 (28%)] Loss: 12254.569336\n",
      "Train Epoch: 3787 [65792/118836 (55%)] Loss: 12182.890625\n",
      "Train Epoch: 3787 [98560/118836 (83%)] Loss: 12149.278320\n",
      "    epoch          : 3787\n",
      "    loss           : 12187.682644973893\n",
      "    val_loss       : 12187.332715567\n",
      "    val_log_likelihood: -12109.690927257805\n",
      "    val_log_marginal: -12118.602324454918\n",
      "Train Epoch: 3788 [256/118836 (0%)] Loss: 12210.986328\n",
      "Train Epoch: 3788 [33024/118836 (28%)] Loss: 12176.898438\n",
      "Train Epoch: 3788 [65792/118836 (55%)] Loss: 12162.738281\n",
      "Train Epoch: 3788 [98560/118836 (83%)] Loss: 12171.585938\n",
      "    epoch          : 3788\n",
      "    loss           : 12185.887791595585\n",
      "    val_loss       : 12189.133744875551\n",
      "    val_log_likelihood: -12110.708059185019\n",
      "    val_log_marginal: -12119.599041802456\n",
      "Train Epoch: 3789 [256/118836 (0%)] Loss: 12256.246094\n",
      "Train Epoch: 3789 [33024/118836 (28%)] Loss: 12271.920898\n",
      "Train Epoch: 3789 [65792/118836 (55%)] Loss: 12206.272461\n",
      "Train Epoch: 3789 [98560/118836 (83%)] Loss: 12106.982422\n",
      "    epoch          : 3789\n",
      "    loss           : 12187.478948414238\n",
      "    val_loss       : 12186.89198935878\n",
      "    val_log_likelihood: -12112.58008361766\n",
      "    val_log_marginal: -12121.459623944535\n",
      "Train Epoch: 3790 [256/118836 (0%)] Loss: 12202.815430\n",
      "Train Epoch: 3790 [33024/118836 (28%)] Loss: 12203.339844\n",
      "Train Epoch: 3790 [65792/118836 (55%)] Loss: 12196.271484\n",
      "Train Epoch: 3790 [98560/118836 (83%)] Loss: 12231.028320\n",
      "    epoch          : 3790\n",
      "    loss           : 12185.109892440807\n",
      "    val_loss       : 12184.667658912764\n",
      "    val_log_likelihood: -12107.19600893688\n",
      "    val_log_marginal: -12116.011729291506\n",
      "Train Epoch: 3791 [256/118836 (0%)] Loss: 12259.004883\n",
      "Train Epoch: 3791 [33024/118836 (28%)] Loss: 12257.161133\n",
      "Train Epoch: 3791 [65792/118836 (55%)] Loss: 12251.642578\n",
      "Train Epoch: 3791 [98560/118836 (83%)] Loss: 12110.719727\n",
      "    epoch          : 3791\n",
      "    loss           : 12187.503868932226\n",
      "    val_loss       : 12188.972566097398\n",
      "    val_log_likelihood: -12109.863708869676\n",
      "    val_log_marginal: -12118.67329121568\n",
      "Train Epoch: 3792 [256/118836 (0%)] Loss: 12137.846680\n",
      "Train Epoch: 3792 [33024/118836 (28%)] Loss: 12154.648438\n",
      "Train Epoch: 3792 [65792/118836 (55%)] Loss: 12243.600586\n",
      "Train Epoch: 3792 [98560/118836 (83%)] Loss: 12237.792969\n",
      "    epoch          : 3792\n",
      "    loss           : 12187.621983237697\n",
      "    val_loss       : 12192.149242170772\n",
      "    val_log_likelihood: -12107.819378586384\n",
      "    val_log_marginal: -12116.666159308345\n",
      "Train Epoch: 3793 [256/118836 (0%)] Loss: 12162.263672\n",
      "Train Epoch: 3793 [33024/118836 (28%)] Loss: 12274.478516\n",
      "Train Epoch: 3793 [65792/118836 (55%)] Loss: 12220.464844\n",
      "Train Epoch: 3793 [98560/118836 (83%)] Loss: 12191.494141\n",
      "    epoch          : 3793\n",
      "    loss           : 12191.981301372518\n",
      "    val_loss       : 12193.190482517948\n",
      "    val_log_likelihood: -12109.996128482993\n",
      "    val_log_marginal: -12119.159826794108\n",
      "Train Epoch: 3794 [256/118836 (0%)] Loss: 12302.945312\n",
      "Train Epoch: 3794 [33024/118836 (28%)] Loss: 12243.269531\n",
      "Train Epoch: 3794 [65792/118836 (55%)] Loss: 12155.454102\n",
      "Train Epoch: 3794 [98560/118836 (83%)] Loss: 12201.584961\n",
      "    epoch          : 3794\n",
      "    loss           : 12190.318329650021\n",
      "    val_loss       : 12188.289895617652\n",
      "    val_log_likelihood: -12105.431553065551\n",
      "    val_log_marginal: -12114.336596847143\n",
      "Train Epoch: 3795 [256/118836 (0%)] Loss: 12204.216797\n",
      "Train Epoch: 3795 [33024/118836 (28%)] Loss: 12231.755859\n",
      "Train Epoch: 3795 [65792/118836 (55%)] Loss: 12199.871094\n",
      "Train Epoch: 3795 [98560/118836 (83%)] Loss: 12189.408203\n",
      "    epoch          : 3795\n",
      "    loss           : 12187.987150246847\n",
      "    val_loss       : 12187.603032448751\n",
      "    val_log_likelihood: -12107.530440802057\n",
      "    val_log_marginal: -12116.488722657898\n",
      "Train Epoch: 3796 [256/118836 (0%)] Loss: 12128.687500\n",
      "Train Epoch: 3796 [33024/118836 (28%)] Loss: 12203.443359\n",
      "Train Epoch: 3796 [65792/118836 (55%)] Loss: 12225.153320\n",
      "Train Epoch: 3796 [98560/118836 (83%)] Loss: 12182.753906\n",
      "    epoch          : 3796\n",
      "    loss           : 12188.684597775797\n",
      "    val_loss       : 12192.899746682679\n",
      "    val_log_likelihood: -12109.972636541048\n",
      "    val_log_marginal: -12118.91192598267\n",
      "Train Epoch: 3797 [256/118836 (0%)] Loss: 12172.319336\n",
      "Train Epoch: 3797 [33024/118836 (28%)] Loss: 12287.500977\n",
      "Train Epoch: 3797 [65792/118836 (55%)] Loss: 12241.724609\n",
      "Train Epoch: 3797 [98560/118836 (83%)] Loss: 12213.802734\n",
      "    epoch          : 3797\n",
      "    loss           : 12188.287382877119\n",
      "    val_loss       : 12186.736247995372\n",
      "    val_log_likelihood: -12106.96334586952\n",
      "    val_log_marginal: -12115.855681289855\n",
      "Train Epoch: 3798 [256/118836 (0%)] Loss: 12211.841797\n",
      "Train Epoch: 3798 [33024/118836 (28%)] Loss: 12236.068359\n",
      "Train Epoch: 3798 [65792/118836 (55%)] Loss: 12176.026367\n",
      "Train Epoch: 3798 [98560/118836 (83%)] Loss: 12163.475586\n",
      "    epoch          : 3798\n",
      "    loss           : 12187.792773114403\n",
      "    val_loss       : 12187.026974538132\n",
      "    val_log_likelihood: -12108.216884434449\n",
      "    val_log_marginal: -12117.036208395017\n",
      "Train Epoch: 3799 [256/118836 (0%)] Loss: 12179.371094\n",
      "Train Epoch: 3799 [33024/118836 (28%)] Loss: 12198.532227\n",
      "Train Epoch: 3799 [65792/118836 (55%)] Loss: 12149.509766\n",
      "Train Epoch: 3799 [98560/118836 (83%)] Loss: 12184.374023\n",
      "    epoch          : 3799\n",
      "    loss           : 12188.835247686622\n",
      "    val_loss       : 12188.211967317186\n",
      "    val_log_likelihood: -12114.882998765766\n",
      "    val_log_marginal: -12123.830483162443\n",
      "Train Epoch: 3800 [256/118836 (0%)] Loss: 12099.236328\n",
      "Train Epoch: 3800 [33024/118836 (28%)] Loss: 12196.806641\n",
      "Train Epoch: 3800 [65792/118836 (55%)] Loss: 12360.025391\n",
      "Train Epoch: 3800 [98560/118836 (83%)] Loss: 12174.898438\n",
      "    epoch          : 3800\n",
      "    loss           : 12188.071935096155\n",
      "    val_loss       : 12188.556631667325\n",
      "    val_log_likelihood: -12105.921131390869\n",
      "    val_log_marginal: -12114.97999802615\n",
      "Saving checkpoint: saved/models/SelfiesAutoencodingOperad/0905_154251/checkpoint-epoch3800.pth ...\n",
      "Train Epoch: 3801 [256/118836 (0%)] Loss: 12163.249023\n",
      "Train Epoch: 3801 [33024/118836 (28%)] Loss: 12209.698242\n",
      "Train Epoch: 3801 [65792/118836 (55%)] Loss: 12214.470703\n",
      "Train Epoch: 3801 [98560/118836 (83%)] Loss: 12265.205078\n",
      "    epoch          : 3801\n",
      "    loss           : 12186.53207034481\n",
      "    val_loss       : 12182.865886198633\n",
      "    val_log_likelihood: -12109.736818102512\n",
      "    val_log_marginal: -12118.461674958478\n",
      "Train Epoch: 3802 [256/118836 (0%)] Loss: 12148.023438\n",
      "Train Epoch: 3802 [33024/118836 (28%)] Loss: 12246.099609\n",
      "Train Epoch: 3802 [65792/118836 (55%)] Loss: 12243.638672\n",
      "Train Epoch: 3802 [98560/118836 (83%)] Loss: 12296.361328\n",
      "    epoch          : 3802\n",
      "    loss           : 12194.863483186\n",
      "    val_loss       : 12192.154602952545\n",
      "    val_log_likelihood: -12113.161135720378\n",
      "    val_log_marginal: -12122.164459697648\n",
      "Train Epoch: 3803 [256/118836 (0%)] Loss: 12343.425781\n",
      "Train Epoch: 3803 [33024/118836 (28%)] Loss: 12200.427734\n",
      "Train Epoch: 3803 [65792/118836 (55%)] Loss: 12235.807617\n",
      "Train Epoch: 3803 [98560/118836 (83%)] Loss: 12160.847656\n",
      "    epoch          : 3803\n",
      "    loss           : 12186.210934269024\n",
      "    val_loss       : 12184.230592078507\n",
      "    val_log_likelihood: -12108.325601446184\n",
      "    val_log_marginal: -12117.168674638859\n",
      "Train Epoch: 3804 [256/118836 (0%)] Loss: 12150.980469\n",
      "Train Epoch: 3804 [33024/118836 (28%)] Loss: 12228.206055\n",
      "Train Epoch: 3804 [65792/118836 (55%)] Loss: 12167.798828\n",
      "Train Epoch: 3804 [98560/118836 (83%)] Loss: 12218.321289\n",
      "    epoch          : 3804\n",
      "    loss           : 12187.341372163202\n",
      "    val_loss       : 12184.234221105999\n",
      "    val_log_likelihood: -12112.700856531741\n",
      "    val_log_marginal: -12121.537276818299\n",
      "Train Epoch: 3805 [256/118836 (0%)] Loss: 12249.528320\n",
      "Train Epoch: 3805 [33024/118836 (28%)] Loss: 12209.266602\n",
      "Train Epoch: 3805 [65792/118836 (55%)] Loss: 12273.548828\n",
      "Train Epoch: 3805 [98560/118836 (83%)] Loss: 12243.232422\n",
      "    epoch          : 3805\n",
      "    loss           : 12184.786243958075\n",
      "    val_loss       : 12190.128790728802\n",
      "    val_log_likelihood: -12108.129581847084\n",
      "    val_log_marginal: -12117.054282725216\n",
      "Train Epoch: 3806 [256/118836 (0%)] Loss: 12186.287109\n",
      "Train Epoch: 3806 [33024/118836 (28%)] Loss: 12213.916992\n",
      "Train Epoch: 3806 [65792/118836 (55%)] Loss: 12120.541016\n",
      "Train Epoch: 3806 [98560/118836 (83%)] Loss: 12184.642578\n",
      "    epoch          : 3806\n",
      "    loss           : 12186.200398217794\n",
      "    val_loss       : 12216.676753535512\n",
      "    val_log_likelihood: -12135.869402334058\n",
      "    val_log_marginal: -12144.90761448211\n",
      "Train Epoch: 3807 [256/118836 (0%)] Loss: 12210.791016\n",
      "Train Epoch: 3807 [33024/118836 (28%)] Loss: 12192.078125\n",
      "Train Epoch: 3807 [65792/118836 (55%)] Loss: 12166.337891\n",
      "Train Epoch: 3807 [98560/118836 (83%)] Loss: 12141.260742\n",
      "    epoch          : 3807\n",
      "    loss           : 12221.409270477925\n",
      "    val_loss       : 12207.640336773595\n",
      "    val_log_likelihood: -12114.60407716863\n",
      "    val_log_marginal: -12123.929775706558\n",
      "Train Epoch: 3808 [256/118836 (0%)] Loss: 12285.654297\n",
      "Train Epoch: 3808 [33024/118836 (28%)] Loss: 12251.537109\n",
      "Train Epoch: 3808 [65792/118836 (55%)] Loss: 12124.427734\n",
      "Train Epoch: 3808 [98560/118836 (83%)] Loss: 12302.478516\n",
      "    epoch          : 3808\n",
      "    loss           : 12201.974059947528\n",
      "    val_loss       : 12194.221499866104\n",
      "    val_log_likelihood: -12115.423970449494\n",
      "    val_log_marginal: -12124.500434761678\n",
      "Train Epoch: 3809 [256/118836 (0%)] Loss: 12261.564453\n",
      "Train Epoch: 3809 [33024/118836 (28%)] Loss: 12267.443359\n",
      "Train Epoch: 3809 [65792/118836 (55%)] Loss: 12182.832031\n",
      "Train Epoch: 3809 [98560/118836 (83%)] Loss: 12150.878906\n",
      "    epoch          : 3809\n",
      "    loss           : 12202.570328493332\n",
      "    val_loss       : 12197.986627214546\n",
      "    val_log_likelihood: -12112.118202995762\n",
      "    val_log_marginal: -12121.322763591847\n",
      "Train Epoch: 3810 [256/118836 (0%)] Loss: 12164.207031\n",
      "Train Epoch: 3810 [33024/118836 (28%)] Loss: 12227.113281\n",
      "Train Epoch: 3810 [65792/118836 (55%)] Loss: 12160.215820\n",
      "Train Epoch: 3810 [98560/118836 (83%)] Loss: 12157.267578\n",
      "    epoch          : 3810\n",
      "    loss           : 12195.15032891336\n",
      "    val_loss       : 12192.942863763417\n",
      "    val_log_likelihood: -12112.42993273108\n",
      "    val_log_marginal: -12121.472162736169\n",
      "Train Epoch: 3811 [256/118836 (0%)] Loss: 12245.650391\n",
      "Train Epoch: 3811 [33024/118836 (28%)] Loss: 12168.097656\n",
      "Train Epoch: 3811 [65792/118836 (55%)] Loss: 12229.859375\n",
      "Train Epoch: 3811 [98560/118836 (83%)] Loss: 12204.966797\n",
      "    epoch          : 3811\n",
      "    loss           : 12192.458723635236\n",
      "    val_loss       : 12189.27466617579\n",
      "    val_log_likelihood: -12112.993026261373\n",
      "    val_log_marginal: -12121.971162263797\n",
      "Train Epoch: 3812 [256/118836 (0%)] Loss: 12223.267578\n",
      "Train Epoch: 3812 [33024/118836 (28%)] Loss: 12142.029297\n",
      "Train Epoch: 3812 [65792/118836 (55%)] Loss: 12180.381836\n",
      "Train Epoch: 3812 [98560/118836 (83%)] Loss: 12177.750000\n",
      "    epoch          : 3812\n",
      "    loss           : 12191.987977861352\n",
      "    val_loss       : 12195.266252419982\n",
      "    val_log_likelihood: -12111.019823330233\n",
      "    val_log_marginal: -12119.988575452873\n",
      "Train Epoch: 3813 [256/118836 (0%)] Loss: 12251.081055\n",
      "Train Epoch: 3813 [33024/118836 (28%)] Loss: 12185.232422\n",
      "Train Epoch: 3813 [65792/118836 (55%)] Loss: 12229.064453\n",
      "Train Epoch: 3813 [98560/118836 (83%)] Loss: 12166.239258\n",
      "    epoch          : 3813\n",
      "    loss           : 12194.84401800946\n",
      "    val_loss       : 12189.740109101309\n",
      "    val_log_likelihood: -12112.099263337468\n",
      "    val_log_marginal: -12121.016439103416\n",
      "Train Epoch: 3814 [256/118836 (0%)] Loss: 12196.785156\n",
      "Train Epoch: 3814 [33024/118836 (28%)] Loss: 12171.765625\n",
      "Train Epoch: 3814 [65792/118836 (55%)] Loss: 12146.647461\n",
      "Train Epoch: 3814 [98560/118836 (83%)] Loss: 12160.025391\n",
      "    epoch          : 3814\n",
      "    loss           : 12189.97674553479\n",
      "    val_loss       : 12193.376838976823\n",
      "    val_log_likelihood: -12108.460787098065\n",
      "    val_log_marginal: -12117.303666150887\n",
      "Train Epoch: 3815 [256/118836 (0%)] Loss: 12130.949219\n",
      "Train Epoch: 3815 [33024/118836 (28%)] Loss: 12153.503906\n",
      "Train Epoch: 3815 [65792/118836 (55%)] Loss: 12162.165039\n",
      "Train Epoch: 3815 [98560/118836 (83%)] Loss: 12176.543945\n",
      "    epoch          : 3815\n",
      "    loss           : 12190.30341449545\n",
      "    val_loss       : 12193.981252394713\n",
      "    val_log_likelihood: -12113.124947173543\n",
      "    val_log_marginal: -12122.080619612496\n",
      "Train Epoch: 3816 [256/118836 (0%)] Loss: 12176.263672\n",
      "Train Epoch: 3816 [33024/118836 (28%)] Loss: 12210.868164\n",
      "Train Epoch: 3816 [65792/118836 (55%)] Loss: 12189.697266\n",
      "Train Epoch: 3816 [98560/118836 (83%)] Loss: 12165.879883\n",
      "    epoch          : 3816\n",
      "    loss           : 12213.377056516232\n",
      "    val_loss       : 12201.593298850377\n",
      "    val_log_likelihood: -12124.858597304074\n",
      "    val_log_marginal: -12134.0054154531\n",
      "Train Epoch: 3817 [256/118836 (0%)] Loss: 12185.268555\n",
      "Train Epoch: 3817 [33024/118836 (28%)] Loss: 12257.407227\n",
      "Train Epoch: 3817 [65792/118836 (55%)] Loss: 12193.812500\n",
      "Train Epoch: 3817 [98560/118836 (83%)] Loss: 12250.245117\n",
      "    epoch          : 3817\n",
      "    loss           : 12198.766684598584\n",
      "    val_loss       : 12198.66892388533\n",
      "    val_log_likelihood: -12123.120433015405\n",
      "    val_log_marginal: -12132.133346706913\n",
      "Train Epoch: 3818 [256/118836 (0%)] Loss: 12187.220703\n",
      "Train Epoch: 3818 [33024/118836 (28%)] Loss: 12242.673828\n",
      "Train Epoch: 3818 [65792/118836 (55%)] Loss: 12234.414062\n",
      "Train Epoch: 3818 [98560/118836 (83%)] Loss: 12195.597656\n",
      "    epoch          : 3818\n",
      "    loss           : 12199.976860072891\n",
      "    val_loss       : 12193.377296967781\n",
      "    val_log_likelihood: -12124.095563385286\n",
      "    val_log_marginal: -12133.04263550416\n",
      "Train Epoch: 3819 [256/118836 (0%)] Loss: 12210.935547\n",
      "Train Epoch: 3819 [33024/118836 (28%)] Loss: 12184.712891\n",
      "Train Epoch: 3819 [65792/118836 (55%)] Loss: 12298.699219\n",
      "Train Epoch: 3819 [98560/118836 (83%)] Loss: 12217.288086\n",
      "    epoch          : 3819\n",
      "    loss           : 12197.79013615333\n",
      "    val_loss       : 12197.965350432234\n",
      "    val_log_likelihood: -12121.111265605614\n",
      "    val_log_marginal: -12129.932771080938\n",
      "Train Epoch: 3820 [256/118836 (0%)] Loss: 12168.536133\n",
      "Train Epoch: 3820 [33024/118836 (28%)] Loss: 12266.139648\n",
      "Train Epoch: 3820 [65792/118836 (55%)] Loss: 12182.464844\n",
      "Train Epoch: 3820 [98560/118836 (83%)] Loss: 12254.063477\n",
      "    epoch          : 3820\n",
      "    loss           : 12189.973603895265\n",
      "    val_loss       : 12196.707200649205\n",
      "    val_log_likelihood: -12123.668486190807\n",
      "    val_log_marginal: -12132.461210015004\n",
      "Train Epoch: 3821 [256/118836 (0%)] Loss: 12069.448242\n",
      "Train Epoch: 3821 [33024/118836 (28%)] Loss: 12238.867188\n",
      "Train Epoch: 3821 [65792/118836 (55%)] Loss: 12249.818359\n",
      "Train Epoch: 3821 [98560/118836 (83%)] Loss: 12195.379883\n",
      "    epoch          : 3821\n",
      "    loss           : 12194.262695635596\n",
      "    val_loss       : 12192.703580476193\n",
      "    val_log_likelihood: -12107.0825566067\n",
      "    val_log_marginal: -12115.966184533438\n",
      "Train Epoch: 3822 [256/118836 (0%)] Loss: 12226.520508\n",
      "Train Epoch: 3822 [33024/118836 (28%)] Loss: 12217.816406\n",
      "Train Epoch: 3822 [65792/118836 (55%)] Loss: 12118.656250\n",
      "Train Epoch: 3822 [98560/118836 (83%)] Loss: 12175.773438\n",
      "    epoch          : 3822\n",
      "    loss           : 12192.462374638131\n",
      "    val_loss       : 12190.515716609512\n",
      "    val_log_likelihood: -12112.918446772903\n",
      "    val_log_marginal: -12121.71935175261\n",
      "Train Epoch: 3823 [256/118836 (0%)] Loss: 12185.642578\n",
      "Train Epoch: 3823 [33024/118836 (28%)] Loss: 12262.936523\n",
      "Train Epoch: 3823 [65792/118836 (55%)] Loss: 12147.544922\n",
      "Train Epoch: 3823 [98560/118836 (83%)] Loss: 12174.500000\n",
      "    epoch          : 3823\n",
      "    loss           : 12191.239005796371\n",
      "    val_loss       : 12191.50328769873\n",
      "    val_log_likelihood: -12110.664394159687\n",
      "    val_log_marginal: -12119.512374105525\n",
      "Train Epoch: 3824 [256/118836 (0%)] Loss: 12164.607422\n",
      "Train Epoch: 3824 [33024/118836 (28%)] Loss: 12220.380859\n",
      "Train Epoch: 3824 [65792/118836 (55%)] Loss: 12220.453125\n",
      "Train Epoch: 3824 [98560/118836 (83%)] Loss: 12182.608398\n",
      "    epoch          : 3824\n",
      "    loss           : 12189.173170621381\n",
      "    val_loss       : 12188.01475432555\n",
      "    val_log_likelihood: -12111.312349921165\n",
      "    val_log_marginal: -12120.073335515724\n",
      "Train Epoch: 3825 [256/118836 (0%)] Loss: 12124.923828\n",
      "Train Epoch: 3825 [33024/118836 (28%)] Loss: 12132.308594\n",
      "Train Epoch: 3825 [65792/118836 (55%)] Loss: 12208.049805\n",
      "Train Epoch: 3825 [98560/118836 (83%)] Loss: 12168.514648\n",
      "    epoch          : 3825\n",
      "    loss           : 12189.491845016542\n",
      "    val_loss       : 12188.426426771812\n",
      "    val_log_likelihood: -12109.855867452441\n",
      "    val_log_marginal: -12118.686638660747\n",
      "Train Epoch: 3826 [256/118836 (0%)] Loss: 12153.839844\n",
      "Train Epoch: 3826 [33024/118836 (28%)] Loss: 12210.032227\n",
      "Train Epoch: 3826 [65792/118836 (55%)] Loss: 12306.148438\n",
      "Train Epoch: 3826 [98560/118836 (83%)] Loss: 12147.302734\n",
      "    epoch          : 3826\n",
      "    loss           : 12189.571433648678\n",
      "    val_loss       : 12188.305365435463\n",
      "    val_log_likelihood: -12109.888804021919\n",
      "    val_log_marginal: -12118.735877289655\n",
      "Train Epoch: 3827 [256/118836 (0%)] Loss: 12170.375977\n",
      "Train Epoch: 3827 [33024/118836 (28%)] Loss: 12251.569336\n",
      "Train Epoch: 3827 [65792/118836 (55%)] Loss: 12145.427734\n",
      "Train Epoch: 3827 [98560/118836 (83%)] Loss: 12193.872070\n",
      "    epoch          : 3827\n",
      "    loss           : 12189.483547223947\n",
      "    val_loss       : 12186.841693640896\n",
      "    val_log_likelihood: -12113.062295802316\n",
      "    val_log_marginal: -12121.831151759865\n",
      "Train Epoch: 3828 [256/118836 (0%)] Loss: 12174.136719\n",
      "Train Epoch: 3828 [33024/118836 (28%)] Loss: 12134.311523\n",
      "Train Epoch: 3828 [65792/118836 (55%)] Loss: 12221.197266\n",
      "Train Epoch: 3828 [98560/118836 (83%)] Loss: 12188.214844\n",
      "    epoch          : 3828\n",
      "    loss           : 12192.121890831782\n",
      "    val_loss       : 12187.598994780881\n",
      "    val_log_likelihood: -12110.224290316119\n",
      "    val_log_marginal: -12118.95374182278\n",
      "Train Epoch: 3829 [256/118836 (0%)] Loss: 12275.783203\n",
      "Train Epoch: 3829 [33024/118836 (28%)] Loss: 12243.970703\n",
      "Train Epoch: 3829 [65792/118836 (55%)] Loss: 12152.040039\n",
      "Train Epoch: 3829 [98560/118836 (83%)] Loss: 12208.190430\n",
      "    epoch          : 3829\n",
      "    loss           : 12187.789996898262\n",
      "    val_loss       : 12189.510988739241\n",
      "    val_log_likelihood: -12113.431224798387\n",
      "    val_log_marginal: -12122.14833198233\n",
      "Train Epoch: 3830 [256/118836 (0%)] Loss: 12253.484375\n",
      "Train Epoch: 3830 [33024/118836 (28%)] Loss: 12132.720703\n",
      "Train Epoch: 3830 [65792/118836 (55%)] Loss: 12226.507812\n",
      "Train Epoch: 3830 [98560/118836 (83%)] Loss: 12184.918945\n",
      "    epoch          : 3830\n",
      "    loss           : 12187.981841914807\n",
      "    val_loss       : 12198.004975076998\n",
      "    val_log_likelihood: -12113.14105342742\n",
      "    val_log_marginal: -12121.92684513663\n",
      "Train Epoch: 3831 [256/118836 (0%)] Loss: 12122.162109\n",
      "Train Epoch: 3831 [33024/118836 (28%)] Loss: 12204.082031\n",
      "Train Epoch: 3831 [65792/118836 (55%)] Loss: 12201.795898\n",
      "Train Epoch: 3831 [98560/118836 (83%)] Loss: 12249.237305\n",
      "    epoch          : 3831\n",
      "    loss           : 12193.4224473674\n",
      "    val_loss       : 12188.929693038375\n",
      "    val_log_likelihood: -12115.313259764009\n",
      "    val_log_marginal: -12124.027419916903\n",
      "Train Epoch: 3832 [256/118836 (0%)] Loss: 12311.450195\n",
      "Train Epoch: 3832 [33024/118836 (28%)] Loss: 12195.101562\n",
      "Train Epoch: 3832 [65792/118836 (55%)] Loss: 12166.285156\n",
      "Train Epoch: 3832 [98560/118836 (83%)] Loss: 12212.692383\n",
      "    epoch          : 3832\n",
      "    loss           : 12190.518771324441\n",
      "    val_loss       : 12187.035578846495\n",
      "    val_log_likelihood: -12112.52195173568\n",
      "    val_log_marginal: -12121.299233234111\n",
      "Train Epoch: 3833 [256/118836 (0%)] Loss: 12156.126953\n",
      "Train Epoch: 3833 [33024/118836 (28%)] Loss: 12184.213867\n",
      "Train Epoch: 3833 [65792/118836 (55%)] Loss: 12231.945312\n",
      "Train Epoch: 3833 [98560/118836 (83%)] Loss: 12282.394531\n",
      "    epoch          : 3833\n",
      "    loss           : 12187.825032632858\n",
      "    val_loss       : 12201.516303905611\n",
      "    val_log_likelihood: -12113.768153723377\n",
      "    val_log_marginal: -12122.429920787557\n",
      "Train Epoch: 3834 [256/118836 (0%)] Loss: 12189.527344\n",
      "Train Epoch: 3834 [33024/118836 (28%)] Loss: 12234.118164\n",
      "Train Epoch: 3834 [65792/118836 (55%)] Loss: 12182.126953\n",
      "Train Epoch: 3834 [98560/118836 (83%)] Loss: 12336.856445\n",
      "    epoch          : 3834\n",
      "    loss           : 12197.03059815059\n",
      "    val_loss       : 12192.441186550355\n",
      "    val_log_likelihood: -12107.095031243538\n",
      "    val_log_marginal: -12115.802902482917\n",
      "Train Epoch: 3835 [256/118836 (0%)] Loss: 12112.511719\n",
      "Train Epoch: 3835 [33024/118836 (28%)] Loss: 12207.884766\n",
      "Train Epoch: 3835 [65792/118836 (55%)] Loss: 12216.333008\n",
      "Train Epoch: 3835 [98560/118836 (83%)] Loss: 12339.930664\n",
      "    epoch          : 3835\n",
      "    loss           : 12187.951308706834\n",
      "    val_loss       : 12190.53977992473\n",
      "    val_log_likelihood: -12112.416431613163\n",
      "    val_log_marginal: -12121.195121183242\n",
      "Train Epoch: 3836 [256/118836 (0%)] Loss: 12215.106445\n",
      "Train Epoch: 3836 [33024/118836 (28%)] Loss: 12176.648438\n",
      "Train Epoch: 3836 [65792/118836 (55%)] Loss: 12111.300781\n",
      "Train Epoch: 3836 [98560/118836 (83%)] Loss: 12143.786133\n",
      "    epoch          : 3836\n",
      "    loss           : 12184.009938966863\n",
      "    val_loss       : 12185.70983507801\n",
      "    val_log_likelihood: -12114.852127920802\n",
      "    val_log_marginal: -12123.63288856536\n",
      "Train Epoch: 3837 [256/118836 (0%)] Loss: 12307.117188\n",
      "Train Epoch: 3837 [33024/118836 (28%)] Loss: 12200.804688\n",
      "Train Epoch: 3837 [65792/118836 (55%)] Loss: 12331.411133\n",
      "Train Epoch: 3837 [98560/118836 (83%)] Loss: 12215.791016\n",
      "    epoch          : 3837\n",
      "    loss           : 12186.912887394024\n",
      "    val_loss       : 12185.554880648237\n",
      "    val_log_likelihood: -12110.714447470793\n",
      "    val_log_marginal: -12119.486378245314\n",
      "Train Epoch: 3838 [256/118836 (0%)] Loss: 12272.336914\n",
      "Train Epoch: 3838 [33024/118836 (28%)] Loss: 12293.202148\n",
      "Train Epoch: 3838 [65792/118836 (55%)] Loss: 12223.697266\n",
      "Train Epoch: 3838 [98560/118836 (83%)] Loss: 12248.296875\n",
      "    epoch          : 3838\n",
      "    loss           : 12188.668747738317\n",
      "    val_loss       : 12188.929944548972\n",
      "    val_log_likelihood: -12108.108734135909\n",
      "    val_log_marginal: -12116.829136850245\n",
      "Train Epoch: 3839 [256/118836 (0%)] Loss: 12175.360352\n",
      "Train Epoch: 3839 [33024/118836 (28%)] Loss: 12159.335938\n",
      "Train Epoch: 3839 [65792/118836 (55%)] Loss: 12181.976562\n",
      "Train Epoch: 3839 [98560/118836 (83%)] Loss: 12189.120117\n",
      "    epoch          : 3839\n",
      "    loss           : 12193.41134298749\n",
      "    val_loss       : 12189.994941072604\n",
      "    val_log_likelihood: -12113.482607171474\n",
      "    val_log_marginal: -12122.307264279585\n",
      "Train Epoch: 3840 [256/118836 (0%)] Loss: 12285.316406\n",
      "Train Epoch: 3840 [33024/118836 (28%)] Loss: 12173.456055\n",
      "Train Epoch: 3840 [65792/118836 (55%)] Loss: 12193.177734\n",
      "Train Epoch: 3840 [98560/118836 (83%)] Loss: 12146.508789\n",
      "    epoch          : 3840\n",
      "    loss           : 12186.699196133168\n",
      "    val_loss       : 12191.725073307278\n",
      "    val_log_likelihood: -12113.22029117556\n",
      "    val_log_marginal: -12122.051778159963\n",
      "Train Epoch: 3841 [256/118836 (0%)] Loss: 12214.441406\n",
      "Train Epoch: 3841 [33024/118836 (28%)] Loss: 12207.505859\n",
      "Train Epoch: 3841 [65792/118836 (55%)] Loss: 12245.685547\n",
      "Train Epoch: 3841 [98560/118836 (83%)] Loss: 12231.412109\n",
      "    epoch          : 3841\n",
      "    loss           : 12192.219780358251\n",
      "    val_loss       : 12191.495279794273\n",
      "    val_log_likelihood: -12111.33945861766\n",
      "    val_log_marginal: -12120.044690528312\n",
      "Train Epoch: 3842 [256/118836 (0%)] Loss: 12191.036133\n",
      "Train Epoch: 3842 [33024/118836 (28%)] Loss: 12214.749023\n",
      "Train Epoch: 3842 [65792/118836 (55%)] Loss: 12198.649414\n",
      "Train Epoch: 3842 [98560/118836 (83%)] Loss: 12227.600586\n",
      "    epoch          : 3842\n",
      "    loss           : 12187.717910107785\n",
      "    val_loss       : 12186.92461991005\n",
      "    val_log_likelihood: -12111.527011605667\n",
      "    val_log_marginal: -12120.286541747904\n",
      "Train Epoch: 3843 [256/118836 (0%)] Loss: 12270.016602\n",
      "Train Epoch: 3843 [33024/118836 (28%)] Loss: 12193.848633\n",
      "Train Epoch: 3843 [65792/118836 (55%)] Loss: 12249.744141\n",
      "Train Epoch: 3843 [98560/118836 (83%)] Loss: 12172.939453\n",
      "    epoch          : 3843\n",
      "    loss           : 12191.502294316067\n",
      "    val_loss       : 12191.812312072856\n",
      "    val_log_likelihood: -12118.388397403589\n",
      "    val_log_marginal: -12127.204046226854\n",
      "Train Epoch: 3844 [256/118836 (0%)] Loss: 12285.385742\n",
      "Train Epoch: 3844 [33024/118836 (28%)] Loss: 12195.678711\n",
      "Train Epoch: 3844 [65792/118836 (55%)] Loss: 12183.685547\n",
      "Train Epoch: 3844 [98560/118836 (83%)] Loss: 12220.544922\n",
      "    epoch          : 3844\n",
      "    loss           : 12189.687356544664\n",
      "    val_loss       : 12188.010548041306\n",
      "    val_log_likelihood: -12119.491341630479\n",
      "    val_log_marginal: -12128.396233533671\n",
      "Train Epoch: 3845 [256/118836 (0%)] Loss: 12181.443359\n",
      "Train Epoch: 3845 [33024/118836 (28%)] Loss: 12235.878906\n",
      "Train Epoch: 3845 [65792/118836 (55%)] Loss: 12195.150391\n",
      "Train Epoch: 3845 [98560/118836 (83%)] Loss: 12211.974609\n",
      "    epoch          : 3845\n",
      "    loss           : 12190.45472255609\n",
      "    val_loss       : 12189.722958240218\n",
      "    val_log_likelihood: -12113.717461325215\n",
      "    val_log_marginal: -12122.481448470608\n",
      "Train Epoch: 3846 [256/118836 (0%)] Loss: 12191.977539\n",
      "Train Epoch: 3846 [33024/118836 (28%)] Loss: 12168.119141\n",
      "Train Epoch: 3846 [65792/118836 (55%)] Loss: 12296.951172\n",
      "Train Epoch: 3846 [98560/118836 (83%)] Loss: 12168.479492\n",
      "    epoch          : 3846\n",
      "    loss           : 12190.56872302135\n",
      "    val_loss       : 12192.75029801659\n",
      "    val_log_likelihood: -12113.711339433416\n",
      "    val_log_marginal: -12122.454811084077\n",
      "Train Epoch: 3847 [256/118836 (0%)] Loss: 12226.845703\n",
      "Train Epoch: 3847 [33024/118836 (28%)] Loss: 12200.480469\n",
      "Train Epoch: 3847 [65792/118836 (55%)] Loss: 12130.712891\n",
      "Train Epoch: 3847 [98560/118836 (83%)] Loss: 12222.111328\n",
      "    epoch          : 3847\n",
      "    loss           : 12189.873330716242\n",
      "    val_loss       : 12193.972575891115\n",
      "    val_log_likelihood: -12115.381947083075\n",
      "    val_log_marginal: -12124.051130992457\n",
      "Train Epoch: 3848 [256/118836 (0%)] Loss: 12383.625000\n",
      "Train Epoch: 3848 [33024/118836 (28%)] Loss: 12211.052734\n",
      "Train Epoch: 3848 [65792/118836 (55%)] Loss: 12160.407227\n",
      "Train Epoch: 3848 [98560/118836 (83%)] Loss: 12159.636719\n",
      "    epoch          : 3848\n",
      "    loss           : 12191.841329837418\n",
      "    val_loss       : 12188.604265769185\n",
      "    val_log_likelihood: -12114.667415606908\n",
      "    val_log_marginal: -12123.386617256227\n",
      "Train Epoch: 3849 [256/118836 (0%)] Loss: 12368.128906\n",
      "Train Epoch: 3849 [33024/118836 (28%)] Loss: 12219.125000\n",
      "Train Epoch: 3849 [65792/118836 (55%)] Loss: 12202.775391\n",
      "Train Epoch: 3849 [98560/118836 (83%)] Loss: 12271.964844\n",
      "    epoch          : 3849\n",
      "    loss           : 12190.086896453682\n",
      "    val_loss       : 12190.454672930684\n",
      "    val_log_likelihood: -12110.761075301129\n",
      "    val_log_marginal: -12119.50597623228\n",
      "Train Epoch: 3850 [256/118836 (0%)] Loss: 12212.245117\n",
      "Train Epoch: 3850 [33024/118836 (28%)] Loss: 12279.281250\n",
      "Train Epoch: 3850 [65792/118836 (55%)] Loss: 12129.786133\n",
      "Train Epoch: 3850 [98560/118836 (83%)] Loss: 12235.845703\n",
      "    epoch          : 3850\n",
      "    loss           : 12193.400773334108\n",
      "    val_loss       : 12193.662380079311\n",
      "    val_log_likelihood: -12109.047255770523\n",
      "    val_log_marginal: -12117.921538486458\n",
      "Train Epoch: 3851 [256/118836 (0%)] Loss: 12208.026367\n",
      "Train Epoch: 3851 [33024/118836 (28%)] Loss: 12224.350586\n",
      "Train Epoch: 3851 [65792/118836 (55%)] Loss: 12185.926758\n",
      "Train Epoch: 3851 [98560/118836 (83%)] Loss: 12196.853516\n",
      "    epoch          : 3851\n",
      "    loss           : 12192.718821566119\n",
      "    val_loss       : 12189.765702444643\n",
      "    val_log_likelihood: -12107.204761166253\n",
      "    val_log_marginal: -12116.119173417997\n",
      "Train Epoch: 3852 [256/118836 (0%)] Loss: 12183.141602\n",
      "Train Epoch: 3852 [33024/118836 (28%)] Loss: 12143.358398\n",
      "Train Epoch: 3852 [65792/118836 (55%)] Loss: 12200.623047\n",
      "Train Epoch: 3852 [98560/118836 (83%)] Loss: 12235.007812\n",
      "    epoch          : 3852\n",
      "    loss           : 12190.289559101013\n",
      "    val_loss       : 12189.550438042175\n",
      "    val_log_likelihood: -12114.895355471981\n",
      "    val_log_marginal: -12123.684109541806\n",
      "Train Epoch: 3853 [256/118836 (0%)] Loss: 12199.003906\n",
      "Train Epoch: 3853 [33024/118836 (28%)] Loss: 12243.711914\n",
      "Train Epoch: 3853 [65792/118836 (55%)] Loss: 12220.345703\n",
      "Train Epoch: 3853 [98560/118836 (83%)] Loss: 12252.597656\n",
      "    epoch          : 3853\n",
      "    loss           : 12189.919370670492\n",
      "    val_loss       : 12191.862822881847\n",
      "    val_log_likelihood: -12116.724019237232\n",
      "    val_log_marginal: -12125.333706712729\n",
      "Train Epoch: 3854 [256/118836 (0%)] Loss: 12151.452148\n",
      "Train Epoch: 3854 [33024/118836 (28%)] Loss: 12159.130859\n",
      "Train Epoch: 3854 [65792/118836 (55%)] Loss: 12184.349609\n",
      "Train Epoch: 3854 [98560/118836 (83%)] Loss: 12243.654297\n",
      "    epoch          : 3854\n",
      "    loss           : 12193.88766300274\n",
      "    val_loss       : 12194.545254547156\n",
      "    val_log_likelihood: -12112.596775001291\n",
      "    val_log_marginal: -12121.53960799027\n",
      "Train Epoch: 3855 [256/118836 (0%)] Loss: 12237.136719\n",
      "Train Epoch: 3855 [33024/118836 (28%)] Loss: 12198.855469\n",
      "Train Epoch: 3855 [65792/118836 (55%)] Loss: 12219.699219\n",
      "Train Epoch: 3855 [98560/118836 (83%)] Loss: 12193.212891\n",
      "    epoch          : 3855\n",
      "    loss           : 12194.279385888389\n",
      "    val_loss       : 12190.728319587965\n",
      "    val_log_likelihood: -12118.350255731752\n",
      "    val_log_marginal: -12127.40298149469\n",
      "Train Epoch: 3856 [256/118836 (0%)] Loss: 12179.619141\n",
      "Train Epoch: 3856 [33024/118836 (28%)] Loss: 12334.531250\n",
      "Train Epoch: 3856 [65792/118836 (55%)] Loss: 12275.392578\n",
      "Train Epoch: 3856 [98560/118836 (83%)] Loss: 12217.955078\n",
      "    epoch          : 3856\n",
      "    loss           : 12193.591055366005\n",
      "    val_loss       : 12187.124584331923\n",
      "    val_log_likelihood: -12108.633080024812\n",
      "    val_log_marginal: -12117.53335448756\n",
      "Train Epoch: 3857 [256/118836 (0%)] Loss: 12285.568359\n",
      "Train Epoch: 3857 [33024/118836 (28%)] Loss: 12203.230469\n",
      "Train Epoch: 3857 [65792/118836 (55%)] Loss: 12171.400391\n",
      "Train Epoch: 3857 [98560/118836 (83%)] Loss: 12182.917969\n",
      "    epoch          : 3857\n",
      "    loss           : 12188.241828053919\n",
      "    val_loss       : 12185.819195144652\n",
      "    val_log_likelihood: -12109.97774665271\n",
      "    val_log_marginal: -12118.704275682376\n",
      "Train Epoch: 3858 [256/118836 (0%)] Loss: 12243.605469\n",
      "Train Epoch: 3858 [33024/118836 (28%)] Loss: 12225.600586\n",
      "Train Epoch: 3858 [65792/118836 (55%)] Loss: 12171.481445\n",
      "Train Epoch: 3858 [98560/118836 (83%)] Loss: 12191.243164\n",
      "    epoch          : 3858\n",
      "    loss           : 12187.555293792648\n",
      "    val_loss       : 12188.942787417427\n",
      "    val_log_likelihood: -12109.49531395394\n",
      "    val_log_marginal: -12118.294464182854\n",
      "Train Epoch: 3859 [256/118836 (0%)] Loss: 12153.326172\n",
      "Train Epoch: 3859 [33024/118836 (28%)] Loss: 12161.097656\n",
      "Train Epoch: 3859 [65792/118836 (55%)] Loss: 12277.705078\n",
      "Train Epoch: 3859 [98560/118836 (83%)] Loss: 12192.091797\n",
      "    epoch          : 3859\n",
      "    loss           : 12188.276953771196\n",
      "    val_loss       : 12190.034769855021\n",
      "    val_log_likelihood: -12113.213532296837\n",
      "    val_log_marginal: -12122.14517675425\n",
      "Train Epoch: 3860 [256/118836 (0%)] Loss: 12224.237305\n",
      "Train Epoch: 3860 [33024/118836 (28%)] Loss: 12261.585938\n",
      "Train Epoch: 3860 [65792/118836 (55%)] Loss: 12122.402344\n",
      "Train Epoch: 3860 [98560/118836 (83%)] Loss: 12217.974609\n",
      "    epoch          : 3860\n",
      "    loss           : 12189.48701406121\n",
      "    val_loss       : 12189.39478695312\n",
      "    val_log_likelihood: -12112.178509163048\n",
      "    val_log_marginal: -12120.972900999705\n",
      "Train Epoch: 3861 [256/118836 (0%)] Loss: 12165.509766\n",
      "Train Epoch: 3861 [33024/118836 (28%)] Loss: 12255.310547\n",
      "Train Epoch: 3861 [65792/118836 (55%)] Loss: 12132.980469\n",
      "Train Epoch: 3861 [98560/118836 (83%)] Loss: 12205.340820\n",
      "    epoch          : 3861\n",
      "    loss           : 12187.308901500466\n",
      "    val_loss       : 12188.052483049234\n",
      "    val_log_likelihood: -12112.54283385675\n",
      "    val_log_marginal: -12121.262045314303\n",
      "Train Epoch: 3862 [256/118836 (0%)] Loss: 12198.183594\n",
      "Train Epoch: 3862 [33024/118836 (28%)] Loss: 12188.021484\n",
      "Train Epoch: 3862 [65792/118836 (55%)] Loss: 12206.855469\n",
      "Train Epoch: 3862 [98560/118836 (83%)] Loss: 12198.044922\n",
      "    epoch          : 3862\n",
      "    loss           : 12189.614938902245\n",
      "    val_loss       : 12188.937933344769\n",
      "    val_log_likelihood: -12114.91825291434\n",
      "    val_log_marginal: -12123.528749244528\n",
      "Train Epoch: 3863 [256/118836 (0%)] Loss: 12165.333984\n",
      "Train Epoch: 3863 [33024/118836 (28%)] Loss: 12330.916016\n",
      "Train Epoch: 3863 [65792/118836 (55%)] Loss: 12185.767578\n",
      "Train Epoch: 3863 [98560/118836 (83%)] Loss: 12276.698242\n",
      "    epoch          : 3863\n",
      "    loss           : 12188.988089006927\n",
      "    val_loss       : 12184.892331711624\n",
      "    val_log_likelihood: -12111.055294277294\n",
      "    val_log_marginal: -12119.642788582281\n",
      "Train Epoch: 3864 [256/118836 (0%)] Loss: 12165.650391\n",
      "Train Epoch: 3864 [33024/118836 (28%)] Loss: 12285.795898\n",
      "Train Epoch: 3864 [65792/118836 (55%)] Loss: 12195.013672\n",
      "Train Epoch: 3864 [98560/118836 (83%)] Loss: 12213.483398\n",
      "    epoch          : 3864\n",
      "    loss           : 12190.623506642885\n",
      "    val_loss       : 12187.814694912155\n",
      "    val_log_likelihood: -12109.96971283085\n",
      "    val_log_marginal: -12118.780232481466\n",
      "Train Epoch: 3865 [256/118836 (0%)] Loss: 12157.822266\n",
      "Train Epoch: 3865 [33024/118836 (28%)] Loss: 12245.973633\n",
      "Train Epoch: 3865 [65792/118836 (55%)] Loss: 12268.321289\n",
      "Train Epoch: 3865 [98560/118836 (83%)] Loss: 12160.851562\n",
      "    epoch          : 3865\n",
      "    loss           : 12188.917344040789\n",
      "    val_loss       : 12197.159836043009\n",
      "    val_log_likelihood: -12109.563625025847\n",
      "    val_log_marginal: -12118.226003331392\n",
      "Train Epoch: 3866 [256/118836 (0%)] Loss: 12246.839844\n",
      "Train Epoch: 3866 [33024/118836 (28%)] Loss: 12130.938477\n",
      "Train Epoch: 3866 [65792/118836 (55%)] Loss: 12188.076172\n",
      "Train Epoch: 3866 [98560/118836 (83%)] Loss: 12236.879883\n",
      "    epoch          : 3866\n",
      "    loss           : 12192.856387962674\n",
      "    val_loss       : 12193.297986376056\n",
      "    val_log_likelihood: -12115.784210866419\n",
      "    val_log_marginal: -12124.618719438275\n",
      "Train Epoch: 3867 [256/118836 (0%)] Loss: 12290.351562\n",
      "Train Epoch: 3867 [33024/118836 (28%)] Loss: 12220.043945\n",
      "Train Epoch: 3867 [65792/118836 (55%)] Loss: 12295.299805\n",
      "Train Epoch: 3867 [98560/118836 (83%)] Loss: 12176.706055\n",
      "    epoch          : 3867\n",
      "    loss           : 12187.391549705335\n",
      "    val_loss       : 12191.241112468251\n",
      "    val_log_likelihood: -12107.085417474409\n",
      "    val_log_marginal: -12115.870832174705\n",
      "Train Epoch: 3868 [256/118836 (0%)] Loss: 12175.162109\n",
      "Train Epoch: 3868 [33024/118836 (28%)] Loss: 12118.509766\n",
      "Train Epoch: 3868 [65792/118836 (55%)] Loss: 12219.131836\n",
      "Train Epoch: 3868 [98560/118836 (83%)] Loss: 12167.029297\n",
      "    epoch          : 3868\n",
      "    loss           : 12191.596979360525\n",
      "    val_loss       : 12189.036875581764\n",
      "    val_log_likelihood: -12113.216671674678\n",
      "    val_log_marginal: -12122.009346691957\n",
      "Train Epoch: 3869 [256/118836 (0%)] Loss: 12225.462891\n",
      "Train Epoch: 3869 [33024/118836 (28%)] Loss: 12131.814453\n",
      "Train Epoch: 3869 [65792/118836 (55%)] Loss: 12170.641602\n",
      "Train Epoch: 3869 [98560/118836 (83%)] Loss: 12223.757812\n",
      "    epoch          : 3869\n",
      "    loss           : 12195.378033724928\n",
      "    val_loss       : 12189.349396261438\n",
      "    val_log_likelihood: -12115.103602861353\n",
      "    val_log_marginal: -12124.02401149325\n",
      "Train Epoch: 3870 [256/118836 (0%)] Loss: 12234.024414\n",
      "Train Epoch: 3870 [33024/118836 (28%)] Loss: 12142.553711\n",
      "Train Epoch: 3870 [65792/118836 (55%)] Loss: 12293.300781\n",
      "Train Epoch: 3870 [98560/118836 (83%)] Loss: 12275.907227\n",
      "    epoch          : 3870\n",
      "    loss           : 12188.998617303816\n",
      "    val_loss       : 12190.861791247808\n",
      "    val_log_likelihood: -12110.272043980045\n",
      "    val_log_marginal: -12119.117560943454\n",
      "Train Epoch: 3871 [256/118836 (0%)] Loss: 12244.854492\n",
      "Train Epoch: 3871 [33024/118836 (28%)] Loss: 12172.222656\n",
      "Train Epoch: 3871 [65792/118836 (55%)] Loss: 12308.037109\n",
      "Train Epoch: 3871 [98560/118836 (83%)] Loss: 12184.115234\n",
      "    epoch          : 3871\n",
      "    loss           : 12194.25556874871\n",
      "    val_loss       : 12195.224745234995\n",
      "    val_log_likelihood: -12113.365851006773\n",
      "    val_log_marginal: -12122.51229613009\n",
      "Train Epoch: 3872 [256/118836 (0%)] Loss: 12195.556641\n",
      "Train Epoch: 3872 [33024/118836 (28%)] Loss: 12119.742188\n",
      "Train Epoch: 3872 [65792/118836 (55%)] Loss: 12319.313477\n",
      "Train Epoch: 3872 [98560/118836 (83%)] Loss: 12262.208984\n",
      "    epoch          : 3872\n",
      "    loss           : 12192.408373235887\n",
      "    val_loss       : 12194.75226691473\n",
      "    val_log_likelihood: -12112.368951289807\n",
      "    val_log_marginal: -12121.377502973297\n",
      "Train Epoch: 3873 [256/118836 (0%)] Loss: 12250.561523\n",
      "Train Epoch: 3873 [33024/118836 (28%)] Loss: 12172.136719\n",
      "Train Epoch: 3873 [65792/118836 (55%)] Loss: 12181.328125\n",
      "Train Epoch: 3873 [98560/118836 (83%)] Loss: 12165.429688\n",
      "    epoch          : 3873\n",
      "    loss           : 12192.50798891129\n",
      "    val_loss       : 12190.284108323118\n",
      "    val_log_likelihood: -12115.842426430676\n",
      "    val_log_marginal: -12124.74198191675\n",
      "Train Epoch: 3874 [256/118836 (0%)] Loss: 12159.809570\n",
      "Train Epoch: 3874 [33024/118836 (28%)] Loss: 12137.414062\n",
      "Train Epoch: 3874 [65792/118836 (55%)] Loss: 12230.553711\n",
      "Train Epoch: 3874 [98560/118836 (83%)] Loss: 12194.029297\n",
      "    epoch          : 3874\n",
      "    loss           : 12191.57056580852\n",
      "    val_loss       : 12188.491514363577\n",
      "    val_log_likelihood: -12111.670924931504\n",
      "    val_log_marginal: -12120.660146704748\n",
      "Train Epoch: 3875 [256/118836 (0%)] Loss: 12140.666016\n",
      "Train Epoch: 3875 [33024/118836 (28%)] Loss: 12176.329102\n",
      "Train Epoch: 3875 [65792/118836 (55%)] Loss: 12184.363281\n",
      "Train Epoch: 3875 [98560/118836 (83%)] Loss: 12215.806641\n",
      "    epoch          : 3875\n",
      "    loss           : 12191.778264093517\n",
      "    val_loss       : 12193.82119795383\n",
      "    val_log_likelihood: -12119.814538907414\n",
      "    val_log_marginal: -12128.56383326678\n",
      "Train Epoch: 3876 [256/118836 (0%)] Loss: 12196.134766\n",
      "Train Epoch: 3876 [33024/118836 (28%)] Loss: 12167.882812\n",
      "Train Epoch: 3876 [65792/118836 (55%)] Loss: 12188.857422\n",
      "Train Epoch: 3876 [98560/118836 (83%)] Loss: 12197.215820\n",
      "    epoch          : 3876\n",
      "    loss           : 12191.360614725496\n",
      "    val_loss       : 12186.74336621406\n",
      "    val_log_likelihood: -12109.783901500465\n",
      "    val_log_marginal: -12118.520380273045\n",
      "Train Epoch: 3877 [256/118836 (0%)] Loss: 12194.140625\n",
      "Train Epoch: 3877 [33024/118836 (28%)] Loss: 12337.373047\n",
      "Train Epoch: 3877 [65792/118836 (55%)] Loss: 12256.746094\n",
      "Train Epoch: 3877 [98560/118836 (83%)] Loss: 12174.248047\n",
      "    epoch          : 3877\n",
      "    loss           : 12192.388956362438\n",
      "    val_loss       : 12187.714477311629\n",
      "    val_log_likelihood: -12113.79705286523\n",
      "    val_log_marginal: -12122.561043046506\n",
      "Train Epoch: 3878 [256/118836 (0%)] Loss: 12225.447266\n",
      "Train Epoch: 3878 [33024/118836 (28%)] Loss: 12253.203125\n",
      "Train Epoch: 3878 [65792/118836 (55%)] Loss: 12124.385742\n",
      "Train Epoch: 3878 [98560/118836 (83%)] Loss: 12252.463867\n",
      "    epoch          : 3878\n",
      "    loss           : 12187.275753463606\n",
      "    val_loss       : 12188.890063505902\n",
      "    val_log_likelihood: -12112.763933745606\n",
      "    val_log_marginal: -12121.531401923761\n",
      "Train Epoch: 3879 [256/118836 (0%)] Loss: 12236.682617\n",
      "Train Epoch: 3879 [33024/118836 (28%)] Loss: 12173.583008\n",
      "Train Epoch: 3879 [65792/118836 (55%)] Loss: 12158.193359\n",
      "Train Epoch: 3879 [98560/118836 (83%)] Loss: 12245.969727\n",
      "    epoch          : 3879\n",
      "    loss           : 12190.683104257134\n",
      "    val_loss       : 12195.292976716806\n",
      "    val_log_likelihood: -12110.785258348842\n",
      "    val_log_marginal: -12119.545412748916\n",
      "Train Epoch: 3880 [256/118836 (0%)] Loss: 12254.502930\n",
      "Train Epoch: 3880 [33024/118836 (28%)] Loss: 12183.372070\n",
      "Train Epoch: 3880 [65792/118836 (55%)] Loss: 12171.310547\n",
      "Train Epoch: 3880 [98560/118836 (83%)] Loss: 12235.786133\n",
      "    epoch          : 3880\n",
      "    loss           : 12192.113835200838\n",
      "    val_loss       : 12189.878483178505\n",
      "    val_log_likelihood: -12114.92311165607\n",
      "    val_log_marginal: -12123.78921657644\n",
      "Train Epoch: 3881 [256/118836 (0%)] Loss: 12222.302734\n",
      "Train Epoch: 3881 [33024/118836 (28%)] Loss: 12173.702148\n",
      "Train Epoch: 3881 [65792/118836 (55%)] Loss: 12202.183594\n",
      "Train Epoch: 3881 [98560/118836 (83%)] Loss: 12228.029297\n",
      "    epoch          : 3881\n",
      "    loss           : 12189.528667480874\n",
      "    val_loss       : 12184.452327884945\n",
      "    val_log_likelihood: -12111.240677180263\n",
      "    val_log_marginal: -12119.9890881258\n",
      "Train Epoch: 3882 [256/118836 (0%)] Loss: 12247.690430\n",
      "Train Epoch: 3882 [33024/118836 (28%)] Loss: 12120.004883\n",
      "Train Epoch: 3882 [65792/118836 (55%)] Loss: 12337.511719\n",
      "Train Epoch: 3882 [98560/118836 (83%)] Loss: 12298.560547\n",
      "    epoch          : 3882\n",
      "    loss           : 12189.373523928607\n",
      "    val_loss       : 12189.567311293864\n",
      "    val_log_likelihood: -12111.07961884176\n",
      "    val_log_marginal: -12120.002125106179\n",
      "Train Epoch: 3883 [256/118836 (0%)] Loss: 12299.104492\n",
      "Train Epoch: 3883 [33024/118836 (28%)] Loss: 12315.534180\n",
      "Train Epoch: 3883 [65792/118836 (55%)] Loss: 12221.113281\n",
      "Train Epoch: 3883 [98560/118836 (83%)] Loss: 12209.917969\n",
      "    epoch          : 3883\n",
      "    loss           : 12189.693088296111\n",
      "    val_loss       : 12188.761755082816\n",
      "    val_log_likelihood: -12113.309705851943\n",
      "    val_log_marginal: -12122.184426329166\n",
      "Train Epoch: 3884 [256/118836 (0%)] Loss: 12283.533203\n",
      "Train Epoch: 3884 [33024/118836 (28%)] Loss: 12164.535156\n",
      "Train Epoch: 3884 [65792/118836 (55%)] Loss: 12159.751953\n",
      "Train Epoch: 3884 [98560/118836 (83%)] Loss: 12237.017578\n",
      "    epoch          : 3884\n",
      "    loss           : 12190.3048089847\n",
      "    val_loss       : 12189.460303121561\n",
      "    val_log_likelihood: -12110.240584935897\n",
      "    val_log_marginal: -12119.15213831337\n",
      "Train Epoch: 3885 [256/118836 (0%)] Loss: 12207.213867\n",
      "Train Epoch: 3885 [33024/118836 (28%)] Loss: 12403.523438\n",
      "Train Epoch: 3885 [65792/118836 (55%)] Loss: 12273.125977\n",
      "Train Epoch: 3885 [98560/118836 (83%)] Loss: 12230.480469\n",
      "    epoch          : 3885\n",
      "    loss           : 12186.87450420673\n",
      "    val_loss       : 12184.748636575154\n",
      "    val_log_likelihood: -12108.303637432795\n",
      "    val_log_marginal: -12116.983002021218\n",
      "Train Epoch: 3886 [256/118836 (0%)] Loss: 12187.999023\n",
      "Train Epoch: 3886 [33024/118836 (28%)] Loss: 12182.383789\n",
      "Train Epoch: 3886 [65792/118836 (55%)] Loss: 12146.494141\n",
      "Train Epoch: 3886 [98560/118836 (83%)] Loss: 12228.235352\n",
      "    epoch          : 3886\n",
      "    loss           : 12183.89741247286\n",
      "    val_loss       : 12186.647593472806\n",
      "    val_log_likelihood: -12109.611080632236\n",
      "    val_log_marginal: -12118.356614603637\n",
      "Train Epoch: 3887 [256/118836 (0%)] Loss: 12265.087891\n",
      "Train Epoch: 3887 [33024/118836 (28%)] Loss: 12185.680664\n",
      "Train Epoch: 3887 [65792/118836 (55%)] Loss: 12190.867188\n",
      "Train Epoch: 3887 [98560/118836 (83%)] Loss: 12208.083008\n",
      "    epoch          : 3887\n",
      "    loss           : 12187.602613859595\n",
      "    val_loss       : 12186.01260234541\n",
      "    val_log_likelihood: -12109.390505938534\n",
      "    val_log_marginal: -12118.067670195782\n",
      "Train Epoch: 3888 [256/118836 (0%)] Loss: 12272.791016\n",
      "Train Epoch: 3888 [33024/118836 (28%)] Loss: 12200.114258\n",
      "Train Epoch: 3888 [65792/118836 (55%)] Loss: 12252.916992\n",
      "Train Epoch: 3888 [98560/118836 (83%)] Loss: 12231.085938\n",
      "    epoch          : 3888\n",
      "    loss           : 12188.350147170959\n",
      "    val_loss       : 12184.069462362135\n",
      "    val_log_likelihood: -12107.473169167442\n",
      "    val_log_marginal: -12116.093040162383\n",
      "Train Epoch: 3889 [256/118836 (0%)] Loss: 12334.018555\n",
      "Train Epoch: 3889 [33024/118836 (28%)] Loss: 12148.181641\n",
      "Train Epoch: 3889 [65792/118836 (55%)] Loss: 12274.051758\n",
      "Train Epoch: 3889 [98560/118836 (83%)] Loss: 12195.018555\n",
      "    epoch          : 3889\n",
      "    loss           : 12190.297538319377\n",
      "    val_loss       : 12188.66991203351\n",
      "    val_log_likelihood: -12110.574775285619\n",
      "    val_log_marginal: -12119.385244277742\n",
      "Train Epoch: 3890 [256/118836 (0%)] Loss: 12214.809570\n",
      "Train Epoch: 3890 [33024/118836 (28%)] Loss: 12212.236328\n",
      "Train Epoch: 3890 [65792/118836 (55%)] Loss: 12181.718750\n",
      "Train Epoch: 3890 [98560/118836 (83%)] Loss: 12284.871094\n",
      "    epoch          : 3890\n",
      "    loss           : 12190.523744119624\n",
      "    val_loss       : 12187.47543326955\n",
      "    val_log_likelihood: -12107.850383516854\n",
      "    val_log_marginal: -12116.609160573982\n",
      "Train Epoch: 3891 [256/118836 (0%)] Loss: 12280.535156\n",
      "Train Epoch: 3891 [33024/118836 (28%)] Loss: 12201.149414\n",
      "Train Epoch: 3891 [65792/118836 (55%)] Loss: 12186.454102\n",
      "Train Epoch: 3891 [98560/118836 (83%)] Loss: 12155.958984\n",
      "    epoch          : 3891\n",
      "    loss           : 12190.386902592536\n",
      "    val_loss       : 12184.107547419851\n",
      "    val_log_likelihood: -12109.040556664857\n",
      "    val_log_marginal: -12117.727248944684\n",
      "Train Epoch: 3892 [256/118836 (0%)] Loss: 12214.861328\n",
      "Train Epoch: 3892 [33024/118836 (28%)] Loss: 12205.698242\n",
      "Train Epoch: 3892 [65792/118836 (55%)] Loss: 12254.420898\n",
      "Train Epoch: 3892 [98560/118836 (83%)] Loss: 12164.999023\n",
      "    epoch          : 3892\n",
      "    loss           : 12186.305548878205\n",
      "    val_loss       : 12190.321262566938\n",
      "    val_log_likelihood: -12109.751774936673\n",
      "    val_log_marginal: -12118.418046250341\n",
      "Train Epoch: 3893 [256/118836 (0%)] Loss: 12181.028320\n",
      "Train Epoch: 3893 [33024/118836 (28%)] Loss: 12258.498047\n",
      "Train Epoch: 3893 [65792/118836 (55%)] Loss: 12274.386719\n",
      "Train Epoch: 3893 [98560/118836 (83%)] Loss: 12229.415039\n",
      "    epoch          : 3893\n",
      "    loss           : 12190.368049847499\n",
      "    val_loss       : 12187.2848242292\n",
      "    val_log_likelihood: -12105.794331252586\n",
      "    val_log_marginal: -12114.41995020383\n",
      "Train Epoch: 3894 [256/118836 (0%)] Loss: 12227.337891\n",
      "Train Epoch: 3894 [33024/118836 (28%)] Loss: 12174.637695\n",
      "Train Epoch: 3894 [65792/118836 (55%)] Loss: 12288.972656\n",
      "Train Epoch: 3894 [98560/118836 (83%)] Loss: 12223.299805\n",
      "    epoch          : 3894\n",
      "    loss           : 12187.923557853857\n",
      "    val_loss       : 12188.865748028371\n",
      "    val_log_likelihood: -12108.871061924887\n",
      "    val_log_marginal: -12117.639694473468\n",
      "Train Epoch: 3895 [256/118836 (0%)] Loss: 12190.210938\n",
      "Train Epoch: 3895 [33024/118836 (28%)] Loss: 12208.368164\n",
      "Train Epoch: 3895 [65792/118836 (55%)] Loss: 12180.071289\n",
      "Train Epoch: 3895 [98560/118836 (83%)] Loss: 12103.292969\n",
      "    epoch          : 3895\n",
      "    loss           : 12187.863713877688\n",
      "    val_loss       : 12186.51965047905\n",
      "    val_log_likelihood: -12110.652149406793\n",
      "    val_log_marginal: -12119.42896926634\n",
      "Train Epoch: 3896 [256/118836 (0%)] Loss: 12221.782227\n",
      "Train Epoch: 3896 [33024/118836 (28%)] Loss: 12137.970703\n",
      "Train Epoch: 3896 [65792/118836 (55%)] Loss: 12261.787109\n",
      "Train Epoch: 3896 [98560/118836 (83%)] Loss: 12296.337891\n",
      "    epoch          : 3896\n",
      "    loss           : 12184.075799666563\n",
      "    val_loss       : 12190.722066008622\n",
      "    val_log_likelihood: -12108.9280038384\n",
      "    val_log_marginal: -12117.64518110202\n",
      "Train Epoch: 3897 [256/118836 (0%)] Loss: 12126.274414\n",
      "Train Epoch: 3897 [33024/118836 (28%)] Loss: 12192.091797\n",
      "Train Epoch: 3897 [65792/118836 (55%)] Loss: 12182.034180\n",
      "Train Epoch: 3897 [98560/118836 (83%)] Loss: 12157.941406\n",
      "    epoch          : 3897\n",
      "    loss           : 12185.384854153743\n",
      "    val_loss       : 12186.648375656132\n",
      "    val_log_likelihood: -12106.799685787582\n",
      "    val_log_marginal: -12115.389931602249\n",
      "Train Epoch: 3898 [256/118836 (0%)] Loss: 12280.740234\n",
      "Train Epoch: 3898 [33024/118836 (28%)] Loss: 12234.502930\n",
      "Train Epoch: 3898 [65792/118836 (55%)] Loss: 12178.462891\n",
      "Train Epoch: 3898 [98560/118836 (83%)] Loss: 12339.852539\n",
      "    epoch          : 3898\n",
      "    loss           : 12185.096330418992\n",
      "    val_loss       : 12185.876208224845\n",
      "    val_log_likelihood: -12109.00729134357\n",
      "    val_log_marginal: -12117.68775773379\n",
      "Train Epoch: 3899 [256/118836 (0%)] Loss: 12122.585938\n",
      "Train Epoch: 3899 [33024/118836 (28%)] Loss: 12221.570312\n",
      "Train Epoch: 3899 [65792/118836 (55%)] Loss: 12167.587891\n",
      "Train Epoch: 3899 [98560/118836 (83%)] Loss: 12148.869141\n",
      "    epoch          : 3899\n",
      "    loss           : 12186.462441519334\n",
      "    val_loss       : 12188.462447208833\n",
      "    val_log_likelihood: -12108.2604187668\n",
      "    val_log_marginal: -12116.958827255263\n",
      "Train Epoch: 3900 [256/118836 (0%)] Loss: 12165.119141\n",
      "Train Epoch: 3900 [33024/118836 (28%)] Loss: 12232.459961\n",
      "Train Epoch: 3900 [65792/118836 (55%)] Loss: 12197.064453\n",
      "Train Epoch: 3900 [98560/118836 (83%)] Loss: 12149.800781\n",
      "    epoch          : 3900\n",
      "    loss           : 12190.416283311362\n",
      "    val_loss       : 12189.50167771221\n",
      "    val_log_likelihood: -12109.876918553557\n",
      "    val_log_marginal: -12118.64711785243\n",
      "Saving checkpoint: saved/models/SelfiesAutoencodingOperad/0905_154251/checkpoint-epoch3900.pth ...\n",
      "Train Epoch: 3901 [256/118836 (0%)] Loss: 12130.718750\n",
      "Train Epoch: 3901 [33024/118836 (28%)] Loss: 12300.601562\n",
      "Train Epoch: 3901 [65792/118836 (55%)] Loss: 12297.082031\n",
      "Train Epoch: 3901 [98560/118836 (83%)] Loss: 12164.253906\n",
      "    epoch          : 3901\n",
      "    loss           : 12190.051417429177\n",
      "    val_loss       : 12184.606733477809\n",
      "    val_log_likelihood: -12113.971882269696\n",
      "    val_log_marginal: -12122.61673944651\n",
      "Train Epoch: 3902 [256/118836 (0%)] Loss: 12235.042969\n",
      "Train Epoch: 3902 [33024/118836 (28%)] Loss: 12194.508789\n",
      "Train Epoch: 3902 [65792/118836 (55%)] Loss: 12354.253906\n",
      "Train Epoch: 3902 [98560/118836 (83%)] Loss: 12199.699219\n",
      "    epoch          : 3902\n",
      "    loss           : 12189.53010930392\n",
      "    val_loss       : 12187.0521144999\n",
      "    val_log_likelihood: -12108.433018151623\n",
      "    val_log_marginal: -12117.216569228673\n",
      "Train Epoch: 3903 [256/118836 (0%)] Loss: 12291.863281\n",
      "Train Epoch: 3903 [33024/118836 (28%)] Loss: 12248.277344\n",
      "Train Epoch: 3903 [65792/118836 (55%)] Loss: 12240.306641\n",
      "Train Epoch: 3903 [98560/118836 (83%)] Loss: 12156.663086\n",
      "    epoch          : 3903\n",
      "    loss           : 12190.30035702285\n",
      "    val_loss       : 12185.348749628243\n",
      "    val_log_likelihood: -12108.51848877559\n",
      "    val_log_marginal: -12117.129564157862\n",
      "Train Epoch: 3904 [256/118836 (0%)] Loss: 12203.198242\n",
      "Train Epoch: 3904 [33024/118836 (28%)] Loss: 12310.648438\n",
      "Train Epoch: 3904 [65792/118836 (55%)] Loss: 12189.534180\n",
      "Train Epoch: 3904 [98560/118836 (83%)] Loss: 12152.185547\n",
      "    epoch          : 3904\n",
      "    loss           : 12187.477264429539\n",
      "    val_loss       : 12186.466439622915\n",
      "    val_log_likelihood: -12109.133275175765\n",
      "    val_log_marginal: -12117.756526276802\n",
      "Train Epoch: 3905 [256/118836 (0%)] Loss: 12184.974609\n",
      "Train Epoch: 3905 [33024/118836 (28%)] Loss: 12247.411133\n",
      "Train Epoch: 3905 [65792/118836 (55%)] Loss: 12177.352539\n",
      "Train Epoch: 3905 [98560/118836 (83%)] Loss: 12213.882812\n",
      "    epoch          : 3905\n",
      "    loss           : 12188.8971040762\n",
      "    val_loss       : 12185.484089076095\n",
      "    val_log_likelihood: -12109.985541866989\n",
      "    val_log_marginal: -12118.705092051845\n",
      "Train Epoch: 3906 [256/118836 (0%)] Loss: 12208.093750\n",
      "Train Epoch: 3906 [33024/118836 (28%)] Loss: 12172.447266\n",
      "Train Epoch: 3906 [65792/118836 (55%)] Loss: 12192.327148\n",
      "Train Epoch: 3906 [98560/118836 (83%)] Loss: 12119.249023\n",
      "    epoch          : 3906\n",
      "    loss           : 12186.416845178092\n",
      "    val_loss       : 12184.7712706259\n",
      "    val_log_likelihood: -12110.96289337133\n",
      "    val_log_marginal: -12119.696264154594\n",
      "Train Epoch: 3907 [256/118836 (0%)] Loss: 12305.054688\n",
      "Train Epoch: 3907 [33024/118836 (28%)] Loss: 12192.437500\n",
      "Train Epoch: 3907 [65792/118836 (55%)] Loss: 12248.284180\n",
      "Train Epoch: 3907 [98560/118836 (83%)] Loss: 12210.559570\n",
      "    epoch          : 3907\n",
      "    loss           : 12185.678942921577\n",
      "    val_loss       : 12188.02842334705\n",
      "    val_log_likelihood: -12108.363816622725\n",
      "    val_log_marginal: -12117.030643503695\n",
      "Train Epoch: 3908 [256/118836 (0%)] Loss: 12298.851562\n",
      "Train Epoch: 3908 [33024/118836 (28%)] Loss: 12214.871094\n",
      "Train Epoch: 3908 [65792/118836 (55%)] Loss: 12169.962891\n",
      "Train Epoch: 3908 [98560/118836 (83%)] Loss: 12217.097656\n",
      "    epoch          : 3908\n",
      "    loss           : 12189.68330296216\n",
      "    val_loss       : 12192.378372708376\n",
      "    val_log_likelihood: -12109.554520943186\n",
      "    val_log_marginal: -12118.30166615213\n",
      "Train Epoch: 3909 [256/118836 (0%)] Loss: 12216.142578\n",
      "Train Epoch: 3909 [33024/118836 (28%)] Loss: 12206.439453\n",
      "Train Epoch: 3909 [65792/118836 (55%)] Loss: 12238.961914\n",
      "Train Epoch: 3909 [98560/118836 (83%)] Loss: 12227.083008\n",
      "    epoch          : 3909\n",
      "    loss           : 12190.279596709574\n",
      "    val_loss       : 12186.28271706494\n",
      "    val_log_likelihood: -12110.489737612437\n",
      "    val_log_marginal: -12119.16046495787\n",
      "Train Epoch: 3910 [256/118836 (0%)] Loss: 12268.638672\n",
      "Train Epoch: 3910 [33024/118836 (28%)] Loss: 12200.806641\n",
      "Train Epoch: 3910 [65792/118836 (55%)] Loss: 12196.744141\n",
      "Train Epoch: 3910 [98560/118836 (83%)] Loss: 12287.846680\n",
      "    epoch          : 3910\n",
      "    loss           : 12184.605706226737\n",
      "    val_loss       : 12183.641823234033\n",
      "    val_log_likelihood: -12108.387489499328\n",
      "    val_log_marginal: -12117.087969109829\n",
      "Train Epoch: 3911 [256/118836 (0%)] Loss: 12285.355469\n",
      "Train Epoch: 3911 [33024/118836 (28%)] Loss: 12247.667969\n",
      "Train Epoch: 3911 [65792/118836 (55%)] Loss: 12133.350586\n",
      "Train Epoch: 3911 [98560/118836 (83%)] Loss: 12239.783203\n",
      "    epoch          : 3911\n",
      "    loss           : 12186.44562089666\n",
      "    val_loss       : 12186.336149066701\n",
      "    val_log_likelihood: -12107.843991677006\n",
      "    val_log_marginal: -12116.520294937332\n",
      "Train Epoch: 3912 [256/118836 (0%)] Loss: 12320.991211\n",
      "Train Epoch: 3912 [33024/118836 (28%)] Loss: 12171.557617\n",
      "Train Epoch: 3912 [65792/118836 (55%)] Loss: 12229.539062\n",
      "Train Epoch: 3912 [98560/118836 (83%)] Loss: 12230.531250\n",
      "    epoch          : 3912\n",
      "    loss           : 12186.798357048698\n",
      "    val_loss       : 12185.394274673547\n",
      "    val_log_likelihood: -12107.261728281379\n",
      "    val_log_marginal: -12116.272160912762\n",
      "Train Epoch: 3913 [256/118836 (0%)] Loss: 12160.327148\n",
      "Train Epoch: 3913 [33024/118836 (28%)] Loss: 12112.402344\n",
      "Train Epoch: 3913 [65792/118836 (55%)] Loss: 12239.175781\n",
      "Train Epoch: 3913 [98560/118836 (83%)] Loss: 12228.783203\n",
      "    epoch          : 3913\n",
      "    loss           : 12186.443842567463\n",
      "    val_loss       : 12186.471727770098\n",
      "    val_log_likelihood: -12110.073998397436\n",
      "    val_log_marginal: -12118.877622838883\n",
      "Train Epoch: 3914 [256/118836 (0%)] Loss: 12196.331055\n",
      "Train Epoch: 3914 [33024/118836 (28%)] Loss: 12229.423828\n",
      "Train Epoch: 3914 [65792/118836 (55%)] Loss: 12206.719727\n",
      "Train Epoch: 3914 [98560/118836 (83%)] Loss: 12138.654297\n",
      "    epoch          : 3914\n",
      "    loss           : 12187.584242206885\n",
      "    val_loss       : 12186.258085678217\n",
      "    val_log_likelihood: -12107.939260074183\n",
      "    val_log_marginal: -12116.614979268283\n",
      "Train Epoch: 3915 [256/118836 (0%)] Loss: 12237.994141\n",
      "Train Epoch: 3915 [33024/118836 (28%)] Loss: 12282.041992\n",
      "Train Epoch: 3915 [65792/118836 (55%)] Loss: 12263.092773\n",
      "Train Epoch: 3915 [98560/118836 (83%)] Loss: 12156.198242\n",
      "    epoch          : 3915\n",
      "    loss           : 12185.579988142317\n",
      "    val_loss       : 12186.207424916107\n",
      "    val_log_likelihood: -12109.517050991264\n",
      "    val_log_marginal: -12118.19253462007\n",
      "Train Epoch: 3916 [256/118836 (0%)] Loss: 12177.374023\n",
      "Train Epoch: 3916 [33024/118836 (28%)] Loss: 12224.488281\n",
      "Train Epoch: 3916 [65792/118836 (55%)] Loss: 12407.655273\n",
      "Train Epoch: 3916 [98560/118836 (83%)] Loss: 12283.685547\n",
      "    epoch          : 3916\n",
      "    loss           : 12183.227989622106\n",
      "    val_loss       : 12188.370667104431\n",
      "    val_log_likelihood: -12110.891650673335\n",
      "    val_log_marginal: -12119.559057535542\n",
      "Train Epoch: 3917 [256/118836 (0%)] Loss: 12151.557617\n",
      "Train Epoch: 3917 [33024/118836 (28%)] Loss: 12254.333984\n",
      "Train Epoch: 3917 [65792/118836 (55%)] Loss: 12163.876953\n",
      "Train Epoch: 3917 [98560/118836 (83%)] Loss: 12190.527344\n",
      "    epoch          : 3917\n",
      "    loss           : 12183.387567042751\n",
      "    val_loss       : 12190.601520347192\n",
      "    val_log_likelihood: -12108.30467376835\n",
      "    val_log_marginal: -12116.945438129482\n",
      "Train Epoch: 3918 [256/118836 (0%)] Loss: 12224.083984\n",
      "Train Epoch: 3918 [33024/118836 (28%)] Loss: 12221.312500\n",
      "Train Epoch: 3918 [65792/118836 (55%)] Loss: 12146.664062\n",
      "Train Epoch: 3918 [98560/118836 (83%)] Loss: 12175.696289\n",
      "    epoch          : 3918\n",
      "    loss           : 12184.69731150486\n",
      "    val_loss       : 12187.591699342822\n",
      "    val_log_likelihood: -12108.842258581473\n",
      "    val_log_marginal: -12117.421618437771\n",
      "Train Epoch: 3919 [256/118836 (0%)] Loss: 12152.289062\n",
      "Train Epoch: 3919 [33024/118836 (28%)] Loss: 12241.836914\n",
      "Train Epoch: 3919 [65792/118836 (55%)] Loss: 12186.228516\n",
      "Train Epoch: 3919 [98560/118836 (83%)] Loss: 12256.674805\n",
      "    epoch          : 3919\n",
      "    loss           : 12187.780201225187\n",
      "    val_loss       : 12183.571725966493\n",
      "    val_log_likelihood: -12107.503054080076\n",
      "    val_log_marginal: -12116.137908826511\n",
      "Train Epoch: 3920 [256/118836 (0%)] Loss: 12183.908203\n",
      "Train Epoch: 3920 [33024/118836 (28%)] Loss: 12202.166016\n",
      "Train Epoch: 3920 [65792/118836 (55%)] Loss: 12162.721680\n",
      "Train Epoch: 3920 [98560/118836 (83%)] Loss: 12300.371094\n",
      "    epoch          : 3920\n",
      "    loss           : 12187.039642137097\n",
      "    val_loss       : 12188.303796388864\n",
      "    val_log_likelihood: -12106.949860583385\n",
      "    val_log_marginal: -12115.690584665877\n",
      "Train Epoch: 3921 [256/118836 (0%)] Loss: 12178.056641\n",
      "Train Epoch: 3921 [33024/118836 (28%)] Loss: 12148.121094\n",
      "Train Epoch: 3921 [65792/118836 (55%)] Loss: 12275.162109\n",
      "Train Epoch: 3921 [98560/118836 (83%)] Loss: 12167.847656\n",
      "    epoch          : 3921\n",
      "    loss           : 12184.2494342561\n",
      "    val_loss       : 12188.160204531781\n",
      "    val_log_likelihood: -12109.275947483715\n",
      "    val_log_marginal: -12118.033569010306\n",
      "Train Epoch: 3922 [256/118836 (0%)] Loss: 12268.284180\n",
      "Train Epoch: 3922 [33024/118836 (28%)] Loss: 12226.625977\n",
      "Train Epoch: 3922 [65792/118836 (55%)] Loss: 12149.120117\n",
      "Train Epoch: 3922 [98560/118836 (83%)] Loss: 12234.428711\n",
      "    epoch          : 3922\n",
      "    loss           : 12187.992263912582\n",
      "    val_loss       : 12187.85846367086\n",
      "    val_log_likelihood: -12111.619039495452\n",
      "    val_log_marginal: -12120.31593231104\n",
      "Train Epoch: 3923 [256/118836 (0%)] Loss: 12169.757812\n",
      "Train Epoch: 3923 [33024/118836 (28%)] Loss: 12192.505859\n",
      "Train Epoch: 3923 [65792/118836 (55%)] Loss: 12189.373047\n",
      "Train Epoch: 3923 [98560/118836 (83%)] Loss: 12144.541992\n",
      "    epoch          : 3923\n",
      "    loss           : 12185.687210666098\n",
      "    val_loss       : 12188.060280029262\n",
      "    val_log_likelihood: -12110.640769909274\n",
      "    val_log_marginal: -12119.416349968971\n",
      "Train Epoch: 3924 [256/118836 (0%)] Loss: 12202.636719\n",
      "Train Epoch: 3924 [33024/118836 (28%)] Loss: 12348.890625\n",
      "Train Epoch: 3924 [65792/118836 (55%)] Loss: 12162.931641\n",
      "Train Epoch: 3924 [98560/118836 (83%)] Loss: 12248.910156\n",
      "    epoch          : 3924\n",
      "    loss           : 12182.029815446649\n",
      "    val_loss       : 12184.216624505872\n",
      "    val_log_likelihood: -12106.75986788539\n",
      "    val_log_marginal: -12115.45031978176\n",
      "Train Epoch: 3925 [256/118836 (0%)] Loss: 12179.163086\n",
      "Train Epoch: 3925 [33024/118836 (28%)] Loss: 12167.575195\n",
      "Train Epoch: 3925 [65792/118836 (55%)] Loss: 12244.658203\n",
      "Train Epoch: 3925 [98560/118836 (83%)] Loss: 12253.033203\n",
      "    epoch          : 3925\n",
      "    loss           : 12190.701269288926\n",
      "    val_loss       : 12182.68657157479\n",
      "    val_log_likelihood: -12108.241672159327\n",
      "    val_log_marginal: -12117.01459418129\n",
      "Train Epoch: 3926 [256/118836 (0%)] Loss: 12223.207031\n",
      "Train Epoch: 3926 [33024/118836 (28%)] Loss: 12253.973633\n",
      "Train Epoch: 3926 [65792/118836 (55%)] Loss: 12164.451172\n",
      "Train Epoch: 3926 [98560/118836 (83%)] Loss: 12219.839844\n",
      "    epoch          : 3926\n",
      "    loss           : 12184.06110858018\n",
      "    val_loss       : 12186.18786391612\n",
      "    val_log_likelihood: -12110.395247557382\n",
      "    val_log_marginal: -12119.054641535984\n",
      "Train Epoch: 3927 [256/118836 (0%)] Loss: 12165.101562\n",
      "Train Epoch: 3927 [33024/118836 (28%)] Loss: 12256.203125\n",
      "Train Epoch: 3927 [65792/118836 (55%)] Loss: 12169.610352\n",
      "Train Epoch: 3927 [98560/118836 (83%)] Loss: 12186.720703\n",
      "    epoch          : 3927\n",
      "    loss           : 12183.938023256565\n",
      "    val_loss       : 12186.641601376094\n",
      "    val_log_likelihood: -12112.674473674006\n",
      "    val_log_marginal: -12121.342982240165\n",
      "Train Epoch: 3928 [256/118836 (0%)] Loss: 12226.017578\n",
      "Train Epoch: 3928 [33024/118836 (28%)] Loss: 12275.974609\n",
      "Train Epoch: 3928 [65792/118836 (55%)] Loss: 12225.606445\n",
      "Train Epoch: 3928 [98560/118836 (83%)] Loss: 12243.491211\n",
      "    epoch          : 3928\n",
      "    loss           : 12186.62715118383\n",
      "    val_loss       : 12188.76418268999\n",
      "    val_log_likelihood: -12120.381478268455\n",
      "    val_log_marginal: -12129.228688548135\n",
      "Train Epoch: 3929 [256/118836 (0%)] Loss: 12262.616211\n",
      "Train Epoch: 3929 [33024/118836 (28%)] Loss: 12151.898438\n",
      "Train Epoch: 3929 [65792/118836 (55%)] Loss: 12145.742188\n",
      "Train Epoch: 3929 [98560/118836 (83%)] Loss: 12187.384766\n",
      "    epoch          : 3929\n",
      "    loss           : 12185.685411335557\n",
      "    val_loss       : 12184.48679032429\n",
      "    val_log_likelihood: -12107.202857475188\n",
      "    val_log_marginal: -12115.972187935651\n",
      "Train Epoch: 3930 [256/118836 (0%)] Loss: 12170.641602\n",
      "Train Epoch: 3930 [33024/118836 (28%)] Loss: 12131.136719\n",
      "Train Epoch: 3930 [65792/118836 (55%)] Loss: 12181.173828\n",
      "Train Epoch: 3930 [98560/118836 (83%)] Loss: 12168.177734\n",
      "    epoch          : 3930\n",
      "    loss           : 12188.901797068858\n",
      "    val_loss       : 12187.214098644597\n",
      "    val_log_likelihood: -12104.859819259202\n",
      "    val_log_marginal: -12113.635186030948\n",
      "Train Epoch: 3931 [256/118836 (0%)] Loss: 12145.438477\n",
      "Train Epoch: 3931 [33024/118836 (28%)] Loss: 12326.400391\n",
      "Train Epoch: 3931 [65792/118836 (55%)] Loss: 12191.468750\n",
      "Train Epoch: 3931 [98560/118836 (83%)] Loss: 12248.126953\n",
      "    epoch          : 3931\n",
      "    loss           : 12185.648937978185\n",
      "    val_loss       : 12183.381743342605\n",
      "    val_log_likelihood: -12108.267886844758\n",
      "    val_log_marginal: -12117.022760042742\n",
      "Train Epoch: 3932 [256/118836 (0%)] Loss: 12209.386719\n",
      "Train Epoch: 3932 [33024/118836 (28%)] Loss: 12174.848633\n",
      "Train Epoch: 3932 [65792/118836 (55%)] Loss: 12203.232422\n",
      "Train Epoch: 3932 [98560/118836 (83%)] Loss: 12235.904297\n",
      "    epoch          : 3932\n",
      "    loss           : 12189.446312487074\n",
      "    val_loss       : 12187.689450347456\n",
      "    val_log_likelihood: -12110.028179765044\n",
      "    val_log_marginal: -12118.681060051287\n",
      "Train Epoch: 3933 [256/118836 (0%)] Loss: 12265.271484\n",
      "Train Epoch: 3933 [33024/118836 (28%)] Loss: 12166.050781\n",
      "Train Epoch: 3933 [65792/118836 (55%)] Loss: 12192.512695\n",
      "Train Epoch: 3933 [98560/118836 (83%)] Loss: 12145.078125\n",
      "    epoch          : 3933\n",
      "    loss           : 12184.98934650279\n",
      "    val_loss       : 12187.48942925185\n",
      "    val_log_likelihood: -12107.6882074222\n",
      "    val_log_marginal: -12116.324235214777\n",
      "Train Epoch: 3934 [256/118836 (0%)] Loss: 12218.840820\n",
      "Train Epoch: 3934 [33024/118836 (28%)] Loss: 12232.505859\n",
      "Train Epoch: 3934 [65792/118836 (55%)] Loss: 12127.377930\n",
      "Train Epoch: 3934 [98560/118836 (83%)] Loss: 12237.543945\n",
      "    epoch          : 3934\n",
      "    loss           : 12189.341551482372\n",
      "    val_loss       : 12186.516123321659\n",
      "    val_log_likelihood: -12112.382928007393\n",
      "    val_log_marginal: -12121.02284852737\n",
      "Train Epoch: 3935 [256/118836 (0%)] Loss: 12221.882812\n",
      "Train Epoch: 3935 [33024/118836 (28%)] Loss: 12195.908203\n",
      "Train Epoch: 3935 [65792/118836 (55%)] Loss: 12184.039062\n",
      "Train Epoch: 3935 [98560/118836 (83%)] Loss: 12237.589844\n",
      "    epoch          : 3935\n",
      "    loss           : 12186.180381836746\n",
      "    val_loss       : 12185.795424277496\n",
      "    val_log_likelihood: -12109.71343892163\n",
      "    val_log_marginal: -12118.51698006655\n",
      "Train Epoch: 3936 [256/118836 (0%)] Loss: 12104.456055\n",
      "Train Epoch: 3936 [33024/118836 (28%)] Loss: 12177.456055\n",
      "Train Epoch: 3936 [65792/118836 (55%)] Loss: 12309.944336\n",
      "Train Epoch: 3936 [98560/118836 (83%)] Loss: 12149.943359\n",
      "    epoch          : 3936\n",
      "    loss           : 12187.567283621536\n",
      "    val_loss       : 12185.738962189014\n",
      "    val_log_likelihood: -12108.41218497984\n",
      "    val_log_marginal: -12117.298777122685\n",
      "Train Epoch: 3937 [256/118836 (0%)] Loss: 12182.542969\n",
      "Train Epoch: 3937 [33024/118836 (28%)] Loss: 12144.318359\n",
      "Train Epoch: 3937 [65792/118836 (55%)] Loss: 12170.807617\n",
      "Train Epoch: 3937 [98560/118836 (83%)] Loss: 12172.373047\n",
      "    epoch          : 3937\n",
      "    loss           : 12185.998314399812\n",
      "    val_loss       : 12187.282755616792\n",
      "    val_log_likelihood: -12109.67567898961\n",
      "    val_log_marginal: -12118.36256838704\n",
      "Train Epoch: 3938 [256/118836 (0%)] Loss: 12198.436523\n",
      "Train Epoch: 3938 [33024/118836 (28%)] Loss: 12202.604492\n",
      "Train Epoch: 3938 [65792/118836 (55%)] Loss: 12166.957031\n",
      "Train Epoch: 3938 [98560/118836 (83%)] Loss: 12348.950195\n",
      "    epoch          : 3938\n",
      "    loss           : 12190.663311459624\n",
      "    val_loss       : 12183.798953465915\n",
      "    val_log_likelihood: -12111.782208630582\n",
      "    val_log_marginal: -12120.501289330754\n",
      "Train Epoch: 3939 [256/118836 (0%)] Loss: 12197.093750\n",
      "Train Epoch: 3939 [33024/118836 (28%)] Loss: 12266.322266\n",
      "Train Epoch: 3939 [65792/118836 (55%)] Loss: 12248.915039\n",
      "Train Epoch: 3939 [98560/118836 (83%)] Loss: 12241.177734\n",
      "    epoch          : 3939\n",
      "    loss           : 12187.465441319015\n",
      "    val_loss       : 12181.850046098669\n",
      "    val_log_likelihood: -12111.876069937707\n",
      "    val_log_marginal: -12120.625242736116\n",
      "Train Epoch: 3940 [256/118836 (0%)] Loss: 12245.075195\n",
      "Train Epoch: 3940 [33024/118836 (28%)] Loss: 12135.500000\n",
      "Train Epoch: 3940 [65792/118836 (55%)] Loss: 12213.756836\n",
      "Train Epoch: 3940 [98560/118836 (83%)] Loss: 12268.853516\n",
      "    epoch          : 3940\n",
      "    loss           : 12187.649152999638\n",
      "    val_loss       : 12188.096356811902\n",
      "    val_log_likelihood: -12107.852480904932\n",
      "    val_log_marginal: -12116.468480630163\n",
      "Train Epoch: 3941 [256/118836 (0%)] Loss: 12155.345703\n",
      "Train Epoch: 3941 [33024/118836 (28%)] Loss: 12137.793945\n",
      "Train Epoch: 3941 [65792/118836 (55%)] Loss: 12232.294922\n",
      "Train Epoch: 3941 [98560/118836 (83%)] Loss: 12208.852539\n",
      "    epoch          : 3941\n",
      "    loss           : 12184.17856021247\n",
      "    val_loss       : 12184.419695998853\n",
      "    val_log_likelihood: -12111.673721179695\n",
      "    val_log_marginal: -12120.465547497648\n",
      "Train Epoch: 3942 [256/118836 (0%)] Loss: 12246.476562\n",
      "Train Epoch: 3942 [33024/118836 (28%)] Loss: 12168.864258\n",
      "Train Epoch: 3942 [65792/118836 (55%)] Loss: 12206.517578\n",
      "Train Epoch: 3942 [98560/118836 (83%)] Loss: 12191.043945\n",
      "    epoch          : 3942\n",
      "    loss           : 12186.45913251525\n",
      "    val_loss       : 12188.662497418669\n",
      "    val_log_likelihood: -12110.791963270265\n",
      "    val_log_marginal: -12119.640238890544\n",
      "Train Epoch: 3943 [256/118836 (0%)] Loss: 12220.218750\n",
      "Train Epoch: 3943 [33024/118836 (28%)] Loss: 12144.537109\n",
      "Train Epoch: 3943 [65792/118836 (55%)] Loss: 12162.017578\n",
      "Train Epoch: 3943 [98560/118836 (83%)] Loss: 12157.303711\n",
      "    epoch          : 3943\n",
      "    loss           : 12190.408912162688\n",
      "    val_loss       : 12186.943801741727\n",
      "    val_log_likelihood: -12107.2433256113\n",
      "    val_log_marginal: -12116.045707306106\n",
      "Train Epoch: 3944 [256/118836 (0%)] Loss: 12119.916992\n",
      "Train Epoch: 3944 [33024/118836 (28%)] Loss: 12211.568359\n",
      "Train Epoch: 3944 [65792/118836 (55%)] Loss: 12181.724609\n",
      "Train Epoch: 3944 [98560/118836 (83%)] Loss: 12178.795898\n",
      "    epoch          : 3944\n",
      "    loss           : 12185.101318399762\n",
      "    val_loss       : 12181.465736672215\n",
      "    val_log_likelihood: -12108.907328015148\n",
      "    val_log_marginal: -12117.555882318993\n",
      "Train Epoch: 3945 [256/118836 (0%)] Loss: 12234.417969\n",
      "Train Epoch: 3945 [33024/118836 (28%)] Loss: 12149.880859\n",
      "Train Epoch: 3945 [65792/118836 (55%)] Loss: 12168.239258\n",
      "Train Epoch: 3945 [98560/118836 (83%)] Loss: 12123.818359\n",
      "    epoch          : 3945\n",
      "    loss           : 12183.66776406767\n",
      "    val_loss       : 12185.718560974572\n",
      "    val_log_likelihood: -12108.657380033861\n",
      "    val_log_marginal: -12117.343209508705\n",
      "Train Epoch: 3946 [256/118836 (0%)] Loss: 12169.312500\n",
      "Train Epoch: 3946 [33024/118836 (28%)] Loss: 12233.408203\n",
      "Train Epoch: 3946 [65792/118836 (55%)] Loss: 12294.468750\n",
      "Train Epoch: 3946 [98560/118836 (83%)] Loss: 12246.617188\n",
      "    epoch          : 3946\n",
      "    loss           : 12186.001288028589\n",
      "    val_loss       : 12184.673009754739\n",
      "    val_log_likelihood: -12110.077863129394\n",
      "    val_log_marginal: -12118.731867995468\n",
      "Train Epoch: 3947 [256/118836 (0%)] Loss: 12238.980469\n",
      "Train Epoch: 3947 [33024/118836 (28%)] Loss: 12160.652344\n",
      "Train Epoch: 3947 [65792/118836 (55%)] Loss: 12145.419922\n",
      "Train Epoch: 3947 [98560/118836 (83%)] Loss: 12154.835938\n",
      "    epoch          : 3947\n",
      "    loss           : 12186.12179147927\n",
      "    val_loss       : 12180.381929778758\n",
      "    val_log_likelihood: -12107.06005124328\n",
      "    val_log_marginal: -12115.700262459806\n",
      "Train Epoch: 3948 [256/118836 (0%)] Loss: 12141.028320\n",
      "Train Epoch: 3948 [33024/118836 (28%)] Loss: 12208.664062\n",
      "Train Epoch: 3948 [65792/118836 (55%)] Loss: 12156.919922\n",
      "Train Epoch: 3948 [98560/118836 (83%)] Loss: 12166.871094\n",
      "    epoch          : 3948\n",
      "    loss           : 12184.176046028484\n",
      "    val_loss       : 12183.269252360336\n",
      "    val_log_likelihood: -12108.689094648213\n",
      "    val_log_marginal: -12117.346113145191\n",
      "Train Epoch: 3949 [256/118836 (0%)] Loss: 12256.228516\n",
      "Train Epoch: 3949 [33024/118836 (28%)] Loss: 12333.587891\n",
      "Train Epoch: 3949 [65792/118836 (55%)] Loss: 12248.997070\n",
      "Train Epoch: 3949 [98560/118836 (83%)] Loss: 12275.950195\n",
      "    epoch          : 3949\n",
      "    loss           : 12185.611165930004\n",
      "    val_loss       : 12186.132209669942\n",
      "    val_log_likelihood: -12108.57360583385\n",
      "    val_log_marginal: -12117.197450725647\n",
      "Train Epoch: 3950 [256/118836 (0%)] Loss: 12245.572266\n",
      "Train Epoch: 3950 [33024/118836 (28%)] Loss: 12266.953125\n",
      "Train Epoch: 3950 [65792/118836 (55%)] Loss: 12316.906250\n",
      "Train Epoch: 3950 [98560/118836 (83%)] Loss: 12169.235352\n",
      "    epoch          : 3950\n",
      "    loss           : 12181.875808390198\n",
      "    val_loss       : 12178.945119703316\n",
      "    val_log_likelihood: -12102.181576651676\n",
      "    val_log_marginal: -12110.858835531697\n",
      "Train Epoch: 3951 [256/118836 (0%)] Loss: 12178.112305\n",
      "Train Epoch: 3951 [33024/118836 (28%)] Loss: 12247.788086\n",
      "Train Epoch: 3951 [65792/118836 (55%)] Loss: 12272.626953\n",
      "Train Epoch: 3951 [98560/118836 (83%)] Loss: 12241.738281\n",
      "    epoch          : 3951\n",
      "    loss           : 12185.745329462625\n",
      "    val_loss       : 12181.743356102705\n",
      "    val_log_likelihood: -12101.038241347445\n",
      "    val_log_marginal: -12109.739421485829\n",
      "Train Epoch: 3952 [256/118836 (0%)] Loss: 12269.011719\n",
      "Train Epoch: 3952 [33024/118836 (28%)] Loss: 12307.230469\n",
      "Train Epoch: 3952 [65792/118836 (55%)] Loss: 12196.000977\n",
      "Train Epoch: 3952 [98560/118836 (83%)] Loss: 12264.046875\n",
      "    epoch          : 3952\n",
      "    loss           : 12186.049199364144\n",
      "    val_loss       : 12181.555207520581\n",
      "    val_log_likelihood: -12103.061472711177\n",
      "    val_log_marginal: -12111.753404783864\n",
      "Train Epoch: 3953 [256/118836 (0%)] Loss: 12155.797852\n",
      "Train Epoch: 3953 [33024/118836 (28%)] Loss: 12191.818359\n",
      "Train Epoch: 3953 [65792/118836 (55%)] Loss: 12223.195312\n",
      "Train Epoch: 3953 [98560/118836 (83%)] Loss: 12192.566406\n",
      "    epoch          : 3953\n",
      "    loss           : 12183.9624394192\n",
      "    val_loss       : 12184.401885891808\n",
      "    val_log_likelihood: -12106.97358951742\n",
      "    val_log_marginal: -12115.713864572768\n",
      "Train Epoch: 3954 [256/118836 (0%)] Loss: 12209.960938\n",
      "Train Epoch: 3954 [33024/118836 (28%)] Loss: 12318.124023\n",
      "Train Epoch: 3954 [65792/118836 (55%)] Loss: 12156.451172\n",
      "Train Epoch: 3954 [98560/118836 (83%)] Loss: 12244.857422\n",
      "    epoch          : 3954\n",
      "    loss           : 12186.337719060175\n",
      "    val_loss       : 12184.497640399104\n",
      "    val_log_likelihood: -12105.62529111094\n",
      "    val_log_marginal: -12114.23512388975\n",
      "Train Epoch: 3955 [256/118836 (0%)] Loss: 12180.422852\n",
      "Train Epoch: 3955 [33024/118836 (28%)] Loss: 12143.782227\n",
      "Train Epoch: 3955 [65792/118836 (55%)] Loss: 12162.050781\n",
      "Train Epoch: 3955 [98560/118836 (83%)] Loss: 12287.649414\n",
      "    epoch          : 3955\n",
      "    loss           : 12183.166699299525\n",
      "    val_loss       : 12183.704355345824\n",
      "    val_log_likelihood: -12100.915368622052\n",
      "    val_log_marginal: -12109.534363462335\n",
      "Train Epoch: 3956 [256/118836 (0%)] Loss: 12233.308594\n",
      "Train Epoch: 3956 [33024/118836 (28%)] Loss: 12146.278320\n",
      "Train Epoch: 3956 [65792/118836 (55%)] Loss: 12249.216797\n",
      "Train Epoch: 3956 [98560/118836 (83%)] Loss: 12256.191406\n",
      "    epoch          : 3956\n",
      "    loss           : 12189.09301866858\n",
      "    val_loss       : 12184.514468784892\n",
      "    val_log_likelihood: -12107.2547480808\n",
      "    val_log_marginal: -12115.90917882631\n",
      "Train Epoch: 3957 [256/118836 (0%)] Loss: 12294.636719\n",
      "Train Epoch: 3957 [33024/118836 (28%)] Loss: 12199.284180\n",
      "Train Epoch: 3957 [65792/118836 (55%)] Loss: 12170.574219\n",
      "Train Epoch: 3957 [98560/118836 (83%)] Loss: 12271.322266\n",
      "    epoch          : 3957\n",
      "    loss           : 12190.167824648468\n",
      "    val_loss       : 12187.759252208893\n",
      "    val_log_likelihood: -12102.759483237696\n",
      "    val_log_marginal: -12111.359674007572\n",
      "Train Epoch: 3958 [256/118836 (0%)] Loss: 12218.245117\n",
      "Train Epoch: 3958 [33024/118836 (28%)] Loss: 12187.586914\n",
      "Train Epoch: 3958 [65792/118836 (55%)] Loss: 12252.853516\n",
      "Train Epoch: 3958 [98560/118836 (83%)] Loss: 12164.995117\n",
      "    epoch          : 3958\n",
      "    loss           : 12185.28733586642\n",
      "    val_loss       : 12183.606909896682\n",
      "    val_log_likelihood: -12102.89064907077\n",
      "    val_log_marginal: -12111.522645258996\n",
      "Train Epoch: 3959 [256/118836 (0%)] Loss: 12350.931641\n",
      "Train Epoch: 3959 [33024/118836 (28%)] Loss: 12152.198242\n",
      "Train Epoch: 3959 [65792/118836 (55%)] Loss: 12221.945312\n",
      "Train Epoch: 3959 [98560/118836 (83%)] Loss: 12270.579102\n",
      "    epoch          : 3959\n",
      "    loss           : 12185.286774645885\n",
      "    val_loss       : 12183.245858852377\n",
      "    val_log_likelihood: -12106.298674815189\n",
      "    val_log_marginal: -12115.007104851185\n",
      "Train Epoch: 3960 [256/118836 (0%)] Loss: 12225.062500\n",
      "Train Epoch: 3960 [33024/118836 (28%)] Loss: 12299.336914\n",
      "Train Epoch: 3960 [65792/118836 (55%)] Loss: 12167.541016\n",
      "Train Epoch: 3960 [98560/118836 (83%)] Loss: 12151.703125\n",
      "    epoch          : 3960\n",
      "    loss           : 12187.030498798078\n",
      "    val_loss       : 12183.170224080175\n",
      "    val_log_likelihood: -12107.675841669252\n",
      "    val_log_marginal: -12116.359231862743\n",
      "Train Epoch: 3961 [256/118836 (0%)] Loss: 12203.893555\n",
      "Train Epoch: 3961 [33024/118836 (28%)] Loss: 12194.467773\n",
      "Train Epoch: 3961 [65792/118836 (55%)] Loss: 12158.062500\n",
      "Train Epoch: 3961 [98560/118836 (83%)] Loss: 12227.787109\n",
      "    epoch          : 3961\n",
      "    loss           : 12183.129012549112\n",
      "    val_loss       : 12180.732630644174\n",
      "    val_log_likelihood: -12105.005862444426\n",
      "    val_log_marginal: -12113.575124787543\n",
      "Train Epoch: 3962 [256/118836 (0%)] Loss: 12210.646484\n",
      "Train Epoch: 3962 [33024/118836 (28%)] Loss: 12201.428711\n",
      "Train Epoch: 3962 [65792/118836 (55%)] Loss: 12325.491211\n",
      "Train Epoch: 3962 [98560/118836 (83%)] Loss: 12256.187500\n",
      "    epoch          : 3962\n",
      "    loss           : 12185.871536232165\n",
      "    val_loss       : 12184.14670697378\n",
      "    val_log_likelihood: -12102.817046144799\n",
      "    val_log_marginal: -12111.632027916488\n",
      "Train Epoch: 3963 [256/118836 (0%)] Loss: 12249.558594\n",
      "Train Epoch: 3963 [33024/118836 (28%)] Loss: 12180.263672\n",
      "Train Epoch: 3963 [65792/118836 (55%)] Loss: 12164.216797\n",
      "Train Epoch: 3963 [98560/118836 (83%)] Loss: 12316.914062\n",
      "    epoch          : 3963\n",
      "    loss           : 12184.388757657414\n",
      "    val_loss       : 12182.081769916384\n",
      "    val_log_likelihood: -12105.79442204301\n",
      "    val_log_marginal: -12114.621852134442\n",
      "Train Epoch: 3964 [256/118836 (0%)] Loss: 12137.090820\n",
      "Train Epoch: 3964 [33024/118836 (28%)] Loss: 12171.214844\n",
      "Train Epoch: 3964 [65792/118836 (55%)] Loss: 12181.787109\n",
      "Train Epoch: 3964 [98560/118836 (83%)] Loss: 12155.607422\n",
      "    epoch          : 3964\n",
      "    loss           : 12183.20549976737\n",
      "    val_loss       : 12183.126659952013\n",
      "    val_log_likelihood: -12103.486095656277\n",
      "    val_log_marginal: -12112.169129682441\n",
      "Train Epoch: 3965 [256/118836 (0%)] Loss: 12127.649414\n",
      "Train Epoch: 3965 [33024/118836 (28%)] Loss: 12178.851562\n",
      "Train Epoch: 3965 [65792/118836 (55%)] Loss: 12106.869141\n",
      "Train Epoch: 3965 [98560/118836 (83%)] Loss: 12208.080078\n",
      "    epoch          : 3965\n",
      "    loss           : 12182.264348441377\n",
      "    val_loss       : 12184.061232120635\n",
      "    val_log_likelihood: -12104.89550797405\n",
      "    val_log_marginal: -12113.43288620835\n",
      "Train Epoch: 3966 [256/118836 (0%)] Loss: 12142.027344\n",
      "Train Epoch: 3966 [33024/118836 (28%)] Loss: 12248.020508\n",
      "Train Epoch: 3966 [65792/118836 (55%)] Loss: 12255.005859\n",
      "Train Epoch: 3966 [98560/118836 (83%)] Loss: 12172.351562\n",
      "    epoch          : 3966\n",
      "    loss           : 12183.457460646712\n",
      "    val_loss       : 12183.177311439054\n",
      "    val_log_likelihood: -12106.751182375672\n",
      "    val_log_marginal: -12115.394265564713\n",
      "Train Epoch: 3967 [256/118836 (0%)] Loss: 12216.937500\n",
      "Train Epoch: 3967 [33024/118836 (28%)] Loss: 12152.021484\n",
      "Train Epoch: 3967 [65792/118836 (55%)] Loss: 12186.676758\n",
      "Train Epoch: 3967 [98560/118836 (83%)] Loss: 12300.534180\n",
      "    epoch          : 3967\n",
      "    loss           : 12181.570024943136\n",
      "    val_loss       : 12179.217568949725\n",
      "    val_log_likelihood: -12105.857714278329\n",
      "    val_log_marginal: -12114.521818746258\n",
      "Train Epoch: 3968 [256/118836 (0%)] Loss: 12173.619141\n",
      "Train Epoch: 3968 [33024/118836 (28%)] Loss: 12164.730469\n",
      "Train Epoch: 3968 [65792/118836 (55%)] Loss: 12189.474609\n",
      "Train Epoch: 3968 [98560/118836 (83%)] Loss: 12159.528320\n",
      "    epoch          : 3968\n",
      "    loss           : 12186.526539883167\n",
      "    val_loss       : 12182.9623445489\n",
      "    val_log_likelihood: -12102.422728139216\n",
      "    val_log_marginal: -12110.984980217561\n",
      "Train Epoch: 3969 [256/118836 (0%)] Loss: 12213.550781\n",
      "Train Epoch: 3969 [33024/118836 (28%)] Loss: 12163.509766\n",
      "Train Epoch: 3969 [65792/118836 (55%)] Loss: 12246.085938\n",
      "Train Epoch: 3969 [98560/118836 (83%)] Loss: 12228.752930\n",
      "    epoch          : 3969\n",
      "    loss           : 12186.72587963322\n",
      "    val_loss       : 12182.545966512913\n",
      "    val_log_likelihood: -12102.661340564257\n",
      "    val_log_marginal: -12111.360319917916\n",
      "Train Epoch: 3970 [256/118836 (0%)] Loss: 12324.925781\n",
      "Train Epoch: 3970 [33024/118836 (28%)] Loss: 12107.704102\n",
      "Train Epoch: 3970 [65792/118836 (55%)] Loss: 12156.193359\n",
      "Train Epoch: 3970 [98560/118836 (83%)] Loss: 12224.836914\n",
      "    epoch          : 3970\n",
      "    loss           : 12181.146950604838\n",
      "    val_loss       : 12182.123341575845\n",
      "    val_log_likelihood: -12105.143571973222\n",
      "    val_log_marginal: -12113.766342158284\n",
      "Train Epoch: 3971 [256/118836 (0%)] Loss: 12264.400391\n",
      "Train Epoch: 3971 [33024/118836 (28%)] Loss: 12177.388672\n",
      "Train Epoch: 3971 [65792/118836 (55%)] Loss: 12191.607422\n",
      "Train Epoch: 3971 [98560/118836 (83%)] Loss: 12184.335938\n",
      "    epoch          : 3971\n",
      "    loss           : 12183.480290561673\n",
      "    val_loss       : 12184.5149698858\n",
      "    val_log_likelihood: -12105.990147623294\n",
      "    val_log_marginal: -12114.571709364973\n",
      "Train Epoch: 3972 [256/118836 (0%)] Loss: 12249.778320\n",
      "Train Epoch: 3972 [33024/118836 (28%)] Loss: 12213.249023\n",
      "Train Epoch: 3972 [65792/118836 (55%)] Loss: 12223.857422\n",
      "Train Epoch: 3972 [98560/118836 (83%)] Loss: 12232.740234\n",
      "    epoch          : 3972\n",
      "    loss           : 12185.11351291098\n",
      "    val_loss       : 12182.422490702404\n",
      "    val_log_likelihood: -12103.248027166048\n",
      "    val_log_marginal: -12111.859310728987\n",
      "Train Epoch: 3973 [256/118836 (0%)] Loss: 12294.034180\n",
      "Train Epoch: 3973 [33024/118836 (28%)] Loss: 12172.503906\n",
      "Train Epoch: 3973 [65792/118836 (55%)] Loss: 12167.113281\n",
      "Train Epoch: 3973 [98560/118836 (83%)] Loss: 12158.298828\n",
      "    epoch          : 3973\n",
      "    loss           : 12186.97083931064\n",
      "    val_loss       : 12182.629031321561\n",
      "    val_log_likelihood: -12106.493679403173\n",
      "    val_log_marginal: -12115.082243807476\n",
      "Train Epoch: 3974 [256/118836 (0%)] Loss: 12274.728516\n",
      "Train Epoch: 3974 [33024/118836 (28%)] Loss: 12194.278320\n",
      "Train Epoch: 3974 [65792/118836 (55%)] Loss: 12186.630859\n",
      "Train Epoch: 3974 [98560/118836 (83%)] Loss: 12230.185547\n",
      "    epoch          : 3974\n",
      "    loss           : 12185.152745037221\n",
      "    val_loss       : 12186.431376805554\n",
      "    val_log_likelihood: -12103.512855730458\n",
      "    val_log_marginal: -12112.188534752811\n",
      "Train Epoch: 3975 [256/118836 (0%)] Loss: 12191.546875\n",
      "Train Epoch: 3975 [33024/118836 (28%)] Loss: 12172.243164\n",
      "Train Epoch: 3975 [65792/118836 (55%)] Loss: 12161.423828\n",
      "Train Epoch: 3975 [98560/118836 (83%)] Loss: 12133.153320\n",
      "    epoch          : 3975\n",
      "    loss           : 12182.530073440084\n",
      "    val_loss       : 12184.784091507327\n",
      "    val_log_likelihood: -12106.340702381876\n",
      "    val_log_marginal: -12114.970368359156\n",
      "Train Epoch: 3976 [256/118836 (0%)] Loss: 12184.544922\n",
      "Train Epoch: 3976 [33024/118836 (28%)] Loss: 12169.360352\n",
      "Train Epoch: 3976 [65792/118836 (55%)] Loss: 12228.425781\n",
      "Train Epoch: 3976 [98560/118836 (83%)] Loss: 12218.685547\n",
      "    epoch          : 3976\n",
      "    loss           : 12182.479289282206\n",
      "    val_loss       : 12181.83504439201\n",
      "    val_log_likelihood: -12106.661687086435\n",
      "    val_log_marginal: -12115.294505047877\n",
      "Train Epoch: 3977 [256/118836 (0%)] Loss: 12186.280273\n",
      "Train Epoch: 3977 [33024/118836 (28%)] Loss: 12161.672852\n",
      "Train Epoch: 3977 [65792/118836 (55%)] Loss: 12217.642578\n",
      "Train Epoch: 3977 [98560/118836 (83%)] Loss: 12355.383789\n",
      "    epoch          : 3977\n",
      "    loss           : 12185.221357074544\n",
      "    val_loss       : 12185.449521084283\n",
      "    val_log_likelihood: -12108.179679099463\n",
      "    val_log_marginal: -12116.786954855816\n",
      "Train Epoch: 3978 [256/118836 (0%)] Loss: 12195.638672\n",
      "Train Epoch: 3978 [33024/118836 (28%)] Loss: 12173.837891\n",
      "Train Epoch: 3978 [65792/118836 (55%)] Loss: 12348.669922\n",
      "Train Epoch: 3978 [98560/118836 (83%)] Loss: 12179.726562\n",
      "    epoch          : 3978\n",
      "    loss           : 12184.92123526675\n",
      "    val_loss       : 12180.002090335707\n",
      "    val_log_likelihood: -12103.553951968312\n",
      "    val_log_marginal: -12112.170405460018\n",
      "Train Epoch: 3979 [256/118836 (0%)] Loss: 12218.176758\n",
      "Train Epoch: 3979 [33024/118836 (28%)] Loss: 12255.068359\n",
      "Train Epoch: 3979 [65792/118836 (55%)] Loss: 12230.110352\n",
      "Train Epoch: 3979 [98560/118836 (83%)] Loss: 12208.684570\n",
      "    epoch          : 3979\n",
      "    loss           : 12178.869216391387\n",
      "    val_loss       : 12182.355818488573\n",
      "    val_log_likelihood: -12101.099254936931\n",
      "    val_log_marginal: -12109.740386811924\n",
      "Train Epoch: 3980 [256/118836 (0%)] Loss: 12270.998047\n",
      "Train Epoch: 3980 [33024/118836 (28%)] Loss: 12212.399414\n",
      "Train Epoch: 3980 [65792/118836 (55%)] Loss: 12223.188477\n",
      "Train Epoch: 3980 [98560/118836 (83%)] Loss: 12171.029297\n",
      "    epoch          : 3980\n",
      "    loss           : 12182.545928970223\n",
      "    val_loss       : 12183.601795622679\n",
      "    val_log_likelihood: -12106.633301185122\n",
      "    val_log_marginal: -12115.23997765487\n",
      "Train Epoch: 3981 [256/118836 (0%)] Loss: 12178.234375\n",
      "Train Epoch: 3981 [33024/118836 (28%)] Loss: 12226.261719\n",
      "Train Epoch: 3981 [65792/118836 (55%)] Loss: 12245.003906\n",
      "Train Epoch: 3981 [98560/118836 (83%)] Loss: 12316.868164\n",
      "    epoch          : 3981\n",
      "    loss           : 12185.038264287376\n",
      "    val_loss       : 12186.92450991744\n",
      "    val_log_likelihood: -12103.073249295647\n",
      "    val_log_marginal: -12111.779497391331\n",
      "Train Epoch: 3982 [256/118836 (0%)] Loss: 12349.863281\n",
      "Train Epoch: 3982 [33024/118836 (28%)] Loss: 12115.901367\n",
      "Train Epoch: 3982 [65792/118836 (55%)] Loss: 12299.640625\n",
      "Train Epoch: 3982 [98560/118836 (83%)] Loss: 12194.754883\n",
      "    epoch          : 3982\n",
      "    loss           : 12184.786237173024\n",
      "    val_loss       : 12185.012983302224\n",
      "    val_log_likelihood: -12103.255316086384\n",
      "    val_log_marginal: -12111.946623720818\n",
      "Train Epoch: 3983 [256/118836 (0%)] Loss: 12241.261719\n",
      "Train Epoch: 3983 [33024/118836 (28%)] Loss: 12162.552734\n",
      "Train Epoch: 3983 [65792/118836 (55%)] Loss: 12185.928711\n",
      "Train Epoch: 3983 [98560/118836 (83%)] Loss: 12206.576172\n",
      "    epoch          : 3983\n",
      "    loss           : 12185.156732869365\n",
      "    val_loss       : 12182.656092690022\n",
      "    val_log_likelihood: -12104.842250342483\n",
      "    val_log_marginal: -12113.715227092522\n",
      "Train Epoch: 3984 [256/118836 (0%)] Loss: 12231.620117\n",
      "Train Epoch: 3984 [33024/118836 (28%)] Loss: 12333.164062\n",
      "Train Epoch: 3984 [65792/118836 (55%)] Loss: 12202.866211\n",
      "Train Epoch: 3984 [98560/118836 (83%)] Loss: 12167.773438\n",
      "    epoch          : 3984\n",
      "    loss           : 12184.246669025279\n",
      "    val_loss       : 12183.985363685868\n",
      "    val_log_likelihood: -12103.257932046112\n",
      "    val_log_marginal: -12112.077219630695\n",
      "Train Epoch: 3985 [256/118836 (0%)] Loss: 12131.395508\n",
      "Train Epoch: 3985 [33024/118836 (28%)] Loss: 12109.737305\n",
      "Train Epoch: 3985 [65792/118836 (55%)] Loss: 12107.534180\n",
      "Train Epoch: 3985 [98560/118836 (83%)] Loss: 12199.582031\n",
      "    epoch          : 3985\n",
      "    loss           : 12182.361059953992\n",
      "    val_loss       : 12187.117798525143\n",
      "    val_log_likelihood: -12103.09939936156\n",
      "    val_log_marginal: -12111.849693110911\n",
      "Train Epoch: 3986 [256/118836 (0%)] Loss: 12268.197266\n",
      "Train Epoch: 3986 [33024/118836 (28%)] Loss: 12223.733398\n",
      "Train Epoch: 3986 [65792/118836 (55%)] Loss: 12172.537109\n",
      "Train Epoch: 3986 [98560/118836 (83%)] Loss: 12173.677734\n",
      "    epoch          : 3986\n",
      "    loss           : 12182.300614854736\n",
      "    val_loss       : 12186.701314802987\n",
      "    val_log_likelihood: -12104.95619071159\n",
      "    val_log_marginal: -12113.674361840402\n",
      "Train Epoch: 3987 [256/118836 (0%)] Loss: 12109.922852\n",
      "Train Epoch: 3987 [33024/118836 (28%)] Loss: 12297.011719\n",
      "Train Epoch: 3987 [65792/118836 (55%)] Loss: 12189.836914\n",
      "Train Epoch: 3987 [98560/118836 (83%)] Loss: 12192.701172\n",
      "    epoch          : 3987\n",
      "    loss           : 12184.265114182692\n",
      "    val_loss       : 12183.326612663177\n",
      "    val_log_likelihood: -12104.848674653638\n",
      "    val_log_marginal: -12113.455491293511\n",
      "Train Epoch: 3988 [256/118836 (0%)] Loss: 12104.626953\n",
      "Train Epoch: 3988 [33024/118836 (28%)] Loss: 12221.531250\n",
      "Train Epoch: 3988 [65792/118836 (55%)] Loss: 12232.541992\n",
      "Train Epoch: 3988 [98560/118836 (83%)] Loss: 12206.665039\n",
      "    epoch          : 3988\n",
      "    loss           : 12185.501407090054\n",
      "    val_loss       : 12187.543921879604\n",
      "    val_log_likelihood: -12110.74173209393\n",
      "    val_log_marginal: -12119.565793637066\n",
      "Train Epoch: 3989 [256/118836 (0%)] Loss: 12185.674805\n",
      "Train Epoch: 3989 [33024/118836 (28%)] Loss: 12214.451172\n",
      "Train Epoch: 3989 [65792/118836 (55%)] Loss: 12177.359375\n",
      "Train Epoch: 3989 [98560/118836 (83%)] Loss: 12311.973633\n",
      "    epoch          : 3989\n",
      "    loss           : 12184.669507825425\n",
      "    val_loss       : 12185.897304277221\n",
      "    val_log_likelihood: -12104.393123029104\n",
      "    val_log_marginal: -12113.015243433769\n",
      "Train Epoch: 3990 [256/118836 (0%)] Loss: 12202.308594\n",
      "Train Epoch: 3990 [33024/118836 (28%)] Loss: 12295.570312\n",
      "Train Epoch: 3990 [65792/118836 (55%)] Loss: 12181.719727\n",
      "Train Epoch: 3990 [98560/118836 (83%)] Loss: 12206.759766\n",
      "    epoch          : 3990\n",
      "    loss           : 12184.468682311053\n",
      "    val_loss       : 12186.572093574021\n",
      "    val_log_likelihood: -12106.343321895678\n",
      "    val_log_marginal: -12115.024937738393\n",
      "Train Epoch: 3991 [256/118836 (0%)] Loss: 12201.721680\n",
      "Train Epoch: 3991 [33024/118836 (28%)] Loss: 12140.979492\n",
      "Train Epoch: 3991 [65792/118836 (55%)] Loss: 12217.081055\n",
      "Train Epoch: 3991 [98560/118836 (83%)] Loss: 12143.188477\n",
      "    epoch          : 3991\n",
      "    loss           : 12183.53457580516\n",
      "    val_loss       : 12186.505273649866\n",
      "    val_log_likelihood: -12103.001859426695\n",
      "    val_log_marginal: -12111.654171349424\n",
      "Train Epoch: 3992 [256/118836 (0%)] Loss: 12176.207031\n",
      "Train Epoch: 3992 [33024/118836 (28%)] Loss: 12175.768555\n",
      "Train Epoch: 3992 [65792/118836 (55%)] Loss: 12257.837891\n",
      "Train Epoch: 3992 [98560/118836 (83%)] Loss: 12154.257812\n",
      "    epoch          : 3992\n",
      "    loss           : 12184.49137814051\n",
      "    val_loss       : 12184.675920892701\n",
      "    val_log_likelihood: -12105.312205658085\n",
      "    val_log_marginal: -12114.110454403728\n",
      "Train Epoch: 3993 [256/118836 (0%)] Loss: 12171.655273\n",
      "Train Epoch: 3993 [33024/118836 (28%)] Loss: 12231.975586\n",
      "Train Epoch: 3993 [65792/118836 (55%)] Loss: 12265.354492\n",
      "Train Epoch: 3993 [98560/118836 (83%)] Loss: 12326.441406\n",
      "    epoch          : 3993\n",
      "    loss           : 12185.487379161497\n",
      "    val_loss       : 12185.797841410102\n",
      "    val_log_likelihood: -12105.264286729736\n",
      "    val_log_marginal: -12114.061629674985\n",
      "Train Epoch: 3994 [256/118836 (0%)] Loss: 12177.309570\n",
      "Train Epoch: 3994 [33024/118836 (28%)] Loss: 12367.572266\n",
      "Train Epoch: 3994 [65792/118836 (55%)] Loss: 12301.489258\n",
      "Train Epoch: 3994 [98560/118836 (83%)] Loss: 12259.595703\n",
      "    epoch          : 3994\n",
      "    loss           : 12185.985122001654\n",
      "    val_loss       : 12188.320332906289\n",
      "    val_log_likelihood: -12103.79300396764\n",
      "    val_log_marginal: -12112.550501998594\n",
      "Train Epoch: 3995 [256/118836 (0%)] Loss: 12257.244141\n",
      "Train Epoch: 3995 [33024/118836 (28%)] Loss: 12209.311523\n",
      "Train Epoch: 3995 [65792/118836 (55%)] Loss: 12181.562500\n",
      "Train Epoch: 3995 [98560/118836 (83%)] Loss: 12212.083984\n",
      "    epoch          : 3995\n",
      "    loss           : 12181.935826677523\n",
      "    val_loss       : 12182.837228877628\n",
      "    val_log_likelihood: -12106.568718174887\n",
      "    val_log_marginal: -12115.209793630862\n",
      "Train Epoch: 3996 [256/118836 (0%)] Loss: 12241.474609\n",
      "Train Epoch: 3996 [33024/118836 (28%)] Loss: 12213.343750\n",
      "Train Epoch: 3996 [65792/118836 (55%)] Loss: 12189.512695\n",
      "Train Epoch: 3996 [98560/118836 (83%)] Loss: 12160.161133\n",
      "    epoch          : 3996\n",
      "    loss           : 12182.474565756824\n",
      "    val_loss       : 12184.267545467545\n",
      "    val_log_likelihood: -12105.207509111353\n",
      "    val_log_marginal: -12113.839923489153\n",
      "Train Epoch: 3997 [256/118836 (0%)] Loss: 12210.594727\n",
      "Train Epoch: 3997 [33024/118836 (28%)] Loss: 12122.538086\n",
      "Train Epoch: 3997 [65792/118836 (55%)] Loss: 12221.273438\n",
      "Train Epoch: 3997 [98560/118836 (83%)] Loss: 12144.538086\n",
      "    epoch          : 3997\n",
      "    loss           : 12185.503374915994\n",
      "    val_loss       : 12182.311566235576\n",
      "    val_log_likelihood: -12107.191704953731\n",
      "    val_log_marginal: -12115.904462880493\n",
      "Train Epoch: 3998 [256/118836 (0%)] Loss: 12206.703125\n",
      "Train Epoch: 3998 [33024/118836 (28%)] Loss: 12240.534180\n",
      "Train Epoch: 3998 [65792/118836 (55%)] Loss: 12156.877930\n",
      "Train Epoch: 3998 [98560/118836 (83%)] Loss: 12219.330078\n",
      "    epoch          : 3998\n",
      "    loss           : 12186.406589090931\n",
      "    val_loss       : 12183.662637268111\n",
      "    val_log_likelihood: -12103.719953215466\n",
      "    val_log_marginal: -12112.371117032397\n",
      "Train Epoch: 3999 [256/118836 (0%)] Loss: 12160.630859\n",
      "Train Epoch: 3999 [33024/118836 (28%)] Loss: 12202.523438\n",
      "Train Epoch: 3999 [65792/118836 (55%)] Loss: 12247.790039\n",
      "Train Epoch: 3999 [98560/118836 (83%)] Loss: 12181.609375\n",
      "    epoch          : 3999\n",
      "    loss           : 12184.390046332195\n",
      "    val_loss       : 12182.53143055552\n",
      "    val_log_likelihood: -12102.271553194789\n",
      "    val_log_marginal: -12110.963267233601\n",
      "Train Epoch: 4000 [256/118836 (0%)] Loss: 12092.193359\n",
      "Train Epoch: 4000 [33024/118836 (28%)] Loss: 12191.962891\n",
      "Train Epoch: 4000 [65792/118836 (55%)] Loss: 12199.947266\n",
      "Train Epoch: 4000 [98560/118836 (83%)] Loss: 12160.021484\n",
      "    epoch          : 4000\n",
      "    loss           : 12184.805371012975\n",
      "    val_loss       : 12184.479784865085\n",
      "    val_log_likelihood: -12105.273324900485\n",
      "    val_log_marginal: -12113.879628877725\n",
      "Saving checkpoint: saved/models/SelfiesAutoencodingOperad/0905_154251/checkpoint-epoch4000.pth ...\n",
      "Train Epoch: 4001 [256/118836 (0%)] Loss: 12239.962891\n",
      "Train Epoch: 4001 [33024/118836 (28%)] Loss: 12190.474609\n",
      "Train Epoch: 4001 [65792/118836 (55%)] Loss: 12264.416016\n",
      "Train Epoch: 4001 [98560/118836 (83%)] Loss: 12203.761719\n",
      "    epoch          : 4001\n",
      "    loss           : 12183.615509815705\n",
      "    val_loss       : 12192.214454765886\n",
      "    val_log_likelihood: -12102.444055488782\n",
      "    val_log_marginal: -12111.264643039452\n",
      "Train Epoch: 4002 [256/118836 (0%)] Loss: 12179.946289\n",
      "Train Epoch: 4002 [33024/118836 (28%)] Loss: 12264.522461\n",
      "Train Epoch: 4002 [65792/118836 (55%)] Loss: 12159.058594\n",
      "Train Epoch: 4002 [98560/118836 (83%)] Loss: 12173.210938\n",
      "    epoch          : 4002\n",
      "    loss           : 12187.625240384616\n",
      "    val_loss       : 12186.854589994527\n",
      "    val_log_likelihood: -12105.186689186568\n",
      "    val_log_marginal: -12114.035383239932\n",
      "Train Epoch: 4003 [256/118836 (0%)] Loss: 12182.606445\n",
      "Train Epoch: 4003 [33024/118836 (28%)] Loss: 12217.424805\n",
      "Train Epoch: 4003 [65792/118836 (55%)] Loss: 12239.326172\n",
      "Train Epoch: 4003 [98560/118836 (83%)] Loss: 12157.492188\n",
      "    epoch          : 4003\n",
      "    loss           : 12180.969657419613\n",
      "    val_loss       : 12188.013387246732\n",
      "    val_log_likelihood: -12103.825472207145\n",
      "    val_log_marginal: -12112.628069092489\n",
      "Train Epoch: 4004 [256/118836 (0%)] Loss: 12197.197266\n",
      "Train Epoch: 4004 [33024/118836 (28%)] Loss: 12171.118164\n",
      "Train Epoch: 4004 [65792/118836 (55%)] Loss: 12131.734375\n",
      "Train Epoch: 4004 [98560/118836 (83%)] Loss: 12270.515625\n",
      "    epoch          : 4004\n",
      "    loss           : 12180.122042849203\n",
      "    val_loss       : 12179.819318831062\n",
      "    val_log_likelihood: -12106.119529149866\n",
      "    val_log_marginal: -12114.831765837758\n",
      "Train Epoch: 4005 [256/118836 (0%)] Loss: 12153.038086\n",
      "Train Epoch: 4005 [33024/118836 (28%)] Loss: 12194.276367\n",
      "Train Epoch: 4005 [65792/118836 (55%)] Loss: 12243.641602\n",
      "Train Epoch: 4005 [98560/118836 (83%)] Loss: 12169.037109\n",
      "    epoch          : 4005\n",
      "    loss           : 12184.305698633943\n",
      "    val_loss       : 12186.226179934687\n",
      "    val_log_likelihood: -12103.869576160565\n",
      "    val_log_marginal: -12112.575465978585\n",
      "Train Epoch: 4006 [256/118836 (0%)] Loss: 12212.974609\n",
      "Train Epoch: 4006 [33024/118836 (28%)] Loss: 12233.026367\n",
      "Train Epoch: 4006 [65792/118836 (55%)] Loss: 12186.872070\n",
      "Train Epoch: 4006 [98560/118836 (83%)] Loss: 12285.908203\n",
      "    epoch          : 4006\n",
      "    loss           : 12188.645400221\n",
      "    val_loss       : 12181.070128925021\n",
      "    val_log_likelihood: -12104.377557155967\n",
      "    val_log_marginal: -12113.041385273506\n",
      "Train Epoch: 4007 [256/118836 (0%)] Loss: 12123.703125\n",
      "Train Epoch: 4007 [33024/118836 (28%)] Loss: 12276.928711\n",
      "Train Epoch: 4007 [65792/118836 (55%)] Loss: 12218.969727\n",
      "Train Epoch: 4007 [98560/118836 (83%)] Loss: 12155.028320\n",
      "    epoch          : 4007\n",
      "    loss           : 12181.528663603702\n",
      "    val_loss       : 12182.940143802934\n",
      "    val_log_likelihood: -12104.461456879395\n",
      "    val_log_marginal: -12113.109688687338\n",
      "Train Epoch: 4008 [256/118836 (0%)] Loss: 12193.731445\n",
      "Train Epoch: 4008 [33024/118836 (28%)] Loss: 12208.695312\n",
      "Train Epoch: 4008 [65792/118836 (55%)] Loss: 12291.176758\n",
      "Train Epoch: 4008 [98560/118836 (83%)] Loss: 12255.414062\n",
      "    epoch          : 4008\n",
      "    loss           : 12183.57761192101\n",
      "    val_loss       : 12182.48930951226\n",
      "    val_log_likelihood: -12108.340217089279\n",
      "    val_log_marginal: -12117.069559665235\n",
      "Train Epoch: 4009 [256/118836 (0%)] Loss: 12154.501953\n",
      "Train Epoch: 4009 [33024/118836 (28%)] Loss: 12180.071289\n",
      "Train Epoch: 4009 [65792/118836 (55%)] Loss: 12093.486328\n",
      "Train Epoch: 4009 [98560/118836 (83%)] Loss: 12246.142578\n",
      "    epoch          : 4009\n",
      "    loss           : 12185.876929377326\n",
      "    val_loss       : 12184.614760389793\n",
      "    val_log_likelihood: -12107.46115591398\n",
      "    val_log_marginal: -12116.16479280849\n",
      "Train Epoch: 4010 [256/118836 (0%)] Loss: 12303.906250\n",
      "Train Epoch: 4010 [33024/118836 (28%)] Loss: 12160.029297\n",
      "Train Epoch: 4010 [65792/118836 (55%)] Loss: 12191.082031\n",
      "Train Epoch: 4010 [98560/118836 (83%)] Loss: 12133.373047\n",
      "    epoch          : 4010\n",
      "    loss           : 12187.971562241522\n",
      "    val_loss       : 12179.805189523038\n",
      "    val_log_likelihood: -12102.548666091554\n",
      "    val_log_marginal: -12111.185307249147\n",
      "Train Epoch: 4011 [256/118836 (0%)] Loss: 12199.906250\n",
      "Train Epoch: 4011 [33024/118836 (28%)] Loss: 12179.610352\n",
      "Train Epoch: 4011 [65792/118836 (55%)] Loss: 12206.773438\n",
      "Train Epoch: 4011 [98560/118836 (83%)] Loss: 12158.482422\n",
      "    epoch          : 4011\n",
      "    loss           : 12182.737000491108\n",
      "    val_loss       : 12185.668455999506\n",
      "    val_log_likelihood: -12106.38633749483\n",
      "    val_log_marginal: -12115.157559022706\n",
      "Train Epoch: 4012 [256/118836 (0%)] Loss: 12166.330078\n",
      "Train Epoch: 4012 [33024/118836 (28%)] Loss: 12237.291016\n",
      "Train Epoch: 4012 [65792/118836 (55%)] Loss: 12123.021484\n",
      "Train Epoch: 4012 [98560/118836 (83%)] Loss: 12280.722656\n",
      "    epoch          : 4012\n",
      "    loss           : 12184.779692346465\n",
      "    val_loss       : 12185.61584037817\n",
      "    val_log_likelihood: -12104.48150185458\n",
      "    val_log_marginal: -12113.21088788811\n",
      "Train Epoch: 4013 [256/118836 (0%)] Loss: 12286.464844\n",
      "Train Epoch: 4013 [33024/118836 (28%)] Loss: 12175.052734\n",
      "Train Epoch: 4013 [65792/118836 (55%)] Loss: 12122.375000\n",
      "Train Epoch: 4013 [98560/118836 (83%)] Loss: 12234.770508\n",
      "    epoch          : 4013\n",
      "    loss           : 12186.93367985551\n",
      "    val_loss       : 12183.193629820367\n",
      "    val_log_likelihood: -12103.74173758659\n",
      "    val_log_marginal: -12112.35199018841\n",
      "Train Epoch: 4014 [256/118836 (0%)] Loss: 12219.416016\n",
      "Train Epoch: 4014 [33024/118836 (28%)] Loss: 12201.822266\n",
      "Train Epoch: 4014 [65792/118836 (55%)] Loss: 12216.280273\n",
      "Train Epoch: 4014 [98560/118836 (83%)] Loss: 12346.754883\n",
      "    epoch          : 4014\n",
      "    loss           : 12181.773677561518\n",
      "    val_loss       : 12183.839859839309\n",
      "    val_log_likelihood: -12102.64771973868\n",
      "    val_log_marginal: -12111.326392088808\n",
      "Train Epoch: 4015 [256/118836 (0%)] Loss: 12199.160156\n",
      "Train Epoch: 4015 [33024/118836 (28%)] Loss: 12334.476562\n",
      "Train Epoch: 4015 [65792/118836 (55%)] Loss: 12179.403320\n",
      "Train Epoch: 4015 [98560/118836 (83%)] Loss: 12149.280273\n",
      "    epoch          : 4015\n",
      "    loss           : 12183.621470158705\n",
      "    val_loss       : 12181.824487160151\n",
      "    val_log_likelihood: -12102.875859762717\n",
      "    val_log_marginal: -12111.59639500672\n",
      "Train Epoch: 4016 [256/118836 (0%)] Loss: 12227.835938\n",
      "Train Epoch: 4016 [33024/118836 (28%)] Loss: 12246.374023\n",
      "Train Epoch: 4016 [65792/118836 (55%)] Loss: 12201.285156\n",
      "Train Epoch: 4016 [98560/118836 (83%)] Loss: 12233.810547\n",
      "    epoch          : 4016\n",
      "    loss           : 12183.672561582402\n",
      "    val_loss       : 12182.21827324487\n",
      "    val_log_likelihood: -12103.04820163875\n",
      "    val_log_marginal: -12111.69259265\n",
      "Train Epoch: 4017 [256/118836 (0%)] Loss: 12236.136719\n",
      "Train Epoch: 4017 [33024/118836 (28%)] Loss: 12168.491211\n",
      "Train Epoch: 4017 [65792/118836 (55%)] Loss: 12128.015625\n",
      "Train Epoch: 4017 [98560/118836 (83%)] Loss: 12336.630859\n",
      "    epoch          : 4017\n",
      "    loss           : 12183.222115546165\n",
      "    val_loss       : 12183.23678221485\n",
      "    val_log_likelihood: -12103.869657419615\n",
      "    val_log_marginal: -12112.486837729237\n",
      "Train Epoch: 4018 [256/118836 (0%)] Loss: 12332.948242\n",
      "Train Epoch: 4018 [33024/118836 (28%)] Loss: 12262.982422\n",
      "Train Epoch: 4018 [65792/118836 (55%)] Loss: 12212.893555\n",
      "Train Epoch: 4018 [98560/118836 (83%)] Loss: 12293.296875\n",
      "    epoch          : 4018\n",
      "    loss           : 12187.427293185225\n",
      "    val_loss       : 12185.04600996733\n",
      "    val_log_likelihood: -12104.555344034326\n",
      "    val_log_marginal: -12113.35984168882\n",
      "Train Epoch: 4019 [256/118836 (0%)] Loss: 12210.410156\n",
      "Train Epoch: 4019 [33024/118836 (28%)] Loss: 12202.594727\n",
      "Train Epoch: 4019 [65792/118836 (55%)] Loss: 12208.718750\n",
      "Train Epoch: 4019 [98560/118836 (83%)] Loss: 12254.591797\n",
      "    epoch          : 4019\n",
      "    loss           : 12189.15324228443\n",
      "    val_loss       : 12185.75179805816\n",
      "    val_log_likelihood: -12102.8438979787\n",
      "    val_log_marginal: -12111.506379972192\n",
      "Train Epoch: 4020 [256/118836 (0%)] Loss: 12160.965820\n",
      "Train Epoch: 4020 [33024/118836 (28%)] Loss: 12172.623047\n",
      "Train Epoch: 4020 [65792/118836 (55%)] Loss: 12375.515625\n",
      "Train Epoch: 4020 [98560/118836 (83%)] Loss: 12191.538086\n",
      "    epoch          : 4020\n",
      "    loss           : 12186.930123681761\n",
      "    val_loss       : 12186.24378028577\n",
      "    val_log_likelihood: -12106.987244429798\n",
      "    val_log_marginal: -12115.625231285663\n",
      "Train Epoch: 4021 [256/118836 (0%)] Loss: 12148.483398\n",
      "Train Epoch: 4021 [33024/118836 (28%)] Loss: 12184.370117\n",
      "Train Epoch: 4021 [65792/118836 (55%)] Loss: 12161.182617\n",
      "Train Epoch: 4021 [98560/118836 (83%)] Loss: 12112.819336\n",
      "    epoch          : 4021\n",
      "    loss           : 12185.702250536342\n",
      "    val_loss       : 12186.656927956343\n",
      "    val_log_likelihood: -12103.626269935121\n",
      "    val_log_marginal: -12112.224923282087\n",
      "Train Epoch: 4022 [256/118836 (0%)] Loss: 12284.316406\n",
      "Train Epoch: 4022 [33024/118836 (28%)] Loss: 12115.685547\n",
      "Train Epoch: 4022 [65792/118836 (55%)] Loss: 12171.618164\n",
      "Train Epoch: 4022 [98560/118836 (83%)] Loss: 12193.988281\n",
      "    epoch          : 4022\n",
      "    loss           : 12185.871939134875\n",
      "    val_loss       : 12184.056818902749\n",
      "    val_log_likelihood: -12103.773173206162\n",
      "    val_log_marginal: -12112.503733617197\n",
      "Train Epoch: 4023 [256/118836 (0%)] Loss: 12191.597656\n",
      "Train Epoch: 4023 [33024/118836 (28%)] Loss: 12256.664062\n",
      "Train Epoch: 4023 [65792/118836 (55%)] Loss: 12249.562500\n",
      "Train Epoch: 4023 [98560/118836 (83%)] Loss: 12125.355469\n",
      "    epoch          : 4023\n",
      "    loss           : 12188.815590267008\n",
      "    val_loss       : 12184.280256434895\n",
      "    val_log_likelihood: -12105.033089071547\n",
      "    val_log_marginal: -12113.713457872018\n",
      "Train Epoch: 4024 [256/118836 (0%)] Loss: 12179.892578\n",
      "Train Epoch: 4024 [33024/118836 (28%)] Loss: 12310.693359\n",
      "Train Epoch: 4024 [65792/118836 (55%)] Loss: 12295.311523\n",
      "Train Epoch: 4024 [98560/118836 (83%)] Loss: 12183.687500\n",
      "    epoch          : 4024\n",
      "    loss           : 12182.796054978287\n",
      "    val_loss       : 12188.28447579281\n",
      "    val_log_likelihood: -12103.7358835427\n",
      "    val_log_marginal: -12112.449001729197\n",
      "Train Epoch: 4025 [256/118836 (0%)] Loss: 12220.150391\n",
      "Train Epoch: 4025 [33024/118836 (28%)] Loss: 12213.606445\n",
      "Train Epoch: 4025 [65792/118836 (55%)] Loss: 12213.573242\n",
      "Train Epoch: 4025 [98560/118836 (83%)] Loss: 12319.978516\n",
      "    epoch          : 4025\n",
      "    loss           : 12188.08204998966\n",
      "    val_loss       : 12185.125199963159\n",
      "    val_log_likelihood: -12108.107590855045\n",
      "    val_log_marginal: -12116.86621465761\n",
      "Train Epoch: 4026 [256/118836 (0%)] Loss: 12257.372070\n",
      "Train Epoch: 4026 [33024/118836 (28%)] Loss: 12197.081055\n",
      "Train Epoch: 4026 [65792/118836 (55%)] Loss: 12155.371094\n",
      "Train Epoch: 4026 [98560/118836 (83%)] Loss: 12200.092773\n",
      "    epoch          : 4026\n",
      "    loss           : 12181.93270587779\n",
      "    val_loss       : 12187.831746113818\n",
      "    val_log_likelihood: -12105.823454785721\n",
      "    val_log_marginal: -12114.580840907553\n",
      "Train Epoch: 4027 [256/118836 (0%)] Loss: 12217.376953\n",
      "Train Epoch: 4027 [33024/118836 (28%)] Loss: 12222.308594\n",
      "Train Epoch: 4027 [65792/118836 (55%)] Loss: 12240.609375\n",
      "Train Epoch: 4027 [98560/118836 (83%)] Loss: 12250.660156\n",
      "    epoch          : 4027\n",
      "    loss           : 12186.596170970326\n",
      "    val_loss       : 12184.588883808454\n",
      "    val_log_likelihood: -12103.627037291926\n",
      "    val_log_marginal: -12112.456746370379\n",
      "Train Epoch: 4028 [256/118836 (0%)] Loss: 12174.554688\n",
      "Train Epoch: 4028 [33024/118836 (28%)] Loss: 12135.956055\n",
      "Train Epoch: 4028 [65792/118836 (55%)] Loss: 12157.086914\n",
      "Train Epoch: 4028 [98560/118836 (83%)] Loss: 12166.330078\n",
      "    epoch          : 4028\n",
      "    loss           : 12192.927545362903\n",
      "    val_loss       : 12192.491972922124\n",
      "    val_log_likelihood: -12109.795263550714\n",
      "    val_log_marginal: -12118.67011590413\n",
      "Train Epoch: 4029 [256/118836 (0%)] Loss: 12264.808594\n",
      "Train Epoch: 4029 [33024/118836 (28%)] Loss: 12185.019531\n",
      "Train Epoch: 4029 [65792/118836 (55%)] Loss: 12224.152344\n",
      "Train Epoch: 4029 [98560/118836 (83%)] Loss: 12228.384766\n",
      "    epoch          : 4029\n",
      "    loss           : 12189.278497208437\n",
      "    val_loss       : 12188.130350350106\n",
      "    val_log_likelihood: -12107.359214905138\n",
      "    val_log_marginal: -12116.239817930345\n",
      "Train Epoch: 4030 [256/118836 (0%)] Loss: 12202.249023\n",
      "Train Epoch: 4030 [33024/118836 (28%)] Loss: 12233.093750\n",
      "Train Epoch: 4030 [65792/118836 (55%)] Loss: 12182.438477\n",
      "Train Epoch: 4030 [98560/118836 (83%)] Loss: 12219.344727\n",
      "    epoch          : 4030\n",
      "    loss           : 12182.673450908549\n",
      "    val_loss       : 12184.213407461679\n",
      "    val_log_likelihood: -12104.935069659843\n",
      "    val_log_marginal: -12113.649709840696\n",
      "Train Epoch: 4031 [256/118836 (0%)] Loss: 12258.520508\n",
      "Train Epoch: 4031 [33024/118836 (28%)] Loss: 12268.608398\n",
      "Train Epoch: 4031 [65792/118836 (55%)] Loss: 12161.627930\n",
      "Train Epoch: 4031 [98560/118836 (83%)] Loss: 12189.775391\n",
      "    epoch          : 4031\n",
      "    loss           : 12186.480925448459\n",
      "    val_loss       : 12183.002887484\n",
      "    val_log_likelihood: -12101.354560199545\n",
      "    val_log_marginal: -12110.051626467553\n",
      "Train Epoch: 4032 [256/118836 (0%)] Loss: 12166.822266\n",
      "Train Epoch: 4032 [33024/118836 (28%)] Loss: 12136.968750\n",
      "Train Epoch: 4032 [65792/118836 (55%)] Loss: 12208.003906\n",
      "Train Epoch: 4032 [98560/118836 (83%)] Loss: 12186.917969\n",
      "    epoch          : 4032\n",
      "    loss           : 12184.103016923853\n",
      "    val_loss       : 12186.073789510017\n",
      "    val_log_likelihood: -12104.296761592743\n",
      "    val_log_marginal: -12113.144272082329\n",
      "Train Epoch: 4033 [256/118836 (0%)] Loss: 12242.980469\n",
      "Train Epoch: 4033 [33024/118836 (28%)] Loss: 12211.817383\n",
      "Train Epoch: 4033 [65792/118836 (55%)] Loss: 12195.519531\n",
      "Train Epoch: 4033 [98560/118836 (83%)] Loss: 12145.655273\n",
      "    epoch          : 4033\n",
      "    loss           : 12191.037168017214\n",
      "    val_loss       : 12189.589987914533\n",
      "    val_log_likelihood: -12104.794526726635\n",
      "    val_log_marginal: -12113.695816384079\n",
      "Train Epoch: 4034 [256/118836 (0%)] Loss: 12148.671875\n",
      "Train Epoch: 4034 [33024/118836 (28%)] Loss: 12178.636719\n",
      "Train Epoch: 4034 [65792/118836 (55%)] Loss: 12212.709961\n",
      "Train Epoch: 4034 [98560/118836 (83%)] Loss: 12318.814453\n",
      "    epoch          : 4034\n",
      "    loss           : 12184.192596864661\n",
      "    val_loss       : 12185.250992464275\n",
      "    val_log_likelihood: -12105.261907600547\n",
      "    val_log_marginal: -12114.096802860902\n",
      "Train Epoch: 4035 [256/118836 (0%)] Loss: 12233.088867\n",
      "Train Epoch: 4035 [33024/118836 (28%)] Loss: 12147.601562\n",
      "Train Epoch: 4035 [65792/118836 (55%)] Loss: 12149.574219\n",
      "Train Epoch: 4035 [98560/118836 (83%)] Loss: 12146.075195\n",
      "    epoch          : 4035\n",
      "    loss           : 12186.68394124147\n",
      "    val_loss       : 12185.930985437197\n",
      "    val_log_likelihood: -12105.812260746226\n",
      "    val_log_marginal: -12114.671521310162\n",
      "Train Epoch: 4036 [256/118836 (0%)] Loss: 12141.182617\n",
      "Train Epoch: 4036 [33024/118836 (28%)] Loss: 12117.658203\n",
      "Train Epoch: 4036 [65792/118836 (55%)] Loss: 12230.603516\n",
      "Train Epoch: 4036 [98560/118836 (83%)] Loss: 12275.268555\n",
      "    epoch          : 4036\n",
      "    loss           : 12185.48766978779\n",
      "    val_loss       : 12185.87174134461\n",
      "    val_log_likelihood: -12107.365634854476\n",
      "    val_log_marginal: -12116.093822265486\n",
      "Train Epoch: 4037 [256/118836 (0%)] Loss: 12243.046875\n",
      "Train Epoch: 4037 [33024/118836 (28%)] Loss: 12248.390625\n",
      "Train Epoch: 4037 [65792/118836 (55%)] Loss: 12213.792969\n",
      "Train Epoch: 4037 [98560/118836 (83%)] Loss: 12228.936523\n",
      "    epoch          : 4037\n",
      "    loss           : 12187.15398993228\n",
      "    val_loss       : 12189.218998681177\n",
      "    val_log_likelihood: -12103.645493596205\n",
      "    val_log_marginal: -12112.60203856434\n",
      "Train Epoch: 4038 [256/118836 (0%)] Loss: 12197.429688\n",
      "Train Epoch: 4038 [33024/118836 (28%)] Loss: 12197.074219\n",
      "Train Epoch: 4038 [65792/118836 (55%)] Loss: 12341.562500\n",
      "Train Epoch: 4038 [98560/118836 (83%)] Loss: 12134.250000\n",
      "    epoch          : 4038\n",
      "    loss           : 12182.019740940344\n",
      "    val_loss       : 12182.787896996411\n",
      "    val_log_likelihood: -12100.292905261322\n",
      "    val_log_marginal: -12109.015268955336\n",
      "Train Epoch: 4039 [256/118836 (0%)] Loss: 12148.808594\n",
      "Train Epoch: 4039 [33024/118836 (28%)] Loss: 12084.185547\n",
      "Train Epoch: 4039 [65792/118836 (55%)] Loss: 12244.413086\n",
      "Train Epoch: 4039 [98560/118836 (83%)] Loss: 12250.017578\n",
      "    epoch          : 4039\n",
      "    loss           : 12181.429079753412\n",
      "    val_loss       : 12187.09704546761\n",
      "    val_log_likelihood: -12104.999920356442\n",
      "    val_log_marginal: -12113.742988316382\n",
      "Train Epoch: 4040 [256/118836 (0%)] Loss: 12193.277344\n",
      "Train Epoch: 4040 [33024/118836 (28%)] Loss: 12153.787109\n",
      "Train Epoch: 4040 [65792/118836 (55%)] Loss: 12181.143555\n",
      "Train Epoch: 4040 [98560/118836 (83%)] Loss: 12138.291992\n",
      "    epoch          : 4040\n",
      "    loss           : 12184.089101271711\n",
      "    val_loss       : 12183.675988189736\n",
      "    val_log_likelihood: -12103.713739402398\n",
      "    val_log_marginal: -12112.498959936831\n",
      "Train Epoch: 4041 [256/118836 (0%)] Loss: 12153.051758\n",
      "Train Epoch: 4041 [33024/118836 (28%)] Loss: 12170.453125\n",
      "Train Epoch: 4041 [65792/118836 (55%)] Loss: 12356.887695\n",
      "Train Epoch: 4041 [98560/118836 (83%)] Loss: 12141.851562\n",
      "    epoch          : 4041\n",
      "    loss           : 12187.62334331705\n",
      "    val_loss       : 12187.14259562928\n",
      "    val_log_likelihood: -12105.102190278638\n",
      "    val_log_marginal: -12113.704437867158\n",
      "Train Epoch: 4042 [256/118836 (0%)] Loss: 12163.167969\n",
      "Train Epoch: 4042 [33024/118836 (28%)] Loss: 12139.183594\n",
      "Train Epoch: 4042 [65792/118836 (55%)] Loss: 12143.427734\n",
      "Train Epoch: 4042 [98560/118836 (83%)] Loss: 12246.079102\n",
      "    epoch          : 4042\n",
      "    loss           : 12184.628894780035\n",
      "    val_loss       : 12189.36625356537\n",
      "    val_log_likelihood: -12103.571944627533\n",
      "    val_log_marginal: -12112.26534812719\n",
      "Train Epoch: 4043 [256/118836 (0%)] Loss: 12229.425781\n",
      "Train Epoch: 4043 [33024/118836 (28%)] Loss: 12167.375000\n",
      "Train Epoch: 4043 [65792/118836 (55%)] Loss: 12205.056641\n",
      "Train Epoch: 4043 [98560/118836 (83%)] Loss: 12175.788086\n",
      "    epoch          : 4043\n",
      "    loss           : 12183.101494003307\n",
      "    val_loss       : 12184.44864194749\n",
      "    val_log_likelihood: -12105.407799899194\n",
      "    val_log_marginal: -12114.262493336746\n",
      "Train Epoch: 4044 [256/118836 (0%)] Loss: 12181.483398\n",
      "Train Epoch: 4044 [33024/118836 (28%)] Loss: 12144.526367\n",
      "Train Epoch: 4044 [65792/118836 (55%)] Loss: 12153.406250\n",
      "Train Epoch: 4044 [98560/118836 (83%)] Loss: 12237.549805\n",
      "    epoch          : 4044\n",
      "    loss           : 12188.48394124147\n",
      "    val_loss       : 12189.050677798046\n",
      "    val_log_likelihood: -12101.439364757805\n",
      "    val_log_marginal: -12110.262273092994\n",
      "Train Epoch: 4045 [256/118836 (0%)] Loss: 12195.456055\n",
      "Train Epoch: 4045 [33024/118836 (28%)] Loss: 12321.405273\n",
      "Train Epoch: 4045 [65792/118836 (55%)] Loss: 12186.130859\n",
      "Train Epoch: 4045 [98560/118836 (83%)] Loss: 12160.009766\n",
      "    epoch          : 4045\n",
      "    loss           : 12183.918813650227\n",
      "    val_loss       : 12187.232356743742\n",
      "    val_log_likelihood: -12104.141243247259\n",
      "    val_log_marginal: -12112.820085066765\n",
      "Train Epoch: 4046 [256/118836 (0%)] Loss: 12186.883789\n",
      "Train Epoch: 4046 [33024/118836 (28%)] Loss: 12136.388672\n",
      "Train Epoch: 4046 [65792/118836 (55%)] Loss: 12171.907227\n",
      "Train Epoch: 4046 [98560/118836 (83%)] Loss: 12130.470703\n",
      "    epoch          : 4046\n",
      "    loss           : 12181.741623856235\n",
      "    val_loss       : 12184.074748095183\n",
      "    val_log_likelihood: -12107.139963780759\n",
      "    val_log_marginal: -12115.90890026713\n",
      "Train Epoch: 4047 [256/118836 (0%)] Loss: 12195.067383\n",
      "Train Epoch: 4047 [33024/118836 (28%)] Loss: 12170.931641\n",
      "Train Epoch: 4047 [65792/118836 (55%)] Loss: 12130.338867\n",
      "Train Epoch: 4047 [98560/118836 (83%)] Loss: 12230.586914\n",
      "    epoch          : 4047\n",
      "    loss           : 12182.740359898418\n",
      "    val_loss       : 12183.666478242252\n",
      "    val_log_likelihood: -12104.837678834521\n",
      "    val_log_marginal: -12113.659008365228\n",
      "Train Epoch: 4048 [256/118836 (0%)] Loss: 12179.238281\n",
      "Train Epoch: 4048 [33024/118836 (28%)] Loss: 12147.346680\n",
      "Train Epoch: 4048 [65792/118836 (55%)] Loss: 12225.907227\n",
      "Train Epoch: 4048 [98560/118836 (83%)] Loss: 12141.888672\n",
      "    epoch          : 4048\n",
      "    loss           : 12183.686962527141\n",
      "    val_loss       : 12180.55773999628\n",
      "    val_log_likelihood: -12106.498457047406\n",
      "    val_log_marginal: -12115.21111503876\n",
      "Train Epoch: 4049 [256/118836 (0%)] Loss: 12272.453125\n",
      "Train Epoch: 4049 [33024/118836 (28%)] Loss: 12232.417969\n",
      "Train Epoch: 4049 [65792/118836 (55%)] Loss: 12233.190430\n",
      "Train Epoch: 4049 [98560/118836 (83%)] Loss: 12237.766602\n",
      "    epoch          : 4049\n",
      "    loss           : 12185.301648605511\n",
      "    val_loss       : 12182.051332310179\n",
      "    val_log_likelihood: -12106.437310341707\n",
      "    val_log_marginal: -12115.077714337966\n",
      "Train Epoch: 4050 [256/118836 (0%)] Loss: 12186.490234\n",
      "Train Epoch: 4050 [33024/118836 (28%)] Loss: 12139.445312\n",
      "Train Epoch: 4050 [65792/118836 (55%)] Loss: 12185.904297\n",
      "Train Epoch: 4050 [98560/118836 (83%)] Loss: 12237.336914\n",
      "    epoch          : 4050\n",
      "    loss           : 12181.495861119727\n",
      "    val_loss       : 12186.995707773573\n",
      "    val_log_likelihood: -12105.336869151934\n",
      "    val_log_marginal: -12114.070073793517\n",
      "Train Epoch: 4051 [256/118836 (0%)] Loss: 12265.813477\n",
      "Train Epoch: 4051 [33024/118836 (28%)] Loss: 12169.276367\n",
      "Train Epoch: 4051 [65792/118836 (55%)] Loss: 12165.383789\n",
      "Train Epoch: 4051 [98560/118836 (83%)] Loss: 12151.003906\n",
      "    epoch          : 4051\n",
      "    loss           : 12180.186796939619\n",
      "    val_loss       : 12186.387724133721\n",
      "    val_log_likelihood: -12105.440612399194\n",
      "    val_log_marginal: -12114.041809597868\n",
      "Train Epoch: 4052 [256/118836 (0%)] Loss: 12386.895508\n",
      "Train Epoch: 4052 [33024/118836 (28%)] Loss: 12267.519531\n",
      "Train Epoch: 4052 [65792/118836 (55%)] Loss: 12193.807617\n",
      "Train Epoch: 4052 [98560/118836 (83%)] Loss: 12238.298828\n",
      "    epoch          : 4052\n",
      "    loss           : 12179.736491773934\n",
      "    val_loss       : 12184.54874996731\n",
      "    val_log_likelihood: -12108.453478953423\n",
      "    val_log_marginal: -12117.217593517484\n",
      "Train Epoch: 4053 [256/118836 (0%)] Loss: 12176.992188\n",
      "Train Epoch: 4053 [33024/118836 (28%)] Loss: 12123.040039\n",
      "Train Epoch: 4053 [65792/118836 (55%)] Loss: 12240.064453\n",
      "Train Epoch: 4053 [98560/118836 (83%)] Loss: 12214.216797\n",
      "    epoch          : 4053\n",
      "    loss           : 12189.499264468312\n",
      "    val_loss       : 12188.44605470128\n",
      "    val_log_likelihood: -12108.469164211125\n",
      "    val_log_marginal: -12117.267912594702\n",
      "Train Epoch: 4054 [256/118836 (0%)] Loss: 12180.147461\n",
      "Train Epoch: 4054 [33024/118836 (28%)] Loss: 12317.226562\n",
      "Train Epoch: 4054 [65792/118836 (55%)] Loss: 12180.365234\n",
      "Train Epoch: 4054 [98560/118836 (83%)] Loss: 12109.521484\n",
      "    epoch          : 4054\n",
      "    loss           : 12184.533134305211\n",
      "    val_loss       : 12187.578328448857\n",
      "    val_log_likelihood: -12106.514306115592\n",
      "    val_log_marginal: -12115.271275682362\n",
      "Train Epoch: 4055 [256/118836 (0%)] Loss: 12272.752930\n",
      "Train Epoch: 4055 [33024/118836 (28%)] Loss: 12153.639648\n",
      "Train Epoch: 4055 [65792/118836 (55%)] Loss: 12121.583984\n",
      "Train Epoch: 4055 [98560/118836 (83%)] Loss: 12184.733398\n",
      "    epoch          : 4055\n",
      "    loss           : 12183.844904589278\n",
      "    val_loss       : 12182.253103636796\n",
      "    val_log_likelihood: -12104.074192579095\n",
      "    val_log_marginal: -12112.782737507112\n",
      "Train Epoch: 4056 [256/118836 (0%)] Loss: 12209.574219\n",
      "Train Epoch: 4056 [33024/118836 (28%)] Loss: 12195.789062\n",
      "Train Epoch: 4056 [65792/118836 (55%)] Loss: 12163.541016\n",
      "Train Epoch: 4056 [98560/118836 (83%)] Loss: 12164.262695\n",
      "    epoch          : 4056\n",
      "    loss           : 12185.45209997286\n",
      "    val_loss       : 12184.876533446832\n",
      "    val_log_likelihood: -12103.608557078422\n",
      "    val_log_marginal: -12112.251378064882\n",
      "Train Epoch: 4057 [256/118836 (0%)] Loss: 12276.370117\n",
      "Train Epoch: 4057 [33024/118836 (28%)] Loss: 12184.065430\n",
      "Train Epoch: 4057 [65792/118836 (55%)] Loss: 12273.820312\n",
      "Train Epoch: 4057 [98560/118836 (83%)] Loss: 12158.326172\n",
      "    epoch          : 4057\n",
      "    loss           : 12182.672975955076\n",
      "    val_loss       : 12182.678617720596\n",
      "    val_log_likelihood: -12106.200725515664\n",
      "    val_log_marginal: -12114.851570499073\n",
      "Train Epoch: 4058 [256/118836 (0%)] Loss: 12175.091797\n",
      "Train Epoch: 4058 [33024/118836 (28%)] Loss: 12218.740234\n",
      "Train Epoch: 4058 [65792/118836 (55%)] Loss: 12186.730469\n",
      "Train Epoch: 4058 [98560/118836 (83%)] Loss: 12250.968750\n",
      "    epoch          : 4058\n",
      "    loss           : 12185.282696507962\n",
      "    val_loss       : 12189.160935192938\n",
      "    val_log_likelihood: -12105.704694446598\n",
      "    val_log_marginal: -12114.40068288825\n",
      "Train Epoch: 4059 [256/118836 (0%)] Loss: 12336.677734\n",
      "Train Epoch: 4059 [33024/118836 (28%)] Loss: 12202.329102\n",
      "Train Epoch: 4059 [65792/118836 (55%)] Loss: 12227.402344\n",
      "Train Epoch: 4059 [98560/118836 (83%)] Loss: 12198.212891\n",
      "    epoch          : 4059\n",
      "    loss           : 12182.474368667286\n",
      "    val_loss       : 12182.125671828499\n",
      "    val_log_likelihood: -12102.297472730563\n",
      "    val_log_marginal: -12111.057971155991\n",
      "Train Epoch: 4060 [256/118836 (0%)] Loss: 12135.018555\n",
      "Train Epoch: 4060 [33024/118836 (28%)] Loss: 12285.442383\n",
      "Train Epoch: 4060 [65792/118836 (55%)] Loss: 12109.547852\n",
      "Train Epoch: 4060 [98560/118836 (83%)] Loss: 12122.359375\n",
      "    epoch          : 4060\n",
      "    loss           : 12187.997539288668\n",
      "    val_loss       : 12181.371921408421\n",
      "    val_log_likelihood: -12105.66661351711\n",
      "    val_log_marginal: -12114.354114579477\n",
      "Train Epoch: 4061 [256/118836 (0%)] Loss: 12241.672852\n",
      "Train Epoch: 4061 [33024/118836 (28%)] Loss: 12271.145508\n",
      "Train Epoch: 4061 [65792/118836 (55%)] Loss: 12262.934570\n",
      "Train Epoch: 4061 [98560/118836 (83%)] Loss: 12107.321289\n",
      "    epoch          : 4061\n",
      "    loss           : 12184.517728203835\n",
      "    val_loss       : 12178.026553736136\n",
      "    val_log_likelihood: -12105.205029983457\n",
      "    val_log_marginal: -12113.862939150651\n",
      "Train Epoch: 4062 [256/118836 (0%)] Loss: 12199.621094\n",
      "Train Epoch: 4062 [33024/118836 (28%)] Loss: 12183.570312\n",
      "Train Epoch: 4062 [65792/118836 (55%)] Loss: 12316.630859\n",
      "Train Epoch: 4062 [98560/118836 (83%)] Loss: 12168.205078\n",
      "    epoch          : 4062\n",
      "    loss           : 12184.037403393817\n",
      "    val_loss       : 12180.317573331828\n",
      "    val_log_likelihood: -12104.149911632805\n",
      "    val_log_marginal: -12112.831559598746\n",
      "Train Epoch: 4063 [256/118836 (0%)] Loss: 12277.808594\n",
      "Train Epoch: 4063 [33024/118836 (28%)] Loss: 12257.696289\n",
      "Train Epoch: 4063 [65792/118836 (55%)] Loss: 12160.929688\n",
      "Train Epoch: 4063 [98560/118836 (83%)] Loss: 12157.050781\n",
      "    epoch          : 4063\n",
      "    loss           : 12187.984425726323\n",
      "    val_loss       : 12187.398023396123\n",
      "    val_log_likelihood: -12102.146355782155\n",
      "    val_log_marginal: -12110.787104022425\n",
      "Train Epoch: 4064 [256/118836 (0%)] Loss: 12141.675781\n",
      "Train Epoch: 4064 [33024/118836 (28%)] Loss: 12160.630859\n",
      "Train Epoch: 4064 [65792/118836 (55%)] Loss: 12266.886719\n",
      "Train Epoch: 4064 [98560/118836 (83%)] Loss: 12239.240234\n",
      "    epoch          : 4064\n",
      "    loss           : 12185.262517285722\n",
      "    val_loss       : 12186.704900764209\n",
      "    val_log_likelihood: -12102.179687015354\n",
      "    val_log_marginal: -12110.775623722275\n",
      "Train Epoch: 4065 [256/118836 (0%)] Loss: 12080.928711\n",
      "Train Epoch: 4065 [33024/118836 (28%)] Loss: 12188.845703\n",
      "Train Epoch: 4065 [65792/118836 (55%)] Loss: 12230.375000\n",
      "Train Epoch: 4065 [98560/118836 (83%)] Loss: 12190.702148\n",
      "    epoch          : 4065\n",
      "    loss           : 12183.802765715467\n",
      "    val_loss       : 12180.019309720916\n",
      "    val_log_likelihood: -12103.784411833127\n",
      "    val_log_marginal: -12112.393464512788\n",
      "Train Epoch: 4066 [256/118836 (0%)] Loss: 12242.672852\n",
      "Train Epoch: 4066 [33024/118836 (28%)] Loss: 12321.957031\n",
      "Train Epoch: 4066 [65792/118836 (55%)] Loss: 12167.395508\n",
      "Train Epoch: 4066 [98560/118836 (83%)] Loss: 12141.103516\n",
      "    epoch          : 4066\n",
      "    loss           : 12181.094592476995\n",
      "    val_loss       : 12184.86146717204\n",
      "    val_log_likelihood: -12102.80272629756\n",
      "    val_log_marginal: -12111.489290826661\n",
      "Train Epoch: 4067 [256/118836 (0%)] Loss: 12232.810547\n",
      "Train Epoch: 4067 [33024/118836 (28%)] Loss: 12294.462891\n",
      "Train Epoch: 4067 [65792/118836 (55%)] Loss: 12145.014648\n",
      "Train Epoch: 4067 [98560/118836 (83%)] Loss: 12153.746094\n",
      "    epoch          : 4067\n",
      "    loss           : 12181.546671286962\n",
      "    val_loss       : 12184.514493372973\n",
      "    val_log_likelihood: -12102.698428776366\n",
      "    val_log_marginal: -12111.359080312968\n",
      "Train Epoch: 4068 [256/118836 (0%)] Loss: 12229.996094\n",
      "Train Epoch: 4068 [33024/118836 (28%)] Loss: 12127.498047\n",
      "Train Epoch: 4068 [65792/118836 (55%)] Loss: 12132.321289\n",
      "Train Epoch: 4068 [98560/118836 (83%)] Loss: 12123.998047\n",
      "    epoch          : 4068\n",
      "    loss           : 12186.067116741626\n",
      "    val_loss       : 12183.287345840346\n",
      "    val_log_likelihood: -12107.73249877223\n",
      "    val_log_marginal: -12116.410970423256\n",
      "Train Epoch: 4069 [256/118836 (0%)] Loss: 12206.982422\n",
      "Train Epoch: 4069 [33024/118836 (28%)] Loss: 12184.832031\n",
      "Train Epoch: 4069 [65792/118836 (55%)] Loss: 12115.432617\n",
      "Train Epoch: 4069 [98560/118836 (83%)] Loss: 12182.998047\n",
      "    epoch          : 4069\n",
      "    loss           : 12188.783336402761\n",
      "    val_loss       : 12186.611611400262\n",
      "    val_log_likelihood: -12108.25963913229\n",
      "    val_log_marginal: -12116.9446611238\n",
      "Train Epoch: 4070 [256/118836 (0%)] Loss: 12227.697266\n",
      "Train Epoch: 4070 [33024/118836 (28%)] Loss: 12158.603516\n",
      "Train Epoch: 4070 [65792/118836 (55%)] Loss: 12156.370117\n",
      "Train Epoch: 4070 [98560/118836 (83%)] Loss: 12183.779297\n",
      "    epoch          : 4070\n",
      "    loss           : 12186.050083197633\n",
      "    val_loss       : 12183.19880716402\n",
      "    val_log_likelihood: -12108.405040968777\n",
      "    val_log_marginal: -12117.303667969805\n",
      "Train Epoch: 4071 [256/118836 (0%)] Loss: 12216.770508\n",
      "Train Epoch: 4071 [33024/118836 (28%)] Loss: 12193.437500\n",
      "Train Epoch: 4071 [65792/118836 (55%)] Loss: 12255.332031\n",
      "Train Epoch: 4071 [98560/118836 (83%)] Loss: 12189.224609\n",
      "    epoch          : 4071\n",
      "    loss           : 12186.108497628464\n",
      "    val_loss       : 12188.18281547447\n",
      "    val_log_likelihood: -12104.987022623294\n",
      "    val_log_marginal: -12113.796521668108\n",
      "Train Epoch: 4072 [256/118836 (0%)] Loss: 12215.820312\n",
      "Train Epoch: 4072 [33024/118836 (28%)] Loss: 12274.462891\n",
      "Train Epoch: 4072 [65792/118836 (55%)] Loss: 12215.710938\n",
      "Train Epoch: 4072 [98560/118836 (83%)] Loss: 12216.205078\n",
      "    epoch          : 4072\n",
      "    loss           : 12186.252036968826\n",
      "    val_loss       : 12182.426721281188\n",
      "    val_log_likelihood: -12105.584819420752\n",
      "    val_log_marginal: -12114.29625425577\n",
      "Train Epoch: 4073 [256/118836 (0%)] Loss: 12133.078125\n",
      "Train Epoch: 4073 [33024/118836 (28%)] Loss: 12148.089844\n",
      "Train Epoch: 4073 [65792/118836 (55%)] Loss: 12192.826172\n",
      "Train Epoch: 4073 [98560/118836 (83%)] Loss: 12275.779297\n",
      "    epoch          : 4073\n",
      "    loss           : 12190.581803950838\n",
      "    val_loss       : 12182.899721842008\n",
      "    val_log_likelihood: -12102.201459108768\n",
      "    val_log_marginal: -12110.88380796467\n",
      "Train Epoch: 4074 [256/118836 (0%)] Loss: 12188.344727\n",
      "Train Epoch: 4074 [33024/118836 (28%)] Loss: 12214.226562\n",
      "Train Epoch: 4074 [65792/118836 (55%)] Loss: 12189.745117\n",
      "Train Epoch: 4074 [98560/118836 (83%)] Loss: 12263.872070\n",
      "    epoch          : 4074\n",
      "    loss           : 12183.942504781846\n",
      "    val_loss       : 12186.33817204399\n",
      "    val_log_likelihood: -12107.617248726994\n",
      "    val_log_marginal: -12116.43669080285\n",
      "Train Epoch: 4075 [256/118836 (0%)] Loss: 12157.279297\n",
      "Train Epoch: 4075 [33024/118836 (28%)] Loss: 12219.285156\n",
      "Train Epoch: 4075 [65792/118836 (55%)] Loss: 12229.489258\n",
      "Train Epoch: 4075 [98560/118836 (83%)] Loss: 12176.681641\n",
      "    epoch          : 4075\n",
      "    loss           : 12181.519882941739\n",
      "    val_loss       : 12188.61047146416\n",
      "    val_log_likelihood: -12104.341085898728\n",
      "    val_log_marginal: -12113.038005576913\n",
      "Train Epoch: 4076 [256/118836 (0%)] Loss: 12201.050781\n",
      "Train Epoch: 4076 [33024/118836 (28%)] Loss: 12293.484375\n",
      "Train Epoch: 4076 [65792/118836 (55%)] Loss: 12207.156250\n",
      "Train Epoch: 4076 [98560/118836 (83%)] Loss: 12242.629883\n",
      "    epoch          : 4076\n",
      "    loss           : 12189.908729127894\n",
      "    val_loss       : 12185.282548054982\n",
      "    val_log_likelihood: -12105.269541427575\n",
      "    val_log_marginal: -12113.953678812071\n",
      "Train Epoch: 4077 [256/118836 (0%)] Loss: 12219.536133\n",
      "Train Epoch: 4077 [33024/118836 (28%)] Loss: 12168.571289\n",
      "Train Epoch: 4077 [65792/118836 (55%)] Loss: 12221.535156\n",
      "Train Epoch: 4077 [98560/118836 (83%)] Loss: 12234.091797\n",
      "    epoch          : 4077\n",
      "    loss           : 12185.264970888906\n",
      "    val_loss       : 12182.886559988157\n",
      "    val_log_likelihood: -12108.079222401004\n",
      "    val_log_marginal: -12116.902880340902\n",
      "Train Epoch: 4078 [256/118836 (0%)] Loss: 12133.234375\n",
      "Train Epoch: 4078 [33024/118836 (28%)] Loss: 12170.656250\n",
      "Train Epoch: 4078 [65792/118836 (55%)] Loss: 12169.492188\n",
      "Train Epoch: 4078 [98560/118836 (83%)] Loss: 12183.112305\n",
      "    epoch          : 4078\n",
      "    loss           : 12184.258821695357\n",
      "    val_loss       : 12184.020846849367\n",
      "    val_log_likelihood: -12103.536787569788\n",
      "    val_log_marginal: -12112.172823948355\n",
      "Train Epoch: 4079 [256/118836 (0%)] Loss: 12179.981445\n",
      "Train Epoch: 4079 [33024/118836 (28%)] Loss: 12266.421875\n",
      "Train Epoch: 4079 [65792/118836 (55%)] Loss: 12162.863281\n",
      "Train Epoch: 4079 [98560/118836 (83%)] Loss: 12267.730469\n",
      "    epoch          : 4079\n",
      "    loss           : 12181.591380402191\n",
      "    val_loss       : 12184.420154982414\n",
      "    val_log_likelihood: -12104.5885103262\n",
      "    val_log_marginal: -12113.290849218754\n",
      "Train Epoch: 4080 [256/118836 (0%)] Loss: 12189.822266\n",
      "Train Epoch: 4080 [33024/118836 (28%)] Loss: 12230.154297\n",
      "Train Epoch: 4080 [65792/118836 (55%)] Loss: 12283.773438\n",
      "Train Epoch: 4080 [98560/118836 (83%)] Loss: 12226.933594\n",
      "    epoch          : 4080\n",
      "    loss           : 12187.645225586746\n",
      "    val_loss       : 12183.763723271943\n",
      "    val_log_likelihood: -12106.534618292495\n",
      "    val_log_marginal: -12115.259287765799\n",
      "Train Epoch: 4081 [256/118836 (0%)] Loss: 12210.033203\n",
      "Train Epoch: 4081 [33024/118836 (28%)] Loss: 12227.218750\n",
      "Train Epoch: 4081 [65792/118836 (55%)] Loss: 12096.973633\n",
      "Train Epoch: 4081 [98560/118836 (83%)] Loss: 12153.541016\n",
      "    epoch          : 4081\n",
      "    loss           : 12183.20806968569\n",
      "    val_loss       : 12183.748742004907\n",
      "    val_log_likelihood: -12102.35174844267\n",
      "    val_log_marginal: -12110.866737098351\n",
      "Train Epoch: 4082 [256/118836 (0%)] Loss: 12146.039062\n",
      "Train Epoch: 4082 [33024/118836 (28%)] Loss: 12154.985352\n",
      "Train Epoch: 4082 [65792/118836 (55%)] Loss: 12309.126953\n",
      "Train Epoch: 4082 [98560/118836 (83%)] Loss: 12173.471680\n",
      "    epoch          : 4082\n",
      "    loss           : 12179.491041795905\n",
      "    val_loss       : 12183.145303855232\n",
      "    val_log_likelihood: -12103.028781211227\n",
      "    val_log_marginal: -12111.747496894757\n",
      "Train Epoch: 4083 [256/118836 (0%)] Loss: 12294.286133\n",
      "Train Epoch: 4083 [33024/118836 (28%)] Loss: 12154.486328\n",
      "Train Epoch: 4083 [65792/118836 (55%)] Loss: 12347.826172\n",
      "Train Epoch: 4083 [98560/118836 (83%)] Loss: 12196.470703\n",
      "    epoch          : 4083\n",
      "    loss           : 12180.685633626706\n",
      "    val_loss       : 12184.570577888851\n",
      "    val_log_likelihood: -12104.516041634355\n",
      "    val_log_marginal: -12113.263874813849\n",
      "Train Epoch: 4084 [256/118836 (0%)] Loss: 12154.954102\n",
      "Train Epoch: 4084 [33024/118836 (28%)] Loss: 12224.476562\n",
      "Train Epoch: 4084 [65792/118836 (55%)] Loss: 12171.234375\n",
      "Train Epoch: 4084 [98560/118836 (83%)] Loss: 12160.749023\n",
      "    epoch          : 4084\n",
      "    loss           : 12180.190003198666\n",
      "    val_loss       : 12187.59521705642\n",
      "    val_log_likelihood: -12105.846011037014\n",
      "    val_log_marginal: -12114.634779795148\n",
      "Train Epoch: 4085 [256/118836 (0%)] Loss: 12138.902344\n",
      "Train Epoch: 4085 [33024/118836 (28%)] Loss: 12211.200195\n",
      "Train Epoch: 4085 [65792/118836 (55%)] Loss: 12293.113281\n",
      "Train Epoch: 4085 [98560/118836 (83%)] Loss: 12173.486328\n",
      "    epoch          : 4085\n",
      "    loss           : 12181.489417422716\n",
      "    val_loss       : 12184.397412742626\n",
      "    val_log_likelihood: -12105.423601310484\n",
      "    val_log_marginal: -12114.346455058538\n",
      "Train Epoch: 4086 [256/118836 (0%)] Loss: 12184.265625\n",
      "Train Epoch: 4086 [33024/118836 (28%)] Loss: 12264.904297\n",
      "Train Epoch: 4086 [65792/118836 (55%)] Loss: 12333.177734\n",
      "Train Epoch: 4086 [98560/118836 (83%)] Loss: 12250.588867\n",
      "    epoch          : 4086\n",
      "    loss           : 12182.192487334574\n",
      "    val_loss       : 12183.597441507904\n",
      "    val_log_likelihood: -12103.6921875\n",
      "    val_log_marginal: -12112.40667057394\n",
      "Train Epoch: 4087 [256/118836 (0%)] Loss: 12216.085938\n",
      "Train Epoch: 4087 [33024/118836 (28%)] Loss: 12264.304688\n",
      "Train Epoch: 4087 [65792/118836 (55%)] Loss: 12190.591797\n",
      "Train Epoch: 4087 [98560/118836 (83%)] Loss: 12224.525391\n",
      "    epoch          : 4087\n",
      "    loss           : 12183.263775589328\n",
      "    val_loss       : 12180.853895221704\n",
      "    val_log_likelihood: -12101.006805404777\n",
      "    val_log_marginal: -12109.764759247591\n",
      "Train Epoch: 4088 [256/118836 (0%)] Loss: 12199.640625\n",
      "Train Epoch: 4088 [33024/118836 (28%)] Loss: 12174.062500\n",
      "Train Epoch: 4088 [65792/118836 (55%)] Loss: 12198.772461\n",
      "Train Epoch: 4088 [98560/118836 (83%)] Loss: 12134.050781\n",
      "    epoch          : 4088\n",
      "    loss           : 12182.171441887665\n",
      "    val_loss       : 12182.133426453225\n",
      "    val_log_likelihood: -12106.720427199649\n",
      "    val_log_marginal: -12115.380746039238\n",
      "Train Epoch: 4089 [256/118836 (0%)] Loss: 12329.220703\n",
      "Train Epoch: 4089 [33024/118836 (28%)] Loss: 12261.022461\n",
      "Train Epoch: 4089 [65792/118836 (55%)] Loss: 12163.872070\n",
      "Train Epoch: 4089 [98560/118836 (83%)] Loss: 12179.375000\n",
      "    epoch          : 4089\n",
      "    loss           : 12184.465797372572\n",
      "    val_loss       : 12180.2161712861\n",
      "    val_log_likelihood: -12102.191946953835\n",
      "    val_log_marginal: -12110.878201910928\n",
      "Train Epoch: 4090 [256/118836 (0%)] Loss: 12417.041016\n",
      "Train Epoch: 4090 [33024/118836 (28%)] Loss: 12299.072266\n",
      "Train Epoch: 4090 [65792/118836 (55%)] Loss: 12223.883789\n",
      "Train Epoch: 4090 [98560/118836 (83%)] Loss: 12219.748047\n",
      "    epoch          : 4090\n",
      "    loss           : 12183.727364912893\n",
      "    val_loss       : 12180.060319177166\n",
      "    val_log_likelihood: -12102.730516245349\n",
      "    val_log_marginal: -12111.315490155072\n",
      "Train Epoch: 4091 [256/118836 (0%)] Loss: 12257.751953\n",
      "Train Epoch: 4091 [33024/118836 (28%)] Loss: 12279.592773\n",
      "Train Epoch: 4091 [65792/118836 (55%)] Loss: 12275.209961\n",
      "Train Epoch: 4091 [98560/118836 (83%)] Loss: 12236.240234\n",
      "    epoch          : 4091\n",
      "    loss           : 12185.34127281069\n",
      "    val_loss       : 12181.264394093001\n",
      "    val_log_likelihood: -12105.846462565913\n",
      "    val_log_marginal: -12114.460938662462\n",
      "Train Epoch: 4092 [256/118836 (0%)] Loss: 12292.370117\n",
      "Train Epoch: 4092 [33024/118836 (28%)] Loss: 12261.044922\n",
      "Train Epoch: 4092 [65792/118836 (55%)] Loss: 12186.211914\n",
      "Train Epoch: 4092 [98560/118836 (83%)] Loss: 12142.892578\n",
      "    epoch          : 4092\n",
      "    loss           : 12179.1362337805\n",
      "    val_loss       : 12185.319722786942\n",
      "    val_log_likelihood: -12104.024696126706\n",
      "    val_log_marginal: -12112.713100368406\n",
      "Train Epoch: 4093 [256/118836 (0%)] Loss: 12188.672852\n",
      "Train Epoch: 4093 [33024/118836 (28%)] Loss: 12267.124023\n",
      "Train Epoch: 4093 [65792/118836 (55%)] Loss: 12151.118164\n",
      "Train Epoch: 4093 [98560/118836 (83%)] Loss: 12219.704102\n",
      "    epoch          : 4093\n",
      "    loss           : 12183.227866683468\n",
      "    val_loss       : 12187.983476405134\n",
      "    val_log_likelihood: -12104.312333766286\n",
      "    val_log_marginal: -12113.13069873597\n",
      "Train Epoch: 4094 [256/118836 (0%)] Loss: 12127.043945\n",
      "Train Epoch: 4094 [33024/118836 (28%)] Loss: 12186.585938\n",
      "Train Epoch: 4094 [65792/118836 (55%)] Loss: 12223.173828\n",
      "Train Epoch: 4094 [98560/118836 (83%)] Loss: 12207.578125\n",
      "    epoch          : 4094\n",
      "    loss           : 12188.445710556245\n",
      "    val_loss       : 12187.394805384296\n",
      "    val_log_likelihood: -12106.24615174602\n",
      "    val_log_marginal: -12114.965179688992\n",
      "Train Epoch: 4095 [256/118836 (0%)] Loss: 12103.828125\n",
      "Train Epoch: 4095 [33024/118836 (28%)] Loss: 12161.201172\n",
      "Train Epoch: 4095 [65792/118836 (55%)] Loss: 12141.738281\n",
      "Train Epoch: 4095 [98560/118836 (83%)] Loss: 12221.360352\n",
      "    epoch          : 4095\n",
      "    loss           : 12187.362164786238\n",
      "    val_loss       : 12183.70439094214\n",
      "    val_log_likelihood: -12106.97445574209\n",
      "    val_log_marginal: -12115.650196242048\n",
      "Train Epoch: 4096 [256/118836 (0%)] Loss: 12273.562500\n",
      "Train Epoch: 4096 [33024/118836 (28%)] Loss: 12217.475586\n",
      "Train Epoch: 4096 [65792/118836 (55%)] Loss: 12246.958984\n",
      "Train Epoch: 4096 [98560/118836 (83%)] Loss: 12226.595703\n",
      "    epoch          : 4096\n",
      "    loss           : 12184.41956210582\n",
      "    val_loss       : 12184.732569832659\n",
      "    val_log_likelihood: -12102.430559540426\n",
      "    val_log_marginal: -12111.09258263159\n",
      "Train Epoch: 4097 [256/118836 (0%)] Loss: 12239.267578\n",
      "Train Epoch: 4097 [33024/118836 (28%)] Loss: 12166.732422\n",
      "Train Epoch: 4097 [65792/118836 (55%)] Loss: 12143.907227\n",
      "Train Epoch: 4097 [98560/118836 (83%)] Loss: 12177.871094\n",
      "    epoch          : 4097\n",
      "    loss           : 12186.43198278536\n",
      "    val_loss       : 12184.190828077353\n",
      "    val_log_likelihood: -12107.914818548386\n",
      "    val_log_marginal: -12116.712313211543\n",
      "Train Epoch: 4098 [256/118836 (0%)] Loss: 12227.004883\n",
      "Train Epoch: 4098 [33024/118836 (28%)] Loss: 12168.096680\n",
      "Train Epoch: 4098 [65792/118836 (55%)] Loss: 12321.630859\n",
      "Train Epoch: 4098 [98560/118836 (83%)] Loss: 12243.837891\n",
      "    epoch          : 4098\n",
      "    loss           : 12188.150400156379\n",
      "    val_loss       : 12187.143393061835\n",
      "    val_log_likelihood: -12106.914104179592\n",
      "    val_log_marginal: -12115.750784065665\n",
      "Train Epoch: 4099 [256/118836 (0%)] Loss: 12236.204102\n",
      "Train Epoch: 4099 [33024/118836 (28%)] Loss: 12283.537109\n",
      "Train Epoch: 4099 [65792/118836 (55%)] Loss: 12125.998047\n",
      "Train Epoch: 4099 [98560/118836 (83%)] Loss: 12172.251953\n",
      "    epoch          : 4099\n",
      "    loss           : 12182.997319905398\n",
      "    val_loss       : 12182.794893502847\n",
      "    val_log_likelihood: -12107.082231408964\n",
      "    val_log_marginal: -12115.906216369856\n",
      "Train Epoch: 4100 [256/118836 (0%)] Loss: 12176.543945\n",
      "Train Epoch: 4100 [33024/118836 (28%)] Loss: 12276.638672\n",
      "Train Epoch: 4100 [65792/118836 (55%)] Loss: 12217.486328\n",
      "Train Epoch: 4100 [98560/118836 (83%)] Loss: 12261.245117\n",
      "    epoch          : 4100\n",
      "    loss           : 12181.610100838763\n",
      "    val_loss       : 12183.378792740436\n",
      "    val_log_likelihood: -12106.313568322219\n",
      "    val_log_marginal: -12115.062897525411\n",
      "Saving checkpoint: saved/models/SelfiesAutoencodingOperad/0905_154251/checkpoint-epoch4100.pth ...\n",
      "Train Epoch: 4101 [256/118836 (0%)] Loss: 12213.484375\n",
      "Train Epoch: 4101 [33024/118836 (28%)] Loss: 12187.254883\n",
      "Train Epoch: 4101 [65792/118836 (55%)] Loss: 12145.954102\n",
      "Train Epoch: 4101 [98560/118836 (83%)] Loss: 12144.845703\n",
      "    epoch          : 4101\n",
      "    loss           : 12183.494550312758\n",
      "    val_loss       : 12183.389101360804\n",
      "    val_log_likelihood: -12104.019221076303\n",
      "    val_log_marginal: -12112.673823080897\n",
      "Train Epoch: 4102 [256/118836 (0%)] Loss: 12291.181641\n",
      "Train Epoch: 4102 [33024/118836 (28%)] Loss: 12161.134766\n",
      "Train Epoch: 4102 [65792/118836 (55%)] Loss: 12343.306641\n",
      "Train Epoch: 4102 [98560/118836 (83%)] Loss: 12233.446289\n",
      "    epoch          : 4102\n",
      "    loss           : 12183.499324241368\n",
      "    val_loss       : 12185.944296785781\n",
      "    val_log_likelihood: -12105.378247777087\n",
      "    val_log_marginal: -12113.994740748405\n",
      "Train Epoch: 4103 [256/118836 (0%)] Loss: 12203.587891\n",
      "Train Epoch: 4103 [33024/118836 (28%)] Loss: 12254.730469\n",
      "Train Epoch: 4103 [65792/118836 (55%)] Loss: 12257.568359\n",
      "Train Epoch: 4103 [98560/118836 (83%)] Loss: 12277.187500\n",
      "    epoch          : 4103\n",
      "    loss           : 12184.084511508736\n",
      "    val_loss       : 12185.27862387628\n",
      "    val_log_likelihood: -12103.596301340209\n",
      "    val_log_marginal: -12112.2037002739\n",
      "Train Epoch: 4104 [256/118836 (0%)] Loss: 12192.395508\n",
      "Train Epoch: 4104 [33024/118836 (28%)] Loss: 12153.997070\n",
      "Train Epoch: 4104 [65792/118836 (55%)] Loss: 12196.706055\n",
      "Train Epoch: 4104 [98560/118836 (83%)] Loss: 12178.054688\n",
      "    epoch          : 4104\n",
      "    loss           : 12179.088120185846\n",
      "    val_loss       : 12186.224026501653\n",
      "    val_log_likelihood: -12104.166327091089\n",
      "    val_log_marginal: -12112.796629922346\n",
      "Train Epoch: 4105 [256/118836 (0%)] Loss: 12323.342773\n",
      "Train Epoch: 4105 [33024/118836 (28%)] Loss: 12176.015625\n",
      "Train Epoch: 4105 [65792/118836 (55%)] Loss: 12204.542969\n",
      "Train Epoch: 4105 [98560/118836 (83%)] Loss: 12134.453125\n",
      "    epoch          : 4105\n",
      "    loss           : 12186.071312810174\n",
      "    val_loss       : 12181.139347123677\n",
      "    val_log_likelihood: -12105.219533188585\n",
      "    val_log_marginal: -12113.86393917153\n",
      "Train Epoch: 4106 [256/118836 (0%)] Loss: 12169.236328\n",
      "Train Epoch: 4106 [33024/118836 (28%)] Loss: 12244.029297\n",
      "Train Epoch: 4106 [65792/118836 (55%)] Loss: 12118.415039\n",
      "Train Epoch: 4106 [98560/118836 (83%)] Loss: 12190.828125\n",
      "    epoch          : 4106\n",
      "    loss           : 12182.4930968582\n",
      "    val_loss       : 12185.05621070422\n",
      "    val_log_likelihood: -12102.119470023006\n",
      "    val_log_marginal: -12110.729320198592\n",
      "Train Epoch: 4107 [256/118836 (0%)] Loss: 12201.073242\n",
      "Train Epoch: 4107 [33024/118836 (28%)] Loss: 12193.152344\n",
      "Train Epoch: 4107 [65792/118836 (55%)] Loss: 12106.020508\n",
      "Train Epoch: 4107 [98560/118836 (83%)] Loss: 12310.086914\n",
      "    epoch          : 4107\n",
      "    loss           : 12184.53213351039\n",
      "    val_loss       : 12182.465573415238\n",
      "    val_log_likelihood: -12101.874110673853\n",
      "    val_log_marginal: -12110.469420078685\n",
      "Train Epoch: 4108 [256/118836 (0%)] Loss: 12204.304688\n",
      "Train Epoch: 4108 [33024/118836 (28%)] Loss: 12095.787109\n",
      "Train Epoch: 4108 [65792/118836 (55%)] Loss: 12135.291992\n",
      "Train Epoch: 4108 [98560/118836 (83%)] Loss: 12174.382812\n",
      "    epoch          : 4108\n",
      "    loss           : 12186.901946663047\n",
      "    val_loss       : 12186.387805750303\n",
      "    val_log_likelihood: -12103.458644476323\n",
      "    val_log_marginal: -12112.083563495215\n",
      "Train Epoch: 4109 [256/118836 (0%)] Loss: 12185.582031\n",
      "Train Epoch: 4109 [33024/118836 (28%)] Loss: 12211.755859\n",
      "Train Epoch: 4109 [65792/118836 (55%)] Loss: 12253.398438\n",
      "Train Epoch: 4109 [98560/118836 (83%)] Loss: 12163.876953\n",
      "    epoch          : 4109\n",
      "    loss           : 12183.087227628723\n",
      "    val_loss       : 12182.751510846878\n",
      "    val_log_likelihood: -12102.958419600394\n",
      "    val_log_marginal: -12111.521987212036\n",
      "Train Epoch: 4110 [256/118836 (0%)] Loss: 12210.671875\n",
      "Train Epoch: 4110 [33024/118836 (28%)] Loss: 12351.226562\n",
      "Train Epoch: 4110 [65792/118836 (55%)] Loss: 12310.909180\n",
      "Train Epoch: 4110 [98560/118836 (83%)] Loss: 12234.813477\n",
      "    epoch          : 4110\n",
      "    loss           : 12184.966730478442\n",
      "    val_loss       : 12183.479096880095\n",
      "    val_log_likelihood: -12101.851895613629\n",
      "    val_log_marginal: -12110.39416882705\n",
      "Train Epoch: 4111 [256/118836 (0%)] Loss: 12162.939453\n",
      "Train Epoch: 4111 [33024/118836 (28%)] Loss: 12203.675781\n",
      "Train Epoch: 4111 [65792/118836 (55%)] Loss: 12160.425781\n",
      "Train Epoch: 4111 [98560/118836 (83%)] Loss: 12254.941406\n",
      "    epoch          : 4111\n",
      "    loss           : 12182.604504788307\n",
      "    val_loss       : 12181.481621078183\n",
      "    val_log_likelihood: -12102.515645678248\n",
      "    val_log_marginal: -12111.115290704529\n",
      "Train Epoch: 4112 [256/118836 (0%)] Loss: 12166.870117\n",
      "Train Epoch: 4112 [33024/118836 (28%)] Loss: 12172.496094\n",
      "Train Epoch: 4112 [65792/118836 (55%)] Loss: 12289.456055\n",
      "Train Epoch: 4112 [98560/118836 (83%)] Loss: 12196.083984\n",
      "    epoch          : 4112\n",
      "    loss           : 12180.44367164883\n",
      "    val_loss       : 12195.701757551085\n",
      "    val_log_likelihood: -12105.182312021816\n",
      "    val_log_marginal: -12113.971141325612\n",
      "Train Epoch: 4113 [256/118836 (0%)] Loss: 12174.919922\n",
      "Train Epoch: 4113 [33024/118836 (28%)] Loss: 12143.111328\n",
      "Train Epoch: 4113 [65792/118836 (55%)] Loss: 12206.963867\n",
      "Train Epoch: 4113 [98560/118836 (83%)] Loss: 12378.536133\n",
      "    epoch          : 4113\n",
      "    loss           : 12189.040578635493\n",
      "    val_loss       : 12186.863293591348\n",
      "    val_log_likelihood: -12103.963657658705\n",
      "    val_log_marginal: -12112.783854707268\n",
      "Train Epoch: 4114 [256/118836 (0%)] Loss: 12110.164062\n",
      "Train Epoch: 4114 [33024/118836 (28%)] Loss: 12207.918945\n",
      "Train Epoch: 4114 [65792/118836 (55%)] Loss: 12205.992188\n",
      "Train Epoch: 4114 [98560/118836 (83%)] Loss: 12192.310547\n",
      "    epoch          : 4114\n",
      "    loss           : 12184.578769095067\n",
      "    val_loss       : 12184.235230386526\n",
      "    val_log_likelihood: -12102.429377164754\n",
      "    val_log_marginal: -12111.127319857382\n",
      "Train Epoch: 4115 [256/118836 (0%)] Loss: 12187.804688\n",
      "Train Epoch: 4115 [33024/118836 (28%)] Loss: 12123.029297\n",
      "Train Epoch: 4115 [65792/118836 (55%)] Loss: 12125.379883\n",
      "Train Epoch: 4115 [98560/118836 (83%)] Loss: 12290.693359\n",
      "    epoch          : 4115\n",
      "    loss           : 12184.085298897591\n",
      "    val_loss       : 12181.95383405294\n",
      "    val_log_likelihood: -12104.694291188482\n",
      "    val_log_marginal: -12113.33513108612\n",
      "Train Epoch: 4116 [256/118836 (0%)] Loss: 12190.681641\n",
      "Train Epoch: 4116 [33024/118836 (28%)] Loss: 12109.855469\n",
      "Train Epoch: 4116 [65792/118836 (55%)] Loss: 12101.029297\n",
      "Train Epoch: 4116 [98560/118836 (83%)] Loss: 12308.349609\n",
      "    epoch          : 4116\n",
      "    loss           : 12179.981408802472\n",
      "    val_loss       : 12184.483127463041\n",
      "    val_log_likelihood: -12104.59279750827\n",
      "    val_log_marginal: -12113.26676421392\n",
      "Train Epoch: 4117 [256/118836 (0%)] Loss: 12178.017578\n",
      "Train Epoch: 4117 [33024/118836 (28%)] Loss: 12282.089844\n",
      "Train Epoch: 4117 [65792/118836 (55%)] Loss: 12128.750977\n",
      "Train Epoch: 4117 [98560/118836 (83%)] Loss: 12101.544922\n",
      "    epoch          : 4117\n",
      "    loss           : 12184.736514875412\n",
      "    val_loss       : 12181.823520868278\n",
      "    val_log_likelihood: -12103.65780038384\n",
      "    val_log_marginal: -12112.32321873849\n",
      "Train Epoch: 4118 [256/118836 (0%)] Loss: 12163.558594\n",
      "Train Epoch: 4118 [33024/118836 (28%)] Loss: 12204.423828\n",
      "Train Epoch: 4118 [65792/118836 (55%)] Loss: 12152.570312\n",
      "Train Epoch: 4118 [98560/118836 (83%)] Loss: 12174.000000\n",
      "    epoch          : 4118\n",
      "    loss           : 12181.122035579507\n",
      "    val_loss       : 12182.46271342656\n",
      "    val_log_likelihood: -12102.801870573563\n",
      "    val_log_marginal: -12111.48909388939\n",
      "Train Epoch: 4119 [256/118836 (0%)] Loss: 12204.132812\n",
      "Train Epoch: 4119 [33024/118836 (28%)] Loss: 12181.363281\n",
      "Train Epoch: 4119 [65792/118836 (55%)] Loss: 12236.375977\n",
      "Train Epoch: 4119 [98560/118836 (83%)] Loss: 12162.457031\n",
      "    epoch          : 4119\n",
      "    loss           : 12182.783347711178\n",
      "    val_loss       : 12183.035185781062\n",
      "    val_log_likelihood: -12102.941168288617\n",
      "    val_log_marginal: -12111.63023443975\n",
      "Train Epoch: 4120 [256/118836 (0%)] Loss: 12301.076172\n",
      "Train Epoch: 4120 [33024/118836 (28%)] Loss: 12297.903320\n",
      "Train Epoch: 4120 [65792/118836 (55%)] Loss: 12198.854492\n",
      "Train Epoch: 4120 [98560/118836 (83%)] Loss: 12279.734375\n",
      "    epoch          : 4120\n",
      "    loss           : 12180.13586625698\n",
      "    val_loss       : 12182.077363151695\n",
      "    val_log_likelihood: -12104.866384602461\n",
      "    val_log_marginal: -12113.691033442201\n",
      "Train Epoch: 4121 [256/118836 (0%)] Loss: 12244.313477\n",
      "Train Epoch: 4121 [33024/118836 (28%)] Loss: 12204.247070\n",
      "Train Epoch: 4121 [65792/118836 (55%)] Loss: 12159.065430\n",
      "Train Epoch: 4121 [98560/118836 (83%)] Loss: 12239.088867\n",
      "    epoch          : 4121\n",
      "    loss           : 12183.151525182227\n",
      "    val_loss       : 12184.017513248877\n",
      "    val_log_likelihood: -12102.349205502998\n",
      "    val_log_marginal: -12111.10254492201\n",
      "Train Epoch: 4122 [256/118836 (0%)] Loss: 12144.162109\n",
      "Train Epoch: 4122 [33024/118836 (28%)] Loss: 12232.025391\n",
      "Train Epoch: 4122 [65792/118836 (55%)] Loss: 12122.137695\n",
      "Train Epoch: 4122 [98560/118836 (83%)] Loss: 12119.156250\n",
      "    epoch          : 4122\n",
      "    loss           : 12183.887172379033\n",
      "    val_loss       : 12185.449539420832\n",
      "    val_log_likelihood: -12100.725200966708\n",
      "    val_log_marginal: -12109.481653284209\n",
      "Train Epoch: 4123 [256/118836 (0%)] Loss: 12321.439453\n",
      "Train Epoch: 4123 [33024/118836 (28%)] Loss: 12299.707031\n",
      "Train Epoch: 4123 [65792/118836 (55%)] Loss: 12296.505859\n",
      "Train Epoch: 4123 [98560/118836 (83%)] Loss: 12193.871094\n",
      "    epoch          : 4123\n",
      "    loss           : 12179.878579759874\n",
      "    val_loss       : 12179.735139858823\n",
      "    val_log_likelihood: -12103.836099856546\n",
      "    val_log_marginal: -12112.752533430623\n",
      "Train Epoch: 4124 [256/118836 (0%)] Loss: 12163.329102\n",
      "Train Epoch: 4124 [33024/118836 (28%)] Loss: 12210.521484\n",
      "Train Epoch: 4124 [65792/118836 (55%)] Loss: 12138.316406\n",
      "Train Epoch: 4124 [98560/118836 (83%)] Loss: 12261.330078\n",
      "    epoch          : 4124\n",
      "    loss           : 12180.109811020215\n",
      "    val_loss       : 12184.913912433858\n",
      "    val_log_likelihood: -12107.80109788565\n",
      "    val_log_marginal: -12116.797007838577\n",
      "Train Epoch: 4125 [256/118836 (0%)] Loss: 12254.337891\n",
      "Train Epoch: 4125 [33024/118836 (28%)] Loss: 12272.438477\n",
      "Train Epoch: 4125 [65792/118836 (55%)] Loss: 12136.145508\n",
      "Train Epoch: 4125 [98560/118836 (83%)] Loss: 12165.496094\n",
      "    epoch          : 4125\n",
      "    loss           : 12186.014453932743\n",
      "    val_loss       : 12180.963583393432\n",
      "    val_log_likelihood: -12100.550455890716\n",
      "    val_log_marginal: -12109.38249570187\n",
      "Train Epoch: 4126 [256/118836 (0%)] Loss: 12207.833984\n",
      "Train Epoch: 4126 [33024/118836 (28%)] Loss: 12216.509766\n",
      "Train Epoch: 4126 [65792/118836 (55%)] Loss: 12137.301758\n",
      "Train Epoch: 4126 [98560/118836 (83%)] Loss: 12240.289062\n",
      "    epoch          : 4126\n",
      "    loss           : 12185.802660062553\n",
      "    val_loss       : 12179.805509276497\n",
      "    val_log_likelihood: -12105.837358967898\n",
      "    val_log_marginal: -12114.702864830688\n",
      "Train Epoch: 4127 [256/118836 (0%)] Loss: 12382.503906\n",
      "Train Epoch: 4127 [33024/118836 (28%)] Loss: 12179.389648\n",
      "Train Epoch: 4127 [65792/118836 (55%)] Loss: 12261.099609\n",
      "Train Epoch: 4127 [98560/118836 (83%)] Loss: 12236.256836\n",
      "    epoch          : 4127\n",
      "    loss           : 12183.965016445667\n",
      "    val_loss       : 12181.727739883572\n",
      "    val_log_likelihood: -12103.67346447865\n",
      "    val_log_marginal: -12112.441132517073\n",
      "Train Epoch: 4128 [256/118836 (0%)] Loss: 12165.708008\n",
      "Train Epoch: 4128 [33024/118836 (28%)] Loss: 12179.403320\n",
      "Train Epoch: 4128 [65792/118836 (55%)] Loss: 12336.654297\n",
      "Train Epoch: 4128 [98560/118836 (83%)] Loss: 12245.199219\n",
      "    epoch          : 4128\n",
      "    loss           : 12188.143520439155\n",
      "    val_loss       : 12179.494686269338\n",
      "    val_log_likelihood: -12101.790989938741\n",
      "    val_log_marginal: -12110.835525181341\n",
      "Train Epoch: 4129 [256/118836 (0%)] Loss: 12138.070312\n",
      "Train Epoch: 4129 [33024/118836 (28%)] Loss: 12260.043945\n",
      "Train Epoch: 4129 [65792/118836 (55%)] Loss: 12171.884766\n",
      "Train Epoch: 4129 [98560/118836 (83%)] Loss: 12167.910156\n",
      "    epoch          : 4129\n",
      "    loss           : 12183.367771337365\n",
      "    val_loss       : 12181.99981365983\n",
      "    val_log_likelihood: -12100.86578784119\n",
      "    val_log_marginal: -12109.847061399263\n",
      "Train Epoch: 4130 [256/118836 (0%)] Loss: 12249.145508\n",
      "Train Epoch: 4130 [33024/118836 (28%)] Loss: 12232.128906\n",
      "Train Epoch: 4130 [65792/118836 (55%)] Loss: 12233.135742\n",
      "Train Epoch: 4130 [98560/118836 (83%)] Loss: 12153.242188\n",
      "    epoch          : 4130\n",
      "    loss           : 12183.837295802316\n",
      "    val_loss       : 12184.066834576155\n",
      "    val_log_likelihood: -12101.48648321185\n",
      "    val_log_marginal: -12110.539550575377\n",
      "Train Epoch: 4131 [256/118836 (0%)] Loss: 12123.349609\n",
      "Train Epoch: 4131 [33024/118836 (28%)] Loss: 12201.254883\n",
      "Train Epoch: 4131 [65792/118836 (55%)] Loss: 12181.972656\n",
      "Train Epoch: 4131 [98560/118836 (83%)] Loss: 12242.866211\n",
      "    epoch          : 4131\n",
      "    loss           : 12180.65766435975\n",
      "    val_loss       : 12195.050220821762\n",
      "    val_log_likelihood: -12105.442285075475\n",
      "    val_log_marginal: -12114.440038440656\n",
      "Train Epoch: 4132 [256/118836 (0%)] Loss: 12190.736328\n",
      "Train Epoch: 4132 [33024/118836 (28%)] Loss: 12121.121094\n",
      "Train Epoch: 4132 [65792/118836 (55%)] Loss: 12105.015625\n",
      "Train Epoch: 4132 [98560/118836 (83%)] Loss: 12198.686523\n",
      "    epoch          : 4132\n",
      "    loss           : 12184.43167971981\n",
      "    val_loss       : 12178.26942876524\n",
      "    val_log_likelihood: -12104.365976853289\n",
      "    val_log_marginal: -12113.379471129754\n",
      "Train Epoch: 4133 [256/118836 (0%)] Loss: 12297.922852\n",
      "Train Epoch: 4133 [33024/118836 (28%)] Loss: 12205.221680\n",
      "Train Epoch: 4133 [65792/118836 (55%)] Loss: 12133.632812\n",
      "Train Epoch: 4133 [98560/118836 (83%)] Loss: 12236.718750\n",
      "    epoch          : 4133\n",
      "    loss           : 12183.126529059398\n",
      "    val_loss       : 12190.857162310922\n",
      "    val_log_likelihood: -12103.195603934037\n",
      "    val_log_marginal: -12112.15419856391\n",
      "Train Epoch: 4134 [256/118836 (0%)] Loss: 12168.044922\n",
      "Train Epoch: 4134 [33024/118836 (28%)] Loss: 12219.656250\n",
      "Train Epoch: 4134 [65792/118836 (55%)] Loss: 12189.998047\n",
      "Train Epoch: 4134 [98560/118836 (83%)] Loss: 12132.089844\n",
      "    epoch          : 4134\n",
      "    loss           : 12185.774050739248\n",
      "    val_loss       : 12184.966831645905\n",
      "    val_log_likelihood: -12104.529832086177\n",
      "    val_log_marginal: -12113.444211400669\n",
      "Train Epoch: 4135 [256/118836 (0%)] Loss: 12168.195312\n",
      "Train Epoch: 4135 [33024/118836 (28%)] Loss: 12152.876953\n",
      "Train Epoch: 4135 [65792/118836 (55%)] Loss: 12206.418945\n",
      "Train Epoch: 4135 [98560/118836 (83%)] Loss: 12194.971680\n",
      "    epoch          : 4135\n",
      "    loss           : 12178.27264397229\n",
      "    val_loss       : 12177.021161304356\n",
      "    val_log_likelihood: -12102.87893872131\n",
      "    val_log_marginal: -12111.769316822845\n",
      "Train Epoch: 4136 [256/118836 (0%)] Loss: 12219.384766\n",
      "Train Epoch: 4136 [33024/118836 (28%)] Loss: 12163.790039\n",
      "Train Epoch: 4136 [65792/118836 (55%)] Loss: 12248.886719\n",
      "Train Epoch: 4136 [98560/118836 (83%)] Loss: 12230.931641\n",
      "    epoch          : 4136\n",
      "    loss           : 12182.170795207818\n",
      "    val_loss       : 12185.531678949365\n",
      "    val_log_likelihood: -12102.939255550817\n",
      "    val_log_marginal: -12111.820634599853\n",
      "Train Epoch: 4137 [256/118836 (0%)] Loss: 12145.209961\n",
      "Train Epoch: 4137 [33024/118836 (28%)] Loss: 12122.821289\n",
      "Train Epoch: 4137 [65792/118836 (55%)] Loss: 12234.735352\n",
      "Train Epoch: 4137 [98560/118836 (83%)] Loss: 12215.695312\n",
      "    epoch          : 4137\n",
      "    loss           : 12181.056141439207\n",
      "    val_loss       : 12182.310024924602\n",
      "    val_log_likelihood: -12102.218912518092\n",
      "    val_log_marginal: -12111.143796082759\n",
      "Train Epoch: 4138 [256/118836 (0%)] Loss: 12134.743164\n",
      "Train Epoch: 4138 [33024/118836 (28%)] Loss: 12202.432617\n",
      "Train Epoch: 4138 [65792/118836 (55%)] Loss: 12243.253906\n",
      "Train Epoch: 4138 [98560/118836 (83%)] Loss: 12134.923828\n",
      "    epoch          : 4138\n",
      "    loss           : 12178.975533434139\n",
      "    val_loss       : 12178.715216453287\n",
      "    val_log_likelihood: -12101.38445835918\n",
      "    val_log_marginal: -12110.247331389826\n",
      "Train Epoch: 4139 [256/118836 (0%)] Loss: 12168.180664\n",
      "Train Epoch: 4139 [33024/118836 (28%)] Loss: 12149.337891\n",
      "Train Epoch: 4139 [65792/118836 (55%)] Loss: 12186.208984\n",
      "Train Epoch: 4139 [98560/118836 (83%)] Loss: 12201.323242\n",
      "    epoch          : 4139\n",
      "    loss           : 12181.461484665788\n",
      "    val_loss       : 12179.455900876335\n",
      "    val_log_likelihood: -12104.165119190704\n",
      "    val_log_marginal: -12113.021888189223\n",
      "Train Epoch: 4140 [256/118836 (0%)] Loss: 12318.075195\n",
      "Train Epoch: 4140 [33024/118836 (28%)] Loss: 12211.867188\n",
      "Train Epoch: 4140 [65792/118836 (55%)] Loss: 12203.185547\n",
      "Train Epoch: 4140 [98560/118836 (83%)] Loss: 12098.654297\n",
      "    epoch          : 4140\n",
      "    loss           : 12179.20613562345\n",
      "    val_loss       : 12183.149540174707\n",
      "    val_log_likelihood: -12099.113040865384\n",
      "    val_log_marginal: -12108.010629845125\n",
      "Train Epoch: 4141 [256/118836 (0%)] Loss: 12177.072266\n",
      "Train Epoch: 4141 [33024/118836 (28%)] Loss: 12148.931641\n",
      "Train Epoch: 4141 [65792/118836 (55%)] Loss: 12273.272461\n",
      "Train Epoch: 4141 [98560/118836 (83%)] Loss: 12245.474609\n",
      "    epoch          : 4141\n",
      "    loss           : 12178.239323078216\n",
      "    val_loss       : 12188.845269712969\n",
      "    val_log_likelihood: -12099.676308222188\n",
      "    val_log_marginal: -12108.545320521052\n",
      "Train Epoch: 4142 [256/118836 (0%)] Loss: 12357.530273\n",
      "Train Epoch: 4142 [33024/118836 (28%)] Loss: 12176.245117\n",
      "Train Epoch: 4142 [65792/118836 (55%)] Loss: 12178.495117\n",
      "Train Epoch: 4142 [98560/118836 (83%)] Loss: 12210.451172\n",
      "    epoch          : 4142\n",
      "    loss           : 12183.130748229425\n",
      "    val_loss       : 12179.673576851455\n",
      "    val_log_likelihood: -12104.95237218259\n",
      "    val_log_marginal: -12113.743579689888\n",
      "Train Epoch: 4143 [256/118836 (0%)] Loss: 12230.641602\n",
      "Train Epoch: 4143 [33024/118836 (28%)] Loss: 12308.156250\n",
      "Train Epoch: 4143 [65792/118836 (55%)] Loss: 12165.611328\n",
      "Train Epoch: 4143 [98560/118836 (83%)] Loss: 12217.107422\n",
      "    epoch          : 4143\n",
      "    loss           : 12183.477834535255\n",
      "    val_loss       : 12185.72997455435\n",
      "    val_log_likelihood: -12102.682879704302\n",
      "    val_log_marginal: -12111.523281116282\n",
      "Train Epoch: 4144 [256/118836 (0%)] Loss: 12136.542969\n",
      "Train Epoch: 4144 [33024/118836 (28%)] Loss: 12295.992188\n",
      "Train Epoch: 4144 [65792/118836 (55%)] Loss: 12263.779297\n",
      "Train Epoch: 4144 [98560/118836 (83%)] Loss: 12203.151367\n",
      "    epoch          : 4144\n",
      "    loss           : 12182.667084431865\n",
      "    val_loss       : 12181.41021110294\n",
      "    val_log_likelihood: -12102.365197218776\n",
      "    val_log_marginal: -12111.202385197432\n",
      "Train Epoch: 4145 [256/118836 (0%)] Loss: 12131.889648\n",
      "Train Epoch: 4145 [33024/118836 (28%)] Loss: 12135.078125\n",
      "Train Epoch: 4145 [65792/118836 (55%)] Loss: 12170.519531\n",
      "Train Epoch: 4145 [98560/118836 (83%)] Loss: 12174.667969\n",
      "    epoch          : 4145\n",
      "    loss           : 12178.987243783602\n",
      "    val_loss       : 12181.330024713534\n",
      "    val_log_likelihood: -12103.955278445512\n",
      "    val_log_marginal: -12112.770742034565\n",
      "Train Epoch: 4146 [256/118836 (0%)] Loss: 12168.894531\n",
      "Train Epoch: 4146 [33024/118836 (28%)] Loss: 12152.955078\n",
      "Train Epoch: 4146 [65792/118836 (55%)] Loss: 12187.653320\n",
      "Train Epoch: 4146 [98560/118836 (83%)] Loss: 12248.220703\n",
      "    epoch          : 4146\n",
      "    loss           : 12184.327122751241\n",
      "    val_loss       : 12177.306367288491\n",
      "    val_log_likelihood: -12102.337097581936\n",
      "    val_log_marginal: -12111.135484420573\n",
      "Train Epoch: 4147 [256/118836 (0%)] Loss: 12195.586914\n",
      "Train Epoch: 4147 [33024/118836 (28%)] Loss: 12179.407227\n",
      "Train Epoch: 4147 [65792/118836 (55%)] Loss: 12171.181641\n",
      "Train Epoch: 4147 [98560/118836 (83%)] Loss: 12237.808594\n",
      "    epoch          : 4147\n",
      "    loss           : 12179.279352770885\n",
      "    val_loss       : 12182.545117201456\n",
      "    val_log_likelihood: -12104.433280668423\n",
      "    val_log_marginal: -12113.40309637278\n",
      "Train Epoch: 4148 [256/118836 (0%)] Loss: 12172.875000\n",
      "Train Epoch: 4148 [33024/118836 (28%)] Loss: 12140.820312\n",
      "Train Epoch: 4148 [65792/118836 (55%)] Loss: 12223.987305\n",
      "Train Epoch: 4148 [98560/118836 (83%)] Loss: 12169.528320\n",
      "    epoch          : 4148\n",
      "    loss           : 12182.29745835272\n",
      "    val_loss       : 12177.812124934942\n",
      "    val_log_likelihood: -12104.176174944427\n",
      "    val_log_marginal: -12113.012072767076\n",
      "Train Epoch: 4149 [256/118836 (0%)] Loss: 12219.476562\n",
      "Train Epoch: 4149 [33024/118836 (28%)] Loss: 12089.372070\n",
      "Train Epoch: 4149 [65792/118836 (55%)] Loss: 12247.918945\n",
      "Train Epoch: 4149 [98560/118836 (83%)] Loss: 12146.083984\n",
      "    epoch          : 4149\n",
      "    loss           : 12179.554761973997\n",
      "    val_loss       : 12180.956478792166\n",
      "    val_log_likelihood: -12100.571440433727\n",
      "    val_log_marginal: -12109.3167519402\n",
      "Train Epoch: 4150 [256/118836 (0%)] Loss: 12260.724609\n",
      "Train Epoch: 4150 [33024/118836 (28%)] Loss: 12259.807617\n",
      "Train Epoch: 4150 [65792/118836 (55%)] Loss: 12159.967773\n",
      "Train Epoch: 4150 [98560/118836 (83%)] Loss: 12192.961914\n",
      "    epoch          : 4150\n",
      "    loss           : 12179.810359963038\n",
      "    val_loss       : 12178.279634629955\n",
      "    val_log_likelihood: -12103.535208107165\n",
      "    val_log_marginal: -12112.364364168294\n",
      "Train Epoch: 4151 [256/118836 (0%)] Loss: 12265.277344\n",
      "Train Epoch: 4151 [33024/118836 (28%)] Loss: 12254.867188\n",
      "Train Epoch: 4151 [65792/118836 (55%)] Loss: 12184.847656\n",
      "Train Epoch: 4151 [98560/118836 (83%)] Loss: 12145.534180\n",
      "    epoch          : 4151\n",
      "    loss           : 12180.960869649503\n",
      "    val_loss       : 12181.750242262906\n",
      "    val_log_likelihood: -12103.55155296862\n",
      "    val_log_marginal: -12112.459709178127\n",
      "Train Epoch: 4152 [256/118836 (0%)] Loss: 12189.018555\n",
      "Train Epoch: 4152 [33024/118836 (28%)] Loss: 12161.687500\n",
      "Train Epoch: 4152 [65792/118836 (55%)] Loss: 12183.012695\n",
      "Train Epoch: 4152 [98560/118836 (83%)] Loss: 12243.954102\n",
      "    epoch          : 4152\n",
      "    loss           : 12180.340865384615\n",
      "    val_loss       : 12176.45639962852\n",
      "    val_log_likelihood: -12100.617982320098\n",
      "    val_log_marginal: -12109.380721874344\n",
      "Train Epoch: 4153 [256/118836 (0%)] Loss: 12118.719727\n",
      "Train Epoch: 4153 [33024/118836 (28%)] Loss: 12174.124023\n",
      "Train Epoch: 4153 [65792/118836 (55%)] Loss: 12185.725586\n",
      "Train Epoch: 4153 [98560/118836 (83%)] Loss: 12193.806641\n",
      "    epoch          : 4153\n",
      "    loss           : 12177.374432155966\n",
      "    val_loss       : 12187.024101750705\n",
      "    val_log_likelihood: -12103.423006972445\n",
      "    val_log_marginal: -12112.202338661431\n",
      "Train Epoch: 4154 [256/118836 (0%)] Loss: 12171.554688\n",
      "Train Epoch: 4154 [33024/118836 (28%)] Loss: 12127.628906\n",
      "Train Epoch: 4154 [65792/118836 (55%)] Loss: 12146.740234\n",
      "Train Epoch: 4154 [98560/118836 (83%)] Loss: 12229.772461\n",
      "    epoch          : 4154\n",
      "    loss           : 12183.194215260546\n",
      "    val_loss       : 12181.070863602923\n",
      "    val_log_likelihood: -12101.857039812086\n",
      "    val_log_marginal: -12110.632974604252\n",
      "Train Epoch: 4155 [256/118836 (0%)] Loss: 12251.036133\n",
      "Train Epoch: 4155 [33024/118836 (28%)] Loss: 12204.084961\n",
      "Train Epoch: 4155 [65792/118836 (55%)] Loss: 12214.351562\n",
      "Train Epoch: 4155 [98560/118836 (83%)] Loss: 12230.179688\n",
      "    epoch          : 4155\n",
      "    loss           : 12182.033897946392\n",
      "    val_loss       : 12183.97661517329\n",
      "    val_log_likelihood: -12103.062810496796\n",
      "    val_log_marginal: -12111.94173666501\n",
      "Train Epoch: 4156 [256/118836 (0%)] Loss: 12214.863281\n",
      "Train Epoch: 4156 [33024/118836 (28%)] Loss: 12164.874023\n",
      "Train Epoch: 4156 [65792/118836 (55%)] Loss: 12205.058594\n",
      "Train Epoch: 4156 [98560/118836 (83%)] Loss: 12162.932617\n",
      "    epoch          : 4156\n",
      "    loss           : 12179.802841158758\n",
      "    val_loss       : 12181.341237758967\n",
      "    val_log_likelihood: -12101.454262949752\n",
      "    val_log_marginal: -12110.458011870003\n",
      "Train Epoch: 4157 [256/118836 (0%)] Loss: 12258.911133\n",
      "Train Epoch: 4157 [33024/118836 (28%)] Loss: 12279.410156\n",
      "Train Epoch: 4157 [65792/118836 (55%)] Loss: 12149.861328\n",
      "Train Epoch: 4157 [98560/118836 (83%)] Loss: 12249.675781\n",
      "    epoch          : 4157\n",
      "    loss           : 12180.656098305677\n",
      "    val_loss       : 12179.986859213734\n",
      "    val_log_likelihood: -12104.457153865538\n",
      "    val_log_marginal: -12113.347247766962\n",
      "Train Epoch: 4158 [256/118836 (0%)] Loss: 12150.430664\n",
      "Train Epoch: 4158 [33024/118836 (28%)] Loss: 12277.120117\n",
      "Train Epoch: 4158 [65792/118836 (55%)] Loss: 12188.528320\n",
      "Train Epoch: 4158 [98560/118836 (83%)] Loss: 12205.726562\n",
      "    epoch          : 4158\n",
      "    loss           : 12181.357391988471\n",
      "    val_loss       : 12181.410728545947\n",
      "    val_log_likelihood: -12102.282990042133\n",
      "    val_log_marginal: -12111.137354612674\n",
      "Train Epoch: 4159 [256/118836 (0%)] Loss: 12172.801758\n",
      "Train Epoch: 4159 [33024/118836 (28%)] Loss: 12216.986328\n",
      "Train Epoch: 4159 [65792/118836 (55%)] Loss: 12215.373047\n",
      "Train Epoch: 4159 [98560/118836 (83%)] Loss: 12132.896484\n",
      "    epoch          : 4159\n",
      "    loss           : 12179.679120140612\n",
      "    val_loss       : 12177.738743594615\n",
      "    val_log_likelihood: -12103.565626292391\n",
      "    val_log_marginal: -12112.424821899927\n",
      "Train Epoch: 4160 [256/118836 (0%)] Loss: 12346.161133\n",
      "Train Epoch: 4160 [33024/118836 (28%)] Loss: 12148.202148\n",
      "Train Epoch: 4160 [65792/118836 (55%)] Loss: 12196.316406\n",
      "Train Epoch: 4160 [98560/118836 (83%)] Loss: 12133.281250\n",
      "    epoch          : 4160\n",
      "    loss           : 12183.869355000259\n",
      "    val_loss       : 12185.173732096084\n",
      "    val_log_likelihood: -12105.166425635856\n",
      "    val_log_marginal: -12114.336396559283\n",
      "Train Epoch: 4161 [256/118836 (0%)] Loss: 12164.585938\n",
      "Train Epoch: 4161 [33024/118836 (28%)] Loss: 12226.031250\n",
      "Train Epoch: 4161 [65792/118836 (55%)] Loss: 12169.375000\n",
      "Train Epoch: 4161 [98560/118836 (83%)] Loss: 12164.366211\n",
      "    epoch          : 4161\n",
      "    loss           : 12184.65264164599\n",
      "    val_loss       : 12185.77920245513\n",
      "    val_log_likelihood: -12107.756145639476\n",
      "    val_log_marginal: -12116.867616846854\n",
      "Train Epoch: 4162 [256/118836 (0%)] Loss: 12270.180664\n",
      "Train Epoch: 4162 [33024/118836 (28%)] Loss: 12296.146484\n",
      "Train Epoch: 4162 [65792/118836 (55%)] Loss: 12170.912109\n",
      "Train Epoch: 4162 [98560/118836 (83%)] Loss: 12108.932617\n",
      "    epoch          : 4162\n",
      "    loss           : 12182.591334360784\n",
      "    val_loss       : 12184.645216344208\n",
      "    val_log_likelihood: -12101.919826722757\n",
      "    val_log_marginal: -12110.852541471453\n",
      "Train Epoch: 4163 [256/118836 (0%)] Loss: 12300.289062\n",
      "Train Epoch: 4163 [33024/118836 (28%)] Loss: 12310.471680\n",
      "Train Epoch: 4163 [65792/118836 (55%)] Loss: 12112.438477\n",
      "Train Epoch: 4163 [98560/118836 (83%)] Loss: 12246.248047\n",
      "    epoch          : 4163\n",
      "    loss           : 12186.001634550765\n",
      "    val_loss       : 12183.594117022694\n",
      "    val_log_likelihood: -12100.04219170027\n",
      "    val_log_marginal: -12109.019461859787\n",
      "Train Epoch: 4164 [256/118836 (0%)] Loss: 12196.768555\n",
      "Train Epoch: 4164 [33024/118836 (28%)] Loss: 12117.521484\n",
      "Train Epoch: 4164 [65792/118836 (55%)] Loss: 12267.809570\n",
      "Train Epoch: 4164 [98560/118836 (83%)] Loss: 12160.990234\n",
      "    epoch          : 4164\n",
      "    loss           : 12182.602510791461\n",
      "    val_loss       : 12182.333127303293\n",
      "    val_log_likelihood: -12100.72657186983\n",
      "    val_log_marginal: -12109.618630062803\n",
      "Train Epoch: 4165 [256/118836 (0%)] Loss: 12155.846680\n",
      "Train Epoch: 4165 [33024/118836 (28%)] Loss: 12133.170898\n",
      "Train Epoch: 4165 [65792/118836 (55%)] Loss: 12174.958008\n",
      "Train Epoch: 4165 [98560/118836 (83%)] Loss: 12253.347656\n",
      "    epoch          : 4165\n",
      "    loss           : 12178.641374586434\n",
      "    val_loss       : 12183.178736574044\n",
      "    val_log_likelihood: -12101.113679790891\n",
      "    val_log_marginal: -12110.168356181835\n",
      "Train Epoch: 4166 [256/118836 (0%)] Loss: 12132.747070\n",
      "Train Epoch: 4166 [33024/118836 (28%)] Loss: 12187.173828\n",
      "Train Epoch: 4166 [65792/118836 (55%)] Loss: 12140.602539\n",
      "Train Epoch: 4166 [98560/118836 (83%)] Loss: 12266.875000\n",
      "    epoch          : 4166\n",
      "    loss           : 12179.067270212985\n",
      "    val_loss       : 12179.947318771738\n",
      "    val_log_likelihood: -12102.721825889166\n",
      "    val_log_marginal: -12111.636515460401\n",
      "Train Epoch: 4167 [256/118836 (0%)] Loss: 12160.043945\n",
      "Train Epoch: 4167 [33024/118836 (28%)] Loss: 12346.941406\n",
      "Train Epoch: 4167 [65792/118836 (55%)] Loss: 12202.210938\n",
      "Train Epoch: 4167 [98560/118836 (83%)] Loss: 12240.251953\n",
      "    epoch          : 4167\n",
      "    loss           : 12184.131345959988\n",
      "    val_loss       : 12182.691364722736\n",
      "    val_log_likelihood: -12100.6734037363\n",
      "    val_log_marginal: -12109.54870332417\n",
      "Train Epoch: 4168 [256/118836 (0%)] Loss: 12200.230469\n",
      "Train Epoch: 4168 [33024/118836 (28%)] Loss: 12350.128906\n",
      "Train Epoch: 4168 [65792/118836 (55%)] Loss: 12248.025391\n",
      "Train Epoch: 4168 [98560/118836 (83%)] Loss: 12180.368164\n",
      "    epoch          : 4168\n",
      "    loss           : 12180.314965234698\n",
      "    val_loss       : 12177.721768910778\n",
      "    val_log_likelihood: -12101.812481906534\n",
      "    val_log_marginal: -12110.614480892724\n",
      "Train Epoch: 4169 [256/118836 (0%)] Loss: 12208.876953\n",
      "Train Epoch: 4169 [33024/118836 (28%)] Loss: 12151.547852\n",
      "Train Epoch: 4169 [65792/118836 (55%)] Loss: 12144.718750\n",
      "Train Epoch: 4169 [98560/118836 (83%)] Loss: 12203.992188\n",
      "    epoch          : 4169\n",
      "    loss           : 12179.894685367555\n",
      "    val_loss       : 12179.196093971099\n",
      "    val_log_likelihood: -12102.184122499224\n",
      "    val_log_marginal: -12111.112153421262\n",
      "Train Epoch: 4170 [256/118836 (0%)] Loss: 12156.537109\n",
      "Train Epoch: 4170 [33024/118836 (28%)] Loss: 12248.276367\n",
      "Train Epoch: 4170 [65792/118836 (55%)] Loss: 12094.873047\n",
      "Train Epoch: 4170 [98560/118836 (83%)] Loss: 12173.435547\n",
      "    epoch          : 4170\n",
      "    loss           : 12180.751894159686\n",
      "    val_loss       : 12181.670570100345\n",
      "    val_log_likelihood: -12104.985196798749\n",
      "    val_log_marginal: -12113.811711817074\n",
      "Train Epoch: 4171 [256/118836 (0%)] Loss: 12268.151367\n",
      "Train Epoch: 4171 [33024/118836 (28%)] Loss: 12180.430664\n",
      "Train Epoch: 4171 [65792/118836 (55%)] Loss: 12253.367188\n",
      "Train Epoch: 4171 [98560/118836 (83%)] Loss: 12238.286133\n",
      "    epoch          : 4171\n",
      "    loss           : 12178.039362496123\n",
      "    val_loss       : 12181.340128168864\n",
      "    val_log_likelihood: -12102.135452853598\n",
      "    val_log_marginal: -12110.902176914515\n",
      "Train Epoch: 4172 [256/118836 (0%)] Loss: 12264.490234\n",
      "Train Epoch: 4172 [33024/118836 (28%)] Loss: 12161.156250\n",
      "Train Epoch: 4172 [65792/118836 (55%)] Loss: 12110.314453\n",
      "Train Epoch: 4172 [98560/118836 (83%)] Loss: 12212.075195\n",
      "    epoch          : 4172\n",
      "    loss           : 12181.430434178557\n",
      "    val_loss       : 12184.145824220104\n",
      "    val_log_likelihood: -12101.50014555547\n",
      "    val_log_marginal: -12110.285907878366\n",
      "Train Epoch: 4173 [256/118836 (0%)] Loss: 12221.074219\n",
      "Train Epoch: 4173 [33024/118836 (28%)] Loss: 12239.689453\n",
      "Train Epoch: 4173 [65792/118836 (55%)] Loss: 12155.959961\n",
      "Train Epoch: 4173 [98560/118836 (83%)] Loss: 12178.736328\n",
      "    epoch          : 4173\n",
      "    loss           : 12179.613213561053\n",
      "    val_loss       : 12182.3598764227\n",
      "    val_log_likelihood: -12101.248169813638\n",
      "    val_log_marginal: -12110.115670336576\n",
      "Train Epoch: 4174 [256/118836 (0%)] Loss: 12188.029297\n",
      "Train Epoch: 4174 [33024/118836 (28%)] Loss: 12175.711914\n",
      "Train Epoch: 4174 [65792/118836 (55%)] Loss: 12192.703125\n",
      "Train Epoch: 4174 [98560/118836 (83%)] Loss: 12150.197266\n",
      "    epoch          : 4174\n",
      "    loss           : 12180.32123494365\n",
      "    val_loss       : 12182.733253140777\n",
      "    val_log_likelihood: -12101.713398049784\n",
      "    val_log_marginal: -12110.623611612695\n",
      "Train Epoch: 4175 [256/118836 (0%)] Loss: 12163.623047\n",
      "Train Epoch: 4175 [33024/118836 (28%)] Loss: 12189.157227\n",
      "Train Epoch: 4175 [65792/118836 (55%)] Loss: 12230.305664\n",
      "Train Epoch: 4175 [98560/118836 (83%)] Loss: 12181.085938\n",
      "    epoch          : 4175\n",
      "    loss           : 12185.003587837313\n",
      "    val_loss       : 12182.158779046611\n",
      "    val_log_likelihood: -12102.99404369572\n",
      "    val_log_marginal: -12111.92451224974\n",
      "Train Epoch: 4176 [256/118836 (0%)] Loss: 12224.764648\n",
      "Train Epoch: 4176 [33024/118836 (28%)] Loss: 12201.105469\n",
      "Train Epoch: 4176 [65792/118836 (55%)] Loss: 12276.087891\n",
      "Train Epoch: 4176 [98560/118836 (83%)] Loss: 12328.064453\n",
      "    epoch          : 4176\n",
      "    loss           : 12182.424790309657\n",
      "    val_loss       : 12181.598657081835\n",
      "    val_log_likelihood: -12103.777986068033\n",
      "    val_log_marginal: -12112.891267632156\n",
      "Train Epoch: 4177 [256/118836 (0%)] Loss: 12166.007812\n",
      "Train Epoch: 4177 [33024/118836 (28%)] Loss: 12167.881836\n",
      "Train Epoch: 4177 [65792/118836 (55%)] Loss: 12223.789062\n",
      "Train Epoch: 4177 [98560/118836 (83%)] Loss: 12303.878906\n",
      "    epoch          : 4177\n",
      "    loss           : 12181.686825533758\n",
      "    val_loss       : 12182.526093618299\n",
      "    val_log_likelihood: -12105.303932259356\n",
      "    val_log_marginal: -12114.146115298417\n",
      "Train Epoch: 4178 [256/118836 (0%)] Loss: 12217.341797\n",
      "Train Epoch: 4178 [33024/118836 (28%)] Loss: 12179.105469\n",
      "Train Epoch: 4178 [65792/118836 (55%)] Loss: 12181.595703\n",
      "Train Epoch: 4178 [98560/118836 (83%)] Loss: 12327.664062\n",
      "    epoch          : 4178\n",
      "    loss           : 12178.693914618227\n",
      "    val_loss       : 12183.807449908201\n",
      "    val_log_likelihood: -12109.461828280086\n",
      "    val_log_marginal: -12118.428230791067\n",
      "Train Epoch: 4179 [256/118836 (0%)] Loss: 12317.978516\n",
      "Train Epoch: 4179 [33024/118836 (28%)] Loss: 12299.245117\n",
      "Train Epoch: 4179 [65792/118836 (55%)] Loss: 12118.367188\n",
      "Train Epoch: 4179 [98560/118836 (83%)] Loss: 12178.819336\n",
      "    epoch          : 4179\n",
      "    loss           : 12183.428233237697\n",
      "    val_loss       : 12183.247154223638\n",
      "    val_log_likelihood: -12104.958594396196\n",
      "    val_log_marginal: -12114.048157287647\n",
      "Train Epoch: 4180 [256/118836 (0%)] Loss: 12265.710938\n",
      "Train Epoch: 4180 [33024/118836 (28%)] Loss: 12176.517578\n",
      "Train Epoch: 4180 [65792/118836 (55%)] Loss: 12285.518555\n",
      "Train Epoch: 4180 [98560/118836 (83%)] Loss: 12270.014648\n",
      "    epoch          : 4180\n",
      "    loss           : 12183.267095740282\n",
      "    val_loss       : 12177.205147352806\n",
      "    val_log_likelihood: -12101.333234465466\n",
      "    val_log_marginal: -12110.296177208405\n",
      "Train Epoch: 4181 [256/118836 (0%)] Loss: 12238.412109\n",
      "Train Epoch: 4181 [33024/118836 (28%)] Loss: 12289.166016\n",
      "Train Epoch: 4181 [65792/118836 (55%)] Loss: 12232.208008\n",
      "Train Epoch: 4181 [98560/118836 (83%)] Loss: 12228.583008\n",
      "    epoch          : 4181\n",
      "    loss           : 12181.779517227564\n",
      "    val_loss       : 12183.986148026303\n",
      "    val_log_likelihood: -12101.564585271919\n",
      "    val_log_marginal: -12110.345066422293\n",
      "Train Epoch: 4182 [256/118836 (0%)] Loss: 12153.464844\n",
      "Train Epoch: 4182 [33024/118836 (28%)] Loss: 12194.244141\n",
      "Train Epoch: 4182 [65792/118836 (55%)] Loss: 12169.697266\n",
      "Train Epoch: 4182 [98560/118836 (83%)] Loss: 12186.897461\n",
      "    epoch          : 4182\n",
      "    loss           : 12179.00394389087\n",
      "    val_loss       : 12183.2430693111\n",
      "    val_log_likelihood: -12104.007489563948\n",
      "    val_log_marginal: -12112.873759448208\n",
      "Train Epoch: 4183 [256/118836 (0%)] Loss: 12252.439453\n",
      "Train Epoch: 4183 [33024/118836 (28%)] Loss: 12153.093750\n",
      "Train Epoch: 4183 [65792/118836 (55%)] Loss: 12172.198242\n",
      "Train Epoch: 4183 [98560/118836 (83%)] Loss: 12151.603516\n",
      "    epoch          : 4183\n",
      "    loss           : 12180.641707538512\n",
      "    val_loss       : 12181.391521393782\n",
      "    val_log_likelihood: -12106.05348444608\n",
      "    val_log_marginal: -12114.987667692149\n",
      "Train Epoch: 4184 [256/118836 (0%)] Loss: 12151.743164\n",
      "Train Epoch: 4184 [33024/118836 (28%)] Loss: 12250.977539\n",
      "Train Epoch: 4184 [65792/118836 (55%)] Loss: 12202.361328\n",
      "Train Epoch: 4184 [98560/118836 (83%)] Loss: 12260.175781\n",
      "    epoch          : 4184\n",
      "    loss           : 12180.978045194892\n",
      "    val_loss       : 12181.030685139787\n",
      "    val_log_likelihood: -12101.672499063015\n",
      "    val_log_marginal: -12110.692958804992\n",
      "Train Epoch: 4185 [256/118836 (0%)] Loss: 12209.898438\n",
      "Train Epoch: 4185 [33024/118836 (28%)] Loss: 12211.537109\n",
      "Train Epoch: 4185 [65792/118836 (55%)] Loss: 12154.598633\n",
      "Train Epoch: 4185 [98560/118836 (83%)] Loss: 12151.903320\n",
      "    epoch          : 4185\n",
      "    loss           : 12187.754450184812\n",
      "    val_loss       : 12180.67906052651\n",
      "    val_log_likelihood: -12100.173667707042\n",
      "    val_log_marginal: -12109.131178347323\n",
      "Train Epoch: 4186 [256/118836 (0%)] Loss: 12262.793945\n",
      "Train Epoch: 4186 [33024/118836 (28%)] Loss: 12120.767578\n",
      "Train Epoch: 4186 [65792/118836 (55%)] Loss: 12341.882812\n",
      "Train Epoch: 4186 [98560/118836 (83%)] Loss: 12128.130859\n",
      "    epoch          : 4186\n",
      "    loss           : 12183.210279673283\n",
      "    val_loss       : 12178.857810839567\n",
      "    val_log_likelihood: -12101.508349165117\n",
      "    val_log_marginal: -12110.578508647213\n",
      "Train Epoch: 4187 [256/118836 (0%)] Loss: 12257.930664\n",
      "Train Epoch: 4187 [33024/118836 (28%)] Loss: 12306.091797\n",
      "Train Epoch: 4187 [65792/118836 (55%)] Loss: 12214.875000\n",
      "Train Epoch: 4187 [98560/118836 (83%)] Loss: 12113.372070\n",
      "    epoch          : 4187\n",
      "    loss           : 12185.871939296423\n",
      "    val_loss       : 12179.454163049651\n",
      "    val_log_likelihood: -12099.148372395834\n",
      "    val_log_marginal: -12108.055363222204\n",
      "Train Epoch: 4188 [256/118836 (0%)] Loss: 12203.838867\n",
      "Train Epoch: 4188 [33024/118836 (28%)] Loss: 12276.843750\n",
      "Train Epoch: 4188 [65792/118836 (55%)] Loss: 12124.402344\n",
      "Train Epoch: 4188 [98560/118836 (83%)] Loss: 12092.872070\n",
      "    epoch          : 4188\n",
      "    loss           : 12184.47139277683\n",
      "    val_loss       : 12180.275766703582\n",
      "    val_log_likelihood: -12109.311884660618\n",
      "    val_log_marginal: -12118.309130365174\n",
      "Train Epoch: 4189 [256/118836 (0%)] Loss: 12147.798828\n",
      "Train Epoch: 4189 [33024/118836 (28%)] Loss: 12213.691406\n",
      "Train Epoch: 4189 [65792/118836 (55%)] Loss: 12214.810547\n",
      "Train Epoch: 4189 [98560/118836 (83%)] Loss: 12169.947266\n",
      "    epoch          : 4189\n",
      "    loss           : 12175.34672265948\n",
      "    val_loss       : 12180.655809304299\n",
      "    val_log_likelihood: -12105.342354218361\n",
      "    val_log_marginal: -12114.240240255487\n",
      "Train Epoch: 4190 [256/118836 (0%)] Loss: 12123.160156\n",
      "Train Epoch: 4190 [33024/118836 (28%)] Loss: 12218.351562\n",
      "Train Epoch: 4190 [65792/118836 (55%)] Loss: 12178.955078\n",
      "Train Epoch: 4190 [98560/118836 (83%)] Loss: 12171.235352\n",
      "    epoch          : 4190\n",
      "    loss           : 12180.231805566325\n",
      "    val_loss       : 12178.078923853527\n",
      "    val_log_likelihood: -12103.545236895161\n",
      "    val_log_marginal: -12112.356773807829\n",
      "Train Epoch: 4191 [256/118836 (0%)] Loss: 12193.864258\n",
      "Train Epoch: 4191 [33024/118836 (28%)] Loss: 12147.892578\n",
      "Train Epoch: 4191 [65792/118836 (55%)] Loss: 12309.564453\n",
      "Train Epoch: 4191 [98560/118836 (83%)] Loss: 12264.871094\n",
      "    epoch          : 4191\n",
      "    loss           : 12180.257085368848\n",
      "    val_loss       : 12176.38815180593\n",
      "    val_log_likelihood: -12099.622305527553\n",
      "    val_log_marginal: -12108.447957608456\n",
      "Train Epoch: 4192 [256/118836 (0%)] Loss: 12123.093750\n",
      "Train Epoch: 4192 [33024/118836 (28%)] Loss: 12142.819336\n",
      "Train Epoch: 4192 [65792/118836 (55%)] Loss: 12194.498047\n",
      "Train Epoch: 4192 [98560/118836 (83%)] Loss: 12166.332031\n",
      "    epoch          : 4192\n",
      "    loss           : 12180.353661503566\n",
      "    val_loss       : 12180.926551382403\n",
      "    val_log_likelihood: -12103.827751660721\n",
      "    val_log_marginal: -12112.781846312497\n",
      "Train Epoch: 4193 [256/118836 (0%)] Loss: 12213.725586\n",
      "Train Epoch: 4193 [33024/118836 (28%)] Loss: 12230.649414\n",
      "Train Epoch: 4193 [65792/118836 (55%)] Loss: 12190.720703\n",
      "Train Epoch: 4193 [98560/118836 (83%)] Loss: 12130.871094\n",
      "    epoch          : 4193\n",
      "    loss           : 12186.192492019489\n",
      "    val_loss       : 12178.068799766514\n",
      "    val_log_likelihood: -12102.577910463193\n",
      "    val_log_marginal: -12111.50767615206\n",
      "Train Epoch: 4194 [256/118836 (0%)] Loss: 12148.552734\n",
      "Train Epoch: 4194 [33024/118836 (28%)] Loss: 12186.574219\n",
      "Train Epoch: 4194 [65792/118836 (55%)] Loss: 12247.663086\n",
      "Train Epoch: 4194 [98560/118836 (83%)] Loss: 12163.709961\n",
      "    epoch          : 4194\n",
      "    loss           : 12184.611945726065\n",
      "    val_loss       : 12182.69974169229\n",
      "    val_log_likelihood: -12106.32214430185\n",
      "    val_log_marginal: -12115.37192122217\n",
      "Train Epoch: 4195 [256/118836 (0%)] Loss: 12232.500977\n",
      "Train Epoch: 4195 [33024/118836 (28%)] Loss: 12173.064453\n",
      "Train Epoch: 4195 [65792/118836 (55%)] Loss: 12167.234375\n",
      "Train Epoch: 4195 [98560/118836 (83%)] Loss: 12236.119141\n",
      "    epoch          : 4195\n",
      "    loss           : 12183.18517918993\n",
      "    val_loss       : 12182.11131613302\n",
      "    val_log_likelihood: -12104.225780765353\n",
      "    val_log_marginal: -12113.185147745566\n",
      "Train Epoch: 4196 [256/118836 (0%)] Loss: 12134.181641\n",
      "Train Epoch: 4196 [33024/118836 (28%)] Loss: 12179.771484\n",
      "Train Epoch: 4196 [65792/118836 (55%)] Loss: 12162.587891\n",
      "Train Epoch: 4196 [98560/118836 (83%)] Loss: 12308.373047\n",
      "    epoch          : 4196\n",
      "    loss           : 12182.580762768817\n",
      "    val_loss       : 12182.660972575279\n",
      "    val_log_likelihood: -12100.916056658396\n",
      "    val_log_marginal: -12109.755871113966\n",
      "Train Epoch: 4197 [256/118836 (0%)] Loss: 12147.845703\n",
      "Train Epoch: 4197 [33024/118836 (28%)] Loss: 12134.183594\n",
      "Train Epoch: 4197 [65792/118836 (55%)] Loss: 12148.360352\n",
      "Train Epoch: 4197 [98560/118836 (83%)] Loss: 12192.164062\n",
      "    epoch          : 4197\n",
      "    loss           : 12177.965550041357\n",
      "    val_loss       : 12181.338743360915\n",
      "    val_log_likelihood: -12103.175244423335\n",
      "    val_log_marginal: -12112.029173404253\n",
      "Train Epoch: 4198 [256/118836 (0%)] Loss: 12241.068359\n",
      "Train Epoch: 4198 [33024/118836 (28%)] Loss: 12235.855469\n",
      "Train Epoch: 4198 [65792/118836 (55%)] Loss: 12155.609375\n",
      "Train Epoch: 4198 [98560/118836 (83%)] Loss: 12210.232422\n",
      "    epoch          : 4198\n",
      "    loss           : 12181.632160327492\n",
      "    val_loss       : 12177.796454617357\n",
      "    val_log_likelihood: -12103.189403529517\n",
      "    val_log_marginal: -12111.966554449575\n",
      "Train Epoch: 4199 [256/118836 (0%)] Loss: 12224.886719\n",
      "Train Epoch: 4199 [33024/118836 (28%)] Loss: 12204.043945\n",
      "Train Epoch: 4199 [65792/118836 (55%)] Loss: 12160.301758\n",
      "Train Epoch: 4199 [98560/118836 (83%)] Loss: 12128.178711\n",
      "    epoch          : 4199\n",
      "    loss           : 12183.96012539418\n",
      "    val_loss       : 12180.737088588055\n",
      "    val_log_likelihood: -12100.867808170493\n",
      "    val_log_marginal: -12109.639192970428\n",
      "Train Epoch: 4200 [256/118836 (0%)] Loss: 12137.990234\n",
      "Train Epoch: 4200 [33024/118836 (28%)] Loss: 12214.416016\n",
      "Train Epoch: 4200 [65792/118836 (55%)] Loss: 12199.984375\n",
      "Train Epoch: 4200 [98560/118836 (83%)] Loss: 12213.783203\n",
      "    epoch          : 4200\n",
      "    loss           : 12183.006294264373\n",
      "    val_loss       : 12184.680019306987\n",
      "    val_log_likelihood: -12100.505684417649\n",
      "    val_log_marginal: -12109.40038299595\n",
      "Saving checkpoint: saved/models/SelfiesAutoencodingOperad/0905_154251/checkpoint-epoch4200.pth ...\n",
      "Train Epoch: 4201 [256/118836 (0%)] Loss: 12239.022461\n",
      "Train Epoch: 4201 [33024/118836 (28%)] Loss: 12161.185547\n",
      "Train Epoch: 4201 [65792/118836 (55%)] Loss: 12279.634766\n",
      "Train Epoch: 4201 [98560/118836 (83%)] Loss: 12251.633789\n",
      "    epoch          : 4201\n",
      "    loss           : 12184.629308183416\n",
      "    val_loss       : 12177.159526933368\n",
      "    val_log_likelihood: -12104.89443561311\n",
      "    val_log_marginal: -12113.854647707285\n",
      "Train Epoch: 4202 [256/118836 (0%)] Loss: 12184.331055\n",
      "Train Epoch: 4202 [33024/118836 (28%)] Loss: 12151.243164\n",
      "Train Epoch: 4202 [65792/118836 (55%)] Loss: 12153.889648\n",
      "Train Epoch: 4202 [98560/118836 (83%)] Loss: 12247.201172\n",
      "    epoch          : 4202\n",
      "    loss           : 12176.530529007703\n",
      "    val_loss       : 12175.901965929212\n",
      "    val_log_likelihood: -12103.844223499535\n",
      "    val_log_marginal: -12112.676767205181\n",
      "Train Epoch: 4203 [256/118836 (0%)] Loss: 12219.801758\n",
      "Train Epoch: 4203 [33024/118836 (28%)] Loss: 12174.180664\n",
      "Train Epoch: 4203 [65792/118836 (55%)] Loss: 12154.499023\n",
      "Train Epoch: 4203 [98560/118836 (83%)] Loss: 12175.682617\n",
      "    epoch          : 4203\n",
      "    loss           : 12184.039781392163\n",
      "    val_loss       : 12179.318127158691\n",
      "    val_log_likelihood: -12102.84500814206\n",
      "    val_log_marginal: -12111.62868403721\n",
      "Train Epoch: 4204 [256/118836 (0%)] Loss: 12274.040039\n",
      "Train Epoch: 4204 [33024/118836 (28%)] Loss: 12143.377930\n",
      "Train Epoch: 4204 [65792/118836 (55%)] Loss: 12150.470703\n",
      "Train Epoch: 4204 [98560/118836 (83%)] Loss: 12062.751953\n",
      "    epoch          : 4204\n",
      "    loss           : 12183.077306270678\n",
      "    val_loss       : 12180.551072938832\n",
      "    val_log_likelihood: -12105.150948453009\n",
      "    val_log_marginal: -12113.89826095756\n",
      "Train Epoch: 4205 [256/118836 (0%)] Loss: 12194.291992\n",
      "Train Epoch: 4205 [33024/118836 (28%)] Loss: 12181.322266\n",
      "Train Epoch: 4205 [65792/118836 (55%)] Loss: 12263.398438\n",
      "Train Epoch: 4205 [98560/118836 (83%)] Loss: 12238.218750\n",
      "    epoch          : 4205\n",
      "    loss           : 12181.068054370864\n",
      "    val_loss       : 12181.415329808311\n",
      "    val_log_likelihood: -12103.783764507083\n",
      "    val_log_marginal: -12112.608459180856\n",
      "Train Epoch: 4206 [256/118836 (0%)] Loss: 12241.014648\n",
      "Train Epoch: 4206 [33024/118836 (28%)] Loss: 12172.628906\n",
      "Train Epoch: 4206 [65792/118836 (55%)] Loss: 12232.343750\n",
      "Train Epoch: 4206 [98560/118836 (83%)] Loss: 12172.298828\n",
      "    epoch          : 4206\n",
      "    loss           : 12183.984581297818\n",
      "    val_loss       : 12187.240191107336\n",
      "    val_log_likelihood: -12104.632471147384\n",
      "    val_log_marginal: -12113.562714708914\n",
      "Train Epoch: 4207 [256/118836 (0%)] Loss: 12178.542969\n",
      "Train Epoch: 4207 [33024/118836 (28%)] Loss: 12177.654297\n",
      "Train Epoch: 4207 [65792/118836 (55%)] Loss: 12276.607422\n",
      "Train Epoch: 4207 [98560/118836 (83%)] Loss: 12164.610352\n",
      "    epoch          : 4207\n",
      "    loss           : 12182.213908705542\n",
      "    val_loss       : 12182.642045221693\n",
      "    val_log_likelihood: -12103.07596202311\n",
      "    val_log_marginal: -12111.999713243426\n",
      "Train Epoch: 4208 [256/118836 (0%)] Loss: 12217.769531\n",
      "Train Epoch: 4208 [33024/118836 (28%)] Loss: 12276.119141\n",
      "Train Epoch: 4208 [65792/118836 (55%)] Loss: 12235.896484\n",
      "Train Epoch: 4208 [98560/118836 (83%)] Loss: 12292.931641\n",
      "    epoch          : 4208\n",
      "    loss           : 12182.936583210556\n",
      "    val_loss       : 12183.393018547073\n",
      "    val_log_likelihood: -12103.2658676463\n",
      "    val_log_marginal: -12112.269245057016\n",
      "Train Epoch: 4209 [256/118836 (0%)] Loss: 12215.274414\n",
      "Train Epoch: 4209 [33024/118836 (28%)] Loss: 12204.986328\n",
      "Train Epoch: 4209 [65792/118836 (55%)] Loss: 12273.557617\n",
      "Train Epoch: 4209 [98560/118836 (83%)] Loss: 12105.107422\n",
      "    epoch          : 4209\n",
      "    loss           : 12181.237486268352\n",
      "    val_loss       : 12182.807598992573\n",
      "    val_log_likelihood: -12104.328938721308\n",
      "    val_log_marginal: -12113.32867609815\n",
      "Train Epoch: 4210 [256/118836 (0%)] Loss: 12211.871094\n",
      "Train Epoch: 4210 [33024/118836 (28%)] Loss: 12159.611328\n",
      "Train Epoch: 4210 [65792/118836 (55%)] Loss: 12157.364258\n",
      "Train Epoch: 4210 [98560/118836 (83%)] Loss: 12206.330078\n",
      "    epoch          : 4210\n",
      "    loss           : 12180.750915012406\n",
      "    val_loss       : 12178.843921486336\n",
      "    val_log_likelihood: -12103.028803343414\n",
      "    val_log_marginal: -12111.98200820766\n",
      "Train Epoch: 4211 [256/118836 (0%)] Loss: 12133.008789\n",
      "Train Epoch: 4211 [33024/118836 (28%)] Loss: 12108.709961\n",
      "Train Epoch: 4211 [65792/118836 (55%)] Loss: 12214.676758\n",
      "Train Epoch: 4211 [98560/118836 (83%)] Loss: 12282.676758\n",
      "    epoch          : 4211\n",
      "    loss           : 12183.570020581317\n",
      "    val_loss       : 12180.855830224793\n",
      "    val_log_likelihood: -12104.43599533447\n",
      "    val_log_marginal: -12113.335276518159\n",
      "Train Epoch: 4212 [256/118836 (0%)] Loss: 12230.089844\n",
      "Train Epoch: 4212 [33024/118836 (28%)] Loss: 12279.341797\n",
      "Train Epoch: 4212 [65792/118836 (55%)] Loss: 12145.323242\n",
      "Train Epoch: 4212 [98560/118836 (83%)] Loss: 12239.737305\n",
      "    epoch          : 4212\n",
      "    loss           : 12182.063187874794\n",
      "    val_loss       : 12183.997802097092\n",
      "    val_log_likelihood: -12102.761078855201\n",
      "    val_log_marginal: -12111.776955637779\n",
      "Train Epoch: 4213 [256/118836 (0%)] Loss: 12182.437500\n",
      "Train Epoch: 4213 [33024/118836 (28%)] Loss: 12246.742188\n",
      "Train Epoch: 4213 [65792/118836 (55%)] Loss: 12145.303711\n",
      "Train Epoch: 4213 [98560/118836 (83%)] Loss: 12132.465820\n",
      "    epoch          : 4213\n",
      "    loss           : 12180.742278128877\n",
      "    val_loss       : 12183.307382039284\n",
      "    val_log_likelihood: -12099.731330451303\n",
      "    val_log_marginal: -12108.551256052851\n",
      "Train Epoch: 4214 [256/118836 (0%)] Loss: 12268.634766\n",
      "Train Epoch: 4214 [33024/118836 (28%)] Loss: 12196.751953\n",
      "Train Epoch: 4214 [65792/118836 (55%)] Loss: 12143.305664\n",
      "Train Epoch: 4214 [98560/118836 (83%)] Loss: 12206.587891\n",
      "    epoch          : 4214\n",
      "    loss           : 12181.057279388957\n",
      "    val_loss       : 12181.051671220584\n",
      "    val_log_likelihood: -12104.366241308675\n",
      "    val_log_marginal: -12113.364116273207\n",
      "Train Epoch: 4215 [256/118836 (0%)] Loss: 12257.445312\n",
      "Train Epoch: 4215 [33024/118836 (28%)] Loss: 12242.147461\n",
      "Train Epoch: 4215 [65792/118836 (55%)] Loss: 12324.722656\n",
      "Train Epoch: 4215 [98560/118836 (83%)] Loss: 12084.117188\n",
      "    epoch          : 4215\n",
      "    loss           : 12184.351396589382\n",
      "    val_loss       : 12177.416650952746\n",
      "    val_log_likelihood: -12101.805607843517\n",
      "    val_log_marginal: -12110.705691885812\n",
      "Train Epoch: 4216 [256/118836 (0%)] Loss: 12182.791016\n",
      "Train Epoch: 4216 [33024/118836 (28%)] Loss: 12202.843750\n",
      "Train Epoch: 4216 [65792/118836 (55%)] Loss: 12257.342773\n",
      "Train Epoch: 4216 [98560/118836 (83%)] Loss: 12158.911133\n",
      "    epoch          : 4216\n",
      "    loss           : 12179.455680055833\n",
      "    val_loss       : 12180.37482501775\n",
      "    val_log_likelihood: -12099.173951386734\n",
      "    val_log_marginal: -12108.032492795382\n",
      "Train Epoch: 4217 [256/118836 (0%)] Loss: 12202.710938\n",
      "Train Epoch: 4217 [33024/118836 (28%)] Loss: 12113.383789\n",
      "Train Epoch: 4217 [65792/118836 (55%)] Loss: 12139.862305\n",
      "Train Epoch: 4217 [98560/118836 (83%)] Loss: 12228.838867\n",
      "    epoch          : 4217\n",
      "    loss           : 12182.512054933055\n",
      "    val_loss       : 12177.813396476942\n",
      "    val_log_likelihood: -12102.772485492917\n",
      "    val_log_marginal: -12111.63478153812\n",
      "Train Epoch: 4218 [256/118836 (0%)] Loss: 12230.458984\n",
      "Train Epoch: 4218 [33024/118836 (28%)] Loss: 12247.005859\n",
      "Train Epoch: 4218 [65792/118836 (55%)] Loss: 12262.342773\n",
      "Train Epoch: 4218 [98560/118836 (83%)] Loss: 12253.596680\n",
      "    epoch          : 4218\n",
      "    loss           : 12179.620042390405\n",
      "    val_loss       : 12178.176678123622\n",
      "    val_log_likelihood: -12099.678718045647\n",
      "    val_log_marginal: -12108.564155716209\n",
      "Train Epoch: 4219 [256/118836 (0%)] Loss: 12226.673828\n",
      "Train Epoch: 4219 [33024/118836 (28%)] Loss: 12246.819336\n",
      "Train Epoch: 4219 [65792/118836 (55%)] Loss: 12185.466797\n",
      "Train Epoch: 4219 [98560/118836 (83%)] Loss: 12238.673828\n",
      "    epoch          : 4219\n",
      "    loss           : 12180.472412634408\n",
      "    val_loss       : 12180.616318859304\n",
      "    val_log_likelihood: -12104.707732694893\n",
      "    val_log_marginal: -12113.569982029843\n",
      "Train Epoch: 4220 [256/118836 (0%)] Loss: 12083.757812\n",
      "Train Epoch: 4220 [33024/118836 (28%)] Loss: 12220.476562\n",
      "Train Epoch: 4220 [65792/118836 (55%)] Loss: 12132.798828\n",
      "Train Epoch: 4220 [98560/118836 (83%)] Loss: 12186.266602\n",
      "    epoch          : 4220\n",
      "    loss           : 12190.142868266645\n",
      "    val_loss       : 12198.375807862714\n",
      "    val_log_likelihood: -12106.921854806398\n",
      "    val_log_marginal: -12115.90839714957\n",
      "Train Epoch: 4221 [256/118836 (0%)] Loss: 12264.659180\n",
      "Train Epoch: 4221 [33024/118836 (28%)] Loss: 12170.744141\n",
      "Train Epoch: 4221 [65792/118836 (55%)] Loss: 12324.936523\n",
      "Train Epoch: 4221 [98560/118836 (83%)] Loss: 12148.283203\n",
      "    epoch          : 4221\n",
      "    loss           : 12186.472919412996\n",
      "    val_loss       : 12183.393062238756\n",
      "    val_log_likelihood: -12106.283201509512\n",
      "    val_log_marginal: -12115.319389244682\n",
      "Train Epoch: 4222 [256/118836 (0%)] Loss: 12167.833984\n",
      "Train Epoch: 4222 [33024/118836 (28%)] Loss: 12178.203125\n",
      "Train Epoch: 4222 [65792/118836 (55%)] Loss: 12239.221680\n",
      "Train Epoch: 4222 [98560/118836 (83%)] Loss: 12223.347656\n",
      "    epoch          : 4222\n",
      "    loss           : 12186.168035308105\n",
      "    val_loss       : 12180.938021814036\n",
      "    val_log_likelihood: -12101.559957706524\n",
      "    val_log_marginal: -12110.635655005326\n",
      "Train Epoch: 4223 [256/118836 (0%)] Loss: 12172.577148\n",
      "Train Epoch: 4223 [33024/118836 (28%)] Loss: 12126.108398\n",
      "Train Epoch: 4223 [65792/118836 (55%)] Loss: 12220.166992\n",
      "Train Epoch: 4223 [98560/118836 (83%)] Loss: 12158.376953\n",
      "    epoch          : 4223\n",
      "    loss           : 12184.418213011788\n",
      "    val_loss       : 12183.679238126546\n",
      "    val_log_likelihood: -12101.971303440345\n",
      "    val_log_marginal: -12110.992697146294\n",
      "Train Epoch: 4224 [256/118836 (0%)] Loss: 12204.458008\n",
      "Train Epoch: 4224 [33024/118836 (28%)] Loss: 12274.458008\n",
      "Train Epoch: 4224 [65792/118836 (55%)] Loss: 12217.312500\n",
      "Train Epoch: 4224 [98560/118836 (83%)] Loss: 12347.666016\n",
      "    epoch          : 4224\n",
      "    loss           : 12182.158719919615\n",
      "    val_loss       : 12181.26942794738\n",
      "    val_log_likelihood: -12101.279192676022\n",
      "    val_log_marginal: -12110.191190229747\n",
      "Train Epoch: 4225 [256/118836 (0%)] Loss: 12241.326172\n",
      "Train Epoch: 4225 [33024/118836 (28%)] Loss: 12256.144531\n",
      "Train Epoch: 4225 [65792/118836 (55%)] Loss: 12168.556641\n",
      "Train Epoch: 4225 [98560/118836 (83%)] Loss: 12142.341797\n",
      "    epoch          : 4225\n",
      "    loss           : 12181.699380137252\n",
      "    val_loss       : 12179.65976939988\n",
      "    val_log_likelihood: -12105.35972798413\n",
      "    val_log_marginal: -12114.248670219502\n",
      "Train Epoch: 4226 [256/118836 (0%)] Loss: 12173.949219\n",
      "Train Epoch: 4226 [33024/118836 (28%)] Loss: 12248.873047\n",
      "Train Epoch: 4226 [65792/118836 (55%)] Loss: 12173.476562\n",
      "Train Epoch: 4226 [98560/118836 (83%)] Loss: 12157.785156\n",
      "    epoch          : 4226\n",
      "    loss           : 12180.553152947943\n",
      "    val_loss       : 12181.41587511571\n",
      "    val_log_likelihood: -12100.899759292286\n",
      "    val_log_marginal: -12109.84412114712\n",
      "Train Epoch: 4227 [256/118836 (0%)] Loss: 12162.410156\n",
      "Train Epoch: 4227 [33024/118836 (28%)] Loss: 12244.759766\n",
      "Train Epoch: 4227 [65792/118836 (55%)] Loss: 12254.884766\n",
      "Train Epoch: 4227 [98560/118836 (83%)] Loss: 12097.283203\n",
      "    epoch          : 4227\n",
      "    loss           : 12179.034651894644\n",
      "    val_loss       : 12185.698631058416\n",
      "    val_log_likelihood: -12101.99111788539\n",
      "    val_log_marginal: -12110.906310901197\n",
      "Train Epoch: 4228 [256/118836 (0%)] Loss: 12234.031250\n",
      "Train Epoch: 4228 [33024/118836 (28%)] Loss: 12134.582031\n",
      "Train Epoch: 4228 [65792/118836 (55%)] Loss: 12162.292969\n",
      "Train Epoch: 4228 [98560/118836 (83%)] Loss: 12130.870117\n",
      "    epoch          : 4228\n",
      "    loss           : 12182.848908737851\n",
      "    val_loss       : 12182.200580997458\n",
      "    val_log_likelihood: -12101.979365371692\n",
      "    val_log_marginal: -12110.836568838518\n",
      "Train Epoch: 4229 [256/118836 (0%)] Loss: 12138.102539\n",
      "Train Epoch: 4229 [33024/118836 (28%)] Loss: 12246.060547\n",
      "Train Epoch: 4229 [65792/118836 (55%)] Loss: 12268.003906\n",
      "Train Epoch: 4229 [98560/118836 (83%)] Loss: 12214.648438\n",
      "    epoch          : 4229\n",
      "    loss           : 12182.760472239454\n",
      "    val_loss       : 12181.711738011767\n",
      "    val_log_likelihood: -12103.780720281482\n",
      "    val_log_marginal: -12112.796804085834\n",
      "Train Epoch: 4230 [256/118836 (0%)] Loss: 12244.781250\n",
      "Train Epoch: 4230 [33024/118836 (28%)] Loss: 12196.630859\n",
      "Train Epoch: 4230 [65792/118836 (55%)] Loss: 12176.458984\n",
      "Train Epoch: 4230 [98560/118836 (83%)] Loss: 12159.572266\n",
      "    epoch          : 4230\n",
      "    loss           : 12184.164539876707\n",
      "    val_loss       : 12178.128151493087\n",
      "    val_log_likelihood: -12103.34298345094\n",
      "    val_log_marginal: -12112.340818506225\n",
      "Train Epoch: 4231 [256/118836 (0%)] Loss: 12201.956055\n",
      "Train Epoch: 4231 [33024/118836 (28%)] Loss: 12180.145508\n",
      "Train Epoch: 4231 [65792/118836 (55%)] Loss: 12148.418945\n",
      "Train Epoch: 4231 [98560/118836 (83%)] Loss: 12287.668945\n",
      "    epoch          : 4231\n",
      "    loss           : 12182.030012374638\n",
      "    val_loss       : 12183.189697151687\n",
      "    val_log_likelihood: -12101.151388996586\n",
      "    val_log_marginal: -12110.206810531705\n",
      "Train Epoch: 4232 [256/118836 (0%)] Loss: 12204.501953\n",
      "Train Epoch: 4232 [33024/118836 (28%)] Loss: 12254.882812\n",
      "Train Epoch: 4232 [65792/118836 (55%)] Loss: 12339.922852\n",
      "Train Epoch: 4232 [98560/118836 (83%)] Loss: 12364.612305\n",
      "    epoch          : 4232\n",
      "    loss           : 12183.627795925093\n",
      "    val_loss       : 12187.64120346319\n",
      "    val_log_likelihood: -12101.968311718105\n",
      "    val_log_marginal: -12111.042462350793\n",
      "Train Epoch: 4233 [256/118836 (0%)] Loss: 12247.234375\n",
      "Train Epoch: 4233 [33024/118836 (28%)] Loss: 12185.186523\n",
      "Train Epoch: 4233 [65792/118836 (55%)] Loss: 12182.441406\n",
      "Train Epoch: 4233 [98560/118836 (83%)] Loss: 12248.546875\n",
      "    epoch          : 4233\n",
      "    loss           : 12180.308279537581\n",
      "    val_loss       : 12181.847338587506\n",
      "    val_log_likelihood: -12101.707285043167\n",
      "    val_log_marginal: -12110.601339440182\n",
      "Train Epoch: 4234 [256/118836 (0%)] Loss: 12142.953125\n",
      "Train Epoch: 4234 [33024/118836 (28%)] Loss: 12240.880859\n",
      "Train Epoch: 4234 [65792/118836 (55%)] Loss: 12229.365234\n",
      "Train Epoch: 4234 [98560/118836 (83%)] Loss: 12214.733398\n",
      "    epoch          : 4234\n",
      "    loss           : 12180.897586137822\n",
      "    val_loss       : 12180.259520203139\n",
      "    val_log_likelihood: -12104.690408686156\n",
      "    val_log_marginal: -12113.605792063729\n",
      "Train Epoch: 4235 [256/118836 (0%)] Loss: 12169.123047\n",
      "Train Epoch: 4235 [33024/118836 (28%)] Loss: 12340.494141\n",
      "Train Epoch: 4235 [65792/118836 (55%)] Loss: 12274.931641\n",
      "Train Epoch: 4235 [98560/118836 (83%)] Loss: 12270.183594\n",
      "    epoch          : 4235\n",
      "    loss           : 12181.907255641285\n",
      "    val_loss       : 12182.043623967334\n",
      "    val_log_likelihood: -12103.040123552522\n",
      "    val_log_marginal: -12112.061992029892\n",
      "Train Epoch: 4236 [256/118836 (0%)] Loss: 12300.474609\n",
      "Train Epoch: 4236 [33024/118836 (28%)] Loss: 12156.845703\n",
      "Train Epoch: 4236 [65792/118836 (55%)] Loss: 12223.048828\n",
      "Train Epoch: 4236 [98560/118836 (83%)] Loss: 12104.347656\n",
      "    epoch          : 4236\n",
      "    loss           : 12181.044515741316\n",
      "    val_loss       : 12180.245711333597\n",
      "    val_log_likelihood: -12104.28068538694\n",
      "    val_log_marginal: -12113.109513916961\n",
      "Train Epoch: 4237 [256/118836 (0%)] Loss: 12157.425781\n",
      "Train Epoch: 4237 [33024/118836 (28%)] Loss: 12181.580078\n",
      "Train Epoch: 4237 [65792/118836 (55%)] Loss: 12157.199219\n",
      "Train Epoch: 4237 [98560/118836 (83%)] Loss: 12214.521484\n",
      "    epoch          : 4237\n",
      "    loss           : 12184.75095216863\n",
      "    val_loss       : 12180.82298975127\n",
      "    val_log_likelihood: -12103.79385646066\n",
      "    val_log_marginal: -12112.665476625878\n",
      "Train Epoch: 4238 [256/118836 (0%)] Loss: 12145.001953\n",
      "Train Epoch: 4238 [33024/118836 (28%)] Loss: 12320.662109\n",
      "Train Epoch: 4238 [65792/118836 (55%)] Loss: 12257.869141\n",
      "Train Epoch: 4238 [98560/118836 (83%)] Loss: 12298.572266\n",
      "    epoch          : 4238\n",
      "    loss           : 12183.996738006617\n",
      "    val_loss       : 12182.236328456835\n",
      "    val_log_likelihood: -12103.813588515819\n",
      "    val_log_marginal: -12112.722765838074\n",
      "Train Epoch: 4239 [256/118836 (0%)] Loss: 12320.770508\n",
      "Train Epoch: 4239 [33024/118836 (28%)] Loss: 12164.541016\n",
      "Train Epoch: 4239 [65792/118836 (55%)] Loss: 12103.208008\n",
      "Train Epoch: 4239 [98560/118836 (83%)] Loss: 12192.940430\n",
      "    epoch          : 4239\n",
      "    loss           : 12179.86940201096\n",
      "    val_loss       : 12177.702459589767\n",
      "    val_log_likelihood: -12100.978827414185\n",
      "    val_log_marginal: -12109.732305015139\n",
      "Train Epoch: 4240 [256/118836 (0%)] Loss: 12207.315430\n",
      "Train Epoch: 4240 [33024/118836 (28%)] Loss: 12179.889648\n",
      "Train Epoch: 4240 [65792/118836 (55%)] Loss: 12239.822266\n",
      "Train Epoch: 4240 [98560/118836 (83%)] Loss: 12185.593750\n",
      "    epoch          : 4240\n",
      "    loss           : 12181.3575433597\n",
      "    val_loss       : 12179.378492940628\n",
      "    val_log_likelihood: -12101.29039188508\n",
      "    val_log_marginal: -12110.092536511369\n",
      "Train Epoch: 4241 [256/118836 (0%)] Loss: 12149.548828\n",
      "Train Epoch: 4241 [33024/118836 (28%)] Loss: 12156.939453\n",
      "Train Epoch: 4241 [65792/118836 (55%)] Loss: 12153.759766\n",
      "Train Epoch: 4241 [98560/118836 (83%)] Loss: 12180.287109\n",
      "    epoch          : 4241\n",
      "    loss           : 12181.673288875103\n",
      "    val_loss       : 12188.211424339765\n",
      "    val_log_likelihood: -12120.941451645214\n",
      "    val_log_marginal: -12130.121593668639\n",
      "Train Epoch: 4242 [256/118836 (0%)] Loss: 12243.901367\n",
      "Train Epoch: 4242 [33024/118836 (28%)] Loss: 12220.112305\n",
      "Train Epoch: 4242 [65792/118836 (55%)] Loss: 12179.128906\n",
      "Train Epoch: 4242 [98560/118836 (83%)] Loss: 12121.279297\n",
      "    epoch          : 4242\n",
      "    loss           : 12183.256053233561\n",
      "    val_loss       : 12186.910752479242\n",
      "    val_log_likelihood: -12121.544363239247\n",
      "    val_log_marginal: -12130.648741075662\n",
      "Train Epoch: 4243 [256/118836 (0%)] Loss: 12238.867188\n",
      "Train Epoch: 4243 [33024/118836 (28%)] Loss: 12179.791992\n",
      "Train Epoch: 4243 [65792/118836 (55%)] Loss: 12193.969727\n",
      "Train Epoch: 4243 [98560/118836 (83%)] Loss: 12241.623047\n",
      "    epoch          : 4243\n",
      "    loss           : 12186.783518145161\n",
      "    val_loss       : 12183.689743346125\n",
      "    val_log_likelihood: -12104.864673477563\n",
      "    val_log_marginal: -12113.884585772768\n",
      "Train Epoch: 4244 [256/118836 (0%)] Loss: 12190.453125\n",
      "Train Epoch: 4244 [33024/118836 (28%)] Loss: 12174.841797\n",
      "Train Epoch: 4244 [65792/118836 (55%)] Loss: 12190.910156\n",
      "Train Epoch: 4244 [98560/118836 (83%)] Loss: 12197.387695\n",
      "    epoch          : 4244\n",
      "    loss           : 12187.038294335453\n",
      "    val_loss       : 12181.612272166763\n",
      "    val_log_likelihood: -12104.512497415219\n",
      "    val_log_marginal: -12113.536879642726\n",
      "Train Epoch: 4245 [256/118836 (0%)] Loss: 12263.225586\n",
      "Train Epoch: 4245 [33024/118836 (28%)] Loss: 12162.736328\n",
      "Train Epoch: 4245 [65792/118836 (55%)] Loss: 12204.539062\n",
      "Train Epoch: 4245 [98560/118836 (83%)] Loss: 12338.550781\n",
      "    epoch          : 4245\n",
      "    loss           : 12184.0038794329\n",
      "    val_loss       : 12181.745410109615\n",
      "    val_log_likelihood: -12103.725437312603\n",
      "    val_log_marginal: -12112.761717939558\n",
      "Train Epoch: 4246 [256/118836 (0%)] Loss: 12211.277344\n",
      "Train Epoch: 4246 [33024/118836 (28%)] Loss: 12197.068359\n",
      "Train Epoch: 4246 [65792/118836 (55%)] Loss: 12174.348633\n",
      "Train Epoch: 4246 [98560/118836 (83%)] Loss: 12141.723633\n",
      "    epoch          : 4246\n",
      "    loss           : 12182.319561298078\n",
      "    val_loss       : 12185.169835838555\n",
      "    val_log_likelihood: -12105.064935671267\n",
      "    val_log_marginal: -12114.10252468635\n",
      "Train Epoch: 4247 [256/118836 (0%)] Loss: 12276.060547\n",
      "Train Epoch: 4247 [33024/118836 (28%)] Loss: 12184.962891\n",
      "Train Epoch: 4247 [65792/118836 (55%)] Loss: 12149.558594\n",
      "Train Epoch: 4247 [98560/118836 (83%)] Loss: 12222.989258\n",
      "    epoch          : 4247\n",
      "    loss           : 12182.428505608974\n",
      "    val_loss       : 12201.164139077879\n",
      "    val_log_likelihood: -12103.703220152243\n",
      "    val_log_marginal: -12112.833349522918\n",
      "Train Epoch: 4248 [256/118836 (0%)] Loss: 12121.716797\n",
      "Train Epoch: 4248 [33024/118836 (28%)] Loss: 12129.619141\n",
      "Train Epoch: 4248 [65792/118836 (55%)] Loss: 12174.380859\n",
      "Train Epoch: 4248 [98560/118836 (83%)] Loss: 12222.539062\n",
      "    epoch          : 4248\n",
      "    loss           : 12184.39570587133\n",
      "    val_loss       : 12186.820037928237\n",
      "    val_log_likelihood: -12109.55238962986\n",
      "    val_log_marginal: -12118.722089364437\n",
      "Train Epoch: 4249 [256/118836 (0%)] Loss: 12207.372070\n",
      "Train Epoch: 4249 [33024/118836 (28%)] Loss: 12247.370117\n",
      "Train Epoch: 4249 [65792/118836 (55%)] Loss: 12264.326172\n",
      "Train Epoch: 4249 [98560/118836 (83%)] Loss: 12136.759766\n",
      "    epoch          : 4249\n",
      "    loss           : 12181.312212927782\n",
      "    val_loss       : 12182.129089077527\n",
      "    val_log_likelihood: -12105.531619623656\n",
      "    val_log_marginal: -12114.49589203473\n",
      "Train Epoch: 4250 [256/118836 (0%)] Loss: 12172.223633\n",
      "Train Epoch: 4250 [33024/118836 (28%)] Loss: 12151.002930\n",
      "Train Epoch: 4250 [65792/118836 (55%)] Loss: 12354.384766\n",
      "Train Epoch: 4250 [98560/118836 (83%)] Loss: 12125.770508\n",
      "    epoch          : 4250\n",
      "    loss           : 12183.176870735111\n",
      "    val_loss       : 12183.490223581495\n",
      "    val_log_likelihood: -12104.413510003102\n",
      "    val_log_marginal: -12113.379976304226\n",
      "Train Epoch: 4251 [256/118836 (0%)] Loss: 12243.181641\n",
      "Train Epoch: 4251 [33024/118836 (28%)] Loss: 12186.007812\n",
      "Train Epoch: 4251 [65792/118836 (55%)] Loss: 12173.660156\n",
      "Train Epoch: 4251 [98560/118836 (83%)] Loss: 12237.785156\n",
      "    epoch          : 4251\n",
      "    loss           : 12180.779862941998\n",
      "    val_loss       : 12184.509991592226\n",
      "    val_log_likelihood: -12105.622375962832\n",
      "    val_log_marginal: -12114.66309415466\n",
      "Train Epoch: 4252 [256/118836 (0%)] Loss: 12213.009766\n",
      "Train Epoch: 4252 [33024/118836 (28%)] Loss: 12194.529297\n",
      "Train Epoch: 4252 [65792/118836 (55%)] Loss: 12243.753906\n",
      "Train Epoch: 4252 [98560/118836 (83%)] Loss: 12216.939453\n",
      "    epoch          : 4252\n",
      "    loss           : 12179.245896498915\n",
      "    val_loss       : 12181.331889176357\n",
      "    val_log_likelihood: -12103.319063243123\n",
      "    val_log_marginal: -12112.398780683836\n",
      "Train Epoch: 4253 [256/118836 (0%)] Loss: 12313.970703\n",
      "Train Epoch: 4253 [33024/118836 (28%)] Loss: 12195.808594\n",
      "Train Epoch: 4253 [65792/118836 (55%)] Loss: 12300.878906\n",
      "Train Epoch: 4253 [98560/118836 (83%)] Loss: 12188.363281\n",
      "    epoch          : 4253\n",
      "    loss           : 12181.342545330592\n",
      "    val_loss       : 12179.47814601779\n",
      "    val_log_likelihood: -12102.192317546784\n",
      "    val_log_marginal: -12111.152330955898\n",
      "Train Epoch: 4254 [256/118836 (0%)] Loss: 12343.287109\n",
      "Train Epoch: 4254 [33024/118836 (28%)] Loss: 12261.022461\n",
      "Train Epoch: 4254 [65792/118836 (55%)] Loss: 12174.387695\n",
      "Train Epoch: 4254 [98560/118836 (83%)] Loss: 12161.853516\n",
      "    epoch          : 4254\n",
      "    loss           : 12180.030672463037\n",
      "    val_loss       : 12181.497695714392\n",
      "    val_log_likelihood: -12100.021597459161\n",
      "    val_log_marginal: -12108.979399946676\n",
      "Train Epoch: 4255 [256/118836 (0%)] Loss: 12223.239258\n",
      "Train Epoch: 4255 [33024/118836 (28%)] Loss: 12279.955078\n",
      "Train Epoch: 4255 [65792/118836 (55%)] Loss: 12166.117188\n",
      "Train Epoch: 4255 [98560/118836 (83%)] Loss: 12247.611328\n",
      "    epoch          : 4255\n",
      "    loss           : 12176.597092283137\n",
      "    val_loss       : 12181.173209345368\n",
      "    val_log_likelihood: -12102.636679493642\n",
      "    val_log_marginal: -12111.379336355842\n",
      "Train Epoch: 4256 [256/118836 (0%)] Loss: 12259.719727\n",
      "Train Epoch: 4256 [33024/118836 (28%)] Loss: 12220.914062\n",
      "Train Epoch: 4256 [65792/118836 (55%)] Loss: 12151.889648\n",
      "Train Epoch: 4256 [98560/118836 (83%)] Loss: 12229.599609\n",
      "    epoch          : 4256\n",
      "    loss           : 12180.400085136218\n",
      "    val_loss       : 12181.971052501356\n",
      "    val_log_likelihood: -12100.42611242504\n",
      "    val_log_marginal: -12109.330327668335\n",
      "Train Epoch: 4257 [256/118836 (0%)] Loss: 12230.785156\n",
      "Train Epoch: 4257 [33024/118836 (28%)] Loss: 12140.041992\n",
      "Train Epoch: 4257 [65792/118836 (55%)] Loss: 12133.720703\n",
      "Train Epoch: 4257 [98560/118836 (83%)] Loss: 12241.797852\n",
      "    epoch          : 4257\n",
      "    loss           : 12181.008500374794\n",
      "    val_loss       : 12179.587466713137\n",
      "    val_log_likelihood: -12103.486151229063\n",
      "    val_log_marginal: -12112.279957437055\n",
      "Train Epoch: 4258 [256/118836 (0%)] Loss: 12211.399414\n",
      "Train Epoch: 4258 [33024/118836 (28%)] Loss: 12173.553711\n",
      "Train Epoch: 4258 [65792/118836 (55%)] Loss: 12141.367188\n",
      "Train Epoch: 4258 [98560/118836 (83%)] Loss: 12219.337891\n",
      "    epoch          : 4258\n",
      "    loss           : 12181.38967008504\n",
      "    val_loss       : 12180.867812024355\n",
      "    val_log_likelihood: -12103.653178634202\n",
      "    val_log_marginal: -12112.467124626206\n",
      "Train Epoch: 4259 [256/118836 (0%)] Loss: 12143.791016\n",
      "Train Epoch: 4259 [33024/118836 (28%)] Loss: 12232.007812\n",
      "Train Epoch: 4259 [65792/118836 (55%)] Loss: 12152.706055\n",
      "Train Epoch: 4259 [98560/118836 (83%)] Loss: 12104.245117\n",
      "    epoch          : 4259\n",
      "    loss           : 12183.25475357346\n",
      "    val_loss       : 12180.681003238828\n",
      "    val_log_likelihood: -12102.651612095482\n",
      "    val_log_marginal: -12111.388542401352\n",
      "Train Epoch: 4260 [256/118836 (0%)] Loss: 12208.551758\n",
      "Train Epoch: 4260 [33024/118836 (28%)] Loss: 12184.665039\n",
      "Train Epoch: 4260 [65792/118836 (55%)] Loss: 12128.748047\n",
      "Train Epoch: 4260 [98560/118836 (83%)] Loss: 12218.751953\n",
      "    epoch          : 4260\n",
      "    loss           : 12178.652957473894\n",
      "    val_loss       : 12181.817518481903\n",
      "    val_log_likelihood: -12098.114246827181\n",
      "    val_log_marginal: -12106.926328164454\n",
      "Train Epoch: 4261 [256/118836 (0%)] Loss: 12176.016602\n",
      "Train Epoch: 4261 [33024/118836 (28%)] Loss: 12180.068359\n",
      "Train Epoch: 4261 [65792/118836 (55%)] Loss: 12185.564453\n",
      "Train Epoch: 4261 [98560/118836 (83%)] Loss: 12232.351562\n",
      "    epoch          : 4261\n",
      "    loss           : 12182.171060955592\n",
      "    val_loss       : 12181.160537226915\n",
      "    val_log_likelihood: -12100.013946669511\n",
      "    val_log_marginal: -12108.745025560946\n",
      "Train Epoch: 4262 [256/118836 (0%)] Loss: 12152.300781\n",
      "Train Epoch: 4262 [33024/118836 (28%)] Loss: 12236.148438\n",
      "Train Epoch: 4262 [65792/118836 (55%)] Loss: 12205.794922\n",
      "Train Epoch: 4262 [98560/118836 (83%)] Loss: 12329.519531\n",
      "    epoch          : 4262\n",
      "    loss           : 12184.610036057693\n",
      "    val_loss       : 12182.279956459419\n",
      "    val_log_likelihood: -12100.349518584575\n",
      "    val_log_marginal: -12109.06439679202\n",
      "Train Epoch: 4263 [256/118836 (0%)] Loss: 12214.408203\n",
      "Train Epoch: 4263 [33024/118836 (28%)] Loss: 12232.270508\n",
      "Train Epoch: 4263 [65792/118836 (55%)] Loss: 12094.695312\n",
      "Train Epoch: 4263 [98560/118836 (83%)] Loss: 12216.623047\n",
      "    epoch          : 4263\n",
      "    loss           : 12180.979362625363\n",
      "    val_loss       : 12178.967963516268\n",
      "    val_log_likelihood: -12100.883229619005\n",
      "    val_log_marginal: -12109.672085024411\n",
      "Train Epoch: 4264 [256/118836 (0%)] Loss: 12379.254883\n",
      "Train Epoch: 4264 [33024/118836 (28%)] Loss: 12254.432617\n",
      "Train Epoch: 4264 [65792/118836 (55%)] Loss: 12214.873047\n",
      "Train Epoch: 4264 [98560/118836 (83%)] Loss: 12226.221680\n",
      "    epoch          : 4264\n",
      "    loss           : 12182.202160230563\n",
      "    val_loss       : 12182.091662155464\n",
      "    val_log_likelihood: -12101.887670110887\n",
      "    val_log_marginal: -12110.650159024868\n",
      "Train Epoch: 4265 [256/118836 (0%)] Loss: 12115.943359\n",
      "Train Epoch: 4265 [33024/118836 (28%)] Loss: 12265.864258\n",
      "Train Epoch: 4265 [65792/118836 (55%)] Loss: 12189.577148\n",
      "Train Epoch: 4265 [98560/118836 (83%)] Loss: 12177.032227\n",
      "    epoch          : 4265\n",
      "    loss           : 12183.799813895781\n",
      "    val_loss       : 12182.304487184632\n",
      "    val_log_likelihood: -12102.275910004395\n",
      "    val_log_marginal: -12111.170975913483\n",
      "Train Epoch: 4266 [256/118836 (0%)] Loss: 12209.207031\n",
      "Train Epoch: 4266 [33024/118836 (28%)] Loss: 12253.771484\n",
      "Train Epoch: 4266 [65792/118836 (55%)] Loss: 12209.226562\n",
      "Train Epoch: 4266 [98560/118836 (83%)] Loss: 12160.987305\n",
      "    epoch          : 4266\n",
      "    loss           : 12184.112309049318\n",
      "    val_loss       : 12178.169747357671\n",
      "    val_log_likelihood: -12101.997089698356\n",
      "    val_log_marginal: -12110.888168658525\n",
      "Train Epoch: 4267 [256/118836 (0%)] Loss: 12176.315430\n",
      "Train Epoch: 4267 [33024/118836 (28%)] Loss: 12159.642578\n",
      "Train Epoch: 4267 [65792/118836 (55%)] Loss: 12342.387695\n",
      "Train Epoch: 4267 [98560/118836 (83%)] Loss: 12350.232422\n",
      "    epoch          : 4267\n",
      "    loss           : 12184.31582709755\n",
      "    val_loss       : 12182.736898836589\n",
      "    val_log_likelihood: -12101.469462914856\n",
      "    val_log_marginal: -12110.365538748612\n",
      "Train Epoch: 4268 [256/118836 (0%)] Loss: 12298.563477\n",
      "Train Epoch: 4268 [33024/118836 (28%)] Loss: 12149.714844\n",
      "Train Epoch: 4268 [65792/118836 (55%)] Loss: 12176.703125\n",
      "Train Epoch: 4268 [98560/118836 (83%)] Loss: 12165.799805\n",
      "    epoch          : 4268\n",
      "    loss           : 12182.081117691532\n",
      "    val_loss       : 12183.553351015422\n",
      "    val_log_likelihood: -12099.494048703733\n",
      "    val_log_marginal: -12108.40919086786\n",
      "Train Epoch: 4269 [256/118836 (0%)] Loss: 12100.660156\n",
      "Train Epoch: 4269 [33024/118836 (28%)] Loss: 12308.033203\n",
      "Train Epoch: 4269 [65792/118836 (55%)] Loss: 12131.309570\n",
      "Train Epoch: 4269 [98560/118836 (83%)] Loss: 12163.431641\n",
      "    epoch          : 4269\n",
      "    loss           : 12182.618563411135\n",
      "    val_loss       : 12179.452547550218\n",
      "    val_log_likelihood: -12100.126002410309\n",
      "    val_log_marginal: -12109.05511658546\n",
      "Train Epoch: 4270 [256/118836 (0%)] Loss: 12158.308594\n",
      "Train Epoch: 4270 [33024/118836 (28%)] Loss: 12166.773438\n",
      "Train Epoch: 4270 [65792/118836 (55%)] Loss: 12211.899414\n",
      "Train Epoch: 4270 [98560/118836 (83%)] Loss: 12195.351562\n",
      "    epoch          : 4270\n",
      "    loss           : 12184.215695758374\n",
      "    val_loss       : 12182.831061271092\n",
      "    val_log_likelihood: -12102.41399513415\n",
      "    val_log_marginal: -12111.224782351987\n",
      "Train Epoch: 4271 [256/118836 (0%)] Loss: 12196.598633\n",
      "Train Epoch: 4271 [33024/118836 (28%)] Loss: 12188.810547\n",
      "Train Epoch: 4271 [65792/118836 (55%)] Loss: 12327.053711\n",
      "Train Epoch: 4271 [98560/118836 (83%)] Loss: 12225.216797\n",
      "    epoch          : 4271\n",
      "    loss           : 12182.257525104684\n",
      "    val_loss       : 12182.116398173694\n",
      "    val_log_likelihood: -12102.094449990953\n",
      "    val_log_marginal: -12111.009382958096\n",
      "Train Epoch: 4272 [256/118836 (0%)] Loss: 12172.467773\n",
      "Train Epoch: 4272 [33024/118836 (28%)] Loss: 12150.522461\n",
      "Train Epoch: 4272 [65792/118836 (55%)] Loss: 12160.082031\n",
      "Train Epoch: 4272 [98560/118836 (83%)] Loss: 12177.416016\n",
      "    epoch          : 4272\n",
      "    loss           : 12179.808834619262\n",
      "    val_loss       : 12182.983608756771\n",
      "    val_log_likelihood: -12100.05239366858\n",
      "    val_log_marginal: -12109.00986549929\n",
      "Train Epoch: 4273 [256/118836 (0%)] Loss: 12323.170898\n",
      "Train Epoch: 4273 [33024/118836 (28%)] Loss: 12216.452148\n",
      "Train Epoch: 4273 [65792/118836 (55%)] Loss: 12230.048828\n",
      "Train Epoch: 4273 [98560/118836 (83%)] Loss: 12156.113281\n",
      "    epoch          : 4273\n",
      "    loss           : 12178.57060312629\n",
      "    val_loss       : 12181.7765430282\n",
      "    val_log_likelihood: -12099.42761563663\n",
      "    val_log_marginal: -12108.375966200738\n",
      "Train Epoch: 4274 [256/118836 (0%)] Loss: 12210.066406\n",
      "Train Epoch: 4274 [33024/118836 (28%)] Loss: 12198.152344\n",
      "Train Epoch: 4274 [65792/118836 (55%)] Loss: 12197.692383\n",
      "Train Epoch: 4274 [98560/118836 (83%)] Loss: 12125.447266\n",
      "    epoch          : 4274\n",
      "    loss           : 12175.707512988523\n",
      "    val_loss       : 12180.920100587222\n",
      "    val_log_likelihood: -12101.681902334058\n",
      "    val_log_marginal: -12110.500264079174\n",
      "Train Epoch: 4275 [256/118836 (0%)] Loss: 12179.521484\n",
      "Train Epoch: 4275 [33024/118836 (28%)] Loss: 12292.850586\n",
      "Train Epoch: 4275 [65792/118836 (55%)] Loss: 12384.000977\n",
      "Train Epoch: 4275 [98560/118836 (83%)] Loss: 12240.315430\n",
      "    epoch          : 4275\n",
      "    loss           : 12179.522144948047\n",
      "    val_loss       : 12184.482256104679\n",
      "    val_log_likelihood: -12102.792574409377\n",
      "    val_log_marginal: -12111.633666601325\n",
      "Train Epoch: 4276 [256/118836 (0%)] Loss: 12276.783203\n",
      "Train Epoch: 4276 [33024/118836 (28%)] Loss: 12166.302734\n",
      "Train Epoch: 4276 [65792/118836 (55%)] Loss: 12249.485352\n",
      "Train Epoch: 4276 [98560/118836 (83%)] Loss: 12233.115234\n",
      "    epoch          : 4276\n",
      "    loss           : 12181.492983774038\n",
      "    val_loss       : 12180.175656002531\n",
      "    val_log_likelihood: -12098.925060096155\n",
      "    val_log_marginal: -12107.760285365013\n",
      "Train Epoch: 4277 [256/118836 (0%)] Loss: 12190.767578\n",
      "Train Epoch: 4277 [33024/118836 (28%)] Loss: 12189.601562\n",
      "Train Epoch: 4277 [65792/118836 (55%)] Loss: 12214.320312\n",
      "Train Epoch: 4277 [98560/118836 (83%)] Loss: 12129.161133\n",
      "    epoch          : 4277\n",
      "    loss           : 12188.022157387304\n",
      "    val_loss       : 12181.166457226635\n",
      "    val_log_likelihood: -12100.678739531639\n",
      "    val_log_marginal: -12109.470657774771\n",
      "Train Epoch: 4278 [256/118836 (0%)] Loss: 12170.895508\n",
      "Train Epoch: 4278 [33024/118836 (28%)] Loss: 12193.590820\n",
      "Train Epoch: 4278 [65792/118836 (55%)] Loss: 12165.080078\n",
      "Train Epoch: 4278 [98560/118836 (83%)] Loss: 12180.831055\n",
      "    epoch          : 4278\n",
      "    loss           : 12182.69076651675\n",
      "    val_loss       : 12183.804764108403\n",
      "    val_log_likelihood: -12102.259207473893\n",
      "    val_log_marginal: -12111.106206041497\n",
      "Train Epoch: 4279 [256/118836 (0%)] Loss: 12177.173828\n",
      "Train Epoch: 4279 [33024/118836 (28%)] Loss: 12367.285156\n",
      "Train Epoch: 4279 [65792/118836 (55%)] Loss: 12173.638672\n",
      "Train Epoch: 4279 [98560/118836 (83%)] Loss: 12208.621094\n",
      "    epoch          : 4279\n",
      "    loss           : 12176.749075133117\n",
      "    val_loss       : 12183.854524576238\n",
      "    val_log_likelihood: -12099.646325087882\n",
      "    val_log_marginal: -12108.366441923215\n",
      "Train Epoch: 4280 [256/118836 (0%)] Loss: 12132.757812\n",
      "Train Epoch: 4280 [33024/118836 (28%)] Loss: 12336.070312\n",
      "Train Epoch: 4280 [65792/118836 (55%)] Loss: 12148.129883\n",
      "Train Epoch: 4280 [98560/118836 (83%)] Loss: 12174.628906\n",
      "    epoch          : 4280\n",
      "    loss           : 12181.134853345999\n",
      "    val_loss       : 12180.990402822506\n",
      "    val_log_likelihood: -12102.699961389837\n",
      "    val_log_marginal: -12111.527215376771\n",
      "Train Epoch: 4281 [256/118836 (0%)] Loss: 12168.864258\n",
      "Train Epoch: 4281 [33024/118836 (28%)] Loss: 12197.331055\n",
      "Train Epoch: 4281 [65792/118836 (55%)] Loss: 12180.444336\n",
      "Train Epoch: 4281 [98560/118836 (83%)] Loss: 12169.225586\n",
      "    epoch          : 4281\n",
      "    loss           : 12183.667667138388\n",
      "    val_loss       : 12180.55551736896\n",
      "    val_log_likelihood: -12101.711036529414\n",
      "    val_log_marginal: -12110.617131851708\n",
      "Train Epoch: 4282 [256/118836 (0%)] Loss: 12284.488281\n",
      "Train Epoch: 4282 [33024/118836 (28%)] Loss: 12146.121094\n",
      "Train Epoch: 4282 [65792/118836 (55%)] Loss: 12420.779297\n",
      "Train Epoch: 4282 [98560/118836 (83%)] Loss: 12225.233398\n",
      "    epoch          : 4282\n",
      "    loss           : 12181.785237347498\n",
      "    val_loss       : 12180.900612737167\n",
      "    val_log_likelihood: -12107.795606518817\n",
      "    val_log_marginal: -12116.71312146994\n",
      "Train Epoch: 4283 [256/118836 (0%)] Loss: 12253.033203\n",
      "Train Epoch: 4283 [33024/118836 (28%)] Loss: 12228.525391\n",
      "Train Epoch: 4283 [65792/118836 (55%)] Loss: 12173.859375\n",
      "Train Epoch: 4283 [98560/118836 (83%)] Loss: 12358.726562\n",
      "    epoch          : 4283\n",
      "    loss           : 12178.86098854942\n",
      "    val_loss       : 12183.994260339652\n",
      "    val_log_likelihood: -12101.245568070202\n",
      "    val_log_marginal: -12109.957984096422\n",
      "Train Epoch: 4284 [256/118836 (0%)] Loss: 12158.429688\n",
      "Train Epoch: 4284 [33024/118836 (28%)] Loss: 12163.789062\n",
      "Train Epoch: 4284 [65792/118836 (55%)] Loss: 12218.508789\n",
      "Train Epoch: 4284 [98560/118836 (83%)] Loss: 12223.500000\n",
      "    epoch          : 4284\n",
      "    loss           : 12180.585378379601\n",
      "    val_loss       : 12178.107764818262\n",
      "    val_log_likelihood: -12100.92940592044\n",
      "    val_log_marginal: -12109.707746214102\n",
      "Train Epoch: 4285 [256/118836 (0%)] Loss: 12224.017578\n",
      "Train Epoch: 4285 [33024/118836 (28%)] Loss: 12171.902344\n",
      "Train Epoch: 4285 [65792/118836 (55%)] Loss: 12170.455078\n",
      "Train Epoch: 4285 [98560/118836 (83%)] Loss: 12345.115234\n",
      "    epoch          : 4285\n",
      "    loss           : 12181.326882043528\n",
      "    val_loss       : 12180.174857261865\n",
      "    val_log_likelihood: -12101.821048516336\n",
      "    val_log_marginal: -12110.709619638732\n",
      "Train Epoch: 4286 [256/118836 (0%)] Loss: 12199.143555\n",
      "Train Epoch: 4286 [33024/118836 (28%)] Loss: 12176.354492\n",
      "Train Epoch: 4286 [65792/118836 (55%)] Loss: 12120.175781\n",
      "Train Epoch: 4286 [98560/118836 (83%)] Loss: 12152.263672\n",
      "    epoch          : 4286\n",
      "    loss           : 12174.960579507859\n",
      "    val_loss       : 12183.142514442938\n",
      "    val_log_likelihood: -12102.716062312604\n",
      "    val_log_marginal: -12111.667371916186\n",
      "Train Epoch: 4287 [256/118836 (0%)] Loss: 12208.322266\n",
      "Train Epoch: 4287 [33024/118836 (28%)] Loss: 12169.230469\n",
      "Train Epoch: 4287 [65792/118836 (55%)] Loss: 12159.892578\n",
      "Train Epoch: 4287 [98560/118836 (83%)] Loss: 12134.894531\n",
      "    epoch          : 4287\n",
      "    loss           : 12180.353414172352\n",
      "    val_loss       : 12177.509925989292\n",
      "    val_log_likelihood: -12105.289898191944\n",
      "    val_log_marginal: -12114.172098611269\n",
      "Train Epoch: 4288 [256/118836 (0%)] Loss: 12176.798828\n",
      "Train Epoch: 4288 [33024/118836 (28%)] Loss: 12295.665039\n",
      "Train Epoch: 4288 [65792/118836 (55%)] Loss: 12240.529297\n",
      "Train Epoch: 4288 [98560/118836 (83%)] Loss: 12241.161133\n",
      "    epoch          : 4288\n",
      "    loss           : 12180.712655571495\n",
      "    val_loss       : 12183.968052037351\n",
      "    val_log_likelihood: -12103.74916366186\n",
      "    val_log_marginal: -12112.761284318933\n",
      "Train Epoch: 4289 [256/118836 (0%)] Loss: 12332.429688\n",
      "Train Epoch: 4289 [33024/118836 (28%)] Loss: 12184.063477\n",
      "Train Epoch: 4289 [65792/118836 (55%)] Loss: 12252.311523\n",
      "Train Epoch: 4289 [98560/118836 (83%)] Loss: 12262.195312\n",
      "    epoch          : 4289\n",
      "    loss           : 12176.784785172405\n",
      "    val_loss       : 12181.667111631827\n",
      "    val_log_likelihood: -12101.820503127585\n",
      "    val_log_marginal: -12110.7206575885\n",
      "Train Epoch: 4290 [256/118836 (0%)] Loss: 12146.341797\n",
      "Train Epoch: 4290 [33024/118836 (28%)] Loss: 12176.819336\n",
      "Train Epoch: 4290 [65792/118836 (55%)] Loss: 12149.541016\n",
      "Train Epoch: 4290 [98560/118836 (83%)] Loss: 12153.027344\n",
      "    epoch          : 4290\n",
      "    loss           : 12181.277731951768\n",
      "    val_loss       : 12179.167563495206\n",
      "    val_log_likelihood: -12101.66991654389\n",
      "    val_log_marginal: -12110.572150308592\n",
      "Train Epoch: 4291 [256/118836 (0%)] Loss: 12214.420898\n",
      "Train Epoch: 4291 [33024/118836 (28%)] Loss: 12216.890625\n",
      "Train Epoch: 4291 [65792/118836 (55%)] Loss: 12162.242188\n",
      "Train Epoch: 4291 [98560/118836 (83%)] Loss: 12166.015625\n",
      "    epoch          : 4291\n",
      "    loss           : 12181.881068257599\n",
      "    val_loss       : 12194.734680654516\n",
      "    val_log_likelihood: -12103.779883135598\n",
      "    val_log_marginal: -12112.787097077593\n",
      "Train Epoch: 4292 [256/118836 (0%)] Loss: 12144.240234\n",
      "Train Epoch: 4292 [33024/118836 (28%)] Loss: 12344.320312\n",
      "Train Epoch: 4292 [65792/118836 (55%)] Loss: 12178.817383\n",
      "Train Epoch: 4292 [98560/118836 (83%)] Loss: 12154.353516\n",
      "    epoch          : 4292\n",
      "    loss           : 12176.699933280344\n",
      "    val_loss       : 12180.57425013785\n",
      "    val_log_likelihood: -12104.125351368642\n",
      "    val_log_marginal: -12112.897555346524\n",
      "Train Epoch: 4293 [256/118836 (0%)] Loss: 12211.798828\n",
      "Train Epoch: 4293 [33024/118836 (28%)] Loss: 12152.280273\n",
      "Train Epoch: 4293 [65792/118836 (55%)] Loss: 12209.708008\n",
      "Train Epoch: 4293 [98560/118836 (83%)] Loss: 12172.355469\n",
      "    epoch          : 4293\n",
      "    loss           : 12178.544601362179\n",
      "    val_loss       : 12182.023540210555\n",
      "    val_log_likelihood: -12100.810967386527\n",
      "    val_log_marginal: -12109.640335016089\n",
      "Train Epoch: 4294 [256/118836 (0%)] Loss: 12152.859375\n",
      "Train Epoch: 4294 [33024/118836 (28%)] Loss: 12128.430664\n",
      "Train Epoch: 4294 [65792/118836 (55%)] Loss: 12156.519531\n",
      "Train Epoch: 4294 [98560/118836 (83%)] Loss: 12257.894531\n",
      "    epoch          : 4294\n",
      "    loss           : 12181.804003179279\n",
      "    val_loss       : 12185.430564193775\n",
      "    val_log_likelihood: -12104.75428734362\n",
      "    val_log_marginal: -12113.63090104099\n",
      "Train Epoch: 4295 [256/118836 (0%)] Loss: 12167.496094\n",
      "Train Epoch: 4295 [33024/118836 (28%)] Loss: 12214.268555\n",
      "Train Epoch: 4295 [65792/118836 (55%)] Loss: 12282.864258\n",
      "Train Epoch: 4295 [98560/118836 (83%)] Loss: 12148.070312\n",
      "    epoch          : 4295\n",
      "    loss           : 12180.134275809036\n",
      "    val_loss       : 12182.586005077108\n",
      "    val_log_likelihood: -12100.094760164651\n",
      "    val_log_marginal: -12109.019395834997\n",
      "Train Epoch: 4296 [256/118836 (0%)] Loss: 12191.536133\n",
      "Train Epoch: 4296 [33024/118836 (28%)] Loss: 12283.520508\n",
      "Train Epoch: 4296 [65792/118836 (55%)] Loss: 12233.129883\n",
      "Train Epoch: 4296 [98560/118836 (83%)] Loss: 12150.589844\n",
      "    epoch          : 4296\n",
      "    loss           : 12179.550572044302\n",
      "    val_loss       : 12183.998536531113\n",
      "    val_log_likelihood: -12102.008731712674\n",
      "    val_log_marginal: -12110.929933555068\n",
      "Train Epoch: 4297 [256/118836 (0%)] Loss: 12212.707031\n",
      "Train Epoch: 4297 [33024/118836 (28%)] Loss: 12185.587891\n",
      "Train Epoch: 4297 [65792/118836 (55%)] Loss: 12199.512695\n",
      "Train Epoch: 4297 [98560/118836 (83%)] Loss: 12258.395508\n",
      "    epoch          : 4297\n",
      "    loss           : 12183.751535521349\n",
      "    val_loss       : 12188.17315560531\n",
      "    val_log_likelihood: -12103.509445435277\n",
      "    val_log_marginal: -12112.527108613205\n",
      "Train Epoch: 4298 [256/118836 (0%)] Loss: 12233.131836\n",
      "Train Epoch: 4298 [33024/118836 (28%)] Loss: 12276.547852\n",
      "Train Epoch: 4298 [65792/118836 (55%)] Loss: 12312.393555\n",
      "Train Epoch: 4298 [98560/118836 (83%)] Loss: 12209.089844\n",
      "    epoch          : 4298\n",
      "    loss           : 12182.670447716346\n",
      "    val_loss       : 12186.04896306105\n",
      "    val_log_likelihood: -12100.711539269283\n",
      "    val_log_marginal: -12109.671714398979\n",
      "Train Epoch: 4299 [256/118836 (0%)] Loss: 12291.504883\n",
      "Train Epoch: 4299 [33024/118836 (28%)] Loss: 12187.259766\n",
      "Train Epoch: 4299 [65792/118836 (55%)] Loss: 12283.202148\n",
      "Train Epoch: 4299 [98560/118836 (83%)] Loss: 12179.662109\n",
      "    epoch          : 4299\n",
      "    loss           : 12183.026475586747\n",
      "    val_loss       : 12181.451117171231\n",
      "    val_log_likelihood: -12103.257574538617\n",
      "    val_log_marginal: -12112.29259030681\n",
      "Train Epoch: 4300 [256/118836 (0%)] Loss: 12124.477539\n",
      "Train Epoch: 4300 [33024/118836 (28%)] Loss: 12243.879883\n",
      "Train Epoch: 4300 [65792/118836 (55%)] Loss: 12147.222656\n",
      "Train Epoch: 4300 [98560/118836 (83%)] Loss: 12101.669922\n",
      "    epoch          : 4300\n",
      "    loss           : 12179.573251234233\n",
      "    val_loss       : 12187.189633052241\n",
      "    val_log_likelihood: -12103.259953667804\n",
      "    val_log_marginal: -12112.181564648401\n",
      "Saving checkpoint: saved/models/SelfiesAutoencodingOperad/0905_154251/checkpoint-epoch4300.pth ...\n",
      "Train Epoch: 4301 [256/118836 (0%)] Loss: 12148.070312\n",
      "Train Epoch: 4301 [33024/118836 (28%)] Loss: 12278.595703\n",
      "Train Epoch: 4301 [65792/118836 (55%)] Loss: 12301.103516\n",
      "Train Epoch: 4301 [98560/118836 (83%)] Loss: 12318.082031\n",
      "    epoch          : 4301\n",
      "    loss           : 12179.687232313638\n",
      "    val_loss       : 12182.075826633596\n",
      "    val_log_likelihood: -12100.273272397124\n",
      "    val_log_marginal: -12109.22036499114\n",
      "Train Epoch: 4302 [256/118836 (0%)] Loss: 12141.197266\n",
      "Train Epoch: 4302 [33024/118836 (28%)] Loss: 12179.940430\n",
      "Train Epoch: 4302 [65792/118836 (55%)] Loss: 12159.264648\n",
      "Train Epoch: 4302 [98560/118836 (83%)] Loss: 12155.173828\n",
      "    epoch          : 4302\n",
      "    loss           : 12179.5578194466\n",
      "    val_loss       : 12180.12815994518\n",
      "    val_log_likelihood: -12103.631727053607\n",
      "    val_log_marginal: -12112.414970349151\n",
      "Train Epoch: 4303 [256/118836 (0%)] Loss: 12224.352539\n",
      "Train Epoch: 4303 [33024/118836 (28%)] Loss: 12245.830078\n",
      "Train Epoch: 4303 [65792/118836 (55%)] Loss: 12217.564453\n",
      "Train Epoch: 4303 [98560/118836 (83%)] Loss: 12183.742188\n",
      "    epoch          : 4303\n",
      "    loss           : 12181.085867872467\n",
      "    val_loss       : 12183.091765779356\n",
      "    val_log_likelihood: -12102.697698737335\n",
      "    val_log_marginal: -12111.55684828958\n",
      "Train Epoch: 4304 [256/118836 (0%)] Loss: 12331.681641\n",
      "Train Epoch: 4304 [33024/118836 (28%)] Loss: 12214.139648\n",
      "Train Epoch: 4304 [65792/118836 (55%)] Loss: 12164.951172\n",
      "Train Epoch: 4304 [98560/118836 (83%)] Loss: 12172.818359\n",
      "    epoch          : 4304\n",
      "    loss           : 12181.260016510287\n",
      "    val_loss       : 12177.588605227502\n",
      "    val_log_likelihood: -12100.674856383117\n",
      "    val_log_marginal: -12109.64212225334\n",
      "Train Epoch: 4305 [256/118836 (0%)] Loss: 12175.938477\n",
      "Train Epoch: 4305 [33024/118836 (28%)] Loss: 12118.348633\n",
      "Train Epoch: 4305 [65792/118836 (55%)] Loss: 12235.795898\n",
      "Train Epoch: 4305 [98560/118836 (83%)] Loss: 12092.837891\n",
      "    epoch          : 4305\n",
      "    loss           : 12176.889837611147\n",
      "    val_loss       : 12177.031079705417\n",
      "    val_log_likelihood: -12101.160302290116\n",
      "    val_log_marginal: -12109.923683561348\n",
      "Train Epoch: 4306 [256/118836 (0%)] Loss: 12129.345703\n",
      "Train Epoch: 4306 [33024/118836 (28%)] Loss: 12160.750977\n",
      "Train Epoch: 4306 [65792/118836 (55%)] Loss: 12133.148438\n",
      "Train Epoch: 4306 [98560/118836 (83%)] Loss: 12152.781250\n",
      "    epoch          : 4306\n",
      "    loss           : 12182.514086086125\n",
      "    val_loss       : 12185.626344934213\n",
      "    val_log_likelihood: -12106.733644153226\n",
      "    val_log_marginal: -12115.651779270036\n",
      "Train Epoch: 4307 [256/118836 (0%)] Loss: 12297.792969\n",
      "Train Epoch: 4307 [33024/118836 (28%)] Loss: 12174.793945\n",
      "Train Epoch: 4307 [65792/118836 (55%)] Loss: 12259.353516\n",
      "Train Epoch: 4307 [98560/118836 (83%)] Loss: 12209.564453\n",
      "    epoch          : 4307\n",
      "    loss           : 12189.191914967174\n",
      "    val_loss       : 12195.46356835727\n",
      "    val_log_likelihood: -12106.152433248037\n",
      "    val_log_marginal: -12115.234893540157\n",
      "Train Epoch: 4308 [256/118836 (0%)] Loss: 12283.621094\n",
      "Train Epoch: 4308 [33024/118836 (28%)] Loss: 12227.321289\n",
      "Train Epoch: 4308 [65792/118836 (55%)] Loss: 12190.821289\n",
      "Train Epoch: 4308 [98560/118836 (83%)] Loss: 12125.119141\n",
      "    epoch          : 4308\n",
      "    loss           : 12187.76755663901\n",
      "    val_loss       : 12192.765386107108\n",
      "    val_log_likelihood: -12098.404305598635\n",
      "    val_log_marginal: -12107.701858514225\n",
      "Train Epoch: 4309 [256/118836 (0%)] Loss: 12219.486328\n",
      "Train Epoch: 4309 [33024/118836 (28%)] Loss: 12191.697266\n",
      "Train Epoch: 4309 [65792/118836 (55%)] Loss: 12128.213867\n",
      "Train Epoch: 4309 [98560/118836 (83%)] Loss: 12194.969727\n",
      "    epoch          : 4309\n",
      "    loss           : 12184.795730103651\n",
      "    val_loss       : 12190.425210576399\n",
      "    val_log_likelihood: -12104.506968084419\n",
      "    val_log_marginal: -12113.727485750414\n",
      "Train Epoch: 4310 [256/118836 (0%)] Loss: 12189.964844\n",
      "Train Epoch: 4310 [33024/118836 (28%)] Loss: 12242.498047\n",
      "Train Epoch: 4310 [65792/118836 (55%)] Loss: 12246.238281\n",
      "Train Epoch: 4310 [98560/118836 (83%)] Loss: 12174.904297\n",
      "    epoch          : 4310\n",
      "    loss           : 12188.127498029104\n",
      "    val_loss       : 12190.39402986488\n",
      "    val_log_likelihood: -12103.449548309552\n",
      "    val_log_marginal: -12112.557380978855\n",
      "Train Epoch: 4311 [256/118836 (0%)] Loss: 12265.066406\n",
      "Train Epoch: 4311 [33024/118836 (28%)] Loss: 12193.131836\n",
      "Train Epoch: 4311 [65792/118836 (55%)] Loss: 12209.660156\n",
      "Train Epoch: 4311 [98560/118836 (83%)] Loss: 12180.742188\n",
      "    epoch          : 4311\n",
      "    loss           : 12186.645854657774\n",
      "    val_loss       : 12188.188052675623\n",
      "    val_log_likelihood: -12105.90234924266\n",
      "    val_log_marginal: -12115.112044106147\n",
      "Train Epoch: 4312 [256/118836 (0%)] Loss: 12199.190430\n",
      "Train Epoch: 4312 [33024/118836 (28%)] Loss: 12252.113281\n",
      "Train Epoch: 4312 [65792/118836 (55%)] Loss: 12243.862305\n",
      "Train Epoch: 4312 [98560/118836 (83%)] Loss: 12194.323242\n",
      "    epoch          : 4312\n",
      "    loss           : 12183.54592509305\n",
      "    val_loss       : 12190.58505917715\n",
      "    val_log_likelihood: -12104.457825747002\n",
      "    val_log_marginal: -12113.552606147836\n",
      "Train Epoch: 4313 [256/118836 (0%)] Loss: 12335.825195\n",
      "Train Epoch: 4313 [33024/118836 (28%)] Loss: 12277.175781\n",
      "Train Epoch: 4313 [65792/118836 (55%)] Loss: 12291.481445\n",
      "Train Epoch: 4313 [98560/118836 (83%)] Loss: 12164.298828\n",
      "    epoch          : 4313\n",
      "    loss           : 12183.89933344965\n",
      "    val_loss       : 12183.191580904746\n",
      "    val_log_likelihood: -12103.2049705335\n",
      "    val_log_marginal: -12112.211021009514\n",
      "Train Epoch: 4314 [256/118836 (0%)] Loss: 12300.723633\n",
      "Train Epoch: 4314 [33024/118836 (28%)] Loss: 12122.109375\n",
      "Train Epoch: 4314 [65792/118836 (55%)] Loss: 12138.396484\n",
      "Train Epoch: 4314 [98560/118836 (83%)] Loss: 12283.762695\n",
      "    epoch          : 4314\n",
      "    loss           : 12183.19881600884\n",
      "    val_loss       : 12179.69808795998\n",
      "    val_log_likelihood: -12103.378015469914\n",
      "    val_log_marginal: -12112.393616747158\n",
      "Train Epoch: 4315 [256/118836 (0%)] Loss: 12168.208008\n",
      "Train Epoch: 4315 [33024/118836 (28%)] Loss: 12154.434570\n",
      "Train Epoch: 4315 [65792/118836 (55%)] Loss: 12206.283203\n",
      "Train Epoch: 4315 [98560/118836 (83%)] Loss: 12191.165039\n",
      "    epoch          : 4315\n",
      "    loss           : 12178.865046816842\n",
      "    val_loss       : 12179.39553200684\n",
      "    val_log_likelihood: -12103.903938559759\n",
      "    val_log_marginal: -12112.86925552635\n",
      "Train Epoch: 4316 [256/118836 (0%)] Loss: 12278.517578\n",
      "Train Epoch: 4316 [33024/118836 (28%)] Loss: 12169.388672\n",
      "Train Epoch: 4316 [65792/118836 (55%)] Loss: 12206.149414\n",
      "Train Epoch: 4316 [98560/118836 (83%)] Loss: 12268.194336\n",
      "    epoch          : 4316\n",
      "    loss           : 12184.555602835506\n",
      "    val_loss       : 12178.79353798882\n",
      "    val_log_likelihood: -12099.97723858173\n",
      "    val_log_marginal: -12108.873983503216\n",
      "Train Epoch: 4317 [256/118836 (0%)] Loss: 12220.746094\n",
      "Train Epoch: 4317 [33024/118836 (28%)] Loss: 12259.488281\n",
      "Train Epoch: 4317 [65792/118836 (55%)] Loss: 12166.398438\n",
      "Train Epoch: 4317 [98560/118836 (83%)] Loss: 12126.101562\n",
      "    epoch          : 4317\n",
      "    loss           : 12178.94117733535\n",
      "    val_loss       : 12183.545355896948\n",
      "    val_log_likelihood: -12101.187307595377\n",
      "    val_log_marginal: -12110.136184306459\n",
      "Train Epoch: 4318 [256/118836 (0%)] Loss: 12124.609375\n",
      "Train Epoch: 4318 [33024/118836 (28%)] Loss: 12243.563477\n",
      "Train Epoch: 4318 [65792/118836 (55%)] Loss: 12215.366211\n",
      "Train Epoch: 4318 [98560/118836 (83%)] Loss: 12126.716797\n",
      "    epoch          : 4318\n",
      "    loss           : 12179.730355827389\n",
      "    val_loss       : 12183.458072709447\n",
      "    val_log_likelihood: -12099.40749861068\n",
      "    val_log_marginal: -12108.395110698082\n",
      "Train Epoch: 4319 [256/118836 (0%)] Loss: 12186.646484\n",
      "Train Epoch: 4319 [33024/118836 (28%)] Loss: 12350.233398\n",
      "Train Epoch: 4319 [65792/118836 (55%)] Loss: 12194.433594\n",
      "Train Epoch: 4319 [98560/118836 (83%)] Loss: 12136.429688\n",
      "    epoch          : 4319\n",
      "    loss           : 12179.753843084418\n",
      "    val_loss       : 12180.792160315605\n",
      "    val_log_likelihood: -12101.774581588606\n",
      "    val_log_marginal: -12110.615511670316\n",
      "Train Epoch: 4320 [256/118836 (0%)] Loss: 12238.669922\n",
      "Train Epoch: 4320 [33024/118836 (28%)] Loss: 12165.602539\n",
      "Train Epoch: 4320 [65792/118836 (55%)] Loss: 12215.259766\n",
      "Train Epoch: 4320 [98560/118836 (83%)] Loss: 12198.813477\n",
      "    epoch          : 4320\n",
      "    loss           : 12181.232657251603\n",
      "    val_loss       : 12190.054741287422\n",
      "    val_log_likelihood: -12102.257023818755\n",
      "    val_log_marginal: -12111.28416005006\n",
      "Train Epoch: 4321 [256/118836 (0%)] Loss: 12319.073242\n",
      "Train Epoch: 4321 [33024/118836 (28%)] Loss: 12292.575195\n",
      "Train Epoch: 4321 [65792/118836 (55%)] Loss: 12231.541016\n",
      "Train Epoch: 4321 [98560/118836 (83%)] Loss: 12117.138672\n",
      "    epoch          : 4321\n",
      "    loss           : 12188.33351426799\n",
      "    val_loss       : 12180.920288229152\n",
      "    val_log_likelihood: -12102.16501208385\n",
      "    val_log_marginal: -12111.061313844404\n",
      "Train Epoch: 4322 [256/118836 (0%)] Loss: 12159.292969\n",
      "Train Epoch: 4322 [33024/118836 (28%)] Loss: 12168.020508\n",
      "Train Epoch: 4322 [65792/118836 (55%)] Loss: 12397.969727\n",
      "Train Epoch: 4322 [98560/118836 (83%)] Loss: 12199.333984\n",
      "    epoch          : 4322\n",
      "    loss           : 12185.726244733509\n",
      "    val_loss       : 12186.750912866037\n",
      "    val_log_likelihood: -12099.750714530344\n",
      "    val_log_marginal: -12108.80455815345\n",
      "Train Epoch: 4323 [256/118836 (0%)] Loss: 12178.066406\n",
      "Train Epoch: 4323 [33024/118836 (28%)] Loss: 12313.757812\n",
      "Train Epoch: 4323 [65792/118836 (55%)] Loss: 12165.560547\n",
      "Train Epoch: 4323 [98560/118836 (83%)] Loss: 12208.342773\n",
      "    epoch          : 4323\n",
      "    loss           : 12183.61825969939\n",
      "    val_loss       : 12180.925990955144\n",
      "    val_log_likelihood: -12101.436124735059\n",
      "    val_log_marginal: -12110.299029764661\n",
      "Train Epoch: 4324 [256/118836 (0%)] Loss: 12273.939453\n",
      "Train Epoch: 4324 [33024/118836 (28%)] Loss: 12227.071289\n",
      "Train Epoch: 4324 [65792/118836 (55%)] Loss: 12242.318359\n",
      "Train Epoch: 4324 [98560/118836 (83%)] Loss: 12177.421875\n",
      "    epoch          : 4324\n",
      "    loss           : 12181.49258087133\n",
      "    val_loss       : 12179.921264963328\n",
      "    val_log_likelihood: -12102.605151468155\n",
      "    val_log_marginal: -12111.480974871529\n",
      "Train Epoch: 4325 [256/118836 (0%)] Loss: 12217.236328\n",
      "Train Epoch: 4325 [33024/118836 (28%)] Loss: 12220.245117\n",
      "Train Epoch: 4325 [65792/118836 (55%)] Loss: 12220.830078\n",
      "Train Epoch: 4325 [98560/118836 (83%)] Loss: 12139.613281\n",
      "    epoch          : 4325\n",
      "    loss           : 12181.623682246433\n",
      "    val_loss       : 12180.613782811164\n",
      "    val_log_likelihood: -12103.004113032464\n",
      "    val_log_marginal: -12111.845773959698\n",
      "Train Epoch: 4326 [256/118836 (0%)] Loss: 12302.232422\n",
      "Train Epoch: 4326 [33024/118836 (28%)] Loss: 12189.351562\n",
      "Train Epoch: 4326 [65792/118836 (55%)] Loss: 12132.146484\n",
      "Train Epoch: 4326 [98560/118836 (83%)] Loss: 12229.765625\n",
      "    epoch          : 4326\n",
      "    loss           : 12175.826325346361\n",
      "    val_loss       : 12180.254901852963\n",
      "    val_log_likelihood: -12098.806510416667\n",
      "    val_log_marginal: -12107.70419360136\n",
      "Train Epoch: 4327 [256/118836 (0%)] Loss: 12249.672852\n",
      "Train Epoch: 4327 [33024/118836 (28%)] Loss: 12120.134766\n",
      "Train Epoch: 4327 [65792/118836 (55%)] Loss: 12229.166992\n",
      "Train Epoch: 4327 [98560/118836 (83%)] Loss: 12258.156250\n",
      "    epoch          : 4327\n",
      "    loss           : 12179.761197916667\n",
      "    val_loss       : 12178.896501807658\n",
      "    val_log_likelihood: -12100.913087876084\n",
      "    val_log_marginal: -12109.803145109561\n",
      "Train Epoch: 4328 [256/118836 (0%)] Loss: 12193.265625\n",
      "Train Epoch: 4328 [33024/118836 (28%)] Loss: 12166.525391\n",
      "Train Epoch: 4328 [65792/118836 (55%)] Loss: 12173.877930\n",
      "Train Epoch: 4328 [98560/118836 (83%)] Loss: 12251.958984\n",
      "    epoch          : 4328\n",
      "    loss           : 12181.838696753515\n",
      "    val_loss       : 12179.825781806281\n",
      "    val_log_likelihood: -12102.900091275073\n",
      "    val_log_marginal: -12111.876794811895\n",
      "Train Epoch: 4329 [256/118836 (0%)] Loss: 12263.936523\n",
      "Train Epoch: 4329 [33024/118836 (28%)] Loss: 12217.640625\n",
      "Train Epoch: 4329 [65792/118836 (55%)] Loss: 12311.231445\n",
      "Train Epoch: 4329 [98560/118836 (83%)] Loss: 12201.386719\n",
      "    epoch          : 4329\n",
      "    loss           : 12184.179950016802\n",
      "    val_loss       : 12175.620013131725\n",
      "    val_log_likelihood: -12102.506959522334\n",
      "    val_log_marginal: -12111.359057790538\n",
      "Train Epoch: 4330 [256/118836 (0%)] Loss: 12188.057617\n",
      "Train Epoch: 4330 [33024/118836 (28%)] Loss: 12206.807617\n",
      "Train Epoch: 4330 [65792/118836 (55%)] Loss: 12315.333984\n",
      "Train Epoch: 4330 [98560/118836 (83%)] Loss: 12290.320312\n",
      "    epoch          : 4330\n",
      "    loss           : 12179.34468746769\n",
      "    val_loss       : 12181.025650830185\n",
      "    val_log_likelihood: -12102.369682136581\n",
      "    val_log_marginal: -12111.208144121752\n",
      "Train Epoch: 4331 [256/118836 (0%)] Loss: 12269.890625\n",
      "Train Epoch: 4331 [33024/118836 (28%)] Loss: 12243.075195\n",
      "Train Epoch: 4331 [65792/118836 (55%)] Loss: 12262.768555\n",
      "Train Epoch: 4331 [98560/118836 (83%)] Loss: 12223.833984\n",
      "    epoch          : 4331\n",
      "    loss           : 12184.01840945513\n",
      "    val_loss       : 12180.310255796494\n",
      "    val_log_likelihood: -12098.457013964278\n",
      "    val_log_marginal: -12107.33995122486\n",
      "Train Epoch: 4332 [256/118836 (0%)] Loss: 12151.449219\n",
      "Train Epoch: 4332 [33024/118836 (28%)] Loss: 12195.776367\n",
      "Train Epoch: 4332 [65792/118836 (55%)] Loss: 12228.839844\n",
      "Train Epoch: 4332 [98560/118836 (83%)] Loss: 12242.335938\n",
      "    epoch          : 4332\n",
      "    loss           : 12181.21623500827\n",
      "    val_loss       : 12177.508253895287\n",
      "    val_log_likelihood: -12101.455608328164\n",
      "    val_log_marginal: -12110.234962681488\n",
      "Train Epoch: 4333 [256/118836 (0%)] Loss: 12214.578125\n",
      "Train Epoch: 4333 [33024/118836 (28%)] Loss: 12272.005859\n",
      "Train Epoch: 4333 [65792/118836 (55%)] Loss: 12204.548828\n",
      "Train Epoch: 4333 [98560/118836 (83%)] Loss: 12218.295898\n",
      "    epoch          : 4333\n",
      "    loss           : 12180.055176669768\n",
      "    val_loss       : 12182.04445794895\n",
      "    val_log_likelihood: -12100.248998397437\n",
      "    val_log_marginal: -12109.04239423182\n",
      "Train Epoch: 4334 [256/118836 (0%)] Loss: 12214.011719\n",
      "Train Epoch: 4334 [33024/118836 (28%)] Loss: 12232.129883\n",
      "Train Epoch: 4334 [65792/118836 (55%)] Loss: 12136.240234\n",
      "Train Epoch: 4334 [98560/118836 (83%)] Loss: 12169.546875\n",
      "    epoch          : 4334\n",
      "    loss           : 12179.056016238885\n",
      "    val_loss       : 12183.034684876904\n",
      "    val_log_likelihood: -12100.33418114144\n",
      "    val_log_marginal: -12109.150569501962\n",
      "Train Epoch: 4335 [256/118836 (0%)] Loss: 12238.234375\n",
      "Train Epoch: 4335 [33024/118836 (28%)] Loss: 12285.500000\n",
      "Train Epoch: 4335 [65792/118836 (55%)] Loss: 12265.463867\n",
      "Train Epoch: 4335 [98560/118836 (83%)] Loss: 12291.471680\n",
      "    epoch          : 4335\n",
      "    loss           : 12180.82924679487\n",
      "    val_loss       : 12182.23111896489\n",
      "    val_log_likelihood: -12100.125225360578\n",
      "    val_log_marginal: -12108.848329387554\n",
      "Train Epoch: 4336 [256/118836 (0%)] Loss: 12213.082031\n",
      "Train Epoch: 4336 [33024/118836 (28%)] Loss: 12208.449219\n",
      "Train Epoch: 4336 [65792/118836 (55%)] Loss: 12190.761719\n",
      "Train Epoch: 4336 [98560/118836 (83%)] Loss: 12240.706055\n",
      "    epoch          : 4336\n",
      "    loss           : 12180.81941412712\n",
      "    val_loss       : 12180.911907364365\n",
      "    val_log_likelihood: -12103.022417157774\n",
      "    val_log_marginal: -12111.93438687546\n",
      "Train Epoch: 4337 [256/118836 (0%)] Loss: 12131.916016\n",
      "Train Epoch: 4337 [33024/118836 (28%)] Loss: 12281.516602\n",
      "Train Epoch: 4337 [65792/118836 (55%)] Loss: 12189.685547\n",
      "Train Epoch: 4337 [98560/118836 (83%)] Loss: 12211.267578\n",
      "    epoch          : 4337\n",
      "    loss           : 12183.615724190964\n",
      "    val_loss       : 12180.802891758627\n",
      "    val_log_likelihood: -12103.970766129032\n",
      "    val_log_marginal: -12112.859543631226\n",
      "Train Epoch: 4338 [256/118836 (0%)] Loss: 12110.590820\n",
      "Train Epoch: 4338 [33024/118836 (28%)] Loss: 12282.077148\n",
      "Train Epoch: 4338 [65792/118836 (55%)] Loss: 12174.410156\n",
      "Train Epoch: 4338 [98560/118836 (83%)] Loss: 12280.830078\n",
      "    epoch          : 4338\n",
      "    loss           : 12180.178404802522\n",
      "    val_loss       : 12181.353548825871\n",
      "    val_log_likelihood: -12097.56427122105\n",
      "    val_log_marginal: -12106.47795152183\n",
      "Train Epoch: 4339 [256/118836 (0%)] Loss: 12189.355469\n",
      "Train Epoch: 4339 [33024/118836 (28%)] Loss: 12342.017578\n",
      "Train Epoch: 4339 [65792/118836 (55%)] Loss: 12121.591797\n",
      "Train Epoch: 4339 [98560/118836 (83%)] Loss: 12173.543945\n",
      "    epoch          : 4339\n",
      "    loss           : 12176.33696672741\n",
      "    val_loss       : 12181.315398160741\n",
      "    val_log_likelihood: -12099.762059779518\n",
      "    val_log_marginal: -12108.639411121436\n",
      "Train Epoch: 4340 [256/118836 (0%)] Loss: 12133.735352\n",
      "Train Epoch: 4340 [33024/118836 (28%)] Loss: 12223.385742\n",
      "Train Epoch: 4340 [65792/118836 (55%)] Loss: 12260.255859\n",
      "Train Epoch: 4340 [98560/118836 (83%)] Loss: 12177.416016\n",
      "    epoch          : 4340\n",
      "    loss           : 12177.96986387898\n",
      "    val_loss       : 12191.961172051835\n",
      "    val_log_likelihood: -12105.1891028872\n",
      "    val_log_marginal: -12114.175286107855\n",
      "Train Epoch: 4341 [256/118836 (0%)] Loss: 12369.055664\n",
      "Train Epoch: 4341 [33024/118836 (28%)] Loss: 12278.300781\n",
      "Train Epoch: 4341 [65792/118836 (55%)] Loss: 12219.943359\n",
      "Train Epoch: 4341 [98560/118836 (83%)] Loss: 12210.712891\n",
      "    epoch          : 4341\n",
      "    loss           : 12185.190583481957\n",
      "    val_loss       : 12183.477227027011\n",
      "    val_log_likelihood: -12103.088671390355\n",
      "    val_log_marginal: -12112.191809726231\n",
      "Train Epoch: 4342 [256/118836 (0%)] Loss: 12185.378906\n",
      "Train Epoch: 4342 [33024/118836 (28%)] Loss: 12312.790039\n",
      "Train Epoch: 4342 [65792/118836 (55%)] Loss: 12203.441406\n",
      "Train Epoch: 4342 [98560/118836 (83%)] Loss: 12323.799805\n",
      "    epoch          : 4342\n",
      "    loss           : 12184.619724947011\n",
      "    val_loss       : 12182.075929897479\n",
      "    val_log_likelihood: -12100.40935351401\n",
      "    val_log_marginal: -12109.400503663283\n",
      "Train Epoch: 4343 [256/118836 (0%)] Loss: 12216.580078\n",
      "Train Epoch: 4343 [33024/118836 (28%)] Loss: 12182.168945\n",
      "Train Epoch: 4343 [65792/118836 (55%)] Loss: 12248.999023\n",
      "Train Epoch: 4343 [98560/118836 (83%)] Loss: 12254.991211\n",
      "    epoch          : 4343\n",
      "    loss           : 12176.523016988473\n",
      "    val_loss       : 12183.110306086532\n",
      "    val_log_likelihood: -12100.328372492764\n",
      "    val_log_marginal: -12109.208868018957\n",
      "Train Epoch: 4344 [256/118836 (0%)] Loss: 12185.001953\n",
      "Train Epoch: 4344 [33024/118836 (28%)] Loss: 12259.924805\n",
      "Train Epoch: 4344 [65792/118836 (55%)] Loss: 12190.173828\n",
      "Train Epoch: 4344 [98560/118836 (83%)] Loss: 12282.564453\n",
      "    epoch          : 4344\n",
      "    loss           : 12177.608040930005\n",
      "    val_loss       : 12180.447425773173\n",
      "    val_log_likelihood: -12100.73634961099\n",
      "    val_log_marginal: -12109.50644436389\n",
      "Train Epoch: 4345 [256/118836 (0%)] Loss: 12286.199219\n",
      "Train Epoch: 4345 [33024/118836 (28%)] Loss: 12240.350586\n",
      "Train Epoch: 4345 [65792/118836 (55%)] Loss: 12230.983398\n",
      "Train Epoch: 4345 [98560/118836 (83%)] Loss: 12243.548828\n",
      "    epoch          : 4345\n",
      "    loss           : 12178.551568154207\n",
      "    val_loss       : 12180.425206229987\n",
      "    val_log_likelihood: -12098.80121759331\n",
      "    val_log_marginal: -12107.726325235395\n",
      "Train Epoch: 4346 [256/118836 (0%)] Loss: 12234.380859\n",
      "Train Epoch: 4346 [33024/118836 (28%)] Loss: 12195.741211\n",
      "Train Epoch: 4346 [65792/118836 (55%)] Loss: 12178.576172\n",
      "Train Epoch: 4346 [98560/118836 (83%)] Loss: 12167.515625\n",
      "    epoch          : 4346\n",
      "    loss           : 12178.684082919768\n",
      "    val_loss       : 12181.10516117547\n",
      "    val_log_likelihood: -12103.213855071339\n",
      "    val_log_marginal: -12112.036736821592\n",
      "Train Epoch: 4347 [256/118836 (0%)] Loss: 12182.347656\n",
      "Train Epoch: 4347 [33024/118836 (28%)] Loss: 12253.670898\n",
      "Train Epoch: 4347 [65792/118836 (55%)] Loss: 12238.784180\n",
      "Train Epoch: 4347 [98560/118836 (83%)] Loss: 12225.049805\n",
      "    epoch          : 4347\n",
      "    loss           : 12181.607026565085\n",
      "    val_loss       : 12180.565525499469\n",
      "    val_log_likelihood: -12103.245467102202\n",
      "    val_log_marginal: -12112.263499387553\n",
      "Train Epoch: 4348 [256/118836 (0%)] Loss: 12221.011719\n",
      "Train Epoch: 4348 [33024/118836 (28%)] Loss: 12219.697266\n",
      "Train Epoch: 4348 [65792/118836 (55%)] Loss: 12104.371094\n",
      "Train Epoch: 4348 [98560/118836 (83%)] Loss: 12260.394531\n",
      "    epoch          : 4348\n",
      "    loss           : 12181.91397914082\n",
      "    val_loss       : 12179.427935036329\n",
      "    val_log_likelihood: -12099.663513880274\n",
      "    val_log_marginal: -12108.520831696353\n",
      "Train Epoch: 4349 [256/118836 (0%)] Loss: 12322.769531\n",
      "Train Epoch: 4349 [33024/118836 (28%)] Loss: 12143.828125\n",
      "Train Epoch: 4349 [65792/118836 (55%)] Loss: 12258.453125\n",
      "Train Epoch: 4349 [98560/118836 (83%)] Loss: 12213.029297\n",
      "    epoch          : 4349\n",
      "    loss           : 12177.308328648418\n",
      "    val_loss       : 12178.008722904204\n",
      "    val_log_likelihood: -12100.053584929436\n",
      "    val_log_marginal: -12108.925566110924\n",
      "Train Epoch: 4350 [256/118836 (0%)] Loss: 12248.138672\n",
      "Train Epoch: 4350 [33024/118836 (28%)] Loss: 12280.078125\n",
      "Train Epoch: 4350 [65792/118836 (55%)] Loss: 12246.226562\n",
      "Train Epoch: 4350 [98560/118836 (83%)] Loss: 12171.473633\n",
      "    epoch          : 4350\n",
      "    loss           : 12178.242430792494\n",
      "    val_loss       : 12177.327689316782\n",
      "    val_log_likelihood: -12100.95859245761\n",
      "    val_log_marginal: -12109.816945211507\n",
      "Train Epoch: 4351 [256/118836 (0%)] Loss: 12241.284180\n",
      "Train Epoch: 4351 [33024/118836 (28%)] Loss: 12137.301758\n",
      "Train Epoch: 4351 [65792/118836 (55%)] Loss: 12282.828125\n",
      "Train Epoch: 4351 [98560/118836 (83%)] Loss: 12255.428711\n",
      "    epoch          : 4351\n",
      "    loss           : 12179.344426566377\n",
      "    val_loss       : 12177.138894973852\n",
      "    val_log_likelihood: -12100.61826244572\n",
      "    val_log_marginal: -12109.360931312862\n",
      "Train Epoch: 4352 [256/118836 (0%)] Loss: 12199.670898\n",
      "Train Epoch: 4352 [33024/118836 (28%)] Loss: 12188.597656\n",
      "Train Epoch: 4352 [65792/118836 (55%)] Loss: 12129.437500\n",
      "Train Epoch: 4352 [98560/118836 (83%)] Loss: 12149.709961\n",
      "    epoch          : 4352\n",
      "    loss           : 12184.643562118745\n",
      "    val_loss       : 12181.65891467997\n",
      "    val_log_likelihood: -12099.4361731997\n",
      "    val_log_marginal: -12108.2819152562\n",
      "Train Epoch: 4353 [256/118836 (0%)] Loss: 12166.712891\n",
      "Train Epoch: 4353 [33024/118836 (28%)] Loss: 12122.971680\n",
      "Train Epoch: 4353 [65792/118836 (55%)] Loss: 12146.823242\n",
      "Train Epoch: 4353 [98560/118836 (83%)] Loss: 12255.019531\n",
      "    epoch          : 4353\n",
      "    loss           : 12180.376379949856\n",
      "    val_loss       : 12181.682608130332\n",
      "    val_log_likelihood: -12100.309311188224\n",
      "    val_log_marginal: -12109.147984618572\n",
      "Train Epoch: 4354 [256/118836 (0%)] Loss: 12176.085938\n",
      "Train Epoch: 4354 [33024/118836 (28%)] Loss: 12200.958008\n",
      "Train Epoch: 4354 [65792/118836 (55%)] Loss: 12135.870117\n",
      "Train Epoch: 4354 [98560/118836 (83%)] Loss: 12272.054688\n",
      "    epoch          : 4354\n",
      "    loss           : 12181.011572063688\n",
      "    val_loss       : 12181.00054007651\n",
      "    val_log_likelihood: -12097.96361387898\n",
      "    val_log_marginal: -12106.771053192371\n",
      "Train Epoch: 4355 [256/118836 (0%)] Loss: 12196.976562\n",
      "Train Epoch: 4355 [33024/118836 (28%)] Loss: 12168.923828\n",
      "Train Epoch: 4355 [65792/118836 (55%)] Loss: 12426.887695\n",
      "Train Epoch: 4355 [98560/118836 (83%)] Loss: 12101.487305\n",
      "    epoch          : 4355\n",
      "    loss           : 12179.604448246228\n",
      "    val_loss       : 12178.905354460163\n",
      "    val_log_likelihood: -12101.243307840932\n",
      "    val_log_marginal: -12109.941958379588\n",
      "Train Epoch: 4356 [256/118836 (0%)] Loss: 12205.672852\n",
      "Train Epoch: 4356 [33024/118836 (28%)] Loss: 12328.062500\n",
      "Train Epoch: 4356 [65792/118836 (55%)] Loss: 12307.992188\n",
      "Train Epoch: 4356 [98560/118836 (83%)] Loss: 12176.740234\n",
      "    epoch          : 4356\n",
      "    loss           : 12179.22625798051\n",
      "    val_loss       : 12179.287941511477\n",
      "    val_log_likelihood: -12101.714460879342\n",
      "    val_log_marginal: -12110.538800364451\n",
      "Train Epoch: 4357 [256/118836 (0%)] Loss: 12280.290039\n",
      "Train Epoch: 4357 [33024/118836 (28%)] Loss: 12119.825195\n",
      "Train Epoch: 4357 [65792/118836 (55%)] Loss: 12248.423828\n",
      "Train Epoch: 4357 [98560/118836 (83%)] Loss: 12185.606445\n",
      "    epoch          : 4357\n",
      "    loss           : 12178.971823950578\n",
      "    val_loss       : 12178.19119824202\n",
      "    val_log_likelihood: -12101.181566958747\n",
      "    val_log_marginal: -12109.89407607951\n",
      "Train Epoch: 4358 [256/118836 (0%)] Loss: 12159.410156\n",
      "Train Epoch: 4358 [33024/118836 (28%)] Loss: 12123.052734\n",
      "Train Epoch: 4358 [65792/118836 (55%)] Loss: 12251.727539\n",
      "Train Epoch: 4358 [98560/118836 (83%)] Loss: 12188.669922\n",
      "    epoch          : 4358\n",
      "    loss           : 12178.909804558261\n",
      "    val_loss       : 12180.841808758014\n",
      "    val_log_likelihood: -12099.449138460246\n",
      "    val_log_marginal: -12108.14684665104\n",
      "Train Epoch: 4359 [256/118836 (0%)] Loss: 12187.409180\n",
      "Train Epoch: 4359 [33024/118836 (28%)] Loss: 12148.623047\n",
      "Train Epoch: 4359 [65792/118836 (55%)] Loss: 12137.730469\n",
      "Train Epoch: 4359 [98560/118836 (83%)] Loss: 12226.748047\n",
      "    epoch          : 4359\n",
      "    loss           : 12177.666202536962\n",
      "    val_loss       : 12182.38638039436\n",
      "    val_log_likelihood: -12101.495824932796\n",
      "    val_log_marginal: -12110.303498688103\n",
      "Train Epoch: 4360 [256/118836 (0%)] Loss: 12224.949219\n",
      "Train Epoch: 4360 [33024/118836 (28%)] Loss: 12227.899414\n",
      "Train Epoch: 4360 [65792/118836 (55%)] Loss: 12194.975586\n",
      "Train Epoch: 4360 [98560/118836 (83%)] Loss: 12170.164062\n",
      "    epoch          : 4360\n",
      "    loss           : 12181.379287828267\n",
      "    val_loss       : 12179.635519682712\n",
      "    val_log_likelihood: -12101.979902036806\n",
      "    val_log_marginal: -12110.881406189648\n",
      "Train Epoch: 4361 [256/118836 (0%)] Loss: 12233.765625\n",
      "Train Epoch: 4361 [33024/118836 (28%)] Loss: 12131.631836\n",
      "Train Epoch: 4361 [65792/118836 (55%)] Loss: 12191.259766\n",
      "Train Epoch: 4361 [98560/118836 (83%)] Loss: 12183.597656\n",
      "    epoch          : 4361\n",
      "    loss           : 12180.987847168373\n",
      "    val_loss       : 12179.895673902658\n",
      "    val_log_likelihood: -12099.839761037016\n",
      "    val_log_marginal: -12108.790185337379\n",
      "Train Epoch: 4362 [256/118836 (0%)] Loss: 12155.761719\n",
      "Train Epoch: 4362 [33024/118836 (28%)] Loss: 12152.695312\n",
      "Train Epoch: 4362 [65792/118836 (55%)] Loss: 12230.699219\n",
      "Train Epoch: 4362 [98560/118836 (83%)] Loss: 12213.004883\n",
      "    epoch          : 4362\n",
      "    loss           : 12180.809258684865\n",
      "    val_loss       : 12182.005102893403\n",
      "    val_log_likelihood: -12099.644045957402\n",
      "    val_log_marginal: -12108.414256727074\n",
      "Train Epoch: 4363 [256/118836 (0%)] Loss: 12248.700195\n",
      "Train Epoch: 4363 [33024/118836 (28%)] Loss: 12288.813477\n",
      "Train Epoch: 4363 [65792/118836 (55%)] Loss: 12197.239258\n",
      "Train Epoch: 4363 [98560/118836 (83%)] Loss: 12142.295898\n",
      "    epoch          : 4363\n",
      "    loss           : 12177.313437629238\n",
      "    val_loss       : 12176.417006151943\n",
      "    val_log_likelihood: -12100.688973001963\n",
      "    val_log_marginal: -12109.480676279796\n",
      "Train Epoch: 4364 [256/118836 (0%)] Loss: 12245.481445\n",
      "Train Epoch: 4364 [33024/118836 (28%)] Loss: 12205.184570\n",
      "Train Epoch: 4364 [65792/118836 (55%)] Loss: 12198.960938\n",
      "Train Epoch: 4364 [98560/118836 (83%)] Loss: 12187.969727\n",
      "    epoch          : 4364\n",
      "    loss           : 12178.267475218414\n",
      "    val_loss       : 12183.333032430688\n",
      "    val_log_likelihood: -12098.950872363523\n",
      "    val_log_marginal: -12107.640963016212\n",
      "Train Epoch: 4365 [256/118836 (0%)] Loss: 12251.830078\n",
      "Train Epoch: 4365 [33024/118836 (28%)] Loss: 12244.731445\n",
      "Train Epoch: 4365 [65792/118836 (55%)] Loss: 12271.576172\n",
      "Train Epoch: 4365 [98560/118836 (83%)] Loss: 12262.490234\n",
      "    epoch          : 4365\n",
      "    loss           : 12184.546581627379\n",
      "    val_loss       : 12183.302054146596\n",
      "    val_log_likelihood: -12097.564466210453\n",
      "    val_log_marginal: -12106.333467167151\n",
      "Train Epoch: 4366 [256/118836 (0%)] Loss: 12207.514648\n",
      "Train Epoch: 4366 [33024/118836 (28%)] Loss: 12126.913086\n",
      "Train Epoch: 4366 [65792/118836 (55%)] Loss: 12228.443359\n",
      "Train Epoch: 4366 [98560/118836 (83%)] Loss: 12136.318359\n",
      "    epoch          : 4366\n",
      "    loss           : 12178.599836512612\n",
      "    val_loss       : 12179.060622540299\n",
      "    val_log_likelihood: -12104.869318328681\n",
      "    val_log_marginal: -12113.730074788704\n",
      "Train Epoch: 4367 [256/118836 (0%)] Loss: 12209.897461\n",
      "Train Epoch: 4367 [33024/118836 (28%)] Loss: 12120.945312\n",
      "Train Epoch: 4367 [65792/118836 (55%)] Loss: 12240.798828\n",
      "Train Epoch: 4367 [98560/118836 (83%)] Loss: 12239.555664\n",
      "    epoch          : 4367\n",
      "    loss           : 12182.134002953113\n",
      "    val_loss       : 12183.580665241027\n",
      "    val_log_likelihood: -12101.536171584212\n",
      "    val_log_marginal: -12110.284627585486\n",
      "Train Epoch: 4368 [256/118836 (0%)] Loss: 12118.561523\n",
      "Train Epoch: 4368 [33024/118836 (28%)] Loss: 12287.416992\n",
      "Train Epoch: 4368 [65792/118836 (55%)] Loss: 12189.876953\n",
      "Train Epoch: 4368 [98560/118836 (83%)] Loss: 12199.964844\n",
      "    epoch          : 4368\n",
      "    loss           : 12176.765691396558\n",
      "    val_loss       : 12179.867050392711\n",
      "    val_log_likelihood: -12102.7633888415\n",
      "    val_log_marginal: -12111.562012802524\n",
      "Train Epoch: 4369 [256/118836 (0%)] Loss: 12189.168945\n",
      "Train Epoch: 4369 [33024/118836 (28%)] Loss: 12144.482422\n",
      "Train Epoch: 4369 [65792/118836 (55%)] Loss: 12229.126953\n",
      "Train Epoch: 4369 [98560/118836 (83%)] Loss: 12218.771484\n",
      "    epoch          : 4369\n",
      "    loss           : 12182.106256300403\n",
      "    val_loss       : 12174.386535806936\n",
      "    val_log_likelihood: -12100.240354890404\n",
      "    val_log_marginal: -12109.007515024367\n",
      "Train Epoch: 4370 [256/118836 (0%)] Loss: 12246.553711\n",
      "Train Epoch: 4370 [33024/118836 (28%)] Loss: 12172.536133\n",
      "Train Epoch: 4370 [65792/118836 (55%)] Loss: 12160.059570\n",
      "Train Epoch: 4370 [98560/118836 (83%)] Loss: 12215.302734\n",
      "    epoch          : 4370\n",
      "    loss           : 12175.971769993279\n",
      "    val_loss       : 12180.813620446692\n",
      "    val_log_likelihood: -12098.647693890869\n",
      "    val_log_marginal: -12107.450218056465\n",
      "Train Epoch: 4371 [256/118836 (0%)] Loss: 12186.074219\n",
      "Train Epoch: 4371 [33024/118836 (28%)] Loss: 12233.161133\n",
      "Train Epoch: 4371 [65792/118836 (55%)] Loss: 12180.018555\n",
      "Train Epoch: 4371 [98560/118836 (83%)] Loss: 12209.590820\n",
      "    epoch          : 4371\n",
      "    loss           : 12179.691292358095\n",
      "    val_loss       : 12180.103018198515\n",
      "    val_log_likelihood: -12101.05395859181\n",
      "    val_log_marginal: -12109.846308846933\n",
      "Train Epoch: 4372 [256/118836 (0%)] Loss: 12188.704102\n",
      "Train Epoch: 4372 [33024/118836 (28%)] Loss: 12141.980469\n",
      "Train Epoch: 4372 [65792/118836 (55%)] Loss: 12214.064453\n",
      "Train Epoch: 4372 [98560/118836 (83%)] Loss: 12253.203125\n",
      "    epoch          : 4372\n",
      "    loss           : 12184.073994520264\n",
      "    val_loss       : 12179.5968519758\n",
      "    val_log_likelihood: -12100.655107526882\n",
      "    val_log_marginal: -12109.469985051184\n",
      "Train Epoch: 4373 [256/118836 (0%)] Loss: 12257.545898\n",
      "Train Epoch: 4373 [33024/118836 (28%)] Loss: 12222.232422\n",
      "Train Epoch: 4373 [65792/118836 (55%)] Loss: 12253.805664\n",
      "Train Epoch: 4373 [98560/118836 (83%)] Loss: 12299.159180\n",
      "    epoch          : 4373\n",
      "    loss           : 12181.64963764604\n",
      "    val_loss       : 12179.453964812801\n",
      "    val_log_likelihood: -12101.63874990307\n",
      "    val_log_marginal: -12110.582931342116\n",
      "Train Epoch: 4374 [256/118836 (0%)] Loss: 12161.494141\n",
      "Train Epoch: 4374 [33024/118836 (28%)] Loss: 12158.436523\n",
      "Train Epoch: 4374 [65792/118836 (55%)] Loss: 12248.865234\n",
      "Train Epoch: 4374 [98560/118836 (83%)] Loss: 12259.545898\n",
      "    epoch          : 4374\n",
      "    loss           : 12183.7804756966\n",
      "    val_loss       : 12181.30275247454\n",
      "    val_log_likelihood: -12098.112975922768\n",
      "    val_log_marginal: -12106.929212745497\n",
      "Train Epoch: 4375 [256/118836 (0%)] Loss: 12171.666016\n",
      "Train Epoch: 4375 [33024/118836 (28%)] Loss: 12219.682617\n",
      "Train Epoch: 4375 [65792/118836 (55%)] Loss: 12145.213867\n",
      "Train Epoch: 4375 [98560/118836 (83%)] Loss: 12238.834961\n",
      "    epoch          : 4375\n",
      "    loss           : 12181.74144938353\n",
      "    val_loss       : 12179.255807855832\n",
      "    val_log_likelihood: -12102.72510516827\n",
      "    val_log_marginal: -12111.422128189726\n",
      "Train Epoch: 4376 [256/118836 (0%)] Loss: 12199.377930\n",
      "Train Epoch: 4376 [33024/118836 (28%)] Loss: 12257.656250\n",
      "Train Epoch: 4376 [65792/118836 (55%)] Loss: 12168.866211\n",
      "Train Epoch: 4376 [98560/118836 (83%)] Loss: 12172.101562\n",
      "    epoch          : 4376\n",
      "    loss           : 12179.768928672975\n",
      "    val_loss       : 12182.440887404731\n",
      "    val_log_likelihood: -12099.357897959315\n",
      "    val_log_marginal: -12108.061602982858\n",
      "Train Epoch: 4377 [256/118836 (0%)] Loss: 12268.286133\n",
      "Train Epoch: 4377 [33024/118836 (28%)] Loss: 12230.404297\n",
      "Train Epoch: 4377 [65792/118836 (55%)] Loss: 12291.015625\n",
      "Train Epoch: 4377 [98560/118836 (83%)] Loss: 12180.102539\n",
      "    epoch          : 4377\n",
      "    loss           : 12177.638971709574\n",
      "    val_loss       : 12181.345735175511\n",
      "    val_log_likelihood: -12099.191311259305\n",
      "    val_log_marginal: -12107.98713120974\n",
      "Train Epoch: 4378 [256/118836 (0%)] Loss: 12133.180664\n",
      "Train Epoch: 4378 [33024/118836 (28%)] Loss: 12212.005859\n",
      "Train Epoch: 4378 [65792/118836 (55%)] Loss: 12217.801758\n",
      "Train Epoch: 4378 [98560/118836 (83%)] Loss: 12248.847656\n",
      "    epoch          : 4378\n",
      "    loss           : 12174.9521620076\n",
      "    val_loss       : 12179.803679440836\n",
      "    val_log_likelihood: -12100.503226775743\n",
      "    val_log_marginal: -12109.354855598624\n",
      "Train Epoch: 4379 [256/118836 (0%)] Loss: 12164.574219\n",
      "Train Epoch: 4379 [33024/118836 (28%)] Loss: 12207.607422\n",
      "Train Epoch: 4379 [65792/118836 (55%)] Loss: 12262.759766\n",
      "Train Epoch: 4379 [98560/118836 (83%)] Loss: 12165.642578\n",
      "    epoch          : 4379\n",
      "    loss           : 12177.114540038254\n",
      "    val_loss       : 12184.63381066356\n",
      "    val_log_likelihood: -12102.922415380739\n",
      "    val_log_marginal: -12111.834557295335\n",
      "Train Epoch: 4380 [256/118836 (0%)] Loss: 12155.885742\n",
      "Train Epoch: 4380 [33024/118836 (28%)] Loss: 12152.381836\n",
      "Train Epoch: 4380 [65792/118836 (55%)] Loss: 12214.291992\n",
      "Train Epoch: 4380 [98560/118836 (83%)] Loss: 12305.862305\n",
      "    epoch          : 4380\n",
      "    loss           : 12183.527437932951\n",
      "    val_loss       : 12179.246078203096\n",
      "    val_log_likelihood: -12103.789238265095\n",
      "    val_log_marginal: -12112.712072149348\n",
      "Train Epoch: 4381 [256/118836 (0%)] Loss: 12135.788086\n",
      "Train Epoch: 4381 [33024/118836 (28%)] Loss: 12166.329102\n",
      "Train Epoch: 4381 [65792/118836 (55%)] Loss: 12267.320312\n",
      "Train Epoch: 4381 [98560/118836 (83%)] Loss: 12145.291992\n",
      "    epoch          : 4381\n",
      "    loss           : 12179.55005508814\n",
      "    val_loss       : 12177.593177447014\n",
      "    val_log_likelihood: -12099.898704540166\n",
      "    val_log_marginal: -12108.67515374325\n",
      "Train Epoch: 4382 [256/118836 (0%)] Loss: 12202.374023\n",
      "Train Epoch: 4382 [33024/118836 (28%)] Loss: 12273.313477\n",
      "Train Epoch: 4382 [65792/118836 (55%)] Loss: 12199.310547\n",
      "Train Epoch: 4382 [98560/118836 (83%)] Loss: 12197.268555\n",
      "    epoch          : 4382\n",
      "    loss           : 12178.136779976994\n",
      "    val_loss       : 12175.755353356742\n",
      "    val_log_likelihood: -12099.577090118382\n",
      "    val_log_marginal: -12108.538506305265\n",
      "Train Epoch: 4383 [256/118836 (0%)] Loss: 12175.449219\n",
      "Train Epoch: 4383 [33024/118836 (28%)] Loss: 12292.909180\n",
      "Train Epoch: 4383 [65792/118836 (55%)] Loss: 12317.479492\n",
      "Train Epoch: 4383 [98560/118836 (83%)] Loss: 12225.945312\n",
      "    epoch          : 4383\n",
      "    loss           : 12180.047832176644\n",
      "    val_loss       : 12180.159007297474\n",
      "    val_log_likelihood: -12099.690383161445\n",
      "    val_log_marginal: -12108.442736334606\n",
      "Train Epoch: 4384 [256/118836 (0%)] Loss: 12210.951172\n",
      "Train Epoch: 4384 [33024/118836 (28%)] Loss: 12355.781250\n",
      "Train Epoch: 4384 [65792/118836 (55%)] Loss: 12241.435547\n",
      "Train Epoch: 4384 [98560/118836 (83%)] Loss: 12229.905273\n",
      "    epoch          : 4384\n",
      "    loss           : 12180.535504710762\n",
      "    val_loss       : 12176.94842908573\n",
      "    val_log_likelihood: -12103.272158356596\n",
      "    val_log_marginal: -12112.007738607777\n",
      "Train Epoch: 4385 [256/118836 (0%)] Loss: 12164.529297\n",
      "Train Epoch: 4385 [33024/118836 (28%)] Loss: 12125.585938\n",
      "Train Epoch: 4385 [65792/118836 (55%)] Loss: 12246.520508\n",
      "Train Epoch: 4385 [98560/118836 (83%)] Loss: 12138.839844\n",
      "    epoch          : 4385\n",
      "    loss           : 12176.597378386063\n",
      "    val_loss       : 12181.835186153203\n",
      "    val_log_likelihood: -12102.917760190498\n",
      "    val_log_marginal: -12111.662063582002\n",
      "Train Epoch: 4386 [256/118836 (0%)] Loss: 12207.882812\n",
      "Train Epoch: 4386 [33024/118836 (28%)] Loss: 12337.590820\n",
      "Train Epoch: 4386 [65792/118836 (55%)] Loss: 12177.734375\n",
      "Train Epoch: 4386 [98560/118836 (83%)] Loss: 12219.329102\n",
      "    epoch          : 4386\n",
      "    loss           : 12183.426178013853\n",
      "    val_loss       : 12182.91251597304\n",
      "    val_log_likelihood: -12100.717560031533\n",
      "    val_log_marginal: -12109.416639935343\n",
      "Train Epoch: 4387 [256/118836 (0%)] Loss: 12224.374023\n",
      "Train Epoch: 4387 [33024/118836 (28%)] Loss: 12136.177734\n",
      "Train Epoch: 4387 [65792/118836 (55%)] Loss: 12121.102539\n",
      "Train Epoch: 4387 [98560/118836 (83%)] Loss: 12180.574219\n",
      "    epoch          : 4387\n",
      "    loss           : 12181.134552542133\n",
      "    val_loss       : 12180.556975670828\n",
      "    val_log_likelihood: -12096.959666110939\n",
      "    val_log_marginal: -12105.65665132602\n",
      "Train Epoch: 4388 [256/118836 (0%)] Loss: 12125.455078\n",
      "Train Epoch: 4388 [33024/118836 (28%)] Loss: 12129.369141\n",
      "Train Epoch: 4388 [65792/118836 (55%)] Loss: 12161.051758\n",
      "Train Epoch: 4388 [98560/118836 (83%)] Loss: 12227.387695\n",
      "    epoch          : 4388\n",
      "    loss           : 12176.3326575747\n",
      "    val_loss       : 12179.029596514005\n",
      "    val_log_likelihood: -12100.843227066533\n",
      "    val_log_marginal: -12109.630899320522\n",
      "Train Epoch: 4389 [256/118836 (0%)] Loss: 12200.381836\n",
      "Train Epoch: 4389 [33024/118836 (28%)] Loss: 12204.427734\n",
      "Train Epoch: 4389 [65792/118836 (55%)] Loss: 12273.361328\n",
      "Train Epoch: 4389 [98560/118836 (83%)] Loss: 12193.123047\n",
      "    epoch          : 4389\n",
      "    loss           : 12179.983376305314\n",
      "    val_loss       : 12178.768247845253\n",
      "    val_log_likelihood: -12101.090174440395\n",
      "    val_log_marginal: -12109.902784089532\n",
      "Train Epoch: 4390 [256/118836 (0%)] Loss: 12287.416992\n",
      "Train Epoch: 4390 [33024/118836 (28%)] Loss: 12252.139648\n",
      "Train Epoch: 4390 [65792/118836 (55%)] Loss: 12295.570312\n",
      "Train Epoch: 4390 [98560/118836 (83%)] Loss: 12187.566406\n",
      "    epoch          : 4390\n",
      "    loss           : 12182.292258258374\n",
      "    val_loss       : 12183.627393280021\n",
      "    val_log_likelihood: -12101.346159015717\n",
      "    val_log_marginal: -12110.268450820158\n",
      "Train Epoch: 4391 [256/118836 (0%)] Loss: 12254.868164\n",
      "Train Epoch: 4391 [33024/118836 (28%)] Loss: 12200.773438\n",
      "Train Epoch: 4391 [65792/118836 (55%)] Loss: 12232.109375\n",
      "Train Epoch: 4391 [98560/118836 (83%)] Loss: 12196.666016\n",
      "    epoch          : 4391\n",
      "    loss           : 12187.154248248811\n",
      "    val_loss       : 12180.223411473162\n",
      "    val_log_likelihood: -12101.988495786807\n",
      "    val_log_marginal: -12110.917452322525\n",
      "Train Epoch: 4392 [256/118836 (0%)] Loss: 12222.630859\n",
      "Train Epoch: 4392 [33024/118836 (28%)] Loss: 12185.205078\n",
      "Train Epoch: 4392 [65792/118836 (55%)] Loss: 12134.843750\n",
      "Train Epoch: 4392 [98560/118836 (83%)] Loss: 12174.830078\n",
      "    epoch          : 4392\n",
      "    loss           : 12183.929643881824\n",
      "    val_loss       : 12181.261743001023\n",
      "    val_log_likelihood: -12101.914696417494\n",
      "    val_log_marginal: -12110.787777084835\n",
      "Train Epoch: 4393 [256/118836 (0%)] Loss: 12211.541016\n",
      "Train Epoch: 4393 [33024/118836 (28%)] Loss: 12195.592773\n",
      "Train Epoch: 4393 [65792/118836 (55%)] Loss: 12229.057617\n",
      "Train Epoch: 4393 [98560/118836 (83%)] Loss: 12173.171875\n",
      "    epoch          : 4393\n",
      "    loss           : 12177.995811685794\n",
      "    val_loss       : 12181.021580930577\n",
      "    val_log_likelihood: -12099.304576515973\n",
      "    val_log_marginal: -12108.143033697414\n",
      "Train Epoch: 4394 [256/118836 (0%)] Loss: 12128.630859\n",
      "Train Epoch: 4394 [33024/118836 (28%)] Loss: 12137.273438\n",
      "Train Epoch: 4394 [65792/118836 (55%)] Loss: 12158.990234\n",
      "Train Epoch: 4394 [98560/118836 (83%)] Loss: 12250.021484\n",
      "    epoch          : 4394\n",
      "    loss           : 12180.126372033965\n",
      "    val_loss       : 12178.17127209296\n",
      "    val_log_likelihood: -12103.26654502042\n",
      "    val_log_marginal: -12112.110124096702\n",
      "Train Epoch: 4395 [256/118836 (0%)] Loss: 12218.776367\n",
      "Train Epoch: 4395 [33024/118836 (28%)] Loss: 12196.619141\n",
      "Train Epoch: 4395 [65792/118836 (55%)] Loss: 12300.246094\n",
      "Train Epoch: 4395 [98560/118836 (83%)] Loss: 12243.834961\n",
      "    epoch          : 4395\n",
      "    loss           : 12181.876501111456\n",
      "    val_loss       : 12180.616976102981\n",
      "    val_log_likelihood: -12097.347548981596\n",
      "    val_log_marginal: -12106.13021795212\n",
      "Train Epoch: 4396 [256/118836 (0%)] Loss: 12159.058594\n",
      "Train Epoch: 4396 [33024/118836 (28%)] Loss: 12167.125000\n",
      "Train Epoch: 4396 [65792/118836 (55%)] Loss: 12203.295898\n",
      "Train Epoch: 4396 [98560/118836 (83%)] Loss: 12316.259766\n",
      "    epoch          : 4396\n",
      "    loss           : 12179.324936188224\n",
      "    val_loss       : 12184.31884580385\n",
      "    val_log_likelihood: -12101.178086066739\n",
      "    val_log_marginal: -12109.950551972937\n",
      "Train Epoch: 4397 [256/118836 (0%)] Loss: 12225.102539\n",
      "Train Epoch: 4397 [33024/118836 (28%)] Loss: 12201.229492\n",
      "Train Epoch: 4397 [65792/118836 (55%)] Loss: 12263.621094\n",
      "Train Epoch: 4397 [98560/118836 (83%)] Loss: 12422.775391\n",
      "    epoch          : 4397\n",
      "    loss           : 12178.470441415942\n",
      "    val_loss       : 12180.124340728686\n",
      "    val_log_likelihood: -12102.27203945668\n",
      "    val_log_marginal: -12111.06250611143\n",
      "Train Epoch: 4398 [256/118836 (0%)] Loss: 12173.223633\n",
      "Train Epoch: 4398 [33024/118836 (28%)] Loss: 12239.678711\n",
      "Train Epoch: 4398 [65792/118836 (55%)] Loss: 12210.685547\n",
      "Train Epoch: 4398 [98560/118836 (83%)] Loss: 12330.831055\n",
      "    epoch          : 4398\n",
      "    loss           : 12182.525405002843\n",
      "    val_loss       : 12179.170117045047\n",
      "    val_log_likelihood: -12099.683813617918\n",
      "    val_log_marginal: -12108.490621557923\n",
      "Train Epoch: 4399 [256/118836 (0%)] Loss: 12123.513672\n",
      "Train Epoch: 4399 [33024/118836 (28%)] Loss: 12269.837891\n",
      "Train Epoch: 4399 [65792/118836 (55%)] Loss: 12190.090820\n",
      "Train Epoch: 4399 [98560/118836 (83%)] Loss: 12285.843750\n",
      "    epoch          : 4399\n",
      "    loss           : 12179.181271809088\n",
      "    val_loss       : 12179.395954134006\n",
      "    val_log_likelihood: -12101.051115009821\n",
      "    val_log_marginal: -12109.983454717241\n",
      "Train Epoch: 4400 [256/118836 (0%)] Loss: 12076.680664\n",
      "Train Epoch: 4400 [33024/118836 (28%)] Loss: 12206.383789\n",
      "Train Epoch: 4400 [65792/118836 (55%)] Loss: 12249.427734\n",
      "Train Epoch: 4400 [98560/118836 (83%)] Loss: 12156.474609\n",
      "    epoch          : 4400\n",
      "    loss           : 12185.987120521868\n",
      "    val_loss       : 12177.808185084701\n",
      "    val_log_likelihood: -12103.114880744677\n",
      "    val_log_marginal: -12111.872629306326\n",
      "Saving checkpoint: saved/models/SelfiesAutoencodingOperad/0905_154251/checkpoint-epoch4400.pth ...\n",
      "Train Epoch: 4401 [256/118836 (0%)] Loss: 12190.860352\n",
      "Train Epoch: 4401 [33024/118836 (28%)] Loss: 12167.883789\n",
      "Train Epoch: 4401 [65792/118836 (55%)] Loss: 12294.259766\n",
      "Train Epoch: 4401 [98560/118836 (83%)] Loss: 12170.018555\n",
      "    epoch          : 4401\n",
      "    loss           : 12178.10684676127\n",
      "    val_loss       : 12180.187094975361\n",
      "    val_log_likelihood: -12102.797878864247\n",
      "    val_log_marginal: -12111.589425547409\n",
      "Train Epoch: 4402 [256/118836 (0%)] Loss: 12189.390625\n",
      "Train Epoch: 4402 [33024/118836 (28%)] Loss: 12180.058594\n",
      "Train Epoch: 4402 [65792/118836 (55%)] Loss: 12160.427734\n",
      "Train Epoch: 4402 [98560/118836 (83%)] Loss: 12152.500977\n",
      "    epoch          : 4402\n",
      "    loss           : 12178.583665962313\n",
      "    val_loss       : 12178.603418514329\n",
      "    val_log_likelihood: -12101.967496704405\n",
      "    val_log_marginal: -12110.755065354977\n",
      "Train Epoch: 4403 [256/118836 (0%)] Loss: 12237.053711\n",
      "Train Epoch: 4403 [33024/118836 (28%)] Loss: 12130.097656\n",
      "Train Epoch: 4403 [65792/118836 (55%)] Loss: 12180.552734\n",
      "Train Epoch: 4403 [98560/118836 (83%)] Loss: 12140.255859\n",
      "    epoch          : 4403\n",
      "    loss           : 12180.17672679513\n",
      "    val_loss       : 12181.85624585089\n",
      "    val_log_likelihood: -12097.17811821495\n",
      "    val_log_marginal: -12105.93257981785\n",
      "Train Epoch: 4404 [256/118836 (0%)] Loss: 12238.729492\n",
      "Train Epoch: 4404 [33024/118836 (28%)] Loss: 12230.822266\n",
      "Train Epoch: 4404 [65792/118836 (55%)] Loss: 12201.666016\n",
      "Train Epoch: 4404 [98560/118836 (83%)] Loss: 12277.829102\n",
      "    epoch          : 4404\n",
      "    loss           : 12180.386971250775\n",
      "    val_loss       : 12179.324510159498\n",
      "    val_log_likelihood: -12102.503897203267\n",
      "    val_log_marginal: -12111.288536095437\n",
      "Train Epoch: 4405 [256/118836 (0%)] Loss: 12283.995117\n",
      "Train Epoch: 4405 [33024/118836 (28%)] Loss: 12205.586914\n",
      "Train Epoch: 4405 [65792/118836 (55%)] Loss: 12136.933594\n",
      "Train Epoch: 4405 [98560/118836 (83%)] Loss: 12140.141602\n",
      "    epoch          : 4405\n",
      "    loss           : 12182.754382011219\n",
      "    val_loss       : 12184.920763226106\n",
      "    val_log_likelihood: -12098.598213108715\n",
      "    val_log_marginal: -12107.410796592108\n",
      "Train Epoch: 4406 [256/118836 (0%)] Loss: 12274.556641\n",
      "Train Epoch: 4406 [33024/118836 (28%)] Loss: 12235.732422\n",
      "Train Epoch: 4406 [65792/118836 (55%)] Loss: 12156.361328\n",
      "Train Epoch: 4406 [98560/118836 (83%)] Loss: 12173.389648\n",
      "    epoch          : 4406\n",
      "    loss           : 12178.073582570823\n",
      "    val_loss       : 12176.322350104316\n",
      "    val_log_likelihood: -12097.930477312088\n",
      "    val_log_marginal: -12106.719315283792\n",
      "Train Epoch: 4407 [256/118836 (0%)] Loss: 12253.929688\n",
      "Train Epoch: 4407 [33024/118836 (28%)] Loss: 12132.357422\n",
      "Train Epoch: 4407 [65792/118836 (55%)] Loss: 12062.078125\n",
      "Train Epoch: 4407 [98560/118836 (83%)] Loss: 12209.590820\n",
      "    epoch          : 4407\n",
      "    loss           : 12179.739093840466\n",
      "    val_loss       : 12179.752743989418\n",
      "    val_log_likelihood: -12102.629036135237\n",
      "    val_log_marginal: -12111.445353467123\n",
      "Train Epoch: 4408 [256/118836 (0%)] Loss: 12210.875000\n",
      "Train Epoch: 4408 [33024/118836 (28%)] Loss: 12161.228516\n",
      "Train Epoch: 4408 [65792/118836 (55%)] Loss: 12202.855469\n",
      "Train Epoch: 4408 [98560/118836 (83%)] Loss: 12183.486328\n",
      "    epoch          : 4408\n",
      "    loss           : 12176.842153251653\n",
      "    val_loss       : 12182.954028821312\n",
      "    val_log_likelihood: -12099.897715215313\n",
      "    val_log_marginal: -12108.644808404853\n",
      "Train Epoch: 4409 [256/118836 (0%)] Loss: 12283.253906\n",
      "Train Epoch: 4409 [33024/118836 (28%)] Loss: 12237.088867\n",
      "Train Epoch: 4409 [65792/118836 (55%)] Loss: 12175.609375\n",
      "Train Epoch: 4409 [98560/118836 (83%)] Loss: 12133.035156\n",
      "    epoch          : 4409\n",
      "    loss           : 12179.979879096878\n",
      "    val_loss       : 12179.7037316537\n",
      "    val_log_likelihood: -12098.40934382108\n",
      "    val_log_marginal: -12107.217199870809\n",
      "Train Epoch: 4410 [256/118836 (0%)] Loss: 12148.316406\n",
      "Train Epoch: 4410 [33024/118836 (28%)] Loss: 12318.137695\n",
      "Train Epoch: 4410 [65792/118836 (55%)] Loss: 12178.285156\n",
      "Train Epoch: 4410 [98560/118836 (83%)] Loss: 12180.373047\n",
      "    epoch          : 4410\n",
      "    loss           : 12178.25814658292\n",
      "    val_loss       : 12176.951224106784\n",
      "    val_log_likelihood: -12099.413153787997\n",
      "    val_log_marginal: -12108.162797546473\n",
      "Train Epoch: 4411 [256/118836 (0%)] Loss: 12158.306641\n",
      "Train Epoch: 4411 [33024/118836 (28%)] Loss: 12219.483398\n",
      "Train Epoch: 4411 [65792/118836 (55%)] Loss: 12242.962891\n",
      "Train Epoch: 4411 [98560/118836 (83%)] Loss: 12151.685547\n",
      "    epoch          : 4411\n",
      "    loss           : 12181.42398175791\n",
      "    val_loss       : 12193.280260496773\n",
      "    val_log_likelihood: -12100.884686789184\n",
      "    val_log_marginal: -12109.733829450459\n",
      "Train Epoch: 4412 [256/118836 (0%)] Loss: 12291.584961\n",
      "Train Epoch: 4412 [33024/118836 (28%)] Loss: 12276.766602\n",
      "Train Epoch: 4412 [65792/118836 (55%)] Loss: 12179.929688\n",
      "Train Epoch: 4412 [98560/118836 (83%)] Loss: 12171.589844\n",
      "    epoch          : 4412\n",
      "    loss           : 12177.68122609078\n",
      "    val_loss       : 12180.403429969769\n",
      "    val_log_likelihood: -12102.941281372778\n",
      "    val_log_marginal: -12111.752511085306\n",
      "Train Epoch: 4413 [256/118836 (0%)] Loss: 12354.535156\n",
      "Train Epoch: 4413 [33024/118836 (28%)] Loss: 12129.097656\n",
      "Train Epoch: 4413 [65792/118836 (55%)] Loss: 12220.779297\n",
      "Train Epoch: 4413 [98560/118836 (83%)] Loss: 12187.823242\n",
      "    epoch          : 4413\n",
      "    loss           : 12179.506814774606\n",
      "    val_loss       : 12182.805276828278\n",
      "    val_log_likelihood: -12102.415829197684\n",
      "    val_log_marginal: -12111.161219730342\n",
      "Train Epoch: 4414 [256/118836 (0%)] Loss: 12366.231445\n",
      "Train Epoch: 4414 [33024/118836 (28%)] Loss: 12217.249023\n",
      "Train Epoch: 4414 [65792/118836 (55%)] Loss: 12294.800781\n",
      "Train Epoch: 4414 [98560/118836 (83%)] Loss: 12192.067383\n",
      "    epoch          : 4414\n",
      "    loss           : 12183.671735744934\n",
      "    val_loss       : 12187.381967483563\n",
      "    val_log_likelihood: -12098.881611384668\n",
      "    val_log_marginal: -12107.848221437518\n",
      "Train Epoch: 4415 [256/118836 (0%)] Loss: 12192.205078\n",
      "Train Epoch: 4415 [33024/118836 (28%)] Loss: 12273.361328\n",
      "Train Epoch: 4415 [65792/118836 (55%)] Loss: 12171.931641\n",
      "Train Epoch: 4415 [98560/118836 (83%)] Loss: 12250.693359\n",
      "    epoch          : 4415\n",
      "    loss           : 12176.961876906276\n",
      "    val_loss       : 12181.299828180867\n",
      "    val_log_likelihood: -12096.484338974618\n",
      "    val_log_marginal: -12105.32173826956\n",
      "Train Epoch: 4416 [256/118836 (0%)] Loss: 12153.944336\n",
      "Train Epoch: 4416 [33024/118836 (28%)] Loss: 12199.757812\n",
      "Train Epoch: 4416 [65792/118836 (55%)] Loss: 12274.983398\n",
      "Train Epoch: 4416 [98560/118836 (83%)] Loss: 12175.659180\n",
      "    epoch          : 4416\n",
      "    loss           : 12180.825776403535\n",
      "    val_loss       : 12185.058365956169\n",
      "    val_log_likelihood: -12098.989502397384\n",
      "    val_log_marginal: -12107.98032395703\n",
      "Train Epoch: 4417 [256/118836 (0%)] Loss: 12210.555664\n",
      "Train Epoch: 4417 [33024/118836 (28%)] Loss: 12334.314453\n",
      "Train Epoch: 4417 [65792/118836 (55%)] Loss: 12221.099609\n",
      "Train Epoch: 4417 [98560/118836 (83%)] Loss: 12135.612305\n",
      "    epoch          : 4417\n",
      "    loss           : 12174.033178569583\n",
      "    val_loss       : 12179.554419922519\n",
      "    val_log_likelihood: -12101.844087313897\n",
      "    val_log_marginal: -12110.734079360767\n",
      "Train Epoch: 4418 [256/118836 (0%)] Loss: 12152.416992\n",
      "Train Epoch: 4418 [33024/118836 (28%)] Loss: 12096.382812\n",
      "Train Epoch: 4418 [65792/118836 (55%)] Loss: 12180.583008\n",
      "Train Epoch: 4418 [98560/118836 (83%)] Loss: 12182.310547\n",
      "    epoch          : 4418\n",
      "    loss           : 12180.00721719267\n",
      "    val_loss       : 12183.869698571345\n",
      "    val_log_likelihood: -12099.147697121847\n",
      "    val_log_marginal: -12107.972091552347\n",
      "Train Epoch: 4419 [256/118836 (0%)] Loss: 12165.540039\n",
      "Train Epoch: 4419 [33024/118836 (28%)] Loss: 12209.964844\n",
      "Train Epoch: 4419 [65792/118836 (55%)] Loss: 12257.691406\n",
      "Train Epoch: 4419 [98560/118836 (83%)] Loss: 12222.879883\n",
      "    epoch          : 4419\n",
      "    loss           : 12182.860245101841\n",
      "    val_loss       : 12178.31102602271\n",
      "    val_log_likelihood: -12102.030197671113\n",
      "    val_log_marginal: -12110.943745845472\n",
      "Train Epoch: 4420 [256/118836 (0%)] Loss: 12196.293945\n",
      "Train Epoch: 4420 [33024/118836 (28%)] Loss: 12204.964844\n",
      "Train Epoch: 4420 [65792/118836 (55%)] Loss: 12262.844727\n",
      "Train Epoch: 4420 [98560/118836 (83%)] Loss: 12213.972656\n",
      "    epoch          : 4420\n",
      "    loss           : 12178.718529970532\n",
      "    val_loss       : 12178.541258386847\n",
      "    val_log_likelihood: -12096.422456898781\n",
      "    val_log_marginal: -12105.209186838163\n",
      "Train Epoch: 4421 [256/118836 (0%)] Loss: 12204.469727\n",
      "Train Epoch: 4421 [33024/118836 (28%)] Loss: 12138.555664\n",
      "Train Epoch: 4421 [65792/118836 (55%)] Loss: 12163.351562\n",
      "Train Epoch: 4421 [98560/118836 (83%)] Loss: 12179.330078\n",
      "    epoch          : 4421\n",
      "    loss           : 12179.895228009977\n",
      "    val_loss       : 12178.95822034276\n",
      "    val_log_likelihood: -12099.786273198408\n",
      "    val_log_marginal: -12108.517104567984\n",
      "Train Epoch: 4422 [256/118836 (0%)] Loss: 12149.664062\n",
      "Train Epoch: 4422 [33024/118836 (28%)] Loss: 12243.616211\n",
      "Train Epoch: 4422 [65792/118836 (55%)] Loss: 12200.808594\n",
      "Train Epoch: 4422 [98560/118836 (83%)] Loss: 12178.332031\n",
      "    epoch          : 4422\n",
      "    loss           : 12185.660249948305\n",
      "    val_loss       : 12179.521528020487\n",
      "    val_log_likelihood: -12099.330144198459\n",
      "    val_log_marginal: -12108.20815431293\n",
      "Train Epoch: 4423 [256/118836 (0%)] Loss: 12157.002930\n",
      "Train Epoch: 4423 [33024/118836 (28%)] Loss: 12164.791016\n",
      "Train Epoch: 4423 [65792/118836 (55%)] Loss: 12221.576172\n",
      "Train Epoch: 4423 [98560/118836 (83%)] Loss: 12138.035156\n",
      "    epoch          : 4423\n",
      "    loss           : 12181.114775414857\n",
      "    val_loss       : 12176.730749434853\n",
      "    val_log_likelihood: -12097.587196772902\n",
      "    val_log_marginal: -12106.437301694179\n",
      "Train Epoch: 4424 [256/118836 (0%)] Loss: 12146.327148\n",
      "Train Epoch: 4424 [33024/118836 (28%)] Loss: 12193.215820\n",
      "Train Epoch: 4424 [65792/118836 (55%)] Loss: 12273.542969\n",
      "Train Epoch: 4424 [98560/118836 (83%)] Loss: 12219.014648\n",
      "    epoch          : 4424\n",
      "    loss           : 12178.81903674912\n",
      "    val_loss       : 12180.35557359459\n",
      "    val_log_likelihood: -12103.320811524247\n",
      "    val_log_marginal: -12112.233653329624\n",
      "Train Epoch: 4425 [256/118836 (0%)] Loss: 12173.749023\n",
      "Train Epoch: 4425 [33024/118836 (28%)] Loss: 12238.934570\n",
      "Train Epoch: 4425 [65792/118836 (55%)] Loss: 12195.746094\n",
      "Train Epoch: 4425 [98560/118836 (83%)] Loss: 12139.364258\n",
      "    epoch          : 4425\n",
      "    loss           : 12178.291960200837\n",
      "    val_loss       : 12182.215614756688\n",
      "    val_log_likelihood: -12097.359373707608\n",
      "    val_log_marginal: -12106.155886076596\n",
      "Train Epoch: 4426 [256/118836 (0%)] Loss: 12176.663086\n",
      "Train Epoch: 4426 [33024/118836 (28%)] Loss: 12215.456055\n",
      "Train Epoch: 4426 [65792/118836 (55%)] Loss: 12257.010742\n",
      "Train Epoch: 4426 [98560/118836 (83%)] Loss: 12178.064453\n",
      "    epoch          : 4426\n",
      "    loss           : 12183.262636508736\n",
      "    val_loss       : 12180.164537414492\n",
      "    val_log_likelihood: -12102.459978869418\n",
      "    val_log_marginal: -12111.233528166616\n",
      "Train Epoch: 4427 [256/118836 (0%)] Loss: 12186.495117\n",
      "Train Epoch: 4427 [33024/118836 (28%)] Loss: 12192.935547\n",
      "Train Epoch: 4427 [65792/118836 (55%)] Loss: 12105.353516\n",
      "Train Epoch: 4427 [98560/118836 (83%)] Loss: 12146.887695\n",
      "    epoch          : 4427\n",
      "    loss           : 12181.667051960556\n",
      "    val_loss       : 12182.86375695054\n",
      "    val_log_likelihood: -12102.350979470377\n",
      "    val_log_marginal: -12111.22868986161\n",
      "Train Epoch: 4428 [256/118836 (0%)] Loss: 12331.849609\n",
      "Train Epoch: 4428 [33024/118836 (28%)] Loss: 12165.945312\n",
      "Train Epoch: 4428 [65792/118836 (55%)] Loss: 12179.314453\n",
      "Train Epoch: 4428 [98560/118836 (83%)] Loss: 12122.343750\n",
      "    epoch          : 4428\n",
      "    loss           : 12180.247160133633\n",
      "    val_loss       : 12178.211137851458\n",
      "    val_log_likelihood: -12101.693799595483\n",
      "    val_log_marginal: -12110.484673692488\n",
      "Train Epoch: 4429 [256/118836 (0%)] Loss: 12224.405273\n",
      "Train Epoch: 4429 [33024/118836 (28%)] Loss: 12238.954102\n",
      "Train Epoch: 4429 [65792/118836 (55%)] Loss: 12188.134766\n",
      "Train Epoch: 4429 [98560/118836 (83%)] Loss: 12265.742188\n",
      "    epoch          : 4429\n",
      "    loss           : 12180.447539288669\n",
      "    val_loss       : 12180.638636994778\n",
      "    val_log_likelihood: -12100.003414495452\n",
      "    val_log_marginal: -12108.942398898089\n",
      "Train Epoch: 4430 [256/118836 (0%)] Loss: 12272.426758\n",
      "Train Epoch: 4430 [33024/118836 (28%)] Loss: 12178.288086\n",
      "Train Epoch: 4430 [65792/118836 (55%)] Loss: 12151.896484\n",
      "Train Epoch: 4430 [98560/118836 (83%)] Loss: 12127.494141\n",
      "    epoch          : 4430\n",
      "    loss           : 12182.15194100884\n",
      "    val_loss       : 12178.556095497213\n",
      "    val_log_likelihood: -12100.73133061285\n",
      "    val_log_marginal: -12109.63279722169\n",
      "Train Epoch: 4431 [256/118836 (0%)] Loss: 12212.660156\n",
      "Train Epoch: 4431 [33024/118836 (28%)] Loss: 12253.914062\n",
      "Train Epoch: 4431 [65792/118836 (55%)] Loss: 12280.670898\n",
      "Train Epoch: 4431 [98560/118836 (83%)] Loss: 12141.179688\n",
      "    epoch          : 4431\n",
      "    loss           : 12181.44478859724\n",
      "    val_loss       : 12180.632093468423\n",
      "    val_log_likelihood: -12101.58862599514\n",
      "    val_log_marginal: -12110.3262361625\n",
      "Train Epoch: 4432 [256/118836 (0%)] Loss: 12212.105469\n",
      "Train Epoch: 4432 [33024/118836 (28%)] Loss: 12145.689453\n",
      "Train Epoch: 4432 [65792/118836 (55%)] Loss: 12238.072266\n",
      "Train Epoch: 4432 [98560/118836 (83%)] Loss: 12172.983398\n",
      "    epoch          : 4432\n",
      "    loss           : 12179.96406266155\n",
      "    val_loss       : 12174.575209424485\n",
      "    val_log_likelihood: -12100.544504109803\n",
      "    val_log_marginal: -12109.279600780128\n",
      "Train Epoch: 4433 [256/118836 (0%)] Loss: 12277.556641\n",
      "Train Epoch: 4433 [33024/118836 (28%)] Loss: 12188.027344\n",
      "Train Epoch: 4433 [65792/118836 (55%)] Loss: 12186.941406\n",
      "Train Epoch: 4433 [98560/118836 (83%)] Loss: 12254.441406\n",
      "    epoch          : 4433\n",
      "    loss           : 12184.232948847188\n",
      "    val_loss       : 12185.278873548468\n",
      "    val_log_likelihood: -12102.379390573305\n",
      "    val_log_marginal: -12111.172167514835\n",
      "Train Epoch: 4434 [256/118836 (0%)] Loss: 12247.557617\n",
      "Train Epoch: 4434 [33024/118836 (28%)] Loss: 12184.530273\n",
      "Train Epoch: 4434 [65792/118836 (55%)] Loss: 12267.350586\n",
      "Train Epoch: 4434 [98560/118836 (83%)] Loss: 12152.062500\n",
      "    epoch          : 4434\n",
      "    loss           : 12182.87657445461\n",
      "    val_loss       : 12177.807515738928\n",
      "    val_log_likelihood: -12097.77395461771\n",
      "    val_log_marginal: -12106.494513771733\n",
      "Train Epoch: 4435 [256/118836 (0%)] Loss: 12105.333984\n",
      "Train Epoch: 4435 [33024/118836 (28%)] Loss: 12177.173828\n",
      "Train Epoch: 4435 [65792/118836 (55%)] Loss: 12196.099609\n",
      "Train Epoch: 4435 [98560/118836 (83%)] Loss: 12182.365234\n",
      "    epoch          : 4435\n",
      "    loss           : 12176.313870580027\n",
      "    val_loss       : 12179.544949136754\n",
      "    val_log_likelihood: -12100.174408892939\n",
      "    val_log_marginal: -12108.961036989038\n",
      "Train Epoch: 4436 [256/118836 (0%)] Loss: 12279.570312\n",
      "Train Epoch: 4436 [33024/118836 (28%)] Loss: 12151.907227\n",
      "Train Epoch: 4436 [65792/118836 (55%)] Loss: 12255.171875\n",
      "Train Epoch: 4436 [98560/118836 (83%)] Loss: 12258.738281\n",
      "    epoch          : 4436\n",
      "    loss           : 12184.954124825528\n",
      "    val_loss       : 12178.267261495324\n",
      "    val_log_likelihood: -12098.794990856339\n",
      "    val_log_marginal: -12107.49265014548\n",
      "Train Epoch: 4437 [256/118836 (0%)] Loss: 12276.445312\n",
      "Train Epoch: 4437 [33024/118836 (28%)] Loss: 12199.460938\n",
      "Train Epoch: 4437 [65792/118836 (55%)] Loss: 12299.796875\n",
      "Train Epoch: 4437 [98560/118836 (83%)] Loss: 12170.775391\n",
      "    epoch          : 4437\n",
      "    loss           : 12182.756027547302\n",
      "    val_loss       : 12182.08965363214\n",
      "    val_log_likelihood: -12099.953014015973\n",
      "    val_log_marginal: -12108.785985794144\n",
      "Train Epoch: 4438 [256/118836 (0%)] Loss: 12235.980469\n",
      "Train Epoch: 4438 [33024/118836 (28%)] Loss: 12161.862305\n",
      "Train Epoch: 4438 [65792/118836 (55%)] Loss: 12195.309570\n",
      "Train Epoch: 4438 [98560/118836 (83%)] Loss: 12264.844727\n",
      "    epoch          : 4438\n",
      "    loss           : 12186.37026015819\n",
      "    val_loss       : 12178.41557631301\n",
      "    val_log_likelihood: -12096.66748798077\n",
      "    val_log_marginal: -12105.530440248629\n",
      "Train Epoch: 4439 [256/118836 (0%)] Loss: 12177.234375\n",
      "Train Epoch: 4439 [33024/118836 (28%)] Loss: 12139.395508\n",
      "Train Epoch: 4439 [65792/118836 (55%)] Loss: 12191.125000\n",
      "Train Epoch: 4439 [98560/118836 (83%)] Loss: 12153.791992\n",
      "    epoch          : 4439\n",
      "    loss           : 12175.2967200747\n",
      "    val_loss       : 12188.649647488859\n",
      "    val_log_likelihood: -12097.21827601582\n",
      "    val_log_marginal: -12106.035325562463\n",
      "Train Epoch: 4440 [256/118836 (0%)] Loss: 12072.556641\n",
      "Train Epoch: 4440 [33024/118836 (28%)] Loss: 12156.156250\n",
      "Train Epoch: 4440 [65792/118836 (55%)] Loss: 12240.088867\n",
      "Train Epoch: 4440 [98560/118836 (83%)] Loss: 12214.114258\n",
      "    epoch          : 4440\n",
      "    loss           : 12182.869477777347\n",
      "    val_loss       : 12179.581086221166\n",
      "    val_log_likelihood: -12101.513752164754\n",
      "    val_log_marginal: -12110.39691379116\n",
      "Train Epoch: 4441 [256/118836 (0%)] Loss: 12265.445312\n",
      "Train Epoch: 4441 [33024/118836 (28%)] Loss: 12204.033203\n",
      "Train Epoch: 4441 [65792/118836 (55%)] Loss: 12133.978516\n",
      "Train Epoch: 4441 [98560/118836 (83%)] Loss: 12307.049805\n",
      "    epoch          : 4441\n",
      "    loss           : 12179.136996613937\n",
      "    val_loss       : 12177.620514507125\n",
      "    val_log_likelihood: -12099.40860311983\n",
      "    val_log_marginal: -12108.310482138306\n",
      "Train Epoch: 4442 [256/118836 (0%)] Loss: 12214.658203\n",
      "Train Epoch: 4442 [33024/118836 (28%)] Loss: 12152.478516\n",
      "Train Epoch: 4442 [65792/118836 (55%)] Loss: 12190.994141\n",
      "Train Epoch: 4442 [98560/118836 (83%)] Loss: 12119.113281\n",
      "    epoch          : 4442\n",
      "    loss           : 12183.776021311518\n",
      "    val_loss       : 12181.830367418224\n",
      "    val_log_likelihood: -12097.381988924215\n",
      "    val_log_marginal: -12106.204630434191\n",
      "Train Epoch: 4443 [256/118836 (0%)] Loss: 12135.500000\n",
      "Train Epoch: 4443 [33024/118836 (28%)] Loss: 12139.025391\n",
      "Train Epoch: 4443 [65792/118836 (55%)] Loss: 12194.404297\n",
      "Train Epoch: 4443 [98560/118836 (83%)] Loss: 12150.204102\n",
      "    epoch          : 4443\n",
      "    loss           : 12176.452757153382\n",
      "    val_loss       : 12174.568957006164\n",
      "    val_log_likelihood: -12099.607482617348\n",
      "    val_log_marginal: -12108.41352339837\n",
      "Train Epoch: 4444 [256/118836 (0%)] Loss: 12218.282227\n",
      "Train Epoch: 4444 [33024/118836 (28%)] Loss: 12231.578125\n",
      "Train Epoch: 4444 [65792/118836 (55%)] Loss: 12159.916016\n",
      "Train Epoch: 4444 [98560/118836 (83%)] Loss: 12098.369141\n",
      "    epoch          : 4444\n",
      "    loss           : 12181.422484200528\n",
      "    val_loss       : 12178.971387026115\n",
      "    val_log_likelihood: -12101.563978817721\n",
      "    val_log_marginal: -12110.421393227964\n",
      "Train Epoch: 4445 [256/118836 (0%)] Loss: 12224.692383\n",
      "Train Epoch: 4445 [33024/118836 (28%)] Loss: 12201.017578\n",
      "Train Epoch: 4445 [65792/118836 (55%)] Loss: 12177.764648\n",
      "Train Epoch: 4445 [98560/118836 (83%)] Loss: 12209.210938\n",
      "    epoch          : 4445\n",
      "    loss           : 12176.512599190963\n",
      "    val_loss       : 12178.085704763438\n",
      "    val_log_likelihood: -12100.63126227771\n",
      "    val_log_marginal: -12109.4049725833\n",
      "Train Epoch: 4446 [256/118836 (0%)] Loss: 12209.252930\n",
      "Train Epoch: 4446 [33024/118836 (28%)] Loss: 12294.352539\n",
      "Train Epoch: 4446 [65792/118836 (55%)] Loss: 12171.993164\n",
      "Train Epoch: 4446 [98560/118836 (83%)] Loss: 12221.036133\n",
      "    epoch          : 4446\n",
      "    loss           : 12180.203549550248\n",
      "    val_loss       : 12174.939634956036\n",
      "    val_log_likelihood: -12099.14292303169\n",
      "    val_log_marginal: -12107.966739059884\n",
      "Train Epoch: 4447 [256/118836 (0%)] Loss: 12140.990234\n",
      "Train Epoch: 4447 [33024/118836 (28%)] Loss: 12187.981445\n",
      "Train Epoch: 4447 [65792/118836 (55%)] Loss: 12157.506836\n",
      "Train Epoch: 4447 [98560/118836 (83%)] Loss: 12305.452148\n",
      "    epoch          : 4447\n",
      "    loss           : 12179.50937483845\n",
      "    val_loss       : 12183.032732790274\n",
      "    val_log_likelihood: -12104.530554047768\n",
      "    val_log_marginal: -12113.343573126383\n",
      "Train Epoch: 4448 [256/118836 (0%)] Loss: 12291.285156\n",
      "Train Epoch: 4448 [33024/118836 (28%)] Loss: 12152.864258\n",
      "Train Epoch: 4448 [65792/118836 (55%)] Loss: 12200.930664\n",
      "Train Epoch: 4448 [98560/118836 (83%)] Loss: 12214.675781\n",
      "    epoch          : 4448\n",
      "    loss           : 12180.647221360628\n",
      "    val_loss       : 12180.275024012612\n",
      "    val_log_likelihood: -12100.826343116729\n",
      "    val_log_marginal: -12109.641790941363\n",
      "Train Epoch: 4449 [256/118836 (0%)] Loss: 12163.458984\n",
      "Train Epoch: 4449 [33024/118836 (28%)] Loss: 12312.023438\n",
      "Train Epoch: 4449 [65792/118836 (55%)] Loss: 12287.599609\n",
      "Train Epoch: 4449 [98560/118836 (83%)] Loss: 12147.017578\n",
      "    epoch          : 4449\n",
      "    loss           : 12177.804483463866\n",
      "    val_loss       : 12178.01006758887\n",
      "    val_log_likelihood: -12099.502258129136\n",
      "    val_log_marginal: -12108.426525421699\n",
      "Train Epoch: 4450 [256/118836 (0%)] Loss: 12180.541016\n",
      "Train Epoch: 4450 [33024/118836 (28%)] Loss: 12172.115234\n",
      "Train Epoch: 4450 [65792/118836 (55%)] Loss: 12184.196289\n",
      "Train Epoch: 4450 [98560/118836 (83%)] Loss: 12152.939453\n",
      "    epoch          : 4450\n",
      "    loss           : 12177.3427330503\n",
      "    val_loss       : 12177.906146041349\n",
      "    val_log_likelihood: -12097.104820131564\n",
      "    val_log_marginal: -12106.027646890625\n",
      "Train Epoch: 4451 [256/118836 (0%)] Loss: 12282.328125\n",
      "Train Epoch: 4451 [33024/118836 (28%)] Loss: 12257.907227\n",
      "Train Epoch: 4451 [65792/118836 (55%)] Loss: 12209.837891\n",
      "Train Epoch: 4451 [98560/118836 (83%)] Loss: 12144.986328\n",
      "    epoch          : 4451\n",
      "    loss           : 12177.698004226117\n",
      "    val_loss       : 12171.956678123792\n",
      "    val_log_likelihood: -12098.525248623604\n",
      "    val_log_marginal: -12107.258549034734\n",
      "Train Epoch: 4452 [256/118836 (0%)] Loss: 12191.400391\n",
      "Train Epoch: 4452 [33024/118836 (28%)] Loss: 12173.115234\n",
      "Train Epoch: 4452 [65792/118836 (55%)] Loss: 12206.306641\n",
      "Train Epoch: 4452 [98560/118836 (83%)] Loss: 12208.784180\n",
      "    epoch          : 4452\n",
      "    loss           : 12176.540671687604\n",
      "    val_loss       : 12180.690999448498\n",
      "    val_log_likelihood: -12103.906672288565\n",
      "    val_log_marginal: -12112.65705601168\n",
      "Train Epoch: 4453 [256/118836 (0%)] Loss: 12204.591797\n",
      "Train Epoch: 4453 [33024/118836 (28%)] Loss: 12211.652344\n",
      "Train Epoch: 4453 [65792/118836 (55%)] Loss: 12249.070312\n",
      "Train Epoch: 4453 [98560/118836 (83%)] Loss: 12205.796875\n",
      "    epoch          : 4453\n",
      "    loss           : 12181.321067902192\n",
      "    val_loss       : 12174.794755953222\n",
      "    val_log_likelihood: -12100.43271411678\n",
      "    val_log_marginal: -12109.237107905532\n",
      "Train Epoch: 4454 [256/118836 (0%)] Loss: 12235.575195\n",
      "Train Epoch: 4454 [33024/118836 (28%)] Loss: 12237.220703\n",
      "Train Epoch: 4454 [65792/118836 (55%)] Loss: 12310.364258\n",
      "Train Epoch: 4454 [98560/118836 (83%)] Loss: 12164.749023\n",
      "    epoch          : 4454\n",
      "    loss           : 12181.088555398315\n",
      "    val_loss       : 12183.43554608008\n",
      "    val_log_likelihood: -12102.50445583902\n",
      "    val_log_marginal: -12111.342828354831\n",
      "Train Epoch: 4455 [256/118836 (0%)] Loss: 12156.164062\n",
      "Train Epoch: 4455 [33024/118836 (28%)] Loss: 12227.310547\n",
      "Train Epoch: 4455 [65792/118836 (55%)] Loss: 12251.204102\n",
      "Train Epoch: 4455 [98560/118836 (83%)] Loss: 12140.721680\n",
      "    epoch          : 4455\n",
      "    loss           : 12185.54066264087\n",
      "    val_loss       : 12179.182510851251\n",
      "    val_log_likelihood: -12096.111278529517\n",
      "    val_log_marginal: -12104.888212028323\n",
      "Train Epoch: 4456 [256/118836 (0%)] Loss: 12199.172852\n",
      "Train Epoch: 4456 [33024/118836 (28%)] Loss: 12258.391602\n",
      "Train Epoch: 4456 [65792/118836 (55%)] Loss: 12344.025391\n",
      "Train Epoch: 4456 [98560/118836 (83%)] Loss: 12218.813477\n",
      "    epoch          : 4456\n",
      "    loss           : 12174.890151823562\n",
      "    val_loss       : 12178.073333037932\n",
      "    val_log_likelihood: -12098.799523592586\n",
      "    val_log_marginal: -12107.564942535015\n",
      "Train Epoch: 4457 [256/118836 (0%)] Loss: 12113.355469\n",
      "Train Epoch: 4457 [33024/118836 (28%)] Loss: 12199.310547\n",
      "Train Epoch: 4457 [65792/118836 (55%)] Loss: 12222.400391\n",
      "Train Epoch: 4457 [98560/118836 (83%)] Loss: 12247.207031\n",
      "    epoch          : 4457\n",
      "    loss           : 12180.381179403174\n",
      "    val_loss       : 12180.086975695875\n",
      "    val_log_likelihood: -12100.235793560018\n",
      "    val_log_marginal: -12109.11067527374\n",
      "Train Epoch: 4458 [256/118836 (0%)] Loss: 12263.800781\n",
      "Train Epoch: 4458 [33024/118836 (28%)] Loss: 12185.686523\n",
      "Train Epoch: 4458 [65792/118836 (55%)] Loss: 12172.510742\n",
      "Train Epoch: 4458 [98560/118836 (83%)] Loss: 12362.060547\n",
      "    epoch          : 4458\n",
      "    loss           : 12178.795186168838\n",
      "    val_loss       : 12181.04292390642\n",
      "    val_log_likelihood: -12098.750898857526\n",
      "    val_log_marginal: -12107.677369131603\n",
      "Train Epoch: 4459 [256/118836 (0%)] Loss: 12189.500000\n",
      "Train Epoch: 4459 [33024/118836 (28%)] Loss: 12194.492188\n",
      "Train Epoch: 4459 [65792/118836 (55%)] Loss: 12282.758789\n",
      "Train Epoch: 4459 [98560/118836 (83%)] Loss: 12148.179688\n",
      "    epoch          : 4459\n",
      "    loss           : 12183.365842767782\n",
      "    val_loss       : 12181.529663758114\n",
      "    val_log_likelihood: -12100.263135532983\n",
      "    val_log_marginal: -12109.1390044102\n",
      "Train Epoch: 4460 [256/118836 (0%)] Loss: 12154.658203\n",
      "Train Epoch: 4460 [33024/118836 (28%)] Loss: 12104.952148\n",
      "Train Epoch: 4460 [65792/118836 (55%)] Loss: 12129.472656\n",
      "Train Epoch: 4460 [98560/118836 (83%)] Loss: 12209.788086\n",
      "    epoch          : 4460\n",
      "    loss           : 12181.520052244883\n",
      "    val_loss       : 12180.52772252316\n",
      "    val_log_likelihood: -12102.353876525021\n",
      "    val_log_marginal: -12111.19780886361\n",
      "Train Epoch: 4461 [256/118836 (0%)] Loss: 12233.972656\n",
      "Train Epoch: 4461 [33024/118836 (28%)] Loss: 12186.209961\n",
      "Train Epoch: 4461 [65792/118836 (55%)] Loss: 12331.360352\n",
      "Train Epoch: 4461 [98560/118836 (83%)] Loss: 12193.485352\n",
      "    epoch          : 4461\n",
      "    loss           : 12174.67549046216\n",
      "    val_loss       : 12181.34507224266\n",
      "    val_log_likelihood: -12099.605015605614\n",
      "    val_log_marginal: -12108.425021758607\n",
      "Train Epoch: 4462 [256/118836 (0%)] Loss: 12262.923828\n",
      "Train Epoch: 4462 [33024/118836 (28%)] Loss: 12133.136719\n",
      "Train Epoch: 4462 [65792/118836 (55%)] Loss: 12170.603516\n",
      "Train Epoch: 4462 [98560/118836 (83%)] Loss: 12200.496094\n",
      "    epoch          : 4462\n",
      "    loss           : 12178.416434197943\n",
      "    val_loss       : 12180.300008358234\n",
      "    val_log_likelihood: -12099.472981447736\n",
      "    val_log_marginal: -12108.278344840128\n",
      "Train Epoch: 4463 [256/118836 (0%)] Loss: 12230.137695\n",
      "Train Epoch: 4463 [33024/118836 (28%)] Loss: 12161.389648\n",
      "Train Epoch: 4463 [65792/118836 (55%)] Loss: 12201.497070\n",
      "Train Epoch: 4463 [98560/118836 (83%)] Loss: 12167.658203\n",
      "    epoch          : 4463\n",
      "    loss           : 12177.57236255428\n",
      "    val_loss       : 12178.604228839167\n",
      "    val_log_likelihood: -12100.769856609284\n",
      "    val_log_marginal: -12109.558044007314\n",
      "Train Epoch: 4464 [256/118836 (0%)] Loss: 12181.347656\n",
      "Train Epoch: 4464 [33024/118836 (28%)] Loss: 12135.528320\n",
      "Train Epoch: 4464 [65792/118836 (55%)] Loss: 12139.035156\n",
      "Train Epoch: 4464 [98560/118836 (83%)] Loss: 12168.982422\n",
      "    epoch          : 4464\n",
      "    loss           : 12179.60262920673\n",
      "    val_loss       : 12174.632503933597\n",
      "    val_log_likelihood: -12097.95896272746\n",
      "    val_log_marginal: -12106.747413466017\n",
      "Train Epoch: 4465 [256/118836 (0%)] Loss: 12155.275391\n",
      "Train Epoch: 4465 [33024/118836 (28%)] Loss: 12292.867188\n",
      "Train Epoch: 4465 [65792/118836 (55%)] Loss: 12121.965820\n",
      "Train Epoch: 4465 [98560/118836 (83%)] Loss: 12252.312500\n",
      "    epoch          : 4465\n",
      "    loss           : 12180.44907319453\n",
      "    val_loss       : 12174.625452751736\n",
      "    val_log_likelihood: -12099.04967819479\n",
      "    val_log_marginal: -12107.787906160858\n",
      "Train Epoch: 4466 [256/118836 (0%)] Loss: 12163.545898\n",
      "Train Epoch: 4466 [33024/118836 (28%)] Loss: 12183.267578\n",
      "Train Epoch: 4466 [65792/118836 (55%)] Loss: 12122.575195\n",
      "Train Epoch: 4466 [98560/118836 (83%)] Loss: 12168.301758\n",
      "    epoch          : 4466\n",
      "    loss           : 12178.494533188585\n",
      "    val_loss       : 12177.61022840658\n",
      "    val_log_likelihood: -12098.499727144077\n",
      "    val_log_marginal: -12107.212421843642\n",
      "Train Epoch: 4467 [256/118836 (0%)] Loss: 12185.404297\n",
      "Train Epoch: 4467 [33024/118836 (28%)] Loss: 12159.669922\n",
      "Train Epoch: 4467 [65792/118836 (55%)] Loss: 12149.287109\n",
      "Train Epoch: 4467 [98560/118836 (83%)] Loss: 12203.818359\n",
      "    epoch          : 4467\n",
      "    loss           : 12178.523789030189\n",
      "    val_loss       : 12180.216801787641\n",
      "    val_log_likelihood: -12099.412073026519\n",
      "    val_log_marginal: -12108.088554763628\n",
      "Train Epoch: 4468 [256/118836 (0%)] Loss: 12162.017578\n",
      "Train Epoch: 4468 [33024/118836 (28%)] Loss: 12121.994141\n",
      "Train Epoch: 4468 [65792/118836 (55%)] Loss: 12259.803711\n",
      "Train Epoch: 4468 [98560/118836 (83%)] Loss: 12143.091797\n",
      "    epoch          : 4468\n",
      "    loss           : 12179.673581924628\n",
      "    val_loss       : 12177.794395391416\n",
      "    val_log_likelihood: -12099.474223758012\n",
      "    val_log_marginal: -12108.173626895097\n",
      "Train Epoch: 4469 [256/118836 (0%)] Loss: 12056.970703\n",
      "Train Epoch: 4469 [33024/118836 (28%)] Loss: 12120.236328\n",
      "Train Epoch: 4469 [65792/118836 (55%)] Loss: 12211.441406\n",
      "Train Epoch: 4469 [98560/118836 (83%)] Loss: 12116.179688\n",
      "    epoch          : 4469\n",
      "    loss           : 12177.382921706989\n",
      "    val_loss       : 12179.729738365226\n",
      "    val_log_likelihood: -12097.489867013028\n",
      "    val_log_marginal: -12106.188074939799\n",
      "Train Epoch: 4470 [256/118836 (0%)] Loss: 12149.462891\n",
      "Train Epoch: 4470 [33024/118836 (28%)] Loss: 12266.931641\n",
      "Train Epoch: 4470 [65792/118836 (55%)] Loss: 12198.599609\n",
      "Train Epoch: 4470 [98560/118836 (83%)] Loss: 12259.541016\n",
      "    epoch          : 4470\n",
      "    loss           : 12178.265578473945\n",
      "    val_loss       : 12179.562647697521\n",
      "    val_log_likelihood: -12103.02765618538\n",
      "    val_log_marginal: -12111.911896099922\n",
      "Train Epoch: 4471 [256/118836 (0%)] Loss: 12199.590820\n",
      "Train Epoch: 4471 [33024/118836 (28%)] Loss: 12212.916016\n",
      "Train Epoch: 4471 [65792/118836 (55%)] Loss: 12136.398438\n",
      "Train Epoch: 4471 [98560/118836 (83%)] Loss: 12245.103516\n",
      "    epoch          : 4471\n",
      "    loss           : 12180.534400847808\n",
      "    val_loss       : 12178.044896773294\n",
      "    val_log_likelihood: -12099.156333843826\n",
      "    val_log_marginal: -12108.00465428457\n",
      "Train Epoch: 4472 [256/118836 (0%)] Loss: 12287.018555\n",
      "Train Epoch: 4472 [33024/118836 (28%)] Loss: 12165.982422\n",
      "Train Epoch: 4472 [65792/118836 (55%)] Loss: 12284.222656\n",
      "Train Epoch: 4472 [98560/118836 (83%)] Loss: 12148.331055\n",
      "    epoch          : 4472\n",
      "    loss           : 12179.537515024038\n",
      "    val_loss       : 12179.987704026715\n",
      "    val_log_likelihood: -12101.32005111404\n",
      "    val_log_marginal: -12110.184331690174\n",
      "Train Epoch: 4473 [256/118836 (0%)] Loss: 12118.990234\n",
      "Train Epoch: 4473 [33024/118836 (28%)] Loss: 12252.069336\n",
      "Train Epoch: 4473 [65792/118836 (55%)] Loss: 12142.011719\n",
      "Train Epoch: 4473 [98560/118836 (83%)] Loss: 12240.069336\n",
      "    epoch          : 4473\n",
      "    loss           : 12181.050445713141\n",
      "    val_loss       : 12181.295620593295\n",
      "    val_log_likelihood: -12099.76360967871\n",
      "    val_log_marginal: -12108.638692275419\n",
      "Train Epoch: 4474 [256/118836 (0%)] Loss: 12128.652344\n",
      "Train Epoch: 4474 [33024/118836 (28%)] Loss: 12148.263672\n",
      "Train Epoch: 4474 [65792/118836 (55%)] Loss: 12148.239258\n",
      "Train Epoch: 4474 [98560/118836 (83%)] Loss: 12243.244141\n",
      "    epoch          : 4474\n",
      "    loss           : 12181.24346179694\n",
      "    val_loss       : 12180.730605722802\n",
      "    val_log_likelihood: -12101.986816325476\n",
      "    val_log_marginal: -12110.78774793301\n",
      "Train Epoch: 4475 [256/118836 (0%)] Loss: 12232.608398\n",
      "Train Epoch: 4475 [33024/118836 (28%)] Loss: 12068.228516\n",
      "Train Epoch: 4475 [65792/118836 (55%)] Loss: 12144.213867\n",
      "Train Epoch: 4475 [98560/118836 (83%)] Loss: 12135.700195\n",
      "    epoch          : 4475\n",
      "    loss           : 12177.615748261735\n",
      "    val_loss       : 12176.479860600779\n",
      "    val_log_likelihood: -12101.239736481595\n",
      "    val_log_marginal: -12110.086962848341\n",
      "Train Epoch: 4476 [256/118836 (0%)] Loss: 12159.340820\n",
      "Train Epoch: 4476 [33024/118836 (28%)] Loss: 12154.857422\n",
      "Train Epoch: 4476 [65792/118836 (55%)] Loss: 12150.758789\n",
      "Train Epoch: 4476 [98560/118836 (83%)] Loss: 12160.671875\n",
      "    epoch          : 4476\n",
      "    loss           : 12181.998812939413\n",
      "    val_loss       : 12182.13544998258\n",
      "    val_log_likelihood: -12099.991182181813\n",
      "    val_log_marginal: -12108.796454114809\n",
      "Train Epoch: 4477 [256/118836 (0%)] Loss: 12149.572266\n",
      "Train Epoch: 4477 [33024/118836 (28%)] Loss: 12272.369141\n",
      "Train Epoch: 4477 [65792/118836 (55%)] Loss: 12217.138672\n",
      "Train Epoch: 4477 [98560/118836 (83%)] Loss: 12237.114258\n",
      "    epoch          : 4477\n",
      "    loss           : 12176.143884247052\n",
      "    val_loss       : 12181.078245377588\n",
      "    val_log_likelihood: -12098.322169503463\n",
      "    val_log_marginal: -12107.124900364537\n",
      "Train Epoch: 4478 [256/118836 (0%)] Loss: 12144.083008\n",
      "Train Epoch: 4478 [33024/118836 (28%)] Loss: 12266.389648\n",
      "Train Epoch: 4478 [65792/118836 (55%)] Loss: 12295.573242\n",
      "Train Epoch: 4478 [98560/118836 (83%)] Loss: 12200.759766\n",
      "    epoch          : 4478\n",
      "    loss           : 12180.026067029828\n",
      "    val_loss       : 12180.837916838214\n",
      "    val_log_likelihood: -12100.380862282878\n",
      "    val_log_marginal: -12109.322020157148\n",
      "Train Epoch: 4479 [256/118836 (0%)] Loss: 12247.801758\n",
      "Train Epoch: 4479 [33024/118836 (28%)] Loss: 12205.842773\n",
      "Train Epoch: 4479 [65792/118836 (55%)] Loss: 12191.554688\n",
      "Train Epoch: 4479 [98560/118836 (83%)] Loss: 12182.751953\n",
      "    epoch          : 4479\n",
      "    loss           : 12180.900521964175\n",
      "    val_loss       : 12178.749163599983\n",
      "    val_log_likelihood: -12102.180722543166\n",
      "    val_log_marginal: -12110.985504907476\n",
      "Train Epoch: 4480 [256/118836 (0%)] Loss: 12261.922852\n",
      "Train Epoch: 4480 [33024/118836 (28%)] Loss: 12161.390625\n",
      "Train Epoch: 4480 [65792/118836 (55%)] Loss: 12200.701172\n",
      "Train Epoch: 4480 [98560/118836 (83%)] Loss: 12190.541016\n",
      "    epoch          : 4480\n",
      "    loss           : 12182.117392990076\n",
      "    val_loss       : 12179.763828376032\n",
      "    val_log_likelihood: -12101.237818735784\n",
      "    val_log_marginal: -12110.191280416411\n",
      "Train Epoch: 4481 [256/118836 (0%)] Loss: 12143.271484\n",
      "Train Epoch: 4481 [33024/118836 (28%)] Loss: 12266.842773\n",
      "Train Epoch: 4481 [65792/118836 (55%)] Loss: 12224.825195\n",
      "Train Epoch: 4481 [98560/118836 (83%)] Loss: 12287.722656\n",
      "    epoch          : 4481\n",
      "    loss           : 12184.821213780759\n",
      "    val_loss       : 12178.632117380093\n",
      "    val_log_likelihood: -12099.591494940292\n",
      "    val_log_marginal: -12108.50826613179\n",
      "Train Epoch: 4482 [256/118836 (0%)] Loss: 12264.315430\n",
      "Train Epoch: 4482 [33024/118836 (28%)] Loss: 12162.247070\n",
      "Train Epoch: 4482 [65792/118836 (55%)] Loss: 12321.218750\n",
      "Train Epoch: 4482 [98560/118836 (83%)] Loss: 12124.042969\n",
      "    epoch          : 4482\n",
      "    loss           : 12184.901948278535\n",
      "    val_loss       : 12182.796492310572\n",
      "    val_log_likelihood: -12100.131612838606\n",
      "    val_log_marginal: -12109.235392556113\n",
      "Train Epoch: 4483 [256/118836 (0%)] Loss: 12157.988281\n",
      "Train Epoch: 4483 [33024/118836 (28%)] Loss: 12255.710938\n",
      "Train Epoch: 4483 [65792/118836 (55%)] Loss: 12206.178711\n",
      "Train Epoch: 4483 [98560/118836 (83%)] Loss: 12283.394531\n",
      "    epoch          : 4483\n",
      "    loss           : 12175.661763499018\n",
      "    val_loss       : 12177.297212226673\n",
      "    val_log_likelihood: -12097.77551986404\n",
      "    val_log_marginal: -12106.649948823655\n",
      "Train Epoch: 4484 [256/118836 (0%)] Loss: 12182.702148\n",
      "Train Epoch: 4484 [33024/118836 (28%)] Loss: 12226.880859\n",
      "Train Epoch: 4484 [65792/118836 (55%)] Loss: 12243.425781\n",
      "Train Epoch: 4484 [98560/118836 (83%)] Loss: 12257.813477\n",
      "    epoch          : 4484\n",
      "    loss           : 12179.455072147693\n",
      "    val_loss       : 12180.595079578681\n",
      "    val_log_likelihood: -12100.25134570151\n",
      "    val_log_marginal: -12109.180300637863\n",
      "Train Epoch: 4485 [256/118836 (0%)] Loss: 12200.643555\n",
      "Train Epoch: 4485 [33024/118836 (28%)] Loss: 12270.969727\n",
      "Train Epoch: 4485 [65792/118836 (55%)] Loss: 12147.397461\n",
      "Train Epoch: 4485 [98560/118836 (83%)] Loss: 12175.437500\n",
      "    epoch          : 4485\n",
      "    loss           : 12177.97307659998\n",
      "    val_loss       : 12180.064300412196\n",
      "    val_log_likelihood: -12100.443335465778\n",
      "    val_log_marginal: -12109.261911402868\n",
      "Train Epoch: 4486 [256/118836 (0%)] Loss: 12236.785156\n",
      "Train Epoch: 4486 [33024/118836 (28%)] Loss: 12184.244141\n",
      "Train Epoch: 4486 [65792/118836 (55%)] Loss: 12166.949219\n",
      "Train Epoch: 4486 [98560/118836 (83%)] Loss: 12159.699219\n",
      "    epoch          : 4486\n",
      "    loss           : 12180.978361507445\n",
      "    val_loss       : 12182.052512814886\n",
      "    val_log_likelihood: -12100.632506526572\n",
      "    val_log_marginal: -12109.511542688864\n",
      "Train Epoch: 4487 [256/118836 (0%)] Loss: 12203.442383\n",
      "Train Epoch: 4487 [33024/118836 (28%)] Loss: 12153.751953\n",
      "Train Epoch: 4487 [65792/118836 (55%)] Loss: 12195.726562\n",
      "Train Epoch: 4487 [98560/118836 (83%)] Loss: 12280.174805\n",
      "    epoch          : 4487\n",
      "    loss           : 12176.928732908136\n",
      "    val_loss       : 12178.20484908375\n",
      "    val_log_likelihood: -12099.213072852048\n",
      "    val_log_marginal: -12108.000884254932\n",
      "Train Epoch: 4488 [256/118836 (0%)] Loss: 12214.846680\n",
      "Train Epoch: 4488 [33024/118836 (28%)] Loss: 12171.705078\n",
      "Train Epoch: 4488 [65792/118836 (55%)] Loss: 12117.564453\n",
      "Train Epoch: 4488 [98560/118836 (83%)] Loss: 12264.637695\n",
      "    epoch          : 4488\n",
      "    loss           : 12179.26210404389\n",
      "    val_loss       : 12177.594377201187\n",
      "    val_log_likelihood: -12100.32244865979\n",
      "    val_log_marginal: -12109.131077938437\n",
      "Train Epoch: 4489 [256/118836 (0%)] Loss: 12247.371094\n",
      "Train Epoch: 4489 [33024/118836 (28%)] Loss: 12219.578125\n",
      "Train Epoch: 4489 [65792/118836 (55%)] Loss: 12227.472656\n",
      "Train Epoch: 4489 [98560/118836 (83%)] Loss: 12234.307617\n",
      "    epoch          : 4489\n",
      "    loss           : 12172.876046997777\n",
      "    val_loss       : 12179.920518136369\n",
      "    val_log_likelihood: -12099.065533886478\n",
      "    val_log_marginal: -12107.845602476857\n",
      "Train Epoch: 4490 [256/118836 (0%)] Loss: 12206.056641\n",
      "Train Epoch: 4490 [33024/118836 (28%)] Loss: 12179.488281\n",
      "Train Epoch: 4490 [65792/118836 (55%)] Loss: 12239.437500\n",
      "Train Epoch: 4490 [98560/118836 (83%)] Loss: 12313.964844\n",
      "    epoch          : 4490\n",
      "    loss           : 12173.91893190395\n",
      "    val_loss       : 12182.404935348497\n",
      "    val_log_likelihood: -12096.983990352306\n",
      "    val_log_marginal: -12105.737294549468\n",
      "Train Epoch: 4491 [256/118836 (0%)] Loss: 12204.779297\n",
      "Train Epoch: 4491 [33024/118836 (28%)] Loss: 12079.537109\n",
      "Train Epoch: 4491 [65792/118836 (55%)] Loss: 12131.283203\n",
      "Train Epoch: 4491 [98560/118836 (83%)] Loss: 12173.891602\n",
      "    epoch          : 4491\n",
      "    loss           : 12180.914738420182\n",
      "    val_loss       : 12179.685840516728\n",
      "    val_log_likelihood: -12098.297588076406\n",
      "    val_log_marginal: -12107.099317669048\n",
      "Train Epoch: 4492 [256/118836 (0%)] Loss: 12128.870117\n",
      "Train Epoch: 4492 [33024/118836 (28%)] Loss: 12107.917969\n",
      "Train Epoch: 4492 [65792/118836 (55%)] Loss: 12156.017578\n",
      "Train Epoch: 4492 [98560/118836 (83%)] Loss: 12187.411133\n",
      "    epoch          : 4492\n",
      "    loss           : 12177.914811117142\n",
      "    val_loss       : 12181.213247113366\n",
      "    val_log_likelihood: -12099.788576399658\n",
      "    val_log_marginal: -12108.599395028528\n",
      "Train Epoch: 4493 [256/118836 (0%)] Loss: 12140.911133\n",
      "Train Epoch: 4493 [33024/118836 (28%)] Loss: 12227.818359\n",
      "Train Epoch: 4493 [65792/118836 (55%)] Loss: 12157.589844\n",
      "Train Epoch: 4493 [98560/118836 (83%)] Loss: 12207.878906\n",
      "    epoch          : 4493\n",
      "    loss           : 12181.062977861353\n",
      "    val_loss       : 12181.078691600094\n",
      "    val_log_likelihood: -12096.26239499328\n",
      "    val_log_marginal: -12105.095676079249\n",
      "Train Epoch: 4494 [256/118836 (0%)] Loss: 12169.973633\n",
      "Train Epoch: 4494 [33024/118836 (28%)] Loss: 12186.655273\n",
      "Train Epoch: 4494 [65792/118836 (55%)] Loss: 12199.136719\n",
      "Train Epoch: 4494 [98560/118836 (83%)] Loss: 12260.302734\n",
      "    epoch          : 4494\n",
      "    loss           : 12177.922689044408\n",
      "    val_loss       : 12177.645721508\n",
      "    val_log_likelihood: -12099.298795976789\n",
      "    val_log_marginal: -12108.151896274561\n",
      "Train Epoch: 4495 [256/118836 (0%)] Loss: 12184.611328\n",
      "Train Epoch: 4495 [33024/118836 (28%)] Loss: 12147.696289\n",
      "Train Epoch: 4495 [65792/118836 (55%)] Loss: 12183.164062\n",
      "Train Epoch: 4495 [98560/118836 (83%)] Loss: 12136.394531\n",
      "    epoch          : 4495\n",
      "    loss           : 12176.173352848427\n",
      "    val_loss       : 12177.60452646857\n",
      "    val_log_likelihood: -12101.104431283602\n",
      "    val_log_marginal: -12109.940374673984\n",
      "Train Epoch: 4496 [256/118836 (0%)] Loss: 12176.218750\n",
      "Train Epoch: 4496 [33024/118836 (28%)] Loss: 12155.547852\n",
      "Train Epoch: 4496 [65792/118836 (55%)] Loss: 12212.998047\n",
      "Train Epoch: 4496 [98560/118836 (83%)] Loss: 12134.037109\n",
      "    epoch          : 4496\n",
      "    loss           : 12180.41380499121\n",
      "    val_loss       : 12178.504132302925\n",
      "    val_log_likelihood: -12098.812346851737\n",
      "    val_log_marginal: -12107.778710635359\n",
      "Train Epoch: 4497 [256/118836 (0%)] Loss: 12182.948242\n",
      "Train Epoch: 4497 [33024/118836 (28%)] Loss: 12156.158203\n",
      "Train Epoch: 4497 [65792/118836 (55%)] Loss: 12130.653320\n",
      "Train Epoch: 4497 [98560/118836 (83%)] Loss: 12128.421875\n",
      "    epoch          : 4497\n",
      "    loss           : 12179.328648579663\n",
      "    val_loss       : 12181.50090597264\n",
      "    val_log_likelihood: -12098.736963334884\n",
      "    val_log_marginal: -12107.576036973402\n",
      "Train Epoch: 4498 [256/118836 (0%)] Loss: 12145.464844\n",
      "Train Epoch: 4498 [33024/118836 (28%)] Loss: 12204.879883\n",
      "Train Epoch: 4498 [65792/118836 (55%)] Loss: 12175.837891\n",
      "Train Epoch: 4498 [98560/118836 (83%)] Loss: 12108.775391\n",
      "    epoch          : 4498\n",
      "    loss           : 12180.959475806452\n",
      "    val_loss       : 12179.460246894329\n",
      "    val_log_likelihood: -12099.760404712057\n",
      "    val_log_marginal: -12108.69933007038\n",
      "Train Epoch: 4499 [256/118836 (0%)] Loss: 12187.962891\n",
      "Train Epoch: 4499 [33024/118836 (28%)] Loss: 12182.610352\n",
      "Train Epoch: 4499 [65792/118836 (55%)] Loss: 12220.157227\n",
      "Train Epoch: 4499 [98560/118836 (83%)] Loss: 12172.095703\n",
      "    epoch          : 4499\n",
      "    loss           : 12184.690928873293\n",
      "    val_loss       : 12179.764344223186\n",
      "    val_log_likelihood: -12100.621182763389\n",
      "    val_log_marginal: -12109.435652486705\n",
      "Train Epoch: 4500 [256/118836 (0%)] Loss: 12207.589844\n",
      "Train Epoch: 4500 [33024/118836 (28%)] Loss: 12145.925781\n",
      "Train Epoch: 4500 [65792/118836 (55%)] Loss: 12230.362305\n",
      "Train Epoch: 4500 [98560/118836 (83%)] Loss: 12140.877930\n",
      "    epoch          : 4500\n",
      "    loss           : 12178.629529020627\n",
      "    val_loss       : 12179.844685564078\n",
      "    val_log_likelihood: -12098.767490080903\n",
      "    val_log_marginal: -12107.59827465288\n",
      "Saving checkpoint: saved/models/SelfiesAutoencodingOperad/0905_154251/checkpoint-epoch4500.pth ...\n",
      "Train Epoch: 4501 [256/118836 (0%)] Loss: 12106.681641\n",
      "Train Epoch: 4501 [33024/118836 (28%)] Loss: 12242.882812\n",
      "Train Epoch: 4501 [65792/118836 (55%)] Loss: 12214.843750\n",
      "Train Epoch: 4501 [98560/118836 (83%)] Loss: 12202.990234\n",
      "    epoch          : 4501\n",
      "    loss           : 12180.813058312657\n",
      "    val_loss       : 12178.744956730903\n",
      "    val_log_likelihood: -12098.664819194582\n",
      "    val_log_marginal: -12107.442620328906\n",
      "Train Epoch: 4502 [256/118836 (0%)] Loss: 12214.250000\n",
      "Train Epoch: 4502 [33024/118836 (28%)] Loss: 12338.230469\n",
      "Train Epoch: 4502 [65792/118836 (55%)] Loss: 12238.024414\n",
      "Train Epoch: 4502 [98560/118836 (83%)] Loss: 12214.339844\n",
      "    epoch          : 4502\n",
      "    loss           : 12181.948602441325\n",
      "    val_loss       : 12177.029663623662\n",
      "    val_log_likelihood: -12102.489159106182\n",
      "    val_log_marginal: -12111.266440069909\n",
      "Train Epoch: 4503 [256/118836 (0%)] Loss: 12155.276367\n",
      "Train Epoch: 4503 [33024/118836 (28%)] Loss: 12230.926758\n",
      "Train Epoch: 4503 [65792/118836 (55%)] Loss: 12281.133789\n",
      "Train Epoch: 4503 [98560/118836 (83%)] Loss: 12238.435547\n",
      "    epoch          : 4503\n",
      "    loss           : 12178.021676618073\n",
      "    val_loss       : 12184.390048635616\n",
      "    val_log_likelihood: -12098.355269075682\n",
      "    val_log_marginal: -12107.14731110886\n",
      "Train Epoch: 4504 [256/118836 (0%)] Loss: 12201.939453\n",
      "Train Epoch: 4504 [33024/118836 (28%)] Loss: 12190.027344\n",
      "Train Epoch: 4504 [65792/118836 (55%)] Loss: 12158.393555\n",
      "Train Epoch: 4504 [98560/118836 (83%)] Loss: 12181.749023\n",
      "    epoch          : 4504\n",
      "    loss           : 12177.144231576975\n",
      "    val_loss       : 12181.229595404284\n",
      "    val_log_likelihood: -12093.30320302807\n",
      "    val_log_marginal: -12102.169674727344\n",
      "Train Epoch: 4505 [256/118836 (0%)] Loss: 12150.498047\n",
      "Train Epoch: 4505 [33024/118836 (28%)] Loss: 12230.997070\n",
      "Train Epoch: 4505 [65792/118836 (55%)] Loss: 12273.270508\n",
      "Train Epoch: 4505 [98560/118836 (83%)] Loss: 12201.125977\n",
      "    epoch          : 4505\n",
      "    loss           : 12189.892980219964\n",
      "    val_loss       : 12179.745369645016\n",
      "    val_log_likelihood: -12099.39597937345\n",
      "    val_log_marginal: -12108.379927545151\n",
      "Train Epoch: 4506 [256/118836 (0%)] Loss: 12246.427734\n",
      "Train Epoch: 4506 [33024/118836 (28%)] Loss: 12142.336914\n",
      "Train Epoch: 4506 [65792/118836 (55%)] Loss: 12181.407227\n",
      "Train Epoch: 4506 [98560/118836 (83%)] Loss: 12187.583984\n",
      "    epoch          : 4506\n",
      "    loss           : 12184.82379306891\n",
      "    val_loss       : 12177.866943825\n",
      "    val_log_likelihood: -12100.440034700681\n",
      "    val_log_marginal: -12109.281563139191\n",
      "Train Epoch: 4507 [256/118836 (0%)] Loss: 12188.320312\n",
      "Train Epoch: 4507 [33024/118836 (28%)] Loss: 12147.191406\n",
      "Train Epoch: 4507 [65792/118836 (55%)] Loss: 12304.325195\n",
      "Train Epoch: 4507 [98560/118836 (83%)] Loss: 12182.667969\n",
      "    epoch          : 4507\n",
      "    loss           : 12181.993840951975\n",
      "    val_loss       : 12179.147734446726\n",
      "    val_log_likelihood: -12098.581155332402\n",
      "    val_log_marginal: -12107.3641277584\n",
      "Train Epoch: 4508 [256/118836 (0%)] Loss: 12291.497070\n",
      "Train Epoch: 4508 [33024/118836 (28%)] Loss: 12238.805664\n",
      "Train Epoch: 4508 [65792/118836 (55%)] Loss: 12156.990234\n",
      "Train Epoch: 4508 [98560/118836 (83%)] Loss: 12288.169922\n",
      "    epoch          : 4508\n",
      "    loss           : 12182.596878715623\n",
      "    val_loss       : 12184.099439496731\n",
      "    val_log_likelihood: -12103.52777734698\n",
      "    val_log_marginal: -12112.695647823526\n",
      "Train Epoch: 4509 [256/118836 (0%)] Loss: 12144.860352\n",
      "Train Epoch: 4509 [33024/118836 (28%)] Loss: 12163.884766\n",
      "Train Epoch: 4509 [65792/118836 (55%)] Loss: 12357.532227\n",
      "Train Epoch: 4509 [98560/118836 (83%)] Loss: 12262.876953\n",
      "    epoch          : 4509\n",
      "    loss           : 12182.302078325321\n",
      "    val_loss       : 12178.582291448487\n",
      "    val_log_likelihood: -12100.082604263596\n",
      "    val_log_marginal: -12108.99345751559\n",
      "Train Epoch: 4510 [256/118836 (0%)] Loss: 12292.969727\n",
      "Train Epoch: 4510 [33024/118836 (28%)] Loss: 12225.652344\n",
      "Train Epoch: 4510 [65792/118836 (55%)] Loss: 12144.522461\n",
      "Train Epoch: 4510 [98560/118836 (83%)] Loss: 12190.443359\n",
      "    epoch          : 4510\n",
      "    loss           : 12177.04520733173\n",
      "    val_loss       : 12177.865460011517\n",
      "    val_log_likelihood: -12103.252504491056\n",
      "    val_log_marginal: -12112.015863883957\n",
      "Train Epoch: 4511 [256/118836 (0%)] Loss: 12319.118164\n",
      "Train Epoch: 4511 [33024/118836 (28%)] Loss: 12264.535156\n",
      "Train Epoch: 4511 [65792/118836 (55%)] Loss: 12119.019531\n",
      "Train Epoch: 4511 [98560/118836 (83%)] Loss: 12178.391602\n",
      "    epoch          : 4511\n",
      "    loss           : 12175.553604961488\n",
      "    val_loss       : 12175.395821499242\n",
      "    val_log_likelihood: -12097.13832422198\n",
      "    val_log_marginal: -12105.8888282757\n",
      "Train Epoch: 4512 [256/118836 (0%)] Loss: 12228.045898\n",
      "Train Epoch: 4512 [33024/118836 (28%)] Loss: 12228.452148\n",
      "Train Epoch: 4512 [65792/118836 (55%)] Loss: 12128.410156\n",
      "Train Epoch: 4512 [98560/118836 (83%)] Loss: 12217.863281\n",
      "    epoch          : 4512\n",
      "    loss           : 12179.271675002585\n",
      "    val_loss       : 12179.860791326373\n",
      "    val_log_likelihood: -12096.705712688688\n",
      "    val_log_marginal: -12105.540685293998\n",
      "Train Epoch: 4513 [256/118836 (0%)] Loss: 12181.861328\n",
      "Train Epoch: 4513 [33024/118836 (28%)] Loss: 12213.129883\n",
      "Train Epoch: 4513 [65792/118836 (55%)] Loss: 12320.324219\n",
      "Train Epoch: 4513 [98560/118836 (83%)] Loss: 12176.801758\n",
      "    epoch          : 4513\n",
      "    loss           : 12176.171479851635\n",
      "    val_loss       : 12177.953474523685\n",
      "    val_log_likelihood: -12097.544673736043\n",
      "    val_log_marginal: -12106.341951483597\n",
      "Train Epoch: 4514 [256/118836 (0%)] Loss: 12163.427734\n",
      "Train Epoch: 4514 [33024/118836 (28%)] Loss: 12154.753906\n",
      "Train Epoch: 4514 [65792/118836 (55%)] Loss: 12264.226562\n",
      "Train Epoch: 4514 [98560/118836 (83%)] Loss: 12230.968750\n",
      "    epoch          : 4514\n",
      "    loss           : 12177.404391057951\n",
      "    val_loss       : 12179.110760918484\n",
      "    val_log_likelihood: -12097.589290930004\n",
      "    val_log_marginal: -12106.389575398003\n",
      "Train Epoch: 4515 [256/118836 (0%)] Loss: 12128.985352\n",
      "Train Epoch: 4515 [33024/118836 (28%)] Loss: 12131.486328\n",
      "Train Epoch: 4515 [65792/118836 (55%)] Loss: 12157.230469\n",
      "Train Epoch: 4515 [98560/118836 (83%)] Loss: 12228.204102\n",
      "    epoch          : 4515\n",
      "    loss           : 12176.174114389476\n",
      "    val_loss       : 12180.186018509286\n",
      "    val_log_likelihood: -12097.500906934967\n",
      "    val_log_marginal: -12106.270967235152\n",
      "Train Epoch: 4516 [256/118836 (0%)] Loss: 12127.402344\n",
      "Train Epoch: 4516 [33024/118836 (28%)] Loss: 12300.160156\n",
      "Train Epoch: 4516 [65792/118836 (55%)] Loss: 12184.896484\n",
      "Train Epoch: 4516 [98560/118836 (83%)] Loss: 12173.367188\n",
      "    epoch          : 4516\n",
      "    loss           : 12178.317251796423\n",
      "    val_loss       : 12180.605217738617\n",
      "    val_log_likelihood: -12099.668876815807\n",
      "    val_log_marginal: -12108.443715881862\n",
      "Train Epoch: 4517 [256/118836 (0%)] Loss: 12195.922852\n",
      "Train Epoch: 4517 [33024/118836 (28%)] Loss: 12212.781250\n",
      "Train Epoch: 4517 [65792/118836 (55%)] Loss: 12204.217773\n",
      "Train Epoch: 4517 [98560/118836 (83%)] Loss: 12143.590820\n",
      "    epoch          : 4517\n",
      "    loss           : 12177.90079465855\n",
      "    val_loss       : 12178.151885423238\n",
      "    val_log_likelihood: -12097.85797679513\n",
      "    val_log_marginal: -12106.683997158127\n",
      "Train Epoch: 4518 [256/118836 (0%)] Loss: 12165.076172\n",
      "Train Epoch: 4518 [33024/118836 (28%)] Loss: 12185.858398\n",
      "Train Epoch: 4518 [65792/118836 (55%)] Loss: 12233.202148\n",
      "Train Epoch: 4518 [98560/118836 (83%)] Loss: 12082.239258\n",
      "    epoch          : 4518\n",
      "    loss           : 12178.893418017215\n",
      "    val_loss       : 12175.945078029317\n",
      "    val_log_likelihood: -12102.233556593776\n",
      "    val_log_marginal: -12111.04237747543\n",
      "Train Epoch: 4519 [256/118836 (0%)] Loss: 12219.074219\n",
      "Train Epoch: 4519 [33024/118836 (28%)] Loss: 12246.866211\n",
      "Train Epoch: 4519 [65792/118836 (55%)] Loss: 12121.130859\n",
      "Train Epoch: 4519 [98560/118836 (83%)] Loss: 12307.573242\n",
      "    epoch          : 4519\n",
      "    loss           : 12181.743330457764\n",
      "    val_loss       : 12178.727761525406\n",
      "    val_log_likelihood: -12096.682475024556\n",
      "    val_log_marginal: -12105.383457333326\n",
      "Train Epoch: 4520 [256/118836 (0%)] Loss: 12241.872070\n",
      "Train Epoch: 4520 [33024/118836 (28%)] Loss: 12204.153320\n",
      "Train Epoch: 4520 [65792/118836 (55%)] Loss: 12211.936523\n",
      "Train Epoch: 4520 [98560/118836 (83%)] Loss: 12224.445312\n",
      "    epoch          : 4520\n",
      "    loss           : 12181.131959199234\n",
      "    val_loss       : 12181.816780892043\n",
      "    val_log_likelihood: -12100.325656211227\n",
      "    val_log_marginal: -12109.167345835449\n",
      "Train Epoch: 4521 [256/118836 (0%)] Loss: 12274.327148\n",
      "Train Epoch: 4521 [33024/118836 (28%)] Loss: 12205.017578\n",
      "Train Epoch: 4521 [65792/118836 (55%)] Loss: 12148.910156\n",
      "Train Epoch: 4521 [98560/118836 (83%)] Loss: 12269.006836\n",
      "    epoch          : 4521\n",
      "    loss           : 12178.006234006667\n",
      "    val_loss       : 12177.3752397494\n",
      "    val_log_likelihood: -12098.6133554009\n",
      "    val_log_marginal: -12107.402923013025\n",
      "Train Epoch: 4522 [256/118836 (0%)] Loss: 12333.108398\n",
      "Train Epoch: 4522 [33024/118836 (28%)] Loss: 12148.466797\n",
      "Train Epoch: 4522 [65792/118836 (55%)] Loss: 12272.845703\n",
      "Train Epoch: 4522 [98560/118836 (83%)] Loss: 12148.962891\n",
      "    epoch          : 4522\n",
      "    loss           : 12179.676930508167\n",
      "    val_loss       : 12182.339589533674\n",
      "    val_log_likelihood: -12099.260231047096\n",
      "    val_log_marginal: -12108.038695945279\n",
      "Train Epoch: 4523 [256/118836 (0%)] Loss: 12177.919922\n",
      "Train Epoch: 4523 [33024/118836 (28%)] Loss: 12139.088867\n",
      "Train Epoch: 4523 [65792/118836 (55%)] Loss: 12274.881836\n",
      "Train Epoch: 4523 [98560/118836 (83%)] Loss: 12157.070312\n",
      "    epoch          : 4523\n",
      "    loss           : 12178.509052225496\n",
      "    val_loss       : 12180.80456050054\n",
      "    val_log_likelihood: -12102.141981848377\n",
      "    val_log_marginal: -12111.024095679475\n",
      "Train Epoch: 4524 [256/118836 (0%)] Loss: 12141.189453\n",
      "Train Epoch: 4524 [33024/118836 (28%)] Loss: 12168.154297\n",
      "Train Epoch: 4524 [65792/118836 (55%)] Loss: 12187.219727\n",
      "Train Epoch: 4524 [98560/118836 (83%)] Loss: 12153.617188\n",
      "    epoch          : 4524\n",
      "    loss           : 12180.523773521505\n",
      "    val_loss       : 12187.436166752923\n",
      "    val_log_likelihood: -12097.142246142213\n",
      "    val_log_marginal: -12105.96578681114\n",
      "Train Epoch: 4525 [256/118836 (0%)] Loss: 12200.505859\n",
      "Train Epoch: 4525 [33024/118836 (28%)] Loss: 12212.384766\n",
      "Train Epoch: 4525 [65792/118836 (55%)] Loss: 12264.327148\n",
      "Train Epoch: 4525 [98560/118836 (83%)] Loss: 12293.172852\n",
      "    epoch          : 4525\n",
      "    loss           : 12181.630021098274\n",
      "    val_loss       : 12180.550622891222\n",
      "    val_log_likelihood: -12097.07302651985\n",
      "    val_log_marginal: -12105.795374683821\n",
      "Train Epoch: 4526 [256/118836 (0%)] Loss: 12170.443359\n",
      "Train Epoch: 4526 [33024/118836 (28%)] Loss: 12174.694336\n",
      "Train Epoch: 4526 [65792/118836 (55%)] Loss: 12221.245117\n",
      "Train Epoch: 4526 [98560/118836 (83%)] Loss: 12156.832031\n",
      "    epoch          : 4526\n",
      "    loss           : 12176.171502953113\n",
      "    val_loss       : 12180.953149385137\n",
      "    val_log_likelihood: -12100.35028949545\n",
      "    val_log_marginal: -12109.165388894944\n",
      "Train Epoch: 4527 [256/118836 (0%)] Loss: 12244.505859\n",
      "Train Epoch: 4527 [33024/118836 (28%)] Loss: 12138.069336\n",
      "Train Epoch: 4527 [65792/118836 (55%)] Loss: 12335.723633\n",
      "Train Epoch: 4527 [98560/118836 (83%)] Loss: 12238.518555\n",
      "    epoch          : 4527\n",
      "    loss           : 12176.696617975858\n",
      "    val_loss       : 12178.665369025386\n",
      "    val_log_likelihood: -12102.605306231908\n",
      "    val_log_marginal: -12111.375061332581\n",
      "Train Epoch: 4528 [256/118836 (0%)] Loss: 12266.751953\n",
      "Train Epoch: 4528 [33024/118836 (28%)] Loss: 12199.164062\n",
      "Train Epoch: 4528 [65792/118836 (55%)] Loss: 12187.279297\n",
      "Train Epoch: 4528 [98560/118836 (83%)] Loss: 12191.852539\n",
      "    epoch          : 4528\n",
      "    loss           : 12179.4507878735\n",
      "    val_loss       : 12175.802039128608\n",
      "    val_log_likelihood: -12099.7396216204\n",
      "    val_log_marginal: -12108.484982835433\n",
      "Train Epoch: 4529 [256/118836 (0%)] Loss: 12195.506836\n",
      "Train Epoch: 4529 [33024/118836 (28%)] Loss: 12125.552734\n",
      "Train Epoch: 4529 [65792/118836 (55%)] Loss: 12227.906250\n",
      "Train Epoch: 4529 [98560/118836 (83%)] Loss: 12247.169922\n",
      "    epoch          : 4529\n",
      "    loss           : 12176.685169497003\n",
      "    val_loss       : 12177.632216959253\n",
      "    val_log_likelihood: -12096.89468762924\n",
      "    val_log_marginal: -12105.692412950717\n",
      "Train Epoch: 4530 [256/118836 (0%)] Loss: 12200.401367\n",
      "Train Epoch: 4530 [33024/118836 (28%)] Loss: 12261.409180\n",
      "Train Epoch: 4530 [65792/118836 (55%)] Loss: 12276.578125\n",
      "Train Epoch: 4530 [98560/118836 (83%)] Loss: 12140.239258\n",
      "    epoch          : 4530\n",
      "    loss           : 12175.638745702801\n",
      "    val_loss       : 12181.448941574361\n",
      "    val_log_likelihood: -12100.024214872828\n",
      "    val_log_marginal: -12108.784926129441\n",
      "Train Epoch: 4531 [256/118836 (0%)] Loss: 12194.375000\n",
      "Train Epoch: 4531 [33024/118836 (28%)] Loss: 12121.992188\n",
      "Train Epoch: 4531 [65792/118836 (55%)] Loss: 12216.832031\n",
      "Train Epoch: 4531 [98560/118836 (83%)] Loss: 12189.242188\n",
      "    epoch          : 4531\n",
      "    loss           : 12175.565759731699\n",
      "    val_loss       : 12177.407071210366\n",
      "    val_log_likelihood: -12099.73779094939\n",
      "    val_log_marginal: -12108.513154028295\n",
      "Train Epoch: 4532 [256/118836 (0%)] Loss: 12172.374023\n",
      "Train Epoch: 4532 [33024/118836 (28%)] Loss: 12153.414062\n",
      "Train Epoch: 4532 [65792/118836 (55%)] Loss: 12294.269531\n",
      "Train Epoch: 4532 [98560/118836 (83%)] Loss: 12301.920898\n",
      "    epoch          : 4532\n",
      "    loss           : 12176.727984452544\n",
      "    val_loss       : 12181.12718129201\n",
      "    val_log_likelihood: -12103.793551779623\n",
      "    val_log_marginal: -12112.680380071488\n",
      "Train Epoch: 4533 [256/118836 (0%)] Loss: 12259.439453\n",
      "Train Epoch: 4533 [33024/118836 (28%)] Loss: 12220.556641\n",
      "Train Epoch: 4533 [65792/118836 (55%)] Loss: 12201.248047\n",
      "Train Epoch: 4533 [98560/118836 (83%)] Loss: 12266.562500\n",
      "    epoch          : 4533\n",
      "    loss           : 12182.345188915167\n",
      "    val_loss       : 12178.869380469858\n",
      "    val_log_likelihood: -12097.111717296062\n",
      "    val_log_marginal: -12105.896519992282\n",
      "Train Epoch: 4534 [256/118836 (0%)] Loss: 12135.919922\n",
      "Train Epoch: 4534 [33024/118836 (28%)] Loss: 12220.916016\n",
      "Train Epoch: 4534 [65792/118836 (55%)] Loss: 12169.691406\n",
      "Train Epoch: 4534 [98560/118836 (83%)] Loss: 12254.497070\n",
      "    epoch          : 4534\n",
      "    loss           : 12180.972868202025\n",
      "    val_loss       : 12176.676224870414\n",
      "    val_log_likelihood: -12097.040117736766\n",
      "    val_log_marginal: -12105.749646634016\n",
      "Train Epoch: 4535 [256/118836 (0%)] Loss: 12223.067383\n",
      "Train Epoch: 4535 [33024/118836 (28%)] Loss: 12260.703125\n",
      "Train Epoch: 4535 [65792/118836 (55%)] Loss: 12278.511719\n",
      "Train Epoch: 4535 [98560/118836 (83%)] Loss: 12116.522461\n",
      "    epoch          : 4535\n",
      "    loss           : 12179.373351556038\n",
      "    val_loss       : 12176.531762186998\n",
      "    val_log_likelihood: -12097.895990358767\n",
      "    val_log_marginal: -12106.740251096773\n",
      "Train Epoch: 4536 [256/118836 (0%)] Loss: 12224.703125\n",
      "Train Epoch: 4536 [33024/118836 (28%)] Loss: 12263.773438\n",
      "Train Epoch: 4536 [65792/118836 (55%)] Loss: 12170.974609\n",
      "Train Epoch: 4536 [98560/118836 (83%)] Loss: 12267.767578\n",
      "    epoch          : 4536\n",
      "    loss           : 12181.538557659998\n",
      "    val_loss       : 12179.042100494516\n",
      "    val_log_likelihood: -12098.108806348222\n",
      "    val_log_marginal: -12106.941783160886\n",
      "Train Epoch: 4537 [256/118836 (0%)] Loss: 12114.499023\n",
      "Train Epoch: 4537 [33024/118836 (28%)] Loss: 12238.939453\n",
      "Train Epoch: 4537 [65792/118836 (55%)] Loss: 12176.409180\n",
      "Train Epoch: 4537 [98560/118836 (83%)] Loss: 12202.630859\n",
      "    epoch          : 4537\n",
      "    loss           : 12177.986133943343\n",
      "    val_loss       : 12175.623958300372\n",
      "    val_log_likelihood: -12095.03523314723\n",
      "    val_log_marginal: -12103.766573904637\n",
      "Train Epoch: 4538 [256/118836 (0%)] Loss: 12189.846680\n",
      "Train Epoch: 4538 [33024/118836 (28%)] Loss: 12216.144531\n",
      "Train Epoch: 4538 [65792/118836 (55%)] Loss: 12298.011719\n",
      "Train Epoch: 4538 [98560/118836 (83%)] Loss: 12184.636719\n",
      "    epoch          : 4538\n",
      "    loss           : 12176.679056167286\n",
      "    val_loss       : 12182.749208902807\n",
      "    val_log_likelihood: -12097.56083782439\n",
      "    val_log_marginal: -12106.411037798556\n",
      "Train Epoch: 4539 [256/118836 (0%)] Loss: 12219.964844\n",
      "Train Epoch: 4539 [33024/118836 (28%)] Loss: 12159.938477\n",
      "Train Epoch: 4539 [65792/118836 (55%)] Loss: 12309.740234\n",
      "Train Epoch: 4539 [98560/118836 (83%)] Loss: 12187.436523\n",
      "    epoch          : 4539\n",
      "    loss           : 12179.823696139629\n",
      "    val_loss       : 12176.7835782607\n",
      "    val_log_likelihood: -12099.547396641077\n",
      "    val_log_marginal: -12108.38526724596\n",
      "Train Epoch: 4540 [256/118836 (0%)] Loss: 12205.126953\n",
      "Train Epoch: 4540 [33024/118836 (28%)] Loss: 12239.025391\n",
      "Train Epoch: 4540 [65792/118836 (55%)] Loss: 12201.337891\n",
      "Train Epoch: 4540 [98560/118836 (83%)] Loss: 12188.131836\n",
      "    epoch          : 4540\n",
      "    loss           : 12180.80270771945\n",
      "    val_loss       : 12178.549577984959\n",
      "    val_log_likelihood: -12097.8055425778\n",
      "    val_log_marginal: -12106.585992182145\n",
      "Train Epoch: 4541 [256/118836 (0%)] Loss: 12121.593750\n",
      "Train Epoch: 4541 [33024/118836 (28%)] Loss: 12185.857422\n",
      "Train Epoch: 4541 [65792/118836 (55%)] Loss: 12135.599609\n",
      "Train Epoch: 4541 [98560/118836 (83%)] Loss: 12233.955078\n",
      "    epoch          : 4541\n",
      "    loss           : 12179.709147054642\n",
      "    val_loss       : 12183.322702587544\n",
      "    val_log_likelihood: -12098.377974759615\n",
      "    val_log_marginal: -12107.202521610634\n",
      "Train Epoch: 4542 [256/118836 (0%)] Loss: 12148.195312\n",
      "Train Epoch: 4542 [33024/118836 (28%)] Loss: 12167.160156\n",
      "Train Epoch: 4542 [65792/118836 (55%)] Loss: 12150.761719\n",
      "Train Epoch: 4542 [98560/118836 (83%)] Loss: 12143.287109\n",
      "    epoch          : 4542\n",
      "    loss           : 12179.037389823718\n",
      "    val_loss       : 12179.08878440462\n",
      "    val_log_likelihood: -12101.010782090054\n",
      "    val_log_marginal: -12109.702647060365\n",
      "Train Epoch: 4543 [256/118836 (0%)] Loss: 12143.863281\n",
      "Train Epoch: 4543 [33024/118836 (28%)] Loss: 12244.492188\n",
      "Train Epoch: 4543 [65792/118836 (55%)] Loss: 12170.625000\n",
      "Train Epoch: 4543 [98560/118836 (83%)] Loss: 12260.078125\n",
      "    epoch          : 4543\n",
      "    loss           : 12178.19194937707\n",
      "    val_loss       : 12181.186924525377\n",
      "    val_log_likelihood: -12099.595315730976\n",
      "    val_log_marginal: -12108.331480005023\n",
      "Train Epoch: 4544 [256/118836 (0%)] Loss: 12293.736328\n",
      "Train Epoch: 4544 [33024/118836 (28%)] Loss: 12186.495117\n",
      "Train Epoch: 4544 [65792/118836 (55%)] Loss: 12232.713867\n",
      "Train Epoch: 4544 [98560/118836 (83%)] Loss: 12163.988281\n",
      "    epoch          : 4544\n",
      "    loss           : 12177.489744882134\n",
      "    val_loss       : 12176.171595557074\n",
      "    val_log_likelihood: -12098.257528981854\n",
      "    val_log_marginal: -12107.12074284658\n",
      "Train Epoch: 4545 [256/118836 (0%)] Loss: 12276.918945\n",
      "Train Epoch: 4545 [33024/118836 (28%)] Loss: 12145.745117\n",
      "Train Epoch: 4545 [65792/118836 (55%)] Loss: 12160.845703\n",
      "Train Epoch: 4545 [98560/118836 (83%)] Loss: 12187.906250\n",
      "    epoch          : 4545\n",
      "    loss           : 12178.497544781327\n",
      "    val_loss       : 12180.008722104703\n",
      "    val_log_likelihood: -12100.328830322065\n",
      "    val_log_marginal: -12109.232263511813\n",
      "Train Epoch: 4546 [256/118836 (0%)] Loss: 12209.383789\n",
      "Train Epoch: 4546 [33024/118836 (28%)] Loss: 12157.702148\n",
      "Train Epoch: 4546 [65792/118836 (55%)] Loss: 12257.431641\n",
      "Train Epoch: 4546 [98560/118836 (83%)] Loss: 12206.002930\n",
      "    epoch          : 4546\n",
      "    loss           : 12180.969137717122\n",
      "    val_loss       : 12177.597720824773\n",
      "    val_log_likelihood: -12098.234720229786\n",
      "    val_log_marginal: -12107.095025529165\n",
      "Train Epoch: 4547 [256/118836 (0%)] Loss: 12103.638672\n",
      "Train Epoch: 4547 [33024/118836 (28%)] Loss: 12127.728516\n",
      "Train Epoch: 4547 [65792/118836 (55%)] Loss: 12262.602539\n",
      "Train Epoch: 4547 [98560/118836 (83%)] Loss: 12194.000000\n",
      "    epoch          : 4547\n",
      "    loss           : 12176.705035799216\n",
      "    val_loss       : 12174.776477018793\n",
      "    val_log_likelihood: -12101.051078338243\n",
      "    val_log_marginal: -12109.960882484555\n",
      "Train Epoch: 4548 [256/118836 (0%)] Loss: 12170.994141\n",
      "Train Epoch: 4548 [33024/118836 (28%)] Loss: 12137.828125\n",
      "Train Epoch: 4548 [65792/118836 (55%)] Loss: 12160.806641\n",
      "Train Epoch: 4548 [98560/118836 (83%)] Loss: 12200.225586\n",
      "    epoch          : 4548\n",
      "    loss           : 12175.268867445977\n",
      "    val_loss       : 12176.807053789531\n",
      "    val_log_likelihood: -12100.109476775744\n",
      "    val_log_marginal: -12109.080026809715\n",
      "Train Epoch: 4549 [256/118836 (0%)] Loss: 12262.497070\n",
      "Train Epoch: 4549 [33024/118836 (28%)] Loss: 12239.279297\n",
      "Train Epoch: 4549 [65792/118836 (55%)] Loss: 12164.656250\n",
      "Train Epoch: 4549 [98560/118836 (83%)] Loss: 12211.586914\n",
      "    epoch          : 4549\n",
      "    loss           : 12179.599237328113\n",
      "    val_loss       : 12177.418321511066\n",
      "    val_log_likelihood: -12100.013602893661\n",
      "    val_log_marginal: -12108.891815907586\n",
      "Train Epoch: 4550 [256/118836 (0%)] Loss: 12175.269531\n",
      "Train Epoch: 4550 [33024/118836 (28%)] Loss: 12191.999023\n",
      "Train Epoch: 4550 [65792/118836 (55%)] Loss: 12210.013672\n",
      "Train Epoch: 4550 [98560/118836 (83%)] Loss: 12151.003906\n",
      "    epoch          : 4550\n",
      "    loss           : 12177.791348738629\n",
      "    val_loss       : 12178.496199765457\n",
      "    val_log_likelihood: -12095.749111804695\n",
      "    val_log_marginal: -12104.601941574347\n",
      "Train Epoch: 4551 [256/118836 (0%)] Loss: 12188.857422\n",
      "Train Epoch: 4551 [33024/118836 (28%)] Loss: 12257.470703\n",
      "Train Epoch: 4551 [65792/118836 (55%)] Loss: 12156.793945\n",
      "Train Epoch: 4551 [98560/118836 (83%)] Loss: 12217.912109\n",
      "    epoch          : 4551\n",
      "    loss           : 12180.636622305366\n",
      "    val_loss       : 12181.237291238758\n",
      "    val_log_likelihood: -12096.300655241936\n",
      "    val_log_marginal: -12105.066885712688\n",
      "Train Epoch: 4552 [256/118836 (0%)] Loss: 12125.244141\n",
      "Train Epoch: 4552 [33024/118836 (28%)] Loss: 12226.800781\n",
      "Train Epoch: 4552 [65792/118836 (55%)] Loss: 12238.002930\n",
      "Train Epoch: 4552 [98560/118836 (83%)] Loss: 12303.702148\n",
      "    epoch          : 4552\n",
      "    loss           : 12175.567827879446\n",
      "    val_loss       : 12179.294205983744\n",
      "    val_log_likelihood: -12097.494809437034\n",
      "    val_log_marginal: -12106.45712212653\n",
      "Train Epoch: 4553 [256/118836 (0%)] Loss: 12123.539062\n",
      "Train Epoch: 4553 [33024/118836 (28%)] Loss: 12188.830078\n",
      "Train Epoch: 4553 [65792/118836 (55%)] Loss: 12286.208984\n",
      "Train Epoch: 4553 [98560/118836 (83%)] Loss: 12280.834961\n",
      "    epoch          : 4553\n",
      "    loss           : 12179.704524820358\n",
      "    val_loss       : 12182.280961378172\n",
      "    val_log_likelihood: -12096.336132489403\n",
      "    val_log_marginal: -12105.107108418671\n",
      "Train Epoch: 4554 [256/118836 (0%)] Loss: 12154.743164\n",
      "Train Epoch: 4554 [33024/118836 (28%)] Loss: 12265.727539\n",
      "Train Epoch: 4554 [65792/118836 (55%)] Loss: 12279.404297\n",
      "Train Epoch: 4554 [98560/118836 (83%)] Loss: 12143.757812\n",
      "    epoch          : 4554\n",
      "    loss           : 12177.078364576872\n",
      "    val_loss       : 12175.926288765797\n",
      "    val_log_likelihood: -12100.213633749483\n",
      "    val_log_marginal: -12109.019330864665\n",
      "Train Epoch: 4555 [256/118836 (0%)] Loss: 12154.378906\n",
      "Train Epoch: 4555 [33024/118836 (28%)] Loss: 12132.120117\n",
      "Train Epoch: 4555 [65792/118836 (55%)] Loss: 12222.174805\n",
      "Train Epoch: 4555 [98560/118836 (83%)] Loss: 12188.027344\n",
      "    epoch          : 4555\n",
      "    loss           : 12175.639989467018\n",
      "    val_loss       : 12174.989827388777\n",
      "    val_log_likelihood: -12093.430198801954\n",
      "    val_log_marginal: -12102.283299280361\n",
      "Train Epoch: 4556 [256/118836 (0%)] Loss: 12216.975586\n",
      "Train Epoch: 4556 [33024/118836 (28%)] Loss: 12227.194336\n",
      "Train Epoch: 4556 [65792/118836 (55%)] Loss: 12171.196289\n",
      "Train Epoch: 4556 [98560/118836 (83%)] Loss: 12374.849609\n",
      "    epoch          : 4556\n",
      "    loss           : 12174.818838044095\n",
      "    val_loss       : 12178.609754150744\n",
      "    val_log_likelihood: -12095.610317475703\n",
      "    val_log_marginal: -12104.359487813532\n",
      "Train Epoch: 4557 [256/118836 (0%)] Loss: 12273.176758\n",
      "Train Epoch: 4557 [33024/118836 (28%)] Loss: 12220.164062\n",
      "Train Epoch: 4557 [65792/118836 (55%)] Loss: 12285.650391\n",
      "Train Epoch: 4557 [98560/118836 (83%)] Loss: 12199.551758\n",
      "    epoch          : 4557\n",
      "    loss           : 12176.983191816586\n",
      "    val_loss       : 12183.972461019617\n",
      "    val_log_likelihood: -12097.63650453629\n",
      "    val_log_marginal: -12106.49293908965\n",
      "Train Epoch: 4558 [256/118836 (0%)] Loss: 12198.037109\n",
      "Train Epoch: 4558 [33024/118836 (28%)] Loss: 12223.212891\n",
      "Train Epoch: 4558 [65792/118836 (55%)] Loss: 12193.931641\n",
      "Train Epoch: 4558 [98560/118836 (83%)] Loss: 12177.922852\n",
      "    epoch          : 4558\n",
      "    loss           : 12178.216148256564\n",
      "    val_loss       : 12179.721695775384\n",
      "    val_log_likelihood: -12096.591009970793\n",
      "    val_log_marginal: -12105.53109368186\n",
      "Train Epoch: 4559 [256/118836 (0%)] Loss: 12212.409180\n",
      "Train Epoch: 4559 [33024/118836 (28%)] Loss: 12253.168945\n",
      "Train Epoch: 4559 [65792/118836 (55%)] Loss: 12132.187500\n",
      "Train Epoch: 4559 [98560/118836 (83%)] Loss: 12230.739258\n",
      "    epoch          : 4559\n",
      "    loss           : 12177.291033395368\n",
      "    val_loss       : 12177.729466294026\n",
      "    val_log_likelihood: -12096.103654072322\n",
      "    val_log_marginal: -12104.922475405521\n",
      "Train Epoch: 4560 [256/118836 (0%)] Loss: 12276.964844\n",
      "Train Epoch: 4560 [33024/118836 (28%)] Loss: 12173.238281\n",
      "Train Epoch: 4560 [65792/118836 (55%)] Loss: 12217.938477\n",
      "Train Epoch: 4560 [98560/118836 (83%)] Loss: 12144.367188\n",
      "    epoch          : 4560\n",
      "    loss           : 12176.528830968258\n",
      "    val_loss       : 12174.447819913756\n",
      "    val_log_likelihood: -12096.057500549266\n",
      "    val_log_marginal: -12105.054435562919\n",
      "Train Epoch: 4561 [256/118836 (0%)] Loss: 12221.151367\n",
      "Train Epoch: 4561 [33024/118836 (28%)] Loss: 12315.188477\n",
      "Train Epoch: 4561 [65792/118836 (55%)] Loss: 12185.333984\n",
      "Train Epoch: 4561 [98560/118836 (83%)] Loss: 12267.752930\n",
      "    epoch          : 4561\n",
      "    loss           : 12183.251826309192\n",
      "    val_loss       : 12181.932694174011\n",
      "    val_log_likelihood: -12097.036895484387\n",
      "    val_log_marginal: -12105.90998595614\n",
      "Train Epoch: 4562 [256/118836 (0%)] Loss: 12262.627930\n",
      "Train Epoch: 4562 [33024/118836 (28%)] Loss: 12203.833984\n",
      "Train Epoch: 4562 [65792/118836 (55%)] Loss: 12251.666016\n",
      "Train Epoch: 4562 [98560/118836 (83%)] Loss: 12166.027344\n",
      "    epoch          : 4562\n",
      "    loss           : 12177.421575650073\n",
      "    val_loss       : 12177.637198342532\n",
      "    val_log_likelihood: -12097.197810367556\n",
      "    val_log_marginal: -12106.203982850717\n",
      "Train Epoch: 4563 [256/118836 (0%)] Loss: 12151.541992\n",
      "Train Epoch: 4563 [33024/118836 (28%)] Loss: 12183.575195\n",
      "Train Epoch: 4563 [65792/118836 (55%)] Loss: 12180.816406\n",
      "Train Epoch: 4563 [98560/118836 (83%)] Loss: 12225.471680\n",
      "    epoch          : 4563\n",
      "    loss           : 12176.771265476375\n",
      "    val_loss       : 12177.616370627484\n",
      "    val_log_likelihood: -12100.67250116315\n",
      "    val_log_marginal: -12109.670780106404\n",
      "Train Epoch: 4564 [256/118836 (0%)] Loss: 12243.752930\n",
      "Train Epoch: 4564 [33024/118836 (28%)] Loss: 12129.916992\n",
      "Train Epoch: 4564 [65792/118836 (55%)] Loss: 12218.997070\n",
      "Train Epoch: 4564 [98560/118836 (83%)] Loss: 12189.890625\n",
      "    epoch          : 4564\n",
      "    loss           : 12176.306022862387\n",
      "    val_loss       : 12175.936137624121\n",
      "    val_log_likelihood: -12099.31087562681\n",
      "    val_log_marginal: -12108.275503898552\n",
      "Train Epoch: 4565 [256/118836 (0%)] Loss: 12150.290039\n",
      "Train Epoch: 4565 [33024/118836 (28%)] Loss: 12310.522461\n",
      "Train Epoch: 4565 [65792/118836 (55%)] Loss: 12230.782227\n",
      "Train Epoch: 4565 [98560/118836 (83%)] Loss: 12165.070312\n",
      "    epoch          : 4565\n",
      "    loss           : 12184.679742103495\n",
      "    val_loss       : 12178.844797412492\n",
      "    val_log_likelihood: -12100.4599745076\n",
      "    val_log_marginal: -12109.330125453092\n",
      "Train Epoch: 4566 [256/118836 (0%)] Loss: 12151.300781\n",
      "Train Epoch: 4566 [33024/118836 (28%)] Loss: 12185.462891\n",
      "Train Epoch: 4566 [65792/118836 (55%)] Loss: 12242.482422\n",
      "Train Epoch: 4566 [98560/118836 (83%)] Loss: 12148.422852\n",
      "    epoch          : 4566\n",
      "    loss           : 12176.39685092923\n",
      "    val_loss       : 12174.407423416682\n",
      "    val_log_likelihood: -12095.52688301282\n",
      "    val_log_marginal: -12104.300567032478\n",
      "Train Epoch: 4567 [256/118836 (0%)] Loss: 12231.243164\n",
      "Train Epoch: 4567 [33024/118836 (28%)] Loss: 12134.139648\n",
      "Train Epoch: 4567 [65792/118836 (55%)] Loss: 12180.751953\n",
      "Train Epoch: 4567 [98560/118836 (83%)] Loss: 12183.433594\n",
      "    epoch          : 4567\n",
      "    loss           : 12174.696779524658\n",
      "    val_loss       : 12175.001831187608\n",
      "    val_log_likelihood: -12098.77813986249\n",
      "    val_log_marginal: -12107.596766164685\n",
      "Train Epoch: 4568 [256/118836 (0%)] Loss: 12118.191406\n",
      "Train Epoch: 4568 [33024/118836 (28%)] Loss: 12179.167969\n",
      "Train Epoch: 4568 [65792/118836 (55%)] Loss: 12129.441406\n",
      "Train Epoch: 4568 [98560/118836 (83%)] Loss: 12207.570312\n",
      "    epoch          : 4568\n",
      "    loss           : 12178.248337016645\n",
      "    val_loss       : 12177.82543814991\n",
      "    val_log_likelihood: -12096.579775705644\n",
      "    val_log_marginal: -12105.364032194153\n",
      "Train Epoch: 4569 [256/118836 (0%)] Loss: 12239.876953\n",
      "Train Epoch: 4569 [33024/118836 (28%)] Loss: 12235.206055\n",
      "Train Epoch: 4569 [65792/118836 (55%)] Loss: 12243.253906\n",
      "Train Epoch: 4569 [98560/118836 (83%)] Loss: 12151.096680\n",
      "    epoch          : 4569\n",
      "    loss           : 12173.647624747984\n",
      "    val_loss       : 12179.769495062774\n",
      "    val_log_likelihood: -12096.047896473066\n",
      "    val_log_marginal: -12104.827605899214\n",
      "Train Epoch: 4570 [256/118836 (0%)] Loss: 12154.227539\n",
      "Train Epoch: 4570 [33024/118836 (28%)] Loss: 12163.518555\n",
      "Train Epoch: 4570 [65792/118836 (55%)] Loss: 12223.476562\n",
      "Train Epoch: 4570 [98560/118836 (83%)] Loss: 12203.302734\n",
      "    epoch          : 4570\n",
      "    loss           : 12177.340364098687\n",
      "    val_loss       : 12174.206461971471\n",
      "    val_log_likelihood: -12097.81164734543\n",
      "    val_log_marginal: -12106.682755856535\n",
      "Train Epoch: 4571 [256/118836 (0%)] Loss: 12177.809570\n",
      "Train Epoch: 4571 [33024/118836 (28%)] Loss: 12184.347656\n",
      "Train Epoch: 4571 [65792/118836 (55%)] Loss: 12217.480469\n",
      "Train Epoch: 4571 [98560/118836 (83%)] Loss: 12296.899414\n",
      "    epoch          : 4571\n",
      "    loss           : 12173.931688120349\n",
      "    val_loss       : 12177.577998588218\n",
      "    val_log_likelihood: -12095.743097342845\n",
      "    val_log_marginal: -12104.69207160136\n",
      "Train Epoch: 4572 [256/118836 (0%)] Loss: 12256.927734\n",
      "Train Epoch: 4572 [33024/118836 (28%)] Loss: 12231.826172\n",
      "Train Epoch: 4572 [65792/118836 (55%)] Loss: 12132.797852\n",
      "Train Epoch: 4572 [98560/118836 (83%)] Loss: 12217.548828\n",
      "    epoch          : 4572\n",
      "    loss           : 12179.382894728338\n",
      "    val_loss       : 12178.396507103214\n",
      "    val_log_likelihood: -12097.282891820461\n",
      "    val_log_marginal: -12106.24118763709\n",
      "Train Epoch: 4573 [256/118836 (0%)] Loss: 12116.605469\n",
      "Train Epoch: 4573 [33024/118836 (28%)] Loss: 12166.994141\n",
      "Train Epoch: 4573 [65792/118836 (55%)] Loss: 12176.225586\n",
      "Train Epoch: 4573 [98560/118836 (83%)] Loss: 12233.589844\n",
      "    epoch          : 4573\n",
      "    loss           : 12177.139836480304\n",
      "    val_loss       : 12178.20509302267\n",
      "    val_log_likelihood: -12097.414219686983\n",
      "    val_log_marginal: -12106.190048515535\n",
      "Train Epoch: 4574 [256/118836 (0%)] Loss: 12122.615234\n",
      "Train Epoch: 4574 [33024/118836 (28%)] Loss: 12196.229492\n",
      "Train Epoch: 4574 [65792/118836 (55%)] Loss: 12174.056641\n",
      "Train Epoch: 4574 [98560/118836 (83%)] Loss: 12159.164062\n",
      "    epoch          : 4574\n",
      "    loss           : 12180.137487399194\n",
      "    val_loss       : 12179.043882436317\n",
      "    val_log_likelihood: -12096.332529789597\n",
      "    val_log_marginal: -12105.388256738792\n",
      "Train Epoch: 4575 [256/118836 (0%)] Loss: 12133.425781\n",
      "Train Epoch: 4575 [33024/118836 (28%)] Loss: 12150.295898\n",
      "Train Epoch: 4575 [65792/118836 (55%)] Loss: 12192.244141\n",
      "Train Epoch: 4575 [98560/118836 (83%)] Loss: 12129.021484\n",
      "    epoch          : 4575\n",
      "    loss           : 12176.725445228494\n",
      "    val_loss       : 12175.0848011429\n",
      "    val_log_likelihood: -12092.11142263105\n",
      "    val_log_marginal: -12101.08889795333\n",
      "Train Epoch: 4576 [256/118836 (0%)] Loss: 12308.270508\n",
      "Train Epoch: 4576 [33024/118836 (28%)] Loss: 12186.351562\n",
      "Train Epoch: 4576 [65792/118836 (55%)] Loss: 12163.866211\n",
      "Train Epoch: 4576 [98560/118836 (83%)] Loss: 12156.564453\n",
      "    epoch          : 4576\n",
      "    loss           : 12176.642431277141\n",
      "    val_loss       : 12175.91483813219\n",
      "    val_log_likelihood: -12097.771461435072\n",
      "    val_log_marginal: -12106.620221161891\n",
      "Train Epoch: 4577 [256/118836 (0%)] Loss: 12234.205078\n",
      "Train Epoch: 4577 [33024/118836 (28%)] Loss: 12237.458984\n",
      "Train Epoch: 4577 [65792/118836 (55%)] Loss: 12074.366211\n",
      "Train Epoch: 4577 [98560/118836 (83%)] Loss: 12205.802734\n",
      "    epoch          : 4577\n",
      "    loss           : 12174.40787728107\n",
      "    val_loss       : 12174.274602544867\n",
      "    val_log_likelihood: -12096.566742433055\n",
      "    val_log_marginal: -12105.489902009274\n",
      "Train Epoch: 4578 [256/118836 (0%)] Loss: 12246.158203\n",
      "Train Epoch: 4578 [33024/118836 (28%)] Loss: 12270.529297\n",
      "Train Epoch: 4578 [65792/118836 (55%)] Loss: 12159.455078\n",
      "Train Epoch: 4578 [98560/118836 (83%)] Loss: 12270.647461\n",
      "    epoch          : 4578\n",
      "    loss           : 12177.15960391465\n",
      "    val_loss       : 12176.05893368287\n",
      "    val_log_likelihood: -12099.194655481027\n",
      "    val_log_marginal: -12108.106094022565\n",
      "Train Epoch: 4579 [256/118836 (0%)] Loss: 12103.266602\n",
      "Train Epoch: 4579 [33024/118836 (28%)] Loss: 12129.956055\n",
      "Train Epoch: 4579 [65792/118836 (55%)] Loss: 12184.429688\n",
      "Train Epoch: 4579 [98560/118836 (83%)] Loss: 12166.791016\n",
      "    epoch          : 4579\n",
      "    loss           : 12175.681727538255\n",
      "    val_loss       : 12186.855033844144\n",
      "    val_log_likelihood: -12095.461064800456\n",
      "    val_log_marginal: -12104.438364916905\n",
      "Train Epoch: 4580 [256/118836 (0%)] Loss: 12147.824219\n",
      "Train Epoch: 4580 [33024/118836 (28%)] Loss: 12173.452148\n",
      "Train Epoch: 4580 [65792/118836 (55%)] Loss: 12320.803711\n",
      "Train Epoch: 4580 [98560/118836 (83%)] Loss: 12275.351562\n",
      "    epoch          : 4580\n",
      "    loss           : 12182.056279078784\n",
      "    val_loss       : 12179.63760445186\n",
      "    val_log_likelihood: -12100.507310729427\n",
      "    val_log_marginal: -12109.65749267197\n",
      "Train Epoch: 4581 [256/118836 (0%)] Loss: 12238.470703\n",
      "Train Epoch: 4581 [33024/118836 (28%)] Loss: 12219.203125\n",
      "Train Epoch: 4581 [65792/118836 (55%)] Loss: 12331.992188\n",
      "Train Epoch: 4581 [98560/118836 (83%)] Loss: 12131.931641\n",
      "    epoch          : 4581\n",
      "    loss           : 12174.102030345326\n",
      "    val_loss       : 12173.437845278919\n",
      "    val_log_likelihood: -12096.924396776778\n",
      "    val_log_marginal: -12105.915777585942\n",
      "Train Epoch: 4582 [256/118836 (0%)] Loss: 12140.581055\n",
      "Train Epoch: 4582 [33024/118836 (28%)] Loss: 12195.923828\n",
      "Train Epoch: 4582 [65792/118836 (55%)] Loss: 12305.928711\n",
      "Train Epoch: 4582 [98560/118836 (83%)] Loss: 12167.142578\n",
      "    epoch          : 4582\n",
      "    loss           : 12175.292521906018\n",
      "    val_loss       : 12172.208372932328\n",
      "    val_log_likelihood: -12096.26754032258\n",
      "    val_log_marginal: -12105.187494503241\n",
      "Train Epoch: 4583 [256/118836 (0%)] Loss: 12132.510742\n",
      "Train Epoch: 4583 [33024/118836 (28%)] Loss: 12174.357422\n",
      "Train Epoch: 4583 [65792/118836 (55%)] Loss: 12202.726562\n",
      "Train Epoch: 4583 [98560/118836 (83%)] Loss: 12141.127930\n",
      "    epoch          : 4583\n",
      "    loss           : 12174.576119371639\n",
      "    val_loss       : 12175.35191992994\n",
      "    val_log_likelihood: -12094.676923561568\n",
      "    val_log_marginal: -12103.517528226124\n",
      "Train Epoch: 4584 [256/118836 (0%)] Loss: 12224.687500\n",
      "Train Epoch: 4584 [33024/118836 (28%)] Loss: 12356.571289\n",
      "Train Epoch: 4584 [65792/118836 (55%)] Loss: 12083.100586\n",
      "Train Epoch: 4584 [98560/118836 (83%)] Loss: 12251.369141\n",
      "    epoch          : 4584\n",
      "    loss           : 12176.800150078836\n",
      "    val_loss       : 12179.44494806582\n",
      "    val_log_likelihood: -12097.455270368073\n",
      "    val_log_marginal: -12106.343785744299\n",
      "Train Epoch: 4585 [256/118836 (0%)] Loss: 12222.900391\n",
      "Train Epoch: 4585 [33024/118836 (28%)] Loss: 12357.255859\n",
      "Train Epoch: 4585 [65792/118836 (55%)] Loss: 12242.449219\n",
      "Train Epoch: 4585 [98560/118836 (83%)] Loss: 12157.084961\n",
      "    epoch          : 4585\n",
      "    loss           : 12179.610852686881\n",
      "    val_loss       : 12185.844853315517\n",
      "    val_log_likelihood: -12095.03626188999\n",
      "    val_log_marginal: -12103.916867680351\n",
      "Train Epoch: 4586 [256/118836 (0%)] Loss: 12180.781250\n",
      "Train Epoch: 4586 [33024/118836 (28%)] Loss: 12227.833984\n",
      "Train Epoch: 4586 [65792/118836 (55%)] Loss: 12262.305664\n",
      "Train Epoch: 4586 [98560/118836 (83%)] Loss: 12116.731445\n",
      "    epoch          : 4586\n",
      "    loss           : 12177.529457292958\n",
      "    val_loss       : 12180.508874047793\n",
      "    val_log_likelihood: -12100.254287182071\n",
      "    val_log_marginal: -12109.225781609306\n",
      "Train Epoch: 4587 [256/118836 (0%)] Loss: 12292.964844\n",
      "Train Epoch: 4587 [33024/118836 (28%)] Loss: 12296.260742\n",
      "Train Epoch: 4587 [65792/118836 (55%)] Loss: 12168.834961\n",
      "Train Epoch: 4587 [98560/118836 (83%)] Loss: 12246.217773\n",
      "    epoch          : 4587\n",
      "    loss           : 12178.53235289366\n",
      "    val_loss       : 12176.473192223311\n",
      "    val_log_likelihood: -12094.40149771893\n",
      "    val_log_marginal: -12103.44317912101\n",
      "Train Epoch: 4588 [256/118836 (0%)] Loss: 12168.576172\n",
      "Train Epoch: 4588 [33024/118836 (28%)] Loss: 12145.354492\n",
      "Train Epoch: 4588 [65792/118836 (55%)] Loss: 12249.429688\n",
      "Train Epoch: 4588 [98560/118836 (83%)] Loss: 12137.559570\n",
      "    epoch          : 4588\n",
      "    loss           : 12174.028692520937\n",
      "    val_loss       : 12174.637264292862\n",
      "    val_log_likelihood: -12095.43596980976\n",
      "    val_log_marginal: -12104.372464816452\n",
      "Train Epoch: 4589 [256/118836 (0%)] Loss: 12241.687500\n",
      "Train Epoch: 4589 [33024/118836 (28%)] Loss: 12142.937500\n",
      "Train Epoch: 4589 [65792/118836 (55%)] Loss: 12181.064453\n",
      "Train Epoch: 4589 [98560/118836 (83%)] Loss: 12228.477539\n",
      "    epoch          : 4589\n",
      "    loss           : 12175.547187112285\n",
      "    val_loss       : 12173.961272597478\n",
      "    val_log_likelihood: -12094.127961835711\n",
      "    val_log_marginal: -12103.116476280364\n",
      "Train Epoch: 4590 [256/118836 (0%)] Loss: 12159.642578\n",
      "Train Epoch: 4590 [33024/118836 (28%)] Loss: 12209.659180\n",
      "Train Epoch: 4590 [65792/118836 (55%)] Loss: 12237.363281\n",
      "Train Epoch: 4590 [98560/118836 (83%)] Loss: 12163.778320\n",
      "    epoch          : 4590\n",
      "    loss           : 12176.235920860474\n",
      "    val_loss       : 12177.479223744424\n",
      "    val_log_likelihood: -12095.0920663384\n",
      "    val_log_marginal: -12104.154422085503\n",
      "Train Epoch: 4591 [256/118836 (0%)] Loss: 12219.682617\n",
      "Train Epoch: 4591 [33024/118836 (28%)] Loss: 12154.497070\n",
      "Train Epoch: 4591 [65792/118836 (55%)] Loss: 12138.456055\n",
      "Train Epoch: 4591 [98560/118836 (83%)] Loss: 12252.614258\n",
      "    epoch          : 4591\n",
      "    loss           : 12178.371832351117\n",
      "    val_loss       : 12174.19716527016\n",
      "    val_log_likelihood: -12094.069675836177\n",
      "    val_log_marginal: -12103.096021770334\n",
      "Train Epoch: 4592 [256/118836 (0%)] Loss: 12383.906250\n",
      "Train Epoch: 4592 [33024/118836 (28%)] Loss: 12109.941406\n",
      "Train Epoch: 4592 [65792/118836 (55%)] Loss: 12201.259766\n",
      "Train Epoch: 4592 [98560/118836 (83%)] Loss: 12183.974609\n",
      "    epoch          : 4592\n",
      "    loss           : 12173.619069381979\n",
      "    val_loss       : 12174.299787682396\n",
      "    val_log_likelihood: -12092.115038254757\n",
      "    val_log_marginal: -12101.073242148621\n",
      "Train Epoch: 4593 [256/118836 (0%)] Loss: 12198.308594\n",
      "Train Epoch: 4593 [33024/118836 (28%)] Loss: 12324.699219\n",
      "Train Epoch: 4593 [65792/118836 (55%)] Loss: 12318.227539\n",
      "Train Epoch: 4593 [98560/118836 (83%)] Loss: 12140.718750\n",
      "    epoch          : 4593\n",
      "    loss           : 12176.271265153278\n",
      "    val_loss       : 12174.666426196929\n",
      "    val_log_likelihood: -12096.934567081524\n",
      "    val_log_marginal: -12105.994686829716\n",
      "Train Epoch: 4594 [256/118836 (0%)] Loss: 12152.949219\n",
      "Train Epoch: 4594 [33024/118836 (28%)] Loss: 12273.028320\n",
      "Train Epoch: 4594 [65792/118836 (55%)] Loss: 12165.250000\n",
      "Train Epoch: 4594 [98560/118836 (83%)] Loss: 12267.435547\n",
      "    epoch          : 4594\n",
      "    loss           : 12181.872109730408\n",
      "    val_loss       : 12180.859321071504\n",
      "    val_log_likelihood: -12097.21297947684\n",
      "    val_log_marginal: -12106.169157595683\n",
      "Train Epoch: 4595 [256/118836 (0%)] Loss: 12149.880859\n",
      "Train Epoch: 4595 [33024/118836 (28%)] Loss: 12094.997070\n",
      "Train Epoch: 4595 [65792/118836 (55%)] Loss: 12148.220703\n",
      "Train Epoch: 4595 [98560/118836 (83%)] Loss: 12261.069336\n",
      "    epoch          : 4595\n",
      "    loss           : 12176.789074616161\n",
      "    val_loss       : 12173.786883427112\n",
      "    val_log_likelihood: -12095.522807298128\n",
      "    val_log_marginal: -12104.56181898349\n",
      "Train Epoch: 4596 [256/118836 (0%)] Loss: 12193.283203\n",
      "Train Epoch: 4596 [33024/118836 (28%)] Loss: 12130.375977\n",
      "Train Epoch: 4596 [65792/118836 (55%)] Loss: 12356.060547\n",
      "Train Epoch: 4596 [98560/118836 (83%)] Loss: 12105.085938\n",
      "    epoch          : 4596\n",
      "    loss           : 12174.606008646093\n",
      "    val_loss       : 12175.420975181949\n",
      "    val_log_likelihood: -12096.199642330956\n",
      "    val_log_marginal: -12105.077244649283\n",
      "Train Epoch: 4597 [256/118836 (0%)] Loss: 12253.347656\n",
      "Train Epoch: 4597 [33024/118836 (28%)] Loss: 12240.998047\n",
      "Train Epoch: 4597 [65792/118836 (55%)] Loss: 12163.156250\n",
      "Train Epoch: 4597 [98560/118836 (83%)] Loss: 12234.177734\n",
      "    epoch          : 4597\n",
      "    loss           : 12175.31996484698\n",
      "    val_loss       : 12177.004493492163\n",
      "    val_log_likelihood: -12093.738618240797\n",
      "    val_log_marginal: -12102.740066648243\n",
      "Train Epoch: 4598 [256/118836 (0%)] Loss: 12232.784180\n",
      "Train Epoch: 4598 [33024/118836 (28%)] Loss: 12250.604492\n",
      "Train Epoch: 4598 [65792/118836 (55%)] Loss: 12374.556641\n",
      "Train Epoch: 4598 [98560/118836 (83%)] Loss: 12179.678711\n",
      "    epoch          : 4598\n",
      "    loss           : 12176.292883290685\n",
      "    val_loss       : 12175.136872092578\n",
      "    val_log_likelihood: -12095.375843930935\n",
      "    val_log_marginal: -12104.437729471554\n",
      "Train Epoch: 4599 [256/118836 (0%)] Loss: 12256.122070\n",
      "Train Epoch: 4599 [33024/118836 (28%)] Loss: 12121.891602\n",
      "Train Epoch: 4599 [65792/118836 (55%)] Loss: 12210.582031\n",
      "Train Epoch: 4599 [98560/118836 (83%)] Loss: 12187.203125\n",
      "    epoch          : 4599\n",
      "    loss           : 12173.692651145058\n",
      "    val_loss       : 12178.770471861288\n",
      "    val_log_likelihood: -12095.067073446546\n",
      "    val_log_marginal: -12104.030287959546\n",
      "Train Epoch: 4600 [256/118836 (0%)] Loss: 12195.576172\n",
      "Train Epoch: 4600 [33024/118836 (28%)] Loss: 12183.577148\n",
      "Train Epoch: 4600 [65792/118836 (55%)] Loss: 12194.416016\n",
      "Train Epoch: 4600 [98560/118836 (83%)] Loss: 12297.000000\n",
      "    epoch          : 4600\n",
      "    loss           : 12174.505008012822\n",
      "    val_loss       : 12175.696977118825\n",
      "    val_log_likelihood: -12097.13576383504\n",
      "    val_log_marginal: -12106.045882289516\n",
      "Saving checkpoint: saved/models/SelfiesAutoencodingOperad/0905_154251/checkpoint-epoch4600.pth ...\n",
      "Train Epoch: 4601 [256/118836 (0%)] Loss: 12178.425781\n",
      "Train Epoch: 4601 [33024/118836 (28%)] Loss: 12290.166016\n",
      "Train Epoch: 4601 [65792/118836 (55%)] Loss: 12183.824219\n",
      "Train Epoch: 4601 [98560/118836 (83%)] Loss: 12151.826172\n",
      "    epoch          : 4601\n",
      "    loss           : 12177.818323026519\n",
      "    val_loss       : 12175.133522516433\n",
      "    val_log_likelihood: -12094.547692921578\n",
      "    val_log_marginal: -12103.491941134802\n",
      "Train Epoch: 4602 [256/118836 (0%)] Loss: 12159.912109\n",
      "Train Epoch: 4602 [33024/118836 (28%)] Loss: 12204.155273\n",
      "Train Epoch: 4602 [65792/118836 (55%)] Loss: 12193.587891\n",
      "Train Epoch: 4602 [98560/118836 (83%)] Loss: 12155.220703\n",
      "    epoch          : 4602\n",
      "    loss           : 12176.139725011632\n",
      "    val_loss       : 12178.138542271958\n",
      "    val_log_likelihood: -12098.0475281418\n",
      "    val_log_marginal: -12106.927839663747\n",
      "Train Epoch: 4603 [256/118836 (0%)] Loss: 12104.613281\n",
      "Train Epoch: 4603 [33024/118836 (28%)] Loss: 12175.820312\n",
      "Train Epoch: 4603 [65792/118836 (55%)] Loss: 12189.830078\n",
      "Train Epoch: 4603 [98560/118836 (83%)] Loss: 12239.091797\n",
      "    epoch          : 4603\n",
      "    loss           : 12171.964832603133\n",
      "    val_loss       : 12173.786427920564\n",
      "    val_log_likelihood: -12094.020435761735\n",
      "    val_log_marginal: -12102.879530759805\n",
      "Train Epoch: 4604 [256/118836 (0%)] Loss: 12255.070312\n",
      "Train Epoch: 4604 [33024/118836 (28%)] Loss: 12158.883789\n",
      "Train Epoch: 4604 [65792/118836 (55%)] Loss: 12122.523438\n",
      "Train Epoch: 4604 [98560/118836 (83%)] Loss: 12127.291992\n",
      "    epoch          : 4604\n",
      "    loss           : 12176.330707842226\n",
      "    val_loss       : 12173.129964224912\n",
      "    val_log_likelihood: -12093.048121348997\n",
      "    val_log_marginal: -12101.977524613585\n",
      "Train Epoch: 4605 [256/118836 (0%)] Loss: 12227.570312\n",
      "Train Epoch: 4605 [33024/118836 (28%)] Loss: 12261.373047\n",
      "Train Epoch: 4605 [65792/118836 (55%)] Loss: 12261.656250\n",
      "Train Epoch: 4605 [98560/118836 (83%)] Loss: 12292.943359\n",
      "    epoch          : 4605\n",
      "    loss           : 12173.822506171164\n",
      "    val_loss       : 12177.749092899574\n",
      "    val_log_likelihood: -12097.105151145059\n",
      "    val_log_marginal: -12106.067918763225\n",
      "Train Epoch: 4606 [256/118836 (0%)] Loss: 12135.242188\n",
      "Train Epoch: 4606 [33024/118836 (28%)] Loss: 12163.142578\n",
      "Train Epoch: 4606 [65792/118836 (55%)] Loss: 12253.761719\n",
      "Train Epoch: 4606 [98560/118836 (83%)] Loss: 12118.296875\n",
      "    epoch          : 4606\n",
      "    loss           : 12180.16552936311\n",
      "    val_loss       : 12179.53607168603\n",
      "    val_log_likelihood: -12096.165159739454\n",
      "    val_log_marginal: -12105.18426612921\n",
      "Train Epoch: 4607 [256/118836 (0%)] Loss: 12259.473633\n",
      "Train Epoch: 4607 [33024/118836 (28%)] Loss: 12317.017578\n",
      "Train Epoch: 4607 [65792/118836 (55%)] Loss: 12112.003906\n",
      "Train Epoch: 4607 [98560/118836 (83%)] Loss: 12165.908203\n",
      "    epoch          : 4607\n",
      "    loss           : 12172.261955580541\n",
      "    val_loss       : 12176.207394351013\n",
      "    val_log_likelihood: -12093.42488029234\n",
      "    val_log_marginal: -12102.325678474142\n",
      "Train Epoch: 4608 [256/118836 (0%)] Loss: 12223.951172\n",
      "Train Epoch: 4608 [33024/118836 (28%)] Loss: 12142.842773\n",
      "Train Epoch: 4608 [65792/118836 (55%)] Loss: 12119.592773\n",
      "Train Epoch: 4608 [98560/118836 (83%)] Loss: 12223.467773\n",
      "    epoch          : 4608\n",
      "    loss           : 12180.156237076097\n",
      "    val_loss       : 12175.52975531019\n",
      "    val_log_likelihood: -12095.714966527088\n",
      "    val_log_marginal: -12104.693047848012\n",
      "Train Epoch: 4609 [256/118836 (0%)] Loss: 12174.770508\n",
      "Train Epoch: 4609 [33024/118836 (28%)] Loss: 12207.579102\n",
      "Train Epoch: 4609 [65792/118836 (55%)] Loss: 12138.841797\n",
      "Train Epoch: 4609 [98560/118836 (83%)] Loss: 12192.039062\n",
      "    epoch          : 4609\n",
      "    loss           : 12177.030677309502\n",
      "    val_loss       : 12179.168158888833\n",
      "    val_log_likelihood: -12095.057731402501\n",
      "    val_log_marginal: -12104.022079651522\n",
      "Train Epoch: 4610 [256/118836 (0%)] Loss: 12140.743164\n",
      "Train Epoch: 4610 [33024/118836 (28%)] Loss: 12190.992188\n",
      "Train Epoch: 4610 [65792/118836 (55%)] Loss: 12249.966797\n",
      "Train Epoch: 4610 [98560/118836 (83%)] Loss: 12135.593750\n",
      "    epoch          : 4610\n",
      "    loss           : 12179.328666511581\n",
      "    val_loss       : 12179.207382532964\n",
      "    val_log_likelihood: -12096.489446016854\n",
      "    val_log_marginal: -12105.725856679797\n",
      "Train Epoch: 4611 [256/118836 (0%)] Loss: 12127.172852\n",
      "Train Epoch: 4611 [33024/118836 (28%)] Loss: 12204.961914\n",
      "Train Epoch: 4611 [65792/118836 (55%)] Loss: 12235.750000\n",
      "Train Epoch: 4611 [98560/118836 (83%)] Loss: 12210.559570\n",
      "    epoch          : 4611\n",
      "    loss           : 12179.272504555676\n",
      "    val_loss       : 12177.778243818366\n",
      "    val_log_likelihood: -12094.56555101065\n",
      "    val_log_marginal: -12103.676228683064\n",
      "Train Epoch: 4612 [256/118836 (0%)] Loss: 12172.604492\n",
      "Train Epoch: 4612 [33024/118836 (28%)] Loss: 12218.297852\n",
      "Train Epoch: 4612 [65792/118836 (55%)] Loss: 12145.788086\n",
      "Train Epoch: 4612 [98560/118836 (83%)] Loss: 12155.568359\n",
      "    epoch          : 4612\n",
      "    loss           : 12172.223758820564\n",
      "    val_loss       : 12173.418829970275\n",
      "    val_log_likelihood: -12095.616234685174\n",
      "    val_log_marginal: -12104.667045319093\n",
      "Train Epoch: 4613 [256/118836 (0%)] Loss: 12085.829102\n",
      "Train Epoch: 4613 [33024/118836 (28%)] Loss: 12172.544922\n",
      "Train Epoch: 4613 [65792/118836 (55%)] Loss: 12196.624023\n",
      "Train Epoch: 4613 [98560/118836 (83%)] Loss: 12135.131836\n",
      "    epoch          : 4613\n",
      "    loss           : 12174.399322948977\n",
      "    val_loss       : 12175.43109031824\n",
      "    val_log_likelihood: -12096.971308286806\n",
      "    val_log_marginal: -12105.958682711705\n",
      "Train Epoch: 4614 [256/118836 (0%)] Loss: 12286.150391\n",
      "Train Epoch: 4614 [33024/118836 (28%)] Loss: 12178.855469\n",
      "Train Epoch: 4614 [65792/118836 (55%)] Loss: 12151.523438\n",
      "Train Epoch: 4614 [98560/118836 (83%)] Loss: 12205.446289\n",
      "    epoch          : 4614\n",
      "    loss           : 12173.914216779105\n",
      "    val_loss       : 12173.31227349758\n",
      "    val_log_likelihood: -12097.820971780655\n",
      "    val_log_marginal: -12106.88464337713\n",
      "Train Epoch: 4615 [256/118836 (0%)] Loss: 12415.154297\n",
      "Train Epoch: 4615 [33024/118836 (28%)] Loss: 12158.142578\n",
      "Train Epoch: 4615 [65792/118836 (55%)] Loss: 12326.431641\n",
      "Train Epoch: 4615 [98560/118836 (83%)] Loss: 12218.113281\n",
      "    epoch          : 4615\n",
      "    loss           : 12174.360929584109\n",
      "    val_loss       : 12178.517793205672\n",
      "    val_log_likelihood: -12097.019486985628\n",
      "    val_log_marginal: -12105.96797694229\n",
      "Train Epoch: 4616 [256/118836 (0%)] Loss: 12080.810547\n",
      "Train Epoch: 4616 [33024/118836 (28%)] Loss: 12239.174805\n",
      "Train Epoch: 4616 [65792/118836 (55%)] Loss: 12193.533203\n",
      "Train Epoch: 4616 [98560/118836 (83%)] Loss: 12182.271484\n",
      "    epoch          : 4616\n",
      "    loss           : 12170.984969822684\n",
      "    val_loss       : 12170.50770762314\n",
      "    val_log_likelihood: -12096.600052826458\n",
      "    val_log_marginal: -12105.590600213627\n",
      "Train Epoch: 4617 [256/118836 (0%)] Loss: 12183.896484\n",
      "Train Epoch: 4617 [33024/118836 (28%)] Loss: 12342.001953\n",
      "Train Epoch: 4617 [65792/118836 (55%)] Loss: 12210.635742\n",
      "Train Epoch: 4617 [98560/118836 (83%)] Loss: 12251.425781\n",
      "    epoch          : 4617\n",
      "    loss           : 12175.347935890974\n",
      "    val_loss       : 12172.960923962466\n",
      "    val_log_likelihood: -12096.848908414753\n",
      "    val_log_marginal: -12105.891984580181\n",
      "Train Epoch: 4618 [256/118836 (0%)] Loss: 12201.197266\n",
      "Train Epoch: 4618 [33024/118836 (28%)] Loss: 12198.036133\n",
      "Train Epoch: 4618 [65792/118836 (55%)] Loss: 12190.438477\n",
      "Train Epoch: 4618 [98560/118836 (83%)] Loss: 12260.577148\n",
      "    epoch          : 4618\n",
      "    loss           : 12176.495971619108\n",
      "    val_loss       : 12174.730927691046\n",
      "    val_log_likelihood: -12096.068413816945\n",
      "    val_log_marginal: -12104.980112230913\n",
      "Train Epoch: 4619 [256/118836 (0%)] Loss: 12299.992188\n",
      "Train Epoch: 4619 [33024/118836 (28%)] Loss: 12218.587891\n",
      "Train Epoch: 4619 [65792/118836 (55%)] Loss: 12153.844727\n",
      "Train Epoch: 4619 [98560/118836 (83%)] Loss: 12249.060547\n",
      "    epoch          : 4619\n",
      "    loss           : 12180.979027250052\n",
      "    val_loss       : 12175.418068830277\n",
      "    val_log_likelihood: -12096.954170705387\n",
      "    val_log_marginal: -12105.863550286289\n",
      "Train Epoch: 4620 [256/118836 (0%)] Loss: 12227.085938\n",
      "Train Epoch: 4620 [33024/118836 (28%)] Loss: 12175.195312\n",
      "Train Epoch: 4620 [65792/118836 (55%)] Loss: 12106.429688\n",
      "Train Epoch: 4620 [98560/118836 (83%)] Loss: 12175.058594\n",
      "    epoch          : 4620\n",
      "    loss           : 12176.736525537635\n",
      "    val_loss       : 12176.539930676106\n",
      "    val_log_likelihood: -12092.615180094603\n",
      "    val_log_marginal: -12101.588853034225\n",
      "Train Epoch: 4621 [256/118836 (0%)] Loss: 12262.373047\n",
      "Train Epoch: 4621 [33024/118836 (28%)] Loss: 12215.015625\n",
      "Train Epoch: 4621 [65792/118836 (55%)] Loss: 12178.873047\n",
      "Train Epoch: 4621 [98560/118836 (83%)] Loss: 12204.742188\n",
      "    epoch          : 4621\n",
      "    loss           : 12172.67107226401\n",
      "    val_loss       : 12177.60659385291\n",
      "    val_log_likelihood: -12093.9402274284\n",
      "    val_log_marginal: -12102.848581739185\n",
      "Train Epoch: 4622 [256/118836 (0%)] Loss: 12090.515625\n",
      "Train Epoch: 4622 [33024/118836 (28%)] Loss: 12198.728516\n",
      "Train Epoch: 4622 [65792/118836 (55%)] Loss: 12154.889648\n",
      "Train Epoch: 4622 [98560/118836 (83%)] Loss: 12208.749023\n",
      "    epoch          : 4622\n",
      "    loss           : 12175.235935238316\n",
      "    val_loss       : 12174.161758512475\n",
      "    val_log_likelihood: -12091.560167881515\n",
      "    val_log_marginal: -12100.587609674541\n",
      "Train Epoch: 4623 [256/118836 (0%)] Loss: 12150.393555\n",
      "Train Epoch: 4623 [33024/118836 (28%)] Loss: 12153.550781\n",
      "Train Epoch: 4623 [65792/118836 (55%)] Loss: 12133.065430\n",
      "Train Epoch: 4623 [98560/118836 (83%)] Loss: 12175.267578\n",
      "    epoch          : 4623\n",
      "    loss           : 12176.846451742142\n",
      "    val_loss       : 12171.105841426825\n",
      "    val_log_likelihood: -12095.338612425041\n",
      "    val_log_marginal: -12104.419065204516\n",
      "Train Epoch: 4624 [256/118836 (0%)] Loss: 12185.943359\n",
      "Train Epoch: 4624 [33024/118836 (28%)] Loss: 12282.834961\n",
      "Train Epoch: 4624 [65792/118836 (55%)] Loss: 12343.851562\n",
      "Train Epoch: 4624 [98560/118836 (83%)] Loss: 12166.195312\n",
      "    epoch          : 4624\n",
      "    loss           : 12176.808600696599\n",
      "    val_loss       : 12174.81235028726\n",
      "    val_log_likelihood: -12091.667391859233\n",
      "    val_log_marginal: -12100.727742577197\n",
      "Train Epoch: 4625 [256/118836 (0%)] Loss: 12144.775391\n",
      "Train Epoch: 4625 [33024/118836 (28%)] Loss: 12244.748047\n",
      "Train Epoch: 4625 [65792/118836 (55%)] Loss: 12218.791016\n",
      "Train Epoch: 4625 [98560/118836 (83%)] Loss: 12202.279297\n",
      "    epoch          : 4625\n",
      "    loss           : 12177.328983793424\n",
      "    val_loss       : 12181.527230255013\n",
      "    val_log_likelihood: -12094.60084716191\n",
      "    val_log_marginal: -12103.493475552988\n",
      "Train Epoch: 4626 [256/118836 (0%)] Loss: 12278.388672\n",
      "Train Epoch: 4626 [33024/118836 (28%)] Loss: 12275.831055\n",
      "Train Epoch: 4626 [65792/118836 (55%)] Loss: 12151.069336\n",
      "Train Epoch: 4626 [98560/118836 (83%)] Loss: 12140.181641\n",
      "    epoch          : 4626\n",
      "    loss           : 12177.53267631436\n",
      "    val_loss       : 12171.820608629614\n",
      "    val_log_likelihood: -12096.524529085245\n",
      "    val_log_marginal: -12105.445586476622\n",
      "Train Epoch: 4627 [256/118836 (0%)] Loss: 12156.482422\n",
      "Train Epoch: 4627 [33024/118836 (28%)] Loss: 12184.587891\n",
      "Train Epoch: 4627 [65792/118836 (55%)] Loss: 12231.273438\n",
      "Train Epoch: 4627 [98560/118836 (83%)] Loss: 12201.701172\n",
      "    epoch          : 4627\n",
      "    loss           : 12176.186056238368\n",
      "    val_loss       : 12176.93669448664\n",
      "    val_log_likelihood: -12093.782739803039\n",
      "    val_log_marginal: -12102.693091068297\n",
      "Train Epoch: 4628 [256/118836 (0%)] Loss: 12246.653320\n",
      "Train Epoch: 4628 [33024/118836 (28%)] Loss: 12150.993164\n",
      "Train Epoch: 4628 [65792/118836 (55%)] Loss: 12135.007812\n",
      "Train Epoch: 4628 [98560/118836 (83%)] Loss: 12168.284180\n",
      "    epoch          : 4628\n",
      "    loss           : 12177.80366538074\n",
      "    val_loss       : 12175.674298628066\n",
      "    val_log_likelihood: -12095.20890747777\n",
      "    val_log_marginal: -12104.20580472144\n",
      "Train Epoch: 4629 [256/118836 (0%)] Loss: 12083.857422\n",
      "Train Epoch: 4629 [33024/118836 (28%)] Loss: 12212.562500\n",
      "Train Epoch: 4629 [65792/118836 (55%)] Loss: 12235.203125\n",
      "Train Epoch: 4629 [98560/118836 (83%)] Loss: 12131.217773\n",
      "    epoch          : 4629\n",
      "    loss           : 12176.207352893662\n",
      "    val_loss       : 12177.662302990002\n",
      "    val_log_likelihood: -12095.183838657982\n",
      "    val_log_marginal: -12104.173718070231\n",
      "Train Epoch: 4630 [256/118836 (0%)] Loss: 12365.312500\n",
      "Train Epoch: 4630 [33024/118836 (28%)] Loss: 12156.923828\n",
      "Train Epoch: 4630 [65792/118836 (55%)] Loss: 12176.478516\n",
      "Train Epoch: 4630 [98560/118836 (83%)] Loss: 12227.141602\n",
      "    epoch          : 4630\n",
      "    loss           : 12178.73415141646\n",
      "    val_loss       : 12176.313596260496\n",
      "    val_log_likelihood: -12092.943598467225\n",
      "    val_log_marginal: -12101.776955719106\n",
      "Train Epoch: 4631 [256/118836 (0%)] Loss: 12248.525391\n",
      "Train Epoch: 4631 [33024/118836 (28%)] Loss: 12129.479492\n",
      "Train Epoch: 4631 [65792/118836 (55%)] Loss: 12136.776367\n",
      "Train Epoch: 4631 [98560/118836 (83%)] Loss: 12169.542969\n",
      "    epoch          : 4631\n",
      "    loss           : 12176.176603533395\n",
      "    val_loss       : 12180.10635044455\n",
      "    val_log_likelihood: -12095.398414721618\n",
      "    val_log_marginal: -12104.235346272028\n",
      "Train Epoch: 4632 [256/118836 (0%)] Loss: 12348.921875\n",
      "Train Epoch: 4632 [33024/118836 (28%)] Loss: 12203.513672\n",
      "Train Epoch: 4632 [65792/118836 (55%)] Loss: 12151.315430\n",
      "Train Epoch: 4632 [98560/118836 (83%)] Loss: 12232.841797\n",
      "    epoch          : 4632\n",
      "    loss           : 12175.978312396608\n",
      "    val_loss       : 12175.414827677781\n",
      "    val_log_likelihood: -12096.838666220792\n",
      "    val_log_marginal: -12105.881127526422\n",
      "Train Epoch: 4633 [256/118836 (0%)] Loss: 12253.950195\n",
      "Train Epoch: 4633 [33024/118836 (28%)] Loss: 12250.964844\n",
      "Train Epoch: 4633 [65792/118836 (55%)] Loss: 12153.544922\n",
      "Train Epoch: 4633 [98560/118836 (83%)] Loss: 12216.373047\n",
      "    epoch          : 4633\n",
      "    loss           : 12178.59293773263\n",
      "    val_loss       : 12178.24416398333\n",
      "    val_log_likelihood: -12094.814066054074\n",
      "    val_log_marginal: -12103.670479810202\n",
      "Train Epoch: 4634 [256/118836 (0%)] Loss: 12128.607422\n",
      "Train Epoch: 4634 [33024/118836 (28%)] Loss: 12162.267578\n",
      "Train Epoch: 4634 [65792/118836 (55%)] Loss: 12193.442383\n",
      "Train Epoch: 4634 [98560/118836 (83%)] Loss: 12208.248047\n",
      "    epoch          : 4634\n",
      "    loss           : 12173.555162453473\n",
      "    val_loss       : 12174.895948661208\n",
      "    val_log_likelihood: -12090.987977376706\n",
      "    val_log_marginal: -12099.90170463828\n",
      "Train Epoch: 4635 [256/118836 (0%)] Loss: 12146.158203\n",
      "Train Epoch: 4635 [33024/118836 (28%)] Loss: 12286.372070\n",
      "Train Epoch: 4635 [65792/118836 (55%)] Loss: 12186.842773\n",
      "Train Epoch: 4635 [98560/118836 (83%)] Loss: 12152.412109\n",
      "    epoch          : 4635\n",
      "    loss           : 12174.879060044457\n",
      "    val_loss       : 12176.50358500536\n",
      "    val_log_likelihood: -12097.303240022746\n",
      "    val_log_marginal: -12106.29484435132\n",
      "Train Epoch: 4636 [256/118836 (0%)] Loss: 12194.402344\n",
      "Train Epoch: 4636 [33024/118836 (28%)] Loss: 12141.354492\n",
      "Train Epoch: 4636 [65792/118836 (55%)] Loss: 12142.028320\n",
      "Train Epoch: 4636 [98560/118836 (83%)] Loss: 12251.647461\n",
      "    epoch          : 4636\n",
      "    loss           : 12177.48120024297\n",
      "    val_loss       : 12176.988402591545\n",
      "    val_log_likelihood: -12094.942719480201\n",
      "    val_log_marginal: -12103.985655200255\n",
      "Train Epoch: 4637 [256/118836 (0%)] Loss: 12103.829102\n",
      "Train Epoch: 4637 [33024/118836 (28%)] Loss: 12194.374023\n",
      "Train Epoch: 4637 [65792/118836 (55%)] Loss: 12165.853516\n",
      "Train Epoch: 4637 [98560/118836 (83%)] Loss: 12219.925781\n",
      "    epoch          : 4637\n",
      "    loss           : 12178.930209948821\n",
      "    val_loss       : 12177.99112404117\n",
      "    val_log_likelihood: -12095.81121374845\n",
      "    val_log_marginal: -12104.786608677676\n",
      "Train Epoch: 4638 [256/118836 (0%)] Loss: 12258.664062\n",
      "Train Epoch: 4638 [33024/118836 (28%)] Loss: 12184.522461\n",
      "Train Epoch: 4638 [65792/118836 (55%)] Loss: 12272.406250\n",
      "Train Epoch: 4638 [98560/118836 (83%)] Loss: 12152.739258\n",
      "    epoch          : 4638\n",
      "    loss           : 12181.060172243333\n",
      "    val_loss       : 12179.330837312908\n",
      "    val_log_likelihood: -12093.30448007134\n",
      "    val_log_marginal: -12102.39887928699\n",
      "Train Epoch: 4639 [256/118836 (0%)] Loss: 12306.127930\n",
      "Train Epoch: 4639 [33024/118836 (28%)] Loss: 12201.383789\n",
      "Train Epoch: 4639 [65792/118836 (55%)] Loss: 12215.623047\n",
      "Train Epoch: 4639 [98560/118836 (83%)] Loss: 12183.044922\n",
      "    epoch          : 4639\n",
      "    loss           : 12178.74269250155\n",
      "    val_loss       : 12175.068892030758\n",
      "    val_log_likelihood: -12094.683594073096\n",
      "    val_log_marginal: -12103.678681509418\n",
      "Train Epoch: 4640 [256/118836 (0%)] Loss: 12175.722656\n",
      "Train Epoch: 4640 [33024/118836 (28%)] Loss: 12144.420898\n",
      "Train Epoch: 4640 [65792/118836 (55%)] Loss: 12203.817383\n",
      "Train Epoch: 4640 [98560/118836 (83%)] Loss: 12120.943359\n",
      "    epoch          : 4640\n",
      "    loss           : 12177.492504620295\n",
      "    val_loss       : 12175.123078025745\n",
      "    val_log_likelihood: -12096.51161390483\n",
      "    val_log_marginal: -12105.427072587645\n",
      "Train Epoch: 4641 [256/118836 (0%)] Loss: 12193.190430\n",
      "Train Epoch: 4641 [33024/118836 (28%)] Loss: 12188.250000\n",
      "Train Epoch: 4641 [65792/118836 (55%)] Loss: 12164.090820\n",
      "Train Epoch: 4641 [98560/118836 (83%)] Loss: 12224.733398\n",
      "    epoch          : 4641\n",
      "    loss           : 12176.988415335505\n",
      "    val_loss       : 12186.711681770186\n",
      "    val_log_likelihood: -12113.985637665426\n",
      "    val_log_marginal: -12123.08429056166\n",
      "Train Epoch: 4642 [256/118836 (0%)] Loss: 12263.244141\n",
      "Train Epoch: 4642 [33024/118836 (28%)] Loss: 12150.493164\n",
      "Train Epoch: 4642 [65792/118836 (55%)] Loss: 12234.250000\n",
      "Train Epoch: 4642 [98560/118836 (83%)] Loss: 12114.427734\n",
      "    epoch          : 4642\n",
      "    loss           : 12180.160940084781\n",
      "    val_loss       : 12180.638869613562\n",
      "    val_log_likelihood: -12099.534607468724\n",
      "    val_log_marginal: -12108.68141263583\n",
      "Train Epoch: 4643 [256/118836 (0%)] Loss: 12284.096680\n",
      "Train Epoch: 4643 [33024/118836 (28%)] Loss: 12140.597656\n",
      "Train Epoch: 4643 [65792/118836 (55%)] Loss: 12159.775391\n",
      "Train Epoch: 4643 [98560/118836 (83%)] Loss: 12180.215820\n",
      "    epoch          : 4643\n",
      "    loss           : 12177.342772145108\n",
      "    val_loss       : 12174.900191107852\n",
      "    val_log_likelihood: -12095.949607436414\n",
      "    val_log_marginal: -12105.068197267703\n",
      "Train Epoch: 4644 [256/118836 (0%)] Loss: 12112.830078\n",
      "Train Epoch: 4644 [33024/118836 (28%)] Loss: 12261.805664\n",
      "Train Epoch: 4644 [65792/118836 (55%)] Loss: 12292.516602\n",
      "Train Epoch: 4644 [98560/118836 (83%)] Loss: 12248.303711\n",
      "    epoch          : 4644\n",
      "    loss           : 12178.937429241625\n",
      "    val_loss       : 12178.026806812053\n",
      "    val_log_likelihood: -12093.376992542908\n",
      "    val_log_marginal: -12102.371908093586\n",
      "Train Epoch: 4645 [256/118836 (0%)] Loss: 12256.944336\n",
      "Train Epoch: 4645 [33024/118836 (28%)] Loss: 12179.880859\n",
      "Train Epoch: 4645 [65792/118836 (55%)] Loss: 12217.083984\n",
      "Train Epoch: 4645 [98560/118836 (83%)] Loss: 12203.767578\n",
      "    epoch          : 4645\n",
      "    loss           : 12178.535318768092\n",
      "    val_loss       : 12177.260506585968\n",
      "    val_log_likelihood: -12092.74777466527\n",
      "    val_log_marginal: -12101.761520709133\n",
      "Train Epoch: 4646 [256/118836 (0%)] Loss: 12185.726562\n",
      "Train Epoch: 4646 [33024/118836 (28%)] Loss: 12249.704102\n",
      "Train Epoch: 4646 [65792/118836 (55%)] Loss: 12184.482422\n",
      "Train Epoch: 4646 [98560/118836 (83%)] Loss: 12128.241211\n",
      "    epoch          : 4646\n",
      "    loss           : 12179.676482210247\n",
      "    val_loss       : 12178.997583638406\n",
      "    val_log_likelihood: -12096.637780610268\n",
      "    val_log_marginal: -12105.83213208328\n",
      "Train Epoch: 4647 [256/118836 (0%)] Loss: 12233.178711\n",
      "Train Epoch: 4647 [33024/118836 (28%)] Loss: 12147.322266\n",
      "Train Epoch: 4647 [65792/118836 (55%)] Loss: 12133.282227\n",
      "Train Epoch: 4647 [98560/118836 (83%)] Loss: 12217.481445\n",
      "    epoch          : 4647\n",
      "    loss           : 12176.656151778328\n",
      "    val_loss       : 12175.060339244981\n",
      "    val_log_likelihood: -12095.545430269076\n",
      "    val_log_marginal: -12104.679932015712\n",
      "Train Epoch: 4648 [256/118836 (0%)] Loss: 12122.760742\n",
      "Train Epoch: 4648 [33024/118836 (28%)] Loss: 12148.807617\n",
      "Train Epoch: 4648 [65792/118836 (55%)] Loss: 12234.435547\n",
      "Train Epoch: 4648 [98560/118836 (83%)] Loss: 12329.389648\n",
      "    epoch          : 4648\n",
      "    loss           : 12177.225373016181\n",
      "    val_loss       : 12179.953835926024\n",
      "    val_log_likelihood: -12093.565604160205\n",
      "    val_log_marginal: -12102.504796271343\n",
      "Train Epoch: 4649 [256/118836 (0%)] Loss: 12141.144531\n",
      "Train Epoch: 4649 [33024/118836 (28%)] Loss: 12345.123047\n",
      "Train Epoch: 4649 [65792/118836 (55%)] Loss: 12149.444336\n",
      "Train Epoch: 4649 [98560/118836 (83%)] Loss: 12210.050781\n",
      "    epoch          : 4649\n",
      "    loss           : 12174.421762885133\n",
      "    val_loss       : 12174.587435058304\n",
      "    val_log_likelihood: -12095.5567078293\n",
      "    val_log_marginal: -12104.508171366693\n",
      "Train Epoch: 4650 [256/118836 (0%)] Loss: 12178.929688\n",
      "Train Epoch: 4650 [33024/118836 (28%)] Loss: 12275.757812\n",
      "Train Epoch: 4650 [65792/118836 (55%)] Loss: 12196.759766\n",
      "Train Epoch: 4650 [98560/118836 (83%)] Loss: 12170.910156\n",
      "    epoch          : 4650\n",
      "    loss           : 12174.288125840054\n",
      "    val_loss       : 12174.67742104819\n",
      "    val_log_likelihood: -12091.480176346671\n",
      "    val_log_marginal: -12100.318951285146\n",
      "Train Epoch: 4651 [256/118836 (0%)] Loss: 12158.786133\n",
      "Train Epoch: 4651 [33024/118836 (28%)] Loss: 12154.414062\n",
      "Train Epoch: 4651 [65792/118836 (55%)] Loss: 12208.449219\n",
      "Train Epoch: 4651 [98560/118836 (83%)] Loss: 12180.402344\n",
      "    epoch          : 4651\n",
      "    loss           : 12177.30304164082\n",
      "    val_loss       : 12176.109448747466\n",
      "    val_log_likelihood: -12092.97345623966\n",
      "    val_log_marginal: -12101.859307973242\n",
      "Train Epoch: 4652 [256/118836 (0%)] Loss: 12151.162109\n",
      "Train Epoch: 4652 [33024/118836 (28%)] Loss: 12236.539062\n",
      "Train Epoch: 4652 [65792/118836 (55%)] Loss: 12147.791992\n",
      "Train Epoch: 4652 [98560/118836 (83%)] Loss: 12171.231445\n",
      "    epoch          : 4652\n",
      "    loss           : 12178.512982061622\n",
      "    val_loss       : 12177.609372618139\n",
      "    val_log_likelihood: -12095.302939541976\n",
      "    val_log_marginal: -12104.184094783455\n",
      "Train Epoch: 4653 [256/118836 (0%)] Loss: 12283.109375\n",
      "Train Epoch: 4653 [33024/118836 (28%)] Loss: 12229.583984\n",
      "Train Epoch: 4653 [65792/118836 (55%)] Loss: 12227.394531\n",
      "Train Epoch: 4653 [98560/118836 (83%)] Loss: 12193.317383\n",
      "    epoch          : 4653\n",
      "    loss           : 12177.474736190808\n",
      "    val_loss       : 12176.012412233908\n",
      "    val_log_likelihood: -12093.79060626034\n",
      "    val_log_marginal: -12102.637427547528\n",
      "Train Epoch: 4654 [256/118836 (0%)] Loss: 12171.090820\n",
      "Train Epoch: 4654 [33024/118836 (28%)] Loss: 12155.666016\n",
      "Train Epoch: 4654 [65792/118836 (55%)] Loss: 12227.365234\n",
      "Train Epoch: 4654 [98560/118836 (83%)] Loss: 12208.385742\n",
      "    epoch          : 4654\n",
      "    loss           : 12179.161000665581\n",
      "    val_loss       : 12175.553934703918\n",
      "    val_log_likelihood: -12094.673626835194\n",
      "    val_log_marginal: -12103.60788789915\n",
      "Train Epoch: 4655 [256/118836 (0%)] Loss: 12244.027344\n",
      "Train Epoch: 4655 [33024/118836 (28%)] Loss: 12271.253906\n",
      "Train Epoch: 4655 [65792/118836 (55%)] Loss: 12286.051758\n",
      "Train Epoch: 4655 [98560/118836 (83%)] Loss: 12132.893555\n",
      "    epoch          : 4655\n",
      "    loss           : 12179.321115720637\n",
      "    val_loss       : 12178.858159490816\n",
      "    val_log_likelihood: -12101.474058978236\n",
      "    val_log_marginal: -12110.482975412835\n",
      "Train Epoch: 4656 [256/118836 (0%)] Loss: 12088.318359\n",
      "Train Epoch: 4656 [33024/118836 (28%)] Loss: 12254.246094\n",
      "Train Epoch: 4656 [65792/118836 (55%)] Loss: 12135.314453\n",
      "Train Epoch: 4656 [98560/118836 (83%)] Loss: 12151.156250\n",
      "    epoch          : 4656\n",
      "    loss           : 12176.948726187706\n",
      "    val_loss       : 12178.614722042108\n",
      "    val_log_likelihood: -12091.65509815705\n",
      "    val_log_marginal: -12100.672921022124\n",
      "Train Epoch: 4657 [256/118836 (0%)] Loss: 12232.843750\n",
      "Train Epoch: 4657 [33024/118836 (28%)] Loss: 12186.729492\n",
      "Train Epoch: 4657 [65792/118836 (55%)] Loss: 12207.400391\n",
      "Train Epoch: 4657 [98560/118836 (83%)] Loss: 12176.740234\n",
      "    epoch          : 4657\n",
      "    loss           : 12179.901127772177\n",
      "    val_loss       : 12174.416141026986\n",
      "    val_log_likelihood: -12092.296479528535\n",
      "    val_log_marginal: -12101.316736192264\n",
      "Train Epoch: 4658 [256/118836 (0%)] Loss: 12188.283203\n",
      "Train Epoch: 4658 [33024/118836 (28%)] Loss: 12146.916016\n",
      "Train Epoch: 4658 [65792/118836 (55%)] Loss: 12235.894531\n",
      "Train Epoch: 4658 [98560/118836 (83%)] Loss: 12125.261719\n",
      "    epoch          : 4658\n",
      "    loss           : 12175.732293120605\n",
      "    val_loss       : 12171.87183675774\n",
      "    val_log_likelihood: -12095.4382342393\n",
      "    val_log_marginal: -12104.575756704204\n",
      "Train Epoch: 4659 [256/118836 (0%)] Loss: 12106.371094\n",
      "Train Epoch: 4659 [33024/118836 (28%)] Loss: 12170.630859\n",
      "Train Epoch: 4659 [65792/118836 (55%)] Loss: 12144.408203\n",
      "Train Epoch: 4659 [98560/118836 (83%)] Loss: 12138.587891\n",
      "    epoch          : 4659\n",
      "    loss           : 12173.229301883011\n",
      "    val_loss       : 12174.630540589287\n",
      "    val_log_likelihood: -12093.688617109956\n",
      "    val_log_marginal: -12102.649860953363\n",
      "Train Epoch: 4660 [256/118836 (0%)] Loss: 12211.946289\n",
      "Train Epoch: 4660 [33024/118836 (28%)] Loss: 12226.072266\n",
      "Train Epoch: 4660 [65792/118836 (55%)] Loss: 12248.076172\n",
      "Train Epoch: 4660 [98560/118836 (83%)] Loss: 12164.025391\n",
      "    epoch          : 4660\n",
      "    loss           : 12174.371728636786\n",
      "    val_loss       : 12174.97776124709\n",
      "    val_log_likelihood: -12095.802945034637\n",
      "    val_log_marginal: -12104.933903380243\n",
      "Train Epoch: 4661 [256/118836 (0%)] Loss: 12176.666992\n",
      "Train Epoch: 4661 [33024/118836 (28%)] Loss: 12249.854492\n",
      "Train Epoch: 4661 [65792/118836 (55%)] Loss: 12140.441406\n",
      "Train Epoch: 4661 [98560/118836 (83%)] Loss: 12274.715820\n",
      "    epoch          : 4661\n",
      "    loss           : 12174.493108328163\n",
      "    val_loss       : 12176.877332041062\n",
      "    val_log_likelihood: -12093.121519107992\n",
      "    val_log_marginal: -12102.146230979431\n",
      "Train Epoch: 4662 [256/118836 (0%)] Loss: 12124.509766\n",
      "Train Epoch: 4662 [33024/118836 (28%)] Loss: 12167.689453\n",
      "Train Epoch: 4662 [65792/118836 (55%)] Loss: 12247.594727\n",
      "Train Epoch: 4662 [98560/118836 (83%)] Loss: 12179.261719\n",
      "    epoch          : 4662\n",
      "    loss           : 12176.563650065913\n",
      "    val_loss       : 12174.805526417722\n",
      "    val_log_likelihood: -12092.512703066843\n",
      "    val_log_marginal: -12101.49096866185\n",
      "Train Epoch: 4663 [256/118836 (0%)] Loss: 12141.112305\n",
      "Train Epoch: 4663 [33024/118836 (28%)] Loss: 12199.091797\n",
      "Train Epoch: 4663 [65792/118836 (55%)] Loss: 12172.209961\n",
      "Train Epoch: 4663 [98560/118836 (83%)] Loss: 12295.033203\n",
      "    epoch          : 4663\n",
      "    loss           : 12175.077036968827\n",
      "    val_loss       : 12177.167495432077\n",
      "    val_log_likelihood: -12092.041802690757\n",
      "    val_log_marginal: -12100.933486941543\n",
      "Train Epoch: 4664 [256/118836 (0%)] Loss: 12108.531250\n",
      "Train Epoch: 4664 [33024/118836 (28%)] Loss: 12167.072266\n",
      "Train Epoch: 4664 [65792/118836 (55%)] Loss: 12237.751953\n",
      "Train Epoch: 4664 [98560/118836 (83%)] Loss: 12141.479492\n",
      "    epoch          : 4664\n",
      "    loss           : 12176.832484717483\n",
      "    val_loss       : 12177.09243228266\n",
      "    val_log_likelihood: -12092.953299311155\n",
      "    val_log_marginal: -12101.863405884415\n",
      "Train Epoch: 4665 [256/118836 (0%)] Loss: 12260.439453\n",
      "Train Epoch: 4665 [33024/118836 (28%)] Loss: 12151.252930\n",
      "Train Epoch: 4665 [65792/118836 (55%)] Loss: 12196.525391\n",
      "Train Epoch: 4665 [98560/118836 (83%)] Loss: 12155.026367\n",
      "    epoch          : 4665\n",
      "    loss           : 12174.614273805832\n",
      "    val_loss       : 12175.511356375346\n",
      "    val_log_likelihood: -12092.15790280578\n",
      "    val_log_marginal: -12101.099448421106\n",
      "Train Epoch: 4666 [256/118836 (0%)] Loss: 12120.355469\n",
      "Train Epoch: 4666 [33024/118836 (28%)] Loss: 12280.653320\n",
      "Train Epoch: 4666 [65792/118836 (55%)] Loss: 12186.559570\n",
      "Train Epoch: 4666 [98560/118836 (83%)] Loss: 12158.732422\n",
      "    epoch          : 4666\n",
      "    loss           : 12174.635042034999\n",
      "    val_loss       : 12176.600230076328\n",
      "    val_log_likelihood: -12093.680474888853\n",
      "    val_log_marginal: -12102.629602004983\n",
      "Train Epoch: 4667 [256/118836 (0%)] Loss: 12215.294922\n",
      "Train Epoch: 4667 [33024/118836 (28%)] Loss: 12190.337891\n",
      "Train Epoch: 4667 [65792/118836 (55%)] Loss: 12184.794922\n",
      "Train Epoch: 4667 [98560/118836 (83%)] Loss: 12243.538086\n",
      "    epoch          : 4667\n",
      "    loss           : 12173.858288907413\n",
      "    val_loss       : 12175.393270962457\n",
      "    val_log_likelihood: -12093.127103688481\n",
      "    val_log_marginal: -12102.090442400757\n",
      "Train Epoch: 4668 [256/118836 (0%)] Loss: 12156.724609\n",
      "Train Epoch: 4668 [33024/118836 (28%)] Loss: 12284.009766\n",
      "Train Epoch: 4668 [65792/118836 (55%)] Loss: 12244.906250\n",
      "Train Epoch: 4668 [98560/118836 (83%)] Loss: 12185.821289\n",
      "    epoch          : 4668\n",
      "    loss           : 12167.695860311984\n",
      "    val_loss       : 12176.09350882392\n",
      "    val_log_likelihood: -12091.965629523365\n",
      "    val_log_marginal: -12101.056085862392\n",
      "Train Epoch: 4669 [256/118836 (0%)] Loss: 12328.548828\n",
      "Train Epoch: 4669 [33024/118836 (28%)] Loss: 12179.854492\n",
      "Train Epoch: 4669 [65792/118836 (55%)] Loss: 12276.034180\n",
      "Train Epoch: 4669 [98560/118836 (83%)] Loss: 12154.923828\n",
      "    epoch          : 4669\n",
      "    loss           : 12176.073844602979\n",
      "    val_loss       : 12172.049092744996\n",
      "    val_log_likelihood: -12092.062393216242\n",
      "    val_log_marginal: -12101.006341869777\n",
      "Train Epoch: 4670 [256/118836 (0%)] Loss: 12163.966797\n",
      "Train Epoch: 4670 [33024/118836 (28%)] Loss: 12154.538086\n",
      "Train Epoch: 4670 [65792/118836 (55%)] Loss: 12196.406250\n",
      "Train Epoch: 4670 [98560/118836 (83%)] Loss: 12299.192383\n",
      "    epoch          : 4670\n",
      "    loss           : 12171.01072587107\n",
      "    val_loss       : 12174.990917130408\n",
      "    val_log_likelihood: -12092.199253321443\n",
      "    val_log_marginal: -12101.12253811793\n",
      "Train Epoch: 4671 [256/118836 (0%)] Loss: 12164.132812\n",
      "Train Epoch: 4671 [33024/118836 (28%)] Loss: 12187.185547\n",
      "Train Epoch: 4671 [65792/118836 (55%)] Loss: 12120.432617\n",
      "Train Epoch: 4671 [98560/118836 (83%)] Loss: 12158.427734\n",
      "    epoch          : 4671\n",
      "    loss           : 12172.686832318808\n",
      "    val_loss       : 12172.96366994362\n",
      "    val_log_likelihood: -12096.866743079248\n",
      "    val_log_marginal: -12105.730707701252\n",
      "Train Epoch: 4672 [256/118836 (0%)] Loss: 12246.365234\n",
      "Train Epoch: 4672 [33024/118836 (28%)] Loss: 12216.876953\n",
      "Train Epoch: 4672 [65792/118836 (55%)] Loss: 12131.967773\n",
      "Train Epoch: 4672 [98560/118836 (83%)] Loss: 12336.390625\n",
      "    epoch          : 4672\n",
      "    loss           : 12174.562475444583\n",
      "    val_loss       : 12172.09729952959\n",
      "    val_log_likelihood: -12097.411427800609\n",
      "    val_log_marginal: -12106.431302349964\n",
      "Train Epoch: 4673 [256/118836 (0%)] Loss: 12084.518555\n",
      "Train Epoch: 4673 [33024/118836 (28%)] Loss: 12349.887695\n",
      "Train Epoch: 4673 [65792/118836 (55%)] Loss: 12186.920898\n",
      "Train Epoch: 4673 [98560/118836 (83%)] Loss: 12152.572266\n",
      "    epoch          : 4673\n",
      "    loss           : 12175.270549168992\n",
      "    val_loss       : 12173.413169726959\n",
      "    val_log_likelihood: -12095.033716850186\n",
      "    val_log_marginal: -12104.045351039938\n",
      "Train Epoch: 4674 [256/118836 (0%)] Loss: 12248.648438\n",
      "Train Epoch: 4674 [33024/118836 (28%)] Loss: 12168.652344\n",
      "Train Epoch: 4674 [65792/118836 (55%)] Loss: 12154.191406\n",
      "Train Epoch: 4674 [98560/118836 (83%)] Loss: 12264.026367\n",
      "    epoch          : 4674\n",
      "    loss           : 12174.635233470326\n",
      "    val_loss       : 12177.909708494803\n",
      "    val_log_likelihood: -12094.375803543735\n",
      "    val_log_marginal: -12103.402188437745\n",
      "Train Epoch: 4675 [256/118836 (0%)] Loss: 12308.169922\n",
      "Train Epoch: 4675 [33024/118836 (28%)] Loss: 12133.611328\n",
      "Train Epoch: 4675 [65792/118836 (55%)] Loss: 12169.226562\n",
      "Train Epoch: 4675 [98560/118836 (83%)] Loss: 12181.728516\n",
      "    epoch          : 4675\n",
      "    loss           : 12189.269799421008\n",
      "    val_loss       : 12200.600436158473\n",
      "    val_log_likelihood: -12099.995311530707\n",
      "    val_log_marginal: -12109.32692003793\n",
      "Train Epoch: 4676 [256/118836 (0%)] Loss: 12242.154297\n",
      "Train Epoch: 4676 [33024/118836 (28%)] Loss: 12154.647461\n",
      "Train Epoch: 4676 [65792/118836 (55%)] Loss: 12227.765625\n",
      "Train Epoch: 4676 [98560/118836 (83%)] Loss: 12120.408203\n",
      "    epoch          : 4676\n",
      "    loss           : 12184.453918689256\n",
      "    val_loss       : 12182.685183384241\n",
      "    val_log_likelihood: -12097.058786316169\n",
      "    val_log_marginal: -12106.41452622853\n",
      "Train Epoch: 4677 [256/118836 (0%)] Loss: 12254.109375\n",
      "Train Epoch: 4677 [33024/118836 (28%)] Loss: 12138.900391\n",
      "Train Epoch: 4677 [65792/118836 (55%)] Loss: 12182.395508\n",
      "Train Epoch: 4677 [98560/118836 (83%)] Loss: 12141.679688\n",
      "    epoch          : 4677\n",
      "    loss           : 12174.705983121381\n",
      "    val_loss       : 12175.02099169942\n",
      "    val_log_likelihood: -12096.889116134202\n",
      "    val_log_marginal: -12105.881798582619\n",
      "Train Epoch: 4678 [256/118836 (0%)] Loss: 12102.164062\n",
      "Train Epoch: 4678 [33024/118836 (28%)] Loss: 12291.958008\n",
      "Train Epoch: 4678 [65792/118836 (55%)] Loss: 12179.940430\n",
      "Train Epoch: 4678 [98560/118836 (83%)] Loss: 12073.584961\n",
      "    epoch          : 4678\n",
      "    loss           : 12176.076943108974\n",
      "    val_loss       : 12170.114520161618\n",
      "    val_log_likelihood: -12093.311170130273\n",
      "    val_log_marginal: -12102.280127886863\n",
      "Train Epoch: 4679 [256/118836 (0%)] Loss: 12176.871094\n",
      "Train Epoch: 4679 [33024/118836 (28%)] Loss: 12197.596680\n",
      "Train Epoch: 4679 [65792/118836 (55%)] Loss: 12177.248047\n",
      "Train Epoch: 4679 [98560/118836 (83%)] Loss: 12263.770508\n",
      "    epoch          : 4679\n",
      "    loss           : 12170.268478113368\n",
      "    val_loss       : 12176.477524830716\n",
      "    val_log_likelihood: -12096.19007928815\n",
      "    val_log_marginal: -12105.153719412894\n",
      "Train Epoch: 4680 [256/118836 (0%)] Loss: 12325.419922\n",
      "Train Epoch: 4680 [33024/118836 (28%)] Loss: 12050.966797\n",
      "Train Epoch: 4680 [65792/118836 (55%)] Loss: 12236.355469\n",
      "Train Epoch: 4680 [98560/118836 (83%)] Loss: 12156.177734\n",
      "    epoch          : 4680\n",
      "    loss           : 12173.404951955386\n",
      "    val_loss       : 12174.390436631138\n",
      "    val_log_likelihood: -12094.081982462263\n",
      "    val_log_marginal: -12102.975735876691\n",
      "Train Epoch: 4681 [256/118836 (0%)] Loss: 12196.851562\n",
      "Train Epoch: 4681 [33024/118836 (28%)] Loss: 12368.758789\n",
      "Train Epoch: 4681 [65792/118836 (55%)] Loss: 12133.760742\n",
      "Train Epoch: 4681 [98560/118836 (83%)] Loss: 12274.056641\n",
      "    epoch          : 4681\n",
      "    loss           : 12176.839134389216\n",
      "    val_loss       : 12170.76176151222\n",
      "    val_log_likelihood: -12093.545661606959\n",
      "    val_log_marginal: -12102.424993959665\n",
      "Train Epoch: 4682 [256/118836 (0%)] Loss: 12195.746094\n",
      "Train Epoch: 4682 [33024/118836 (28%)] Loss: 12371.384766\n",
      "Train Epoch: 4682 [65792/118836 (55%)] Loss: 12157.961914\n",
      "Train Epoch: 4682 [98560/118836 (83%)] Loss: 12217.292969\n",
      "    epoch          : 4682\n",
      "    loss           : 12177.884576774453\n",
      "    val_loss       : 12172.514956314913\n",
      "    val_log_likelihood: -12092.198842987491\n",
      "    val_log_marginal: -12101.025263271695\n",
      "Train Epoch: 4683 [256/118836 (0%)] Loss: 12210.857422\n",
      "Train Epoch: 4683 [33024/118836 (28%)] Loss: 12315.118164\n",
      "Train Epoch: 4683 [65792/118836 (55%)] Loss: 12143.873047\n",
      "Train Epoch: 4683 [98560/118836 (83%)] Loss: 12171.737305\n",
      "    epoch          : 4683\n",
      "    loss           : 12177.984893087003\n",
      "    val_loss       : 12174.548130854486\n",
      "    val_log_likelihood: -12095.474259783396\n",
      "    val_log_marginal: -12104.420335810779\n",
      "Train Epoch: 4684 [256/118836 (0%)] Loss: 12132.445312\n",
      "Train Epoch: 4684 [33024/118836 (28%)] Loss: 12266.702148\n",
      "Train Epoch: 4684 [65792/118836 (55%)] Loss: 12220.254883\n",
      "Train Epoch: 4684 [98560/118836 (83%)] Loss: 12255.196289\n",
      "    epoch          : 4684\n",
      "    loss           : 12177.084814251188\n",
      "    val_loss       : 12173.77952736294\n",
      "    val_log_likelihood: -12094.01913093207\n",
      "    val_log_marginal: -12102.81149862443\n",
      "Train Epoch: 4685 [256/118836 (0%)] Loss: 12149.004883\n",
      "Train Epoch: 4685 [33024/118836 (28%)] Loss: 12304.172852\n",
      "Train Epoch: 4685 [65792/118836 (55%)] Loss: 12165.307617\n",
      "Train Epoch: 4685 [98560/118836 (83%)] Loss: 12170.808594\n",
      "    epoch          : 4685\n",
      "    loss           : 12177.94739195616\n",
      "    val_loss       : 12176.394404022756\n",
      "    val_log_likelihood: -12094.32640078965\n",
      "    val_log_marginal: -12103.176917031302\n",
      "Train Epoch: 4686 [256/118836 (0%)] Loss: 12177.156250\n",
      "Train Epoch: 4686 [33024/118836 (28%)] Loss: 12263.900391\n",
      "Train Epoch: 4686 [65792/118836 (55%)] Loss: 12227.150391\n",
      "Train Epoch: 4686 [98560/118836 (83%)] Loss: 12153.699219\n",
      "    epoch          : 4686\n",
      "    loss           : 12169.743495075994\n",
      "    val_loss       : 12173.507967995236\n",
      "    val_log_likelihood: -12093.892521744468\n",
      "    val_log_marginal: -12102.915200071197\n",
      "Train Epoch: 4687 [256/118836 (0%)] Loss: 12202.609375\n",
      "Train Epoch: 4687 [33024/118836 (28%)] Loss: 12152.595703\n",
      "Train Epoch: 4687 [65792/118836 (55%)] Loss: 12295.151367\n",
      "Train Epoch: 4687 [98560/118836 (83%)] Loss: 12179.924805\n",
      "    epoch          : 4687\n",
      "    loss           : 12172.6604796707\n",
      "    val_loss       : 12173.572839784561\n",
      "    val_log_likelihood: -12091.470730911393\n",
      "    val_log_marginal: -12100.458577202016\n",
      "Train Epoch: 4688 [256/118836 (0%)] Loss: 12171.535156\n",
      "Train Epoch: 4688 [33024/118836 (28%)] Loss: 12092.233398\n",
      "Train Epoch: 4688 [65792/118836 (55%)] Loss: 12174.510742\n",
      "Train Epoch: 4688 [98560/118836 (83%)] Loss: 12278.044922\n",
      "    epoch          : 4688\n",
      "    loss           : 12173.155125781896\n",
      "    val_loss       : 12172.100485228517\n",
      "    val_log_likelihood: -12094.142777960866\n",
      "    val_log_marginal: -12103.01400670796\n",
      "Train Epoch: 4689 [256/118836 (0%)] Loss: 12135.144531\n",
      "Train Epoch: 4689 [33024/118836 (28%)] Loss: 12172.289062\n",
      "Train Epoch: 4689 [65792/118836 (55%)] Loss: 12162.666016\n",
      "Train Epoch: 4689 [98560/118836 (83%)] Loss: 12248.843750\n",
      "    epoch          : 4689\n",
      "    loss           : 12170.0919584238\n",
      "    val_loss       : 12173.029363974969\n",
      "    val_log_likelihood: -12092.483625575112\n",
      "    val_log_marginal: -12101.324417276428\n",
      "Train Epoch: 4690 [256/118836 (0%)] Loss: 12177.611328\n",
      "Train Epoch: 4690 [33024/118836 (28%)] Loss: 12160.709961\n",
      "Train Epoch: 4690 [65792/118836 (55%)] Loss: 12145.177734\n",
      "Train Epoch: 4690 [98560/118836 (83%)] Loss: 12147.907227\n",
      "    epoch          : 4690\n",
      "    loss           : 12172.012958798594\n",
      "    val_loss       : 12175.347235478168\n",
      "    val_log_likelihood: -12093.449615513853\n",
      "    val_log_marginal: -12102.292914805472\n",
      "Train Epoch: 4691 [256/118836 (0%)] Loss: 12172.625977\n",
      "Train Epoch: 4691 [33024/118836 (28%)] Loss: 12322.764648\n",
      "Train Epoch: 4691 [65792/118836 (55%)] Loss: 12216.979492\n",
      "Train Epoch: 4691 [98560/118836 (83%)] Loss: 12120.843750\n",
      "    epoch          : 4691\n",
      "    loss           : 12176.21835695177\n",
      "    val_loss       : 12170.757262097597\n",
      "    val_log_likelihood: -12094.883834457714\n",
      "    val_log_marginal: -12103.800741010677\n",
      "Train Epoch: 4692 [256/118836 (0%)] Loss: 12170.677734\n",
      "Train Epoch: 4692 [33024/118836 (28%)] Loss: 12258.482422\n",
      "Train Epoch: 4692 [65792/118836 (55%)] Loss: 12104.691406\n",
      "Train Epoch: 4692 [98560/118836 (83%)] Loss: 12167.082031\n",
      "    epoch          : 4692\n",
      "    loss           : 12176.348383219602\n",
      "    val_loss       : 12172.95283978765\n",
      "    val_log_likelihood: -12092.593359051903\n",
      "    val_log_marginal: -12101.592494952249\n",
      "Train Epoch: 4693 [256/118836 (0%)] Loss: 12155.916016\n",
      "Train Epoch: 4693 [33024/118836 (28%)] Loss: 12129.781250\n",
      "Train Epoch: 4693 [65792/118836 (55%)] Loss: 12125.974609\n",
      "Train Epoch: 4693 [98560/118836 (83%)] Loss: 12168.946289\n",
      "    epoch          : 4693\n",
      "    loss           : 12169.106384570152\n",
      "    val_loss       : 12177.140882273\n",
      "    val_log_likelihood: -12092.423108425093\n",
      "    val_log_marginal: -12101.33226002222\n",
      "Train Epoch: 4694 [256/118836 (0%)] Loss: 12162.833984\n",
      "Train Epoch: 4694 [33024/118836 (28%)] Loss: 12234.098633\n",
      "Train Epoch: 4694 [65792/118836 (55%)] Loss: 12146.153320\n",
      "Train Epoch: 4694 [98560/118836 (83%)] Loss: 12213.882812\n",
      "    epoch          : 4694\n",
      "    loss           : 12179.04585255764\n",
      "    val_loss       : 12175.391374953917\n",
      "    val_log_likelihood: -12092.728492685072\n",
      "    val_log_marginal: -12101.755397313831\n",
      "Train Epoch: 4695 [256/118836 (0%)] Loss: 12252.015625\n",
      "Train Epoch: 4695 [33024/118836 (28%)] Loss: 12141.253906\n",
      "Train Epoch: 4695 [65792/118836 (55%)] Loss: 12196.078125\n",
      "Train Epoch: 4695 [98560/118836 (83%)] Loss: 12268.720703\n",
      "    epoch          : 4695\n",
      "    loss           : 12180.37589045699\n",
      "    val_loss       : 12172.245647085103\n",
      "    val_log_likelihood: -12092.533805540479\n",
      "    val_log_marginal: -12101.627654230933\n",
      "Train Epoch: 4696 [256/118836 (0%)] Loss: 12175.015625\n",
      "Train Epoch: 4696 [33024/118836 (28%)] Loss: 12241.108398\n",
      "Train Epoch: 4696 [65792/118836 (55%)] Loss: 12123.456055\n",
      "Train Epoch: 4696 [98560/118836 (83%)] Loss: 12201.088867\n",
      "    epoch          : 4696\n",
      "    loss           : 12174.538932130117\n",
      "    val_loss       : 12171.58824207024\n",
      "    val_log_likelihood: -12089.941287350082\n",
      "    val_log_marginal: -12098.934434039164\n",
      "Train Epoch: 4697 [256/118836 (0%)] Loss: 12139.431641\n",
      "Train Epoch: 4697 [33024/118836 (28%)] Loss: 12158.576172\n",
      "Train Epoch: 4697 [65792/118836 (55%)] Loss: 12189.352539\n",
      "Train Epoch: 4697 [98560/118836 (83%)] Loss: 12218.908203\n",
      "    epoch          : 4697\n",
      "    loss           : 12174.9408606997\n",
      "    val_loss       : 12172.977828955674\n",
      "    val_log_likelihood: -12093.133394560327\n",
      "    val_log_marginal: -12102.032617762165\n",
      "Train Epoch: 4698 [256/118836 (0%)] Loss: 12210.683594\n",
      "Train Epoch: 4698 [33024/118836 (28%)] Loss: 12193.220703\n",
      "Train Epoch: 4698 [65792/118836 (55%)] Loss: 12160.458984\n",
      "Train Epoch: 4698 [98560/118836 (83%)] Loss: 12203.249023\n",
      "    epoch          : 4698\n",
      "    loss           : 12175.528311911963\n",
      "    val_loss       : 12169.696343847989\n",
      "    val_log_likelihood: -12095.39530313017\n",
      "    val_log_marginal: -12104.459721371115\n",
      "Train Epoch: 4699 [256/118836 (0%)] Loss: 12203.086914\n",
      "Train Epoch: 4699 [33024/118836 (28%)] Loss: 12195.301758\n",
      "Train Epoch: 4699 [65792/118836 (55%)] Loss: 12119.659180\n",
      "Train Epoch: 4699 [98560/118836 (83%)] Loss: 12190.165039\n",
      "    epoch          : 4699\n",
      "    loss           : 12173.539575255892\n",
      "    val_loss       : 12178.97445769675\n",
      "    val_log_likelihood: -12094.369891665376\n",
      "    val_log_marginal: -12103.36610511207\n",
      "Train Epoch: 4700 [256/118836 (0%)] Loss: 12263.134766\n",
      "Train Epoch: 4700 [33024/118836 (28%)] Loss: 12125.014648\n",
      "Train Epoch: 4700 [65792/118836 (55%)] Loss: 12238.811523\n",
      "Train Epoch: 4700 [98560/118836 (83%)] Loss: 12193.586914\n",
      "    epoch          : 4700\n",
      "    loss           : 12177.095501835194\n",
      "    val_loss       : 12179.681843326169\n",
      "    val_log_likelihood: -12096.940196734131\n",
      "    val_log_marginal: -12106.088608143124\n",
      "Saving checkpoint: saved/models/SelfiesAutoencodingOperad/0905_154251/checkpoint-epoch4700.pth ...\n",
      "Train Epoch: 4701 [256/118836 (0%)] Loss: 12195.578125\n",
      "Train Epoch: 4701 [33024/118836 (28%)] Loss: 12140.339844\n",
      "Train Epoch: 4701 [65792/118836 (55%)] Loss: 12225.334961\n",
      "Train Epoch: 4701 [98560/118836 (83%)] Loss: 12134.105469\n",
      "    epoch          : 4701\n",
      "    loss           : 12176.342853242608\n",
      "    val_loss       : 12174.605163141106\n",
      "    val_log_likelihood: -12093.876040374274\n",
      "    val_log_marginal: -12102.94072287841\n",
      "Train Epoch: 4702 [256/118836 (0%)] Loss: 12173.182617\n",
      "Train Epoch: 4702 [33024/118836 (28%)] Loss: 12156.775391\n",
      "Train Epoch: 4702 [65792/118836 (55%)] Loss: 12170.750000\n",
      "Train Epoch: 4702 [98560/118836 (83%)] Loss: 12183.042969\n",
      "    epoch          : 4702\n",
      "    loss           : 12176.929410282259\n",
      "    val_loss       : 12176.738005050443\n",
      "    val_log_likelihood: -12092.229942747106\n",
      "    val_log_marginal: -12101.252557538124\n",
      "Train Epoch: 4703 [256/118836 (0%)] Loss: 12161.162109\n",
      "Train Epoch: 4703 [33024/118836 (28%)] Loss: 12152.601562\n",
      "Train Epoch: 4703 [65792/118836 (55%)] Loss: 12138.076172\n",
      "Train Epoch: 4703 [98560/118836 (83%)] Loss: 12344.761719\n",
      "    epoch          : 4703\n",
      "    loss           : 12176.617328209006\n",
      "    val_loss       : 12172.15015599066\n",
      "    val_log_likelihood: -12094.610846063379\n",
      "    val_log_marginal: -12103.622313059524\n",
      "Train Epoch: 4704 [256/118836 (0%)] Loss: 12130.884766\n",
      "Train Epoch: 4704 [33024/118836 (28%)] Loss: 12127.511719\n",
      "Train Epoch: 4704 [65792/118836 (55%)] Loss: 12170.965820\n",
      "Train Epoch: 4704 [98560/118836 (83%)] Loss: 12210.144531\n",
      "    epoch          : 4704\n",
      "    loss           : 12175.074058655138\n",
      "    val_loss       : 12172.486179398744\n",
      "    val_log_likelihood: -12091.747402295287\n",
      "    val_log_marginal: -12100.745830173004\n",
      "Train Epoch: 4705 [256/118836 (0%)] Loss: 12216.619141\n",
      "Train Epoch: 4705 [33024/118836 (28%)] Loss: 12256.416992\n",
      "Train Epoch: 4705 [65792/118836 (55%)] Loss: 12258.197266\n",
      "Train Epoch: 4705 [98560/118836 (83%)] Loss: 12254.607422\n",
      "    epoch          : 4705\n",
      "    loss           : 12174.394739486403\n",
      "    val_loss       : 12175.93124857613\n",
      "    val_log_likelihood: -12094.115126945047\n",
      "    val_log_marginal: -12103.18992999935\n",
      "Train Epoch: 4706 [256/118836 (0%)] Loss: 12140.167969\n",
      "Train Epoch: 4706 [33024/118836 (28%)] Loss: 12134.677734\n",
      "Train Epoch: 4706 [65792/118836 (55%)] Loss: 12238.857422\n",
      "Train Epoch: 4706 [98560/118836 (83%)] Loss: 12300.241211\n",
      "    epoch          : 4706\n",
      "    loss           : 12177.258378890094\n",
      "    val_loss       : 12174.952535228522\n",
      "    val_log_likelihood: -12093.680280061\n",
      "    val_log_marginal: -12102.735945649825\n",
      "Train Epoch: 4707 [256/118836 (0%)] Loss: 12160.259766\n",
      "Train Epoch: 4707 [33024/118836 (28%)] Loss: 12167.089844\n",
      "Train Epoch: 4707 [65792/118836 (55%)] Loss: 12132.831055\n",
      "Train Epoch: 4707 [98560/118836 (83%)] Loss: 12281.379883\n",
      "    epoch          : 4707\n",
      "    loss           : 12170.416371840107\n",
      "    val_loss       : 12171.350747261398\n",
      "    val_log_likelihood: -12091.766725955076\n",
      "    val_log_marginal: -12100.777322399585\n",
      "Train Epoch: 4708 [256/118836 (0%)] Loss: 12206.843750\n",
      "Train Epoch: 4708 [33024/118836 (28%)] Loss: 12163.105469\n",
      "Train Epoch: 4708 [65792/118836 (55%)] Loss: 12194.441406\n",
      "Train Epoch: 4708 [98560/118836 (83%)] Loss: 12177.998047\n",
      "    epoch          : 4708\n",
      "    loss           : 12173.041153587676\n",
      "    val_loss       : 12179.09003370515\n",
      "    val_log_likelihood: -12094.364868790064\n",
      "    val_log_marginal: -12103.37319875059\n",
      "Train Epoch: 4709 [256/118836 (0%)] Loss: 12127.560547\n",
      "Train Epoch: 4709 [33024/118836 (28%)] Loss: 12236.258789\n",
      "Train Epoch: 4709 [65792/118836 (55%)] Loss: 12263.340820\n",
      "Train Epoch: 4709 [98560/118836 (83%)] Loss: 12146.838867\n",
      "    epoch          : 4709\n",
      "    loss           : 12172.799969467276\n",
      "    val_loss       : 12175.631164823368\n",
      "    val_log_likelihood: -12094.261313585608\n",
      "    val_log_marginal: -12103.109243635065\n",
      "Train Epoch: 4710 [256/118836 (0%)] Loss: 12263.217773\n",
      "Train Epoch: 4710 [33024/118836 (28%)] Loss: 12120.744141\n",
      "Train Epoch: 4710 [65792/118836 (55%)] Loss: 12171.976562\n",
      "Train Epoch: 4710 [98560/118836 (83%)] Loss: 12348.935547\n",
      "    epoch          : 4710\n",
      "    loss           : 12169.616671997777\n",
      "    val_loss       : 12171.06021760945\n",
      "    val_log_likelihood: -12093.148941532258\n",
      "    val_log_marginal: -12102.144327160007\n",
      "Train Epoch: 4711 [256/118836 (0%)] Loss: 12170.158203\n",
      "Train Epoch: 4711 [33024/118836 (28%)] Loss: 12192.626953\n",
      "Train Epoch: 4711 [65792/118836 (55%)] Loss: 12166.357422\n",
      "Train Epoch: 4711 [98560/118836 (83%)] Loss: 12229.512695\n",
      "    epoch          : 4711\n",
      "    loss           : 12175.55739618874\n",
      "    val_loss       : 12171.643119802704\n",
      "    val_log_likelihood: -12096.028709806658\n",
      "    val_log_marginal: -12104.985437125319\n",
      "Train Epoch: 4712 [256/118836 (0%)] Loss: 12214.733398\n",
      "Train Epoch: 4712 [33024/118836 (28%)] Loss: 12128.706055\n",
      "Train Epoch: 4712 [65792/118836 (55%)] Loss: 12312.578125\n",
      "Train Epoch: 4712 [98560/118836 (83%)] Loss: 12282.232422\n",
      "    epoch          : 4712\n",
      "    loss           : 12176.546138822116\n",
      "    val_loss       : 12172.858155234218\n",
      "    val_log_likelihood: -12096.35312257677\n",
      "    val_log_marginal: -12105.34277857653\n",
      "Train Epoch: 4713 [256/118836 (0%)] Loss: 12243.934570\n",
      "Train Epoch: 4713 [33024/118836 (28%)] Loss: 12163.583984\n",
      "Train Epoch: 4713 [65792/118836 (55%)] Loss: 12206.416992\n",
      "Train Epoch: 4713 [98560/118836 (83%)] Loss: 12191.176758\n",
      "    epoch          : 4713\n",
      "    loss           : 12172.312425041357\n",
      "    val_loss       : 12183.923541756254\n",
      "    val_log_likelihood: -12096.008453848737\n",
      "    val_log_marginal: -12105.225100377313\n",
      "Train Epoch: 4714 [256/118836 (0%)] Loss: 12273.605469\n",
      "Train Epoch: 4714 [33024/118836 (28%)] Loss: 12189.100586\n",
      "Train Epoch: 4714 [65792/118836 (55%)] Loss: 12083.494141\n",
      "Train Epoch: 4714 [98560/118836 (83%)] Loss: 12156.511719\n",
      "    epoch          : 4714\n",
      "    loss           : 12176.151285766904\n",
      "    val_loss       : 12176.473447706398\n",
      "    val_log_likelihood: -12094.104961325216\n",
      "    val_log_marginal: -12103.26021854819\n",
      "Train Epoch: 4715 [256/118836 (0%)] Loss: 12223.597656\n",
      "Train Epoch: 4715 [33024/118836 (28%)] Loss: 12109.031250\n",
      "Train Epoch: 4715 [65792/118836 (55%)] Loss: 12263.980469\n",
      "Train Epoch: 4715 [98560/118836 (83%)] Loss: 12142.812500\n",
      "    epoch          : 4715\n",
      "    loss           : 12174.761006481338\n",
      "    val_loss       : 12175.810926649952\n",
      "    val_log_likelihood: -12091.84680908809\n",
      "    val_log_marginal: -12100.959361843408\n",
      "Train Epoch: 4716 [256/118836 (0%)] Loss: 12248.307617\n",
      "Train Epoch: 4716 [33024/118836 (28%)] Loss: 12248.345703\n",
      "Train Epoch: 4716 [65792/118836 (55%)] Loss: 12216.397461\n",
      "Train Epoch: 4716 [98560/118836 (83%)] Loss: 12257.881836\n",
      "    epoch          : 4716\n",
      "    loss           : 12173.415116767474\n",
      "    val_loss       : 12179.39603063748\n",
      "    val_log_likelihood: -12095.098030881667\n",
      "    val_log_marginal: -12104.199647222462\n",
      "Train Epoch: 4717 [256/118836 (0%)] Loss: 12369.680664\n",
      "Train Epoch: 4717 [33024/118836 (28%)] Loss: 12185.468750\n",
      "Train Epoch: 4717 [65792/118836 (55%)] Loss: 12234.316406\n",
      "Train Epoch: 4717 [98560/118836 (83%)] Loss: 12107.818359\n",
      "    epoch          : 4717\n",
      "    loss           : 12174.648856234491\n",
      "    val_loss       : 12179.101598991729\n",
      "    val_log_likelihood: -12093.274907917183\n",
      "    val_log_marginal: -12102.56842510245\n",
      "Train Epoch: 4718 [256/118836 (0%)] Loss: 12144.933594\n",
      "Train Epoch: 4718 [33024/118836 (28%)] Loss: 12263.427734\n",
      "Train Epoch: 4718 [65792/118836 (55%)] Loss: 12221.024414\n",
      "Train Epoch: 4718 [98560/118836 (83%)] Loss: 12241.276367\n",
      "    epoch          : 4718\n",
      "    loss           : 12175.43941516103\n",
      "    val_loss       : 12175.01731692299\n",
      "    val_log_likelihood: -12093.632762419871\n",
      "    val_log_marginal: -12102.723844674467\n",
      "Train Epoch: 4719 [256/118836 (0%)] Loss: 12211.432617\n",
      "Train Epoch: 4719 [33024/118836 (28%)] Loss: 12205.030273\n",
      "Train Epoch: 4719 [65792/118836 (55%)] Loss: 12132.007812\n",
      "Train Epoch: 4719 [98560/118836 (83%)] Loss: 12168.944336\n",
      "    epoch          : 4719\n",
      "    loss           : 12177.409770633012\n",
      "    val_loss       : 12170.877366726761\n",
      "    val_log_likelihood: -12092.72350082713\n",
      "    val_log_marginal: -12101.839322883592\n",
      "Train Epoch: 4720 [256/118836 (0%)] Loss: 12102.604492\n",
      "Train Epoch: 4720 [33024/118836 (28%)] Loss: 12165.994141\n",
      "Train Epoch: 4720 [65792/118836 (55%)] Loss: 12183.302734\n",
      "Train Epoch: 4720 [98560/118836 (83%)] Loss: 12270.818359\n",
      "    epoch          : 4720\n",
      "    loss           : 12171.82541098015\n",
      "    val_loss       : 12172.043966706406\n",
      "    val_log_likelihood: -12093.840068949028\n",
      "    val_log_marginal: -12102.865544886055\n",
      "Train Epoch: 4721 [256/118836 (0%)] Loss: 12278.409180\n",
      "Train Epoch: 4721 [33024/118836 (28%)] Loss: 12142.454102\n",
      "Train Epoch: 4721 [65792/118836 (55%)] Loss: 12166.976562\n",
      "Train Epoch: 4721 [98560/118836 (83%)] Loss: 12140.761719\n",
      "    epoch          : 4721\n",
      "    loss           : 12173.547274510183\n",
      "    val_loss       : 12173.613023633241\n",
      "    val_log_likelihood: -12094.857070183261\n",
      "    val_log_marginal: -12103.871969083513\n",
      "Train Epoch: 4722 [256/118836 (0%)] Loss: 12127.205078\n",
      "Train Epoch: 4722 [33024/118836 (28%)] Loss: 12130.090820\n",
      "Train Epoch: 4722 [65792/118836 (55%)] Loss: 12201.338867\n",
      "Train Epoch: 4722 [98560/118836 (83%)] Loss: 12178.000977\n",
      "    epoch          : 4722\n",
      "    loss           : 12179.545958695202\n",
      "    val_loss       : 12178.79333548961\n",
      "    val_log_likelihood: -12093.911037337159\n",
      "    val_log_marginal: -12102.962084006493\n",
      "Train Epoch: 4723 [256/118836 (0%)] Loss: 12241.466797\n",
      "Train Epoch: 4723 [33024/118836 (28%)] Loss: 12182.271484\n",
      "Train Epoch: 4723 [65792/118836 (55%)] Loss: 12254.242188\n",
      "Train Epoch: 4723 [98560/118836 (83%)] Loss: 12154.445312\n",
      "    epoch          : 4723\n",
      "    loss           : 12176.299098557693\n",
      "    val_loss       : 12174.027224037227\n",
      "    val_log_likelihood: -12092.278329197683\n",
      "    val_log_marginal: -12101.282912745364\n",
      "Train Epoch: 4724 [256/118836 (0%)] Loss: 12186.127930\n",
      "Train Epoch: 4724 [33024/118836 (28%)] Loss: 12126.321289\n",
      "Train Epoch: 4724 [65792/118836 (55%)] Loss: 12172.574219\n",
      "Train Epoch: 4724 [98560/118836 (83%)] Loss: 12170.459961\n",
      "    epoch          : 4724\n",
      "    loss           : 12175.37087420518\n",
      "    val_loss       : 12169.952872782327\n",
      "    val_log_likelihood: -12093.847495993588\n",
      "    val_log_marginal: -12102.754785063678\n",
      "Train Epoch: 4725 [256/118836 (0%)] Loss: 12277.623047\n",
      "Train Epoch: 4725 [33024/118836 (28%)] Loss: 12250.483398\n",
      "Train Epoch: 4725 [65792/118836 (55%)] Loss: 12218.091797\n",
      "Train Epoch: 4725 [98560/118836 (83%)] Loss: 12152.356445\n",
      "    epoch          : 4725\n",
      "    loss           : 12170.212850722446\n",
      "    val_loss       : 12173.551296053196\n",
      "    val_log_likelihood: -12093.280410269334\n",
      "    val_log_marginal: -12102.322817231887\n",
      "Train Epoch: 4726 [256/118836 (0%)] Loss: 12266.843750\n",
      "Train Epoch: 4726 [33024/118836 (28%)] Loss: 12153.625000\n",
      "Train Epoch: 4726 [65792/118836 (55%)] Loss: 12117.711914\n",
      "Train Epoch: 4726 [98560/118836 (83%)] Loss: 12198.434570\n",
      "    epoch          : 4726\n",
      "    loss           : 12172.600233761115\n",
      "    val_loss       : 12177.429433597388\n",
      "    val_log_likelihood: -12091.224736352357\n",
      "    val_log_marginal: -12100.146030614276\n",
      "Train Epoch: 4727 [256/118836 (0%)] Loss: 12182.869141\n",
      "Train Epoch: 4727 [33024/118836 (28%)] Loss: 12177.998047\n",
      "Train Epoch: 4727 [65792/118836 (55%)] Loss: 12188.394531\n",
      "Train Epoch: 4727 [98560/118836 (83%)] Loss: 12103.116211\n",
      "    epoch          : 4727\n",
      "    loss           : 12170.682307821546\n",
      "    val_loss       : 12171.659215432835\n",
      "    val_log_likelihood: -12095.666509156586\n",
      "    val_log_marginal: -12104.72375138653\n",
      "Train Epoch: 4728 [256/118836 (0%)] Loss: 12196.942383\n",
      "Train Epoch: 4728 [33024/118836 (28%)] Loss: 12348.085938\n",
      "Train Epoch: 4728 [65792/118836 (55%)] Loss: 12149.349609\n",
      "Train Epoch: 4728 [98560/118836 (83%)] Loss: 12204.834961\n",
      "    epoch          : 4728\n",
      "    loss           : 12174.583987605976\n",
      "    val_loss       : 12179.23775506515\n",
      "    val_log_likelihood: -12093.276998358664\n",
      "    val_log_marginal: -12102.28429235829\n",
      "Train Epoch: 4729 [256/118836 (0%)] Loss: 12331.250000\n",
      "Train Epoch: 4729 [33024/118836 (28%)] Loss: 12171.483398\n",
      "Train Epoch: 4729 [65792/118836 (55%)] Loss: 12166.958984\n",
      "Train Epoch: 4729 [98560/118836 (83%)] Loss: 12307.809570\n",
      "    epoch          : 4729\n",
      "    loss           : 12176.215140838243\n",
      "    val_loss       : 12174.41606268275\n",
      "    val_log_likelihood: -12094.937164947787\n",
      "    val_log_marginal: -12104.10922493492\n",
      "Train Epoch: 4730 [256/118836 (0%)] Loss: 12178.980469\n",
      "Train Epoch: 4730 [33024/118836 (28%)] Loss: 12251.400391\n",
      "Train Epoch: 4730 [65792/118836 (55%)] Loss: 12167.858398\n",
      "Train Epoch: 4730 [98560/118836 (83%)] Loss: 12297.921875\n",
      "    epoch          : 4730\n",
      "    loss           : 12175.987959606338\n",
      "    val_loss       : 12170.999558926027\n",
      "    val_log_likelihood: -12092.167534345273\n",
      "    val_log_marginal: -12101.357657101777\n",
      "Train Epoch: 4731 [256/118836 (0%)] Loss: 12216.866211\n",
      "Train Epoch: 4731 [33024/118836 (28%)] Loss: 12152.835938\n",
      "Train Epoch: 4731 [65792/118836 (55%)] Loss: 12297.587891\n",
      "Train Epoch: 4731 [98560/118836 (83%)] Loss: 12275.348633\n",
      "    epoch          : 4731\n",
      "    loss           : 12170.820234956576\n",
      "    val_loss       : 12177.9576138403\n",
      "    val_log_likelihood: -12094.22411374328\n",
      "    val_log_marginal: -12103.280917674632\n",
      "Train Epoch: 4732 [256/118836 (0%)] Loss: 12247.841797\n",
      "Train Epoch: 4732 [33024/118836 (28%)] Loss: 12248.437500\n",
      "Train Epoch: 4732 [65792/118836 (55%)] Loss: 12152.483398\n",
      "Train Epoch: 4732 [98560/118836 (83%)] Loss: 12130.177734\n",
      "    epoch          : 4732\n",
      "    loss           : 12175.100077220326\n",
      "    val_loss       : 12172.198062328149\n",
      "    val_log_likelihood: -12093.600927936312\n",
      "    val_log_marginal: -12102.629323406956\n",
      "Train Epoch: 4733 [256/118836 (0%)] Loss: 12145.765625\n",
      "Train Epoch: 4733 [33024/118836 (28%)] Loss: 12168.208984\n",
      "Train Epoch: 4733 [65792/118836 (55%)] Loss: 12176.190430\n",
      "Train Epoch: 4733 [98560/118836 (83%)] Loss: 12159.232422\n",
      "    epoch          : 4733\n",
      "    loss           : 12171.139346179694\n",
      "    val_loss       : 12176.28104095159\n",
      "    val_log_likelihood: -12092.753460213762\n",
      "    val_log_marginal: -12101.753326776881\n",
      "Train Epoch: 4734 [256/118836 (0%)] Loss: 12189.699219\n",
      "Train Epoch: 4734 [33024/118836 (28%)] Loss: 12149.828125\n",
      "Train Epoch: 4734 [65792/118836 (55%)] Loss: 12148.574219\n",
      "Train Epoch: 4734 [98560/118836 (83%)] Loss: 12157.965820\n",
      "    epoch          : 4734\n",
      "    loss           : 12174.36618686673\n",
      "    val_loss       : 12172.872716193075\n",
      "    val_log_likelihood: -12092.151721140923\n",
      "    val_log_marginal: -12101.096000862026\n",
      "Train Epoch: 4735 [256/118836 (0%)] Loss: 12160.066406\n",
      "Train Epoch: 4735 [33024/118836 (28%)] Loss: 12220.462891\n",
      "Train Epoch: 4735 [65792/118836 (55%)] Loss: 12093.271484\n",
      "Train Epoch: 4735 [98560/118836 (83%)] Loss: 12163.610352\n",
      "    epoch          : 4735\n",
      "    loss           : 12173.185731363732\n",
      "    val_loss       : 12176.173675463391\n",
      "    val_log_likelihood: -12094.768959851892\n",
      "    val_log_marginal: -12103.80140551996\n",
      "Train Epoch: 4736 [256/118836 (0%)] Loss: 12200.585938\n",
      "Train Epoch: 4736 [33024/118836 (28%)] Loss: 12227.212891\n",
      "Train Epoch: 4736 [65792/118836 (55%)] Loss: 12251.356445\n",
      "Train Epoch: 4736 [98560/118836 (83%)] Loss: 12190.185547\n",
      "    epoch          : 4736\n",
      "    loss           : 12175.259540264422\n",
      "    val_loss       : 12179.53052882923\n",
      "    val_log_likelihood: -12095.128979593155\n",
      "    val_log_marginal: -12104.190203559643\n",
      "Train Epoch: 4737 [256/118836 (0%)] Loss: 12268.476562\n",
      "Train Epoch: 4737 [33024/118836 (28%)] Loss: 12213.064453\n",
      "Train Epoch: 4737 [65792/118836 (55%)] Loss: 12174.808594\n",
      "Train Epoch: 4737 [98560/118836 (83%)] Loss: 12174.054688\n",
      "    epoch          : 4737\n",
      "    loss           : 12177.797189212419\n",
      "    val_loss       : 12180.211671907218\n",
      "    val_log_likelihood: -12092.199133290685\n",
      "    val_log_marginal: -12101.374075700542\n",
      "Train Epoch: 4738 [256/118836 (0%)] Loss: 12251.104492\n",
      "Train Epoch: 4738 [33024/118836 (28%)] Loss: 12249.119141\n",
      "Train Epoch: 4738 [65792/118836 (55%)] Loss: 12262.680664\n",
      "Train Epoch: 4738 [98560/118836 (83%)] Loss: 12076.043945\n",
      "    epoch          : 4738\n",
      "    loss           : 12177.623184837676\n",
      "    val_loss       : 12168.941227835932\n",
      "    val_log_likelihood: -12095.542277159584\n",
      "    val_log_marginal: -12104.704115838935\n",
      "Train Epoch: 4739 [256/118836 (0%)] Loss: 12136.005859\n",
      "Train Epoch: 4739 [33024/118836 (28%)] Loss: 12189.914062\n",
      "Train Epoch: 4739 [65792/118836 (55%)] Loss: 12209.773438\n",
      "Train Epoch: 4739 [98560/118836 (83%)] Loss: 12239.470703\n",
      "    epoch          : 4739\n",
      "    loss           : 12171.988268326097\n",
      "    val_loss       : 12172.784611209485\n",
      "    val_log_likelihood: -12093.290266038566\n",
      "    val_log_marginal: -12102.192767542336\n",
      "Train Epoch: 4740 [256/118836 (0%)] Loss: 12172.288086\n",
      "Train Epoch: 4740 [33024/118836 (28%)] Loss: 12193.625977\n",
      "Train Epoch: 4740 [65792/118836 (55%)] Loss: 12041.785156\n",
      "Train Epoch: 4740 [98560/118836 (83%)] Loss: 12210.667969\n",
      "    epoch          : 4740\n",
      "    loss           : 12171.0476900137\n",
      "    val_loss       : 12174.106275343254\n",
      "    val_log_likelihood: -12092.555570202647\n",
      "    val_log_marginal: -12101.501847575979\n",
      "Train Epoch: 4741 [256/118836 (0%)] Loss: 12146.377930\n",
      "Train Epoch: 4741 [33024/118836 (28%)] Loss: 12160.164062\n",
      "Train Epoch: 4741 [65792/118836 (55%)] Loss: 12119.457031\n",
      "Train Epoch: 4741 [98560/118836 (83%)] Loss: 12169.917969\n",
      "    epoch          : 4741\n",
      "    loss           : 12175.93603701406\n",
      "    val_loss       : 12169.23044856866\n",
      "    val_log_likelihood: -12091.06025043295\n",
      "    val_log_marginal: -12099.94741760757\n",
      "Train Epoch: 4742 [256/118836 (0%)] Loss: 12171.025391\n",
      "Train Epoch: 4742 [33024/118836 (28%)] Loss: 12290.748047\n",
      "Train Epoch: 4742 [65792/118836 (55%)] Loss: 12183.712891\n",
      "Train Epoch: 4742 [98560/118836 (83%)] Loss: 12256.152344\n",
      "    epoch          : 4742\n",
      "    loss           : 12173.01928327259\n",
      "    val_loss       : 12169.079976429342\n",
      "    val_log_likelihood: -12093.782968071495\n",
      "    val_log_marginal: -12102.720438295764\n",
      "Train Epoch: 4743 [256/118836 (0%)] Loss: 12190.860352\n",
      "Train Epoch: 4743 [33024/118836 (28%)] Loss: 12217.043945\n",
      "Train Epoch: 4743 [65792/118836 (55%)] Loss: 12229.790039\n",
      "Train Epoch: 4743 [98560/118836 (83%)] Loss: 12216.577148\n",
      "    epoch          : 4743\n",
      "    loss           : 12171.334637193704\n",
      "    val_loss       : 12173.527799361838\n",
      "    val_log_likelihood: -12093.7449824558\n",
      "    val_log_marginal: -12102.525208594137\n",
      "Train Epoch: 4744 [256/118836 (0%)] Loss: 12218.945312\n",
      "Train Epoch: 4744 [33024/118836 (28%)] Loss: 12279.612305\n",
      "Train Epoch: 4744 [65792/118836 (55%)] Loss: 12122.693359\n",
      "Train Epoch: 4744 [98560/118836 (83%)] Loss: 12136.543945\n",
      "    epoch          : 4744\n",
      "    loss           : 12173.429468601375\n",
      "    val_loss       : 12179.79879748968\n",
      "    val_log_likelihood: -12089.014395936725\n",
      "    val_log_marginal: -12097.912538469745\n",
      "Train Epoch: 4745 [256/118836 (0%)] Loss: 12159.301758\n",
      "Train Epoch: 4745 [33024/118836 (28%)] Loss: 12229.003906\n",
      "Train Epoch: 4745 [65792/118836 (55%)] Loss: 12243.634766\n",
      "Train Epoch: 4745 [98560/118836 (83%)] Loss: 12199.429688\n",
      "    epoch          : 4745\n",
      "    loss           : 12173.550434404726\n",
      "    val_loss       : 12173.378245980999\n",
      "    val_log_likelihood: -12089.763709192774\n",
      "    val_log_marginal: -12098.72603364885\n",
      "Train Epoch: 4746 [256/118836 (0%)] Loss: 12109.259766\n",
      "Train Epoch: 4746 [33024/118836 (28%)] Loss: 12220.414062\n",
      "Train Epoch: 4746 [65792/118836 (55%)] Loss: 12199.789062\n",
      "Train Epoch: 4746 [98560/118836 (83%)] Loss: 12216.117188\n",
      "    epoch          : 4746\n",
      "    loss           : 12171.934137200165\n",
      "    val_loss       : 12173.483218255378\n",
      "    val_log_likelihood: -12093.868410747518\n",
      "    val_log_marginal: -12102.782879372735\n",
      "Train Epoch: 4747 [256/118836 (0%)] Loss: 12125.512695\n",
      "Train Epoch: 4747 [33024/118836 (28%)] Loss: 12164.919922\n",
      "Train Epoch: 4747 [65792/118836 (55%)] Loss: 12208.933594\n",
      "Train Epoch: 4747 [98560/118836 (83%)] Loss: 12159.744141\n",
      "    epoch          : 4747\n",
      "    loss           : 12177.216891865695\n",
      "    val_loss       : 12175.057365385697\n",
      "    val_log_likelihood: -12092.534918773263\n",
      "    val_log_marginal: -12101.42775476005\n",
      "Train Epoch: 4748 [256/118836 (0%)] Loss: 12180.635742\n",
      "Train Epoch: 4748 [33024/118836 (28%)] Loss: 12177.066406\n",
      "Train Epoch: 4748 [65792/118836 (55%)] Loss: 12088.292969\n",
      "Train Epoch: 4748 [98560/118836 (83%)] Loss: 12198.093750\n",
      "    epoch          : 4748\n",
      "    loss           : 12174.2803542119\n",
      "    val_loss       : 12176.193685499271\n",
      "    val_log_likelihood: -12094.098612134252\n",
      "    val_log_marginal: -12103.13767406444\n",
      "Train Epoch: 4749 [256/118836 (0%)] Loss: 12254.741211\n",
      "Train Epoch: 4749 [33024/118836 (28%)] Loss: 12136.270508\n",
      "Train Epoch: 4749 [65792/118836 (55%)] Loss: 12266.046875\n",
      "Train Epoch: 4749 [98560/118836 (83%)] Loss: 12153.404297\n",
      "    epoch          : 4749\n",
      "    loss           : 12173.698017796216\n",
      "    val_loss       : 12172.530775652034\n",
      "    val_log_likelihood: -12093.594702653278\n",
      "    val_log_marginal: -12102.674449469867\n",
      "Train Epoch: 4750 [256/118836 (0%)] Loss: 12216.552734\n",
      "Train Epoch: 4750 [33024/118836 (28%)] Loss: 12218.017578\n",
      "Train Epoch: 4750 [65792/118836 (55%)] Loss: 12246.219727\n",
      "Train Epoch: 4750 [98560/118836 (83%)] Loss: 12192.671875\n",
      "    epoch          : 4750\n",
      "    loss           : 12170.908460795337\n",
      "    val_loss       : 12173.286009675783\n",
      "    val_log_likelihood: -12091.712766393974\n",
      "    val_log_marginal: -12100.760943146746\n",
      "Train Epoch: 4751 [256/118836 (0%)] Loss: 12135.825195\n",
      "Train Epoch: 4751 [33024/118836 (28%)] Loss: 12174.289062\n",
      "Train Epoch: 4751 [65792/118836 (55%)] Loss: 12230.632812\n",
      "Train Epoch: 4751 [98560/118836 (83%)] Loss: 12176.250000\n",
      "    epoch          : 4751\n",
      "    loss           : 12175.69998788384\n",
      "    val_loss       : 12174.375868824305\n",
      "    val_log_likelihood: -12093.751157497156\n",
      "    val_log_marginal: -12102.74607926484\n",
      "Train Epoch: 4752 [256/118836 (0%)] Loss: 12145.213867\n",
      "Train Epoch: 4752 [33024/118836 (28%)] Loss: 12157.416992\n",
      "Train Epoch: 4752 [65792/118836 (55%)] Loss: 12148.511719\n",
      "Train Epoch: 4752 [98560/118836 (83%)] Loss: 12181.308594\n",
      "    epoch          : 4752\n",
      "    loss           : 12172.991914482527\n",
      "    val_loss       : 12173.687607262458\n",
      "    val_log_likelihood: -12094.155770846259\n",
      "    val_log_marginal: -12103.309322281488\n",
      "Train Epoch: 4753 [256/118836 (0%)] Loss: 12133.453125\n",
      "Train Epoch: 4753 [33024/118836 (28%)] Loss: 12217.773438\n",
      "Train Epoch: 4753 [65792/118836 (55%)] Loss: 12215.018555\n",
      "Train Epoch: 4753 [98560/118836 (83%)] Loss: 12121.527344\n",
      "    epoch          : 4753\n",
      "    loss           : 12173.770202162168\n",
      "    val_loss       : 12172.81982091924\n",
      "    val_log_likelihood: -12095.43136437655\n",
      "    val_log_marginal: -12104.379583932296\n",
      "Train Epoch: 4754 [256/118836 (0%)] Loss: 12332.769531\n",
      "Train Epoch: 4754 [33024/118836 (28%)] Loss: 12174.548828\n",
      "Train Epoch: 4754 [65792/118836 (55%)] Loss: 12226.347656\n",
      "Train Epoch: 4754 [98560/118836 (83%)] Loss: 12174.782227\n",
      "    epoch          : 4754\n",
      "    loss           : 12173.150771233974\n",
      "    val_loss       : 12176.134853208925\n",
      "    val_log_likelihood: -12096.513554105924\n",
      "    val_log_marginal: -12105.553576250504\n",
      "Train Epoch: 4755 [256/118836 (0%)] Loss: 12182.864258\n",
      "Train Epoch: 4755 [33024/118836 (28%)] Loss: 12142.763672\n",
      "Train Epoch: 4755 [65792/118836 (55%)] Loss: 12203.085938\n",
      "Train Epoch: 4755 [98560/118836 (83%)] Loss: 12162.271484\n",
      "    epoch          : 4755\n",
      "    loss           : 12177.391795744157\n",
      "    val_loss       : 12171.607139827822\n",
      "    val_log_likelihood: -12095.109657064206\n",
      "    val_log_marginal: -12104.247307387319\n",
      "Train Epoch: 4756 [256/118836 (0%)] Loss: 12130.252930\n",
      "Train Epoch: 4756 [33024/118836 (28%)] Loss: 12283.212891\n",
      "Train Epoch: 4756 [65792/118836 (55%)] Loss: 12193.230469\n",
      "Train Epoch: 4756 [98560/118836 (83%)] Loss: 12173.292969\n",
      "    epoch          : 4756\n",
      "    loss           : 12173.558074370605\n",
      "    val_loss       : 12170.710414581778\n",
      "    val_log_likelihood: -12094.214281398625\n",
      "    val_log_marginal: -12103.146683949206\n",
      "Train Epoch: 4757 [256/118836 (0%)] Loss: 12096.349609\n",
      "Train Epoch: 4757 [33024/118836 (28%)] Loss: 12087.196289\n",
      "Train Epoch: 4757 [65792/118836 (55%)] Loss: 12264.015625\n",
      "Train Epoch: 4757 [98560/118836 (83%)] Loss: 12198.478516\n",
      "    epoch          : 4757\n",
      "    loss           : 12171.782460000517\n",
      "    val_loss       : 12173.9111503286\n",
      "    val_log_likelihood: -12090.77077194479\n",
      "    val_log_marginal: -12099.66163822152\n",
      "Train Epoch: 4758 [256/118836 (0%)] Loss: 12212.049805\n",
      "Train Epoch: 4758 [33024/118836 (28%)] Loss: 12157.427734\n",
      "Train Epoch: 4758 [65792/118836 (55%)] Loss: 12184.854492\n",
      "Train Epoch: 4758 [98560/118836 (83%)] Loss: 12130.521484\n",
      "    epoch          : 4758\n",
      "    loss           : 12172.343164870243\n",
      "    val_loss       : 12173.087412169507\n",
      "    val_log_likelihood: -12091.954751957972\n",
      "    val_log_marginal: -12100.921693420847\n",
      "Train Epoch: 4759 [256/118836 (0%)] Loss: 12402.737305\n",
      "Train Epoch: 4759 [33024/118836 (28%)] Loss: 12151.048828\n",
      "Train Epoch: 4759 [65792/118836 (55%)] Loss: 12176.084961\n",
      "Train Epoch: 4759 [98560/118836 (83%)] Loss: 12227.093750\n",
      "    epoch          : 4759\n",
      "    loss           : 12173.589504335969\n",
      "    val_loss       : 12175.245558653362\n",
      "    val_log_likelihood: -12094.430535954301\n",
      "    val_log_marginal: -12103.40343336064\n",
      "Train Epoch: 4760 [256/118836 (0%)] Loss: 12247.583984\n",
      "Train Epoch: 4760 [33024/118836 (28%)] Loss: 12239.505859\n",
      "Train Epoch: 4760 [65792/118836 (55%)] Loss: 12167.883789\n",
      "Train Epoch: 4760 [98560/118836 (83%)] Loss: 12205.367188\n",
      "    epoch          : 4760\n",
      "    loss           : 12174.715133568548\n",
      "    val_loss       : 12173.790373445472\n",
      "    val_log_likelihood: -12091.8653893003\n",
      "    val_log_marginal: -12100.810672724108\n",
      "Train Epoch: 4761 [256/118836 (0%)] Loss: 12086.288086\n",
      "Train Epoch: 4761 [33024/118836 (28%)] Loss: 12148.940430\n",
      "Train Epoch: 4761 [65792/118836 (55%)] Loss: 12097.561523\n",
      "Train Epoch: 4761 [98560/118836 (83%)] Loss: 12169.628906\n",
      "    epoch          : 4761\n",
      "    loss           : 12176.149641038566\n",
      "    val_loss       : 12172.789270372192\n",
      "    val_log_likelihood: -12092.43727350858\n",
      "    val_log_marginal: -12101.405203087668\n",
      "Train Epoch: 4762 [256/118836 (0%)] Loss: 12173.003906\n",
      "Train Epoch: 4762 [33024/118836 (28%)] Loss: 12217.429688\n",
      "Train Epoch: 4762 [65792/118836 (55%)] Loss: 12181.757812\n",
      "Train Epoch: 4762 [98560/118836 (83%)] Loss: 12152.556641\n",
      "    epoch          : 4762\n",
      "    loss           : 12172.975695144489\n",
      "    val_loss       : 12174.70294671537\n",
      "    val_log_likelihood: -12095.098467063432\n",
      "    val_log_marginal: -12104.190660859202\n",
      "Train Epoch: 4763 [256/118836 (0%)] Loss: 12125.785156\n",
      "Train Epoch: 4763 [33024/118836 (28%)] Loss: 12164.853516\n",
      "Train Epoch: 4763 [65792/118836 (55%)] Loss: 12135.958984\n",
      "Train Epoch: 4763 [98560/118836 (83%)] Loss: 12097.612305\n",
      "    epoch          : 4763\n",
      "    loss           : 12171.622206821237\n",
      "    val_loss       : 12176.35643269751\n",
      "    val_log_likelihood: -12095.076086415685\n",
      "    val_log_marginal: -12104.197985458728\n",
      "Train Epoch: 4764 [256/118836 (0%)] Loss: 12273.134766\n",
      "Train Epoch: 4764 [33024/118836 (28%)] Loss: 12123.886719\n",
      "Train Epoch: 4764 [65792/118836 (55%)] Loss: 12261.308594\n",
      "Train Epoch: 4764 [98560/118836 (83%)] Loss: 12236.208984\n",
      "    epoch          : 4764\n",
      "    loss           : 12174.894365500932\n",
      "    val_loss       : 12180.25778761669\n",
      "    val_log_likelihood: -12092.438321314103\n",
      "    val_log_marginal: -12101.56629845655\n",
      "Train Epoch: 4765 [256/118836 (0%)] Loss: 12278.987305\n",
      "Train Epoch: 4765 [33024/118836 (28%)] Loss: 12313.394531\n",
      "Train Epoch: 4765 [65792/118836 (55%)] Loss: 12193.174805\n",
      "Train Epoch: 4765 [98560/118836 (83%)] Loss: 12180.848633\n",
      "    epoch          : 4765\n",
      "    loss           : 12172.738904020627\n",
      "    val_loss       : 12173.938279255675\n",
      "    val_log_likelihood: -12093.009879355355\n",
      "    val_log_marginal: -12101.99701606894\n",
      "Train Epoch: 4766 [256/118836 (0%)] Loss: 12122.240234\n",
      "Train Epoch: 4766 [33024/118836 (28%)] Loss: 12159.884766\n",
      "Train Epoch: 4766 [65792/118836 (55%)] Loss: 12249.636719\n",
      "Train Epoch: 4766 [98560/118836 (83%)] Loss: 12248.573242\n",
      "    epoch          : 4766\n",
      "    loss           : 12172.699033291976\n",
      "    val_loss       : 12173.436964239225\n",
      "    val_log_likelihood: -12095.230886999843\n",
      "    val_log_marginal: -12104.182966640275\n",
      "Train Epoch: 4767 [256/118836 (0%)] Loss: 12153.705078\n",
      "Train Epoch: 4767 [33024/118836 (28%)] Loss: 12212.420898\n",
      "Train Epoch: 4767 [65792/118836 (55%)] Loss: 12132.001953\n",
      "Train Epoch: 4767 [98560/118836 (83%)] Loss: 12267.039062\n",
      "    epoch          : 4767\n",
      "    loss           : 12174.487314218879\n",
      "    val_loss       : 12170.778421472482\n",
      "    val_log_likelihood: -12093.752370082455\n",
      "    val_log_marginal: -12102.6061082703\n",
      "Train Epoch: 4768 [256/118836 (0%)] Loss: 12318.982422\n",
      "Train Epoch: 4768 [33024/118836 (28%)] Loss: 12148.750000\n",
      "Train Epoch: 4768 [65792/118836 (55%)] Loss: 12102.221680\n",
      "Train Epoch: 4768 [98560/118836 (83%)] Loss: 12258.625977\n",
      "    epoch          : 4768\n",
      "    loss           : 12176.540692688948\n",
      "    val_loss       : 12172.902404523064\n",
      "    val_log_likelihood: -12096.680800732785\n",
      "    val_log_marginal: -12105.65153059193\n",
      "Train Epoch: 4769 [256/118836 (0%)] Loss: 12234.014648\n",
      "Train Epoch: 4769 [33024/118836 (28%)] Loss: 12156.631836\n",
      "Train Epoch: 4769 [65792/118836 (55%)] Loss: 12193.139648\n",
      "Train Epoch: 4769 [98560/118836 (83%)] Loss: 12226.332031\n",
      "    epoch          : 4769\n",
      "    loss           : 12179.460976756358\n",
      "    val_loss       : 12181.048653337455\n",
      "    val_log_likelihood: -12091.016608186\n",
      "    val_log_marginal: -12100.1129816267\n",
      "Train Epoch: 4770 [256/118836 (0%)] Loss: 12155.962891\n",
      "Train Epoch: 4770 [33024/118836 (28%)] Loss: 12223.506836\n",
      "Train Epoch: 4770 [65792/118836 (55%)] Loss: 12235.191406\n",
      "Train Epoch: 4770 [98560/118836 (83%)] Loss: 12250.877930\n",
      "    epoch          : 4770\n",
      "    loss           : 12176.915421448512\n",
      "    val_loss       : 12174.81975824413\n",
      "    val_log_likelihood: -12096.480283453526\n",
      "    val_log_marginal: -12105.457188556404\n",
      "Train Epoch: 4771 [256/118836 (0%)] Loss: 12151.974609\n",
      "Train Epoch: 4771 [33024/118836 (28%)] Loss: 12253.152344\n",
      "Train Epoch: 4771 [65792/118836 (55%)] Loss: 12184.070312\n",
      "Train Epoch: 4771 [98560/118836 (83%)] Loss: 12243.641602\n",
      "    epoch          : 4771\n",
      "    loss           : 12177.984749147021\n",
      "    val_loss       : 12176.369409951712\n",
      "    val_log_likelihood: -12095.237289986559\n",
      "    val_log_marginal: -12104.359695739384\n",
      "Train Epoch: 4772 [256/118836 (0%)] Loss: 12176.566406\n",
      "Train Epoch: 4772 [33024/118836 (28%)] Loss: 12216.729492\n",
      "Train Epoch: 4772 [65792/118836 (55%)] Loss: 12137.813477\n",
      "Train Epoch: 4772 [98560/118836 (83%)] Loss: 12235.947266\n",
      "    epoch          : 4772\n",
      "    loss           : 12173.937015676695\n",
      "    val_loss       : 12176.92121473841\n",
      "    val_log_likelihood: -12093.09925671397\n",
      "    val_log_marginal: -12102.101742130628\n",
      "Train Epoch: 4773 [256/118836 (0%)] Loss: 12111.113281\n",
      "Train Epoch: 4773 [33024/118836 (28%)] Loss: 12318.429688\n",
      "Train Epoch: 4773 [65792/118836 (55%)] Loss: 12201.265625\n",
      "Train Epoch: 4773 [98560/118836 (83%)] Loss: 12214.655273\n",
      "    epoch          : 4773\n",
      "    loss           : 12169.601494972601\n",
      "    val_loss       : 12174.843208704964\n",
      "    val_log_likelihood: -12093.468441926438\n",
      "    val_log_marginal: -12102.408518938766\n",
      "Train Epoch: 4774 [256/118836 (0%)] Loss: 12140.833984\n",
      "Train Epoch: 4774 [33024/118836 (28%)] Loss: 12139.648438\n",
      "Train Epoch: 4774 [65792/118836 (55%)] Loss: 12228.568359\n",
      "Train Epoch: 4774 [98560/118836 (83%)] Loss: 12111.831055\n",
      "    epoch          : 4774\n",
      "    loss           : 12171.339398359956\n",
      "    val_loss       : 12175.271537137825\n",
      "    val_log_likelihood: -12094.883500213244\n",
      "    val_log_marginal: -12103.758450097366\n",
      "Train Epoch: 4775 [256/118836 (0%)] Loss: 12126.691406\n",
      "Train Epoch: 4775 [33024/118836 (28%)] Loss: 12203.721680\n",
      "Train Epoch: 4775 [65792/118836 (55%)] Loss: 12139.029297\n",
      "Train Epoch: 4775 [98560/118836 (83%)] Loss: 12143.530273\n",
      "    epoch          : 4775\n",
      "    loss           : 12174.76738830516\n",
      "    val_loss       : 12172.613067181625\n",
      "    val_log_likelihood: -12092.32226304022\n",
      "    val_log_marginal: -12101.286570217795\n",
      "Train Epoch: 4776 [256/118836 (0%)] Loss: 12342.946289\n",
      "Train Epoch: 4776 [33024/118836 (28%)] Loss: 12285.000977\n",
      "Train Epoch: 4776 [65792/118836 (55%)] Loss: 12207.443359\n",
      "Train Epoch: 4776 [98560/118836 (83%)] Loss: 12337.712891\n",
      "    epoch          : 4776\n",
      "    loss           : 12170.492041459884\n",
      "    val_loss       : 12177.471886093706\n",
      "    val_log_likelihood: -12092.71919845947\n",
      "    val_log_marginal: -12101.605211258173\n",
      "Train Epoch: 4777 [256/118836 (0%)] Loss: 12244.523438\n",
      "Train Epoch: 4777 [33024/118836 (28%)] Loss: 12166.465820\n",
      "Train Epoch: 4777 [65792/118836 (55%)] Loss: 12181.062500\n",
      "Train Epoch: 4777 [98560/118836 (83%)] Loss: 12166.143555\n",
      "    epoch          : 4777\n",
      "    loss           : 12176.63926314361\n",
      "    val_loss       : 12172.292350428575\n",
      "    val_log_likelihood: -12094.663185290014\n",
      "    val_log_marginal: -12103.529746421582\n",
      "Train Epoch: 4778 [256/118836 (0%)] Loss: 12141.869141\n",
      "Train Epoch: 4778 [33024/118836 (28%)] Loss: 12205.062500\n",
      "Train Epoch: 4778 [65792/118836 (55%)] Loss: 12356.644531\n",
      "Train Epoch: 4778 [98560/118836 (83%)] Loss: 12164.185547\n",
      "    epoch          : 4778\n",
      "    loss           : 12176.528553265869\n",
      "    val_loss       : 12173.719663272168\n",
      "    val_log_likelihood: -12093.266739848274\n",
      "    val_log_marginal: -12102.226907774251\n",
      "Train Epoch: 4779 [256/118836 (0%)] Loss: 12168.879883\n",
      "Train Epoch: 4779 [33024/118836 (28%)] Loss: 12209.099609\n",
      "Train Epoch: 4779 [65792/118836 (55%)] Loss: 12251.946289\n",
      "Train Epoch: 4779 [98560/118836 (83%)] Loss: 12203.755859\n",
      "    epoch          : 4779\n",
      "    loss           : 12175.369459360783\n",
      "    val_loss       : 12177.056914406647\n",
      "    val_log_likelihood: -12091.858541569736\n",
      "    val_log_marginal: -12100.880275838757\n",
      "Train Epoch: 4780 [256/118836 (0%)] Loss: 12184.535156\n",
      "Train Epoch: 4780 [33024/118836 (28%)] Loss: 12140.306641\n",
      "Train Epoch: 4780 [65792/118836 (55%)] Loss: 12068.720703\n",
      "Train Epoch: 4780 [98560/118836 (83%)] Loss: 12141.242188\n",
      "    epoch          : 4780\n",
      "    loss           : 12175.918991677006\n",
      "    val_loss       : 12177.504813504072\n",
      "    val_log_likelihood: -12093.466174265923\n",
      "    val_log_marginal: -12102.514998649998\n",
      "Train Epoch: 4781 [256/118836 (0%)] Loss: 12135.512695\n",
      "Train Epoch: 4781 [33024/118836 (28%)] Loss: 12207.660156\n",
      "Train Epoch: 4781 [65792/118836 (55%)] Loss: 12151.086914\n",
      "Train Epoch: 4781 [98560/118836 (83%)] Loss: 12195.313477\n",
      "    epoch          : 4781\n",
      "    loss           : 12171.565398993227\n",
      "    val_loss       : 12175.769529909114\n",
      "    val_log_likelihood: -12094.90251321469\n",
      "    val_log_marginal: -12103.978877911562\n",
      "Train Epoch: 4782 [256/118836 (0%)] Loss: 12159.091797\n",
      "Train Epoch: 4782 [33024/118836 (28%)] Loss: 12271.863281\n",
      "Train Epoch: 4782 [65792/118836 (55%)] Loss: 12216.365234\n",
      "Train Epoch: 4782 [98560/118836 (83%)] Loss: 12163.713867\n",
      "    epoch          : 4782\n",
      "    loss           : 12168.578223706318\n",
      "    val_loss       : 12178.692577275657\n",
      "    val_log_likelihood: -12098.846592128051\n",
      "    val_log_marginal: -12108.01221910446\n",
      "Train Epoch: 4783 [256/118836 (0%)] Loss: 12184.220703\n",
      "Train Epoch: 4783 [33024/118836 (28%)] Loss: 12118.443359\n",
      "Train Epoch: 4783 [65792/118836 (55%)] Loss: 12251.973633\n",
      "Train Epoch: 4783 [98560/118836 (83%)] Loss: 12248.910156\n",
      "    epoch          : 4783\n",
      "    loss           : 12170.570424776417\n",
      "    val_loss       : 12178.358811657716\n",
      "    val_log_likelihood: -12095.460562545233\n",
      "    val_log_marginal: -12104.489448417698\n",
      "Train Epoch: 4784 [256/118836 (0%)] Loss: 12203.388672\n",
      "Train Epoch: 4784 [33024/118836 (28%)] Loss: 12199.654297\n",
      "Train Epoch: 4784 [65792/118836 (55%)] Loss: 12145.007812\n",
      "Train Epoch: 4784 [98560/118836 (83%)] Loss: 12250.406250\n",
      "    epoch          : 4784\n",
      "    loss           : 12174.192640967483\n",
      "    val_loss       : 12175.124890847068\n",
      "    val_log_likelihood: -12093.437169632702\n",
      "    val_log_marginal: -12102.423188817957\n",
      "Train Epoch: 4785 [256/118836 (0%)] Loss: 12171.139648\n",
      "Train Epoch: 4785 [33024/118836 (28%)] Loss: 12244.343750\n",
      "Train Epoch: 4785 [65792/118836 (55%)] Loss: 12169.440430\n",
      "Train Epoch: 4785 [98560/118836 (83%)] Loss: 12150.695312\n",
      "    epoch          : 4785\n",
      "    loss           : 12174.390764416614\n",
      "    val_loss       : 12173.997943101967\n",
      "    val_log_likelihood: -12096.589727596413\n",
      "    val_log_marginal: -12105.50469896004\n",
      "Train Epoch: 4786 [256/118836 (0%)] Loss: 12258.692383\n",
      "Train Epoch: 4786 [33024/118836 (28%)] Loss: 12213.224609\n",
      "Train Epoch: 4786 [65792/118836 (55%)] Loss: 12258.235352\n",
      "Train Epoch: 4786 [98560/118836 (83%)] Loss: 12235.632812\n",
      "    epoch          : 4786\n",
      "    loss           : 12171.295779376034\n",
      "    val_loss       : 12169.476458752175\n",
      "    val_log_likelihood: -12093.409831052264\n",
      "    val_log_marginal: -12102.248895051216\n",
      "Train Epoch: 4787 [256/118836 (0%)] Loss: 12166.956055\n",
      "Train Epoch: 4787 [33024/118836 (28%)] Loss: 12141.982422\n",
      "Train Epoch: 4787 [65792/118836 (55%)] Loss: 12173.291016\n",
      "Train Epoch: 4787 [98560/118836 (83%)] Loss: 12322.024414\n",
      "    epoch          : 4787\n",
      "    loss           : 12175.758490520317\n",
      "    val_loss       : 12177.997726294316\n",
      "    val_log_likelihood: -12095.202870560639\n",
      "    val_log_marginal: -12104.46499616912\n",
      "Train Epoch: 4788 [256/118836 (0%)] Loss: 12289.942383\n",
      "Train Epoch: 4788 [33024/118836 (28%)] Loss: 12197.257812\n",
      "Train Epoch: 4788 [65792/118836 (55%)] Loss: 12180.375000\n",
      "Train Epoch: 4788 [98560/118836 (83%)] Loss: 12141.725586\n",
      "    epoch          : 4788\n",
      "    loss           : 12177.070275182226\n",
      "    val_loss       : 12171.428289769998\n",
      "    val_log_likelihood: -12093.931500239092\n",
      "    val_log_marginal: -12102.99389691024\n",
      "Train Epoch: 4789 [256/118836 (0%)] Loss: 12164.929688\n",
      "Train Epoch: 4789 [33024/118836 (28%)] Loss: 12199.181641\n",
      "Train Epoch: 4789 [65792/118836 (55%)] Loss: 12158.356445\n",
      "Train Epoch: 4789 [98560/118836 (83%)] Loss: 12189.835938\n",
      "    epoch          : 4789\n",
      "    loss           : 12171.577441810121\n",
      "    val_loss       : 12174.201593678406\n",
      "    val_log_likelihood: -12094.510038157827\n",
      "    val_log_marginal: -12103.544119869277\n",
      "Train Epoch: 4790 [256/118836 (0%)] Loss: 12170.310547\n",
      "Train Epoch: 4790 [33024/118836 (28%)] Loss: 12198.833008\n",
      "Train Epoch: 4790 [65792/118836 (55%)] Loss: 12208.876953\n",
      "Train Epoch: 4790 [98560/118836 (83%)] Loss: 12140.427734\n",
      "    epoch          : 4790\n",
      "    loss           : 12173.643911225703\n",
      "    val_loss       : 12169.73594482138\n",
      "    val_log_likelihood: -12095.972557059036\n",
      "    val_log_marginal: -12104.863276897091\n",
      "Train Epoch: 4791 [256/118836 (0%)] Loss: 12292.730469\n",
      "Train Epoch: 4791 [33024/118836 (28%)] Loss: 12140.972656\n",
      "Train Epoch: 4791 [65792/118836 (55%)] Loss: 12105.755859\n",
      "Train Epoch: 4791 [98560/118836 (83%)] Loss: 12305.630859\n",
      "    epoch          : 4791\n",
      "    loss           : 12172.995901022281\n",
      "    val_loss       : 12174.863869443992\n",
      "    val_log_likelihood: -12095.574256229322\n",
      "    val_log_marginal: -12104.552255493423\n",
      "Train Epoch: 4792 [256/118836 (0%)] Loss: 12244.021484\n",
      "Train Epoch: 4792 [33024/118836 (28%)] Loss: 12158.631836\n",
      "Train Epoch: 4792 [65792/118836 (55%)] Loss: 12255.043945\n",
      "Train Epoch: 4792 [98560/118836 (83%)] Loss: 12152.034180\n",
      "    epoch          : 4792\n",
      "    loss           : 12176.414088832455\n",
      "    val_loss       : 12175.262025465578\n",
      "    val_log_likelihood: -12099.805893946443\n",
      "    val_log_marginal: -12108.950047738312\n",
      "Train Epoch: 4793 [256/118836 (0%)] Loss: 12169.646484\n",
      "Train Epoch: 4793 [33024/118836 (28%)] Loss: 12154.934570\n",
      "Train Epoch: 4793 [65792/118836 (55%)] Loss: 12161.093750\n",
      "Train Epoch: 4793 [98560/118836 (83%)] Loss: 12146.343750\n",
      "    epoch          : 4793\n",
      "    loss           : 12172.418808642215\n",
      "    val_loss       : 12177.446338982843\n",
      "    val_log_likelihood: -12095.81467687009\n",
      "    val_log_marginal: -12104.888519188196\n",
      "Train Epoch: 4794 [256/118836 (0%)] Loss: 12218.582031\n",
      "Train Epoch: 4794 [33024/118836 (28%)] Loss: 12250.484375\n",
      "Train Epoch: 4794 [65792/118836 (55%)] Loss: 12108.923828\n",
      "Train Epoch: 4794 [98560/118836 (83%)] Loss: 12166.682617\n",
      "    epoch          : 4794\n",
      "    loss           : 12172.069313643764\n",
      "    val_loss       : 12169.296359739434\n",
      "    val_log_likelihood: -12092.534415225651\n",
      "    val_log_marginal: -12101.485756597838\n",
      "Train Epoch: 4795 [256/118836 (0%)] Loss: 12135.090820\n",
      "Train Epoch: 4795 [33024/118836 (28%)] Loss: 12336.170898\n",
      "Train Epoch: 4795 [65792/118836 (55%)] Loss: 12117.674805\n",
      "Train Epoch: 4795 [98560/118836 (83%)] Loss: 12169.859375\n",
      "    epoch          : 4795\n",
      "    loss           : 12175.128302542133\n",
      "    val_loss       : 12171.277699142738\n",
      "    val_log_likelihood: -12091.93310474178\n",
      "    val_log_marginal: -12100.913485426752\n",
      "Train Epoch: 4796 [256/118836 (0%)] Loss: 12232.724609\n",
      "Train Epoch: 4796 [33024/118836 (28%)] Loss: 12216.806641\n",
      "Train Epoch: 4796 [65792/118836 (55%)] Loss: 12213.769531\n",
      "Train Epoch: 4796 [98560/118836 (83%)] Loss: 12265.378906\n",
      "    epoch          : 4796\n",
      "    loss           : 12175.351405797663\n",
      "    val_loss       : 12174.312587471044\n",
      "    val_log_likelihood: -12092.965418379084\n",
      "    val_log_marginal: -12101.833112123553\n",
      "Train Epoch: 4797 [256/118836 (0%)] Loss: 12155.625000\n",
      "Train Epoch: 4797 [33024/118836 (28%)] Loss: 12127.782227\n",
      "Train Epoch: 4797 [65792/118836 (55%)] Loss: 12221.889648\n",
      "Train Epoch: 4797 [98560/118836 (83%)] Loss: 12191.685547\n",
      "    epoch          : 4797\n",
      "    loss           : 12172.486118919302\n",
      "    val_loss       : 12173.123984644897\n",
      "    val_log_likelihood: -12091.784106344345\n",
      "    val_log_marginal: -12100.770953849222\n",
      "Train Epoch: 4798 [256/118836 (0%)] Loss: 12198.142578\n",
      "Train Epoch: 4798 [33024/118836 (28%)] Loss: 12138.108398\n",
      "Train Epoch: 4798 [65792/118836 (55%)] Loss: 12275.124023\n",
      "Train Epoch: 4798 [98560/118836 (83%)] Loss: 12243.757812\n",
      "    epoch          : 4798\n",
      "    loss           : 12174.518646608767\n",
      "    val_loss       : 12171.919537069843\n",
      "    val_log_likelihood: -12094.181890379445\n",
      "    val_log_marginal: -12103.129988580842\n",
      "Train Epoch: 4799 [256/118836 (0%)] Loss: 12190.904297\n",
      "Train Epoch: 4799 [33024/118836 (28%)] Loss: 12214.874023\n",
      "Train Epoch: 4799 [65792/118836 (55%)] Loss: 12179.929688\n",
      "Train Epoch: 4799 [98560/118836 (83%)] Loss: 12161.714844\n",
      "    epoch          : 4799\n",
      "    loss           : 12175.347250600962\n",
      "    val_loss       : 12170.838963742752\n",
      "    val_log_likelihood: -12093.452393183934\n",
      "    val_log_marginal: -12102.355271024038\n",
      "Train Epoch: 4800 [256/118836 (0%)] Loss: 12218.116211\n",
      "Train Epoch: 4800 [33024/118836 (28%)] Loss: 12342.619141\n",
      "Train Epoch: 4800 [65792/118836 (55%)] Loss: 12335.392578\n",
      "Train Epoch: 4800 [98560/118836 (83%)] Loss: 12200.580078\n",
      "    epoch          : 4800\n",
      "    loss           : 12173.333406191841\n",
      "    val_loss       : 12174.890383217962\n",
      "    val_log_likelihood: -12091.808240281223\n",
      "    val_log_marginal: -12100.686201833632\n",
      "Saving checkpoint: saved/models/SelfiesAutoencodingOperad/0905_154251/checkpoint-epoch4800.pth ...\n",
      "Train Epoch: 4801 [256/118836 (0%)] Loss: 12183.113281\n",
      "Train Epoch: 4801 [33024/118836 (28%)] Loss: 12250.781250\n",
      "Train Epoch: 4801 [65792/118836 (55%)] Loss: 12181.248047\n",
      "Train Epoch: 4801 [98560/118836 (83%)] Loss: 12224.882812\n",
      "    epoch          : 4801\n",
      "    loss           : 12172.988973163512\n",
      "    val_loss       : 12178.20129603352\n",
      "    val_log_likelihood: -12095.06538655397\n",
      "    val_log_marginal: -12104.049946476025\n",
      "Train Epoch: 4802 [256/118836 (0%)] Loss: 12209.939453\n",
      "Train Epoch: 4802 [33024/118836 (28%)] Loss: 12235.867188\n",
      "Train Epoch: 4802 [65792/118836 (55%)] Loss: 12261.285156\n",
      "Train Epoch: 4802 [98560/118836 (83%)] Loss: 12146.463867\n",
      "    epoch          : 4802\n",
      "    loss           : 12175.870143035309\n",
      "    val_loss       : 12175.000705084427\n",
      "    val_log_likelihood: -12095.973578370555\n",
      "    val_log_marginal: -12105.112248809486\n",
      "Train Epoch: 4803 [256/118836 (0%)] Loss: 12267.871094\n",
      "Train Epoch: 4803 [33024/118836 (28%)] Loss: 12215.585938\n",
      "Train Epoch: 4803 [65792/118836 (55%)] Loss: 12083.009766\n",
      "Train Epoch: 4803 [98560/118836 (83%)] Loss: 12282.621094\n",
      "    epoch          : 4803\n",
      "    loss           : 12174.320403936621\n",
      "    val_loss       : 12167.737126514887\n",
      "    val_log_likelihood: -12095.286410030241\n",
      "    val_log_marginal: -12104.368352742718\n",
      "Train Epoch: 4804 [256/118836 (0%)] Loss: 12171.625000\n",
      "Train Epoch: 4804 [33024/118836 (28%)] Loss: 12255.246094\n",
      "Train Epoch: 4804 [65792/118836 (55%)] Loss: 12196.132812\n",
      "Train Epoch: 4804 [98560/118836 (83%)] Loss: 12210.371094\n",
      "    epoch          : 4804\n",
      "    loss           : 12173.398055437086\n",
      "    val_loss       : 12171.919081146232\n",
      "    val_log_likelihood: -12090.935273049783\n",
      "    val_log_marginal: -12099.910206837549\n",
      "Train Epoch: 4805 [256/118836 (0%)] Loss: 12111.042969\n",
      "Train Epoch: 4805 [33024/118836 (28%)] Loss: 12150.248047\n",
      "Train Epoch: 4805 [65792/118836 (55%)] Loss: 12295.579102\n",
      "Train Epoch: 4805 [98560/118836 (83%)] Loss: 12216.318359\n",
      "    epoch          : 4805\n",
      "    loss           : 12168.843409455128\n",
      "    val_loss       : 12177.102910160167\n",
      "    val_log_likelihood: -12093.245815886063\n",
      "    val_log_marginal: -12102.259692721567\n",
      "Train Epoch: 4806 [256/118836 (0%)] Loss: 12124.347656\n",
      "Train Epoch: 4806 [33024/118836 (28%)] Loss: 12144.486328\n",
      "Train Epoch: 4806 [65792/118836 (55%)] Loss: 12226.407227\n",
      "Train Epoch: 4806 [98560/118836 (83%)] Loss: 12343.000977\n",
      "    epoch          : 4806\n",
      "    loss           : 12171.421930411238\n",
      "    val_loss       : 12176.809564145018\n",
      "    val_log_likelihood: -12088.665421771608\n",
      "    val_log_marginal: -12097.626413569167\n",
      "Train Epoch: 4807 [256/118836 (0%)] Loss: 12161.206055\n",
      "Train Epoch: 4807 [33024/118836 (28%)] Loss: 12210.226562\n",
      "Train Epoch: 4807 [65792/118836 (55%)] Loss: 12331.691406\n",
      "Train Epoch: 4807 [98560/118836 (83%)] Loss: 12211.244141\n",
      "    epoch          : 4807\n",
      "    loss           : 12177.828542442101\n",
      "    val_loss       : 12172.602096301134\n",
      "    val_log_likelihood: -12093.367079423853\n",
      "    val_log_marginal: -12102.226934767068\n",
      "Train Epoch: 4808 [256/118836 (0%)] Loss: 12233.200195\n",
      "Train Epoch: 4808 [33024/118836 (28%)] Loss: 12174.847656\n",
      "Train Epoch: 4808 [65792/118836 (55%)] Loss: 12153.285156\n",
      "Train Epoch: 4808 [98560/118836 (83%)] Loss: 12214.418945\n",
      "    epoch          : 4808\n",
      "    loss           : 12173.105634983714\n",
      "    val_loss       : 12171.8723863827\n",
      "    val_log_likelihood: -12093.399996445927\n",
      "    val_log_marginal: -12102.234346258745\n",
      "Train Epoch: 4809 [256/118836 (0%)] Loss: 12140.568359\n",
      "Train Epoch: 4809 [33024/118836 (28%)] Loss: 12219.863281\n",
      "Train Epoch: 4809 [65792/118836 (55%)] Loss: 12160.763672\n",
      "Train Epoch: 4809 [98560/118836 (83%)] Loss: 12211.486328\n",
      "    epoch          : 4809\n",
      "    loss           : 12176.509345759669\n",
      "    val_loss       : 12174.894565322413\n",
      "    val_log_likelihood: -12095.773417952594\n",
      "    val_log_marginal: -12104.636133881386\n",
      "Train Epoch: 4810 [256/118836 (0%)] Loss: 12158.693359\n",
      "Train Epoch: 4810 [33024/118836 (28%)] Loss: 12199.325195\n",
      "Train Epoch: 4810 [65792/118836 (55%)] Loss: 12129.616211\n",
      "Train Epoch: 4810 [98560/118836 (83%)] Loss: 12164.195312\n",
      "    epoch          : 4810\n",
      "    loss           : 12173.664971050455\n",
      "    val_loss       : 12172.21514955791\n",
      "    val_log_likelihood: -12094.779246310225\n",
      "    val_log_marginal: -12103.62433205894\n",
      "Train Epoch: 4811 [256/118836 (0%)] Loss: 12130.454102\n",
      "Train Epoch: 4811 [33024/118836 (28%)] Loss: 12227.136719\n",
      "Train Epoch: 4811 [65792/118836 (55%)] Loss: 12182.648438\n",
      "Train Epoch: 4811 [98560/118836 (83%)] Loss: 12184.511719\n",
      "    epoch          : 4811\n",
      "    loss           : 12174.136930702025\n",
      "    val_loss       : 12168.88270076316\n",
      "    val_log_likelihood: -12092.272315058934\n",
      "    val_log_marginal: -12101.154472169092\n",
      "Train Epoch: 4812 [256/118836 (0%)] Loss: 12208.126953\n",
      "Train Epoch: 4812 [33024/118836 (28%)] Loss: 12299.643555\n",
      "Train Epoch: 4812 [65792/118836 (55%)] Loss: 12149.483398\n",
      "Train Epoch: 4812 [98560/118836 (83%)] Loss: 12117.342773\n",
      "    epoch          : 4812\n",
      "    loss           : 12171.771337042495\n",
      "    val_loss       : 12175.762349880017\n",
      "    val_log_likelihood: -12092.71649510184\n",
      "    val_log_marginal: -12101.618279431063\n",
      "Train Epoch: 4813 [256/118836 (0%)] Loss: 12167.369141\n",
      "Train Epoch: 4813 [33024/118836 (28%)] Loss: 12126.454102\n",
      "Train Epoch: 4813 [65792/118836 (55%)] Loss: 12140.532227\n",
      "Train Epoch: 4813 [98560/118836 (83%)] Loss: 12095.095703\n",
      "    epoch          : 4813\n",
      "    loss           : 12171.517448078215\n",
      "    val_loss       : 12170.633728925284\n",
      "    val_log_likelihood: -12091.81657038358\n",
      "    val_log_marginal: -12100.682944917735\n",
      "Train Epoch: 4814 [256/118836 (0%)] Loss: 12260.685547\n",
      "Train Epoch: 4814 [33024/118836 (28%)] Loss: 12224.871094\n",
      "Train Epoch: 4814 [65792/118836 (55%)] Loss: 12127.993164\n",
      "Train Epoch: 4814 [98560/118836 (83%)] Loss: 12213.349609\n",
      "    epoch          : 4814\n",
      "    loss           : 12171.120436246381\n",
      "    val_loss       : 12169.107566304701\n",
      "    val_log_likelihood: -12093.793465351013\n",
      "    val_log_marginal: -12102.641369685254\n",
      "Train Epoch: 4815 [256/118836 (0%)] Loss: 12165.068359\n",
      "Train Epoch: 4815 [33024/118836 (28%)] Loss: 12214.894531\n",
      "Train Epoch: 4815 [65792/118836 (55%)] Loss: 12173.665039\n",
      "Train Epoch: 4815 [98560/118836 (83%)] Loss: 12129.633789\n",
      "    epoch          : 4815\n",
      "    loss           : 12171.42766959393\n",
      "    val_loss       : 12171.491200301938\n",
      "    val_log_likelihood: -12092.405427555055\n",
      "    val_log_marginal: -12101.156128018698\n",
      "Train Epoch: 4816 [256/118836 (0%)] Loss: 12311.414062\n",
      "Train Epoch: 4816 [33024/118836 (28%)] Loss: 12230.832031\n",
      "Train Epoch: 4816 [65792/118836 (55%)] Loss: 12237.535156\n",
      "Train Epoch: 4816 [98560/118836 (83%)] Loss: 12329.823242\n",
      "    epoch          : 4816\n",
      "    loss           : 12172.766502856182\n",
      "    val_loss       : 12171.434665099314\n",
      "    val_log_likelihood: -12095.11865436311\n",
      "    val_log_marginal: -12104.030886136907\n",
      "Train Epoch: 4817 [256/118836 (0%)] Loss: 12162.805664\n",
      "Train Epoch: 4817 [33024/118836 (28%)] Loss: 12323.708984\n",
      "Train Epoch: 4817 [65792/118836 (55%)] Loss: 12153.481445\n",
      "Train Epoch: 4817 [98560/118836 (83%)] Loss: 12134.081055\n",
      "    epoch          : 4817\n",
      "    loss           : 12177.393494106698\n",
      "    val_loss       : 12175.563731151367\n",
      "    val_log_likelihood: -12093.016767796214\n",
      "    val_log_marginal: -12101.948434061509\n",
      "Train Epoch: 4818 [256/118836 (0%)] Loss: 12275.208984\n",
      "Train Epoch: 4818 [33024/118836 (28%)] Loss: 12260.557617\n",
      "Train Epoch: 4818 [65792/118836 (55%)] Loss: 12181.165039\n",
      "Train Epoch: 4818 [98560/118836 (83%)] Loss: 12116.720703\n",
      "    epoch          : 4818\n",
      "    loss           : 12173.355448071752\n",
      "    val_loss       : 12175.191332679144\n",
      "    val_log_likelihood: -12096.454244694736\n",
      "    val_log_marginal: -12105.445232077127\n",
      "Train Epoch: 4819 [256/118836 (0%)] Loss: 12121.780273\n",
      "Train Epoch: 4819 [33024/118836 (28%)] Loss: 12115.618164\n",
      "Train Epoch: 4819 [65792/118836 (55%)] Loss: 12159.644531\n",
      "Train Epoch: 4819 [98560/118836 (83%)] Loss: 12186.070312\n",
      "    epoch          : 4819\n",
      "    loss           : 12175.24101691739\n",
      "    val_loss       : 12174.830028698085\n",
      "    val_log_likelihood: -12093.553408518144\n",
      "    val_log_marginal: -12102.606227464401\n",
      "Train Epoch: 4820 [256/118836 (0%)] Loss: 12245.269531\n",
      "Train Epoch: 4820 [33024/118836 (28%)] Loss: 12227.040039\n",
      "Train Epoch: 4820 [65792/118836 (55%)] Loss: 12331.532227\n",
      "Train Epoch: 4820 [98560/118836 (83%)] Loss: 12226.609375\n",
      "    epoch          : 4820\n",
      "    loss           : 12171.990918049525\n",
      "    val_loss       : 12172.491626909554\n",
      "    val_log_likelihood: -12091.025221968051\n",
      "    val_log_marginal: -12099.886083492298\n",
      "Train Epoch: 4821 [256/118836 (0%)] Loss: 12141.140625\n",
      "Train Epoch: 4821 [33024/118836 (28%)] Loss: 12274.009766\n",
      "Train Epoch: 4821 [65792/118836 (55%)] Loss: 12155.919922\n",
      "Train Epoch: 4821 [98560/118836 (83%)] Loss: 12152.078125\n",
      "    epoch          : 4821\n",
      "    loss           : 12179.428529841294\n",
      "    val_loss       : 12174.412533801022\n",
      "    val_log_likelihood: -12094.673670776468\n",
      "    val_log_marginal: -12103.661033107343\n",
      "Train Epoch: 4822 [256/118836 (0%)] Loss: 12159.960938\n",
      "Train Epoch: 4822 [33024/118836 (28%)] Loss: 12138.294922\n",
      "Train Epoch: 4822 [65792/118836 (55%)] Loss: 12318.084961\n",
      "Train Epoch: 4822 [98560/118836 (83%)] Loss: 12139.982422\n",
      "    epoch          : 4822\n",
      "    loss           : 12175.308025582868\n",
      "    val_loss       : 12175.019147506264\n",
      "    val_log_likelihood: -12094.848740242453\n",
      "    val_log_marginal: -12103.80122490831\n",
      "Train Epoch: 4823 [256/118836 (0%)] Loss: 12275.076172\n",
      "Train Epoch: 4823 [33024/118836 (28%)] Loss: 12340.447266\n",
      "Train Epoch: 4823 [65792/118836 (55%)] Loss: 12308.964844\n",
      "Train Epoch: 4823 [98560/118836 (83%)] Loss: 12191.090820\n",
      "    epoch          : 4823\n",
      "    loss           : 12173.98445044329\n",
      "    val_loss       : 12174.07057424918\n",
      "    val_log_likelihood: -12092.391722562552\n",
      "    val_log_marginal: -12101.41733265411\n",
      "Train Epoch: 4824 [256/118836 (0%)] Loss: 12281.842773\n",
      "Train Epoch: 4824 [33024/118836 (28%)] Loss: 12161.021484\n",
      "Train Epoch: 4824 [65792/118836 (55%)] Loss: 12200.670898\n",
      "Train Epoch: 4824 [98560/118836 (83%)] Loss: 12158.013672\n",
      "    epoch          : 4824\n",
      "    loss           : 12174.559825559605\n",
      "    val_loss       : 12174.030324749116\n",
      "    val_log_likelihood: -12091.274570603287\n",
      "    val_log_marginal: -12100.34199420717\n",
      "Train Epoch: 4825 [256/118836 (0%)] Loss: 12141.099609\n",
      "Train Epoch: 4825 [33024/118836 (28%)] Loss: 12177.208008\n",
      "Train Epoch: 4825 [65792/118836 (55%)] Loss: 12299.406250\n",
      "Train Epoch: 4825 [98560/118836 (83%)] Loss: 12278.727539\n",
      "    epoch          : 4825\n",
      "    loss           : 12174.07686152683\n",
      "    val_loss       : 12175.149797124537\n",
      "    val_log_likelihood: -12095.23757673568\n",
      "    val_log_marginal: -12104.118547477368\n",
      "Train Epoch: 4826 [256/118836 (0%)] Loss: 12194.823242\n",
      "Train Epoch: 4826 [33024/118836 (28%)] Loss: 12116.477539\n",
      "Train Epoch: 4826 [65792/118836 (55%)] Loss: 12152.976562\n",
      "Train Epoch: 4826 [98560/118836 (83%)] Loss: 12121.914062\n",
      "    epoch          : 4826\n",
      "    loss           : 12172.791654227409\n",
      "    val_loss       : 12173.182051958436\n",
      "    val_log_likelihood: -12092.27928750517\n",
      "    val_log_marginal: -12101.232602130178\n",
      "Train Epoch: 4827 [256/118836 (0%)] Loss: 12186.161133\n",
      "Train Epoch: 4827 [33024/118836 (28%)] Loss: 12239.495117\n",
      "Train Epoch: 4827 [65792/118836 (55%)] Loss: 12228.185547\n",
      "Train Epoch: 4827 [98560/118836 (83%)] Loss: 12328.157227\n",
      "    epoch          : 4827\n",
      "    loss           : 12176.847097291151\n",
      "    val_loss       : 12171.54022355571\n",
      "    val_log_likelihood: -12093.939196423957\n",
      "    val_log_marginal: -12102.868382217637\n",
      "Train Epoch: 4828 [256/118836 (0%)] Loss: 12105.326172\n",
      "Train Epoch: 4828 [33024/118836 (28%)] Loss: 12177.564453\n",
      "Train Epoch: 4828 [65792/118836 (55%)] Loss: 12169.862305\n",
      "Train Epoch: 4828 [98560/118836 (83%)] Loss: 12183.173828\n",
      "    epoch          : 4828\n",
      "    loss           : 12174.160738956523\n",
      "    val_loss       : 12170.33911932258\n",
      "    val_log_likelihood: -12100.332646266284\n",
      "    val_log_marginal: -12109.329039415696\n",
      "Train Epoch: 4829 [256/118836 (0%)] Loss: 12177.422852\n",
      "Train Epoch: 4829 [33024/118836 (28%)] Loss: 12120.803711\n",
      "Train Epoch: 4829 [65792/118836 (55%)] Loss: 12309.125000\n",
      "Train Epoch: 4829 [98560/118836 (83%)] Loss: 12190.926758\n",
      "    epoch          : 4829\n",
      "    loss           : 12175.597080651623\n",
      "    val_loss       : 12172.590658968913\n",
      "    val_log_likelihood: -12090.337554118849\n",
      "    val_log_marginal: -12099.323336053747\n",
      "Train Epoch: 4830 [256/118836 (0%)] Loss: 12208.172852\n",
      "Train Epoch: 4830 [33024/118836 (28%)] Loss: 12237.355469\n",
      "Train Epoch: 4830 [65792/118836 (55%)] Loss: 12142.386719\n",
      "Train Epoch: 4830 [98560/118836 (83%)] Loss: 12170.991211\n",
      "    epoch          : 4830\n",
      "    loss           : 12173.882239324856\n",
      "    val_loss       : 12172.186718483717\n",
      "    val_log_likelihood: -12092.96325039418\n",
      "    val_log_marginal: -12101.920287433075\n",
      "Train Epoch: 4831 [256/118836 (0%)] Loss: 12261.024414\n",
      "Train Epoch: 4831 [33024/118836 (28%)] Loss: 12217.093750\n",
      "Train Epoch: 4831 [65792/118836 (55%)] Loss: 12185.980469\n",
      "Train Epoch: 4831 [98560/118836 (83%)] Loss: 12155.470703\n",
      "    epoch          : 4831\n",
      "    loss           : 12169.254288151365\n",
      "    val_loss       : 12170.983022002576\n",
      "    val_log_likelihood: -12090.392940963606\n",
      "    val_log_marginal: -12099.286839583388\n",
      "Train Epoch: 4832 [256/118836 (0%)] Loss: 12205.608398\n",
      "Train Epoch: 4832 [33024/118836 (28%)] Loss: 12166.694336\n",
      "Train Epoch: 4832 [65792/118836 (55%)] Loss: 12292.917969\n",
      "Train Epoch: 4832 [98560/118836 (83%)] Loss: 12286.744141\n",
      "    epoch          : 4832\n",
      "    loss           : 12172.646482113316\n",
      "    val_loss       : 12177.993355660665\n",
      "    val_log_likelihood: -12091.6992859543\n",
      "    val_log_marginal: -12100.679476472687\n",
      "Train Epoch: 4833 [256/118836 (0%)] Loss: 12185.550781\n",
      "Train Epoch: 4833 [33024/118836 (28%)] Loss: 12154.101562\n",
      "Train Epoch: 4833 [65792/118836 (55%)] Loss: 12286.124023\n",
      "Train Epoch: 4833 [98560/118836 (83%)] Loss: 12156.637695\n",
      "    epoch          : 4833\n",
      "    loss           : 12172.445087300972\n",
      "    val_loss       : 12172.710387965953\n",
      "    val_log_likelihood: -12092.954170382289\n",
      "    val_log_marginal: -12101.847177048074\n",
      "Train Epoch: 4834 [256/118836 (0%)] Loss: 12153.177734\n",
      "Train Epoch: 4834 [33024/118836 (28%)] Loss: 12241.642578\n",
      "Train Epoch: 4834 [65792/118836 (55%)] Loss: 12263.023438\n",
      "Train Epoch: 4834 [98560/118836 (83%)] Loss: 12138.650391\n",
      "    epoch          : 4834\n",
      "    loss           : 12172.95046719913\n",
      "    val_loss       : 12177.065060147712\n",
      "    val_log_likelihood: -12093.452091087674\n",
      "    val_log_marginal: -12102.479552406734\n",
      "Train Epoch: 4835 [256/118836 (0%)] Loss: 12158.165039\n",
      "Train Epoch: 4835 [33024/118836 (28%)] Loss: 12240.822266\n",
      "Train Epoch: 4835 [65792/118836 (55%)] Loss: 12344.558594\n",
      "Train Epoch: 4835 [98560/118836 (83%)] Loss: 12163.677734\n",
      "    epoch          : 4835\n",
      "    loss           : 12180.878380408654\n",
      "    val_loss       : 12187.056376135137\n",
      "    val_log_likelihood: -12093.33172398418\n",
      "    val_log_marginal: -12102.352197626251\n",
      "Train Epoch: 4836 [256/118836 (0%)] Loss: 12109.378906\n",
      "Train Epoch: 4836 [33024/118836 (28%)] Loss: 12189.753906\n",
      "Train Epoch: 4836 [65792/118836 (55%)] Loss: 12142.795898\n",
      "Train Epoch: 4836 [98560/118836 (83%)] Loss: 12153.154297\n",
      "    epoch          : 4836\n",
      "    loss           : 12176.679398973843\n",
      "    val_loss       : 12178.46913185232\n",
      "    val_log_likelihood: -12094.634130415116\n",
      "    val_log_marginal: -12103.685480374985\n",
      "Train Epoch: 4837 [256/118836 (0%)] Loss: 12201.682617\n",
      "Train Epoch: 4837 [33024/118836 (28%)] Loss: 12206.903320\n",
      "Train Epoch: 4837 [65792/118836 (55%)] Loss: 12310.250977\n",
      "Train Epoch: 4837 [98560/118836 (83%)] Loss: 12124.275391\n",
      "    epoch          : 4837\n",
      "    loss           : 12172.484802296578\n",
      "    val_loss       : 12175.517980437642\n",
      "    val_log_likelihood: -12093.677776700784\n",
      "    val_log_marginal: -12102.806202970967\n",
      "Train Epoch: 4838 [256/118836 (0%)] Loss: 12135.595703\n",
      "Train Epoch: 4838 [33024/118836 (28%)] Loss: 12216.281250\n",
      "Train Epoch: 4838 [65792/118836 (55%)] Loss: 12247.057617\n",
      "Train Epoch: 4838 [98560/118836 (83%)] Loss: 12135.534180\n",
      "    epoch          : 4838\n",
      "    loss           : 12175.872997764165\n",
      "    val_loss       : 12172.379091678153\n",
      "    val_log_likelihood: -12093.934030416407\n",
      "    val_log_marginal: -12102.81687983836\n",
      "Train Epoch: 4839 [256/118836 (0%)] Loss: 12181.203125\n",
      "Train Epoch: 4839 [33024/118836 (28%)] Loss: 12194.396484\n",
      "Train Epoch: 4839 [65792/118836 (55%)] Loss: 12216.173828\n",
      "Train Epoch: 4839 [98560/118836 (83%)] Loss: 12139.670898\n",
      "    epoch          : 4839\n",
      "    loss           : 12174.534562073512\n",
      "    val_loss       : 12183.620191044702\n",
      "    val_log_likelihood: -12092.804452608043\n",
      "    val_log_marginal: -12101.842481314097\n",
      "Train Epoch: 4840 [256/118836 (0%)] Loss: 12185.548828\n",
      "Train Epoch: 4840 [33024/118836 (28%)] Loss: 12281.654297\n",
      "Train Epoch: 4840 [65792/118836 (55%)] Loss: 12215.394531\n",
      "Train Epoch: 4840 [98560/118836 (83%)] Loss: 12129.851562\n",
      "    epoch          : 4840\n",
      "    loss           : 12172.945103778951\n",
      "    val_loss       : 12174.61484960876\n",
      "    val_log_likelihood: -12093.70383468388\n",
      "    val_log_marginal: -12102.565936709381\n",
      "Train Epoch: 4841 [256/118836 (0%)] Loss: 12334.906250\n",
      "Train Epoch: 4841 [33024/118836 (28%)] Loss: 12147.764648\n",
      "Train Epoch: 4841 [65792/118836 (55%)] Loss: 12253.746094\n",
      "Train Epoch: 4841 [98560/118836 (83%)] Loss: 12186.158203\n",
      "    epoch          : 4841\n",
      "    loss           : 12173.30213648289\n",
      "    val_loss       : 12175.289266191066\n",
      "    val_log_likelihood: -12092.660539282206\n",
      "    val_log_marginal: -12101.507826428684\n",
      "Train Epoch: 4842 [256/118836 (0%)] Loss: 12178.627930\n",
      "Train Epoch: 4842 [33024/118836 (28%)] Loss: 12121.857422\n",
      "Train Epoch: 4842 [65792/118836 (55%)] Loss: 12163.883789\n",
      "Train Epoch: 4842 [98560/118836 (83%)] Loss: 12119.788086\n",
      "    epoch          : 4842\n",
      "    loss           : 12169.94211351065\n",
      "    val_loss       : 12168.534110121669\n",
      "    val_log_likelihood: -12093.632362425042\n",
      "    val_log_marginal: -12102.422928193084\n",
      "Train Epoch: 4843 [256/118836 (0%)] Loss: 12220.744141\n",
      "Train Epoch: 4843 [33024/118836 (28%)] Loss: 12130.707031\n",
      "Train Epoch: 4843 [65792/118836 (55%)] Loss: 12202.335938\n",
      "Train Epoch: 4843 [98560/118836 (83%)] Loss: 12191.846680\n",
      "    epoch          : 4843\n",
      "    loss           : 12173.88873358664\n",
      "    val_loss       : 12171.15175657152\n",
      "    val_log_likelihood: -12090.426307091346\n",
      "    val_log_marginal: -12099.216933462973\n",
      "Train Epoch: 4844 [256/118836 (0%)] Loss: 12318.827148\n",
      "Train Epoch: 4844 [33024/118836 (28%)] Loss: 12259.034180\n",
      "Train Epoch: 4844 [65792/118836 (55%)] Loss: 12310.856445\n",
      "Train Epoch: 4844 [98560/118836 (83%)] Loss: 12234.382812\n",
      "    epoch          : 4844\n",
      "    loss           : 12175.351651836487\n",
      "    val_loss       : 12172.34425063494\n",
      "    val_log_likelihood: -12092.030009789856\n",
      "    val_log_marginal: -12100.812478256736\n",
      "Train Epoch: 4845 [256/118836 (0%)] Loss: 12142.998047\n",
      "Train Epoch: 4845 [33024/118836 (28%)] Loss: 12279.172852\n",
      "Train Epoch: 4845 [65792/118836 (55%)] Loss: 12236.741211\n",
      "Train Epoch: 4845 [98560/118836 (83%)] Loss: 12280.228516\n",
      "    epoch          : 4845\n",
      "    loss           : 12171.90459606338\n",
      "    val_loss       : 12174.8863620426\n",
      "    val_log_likelihood: -12093.580418669872\n",
      "    val_log_marginal: -12102.428411935662\n",
      "Train Epoch: 4846 [256/118836 (0%)] Loss: 12143.691406\n",
      "Train Epoch: 4846 [33024/118836 (28%)] Loss: 12156.885742\n",
      "Train Epoch: 4846 [65792/118836 (55%)] Loss: 12188.726562\n",
      "Train Epoch: 4846 [98560/118836 (83%)] Loss: 12189.171875\n",
      "    epoch          : 4846\n",
      "    loss           : 12173.157263557176\n",
      "    val_loss       : 12171.401014713534\n",
      "    val_log_likelihood: -12091.716493970998\n",
      "    val_log_marginal: -12100.58577102448\n",
      "Train Epoch: 4847 [256/118836 (0%)] Loss: 12219.665039\n",
      "Train Epoch: 4847 [33024/118836 (28%)] Loss: 12327.049805\n",
      "Train Epoch: 4847 [65792/118836 (55%)] Loss: 12171.786133\n",
      "Train Epoch: 4847 [98560/118836 (83%)] Loss: 12159.791992\n",
      "    epoch          : 4847\n",
      "    loss           : 12177.181763240538\n",
      "    val_loss       : 12173.538466162463\n",
      "    val_log_likelihood: -12095.100176088194\n",
      "    val_log_marginal: -12104.028885376936\n",
      "Train Epoch: 4848 [256/118836 (0%)] Loss: 12204.257812\n",
      "Train Epoch: 4848 [33024/118836 (28%)] Loss: 12144.482422\n",
      "Train Epoch: 4848 [65792/118836 (55%)] Loss: 12194.492188\n",
      "Train Epoch: 4848 [98560/118836 (83%)] Loss: 12240.305664\n",
      "    epoch          : 4848\n",
      "    loss           : 12174.689567178453\n",
      "    val_loss       : 12172.21907831063\n",
      "    val_log_likelihood: -12092.695137865747\n",
      "    val_log_marginal: -12101.582242016628\n",
      "Train Epoch: 4849 [256/118836 (0%)] Loss: 12157.072266\n",
      "Train Epoch: 4849 [33024/118836 (28%)] Loss: 12205.167969\n",
      "Train Epoch: 4849 [65792/118836 (55%)] Loss: 12291.923828\n",
      "Train Epoch: 4849 [98560/118836 (83%)] Loss: 12182.014648\n",
      "    epoch          : 4849\n",
      "    loss           : 12175.492308500052\n",
      "    val_loss       : 12174.587879265338\n",
      "    val_log_likelihood: -12094.205287169149\n",
      "    val_log_marginal: -12103.204785641632\n",
      "Train Epoch: 4850 [256/118836 (0%)] Loss: 12187.061523\n",
      "Train Epoch: 4850 [33024/118836 (28%)] Loss: 12323.664062\n",
      "Train Epoch: 4850 [65792/118836 (55%)] Loss: 12225.183594\n",
      "Train Epoch: 4850 [98560/118836 (83%)] Loss: 12228.616211\n",
      "    epoch          : 4850\n",
      "    loss           : 12170.113845216863\n",
      "    val_loss       : 12173.56519461292\n",
      "    val_log_likelihood: -12093.242995244003\n",
      "    val_log_marginal: -12102.212056114522\n",
      "Train Epoch: 4851 [256/118836 (0%)] Loss: 12270.978516\n",
      "Train Epoch: 4851 [33024/118836 (28%)] Loss: 12288.950195\n",
      "Train Epoch: 4851 [65792/118836 (55%)] Loss: 12168.790039\n",
      "Train Epoch: 4851 [98560/118836 (83%)] Loss: 12263.452148\n",
      "    epoch          : 4851\n",
      "    loss           : 12175.22844018171\n",
      "    val_loss       : 12169.678489694785\n",
      "    val_log_likelihood: -12091.66638476401\n",
      "    val_log_marginal: -12100.71509304535\n",
      "Train Epoch: 4852 [256/118836 (0%)] Loss: 12201.104492\n",
      "Train Epoch: 4852 [33024/118836 (28%)] Loss: 12134.900391\n",
      "Train Epoch: 4852 [65792/118836 (55%)] Loss: 12150.147461\n",
      "Train Epoch: 4852 [98560/118836 (83%)] Loss: 12220.254883\n",
      "    epoch          : 4852\n",
      "    loss           : 12169.85357491341\n",
      "    val_loss       : 12174.025854298276\n",
      "    val_log_likelihood: -12092.251931315914\n",
      "    val_log_marginal: -12101.342419813916\n",
      "Train Epoch: 4853 [256/118836 (0%)] Loss: 12174.566406\n",
      "Train Epoch: 4853 [33024/118836 (28%)] Loss: 12159.432617\n",
      "Train Epoch: 4853 [65792/118836 (55%)] Loss: 12251.324219\n",
      "Train Epoch: 4853 [98560/118836 (83%)] Loss: 12257.713867\n",
      "    epoch          : 4853\n",
      "    loss           : 12176.501298044614\n",
      "    val_loss       : 12172.175549289996\n",
      "    val_log_likelihood: -12090.058055792495\n",
      "    val_log_marginal: -12099.084584311495\n",
      "Train Epoch: 4854 [256/118836 (0%)] Loss: 12178.367188\n",
      "Train Epoch: 4854 [33024/118836 (28%)] Loss: 12237.476562\n",
      "Train Epoch: 4854 [65792/118836 (55%)] Loss: 12283.660156\n",
      "Train Epoch: 4854 [98560/118836 (83%)] Loss: 12207.677734\n",
      "    epoch          : 4854\n",
      "    loss           : 12176.360243971\n",
      "    val_loss       : 12174.25127169194\n",
      "    val_log_likelihood: -12096.162217935793\n",
      "    val_log_marginal: -12105.185204623107\n",
      "Train Epoch: 4855 [256/118836 (0%)] Loss: 12212.922852\n",
      "Train Epoch: 4855 [33024/118836 (28%)] Loss: 12231.586914\n",
      "Train Epoch: 4855 [65792/118836 (55%)] Loss: 12141.111328\n",
      "Train Epoch: 4855 [98560/118836 (83%)] Loss: 12324.958984\n",
      "    epoch          : 4855\n",
      "    loss           : 12173.002772985163\n",
      "    val_loss       : 12174.775471354827\n",
      "    val_log_likelihood: -12094.331540303194\n",
      "    val_log_marginal: -12103.337971029334\n",
      "Train Epoch: 4856 [256/118836 (0%)] Loss: 12253.649414\n",
      "Train Epoch: 4856 [33024/118836 (28%)] Loss: 12112.248047\n",
      "Train Epoch: 4856 [65792/118836 (55%)] Loss: 12332.000977\n",
      "Train Epoch: 4856 [98560/118836 (83%)] Loss: 12168.286133\n",
      "    epoch          : 4856\n",
      "    loss           : 12170.275871232683\n",
      "    val_loss       : 12172.878379426742\n",
      "    val_log_likelihood: -12095.206307188275\n",
      "    val_log_marginal: -12104.197992856518\n",
      "Train Epoch: 4857 [256/118836 (0%)] Loss: 12175.333984\n",
      "Train Epoch: 4857 [33024/118836 (28%)] Loss: 12192.901367\n",
      "Train Epoch: 4857 [65792/118836 (55%)] Loss: 12286.601562\n",
      "Train Epoch: 4857 [98560/118836 (83%)] Loss: 12167.130859\n",
      "    epoch          : 4857\n",
      "    loss           : 12171.03655978598\n",
      "    val_loss       : 12173.863777195413\n",
      "    val_log_likelihood: -12089.956621239144\n",
      "    val_log_marginal: -12098.84395328633\n",
      "Train Epoch: 4858 [256/118836 (0%)] Loss: 12092.582031\n",
      "Train Epoch: 4858 [33024/118836 (28%)] Loss: 12165.440430\n",
      "Train Epoch: 4858 [65792/118836 (55%)] Loss: 12094.860352\n",
      "Train Epoch: 4858 [98560/118836 (83%)] Loss: 12249.048828\n",
      "    epoch          : 4858\n",
      "    loss           : 12170.354770697633\n",
      "    val_loss       : 12175.970678330765\n",
      "    val_log_likelihood: -12093.138698045905\n",
      "    val_log_marginal: -12102.085563219616\n",
      "Train Epoch: 4859 [256/118836 (0%)] Loss: 12155.623047\n",
      "Train Epoch: 4859 [33024/118836 (28%)] Loss: 12131.228516\n",
      "Train Epoch: 4859 [65792/118836 (55%)] Loss: 12178.979492\n",
      "Train Epoch: 4859 [98560/118836 (83%)] Loss: 12164.925781\n",
      "    epoch          : 4859\n",
      "    loss           : 12171.297627494314\n",
      "    val_loss       : 12169.232733156416\n",
      "    val_log_likelihood: -12095.083198116989\n",
      "    val_log_marginal: -12103.93626217384\n",
      "Train Epoch: 4860 [256/118836 (0%)] Loss: 12230.557617\n",
      "Train Epoch: 4860 [33024/118836 (28%)] Loss: 12257.148438\n",
      "Train Epoch: 4860 [65792/118836 (55%)] Loss: 12281.936523\n",
      "Train Epoch: 4860 [98560/118836 (83%)] Loss: 12155.022461\n",
      "    epoch          : 4860\n",
      "    loss           : 12171.855446133168\n",
      "    val_loss       : 12172.037974482057\n",
      "    val_log_likelihood: -12089.51686569479\n",
      "    val_log_marginal: -12098.440090560041\n",
      "Train Epoch: 4861 [256/118836 (0%)] Loss: 12241.577148\n",
      "Train Epoch: 4861 [33024/118836 (28%)] Loss: 12135.815430\n",
      "Train Epoch: 4861 [65792/118836 (55%)] Loss: 12243.680664\n",
      "Train Epoch: 4861 [98560/118836 (83%)] Loss: 12312.538086\n",
      "    epoch          : 4861\n",
      "    loss           : 12177.864793346775\n",
      "    val_loss       : 12174.555865027423\n",
      "    val_log_likelihood: -12093.022798736043\n",
      "    val_log_marginal: -12102.096398508766\n",
      "Train Epoch: 4862 [256/118836 (0%)] Loss: 12152.517578\n",
      "Train Epoch: 4862 [33024/118836 (28%)] Loss: 12164.324219\n",
      "Train Epoch: 4862 [65792/118836 (55%)] Loss: 12231.257812\n",
      "Train Epoch: 4862 [98560/118836 (83%)] Loss: 12134.594727\n",
      "    epoch          : 4862\n",
      "    loss           : 12172.853497531534\n",
      "    val_loss       : 12176.168508622239\n",
      "    val_log_likelihood: -12093.355730620606\n",
      "    val_log_marginal: -12102.345969284099\n",
      "Train Epoch: 4863 [256/118836 (0%)] Loss: 12142.586914\n",
      "Train Epoch: 4863 [33024/118836 (28%)] Loss: 12216.810547\n",
      "Train Epoch: 4863 [65792/118836 (55%)] Loss: 12236.184570\n",
      "Train Epoch: 4863 [98560/118836 (83%)] Loss: 12103.689453\n",
      "    epoch          : 4863\n",
      "    loss           : 12174.315460381773\n",
      "    val_loss       : 12173.209716152376\n",
      "    val_log_likelihood: -12092.287468821081\n",
      "    val_log_marginal: -12101.284901961631\n",
      "Train Epoch: 4864 [256/118836 (0%)] Loss: 12175.224609\n",
      "Train Epoch: 4864 [33024/118836 (28%)] Loss: 12214.817383\n",
      "Train Epoch: 4864 [65792/118836 (55%)] Loss: 12146.483398\n",
      "Train Epoch: 4864 [98560/118836 (83%)] Loss: 12167.699219\n",
      "    epoch          : 4864\n",
      "    loss           : 12174.631726730511\n",
      "    val_loss       : 12175.680327739792\n",
      "    val_log_likelihood: -12093.222515217898\n",
      "    val_log_marginal: -12102.203771926404\n",
      "Train Epoch: 4865 [256/118836 (0%)] Loss: 12206.878906\n",
      "Train Epoch: 4865 [33024/118836 (28%)] Loss: 12137.630859\n",
      "Train Epoch: 4865 [65792/118836 (55%)] Loss: 12185.803711\n",
      "Train Epoch: 4865 [98560/118836 (83%)] Loss: 12227.221680\n",
      "    epoch          : 4865\n",
      "    loss           : 12171.484538810484\n",
      "    val_loss       : 12173.94116589378\n",
      "    val_log_likelihood: -12093.056753224515\n",
      "    val_log_marginal: -12101.94753080352\n",
      "Train Epoch: 4866 [256/118836 (0%)] Loss: 12156.992188\n",
      "Train Epoch: 4866 [33024/118836 (28%)] Loss: 12149.315430\n",
      "Train Epoch: 4866 [65792/118836 (55%)] Loss: 12332.666992\n",
      "Train Epoch: 4866 [98560/118836 (83%)] Loss: 12166.189453\n",
      "    epoch          : 4866\n",
      "    loss           : 12185.208129620296\n",
      "    val_loss       : 12178.97428496887\n",
      "    val_log_likelihood: -12099.93181008969\n",
      "    val_log_marginal: -12109.046457730627\n",
      "Train Epoch: 4867 [256/118836 (0%)] Loss: 12227.036133\n",
      "Train Epoch: 4867 [33024/118836 (28%)] Loss: 12244.214844\n",
      "Train Epoch: 4867 [65792/118836 (55%)] Loss: 12145.357422\n",
      "Train Epoch: 4867 [98560/118836 (83%)] Loss: 12142.923828\n",
      "    epoch          : 4867\n",
      "    loss           : 12176.843785540736\n",
      "    val_loss       : 12183.019370126729\n",
      "    val_log_likelihood: -12094.262252507237\n",
      "    val_log_marginal: -12103.435622785102\n",
      "Train Epoch: 4868 [256/118836 (0%)] Loss: 12197.515625\n",
      "Train Epoch: 4868 [33024/118836 (28%)] Loss: 12229.373047\n",
      "Train Epoch: 4868 [65792/118836 (55%)] Loss: 12253.500000\n",
      "Train Epoch: 4868 [98560/118836 (83%)] Loss: 12164.870117\n",
      "    epoch          : 4868\n",
      "    loss           : 12176.101201276882\n",
      "    val_loss       : 12172.108205991857\n",
      "    val_log_likelihood: -12093.78577724359\n",
      "    val_log_marginal: -12102.901112357496\n",
      "Train Epoch: 4869 [256/118836 (0%)] Loss: 12165.973633\n",
      "Train Epoch: 4869 [33024/118836 (28%)] Loss: 12215.072266\n",
      "Train Epoch: 4869 [65792/118836 (55%)] Loss: 12267.002930\n",
      "Train Epoch: 4869 [98560/118836 (83%)] Loss: 12235.091797\n",
      "    epoch          : 4869\n",
      "    loss           : 12172.115304487179\n",
      "    val_loss       : 12170.541072518208\n",
      "    val_log_likelihood: -12091.591231454198\n",
      "    val_log_marginal: -12100.55665128993\n",
      "Train Epoch: 4870 [256/118836 (0%)] Loss: 12226.998047\n",
      "Train Epoch: 4870 [33024/118836 (28%)] Loss: 12182.473633\n",
      "Train Epoch: 4870 [65792/118836 (55%)] Loss: 12253.125000\n",
      "Train Epoch: 4870 [98560/118836 (83%)] Loss: 12221.726562\n",
      "    epoch          : 4870\n",
      "    loss           : 12179.258098764476\n",
      "    val_loss       : 12173.115009140636\n",
      "    val_log_likelihood: -12093.31743402347\n",
      "    val_log_marginal: -12102.16454653389\n",
      "Train Epoch: 4871 [256/118836 (0%)] Loss: 12141.404297\n",
      "Train Epoch: 4871 [33024/118836 (28%)] Loss: 12160.884766\n",
      "Train Epoch: 4871 [65792/118836 (55%)] Loss: 12213.083984\n",
      "Train Epoch: 4871 [98560/118836 (83%)] Loss: 12224.846680\n",
      "    epoch          : 4871\n",
      "    loss           : 12174.906533841242\n",
      "    val_loss       : 12173.793692626261\n",
      "    val_log_likelihood: -12096.468543540632\n",
      "    val_log_marginal: -12105.431385166581\n",
      "Train Epoch: 4872 [256/118836 (0%)] Loss: 12198.996094\n",
      "Train Epoch: 4872 [33024/118836 (28%)] Loss: 12109.683594\n",
      "Train Epoch: 4872 [65792/118836 (55%)] Loss: 12138.601562\n",
      "Train Epoch: 4872 [98560/118836 (83%)] Loss: 12175.717773\n",
      "    epoch          : 4872\n",
      "    loss           : 12176.41068952259\n",
      "    val_loss       : 12173.803501433234\n",
      "    val_log_likelihood: -12091.269521072425\n",
      "    val_log_marginal: -12100.269675560707\n",
      "Train Epoch: 4873 [256/118836 (0%)] Loss: 12173.399414\n",
      "Train Epoch: 4873 [33024/118836 (28%)] Loss: 12144.469727\n",
      "Train Epoch: 4873 [65792/118836 (55%)] Loss: 12272.994141\n",
      "Train Epoch: 4873 [98560/118836 (83%)] Loss: 12274.226562\n",
      "    epoch          : 4873\n",
      "    loss           : 12176.244121400694\n",
      "    val_loss       : 12175.47214213989\n",
      "    val_log_likelihood: -12095.00011324571\n",
      "    val_log_marginal: -12104.161937248185\n",
      "Train Epoch: 4874 [256/118836 (0%)] Loss: 12308.359375\n",
      "Train Epoch: 4874 [33024/118836 (28%)] Loss: 12293.379883\n",
      "Train Epoch: 4874 [65792/118836 (55%)] Loss: 12264.328125\n",
      "Train Epoch: 4874 [98560/118836 (83%)] Loss: 12155.703125\n",
      "    epoch          : 4874\n",
      "    loss           : 12174.901901590933\n",
      "    val_loss       : 12172.345098764781\n",
      "    val_log_likelihood: -12094.246397784844\n",
      "    val_log_marginal: -12103.245053004137\n",
      "Train Epoch: 4875 [256/118836 (0%)] Loss: 12113.279297\n",
      "Train Epoch: 4875 [33024/118836 (28%)] Loss: 12198.365234\n",
      "Train Epoch: 4875 [65792/118836 (55%)] Loss: 12164.935547\n",
      "Train Epoch: 4875 [98560/118836 (83%)] Loss: 12294.106445\n",
      "    epoch          : 4875\n",
      "    loss           : 12178.377809979838\n",
      "    val_loss       : 12174.427909025679\n",
      "    val_log_likelihood: -12093.694673251397\n",
      "    val_log_marginal: -12102.638304860333\n",
      "Train Epoch: 4876 [256/118836 (0%)] Loss: 12218.947266\n",
      "Train Epoch: 4876 [33024/118836 (28%)] Loss: 12182.201172\n",
      "Train Epoch: 4876 [65792/118836 (55%)] Loss: 12153.072266\n",
      "Train Epoch: 4876 [98560/118836 (83%)] Loss: 12150.357422\n",
      "    epoch          : 4876\n",
      "    loss           : 12172.046750768974\n",
      "    val_loss       : 12172.999519210838\n",
      "    val_log_likelihood: -12091.280408007651\n",
      "    val_log_marginal: -12100.097184860679\n",
      "Train Epoch: 4877 [256/118836 (0%)] Loss: 12246.900391\n",
      "Train Epoch: 4877 [33024/118836 (28%)] Loss: 12133.583984\n",
      "Train Epoch: 4877 [65792/118836 (55%)] Loss: 12229.825195\n",
      "Train Epoch: 4877 [98560/118836 (83%)] Loss: 12145.775391\n",
      "    epoch          : 4877\n",
      "    loss           : 12180.127514022437\n",
      "    val_loss       : 12171.192620692416\n",
      "    val_log_likelihood: -12095.321461111973\n",
      "    val_log_marginal: -12104.276153285136\n",
      "Train Epoch: 4878 [256/118836 (0%)] Loss: 12145.048828\n",
      "Train Epoch: 4878 [33024/118836 (28%)] Loss: 12220.796875\n",
      "Train Epoch: 4878 [65792/118836 (55%)] Loss: 12341.612305\n",
      "Train Epoch: 4878 [98560/118836 (83%)] Loss: 12188.298828\n",
      "    epoch          : 4878\n",
      "    loss           : 12173.606154040013\n",
      "    val_loss       : 12179.426935847836\n",
      "    val_log_likelihood: -12094.8666151326\n",
      "    val_log_marginal: -12103.860001778541\n",
      "Train Epoch: 4879 [256/118836 (0%)] Loss: 12343.629883\n",
      "Train Epoch: 4879 [33024/118836 (28%)] Loss: 12150.430664\n",
      "Train Epoch: 4879 [65792/118836 (55%)] Loss: 12224.517578\n",
      "Train Epoch: 4879 [98560/118836 (83%)] Loss: 12194.009766\n",
      "    epoch          : 4879\n",
      "    loss           : 12176.739263951355\n",
      "    val_loss       : 12179.546791455708\n",
      "    val_log_likelihood: -12094.60182905552\n",
      "    val_log_marginal: -12103.655047502605\n",
      "Train Epoch: 4880 [256/118836 (0%)] Loss: 12126.981445\n",
      "Train Epoch: 4880 [33024/118836 (28%)] Loss: 12242.655273\n",
      "Train Epoch: 4880 [65792/118836 (55%)] Loss: 12307.677734\n",
      "Train Epoch: 4880 [98560/118836 (83%)] Loss: 12224.776367\n",
      "    epoch          : 4880\n",
      "    loss           : 12174.033140605614\n",
      "    val_loss       : 12171.324813550404\n",
      "    val_log_likelihood: -12089.300180934655\n",
      "    val_log_marginal: -12098.306175555259\n",
      "Train Epoch: 4881 [256/118836 (0%)] Loss: 12245.695312\n",
      "Train Epoch: 4881 [33024/118836 (28%)] Loss: 12155.263672\n",
      "Train Epoch: 4881 [65792/118836 (55%)] Loss: 12325.533203\n",
      "Train Epoch: 4881 [98560/118836 (83%)] Loss: 12277.246094\n",
      "    epoch          : 4881\n",
      "    loss           : 12176.247260940085\n",
      "    val_loss       : 12172.87439838892\n",
      "    val_log_likelihood: -12093.092847265301\n",
      "    val_log_marginal: -12102.07964105465\n",
      "Train Epoch: 4882 [256/118836 (0%)] Loss: 12206.005859\n",
      "Train Epoch: 4882 [33024/118836 (28%)] Loss: 12142.908203\n",
      "Train Epoch: 4882 [65792/118836 (55%)] Loss: 12196.380859\n",
      "Train Epoch: 4882 [98560/118836 (83%)] Loss: 12156.708008\n",
      "    epoch          : 4882\n",
      "    loss           : 12172.078833229942\n",
      "    val_loss       : 12174.714171131729\n",
      "    val_log_likelihood: -12091.435617471827\n",
      "    val_log_marginal: -12100.430448691137\n",
      "Train Epoch: 4883 [256/118836 (0%)] Loss: 12143.978516\n",
      "Train Epoch: 4883 [33024/118836 (28%)] Loss: 12243.417969\n",
      "Train Epoch: 4883 [65792/118836 (55%)] Loss: 12138.710938\n",
      "Train Epoch: 4883 [98560/118836 (83%)] Loss: 12214.250000\n",
      "    epoch          : 4883\n",
      "    loss           : 12172.69784219267\n",
      "    val_loss       : 12171.779129284052\n",
      "    val_log_likelihood: -12093.860078706577\n",
      "    val_log_marginal: -12102.931882773471\n",
      "Train Epoch: 4884 [256/118836 (0%)] Loss: 12158.101562\n",
      "Train Epoch: 4884 [33024/118836 (28%)] Loss: 12192.208984\n",
      "Train Epoch: 4884 [65792/118836 (55%)] Loss: 12130.580078\n",
      "Train Epoch: 4884 [98560/118836 (83%)] Loss: 12176.531250\n",
      "    epoch          : 4884\n",
      "    loss           : 12184.160123455593\n",
      "    val_loss       : 12178.294138259093\n",
      "    val_log_likelihood: -12098.575764448924\n",
      "    val_log_marginal: -12107.669233135925\n",
      "Train Epoch: 4885 [256/118836 (0%)] Loss: 12313.715820\n",
      "Train Epoch: 4885 [33024/118836 (28%)] Loss: 12267.283203\n",
      "Train Epoch: 4885 [65792/118836 (55%)] Loss: 12139.751953\n",
      "Train Epoch: 4885 [98560/118836 (83%)] Loss: 12164.693359\n",
      "    epoch          : 4885\n",
      "    loss           : 12175.294497970946\n",
      "    val_loss       : 12182.09221082457\n",
      "    val_log_likelihood: -12103.080615274763\n",
      "    val_log_marginal: -12112.178251748448\n",
      "Train Epoch: 4886 [256/118836 (0%)] Loss: 12324.848633\n",
      "Train Epoch: 4886 [33024/118836 (28%)] Loss: 12150.109375\n",
      "Train Epoch: 4886 [65792/118836 (55%)] Loss: 12213.236328\n",
      "Train Epoch: 4886 [98560/118836 (83%)] Loss: 12193.469727\n",
      "    epoch          : 4886\n",
      "    loss           : 12174.105405099772\n",
      "    val_loss       : 12176.857755327213\n",
      "    val_log_likelihood: -12095.482136741366\n",
      "    val_log_marginal: -12104.522451400882\n",
      "Train Epoch: 4887 [256/118836 (0%)] Loss: 12170.453125\n",
      "Train Epoch: 4887 [33024/118836 (28%)] Loss: 12115.997070\n",
      "Train Epoch: 4887 [65792/118836 (55%)] Loss: 12231.906250\n",
      "Train Epoch: 4887 [98560/118836 (83%)] Loss: 12135.032227\n",
      "    epoch          : 4887\n",
      "    loss           : 12174.592453570875\n",
      "    val_loss       : 12174.328123005285\n",
      "    val_log_likelihood: -12093.999113258633\n",
      "    val_log_marginal: -12103.068034453709\n",
      "Train Epoch: 4888 [256/118836 (0%)] Loss: 12124.799805\n",
      "Train Epoch: 4888 [33024/118836 (28%)] Loss: 12155.432617\n",
      "Train Epoch: 4888 [65792/118836 (55%)] Loss: 12322.484375\n",
      "Train Epoch: 4888 [98560/118836 (83%)] Loss: 12212.455078\n",
      "    epoch          : 4888\n",
      "    loss           : 12174.835409720068\n",
      "    val_loss       : 12168.318782374105\n",
      "    val_log_likelihood: -12091.567207047405\n",
      "    val_log_marginal: -12100.489673650498\n",
      "Train Epoch: 4889 [256/118836 (0%)] Loss: 12186.099609\n",
      "Train Epoch: 4889 [33024/118836 (28%)] Loss: 12093.126953\n",
      "Train Epoch: 4889 [65792/118836 (55%)] Loss: 12142.487305\n",
      "Train Epoch: 4889 [98560/118836 (83%)] Loss: 12126.140625\n",
      "    epoch          : 4889\n",
      "    loss           : 12179.240446003929\n",
      "    val_loss       : 12172.803408327416\n",
      "    val_log_likelihood: -12095.476390288979\n",
      "    val_log_marginal: -12104.337811800702\n",
      "Train Epoch: 4890 [256/118836 (0%)] Loss: 12204.449219\n",
      "Train Epoch: 4890 [33024/118836 (28%)] Loss: 12151.816406\n",
      "Train Epoch: 4890 [65792/118836 (55%)] Loss: 12163.282227\n",
      "Train Epoch: 4890 [98560/118836 (83%)] Loss: 12197.488281\n",
      "    epoch          : 4890\n",
      "    loss           : 12174.855394114455\n",
      "    val_loss       : 12166.973092514696\n",
      "    val_log_likelihood: -12094.631421726375\n",
      "    val_log_marginal: -12103.561570431717\n",
      "Train Epoch: 4891 [256/118836 (0%)] Loss: 12264.691406\n",
      "Train Epoch: 4891 [33024/118836 (28%)] Loss: 12115.354492\n",
      "Train Epoch: 4891 [65792/118836 (55%)] Loss: 12241.458984\n",
      "Train Epoch: 4891 [98560/118836 (83%)] Loss: 12227.361328\n",
      "    epoch          : 4891\n",
      "    loss           : 12169.782723001963\n",
      "    val_loss       : 12169.69419864943\n",
      "    val_log_likelihood: -12094.793493945152\n",
      "    val_log_marginal: -12103.717206385256\n",
      "Train Epoch: 4892 [256/118836 (0%)] Loss: 12246.793945\n",
      "Train Epoch: 4892 [33024/118836 (28%)] Loss: 12117.234375\n",
      "Train Epoch: 4892 [65792/118836 (55%)] Loss: 12280.082031\n",
      "Train Epoch: 4892 [98560/118836 (83%)] Loss: 12258.711914\n",
      "    epoch          : 4892\n",
      "    loss           : 12174.55517117711\n",
      "    val_loss       : 12172.549686470764\n",
      "    val_log_likelihood: -12092.404388634719\n",
      "    val_log_marginal: -12101.279077107445\n",
      "Train Epoch: 4893 [256/118836 (0%)] Loss: 12216.597656\n",
      "Train Epoch: 4893 [33024/118836 (28%)] Loss: 12162.151367\n",
      "Train Epoch: 4893 [65792/118836 (55%)] Loss: 12200.720703\n",
      "Train Epoch: 4893 [98560/118836 (83%)] Loss: 12237.821289\n",
      "    epoch          : 4893\n",
      "    loss           : 12173.432566945823\n",
      "    val_loss       : 12175.46660666507\n",
      "    val_log_likelihood: -12092.750767518351\n",
      "    val_log_marginal: -12101.557961531698\n",
      "Train Epoch: 4894 [256/118836 (0%)] Loss: 12139.113281\n",
      "Train Epoch: 4894 [33024/118836 (28%)] Loss: 12135.552734\n",
      "Train Epoch: 4894 [65792/118836 (55%)] Loss: 12223.391602\n",
      "Train Epoch: 4894 [98560/118836 (83%)] Loss: 12167.992188\n",
      "    epoch          : 4894\n",
      "    loss           : 12168.779624334418\n",
      "    val_loss       : 12170.840688400782\n",
      "    val_log_likelihood: -12095.326697393248\n",
      "    val_log_marginal: -12104.290778472754\n",
      "Train Epoch: 4895 [256/118836 (0%)] Loss: 12144.482422\n",
      "Train Epoch: 4895 [33024/118836 (28%)] Loss: 12200.421875\n",
      "Train Epoch: 4895 [65792/118836 (55%)] Loss: 12292.892578\n",
      "Train Epoch: 4895 [98560/118836 (83%)] Loss: 12185.583008\n",
      "    epoch          : 4895\n",
      "    loss           : 12170.960023456886\n",
      "    val_loss       : 12170.350944274885\n",
      "    val_log_likelihood: -12093.911455102358\n",
      "    val_log_marginal: -12102.788474752919\n",
      "Train Epoch: 4896 [256/118836 (0%)] Loss: 12162.017578\n",
      "Train Epoch: 4896 [33024/118836 (28%)] Loss: 12211.187500\n",
      "Train Epoch: 4896 [65792/118836 (55%)] Loss: 12173.033203\n",
      "Train Epoch: 4896 [98560/118836 (83%)] Loss: 12211.605469\n",
      "    epoch          : 4896\n",
      "    loss           : 12171.600452336641\n",
      "    val_loss       : 12173.748327582845\n",
      "    val_log_likelihood: -12091.63117164883\n",
      "    val_log_marginal: -12100.423425134832\n",
      "Train Epoch: 4897 [256/118836 (0%)] Loss: 12190.673828\n",
      "Train Epoch: 4897 [33024/118836 (28%)] Loss: 12215.221680\n",
      "Train Epoch: 4897 [65792/118836 (55%)] Loss: 12136.324219\n",
      "Train Epoch: 4897 [98560/118836 (83%)] Loss: 12191.343750\n",
      "    epoch          : 4897\n",
      "    loss           : 12174.868851937294\n",
      "    val_loss       : 12171.721638436038\n",
      "    val_log_likelihood: -12091.582849010028\n",
      "    val_log_marginal: -12100.452414469326\n",
      "Train Epoch: 4898 [256/118836 (0%)] Loss: 12244.776367\n",
      "Train Epoch: 4898 [33024/118836 (28%)] Loss: 12183.420898\n",
      "Train Epoch: 4898 [65792/118836 (55%)] Loss: 12344.642578\n",
      "Train Epoch: 4898 [98560/118836 (83%)] Loss: 12171.474609\n",
      "    epoch          : 4898\n",
      "    loss           : 12175.520721864661\n",
      "    val_loss       : 12171.41286174571\n",
      "    val_log_likelihood: -12092.123691131617\n",
      "    val_log_marginal: -12100.976744269901\n",
      "Train Epoch: 4899 [256/118836 (0%)] Loss: 12129.044922\n",
      "Train Epoch: 4899 [33024/118836 (28%)] Loss: 12146.557617\n",
      "Train Epoch: 4899 [65792/118836 (55%)] Loss: 12124.601562\n",
      "Train Epoch: 4899 [98560/118836 (83%)] Loss: 12165.265625\n",
      "    epoch          : 4899\n",
      "    loss           : 12174.380024652348\n",
      "    val_loss       : 12171.860416116815\n",
      "    val_log_likelihood: -12095.642459063534\n",
      "    val_log_marginal: -12104.640725658242\n",
      "Train Epoch: 4900 [256/118836 (0%)] Loss: 12158.002930\n",
      "Train Epoch: 4900 [33024/118836 (28%)] Loss: 12095.521484\n",
      "Train Epoch: 4900 [65792/118836 (55%)] Loss: 12189.268555\n",
      "Train Epoch: 4900 [98560/118836 (83%)] Loss: 12103.179688\n",
      "    epoch          : 4900\n",
      "    loss           : 12174.321720882444\n",
      "    val_loss       : 12170.87829084056\n",
      "    val_log_likelihood: -12098.109572251085\n",
      "    val_log_marginal: -12107.100856843925\n",
      "Saving checkpoint: saved/models/SelfiesAutoencodingOperad/0905_154251/checkpoint-epoch4900.pth ...\n",
      "Train Epoch: 4901 [256/118836 (0%)] Loss: 12339.644531\n",
      "Train Epoch: 4901 [33024/118836 (28%)] Loss: 12115.029297\n",
      "Train Epoch: 4901 [65792/118836 (55%)] Loss: 12165.445312\n",
      "Train Epoch: 4901 [98560/118836 (83%)] Loss: 12184.394531\n",
      "    epoch          : 4901\n",
      "    loss           : 12174.565896725082\n",
      "    val_loss       : 12171.877712261254\n",
      "    val_log_likelihood: -12090.871801818392\n",
      "    val_log_marginal: -12099.750984794582\n",
      "Train Epoch: 4902 [256/118836 (0%)] Loss: 12144.841797\n",
      "Train Epoch: 4902 [33024/118836 (28%)] Loss: 12168.762695\n",
      "Train Epoch: 4902 [65792/118836 (55%)] Loss: 12176.339844\n",
      "Train Epoch: 4902 [98560/118836 (83%)] Loss: 12155.412109\n",
      "    epoch          : 4902\n",
      "    loss           : 12178.201732126241\n",
      "    val_loss       : 12179.262186087295\n",
      "    val_log_likelihood: -12094.05463774297\n",
      "    val_log_marginal: -12103.127150090455\n",
      "Train Epoch: 4903 [256/118836 (0%)] Loss: 12130.990234\n",
      "Train Epoch: 4903 [33024/118836 (28%)] Loss: 12177.259766\n",
      "Train Epoch: 4903 [65792/118836 (55%)] Loss: 12174.999023\n",
      "Train Epoch: 4903 [98560/118836 (83%)] Loss: 12264.857422\n",
      "    epoch          : 4903\n",
      "    loss           : 12174.37765634693\n",
      "    val_loss       : 12180.444165368426\n",
      "    val_log_likelihood: -12093.887025208074\n",
      "    val_log_marginal: -12103.041441612944\n",
      "Train Epoch: 4904 [256/118836 (0%)] Loss: 12246.653320\n",
      "Train Epoch: 4904 [33024/118836 (28%)] Loss: 12177.332031\n",
      "Train Epoch: 4904 [65792/118836 (55%)] Loss: 12266.240234\n",
      "Train Epoch: 4904 [98560/118836 (83%)] Loss: 12151.038086\n",
      "    epoch          : 4904\n",
      "    loss           : 12170.547123785153\n",
      "    val_loss       : 12173.178544886303\n",
      "    val_log_likelihood: -12095.627646977098\n",
      "    val_log_marginal: -12104.597412188445\n",
      "Train Epoch: 4905 [256/118836 (0%)] Loss: 12201.166016\n",
      "Train Epoch: 4905 [33024/118836 (28%)] Loss: 12140.743164\n",
      "Train Epoch: 4905 [65792/118836 (55%)] Loss: 12273.287109\n",
      "Train Epoch: 4905 [98560/118836 (83%)] Loss: 12171.900391\n",
      "    epoch          : 4905\n",
      "    loss           : 12174.328231299112\n",
      "    val_loss       : 12167.732943181774\n",
      "    val_log_likelihood: -12093.715050047818\n",
      "    val_log_marginal: -12102.642329544298\n",
      "Train Epoch: 4906 [256/118836 (0%)] Loss: 12169.615234\n",
      "Train Epoch: 4906 [33024/118836 (28%)] Loss: 12225.594727\n",
      "Train Epoch: 4906 [65792/118836 (55%)] Loss: 12188.164062\n",
      "Train Epoch: 4906 [98560/118836 (83%)] Loss: 12236.861328\n",
      "    epoch          : 4906\n",
      "    loss           : 12174.620002326303\n",
      "    val_loss       : 12179.985972399341\n",
      "    val_log_likelihood: -12096.76806454844\n",
      "    val_log_marginal: -12105.88519984833\n",
      "Train Epoch: 4907 [256/118836 (0%)] Loss: 12266.642578\n",
      "Train Epoch: 4907 [33024/118836 (28%)] Loss: 12208.574219\n",
      "Train Epoch: 4907 [65792/118836 (55%)] Loss: 12222.924805\n",
      "Train Epoch: 4907 [98560/118836 (83%)] Loss: 12222.960938\n",
      "    epoch          : 4907\n",
      "    loss           : 12172.966567475703\n",
      "    val_loss       : 12175.415989863173\n",
      "    val_log_likelihood: -12094.963470423647\n",
      "    val_log_marginal: -12104.03658383055\n",
      "Train Epoch: 4908 [256/118836 (0%)] Loss: 12088.529297\n",
      "Train Epoch: 4908 [33024/118836 (28%)] Loss: 12348.557617\n",
      "Train Epoch: 4908 [65792/118836 (55%)] Loss: 12168.445312\n",
      "Train Epoch: 4908 [98560/118836 (83%)] Loss: 12124.121094\n",
      "    epoch          : 4908\n",
      "    loss           : 12178.833156922043\n",
      "    val_loss       : 12173.226613677658\n",
      "    val_log_likelihood: -12093.386363019541\n",
      "    val_log_marginal: -12102.31608343904\n",
      "Train Epoch: 4909 [256/118836 (0%)] Loss: 12150.345703\n",
      "Train Epoch: 4909 [33024/118836 (28%)] Loss: 12281.628906\n",
      "Train Epoch: 4909 [65792/118836 (55%)] Loss: 12144.470703\n",
      "Train Epoch: 4909 [98560/118836 (83%)] Loss: 12159.373047\n",
      "    epoch          : 4909\n",
      "    loss           : 12170.721309094552\n",
      "    val_loss       : 12174.540009888866\n",
      "    val_log_likelihood: -12092.3646014268\n",
      "    val_log_marginal: -12101.353866616088\n",
      "Train Epoch: 4910 [256/118836 (0%)] Loss: 12210.413086\n",
      "Train Epoch: 4910 [33024/118836 (28%)] Loss: 12202.515625\n",
      "Train Epoch: 4910 [65792/118836 (55%)] Loss: 12264.314453\n",
      "Train Epoch: 4910 [98560/118836 (83%)] Loss: 12128.228516\n",
      "    epoch          : 4910\n",
      "    loss           : 12171.654223047199\n",
      "    val_loss       : 12175.868175058482\n",
      "    val_log_likelihood: -12092.81101423568\n",
      "    val_log_marginal: -12101.827781506807\n",
      "Train Epoch: 4911 [256/118836 (0%)] Loss: 12239.371094\n",
      "Train Epoch: 4911 [33024/118836 (28%)] Loss: 12224.529297\n",
      "Train Epoch: 4911 [65792/118836 (55%)] Loss: 12136.118164\n",
      "Train Epoch: 4911 [98560/118836 (83%)] Loss: 12152.008789\n",
      "    epoch          : 4911\n",
      "    loss           : 12177.950597892112\n",
      "    val_loss       : 12172.583141581168\n",
      "    val_log_likelihood: -12093.191246316688\n",
      "    val_log_marginal: -12102.076088280877\n",
      "Train Epoch: 4912 [256/118836 (0%)] Loss: 12192.743164\n",
      "Train Epoch: 4912 [33024/118836 (28%)] Loss: 12204.017578\n",
      "Train Epoch: 4912 [65792/118836 (55%)] Loss: 12140.419922\n",
      "Train Epoch: 4912 [98560/118836 (83%)] Loss: 12152.619141\n",
      "    epoch          : 4912\n",
      "    loss           : 12171.715574435224\n",
      "    val_loss       : 12179.346504008277\n",
      "    val_log_likelihood: -12094.029252449081\n",
      "    val_log_marginal: -12103.001569630022\n",
      "Train Epoch: 4913 [256/118836 (0%)] Loss: 12177.622070\n",
      "Train Epoch: 4913 [33024/118836 (28%)] Loss: 12292.611328\n",
      "Train Epoch: 4913 [65792/118836 (55%)] Loss: 12197.667969\n",
      "Train Epoch: 4913 [98560/118836 (83%)] Loss: 12184.178711\n",
      "    epoch          : 4913\n",
      "    loss           : 12177.073724410671\n",
      "    val_loss       : 12176.409924684722\n",
      "    val_log_likelihood: -12092.860434598584\n",
      "    val_log_marginal: -12102.051896542354\n",
      "Train Epoch: 4914 [256/118836 (0%)] Loss: 12129.025391\n",
      "Train Epoch: 4914 [33024/118836 (28%)] Loss: 12211.211914\n",
      "Train Epoch: 4914 [65792/118836 (55%)] Loss: 12180.499023\n",
      "Train Epoch: 4914 [98560/118836 (83%)] Loss: 12178.564453\n",
      "    epoch          : 4914\n",
      "    loss           : 12169.662550887871\n",
      "    val_loss       : 12172.879828835403\n",
      "    val_log_likelihood: -12089.770021712158\n",
      "    val_log_marginal: -12098.735702685539\n",
      "Train Epoch: 4915 [256/118836 (0%)] Loss: 12142.068359\n",
      "Train Epoch: 4915 [33024/118836 (28%)] Loss: 12230.675781\n",
      "Train Epoch: 4915 [65792/118836 (55%)] Loss: 12185.402344\n",
      "Train Epoch: 4915 [98560/118836 (83%)] Loss: 12213.365234\n",
      "    epoch          : 4915\n",
      "    loss           : 12169.560308105873\n",
      "    val_loss       : 12173.046264737111\n",
      "    val_log_likelihood: -12093.0759295518\n",
      "    val_log_marginal: -12101.905735869064\n",
      "Train Epoch: 4916 [256/118836 (0%)] Loss: 12240.226562\n",
      "Train Epoch: 4916 [33024/118836 (28%)] Loss: 12254.963867\n",
      "Train Epoch: 4916 [65792/118836 (55%)] Loss: 12139.658203\n",
      "Train Epoch: 4916 [98560/118836 (83%)] Loss: 12122.360352\n",
      "    epoch          : 4916\n",
      "    loss           : 12173.541016917392\n",
      "    val_loss       : 12171.37766289734\n",
      "    val_log_likelihood: -12092.685086784015\n",
      "    val_log_marginal: -12101.554881529917\n",
      "Train Epoch: 4917 [256/118836 (0%)] Loss: 12195.048828\n",
      "Train Epoch: 4917 [33024/118836 (28%)] Loss: 12165.146484\n",
      "Train Epoch: 4917 [65792/118836 (55%)] Loss: 12145.149414\n",
      "Train Epoch: 4917 [98560/118836 (83%)] Loss: 12276.883789\n",
      "    epoch          : 4917\n",
      "    loss           : 12173.40935206007\n",
      "    val_loss       : 12173.343074552868\n",
      "    val_log_likelihood: -12093.0160493887\n",
      "    val_log_marginal: -12101.821519253295\n",
      "Train Epoch: 4918 [256/118836 (0%)] Loss: 12187.827148\n",
      "Train Epoch: 4918 [33024/118836 (28%)] Loss: 12170.164062\n",
      "Train Epoch: 4918 [65792/118836 (55%)] Loss: 12343.118164\n",
      "Train Epoch: 4918 [98560/118836 (83%)] Loss: 12159.508789\n",
      "    epoch          : 4918\n",
      "    loss           : 12173.816559398263\n",
      "    val_loss       : 12170.559575512145\n",
      "    val_log_likelihood: -12092.857082784069\n",
      "    val_log_marginal: -12101.712997272607\n",
      "Train Epoch: 4919 [256/118836 (0%)] Loss: 12145.164062\n",
      "Train Epoch: 4919 [33024/118836 (28%)] Loss: 12206.113281\n",
      "Train Epoch: 4919 [65792/118836 (55%)] Loss: 12218.181641\n",
      "Train Epoch: 4919 [98560/118836 (83%)] Loss: 12190.279297\n",
      "    epoch          : 4919\n",
      "    loss           : 12167.828717076354\n",
      "    val_loss       : 12173.59426135707\n",
      "    val_log_likelihood: -12092.57866118047\n",
      "    val_log_marginal: -12101.522019143076\n",
      "Train Epoch: 4920 [256/118836 (0%)] Loss: 12235.984375\n",
      "Train Epoch: 4920 [33024/118836 (28%)] Loss: 12152.286133\n",
      "Train Epoch: 4920 [65792/118836 (55%)] Loss: 12239.130859\n",
      "Train Epoch: 4920 [98560/118836 (83%)] Loss: 12247.609375\n",
      "    epoch          : 4920\n",
      "    loss           : 12179.061631675197\n",
      "    val_loss       : 12173.356285627555\n",
      "    val_log_likelihood: -12093.631700721155\n",
      "    val_log_marginal: -12102.57654724107\n",
      "Train Epoch: 4921 [256/118836 (0%)] Loss: 12180.703125\n",
      "Train Epoch: 4921 [33024/118836 (28%)] Loss: 12261.135742\n",
      "Train Epoch: 4921 [65792/118836 (55%)] Loss: 12214.546875\n",
      "Train Epoch: 4921 [98560/118836 (83%)] Loss: 12254.112305\n",
      "    epoch          : 4921\n",
      "    loss           : 12176.336152198355\n",
      "    val_loss       : 12175.818706771362\n",
      "    val_log_likelihood: -12094.29427681064\n",
      "    val_log_marginal: -12103.352761512115\n",
      "Train Epoch: 4922 [256/118836 (0%)] Loss: 12217.213867\n",
      "Train Epoch: 4922 [33024/118836 (28%)] Loss: 12179.285156\n",
      "Train Epoch: 4922 [65792/118836 (55%)] Loss: 12267.642578\n",
      "Train Epoch: 4922 [98560/118836 (83%)] Loss: 12088.301758\n",
      "    epoch          : 4922\n",
      "    loss           : 12172.770654660359\n",
      "    val_loss       : 12177.539651752872\n",
      "    val_log_likelihood: -12093.726427929849\n",
      "    val_log_marginal: -12102.65133624144\n",
      "Train Epoch: 4923 [256/118836 (0%)] Loss: 12110.113281\n",
      "Train Epoch: 4923 [33024/118836 (28%)] Loss: 12178.061523\n",
      "Train Epoch: 4923 [65792/118836 (55%)] Loss: 12189.916992\n",
      "Train Epoch: 4923 [98560/118836 (83%)] Loss: 12163.695312\n",
      "    epoch          : 4923\n",
      "    loss           : 12174.467478610939\n",
      "    val_loss       : 12173.807478157423\n",
      "    val_log_likelihood: -12093.375632463554\n",
      "    val_log_marginal: -12102.403960429878\n",
      "Train Epoch: 4924 [256/118836 (0%)] Loss: 12152.255859\n",
      "Train Epoch: 4924 [33024/118836 (28%)] Loss: 12156.443359\n",
      "Train Epoch: 4924 [65792/118836 (55%)] Loss: 12161.563477\n",
      "Train Epoch: 4924 [98560/118836 (83%)] Loss: 12332.810547\n",
      "    epoch          : 4924\n",
      "    loss           : 12177.875863801437\n",
      "    val_loss       : 12174.417654235445\n",
      "    val_log_likelihood: -12091.656706375363\n",
      "    val_log_marginal: -12100.713465671988\n",
      "Train Epoch: 4925 [256/118836 (0%)] Loss: 12180.151367\n",
      "Train Epoch: 4925 [33024/118836 (28%)] Loss: 12147.156250\n",
      "Train Epoch: 4925 [65792/118836 (55%)] Loss: 12210.299805\n",
      "Train Epoch: 4925 [98560/118836 (83%)] Loss: 12088.036133\n",
      "    epoch          : 4925\n",
      "    loss           : 12172.812343297663\n",
      "    val_loss       : 12172.137210642903\n",
      "    val_log_likelihood: -12095.161706310742\n",
      "    val_log_marginal: -12104.221288411187\n",
      "Train Epoch: 4926 [256/118836 (0%)] Loss: 12210.291016\n",
      "Train Epoch: 4926 [33024/118836 (28%)] Loss: 12313.465820\n",
      "Train Epoch: 4926 [65792/118836 (55%)] Loss: 12203.652344\n",
      "Train Epoch: 4926 [98560/118836 (83%)] Loss: 12294.334961\n",
      "    epoch          : 4926\n",
      "    loss           : 12174.488069621071\n",
      "    val_loss       : 12169.154029891602\n",
      "    val_log_likelihood: -12095.541358916202\n",
      "    val_log_marginal: -12104.553831437073\n",
      "Train Epoch: 4927 [256/118836 (0%)] Loss: 12160.878906\n",
      "Train Epoch: 4927 [33024/118836 (28%)] Loss: 12159.258789\n",
      "Train Epoch: 4927 [65792/118836 (55%)] Loss: 12247.566406\n",
      "Train Epoch: 4927 [98560/118836 (83%)] Loss: 12286.792969\n",
      "    epoch          : 4927\n",
      "    loss           : 12175.426243118021\n",
      "    val_loss       : 12175.03729066099\n",
      "    val_log_likelihood: -12094.875558151107\n",
      "    val_log_marginal: -12103.826661394278\n",
      "Train Epoch: 4928 [256/118836 (0%)] Loss: 12133.606445\n",
      "Train Epoch: 4928 [33024/118836 (28%)] Loss: 12156.908203\n",
      "Train Epoch: 4928 [65792/118836 (55%)] Loss: 12237.705078\n",
      "Train Epoch: 4928 [98560/118836 (83%)] Loss: 12263.013672\n",
      "    epoch          : 4928\n",
      "    loss           : 12173.141578137926\n",
      "    val_loss       : 12172.690985582733\n",
      "    val_log_likelihood: -12093.735883865798\n",
      "    val_log_marginal: -12102.617827273742\n",
      "Train Epoch: 4929 [256/118836 (0%)] Loss: 12180.214844\n",
      "Train Epoch: 4929 [33024/118836 (28%)] Loss: 12167.343750\n",
      "Train Epoch: 4929 [65792/118836 (55%)] Loss: 12239.905273\n",
      "Train Epoch: 4929 [98560/118836 (83%)] Loss: 12203.370117\n",
      "    epoch          : 4929\n",
      "    loss           : 12175.025847808105\n",
      "    val_loss       : 12170.22288562441\n",
      "    val_log_likelihood: -12094.779851148935\n",
      "    val_log_marginal: -12103.801061569206\n",
      "Train Epoch: 4930 [256/118836 (0%)] Loss: 12170.824219\n",
      "Train Epoch: 4930 [33024/118836 (28%)] Loss: 12263.280273\n",
      "Train Epoch: 4930 [65792/118836 (55%)] Loss: 12141.313477\n",
      "Train Epoch: 4930 [98560/118836 (83%)] Loss: 12147.791992\n",
      "    epoch          : 4930\n",
      "    loss           : 12173.976463309036\n",
      "    val_loss       : 12176.46002172505\n",
      "    val_log_likelihood: -12090.048852680417\n",
      "    val_log_marginal: -12098.954591128848\n",
      "Train Epoch: 4931 [256/118836 (0%)] Loss: 12253.597656\n",
      "Train Epoch: 4931 [33024/118836 (28%)] Loss: 12168.219727\n",
      "Train Epoch: 4931 [65792/118836 (55%)] Loss: 12334.146484\n",
      "Train Epoch: 4931 [98560/118836 (83%)] Loss: 12104.208984\n",
      "    epoch          : 4931\n",
      "    loss           : 12170.998459955283\n",
      "    val_loss       : 12176.935515879957\n",
      "    val_log_likelihood: -12095.021839459265\n",
      "    val_log_marginal: -12103.905905230551\n",
      "Train Epoch: 4932 [256/118836 (0%)] Loss: 12185.700195\n",
      "Train Epoch: 4932 [33024/118836 (28%)] Loss: 12132.208984\n",
      "Train Epoch: 4932 [65792/118836 (55%)] Loss: 12178.223633\n",
      "Train Epoch: 4932 [98560/118836 (83%)] Loss: 12218.739258\n",
      "    epoch          : 4932\n",
      "    loss           : 12172.300758794718\n",
      "    val_loss       : 12176.124641147073\n",
      "    val_log_likelihood: -12091.806522855924\n",
      "    val_log_marginal: -12100.713820718423\n",
      "Train Epoch: 4933 [256/118836 (0%)] Loss: 12221.394531\n",
      "Train Epoch: 4933 [33024/118836 (28%)] Loss: 12111.453125\n",
      "Train Epoch: 4933 [65792/118836 (55%)] Loss: 12081.517578\n",
      "Train Epoch: 4933 [98560/118836 (83%)] Loss: 12212.243164\n",
      "    epoch          : 4933\n",
      "    loss           : 12172.57417561647\n",
      "    val_loss       : 12176.863112558287\n",
      "    val_log_likelihood: -12098.512371568704\n",
      "    val_log_marginal: -12107.507769132217\n",
      "Train Epoch: 4934 [256/118836 (0%)] Loss: 12144.896484\n",
      "Train Epoch: 4934 [33024/118836 (28%)] Loss: 12147.708984\n",
      "Train Epoch: 4934 [65792/118836 (55%)] Loss: 12160.608398\n",
      "Train Epoch: 4934 [98560/118836 (83%)] Loss: 12209.670898\n",
      "    epoch          : 4934\n",
      "    loss           : 12175.058698433624\n",
      "    val_loss       : 12173.884117722744\n",
      "    val_log_likelihood: -12095.684747531534\n",
      "    val_log_marginal: -12104.725916810556\n",
      "Train Epoch: 4935 [256/118836 (0%)] Loss: 12210.583008\n",
      "Train Epoch: 4935 [33024/118836 (28%)] Loss: 12200.568359\n",
      "Train Epoch: 4935 [65792/118836 (55%)] Loss: 12187.942383\n",
      "Train Epoch: 4935 [98560/118836 (83%)] Loss: 12127.142578\n",
      "    epoch          : 4935\n",
      "    loss           : 12175.792060684193\n",
      "    val_loss       : 12173.930016131102\n",
      "    val_log_likelihood: -12091.600551204507\n",
      "    val_log_marginal: -12100.60789419639\n",
      "Train Epoch: 4936 [256/118836 (0%)] Loss: 12115.876953\n",
      "Train Epoch: 4936 [33024/118836 (28%)] Loss: 12143.494141\n",
      "Train Epoch: 4936 [65792/118836 (55%)] Loss: 12154.407227\n",
      "Train Epoch: 4936 [98560/118836 (83%)] Loss: 12231.483398\n",
      "    epoch          : 4936\n",
      "    loss           : 12176.931561950734\n",
      "    val_loss       : 12172.72583087832\n",
      "    val_log_likelihood: -12093.72306836099\n",
      "    val_log_marginal: -12102.752745021913\n",
      "Train Epoch: 4937 [256/118836 (0%)] Loss: 12227.549805\n",
      "Train Epoch: 4937 [33024/118836 (28%)] Loss: 12299.466797\n",
      "Train Epoch: 4937 [65792/118836 (55%)] Loss: 12234.013672\n",
      "Train Epoch: 4937 [98560/118836 (83%)] Loss: 12205.344727\n",
      "    epoch          : 4937\n",
      "    loss           : 12173.123124095328\n",
      "    val_loss       : 12175.498893158585\n",
      "    val_log_likelihood: -12092.624697095998\n",
      "    val_log_marginal: -12101.651977714862\n",
      "Train Epoch: 4938 [256/118836 (0%)] Loss: 12191.613281\n",
      "Train Epoch: 4938 [33024/118836 (28%)] Loss: 12271.099609\n",
      "Train Epoch: 4938 [65792/118836 (55%)] Loss: 12153.628906\n",
      "Train Epoch: 4938 [98560/118836 (83%)] Loss: 12279.294922\n",
      "    epoch          : 4938\n",
      "    loss           : 12171.782964840519\n",
      "    val_loss       : 12172.470123006076\n",
      "    val_log_likelihood: -12090.850759925559\n",
      "    val_log_marginal: -12099.915043217063\n",
      "Train Epoch: 4939 [256/118836 (0%)] Loss: 12216.124023\n",
      "Train Epoch: 4939 [33024/118836 (28%)] Loss: 12143.179688\n",
      "Train Epoch: 4939 [65792/118836 (55%)] Loss: 12234.479492\n",
      "Train Epoch: 4939 [98560/118836 (83%)] Loss: 12169.968750\n",
      "    epoch          : 4939\n",
      "    loss           : 12173.657486817618\n",
      "    val_loss       : 12173.566572250915\n",
      "    val_log_likelihood: -12094.766172004238\n",
      "    val_log_marginal: -12103.861511143168\n",
      "Train Epoch: 4940 [256/118836 (0%)] Loss: 12178.480469\n",
      "Train Epoch: 4940 [33024/118836 (28%)] Loss: 12266.045898\n",
      "Train Epoch: 4940 [65792/118836 (55%)] Loss: 12302.976562\n",
      "Train Epoch: 4940 [98560/118836 (83%)] Loss: 12138.761719\n",
      "    epoch          : 4940\n",
      "    loss           : 12175.114929370864\n",
      "    val_loss       : 12174.639260901133\n",
      "    val_log_likelihood: -12093.699513576561\n",
      "    val_log_marginal: -12102.766895001892\n",
      "Train Epoch: 4941 [256/118836 (0%)] Loss: 12193.118164\n",
      "Train Epoch: 4941 [33024/118836 (28%)] Loss: 12194.726562\n",
      "Train Epoch: 4941 [65792/118836 (55%)] Loss: 12218.822266\n",
      "Train Epoch: 4941 [98560/118836 (83%)] Loss: 12271.566406\n",
      "    epoch          : 4941\n",
      "    loss           : 12170.550979955025\n",
      "    val_loss       : 12175.496524048103\n",
      "    val_log_likelihood: -12092.553903665219\n",
      "    val_log_marginal: -12101.55765090125\n",
      "Train Epoch: 4942 [256/118836 (0%)] Loss: 12222.598633\n",
      "Train Epoch: 4942 [33024/118836 (28%)] Loss: 12226.742188\n",
      "Train Epoch: 4942 [65792/118836 (55%)] Loss: 12158.128906\n",
      "Train Epoch: 4942 [98560/118836 (83%)] Loss: 12156.899414\n",
      "    epoch          : 4942\n",
      "    loss           : 12171.741757133996\n",
      "    val_loss       : 12176.16598431701\n",
      "    val_log_likelihood: -12096.752839220171\n",
      "    val_log_marginal: -12105.790452403202\n",
      "Train Epoch: 4943 [256/118836 (0%)] Loss: 12238.455078\n",
      "Train Epoch: 4943 [33024/118836 (28%)] Loss: 12181.524414\n",
      "Train Epoch: 4943 [65792/118836 (55%)] Loss: 12226.025391\n",
      "Train Epoch: 4943 [98560/118836 (83%)] Loss: 12185.562500\n",
      "    epoch          : 4943\n",
      "    loss           : 12174.955316894127\n",
      "    val_loss       : 12172.422213675634\n",
      "    val_log_likelihood: -12094.220838502895\n",
      "    val_log_marginal: -12103.326741514158\n",
      "Train Epoch: 4944 [256/118836 (0%)] Loss: 12207.511719\n",
      "Train Epoch: 4944 [33024/118836 (28%)] Loss: 12245.453125\n",
      "Train Epoch: 4944 [65792/118836 (55%)] Loss: 12182.945312\n",
      "Train Epoch: 4944 [98560/118836 (83%)] Loss: 12140.404297\n",
      "    epoch          : 4944\n",
      "    loss           : 12175.754673445255\n",
      "    val_loss       : 12172.309283727323\n",
      "    val_log_likelihood: -12091.74554416098\n",
      "    val_log_marginal: -12100.772014023822\n",
      "Train Epoch: 4945 [256/118836 (0%)] Loss: 12257.336914\n",
      "Train Epoch: 4945 [33024/118836 (28%)] Loss: 12156.372070\n",
      "Train Epoch: 4945 [65792/118836 (55%)] Loss: 12271.777344\n",
      "Train Epoch: 4945 [98560/118836 (83%)] Loss: 12112.782227\n",
      "    epoch          : 4945\n",
      "    loss           : 12176.022383394076\n",
      "    val_loss       : 12173.046214990762\n",
      "    val_log_likelihood: -12096.618916072168\n",
      "    val_log_marginal: -12105.73195000798\n",
      "Train Epoch: 4946 [256/118836 (0%)] Loss: 12121.297852\n",
      "Train Epoch: 4946 [33024/118836 (28%)] Loss: 12161.494141\n",
      "Train Epoch: 4946 [65792/118836 (55%)] Loss: 12131.740234\n",
      "Train Epoch: 4946 [98560/118836 (83%)] Loss: 12200.812500\n",
      "    epoch          : 4946\n",
      "    loss           : 12174.245403775072\n",
      "    val_loss       : 12176.754639676381\n",
      "    val_log_likelihood: -12094.536766568444\n",
      "    val_log_marginal: -12103.801461253976\n",
      "Train Epoch: 4947 [256/118836 (0%)] Loss: 12193.340820\n",
      "Train Epoch: 4947 [33024/118836 (28%)] Loss: 12202.944336\n",
      "Train Epoch: 4947 [65792/118836 (55%)] Loss: 12118.938477\n",
      "Train Epoch: 4947 [98560/118836 (83%)] Loss: 12112.137695\n",
      "    epoch          : 4947\n",
      "    loss           : 12172.400008885184\n",
      "    val_loss       : 12171.277312634902\n",
      "    val_log_likelihood: -12090.92420259512\n",
      "    val_log_marginal: -12099.929295313423\n",
      "Train Epoch: 4948 [256/118836 (0%)] Loss: 12265.338867\n",
      "Train Epoch: 4948 [33024/118836 (28%)] Loss: 12213.409180\n",
      "Train Epoch: 4948 [65792/118836 (55%)] Loss: 12153.798828\n",
      "Train Epoch: 4948 [98560/118836 (83%)] Loss: 12191.937500\n",
      "    epoch          : 4948\n",
      "    loss           : 12172.96573146066\n",
      "    val_loss       : 12171.868709223016\n",
      "    val_log_likelihood: -12094.8069640457\n",
      "    val_log_marginal: -12103.998100108256\n",
      "Train Epoch: 4949 [256/118836 (0%)] Loss: 12208.628906\n",
      "Train Epoch: 4949 [33024/118836 (28%)] Loss: 12182.097656\n",
      "Train Epoch: 4949 [65792/118836 (55%)] Loss: 12104.719727\n",
      "Train Epoch: 4949 [98560/118836 (83%)] Loss: 12123.500000\n",
      "    epoch          : 4949\n",
      "    loss           : 12172.785410043167\n",
      "    val_loss       : 12170.663823618974\n",
      "    val_log_likelihood: -12093.908960950424\n",
      "    val_log_marginal: -12102.910920079057\n",
      "Train Epoch: 4950 [256/118836 (0%)] Loss: 12317.529297\n",
      "Train Epoch: 4950 [33024/118836 (28%)] Loss: 12211.635742\n",
      "Train Epoch: 4950 [65792/118836 (55%)] Loss: 12327.210938\n",
      "Train Epoch: 4950 [98560/118836 (83%)] Loss: 12178.485352\n",
      "    epoch          : 4950\n",
      "    loss           : 12173.767930624485\n",
      "    val_loss       : 12168.623503594648\n",
      "    val_log_likelihood: -12094.446332842226\n",
      "    val_log_marginal: -12103.448388601053\n",
      "Train Epoch: 4951 [256/118836 (0%)] Loss: 12185.783203\n",
      "Train Epoch: 4951 [33024/118836 (28%)] Loss: 12145.804688\n",
      "Train Epoch: 4951 [65792/118836 (55%)] Loss: 12158.821289\n",
      "Train Epoch: 4951 [98560/118836 (83%)] Loss: 12255.421875\n",
      "    epoch          : 4951\n",
      "    loss           : 12174.976944886012\n",
      "    val_loss       : 12174.911632627785\n",
      "    val_log_likelihood: -12093.833075339899\n",
      "    val_log_marginal: -12102.960366157895\n",
      "Train Epoch: 4952 [256/118836 (0%)] Loss: 12192.205078\n",
      "Train Epoch: 4952 [33024/118836 (28%)] Loss: 12196.076172\n",
      "Train Epoch: 4952 [65792/118836 (55%)] Loss: 12158.992188\n",
      "Train Epoch: 4952 [98560/118836 (83%)] Loss: 12236.935547\n",
      "    epoch          : 4952\n",
      "    loss           : 12175.780381513647\n",
      "    val_loss       : 12172.658931011814\n",
      "    val_log_likelihood: -12094.850624709212\n",
      "    val_log_marginal: -12103.879591135394\n",
      "Train Epoch: 4953 [256/118836 (0%)] Loss: 12182.560547\n",
      "Train Epoch: 4953 [33024/118836 (28%)] Loss: 12179.130859\n",
      "Train Epoch: 4953 [65792/118836 (55%)] Loss: 12144.308594\n",
      "Train Epoch: 4953 [98560/118836 (83%)] Loss: 12205.519531\n",
      "    epoch          : 4953\n",
      "    loss           : 12174.250064942617\n",
      "    val_loss       : 12172.88443865461\n",
      "    val_log_likelihood: -12089.78835249302\n",
      "    val_log_marginal: -12098.640847105353\n",
      "Train Epoch: 4954 [256/118836 (0%)] Loss: 12158.736328\n",
      "Train Epoch: 4954 [33024/118836 (28%)] Loss: 12208.055664\n",
      "Train Epoch: 4954 [65792/118836 (55%)] Loss: 12221.998047\n",
      "Train Epoch: 4954 [98560/118836 (83%)] Loss: 12234.959961\n",
      "    epoch          : 4954\n",
      "    loss           : 12173.769239169767\n",
      "    val_loss       : 12168.811687211812\n",
      "    val_log_likelihood: -12093.131011230873\n",
      "    val_log_marginal: -12102.114650723106\n",
      "Train Epoch: 4955 [256/118836 (0%)] Loss: 12223.119141\n",
      "Train Epoch: 4955 [33024/118836 (28%)] Loss: 12155.694336\n",
      "Train Epoch: 4955 [65792/118836 (55%)] Loss: 12277.070312\n",
      "Train Epoch: 4955 [98560/118836 (83%)] Loss: 12103.990234\n",
      "    epoch          : 4955\n",
      "    loss           : 12173.311421984852\n",
      "    val_loss       : 12176.011514116257\n",
      "    val_log_likelihood: -12096.495959664495\n",
      "    val_log_marginal: -12105.660484221395\n",
      "Train Epoch: 4956 [256/118836 (0%)] Loss: 12249.020508\n",
      "Train Epoch: 4956 [33024/118836 (28%)] Loss: 12247.650391\n",
      "Train Epoch: 4956 [65792/118836 (55%)] Loss: 12167.816406\n",
      "Train Epoch: 4956 [98560/118836 (83%)] Loss: 12227.146484\n",
      "    epoch          : 4956\n",
      "    loss           : 12180.09761570125\n",
      "    val_loss       : 12177.524739026381\n",
      "    val_log_likelihood: -12102.233112173024\n",
      "    val_log_marginal: -12111.5640017704\n",
      "Train Epoch: 4957 [256/118836 (0%)] Loss: 12153.798828\n",
      "Train Epoch: 4957 [33024/118836 (28%)] Loss: 12237.429688\n",
      "Train Epoch: 4957 [65792/118836 (55%)] Loss: 12166.079102\n",
      "Train Epoch: 4957 [98560/118836 (83%)] Loss: 12153.930664\n",
      "    epoch          : 4957\n",
      "    loss           : 12180.461425538926\n",
      "    val_loss       : 12176.03107211443\n",
      "    val_log_likelihood: -12096.02262797896\n",
      "    val_log_marginal: -12105.305995640298\n",
      "Train Epoch: 4958 [256/118836 (0%)] Loss: 12119.899414\n",
      "Train Epoch: 4958 [33024/118836 (28%)] Loss: 12219.096680\n",
      "Train Epoch: 4958 [65792/118836 (55%)] Loss: 12148.082031\n",
      "Train Epoch: 4958 [98560/118836 (83%)] Loss: 12213.383789\n",
      "    epoch          : 4958\n",
      "    loss           : 12170.622294219138\n",
      "    val_loss       : 12176.041188288134\n",
      "    val_log_likelihood: -12093.037241521919\n",
      "    val_log_marginal: -12102.111314180993\n",
      "Train Epoch: 4959 [256/118836 (0%)] Loss: 12175.929688\n",
      "Train Epoch: 4959 [33024/118836 (28%)] Loss: 12210.493164\n",
      "Train Epoch: 4959 [65792/118836 (55%)] Loss: 12245.208984\n",
      "Train Epoch: 4959 [98560/118836 (83%)] Loss: 12255.415039\n",
      "    epoch          : 4959\n",
      "    loss           : 12172.701495780346\n",
      "    val_loss       : 12175.501540286637\n",
      "    val_log_likelihood: -12092.685817307693\n",
      "    val_log_marginal: -12101.675977480345\n",
      "Train Epoch: 4960 [256/118836 (0%)] Loss: 12160.789062\n",
      "Train Epoch: 4960 [33024/118836 (28%)] Loss: 12197.255859\n",
      "Train Epoch: 4960 [65792/118836 (55%)] Loss: 12318.496094\n",
      "Train Epoch: 4960 [98560/118836 (83%)] Loss: 12179.684570\n",
      "    epoch          : 4960\n",
      "    loss           : 12177.586487412118\n",
      "    val_loss       : 12173.269013852283\n",
      "    val_log_likelihood: -12092.404422075322\n",
      "    val_log_marginal: -12101.513531386203\n",
      "Train Epoch: 4961 [256/118836 (0%)] Loss: 12224.190430\n",
      "Train Epoch: 4961 [33024/118836 (28%)] Loss: 12166.510742\n",
      "Train Epoch: 4961 [65792/118836 (55%)] Loss: 12181.359375\n",
      "Train Epoch: 4961 [98560/118836 (83%)] Loss: 12125.933594\n",
      "    epoch          : 4961\n",
      "    loss           : 12173.267519159686\n",
      "    val_loss       : 12177.97240085829\n",
      "    val_log_likelihood: -12097.253560374018\n",
      "    val_log_marginal: -12106.485083232348\n",
      "Train Epoch: 4962 [256/118836 (0%)] Loss: 12149.317383\n",
      "Train Epoch: 4962 [33024/118836 (28%)] Loss: 12174.131836\n",
      "Train Epoch: 4962 [65792/118836 (55%)] Loss: 12150.164062\n",
      "Train Epoch: 4962 [98560/118836 (83%)] Loss: 12195.486328\n",
      "    epoch          : 4962\n",
      "    loss           : 12177.798533621537\n",
      "    val_loss       : 12170.18447378181\n",
      "    val_log_likelihood: -12093.871184540425\n",
      "    val_log_marginal: -12102.983908864597\n",
      "Train Epoch: 4963 [256/118836 (0%)] Loss: 12173.339844\n",
      "Train Epoch: 4963 [33024/118836 (28%)] Loss: 12162.921875\n",
      "Train Epoch: 4963 [65792/118836 (55%)] Loss: 12189.251953\n",
      "Train Epoch: 4963 [98560/118836 (83%)] Loss: 12132.396484\n",
      "    epoch          : 4963\n",
      "    loss           : 12172.609812474153\n",
      "    val_loss       : 12178.109179725572\n",
      "    val_log_likelihood: -12100.462005983767\n",
      "    val_log_marginal: -12109.584619484476\n",
      "Train Epoch: 4964 [256/118836 (0%)] Loss: 12177.042969\n",
      "Train Epoch: 4964 [33024/118836 (28%)] Loss: 12146.728516\n",
      "Train Epoch: 4964 [65792/118836 (55%)] Loss: 12157.999023\n",
      "Train Epoch: 4964 [98560/118836 (83%)] Loss: 12195.673828\n",
      "    epoch          : 4964\n",
      "    loss           : 12173.705315117091\n",
      "    val_loss       : 12175.17636619873\n",
      "    val_log_likelihood: -12094.656990539703\n",
      "    val_log_marginal: -12103.820402837266\n",
      "Train Epoch: 4965 [256/118836 (0%)] Loss: 12209.622070\n",
      "Train Epoch: 4965 [33024/118836 (28%)] Loss: 12142.462891\n",
      "Train Epoch: 4965 [65792/118836 (55%)] Loss: 12172.825195\n",
      "Train Epoch: 4965 [98560/118836 (83%)] Loss: 12188.790039\n",
      "    epoch          : 4965\n",
      "    loss           : 12175.875173341863\n",
      "    val_loss       : 12172.534308035074\n",
      "    val_log_likelihood: -12092.47916359724\n",
      "    val_log_marginal: -12101.510338891016\n",
      "Train Epoch: 4966 [256/118836 (0%)] Loss: 12171.349609\n",
      "Train Epoch: 4966 [33024/118836 (28%)] Loss: 12196.460938\n",
      "Train Epoch: 4966 [65792/118836 (55%)] Loss: 12223.272461\n",
      "Train Epoch: 4966 [98560/118836 (83%)] Loss: 12120.648438\n",
      "    epoch          : 4966\n",
      "    loss           : 12175.293967444686\n",
      "    val_loss       : 12176.387376506715\n",
      "    val_log_likelihood: -12091.707143364867\n",
      "    val_log_marginal: -12100.858650009162\n",
      "Train Epoch: 4967 [256/118836 (0%)] Loss: 12200.305664\n",
      "Train Epoch: 4967 [33024/118836 (28%)] Loss: 12262.320312\n",
      "Train Epoch: 4967 [65792/118836 (55%)] Loss: 12163.697266\n",
      "Train Epoch: 4967 [98560/118836 (83%)] Loss: 12233.191406\n",
      "    epoch          : 4967\n",
      "    loss           : 12178.715431302988\n",
      "    val_loss       : 12182.146798429247\n",
      "    val_log_likelihood: -12101.114703202544\n",
      "    val_log_marginal: -12110.492255946008\n",
      "Train Epoch: 4968 [256/118836 (0%)] Loss: 12193.753906\n",
      "Train Epoch: 4968 [33024/118836 (28%)] Loss: 12150.059570\n",
      "Train Epoch: 4968 [65792/118836 (55%)] Loss: 12216.906250\n",
      "Train Epoch: 4968 [98560/118836 (83%)] Loss: 12214.719727\n",
      "    epoch          : 4968\n",
      "    loss           : 12180.592162459936\n",
      "    val_loss       : 12176.652344292328\n",
      "    val_log_likelihood: -12097.495744966138\n",
      "    val_log_marginal: -12106.810521425732\n",
      "Train Epoch: 4969 [256/118836 (0%)] Loss: 12118.907227\n",
      "Train Epoch: 4969 [33024/118836 (28%)] Loss: 12240.726562\n",
      "Train Epoch: 4969 [65792/118836 (55%)] Loss: 12138.493164\n",
      "Train Epoch: 4969 [98560/118836 (83%)] Loss: 12174.925781\n",
      "    epoch          : 4969\n",
      "    loss           : 12173.303393332559\n",
      "    val_loss       : 12173.673760490516\n",
      "    val_log_likelihood: -12095.59754300429\n",
      "    val_log_marginal: -12104.772812463598\n",
      "Train Epoch: 4970 [256/118836 (0%)] Loss: 12195.574219\n",
      "Train Epoch: 4970 [33024/118836 (28%)] Loss: 12096.334961\n",
      "Train Epoch: 4970 [65792/118836 (55%)] Loss: 12286.456055\n",
      "Train Epoch: 4970 [98560/118836 (83%)] Loss: 12082.231445\n",
      "    epoch          : 4970\n",
      "    loss           : 12174.837778833231\n",
      "    val_loss       : 12174.474122572381\n",
      "    val_log_likelihood: -12092.042622066274\n",
      "    val_log_marginal: -12101.131118496349\n",
      "Train Epoch: 4971 [256/118836 (0%)] Loss: 12223.531250\n",
      "Train Epoch: 4971 [33024/118836 (28%)] Loss: 12108.515625\n",
      "Train Epoch: 4971 [65792/118836 (55%)] Loss: 12132.141602\n",
      "Train Epoch: 4971 [98560/118836 (83%)] Loss: 12139.467773\n",
      "    epoch          : 4971\n",
      "    loss           : 12175.54336874483\n",
      "    val_loss       : 12174.083241980266\n",
      "    val_log_likelihood: -12089.270726388027\n",
      "    val_log_marginal: -12098.209714660694\n",
      "Train Epoch: 4972 [256/118836 (0%)] Loss: 12146.673828\n",
      "Train Epoch: 4972 [33024/118836 (28%)] Loss: 12188.709961\n",
      "Train Epoch: 4972 [65792/118836 (55%)] Loss: 12189.855469\n",
      "Train Epoch: 4972 [98560/118836 (83%)] Loss: 12237.640625\n",
      "    epoch          : 4972\n",
      "    loss           : 12174.720244811053\n",
      "    val_loss       : 12175.744473713323\n",
      "    val_log_likelihood: -12095.559905526263\n",
      "    val_log_marginal: -12104.662235681788\n",
      "Train Epoch: 4973 [256/118836 (0%)] Loss: 12165.352539\n",
      "Train Epoch: 4973 [33024/118836 (28%)] Loss: 12194.813477\n",
      "Train Epoch: 4973 [65792/118836 (55%)] Loss: 12233.466797\n",
      "Train Epoch: 4973 [98560/118836 (83%)] Loss: 12261.700195\n",
      "    epoch          : 4973\n",
      "    loss           : 12173.289867497675\n",
      "    val_loss       : 12179.062347570942\n",
      "    val_log_likelihood: -12090.576833094241\n",
      "    val_log_marginal: -12099.588841553928\n",
      "Train Epoch: 4974 [256/118836 (0%)] Loss: 12174.612305\n",
      "Train Epoch: 4974 [33024/118836 (28%)] Loss: 12255.494141\n",
      "Train Epoch: 4974 [65792/118836 (55%)] Loss: 12134.368164\n",
      "Train Epoch: 4974 [98560/118836 (83%)] Loss: 12254.589844\n",
      "    epoch          : 4974\n",
      "    loss           : 12173.464996898263\n",
      "    val_loss       : 12172.48885203126\n",
      "    val_log_likelihood: -12093.359421526055\n",
      "    val_log_marginal: -12102.33915962085\n",
      "Train Epoch: 4975 [256/118836 (0%)] Loss: 12213.335938\n",
      "Train Epoch: 4975 [33024/118836 (28%)] Loss: 12114.058594\n",
      "Train Epoch: 4975 [65792/118836 (55%)] Loss: 12110.625000\n",
      "Train Epoch: 4975 [98560/118836 (83%)] Loss: 12234.847656\n",
      "    epoch          : 4975\n",
      "    loss           : 12175.136854127895\n",
      "    val_loss       : 12174.748726407357\n",
      "    val_log_likelihood: -12092.044344661135\n",
      "    val_log_marginal: -12100.937813834598\n",
      "Train Epoch: 4976 [256/118836 (0%)] Loss: 12185.466797\n",
      "Train Epoch: 4976 [33024/118836 (28%)] Loss: 12306.065430\n",
      "Train Epoch: 4976 [65792/118836 (55%)] Loss: 12076.526367\n",
      "Train Epoch: 4976 [98560/118836 (83%)] Loss: 12241.300781\n",
      "    epoch          : 4976\n",
      "    loss           : 12180.569146602307\n",
      "    val_loss       : 12170.34687998004\n",
      "    val_log_likelihood: -12093.442728203836\n",
      "    val_log_marginal: -12102.583527154942\n",
      "Train Epoch: 4977 [256/118836 (0%)] Loss: 12141.232422\n",
      "Train Epoch: 4977 [33024/118836 (28%)] Loss: 12252.380859\n",
      "Train Epoch: 4977 [65792/118836 (55%)] Loss: 12264.590820\n",
      "Train Epoch: 4977 [98560/118836 (83%)] Loss: 12177.112305\n",
      "    epoch          : 4977\n",
      "    loss           : 12172.01243538048\n",
      "    val_loss       : 12174.519101725846\n",
      "    val_log_likelihood: -12094.128635171111\n",
      "    val_log_marginal: -12103.118216474944\n",
      "Train Epoch: 4978 [256/118836 (0%)] Loss: 12199.583008\n",
      "Train Epoch: 4978 [33024/118836 (28%)] Loss: 12125.296875\n",
      "Train Epoch: 4978 [65792/118836 (55%)] Loss: 12202.464844\n",
      "Train Epoch: 4978 [98560/118836 (83%)] Loss: 12203.166016\n",
      "    epoch          : 4978\n",
      "    loss           : 12173.693462766232\n",
      "    val_loss       : 12174.760449306374\n",
      "    val_log_likelihood: -12093.471273876912\n",
      "    val_log_marginal: -12102.524958732181\n",
      "Train Epoch: 4979 [256/118836 (0%)] Loss: 12185.712891\n",
      "Train Epoch: 4979 [33024/118836 (28%)] Loss: 12142.769531\n",
      "Train Epoch: 4979 [65792/118836 (55%)] Loss: 12104.425781\n",
      "Train Epoch: 4979 [98560/118836 (83%)] Loss: 12174.264648\n",
      "    epoch          : 4979\n",
      "    loss           : 12175.861810671267\n",
      "    val_loss       : 12176.526545843653\n",
      "    val_log_likelihood: -12095.55183067101\n",
      "    val_log_marginal: -12104.49999321117\n",
      "Train Epoch: 4980 [256/118836 (0%)] Loss: 12235.617188\n",
      "Train Epoch: 4980 [33024/118836 (28%)] Loss: 12324.550781\n",
      "Train Epoch: 4980 [65792/118836 (55%)] Loss: 12182.158203\n",
      "Train Epoch: 4980 [98560/118836 (83%)] Loss: 12164.606445\n",
      "    epoch          : 4980\n",
      "    loss           : 12174.742593472136\n",
      "    val_loss       : 12172.955012727707\n",
      "    val_log_likelihood: -12093.274120205233\n",
      "    val_log_marginal: -12102.280954791628\n",
      "Train Epoch: 4981 [256/118836 (0%)] Loss: 12199.192383\n",
      "Train Epoch: 4981 [33024/118836 (28%)] Loss: 12179.320312\n",
      "Train Epoch: 4981 [65792/118836 (55%)] Loss: 12153.175781\n",
      "Train Epoch: 4981 [98560/118836 (83%)] Loss: 12273.613281\n",
      "    epoch          : 4981\n",
      "    loss           : 12172.719874218104\n",
      "    val_loss       : 12171.503413432341\n",
      "    val_log_likelihood: -12092.81682514604\n",
      "    val_log_marginal: -12101.772315672832\n",
      "Train Epoch: 4982 [256/118836 (0%)] Loss: 12254.563477\n",
      "Train Epoch: 4982 [33024/118836 (28%)] Loss: 12183.910156\n",
      "Train Epoch: 4982 [65792/118836 (55%)] Loss: 12166.881836\n",
      "Train Epoch: 4982 [98560/118836 (83%)] Loss: 12211.849609\n",
      "    epoch          : 4982\n",
      "    loss           : 12173.51857617349\n",
      "    val_loss       : 12175.623077516293\n",
      "    val_log_likelihood: -12096.08815459574\n",
      "    val_log_marginal: -12105.124189728105\n",
      "Train Epoch: 4983 [256/118836 (0%)] Loss: 12241.616211\n",
      "Train Epoch: 4983 [33024/118836 (28%)] Loss: 12232.916016\n",
      "Train Epoch: 4983 [65792/118836 (55%)] Loss: 12108.651367\n",
      "Train Epoch: 4983 [98560/118836 (83%)] Loss: 12168.010742\n",
      "    epoch          : 4983\n",
      "    loss           : 12172.426245541254\n",
      "    val_loss       : 12171.755364365848\n",
      "    val_log_likelihood: -12094.779252125982\n",
      "    val_log_marginal: -12103.77113521765\n",
      "Train Epoch: 4984 [256/118836 (0%)] Loss: 12247.250000\n",
      "Train Epoch: 4984 [33024/118836 (28%)] Loss: 12136.241211\n",
      "Train Epoch: 4984 [65792/118836 (55%)] Loss: 12147.410156\n",
      "Train Epoch: 4984 [98560/118836 (83%)] Loss: 12175.861328\n",
      "    epoch          : 4984\n",
      "    loss           : 12170.554809792442\n",
      "    val_loss       : 12176.236197384049\n",
      "    val_log_likelihood: -12093.610547682743\n",
      "    val_log_marginal: -12102.637169587519\n",
      "Train Epoch: 4985 [256/118836 (0%)] Loss: 12160.929688\n",
      "Train Epoch: 4985 [33024/118836 (28%)] Loss: 12212.408203\n",
      "Train Epoch: 4985 [65792/118836 (55%)] Loss: 12140.165039\n",
      "Train Epoch: 4985 [98560/118836 (83%)] Loss: 12234.120117\n",
      "    epoch          : 4985\n",
      "    loss           : 12175.86370159998\n",
      "    val_loss       : 12172.68327839459\n",
      "    val_log_likelihood: -12093.187457512666\n",
      "    val_log_marginal: -12102.257218642162\n",
      "Train Epoch: 4986 [256/118836 (0%)] Loss: 12202.726562\n",
      "Train Epoch: 4986 [33024/118836 (28%)] Loss: 12258.774414\n",
      "Train Epoch: 4986 [65792/118836 (55%)] Loss: 12187.191406\n",
      "Train Epoch: 4986 [98560/118836 (83%)] Loss: 12218.709961\n",
      "    epoch          : 4986\n",
      "    loss           : 12178.009331220273\n",
      "    val_loss       : 12174.88942573507\n",
      "    val_log_likelihood: -12096.047046564825\n",
      "    val_log_marginal: -12105.244592072517\n",
      "Train Epoch: 4987 [256/118836 (0%)] Loss: 12169.144531\n",
      "Train Epoch: 4987 [33024/118836 (28%)] Loss: 12136.417969\n",
      "Train Epoch: 4987 [65792/118836 (55%)] Loss: 12203.734375\n",
      "Train Epoch: 4987 [98560/118836 (83%)] Loss: 12194.564453\n",
      "    epoch          : 4987\n",
      "    loss           : 12174.30901264604\n",
      "    val_loss       : 12179.53468839161\n",
      "    val_log_likelihood: -12095.188659112644\n",
      "    val_log_marginal: -12104.454537909518\n",
      "Train Epoch: 4988 [256/118836 (0%)] Loss: 12161.671875\n",
      "Train Epoch: 4988 [33024/118836 (28%)] Loss: 12271.691406\n",
      "Train Epoch: 4988 [65792/118836 (55%)] Loss: 12284.260742\n",
      "Train Epoch: 4988 [98560/118836 (83%)] Loss: 12152.841797\n",
      "    epoch          : 4988\n",
      "    loss           : 12176.67978976039\n",
      "    val_loss       : 12185.78724312712\n",
      "    val_log_likelihood: -12096.440390108042\n",
      "    val_log_marginal: -12105.801853561163\n",
      "Train Epoch: 4989 [256/118836 (0%)] Loss: 12179.685547\n",
      "Train Epoch: 4989 [33024/118836 (28%)] Loss: 12159.672852\n",
      "Train Epoch: 4989 [65792/118836 (55%)] Loss: 12138.724609\n",
      "Train Epoch: 4989 [98560/118836 (83%)] Loss: 12170.105469\n",
      "    epoch          : 4989\n",
      "    loss           : 12178.18425513079\n",
      "    val_loss       : 12171.039119782457\n",
      "    val_log_likelihood: -12093.318985376603\n",
      "    val_log_marginal: -12102.463226059677\n",
      "Train Epoch: 4990 [256/118836 (0%)] Loss: 12222.425781\n",
      "Train Epoch: 4990 [33024/118836 (28%)] Loss: 12240.121094\n",
      "Train Epoch: 4990 [65792/118836 (55%)] Loss: 12132.076172\n",
      "Train Epoch: 4990 [98560/118836 (83%)] Loss: 12143.351562\n",
      "    epoch          : 4990\n",
      "    loss           : 12177.52493134176\n",
      "    val_loss       : 12175.12568496625\n",
      "    val_log_likelihood: -12094.62351811285\n",
      "    val_log_marginal: -12103.801240342607\n",
      "Train Epoch: 4991 [256/118836 (0%)] Loss: 12125.801758\n",
      "Train Epoch: 4991 [33024/118836 (28%)] Loss: 12189.814453\n",
      "Train Epoch: 4991 [65792/118836 (55%)] Loss: 12165.978516\n",
      "Train Epoch: 4991 [98560/118836 (83%)] Loss: 12156.184570\n",
      "    epoch          : 4991\n",
      "    loss           : 12177.981941751963\n",
      "    val_loss       : 12190.626889377303\n",
      "    val_log_likelihood: -12098.541907051282\n",
      "    val_log_marginal: -12107.773730316236\n",
      "Train Epoch: 4992 [256/118836 (0%)] Loss: 12194.613281\n",
      "Train Epoch: 4992 [33024/118836 (28%)] Loss: 12249.938477\n",
      "Train Epoch: 4992 [65792/118836 (55%)] Loss: 12114.140625\n",
      "Train Epoch: 4992 [98560/118836 (83%)] Loss: 12249.562500\n",
      "    epoch          : 4992\n",
      "    loss           : 12178.994571960297\n",
      "    val_loss       : 12179.942117950031\n",
      "    val_log_likelihood: -12096.51127836797\n",
      "    val_log_marginal: -12105.841997618945\n",
      "Train Epoch: 4993 [256/118836 (0%)] Loss: 12165.784180\n",
      "Train Epoch: 4993 [33024/118836 (28%)] Loss: 12153.590820\n",
      "Train Epoch: 4993 [65792/118836 (55%)] Loss: 12229.625977\n",
      "Train Epoch: 4993 [98560/118836 (83%)] Loss: 12193.722656\n",
      "    epoch          : 4993\n",
      "    loss           : 12175.597209244468\n",
      "    val_loss       : 12175.145665566095\n",
      "    val_log_likelihood: -12093.9364022759\n",
      "    val_log_marginal: -12103.1185133583\n",
      "Train Epoch: 4994 [256/118836 (0%)] Loss: 12203.091797\n",
      "Train Epoch: 4994 [33024/118836 (28%)] Loss: 12290.242188\n",
      "Train Epoch: 4994 [65792/118836 (55%)] Loss: 12256.910156\n",
      "Train Epoch: 4994 [98560/118836 (83%)] Loss: 12148.688477\n",
      "    epoch          : 4994\n",
      "    loss           : 12176.528403025484\n",
      "    val_loss       : 12177.652555102139\n",
      "    val_log_likelihood: -12093.661594680521\n",
      "    val_log_marginal: -12102.841020103211\n",
      "Train Epoch: 4995 [256/118836 (0%)] Loss: 12223.045898\n",
      "Train Epoch: 4995 [33024/118836 (28%)] Loss: 12130.377930\n",
      "Train Epoch: 4995 [65792/118836 (55%)] Loss: 12155.640625\n",
      "Train Epoch: 4995 [98560/118836 (83%)] Loss: 12220.200195\n",
      "    epoch          : 4995\n",
      "    loss           : 12175.01954998966\n",
      "    val_loss       : 12173.306067150133\n",
      "    val_log_likelihood: -12093.913589485112\n",
      "    val_log_marginal: -12103.003441010706\n",
      "Train Epoch: 4996 [256/118836 (0%)] Loss: 12133.804688\n",
      "Train Epoch: 4996 [33024/118836 (28%)] Loss: 12151.540039\n",
      "Train Epoch: 4996 [65792/118836 (55%)] Loss: 12262.815430\n",
      "Train Epoch: 4996 [98560/118836 (83%)] Loss: 12150.554688\n",
      "    epoch          : 4996\n",
      "    loss           : 12168.50403823537\n",
      "    val_loss       : 12174.586575931491\n",
      "    val_log_likelihood: -12098.257856279726\n",
      "    val_log_marginal: -12107.379838900177\n",
      "Train Epoch: 4997 [256/118836 (0%)] Loss: 12197.642578\n",
      "Train Epoch: 4997 [33024/118836 (28%)] Loss: 12252.236328\n",
      "Train Epoch: 4997 [65792/118836 (55%)] Loss: 12163.236328\n",
      "Train Epoch: 4997 [98560/118836 (83%)] Loss: 12141.987305\n",
      "    epoch          : 4997\n",
      "    loss           : 12175.519623009719\n",
      "    val_loss       : 12172.868185673327\n",
      "    val_log_likelihood: -12089.041366670543\n",
      "    val_log_marginal: -12098.090985954557\n",
      "Train Epoch: 4998 [256/118836 (0%)] Loss: 12243.112305\n",
      "Train Epoch: 4998 [33024/118836 (28%)] Loss: 12241.002930\n",
      "Train Epoch: 4998 [65792/118836 (55%)] Loss: 12239.164062\n",
      "Train Epoch: 4998 [98560/118836 (83%)] Loss: 12183.475586\n",
      "    epoch          : 4998\n",
      "    loss           : 12175.79359491315\n",
      "    val_loss       : 12170.365478251464\n",
      "    val_log_likelihood: -12097.396533324287\n",
      "    val_log_marginal: -12106.447605066067\n",
      "Train Epoch: 4999 [256/118836 (0%)] Loss: 12210.135742\n",
      "Train Epoch: 4999 [33024/118836 (28%)] Loss: 12163.287109\n",
      "Train Epoch: 4999 [65792/118836 (55%)] Loss: 12173.818359\n",
      "Train Epoch: 4999 [98560/118836 (83%)] Loss: 12243.065430\n",
      "    epoch          : 4999\n",
      "    loss           : 12172.009617000103\n",
      "    val_loss       : 12176.446819202618\n",
      "    val_log_likelihood: -12091.931921719914\n",
      "    val_log_marginal: -12101.050221028187\n",
      "Train Epoch: 5000 [256/118836 (0%)] Loss: 12274.366211\n",
      "Train Epoch: 5000 [33024/118836 (28%)] Loss: 12310.611328\n",
      "Train Epoch: 5000 [65792/118836 (55%)] Loss: 12221.988281\n",
      "Train Epoch: 5000 [98560/118836 (83%)] Loss: 12115.989258\n",
      "    epoch          : 5000\n",
      "    loss           : 12170.154895574857\n",
      "    val_loss       : 12171.566848677838\n",
      "    val_log_likelihood: -12092.602977667495\n",
      "    val_log_marginal: -12101.674648693122\n",
      "Saving checkpoint: saved/models/SelfiesAutoencodingOperad/0905_154251/checkpoint-epoch5000.pth ...\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelfiesAutoencodingModel(\n",
       "  (_operad): FreeOperad(\n",
       "    (generator_0): RecurrentDecoder(\n",
       "      (recurrence): GRU(32, 64, batch_first=True)\n",
       "      (decoder): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=18, bias=True)\n",
       "        (1): Softmax(dim=-1)\n",
       "      )\n",
       "    )\n",
       "    (generator_1): RecurrentDecoder(\n",
       "      (recurrence): GRU(32, 64, batch_first=True)\n",
       "      (decoder): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=18, bias=True)\n",
       "        (1): Softmax(dim=-1)\n",
       "      )\n",
       "    )\n",
       "    (generator_2): RecurrentDecoder(\n",
       "      (recurrence): GRU(32, 64, num_layers=2, batch_first=True)\n",
       "      (decoder): Sequential(\n",
       "        (0): Linear(in_features=128, out_features=18, bias=True)\n",
       "        (1): Softmax(dim=-1)\n",
       "      )\n",
       "    )\n",
       "    (generator_3): RecurrentDecoder(\n",
       "      (recurrence): GRU(32, 64, num_layers=2, batch_first=True)\n",
       "      (decoder): Sequential(\n",
       "        (0): Linear(in_features=128, out_features=18, bias=True)\n",
       "        (1): Softmax(dim=-1)\n",
       "      )\n",
       "    )\n",
       "    (generator_4): RecurrentDecoder(\n",
       "      (recurrence): GRU(32, 64, num_layers=4, batch_first=True)\n",
       "      (decoder): Sequential(\n",
       "        (0): Linear(in_features=256, out_features=18, bias=True)\n",
       "        (1): Softmax(dim=-1)\n",
       "      )\n",
       "    )\n",
       "    (generator_5): RecurrentDecoder(\n",
       "      (recurrence): GRU(32, 64, num_layers=4, batch_first=True)\n",
       "      (decoder): Sequential(\n",
       "        (0): Linear(in_features=256, out_features=18, bias=True)\n",
       "        (1): Softmax(dim=-1)\n",
       "      )\n",
       "    )\n",
       "    (generator_6): RecurrentDecoder(\n",
       "      (recurrence): GRU(32, 100, batch_first=True)\n",
       "      (decoder): Sequential(\n",
       "        (0): Linear(in_features=100, out_features=18, bias=True)\n",
       "        (1): Softmax(dim=-1)\n",
       "      )\n",
       "    )\n",
       "    (generator_7): RecurrentDecoder(\n",
       "      (recurrence): GRU(32, 100, batch_first=True)\n",
       "      (decoder): Sequential(\n",
       "        (0): Linear(in_features=100, out_features=18, bias=True)\n",
       "        (1): Softmax(dim=-1)\n",
       "      )\n",
       "    )\n",
       "    (generator_8): RecurrentDecoder(\n",
       "      (recurrence): GRU(32, 100, num_layers=2, batch_first=True)\n",
       "      (decoder): Sequential(\n",
       "        (0): Linear(in_features=200, out_features=18, bias=True)\n",
       "        (1): Softmax(dim=-1)\n",
       "      )\n",
       "    )\n",
       "    (generator_9): RecurrentDecoder(\n",
       "      (recurrence): GRU(32, 100, num_layers=2, batch_first=True)\n",
       "      (decoder): Sequential(\n",
       "        (0): Linear(in_features=200, out_features=18, bias=True)\n",
       "        (1): Softmax(dim=-1)\n",
       "      )\n",
       "    )\n",
       "    (generator_10): RecurrentDecoder(\n",
       "      (recurrence): GRU(32, 100, num_layers=4, batch_first=True)\n",
       "      (decoder): Sequential(\n",
       "        (0): Linear(in_features=400, out_features=18, bias=True)\n",
       "        (1): Softmax(dim=-1)\n",
       "      )\n",
       "    )\n",
       "    (generator_11): RecurrentDecoder(\n",
       "      (recurrence): GRU(32, 100, num_layers=4, batch_first=True)\n",
       "      (decoder): Sequential(\n",
       "        (0): Linear(in_features=400, out_features=18, bias=True)\n",
       "        (1): Softmax(dim=-1)\n",
       "      )\n",
       "    )\n",
       "    (generator_12): RecurrentDecoder(\n",
       "      (recurrence): GRU(32, 128, batch_first=True)\n",
       "      (decoder): Sequential(\n",
       "        (0): Linear(in_features=128, out_features=18, bias=True)\n",
       "        (1): Softmax(dim=-1)\n",
       "      )\n",
       "    )\n",
       "    (generator_13): RecurrentDecoder(\n",
       "      (recurrence): GRU(32, 128, batch_first=True)\n",
       "      (decoder): Sequential(\n",
       "        (0): Linear(in_features=128, out_features=18, bias=True)\n",
       "        (1): Softmax(dim=-1)\n",
       "      )\n",
       "    )\n",
       "    (generator_14): RecurrentDecoder(\n",
       "      (recurrence): GRU(32, 128, num_layers=2, batch_first=True)\n",
       "      (decoder): Sequential(\n",
       "        (0): Linear(in_features=256, out_features=18, bias=True)\n",
       "        (1): Softmax(dim=-1)\n",
       "      )\n",
       "    )\n",
       "    (generator_15): RecurrentDecoder(\n",
       "      (recurrence): GRU(32, 128, num_layers=2, batch_first=True)\n",
       "      (decoder): Sequential(\n",
       "        (0): Linear(in_features=256, out_features=18, bias=True)\n",
       "        (1): Softmax(dim=-1)\n",
       "      )\n",
       "    )\n",
       "    (generator_16): RecurrentDecoder(\n",
       "      (recurrence): GRU(32, 128, num_layers=4, batch_first=True)\n",
       "      (decoder): Sequential(\n",
       "        (0): Linear(in_features=512, out_features=18, bias=True)\n",
       "        (1): Softmax(dim=-1)\n",
       "      )\n",
       "    )\n",
       "    (generator_17): RecurrentDecoder(\n",
       "      (recurrence): GRU(32, 128, num_layers=4, batch_first=True)\n",
       "      (decoder): Sequential(\n",
       "        (0): Linear(in_features=512, out_features=18, bias=True)\n",
       "        (1): Softmax(dim=-1)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (guide_temperatures): Sequential(\n",
       "    (0): Linear(in_features=378, out_features=256, bias=True)\n",
       "    (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    (2): PReLU(num_parameters=1)\n",
       "    (3): Linear(in_features=256, out_features=2, bias=True)\n",
       "    (4): Softplus(beta=1, threshold=20)\n",
       "  )\n",
       "  (guide_arrow_weights): Sequential(\n",
       "    (0): Linear(in_features=378, out_features=256, bias=True)\n",
       "    (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    (2): PReLU(num_parameters=1)\n",
       "    (3): Linear(in_features=256, out_features=18, bias=True)\n",
       "    (4): Softplus(beta=1, threshold=20)\n",
       "  )\n",
       "  (latent_prior): StandardNormal()\n",
       "  (encoder): StringEncoder(\n",
       "    (conv_layers): Sequential(\n",
       "      (0): Conv1d(21, 32, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "      (1): ReLU()\n",
       "      (2): Conv1d(32, 64, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "      (3): ReLU()\n",
       "      (4): Flatten(start_dim=1, end_dim=-1)\n",
       "    )\n",
       "    (dense): Sequential(\n",
       "      (0): Linear(in_features=320, out_features=435, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=435, out_features=64, bias=True)\n",
       "    )\n",
       "    (distribution): DiagonalGaussian()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:categorical_bpl] *",
   "language": "python",
   "name": "conda-env-categorical_bpl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
