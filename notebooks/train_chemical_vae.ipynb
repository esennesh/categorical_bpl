{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/eli/AnacondaProjects/categorical_bpl\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit WARNING: [11:09:05] Enabling RDKit 2019.09.3 jupyter extensions\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import collections\n",
    "import pyro\n",
    "import torch\n",
    "import numpy as np\n",
    "import data_loader.data_loaders as module_data\n",
    "import model.model as module_arch\n",
    "from parse_config import ConfigParser\n",
    "from trainer import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyro.enable_validation(True)\n",
    "# torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seeds for reproducibility\n",
    "SEED = 123\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Args = collections.namedtuple('Args', 'config resume device')\n",
    "config = ConfigParser.from_args(Args(config='chemical_config.json', resume=None, device=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = config.get_logger('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup data_loader instances\n",
    "data_loader = config.init_obj('data_loader', module_data)\n",
    "valid_data_loader = data_loader.split_validation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model architecture, then print to console\n",
    "model = config.init_obj('arch', module_arch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = pyro.optim.ReduceLROnPlateau({\n",
    "    'optimizer': torch.optim.Adam,\n",
    "    'optim_args': {\n",
    "        \"lr\": 1e-4,\n",
    "        \"weight_decay\": 0,\n",
    "        \"amsgrad\": True\n",
    "    },\n",
    "    \"patience\": 50,\n",
    "    \"factor\": 0.1,\n",
    "    \"verbose\": True,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = config.init_obj('optimizer', pyro.optim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model, [], optimizer, config=config,\n",
    "                  data_loader=data_loader,\n",
    "                  valid_data_loader=valid_data_loader,\n",
    "                  lr_scheduler=optimizer, log_images=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [128/225000 (0%)] Loss: 55128.839844\n",
      "Train Epoch: 1 [1536/225000 (1%)] Loss: 54572.738281\n",
      "Train Epoch: 1 [2944/225000 (1%)] Loss: 51793.761719\n",
      "Train Epoch: 1 [4352/225000 (2%)] Loss: 49305.718750\n",
      "Train Epoch: 1 [5760/225000 (3%)] Loss: 49255.472656\n",
      "Train Epoch: 1 [7168/225000 (3%)] Loss: 47818.671875\n",
      "Train Epoch: 1 [8576/225000 (4%)] Loss: 37596.101562\n",
      "Train Epoch: 1 [9984/225000 (4%)] Loss: 36286.707031\n",
      "Train Epoch: 1 [11392/225000 (5%)] Loss: 36477.785156\n",
      "Train Epoch: 1 [12800/225000 (6%)] Loss: 40157.867188\n",
      "Train Epoch: 1 [14208/225000 (6%)] Loss: 34400.484375\n",
      "Train Epoch: 1 [15616/225000 (7%)] Loss: 44552.707031\n",
      "Train Epoch: 1 [17024/225000 (8%)] Loss: 25144.384766\n",
      "Train Epoch: 1 [18432/225000 (8%)] Loss: 37204.828125\n",
      "Train Epoch: 1 [19840/225000 (9%)] Loss: 23136.542969\n",
      "Train Epoch: 1 [21248/225000 (9%)] Loss: 20360.332031\n",
      "Train Epoch: 1 [22656/225000 (10%)] Loss: 24250.691406\n",
      "Train Epoch: 1 [24064/225000 (11%)] Loss: 19880.162109\n",
      "Train Epoch: 1 [25472/225000 (11%)] Loss: 18366.818359\n",
      "Train Epoch: 1 [26880/225000 (12%)] Loss: 16518.501953\n",
      "Train Epoch: 1 [28288/225000 (13%)] Loss: 15627.389648\n",
      "Train Epoch: 1 [29696/225000 (13%)] Loss: 15897.822266\n",
      "Train Epoch: 1 [31104/225000 (14%)] Loss: 15988.470703\n",
      "Train Epoch: 1 [32512/225000 (14%)] Loss: 15468.236328\n",
      "Train Epoch: 1 [33920/225000 (15%)] Loss: 16083.194336\n",
      "Train Epoch: 1 [35328/225000 (16%)] Loss: 17755.830078\n",
      "Train Epoch: 1 [36736/225000 (16%)] Loss: 15963.748047\n",
      "Train Epoch: 1 [38144/225000 (17%)] Loss: 15736.602539\n",
      "Train Epoch: 1 [39552/225000 (18%)] Loss: 15732.239258\n",
      "Train Epoch: 1 [40960/225000 (18%)] Loss: 15766.042969\n",
      "Train Epoch: 1 [42368/225000 (19%)] Loss: 17021.761719\n",
      "Train Epoch: 1 [43776/225000 (19%)] Loss: 15262.066406\n",
      "Train Epoch: 1 [45184/225000 (20%)] Loss: 16229.782227\n",
      "Train Epoch: 1 [46592/225000 (21%)] Loss: 16080.703125\n",
      "Train Epoch: 1 [48000/225000 (21%)] Loss: 15994.073242\n",
      "Train Epoch: 1 [49408/225000 (22%)] Loss: 16662.050781\n",
      "Train Epoch: 1 [50816/225000 (23%)] Loss: 15909.670898\n",
      "Train Epoch: 1 [52224/225000 (23%)] Loss: 15579.303711\n",
      "Train Epoch: 1 [53632/225000 (24%)] Loss: 16840.531250\n",
      "Train Epoch: 1 [55040/225000 (24%)] Loss: 15637.510742\n",
      "Train Epoch: 1 [56448/225000 (25%)] Loss: 15259.787109\n",
      "Train Epoch: 1 [57856/225000 (26%)] Loss: 15894.194336\n",
      "Train Epoch: 1 [59264/225000 (26%)] Loss: 15220.857422\n",
      "Train Epoch: 1 [60672/225000 (27%)] Loss: 15740.069336\n",
      "Train Epoch: 1 [62080/225000 (28%)] Loss: 15563.291992\n",
      "Train Epoch: 1 [63488/225000 (28%)] Loss: 15615.095703\n",
      "Train Epoch: 1 [64896/225000 (29%)] Loss: 15308.941406\n",
      "Train Epoch: 1 [66304/225000 (29%)] Loss: 15607.348633\n",
      "Train Epoch: 1 [67712/225000 (30%)] Loss: 15412.303711\n",
      "Train Epoch: 1 [69120/225000 (31%)] Loss: 15282.388672\n",
      "Train Epoch: 1 [70528/225000 (31%)] Loss: 15477.996094\n",
      "Train Epoch: 1 [71936/225000 (32%)] Loss: 15904.482422\n",
      "Train Epoch: 1 [73344/225000 (33%)] Loss: 15755.753906\n",
      "Train Epoch: 1 [74752/225000 (33%)] Loss: 15542.070312\n",
      "Train Epoch: 1 [76160/225000 (34%)] Loss: 15227.006836\n",
      "Train Epoch: 1 [77568/225000 (34%)] Loss: 15444.291016\n",
      "Train Epoch: 1 [78976/225000 (35%)] Loss: 15588.344727\n",
      "Train Epoch: 1 [80384/225000 (36%)] Loss: 15361.898438\n",
      "Train Epoch: 1 [81792/225000 (36%)] Loss: 15533.865234\n",
      "Train Epoch: 1 [83200/225000 (37%)] Loss: 15391.547852\n",
      "Train Epoch: 1 [84608/225000 (38%)] Loss: 15173.500977\n",
      "Train Epoch: 1 [86016/225000 (38%)] Loss: 15549.906250\n",
      "Train Epoch: 1 [87424/225000 (39%)] Loss: 15366.918945\n",
      "Train Epoch: 1 [88832/225000 (39%)] Loss: 15491.226562\n",
      "Train Epoch: 1 [90240/225000 (40%)] Loss: 15600.624023\n",
      "Train Epoch: 1 [91648/225000 (41%)] Loss: 15113.957031\n",
      "Train Epoch: 1 [93056/225000 (41%)] Loss: 15577.376953\n",
      "Train Epoch: 1 [94464/225000 (42%)] Loss: 15466.228516\n",
      "Train Epoch: 1 [95872/225000 (43%)] Loss: 14819.524414\n",
      "Train Epoch: 1 [97280/225000 (43%)] Loss: 15622.347656\n",
      "Train Epoch: 1 [98688/225000 (44%)] Loss: 15242.285156\n",
      "Train Epoch: 1 [100096/225000 (44%)] Loss: 15403.329102\n",
      "Train Epoch: 1 [101504/225000 (45%)] Loss: 15497.453125\n",
      "Train Epoch: 1 [102912/225000 (46%)] Loss: 15653.416992\n",
      "Train Epoch: 1 [104320/225000 (46%)] Loss: 15453.442383\n",
      "Train Epoch: 1 [105728/225000 (47%)] Loss: 15606.259766\n",
      "Train Epoch: 1 [107136/225000 (48%)] Loss: 15531.608398\n",
      "Train Epoch: 1 [108544/225000 (48%)] Loss: 15466.103516\n",
      "Train Epoch: 1 [109952/225000 (49%)] Loss: 15307.218750\n",
      "Train Epoch: 1 [111360/225000 (49%)] Loss: 15277.416992\n",
      "Train Epoch: 1 [112768/225000 (50%)] Loss: 15049.942383\n",
      "Train Epoch: 1 [114176/225000 (51%)] Loss: 14938.143555\n",
      "Train Epoch: 1 [115584/225000 (51%)] Loss: 15735.041992\n",
      "Train Epoch: 1 [116992/225000 (52%)] Loss: 15445.815430\n",
      "Train Epoch: 1 [118400/225000 (53%)] Loss: 15675.326172\n",
      "Train Epoch: 1 [119808/225000 (53%)] Loss: 15794.345703\n",
      "Train Epoch: 1 [121216/225000 (54%)] Loss: 15293.509766\n",
      "Train Epoch: 1 [122624/225000 (54%)] Loss: 15147.503906\n",
      "Train Epoch: 1 [124032/225000 (55%)] Loss: 15543.589844\n",
      "Train Epoch: 1 [125440/225000 (56%)] Loss: 15301.229492\n",
      "Train Epoch: 1 [126848/225000 (56%)] Loss: 15919.984375\n",
      "Train Epoch: 1 [128256/225000 (57%)] Loss: 15160.698242\n",
      "Train Epoch: 1 [129664/225000 (58%)] Loss: 15198.207031\n",
      "Train Epoch: 1 [131072/225000 (58%)] Loss: 15176.179688\n",
      "Train Epoch: 1 [132480/225000 (59%)] Loss: 15432.232422\n",
      "Train Epoch: 1 [133888/225000 (60%)] Loss: 16607.828125\n",
      "Train Epoch: 1 [135296/225000 (60%)] Loss: 15545.331055\n",
      "Train Epoch: 1 [136704/225000 (61%)] Loss: 16034.618164\n",
      "Train Epoch: 1 [138112/225000 (61%)] Loss: 15589.970703\n",
      "Train Epoch: 1 [139520/225000 (62%)] Loss: 15074.426758\n",
      "Train Epoch: 1 [140928/225000 (63%)] Loss: 15984.431641\n",
      "Train Epoch: 1 [142336/225000 (63%)] Loss: 15414.696289\n",
      "Train Epoch: 1 [143744/225000 (64%)] Loss: 15413.813477\n",
      "Train Epoch: 1 [145152/225000 (65%)] Loss: 15324.734375\n",
      "Train Epoch: 1 [146560/225000 (65%)] Loss: 15171.123047\n",
      "Train Epoch: 1 [147968/225000 (66%)] Loss: 15199.351562\n",
      "Train Epoch: 1 [149376/225000 (66%)] Loss: 15193.134766\n",
      "Train Epoch: 1 [150784/225000 (67%)] Loss: 15336.850586\n",
      "Train Epoch: 1 [152192/225000 (68%)] Loss: 14948.674805\n",
      "Train Epoch: 1 [153600/225000 (68%)] Loss: 15585.734375\n",
      "Train Epoch: 1 [155008/225000 (69%)] Loss: 15572.524414\n",
      "Train Epoch: 1 [156416/225000 (70%)] Loss: 15412.680664\n",
      "Train Epoch: 1 [157824/225000 (70%)] Loss: 15295.175781\n",
      "Train Epoch: 1 [159232/225000 (71%)] Loss: 15361.112305\n",
      "Train Epoch: 1 [160640/225000 (71%)] Loss: 15201.074219\n",
      "Train Epoch: 1 [162048/225000 (72%)] Loss: 15299.331055\n",
      "Train Epoch: 1 [163456/225000 (73%)] Loss: 14810.265625\n",
      "Train Epoch: 1 [164864/225000 (73%)] Loss: 15687.209961\n",
      "Train Epoch: 1 [166272/225000 (74%)] Loss: 15202.622070\n",
      "Train Epoch: 1 [167680/225000 (75%)] Loss: 15231.099609\n",
      "Train Epoch: 1 [169088/225000 (75%)] Loss: 14980.771484\n",
      "Train Epoch: 1 [170496/225000 (76%)] Loss: 15310.520508\n",
      "Train Epoch: 1 [171904/225000 (76%)] Loss: 15418.655273\n",
      "Train Epoch: 1 [173312/225000 (77%)] Loss: 15052.765625\n",
      "Train Epoch: 1 [174720/225000 (78%)] Loss: 15477.786133\n",
      "Train Epoch: 1 [176128/225000 (78%)] Loss: 15404.581055\n",
      "Train Epoch: 1 [177536/225000 (79%)] Loss: 14689.066406\n",
      "Train Epoch: 1 [178944/225000 (80%)] Loss: 15558.188477\n",
      "Train Epoch: 1 [180352/225000 (80%)] Loss: 14948.540039\n",
      "Train Epoch: 1 [181760/225000 (81%)] Loss: 15225.479492\n",
      "Train Epoch: 1 [183168/225000 (81%)] Loss: 15154.541016\n",
      "Train Epoch: 1 [184576/225000 (82%)] Loss: 15822.546875\n",
      "Train Epoch: 1 [185984/225000 (83%)] Loss: 15338.444336\n",
      "Train Epoch: 1 [187392/225000 (83%)] Loss: 15485.816406\n",
      "Train Epoch: 1 [188800/225000 (84%)] Loss: 14894.053711\n",
      "Train Epoch: 1 [190208/225000 (85%)] Loss: 15429.309570\n",
      "Train Epoch: 1 [191616/225000 (85%)] Loss: 15151.495117\n",
      "Train Epoch: 1 [193024/225000 (86%)] Loss: 15590.172852\n",
      "Train Epoch: 1 [194432/225000 (86%)] Loss: 15175.557617\n",
      "Train Epoch: 1 [195840/225000 (87%)] Loss: 15369.593750\n",
      "Train Epoch: 1 [197248/225000 (88%)] Loss: 15574.643555\n",
      "Train Epoch: 1 [198656/225000 (88%)] Loss: 15461.516602\n",
      "Train Epoch: 1 [200064/225000 (89%)] Loss: 15296.972656\n",
      "Train Epoch: 1 [201472/225000 (90%)] Loss: 15489.086914\n",
      "Train Epoch: 1 [202880/225000 (90%)] Loss: 14875.673828\n",
      "Train Epoch: 1 [204288/225000 (91%)] Loss: 15530.424805\n",
      "Train Epoch: 1 [205696/225000 (91%)] Loss: 15016.702148\n",
      "Train Epoch: 1 [207104/225000 (92%)] Loss: 15557.985352\n",
      "Train Epoch: 1 [208512/225000 (93%)] Loss: 15274.848633\n",
      "Train Epoch: 1 [209920/225000 (93%)] Loss: 15036.092773\n",
      "Train Epoch: 1 [211328/225000 (94%)] Loss: 15600.782227\n",
      "Train Epoch: 1 [212736/225000 (95%)] Loss: 15165.791016\n",
      "Train Epoch: 1 [214144/225000 (95%)] Loss: 15360.461914\n",
      "Train Epoch: 1 [215552/225000 (96%)] Loss: 15902.763672\n",
      "Train Epoch: 1 [216960/225000 (96%)] Loss: 15199.965820\n",
      "Train Epoch: 1 [218368/225000 (97%)] Loss: 15813.829102\n",
      "Train Epoch: 1 [219776/225000 (98%)] Loss: 15267.403320\n",
      "Train Epoch: 1 [221184/225000 (98%)] Loss: 14914.882812\n",
      "Train Epoch: 1 [222592/225000 (99%)] Loss: 15021.070312\n",
      "Train Epoch: 1 [224000/225000 (100%)] Loss: 15197.770508\n",
      "    epoch          : 1\n",
      "    loss           : 17947.311991720882\n",
      "    val_loss       : 15234.629038735311\n",
      "Train Epoch: 2 [128/225000 (0%)] Loss: 15234.163086\n",
      "Train Epoch: 2 [1536/225000 (1%)] Loss: 15224.132812\n",
      "Train Epoch: 2 [2944/225000 (1%)] Loss: 15107.210938\n",
      "Train Epoch: 2 [4352/225000 (2%)] Loss: 15855.179688\n",
      "Train Epoch: 2 [5760/225000 (3%)] Loss: 15462.130859\n",
      "Train Epoch: 2 [7168/225000 (3%)] Loss: 15472.509766\n",
      "Train Epoch: 2 [8576/225000 (4%)] Loss: 14611.429688\n",
      "Train Epoch: 2 [9984/225000 (4%)] Loss: 15213.666016\n",
      "Train Epoch: 2 [11392/225000 (5%)] Loss: 15644.411133\n",
      "Train Epoch: 2 [12800/225000 (6%)] Loss: 15638.355469\n",
      "Train Epoch: 2 [14208/225000 (6%)] Loss: 15121.493164\n",
      "Train Epoch: 2 [15616/225000 (7%)] Loss: 15112.457031\n",
      "Train Epoch: 2 [17024/225000 (8%)] Loss: 15523.291016\n",
      "Train Epoch: 2 [18432/225000 (8%)] Loss: 15218.027344\n",
      "Train Epoch: 2 [19840/225000 (9%)] Loss: 15317.451172\n",
      "Train Epoch: 2 [21248/225000 (9%)] Loss: 15146.444336\n",
      "Train Epoch: 2 [22656/225000 (10%)] Loss: 15222.792969\n",
      "Train Epoch: 2 [24064/225000 (11%)] Loss: 14960.121094\n",
      "Train Epoch: 2 [25472/225000 (11%)] Loss: 15173.673828\n",
      "Train Epoch: 2 [26880/225000 (12%)] Loss: 16054.680664\n",
      "Train Epoch: 2 [28288/225000 (13%)] Loss: 15722.932617\n",
      "Train Epoch: 2 [29696/225000 (13%)] Loss: 15223.017578\n",
      "Train Epoch: 2 [31104/225000 (14%)] Loss: 15062.630859\n",
      "Train Epoch: 2 [32512/225000 (14%)] Loss: 15031.291992\n",
      "Train Epoch: 2 [33920/225000 (15%)] Loss: 15291.887695\n",
      "Train Epoch: 2 [35328/225000 (16%)] Loss: 15439.228516\n",
      "Train Epoch: 2 [36736/225000 (16%)] Loss: 15787.665039\n",
      "Train Epoch: 2 [38144/225000 (17%)] Loss: 15356.017578\n",
      "Train Epoch: 2 [39552/225000 (18%)] Loss: 15049.343750\n",
      "Train Epoch: 2 [40960/225000 (18%)] Loss: 15186.452148\n",
      "Train Epoch: 2 [42368/225000 (19%)] Loss: 14690.451172\n",
      "Train Epoch: 2 [43776/225000 (19%)] Loss: 15319.436523\n",
      "Train Epoch: 2 [45184/225000 (20%)] Loss: 15566.298828\n",
      "Train Epoch: 2 [46592/225000 (21%)] Loss: 15585.657227\n",
      "Train Epoch: 2 [48000/225000 (21%)] Loss: 15569.064453\n",
      "Train Epoch: 2 [49408/225000 (22%)] Loss: 15283.479492\n",
      "Train Epoch: 2 [50816/225000 (23%)] Loss: 14988.818359\n",
      "Train Epoch: 2 [52224/225000 (23%)] Loss: 15708.900391\n",
      "Train Epoch: 2 [53632/225000 (24%)] Loss: 15261.362305\n",
      "Train Epoch: 2 [55040/225000 (24%)] Loss: 15503.480469\n",
      "Train Epoch: 2 [56448/225000 (25%)] Loss: 15357.540039\n",
      "Train Epoch: 2 [57856/225000 (26%)] Loss: 15228.391602\n",
      "Train Epoch: 2 [59264/225000 (26%)] Loss: 14731.762695\n",
      "Train Epoch: 2 [60672/225000 (27%)] Loss: 15229.288086\n",
      "Train Epoch: 2 [62080/225000 (28%)] Loss: 15129.494141\n",
      "Train Epoch: 2 [63488/225000 (28%)] Loss: 15493.312500\n",
      "Train Epoch: 2 [64896/225000 (29%)] Loss: 15281.976562\n",
      "Train Epoch: 2 [66304/225000 (29%)] Loss: 15192.693359\n",
      "Train Epoch: 2 [67712/225000 (30%)] Loss: 15470.192383\n",
      "Train Epoch: 2 [69120/225000 (31%)] Loss: 14781.717773\n",
      "Train Epoch: 2 [70528/225000 (31%)] Loss: 14891.958008\n",
      "Train Epoch: 2 [71936/225000 (32%)] Loss: 15656.830078\n",
      "Train Epoch: 2 [73344/225000 (33%)] Loss: 15001.181641\n",
      "Train Epoch: 2 [74752/225000 (33%)] Loss: 14886.840820\n",
      "Train Epoch: 2 [76160/225000 (34%)] Loss: 14973.623047\n",
      "Train Epoch: 2 [77568/225000 (34%)] Loss: 15311.724609\n",
      "Train Epoch: 2 [78976/225000 (35%)] Loss: 15169.351562\n",
      "Train Epoch: 2 [80384/225000 (36%)] Loss: 15300.818359\n",
      "Train Epoch: 2 [81792/225000 (36%)] Loss: 15037.216797\n",
      "Train Epoch: 2 [83200/225000 (37%)] Loss: 15373.190430\n",
      "Train Epoch: 2 [84608/225000 (38%)] Loss: 14978.600586\n",
      "Train Epoch: 2 [86016/225000 (38%)] Loss: 14498.707031\n",
      "Train Epoch: 2 [87424/225000 (39%)] Loss: 14988.815430\n",
      "Train Epoch: 2 [88832/225000 (39%)] Loss: 15082.923828\n",
      "Train Epoch: 2 [90240/225000 (40%)] Loss: 15462.625977\n",
      "Train Epoch: 2 [91648/225000 (41%)] Loss: 14875.977539\n",
      "Train Epoch: 2 [93056/225000 (41%)] Loss: 15378.566406\n",
      "Train Epoch: 2 [94464/225000 (42%)] Loss: 14903.358398\n",
      "Train Epoch: 2 [95872/225000 (43%)] Loss: 15137.371094\n",
      "Train Epoch: 2 [97280/225000 (43%)] Loss: 15335.496094\n",
      "Train Epoch: 2 [98688/225000 (44%)] Loss: 15228.185547\n",
      "Train Epoch: 2 [100096/225000 (44%)] Loss: 14729.726562\n",
      "Train Epoch: 2 [101504/225000 (45%)] Loss: 15416.300781\n",
      "Train Epoch: 2 [102912/225000 (46%)] Loss: 15071.069336\n",
      "Train Epoch: 2 [104320/225000 (46%)] Loss: 15153.049805\n",
      "Train Epoch: 2 [105728/225000 (47%)] Loss: 15245.154297\n",
      "Train Epoch: 2 [107136/225000 (48%)] Loss: 14806.305664\n",
      "Train Epoch: 2 [108544/225000 (48%)] Loss: 15451.638672\n",
      "Train Epoch: 2 [109952/225000 (49%)] Loss: 14994.357422\n",
      "Train Epoch: 2 [111360/225000 (49%)] Loss: 15262.263672\n",
      "Train Epoch: 2 [112768/225000 (50%)] Loss: 15709.721680\n",
      "Train Epoch: 2 [114176/225000 (51%)] Loss: 15181.784180\n",
      "Train Epoch: 2 [115584/225000 (51%)] Loss: 14862.397461\n",
      "Train Epoch: 2 [116992/225000 (52%)] Loss: 15521.910156\n",
      "Train Epoch: 2 [118400/225000 (53%)] Loss: 15112.648438\n",
      "Train Epoch: 2 [119808/225000 (53%)] Loss: 15285.667969\n",
      "Train Epoch: 2 [121216/225000 (54%)] Loss: 14917.458984\n",
      "Train Epoch: 2 [122624/225000 (54%)] Loss: 15187.888672\n",
      "Train Epoch: 2 [124032/225000 (55%)] Loss: 15254.301758\n",
      "Train Epoch: 2 [125440/225000 (56%)] Loss: 15489.074219\n",
      "Train Epoch: 2 [126848/225000 (56%)] Loss: 16271.140625\n",
      "Train Epoch: 2 [128256/225000 (57%)] Loss: 14914.423828\n",
      "Train Epoch: 2 [129664/225000 (58%)] Loss: 15289.106445\n",
      "Train Epoch: 2 [131072/225000 (58%)] Loss: 15059.102539\n",
      "Train Epoch: 2 [132480/225000 (59%)] Loss: 15566.229492\n",
      "Train Epoch: 2 [133888/225000 (60%)] Loss: 14883.375977\n",
      "Train Epoch: 2 [135296/225000 (60%)] Loss: 15239.071289\n",
      "Train Epoch: 2 [136704/225000 (61%)] Loss: 15060.604492\n",
      "Train Epoch: 2 [138112/225000 (61%)] Loss: 14812.957031\n",
      "Train Epoch: 2 [139520/225000 (62%)] Loss: 15401.321289\n",
      "Train Epoch: 2 [140928/225000 (63%)] Loss: 15233.291016\n",
      "Train Epoch: 2 [142336/225000 (63%)] Loss: 15437.290039\n",
      "Train Epoch: 2 [143744/225000 (64%)] Loss: 15106.283203\n",
      "Train Epoch: 2 [145152/225000 (65%)] Loss: 15073.402344\n",
      "Train Epoch: 2 [146560/225000 (65%)] Loss: 15143.023438\n",
      "Train Epoch: 2 [147968/225000 (66%)] Loss: 15139.374023\n",
      "Train Epoch: 2 [149376/225000 (66%)] Loss: 15072.699219\n",
      "Train Epoch: 2 [150784/225000 (67%)] Loss: 15186.021484\n",
      "Train Epoch: 2 [152192/225000 (68%)] Loss: 15273.670898\n",
      "Train Epoch: 2 [153600/225000 (68%)] Loss: 15054.364258\n",
      "Train Epoch: 2 [155008/225000 (69%)] Loss: 15077.411133\n",
      "Train Epoch: 2 [156416/225000 (70%)] Loss: 15469.536133\n",
      "Train Epoch: 2 [157824/225000 (70%)] Loss: 15072.155273\n",
      "Train Epoch: 2 [159232/225000 (71%)] Loss: 15174.833008\n",
      "Train Epoch: 2 [160640/225000 (71%)] Loss: 15089.859375\n",
      "Train Epoch: 2 [162048/225000 (72%)] Loss: 15012.134766\n",
      "Train Epoch: 2 [163456/225000 (73%)] Loss: 15101.398438\n",
      "Train Epoch: 2 [164864/225000 (73%)] Loss: 15624.898438\n",
      "Train Epoch: 2 [166272/225000 (74%)] Loss: 15162.626953\n",
      "Train Epoch: 2 [167680/225000 (75%)] Loss: 14980.663086\n",
      "Train Epoch: 2 [169088/225000 (75%)] Loss: 14758.735352\n",
      "Train Epoch: 2 [170496/225000 (76%)] Loss: 15327.132812\n",
      "Train Epoch: 2 [171904/225000 (76%)] Loss: 14940.165039\n",
      "Train Epoch: 2 [173312/225000 (77%)] Loss: 14818.289062\n",
      "Train Epoch: 2 [174720/225000 (78%)] Loss: 14991.768555\n",
      "Train Epoch: 2 [176128/225000 (78%)] Loss: 14859.947266\n",
      "Train Epoch: 2 [177536/225000 (79%)] Loss: 15504.949219\n",
      "Train Epoch: 2 [178944/225000 (80%)] Loss: 15093.655273\n",
      "Train Epoch: 2 [180352/225000 (80%)] Loss: 15191.439453\n",
      "Train Epoch: 2 [181760/225000 (81%)] Loss: 15201.291016\n",
      "Train Epoch: 2 [183168/225000 (81%)] Loss: 15126.791992\n",
      "Train Epoch: 2 [184576/225000 (82%)] Loss: 15189.268555\n",
      "Train Epoch: 2 [185984/225000 (83%)] Loss: 15099.357422\n",
      "Train Epoch: 2 [187392/225000 (83%)] Loss: 15286.713867\n",
      "Train Epoch: 2 [188800/225000 (84%)] Loss: 15181.612305\n",
      "Train Epoch: 2 [190208/225000 (85%)] Loss: 15103.865234\n",
      "Train Epoch: 2 [191616/225000 (85%)] Loss: 15531.776367\n",
      "Train Epoch: 2 [193024/225000 (86%)] Loss: 14597.135742\n",
      "Train Epoch: 2 [194432/225000 (86%)] Loss: 14893.115234\n",
      "Train Epoch: 2 [195840/225000 (87%)] Loss: 15610.081055\n",
      "Train Epoch: 2 [197248/225000 (88%)] Loss: 15471.551758\n",
      "Train Epoch: 2 [198656/225000 (88%)] Loss: 15055.884766\n",
      "Train Epoch: 2 [200064/225000 (89%)] Loss: 14433.856445\n",
      "Train Epoch: 2 [201472/225000 (90%)] Loss: 15282.812500\n",
      "Train Epoch: 2 [202880/225000 (90%)] Loss: 15173.761719\n",
      "Train Epoch: 2 [204288/225000 (91%)] Loss: 14819.520508\n",
      "Train Epoch: 2 [205696/225000 (91%)] Loss: 14915.497070\n",
      "Train Epoch: 2 [207104/225000 (92%)] Loss: 15547.113281\n",
      "Train Epoch: 2 [208512/225000 (93%)] Loss: 15689.084961\n",
      "Train Epoch: 2 [209920/225000 (93%)] Loss: 15185.110352\n",
      "Train Epoch: 2 [211328/225000 (94%)] Loss: 15493.596680\n",
      "Train Epoch: 2 [212736/225000 (95%)] Loss: 15259.298828\n",
      "Train Epoch: 2 [214144/225000 (95%)] Loss: 15132.415039\n",
      "Train Epoch: 2 [215552/225000 (96%)] Loss: 14896.746094\n",
      "Train Epoch: 2 [216960/225000 (96%)] Loss: 15266.115234\n",
      "Train Epoch: 2 [218368/225000 (97%)] Loss: 15095.912109\n",
      "Train Epoch: 2 [219776/225000 (98%)] Loss: 15250.385742\n",
      "Train Epoch: 2 [221184/225000 (98%)] Loss: 15289.951172\n",
      "Train Epoch: 2 [222592/225000 (99%)] Loss: 15500.256836\n",
      "Train Epoch: 2 [224000/225000 (100%)] Loss: 14683.890625\n",
      "    epoch          : 2\n",
      "    loss           : 15225.821404050235\n",
      "    val_loss       : 15152.564916587606\n",
      "Train Epoch: 3 [128/225000 (0%)] Loss: 15061.445312\n",
      "Train Epoch: 3 [1536/225000 (1%)] Loss: 14972.733398\n",
      "Train Epoch: 3 [2944/225000 (1%)] Loss: 14871.703125\n",
      "Train Epoch: 3 [4352/225000 (2%)] Loss: 16000.569336\n",
      "Train Epoch: 3 [5760/225000 (3%)] Loss: 15346.532227\n",
      "Train Epoch: 3 [7168/225000 (3%)] Loss: 15340.441406\n",
      "Train Epoch: 3 [8576/225000 (4%)] Loss: 15901.307617\n",
      "Train Epoch: 3 [9984/225000 (4%)] Loss: 15131.050781\n",
      "Train Epoch: 3 [11392/225000 (5%)] Loss: 15222.562500\n",
      "Train Epoch: 3 [12800/225000 (6%)] Loss: 14826.390625\n",
      "Train Epoch: 3 [14208/225000 (6%)] Loss: 15472.627930\n",
      "Train Epoch: 3 [15616/225000 (7%)] Loss: 15069.249023\n",
      "Train Epoch: 3 [17024/225000 (8%)] Loss: 14676.819336\n",
      "Train Epoch: 3 [18432/225000 (8%)] Loss: 15244.040039\n",
      "Train Epoch: 3 [19840/225000 (9%)] Loss: 15362.714844\n",
      "Train Epoch: 3 [21248/225000 (9%)] Loss: 14911.681641\n",
      "Train Epoch: 3 [22656/225000 (10%)] Loss: 15083.576172\n",
      "Train Epoch: 3 [24064/225000 (11%)] Loss: 15334.834961\n",
      "Train Epoch: 3 [25472/225000 (11%)] Loss: 15534.423828\n",
      "Train Epoch: 3 [26880/225000 (12%)] Loss: 15121.570312\n",
      "Train Epoch: 3 [28288/225000 (13%)] Loss: 15060.640625\n",
      "Train Epoch: 3 [29696/225000 (13%)] Loss: 14742.718750\n",
      "Train Epoch: 3 [31104/225000 (14%)] Loss: 15120.084961\n",
      "Train Epoch: 3 [32512/225000 (14%)] Loss: 15286.971680\n",
      "Train Epoch: 3 [33920/225000 (15%)] Loss: 14796.894531\n",
      "Train Epoch: 3 [35328/225000 (16%)] Loss: 14938.802734\n",
      "Train Epoch: 3 [36736/225000 (16%)] Loss: 14583.633789\n",
      "Train Epoch: 3 [38144/225000 (17%)] Loss: 15819.589844\n",
      "Train Epoch: 3 [39552/225000 (18%)] Loss: 15291.508789\n",
      "Train Epoch: 3 [40960/225000 (18%)] Loss: 14795.751953\n",
      "Train Epoch: 3 [42368/225000 (19%)] Loss: 15582.193359\n",
      "Train Epoch: 3 [43776/225000 (19%)] Loss: 15059.289062\n",
      "Train Epoch: 3 [45184/225000 (20%)] Loss: 14817.085938\n",
      "Train Epoch: 3 [46592/225000 (21%)] Loss: 15247.561523\n",
      "Train Epoch: 3 [48000/225000 (21%)] Loss: 14967.239258\n",
      "Train Epoch: 3 [49408/225000 (22%)] Loss: 15057.217773\n",
      "Train Epoch: 3 [50816/225000 (23%)] Loss: 14902.360352\n",
      "Train Epoch: 3 [52224/225000 (23%)] Loss: 15162.853516\n",
      "Train Epoch: 3 [53632/225000 (24%)] Loss: 15416.877930\n",
      "Train Epoch: 3 [55040/225000 (24%)] Loss: 15379.727539\n",
      "Train Epoch: 3 [56448/225000 (25%)] Loss: 15187.081055\n",
      "Train Epoch: 3 [57856/225000 (26%)] Loss: 15013.085938\n",
      "Train Epoch: 3 [59264/225000 (26%)] Loss: 15108.166992\n",
      "Train Epoch: 3 [60672/225000 (27%)] Loss: 14970.327148\n",
      "Train Epoch: 3 [62080/225000 (28%)] Loss: 14804.805664\n",
      "Train Epoch: 3 [63488/225000 (28%)] Loss: 15096.936523\n",
      "Train Epoch: 3 [64896/225000 (29%)] Loss: 15501.849609\n",
      "Train Epoch: 3 [66304/225000 (29%)] Loss: 14789.140625\n",
      "Train Epoch: 3 [67712/225000 (30%)] Loss: 14969.552734\n",
      "Train Epoch: 3 [69120/225000 (31%)] Loss: 15125.878906\n",
      "Train Epoch: 3 [70528/225000 (31%)] Loss: 15344.423828\n",
      "Train Epoch: 3 [71936/225000 (32%)] Loss: 14864.294922\n",
      "Train Epoch: 3 [73344/225000 (33%)] Loss: 15269.983398\n",
      "Train Epoch: 3 [74752/225000 (33%)] Loss: 15295.470703\n",
      "Train Epoch: 3 [76160/225000 (34%)] Loss: 15147.762695\n",
      "Train Epoch: 3 [77568/225000 (34%)] Loss: 15006.158203\n",
      "Train Epoch: 3 [78976/225000 (35%)] Loss: 15148.145508\n",
      "Train Epoch: 3 [80384/225000 (36%)] Loss: 14958.699219\n",
      "Train Epoch: 3 [81792/225000 (36%)] Loss: 15463.030273\n",
      "Train Epoch: 3 [83200/225000 (37%)] Loss: 15155.078125\n",
      "Train Epoch: 3 [84608/225000 (38%)] Loss: 15271.865234\n",
      "Train Epoch: 3 [86016/225000 (38%)] Loss: 15302.622070\n",
      "Train Epoch: 3 [87424/225000 (39%)] Loss: 14909.986328\n",
      "Train Epoch: 3 [88832/225000 (39%)] Loss: 15792.901367\n",
      "Train Epoch: 3 [90240/225000 (40%)] Loss: 15519.281250\n",
      "Train Epoch: 3 [91648/225000 (41%)] Loss: 14925.977539\n",
      "Train Epoch: 3 [93056/225000 (41%)] Loss: 15241.259766\n",
      "Train Epoch: 3 [94464/225000 (42%)] Loss: 15001.354492\n",
      "Train Epoch: 3 [95872/225000 (43%)] Loss: 14749.930664\n",
      "Train Epoch: 3 [97280/225000 (43%)] Loss: 15210.694336\n",
      "Train Epoch: 3 [98688/225000 (44%)] Loss: 14799.963867\n",
      "Train Epoch: 3 [100096/225000 (44%)] Loss: 15257.495117\n",
      "Train Epoch: 3 [101504/225000 (45%)] Loss: 15393.834961\n",
      "Train Epoch: 3 [102912/225000 (46%)] Loss: 15204.708984\n",
      "Train Epoch: 3 [104320/225000 (46%)] Loss: 14996.523438\n",
      "Train Epoch: 3 [105728/225000 (47%)] Loss: 15593.261719\n",
      "Train Epoch: 3 [107136/225000 (48%)] Loss: 15145.985352\n",
      "Train Epoch: 3 [108544/225000 (48%)] Loss: 14935.362305\n",
      "Train Epoch: 3 [109952/225000 (49%)] Loss: 15124.784180\n",
      "Train Epoch: 3 [111360/225000 (49%)] Loss: 15053.859375\n",
      "Train Epoch: 3 [112768/225000 (50%)] Loss: 15515.964844\n",
      "Train Epoch: 3 [114176/225000 (51%)] Loss: 15074.817383\n",
      "Train Epoch: 3 [115584/225000 (51%)] Loss: 14877.346680\n",
      "Train Epoch: 3 [116992/225000 (52%)] Loss: 15190.727539\n",
      "Train Epoch: 3 [118400/225000 (53%)] Loss: 15046.479492\n",
      "Train Epoch: 3 [119808/225000 (53%)] Loss: 15548.612305\n",
      "Train Epoch: 3 [121216/225000 (54%)] Loss: 15807.537109\n",
      "Train Epoch: 3 [122624/225000 (54%)] Loss: 15184.291992\n",
      "Train Epoch: 3 [124032/225000 (55%)] Loss: 15694.182617\n",
      "Train Epoch: 3 [125440/225000 (56%)] Loss: 15336.637695\n",
      "Train Epoch: 3 [126848/225000 (56%)] Loss: 15440.842773\n",
      "Train Epoch: 3 [128256/225000 (57%)] Loss: 15286.478516\n",
      "Train Epoch: 3 [129664/225000 (58%)] Loss: 15127.821289\n",
      "Train Epoch: 3 [131072/225000 (58%)] Loss: 15173.315430\n",
      "Train Epoch: 3 [132480/225000 (59%)] Loss: 15961.645508\n",
      "Train Epoch: 3 [133888/225000 (60%)] Loss: 14766.693359\n",
      "Train Epoch: 3 [135296/225000 (60%)] Loss: 14799.869141\n",
      "Train Epoch: 3 [136704/225000 (61%)] Loss: 15127.835938\n",
      "Train Epoch: 3 [138112/225000 (61%)] Loss: 14843.982422\n",
      "Train Epoch: 3 [139520/225000 (62%)] Loss: 14914.685547\n",
      "Train Epoch: 3 [140928/225000 (63%)] Loss: 15257.536133\n",
      "Train Epoch: 3 [142336/225000 (63%)] Loss: 15510.601562\n",
      "Train Epoch: 3 [143744/225000 (64%)] Loss: 15051.535156\n",
      "Train Epoch: 3 [145152/225000 (65%)] Loss: 14676.578125\n",
      "Train Epoch: 3 [146560/225000 (65%)] Loss: 15204.794922\n",
      "Train Epoch: 3 [147968/225000 (66%)] Loss: 15562.480469\n",
      "Train Epoch: 3 [149376/225000 (66%)] Loss: 15163.692383\n",
      "Train Epoch: 3 [150784/225000 (67%)] Loss: 14626.930664\n",
      "Train Epoch: 3 [152192/225000 (68%)] Loss: 15585.000000\n",
      "Train Epoch: 3 [153600/225000 (68%)] Loss: 15284.289062\n",
      "Train Epoch: 3 [155008/225000 (69%)] Loss: 15077.941406\n",
      "Train Epoch: 3 [156416/225000 (70%)] Loss: 15046.006836\n",
      "Train Epoch: 3 [157824/225000 (70%)] Loss: 15169.967773\n",
      "Train Epoch: 3 [159232/225000 (71%)] Loss: 14838.448242\n",
      "Train Epoch: 3 [160640/225000 (71%)] Loss: 15042.568359\n",
      "Train Epoch: 3 [162048/225000 (72%)] Loss: 15461.441406\n",
      "Train Epoch: 3 [163456/225000 (73%)] Loss: 15342.208984\n",
      "Train Epoch: 3 [164864/225000 (73%)] Loss: 15437.617188\n",
      "Train Epoch: 3 [166272/225000 (74%)] Loss: 15004.738281\n",
      "Train Epoch: 3 [167680/225000 (75%)] Loss: 15120.101562\n",
      "Train Epoch: 3 [169088/225000 (75%)] Loss: 15342.130859\n",
      "Train Epoch: 3 [170496/225000 (76%)] Loss: 15189.393555\n",
      "Train Epoch: 3 [171904/225000 (76%)] Loss: 15256.602539\n",
      "Train Epoch: 3 [173312/225000 (77%)] Loss: 14851.859375\n",
      "Train Epoch: 3 [174720/225000 (78%)] Loss: 15195.629883\n",
      "Train Epoch: 3 [176128/225000 (78%)] Loss: 14550.878906\n",
      "Train Epoch: 3 [177536/225000 (79%)] Loss: 15197.475586\n",
      "Train Epoch: 3 [178944/225000 (80%)] Loss: 15315.026367\n",
      "Train Epoch: 3 [180352/225000 (80%)] Loss: 15486.789062\n",
      "Train Epoch: 3 [181760/225000 (81%)] Loss: 15161.219727\n",
      "Train Epoch: 3 [183168/225000 (81%)] Loss: 15431.698242\n",
      "Train Epoch: 3 [184576/225000 (82%)] Loss: 15586.475586\n",
      "Train Epoch: 3 [185984/225000 (83%)] Loss: 15403.468750\n",
      "Train Epoch: 3 [187392/225000 (83%)] Loss: 15066.896484\n",
      "Train Epoch: 3 [188800/225000 (84%)] Loss: 15225.310547\n",
      "Train Epoch: 3 [190208/225000 (85%)] Loss: 15060.713867\n",
      "Train Epoch: 3 [191616/225000 (85%)] Loss: 15088.090820\n",
      "Train Epoch: 3 [193024/225000 (86%)] Loss: 15113.881836\n",
      "Train Epoch: 3 [194432/225000 (86%)] Loss: 15302.304688\n",
      "Train Epoch: 3 [195840/225000 (87%)] Loss: 15109.352539\n",
      "Train Epoch: 3 [197248/225000 (88%)] Loss: 15283.686523\n",
      "Train Epoch: 3 [198656/225000 (88%)] Loss: 15148.742188\n",
      "Train Epoch: 3 [200064/225000 (89%)] Loss: 14992.436523\n",
      "Train Epoch: 3 [201472/225000 (90%)] Loss: 15033.112305\n",
      "Train Epoch: 3 [202880/225000 (90%)] Loss: 14675.150391\n",
      "Train Epoch: 3 [204288/225000 (91%)] Loss: 15084.453125\n",
      "Train Epoch: 3 [205696/225000 (91%)] Loss: 16261.146484\n",
      "Train Epoch: 3 [207104/225000 (92%)] Loss: 15080.705078\n",
      "Train Epoch: 3 [208512/225000 (93%)] Loss: 15428.478516\n",
      "Train Epoch: 3 [209920/225000 (93%)] Loss: 15500.684570\n",
      "Train Epoch: 3 [211328/225000 (94%)] Loss: 15264.563477\n",
      "Train Epoch: 3 [212736/225000 (95%)] Loss: 15885.515625\n",
      "Train Epoch: 3 [214144/225000 (95%)] Loss: 15530.060547\n",
      "Train Epoch: 3 [215552/225000 (96%)] Loss: 15475.614258\n",
      "Train Epoch: 3 [216960/225000 (96%)] Loss: 15482.283203\n",
      "Train Epoch: 3 [218368/225000 (97%)] Loss: 14651.862305\n",
      "Train Epoch: 3 [219776/225000 (98%)] Loss: 14739.796875\n",
      "Train Epoch: 3 [221184/225000 (98%)] Loss: 15119.507812\n",
      "Train Epoch: 3 [222592/225000 (99%)] Loss: 14907.118164\n",
      "Train Epoch: 3 [224000/225000 (100%)] Loss: 15260.601562\n",
      "    epoch          : 3\n",
      "    loss           : 15188.780508967933\n",
      "    val_loss       : 15175.041550036596\n",
      "Train Epoch: 4 [128/225000 (0%)] Loss: 15021.884766\n",
      "Train Epoch: 4 [1536/225000 (1%)] Loss: 14741.537109\n",
      "Train Epoch: 4 [2944/225000 (1%)] Loss: 15102.120117\n",
      "Train Epoch: 4 [4352/225000 (2%)] Loss: 15177.961914\n",
      "Train Epoch: 4 [5760/225000 (3%)] Loss: 15117.084961\n",
      "Train Epoch: 4 [7168/225000 (3%)] Loss: 15768.324219\n",
      "Train Epoch: 4 [8576/225000 (4%)] Loss: 15400.528320\n",
      "Train Epoch: 4 [9984/225000 (4%)] Loss: 15096.519531\n",
      "Train Epoch: 4 [11392/225000 (5%)] Loss: 14888.283203\n",
      "Train Epoch: 4 [12800/225000 (6%)] Loss: 15549.135742\n",
      "Train Epoch: 4 [14208/225000 (6%)] Loss: 15089.544922\n",
      "Train Epoch: 4 [15616/225000 (7%)] Loss: 15135.200195\n",
      "Train Epoch: 4 [17024/225000 (8%)] Loss: 14751.806641\n",
      "Train Epoch: 4 [18432/225000 (8%)] Loss: 15304.666992\n",
      "Train Epoch: 4 [19840/225000 (9%)] Loss: 15593.195312\n",
      "Train Epoch: 4 [21248/225000 (9%)] Loss: 15179.937500\n",
      "Train Epoch: 4 [22656/225000 (10%)] Loss: 14982.019531\n",
      "Train Epoch: 4 [24064/225000 (11%)] Loss: 15109.440430\n",
      "Train Epoch: 4 [25472/225000 (11%)] Loss: 14998.302734\n",
      "Train Epoch: 4 [26880/225000 (12%)] Loss: 14770.650391\n",
      "Train Epoch: 4 [28288/225000 (13%)] Loss: 15467.130859\n",
      "Train Epoch: 4 [29696/225000 (13%)] Loss: 15315.106445\n",
      "Train Epoch: 4 [31104/225000 (14%)] Loss: 15549.099609\n",
      "Train Epoch: 4 [32512/225000 (14%)] Loss: 14910.520508\n",
      "Train Epoch: 4 [33920/225000 (15%)] Loss: 15039.223633\n",
      "Train Epoch: 4 [35328/225000 (16%)] Loss: 15242.825195\n",
      "Train Epoch: 4 [36736/225000 (16%)] Loss: 15386.855469\n",
      "Train Epoch: 4 [38144/225000 (17%)] Loss: 15192.215820\n",
      "Train Epoch: 4 [39552/225000 (18%)] Loss: 14946.662109\n",
      "Train Epoch: 4 [40960/225000 (18%)] Loss: 15146.421875\n",
      "Train Epoch: 4 [42368/225000 (19%)] Loss: 15262.381836\n",
      "Train Epoch: 4 [43776/225000 (19%)] Loss: 14923.909180\n",
      "Train Epoch: 4 [45184/225000 (20%)] Loss: 15266.010742\n",
      "Train Epoch: 4 [46592/225000 (21%)] Loss: 14931.823242\n",
      "Train Epoch: 4 [48000/225000 (21%)] Loss: 15406.120117\n",
      "Train Epoch: 4 [49408/225000 (22%)] Loss: 15658.265625\n",
      "Train Epoch: 4 [50816/225000 (23%)] Loss: 14976.474609\n",
      "Train Epoch: 4 [52224/225000 (23%)] Loss: 15257.083008\n",
      "Train Epoch: 4 [53632/225000 (24%)] Loss: 15215.492188\n",
      "Train Epoch: 4 [55040/225000 (24%)] Loss: 14609.843750\n",
      "Train Epoch: 4 [56448/225000 (25%)] Loss: 15075.833984\n",
      "Train Epoch: 4 [57856/225000 (26%)] Loss: 14883.517578\n",
      "Train Epoch: 4 [59264/225000 (26%)] Loss: 15238.323242\n",
      "Train Epoch: 4 [60672/225000 (27%)] Loss: 14624.005859\n",
      "Train Epoch: 4 [62080/225000 (28%)] Loss: 15112.272461\n",
      "Train Epoch: 4 [63488/225000 (28%)] Loss: 15060.483398\n",
      "Train Epoch: 4 [64896/225000 (29%)] Loss: 15216.815430\n",
      "Train Epoch: 4 [66304/225000 (29%)] Loss: 15171.868164\n",
      "Train Epoch: 4 [67712/225000 (30%)] Loss: 15730.564453\n",
      "Train Epoch: 4 [69120/225000 (31%)] Loss: 15469.736328\n",
      "Train Epoch: 4 [70528/225000 (31%)] Loss: 14736.795898\n",
      "Train Epoch: 4 [71936/225000 (32%)] Loss: 15173.242188\n",
      "Train Epoch: 4 [73344/225000 (33%)] Loss: 14931.308594\n",
      "Train Epoch: 4 [74752/225000 (33%)] Loss: 15069.677734\n",
      "Train Epoch: 4 [76160/225000 (34%)] Loss: 15528.411133\n",
      "Train Epoch: 4 [77568/225000 (34%)] Loss: 15126.484375\n",
      "Train Epoch: 4 [78976/225000 (35%)] Loss: 14785.213867\n",
      "Train Epoch: 4 [80384/225000 (36%)] Loss: 15228.031250\n",
      "Train Epoch: 4 [81792/225000 (36%)] Loss: 15618.000977\n",
      "Train Epoch: 4 [83200/225000 (37%)] Loss: 15452.235352\n",
      "Train Epoch: 4 [84608/225000 (38%)] Loss: 15053.140625\n",
      "Train Epoch: 4 [86016/225000 (38%)] Loss: 15212.397461\n",
      "Train Epoch: 4 [87424/225000 (39%)] Loss: 14952.171875\n",
      "Train Epoch: 4 [88832/225000 (39%)] Loss: 15015.279297\n",
      "Train Epoch: 4 [90240/225000 (40%)] Loss: 24030.820312\n",
      "Train Epoch: 4 [91648/225000 (41%)] Loss: 14829.766602\n",
      "Train Epoch: 4 [93056/225000 (41%)] Loss: 15168.773438\n",
      "Train Epoch: 4 [94464/225000 (42%)] Loss: 15011.484375\n",
      "Train Epoch: 4 [95872/225000 (43%)] Loss: 14986.432617\n",
      "Train Epoch: 4 [97280/225000 (43%)] Loss: 14886.300781\n",
      "Train Epoch: 4 [98688/225000 (44%)] Loss: 15639.090820\n",
      "Train Epoch: 4 [100096/225000 (44%)] Loss: 15157.339844\n",
      "Train Epoch: 4 [101504/225000 (45%)] Loss: 14948.447266\n",
      "Train Epoch: 4 [102912/225000 (46%)] Loss: 14648.615234\n",
      "Train Epoch: 4 [104320/225000 (46%)] Loss: 15405.787109\n",
      "Train Epoch: 4 [105728/225000 (47%)] Loss: 15073.278320\n",
      "Train Epoch: 4 [107136/225000 (48%)] Loss: 15527.053711\n",
      "Train Epoch: 4 [108544/225000 (48%)] Loss: 15031.458008\n",
      "Train Epoch: 4 [109952/225000 (49%)] Loss: 15339.872070\n",
      "Train Epoch: 4 [111360/225000 (49%)] Loss: 14842.965820\n",
      "Train Epoch: 4 [112768/225000 (50%)] Loss: 15261.766602\n",
      "Train Epoch: 4 [114176/225000 (51%)] Loss: 14889.267578\n",
      "Train Epoch: 4 [115584/225000 (51%)] Loss: 15281.950195\n",
      "Train Epoch: 4 [116992/225000 (52%)] Loss: 15213.868164\n",
      "Train Epoch: 4 [118400/225000 (53%)] Loss: 14725.730469\n",
      "Train Epoch: 4 [119808/225000 (53%)] Loss: 15350.522461\n",
      "Train Epoch: 4 [121216/225000 (54%)] Loss: 15128.867188\n",
      "Train Epoch: 4 [122624/225000 (54%)] Loss: 14901.661133\n",
      "Train Epoch: 4 [124032/225000 (55%)] Loss: 14967.112305\n",
      "Train Epoch: 4 [125440/225000 (56%)] Loss: 15252.478516\n",
      "Train Epoch: 4 [126848/225000 (56%)] Loss: 15442.194336\n",
      "Train Epoch: 4 [128256/225000 (57%)] Loss: 15155.135742\n",
      "Train Epoch: 4 [129664/225000 (58%)] Loss: 14681.195312\n",
      "Train Epoch: 4 [131072/225000 (58%)] Loss: 15198.215820\n",
      "Train Epoch: 4 [132480/225000 (59%)] Loss: 15200.556641\n",
      "Train Epoch: 4 [133888/225000 (60%)] Loss: 15024.068359\n",
      "Train Epoch: 4 [135296/225000 (60%)] Loss: 15364.365234\n",
      "Train Epoch: 4 [136704/225000 (61%)] Loss: 14951.676758\n",
      "Train Epoch: 4 [138112/225000 (61%)] Loss: 15042.112305\n",
      "Train Epoch: 4 [139520/225000 (62%)] Loss: 15044.642578\n",
      "Train Epoch: 4 [140928/225000 (63%)] Loss: 14857.733398\n",
      "Train Epoch: 4 [142336/225000 (63%)] Loss: 15198.095703\n",
      "Train Epoch: 4 [143744/225000 (64%)] Loss: 15045.993164\n",
      "Train Epoch: 4 [145152/225000 (65%)] Loss: 15499.293945\n",
      "Train Epoch: 4 [146560/225000 (65%)] Loss: 15215.762695\n",
      "Train Epoch: 4 [147968/225000 (66%)] Loss: 15005.411133\n",
      "Train Epoch: 4 [149376/225000 (66%)] Loss: 14656.081055\n",
      "Train Epoch: 4 [150784/225000 (67%)] Loss: 14612.091797\n",
      "Train Epoch: 4 [152192/225000 (68%)] Loss: 15157.473633\n",
      "Train Epoch: 4 [153600/225000 (68%)] Loss: 15104.520508\n",
      "Train Epoch: 4 [155008/225000 (69%)] Loss: 14998.047852\n",
      "Train Epoch: 4 [156416/225000 (70%)] Loss: 14837.747070\n",
      "Train Epoch: 4 [157824/225000 (70%)] Loss: 15156.826172\n",
      "Train Epoch: 4 [159232/225000 (71%)] Loss: 15369.119141\n",
      "Train Epoch: 4 [160640/225000 (71%)] Loss: 15225.363281\n",
      "Train Epoch: 4 [162048/225000 (72%)] Loss: 14967.897461\n",
      "Train Epoch: 4 [163456/225000 (73%)] Loss: 14864.474609\n",
      "Train Epoch: 4 [164864/225000 (73%)] Loss: 14998.277344\n",
      "Train Epoch: 4 [166272/225000 (74%)] Loss: 15316.208984\n",
      "Train Epoch: 4 [167680/225000 (75%)] Loss: 22574.068359\n",
      "Train Epoch: 4 [169088/225000 (75%)] Loss: 14901.681641\n",
      "Train Epoch: 4 [170496/225000 (76%)] Loss: 15479.845703\n",
      "Train Epoch: 4 [171904/225000 (76%)] Loss: 15072.187500\n",
      "Train Epoch: 4 [173312/225000 (77%)] Loss: 15189.668945\n",
      "Train Epoch: 4 [174720/225000 (78%)] Loss: 15044.115234\n",
      "Train Epoch: 4 [176128/225000 (78%)] Loss: 14684.776367\n",
      "Train Epoch: 4 [177536/225000 (79%)] Loss: 15452.388672\n",
      "Train Epoch: 4 [178944/225000 (80%)] Loss: 15026.836914\n",
      "Train Epoch: 4 [180352/225000 (80%)] Loss: 15317.745117\n",
      "Train Epoch: 4 [181760/225000 (81%)] Loss: 14972.746094\n",
      "Train Epoch: 4 [183168/225000 (81%)] Loss: 15573.111328\n",
      "Train Epoch: 4 [184576/225000 (82%)] Loss: 15506.485352\n",
      "Train Epoch: 4 [185984/225000 (83%)] Loss: 14661.812500\n",
      "Train Epoch: 4 [187392/225000 (83%)] Loss: 15505.348633\n",
      "Train Epoch: 4 [188800/225000 (84%)] Loss: 14787.713867\n",
      "Train Epoch: 4 [190208/225000 (85%)] Loss: 15074.780273\n",
      "Train Epoch: 4 [191616/225000 (85%)] Loss: 15427.690430\n",
      "Train Epoch: 4 [193024/225000 (86%)] Loss: 15131.532227\n",
      "Train Epoch: 4 [194432/225000 (86%)] Loss: 15297.909180\n",
      "Train Epoch: 4 [195840/225000 (87%)] Loss: 15087.298828\n",
      "Train Epoch: 4 [197248/225000 (88%)] Loss: 14661.398438\n",
      "Train Epoch: 4 [198656/225000 (88%)] Loss: 15341.439453\n",
      "Train Epoch: 4 [200064/225000 (89%)] Loss: 15039.013672\n",
      "Train Epoch: 4 [201472/225000 (90%)] Loss: 15287.215820\n",
      "Train Epoch: 4 [202880/225000 (90%)] Loss: 15147.255859\n",
      "Train Epoch: 4 [204288/225000 (91%)] Loss: 15007.765625\n",
      "Train Epoch: 4 [205696/225000 (91%)] Loss: 14684.471680\n",
      "Train Epoch: 4 [207104/225000 (92%)] Loss: 15012.602539\n",
      "Train Epoch: 4 [208512/225000 (93%)] Loss: 15305.831055\n",
      "Train Epoch: 4 [209920/225000 (93%)] Loss: 15149.101562\n",
      "Train Epoch: 4 [211328/225000 (94%)] Loss: 15163.825195\n",
      "Train Epoch: 4 [212736/225000 (95%)] Loss: 15228.213867\n",
      "Train Epoch: 4 [214144/225000 (95%)] Loss: 15024.413086\n",
      "Train Epoch: 4 [215552/225000 (96%)] Loss: 14983.694336\n",
      "Train Epoch: 4 [216960/225000 (96%)] Loss: 14615.209961\n",
      "Train Epoch: 4 [218368/225000 (97%)] Loss: 15058.294922\n",
      "Train Epoch: 4 [219776/225000 (98%)] Loss: 14732.701172\n",
      "Train Epoch: 4 [221184/225000 (98%)] Loss: 15873.026367\n",
      "Train Epoch: 4 [222592/225000 (99%)] Loss: 14725.993164\n",
      "Train Epoch: 4 [224000/225000 (100%)] Loss: 15331.435547\n",
      "    epoch          : 4\n",
      "    loss           : 15186.608812282246\n",
      "    val_loss       : 15188.833406100164\n",
      "Train Epoch: 5 [128/225000 (0%)] Loss: 17229.769531\n",
      "Train Epoch: 5 [1536/225000 (1%)] Loss: 15285.124023\n",
      "Train Epoch: 5 [2944/225000 (1%)] Loss: 15317.238281\n",
      "Train Epoch: 5 [4352/225000 (2%)] Loss: 15324.538086\n",
      "Train Epoch: 5 [5760/225000 (3%)] Loss: 14907.327148\n",
      "Train Epoch: 5 [7168/225000 (3%)] Loss: 15338.676758\n",
      "Train Epoch: 5 [8576/225000 (4%)] Loss: 15435.272461\n",
      "Train Epoch: 5 [9984/225000 (4%)] Loss: 15435.319336\n",
      "Train Epoch: 5 [11392/225000 (5%)] Loss: 14890.758789\n",
      "Train Epoch: 5 [12800/225000 (6%)] Loss: 15067.022461\n",
      "Train Epoch: 5 [14208/225000 (6%)] Loss: 15251.104492\n",
      "Train Epoch: 5 [15616/225000 (7%)] Loss: 15267.492188\n",
      "Train Epoch: 5 [17024/225000 (8%)] Loss: 15289.406250\n",
      "Train Epoch: 5 [18432/225000 (8%)] Loss: 14773.947266\n",
      "Train Epoch: 5 [19840/225000 (9%)] Loss: 14938.365234\n",
      "Train Epoch: 5 [21248/225000 (9%)] Loss: 14804.879883\n",
      "Train Epoch: 5 [22656/225000 (10%)] Loss: 15351.460938\n",
      "Train Epoch: 5 [24064/225000 (11%)] Loss: 20099.726562\n",
      "Train Epoch: 5 [25472/225000 (11%)] Loss: 15181.767578\n",
      "Train Epoch: 5 [26880/225000 (12%)] Loss: 15212.329102\n",
      "Train Epoch: 5 [28288/225000 (13%)] Loss: 15130.845703\n",
      "Train Epoch: 5 [29696/225000 (13%)] Loss: 15301.061523\n",
      "Train Epoch: 5 [31104/225000 (14%)] Loss: 15101.710938\n",
      "Train Epoch: 5 [32512/225000 (14%)] Loss: 14970.573242\n",
      "Train Epoch: 5 [33920/225000 (15%)] Loss: 15037.296875\n",
      "Train Epoch: 5 [35328/225000 (16%)] Loss: 15375.716797\n",
      "Train Epoch: 5 [36736/225000 (16%)] Loss: 15070.572266\n",
      "Train Epoch: 5 [38144/225000 (17%)] Loss: 15207.269531\n",
      "Train Epoch: 5 [39552/225000 (18%)] Loss: 15034.011719\n",
      "Train Epoch: 5 [40960/225000 (18%)] Loss: 14884.092773\n",
      "Train Epoch: 5 [42368/225000 (19%)] Loss: 15204.415039\n",
      "Train Epoch: 5 [43776/225000 (19%)] Loss: 14669.029297\n",
      "Train Epoch: 5 [45184/225000 (20%)] Loss: 14968.807617\n",
      "Train Epoch: 5 [46592/225000 (21%)] Loss: 15688.254883\n",
      "Train Epoch: 5 [48000/225000 (21%)] Loss: 15281.238281\n",
      "Train Epoch: 5 [49408/225000 (22%)] Loss: 14843.834961\n",
      "Train Epoch: 5 [50816/225000 (23%)] Loss: 14725.618164\n",
      "Train Epoch: 5 [52224/225000 (23%)] Loss: 14973.899414\n",
      "Train Epoch: 5 [53632/225000 (24%)] Loss: 14982.029297\n",
      "Train Epoch: 5 [55040/225000 (24%)] Loss: 15195.800781\n",
      "Train Epoch: 5 [56448/225000 (25%)] Loss: 15459.557617\n",
      "Train Epoch: 5 [57856/225000 (26%)] Loss: 14880.757812\n",
      "Train Epoch: 5 [59264/225000 (26%)] Loss: 15136.706055\n",
      "Train Epoch: 5 [60672/225000 (27%)] Loss: 15165.288086\n",
      "Train Epoch: 5 [62080/225000 (28%)] Loss: 14460.392578\n",
      "Train Epoch: 5 [63488/225000 (28%)] Loss: 15123.987305\n",
      "Train Epoch: 5 [64896/225000 (29%)] Loss: 15820.527344\n",
      "Train Epoch: 5 [66304/225000 (29%)] Loss: 15172.256836\n",
      "Train Epoch: 5 [67712/225000 (30%)] Loss: 14896.083984\n",
      "Train Epoch: 5 [69120/225000 (31%)] Loss: 15129.227539\n",
      "Train Epoch: 5 [70528/225000 (31%)] Loss: 15028.925781\n",
      "Train Epoch: 5 [71936/225000 (32%)] Loss: 14987.884766\n",
      "Train Epoch: 5 [73344/225000 (33%)] Loss: 15412.125977\n",
      "Train Epoch: 5 [74752/225000 (33%)] Loss: 15193.330078\n",
      "Train Epoch: 5 [76160/225000 (34%)] Loss: 14750.093750\n",
      "Train Epoch: 5 [77568/225000 (34%)] Loss: 15486.561523\n",
      "Train Epoch: 5 [78976/225000 (35%)] Loss: 15032.739258\n",
      "Train Epoch: 5 [80384/225000 (36%)] Loss: 15071.373047\n",
      "Train Epoch: 5 [81792/225000 (36%)] Loss: 14825.064453\n",
      "Train Epoch: 5 [83200/225000 (37%)] Loss: 15442.516602\n",
      "Train Epoch: 5 [84608/225000 (38%)] Loss: 15413.739258\n",
      "Train Epoch: 5 [86016/225000 (38%)] Loss: 14820.036133\n",
      "Train Epoch: 5 [87424/225000 (39%)] Loss: 14755.504883\n",
      "Train Epoch: 5 [88832/225000 (39%)] Loss: 14556.263672\n",
      "Train Epoch: 5 [90240/225000 (40%)] Loss: 15198.313477\n",
      "Train Epoch: 5 [91648/225000 (41%)] Loss: 15156.068359\n",
      "Train Epoch: 5 [93056/225000 (41%)] Loss: 15060.938477\n",
      "Train Epoch: 5 [94464/225000 (42%)] Loss: 15164.886719\n",
      "Train Epoch: 5 [95872/225000 (43%)] Loss: 14882.240234\n",
      "Train Epoch: 5 [97280/225000 (43%)] Loss: 14967.149414\n",
      "Train Epoch: 5 [98688/225000 (44%)] Loss: 15141.423828\n",
      "Train Epoch: 5 [100096/225000 (44%)] Loss: 15252.100586\n",
      "Train Epoch: 5 [101504/225000 (45%)] Loss: 15258.939453\n",
      "Train Epoch: 5 [102912/225000 (46%)] Loss: 15327.333984\n",
      "Train Epoch: 5 [104320/225000 (46%)] Loss: 15143.494141\n",
      "Train Epoch: 5 [105728/225000 (47%)] Loss: 15020.084961\n",
      "Train Epoch: 5 [107136/225000 (48%)] Loss: 15021.100586\n",
      "Train Epoch: 5 [108544/225000 (48%)] Loss: 14906.408203\n",
      "Train Epoch: 5 [109952/225000 (49%)] Loss: 14775.694336\n",
      "Train Epoch: 5 [111360/225000 (49%)] Loss: 14923.541016\n",
      "Train Epoch: 5 [112768/225000 (50%)] Loss: 15161.010742\n",
      "Train Epoch: 5 [114176/225000 (51%)] Loss: 14976.288086\n",
      "Train Epoch: 5 [115584/225000 (51%)] Loss: 14763.124023\n",
      "Train Epoch: 5 [116992/225000 (52%)] Loss: 15018.419922\n",
      "Train Epoch: 5 [118400/225000 (53%)] Loss: 15062.835938\n",
      "Train Epoch: 5 [119808/225000 (53%)] Loss: 15282.854492\n",
      "Train Epoch: 5 [121216/225000 (54%)] Loss: 15218.500000\n",
      "Train Epoch: 5 [122624/225000 (54%)] Loss: 14978.313477\n",
      "Train Epoch: 5 [124032/225000 (55%)] Loss: 14689.234375\n",
      "Train Epoch: 5 [125440/225000 (56%)] Loss: 15517.378906\n",
      "Train Epoch: 5 [126848/225000 (56%)] Loss: 15361.644531\n",
      "Train Epoch: 5 [128256/225000 (57%)] Loss: 15082.058594\n",
      "Train Epoch: 5 [129664/225000 (58%)] Loss: 15255.042969\n",
      "Train Epoch: 5 [131072/225000 (58%)] Loss: 15153.898438\n",
      "Train Epoch: 5 [132480/225000 (59%)] Loss: 14926.207031\n",
      "Train Epoch: 5 [133888/225000 (60%)] Loss: 15204.456055\n",
      "Train Epoch: 5 [135296/225000 (60%)] Loss: 15116.232422\n",
      "Train Epoch: 5 [136704/225000 (61%)] Loss: 15100.873047\n",
      "Train Epoch: 5 [138112/225000 (61%)] Loss: 15283.169922\n",
      "Train Epoch: 5 [139520/225000 (62%)] Loss: 14428.531250\n",
      "Train Epoch: 5 [140928/225000 (63%)] Loss: 14764.795898\n",
      "Train Epoch: 5 [142336/225000 (63%)] Loss: 15113.062500\n",
      "Train Epoch: 5 [143744/225000 (64%)] Loss: 15322.011719\n",
      "Train Epoch: 5 [145152/225000 (65%)] Loss: 14980.937500\n",
      "Train Epoch: 5 [146560/225000 (65%)] Loss: 14961.475586\n",
      "Train Epoch: 5 [147968/225000 (66%)] Loss: 15125.769531\n",
      "Train Epoch: 5 [149376/225000 (66%)] Loss: 15090.808594\n",
      "Train Epoch: 5 [150784/225000 (67%)] Loss: 15157.291016\n",
      "Train Epoch: 5 [152192/225000 (68%)] Loss: 14908.383789\n",
      "Train Epoch: 5 [153600/225000 (68%)] Loss: 15079.342773\n",
      "Train Epoch: 5 [155008/225000 (69%)] Loss: 14865.442383\n",
      "Train Epoch: 5 [156416/225000 (70%)] Loss: 15258.295898\n",
      "Train Epoch: 5 [157824/225000 (70%)] Loss: 15627.287109\n",
      "Train Epoch: 5 [159232/225000 (71%)] Loss: 15127.089844\n",
      "Train Epoch: 5 [160640/225000 (71%)] Loss: 15094.701172\n",
      "Train Epoch: 5 [162048/225000 (72%)] Loss: 14641.244141\n",
      "Train Epoch: 5 [163456/225000 (73%)] Loss: 15379.607422\n",
      "Train Epoch: 5 [164864/225000 (73%)] Loss: 14955.751953\n",
      "Train Epoch: 5 [166272/225000 (74%)] Loss: 14937.270508\n",
      "Train Epoch: 5 [167680/225000 (75%)] Loss: 15085.792969\n",
      "Train Epoch: 5 [169088/225000 (75%)] Loss: 15072.475586\n",
      "Train Epoch: 5 [170496/225000 (76%)] Loss: 15160.796875\n",
      "Train Epoch: 5 [171904/225000 (76%)] Loss: 15123.170898\n",
      "Train Epoch: 5 [173312/225000 (77%)] Loss: 15357.037109\n",
      "Train Epoch: 5 [174720/225000 (78%)] Loss: 15250.705078\n",
      "Train Epoch: 5 [176128/225000 (78%)] Loss: 14858.343750\n",
      "Train Epoch: 5 [177536/225000 (79%)] Loss: 14785.185547\n",
      "Train Epoch: 5 [178944/225000 (80%)] Loss: 15116.383789\n",
      "Train Epoch: 5 [180352/225000 (80%)] Loss: 14959.433594\n",
      "Train Epoch: 5 [181760/225000 (81%)] Loss: 15151.411133\n",
      "Train Epoch: 5 [183168/225000 (81%)] Loss: 15227.429688\n",
      "Train Epoch: 5 [184576/225000 (82%)] Loss: 15247.778320\n",
      "Train Epoch: 5 [185984/225000 (83%)] Loss: 15320.238281\n",
      "Train Epoch: 5 [187392/225000 (83%)] Loss: 15114.273438\n",
      "Train Epoch: 5 [188800/225000 (84%)] Loss: 14953.763672\n",
      "Train Epoch: 5 [190208/225000 (85%)] Loss: 15261.775391\n",
      "Train Epoch: 5 [191616/225000 (85%)] Loss: 15260.105469\n",
      "Train Epoch: 5 [193024/225000 (86%)] Loss: 15050.017578\n",
      "Train Epoch: 5 [194432/225000 (86%)] Loss: 15266.409180\n",
      "Train Epoch: 5 [195840/225000 (87%)] Loss: 15152.594727\n",
      "Train Epoch: 5 [197248/225000 (88%)] Loss: 14966.250000\n",
      "Train Epoch: 5 [198656/225000 (88%)] Loss: 15188.959961\n",
      "Train Epoch: 5 [200064/225000 (89%)] Loss: 15224.657227\n",
      "Train Epoch: 5 [201472/225000 (90%)] Loss: 15323.827148\n",
      "Train Epoch: 5 [202880/225000 (90%)] Loss: 15170.379883\n",
      "Train Epoch: 5 [204288/225000 (91%)] Loss: 16110.996094\n",
      "Train Epoch: 5 [205696/225000 (91%)] Loss: 15308.661133\n",
      "Train Epoch: 5 [207104/225000 (92%)] Loss: 14948.185547\n",
      "Train Epoch: 5 [208512/225000 (93%)] Loss: 15607.665039\n",
      "Train Epoch: 5 [209920/225000 (93%)] Loss: 14885.199219\n",
      "Train Epoch: 5 [211328/225000 (94%)] Loss: 14710.537109\n",
      "Train Epoch: 5 [212736/225000 (95%)] Loss: 15221.064453\n",
      "Train Epoch: 5 [214144/225000 (95%)] Loss: 15090.432617\n",
      "Train Epoch: 5 [215552/225000 (96%)] Loss: 14779.774414\n",
      "Train Epoch: 5 [216960/225000 (96%)] Loss: 14798.202148\n",
      "Train Epoch: 5 [218368/225000 (97%)] Loss: 14964.658203\n",
      "Train Epoch: 5 [219776/225000 (98%)] Loss: 14828.307617\n",
      "Train Epoch: 5 [221184/225000 (98%)] Loss: 15302.743164\n",
      "Train Epoch: 5 [222592/225000 (99%)] Loss: 14973.134766\n",
      "Train Epoch: 5 [224000/225000 (100%)] Loss: 15252.072266\n",
      "    epoch          : 5\n",
      "    loss           : 15174.753416857757\n",
      "    val_loss       : 15079.567457172943\n",
      "Train Epoch: 6 [128/225000 (0%)] Loss: 15149.291992\n",
      "Train Epoch: 6 [1536/225000 (1%)] Loss: 15275.708008\n",
      "Train Epoch: 6 [2944/225000 (1%)] Loss: 15336.662109\n",
      "Train Epoch: 6 [4352/225000 (2%)] Loss: 14906.647461\n",
      "Train Epoch: 6 [5760/225000 (3%)] Loss: 15413.103516\n",
      "Train Epoch: 6 [7168/225000 (3%)] Loss: 14779.968750\n",
      "Train Epoch: 6 [8576/225000 (4%)] Loss: 15353.218750\n",
      "Train Epoch: 6 [9984/225000 (4%)] Loss: 15331.166992\n",
      "Train Epoch: 6 [11392/225000 (5%)] Loss: 14868.234375\n",
      "Train Epoch: 6 [12800/225000 (6%)] Loss: 15524.532227\n",
      "Train Epoch: 6 [14208/225000 (6%)] Loss: 15228.622070\n",
      "Train Epoch: 6 [15616/225000 (7%)] Loss: 15116.000977\n",
      "Train Epoch: 6 [17024/225000 (8%)] Loss: 15204.467773\n",
      "Train Epoch: 6 [18432/225000 (8%)] Loss: 14910.698242\n",
      "Train Epoch: 6 [19840/225000 (9%)] Loss: 14963.074219\n",
      "Train Epoch: 6 [21248/225000 (9%)] Loss: 15506.633789\n",
      "Train Epoch: 6 [22656/225000 (10%)] Loss: 15051.656250\n",
      "Train Epoch: 6 [24064/225000 (11%)] Loss: 15116.448242\n",
      "Train Epoch: 6 [25472/225000 (11%)] Loss: 15116.888672\n",
      "Train Epoch: 6 [26880/225000 (12%)] Loss: 15069.015625\n",
      "Train Epoch: 6 [28288/225000 (13%)] Loss: 15210.738281\n",
      "Train Epoch: 6 [29696/225000 (13%)] Loss: 15211.063477\n",
      "Train Epoch: 6 [31104/225000 (14%)] Loss: 14784.773438\n",
      "Train Epoch: 6 [32512/225000 (14%)] Loss: 14818.668945\n",
      "Train Epoch: 6 [33920/225000 (15%)] Loss: 15143.608398\n",
      "Train Epoch: 6 [35328/225000 (16%)] Loss: 15449.537109\n",
      "Train Epoch: 6 [36736/225000 (16%)] Loss: 15021.619141\n",
      "Train Epoch: 6 [38144/225000 (17%)] Loss: 14797.798828\n",
      "Train Epoch: 6 [39552/225000 (18%)] Loss: 14950.833984\n",
      "Train Epoch: 6 [40960/225000 (18%)] Loss: 15168.288086\n",
      "Train Epoch: 6 [42368/225000 (19%)] Loss: 15309.838867\n",
      "Train Epoch: 6 [43776/225000 (19%)] Loss: 14811.352539\n",
      "Train Epoch: 6 [45184/225000 (20%)] Loss: 15025.453125\n",
      "Train Epoch: 6 [46592/225000 (21%)] Loss: 15220.749023\n",
      "Train Epoch: 6 [48000/225000 (21%)] Loss: 14930.378906\n",
      "Train Epoch: 6 [49408/225000 (22%)] Loss: 15424.207031\n",
      "Train Epoch: 6 [50816/225000 (23%)] Loss: 15153.195312\n",
      "Train Epoch: 6 [52224/225000 (23%)] Loss: 15395.901367\n",
      "Train Epoch: 6 [53632/225000 (24%)] Loss: 14993.607422\n",
      "Train Epoch: 6 [55040/225000 (24%)] Loss: 15281.127930\n",
      "Train Epoch: 6 [56448/225000 (25%)] Loss: 14683.512695\n",
      "Train Epoch: 6 [57856/225000 (26%)] Loss: 15132.989258\n",
      "Train Epoch: 6 [59264/225000 (26%)] Loss: 14805.930664\n",
      "Train Epoch: 6 [60672/225000 (27%)] Loss: 15575.954102\n",
      "Train Epoch: 6 [62080/225000 (28%)] Loss: 14966.076172\n",
      "Train Epoch: 6 [63488/225000 (28%)] Loss: 15454.990234\n",
      "Train Epoch: 6 [64896/225000 (29%)] Loss: 15120.952148\n",
      "Train Epoch: 6 [66304/225000 (29%)] Loss: 14978.081055\n",
      "Train Epoch: 6 [67712/225000 (30%)] Loss: 15013.886719\n",
      "Train Epoch: 6 [69120/225000 (31%)] Loss: 15595.175781\n",
      "Train Epoch: 6 [70528/225000 (31%)] Loss: 15405.922852\n",
      "Train Epoch: 6 [71936/225000 (32%)] Loss: 15581.323242\n",
      "Train Epoch: 6 [73344/225000 (33%)] Loss: 17057.800781\n",
      "Train Epoch: 6 [74752/225000 (33%)] Loss: 14693.411133\n",
      "Train Epoch: 6 [76160/225000 (34%)] Loss: 14579.598633\n",
      "Train Epoch: 6 [77568/225000 (34%)] Loss: 15194.028320\n",
      "Train Epoch: 6 [78976/225000 (35%)] Loss: 14788.838867\n",
      "Train Epoch: 6 [80384/225000 (36%)] Loss: 14913.182617\n",
      "Train Epoch: 6 [81792/225000 (36%)] Loss: 15523.062500\n",
      "Train Epoch: 6 [83200/225000 (37%)] Loss: 15571.281250\n",
      "Train Epoch: 6 [84608/225000 (38%)] Loss: 14827.674805\n",
      "Train Epoch: 6 [86016/225000 (38%)] Loss: 15049.574219\n",
      "Train Epoch: 6 [87424/225000 (39%)] Loss: 15014.280273\n",
      "Train Epoch: 6 [88832/225000 (39%)] Loss: 14986.839844\n",
      "Train Epoch: 6 [90240/225000 (40%)] Loss: 14864.763672\n",
      "Train Epoch: 6 [91648/225000 (41%)] Loss: 15612.106445\n",
      "Train Epoch: 6 [93056/225000 (41%)] Loss: 15267.256836\n",
      "Train Epoch: 6 [94464/225000 (42%)] Loss: 15178.169922\n",
      "Train Epoch: 6 [95872/225000 (43%)] Loss: 15155.687500\n",
      "Train Epoch: 6 [97280/225000 (43%)] Loss: 15191.140625\n",
      "Train Epoch: 6 [98688/225000 (44%)] Loss: 14918.436523\n",
      "Train Epoch: 6 [100096/225000 (44%)] Loss: 15152.614258\n",
      "Train Epoch: 6 [101504/225000 (45%)] Loss: 14945.732422\n",
      "Train Epoch: 6 [102912/225000 (46%)] Loss: 15273.656250\n",
      "Train Epoch: 6 [104320/225000 (46%)] Loss: 15392.062500\n",
      "Train Epoch: 6 [105728/225000 (47%)] Loss: 14886.213867\n",
      "Train Epoch: 6 [107136/225000 (48%)] Loss: 14991.293945\n",
      "Train Epoch: 6 [108544/225000 (48%)] Loss: 15000.042969\n",
      "Train Epoch: 6 [109952/225000 (49%)] Loss: 14826.644531\n",
      "Train Epoch: 6 [111360/225000 (49%)] Loss: 14865.631836\n",
      "Train Epoch: 6 [112768/225000 (50%)] Loss: 15455.186523\n",
      "Train Epoch: 6 [114176/225000 (51%)] Loss: 15380.897461\n",
      "Train Epoch: 6 [115584/225000 (51%)] Loss: 15068.496094\n",
      "Train Epoch: 6 [116992/225000 (52%)] Loss: 14958.736328\n",
      "Train Epoch: 6 [118400/225000 (53%)] Loss: 14773.564453\n",
      "Train Epoch: 6 [119808/225000 (53%)] Loss: 14842.375000\n",
      "Train Epoch: 6 [121216/225000 (54%)] Loss: 14671.765625\n",
      "Train Epoch: 6 [122624/225000 (54%)] Loss: 15573.757812\n",
      "Train Epoch: 6 [124032/225000 (55%)] Loss: 15233.128906\n",
      "Train Epoch: 6 [125440/225000 (56%)] Loss: 14857.805664\n",
      "Train Epoch: 6 [126848/225000 (56%)] Loss: 15047.886719\n",
      "Train Epoch: 6 [128256/225000 (57%)] Loss: 14801.026367\n",
      "Train Epoch: 6 [129664/225000 (58%)] Loss: 15553.006836\n",
      "Train Epoch: 6 [131072/225000 (58%)] Loss: 14781.217773\n",
      "Train Epoch: 6 [132480/225000 (59%)] Loss: 14896.240234\n",
      "Train Epoch: 6 [133888/225000 (60%)] Loss: 14772.625000\n",
      "Train Epoch: 6 [135296/225000 (60%)] Loss: 14938.673828\n",
      "Train Epoch: 6 [136704/225000 (61%)] Loss: 15119.255859\n",
      "Train Epoch: 6 [138112/225000 (61%)] Loss: 15353.972656\n",
      "Train Epoch: 6 [139520/225000 (62%)] Loss: 15010.012695\n",
      "Train Epoch: 6 [140928/225000 (63%)] Loss: 15233.692383\n",
      "Train Epoch: 6 [142336/225000 (63%)] Loss: 15254.003906\n",
      "Train Epoch: 6 [143744/225000 (64%)] Loss: 14959.163086\n",
      "Train Epoch: 6 [145152/225000 (65%)] Loss: 14901.646484\n",
      "Train Epoch: 6 [146560/225000 (65%)] Loss: 15375.625977\n",
      "Train Epoch: 6 [147968/225000 (66%)] Loss: 15147.615234\n",
      "Train Epoch: 6 [149376/225000 (66%)] Loss: 14817.440430\n",
      "Train Epoch: 6 [150784/225000 (67%)] Loss: 14837.414062\n",
      "Train Epoch: 6 [152192/225000 (68%)] Loss: 15551.052734\n",
      "Train Epoch: 6 [153600/225000 (68%)] Loss: 15027.825195\n",
      "Train Epoch: 6 [155008/225000 (69%)] Loss: 15079.096680\n",
      "Train Epoch: 6 [156416/225000 (70%)] Loss: 14574.848633\n",
      "Train Epoch: 6 [157824/225000 (70%)] Loss: 15063.364258\n",
      "Train Epoch: 6 [159232/225000 (71%)] Loss: 14988.940430\n",
      "Train Epoch: 6 [160640/225000 (71%)] Loss: 15712.702148\n",
      "Train Epoch: 6 [162048/225000 (72%)] Loss: 15099.602539\n",
      "Train Epoch: 6 [163456/225000 (73%)] Loss: 15467.041992\n",
      "Train Epoch: 6 [164864/225000 (73%)] Loss: 15025.660156\n",
      "Train Epoch: 6 [166272/225000 (74%)] Loss: 14976.126953\n",
      "Train Epoch: 6 [167680/225000 (75%)] Loss: 15426.537109\n",
      "Train Epoch: 6 [169088/225000 (75%)] Loss: 15331.213867\n",
      "Train Epoch: 6 [170496/225000 (76%)] Loss: 14820.955078\n",
      "Train Epoch: 6 [171904/225000 (76%)] Loss: 15474.842773\n",
      "Train Epoch: 6 [173312/225000 (77%)] Loss: 14795.367188\n",
      "Train Epoch: 6 [174720/225000 (78%)] Loss: 15178.470703\n",
      "Train Epoch: 6 [176128/225000 (78%)] Loss: 15244.066406\n",
      "Train Epoch: 6 [177536/225000 (79%)] Loss: 15661.432617\n",
      "Train Epoch: 6 [178944/225000 (80%)] Loss: 15193.392578\n",
      "Train Epoch: 6 [180352/225000 (80%)] Loss: 14960.730469\n",
      "Train Epoch: 6 [181760/225000 (81%)] Loss: 15021.727539\n",
      "Train Epoch: 6 [183168/225000 (81%)] Loss: 15367.593750\n",
      "Train Epoch: 6 [184576/225000 (82%)] Loss: 15214.315430\n",
      "Train Epoch: 6 [185984/225000 (83%)] Loss: 14838.953125\n",
      "Train Epoch: 6 [187392/225000 (83%)] Loss: 15022.421875\n",
      "Train Epoch: 6 [188800/225000 (84%)] Loss: 14681.878906\n",
      "Train Epoch: 6 [190208/225000 (85%)] Loss: 15095.010742\n",
      "Train Epoch: 6 [191616/225000 (85%)] Loss: 15100.710938\n",
      "Train Epoch: 6 [193024/225000 (86%)] Loss: 15347.121094\n",
      "Train Epoch: 6 [194432/225000 (86%)] Loss: 15036.818359\n",
      "Train Epoch: 6 [195840/225000 (87%)] Loss: 15514.531250\n",
      "Train Epoch: 6 [197248/225000 (88%)] Loss: 15568.586914\n",
      "Train Epoch: 6 [198656/225000 (88%)] Loss: 14717.264648\n",
      "Train Epoch: 6 [200064/225000 (89%)] Loss: 14698.281250\n",
      "Train Epoch: 6 [201472/225000 (90%)] Loss: 14946.315430\n",
      "Train Epoch: 6 [202880/225000 (90%)] Loss: 14927.426758\n",
      "Train Epoch: 6 [204288/225000 (91%)] Loss: 15955.641602\n",
      "Train Epoch: 6 [205696/225000 (91%)] Loss: 15614.688477\n",
      "Train Epoch: 6 [207104/225000 (92%)] Loss: 15112.989258\n",
      "Train Epoch: 6 [208512/225000 (93%)] Loss: 15160.705078\n",
      "Train Epoch: 6 [209920/225000 (93%)] Loss: 15223.226562\n",
      "Train Epoch: 6 [211328/225000 (94%)] Loss: 15030.615234\n",
      "Train Epoch: 6 [212736/225000 (95%)] Loss: 14920.458008\n",
      "Train Epoch: 6 [214144/225000 (95%)] Loss: 15172.200195\n",
      "Train Epoch: 6 [215552/225000 (96%)] Loss: 15509.028320\n",
      "Train Epoch: 6 [216960/225000 (96%)] Loss: 15225.330078\n",
      "Train Epoch: 6 [218368/225000 (97%)] Loss: 15377.498047\n",
      "Train Epoch: 6 [219776/225000 (98%)] Loss: 15191.421875\n",
      "Train Epoch: 6 [221184/225000 (98%)] Loss: 15064.756836\n",
      "Train Epoch: 6 [222592/225000 (99%)] Loss: 15067.523438\n",
      "Train Epoch: 6 [224000/225000 (100%)] Loss: 15411.194336\n",
      "    epoch          : 6\n",
      "    loss           : 15139.721700240863\n",
      "    val_loss       : 15101.097886451045\n",
      "Train Epoch: 7 [128/225000 (0%)] Loss: 14981.019531\n",
      "Train Epoch: 7 [1536/225000 (1%)] Loss: 14965.405273\n",
      "Train Epoch: 7 [2944/225000 (1%)] Loss: 15613.093750\n",
      "Train Epoch: 7 [4352/225000 (2%)] Loss: 15185.665039\n",
      "Train Epoch: 7 [5760/225000 (3%)] Loss: 15168.451172\n",
      "Train Epoch: 7 [7168/225000 (3%)] Loss: 15586.603516\n",
      "Train Epoch: 7 [8576/225000 (4%)] Loss: 15009.650391\n",
      "Train Epoch: 7 [9984/225000 (4%)] Loss: 15066.617188\n",
      "Train Epoch: 7 [11392/225000 (5%)] Loss: 15168.295898\n",
      "Train Epoch: 7 [12800/225000 (6%)] Loss: 15468.975586\n",
      "Train Epoch: 7 [14208/225000 (6%)] Loss: 15059.996094\n",
      "Train Epoch: 7 [15616/225000 (7%)] Loss: 15169.280273\n",
      "Train Epoch: 7 [17024/225000 (8%)] Loss: 14654.930664\n",
      "Train Epoch: 7 [18432/225000 (8%)] Loss: 15199.402344\n",
      "Train Epoch: 7 [19840/225000 (9%)] Loss: 15228.015625\n",
      "Train Epoch: 7 [21248/225000 (9%)] Loss: 15059.052734\n",
      "Train Epoch: 7 [22656/225000 (10%)] Loss: 15234.614258\n",
      "Train Epoch: 7 [24064/225000 (11%)] Loss: 15065.403320\n",
      "Train Epoch: 7 [25472/225000 (11%)] Loss: 14993.363281\n",
      "Train Epoch: 7 [26880/225000 (12%)] Loss: 15125.432617\n",
      "Train Epoch: 7 [28288/225000 (13%)] Loss: 14166.596680\n",
      "Train Epoch: 7 [29696/225000 (13%)] Loss: 15257.281250\n",
      "Train Epoch: 7 [31104/225000 (14%)] Loss: 15108.496094\n",
      "Train Epoch: 7 [32512/225000 (14%)] Loss: 14857.138672\n",
      "Train Epoch: 7 [33920/225000 (15%)] Loss: 15175.378906\n",
      "Train Epoch: 7 [35328/225000 (16%)] Loss: 14927.896484\n",
      "Train Epoch: 7 [36736/225000 (16%)] Loss: 15098.768555\n",
      "Train Epoch: 7 [38144/225000 (17%)] Loss: 15186.381836\n",
      "Train Epoch: 7 [39552/225000 (18%)] Loss: 15038.721680\n",
      "Train Epoch: 7 [40960/225000 (18%)] Loss: 15300.263672\n",
      "Train Epoch: 7 [42368/225000 (19%)] Loss: 14479.683594\n",
      "Train Epoch: 7 [43776/225000 (19%)] Loss: 15026.020508\n",
      "Train Epoch: 7 [45184/225000 (20%)] Loss: 14664.106445\n",
      "Train Epoch: 7 [46592/225000 (21%)] Loss: 15047.951172\n",
      "Train Epoch: 7 [48000/225000 (21%)] Loss: 15187.160156\n",
      "Train Epoch: 7 [49408/225000 (22%)] Loss: 14858.857422\n",
      "Train Epoch: 7 [50816/225000 (23%)] Loss: 14792.716797\n",
      "Train Epoch: 7 [52224/225000 (23%)] Loss: 15439.135742\n",
      "Train Epoch: 7 [53632/225000 (24%)] Loss: 15033.519531\n",
      "Train Epoch: 7 [55040/225000 (24%)] Loss: 15278.522461\n",
      "Train Epoch: 7 [56448/225000 (25%)] Loss: 15323.068359\n",
      "Train Epoch: 7 [57856/225000 (26%)] Loss: 15096.580078\n",
      "Train Epoch: 7 [59264/225000 (26%)] Loss: 14754.537109\n",
      "Train Epoch: 7 [60672/225000 (27%)] Loss: 14635.921875\n",
      "Train Epoch: 7 [62080/225000 (28%)] Loss: 15205.328125\n",
      "Train Epoch: 7 [63488/225000 (28%)] Loss: 14941.514648\n",
      "Train Epoch: 7 [64896/225000 (29%)] Loss: 14554.278320\n",
      "Train Epoch: 7 [66304/225000 (29%)] Loss: 15134.928711\n",
      "Train Epoch: 7 [67712/225000 (30%)] Loss: 14621.308594\n",
      "Train Epoch: 7 [69120/225000 (31%)] Loss: 14592.331055\n",
      "Train Epoch: 7 [70528/225000 (31%)] Loss: 14929.230469\n",
      "Train Epoch: 7 [71936/225000 (32%)] Loss: 15262.988281\n",
      "Train Epoch: 7 [73344/225000 (33%)] Loss: 15067.967773\n",
      "Train Epoch: 7 [74752/225000 (33%)] Loss: 15293.024414\n",
      "Train Epoch: 7 [76160/225000 (34%)] Loss: 15415.227539\n",
      "Train Epoch: 7 [77568/225000 (34%)] Loss: 15184.876953\n",
      "Train Epoch: 7 [78976/225000 (35%)] Loss: 15299.733398\n",
      "Train Epoch: 7 [80384/225000 (36%)] Loss: 15251.810547\n",
      "Train Epoch: 7 [81792/225000 (36%)] Loss: 15124.713867\n",
      "Train Epoch: 7 [83200/225000 (37%)] Loss: 15067.863281\n",
      "Train Epoch: 7 [84608/225000 (38%)] Loss: 15262.176758\n",
      "Train Epoch: 7 [86016/225000 (38%)] Loss: 14531.869141\n",
      "Train Epoch: 7 [87424/225000 (39%)] Loss: 14804.333008\n",
      "Train Epoch: 7 [88832/225000 (39%)] Loss: 14997.073242\n",
      "Train Epoch: 7 [90240/225000 (40%)] Loss: 15244.495117\n",
      "Train Epoch: 7 [91648/225000 (41%)] Loss: 15269.624023\n",
      "Train Epoch: 7 [93056/225000 (41%)] Loss: 14953.157227\n",
      "Train Epoch: 7 [94464/225000 (42%)] Loss: 15273.885742\n",
      "Train Epoch: 7 [95872/225000 (43%)] Loss: 14987.820312\n",
      "Train Epoch: 7 [97280/225000 (43%)] Loss: 15241.479492\n",
      "Train Epoch: 7 [98688/225000 (44%)] Loss: 14963.636719\n",
      "Train Epoch: 7 [100096/225000 (44%)] Loss: 15341.113281\n",
      "Train Epoch: 7 [101504/225000 (45%)] Loss: 15191.909180\n",
      "Train Epoch: 7 [102912/225000 (46%)] Loss: 15442.758789\n",
      "Train Epoch: 7 [104320/225000 (46%)] Loss: 15353.852539\n",
      "Train Epoch: 7 [105728/225000 (47%)] Loss: 14847.458984\n",
      "Train Epoch: 7 [107136/225000 (48%)] Loss: 15420.117188\n",
      "Train Epoch: 7 [108544/225000 (48%)] Loss: 14794.974609\n",
      "Train Epoch: 7 [109952/225000 (49%)] Loss: 14888.676758\n",
      "Train Epoch: 7 [111360/225000 (49%)] Loss: 15314.826172\n",
      "Train Epoch: 7 [112768/225000 (50%)] Loss: 15045.617188\n",
      "Train Epoch: 7 [114176/225000 (51%)] Loss: 15659.621094\n",
      "Train Epoch: 7 [115584/225000 (51%)] Loss: 14832.241211\n",
      "Train Epoch: 7 [116992/225000 (52%)] Loss: 15025.479492\n",
      "Train Epoch: 7 [118400/225000 (53%)] Loss: 14944.322266\n",
      "Train Epoch: 7 [119808/225000 (53%)] Loss: 14888.556641\n",
      "Train Epoch: 7 [121216/225000 (54%)] Loss: 14940.032227\n",
      "Train Epoch: 7 [122624/225000 (54%)] Loss: 15371.217773\n",
      "Train Epoch: 7 [124032/225000 (55%)] Loss: 14940.717773\n",
      "Train Epoch: 7 [125440/225000 (56%)] Loss: 14701.872070\n",
      "Train Epoch: 7 [126848/225000 (56%)] Loss: 14660.150391\n",
      "Train Epoch: 7 [128256/225000 (57%)] Loss: 15076.234375\n",
      "Train Epoch: 7 [129664/225000 (58%)] Loss: 14707.315430\n",
      "Train Epoch: 7 [131072/225000 (58%)] Loss: 14768.405273\n",
      "Train Epoch: 7 [132480/225000 (59%)] Loss: 14853.194336\n",
      "Train Epoch: 7 [133888/225000 (60%)] Loss: 15217.560547\n",
      "Train Epoch: 7 [135296/225000 (60%)] Loss: 14921.411133\n",
      "Train Epoch: 7 [136704/225000 (61%)] Loss: 15197.624023\n",
      "Train Epoch: 7 [138112/225000 (61%)] Loss: 14781.310547\n",
      "Train Epoch: 7 [139520/225000 (62%)] Loss: 15337.756836\n",
      "Train Epoch: 7 [140928/225000 (63%)] Loss: 14758.510742\n",
      "Train Epoch: 7 [142336/225000 (63%)] Loss: 14917.688477\n",
      "Train Epoch: 7 [143744/225000 (64%)] Loss: 15001.785156\n",
      "Train Epoch: 7 [145152/225000 (65%)] Loss: 15151.244141\n",
      "Train Epoch: 7 [146560/225000 (65%)] Loss: 14786.106445\n",
      "Train Epoch: 7 [147968/225000 (66%)] Loss: 14648.445312\n",
      "Train Epoch: 7 [149376/225000 (66%)] Loss: 15129.249023\n",
      "Train Epoch: 7 [150784/225000 (67%)] Loss: 15121.688477\n",
      "Train Epoch: 7 [152192/225000 (68%)] Loss: 14966.935547\n",
      "Train Epoch: 7 [153600/225000 (68%)] Loss: 15068.799805\n",
      "Train Epoch: 7 [155008/225000 (69%)] Loss: 15283.988281\n",
      "Train Epoch: 7 [156416/225000 (70%)] Loss: 15094.478516\n",
      "Train Epoch: 7 [157824/225000 (70%)] Loss: 14877.612305\n",
      "Train Epoch: 7 [159232/225000 (71%)] Loss: 14828.473633\n",
      "Train Epoch: 7 [160640/225000 (71%)] Loss: 14822.571289\n",
      "Train Epoch: 7 [162048/225000 (72%)] Loss: 15165.895508\n",
      "Train Epoch: 7 [163456/225000 (73%)] Loss: 14920.930664\n",
      "Train Epoch: 7 [164864/225000 (73%)] Loss: 15293.201172\n",
      "Train Epoch: 7 [166272/225000 (74%)] Loss: 15518.000000\n",
      "Train Epoch: 7 [167680/225000 (75%)] Loss: 15207.626953\n",
      "Train Epoch: 7 [169088/225000 (75%)] Loss: 15580.984375\n",
      "Train Epoch: 7 [170496/225000 (76%)] Loss: 15151.237305\n",
      "Train Epoch: 7 [171904/225000 (76%)] Loss: 15205.801758\n",
      "Train Epoch: 7 [173312/225000 (77%)] Loss: 14949.034180\n",
      "Train Epoch: 7 [174720/225000 (78%)] Loss: 15153.726562\n",
      "Train Epoch: 7 [176128/225000 (78%)] Loss: 15268.408203\n",
      "Train Epoch: 7 [177536/225000 (79%)] Loss: 15435.180664\n",
      "Train Epoch: 7 [178944/225000 (80%)] Loss: 15028.813477\n",
      "Train Epoch: 7 [180352/225000 (80%)] Loss: 14744.329102\n",
      "Train Epoch: 7 [181760/225000 (81%)] Loss: 15249.993164\n",
      "Train Epoch: 7 [183168/225000 (81%)] Loss: 15130.281250\n",
      "Train Epoch: 7 [184576/225000 (82%)] Loss: 14981.730469\n",
      "Train Epoch: 7 [185984/225000 (83%)] Loss: 14994.247070\n",
      "Train Epoch: 7 [187392/225000 (83%)] Loss: 15260.067383\n",
      "Train Epoch: 7 [188800/225000 (84%)] Loss: 15052.544922\n",
      "Train Epoch: 7 [190208/225000 (85%)] Loss: 14960.712891\n",
      "Train Epoch: 7 [191616/225000 (85%)] Loss: 15318.737305\n",
      "Train Epoch: 7 [193024/225000 (86%)] Loss: 15426.198242\n",
      "Train Epoch: 7 [194432/225000 (86%)] Loss: 15060.359375\n",
      "Train Epoch: 7 [195840/225000 (87%)] Loss: 15365.419922\n",
      "Train Epoch: 7 [197248/225000 (88%)] Loss: 14948.776367\n",
      "Train Epoch: 7 [198656/225000 (88%)] Loss: 15046.768555\n",
      "Train Epoch: 7 [200064/225000 (89%)] Loss: 15056.648438\n",
      "Train Epoch: 7 [201472/225000 (90%)] Loss: 14738.946289\n",
      "Train Epoch: 7 [202880/225000 (90%)] Loss: 15663.158203\n",
      "Train Epoch: 7 [204288/225000 (91%)] Loss: 14929.781250\n",
      "Train Epoch: 7 [205696/225000 (91%)] Loss: 15323.847656\n",
      "Train Epoch: 7 [207104/225000 (92%)] Loss: 14963.322266\n",
      "Train Epoch: 7 [208512/225000 (93%)] Loss: 15613.279297\n",
      "Train Epoch: 7 [209920/225000 (93%)] Loss: 14949.379883\n",
      "Train Epoch: 7 [211328/225000 (94%)] Loss: 14838.142578\n",
      "Train Epoch: 7 [212736/225000 (95%)] Loss: 14901.583008\n",
      "Train Epoch: 7 [214144/225000 (95%)] Loss: 15469.341797\n",
      "Train Epoch: 7 [215552/225000 (96%)] Loss: 14913.905273\n",
      "Train Epoch: 7 [216960/225000 (96%)] Loss: 15096.428711\n",
      "Train Epoch: 7 [218368/225000 (97%)] Loss: 15210.023438\n",
      "Train Epoch: 7 [219776/225000 (98%)] Loss: 14805.647461\n",
      "Train Epoch: 7 [221184/225000 (98%)] Loss: 15087.279297\n",
      "Train Epoch: 7 [222592/225000 (99%)] Loss: 14752.210938\n",
      "Train Epoch: 7 [224000/225000 (100%)] Loss: 15050.734375\n",
      "    epoch          : 7\n",
      "    loss           : 15120.551677821033\n",
      "    val_loss       : 15089.585669133889\n",
      "Train Epoch: 8 [128/225000 (0%)] Loss: 15948.616211\n",
      "Train Epoch: 8 [1536/225000 (1%)] Loss: 15215.877930\n",
      "Train Epoch: 8 [2944/225000 (1%)] Loss: 15279.304688\n",
      "Train Epoch: 8 [4352/225000 (2%)] Loss: 14601.572266\n",
      "Train Epoch: 8 [5760/225000 (3%)] Loss: 14881.360352\n",
      "Train Epoch: 8 [7168/225000 (3%)] Loss: 14875.591797\n",
      "Train Epoch: 8 [8576/225000 (4%)] Loss: 14457.771484\n",
      "Train Epoch: 8 [9984/225000 (4%)] Loss: 14871.642578\n",
      "Train Epoch: 8 [11392/225000 (5%)] Loss: 15310.371094\n",
      "Train Epoch: 8 [12800/225000 (6%)] Loss: 15068.717773\n",
      "Train Epoch: 8 [14208/225000 (6%)] Loss: 15353.250977\n",
      "Train Epoch: 8 [15616/225000 (7%)] Loss: 15141.588867\n",
      "Train Epoch: 8 [17024/225000 (8%)] Loss: 15374.827148\n",
      "Train Epoch: 8 [18432/225000 (8%)] Loss: 15070.696289\n",
      "Train Epoch: 8 [19840/225000 (9%)] Loss: 14357.891602\n",
      "Train Epoch: 8 [21248/225000 (9%)] Loss: 15965.570312\n",
      "Train Epoch: 8 [22656/225000 (10%)] Loss: 15011.115234\n",
      "Train Epoch: 8 [24064/225000 (11%)] Loss: 14878.030273\n",
      "Train Epoch: 8 [25472/225000 (11%)] Loss: 14972.845703\n",
      "Train Epoch: 8 [26880/225000 (12%)] Loss: 15102.098633\n",
      "Train Epoch: 8 [28288/225000 (13%)] Loss: 14961.599609\n",
      "Train Epoch: 8 [29696/225000 (13%)] Loss: 14880.426758\n",
      "Train Epoch: 8 [31104/225000 (14%)] Loss: 15237.785156\n",
      "Train Epoch: 8 [32512/225000 (14%)] Loss: 15036.597656\n",
      "Train Epoch: 8 [33920/225000 (15%)] Loss: 15194.867188\n",
      "Train Epoch: 8 [35328/225000 (16%)] Loss: 14692.427734\n",
      "Train Epoch: 8 [36736/225000 (16%)] Loss: 14812.115234\n",
      "Train Epoch: 8 [38144/225000 (17%)] Loss: 15356.678711\n",
      "Train Epoch: 8 [39552/225000 (18%)] Loss: 15129.830078\n",
      "Train Epoch: 8 [40960/225000 (18%)] Loss: 14812.961914\n",
      "Train Epoch: 8 [42368/225000 (19%)] Loss: 15049.996094\n",
      "Train Epoch: 8 [43776/225000 (19%)] Loss: 14991.076172\n",
      "Train Epoch: 8 [45184/225000 (20%)] Loss: 15300.468750\n",
      "Train Epoch: 8 [46592/225000 (21%)] Loss: 14866.234375\n",
      "Train Epoch: 8 [48000/225000 (21%)] Loss: 15176.325195\n",
      "Train Epoch: 8 [49408/225000 (22%)] Loss: 15205.171875\n",
      "Train Epoch: 8 [50816/225000 (23%)] Loss: 15037.976562\n",
      "Train Epoch: 8 [52224/225000 (23%)] Loss: 14517.032227\n",
      "Train Epoch: 8 [53632/225000 (24%)] Loss: 15118.101562\n",
      "Train Epoch: 8 [55040/225000 (24%)] Loss: 15361.009766\n",
      "Train Epoch: 8 [56448/225000 (25%)] Loss: 15433.884766\n",
      "Train Epoch: 8 [57856/225000 (26%)] Loss: 15160.508789\n",
      "Train Epoch: 8 [59264/225000 (26%)] Loss: 15261.012695\n",
      "Train Epoch: 8 [60672/225000 (27%)] Loss: 15241.538086\n",
      "Train Epoch: 8 [62080/225000 (28%)] Loss: 15121.860352\n",
      "Train Epoch: 8 [63488/225000 (28%)] Loss: 15079.576172\n",
      "Train Epoch: 8 [64896/225000 (29%)] Loss: 14924.699219\n",
      "Train Epoch: 8 [66304/225000 (29%)] Loss: 15052.600586\n",
      "Train Epoch: 8 [67712/225000 (30%)] Loss: 15052.679688\n",
      "Train Epoch: 8 [69120/225000 (31%)] Loss: 14878.677734\n",
      "Train Epoch: 8 [70528/225000 (31%)] Loss: 15286.730469\n",
      "Train Epoch: 8 [71936/225000 (32%)] Loss: 14931.999023\n",
      "Train Epoch: 8 [73344/225000 (33%)] Loss: 15598.228516\n",
      "Train Epoch: 8 [74752/225000 (33%)] Loss: 14728.171875\n",
      "Train Epoch: 8 [76160/225000 (34%)] Loss: 15088.445312\n",
      "Train Epoch: 8 [77568/225000 (34%)] Loss: 15339.935547\n",
      "Train Epoch: 8 [78976/225000 (35%)] Loss: 15202.174805\n",
      "Train Epoch: 8 [80384/225000 (36%)] Loss: 15062.430664\n",
      "Train Epoch: 8 [81792/225000 (36%)] Loss: 15374.517578\n",
      "Train Epoch: 8 [83200/225000 (37%)] Loss: 14928.211914\n",
      "Train Epoch: 8 [84608/225000 (38%)] Loss: 15171.720703\n",
      "Train Epoch: 8 [86016/225000 (38%)] Loss: 14901.990234\n",
      "Train Epoch: 8 [87424/225000 (39%)] Loss: 14825.470703\n",
      "Train Epoch: 8 [88832/225000 (39%)] Loss: 14916.606445\n",
      "Train Epoch: 8 [90240/225000 (40%)] Loss: 14694.656250\n",
      "Train Epoch: 8 [91648/225000 (41%)] Loss: 15346.042969\n",
      "Train Epoch: 8 [93056/225000 (41%)] Loss: 15217.135742\n",
      "Train Epoch: 8 [94464/225000 (42%)] Loss: 15082.189453\n",
      "Train Epoch: 8 [95872/225000 (43%)] Loss: 15208.560547\n",
      "Train Epoch: 8 [97280/225000 (43%)] Loss: 15317.305664\n",
      "Train Epoch: 8 [98688/225000 (44%)] Loss: 15253.588867\n",
      "Train Epoch: 8 [100096/225000 (44%)] Loss: 14887.288086\n",
      "Train Epoch: 8 [101504/225000 (45%)] Loss: 14654.129883\n",
      "Train Epoch: 8 [102912/225000 (46%)] Loss: 15354.458008\n",
      "Train Epoch: 8 [104320/225000 (46%)] Loss: 15155.513672\n",
      "Train Epoch: 8 [105728/225000 (47%)] Loss: 15147.405273\n",
      "Train Epoch: 8 [107136/225000 (48%)] Loss: 15431.182617\n",
      "Train Epoch: 8 [108544/225000 (48%)] Loss: 14430.140625\n",
      "Train Epoch: 8 [109952/225000 (49%)] Loss: 14994.829102\n",
      "Train Epoch: 8 [111360/225000 (49%)] Loss: 14976.994141\n",
      "Train Epoch: 8 [112768/225000 (50%)] Loss: 15248.250977\n",
      "Train Epoch: 8 [114176/225000 (51%)] Loss: 15086.790039\n",
      "Train Epoch: 8 [115584/225000 (51%)] Loss: 14978.201172\n",
      "Train Epoch: 8 [116992/225000 (52%)] Loss: 15577.833984\n",
      "Train Epoch: 8 [118400/225000 (53%)] Loss: 14824.800781\n",
      "Train Epoch: 8 [119808/225000 (53%)] Loss: 15212.110352\n",
      "Train Epoch: 8 [121216/225000 (54%)] Loss: 15113.781250\n",
      "Train Epoch: 8 [122624/225000 (54%)] Loss: 15325.057617\n",
      "Train Epoch: 8 [124032/225000 (55%)] Loss: 15304.873047\n",
      "Train Epoch: 8 [125440/225000 (56%)] Loss: 15222.750000\n",
      "Train Epoch: 8 [126848/225000 (56%)] Loss: 15233.726562\n",
      "Train Epoch: 8 [128256/225000 (57%)] Loss: 15975.050781\n",
      "Train Epoch: 8 [129664/225000 (58%)] Loss: 15188.926758\n",
      "Train Epoch: 8 [131072/225000 (58%)] Loss: 15097.438477\n",
      "Train Epoch: 8 [132480/225000 (59%)] Loss: 15137.826172\n",
      "Train Epoch: 8 [133888/225000 (60%)] Loss: 14961.776367\n",
      "Train Epoch: 8 [135296/225000 (60%)] Loss: 14804.687500\n",
      "Train Epoch: 8 [136704/225000 (61%)] Loss: 15037.992188\n",
      "Train Epoch: 8 [138112/225000 (61%)] Loss: 15352.301758\n",
      "Train Epoch: 8 [139520/225000 (62%)] Loss: 14925.980469\n",
      "Train Epoch: 8 [140928/225000 (63%)] Loss: 15147.500977\n",
      "Train Epoch: 8 [142336/225000 (63%)] Loss: 15375.496094\n",
      "Train Epoch: 8 [143744/225000 (64%)] Loss: 15261.733398\n",
      "Train Epoch: 8 [145152/225000 (65%)] Loss: 15185.798828\n",
      "Train Epoch: 8 [146560/225000 (65%)] Loss: 15241.207031\n",
      "Train Epoch: 8 [147968/225000 (66%)] Loss: 15369.805664\n",
      "Train Epoch: 8 [149376/225000 (66%)] Loss: 15579.794922\n",
      "Train Epoch: 8 [150784/225000 (67%)] Loss: 15248.955078\n",
      "Train Epoch: 8 [152192/225000 (68%)] Loss: 15042.132812\n",
      "Train Epoch: 8 [153600/225000 (68%)] Loss: 15003.930664\n",
      "Train Epoch: 8 [155008/225000 (69%)] Loss: 14810.473633\n",
      "Train Epoch: 8 [156416/225000 (70%)] Loss: 14791.508789\n",
      "Train Epoch: 8 [157824/225000 (70%)] Loss: 15565.403320\n",
      "Train Epoch: 8 [159232/225000 (71%)] Loss: 15586.297852\n",
      "Train Epoch: 8 [160640/225000 (71%)] Loss: 14975.643555\n",
      "Train Epoch: 8 [162048/225000 (72%)] Loss: 15042.622070\n",
      "Train Epoch: 8 [163456/225000 (73%)] Loss: 15429.124023\n",
      "Train Epoch: 8 [164864/225000 (73%)] Loss: 15156.803711\n",
      "Train Epoch: 8 [166272/225000 (74%)] Loss: 14643.504883\n",
      "Train Epoch: 8 [167680/225000 (75%)] Loss: 15554.247070\n",
      "Train Epoch: 8 [169088/225000 (75%)] Loss: 14979.193359\n",
      "Train Epoch: 8 [170496/225000 (76%)] Loss: 14796.217773\n",
      "Train Epoch: 8 [171904/225000 (76%)] Loss: 14670.416992\n",
      "Train Epoch: 8 [173312/225000 (77%)] Loss: 14914.798828\n",
      "Train Epoch: 8 [174720/225000 (78%)] Loss: 15074.831055\n",
      "Train Epoch: 8 [176128/225000 (78%)] Loss: 14899.277344\n",
      "Train Epoch: 8 [177536/225000 (79%)] Loss: 14940.251953\n",
      "Train Epoch: 8 [178944/225000 (80%)] Loss: 15277.887695\n",
      "Train Epoch: 8 [180352/225000 (80%)] Loss: 15133.230469\n",
      "Train Epoch: 8 [181760/225000 (81%)] Loss: 14817.037109\n",
      "Train Epoch: 8 [183168/225000 (81%)] Loss: 14837.591797\n",
      "Train Epoch: 8 [184576/225000 (82%)] Loss: 14886.664062\n",
      "Train Epoch: 8 [185984/225000 (83%)] Loss: 15258.161133\n",
      "Train Epoch: 8 [187392/225000 (83%)] Loss: 15202.545898\n",
      "Train Epoch: 8 [188800/225000 (84%)] Loss: 14786.620117\n",
      "Train Epoch: 8 [190208/225000 (85%)] Loss: 14842.761719\n",
      "Train Epoch: 8 [191616/225000 (85%)] Loss: 15105.292969\n",
      "Train Epoch: 8 [193024/225000 (86%)] Loss: 14764.148438\n",
      "Train Epoch: 8 [194432/225000 (86%)] Loss: 15324.907227\n",
      "Train Epoch: 8 [195840/225000 (87%)] Loss: 14927.941406\n",
      "Train Epoch: 8 [197248/225000 (88%)] Loss: 14634.567383\n",
      "Train Epoch: 8 [198656/225000 (88%)] Loss: 15157.040039\n",
      "Train Epoch: 8 [200064/225000 (89%)] Loss: 15520.683594\n",
      "Train Epoch: 8 [201472/225000 (90%)] Loss: 14941.611328\n",
      "Train Epoch: 8 [202880/225000 (90%)] Loss: 15871.567383\n",
      "Train Epoch: 8 [204288/225000 (91%)] Loss: 14645.991211\n",
      "Train Epoch: 8 [205696/225000 (91%)] Loss: 14910.583008\n",
      "Train Epoch: 8 [207104/225000 (92%)] Loss: 15106.637695\n",
      "Train Epoch: 8 [208512/225000 (93%)] Loss: 15631.466797\n",
      "Train Epoch: 8 [209920/225000 (93%)] Loss: 15018.517578\n",
      "Train Epoch: 8 [211328/225000 (94%)] Loss: 14634.037109\n",
      "Train Epoch: 8 [212736/225000 (95%)] Loss: 15176.328125\n",
      "Train Epoch: 8 [214144/225000 (95%)] Loss: 14759.762695\n",
      "Train Epoch: 8 [215552/225000 (96%)] Loss: 14938.528320\n",
      "Train Epoch: 8 [216960/225000 (96%)] Loss: 15072.352539\n",
      "Train Epoch: 8 [218368/225000 (97%)] Loss: 14858.471680\n",
      "Train Epoch: 8 [219776/225000 (98%)] Loss: 14970.928711\n",
      "Train Epoch: 8 [221184/225000 (98%)] Loss: 15059.979492\n",
      "Train Epoch: 8 [222592/225000 (99%)] Loss: 14806.886719\n",
      "Train Epoch: 8 [224000/225000 (100%)] Loss: 15195.877930\n",
      "    epoch          : 8\n",
      "    loss           : 15118.905576738482\n",
      "    val_loss       : 15101.974575818498\n",
      "Train Epoch: 9 [128/225000 (0%)] Loss: 15297.233398\n",
      "Train Epoch: 9 [1536/225000 (1%)] Loss: 14774.334961\n",
      "Train Epoch: 9 [2944/225000 (1%)] Loss: 14897.887695\n",
      "Train Epoch: 9 [4352/225000 (2%)] Loss: 14985.148438\n",
      "Train Epoch: 9 [5760/225000 (3%)] Loss: 15226.842773\n",
      "Train Epoch: 9 [7168/225000 (3%)] Loss: 15246.249023\n",
      "Train Epoch: 9 [8576/225000 (4%)] Loss: 15044.887695\n",
      "Train Epoch: 9 [9984/225000 (4%)] Loss: 15279.648438\n",
      "Train Epoch: 9 [11392/225000 (5%)] Loss: 15390.563477\n",
      "Train Epoch: 9 [12800/225000 (6%)] Loss: 15461.481445\n",
      "Train Epoch: 9 [14208/225000 (6%)] Loss: 15249.285156\n",
      "Train Epoch: 9 [15616/225000 (7%)] Loss: 15478.861328\n",
      "Train Epoch: 9 [17024/225000 (8%)] Loss: 15324.314453\n",
      "Train Epoch: 9 [18432/225000 (8%)] Loss: 14913.480469\n",
      "Train Epoch: 9 [19840/225000 (9%)] Loss: 15196.757812\n",
      "Train Epoch: 9 [21248/225000 (9%)] Loss: 14982.398438\n",
      "Train Epoch: 9 [22656/225000 (10%)] Loss: 15027.717773\n",
      "Train Epoch: 9 [24064/225000 (11%)] Loss: 17464.226562\n",
      "Train Epoch: 9 [25472/225000 (11%)] Loss: 14556.907227\n",
      "Train Epoch: 9 [26880/225000 (12%)] Loss: 15656.189453\n",
      "Train Epoch: 9 [28288/225000 (13%)] Loss: 15367.548828\n",
      "Train Epoch: 9 [29696/225000 (13%)] Loss: 14864.832031\n",
      "Train Epoch: 9 [31104/225000 (14%)] Loss: 15029.884766\n",
      "Train Epoch: 9 [32512/225000 (14%)] Loss: 14690.642578\n",
      "Train Epoch: 9 [33920/225000 (15%)] Loss: 15158.148438\n",
      "Train Epoch: 9 [35328/225000 (16%)] Loss: 14980.890625\n",
      "Train Epoch: 9 [36736/225000 (16%)] Loss: 15063.502930\n",
      "Train Epoch: 9 [38144/225000 (17%)] Loss: 14737.112305\n",
      "Train Epoch: 9 [39552/225000 (18%)] Loss: 14676.022461\n",
      "Train Epoch: 9 [40960/225000 (18%)] Loss: 14964.631836\n",
      "Train Epoch: 9 [42368/225000 (19%)] Loss: 14958.451172\n",
      "Train Epoch: 9 [43776/225000 (19%)] Loss: 14807.271484\n",
      "Train Epoch: 9 [45184/225000 (20%)] Loss: 15109.635742\n",
      "Train Epoch: 9 [46592/225000 (21%)] Loss: 14495.402344\n",
      "Train Epoch: 9 [48000/225000 (21%)] Loss: 14953.291016\n",
      "Train Epoch: 9 [49408/225000 (22%)] Loss: 14534.039062\n",
      "Train Epoch: 9 [50816/225000 (23%)] Loss: 15434.475586\n",
      "Train Epoch: 9 [52224/225000 (23%)] Loss: 14553.863281\n",
      "Train Epoch: 9 [53632/225000 (24%)] Loss: 15253.642578\n",
      "Train Epoch: 9 [55040/225000 (24%)] Loss: 14975.551758\n",
      "Train Epoch: 9 [56448/225000 (25%)] Loss: 14850.609375\n",
      "Train Epoch: 9 [57856/225000 (26%)] Loss: 15384.406250\n",
      "Train Epoch: 9 [59264/225000 (26%)] Loss: 15410.295898\n",
      "Train Epoch: 9 [60672/225000 (27%)] Loss: 15144.320312\n",
      "Train Epoch: 9 [62080/225000 (28%)] Loss: 15446.191406\n",
      "Train Epoch: 9 [63488/225000 (28%)] Loss: 14890.904297\n",
      "Train Epoch: 9 [64896/225000 (29%)] Loss: 14922.250977\n",
      "Train Epoch: 9 [66304/225000 (29%)] Loss: 14744.818359\n",
      "Train Epoch: 9 [67712/225000 (30%)] Loss: 15590.778320\n",
      "Train Epoch: 9 [69120/225000 (31%)] Loss: 15548.265625\n",
      "Train Epoch: 9 [70528/225000 (31%)] Loss: 15204.261719\n",
      "Train Epoch: 9 [71936/225000 (32%)] Loss: 14815.613281\n",
      "Train Epoch: 9 [73344/225000 (33%)] Loss: 15345.833984\n",
      "Train Epoch: 9 [74752/225000 (33%)] Loss: 14748.874023\n",
      "Train Epoch: 9 [76160/225000 (34%)] Loss: 15187.957031\n",
      "Train Epoch: 9 [77568/225000 (34%)] Loss: 14833.062500\n",
      "Train Epoch: 9 [78976/225000 (35%)] Loss: 15687.332031\n",
      "Train Epoch: 9 [80384/225000 (36%)] Loss: 14821.514648\n",
      "Train Epoch: 9 [81792/225000 (36%)] Loss: 21988.343750\n",
      "Train Epoch: 9 [83200/225000 (37%)] Loss: 14975.236328\n",
      "Train Epoch: 9 [84608/225000 (38%)] Loss: 14959.182617\n",
      "Train Epoch: 9 [86016/225000 (38%)] Loss: 15206.002930\n",
      "Train Epoch: 9 [87424/225000 (39%)] Loss: 14780.791992\n",
      "Train Epoch: 9 [88832/225000 (39%)] Loss: 15111.026367\n",
      "Train Epoch: 9 [90240/225000 (40%)] Loss: 14886.017578\n",
      "Train Epoch: 9 [91648/225000 (41%)] Loss: 15177.476562\n",
      "Train Epoch: 9 [93056/225000 (41%)] Loss: 15272.184570\n",
      "Train Epoch: 9 [94464/225000 (42%)] Loss: 14854.111328\n",
      "Train Epoch: 9 [95872/225000 (43%)] Loss: 14859.300781\n",
      "Train Epoch: 9 [97280/225000 (43%)] Loss: 15530.275391\n",
      "Train Epoch: 9 [98688/225000 (44%)] Loss: 15238.477539\n",
      "Train Epoch: 9 [100096/225000 (44%)] Loss: 15418.504883\n",
      "Train Epoch: 9 [101504/225000 (45%)] Loss: 15116.656250\n",
      "Train Epoch: 9 [102912/225000 (46%)] Loss: 15535.911133\n",
      "Train Epoch: 9 [104320/225000 (46%)] Loss: 15021.820312\n",
      "Train Epoch: 9 [105728/225000 (47%)] Loss: 15007.164062\n",
      "Train Epoch: 9 [107136/225000 (48%)] Loss: 15135.687500\n",
      "Train Epoch: 9 [108544/225000 (48%)] Loss: 16204.368164\n",
      "Train Epoch: 9 [109952/225000 (49%)] Loss: 15309.988281\n",
      "Train Epoch: 9 [111360/225000 (49%)] Loss: 14973.701172\n",
      "Train Epoch: 9 [112768/225000 (50%)] Loss: 15750.839844\n",
      "Train Epoch: 9 [114176/225000 (51%)] Loss: 15122.314453\n",
      "Train Epoch: 9 [115584/225000 (51%)] Loss: 14882.984375\n",
      "Train Epoch: 9 [116992/225000 (52%)] Loss: 14765.977539\n",
      "Train Epoch: 9 [118400/225000 (53%)] Loss: 15193.459961\n",
      "Train Epoch: 9 [119808/225000 (53%)] Loss: 14966.628906\n",
      "Train Epoch: 9 [121216/225000 (54%)] Loss: 15204.643555\n",
      "Train Epoch: 9 [122624/225000 (54%)] Loss: 15187.786133\n",
      "Train Epoch: 9 [124032/225000 (55%)] Loss: 14966.018555\n",
      "Train Epoch: 9 [125440/225000 (56%)] Loss: 15734.352539\n",
      "Train Epoch: 9 [126848/225000 (56%)] Loss: 15205.324219\n",
      "Train Epoch: 9 [128256/225000 (57%)] Loss: 14831.658203\n",
      "Train Epoch: 9 [129664/225000 (58%)] Loss: 14534.636719\n",
      "Train Epoch: 9 [131072/225000 (58%)] Loss: 15216.971680\n",
      "Train Epoch: 9 [132480/225000 (59%)] Loss: 14905.266602\n",
      "Train Epoch: 9 [133888/225000 (60%)] Loss: 15202.398438\n",
      "Train Epoch: 9 [135296/225000 (60%)] Loss: 15326.841797\n",
      "Train Epoch: 9 [136704/225000 (61%)] Loss: 14874.999023\n",
      "Train Epoch: 9 [138112/225000 (61%)] Loss: 14846.710938\n",
      "Train Epoch: 9 [139520/225000 (62%)] Loss: 15476.162109\n",
      "Train Epoch: 9 [140928/225000 (63%)] Loss: 15056.659180\n",
      "Train Epoch: 9 [142336/225000 (63%)] Loss: 15279.252930\n",
      "Train Epoch: 9 [143744/225000 (64%)] Loss: 15303.460938\n",
      "Train Epoch: 9 [145152/225000 (65%)] Loss: 14792.824219\n",
      "Train Epoch: 9 [146560/225000 (65%)] Loss: 15013.495117\n",
      "Train Epoch: 9 [147968/225000 (66%)] Loss: 14910.200195\n",
      "Train Epoch: 9 [149376/225000 (66%)] Loss: 14889.972656\n",
      "Train Epoch: 9 [150784/225000 (67%)] Loss: 14897.917969\n",
      "Train Epoch: 9 [152192/225000 (68%)] Loss: 15412.684570\n",
      "Train Epoch: 9 [153600/225000 (68%)] Loss: 15103.691406\n",
      "Train Epoch: 9 [155008/225000 (69%)] Loss: 15026.299805\n",
      "Train Epoch: 9 [156416/225000 (70%)] Loss: 15140.901367\n",
      "Train Epoch: 9 [157824/225000 (70%)] Loss: 14873.514648\n",
      "Train Epoch: 9 [159232/225000 (71%)] Loss: 14805.023438\n",
      "Train Epoch: 9 [160640/225000 (71%)] Loss: 15154.164062\n",
      "Train Epoch: 9 [162048/225000 (72%)] Loss: 14874.000000\n",
      "Train Epoch: 9 [163456/225000 (73%)] Loss: 15036.959961\n",
      "Train Epoch: 9 [164864/225000 (73%)] Loss: 15223.625000\n",
      "Train Epoch: 9 [166272/225000 (74%)] Loss: 14850.928711\n",
      "Train Epoch: 9 [167680/225000 (75%)] Loss: 15215.123047\n",
      "Train Epoch: 9 [169088/225000 (75%)] Loss: 15097.529297\n",
      "Train Epoch: 9 [170496/225000 (76%)] Loss: 15383.264648\n",
      "Train Epoch: 9 [171904/225000 (76%)] Loss: 15461.492188\n",
      "Train Epoch: 9 [173312/225000 (77%)] Loss: 14595.321289\n",
      "Train Epoch: 9 [174720/225000 (78%)] Loss: 14829.829102\n",
      "Train Epoch: 9 [176128/225000 (78%)] Loss: 15138.654297\n",
      "Train Epoch: 9 [177536/225000 (79%)] Loss: 15146.452148\n",
      "Train Epoch: 9 [178944/225000 (80%)] Loss: 14485.625977\n",
      "Train Epoch: 9 [180352/225000 (80%)] Loss: 15298.078125\n",
      "Train Epoch: 9 [181760/225000 (81%)] Loss: 15156.731445\n",
      "Train Epoch: 9 [183168/225000 (81%)] Loss: 14948.742188\n",
      "Train Epoch: 9 [184576/225000 (82%)] Loss: 15129.337891\n",
      "Train Epoch: 9 [185984/225000 (83%)] Loss: 15116.905273\n",
      "Train Epoch: 9 [187392/225000 (83%)] Loss: 14884.610352\n",
      "Train Epoch: 9 [188800/225000 (84%)] Loss: 15312.618164\n",
      "Train Epoch: 9 [190208/225000 (85%)] Loss: 14936.428711\n",
      "Train Epoch: 9 [191616/225000 (85%)] Loss: 14683.734375\n",
      "Train Epoch: 9 [193024/225000 (86%)] Loss: 15113.397461\n",
      "Train Epoch: 9 [194432/225000 (86%)] Loss: 15277.379883\n",
      "Train Epoch: 9 [195840/225000 (87%)] Loss: 15331.941406\n",
      "Train Epoch: 9 [197248/225000 (88%)] Loss: 14841.801758\n",
      "Train Epoch: 9 [198656/225000 (88%)] Loss: 14962.771484\n",
      "Train Epoch: 9 [200064/225000 (89%)] Loss: 14973.986328\n",
      "Train Epoch: 9 [201472/225000 (90%)] Loss: 15110.444336\n",
      "Train Epoch: 9 [202880/225000 (90%)] Loss: 15292.548828\n",
      "Train Epoch: 9 [204288/225000 (91%)] Loss: 14927.935547\n",
      "Train Epoch: 9 [205696/225000 (91%)] Loss: 15564.038086\n",
      "Train Epoch: 9 [207104/225000 (92%)] Loss: 15066.936523\n",
      "Train Epoch: 9 [208512/225000 (93%)] Loss: 14970.544922\n",
      "Train Epoch: 9 [209920/225000 (93%)] Loss: 15412.770508\n",
      "Train Epoch: 9 [211328/225000 (94%)] Loss: 14756.225586\n",
      "Train Epoch: 9 [212736/225000 (95%)] Loss: 15088.606445\n",
      "Train Epoch: 9 [214144/225000 (95%)] Loss: 15108.283203\n",
      "Train Epoch: 9 [215552/225000 (96%)] Loss: 15091.503906\n",
      "Train Epoch: 9 [216960/225000 (96%)] Loss: 14949.435547\n",
      "Train Epoch: 9 [218368/225000 (97%)] Loss: 14991.116211\n",
      "Train Epoch: 9 [219776/225000 (98%)] Loss: 15432.151367\n",
      "Train Epoch: 9 [221184/225000 (98%)] Loss: 15201.356445\n",
      "Train Epoch: 9 [222592/225000 (99%)] Loss: 15392.161133\n",
      "Train Epoch: 9 [224000/225000 (100%)] Loss: 14810.024414\n",
      "    epoch          : 9\n",
      "    loss           : 15124.410466216937\n",
      "    val_loss       : 15131.141452461481\n",
      "Train Epoch: 10 [128/225000 (0%)] Loss: 15206.870117\n",
      "Train Epoch: 10 [1536/225000 (1%)] Loss: 15267.824219\n",
      "Train Epoch: 10 [2944/225000 (1%)] Loss: 15038.506836\n",
      "Train Epoch: 10 [4352/225000 (2%)] Loss: 14840.451172\n",
      "Train Epoch: 10 [5760/225000 (3%)] Loss: 15464.236328\n",
      "Train Epoch: 10 [7168/225000 (3%)] Loss: 15258.112305\n",
      "Train Epoch: 10 [8576/225000 (4%)] Loss: 14861.496094\n",
      "Train Epoch: 10 [9984/225000 (4%)] Loss: 14793.434570\n",
      "Train Epoch: 10 [11392/225000 (5%)] Loss: 15389.957031\n",
      "Train Epoch: 10 [12800/225000 (6%)] Loss: 15306.753906\n",
      "Train Epoch: 10 [14208/225000 (6%)] Loss: 15000.755859\n",
      "Train Epoch: 10 [15616/225000 (7%)] Loss: 15012.675781\n",
      "Train Epoch: 10 [17024/225000 (8%)] Loss: 14966.164062\n",
      "Train Epoch: 10 [18432/225000 (8%)] Loss: 15051.376953\n",
      "Train Epoch: 10 [19840/225000 (9%)] Loss: 15094.525391\n",
      "Train Epoch: 10 [21248/225000 (9%)] Loss: 15254.155273\n",
      "Train Epoch: 10 [22656/225000 (10%)] Loss: 15505.024414\n",
      "Train Epoch: 10 [24064/225000 (11%)] Loss: 14772.495117\n",
      "Train Epoch: 10 [25472/225000 (11%)] Loss: 14753.021484\n",
      "Train Epoch: 10 [26880/225000 (12%)] Loss: 14926.443359\n",
      "Train Epoch: 10 [28288/225000 (13%)] Loss: 14951.030273\n",
      "Train Epoch: 10 [29696/225000 (13%)] Loss: 14911.490234\n",
      "Train Epoch: 10 [31104/225000 (14%)] Loss: 15131.738281\n",
      "Train Epoch: 10 [32512/225000 (14%)] Loss: 15179.687500\n",
      "Train Epoch: 10 [33920/225000 (15%)] Loss: 14991.425781\n",
      "Train Epoch: 10 [35328/225000 (16%)] Loss: 15280.109375\n",
      "Train Epoch: 10 [36736/225000 (16%)] Loss: 15533.515625\n",
      "Train Epoch: 10 [38144/225000 (17%)] Loss: 15641.312500\n",
      "Train Epoch: 10 [39552/225000 (18%)] Loss: 15235.359375\n",
      "Train Epoch: 10 [40960/225000 (18%)] Loss: 15356.737305\n",
      "Train Epoch: 10 [42368/225000 (19%)] Loss: 15242.589844\n",
      "Train Epoch: 10 [43776/225000 (19%)] Loss: 14878.366211\n",
      "Train Epoch: 10 [45184/225000 (20%)] Loss: 15401.179688\n",
      "Train Epoch: 10 [46592/225000 (21%)] Loss: 15047.302734\n",
      "Train Epoch: 10 [48000/225000 (21%)] Loss: 15339.463867\n",
      "Train Epoch: 10 [49408/225000 (22%)] Loss: 15132.824219\n",
      "Train Epoch: 10 [50816/225000 (23%)] Loss: 15021.445312\n",
      "Train Epoch: 10 [52224/225000 (23%)] Loss: 14901.990234\n",
      "Train Epoch: 10 [53632/225000 (24%)] Loss: 15053.318359\n",
      "Train Epoch: 10 [55040/225000 (24%)] Loss: 15295.482422\n",
      "Train Epoch: 10 [56448/225000 (25%)] Loss: 14921.462891\n",
      "Train Epoch: 10 [57856/225000 (26%)] Loss: 14832.212891\n",
      "Train Epoch: 10 [59264/225000 (26%)] Loss: 14726.500000\n",
      "Train Epoch: 10 [60672/225000 (27%)] Loss: 14776.217773\n",
      "Train Epoch: 10 [62080/225000 (28%)] Loss: 15002.737305\n",
      "Train Epoch: 10 [63488/225000 (28%)] Loss: 15447.551758\n",
      "Train Epoch: 10 [64896/225000 (29%)] Loss: 14628.933594\n",
      "Train Epoch: 10 [66304/225000 (29%)] Loss: 15057.292969\n",
      "Train Epoch: 10 [67712/225000 (30%)] Loss: 15276.976562\n",
      "Train Epoch: 10 [69120/225000 (31%)] Loss: 14670.551758\n",
      "Train Epoch: 10 [70528/225000 (31%)] Loss: 15127.728516\n",
      "Train Epoch: 10 [71936/225000 (32%)] Loss: 14919.826172\n",
      "Train Epoch: 10 [73344/225000 (33%)] Loss: 14894.859375\n",
      "Train Epoch: 10 [74752/225000 (33%)] Loss: 15178.653320\n",
      "Train Epoch: 10 [76160/225000 (34%)] Loss: 15779.636719\n",
      "Train Epoch: 10 [77568/225000 (34%)] Loss: 15088.269531\n",
      "Train Epoch: 10 [78976/225000 (35%)] Loss: 15467.040039\n",
      "Train Epoch: 10 [80384/225000 (36%)] Loss: 15746.398438\n",
      "Train Epoch: 10 [81792/225000 (36%)] Loss: 15149.239258\n",
      "Train Epoch: 10 [83200/225000 (37%)] Loss: 15189.328125\n",
      "Train Epoch: 10 [84608/225000 (38%)] Loss: 14912.467773\n",
      "Train Epoch: 10 [86016/225000 (38%)] Loss: 15270.282227\n",
      "Train Epoch: 10 [87424/225000 (39%)] Loss: 15235.646484\n",
      "Train Epoch: 10 [88832/225000 (39%)] Loss: 14743.153320\n",
      "Train Epoch: 10 [90240/225000 (40%)] Loss: 15206.339844\n",
      "Train Epoch: 10 [91648/225000 (41%)] Loss: 15284.905273\n",
      "Train Epoch: 10 [93056/225000 (41%)] Loss: 15201.160156\n",
      "Train Epoch: 10 [94464/225000 (42%)] Loss: 15226.612305\n",
      "Train Epoch: 10 [95872/225000 (43%)] Loss: 15202.448242\n",
      "Train Epoch: 10 [97280/225000 (43%)] Loss: 15248.259766\n",
      "Train Epoch: 10 [98688/225000 (44%)] Loss: 14893.548828\n",
      "Train Epoch: 10 [100096/225000 (44%)] Loss: 15204.692383\n",
      "Train Epoch: 10 [101504/225000 (45%)] Loss: 15091.499023\n",
      "Train Epoch: 10 [102912/225000 (46%)] Loss: 15212.465820\n",
      "Train Epoch: 10 [104320/225000 (46%)] Loss: 15603.558594\n",
      "Train Epoch: 10 [105728/225000 (47%)] Loss: 14741.258789\n",
      "Train Epoch: 10 [107136/225000 (48%)] Loss: 15119.530273\n",
      "Train Epoch: 10 [108544/225000 (48%)] Loss: 14775.670898\n",
      "Train Epoch: 10 [109952/225000 (49%)] Loss: 15260.785156\n",
      "Train Epoch: 10 [111360/225000 (49%)] Loss: 15119.472656\n",
      "Train Epoch: 10 [112768/225000 (50%)] Loss: 15666.435547\n",
      "Train Epoch: 10 [114176/225000 (51%)] Loss: 15465.862305\n",
      "Train Epoch: 10 [115584/225000 (51%)] Loss: 15282.713867\n",
      "Train Epoch: 10 [116992/225000 (52%)] Loss: 15018.117188\n",
      "Train Epoch: 10 [118400/225000 (53%)] Loss: 15149.844727\n",
      "Train Epoch: 10 [119808/225000 (53%)] Loss: 15422.566406\n",
      "Train Epoch: 10 [121216/225000 (54%)] Loss: 15495.906250\n",
      "Train Epoch: 10 [122624/225000 (54%)] Loss: 15477.118164\n",
      "Train Epoch: 10 [124032/225000 (55%)] Loss: 15062.275391\n",
      "Train Epoch: 10 [125440/225000 (56%)] Loss: 15174.729492\n",
      "Train Epoch: 10 [126848/225000 (56%)] Loss: 15319.630859\n",
      "Train Epoch: 10 [128256/225000 (57%)] Loss: 14780.371094\n",
      "Train Epoch: 10 [129664/225000 (58%)] Loss: 15123.059570\n",
      "Train Epoch: 10 [131072/225000 (58%)] Loss: 14806.304688\n",
      "Train Epoch: 10 [132480/225000 (59%)] Loss: 14690.456055\n",
      "Train Epoch: 10 [133888/225000 (60%)] Loss: 15303.139648\n",
      "Train Epoch: 10 [135296/225000 (60%)] Loss: 15313.029297\n",
      "Train Epoch: 10 [136704/225000 (61%)] Loss: 15298.043945\n",
      "Train Epoch: 10 [138112/225000 (61%)] Loss: 15249.207031\n",
      "Train Epoch: 10 [139520/225000 (62%)] Loss: 14805.276367\n",
      "Train Epoch: 10 [140928/225000 (63%)] Loss: 15285.016602\n",
      "Train Epoch: 10 [142336/225000 (63%)] Loss: 14766.468750\n",
      "Train Epoch: 10 [143744/225000 (64%)] Loss: 15133.728516\n",
      "Train Epoch: 10 [145152/225000 (65%)] Loss: 14621.334961\n",
      "Train Epoch: 10 [146560/225000 (65%)] Loss: 14953.519531\n",
      "Train Epoch: 10 [147968/225000 (66%)] Loss: 15180.780273\n",
      "Train Epoch: 10 [149376/225000 (66%)] Loss: 14663.579102\n",
      "Train Epoch: 10 [150784/225000 (67%)] Loss: 15351.452148\n",
      "Train Epoch: 10 [152192/225000 (68%)] Loss: 14842.529297\n",
      "Train Epoch: 10 [153600/225000 (68%)] Loss: 14908.879883\n",
      "Train Epoch: 10 [155008/225000 (69%)] Loss: 14669.434570\n",
      "Train Epoch: 10 [156416/225000 (70%)] Loss: 14918.185547\n",
      "Train Epoch: 10 [157824/225000 (70%)] Loss: 15160.140625\n",
      "Train Epoch: 10 [159232/225000 (71%)] Loss: 15150.656250\n",
      "Train Epoch: 10 [160640/225000 (71%)] Loss: 14846.468750\n",
      "Train Epoch: 10 [162048/225000 (72%)] Loss: 15445.005859\n",
      "Train Epoch: 10 [163456/225000 (73%)] Loss: 15313.221680\n",
      "Train Epoch: 10 [164864/225000 (73%)] Loss: 14918.341797\n",
      "Train Epoch: 10 [166272/225000 (74%)] Loss: 14931.365234\n",
      "Train Epoch: 10 [167680/225000 (75%)] Loss: 15156.734375\n",
      "Train Epoch: 10 [169088/225000 (75%)] Loss: 15428.421875\n",
      "Train Epoch: 10 [170496/225000 (76%)] Loss: 15108.039062\n",
      "Train Epoch: 10 [171904/225000 (76%)] Loss: 15171.069336\n",
      "Train Epoch: 10 [173312/225000 (77%)] Loss: 14793.011719\n",
      "Train Epoch: 10 [174720/225000 (78%)] Loss: 14847.270508\n",
      "Train Epoch: 10 [176128/225000 (78%)] Loss: 14757.630859\n",
      "Train Epoch: 10 [177536/225000 (79%)] Loss: 14847.182617\n",
      "Train Epoch: 10 [178944/225000 (80%)] Loss: 15102.386719\n",
      "Train Epoch: 10 [180352/225000 (80%)] Loss: 14675.104492\n",
      "Train Epoch: 10 [181760/225000 (81%)] Loss: 15061.669922\n",
      "Train Epoch: 10 [183168/225000 (81%)] Loss: 15283.045898\n",
      "Train Epoch: 10 [184576/225000 (82%)] Loss: 14749.979492\n",
      "Train Epoch: 10 [185984/225000 (83%)] Loss: 15133.514648\n",
      "Train Epoch: 10 [187392/225000 (83%)] Loss: 14608.998047\n",
      "Train Epoch: 10 [188800/225000 (84%)] Loss: 15050.855469\n",
      "Train Epoch: 10 [190208/225000 (85%)] Loss: 15443.029297\n",
      "Train Epoch: 10 [191616/225000 (85%)] Loss: 15082.463867\n",
      "Train Epoch: 10 [193024/225000 (86%)] Loss: 15214.643555\n",
      "Train Epoch: 10 [194432/225000 (86%)] Loss: 15117.083008\n",
      "Train Epoch: 10 [195840/225000 (87%)] Loss: 15362.669922\n",
      "Train Epoch: 10 [197248/225000 (88%)] Loss: 15063.664062\n",
      "Train Epoch: 10 [198656/225000 (88%)] Loss: 14586.820312\n",
      "Train Epoch: 10 [200064/225000 (89%)] Loss: 15092.765625\n",
      "Train Epoch: 10 [201472/225000 (90%)] Loss: 15382.513672\n",
      "Train Epoch: 10 [202880/225000 (90%)] Loss: 14791.630859\n",
      "Train Epoch: 10 [204288/225000 (91%)] Loss: 15593.811523\n",
      "Train Epoch: 10 [205696/225000 (91%)] Loss: 15746.490234\n",
      "Train Epoch: 10 [207104/225000 (92%)] Loss: 14921.163086\n",
      "Train Epoch: 10 [208512/225000 (93%)] Loss: 14727.017578\n",
      "Train Epoch: 10 [209920/225000 (93%)] Loss: 14948.787109\n",
      "Train Epoch: 10 [211328/225000 (94%)] Loss: 15803.883789\n",
      "Train Epoch: 10 [212736/225000 (95%)] Loss: 14997.210938\n",
      "Train Epoch: 10 [214144/225000 (95%)] Loss: 15143.136719\n",
      "Train Epoch: 10 [215552/225000 (96%)] Loss: 14995.996094\n",
      "Train Epoch: 10 [216960/225000 (96%)] Loss: 14657.342773\n",
      "Train Epoch: 10 [218368/225000 (97%)] Loss: 15088.303711\n",
      "Train Epoch: 10 [219776/225000 (98%)] Loss: 15109.594727\n",
      "Train Epoch: 10 [221184/225000 (98%)] Loss: 15017.743164\n",
      "Train Epoch: 10 [222592/225000 (99%)] Loss: 14792.178711\n",
      "Train Epoch: 10 [224000/225000 (100%)] Loss: 14912.941406\n",
      "    epoch          : 10\n",
      "    loss           : 15118.915509012371\n",
      "    val_loss       : 15079.243607866216\n",
      "Train Epoch: 11 [128/225000 (0%)] Loss: 14639.708984\n",
      "Train Epoch: 11 [1536/225000 (1%)] Loss: 15472.136719\n",
      "Train Epoch: 11 [2944/225000 (1%)] Loss: 15040.206055\n",
      "Train Epoch: 11 [4352/225000 (2%)] Loss: 15454.682617\n",
      "Train Epoch: 11 [5760/225000 (3%)] Loss: 15020.279297\n",
      "Train Epoch: 11 [7168/225000 (3%)] Loss: 15022.660156\n",
      "Train Epoch: 11 [8576/225000 (4%)] Loss: 15428.266602\n",
      "Train Epoch: 11 [9984/225000 (4%)] Loss: 15012.159180\n",
      "Train Epoch: 11 [11392/225000 (5%)] Loss: 15309.054688\n",
      "Train Epoch: 11 [12800/225000 (6%)] Loss: 15297.078125\n",
      "Train Epoch: 11 [14208/225000 (6%)] Loss: 14957.517578\n",
      "Train Epoch: 11 [15616/225000 (7%)] Loss: 14880.086914\n",
      "Train Epoch: 11 [17024/225000 (8%)] Loss: 14574.841797\n",
      "Train Epoch: 11 [18432/225000 (8%)] Loss: 15001.137695\n",
      "Train Epoch: 11 [19840/225000 (9%)] Loss: 15137.481445\n",
      "Train Epoch: 11 [21248/225000 (9%)] Loss: 15260.386719\n",
      "Train Epoch: 11 [22656/225000 (10%)] Loss: 15605.673828\n",
      "Train Epoch: 11 [24064/225000 (11%)] Loss: 14991.071289\n",
      "Train Epoch: 11 [25472/225000 (11%)] Loss: 15082.121094\n",
      "Train Epoch: 11 [26880/225000 (12%)] Loss: 15449.420898\n",
      "Train Epoch: 11 [28288/225000 (13%)] Loss: 15401.333984\n",
      "Train Epoch: 11 [29696/225000 (13%)] Loss: 15316.536133\n",
      "Train Epoch: 11 [31104/225000 (14%)] Loss: 15640.387695\n",
      "Train Epoch: 11 [32512/225000 (14%)] Loss: 15262.221680\n",
      "Train Epoch: 11 [33920/225000 (15%)] Loss: 14918.793945\n",
      "Train Epoch: 11 [35328/225000 (16%)] Loss: 15272.363281\n",
      "Train Epoch: 11 [36736/225000 (16%)] Loss: 15429.847656\n",
      "Train Epoch: 11 [38144/225000 (17%)] Loss: 14593.488281\n",
      "Train Epoch: 11 [39552/225000 (18%)] Loss: 15287.559570\n",
      "Train Epoch: 11 [40960/225000 (18%)] Loss: 15108.873047\n",
      "Train Epoch: 11 [42368/225000 (19%)] Loss: 15759.461914\n",
      "Train Epoch: 11 [43776/225000 (19%)] Loss: 15264.571289\n",
      "Train Epoch: 11 [45184/225000 (20%)] Loss: 15284.510742\n",
      "Train Epoch: 11 [46592/225000 (21%)] Loss: 15109.451172\n",
      "Train Epoch: 11 [48000/225000 (21%)] Loss: 15358.813477\n",
      "Train Epoch: 11 [49408/225000 (22%)] Loss: 15121.271484\n",
      "Train Epoch: 11 [50816/225000 (23%)] Loss: 15399.045898\n",
      "Train Epoch: 11 [52224/225000 (23%)] Loss: 15406.015625\n",
      "Train Epoch: 11 [53632/225000 (24%)] Loss: 15231.919922\n",
      "Train Epoch: 11 [55040/225000 (24%)] Loss: 15285.573242\n",
      "Train Epoch: 11 [56448/225000 (25%)] Loss: 15480.521484\n",
      "Train Epoch: 11 [57856/225000 (26%)] Loss: 15090.094727\n",
      "Train Epoch: 11 [59264/225000 (26%)] Loss: 15220.097656\n",
      "Train Epoch: 11 [60672/225000 (27%)] Loss: 15416.183594\n",
      "Train Epoch: 11 [62080/225000 (28%)] Loss: 15282.094727\n",
      "Train Epoch: 11 [63488/225000 (28%)] Loss: 14931.107422\n",
      "Train Epoch: 11 [64896/225000 (29%)] Loss: 14911.094727\n",
      "Train Epoch: 11 [66304/225000 (29%)] Loss: 14836.253906\n",
      "Train Epoch: 11 [67712/225000 (30%)] Loss: 15236.318359\n",
      "Train Epoch: 11 [69120/225000 (31%)] Loss: 15971.287109\n",
      "Train Epoch: 11 [70528/225000 (31%)] Loss: 15144.274414\n",
      "Train Epoch: 11 [71936/225000 (32%)] Loss: 14964.922852\n",
      "Train Epoch: 11 [73344/225000 (33%)] Loss: 14811.591797\n",
      "Train Epoch: 11 [74752/225000 (33%)] Loss: 15242.609375\n",
      "Train Epoch: 11 [76160/225000 (34%)] Loss: 15028.619141\n",
      "Train Epoch: 11 [77568/225000 (34%)] Loss: 14584.321289\n",
      "Train Epoch: 11 [78976/225000 (35%)] Loss: 14855.285156\n",
      "Train Epoch: 11 [80384/225000 (36%)] Loss: 15026.058594\n",
      "Train Epoch: 11 [81792/225000 (36%)] Loss: 14727.566406\n",
      "Train Epoch: 11 [83200/225000 (37%)] Loss: 14883.268555\n",
      "Train Epoch: 11 [84608/225000 (38%)] Loss: 15298.279297\n",
      "Train Epoch: 11 [86016/225000 (38%)] Loss: 15179.617188\n",
      "Train Epoch: 11 [87424/225000 (39%)] Loss: 14972.506836\n",
      "Train Epoch: 11 [88832/225000 (39%)] Loss: 14893.491211\n",
      "Train Epoch: 11 [90240/225000 (40%)] Loss: 15028.443359\n",
      "Train Epoch: 11 [91648/225000 (41%)] Loss: 14808.298828\n",
      "Train Epoch: 11 [93056/225000 (41%)] Loss: 15226.556641\n",
      "Train Epoch: 11 [94464/225000 (42%)] Loss: 14961.820312\n",
      "Train Epoch: 11 [95872/225000 (43%)] Loss: 14651.314453\n",
      "Train Epoch: 11 [97280/225000 (43%)] Loss: 15282.083008\n",
      "Train Epoch: 11 [98688/225000 (44%)] Loss: 15210.950195\n",
      "Train Epoch: 11 [100096/225000 (44%)] Loss: 14713.597656\n",
      "Train Epoch: 11 [101504/225000 (45%)] Loss: 15025.933594\n",
      "Train Epoch: 11 [102912/225000 (46%)] Loss: 15098.864258\n",
      "Train Epoch: 11 [104320/225000 (46%)] Loss: 15218.875977\n",
      "Train Epoch: 11 [105728/225000 (47%)] Loss: 16000.613281\n",
      "Train Epoch: 11 [107136/225000 (48%)] Loss: 15007.600586\n",
      "Train Epoch: 11 [108544/225000 (48%)] Loss: 14774.341797\n",
      "Train Epoch: 11 [109952/225000 (49%)] Loss: 15132.079102\n",
      "Train Epoch: 11 [111360/225000 (49%)] Loss: 15151.339844\n",
      "Train Epoch: 11 [112768/225000 (50%)] Loss: 15175.130859\n",
      "Train Epoch: 11 [114176/225000 (51%)] Loss: 15113.285156\n",
      "Train Epoch: 11 [115584/225000 (51%)] Loss: 15405.928711\n",
      "Train Epoch: 11 [116992/225000 (52%)] Loss: 15136.229492\n",
      "Train Epoch: 11 [118400/225000 (53%)] Loss: 15542.078125\n",
      "Train Epoch: 11 [119808/225000 (53%)] Loss: 15359.145508\n",
      "Train Epoch: 11 [121216/225000 (54%)] Loss: 14868.570312\n",
      "Train Epoch: 11 [122624/225000 (54%)] Loss: 15263.125977\n",
      "Train Epoch: 11 [124032/225000 (55%)] Loss: 15191.067383\n",
      "Train Epoch: 11 [125440/225000 (56%)] Loss: 15331.364258\n",
      "Train Epoch: 11 [126848/225000 (56%)] Loss: 15235.826172\n",
      "Train Epoch: 11 [128256/225000 (57%)] Loss: 14830.245117\n",
      "Train Epoch: 11 [129664/225000 (58%)] Loss: 14729.962891\n",
      "Train Epoch: 11 [131072/225000 (58%)] Loss: 15263.688477\n",
      "Train Epoch: 11 [132480/225000 (59%)] Loss: 15095.305664\n",
      "Train Epoch: 11 [133888/225000 (60%)] Loss: 15311.769531\n",
      "Train Epoch: 11 [135296/225000 (60%)] Loss: 14635.038086\n",
      "Train Epoch: 11 [136704/225000 (61%)] Loss: 15259.689453\n",
      "Train Epoch: 11 [138112/225000 (61%)] Loss: 15000.573242\n",
      "Train Epoch: 11 [139520/225000 (62%)] Loss: 15166.159180\n",
      "Train Epoch: 11 [140928/225000 (63%)] Loss: 14795.962891\n",
      "Train Epoch: 11 [142336/225000 (63%)] Loss: 15129.986328\n",
      "Train Epoch: 11 [143744/225000 (64%)] Loss: 15123.361328\n",
      "Train Epoch: 11 [145152/225000 (65%)] Loss: 15213.452148\n",
      "Train Epoch: 11 [146560/225000 (65%)] Loss: 14856.976562\n",
      "Train Epoch: 11 [147968/225000 (66%)] Loss: 15154.337891\n",
      "Train Epoch: 11 [149376/225000 (66%)] Loss: 15349.399414\n",
      "Train Epoch: 11 [150784/225000 (67%)] Loss: 14861.125000\n",
      "Train Epoch: 11 [152192/225000 (68%)] Loss: 15080.064453\n",
      "Train Epoch: 11 [153600/225000 (68%)] Loss: 15092.454102\n",
      "Train Epoch: 11 [155008/225000 (69%)] Loss: 15009.833008\n",
      "Train Epoch: 11 [156416/225000 (70%)] Loss: 15263.186523\n",
      "Train Epoch: 11 [157824/225000 (70%)] Loss: 15208.699219\n",
      "Train Epoch: 11 [159232/225000 (71%)] Loss: 15268.176758\n",
      "Train Epoch: 11 [160640/225000 (71%)] Loss: 15133.270508\n",
      "Train Epoch: 11 [162048/225000 (72%)] Loss: 15135.026367\n",
      "Train Epoch: 11 [163456/225000 (73%)] Loss: 15448.587891\n",
      "Train Epoch: 11 [164864/225000 (73%)] Loss: 14989.325195\n",
      "Train Epoch: 11 [166272/225000 (74%)] Loss: 15449.335938\n",
      "Train Epoch: 11 [167680/225000 (75%)] Loss: 15264.987305\n",
      "Train Epoch: 11 [169088/225000 (75%)] Loss: 15082.636719\n",
      "Train Epoch: 11 [170496/225000 (76%)] Loss: 14954.125000\n",
      "Train Epoch: 11 [171904/225000 (76%)] Loss: 15354.725586\n",
      "Train Epoch: 11 [173312/225000 (77%)] Loss: 14900.020508\n",
      "Train Epoch: 11 [174720/225000 (78%)] Loss: 15228.680664\n",
      "Train Epoch: 11 [176128/225000 (78%)] Loss: 15332.534180\n",
      "Train Epoch: 11 [177536/225000 (79%)] Loss: 14904.431641\n",
      "Train Epoch: 11 [178944/225000 (80%)] Loss: 15397.869141\n",
      "Train Epoch: 11 [180352/225000 (80%)] Loss: 15338.098633\n",
      "Train Epoch: 11 [181760/225000 (81%)] Loss: 14944.937500\n",
      "Train Epoch: 11 [183168/225000 (81%)] Loss: 15021.084961\n",
      "Train Epoch: 11 [184576/225000 (82%)] Loss: 15476.389648\n",
      "Train Epoch: 11 [185984/225000 (83%)] Loss: 15418.952148\n",
      "Train Epoch: 11 [187392/225000 (83%)] Loss: 15030.092773\n",
      "Train Epoch: 11 [188800/225000 (84%)] Loss: 15187.794922\n",
      "Train Epoch: 11 [190208/225000 (85%)] Loss: 15663.787109\n",
      "Train Epoch: 11 [191616/225000 (85%)] Loss: 14838.969727\n",
      "Train Epoch: 11 [193024/225000 (86%)] Loss: 14931.172852\n",
      "Train Epoch: 11 [194432/225000 (86%)] Loss: 15140.844727\n",
      "Train Epoch: 11 [195840/225000 (87%)] Loss: 15339.556641\n",
      "Train Epoch: 11 [197248/225000 (88%)] Loss: 15304.666016\n",
      "Train Epoch: 11 [198656/225000 (88%)] Loss: 15040.426758\n",
      "Train Epoch: 11 [200064/225000 (89%)] Loss: 14919.850586\n",
      "Train Epoch: 11 [201472/225000 (90%)] Loss: 15077.394531\n",
      "Train Epoch: 11 [202880/225000 (90%)] Loss: 14862.218750\n",
      "Train Epoch: 11 [204288/225000 (91%)] Loss: 15060.767578\n",
      "Train Epoch: 11 [205696/225000 (91%)] Loss: 15099.260742\n",
      "Train Epoch: 11 [207104/225000 (92%)] Loss: 14975.622070\n",
      "Train Epoch: 11 [208512/225000 (93%)] Loss: 14808.240234\n",
      "Train Epoch: 11 [209920/225000 (93%)] Loss: 15070.351562\n",
      "Train Epoch: 11 [211328/225000 (94%)] Loss: 15270.082031\n",
      "Train Epoch: 11 [212736/225000 (95%)] Loss: 15103.324219\n",
      "Train Epoch: 11 [214144/225000 (95%)] Loss: 15026.510742\n",
      "Train Epoch: 11 [215552/225000 (96%)] Loss: 15530.365234\n",
      "Train Epoch: 11 [216960/225000 (96%)] Loss: 15686.574219\n",
      "Train Epoch: 11 [218368/225000 (97%)] Loss: 15063.411133\n",
      "Train Epoch: 11 [219776/225000 (98%)] Loss: 15527.928711\n",
      "Train Epoch: 11 [221184/225000 (98%)] Loss: 15348.355469\n",
      "Train Epoch: 11 [222592/225000 (99%)] Loss: 15297.639648\n",
      "Train Epoch: 11 [224000/225000 (100%)] Loss: 14970.190430\n",
      "    epoch          : 11\n",
      "    loss           : 15104.109791622226\n",
      "    val_loss       : 15111.277065769751\n",
      "Train Epoch: 12 [128/225000 (0%)] Loss: 14818.203125\n",
      "Train Epoch: 12 [1536/225000 (1%)] Loss: 15175.154297\n",
      "Train Epoch: 12 [2944/225000 (1%)] Loss: 14535.164062\n",
      "Train Epoch: 12 [4352/225000 (2%)] Loss: 22399.843750\n",
      "Train Epoch: 12 [5760/225000 (3%)] Loss: 15564.039062\n",
      "Train Epoch: 12 [7168/225000 (3%)] Loss: 15064.915039\n",
      "Train Epoch: 12 [8576/225000 (4%)] Loss: 15028.238281\n",
      "Train Epoch: 12 [9984/225000 (4%)] Loss: 15092.729492\n",
      "Train Epoch: 12 [11392/225000 (5%)] Loss: 15127.513672\n",
      "Train Epoch: 12 [12800/225000 (6%)] Loss: 15061.670898\n",
      "Train Epoch: 12 [14208/225000 (6%)] Loss: 15066.376953\n",
      "Train Epoch: 12 [15616/225000 (7%)] Loss: 14980.876953\n",
      "Train Epoch: 12 [17024/225000 (8%)] Loss: 14904.731445\n",
      "Train Epoch: 12 [18432/225000 (8%)] Loss: 15309.087891\n",
      "Train Epoch: 12 [19840/225000 (9%)] Loss: 15126.069336\n",
      "Train Epoch: 12 [21248/225000 (9%)] Loss: 15106.555664\n",
      "Train Epoch: 12 [22656/225000 (10%)] Loss: 15694.478516\n",
      "Train Epoch: 12 [24064/225000 (11%)] Loss: 15279.532227\n",
      "Train Epoch: 12 [25472/225000 (11%)] Loss: 15264.357422\n",
      "Train Epoch: 12 [26880/225000 (12%)] Loss: 14724.427734\n",
      "Train Epoch: 12 [28288/225000 (13%)] Loss: 15018.849609\n",
      "Train Epoch: 12 [29696/225000 (13%)] Loss: 15367.042969\n",
      "Train Epoch: 12 [31104/225000 (14%)] Loss: 14986.929688\n",
      "Train Epoch: 12 [32512/225000 (14%)] Loss: 15064.191406\n",
      "Train Epoch: 12 [33920/225000 (15%)] Loss: 15155.380859\n",
      "Train Epoch: 12 [35328/225000 (16%)] Loss: 15069.130859\n",
      "Train Epoch: 12 [36736/225000 (16%)] Loss: 14599.806641\n",
      "Train Epoch: 12 [38144/225000 (17%)] Loss: 15110.411133\n",
      "Train Epoch: 12 [39552/225000 (18%)] Loss: 15159.215820\n",
      "Train Epoch: 12 [40960/225000 (18%)] Loss: 14971.710938\n",
      "Train Epoch: 12 [42368/225000 (19%)] Loss: 14901.586914\n",
      "Train Epoch: 12 [43776/225000 (19%)] Loss: 14973.379883\n",
      "Train Epoch: 12 [45184/225000 (20%)] Loss: 14832.090820\n",
      "Train Epoch: 12 [46592/225000 (21%)] Loss: 15245.614258\n",
      "Train Epoch: 12 [48000/225000 (21%)] Loss: 15096.565430\n",
      "Train Epoch: 12 [49408/225000 (22%)] Loss: 14833.437500\n",
      "Train Epoch: 12 [50816/225000 (23%)] Loss: 21923.402344\n",
      "Train Epoch: 12 [52224/225000 (23%)] Loss: 15163.468750\n",
      "Train Epoch: 12 [53632/225000 (24%)] Loss: 14929.202148\n",
      "Train Epoch: 12 [55040/225000 (24%)] Loss: 14792.427734\n",
      "Train Epoch: 12 [56448/225000 (25%)] Loss: 15427.708984\n",
      "Train Epoch: 12 [57856/225000 (26%)] Loss: 15326.036133\n",
      "Train Epoch: 12 [59264/225000 (26%)] Loss: 17236.628906\n",
      "Train Epoch: 12 [60672/225000 (27%)] Loss: 14996.727539\n",
      "Train Epoch: 12 [62080/225000 (28%)] Loss: 15076.125977\n",
      "Train Epoch: 12 [63488/225000 (28%)] Loss: 14849.737305\n",
      "Train Epoch: 12 [64896/225000 (29%)] Loss: 15062.595703\n",
      "Train Epoch: 12 [66304/225000 (29%)] Loss: 15098.978516\n",
      "Train Epoch: 12 [67712/225000 (30%)] Loss: 14918.856445\n",
      "Train Epoch: 12 [69120/225000 (31%)] Loss: 14807.486328\n",
      "Train Epoch: 12 [70528/225000 (31%)] Loss: 15361.958008\n",
      "Train Epoch: 12 [71936/225000 (32%)] Loss: 15105.388672\n",
      "Train Epoch: 12 [73344/225000 (33%)] Loss: 15428.846680\n",
      "Train Epoch: 12 [74752/225000 (33%)] Loss: 14898.023438\n",
      "Train Epoch: 12 [76160/225000 (34%)] Loss: 14965.116211\n",
      "Train Epoch: 12 [77568/225000 (34%)] Loss: 15124.133789\n",
      "Train Epoch: 12 [78976/225000 (35%)] Loss: 14951.675781\n",
      "Train Epoch: 12 [80384/225000 (36%)] Loss: 15228.112305\n",
      "Train Epoch: 12 [81792/225000 (36%)] Loss: 14728.991211\n",
      "Train Epoch: 12 [83200/225000 (37%)] Loss: 14822.428711\n",
      "Train Epoch: 12 [84608/225000 (38%)] Loss: 14885.572266\n",
      "Train Epoch: 12 [86016/225000 (38%)] Loss: 15116.670898\n",
      "Train Epoch: 12 [87424/225000 (39%)] Loss: 15168.642578\n",
      "Train Epoch: 12 [88832/225000 (39%)] Loss: 15002.358398\n",
      "Train Epoch: 12 [90240/225000 (40%)] Loss: 14668.125000\n",
      "Train Epoch: 12 [91648/225000 (41%)] Loss: 14838.797852\n",
      "Train Epoch: 12 [93056/225000 (41%)] Loss: 15267.839844\n",
      "Train Epoch: 12 [94464/225000 (42%)] Loss: 15034.298828\n",
      "Train Epoch: 12 [95872/225000 (43%)] Loss: 15108.885742\n",
      "Train Epoch: 12 [97280/225000 (43%)] Loss: 14605.283203\n",
      "Train Epoch: 12 [98688/225000 (44%)] Loss: 14940.044922\n",
      "Train Epoch: 12 [100096/225000 (44%)] Loss: 15505.458984\n",
      "Train Epoch: 12 [101504/225000 (45%)] Loss: 14840.262695\n",
      "Train Epoch: 12 [102912/225000 (46%)] Loss: 15157.928711\n",
      "Train Epoch: 12 [104320/225000 (46%)] Loss: 15592.988281\n",
      "Train Epoch: 12 [105728/225000 (47%)] Loss: 14652.350586\n",
      "Train Epoch: 12 [107136/225000 (48%)] Loss: 14743.586914\n",
      "Train Epoch: 12 [108544/225000 (48%)] Loss: 15326.956055\n",
      "Train Epoch: 12 [109952/225000 (49%)] Loss: 15044.573242\n",
      "Train Epoch: 12 [111360/225000 (49%)] Loss: 14680.858398\n",
      "Train Epoch: 12 [112768/225000 (50%)] Loss: 15141.595703\n",
      "Train Epoch: 12 [114176/225000 (51%)] Loss: 14905.061523\n",
      "Train Epoch: 12 [115584/225000 (51%)] Loss: 15511.343750\n",
      "Train Epoch: 12 [116992/225000 (52%)] Loss: 15270.098633\n",
      "Train Epoch: 12 [118400/225000 (53%)] Loss: 15011.160156\n",
      "Train Epoch: 12 [119808/225000 (53%)] Loss: 15158.864258\n",
      "Train Epoch: 12 [121216/225000 (54%)] Loss: 15214.079102\n",
      "Train Epoch: 12 [122624/225000 (54%)] Loss: 15193.192383\n",
      "Train Epoch: 12 [124032/225000 (55%)] Loss: 15139.243164\n",
      "Train Epoch: 12 [125440/225000 (56%)] Loss: 15227.968750\n",
      "Train Epoch: 12 [126848/225000 (56%)] Loss: 15271.699219\n",
      "Train Epoch: 12 [128256/225000 (57%)] Loss: 14961.664062\n",
      "Train Epoch: 12 [129664/225000 (58%)] Loss: 15143.417969\n",
      "Train Epoch: 12 [131072/225000 (58%)] Loss: 15046.360352\n",
      "Train Epoch: 12 [132480/225000 (59%)] Loss: 15255.220703\n",
      "Train Epoch: 12 [133888/225000 (60%)] Loss: 14874.102539\n",
      "Train Epoch: 12 [135296/225000 (60%)] Loss: 14964.708008\n",
      "Train Epoch: 12 [136704/225000 (61%)] Loss: 15234.559570\n",
      "Train Epoch: 12 [138112/225000 (61%)] Loss: 14676.409180\n",
      "Train Epoch: 12 [139520/225000 (62%)] Loss: 15154.856445\n",
      "Train Epoch: 12 [140928/225000 (63%)] Loss: 15002.596680\n",
      "Train Epoch: 12 [142336/225000 (63%)] Loss: 15249.660156\n",
      "Train Epoch: 12 [143744/225000 (64%)] Loss: 14492.003906\n",
      "Train Epoch: 12 [145152/225000 (65%)] Loss: 14732.148438\n",
      "Train Epoch: 12 [146560/225000 (65%)] Loss: 14954.802734\n",
      "Train Epoch: 12 [147968/225000 (66%)] Loss: 15046.860352\n",
      "Train Epoch: 12 [149376/225000 (66%)] Loss: 15124.158203\n",
      "Train Epoch: 12 [150784/225000 (67%)] Loss: 14797.857422\n",
      "Train Epoch: 12 [152192/225000 (68%)] Loss: 15173.696289\n",
      "Train Epoch: 12 [153600/225000 (68%)] Loss: 14692.431641\n",
      "Train Epoch: 12 [155008/225000 (69%)] Loss: 15309.618164\n",
      "Train Epoch: 12 [156416/225000 (70%)] Loss: 15353.287109\n",
      "Train Epoch: 12 [157824/225000 (70%)] Loss: 15335.988281\n",
      "Train Epoch: 12 [159232/225000 (71%)] Loss: 15304.338867\n",
      "Train Epoch: 12 [160640/225000 (71%)] Loss: 15689.883789\n",
      "Train Epoch: 12 [162048/225000 (72%)] Loss: 15227.656250\n",
      "Train Epoch: 12 [163456/225000 (73%)] Loss: 14828.301758\n",
      "Train Epoch: 12 [164864/225000 (73%)] Loss: 15237.779297\n",
      "Train Epoch: 12 [166272/225000 (74%)] Loss: 14803.223633\n",
      "Train Epoch: 12 [167680/225000 (75%)] Loss: 15038.581055\n",
      "Train Epoch: 12 [169088/225000 (75%)] Loss: 15123.935547\n",
      "Train Epoch: 12 [170496/225000 (76%)] Loss: 15126.884766\n",
      "Train Epoch: 12 [171904/225000 (76%)] Loss: 15258.959961\n",
      "Train Epoch: 12 [173312/225000 (77%)] Loss: 14738.471680\n",
      "Train Epoch: 12 [174720/225000 (78%)] Loss: 14707.908203\n",
      "Train Epoch: 12 [176128/225000 (78%)] Loss: 15151.133789\n",
      "Train Epoch: 12 [177536/225000 (79%)] Loss: 15468.008789\n",
      "Train Epoch: 12 [178944/225000 (80%)] Loss: 15235.605469\n",
      "Train Epoch: 12 [180352/225000 (80%)] Loss: 15105.896484\n",
      "Train Epoch: 12 [181760/225000 (81%)] Loss: 14806.655273\n",
      "Train Epoch: 12 [183168/225000 (81%)] Loss: 14961.572266\n",
      "Train Epoch: 12 [184576/225000 (82%)] Loss: 15379.998047\n",
      "Train Epoch: 12 [185984/225000 (83%)] Loss: 15054.255859\n",
      "Train Epoch: 12 [187392/225000 (83%)] Loss: 15062.319336\n",
      "Train Epoch: 12 [188800/225000 (84%)] Loss: 15030.605469\n",
      "Train Epoch: 12 [190208/225000 (85%)] Loss: 15498.944336\n",
      "Train Epoch: 12 [191616/225000 (85%)] Loss: 15149.716797\n",
      "Train Epoch: 12 [193024/225000 (86%)] Loss: 14920.955078\n",
      "Train Epoch: 12 [194432/225000 (86%)] Loss: 14781.993164\n",
      "Train Epoch: 12 [195840/225000 (87%)] Loss: 14915.464844\n",
      "Train Epoch: 12 [197248/225000 (88%)] Loss: 14853.348633\n",
      "Train Epoch: 12 [198656/225000 (88%)] Loss: 14992.400391\n",
      "Train Epoch: 12 [200064/225000 (89%)] Loss: 14960.436523\n",
      "Train Epoch: 12 [201472/225000 (90%)] Loss: 15497.459961\n",
      "Train Epoch: 12 [202880/225000 (90%)] Loss: 15264.379883\n",
      "Train Epoch: 12 [204288/225000 (91%)] Loss: 14949.662109\n",
      "Train Epoch: 12 [205696/225000 (91%)] Loss: 15005.954102\n",
      "Train Epoch: 12 [207104/225000 (92%)] Loss: 14581.729492\n",
      "Train Epoch: 12 [208512/225000 (93%)] Loss: 15310.323242\n",
      "Train Epoch: 12 [209920/225000 (93%)] Loss: 14629.276367\n",
      "Train Epoch: 12 [211328/225000 (94%)] Loss: 14927.546875\n",
      "Train Epoch: 12 [212736/225000 (95%)] Loss: 15552.265625\n",
      "Train Epoch: 12 [214144/225000 (95%)] Loss: 14924.513672\n",
      "Train Epoch: 12 [215552/225000 (96%)] Loss: 15535.213867\n",
      "Train Epoch: 12 [216960/225000 (96%)] Loss: 15180.116211\n",
      "Train Epoch: 12 [218368/225000 (97%)] Loss: 15167.189453\n",
      "Train Epoch: 12 [219776/225000 (98%)] Loss: 14752.751953\n",
      "Train Epoch: 12 [221184/225000 (98%)] Loss: 14696.668945\n",
      "Train Epoch: 12 [222592/225000 (99%)] Loss: 15229.853516\n",
      "Train Epoch: 12 [224000/225000 (100%)] Loss: 15106.020508\n",
      "    epoch          : 12\n",
      "    loss           : 15105.684072587814\n",
      "    val_loss       : 15103.037004065149\n",
      "Train Epoch: 13 [128/225000 (0%)] Loss: 15513.526367\n",
      "Train Epoch: 13 [1536/225000 (1%)] Loss: 14950.120117\n",
      "Train Epoch: 13 [2944/225000 (1%)] Loss: 15369.281250\n",
      "Train Epoch: 13 [4352/225000 (2%)] Loss: 15025.184570\n",
      "Train Epoch: 13 [5760/225000 (3%)] Loss: 15003.340820\n",
      "Train Epoch: 13 [7168/225000 (3%)] Loss: 15145.746094\n",
      "Train Epoch: 13 [8576/225000 (4%)] Loss: 14429.425781\n",
      "Train Epoch: 13 [9984/225000 (4%)] Loss: 15114.660156\n",
      "Train Epoch: 13 [11392/225000 (5%)] Loss: 15247.716797\n",
      "Train Epoch: 13 [12800/225000 (6%)] Loss: 15141.449219\n",
      "Train Epoch: 13 [14208/225000 (6%)] Loss: 15018.166016\n",
      "Train Epoch: 13 [15616/225000 (7%)] Loss: 15240.653320\n",
      "Train Epoch: 13 [17024/225000 (8%)] Loss: 15328.542969\n",
      "Train Epoch: 13 [18432/225000 (8%)] Loss: 14500.089844\n",
      "Train Epoch: 13 [19840/225000 (9%)] Loss: 15383.014648\n",
      "Train Epoch: 13 [21248/225000 (9%)] Loss: 15478.476562\n",
      "Train Epoch: 13 [22656/225000 (10%)] Loss: 15181.615234\n",
      "Train Epoch: 13 [24064/225000 (11%)] Loss: 15338.203125\n",
      "Train Epoch: 13 [25472/225000 (11%)] Loss: 15108.230469\n",
      "Train Epoch: 13 [26880/225000 (12%)] Loss: 15538.184570\n",
      "Train Epoch: 13 [28288/225000 (13%)] Loss: 14509.636719\n",
      "Train Epoch: 13 [29696/225000 (13%)] Loss: 15139.250977\n",
      "Train Epoch: 13 [31104/225000 (14%)] Loss: 15265.282227\n",
      "Train Epoch: 13 [32512/225000 (14%)] Loss: 15217.441406\n",
      "Train Epoch: 13 [33920/225000 (15%)] Loss: 14995.080078\n",
      "Train Epoch: 13 [35328/225000 (16%)] Loss: 15274.975586\n",
      "Train Epoch: 13 [36736/225000 (16%)] Loss: 15478.294922\n",
      "Train Epoch: 13 [38144/225000 (17%)] Loss: 14570.791992\n",
      "Train Epoch: 13 [39552/225000 (18%)] Loss: 14757.259766\n",
      "Train Epoch: 13 [40960/225000 (18%)] Loss: 15080.284180\n",
      "Train Epoch: 13 [42368/225000 (19%)] Loss: 14837.561523\n",
      "Train Epoch: 13 [43776/225000 (19%)] Loss: 14830.872070\n",
      "Train Epoch: 13 [45184/225000 (20%)] Loss: 14899.122070\n",
      "Train Epoch: 13 [46592/225000 (21%)] Loss: 15074.074219\n",
      "Train Epoch: 13 [48000/225000 (21%)] Loss: 15020.580078\n",
      "Train Epoch: 13 [49408/225000 (22%)] Loss: 14925.011719\n",
      "Train Epoch: 13 [50816/225000 (23%)] Loss: 14943.760742\n",
      "Train Epoch: 13 [52224/225000 (23%)] Loss: 15219.497070\n",
      "Train Epoch: 13 [53632/225000 (24%)] Loss: 14954.998047\n",
      "Train Epoch: 13 [55040/225000 (24%)] Loss: 15328.125977\n",
      "Train Epoch: 13 [56448/225000 (25%)] Loss: 14949.816406\n",
      "Train Epoch: 13 [57856/225000 (26%)] Loss: 15168.690430\n",
      "Train Epoch: 13 [59264/225000 (26%)] Loss: 14561.565430\n",
      "Train Epoch: 13 [60672/225000 (27%)] Loss: 15449.797852\n",
      "Train Epoch: 13 [62080/225000 (28%)] Loss: 14993.813477\n",
      "Train Epoch: 13 [63488/225000 (28%)] Loss: 14987.388672\n",
      "Train Epoch: 13 [64896/225000 (29%)] Loss: 15117.101562\n",
      "Train Epoch: 13 [66304/225000 (29%)] Loss: 15132.179688\n",
      "Train Epoch: 13 [67712/225000 (30%)] Loss: 15289.563477\n",
      "Train Epoch: 13 [69120/225000 (31%)] Loss: 15137.859375\n",
      "Train Epoch: 13 [70528/225000 (31%)] Loss: 15174.443359\n",
      "Train Epoch: 13 [71936/225000 (32%)] Loss: 15117.111328\n",
      "Train Epoch: 13 [73344/225000 (33%)] Loss: 15267.235352\n",
      "Train Epoch: 13 [74752/225000 (33%)] Loss: 15507.259766\n",
      "Train Epoch: 13 [76160/225000 (34%)] Loss: 15678.983398\n",
      "Train Epoch: 13 [77568/225000 (34%)] Loss: 14882.087891\n",
      "Train Epoch: 13 [78976/225000 (35%)] Loss: 16101.624023\n",
      "Train Epoch: 13 [80384/225000 (36%)] Loss: 15437.711914\n",
      "Train Epoch: 13 [81792/225000 (36%)] Loss: 15080.792969\n",
      "Train Epoch: 13 [83200/225000 (37%)] Loss: 15017.650391\n",
      "Train Epoch: 13 [84608/225000 (38%)] Loss: 14899.491211\n",
      "Train Epoch: 13 [86016/225000 (38%)] Loss: 15023.463867\n",
      "Train Epoch: 13 [87424/225000 (39%)] Loss: 15224.582031\n",
      "Train Epoch: 13 [88832/225000 (39%)] Loss: 14965.096680\n",
      "Train Epoch: 13 [90240/225000 (40%)] Loss: 15358.309570\n",
      "Train Epoch: 13 [91648/225000 (41%)] Loss: 15225.124023\n",
      "Train Epoch: 13 [93056/225000 (41%)] Loss: 15372.206055\n",
      "Train Epoch: 13 [94464/225000 (42%)] Loss: 15577.097656\n",
      "Train Epoch: 13 [95872/225000 (43%)] Loss: 15247.040039\n",
      "Train Epoch: 13 [97280/225000 (43%)] Loss: 14647.702148\n",
      "Train Epoch: 13 [98688/225000 (44%)] Loss: 15181.019531\n",
      "Train Epoch: 13 [100096/225000 (44%)] Loss: 14741.690430\n",
      "Train Epoch: 13 [101504/225000 (45%)] Loss: 14893.103516\n",
      "Train Epoch: 13 [102912/225000 (46%)] Loss: 15144.592773\n",
      "Train Epoch: 13 [104320/225000 (46%)] Loss: 15161.807617\n",
      "Train Epoch: 13 [105728/225000 (47%)] Loss: 15202.541992\n",
      "Train Epoch: 13 [107136/225000 (48%)] Loss: 15779.133789\n",
      "Train Epoch: 13 [108544/225000 (48%)] Loss: 15179.921875\n",
      "Train Epoch: 13 [109952/225000 (49%)] Loss: 14867.891602\n",
      "Train Epoch: 13 [111360/225000 (49%)] Loss: 15596.818359\n",
      "Train Epoch: 13 [112768/225000 (50%)] Loss: 14736.102539\n",
      "Train Epoch: 13 [114176/225000 (51%)] Loss: 14879.717773\n",
      "Train Epoch: 13 [115584/225000 (51%)] Loss: 15241.137695\n",
      "Train Epoch: 13 [116992/225000 (52%)] Loss: 15183.635742\n",
      "Train Epoch: 13 [118400/225000 (53%)] Loss: 14940.935547\n",
      "Train Epoch: 13 [119808/225000 (53%)] Loss: 14986.787109\n",
      "Train Epoch: 13 [121216/225000 (54%)] Loss: 15070.348633\n",
      "Train Epoch: 13 [122624/225000 (54%)] Loss: 15051.751953\n",
      "Train Epoch: 13 [124032/225000 (55%)] Loss: 14888.924805\n",
      "Train Epoch: 13 [125440/225000 (56%)] Loss: 14794.399414\n",
      "Train Epoch: 13 [126848/225000 (56%)] Loss: 14984.250977\n",
      "Train Epoch: 13 [128256/225000 (57%)] Loss: 15137.713867\n",
      "Train Epoch: 13 [129664/225000 (58%)] Loss: 15223.462891\n",
      "Train Epoch: 13 [131072/225000 (58%)] Loss: 15347.822266\n",
      "Train Epoch: 13 [132480/225000 (59%)] Loss: 14868.483398\n",
      "Train Epoch: 13 [133888/225000 (60%)] Loss: 15272.423828\n",
      "Train Epoch: 13 [135296/225000 (60%)] Loss: 15131.473633\n",
      "Train Epoch: 13 [136704/225000 (61%)] Loss: 14997.629883\n",
      "Train Epoch: 13 [138112/225000 (61%)] Loss: 15052.619141\n",
      "Train Epoch: 13 [139520/225000 (62%)] Loss: 14892.491211\n",
      "Train Epoch: 13 [140928/225000 (63%)] Loss: 15422.724609\n",
      "Train Epoch: 13 [142336/225000 (63%)] Loss: 15081.372070\n",
      "Train Epoch: 13 [143744/225000 (64%)] Loss: 14885.632812\n",
      "Train Epoch: 13 [145152/225000 (65%)] Loss: 15316.195312\n",
      "Train Epoch: 13 [146560/225000 (65%)] Loss: 15474.171875\n",
      "Train Epoch: 13 [147968/225000 (66%)] Loss: 15421.052734\n",
      "Train Epoch: 13 [149376/225000 (66%)] Loss: 15069.147461\n",
      "Train Epoch: 13 [150784/225000 (67%)] Loss: 15082.695312\n",
      "Train Epoch: 13 [152192/225000 (68%)] Loss: 15539.678711\n",
      "Train Epoch: 13 [153600/225000 (68%)] Loss: 14619.185547\n",
      "Train Epoch: 13 [155008/225000 (69%)] Loss: 14661.290039\n",
      "Train Epoch: 13 [156416/225000 (70%)] Loss: 15147.420898\n",
      "Train Epoch: 13 [157824/225000 (70%)] Loss: 15329.724609\n",
      "Train Epoch: 13 [159232/225000 (71%)] Loss: 14950.033203\n",
      "Train Epoch: 13 [160640/225000 (71%)] Loss: 15229.746094\n",
      "Train Epoch: 13 [162048/225000 (72%)] Loss: 15153.541016\n",
      "Train Epoch: 13 [163456/225000 (73%)] Loss: 14769.977539\n",
      "Train Epoch: 13 [164864/225000 (73%)] Loss: 15437.244141\n",
      "Train Epoch: 13 [166272/225000 (74%)] Loss: 15274.574219\n",
      "Train Epoch: 13 [167680/225000 (75%)] Loss: 14804.632812\n",
      "Train Epoch: 13 [169088/225000 (75%)] Loss: 14612.711914\n",
      "Train Epoch: 13 [170496/225000 (76%)] Loss: 14682.203125\n",
      "Train Epoch: 13 [171904/225000 (76%)] Loss: 15355.455078\n",
      "Train Epoch: 13 [173312/225000 (77%)] Loss: 15682.725586\n",
      "Train Epoch: 13 [174720/225000 (78%)] Loss: 14573.704102\n",
      "Train Epoch: 13 [176128/225000 (78%)] Loss: 15240.959961\n",
      "Train Epoch: 13 [177536/225000 (79%)] Loss: 15448.871094\n",
      "Train Epoch: 13 [178944/225000 (80%)] Loss: 15030.704102\n",
      "Train Epoch: 13 [180352/225000 (80%)] Loss: 14953.276367\n",
      "Train Epoch: 13 [181760/225000 (81%)] Loss: 15300.799805\n",
      "Train Epoch: 13 [183168/225000 (81%)] Loss: 15102.500977\n",
      "Train Epoch: 13 [184576/225000 (82%)] Loss: 14928.932617\n",
      "Train Epoch: 13 [185984/225000 (83%)] Loss: 14772.136719\n",
      "Train Epoch: 13 [187392/225000 (83%)] Loss: 15239.585938\n",
      "Train Epoch: 13 [188800/225000 (84%)] Loss: 14719.453125\n",
      "Train Epoch: 13 [190208/225000 (85%)] Loss: 14961.366211\n",
      "Train Epoch: 13 [191616/225000 (85%)] Loss: 14864.665039\n",
      "Train Epoch: 13 [193024/225000 (86%)] Loss: 15256.283203\n",
      "Train Epoch: 13 [194432/225000 (86%)] Loss: 15072.171875\n",
      "Train Epoch: 13 [195840/225000 (87%)] Loss: 15204.283203\n",
      "Train Epoch: 13 [197248/225000 (88%)] Loss: 14769.204102\n",
      "Train Epoch: 13 [198656/225000 (88%)] Loss: 14947.138672\n",
      "Train Epoch: 13 [200064/225000 (89%)] Loss: 14766.408203\n",
      "Train Epoch: 13 [201472/225000 (90%)] Loss: 14703.913086\n",
      "Train Epoch: 13 [202880/225000 (90%)] Loss: 15066.866211\n",
      "Train Epoch: 13 [204288/225000 (91%)] Loss: 14997.769531\n",
      "Train Epoch: 13 [205696/225000 (91%)] Loss: 14590.152344\n",
      "Train Epoch: 13 [207104/225000 (92%)] Loss: 15456.214844\n",
      "Train Epoch: 13 [208512/225000 (93%)] Loss: 14920.454102\n",
      "Train Epoch: 13 [209920/225000 (93%)] Loss: 15255.115234\n",
      "Train Epoch: 13 [211328/225000 (94%)] Loss: 15668.959961\n",
      "Train Epoch: 13 [212736/225000 (95%)] Loss: 14949.434570\n",
      "Train Epoch: 13 [214144/225000 (95%)] Loss: 15560.284180\n",
      "Train Epoch: 13 [215552/225000 (96%)] Loss: 15021.916016\n",
      "Train Epoch: 13 [216960/225000 (96%)] Loss: 15056.519531\n",
      "Train Epoch: 13 [218368/225000 (97%)] Loss: 15466.283203\n",
      "Train Epoch: 13 [219776/225000 (98%)] Loss: 15097.733398\n",
      "Train Epoch: 13 [221184/225000 (98%)] Loss: 14756.168945\n",
      "Train Epoch: 13 [222592/225000 (99%)] Loss: 14597.656250\n",
      "Train Epoch: 13 [224000/225000 (100%)] Loss: 15102.586914\n",
      "    epoch          : 13\n",
      "    loss           : 15111.44621684798\n",
      "    val_loss       : 15080.452927403\n",
      "Train Epoch: 14 [128/225000 (0%)] Loss: 15098.082031\n",
      "Train Epoch: 14 [1536/225000 (1%)] Loss: 15018.015625\n",
      "Train Epoch: 14 [2944/225000 (1%)] Loss: 15162.300781\n",
      "Train Epoch: 14 [4352/225000 (2%)] Loss: 14644.776367\n",
      "Train Epoch: 14 [5760/225000 (3%)] Loss: 14778.704102\n",
      "Train Epoch: 14 [7168/225000 (3%)] Loss: 15105.741211\n",
      "Train Epoch: 14 [8576/225000 (4%)] Loss: 14602.247070\n",
      "Train Epoch: 14 [9984/225000 (4%)] Loss: 15352.665039\n",
      "Train Epoch: 14 [11392/225000 (5%)] Loss: 15141.371094\n",
      "Train Epoch: 14 [12800/225000 (6%)] Loss: 14981.309570\n",
      "Train Epoch: 14 [14208/225000 (6%)] Loss: 15109.682617\n",
      "Train Epoch: 14 [15616/225000 (7%)] Loss: 15453.317383\n",
      "Train Epoch: 14 [17024/225000 (8%)] Loss: 15076.955078\n",
      "Train Epoch: 14 [18432/225000 (8%)] Loss: 15016.211914\n",
      "Train Epoch: 14 [19840/225000 (9%)] Loss: 15330.274414\n",
      "Train Epoch: 14 [21248/225000 (9%)] Loss: 15768.426758\n",
      "Train Epoch: 14 [22656/225000 (10%)] Loss: 15413.115234\n",
      "Train Epoch: 14 [24064/225000 (11%)] Loss: 15186.997070\n",
      "Train Epoch: 14 [25472/225000 (11%)] Loss: 14574.550781\n",
      "Train Epoch: 14 [26880/225000 (12%)] Loss: 15132.830078\n",
      "Train Epoch: 14 [28288/225000 (13%)] Loss: 15013.954102\n",
      "Train Epoch: 14 [29696/225000 (13%)] Loss: 15422.685547\n",
      "Train Epoch: 14 [31104/225000 (14%)] Loss: 15375.008789\n",
      "Train Epoch: 14 [32512/225000 (14%)] Loss: 15024.193359\n",
      "Train Epoch: 14 [33920/225000 (15%)] Loss: 15362.198242\n",
      "Train Epoch: 14 [35328/225000 (16%)] Loss: 15231.727539\n",
      "Train Epoch: 14 [36736/225000 (16%)] Loss: 14552.536133\n",
      "Train Epoch: 14 [38144/225000 (17%)] Loss: 15439.363281\n",
      "Train Epoch: 14 [39552/225000 (18%)] Loss: 15616.341797\n",
      "Train Epoch: 14 [40960/225000 (18%)] Loss: 14938.467773\n",
      "Train Epoch: 14 [42368/225000 (19%)] Loss: 14887.147461\n",
      "Train Epoch: 14 [43776/225000 (19%)] Loss: 14992.933594\n",
      "Train Epoch: 14 [45184/225000 (20%)] Loss: 14898.116211\n",
      "Train Epoch: 14 [46592/225000 (21%)] Loss: 14993.870117\n",
      "Train Epoch: 14 [48000/225000 (21%)] Loss: 15398.004883\n",
      "Train Epoch: 14 [49408/225000 (22%)] Loss: 14950.272461\n",
      "Train Epoch: 14 [50816/225000 (23%)] Loss: 15260.512695\n",
      "Train Epoch: 14 [52224/225000 (23%)] Loss: 15177.757812\n",
      "Train Epoch: 14 [53632/225000 (24%)] Loss: 15290.283203\n",
      "Train Epoch: 14 [55040/225000 (24%)] Loss: 15427.401367\n",
      "Train Epoch: 14 [56448/225000 (25%)] Loss: 14736.421875\n",
      "Train Epoch: 14 [57856/225000 (26%)] Loss: 15232.348633\n",
      "Train Epoch: 14 [59264/225000 (26%)] Loss: 15278.957031\n",
      "Train Epoch: 14 [60672/225000 (27%)] Loss: 15187.703125\n",
      "Train Epoch: 14 [62080/225000 (28%)] Loss: 15138.202148\n",
      "Train Epoch: 14 [63488/225000 (28%)] Loss: 15361.151367\n",
      "Train Epoch: 14 [64896/225000 (29%)] Loss: 15449.603516\n",
      "Train Epoch: 14 [66304/225000 (29%)] Loss: 15270.770508\n",
      "Train Epoch: 14 [67712/225000 (30%)] Loss: 14935.625977\n",
      "Train Epoch: 14 [69120/225000 (31%)] Loss: 14916.021484\n",
      "Train Epoch: 14 [70528/225000 (31%)] Loss: 15193.421875\n",
      "Train Epoch: 14 [71936/225000 (32%)] Loss: 15182.778320\n",
      "Train Epoch: 14 [73344/225000 (33%)] Loss: 15441.529297\n",
      "Train Epoch: 14 [74752/225000 (33%)] Loss: 15608.973633\n",
      "Train Epoch: 14 [76160/225000 (34%)] Loss: 15265.076172\n",
      "Train Epoch: 14 [77568/225000 (34%)] Loss: 15303.703125\n",
      "Train Epoch: 14 [78976/225000 (35%)] Loss: 14721.963867\n",
      "Train Epoch: 14 [80384/225000 (36%)] Loss: 14562.387695\n",
      "Train Epoch: 14 [81792/225000 (36%)] Loss: 15001.901367\n",
      "Train Epoch: 14 [83200/225000 (37%)] Loss: 15102.772461\n",
      "Train Epoch: 14 [84608/225000 (38%)] Loss: 15508.355469\n",
      "Train Epoch: 14 [86016/225000 (38%)] Loss: 15259.798828\n",
      "Train Epoch: 14 [87424/225000 (39%)] Loss: 15341.532227\n",
      "Train Epoch: 14 [88832/225000 (39%)] Loss: 15483.204102\n",
      "Train Epoch: 14 [90240/225000 (40%)] Loss: 15051.369141\n",
      "Train Epoch: 14 [91648/225000 (41%)] Loss: 15638.919922\n",
      "Train Epoch: 14 [93056/225000 (41%)] Loss: 15115.353516\n",
      "Train Epoch: 14 [94464/225000 (42%)] Loss: 15369.822266\n",
      "Train Epoch: 14 [95872/225000 (43%)] Loss: 15080.792969\n",
      "Train Epoch: 14 [97280/225000 (43%)] Loss: 14805.786133\n",
      "Train Epoch: 14 [98688/225000 (44%)] Loss: 15225.004883\n",
      "Train Epoch: 14 [100096/225000 (44%)] Loss: 14786.026367\n",
      "Train Epoch: 14 [101504/225000 (45%)] Loss: 14967.245117\n",
      "Train Epoch: 14 [102912/225000 (46%)] Loss: 14664.332031\n",
      "Train Epoch: 14 [104320/225000 (46%)] Loss: 15286.159180\n",
      "Train Epoch: 14 [105728/225000 (47%)] Loss: 15730.655273\n",
      "Train Epoch: 14 [107136/225000 (48%)] Loss: 15126.632812\n",
      "Train Epoch: 14 [108544/225000 (48%)] Loss: 15214.875000\n",
      "Train Epoch: 14 [109952/225000 (49%)] Loss: 15162.586914\n",
      "Train Epoch: 14 [111360/225000 (49%)] Loss: 15378.452148\n",
      "Train Epoch: 14 [112768/225000 (50%)] Loss: 15183.457031\n",
      "Train Epoch: 14 [114176/225000 (51%)] Loss: 15302.519531\n",
      "Train Epoch: 14 [115584/225000 (51%)] Loss: 15463.058594\n",
      "Train Epoch: 14 [116992/225000 (52%)] Loss: 15096.649414\n",
      "Train Epoch: 14 [118400/225000 (53%)] Loss: 15244.072266\n",
      "Train Epoch: 14 [119808/225000 (53%)] Loss: 15337.123047\n",
      "Train Epoch: 14 [121216/225000 (54%)] Loss: 15011.831055\n",
      "Train Epoch: 14 [122624/225000 (54%)] Loss: 14830.412109\n",
      "Train Epoch: 14 [124032/225000 (55%)] Loss: 14894.155273\n",
      "Train Epoch: 14 [125440/225000 (56%)] Loss: 15019.593750\n",
      "Train Epoch: 14 [126848/225000 (56%)] Loss: 15629.709961\n",
      "Train Epoch: 14 [128256/225000 (57%)] Loss: 15100.244141\n",
      "Train Epoch: 14 [129664/225000 (58%)] Loss: 15020.170898\n",
      "Train Epoch: 14 [131072/225000 (58%)] Loss: 15212.131836\n",
      "Train Epoch: 14 [132480/225000 (59%)] Loss: 14702.745117\n",
      "Train Epoch: 14 [133888/225000 (60%)] Loss: 14881.470703\n",
      "Train Epoch: 14 [135296/225000 (60%)] Loss: 14896.136719\n",
      "Train Epoch: 14 [136704/225000 (61%)] Loss: 15159.385742\n",
      "Train Epoch: 14 [138112/225000 (61%)] Loss: 14747.565430\n",
      "Train Epoch: 14 [139520/225000 (62%)] Loss: 14914.117188\n",
      "Train Epoch: 14 [140928/225000 (63%)] Loss: 14978.058594\n",
      "Train Epoch: 14 [142336/225000 (63%)] Loss: 14789.598633\n",
      "Train Epoch: 14 [143744/225000 (64%)] Loss: 14961.473633\n",
      "Train Epoch: 14 [145152/225000 (65%)] Loss: 15089.885742\n",
      "Train Epoch: 14 [146560/225000 (65%)] Loss: 15213.542969\n",
      "Train Epoch: 14 [147968/225000 (66%)] Loss: 14839.027344\n",
      "Train Epoch: 14 [149376/225000 (66%)] Loss: 15056.491211\n",
      "Train Epoch: 14 [150784/225000 (67%)] Loss: 14999.263672\n",
      "Train Epoch: 14 [152192/225000 (68%)] Loss: 15212.804688\n",
      "Train Epoch: 14 [153600/225000 (68%)] Loss: 14929.608398\n",
      "Train Epoch: 14 [155008/225000 (69%)] Loss: 15122.402344\n",
      "Train Epoch: 14 [156416/225000 (70%)] Loss: 15012.098633\n",
      "Train Epoch: 14 [157824/225000 (70%)] Loss: 15203.352539\n",
      "Train Epoch: 14 [159232/225000 (71%)] Loss: 15196.321289\n",
      "Train Epoch: 14 [160640/225000 (71%)] Loss: 14885.893555\n",
      "Train Epoch: 14 [162048/225000 (72%)] Loss: 14990.516602\n",
      "Train Epoch: 14 [163456/225000 (73%)] Loss: 14834.542969\n",
      "Train Epoch: 14 [164864/225000 (73%)] Loss: 15274.124023\n",
      "Train Epoch: 14 [166272/225000 (74%)] Loss: 14838.798828\n",
      "Train Epoch: 14 [167680/225000 (75%)] Loss: 15234.779297\n",
      "Train Epoch: 14 [169088/225000 (75%)] Loss: 14691.837891\n",
      "Train Epoch: 14 [170496/225000 (76%)] Loss: 15226.306641\n",
      "Train Epoch: 14 [171904/225000 (76%)] Loss: 15452.719727\n",
      "Train Epoch: 14 [173312/225000 (77%)] Loss: 15145.300781\n",
      "Train Epoch: 14 [174720/225000 (78%)] Loss: 15124.836914\n",
      "Train Epoch: 14 [176128/225000 (78%)] Loss: 15133.065430\n",
      "Train Epoch: 14 [177536/225000 (79%)] Loss: 14969.941406\n",
      "Train Epoch: 14 [178944/225000 (80%)] Loss: 15062.620117\n",
      "Train Epoch: 14 [180352/225000 (80%)] Loss: 14881.873047\n",
      "Train Epoch: 14 [181760/225000 (81%)] Loss: 15640.731445\n",
      "Train Epoch: 14 [183168/225000 (81%)] Loss: 15076.826172\n",
      "Train Epoch: 14 [184576/225000 (82%)] Loss: 15111.766602\n",
      "Train Epoch: 14 [185984/225000 (83%)] Loss: 14681.382812\n",
      "Train Epoch: 14 [187392/225000 (83%)] Loss: 14811.223633\n",
      "Train Epoch: 14 [188800/225000 (84%)] Loss: 15035.333984\n",
      "Train Epoch: 14 [190208/225000 (85%)] Loss: 14470.614258\n",
      "Train Epoch: 14 [191616/225000 (85%)] Loss: 14832.214844\n",
      "Train Epoch: 14 [193024/225000 (86%)] Loss: 15219.157227\n",
      "Train Epoch: 14 [194432/225000 (86%)] Loss: 15376.392578\n",
      "Train Epoch: 14 [195840/225000 (87%)] Loss: 14867.936523\n",
      "Train Epoch: 14 [197248/225000 (88%)] Loss: 15012.791016\n",
      "Train Epoch: 14 [198656/225000 (88%)] Loss: 15146.993164\n",
      "Train Epoch: 14 [200064/225000 (89%)] Loss: 15014.963867\n",
      "Train Epoch: 14 [201472/225000 (90%)] Loss: 14970.131836\n",
      "Train Epoch: 14 [202880/225000 (90%)] Loss: 15492.287109\n",
      "Train Epoch: 14 [204288/225000 (91%)] Loss: 15145.412109\n",
      "Train Epoch: 14 [205696/225000 (91%)] Loss: 14440.316406\n",
      "Train Epoch: 14 [207104/225000 (92%)] Loss: 14991.474609\n",
      "Train Epoch: 14 [208512/225000 (93%)] Loss: 14741.563477\n",
      "Train Epoch: 14 [209920/225000 (93%)] Loss: 15025.000000\n",
      "Train Epoch: 14 [211328/225000 (94%)] Loss: 14978.241211\n",
      "Train Epoch: 14 [212736/225000 (95%)] Loss: 15143.762695\n",
      "Train Epoch: 14 [214144/225000 (95%)] Loss: 14763.354492\n",
      "Train Epoch: 14 [215552/225000 (96%)] Loss: 15318.489258\n",
      "Train Epoch: 14 [216960/225000 (96%)] Loss: 15000.978516\n",
      "Train Epoch: 14 [218368/225000 (97%)] Loss: 15147.230469\n",
      "Train Epoch: 14 [219776/225000 (98%)] Loss: 14572.887695\n",
      "Train Epoch: 14 [221184/225000 (98%)] Loss: 14825.176758\n",
      "Train Epoch: 14 [222592/225000 (99%)] Loss: 14696.236328\n",
      "Train Epoch: 14 [224000/225000 (100%)] Loss: 14997.641602\n",
      "    epoch          : 14\n",
      "    loss           : 15106.143033631968\n",
      "    val_loss       : 15111.517181996483\n",
      "Train Epoch: 15 [128/225000 (0%)] Loss: 15184.752930\n",
      "Train Epoch: 15 [1536/225000 (1%)] Loss: 15300.135742\n",
      "Train Epoch: 15 [2944/225000 (1%)] Loss: 14466.283203\n",
      "Train Epoch: 15 [4352/225000 (2%)] Loss: 15342.542969\n",
      "Train Epoch: 15 [5760/225000 (3%)] Loss: 14993.066406\n",
      "Train Epoch: 15 [7168/225000 (3%)] Loss: 14993.354492\n",
      "Train Epoch: 15 [8576/225000 (4%)] Loss: 15093.408203\n",
      "Train Epoch: 15 [9984/225000 (4%)] Loss: 15690.065430\n",
      "Train Epoch: 15 [11392/225000 (5%)] Loss: 14968.410156\n",
      "Train Epoch: 15 [12800/225000 (6%)] Loss: 14758.664062\n",
      "Train Epoch: 15 [14208/225000 (6%)] Loss: 15262.670898\n",
      "Train Epoch: 15 [15616/225000 (7%)] Loss: 15023.671875\n",
      "Train Epoch: 15 [17024/225000 (8%)] Loss: 15002.715820\n",
      "Train Epoch: 15 [18432/225000 (8%)] Loss: 14788.106445\n",
      "Train Epoch: 15 [19840/225000 (9%)] Loss: 15008.787109\n",
      "Train Epoch: 15 [21248/225000 (9%)] Loss: 15300.886719\n",
      "Train Epoch: 15 [22656/225000 (10%)] Loss: 15009.355469\n",
      "Train Epoch: 15 [24064/225000 (11%)] Loss: 14856.982422\n",
      "Train Epoch: 15 [25472/225000 (11%)] Loss: 15064.596680\n",
      "Train Epoch: 15 [26880/225000 (12%)] Loss: 15332.142578\n",
      "Train Epoch: 15 [28288/225000 (13%)] Loss: 14812.702148\n",
      "Train Epoch: 15 [29696/225000 (13%)] Loss: 15348.527344\n",
      "Train Epoch: 15 [31104/225000 (14%)] Loss: 15258.244141\n",
      "Train Epoch: 15 [32512/225000 (14%)] Loss: 15325.300781\n",
      "Train Epoch: 15 [33920/225000 (15%)] Loss: 14840.300781\n",
      "Train Epoch: 15 [35328/225000 (16%)] Loss: 15228.338867\n",
      "Train Epoch: 15 [36736/225000 (16%)] Loss: 15016.509766\n",
      "Train Epoch: 15 [38144/225000 (17%)] Loss: 14605.158203\n",
      "Train Epoch: 15 [39552/225000 (18%)] Loss: 14816.487305\n",
      "Train Epoch: 15 [40960/225000 (18%)] Loss: 15162.283203\n",
      "Train Epoch: 15 [42368/225000 (19%)] Loss: 14671.161133\n",
      "Train Epoch: 15 [43776/225000 (19%)] Loss: 15217.307617\n",
      "Train Epoch: 15 [45184/225000 (20%)] Loss: 15459.227539\n",
      "Train Epoch: 15 [46592/225000 (21%)] Loss: 15198.479492\n",
      "Train Epoch: 15 [48000/225000 (21%)] Loss: 15635.170898\n",
      "Train Epoch: 15 [49408/225000 (22%)] Loss: 15244.137695\n",
      "Train Epoch: 15 [50816/225000 (23%)] Loss: 14634.799805\n",
      "Train Epoch: 15 [52224/225000 (23%)] Loss: 14918.195312\n",
      "Train Epoch: 15 [53632/225000 (24%)] Loss: 15017.098633\n",
      "Train Epoch: 15 [55040/225000 (24%)] Loss: 15071.564453\n",
      "Train Epoch: 15 [56448/225000 (25%)] Loss: 15004.462891\n",
      "Train Epoch: 15 [57856/225000 (26%)] Loss: 15073.371094\n",
      "Train Epoch: 15 [59264/225000 (26%)] Loss: 15429.091797\n",
      "Train Epoch: 15 [60672/225000 (27%)] Loss: 15085.147461\n",
      "Train Epoch: 15 [62080/225000 (28%)] Loss: 15232.041016\n",
      "Train Epoch: 15 [63488/225000 (28%)] Loss: 15130.604492\n",
      "Train Epoch: 15 [64896/225000 (29%)] Loss: 14806.127930\n",
      "Train Epoch: 15 [66304/225000 (29%)] Loss: 15045.944336\n",
      "Train Epoch: 15 [67712/225000 (30%)] Loss: 14674.613281\n",
      "Train Epoch: 15 [69120/225000 (31%)] Loss: 15307.541016\n",
      "Train Epoch: 15 [70528/225000 (31%)] Loss: 14751.116211\n",
      "Train Epoch: 15 [71936/225000 (32%)] Loss: 14873.189453\n",
      "Train Epoch: 15 [73344/225000 (33%)] Loss: 15131.161133\n",
      "Train Epoch: 15 [74752/225000 (33%)] Loss: 15542.089844\n",
      "Train Epoch: 15 [76160/225000 (34%)] Loss: 14793.437500\n",
      "Train Epoch: 15 [77568/225000 (34%)] Loss: 15067.662109\n",
      "Train Epoch: 15 [78976/225000 (35%)] Loss: 14916.935547\n",
      "Train Epoch: 15 [80384/225000 (36%)] Loss: 14699.416992\n",
      "Train Epoch: 15 [81792/225000 (36%)] Loss: 15173.067383\n",
      "Train Epoch: 15 [83200/225000 (37%)] Loss: 14685.257812\n",
      "Train Epoch: 15 [84608/225000 (38%)] Loss: 15703.662109\n",
      "Train Epoch: 15 [86016/225000 (38%)] Loss: 15376.759766\n",
      "Train Epoch: 15 [87424/225000 (39%)] Loss: 14957.380859\n",
      "Train Epoch: 15 [88832/225000 (39%)] Loss: 14980.817383\n",
      "Train Epoch: 15 [90240/225000 (40%)] Loss: 15100.256836\n",
      "Train Epoch: 15 [91648/225000 (41%)] Loss: 14815.729492\n",
      "Train Epoch: 15 [93056/225000 (41%)] Loss: 14802.001953\n",
      "Train Epoch: 15 [94464/225000 (42%)] Loss: 14775.602539\n",
      "Train Epoch: 15 [95872/225000 (43%)] Loss: 14796.849609\n",
      "Train Epoch: 15 [97280/225000 (43%)] Loss: 15431.207031\n",
      "Train Epoch: 15 [98688/225000 (44%)] Loss: 15029.358398\n",
      "Train Epoch: 15 [100096/225000 (44%)] Loss: 15076.499023\n",
      "Train Epoch: 15 [101504/225000 (45%)] Loss: 15235.375000\n",
      "Train Epoch: 15 [102912/225000 (46%)] Loss: 14465.443359\n",
      "Train Epoch: 15 [104320/225000 (46%)] Loss: 15483.848633\n",
      "Train Epoch: 15 [105728/225000 (47%)] Loss: 15167.840820\n",
      "Train Epoch: 15 [107136/225000 (48%)] Loss: 14937.468750\n",
      "Train Epoch: 15 [108544/225000 (48%)] Loss: 15067.028320\n",
      "Train Epoch: 15 [109952/225000 (49%)] Loss: 15158.023438\n",
      "Train Epoch: 15 [111360/225000 (49%)] Loss: 15108.418945\n",
      "Train Epoch: 15 [112768/225000 (50%)] Loss: 15128.262695\n",
      "Train Epoch: 15 [114176/225000 (51%)] Loss: 14992.152344\n",
      "Train Epoch: 15 [115584/225000 (51%)] Loss: 15126.693359\n",
      "Train Epoch: 15 [116992/225000 (52%)] Loss: 14529.949219\n",
      "Train Epoch: 15 [118400/225000 (53%)] Loss: 15091.898438\n",
      "Train Epoch: 15 [119808/225000 (53%)] Loss: 14927.387695\n",
      "Train Epoch: 15 [121216/225000 (54%)] Loss: 15322.416016\n",
      "Train Epoch: 15 [122624/225000 (54%)] Loss: 15278.089844\n",
      "Train Epoch: 15 [124032/225000 (55%)] Loss: 15087.001953\n",
      "Train Epoch: 15 [125440/225000 (56%)] Loss: 15478.451172\n",
      "Train Epoch: 15 [126848/225000 (56%)] Loss: 14812.161133\n",
      "Train Epoch: 15 [128256/225000 (57%)] Loss: 14983.194336\n",
      "Train Epoch: 15 [129664/225000 (58%)] Loss: 14512.445312\n",
      "Train Epoch: 15 [131072/225000 (58%)] Loss: 15261.920898\n",
      "Train Epoch: 15 [132480/225000 (59%)] Loss: 14889.996094\n",
      "Train Epoch: 15 [133888/225000 (60%)] Loss: 15588.729492\n",
      "Train Epoch: 15 [135296/225000 (60%)] Loss: 15003.748047\n",
      "Train Epoch: 15 [136704/225000 (61%)] Loss: 15411.397461\n",
      "Train Epoch: 15 [138112/225000 (61%)] Loss: 14975.883789\n",
      "Train Epoch: 15 [139520/225000 (62%)] Loss: 14974.086914\n",
      "Train Epoch: 15 [140928/225000 (63%)] Loss: 15079.445312\n",
      "Train Epoch: 15 [142336/225000 (63%)] Loss: 14888.185547\n",
      "Train Epoch: 15 [143744/225000 (64%)] Loss: 15245.124023\n",
      "Train Epoch: 15 [145152/225000 (65%)] Loss: 15587.417969\n",
      "Train Epoch: 15 [146560/225000 (65%)] Loss: 15172.068359\n",
      "Train Epoch: 15 [147968/225000 (66%)] Loss: 15030.310547\n",
      "Train Epoch: 15 [149376/225000 (66%)] Loss: 15627.550781\n",
      "Train Epoch: 15 [150784/225000 (67%)] Loss: 15577.861328\n",
      "Train Epoch: 15 [152192/225000 (68%)] Loss: 15752.732422\n",
      "Train Epoch: 15 [153600/225000 (68%)] Loss: 15006.491211\n",
      "Train Epoch: 15 [155008/225000 (69%)] Loss: 15325.579102\n",
      "Train Epoch: 15 [156416/225000 (70%)] Loss: 14786.852539\n",
      "Train Epoch: 15 [157824/225000 (70%)] Loss: 15518.171875\n",
      "Train Epoch: 15 [159232/225000 (71%)] Loss: 15130.576172\n",
      "Train Epoch: 15 [160640/225000 (71%)] Loss: 15101.896484\n",
      "Train Epoch: 15 [162048/225000 (72%)] Loss: 14863.418945\n",
      "Train Epoch: 15 [163456/225000 (73%)] Loss: 14923.550781\n",
      "Train Epoch: 15 [164864/225000 (73%)] Loss: 15413.207031\n",
      "Train Epoch: 15 [166272/225000 (74%)] Loss: 15145.687500\n",
      "Train Epoch: 15 [167680/225000 (75%)] Loss: 15234.310547\n",
      "Train Epoch: 15 [169088/225000 (75%)] Loss: 14579.962891\n",
      "Train Epoch: 15 [170496/225000 (76%)] Loss: 14740.556641\n",
      "Train Epoch: 15 [171904/225000 (76%)] Loss: 14950.958008\n",
      "Train Epoch: 15 [173312/225000 (77%)] Loss: 15068.907227\n",
      "Train Epoch: 15 [174720/225000 (78%)] Loss: 14839.130859\n",
      "Train Epoch: 15 [176128/225000 (78%)] Loss: 15037.889648\n",
      "Train Epoch: 15 [177536/225000 (79%)] Loss: 15080.229492\n",
      "Train Epoch: 15 [178944/225000 (80%)] Loss: 15290.623047\n",
      "Train Epoch: 15 [180352/225000 (80%)] Loss: 15160.090820\n",
      "Train Epoch: 15 [181760/225000 (81%)] Loss: 15075.784180\n",
      "Train Epoch: 15 [183168/225000 (81%)] Loss: 15506.516602\n",
      "Train Epoch: 15 [184576/225000 (82%)] Loss: 14958.894531\n",
      "Train Epoch: 15 [185984/225000 (83%)] Loss: 14826.958984\n",
      "Train Epoch: 15 [187392/225000 (83%)] Loss: 15047.486328\n",
      "Train Epoch: 15 [188800/225000 (84%)] Loss: 14914.672852\n",
      "Train Epoch: 15 [190208/225000 (85%)] Loss: 14541.909180\n",
      "Train Epoch: 15 [191616/225000 (85%)] Loss: 15176.062500\n",
      "Train Epoch: 15 [193024/225000 (86%)] Loss: 14713.275391\n",
      "Train Epoch: 15 [194432/225000 (86%)] Loss: 15267.266602\n",
      "Train Epoch: 15 [195840/225000 (87%)] Loss: 15373.298828\n",
      "Train Epoch: 15 [197248/225000 (88%)] Loss: 14755.121094\n",
      "Train Epoch: 15 [198656/225000 (88%)] Loss: 15309.551758\n",
      "Train Epoch: 15 [200064/225000 (89%)] Loss: 15129.135742\n",
      "Train Epoch: 15 [201472/225000 (90%)] Loss: 15101.915039\n",
      "Train Epoch: 15 [202880/225000 (90%)] Loss: 15063.157227\n",
      "Train Epoch: 15 [204288/225000 (91%)] Loss: 15378.872070\n",
      "Train Epoch: 15 [205696/225000 (91%)] Loss: 14750.704102\n",
      "Train Epoch: 15 [207104/225000 (92%)] Loss: 14753.440430\n",
      "Train Epoch: 15 [208512/225000 (93%)] Loss: 14839.769531\n",
      "Train Epoch: 15 [209920/225000 (93%)] Loss: 14935.847656\n",
      "Train Epoch: 15 [211328/225000 (94%)] Loss: 14883.198242\n",
      "Train Epoch: 15 [212736/225000 (95%)] Loss: 15280.234375\n",
      "Train Epoch: 15 [214144/225000 (95%)] Loss: 15144.341797\n",
      "Train Epoch: 15 [215552/225000 (96%)] Loss: 15172.411133\n",
      "Train Epoch: 15 [216960/225000 (96%)] Loss: 14967.304688\n",
      "Train Epoch: 15 [218368/225000 (97%)] Loss: 15452.197266\n",
      "Train Epoch: 15 [219776/225000 (98%)] Loss: 15078.580078\n",
      "Train Epoch: 15 [221184/225000 (98%)] Loss: 15020.212891\n",
      "Train Epoch: 15 [222592/225000 (99%)] Loss: 15294.852539\n",
      "Train Epoch: 15 [224000/225000 (100%)] Loss: 14941.980469\n",
      "    epoch          : 15\n",
      "    loss           : 15094.468285605091\n",
      "    val_loss       : 15086.511805137201\n",
      "Train Epoch: 16 [128/225000 (0%)] Loss: 15163.337891\n",
      "Train Epoch: 16 [1536/225000 (1%)] Loss: 14832.458008\n",
      "Train Epoch: 16 [2944/225000 (1%)] Loss: 14943.656250\n",
      "Train Epoch: 16 [4352/225000 (2%)] Loss: 15000.729492\n",
      "Train Epoch: 16 [5760/225000 (3%)] Loss: 15490.175781\n",
      "Train Epoch: 16 [7168/225000 (3%)] Loss: 15395.275391\n",
      "Train Epoch: 16 [8576/225000 (4%)] Loss: 14773.657227\n",
      "Train Epoch: 16 [9984/225000 (4%)] Loss: 15072.625000\n",
      "Train Epoch: 16 [11392/225000 (5%)] Loss: 14880.711914\n",
      "Train Epoch: 16 [12800/225000 (6%)] Loss: 14977.669922\n",
      "Train Epoch: 16 [14208/225000 (6%)] Loss: 14562.271484\n",
      "Train Epoch: 16 [15616/225000 (7%)] Loss: 14965.695312\n",
      "Train Epoch: 16 [17024/225000 (8%)] Loss: 15056.134766\n",
      "Train Epoch: 16 [18432/225000 (8%)] Loss: 15092.273438\n",
      "Train Epoch: 16 [19840/225000 (9%)] Loss: 15423.609375\n",
      "Train Epoch: 16 [21248/225000 (9%)] Loss: 15307.959961\n",
      "Train Epoch: 16 [22656/225000 (10%)] Loss: 15205.852539\n",
      "Train Epoch: 16 [24064/225000 (11%)] Loss: 14873.771484\n",
      "Train Epoch: 16 [25472/225000 (11%)] Loss: 14790.851562\n",
      "Train Epoch: 16 [26880/225000 (12%)] Loss: 14807.794922\n",
      "Train Epoch: 16 [28288/225000 (13%)] Loss: 15354.186523\n",
      "Train Epoch: 16 [29696/225000 (13%)] Loss: 14657.333984\n",
      "Train Epoch: 16 [31104/225000 (14%)] Loss: 14884.475586\n",
      "Train Epoch: 16 [32512/225000 (14%)] Loss: 14896.587891\n",
      "Train Epoch: 16 [33920/225000 (15%)] Loss: 15239.369141\n",
      "Train Epoch: 16 [35328/225000 (16%)] Loss: 15232.444336\n",
      "Train Epoch: 16 [36736/225000 (16%)] Loss: 15058.578125\n",
      "Train Epoch: 16 [38144/225000 (17%)] Loss: 14934.483398\n",
      "Train Epoch: 16 [39552/225000 (18%)] Loss: 15075.723633\n",
      "Train Epoch: 16 [40960/225000 (18%)] Loss: 14969.700195\n",
      "Train Epoch: 16 [42368/225000 (19%)] Loss: 15313.467773\n",
      "Train Epoch: 16 [43776/225000 (19%)] Loss: 15061.329102\n",
      "Train Epoch: 16 [45184/225000 (20%)] Loss: 15043.161133\n",
      "Train Epoch: 16 [46592/225000 (21%)] Loss: 14926.010742\n",
      "Train Epoch: 16 [48000/225000 (21%)] Loss: 14614.856445\n",
      "Train Epoch: 16 [49408/225000 (22%)] Loss: 14778.615234\n",
      "Train Epoch: 16 [50816/225000 (23%)] Loss: 14995.940430\n",
      "Train Epoch: 16 [52224/225000 (23%)] Loss: 15685.088867\n",
      "Train Epoch: 16 [53632/225000 (24%)] Loss: 14885.125000\n",
      "Train Epoch: 16 [55040/225000 (24%)] Loss: 15210.402344\n",
      "Train Epoch: 16 [56448/225000 (25%)] Loss: 15319.742188\n",
      "Train Epoch: 16 [57856/225000 (26%)] Loss: 15415.352539\n",
      "Train Epoch: 16 [59264/225000 (26%)] Loss: 15013.931641\n",
      "Train Epoch: 16 [60672/225000 (27%)] Loss: 15184.660156\n",
      "Train Epoch: 16 [62080/225000 (28%)] Loss: 14795.777344\n",
      "Train Epoch: 16 [63488/225000 (28%)] Loss: 15054.171875\n",
      "Train Epoch: 16 [64896/225000 (29%)] Loss: 15242.228516\n",
      "Train Epoch: 16 [66304/225000 (29%)] Loss: 14984.520508\n",
      "Train Epoch: 16 [67712/225000 (30%)] Loss: 15014.996094\n",
      "Train Epoch: 16 [69120/225000 (31%)] Loss: 14901.351562\n",
      "Train Epoch: 16 [70528/225000 (31%)] Loss: 15141.616211\n",
      "Train Epoch: 16 [71936/225000 (32%)] Loss: 15287.394531\n",
      "Train Epoch: 16 [73344/225000 (33%)] Loss: 15388.835938\n",
      "Train Epoch: 16 [74752/225000 (33%)] Loss: 15296.135742\n",
      "Train Epoch: 16 [76160/225000 (34%)] Loss: 15059.652344\n",
      "Train Epoch: 16 [77568/225000 (34%)] Loss: 15190.458984\n",
      "Train Epoch: 16 [78976/225000 (35%)] Loss: 14990.811523\n",
      "Train Epoch: 16 [80384/225000 (36%)] Loss: 15259.306641\n",
      "Train Epoch: 16 [81792/225000 (36%)] Loss: 14803.447266\n",
      "Train Epoch: 16 [83200/225000 (37%)] Loss: 15131.650391\n",
      "Train Epoch: 16 [84608/225000 (38%)] Loss: 15280.657227\n",
      "Train Epoch: 16 [86016/225000 (38%)] Loss: 14965.996094\n",
      "Train Epoch: 16 [87424/225000 (39%)] Loss: 15213.206055\n",
      "Train Epoch: 16 [88832/225000 (39%)] Loss: 15166.973633\n",
      "Train Epoch: 16 [90240/225000 (40%)] Loss: 15194.914062\n",
      "Train Epoch: 16 [91648/225000 (41%)] Loss: 15009.581055\n",
      "Train Epoch: 16 [93056/225000 (41%)] Loss: 15221.237305\n",
      "Train Epoch: 16 [94464/225000 (42%)] Loss: 15050.681641\n",
      "Train Epoch: 16 [95872/225000 (43%)] Loss: 15029.260742\n",
      "Train Epoch: 16 [97280/225000 (43%)] Loss: 15159.617188\n",
      "Train Epoch: 16 [98688/225000 (44%)] Loss: 15117.888672\n",
      "Train Epoch: 16 [100096/225000 (44%)] Loss: 14837.920898\n",
      "Train Epoch: 16 [101504/225000 (45%)] Loss: 14932.232422\n",
      "Train Epoch: 16 [102912/225000 (46%)] Loss: 15178.308594\n",
      "Train Epoch: 16 [104320/225000 (46%)] Loss: 15220.381836\n",
      "Train Epoch: 16 [105728/225000 (47%)] Loss: 15140.791016\n",
      "Train Epoch: 16 [107136/225000 (48%)] Loss: 15016.501953\n",
      "Train Epoch: 16 [108544/225000 (48%)] Loss: 14981.948242\n",
      "Train Epoch: 16 [109952/225000 (49%)] Loss: 14774.488281\n",
      "Train Epoch: 16 [111360/225000 (49%)] Loss: 15197.040039\n",
      "Train Epoch: 16 [112768/225000 (50%)] Loss: 14914.315430\n",
      "Train Epoch: 16 [114176/225000 (51%)] Loss: 15070.958008\n",
      "Train Epoch: 16 [115584/225000 (51%)] Loss: 14865.007812\n",
      "Train Epoch: 16 [116992/225000 (52%)] Loss: 15293.636719\n",
      "Train Epoch: 16 [118400/225000 (53%)] Loss: 14792.876953\n",
      "Train Epoch: 16 [119808/225000 (53%)] Loss: 14783.921875\n",
      "Train Epoch: 16 [121216/225000 (54%)] Loss: 15056.226562\n",
      "Train Epoch: 16 [122624/225000 (54%)] Loss: 15201.489258\n",
      "Train Epoch: 16 [124032/225000 (55%)] Loss: 15522.605469\n",
      "Train Epoch: 16 [125440/225000 (56%)] Loss: 15087.790039\n",
      "Train Epoch: 16 [126848/225000 (56%)] Loss: 15031.797852\n",
      "Train Epoch: 16 [128256/225000 (57%)] Loss: 15180.605469\n",
      "Train Epoch: 16 [129664/225000 (58%)] Loss: 15059.429688\n",
      "Train Epoch: 16 [131072/225000 (58%)] Loss: 14672.312500\n",
      "Train Epoch: 16 [132480/225000 (59%)] Loss: 15190.234375\n",
      "Train Epoch: 16 [133888/225000 (60%)] Loss: 14991.637695\n",
      "Train Epoch: 16 [135296/225000 (60%)] Loss: 14882.770508\n",
      "Train Epoch: 16 [136704/225000 (61%)] Loss: 15523.216797\n",
      "Train Epoch: 16 [138112/225000 (61%)] Loss: 14849.460938\n",
      "Train Epoch: 16 [139520/225000 (62%)] Loss: 15187.740234\n",
      "Train Epoch: 16 [140928/225000 (63%)] Loss: 15130.150391\n",
      "Train Epoch: 16 [142336/225000 (63%)] Loss: 15207.699219\n",
      "Train Epoch: 16 [143744/225000 (64%)] Loss: 14895.269531\n",
      "Train Epoch: 16 [145152/225000 (65%)] Loss: 14839.875000\n",
      "Train Epoch: 16 [146560/225000 (65%)] Loss: 14892.808594\n",
      "Train Epoch: 16 [147968/225000 (66%)] Loss: 15616.188477\n",
      "Train Epoch: 16 [149376/225000 (66%)] Loss: 14945.691406\n",
      "Train Epoch: 16 [150784/225000 (67%)] Loss: 14834.270508\n",
      "Train Epoch: 16 [152192/225000 (68%)] Loss: 14979.411133\n",
      "Train Epoch: 16 [153600/225000 (68%)] Loss: 15375.425781\n",
      "Train Epoch: 16 [155008/225000 (69%)] Loss: 14831.076172\n",
      "Train Epoch: 16 [156416/225000 (70%)] Loss: 15522.869141\n",
      "Train Epoch: 16 [157824/225000 (70%)] Loss: 14978.361328\n",
      "Train Epoch: 16 [159232/225000 (71%)] Loss: 15103.670898\n",
      "Train Epoch: 16 [160640/225000 (71%)] Loss: 14922.166016\n",
      "Train Epoch: 16 [162048/225000 (72%)] Loss: 15120.103516\n",
      "Train Epoch: 16 [163456/225000 (73%)] Loss: 14862.196289\n",
      "Train Epoch: 16 [164864/225000 (73%)] Loss: 15051.712891\n",
      "Train Epoch: 16 [166272/225000 (74%)] Loss: 14728.154297\n",
      "Train Epoch: 16 [167680/225000 (75%)] Loss: 15309.066406\n",
      "Train Epoch: 16 [169088/225000 (75%)] Loss: 14965.151367\n",
      "Train Epoch: 16 [170496/225000 (76%)] Loss: 15142.608398\n",
      "Train Epoch: 16 [171904/225000 (76%)] Loss: 15156.759766\n",
      "Train Epoch: 16 [173312/225000 (77%)] Loss: 15141.461914\n",
      "Train Epoch: 16 [174720/225000 (78%)] Loss: 15103.486328\n",
      "Train Epoch: 16 [176128/225000 (78%)] Loss: 15403.520508\n",
      "Train Epoch: 16 [177536/225000 (79%)] Loss: 15282.129883\n",
      "Train Epoch: 16 [178944/225000 (80%)] Loss: 15269.925781\n",
      "Train Epoch: 16 [180352/225000 (80%)] Loss: 14843.468750\n",
      "Train Epoch: 16 [181760/225000 (81%)] Loss: 15051.243164\n",
      "Train Epoch: 16 [183168/225000 (81%)] Loss: 15171.462891\n",
      "Train Epoch: 16 [184576/225000 (82%)] Loss: 15363.410156\n",
      "Train Epoch: 16 [185984/225000 (83%)] Loss: 15276.208008\n",
      "Train Epoch: 16 [187392/225000 (83%)] Loss: 14801.264648\n",
      "Train Epoch: 16 [188800/225000 (84%)] Loss: 15187.722656\n",
      "Train Epoch: 16 [190208/225000 (85%)] Loss: 15184.429688\n",
      "Train Epoch: 16 [191616/225000 (85%)] Loss: 14740.955078\n",
      "Train Epoch: 16 [193024/225000 (86%)] Loss: 15726.833984\n",
      "Train Epoch: 16 [194432/225000 (86%)] Loss: 14881.846680\n",
      "Train Epoch: 16 [195840/225000 (87%)] Loss: 15111.955078\n",
      "Train Epoch: 16 [197248/225000 (88%)] Loss: 15275.493164\n",
      "Train Epoch: 16 [198656/225000 (88%)] Loss: 15472.314453\n",
      "Train Epoch: 16 [200064/225000 (89%)] Loss: 14910.708984\n",
      "Train Epoch: 16 [201472/225000 (90%)] Loss: 14898.006836\n",
      "Train Epoch: 16 [202880/225000 (90%)] Loss: 15133.890625\n",
      "Train Epoch: 16 [204288/225000 (91%)] Loss: 14911.638672\n",
      "Train Epoch: 16 [205696/225000 (91%)] Loss: 15094.844727\n",
      "Train Epoch: 16 [207104/225000 (92%)] Loss: 15763.833984\n",
      "Train Epoch: 16 [208512/225000 (93%)] Loss: 14976.546875\n",
      "Train Epoch: 16 [209920/225000 (93%)] Loss: 14805.349609\n",
      "Train Epoch: 16 [211328/225000 (94%)] Loss: 15161.447266\n",
      "Train Epoch: 16 [212736/225000 (95%)] Loss: 14955.419922\n",
      "Train Epoch: 16 [214144/225000 (95%)] Loss: 14811.764648\n",
      "Train Epoch: 16 [215552/225000 (96%)] Loss: 14808.961914\n",
      "Train Epoch: 16 [216960/225000 (96%)] Loss: 14797.591797\n",
      "Train Epoch: 16 [218368/225000 (97%)] Loss: 14800.951172\n",
      "Train Epoch: 16 [219776/225000 (98%)] Loss: 14857.942383\n",
      "Train Epoch: 16 [221184/225000 (98%)] Loss: 14943.211914\n",
      "Train Epoch: 16 [222592/225000 (99%)] Loss: 14977.470703\n",
      "Train Epoch: 16 [224000/225000 (100%)] Loss: 15716.317383\n",
      "    epoch          : 16\n",
      "    loss           : 15097.506295439598\n",
      "    val_loss       : 15087.407139370029\n",
      "Train Epoch: 17 [128/225000 (0%)] Loss: 15002.638672\n",
      "Train Epoch: 17 [1536/225000 (1%)] Loss: 15607.276367\n",
      "Train Epoch: 17 [2944/225000 (1%)] Loss: 15380.669922\n",
      "Train Epoch: 17 [4352/225000 (2%)] Loss: 15026.818359\n",
      "Train Epoch: 17 [5760/225000 (3%)] Loss: 15461.050781\n",
      "Train Epoch: 17 [7168/225000 (3%)] Loss: 15641.036133\n",
      "Train Epoch: 17 [8576/225000 (4%)] Loss: 14761.637695\n",
      "Train Epoch: 17 [9984/225000 (4%)] Loss: 14862.165039\n",
      "Train Epoch: 17 [11392/225000 (5%)] Loss: 15295.464844\n",
      "Train Epoch: 17 [12800/225000 (6%)] Loss: 15208.519531\n",
      "Train Epoch: 17 [14208/225000 (6%)] Loss: 14791.080078\n",
      "Train Epoch: 17 [15616/225000 (7%)] Loss: 15381.583984\n",
      "Train Epoch: 17 [17024/225000 (8%)] Loss: 15044.527344\n",
      "Train Epoch: 17 [18432/225000 (8%)] Loss: 15033.532227\n",
      "Train Epoch: 17 [19840/225000 (9%)] Loss: 14924.061523\n",
      "Train Epoch: 17 [21248/225000 (9%)] Loss: 15027.482422\n",
      "Train Epoch: 17 [22656/225000 (10%)] Loss: 14825.791992\n",
      "Train Epoch: 17 [24064/225000 (11%)] Loss: 15052.782227\n",
      "Train Epoch: 17 [25472/225000 (11%)] Loss: 14835.504883\n",
      "Train Epoch: 17 [26880/225000 (12%)] Loss: 15239.987305\n",
      "Train Epoch: 17 [28288/225000 (13%)] Loss: 14865.422852\n",
      "Train Epoch: 17 [29696/225000 (13%)] Loss: 14823.819336\n",
      "Train Epoch: 17 [31104/225000 (14%)] Loss: 15112.729492\n",
      "Train Epoch: 17 [32512/225000 (14%)] Loss: 15163.108398\n",
      "Train Epoch: 17 [33920/225000 (15%)] Loss: 15266.122070\n",
      "Train Epoch: 17 [35328/225000 (16%)] Loss: 15661.457031\n",
      "Train Epoch: 17 [36736/225000 (16%)] Loss: 14942.517578\n",
      "Train Epoch: 17 [38144/225000 (17%)] Loss: 15481.422852\n",
      "Train Epoch: 17 [39552/225000 (18%)] Loss: 15007.469727\n",
      "Train Epoch: 17 [40960/225000 (18%)] Loss: 15073.506836\n",
      "Train Epoch: 17 [42368/225000 (19%)] Loss: 15077.166992\n",
      "Train Epoch: 17 [43776/225000 (19%)] Loss: 15192.339844\n",
      "Train Epoch: 17 [45184/225000 (20%)] Loss: 15903.082031\n",
      "Train Epoch: 17 [46592/225000 (21%)] Loss: 14652.211914\n",
      "Train Epoch: 17 [48000/225000 (21%)] Loss: 15346.584961\n",
      "Train Epoch: 17 [49408/225000 (22%)] Loss: 15177.520508\n",
      "Train Epoch: 17 [50816/225000 (23%)] Loss: 14779.779297\n",
      "Train Epoch: 17 [52224/225000 (23%)] Loss: 14964.172852\n",
      "Train Epoch: 17 [53632/225000 (24%)] Loss: 15080.086914\n",
      "Train Epoch: 17 [55040/225000 (24%)] Loss: 15286.894531\n",
      "Train Epoch: 17 [56448/225000 (25%)] Loss: 14605.117188\n",
      "Train Epoch: 17 [57856/225000 (26%)] Loss: 14806.803711\n",
      "Train Epoch: 17 [59264/225000 (26%)] Loss: 14881.460938\n",
      "Train Epoch: 17 [60672/225000 (27%)] Loss: 14929.029297\n",
      "Train Epoch: 17 [62080/225000 (28%)] Loss: 15210.675781\n",
      "Train Epoch: 17 [63488/225000 (28%)] Loss: 15091.364258\n",
      "Train Epoch: 17 [64896/225000 (29%)] Loss: 15075.247070\n",
      "Train Epoch: 17 [66304/225000 (29%)] Loss: 15101.653320\n",
      "Train Epoch: 17 [67712/225000 (30%)] Loss: 15327.198242\n",
      "Train Epoch: 17 [69120/225000 (31%)] Loss: 14959.128906\n",
      "Train Epoch: 17 [70528/225000 (31%)] Loss: 15299.462891\n",
      "Train Epoch: 17 [71936/225000 (32%)] Loss: 15276.653320\n",
      "Train Epoch: 17 [73344/225000 (33%)] Loss: 14406.164062\n",
      "Train Epoch: 17 [74752/225000 (33%)] Loss: 15002.898438\n",
      "Train Epoch: 17 [76160/225000 (34%)] Loss: 15150.446289\n",
      "Train Epoch: 17 [77568/225000 (34%)] Loss: 14447.812500\n",
      "Train Epoch: 17 [78976/225000 (35%)] Loss: 14972.857422\n",
      "Train Epoch: 17 [80384/225000 (36%)] Loss: 15027.002930\n",
      "Train Epoch: 17 [81792/225000 (36%)] Loss: 15588.388672\n",
      "Train Epoch: 17 [83200/225000 (37%)] Loss: 14936.931641\n",
      "Train Epoch: 17 [84608/225000 (38%)] Loss: 15374.304688\n",
      "Train Epoch: 17 [86016/225000 (38%)] Loss: 15444.984375\n",
      "Train Epoch: 17 [87424/225000 (39%)] Loss: 15050.001953\n",
      "Train Epoch: 17 [88832/225000 (39%)] Loss: 15135.083008\n",
      "Train Epoch: 17 [90240/225000 (40%)] Loss: 15019.305664\n",
      "Train Epoch: 17 [91648/225000 (41%)] Loss: 15193.903320\n",
      "Train Epoch: 17 [93056/225000 (41%)] Loss: 15108.321289\n",
      "Train Epoch: 17 [94464/225000 (42%)] Loss: 15547.043945\n",
      "Train Epoch: 17 [95872/225000 (43%)] Loss: 15133.867188\n",
      "Train Epoch: 17 [97280/225000 (43%)] Loss: 15054.046875\n",
      "Train Epoch: 17 [98688/225000 (44%)] Loss: 14804.920898\n",
      "Train Epoch: 17 [100096/225000 (44%)] Loss: 15068.809570\n",
      "Train Epoch: 17 [101504/225000 (45%)] Loss: 15029.224609\n",
      "Train Epoch: 17 [102912/225000 (46%)] Loss: 15133.621094\n",
      "Train Epoch: 17 [104320/225000 (46%)] Loss: 15159.668945\n",
      "Train Epoch: 17 [105728/225000 (47%)] Loss: 15471.977539\n",
      "Train Epoch: 17 [107136/225000 (48%)] Loss: 14847.070312\n",
      "Train Epoch: 17 [108544/225000 (48%)] Loss: 15035.458008\n",
      "Train Epoch: 17 [109952/225000 (49%)] Loss: 15392.644531\n",
      "Train Epoch: 17 [111360/225000 (49%)] Loss: 14797.833008\n",
      "Train Epoch: 17 [112768/225000 (50%)] Loss: 14826.506836\n",
      "Train Epoch: 17 [114176/225000 (51%)] Loss: 15233.387695\n",
      "Train Epoch: 17 [115584/225000 (51%)] Loss: 15142.820312\n",
      "Train Epoch: 17 [116992/225000 (52%)] Loss: 14753.097656\n",
      "Train Epoch: 17 [118400/225000 (53%)] Loss: 15143.076172\n",
      "Train Epoch: 17 [119808/225000 (53%)] Loss: 15790.709961\n",
      "Train Epoch: 17 [121216/225000 (54%)] Loss: 15294.953125\n",
      "Train Epoch: 17 [122624/225000 (54%)] Loss: 15336.293945\n",
      "Train Epoch: 17 [124032/225000 (55%)] Loss: 14892.603516\n",
      "Train Epoch: 17 [125440/225000 (56%)] Loss: 14787.295898\n",
      "Train Epoch: 17 [126848/225000 (56%)] Loss: 15442.314453\n",
      "Train Epoch: 17 [128256/225000 (57%)] Loss: 15144.770508\n",
      "Train Epoch: 17 [129664/225000 (58%)] Loss: 15285.542969\n",
      "Train Epoch: 17 [131072/225000 (58%)] Loss: 14320.802734\n",
      "Train Epoch: 17 [132480/225000 (59%)] Loss: 15239.686523\n",
      "Train Epoch: 17 [133888/225000 (60%)] Loss: 15069.108398\n",
      "Train Epoch: 17 [135296/225000 (60%)] Loss: 14769.193359\n",
      "Train Epoch: 17 [136704/225000 (61%)] Loss: 15039.409180\n",
      "Train Epoch: 17 [138112/225000 (61%)] Loss: 15246.468750\n",
      "Train Epoch: 17 [139520/225000 (62%)] Loss: 14913.869141\n",
      "Train Epoch: 17 [140928/225000 (63%)] Loss: 14711.272461\n",
      "Train Epoch: 17 [142336/225000 (63%)] Loss: 15106.559570\n",
      "Train Epoch: 17 [143744/225000 (64%)] Loss: 15349.508789\n",
      "Train Epoch: 17 [145152/225000 (65%)] Loss: 14856.193359\n",
      "Train Epoch: 17 [146560/225000 (65%)] Loss: 15213.552734\n",
      "Train Epoch: 17 [147968/225000 (66%)] Loss: 15141.448242\n",
      "Train Epoch: 17 [149376/225000 (66%)] Loss: 15361.190430\n",
      "Train Epoch: 17 [150784/225000 (67%)] Loss: 15714.645508\n",
      "Train Epoch: 17 [152192/225000 (68%)] Loss: 15217.080078\n",
      "Train Epoch: 17 [153600/225000 (68%)] Loss: 14784.085938\n",
      "Train Epoch: 17 [155008/225000 (69%)] Loss: 14723.890625\n",
      "Train Epoch: 17 [156416/225000 (70%)] Loss: 14996.414062\n",
      "Train Epoch: 17 [157824/225000 (70%)] Loss: 14927.578125\n",
      "Train Epoch: 17 [159232/225000 (71%)] Loss: 14920.803711\n",
      "Train Epoch: 17 [160640/225000 (71%)] Loss: 15248.602539\n",
      "Train Epoch: 17 [162048/225000 (72%)] Loss: 15243.805664\n",
      "Train Epoch: 17 [163456/225000 (73%)] Loss: 15340.710938\n",
      "Train Epoch: 17 [164864/225000 (73%)] Loss: 14873.489258\n",
      "Train Epoch: 17 [166272/225000 (74%)] Loss: 15211.991211\n",
      "Train Epoch: 17 [167680/225000 (75%)] Loss: 14820.080078\n",
      "Train Epoch: 17 [169088/225000 (75%)] Loss: 15497.257812\n",
      "Train Epoch: 17 [170496/225000 (76%)] Loss: 15152.230469\n",
      "Train Epoch: 17 [171904/225000 (76%)] Loss: 14875.633789\n",
      "Train Epoch: 17 [173312/225000 (77%)] Loss: 15017.362305\n",
      "Train Epoch: 17 [174720/225000 (78%)] Loss: 14959.040039\n",
      "Train Epoch: 17 [176128/225000 (78%)] Loss: 15513.783203\n",
      "Train Epoch: 17 [177536/225000 (79%)] Loss: 14930.853516\n",
      "Train Epoch: 17 [178944/225000 (80%)] Loss: 14741.428711\n",
      "Train Epoch: 17 [180352/225000 (80%)] Loss: 15541.853516\n",
      "Train Epoch: 17 [181760/225000 (81%)] Loss: 15504.375977\n",
      "Train Epoch: 17 [183168/225000 (81%)] Loss: 14745.984375\n",
      "Train Epoch: 17 [184576/225000 (82%)] Loss: 15220.444336\n",
      "Train Epoch: 17 [185984/225000 (83%)] Loss: 15425.953125\n",
      "Train Epoch: 17 [187392/225000 (83%)] Loss: 15284.431641\n",
      "Train Epoch: 17 [188800/225000 (84%)] Loss: 15159.685547\n",
      "Train Epoch: 17 [190208/225000 (85%)] Loss: 14911.374023\n",
      "Train Epoch: 17 [191616/225000 (85%)] Loss: 15659.757812\n",
      "Train Epoch: 17 [193024/225000 (86%)] Loss: 15129.824219\n",
      "Train Epoch: 17 [194432/225000 (86%)] Loss: 15097.818359\n",
      "Train Epoch: 17 [195840/225000 (87%)] Loss: 14874.825195\n",
      "Train Epoch: 17 [197248/225000 (88%)] Loss: 15840.036133\n",
      "Train Epoch: 17 [198656/225000 (88%)] Loss: 15203.346680\n",
      "Train Epoch: 17 [200064/225000 (89%)] Loss: 15089.215820\n",
      "Train Epoch: 17 [201472/225000 (90%)] Loss: 15140.798828\n",
      "Train Epoch: 17 [202880/225000 (90%)] Loss: 15560.676758\n",
      "Train Epoch: 17 [204288/225000 (91%)] Loss: 15204.360352\n",
      "Train Epoch: 17 [205696/225000 (91%)] Loss: 14997.391602\n",
      "Train Epoch: 17 [207104/225000 (92%)] Loss: 14903.683594\n",
      "Train Epoch: 17 [208512/225000 (93%)] Loss: 15288.732422\n",
      "Train Epoch: 17 [209920/225000 (93%)] Loss: 15279.511719\n",
      "Train Epoch: 17 [211328/225000 (94%)] Loss: 15198.016602\n",
      "Train Epoch: 17 [212736/225000 (95%)] Loss: 14880.785156\n",
      "Train Epoch: 17 [214144/225000 (95%)] Loss: 15640.590820\n",
      "Train Epoch: 17 [215552/225000 (96%)] Loss: 15068.204102\n",
      "Train Epoch: 17 [216960/225000 (96%)] Loss: 15026.961914\n",
      "Train Epoch: 17 [218368/225000 (97%)] Loss: 15560.723633\n",
      "Train Epoch: 17 [219776/225000 (98%)] Loss: 15013.018555\n",
      "Train Epoch: 17 [221184/225000 (98%)] Loss: 15113.220703\n",
      "Train Epoch: 17 [222592/225000 (99%)] Loss: 14844.020508\n",
      "Train Epoch: 17 [224000/225000 (100%)] Loss: 14669.719727\n",
      "    epoch          : 17\n",
      "    loss           : 15099.462700089769\n",
      "    val_loss       : 15068.212989416354\n",
      "Train Epoch: 18 [128/225000 (0%)] Loss: 15026.534180\n",
      "Train Epoch: 18 [1536/225000 (1%)] Loss: 14897.069336\n",
      "Train Epoch: 18 [2944/225000 (1%)] Loss: 15251.776367\n",
      "Train Epoch: 18 [4352/225000 (2%)] Loss: 15556.571289\n",
      "Train Epoch: 18 [5760/225000 (3%)] Loss: 14862.672852\n",
      "Train Epoch: 18 [7168/225000 (3%)] Loss: 15080.615234\n",
      "Train Epoch: 18 [8576/225000 (4%)] Loss: 15051.278320\n",
      "Train Epoch: 18 [9984/225000 (4%)] Loss: 14973.033203\n",
      "Train Epoch: 18 [11392/225000 (5%)] Loss: 14869.192383\n",
      "Train Epoch: 18 [12800/225000 (6%)] Loss: 14886.489258\n",
      "Train Epoch: 18 [14208/225000 (6%)] Loss: 14941.551758\n",
      "Train Epoch: 18 [15616/225000 (7%)] Loss: 15406.930664\n",
      "Train Epoch: 18 [17024/225000 (8%)] Loss: 15039.978516\n",
      "Train Epoch: 18 [18432/225000 (8%)] Loss: 15084.470703\n",
      "Train Epoch: 18 [19840/225000 (9%)] Loss: 15019.800781\n",
      "Train Epoch: 18 [21248/225000 (9%)] Loss: 15254.611328\n",
      "Train Epoch: 18 [22656/225000 (10%)] Loss: 15537.975586\n",
      "Train Epoch: 18 [24064/225000 (11%)] Loss: 14841.801758\n",
      "Train Epoch: 18 [25472/225000 (11%)] Loss: 14970.060547\n",
      "Train Epoch: 18 [26880/225000 (12%)] Loss: 15175.409180\n",
      "Train Epoch: 18 [28288/225000 (13%)] Loss: 14769.192383\n",
      "Train Epoch: 18 [29696/225000 (13%)] Loss: 15558.835938\n",
      "Train Epoch: 18 [31104/225000 (14%)] Loss: 15330.629883\n",
      "Train Epoch: 18 [32512/225000 (14%)] Loss: 15407.041016\n",
      "Train Epoch: 18 [33920/225000 (15%)] Loss: 15160.095703\n",
      "Train Epoch: 18 [35328/225000 (16%)] Loss: 14898.977539\n",
      "Train Epoch: 18 [36736/225000 (16%)] Loss: 15182.849609\n",
      "Train Epoch: 18 [38144/225000 (17%)] Loss: 14952.419922\n",
      "Train Epoch: 18 [39552/225000 (18%)] Loss: 15463.223633\n",
      "Train Epoch: 18 [40960/225000 (18%)] Loss: 15230.490234\n",
      "Train Epoch: 18 [42368/225000 (19%)] Loss: 15217.379883\n",
      "Train Epoch: 18 [43776/225000 (19%)] Loss: 15073.542969\n",
      "Train Epoch: 18 [45184/225000 (20%)] Loss: 15016.824219\n",
      "Train Epoch: 18 [46592/225000 (21%)] Loss: 15136.003906\n",
      "Train Epoch: 18 [48000/225000 (21%)] Loss: 15075.238281\n",
      "Train Epoch: 18 [49408/225000 (22%)] Loss: 14835.855469\n",
      "Train Epoch: 18 [50816/225000 (23%)] Loss: 15070.357422\n",
      "Train Epoch: 18 [52224/225000 (23%)] Loss: 15497.816406\n",
      "Train Epoch: 18 [53632/225000 (24%)] Loss: 15405.497070\n",
      "Train Epoch: 18 [55040/225000 (24%)] Loss: 14969.281250\n",
      "Train Epoch: 18 [56448/225000 (25%)] Loss: 15169.467773\n",
      "Train Epoch: 18 [57856/225000 (26%)] Loss: 15408.384766\n",
      "Train Epoch: 18 [59264/225000 (26%)] Loss: 15114.083984\n",
      "Train Epoch: 18 [60672/225000 (27%)] Loss: 15160.824219\n",
      "Train Epoch: 18 [62080/225000 (28%)] Loss: 15209.813477\n",
      "Train Epoch: 18 [63488/225000 (28%)] Loss: 15140.048828\n",
      "Train Epoch: 18 [64896/225000 (29%)] Loss: 14951.811523\n",
      "Train Epoch: 18 [66304/225000 (29%)] Loss: 15055.219727\n",
      "Train Epoch: 18 [67712/225000 (30%)] Loss: 15260.364258\n",
      "Train Epoch: 18 [69120/225000 (31%)] Loss: 15639.477539\n",
      "Train Epoch: 18 [70528/225000 (31%)] Loss: 14956.628906\n",
      "Train Epoch: 18 [71936/225000 (32%)] Loss: 15090.603516\n",
      "Train Epoch: 18 [73344/225000 (33%)] Loss: 15415.334961\n",
      "Train Epoch: 18 [74752/225000 (33%)] Loss: 14794.915039\n",
      "Train Epoch: 18 [76160/225000 (34%)] Loss: 14828.430664\n",
      "Train Epoch: 18 [77568/225000 (34%)] Loss: 15242.286133\n",
      "Train Epoch: 18 [78976/225000 (35%)] Loss: 15058.070312\n",
      "Train Epoch: 18 [80384/225000 (36%)] Loss: 14761.313477\n",
      "Train Epoch: 18 [81792/225000 (36%)] Loss: 15242.370117\n",
      "Train Epoch: 18 [83200/225000 (37%)] Loss: 15163.232422\n",
      "Train Epoch: 18 [84608/225000 (38%)] Loss: 15076.328125\n",
      "Train Epoch: 18 [86016/225000 (38%)] Loss: 14764.442383\n",
      "Train Epoch: 18 [87424/225000 (39%)] Loss: 15213.341797\n",
      "Train Epoch: 18 [88832/225000 (39%)] Loss: 15120.739258\n",
      "Train Epoch: 18 [90240/225000 (40%)] Loss: 14829.125000\n",
      "Train Epoch: 18 [91648/225000 (41%)] Loss: 14757.001953\n",
      "Train Epoch: 18 [93056/225000 (41%)] Loss: 15045.737305\n",
      "Train Epoch: 18 [94464/225000 (42%)] Loss: 15287.329102\n",
      "Train Epoch: 18 [95872/225000 (43%)] Loss: 14681.108398\n",
      "Train Epoch: 18 [97280/225000 (43%)] Loss: 14497.233398\n",
      "Train Epoch: 18 [98688/225000 (44%)] Loss: 14853.763672\n",
      "Train Epoch: 18 [100096/225000 (44%)] Loss: 14669.412109\n",
      "Train Epoch: 18 [101504/225000 (45%)] Loss: 14398.808594\n",
      "Train Epoch: 18 [102912/225000 (46%)] Loss: 15398.047852\n",
      "Train Epoch: 18 [104320/225000 (46%)] Loss: 15224.207031\n",
      "Train Epoch: 18 [105728/225000 (47%)] Loss: 15031.500977\n",
      "Train Epoch: 18 [107136/225000 (48%)] Loss: 15168.720703\n",
      "Train Epoch: 18 [108544/225000 (48%)] Loss: 14725.270508\n",
      "Train Epoch: 18 [109952/225000 (49%)] Loss: 15109.317383\n",
      "Train Epoch: 18 [111360/225000 (49%)] Loss: 14974.896484\n",
      "Train Epoch: 18 [112768/225000 (50%)] Loss: 15019.518555\n",
      "Train Epoch: 18 [114176/225000 (51%)] Loss: 15050.899414\n",
      "Train Epoch: 18 [115584/225000 (51%)] Loss: 15613.007812\n",
      "Train Epoch: 18 [116992/225000 (52%)] Loss: 15471.295898\n",
      "Train Epoch: 18 [118400/225000 (53%)] Loss: 15195.270508\n",
      "Train Epoch: 18 [119808/225000 (53%)] Loss: 14748.216797\n",
      "Train Epoch: 18 [121216/225000 (54%)] Loss: 15094.052734\n",
      "Train Epoch: 18 [122624/225000 (54%)] Loss: 15148.962891\n",
      "Train Epoch: 18 [124032/225000 (55%)] Loss: 15285.894531\n",
      "Train Epoch: 18 [125440/225000 (56%)] Loss: 15134.093750\n",
      "Train Epoch: 18 [126848/225000 (56%)] Loss: 15466.743164\n",
      "Train Epoch: 18 [128256/225000 (57%)] Loss: 14936.654297\n",
      "Train Epoch: 18 [129664/225000 (58%)] Loss: 15604.114258\n",
      "Train Epoch: 18 [131072/225000 (58%)] Loss: 14956.573242\n",
      "Train Epoch: 18 [132480/225000 (59%)] Loss: 15128.586914\n",
      "Train Epoch: 18 [133888/225000 (60%)] Loss: 15055.296875\n",
      "Train Epoch: 18 [135296/225000 (60%)] Loss: 14720.955078\n",
      "Train Epoch: 18 [136704/225000 (61%)] Loss: 15001.967773\n",
      "Train Epoch: 18 [138112/225000 (61%)] Loss: 15101.150391\n",
      "Train Epoch: 18 [139520/225000 (62%)] Loss: 15256.064453\n",
      "Train Epoch: 18 [140928/225000 (63%)] Loss: 14759.772461\n",
      "Train Epoch: 18 [142336/225000 (63%)] Loss: 15518.131836\n",
      "Train Epoch: 18 [143744/225000 (64%)] Loss: 15531.857422\n",
      "Train Epoch: 18 [145152/225000 (65%)] Loss: 14890.033203\n",
      "Train Epoch: 18 [146560/225000 (65%)] Loss: 14752.346680\n",
      "Train Epoch: 18 [147968/225000 (66%)] Loss: 15004.203125\n",
      "Train Epoch: 18 [149376/225000 (66%)] Loss: 15182.015625\n",
      "Train Epoch: 18 [150784/225000 (67%)] Loss: 15132.887695\n",
      "Train Epoch: 18 [152192/225000 (68%)] Loss: 15097.266602\n",
      "Train Epoch: 18 [153600/225000 (68%)] Loss: 15016.230469\n",
      "Train Epoch: 18 [155008/225000 (69%)] Loss: 15444.802734\n",
      "Train Epoch: 18 [156416/225000 (70%)] Loss: 15124.930664\n",
      "Train Epoch: 18 [157824/225000 (70%)] Loss: 15098.784180\n",
      "Train Epoch: 18 [159232/225000 (71%)] Loss: 15060.145508\n",
      "Train Epoch: 18 [160640/225000 (71%)] Loss: 15892.908203\n",
      "Train Epoch: 18 [162048/225000 (72%)] Loss: 14560.866211\n",
      "Train Epoch: 18 [163456/225000 (73%)] Loss: 15132.263672\n",
      "Train Epoch: 18 [164864/225000 (73%)] Loss: 14865.974609\n",
      "Train Epoch: 18 [166272/225000 (74%)] Loss: 15227.496094\n",
      "Train Epoch: 18 [167680/225000 (75%)] Loss: 15360.553711\n",
      "Train Epoch: 18 [169088/225000 (75%)] Loss: 15679.971680\n",
      "Train Epoch: 18 [170496/225000 (76%)] Loss: 15410.118164\n",
      "Train Epoch: 18 [171904/225000 (76%)] Loss: 14798.727539\n",
      "Train Epoch: 18 [173312/225000 (77%)] Loss: 15184.922852\n",
      "Train Epoch: 18 [174720/225000 (78%)] Loss: 14969.945312\n",
      "Train Epoch: 18 [176128/225000 (78%)] Loss: 15053.114258\n",
      "Train Epoch: 18 [177536/225000 (79%)] Loss: 14868.633789\n",
      "Train Epoch: 18 [178944/225000 (80%)] Loss: 14986.783203\n",
      "Train Epoch: 18 [180352/225000 (80%)] Loss: 14831.393555\n",
      "Train Epoch: 18 [181760/225000 (81%)] Loss: 14687.280273\n",
      "Train Epoch: 18 [183168/225000 (81%)] Loss: 14819.289062\n",
      "Train Epoch: 18 [184576/225000 (82%)] Loss: 14746.291016\n",
      "Train Epoch: 18 [185984/225000 (83%)] Loss: 15010.540039\n",
      "Train Epoch: 18 [187392/225000 (83%)] Loss: 14669.509766\n",
      "Train Epoch: 18 [188800/225000 (84%)] Loss: 15566.738281\n",
      "Train Epoch: 18 [190208/225000 (85%)] Loss: 14741.449219\n",
      "Train Epoch: 18 [191616/225000 (85%)] Loss: 15041.464844\n",
      "Train Epoch: 18 [193024/225000 (86%)] Loss: 15334.791992\n",
      "Train Epoch: 18 [194432/225000 (86%)] Loss: 14933.574219\n",
      "Train Epoch: 18 [195840/225000 (87%)] Loss: 15331.298828\n",
      "Train Epoch: 18 [197248/225000 (88%)] Loss: 14645.867188\n",
      "Train Epoch: 18 [198656/225000 (88%)] Loss: 15200.453125\n",
      "Train Epoch: 18 [200064/225000 (89%)] Loss: 14678.254883\n",
      "Train Epoch: 18 [201472/225000 (90%)] Loss: 14764.413086\n",
      "Train Epoch: 18 [202880/225000 (90%)] Loss: 14957.709961\n",
      "Train Epoch: 18 [204288/225000 (91%)] Loss: 15244.034180\n",
      "Train Epoch: 18 [205696/225000 (91%)] Loss: 15348.216797\n",
      "Train Epoch: 18 [207104/225000 (92%)] Loss: 14845.623047\n",
      "Train Epoch: 18 [208512/225000 (93%)] Loss: 15740.487305\n",
      "Train Epoch: 18 [209920/225000 (93%)] Loss: 15557.607422\n",
      "Train Epoch: 18 [211328/225000 (94%)] Loss: 15068.213867\n",
      "Train Epoch: 18 [212736/225000 (95%)] Loss: 15021.866211\n",
      "Train Epoch: 18 [214144/225000 (95%)] Loss: 14605.327148\n",
      "Train Epoch: 18 [215552/225000 (96%)] Loss: 14932.796875\n",
      "Train Epoch: 18 [216960/225000 (96%)] Loss: 15274.337891\n",
      "Train Epoch: 18 [218368/225000 (97%)] Loss: 14431.518555\n",
      "Train Epoch: 18 [219776/225000 (98%)] Loss: 15494.324219\n",
      "Train Epoch: 18 [221184/225000 (98%)] Loss: 15013.439453\n",
      "Train Epoch: 18 [222592/225000 (99%)] Loss: 14833.994141\n",
      "Train Epoch: 18 [224000/225000 (100%)] Loss: 15050.442383\n",
      "    epoch          : 18\n",
      "    loss           : 15093.011287684869\n",
      "    val_loss       : 15073.63014964592\n",
      "Train Epoch: 19 [128/225000 (0%)] Loss: 14811.252930\n",
      "Train Epoch: 19 [1536/225000 (1%)] Loss: 15004.694336\n",
      "Train Epoch: 19 [2944/225000 (1%)] Loss: 15084.056641\n",
      "Train Epoch: 19 [4352/225000 (2%)] Loss: 15099.654297\n",
      "Train Epoch: 19 [5760/225000 (3%)] Loss: 14734.155273\n",
      "Train Epoch: 19 [7168/225000 (3%)] Loss: 15469.323242\n",
      "Train Epoch: 19 [8576/225000 (4%)] Loss: 15162.500977\n",
      "Train Epoch: 19 [9984/225000 (4%)] Loss: 14995.139648\n",
      "Train Epoch: 19 [11392/225000 (5%)] Loss: 14790.771484\n",
      "Train Epoch: 19 [12800/225000 (6%)] Loss: 14569.349609\n",
      "Train Epoch: 19 [14208/225000 (6%)] Loss: 14905.988281\n",
      "Train Epoch: 19 [15616/225000 (7%)] Loss: 15310.980469\n",
      "Train Epoch: 19 [17024/225000 (8%)] Loss: 14769.343750\n",
      "Train Epoch: 19 [18432/225000 (8%)] Loss: 14710.928711\n",
      "Train Epoch: 19 [19840/225000 (9%)] Loss: 14849.888672\n",
      "Train Epoch: 19 [21248/225000 (9%)] Loss: 15203.383789\n",
      "Train Epoch: 19 [22656/225000 (10%)] Loss: 15491.770508\n",
      "Train Epoch: 19 [24064/225000 (11%)] Loss: 14933.902344\n",
      "Train Epoch: 19 [25472/225000 (11%)] Loss: 14913.295898\n",
      "Train Epoch: 19 [26880/225000 (12%)] Loss: 15176.660156\n",
      "Train Epoch: 19 [28288/225000 (13%)] Loss: 15340.187500\n",
      "Train Epoch: 19 [29696/225000 (13%)] Loss: 15321.494141\n",
      "Train Epoch: 19 [31104/225000 (14%)] Loss: 15202.387695\n",
      "Train Epoch: 19 [32512/225000 (14%)] Loss: 15189.442383\n",
      "Train Epoch: 19 [33920/225000 (15%)] Loss: 14845.708984\n",
      "Train Epoch: 19 [35328/225000 (16%)] Loss: 14963.949219\n",
      "Train Epoch: 19 [36736/225000 (16%)] Loss: 15183.320312\n",
      "Train Epoch: 19 [38144/225000 (17%)] Loss: 15499.411133\n",
      "Train Epoch: 19 [39552/225000 (18%)] Loss: 14759.919922\n",
      "Train Epoch: 19 [40960/225000 (18%)] Loss: 14958.162109\n",
      "Train Epoch: 19 [42368/225000 (19%)] Loss: 15101.154297\n",
      "Train Epoch: 19 [43776/225000 (19%)] Loss: 14846.064453\n",
      "Train Epoch: 19 [45184/225000 (20%)] Loss: 14992.191406\n",
      "Train Epoch: 19 [46592/225000 (21%)] Loss: 15012.925781\n",
      "Train Epoch: 19 [48000/225000 (21%)] Loss: 15084.644531\n",
      "Train Epoch: 19 [49408/225000 (22%)] Loss: 15567.035156\n",
      "Train Epoch: 19 [50816/225000 (23%)] Loss: 14667.550781\n",
      "Train Epoch: 19 [52224/225000 (23%)] Loss: 14959.168945\n",
      "Train Epoch: 19 [53632/225000 (24%)] Loss: 14826.224609\n",
      "Train Epoch: 19 [55040/225000 (24%)] Loss: 15359.865234\n",
      "Train Epoch: 19 [56448/225000 (25%)] Loss: 15179.125977\n",
      "Train Epoch: 19 [57856/225000 (26%)] Loss: 15426.778320\n",
      "Train Epoch: 19 [59264/225000 (26%)] Loss: 15490.600586\n",
      "Train Epoch: 19 [60672/225000 (27%)] Loss: 15167.397461\n",
      "Train Epoch: 19 [62080/225000 (28%)] Loss: 15084.582031\n",
      "Train Epoch: 19 [63488/225000 (28%)] Loss: 15073.231445\n",
      "Train Epoch: 19 [64896/225000 (29%)] Loss: 15503.872070\n",
      "Train Epoch: 19 [66304/225000 (29%)] Loss: 14844.162109\n",
      "Train Epoch: 19 [67712/225000 (30%)] Loss: 15469.280273\n",
      "Train Epoch: 19 [69120/225000 (31%)] Loss: 15230.575195\n",
      "Train Epoch: 19 [70528/225000 (31%)] Loss: 15057.279297\n",
      "Train Epoch: 19 [71936/225000 (32%)] Loss: 15015.651367\n",
      "Train Epoch: 19 [73344/225000 (33%)] Loss: 15165.730469\n",
      "Train Epoch: 19 [74752/225000 (33%)] Loss: 15312.472656\n",
      "Train Epoch: 19 [76160/225000 (34%)] Loss: 15777.527344\n",
      "Train Epoch: 19 [77568/225000 (34%)] Loss: 15348.226562\n",
      "Train Epoch: 19 [78976/225000 (35%)] Loss: 15296.577148\n",
      "Train Epoch: 19 [80384/225000 (36%)] Loss: 15055.346680\n",
      "Train Epoch: 19 [81792/225000 (36%)] Loss: 15193.946289\n",
      "Train Epoch: 19 [83200/225000 (37%)] Loss: 14972.318359\n",
      "Train Epoch: 19 [84608/225000 (38%)] Loss: 14974.845703\n",
      "Train Epoch: 19 [86016/225000 (38%)] Loss: 15497.838867\n",
      "Train Epoch: 19 [87424/225000 (39%)] Loss: 15829.547852\n",
      "Train Epoch: 19 [88832/225000 (39%)] Loss: 15392.398438\n",
      "Train Epoch: 19 [90240/225000 (40%)] Loss: 15573.348633\n",
      "Train Epoch: 19 [91648/225000 (41%)] Loss: 15044.351562\n",
      "Train Epoch: 19 [93056/225000 (41%)] Loss: 15300.630859\n",
      "Train Epoch: 19 [94464/225000 (42%)] Loss: 15133.595703\n",
      "Train Epoch: 19 [95872/225000 (43%)] Loss: 15514.503906\n",
      "Train Epoch: 19 [97280/225000 (43%)] Loss: 15001.658203\n",
      "Train Epoch: 19 [98688/225000 (44%)] Loss: 15070.441406\n",
      "Train Epoch: 19 [100096/225000 (44%)] Loss: 15204.010742\n",
      "Train Epoch: 19 [101504/225000 (45%)] Loss: 15414.050781\n",
      "Train Epoch: 19 [102912/225000 (46%)] Loss: 14866.361328\n",
      "Train Epoch: 19 [104320/225000 (46%)] Loss: 15281.034180\n",
      "Train Epoch: 19 [105728/225000 (47%)] Loss: 15677.510742\n",
      "Train Epoch: 19 [107136/225000 (48%)] Loss: 15046.324219\n",
      "Train Epoch: 19 [108544/225000 (48%)] Loss: 15022.885742\n",
      "Train Epoch: 19 [109952/225000 (49%)] Loss: 15315.395508\n",
      "Train Epoch: 19 [111360/225000 (49%)] Loss: 15313.288086\n",
      "Train Epoch: 19 [112768/225000 (50%)] Loss: 15041.020508\n",
      "Train Epoch: 19 [114176/225000 (51%)] Loss: 14898.929688\n",
      "Train Epoch: 19 [115584/225000 (51%)] Loss: 14581.450195\n",
      "Train Epoch: 19 [116992/225000 (52%)] Loss: 15012.509766\n",
      "Train Epoch: 19 [118400/225000 (53%)] Loss: 14965.862305\n",
      "Train Epoch: 19 [119808/225000 (53%)] Loss: 14949.073242\n",
      "Train Epoch: 19 [121216/225000 (54%)] Loss: 15165.126953\n",
      "Train Epoch: 19 [122624/225000 (54%)] Loss: 14823.401367\n",
      "Train Epoch: 19 [124032/225000 (55%)] Loss: 15145.335938\n",
      "Train Epoch: 19 [125440/225000 (56%)] Loss: 14991.225586\n",
      "Train Epoch: 19 [126848/225000 (56%)] Loss: 14956.051758\n",
      "Train Epoch: 19 [128256/225000 (57%)] Loss: 14787.967773\n",
      "Train Epoch: 19 [129664/225000 (58%)] Loss: 15114.338867\n",
      "Train Epoch: 19 [131072/225000 (58%)] Loss: 15050.067383\n",
      "Train Epoch: 19 [132480/225000 (59%)] Loss: 15622.885742\n",
      "Train Epoch: 19 [133888/225000 (60%)] Loss: 15279.252930\n",
      "Train Epoch: 19 [135296/225000 (60%)] Loss: 15574.793945\n",
      "Train Epoch: 19 [136704/225000 (61%)] Loss: 14918.195312\n",
      "Train Epoch: 19 [138112/225000 (61%)] Loss: 14876.613281\n",
      "Train Epoch: 19 [139520/225000 (62%)] Loss: 15001.077148\n",
      "Train Epoch: 19 [140928/225000 (63%)] Loss: 15330.409180\n",
      "Train Epoch: 19 [142336/225000 (63%)] Loss: 15217.096680\n",
      "Train Epoch: 19 [143744/225000 (64%)] Loss: 15177.200195\n",
      "Train Epoch: 19 [145152/225000 (65%)] Loss: 15214.509766\n",
      "Train Epoch: 19 [146560/225000 (65%)] Loss: 14935.750000\n",
      "Train Epoch: 19 [147968/225000 (66%)] Loss: 15393.431641\n",
      "Train Epoch: 19 [149376/225000 (66%)] Loss: 14474.939453\n",
      "Train Epoch: 19 [150784/225000 (67%)] Loss: 15661.475586\n",
      "Train Epoch: 19 [152192/225000 (68%)] Loss: 14913.153320\n",
      "Train Epoch: 19 [153600/225000 (68%)] Loss: 15420.313477\n",
      "Train Epoch: 19 [155008/225000 (69%)] Loss: 15076.340820\n",
      "Train Epoch: 19 [156416/225000 (70%)] Loss: 15393.523438\n",
      "Train Epoch: 19 [157824/225000 (70%)] Loss: 15188.484375\n",
      "Train Epoch: 19 [159232/225000 (71%)] Loss: 15255.889648\n",
      "Train Epoch: 19 [160640/225000 (71%)] Loss: 14996.783203\n",
      "Train Epoch: 19 [162048/225000 (72%)] Loss: 15036.733398\n",
      "Train Epoch: 19 [163456/225000 (73%)] Loss: 14711.946289\n",
      "Train Epoch: 19 [164864/225000 (73%)] Loss: 15447.540039\n",
      "Train Epoch: 19 [166272/225000 (74%)] Loss: 15161.360352\n",
      "Train Epoch: 19 [167680/225000 (75%)] Loss: 14754.198242\n",
      "Train Epoch: 19 [169088/225000 (75%)] Loss: 15547.931641\n",
      "Train Epoch: 19 [170496/225000 (76%)] Loss: 14796.335938\n",
      "Train Epoch: 19 [171904/225000 (76%)] Loss: 14890.971680\n",
      "Train Epoch: 19 [173312/225000 (77%)] Loss: 15365.540039\n",
      "Train Epoch: 19 [174720/225000 (78%)] Loss: 15548.405273\n",
      "Train Epoch: 19 [176128/225000 (78%)] Loss: 15125.666992\n",
      "Train Epoch: 19 [177536/225000 (79%)] Loss: 14888.579102\n",
      "Train Epoch: 19 [178944/225000 (80%)] Loss: 15200.138672\n",
      "Train Epoch: 19 [180352/225000 (80%)] Loss: 15270.045898\n",
      "Train Epoch: 19 [181760/225000 (81%)] Loss: 15153.487305\n",
      "Train Epoch: 19 [183168/225000 (81%)] Loss: 14844.528320\n",
      "Train Epoch: 19 [184576/225000 (82%)] Loss: 14951.188477\n",
      "Train Epoch: 19 [185984/225000 (83%)] Loss: 14878.916016\n",
      "Train Epoch: 19 [187392/225000 (83%)] Loss: 15245.981445\n",
      "Train Epoch: 19 [188800/225000 (84%)] Loss: 14980.604492\n",
      "Train Epoch: 19 [190208/225000 (85%)] Loss: 15135.343750\n",
      "Train Epoch: 19 [191616/225000 (85%)] Loss: 14975.951172\n",
      "Train Epoch: 19 [193024/225000 (86%)] Loss: 15422.429688\n",
      "Train Epoch: 19 [194432/225000 (86%)] Loss: 15213.656250\n",
      "Train Epoch: 19 [195840/225000 (87%)] Loss: 15022.125977\n",
      "Train Epoch: 19 [197248/225000 (88%)] Loss: 14982.765625\n",
      "Train Epoch: 19 [198656/225000 (88%)] Loss: 14837.028320\n",
      "Train Epoch: 19 [200064/225000 (89%)] Loss: 15301.572266\n",
      "Train Epoch: 19 [201472/225000 (90%)] Loss: 14900.552734\n",
      "Train Epoch: 19 [202880/225000 (90%)] Loss: 14994.702148\n",
      "Train Epoch: 19 [204288/225000 (91%)] Loss: 14924.942383\n",
      "Train Epoch: 19 [205696/225000 (91%)] Loss: 15143.844727\n",
      "Train Epoch: 19 [207104/225000 (92%)] Loss: 14798.749023\n",
      "Train Epoch: 19 [208512/225000 (93%)] Loss: 15240.162109\n",
      "Train Epoch: 19 [209920/225000 (93%)] Loss: 14772.038086\n",
      "Train Epoch: 19 [211328/225000 (94%)] Loss: 14856.261719\n",
      "Train Epoch: 19 [212736/225000 (95%)] Loss: 15497.241211\n",
      "Train Epoch: 19 [214144/225000 (95%)] Loss: 15359.538086\n",
      "Train Epoch: 19 [215552/225000 (96%)] Loss: 14727.209961\n",
      "Train Epoch: 19 [216960/225000 (96%)] Loss: 15304.320312\n",
      "Train Epoch: 19 [218368/225000 (97%)] Loss: 14898.802734\n",
      "Train Epoch: 19 [219776/225000 (98%)] Loss: 14925.910156\n",
      "Train Epoch: 19 [221184/225000 (98%)] Loss: 15114.993164\n",
      "Train Epoch: 19 [222592/225000 (99%)] Loss: 15085.115234\n",
      "Train Epoch: 19 [224000/225000 (100%)] Loss: 15074.070312\n",
      "    epoch          : 19\n",
      "    loss           : 15095.083908272007\n",
      "    val_loss       : 15068.422655491804\n",
      "Train Epoch: 20 [128/225000 (0%)] Loss: 15386.534180\n",
      "Train Epoch: 20 [1536/225000 (1%)] Loss: 14977.531250\n",
      "Train Epoch: 20 [2944/225000 (1%)] Loss: 15216.152344\n",
      "Train Epoch: 20 [4352/225000 (2%)] Loss: 14775.579102\n",
      "Train Epoch: 20 [5760/225000 (3%)] Loss: 15093.508789\n",
      "Train Epoch: 20 [7168/225000 (3%)] Loss: 15156.782227\n",
      "Train Epoch: 20 [8576/225000 (4%)] Loss: 15231.578125\n",
      "Train Epoch: 20 [9984/225000 (4%)] Loss: 15099.017578\n",
      "Train Epoch: 20 [11392/225000 (5%)] Loss: 15527.262695\n",
      "Train Epoch: 20 [12800/225000 (6%)] Loss: 15080.753906\n",
      "Train Epoch: 20 [14208/225000 (6%)] Loss: 14921.152344\n",
      "Train Epoch: 20 [15616/225000 (7%)] Loss: 15329.875977\n",
      "Train Epoch: 20 [17024/225000 (8%)] Loss: 15213.011719\n",
      "Train Epoch: 20 [18432/225000 (8%)] Loss: 15311.403320\n",
      "Train Epoch: 20 [19840/225000 (9%)] Loss: 14670.743164\n",
      "Train Epoch: 20 [21248/225000 (9%)] Loss: 14890.645508\n",
      "Train Epoch: 20 [22656/225000 (10%)] Loss: 14989.267578\n",
      "Train Epoch: 20 [24064/225000 (11%)] Loss: 15247.204102\n",
      "Train Epoch: 20 [25472/225000 (11%)] Loss: 14969.137695\n",
      "Train Epoch: 20 [26880/225000 (12%)] Loss: 15005.659180\n",
      "Train Epoch: 20 [28288/225000 (13%)] Loss: 15270.212891\n",
      "Train Epoch: 20 [29696/225000 (13%)] Loss: 15574.509766\n",
      "Train Epoch: 20 [31104/225000 (14%)] Loss: 15017.598633\n",
      "Train Epoch: 20 [32512/225000 (14%)] Loss: 15284.804688\n",
      "Train Epoch: 20 [33920/225000 (15%)] Loss: 15678.993164\n",
      "Train Epoch: 20 [35328/225000 (16%)] Loss: 15074.185547\n",
      "Train Epoch: 20 [36736/225000 (16%)] Loss: 14706.658203\n",
      "Train Epoch: 20 [38144/225000 (17%)] Loss: 14557.103516\n",
      "Train Epoch: 20 [39552/225000 (18%)] Loss: 15434.709961\n",
      "Train Epoch: 20 [40960/225000 (18%)] Loss: 14928.776367\n",
      "Train Epoch: 20 [42368/225000 (19%)] Loss: 14873.170898\n",
      "Train Epoch: 20 [43776/225000 (19%)] Loss: 14747.208984\n",
      "Train Epoch: 20 [45184/225000 (20%)] Loss: 15092.668945\n",
      "Train Epoch: 20 [46592/225000 (21%)] Loss: 14879.360352\n",
      "Train Epoch: 20 [48000/225000 (21%)] Loss: 14562.111328\n",
      "Train Epoch: 20 [49408/225000 (22%)] Loss: 15619.833984\n",
      "Train Epoch: 20 [50816/225000 (23%)] Loss: 14829.627930\n",
      "Train Epoch: 20 [52224/225000 (23%)] Loss: 15619.025391\n",
      "Train Epoch: 20 [53632/225000 (24%)] Loss: 14899.321289\n",
      "Train Epoch: 20 [55040/225000 (24%)] Loss: 15648.235352\n",
      "Train Epoch: 20 [56448/225000 (25%)] Loss: 14948.847656\n",
      "Train Epoch: 20 [57856/225000 (26%)] Loss: 15089.416016\n",
      "Train Epoch: 20 [59264/225000 (26%)] Loss: 15129.961914\n",
      "Train Epoch: 20 [60672/225000 (27%)] Loss: 15127.944336\n",
      "Train Epoch: 20 [62080/225000 (28%)] Loss: 14884.033203\n",
      "Train Epoch: 20 [63488/225000 (28%)] Loss: 15389.928711\n",
      "Train Epoch: 20 [64896/225000 (29%)] Loss: 15003.180664\n",
      "Train Epoch: 20 [66304/225000 (29%)] Loss: 15314.432617\n",
      "Train Epoch: 20 [67712/225000 (30%)] Loss: 14950.725586\n",
      "Train Epoch: 20 [69120/225000 (31%)] Loss: 15486.963867\n",
      "Train Epoch: 20 [70528/225000 (31%)] Loss: 15256.406250\n",
      "Train Epoch: 20 [71936/225000 (32%)] Loss: 15015.160156\n",
      "Train Epoch: 20 [73344/225000 (33%)] Loss: 15301.016602\n",
      "Train Epoch: 20 [74752/225000 (33%)] Loss: 14918.782227\n",
      "Train Epoch: 20 [76160/225000 (34%)] Loss: 15186.405273\n",
      "Train Epoch: 20 [77568/225000 (34%)] Loss: 15149.360352\n",
      "Train Epoch: 20 [78976/225000 (35%)] Loss: 15055.192383\n",
      "Train Epoch: 20 [80384/225000 (36%)] Loss: 15235.835938\n",
      "Train Epoch: 20 [81792/225000 (36%)] Loss: 15771.858398\n",
      "Train Epoch: 20 [83200/225000 (37%)] Loss: 14962.761719\n",
      "Train Epoch: 20 [84608/225000 (38%)] Loss: 15028.139648\n",
      "Train Epoch: 20 [86016/225000 (38%)] Loss: 14844.822266\n",
      "Train Epoch: 20 [87424/225000 (39%)] Loss: 15154.405273\n",
      "Train Epoch: 20 [88832/225000 (39%)] Loss: 14894.899414\n",
      "Train Epoch: 20 [90240/225000 (40%)] Loss: 14870.946289\n",
      "Train Epoch: 20 [91648/225000 (41%)] Loss: 15346.400391\n",
      "Train Epoch: 20 [93056/225000 (41%)] Loss: 14944.638672\n",
      "Train Epoch: 20 [94464/225000 (42%)] Loss: 15474.721680\n",
      "Train Epoch: 20 [95872/225000 (43%)] Loss: 14855.032227\n",
      "Train Epoch: 20 [97280/225000 (43%)] Loss: 14885.136719\n",
      "Train Epoch: 20 [98688/225000 (44%)] Loss: 15602.293945\n",
      "Train Epoch: 20 [100096/225000 (44%)] Loss: 14958.409180\n",
      "Train Epoch: 20 [101504/225000 (45%)] Loss: 14857.685547\n",
      "Train Epoch: 20 [102912/225000 (46%)] Loss: 14991.230469\n",
      "Train Epoch: 20 [104320/225000 (46%)] Loss: 15340.398438\n",
      "Train Epoch: 20 [105728/225000 (47%)] Loss: 15243.879883\n",
      "Train Epoch: 20 [107136/225000 (48%)] Loss: 15102.129883\n",
      "Train Epoch: 20 [108544/225000 (48%)] Loss: 14859.025391\n",
      "Train Epoch: 20 [109952/225000 (49%)] Loss: 15435.451172\n",
      "Train Epoch: 20 [111360/225000 (49%)] Loss: 14900.567383\n",
      "Train Epoch: 20 [112768/225000 (50%)] Loss: 15107.512695\n",
      "Train Epoch: 20 [114176/225000 (51%)] Loss: 15412.057617\n",
      "Train Epoch: 20 [115584/225000 (51%)] Loss: 15021.527344\n",
      "Train Epoch: 20 [116992/225000 (52%)] Loss: 15368.404297\n",
      "Train Epoch: 20 [118400/225000 (53%)] Loss: 14783.905273\n",
      "Train Epoch: 20 [119808/225000 (53%)] Loss: 15346.470703\n",
      "Train Epoch: 20 [121216/225000 (54%)] Loss: 15307.741211\n",
      "Train Epoch: 20 [122624/225000 (54%)] Loss: 14776.931641\n",
      "Train Epoch: 20 [124032/225000 (55%)] Loss: 15174.655273\n",
      "Train Epoch: 20 [125440/225000 (56%)] Loss: 14965.882812\n",
      "Train Epoch: 20 [126848/225000 (56%)] Loss: 15424.936523\n",
      "Train Epoch: 20 [128256/225000 (57%)] Loss: 15045.736328\n",
      "Train Epoch: 20 [129664/225000 (58%)] Loss: 15026.543945\n",
      "Train Epoch: 20 [131072/225000 (58%)] Loss: 15079.270508\n",
      "Train Epoch: 20 [132480/225000 (59%)] Loss: 15348.132812\n",
      "Train Epoch: 20 [133888/225000 (60%)] Loss: 14869.978516\n",
      "Train Epoch: 20 [135296/225000 (60%)] Loss: 15360.852539\n",
      "Train Epoch: 20 [136704/225000 (61%)] Loss: 14769.208008\n",
      "Train Epoch: 20 [138112/225000 (61%)] Loss: 15006.904297\n",
      "Train Epoch: 20 [139520/225000 (62%)] Loss: 15088.807617\n",
      "Train Epoch: 20 [140928/225000 (63%)] Loss: 15325.809570\n",
      "Train Epoch: 20 [142336/225000 (63%)] Loss: 15270.333008\n",
      "Train Epoch: 20 [143744/225000 (64%)] Loss: 14882.917969\n",
      "Train Epoch: 20 [145152/225000 (65%)] Loss: 15199.536133\n",
      "Train Epoch: 20 [146560/225000 (65%)] Loss: 14736.704102\n",
      "Train Epoch: 20 [147968/225000 (66%)] Loss: 15469.291992\n",
      "Train Epoch: 20 [149376/225000 (66%)] Loss: 14998.947266\n",
      "Train Epoch: 20 [150784/225000 (67%)] Loss: 15114.371094\n",
      "Train Epoch: 20 [152192/225000 (68%)] Loss: 14961.060547\n",
      "Train Epoch: 20 [153600/225000 (68%)] Loss: 14873.571289\n",
      "Train Epoch: 20 [155008/225000 (69%)] Loss: 14775.713867\n",
      "Train Epoch: 20 [156416/225000 (70%)] Loss: 15161.622070\n",
      "Train Epoch: 20 [157824/225000 (70%)] Loss: 15074.324219\n",
      "Train Epoch: 20 [159232/225000 (71%)] Loss: 15389.229492\n",
      "Train Epoch: 20 [160640/225000 (71%)] Loss: 15318.612305\n",
      "Train Epoch: 20 [162048/225000 (72%)] Loss: 15168.923828\n",
      "Train Epoch: 20 [163456/225000 (73%)] Loss: 15312.289062\n",
      "Train Epoch: 20 [164864/225000 (73%)] Loss: 15149.610352\n",
      "Train Epoch: 20 [166272/225000 (74%)] Loss: 14508.522461\n",
      "Train Epoch: 20 [167680/225000 (75%)] Loss: 15094.943359\n",
      "Train Epoch: 20 [169088/225000 (75%)] Loss: 15057.206055\n",
      "Train Epoch: 20 [170496/225000 (76%)] Loss: 15566.684570\n",
      "Train Epoch: 20 [171904/225000 (76%)] Loss: 14532.457031\n",
      "Train Epoch: 20 [173312/225000 (77%)] Loss: 14863.737305\n",
      "Train Epoch: 20 [174720/225000 (78%)] Loss: 14940.647461\n",
      "Train Epoch: 20 [176128/225000 (78%)] Loss: 14752.577148\n",
      "Train Epoch: 20 [177536/225000 (79%)] Loss: 15136.597656\n",
      "Train Epoch: 20 [178944/225000 (80%)] Loss: 15075.824219\n",
      "Train Epoch: 20 [180352/225000 (80%)] Loss: 14857.550781\n",
      "Train Epoch: 20 [181760/225000 (81%)] Loss: 14962.798828\n",
      "Train Epoch: 20 [183168/225000 (81%)] Loss: 14658.416016\n",
      "Train Epoch: 20 [184576/225000 (82%)] Loss: 15183.662109\n",
      "Train Epoch: 20 [185984/225000 (83%)] Loss: 15492.828125\n",
      "Train Epoch: 20 [187392/225000 (83%)] Loss: 14904.769531\n",
      "Train Epoch: 20 [188800/225000 (84%)] Loss: 15229.663086\n",
      "Train Epoch: 20 [190208/225000 (85%)] Loss: 14856.166016\n",
      "Train Epoch: 20 [191616/225000 (85%)] Loss: 14745.840820\n",
      "Train Epoch: 20 [193024/225000 (86%)] Loss: 15124.685547\n",
      "Train Epoch: 20 [194432/225000 (86%)] Loss: 15440.586914\n",
      "Train Epoch: 20 [195840/225000 (87%)] Loss: 15316.245117\n",
      "Train Epoch: 20 [197248/225000 (88%)] Loss: 14652.517578\n",
      "Train Epoch: 20 [198656/225000 (88%)] Loss: 14644.296875\n",
      "Train Epoch: 20 [200064/225000 (89%)] Loss: 15061.752930\n",
      "Train Epoch: 20 [201472/225000 (90%)] Loss: 15006.498047\n",
      "Train Epoch: 20 [202880/225000 (90%)] Loss: 15446.791016\n",
      "Train Epoch: 20 [204288/225000 (91%)] Loss: 15000.497070\n",
      "Train Epoch: 20 [205696/225000 (91%)] Loss: 14801.442383\n",
      "Train Epoch: 20 [207104/225000 (92%)] Loss: 15288.654297\n",
      "Train Epoch: 20 [208512/225000 (93%)] Loss: 14972.149414\n",
      "Train Epoch: 20 [209920/225000 (93%)] Loss: 15135.859375\n",
      "Train Epoch: 20 [211328/225000 (94%)] Loss: 14893.734375\n",
      "Train Epoch: 20 [212736/225000 (95%)] Loss: 15457.793945\n",
      "Train Epoch: 20 [214144/225000 (95%)] Loss: 14757.701172\n",
      "Train Epoch: 20 [215552/225000 (96%)] Loss: 14776.161133\n",
      "Train Epoch: 20 [216960/225000 (96%)] Loss: 15164.695312\n",
      "Train Epoch: 20 [218368/225000 (97%)] Loss: 15860.422852\n",
      "Train Epoch: 20 [219776/225000 (98%)] Loss: 15319.324219\n",
      "Train Epoch: 20 [221184/225000 (98%)] Loss: 14711.376953\n",
      "Train Epoch: 20 [222592/225000 (99%)] Loss: 15041.891602\n",
      "Train Epoch: 20 [224000/225000 (100%)] Loss: 15198.352539\n",
      "    epoch          : 20\n",
      "    loss           : 15097.441623449055\n",
      "    val_loss       : 15073.55047983965\n",
      "Train Epoch: 21 [128/225000 (0%)] Loss: 15016.129883\n",
      "Train Epoch: 21 [1536/225000 (1%)] Loss: 15300.606445\n",
      "Train Epoch: 21 [2944/225000 (1%)] Loss: 15000.543945\n",
      "Train Epoch: 21 [4352/225000 (2%)] Loss: 15072.670898\n",
      "Train Epoch: 21 [5760/225000 (3%)] Loss: 15492.217773\n",
      "Train Epoch: 21 [7168/225000 (3%)] Loss: 15228.718750\n",
      "Train Epoch: 21 [8576/225000 (4%)] Loss: 15474.567383\n",
      "Train Epoch: 21 [9984/225000 (4%)] Loss: 15144.690430\n",
      "Train Epoch: 21 [11392/225000 (5%)] Loss: 15104.768555\n",
      "Train Epoch: 21 [12800/225000 (6%)] Loss: 15256.500000\n",
      "Train Epoch: 21 [14208/225000 (6%)] Loss: 15702.734375\n",
      "Train Epoch: 21 [15616/225000 (7%)] Loss: 15222.845703\n",
      "Train Epoch: 21 [17024/225000 (8%)] Loss: 14939.365234\n",
      "Train Epoch: 21 [18432/225000 (8%)] Loss: 14847.646484\n",
      "Train Epoch: 21 [19840/225000 (9%)] Loss: 14847.139648\n",
      "Train Epoch: 21 [21248/225000 (9%)] Loss: 15445.205078\n",
      "Train Epoch: 21 [22656/225000 (10%)] Loss: 15448.343750\n",
      "Train Epoch: 21 [24064/225000 (11%)] Loss: 15052.348633\n",
      "Train Epoch: 21 [25472/225000 (11%)] Loss: 15185.387695\n",
      "Train Epoch: 21 [26880/225000 (12%)] Loss: 15359.661133\n",
      "Train Epoch: 21 [28288/225000 (13%)] Loss: 15270.543945\n",
      "Train Epoch: 21 [29696/225000 (13%)] Loss: 14869.440430\n",
      "Train Epoch: 21 [31104/225000 (14%)] Loss: 14647.699219\n",
      "Train Epoch: 21 [32512/225000 (14%)] Loss: 15550.025391\n",
      "Train Epoch: 21 [33920/225000 (15%)] Loss: 15233.907227\n",
      "Train Epoch: 21 [35328/225000 (16%)] Loss: 14991.638672\n",
      "Train Epoch: 21 [36736/225000 (16%)] Loss: 15292.070312\n",
      "Train Epoch: 21 [38144/225000 (17%)] Loss: 15079.955078\n",
      "Train Epoch: 21 [39552/225000 (18%)] Loss: 15068.585938\n",
      "Train Epoch: 21 [40960/225000 (18%)] Loss: 15031.350586\n",
      "Train Epoch: 21 [42368/225000 (19%)] Loss: 14801.401367\n",
      "Train Epoch: 21 [43776/225000 (19%)] Loss: 15389.492188\n",
      "Train Epoch: 21 [45184/225000 (20%)] Loss: 15369.086914\n",
      "Train Epoch: 21 [46592/225000 (21%)] Loss: 14806.670898\n",
      "Train Epoch: 21 [48000/225000 (21%)] Loss: 15356.884766\n",
      "Train Epoch: 21 [49408/225000 (22%)] Loss: 14558.024414\n",
      "Train Epoch: 21 [50816/225000 (23%)] Loss: 15042.187500\n",
      "Train Epoch: 21 [52224/225000 (23%)] Loss: 15141.334961\n",
      "Train Epoch: 21 [53632/225000 (24%)] Loss: 15385.106445\n",
      "Train Epoch: 21 [55040/225000 (24%)] Loss: 14887.411133\n",
      "Train Epoch: 21 [56448/225000 (25%)] Loss: 15134.142578\n",
      "Train Epoch: 21 [57856/225000 (26%)] Loss: 14762.754883\n",
      "Train Epoch: 21 [59264/225000 (26%)] Loss: 14669.320312\n",
      "Train Epoch: 21 [60672/225000 (27%)] Loss: 15036.818359\n",
      "Train Epoch: 21 [62080/225000 (28%)] Loss: 14677.218750\n",
      "Train Epoch: 21 [63488/225000 (28%)] Loss: 14916.195312\n",
      "Train Epoch: 21 [64896/225000 (29%)] Loss: 15295.869141\n",
      "Train Epoch: 21 [66304/225000 (29%)] Loss: 15297.172852\n",
      "Train Epoch: 21 [67712/225000 (30%)] Loss: 14849.160156\n",
      "Train Epoch: 21 [69120/225000 (31%)] Loss: 15256.454102\n",
      "Train Epoch: 21 [70528/225000 (31%)] Loss: 15534.799805\n",
      "Train Epoch: 21 [71936/225000 (32%)] Loss: 15393.686523\n",
      "Train Epoch: 21 [73344/225000 (33%)] Loss: 14687.610352\n",
      "Train Epoch: 21 [74752/225000 (33%)] Loss: 15150.577148\n",
      "Train Epoch: 21 [76160/225000 (34%)] Loss: 14827.879883\n",
      "Train Epoch: 21 [77568/225000 (34%)] Loss: 14963.315430\n",
      "Train Epoch: 21 [78976/225000 (35%)] Loss: 15164.161133\n",
      "Train Epoch: 21 [80384/225000 (36%)] Loss: 15194.889648\n",
      "Train Epoch: 21 [81792/225000 (36%)] Loss: 14915.375977\n",
      "Train Epoch: 21 [83200/225000 (37%)] Loss: 15178.979492\n",
      "Train Epoch: 21 [84608/225000 (38%)] Loss: 15283.870117\n",
      "Train Epoch: 21 [86016/225000 (38%)] Loss: 15370.312500\n",
      "Train Epoch: 21 [87424/225000 (39%)] Loss: 14806.697266\n",
      "Train Epoch: 21 [88832/225000 (39%)] Loss: 15596.946289\n",
      "Train Epoch: 21 [90240/225000 (40%)] Loss: 15253.106445\n",
      "Train Epoch: 21 [91648/225000 (41%)] Loss: 15217.980469\n",
      "Train Epoch: 21 [93056/225000 (41%)] Loss: 15018.589844\n",
      "Train Epoch: 21 [94464/225000 (42%)] Loss: 14671.681641\n",
      "Train Epoch: 21 [95872/225000 (43%)] Loss: 15423.474609\n",
      "Train Epoch: 21 [97280/225000 (43%)] Loss: 15113.665039\n",
      "Train Epoch: 21 [98688/225000 (44%)] Loss: 14854.163086\n",
      "Train Epoch: 21 [100096/225000 (44%)] Loss: 14799.545898\n",
      "Train Epoch: 21 [101504/225000 (45%)] Loss: 15142.620117\n",
      "Train Epoch: 21 [102912/225000 (46%)] Loss: 15506.949219\n",
      "Train Epoch: 21 [104320/225000 (46%)] Loss: 15358.136719\n",
      "Train Epoch: 21 [105728/225000 (47%)] Loss: 15180.040039\n",
      "Train Epoch: 21 [107136/225000 (48%)] Loss: 15252.563477\n",
      "Train Epoch: 21 [108544/225000 (48%)] Loss: 15144.495117\n",
      "Train Epoch: 21 [109952/225000 (49%)] Loss: 15285.067383\n",
      "Train Epoch: 21 [111360/225000 (49%)] Loss: 15067.856445\n",
      "Train Epoch: 21 [112768/225000 (50%)] Loss: 15050.750977\n",
      "Train Epoch: 21 [114176/225000 (51%)] Loss: 15154.177734\n",
      "Train Epoch: 21 [115584/225000 (51%)] Loss: 15265.443359\n",
      "Train Epoch: 21 [116992/225000 (52%)] Loss: 15618.478516\n",
      "Train Epoch: 21 [118400/225000 (53%)] Loss: 15429.899414\n",
      "Train Epoch: 21 [119808/225000 (53%)] Loss: 14909.067383\n",
      "Train Epoch: 21 [121216/225000 (54%)] Loss: 15033.420898\n",
      "Train Epoch: 21 [122624/225000 (54%)] Loss: 15229.331055\n",
      "Train Epoch: 21 [124032/225000 (55%)] Loss: 14808.949219\n",
      "Train Epoch: 21 [125440/225000 (56%)] Loss: 15166.751953\n",
      "Train Epoch: 21 [126848/225000 (56%)] Loss: 14803.641602\n",
      "Train Epoch: 21 [128256/225000 (57%)] Loss: 14986.411133\n",
      "Train Epoch: 21 [129664/225000 (58%)] Loss: 14867.120117\n",
      "Train Epoch: 21 [131072/225000 (58%)] Loss: 15198.059570\n",
      "Train Epoch: 21 [132480/225000 (59%)] Loss: 15074.038086\n",
      "Train Epoch: 21 [133888/225000 (60%)] Loss: 14952.953125\n",
      "Train Epoch: 21 [135296/225000 (60%)] Loss: 15072.968750\n",
      "Train Epoch: 21 [136704/225000 (61%)] Loss: 15366.138672\n",
      "Train Epoch: 21 [138112/225000 (61%)] Loss: 14871.924805\n",
      "Train Epoch: 21 [139520/225000 (62%)] Loss: 15200.124023\n",
      "Train Epoch: 21 [140928/225000 (63%)] Loss: 14859.428711\n",
      "Train Epoch: 21 [142336/225000 (63%)] Loss: 14808.860352\n",
      "Train Epoch: 21 [143744/225000 (64%)] Loss: 15038.535156\n",
      "Train Epoch: 21 [145152/225000 (65%)] Loss: 15051.636719\n",
      "Train Epoch: 21 [146560/225000 (65%)] Loss: 15074.982422\n",
      "Train Epoch: 21 [147968/225000 (66%)] Loss: 14999.165039\n",
      "Train Epoch: 21 [149376/225000 (66%)] Loss: 15114.946289\n",
      "Train Epoch: 21 [150784/225000 (67%)] Loss: 14780.782227\n",
      "Train Epoch: 21 [152192/225000 (68%)] Loss: 15048.713867\n",
      "Train Epoch: 21 [153600/225000 (68%)] Loss: 15310.160156\n",
      "Train Epoch: 21 [155008/225000 (69%)] Loss: 15123.142578\n",
      "Train Epoch: 21 [156416/225000 (70%)] Loss: 14866.628906\n",
      "Train Epoch: 21 [157824/225000 (70%)] Loss: 14936.053711\n",
      "Train Epoch: 21 [159232/225000 (71%)] Loss: 15004.842773\n",
      "Train Epoch: 21 [160640/225000 (71%)] Loss: 14756.750000\n",
      "Train Epoch: 21 [162048/225000 (72%)] Loss: 15572.564453\n",
      "Train Epoch: 21 [163456/225000 (73%)] Loss: 15279.479492\n",
      "Train Epoch: 21 [164864/225000 (73%)] Loss: 15335.670898\n",
      "Train Epoch: 21 [166272/225000 (74%)] Loss: 14950.672852\n",
      "Train Epoch: 21 [167680/225000 (75%)] Loss: 15090.902344\n",
      "Train Epoch: 21 [169088/225000 (75%)] Loss: 15019.772461\n",
      "Train Epoch: 21 [170496/225000 (76%)] Loss: 14669.505859\n",
      "Train Epoch: 21 [171904/225000 (76%)] Loss: 14969.597656\n",
      "Train Epoch: 21 [173312/225000 (77%)] Loss: 15379.530273\n",
      "Train Epoch: 21 [174720/225000 (78%)] Loss: 15018.734375\n",
      "Train Epoch: 21 [176128/225000 (78%)] Loss: 15056.787109\n",
      "Train Epoch: 21 [177536/225000 (79%)] Loss: 14838.448242\n",
      "Train Epoch: 21 [178944/225000 (80%)] Loss: 15122.307617\n",
      "Train Epoch: 21 [180352/225000 (80%)] Loss: 15026.984375\n",
      "Train Epoch: 21 [181760/225000 (81%)] Loss: 14965.711914\n",
      "Train Epoch: 21 [183168/225000 (81%)] Loss: 15036.620117\n",
      "Train Epoch: 21 [184576/225000 (82%)] Loss: 15673.255859\n",
      "Train Epoch: 21 [185984/225000 (83%)] Loss: 15052.423828\n",
      "Train Epoch: 21 [187392/225000 (83%)] Loss: 15166.542969\n",
      "Train Epoch: 21 [188800/225000 (84%)] Loss: 14978.499023\n",
      "Train Epoch: 21 [190208/225000 (85%)] Loss: 15106.247070\n",
      "Train Epoch: 21 [191616/225000 (85%)] Loss: 15245.226562\n",
      "Train Epoch: 21 [193024/225000 (86%)] Loss: 15032.690430\n",
      "Train Epoch: 21 [194432/225000 (86%)] Loss: 15181.813477\n",
      "Train Epoch: 21 [195840/225000 (87%)] Loss: 15287.841797\n",
      "Train Epoch: 21 [197248/225000 (88%)] Loss: 15626.381836\n",
      "Train Epoch: 21 [198656/225000 (88%)] Loss: 15045.737305\n",
      "Train Epoch: 21 [200064/225000 (89%)] Loss: 15294.347656\n",
      "Train Epoch: 21 [201472/225000 (90%)] Loss: 15242.125000\n",
      "Train Epoch: 21 [202880/225000 (90%)] Loss: 14821.512695\n",
      "Train Epoch: 21 [204288/225000 (91%)] Loss: 15183.569336\n",
      "Train Epoch: 21 [205696/225000 (91%)] Loss: 14907.106445\n",
      "Train Epoch: 21 [207104/225000 (92%)] Loss: 15526.293945\n",
      "Train Epoch: 21 [208512/225000 (93%)] Loss: 14993.519531\n",
      "Train Epoch: 21 [209920/225000 (93%)] Loss: 14939.063477\n",
      "Train Epoch: 21 [211328/225000 (94%)] Loss: 15034.919922\n",
      "Train Epoch: 21 [212736/225000 (95%)] Loss: 14823.662109\n",
      "Train Epoch: 21 [214144/225000 (95%)] Loss: 15087.335938\n",
      "Train Epoch: 21 [215552/225000 (96%)] Loss: 15254.925781\n",
      "Train Epoch: 21 [216960/225000 (96%)] Loss: 15269.484375\n",
      "Train Epoch: 21 [218368/225000 (97%)] Loss: 15069.998047\n",
      "Train Epoch: 21 [219776/225000 (98%)] Loss: 14847.375977\n",
      "Train Epoch: 21 [221184/225000 (98%)] Loss: 15288.441406\n",
      "Train Epoch: 21 [222592/225000 (99%)] Loss: 15102.468750\n",
      "Train Epoch: 21 [224000/225000 (100%)] Loss: 15022.822266\n",
      "    epoch          : 21\n",
      "    loss           : 15086.090318143843\n",
      "    val_loss       : 15092.491529689607\n",
      "Train Epoch: 22 [128/225000 (0%)] Loss: 14644.534180\n",
      "Train Epoch: 22 [1536/225000 (1%)] Loss: 14903.187500\n",
      "Train Epoch: 22 [2944/225000 (1%)] Loss: 14735.687500\n",
      "Train Epoch: 22 [4352/225000 (2%)] Loss: 15071.333984\n",
      "Train Epoch: 22 [5760/225000 (3%)] Loss: 15448.849609\n",
      "Train Epoch: 22 [7168/225000 (3%)] Loss: 15216.578125\n",
      "Train Epoch: 22 [8576/225000 (4%)] Loss: 14657.967773\n",
      "Train Epoch: 22 [9984/225000 (4%)] Loss: 15178.744141\n",
      "Train Epoch: 22 [11392/225000 (5%)] Loss: 15130.438477\n",
      "Train Epoch: 22 [12800/225000 (6%)] Loss: 15345.417969\n",
      "Train Epoch: 22 [14208/225000 (6%)] Loss: 15054.470703\n",
      "Train Epoch: 22 [15616/225000 (7%)] Loss: 14874.829102\n",
      "Train Epoch: 22 [17024/225000 (8%)] Loss: 14983.934570\n",
      "Train Epoch: 22 [18432/225000 (8%)] Loss: 14932.060547\n",
      "Train Epoch: 22 [19840/225000 (9%)] Loss: 15372.914062\n",
      "Train Epoch: 22 [21248/225000 (9%)] Loss: 15017.364258\n",
      "Train Epoch: 22 [22656/225000 (10%)] Loss: 14574.611328\n",
      "Train Epoch: 22 [24064/225000 (11%)] Loss: 14996.209961\n",
      "Train Epoch: 22 [25472/225000 (11%)] Loss: 15097.750000\n",
      "Train Epoch: 22 [26880/225000 (12%)] Loss: 14940.411133\n",
      "Train Epoch: 22 [28288/225000 (13%)] Loss: 14937.411133\n",
      "Train Epoch: 22 [29696/225000 (13%)] Loss: 15016.059570\n",
      "Train Epoch: 22 [31104/225000 (14%)] Loss: 15465.995117\n",
      "Train Epoch: 22 [32512/225000 (14%)] Loss: 15011.661133\n",
      "Train Epoch: 22 [33920/225000 (15%)] Loss: 14934.390625\n",
      "Train Epoch: 22 [35328/225000 (16%)] Loss: 15744.064453\n",
      "Train Epoch: 22 [36736/225000 (16%)] Loss: 15515.947266\n",
      "Train Epoch: 22 [38144/225000 (17%)] Loss: 15101.827148\n",
      "Train Epoch: 22 [39552/225000 (18%)] Loss: 14960.065430\n",
      "Train Epoch: 22 [40960/225000 (18%)] Loss: 15106.629883\n",
      "Train Epoch: 22 [42368/225000 (19%)] Loss: 15191.629883\n",
      "Train Epoch: 22 [43776/225000 (19%)] Loss: 14964.446289\n",
      "Train Epoch: 22 [45184/225000 (20%)] Loss: 15072.598633\n",
      "Train Epoch: 22 [46592/225000 (21%)] Loss: 15445.951172\n",
      "Train Epoch: 22 [48000/225000 (21%)] Loss: 15197.842773\n",
      "Train Epoch: 22 [49408/225000 (22%)] Loss: 14688.971680\n",
      "Train Epoch: 22 [50816/225000 (23%)] Loss: 15117.717773\n",
      "Train Epoch: 22 [52224/225000 (23%)] Loss: 14775.428711\n",
      "Train Epoch: 22 [53632/225000 (24%)] Loss: 15089.118164\n",
      "Train Epoch: 22 [55040/225000 (24%)] Loss: 15176.034180\n",
      "Train Epoch: 22 [56448/225000 (25%)] Loss: 15194.840820\n",
      "Train Epoch: 22 [57856/225000 (26%)] Loss: 15056.837891\n",
      "Train Epoch: 22 [59264/225000 (26%)] Loss: 14783.672852\n",
      "Train Epoch: 22 [60672/225000 (27%)] Loss: 15392.001953\n",
      "Train Epoch: 22 [62080/225000 (28%)] Loss: 14950.741211\n",
      "Train Epoch: 22 [63488/225000 (28%)] Loss: 15354.756836\n",
      "Train Epoch: 22 [64896/225000 (29%)] Loss: 15510.347656\n",
      "Train Epoch: 22 [66304/225000 (29%)] Loss: 14627.936523\n",
      "Train Epoch: 22 [67712/225000 (30%)] Loss: 15179.362305\n",
      "Train Epoch: 22 [69120/225000 (31%)] Loss: 14985.202148\n",
      "Train Epoch: 22 [70528/225000 (31%)] Loss: 15256.948242\n",
      "Train Epoch: 22 [71936/225000 (32%)] Loss: 15154.375977\n",
      "Train Epoch: 22 [73344/225000 (33%)] Loss: 15336.428711\n",
      "Train Epoch: 22 [74752/225000 (33%)] Loss: 14677.685547\n",
      "Train Epoch: 22 [76160/225000 (34%)] Loss: 14890.864258\n",
      "Train Epoch: 22 [77568/225000 (34%)] Loss: 15084.598633\n",
      "Train Epoch: 22 [78976/225000 (35%)] Loss: 15114.019531\n",
      "Train Epoch: 22 [80384/225000 (36%)] Loss: 14988.326172\n",
      "Train Epoch: 22 [81792/225000 (36%)] Loss: 14884.811523\n",
      "Train Epoch: 22 [83200/225000 (37%)] Loss: 15000.048828\n",
      "Train Epoch: 22 [84608/225000 (38%)] Loss: 14627.510742\n",
      "Train Epoch: 22 [86016/225000 (38%)] Loss: 15103.274414\n",
      "Train Epoch: 22 [87424/225000 (39%)] Loss: 15137.637695\n",
      "Train Epoch: 22 [88832/225000 (39%)] Loss: 15419.952148\n",
      "Train Epoch: 22 [90240/225000 (40%)] Loss: 15230.297852\n",
      "Train Epoch: 22 [91648/225000 (41%)] Loss: 14797.361328\n",
      "Train Epoch: 22 [93056/225000 (41%)] Loss: 15026.393555\n",
      "Train Epoch: 22 [94464/225000 (42%)] Loss: 15251.703125\n",
      "Train Epoch: 22 [95872/225000 (43%)] Loss: 15051.987305\n",
      "Train Epoch: 22 [97280/225000 (43%)] Loss: 15011.994141\n",
      "Train Epoch: 22 [98688/225000 (44%)] Loss: 14979.891602\n",
      "Train Epoch: 22 [100096/225000 (44%)] Loss: 15663.849609\n",
      "Train Epoch: 22 [101504/225000 (45%)] Loss: 15055.710938\n",
      "Train Epoch: 22 [102912/225000 (46%)] Loss: 14884.897461\n",
      "Train Epoch: 22 [104320/225000 (46%)] Loss: 14931.658203\n",
      "Train Epoch: 22 [105728/225000 (47%)] Loss: 14783.919922\n",
      "Train Epoch: 22 [107136/225000 (48%)] Loss: 15229.414062\n",
      "Train Epoch: 22 [108544/225000 (48%)] Loss: 14952.931641\n",
      "Train Epoch: 22 [109952/225000 (49%)] Loss: 15116.182617\n",
      "Train Epoch: 22 [111360/225000 (49%)] Loss: 15766.856445\n",
      "Train Epoch: 22 [112768/225000 (50%)] Loss: 14979.722656\n",
      "Train Epoch: 22 [114176/225000 (51%)] Loss: 15088.819336\n",
      "Train Epoch: 22 [115584/225000 (51%)] Loss: 15261.158203\n",
      "Train Epoch: 22 [116992/225000 (52%)] Loss: 14907.617188\n",
      "Train Epoch: 22 [118400/225000 (53%)] Loss: 15267.386719\n",
      "Train Epoch: 22 [119808/225000 (53%)] Loss: 15350.904297\n",
      "Train Epoch: 22 [121216/225000 (54%)] Loss: 14959.606445\n",
      "Train Epoch: 22 [122624/225000 (54%)] Loss: 15352.914062\n",
      "Train Epoch: 22 [124032/225000 (55%)] Loss: 15288.921875\n",
      "Train Epoch: 22 [125440/225000 (56%)] Loss: 15094.134766\n",
      "Train Epoch: 22 [126848/225000 (56%)] Loss: 15496.230469\n",
      "Train Epoch: 22 [128256/225000 (57%)] Loss: 15333.938477\n",
      "Train Epoch: 22 [129664/225000 (58%)] Loss: 15312.464844\n",
      "Train Epoch: 22 [131072/225000 (58%)] Loss: 15145.868164\n",
      "Train Epoch: 22 [132480/225000 (59%)] Loss: 15037.787109\n",
      "Train Epoch: 22 [133888/225000 (60%)] Loss: 15289.382812\n",
      "Train Epoch: 22 [135296/225000 (60%)] Loss: 15288.743164\n",
      "Train Epoch: 22 [136704/225000 (61%)] Loss: 14960.756836\n",
      "Train Epoch: 22 [138112/225000 (61%)] Loss: 15423.098633\n",
      "Train Epoch: 22 [139520/225000 (62%)] Loss: 14809.773438\n",
      "Train Epoch: 22 [140928/225000 (63%)] Loss: 14949.002930\n",
      "Train Epoch: 22 [142336/225000 (63%)] Loss: 15351.988281\n",
      "Train Epoch: 22 [143744/225000 (64%)] Loss: 15193.286133\n",
      "Train Epoch: 22 [145152/225000 (65%)] Loss: 15562.672852\n",
      "Train Epoch: 22 [146560/225000 (65%)] Loss: 15086.670898\n",
      "Train Epoch: 22 [147968/225000 (66%)] Loss: 14886.465820\n",
      "Train Epoch: 22 [149376/225000 (66%)] Loss: 15300.553711\n",
      "Train Epoch: 22 [150784/225000 (67%)] Loss: 15083.185547\n",
      "Train Epoch: 22 [152192/225000 (68%)] Loss: 15099.916992\n",
      "Train Epoch: 22 [153600/225000 (68%)] Loss: 14560.810547\n",
      "Train Epoch: 22 [155008/225000 (69%)] Loss: 15089.722656\n",
      "Train Epoch: 22 [156416/225000 (70%)] Loss: 15320.145508\n",
      "Train Epoch: 22 [157824/225000 (70%)] Loss: 15108.826172\n",
      "Train Epoch: 22 [159232/225000 (71%)] Loss: 15282.947266\n",
      "Train Epoch: 22 [160640/225000 (71%)] Loss: 14697.210938\n",
      "Train Epoch: 22 [162048/225000 (72%)] Loss: 14828.372070\n",
      "Train Epoch: 22 [163456/225000 (73%)] Loss: 14916.745117\n",
      "Train Epoch: 22 [164864/225000 (73%)] Loss: 14961.462891\n",
      "Train Epoch: 22 [166272/225000 (74%)] Loss: 15064.670898\n",
      "Train Epoch: 22 [167680/225000 (75%)] Loss: 14651.224609\n",
      "Train Epoch: 22 [169088/225000 (75%)] Loss: 15083.942383\n",
      "Train Epoch: 22 [170496/225000 (76%)] Loss: 15182.783203\n",
      "Train Epoch: 22 [171904/225000 (76%)] Loss: 15214.321289\n",
      "Train Epoch: 22 [173312/225000 (77%)] Loss: 15497.826172\n",
      "Train Epoch: 22 [174720/225000 (78%)] Loss: 15134.537109\n",
      "Train Epoch: 22 [176128/225000 (78%)] Loss: 14951.542969\n",
      "Train Epoch: 22 [177536/225000 (79%)] Loss: 14923.481445\n",
      "Train Epoch: 22 [178944/225000 (80%)] Loss: 14784.178711\n",
      "Train Epoch: 22 [180352/225000 (80%)] Loss: 15203.761719\n",
      "Train Epoch: 22 [181760/225000 (81%)] Loss: 15095.482422\n",
      "Train Epoch: 22 [183168/225000 (81%)] Loss: 15339.703125\n",
      "Train Epoch: 22 [184576/225000 (82%)] Loss: 15025.056641\n",
      "Train Epoch: 22 [185984/225000 (83%)] Loss: 14866.557617\n",
      "Train Epoch: 22 [187392/225000 (83%)] Loss: 14615.932617\n",
      "Train Epoch: 22 [188800/225000 (84%)] Loss: 14987.587891\n",
      "Train Epoch: 22 [190208/225000 (85%)] Loss: 14940.333984\n",
      "Train Epoch: 22 [191616/225000 (85%)] Loss: 15168.321289\n",
      "Train Epoch: 22 [193024/225000 (86%)] Loss: 14996.083008\n",
      "Train Epoch: 22 [194432/225000 (86%)] Loss: 14887.575195\n",
      "Train Epoch: 22 [195840/225000 (87%)] Loss: 15238.258789\n",
      "Train Epoch: 22 [197248/225000 (88%)] Loss: 15271.016602\n",
      "Train Epoch: 22 [198656/225000 (88%)] Loss: 15517.825195\n",
      "Train Epoch: 22 [200064/225000 (89%)] Loss: 15159.631836\n",
      "Train Epoch: 22 [201472/225000 (90%)] Loss: 14965.050781\n",
      "Train Epoch: 22 [202880/225000 (90%)] Loss: 15512.242188\n",
      "Train Epoch: 22 [204288/225000 (91%)] Loss: 14556.165039\n",
      "Train Epoch: 22 [205696/225000 (91%)] Loss: 14961.589844\n",
      "Train Epoch: 22 [207104/225000 (92%)] Loss: 14655.617188\n",
      "Train Epoch: 22 [208512/225000 (93%)] Loss: 15307.787109\n",
      "Train Epoch: 22 [209920/225000 (93%)] Loss: 14969.937500\n",
      "Train Epoch: 22 [211328/225000 (94%)] Loss: 14847.076172\n",
      "Train Epoch: 22 [212736/225000 (95%)] Loss: 15145.702148\n",
      "Train Epoch: 22 [214144/225000 (95%)] Loss: 15203.900391\n",
      "Train Epoch: 22 [215552/225000 (96%)] Loss: 15155.203125\n",
      "Train Epoch: 22 [216960/225000 (96%)] Loss: 15399.657227\n",
      "Train Epoch: 22 [218368/225000 (97%)] Loss: 14988.609375\n",
      "Train Epoch: 22 [219776/225000 (98%)] Loss: 15055.890625\n",
      "Train Epoch: 22 [221184/225000 (98%)] Loss: 14471.668945\n",
      "Train Epoch: 22 [222592/225000 (99%)] Loss: 15090.784180\n",
      "Train Epoch: 22 [224000/225000 (100%)] Loss: 15375.582031\n",
      "    epoch          : 22\n",
      "    loss           : 15089.744322827788\n",
      "    val_loss       : 15065.15876406416\n",
      "Train Epoch: 23 [128/225000 (0%)] Loss: 15511.710938\n",
      "Train Epoch: 23 [1536/225000 (1%)] Loss: 15617.005859\n",
      "Train Epoch: 23 [2944/225000 (1%)] Loss: 14895.556641\n",
      "Train Epoch: 23 [4352/225000 (2%)] Loss: 14989.193359\n",
      "Train Epoch: 23 [5760/225000 (3%)] Loss: 14851.595703\n",
      "Train Epoch: 23 [7168/225000 (3%)] Loss: 14949.502930\n",
      "Train Epoch: 23 [8576/225000 (4%)] Loss: 15053.027344\n",
      "Train Epoch: 23 [9984/225000 (4%)] Loss: 15200.647461\n",
      "Train Epoch: 23 [11392/225000 (5%)] Loss: 15129.410156\n",
      "Train Epoch: 23 [12800/225000 (6%)] Loss: 14692.303711\n",
      "Train Epoch: 23 [14208/225000 (6%)] Loss: 14908.428711\n",
      "Train Epoch: 23 [15616/225000 (7%)] Loss: 15115.504883\n",
      "Train Epoch: 23 [17024/225000 (8%)] Loss: 15719.889648\n",
      "Train Epoch: 23 [18432/225000 (8%)] Loss: 14429.545898\n",
      "Train Epoch: 23 [19840/225000 (9%)] Loss: 14723.495117\n",
      "Train Epoch: 23 [21248/225000 (9%)] Loss: 15041.089844\n",
      "Train Epoch: 23 [22656/225000 (10%)] Loss: 15145.098633\n",
      "Train Epoch: 23 [24064/225000 (11%)] Loss: 15282.315430\n",
      "Train Epoch: 23 [25472/225000 (11%)] Loss: 15177.388672\n",
      "Train Epoch: 23 [26880/225000 (12%)] Loss: 15279.798828\n",
      "Train Epoch: 23 [28288/225000 (13%)] Loss: 15336.208984\n",
      "Train Epoch: 23 [29696/225000 (13%)] Loss: 14762.271484\n",
      "Train Epoch: 23 [31104/225000 (14%)] Loss: 14962.220703\n",
      "Train Epoch: 23 [32512/225000 (14%)] Loss: 14596.424805\n",
      "Train Epoch: 23 [33920/225000 (15%)] Loss: 14848.024414\n",
      "Train Epoch: 23 [35328/225000 (16%)] Loss: 14998.846680\n",
      "Train Epoch: 23 [36736/225000 (16%)] Loss: 14830.485352\n",
      "Train Epoch: 23 [38144/225000 (17%)] Loss: 14937.455078\n",
      "Train Epoch: 23 [39552/225000 (18%)] Loss: 15283.146484\n",
      "Train Epoch: 23 [40960/225000 (18%)] Loss: 14757.272461\n",
      "Train Epoch: 23 [42368/225000 (19%)] Loss: 15023.025391\n",
      "Train Epoch: 23 [43776/225000 (19%)] Loss: 15231.038086\n",
      "Train Epoch: 23 [45184/225000 (20%)] Loss: 15374.476562\n",
      "Train Epoch: 23 [46592/225000 (21%)] Loss: 15271.688477\n",
      "Train Epoch: 23 [48000/225000 (21%)] Loss: 14846.833984\n",
      "Train Epoch: 23 [49408/225000 (22%)] Loss: 14803.889648\n",
      "Train Epoch: 23 [50816/225000 (23%)] Loss: 15181.360352\n",
      "Train Epoch: 23 [52224/225000 (23%)] Loss: 15009.200195\n",
      "Train Epoch: 23 [53632/225000 (24%)] Loss: 14743.723633\n",
      "Train Epoch: 23 [55040/225000 (24%)] Loss: 15192.921875\n",
      "Train Epoch: 23 [56448/225000 (25%)] Loss: 14700.284180\n",
      "Train Epoch: 23 [57856/225000 (26%)] Loss: 14923.040039\n",
      "Train Epoch: 23 [59264/225000 (26%)] Loss: 15344.988281\n",
      "Train Epoch: 23 [60672/225000 (27%)] Loss: 14843.914062\n",
      "Train Epoch: 23 [62080/225000 (28%)] Loss: 14970.146484\n",
      "Train Epoch: 23 [63488/225000 (28%)] Loss: 15211.246094\n",
      "Train Epoch: 23 [64896/225000 (29%)] Loss: 15453.709961\n",
      "Train Epoch: 23 [66304/225000 (29%)] Loss: 15127.209961\n",
      "Train Epoch: 23 [67712/225000 (30%)] Loss: 15697.646484\n",
      "Train Epoch: 23 [69120/225000 (31%)] Loss: 14995.972656\n",
      "Train Epoch: 23 [70528/225000 (31%)] Loss: 15285.276367\n",
      "Train Epoch: 23 [71936/225000 (32%)] Loss: 15373.499023\n",
      "Train Epoch: 23 [73344/225000 (33%)] Loss: 15395.925781\n",
      "Train Epoch: 23 [74752/225000 (33%)] Loss: 15620.295898\n",
      "Train Epoch: 23 [76160/225000 (34%)] Loss: 15292.895508\n",
      "Train Epoch: 23 [77568/225000 (34%)] Loss: 15558.611328\n",
      "Train Epoch: 23 [78976/225000 (35%)] Loss: 15467.042969\n",
      "Train Epoch: 23 [80384/225000 (36%)] Loss: 15193.077148\n",
      "Train Epoch: 23 [81792/225000 (36%)] Loss: 15295.450195\n",
      "Train Epoch: 23 [83200/225000 (37%)] Loss: 15223.815430\n",
      "Train Epoch: 23 [84608/225000 (38%)] Loss: 14798.412109\n",
      "Train Epoch: 23 [86016/225000 (38%)] Loss: 14831.651367\n",
      "Train Epoch: 23 [87424/225000 (39%)] Loss: 15078.176758\n",
      "Train Epoch: 23 [88832/225000 (39%)] Loss: 15065.820312\n",
      "Train Epoch: 23 [90240/225000 (40%)] Loss: 15316.670898\n",
      "Train Epoch: 23 [91648/225000 (41%)] Loss: 15010.500977\n",
      "Train Epoch: 23 [93056/225000 (41%)] Loss: 14714.396484\n",
      "Train Epoch: 23 [94464/225000 (42%)] Loss: 15435.681641\n",
      "Train Epoch: 23 [95872/225000 (43%)] Loss: 15021.689453\n",
      "Train Epoch: 23 [97280/225000 (43%)] Loss: 15106.513672\n",
      "Train Epoch: 23 [98688/225000 (44%)] Loss: 15447.849609\n",
      "Train Epoch: 23 [100096/225000 (44%)] Loss: 14874.896484\n",
      "Train Epoch: 23 [101504/225000 (45%)] Loss: 15547.697266\n",
      "Train Epoch: 23 [102912/225000 (46%)] Loss: 14903.165039\n",
      "Train Epoch: 23 [104320/225000 (46%)] Loss: 15196.638672\n",
      "Train Epoch: 23 [105728/225000 (47%)] Loss: 15171.554688\n",
      "Train Epoch: 23 [107136/225000 (48%)] Loss: 15119.213867\n",
      "Train Epoch: 23 [108544/225000 (48%)] Loss: 15704.974609\n",
      "Train Epoch: 23 [109952/225000 (49%)] Loss: 15265.833008\n",
      "Train Epoch: 23 [111360/225000 (49%)] Loss: 14724.628906\n",
      "Train Epoch: 23 [112768/225000 (50%)] Loss: 14973.398438\n",
      "Train Epoch: 23 [114176/225000 (51%)] Loss: 14936.644531\n",
      "Train Epoch: 23 [115584/225000 (51%)] Loss: 15227.372070\n",
      "Train Epoch: 23 [116992/225000 (52%)] Loss: 14966.075195\n",
      "Train Epoch: 23 [118400/225000 (53%)] Loss: 15161.002930\n",
      "Train Epoch: 23 [119808/225000 (53%)] Loss: 14864.163086\n",
      "Train Epoch: 23 [121216/225000 (54%)] Loss: 14814.489258\n",
      "Train Epoch: 23 [122624/225000 (54%)] Loss: 14829.460938\n",
      "Train Epoch: 23 [124032/225000 (55%)] Loss: 15092.031250\n",
      "Train Epoch: 23 [125440/225000 (56%)] Loss: 15253.634766\n",
      "Train Epoch: 23 [126848/225000 (56%)] Loss: 15145.925781\n",
      "Train Epoch: 23 [128256/225000 (57%)] Loss: 15210.984375\n",
      "Train Epoch: 23 [129664/225000 (58%)] Loss: 15238.322266\n",
      "Train Epoch: 23 [131072/225000 (58%)] Loss: 14749.898438\n",
      "Train Epoch: 23 [132480/225000 (59%)] Loss: 15143.826172\n",
      "Train Epoch: 23 [133888/225000 (60%)] Loss: 15013.176758\n",
      "Train Epoch: 23 [135296/225000 (60%)] Loss: 14980.920898\n",
      "Train Epoch: 23 [136704/225000 (61%)] Loss: 14911.398438\n",
      "Train Epoch: 23 [138112/225000 (61%)] Loss: 15200.831055\n",
      "Train Epoch: 23 [139520/225000 (62%)] Loss: 15389.735352\n",
      "Train Epoch: 23 [140928/225000 (63%)] Loss: 14948.703125\n",
      "Train Epoch: 23 [142336/225000 (63%)] Loss: 15212.144531\n",
      "Train Epoch: 23 [143744/225000 (64%)] Loss: 15800.126953\n",
      "Train Epoch: 23 [145152/225000 (65%)] Loss: 15238.778320\n",
      "Train Epoch: 23 [146560/225000 (65%)] Loss: 15094.623047\n",
      "Train Epoch: 23 [147968/225000 (66%)] Loss: 14872.551758\n",
      "Train Epoch: 23 [149376/225000 (66%)] Loss: 15228.272461\n",
      "Train Epoch: 23 [150784/225000 (67%)] Loss: 15285.037109\n",
      "Train Epoch: 23 [152192/225000 (68%)] Loss: 15589.396484\n",
      "Train Epoch: 23 [153600/225000 (68%)] Loss: 15278.726562\n",
      "Train Epoch: 23 [155008/225000 (69%)] Loss: 15591.512695\n",
      "Train Epoch: 23 [156416/225000 (70%)] Loss: 14857.216797\n",
      "Train Epoch: 23 [157824/225000 (70%)] Loss: 15604.250000\n",
      "Train Epoch: 23 [159232/225000 (71%)] Loss: 15385.709961\n",
      "Train Epoch: 23 [160640/225000 (71%)] Loss: 15280.000000\n",
      "Train Epoch: 23 [162048/225000 (72%)] Loss: 15516.450195\n",
      "Train Epoch: 23 [163456/225000 (73%)] Loss: 15233.439453\n",
      "Train Epoch: 23 [164864/225000 (73%)] Loss: 15645.661133\n",
      "Train Epoch: 23 [166272/225000 (74%)] Loss: 15384.539062\n",
      "Train Epoch: 23 [167680/225000 (75%)] Loss: 14908.869141\n",
      "Train Epoch: 23 [169088/225000 (75%)] Loss: 15436.695312\n",
      "Train Epoch: 23 [170496/225000 (76%)] Loss: 15052.602539\n",
      "Train Epoch: 23 [171904/225000 (76%)] Loss: 14760.744141\n",
      "Train Epoch: 23 [173312/225000 (77%)] Loss: 15179.341797\n",
      "Train Epoch: 23 [174720/225000 (78%)] Loss: 15373.804688\n",
      "Train Epoch: 23 [176128/225000 (78%)] Loss: 14729.797852\n",
      "Train Epoch: 23 [177536/225000 (79%)] Loss: 15026.773438\n",
      "Train Epoch: 23 [178944/225000 (80%)] Loss: 15153.470703\n",
      "Train Epoch: 23 [180352/225000 (80%)] Loss: 14897.439453\n",
      "Train Epoch: 23 [181760/225000 (81%)] Loss: 15409.568359\n",
      "Train Epoch: 23 [183168/225000 (81%)] Loss: 14780.290039\n",
      "Train Epoch: 23 [184576/225000 (82%)] Loss: 15005.981445\n",
      "Train Epoch: 23 [185984/225000 (83%)] Loss: 15312.570312\n",
      "Train Epoch: 23 [187392/225000 (83%)] Loss: 15255.200195\n",
      "Train Epoch: 23 [188800/225000 (84%)] Loss: 14749.695312\n",
      "Train Epoch: 23 [190208/225000 (85%)] Loss: 15341.042969\n",
      "Train Epoch: 23 [191616/225000 (85%)] Loss: 14995.664062\n",
      "Train Epoch: 23 [193024/225000 (86%)] Loss: 15000.427734\n",
      "Train Epoch: 23 [194432/225000 (86%)] Loss: 15001.966797\n",
      "Train Epoch: 23 [195840/225000 (87%)] Loss: 14855.603516\n",
      "Train Epoch: 23 [197248/225000 (88%)] Loss: 15204.222656\n",
      "Train Epoch: 23 [198656/225000 (88%)] Loss: 15005.321289\n",
      "Train Epoch: 23 [200064/225000 (89%)] Loss: 15246.085938\n",
      "Train Epoch: 23 [201472/225000 (90%)] Loss: 15423.529297\n",
      "Train Epoch: 23 [202880/225000 (90%)] Loss: 15151.372070\n",
      "Train Epoch: 23 [204288/225000 (91%)] Loss: 15152.541016\n",
      "Train Epoch: 23 [205696/225000 (91%)] Loss: 14986.177734\n",
      "Train Epoch: 23 [207104/225000 (92%)] Loss: 15167.703125\n",
      "Train Epoch: 23 [208512/225000 (93%)] Loss: 15307.532227\n",
      "Train Epoch: 23 [209920/225000 (93%)] Loss: 15033.609375\n",
      "Train Epoch: 23 [211328/225000 (94%)] Loss: 14902.152344\n",
      "Train Epoch: 23 [212736/225000 (95%)] Loss: 15546.802734\n",
      "Train Epoch: 23 [214144/225000 (95%)] Loss: 15256.348633\n",
      "Train Epoch: 23 [215552/225000 (96%)] Loss: 15198.131836\n",
      "Train Epoch: 23 [216960/225000 (96%)] Loss: 14970.711914\n",
      "Train Epoch: 23 [218368/225000 (97%)] Loss: 15105.848633\n",
      "Train Epoch: 23 [219776/225000 (98%)] Loss: 15067.788086\n",
      "Train Epoch: 23 [221184/225000 (98%)] Loss: 14989.316406\n",
      "Train Epoch: 23 [222592/225000 (99%)] Loss: 15153.757812\n",
      "Train Epoch: 23 [224000/225000 (100%)] Loss: 15060.951172\n",
      "    epoch          : 23\n",
      "    loss           : 15095.208190015288\n",
      "    val_loss       : 15080.361456304485\n",
      "Train Epoch: 24 [128/225000 (0%)] Loss: 15072.926758\n",
      "Train Epoch: 24 [1536/225000 (1%)] Loss: 15092.686523\n",
      "Train Epoch: 24 [2944/225000 (1%)] Loss: 15140.517578\n",
      "Train Epoch: 24 [4352/225000 (2%)] Loss: 14960.453125\n",
      "Train Epoch: 24 [5760/225000 (3%)] Loss: 14804.589844\n",
      "Train Epoch: 24 [7168/225000 (3%)] Loss: 14781.384766\n",
      "Train Epoch: 24 [8576/225000 (4%)] Loss: 14612.496094\n",
      "Train Epoch: 24 [9984/225000 (4%)] Loss: 15347.209961\n",
      "Train Epoch: 24 [11392/225000 (5%)] Loss: 15162.854492\n",
      "Train Epoch: 24 [12800/225000 (6%)] Loss: 21737.179688\n",
      "Train Epoch: 24 [14208/225000 (6%)] Loss: 15370.801758\n",
      "Train Epoch: 24 [15616/225000 (7%)] Loss: 14676.651367\n",
      "Train Epoch: 24 [17024/225000 (8%)] Loss: 14870.635742\n",
      "Train Epoch: 24 [18432/225000 (8%)] Loss: 15189.939453\n",
      "Train Epoch: 24 [19840/225000 (9%)] Loss: 15261.530273\n",
      "Train Epoch: 24 [21248/225000 (9%)] Loss: 14990.551758\n",
      "Train Epoch: 24 [22656/225000 (10%)] Loss: 15280.759766\n",
      "Train Epoch: 24 [24064/225000 (11%)] Loss: 15132.949219\n",
      "Train Epoch: 24 [25472/225000 (11%)] Loss: 14850.207031\n",
      "Train Epoch: 24 [26880/225000 (12%)] Loss: 15180.641602\n",
      "Train Epoch: 24 [28288/225000 (13%)] Loss: 14982.763672\n",
      "Train Epoch: 24 [29696/225000 (13%)] Loss: 15285.921875\n",
      "Train Epoch: 24 [31104/225000 (14%)] Loss: 15095.114258\n",
      "Train Epoch: 24 [32512/225000 (14%)] Loss: 15382.522461\n",
      "Train Epoch: 24 [33920/225000 (15%)] Loss: 14621.702148\n",
      "Train Epoch: 24 [35328/225000 (16%)] Loss: 14832.384766\n",
      "Train Epoch: 24 [36736/225000 (16%)] Loss: 14783.429688\n",
      "Train Epoch: 24 [38144/225000 (17%)] Loss: 15231.801758\n",
      "Train Epoch: 24 [39552/225000 (18%)] Loss: 15197.826172\n",
      "Train Epoch: 24 [40960/225000 (18%)] Loss: 15273.901367\n",
      "Train Epoch: 24 [42368/225000 (19%)] Loss: 15038.635742\n",
      "Train Epoch: 24 [43776/225000 (19%)] Loss: 15042.772461\n",
      "Train Epoch: 24 [45184/225000 (20%)] Loss: 14909.879883\n",
      "Train Epoch: 24 [46592/225000 (21%)] Loss: 14876.022461\n",
      "Train Epoch: 24 [48000/225000 (21%)] Loss: 14740.925781\n",
      "Train Epoch: 24 [49408/225000 (22%)] Loss: 14896.463867\n",
      "Train Epoch: 24 [50816/225000 (23%)] Loss: 15163.319336\n",
      "Train Epoch: 24 [52224/225000 (23%)] Loss: 15121.532227\n",
      "Train Epoch: 24 [53632/225000 (24%)] Loss: 14732.788086\n",
      "Train Epoch: 24 [55040/225000 (24%)] Loss: 14964.743164\n",
      "Train Epoch: 24 [56448/225000 (25%)] Loss: 15313.934570\n",
      "Train Epoch: 24 [57856/225000 (26%)] Loss: 15151.650391\n",
      "Train Epoch: 24 [59264/225000 (26%)] Loss: 14743.153320\n",
      "Train Epoch: 24 [60672/225000 (27%)] Loss: 14761.506836\n",
      "Train Epoch: 24 [62080/225000 (28%)] Loss: 15117.924805\n",
      "Train Epoch: 24 [63488/225000 (28%)] Loss: 15008.485352\n",
      "Train Epoch: 24 [64896/225000 (29%)] Loss: 15149.346680\n",
      "Train Epoch: 24 [66304/225000 (29%)] Loss: 15304.206055\n",
      "Train Epoch: 24 [67712/225000 (30%)] Loss: 15336.751953\n",
      "Train Epoch: 24 [69120/225000 (31%)] Loss: 14370.986328\n",
      "Train Epoch: 24 [70528/225000 (31%)] Loss: 15646.956055\n",
      "Train Epoch: 24 [71936/225000 (32%)] Loss: 15020.485352\n",
      "Train Epoch: 24 [73344/225000 (33%)] Loss: 14908.282227\n",
      "Train Epoch: 24 [74752/225000 (33%)] Loss: 15259.014648\n",
      "Train Epoch: 24 [76160/225000 (34%)] Loss: 15389.080078\n",
      "Train Epoch: 24 [77568/225000 (34%)] Loss: 15048.418945\n",
      "Train Epoch: 24 [78976/225000 (35%)] Loss: 14671.513672\n",
      "Train Epoch: 24 [80384/225000 (36%)] Loss: 14994.780273\n",
      "Train Epoch: 24 [81792/225000 (36%)] Loss: 15040.447266\n",
      "Train Epoch: 24 [83200/225000 (37%)] Loss: 15408.453125\n",
      "Train Epoch: 24 [84608/225000 (38%)] Loss: 14881.317383\n",
      "Train Epoch: 24 [86016/225000 (38%)] Loss: 14987.786133\n",
      "Train Epoch: 24 [87424/225000 (39%)] Loss: 15190.332031\n",
      "Train Epoch: 24 [88832/225000 (39%)] Loss: 15089.674805\n",
      "Train Epoch: 24 [90240/225000 (40%)] Loss: 15238.526367\n",
      "Train Epoch: 24 [91648/225000 (41%)] Loss: 15319.336914\n",
      "Train Epoch: 24 [93056/225000 (41%)] Loss: 15046.928711\n",
      "Train Epoch: 24 [94464/225000 (42%)] Loss: 15217.174805\n",
      "Train Epoch: 24 [95872/225000 (43%)] Loss: 14913.763672\n",
      "Train Epoch: 24 [97280/225000 (43%)] Loss: 15437.801758\n",
      "Train Epoch: 24 [98688/225000 (44%)] Loss: 15298.071289\n",
      "Train Epoch: 24 [100096/225000 (44%)] Loss: 15131.759766\n",
      "Train Epoch: 24 [101504/225000 (45%)] Loss: 15417.466797\n",
      "Train Epoch: 24 [102912/225000 (46%)] Loss: 15002.210938\n",
      "Train Epoch: 24 [104320/225000 (46%)] Loss: 15407.706055\n",
      "Train Epoch: 24 [105728/225000 (47%)] Loss: 15131.617188\n",
      "Train Epoch: 24 [107136/225000 (48%)] Loss: 15051.956055\n",
      "Train Epoch: 24 [108544/225000 (48%)] Loss: 15279.113281\n",
      "Train Epoch: 24 [109952/225000 (49%)] Loss: 15276.348633\n",
      "Train Epoch: 24 [111360/225000 (49%)] Loss: 15223.600586\n",
      "Train Epoch: 24 [112768/225000 (50%)] Loss: 14936.027344\n",
      "Train Epoch: 24 [114176/225000 (51%)] Loss: 15028.271484\n",
      "Train Epoch: 24 [115584/225000 (51%)] Loss: 14861.849609\n",
      "Train Epoch: 24 [116992/225000 (52%)] Loss: 15465.034180\n",
      "Train Epoch: 24 [118400/225000 (53%)] Loss: 15174.630859\n",
      "Train Epoch: 24 [119808/225000 (53%)] Loss: 15046.439453\n",
      "Train Epoch: 24 [121216/225000 (54%)] Loss: 14898.999023\n",
      "Train Epoch: 24 [122624/225000 (54%)] Loss: 15029.040039\n",
      "Train Epoch: 24 [124032/225000 (55%)] Loss: 15285.257812\n",
      "Train Epoch: 24 [125440/225000 (56%)] Loss: 15624.713867\n",
      "Train Epoch: 24 [126848/225000 (56%)] Loss: 14798.202148\n",
      "Train Epoch: 24 [128256/225000 (57%)] Loss: 15107.164062\n",
      "Train Epoch: 24 [129664/225000 (58%)] Loss: 15356.974609\n",
      "Train Epoch: 24 [131072/225000 (58%)] Loss: 15456.677734\n",
      "Train Epoch: 24 [132480/225000 (59%)] Loss: 14500.916992\n",
      "Train Epoch: 24 [133888/225000 (60%)] Loss: 15532.541016\n",
      "Train Epoch: 24 [135296/225000 (60%)] Loss: 15170.532227\n",
      "Train Epoch: 24 [136704/225000 (61%)] Loss: 14891.735352\n",
      "Train Epoch: 24 [138112/225000 (61%)] Loss: 14877.043945\n",
      "Train Epoch: 24 [139520/225000 (62%)] Loss: 14679.011719\n",
      "Train Epoch: 24 [140928/225000 (63%)] Loss: 15525.379883\n",
      "Train Epoch: 24 [142336/225000 (63%)] Loss: 14872.615234\n",
      "Train Epoch: 24 [143744/225000 (64%)] Loss: 15261.866211\n",
      "Train Epoch: 24 [145152/225000 (65%)] Loss: 15325.306641\n",
      "Train Epoch: 24 [146560/225000 (65%)] Loss: 15474.950195\n",
      "Train Epoch: 24 [147968/225000 (66%)] Loss: 14982.587891\n",
      "Train Epoch: 24 [149376/225000 (66%)] Loss: 14878.339844\n",
      "Train Epoch: 24 [150784/225000 (67%)] Loss: 15353.464844\n",
      "Train Epoch: 24 [152192/225000 (68%)] Loss: 14912.929688\n",
      "Train Epoch: 24 [153600/225000 (68%)] Loss: 15203.662109\n",
      "Train Epoch: 24 [155008/225000 (69%)] Loss: 15244.300781\n",
      "Train Epoch: 24 [156416/225000 (70%)] Loss: 15097.054688\n",
      "Train Epoch: 24 [157824/225000 (70%)] Loss: 14424.714844\n",
      "Train Epoch: 24 [159232/225000 (71%)] Loss: 15220.640625\n",
      "Train Epoch: 24 [160640/225000 (71%)] Loss: 15420.842773\n",
      "Train Epoch: 24 [162048/225000 (72%)] Loss: 14640.957031\n",
      "Train Epoch: 24 [163456/225000 (73%)] Loss: 15266.213867\n",
      "Train Epoch: 24 [164864/225000 (73%)] Loss: 15061.702148\n",
      "Train Epoch: 24 [166272/225000 (74%)] Loss: 14985.382812\n",
      "Train Epoch: 24 [167680/225000 (75%)] Loss: 14549.231445\n",
      "Train Epoch: 24 [169088/225000 (75%)] Loss: 15174.800781\n",
      "Train Epoch: 24 [170496/225000 (76%)] Loss: 15510.815430\n",
      "Train Epoch: 24 [171904/225000 (76%)] Loss: 15220.059570\n",
      "Train Epoch: 24 [173312/225000 (77%)] Loss: 15131.963867\n",
      "Train Epoch: 24 [174720/225000 (78%)] Loss: 15254.442383\n",
      "Train Epoch: 24 [176128/225000 (78%)] Loss: 14870.415039\n",
      "Train Epoch: 24 [177536/225000 (79%)] Loss: 15133.572266\n",
      "Train Epoch: 24 [178944/225000 (80%)] Loss: 14759.425781\n",
      "Train Epoch: 24 [180352/225000 (80%)] Loss: 15224.619141\n",
      "Train Epoch: 24 [181760/225000 (81%)] Loss: 15113.517578\n",
      "Train Epoch: 24 [183168/225000 (81%)] Loss: 15465.892578\n",
      "Train Epoch: 24 [184576/225000 (82%)] Loss: 15392.987305\n",
      "Train Epoch: 24 [185984/225000 (83%)] Loss: 15153.581055\n",
      "Train Epoch: 24 [187392/225000 (83%)] Loss: 14655.768555\n",
      "Train Epoch: 24 [188800/225000 (84%)] Loss: 14919.296875\n",
      "Train Epoch: 24 [190208/225000 (85%)] Loss: 15103.808594\n",
      "Train Epoch: 24 [191616/225000 (85%)] Loss: 15021.608398\n",
      "Train Epoch: 24 [193024/225000 (86%)] Loss: 15006.628906\n",
      "Train Epoch: 24 [194432/225000 (86%)] Loss: 15429.078125\n",
      "Train Epoch: 24 [195840/225000 (87%)] Loss: 15514.791992\n",
      "Train Epoch: 24 [197248/225000 (88%)] Loss: 14777.064453\n",
      "Train Epoch: 24 [198656/225000 (88%)] Loss: 15101.813477\n",
      "Train Epoch: 24 [200064/225000 (89%)] Loss: 14639.514648\n",
      "Train Epoch: 24 [201472/225000 (90%)] Loss: 14838.048828\n",
      "Train Epoch: 24 [202880/225000 (90%)] Loss: 15040.034180\n",
      "Train Epoch: 24 [204288/225000 (91%)] Loss: 14714.122070\n",
      "Train Epoch: 24 [205696/225000 (91%)] Loss: 14987.913086\n",
      "Train Epoch: 24 [207104/225000 (92%)] Loss: 14867.159180\n",
      "Train Epoch: 24 [208512/225000 (93%)] Loss: 14885.747070\n",
      "Train Epoch: 24 [209920/225000 (93%)] Loss: 14846.046875\n",
      "Train Epoch: 24 [211328/225000 (94%)] Loss: 14961.520508\n",
      "Train Epoch: 24 [212736/225000 (95%)] Loss: 15142.167969\n",
      "Train Epoch: 24 [214144/225000 (95%)] Loss: 15404.252930\n",
      "Train Epoch: 24 [215552/225000 (96%)] Loss: 15279.174805\n",
      "Train Epoch: 24 [216960/225000 (96%)] Loss: 15321.427734\n",
      "Train Epoch: 24 [218368/225000 (97%)] Loss: 15063.917969\n",
      "Train Epoch: 24 [219776/225000 (98%)] Loss: 15576.234375\n",
      "Train Epoch: 24 [221184/225000 (98%)] Loss: 15202.213867\n",
      "Train Epoch: 24 [222592/225000 (99%)] Loss: 14621.261719\n",
      "Train Epoch: 24 [224000/225000 (100%)] Loss: 15241.670898\n",
      "    epoch          : 24\n",
      "    loss           : 15089.67300765696\n",
      "    val_loss       : 15070.730377618756\n",
      "Train Epoch: 25 [128/225000 (0%)] Loss: 14813.264648\n",
      "Train Epoch: 25 [1536/225000 (1%)] Loss: 15677.773438\n",
      "Train Epoch: 25 [2944/225000 (1%)] Loss: 15067.942383\n",
      "Train Epoch: 25 [4352/225000 (2%)] Loss: 14917.030273\n",
      "Train Epoch: 25 [5760/225000 (3%)] Loss: 15364.177734\n",
      "Train Epoch: 25 [7168/225000 (3%)] Loss: 14943.870117\n",
      "Train Epoch: 25 [8576/225000 (4%)] Loss: 14903.672852\n",
      "Train Epoch: 25 [9984/225000 (4%)] Loss: 15248.557617\n",
      "Train Epoch: 25 [11392/225000 (5%)] Loss: 15306.051758\n",
      "Train Epoch: 25 [12800/225000 (6%)] Loss: 15230.907227\n",
      "Train Epoch: 25 [14208/225000 (6%)] Loss: 14886.350586\n",
      "Train Epoch: 25 [15616/225000 (7%)] Loss: 14798.108398\n",
      "Train Epoch: 25 [17024/225000 (8%)] Loss: 15019.511719\n",
      "Train Epoch: 25 [18432/225000 (8%)] Loss: 15576.376953\n",
      "Train Epoch: 25 [19840/225000 (9%)] Loss: 14970.393555\n",
      "Train Epoch: 25 [21248/225000 (9%)] Loss: 15143.614258\n",
      "Train Epoch: 25 [22656/225000 (10%)] Loss: 14710.454102\n",
      "Train Epoch: 25 [24064/225000 (11%)] Loss: 15182.787109\n",
      "Train Epoch: 25 [25472/225000 (11%)] Loss: 15098.877930\n",
      "Train Epoch: 25 [26880/225000 (12%)] Loss: 14864.110352\n",
      "Train Epoch: 25 [28288/225000 (13%)] Loss: 15362.823242\n",
      "Train Epoch: 25 [29696/225000 (13%)] Loss: 14797.551758\n",
      "Train Epoch: 25 [31104/225000 (14%)] Loss: 14693.102539\n",
      "Train Epoch: 25 [32512/225000 (14%)] Loss: 15014.916016\n",
      "Train Epoch: 25 [33920/225000 (15%)] Loss: 15581.929688\n",
      "Train Epoch: 25 [35328/225000 (16%)] Loss: 15173.226562\n",
      "Train Epoch: 25 [36736/225000 (16%)] Loss: 15111.573242\n",
      "Train Epoch: 25 [38144/225000 (17%)] Loss: 15199.247070\n",
      "Train Epoch: 25 [39552/225000 (18%)] Loss: 14839.364258\n",
      "Train Epoch: 25 [40960/225000 (18%)] Loss: 15097.016602\n",
      "Train Epoch: 25 [42368/225000 (19%)] Loss: 14889.808594\n",
      "Train Epoch: 25 [43776/225000 (19%)] Loss: 15544.974609\n",
      "Train Epoch: 25 [45184/225000 (20%)] Loss: 14840.376953\n",
      "Train Epoch: 25 [46592/225000 (21%)] Loss: 15093.109375\n",
      "Train Epoch: 25 [48000/225000 (21%)] Loss: 15398.919922\n",
      "Train Epoch: 25 [49408/225000 (22%)] Loss: 15314.881836\n",
      "Train Epoch: 25 [50816/225000 (23%)] Loss: 15418.569336\n",
      "Train Epoch: 25 [52224/225000 (23%)] Loss: 14929.357422\n",
      "Train Epoch: 25 [53632/225000 (24%)] Loss: 14880.830078\n",
      "Train Epoch: 25 [55040/225000 (24%)] Loss: 14909.185547\n",
      "Train Epoch: 25 [56448/225000 (25%)] Loss: 14991.378906\n",
      "Train Epoch: 25 [57856/225000 (26%)] Loss: 15371.436523\n",
      "Train Epoch: 25 [59264/225000 (26%)] Loss: 14951.272461\n",
      "Train Epoch: 25 [60672/225000 (27%)] Loss: 15492.760742\n",
      "Train Epoch: 25 [62080/225000 (28%)] Loss: 15237.719727\n",
      "Train Epoch: 25 [63488/225000 (28%)] Loss: 15591.794922\n",
      "Train Epoch: 25 [64896/225000 (29%)] Loss: 15435.429688\n",
      "Train Epoch: 25 [66304/225000 (29%)] Loss: 15431.001953\n",
      "Train Epoch: 25 [67712/225000 (30%)] Loss: 15191.217773\n",
      "Train Epoch: 25 [69120/225000 (31%)] Loss: 14999.607422\n",
      "Train Epoch: 25 [70528/225000 (31%)] Loss: 15185.052734\n",
      "Train Epoch: 25 [71936/225000 (32%)] Loss: 15221.019531\n",
      "Train Epoch: 25 [73344/225000 (33%)] Loss: 14975.460938\n",
      "Train Epoch: 25 [74752/225000 (33%)] Loss: 15440.911133\n",
      "Train Epoch: 25 [76160/225000 (34%)] Loss: 14780.426758\n",
      "Train Epoch: 25 [77568/225000 (34%)] Loss: 14856.334961\n",
      "Train Epoch: 25 [78976/225000 (35%)] Loss: 14840.189453\n",
      "Train Epoch: 25 [80384/225000 (36%)] Loss: 15187.098633\n",
      "Train Epoch: 25 [81792/225000 (36%)] Loss: 15305.425781\n",
      "Train Epoch: 25 [83200/225000 (37%)] Loss: 14747.575195\n",
      "Train Epoch: 25 [84608/225000 (38%)] Loss: 14901.727539\n",
      "Train Epoch: 25 [86016/225000 (38%)] Loss: 15052.791992\n",
      "Train Epoch: 25 [87424/225000 (39%)] Loss: 15501.636719\n",
      "Train Epoch: 25 [88832/225000 (39%)] Loss: 14898.916992\n",
      "Train Epoch: 25 [90240/225000 (40%)] Loss: 15099.053711\n",
      "Train Epoch: 25 [91648/225000 (41%)] Loss: 15040.348633\n",
      "Train Epoch: 25 [93056/225000 (41%)] Loss: 14956.268555\n",
      "Train Epoch: 25 [94464/225000 (42%)] Loss: 15063.044922\n",
      "Train Epoch: 25 [95872/225000 (43%)] Loss: 15023.865234\n",
      "Train Epoch: 25 [97280/225000 (43%)] Loss: 15048.834961\n",
      "Train Epoch: 25 [98688/225000 (44%)] Loss: 14985.733398\n",
      "Train Epoch: 25 [100096/225000 (44%)] Loss: 15157.167969\n",
      "Train Epoch: 25 [101504/225000 (45%)] Loss: 14971.441406\n",
      "Train Epoch: 25 [102912/225000 (46%)] Loss: 15365.285156\n",
      "Train Epoch: 25 [104320/225000 (46%)] Loss: 14723.339844\n",
      "Train Epoch: 25 [105728/225000 (47%)] Loss: 15095.334961\n",
      "Train Epoch: 25 [107136/225000 (48%)] Loss: 14967.469727\n",
      "Train Epoch: 25 [108544/225000 (48%)] Loss: 15374.586914\n",
      "Train Epoch: 25 [109952/225000 (49%)] Loss: 15266.000000\n",
      "Train Epoch: 25 [111360/225000 (49%)] Loss: 14847.395508\n",
      "Train Epoch: 25 [112768/225000 (50%)] Loss: 20605.640625\n",
      "Train Epoch: 25 [114176/225000 (51%)] Loss: 15380.501953\n",
      "Train Epoch: 25 [115584/225000 (51%)] Loss: 15129.375000\n",
      "Train Epoch: 25 [116992/225000 (52%)] Loss: 15477.491211\n",
      "Train Epoch: 25 [118400/225000 (53%)] Loss: 14847.805664\n",
      "Train Epoch: 25 [119808/225000 (53%)] Loss: 15086.630859\n",
      "Train Epoch: 25 [121216/225000 (54%)] Loss: 14935.674805\n",
      "Train Epoch: 25 [122624/225000 (54%)] Loss: 15022.925781\n",
      "Train Epoch: 25 [124032/225000 (55%)] Loss: 15225.647461\n",
      "Train Epoch: 25 [125440/225000 (56%)] Loss: 15262.864258\n",
      "Train Epoch: 25 [126848/225000 (56%)] Loss: 15065.034180\n",
      "Train Epoch: 25 [128256/225000 (57%)] Loss: 14802.302734\n",
      "Train Epoch: 25 [129664/225000 (58%)] Loss: 15410.209961\n",
      "Train Epoch: 25 [131072/225000 (58%)] Loss: 17393.558594\n",
      "Train Epoch: 25 [132480/225000 (59%)] Loss: 14740.227539\n",
      "Train Epoch: 25 [133888/225000 (60%)] Loss: 14898.207031\n",
      "Train Epoch: 25 [135296/225000 (60%)] Loss: 15037.094727\n",
      "Train Epoch: 25 [136704/225000 (61%)] Loss: 15137.162109\n",
      "Train Epoch: 25 [138112/225000 (61%)] Loss: 15354.212891\n",
      "Train Epoch: 25 [139520/225000 (62%)] Loss: 14666.632812\n",
      "Train Epoch: 25 [140928/225000 (63%)] Loss: 15275.604492\n",
      "Train Epoch: 25 [142336/225000 (63%)] Loss: 14517.596680\n",
      "Train Epoch: 25 [143744/225000 (64%)] Loss: 15171.219727\n",
      "Train Epoch: 25 [145152/225000 (65%)] Loss: 14730.467773\n",
      "Train Epoch: 25 [146560/225000 (65%)] Loss: 14748.801758\n",
      "Train Epoch: 25 [147968/225000 (66%)] Loss: 15074.126953\n",
      "Train Epoch: 25 [149376/225000 (66%)] Loss: 15296.518555\n",
      "Train Epoch: 25 [150784/225000 (67%)] Loss: 14770.824219\n",
      "Train Epoch: 25 [152192/225000 (68%)] Loss: 15158.920898\n",
      "Train Epoch: 25 [153600/225000 (68%)] Loss: 15164.625000\n",
      "Train Epoch: 25 [155008/225000 (69%)] Loss: 22302.339844\n",
      "Train Epoch: 25 [156416/225000 (70%)] Loss: 15268.666992\n",
      "Train Epoch: 25 [157824/225000 (70%)] Loss: 15094.561523\n",
      "Train Epoch: 25 [159232/225000 (71%)] Loss: 15166.252930\n",
      "Train Epoch: 25 [160640/225000 (71%)] Loss: 15078.048828\n",
      "Train Epoch: 25 [162048/225000 (72%)] Loss: 14993.881836\n",
      "Train Epoch: 25 [163456/225000 (73%)] Loss: 15072.428711\n",
      "Train Epoch: 25 [164864/225000 (73%)] Loss: 14944.306641\n",
      "Train Epoch: 25 [166272/225000 (74%)] Loss: 15514.430664\n",
      "Train Epoch: 25 [167680/225000 (75%)] Loss: 14798.028320\n",
      "Train Epoch: 25 [169088/225000 (75%)] Loss: 15424.720703\n",
      "Train Epoch: 25 [170496/225000 (76%)] Loss: 15054.398438\n",
      "Train Epoch: 25 [171904/225000 (76%)] Loss: 15123.015625\n",
      "Train Epoch: 25 [173312/225000 (77%)] Loss: 14950.705078\n",
      "Train Epoch: 25 [174720/225000 (78%)] Loss: 15416.377930\n",
      "Train Epoch: 25 [176128/225000 (78%)] Loss: 14741.883789\n",
      "Train Epoch: 25 [177536/225000 (79%)] Loss: 14986.833984\n",
      "Train Epoch: 25 [178944/225000 (80%)] Loss: 15302.469727\n",
      "Train Epoch: 25 [180352/225000 (80%)] Loss: 15247.883789\n",
      "Train Epoch: 25 [181760/225000 (81%)] Loss: 15097.875000\n",
      "Train Epoch: 25 [183168/225000 (81%)] Loss: 15204.897461\n",
      "Train Epoch: 25 [184576/225000 (82%)] Loss: 14789.645508\n",
      "Train Epoch: 25 [185984/225000 (83%)] Loss: 14933.632812\n",
      "Train Epoch: 25 [187392/225000 (83%)] Loss: 14967.909180\n",
      "Train Epoch: 25 [188800/225000 (84%)] Loss: 14752.978516\n",
      "Train Epoch: 25 [190208/225000 (85%)] Loss: 14763.612305\n",
      "Train Epoch: 25 [191616/225000 (85%)] Loss: 14879.046875\n",
      "Train Epoch: 25 [193024/225000 (86%)] Loss: 15302.679688\n",
      "Train Epoch: 25 [194432/225000 (86%)] Loss: 15094.373047\n",
      "Train Epoch: 25 [195840/225000 (87%)] Loss: 14646.159180\n",
      "Train Epoch: 25 [197248/225000 (88%)] Loss: 15352.300781\n",
      "Train Epoch: 25 [198656/225000 (88%)] Loss: 15052.724609\n",
      "Train Epoch: 25 [200064/225000 (89%)] Loss: 15407.632812\n",
      "Train Epoch: 25 [201472/225000 (90%)] Loss: 15056.078125\n",
      "Train Epoch: 25 [202880/225000 (90%)] Loss: 15274.836914\n",
      "Train Epoch: 25 [204288/225000 (91%)] Loss: 15311.809570\n",
      "Train Epoch: 25 [205696/225000 (91%)] Loss: 15021.572266\n",
      "Train Epoch: 25 [207104/225000 (92%)] Loss: 15151.601562\n",
      "Train Epoch: 25 [208512/225000 (93%)] Loss: 15365.261719\n",
      "Train Epoch: 25 [209920/225000 (93%)] Loss: 15482.851562\n",
      "Train Epoch: 25 [211328/225000 (94%)] Loss: 14974.153320\n",
      "Train Epoch: 25 [212736/225000 (95%)] Loss: 15223.466797\n",
      "Train Epoch: 25 [214144/225000 (95%)] Loss: 14972.609375\n",
      "Train Epoch: 25 [215552/225000 (96%)] Loss: 15063.701172\n",
      "Train Epoch: 25 [216960/225000 (96%)] Loss: 14968.882812\n",
      "Train Epoch: 25 [218368/225000 (97%)] Loss: 15438.819336\n",
      "Train Epoch: 25 [219776/225000 (98%)] Loss: 15334.258789\n",
      "Train Epoch: 25 [221184/225000 (98%)] Loss: 14973.223633\n",
      "Train Epoch: 25 [222592/225000 (99%)] Loss: 15021.535156\n",
      "Train Epoch: 25 [224000/225000 (100%)] Loss: 14989.983398\n",
      "    epoch          : 25\n",
      "    loss           : 15101.984732184123\n",
      "    val_loss       : 15063.359925861108\n",
      "Train Epoch: 26 [128/225000 (0%)] Loss: 15417.923828\n",
      "Train Epoch: 26 [1536/225000 (1%)] Loss: 14745.473633\n",
      "Train Epoch: 26 [2944/225000 (1%)] Loss: 15184.711914\n",
      "Train Epoch: 26 [4352/225000 (2%)] Loss: 15342.237305\n",
      "Train Epoch: 26 [5760/225000 (3%)] Loss: 15505.498047\n",
      "Train Epoch: 26 [7168/225000 (3%)] Loss: 15214.507812\n",
      "Train Epoch: 26 [8576/225000 (4%)] Loss: 15176.684570\n",
      "Train Epoch: 26 [9984/225000 (4%)] Loss: 15005.379883\n",
      "Train Epoch: 26 [11392/225000 (5%)] Loss: 15171.581055\n",
      "Train Epoch: 26 [12800/225000 (6%)] Loss: 14972.792969\n",
      "Train Epoch: 26 [14208/225000 (6%)] Loss: 15407.416016\n",
      "Train Epoch: 26 [15616/225000 (7%)] Loss: 15340.305664\n",
      "Train Epoch: 26 [17024/225000 (8%)] Loss: 14851.462891\n",
      "Train Epoch: 26 [18432/225000 (8%)] Loss: 14822.064453\n",
      "Train Epoch: 26 [19840/225000 (9%)] Loss: 14975.309570\n",
      "Train Epoch: 26 [21248/225000 (9%)] Loss: 14973.714844\n",
      "Train Epoch: 26 [22656/225000 (10%)] Loss: 14861.232422\n",
      "Train Epoch: 26 [24064/225000 (11%)] Loss: 15045.361328\n",
      "Train Epoch: 26 [25472/225000 (11%)] Loss: 15280.706055\n",
      "Train Epoch: 26 [26880/225000 (12%)] Loss: 14825.833984\n",
      "Train Epoch: 26 [28288/225000 (13%)] Loss: 14990.852539\n",
      "Train Epoch: 26 [29696/225000 (13%)] Loss: 14786.576172\n",
      "Train Epoch: 26 [31104/225000 (14%)] Loss: 14853.315430\n",
      "Train Epoch: 26 [32512/225000 (14%)] Loss: 14889.978516\n",
      "Train Epoch: 26 [33920/225000 (15%)] Loss: 14825.768555\n",
      "Train Epoch: 26 [35328/225000 (16%)] Loss: 15027.269531\n",
      "Train Epoch: 26 [36736/225000 (16%)] Loss: 15261.981445\n",
      "Train Epoch: 26 [38144/225000 (17%)] Loss: 15027.934570\n",
      "Train Epoch: 26 [39552/225000 (18%)] Loss: 15029.295898\n",
      "Train Epoch: 26 [40960/225000 (18%)] Loss: 15479.665039\n",
      "Train Epoch: 26 [42368/225000 (19%)] Loss: 15304.079102\n",
      "Train Epoch: 26 [43776/225000 (19%)] Loss: 15289.820312\n",
      "Train Epoch: 26 [45184/225000 (20%)] Loss: 15116.718750\n",
      "Train Epoch: 26 [46592/225000 (21%)] Loss: 15324.549805\n",
      "Train Epoch: 26 [48000/225000 (21%)] Loss: 15332.833008\n",
      "Train Epoch: 26 [49408/225000 (22%)] Loss: 15554.476562\n",
      "Train Epoch: 26 [50816/225000 (23%)] Loss: 15506.881836\n",
      "Train Epoch: 26 [52224/225000 (23%)] Loss: 15117.764648\n",
      "Train Epoch: 26 [53632/225000 (24%)] Loss: 14989.137695\n",
      "Train Epoch: 26 [55040/225000 (24%)] Loss: 14691.479492\n",
      "Train Epoch: 26 [56448/225000 (25%)] Loss: 15198.230469\n",
      "Train Epoch: 26 [57856/225000 (26%)] Loss: 15182.855469\n",
      "Train Epoch: 26 [59264/225000 (26%)] Loss: 14779.161133\n",
      "Train Epoch: 26 [60672/225000 (27%)] Loss: 15231.387695\n",
      "Train Epoch: 26 [62080/225000 (28%)] Loss: 15375.979492\n",
      "Train Epoch: 26 [63488/225000 (28%)] Loss: 14836.641602\n",
      "Train Epoch: 26 [64896/225000 (29%)] Loss: 14836.696289\n",
      "Train Epoch: 26 [66304/225000 (29%)] Loss: 14871.326172\n",
      "Train Epoch: 26 [67712/225000 (30%)] Loss: 14792.851562\n",
      "Train Epoch: 26 [69120/225000 (31%)] Loss: 15558.221680\n",
      "Train Epoch: 26 [70528/225000 (31%)] Loss: 14898.182617\n",
      "Train Epoch: 26 [71936/225000 (32%)] Loss: 14991.916992\n",
      "Train Epoch: 26 [73344/225000 (33%)] Loss: 15314.202148\n",
      "Train Epoch: 26 [74752/225000 (33%)] Loss: 14711.827148\n",
      "Train Epoch: 26 [76160/225000 (34%)] Loss: 15292.114258\n",
      "Train Epoch: 26 [77568/225000 (34%)] Loss: 14703.119141\n",
      "Train Epoch: 26 [78976/225000 (35%)] Loss: 15328.368164\n",
      "Train Epoch: 26 [80384/225000 (36%)] Loss: 15674.256836\n",
      "Train Epoch: 26 [81792/225000 (36%)] Loss: 15064.902344\n",
      "Train Epoch: 26 [83200/225000 (37%)] Loss: 14994.591797\n",
      "Train Epoch: 26 [84608/225000 (38%)] Loss: 14574.159180\n",
      "Train Epoch: 26 [86016/225000 (38%)] Loss: 16351.254883\n",
      "Train Epoch: 26 [87424/225000 (39%)] Loss: 14869.600586\n",
      "Train Epoch: 26 [88832/225000 (39%)] Loss: 14679.861328\n",
      "Train Epoch: 26 [90240/225000 (40%)] Loss: 15069.900391\n",
      "Train Epoch: 26 [91648/225000 (41%)] Loss: 15282.641602\n",
      "Train Epoch: 26 [93056/225000 (41%)] Loss: 15047.939453\n",
      "Train Epoch: 26 [94464/225000 (42%)] Loss: 14975.250977\n",
      "Train Epoch: 26 [95872/225000 (43%)] Loss: 14960.930664\n",
      "Train Epoch: 26 [97280/225000 (43%)] Loss: 15205.534180\n",
      "Train Epoch: 26 [98688/225000 (44%)] Loss: 15345.741211\n",
      "Train Epoch: 26 [100096/225000 (44%)] Loss: 15249.382812\n",
      "Train Epoch: 26 [101504/225000 (45%)] Loss: 15379.145508\n",
      "Train Epoch: 26 [102912/225000 (46%)] Loss: 15193.598633\n",
      "Train Epoch: 26 [104320/225000 (46%)] Loss: 15403.532227\n",
      "Train Epoch: 26 [105728/225000 (47%)] Loss: 15343.936523\n",
      "Train Epoch: 26 [107136/225000 (48%)] Loss: 15207.017578\n",
      "Train Epoch: 26 [108544/225000 (48%)] Loss: 14836.302734\n",
      "Train Epoch: 26 [109952/225000 (49%)] Loss: 14468.124023\n",
      "Train Epoch: 26 [111360/225000 (49%)] Loss: 15344.566406\n",
      "Train Epoch: 26 [112768/225000 (50%)] Loss: 14843.452148\n",
      "Train Epoch: 26 [114176/225000 (51%)] Loss: 15008.479492\n",
      "Train Epoch: 26 [115584/225000 (51%)] Loss: 15009.614258\n",
      "Train Epoch: 26 [116992/225000 (52%)] Loss: 15111.159180\n",
      "Train Epoch: 26 [118400/225000 (53%)] Loss: 15177.778320\n",
      "Train Epoch: 26 [119808/225000 (53%)] Loss: 14991.067383\n",
      "Train Epoch: 26 [121216/225000 (54%)] Loss: 14814.986328\n",
      "Train Epoch: 26 [122624/225000 (54%)] Loss: 15231.266602\n",
      "Train Epoch: 26 [124032/225000 (55%)] Loss: 14924.846680\n",
      "Train Epoch: 26 [125440/225000 (56%)] Loss: 15700.104492\n",
      "Train Epoch: 26 [126848/225000 (56%)] Loss: 14848.813477\n",
      "Train Epoch: 26 [128256/225000 (57%)] Loss: 14711.827148\n",
      "Train Epoch: 26 [129664/225000 (58%)] Loss: 14995.029297\n",
      "Train Epoch: 26 [131072/225000 (58%)] Loss: 15001.736328\n",
      "Train Epoch: 26 [132480/225000 (59%)] Loss: 14953.968750\n",
      "Train Epoch: 26 [133888/225000 (60%)] Loss: 15346.041992\n",
      "Train Epoch: 26 [135296/225000 (60%)] Loss: 14784.862305\n",
      "Train Epoch: 26 [136704/225000 (61%)] Loss: 15026.970703\n",
      "Train Epoch: 26 [138112/225000 (61%)] Loss: 15009.884766\n",
      "Train Epoch: 26 [139520/225000 (62%)] Loss: 14394.171875\n",
      "Train Epoch: 26 [140928/225000 (63%)] Loss: 14849.813477\n",
      "Train Epoch: 26 [142336/225000 (63%)] Loss: 14781.292969\n",
      "Train Epoch: 26 [143744/225000 (64%)] Loss: 15169.280273\n",
      "Train Epoch: 26 [145152/225000 (65%)] Loss: 15070.780273\n",
      "Train Epoch: 26 [146560/225000 (65%)] Loss: 14876.567383\n",
      "Train Epoch: 26 [147968/225000 (66%)] Loss: 15180.028320\n",
      "Train Epoch: 26 [149376/225000 (66%)] Loss: 15065.523438\n",
      "Train Epoch: 26 [150784/225000 (67%)] Loss: 15123.634766\n",
      "Train Epoch: 26 [152192/225000 (68%)] Loss: 15004.025391\n",
      "Train Epoch: 26 [153600/225000 (68%)] Loss: 15127.283203\n",
      "Train Epoch: 26 [155008/225000 (69%)] Loss: 14905.254883\n",
      "Train Epoch: 26 [156416/225000 (70%)] Loss: 14633.258789\n",
      "Train Epoch: 26 [157824/225000 (70%)] Loss: 15485.047852\n",
      "Train Epoch: 26 [159232/225000 (71%)] Loss: 14855.270508\n",
      "Train Epoch: 26 [160640/225000 (71%)] Loss: 15139.389648\n",
      "Train Epoch: 26 [162048/225000 (72%)] Loss: 15169.359375\n",
      "Train Epoch: 26 [163456/225000 (73%)] Loss: 15236.370117\n",
      "Train Epoch: 26 [164864/225000 (73%)] Loss: 15098.136719\n",
      "Train Epoch: 26 [166272/225000 (74%)] Loss: 14806.779297\n",
      "Train Epoch: 26 [167680/225000 (75%)] Loss: 14643.477539\n",
      "Train Epoch: 26 [169088/225000 (75%)] Loss: 15630.013672\n",
      "Train Epoch: 26 [170496/225000 (76%)] Loss: 15235.085938\n",
      "Train Epoch: 26 [171904/225000 (76%)] Loss: 14783.775391\n",
      "Train Epoch: 26 [173312/225000 (77%)] Loss: 14814.460938\n",
      "Train Epoch: 26 [174720/225000 (78%)] Loss: 15150.647461\n",
      "Train Epoch: 26 [176128/225000 (78%)] Loss: 14886.145508\n",
      "Train Epoch: 26 [177536/225000 (79%)] Loss: 15100.410156\n",
      "Train Epoch: 26 [178944/225000 (80%)] Loss: 14860.571289\n",
      "Train Epoch: 26 [180352/225000 (80%)] Loss: 14968.157227\n",
      "Train Epoch: 26 [181760/225000 (81%)] Loss: 15180.812500\n",
      "Train Epoch: 26 [183168/225000 (81%)] Loss: 14658.135742\n",
      "Train Epoch: 26 [184576/225000 (82%)] Loss: 15086.020508\n",
      "Train Epoch: 26 [185984/225000 (83%)] Loss: 14690.447266\n",
      "Train Epoch: 26 [187392/225000 (83%)] Loss: 15096.427734\n",
      "Train Epoch: 26 [188800/225000 (84%)] Loss: 15193.594727\n",
      "Train Epoch: 26 [190208/225000 (85%)] Loss: 14935.154297\n",
      "Train Epoch: 26 [191616/225000 (85%)] Loss: 15237.164062\n",
      "Train Epoch: 26 [193024/225000 (86%)] Loss: 15185.765625\n",
      "Train Epoch: 26 [194432/225000 (86%)] Loss: 15283.827148\n",
      "Train Epoch: 26 [195840/225000 (87%)] Loss: 15286.906250\n",
      "Train Epoch: 26 [197248/225000 (88%)] Loss: 14769.961914\n",
      "Train Epoch: 26 [198656/225000 (88%)] Loss: 15125.329102\n",
      "Train Epoch: 26 [200064/225000 (89%)] Loss: 15029.502930\n",
      "Train Epoch: 26 [201472/225000 (90%)] Loss: 15216.456055\n",
      "Train Epoch: 26 [202880/225000 (90%)] Loss: 14514.291016\n",
      "Train Epoch: 26 [204288/225000 (91%)] Loss: 15037.476562\n",
      "Train Epoch: 26 [205696/225000 (91%)] Loss: 15024.511719\n",
      "Train Epoch: 26 [207104/225000 (92%)] Loss: 14795.294922\n",
      "Train Epoch: 26 [208512/225000 (93%)] Loss: 14931.440430\n",
      "Train Epoch: 26 [209920/225000 (93%)] Loss: 15232.549805\n",
      "Train Epoch: 26 [211328/225000 (94%)] Loss: 15065.887695\n",
      "Train Epoch: 26 [212736/225000 (95%)] Loss: 15122.254883\n",
      "Train Epoch: 26 [214144/225000 (95%)] Loss: 14910.530273\n",
      "Train Epoch: 26 [215552/225000 (96%)] Loss: 15019.587891\n",
      "Train Epoch: 26 [216960/225000 (96%)] Loss: 14789.648438\n",
      "Train Epoch: 26 [218368/225000 (97%)] Loss: 14970.286133\n",
      "Train Epoch: 26 [219776/225000 (98%)] Loss: 14777.247070\n",
      "Train Epoch: 26 [221184/225000 (98%)] Loss: 15130.242188\n",
      "Train Epoch: 26 [222592/225000 (99%)] Loss: 15145.990234\n",
      "Train Epoch: 26 [224000/225000 (100%)] Loss: 14906.902344\n",
      "    epoch          : 26\n",
      "    loss           : 15101.09192297266\n",
      "    val_loss       : 15095.11886083958\n",
      "Train Epoch: 27 [128/225000 (0%)] Loss: 15271.838867\n",
      "Train Epoch: 27 [1536/225000 (1%)] Loss: 15473.504883\n",
      "Train Epoch: 27 [2944/225000 (1%)] Loss: 15128.297852\n",
      "Train Epoch: 27 [4352/225000 (2%)] Loss: 15218.162109\n",
      "Train Epoch: 27 [5760/225000 (3%)] Loss: 15229.802734\n",
      "Train Epoch: 27 [7168/225000 (3%)] Loss: 14961.095703\n",
      "Train Epoch: 27 [8576/225000 (4%)] Loss: 15034.355469\n",
      "Train Epoch: 27 [9984/225000 (4%)] Loss: 15003.348633\n",
      "Train Epoch: 27 [11392/225000 (5%)] Loss: 14890.441406\n",
      "Train Epoch: 27 [12800/225000 (6%)] Loss: 15170.937500\n",
      "Train Epoch: 27 [14208/225000 (6%)] Loss: 15135.557617\n",
      "Train Epoch: 27 [15616/225000 (7%)] Loss: 15517.159180\n",
      "Train Epoch: 27 [17024/225000 (8%)] Loss: 15171.544922\n",
      "Train Epoch: 27 [18432/225000 (8%)] Loss: 15426.109375\n",
      "Train Epoch: 27 [19840/225000 (9%)] Loss: 14725.622070\n",
      "Train Epoch: 27 [21248/225000 (9%)] Loss: 15017.026367\n",
      "Train Epoch: 27 [22656/225000 (10%)] Loss: 15142.240234\n",
      "Train Epoch: 27 [24064/225000 (11%)] Loss: 15261.612305\n",
      "Train Epoch: 27 [25472/225000 (11%)] Loss: 14781.181641\n",
      "Train Epoch: 27 [26880/225000 (12%)] Loss: 15075.953125\n",
      "Train Epoch: 27 [28288/225000 (13%)] Loss: 14685.249023\n",
      "Train Epoch: 27 [29696/225000 (13%)] Loss: 14782.331055\n",
      "Train Epoch: 27 [31104/225000 (14%)] Loss: 14804.917969\n",
      "Train Epoch: 27 [32512/225000 (14%)] Loss: 14839.895508\n",
      "Train Epoch: 27 [33920/225000 (15%)] Loss: 15277.648438\n",
      "Train Epoch: 27 [35328/225000 (16%)] Loss: 14986.683594\n",
      "Train Epoch: 27 [36736/225000 (16%)] Loss: 15083.192383\n",
      "Train Epoch: 27 [38144/225000 (17%)] Loss: 15020.793945\n",
      "Train Epoch: 27 [39552/225000 (18%)] Loss: 15275.263672\n",
      "Train Epoch: 27 [40960/225000 (18%)] Loss: 15179.222656\n",
      "Train Epoch: 27 [42368/225000 (19%)] Loss: 14778.497070\n",
      "Train Epoch: 27 [43776/225000 (19%)] Loss: 14803.787109\n",
      "Train Epoch: 27 [45184/225000 (20%)] Loss: 15081.937500\n",
      "Train Epoch: 27 [46592/225000 (21%)] Loss: 14912.547852\n",
      "Train Epoch: 27 [48000/225000 (21%)] Loss: 15232.456055\n",
      "Train Epoch: 27 [49408/225000 (22%)] Loss: 15276.511719\n",
      "Train Epoch: 27 [50816/225000 (23%)] Loss: 15282.410156\n",
      "Train Epoch: 27 [52224/225000 (23%)] Loss: 14634.988281\n",
      "Train Epoch: 27 [53632/225000 (24%)] Loss: 14525.687500\n",
      "Train Epoch: 27 [55040/225000 (24%)] Loss: 14894.568359\n",
      "Train Epoch: 27 [56448/225000 (25%)] Loss: 15311.979492\n",
      "Train Epoch: 27 [57856/225000 (26%)] Loss: 14778.861328\n",
      "Train Epoch: 27 [59264/225000 (26%)] Loss: 15263.008789\n",
      "Train Epoch: 27 [60672/225000 (27%)] Loss: 14804.249023\n",
      "Train Epoch: 27 [62080/225000 (28%)] Loss: 14780.050781\n",
      "Train Epoch: 27 [63488/225000 (28%)] Loss: 15106.755859\n",
      "Train Epoch: 27 [64896/225000 (29%)] Loss: 15019.691406\n",
      "Train Epoch: 27 [66304/225000 (29%)] Loss: 15154.460938\n",
      "Train Epoch: 27 [67712/225000 (30%)] Loss: 15204.881836\n",
      "Train Epoch: 27 [69120/225000 (31%)] Loss: 15007.457031\n",
      "Train Epoch: 27 [70528/225000 (31%)] Loss: 15215.882812\n",
      "Train Epoch: 27 [71936/225000 (32%)] Loss: 15266.558594\n",
      "Train Epoch: 27 [73344/225000 (33%)] Loss: 15201.055664\n",
      "Train Epoch: 27 [74752/225000 (33%)] Loss: 15245.865234\n",
      "Train Epoch: 27 [76160/225000 (34%)] Loss: 14517.973633\n",
      "Train Epoch: 27 [77568/225000 (34%)] Loss: 15114.260742\n",
      "Train Epoch: 27 [78976/225000 (35%)] Loss: 15203.996094\n",
      "Train Epoch: 27 [80384/225000 (36%)] Loss: 14896.383789\n",
      "Train Epoch: 27 [81792/225000 (36%)] Loss: 15229.555664\n",
      "Train Epoch: 27 [83200/225000 (37%)] Loss: 14826.935547\n",
      "Train Epoch: 27 [84608/225000 (38%)] Loss: 14819.041992\n",
      "Train Epoch: 27 [86016/225000 (38%)] Loss: 15284.500000\n",
      "Train Epoch: 27 [87424/225000 (39%)] Loss: 15514.798828\n",
      "Train Epoch: 27 [88832/225000 (39%)] Loss: 15102.958008\n",
      "Train Epoch: 27 [90240/225000 (40%)] Loss: 15431.354492\n",
      "Train Epoch: 27 [91648/225000 (41%)] Loss: 14348.362305\n",
      "Train Epoch: 27 [93056/225000 (41%)] Loss: 14984.485352\n",
      "Train Epoch: 27 [94464/225000 (42%)] Loss: 15983.458984\n",
      "Train Epoch: 27 [95872/225000 (43%)] Loss: 15118.413086\n",
      "Train Epoch: 27 [97280/225000 (43%)] Loss: 15007.167969\n",
      "Train Epoch: 27 [98688/225000 (44%)] Loss: 14949.868164\n",
      "Train Epoch: 27 [100096/225000 (44%)] Loss: 15110.273438\n",
      "Train Epoch: 27 [101504/225000 (45%)] Loss: 14890.270508\n",
      "Train Epoch: 27 [102912/225000 (46%)] Loss: 15115.280273\n",
      "Train Epoch: 27 [104320/225000 (46%)] Loss: 14903.397461\n",
      "Train Epoch: 27 [105728/225000 (47%)] Loss: 15387.512695\n",
      "Train Epoch: 27 [107136/225000 (48%)] Loss: 14502.129883\n",
      "Train Epoch: 27 [108544/225000 (48%)] Loss: 14833.278320\n",
      "Train Epoch: 27 [109952/225000 (49%)] Loss: 15025.862305\n",
      "Train Epoch: 27 [111360/225000 (49%)] Loss: 15296.560547\n",
      "Train Epoch: 27 [112768/225000 (50%)] Loss: 14828.241211\n",
      "Train Epoch: 27 [114176/225000 (51%)] Loss: 15142.404297\n",
      "Train Epoch: 27 [115584/225000 (51%)] Loss: 15102.500977\n",
      "Train Epoch: 27 [116992/225000 (52%)] Loss: 14881.544922\n",
      "Train Epoch: 27 [118400/225000 (53%)] Loss: 14825.467773\n",
      "Train Epoch: 27 [119808/225000 (53%)] Loss: 15368.361328\n",
      "Train Epoch: 27 [121216/225000 (54%)] Loss: 15086.441406\n",
      "Train Epoch: 27 [122624/225000 (54%)] Loss: 15131.602539\n",
      "Train Epoch: 27 [124032/225000 (55%)] Loss: 15018.447266\n",
      "Train Epoch: 27 [125440/225000 (56%)] Loss: 15190.658203\n",
      "Train Epoch: 27 [126848/225000 (56%)] Loss: 15311.094727\n",
      "Train Epoch: 27 [128256/225000 (57%)] Loss: 14966.161133\n",
      "Train Epoch: 27 [129664/225000 (58%)] Loss: 14912.743164\n",
      "Train Epoch: 27 [131072/225000 (58%)] Loss: 14943.476562\n",
      "Train Epoch: 27 [132480/225000 (59%)] Loss: 15301.908203\n",
      "Train Epoch: 27 [133888/225000 (60%)] Loss: 14713.433594\n",
      "Train Epoch: 27 [135296/225000 (60%)] Loss: 14671.539062\n",
      "Train Epoch: 27 [136704/225000 (61%)] Loss: 14369.173828\n",
      "Train Epoch: 27 [138112/225000 (61%)] Loss: 15159.921875\n",
      "Train Epoch: 27 [139520/225000 (62%)] Loss: 14918.869141\n",
      "Train Epoch: 27 [140928/225000 (63%)] Loss: 15020.483398\n",
      "Train Epoch: 27 [142336/225000 (63%)] Loss: 15825.166016\n",
      "Train Epoch: 27 [143744/225000 (64%)] Loss: 15173.037109\n",
      "Train Epoch: 27 [145152/225000 (65%)] Loss: 15515.856445\n",
      "Train Epoch: 27 [146560/225000 (65%)] Loss: 15060.253906\n",
      "Train Epoch: 27 [147968/225000 (66%)] Loss: 15680.127930\n",
      "Train Epoch: 27 [149376/225000 (66%)] Loss: 14981.625000\n",
      "Train Epoch: 27 [150784/225000 (67%)] Loss: 14939.256836\n",
      "Train Epoch: 27 [152192/225000 (68%)] Loss: 15054.005859\n",
      "Train Epoch: 27 [153600/225000 (68%)] Loss: 15361.493164\n",
      "Train Epoch: 27 [155008/225000 (69%)] Loss: 15439.928711\n",
      "Train Epoch: 27 [156416/225000 (70%)] Loss: 15546.565430\n",
      "Train Epoch: 27 [157824/225000 (70%)] Loss: 14878.041992\n",
      "Train Epoch: 27 [159232/225000 (71%)] Loss: 15297.267578\n",
      "Train Epoch: 27 [160640/225000 (71%)] Loss: 14769.452148\n",
      "Train Epoch: 27 [162048/225000 (72%)] Loss: 15369.885742\n",
      "Train Epoch: 27 [163456/225000 (73%)] Loss: 14818.186523\n",
      "Train Epoch: 27 [164864/225000 (73%)] Loss: 14989.881836\n",
      "Train Epoch: 27 [166272/225000 (74%)] Loss: 14941.154297\n",
      "Train Epoch: 27 [167680/225000 (75%)] Loss: 15178.334961\n",
      "Train Epoch: 27 [169088/225000 (75%)] Loss: 14880.521484\n",
      "Train Epoch: 27 [170496/225000 (76%)] Loss: 14986.328125\n",
      "Train Epoch: 27 [171904/225000 (76%)] Loss: 15309.147461\n",
      "Train Epoch: 27 [173312/225000 (77%)] Loss: 15000.062500\n",
      "Train Epoch: 27 [174720/225000 (78%)] Loss: 15193.730469\n",
      "Train Epoch: 27 [176128/225000 (78%)] Loss: 14892.043945\n",
      "Train Epoch: 27 [177536/225000 (79%)] Loss: 15158.657227\n",
      "Train Epoch: 27 [178944/225000 (80%)] Loss: 15417.617188\n",
      "Train Epoch: 27 [180352/225000 (80%)] Loss: 15028.338867\n",
      "Train Epoch: 27 [181760/225000 (81%)] Loss: 14917.524414\n",
      "Train Epoch: 27 [183168/225000 (81%)] Loss: 14908.905273\n",
      "Train Epoch: 27 [184576/225000 (82%)] Loss: 14909.645508\n",
      "Train Epoch: 27 [185984/225000 (83%)] Loss: 15187.634766\n",
      "Train Epoch: 27 [187392/225000 (83%)] Loss: 14982.712891\n",
      "Train Epoch: 27 [188800/225000 (84%)] Loss: 15318.615234\n",
      "Train Epoch: 27 [190208/225000 (85%)] Loss: 14796.664062\n",
      "Train Epoch: 27 [191616/225000 (85%)] Loss: 15334.433594\n",
      "Train Epoch: 27 [193024/225000 (86%)] Loss: 15463.891602\n",
      "Train Epoch: 27 [194432/225000 (86%)] Loss: 15253.454102\n",
      "Train Epoch: 27 [195840/225000 (87%)] Loss: 14866.026367\n",
      "Train Epoch: 27 [197248/225000 (88%)] Loss: 15410.324219\n",
      "Train Epoch: 27 [198656/225000 (88%)] Loss: 14844.934570\n",
      "Train Epoch: 27 [200064/225000 (89%)] Loss: 15285.181641\n",
      "Train Epoch: 27 [201472/225000 (90%)] Loss: 15219.669922\n",
      "Train Epoch: 27 [202880/225000 (90%)] Loss: 14886.275391\n",
      "Train Epoch: 27 [204288/225000 (91%)] Loss: 14995.712891\n",
      "Train Epoch: 27 [205696/225000 (91%)] Loss: 15178.386719\n",
      "Train Epoch: 27 [207104/225000 (92%)] Loss: 15142.195312\n",
      "Train Epoch: 27 [208512/225000 (93%)] Loss: 15048.283203\n",
      "Train Epoch: 27 [209920/225000 (93%)] Loss: 15092.052734\n",
      "Train Epoch: 27 [211328/225000 (94%)] Loss: 14914.494141\n",
      "Train Epoch: 27 [212736/225000 (95%)] Loss: 15042.571289\n",
      "Train Epoch: 27 [214144/225000 (95%)] Loss: 14981.791016\n",
      "Train Epoch: 27 [215552/225000 (96%)] Loss: 14895.282227\n",
      "Train Epoch: 27 [216960/225000 (96%)] Loss: 14747.500977\n",
      "Train Epoch: 27 [218368/225000 (97%)] Loss: 14948.171875\n",
      "Train Epoch: 27 [219776/225000 (98%)] Loss: 15582.683594\n",
      "Train Epoch: 27 [221184/225000 (98%)] Loss: 14985.518555\n",
      "Train Epoch: 27 [222592/225000 (99%)] Loss: 15523.221680\n",
      "Train Epoch: 27 [224000/225000 (100%)] Loss: 15578.704102\n",
      "    epoch          : 27\n",
      "    loss           : 15092.722407387657\n",
      "    val_loss       : 15075.730078781746\n",
      "Train Epoch: 28 [128/225000 (0%)] Loss: 15092.654297\n",
      "Train Epoch: 28 [1536/225000 (1%)] Loss: 14693.081055\n",
      "Train Epoch: 28 [2944/225000 (1%)] Loss: 15073.858398\n",
      "Train Epoch: 28 [4352/225000 (2%)] Loss: 15272.573242\n",
      "Train Epoch: 28 [5760/225000 (3%)] Loss: 15179.339844\n",
      "Train Epoch: 28 [7168/225000 (3%)] Loss: 14503.371094\n",
      "Train Epoch: 28 [8576/225000 (4%)] Loss: 14790.351562\n",
      "Train Epoch: 28 [9984/225000 (4%)] Loss: 15055.351562\n",
      "Train Epoch: 28 [11392/225000 (5%)] Loss: 14664.385742\n",
      "Train Epoch: 28 [12800/225000 (6%)] Loss: 15000.843750\n",
      "Train Epoch: 28 [14208/225000 (6%)] Loss: 15295.102539\n",
      "Train Epoch: 28 [15616/225000 (7%)] Loss: 14711.097656\n",
      "Train Epoch: 28 [17024/225000 (8%)] Loss: 15077.061523\n",
      "Train Epoch: 28 [18432/225000 (8%)] Loss: 14913.184570\n",
      "Train Epoch: 28 [19840/225000 (9%)] Loss: 14514.820312\n",
      "Train Epoch: 28 [21248/225000 (9%)] Loss: 15246.034180\n",
      "Train Epoch: 28 [22656/225000 (10%)] Loss: 14750.037109\n",
      "Train Epoch: 28 [24064/225000 (11%)] Loss: 15308.658203\n",
      "Train Epoch: 28 [25472/225000 (11%)] Loss: 15198.364258\n",
      "Train Epoch: 28 [26880/225000 (12%)] Loss: 15011.657227\n",
      "Train Epoch: 28 [28288/225000 (13%)] Loss: 15290.902344\n",
      "Train Epoch: 28 [29696/225000 (13%)] Loss: 14803.764648\n",
      "Train Epoch: 28 [31104/225000 (14%)] Loss: 15231.197266\n",
      "Train Epoch: 28 [32512/225000 (14%)] Loss: 14774.765625\n",
      "Train Epoch: 28 [33920/225000 (15%)] Loss: 15405.832031\n",
      "Train Epoch: 28 [35328/225000 (16%)] Loss: 14758.073242\n",
      "Train Epoch: 28 [36736/225000 (16%)] Loss: 14996.303711\n",
      "Train Epoch: 28 [38144/225000 (17%)] Loss: 14881.314453\n",
      "Train Epoch: 28 [39552/225000 (18%)] Loss: 15657.768555\n",
      "Train Epoch: 28 [40960/225000 (18%)] Loss: 14838.619141\n",
      "Train Epoch: 28 [42368/225000 (19%)] Loss: 14828.212891\n",
      "Train Epoch: 28 [43776/225000 (19%)] Loss: 14820.015625\n",
      "Train Epoch: 28 [45184/225000 (20%)] Loss: 14830.902344\n",
      "Train Epoch: 28 [46592/225000 (21%)] Loss: 15180.030273\n",
      "Train Epoch: 28 [48000/225000 (21%)] Loss: 14485.924805\n",
      "Train Epoch: 28 [49408/225000 (22%)] Loss: 14965.633789\n",
      "Train Epoch: 28 [50816/225000 (23%)] Loss: 15301.366211\n",
      "Train Epoch: 28 [52224/225000 (23%)] Loss: 15627.312500\n",
      "Train Epoch: 28 [53632/225000 (24%)] Loss: 15289.172852\n",
      "Train Epoch: 28 [55040/225000 (24%)] Loss: 15001.211914\n",
      "Train Epoch: 28 [56448/225000 (25%)] Loss: 15276.267578\n",
      "Train Epoch: 28 [57856/225000 (26%)] Loss: 14941.581055\n",
      "Train Epoch: 28 [59264/225000 (26%)] Loss: 14827.458008\n",
      "Train Epoch: 28 [60672/225000 (27%)] Loss: 14889.139648\n",
      "Train Epoch: 28 [62080/225000 (28%)] Loss: 15059.568359\n",
      "Train Epoch: 28 [63488/225000 (28%)] Loss: 14911.083008\n",
      "Train Epoch: 28 [64896/225000 (29%)] Loss: 15218.729492\n",
      "Train Epoch: 28 [66304/225000 (29%)] Loss: 14646.710938\n",
      "Train Epoch: 28 [67712/225000 (30%)] Loss: 15087.284180\n",
      "Train Epoch: 28 [69120/225000 (31%)] Loss: 14876.300781\n",
      "Train Epoch: 28 [70528/225000 (31%)] Loss: 15244.916992\n",
      "Train Epoch: 28 [71936/225000 (32%)] Loss: 14884.419922\n",
      "Train Epoch: 28 [73344/225000 (33%)] Loss: 14933.855469\n",
      "Train Epoch: 28 [74752/225000 (33%)] Loss: 14726.124023\n",
      "Train Epoch: 28 [76160/225000 (34%)] Loss: 14800.385742\n",
      "Train Epoch: 28 [77568/225000 (34%)] Loss: 15291.417969\n",
      "Train Epoch: 28 [78976/225000 (35%)] Loss: 15316.227539\n",
      "Train Epoch: 28 [80384/225000 (36%)] Loss: 14859.220703\n",
      "Train Epoch: 28 [81792/225000 (36%)] Loss: 14920.429688\n",
      "Train Epoch: 28 [83200/225000 (37%)] Loss: 15163.971680\n",
      "Train Epoch: 28 [84608/225000 (38%)] Loss: 14967.160156\n",
      "Train Epoch: 28 [86016/225000 (38%)] Loss: 14991.440430\n",
      "Train Epoch: 28 [87424/225000 (39%)] Loss: 15130.312500\n",
      "Train Epoch: 28 [88832/225000 (39%)] Loss: 14851.033203\n",
      "Train Epoch: 28 [90240/225000 (40%)] Loss: 15208.599609\n",
      "Train Epoch: 28 [91648/225000 (41%)] Loss: 14753.004883\n",
      "Train Epoch: 28 [93056/225000 (41%)] Loss: 15131.510742\n",
      "Train Epoch: 28 [94464/225000 (42%)] Loss: 14906.920898\n",
      "Train Epoch: 28 [95872/225000 (43%)] Loss: 15366.625000\n",
      "Train Epoch: 28 [97280/225000 (43%)] Loss: 15030.821289\n",
      "Train Epoch: 28 [98688/225000 (44%)] Loss: 14796.289062\n",
      "Train Epoch: 28 [100096/225000 (44%)] Loss: 14807.030273\n",
      "Train Epoch: 28 [101504/225000 (45%)] Loss: 14480.719727\n",
      "Train Epoch: 28 [102912/225000 (46%)] Loss: 15022.065430\n",
      "Train Epoch: 28 [104320/225000 (46%)] Loss: 15356.732422\n",
      "Train Epoch: 28 [105728/225000 (47%)] Loss: 14667.694336\n",
      "Train Epoch: 28 [107136/225000 (48%)] Loss: 14717.632812\n",
      "Train Epoch: 28 [108544/225000 (48%)] Loss: 15160.053711\n",
      "Train Epoch: 28 [109952/225000 (49%)] Loss: 14933.309570\n",
      "Train Epoch: 28 [111360/225000 (49%)] Loss: 15142.382812\n",
      "Train Epoch: 28 [112768/225000 (50%)] Loss: 15292.713867\n",
      "Train Epoch: 28 [114176/225000 (51%)] Loss: 14993.489258\n",
      "Train Epoch: 28 [115584/225000 (51%)] Loss: 14849.456055\n",
      "Train Epoch: 28 [116992/225000 (52%)] Loss: 15328.437500\n",
      "Train Epoch: 28 [118400/225000 (53%)] Loss: 15078.372070\n",
      "Train Epoch: 28 [119808/225000 (53%)] Loss: 15393.441406\n",
      "Train Epoch: 28 [121216/225000 (54%)] Loss: 15290.113281\n",
      "Train Epoch: 28 [122624/225000 (54%)] Loss: 15070.892578\n",
      "Train Epoch: 28 [124032/225000 (55%)] Loss: 14894.513672\n",
      "Train Epoch: 28 [125440/225000 (56%)] Loss: 14990.962891\n",
      "Train Epoch: 28 [126848/225000 (56%)] Loss: 15343.458008\n",
      "Train Epoch: 28 [128256/225000 (57%)] Loss: 15240.972656\n",
      "Train Epoch: 28 [129664/225000 (58%)] Loss: 15250.960938\n",
      "Train Epoch: 28 [131072/225000 (58%)] Loss: 15366.269531\n",
      "Train Epoch: 28 [132480/225000 (59%)] Loss: 14405.803711\n",
      "Train Epoch: 28 [133888/225000 (60%)] Loss: 14847.093750\n",
      "Train Epoch: 28 [135296/225000 (60%)] Loss: 15362.950195\n",
      "Train Epoch: 28 [136704/225000 (61%)] Loss: 15047.769531\n",
      "Train Epoch: 28 [138112/225000 (61%)] Loss: 14757.178711\n",
      "Train Epoch: 28 [139520/225000 (62%)] Loss: 14945.049805\n",
      "Train Epoch: 28 [140928/225000 (63%)] Loss: 14967.402344\n",
      "Train Epoch: 28 [142336/225000 (63%)] Loss: 15381.685547\n",
      "Train Epoch: 28 [143744/225000 (64%)] Loss: 15240.046875\n",
      "Train Epoch: 28 [145152/225000 (65%)] Loss: 14955.221680\n",
      "Train Epoch: 28 [146560/225000 (65%)] Loss: 14431.609375\n",
      "Train Epoch: 28 [147968/225000 (66%)] Loss: 14967.420898\n",
      "Train Epoch: 28 [149376/225000 (66%)] Loss: 14791.013672\n",
      "Train Epoch: 28 [150784/225000 (67%)] Loss: 14897.938477\n",
      "Train Epoch: 28 [152192/225000 (68%)] Loss: 14908.157227\n",
      "Train Epoch: 28 [153600/225000 (68%)] Loss: 14807.475586\n",
      "Train Epoch: 28 [155008/225000 (69%)] Loss: 14929.522461\n",
      "Train Epoch: 28 [156416/225000 (70%)] Loss: 14790.998047\n",
      "Train Epoch: 28 [157824/225000 (70%)] Loss: 14787.169922\n",
      "Train Epoch: 28 [159232/225000 (71%)] Loss: 15348.167969\n",
      "Train Epoch: 28 [160640/225000 (71%)] Loss: 15215.642578\n",
      "Train Epoch: 28 [162048/225000 (72%)] Loss: 15398.757812\n",
      "Train Epoch: 28 [163456/225000 (73%)] Loss: 15160.881836\n",
      "Train Epoch: 28 [164864/225000 (73%)] Loss: 14965.205078\n",
      "Train Epoch: 28 [166272/225000 (74%)] Loss: 15174.317383\n",
      "Train Epoch: 28 [167680/225000 (75%)] Loss: 15143.299805\n",
      "Train Epoch: 28 [169088/225000 (75%)] Loss: 15066.753906\n",
      "Train Epoch: 28 [170496/225000 (76%)] Loss: 15246.049805\n",
      "Train Epoch: 28 [171904/225000 (76%)] Loss: 15121.639648\n",
      "Train Epoch: 28 [173312/225000 (77%)] Loss: 15083.915039\n",
      "Train Epoch: 28 [174720/225000 (78%)] Loss: 15341.555664\n",
      "Train Epoch: 28 [176128/225000 (78%)] Loss: 14789.009766\n",
      "Train Epoch: 28 [177536/225000 (79%)] Loss: 14961.593750\n",
      "Train Epoch: 28 [178944/225000 (80%)] Loss: 14951.125977\n",
      "Train Epoch: 28 [180352/225000 (80%)] Loss: 15449.190430\n",
      "Train Epoch: 28 [181760/225000 (81%)] Loss: 15061.041016\n",
      "Train Epoch: 28 [183168/225000 (81%)] Loss: 14835.511719\n",
      "Train Epoch: 28 [184576/225000 (82%)] Loss: 14861.454102\n",
      "Train Epoch: 28 [185984/225000 (83%)] Loss: 14927.989258\n",
      "Train Epoch: 28 [187392/225000 (83%)] Loss: 15643.823242\n",
      "Train Epoch: 28 [188800/225000 (84%)] Loss: 14709.390625\n",
      "Train Epoch: 28 [190208/225000 (85%)] Loss: 15128.310547\n",
      "Train Epoch: 28 [191616/225000 (85%)] Loss: 14823.374023\n",
      "Train Epoch: 28 [193024/225000 (86%)] Loss: 15543.170898\n",
      "Train Epoch: 28 [194432/225000 (86%)] Loss: 15161.413086\n",
      "Train Epoch: 28 [195840/225000 (87%)] Loss: 14811.945312\n",
      "Train Epoch: 28 [197248/225000 (88%)] Loss: 15036.282227\n",
      "Train Epoch: 28 [198656/225000 (88%)] Loss: 14988.968750\n",
      "Train Epoch: 28 [200064/225000 (89%)] Loss: 14929.145508\n",
      "Train Epoch: 28 [201472/225000 (90%)] Loss: 15670.666016\n",
      "Train Epoch: 28 [202880/225000 (90%)] Loss: 14873.275391\n",
      "Train Epoch: 28 [204288/225000 (91%)] Loss: 15400.041992\n",
      "Train Epoch: 28 [205696/225000 (91%)] Loss: 14967.226562\n",
      "Train Epoch: 28 [207104/225000 (92%)] Loss: 15172.285156\n",
      "Train Epoch: 28 [208512/225000 (93%)] Loss: 15415.568359\n",
      "Train Epoch: 28 [209920/225000 (93%)] Loss: 15413.730469\n",
      "Train Epoch: 28 [211328/225000 (94%)] Loss: 15019.173828\n",
      "Train Epoch: 28 [212736/225000 (95%)] Loss: 14994.566406\n",
      "Train Epoch: 28 [214144/225000 (95%)] Loss: 15239.033203\n",
      "Train Epoch: 28 [215552/225000 (96%)] Loss: 14820.014648\n",
      "Train Epoch: 28 [216960/225000 (96%)] Loss: 15081.302734\n",
      "Train Epoch: 28 [218368/225000 (97%)] Loss: 14791.946289\n",
      "Train Epoch: 28 [219776/225000 (98%)] Loss: 14954.446289\n",
      "Train Epoch: 28 [221184/225000 (98%)] Loss: 14936.774414\n",
      "Train Epoch: 28 [222592/225000 (99%)] Loss: 14896.705078\n",
      "Train Epoch: 28 [224000/225000 (100%)] Loss: 14948.279297\n",
      "    epoch          : 28\n",
      "    loss           : 15086.557463315025\n",
      "    val_loss       : 15093.697801237051\n",
      "Train Epoch: 29 [128/225000 (0%)] Loss: 14971.401367\n",
      "Train Epoch: 29 [1536/225000 (1%)] Loss: 14922.238281\n",
      "Train Epoch: 29 [2944/225000 (1%)] Loss: 14796.885742\n",
      "Train Epoch: 29 [4352/225000 (2%)] Loss: 14894.761719\n",
      "Train Epoch: 29 [5760/225000 (3%)] Loss: 15195.173828\n",
      "Train Epoch: 29 [7168/225000 (3%)] Loss: 14394.010742\n",
      "Train Epoch: 29 [8576/225000 (4%)] Loss: 15131.991211\n",
      "Train Epoch: 29 [9984/225000 (4%)] Loss: 15206.421875\n",
      "Train Epoch: 29 [11392/225000 (5%)] Loss: 19867.953125\n",
      "Train Epoch: 29 [12800/225000 (6%)] Loss: 14796.644531\n",
      "Train Epoch: 29 [14208/225000 (6%)] Loss: 19105.089844\n",
      "Train Epoch: 29 [15616/225000 (7%)] Loss: 19042.597656\n",
      "Train Epoch: 29 [17024/225000 (8%)] Loss: 21913.005859\n",
      "Train Epoch: 29 [18432/225000 (8%)] Loss: 27984.460938\n",
      "Train Epoch: 29 [19840/225000 (9%)] Loss: 27503.656250\n",
      "Train Epoch: 29 [21248/225000 (9%)] Loss: 26181.271484\n",
      "Train Epoch: 29 [22656/225000 (10%)] Loss: 25656.542969\n",
      "Train Epoch: 29 [24064/225000 (11%)] Loss: 24918.730469\n",
      "Train Epoch: 29 [25472/225000 (11%)] Loss: 24650.011719\n",
      "Train Epoch: 29 [26880/225000 (12%)] Loss: 21225.304688\n",
      "Train Epoch: 29 [28288/225000 (13%)] Loss: 24113.533203\n",
      "Train Epoch: 29 [29696/225000 (13%)] Loss: 23509.386719\n",
      "Train Epoch: 29 [31104/225000 (14%)] Loss: 23200.082031\n",
      "Train Epoch: 29 [32512/225000 (14%)] Loss: 23085.457031\n",
      "Train Epoch: 29 [33920/225000 (15%)] Loss: 22510.429688\n",
      "Train Epoch: 29 [35328/225000 (16%)] Loss: 22361.101562\n",
      "Train Epoch: 29 [36736/225000 (16%)] Loss: 18706.664062\n",
      "Train Epoch: 29 [38144/225000 (17%)] Loss: 21175.337891\n",
      "Train Epoch: 29 [39552/225000 (18%)] Loss: 21250.406250\n",
      "Train Epoch: 29 [40960/225000 (18%)] Loss: 20361.748047\n",
      "Train Epoch: 29 [42368/225000 (19%)] Loss: 20589.085938\n",
      "Train Epoch: 29 [43776/225000 (19%)] Loss: 19930.550781\n",
      "Train Epoch: 29 [45184/225000 (20%)] Loss: 19473.457031\n",
      "Train Epoch: 29 [46592/225000 (21%)] Loss: 18955.996094\n",
      "Train Epoch: 29 [48000/225000 (21%)] Loss: 19026.234375\n",
      "Train Epoch: 29 [49408/225000 (22%)] Loss: 19247.292969\n",
      "Train Epoch: 29 [50816/225000 (23%)] Loss: 19126.515625\n",
      "Train Epoch: 29 [52224/225000 (23%)] Loss: 18280.636719\n",
      "Train Epoch: 29 [53632/225000 (24%)] Loss: 18242.828125\n",
      "Train Epoch: 29 [55040/225000 (24%)] Loss: 18120.962891\n",
      "Train Epoch: 29 [56448/225000 (25%)] Loss: 17764.171875\n",
      "Train Epoch: 29 [57856/225000 (26%)] Loss: 18120.363281\n",
      "Train Epoch: 29 [59264/225000 (26%)] Loss: 17361.839844\n",
      "Train Epoch: 29 [60672/225000 (27%)] Loss: 17467.722656\n",
      "Train Epoch: 29 [62080/225000 (28%)] Loss: 16981.847656\n",
      "Train Epoch: 29 [63488/225000 (28%)] Loss: 17048.671875\n",
      "Train Epoch: 29 [64896/225000 (29%)] Loss: 17444.445312\n",
      "Train Epoch: 29 [66304/225000 (29%)] Loss: 17015.000000\n",
      "Train Epoch: 29 [67712/225000 (30%)] Loss: 17627.935547\n",
      "Train Epoch: 29 [69120/225000 (31%)] Loss: 16870.085938\n",
      "Train Epoch: 29 [70528/225000 (31%)] Loss: 16652.865234\n",
      "Train Epoch: 29 [71936/225000 (32%)] Loss: 16578.464844\n",
      "Train Epoch: 29 [73344/225000 (33%)] Loss: 16938.689453\n",
      "Train Epoch: 29 [74752/225000 (33%)] Loss: 17460.113281\n",
      "Train Epoch: 29 [76160/225000 (34%)] Loss: 16712.087891\n",
      "Train Epoch: 29 [77568/225000 (34%)] Loss: 16528.908203\n",
      "Train Epoch: 29 [78976/225000 (35%)] Loss: 16837.771484\n",
      "Train Epoch: 29 [80384/225000 (36%)] Loss: 17036.652344\n",
      "Train Epoch: 29 [81792/225000 (36%)] Loss: 16984.628906\n",
      "Train Epoch: 29 [83200/225000 (37%)] Loss: 16467.548828\n",
      "Train Epoch: 29 [84608/225000 (38%)] Loss: 16739.523438\n",
      "Train Epoch: 29 [86016/225000 (38%)] Loss: 16797.882812\n",
      "Train Epoch: 29 [87424/225000 (39%)] Loss: 16923.566406\n",
      "Train Epoch: 29 [88832/225000 (39%)] Loss: 16645.515625\n",
      "Train Epoch: 29 [90240/225000 (40%)] Loss: 16625.523438\n",
      "Train Epoch: 29 [91648/225000 (41%)] Loss: 16863.556641\n",
      "Train Epoch: 29 [93056/225000 (41%)] Loss: 16739.552734\n",
      "Train Epoch: 29 [94464/225000 (42%)] Loss: 16455.685547\n",
      "Train Epoch: 29 [95872/225000 (43%)] Loss: 16430.142578\n",
      "Train Epoch: 29 [97280/225000 (43%)] Loss: 16296.837891\n",
      "Train Epoch: 29 [98688/225000 (44%)] Loss: 16557.583984\n",
      "Train Epoch: 29 [100096/225000 (44%)] Loss: 16457.609375\n",
      "Train Epoch: 29 [101504/225000 (45%)] Loss: 17086.951172\n",
      "Train Epoch: 29 [102912/225000 (46%)] Loss: 16336.346680\n",
      "Train Epoch: 29 [104320/225000 (46%)] Loss: 16802.537109\n",
      "Train Epoch: 29 [105728/225000 (47%)] Loss: 15714.948242\n",
      "Train Epoch: 29 [107136/225000 (48%)] Loss: 15986.735352\n",
      "Train Epoch: 29 [108544/225000 (48%)] Loss: 16642.191406\n",
      "Train Epoch: 29 [109952/225000 (49%)] Loss: 16308.763672\n",
      "Train Epoch: 29 [111360/225000 (49%)] Loss: 16130.313477\n",
      "Train Epoch: 29 [112768/225000 (50%)] Loss: 16384.019531\n",
      "Train Epoch: 29 [114176/225000 (51%)] Loss: 16798.636719\n",
      "Train Epoch: 29 [115584/225000 (51%)] Loss: 16502.441406\n",
      "Train Epoch: 29 [116992/225000 (52%)] Loss: 22985.699219\n",
      "Train Epoch: 29 [118400/225000 (53%)] Loss: 16963.980469\n",
      "Train Epoch: 29 [119808/225000 (53%)] Loss: 19570.300781\n",
      "Train Epoch: 29 [121216/225000 (54%)] Loss: 16630.769531\n",
      "Train Epoch: 29 [122624/225000 (54%)] Loss: 15483.695312\n",
      "Train Epoch: 29 [124032/225000 (55%)] Loss: 17134.044922\n",
      "Train Epoch: 29 [125440/225000 (56%)] Loss: 15679.822266\n",
      "Train Epoch: 29 [126848/225000 (56%)] Loss: 16558.220703\n",
      "Train Epoch: 29 [128256/225000 (57%)] Loss: 15910.791992\n",
      "Train Epoch: 29 [129664/225000 (58%)] Loss: 14983.274414\n",
      "Train Epoch: 29 [131072/225000 (58%)] Loss: 16023.802734\n",
      "Train Epoch: 29 [132480/225000 (59%)] Loss: 16071.447266\n",
      "Train Epoch: 29 [133888/225000 (60%)] Loss: 15399.377930\n",
      "Train Epoch: 29 [135296/225000 (60%)] Loss: 15294.938477\n",
      "Train Epoch: 29 [136704/225000 (61%)] Loss: 15923.723633\n",
      "Train Epoch: 29 [138112/225000 (61%)] Loss: 20312.996094\n",
      "Train Epoch: 29 [139520/225000 (62%)] Loss: 16087.742188\n",
      "Train Epoch: 29 [140928/225000 (63%)] Loss: 16003.193359\n",
      "Train Epoch: 29 [142336/225000 (63%)] Loss: 15838.520508\n",
      "Train Epoch: 29 [143744/225000 (64%)] Loss: 14854.575195\n",
      "Train Epoch: 29 [145152/225000 (65%)] Loss: 15683.807617\n",
      "Train Epoch: 29 [146560/225000 (65%)] Loss: 15350.379883\n",
      "Train Epoch: 29 [147968/225000 (66%)] Loss: 19385.085938\n",
      "Train Epoch: 29 [149376/225000 (66%)] Loss: 15222.479492\n",
      "Train Epoch: 29 [150784/225000 (67%)] Loss: 14882.342773\n",
      "Train Epoch: 29 [152192/225000 (68%)] Loss: 15348.609375\n",
      "Train Epoch: 29 [153600/225000 (68%)] Loss: 15059.527344\n",
      "Train Epoch: 29 [155008/225000 (69%)] Loss: 15579.650391\n",
      "Train Epoch: 29 [156416/225000 (70%)] Loss: 15288.510742\n",
      "Train Epoch: 29 [157824/225000 (70%)] Loss: 15168.669922\n",
      "Train Epoch: 29 [159232/225000 (71%)] Loss: 15676.958008\n",
      "Train Epoch: 29 [160640/225000 (71%)] Loss: 15998.542969\n",
      "Train Epoch: 29 [162048/225000 (72%)] Loss: 15018.719727\n",
      "Train Epoch: 29 [163456/225000 (73%)] Loss: 18762.253906\n",
      "Train Epoch: 29 [164864/225000 (73%)] Loss: 15722.366211\n",
      "Train Epoch: 29 [166272/225000 (74%)] Loss: 15485.879883\n",
      "Train Epoch: 29 [167680/225000 (75%)] Loss: 15348.458984\n",
      "Train Epoch: 29 [169088/225000 (75%)] Loss: 18857.910156\n",
      "Train Epoch: 29 [170496/225000 (76%)] Loss: 15349.863281\n",
      "Train Epoch: 29 [171904/225000 (76%)] Loss: 15297.158203\n",
      "Train Epoch: 29 [173312/225000 (77%)] Loss: 14995.948242\n",
      "Train Epoch: 29 [174720/225000 (78%)] Loss: 15082.495117\n",
      "Train Epoch: 29 [176128/225000 (78%)] Loss: 14842.872070\n",
      "Train Epoch: 29 [177536/225000 (79%)] Loss: 15428.768555\n",
      "Train Epoch: 29 [178944/225000 (80%)] Loss: 15618.442383\n",
      "Train Epoch: 29 [180352/225000 (80%)] Loss: 15384.499023\n",
      "Train Epoch: 29 [181760/225000 (81%)] Loss: 15119.468750\n",
      "Train Epoch: 29 [183168/225000 (81%)] Loss: 14853.573242\n",
      "Train Epoch: 29 [184576/225000 (82%)] Loss: 15334.342773\n",
      "Train Epoch: 29 [185984/225000 (83%)] Loss: 15353.802734\n",
      "Train Epoch: 29 [187392/225000 (83%)] Loss: 15171.724609\n",
      "Train Epoch: 29 [188800/225000 (84%)] Loss: 17386.464844\n",
      "Train Epoch: 29 [190208/225000 (85%)] Loss: 15257.673828\n",
      "Train Epoch: 29 [191616/225000 (85%)] Loss: 15370.131836\n",
      "Train Epoch: 29 [193024/225000 (86%)] Loss: 15241.026367\n",
      "Train Epoch: 29 [194432/225000 (86%)] Loss: 15995.302734\n",
      "Train Epoch: 29 [195840/225000 (87%)] Loss: 17923.726562\n",
      "Train Epoch: 29 [197248/225000 (88%)] Loss: 15466.681641\n",
      "Train Epoch: 29 [198656/225000 (88%)] Loss: 15589.058594\n",
      "Train Epoch: 29 [200064/225000 (89%)] Loss: 17561.898438\n",
      "Train Epoch: 29 [201472/225000 (90%)] Loss: 14841.286133\n",
      "Train Epoch: 29 [202880/225000 (90%)] Loss: 14951.970703\n",
      "Train Epoch: 29 [204288/225000 (91%)] Loss: 15179.539062\n",
      "Train Epoch: 29 [205696/225000 (91%)] Loss: 15238.149414\n",
      "Train Epoch: 29 [207104/225000 (92%)] Loss: 15195.122070\n",
      "Train Epoch: 29 [208512/225000 (93%)] Loss: 15440.066406\n",
      "Train Epoch: 29 [209920/225000 (93%)] Loss: 15279.017578\n",
      "Train Epoch: 29 [211328/225000 (94%)] Loss: 14899.661133\n",
      "Train Epoch: 29 [212736/225000 (95%)] Loss: 15392.458984\n",
      "Train Epoch: 29 [214144/225000 (95%)] Loss: 17076.576172\n",
      "Train Epoch: 29 [215552/225000 (96%)] Loss: 14680.885742\n",
      "Train Epoch: 29 [216960/225000 (96%)] Loss: 15176.528320\n",
      "Train Epoch: 29 [218368/225000 (97%)] Loss: 15419.952148\n",
      "Train Epoch: 29 [219776/225000 (98%)] Loss: 15072.977539\n",
      "Train Epoch: 29 [221184/225000 (98%)] Loss: 14811.264648\n",
      "Train Epoch: 29 [222592/225000 (99%)] Loss: 17160.455078\n",
      "Train Epoch: 29 [224000/225000 (100%)] Loss: 15586.972656\n",
      "    epoch          : 29\n",
      "    loss           : 17307.450025330632\n",
      "    val_loss       : 15230.413052054084\n",
      "Train Epoch: 30 [128/225000 (0%)] Loss: 14848.134766\n",
      "Train Epoch: 30 [1536/225000 (1%)] Loss: 15281.855469\n",
      "Train Epoch: 30 [2944/225000 (1%)] Loss: 15003.746094\n",
      "Train Epoch: 30 [4352/225000 (2%)] Loss: 15287.317383\n",
      "Train Epoch: 30 [5760/225000 (3%)] Loss: 15037.070312\n",
      "Train Epoch: 30 [7168/225000 (3%)] Loss: 14921.355469\n",
      "Train Epoch: 30 [8576/225000 (4%)] Loss: 14990.451172\n",
      "Train Epoch: 30 [9984/225000 (4%)] Loss: 15398.806641\n",
      "Train Epoch: 30 [11392/225000 (5%)] Loss: 15174.383789\n",
      "Train Epoch: 30 [12800/225000 (6%)] Loss: 15236.930664\n",
      "Train Epoch: 30 [14208/225000 (6%)] Loss: 15488.325195\n",
      "Train Epoch: 30 [15616/225000 (7%)] Loss: 14972.924805\n",
      "Train Epoch: 30 [17024/225000 (8%)] Loss: 15828.561523\n",
      "Train Epoch: 30 [18432/225000 (8%)] Loss: 15138.825195\n",
      "Train Epoch: 30 [19840/225000 (9%)] Loss: 15177.363281\n",
      "Train Epoch: 30 [21248/225000 (9%)] Loss: 14878.422852\n",
      "Train Epoch: 30 [22656/225000 (10%)] Loss: 15033.406250\n",
      "Train Epoch: 30 [24064/225000 (11%)] Loss: 14645.709961\n",
      "Train Epoch: 30 [25472/225000 (11%)] Loss: 14773.826172\n",
      "Train Epoch: 30 [26880/225000 (12%)] Loss: 14985.287109\n",
      "Train Epoch: 30 [28288/225000 (13%)] Loss: 14586.399414\n",
      "Train Epoch: 30 [29696/225000 (13%)] Loss: 14801.500977\n",
      "Train Epoch: 30 [31104/225000 (14%)] Loss: 14973.799805\n",
      "Train Epoch: 30 [32512/225000 (14%)] Loss: 14622.659180\n",
      "Train Epoch: 30 [33920/225000 (15%)] Loss: 14914.440430\n",
      "Train Epoch: 30 [35328/225000 (16%)] Loss: 15159.056641\n",
      "Train Epoch: 30 [36736/225000 (16%)] Loss: 15166.284180\n",
      "Train Epoch: 30 [38144/225000 (17%)] Loss: 14852.363281\n",
      "Train Epoch: 30 [39552/225000 (18%)] Loss: 14814.396484\n",
      "Train Epoch: 30 [40960/225000 (18%)] Loss: 14797.443359\n",
      "Train Epoch: 30 [42368/225000 (19%)] Loss: 15350.555664\n",
      "Train Epoch: 30 [43776/225000 (19%)] Loss: 15152.551758\n",
      "Train Epoch: 30 [45184/225000 (20%)] Loss: 15344.289062\n",
      "Train Epoch: 30 [46592/225000 (21%)] Loss: 15214.231445\n",
      "Train Epoch: 30 [48000/225000 (21%)] Loss: 14934.108398\n",
      "Train Epoch: 30 [49408/225000 (22%)] Loss: 14899.671875\n",
      "Train Epoch: 30 [50816/225000 (23%)] Loss: 15049.608398\n",
      "Train Epoch: 30 [52224/225000 (23%)] Loss: 15042.385742\n",
      "Train Epoch: 30 [53632/225000 (24%)] Loss: 14894.580078\n",
      "Train Epoch: 30 [55040/225000 (24%)] Loss: 14999.109375\n",
      "Train Epoch: 30 [56448/225000 (25%)] Loss: 15384.604492\n",
      "Train Epoch: 30 [57856/225000 (26%)] Loss: 15045.848633\n",
      "Train Epoch: 30 [59264/225000 (26%)] Loss: 15838.274414\n",
      "Train Epoch: 30 [60672/225000 (27%)] Loss: 14621.532227\n",
      "Train Epoch: 30 [62080/225000 (28%)] Loss: 14955.583008\n",
      "Train Epoch: 30 [63488/225000 (28%)] Loss: 15344.558594\n",
      "Train Epoch: 30 [64896/225000 (29%)] Loss: 15198.563477\n",
      "Train Epoch: 30 [66304/225000 (29%)] Loss: 14990.860352\n",
      "Train Epoch: 30 [67712/225000 (30%)] Loss: 15190.544922\n",
      "Train Epoch: 30 [69120/225000 (31%)] Loss: 15240.061523\n",
      "Train Epoch: 30 [70528/225000 (31%)] Loss: 15088.147461\n",
      "Train Epoch: 30 [71936/225000 (32%)] Loss: 14869.340820\n",
      "Train Epoch: 30 [73344/225000 (33%)] Loss: 15172.179688\n",
      "Train Epoch: 30 [74752/225000 (33%)] Loss: 14980.619141\n",
      "Train Epoch: 30 [76160/225000 (34%)] Loss: 14956.437500\n",
      "Train Epoch: 30 [77568/225000 (34%)] Loss: 15353.457031\n",
      "Train Epoch: 30 [78976/225000 (35%)] Loss: 15177.606445\n",
      "Train Epoch: 30 [80384/225000 (36%)] Loss: 15400.380859\n",
      "Train Epoch: 30 [81792/225000 (36%)] Loss: 14594.136719\n",
      "Train Epoch: 30 [83200/225000 (37%)] Loss: 14870.636719\n",
      "Train Epoch: 30 [84608/225000 (38%)] Loss: 14836.547852\n",
      "Train Epoch: 30 [86016/225000 (38%)] Loss: 15181.485352\n",
      "Train Epoch: 30 [87424/225000 (39%)] Loss: 15307.692383\n",
      "Train Epoch: 30 [88832/225000 (39%)] Loss: 15125.770508\n",
      "Train Epoch: 30 [90240/225000 (40%)] Loss: 14690.321289\n",
      "Train Epoch: 30 [91648/225000 (41%)] Loss: 14983.496094\n",
      "Train Epoch: 30 [93056/225000 (41%)] Loss: 15270.074219\n",
      "Train Epoch: 30 [94464/225000 (42%)] Loss: 14558.620117\n",
      "Train Epoch: 30 [95872/225000 (43%)] Loss: 15042.613281\n",
      "Train Epoch: 30 [97280/225000 (43%)] Loss: 15074.013672\n",
      "Train Epoch: 30 [98688/225000 (44%)] Loss: 15157.689453\n",
      "Train Epoch: 30 [100096/225000 (44%)] Loss: 14932.573242\n",
      "Train Epoch: 30 [101504/225000 (45%)] Loss: 15280.156250\n",
      "Train Epoch: 30 [102912/225000 (46%)] Loss: 15178.924805\n",
      "Train Epoch: 30 [104320/225000 (46%)] Loss: 14771.222656\n",
      "Train Epoch: 30 [105728/225000 (47%)] Loss: 14985.788086\n",
      "Train Epoch: 30 [107136/225000 (48%)] Loss: 15234.435547\n",
      "Train Epoch: 30 [108544/225000 (48%)] Loss: 14662.494141\n",
      "Train Epoch: 30 [109952/225000 (49%)] Loss: 15464.051758\n",
      "Train Epoch: 30 [111360/225000 (49%)] Loss: 15051.705078\n",
      "Train Epoch: 30 [112768/225000 (50%)] Loss: 14792.288086\n",
      "Train Epoch: 30 [114176/225000 (51%)] Loss: 15066.680664\n",
      "Train Epoch: 30 [115584/225000 (51%)] Loss: 15039.029297\n",
      "Train Epoch: 30 [116992/225000 (52%)] Loss: 15605.896484\n",
      "Train Epoch: 30 [118400/225000 (53%)] Loss: 15235.626953\n",
      "Train Epoch: 30 [119808/225000 (53%)] Loss: 15252.277344\n",
      "Train Epoch: 30 [121216/225000 (54%)] Loss: 14928.596680\n",
      "Train Epoch: 30 [122624/225000 (54%)] Loss: 14889.037109\n",
      "Train Epoch: 30 [124032/225000 (55%)] Loss: 15111.311523\n",
      "Train Epoch: 30 [125440/225000 (56%)] Loss: 15004.323242\n",
      "Train Epoch: 30 [126848/225000 (56%)] Loss: 15434.675781\n",
      "Train Epoch: 30 [128256/225000 (57%)] Loss: 14734.383789\n",
      "Train Epoch: 30 [129664/225000 (58%)] Loss: 14964.606445\n",
      "Train Epoch: 30 [131072/225000 (58%)] Loss: 15357.462891\n",
      "Train Epoch: 30 [132480/225000 (59%)] Loss: 15273.370117\n",
      "Train Epoch: 30 [133888/225000 (60%)] Loss: 14817.127930\n",
      "Train Epoch: 30 [135296/225000 (60%)] Loss: 15285.713867\n",
      "Train Epoch: 30 [136704/225000 (61%)] Loss: 15012.588867\n",
      "Train Epoch: 30 [138112/225000 (61%)] Loss: 15015.748047\n",
      "Train Epoch: 30 [139520/225000 (62%)] Loss: 15068.392578\n",
      "Train Epoch: 30 [140928/225000 (63%)] Loss: 14991.018555\n",
      "Train Epoch: 30 [142336/225000 (63%)] Loss: 14904.282227\n",
      "Train Epoch: 30 [143744/225000 (64%)] Loss: 15516.323242\n",
      "Train Epoch: 30 [145152/225000 (65%)] Loss: 14573.708008\n",
      "Train Epoch: 30 [146560/225000 (65%)] Loss: 14973.314453\n",
      "Train Epoch: 30 [147968/225000 (66%)] Loss: 14877.929688\n",
      "Train Epoch: 30 [149376/225000 (66%)] Loss: 14735.142578\n",
      "Train Epoch: 30 [150784/225000 (67%)] Loss: 15182.541016\n",
      "Train Epoch: 30 [152192/225000 (68%)] Loss: 14788.154297\n",
      "Train Epoch: 30 [153600/225000 (68%)] Loss: 14858.977539\n",
      "Train Epoch: 30 [155008/225000 (69%)] Loss: 14742.016602\n",
      "Train Epoch: 30 [156416/225000 (70%)] Loss: 15018.557617\n",
      "Train Epoch: 30 [157824/225000 (70%)] Loss: 14943.844727\n",
      "Train Epoch: 30 [159232/225000 (71%)] Loss: 14761.212891\n",
      "Train Epoch: 30 [160640/225000 (71%)] Loss: 15036.061523\n",
      "Train Epoch: 30 [162048/225000 (72%)] Loss: 15197.782227\n",
      "Train Epoch: 30 [163456/225000 (73%)] Loss: 15357.396484\n",
      "Train Epoch: 30 [164864/225000 (73%)] Loss: 14928.552734\n",
      "Train Epoch: 30 [166272/225000 (74%)] Loss: 14914.504883\n",
      "Train Epoch: 30 [167680/225000 (75%)] Loss: 14788.939453\n",
      "Train Epoch: 30 [169088/225000 (75%)] Loss: 15140.033203\n",
      "Train Epoch: 30 [170496/225000 (76%)] Loss: 14875.560547\n",
      "Train Epoch: 30 [171904/225000 (76%)] Loss: 15219.850586\n",
      "Train Epoch: 30 [173312/225000 (77%)] Loss: 14970.347656\n",
      "Train Epoch: 30 [174720/225000 (78%)] Loss: 15105.664062\n",
      "Train Epoch: 30 [176128/225000 (78%)] Loss: 15201.086914\n",
      "Train Epoch: 30 [177536/225000 (79%)] Loss: 15186.530273\n",
      "Train Epoch: 30 [178944/225000 (80%)] Loss: 15348.248047\n",
      "Train Epoch: 30 [180352/225000 (80%)] Loss: 15122.790039\n",
      "Train Epoch: 30 [181760/225000 (81%)] Loss: 14625.769531\n",
      "Train Epoch: 30 [183168/225000 (81%)] Loss: 14851.427734\n",
      "Train Epoch: 30 [184576/225000 (82%)] Loss: 14833.056641\n",
      "Train Epoch: 30 [185984/225000 (83%)] Loss: 15102.633789\n",
      "Train Epoch: 30 [187392/225000 (83%)] Loss: 14885.097656\n",
      "Train Epoch: 30 [188800/225000 (84%)] Loss: 15418.536133\n",
      "Train Epoch: 30 [190208/225000 (85%)] Loss: 15045.320312\n",
      "Train Epoch: 30 [191616/225000 (85%)] Loss: 15168.180664\n",
      "Train Epoch: 30 [193024/225000 (86%)] Loss: 15128.242188\n",
      "Train Epoch: 30 [194432/225000 (86%)] Loss: 15108.382812\n",
      "Train Epoch: 30 [195840/225000 (87%)] Loss: 15383.110352\n",
      "Train Epoch: 30 [197248/225000 (88%)] Loss: 15032.433594\n",
      "Train Epoch: 30 [198656/225000 (88%)] Loss: 14955.844727\n",
      "Train Epoch: 30 [200064/225000 (89%)] Loss: 15221.812500\n",
      "Train Epoch: 30 [201472/225000 (90%)] Loss: 15089.390625\n",
      "Train Epoch: 30 [202880/225000 (90%)] Loss: 14939.947266\n",
      "Train Epoch: 30 [204288/225000 (91%)] Loss: 15412.463867\n",
      "Train Epoch: 30 [205696/225000 (91%)] Loss: 15125.775391\n",
      "Train Epoch: 30 [207104/225000 (92%)] Loss: 15185.685547\n",
      "Train Epoch: 30 [208512/225000 (93%)] Loss: 15126.271484\n",
      "Train Epoch: 30 [209920/225000 (93%)] Loss: 15280.393555\n",
      "Train Epoch: 30 [211328/225000 (94%)] Loss: 14933.505859\n",
      "Train Epoch: 30 [212736/225000 (95%)] Loss: 14909.059570\n",
      "Train Epoch: 30 [214144/225000 (95%)] Loss: 14942.804688\n",
      "Train Epoch: 30 [215552/225000 (96%)] Loss: 15022.517578\n",
      "Train Epoch: 30 [216960/225000 (96%)] Loss: 15186.869141\n",
      "Train Epoch: 30 [218368/225000 (97%)] Loss: 15484.080078\n",
      "Train Epoch: 30 [219776/225000 (98%)] Loss: 15231.488281\n",
      "Train Epoch: 30 [221184/225000 (98%)] Loss: 14893.178711\n",
      "Train Epoch: 30 [222592/225000 (99%)] Loss: 15226.660156\n",
      "Train Epoch: 30 [224000/225000 (100%)] Loss: 15093.655273\n",
      "    epoch          : 30\n",
      "    loss           : 15081.239521117748\n",
      "    val_loss       : 15073.923491328194\n",
      "Train Epoch: 31 [128/225000 (0%)] Loss: 14849.107422\n",
      "Train Epoch: 31 [1536/225000 (1%)] Loss: 15338.438477\n",
      "Train Epoch: 31 [2944/225000 (1%)] Loss: 14988.048828\n",
      "Train Epoch: 31 [4352/225000 (2%)] Loss: 14700.440430\n",
      "Train Epoch: 31 [5760/225000 (3%)] Loss: 15232.769531\n",
      "Train Epoch: 31 [7168/225000 (3%)] Loss: 14926.880859\n",
      "Train Epoch: 31 [8576/225000 (4%)] Loss: 14960.764648\n",
      "Train Epoch: 31 [9984/225000 (4%)] Loss: 14882.157227\n",
      "Train Epoch: 31 [11392/225000 (5%)] Loss: 15612.511719\n",
      "Train Epoch: 31 [12800/225000 (6%)] Loss: 14969.333984\n",
      "Train Epoch: 31 [14208/225000 (6%)] Loss: 14936.354492\n",
      "Train Epoch: 31 [15616/225000 (7%)] Loss: 15814.282227\n",
      "Train Epoch: 31 [17024/225000 (8%)] Loss: 15065.984375\n",
      "Train Epoch: 31 [18432/225000 (8%)] Loss: 14333.231445\n",
      "Train Epoch: 31 [19840/225000 (9%)] Loss: 14961.172852\n",
      "Train Epoch: 31 [21248/225000 (9%)] Loss: 15020.182617\n",
      "Train Epoch: 31 [22656/225000 (10%)] Loss: 14999.942383\n",
      "Train Epoch: 31 [24064/225000 (11%)] Loss: 14797.901367\n",
      "Train Epoch: 31 [25472/225000 (11%)] Loss: 14733.642578\n",
      "Train Epoch: 31 [26880/225000 (12%)] Loss: 14675.034180\n",
      "Train Epoch: 31 [28288/225000 (13%)] Loss: 15335.103516\n",
      "Train Epoch: 31 [29696/225000 (13%)] Loss: 14843.865234\n",
      "Train Epoch: 31 [31104/225000 (14%)] Loss: 14868.015625\n",
      "Train Epoch: 31 [32512/225000 (14%)] Loss: 15089.269531\n",
      "Train Epoch: 31 [33920/225000 (15%)] Loss: 15738.856445\n",
      "Train Epoch: 31 [35328/225000 (16%)] Loss: 14901.157227\n",
      "Train Epoch: 31 [36736/225000 (16%)] Loss: 15090.205078\n",
      "Train Epoch: 31 [38144/225000 (17%)] Loss: 15057.191406\n",
      "Train Epoch: 31 [39552/225000 (18%)] Loss: 15457.979492\n",
      "Train Epoch: 31 [40960/225000 (18%)] Loss: 14965.998047\n",
      "Train Epoch: 31 [42368/225000 (19%)] Loss: 15060.279297\n",
      "Train Epoch: 31 [43776/225000 (19%)] Loss: 15316.957031\n",
      "Train Epoch: 31 [45184/225000 (20%)] Loss: 14950.597656\n",
      "Train Epoch: 31 [46592/225000 (21%)] Loss: 14908.962891\n",
      "Train Epoch: 31 [48000/225000 (21%)] Loss: 15041.182617\n",
      "Train Epoch: 31 [49408/225000 (22%)] Loss: 14848.598633\n",
      "Train Epoch: 31 [50816/225000 (23%)] Loss: 15204.667969\n",
      "Train Epoch: 31 [52224/225000 (23%)] Loss: 15261.667969\n",
      "Train Epoch: 31 [53632/225000 (24%)] Loss: 15124.723633\n",
      "Train Epoch: 31 [55040/225000 (24%)] Loss: 15255.787109\n",
      "Train Epoch: 31 [56448/225000 (25%)] Loss: 15016.980469\n",
      "Train Epoch: 31 [57856/225000 (26%)] Loss: 14955.774414\n",
      "Train Epoch: 31 [59264/225000 (26%)] Loss: 14961.520508\n",
      "Train Epoch: 31 [60672/225000 (27%)] Loss: 14666.538086\n",
      "Train Epoch: 31 [62080/225000 (28%)] Loss: 15392.202148\n",
      "Train Epoch: 31 [63488/225000 (28%)] Loss: 15251.475586\n",
      "Train Epoch: 31 [64896/225000 (29%)] Loss: 15041.710938\n",
      "Train Epoch: 31 [66304/225000 (29%)] Loss: 15057.891602\n",
      "Train Epoch: 31 [67712/225000 (30%)] Loss: 15245.083008\n",
      "Train Epoch: 31 [69120/225000 (31%)] Loss: 14976.090820\n",
      "Train Epoch: 31 [70528/225000 (31%)] Loss: 14960.295898\n",
      "Train Epoch: 31 [71936/225000 (32%)] Loss: 15394.526367\n",
      "Train Epoch: 31 [73344/225000 (33%)] Loss: 15290.302734\n",
      "Train Epoch: 31 [74752/225000 (33%)] Loss: 15225.705078\n",
      "Train Epoch: 31 [76160/225000 (34%)] Loss: 15489.394531\n",
      "Train Epoch: 31 [77568/225000 (34%)] Loss: 15125.081055\n",
      "Train Epoch: 31 [78976/225000 (35%)] Loss: 15523.918945\n",
      "Train Epoch: 31 [80384/225000 (36%)] Loss: 15014.864258\n",
      "Train Epoch: 31 [81792/225000 (36%)] Loss: 14855.134766\n",
      "Train Epoch: 31 [83200/225000 (37%)] Loss: 15007.720703\n",
      "Train Epoch: 31 [84608/225000 (38%)] Loss: 14974.654297\n",
      "Train Epoch: 31 [86016/225000 (38%)] Loss: 15174.580078\n",
      "Train Epoch: 31 [87424/225000 (39%)] Loss: 15236.991211\n",
      "Train Epoch: 31 [88832/225000 (39%)] Loss: 15242.631836\n",
      "Train Epoch: 31 [90240/225000 (40%)] Loss: 15210.124023\n",
      "Train Epoch: 31 [91648/225000 (41%)] Loss: 15120.653320\n",
      "Train Epoch: 31 [93056/225000 (41%)] Loss: 14583.882812\n",
      "Train Epoch: 31 [94464/225000 (42%)] Loss: 14522.996094\n",
      "Train Epoch: 31 [95872/225000 (43%)] Loss: 14757.559570\n",
      "Train Epoch: 31 [97280/225000 (43%)] Loss: 15254.348633\n",
      "Train Epoch: 31 [98688/225000 (44%)] Loss: 15115.087891\n",
      "Train Epoch: 31 [100096/225000 (44%)] Loss: 15267.327148\n",
      "Train Epoch: 31 [101504/225000 (45%)] Loss: 15041.386719\n",
      "Train Epoch: 31 [102912/225000 (46%)] Loss: 15028.894531\n",
      "Train Epoch: 31 [104320/225000 (46%)] Loss: 15403.454102\n",
      "Train Epoch: 31 [105728/225000 (47%)] Loss: 14887.315430\n",
      "Train Epoch: 31 [107136/225000 (48%)] Loss: 14693.372070\n",
      "Train Epoch: 31 [108544/225000 (48%)] Loss: 15518.085938\n",
      "Train Epoch: 31 [109952/225000 (49%)] Loss: 15262.841797\n",
      "Train Epoch: 31 [111360/225000 (49%)] Loss: 14765.538086\n",
      "Train Epoch: 31 [112768/225000 (50%)] Loss: 15132.105469\n",
      "Train Epoch: 31 [114176/225000 (51%)] Loss: 15530.075195\n",
      "Train Epoch: 31 [115584/225000 (51%)] Loss: 15324.513672\n",
      "Train Epoch: 31 [116992/225000 (52%)] Loss: 15295.758789\n",
      "Train Epoch: 31 [118400/225000 (53%)] Loss: 15251.125000\n",
      "Train Epoch: 31 [119808/225000 (53%)] Loss: 14771.738281\n",
      "Train Epoch: 31 [121216/225000 (54%)] Loss: 15426.541992\n",
      "Train Epoch: 31 [122624/225000 (54%)] Loss: 15068.290039\n",
      "Train Epoch: 31 [124032/225000 (55%)] Loss: 14945.629883\n",
      "Train Epoch: 31 [125440/225000 (56%)] Loss: 15308.172852\n",
      "Train Epoch: 31 [126848/225000 (56%)] Loss: 14633.083984\n",
      "Train Epoch: 31 [128256/225000 (57%)] Loss: 14731.895508\n",
      "Train Epoch: 31 [129664/225000 (58%)] Loss: 14933.353516\n",
      "Train Epoch: 31 [131072/225000 (58%)] Loss: 14900.483398\n",
      "Train Epoch: 31 [132480/225000 (59%)] Loss: 15740.794922\n",
      "Train Epoch: 31 [133888/225000 (60%)] Loss: 15306.154297\n",
      "Train Epoch: 31 [135296/225000 (60%)] Loss: 15088.490234\n",
      "Train Epoch: 31 [136704/225000 (61%)] Loss: 15106.346680\n",
      "Train Epoch: 31 [138112/225000 (61%)] Loss: 15375.437500\n",
      "Train Epoch: 31 [139520/225000 (62%)] Loss: 15195.714844\n",
      "Train Epoch: 31 [140928/225000 (63%)] Loss: 14737.623047\n",
      "Train Epoch: 31 [142336/225000 (63%)] Loss: 14674.994141\n",
      "Train Epoch: 31 [143744/225000 (64%)] Loss: 14991.163086\n",
      "Train Epoch: 31 [145152/225000 (65%)] Loss: 14977.855469\n",
      "Train Epoch: 31 [146560/225000 (65%)] Loss: 15171.885742\n",
      "Train Epoch: 31 [147968/225000 (66%)] Loss: 15196.455078\n",
      "Train Epoch: 31 [149376/225000 (66%)] Loss: 15342.626953\n",
      "Train Epoch: 31 [150784/225000 (67%)] Loss: 15342.617188\n",
      "Train Epoch: 31 [152192/225000 (68%)] Loss: 14716.886719\n",
      "Train Epoch: 31 [153600/225000 (68%)] Loss: 14946.465820\n",
      "Train Epoch: 31 [155008/225000 (69%)] Loss: 15160.222656\n",
      "Train Epoch: 31 [156416/225000 (70%)] Loss: 15192.201172\n",
      "Train Epoch: 31 [157824/225000 (70%)] Loss: 15394.720703\n",
      "Train Epoch: 31 [159232/225000 (71%)] Loss: 15026.149414\n",
      "Train Epoch: 31 [160640/225000 (71%)] Loss: 14910.542969\n",
      "Train Epoch: 31 [162048/225000 (72%)] Loss: 15177.494141\n",
      "Train Epoch: 31 [163456/225000 (73%)] Loss: 14772.236328\n",
      "Train Epoch: 31 [164864/225000 (73%)] Loss: 15049.308594\n",
      "Train Epoch: 31 [166272/225000 (74%)] Loss: 14945.580078\n",
      "Train Epoch: 31 [167680/225000 (75%)] Loss: 15102.736328\n",
      "Train Epoch: 31 [169088/225000 (75%)] Loss: 15266.874023\n",
      "Train Epoch: 31 [170496/225000 (76%)] Loss: 15292.901367\n",
      "Train Epoch: 31 [171904/225000 (76%)] Loss: 14685.329102\n",
      "Train Epoch: 31 [173312/225000 (77%)] Loss: 15078.627930\n",
      "Train Epoch: 31 [174720/225000 (78%)] Loss: 15061.113281\n",
      "Train Epoch: 31 [176128/225000 (78%)] Loss: 15312.548828\n",
      "Train Epoch: 31 [177536/225000 (79%)] Loss: 15017.611328\n",
      "Train Epoch: 31 [178944/225000 (80%)] Loss: 15062.261719\n",
      "Train Epoch: 31 [180352/225000 (80%)] Loss: 15016.614258\n",
      "Train Epoch: 31 [181760/225000 (81%)] Loss: 14739.172852\n",
      "Train Epoch: 31 [183168/225000 (81%)] Loss: 14597.015625\n",
      "Train Epoch: 31 [184576/225000 (82%)] Loss: 14388.587891\n",
      "Train Epoch: 31 [185984/225000 (83%)] Loss: 14986.151367\n",
      "Train Epoch: 31 [187392/225000 (83%)] Loss: 14704.842773\n",
      "Train Epoch: 31 [188800/225000 (84%)] Loss: 14490.444336\n",
      "Train Epoch: 31 [190208/225000 (85%)] Loss: 15230.139648\n",
      "Train Epoch: 31 [191616/225000 (85%)] Loss: 15043.132812\n",
      "Train Epoch: 31 [193024/225000 (86%)] Loss: 15132.760742\n",
      "Train Epoch: 31 [194432/225000 (86%)] Loss: 15698.978516\n",
      "Train Epoch: 31 [195840/225000 (87%)] Loss: 14613.193359\n",
      "Train Epoch: 31 [197248/225000 (88%)] Loss: 15416.834961\n",
      "Train Epoch: 31 [198656/225000 (88%)] Loss: 15204.369141\n",
      "Train Epoch: 31 [200064/225000 (89%)] Loss: 15145.922852\n",
      "Train Epoch: 31 [201472/225000 (90%)] Loss: 15144.750977\n",
      "Train Epoch: 31 [202880/225000 (90%)] Loss: 14866.965820\n",
      "Train Epoch: 31 [204288/225000 (91%)] Loss: 14579.298828\n",
      "Train Epoch: 31 [205696/225000 (91%)] Loss: 14928.267578\n",
      "Train Epoch: 31 [207104/225000 (92%)] Loss: 14984.533203\n",
      "Train Epoch: 31 [208512/225000 (93%)] Loss: 15001.251953\n",
      "Train Epoch: 31 [209920/225000 (93%)] Loss: 15015.328125\n",
      "Train Epoch: 31 [211328/225000 (94%)] Loss: 15063.119141\n",
      "Train Epoch: 31 [212736/225000 (95%)] Loss: 15142.374023\n",
      "Train Epoch: 31 [214144/225000 (95%)] Loss: 14982.717773\n",
      "Train Epoch: 31 [215552/225000 (96%)] Loss: 14866.574219\n",
      "Train Epoch: 31 [216960/225000 (96%)] Loss: 14596.007812\n",
      "Train Epoch: 31 [218368/225000 (97%)] Loss: 14830.739258\n",
      "Train Epoch: 31 [219776/225000 (98%)] Loss: 14499.120117\n",
      "Train Epoch: 31 [221184/225000 (98%)] Loss: 14933.291992\n",
      "Train Epoch: 31 [222592/225000 (99%)] Loss: 14932.187500\n",
      "Train Epoch: 31 [224000/225000 (100%)] Loss: 15123.559570\n",
      "    epoch          : 31\n",
      "    loss           : 15084.550493502915\n",
      "    val_loss       : 15087.590645639264\n",
      "Train Epoch: 32 [128/225000 (0%)] Loss: 14989.534180\n",
      "Train Epoch: 32 [1536/225000 (1%)] Loss: 15278.682617\n",
      "Train Epoch: 32 [2944/225000 (1%)] Loss: 14328.272461\n",
      "Train Epoch: 32 [4352/225000 (2%)] Loss: 14868.214844\n",
      "Train Epoch: 32 [5760/225000 (3%)] Loss: 15070.398438\n",
      "Train Epoch: 32 [7168/225000 (3%)] Loss: 14958.041016\n",
      "Train Epoch: 32 [8576/225000 (4%)] Loss: 15114.013672\n",
      "Train Epoch: 32 [9984/225000 (4%)] Loss: 15028.032227\n",
      "Train Epoch: 32 [11392/225000 (5%)] Loss: 15200.150391\n",
      "Train Epoch: 32 [12800/225000 (6%)] Loss: 14947.889648\n",
      "Train Epoch: 32 [14208/225000 (6%)] Loss: 15136.932617\n",
      "Train Epoch: 32 [15616/225000 (7%)] Loss: 14938.875000\n",
      "Train Epoch: 32 [17024/225000 (8%)] Loss: 15259.910156\n",
      "Train Epoch: 32 [18432/225000 (8%)] Loss: 15266.710938\n",
      "Train Epoch: 32 [19840/225000 (9%)] Loss: 15352.866211\n",
      "Train Epoch: 32 [21248/225000 (9%)] Loss: 15341.974609\n",
      "Train Epoch: 32 [22656/225000 (10%)] Loss: 15480.240234\n",
      "Train Epoch: 32 [24064/225000 (11%)] Loss: 15313.180664\n",
      "Train Epoch: 32 [25472/225000 (11%)] Loss: 14783.651367\n",
      "Train Epoch: 32 [26880/225000 (12%)] Loss: 15083.042969\n",
      "Train Epoch: 32 [28288/225000 (13%)] Loss: 14729.845703\n",
      "Train Epoch: 32 [29696/225000 (13%)] Loss: 15034.976562\n",
      "Train Epoch: 32 [31104/225000 (14%)] Loss: 15205.393555\n",
      "Train Epoch: 32 [32512/225000 (14%)] Loss: 15073.360352\n",
      "Train Epoch: 32 [33920/225000 (15%)] Loss: 15370.697266\n",
      "Train Epoch: 32 [35328/225000 (16%)] Loss: 14974.221680\n",
      "Train Epoch: 32 [36736/225000 (16%)] Loss: 14437.116211\n",
      "Train Epoch: 32 [38144/225000 (17%)] Loss: 15408.410156\n",
      "Train Epoch: 32 [39552/225000 (18%)] Loss: 15192.576172\n",
      "Train Epoch: 32 [40960/225000 (18%)] Loss: 15236.441406\n",
      "Train Epoch: 32 [42368/225000 (19%)] Loss: 15066.183594\n",
      "Train Epoch: 32 [43776/225000 (19%)] Loss: 14930.641602\n",
      "Train Epoch: 32 [45184/225000 (20%)] Loss: 14843.696289\n",
      "Train Epoch: 32 [46592/225000 (21%)] Loss: 15470.543945\n",
      "Train Epoch: 32 [48000/225000 (21%)] Loss: 15238.888672\n",
      "Train Epoch: 32 [49408/225000 (22%)] Loss: 15309.172852\n",
      "Train Epoch: 32 [50816/225000 (23%)] Loss: 15179.630859\n",
      "Train Epoch: 32 [52224/225000 (23%)] Loss: 15207.652344\n",
      "Train Epoch: 32 [53632/225000 (24%)] Loss: 15626.828125\n",
      "Train Epoch: 32 [55040/225000 (24%)] Loss: 14935.438477\n",
      "Train Epoch: 32 [56448/225000 (25%)] Loss: 15040.923828\n",
      "Train Epoch: 32 [57856/225000 (26%)] Loss: 15123.542969\n",
      "Train Epoch: 32 [59264/225000 (26%)] Loss: 15775.867188\n",
      "Train Epoch: 32 [60672/225000 (27%)] Loss: 15303.434570\n",
      "Train Epoch: 32 [62080/225000 (28%)] Loss: 15154.763672\n",
      "Train Epoch: 32 [63488/225000 (28%)] Loss: 14765.958984\n",
      "Train Epoch: 32 [64896/225000 (29%)] Loss: 14574.954102\n",
      "Train Epoch: 32 [66304/225000 (29%)] Loss: 14991.128906\n",
      "Train Epoch: 32 [67712/225000 (30%)] Loss: 15059.333984\n",
      "Train Epoch: 32 [69120/225000 (31%)] Loss: 15124.603516\n",
      "Train Epoch: 32 [70528/225000 (31%)] Loss: 15365.410156\n",
      "Train Epoch: 32 [71936/225000 (32%)] Loss: 14912.757812\n",
      "Train Epoch: 32 [73344/225000 (33%)] Loss: 15286.162109\n",
      "Train Epoch: 32 [74752/225000 (33%)] Loss: 14933.280273\n",
      "Train Epoch: 32 [76160/225000 (34%)] Loss: 15169.421875\n",
      "Train Epoch: 32 [77568/225000 (34%)] Loss: 15955.495117\n",
      "Train Epoch: 32 [78976/225000 (35%)] Loss: 14909.943359\n",
      "Train Epoch: 32 [80384/225000 (36%)] Loss: 15161.697266\n",
      "Train Epoch: 32 [81792/225000 (36%)] Loss: 14907.670898\n",
      "Train Epoch: 32 [83200/225000 (37%)] Loss: 15128.711914\n",
      "Train Epoch: 32 [84608/225000 (38%)] Loss: 14775.001953\n",
      "Train Epoch: 32 [86016/225000 (38%)] Loss: 14789.064453\n",
      "Train Epoch: 32 [87424/225000 (39%)] Loss: 14880.890625\n",
      "Train Epoch: 32 [88832/225000 (39%)] Loss: 15050.358398\n",
      "Train Epoch: 32 [90240/225000 (40%)] Loss: 14841.273438\n",
      "Train Epoch: 32 [91648/225000 (41%)] Loss: 15171.604492\n",
      "Train Epoch: 32 [93056/225000 (41%)] Loss: 15332.033203\n",
      "Train Epoch: 32 [94464/225000 (42%)] Loss: 15071.916992\n",
      "Train Epoch: 32 [95872/225000 (43%)] Loss: 15269.138672\n",
      "Train Epoch: 32 [97280/225000 (43%)] Loss: 15139.212891\n",
      "Train Epoch: 32 [98688/225000 (44%)] Loss: 15235.922852\n",
      "Train Epoch: 32 [100096/225000 (44%)] Loss: 15192.612305\n",
      "Train Epoch: 32 [101504/225000 (45%)] Loss: 14430.416016\n",
      "Train Epoch: 32 [102912/225000 (46%)] Loss: 15346.962891\n",
      "Train Epoch: 32 [104320/225000 (46%)] Loss: 14903.568359\n",
      "Train Epoch: 32 [105728/225000 (47%)] Loss: 15208.482422\n",
      "Train Epoch: 32 [107136/225000 (48%)] Loss: 14515.723633\n",
      "Train Epoch: 32 [108544/225000 (48%)] Loss: 14906.411133\n",
      "Train Epoch: 32 [109952/225000 (49%)] Loss: 14939.657227\n",
      "Train Epoch: 32 [111360/225000 (49%)] Loss: 14608.691406\n",
      "Train Epoch: 32 [112768/225000 (50%)] Loss: 15051.734375\n",
      "Train Epoch: 32 [114176/225000 (51%)] Loss: 14577.410156\n",
      "Train Epoch: 32 [115584/225000 (51%)] Loss: 15061.836914\n",
      "Train Epoch: 32 [116992/225000 (52%)] Loss: 15461.076172\n",
      "Train Epoch: 32 [118400/225000 (53%)] Loss: 15268.757812\n",
      "Train Epoch: 32 [119808/225000 (53%)] Loss: 14863.168945\n",
      "Train Epoch: 32 [121216/225000 (54%)] Loss: 14798.471680\n",
      "Train Epoch: 32 [122624/225000 (54%)] Loss: 15135.041992\n",
      "Train Epoch: 32 [124032/225000 (55%)] Loss: 15210.654297\n",
      "Train Epoch: 32 [125440/225000 (56%)] Loss: 15037.860352\n",
      "Train Epoch: 32 [126848/225000 (56%)] Loss: 15628.927734\n",
      "Train Epoch: 32 [128256/225000 (57%)] Loss: 15258.735352\n",
      "Train Epoch: 32 [129664/225000 (58%)] Loss: 15251.012695\n",
      "Train Epoch: 32 [131072/225000 (58%)] Loss: 15128.489258\n",
      "Train Epoch: 32 [132480/225000 (59%)] Loss: 14759.694336\n",
      "Train Epoch: 32 [133888/225000 (60%)] Loss: 15470.920898\n",
      "Train Epoch: 32 [135296/225000 (60%)] Loss: 14731.682617\n",
      "Train Epoch: 32 [136704/225000 (61%)] Loss: 14790.047852\n",
      "Train Epoch: 32 [138112/225000 (61%)] Loss: 14507.345703\n",
      "Train Epoch: 32 [139520/225000 (62%)] Loss: 14886.830078\n",
      "Train Epoch: 32 [140928/225000 (63%)] Loss: 15044.832031\n",
      "Train Epoch: 32 [142336/225000 (63%)] Loss: 15002.890625\n",
      "Train Epoch: 32 [143744/225000 (64%)] Loss: 15292.333008\n",
      "Train Epoch: 32 [145152/225000 (65%)] Loss: 15305.368164\n",
      "Train Epoch: 32 [146560/225000 (65%)] Loss: 15785.094727\n",
      "Train Epoch: 32 [147968/225000 (66%)] Loss: 15239.977539\n",
      "Train Epoch: 32 [149376/225000 (66%)] Loss: 15252.997070\n",
      "Train Epoch: 32 [150784/225000 (67%)] Loss: 14927.347656\n",
      "Train Epoch: 32 [152192/225000 (68%)] Loss: 15644.770508\n",
      "Train Epoch: 32 [153600/225000 (68%)] Loss: 15137.049805\n",
      "Train Epoch: 32 [155008/225000 (69%)] Loss: 15059.820312\n",
      "Train Epoch: 32 [156416/225000 (70%)] Loss: 14808.189453\n",
      "Train Epoch: 32 [157824/225000 (70%)] Loss: 15373.010742\n",
      "Train Epoch: 32 [159232/225000 (71%)] Loss: 15026.876953\n",
      "Train Epoch: 32 [160640/225000 (71%)] Loss: 15532.141602\n",
      "Train Epoch: 32 [162048/225000 (72%)] Loss: 15437.392578\n",
      "Train Epoch: 32 [163456/225000 (73%)] Loss: 15202.520508\n",
      "Train Epoch: 32 [164864/225000 (73%)] Loss: 14713.798828\n",
      "Train Epoch: 32 [166272/225000 (74%)] Loss: 14746.184570\n",
      "Train Epoch: 32 [167680/225000 (75%)] Loss: 14777.445312\n",
      "Train Epoch: 32 [169088/225000 (75%)] Loss: 15126.643555\n",
      "Train Epoch: 32 [170496/225000 (76%)] Loss: 14892.698242\n",
      "Train Epoch: 32 [171904/225000 (76%)] Loss: 15224.984375\n",
      "Train Epoch: 32 [173312/225000 (77%)] Loss: 15174.147461\n",
      "Train Epoch: 32 [174720/225000 (78%)] Loss: 15627.926758\n",
      "Train Epoch: 32 [176128/225000 (78%)] Loss: 15541.424805\n",
      "Train Epoch: 32 [177536/225000 (79%)] Loss: 15539.832031\n",
      "Train Epoch: 32 [178944/225000 (80%)] Loss: 15302.626953\n",
      "Train Epoch: 32 [180352/225000 (80%)] Loss: 15248.064453\n",
      "Train Epoch: 32 [181760/225000 (81%)] Loss: 14698.134766\n",
      "Train Epoch: 32 [183168/225000 (81%)] Loss: 15477.179688\n",
      "Train Epoch: 32 [184576/225000 (82%)] Loss: 14876.913086\n",
      "Train Epoch: 32 [185984/225000 (83%)] Loss: 15094.398438\n",
      "Train Epoch: 32 [187392/225000 (83%)] Loss: 15097.825195\n",
      "Train Epoch: 32 [188800/225000 (84%)] Loss: 14941.469727\n",
      "Train Epoch: 32 [190208/225000 (85%)] Loss: 14886.902344\n",
      "Train Epoch: 32 [191616/225000 (85%)] Loss: 15674.645508\n",
      "Train Epoch: 32 [193024/225000 (86%)] Loss: 15118.299805\n",
      "Train Epoch: 32 [194432/225000 (86%)] Loss: 14875.601562\n",
      "Train Epoch: 32 [195840/225000 (87%)] Loss: 14584.921875\n",
      "Train Epoch: 32 [197248/225000 (88%)] Loss: 15498.039062\n",
      "Train Epoch: 32 [198656/225000 (88%)] Loss: 15729.763672\n",
      "Train Epoch: 32 [200064/225000 (89%)] Loss: 14836.391602\n",
      "Train Epoch: 32 [201472/225000 (90%)] Loss: 14499.514648\n",
      "Train Epoch: 32 [202880/225000 (90%)] Loss: 15352.988281\n",
      "Train Epoch: 32 [204288/225000 (91%)] Loss: 15088.299805\n",
      "Train Epoch: 32 [205696/225000 (91%)] Loss: 15271.523438\n",
      "Train Epoch: 32 [207104/225000 (92%)] Loss: 15144.191406\n",
      "Train Epoch: 32 [208512/225000 (93%)] Loss: 14758.134766\n",
      "Train Epoch: 32 [209920/225000 (93%)] Loss: 15480.379883\n",
      "Train Epoch: 32 [211328/225000 (94%)] Loss: 15102.918945\n",
      "Train Epoch: 32 [212736/225000 (95%)] Loss: 15127.849609\n",
      "Train Epoch: 32 [214144/225000 (95%)] Loss: 15313.507812\n",
      "Train Epoch: 32 [215552/225000 (96%)] Loss: 15055.772461\n",
      "Train Epoch: 32 [216960/225000 (96%)] Loss: 14554.792969\n",
      "Train Epoch: 32 [218368/225000 (97%)] Loss: 15116.054688\n",
      "Train Epoch: 32 [219776/225000 (98%)] Loss: 15406.436523\n",
      "Train Epoch: 32 [221184/225000 (98%)] Loss: 15040.618164\n",
      "Train Epoch: 32 [222592/225000 (99%)] Loss: 15004.159180\n",
      "Train Epoch: 32 [224000/225000 (100%)] Loss: 15200.143555\n",
      "    epoch          : 32\n",
      "    loss           : 15090.344543804216\n",
      "    val_loss       : 15073.995038526931\n",
      "Train Epoch: 33 [128/225000 (0%)] Loss: 14999.858398\n",
      "Train Epoch: 33 [1536/225000 (1%)] Loss: 14652.742188\n",
      "Train Epoch: 33 [2944/225000 (1%)] Loss: 15150.162109\n",
      "Train Epoch: 33 [4352/225000 (2%)] Loss: 15062.649414\n",
      "Train Epoch: 33 [5760/225000 (3%)] Loss: 15314.668945\n",
      "Train Epoch: 33 [7168/225000 (3%)] Loss: 15053.520508\n",
      "Train Epoch: 33 [8576/225000 (4%)] Loss: 15003.841797\n",
      "Train Epoch: 33 [9984/225000 (4%)] Loss: 15788.754883\n",
      "Train Epoch: 33 [11392/225000 (5%)] Loss: 15879.740234\n",
      "Train Epoch: 33 [12800/225000 (6%)] Loss: 15319.059570\n",
      "Train Epoch: 33 [14208/225000 (6%)] Loss: 14789.074219\n",
      "Train Epoch: 33 [15616/225000 (7%)] Loss: 15004.486328\n",
      "Train Epoch: 33 [17024/225000 (8%)] Loss: 15514.096680\n",
      "Train Epoch: 33 [18432/225000 (8%)] Loss: 15134.772461\n",
      "Train Epoch: 33 [19840/225000 (9%)] Loss: 15046.755859\n",
      "Train Epoch: 33 [21248/225000 (9%)] Loss: 14572.120117\n",
      "Train Epoch: 33 [22656/225000 (10%)] Loss: 14935.112305\n",
      "Train Epoch: 33 [24064/225000 (11%)] Loss: 14906.125977\n",
      "Train Epoch: 33 [25472/225000 (11%)] Loss: 14808.892578\n",
      "Train Epoch: 33 [26880/225000 (12%)] Loss: 15147.592773\n",
      "Train Epoch: 33 [28288/225000 (13%)] Loss: 15107.653320\n",
      "Train Epoch: 33 [29696/225000 (13%)] Loss: 14875.650391\n",
      "Train Epoch: 33 [31104/225000 (14%)] Loss: 15031.631836\n",
      "Train Epoch: 33 [32512/225000 (14%)] Loss: 15369.126953\n",
      "Train Epoch: 33 [33920/225000 (15%)] Loss: 14901.329102\n",
      "Train Epoch: 33 [35328/225000 (16%)] Loss: 14612.113281\n",
      "Train Epoch: 33 [36736/225000 (16%)] Loss: 14974.534180\n",
      "Train Epoch: 33 [38144/225000 (17%)] Loss: 15102.113281\n",
      "Train Epoch: 33 [39552/225000 (18%)] Loss: 15018.315430\n",
      "Train Epoch: 33 [40960/225000 (18%)] Loss: 15210.966797\n",
      "Train Epoch: 33 [42368/225000 (19%)] Loss: 15438.217773\n",
      "Train Epoch: 33 [43776/225000 (19%)] Loss: 14885.058594\n",
      "Train Epoch: 33 [45184/225000 (20%)] Loss: 15016.694336\n",
      "Train Epoch: 33 [46592/225000 (21%)] Loss: 15134.680664\n",
      "Train Epoch: 33 [48000/225000 (21%)] Loss: 15158.224609\n",
      "Train Epoch: 33 [49408/225000 (22%)] Loss: 15231.303711\n",
      "Train Epoch: 33 [50816/225000 (23%)] Loss: 14776.362305\n",
      "Train Epoch: 33 [52224/225000 (23%)] Loss: 14994.523438\n",
      "Train Epoch: 33 [53632/225000 (24%)] Loss: 14841.614258\n",
      "Train Epoch: 33 [55040/225000 (24%)] Loss: 15127.288086\n",
      "Train Epoch: 33 [56448/225000 (25%)] Loss: 15122.576172\n",
      "Train Epoch: 33 [57856/225000 (26%)] Loss: 15217.500977\n",
      "Train Epoch: 33 [59264/225000 (26%)] Loss: 15075.607422\n",
      "Train Epoch: 33 [60672/225000 (27%)] Loss: 14612.583008\n",
      "Train Epoch: 33 [62080/225000 (28%)] Loss: 15430.312500\n",
      "Train Epoch: 33 [63488/225000 (28%)] Loss: 15168.347656\n",
      "Train Epoch: 33 [64896/225000 (29%)] Loss: 15072.718750\n",
      "Train Epoch: 33 [66304/225000 (29%)] Loss: 14899.349609\n",
      "Train Epoch: 33 [67712/225000 (30%)] Loss: 15169.367188\n",
      "Train Epoch: 33 [69120/225000 (31%)] Loss: 15012.454102\n",
      "Train Epoch: 33 [70528/225000 (31%)] Loss: 15475.916016\n",
      "Train Epoch: 33 [71936/225000 (32%)] Loss: 14977.678711\n",
      "Train Epoch: 33 [73344/225000 (33%)] Loss: 15047.663086\n",
      "Train Epoch: 33 [74752/225000 (33%)] Loss: 15075.898438\n",
      "Train Epoch: 33 [76160/225000 (34%)] Loss: 15235.306641\n",
      "Train Epoch: 33 [77568/225000 (34%)] Loss: 15248.555664\n",
      "Train Epoch: 33 [78976/225000 (35%)] Loss: 15105.753906\n",
      "Train Epoch: 33 [80384/225000 (36%)] Loss: 14831.109375\n",
      "Train Epoch: 33 [81792/225000 (36%)] Loss: 14604.369141\n",
      "Train Epoch: 33 [83200/225000 (37%)] Loss: 14902.542969\n",
      "Train Epoch: 33 [84608/225000 (38%)] Loss: 14990.250000\n",
      "Train Epoch: 33 [86016/225000 (38%)] Loss: 15538.358398\n",
      "Train Epoch: 33 [87424/225000 (39%)] Loss: 15428.298828\n",
      "Train Epoch: 33 [88832/225000 (39%)] Loss: 15140.177734\n",
      "Train Epoch: 33 [90240/225000 (40%)] Loss: 14930.042969\n",
      "Train Epoch: 33 [91648/225000 (41%)] Loss: 15045.404297\n",
      "Train Epoch: 33 [93056/225000 (41%)] Loss: 15450.606445\n",
      "Train Epoch: 33 [94464/225000 (42%)] Loss: 14767.436523\n",
      "Train Epoch: 33 [95872/225000 (43%)] Loss: 15338.035156\n",
      "Train Epoch: 33 [97280/225000 (43%)] Loss: 15082.265625\n",
      "Train Epoch: 33 [98688/225000 (44%)] Loss: 15390.964844\n",
      "Train Epoch: 33 [100096/225000 (44%)] Loss: 15012.883789\n",
      "Train Epoch: 33 [101504/225000 (45%)] Loss: 15229.269531\n",
      "Train Epoch: 33 [102912/225000 (46%)] Loss: 15391.291992\n",
      "Train Epoch: 33 [104320/225000 (46%)] Loss: 15231.843750\n",
      "Train Epoch: 33 [105728/225000 (47%)] Loss: 14672.636719\n",
      "Train Epoch: 33 [107136/225000 (48%)] Loss: 14942.626953\n",
      "Train Epoch: 33 [108544/225000 (48%)] Loss: 14886.619141\n",
      "Train Epoch: 33 [109952/225000 (49%)] Loss: 15189.824219\n",
      "Train Epoch: 33 [111360/225000 (49%)] Loss: 15118.413086\n",
      "Train Epoch: 33 [112768/225000 (50%)] Loss: 15561.855469\n",
      "Train Epoch: 33 [114176/225000 (51%)] Loss: 14902.030273\n",
      "Train Epoch: 33 [115584/225000 (51%)] Loss: 15159.889648\n",
      "Train Epoch: 33 [116992/225000 (52%)] Loss: 15197.151367\n",
      "Train Epoch: 33 [118400/225000 (53%)] Loss: 15417.159180\n",
      "Train Epoch: 33 [119808/225000 (53%)] Loss: 15093.658203\n",
      "Train Epoch: 33 [121216/225000 (54%)] Loss: 14928.339844\n",
      "Train Epoch: 33 [122624/225000 (54%)] Loss: 15253.048828\n",
      "Train Epoch: 33 [124032/225000 (55%)] Loss: 15129.776367\n",
      "Train Epoch: 33 [125440/225000 (56%)] Loss: 15077.318359\n",
      "Train Epoch: 33 [126848/225000 (56%)] Loss: 15315.408203\n",
      "Train Epoch: 33 [128256/225000 (57%)] Loss: 15360.880859\n",
      "Train Epoch: 33 [129664/225000 (58%)] Loss: 14895.370117\n",
      "Train Epoch: 33 [131072/225000 (58%)] Loss: 15030.389648\n",
      "Train Epoch: 33 [132480/225000 (59%)] Loss: 15641.145508\n",
      "Train Epoch: 33 [133888/225000 (60%)] Loss: 15258.310547\n",
      "Train Epoch: 33 [135296/225000 (60%)] Loss: 14893.972656\n",
      "Train Epoch: 33 [136704/225000 (61%)] Loss: 15277.036133\n",
      "Train Epoch: 33 [138112/225000 (61%)] Loss: 15495.071289\n",
      "Train Epoch: 33 [139520/225000 (62%)] Loss: 15039.593750\n",
      "Train Epoch: 33 [140928/225000 (63%)] Loss: 15709.423828\n",
      "Train Epoch: 33 [142336/225000 (63%)] Loss: 14747.079102\n",
      "Train Epoch: 33 [143744/225000 (64%)] Loss: 14738.330078\n",
      "Train Epoch: 33 [145152/225000 (65%)] Loss: 15082.567383\n",
      "Train Epoch: 33 [146560/225000 (65%)] Loss: 15168.381836\n",
      "Train Epoch: 33 [147968/225000 (66%)] Loss: 14834.482422\n",
      "Train Epoch: 33 [149376/225000 (66%)] Loss: 14893.349609\n",
      "Train Epoch: 33 [150784/225000 (67%)] Loss: 15032.111328\n",
      "Train Epoch: 33 [152192/225000 (68%)] Loss: 14907.302734\n",
      "Train Epoch: 33 [153600/225000 (68%)] Loss: 15013.218750\n",
      "Train Epoch: 33 [155008/225000 (69%)] Loss: 15211.667969\n",
      "Train Epoch: 33 [156416/225000 (70%)] Loss: 15118.619141\n",
      "Train Epoch: 33 [157824/225000 (70%)] Loss: 15465.886719\n",
      "Train Epoch: 33 [159232/225000 (71%)] Loss: 15053.487305\n",
      "Train Epoch: 33 [160640/225000 (71%)] Loss: 15068.100586\n",
      "Train Epoch: 33 [162048/225000 (72%)] Loss: 14777.440430\n",
      "Train Epoch: 33 [163456/225000 (73%)] Loss: 15293.974609\n",
      "Train Epoch: 33 [164864/225000 (73%)] Loss: 15173.635742\n",
      "Train Epoch: 33 [166272/225000 (74%)] Loss: 14953.885742\n",
      "Train Epoch: 33 [167680/225000 (75%)] Loss: 15479.821289\n",
      "Train Epoch: 33 [169088/225000 (75%)] Loss: 14934.005859\n",
      "Train Epoch: 33 [170496/225000 (76%)] Loss: 14817.496094\n",
      "Train Epoch: 33 [171904/225000 (76%)] Loss: 15193.637695\n",
      "Train Epoch: 33 [173312/225000 (77%)] Loss: 15176.920898\n",
      "Train Epoch: 33 [174720/225000 (78%)] Loss: 14624.508789\n",
      "Train Epoch: 33 [176128/225000 (78%)] Loss: 14909.120117\n",
      "Train Epoch: 33 [177536/225000 (79%)] Loss: 15143.445312\n",
      "Train Epoch: 33 [178944/225000 (80%)] Loss: 14961.616211\n",
      "Train Epoch: 33 [180352/225000 (80%)] Loss: 15342.263672\n",
      "Train Epoch: 33 [181760/225000 (81%)] Loss: 15695.678711\n",
      "Train Epoch: 33 [183168/225000 (81%)] Loss: 15438.030273\n",
      "Train Epoch: 33 [184576/225000 (82%)] Loss: 14734.992188\n",
      "Train Epoch: 33 [185984/225000 (83%)] Loss: 14651.703125\n",
      "Train Epoch: 33 [187392/225000 (83%)] Loss: 15242.042969\n",
      "Train Epoch: 33 [188800/225000 (84%)] Loss: 15156.177734\n",
      "Train Epoch: 33 [190208/225000 (85%)] Loss: 15293.383789\n",
      "Train Epoch: 33 [191616/225000 (85%)] Loss: 15261.617188\n",
      "Train Epoch: 33 [193024/225000 (86%)] Loss: 15455.510742\n",
      "Train Epoch: 33 [194432/225000 (86%)] Loss: 15084.442383\n",
      "Train Epoch: 33 [195840/225000 (87%)] Loss: 15190.758789\n",
      "Train Epoch: 33 [197248/225000 (88%)] Loss: 15542.728516\n",
      "Train Epoch: 33 [198656/225000 (88%)] Loss: 15016.536133\n",
      "Train Epoch: 33 [200064/225000 (89%)] Loss: 15148.875000\n",
      "Train Epoch: 33 [201472/225000 (90%)] Loss: 15168.361328\n",
      "Train Epoch: 33 [202880/225000 (90%)] Loss: 15342.558594\n",
      "Train Epoch: 33 [204288/225000 (91%)] Loss: 14952.691406\n",
      "Train Epoch: 33 [205696/225000 (91%)] Loss: 15218.322266\n",
      "Train Epoch: 33 [207104/225000 (92%)] Loss: 15253.823242\n",
      "Train Epoch: 33 [208512/225000 (93%)] Loss: 15084.713867\n",
      "Train Epoch: 33 [209920/225000 (93%)] Loss: 15360.949219\n",
      "Train Epoch: 33 [211328/225000 (94%)] Loss: 15300.211914\n",
      "Train Epoch: 33 [212736/225000 (95%)] Loss: 14843.150391\n",
      "Train Epoch: 33 [214144/225000 (95%)] Loss: 15254.157227\n",
      "Train Epoch: 33 [215552/225000 (96%)] Loss: 14987.004883\n",
      "Train Epoch: 33 [216960/225000 (96%)] Loss: 15427.505859\n",
      "Train Epoch: 33 [218368/225000 (97%)] Loss: 15149.404297\n",
      "Train Epoch: 33 [219776/225000 (98%)] Loss: 14866.708008\n",
      "Train Epoch: 33 [221184/225000 (98%)] Loss: 14908.334961\n",
      "Train Epoch: 33 [222592/225000 (99%)] Loss: 14977.117188\n",
      "Train Epoch: 33 [224000/225000 (100%)] Loss: 15200.689453\n",
      "    epoch          : 33\n",
      "    loss           : 15089.88785918391\n",
      "    val_loss       : 15064.67178374027\n",
      "Train Epoch: 34 [128/225000 (0%)] Loss: 15114.743164\n",
      "Train Epoch: 34 [1536/225000 (1%)] Loss: 15179.533203\n",
      "Train Epoch: 34 [2944/225000 (1%)] Loss: 15394.433594\n",
      "Train Epoch: 34 [4352/225000 (2%)] Loss: 15070.520508\n",
      "Train Epoch: 34 [5760/225000 (3%)] Loss: 14681.515625\n",
      "Train Epoch: 34 [7168/225000 (3%)] Loss: 15021.723633\n",
      "Train Epoch: 34 [8576/225000 (4%)] Loss: 14947.024414\n",
      "Train Epoch: 34 [9984/225000 (4%)] Loss: 14845.298828\n",
      "Train Epoch: 34 [11392/225000 (5%)] Loss: 15054.295898\n",
      "Train Epoch: 34 [12800/225000 (6%)] Loss: 15094.836914\n",
      "Train Epoch: 34 [14208/225000 (6%)] Loss: 15050.461914\n",
      "Train Epoch: 34 [15616/225000 (7%)] Loss: 16208.609375\n",
      "Train Epoch: 34 [17024/225000 (8%)] Loss: 14838.102539\n",
      "Train Epoch: 34 [18432/225000 (8%)] Loss: 14866.496094\n",
      "Train Epoch: 34 [19840/225000 (9%)] Loss: 15064.807617\n",
      "Train Epoch: 34 [21248/225000 (9%)] Loss: 15176.958008\n",
      "Train Epoch: 34 [22656/225000 (10%)] Loss: 15009.618164\n",
      "Train Epoch: 34 [24064/225000 (11%)] Loss: 15643.050781\n",
      "Train Epoch: 34 [25472/225000 (11%)] Loss: 14885.332031\n",
      "Train Epoch: 34 [26880/225000 (12%)] Loss: 15380.312500\n",
      "Train Epoch: 34 [28288/225000 (13%)] Loss: 15651.302734\n",
      "Train Epoch: 34 [29696/225000 (13%)] Loss: 15266.834961\n",
      "Train Epoch: 34 [31104/225000 (14%)] Loss: 15263.041016\n",
      "Train Epoch: 34 [32512/225000 (14%)] Loss: 14883.218750\n",
      "Train Epoch: 34 [33920/225000 (15%)] Loss: 15356.880859\n",
      "Train Epoch: 34 [35328/225000 (16%)] Loss: 15294.497070\n",
      "Train Epoch: 34 [36736/225000 (16%)] Loss: 15343.217773\n",
      "Train Epoch: 34 [38144/225000 (17%)] Loss: 14847.613281\n",
      "Train Epoch: 34 [39552/225000 (18%)] Loss: 14606.812500\n",
      "Train Epoch: 34 [40960/225000 (18%)] Loss: 15103.242188\n",
      "Train Epoch: 34 [42368/225000 (19%)] Loss: 14791.104492\n",
      "Train Epoch: 34 [43776/225000 (19%)] Loss: 15115.773438\n",
      "Train Epoch: 34 [45184/225000 (20%)] Loss: 15363.934570\n",
      "Train Epoch: 34 [46592/225000 (21%)] Loss: 15546.224609\n",
      "Train Epoch: 34 [48000/225000 (21%)] Loss: 15009.943359\n",
      "Train Epoch: 34 [49408/225000 (22%)] Loss: 15228.590820\n",
      "Train Epoch: 34 [50816/225000 (23%)] Loss: 14894.143555\n",
      "Train Epoch: 34 [52224/225000 (23%)] Loss: 15295.522461\n",
      "Train Epoch: 34 [53632/225000 (24%)] Loss: 15002.299805\n",
      "Train Epoch: 34 [55040/225000 (24%)] Loss: 15421.708008\n",
      "Train Epoch: 34 [56448/225000 (25%)] Loss: 15126.936523\n",
      "Train Epoch: 34 [57856/225000 (26%)] Loss: 14845.589844\n",
      "Train Epoch: 34 [59264/225000 (26%)] Loss: 14706.770508\n",
      "Train Epoch: 34 [60672/225000 (27%)] Loss: 15148.130859\n",
      "Train Epoch: 34 [62080/225000 (28%)] Loss: 14754.500977\n",
      "Train Epoch: 34 [63488/225000 (28%)] Loss: 15153.009766\n",
      "Train Epoch: 34 [64896/225000 (29%)] Loss: 15264.651367\n",
      "Train Epoch: 34 [66304/225000 (29%)] Loss: 14983.229492\n",
      "Train Epoch: 34 [67712/225000 (30%)] Loss: 14662.547852\n",
      "Train Epoch: 34 [69120/225000 (31%)] Loss: 15051.819336\n",
      "Train Epoch: 34 [70528/225000 (31%)] Loss: 15141.831055\n",
      "Train Epoch: 34 [71936/225000 (32%)] Loss: 15387.325195\n",
      "Train Epoch: 34 [73344/225000 (33%)] Loss: 14977.185547\n",
      "Train Epoch: 34 [74752/225000 (33%)] Loss: 14877.464844\n",
      "Train Epoch: 34 [76160/225000 (34%)] Loss: 14909.980469\n",
      "Train Epoch: 34 [77568/225000 (34%)] Loss: 14587.059570\n",
      "Train Epoch: 34 [78976/225000 (35%)] Loss: 15357.326172\n",
      "Train Epoch: 34 [80384/225000 (36%)] Loss: 14750.347656\n",
      "Train Epoch: 34 [81792/225000 (36%)] Loss: 14785.850586\n",
      "Train Epoch: 34 [83200/225000 (37%)] Loss: 14813.748047\n",
      "Train Epoch: 34 [84608/225000 (38%)] Loss: 15082.823242\n",
      "Train Epoch: 34 [86016/225000 (38%)] Loss: 15215.747070\n",
      "Train Epoch: 34 [87424/225000 (39%)] Loss: 15269.477539\n",
      "Train Epoch: 34 [88832/225000 (39%)] Loss: 14810.500977\n",
      "Train Epoch: 34 [90240/225000 (40%)] Loss: 14605.398438\n",
      "Train Epoch: 34 [91648/225000 (41%)] Loss: 15396.076172\n",
      "Train Epoch: 34 [93056/225000 (41%)] Loss: 15332.919922\n",
      "Train Epoch: 34 [94464/225000 (42%)] Loss: 15500.526367\n",
      "Train Epoch: 34 [95872/225000 (43%)] Loss: 15344.852539\n",
      "Train Epoch: 34 [97280/225000 (43%)] Loss: 15021.036133\n",
      "Train Epoch: 34 [98688/225000 (44%)] Loss: 15275.562500\n",
      "Train Epoch: 34 [100096/225000 (44%)] Loss: 15073.270508\n",
      "Train Epoch: 34 [101504/225000 (45%)] Loss: 15716.573242\n",
      "Train Epoch: 34 [102912/225000 (46%)] Loss: 14848.026367\n",
      "Train Epoch: 34 [104320/225000 (46%)] Loss: 15245.641602\n",
      "Train Epoch: 34 [105728/225000 (47%)] Loss: 14847.619141\n",
      "Train Epoch: 34 [107136/225000 (48%)] Loss: 15425.263672\n",
      "Train Epoch: 34 [108544/225000 (48%)] Loss: 15139.991211\n",
      "Train Epoch: 34 [109952/225000 (49%)] Loss: 14970.195312\n",
      "Train Epoch: 34 [111360/225000 (49%)] Loss: 15508.499023\n",
      "Train Epoch: 34 [112768/225000 (50%)] Loss: 14849.981445\n",
      "Train Epoch: 34 [114176/225000 (51%)] Loss: 14875.232422\n",
      "Train Epoch: 34 [115584/225000 (51%)] Loss: 14956.178711\n",
      "Train Epoch: 34 [116992/225000 (52%)] Loss: 15230.839844\n",
      "Train Epoch: 34 [118400/225000 (53%)] Loss: 14991.277344\n",
      "Train Epoch: 34 [119808/225000 (53%)] Loss: 15276.965820\n",
      "Train Epoch: 34 [121216/225000 (54%)] Loss: 14960.803711\n",
      "Train Epoch: 34 [122624/225000 (54%)] Loss: 15442.538086\n",
      "Train Epoch: 34 [124032/225000 (55%)] Loss: 14853.577148\n",
      "Train Epoch: 34 [125440/225000 (56%)] Loss: 14748.494141\n",
      "Train Epoch: 34 [126848/225000 (56%)] Loss: 14822.772461\n",
      "Train Epoch: 34 [128256/225000 (57%)] Loss: 15055.874023\n",
      "Train Epoch: 34 [129664/225000 (58%)] Loss: 14697.272461\n",
      "Train Epoch: 34 [131072/225000 (58%)] Loss: 15391.865234\n",
      "Train Epoch: 34 [132480/225000 (59%)] Loss: 14877.089844\n",
      "Train Epoch: 34 [133888/225000 (60%)] Loss: 15290.848633\n",
      "Train Epoch: 34 [135296/225000 (60%)] Loss: 15281.739258\n",
      "Train Epoch: 34 [136704/225000 (61%)] Loss: 15331.528320\n",
      "Train Epoch: 34 [138112/225000 (61%)] Loss: 15341.253906\n",
      "Train Epoch: 34 [139520/225000 (62%)] Loss: 14806.933594\n",
      "Train Epoch: 34 [140928/225000 (63%)] Loss: 15337.322266\n",
      "Train Epoch: 34 [142336/225000 (63%)] Loss: 15503.487305\n",
      "Train Epoch: 34 [143744/225000 (64%)] Loss: 15490.272461\n",
      "Train Epoch: 34 [145152/225000 (65%)] Loss: 15195.855469\n",
      "Train Epoch: 34 [146560/225000 (65%)] Loss: 15000.513672\n",
      "Train Epoch: 34 [147968/225000 (66%)] Loss: 14732.724609\n",
      "Train Epoch: 34 [149376/225000 (66%)] Loss: 15108.617188\n",
      "Train Epoch: 34 [150784/225000 (67%)] Loss: 15463.249023\n",
      "Train Epoch: 34 [152192/225000 (68%)] Loss: 15526.591797\n",
      "Train Epoch: 34 [153600/225000 (68%)] Loss: 15318.166016\n",
      "Train Epoch: 34 [155008/225000 (69%)] Loss: 15152.798828\n",
      "Train Epoch: 34 [156416/225000 (70%)] Loss: 15166.419922\n",
      "Train Epoch: 34 [157824/225000 (70%)] Loss: 14871.881836\n",
      "Train Epoch: 34 [159232/225000 (71%)] Loss: 15456.206055\n",
      "Train Epoch: 34 [160640/225000 (71%)] Loss: 15308.254883\n",
      "Train Epoch: 34 [162048/225000 (72%)] Loss: 14736.085938\n",
      "Train Epoch: 34 [163456/225000 (73%)] Loss: 14755.740234\n",
      "Train Epoch: 34 [164864/225000 (73%)] Loss: 15132.694336\n",
      "Train Epoch: 34 [166272/225000 (74%)] Loss: 15107.266602\n",
      "Train Epoch: 34 [167680/225000 (75%)] Loss: 15398.538086\n",
      "Train Epoch: 34 [169088/225000 (75%)] Loss: 15162.085938\n",
      "Train Epoch: 34 [170496/225000 (76%)] Loss: 15106.643555\n",
      "Train Epoch: 34 [171904/225000 (76%)] Loss: 14938.962891\n",
      "Train Epoch: 34 [173312/225000 (77%)] Loss: 15203.520508\n",
      "Train Epoch: 34 [174720/225000 (78%)] Loss: 15196.596680\n",
      "Train Epoch: 34 [176128/225000 (78%)] Loss: 15257.802734\n",
      "Train Epoch: 34 [177536/225000 (79%)] Loss: 15195.398438\n",
      "Train Epoch: 34 [178944/225000 (80%)] Loss: 15371.062500\n",
      "Train Epoch: 34 [180352/225000 (80%)] Loss: 14812.420898\n",
      "Train Epoch: 34 [181760/225000 (81%)] Loss: 15135.865234\n",
      "Train Epoch: 34 [183168/225000 (81%)] Loss: 14909.853516\n",
      "Train Epoch: 34 [184576/225000 (82%)] Loss: 14973.043945\n",
      "Train Epoch: 34 [185984/225000 (83%)] Loss: 14795.179688\n",
      "Train Epoch: 34 [187392/225000 (83%)] Loss: 14768.580078\n",
      "Train Epoch: 34 [188800/225000 (84%)] Loss: 14747.060547\n",
      "Train Epoch: 34 [190208/225000 (85%)] Loss: 15108.322266\n",
      "Train Epoch: 34 [191616/225000 (85%)] Loss: 15152.984375\n",
      "Train Epoch: 34 [193024/225000 (86%)] Loss: 15719.150391\n",
      "Train Epoch: 34 [194432/225000 (86%)] Loss: 15027.451172\n",
      "Train Epoch: 34 [195840/225000 (87%)] Loss: 14928.398438\n",
      "Train Epoch: 34 [197248/225000 (88%)] Loss: 14959.555664\n",
      "Train Epoch: 34 [198656/225000 (88%)] Loss: 15193.757812\n",
      "Train Epoch: 34 [200064/225000 (89%)] Loss: 15004.192383\n",
      "Train Epoch: 34 [201472/225000 (90%)] Loss: 15425.554688\n",
      "Train Epoch: 34 [202880/225000 (90%)] Loss: 15577.910156\n",
      "Train Epoch: 34 [204288/225000 (91%)] Loss: 14901.475586\n",
      "Train Epoch: 34 [205696/225000 (91%)] Loss: 15078.703125\n",
      "Train Epoch: 34 [207104/225000 (92%)] Loss: 14803.635742\n",
      "Train Epoch: 34 [208512/225000 (93%)] Loss: 15461.538086\n",
      "Train Epoch: 34 [209920/225000 (93%)] Loss: 15279.938477\n",
      "Train Epoch: 34 [211328/225000 (94%)] Loss: 14972.150391\n",
      "Train Epoch: 34 [212736/225000 (95%)] Loss: 14777.334961\n",
      "Train Epoch: 34 [214144/225000 (95%)] Loss: 14924.342773\n",
      "Train Epoch: 34 [215552/225000 (96%)] Loss: 15317.132812\n",
      "Train Epoch: 34 [216960/225000 (96%)] Loss: 15244.328125\n",
      "Train Epoch: 34 [218368/225000 (97%)] Loss: 15074.593750\n",
      "Train Epoch: 34 [219776/225000 (98%)] Loss: 14635.782227\n",
      "Train Epoch: 34 [221184/225000 (98%)] Loss: 14802.902344\n",
      "Train Epoch: 34 [222592/225000 (99%)] Loss: 15458.666992\n",
      "Train Epoch: 34 [224000/225000 (100%)] Loss: 15152.174805\n",
      "    epoch          : 34\n",
      "    loss           : 15089.23224022771\n",
      "    val_loss       : 15066.357251671048\n",
      "Train Epoch: 35 [128/225000 (0%)] Loss: 15527.678711\n",
      "Train Epoch: 35 [1536/225000 (1%)] Loss: 15341.877930\n",
      "Train Epoch: 35 [2944/225000 (1%)] Loss: 15312.382812\n",
      "Train Epoch: 35 [4352/225000 (2%)] Loss: 15181.805664\n",
      "Train Epoch: 35 [5760/225000 (3%)] Loss: 15063.078125\n",
      "Train Epoch: 35 [7168/225000 (3%)] Loss: 15262.771484\n",
      "Train Epoch: 35 [8576/225000 (4%)] Loss: 15368.022461\n",
      "Train Epoch: 35 [9984/225000 (4%)] Loss: 15305.933594\n",
      "Train Epoch: 35 [11392/225000 (5%)] Loss: 15139.825195\n",
      "Train Epoch: 35 [12800/225000 (6%)] Loss: 15202.313477\n",
      "Train Epoch: 35 [14208/225000 (6%)] Loss: 15353.769531\n",
      "Train Epoch: 35 [15616/225000 (7%)] Loss: 14880.185547\n",
      "Train Epoch: 35 [17024/225000 (8%)] Loss: 14875.973633\n",
      "Train Epoch: 35 [18432/225000 (8%)] Loss: 15071.492188\n",
      "Train Epoch: 35 [19840/225000 (9%)] Loss: 14980.789062\n",
      "Train Epoch: 35 [21248/225000 (9%)] Loss: 15404.804688\n",
      "Train Epoch: 35 [22656/225000 (10%)] Loss: 15346.947266\n",
      "Train Epoch: 35 [24064/225000 (11%)] Loss: 15600.383789\n",
      "Train Epoch: 35 [25472/225000 (11%)] Loss: 14868.554688\n",
      "Train Epoch: 35 [26880/225000 (12%)] Loss: 14791.355469\n",
      "Train Epoch: 35 [28288/225000 (13%)] Loss: 15428.944336\n",
      "Train Epoch: 35 [29696/225000 (13%)] Loss: 14745.120117\n",
      "Train Epoch: 35 [31104/225000 (14%)] Loss: 14772.827148\n",
      "Train Epoch: 35 [32512/225000 (14%)] Loss: 15502.896484\n",
      "Train Epoch: 35 [33920/225000 (15%)] Loss: 15208.883789\n",
      "Train Epoch: 35 [35328/225000 (16%)] Loss: 15722.365234\n",
      "Train Epoch: 35 [36736/225000 (16%)] Loss: 15372.248047\n",
      "Train Epoch: 35 [38144/225000 (17%)] Loss: 14981.693359\n",
      "Train Epoch: 35 [39552/225000 (18%)] Loss: 14422.852539\n",
      "Train Epoch: 35 [40960/225000 (18%)] Loss: 15060.695312\n",
      "Train Epoch: 35 [42368/225000 (19%)] Loss: 15173.345703\n",
      "Train Epoch: 35 [43776/225000 (19%)] Loss: 14893.179688\n",
      "Train Epoch: 35 [45184/225000 (20%)] Loss: 14925.930664\n",
      "Train Epoch: 35 [46592/225000 (21%)] Loss: 14608.422852\n",
      "Train Epoch: 35 [48000/225000 (21%)] Loss: 15088.260742\n",
      "Train Epoch: 35 [49408/225000 (22%)] Loss: 15238.026367\n",
      "Train Epoch: 35 [50816/225000 (23%)] Loss: 15161.304688\n",
      "Train Epoch: 35 [52224/225000 (23%)] Loss: 15049.168945\n",
      "Train Epoch: 35 [53632/225000 (24%)] Loss: 14983.222656\n",
      "Train Epoch: 35 [55040/225000 (24%)] Loss: 14871.051758\n",
      "Train Epoch: 35 [56448/225000 (25%)] Loss: 15333.410156\n",
      "Train Epoch: 35 [57856/225000 (26%)] Loss: 15253.688477\n",
      "Train Epoch: 35 [59264/225000 (26%)] Loss: 14921.638672\n",
      "Train Epoch: 35 [60672/225000 (27%)] Loss: 14957.298828\n",
      "Train Epoch: 35 [62080/225000 (28%)] Loss: 15029.550781\n",
      "Train Epoch: 35 [63488/225000 (28%)] Loss: 14554.336914\n",
      "Train Epoch: 35 [64896/225000 (29%)] Loss: 15260.697266\n",
      "Train Epoch: 35 [66304/225000 (29%)] Loss: 15294.913086\n",
      "Train Epoch: 35 [67712/225000 (30%)] Loss: 15647.057617\n",
      "Train Epoch: 35 [69120/225000 (31%)] Loss: 15240.653320\n",
      "Train Epoch: 35 [70528/225000 (31%)] Loss: 15209.254883\n",
      "Train Epoch: 35 [71936/225000 (32%)] Loss: 14840.357422\n",
      "Train Epoch: 35 [73344/225000 (33%)] Loss: 15191.305664\n",
      "Train Epoch: 35 [74752/225000 (33%)] Loss: 15023.655273\n",
      "Train Epoch: 35 [76160/225000 (34%)] Loss: 14987.295898\n",
      "Train Epoch: 35 [77568/225000 (34%)] Loss: 14531.355469\n",
      "Train Epoch: 35 [78976/225000 (35%)] Loss: 14936.169922\n",
      "Train Epoch: 35 [80384/225000 (36%)] Loss: 14963.035156\n",
      "Train Epoch: 35 [81792/225000 (36%)] Loss: 15529.201172\n",
      "Train Epoch: 35 [83200/225000 (37%)] Loss: 15483.847656\n",
      "Train Epoch: 35 [84608/225000 (38%)] Loss: 15249.757812\n",
      "Train Epoch: 35 [86016/225000 (38%)] Loss: 15154.551758\n",
      "Train Epoch: 35 [87424/225000 (39%)] Loss: 15010.703125\n",
      "Train Epoch: 35 [88832/225000 (39%)] Loss: 15460.206055\n",
      "Train Epoch: 35 [90240/225000 (40%)] Loss: 15326.566406\n",
      "Train Epoch: 35 [91648/225000 (41%)] Loss: 15071.453125\n",
      "Train Epoch: 35 [93056/225000 (41%)] Loss: 14974.695312\n",
      "Train Epoch: 35 [94464/225000 (42%)] Loss: 14996.611328\n",
      "Train Epoch: 35 [95872/225000 (43%)] Loss: 14831.247070\n",
      "Train Epoch: 35 [97280/225000 (43%)] Loss: 15008.077148\n",
      "Train Epoch: 35 [98688/225000 (44%)] Loss: 15088.784180\n",
      "Train Epoch: 35 [100096/225000 (44%)] Loss: 15776.737305\n",
      "Train Epoch: 35 [101504/225000 (45%)] Loss: 15202.331055\n",
      "Train Epoch: 35 [102912/225000 (46%)] Loss: 15051.879883\n",
      "Train Epoch: 35 [104320/225000 (46%)] Loss: 14861.261719\n",
      "Train Epoch: 35 [105728/225000 (47%)] Loss: 15490.977539\n",
      "Train Epoch: 35 [107136/225000 (48%)] Loss: 15023.785156\n",
      "Train Epoch: 35 [108544/225000 (48%)] Loss: 15260.830078\n",
      "Train Epoch: 35 [109952/225000 (49%)] Loss: 15116.535156\n",
      "Train Epoch: 35 [111360/225000 (49%)] Loss: 14919.477539\n",
      "Train Epoch: 35 [112768/225000 (50%)] Loss: 14707.112305\n",
      "Train Epoch: 35 [114176/225000 (51%)] Loss: 15102.180664\n",
      "Train Epoch: 35 [115584/225000 (51%)] Loss: 14900.583984\n",
      "Train Epoch: 35 [116992/225000 (52%)] Loss: 15191.648438\n",
      "Train Epoch: 35 [118400/225000 (53%)] Loss: 15110.713867\n",
      "Train Epoch: 35 [119808/225000 (53%)] Loss: 14425.041016\n",
      "Train Epoch: 35 [121216/225000 (54%)] Loss: 15427.593750\n",
      "Train Epoch: 35 [122624/225000 (54%)] Loss: 15123.208984\n",
      "Train Epoch: 35 [124032/225000 (55%)] Loss: 14720.885742\n",
      "Train Epoch: 35 [125440/225000 (56%)] Loss: 15181.931641\n",
      "Train Epoch: 35 [126848/225000 (56%)] Loss: 15348.954102\n",
      "Train Epoch: 35 [128256/225000 (57%)] Loss: 15226.066406\n",
      "Train Epoch: 35 [129664/225000 (58%)] Loss: 15028.208984\n",
      "Train Epoch: 35 [131072/225000 (58%)] Loss: 15113.120117\n",
      "Train Epoch: 35 [132480/225000 (59%)] Loss: 14901.138672\n",
      "Train Epoch: 35 [133888/225000 (60%)] Loss: 14993.340820\n",
      "Train Epoch: 35 [135296/225000 (60%)] Loss: 14885.785156\n",
      "Train Epoch: 35 [136704/225000 (61%)] Loss: 15188.360352\n",
      "Train Epoch: 35 [138112/225000 (61%)] Loss: 14869.037109\n",
      "Train Epoch: 35 [139520/225000 (62%)] Loss: 15130.554688\n",
      "Train Epoch: 35 [140928/225000 (63%)] Loss: 15097.768555\n",
      "Train Epoch: 35 [142336/225000 (63%)] Loss: 15235.080078\n",
      "Train Epoch: 35 [143744/225000 (64%)] Loss: 15231.247070\n",
      "Train Epoch: 35 [145152/225000 (65%)] Loss: 14902.977539\n",
      "Train Epoch: 35 [146560/225000 (65%)] Loss: 14930.878906\n",
      "Train Epoch: 35 [147968/225000 (66%)] Loss: 14947.828125\n",
      "Train Epoch: 35 [149376/225000 (66%)] Loss: 15223.874023\n",
      "Train Epoch: 35 [150784/225000 (67%)] Loss: 15425.832031\n",
      "Train Epoch: 35 [152192/225000 (68%)] Loss: 14722.739258\n",
      "Train Epoch: 35 [153600/225000 (68%)] Loss: 14879.728516\n",
      "Train Epoch: 35 [155008/225000 (69%)] Loss: 15548.188477\n",
      "Train Epoch: 35 [156416/225000 (70%)] Loss: 15133.306641\n",
      "Train Epoch: 35 [157824/225000 (70%)] Loss: 14895.849609\n",
      "Train Epoch: 35 [159232/225000 (71%)] Loss: 15143.988281\n",
      "Train Epoch: 35 [160640/225000 (71%)] Loss: 14909.365234\n",
      "Train Epoch: 35 [162048/225000 (72%)] Loss: 14820.996094\n",
      "Train Epoch: 35 [163456/225000 (73%)] Loss: 15248.143555\n",
      "Train Epoch: 35 [164864/225000 (73%)] Loss: 15024.202148\n",
      "Train Epoch: 35 [166272/225000 (74%)] Loss: 14925.864258\n",
      "Train Epoch: 35 [167680/225000 (75%)] Loss: 15204.961914\n",
      "Train Epoch: 35 [169088/225000 (75%)] Loss: 14757.389648\n",
      "Train Epoch: 35 [170496/225000 (76%)] Loss: 15115.758789\n",
      "Train Epoch: 35 [171904/225000 (76%)] Loss: 14962.155273\n",
      "Train Epoch: 35 [173312/225000 (77%)] Loss: 15874.749023\n",
      "Train Epoch: 35 [174720/225000 (78%)] Loss: 15034.421875\n",
      "Train Epoch: 35 [176128/225000 (78%)] Loss: 15401.218750\n",
      "Train Epoch: 35 [177536/225000 (79%)] Loss: 16114.983398\n",
      "Train Epoch: 35 [178944/225000 (80%)] Loss: 14712.030273\n",
      "Train Epoch: 35 [180352/225000 (80%)] Loss: 15579.243164\n",
      "Train Epoch: 35 [181760/225000 (81%)] Loss: 15636.782227\n",
      "Train Epoch: 35 [183168/225000 (81%)] Loss: 15167.061523\n",
      "Train Epoch: 35 [184576/225000 (82%)] Loss: 15214.348633\n",
      "Train Epoch: 35 [185984/225000 (83%)] Loss: 15735.388672\n",
      "Train Epoch: 35 [187392/225000 (83%)] Loss: 15349.761719\n",
      "Train Epoch: 35 [188800/225000 (84%)] Loss: 14975.738281\n",
      "Train Epoch: 35 [190208/225000 (85%)] Loss: 15013.812500\n",
      "Train Epoch: 35 [191616/225000 (85%)] Loss: 14952.378906\n",
      "Train Epoch: 35 [193024/225000 (86%)] Loss: 15007.909180\n",
      "Train Epoch: 35 [194432/225000 (86%)] Loss: 14708.360352\n",
      "Train Epoch: 35 [195840/225000 (87%)] Loss: 15116.016602\n",
      "Train Epoch: 35 [197248/225000 (88%)] Loss: 14810.113281\n",
      "Train Epoch: 35 [198656/225000 (88%)] Loss: 14868.392578\n",
      "Train Epoch: 35 [200064/225000 (89%)] Loss: 15077.848633\n",
      "Train Epoch: 35 [201472/225000 (90%)] Loss: 15048.325195\n",
      "Train Epoch: 35 [202880/225000 (90%)] Loss: 14667.832031\n",
      "Train Epoch: 35 [204288/225000 (91%)] Loss: 15150.253906\n",
      "Train Epoch: 35 [205696/225000 (91%)] Loss: 15482.861328\n",
      "Train Epoch: 35 [207104/225000 (92%)] Loss: 15152.011719\n",
      "Train Epoch: 35 [208512/225000 (93%)] Loss: 15014.579102\n",
      "Train Epoch: 35 [209920/225000 (93%)] Loss: 14942.364258\n",
      "Train Epoch: 35 [211328/225000 (94%)] Loss: 15278.320312\n",
      "Train Epoch: 35 [212736/225000 (95%)] Loss: 14512.898438\n",
      "Train Epoch: 35 [214144/225000 (95%)] Loss: 14653.065430\n",
      "Train Epoch: 35 [215552/225000 (96%)] Loss: 14959.514648\n",
      "Train Epoch: 35 [216960/225000 (96%)] Loss: 15202.887695\n",
      "Train Epoch: 35 [218368/225000 (97%)] Loss: 15365.384766\n",
      "Train Epoch: 35 [219776/225000 (98%)] Loss: 15480.712891\n",
      "Train Epoch: 35 [221184/225000 (98%)] Loss: 15382.669922\n",
      "Train Epoch: 35 [222592/225000 (99%)] Loss: 15099.791016\n",
      "Train Epoch: 35 [224000/225000 (100%)] Loss: 15706.780273\n",
      "    epoch          : 35\n",
      "    loss           : 15081.86978055674\n",
      "    val_loss       : 15061.859455451522\n",
      "Train Epoch: 36 [128/225000 (0%)] Loss: 14705.571289\n",
      "Train Epoch: 36 [1536/225000 (1%)] Loss: 15128.869141\n",
      "Train Epoch: 36 [2944/225000 (1%)] Loss: 14576.254883\n",
      "Train Epoch: 36 [4352/225000 (2%)] Loss: 14928.677734\n",
      "Train Epoch: 36 [5760/225000 (3%)] Loss: 14735.401367\n",
      "Train Epoch: 36 [7168/225000 (3%)] Loss: 14889.575195\n",
      "Train Epoch: 36 [8576/225000 (4%)] Loss: 14926.831055\n",
      "Train Epoch: 36 [9984/225000 (4%)] Loss: 14906.133789\n",
      "Train Epoch: 36 [11392/225000 (5%)] Loss: 15197.748047\n",
      "Train Epoch: 36 [12800/225000 (6%)] Loss: 15219.531250\n",
      "Train Epoch: 36 [14208/225000 (6%)] Loss: 15308.794922\n",
      "Train Epoch: 36 [15616/225000 (7%)] Loss: 15511.551758\n",
      "Train Epoch: 36 [17024/225000 (8%)] Loss: 14862.033203\n",
      "Train Epoch: 36 [18432/225000 (8%)] Loss: 15249.502930\n",
      "Train Epoch: 36 [19840/225000 (9%)] Loss: 15124.685547\n",
      "Train Epoch: 36 [21248/225000 (9%)] Loss: 15340.753906\n",
      "Train Epoch: 36 [22656/225000 (10%)] Loss: 15020.599609\n",
      "Train Epoch: 36 [24064/225000 (11%)] Loss: 15213.595703\n",
      "Train Epoch: 36 [25472/225000 (11%)] Loss: 14776.634766\n",
      "Train Epoch: 36 [26880/225000 (12%)] Loss: 15278.708984\n",
      "Train Epoch: 36 [28288/225000 (13%)] Loss: 15386.902344\n",
      "Train Epoch: 36 [29696/225000 (13%)] Loss: 15019.401367\n",
      "Train Epoch: 36 [31104/225000 (14%)] Loss: 15364.295898\n",
      "Train Epoch: 36 [32512/225000 (14%)] Loss: 14714.351562\n",
      "Train Epoch: 36 [33920/225000 (15%)] Loss: 15028.209961\n",
      "Train Epoch: 36 [35328/225000 (16%)] Loss: 15506.818359\n",
      "Train Epoch: 36 [36736/225000 (16%)] Loss: 15046.782227\n",
      "Train Epoch: 36 [38144/225000 (17%)] Loss: 14789.884766\n",
      "Train Epoch: 36 [39552/225000 (18%)] Loss: 15193.604492\n",
      "Train Epoch: 36 [40960/225000 (18%)] Loss: 14985.708984\n",
      "Train Epoch: 36 [42368/225000 (19%)] Loss: 14765.473633\n",
      "Train Epoch: 36 [43776/225000 (19%)] Loss: 15265.941406\n",
      "Train Epoch: 36 [45184/225000 (20%)] Loss: 14642.501953\n",
      "Train Epoch: 36 [46592/225000 (21%)] Loss: 14954.311523\n",
      "Train Epoch: 36 [48000/225000 (21%)] Loss: 15639.829102\n",
      "Train Epoch: 36 [49408/225000 (22%)] Loss: 15361.003906\n",
      "Train Epoch: 36 [50816/225000 (23%)] Loss: 14967.453125\n",
      "Train Epoch: 36 [52224/225000 (23%)] Loss: 15277.301758\n",
      "Train Epoch: 36 [53632/225000 (24%)] Loss: 14963.696289\n",
      "Train Epoch: 36 [55040/225000 (24%)] Loss: 15080.991211\n",
      "Train Epoch: 36 [56448/225000 (25%)] Loss: 14894.741211\n",
      "Train Epoch: 36 [57856/225000 (26%)] Loss: 15472.754883\n",
      "Train Epoch: 36 [59264/225000 (26%)] Loss: 15142.267578\n",
      "Train Epoch: 36 [60672/225000 (27%)] Loss: 15301.083984\n",
      "Train Epoch: 36 [62080/225000 (28%)] Loss: 14930.976562\n",
      "Train Epoch: 36 [63488/225000 (28%)] Loss: 15268.125977\n",
      "Train Epoch: 36 [64896/225000 (29%)] Loss: 15239.832031\n",
      "Train Epoch: 36 [66304/225000 (29%)] Loss: 15492.352539\n",
      "Train Epoch: 36 [67712/225000 (30%)] Loss: 15151.376953\n",
      "Train Epoch: 36 [69120/225000 (31%)] Loss: 14980.936523\n",
      "Train Epoch: 36 [70528/225000 (31%)] Loss: 14989.055664\n",
      "Train Epoch: 36 [71936/225000 (32%)] Loss: 15054.420898\n",
      "Train Epoch: 36 [73344/225000 (33%)] Loss: 15127.251953\n",
      "Train Epoch: 36 [74752/225000 (33%)] Loss: 15014.486328\n",
      "Train Epoch: 36 [76160/225000 (34%)] Loss: 14757.484375\n",
      "Train Epoch: 36 [77568/225000 (34%)] Loss: 15247.532227\n",
      "Train Epoch: 36 [78976/225000 (35%)] Loss: 15051.647461\n",
      "Train Epoch: 36 [80384/225000 (36%)] Loss: 15247.024414\n",
      "Train Epoch: 36 [81792/225000 (36%)] Loss: 14843.348633\n",
      "Train Epoch: 36 [83200/225000 (37%)] Loss: 15122.646484\n",
      "Train Epoch: 36 [84608/225000 (38%)] Loss: 15284.296875\n",
      "Train Epoch: 36 [86016/225000 (38%)] Loss: 14883.725586\n",
      "Train Epoch: 36 [87424/225000 (39%)] Loss: 15291.859375\n",
      "Train Epoch: 36 [88832/225000 (39%)] Loss: 14971.375000\n",
      "Train Epoch: 36 [90240/225000 (40%)] Loss: 14794.658203\n",
      "Train Epoch: 36 [91648/225000 (41%)] Loss: 15090.009766\n",
      "Train Epoch: 36 [93056/225000 (41%)] Loss: 14805.096680\n",
      "Train Epoch: 36 [94464/225000 (42%)] Loss: 15230.003906\n",
      "Train Epoch: 36 [95872/225000 (43%)] Loss: 14948.467773\n",
      "Train Epoch: 36 [97280/225000 (43%)] Loss: 14897.984375\n",
      "Train Epoch: 36 [98688/225000 (44%)] Loss: 15106.509766\n",
      "Train Epoch: 36 [100096/225000 (44%)] Loss: 15119.246094\n",
      "Train Epoch: 36 [101504/225000 (45%)] Loss: 14941.521484\n",
      "Train Epoch: 36 [102912/225000 (46%)] Loss: 14756.235352\n",
      "Train Epoch: 36 [104320/225000 (46%)] Loss: 15118.308594\n",
      "Train Epoch: 36 [105728/225000 (47%)] Loss: 15183.790039\n",
      "Train Epoch: 36 [107136/225000 (48%)] Loss: 15100.479492\n",
      "Train Epoch: 36 [108544/225000 (48%)] Loss: 15435.772461\n",
      "Train Epoch: 36 [109952/225000 (49%)] Loss: 15037.517578\n",
      "Train Epoch: 36 [111360/225000 (49%)] Loss: 15470.293945\n",
      "Train Epoch: 36 [112768/225000 (50%)] Loss: 15340.711914\n",
      "Train Epoch: 36 [114176/225000 (51%)] Loss: 15121.983398\n",
      "Train Epoch: 36 [115584/225000 (51%)] Loss: 14934.865234\n",
      "Train Epoch: 36 [116992/225000 (52%)] Loss: 15170.488281\n",
      "Train Epoch: 36 [118400/225000 (53%)] Loss: 15284.462891\n",
      "Train Epoch: 36 [119808/225000 (53%)] Loss: 15256.920898\n",
      "Train Epoch: 36 [121216/225000 (54%)] Loss: 14739.880859\n",
      "Train Epoch: 36 [122624/225000 (54%)] Loss: 15295.254883\n",
      "Train Epoch: 36 [124032/225000 (55%)] Loss: 15137.146484\n",
      "Train Epoch: 36 [125440/225000 (56%)] Loss: 15054.271484\n",
      "Train Epoch: 36 [126848/225000 (56%)] Loss: 15312.913086\n",
      "Train Epoch: 36 [128256/225000 (57%)] Loss: 15186.466797\n",
      "Train Epoch: 36 [129664/225000 (58%)] Loss: 14699.607422\n",
      "Train Epoch: 36 [131072/225000 (58%)] Loss: 14564.194336\n",
      "Train Epoch: 36 [132480/225000 (59%)] Loss: 15392.283203\n",
      "Train Epoch: 36 [133888/225000 (60%)] Loss: 14473.628906\n",
      "Train Epoch: 36 [135296/225000 (60%)] Loss: 14906.170898\n",
      "Train Epoch: 36 [136704/225000 (61%)] Loss: 14875.258789\n",
      "Train Epoch: 36 [138112/225000 (61%)] Loss: 15584.560547\n",
      "Train Epoch: 36 [139520/225000 (62%)] Loss: 15107.484375\n",
      "Train Epoch: 36 [140928/225000 (63%)] Loss: 15212.449219\n",
      "Train Epoch: 36 [142336/225000 (63%)] Loss: 15452.777344\n",
      "Train Epoch: 36 [143744/225000 (64%)] Loss: 15456.629883\n",
      "Train Epoch: 36 [145152/225000 (65%)] Loss: 14865.776367\n",
      "Train Epoch: 36 [146560/225000 (65%)] Loss: 15377.739258\n",
      "Train Epoch: 36 [147968/225000 (66%)] Loss: 15113.453125\n",
      "Train Epoch: 36 [149376/225000 (66%)] Loss: 14779.140625\n",
      "Train Epoch: 36 [150784/225000 (67%)] Loss: 14795.923828\n",
      "Train Epoch: 36 [152192/225000 (68%)] Loss: 15123.473633\n",
      "Train Epoch: 36 [153600/225000 (68%)] Loss: 15323.172852\n",
      "Train Epoch: 36 [155008/225000 (69%)] Loss: 15021.205078\n",
      "Train Epoch: 36 [156416/225000 (70%)] Loss: 14916.880859\n",
      "Train Epoch: 36 [157824/225000 (70%)] Loss: 15030.375000\n",
      "Train Epoch: 36 [159232/225000 (71%)] Loss: 14943.442383\n",
      "Train Epoch: 36 [160640/225000 (71%)] Loss: 15095.513672\n",
      "Train Epoch: 36 [162048/225000 (72%)] Loss: 14851.700195\n",
      "Train Epoch: 36 [163456/225000 (73%)] Loss: 15071.550781\n",
      "Train Epoch: 36 [164864/225000 (73%)] Loss: 15255.880859\n",
      "Train Epoch: 36 [166272/225000 (74%)] Loss: 15492.632812\n",
      "Train Epoch: 36 [167680/225000 (75%)] Loss: 15136.102539\n",
      "Train Epoch: 36 [169088/225000 (75%)] Loss: 14797.160156\n",
      "Train Epoch: 36 [170496/225000 (76%)] Loss: 14652.968750\n",
      "Train Epoch: 36 [171904/225000 (76%)] Loss: 14781.946289\n",
      "Train Epoch: 36 [173312/225000 (77%)] Loss: 15021.098633\n",
      "Train Epoch: 36 [174720/225000 (78%)] Loss: 15175.788086\n",
      "Train Epoch: 36 [176128/225000 (78%)] Loss: 14917.717773\n",
      "Train Epoch: 36 [177536/225000 (79%)] Loss: 14938.631836\n",
      "Train Epoch: 36 [178944/225000 (80%)] Loss: 14726.109375\n",
      "Train Epoch: 36 [180352/225000 (80%)] Loss: 14832.703125\n",
      "Train Epoch: 36 [181760/225000 (81%)] Loss: 15372.157227\n",
      "Train Epoch: 36 [183168/225000 (81%)] Loss: 14817.377930\n",
      "Train Epoch: 36 [184576/225000 (82%)] Loss: 15022.631836\n",
      "Train Epoch: 36 [185984/225000 (83%)] Loss: 14959.301758\n",
      "Train Epoch: 36 [187392/225000 (83%)] Loss: 14713.943359\n",
      "Train Epoch: 36 [188800/225000 (84%)] Loss: 15590.575195\n",
      "Train Epoch: 36 [190208/225000 (85%)] Loss: 15378.577148\n",
      "Train Epoch: 36 [191616/225000 (85%)] Loss: 15365.409180\n",
      "Train Epoch: 36 [193024/225000 (86%)] Loss: 14994.455078\n",
      "Train Epoch: 36 [194432/225000 (86%)] Loss: 14708.593750\n",
      "Train Epoch: 36 [195840/225000 (87%)] Loss: 15417.318359\n",
      "Train Epoch: 36 [197248/225000 (88%)] Loss: 15333.220703\n",
      "Train Epoch: 36 [198656/225000 (88%)] Loss: 15381.271484\n",
      "Train Epoch: 36 [200064/225000 (89%)] Loss: 15527.029297\n",
      "Train Epoch: 36 [201472/225000 (90%)] Loss: 15334.060547\n",
      "Train Epoch: 36 [202880/225000 (90%)] Loss: 15312.485352\n",
      "Train Epoch: 36 [204288/225000 (91%)] Loss: 15040.473633\n",
      "Train Epoch: 36 [205696/225000 (91%)] Loss: 15046.209961\n",
      "Train Epoch: 36 [207104/225000 (92%)] Loss: 15032.788086\n",
      "Train Epoch: 36 [208512/225000 (93%)] Loss: 15133.024414\n",
      "Train Epoch: 36 [209920/225000 (93%)] Loss: 14932.875000\n",
      "Train Epoch: 36 [211328/225000 (94%)] Loss: 15564.309570\n",
      "Train Epoch: 36 [212736/225000 (95%)] Loss: 15169.788086\n",
      "Train Epoch: 36 [214144/225000 (95%)] Loss: 15606.657227\n",
      "Train Epoch: 36 [215552/225000 (96%)] Loss: 15341.690430\n",
      "Train Epoch: 36 [216960/225000 (96%)] Loss: 15090.656250\n",
      "Train Epoch: 36 [218368/225000 (97%)] Loss: 15126.416016\n",
      "Train Epoch: 36 [219776/225000 (98%)] Loss: 14709.962891\n",
      "Train Epoch: 36 [221184/225000 (98%)] Loss: 15241.487305\n",
      "Train Epoch: 36 [222592/225000 (99%)] Loss: 14721.506836\n",
      "Train Epoch: 36 [224000/225000 (100%)] Loss: 15119.479492\n",
      "    epoch          : 36\n",
      "    loss           : 15079.44754670613\n",
      "    val_loss       : 15099.350518297784\n",
      "Train Epoch: 37 [128/225000 (0%)] Loss: 15194.036133\n",
      "Train Epoch: 37 [1536/225000 (1%)] Loss: 15135.154297\n",
      "Train Epoch: 37 [2944/225000 (1%)] Loss: 14896.216797\n",
      "Train Epoch: 37 [4352/225000 (2%)] Loss: 14871.875977\n",
      "Train Epoch: 37 [5760/225000 (3%)] Loss: 15428.768555\n",
      "Train Epoch: 37 [7168/225000 (3%)] Loss: 15066.114258\n",
      "Train Epoch: 37 [8576/225000 (4%)] Loss: 15345.374023\n",
      "Train Epoch: 37 [9984/225000 (4%)] Loss: 14814.515625\n",
      "Train Epoch: 37 [11392/225000 (5%)] Loss: 14814.618164\n",
      "Train Epoch: 37 [12800/225000 (6%)] Loss: 15352.220703\n",
      "Train Epoch: 37 [14208/225000 (6%)] Loss: 15063.420898\n",
      "Train Epoch: 37 [15616/225000 (7%)] Loss: 15401.520508\n",
      "Train Epoch: 37 [17024/225000 (8%)] Loss: 14965.548828\n",
      "Train Epoch: 37 [18432/225000 (8%)] Loss: 15430.871094\n",
      "Train Epoch: 37 [19840/225000 (9%)] Loss: 14818.117188\n",
      "Train Epoch: 37 [21248/225000 (9%)] Loss: 14976.256836\n",
      "Train Epoch: 37 [22656/225000 (10%)] Loss: 15544.414062\n",
      "Train Epoch: 37 [24064/225000 (11%)] Loss: 15129.636719\n",
      "Train Epoch: 37 [25472/225000 (11%)] Loss: 14969.525391\n",
      "Train Epoch: 37 [26880/225000 (12%)] Loss: 14940.697266\n",
      "Train Epoch: 37 [28288/225000 (13%)] Loss: 15070.672852\n",
      "Train Epoch: 37 [29696/225000 (13%)] Loss: 14936.704102\n",
      "Train Epoch: 37 [31104/225000 (14%)] Loss: 14917.780273\n",
      "Train Epoch: 37 [32512/225000 (14%)] Loss: 15920.717773\n",
      "Train Epoch: 37 [33920/225000 (15%)] Loss: 15221.666992\n",
      "Train Epoch: 37 [35328/225000 (16%)] Loss: 14920.057617\n",
      "Train Epoch: 37 [36736/225000 (16%)] Loss: 15093.340820\n",
      "Train Epoch: 37 [38144/225000 (17%)] Loss: 14846.453125\n",
      "Train Epoch: 37 [39552/225000 (18%)] Loss: 15070.599609\n",
      "Train Epoch: 37 [40960/225000 (18%)] Loss: 14747.164062\n",
      "Train Epoch: 37 [42368/225000 (19%)] Loss: 15145.055664\n",
      "Train Epoch: 37 [43776/225000 (19%)] Loss: 15501.459961\n",
      "Train Epoch: 37 [45184/225000 (20%)] Loss: 15198.420898\n",
      "Train Epoch: 37 [46592/225000 (21%)] Loss: 14921.065430\n",
      "Train Epoch: 37 [48000/225000 (21%)] Loss: 14738.713867\n",
      "Train Epoch: 37 [49408/225000 (22%)] Loss: 15154.135742\n",
      "Train Epoch: 37 [50816/225000 (23%)] Loss: 15131.143555\n",
      "Train Epoch: 37 [52224/225000 (23%)] Loss: 15926.567383\n",
      "Train Epoch: 37 [53632/225000 (24%)] Loss: 15052.491211\n",
      "Train Epoch: 37 [55040/225000 (24%)] Loss: 14680.666992\n",
      "Train Epoch: 37 [56448/225000 (25%)] Loss: 14993.850586\n",
      "Train Epoch: 37 [57856/225000 (26%)] Loss: 14891.545898\n",
      "Train Epoch: 37 [59264/225000 (26%)] Loss: 15159.560547\n",
      "Train Epoch: 37 [60672/225000 (27%)] Loss: 15358.526367\n",
      "Train Epoch: 37 [62080/225000 (28%)] Loss: 15014.299805\n",
      "Train Epoch: 37 [63488/225000 (28%)] Loss: 14792.783203\n",
      "Train Epoch: 37 [64896/225000 (29%)] Loss: 15105.068359\n",
      "Train Epoch: 37 [66304/225000 (29%)] Loss: 15185.605469\n",
      "Train Epoch: 37 [67712/225000 (30%)] Loss: 14870.845703\n",
      "Train Epoch: 37 [69120/225000 (31%)] Loss: 14929.249023\n",
      "Train Epoch: 37 [70528/225000 (31%)] Loss: 14809.714844\n",
      "Train Epoch: 37 [71936/225000 (32%)] Loss: 15100.520508\n",
      "Train Epoch: 37 [73344/225000 (33%)] Loss: 14907.960938\n",
      "Train Epoch: 37 [74752/225000 (33%)] Loss: 15271.615234\n",
      "Train Epoch: 37 [76160/225000 (34%)] Loss: 14979.566406\n",
      "Train Epoch: 37 [77568/225000 (34%)] Loss: 15623.515625\n",
      "Train Epoch: 37 [78976/225000 (35%)] Loss: 15722.355469\n",
      "Train Epoch: 37 [80384/225000 (36%)] Loss: 14755.149414\n",
      "Train Epoch: 37 [81792/225000 (36%)] Loss: 14930.780273\n",
      "Train Epoch: 37 [83200/225000 (37%)] Loss: 15729.403320\n",
      "Train Epoch: 37 [84608/225000 (38%)] Loss: 15515.451172\n",
      "Train Epoch: 37 [86016/225000 (38%)] Loss: 15190.342773\n",
      "Train Epoch: 37 [87424/225000 (39%)] Loss: 14989.241211\n",
      "Train Epoch: 37 [88832/225000 (39%)] Loss: 15329.392578\n",
      "Train Epoch: 37 [90240/225000 (40%)] Loss: 15466.930664\n",
      "Train Epoch: 37 [91648/225000 (41%)] Loss: 15383.938477\n",
      "Train Epoch: 37 [93056/225000 (41%)] Loss: 15240.817383\n",
      "Train Epoch: 37 [94464/225000 (42%)] Loss: 15103.857422\n",
      "Train Epoch: 37 [95872/225000 (43%)] Loss: 14405.017578\n",
      "Train Epoch: 37 [97280/225000 (43%)] Loss: 14700.076172\n",
      "Train Epoch: 37 [98688/225000 (44%)] Loss: 14920.520508\n",
      "Train Epoch: 37 [100096/225000 (44%)] Loss: 14840.041016\n",
      "Train Epoch: 37 [101504/225000 (45%)] Loss: 14819.195312\n",
      "Train Epoch: 37 [102912/225000 (46%)] Loss: 14642.165039\n",
      "Train Epoch: 37 [104320/225000 (46%)] Loss: 15319.525391\n",
      "Train Epoch: 37 [105728/225000 (47%)] Loss: 15096.344727\n",
      "Train Epoch: 37 [107136/225000 (48%)] Loss: 15480.712891\n",
      "Train Epoch: 37 [108544/225000 (48%)] Loss: 15417.037109\n",
      "Train Epoch: 37 [109952/225000 (49%)] Loss: 14811.801758\n",
      "Train Epoch: 37 [111360/225000 (49%)] Loss: 14775.305664\n",
      "Train Epoch: 37 [112768/225000 (50%)] Loss: 14626.500000\n",
      "Train Epoch: 37 [114176/225000 (51%)] Loss: 14621.375000\n",
      "Train Epoch: 37 [115584/225000 (51%)] Loss: 14799.047852\n",
      "Train Epoch: 37 [116992/225000 (52%)] Loss: 15480.847656\n",
      "Train Epoch: 37 [118400/225000 (53%)] Loss: 15009.777344\n",
      "Train Epoch: 37 [119808/225000 (53%)] Loss: 15645.272461\n",
      "Train Epoch: 37 [121216/225000 (54%)] Loss: 15004.847656\n",
      "Train Epoch: 37 [122624/225000 (54%)] Loss: 15292.419922\n",
      "Train Epoch: 37 [124032/225000 (55%)] Loss: 14959.495117\n",
      "Train Epoch: 37 [125440/225000 (56%)] Loss: 14919.634766\n",
      "Train Epoch: 37 [126848/225000 (56%)] Loss: 14992.669922\n",
      "Train Epoch: 37 [128256/225000 (57%)] Loss: 14889.756836\n",
      "Train Epoch: 37 [129664/225000 (58%)] Loss: 15093.602539\n",
      "Train Epoch: 37 [131072/225000 (58%)] Loss: 14869.000000\n",
      "Train Epoch: 37 [132480/225000 (59%)] Loss: 15050.020508\n",
      "Train Epoch: 37 [133888/225000 (60%)] Loss: 15212.886719\n",
      "Train Epoch: 37 [135296/225000 (60%)] Loss: 15347.628906\n",
      "Train Epoch: 37 [136704/225000 (61%)] Loss: 15073.401367\n",
      "Train Epoch: 37 [138112/225000 (61%)] Loss: 14527.763672\n",
      "Train Epoch: 37 [139520/225000 (62%)] Loss: 14286.369141\n",
      "Train Epoch: 37 [140928/225000 (63%)] Loss: 14779.718750\n",
      "Train Epoch: 37 [142336/225000 (63%)] Loss: 14911.057617\n",
      "Train Epoch: 37 [143744/225000 (64%)] Loss: 15556.712891\n",
      "Train Epoch: 37 [145152/225000 (65%)] Loss: 15169.480469\n",
      "Train Epoch: 37 [146560/225000 (65%)] Loss: 14995.485352\n",
      "Train Epoch: 37 [147968/225000 (66%)] Loss: 15049.836914\n",
      "Train Epoch: 37 [149376/225000 (66%)] Loss: 14903.230469\n",
      "Train Epoch: 37 [150784/225000 (67%)] Loss: 15016.740234\n",
      "Train Epoch: 37 [152192/225000 (68%)] Loss: 15048.595703\n",
      "Train Epoch: 37 [153600/225000 (68%)] Loss: 15602.849609\n",
      "Train Epoch: 37 [155008/225000 (69%)] Loss: 15125.955078\n",
      "Train Epoch: 37 [156416/225000 (70%)] Loss: 14934.543945\n",
      "Train Epoch: 37 [157824/225000 (70%)] Loss: 15399.202148\n",
      "Train Epoch: 37 [159232/225000 (71%)] Loss: 14901.634766\n",
      "Train Epoch: 37 [160640/225000 (71%)] Loss: 15166.439453\n",
      "Train Epoch: 37 [162048/225000 (72%)] Loss: 15019.229492\n",
      "Train Epoch: 37 [163456/225000 (73%)] Loss: 14676.213867\n",
      "Train Epoch: 37 [164864/225000 (73%)] Loss: 15154.418945\n",
      "Train Epoch: 37 [166272/225000 (74%)] Loss: 15264.662109\n",
      "Train Epoch: 37 [167680/225000 (75%)] Loss: 14646.000977\n",
      "Train Epoch: 37 [169088/225000 (75%)] Loss: 15184.756836\n",
      "Train Epoch: 37 [170496/225000 (76%)] Loss: 15026.919922\n",
      "Train Epoch: 37 [171904/225000 (76%)] Loss: 15173.005859\n",
      "Train Epoch: 37 [173312/225000 (77%)] Loss: 15763.608398\n",
      "Train Epoch: 37 [174720/225000 (78%)] Loss: 14983.172852\n",
      "Train Epoch: 37 [176128/225000 (78%)] Loss: 15102.936523\n",
      "Train Epoch: 37 [177536/225000 (79%)] Loss: 14706.819336\n",
      "Train Epoch: 37 [178944/225000 (80%)] Loss: 14932.042969\n",
      "Train Epoch: 37 [180352/225000 (80%)] Loss: 14880.048828\n",
      "Train Epoch: 37 [181760/225000 (81%)] Loss: 14845.281250\n",
      "Train Epoch: 37 [183168/225000 (81%)] Loss: 15375.067383\n",
      "Train Epoch: 37 [184576/225000 (82%)] Loss: 15068.195312\n",
      "Train Epoch: 37 [185984/225000 (83%)] Loss: 15064.212891\n",
      "Train Epoch: 37 [187392/225000 (83%)] Loss: 14866.017578\n",
      "Train Epoch: 37 [188800/225000 (84%)] Loss: 14683.423828\n",
      "Train Epoch: 37 [190208/225000 (85%)] Loss: 14731.411133\n",
      "Train Epoch: 37 [191616/225000 (85%)] Loss: 14982.347656\n",
      "Train Epoch: 37 [193024/225000 (86%)] Loss: 15060.015625\n",
      "Train Epoch: 37 [194432/225000 (86%)] Loss: 14949.660156\n",
      "Train Epoch: 37 [195840/225000 (87%)] Loss: 14644.530273\n",
      "Train Epoch: 37 [197248/225000 (88%)] Loss: 14642.514648\n",
      "Train Epoch: 37 [198656/225000 (88%)] Loss: 14909.664062\n",
      "Train Epoch: 37 [200064/225000 (89%)] Loss: 15205.244141\n",
      "Train Epoch: 37 [201472/225000 (90%)] Loss: 15498.750000\n",
      "Train Epoch: 37 [202880/225000 (90%)] Loss: 14809.863281\n",
      "Train Epoch: 37 [204288/225000 (91%)] Loss: 14869.068359\n",
      "Train Epoch: 37 [205696/225000 (91%)] Loss: 15119.258789\n",
      "Train Epoch: 37 [207104/225000 (92%)] Loss: 15482.020508\n",
      "Train Epoch: 37 [208512/225000 (93%)] Loss: 15147.767578\n",
      "Train Epoch: 37 [209920/225000 (93%)] Loss: 15096.875977\n",
      "Train Epoch: 37 [211328/225000 (94%)] Loss: 14608.412109\n",
      "Train Epoch: 37 [212736/225000 (95%)] Loss: 15101.591797\n",
      "Train Epoch: 37 [214144/225000 (95%)] Loss: 15275.812500\n",
      "Train Epoch: 37 [215552/225000 (96%)] Loss: 14705.867188\n",
      "Train Epoch: 37 [216960/225000 (96%)] Loss: 14976.752930\n",
      "Train Epoch: 37 [218368/225000 (97%)] Loss: 14959.793945\n",
      "Train Epoch: 37 [219776/225000 (98%)] Loss: 15144.770508\n",
      "Train Epoch: 37 [221184/225000 (98%)] Loss: 14993.843750\n",
      "Train Epoch: 37 [222592/225000 (99%)] Loss: 15155.490234\n",
      "Train Epoch: 37 [224000/225000 (100%)] Loss: 15131.556641\n",
      "    epoch          : 37\n",
      "    loss           : 15080.21744125071\n",
      "    val_loss       : 15059.534440765423\n",
      "Train Epoch: 38 [128/225000 (0%)] Loss: 14570.302734\n",
      "Train Epoch: 38 [1536/225000 (1%)] Loss: 15016.233398\n",
      "Train Epoch: 38 [2944/225000 (1%)] Loss: 14948.064453\n",
      "Train Epoch: 38 [4352/225000 (2%)] Loss: 14754.273438\n",
      "Train Epoch: 38 [5760/225000 (3%)] Loss: 14844.229492\n",
      "Train Epoch: 38 [7168/225000 (3%)] Loss: 14948.180664\n",
      "Train Epoch: 38 [8576/225000 (4%)] Loss: 15109.327148\n",
      "Train Epoch: 38 [9984/225000 (4%)] Loss: 14990.799805\n",
      "Train Epoch: 38 [11392/225000 (5%)] Loss: 14985.429688\n",
      "Train Epoch: 38 [12800/225000 (6%)] Loss: 15240.818359\n",
      "Train Epoch: 38 [14208/225000 (6%)] Loss: 15360.836914\n",
      "Train Epoch: 38 [15616/225000 (7%)] Loss: 14695.425781\n",
      "Train Epoch: 38 [17024/225000 (8%)] Loss: 15200.747070\n",
      "Train Epoch: 38 [18432/225000 (8%)] Loss: 15460.482422\n",
      "Train Epoch: 38 [19840/225000 (9%)] Loss: 15273.252930\n",
      "Train Epoch: 38 [21248/225000 (9%)] Loss: 15021.359375\n",
      "Train Epoch: 38 [22656/225000 (10%)] Loss: 14568.028320\n",
      "Train Epoch: 38 [24064/225000 (11%)] Loss: 15177.846680\n",
      "Train Epoch: 38 [25472/225000 (11%)] Loss: 15074.507812\n",
      "Train Epoch: 38 [26880/225000 (12%)] Loss: 15249.447266\n",
      "Train Epoch: 38 [28288/225000 (13%)] Loss: 15610.929688\n",
      "Train Epoch: 38 [29696/225000 (13%)] Loss: 14992.831055\n",
      "Train Epoch: 38 [31104/225000 (14%)] Loss: 14843.729492\n",
      "Train Epoch: 38 [32512/225000 (14%)] Loss: 14936.906250\n",
      "Train Epoch: 38 [33920/225000 (15%)] Loss: 15028.457031\n",
      "Train Epoch: 38 [35328/225000 (16%)] Loss: 15421.617188\n",
      "Train Epoch: 38 [36736/225000 (16%)] Loss: 14976.792969\n",
      "Train Epoch: 38 [38144/225000 (17%)] Loss: 15204.816406\n",
      "Train Epoch: 38 [39552/225000 (18%)] Loss: 14870.007812\n",
      "Train Epoch: 38 [40960/225000 (18%)] Loss: 14803.173828\n",
      "Train Epoch: 38 [42368/225000 (19%)] Loss: 14852.010742\n",
      "Train Epoch: 38 [43776/225000 (19%)] Loss: 15161.003906\n",
      "Train Epoch: 38 [45184/225000 (20%)] Loss: 15253.661133\n",
      "Train Epoch: 38 [46592/225000 (21%)] Loss: 15249.317383\n",
      "Train Epoch: 38 [48000/225000 (21%)] Loss: 14952.131836\n",
      "Train Epoch: 38 [49408/225000 (22%)] Loss: 15479.668945\n",
      "Train Epoch: 38 [50816/225000 (23%)] Loss: 15534.826172\n",
      "Train Epoch: 38 [52224/225000 (23%)] Loss: 15384.987305\n",
      "Train Epoch: 38 [53632/225000 (24%)] Loss: 14894.214844\n",
      "Train Epoch: 38 [55040/225000 (24%)] Loss: 15019.158203\n",
      "Train Epoch: 38 [56448/225000 (25%)] Loss: 15146.656250\n",
      "Train Epoch: 38 [57856/225000 (26%)] Loss: 15085.485352\n",
      "Train Epoch: 38 [59264/225000 (26%)] Loss: 15026.670898\n",
      "Train Epoch: 38 [60672/225000 (27%)] Loss: 14921.322266\n",
      "Train Epoch: 38 [62080/225000 (28%)] Loss: 15038.362305\n",
      "Train Epoch: 38 [63488/225000 (28%)] Loss: 15121.900391\n",
      "Train Epoch: 38 [64896/225000 (29%)] Loss: 14862.977539\n",
      "Train Epoch: 38 [66304/225000 (29%)] Loss: 15660.408203\n",
      "Train Epoch: 38 [67712/225000 (30%)] Loss: 15181.558594\n",
      "Train Epoch: 38 [69120/225000 (31%)] Loss: 15095.372070\n",
      "Train Epoch: 38 [70528/225000 (31%)] Loss: 15314.831055\n",
      "Train Epoch: 38 [71936/225000 (32%)] Loss: 15016.120117\n",
      "Train Epoch: 38 [73344/225000 (33%)] Loss: 14592.000977\n",
      "Train Epoch: 38 [74752/225000 (33%)] Loss: 14889.363281\n",
      "Train Epoch: 38 [76160/225000 (34%)] Loss: 14846.155273\n",
      "Train Epoch: 38 [77568/225000 (34%)] Loss: 14550.446289\n",
      "Train Epoch: 38 [78976/225000 (35%)] Loss: 14865.704102\n",
      "Train Epoch: 38 [80384/225000 (36%)] Loss: 15058.880859\n",
      "Train Epoch: 38 [81792/225000 (36%)] Loss: 15254.875977\n",
      "Train Epoch: 38 [83200/225000 (37%)] Loss: 14833.900391\n",
      "Train Epoch: 38 [84608/225000 (38%)] Loss: 14517.182617\n",
      "Train Epoch: 38 [86016/225000 (38%)] Loss: 14950.107422\n",
      "Train Epoch: 38 [87424/225000 (39%)] Loss: 14917.677734\n",
      "Train Epoch: 38 [88832/225000 (39%)] Loss: 15158.086914\n",
      "Train Epoch: 38 [90240/225000 (40%)] Loss: 14908.855469\n",
      "Train Epoch: 38 [91648/225000 (41%)] Loss: 15144.564453\n",
      "Train Epoch: 38 [93056/225000 (41%)] Loss: 14681.508789\n",
      "Train Epoch: 38 [94464/225000 (42%)] Loss: 15053.338867\n",
      "Train Epoch: 38 [95872/225000 (43%)] Loss: 15011.549805\n",
      "Train Epoch: 38 [97280/225000 (43%)] Loss: 14627.550781\n",
      "Train Epoch: 38 [98688/225000 (44%)] Loss: 15468.122070\n",
      "Train Epoch: 38 [100096/225000 (44%)] Loss: 14509.737305\n",
      "Train Epoch: 38 [101504/225000 (45%)] Loss: 15375.452148\n",
      "Train Epoch: 38 [102912/225000 (46%)] Loss: 14707.951172\n",
      "Train Epoch: 38 [104320/225000 (46%)] Loss: 15182.029297\n",
      "Train Epoch: 38 [105728/225000 (47%)] Loss: 15509.749023\n",
      "Train Epoch: 38 [107136/225000 (48%)] Loss: 14964.234375\n",
      "Train Epoch: 38 [108544/225000 (48%)] Loss: 14849.027344\n",
      "Train Epoch: 38 [109952/225000 (49%)] Loss: 14986.417969\n",
      "Train Epoch: 38 [111360/225000 (49%)] Loss: 15339.530273\n",
      "Train Epoch: 38 [112768/225000 (50%)] Loss: 15078.114258\n",
      "Train Epoch: 38 [114176/225000 (51%)] Loss: 14793.125000\n",
      "Train Epoch: 38 [115584/225000 (51%)] Loss: 15503.934570\n",
      "Train Epoch: 38 [116992/225000 (52%)] Loss: 14862.779297\n",
      "Train Epoch: 38 [118400/225000 (53%)] Loss: 14787.847656\n",
      "Train Epoch: 38 [119808/225000 (53%)] Loss: 15032.089844\n",
      "Train Epoch: 38 [121216/225000 (54%)] Loss: 15033.604492\n",
      "Train Epoch: 38 [122624/225000 (54%)] Loss: 14962.159180\n",
      "Train Epoch: 38 [124032/225000 (55%)] Loss: 14718.066406\n",
      "Train Epoch: 38 [125440/225000 (56%)] Loss: 14963.906250\n",
      "Train Epoch: 38 [126848/225000 (56%)] Loss: 15087.755859\n",
      "Train Epoch: 38 [128256/225000 (57%)] Loss: 15336.084961\n",
      "Train Epoch: 38 [129664/225000 (58%)] Loss: 15004.912109\n",
      "Train Epoch: 38 [131072/225000 (58%)] Loss: 14741.336914\n",
      "Train Epoch: 38 [132480/225000 (59%)] Loss: 15740.405273\n",
      "Train Epoch: 38 [133888/225000 (60%)] Loss: 15578.372070\n",
      "Train Epoch: 38 [135296/225000 (60%)] Loss: 15108.776367\n",
      "Train Epoch: 38 [136704/225000 (61%)] Loss: 15072.895508\n",
      "Train Epoch: 38 [138112/225000 (61%)] Loss: 15119.457031\n",
      "Train Epoch: 38 [139520/225000 (62%)] Loss: 14929.794922\n",
      "Train Epoch: 38 [140928/225000 (63%)] Loss: 15294.201172\n",
      "Train Epoch: 38 [142336/225000 (63%)] Loss: 14709.305664\n",
      "Train Epoch: 38 [143744/225000 (64%)] Loss: 15164.066406\n",
      "Train Epoch: 38 [145152/225000 (65%)] Loss: 15235.955078\n",
      "Train Epoch: 38 [146560/225000 (65%)] Loss: 15112.376953\n",
      "Train Epoch: 38 [147968/225000 (66%)] Loss: 14830.581055\n",
      "Train Epoch: 38 [149376/225000 (66%)] Loss: 15186.984375\n",
      "Train Epoch: 38 [150784/225000 (67%)] Loss: 15010.257812\n",
      "Train Epoch: 38 [152192/225000 (68%)] Loss: 15337.352539\n",
      "Train Epoch: 38 [153600/225000 (68%)] Loss: 15228.813477\n",
      "Train Epoch: 38 [155008/225000 (69%)] Loss: 15382.238281\n",
      "Train Epoch: 38 [156416/225000 (70%)] Loss: 15695.199219\n",
      "Train Epoch: 38 [157824/225000 (70%)] Loss: 15108.609375\n",
      "Train Epoch: 38 [159232/225000 (71%)] Loss: 15689.458984\n",
      "Train Epoch: 38 [160640/225000 (71%)] Loss: 15560.474609\n",
      "Train Epoch: 38 [162048/225000 (72%)] Loss: 14929.293945\n",
      "Train Epoch: 38 [163456/225000 (73%)] Loss: 15173.964844\n",
      "Train Epoch: 38 [164864/225000 (73%)] Loss: 15114.371094\n",
      "Train Epoch: 38 [166272/225000 (74%)] Loss: 14971.738281\n",
      "Train Epoch: 38 [167680/225000 (75%)] Loss: 14976.120117\n",
      "Train Epoch: 38 [169088/225000 (75%)] Loss: 15206.227539\n",
      "Train Epoch: 38 [170496/225000 (76%)] Loss: 15674.301758\n",
      "Train Epoch: 38 [171904/225000 (76%)] Loss: 15854.983398\n",
      "Train Epoch: 38 [173312/225000 (77%)] Loss: 15155.799805\n",
      "Train Epoch: 38 [174720/225000 (78%)] Loss: 15047.634766\n",
      "Train Epoch: 38 [176128/225000 (78%)] Loss: 15259.754883\n",
      "Train Epoch: 38 [177536/225000 (79%)] Loss: 14854.890625\n",
      "Train Epoch: 38 [178944/225000 (80%)] Loss: 15120.282227\n",
      "Train Epoch: 38 [180352/225000 (80%)] Loss: 15114.389648\n",
      "Train Epoch: 38 [181760/225000 (81%)] Loss: 14442.684570\n",
      "Train Epoch: 38 [183168/225000 (81%)] Loss: 14929.896484\n",
      "Train Epoch: 38 [184576/225000 (82%)] Loss: 14962.644531\n",
      "Train Epoch: 38 [185984/225000 (83%)] Loss: 14855.755859\n",
      "Train Epoch: 38 [187392/225000 (83%)] Loss: 14759.653320\n",
      "Train Epoch: 38 [188800/225000 (84%)] Loss: 14604.065430\n",
      "Train Epoch: 38 [190208/225000 (85%)] Loss: 14956.350586\n",
      "Train Epoch: 38 [191616/225000 (85%)] Loss: 14899.205078\n",
      "Train Epoch: 38 [193024/225000 (86%)] Loss: 15390.218750\n",
      "Train Epoch: 38 [194432/225000 (86%)] Loss: 15258.008789\n",
      "Train Epoch: 38 [195840/225000 (87%)] Loss: 15014.333984\n",
      "Train Epoch: 38 [197248/225000 (88%)] Loss: 15391.738281\n",
      "Train Epoch: 38 [198656/225000 (88%)] Loss: 15197.473633\n",
      "Train Epoch: 38 [200064/225000 (89%)] Loss: 14646.983398\n",
      "Train Epoch: 38 [201472/225000 (90%)] Loss: 15279.865234\n",
      "Train Epoch: 38 [202880/225000 (90%)] Loss: 14967.512695\n",
      "Train Epoch: 38 [204288/225000 (91%)] Loss: 14746.273438\n",
      "Train Epoch: 38 [205696/225000 (91%)] Loss: 14809.232422\n",
      "Train Epoch: 38 [207104/225000 (92%)] Loss: 14779.803711\n",
      "Train Epoch: 38 [208512/225000 (93%)] Loss: 14782.831055\n",
      "Train Epoch: 38 [209920/225000 (93%)] Loss: 15795.031250\n",
      "Train Epoch: 38 [211328/225000 (94%)] Loss: 15588.812500\n",
      "Train Epoch: 38 [212736/225000 (95%)] Loss: 14894.419922\n",
      "Train Epoch: 38 [214144/225000 (95%)] Loss: 14899.184570\n",
      "Train Epoch: 38 [215552/225000 (96%)] Loss: 15263.992188\n",
      "Train Epoch: 38 [216960/225000 (96%)] Loss: 15795.552734\n",
      "Train Epoch: 38 [218368/225000 (97%)] Loss: 14679.242188\n",
      "Train Epoch: 38 [219776/225000 (98%)] Loss: 15150.361328\n",
      "Train Epoch: 38 [221184/225000 (98%)] Loss: 15164.345703\n",
      "Train Epoch: 38 [222592/225000 (99%)] Loss: 15134.518555\n",
      "Train Epoch: 38 [224000/225000 (100%)] Loss: 15177.224609\n",
      "    epoch          : 38\n",
      "    loss           : 15079.13262474225\n",
      "    val_loss       : 15080.71177974313\n",
      "Train Epoch: 39 [128/225000 (0%)] Loss: 15146.371094\n",
      "Train Epoch: 39 [1536/225000 (1%)] Loss: 14764.774414\n",
      "Train Epoch: 39 [2944/225000 (1%)] Loss: 15163.716797\n",
      "Train Epoch: 39 [4352/225000 (2%)] Loss: 14861.863281\n",
      "Train Epoch: 39 [5760/225000 (3%)] Loss: 15181.623047\n",
      "Train Epoch: 39 [7168/225000 (3%)] Loss: 15225.182617\n",
      "Train Epoch: 39 [8576/225000 (4%)] Loss: 15171.250000\n",
      "Train Epoch: 39 [9984/225000 (4%)] Loss: 15072.788086\n",
      "Train Epoch: 39 [11392/225000 (5%)] Loss: 15257.945312\n",
      "Train Epoch: 39 [12800/225000 (6%)] Loss: 14984.578125\n",
      "Train Epoch: 39 [14208/225000 (6%)] Loss: 14890.698242\n",
      "Train Epoch: 39 [15616/225000 (7%)] Loss: 14954.844727\n",
      "Train Epoch: 39 [17024/225000 (8%)] Loss: 15331.274414\n",
      "Train Epoch: 39 [18432/225000 (8%)] Loss: 14912.778320\n",
      "Train Epoch: 39 [19840/225000 (9%)] Loss: 14986.246094\n",
      "Train Epoch: 39 [21248/225000 (9%)] Loss: 14837.451172\n",
      "Train Epoch: 39 [22656/225000 (10%)] Loss: 15565.733398\n",
      "Train Epoch: 39 [24064/225000 (11%)] Loss: 14609.187500\n",
      "Train Epoch: 39 [25472/225000 (11%)] Loss: 16031.215820\n",
      "Train Epoch: 39 [26880/225000 (12%)] Loss: 14970.396484\n",
      "Train Epoch: 39 [28288/225000 (13%)] Loss: 14418.786133\n",
      "Train Epoch: 39 [29696/225000 (13%)] Loss: 15007.542969\n",
      "Train Epoch: 39 [31104/225000 (14%)] Loss: 15034.812500\n",
      "Train Epoch: 39 [32512/225000 (14%)] Loss: 15113.331055\n",
      "Train Epoch: 39 [33920/225000 (15%)] Loss: 15250.559570\n",
      "Train Epoch: 39 [35328/225000 (16%)] Loss: 15150.093750\n",
      "Train Epoch: 39 [36736/225000 (16%)] Loss: 15165.803711\n",
      "Train Epoch: 39 [38144/225000 (17%)] Loss: 14995.077148\n",
      "Train Epoch: 39 [39552/225000 (18%)] Loss: 15021.044922\n",
      "Train Epoch: 39 [40960/225000 (18%)] Loss: 15331.153320\n",
      "Train Epoch: 39 [42368/225000 (19%)] Loss: 15361.374023\n",
      "Train Epoch: 39 [43776/225000 (19%)] Loss: 15037.240234\n",
      "Train Epoch: 39 [45184/225000 (20%)] Loss: 15496.057617\n",
      "Train Epoch: 39 [46592/225000 (21%)] Loss: 15224.848633\n",
      "Train Epoch: 39 [48000/225000 (21%)] Loss: 15334.013672\n",
      "Train Epoch: 39 [49408/225000 (22%)] Loss: 14943.568359\n",
      "Train Epoch: 39 [50816/225000 (23%)] Loss: 15492.777344\n",
      "Train Epoch: 39 [52224/225000 (23%)] Loss: 14992.986328\n",
      "Train Epoch: 39 [53632/225000 (24%)] Loss: 15134.380859\n",
      "Train Epoch: 39 [55040/225000 (24%)] Loss: 15408.878906\n",
      "Train Epoch: 39 [56448/225000 (25%)] Loss: 15120.312500\n",
      "Train Epoch: 39 [57856/225000 (26%)] Loss: 14836.524414\n",
      "Train Epoch: 39 [59264/225000 (26%)] Loss: 15036.517578\n",
      "Train Epoch: 39 [60672/225000 (27%)] Loss: 15130.550781\n",
      "Train Epoch: 39 [62080/225000 (28%)] Loss: 15013.485352\n",
      "Train Epoch: 39 [63488/225000 (28%)] Loss: 15154.102539\n",
      "Train Epoch: 39 [64896/225000 (29%)] Loss: 15096.497070\n",
      "Train Epoch: 39 [66304/225000 (29%)] Loss: 14964.727539\n",
      "Train Epoch: 39 [67712/225000 (30%)] Loss: 15094.164062\n",
      "Train Epoch: 39 [69120/225000 (31%)] Loss: 14457.546875\n",
      "Train Epoch: 39 [70528/225000 (31%)] Loss: 14738.016602\n",
      "Train Epoch: 39 [71936/225000 (32%)] Loss: 15097.001953\n",
      "Train Epoch: 39 [73344/225000 (33%)] Loss: 14802.145508\n",
      "Train Epoch: 39 [74752/225000 (33%)] Loss: 15217.154297\n",
      "Train Epoch: 39 [76160/225000 (34%)] Loss: 15025.551758\n",
      "Train Epoch: 39 [77568/225000 (34%)] Loss: 14586.186523\n",
      "Train Epoch: 39 [78976/225000 (35%)] Loss: 14918.700195\n",
      "Train Epoch: 39 [80384/225000 (36%)] Loss: 14926.863281\n",
      "Train Epoch: 39 [81792/225000 (36%)] Loss: 14675.129883\n",
      "Train Epoch: 39 [83200/225000 (37%)] Loss: 15480.318359\n",
      "Train Epoch: 39 [84608/225000 (38%)] Loss: 15570.966797\n",
      "Train Epoch: 39 [86016/225000 (38%)] Loss: 14788.041016\n",
      "Train Epoch: 39 [87424/225000 (39%)] Loss: 15215.880859\n",
      "Train Epoch: 39 [88832/225000 (39%)] Loss: 15209.792969\n",
      "Train Epoch: 39 [90240/225000 (40%)] Loss: 14847.210938\n",
      "Train Epoch: 39 [91648/225000 (41%)] Loss: 15148.351562\n",
      "Train Epoch: 39 [93056/225000 (41%)] Loss: 14766.719727\n",
      "Train Epoch: 39 [94464/225000 (42%)] Loss: 14767.420898\n",
      "Train Epoch: 39 [95872/225000 (43%)] Loss: 15033.238281\n",
      "Train Epoch: 39 [97280/225000 (43%)] Loss: 15027.178711\n",
      "Train Epoch: 39 [98688/225000 (44%)] Loss: 15054.094727\n",
      "Train Epoch: 39 [100096/225000 (44%)] Loss: 14990.492188\n",
      "Train Epoch: 39 [101504/225000 (45%)] Loss: 15164.434570\n",
      "Train Epoch: 39 [102912/225000 (46%)] Loss: 14710.006836\n",
      "Train Epoch: 39 [104320/225000 (46%)] Loss: 14817.944336\n",
      "Train Epoch: 39 [105728/225000 (47%)] Loss: 15286.680664\n",
      "Train Epoch: 39 [107136/225000 (48%)] Loss: 15274.482422\n",
      "Train Epoch: 39 [108544/225000 (48%)] Loss: 14808.760742\n",
      "Train Epoch: 39 [109952/225000 (49%)] Loss: 14966.356445\n",
      "Train Epoch: 39 [111360/225000 (49%)] Loss: 15343.991211\n",
      "Train Epoch: 39 [112768/225000 (50%)] Loss: 15226.144531\n",
      "Train Epoch: 39 [114176/225000 (51%)] Loss: 14878.873047\n",
      "Train Epoch: 39 [115584/225000 (51%)] Loss: 15131.395508\n",
      "Train Epoch: 39 [116992/225000 (52%)] Loss: 14903.693359\n",
      "Train Epoch: 39 [118400/225000 (53%)] Loss: 15197.867188\n",
      "Train Epoch: 39 [119808/225000 (53%)] Loss: 14892.650391\n",
      "Train Epoch: 39 [121216/225000 (54%)] Loss: 14846.368164\n",
      "Train Epoch: 39 [122624/225000 (54%)] Loss: 14712.448242\n",
      "Train Epoch: 39 [124032/225000 (55%)] Loss: 14970.947266\n",
      "Train Epoch: 39 [125440/225000 (56%)] Loss: 14840.987305\n",
      "Train Epoch: 39 [126848/225000 (56%)] Loss: 14735.833008\n",
      "Train Epoch: 39 [128256/225000 (57%)] Loss: 15083.191406\n",
      "Train Epoch: 39 [129664/225000 (58%)] Loss: 14804.658203\n",
      "Train Epoch: 39 [131072/225000 (58%)] Loss: 15138.663086\n",
      "Train Epoch: 39 [132480/225000 (59%)] Loss: 15413.144531\n",
      "Train Epoch: 39 [133888/225000 (60%)] Loss: 15246.725586\n",
      "Train Epoch: 39 [135296/225000 (60%)] Loss: 14906.527344\n",
      "Train Epoch: 39 [136704/225000 (61%)] Loss: 15121.465820\n",
      "Train Epoch: 39 [138112/225000 (61%)] Loss: 14588.104492\n",
      "Train Epoch: 39 [139520/225000 (62%)] Loss: 14791.691406\n",
      "Train Epoch: 39 [140928/225000 (63%)] Loss: 14621.450195\n",
      "Train Epoch: 39 [142336/225000 (63%)] Loss: 14857.607422\n",
      "Train Epoch: 39 [143744/225000 (64%)] Loss: 15281.665039\n",
      "Train Epoch: 39 [145152/225000 (65%)] Loss: 14783.031250\n",
      "Train Epoch: 39 [146560/225000 (65%)] Loss: 15202.576172\n",
      "Train Epoch: 39 [147968/225000 (66%)] Loss: 15371.015625\n",
      "Train Epoch: 39 [149376/225000 (66%)] Loss: 14882.920898\n",
      "Train Epoch: 39 [150784/225000 (67%)] Loss: 14816.771484\n",
      "Train Epoch: 39 [152192/225000 (68%)] Loss: 15306.993164\n",
      "Train Epoch: 39 [153600/225000 (68%)] Loss: 14860.097656\n",
      "Train Epoch: 39 [155008/225000 (69%)] Loss: 14712.217773\n",
      "Train Epoch: 39 [156416/225000 (70%)] Loss: 15329.472656\n",
      "Train Epoch: 39 [157824/225000 (70%)] Loss: 14934.670898\n",
      "Train Epoch: 39 [159232/225000 (71%)] Loss: 14916.852539\n",
      "Train Epoch: 39 [160640/225000 (71%)] Loss: 15109.859375\n",
      "Train Epoch: 39 [162048/225000 (72%)] Loss: 14829.520508\n",
      "Train Epoch: 39 [163456/225000 (73%)] Loss: 15594.041992\n",
      "Train Epoch: 39 [164864/225000 (73%)] Loss: 14964.368164\n",
      "Train Epoch: 39 [166272/225000 (74%)] Loss: 15293.566406\n",
      "Train Epoch: 39 [167680/225000 (75%)] Loss: 14977.443359\n",
      "Train Epoch: 39 [169088/225000 (75%)] Loss: 15249.569336\n",
      "Train Epoch: 39 [170496/225000 (76%)] Loss: 15048.205078\n",
      "Train Epoch: 39 [171904/225000 (76%)] Loss: 14918.868164\n",
      "Train Epoch: 39 [173312/225000 (77%)] Loss: 14997.291016\n",
      "Train Epoch: 39 [174720/225000 (78%)] Loss: 15202.440430\n",
      "Train Epoch: 39 [176128/225000 (78%)] Loss: 14940.778320\n",
      "Train Epoch: 39 [177536/225000 (79%)] Loss: 15293.977539\n",
      "Train Epoch: 39 [178944/225000 (80%)] Loss: 15168.376953\n",
      "Train Epoch: 39 [180352/225000 (80%)] Loss: 14924.213867\n",
      "Train Epoch: 39 [181760/225000 (81%)] Loss: 15577.098633\n",
      "Train Epoch: 39 [183168/225000 (81%)] Loss: 15370.721680\n",
      "Train Epoch: 39 [184576/225000 (82%)] Loss: 15087.340820\n",
      "Train Epoch: 39 [185984/225000 (83%)] Loss: 15376.833984\n",
      "Train Epoch: 39 [187392/225000 (83%)] Loss: 14873.616211\n",
      "Train Epoch: 39 [188800/225000 (84%)] Loss: 14940.235352\n",
      "Train Epoch: 39 [190208/225000 (85%)] Loss: 15210.381836\n",
      "Train Epoch: 39 [191616/225000 (85%)] Loss: 14935.958008\n",
      "Train Epoch: 39 [193024/225000 (86%)] Loss: 15018.461914\n",
      "Train Epoch: 39 [194432/225000 (86%)] Loss: 15232.063477\n",
      "Train Epoch: 39 [195840/225000 (87%)] Loss: 14906.612305\n",
      "Train Epoch: 39 [197248/225000 (88%)] Loss: 15073.806641\n",
      "Train Epoch: 39 [198656/225000 (88%)] Loss: 14772.626953\n",
      "Train Epoch: 39 [200064/225000 (89%)] Loss: 14725.686523\n",
      "Train Epoch: 39 [201472/225000 (90%)] Loss: 15571.831055\n",
      "Train Epoch: 39 [202880/225000 (90%)] Loss: 15009.444336\n",
      "Train Epoch: 39 [204288/225000 (91%)] Loss: 15276.503906\n",
      "Train Epoch: 39 [205696/225000 (91%)] Loss: 15091.445312\n",
      "Train Epoch: 39 [207104/225000 (92%)] Loss: 15705.000000\n",
      "Train Epoch: 39 [208512/225000 (93%)] Loss: 15016.539062\n",
      "Train Epoch: 39 [209920/225000 (93%)] Loss: 14935.947266\n",
      "Train Epoch: 39 [211328/225000 (94%)] Loss: 14911.624023\n",
      "Train Epoch: 39 [212736/225000 (95%)] Loss: 15022.332031\n",
      "Train Epoch: 39 [214144/225000 (95%)] Loss: 15100.309570\n",
      "Train Epoch: 39 [215552/225000 (96%)] Loss: 15177.850586\n",
      "Train Epoch: 39 [216960/225000 (96%)] Loss: 14838.049805\n",
      "Train Epoch: 39 [218368/225000 (97%)] Loss: 15379.029297\n",
      "Train Epoch: 39 [219776/225000 (98%)] Loss: 15034.212891\n",
      "Train Epoch: 39 [221184/225000 (98%)] Loss: 15640.195312\n",
      "Train Epoch: 39 [222592/225000 (99%)] Loss: 14992.657227\n",
      "Train Epoch: 39 [224000/225000 (100%)] Loss: 15032.854492\n",
      "    epoch          : 39\n",
      "    loss           : 15077.555696281286\n",
      "    val_loss       : 15058.028727627378\n",
      "Train Epoch: 40 [128/225000 (0%)] Loss: 15118.024414\n",
      "Train Epoch: 40 [1536/225000 (1%)] Loss: 15481.949219\n",
      "Train Epoch: 40 [2944/225000 (1%)] Loss: 15212.895508\n",
      "Train Epoch: 40 [4352/225000 (2%)] Loss: 15464.040039\n",
      "Train Epoch: 40 [5760/225000 (3%)] Loss: 14828.949219\n",
      "Train Epoch: 40 [7168/225000 (3%)] Loss: 14679.900391\n",
      "Train Epoch: 40 [8576/225000 (4%)] Loss: 14907.465820\n",
      "Train Epoch: 40 [9984/225000 (4%)] Loss: 14818.374023\n",
      "Train Epoch: 40 [11392/225000 (5%)] Loss: 14759.260742\n",
      "Train Epoch: 40 [12800/225000 (6%)] Loss: 15220.950195\n",
      "Train Epoch: 40 [14208/225000 (6%)] Loss: 15194.111328\n",
      "Train Epoch: 40 [15616/225000 (7%)] Loss: 15329.054688\n",
      "Train Epoch: 40 [17024/225000 (8%)] Loss: 14923.500000\n",
      "Train Epoch: 40 [18432/225000 (8%)] Loss: 15417.531250\n",
      "Train Epoch: 40 [19840/225000 (9%)] Loss: 14718.013672\n",
      "Train Epoch: 40 [21248/225000 (9%)] Loss: 15291.906250\n",
      "Train Epoch: 40 [22656/225000 (10%)] Loss: 14831.039062\n",
      "Train Epoch: 40 [24064/225000 (11%)] Loss: 15535.416992\n",
      "Train Epoch: 40 [25472/225000 (11%)] Loss: 14879.419922\n",
      "Train Epoch: 40 [26880/225000 (12%)] Loss: 15012.406250\n",
      "Train Epoch: 40 [28288/225000 (13%)] Loss: 14887.097656\n",
      "Train Epoch: 40 [29696/225000 (13%)] Loss: 14742.435547\n",
      "Train Epoch: 40 [31104/225000 (14%)] Loss: 15286.275391\n",
      "Train Epoch: 40 [32512/225000 (14%)] Loss: 15124.845703\n",
      "Train Epoch: 40 [33920/225000 (15%)] Loss: 15007.943359\n",
      "Train Epoch: 40 [35328/225000 (16%)] Loss: 14959.339844\n",
      "Train Epoch: 40 [36736/225000 (16%)] Loss: 15169.555664\n",
      "Train Epoch: 40 [38144/225000 (17%)] Loss: 14601.835938\n",
      "Train Epoch: 40 [39552/225000 (18%)] Loss: 14944.437500\n",
      "Train Epoch: 40 [40960/225000 (18%)] Loss: 15204.730469\n",
      "Train Epoch: 40 [42368/225000 (19%)] Loss: 15666.759766\n",
      "Train Epoch: 40 [43776/225000 (19%)] Loss: 15063.855469\n",
      "Train Epoch: 40 [45184/225000 (20%)] Loss: 15187.560547\n",
      "Train Epoch: 40 [46592/225000 (21%)] Loss: 15134.613281\n",
      "Train Epoch: 40 [48000/225000 (21%)] Loss: 14963.013672\n",
      "Train Epoch: 40 [49408/225000 (22%)] Loss: 15426.170898\n",
      "Train Epoch: 40 [50816/225000 (23%)] Loss: 14949.262695\n",
      "Train Epoch: 40 [52224/225000 (23%)] Loss: 15454.002930\n",
      "Train Epoch: 40 [53632/225000 (24%)] Loss: 15571.374023\n",
      "Train Epoch: 40 [55040/225000 (24%)] Loss: 15162.374023\n",
      "Train Epoch: 40 [56448/225000 (25%)] Loss: 14649.022461\n",
      "Train Epoch: 40 [57856/225000 (26%)] Loss: 15205.875977\n",
      "Train Epoch: 40 [59264/225000 (26%)] Loss: 14576.257812\n",
      "Train Epoch: 40 [60672/225000 (27%)] Loss: 15180.673828\n",
      "Train Epoch: 40 [62080/225000 (28%)] Loss: 14732.331055\n",
      "Train Epoch: 40 [63488/225000 (28%)] Loss: 15234.252930\n",
      "Train Epoch: 40 [64896/225000 (29%)] Loss: 15224.234375\n",
      "Train Epoch: 40 [66304/225000 (29%)] Loss: 14724.623047\n",
      "Train Epoch: 40 [67712/225000 (30%)] Loss: 15440.932617\n",
      "Train Epoch: 40 [69120/225000 (31%)] Loss: 15068.966797\n",
      "Train Epoch: 40 [70528/225000 (31%)] Loss: 15535.975586\n",
      "Train Epoch: 40 [71936/225000 (32%)] Loss: 15066.607422\n",
      "Train Epoch: 40 [73344/225000 (33%)] Loss: 15246.560547\n",
      "Train Epoch: 40 [74752/225000 (33%)] Loss: 15279.879883\n",
      "Train Epoch: 40 [76160/225000 (34%)] Loss: 14834.084961\n",
      "Train Epoch: 40 [77568/225000 (34%)] Loss: 14793.704102\n",
      "Train Epoch: 40 [78976/225000 (35%)] Loss: 14588.625977\n",
      "Train Epoch: 40 [80384/225000 (36%)] Loss: 15300.619141\n",
      "Train Epoch: 40 [81792/225000 (36%)] Loss: 15058.597656\n",
      "Train Epoch: 40 [83200/225000 (37%)] Loss: 15428.761719\n",
      "Train Epoch: 40 [84608/225000 (38%)] Loss: 14858.278320\n",
      "Train Epoch: 40 [86016/225000 (38%)] Loss: 14954.083008\n",
      "Train Epoch: 40 [87424/225000 (39%)] Loss: 15103.875000\n",
      "Train Epoch: 40 [88832/225000 (39%)] Loss: 14945.117188\n",
      "Train Epoch: 40 [90240/225000 (40%)] Loss: 15296.757812\n",
      "Train Epoch: 40 [91648/225000 (41%)] Loss: 15555.935547\n",
      "Train Epoch: 40 [93056/225000 (41%)] Loss: 14618.288086\n",
      "Train Epoch: 40 [94464/225000 (42%)] Loss: 15333.063477\n",
      "Train Epoch: 40 [95872/225000 (43%)] Loss: 15353.913086\n",
      "Train Epoch: 40 [97280/225000 (43%)] Loss: 15057.941406\n",
      "Train Epoch: 40 [98688/225000 (44%)] Loss: 15023.769531\n",
      "Train Epoch: 40 [100096/225000 (44%)] Loss: 15112.124023\n",
      "Train Epoch: 40 [101504/225000 (45%)] Loss: 15018.039062\n",
      "Train Epoch: 40 [102912/225000 (46%)] Loss: 14804.701172\n",
      "Train Epoch: 40 [104320/225000 (46%)] Loss: 14983.881836\n",
      "Train Epoch: 40 [105728/225000 (47%)] Loss: 15030.489258\n",
      "Train Epoch: 40 [107136/225000 (48%)] Loss: 15050.844727\n",
      "Train Epoch: 40 [108544/225000 (48%)] Loss: 15276.879883\n",
      "Train Epoch: 40 [109952/225000 (49%)] Loss: 15088.590820\n",
      "Train Epoch: 40 [111360/225000 (49%)] Loss: 15084.401367\n",
      "Train Epoch: 40 [112768/225000 (50%)] Loss: 15202.116211\n",
      "Train Epoch: 40 [114176/225000 (51%)] Loss: 15050.001953\n",
      "Train Epoch: 40 [115584/225000 (51%)] Loss: 14950.391602\n",
      "Train Epoch: 40 [116992/225000 (52%)] Loss: 15198.484375\n",
      "Train Epoch: 40 [118400/225000 (53%)] Loss: 14991.324219\n",
      "Train Epoch: 40 [119808/225000 (53%)] Loss: 14877.646484\n",
      "Train Epoch: 40 [121216/225000 (54%)] Loss: 15173.085938\n",
      "Train Epoch: 40 [122624/225000 (54%)] Loss: 14859.656250\n",
      "Train Epoch: 40 [124032/225000 (55%)] Loss: 15244.306641\n",
      "Train Epoch: 40 [125440/225000 (56%)] Loss: 15922.737305\n",
      "Train Epoch: 40 [126848/225000 (56%)] Loss: 15061.119141\n",
      "Train Epoch: 40 [128256/225000 (57%)] Loss: 15107.124023\n",
      "Train Epoch: 40 [129664/225000 (58%)] Loss: 15159.991211\n",
      "Train Epoch: 40 [131072/225000 (58%)] Loss: 15221.063477\n",
      "Train Epoch: 40 [132480/225000 (59%)] Loss: 14540.703125\n",
      "Train Epoch: 40 [133888/225000 (60%)] Loss: 14969.549805\n",
      "Train Epoch: 40 [135296/225000 (60%)] Loss: 15196.208984\n",
      "Train Epoch: 40 [136704/225000 (61%)] Loss: 14878.315430\n",
      "Train Epoch: 40 [138112/225000 (61%)] Loss: 14920.908203\n",
      "Train Epoch: 40 [139520/225000 (62%)] Loss: 15153.160156\n",
      "Train Epoch: 40 [140928/225000 (63%)] Loss: 14977.944336\n",
      "Train Epoch: 40 [142336/225000 (63%)] Loss: 15188.554688\n",
      "Train Epoch: 40 [143744/225000 (64%)] Loss: 15004.978516\n",
      "Train Epoch: 40 [145152/225000 (65%)] Loss: 14979.624023\n",
      "Train Epoch: 40 [146560/225000 (65%)] Loss: 14997.260742\n",
      "Train Epoch: 40 [147968/225000 (66%)] Loss: 15235.105469\n",
      "Train Epoch: 40 [149376/225000 (66%)] Loss: 15621.236328\n",
      "Train Epoch: 40 [150784/225000 (67%)] Loss: 15130.271484\n",
      "Train Epoch: 40 [152192/225000 (68%)] Loss: 15575.188477\n",
      "Train Epoch: 40 [153600/225000 (68%)] Loss: 15374.831055\n",
      "Train Epoch: 40 [155008/225000 (69%)] Loss: 15158.072266\n",
      "Train Epoch: 40 [156416/225000 (70%)] Loss: 14971.842773\n",
      "Train Epoch: 40 [157824/225000 (70%)] Loss: 15671.649414\n",
      "Train Epoch: 40 [159232/225000 (71%)] Loss: 14916.986328\n",
      "Train Epoch: 40 [160640/225000 (71%)] Loss: 14963.351562\n",
      "Train Epoch: 40 [162048/225000 (72%)] Loss: 14918.669922\n",
      "Train Epoch: 40 [163456/225000 (73%)] Loss: 15376.215820\n",
      "Train Epoch: 40 [164864/225000 (73%)] Loss: 14954.514648\n",
      "Train Epoch: 40 [166272/225000 (74%)] Loss: 14919.387695\n",
      "Train Epoch: 40 [167680/225000 (75%)] Loss: 15470.139648\n",
      "Train Epoch: 40 [169088/225000 (75%)] Loss: 15413.401367\n",
      "Train Epoch: 40 [170496/225000 (76%)] Loss: 14836.950195\n",
      "Train Epoch: 40 [171904/225000 (76%)] Loss: 14677.082031\n",
      "Train Epoch: 40 [173312/225000 (77%)] Loss: 15017.255859\n",
      "Train Epoch: 40 [174720/225000 (78%)] Loss: 15063.966797\n",
      "Train Epoch: 40 [176128/225000 (78%)] Loss: 14839.865234\n",
      "Train Epoch: 40 [177536/225000 (79%)] Loss: 15054.860352\n",
      "Train Epoch: 40 [178944/225000 (80%)] Loss: 14696.316406\n",
      "Train Epoch: 40 [180352/225000 (80%)] Loss: 15274.530273\n",
      "Train Epoch: 40 [181760/225000 (81%)] Loss: 15601.315430\n",
      "Train Epoch: 40 [183168/225000 (81%)] Loss: 15118.686523\n",
      "Train Epoch: 40 [184576/225000 (82%)] Loss: 15194.966797\n",
      "Train Epoch: 40 [185984/225000 (83%)] Loss: 15416.110352\n",
      "Train Epoch: 40 [187392/225000 (83%)] Loss: 15125.153320\n",
      "Train Epoch: 40 [188800/225000 (84%)] Loss: 15145.044922\n",
      "Train Epoch: 40 [190208/225000 (85%)] Loss: 15099.844727\n",
      "Train Epoch: 40 [191616/225000 (85%)] Loss: 15215.560547\n",
      "Train Epoch: 40 [193024/225000 (86%)] Loss: 15170.760742\n",
      "Train Epoch: 40 [194432/225000 (86%)] Loss: 15299.824219\n",
      "Train Epoch: 40 [195840/225000 (87%)] Loss: 15184.165039\n",
      "Train Epoch: 40 [197248/225000 (88%)] Loss: 14997.542969\n",
      "Train Epoch: 40 [198656/225000 (88%)] Loss: 15047.781250\n",
      "Train Epoch: 40 [200064/225000 (89%)] Loss: 15352.048828\n",
      "Train Epoch: 40 [201472/225000 (90%)] Loss: 15260.877930\n",
      "Train Epoch: 40 [202880/225000 (90%)] Loss: 15153.718750\n",
      "Train Epoch: 40 [204288/225000 (91%)] Loss: 14825.263672\n",
      "Train Epoch: 40 [205696/225000 (91%)] Loss: 14735.369141\n",
      "Train Epoch: 40 [207104/225000 (92%)] Loss: 15296.705078\n",
      "Train Epoch: 40 [208512/225000 (93%)] Loss: 14722.958008\n",
      "Train Epoch: 40 [209920/225000 (93%)] Loss: 14755.610352\n",
      "Train Epoch: 40 [211328/225000 (94%)] Loss: 14920.054688\n",
      "Train Epoch: 40 [212736/225000 (95%)] Loss: 15042.159180\n",
      "Train Epoch: 40 [214144/225000 (95%)] Loss: 14825.666016\n",
      "Train Epoch: 40 [215552/225000 (96%)] Loss: 14473.816406\n",
      "Train Epoch: 40 [216960/225000 (96%)] Loss: 15182.058594\n",
      "Train Epoch: 40 [218368/225000 (97%)] Loss: 14935.610352\n",
      "Train Epoch: 40 [219776/225000 (98%)] Loss: 14804.131836\n",
      "Train Epoch: 40 [221184/225000 (98%)] Loss: 14952.796875\n",
      "Train Epoch: 40 [222592/225000 (99%)] Loss: 15061.641602\n",
      "Train Epoch: 40 [224000/225000 (100%)] Loss: 14662.843750\n",
      "    epoch          : 40\n",
      "    loss           : 15078.739281698841\n",
      "    val_loss       : 15060.439492342575\n",
      "Train Epoch: 41 [128/225000 (0%)] Loss: 14159.958008\n",
      "Train Epoch: 41 [1536/225000 (1%)] Loss: 15333.970703\n",
      "Train Epoch: 41 [2944/225000 (1%)] Loss: 15273.211914\n",
      "Train Epoch: 41 [4352/225000 (2%)] Loss: 15854.583008\n",
      "Train Epoch: 41 [5760/225000 (3%)] Loss: 15364.586914\n",
      "Train Epoch: 41 [7168/225000 (3%)] Loss: 15198.910156\n",
      "Train Epoch: 41 [8576/225000 (4%)] Loss: 14986.494141\n",
      "Train Epoch: 41 [9984/225000 (4%)] Loss: 15337.846680\n",
      "Train Epoch: 41 [11392/225000 (5%)] Loss: 15392.552734\n",
      "Train Epoch: 41 [12800/225000 (6%)] Loss: 14999.873047\n",
      "Train Epoch: 41 [14208/225000 (6%)] Loss: 15183.791992\n",
      "Train Epoch: 41 [15616/225000 (7%)] Loss: 14879.636719\n",
      "Train Epoch: 41 [17024/225000 (8%)] Loss: 15043.059570\n",
      "Train Epoch: 41 [18432/225000 (8%)] Loss: 15199.680664\n",
      "Train Epoch: 41 [19840/225000 (9%)] Loss: 14655.750000\n",
      "Train Epoch: 41 [21248/225000 (9%)] Loss: 15282.128906\n",
      "Train Epoch: 41 [22656/225000 (10%)] Loss: 15046.574219\n",
      "Train Epoch: 41 [24064/225000 (11%)] Loss: 14906.941406\n",
      "Train Epoch: 41 [25472/225000 (11%)] Loss: 15069.759766\n",
      "Train Epoch: 41 [26880/225000 (12%)] Loss: 15117.212891\n",
      "Train Epoch: 41 [28288/225000 (13%)] Loss: 15482.590820\n",
      "Train Epoch: 41 [29696/225000 (13%)] Loss: 15082.765625\n",
      "Train Epoch: 41 [31104/225000 (14%)] Loss: 15127.752930\n",
      "Train Epoch: 41 [32512/225000 (14%)] Loss: 14930.421875\n",
      "Train Epoch: 41 [33920/225000 (15%)] Loss: 14892.062500\n",
      "Train Epoch: 41 [35328/225000 (16%)] Loss: 15531.253906\n",
      "Train Epoch: 41 [36736/225000 (16%)] Loss: 15249.281250\n",
      "Train Epoch: 41 [38144/225000 (17%)] Loss: 14746.578125\n",
      "Train Epoch: 41 [39552/225000 (18%)] Loss: 15209.027344\n",
      "Train Epoch: 41 [40960/225000 (18%)] Loss: 15563.979492\n",
      "Train Epoch: 41 [42368/225000 (19%)] Loss: 15563.999023\n",
      "Train Epoch: 41 [43776/225000 (19%)] Loss: 15152.492188\n",
      "Train Epoch: 41 [45184/225000 (20%)] Loss: 14917.514648\n",
      "Train Epoch: 41 [46592/225000 (21%)] Loss: 14949.152344\n",
      "Train Epoch: 41 [48000/225000 (21%)] Loss: 14853.741211\n",
      "Train Epoch: 41 [49408/225000 (22%)] Loss: 14662.334961\n",
      "Train Epoch: 41 [50816/225000 (23%)] Loss: 15197.671875\n",
      "Train Epoch: 41 [52224/225000 (23%)] Loss: 14709.337891\n",
      "Train Epoch: 41 [53632/225000 (24%)] Loss: 14668.279297\n",
      "Train Epoch: 41 [55040/225000 (24%)] Loss: 15876.360352\n",
      "Train Epoch: 41 [56448/225000 (25%)] Loss: 15318.597656\n",
      "Train Epoch: 41 [57856/225000 (26%)] Loss: 14519.743164\n",
      "Train Epoch: 41 [59264/225000 (26%)] Loss: 15381.929688\n",
      "Train Epoch: 41 [60672/225000 (27%)] Loss: 14755.754883\n",
      "Train Epoch: 41 [62080/225000 (28%)] Loss: 14870.150391\n",
      "Train Epoch: 41 [63488/225000 (28%)] Loss: 14870.433594\n",
      "Train Epoch: 41 [64896/225000 (29%)] Loss: 15519.506836\n",
      "Train Epoch: 41 [66304/225000 (29%)] Loss: 14925.375977\n",
      "Train Epoch: 41 [67712/225000 (30%)] Loss: 15287.193359\n",
      "Train Epoch: 41 [69120/225000 (31%)] Loss: 14903.425781\n",
      "Train Epoch: 41 [70528/225000 (31%)] Loss: 14989.370117\n",
      "Train Epoch: 41 [71936/225000 (32%)] Loss: 15272.823242\n",
      "Train Epoch: 41 [73344/225000 (33%)] Loss: 14778.079102\n",
      "Train Epoch: 41 [74752/225000 (33%)] Loss: 14902.693359\n",
      "Train Epoch: 41 [76160/225000 (34%)] Loss: 15003.436523\n",
      "Train Epoch: 41 [77568/225000 (34%)] Loss: 14849.943359\n",
      "Train Epoch: 41 [78976/225000 (35%)] Loss: 15100.095703\n",
      "Train Epoch: 41 [80384/225000 (36%)] Loss: 15357.419922\n",
      "Train Epoch: 41 [81792/225000 (36%)] Loss: 15212.334961\n",
      "Train Epoch: 41 [83200/225000 (37%)] Loss: 15518.183594\n",
      "Train Epoch: 41 [84608/225000 (38%)] Loss: 15525.113281\n",
      "Train Epoch: 41 [86016/225000 (38%)] Loss: 15315.332031\n",
      "Train Epoch: 41 [87424/225000 (39%)] Loss: 15015.132812\n",
      "Train Epoch: 41 [88832/225000 (39%)] Loss: 15474.505859\n",
      "Train Epoch: 41 [90240/225000 (40%)] Loss: 15525.629883\n",
      "Train Epoch: 41 [91648/225000 (41%)] Loss: 15035.032227\n",
      "Train Epoch: 41 [93056/225000 (41%)] Loss: 14856.307617\n",
      "Train Epoch: 41 [94464/225000 (42%)] Loss: 14871.290039\n",
      "Train Epoch: 41 [95872/225000 (43%)] Loss: 14932.256836\n",
      "Train Epoch: 41 [97280/225000 (43%)] Loss: 14841.555664\n",
      "Train Epoch: 41 [98688/225000 (44%)] Loss: 15074.232422\n",
      "Train Epoch: 41 [100096/225000 (44%)] Loss: 15269.446289\n",
      "Train Epoch: 41 [101504/225000 (45%)] Loss: 14623.146484\n",
      "Train Epoch: 41 [102912/225000 (46%)] Loss: 14783.913086\n",
      "Train Epoch: 41 [104320/225000 (46%)] Loss: 15062.367188\n",
      "Train Epoch: 41 [105728/225000 (47%)] Loss: 14778.460938\n",
      "Train Epoch: 41 [107136/225000 (48%)] Loss: 14294.592773\n",
      "Train Epoch: 41 [108544/225000 (48%)] Loss: 15145.334961\n",
      "Train Epoch: 41 [109952/225000 (49%)] Loss: 14976.460938\n",
      "Train Epoch: 41 [111360/225000 (49%)] Loss: 14796.553711\n",
      "Train Epoch: 41 [112768/225000 (50%)] Loss: 14946.857422\n",
      "Train Epoch: 41 [114176/225000 (51%)] Loss: 15468.125977\n",
      "Train Epoch: 41 [115584/225000 (51%)] Loss: 15333.551758\n",
      "Train Epoch: 41 [116992/225000 (52%)] Loss: 14919.640625\n",
      "Train Epoch: 41 [118400/225000 (53%)] Loss: 14888.074219\n",
      "Train Epoch: 41 [119808/225000 (53%)] Loss: 14784.119141\n",
      "Train Epoch: 41 [121216/225000 (54%)] Loss: 14828.062500\n",
      "Train Epoch: 41 [122624/225000 (54%)] Loss: 14832.548828\n",
      "Train Epoch: 41 [124032/225000 (55%)] Loss: 15148.347656\n",
      "Train Epoch: 41 [125440/225000 (56%)] Loss: 14712.785156\n",
      "Train Epoch: 41 [126848/225000 (56%)] Loss: 14805.514648\n",
      "Train Epoch: 41 [128256/225000 (57%)] Loss: 15260.008789\n",
      "Train Epoch: 41 [129664/225000 (58%)] Loss: 14909.627930\n",
      "Train Epoch: 41 [131072/225000 (58%)] Loss: 15172.784180\n",
      "Train Epoch: 41 [132480/225000 (59%)] Loss: 15020.416016\n",
      "Train Epoch: 41 [133888/225000 (60%)] Loss: 15007.583984\n",
      "Train Epoch: 41 [135296/225000 (60%)] Loss: 15258.601562\n",
      "Train Epoch: 41 [136704/225000 (61%)] Loss: 15097.838867\n",
      "Train Epoch: 41 [138112/225000 (61%)] Loss: 14501.256836\n",
      "Train Epoch: 41 [139520/225000 (62%)] Loss: 15176.692383\n",
      "Train Epoch: 41 [140928/225000 (63%)] Loss: 14989.979492\n",
      "Train Epoch: 41 [142336/225000 (63%)] Loss: 15150.542969\n",
      "Train Epoch: 41 [143744/225000 (64%)] Loss: 15236.439453\n",
      "Train Epoch: 41 [145152/225000 (65%)] Loss: 15233.081055\n",
      "Train Epoch: 41 [146560/225000 (65%)] Loss: 14924.770508\n",
      "Train Epoch: 41 [147968/225000 (66%)] Loss: 15023.340820\n",
      "Train Epoch: 41 [149376/225000 (66%)] Loss: 15029.165039\n",
      "Train Epoch: 41 [150784/225000 (67%)] Loss: 14974.949219\n",
      "Train Epoch: 41 [152192/225000 (68%)] Loss: 14234.316406\n",
      "Train Epoch: 41 [153600/225000 (68%)] Loss: 14939.136719\n",
      "Train Epoch: 41 [155008/225000 (69%)] Loss: 15712.405273\n",
      "Train Epoch: 41 [156416/225000 (70%)] Loss: 14942.544922\n",
      "Train Epoch: 41 [157824/225000 (70%)] Loss: 15423.136719\n",
      "Train Epoch: 41 [159232/225000 (71%)] Loss: 14786.789062\n",
      "Train Epoch: 41 [160640/225000 (71%)] Loss: 15553.191406\n",
      "Train Epoch: 41 [162048/225000 (72%)] Loss: 15069.573242\n",
      "Train Epoch: 41 [163456/225000 (73%)] Loss: 14900.647461\n",
      "Train Epoch: 41 [164864/225000 (73%)] Loss: 15334.528320\n",
      "Train Epoch: 41 [166272/225000 (74%)] Loss: 14849.887695\n",
      "Train Epoch: 41 [167680/225000 (75%)] Loss: 15594.469727\n",
      "Train Epoch: 41 [169088/225000 (75%)] Loss: 15358.787109\n",
      "Train Epoch: 41 [170496/225000 (76%)] Loss: 14655.647461\n",
      "Train Epoch: 41 [171904/225000 (76%)] Loss: 15617.081055\n",
      "Train Epoch: 41 [173312/225000 (77%)] Loss: 14770.102539\n",
      "Train Epoch: 41 [174720/225000 (78%)] Loss: 15172.041992\n",
      "Train Epoch: 41 [176128/225000 (78%)] Loss: 14976.128906\n",
      "Train Epoch: 41 [177536/225000 (79%)] Loss: 14854.166992\n",
      "Train Epoch: 41 [178944/225000 (80%)] Loss: 15235.964844\n",
      "Train Epoch: 41 [180352/225000 (80%)] Loss: 15345.033203\n",
      "Train Epoch: 41 [181760/225000 (81%)] Loss: 15032.959961\n",
      "Train Epoch: 41 [183168/225000 (81%)] Loss: 14961.027344\n",
      "Train Epoch: 41 [184576/225000 (82%)] Loss: 15269.250977\n",
      "Train Epoch: 41 [185984/225000 (83%)] Loss: 14948.457031\n",
      "Train Epoch: 41 [187392/225000 (83%)] Loss: 14725.427734\n",
      "Train Epoch: 41 [188800/225000 (84%)] Loss: 14608.908203\n",
      "Train Epoch: 41 [190208/225000 (85%)] Loss: 14718.855469\n",
      "Train Epoch: 41 [191616/225000 (85%)] Loss: 15058.601562\n",
      "Train Epoch: 41 [193024/225000 (86%)] Loss: 15092.148438\n",
      "Train Epoch: 41 [194432/225000 (86%)] Loss: 15393.686523\n",
      "Train Epoch: 41 [195840/225000 (87%)] Loss: 14961.255859\n",
      "Train Epoch: 41 [197248/225000 (88%)] Loss: 14884.978516\n",
      "Train Epoch: 41 [198656/225000 (88%)] Loss: 15158.149414\n",
      "Train Epoch: 41 [200064/225000 (89%)] Loss: 15434.211914\n",
      "Train Epoch: 41 [201472/225000 (90%)] Loss: 15274.015625\n",
      "Train Epoch: 41 [202880/225000 (90%)] Loss: 14740.166016\n",
      "Train Epoch: 41 [204288/225000 (91%)] Loss: 15805.124023\n",
      "Train Epoch: 41 [205696/225000 (91%)] Loss: 15097.406250\n",
      "Train Epoch: 41 [207104/225000 (92%)] Loss: 14871.428711\n",
      "Train Epoch: 41 [208512/225000 (93%)] Loss: 15094.131836\n",
      "Train Epoch: 41 [209920/225000 (93%)] Loss: 15276.061523\n",
      "Train Epoch: 41 [211328/225000 (94%)] Loss: 15190.683594\n",
      "Train Epoch: 41 [212736/225000 (95%)] Loss: 15165.975586\n",
      "Train Epoch: 41 [214144/225000 (95%)] Loss: 14675.784180\n",
      "Train Epoch: 41 [215552/225000 (96%)] Loss: 15149.572266\n",
      "Train Epoch: 41 [216960/225000 (96%)] Loss: 14991.315430\n",
      "Train Epoch: 41 [218368/225000 (97%)] Loss: 15076.431641\n",
      "Train Epoch: 41 [219776/225000 (98%)] Loss: 14918.607422\n",
      "Train Epoch: 41 [221184/225000 (98%)] Loss: 15018.278320\n",
      "Train Epoch: 41 [222592/225000 (99%)] Loss: 14810.681641\n",
      "Train Epoch: 41 [224000/225000 (100%)] Loss: 15246.028320\n",
      "    epoch          : 41\n",
      "    loss           : 15078.351518615793\n",
      "    val_loss       : 15071.475080577391\n",
      "Train Epoch: 42 [128/225000 (0%)] Loss: 15084.545898\n",
      "Train Epoch: 42 [1536/225000 (1%)] Loss: 15195.923828\n",
      "Train Epoch: 42 [2944/225000 (1%)] Loss: 14675.600586\n",
      "Train Epoch: 42 [4352/225000 (2%)] Loss: 15028.269531\n",
      "Train Epoch: 42 [5760/225000 (3%)] Loss: 15196.896484\n",
      "Train Epoch: 42 [7168/225000 (3%)] Loss: 14882.486328\n",
      "Train Epoch: 42 [8576/225000 (4%)] Loss: 14706.166992\n",
      "Train Epoch: 42 [9984/225000 (4%)] Loss: 14431.653320\n",
      "Train Epoch: 42 [11392/225000 (5%)] Loss: 14914.032227\n",
      "Train Epoch: 42 [12800/225000 (6%)] Loss: 15230.762695\n",
      "Train Epoch: 42 [14208/225000 (6%)] Loss: 14855.097656\n",
      "Train Epoch: 42 [15616/225000 (7%)] Loss: 15215.853516\n",
      "Train Epoch: 42 [17024/225000 (8%)] Loss: 15175.693359\n",
      "Train Epoch: 42 [18432/225000 (8%)] Loss: 14831.394531\n",
      "Train Epoch: 42 [19840/225000 (9%)] Loss: 15223.146484\n",
      "Train Epoch: 42 [21248/225000 (9%)] Loss: 15391.565430\n",
      "Train Epoch: 42 [22656/225000 (10%)] Loss: 15106.737305\n",
      "Train Epoch: 42 [24064/225000 (11%)] Loss: 15269.963867\n",
      "Train Epoch: 42 [25472/225000 (11%)] Loss: 15096.870117\n",
      "Train Epoch: 42 [26880/225000 (12%)] Loss: 15143.744141\n",
      "Train Epoch: 42 [28288/225000 (13%)] Loss: 15196.152344\n",
      "Train Epoch: 42 [29696/225000 (13%)] Loss: 14852.970703\n",
      "Train Epoch: 42 [31104/225000 (14%)] Loss: 15340.522461\n",
      "Train Epoch: 42 [32512/225000 (14%)] Loss: 15460.721680\n",
      "Train Epoch: 42 [33920/225000 (15%)] Loss: 15912.969727\n",
      "Train Epoch: 42 [35328/225000 (16%)] Loss: 15118.953125\n",
      "Train Epoch: 42 [36736/225000 (16%)] Loss: 15196.848633\n",
      "Train Epoch: 42 [38144/225000 (17%)] Loss: 14985.727539\n",
      "Train Epoch: 42 [39552/225000 (18%)] Loss: 14862.967773\n",
      "Train Epoch: 42 [40960/225000 (18%)] Loss: 15144.370117\n",
      "Train Epoch: 42 [42368/225000 (19%)] Loss: 15367.073242\n",
      "Train Epoch: 42 [43776/225000 (19%)] Loss: 15123.274414\n",
      "Train Epoch: 42 [45184/225000 (20%)] Loss: 14966.333984\n",
      "Train Epoch: 42 [46592/225000 (21%)] Loss: 15020.653320\n",
      "Train Epoch: 42 [48000/225000 (21%)] Loss: 14724.467773\n",
      "Train Epoch: 42 [49408/225000 (22%)] Loss: 15585.524414\n",
      "Train Epoch: 42 [50816/225000 (23%)] Loss: 14590.493164\n",
      "Train Epoch: 42 [52224/225000 (23%)] Loss: 14810.535156\n",
      "Train Epoch: 42 [53632/225000 (24%)] Loss: 15250.961914\n",
      "Train Epoch: 42 [55040/225000 (24%)] Loss: 15102.563477\n",
      "Train Epoch: 42 [56448/225000 (25%)] Loss: 14908.942383\n",
      "Train Epoch: 42 [57856/225000 (26%)] Loss: 15058.478516\n",
      "Train Epoch: 42 [59264/225000 (26%)] Loss: 14725.067383\n",
      "Train Epoch: 42 [60672/225000 (27%)] Loss: 15523.510742\n",
      "Train Epoch: 42 [62080/225000 (28%)] Loss: 15522.119141\n",
      "Train Epoch: 42 [63488/225000 (28%)] Loss: 14890.123047\n",
      "Train Epoch: 42 [64896/225000 (29%)] Loss: 15196.295898\n",
      "Train Epoch: 42 [66304/225000 (29%)] Loss: 14762.045898\n",
      "Train Epoch: 42 [67712/225000 (30%)] Loss: 14748.398438\n",
      "Train Epoch: 42 [69120/225000 (31%)] Loss: 15569.167969\n",
      "Train Epoch: 42 [70528/225000 (31%)] Loss: 14703.791016\n",
      "Train Epoch: 42 [71936/225000 (32%)] Loss: 15321.332031\n",
      "Train Epoch: 42 [73344/225000 (33%)] Loss: 15159.080078\n",
      "Train Epoch: 42 [74752/225000 (33%)] Loss: 15029.357422\n",
      "Train Epoch: 42 [76160/225000 (34%)] Loss: 14580.348633\n",
      "Train Epoch: 42 [77568/225000 (34%)] Loss: 15299.919922\n",
      "Train Epoch: 42 [78976/225000 (35%)] Loss: 14998.814453\n",
      "Train Epoch: 42 [80384/225000 (36%)] Loss: 15395.298828\n",
      "Train Epoch: 42 [81792/225000 (36%)] Loss: 15451.192383\n",
      "Train Epoch: 42 [83200/225000 (37%)] Loss: 14967.800781\n",
      "Train Epoch: 42 [84608/225000 (38%)] Loss: 15010.449219\n",
      "Train Epoch: 42 [86016/225000 (38%)] Loss: 15316.443359\n",
      "Train Epoch: 42 [87424/225000 (39%)] Loss: 14977.856445\n",
      "Train Epoch: 42 [88832/225000 (39%)] Loss: 15228.104492\n",
      "Train Epoch: 42 [90240/225000 (40%)] Loss: 14792.735352\n",
      "Train Epoch: 42 [91648/225000 (41%)] Loss: 15197.802734\n",
      "Train Epoch: 42 [93056/225000 (41%)] Loss: 15229.536133\n",
      "Train Epoch: 42 [94464/225000 (42%)] Loss: 15488.711914\n",
      "Train Epoch: 42 [95872/225000 (43%)] Loss: 15007.506836\n",
      "Train Epoch: 42 [97280/225000 (43%)] Loss: 15036.806641\n",
      "Train Epoch: 42 [98688/225000 (44%)] Loss: 14797.475586\n",
      "Train Epoch: 42 [100096/225000 (44%)] Loss: 15005.507812\n",
      "Train Epoch: 42 [101504/225000 (45%)] Loss: 15040.935547\n",
      "Train Epoch: 42 [102912/225000 (46%)] Loss: 14606.308594\n",
      "Train Epoch: 42 [104320/225000 (46%)] Loss: 15225.384766\n",
      "Train Epoch: 42 [105728/225000 (47%)] Loss: 14866.340820\n",
      "Train Epoch: 42 [107136/225000 (48%)] Loss: 15356.762695\n",
      "Train Epoch: 42 [108544/225000 (48%)] Loss: 15013.144531\n",
      "Train Epoch: 42 [109952/225000 (49%)] Loss: 14548.333008\n",
      "Train Epoch: 42 [111360/225000 (49%)] Loss: 15415.685547\n",
      "Train Epoch: 42 [112768/225000 (50%)] Loss: 15421.603516\n",
      "Train Epoch: 42 [114176/225000 (51%)] Loss: 15185.516602\n",
      "Train Epoch: 42 [115584/225000 (51%)] Loss: 15058.783203\n",
      "Train Epoch: 42 [116992/225000 (52%)] Loss: 14869.544922\n",
      "Train Epoch: 42 [118400/225000 (53%)] Loss: 15263.746094\n",
      "Train Epoch: 42 [119808/225000 (53%)] Loss: 15028.316406\n",
      "Train Epoch: 42 [121216/225000 (54%)] Loss: 15088.109375\n",
      "Train Epoch: 42 [122624/225000 (54%)] Loss: 15351.881836\n",
      "Train Epoch: 42 [124032/225000 (55%)] Loss: 14739.635742\n",
      "Train Epoch: 42 [125440/225000 (56%)] Loss: 14644.811523\n",
      "Train Epoch: 42 [126848/225000 (56%)] Loss: 14545.010742\n",
      "Train Epoch: 42 [128256/225000 (57%)] Loss: 15036.056641\n",
      "Train Epoch: 42 [129664/225000 (58%)] Loss: 14713.967773\n",
      "Train Epoch: 42 [131072/225000 (58%)] Loss: 15100.450195\n",
      "Train Epoch: 42 [132480/225000 (59%)] Loss: 15104.837891\n",
      "Train Epoch: 42 [133888/225000 (60%)] Loss: 15437.207031\n",
      "Train Epoch: 42 [135296/225000 (60%)] Loss: 14439.936523\n",
      "Train Epoch: 42 [136704/225000 (61%)] Loss: 15084.526367\n",
      "Train Epoch: 42 [138112/225000 (61%)] Loss: 15029.124023\n",
      "Train Epoch: 42 [139520/225000 (62%)] Loss: 15053.187500\n",
      "Train Epoch: 42 [140928/225000 (63%)] Loss: 15237.397461\n",
      "Train Epoch: 42 [142336/225000 (63%)] Loss: 15205.224609\n",
      "Train Epoch: 42 [143744/225000 (64%)] Loss: 14530.456055\n",
      "Train Epoch: 42 [145152/225000 (65%)] Loss: 14875.995117\n",
      "Train Epoch: 42 [146560/225000 (65%)] Loss: 15037.783203\n",
      "Train Epoch: 42 [147968/225000 (66%)] Loss: 15094.590820\n",
      "Train Epoch: 42 [149376/225000 (66%)] Loss: 14414.295898\n",
      "Train Epoch: 42 [150784/225000 (67%)] Loss: 15035.166992\n",
      "Train Epoch: 42 [152192/225000 (68%)] Loss: 14947.973633\n",
      "Train Epoch: 42 [153600/225000 (68%)] Loss: 15736.078125\n",
      "Train Epoch: 42 [155008/225000 (69%)] Loss: 15453.632812\n",
      "Train Epoch: 42 [156416/225000 (70%)] Loss: 15019.321289\n",
      "Train Epoch: 42 [157824/225000 (70%)] Loss: 14923.272461\n",
      "Train Epoch: 42 [159232/225000 (71%)] Loss: 15326.041016\n",
      "Train Epoch: 42 [160640/225000 (71%)] Loss: 15015.095703\n",
      "Train Epoch: 42 [162048/225000 (72%)] Loss: 15025.949219\n",
      "Train Epoch: 42 [163456/225000 (73%)] Loss: 15302.633789\n",
      "Train Epoch: 42 [164864/225000 (73%)] Loss: 14911.879883\n",
      "Train Epoch: 42 [166272/225000 (74%)] Loss: 14752.052734\n",
      "Train Epoch: 42 [167680/225000 (75%)] Loss: 15127.987305\n",
      "Train Epoch: 42 [169088/225000 (75%)] Loss: 15330.404297\n",
      "Train Epoch: 42 [170496/225000 (76%)] Loss: 15037.264648\n",
      "Train Epoch: 42 [171904/225000 (76%)] Loss: 14863.964844\n",
      "Train Epoch: 42 [173312/225000 (77%)] Loss: 15276.525391\n",
      "Train Epoch: 42 [174720/225000 (78%)] Loss: 15240.270508\n",
      "Train Epoch: 42 [176128/225000 (78%)] Loss: 14609.106445\n",
      "Train Epoch: 42 [177536/225000 (79%)] Loss: 15038.824219\n",
      "Train Epoch: 42 [178944/225000 (80%)] Loss: 15408.780273\n",
      "Train Epoch: 42 [180352/225000 (80%)] Loss: 15188.100586\n",
      "Train Epoch: 42 [181760/225000 (81%)] Loss: 14981.184570\n",
      "Train Epoch: 42 [183168/225000 (81%)] Loss: 14793.302734\n",
      "Train Epoch: 42 [184576/225000 (82%)] Loss: 15462.093750\n",
      "Train Epoch: 42 [185984/225000 (83%)] Loss: 15228.638672\n",
      "Train Epoch: 42 [187392/225000 (83%)] Loss: 15375.815430\n",
      "Train Epoch: 42 [188800/225000 (84%)] Loss: 14868.731445\n",
      "Train Epoch: 42 [190208/225000 (85%)] Loss: 15131.251953\n",
      "Train Epoch: 42 [191616/225000 (85%)] Loss: 15209.676758\n",
      "Train Epoch: 42 [193024/225000 (86%)] Loss: 14859.919922\n",
      "Train Epoch: 42 [194432/225000 (86%)] Loss: 15408.196289\n",
      "Train Epoch: 42 [195840/225000 (87%)] Loss: 14793.188477\n",
      "Train Epoch: 42 [197248/225000 (88%)] Loss: 15051.278320\n",
      "Train Epoch: 42 [198656/225000 (88%)] Loss: 14663.546875\n",
      "Train Epoch: 42 [200064/225000 (89%)] Loss: 15250.539062\n",
      "Train Epoch: 42 [201472/225000 (90%)] Loss: 15585.577148\n",
      "Train Epoch: 42 [202880/225000 (90%)] Loss: 14957.806641\n",
      "Train Epoch: 42 [204288/225000 (91%)] Loss: 15020.405273\n",
      "Train Epoch: 42 [205696/225000 (91%)] Loss: 15001.458008\n",
      "Train Epoch: 42 [207104/225000 (92%)] Loss: 15275.079102\n",
      "Train Epoch: 42 [208512/225000 (93%)] Loss: 15015.401367\n",
      "Train Epoch: 42 [209920/225000 (93%)] Loss: 15223.681641\n",
      "Train Epoch: 42 [211328/225000 (94%)] Loss: 14944.351562\n",
      "Train Epoch: 42 [212736/225000 (95%)] Loss: 15268.246094\n",
      "Train Epoch: 42 [214144/225000 (95%)] Loss: 15646.076172\n",
      "Train Epoch: 42 [215552/225000 (96%)] Loss: 15715.111328\n",
      "Train Epoch: 42 [216960/225000 (96%)] Loss: 15015.330078\n",
      "Train Epoch: 42 [218368/225000 (97%)] Loss: 14912.973633\n",
      "Train Epoch: 42 [219776/225000 (98%)] Loss: 15514.621094\n",
      "Train Epoch: 42 [221184/225000 (98%)] Loss: 14849.845703\n",
      "Train Epoch: 42 [222592/225000 (99%)] Loss: 15575.890625\n",
      "Train Epoch: 42 [224000/225000 (100%)] Loss: 15489.975586\n",
      "    epoch          : 42\n",
      "    loss           : 15077.304944694788\n",
      "    val_loss       : 15067.405645524817\n",
      "Train Epoch: 43 [128/225000 (0%)] Loss: 14480.378906\n",
      "Train Epoch: 43 [1536/225000 (1%)] Loss: 14933.865234\n",
      "Train Epoch: 43 [2944/225000 (1%)] Loss: 15107.349609\n",
      "Train Epoch: 43 [4352/225000 (2%)] Loss: 14867.445312\n",
      "Train Epoch: 43 [5760/225000 (3%)] Loss: 14970.160156\n",
      "Train Epoch: 43 [7168/225000 (3%)] Loss: 15454.703125\n",
      "Train Epoch: 43 [8576/225000 (4%)] Loss: 15305.258789\n",
      "Train Epoch: 43 [9984/225000 (4%)] Loss: 14975.522461\n",
      "Train Epoch: 43 [11392/225000 (5%)] Loss: 14670.199219\n",
      "Train Epoch: 43 [12800/225000 (6%)] Loss: 15006.742188\n",
      "Train Epoch: 43 [14208/225000 (6%)] Loss: 15369.187500\n",
      "Train Epoch: 43 [15616/225000 (7%)] Loss: 14957.084961\n",
      "Train Epoch: 43 [17024/225000 (8%)] Loss: 15410.875977\n",
      "Train Epoch: 43 [18432/225000 (8%)] Loss: 15236.064453\n",
      "Train Epoch: 43 [19840/225000 (9%)] Loss: 14844.337891\n",
      "Train Epoch: 43 [21248/225000 (9%)] Loss: 14549.794922\n",
      "Train Epoch: 43 [22656/225000 (10%)] Loss: 14971.611328\n",
      "Train Epoch: 43 [24064/225000 (11%)] Loss: 14918.868164\n",
      "Train Epoch: 43 [25472/225000 (11%)] Loss: 15165.207031\n",
      "Train Epoch: 43 [26880/225000 (12%)] Loss: 15120.102539\n",
      "Train Epoch: 43 [28288/225000 (13%)] Loss: 15106.333984\n",
      "Train Epoch: 43 [29696/225000 (13%)] Loss: 14785.893555\n",
      "Train Epoch: 43 [31104/225000 (14%)] Loss: 15189.245117\n",
      "Train Epoch: 43 [32512/225000 (14%)] Loss: 14784.156250\n",
      "Train Epoch: 43 [33920/225000 (15%)] Loss: 15357.364258\n",
      "Train Epoch: 43 [35328/225000 (16%)] Loss: 14901.142578\n",
      "Train Epoch: 43 [36736/225000 (16%)] Loss: 15004.733398\n",
      "Train Epoch: 43 [38144/225000 (17%)] Loss: 15061.645508\n",
      "Train Epoch: 43 [39552/225000 (18%)] Loss: 14688.417969\n",
      "Train Epoch: 43 [40960/225000 (18%)] Loss: 14916.902344\n",
      "Train Epoch: 43 [42368/225000 (19%)] Loss: 14939.853516\n",
      "Train Epoch: 43 [43776/225000 (19%)] Loss: 15018.451172\n",
      "Train Epoch: 43 [45184/225000 (20%)] Loss: 14814.413086\n",
      "Train Epoch: 43 [46592/225000 (21%)] Loss: 15244.519531\n",
      "Train Epoch: 43 [48000/225000 (21%)] Loss: 15328.354492\n",
      "Train Epoch: 43 [49408/225000 (22%)] Loss: 15118.925781\n",
      "Train Epoch: 43 [50816/225000 (23%)] Loss: 14889.621094\n",
      "Train Epoch: 43 [52224/225000 (23%)] Loss: 15025.771484\n",
      "Train Epoch: 43 [53632/225000 (24%)] Loss: 15535.869141\n",
      "Train Epoch: 43 [55040/225000 (24%)] Loss: 15056.779297\n",
      "Train Epoch: 43 [56448/225000 (25%)] Loss: 14868.537109\n",
      "Train Epoch: 43 [57856/225000 (26%)] Loss: 15078.488281\n",
      "Train Epoch: 43 [59264/225000 (26%)] Loss: 15127.818359\n",
      "Train Epoch: 43 [60672/225000 (27%)] Loss: 15220.966797\n",
      "Train Epoch: 43 [62080/225000 (28%)] Loss: 14693.659180\n",
      "Train Epoch: 43 [63488/225000 (28%)] Loss: 15479.342773\n",
      "Train Epoch: 43 [64896/225000 (29%)] Loss: 15233.845703\n",
      "Train Epoch: 43 [66304/225000 (29%)] Loss: 14921.282227\n",
      "Train Epoch: 43 [67712/225000 (30%)] Loss: 15223.640625\n",
      "Train Epoch: 43 [69120/225000 (31%)] Loss: 14639.980469\n",
      "Train Epoch: 43 [70528/225000 (31%)] Loss: 14979.037109\n",
      "Train Epoch: 43 [71936/225000 (32%)] Loss: 15421.135742\n",
      "Train Epoch: 43 [73344/225000 (33%)] Loss: 15273.546875\n",
      "Train Epoch: 43 [74752/225000 (33%)] Loss: 15268.886719\n",
      "Train Epoch: 43 [76160/225000 (34%)] Loss: 15349.625977\n",
      "Train Epoch: 43 [77568/225000 (34%)] Loss: 14970.989258\n",
      "Train Epoch: 43 [78976/225000 (35%)] Loss: 15118.170898\n",
      "Train Epoch: 43 [80384/225000 (36%)] Loss: 15082.491211\n",
      "Train Epoch: 43 [81792/225000 (36%)] Loss: 14788.255859\n",
      "Train Epoch: 43 [83200/225000 (37%)] Loss: 14667.613281\n",
      "Train Epoch: 43 [84608/225000 (38%)] Loss: 15164.815430\n",
      "Train Epoch: 43 [86016/225000 (38%)] Loss: 14621.827148\n",
      "Train Epoch: 43 [87424/225000 (39%)] Loss: 15350.200195\n",
      "Train Epoch: 43 [88832/225000 (39%)] Loss: 15713.237305\n",
      "Train Epoch: 43 [90240/225000 (40%)] Loss: 14769.446289\n",
      "Train Epoch: 43 [91648/225000 (41%)] Loss: 15110.094727\n",
      "Train Epoch: 43 [93056/225000 (41%)] Loss: 15059.893555\n",
      "Train Epoch: 43 [94464/225000 (42%)] Loss: 15411.513672\n",
      "Train Epoch: 43 [95872/225000 (43%)] Loss: 15506.387695\n",
      "Train Epoch: 43 [97280/225000 (43%)] Loss: 14783.704102\n",
      "Train Epoch: 43 [98688/225000 (44%)] Loss: 15096.749023\n",
      "Train Epoch: 43 [100096/225000 (44%)] Loss: 14791.287109\n",
      "Train Epoch: 43 [101504/225000 (45%)] Loss: 15357.899414\n",
      "Train Epoch: 43 [102912/225000 (46%)] Loss: 14796.348633\n",
      "Train Epoch: 43 [104320/225000 (46%)] Loss: 15525.760742\n",
      "Train Epoch: 43 [105728/225000 (47%)] Loss: 15552.245117\n",
      "Train Epoch: 43 [107136/225000 (48%)] Loss: 15068.458984\n",
      "Train Epoch: 43 [108544/225000 (48%)] Loss: 15247.659180\n",
      "Train Epoch: 43 [109952/225000 (49%)] Loss: 15508.932617\n",
      "Train Epoch: 43 [111360/225000 (49%)] Loss: 15374.097656\n",
      "Train Epoch: 43 [112768/225000 (50%)] Loss: 14803.301758\n",
      "Train Epoch: 43 [114176/225000 (51%)] Loss: 15105.260742\n",
      "Train Epoch: 43 [115584/225000 (51%)] Loss: 15136.726562\n",
      "Train Epoch: 43 [116992/225000 (52%)] Loss: 15291.015625\n",
      "Train Epoch: 43 [118400/225000 (53%)] Loss: 15801.239258\n",
      "Train Epoch: 43 [119808/225000 (53%)] Loss: 14910.232422\n",
      "Train Epoch: 43 [121216/225000 (54%)] Loss: 15265.118164\n",
      "Train Epoch: 43 [122624/225000 (54%)] Loss: 15311.874023\n",
      "Train Epoch: 43 [124032/225000 (55%)] Loss: 14925.667969\n",
      "Train Epoch: 43 [125440/225000 (56%)] Loss: 15109.239258\n",
      "Train Epoch: 43 [126848/225000 (56%)] Loss: 14653.012695\n",
      "Train Epoch: 43 [128256/225000 (57%)] Loss: 15382.750977\n",
      "Train Epoch: 43 [129664/225000 (58%)] Loss: 15122.837891\n",
      "Train Epoch: 43 [131072/225000 (58%)] Loss: 15135.669922\n",
      "Train Epoch: 43 [132480/225000 (59%)] Loss: 15013.719727\n",
      "Train Epoch: 43 [133888/225000 (60%)] Loss: 15400.559570\n",
      "Train Epoch: 43 [135296/225000 (60%)] Loss: 15218.422852\n",
      "Train Epoch: 43 [136704/225000 (61%)] Loss: 14953.019531\n",
      "Train Epoch: 43 [138112/225000 (61%)] Loss: 15077.138672\n",
      "Train Epoch: 43 [139520/225000 (62%)] Loss: 14851.587891\n",
      "Train Epoch: 43 [140928/225000 (63%)] Loss: 14867.274414\n",
      "Train Epoch: 43 [142336/225000 (63%)] Loss: 15271.124023\n",
      "Train Epoch: 43 [143744/225000 (64%)] Loss: 15216.753906\n",
      "Train Epoch: 43 [145152/225000 (65%)] Loss: 14975.184570\n",
      "Train Epoch: 43 [146560/225000 (65%)] Loss: 14962.433594\n",
      "Train Epoch: 43 [147968/225000 (66%)] Loss: 14710.218750\n",
      "Train Epoch: 43 [149376/225000 (66%)] Loss: 14977.163086\n",
      "Train Epoch: 43 [150784/225000 (67%)] Loss: 14809.831055\n",
      "Train Epoch: 43 [152192/225000 (68%)] Loss: 15391.244141\n",
      "Train Epoch: 43 [153600/225000 (68%)] Loss: 15225.199219\n",
      "Train Epoch: 43 [155008/225000 (69%)] Loss: 15238.539062\n",
      "Train Epoch: 43 [156416/225000 (70%)] Loss: 14943.927734\n",
      "Train Epoch: 43 [157824/225000 (70%)] Loss: 14957.312500\n",
      "Train Epoch: 43 [159232/225000 (71%)] Loss: 14873.301758\n",
      "Train Epoch: 43 [160640/225000 (71%)] Loss: 15050.957031\n",
      "Train Epoch: 43 [162048/225000 (72%)] Loss: 15239.769531\n",
      "Train Epoch: 43 [163456/225000 (73%)] Loss: 15039.665039\n",
      "Train Epoch: 43 [164864/225000 (73%)] Loss: 15620.788086\n",
      "Train Epoch: 43 [166272/225000 (74%)] Loss: 14999.344727\n",
      "Train Epoch: 43 [167680/225000 (75%)] Loss: 14964.422852\n",
      "Train Epoch: 43 [169088/225000 (75%)] Loss: 15829.426758\n",
      "Train Epoch: 43 [170496/225000 (76%)] Loss: 15316.459961\n",
      "Train Epoch: 43 [171904/225000 (76%)] Loss: 15379.170898\n",
      "Train Epoch: 43 [173312/225000 (77%)] Loss: 14874.075195\n",
      "Train Epoch: 43 [174720/225000 (78%)] Loss: 15078.785156\n",
      "Train Epoch: 43 [176128/225000 (78%)] Loss: 15136.766602\n",
      "Train Epoch: 43 [177536/225000 (79%)] Loss: 14740.980469\n",
      "Train Epoch: 43 [178944/225000 (80%)] Loss: 14705.285156\n",
      "Train Epoch: 43 [180352/225000 (80%)] Loss: 14623.175781\n",
      "Train Epoch: 43 [181760/225000 (81%)] Loss: 15379.622070\n",
      "Train Epoch: 43 [183168/225000 (81%)] Loss: 15116.655273\n",
      "Train Epoch: 43 [184576/225000 (82%)] Loss: 14982.723633\n",
      "Train Epoch: 43 [185984/225000 (83%)] Loss: 14921.038086\n",
      "Train Epoch: 43 [187392/225000 (83%)] Loss: 15063.266602\n",
      "Train Epoch: 43 [188800/225000 (84%)] Loss: 15360.683594\n",
      "Train Epoch: 43 [190208/225000 (85%)] Loss: 15456.650391\n",
      "Train Epoch: 43 [191616/225000 (85%)] Loss: 14674.804688\n",
      "Train Epoch: 43 [193024/225000 (86%)] Loss: 14708.951172\n",
      "Train Epoch: 43 [194432/225000 (86%)] Loss: 15100.584961\n",
      "Train Epoch: 43 [195840/225000 (87%)] Loss: 15136.518555\n",
      "Train Epoch: 43 [197248/225000 (88%)] Loss: 15111.474609\n",
      "Train Epoch: 43 [198656/225000 (88%)] Loss: 15039.327148\n",
      "Train Epoch: 43 [200064/225000 (89%)] Loss: 15292.153320\n",
      "Train Epoch: 43 [201472/225000 (90%)] Loss: 15168.727539\n",
      "Train Epoch: 43 [202880/225000 (90%)] Loss: 14862.849609\n",
      "Train Epoch: 43 [204288/225000 (91%)] Loss: 15425.820312\n",
      "Train Epoch: 43 [205696/225000 (91%)] Loss: 15079.703125\n",
      "Train Epoch: 43 [207104/225000 (92%)] Loss: 14970.576172\n",
      "Train Epoch: 43 [208512/225000 (93%)] Loss: 15275.062500\n",
      "Train Epoch: 43 [209920/225000 (93%)] Loss: 14903.136719\n",
      "Train Epoch: 43 [211328/225000 (94%)] Loss: 15271.040039\n",
      "Train Epoch: 43 [212736/225000 (95%)] Loss: 14983.412109\n",
      "Train Epoch: 43 [214144/225000 (95%)] Loss: 15018.470703\n",
      "Train Epoch: 43 [215552/225000 (96%)] Loss: 14832.865234\n",
      "Train Epoch: 43 [216960/225000 (96%)] Loss: 15172.646484\n",
      "Train Epoch: 43 [218368/225000 (97%)] Loss: 15204.105469\n",
      "Train Epoch: 43 [219776/225000 (98%)] Loss: 15281.604492\n",
      "Train Epoch: 43 [221184/225000 (98%)] Loss: 15235.863281\n",
      "Train Epoch: 43 [222592/225000 (99%)] Loss: 15366.622070\n",
      "Train Epoch: 43 [224000/225000 (100%)] Loss: 15457.142578\n",
      "    epoch          : 43\n",
      "    loss           : 15079.004680056349\n",
      "    val_loss       : 15061.83675146924\n",
      "Train Epoch: 44 [128/225000 (0%)] Loss: 14916.269531\n",
      "Train Epoch: 44 [1536/225000 (1%)] Loss: 15088.145508\n",
      "Train Epoch: 44 [2944/225000 (1%)] Loss: 15292.646484\n",
      "Train Epoch: 44 [4352/225000 (2%)] Loss: 15278.963867\n",
      "Train Epoch: 44 [5760/225000 (3%)] Loss: 14889.472656\n",
      "Train Epoch: 44 [7168/225000 (3%)] Loss: 14810.920898\n",
      "Train Epoch: 44 [8576/225000 (4%)] Loss: 14446.369141\n",
      "Train Epoch: 44 [9984/225000 (4%)] Loss: 15646.818359\n",
      "Train Epoch: 44 [11392/225000 (5%)] Loss: 15114.973633\n",
      "Train Epoch: 44 [12800/225000 (6%)] Loss: 15152.286133\n",
      "Train Epoch: 44 [14208/225000 (6%)] Loss: 15218.642578\n",
      "Train Epoch: 44 [15616/225000 (7%)] Loss: 15212.287109\n",
      "Train Epoch: 44 [17024/225000 (8%)] Loss: 14934.443359\n",
      "Train Epoch: 44 [18432/225000 (8%)] Loss: 15025.726562\n",
      "Train Epoch: 44 [19840/225000 (9%)] Loss: 14691.895508\n",
      "Train Epoch: 44 [21248/225000 (9%)] Loss: 15160.629883\n",
      "Train Epoch: 44 [22656/225000 (10%)] Loss: 14836.336914\n",
      "Train Epoch: 44 [24064/225000 (11%)] Loss: 15330.487305\n",
      "Train Epoch: 44 [25472/225000 (11%)] Loss: 15305.833984\n",
      "Train Epoch: 44 [26880/225000 (12%)] Loss: 14806.646484\n",
      "Train Epoch: 44 [28288/225000 (13%)] Loss: 15393.189453\n",
      "Train Epoch: 44 [29696/225000 (13%)] Loss: 14867.439453\n",
      "Train Epoch: 44 [31104/225000 (14%)] Loss: 15341.427734\n",
      "Train Epoch: 44 [32512/225000 (14%)] Loss: 15159.658203\n",
      "Train Epoch: 44 [33920/225000 (15%)] Loss: 14810.105469\n",
      "Train Epoch: 44 [35328/225000 (16%)] Loss: 14986.835938\n",
      "Train Epoch: 44 [36736/225000 (16%)] Loss: 15078.730469\n",
      "Train Epoch: 44 [38144/225000 (17%)] Loss: 14978.818359\n",
      "Train Epoch: 44 [39552/225000 (18%)] Loss: 15105.685547\n",
      "Train Epoch: 44 [40960/225000 (18%)] Loss: 15126.612305\n",
      "Train Epoch: 44 [42368/225000 (19%)] Loss: 15164.784180\n",
      "Train Epoch: 44 [43776/225000 (19%)] Loss: 15135.719727\n",
      "Train Epoch: 44 [45184/225000 (20%)] Loss: 15016.142578\n",
      "Train Epoch: 44 [46592/225000 (21%)] Loss: 14606.527344\n",
      "Train Epoch: 44 [48000/225000 (21%)] Loss: 14888.886719\n",
      "Train Epoch: 44 [49408/225000 (22%)] Loss: 15074.048828\n",
      "Train Epoch: 44 [50816/225000 (23%)] Loss: 14548.177734\n",
      "Train Epoch: 44 [52224/225000 (23%)] Loss: 14903.757812\n",
      "Train Epoch: 44 [53632/225000 (24%)] Loss: 15082.203125\n",
      "Train Epoch: 44 [55040/225000 (24%)] Loss: 14984.085938\n",
      "Train Epoch: 44 [56448/225000 (25%)] Loss: 15213.415039\n",
      "Train Epoch: 44 [57856/225000 (26%)] Loss: 15342.338867\n",
      "Train Epoch: 44 [59264/225000 (26%)] Loss: 15488.766602\n",
      "Train Epoch: 44 [60672/225000 (27%)] Loss: 15246.112305\n",
      "Train Epoch: 44 [62080/225000 (28%)] Loss: 14906.533203\n",
      "Train Epoch: 44 [63488/225000 (28%)] Loss: 15197.625977\n",
      "Train Epoch: 44 [64896/225000 (29%)] Loss: 14982.034180\n",
      "Train Epoch: 44 [66304/225000 (29%)] Loss: 15102.810547\n",
      "Train Epoch: 44 [67712/225000 (30%)] Loss: 15206.227539\n",
      "Train Epoch: 44 [69120/225000 (31%)] Loss: 14970.495117\n",
      "Train Epoch: 44 [70528/225000 (31%)] Loss: 14781.498047\n",
      "Train Epoch: 44 [71936/225000 (32%)] Loss: 15385.365234\n",
      "Train Epoch: 44 [73344/225000 (33%)] Loss: 15131.818359\n",
      "Train Epoch: 44 [74752/225000 (33%)] Loss: 15288.309570\n",
      "Train Epoch: 44 [76160/225000 (34%)] Loss: 15074.276367\n",
      "Train Epoch: 44 [77568/225000 (34%)] Loss: 14727.120117\n",
      "Train Epoch: 44 [78976/225000 (35%)] Loss: 15254.986328\n",
      "Train Epoch: 44 [80384/225000 (36%)] Loss: 14967.349609\n",
      "Train Epoch: 44 [81792/225000 (36%)] Loss: 15349.507812\n",
      "Train Epoch: 44 [83200/225000 (37%)] Loss: 15094.643555\n",
      "Train Epoch: 44 [84608/225000 (38%)] Loss: 15075.116211\n",
      "Train Epoch: 44 [86016/225000 (38%)] Loss: 14708.237305\n",
      "Train Epoch: 44 [87424/225000 (39%)] Loss: 14849.126953\n",
      "Train Epoch: 44 [88832/225000 (39%)] Loss: 14728.440430\n",
      "Train Epoch: 44 [90240/225000 (40%)] Loss: 14986.727539\n",
      "Train Epoch: 44 [91648/225000 (41%)] Loss: 15248.639648\n",
      "Train Epoch: 44 [93056/225000 (41%)] Loss: 15423.141602\n",
      "Train Epoch: 44 [94464/225000 (42%)] Loss: 15029.009766\n",
      "Train Epoch: 44 [95872/225000 (43%)] Loss: 15002.202148\n",
      "Train Epoch: 44 [97280/225000 (43%)] Loss: 14822.204102\n",
      "Train Epoch: 44 [98688/225000 (44%)] Loss: 15295.919922\n",
      "Train Epoch: 44 [100096/225000 (44%)] Loss: 15005.381836\n",
      "Train Epoch: 44 [101504/225000 (45%)] Loss: 15357.884766\n",
      "Train Epoch: 44 [102912/225000 (46%)] Loss: 14933.544922\n",
      "Train Epoch: 44 [104320/225000 (46%)] Loss: 15112.443359\n",
      "Train Epoch: 44 [105728/225000 (47%)] Loss: 14756.165039\n",
      "Train Epoch: 44 [107136/225000 (48%)] Loss: 15129.425781\n",
      "Train Epoch: 44 [108544/225000 (48%)] Loss: 15348.892578\n",
      "Train Epoch: 44 [109952/225000 (49%)] Loss: 15190.606445\n",
      "Train Epoch: 44 [111360/225000 (49%)] Loss: 15071.805664\n",
      "Train Epoch: 44 [112768/225000 (50%)] Loss: 15044.436523\n",
      "Train Epoch: 44 [114176/225000 (51%)] Loss: 15156.144531\n",
      "Train Epoch: 44 [115584/225000 (51%)] Loss: 14918.920898\n",
      "Train Epoch: 44 [116992/225000 (52%)] Loss: 15300.380859\n",
      "Train Epoch: 44 [118400/225000 (53%)] Loss: 14586.067383\n",
      "Train Epoch: 44 [119808/225000 (53%)] Loss: 14906.027344\n",
      "Train Epoch: 44 [121216/225000 (54%)] Loss: 14845.383789\n",
      "Train Epoch: 44 [122624/225000 (54%)] Loss: 14601.891602\n",
      "Train Epoch: 44 [124032/225000 (55%)] Loss: 15010.895508\n",
      "Train Epoch: 44 [125440/225000 (56%)] Loss: 14825.685547\n",
      "Train Epoch: 44 [126848/225000 (56%)] Loss: 14953.691406\n",
      "Train Epoch: 44 [128256/225000 (57%)] Loss: 14953.098633\n",
      "Train Epoch: 44 [129664/225000 (58%)] Loss: 15428.228516\n",
      "Train Epoch: 44 [131072/225000 (58%)] Loss: 14992.000977\n",
      "Train Epoch: 44 [132480/225000 (59%)] Loss: 14992.106445\n",
      "Train Epoch: 44 [133888/225000 (60%)] Loss: 15147.618164\n",
      "Train Epoch: 44 [135296/225000 (60%)] Loss: 15281.657227\n",
      "Train Epoch: 44 [136704/225000 (61%)] Loss: 15159.281250\n",
      "Train Epoch: 44 [138112/225000 (61%)] Loss: 14802.265625\n",
      "Train Epoch: 44 [139520/225000 (62%)] Loss: 14742.588867\n",
      "Train Epoch: 44 [140928/225000 (63%)] Loss: 15285.148438\n",
      "Train Epoch: 44 [142336/225000 (63%)] Loss: 14954.469727\n",
      "Train Epoch: 44 [143744/225000 (64%)] Loss: 15155.028320\n",
      "Train Epoch: 44 [145152/225000 (65%)] Loss: 15305.987305\n",
      "Train Epoch: 44 [146560/225000 (65%)] Loss: 15206.593750\n",
      "Train Epoch: 44 [147968/225000 (66%)] Loss: 14604.786133\n",
      "Train Epoch: 44 [149376/225000 (66%)] Loss: 15104.443359\n",
      "Train Epoch: 44 [150784/225000 (67%)] Loss: 15303.348633\n",
      "Train Epoch: 44 [152192/225000 (68%)] Loss: 14933.282227\n",
      "Train Epoch: 44 [153600/225000 (68%)] Loss: 15493.366211\n",
      "Train Epoch: 44 [155008/225000 (69%)] Loss: 15033.852539\n",
      "Train Epoch: 44 [156416/225000 (70%)] Loss: 14561.655273\n",
      "Train Epoch: 44 [157824/225000 (70%)] Loss: 15323.280273\n",
      "Train Epoch: 44 [159232/225000 (71%)] Loss: 15269.004883\n",
      "Train Epoch: 44 [160640/225000 (71%)] Loss: 14947.068359\n",
      "Train Epoch: 44 [162048/225000 (72%)] Loss: 14822.573242\n",
      "Train Epoch: 44 [163456/225000 (73%)] Loss: 15463.904297\n",
      "Train Epoch: 44 [164864/225000 (73%)] Loss: 14859.966797\n",
      "Train Epoch: 44 [166272/225000 (74%)] Loss: 15218.752930\n",
      "Train Epoch: 44 [167680/225000 (75%)] Loss: 15158.075195\n",
      "Train Epoch: 44 [169088/225000 (75%)] Loss: 15253.517578\n",
      "Train Epoch: 44 [170496/225000 (76%)] Loss: 15361.607422\n",
      "Train Epoch: 44 [171904/225000 (76%)] Loss: 14961.009766\n",
      "Train Epoch: 44 [173312/225000 (77%)] Loss: 15204.121094\n",
      "Train Epoch: 44 [174720/225000 (78%)] Loss: 15008.074219\n",
      "Train Epoch: 44 [176128/225000 (78%)] Loss: 14655.593750\n",
      "Train Epoch: 44 [177536/225000 (79%)] Loss: 14858.685547\n",
      "Train Epoch: 44 [178944/225000 (80%)] Loss: 14993.797852\n",
      "Train Epoch: 44 [180352/225000 (80%)] Loss: 15083.555664\n",
      "Train Epoch: 44 [181760/225000 (81%)] Loss: 14912.861328\n",
      "Train Epoch: 44 [183168/225000 (81%)] Loss: 15098.899414\n",
      "Train Epoch: 44 [184576/225000 (82%)] Loss: 15400.361328\n",
      "Train Epoch: 44 [185984/225000 (83%)] Loss: 15108.875977\n",
      "Train Epoch: 44 [187392/225000 (83%)] Loss: 15344.817383\n",
      "Train Epoch: 44 [188800/225000 (84%)] Loss: 14735.655273\n",
      "Train Epoch: 44 [190208/225000 (85%)] Loss: 15643.890625\n",
      "Train Epoch: 44 [191616/225000 (85%)] Loss: 15161.040039\n",
      "Train Epoch: 44 [193024/225000 (86%)] Loss: 14883.276367\n",
      "Train Epoch: 44 [194432/225000 (86%)] Loss: 15305.045898\n",
      "Train Epoch: 44 [195840/225000 (87%)] Loss: 15449.488281\n",
      "Train Epoch: 44 [197248/225000 (88%)] Loss: 15614.998047\n",
      "Train Epoch: 44 [198656/225000 (88%)] Loss: 14966.329102\n",
      "Train Epoch: 44 [200064/225000 (89%)] Loss: 14799.338867\n",
      "Train Epoch: 44 [201472/225000 (90%)] Loss: 14917.302734\n",
      "Train Epoch: 44 [202880/225000 (90%)] Loss: 15538.598633\n",
      "Train Epoch: 44 [204288/225000 (91%)] Loss: 14628.692383\n",
      "Train Epoch: 44 [205696/225000 (91%)] Loss: 15763.000000\n",
      "Train Epoch: 44 [207104/225000 (92%)] Loss: 15032.472656\n",
      "Train Epoch: 44 [208512/225000 (93%)] Loss: 15216.355469\n",
      "Train Epoch: 44 [209920/225000 (93%)] Loss: 15111.545898\n",
      "Train Epoch: 44 [211328/225000 (94%)] Loss: 14883.466797\n",
      "Train Epoch: 44 [212736/225000 (95%)] Loss: 14993.146484\n",
      "Train Epoch: 44 [214144/225000 (95%)] Loss: 15102.774414\n",
      "Train Epoch: 44 [215552/225000 (96%)] Loss: 14983.701172\n",
      "Train Epoch: 44 [216960/225000 (96%)] Loss: 15241.698242\n",
      "Train Epoch: 44 [218368/225000 (97%)] Loss: 15139.482422\n",
      "Train Epoch: 44 [219776/225000 (98%)] Loss: 14775.401367\n",
      "Train Epoch: 44 [221184/225000 (98%)] Loss: 15643.616211\n",
      "Train Epoch: 44 [222592/225000 (99%)] Loss: 14906.079102\n",
      "Train Epoch: 44 [224000/225000 (100%)] Loss: 15216.303711\n",
      "    epoch          : 44\n",
      "    loss           : 15077.443539911299\n",
      "    val_loss       : 15061.060647095801\n",
      "Train Epoch: 45 [128/225000 (0%)] Loss: 15359.791992\n",
      "Train Epoch: 45 [1536/225000 (1%)] Loss: 15356.264648\n",
      "Train Epoch: 45 [2944/225000 (1%)] Loss: 15480.474609\n",
      "Train Epoch: 45 [4352/225000 (2%)] Loss: 15630.958008\n",
      "Train Epoch: 45 [5760/225000 (3%)] Loss: 14789.950195\n",
      "Train Epoch: 45 [7168/225000 (3%)] Loss: 15024.110352\n",
      "Train Epoch: 45 [8576/225000 (4%)] Loss: 14760.366211\n",
      "Train Epoch: 45 [9984/225000 (4%)] Loss: 15503.306641\n",
      "Train Epoch: 45 [11392/225000 (5%)] Loss: 14926.372070\n",
      "Train Epoch: 45 [12800/225000 (6%)] Loss: 14838.543945\n",
      "Train Epoch: 45 [14208/225000 (6%)] Loss: 15293.032227\n",
      "Train Epoch: 45 [15616/225000 (7%)] Loss: 15028.122070\n",
      "Train Epoch: 45 [17024/225000 (8%)] Loss: 14900.612305\n",
      "Train Epoch: 45 [18432/225000 (8%)] Loss: 15019.370117\n",
      "Train Epoch: 45 [19840/225000 (9%)] Loss: 15113.279297\n",
      "Train Epoch: 45 [21248/225000 (9%)] Loss: 15192.861328\n",
      "Train Epoch: 45 [22656/225000 (10%)] Loss: 15100.794922\n",
      "Train Epoch: 45 [24064/225000 (11%)] Loss: 15046.993164\n",
      "Train Epoch: 45 [25472/225000 (11%)] Loss: 15067.153320\n",
      "Train Epoch: 45 [26880/225000 (12%)] Loss: 15501.238281\n",
      "Train Epoch: 45 [28288/225000 (13%)] Loss: 14898.567383\n",
      "Train Epoch: 45 [29696/225000 (13%)] Loss: 15161.010742\n",
      "Train Epoch: 45 [31104/225000 (14%)] Loss: 15347.018555\n",
      "Train Epoch: 45 [32512/225000 (14%)] Loss: 15177.282227\n",
      "Train Epoch: 45 [33920/225000 (15%)] Loss: 15230.143555\n",
      "Train Epoch: 45 [35328/225000 (16%)] Loss: 15372.738281\n",
      "Train Epoch: 45 [36736/225000 (16%)] Loss: 15652.468750\n",
      "Train Epoch: 45 [38144/225000 (17%)] Loss: 15036.583008\n",
      "Train Epoch: 45 [39552/225000 (18%)] Loss: 14803.079102\n",
      "Train Epoch: 45 [40960/225000 (18%)] Loss: 15311.584961\n",
      "Train Epoch: 45 [42368/225000 (19%)] Loss: 14867.368164\n",
      "Train Epoch: 45 [43776/225000 (19%)] Loss: 15017.189453\n",
      "Train Epoch: 45 [45184/225000 (20%)] Loss: 15091.409180\n",
      "Train Epoch: 45 [46592/225000 (21%)] Loss: 15050.543945\n",
      "Train Epoch: 45 [48000/225000 (21%)] Loss: 15339.504883\n",
      "Train Epoch: 45 [49408/225000 (22%)] Loss: 15095.304688\n",
      "Train Epoch: 45 [50816/225000 (23%)] Loss: 14916.241211\n",
      "Train Epoch: 45 [52224/225000 (23%)] Loss: 15233.025391\n",
      "Train Epoch: 45 [53632/225000 (24%)] Loss: 14835.761719\n",
      "Train Epoch: 45 [55040/225000 (24%)] Loss: 15229.072266\n",
      "Train Epoch: 45 [56448/225000 (25%)] Loss: 14806.143555\n",
      "Train Epoch: 45 [57856/225000 (26%)] Loss: 15676.192383\n",
      "Train Epoch: 45 [59264/225000 (26%)] Loss: 15208.877930\n",
      "Train Epoch: 45 [60672/225000 (27%)] Loss: 14906.727539\n",
      "Train Epoch: 45 [62080/225000 (28%)] Loss: 15083.908203\n",
      "Train Epoch: 45 [63488/225000 (28%)] Loss: 14866.404297\n",
      "Train Epoch: 45 [64896/225000 (29%)] Loss: 15048.688477\n",
      "Train Epoch: 45 [66304/225000 (29%)] Loss: 14795.801758\n",
      "Train Epoch: 45 [67712/225000 (30%)] Loss: 15120.916992\n",
      "Train Epoch: 45 [69120/225000 (31%)] Loss: 15189.367188\n",
      "Train Epoch: 45 [70528/225000 (31%)] Loss: 15110.385742\n",
      "Train Epoch: 45 [71936/225000 (32%)] Loss: 15428.742188\n",
      "Train Epoch: 45 [73344/225000 (33%)] Loss: 14877.036133\n",
      "Train Epoch: 45 [74752/225000 (33%)] Loss: 15093.208008\n",
      "Train Epoch: 45 [76160/225000 (34%)] Loss: 15014.099609\n",
      "Train Epoch: 45 [77568/225000 (34%)] Loss: 15233.345703\n",
      "Train Epoch: 45 [78976/225000 (35%)] Loss: 15044.490234\n",
      "Train Epoch: 45 [80384/225000 (36%)] Loss: 14909.384766\n",
      "Train Epoch: 45 [81792/225000 (36%)] Loss: 14735.106445\n",
      "Train Epoch: 45 [83200/225000 (37%)] Loss: 14781.175781\n",
      "Train Epoch: 45 [84608/225000 (38%)] Loss: 15251.464844\n",
      "Train Epoch: 45 [86016/225000 (38%)] Loss: 15088.642578\n",
      "Train Epoch: 45 [87424/225000 (39%)] Loss: 15398.902344\n",
      "Train Epoch: 45 [88832/225000 (39%)] Loss: 14797.442383\n",
      "Train Epoch: 45 [90240/225000 (40%)] Loss: 14775.873047\n",
      "Train Epoch: 45 [91648/225000 (41%)] Loss: 14892.337891\n",
      "Train Epoch: 45 [93056/225000 (41%)] Loss: 14879.197266\n",
      "Train Epoch: 45 [94464/225000 (42%)] Loss: 14922.622070\n",
      "Train Epoch: 45 [95872/225000 (43%)] Loss: 15391.689453\n",
      "Train Epoch: 45 [97280/225000 (43%)] Loss: 15269.646484\n",
      "Train Epoch: 45 [98688/225000 (44%)] Loss: 15057.125977\n",
      "Train Epoch: 45 [100096/225000 (44%)] Loss: 14826.153320\n",
      "Train Epoch: 45 [101504/225000 (45%)] Loss: 14765.848633\n",
      "Train Epoch: 45 [102912/225000 (46%)] Loss: 14605.604492\n",
      "Train Epoch: 45 [104320/225000 (46%)] Loss: 15073.125977\n",
      "Train Epoch: 45 [105728/225000 (47%)] Loss: 15316.115234\n",
      "Train Epoch: 45 [107136/225000 (48%)] Loss: 14695.163086\n",
      "Train Epoch: 45 [108544/225000 (48%)] Loss: 15447.965820\n",
      "Train Epoch: 45 [109952/225000 (49%)] Loss: 14974.103516\n",
      "Train Epoch: 45 [111360/225000 (49%)] Loss: 15111.102539\n",
      "Train Epoch: 45 [112768/225000 (50%)] Loss: 14990.398438\n",
      "Train Epoch: 45 [114176/225000 (51%)] Loss: 15057.844727\n",
      "Train Epoch: 45 [115584/225000 (51%)] Loss: 15243.834961\n",
      "Train Epoch: 45 [116992/225000 (52%)] Loss: 14819.673828\n",
      "Train Epoch: 45 [118400/225000 (53%)] Loss: 14844.791992\n",
      "Train Epoch: 45 [119808/225000 (53%)] Loss: 15080.824219\n",
      "Train Epoch: 45 [121216/225000 (54%)] Loss: 15325.059570\n",
      "Train Epoch: 45 [122624/225000 (54%)] Loss: 14741.544922\n",
      "Train Epoch: 45 [124032/225000 (55%)] Loss: 14891.304688\n",
      "Train Epoch: 45 [125440/225000 (56%)] Loss: 15139.037109\n",
      "Train Epoch: 45 [126848/225000 (56%)] Loss: 15139.239258\n",
      "Train Epoch: 45 [128256/225000 (57%)] Loss: 14880.568359\n",
      "Train Epoch: 45 [129664/225000 (58%)] Loss: 14984.482422\n",
      "Train Epoch: 45 [131072/225000 (58%)] Loss: 14732.052734\n",
      "Train Epoch: 45 [132480/225000 (59%)] Loss: 15496.799805\n",
      "Train Epoch: 45 [133888/225000 (60%)] Loss: 15131.898438\n",
      "Train Epoch: 45 [135296/225000 (60%)] Loss: 14961.212891\n",
      "Train Epoch: 45 [136704/225000 (61%)] Loss: 15130.053711\n",
      "Train Epoch: 45 [138112/225000 (61%)] Loss: 15161.720703\n",
      "Train Epoch: 45 [139520/225000 (62%)] Loss: 15374.875000\n",
      "Train Epoch: 45 [140928/225000 (63%)] Loss: 15240.077148\n",
      "Train Epoch: 45 [142336/225000 (63%)] Loss: 14985.504883\n",
      "Train Epoch: 45 [143744/225000 (64%)] Loss: 14794.581055\n",
      "Train Epoch: 45 [145152/225000 (65%)] Loss: 15348.813477\n",
      "Train Epoch: 45 [146560/225000 (65%)] Loss: 15264.423828\n",
      "Train Epoch: 45 [147968/225000 (66%)] Loss: 15266.548828\n",
      "Train Epoch: 45 [149376/225000 (66%)] Loss: 15266.896484\n",
      "Train Epoch: 45 [150784/225000 (67%)] Loss: 15230.818359\n",
      "Train Epoch: 45 [152192/225000 (68%)] Loss: 14846.179688\n",
      "Train Epoch: 45 [153600/225000 (68%)] Loss: 15723.958984\n",
      "Train Epoch: 45 [155008/225000 (69%)] Loss: 14894.272461\n",
      "Train Epoch: 45 [156416/225000 (70%)] Loss: 15012.144531\n",
      "Train Epoch: 45 [157824/225000 (70%)] Loss: 15296.455078\n",
      "Train Epoch: 45 [159232/225000 (71%)] Loss: 15270.347656\n",
      "Train Epoch: 45 [160640/225000 (71%)] Loss: 14907.544922\n",
      "Train Epoch: 45 [162048/225000 (72%)] Loss: 14830.636719\n",
      "Train Epoch: 45 [163456/225000 (73%)] Loss: 14769.440430\n",
      "Train Epoch: 45 [164864/225000 (73%)] Loss: 15347.583984\n",
      "Train Epoch: 45 [166272/225000 (74%)] Loss: 15116.490234\n",
      "Train Epoch: 45 [167680/225000 (75%)] Loss: 15032.715820\n",
      "Train Epoch: 45 [169088/225000 (75%)] Loss: 15350.032227\n",
      "Train Epoch: 45 [170496/225000 (76%)] Loss: 14975.962891\n",
      "Train Epoch: 45 [171904/225000 (76%)] Loss: 14826.916016\n",
      "Train Epoch: 45 [173312/225000 (77%)] Loss: 15082.059570\n",
      "Train Epoch: 45 [174720/225000 (78%)] Loss: 15073.003906\n",
      "Train Epoch: 45 [176128/225000 (78%)] Loss: 14673.425781\n",
      "Train Epoch: 45 [177536/225000 (79%)] Loss: 15492.372070\n",
      "Train Epoch: 45 [178944/225000 (80%)] Loss: 15114.719727\n",
      "Train Epoch: 45 [180352/225000 (80%)] Loss: 14861.617188\n",
      "Train Epoch: 45 [181760/225000 (81%)] Loss: 15165.800781\n",
      "Train Epoch: 45 [183168/225000 (81%)] Loss: 15097.581055\n",
      "Train Epoch: 45 [184576/225000 (82%)] Loss: 14830.294922\n",
      "Train Epoch: 45 [185984/225000 (83%)] Loss: 15152.171875\n",
      "Train Epoch: 45 [187392/225000 (83%)] Loss: 14819.994141\n",
      "Train Epoch: 45 [188800/225000 (84%)] Loss: 15135.232422\n",
      "Train Epoch: 45 [190208/225000 (85%)] Loss: 15001.625000\n",
      "Train Epoch: 45 [191616/225000 (85%)] Loss: 15320.616211\n",
      "Train Epoch: 45 [193024/225000 (86%)] Loss: 15487.055664\n",
      "Train Epoch: 45 [194432/225000 (86%)] Loss: 15240.733398\n",
      "Train Epoch: 45 [195840/225000 (87%)] Loss: 15015.591797\n",
      "Train Epoch: 45 [197248/225000 (88%)] Loss: 14859.563477\n",
      "Train Epoch: 45 [198656/225000 (88%)] Loss: 15394.215820\n",
      "Train Epoch: 45 [200064/225000 (89%)] Loss: 14927.825195\n",
      "Train Epoch: 45 [201472/225000 (90%)] Loss: 15781.361328\n",
      "Train Epoch: 45 [202880/225000 (90%)] Loss: 14824.959961\n",
      "Train Epoch: 45 [204288/225000 (91%)] Loss: 14622.453125\n",
      "Train Epoch: 45 [205696/225000 (91%)] Loss: 15428.152344\n",
      "Train Epoch: 45 [207104/225000 (92%)] Loss: 15031.029297\n",
      "Train Epoch: 45 [208512/225000 (93%)] Loss: 14870.783203\n",
      "Train Epoch: 45 [209920/225000 (93%)] Loss: 15456.973633\n",
      "Train Epoch: 45 [211328/225000 (94%)] Loss: 15059.972656\n",
      "Train Epoch: 45 [212736/225000 (95%)] Loss: 15346.734375\n",
      "Train Epoch: 45 [214144/225000 (95%)] Loss: 14936.344727\n",
      "Train Epoch: 45 [215552/225000 (96%)] Loss: 14647.430664\n",
      "Train Epoch: 45 [216960/225000 (96%)] Loss: 14854.068359\n",
      "Train Epoch: 45 [218368/225000 (97%)] Loss: 15613.200195\n",
      "Train Epoch: 45 [219776/225000 (98%)] Loss: 15182.693359\n",
      "Train Epoch: 45 [221184/225000 (98%)] Loss: 14639.711914\n",
      "Train Epoch: 45 [222592/225000 (99%)] Loss: 14921.267578\n",
      "Train Epoch: 45 [224000/225000 (100%)] Loss: 14676.711914\n",
      "    epoch          : 45\n",
      "    loss           : 15078.003439077609\n",
      "    val_loss       : 15060.130340254733\n",
      "Train Epoch: 46 [128/225000 (0%)] Loss: 15094.279297\n",
      "Train Epoch: 46 [1536/225000 (1%)] Loss: 14953.764648\n",
      "Train Epoch: 46 [2944/225000 (1%)] Loss: 14927.662109\n",
      "Train Epoch: 46 [4352/225000 (2%)] Loss: 14815.767578\n",
      "Train Epoch: 46 [5760/225000 (3%)] Loss: 15282.148438\n",
      "Train Epoch: 46 [7168/225000 (3%)] Loss: 14847.942383\n",
      "Train Epoch: 46 [8576/225000 (4%)] Loss: 15140.865234\n",
      "Train Epoch: 46 [9984/225000 (4%)] Loss: 14640.280273\n",
      "Train Epoch: 46 [11392/225000 (5%)] Loss: 15094.975586\n",
      "Train Epoch: 46 [12800/225000 (6%)] Loss: 14995.958008\n",
      "Train Epoch: 46 [14208/225000 (6%)] Loss: 15463.605469\n",
      "Train Epoch: 46 [15616/225000 (7%)] Loss: 14933.039062\n",
      "Train Epoch: 46 [17024/225000 (8%)] Loss: 14524.320312\n",
      "Train Epoch: 46 [18432/225000 (8%)] Loss: 15169.085938\n",
      "Train Epoch: 46 [19840/225000 (9%)] Loss: 14960.147461\n",
      "Train Epoch: 46 [21248/225000 (9%)] Loss: 15158.865234\n",
      "Train Epoch: 46 [22656/225000 (10%)] Loss: 15016.254883\n",
      "Train Epoch: 46 [24064/225000 (11%)] Loss: 14699.493164\n",
      "Train Epoch: 46 [25472/225000 (11%)] Loss: 15426.110352\n",
      "Train Epoch: 46 [26880/225000 (12%)] Loss: 15359.668945\n",
      "Train Epoch: 46 [28288/225000 (13%)] Loss: 14795.673828\n",
      "Train Epoch: 46 [29696/225000 (13%)] Loss: 14878.816406\n",
      "Train Epoch: 46 [31104/225000 (14%)] Loss: 15145.135742\n",
      "Train Epoch: 46 [32512/225000 (14%)] Loss: 15081.147461\n",
      "Train Epoch: 46 [33920/225000 (15%)] Loss: 15186.305664\n",
      "Train Epoch: 46 [35328/225000 (16%)] Loss: 14928.028320\n",
      "Train Epoch: 46 [36736/225000 (16%)] Loss: 15383.845703\n",
      "Train Epoch: 46 [38144/225000 (17%)] Loss: 14978.010742\n",
      "Train Epoch: 46 [39552/225000 (18%)] Loss: 14998.774414\n",
      "Train Epoch: 46 [40960/225000 (18%)] Loss: 15037.982422\n",
      "Train Epoch: 46 [42368/225000 (19%)] Loss: 14921.110352\n",
      "Train Epoch: 46 [43776/225000 (19%)] Loss: 14996.961914\n",
      "Train Epoch: 46 [45184/225000 (20%)] Loss: 15191.411133\n",
      "Train Epoch: 46 [46592/225000 (21%)] Loss: 14654.415039\n",
      "Train Epoch: 46 [48000/225000 (21%)] Loss: 15195.947266\n",
      "Train Epoch: 46 [49408/225000 (22%)] Loss: 15439.013672\n",
      "Train Epoch: 46 [50816/225000 (23%)] Loss: 15474.894531\n",
      "Train Epoch: 46 [52224/225000 (23%)] Loss: 15226.989258\n",
      "Train Epoch: 46 [53632/225000 (24%)] Loss: 15022.297852\n",
      "Train Epoch: 46 [55040/225000 (24%)] Loss: 15499.921875\n",
      "Train Epoch: 46 [56448/225000 (25%)] Loss: 14804.666992\n",
      "Train Epoch: 46 [57856/225000 (26%)] Loss: 15168.996094\n",
      "Train Epoch: 46 [59264/225000 (26%)] Loss: 14924.825195\n",
      "Train Epoch: 46 [60672/225000 (27%)] Loss: 14602.731445\n",
      "Train Epoch: 46 [62080/225000 (28%)] Loss: 14974.613281\n",
      "Train Epoch: 46 [63488/225000 (28%)] Loss: 15089.752930\n",
      "Train Epoch: 46 [64896/225000 (29%)] Loss: 14833.169922\n",
      "Train Epoch: 46 [66304/225000 (29%)] Loss: 15145.855469\n",
      "Train Epoch: 46 [67712/225000 (30%)] Loss: 15331.436523\n",
      "Train Epoch: 46 [69120/225000 (31%)] Loss: 15378.705078\n",
      "Train Epoch: 46 [70528/225000 (31%)] Loss: 15747.937500\n",
      "Train Epoch: 46 [71936/225000 (32%)] Loss: 15126.743164\n",
      "Train Epoch: 46 [73344/225000 (33%)] Loss: 15320.357422\n",
      "Train Epoch: 46 [74752/225000 (33%)] Loss: 15361.452148\n",
      "Train Epoch: 46 [76160/225000 (34%)] Loss: 14931.185547\n",
      "Train Epoch: 46 [77568/225000 (34%)] Loss: 15081.232422\n",
      "Train Epoch: 46 [78976/225000 (35%)] Loss: 14920.479492\n",
      "Train Epoch: 46 [80384/225000 (36%)] Loss: 14896.132812\n",
      "Train Epoch: 46 [81792/225000 (36%)] Loss: 14941.643555\n",
      "Train Epoch: 46 [83200/225000 (37%)] Loss: 15302.231445\n",
      "Train Epoch: 46 [84608/225000 (38%)] Loss: 15366.194336\n",
      "Train Epoch: 46 [86016/225000 (38%)] Loss: 15053.733398\n",
      "Train Epoch: 46 [87424/225000 (39%)] Loss: 15294.676758\n",
      "Train Epoch: 46 [88832/225000 (39%)] Loss: 15254.706055\n",
      "Train Epoch: 46 [90240/225000 (40%)] Loss: 14667.711914\n",
      "Train Epoch: 46 [91648/225000 (41%)] Loss: 15253.303711\n",
      "Train Epoch: 46 [93056/225000 (41%)] Loss: 15497.422852\n",
      "Train Epoch: 46 [94464/225000 (42%)] Loss: 15322.532227\n",
      "Train Epoch: 46 [95872/225000 (43%)] Loss: 15233.224609\n",
      "Train Epoch: 46 [97280/225000 (43%)] Loss: 15253.369141\n",
      "Train Epoch: 46 [98688/225000 (44%)] Loss: 14979.738281\n",
      "Train Epoch: 46 [100096/225000 (44%)] Loss: 15350.559570\n",
      "Train Epoch: 46 [101504/225000 (45%)] Loss: 15214.038086\n",
      "Train Epoch: 46 [102912/225000 (46%)] Loss: 15053.846680\n",
      "Train Epoch: 46 [104320/225000 (46%)] Loss: 15092.958008\n",
      "Train Epoch: 46 [105728/225000 (47%)] Loss: 15055.935547\n",
      "Train Epoch: 46 [107136/225000 (48%)] Loss: 15001.495117\n",
      "Train Epoch: 46 [108544/225000 (48%)] Loss: 15151.068359\n",
      "Train Epoch: 46 [109952/225000 (49%)] Loss: 15352.796875\n",
      "Train Epoch: 46 [111360/225000 (49%)] Loss: 15188.408203\n",
      "Train Epoch: 46 [112768/225000 (50%)] Loss: 15026.355469\n",
      "Train Epoch: 46 [114176/225000 (51%)] Loss: 14886.054688\n",
      "Train Epoch: 46 [115584/225000 (51%)] Loss: 15151.640625\n",
      "Train Epoch: 46 [116992/225000 (52%)] Loss: 15486.868164\n",
      "Train Epoch: 46 [118400/225000 (53%)] Loss: 15721.275391\n",
      "Train Epoch: 46 [119808/225000 (53%)] Loss: 14880.354492\n",
      "Train Epoch: 46 [121216/225000 (54%)] Loss: 14976.901367\n",
      "Train Epoch: 46 [122624/225000 (54%)] Loss: 15240.577148\n",
      "Train Epoch: 46 [124032/225000 (55%)] Loss: 14787.606445\n",
      "Train Epoch: 46 [125440/225000 (56%)] Loss: 14952.135742\n",
      "Train Epoch: 46 [126848/225000 (56%)] Loss: 14985.052734\n",
      "Train Epoch: 46 [128256/225000 (57%)] Loss: 15281.191406\n",
      "Train Epoch: 46 [129664/225000 (58%)] Loss: 15294.586914\n",
      "Train Epoch: 46 [131072/225000 (58%)] Loss: 14738.541016\n",
      "Train Epoch: 46 [132480/225000 (59%)] Loss: 15155.459961\n",
      "Train Epoch: 46 [133888/225000 (60%)] Loss: 15053.776367\n",
      "Train Epoch: 46 [135296/225000 (60%)] Loss: 14507.048828\n",
      "Train Epoch: 46 [136704/225000 (61%)] Loss: 15180.341797\n",
      "Train Epoch: 46 [138112/225000 (61%)] Loss: 15455.654297\n",
      "Train Epoch: 46 [139520/225000 (62%)] Loss: 14760.726562\n",
      "Train Epoch: 46 [140928/225000 (63%)] Loss: 14887.599609\n",
      "Train Epoch: 46 [142336/225000 (63%)] Loss: 14906.567383\n",
      "Train Epoch: 46 [143744/225000 (64%)] Loss: 15198.858398\n",
      "Train Epoch: 46 [145152/225000 (65%)] Loss: 14985.141602\n",
      "Train Epoch: 46 [146560/225000 (65%)] Loss: 14953.974609\n",
      "Train Epoch: 46 [147968/225000 (66%)] Loss: 15145.422852\n",
      "Train Epoch: 46 [149376/225000 (66%)] Loss: 15133.027344\n",
      "Train Epoch: 46 [150784/225000 (67%)] Loss: 14852.249023\n",
      "Train Epoch: 46 [152192/225000 (68%)] Loss: 14623.079102\n",
      "Train Epoch: 46 [153600/225000 (68%)] Loss: 15206.238281\n",
      "Train Epoch: 46 [155008/225000 (69%)] Loss: 14859.121094\n",
      "Train Epoch: 46 [156416/225000 (70%)] Loss: 15413.733398\n",
      "Train Epoch: 46 [157824/225000 (70%)] Loss: 15154.028320\n",
      "Train Epoch: 46 [159232/225000 (71%)] Loss: 15089.116211\n",
      "Train Epoch: 46 [160640/225000 (71%)] Loss: 14765.787109\n",
      "Train Epoch: 46 [162048/225000 (72%)] Loss: 15517.158203\n",
      "Train Epoch: 46 [163456/225000 (73%)] Loss: 15197.052734\n",
      "Train Epoch: 46 [164864/225000 (73%)] Loss: 15104.905273\n",
      "Train Epoch: 46 [166272/225000 (74%)] Loss: 14912.818359\n",
      "Train Epoch: 46 [167680/225000 (75%)] Loss: 14825.403320\n",
      "Train Epoch: 46 [169088/225000 (75%)] Loss: 15134.142578\n",
      "Train Epoch: 46 [170496/225000 (76%)] Loss: 15014.425781\n",
      "Train Epoch: 46 [171904/225000 (76%)] Loss: 14874.781250\n",
      "Train Epoch: 46 [173312/225000 (77%)] Loss: 14887.208008\n",
      "Train Epoch: 46 [174720/225000 (78%)] Loss: 15034.288086\n",
      "Train Epoch: 46 [176128/225000 (78%)] Loss: 15042.030273\n",
      "Train Epoch: 46 [177536/225000 (79%)] Loss: 15418.573242\n",
      "Train Epoch: 46 [178944/225000 (80%)] Loss: 15027.937500\n",
      "Train Epoch: 46 [180352/225000 (80%)] Loss: 15071.279297\n",
      "Train Epoch: 46 [181760/225000 (81%)] Loss: 15354.547852\n",
      "Train Epoch: 46 [183168/225000 (81%)] Loss: 15227.609375\n",
      "Train Epoch: 46 [184576/225000 (82%)] Loss: 14897.639648\n",
      "Train Epoch: 46 [185984/225000 (83%)] Loss: 14861.221680\n",
      "Train Epoch: 46 [187392/225000 (83%)] Loss: 15452.200195\n",
      "Train Epoch: 46 [188800/225000 (84%)] Loss: 14999.765625\n",
      "Train Epoch: 46 [190208/225000 (85%)] Loss: 14987.752930\n",
      "Train Epoch: 46 [191616/225000 (85%)] Loss: 15205.834961\n",
      "Train Epoch: 46 [193024/225000 (86%)] Loss: 15372.151367\n",
      "Train Epoch: 46 [194432/225000 (86%)] Loss: 14833.684570\n",
      "Train Epoch: 46 [195840/225000 (87%)] Loss: 15122.969727\n",
      "Train Epoch: 46 [197248/225000 (88%)] Loss: 15207.667969\n",
      "Train Epoch: 46 [198656/225000 (88%)] Loss: 15143.046875\n",
      "Train Epoch: 46 [200064/225000 (89%)] Loss: 14594.907227\n",
      "Train Epoch: 46 [201472/225000 (90%)] Loss: 15027.298828\n",
      "Train Epoch: 46 [202880/225000 (90%)] Loss: 14600.194336\n",
      "Train Epoch: 46 [204288/225000 (91%)] Loss: 15491.341797\n",
      "Train Epoch: 46 [205696/225000 (91%)] Loss: 15441.475586\n",
      "Train Epoch: 46 [207104/225000 (92%)] Loss: 15217.008789\n",
      "Train Epoch: 46 [208512/225000 (93%)] Loss: 15042.466797\n",
      "Train Epoch: 46 [209920/225000 (93%)] Loss: 14934.676758\n",
      "Train Epoch: 46 [211328/225000 (94%)] Loss: 14441.741211\n",
      "Train Epoch: 46 [212736/225000 (95%)] Loss: 14973.962891\n",
      "Train Epoch: 46 [214144/225000 (95%)] Loss: 14538.786133\n",
      "Train Epoch: 46 [215552/225000 (96%)] Loss: 15539.307617\n",
      "Train Epoch: 46 [216960/225000 (96%)] Loss: 15421.103516\n",
      "Train Epoch: 46 [218368/225000 (97%)] Loss: 14946.418945\n",
      "Train Epoch: 46 [219776/225000 (98%)] Loss: 14797.331055\n",
      "Train Epoch: 46 [221184/225000 (98%)] Loss: 15137.398438\n",
      "Train Epoch: 46 [222592/225000 (99%)] Loss: 14469.897461\n",
      "Train Epoch: 46 [224000/225000 (100%)] Loss: 15646.390625\n",
      "    epoch          : 46\n",
      "    loss           : 15077.59871558145\n",
      "    val_loss       : 15073.606557812618\n",
      "Train Epoch: 47 [128/225000 (0%)] Loss: 14945.492188\n",
      "Train Epoch: 47 [1536/225000 (1%)] Loss: 15311.897461\n",
      "Train Epoch: 47 [2944/225000 (1%)] Loss: 15526.925781\n",
      "Train Epoch: 47 [4352/225000 (2%)] Loss: 14809.719727\n",
      "Train Epoch: 47 [5760/225000 (3%)] Loss: 15114.227539\n",
      "Train Epoch: 47 [7168/225000 (3%)] Loss: 15261.583008\n",
      "Train Epoch: 47 [8576/225000 (4%)] Loss: 15512.099609\n",
      "Train Epoch: 47 [9984/225000 (4%)] Loss: 14421.877930\n",
      "Train Epoch: 47 [11392/225000 (5%)] Loss: 15160.856445\n",
      "Train Epoch: 47 [12800/225000 (6%)] Loss: 15003.064453\n",
      "Train Epoch: 47 [14208/225000 (6%)] Loss: 15344.137695\n",
      "Train Epoch: 47 [15616/225000 (7%)] Loss: 15347.116211\n",
      "Train Epoch: 47 [17024/225000 (8%)] Loss: 15462.876953\n",
      "Train Epoch: 47 [18432/225000 (8%)] Loss: 15092.089844\n",
      "Train Epoch: 47 [19840/225000 (9%)] Loss: 15182.337891\n",
      "Train Epoch: 47 [21248/225000 (9%)] Loss: 15209.802734\n",
      "Train Epoch: 47 [22656/225000 (10%)] Loss: 15091.839844\n",
      "Train Epoch: 47 [24064/225000 (11%)] Loss: 14962.802734\n",
      "Train Epoch: 47 [25472/225000 (11%)] Loss: 15091.351562\n",
      "Train Epoch: 47 [26880/225000 (12%)] Loss: 15050.107422\n",
      "Train Epoch: 47 [28288/225000 (13%)] Loss: 15375.640625\n",
      "Train Epoch: 47 [29696/225000 (13%)] Loss: 15239.547852\n",
      "Train Epoch: 47 [31104/225000 (14%)] Loss: 15699.959961\n",
      "Train Epoch: 47 [32512/225000 (14%)] Loss: 14491.219727\n",
      "Train Epoch: 47 [33920/225000 (15%)] Loss: 14893.508789\n",
      "Train Epoch: 47 [35328/225000 (16%)] Loss: 14976.219727\n",
      "Train Epoch: 47 [36736/225000 (16%)] Loss: 15210.752930\n",
      "Train Epoch: 47 [38144/225000 (17%)] Loss: 14478.746094\n",
      "Train Epoch: 47 [39552/225000 (18%)] Loss: 14885.339844\n",
      "Train Epoch: 47 [40960/225000 (18%)] Loss: 14909.776367\n",
      "Train Epoch: 47 [42368/225000 (19%)] Loss: 15286.076172\n",
      "Train Epoch: 47 [43776/225000 (19%)] Loss: 15063.337891\n",
      "Train Epoch: 47 [45184/225000 (20%)] Loss: 14785.498047\n",
      "Train Epoch: 47 [46592/225000 (21%)] Loss: 14536.156250\n",
      "Train Epoch: 47 [48000/225000 (21%)] Loss: 15660.088867\n",
      "Train Epoch: 47 [49408/225000 (22%)] Loss: 14811.267578\n",
      "Train Epoch: 47 [50816/225000 (23%)] Loss: 15271.649414\n",
      "Train Epoch: 47 [52224/225000 (23%)] Loss: 14972.144531\n",
      "Train Epoch: 47 [53632/225000 (24%)] Loss: 15138.362305\n",
      "Train Epoch: 47 [55040/225000 (24%)] Loss: 15081.474609\n",
      "Train Epoch: 47 [56448/225000 (25%)] Loss: 14927.831055\n",
      "Train Epoch: 47 [57856/225000 (26%)] Loss: 15269.500000\n",
      "Train Epoch: 47 [59264/225000 (26%)] Loss: 14704.403320\n",
      "Train Epoch: 47 [60672/225000 (27%)] Loss: 15094.256836\n",
      "Train Epoch: 47 [62080/225000 (28%)] Loss: 14871.828125\n",
      "Train Epoch: 47 [63488/225000 (28%)] Loss: 15372.258789\n",
      "Train Epoch: 47 [64896/225000 (29%)] Loss: 14848.086914\n",
      "Train Epoch: 47 [66304/225000 (29%)] Loss: 15085.844727\n",
      "Train Epoch: 47 [67712/225000 (30%)] Loss: 14976.249023\n",
      "Train Epoch: 47 [69120/225000 (31%)] Loss: 15103.634766\n",
      "Train Epoch: 47 [70528/225000 (31%)] Loss: 14850.122070\n",
      "Train Epoch: 47 [71936/225000 (32%)] Loss: 14865.882812\n",
      "Train Epoch: 47 [73344/225000 (33%)] Loss: 15481.862305\n",
      "Train Epoch: 47 [74752/225000 (33%)] Loss: 15402.974609\n",
      "Train Epoch: 47 [76160/225000 (34%)] Loss: 14920.734375\n",
      "Train Epoch: 47 [77568/225000 (34%)] Loss: 15244.339844\n",
      "Train Epoch: 47 [78976/225000 (35%)] Loss: 15550.821289\n",
      "Train Epoch: 47 [80384/225000 (36%)] Loss: 15664.563477\n",
      "Train Epoch: 47 [81792/225000 (36%)] Loss: 14906.496094\n",
      "Train Epoch: 47 [83200/225000 (37%)] Loss: 15294.445312\n",
      "Train Epoch: 47 [84608/225000 (38%)] Loss: 15602.942383\n",
      "Train Epoch: 47 [86016/225000 (38%)] Loss: 15035.563477\n",
      "Train Epoch: 47 [87424/225000 (39%)] Loss: 15141.061523\n",
      "Train Epoch: 47 [88832/225000 (39%)] Loss: 15156.151367\n",
      "Train Epoch: 47 [90240/225000 (40%)] Loss: 15168.851562\n",
      "Train Epoch: 47 [91648/225000 (41%)] Loss: 15168.955078\n",
      "Train Epoch: 47 [93056/225000 (41%)] Loss: 15167.407227\n",
      "Train Epoch: 47 [94464/225000 (42%)] Loss: 14670.488281\n",
      "Train Epoch: 47 [95872/225000 (43%)] Loss: 15233.694336\n",
      "Train Epoch: 47 [97280/225000 (43%)] Loss: 15137.717773\n",
      "Train Epoch: 47 [98688/225000 (44%)] Loss: 15315.900391\n",
      "Train Epoch: 47 [100096/225000 (44%)] Loss: 15261.601562\n",
      "Train Epoch: 47 [101504/225000 (45%)] Loss: 14816.183594\n",
      "Train Epoch: 47 [102912/225000 (46%)] Loss: 15388.562500\n",
      "Train Epoch: 47 [104320/225000 (46%)] Loss: 15015.741211\n",
      "Train Epoch: 47 [105728/225000 (47%)] Loss: 15285.038086\n",
      "Train Epoch: 47 [107136/225000 (48%)] Loss: 15051.851562\n",
      "Train Epoch: 47 [108544/225000 (48%)] Loss: 14945.508789\n",
      "Train Epoch: 47 [109952/225000 (49%)] Loss: 14699.594727\n",
      "Train Epoch: 47 [111360/225000 (49%)] Loss: 15331.983398\n",
      "Train Epoch: 47 [112768/225000 (50%)] Loss: 15349.330078\n",
      "Train Epoch: 47 [114176/225000 (51%)] Loss: 15248.603516\n",
      "Train Epoch: 47 [115584/225000 (51%)] Loss: 14951.848633\n",
      "Train Epoch: 47 [116992/225000 (52%)] Loss: 15179.615234\n",
      "Train Epoch: 47 [118400/225000 (53%)] Loss: 15011.427734\n",
      "Train Epoch: 47 [119808/225000 (53%)] Loss: 14860.305664\n",
      "Train Epoch: 47 [121216/225000 (54%)] Loss: 15350.544922\n",
      "Train Epoch: 47 [122624/225000 (54%)] Loss: 15291.396484\n",
      "Train Epoch: 47 [124032/225000 (55%)] Loss: 14918.700195\n",
      "Train Epoch: 47 [125440/225000 (56%)] Loss: 14931.705078\n",
      "Train Epoch: 47 [126848/225000 (56%)] Loss: 15607.308594\n",
      "Train Epoch: 47 [128256/225000 (57%)] Loss: 14785.871094\n",
      "Train Epoch: 47 [129664/225000 (58%)] Loss: 14972.446289\n",
      "Train Epoch: 47 [131072/225000 (58%)] Loss: 14792.646484\n",
      "Train Epoch: 47 [132480/225000 (59%)] Loss: 15201.338867\n",
      "Train Epoch: 47 [133888/225000 (60%)] Loss: 15355.393555\n",
      "Train Epoch: 47 [135296/225000 (60%)] Loss: 15076.372070\n",
      "Train Epoch: 47 [136704/225000 (61%)] Loss: 14812.441406\n",
      "Train Epoch: 47 [138112/225000 (61%)] Loss: 15189.627930\n",
      "Train Epoch: 47 [139520/225000 (62%)] Loss: 14802.771484\n",
      "Train Epoch: 47 [140928/225000 (63%)] Loss: 14827.648438\n",
      "Train Epoch: 47 [142336/225000 (63%)] Loss: 14864.069336\n",
      "Train Epoch: 47 [143744/225000 (64%)] Loss: 14493.545898\n",
      "Train Epoch: 47 [145152/225000 (65%)] Loss: 15208.543945\n",
      "Train Epoch: 47 [146560/225000 (65%)] Loss: 14802.212891\n",
      "Train Epoch: 47 [147968/225000 (66%)] Loss: 15146.816406\n",
      "Train Epoch: 47 [149376/225000 (66%)] Loss: 15302.258789\n",
      "Train Epoch: 47 [150784/225000 (67%)] Loss: 14969.346680\n",
      "Train Epoch: 47 [152192/225000 (68%)] Loss: 15124.899414\n",
      "Train Epoch: 47 [153600/225000 (68%)] Loss: 15371.031250\n",
      "Train Epoch: 47 [155008/225000 (69%)] Loss: 15205.672852\n",
      "Train Epoch: 47 [156416/225000 (70%)] Loss: 15068.520508\n",
      "Train Epoch: 47 [157824/225000 (70%)] Loss: 15022.567383\n",
      "Train Epoch: 47 [159232/225000 (71%)] Loss: 14977.037109\n",
      "Train Epoch: 47 [160640/225000 (71%)] Loss: 14973.914062\n",
      "Train Epoch: 47 [162048/225000 (72%)] Loss: 15172.730469\n",
      "Train Epoch: 47 [163456/225000 (73%)] Loss: 14883.013672\n",
      "Train Epoch: 47 [164864/225000 (73%)] Loss: 14863.463867\n",
      "Train Epoch: 47 [166272/225000 (74%)] Loss: 15127.491211\n",
      "Train Epoch: 47 [167680/225000 (75%)] Loss: 14852.933594\n",
      "Train Epoch: 47 [169088/225000 (75%)] Loss: 14584.815430\n",
      "Train Epoch: 47 [170496/225000 (76%)] Loss: 15250.233398\n",
      "Train Epoch: 47 [171904/225000 (76%)] Loss: 15306.506836\n",
      "Train Epoch: 47 [173312/225000 (77%)] Loss: 14643.832031\n",
      "Train Epoch: 47 [174720/225000 (78%)] Loss: 14970.910156\n",
      "Train Epoch: 47 [176128/225000 (78%)] Loss: 14627.207031\n",
      "Train Epoch: 47 [177536/225000 (79%)] Loss: 15571.944336\n",
      "Train Epoch: 47 [178944/225000 (80%)] Loss: 14628.168945\n",
      "Train Epoch: 47 [180352/225000 (80%)] Loss: 15441.571289\n",
      "Train Epoch: 47 [181760/225000 (81%)] Loss: 14856.276367\n",
      "Train Epoch: 47 [183168/225000 (81%)] Loss: 15517.869141\n",
      "Train Epoch: 47 [184576/225000 (82%)] Loss: 14804.918945\n",
      "Train Epoch: 47 [185984/225000 (83%)] Loss: 15069.697266\n",
      "Train Epoch: 47 [187392/225000 (83%)] Loss: 14945.124023\n",
      "Train Epoch: 47 [188800/225000 (84%)] Loss: 14873.957031\n",
      "Train Epoch: 47 [190208/225000 (85%)] Loss: 15125.208984\n",
      "Train Epoch: 47 [191616/225000 (85%)] Loss: 14865.993164\n",
      "Train Epoch: 47 [193024/225000 (86%)] Loss: 15076.157227\n",
      "Train Epoch: 47 [194432/225000 (86%)] Loss: 14814.670898\n",
      "Train Epoch: 47 [195840/225000 (87%)] Loss: 14958.147461\n",
      "Train Epoch: 47 [197248/225000 (88%)] Loss: 15184.081055\n",
      "Train Epoch: 47 [198656/225000 (88%)] Loss: 14933.455078\n",
      "Train Epoch: 47 [200064/225000 (89%)] Loss: 15108.303711\n",
      "Train Epoch: 47 [201472/225000 (90%)] Loss: 14886.092773\n",
      "Train Epoch: 47 [202880/225000 (90%)] Loss: 15207.929688\n",
      "Train Epoch: 47 [204288/225000 (91%)] Loss: 15362.555664\n",
      "Train Epoch: 47 [205696/225000 (91%)] Loss: 15120.877930\n",
      "Train Epoch: 47 [207104/225000 (92%)] Loss: 15299.661133\n",
      "Train Epoch: 47 [208512/225000 (93%)] Loss: 15275.062500\n",
      "Train Epoch: 47 [209920/225000 (93%)] Loss: 14962.213867\n",
      "Train Epoch: 47 [211328/225000 (94%)] Loss: 15360.031250\n",
      "Train Epoch: 47 [212736/225000 (95%)] Loss: 15259.661133\n",
      "Train Epoch: 47 [214144/225000 (95%)] Loss: 15346.220703\n",
      "Train Epoch: 47 [215552/225000 (96%)] Loss: 15093.289062\n",
      "Train Epoch: 47 [216960/225000 (96%)] Loss: 14924.578125\n",
      "Train Epoch: 47 [218368/225000 (97%)] Loss: 15155.533203\n",
      "Train Epoch: 47 [219776/225000 (98%)] Loss: 14927.157227\n",
      "Train Epoch: 47 [221184/225000 (98%)] Loss: 15263.061523\n",
      "Train Epoch: 47 [222592/225000 (99%)] Loss: 15014.396484\n",
      "Train Epoch: 47 [224000/225000 (100%)] Loss: 15096.738281\n",
      "    epoch          : 47\n",
      "    loss           : 15083.091469687677\n",
      "    val_loss       : 15080.045276059787\n",
      "Train Epoch: 48 [128/225000 (0%)] Loss: 15789.823242\n",
      "Train Epoch: 48 [1536/225000 (1%)] Loss: 15148.998047\n",
      "Train Epoch: 48 [2944/225000 (1%)] Loss: 14807.424805\n",
      "Train Epoch: 48 [4352/225000 (2%)] Loss: 14703.232422\n",
      "Train Epoch: 48 [5760/225000 (3%)] Loss: 15263.969727\n",
      "Train Epoch: 48 [7168/225000 (3%)] Loss: 15362.755859\n",
      "Train Epoch: 48 [8576/225000 (4%)] Loss: 15253.588867\n",
      "Train Epoch: 48 [9984/225000 (4%)] Loss: 15237.464844\n",
      "Train Epoch: 48 [11392/225000 (5%)] Loss: 15342.698242\n",
      "Train Epoch: 48 [12800/225000 (6%)] Loss: 15299.661133\n",
      "Train Epoch: 48 [14208/225000 (6%)] Loss: 14653.983398\n",
      "Train Epoch: 48 [15616/225000 (7%)] Loss: 15108.661133\n",
      "Train Epoch: 48 [17024/225000 (8%)] Loss: 14830.337891\n",
      "Train Epoch: 48 [18432/225000 (8%)] Loss: 15401.923828\n",
      "Train Epoch: 48 [19840/225000 (9%)] Loss: 15291.478516\n",
      "Train Epoch: 48 [21248/225000 (9%)] Loss: 15496.675781\n",
      "Train Epoch: 48 [22656/225000 (10%)] Loss: 15112.546875\n",
      "Train Epoch: 48 [24064/225000 (11%)] Loss: 15445.578125\n",
      "Train Epoch: 48 [25472/225000 (11%)] Loss: 15068.736328\n",
      "Train Epoch: 48 [26880/225000 (12%)] Loss: 15488.774414\n",
      "Train Epoch: 48 [28288/225000 (13%)] Loss: 14656.877930\n",
      "Train Epoch: 48 [29696/225000 (13%)] Loss: 15538.950195\n",
      "Train Epoch: 48 [31104/225000 (14%)] Loss: 15226.429688\n",
      "Train Epoch: 48 [32512/225000 (14%)] Loss: 15390.784180\n",
      "Train Epoch: 48 [33920/225000 (15%)] Loss: 14940.698242\n",
      "Train Epoch: 48 [35328/225000 (16%)] Loss: 14853.466797\n",
      "Train Epoch: 48 [36736/225000 (16%)] Loss: 14910.755859\n",
      "Train Epoch: 48 [38144/225000 (17%)] Loss: 14971.210938\n",
      "Train Epoch: 48 [39552/225000 (18%)] Loss: 14881.920898\n",
      "Train Epoch: 48 [40960/225000 (18%)] Loss: 15151.882812\n",
      "Train Epoch: 48 [42368/225000 (19%)] Loss: 15089.994141\n",
      "Train Epoch: 48 [43776/225000 (19%)] Loss: 15570.382812\n",
      "Train Epoch: 48 [45184/225000 (20%)] Loss: 15413.902344\n",
      "Train Epoch: 48 [46592/225000 (21%)] Loss: 14704.952148\n",
      "Train Epoch: 48 [48000/225000 (21%)] Loss: 15820.594727\n",
      "Train Epoch: 48 [49408/225000 (22%)] Loss: 14861.970703\n",
      "Train Epoch: 48 [50816/225000 (23%)] Loss: 15033.979492\n",
      "Train Epoch: 48 [52224/225000 (23%)] Loss: 14743.539062\n",
      "Train Epoch: 48 [53632/225000 (24%)] Loss: 15218.864258\n",
      "Train Epoch: 48 [55040/225000 (24%)] Loss: 15063.119141\n",
      "Train Epoch: 48 [56448/225000 (25%)] Loss: 14886.992188\n",
      "Train Epoch: 48 [57856/225000 (26%)] Loss: 14994.206055\n",
      "Train Epoch: 48 [59264/225000 (26%)] Loss: 15015.687500\n",
      "Train Epoch: 48 [60672/225000 (27%)] Loss: 15346.536133\n",
      "Train Epoch: 48 [62080/225000 (28%)] Loss: 15312.278320\n",
      "Train Epoch: 48 [63488/225000 (28%)] Loss: 15012.339844\n",
      "Train Epoch: 48 [64896/225000 (29%)] Loss: 15173.415039\n",
      "Train Epoch: 48 [66304/225000 (29%)] Loss: 14827.709961\n",
      "Train Epoch: 48 [67712/225000 (30%)] Loss: 15088.631836\n",
      "Train Epoch: 48 [69120/225000 (31%)] Loss: 15149.821289\n",
      "Train Epoch: 48 [70528/225000 (31%)] Loss: 15009.376953\n",
      "Train Epoch: 48 [71936/225000 (32%)] Loss: 14934.744141\n",
      "Train Epoch: 48 [73344/225000 (33%)] Loss: 14943.837891\n",
      "Train Epoch: 48 [74752/225000 (33%)] Loss: 15586.653320\n",
      "Train Epoch: 48 [76160/225000 (34%)] Loss: 14978.241211\n",
      "Train Epoch: 48 [77568/225000 (34%)] Loss: 14722.575195\n",
      "Train Epoch: 48 [78976/225000 (35%)] Loss: 15449.889648\n",
      "Train Epoch: 48 [80384/225000 (36%)] Loss: 14970.179688\n",
      "Train Epoch: 48 [81792/225000 (36%)] Loss: 14903.830078\n",
      "Train Epoch: 48 [83200/225000 (37%)] Loss: 14913.078125\n",
      "Train Epoch: 48 [84608/225000 (38%)] Loss: 14699.632812\n",
      "Train Epoch: 48 [86016/225000 (38%)] Loss: 15510.150391\n",
      "Train Epoch: 48 [87424/225000 (39%)] Loss: 15119.855469\n",
      "Train Epoch: 48 [88832/225000 (39%)] Loss: 15115.920898\n",
      "Train Epoch: 48 [90240/225000 (40%)] Loss: 14734.937500\n",
      "Train Epoch: 48 [91648/225000 (41%)] Loss: 14949.805664\n",
      "Train Epoch: 48 [93056/225000 (41%)] Loss: 14819.093750\n",
      "Train Epoch: 48 [94464/225000 (42%)] Loss: 14981.735352\n",
      "Train Epoch: 48 [95872/225000 (43%)] Loss: 15576.144531\n",
      "Train Epoch: 48 [97280/225000 (43%)] Loss: 15012.229492\n",
      "Train Epoch: 48 [98688/225000 (44%)] Loss: 15182.377930\n",
      "Train Epoch: 48 [100096/225000 (44%)] Loss: 14927.503906\n",
      "Train Epoch: 48 [101504/225000 (45%)] Loss: 14853.094727\n",
      "Train Epoch: 48 [102912/225000 (46%)] Loss: 15137.963867\n",
      "Train Epoch: 48 [104320/225000 (46%)] Loss: 15168.947266\n",
      "Train Epoch: 48 [105728/225000 (47%)] Loss: 15168.939453\n",
      "Train Epoch: 48 [107136/225000 (48%)] Loss: 14515.817383\n",
      "Train Epoch: 48 [108544/225000 (48%)] Loss: 15370.425781\n",
      "Train Epoch: 48 [109952/225000 (49%)] Loss: 14971.244141\n",
      "Train Epoch: 48 [111360/225000 (49%)] Loss: 14841.103516\n",
      "Train Epoch: 48 [112768/225000 (50%)] Loss: 15250.675781\n",
      "Train Epoch: 48 [114176/225000 (51%)] Loss: 15097.792969\n",
      "Train Epoch: 48 [115584/225000 (51%)] Loss: 15088.135742\n",
      "Train Epoch: 48 [116992/225000 (52%)] Loss: 14897.135742\n",
      "Train Epoch: 48 [118400/225000 (53%)] Loss: 14885.033203\n",
      "Train Epoch: 48 [119808/225000 (53%)] Loss: 14921.262695\n",
      "Train Epoch: 48 [121216/225000 (54%)] Loss: 14659.613281\n",
      "Train Epoch: 48 [122624/225000 (54%)] Loss: 15616.587891\n",
      "Train Epoch: 48 [124032/225000 (55%)] Loss: 15442.959961\n",
      "Train Epoch: 48 [125440/225000 (56%)] Loss: 14987.207031\n",
      "Train Epoch: 48 [126848/225000 (56%)] Loss: 15357.742188\n",
      "Train Epoch: 48 [128256/225000 (57%)] Loss: 14844.374023\n",
      "Train Epoch: 48 [129664/225000 (58%)] Loss: 15373.068359\n",
      "Train Epoch: 48 [131072/225000 (58%)] Loss: 14868.159180\n",
      "Train Epoch: 48 [132480/225000 (59%)] Loss: 15296.733398\n",
      "Train Epoch: 48 [133888/225000 (60%)] Loss: 14831.810547\n",
      "Train Epoch: 48 [135296/225000 (60%)] Loss: 15308.943359\n",
      "Train Epoch: 48 [136704/225000 (61%)] Loss: 15078.544922\n",
      "Train Epoch: 48 [138112/225000 (61%)] Loss: 15349.666992\n",
      "Train Epoch: 48 [139520/225000 (62%)] Loss: 15018.251953\n",
      "Train Epoch: 48 [140928/225000 (63%)] Loss: 14867.460938\n",
      "Train Epoch: 48 [142336/225000 (63%)] Loss: 15118.138672\n",
      "Train Epoch: 48 [143744/225000 (64%)] Loss: 15679.143555\n",
      "Train Epoch: 48 [145152/225000 (65%)] Loss: 15056.253906\n",
      "Train Epoch: 48 [146560/225000 (65%)] Loss: 14917.712891\n",
      "Train Epoch: 48 [147968/225000 (66%)] Loss: 15056.114258\n",
      "Train Epoch: 48 [149376/225000 (66%)] Loss: 15079.542969\n",
      "Train Epoch: 48 [150784/225000 (67%)] Loss: 14942.520508\n",
      "Train Epoch: 48 [152192/225000 (68%)] Loss: 14808.984375\n",
      "Train Epoch: 48 [153600/225000 (68%)] Loss: 15132.783203\n",
      "Train Epoch: 48 [155008/225000 (69%)] Loss: 14680.083008\n",
      "Train Epoch: 48 [156416/225000 (70%)] Loss: 14790.889648\n",
      "Train Epoch: 48 [157824/225000 (70%)] Loss: 15135.796875\n",
      "Train Epoch: 48 [159232/225000 (71%)] Loss: 14775.596680\n",
      "Train Epoch: 48 [160640/225000 (71%)] Loss: 15682.951172\n",
      "Train Epoch: 48 [162048/225000 (72%)] Loss: 15242.622070\n",
      "Train Epoch: 48 [163456/225000 (73%)] Loss: 15341.122070\n",
      "Train Epoch: 48 [164864/225000 (73%)] Loss: 15248.735352\n",
      "Train Epoch: 48 [166272/225000 (74%)] Loss: 14897.427734\n",
      "Train Epoch: 48 [167680/225000 (75%)] Loss: 14489.249023\n",
      "Train Epoch: 48 [169088/225000 (75%)] Loss: 14919.310547\n",
      "Train Epoch: 48 [170496/225000 (76%)] Loss: 15062.221680\n",
      "Train Epoch: 48 [171904/225000 (76%)] Loss: 15083.442383\n",
      "Train Epoch: 48 [173312/225000 (77%)] Loss: 14832.344727\n",
      "Train Epoch: 48 [174720/225000 (78%)] Loss: 15057.594727\n",
      "Train Epoch: 48 [176128/225000 (78%)] Loss: 15086.749023\n",
      "Train Epoch: 48 [177536/225000 (79%)] Loss: 14980.447266\n",
      "Train Epoch: 48 [178944/225000 (80%)] Loss: 14695.450195\n",
      "Train Epoch: 48 [180352/225000 (80%)] Loss: 15299.037109\n",
      "Train Epoch: 48 [181760/225000 (81%)] Loss: 15066.317383\n",
      "Train Epoch: 48 [183168/225000 (81%)] Loss: 15725.047852\n",
      "Train Epoch: 48 [184576/225000 (82%)] Loss: 15214.640625\n",
      "Train Epoch: 48 [185984/225000 (83%)] Loss: 14984.668945\n",
      "Train Epoch: 48 [187392/225000 (83%)] Loss: 15074.041016\n",
      "Train Epoch: 48 [188800/225000 (84%)] Loss: 14740.994141\n",
      "Train Epoch: 48 [190208/225000 (85%)] Loss: 15238.072266\n",
      "Train Epoch: 48 [191616/225000 (85%)] Loss: 14747.134766\n",
      "Train Epoch: 48 [193024/225000 (86%)] Loss: 14714.500000\n",
      "Train Epoch: 48 [194432/225000 (86%)] Loss: 14883.538086\n",
      "Train Epoch: 48 [195840/225000 (87%)] Loss: 15247.776367\n",
      "Train Epoch: 48 [197248/225000 (88%)] Loss: 15167.657227\n",
      "Train Epoch: 48 [198656/225000 (88%)] Loss: 15078.042969\n",
      "Train Epoch: 48 [200064/225000 (89%)] Loss: 15487.853516\n",
      "Train Epoch: 48 [201472/225000 (90%)] Loss: 14980.571289\n",
      "Train Epoch: 48 [202880/225000 (90%)] Loss: 14737.000000\n",
      "Train Epoch: 48 [204288/225000 (91%)] Loss: 15123.402344\n",
      "Train Epoch: 48 [205696/225000 (91%)] Loss: 14648.222656\n",
      "Train Epoch: 48 [207104/225000 (92%)] Loss: 14925.849609\n",
      "Train Epoch: 48 [208512/225000 (93%)] Loss: 15459.664062\n",
      "Train Epoch: 48 [209920/225000 (93%)] Loss: 15380.390625\n",
      "Train Epoch: 48 [211328/225000 (94%)] Loss: 15280.998047\n",
      "Train Epoch: 48 [212736/225000 (95%)] Loss: 15150.360352\n",
      "Train Epoch: 48 [214144/225000 (95%)] Loss: 15585.142578\n",
      "Train Epoch: 48 [215552/225000 (96%)] Loss: 15591.095703\n",
      "Train Epoch: 48 [216960/225000 (96%)] Loss: 15173.074219\n",
      "Train Epoch: 48 [218368/225000 (97%)] Loss: 14764.555664\n",
      "Train Epoch: 48 [219776/225000 (98%)] Loss: 14756.971680\n",
      "Train Epoch: 48 [221184/225000 (98%)] Loss: 15238.776367\n",
      "Train Epoch: 48 [222592/225000 (99%)] Loss: 14892.466797\n",
      "Train Epoch: 48 [224000/225000 (100%)] Loss: 14811.366211\n",
      "    epoch          : 48\n",
      "    loss           : 15081.653876364298\n",
      "    val_loss       : 15066.86261302841\n",
      "Train Epoch: 49 [128/225000 (0%)] Loss: 14940.685547\n",
      "Train Epoch: 49 [1536/225000 (1%)] Loss: 14404.532227\n",
      "Train Epoch: 49 [2944/225000 (1%)] Loss: 14822.957031\n",
      "Train Epoch: 49 [4352/225000 (2%)] Loss: 15267.094727\n",
      "Train Epoch: 49 [5760/225000 (3%)] Loss: 15170.139648\n",
      "Train Epoch: 49 [7168/225000 (3%)] Loss: 15490.515625\n",
      "Train Epoch: 49 [8576/225000 (4%)] Loss: 15004.496094\n",
      "Train Epoch: 49 [9984/225000 (4%)] Loss: 14907.417969\n",
      "Train Epoch: 49 [11392/225000 (5%)] Loss: 15384.535156\n",
      "Train Epoch: 49 [12800/225000 (6%)] Loss: 14843.371094\n",
      "Train Epoch: 49 [14208/225000 (6%)] Loss: 15317.087891\n",
      "Train Epoch: 49 [15616/225000 (7%)] Loss: 15150.100586\n",
      "Train Epoch: 49 [17024/225000 (8%)] Loss: 15447.992188\n",
      "Train Epoch: 49 [18432/225000 (8%)] Loss: 15266.626953\n",
      "Train Epoch: 49 [19840/225000 (9%)] Loss: 15298.022461\n",
      "Train Epoch: 49 [21248/225000 (9%)] Loss: 15340.135742\n",
      "Train Epoch: 49 [22656/225000 (10%)] Loss: 15305.093750\n",
      "Train Epoch: 49 [24064/225000 (11%)] Loss: 15154.959961\n",
      "Train Epoch: 49 [25472/225000 (11%)] Loss: 15378.003906\n",
      "Train Epoch: 49 [26880/225000 (12%)] Loss: 15032.790039\n",
      "Train Epoch: 49 [28288/225000 (13%)] Loss: 15566.509766\n",
      "Train Epoch: 49 [29696/225000 (13%)] Loss: 14813.541992\n",
      "Train Epoch: 49 [31104/225000 (14%)] Loss: 15429.009766\n",
      "Train Epoch: 49 [32512/225000 (14%)] Loss: 14901.461914\n",
      "Train Epoch: 49 [33920/225000 (15%)] Loss: 15057.406250\n",
      "Train Epoch: 49 [35328/225000 (16%)] Loss: 14873.699219\n",
      "Train Epoch: 49 [36736/225000 (16%)] Loss: 14696.609375\n",
      "Train Epoch: 49 [38144/225000 (17%)] Loss: 15708.512695\n",
      "Train Epoch: 49 [39552/225000 (18%)] Loss: 15180.243164\n",
      "Train Epoch: 49 [40960/225000 (18%)] Loss: 15188.863281\n",
      "Train Epoch: 49 [42368/225000 (19%)] Loss: 14787.838867\n",
      "Train Epoch: 49 [43776/225000 (19%)] Loss: 15125.398438\n",
      "Train Epoch: 49 [45184/225000 (20%)] Loss: 15049.266602\n",
      "Train Epoch: 49 [46592/225000 (21%)] Loss: 15119.417969\n",
      "Train Epoch: 49 [48000/225000 (21%)] Loss: 15374.166992\n",
      "Train Epoch: 49 [49408/225000 (22%)] Loss: 15278.354492\n",
      "Train Epoch: 49 [50816/225000 (23%)] Loss: 15789.934570\n",
      "Train Epoch: 49 [52224/225000 (23%)] Loss: 14753.560547\n",
      "Train Epoch: 49 [53632/225000 (24%)] Loss: 15232.874023\n",
      "Train Epoch: 49 [55040/225000 (24%)] Loss: 15274.717773\n",
      "Train Epoch: 49 [56448/225000 (25%)] Loss: 15155.543945\n",
      "Train Epoch: 49 [57856/225000 (26%)] Loss: 14820.124023\n",
      "Train Epoch: 49 [59264/225000 (26%)] Loss: 14933.237305\n",
      "Train Epoch: 49 [60672/225000 (27%)] Loss: 15153.707031\n",
      "Train Epoch: 49 [62080/225000 (28%)] Loss: 14889.693359\n",
      "Train Epoch: 49 [63488/225000 (28%)] Loss: 15312.078125\n",
      "Train Epoch: 49 [64896/225000 (29%)] Loss: 14409.764648\n",
      "Train Epoch: 49 [66304/225000 (29%)] Loss: 14991.270508\n",
      "Train Epoch: 49 [67712/225000 (30%)] Loss: 15016.244141\n",
      "Train Epoch: 49 [69120/225000 (31%)] Loss: 15002.718750\n",
      "Train Epoch: 49 [70528/225000 (31%)] Loss: 14981.597656\n",
      "Train Epoch: 49 [71936/225000 (32%)] Loss: 15464.964844\n",
      "Train Epoch: 49 [73344/225000 (33%)] Loss: 15020.234375\n",
      "Train Epoch: 49 [74752/225000 (33%)] Loss: 15700.288086\n",
      "Train Epoch: 49 [76160/225000 (34%)] Loss: 14867.888672\n",
      "Train Epoch: 49 [77568/225000 (34%)] Loss: 15021.927734\n",
      "Train Epoch: 49 [78976/225000 (35%)] Loss: 15396.155273\n",
      "Train Epoch: 49 [80384/225000 (36%)] Loss: 14954.832031\n",
      "Train Epoch: 49 [81792/225000 (36%)] Loss: 15425.422852\n",
      "Train Epoch: 49 [83200/225000 (37%)] Loss: 15448.339844\n",
      "Train Epoch: 49 [84608/225000 (38%)] Loss: 14792.839844\n",
      "Train Epoch: 49 [86016/225000 (38%)] Loss: 15622.461914\n",
      "Train Epoch: 49 [87424/225000 (39%)] Loss: 15111.410156\n",
      "Train Epoch: 49 [88832/225000 (39%)] Loss: 14915.471680\n",
      "Train Epoch: 49 [90240/225000 (40%)] Loss: 15346.323242\n",
      "Train Epoch: 49 [91648/225000 (41%)] Loss: 15094.859375\n",
      "Train Epoch: 49 [93056/225000 (41%)] Loss: 14833.962891\n",
      "Train Epoch: 49 [94464/225000 (42%)] Loss: 14935.981445\n",
      "Train Epoch: 49 [95872/225000 (43%)] Loss: 15337.201172\n",
      "Train Epoch: 49 [97280/225000 (43%)] Loss: 14929.896484\n",
      "Train Epoch: 49 [98688/225000 (44%)] Loss: 14882.130859\n",
      "Train Epoch: 49 [100096/225000 (44%)] Loss: 14863.169922\n",
      "Train Epoch: 49 [101504/225000 (45%)] Loss: 15297.448242\n",
      "Train Epoch: 49 [102912/225000 (46%)] Loss: 14801.702148\n",
      "Train Epoch: 49 [104320/225000 (46%)] Loss: 15177.876953\n",
      "Train Epoch: 49 [105728/225000 (47%)] Loss: 15219.146484\n",
      "Train Epoch: 49 [107136/225000 (48%)] Loss: 15049.386719\n",
      "Train Epoch: 49 [108544/225000 (48%)] Loss: 15180.297852\n",
      "Train Epoch: 49 [109952/225000 (49%)] Loss: 15196.777344\n",
      "Train Epoch: 49 [111360/225000 (49%)] Loss: 14844.666016\n",
      "Train Epoch: 49 [112768/225000 (50%)] Loss: 15150.346680\n",
      "Train Epoch: 49 [114176/225000 (51%)] Loss: 15456.627930\n",
      "Train Epoch: 49 [115584/225000 (51%)] Loss: 17263.486328\n",
      "Train Epoch: 49 [116992/225000 (52%)] Loss: 14967.299805\n",
      "Train Epoch: 49 [118400/225000 (53%)] Loss: 15471.591797\n",
      "Train Epoch: 49 [119808/225000 (53%)] Loss: 14857.972656\n",
      "Train Epoch: 49 [121216/225000 (54%)] Loss: 14852.263672\n",
      "Train Epoch: 49 [122624/225000 (54%)] Loss: 14786.158203\n",
      "Train Epoch: 49 [124032/225000 (55%)] Loss: 15317.332031\n",
      "Train Epoch: 49 [125440/225000 (56%)] Loss: 15091.966797\n",
      "Train Epoch: 49 [126848/225000 (56%)] Loss: 15311.695312\n",
      "Train Epoch: 49 [128256/225000 (57%)] Loss: 15258.433594\n",
      "Train Epoch: 49 [129664/225000 (58%)] Loss: 14923.671875\n",
      "Train Epoch: 49 [131072/225000 (58%)] Loss: 14898.783203\n",
      "Train Epoch: 49 [132480/225000 (59%)] Loss: 15062.755859\n",
      "Train Epoch: 49 [133888/225000 (60%)] Loss: 15300.732422\n",
      "Train Epoch: 49 [135296/225000 (60%)] Loss: 15382.262695\n",
      "Train Epoch: 49 [136704/225000 (61%)] Loss: 15037.387695\n",
      "Train Epoch: 49 [138112/225000 (61%)] Loss: 15078.711914\n",
      "Train Epoch: 49 [139520/225000 (62%)] Loss: 15156.465820\n",
      "Train Epoch: 49 [140928/225000 (63%)] Loss: 14684.391602\n",
      "Train Epoch: 49 [142336/225000 (63%)] Loss: 15149.107422\n",
      "Train Epoch: 49 [143744/225000 (64%)] Loss: 14813.660156\n",
      "Train Epoch: 49 [145152/225000 (65%)] Loss: 14957.625000\n",
      "Train Epoch: 49 [146560/225000 (65%)] Loss: 14952.250977\n",
      "Train Epoch: 49 [147968/225000 (66%)] Loss: 15381.935547\n",
      "Train Epoch: 49 [149376/225000 (66%)] Loss: 15180.730469\n",
      "Train Epoch: 49 [150784/225000 (67%)] Loss: 14882.778320\n",
      "Train Epoch: 49 [152192/225000 (68%)] Loss: 15023.624023\n",
      "Train Epoch: 49 [153600/225000 (68%)] Loss: 14803.001953\n",
      "Train Epoch: 49 [155008/225000 (69%)] Loss: 15026.011719\n",
      "Train Epoch: 49 [156416/225000 (70%)] Loss: 15019.289062\n",
      "Train Epoch: 49 [157824/225000 (70%)] Loss: 15328.538086\n",
      "Train Epoch: 49 [159232/225000 (71%)] Loss: 14819.526367\n",
      "Train Epoch: 49 [160640/225000 (71%)] Loss: 15416.052734\n",
      "Train Epoch: 49 [162048/225000 (72%)] Loss: 15028.770508\n",
      "Train Epoch: 49 [163456/225000 (73%)] Loss: 15755.591797\n",
      "Train Epoch: 49 [164864/225000 (73%)] Loss: 15333.353516\n",
      "Train Epoch: 49 [166272/225000 (74%)] Loss: 15299.982422\n",
      "Train Epoch: 49 [167680/225000 (75%)] Loss: 15079.937500\n",
      "Train Epoch: 49 [169088/225000 (75%)] Loss: 14852.729492\n",
      "Train Epoch: 49 [170496/225000 (76%)] Loss: 15208.100586\n",
      "Train Epoch: 49 [171904/225000 (76%)] Loss: 14683.591797\n",
      "Train Epoch: 49 [173312/225000 (77%)] Loss: 15182.682617\n",
      "Train Epoch: 49 [174720/225000 (78%)] Loss: 15245.053711\n",
      "Train Epoch: 49 [176128/225000 (78%)] Loss: 15158.832031\n",
      "Train Epoch: 49 [177536/225000 (79%)] Loss: 15434.360352\n",
      "Train Epoch: 49 [178944/225000 (80%)] Loss: 15347.145508\n",
      "Train Epoch: 49 [180352/225000 (80%)] Loss: 14635.321289\n",
      "Train Epoch: 49 [181760/225000 (81%)] Loss: 14764.053711\n",
      "Train Epoch: 49 [183168/225000 (81%)] Loss: 15129.805664\n",
      "Train Epoch: 49 [184576/225000 (82%)] Loss: 15271.723633\n",
      "Train Epoch: 49 [185984/225000 (83%)] Loss: 14755.249023\n",
      "Train Epoch: 49 [187392/225000 (83%)] Loss: 15375.833008\n",
      "Train Epoch: 49 [188800/225000 (84%)] Loss: 15004.327148\n",
      "Train Epoch: 49 [190208/225000 (85%)] Loss: 14764.017578\n",
      "Train Epoch: 49 [191616/225000 (85%)] Loss: 15472.564453\n",
      "Train Epoch: 49 [193024/225000 (86%)] Loss: 15071.474609\n",
      "Train Epoch: 49 [194432/225000 (86%)] Loss: 15019.531250\n",
      "Train Epoch: 49 [195840/225000 (87%)] Loss: 14969.942383\n",
      "Train Epoch: 49 [197248/225000 (88%)] Loss: 15116.355469\n",
      "Train Epoch: 49 [198656/225000 (88%)] Loss: 14267.600586\n",
      "Train Epoch: 49 [200064/225000 (89%)] Loss: 15267.125000\n",
      "Train Epoch: 49 [201472/225000 (90%)] Loss: 14867.841797\n",
      "Train Epoch: 49 [202880/225000 (90%)] Loss: 15148.063477\n",
      "Train Epoch: 49 [204288/225000 (91%)] Loss: 14789.820312\n",
      "Train Epoch: 49 [205696/225000 (91%)] Loss: 14911.697266\n",
      "Train Epoch: 49 [207104/225000 (92%)] Loss: 15151.245117\n",
      "Train Epoch: 49 [208512/225000 (93%)] Loss: 14982.924805\n",
      "Train Epoch: 49 [209920/225000 (93%)] Loss: 15336.719727\n",
      "Train Epoch: 49 [211328/225000 (94%)] Loss: 15371.671875\n",
      "Train Epoch: 49 [212736/225000 (95%)] Loss: 15441.864258\n",
      "Train Epoch: 49 [214144/225000 (95%)] Loss: 15123.673828\n",
      "Train Epoch: 49 [215552/225000 (96%)] Loss: 14637.952148\n",
      "Train Epoch: 49 [216960/225000 (96%)] Loss: 15218.554688\n",
      "Train Epoch: 49 [218368/225000 (97%)] Loss: 14908.879883\n",
      "Train Epoch: 49 [219776/225000 (98%)] Loss: 14897.168945\n",
      "Train Epoch: 49 [221184/225000 (98%)] Loss: 15102.446289\n",
      "Train Epoch: 49 [222592/225000 (99%)] Loss: 15085.347656\n",
      "Train Epoch: 49 [224000/225000 (100%)] Loss: 15181.270508\n",
      "    epoch          : 49\n",
      "    loss           : 15081.681141233825\n",
      "    val_loss       : 15058.967185558562\n",
      "Train Epoch: 50 [128/225000 (0%)] Loss: 15332.038086\n",
      "Train Epoch: 50 [1536/225000 (1%)] Loss: 14887.663086\n",
      "Train Epoch: 50 [2944/225000 (1%)] Loss: 15114.741211\n",
      "Train Epoch: 50 [4352/225000 (2%)] Loss: 15208.059570\n",
      "Train Epoch: 50 [5760/225000 (3%)] Loss: 15175.602539\n",
      "Train Epoch: 50 [7168/225000 (3%)] Loss: 15236.101562\n",
      "Train Epoch: 50 [8576/225000 (4%)] Loss: 15028.794922\n",
      "Train Epoch: 50 [9984/225000 (4%)] Loss: 15151.872070\n",
      "Train Epoch: 50 [11392/225000 (5%)] Loss: 14936.653320\n",
      "Train Epoch: 50 [12800/225000 (6%)] Loss: 15020.180664\n",
      "Train Epoch: 50 [14208/225000 (6%)] Loss: 14919.154297\n",
      "Train Epoch: 50 [15616/225000 (7%)] Loss: 14672.857422\n",
      "Train Epoch: 50 [17024/225000 (8%)] Loss: 14865.658203\n",
      "Train Epoch: 50 [18432/225000 (8%)] Loss: 15173.623047\n",
      "Train Epoch: 50 [19840/225000 (9%)] Loss: 15142.442383\n",
      "Train Epoch: 50 [21248/225000 (9%)] Loss: 15138.842773\n",
      "Train Epoch: 50 [22656/225000 (10%)] Loss: 15099.404297\n",
      "Train Epoch: 50 [24064/225000 (11%)] Loss: 15088.585938\n",
      "Train Epoch: 50 [25472/225000 (11%)] Loss: 15521.618164\n",
      "Train Epoch: 50 [26880/225000 (12%)] Loss: 15300.321289\n",
      "Train Epoch: 50 [28288/225000 (13%)] Loss: 15256.734375\n",
      "Train Epoch: 50 [29696/225000 (13%)] Loss: 15073.990234\n",
      "Train Epoch: 50 [31104/225000 (14%)] Loss: 15015.456055\n",
      "Train Epoch: 50 [32512/225000 (14%)] Loss: 14756.897461\n",
      "Train Epoch: 50 [33920/225000 (15%)] Loss: 14985.923828\n",
      "Train Epoch: 50 [35328/225000 (16%)] Loss: 15067.669922\n",
      "Train Epoch: 50 [36736/225000 (16%)] Loss: 15091.176758\n",
      "Train Epoch: 50 [38144/225000 (17%)] Loss: 15205.441406\n",
      "Train Epoch: 50 [39552/225000 (18%)] Loss: 15303.321289\n",
      "Train Epoch: 50 [40960/225000 (18%)] Loss: 15130.194336\n",
      "Train Epoch: 50 [42368/225000 (19%)] Loss: 15356.230469\n",
      "Train Epoch: 50 [43776/225000 (19%)] Loss: 14952.714844\n",
      "Train Epoch: 50 [45184/225000 (20%)] Loss: 15125.222656\n",
      "Train Epoch: 50 [46592/225000 (21%)] Loss: 15103.024414\n",
      "Train Epoch: 50 [48000/225000 (21%)] Loss: 15386.104492\n",
      "Train Epoch: 50 [49408/225000 (22%)] Loss: 15481.752930\n",
      "Train Epoch: 50 [50816/225000 (23%)] Loss: 15195.082031\n",
      "Train Epoch: 50 [52224/225000 (23%)] Loss: 15223.503906\n",
      "Train Epoch: 50 [53632/225000 (24%)] Loss: 14856.879883\n",
      "Train Epoch: 50 [55040/225000 (24%)] Loss: 15102.869141\n",
      "Train Epoch: 50 [56448/225000 (25%)] Loss: 15179.375977\n",
      "Train Epoch: 50 [57856/225000 (26%)] Loss: 15582.264648\n",
      "Train Epoch: 50 [59264/225000 (26%)] Loss: 14887.848633\n",
      "Train Epoch: 50 [60672/225000 (27%)] Loss: 15229.103516\n",
      "Train Epoch: 50 [62080/225000 (28%)] Loss: 14671.730469\n",
      "Train Epoch: 50 [63488/225000 (28%)] Loss: 15097.370117\n",
      "Train Epoch: 50 [64896/225000 (29%)] Loss: 14658.586914\n",
      "Train Epoch: 50 [66304/225000 (29%)] Loss: 14789.342773\n",
      "Train Epoch: 50 [67712/225000 (30%)] Loss: 14999.917969\n",
      "Train Epoch: 50 [69120/225000 (31%)] Loss: 14988.834961\n",
      "Train Epoch: 50 [70528/225000 (31%)] Loss: 14712.346680\n",
      "Train Epoch: 50 [71936/225000 (32%)] Loss: 15086.827148\n",
      "Train Epoch: 50 [73344/225000 (33%)] Loss: 14703.030273\n",
      "Train Epoch: 50 [74752/225000 (33%)] Loss: 14964.249023\n",
      "Train Epoch: 50 [76160/225000 (34%)] Loss: 15096.733398\n",
      "Train Epoch: 50 [77568/225000 (34%)] Loss: 14924.181641\n",
      "Train Epoch: 50 [78976/225000 (35%)] Loss: 15101.027344\n",
      "Train Epoch: 50 [80384/225000 (36%)] Loss: 14898.312500\n",
      "Train Epoch: 50 [81792/225000 (36%)] Loss: 15085.652344\n",
      "Train Epoch: 50 [83200/225000 (37%)] Loss: 15198.616211\n",
      "Train Epoch: 50 [84608/225000 (38%)] Loss: 14884.358398\n",
      "Train Epoch: 50 [86016/225000 (38%)] Loss: 15016.685547\n",
      "Train Epoch: 50 [87424/225000 (39%)] Loss: 15286.086914\n",
      "Train Epoch: 50 [88832/225000 (39%)] Loss: 14846.359375\n",
      "Train Epoch: 50 [90240/225000 (40%)] Loss: 15249.233398\n",
      "Train Epoch: 50 [91648/225000 (41%)] Loss: 15497.064453\n",
      "Train Epoch: 50 [93056/225000 (41%)] Loss: 15093.270508\n",
      "Train Epoch: 50 [94464/225000 (42%)] Loss: 14612.927734\n",
      "Train Epoch: 50 [95872/225000 (43%)] Loss: 14917.044922\n",
      "Train Epoch: 50 [97280/225000 (43%)] Loss: 15247.089844\n",
      "Train Epoch: 50 [98688/225000 (44%)] Loss: 14899.517578\n",
      "Train Epoch: 50 [100096/225000 (44%)] Loss: 15345.460938\n",
      "Train Epoch: 50 [101504/225000 (45%)] Loss: 15234.869141\n",
      "Train Epoch: 50 [102912/225000 (46%)] Loss: 14842.782227\n",
      "Train Epoch: 50 [104320/225000 (46%)] Loss: 14758.724609\n",
      "Train Epoch: 50 [105728/225000 (47%)] Loss: 15120.086914\n",
      "Train Epoch: 50 [107136/225000 (48%)] Loss: 15144.406250\n",
      "Train Epoch: 50 [108544/225000 (48%)] Loss: 14630.243164\n",
      "Train Epoch: 50 [109952/225000 (49%)] Loss: 15103.889648\n",
      "Train Epoch: 50 [111360/225000 (49%)] Loss: 14672.422852\n",
      "Train Epoch: 50 [112768/225000 (50%)] Loss: 15032.232422\n",
      "Train Epoch: 50 [114176/225000 (51%)] Loss: 15101.463867\n",
      "Train Epoch: 50 [115584/225000 (51%)] Loss: 15613.709961\n",
      "Train Epoch: 50 [116992/225000 (52%)] Loss: 14802.442383\n",
      "Train Epoch: 50 [118400/225000 (53%)] Loss: 15380.877930\n",
      "Train Epoch: 50 [119808/225000 (53%)] Loss: 14619.658203\n",
      "Train Epoch: 50 [121216/225000 (54%)] Loss: 15024.276367\n",
      "Train Epoch: 50 [122624/225000 (54%)] Loss: 14773.700195\n",
      "Train Epoch: 50 [124032/225000 (55%)] Loss: 15526.910156\n",
      "Train Epoch: 50 [125440/225000 (56%)] Loss: 15310.167969\n",
      "Train Epoch: 50 [126848/225000 (56%)] Loss: 14769.654297\n",
      "Train Epoch: 50 [128256/225000 (57%)] Loss: 15024.011719\n",
      "Train Epoch: 50 [129664/225000 (58%)] Loss: 14746.381836\n",
      "Train Epoch: 50 [131072/225000 (58%)] Loss: 14909.805664\n",
      "Train Epoch: 50 [132480/225000 (59%)] Loss: 14787.800781\n",
      "Train Epoch: 50 [133888/225000 (60%)] Loss: 14874.247070\n",
      "Train Epoch: 50 [135296/225000 (60%)] Loss: 15104.902344\n",
      "Train Epoch: 50 [136704/225000 (61%)] Loss: 14847.275391\n",
      "Train Epoch: 50 [138112/225000 (61%)] Loss: 14986.343750\n",
      "Train Epoch: 50 [139520/225000 (62%)] Loss: 15144.800781\n",
      "Train Epoch: 50 [140928/225000 (63%)] Loss: 14902.291992\n",
      "Train Epoch: 50 [142336/225000 (63%)] Loss: 15092.335938\n",
      "Train Epoch: 50 [143744/225000 (64%)] Loss: 15454.425781\n",
      "Train Epoch: 50 [145152/225000 (65%)] Loss: 15494.599609\n",
      "Train Epoch: 50 [146560/225000 (65%)] Loss: 15002.366211\n",
      "Train Epoch: 50 [147968/225000 (66%)] Loss: 14653.944336\n",
      "Train Epoch: 50 [149376/225000 (66%)] Loss: 14889.735352\n",
      "Train Epoch: 50 [150784/225000 (67%)] Loss: 14633.101562\n",
      "Train Epoch: 50 [152192/225000 (68%)] Loss: 15315.817383\n",
      "Train Epoch: 50 [153600/225000 (68%)] Loss: 15398.711914\n",
      "Train Epoch: 50 [155008/225000 (69%)] Loss: 14792.758789\n",
      "Train Epoch: 50 [156416/225000 (70%)] Loss: 15160.401367\n",
      "Train Epoch: 50 [157824/225000 (70%)] Loss: 15051.554688\n",
      "Train Epoch: 50 [159232/225000 (71%)] Loss: 14957.445312\n",
      "Train Epoch: 50 [160640/225000 (71%)] Loss: 15304.808594\n",
      "Train Epoch: 50 [162048/225000 (72%)] Loss: 15012.670898\n",
      "Train Epoch: 50 [163456/225000 (73%)] Loss: 14864.587891\n",
      "Train Epoch: 50 [164864/225000 (73%)] Loss: 14973.897461\n",
      "Train Epoch: 50 [166272/225000 (74%)] Loss: 15008.281250\n",
      "Train Epoch: 50 [167680/225000 (75%)] Loss: 15530.629883\n",
      "Train Epoch: 50 [169088/225000 (75%)] Loss: 15457.875977\n",
      "Train Epoch: 50 [170496/225000 (76%)] Loss: 15062.867188\n",
      "Train Epoch: 50 [171904/225000 (76%)] Loss: 14685.122070\n",
      "Train Epoch: 50 [173312/225000 (77%)] Loss: 15400.235352\n",
      "Train Epoch: 50 [174720/225000 (78%)] Loss: 14957.552734\n",
      "Train Epoch: 50 [176128/225000 (78%)] Loss: 15043.270508\n",
      "Train Epoch: 50 [177536/225000 (79%)] Loss: 14982.540039\n",
      "Train Epoch: 50 [178944/225000 (80%)] Loss: 14987.306641\n",
      "Train Epoch: 50 [180352/225000 (80%)] Loss: 14887.695312\n",
      "Train Epoch: 50 [181760/225000 (81%)] Loss: 15299.538086\n",
      "Train Epoch: 50 [183168/225000 (81%)] Loss: 15163.243164\n",
      "Train Epoch: 50 [184576/225000 (82%)] Loss: 14997.293945\n",
      "Train Epoch: 50 [185984/225000 (83%)] Loss: 15074.562500\n",
      "Train Epoch: 50 [187392/225000 (83%)] Loss: 14969.278320\n",
      "Train Epoch: 50 [188800/225000 (84%)] Loss: 15119.875000\n",
      "Train Epoch: 50 [190208/225000 (85%)] Loss: 15187.819336\n",
      "Train Epoch: 50 [191616/225000 (85%)] Loss: 14924.598633\n",
      "Train Epoch: 50 [193024/225000 (86%)] Loss: 14900.322266\n",
      "Train Epoch: 50 [194432/225000 (86%)] Loss: 15150.512695\n",
      "Train Epoch: 50 [195840/225000 (87%)] Loss: 14770.060547\n",
      "Train Epoch: 50 [197248/225000 (88%)] Loss: 14631.677734\n",
      "Train Epoch: 50 [198656/225000 (88%)] Loss: 15111.511719\n",
      "Train Epoch: 50 [200064/225000 (89%)] Loss: 15379.435547\n",
      "Train Epoch: 50 [201472/225000 (90%)] Loss: 15153.004883\n",
      "Train Epoch: 50 [202880/225000 (90%)] Loss: 15479.039062\n",
      "Train Epoch: 50 [204288/225000 (91%)] Loss: 14958.887695\n",
      "Train Epoch: 50 [205696/225000 (91%)] Loss: 14962.521484\n",
      "Train Epoch: 50 [207104/225000 (92%)] Loss: 15171.124023\n",
      "Train Epoch: 50 [208512/225000 (93%)] Loss: 15116.732422\n",
      "Train Epoch: 50 [209920/225000 (93%)] Loss: 14967.098633\n",
      "Train Epoch: 50 [211328/225000 (94%)] Loss: 15110.299805\n",
      "Train Epoch: 50 [212736/225000 (95%)] Loss: 15178.683594\n",
      "Train Epoch: 50 [214144/225000 (95%)] Loss: 15209.967773\n",
      "Train Epoch: 50 [215552/225000 (96%)] Loss: 14808.429688\n",
      "Train Epoch: 50 [216960/225000 (96%)] Loss: 14830.482422\n",
      "Train Epoch: 50 [218368/225000 (97%)] Loss: 14828.636719\n",
      "Train Epoch: 50 [219776/225000 (98%)] Loss: 14843.155273\n",
      "Train Epoch: 50 [221184/225000 (98%)] Loss: 14959.531250\n",
      "Train Epoch: 50 [222592/225000 (99%)] Loss: 15340.385742\n",
      "Train Epoch: 50 [224000/225000 (100%)] Loss: 14949.472656\n",
      "    epoch          : 50\n",
      "    loss           : 15078.508107468537\n",
      "    val_loss       : 15058.848504940543\n",
      "Saving checkpoint: saved/models/Molecular_VaeCategory/0723_110905/checkpoint-epoch50.pth ...\n",
      "Train Epoch: 51 [128/225000 (0%)] Loss: 15150.437500\n",
      "Train Epoch: 51 [1536/225000 (1%)] Loss: 14827.855469\n",
      "Train Epoch: 51 [2944/225000 (1%)] Loss: 15266.014648\n",
      "Train Epoch: 51 [4352/225000 (2%)] Loss: 15262.529297\n",
      "Train Epoch: 51 [5760/225000 (3%)] Loss: 14862.792969\n",
      "Train Epoch: 51 [7168/225000 (3%)] Loss: 14906.259766\n",
      "Train Epoch: 51 [8576/225000 (4%)] Loss: 15011.066406\n",
      "Train Epoch: 51 [9984/225000 (4%)] Loss: 14906.198242\n",
      "Train Epoch: 51 [11392/225000 (5%)] Loss: 15073.819336\n",
      "Train Epoch: 51 [12800/225000 (6%)] Loss: 14862.055664\n",
      "Train Epoch: 51 [14208/225000 (6%)] Loss: 14694.759766\n",
      "Train Epoch: 51 [15616/225000 (7%)] Loss: 14963.693359\n",
      "Train Epoch: 51 [17024/225000 (8%)] Loss: 15304.036133\n",
      "Train Epoch: 51 [18432/225000 (8%)] Loss: 15072.091797\n",
      "Train Epoch: 51 [19840/225000 (9%)] Loss: 15344.806641\n",
      "Train Epoch: 51 [21248/225000 (9%)] Loss: 14746.063477\n",
      "Train Epoch: 51 [22656/225000 (10%)] Loss: 14858.860352\n",
      "Train Epoch: 51 [24064/225000 (11%)] Loss: 14950.916992\n",
      "Train Epoch: 51 [25472/225000 (11%)] Loss: 15235.835938\n",
      "Train Epoch: 51 [26880/225000 (12%)] Loss: 14982.175781\n",
      "Train Epoch: 51 [28288/225000 (13%)] Loss: 15020.725586\n",
      "Train Epoch: 51 [29696/225000 (13%)] Loss: 15306.041992\n",
      "Train Epoch: 51 [31104/225000 (14%)] Loss: 15219.209961\n",
      "Train Epoch: 51 [32512/225000 (14%)] Loss: 14677.457031\n",
      "Train Epoch: 51 [33920/225000 (15%)] Loss: 15098.144531\n",
      "Train Epoch: 51 [35328/225000 (16%)] Loss: 14890.127930\n",
      "Train Epoch: 51 [36736/225000 (16%)] Loss: 15536.960938\n",
      "Train Epoch: 51 [38144/225000 (17%)] Loss: 15484.670898\n",
      "Train Epoch: 51 [39552/225000 (18%)] Loss: 15051.492188\n",
      "Train Epoch: 51 [40960/225000 (18%)] Loss: 14996.082031\n",
      "Train Epoch: 51 [42368/225000 (19%)] Loss: 15149.321289\n",
      "Train Epoch: 51 [43776/225000 (19%)] Loss: 14933.160156\n",
      "Train Epoch: 51 [45184/225000 (20%)] Loss: 15073.598633\n",
      "Train Epoch: 51 [46592/225000 (21%)] Loss: 15084.851562\n",
      "Train Epoch: 51 [48000/225000 (21%)] Loss: 14895.597656\n",
      "Train Epoch: 51 [49408/225000 (22%)] Loss: 14744.186523\n",
      "Train Epoch: 51 [50816/225000 (23%)] Loss: 14931.950195\n",
      "Train Epoch: 51 [52224/225000 (23%)] Loss: 14804.378906\n",
      "Train Epoch: 51 [53632/225000 (24%)] Loss: 15190.004883\n",
      "Train Epoch: 51 [55040/225000 (24%)] Loss: 15423.636719\n",
      "Train Epoch: 51 [56448/225000 (25%)] Loss: 15172.912109\n",
      "Train Epoch: 51 [57856/225000 (26%)] Loss: 14882.739258\n",
      "Train Epoch: 51 [59264/225000 (26%)] Loss: 15595.129883\n",
      "Train Epoch: 51 [60672/225000 (27%)] Loss: 15009.554688\n",
      "Train Epoch: 51 [62080/225000 (28%)] Loss: 14980.083008\n",
      "Train Epoch: 51 [63488/225000 (28%)] Loss: 14891.570312\n",
      "Train Epoch: 51 [64896/225000 (29%)] Loss: 15056.775391\n",
      "Train Epoch: 51 [66304/225000 (29%)] Loss: 15360.689453\n",
      "Train Epoch: 51 [67712/225000 (30%)] Loss: 14977.138672\n",
      "Train Epoch: 51 [69120/225000 (31%)] Loss: 15548.101562\n",
      "Train Epoch: 51 [70528/225000 (31%)] Loss: 14927.968750\n",
      "Train Epoch: 51 [71936/225000 (32%)] Loss: 14974.493164\n",
      "Train Epoch: 51 [73344/225000 (33%)] Loss: 15380.611328\n",
      "Train Epoch: 51 [74752/225000 (33%)] Loss: 15280.197266\n",
      "Train Epoch: 51 [76160/225000 (34%)] Loss: 15282.078125\n",
      "Train Epoch: 51 [77568/225000 (34%)] Loss: 15436.362305\n",
      "Train Epoch: 51 [78976/225000 (35%)] Loss: 14913.961914\n",
      "Train Epoch: 51 [80384/225000 (36%)] Loss: 14879.185547\n",
      "Train Epoch: 51 [81792/225000 (36%)] Loss: 14715.717773\n",
      "Train Epoch: 51 [83200/225000 (37%)] Loss: 15270.078125\n",
      "Train Epoch: 51 [84608/225000 (38%)] Loss: 15285.211914\n",
      "Train Epoch: 51 [86016/225000 (38%)] Loss: 15099.931641\n",
      "Train Epoch: 51 [87424/225000 (39%)] Loss: 14989.918945\n",
      "Train Epoch: 51 [88832/225000 (39%)] Loss: 15090.685547\n",
      "Train Epoch: 51 [90240/225000 (40%)] Loss: 15406.898438\n",
      "Train Epoch: 51 [91648/225000 (41%)] Loss: 14734.129883\n",
      "Train Epoch: 51 [93056/225000 (41%)] Loss: 15474.791016\n",
      "Train Epoch: 51 [94464/225000 (42%)] Loss: 15210.663086\n",
      "Train Epoch: 51 [95872/225000 (43%)] Loss: 14483.763672\n",
      "Train Epoch: 51 [97280/225000 (43%)] Loss: 15067.959961\n",
      "Train Epoch: 51 [98688/225000 (44%)] Loss: 14959.805664\n",
      "Train Epoch: 51 [100096/225000 (44%)] Loss: 15708.549805\n",
      "Train Epoch: 51 [101504/225000 (45%)] Loss: 14955.675781\n",
      "Train Epoch: 51 [102912/225000 (46%)] Loss: 15474.941406\n",
      "Train Epoch: 51 [104320/225000 (46%)] Loss: 15200.602539\n",
      "Train Epoch: 51 [105728/225000 (47%)] Loss: 14415.536133\n",
      "Train Epoch: 51 [107136/225000 (48%)] Loss: 15567.802734\n",
      "Train Epoch: 51 [108544/225000 (48%)] Loss: 14682.719727\n",
      "Train Epoch: 51 [109952/225000 (49%)] Loss: 14987.455078\n",
      "Train Epoch: 51 [111360/225000 (49%)] Loss: 15195.652344\n",
      "Train Epoch: 51 [112768/225000 (50%)] Loss: 14925.479492\n",
      "Train Epoch: 51 [114176/225000 (51%)] Loss: 14967.713867\n",
      "Train Epoch: 51 [115584/225000 (51%)] Loss: 14950.686523\n",
      "Train Epoch: 51 [116992/225000 (52%)] Loss: 14899.107422\n",
      "Train Epoch: 51 [118400/225000 (53%)] Loss: 14768.057617\n",
      "Train Epoch: 51 [119808/225000 (53%)] Loss: 15021.357422\n",
      "Train Epoch: 51 [121216/225000 (54%)] Loss: 15003.890625\n",
      "Train Epoch: 51 [122624/225000 (54%)] Loss: 15049.467773\n",
      "Train Epoch: 51 [124032/225000 (55%)] Loss: 14903.033203\n",
      "Train Epoch: 51 [125440/225000 (56%)] Loss: 14851.249023\n",
      "Train Epoch: 51 [126848/225000 (56%)] Loss: 14830.485352\n",
      "Train Epoch: 51 [128256/225000 (57%)] Loss: 15049.263672\n",
      "Train Epoch: 51 [129664/225000 (58%)] Loss: 15191.258789\n",
      "Train Epoch: 51 [131072/225000 (58%)] Loss: 14966.191406\n",
      "Train Epoch: 51 [132480/225000 (59%)] Loss: 15494.770508\n",
      "Train Epoch: 51 [133888/225000 (60%)] Loss: 14616.377930\n",
      "Train Epoch: 51 [135296/225000 (60%)] Loss: 15379.779297\n",
      "Train Epoch: 51 [136704/225000 (61%)] Loss: 14779.582031\n",
      "Train Epoch: 51 [138112/225000 (61%)] Loss: 14872.000977\n",
      "Train Epoch: 51 [139520/225000 (62%)] Loss: 15418.737305\n",
      "Train Epoch: 51 [140928/225000 (63%)] Loss: 15085.692383\n",
      "Train Epoch: 51 [142336/225000 (63%)] Loss: 15232.899414\n",
      "Train Epoch: 51 [143744/225000 (64%)] Loss: 14885.407227\n",
      "Train Epoch: 51 [145152/225000 (65%)] Loss: 14554.544922\n",
      "Train Epoch: 51 [146560/225000 (65%)] Loss: 14746.040039\n",
      "Train Epoch: 51 [147968/225000 (66%)] Loss: 15291.825195\n",
      "Train Epoch: 51 [149376/225000 (66%)] Loss: 15336.982422\n",
      "Train Epoch: 51 [150784/225000 (67%)] Loss: 15341.074219\n",
      "Train Epoch: 51 [152192/225000 (68%)] Loss: 14973.044922\n",
      "Train Epoch: 51 [153600/225000 (68%)] Loss: 15316.609375\n",
      "Train Epoch: 51 [155008/225000 (69%)] Loss: 14684.650391\n",
      "Train Epoch: 51 [156416/225000 (70%)] Loss: 15362.428711\n",
      "Train Epoch: 51 [157824/225000 (70%)] Loss: 14888.502930\n",
      "Train Epoch: 51 [159232/225000 (71%)] Loss: 14836.220703\n",
      "Train Epoch: 51 [160640/225000 (71%)] Loss: 15004.900391\n",
      "Train Epoch: 51 [162048/225000 (72%)] Loss: 14933.838867\n",
      "Train Epoch: 51 [163456/225000 (73%)] Loss: 14840.243164\n",
      "Train Epoch: 51 [164864/225000 (73%)] Loss: 14628.553711\n",
      "Train Epoch: 51 [166272/225000 (74%)] Loss: 15365.676758\n",
      "Train Epoch: 51 [167680/225000 (75%)] Loss: 14940.713867\n",
      "Train Epoch: 51 [169088/225000 (75%)] Loss: 15213.282227\n",
      "Train Epoch: 51 [170496/225000 (76%)] Loss: 15261.247070\n",
      "Train Epoch: 51 [171904/225000 (76%)] Loss: 14632.386719\n",
      "Train Epoch: 51 [173312/225000 (77%)] Loss: 15128.826172\n",
      "Train Epoch: 51 [174720/225000 (78%)] Loss: 14460.275391\n",
      "Train Epoch: 51 [176128/225000 (78%)] Loss: 15419.757812\n",
      "Train Epoch: 51 [177536/225000 (79%)] Loss: 15431.063477\n",
      "Train Epoch: 51 [178944/225000 (80%)] Loss: 14895.121094\n",
      "Train Epoch: 51 [180352/225000 (80%)] Loss: 15254.045898\n",
      "Train Epoch: 51 [181760/225000 (81%)] Loss: 15202.238281\n",
      "Train Epoch: 51 [183168/225000 (81%)] Loss: 14792.007812\n",
      "Train Epoch: 51 [184576/225000 (82%)] Loss: 14604.318359\n",
      "Train Epoch: 51 [185984/225000 (83%)] Loss: 15056.060547\n",
      "Train Epoch: 51 [187392/225000 (83%)] Loss: 14934.378906\n",
      "Train Epoch: 51 [188800/225000 (84%)] Loss: 15116.834961\n",
      "Train Epoch: 51 [190208/225000 (85%)] Loss: 15360.516602\n",
      "Train Epoch: 51 [191616/225000 (85%)] Loss: 15281.835938\n",
      "Train Epoch: 51 [193024/225000 (86%)] Loss: 14642.700195\n",
      "Train Epoch: 51 [194432/225000 (86%)] Loss: 15160.727539\n",
      "Train Epoch: 51 [195840/225000 (87%)] Loss: 14913.252930\n",
      "Train Epoch: 51 [197248/225000 (88%)] Loss: 15228.340820\n",
      "Train Epoch: 51 [198656/225000 (88%)] Loss: 15247.626953\n",
      "Train Epoch: 51 [200064/225000 (89%)] Loss: 14930.305664\n",
      "Train Epoch: 51 [201472/225000 (90%)] Loss: 14787.024414\n",
      "Train Epoch: 51 [202880/225000 (90%)] Loss: 15153.960938\n",
      "Train Epoch: 51 [204288/225000 (91%)] Loss: 15182.341797\n",
      "Train Epoch: 51 [205696/225000 (91%)] Loss: 15130.464844\n",
      "Train Epoch: 51 [207104/225000 (92%)] Loss: 15313.738281\n",
      "Train Epoch: 51 [208512/225000 (93%)] Loss: 14782.059570\n",
      "Train Epoch: 51 [209920/225000 (93%)] Loss: 15180.791992\n",
      "Train Epoch: 51 [211328/225000 (94%)] Loss: 15066.112305\n",
      "Train Epoch: 51 [212736/225000 (95%)] Loss: 15061.556641\n",
      "Train Epoch: 51 [214144/225000 (95%)] Loss: 15303.892578\n",
      "Train Epoch: 51 [215552/225000 (96%)] Loss: 15039.886719\n",
      "Train Epoch: 51 [216960/225000 (96%)] Loss: 15178.130859\n",
      "Train Epoch: 51 [218368/225000 (97%)] Loss: 14936.887695\n",
      "Train Epoch: 51 [219776/225000 (98%)] Loss: 14905.773438\n",
      "Train Epoch: 51 [221184/225000 (98%)] Loss: 15057.554688\n",
      "Train Epoch: 51 [222592/225000 (99%)] Loss: 15166.484375\n",
      "Train Epoch: 51 [224000/225000 (100%)] Loss: 15276.417969\n",
      "    epoch          : 51\n",
      "    loss           : 15080.66440524122\n",
      "    val_loss       : 15066.643096897675\n",
      "Train Epoch: 52 [128/225000 (0%)] Loss: 15122.928711\n",
      "Train Epoch: 52 [1536/225000 (1%)] Loss: 15216.640625\n",
      "Train Epoch: 52 [2944/225000 (1%)] Loss: 14806.056641\n",
      "Train Epoch: 52 [4352/225000 (2%)] Loss: 15145.529297\n",
      "Train Epoch: 52 [5760/225000 (3%)] Loss: 15269.956055\n",
      "Train Epoch: 52 [7168/225000 (3%)] Loss: 15476.678711\n",
      "Train Epoch: 52 [8576/225000 (4%)] Loss: 15401.334961\n",
      "Train Epoch: 52 [9984/225000 (4%)] Loss: 14993.312500\n",
      "Train Epoch: 52 [11392/225000 (5%)] Loss: 14960.527344\n",
      "Train Epoch: 52 [12800/225000 (6%)] Loss: 15194.925781\n",
      "Train Epoch: 52 [14208/225000 (6%)] Loss: 15119.912109\n",
      "Train Epoch: 52 [15616/225000 (7%)] Loss: 14764.284180\n",
      "Train Epoch: 52 [17024/225000 (8%)] Loss: 14835.647461\n",
      "Train Epoch: 52 [18432/225000 (8%)] Loss: 15114.791016\n",
      "Train Epoch: 52 [19840/225000 (9%)] Loss: 14828.504883\n",
      "Train Epoch: 52 [21248/225000 (9%)] Loss: 15256.892578\n",
      "Train Epoch: 52 [22656/225000 (10%)] Loss: 15629.575195\n",
      "Train Epoch: 52 [24064/225000 (11%)] Loss: 15206.346680\n",
      "Train Epoch: 52 [25472/225000 (11%)] Loss: 15258.451172\n",
      "Train Epoch: 52 [26880/225000 (12%)] Loss: 15017.412109\n",
      "Train Epoch: 52 [28288/225000 (13%)] Loss: 14599.586914\n",
      "Train Epoch: 52 [29696/225000 (13%)] Loss: 15199.775391\n",
      "Train Epoch: 52 [31104/225000 (14%)] Loss: 15301.545898\n",
      "Train Epoch: 52 [32512/225000 (14%)] Loss: 15145.961914\n",
      "Train Epoch: 52 [33920/225000 (15%)] Loss: 15066.801758\n",
      "Train Epoch: 52 [35328/225000 (16%)] Loss: 14963.341797\n",
      "Train Epoch: 52 [36736/225000 (16%)] Loss: 14740.920898\n",
      "Train Epoch: 52 [38144/225000 (17%)] Loss: 15039.815430\n",
      "Train Epoch: 52 [39552/225000 (18%)] Loss: 15011.020508\n",
      "Train Epoch: 52 [40960/225000 (18%)] Loss: 14921.376953\n",
      "Train Epoch: 52 [42368/225000 (19%)] Loss: 15299.249023\n",
      "Train Epoch: 52 [43776/225000 (19%)] Loss: 15285.959961\n",
      "Train Epoch: 52 [45184/225000 (20%)] Loss: 15093.805664\n",
      "Train Epoch: 52 [46592/225000 (21%)] Loss: 15232.613281\n",
      "Train Epoch: 52 [48000/225000 (21%)] Loss: 15048.076172\n",
      "Train Epoch: 52 [49408/225000 (22%)] Loss: 15150.728516\n",
      "Train Epoch: 52 [50816/225000 (23%)] Loss: 15028.857422\n",
      "Train Epoch: 52 [52224/225000 (23%)] Loss: 14982.633789\n",
      "Train Epoch: 52 [53632/225000 (24%)] Loss: 15036.831055\n",
      "Train Epoch: 52 [55040/225000 (24%)] Loss: 14987.974609\n",
      "Train Epoch: 52 [56448/225000 (25%)] Loss: 14662.763672\n",
      "Train Epoch: 52 [57856/225000 (26%)] Loss: 15541.963867\n",
      "Train Epoch: 52 [59264/225000 (26%)] Loss: 15180.797852\n",
      "Train Epoch: 52 [60672/225000 (27%)] Loss: 14685.920898\n",
      "Train Epoch: 52 [62080/225000 (28%)] Loss: 15305.674805\n",
      "Train Epoch: 52 [63488/225000 (28%)] Loss: 14752.269531\n",
      "Train Epoch: 52 [64896/225000 (29%)] Loss: 15035.904297\n",
      "Train Epoch: 52 [66304/225000 (29%)] Loss: 14752.015625\n",
      "Train Epoch: 52 [67712/225000 (30%)] Loss: 14978.349609\n",
      "Train Epoch: 52 [69120/225000 (31%)] Loss: 14785.915039\n",
      "Train Epoch: 52 [70528/225000 (31%)] Loss: 15124.727539\n",
      "Train Epoch: 52 [71936/225000 (32%)] Loss: 14658.293945\n",
      "Train Epoch: 52 [73344/225000 (33%)] Loss: 14993.541992\n",
      "Train Epoch: 52 [74752/225000 (33%)] Loss: 15000.145508\n",
      "Train Epoch: 52 [76160/225000 (34%)] Loss: 15047.208984\n",
      "Train Epoch: 52 [77568/225000 (34%)] Loss: 15022.548828\n",
      "Train Epoch: 52 [78976/225000 (35%)] Loss: 15275.150391\n",
      "Train Epoch: 52 [80384/225000 (36%)] Loss: 14874.501953\n",
      "Train Epoch: 52 [81792/225000 (36%)] Loss: 14736.204102\n",
      "Train Epoch: 52 [83200/225000 (37%)] Loss: 15097.657227\n",
      "Train Epoch: 52 [84608/225000 (38%)] Loss: 15231.173828\n",
      "Train Epoch: 52 [86016/225000 (38%)] Loss: 14802.425781\n",
      "Train Epoch: 52 [87424/225000 (39%)] Loss: 14935.641602\n",
      "Train Epoch: 52 [88832/225000 (39%)] Loss: 15238.298828\n",
      "Train Epoch: 52 [90240/225000 (40%)] Loss: 15377.889648\n",
      "Train Epoch: 52 [91648/225000 (41%)] Loss: 14863.814453\n",
      "Train Epoch: 52 [93056/225000 (41%)] Loss: 14666.481445\n",
      "Train Epoch: 52 [94464/225000 (42%)] Loss: 15043.761719\n",
      "Train Epoch: 52 [95872/225000 (43%)] Loss: 15040.875000\n",
      "Train Epoch: 52 [97280/225000 (43%)] Loss: 14632.172852\n",
      "Train Epoch: 52 [98688/225000 (44%)] Loss: 15123.023438\n",
      "Train Epoch: 52 [100096/225000 (44%)] Loss: 15196.023438\n",
      "Train Epoch: 52 [101504/225000 (45%)] Loss: 14681.000977\n",
      "Train Epoch: 52 [102912/225000 (46%)] Loss: 15563.782227\n",
      "Train Epoch: 52 [104320/225000 (46%)] Loss: 15695.774414\n",
      "Train Epoch: 52 [105728/225000 (47%)] Loss: 15028.841797\n",
      "Train Epoch: 52 [107136/225000 (48%)] Loss: 14971.833984\n",
      "Train Epoch: 52 [108544/225000 (48%)] Loss: 14864.856445\n",
      "Train Epoch: 52 [109952/225000 (49%)] Loss: 15117.283203\n",
      "Train Epoch: 52 [111360/225000 (49%)] Loss: 15272.039062\n",
      "Train Epoch: 52 [112768/225000 (50%)] Loss: 15258.042969\n",
      "Train Epoch: 52 [114176/225000 (51%)] Loss: 15197.282227\n",
      "Train Epoch: 52 [115584/225000 (51%)] Loss: 15306.146484\n",
      "Train Epoch: 52 [116992/225000 (52%)] Loss: 15385.640625\n",
      "Train Epoch: 52 [118400/225000 (53%)] Loss: 15232.678711\n",
      "Train Epoch: 52 [119808/225000 (53%)] Loss: 15332.558594\n",
      "Train Epoch: 52 [121216/225000 (54%)] Loss: 14690.285156\n",
      "Train Epoch: 52 [122624/225000 (54%)] Loss: 15172.462891\n",
      "Train Epoch: 52 [124032/225000 (55%)] Loss: 15109.231445\n",
      "Train Epoch: 52 [125440/225000 (56%)] Loss: 15148.301758\n",
      "Train Epoch: 52 [126848/225000 (56%)] Loss: 14948.633789\n",
      "Train Epoch: 52 [128256/225000 (57%)] Loss: 15346.450195\n",
      "Train Epoch: 52 [129664/225000 (58%)] Loss: 15300.841797\n",
      "Train Epoch: 52 [131072/225000 (58%)] Loss: 15168.289062\n",
      "Train Epoch: 52 [132480/225000 (59%)] Loss: 15140.320312\n",
      "Train Epoch: 52 [133888/225000 (60%)] Loss: 15062.779297\n",
      "Train Epoch: 52 [135296/225000 (60%)] Loss: 14870.465820\n",
      "Train Epoch: 52 [136704/225000 (61%)] Loss: 15023.469727\n",
      "Train Epoch: 52 [138112/225000 (61%)] Loss: 15069.476562\n",
      "Train Epoch: 52 [139520/225000 (62%)] Loss: 15087.364258\n",
      "Train Epoch: 52 [140928/225000 (63%)] Loss: 14775.657227\n",
      "Train Epoch: 52 [142336/225000 (63%)] Loss: 15032.202148\n",
      "Train Epoch: 52 [143744/225000 (64%)] Loss: 14721.264648\n",
      "Train Epoch: 52 [145152/225000 (65%)] Loss: 14823.624023\n",
      "Train Epoch: 52 [146560/225000 (65%)] Loss: 15632.809570\n",
      "Train Epoch: 52 [147968/225000 (66%)] Loss: 14988.826172\n",
      "Train Epoch: 52 [149376/225000 (66%)] Loss: 14972.909180\n",
      "Train Epoch: 52 [150784/225000 (67%)] Loss: 15187.771484\n",
      "Train Epoch: 52 [152192/225000 (68%)] Loss: 15606.188477\n",
      "Train Epoch: 52 [153600/225000 (68%)] Loss: 15189.755859\n",
      "Train Epoch: 52 [155008/225000 (69%)] Loss: 14826.934570\n",
      "Train Epoch: 52 [156416/225000 (70%)] Loss: 15270.986328\n",
      "Train Epoch: 52 [157824/225000 (70%)] Loss: 15061.305664\n",
      "Train Epoch: 52 [159232/225000 (71%)] Loss: 14807.023438\n",
      "Train Epoch: 52 [160640/225000 (71%)] Loss: 15089.662109\n",
      "Train Epoch: 52 [162048/225000 (72%)] Loss: 15202.755859\n",
      "Train Epoch: 52 [163456/225000 (73%)] Loss: 15190.314453\n",
      "Train Epoch: 52 [164864/225000 (73%)] Loss: 15110.494141\n",
      "Train Epoch: 52 [166272/225000 (74%)] Loss: 14937.715820\n",
      "Train Epoch: 52 [167680/225000 (75%)] Loss: 15057.318359\n",
      "Train Epoch: 52 [169088/225000 (75%)] Loss: 14946.465820\n",
      "Train Epoch: 52 [170496/225000 (76%)] Loss: 14811.791992\n",
      "Train Epoch: 52 [171904/225000 (76%)] Loss: 15160.454102\n",
      "Train Epoch: 52 [173312/225000 (77%)] Loss: 15073.233398\n",
      "Train Epoch: 52 [174720/225000 (78%)] Loss: 14491.970703\n",
      "Train Epoch: 52 [176128/225000 (78%)] Loss: 15517.490234\n",
      "Train Epoch: 52 [177536/225000 (79%)] Loss: 14949.797852\n",
      "Train Epoch: 52 [178944/225000 (80%)] Loss: 15245.838867\n",
      "Train Epoch: 52 [180352/225000 (80%)] Loss: 15763.728516\n",
      "Train Epoch: 52 [181760/225000 (81%)] Loss: 15227.234375\n",
      "Train Epoch: 52 [183168/225000 (81%)] Loss: 14890.433594\n",
      "Train Epoch: 52 [184576/225000 (82%)] Loss: 15302.734375\n",
      "Train Epoch: 52 [185984/225000 (83%)] Loss: 15073.946289\n",
      "Train Epoch: 52 [187392/225000 (83%)] Loss: 14797.938477\n",
      "Train Epoch: 52 [188800/225000 (84%)] Loss: 15315.116211\n",
      "Train Epoch: 52 [190208/225000 (85%)] Loss: 14951.768555\n",
      "Train Epoch: 52 [191616/225000 (85%)] Loss: 15128.114258\n",
      "Train Epoch: 52 [193024/225000 (86%)] Loss: 15407.268555\n",
      "Train Epoch: 52 [194432/225000 (86%)] Loss: 15451.560547\n",
      "Train Epoch: 52 [195840/225000 (87%)] Loss: 15034.904297\n",
      "Train Epoch: 52 [197248/225000 (88%)] Loss: 15047.236328\n",
      "Train Epoch: 52 [198656/225000 (88%)] Loss: 15271.167969\n",
      "Train Epoch: 52 [200064/225000 (89%)] Loss: 15097.326172\n",
      "Train Epoch: 52 [201472/225000 (90%)] Loss: 15166.226562\n",
      "Train Epoch: 52 [202880/225000 (90%)] Loss: 15231.015625\n",
      "Train Epoch: 52 [204288/225000 (91%)] Loss: 15299.396484\n",
      "Train Epoch: 52 [205696/225000 (91%)] Loss: 14731.557617\n",
      "Train Epoch: 52 [207104/225000 (92%)] Loss: 15522.250977\n",
      "Train Epoch: 52 [208512/225000 (93%)] Loss: 15000.564453\n",
      "Train Epoch: 52 [209920/225000 (93%)] Loss: 15310.463867\n",
      "Train Epoch: 52 [211328/225000 (94%)] Loss: 14433.010742\n",
      "Train Epoch: 52 [212736/225000 (95%)] Loss: 15054.283203\n",
      "Train Epoch: 52 [214144/225000 (95%)] Loss: 15143.976562\n",
      "Train Epoch: 52 [215552/225000 (96%)] Loss: 15099.651367\n",
      "Train Epoch: 52 [216960/225000 (96%)] Loss: 14728.961914\n",
      "Train Epoch: 52 [218368/225000 (97%)] Loss: 15193.725586\n",
      "Train Epoch: 52 [219776/225000 (98%)] Loss: 15344.618164\n",
      "Train Epoch: 52 [221184/225000 (98%)] Loss: 14991.626953\n",
      "Train Epoch: 52 [222592/225000 (99%)] Loss: 14875.182617\n",
      "Train Epoch: 52 [224000/225000 (100%)] Loss: 14950.959961\n",
      "    epoch          : 52\n",
      "    loss           : 15075.574850904792\n",
      "    val_loss       : 15068.533274131465\n",
      "Train Epoch: 53 [128/225000 (0%)] Loss: 14840.843750\n",
      "Train Epoch: 53 [1536/225000 (1%)] Loss: 15344.941406\n",
      "Train Epoch: 53 [2944/225000 (1%)] Loss: 15057.317383\n",
      "Train Epoch: 53 [4352/225000 (2%)] Loss: 15425.775391\n",
      "Train Epoch: 53 [5760/225000 (3%)] Loss: 15104.247070\n",
      "Train Epoch: 53 [7168/225000 (3%)] Loss: 15112.139648\n",
      "Train Epoch: 53 [8576/225000 (4%)] Loss: 14969.649414\n",
      "Train Epoch: 53 [9984/225000 (4%)] Loss: 15134.006836\n",
      "Train Epoch: 53 [11392/225000 (5%)] Loss: 15236.994141\n",
      "Train Epoch: 53 [12800/225000 (6%)] Loss: 15185.909180\n",
      "Train Epoch: 53 [14208/225000 (6%)] Loss: 15109.421875\n",
      "Train Epoch: 53 [15616/225000 (7%)] Loss: 15250.223633\n",
      "Train Epoch: 53 [17024/225000 (8%)] Loss: 14690.219727\n",
      "Train Epoch: 53 [18432/225000 (8%)] Loss: 15122.654297\n",
      "Train Epoch: 53 [19840/225000 (9%)] Loss: 15143.976562\n",
      "Train Epoch: 53 [21248/225000 (9%)] Loss: 15007.087891\n",
      "Train Epoch: 53 [22656/225000 (10%)] Loss: 15129.870117\n",
      "Train Epoch: 53 [24064/225000 (11%)] Loss: 14941.409180\n",
      "Train Epoch: 53 [25472/225000 (11%)] Loss: 15266.612305\n",
      "Train Epoch: 53 [26880/225000 (12%)] Loss: 15047.799805\n",
      "Train Epoch: 53 [28288/225000 (13%)] Loss: 15157.872070\n",
      "Train Epoch: 53 [29696/225000 (13%)] Loss: 15546.568359\n",
      "Train Epoch: 53 [31104/225000 (14%)] Loss: 14743.190430\n",
      "Train Epoch: 53 [32512/225000 (14%)] Loss: 14902.325195\n",
      "Train Epoch: 53 [33920/225000 (15%)] Loss: 15052.520508\n",
      "Train Epoch: 53 [35328/225000 (16%)] Loss: 15509.763672\n",
      "Train Epoch: 53 [36736/225000 (16%)] Loss: 15352.765625\n",
      "Train Epoch: 53 [38144/225000 (17%)] Loss: 15637.671875\n",
      "Train Epoch: 53 [39552/225000 (18%)] Loss: 14943.996094\n",
      "Train Epoch: 53 [40960/225000 (18%)] Loss: 14728.324219\n",
      "Train Epoch: 53 [42368/225000 (19%)] Loss: 15141.536133\n",
      "Train Epoch: 53 [43776/225000 (19%)] Loss: 15188.427734\n",
      "Train Epoch: 53 [45184/225000 (20%)] Loss: 14914.789062\n",
      "Train Epoch: 53 [46592/225000 (21%)] Loss: 14837.887695\n",
      "Train Epoch: 53 [48000/225000 (21%)] Loss: 14802.651367\n",
      "Train Epoch: 53 [49408/225000 (22%)] Loss: 14850.803711\n",
      "Train Epoch: 53 [50816/225000 (23%)] Loss: 15091.242188\n",
      "Train Epoch: 53 [52224/225000 (23%)] Loss: 15336.811523\n",
      "Train Epoch: 53 [53632/225000 (24%)] Loss: 15494.158203\n",
      "Train Epoch: 53 [55040/225000 (24%)] Loss: 15125.294922\n",
      "Train Epoch: 53 [56448/225000 (25%)] Loss: 14763.569336\n",
      "Train Epoch: 53 [57856/225000 (26%)] Loss: 14646.734375\n",
      "Train Epoch: 53 [59264/225000 (26%)] Loss: 15516.412109\n",
      "Train Epoch: 53 [60672/225000 (27%)] Loss: 15125.152344\n",
      "Train Epoch: 53 [62080/225000 (28%)] Loss: 15070.316406\n",
      "Train Epoch: 53 [63488/225000 (28%)] Loss: 14807.306641\n",
      "Train Epoch: 53 [64896/225000 (29%)] Loss: 15262.398438\n",
      "Train Epoch: 53 [66304/225000 (29%)] Loss: 15358.945312\n",
      "Train Epoch: 53 [67712/225000 (30%)] Loss: 15144.368164\n",
      "Train Epoch: 53 [69120/225000 (31%)] Loss: 15378.581055\n",
      "Train Epoch: 53 [70528/225000 (31%)] Loss: 15005.300781\n",
      "Train Epoch: 53 [71936/225000 (32%)] Loss: 14888.343750\n",
      "Train Epoch: 53 [73344/225000 (33%)] Loss: 14976.766602\n",
      "Train Epoch: 53 [74752/225000 (33%)] Loss: 14935.750000\n",
      "Train Epoch: 53 [76160/225000 (34%)] Loss: 15302.214844\n",
      "Train Epoch: 53 [77568/225000 (34%)] Loss: 14735.989258\n",
      "Train Epoch: 53 [78976/225000 (35%)] Loss: 15216.387695\n",
      "Train Epoch: 53 [80384/225000 (36%)] Loss: 14825.152344\n",
      "Train Epoch: 53 [81792/225000 (36%)] Loss: 15171.622070\n",
      "Train Epoch: 53 [83200/225000 (37%)] Loss: 15214.054688\n",
      "Train Epoch: 53 [84608/225000 (38%)] Loss: 15130.081055\n",
      "Train Epoch: 53 [86016/225000 (38%)] Loss: 14789.892578\n",
      "Train Epoch: 53 [87424/225000 (39%)] Loss: 14959.909180\n",
      "Train Epoch: 53 [88832/225000 (39%)] Loss: 15180.262695\n",
      "Train Epoch: 53 [90240/225000 (40%)] Loss: 15031.744141\n",
      "Train Epoch: 53 [91648/225000 (41%)] Loss: 15020.660156\n",
      "Train Epoch: 53 [93056/225000 (41%)] Loss: 15228.165039\n",
      "Train Epoch: 53 [94464/225000 (42%)] Loss: 15233.435547\n",
      "Train Epoch: 53 [95872/225000 (43%)] Loss: 15171.528320\n",
      "Train Epoch: 53 [97280/225000 (43%)] Loss: 15194.652344\n",
      "Train Epoch: 53 [98688/225000 (44%)] Loss: 14618.347656\n",
      "Train Epoch: 53 [100096/225000 (44%)] Loss: 15226.934570\n",
      "Train Epoch: 53 [101504/225000 (45%)] Loss: 15229.821289\n",
      "Train Epoch: 53 [102912/225000 (46%)] Loss: 15165.756836\n",
      "Train Epoch: 53 [104320/225000 (46%)] Loss: 15093.064453\n",
      "Train Epoch: 53 [105728/225000 (47%)] Loss: 14992.293945\n",
      "Train Epoch: 53 [107136/225000 (48%)] Loss: 15474.763672\n",
      "Train Epoch: 53 [108544/225000 (48%)] Loss: 15112.965820\n",
      "Train Epoch: 53 [109952/225000 (49%)] Loss: 15081.400391\n",
      "Train Epoch: 53 [111360/225000 (49%)] Loss: 15279.809570\n",
      "Train Epoch: 53 [112768/225000 (50%)] Loss: 15151.728516\n",
      "Train Epoch: 53 [114176/225000 (51%)] Loss: 14705.585938\n",
      "Train Epoch: 53 [115584/225000 (51%)] Loss: 15512.819336\n",
      "Train Epoch: 53 [116992/225000 (52%)] Loss: 14964.767578\n",
      "Train Epoch: 53 [118400/225000 (53%)] Loss: 15115.232422\n",
      "Train Epoch: 53 [119808/225000 (53%)] Loss: 15237.487305\n",
      "Train Epoch: 53 [121216/225000 (54%)] Loss: 14416.165039\n",
      "Train Epoch: 53 [122624/225000 (54%)] Loss: 15052.096680\n",
      "Train Epoch: 53 [124032/225000 (55%)] Loss: 15305.308594\n",
      "Train Epoch: 53 [125440/225000 (56%)] Loss: 15475.441406\n",
      "Train Epoch: 53 [126848/225000 (56%)] Loss: 15049.746094\n",
      "Train Epoch: 53 [128256/225000 (57%)] Loss: 15114.562500\n",
      "Train Epoch: 53 [129664/225000 (58%)] Loss: 15132.800781\n",
      "Train Epoch: 53 [131072/225000 (58%)] Loss: 14859.623047\n",
      "Train Epoch: 53 [132480/225000 (59%)] Loss: 15011.751953\n",
      "Train Epoch: 53 [133888/225000 (60%)] Loss: 15056.559570\n",
      "Train Epoch: 53 [135296/225000 (60%)] Loss: 14994.906250\n",
      "Train Epoch: 53 [136704/225000 (61%)] Loss: 14672.432617\n",
      "Train Epoch: 53 [138112/225000 (61%)] Loss: 14602.658203\n",
      "Train Epoch: 53 [139520/225000 (62%)] Loss: 15530.561523\n",
      "Train Epoch: 53 [140928/225000 (63%)] Loss: 15308.180664\n",
      "Train Epoch: 53 [142336/225000 (63%)] Loss: 14629.617188\n",
      "Train Epoch: 53 [143744/225000 (64%)] Loss: 14923.886719\n",
      "Train Epoch: 53 [145152/225000 (65%)] Loss: 15140.020508\n",
      "Train Epoch: 53 [146560/225000 (65%)] Loss: 14969.467773\n",
      "Train Epoch: 53 [147968/225000 (66%)] Loss: 15119.804688\n",
      "Train Epoch: 53 [149376/225000 (66%)] Loss: 14667.923828\n",
      "Train Epoch: 53 [150784/225000 (67%)] Loss: 14834.625977\n",
      "Train Epoch: 53 [152192/225000 (68%)] Loss: 14907.477539\n",
      "Train Epoch: 53 [153600/225000 (68%)] Loss: 14791.410156\n",
      "Train Epoch: 53 [155008/225000 (69%)] Loss: 15018.364258\n",
      "Train Epoch: 53 [156416/225000 (70%)] Loss: 14949.678711\n",
      "Train Epoch: 53 [157824/225000 (70%)] Loss: 14782.138672\n",
      "Train Epoch: 53 [159232/225000 (71%)] Loss: 15010.784180\n",
      "Train Epoch: 53 [160640/225000 (71%)] Loss: 14867.741211\n",
      "Train Epoch: 53 [162048/225000 (72%)] Loss: 14799.914062\n",
      "Train Epoch: 53 [163456/225000 (73%)] Loss: 14555.097656\n",
      "Train Epoch: 53 [164864/225000 (73%)] Loss: 15457.443359\n",
      "Train Epoch: 53 [166272/225000 (74%)] Loss: 15115.806641\n",
      "Train Epoch: 53 [167680/225000 (75%)] Loss: 15388.476562\n",
      "Train Epoch: 53 [169088/225000 (75%)] Loss: 14352.894531\n",
      "Train Epoch: 53 [170496/225000 (76%)] Loss: 14992.409180\n",
      "Train Epoch: 53 [171904/225000 (76%)] Loss: 15015.690430\n",
      "Train Epoch: 53 [173312/225000 (77%)] Loss: 15321.502930\n",
      "Train Epoch: 53 [174720/225000 (78%)] Loss: 14976.784180\n",
      "Train Epoch: 53 [176128/225000 (78%)] Loss: 15616.946289\n",
      "Train Epoch: 53 [177536/225000 (79%)] Loss: 14810.975586\n",
      "Train Epoch: 53 [178944/225000 (80%)] Loss: 15025.135742\n",
      "Train Epoch: 53 [180352/225000 (80%)] Loss: 15398.212891\n",
      "Train Epoch: 53 [181760/225000 (81%)] Loss: 14619.919922\n",
      "Train Epoch: 53 [183168/225000 (81%)] Loss: 14903.549805\n",
      "Train Epoch: 53 [184576/225000 (82%)] Loss: 15259.616211\n",
      "Train Epoch: 53 [185984/225000 (83%)] Loss: 14777.614258\n",
      "Train Epoch: 53 [187392/225000 (83%)] Loss: 14963.112305\n",
      "Train Epoch: 53 [188800/225000 (84%)] Loss: 15339.186523\n",
      "Train Epoch: 53 [190208/225000 (85%)] Loss: 15829.187500\n",
      "Train Epoch: 53 [191616/225000 (85%)] Loss: 14844.276367\n",
      "Train Epoch: 53 [193024/225000 (86%)] Loss: 15081.192383\n",
      "Train Epoch: 53 [194432/225000 (86%)] Loss: 15165.458008\n",
      "Train Epoch: 53 [195840/225000 (87%)] Loss: 15029.081055\n",
      "Train Epoch: 53 [197248/225000 (88%)] Loss: 14985.193359\n",
      "Train Epoch: 53 [198656/225000 (88%)] Loss: 14879.464844\n",
      "Train Epoch: 53 [200064/225000 (89%)] Loss: 15168.903320\n",
      "Train Epoch: 53 [201472/225000 (90%)] Loss: 15021.001953\n",
      "Train Epoch: 53 [202880/225000 (90%)] Loss: 14851.165039\n",
      "Train Epoch: 53 [204288/225000 (91%)] Loss: 14995.875977\n",
      "Train Epoch: 53 [205696/225000 (91%)] Loss: 14817.328125\n",
      "Train Epoch: 53 [207104/225000 (92%)] Loss: 14911.294922\n",
      "Train Epoch: 53 [208512/225000 (93%)] Loss: 14963.408203\n",
      "Train Epoch: 53 [209920/225000 (93%)] Loss: 15074.729492\n",
      "Train Epoch: 53 [211328/225000 (94%)] Loss: 15005.124023\n",
      "Train Epoch: 53 [212736/225000 (95%)] Loss: 15079.510742\n",
      "Train Epoch: 53 [214144/225000 (95%)] Loss: 14906.083008\n",
      "Train Epoch: 53 [215552/225000 (96%)] Loss: 14536.744141\n",
      "Train Epoch: 53 [216960/225000 (96%)] Loss: 14647.476562\n",
      "Train Epoch: 53 [218368/225000 (97%)] Loss: 15203.085938\n",
      "Train Epoch: 53 [219776/225000 (98%)] Loss: 15198.434570\n",
      "Train Epoch: 53 [221184/225000 (98%)] Loss: 15094.593750\n",
      "Train Epoch: 53 [222592/225000 (99%)] Loss: 15675.375000\n",
      "Train Epoch: 53 [224000/225000 (100%)] Loss: 15063.446289\n",
      "    epoch          : 53\n",
      "    loss           : 15079.331049688033\n",
      "    val_loss       : 15059.504703543927\n",
      "Train Epoch: 54 [128/225000 (0%)] Loss: 15084.451172\n",
      "Train Epoch: 54 [1536/225000 (1%)] Loss: 14851.117188\n",
      "Train Epoch: 54 [2944/225000 (1%)] Loss: 14977.230469\n",
      "Train Epoch: 54 [4352/225000 (2%)] Loss: 14947.199219\n",
      "Train Epoch: 54 [5760/225000 (3%)] Loss: 15174.352539\n",
      "Train Epoch: 54 [7168/225000 (3%)] Loss: 15315.333008\n",
      "Train Epoch: 54 [8576/225000 (4%)] Loss: 14735.923828\n",
      "Train Epoch: 54 [9984/225000 (4%)] Loss: 15073.554688\n",
      "Train Epoch: 54 [11392/225000 (5%)] Loss: 15488.530273\n",
      "Train Epoch: 54 [12800/225000 (6%)] Loss: 15033.273438\n",
      "Train Epoch: 54 [14208/225000 (6%)] Loss: 14963.007812\n",
      "Train Epoch: 54 [15616/225000 (7%)] Loss: 15179.211914\n",
      "Train Epoch: 54 [17024/225000 (8%)] Loss: 15056.599609\n",
      "Train Epoch: 54 [18432/225000 (8%)] Loss: 15051.235352\n",
      "Train Epoch: 54 [19840/225000 (9%)] Loss: 15449.943359\n",
      "Train Epoch: 54 [21248/225000 (9%)] Loss: 14952.794922\n",
      "Train Epoch: 54 [22656/225000 (10%)] Loss: 14917.308594\n",
      "Train Epoch: 54 [24064/225000 (11%)] Loss: 15243.850586\n",
      "Train Epoch: 54 [25472/225000 (11%)] Loss: 15369.544922\n",
      "Train Epoch: 54 [26880/225000 (12%)] Loss: 15034.868164\n",
      "Train Epoch: 54 [28288/225000 (13%)] Loss: 15089.789062\n",
      "Train Epoch: 54 [29696/225000 (13%)] Loss: 14876.600586\n",
      "Train Epoch: 54 [31104/225000 (14%)] Loss: 14872.059570\n",
      "Train Epoch: 54 [32512/225000 (14%)] Loss: 15519.558594\n",
      "Train Epoch: 54 [33920/225000 (15%)] Loss: 15237.837891\n",
      "Train Epoch: 54 [35328/225000 (16%)] Loss: 15004.972656\n",
      "Train Epoch: 54 [36736/225000 (16%)] Loss: 14934.414062\n",
      "Train Epoch: 54 [38144/225000 (17%)] Loss: 15356.097656\n",
      "Train Epoch: 54 [39552/225000 (18%)] Loss: 15010.044922\n",
      "Train Epoch: 54 [40960/225000 (18%)] Loss: 15090.315430\n",
      "Train Epoch: 54 [42368/225000 (19%)] Loss: 15115.805664\n",
      "Train Epoch: 54 [43776/225000 (19%)] Loss: 15372.034180\n",
      "Train Epoch: 54 [45184/225000 (20%)] Loss: 15061.530273\n",
      "Train Epoch: 54 [46592/225000 (21%)] Loss: 15012.451172\n",
      "Train Epoch: 54 [48000/225000 (21%)] Loss: 15237.699219\n",
      "Train Epoch: 54 [49408/225000 (22%)] Loss: 14953.149414\n",
      "Train Epoch: 54 [50816/225000 (23%)] Loss: 15083.699219\n",
      "Train Epoch: 54 [52224/225000 (23%)] Loss: 14992.078125\n",
      "Train Epoch: 54 [53632/225000 (24%)] Loss: 15196.931641\n",
      "Train Epoch: 54 [55040/225000 (24%)] Loss: 15097.407227\n",
      "Train Epoch: 54 [56448/225000 (25%)] Loss: 14860.479492\n",
      "Train Epoch: 54 [57856/225000 (26%)] Loss: 14862.930664\n",
      "Train Epoch: 54 [59264/225000 (26%)] Loss: 15336.646484\n",
      "Train Epoch: 54 [60672/225000 (27%)] Loss: 14912.941406\n",
      "Train Epoch: 54 [62080/225000 (28%)] Loss: 15171.194336\n",
      "Train Epoch: 54 [63488/225000 (28%)] Loss: 15091.176758\n",
      "Train Epoch: 54 [64896/225000 (29%)] Loss: 15127.869141\n",
      "Train Epoch: 54 [66304/225000 (29%)] Loss: 15627.985352\n",
      "Train Epoch: 54 [67712/225000 (30%)] Loss: 15584.297852\n",
      "Train Epoch: 54 [69120/225000 (31%)] Loss: 15101.654297\n",
      "Train Epoch: 54 [70528/225000 (31%)] Loss: 15065.813477\n",
      "Train Epoch: 54 [71936/225000 (32%)] Loss: 14895.048828\n",
      "Train Epoch: 54 [73344/225000 (33%)] Loss: 15021.543945\n",
      "Train Epoch: 54 [74752/225000 (33%)] Loss: 15535.464844\n",
      "Train Epoch: 54 [76160/225000 (34%)] Loss: 15109.696289\n",
      "Train Epoch: 54 [77568/225000 (34%)] Loss: 14633.403320\n",
      "Train Epoch: 54 [78976/225000 (35%)] Loss: 15364.803711\n",
      "Train Epoch: 54 [80384/225000 (36%)] Loss: 14845.285156\n",
      "Train Epoch: 54 [81792/225000 (36%)] Loss: 15295.317383\n",
      "Train Epoch: 54 [83200/225000 (37%)] Loss: 15105.680664\n",
      "Train Epoch: 54 [84608/225000 (38%)] Loss: 15648.598633\n",
      "Train Epoch: 54 [86016/225000 (38%)] Loss: 15377.107422\n",
      "Train Epoch: 54 [87424/225000 (39%)] Loss: 15410.004883\n",
      "Train Epoch: 54 [88832/225000 (39%)] Loss: 15265.893555\n",
      "Train Epoch: 54 [90240/225000 (40%)] Loss: 15042.585938\n",
      "Train Epoch: 54 [91648/225000 (41%)] Loss: 14819.876953\n",
      "Train Epoch: 54 [93056/225000 (41%)] Loss: 15012.961914\n",
      "Train Epoch: 54 [94464/225000 (42%)] Loss: 14724.514648\n",
      "Train Epoch: 54 [95872/225000 (43%)] Loss: 15340.045898\n",
      "Train Epoch: 54 [97280/225000 (43%)] Loss: 14976.444336\n",
      "Train Epoch: 54 [98688/225000 (44%)] Loss: 15496.974609\n",
      "Train Epoch: 54 [100096/225000 (44%)] Loss: 15222.988281\n",
      "Train Epoch: 54 [101504/225000 (45%)] Loss: 14579.112305\n",
      "Train Epoch: 54 [102912/225000 (46%)] Loss: 14803.263672\n",
      "Train Epoch: 54 [104320/225000 (46%)] Loss: 14983.380859\n",
      "Train Epoch: 54 [105728/225000 (47%)] Loss: 15447.298828\n",
      "Train Epoch: 54 [107136/225000 (48%)] Loss: 15043.816406\n",
      "Train Epoch: 54 [108544/225000 (48%)] Loss: 14900.696289\n",
      "Train Epoch: 54 [109952/225000 (49%)] Loss: 15643.835938\n",
      "Train Epoch: 54 [111360/225000 (49%)] Loss: 14795.692383\n",
      "Train Epoch: 54 [112768/225000 (50%)] Loss: 14977.044922\n",
      "Train Epoch: 54 [114176/225000 (51%)] Loss: 14869.304688\n",
      "Train Epoch: 54 [115584/225000 (51%)] Loss: 14746.022461\n",
      "Train Epoch: 54 [116992/225000 (52%)] Loss: 14754.668945\n",
      "Train Epoch: 54 [118400/225000 (53%)] Loss: 14495.170898\n",
      "Train Epoch: 54 [119808/225000 (53%)] Loss: 14825.109375\n",
      "Train Epoch: 54 [121216/225000 (54%)] Loss: 15239.470703\n",
      "Train Epoch: 54 [122624/225000 (54%)] Loss: 14998.522461\n",
      "Train Epoch: 54 [124032/225000 (55%)] Loss: 15105.949219\n",
      "Train Epoch: 54 [125440/225000 (56%)] Loss: 15606.853516\n",
      "Train Epoch: 54 [126848/225000 (56%)] Loss: 14727.767578\n",
      "Train Epoch: 54 [128256/225000 (57%)] Loss: 14781.048828\n",
      "Train Epoch: 54 [129664/225000 (58%)] Loss: 15079.649414\n",
      "Train Epoch: 54 [131072/225000 (58%)] Loss: 14900.419922\n",
      "Train Epoch: 54 [132480/225000 (59%)] Loss: 14904.664062\n",
      "Train Epoch: 54 [133888/225000 (60%)] Loss: 15365.209961\n",
      "Train Epoch: 54 [135296/225000 (60%)] Loss: 14795.878906\n",
      "Train Epoch: 54 [136704/225000 (61%)] Loss: 14868.546875\n",
      "Train Epoch: 54 [138112/225000 (61%)] Loss: 15252.442383\n",
      "Train Epoch: 54 [139520/225000 (62%)] Loss: 15090.479492\n",
      "Train Epoch: 54 [140928/225000 (63%)] Loss: 14705.256836\n",
      "Train Epoch: 54 [142336/225000 (63%)] Loss: 15452.390625\n",
      "Train Epoch: 54 [143744/225000 (64%)] Loss: 15043.347656\n",
      "Train Epoch: 54 [145152/225000 (65%)] Loss: 15201.622070\n",
      "Train Epoch: 54 [146560/225000 (65%)] Loss: 14653.704102\n",
      "Train Epoch: 54 [147968/225000 (66%)] Loss: 14923.760742\n",
      "Train Epoch: 54 [149376/225000 (66%)] Loss: 15066.135742\n",
      "Train Epoch: 54 [150784/225000 (67%)] Loss: 15508.293945\n",
      "Train Epoch: 54 [152192/225000 (68%)] Loss: 15328.337891\n",
      "Train Epoch: 54 [153600/225000 (68%)] Loss: 14981.112305\n",
      "Train Epoch: 54 [155008/225000 (69%)] Loss: 15360.628906\n",
      "Train Epoch: 54 [156416/225000 (70%)] Loss: 15262.206055\n",
      "Train Epoch: 54 [157824/225000 (70%)] Loss: 15594.858398\n",
      "Train Epoch: 54 [159232/225000 (71%)] Loss: 15236.259766\n",
      "Train Epoch: 54 [160640/225000 (71%)] Loss: 14924.329102\n",
      "Train Epoch: 54 [162048/225000 (72%)] Loss: 15146.931641\n",
      "Train Epoch: 54 [163456/225000 (73%)] Loss: 15149.760742\n",
      "Train Epoch: 54 [164864/225000 (73%)] Loss: 15045.866211\n",
      "Train Epoch: 54 [166272/225000 (74%)] Loss: 14758.109375\n",
      "Train Epoch: 54 [167680/225000 (75%)] Loss: 15173.516602\n",
      "Train Epoch: 54 [169088/225000 (75%)] Loss: 14901.330078\n",
      "Train Epoch: 54 [170496/225000 (76%)] Loss: 15225.720703\n",
      "Train Epoch: 54 [171904/225000 (76%)] Loss: 15203.359375\n",
      "Train Epoch: 54 [173312/225000 (77%)] Loss: 15493.140625\n",
      "Train Epoch: 54 [174720/225000 (78%)] Loss: 14631.300781\n",
      "Train Epoch: 54 [176128/225000 (78%)] Loss: 15336.249023\n",
      "Train Epoch: 54 [177536/225000 (79%)] Loss: 15176.089844\n",
      "Train Epoch: 54 [178944/225000 (80%)] Loss: 15108.916016\n",
      "Train Epoch: 54 [180352/225000 (80%)] Loss: 14815.699219\n",
      "Train Epoch: 54 [181760/225000 (81%)] Loss: 14974.131836\n",
      "Train Epoch: 54 [183168/225000 (81%)] Loss: 14953.137695\n",
      "Train Epoch: 54 [184576/225000 (82%)] Loss: 15535.390625\n",
      "Train Epoch: 54 [185984/225000 (83%)] Loss: 15024.143555\n",
      "Train Epoch: 54 [187392/225000 (83%)] Loss: 15263.028320\n",
      "Train Epoch: 54 [188800/225000 (84%)] Loss: 14788.602539\n",
      "Train Epoch: 54 [190208/225000 (85%)] Loss: 15124.665039\n",
      "Train Epoch: 54 [191616/225000 (85%)] Loss: 15130.506836\n",
      "Train Epoch: 54 [193024/225000 (86%)] Loss: 14978.858398\n",
      "Train Epoch: 54 [194432/225000 (86%)] Loss: 15393.508789\n",
      "Train Epoch: 54 [195840/225000 (87%)] Loss: 14979.877930\n",
      "Train Epoch: 54 [197248/225000 (88%)] Loss: 15142.012695\n",
      "Train Epoch: 54 [198656/225000 (88%)] Loss: 14745.118164\n",
      "Train Epoch: 54 [200064/225000 (89%)] Loss: 15408.610352\n",
      "Train Epoch: 54 [201472/225000 (90%)] Loss: 14651.966797\n",
      "Train Epoch: 54 [202880/225000 (90%)] Loss: 14944.244141\n",
      "Train Epoch: 54 [204288/225000 (91%)] Loss: 14868.927734\n",
      "Train Epoch: 54 [205696/225000 (91%)] Loss: 15135.283203\n",
      "Train Epoch: 54 [207104/225000 (92%)] Loss: 15166.998047\n",
      "Train Epoch: 54 [208512/225000 (93%)] Loss: 15166.620117\n",
      "Train Epoch: 54 [209920/225000 (93%)] Loss: 15257.139648\n",
      "Train Epoch: 54 [211328/225000 (94%)] Loss: 15259.213867\n",
      "Train Epoch: 54 [212736/225000 (95%)] Loss: 15325.162109\n",
      "Train Epoch: 54 [214144/225000 (95%)] Loss: 14837.728516\n",
      "Train Epoch: 54 [215552/225000 (96%)] Loss: 15432.099609\n",
      "Train Epoch: 54 [216960/225000 (96%)] Loss: 15149.218750\n",
      "Train Epoch: 54 [218368/225000 (97%)] Loss: 14971.032227\n",
      "Train Epoch: 54 [219776/225000 (98%)] Loss: 15322.839844\n",
      "Train Epoch: 54 [221184/225000 (98%)] Loss: 15019.934570\n",
      "Train Epoch: 54 [222592/225000 (99%)] Loss: 14916.411133\n",
      "Train Epoch: 54 [224000/225000 (100%)] Loss: 14907.926758\n",
      "    epoch          : 54\n",
      "    loss           : 15076.898611370343\n",
      "    val_loss       : 15057.615332669597\n",
      "Train Epoch: 55 [128/225000 (0%)] Loss: 15353.978516\n",
      "Train Epoch: 55 [1536/225000 (1%)] Loss: 15195.154297\n",
      "Train Epoch: 55 [2944/225000 (1%)] Loss: 15139.777344\n",
      "Train Epoch: 55 [4352/225000 (2%)] Loss: 15361.171875\n",
      "Train Epoch: 55 [5760/225000 (3%)] Loss: 14918.131836\n",
      "Train Epoch: 55 [7168/225000 (3%)] Loss: 15244.133789\n",
      "Train Epoch: 55 [8576/225000 (4%)] Loss: 15427.368164\n",
      "Train Epoch: 55 [9984/225000 (4%)] Loss: 14850.802734\n",
      "Train Epoch: 55 [11392/225000 (5%)] Loss: 15368.445312\n",
      "Train Epoch: 55 [12800/225000 (6%)] Loss: 14825.614258\n",
      "Train Epoch: 55 [14208/225000 (6%)] Loss: 15129.862305\n",
      "Train Epoch: 55 [15616/225000 (7%)] Loss: 15170.990234\n",
      "Train Epoch: 55 [17024/225000 (8%)] Loss: 15035.330078\n",
      "Train Epoch: 55 [18432/225000 (8%)] Loss: 15207.812500\n",
      "Train Epoch: 55 [19840/225000 (9%)] Loss: 15042.894531\n",
      "Train Epoch: 55 [21248/225000 (9%)] Loss: 14709.226562\n",
      "Train Epoch: 55 [22656/225000 (10%)] Loss: 15507.437500\n",
      "Train Epoch: 55 [24064/225000 (11%)] Loss: 15154.865234\n",
      "Train Epoch: 55 [25472/225000 (11%)] Loss: 14938.091797\n",
      "Train Epoch: 55 [26880/225000 (12%)] Loss: 15018.488281\n",
      "Train Epoch: 55 [28288/225000 (13%)] Loss: 15159.339844\n",
      "Train Epoch: 55 [29696/225000 (13%)] Loss: 15132.289062\n",
      "Train Epoch: 55 [31104/225000 (14%)] Loss: 14744.668945\n",
      "Train Epoch: 55 [32512/225000 (14%)] Loss: 14880.180664\n",
      "Train Epoch: 55 [33920/225000 (15%)] Loss: 15227.496094\n",
      "Train Epoch: 55 [35328/225000 (16%)] Loss: 15249.376953\n",
      "Train Epoch: 55 [36736/225000 (16%)] Loss: 14732.745117\n",
      "Train Epoch: 55 [38144/225000 (17%)] Loss: 14993.601562\n",
      "Train Epoch: 55 [39552/225000 (18%)] Loss: 14815.331055\n",
      "Train Epoch: 55 [40960/225000 (18%)] Loss: 14965.117188\n",
      "Train Epoch: 55 [42368/225000 (19%)] Loss: 15280.211914\n",
      "Train Epoch: 55 [43776/225000 (19%)] Loss: 15151.366211\n",
      "Train Epoch: 55 [45184/225000 (20%)] Loss: 15560.315430\n",
      "Train Epoch: 55 [46592/225000 (21%)] Loss: 14957.199219\n",
      "Train Epoch: 55 [48000/225000 (21%)] Loss: 15383.418945\n",
      "Train Epoch: 55 [49408/225000 (22%)] Loss: 14629.830078\n",
      "Train Epoch: 55 [50816/225000 (23%)] Loss: 15233.169922\n",
      "Train Epoch: 55 [52224/225000 (23%)] Loss: 14971.956055\n",
      "Train Epoch: 55 [53632/225000 (24%)] Loss: 15160.854492\n",
      "Train Epoch: 55 [55040/225000 (24%)] Loss: 14593.444336\n",
      "Train Epoch: 55 [56448/225000 (25%)] Loss: 15190.249023\n",
      "Train Epoch: 55 [57856/225000 (26%)] Loss: 14792.291992\n",
      "Train Epoch: 55 [59264/225000 (26%)] Loss: 14921.009766\n",
      "Train Epoch: 55 [60672/225000 (27%)] Loss: 14958.490234\n",
      "Train Epoch: 55 [62080/225000 (28%)] Loss: 15458.604492\n",
      "Train Epoch: 55 [63488/225000 (28%)] Loss: 14500.057617\n",
      "Train Epoch: 55 [64896/225000 (29%)] Loss: 14828.227539\n",
      "Train Epoch: 55 [66304/225000 (29%)] Loss: 15108.635742\n",
      "Train Epoch: 55 [67712/225000 (30%)] Loss: 14643.370117\n",
      "Train Epoch: 55 [69120/225000 (31%)] Loss: 15561.283203\n",
      "Train Epoch: 55 [70528/225000 (31%)] Loss: 15254.822266\n",
      "Train Epoch: 55 [71936/225000 (32%)] Loss: 15294.881836\n",
      "Train Epoch: 55 [73344/225000 (33%)] Loss: 14748.653320\n",
      "Train Epoch: 55 [74752/225000 (33%)] Loss: 15211.623047\n",
      "Train Epoch: 55 [76160/225000 (34%)] Loss: 14936.759766\n",
      "Train Epoch: 55 [77568/225000 (34%)] Loss: 15490.314453\n",
      "Train Epoch: 55 [78976/225000 (35%)] Loss: 14850.943359\n",
      "Train Epoch: 55 [80384/225000 (36%)] Loss: 15296.070312\n",
      "Train Epoch: 55 [81792/225000 (36%)] Loss: 15029.467773\n",
      "Train Epoch: 55 [83200/225000 (37%)] Loss: 15176.799805\n",
      "Train Epoch: 55 [84608/225000 (38%)] Loss: 14636.034180\n",
      "Train Epoch: 55 [86016/225000 (38%)] Loss: 15585.458984\n",
      "Train Epoch: 55 [87424/225000 (39%)] Loss: 14790.454102\n",
      "Train Epoch: 55 [88832/225000 (39%)] Loss: 15218.617188\n",
      "Train Epoch: 55 [90240/225000 (40%)] Loss: 14705.370117\n",
      "Train Epoch: 55 [91648/225000 (41%)] Loss: 15022.241211\n",
      "Train Epoch: 55 [93056/225000 (41%)] Loss: 15178.140625\n",
      "Train Epoch: 55 [94464/225000 (42%)] Loss: 14703.735352\n",
      "Train Epoch: 55 [95872/225000 (43%)] Loss: 15249.847656\n",
      "Train Epoch: 55 [97280/225000 (43%)] Loss: 15277.075195\n",
      "Train Epoch: 55 [98688/225000 (44%)] Loss: 14883.551758\n",
      "Train Epoch: 55 [100096/225000 (44%)] Loss: 15123.755859\n",
      "Train Epoch: 55 [101504/225000 (45%)] Loss: 14734.447266\n",
      "Train Epoch: 55 [102912/225000 (46%)] Loss: 15207.859375\n",
      "Train Epoch: 55 [104320/225000 (46%)] Loss: 14824.969727\n",
      "Train Epoch: 55 [105728/225000 (47%)] Loss: 15226.045898\n",
      "Train Epoch: 55 [107136/225000 (48%)] Loss: 15065.640625\n",
      "Train Epoch: 55 [108544/225000 (48%)] Loss: 15198.905273\n",
      "Train Epoch: 55 [109952/225000 (49%)] Loss: 15440.332031\n",
      "Train Epoch: 55 [111360/225000 (49%)] Loss: 14986.140625\n",
      "Train Epoch: 55 [112768/225000 (50%)] Loss: 15461.959961\n",
      "Train Epoch: 55 [114176/225000 (51%)] Loss: 14953.583008\n",
      "Train Epoch: 55 [115584/225000 (51%)] Loss: 14782.580078\n",
      "Train Epoch: 55 [116992/225000 (52%)] Loss: 15170.369141\n",
      "Train Epoch: 55 [118400/225000 (53%)] Loss: 15059.127930\n",
      "Train Epoch: 55 [119808/225000 (53%)] Loss: 14946.063477\n",
      "Train Epoch: 55 [121216/225000 (54%)] Loss: 14624.242188\n",
      "Train Epoch: 55 [122624/225000 (54%)] Loss: 15307.717773\n",
      "Train Epoch: 55 [124032/225000 (55%)] Loss: 14861.857422\n",
      "Train Epoch: 55 [125440/225000 (56%)] Loss: 15351.065430\n",
      "Train Epoch: 55 [126848/225000 (56%)] Loss: 14810.268555\n",
      "Train Epoch: 55 [128256/225000 (57%)] Loss: 15131.156250\n",
      "Train Epoch: 55 [129664/225000 (58%)] Loss: 15286.872070\n",
      "Train Epoch: 55 [131072/225000 (58%)] Loss: 15100.336914\n",
      "Train Epoch: 55 [132480/225000 (59%)] Loss: 14642.244141\n",
      "Train Epoch: 55 [133888/225000 (60%)] Loss: 14939.096680\n",
      "Train Epoch: 55 [135296/225000 (60%)] Loss: 15088.985352\n",
      "Train Epoch: 55 [136704/225000 (61%)] Loss: 14908.109375\n",
      "Train Epoch: 55 [138112/225000 (61%)] Loss: 15368.276367\n",
      "Train Epoch: 55 [139520/225000 (62%)] Loss: 15035.708008\n",
      "Train Epoch: 55 [140928/225000 (63%)] Loss: 15026.838867\n",
      "Train Epoch: 55 [142336/225000 (63%)] Loss: 15196.188477\n",
      "Train Epoch: 55 [143744/225000 (64%)] Loss: 15176.452148\n",
      "Train Epoch: 55 [145152/225000 (65%)] Loss: 14786.336914\n",
      "Train Epoch: 55 [146560/225000 (65%)] Loss: 15330.711914\n",
      "Train Epoch: 55 [147968/225000 (66%)] Loss: 14844.893555\n",
      "Train Epoch: 55 [149376/225000 (66%)] Loss: 15325.958008\n",
      "Train Epoch: 55 [150784/225000 (67%)] Loss: 15470.853516\n",
      "Train Epoch: 55 [152192/225000 (68%)] Loss: 14890.076172\n",
      "Train Epoch: 55 [153600/225000 (68%)] Loss: 15088.346680\n",
      "Train Epoch: 55 [155008/225000 (69%)] Loss: 15342.654297\n",
      "Train Epoch: 55 [156416/225000 (70%)] Loss: 15222.591797\n",
      "Train Epoch: 55 [157824/225000 (70%)] Loss: 15066.033203\n",
      "Train Epoch: 55 [159232/225000 (71%)] Loss: 14764.637695\n",
      "Train Epoch: 55 [160640/225000 (71%)] Loss: 14991.694336\n",
      "Train Epoch: 55 [162048/225000 (72%)] Loss: 14767.201172\n",
      "Train Epoch: 55 [163456/225000 (73%)] Loss: 15019.022461\n",
      "Train Epoch: 55 [164864/225000 (73%)] Loss: 15487.173828\n",
      "Train Epoch: 55 [166272/225000 (74%)] Loss: 14868.257812\n",
      "Train Epoch: 55 [167680/225000 (75%)] Loss: 15041.904297\n",
      "Train Epoch: 55 [169088/225000 (75%)] Loss: 15537.204102\n",
      "Train Epoch: 55 [170496/225000 (76%)] Loss: 15052.016602\n",
      "Train Epoch: 55 [171904/225000 (76%)] Loss: 15453.342773\n",
      "Train Epoch: 55 [173312/225000 (77%)] Loss: 14840.843750\n",
      "Train Epoch: 55 [174720/225000 (78%)] Loss: 15181.042969\n",
      "Train Epoch: 55 [176128/225000 (78%)] Loss: 16175.398438\n",
      "Train Epoch: 55 [177536/225000 (79%)] Loss: 15232.993164\n",
      "Train Epoch: 55 [178944/225000 (80%)] Loss: 15253.400391\n",
      "Train Epoch: 55 [180352/225000 (80%)] Loss: 15108.252930\n",
      "Train Epoch: 55 [181760/225000 (81%)] Loss: 14739.675781\n",
      "Train Epoch: 55 [183168/225000 (81%)] Loss: 15513.258789\n",
      "Train Epoch: 55 [184576/225000 (82%)] Loss: 15087.481445\n",
      "Train Epoch: 55 [185984/225000 (83%)] Loss: 14998.147461\n",
      "Train Epoch: 55 [187392/225000 (83%)] Loss: 15049.589844\n",
      "Train Epoch: 55 [188800/225000 (84%)] Loss: 15455.989258\n",
      "Train Epoch: 55 [190208/225000 (85%)] Loss: 14658.431641\n",
      "Train Epoch: 55 [191616/225000 (85%)] Loss: 14755.735352\n",
      "Train Epoch: 55 [193024/225000 (86%)] Loss: 15002.545898\n",
      "Train Epoch: 55 [194432/225000 (86%)] Loss: 15247.861328\n",
      "Train Epoch: 55 [195840/225000 (87%)] Loss: 15056.390625\n",
      "Train Epoch: 55 [197248/225000 (88%)] Loss: 15359.584961\n",
      "Train Epoch: 55 [198656/225000 (88%)] Loss: 15139.336914\n",
      "Train Epoch: 55 [200064/225000 (89%)] Loss: 14929.785156\n",
      "Train Epoch: 55 [201472/225000 (90%)] Loss: 15385.121094\n",
      "Train Epoch: 55 [202880/225000 (90%)] Loss: 15297.130859\n",
      "Train Epoch: 55 [204288/225000 (91%)] Loss: 14992.583984\n",
      "Train Epoch: 55 [205696/225000 (91%)] Loss: 15466.415039\n",
      "Train Epoch: 55 [207104/225000 (92%)] Loss: 14524.301758\n",
      "Train Epoch: 55 [208512/225000 (93%)] Loss: 15366.091797\n",
      "Train Epoch: 55 [209920/225000 (93%)] Loss: 15138.101562\n",
      "Train Epoch: 55 [211328/225000 (94%)] Loss: 15032.856445\n",
      "Train Epoch: 55 [212736/225000 (95%)] Loss: 15941.870117\n",
      "Train Epoch: 55 [214144/225000 (95%)] Loss: 14631.578125\n",
      "Train Epoch: 55 [215552/225000 (96%)] Loss: 14585.142578\n",
      "Train Epoch: 55 [216960/225000 (96%)] Loss: 14653.143555\n",
      "Train Epoch: 55 [218368/225000 (97%)] Loss: 15012.300781\n",
      "Train Epoch: 55 [219776/225000 (98%)] Loss: 15387.518555\n",
      "Train Epoch: 55 [221184/225000 (98%)] Loss: 15396.321289\n",
      "Train Epoch: 55 [222592/225000 (99%)] Loss: 15608.333984\n",
      "Train Epoch: 55 [224000/225000 (100%)] Loss: 14852.347656\n",
      "    epoch          : 55\n",
      "    loss           : 15077.015220043195\n",
      "    val_loss       : 15059.823481752404\n",
      "Train Epoch: 56 [128/225000 (0%)] Loss: 15069.573242\n",
      "Train Epoch: 56 [1536/225000 (1%)] Loss: 15005.292969\n",
      "Train Epoch: 56 [2944/225000 (1%)] Loss: 14724.104492\n",
      "Train Epoch: 56 [4352/225000 (2%)] Loss: 15046.430664\n",
      "Train Epoch: 56 [5760/225000 (3%)] Loss: 15332.122070\n",
      "Train Epoch: 56 [7168/225000 (3%)] Loss: 14874.571289\n",
      "Train Epoch: 56 [8576/225000 (4%)] Loss: 14943.387695\n",
      "Train Epoch: 56 [9984/225000 (4%)] Loss: 15401.245117\n",
      "Train Epoch: 56 [11392/225000 (5%)] Loss: 14878.276367\n",
      "Train Epoch: 56 [12800/225000 (6%)] Loss: 14766.454102\n",
      "Train Epoch: 56 [14208/225000 (6%)] Loss: 15212.832031\n",
      "Train Epoch: 56 [15616/225000 (7%)] Loss: 15466.809570\n",
      "Train Epoch: 56 [17024/225000 (8%)] Loss: 15489.965820\n",
      "Train Epoch: 56 [18432/225000 (8%)] Loss: 15038.545898\n",
      "Train Epoch: 56 [19840/225000 (9%)] Loss: 15121.453125\n",
      "Train Epoch: 56 [21248/225000 (9%)] Loss: 15916.131836\n",
      "Train Epoch: 56 [22656/225000 (10%)] Loss: 14724.462891\n",
      "Train Epoch: 56 [24064/225000 (11%)] Loss: 14652.222656\n",
      "Train Epoch: 56 [25472/225000 (11%)] Loss: 15211.903320\n",
      "Train Epoch: 56 [26880/225000 (12%)] Loss: 14805.226562\n",
      "Train Epoch: 56 [28288/225000 (13%)] Loss: 15221.204102\n",
      "Train Epoch: 56 [29696/225000 (13%)] Loss: 15050.676758\n",
      "Train Epoch: 56 [31104/225000 (14%)] Loss: 15124.196289\n",
      "Train Epoch: 56 [32512/225000 (14%)] Loss: 14541.890625\n",
      "Train Epoch: 56 [33920/225000 (15%)] Loss: 15030.566406\n",
      "Train Epoch: 56 [35328/225000 (16%)] Loss: 15208.208008\n",
      "Train Epoch: 56 [36736/225000 (16%)] Loss: 15915.985352\n",
      "Train Epoch: 56 [38144/225000 (17%)] Loss: 15119.756836\n",
      "Train Epoch: 56 [39552/225000 (18%)] Loss: 15278.470703\n",
      "Train Epoch: 56 [40960/225000 (18%)] Loss: 15285.765625\n",
      "Train Epoch: 56 [42368/225000 (19%)] Loss: 14853.324219\n",
      "Train Epoch: 56 [43776/225000 (19%)] Loss: 14865.444336\n",
      "Train Epoch: 56 [45184/225000 (20%)] Loss: 14957.264648\n",
      "Train Epoch: 56 [46592/225000 (21%)] Loss: 15546.412109\n",
      "Train Epoch: 56 [48000/225000 (21%)] Loss: 15085.614258\n",
      "Train Epoch: 56 [49408/225000 (22%)] Loss: 15334.927734\n",
      "Train Epoch: 56 [50816/225000 (23%)] Loss: 14861.662109\n",
      "Train Epoch: 56 [52224/225000 (23%)] Loss: 15121.648438\n",
      "Train Epoch: 56 [53632/225000 (24%)] Loss: 14602.160156\n",
      "Train Epoch: 56 [55040/225000 (24%)] Loss: 15120.462891\n",
      "Train Epoch: 56 [56448/225000 (25%)] Loss: 14852.094727\n",
      "Train Epoch: 56 [57856/225000 (26%)] Loss: 14709.165039\n",
      "Train Epoch: 56 [59264/225000 (26%)] Loss: 15518.408203\n",
      "Train Epoch: 56 [60672/225000 (27%)] Loss: 15207.432617\n",
      "Train Epoch: 56 [62080/225000 (28%)] Loss: 15554.688477\n",
      "Train Epoch: 56 [63488/225000 (28%)] Loss: 15182.498047\n",
      "Train Epoch: 56 [64896/225000 (29%)] Loss: 15042.211914\n",
      "Train Epoch: 56 [66304/225000 (29%)] Loss: 15186.128906\n",
      "Train Epoch: 56 [67712/225000 (30%)] Loss: 14540.809570\n",
      "Train Epoch: 56 [69120/225000 (31%)] Loss: 14274.315430\n",
      "Train Epoch: 56 [70528/225000 (31%)] Loss: 14967.043945\n",
      "Train Epoch: 56 [71936/225000 (32%)] Loss: 15112.747070\n",
      "Train Epoch: 56 [73344/225000 (33%)] Loss: 14871.992188\n",
      "Train Epoch: 56 [74752/225000 (33%)] Loss: 15060.861328\n",
      "Train Epoch: 56 [76160/225000 (34%)] Loss: 15187.014648\n",
      "Train Epoch: 56 [77568/225000 (34%)] Loss: 14922.160156\n",
      "Train Epoch: 56 [78976/225000 (35%)] Loss: 14816.773438\n",
      "Train Epoch: 56 [80384/225000 (36%)] Loss: 14807.125977\n",
      "Train Epoch: 56 [81792/225000 (36%)] Loss: 14225.657227\n",
      "Train Epoch: 56 [83200/225000 (37%)] Loss: 15325.399414\n",
      "Train Epoch: 56 [84608/225000 (38%)] Loss: 15089.137695\n",
      "Train Epoch: 56 [86016/225000 (38%)] Loss: 15804.409180\n",
      "Train Epoch: 56 [87424/225000 (39%)] Loss: 15267.970703\n",
      "Train Epoch: 56 [88832/225000 (39%)] Loss: 14762.268555\n",
      "Train Epoch: 56 [90240/225000 (40%)] Loss: 14916.121094\n",
      "Train Epoch: 56 [91648/225000 (41%)] Loss: 14930.345703\n",
      "Train Epoch: 56 [93056/225000 (41%)] Loss: 15187.480469\n",
      "Train Epoch: 56 [94464/225000 (42%)] Loss: 15024.316406\n",
      "Train Epoch: 56 [95872/225000 (43%)] Loss: 14914.148438\n",
      "Train Epoch: 56 [97280/225000 (43%)] Loss: 14643.636719\n",
      "Train Epoch: 56 [98688/225000 (44%)] Loss: 15228.672852\n",
      "Train Epoch: 56 [100096/225000 (44%)] Loss: 15504.838867\n",
      "Train Epoch: 56 [101504/225000 (45%)] Loss: 15266.599609\n",
      "Train Epoch: 56 [102912/225000 (46%)] Loss: 15195.583984\n",
      "Train Epoch: 56 [104320/225000 (46%)] Loss: 15586.327148\n",
      "Train Epoch: 56 [105728/225000 (47%)] Loss: 14947.278320\n",
      "Train Epoch: 56 [107136/225000 (48%)] Loss: 14918.661133\n",
      "Train Epoch: 56 [108544/225000 (48%)] Loss: 14963.692383\n",
      "Train Epoch: 56 [109952/225000 (49%)] Loss: 14781.586914\n",
      "Train Epoch: 56 [111360/225000 (49%)] Loss: 15013.181641\n",
      "Train Epoch: 56 [112768/225000 (50%)] Loss: 14636.144531\n",
      "Train Epoch: 56 [114176/225000 (51%)] Loss: 14747.878906\n",
      "Train Epoch: 56 [115584/225000 (51%)] Loss: 15125.153320\n",
      "Train Epoch: 56 [116992/225000 (52%)] Loss: 14988.931641\n",
      "Train Epoch: 56 [118400/225000 (53%)] Loss: 15853.136719\n",
      "Train Epoch: 56 [119808/225000 (53%)] Loss: 14977.416016\n",
      "Train Epoch: 56 [121216/225000 (54%)] Loss: 14717.251953\n",
      "Train Epoch: 56 [122624/225000 (54%)] Loss: 14694.774414\n",
      "Train Epoch: 56 [124032/225000 (55%)] Loss: 14694.298828\n",
      "Train Epoch: 56 [125440/225000 (56%)] Loss: 14630.942383\n",
      "Train Epoch: 56 [126848/225000 (56%)] Loss: 14859.657227\n",
      "Train Epoch: 56 [128256/225000 (57%)] Loss: 15439.102539\n",
      "Train Epoch: 56 [129664/225000 (58%)] Loss: 15362.608398\n",
      "Train Epoch: 56 [131072/225000 (58%)] Loss: 15049.533203\n",
      "Train Epoch: 56 [132480/225000 (59%)] Loss: 14725.025391\n",
      "Train Epoch: 56 [133888/225000 (60%)] Loss: 15275.864258\n",
      "Train Epoch: 56 [135296/225000 (60%)] Loss: 14646.465820\n",
      "Train Epoch: 56 [136704/225000 (61%)] Loss: 14908.752930\n",
      "Train Epoch: 56 [138112/225000 (61%)] Loss: 15411.319336\n",
      "Train Epoch: 56 [139520/225000 (62%)] Loss: 15025.295898\n",
      "Train Epoch: 56 [140928/225000 (63%)] Loss: 15314.630859\n",
      "Train Epoch: 56 [142336/225000 (63%)] Loss: 14825.146484\n",
      "Train Epoch: 56 [143744/225000 (64%)] Loss: 14767.143555\n",
      "Train Epoch: 56 [145152/225000 (65%)] Loss: 14976.214844\n",
      "Train Epoch: 56 [146560/225000 (65%)] Loss: 15320.944336\n",
      "Train Epoch: 56 [147968/225000 (66%)] Loss: 14876.518555\n",
      "Train Epoch: 56 [149376/225000 (66%)] Loss: 15175.152344\n",
      "Train Epoch: 56 [150784/225000 (67%)] Loss: 15068.736328\n",
      "Train Epoch: 56 [152192/225000 (68%)] Loss: 15187.691406\n",
      "Train Epoch: 56 [153600/225000 (68%)] Loss: 15542.886719\n",
      "Train Epoch: 56 [155008/225000 (69%)] Loss: 15045.753906\n",
      "Train Epoch: 56 [156416/225000 (70%)] Loss: 14960.788086\n",
      "Train Epoch: 56 [157824/225000 (70%)] Loss: 15038.995117\n",
      "Train Epoch: 56 [159232/225000 (71%)] Loss: 14933.606445\n",
      "Train Epoch: 56 [160640/225000 (71%)] Loss: 14998.554688\n",
      "Train Epoch: 56 [162048/225000 (72%)] Loss: 15370.523438\n",
      "Train Epoch: 56 [163456/225000 (73%)] Loss: 15009.682617\n",
      "Train Epoch: 56 [164864/225000 (73%)] Loss: 15180.666016\n",
      "Train Epoch: 56 [166272/225000 (74%)] Loss: 14871.717773\n",
      "Train Epoch: 56 [167680/225000 (75%)] Loss: 15004.405273\n",
      "Train Epoch: 56 [169088/225000 (75%)] Loss: 14886.976562\n",
      "Train Epoch: 56 [170496/225000 (76%)] Loss: 14819.997070\n",
      "Train Epoch: 56 [171904/225000 (76%)] Loss: 14813.000000\n",
      "Train Epoch: 56 [173312/225000 (77%)] Loss: 15060.741211\n",
      "Train Epoch: 56 [174720/225000 (78%)] Loss: 14954.253906\n",
      "Train Epoch: 56 [176128/225000 (78%)] Loss: 15074.001953\n",
      "Train Epoch: 56 [177536/225000 (79%)] Loss: 15438.807617\n",
      "Train Epoch: 56 [178944/225000 (80%)] Loss: 14849.280273\n",
      "Train Epoch: 56 [180352/225000 (80%)] Loss: 15555.741211\n",
      "Train Epoch: 56 [181760/225000 (81%)] Loss: 15192.335938\n",
      "Train Epoch: 56 [183168/225000 (81%)] Loss: 14872.848633\n",
      "Train Epoch: 56 [184576/225000 (82%)] Loss: 15114.970703\n",
      "Train Epoch: 56 [185984/225000 (83%)] Loss: 15156.017578\n",
      "Train Epoch: 56 [187392/225000 (83%)] Loss: 14987.588867\n",
      "Train Epoch: 56 [188800/225000 (84%)] Loss: 15149.090820\n",
      "Train Epoch: 56 [190208/225000 (85%)] Loss: 15485.233398\n",
      "Train Epoch: 56 [191616/225000 (85%)] Loss: 15110.713867\n",
      "Train Epoch: 56 [193024/225000 (86%)] Loss: 14861.282227\n",
      "Train Epoch: 56 [194432/225000 (86%)] Loss: 15229.091797\n",
      "Train Epoch: 56 [195840/225000 (87%)] Loss: 15093.394531\n",
      "Train Epoch: 56 [197248/225000 (88%)] Loss: 15272.530273\n",
      "Train Epoch: 56 [198656/225000 (88%)] Loss: 15331.133789\n",
      "Train Epoch: 56 [200064/225000 (89%)] Loss: 15062.897461\n",
      "Train Epoch: 56 [201472/225000 (90%)] Loss: 15408.536133\n",
      "Train Epoch: 56 [202880/225000 (90%)] Loss: 15192.623047\n",
      "Train Epoch: 56 [204288/225000 (91%)] Loss: 15102.504883\n",
      "Train Epoch: 56 [205696/225000 (91%)] Loss: 14835.596680\n",
      "Train Epoch: 56 [207104/225000 (92%)] Loss: 15134.028320\n",
      "Train Epoch: 56 [208512/225000 (93%)] Loss: 15125.260742\n",
      "Train Epoch: 56 [209920/225000 (93%)] Loss: 15155.875000\n",
      "Train Epoch: 56 [211328/225000 (94%)] Loss: 14923.719727\n",
      "Train Epoch: 56 [212736/225000 (95%)] Loss: 14938.671875\n",
      "Train Epoch: 56 [214144/225000 (95%)] Loss: 15498.422852\n",
      "Train Epoch: 56 [215552/225000 (96%)] Loss: 15687.769531\n",
      "Train Epoch: 56 [216960/225000 (96%)] Loss: 14532.903320\n",
      "Train Epoch: 56 [218368/225000 (97%)] Loss: 15395.912109\n",
      "Train Epoch: 56 [219776/225000 (98%)] Loss: 15105.841797\n",
      "Train Epoch: 56 [221184/225000 (98%)] Loss: 15336.638672\n",
      "Train Epoch: 56 [222592/225000 (99%)] Loss: 15094.901367\n",
      "Train Epoch: 56 [224000/225000 (100%)] Loss: 14996.406250\n",
      "    epoch          : 56\n",
      "    loss           : 15075.765666106727\n",
      "    val_loss       : 15056.441633373195\n",
      "Train Epoch: 57 [128/225000 (0%)] Loss: 15043.393555\n",
      "Train Epoch: 57 [1536/225000 (1%)] Loss: 14905.594727\n",
      "Train Epoch: 57 [2944/225000 (1%)] Loss: 14915.948242\n",
      "Train Epoch: 57 [4352/225000 (2%)] Loss: 14837.134766\n",
      "Train Epoch: 57 [5760/225000 (3%)] Loss: 15118.602539\n",
      "Train Epoch: 57 [7168/225000 (3%)] Loss: 15331.047852\n",
      "Train Epoch: 57 [8576/225000 (4%)] Loss: 14784.774414\n",
      "Train Epoch: 57 [9984/225000 (4%)] Loss: 14722.878906\n",
      "Train Epoch: 57 [11392/225000 (5%)] Loss: 14797.289062\n",
      "Train Epoch: 57 [12800/225000 (6%)] Loss: 15278.041016\n",
      "Train Epoch: 57 [14208/225000 (6%)] Loss: 14571.739258\n",
      "Train Epoch: 57 [15616/225000 (7%)] Loss: 14874.577148\n",
      "Train Epoch: 57 [17024/225000 (8%)] Loss: 14833.037109\n",
      "Train Epoch: 57 [18432/225000 (8%)] Loss: 15562.034180\n",
      "Train Epoch: 57 [19840/225000 (9%)] Loss: 15036.241211\n",
      "Train Epoch: 57 [21248/225000 (9%)] Loss: 14697.683594\n",
      "Train Epoch: 57 [22656/225000 (10%)] Loss: 15006.572266\n",
      "Train Epoch: 57 [24064/225000 (11%)] Loss: 14449.032227\n",
      "Train Epoch: 57 [25472/225000 (11%)] Loss: 14693.395508\n",
      "Train Epoch: 57 [26880/225000 (12%)] Loss: 14948.929688\n",
      "Train Epoch: 57 [28288/225000 (13%)] Loss: 15169.259766\n",
      "Train Epoch: 57 [29696/225000 (13%)] Loss: 15116.223633\n",
      "Train Epoch: 57 [31104/225000 (14%)] Loss: 14915.013672\n",
      "Train Epoch: 57 [32512/225000 (14%)] Loss: 15303.014648\n",
      "Train Epoch: 57 [33920/225000 (15%)] Loss: 15030.033203\n",
      "Train Epoch: 57 [35328/225000 (16%)] Loss: 14924.780273\n",
      "Train Epoch: 57 [36736/225000 (16%)] Loss: 15449.765625\n",
      "Train Epoch: 57 [38144/225000 (17%)] Loss: 14837.132812\n",
      "Train Epoch: 57 [39552/225000 (18%)] Loss: 15032.013672\n",
      "Train Epoch: 57 [40960/225000 (18%)] Loss: 14804.783203\n",
      "Train Epoch: 57 [42368/225000 (19%)] Loss: 14917.002930\n",
      "Train Epoch: 57 [43776/225000 (19%)] Loss: 14902.515625\n",
      "Train Epoch: 57 [45184/225000 (20%)] Loss: 15135.072266\n",
      "Train Epoch: 57 [46592/225000 (21%)] Loss: 14822.861328\n",
      "Train Epoch: 57 [48000/225000 (21%)] Loss: 15084.211914\n",
      "Train Epoch: 57 [49408/225000 (22%)] Loss: 14836.708984\n",
      "Train Epoch: 57 [50816/225000 (23%)] Loss: 14529.696289\n",
      "Train Epoch: 57 [52224/225000 (23%)] Loss: 15307.896484\n",
      "Train Epoch: 57 [53632/225000 (24%)] Loss: 14817.271484\n",
      "Train Epoch: 57 [55040/225000 (24%)] Loss: 15170.703125\n",
      "Train Epoch: 57 [56448/225000 (25%)] Loss: 15079.417969\n",
      "Train Epoch: 57 [57856/225000 (26%)] Loss: 15168.304688\n",
      "Train Epoch: 57 [59264/225000 (26%)] Loss: 14893.507812\n",
      "Train Epoch: 57 [60672/225000 (27%)] Loss: 15171.236328\n",
      "Train Epoch: 57 [62080/225000 (28%)] Loss: 15100.497070\n",
      "Train Epoch: 57 [63488/225000 (28%)] Loss: 15082.990234\n",
      "Train Epoch: 57 [64896/225000 (29%)] Loss: 15154.372070\n",
      "Train Epoch: 57 [66304/225000 (29%)] Loss: 15470.069336\n",
      "Train Epoch: 57 [67712/225000 (30%)] Loss: 15437.101562\n",
      "Train Epoch: 57 [69120/225000 (31%)] Loss: 14987.177734\n",
      "Train Epoch: 57 [70528/225000 (31%)] Loss: 15083.243164\n",
      "Train Epoch: 57 [71936/225000 (32%)] Loss: 15281.038086\n",
      "Train Epoch: 57 [73344/225000 (33%)] Loss: 15400.923828\n",
      "Train Epoch: 57 [74752/225000 (33%)] Loss: 15105.206055\n",
      "Train Epoch: 57 [76160/225000 (34%)] Loss: 15210.175781\n",
      "Train Epoch: 57 [77568/225000 (34%)] Loss: 15074.993164\n",
      "Train Epoch: 57 [78976/225000 (35%)] Loss: 14798.008789\n",
      "Train Epoch: 57 [80384/225000 (36%)] Loss: 14649.374023\n",
      "Train Epoch: 57 [81792/225000 (36%)] Loss: 15033.007812\n",
      "Train Epoch: 57 [83200/225000 (37%)] Loss: 15512.459961\n",
      "Train Epoch: 57 [84608/225000 (38%)] Loss: 15174.175781\n",
      "Train Epoch: 57 [86016/225000 (38%)] Loss: 14939.059570\n",
      "Train Epoch: 57 [87424/225000 (39%)] Loss: 14599.302734\n",
      "Train Epoch: 57 [88832/225000 (39%)] Loss: 15024.117188\n",
      "Train Epoch: 57 [90240/225000 (40%)] Loss: 15210.132812\n",
      "Train Epoch: 57 [91648/225000 (41%)] Loss: 14694.714844\n",
      "Train Epoch: 57 [93056/225000 (41%)] Loss: 15392.385742\n",
      "Train Epoch: 57 [94464/225000 (42%)] Loss: 14829.756836\n",
      "Train Epoch: 57 [95872/225000 (43%)] Loss: 14787.191406\n",
      "Train Epoch: 57 [97280/225000 (43%)] Loss: 14743.160156\n",
      "Train Epoch: 57 [98688/225000 (44%)] Loss: 15273.958984\n",
      "Train Epoch: 57 [100096/225000 (44%)] Loss: 15327.393555\n",
      "Train Epoch: 57 [101504/225000 (45%)] Loss: 15364.616211\n",
      "Train Epoch: 57 [102912/225000 (46%)] Loss: 15586.157227\n",
      "Train Epoch: 57 [104320/225000 (46%)] Loss: 15514.437500\n",
      "Train Epoch: 57 [105728/225000 (47%)] Loss: 15094.548828\n",
      "Train Epoch: 57 [107136/225000 (48%)] Loss: 15397.406250\n",
      "Train Epoch: 57 [108544/225000 (48%)] Loss: 15005.798828\n",
      "Train Epoch: 57 [109952/225000 (49%)] Loss: 15303.518555\n",
      "Train Epoch: 57 [111360/225000 (49%)] Loss: 15096.147461\n",
      "Train Epoch: 57 [112768/225000 (50%)] Loss: 15627.400391\n",
      "Train Epoch: 57 [114176/225000 (51%)] Loss: 14821.817383\n",
      "Train Epoch: 57 [115584/225000 (51%)] Loss: 15795.588867\n",
      "Train Epoch: 57 [116992/225000 (52%)] Loss: 14939.063477\n",
      "Train Epoch: 57 [118400/225000 (53%)] Loss: 15183.481445\n",
      "Train Epoch: 57 [119808/225000 (53%)] Loss: 15314.041016\n",
      "Train Epoch: 57 [121216/225000 (54%)] Loss: 15100.849609\n",
      "Train Epoch: 57 [122624/225000 (54%)] Loss: 14936.744141\n",
      "Train Epoch: 57 [124032/225000 (55%)] Loss: 15262.542969\n",
      "Train Epoch: 57 [125440/225000 (56%)] Loss: 15234.777344\n",
      "Train Epoch: 57 [126848/225000 (56%)] Loss: 15201.593750\n",
      "Train Epoch: 57 [128256/225000 (57%)] Loss: 15045.785156\n",
      "Train Epoch: 57 [129664/225000 (58%)] Loss: 15254.340820\n",
      "Train Epoch: 57 [131072/225000 (58%)] Loss: 15007.176758\n",
      "Train Epoch: 57 [132480/225000 (59%)] Loss: 14765.732422\n",
      "Train Epoch: 57 [133888/225000 (60%)] Loss: 14771.508789\n",
      "Train Epoch: 57 [135296/225000 (60%)] Loss: 15001.227539\n",
      "Train Epoch: 57 [136704/225000 (61%)] Loss: 14780.691406\n",
      "Train Epoch: 57 [138112/225000 (61%)] Loss: 14600.867188\n",
      "Train Epoch: 57 [139520/225000 (62%)] Loss: 14723.861328\n",
      "Train Epoch: 57 [140928/225000 (63%)] Loss: 14821.268555\n",
      "Train Epoch: 57 [142336/225000 (63%)] Loss: 15186.434570\n",
      "Train Epoch: 57 [143744/225000 (64%)] Loss: 15184.776367\n",
      "Train Epoch: 57 [145152/225000 (65%)] Loss: 15119.419922\n",
      "Train Epoch: 57 [146560/225000 (65%)] Loss: 15016.963867\n",
      "Train Epoch: 57 [147968/225000 (66%)] Loss: 15048.528320\n",
      "Train Epoch: 57 [149376/225000 (66%)] Loss: 15246.515625\n",
      "Train Epoch: 57 [150784/225000 (67%)] Loss: 15001.731445\n",
      "Train Epoch: 57 [152192/225000 (68%)] Loss: 15204.708008\n",
      "Train Epoch: 57 [153600/225000 (68%)] Loss: 15319.375977\n",
      "Train Epoch: 57 [155008/225000 (69%)] Loss: 14831.357422\n",
      "Train Epoch: 57 [156416/225000 (70%)] Loss: 15412.875977\n",
      "Train Epoch: 57 [157824/225000 (70%)] Loss: 15182.665039\n",
      "Train Epoch: 57 [159232/225000 (71%)] Loss: 15113.370117\n",
      "Train Epoch: 57 [160640/225000 (71%)] Loss: 15051.408203\n",
      "Train Epoch: 57 [162048/225000 (72%)] Loss: 15130.625000\n",
      "Train Epoch: 57 [163456/225000 (73%)] Loss: 15253.904297\n",
      "Train Epoch: 57 [164864/225000 (73%)] Loss: 14602.817383\n",
      "Train Epoch: 57 [166272/225000 (74%)] Loss: 14642.730469\n",
      "Train Epoch: 57 [167680/225000 (75%)] Loss: 15490.758789\n",
      "Train Epoch: 57 [169088/225000 (75%)] Loss: 14797.006836\n",
      "Train Epoch: 57 [170496/225000 (76%)] Loss: 14868.421875\n",
      "Train Epoch: 57 [171904/225000 (76%)] Loss: 15314.436523\n",
      "Train Epoch: 57 [173312/225000 (77%)] Loss: 14962.162109\n",
      "Train Epoch: 57 [174720/225000 (78%)] Loss: 15312.219727\n",
      "Train Epoch: 57 [176128/225000 (78%)] Loss: 14810.100586\n",
      "Train Epoch: 57 [177536/225000 (79%)] Loss: 14964.106445\n",
      "Train Epoch: 57 [178944/225000 (80%)] Loss: 15031.338867\n",
      "Train Epoch: 57 [180352/225000 (80%)] Loss: 15178.449219\n",
      "Train Epoch: 57 [181760/225000 (81%)] Loss: 14935.986328\n",
      "Train Epoch: 57 [183168/225000 (81%)] Loss: 15313.672852\n",
      "Train Epoch: 57 [184576/225000 (82%)] Loss: 14971.928711\n",
      "Train Epoch: 57 [185984/225000 (83%)] Loss: 15306.268555\n",
      "Train Epoch: 57 [187392/225000 (83%)] Loss: 15230.570312\n",
      "Train Epoch: 57 [188800/225000 (84%)] Loss: 15051.877930\n",
      "Train Epoch: 57 [190208/225000 (85%)] Loss: 15288.228516\n",
      "Train Epoch: 57 [191616/225000 (85%)] Loss: 14500.696289\n",
      "Train Epoch: 57 [193024/225000 (86%)] Loss: 14881.404297\n",
      "Train Epoch: 57 [194432/225000 (86%)] Loss: 14977.149414\n",
      "Train Epoch: 57 [195840/225000 (87%)] Loss: 15226.163086\n",
      "Train Epoch: 57 [197248/225000 (88%)] Loss: 15323.114258\n",
      "Train Epoch: 57 [198656/225000 (88%)] Loss: 14990.503906\n",
      "Train Epoch: 57 [200064/225000 (89%)] Loss: 15328.704102\n",
      "Train Epoch: 57 [201472/225000 (90%)] Loss: 15131.963867\n",
      "Train Epoch: 57 [202880/225000 (90%)] Loss: 15133.320312\n",
      "Train Epoch: 57 [204288/225000 (91%)] Loss: 15565.522461\n",
      "Train Epoch: 57 [205696/225000 (91%)] Loss: 15204.564453\n",
      "Train Epoch: 57 [207104/225000 (92%)] Loss: 15208.362305\n",
      "Train Epoch: 57 [208512/225000 (93%)] Loss: 15035.041992\n",
      "Train Epoch: 57 [209920/225000 (93%)] Loss: 15350.599609\n",
      "Train Epoch: 57 [211328/225000 (94%)] Loss: 14758.389648\n",
      "Train Epoch: 57 [212736/225000 (95%)] Loss: 15427.811523\n",
      "Train Epoch: 57 [214144/225000 (95%)] Loss: 15621.042969\n",
      "Train Epoch: 57 [215552/225000 (96%)] Loss: 15200.653320\n",
      "Train Epoch: 57 [216960/225000 (96%)] Loss: 15259.611328\n",
      "Train Epoch: 57 [218368/225000 (97%)] Loss: 14985.314453\n",
      "Train Epoch: 57 [219776/225000 (98%)] Loss: 15539.088867\n",
      "Train Epoch: 57 [221184/225000 (98%)] Loss: 15007.400391\n",
      "Train Epoch: 57 [222592/225000 (99%)] Loss: 14931.216797\n",
      "Train Epoch: 57 [224000/225000 (100%)] Loss: 15273.573242\n",
      "    epoch          : 57\n",
      "    loss           : 15076.490140496126\n",
      "    val_loss       : 15060.312859189906\n",
      "Train Epoch: 58 [128/225000 (0%)] Loss: 14695.854492\n",
      "Train Epoch: 58 [1536/225000 (1%)] Loss: 14896.699219\n",
      "Train Epoch: 58 [2944/225000 (1%)] Loss: 14913.856445\n",
      "Train Epoch: 58 [4352/225000 (2%)] Loss: 15036.284180\n",
      "Train Epoch: 58 [5760/225000 (3%)] Loss: 15910.369141\n",
      "Train Epoch: 58 [7168/225000 (3%)] Loss: 15253.314453\n",
      "Train Epoch: 58 [8576/225000 (4%)] Loss: 14795.336914\n",
      "Train Epoch: 58 [9984/225000 (4%)] Loss: 14907.881836\n",
      "Train Epoch: 58 [11392/225000 (5%)] Loss: 14802.372070\n",
      "Train Epoch: 58 [12800/225000 (6%)] Loss: 15279.962891\n",
      "Train Epoch: 58 [14208/225000 (6%)] Loss: 15163.171875\n",
      "Train Epoch: 58 [15616/225000 (7%)] Loss: 15399.773438\n",
      "Train Epoch: 58 [17024/225000 (8%)] Loss: 15075.384766\n",
      "Train Epoch: 58 [18432/225000 (8%)] Loss: 14663.696289\n",
      "Train Epoch: 58 [19840/225000 (9%)] Loss: 14931.930664\n",
      "Train Epoch: 58 [21248/225000 (9%)] Loss: 15056.168945\n",
      "Train Epoch: 58 [22656/225000 (10%)] Loss: 14973.704102\n",
      "Train Epoch: 58 [24064/225000 (11%)] Loss: 15099.280273\n",
      "Train Epoch: 58 [25472/225000 (11%)] Loss: 15117.823242\n",
      "Train Epoch: 58 [26880/225000 (12%)] Loss: 15368.420898\n",
      "Train Epoch: 58 [28288/225000 (13%)] Loss: 15282.855469\n",
      "Train Epoch: 58 [29696/225000 (13%)] Loss: 14901.503906\n",
      "Train Epoch: 58 [31104/225000 (14%)] Loss: 15084.630859\n",
      "Train Epoch: 58 [32512/225000 (14%)] Loss: 15818.883789\n",
      "Train Epoch: 58 [33920/225000 (15%)] Loss: 14879.468750\n",
      "Train Epoch: 58 [35328/225000 (16%)] Loss: 15250.493164\n",
      "Train Epoch: 58 [36736/225000 (16%)] Loss: 15355.963867\n",
      "Train Epoch: 58 [38144/225000 (17%)] Loss: 15018.110352\n",
      "Train Epoch: 58 [39552/225000 (18%)] Loss: 15434.292969\n",
      "Train Epoch: 58 [40960/225000 (18%)] Loss: 15078.748047\n",
      "Train Epoch: 58 [42368/225000 (19%)] Loss: 14813.715820\n",
      "Train Epoch: 58 [43776/225000 (19%)] Loss: 14953.796875\n",
      "Train Epoch: 58 [45184/225000 (20%)] Loss: 15389.212891\n",
      "Train Epoch: 58 [46592/225000 (21%)] Loss: 14889.197266\n",
      "Train Epoch: 58 [48000/225000 (21%)] Loss: 15248.537109\n",
      "Train Epoch: 58 [49408/225000 (22%)] Loss: 15246.081055\n",
      "Train Epoch: 58 [50816/225000 (23%)] Loss: 15003.999023\n",
      "Train Epoch: 58 [52224/225000 (23%)] Loss: 14885.584961\n",
      "Train Epoch: 58 [53632/225000 (24%)] Loss: 15132.598633\n",
      "Train Epoch: 58 [55040/225000 (24%)] Loss: 14889.312500\n",
      "Train Epoch: 58 [56448/225000 (25%)] Loss: 14998.160156\n",
      "Train Epoch: 58 [57856/225000 (26%)] Loss: 15287.916992\n",
      "Train Epoch: 58 [59264/225000 (26%)] Loss: 15347.495117\n",
      "Train Epoch: 58 [60672/225000 (27%)] Loss: 14663.594727\n",
      "Train Epoch: 58 [62080/225000 (28%)] Loss: 15201.084961\n",
      "Train Epoch: 58 [63488/225000 (28%)] Loss: 15617.092773\n",
      "Train Epoch: 58 [64896/225000 (29%)] Loss: 14810.741211\n",
      "Train Epoch: 58 [66304/225000 (29%)] Loss: 15174.033203\n",
      "Train Epoch: 58 [67712/225000 (30%)] Loss: 15376.509766\n",
      "Train Epoch: 58 [69120/225000 (31%)] Loss: 15185.318359\n",
      "Train Epoch: 58 [70528/225000 (31%)] Loss: 14981.414062\n",
      "Train Epoch: 58 [71936/225000 (32%)] Loss: 15088.835938\n",
      "Train Epoch: 58 [73344/225000 (33%)] Loss: 15007.771484\n",
      "Train Epoch: 58 [74752/225000 (33%)] Loss: 14822.810547\n",
      "Train Epoch: 58 [76160/225000 (34%)] Loss: 15217.785156\n",
      "Train Epoch: 58 [77568/225000 (34%)] Loss: 14916.019531\n",
      "Train Epoch: 58 [78976/225000 (35%)] Loss: 14807.669922\n",
      "Train Epoch: 58 [80384/225000 (36%)] Loss: 15053.775391\n",
      "Train Epoch: 58 [81792/225000 (36%)] Loss: 15093.090820\n",
      "Train Epoch: 58 [83200/225000 (37%)] Loss: 15376.950195\n",
      "Train Epoch: 58 [84608/225000 (38%)] Loss: 15428.795898\n",
      "Train Epoch: 58 [86016/225000 (38%)] Loss: 15067.485352\n",
      "Train Epoch: 58 [87424/225000 (39%)] Loss: 15059.271484\n",
      "Train Epoch: 58 [88832/225000 (39%)] Loss: 15497.014648\n",
      "Train Epoch: 58 [90240/225000 (40%)] Loss: 15087.694336\n",
      "Train Epoch: 58 [91648/225000 (41%)] Loss: 15182.502930\n",
      "Train Epoch: 58 [93056/225000 (41%)] Loss: 14909.175781\n",
      "Train Epoch: 58 [94464/225000 (42%)] Loss: 14934.802734\n",
      "Train Epoch: 58 [95872/225000 (43%)] Loss: 14832.458008\n",
      "Train Epoch: 58 [97280/225000 (43%)] Loss: 15047.791992\n",
      "Train Epoch: 58 [98688/225000 (44%)] Loss: 14727.548828\n",
      "Train Epoch: 58 [100096/225000 (44%)] Loss: 15025.064453\n",
      "Train Epoch: 58 [101504/225000 (45%)] Loss: 15031.036133\n",
      "Train Epoch: 58 [102912/225000 (46%)] Loss: 15225.587891\n",
      "Train Epoch: 58 [104320/225000 (46%)] Loss: 15775.875000\n",
      "Train Epoch: 58 [105728/225000 (47%)] Loss: 15289.705078\n",
      "Train Epoch: 58 [107136/225000 (48%)] Loss: 14926.763672\n",
      "Train Epoch: 58 [108544/225000 (48%)] Loss: 15092.264648\n",
      "Train Epoch: 58 [109952/225000 (49%)] Loss: 14922.656250\n",
      "Train Epoch: 58 [111360/225000 (49%)] Loss: 14979.476562\n",
      "Train Epoch: 58 [112768/225000 (50%)] Loss: 15405.677734\n",
      "Train Epoch: 58 [114176/225000 (51%)] Loss: 14689.825195\n",
      "Train Epoch: 58 [115584/225000 (51%)] Loss: 14824.763672\n",
      "Train Epoch: 58 [116992/225000 (52%)] Loss: 15116.845703\n",
      "Train Epoch: 58 [118400/225000 (53%)] Loss: 14956.750977\n",
      "Train Epoch: 58 [119808/225000 (53%)] Loss: 15055.703125\n",
      "Train Epoch: 58 [121216/225000 (54%)] Loss: 14970.483398\n",
      "Train Epoch: 58 [122624/225000 (54%)] Loss: 15521.242188\n",
      "Train Epoch: 58 [124032/225000 (55%)] Loss: 15269.165039\n",
      "Train Epoch: 58 [125440/225000 (56%)] Loss: 15110.254883\n",
      "Train Epoch: 58 [126848/225000 (56%)] Loss: 15275.125000\n",
      "Train Epoch: 58 [128256/225000 (57%)] Loss: 15029.667969\n",
      "Train Epoch: 58 [129664/225000 (58%)] Loss: 15386.603516\n",
      "Train Epoch: 58 [131072/225000 (58%)] Loss: 15131.909180\n",
      "Train Epoch: 58 [132480/225000 (59%)] Loss: 14994.258789\n",
      "Train Epoch: 58 [133888/225000 (60%)] Loss: 15202.191406\n",
      "Train Epoch: 58 [135296/225000 (60%)] Loss: 14895.125000\n",
      "Train Epoch: 58 [136704/225000 (61%)] Loss: 15296.649414\n",
      "Train Epoch: 58 [138112/225000 (61%)] Loss: 15224.918945\n",
      "Train Epoch: 58 [139520/225000 (62%)] Loss: 15321.958008\n",
      "Train Epoch: 58 [140928/225000 (63%)] Loss: 15299.478516\n",
      "Train Epoch: 58 [142336/225000 (63%)] Loss: 15194.448242\n",
      "Train Epoch: 58 [143744/225000 (64%)] Loss: 14814.879883\n",
      "Train Epoch: 58 [145152/225000 (65%)] Loss: 14916.212891\n",
      "Train Epoch: 58 [146560/225000 (65%)] Loss: 14586.319336\n",
      "Train Epoch: 58 [147968/225000 (66%)] Loss: 14754.733398\n",
      "Train Epoch: 58 [149376/225000 (66%)] Loss: 14776.689453\n",
      "Train Epoch: 58 [150784/225000 (67%)] Loss: 15207.148438\n",
      "Train Epoch: 58 [152192/225000 (68%)] Loss: 14832.381836\n",
      "Train Epoch: 58 [153600/225000 (68%)] Loss: 15217.047852\n",
      "Train Epoch: 58 [155008/225000 (69%)] Loss: 14935.413086\n",
      "Train Epoch: 58 [156416/225000 (70%)] Loss: 15635.939453\n",
      "Train Epoch: 58 [157824/225000 (70%)] Loss: 14960.999023\n",
      "Train Epoch: 58 [159232/225000 (71%)] Loss: 15478.166016\n",
      "Train Epoch: 58 [160640/225000 (71%)] Loss: 15447.292969\n",
      "Train Epoch: 58 [162048/225000 (72%)] Loss: 14940.884766\n",
      "Train Epoch: 58 [163456/225000 (73%)] Loss: 14711.792969\n",
      "Train Epoch: 58 [164864/225000 (73%)] Loss: 14996.990234\n",
      "Train Epoch: 58 [166272/225000 (74%)] Loss: 14547.958984\n",
      "Train Epoch: 58 [167680/225000 (75%)] Loss: 14897.395508\n",
      "Train Epoch: 58 [169088/225000 (75%)] Loss: 14798.227539\n",
      "Train Epoch: 58 [170496/225000 (76%)] Loss: 15549.575195\n",
      "Train Epoch: 58 [171904/225000 (76%)] Loss: 15247.323242\n",
      "Train Epoch: 58 [173312/225000 (77%)] Loss: 14943.544922\n",
      "Train Epoch: 58 [174720/225000 (78%)] Loss: 14781.274414\n",
      "Train Epoch: 58 [176128/225000 (78%)] Loss: 15331.304688\n",
      "Train Epoch: 58 [177536/225000 (79%)] Loss: 15023.439453\n",
      "Train Epoch: 58 [178944/225000 (80%)] Loss: 15035.041992\n",
      "Train Epoch: 58 [180352/225000 (80%)] Loss: 15259.297852\n",
      "Train Epoch: 58 [181760/225000 (81%)] Loss: 14716.260742\n",
      "Train Epoch: 58 [183168/225000 (81%)] Loss: 14682.208984\n",
      "Train Epoch: 58 [184576/225000 (82%)] Loss: 14721.649414\n",
      "Train Epoch: 58 [185984/225000 (83%)] Loss: 14888.498047\n",
      "Train Epoch: 58 [187392/225000 (83%)] Loss: 14598.586914\n",
      "Train Epoch: 58 [188800/225000 (84%)] Loss: 14712.625977\n",
      "Train Epoch: 58 [190208/225000 (85%)] Loss: 15316.370117\n",
      "Train Epoch: 58 [191616/225000 (85%)] Loss: 14611.493164\n",
      "Train Epoch: 58 [193024/225000 (86%)] Loss: 14878.792969\n",
      "Train Epoch: 58 [194432/225000 (86%)] Loss: 15271.519531\n",
      "Train Epoch: 58 [195840/225000 (87%)] Loss: 15711.354492\n",
      "Train Epoch: 58 [197248/225000 (88%)] Loss: 15301.301758\n",
      "Train Epoch: 58 [198656/225000 (88%)] Loss: 15641.637695\n",
      "Train Epoch: 58 [200064/225000 (89%)] Loss: 15025.937500\n",
      "Train Epoch: 58 [201472/225000 (90%)] Loss: 15054.388672\n",
      "Train Epoch: 58 [202880/225000 (90%)] Loss: 14985.413086\n",
      "Train Epoch: 58 [204288/225000 (91%)] Loss: 15110.992188\n",
      "Train Epoch: 58 [205696/225000 (91%)] Loss: 15227.522461\n",
      "Train Epoch: 58 [207104/225000 (92%)] Loss: 15276.679688\n",
      "Train Epoch: 58 [208512/225000 (93%)] Loss: 14730.622070\n",
      "Train Epoch: 58 [209920/225000 (93%)] Loss: 14765.932617\n",
      "Train Epoch: 58 [211328/225000 (94%)] Loss: 14670.512695\n",
      "Train Epoch: 58 [212736/225000 (95%)] Loss: 15301.869141\n",
      "Train Epoch: 58 [214144/225000 (95%)] Loss: 15040.223633\n",
      "Train Epoch: 58 [215552/225000 (96%)] Loss: 15069.597656\n",
      "Train Epoch: 58 [216960/225000 (96%)] Loss: 14794.489258\n",
      "Train Epoch: 58 [218368/225000 (97%)] Loss: 14785.600586\n",
      "Train Epoch: 58 [219776/225000 (98%)] Loss: 14952.499023\n",
      "Train Epoch: 58 [221184/225000 (98%)] Loss: 15149.926758\n",
      "Train Epoch: 58 [222592/225000 (99%)] Loss: 14588.799805\n",
      "Train Epoch: 58 [224000/225000 (100%)] Loss: 15117.031250\n",
      "    epoch          : 58\n",
      "    loss           : 15077.148014211818\n",
      "    val_loss       : 15057.197281868179\n",
      "Train Epoch: 59 [128/225000 (0%)] Loss: 15126.440430\n",
      "Train Epoch: 59 [1536/225000 (1%)] Loss: 15078.245117\n",
      "Train Epoch: 59 [2944/225000 (1%)] Loss: 14784.316406\n",
      "Train Epoch: 59 [4352/225000 (2%)] Loss: 15703.635742\n",
      "Train Epoch: 59 [5760/225000 (3%)] Loss: 15373.122070\n",
      "Train Epoch: 59 [7168/225000 (3%)] Loss: 15278.224609\n",
      "Train Epoch: 59 [8576/225000 (4%)] Loss: 15438.117188\n",
      "Train Epoch: 59 [9984/225000 (4%)] Loss: 15285.797852\n",
      "Train Epoch: 59 [11392/225000 (5%)] Loss: 15165.346680\n",
      "Train Epoch: 59 [12800/225000 (6%)] Loss: 14687.076172\n",
      "Train Epoch: 59 [14208/225000 (6%)] Loss: 15190.538086\n",
      "Train Epoch: 59 [15616/225000 (7%)] Loss: 15531.216797\n",
      "Train Epoch: 59 [17024/225000 (8%)] Loss: 15059.886719\n",
      "Train Epoch: 59 [18432/225000 (8%)] Loss: 14553.586914\n",
      "Train Epoch: 59 [19840/225000 (9%)] Loss: 15490.903320\n",
      "Train Epoch: 59 [21248/225000 (9%)] Loss: 15426.168945\n",
      "Train Epoch: 59 [22656/225000 (10%)] Loss: 14884.888672\n",
      "Train Epoch: 59 [24064/225000 (11%)] Loss: 14627.532227\n",
      "Train Epoch: 59 [25472/225000 (11%)] Loss: 15585.011719\n",
      "Train Epoch: 59 [26880/225000 (12%)] Loss: 14996.005859\n",
      "Train Epoch: 59 [28288/225000 (13%)] Loss: 14680.009766\n",
      "Train Epoch: 59 [29696/225000 (13%)] Loss: 14939.102539\n",
      "Train Epoch: 59 [31104/225000 (14%)] Loss: 14991.731445\n",
      "Train Epoch: 59 [32512/225000 (14%)] Loss: 15471.136719\n",
      "Train Epoch: 59 [33920/225000 (15%)] Loss: 14969.889648\n",
      "Train Epoch: 59 [35328/225000 (16%)] Loss: 15120.844727\n",
      "Train Epoch: 59 [36736/225000 (16%)] Loss: 15318.316406\n",
      "Train Epoch: 59 [38144/225000 (17%)] Loss: 14766.386719\n",
      "Train Epoch: 59 [39552/225000 (18%)] Loss: 15536.455078\n",
      "Train Epoch: 59 [40960/225000 (18%)] Loss: 14843.054688\n",
      "Train Epoch: 59 [42368/225000 (19%)] Loss: 15126.358398\n",
      "Train Epoch: 59 [43776/225000 (19%)] Loss: 14689.064453\n",
      "Train Epoch: 59 [45184/225000 (20%)] Loss: 15299.124023\n",
      "Train Epoch: 59 [46592/225000 (21%)] Loss: 15246.228516\n",
      "Train Epoch: 59 [48000/225000 (21%)] Loss: 15209.950195\n",
      "Train Epoch: 59 [49408/225000 (22%)] Loss: 15168.565430\n",
      "Train Epoch: 59 [50816/225000 (23%)] Loss: 15296.927734\n",
      "Train Epoch: 59 [52224/225000 (23%)] Loss: 14652.852539\n",
      "Train Epoch: 59 [53632/225000 (24%)] Loss: 15028.455078\n",
      "Train Epoch: 59 [55040/225000 (24%)] Loss: 14823.848633\n",
      "Train Epoch: 59 [56448/225000 (25%)] Loss: 15186.812500\n",
      "Train Epoch: 59 [57856/225000 (26%)] Loss: 15345.806641\n",
      "Train Epoch: 59 [59264/225000 (26%)] Loss: 15084.560547\n",
      "Train Epoch: 59 [60672/225000 (27%)] Loss: 15102.922852\n",
      "Train Epoch: 59 [62080/225000 (28%)] Loss: 15061.286133\n",
      "Train Epoch: 59 [63488/225000 (28%)] Loss: 14602.280273\n",
      "Train Epoch: 59 [64896/225000 (29%)] Loss: 14792.077148\n",
      "Train Epoch: 59 [66304/225000 (29%)] Loss: 15297.078125\n",
      "Train Epoch: 59 [67712/225000 (30%)] Loss: 15374.223633\n",
      "Train Epoch: 59 [69120/225000 (31%)] Loss: 14837.012695\n",
      "Train Epoch: 59 [70528/225000 (31%)] Loss: 15038.287109\n",
      "Train Epoch: 59 [71936/225000 (32%)] Loss: 14976.168945\n",
      "Train Epoch: 59 [73344/225000 (33%)] Loss: 14995.527344\n",
      "Train Epoch: 59 [74752/225000 (33%)] Loss: 15117.275391\n",
      "Train Epoch: 59 [76160/225000 (34%)] Loss: 15045.574219\n",
      "Train Epoch: 59 [77568/225000 (34%)] Loss: 15344.833008\n",
      "Train Epoch: 59 [78976/225000 (35%)] Loss: 15201.087891\n",
      "Train Epoch: 59 [80384/225000 (36%)] Loss: 15510.754883\n",
      "Train Epoch: 59 [81792/225000 (36%)] Loss: 15633.643555\n",
      "Train Epoch: 59 [83200/225000 (37%)] Loss: 14541.500000\n",
      "Train Epoch: 59 [84608/225000 (38%)] Loss: 15242.524414\n",
      "Train Epoch: 59 [86016/225000 (38%)] Loss: 15052.024414\n",
      "Train Epoch: 59 [87424/225000 (39%)] Loss: 15372.492188\n",
      "Train Epoch: 59 [88832/225000 (39%)] Loss: 15635.992188\n",
      "Train Epoch: 59 [90240/225000 (40%)] Loss: 14532.226562\n",
      "Train Epoch: 59 [91648/225000 (41%)] Loss: 14775.704102\n",
      "Train Epoch: 59 [93056/225000 (41%)] Loss: 14887.291016\n",
      "Train Epoch: 59 [94464/225000 (42%)] Loss: 15098.309570\n",
      "Train Epoch: 59 [95872/225000 (43%)] Loss: 15212.253906\n",
      "Train Epoch: 59 [97280/225000 (43%)] Loss: 14758.207031\n",
      "Train Epoch: 59 [98688/225000 (44%)] Loss: 15191.665039\n",
      "Train Epoch: 59 [100096/225000 (44%)] Loss: 14700.052734\n",
      "Train Epoch: 59 [101504/225000 (45%)] Loss: 14673.416992\n",
      "Train Epoch: 59 [102912/225000 (46%)] Loss: 14910.089844\n",
      "Train Epoch: 59 [104320/225000 (46%)] Loss: 15163.020508\n",
      "Train Epoch: 59 [105728/225000 (47%)] Loss: 14910.647461\n",
      "Train Epoch: 59 [107136/225000 (48%)] Loss: 15094.791016\n",
      "Train Epoch: 59 [108544/225000 (48%)] Loss: 14844.482422\n",
      "Train Epoch: 59 [109952/225000 (49%)] Loss: 14686.892578\n",
      "Train Epoch: 59 [111360/225000 (49%)] Loss: 14869.945312\n",
      "Train Epoch: 59 [112768/225000 (50%)] Loss: 14803.726562\n",
      "Train Epoch: 59 [114176/225000 (51%)] Loss: 14808.430664\n",
      "Train Epoch: 59 [115584/225000 (51%)] Loss: 14986.886719\n",
      "Train Epoch: 59 [116992/225000 (52%)] Loss: 15364.103516\n",
      "Train Epoch: 59 [118400/225000 (53%)] Loss: 14905.930664\n",
      "Train Epoch: 59 [119808/225000 (53%)] Loss: 14761.121094\n",
      "Train Epoch: 59 [121216/225000 (54%)] Loss: 14798.902344\n",
      "Train Epoch: 59 [122624/225000 (54%)] Loss: 14904.402344\n",
      "Train Epoch: 59 [124032/225000 (55%)] Loss: 14909.415039\n",
      "Train Epoch: 59 [125440/225000 (56%)] Loss: 15163.446289\n",
      "Train Epoch: 59 [126848/225000 (56%)] Loss: 15121.216797\n",
      "Train Epoch: 59 [128256/225000 (57%)] Loss: 14599.891602\n",
      "Train Epoch: 59 [129664/225000 (58%)] Loss: 15514.198242\n",
      "Train Epoch: 59 [131072/225000 (58%)] Loss: 15139.472656\n",
      "Train Epoch: 59 [132480/225000 (59%)] Loss: 15507.024414\n",
      "Train Epoch: 59 [133888/225000 (60%)] Loss: 14726.387695\n",
      "Train Epoch: 59 [135296/225000 (60%)] Loss: 14679.920898\n",
      "Train Epoch: 59 [136704/225000 (61%)] Loss: 14912.528320\n",
      "Train Epoch: 59 [138112/225000 (61%)] Loss: 14933.556641\n",
      "Train Epoch: 59 [139520/225000 (62%)] Loss: 14948.039062\n",
      "Train Epoch: 59 [140928/225000 (63%)] Loss: 14915.166016\n",
      "Train Epoch: 59 [142336/225000 (63%)] Loss: 15073.265625\n",
      "Train Epoch: 59 [143744/225000 (64%)] Loss: 14894.557617\n",
      "Train Epoch: 59 [145152/225000 (65%)] Loss: 15195.325195\n",
      "Train Epoch: 59 [146560/225000 (65%)] Loss: 15487.537109\n",
      "Train Epoch: 59 [147968/225000 (66%)] Loss: 15144.647461\n",
      "Train Epoch: 59 [149376/225000 (66%)] Loss: 15045.324219\n",
      "Train Epoch: 59 [150784/225000 (67%)] Loss: 15147.426758\n",
      "Train Epoch: 59 [152192/225000 (68%)] Loss: 15175.140625\n",
      "Train Epoch: 59 [153600/225000 (68%)] Loss: 15128.413086\n",
      "Train Epoch: 59 [155008/225000 (69%)] Loss: 15318.781250\n",
      "Train Epoch: 59 [156416/225000 (70%)] Loss: 15504.320312\n",
      "Train Epoch: 59 [157824/225000 (70%)] Loss: 14660.311523\n",
      "Train Epoch: 59 [159232/225000 (71%)] Loss: 14717.531250\n",
      "Train Epoch: 59 [160640/225000 (71%)] Loss: 14454.896484\n",
      "Train Epoch: 59 [162048/225000 (72%)] Loss: 14542.657227\n",
      "Train Epoch: 59 [163456/225000 (73%)] Loss: 14990.875000\n",
      "Train Epoch: 59 [164864/225000 (73%)] Loss: 14774.076172\n",
      "Train Epoch: 59 [166272/225000 (74%)] Loss: 15441.148438\n",
      "Train Epoch: 59 [167680/225000 (75%)] Loss: 14795.556641\n",
      "Train Epoch: 59 [169088/225000 (75%)] Loss: 15248.287109\n",
      "Train Epoch: 59 [170496/225000 (76%)] Loss: 15134.039062\n",
      "Train Epoch: 59 [171904/225000 (76%)] Loss: 14646.593750\n",
      "Train Epoch: 59 [173312/225000 (77%)] Loss: 15140.109375\n",
      "Train Epoch: 59 [174720/225000 (78%)] Loss: 14799.257812\n",
      "Train Epoch: 59 [176128/225000 (78%)] Loss: 15024.034180\n",
      "Train Epoch: 59 [177536/225000 (79%)] Loss: 15160.055664\n",
      "Train Epoch: 59 [178944/225000 (80%)] Loss: 15668.065430\n",
      "Train Epoch: 59 [180352/225000 (80%)] Loss: 14617.117188\n",
      "Train Epoch: 59 [181760/225000 (81%)] Loss: 15114.551758\n",
      "Train Epoch: 59 [183168/225000 (81%)] Loss: 15036.621094\n",
      "Train Epoch: 59 [184576/225000 (82%)] Loss: 15303.562500\n",
      "Train Epoch: 59 [185984/225000 (83%)] Loss: 14363.454102\n",
      "Train Epoch: 59 [187392/225000 (83%)] Loss: 15122.286133\n",
      "Train Epoch: 59 [188800/225000 (84%)] Loss: 15099.260742\n",
      "Train Epoch: 59 [190208/225000 (85%)] Loss: 15518.925781\n",
      "Train Epoch: 59 [191616/225000 (85%)] Loss: 14893.821289\n",
      "Train Epoch: 59 [193024/225000 (86%)] Loss: 14884.025391\n",
      "Train Epoch: 59 [194432/225000 (86%)] Loss: 15026.655273\n",
      "Train Epoch: 59 [195840/225000 (87%)] Loss: 14742.842773\n",
      "Train Epoch: 59 [197248/225000 (88%)] Loss: 14848.000000\n",
      "Train Epoch: 59 [198656/225000 (88%)] Loss: 15075.465820\n",
      "Train Epoch: 59 [200064/225000 (89%)] Loss: 14808.920898\n",
      "Train Epoch: 59 [201472/225000 (90%)] Loss: 15839.092773\n",
      "Train Epoch: 59 [202880/225000 (90%)] Loss: 14905.124023\n",
      "Train Epoch: 59 [204288/225000 (91%)] Loss: 14741.334961\n",
      "Train Epoch: 59 [205696/225000 (91%)] Loss: 14997.351562\n",
      "Train Epoch: 59 [207104/225000 (92%)] Loss: 15198.471680\n",
      "Train Epoch: 59 [208512/225000 (93%)] Loss: 15177.818359\n",
      "Train Epoch: 59 [209920/225000 (93%)] Loss: 15080.121094\n",
      "Train Epoch: 59 [211328/225000 (94%)] Loss: 14931.220703\n",
      "Train Epoch: 59 [212736/225000 (95%)] Loss: 14817.790039\n",
      "Train Epoch: 59 [214144/225000 (95%)] Loss: 14735.351562\n",
      "Train Epoch: 59 [215552/225000 (96%)] Loss: 14905.529297\n",
      "Train Epoch: 59 [216960/225000 (96%)] Loss: 15522.682617\n",
      "Train Epoch: 59 [218368/225000 (97%)] Loss: 14657.435547\n",
      "Train Epoch: 59 [219776/225000 (98%)] Loss: 15124.540039\n",
      "Train Epoch: 59 [221184/225000 (98%)] Loss: 15248.531250\n",
      "Train Epoch: 59 [222592/225000 (99%)] Loss: 15027.216797\n",
      "Train Epoch: 59 [224000/225000 (100%)] Loss: 14948.949219\n",
      "    epoch          : 59\n",
      "    loss           : 15075.575155316767\n",
      "    val_loss       : 15060.18703704449\n",
      "Train Epoch: 60 [128/225000 (0%)] Loss: 14815.874023\n",
      "Train Epoch: 60 [1536/225000 (1%)] Loss: 15345.130859\n",
      "Train Epoch: 60 [2944/225000 (1%)] Loss: 14976.661133\n",
      "Train Epoch: 60 [4352/225000 (2%)] Loss: 15643.247070\n",
      "Train Epoch: 60 [5760/225000 (3%)] Loss: 15068.116211\n",
      "Train Epoch: 60 [7168/225000 (3%)] Loss: 15243.689453\n",
      "Train Epoch: 60 [8576/225000 (4%)] Loss: 14978.059570\n",
      "Train Epoch: 60 [9984/225000 (4%)] Loss: 14765.332031\n",
      "Train Epoch: 60 [11392/225000 (5%)] Loss: 15160.087891\n",
      "Train Epoch: 60 [12800/225000 (6%)] Loss: 14901.687500\n",
      "Train Epoch: 60 [14208/225000 (6%)] Loss: 15096.017578\n",
      "Train Epoch: 60 [15616/225000 (7%)] Loss: 15349.458984\n",
      "Train Epoch: 60 [17024/225000 (8%)] Loss: 14909.803711\n",
      "Train Epoch: 60 [18432/225000 (8%)] Loss: 15640.979492\n",
      "Train Epoch: 60 [19840/225000 (9%)] Loss: 14631.061523\n",
      "Train Epoch: 60 [21248/225000 (9%)] Loss: 14892.334961\n",
      "Train Epoch: 60 [22656/225000 (10%)] Loss: 15303.606445\n",
      "Train Epoch: 60 [24064/225000 (11%)] Loss: 15264.699219\n",
      "Train Epoch: 60 [25472/225000 (11%)] Loss: 15248.534180\n",
      "Train Epoch: 60 [26880/225000 (12%)] Loss: 15017.223633\n",
      "Train Epoch: 60 [28288/225000 (13%)] Loss: 15129.700195\n",
      "Train Epoch: 60 [29696/225000 (13%)] Loss: 15008.811523\n",
      "Train Epoch: 60 [31104/225000 (14%)] Loss: 15371.606445\n",
      "Train Epoch: 60 [32512/225000 (14%)] Loss: 15116.169922\n",
      "Train Epoch: 60 [33920/225000 (15%)] Loss: 14886.492188\n",
      "Train Epoch: 60 [35328/225000 (16%)] Loss: 14980.893555\n",
      "Train Epoch: 60 [36736/225000 (16%)] Loss: 15137.236328\n",
      "Train Epoch: 60 [38144/225000 (17%)] Loss: 14785.981445\n",
      "Train Epoch: 60 [39552/225000 (18%)] Loss: 15260.614258\n",
      "Train Epoch: 60 [40960/225000 (18%)] Loss: 14830.478516\n",
      "Train Epoch: 60 [42368/225000 (19%)] Loss: 14968.538086\n",
      "Train Epoch: 60 [43776/225000 (19%)] Loss: 15292.592773\n",
      "Train Epoch: 60 [45184/225000 (20%)] Loss: 15049.262695\n",
      "Train Epoch: 60 [46592/225000 (21%)] Loss: 14632.384766\n",
      "Train Epoch: 60 [48000/225000 (21%)] Loss: 15011.782227\n",
      "Train Epoch: 60 [49408/225000 (22%)] Loss: 15303.970703\n",
      "Train Epoch: 60 [50816/225000 (23%)] Loss: 15441.274414\n",
      "Train Epoch: 60 [52224/225000 (23%)] Loss: 14862.295898\n",
      "Train Epoch: 60 [53632/225000 (24%)] Loss: 15294.796875\n",
      "Train Epoch: 60 [55040/225000 (24%)] Loss: 15336.125000\n",
      "Train Epoch: 60 [56448/225000 (25%)] Loss: 15846.254883\n",
      "Train Epoch: 60 [57856/225000 (26%)] Loss: 14908.527344\n",
      "Train Epoch: 60 [59264/225000 (26%)] Loss: 14665.362305\n",
      "Train Epoch: 60 [60672/225000 (27%)] Loss: 14775.995117\n",
      "Train Epoch: 60 [62080/225000 (28%)] Loss: 15379.037109\n",
      "Train Epoch: 60 [63488/225000 (28%)] Loss: 14668.721680\n",
      "Train Epoch: 60 [64896/225000 (29%)] Loss: 15073.584961\n",
      "Train Epoch: 60 [66304/225000 (29%)] Loss: 15194.213867\n",
      "Train Epoch: 60 [67712/225000 (30%)] Loss: 15132.790039\n",
      "Train Epoch: 60 [69120/225000 (31%)] Loss: 14801.500977\n",
      "Train Epoch: 60 [70528/225000 (31%)] Loss: 15019.898438\n",
      "Train Epoch: 60 [71936/225000 (32%)] Loss: 15053.525391\n",
      "Train Epoch: 60 [73344/225000 (33%)] Loss: 14847.213867\n",
      "Train Epoch: 60 [74752/225000 (33%)] Loss: 14923.092773\n",
      "Train Epoch: 60 [76160/225000 (34%)] Loss: 15237.763672\n",
      "Train Epoch: 60 [77568/225000 (34%)] Loss: 15234.622070\n",
      "Train Epoch: 60 [78976/225000 (35%)] Loss: 15088.375977\n",
      "Train Epoch: 60 [80384/225000 (36%)] Loss: 14966.010742\n",
      "Train Epoch: 60 [81792/225000 (36%)] Loss: 15444.865234\n",
      "Train Epoch: 60 [83200/225000 (37%)] Loss: 15014.565430\n",
      "Train Epoch: 60 [84608/225000 (38%)] Loss: 15015.675781\n",
      "Train Epoch: 60 [86016/225000 (38%)] Loss: 15058.531250\n",
      "Train Epoch: 60 [87424/225000 (39%)] Loss: 14613.003906\n",
      "Train Epoch: 60 [88832/225000 (39%)] Loss: 15195.421875\n",
      "Train Epoch: 60 [90240/225000 (40%)] Loss: 14909.333008\n",
      "Train Epoch: 60 [91648/225000 (41%)] Loss: 15052.879883\n",
      "Train Epoch: 60 [93056/225000 (41%)] Loss: 14996.744141\n",
      "Train Epoch: 60 [94464/225000 (42%)] Loss: 15367.438477\n",
      "Train Epoch: 60 [95872/225000 (43%)] Loss: 15439.312500\n",
      "Train Epoch: 60 [97280/225000 (43%)] Loss: 14891.656250\n",
      "Train Epoch: 60 [98688/225000 (44%)] Loss: 15125.203125\n",
      "Train Epoch: 60 [100096/225000 (44%)] Loss: 15505.790039\n",
      "Train Epoch: 60 [101504/225000 (45%)] Loss: 14712.381836\n",
      "Train Epoch: 60 [102912/225000 (46%)] Loss: 15183.440430\n",
      "Train Epoch: 60 [104320/225000 (46%)] Loss: 15021.766602\n",
      "Train Epoch: 60 [105728/225000 (47%)] Loss: 14860.892578\n",
      "Train Epoch: 60 [107136/225000 (48%)] Loss: 15450.647461\n",
      "Train Epoch: 60 [108544/225000 (48%)] Loss: 15264.650391\n",
      "Train Epoch: 60 [109952/225000 (49%)] Loss: 15150.124023\n",
      "Train Epoch: 60 [111360/225000 (49%)] Loss: 14800.741211\n",
      "Train Epoch: 60 [112768/225000 (50%)] Loss: 15026.424805\n",
      "Train Epoch: 60 [114176/225000 (51%)] Loss: 14959.833984\n",
      "Train Epoch: 60 [115584/225000 (51%)] Loss: 15246.134766\n",
      "Train Epoch: 60 [116992/225000 (52%)] Loss: 14793.522461\n",
      "Train Epoch: 60 [118400/225000 (53%)] Loss: 15495.303711\n",
      "Train Epoch: 60 [119808/225000 (53%)] Loss: 14978.118164\n",
      "Train Epoch: 60 [121216/225000 (54%)] Loss: 15005.038086\n",
      "Train Epoch: 60 [122624/225000 (54%)] Loss: 15319.681641\n",
      "Train Epoch: 60 [124032/225000 (55%)] Loss: 15132.832031\n",
      "Train Epoch: 60 [125440/225000 (56%)] Loss: 15301.881836\n",
      "Train Epoch: 60 [126848/225000 (56%)] Loss: 14939.544922\n",
      "Train Epoch: 60 [128256/225000 (57%)] Loss: 15373.732422\n",
      "Train Epoch: 60 [129664/225000 (58%)] Loss: 15028.545898\n",
      "Train Epoch: 60 [131072/225000 (58%)] Loss: 14825.521484\n",
      "Train Epoch: 60 [132480/225000 (59%)] Loss: 15098.901367\n",
      "Train Epoch: 60 [133888/225000 (60%)] Loss: 15458.724609\n",
      "Train Epoch: 60 [135296/225000 (60%)] Loss: 15382.150391\n",
      "Train Epoch: 60 [136704/225000 (61%)] Loss: 14981.605469\n",
      "Train Epoch: 60 [138112/225000 (61%)] Loss: 15279.750977\n",
      "Train Epoch: 60 [139520/225000 (62%)] Loss: 14964.130859\n",
      "Train Epoch: 60 [140928/225000 (63%)] Loss: 14902.008789\n",
      "Train Epoch: 60 [142336/225000 (63%)] Loss: 14843.411133\n",
      "Train Epoch: 60 [143744/225000 (64%)] Loss: 15196.117188\n",
      "Train Epoch: 60 [145152/225000 (65%)] Loss: 14739.633789\n",
      "Train Epoch: 60 [146560/225000 (65%)] Loss: 15337.017578\n",
      "Train Epoch: 60 [147968/225000 (66%)] Loss: 15780.959961\n",
      "Train Epoch: 60 [149376/225000 (66%)] Loss: 14794.020508\n",
      "Train Epoch: 60 [150784/225000 (67%)] Loss: 14906.901367\n",
      "Train Epoch: 60 [152192/225000 (68%)] Loss: 15169.262695\n",
      "Train Epoch: 60 [153600/225000 (68%)] Loss: 15056.926758\n",
      "Train Epoch: 60 [155008/225000 (69%)] Loss: 14871.076172\n",
      "Train Epoch: 60 [156416/225000 (70%)] Loss: 14790.537109\n",
      "Train Epoch: 60 [157824/225000 (70%)] Loss: 14865.049805\n",
      "Train Epoch: 60 [159232/225000 (71%)] Loss: 14913.767578\n",
      "Train Epoch: 60 [160640/225000 (71%)] Loss: 14746.261719\n",
      "Train Epoch: 60 [162048/225000 (72%)] Loss: 15055.914062\n",
      "Train Epoch: 60 [163456/225000 (73%)] Loss: 14943.860352\n",
      "Train Epoch: 60 [164864/225000 (73%)] Loss: 15256.783203\n",
      "Train Epoch: 60 [166272/225000 (74%)] Loss: 15267.070312\n",
      "Train Epoch: 60 [167680/225000 (75%)] Loss: 15294.739258\n",
      "Train Epoch: 60 [169088/225000 (75%)] Loss: 15112.564453\n",
      "Train Epoch: 60 [170496/225000 (76%)] Loss: 14986.355469\n",
      "Train Epoch: 60 [171904/225000 (76%)] Loss: 15316.611328\n",
      "Train Epoch: 60 [173312/225000 (77%)] Loss: 15217.713867\n",
      "Train Epoch: 60 [174720/225000 (78%)] Loss: 15213.479492\n",
      "Train Epoch: 60 [176128/225000 (78%)] Loss: 15024.218750\n",
      "Train Epoch: 60 [177536/225000 (79%)] Loss: 15625.375000\n",
      "Train Epoch: 60 [178944/225000 (80%)] Loss: 15132.147461\n",
      "Train Epoch: 60 [180352/225000 (80%)] Loss: 14808.367188\n",
      "Train Epoch: 60 [181760/225000 (81%)] Loss: 15128.802734\n",
      "Train Epoch: 60 [183168/225000 (81%)] Loss: 14853.996094\n",
      "Train Epoch: 60 [184576/225000 (82%)] Loss: 15847.234375\n",
      "Train Epoch: 60 [185984/225000 (83%)] Loss: 15110.512695\n",
      "Train Epoch: 60 [187392/225000 (83%)] Loss: 14820.689453\n",
      "Train Epoch: 60 [188800/225000 (84%)] Loss: 14850.301758\n",
      "Train Epoch: 60 [190208/225000 (85%)] Loss: 15020.493164\n",
      "Train Epoch: 60 [191616/225000 (85%)] Loss: 15382.050781\n",
      "Train Epoch: 60 [193024/225000 (86%)] Loss: 15074.094727\n",
      "Train Epoch: 60 [194432/225000 (86%)] Loss: 14896.841797\n",
      "Train Epoch: 60 [195840/225000 (87%)] Loss: 14895.772461\n",
      "Train Epoch: 60 [197248/225000 (88%)] Loss: 15027.824219\n",
      "Train Epoch: 60 [198656/225000 (88%)] Loss: 15226.390625\n",
      "Train Epoch: 60 [200064/225000 (89%)] Loss: 15209.248047\n",
      "Train Epoch: 60 [201472/225000 (90%)] Loss: 15379.208008\n",
      "Train Epoch: 60 [202880/225000 (90%)] Loss: 15361.431641\n",
      "Train Epoch: 60 [204288/225000 (91%)] Loss: 15006.745117\n",
      "Train Epoch: 60 [205696/225000 (91%)] Loss: 14771.349609\n",
      "Train Epoch: 60 [207104/225000 (92%)] Loss: 15494.944336\n",
      "Train Epoch: 60 [208512/225000 (93%)] Loss: 14923.904297\n",
      "Train Epoch: 60 [209920/225000 (93%)] Loss: 15053.889648\n",
      "Train Epoch: 60 [211328/225000 (94%)] Loss: 15048.192383\n",
      "Train Epoch: 60 [212736/225000 (95%)] Loss: 15077.059570\n",
      "Train Epoch: 60 [214144/225000 (95%)] Loss: 14936.289062\n",
      "Train Epoch: 60 [215552/225000 (96%)] Loss: 15034.406250\n",
      "Train Epoch: 60 [216960/225000 (96%)] Loss: 15337.830078\n",
      "Train Epoch: 60 [218368/225000 (97%)] Loss: 15253.643555\n",
      "Train Epoch: 60 [219776/225000 (98%)] Loss: 14948.544922\n",
      "Train Epoch: 60 [221184/225000 (98%)] Loss: 14723.916016\n",
      "Train Epoch: 60 [222592/225000 (99%)] Loss: 14972.652344\n",
      "Train Epoch: 60 [224000/225000 (100%)] Loss: 14649.365234\n",
      "    epoch          : 60\n",
      "    loss           : 15076.358768953534\n",
      "    val_loss       : 15057.027701306251\n",
      "Train Epoch: 61 [128/225000 (0%)] Loss: 14861.056641\n",
      "Train Epoch: 61 [1536/225000 (1%)] Loss: 15149.312500\n",
      "Train Epoch: 61 [2944/225000 (1%)] Loss: 15162.649414\n",
      "Train Epoch: 61 [4352/225000 (2%)] Loss: 15374.238281\n",
      "Train Epoch: 61 [5760/225000 (3%)] Loss: 15067.969727\n",
      "Train Epoch: 61 [7168/225000 (3%)] Loss: 15005.330078\n",
      "Train Epoch: 61 [8576/225000 (4%)] Loss: 14766.853516\n",
      "Train Epoch: 61 [9984/225000 (4%)] Loss: 14887.873047\n",
      "Train Epoch: 61 [11392/225000 (5%)] Loss: 15304.253906\n",
      "Train Epoch: 61 [12800/225000 (6%)] Loss: 15017.029297\n",
      "Train Epoch: 61 [14208/225000 (6%)] Loss: 15188.798828\n",
      "Train Epoch: 61 [15616/225000 (7%)] Loss: 14926.041992\n",
      "Train Epoch: 61 [17024/225000 (8%)] Loss: 15238.500977\n",
      "Train Epoch: 61 [18432/225000 (8%)] Loss: 15320.513672\n",
      "Train Epoch: 61 [19840/225000 (9%)] Loss: 15475.065430\n",
      "Train Epoch: 61 [21248/225000 (9%)] Loss: 15250.587891\n",
      "Train Epoch: 61 [22656/225000 (10%)] Loss: 15728.292969\n",
      "Train Epoch: 61 [24064/225000 (11%)] Loss: 14422.325195\n",
      "Train Epoch: 61 [25472/225000 (11%)] Loss: 15092.960938\n",
      "Train Epoch: 61 [26880/225000 (12%)] Loss: 15737.161133\n",
      "Train Epoch: 61 [28288/225000 (13%)] Loss: 15253.432617\n",
      "Train Epoch: 61 [29696/225000 (13%)] Loss: 14785.652344\n",
      "Train Epoch: 61 [31104/225000 (14%)] Loss: 15177.541016\n",
      "Train Epoch: 61 [32512/225000 (14%)] Loss: 15645.893555\n",
      "Train Epoch: 61 [33920/225000 (15%)] Loss: 14923.324219\n",
      "Train Epoch: 61 [35328/225000 (16%)] Loss: 14876.243164\n",
      "Train Epoch: 61 [36736/225000 (16%)] Loss: 14998.920898\n",
      "Train Epoch: 61 [38144/225000 (17%)] Loss: 15272.894531\n",
      "Train Epoch: 61 [39552/225000 (18%)] Loss: 15285.790039\n",
      "Train Epoch: 61 [40960/225000 (18%)] Loss: 15083.205078\n",
      "Train Epoch: 61 [42368/225000 (19%)] Loss: 14993.428711\n",
      "Train Epoch: 61 [43776/225000 (19%)] Loss: 15077.930664\n",
      "Train Epoch: 61 [45184/225000 (20%)] Loss: 15390.371094\n",
      "Train Epoch: 61 [46592/225000 (21%)] Loss: 14742.366211\n",
      "Train Epoch: 61 [48000/225000 (21%)] Loss: 15344.331055\n",
      "Train Epoch: 61 [49408/225000 (22%)] Loss: 15277.959961\n",
      "Train Epoch: 61 [50816/225000 (23%)] Loss: 15073.160156\n",
      "Train Epoch: 61 [52224/225000 (23%)] Loss: 15032.931641\n",
      "Train Epoch: 61 [53632/225000 (24%)] Loss: 15733.569336\n",
      "Train Epoch: 61 [55040/225000 (24%)] Loss: 15406.084961\n",
      "Train Epoch: 61 [56448/225000 (25%)] Loss: 14774.458984\n",
      "Train Epoch: 61 [57856/225000 (26%)] Loss: 15314.748047\n",
      "Train Epoch: 61 [59264/225000 (26%)] Loss: 15064.894531\n",
      "Train Epoch: 61 [60672/225000 (27%)] Loss: 15009.262695\n",
      "Train Epoch: 61 [62080/225000 (28%)] Loss: 14667.354492\n",
      "Train Epoch: 61 [63488/225000 (28%)] Loss: 14742.981445\n",
      "Train Epoch: 61 [64896/225000 (29%)] Loss: 14739.873047\n",
      "Train Epoch: 61 [66304/225000 (29%)] Loss: 15254.226562\n",
      "Train Epoch: 61 [67712/225000 (30%)] Loss: 14850.295898\n",
      "Train Epoch: 61 [69120/225000 (31%)] Loss: 15118.759766\n",
      "Train Epoch: 61 [70528/225000 (31%)] Loss: 15028.986328\n",
      "Train Epoch: 61 [71936/225000 (32%)] Loss: 15140.835938\n",
      "Train Epoch: 61 [73344/225000 (33%)] Loss: 15143.291992\n",
      "Train Epoch: 61 [74752/225000 (33%)] Loss: 15279.548828\n",
      "Train Epoch: 61 [76160/225000 (34%)] Loss: 15020.199219\n",
      "Train Epoch: 61 [77568/225000 (34%)] Loss: 15153.139648\n",
      "Train Epoch: 61 [78976/225000 (35%)] Loss: 14810.752930\n",
      "Train Epoch: 61 [80384/225000 (36%)] Loss: 15361.179688\n",
      "Train Epoch: 61 [81792/225000 (36%)] Loss: 15153.993164\n",
      "Train Epoch: 61 [83200/225000 (37%)] Loss: 15188.122070\n",
      "Train Epoch: 61 [84608/225000 (38%)] Loss: 15228.355469\n",
      "Train Epoch: 61 [86016/225000 (38%)] Loss: 15351.962891\n",
      "Train Epoch: 61 [87424/225000 (39%)] Loss: 14933.712891\n",
      "Train Epoch: 61 [88832/225000 (39%)] Loss: 15585.361328\n",
      "Train Epoch: 61 [90240/225000 (40%)] Loss: 14833.750977\n",
      "Train Epoch: 61 [91648/225000 (41%)] Loss: 15154.405273\n",
      "Train Epoch: 61 [93056/225000 (41%)] Loss: 14933.167969\n",
      "Train Epoch: 61 [94464/225000 (42%)] Loss: 14922.006836\n",
      "Train Epoch: 61 [95872/225000 (43%)] Loss: 15078.619141\n",
      "Train Epoch: 61 [97280/225000 (43%)] Loss: 15199.112305\n",
      "Train Epoch: 61 [98688/225000 (44%)] Loss: 14913.670898\n",
      "Train Epoch: 61 [100096/225000 (44%)] Loss: 15113.083008\n",
      "Train Epoch: 61 [101504/225000 (45%)] Loss: 15093.092773\n",
      "Train Epoch: 61 [102912/225000 (46%)] Loss: 14802.484375\n",
      "Train Epoch: 61 [104320/225000 (46%)] Loss: 15372.062500\n",
      "Train Epoch: 61 [105728/225000 (47%)] Loss: 14880.073242\n",
      "Train Epoch: 61 [107136/225000 (48%)] Loss: 14906.215820\n",
      "Train Epoch: 61 [108544/225000 (48%)] Loss: 15455.846680\n",
      "Train Epoch: 61 [109952/225000 (49%)] Loss: 14976.196289\n",
      "Train Epoch: 61 [111360/225000 (49%)] Loss: 15091.797852\n",
      "Train Epoch: 61 [112768/225000 (50%)] Loss: 15348.144531\n",
      "Train Epoch: 61 [114176/225000 (51%)] Loss: 14949.712891\n",
      "Train Epoch: 61 [115584/225000 (51%)] Loss: 14838.724609\n",
      "Train Epoch: 61 [116992/225000 (52%)] Loss: 14956.558594\n",
      "Train Epoch: 61 [118400/225000 (53%)] Loss: 15052.969727\n",
      "Train Epoch: 61 [119808/225000 (53%)] Loss: 15379.294922\n",
      "Train Epoch: 61 [121216/225000 (54%)] Loss: 14699.413086\n",
      "Train Epoch: 61 [122624/225000 (54%)] Loss: 15235.873047\n",
      "Train Epoch: 61 [124032/225000 (55%)] Loss: 14378.986328\n",
      "Train Epoch: 61 [125440/225000 (56%)] Loss: 15054.654297\n",
      "Train Epoch: 61 [126848/225000 (56%)] Loss: 15336.858398\n",
      "Train Epoch: 61 [128256/225000 (57%)] Loss: 15266.065430\n",
      "Train Epoch: 61 [129664/225000 (58%)] Loss: 14738.200195\n",
      "Train Epoch: 61 [131072/225000 (58%)] Loss: 15178.065430\n",
      "Train Epoch: 61 [132480/225000 (59%)] Loss: 14945.550781\n",
      "Train Epoch: 61 [133888/225000 (60%)] Loss: 14692.084961\n",
      "Train Epoch: 61 [135296/225000 (60%)] Loss: 14725.104492\n",
      "Train Epoch: 61 [136704/225000 (61%)] Loss: 15493.949219\n",
      "Train Epoch: 61 [138112/225000 (61%)] Loss: 15368.247070\n",
      "Train Epoch: 61 [139520/225000 (62%)] Loss: 15037.928711\n",
      "Train Epoch: 61 [140928/225000 (63%)] Loss: 14769.527344\n",
      "Train Epoch: 61 [142336/225000 (63%)] Loss: 15009.340820\n",
      "Train Epoch: 61 [143744/225000 (64%)] Loss: 14824.803711\n",
      "Train Epoch: 61 [145152/225000 (65%)] Loss: 15670.420898\n",
      "Train Epoch: 61 [146560/225000 (65%)] Loss: 14827.333008\n",
      "Train Epoch: 61 [147968/225000 (66%)] Loss: 15365.497070\n",
      "Train Epoch: 61 [149376/225000 (66%)] Loss: 15181.559570\n",
      "Train Epoch: 61 [150784/225000 (67%)] Loss: 14816.023438\n",
      "Train Epoch: 61 [152192/225000 (68%)] Loss: 14913.779297\n",
      "Train Epoch: 61 [153600/225000 (68%)] Loss: 15442.607422\n",
      "Train Epoch: 61 [155008/225000 (69%)] Loss: 15347.317383\n",
      "Train Epoch: 61 [156416/225000 (70%)] Loss: 15207.107422\n",
      "Train Epoch: 61 [157824/225000 (70%)] Loss: 15523.563477\n",
      "Train Epoch: 61 [159232/225000 (71%)] Loss: 15329.678711\n",
      "Train Epoch: 61 [160640/225000 (71%)] Loss: 15175.061523\n",
      "Train Epoch: 61 [162048/225000 (72%)] Loss: 15063.663086\n",
      "Train Epoch: 61 [163456/225000 (73%)] Loss: 15051.258789\n",
      "Train Epoch: 61 [164864/225000 (73%)] Loss: 15006.469727\n",
      "Train Epoch: 61 [166272/225000 (74%)] Loss: 15054.753906\n",
      "Train Epoch: 61 [167680/225000 (75%)] Loss: 15100.748047\n",
      "Train Epoch: 61 [169088/225000 (75%)] Loss: 15031.006836\n",
      "Train Epoch: 61 [170496/225000 (76%)] Loss: 15313.353516\n",
      "Train Epoch: 61 [171904/225000 (76%)] Loss: 15358.691406\n",
      "Train Epoch: 61 [173312/225000 (77%)] Loss: 15037.877930\n",
      "Train Epoch: 61 [174720/225000 (78%)] Loss: 14667.049805\n",
      "Train Epoch: 61 [176128/225000 (78%)] Loss: 15077.175781\n",
      "Train Epoch: 61 [177536/225000 (79%)] Loss: 14863.204102\n",
      "Train Epoch: 61 [178944/225000 (80%)] Loss: 15180.146484\n",
      "Train Epoch: 61 [180352/225000 (80%)] Loss: 15218.941406\n",
      "Train Epoch: 61 [181760/225000 (81%)] Loss: 14831.988281\n",
      "Train Epoch: 61 [183168/225000 (81%)] Loss: 15038.850586\n",
      "Train Epoch: 61 [184576/225000 (82%)] Loss: 15441.837891\n",
      "Train Epoch: 61 [185984/225000 (83%)] Loss: 15368.343750\n",
      "Train Epoch: 61 [187392/225000 (83%)] Loss: 14825.886719\n",
      "Train Epoch: 61 [188800/225000 (84%)] Loss: 15056.462891\n",
      "Train Epoch: 61 [190208/225000 (85%)] Loss: 15205.961914\n",
      "Train Epoch: 61 [191616/225000 (85%)] Loss: 15285.494141\n",
      "Train Epoch: 61 [193024/225000 (86%)] Loss: 15258.833008\n",
      "Train Epoch: 61 [194432/225000 (86%)] Loss: 15674.463867\n",
      "Train Epoch: 61 [195840/225000 (87%)] Loss: 15157.030273\n",
      "Train Epoch: 61 [197248/225000 (88%)] Loss: 14581.852539\n",
      "Train Epoch: 61 [198656/225000 (88%)] Loss: 14936.087891\n",
      "Train Epoch: 61 [200064/225000 (89%)] Loss: 15095.326172\n",
      "Train Epoch: 61 [201472/225000 (90%)] Loss: 15366.846680\n",
      "Train Epoch: 61 [202880/225000 (90%)] Loss: 14853.145508\n",
      "Train Epoch: 61 [204288/225000 (91%)] Loss: 14975.266602\n",
      "Train Epoch: 61 [205696/225000 (91%)] Loss: 14799.033203\n",
      "Train Epoch: 61 [207104/225000 (92%)] Loss: 15054.026367\n",
      "Train Epoch: 61 [208512/225000 (93%)] Loss: 14813.856445\n",
      "Train Epoch: 61 [209920/225000 (93%)] Loss: 15090.344727\n",
      "Train Epoch: 61 [211328/225000 (94%)] Loss: 14871.498047\n",
      "Train Epoch: 61 [212736/225000 (95%)] Loss: 14621.948242\n",
      "Train Epoch: 61 [214144/225000 (95%)] Loss: 15190.531250\n",
      "Train Epoch: 61 [215552/225000 (96%)] Loss: 15318.195312\n",
      "Train Epoch: 61 [216960/225000 (96%)] Loss: 15281.232422\n",
      "Train Epoch: 61 [218368/225000 (97%)] Loss: 14810.493164\n",
      "Train Epoch: 61 [219776/225000 (98%)] Loss: 15155.021484\n",
      "Train Epoch: 61 [221184/225000 (98%)] Loss: 14749.198242\n",
      "Train Epoch: 61 [222592/225000 (99%)] Loss: 15314.766602\n",
      "Train Epoch: 61 [224000/225000 (100%)] Loss: 14976.089844\n",
      "    epoch          : 61\n",
      "    loss           : 15076.668188726535\n",
      "    val_loss       : 15057.253725586648\n",
      "Train Epoch: 62 [128/225000 (0%)] Loss: 15179.440430\n",
      "Train Epoch: 62 [1536/225000 (1%)] Loss: 14981.886719\n",
      "Train Epoch: 62 [2944/225000 (1%)] Loss: 15167.833984\n",
      "Train Epoch: 62 [4352/225000 (2%)] Loss: 15085.192383\n",
      "Train Epoch: 62 [5760/225000 (3%)] Loss: 15386.941406\n",
      "Train Epoch: 62 [7168/225000 (3%)] Loss: 14828.576172\n",
      "Train Epoch: 62 [8576/225000 (4%)] Loss: 15097.720703\n",
      "Train Epoch: 62 [9984/225000 (4%)] Loss: 15622.895508\n",
      "Train Epoch: 62 [11392/225000 (5%)] Loss: 14878.239258\n",
      "Train Epoch: 62 [12800/225000 (6%)] Loss: 15201.312500\n",
      "Train Epoch: 62 [14208/225000 (6%)] Loss: 14865.035156\n",
      "Train Epoch: 62 [15616/225000 (7%)] Loss: 14549.470703\n",
      "Train Epoch: 62 [17024/225000 (8%)] Loss: 15309.944336\n",
      "Train Epoch: 62 [18432/225000 (8%)] Loss: 15187.471680\n",
      "Train Epoch: 62 [19840/225000 (9%)] Loss: 15004.533203\n",
      "Train Epoch: 62 [21248/225000 (9%)] Loss: 15206.195312\n",
      "Train Epoch: 62 [22656/225000 (10%)] Loss: 15584.465820\n",
      "Train Epoch: 62 [24064/225000 (11%)] Loss: 15412.107422\n",
      "Train Epoch: 62 [25472/225000 (11%)] Loss: 15024.850586\n",
      "Train Epoch: 62 [26880/225000 (12%)] Loss: 14880.935547\n",
      "Train Epoch: 62 [28288/225000 (13%)] Loss: 15749.296875\n",
      "Train Epoch: 62 [29696/225000 (13%)] Loss: 15551.751953\n",
      "Train Epoch: 62 [31104/225000 (14%)] Loss: 14681.229492\n",
      "Train Epoch: 62 [32512/225000 (14%)] Loss: 15175.037109\n",
      "Train Epoch: 62 [33920/225000 (15%)] Loss: 14876.026367\n",
      "Train Epoch: 62 [35328/225000 (16%)] Loss: 15104.047852\n",
      "Train Epoch: 62 [36736/225000 (16%)] Loss: 14705.404297\n",
      "Train Epoch: 62 [38144/225000 (17%)] Loss: 15039.474609\n",
      "Train Epoch: 62 [39552/225000 (18%)] Loss: 15180.234375\n",
      "Train Epoch: 62 [40960/225000 (18%)] Loss: 15067.881836\n",
      "Train Epoch: 62 [42368/225000 (19%)] Loss: 15053.581055\n",
      "Train Epoch: 62 [43776/225000 (19%)] Loss: 15728.421875\n",
      "Train Epoch: 62 [45184/225000 (20%)] Loss: 14744.652344\n",
      "Train Epoch: 62 [46592/225000 (21%)] Loss: 15162.678711\n",
      "Train Epoch: 62 [48000/225000 (21%)] Loss: 14861.858398\n",
      "Train Epoch: 62 [49408/225000 (22%)] Loss: 15039.883789\n",
      "Train Epoch: 62 [50816/225000 (23%)] Loss: 15022.005859\n",
      "Train Epoch: 62 [52224/225000 (23%)] Loss: 15116.581055\n",
      "Train Epoch: 62 [53632/225000 (24%)] Loss: 14537.562500\n",
      "Train Epoch: 62 [55040/225000 (24%)] Loss: 14884.308594\n",
      "Train Epoch: 62 [56448/225000 (25%)] Loss: 15906.247070\n",
      "Train Epoch: 62 [57856/225000 (26%)] Loss: 15250.118164\n",
      "Train Epoch: 62 [59264/225000 (26%)] Loss: 15051.562500\n",
      "Train Epoch: 62 [60672/225000 (27%)] Loss: 15149.854492\n",
      "Train Epoch: 62 [62080/225000 (28%)] Loss: 14877.352539\n",
      "Train Epoch: 62 [63488/225000 (28%)] Loss: 14948.723633\n",
      "Train Epoch: 62 [64896/225000 (29%)] Loss: 14758.386719\n",
      "Train Epoch: 62 [66304/225000 (29%)] Loss: 15121.188477\n",
      "Train Epoch: 62 [67712/225000 (30%)] Loss: 15389.193359\n",
      "Train Epoch: 62 [69120/225000 (31%)] Loss: 14829.101562\n",
      "Train Epoch: 62 [70528/225000 (31%)] Loss: 14997.660156\n",
      "Train Epoch: 62 [71936/225000 (32%)] Loss: 15279.583984\n",
      "Train Epoch: 62 [73344/225000 (33%)] Loss: 15606.896484\n",
      "Train Epoch: 62 [74752/225000 (33%)] Loss: 14789.606445\n",
      "Train Epoch: 62 [76160/225000 (34%)] Loss: 15343.569336\n",
      "Train Epoch: 62 [77568/225000 (34%)] Loss: 15047.130859\n",
      "Train Epoch: 62 [78976/225000 (35%)] Loss: 14676.879883\n",
      "Train Epoch: 62 [80384/225000 (36%)] Loss: 14641.099609\n",
      "Train Epoch: 62 [81792/225000 (36%)] Loss: 15096.079102\n",
      "Train Epoch: 62 [83200/225000 (37%)] Loss: 15152.133789\n",
      "Train Epoch: 62 [84608/225000 (38%)] Loss: 15484.986328\n",
      "Train Epoch: 62 [86016/225000 (38%)] Loss: 15092.475586\n",
      "Train Epoch: 62 [87424/225000 (39%)] Loss: 14658.920898\n",
      "Train Epoch: 62 [88832/225000 (39%)] Loss: 15061.475586\n",
      "Train Epoch: 62 [90240/225000 (40%)] Loss: 15389.906250\n",
      "Train Epoch: 62 [91648/225000 (41%)] Loss: 15042.242188\n",
      "Train Epoch: 62 [93056/225000 (41%)] Loss: 14951.883789\n",
      "Train Epoch: 62 [94464/225000 (42%)] Loss: 15003.624023\n",
      "Train Epoch: 62 [95872/225000 (43%)] Loss: 15283.713867\n",
      "Train Epoch: 62 [97280/225000 (43%)] Loss: 14964.211914\n",
      "Train Epoch: 62 [98688/225000 (44%)] Loss: 15365.829102\n",
      "Train Epoch: 62 [100096/225000 (44%)] Loss: 15133.572266\n",
      "Train Epoch: 62 [101504/225000 (45%)] Loss: 15178.191406\n",
      "Train Epoch: 62 [102912/225000 (46%)] Loss: 14616.290039\n",
      "Train Epoch: 62 [104320/225000 (46%)] Loss: 14996.930664\n",
      "Train Epoch: 62 [105728/225000 (47%)] Loss: 14597.509766\n",
      "Train Epoch: 62 [107136/225000 (48%)] Loss: 14807.047852\n",
      "Train Epoch: 62 [108544/225000 (48%)] Loss: 14877.092773\n",
      "Train Epoch: 62 [109952/225000 (49%)] Loss: 15184.969727\n",
      "Train Epoch: 62 [111360/225000 (49%)] Loss: 14829.964844\n",
      "Train Epoch: 62 [112768/225000 (50%)] Loss: 14856.934570\n",
      "Train Epoch: 62 [114176/225000 (51%)] Loss: 15238.339844\n",
      "Train Epoch: 62 [115584/225000 (51%)] Loss: 15175.250000\n",
      "Train Epoch: 62 [116992/225000 (52%)] Loss: 14749.088867\n",
      "Train Epoch: 62 [118400/225000 (53%)] Loss: 15166.571289\n",
      "Train Epoch: 62 [119808/225000 (53%)] Loss: 14811.787109\n",
      "Train Epoch: 62 [121216/225000 (54%)] Loss: 15720.568359\n",
      "Train Epoch: 62 [122624/225000 (54%)] Loss: 15114.869141\n",
      "Train Epoch: 62 [124032/225000 (55%)] Loss: 15237.698242\n",
      "Train Epoch: 62 [125440/225000 (56%)] Loss: 15110.963867\n",
      "Train Epoch: 62 [126848/225000 (56%)] Loss: 14780.632812\n",
      "Train Epoch: 62 [128256/225000 (57%)] Loss: 15036.247070\n",
      "Train Epoch: 62 [129664/225000 (58%)] Loss: 15470.473633\n",
      "Train Epoch: 62 [131072/225000 (58%)] Loss: 14917.307617\n",
      "Train Epoch: 62 [132480/225000 (59%)] Loss: 14959.964844\n",
      "Train Epoch: 62 [133888/225000 (60%)] Loss: 14829.564453\n",
      "Train Epoch: 62 [135296/225000 (60%)] Loss: 14734.888672\n",
      "Train Epoch: 62 [136704/225000 (61%)] Loss: 15107.134766\n",
      "Train Epoch: 62 [138112/225000 (61%)] Loss: 15815.847656\n",
      "Train Epoch: 62 [139520/225000 (62%)] Loss: 15089.232422\n",
      "Train Epoch: 62 [140928/225000 (63%)] Loss: 15668.976562\n",
      "Train Epoch: 62 [142336/225000 (63%)] Loss: 14914.655273\n",
      "Train Epoch: 62 [143744/225000 (64%)] Loss: 15153.660156\n",
      "Train Epoch: 62 [145152/225000 (65%)] Loss: 14931.072266\n",
      "Train Epoch: 62 [146560/225000 (65%)] Loss: 14848.083008\n",
      "Train Epoch: 62 [147968/225000 (66%)] Loss: 14945.334961\n",
      "Train Epoch: 62 [149376/225000 (66%)] Loss: 15703.803711\n",
      "Train Epoch: 62 [150784/225000 (67%)] Loss: 15318.213867\n",
      "Train Epoch: 62 [152192/225000 (68%)] Loss: 15157.904297\n",
      "Train Epoch: 62 [153600/225000 (68%)] Loss: 15086.756836\n",
      "Train Epoch: 62 [155008/225000 (69%)] Loss: 14735.365234\n",
      "Train Epoch: 62 [156416/225000 (70%)] Loss: 15768.018555\n",
      "Train Epoch: 62 [157824/225000 (70%)] Loss: 14824.662109\n",
      "Train Epoch: 62 [159232/225000 (71%)] Loss: 14758.709961\n",
      "Train Epoch: 62 [160640/225000 (71%)] Loss: 15026.136719\n",
      "Train Epoch: 62 [162048/225000 (72%)] Loss: 15506.118164\n",
      "Train Epoch: 62 [163456/225000 (73%)] Loss: 14443.805664\n",
      "Train Epoch: 62 [164864/225000 (73%)] Loss: 15761.359375\n",
      "Train Epoch: 62 [166272/225000 (74%)] Loss: 15117.281250\n",
      "Train Epoch: 62 [167680/225000 (75%)] Loss: 15273.384766\n",
      "Train Epoch: 62 [169088/225000 (75%)] Loss: 14763.102539\n",
      "Train Epoch: 62 [170496/225000 (76%)] Loss: 14993.440430\n",
      "Train Epoch: 62 [171904/225000 (76%)] Loss: 14975.215820\n",
      "Train Epoch: 62 [173312/225000 (77%)] Loss: 15352.295898\n",
      "Train Epoch: 62 [174720/225000 (78%)] Loss: 14939.717773\n",
      "Train Epoch: 62 [176128/225000 (78%)] Loss: 14628.173828\n",
      "Train Epoch: 62 [177536/225000 (79%)] Loss: 15237.089844\n",
      "Train Epoch: 62 [178944/225000 (80%)] Loss: 14937.188477\n",
      "Train Epoch: 62 [180352/225000 (80%)] Loss: 14924.012695\n",
      "Train Epoch: 62 [181760/225000 (81%)] Loss: 14903.360352\n",
      "Train Epoch: 62 [183168/225000 (81%)] Loss: 14691.094727\n",
      "Train Epoch: 62 [184576/225000 (82%)] Loss: 14926.610352\n",
      "Train Epoch: 62 [185984/225000 (83%)] Loss: 15448.806641\n",
      "Train Epoch: 62 [187392/225000 (83%)] Loss: 15428.705078\n",
      "Train Epoch: 62 [188800/225000 (84%)] Loss: 14757.423828\n",
      "Train Epoch: 62 [190208/225000 (85%)] Loss: 15416.307617\n",
      "Train Epoch: 62 [191616/225000 (85%)] Loss: 15471.042969\n",
      "Train Epoch: 62 [193024/225000 (86%)] Loss: 14900.629883\n",
      "Train Epoch: 62 [194432/225000 (86%)] Loss: 14873.905273\n",
      "Train Epoch: 62 [195840/225000 (87%)] Loss: 15574.421875\n",
      "Train Epoch: 62 [197248/225000 (88%)] Loss: 14977.263672\n",
      "Train Epoch: 62 [198656/225000 (88%)] Loss: 14916.658203\n",
      "Train Epoch: 62 [200064/225000 (89%)] Loss: 16043.255859\n",
      "Train Epoch: 62 [201472/225000 (90%)] Loss: 14658.426758\n",
      "Train Epoch: 62 [202880/225000 (90%)] Loss: 15426.571289\n",
      "Train Epoch: 62 [204288/225000 (91%)] Loss: 14977.353516\n",
      "Train Epoch: 62 [205696/225000 (91%)] Loss: 15036.515625\n",
      "Train Epoch: 62 [207104/225000 (92%)] Loss: 15524.837891\n",
      "Train Epoch: 62 [208512/225000 (93%)] Loss: 14800.448242\n",
      "Train Epoch: 62 [209920/225000 (93%)] Loss: 15037.763672\n",
      "Train Epoch: 62 [211328/225000 (94%)] Loss: 15222.256836\n",
      "Train Epoch: 62 [212736/225000 (95%)] Loss: 14875.759766\n",
      "Train Epoch: 62 [214144/225000 (95%)] Loss: 15181.991211\n",
      "Train Epoch: 62 [215552/225000 (96%)] Loss: 14661.415039\n",
      "Train Epoch: 62 [216960/225000 (96%)] Loss: 14992.758789\n",
      "Train Epoch: 62 [218368/225000 (97%)] Loss: 14828.896484\n",
      "Train Epoch: 62 [219776/225000 (98%)] Loss: 14547.715820\n",
      "Train Epoch: 62 [221184/225000 (98%)] Loss: 15145.856445\n",
      "Train Epoch: 62 [222592/225000 (99%)] Loss: 15353.533203\n",
      "Train Epoch: 62 [224000/225000 (100%)] Loss: 15682.068359\n",
      "    epoch          : 62\n",
      "    loss           : 15076.186551212315\n",
      "    val_loss       : 15056.382257821\n",
      "Train Epoch: 63 [128/225000 (0%)] Loss: 14812.882812\n",
      "Train Epoch: 63 [1536/225000 (1%)] Loss: 14861.378906\n",
      "Train Epoch: 63 [2944/225000 (1%)] Loss: 15484.182617\n",
      "Train Epoch: 63 [4352/225000 (2%)] Loss: 14864.879883\n",
      "Train Epoch: 63 [5760/225000 (3%)] Loss: 15106.506836\n",
      "Train Epoch: 63 [7168/225000 (3%)] Loss: 15151.144531\n",
      "Train Epoch: 63 [8576/225000 (4%)] Loss: 15255.594727\n",
      "Train Epoch: 63 [9984/225000 (4%)] Loss: 15147.392578\n",
      "Train Epoch: 63 [11392/225000 (5%)] Loss: 15021.500977\n",
      "Train Epoch: 63 [12800/225000 (6%)] Loss: 15353.930664\n",
      "Train Epoch: 63 [14208/225000 (6%)] Loss: 15049.254883\n",
      "Train Epoch: 63 [15616/225000 (7%)] Loss: 15035.093750\n",
      "Train Epoch: 63 [17024/225000 (8%)] Loss: 15155.399414\n",
      "Train Epoch: 63 [18432/225000 (8%)] Loss: 14868.563477\n",
      "Train Epoch: 63 [19840/225000 (9%)] Loss: 14912.086914\n",
      "Train Epoch: 63 [21248/225000 (9%)] Loss: 15629.053711\n",
      "Train Epoch: 63 [22656/225000 (10%)] Loss: 14925.213867\n",
      "Train Epoch: 63 [24064/225000 (11%)] Loss: 15337.885742\n",
      "Train Epoch: 63 [25472/225000 (11%)] Loss: 15038.006836\n",
      "Train Epoch: 63 [26880/225000 (12%)] Loss: 14928.915039\n",
      "Train Epoch: 63 [28288/225000 (13%)] Loss: 15121.033203\n",
      "Train Epoch: 63 [29696/225000 (13%)] Loss: 14769.587891\n",
      "Train Epoch: 63 [31104/225000 (14%)] Loss: 15113.975586\n",
      "Train Epoch: 63 [32512/225000 (14%)] Loss: 15126.830078\n",
      "Train Epoch: 63 [33920/225000 (15%)] Loss: 15076.604492\n",
      "Train Epoch: 63 [35328/225000 (16%)] Loss: 14937.855469\n",
      "Train Epoch: 63 [36736/225000 (16%)] Loss: 15222.587891\n",
      "Train Epoch: 63 [38144/225000 (17%)] Loss: 15572.279297\n",
      "Train Epoch: 63 [39552/225000 (18%)] Loss: 15229.804688\n",
      "Train Epoch: 63 [40960/225000 (18%)] Loss: 15480.943359\n",
      "Train Epoch: 63 [42368/225000 (19%)] Loss: 15078.313477\n",
      "Train Epoch: 63 [43776/225000 (19%)] Loss: 14773.290039\n",
      "Train Epoch: 63 [45184/225000 (20%)] Loss: 14977.010742\n",
      "Train Epoch: 63 [46592/225000 (21%)] Loss: 14996.280273\n",
      "Train Epoch: 63 [48000/225000 (21%)] Loss: 14901.101562\n",
      "Train Epoch: 63 [49408/225000 (22%)] Loss: 15543.643555\n",
      "Train Epoch: 63 [50816/225000 (23%)] Loss: 15027.781250\n",
      "Train Epoch: 63 [52224/225000 (23%)] Loss: 15423.980469\n",
      "Train Epoch: 63 [53632/225000 (24%)] Loss: 14936.450195\n",
      "Train Epoch: 63 [55040/225000 (24%)] Loss: 15249.044922\n",
      "Train Epoch: 63 [56448/225000 (25%)] Loss: 14835.626953\n",
      "Train Epoch: 63 [57856/225000 (26%)] Loss: 14848.965820\n",
      "Train Epoch: 63 [59264/225000 (26%)] Loss: 15157.806641\n",
      "Train Epoch: 63 [60672/225000 (27%)] Loss: 15149.369141\n",
      "Train Epoch: 63 [62080/225000 (28%)] Loss: 16084.697266\n",
      "Train Epoch: 63 [63488/225000 (28%)] Loss: 15352.931641\n",
      "Train Epoch: 63 [64896/225000 (29%)] Loss: 15281.236328\n",
      "Train Epoch: 63 [66304/225000 (29%)] Loss: 15163.370117\n",
      "Train Epoch: 63 [67712/225000 (30%)] Loss: 15144.416016\n",
      "Train Epoch: 63 [69120/225000 (31%)] Loss: 15271.630859\n",
      "Train Epoch: 63 [70528/225000 (31%)] Loss: 14905.951172\n",
      "Train Epoch: 63 [71936/225000 (32%)] Loss: 14986.624023\n",
      "Train Epoch: 63 [73344/225000 (33%)] Loss: 15081.060547\n",
      "Train Epoch: 63 [74752/225000 (33%)] Loss: 14959.931641\n",
      "Train Epoch: 63 [76160/225000 (34%)] Loss: 15308.057617\n",
      "Train Epoch: 63 [77568/225000 (34%)] Loss: 14953.267578\n",
      "Train Epoch: 63 [78976/225000 (35%)] Loss: 15030.518555\n",
      "Train Epoch: 63 [80384/225000 (36%)] Loss: 15176.532227\n",
      "Train Epoch: 63 [81792/225000 (36%)] Loss: 14990.728516\n",
      "Train Epoch: 63 [83200/225000 (37%)] Loss: 14991.439453\n",
      "Train Epoch: 63 [84608/225000 (38%)] Loss: 15195.131836\n",
      "Train Epoch: 63 [86016/225000 (38%)] Loss: 15082.070312\n",
      "Train Epoch: 63 [87424/225000 (39%)] Loss: 14977.049805\n",
      "Train Epoch: 63 [88832/225000 (39%)] Loss: 15368.868164\n",
      "Train Epoch: 63 [90240/225000 (40%)] Loss: 15322.855469\n",
      "Train Epoch: 63 [91648/225000 (41%)] Loss: 15317.129883\n",
      "Train Epoch: 63 [93056/225000 (41%)] Loss: 15206.050781\n",
      "Train Epoch: 63 [94464/225000 (42%)] Loss: 14940.170898\n",
      "Train Epoch: 63 [95872/225000 (43%)] Loss: 15174.967773\n",
      "Train Epoch: 63 [97280/225000 (43%)] Loss: 15080.316406\n",
      "Train Epoch: 63 [98688/225000 (44%)] Loss: 15048.389648\n",
      "Train Epoch: 63 [100096/225000 (44%)] Loss: 15098.859375\n",
      "Train Epoch: 63 [101504/225000 (45%)] Loss: 14979.645508\n",
      "Train Epoch: 63 [102912/225000 (46%)] Loss: 14955.720703\n",
      "Train Epoch: 63 [104320/225000 (46%)] Loss: 14907.728516\n",
      "Train Epoch: 63 [105728/225000 (47%)] Loss: 14879.072266\n",
      "Train Epoch: 63 [107136/225000 (48%)] Loss: 15259.858398\n",
      "Train Epoch: 63 [108544/225000 (48%)] Loss: 15326.156250\n",
      "Train Epoch: 63 [109952/225000 (49%)] Loss: 15235.211914\n",
      "Train Epoch: 63 [111360/225000 (49%)] Loss: 14609.392578\n",
      "Train Epoch: 63 [112768/225000 (50%)] Loss: 14900.080078\n",
      "Train Epoch: 63 [114176/225000 (51%)] Loss: 15351.008789\n",
      "Train Epoch: 63 [115584/225000 (51%)] Loss: 15185.481445\n",
      "Train Epoch: 63 [116992/225000 (52%)] Loss: 14827.935547\n",
      "Train Epoch: 63 [118400/225000 (53%)] Loss: 14804.863281\n",
      "Train Epoch: 63 [119808/225000 (53%)] Loss: 15463.953125\n",
      "Train Epoch: 63 [121216/225000 (54%)] Loss: 15363.003906\n",
      "Train Epoch: 63 [122624/225000 (54%)] Loss: 15312.826172\n",
      "Train Epoch: 63 [124032/225000 (55%)] Loss: 14436.239258\n",
      "Train Epoch: 63 [125440/225000 (56%)] Loss: 15360.884766\n",
      "Train Epoch: 63 [126848/225000 (56%)] Loss: 15524.588867\n",
      "Train Epoch: 63 [128256/225000 (57%)] Loss: 15625.486328\n",
      "Train Epoch: 63 [129664/225000 (58%)] Loss: 14622.104492\n",
      "Train Epoch: 63 [131072/225000 (58%)] Loss: 14753.707031\n",
      "Train Epoch: 63 [132480/225000 (59%)] Loss: 15266.247070\n",
      "Train Epoch: 63 [133888/225000 (60%)] Loss: 15462.183594\n",
      "Train Epoch: 63 [135296/225000 (60%)] Loss: 14946.215820\n",
      "Train Epoch: 63 [136704/225000 (61%)] Loss: 15304.912109\n",
      "Train Epoch: 63 [138112/225000 (61%)] Loss: 15006.311523\n",
      "Train Epoch: 63 [139520/225000 (62%)] Loss: 15265.184570\n",
      "Train Epoch: 63 [140928/225000 (63%)] Loss: 14843.223633\n",
      "Train Epoch: 63 [142336/225000 (63%)] Loss: 15519.039062\n",
      "Train Epoch: 63 [143744/225000 (64%)] Loss: 15251.056641\n",
      "Train Epoch: 63 [145152/225000 (65%)] Loss: 14880.310547\n",
      "Train Epoch: 63 [146560/225000 (65%)] Loss: 14693.276367\n",
      "Train Epoch: 63 [147968/225000 (66%)] Loss: 14741.744141\n",
      "Train Epoch: 63 [149376/225000 (66%)] Loss: 15007.156250\n",
      "Train Epoch: 63 [150784/225000 (67%)] Loss: 15157.815430\n",
      "Train Epoch: 63 [152192/225000 (68%)] Loss: 14840.920898\n",
      "Train Epoch: 63 [153600/225000 (68%)] Loss: 15201.947266\n",
      "Train Epoch: 63 [155008/225000 (69%)] Loss: 15093.137695\n",
      "Train Epoch: 63 [156416/225000 (70%)] Loss: 14726.779297\n",
      "Train Epoch: 63 [157824/225000 (70%)] Loss: 14730.424805\n",
      "Train Epoch: 63 [159232/225000 (71%)] Loss: 15251.054688\n",
      "Train Epoch: 63 [160640/225000 (71%)] Loss: 14968.892578\n",
      "Train Epoch: 63 [162048/225000 (72%)] Loss: 15247.335938\n",
      "Train Epoch: 63 [163456/225000 (73%)] Loss: 15297.444336\n",
      "Train Epoch: 63 [164864/225000 (73%)] Loss: 15018.729492\n",
      "Train Epoch: 63 [166272/225000 (74%)] Loss: 15186.140625\n",
      "Train Epoch: 63 [167680/225000 (75%)] Loss: 15279.689453\n",
      "Train Epoch: 63 [169088/225000 (75%)] Loss: 14987.839844\n",
      "Train Epoch: 63 [170496/225000 (76%)] Loss: 14253.788086\n",
      "Train Epoch: 63 [171904/225000 (76%)] Loss: 14815.612305\n",
      "Train Epoch: 63 [173312/225000 (77%)] Loss: 14931.148438\n",
      "Train Epoch: 63 [174720/225000 (78%)] Loss: 15092.799805\n",
      "Train Epoch: 63 [176128/225000 (78%)] Loss: 14949.876953\n",
      "Train Epoch: 63 [177536/225000 (79%)] Loss: 14931.856445\n",
      "Train Epoch: 63 [178944/225000 (80%)] Loss: 15029.855469\n",
      "Train Epoch: 63 [180352/225000 (80%)] Loss: 15586.766602\n",
      "Train Epoch: 63 [181760/225000 (81%)] Loss: 14510.133789\n",
      "Train Epoch: 63 [183168/225000 (81%)] Loss: 14658.408203\n",
      "Train Epoch: 63 [184576/225000 (82%)] Loss: 15766.535156\n",
      "Train Epoch: 63 [185984/225000 (83%)] Loss: 15117.056641\n",
      "Train Epoch: 63 [187392/225000 (83%)] Loss: 14897.869141\n",
      "Train Epoch: 63 [188800/225000 (84%)] Loss: 14620.034180\n",
      "Train Epoch: 63 [190208/225000 (85%)] Loss: 15035.500000\n",
      "Train Epoch: 63 [191616/225000 (85%)] Loss: 14653.684570\n",
      "Train Epoch: 63 [193024/225000 (86%)] Loss: 15167.449219\n",
      "Train Epoch: 63 [194432/225000 (86%)] Loss: 15191.541992\n",
      "Train Epoch: 63 [195840/225000 (87%)] Loss: 15592.477539\n",
      "Train Epoch: 63 [197248/225000 (88%)] Loss: 14873.177734\n",
      "Train Epoch: 63 [198656/225000 (88%)] Loss: 14848.860352\n",
      "Train Epoch: 63 [200064/225000 (89%)] Loss: 15497.304688\n",
      "Train Epoch: 63 [201472/225000 (90%)] Loss: 15471.962891\n",
      "Train Epoch: 63 [202880/225000 (90%)] Loss: 15199.820312\n",
      "Train Epoch: 63 [204288/225000 (91%)] Loss: 15356.063477\n",
      "Train Epoch: 63 [205696/225000 (91%)] Loss: 15192.327148\n",
      "Train Epoch: 63 [207104/225000 (92%)] Loss: 15367.140625\n",
      "Train Epoch: 63 [208512/225000 (93%)] Loss: 15435.817383\n",
      "Train Epoch: 63 [209920/225000 (93%)] Loss: 15093.093750\n",
      "Train Epoch: 63 [211328/225000 (94%)] Loss: 15356.041016\n",
      "Train Epoch: 63 [212736/225000 (95%)] Loss: 15076.306641\n",
      "Train Epoch: 63 [214144/225000 (95%)] Loss: 15066.943359\n",
      "Train Epoch: 63 [215552/225000 (96%)] Loss: 14802.504883\n",
      "Train Epoch: 63 [216960/225000 (96%)] Loss: 14602.003906\n",
      "Train Epoch: 63 [218368/225000 (97%)] Loss: 14970.622070\n",
      "Train Epoch: 63 [219776/225000 (98%)] Loss: 15163.725586\n",
      "Train Epoch: 63 [221184/225000 (98%)] Loss: 14902.175781\n",
      "Train Epoch: 63 [222592/225000 (99%)] Loss: 14921.304688\n",
      "Train Epoch: 63 [224000/225000 (100%)] Loss: 15640.972656\n",
      "    epoch          : 63\n",
      "    loss           : 15075.6955380315\n",
      "    val_loss       : 15056.773865095054\n",
      "Train Epoch: 64 [128/225000 (0%)] Loss: 15171.612305\n",
      "Train Epoch: 64 [1536/225000 (1%)] Loss: 15094.370117\n",
      "Train Epoch: 64 [2944/225000 (1%)] Loss: 15265.273438\n",
      "Train Epoch: 64 [4352/225000 (2%)] Loss: 15207.797852\n",
      "Train Epoch: 64 [5760/225000 (3%)] Loss: 14867.596680\n",
      "Train Epoch: 64 [7168/225000 (3%)] Loss: 15228.040039\n",
      "Train Epoch: 64 [8576/225000 (4%)] Loss: 15056.741211\n",
      "Train Epoch: 64 [9984/225000 (4%)] Loss: 15619.464844\n",
      "Train Epoch: 64 [11392/225000 (5%)] Loss: 15105.524414\n",
      "Train Epoch: 64 [12800/225000 (6%)] Loss: 14867.857422\n",
      "Train Epoch: 64 [14208/225000 (6%)] Loss: 14854.722656\n",
      "Train Epoch: 64 [15616/225000 (7%)] Loss: 15246.158203\n",
      "Train Epoch: 64 [17024/225000 (8%)] Loss: 15162.843750\n",
      "Train Epoch: 64 [18432/225000 (8%)] Loss: 15206.090820\n",
      "Train Epoch: 64 [19840/225000 (9%)] Loss: 14821.530273\n",
      "Train Epoch: 64 [21248/225000 (9%)] Loss: 14879.534180\n",
      "Train Epoch: 64 [22656/225000 (10%)] Loss: 15088.149414\n",
      "Train Epoch: 64 [24064/225000 (11%)] Loss: 14897.898438\n",
      "Train Epoch: 64 [25472/225000 (11%)] Loss: 15314.043945\n",
      "Train Epoch: 64 [26880/225000 (12%)] Loss: 15351.389648\n",
      "Train Epoch: 64 [28288/225000 (13%)] Loss: 15076.864258\n",
      "Train Epoch: 64 [29696/225000 (13%)] Loss: 14720.184570\n",
      "Train Epoch: 64 [31104/225000 (14%)] Loss: 15070.465820\n",
      "Train Epoch: 64 [32512/225000 (14%)] Loss: 14742.924805\n",
      "Train Epoch: 64 [33920/225000 (15%)] Loss: 14813.954102\n",
      "Train Epoch: 64 [35328/225000 (16%)] Loss: 14705.482422\n",
      "Train Epoch: 64 [36736/225000 (16%)] Loss: 15156.578125\n",
      "Train Epoch: 64 [38144/225000 (17%)] Loss: 14855.041016\n",
      "Train Epoch: 64 [39552/225000 (18%)] Loss: 14957.788086\n",
      "Train Epoch: 64 [40960/225000 (18%)] Loss: 15143.346680\n",
      "Train Epoch: 64 [42368/225000 (19%)] Loss: 15555.901367\n",
      "Train Epoch: 64 [43776/225000 (19%)] Loss: 15031.279297\n",
      "Train Epoch: 64 [45184/225000 (20%)] Loss: 14810.957031\n",
      "Train Epoch: 64 [46592/225000 (21%)] Loss: 15894.155273\n",
      "Train Epoch: 64 [48000/225000 (21%)] Loss: 14628.164062\n",
      "Train Epoch: 64 [49408/225000 (22%)] Loss: 14776.344727\n",
      "Train Epoch: 64 [50816/225000 (23%)] Loss: 15485.416992\n",
      "Train Epoch: 64 [52224/225000 (23%)] Loss: 15499.393555\n",
      "Train Epoch: 64 [53632/225000 (24%)] Loss: 15404.831055\n",
      "Train Epoch: 64 [55040/225000 (24%)] Loss: 15056.768555\n",
      "Train Epoch: 64 [56448/225000 (25%)] Loss: 15497.625000\n",
      "Train Epoch: 64 [57856/225000 (26%)] Loss: 14833.154297\n",
      "Train Epoch: 64 [59264/225000 (26%)] Loss: 14902.787109\n",
      "Train Epoch: 64 [60672/225000 (27%)] Loss: 15534.087891\n",
      "Train Epoch: 64 [62080/225000 (28%)] Loss: 15044.504883\n",
      "Train Epoch: 64 [63488/225000 (28%)] Loss: 14545.862305\n",
      "Train Epoch: 64 [64896/225000 (29%)] Loss: 14950.242188\n",
      "Train Epoch: 64 [66304/225000 (29%)] Loss: 15348.304688\n",
      "Train Epoch: 64 [67712/225000 (30%)] Loss: 14720.487305\n",
      "Train Epoch: 64 [69120/225000 (31%)] Loss: 15426.471680\n",
      "Train Epoch: 64 [70528/225000 (31%)] Loss: 14771.130859\n",
      "Train Epoch: 64 [71936/225000 (32%)] Loss: 14937.965820\n",
      "Train Epoch: 64 [73344/225000 (33%)] Loss: 14770.007812\n",
      "Train Epoch: 64 [74752/225000 (33%)] Loss: 15100.123047\n",
      "Train Epoch: 64 [76160/225000 (34%)] Loss: 14958.572266\n",
      "Train Epoch: 64 [77568/225000 (34%)] Loss: 15045.265625\n",
      "Train Epoch: 64 [78976/225000 (35%)] Loss: 15456.795898\n",
      "Train Epoch: 64 [80384/225000 (36%)] Loss: 15068.772461\n",
      "Train Epoch: 64 [81792/225000 (36%)] Loss: 15092.940430\n",
      "Train Epoch: 64 [83200/225000 (37%)] Loss: 15131.120117\n",
      "Train Epoch: 64 [84608/225000 (38%)] Loss: 15222.136719\n",
      "Train Epoch: 64 [86016/225000 (38%)] Loss: 14965.358398\n",
      "Train Epoch: 64 [87424/225000 (39%)] Loss: 14983.634766\n",
      "Train Epoch: 64 [88832/225000 (39%)] Loss: 15183.890625\n",
      "Train Epoch: 64 [90240/225000 (40%)] Loss: 15022.494141\n",
      "Train Epoch: 64 [91648/225000 (41%)] Loss: 15826.076172\n",
      "Train Epoch: 64 [93056/225000 (41%)] Loss: 15357.802734\n",
      "Train Epoch: 64 [94464/225000 (42%)] Loss: 15289.513672\n",
      "Train Epoch: 64 [95872/225000 (43%)] Loss: 15243.286133\n",
      "Train Epoch: 64 [97280/225000 (43%)] Loss: 15157.426758\n",
      "Train Epoch: 64 [98688/225000 (44%)] Loss: 15707.343750\n",
      "Train Epoch: 64 [100096/225000 (44%)] Loss: 15345.064453\n",
      "Train Epoch: 64 [101504/225000 (45%)] Loss: 15226.214844\n",
      "Train Epoch: 64 [102912/225000 (46%)] Loss: 15005.674805\n",
      "Train Epoch: 64 [104320/225000 (46%)] Loss: 14981.824219\n",
      "Train Epoch: 64 [105728/225000 (47%)] Loss: 15153.322266\n",
      "Train Epoch: 64 [107136/225000 (48%)] Loss: 15147.680664\n",
      "Train Epoch: 64 [108544/225000 (48%)] Loss: 15024.181641\n",
      "Train Epoch: 64 [109952/225000 (49%)] Loss: 14925.853516\n",
      "Train Epoch: 64 [111360/225000 (49%)] Loss: 15087.989258\n",
      "Train Epoch: 64 [112768/225000 (50%)] Loss: 14650.127930\n",
      "Train Epoch: 64 [114176/225000 (51%)] Loss: 14827.122070\n",
      "Train Epoch: 64 [115584/225000 (51%)] Loss: 15093.837891\n",
      "Train Epoch: 64 [116992/225000 (52%)] Loss: 15306.677734\n",
      "Train Epoch: 64 [118400/225000 (53%)] Loss: 15391.006836\n",
      "Train Epoch: 64 [119808/225000 (53%)] Loss: 14853.434570\n",
      "Train Epoch: 64 [121216/225000 (54%)] Loss: 15417.996094\n",
      "Train Epoch: 64 [122624/225000 (54%)] Loss: 15088.658203\n",
      "Train Epoch: 64 [124032/225000 (55%)] Loss: 15090.962891\n",
      "Train Epoch: 64 [125440/225000 (56%)] Loss: 15123.044922\n",
      "Train Epoch: 64 [126848/225000 (56%)] Loss: 14782.379883\n",
      "Train Epoch: 64 [128256/225000 (57%)] Loss: 15298.791992\n",
      "Train Epoch: 64 [129664/225000 (58%)] Loss: 15259.978516\n",
      "Train Epoch: 64 [131072/225000 (58%)] Loss: 15279.825195\n",
      "Train Epoch: 64 [132480/225000 (59%)] Loss: 14737.208008\n",
      "Train Epoch: 64 [133888/225000 (60%)] Loss: 15038.853516\n",
      "Train Epoch: 64 [135296/225000 (60%)] Loss: 15054.978516\n",
      "Train Epoch: 64 [136704/225000 (61%)] Loss: 15006.490234\n",
      "Train Epoch: 64 [138112/225000 (61%)] Loss: 15202.856445\n",
      "Train Epoch: 64 [139520/225000 (62%)] Loss: 14724.008789\n",
      "Train Epoch: 64 [140928/225000 (63%)] Loss: 14548.317383\n",
      "Train Epoch: 64 [142336/225000 (63%)] Loss: 14907.841797\n",
      "Train Epoch: 64 [143744/225000 (64%)] Loss: 15112.566406\n",
      "Train Epoch: 64 [145152/225000 (65%)] Loss: 15243.874023\n",
      "Train Epoch: 64 [146560/225000 (65%)] Loss: 15108.530273\n",
      "Train Epoch: 64 [147968/225000 (66%)] Loss: 14985.197266\n",
      "Train Epoch: 64 [149376/225000 (66%)] Loss: 15552.275391\n",
      "Train Epoch: 64 [150784/225000 (67%)] Loss: 15231.956055\n",
      "Train Epoch: 64 [152192/225000 (68%)] Loss: 14720.644531\n",
      "Train Epoch: 64 [153600/225000 (68%)] Loss: 14970.512695\n",
      "Train Epoch: 64 [155008/225000 (69%)] Loss: 15196.112305\n",
      "Train Epoch: 64 [156416/225000 (70%)] Loss: 15434.828125\n",
      "Train Epoch: 64 [157824/225000 (70%)] Loss: 15191.500977\n",
      "Train Epoch: 64 [159232/225000 (71%)] Loss: 14679.565430\n",
      "Train Epoch: 64 [160640/225000 (71%)] Loss: 14832.190430\n",
      "Train Epoch: 64 [162048/225000 (72%)] Loss: 15503.820312\n",
      "Train Epoch: 64 [163456/225000 (73%)] Loss: 15213.335938\n",
      "Train Epoch: 64 [164864/225000 (73%)] Loss: 14906.451172\n",
      "Train Epoch: 64 [166272/225000 (74%)] Loss: 15108.852539\n",
      "Train Epoch: 64 [167680/225000 (75%)] Loss: 14949.225586\n",
      "Train Epoch: 64 [169088/225000 (75%)] Loss: 14833.577148\n",
      "Train Epoch: 64 [170496/225000 (76%)] Loss: 14972.743164\n",
      "Train Epoch: 64 [171904/225000 (76%)] Loss: 15322.299805\n",
      "Train Epoch: 64 [173312/225000 (77%)] Loss: 14980.167969\n",
      "Train Epoch: 64 [174720/225000 (78%)] Loss: 15116.835938\n",
      "Train Epoch: 64 [176128/225000 (78%)] Loss: 14800.666992\n",
      "Train Epoch: 64 [177536/225000 (79%)] Loss: 15174.047852\n",
      "Train Epoch: 64 [178944/225000 (80%)] Loss: 14845.305664\n",
      "Train Epoch: 64 [180352/225000 (80%)] Loss: 14934.981445\n",
      "Train Epoch: 64 [181760/225000 (81%)] Loss: 15114.602539\n",
      "Train Epoch: 64 [183168/225000 (81%)] Loss: 15314.676758\n",
      "Train Epoch: 64 [184576/225000 (82%)] Loss: 15278.317383\n",
      "Train Epoch: 64 [185984/225000 (83%)] Loss: 14871.067383\n",
      "Train Epoch: 64 [187392/225000 (83%)] Loss: 15690.328125\n",
      "Train Epoch: 64 [188800/225000 (84%)] Loss: 15074.439453\n",
      "Train Epoch: 64 [190208/225000 (85%)] Loss: 15563.833008\n",
      "Train Epoch: 64 [191616/225000 (85%)] Loss: 15493.705078\n",
      "Train Epoch: 64 [193024/225000 (86%)] Loss: 15016.522461\n",
      "Train Epoch: 64 [194432/225000 (86%)] Loss: 14884.212891\n",
      "Train Epoch: 64 [195840/225000 (87%)] Loss: 15748.319336\n",
      "Train Epoch: 64 [197248/225000 (88%)] Loss: 14590.867188\n",
      "Train Epoch: 64 [198656/225000 (88%)] Loss: 14755.873047\n",
      "Train Epoch: 64 [200064/225000 (89%)] Loss: 15089.280273\n",
      "Train Epoch: 64 [201472/225000 (90%)] Loss: 15097.043945\n",
      "Train Epoch: 64 [202880/225000 (90%)] Loss: 15448.500977\n",
      "Train Epoch: 64 [204288/225000 (91%)] Loss: 15080.390625\n",
      "Train Epoch: 64 [205696/225000 (91%)] Loss: 15199.647461\n",
      "Train Epoch: 64 [207104/225000 (92%)] Loss: 15046.644531\n",
      "Train Epoch: 64 [208512/225000 (93%)] Loss: 15043.136719\n",
      "Train Epoch: 64 [209920/225000 (93%)] Loss: 15331.527344\n",
      "Train Epoch: 64 [211328/225000 (94%)] Loss: 15243.633789\n",
      "Train Epoch: 64 [212736/225000 (95%)] Loss: 15148.833008\n",
      "Train Epoch: 64 [214144/225000 (95%)] Loss: 15734.506836\n",
      "Train Epoch: 64 [215552/225000 (96%)] Loss: 15303.089844\n",
      "Train Epoch: 64 [216960/225000 (96%)] Loss: 15592.223633\n",
      "Train Epoch: 64 [218368/225000 (97%)] Loss: 14885.092773\n",
      "Train Epoch: 64 [219776/225000 (98%)] Loss: 15291.856445\n",
      "Train Epoch: 64 [221184/225000 (98%)] Loss: 14960.817383\n",
      "Train Epoch: 64 [222592/225000 (99%)] Loss: 14731.597656\n",
      "Train Epoch: 64 [224000/225000 (100%)] Loss: 14939.973633\n",
      "    epoch          : 64\n",
      "    loss           : 15074.42359370556\n",
      "    val_loss       : 15062.962978007083\n",
      "Train Epoch: 65 [128/225000 (0%)] Loss: 15034.480469\n",
      "Train Epoch: 65 [1536/225000 (1%)] Loss: 15201.629883\n",
      "Train Epoch: 65 [2944/225000 (1%)] Loss: 14739.691406\n",
      "Train Epoch: 65 [4352/225000 (2%)] Loss: 15199.334961\n",
      "Train Epoch: 65 [5760/225000 (3%)] Loss: 15007.850586\n",
      "Train Epoch: 65 [7168/225000 (3%)] Loss: 15331.742188\n",
      "Train Epoch: 65 [8576/225000 (4%)] Loss: 14795.198242\n",
      "Train Epoch: 65 [9984/225000 (4%)] Loss: 15517.360352\n",
      "Train Epoch: 65 [11392/225000 (5%)] Loss: 14796.270508\n",
      "Train Epoch: 65 [12800/225000 (6%)] Loss: 15029.681641\n",
      "Train Epoch: 65 [14208/225000 (6%)] Loss: 14896.547852\n",
      "Train Epoch: 65 [15616/225000 (7%)] Loss: 15408.978516\n",
      "Train Epoch: 65 [17024/225000 (8%)] Loss: 15152.774414\n",
      "Train Epoch: 65 [18432/225000 (8%)] Loss: 14489.766602\n",
      "Train Epoch: 65 [19840/225000 (9%)] Loss: 15311.750000\n",
      "Train Epoch: 65 [21248/225000 (9%)] Loss: 14968.559570\n",
      "Train Epoch: 65 [22656/225000 (10%)] Loss: 15246.641602\n",
      "Train Epoch: 65 [24064/225000 (11%)] Loss: 15103.492188\n",
      "Train Epoch: 65 [25472/225000 (11%)] Loss: 14939.156250\n",
      "Train Epoch: 65 [26880/225000 (12%)] Loss: 15233.675781\n",
      "Train Epoch: 65 [28288/225000 (13%)] Loss: 14771.755859\n",
      "Train Epoch: 65 [29696/225000 (13%)] Loss: 15252.792969\n",
      "Train Epoch: 65 [31104/225000 (14%)] Loss: 14887.582031\n",
      "Train Epoch: 65 [32512/225000 (14%)] Loss: 14788.202148\n",
      "Train Epoch: 65 [33920/225000 (15%)] Loss: 15012.831055\n",
      "Train Epoch: 65 [35328/225000 (16%)] Loss: 14967.556641\n",
      "Train Epoch: 65 [36736/225000 (16%)] Loss: 15460.732422\n",
      "Train Epoch: 65 [38144/225000 (17%)] Loss: 15087.005859\n",
      "Train Epoch: 65 [39552/225000 (18%)] Loss: 14882.484375\n",
      "Train Epoch: 65 [40960/225000 (18%)] Loss: 14975.914062\n",
      "Train Epoch: 65 [42368/225000 (19%)] Loss: 15047.793945\n",
      "Train Epoch: 65 [43776/225000 (19%)] Loss: 15267.231445\n",
      "Train Epoch: 65 [45184/225000 (20%)] Loss: 15055.669922\n",
      "Train Epoch: 65 [46592/225000 (21%)] Loss: 14722.869141\n",
      "Train Epoch: 65 [48000/225000 (21%)] Loss: 15131.216797\n",
      "Train Epoch: 65 [49408/225000 (22%)] Loss: 14929.052734\n",
      "Train Epoch: 65 [50816/225000 (23%)] Loss: 15550.694336\n",
      "Train Epoch: 65 [52224/225000 (23%)] Loss: 15140.667969\n",
      "Train Epoch: 65 [53632/225000 (24%)] Loss: 14995.544922\n",
      "Train Epoch: 65 [55040/225000 (24%)] Loss: 14500.856445\n",
      "Train Epoch: 65 [56448/225000 (25%)] Loss: 14935.360352\n",
      "Train Epoch: 65 [57856/225000 (26%)] Loss: 14983.834961\n",
      "Train Epoch: 65 [59264/225000 (26%)] Loss: 14851.933594\n",
      "Train Epoch: 65 [60672/225000 (27%)] Loss: 15301.330078\n",
      "Train Epoch: 65 [62080/225000 (28%)] Loss: 15450.076172\n",
      "Train Epoch: 65 [63488/225000 (28%)] Loss: 15053.172852\n",
      "Train Epoch: 65 [64896/225000 (29%)] Loss: 14994.995117\n",
      "Train Epoch: 65 [66304/225000 (29%)] Loss: 15611.690430\n",
      "Train Epoch: 65 [67712/225000 (30%)] Loss: 14948.047852\n",
      "Train Epoch: 65 [69120/225000 (31%)] Loss: 15147.022461\n",
      "Train Epoch: 65 [70528/225000 (31%)] Loss: 15071.073242\n",
      "Train Epoch: 65 [71936/225000 (32%)] Loss: 14767.505859\n",
      "Train Epoch: 65 [73344/225000 (33%)] Loss: 15284.873047\n",
      "Train Epoch: 65 [74752/225000 (33%)] Loss: 14805.813477\n",
      "Train Epoch: 65 [76160/225000 (34%)] Loss: 14968.281250\n",
      "Train Epoch: 65 [77568/225000 (34%)] Loss: 14776.495117\n",
      "Train Epoch: 65 [78976/225000 (35%)] Loss: 15179.442383\n",
      "Train Epoch: 65 [80384/225000 (36%)] Loss: 15411.958984\n",
      "Train Epoch: 65 [81792/225000 (36%)] Loss: 14986.709961\n",
      "Train Epoch: 65 [83200/225000 (37%)] Loss: 15205.644531\n",
      "Train Epoch: 65 [84608/225000 (38%)] Loss: 14623.195312\n",
      "Train Epoch: 65 [86016/225000 (38%)] Loss: 14881.002930\n",
      "Train Epoch: 65 [87424/225000 (39%)] Loss: 15186.723633\n",
      "Train Epoch: 65 [88832/225000 (39%)] Loss: 14697.533203\n",
      "Train Epoch: 65 [90240/225000 (40%)] Loss: 15087.668945\n",
      "Train Epoch: 65 [91648/225000 (41%)] Loss: 15174.759766\n",
      "Train Epoch: 65 [93056/225000 (41%)] Loss: 15180.464844\n",
      "Train Epoch: 65 [94464/225000 (42%)] Loss: 14902.923828\n",
      "Train Epoch: 65 [95872/225000 (43%)] Loss: 15421.760742\n",
      "Train Epoch: 65 [97280/225000 (43%)] Loss: 14867.659180\n",
      "Train Epoch: 65 [98688/225000 (44%)] Loss: 15110.673828\n",
      "Train Epoch: 65 [100096/225000 (44%)] Loss: 15217.804688\n",
      "Train Epoch: 65 [101504/225000 (45%)] Loss: 15216.916992\n",
      "Train Epoch: 65 [102912/225000 (46%)] Loss: 14983.422852\n",
      "Train Epoch: 65 [104320/225000 (46%)] Loss: 15106.012695\n",
      "Train Epoch: 65 [105728/225000 (47%)] Loss: 14703.114258\n",
      "Train Epoch: 65 [107136/225000 (48%)] Loss: 15016.538086\n",
      "Train Epoch: 65 [108544/225000 (48%)] Loss: 15315.202148\n",
      "Train Epoch: 65 [109952/225000 (49%)] Loss: 15319.865234\n",
      "Train Epoch: 65 [111360/225000 (49%)] Loss: 15080.721680\n",
      "Train Epoch: 65 [112768/225000 (50%)] Loss: 14684.353516\n",
      "Train Epoch: 65 [114176/225000 (51%)] Loss: 14886.878906\n",
      "Train Epoch: 65 [115584/225000 (51%)] Loss: 15188.838867\n",
      "Train Epoch: 65 [116992/225000 (52%)] Loss: 14607.949219\n",
      "Train Epoch: 65 [118400/225000 (53%)] Loss: 15234.745117\n",
      "Train Epoch: 65 [119808/225000 (53%)] Loss: 15185.640625\n",
      "Train Epoch: 65 [121216/225000 (54%)] Loss: 15005.671875\n",
      "Train Epoch: 65 [122624/225000 (54%)] Loss: 15557.254883\n",
      "Train Epoch: 65 [124032/225000 (55%)] Loss: 15154.794922\n",
      "Train Epoch: 65 [125440/225000 (56%)] Loss: 15220.514648\n",
      "Train Epoch: 65 [126848/225000 (56%)] Loss: 14632.816406\n",
      "Train Epoch: 65 [128256/225000 (57%)] Loss: 14872.181641\n",
      "Train Epoch: 65 [129664/225000 (58%)] Loss: 14834.362305\n",
      "Train Epoch: 65 [131072/225000 (58%)] Loss: 15267.853516\n",
      "Train Epoch: 65 [132480/225000 (59%)] Loss: 15096.142578\n",
      "Train Epoch: 65 [133888/225000 (60%)] Loss: 14844.578125\n",
      "Train Epoch: 65 [135296/225000 (60%)] Loss: 14933.335938\n",
      "Train Epoch: 65 [136704/225000 (61%)] Loss: 15057.175781\n",
      "Train Epoch: 65 [138112/225000 (61%)] Loss: 15361.046875\n",
      "Train Epoch: 65 [139520/225000 (62%)] Loss: 15144.204102\n",
      "Train Epoch: 65 [140928/225000 (63%)] Loss: 15643.509766\n",
      "Train Epoch: 65 [142336/225000 (63%)] Loss: 15211.850586\n",
      "Train Epoch: 65 [143744/225000 (64%)] Loss: 15539.935547\n",
      "Train Epoch: 65 [145152/225000 (65%)] Loss: 14934.770508\n",
      "Train Epoch: 65 [146560/225000 (65%)] Loss: 15145.205078\n",
      "Train Epoch: 65 [147968/225000 (66%)] Loss: 15356.109375\n",
      "Train Epoch: 65 [149376/225000 (66%)] Loss: 14974.177734\n",
      "Train Epoch: 65 [150784/225000 (67%)] Loss: 15172.587891\n",
      "Train Epoch: 65 [152192/225000 (68%)] Loss: 15334.497070\n",
      "Train Epoch: 65 [153600/225000 (68%)] Loss: 15093.949219\n",
      "Train Epoch: 65 [155008/225000 (69%)] Loss: 15268.291992\n",
      "Train Epoch: 65 [156416/225000 (70%)] Loss: 15121.243164\n",
      "Train Epoch: 65 [157824/225000 (70%)] Loss: 15423.725586\n",
      "Train Epoch: 65 [159232/225000 (71%)] Loss: 15261.232422\n",
      "Train Epoch: 65 [160640/225000 (71%)] Loss: 15081.050781\n",
      "Train Epoch: 65 [162048/225000 (72%)] Loss: 15058.794922\n",
      "Train Epoch: 65 [163456/225000 (73%)] Loss: 15108.986328\n",
      "Train Epoch: 65 [164864/225000 (73%)] Loss: 15200.404297\n",
      "Train Epoch: 65 [166272/225000 (74%)] Loss: 14869.582031\n",
      "Train Epoch: 65 [167680/225000 (75%)] Loss: 14885.212891\n",
      "Train Epoch: 65 [169088/225000 (75%)] Loss: 15384.458008\n",
      "Train Epoch: 65 [170496/225000 (76%)] Loss: 15052.725586\n",
      "Train Epoch: 65 [171904/225000 (76%)] Loss: 15664.431641\n",
      "Train Epoch: 65 [173312/225000 (77%)] Loss: 14808.181641\n",
      "Train Epoch: 65 [174720/225000 (78%)] Loss: 14921.540039\n",
      "Train Epoch: 65 [176128/225000 (78%)] Loss: 15078.123047\n",
      "Train Epoch: 65 [177536/225000 (79%)] Loss: 15075.849609\n",
      "Train Epoch: 65 [178944/225000 (80%)] Loss: 15084.666992\n",
      "Train Epoch: 65 [180352/225000 (80%)] Loss: 15060.416016\n",
      "Train Epoch: 65 [181760/225000 (81%)] Loss: 15086.787109\n",
      "Train Epoch: 65 [183168/225000 (81%)] Loss: 15360.657227\n",
      "Train Epoch: 65 [184576/225000 (82%)] Loss: 14717.567383\n",
      "Train Epoch: 65 [185984/225000 (83%)] Loss: 15367.871094\n",
      "Train Epoch: 65 [187392/225000 (83%)] Loss: 14780.371094\n",
      "Train Epoch: 65 [188800/225000 (84%)] Loss: 14930.587891\n",
      "Train Epoch: 65 [190208/225000 (85%)] Loss: 15647.365234\n",
      "Train Epoch: 65 [191616/225000 (85%)] Loss: 15063.246094\n",
      "Train Epoch: 65 [193024/225000 (86%)] Loss: 15709.480469\n",
      "Train Epoch: 65 [194432/225000 (86%)] Loss: 15779.937500\n",
      "Train Epoch: 65 [195840/225000 (87%)] Loss: 15195.304688\n",
      "Train Epoch: 65 [197248/225000 (88%)] Loss: 14758.707031\n",
      "Train Epoch: 65 [198656/225000 (88%)] Loss: 14693.302734\n",
      "Train Epoch: 65 [200064/225000 (89%)] Loss: 14833.584961\n",
      "Train Epoch: 65 [201472/225000 (90%)] Loss: 15054.347656\n",
      "Train Epoch: 65 [202880/225000 (90%)] Loss: 15178.029297\n",
      "Train Epoch: 65 [204288/225000 (91%)] Loss: 15187.155273\n",
      "Train Epoch: 65 [205696/225000 (91%)] Loss: 15385.105469\n",
      "Train Epoch: 65 [207104/225000 (92%)] Loss: 15288.791016\n",
      "Train Epoch: 65 [208512/225000 (93%)] Loss: 15317.956055\n",
      "Train Epoch: 65 [209920/225000 (93%)] Loss: 14709.058594\n",
      "Train Epoch: 65 [211328/225000 (94%)] Loss: 15010.854492\n",
      "Train Epoch: 65 [212736/225000 (95%)] Loss: 14428.847656\n",
      "Train Epoch: 65 [214144/225000 (95%)] Loss: 15116.461914\n",
      "Train Epoch: 65 [215552/225000 (96%)] Loss: 15490.328125\n",
      "Train Epoch: 65 [216960/225000 (96%)] Loss: 14938.267578\n",
      "Train Epoch: 65 [218368/225000 (97%)] Loss: 14809.499023\n",
      "Train Epoch: 65 [219776/225000 (98%)] Loss: 15451.497070\n",
      "Train Epoch: 65 [221184/225000 (98%)] Loss: 15278.446289\n",
      "Train Epoch: 65 [222592/225000 (99%)] Loss: 15261.511719\n",
      "Train Epoch: 65 [224000/225000 (100%)] Loss: 14829.175781\n",
      "    epoch          : 65\n",
      "    loss           : 15077.03387027606\n",
      "    val_loss       : 15056.638274227325\n",
      "Train Epoch: 66 [128/225000 (0%)] Loss: 14645.380859\n",
      "Train Epoch: 66 [1536/225000 (1%)] Loss: 15119.016602\n",
      "Train Epoch: 66 [2944/225000 (1%)] Loss: 15261.762695\n",
      "Train Epoch: 66 [4352/225000 (2%)] Loss: 15244.581055\n",
      "Train Epoch: 66 [5760/225000 (3%)] Loss: 14840.458984\n",
      "Train Epoch: 66 [7168/225000 (3%)] Loss: 15192.912109\n",
      "Train Epoch: 66 [8576/225000 (4%)] Loss: 15093.549805\n",
      "Train Epoch: 66 [9984/225000 (4%)] Loss: 15423.667969\n",
      "Train Epoch: 66 [11392/225000 (5%)] Loss: 15420.126953\n",
      "Train Epoch: 66 [12800/225000 (6%)] Loss: 15135.413086\n",
      "Train Epoch: 66 [14208/225000 (6%)] Loss: 14804.749023\n",
      "Train Epoch: 66 [15616/225000 (7%)] Loss: 14967.281250\n",
      "Train Epoch: 66 [17024/225000 (8%)] Loss: 15530.708984\n",
      "Train Epoch: 66 [18432/225000 (8%)] Loss: 15336.614258\n",
      "Train Epoch: 66 [19840/225000 (9%)] Loss: 14864.359375\n",
      "Train Epoch: 66 [21248/225000 (9%)] Loss: 15132.926758\n",
      "Train Epoch: 66 [22656/225000 (10%)] Loss: 15249.783203\n",
      "Train Epoch: 66 [24064/225000 (11%)] Loss: 15293.112305\n",
      "Train Epoch: 66 [25472/225000 (11%)] Loss: 15016.571289\n",
      "Train Epoch: 66 [26880/225000 (12%)] Loss: 15189.455078\n",
      "Train Epoch: 66 [28288/225000 (13%)] Loss: 14977.271484\n",
      "Train Epoch: 66 [29696/225000 (13%)] Loss: 15198.427734\n",
      "Train Epoch: 66 [31104/225000 (14%)] Loss: 14903.775391\n",
      "Train Epoch: 66 [32512/225000 (14%)] Loss: 14828.322266\n",
      "Train Epoch: 66 [33920/225000 (15%)] Loss: 15309.664062\n",
      "Train Epoch: 66 [35328/225000 (16%)] Loss: 15160.958008\n",
      "Train Epoch: 66 [36736/225000 (16%)] Loss: 15080.316406\n",
      "Train Epoch: 66 [38144/225000 (17%)] Loss: 15293.410156\n",
      "Train Epoch: 66 [39552/225000 (18%)] Loss: 14866.992188\n",
      "Train Epoch: 66 [40960/225000 (18%)] Loss: 15019.939453\n",
      "Train Epoch: 66 [42368/225000 (19%)] Loss: 15271.715820\n",
      "Train Epoch: 66 [43776/225000 (19%)] Loss: 15035.688477\n",
      "Train Epoch: 66 [45184/225000 (20%)] Loss: 14825.166992\n",
      "Train Epoch: 66 [46592/225000 (21%)] Loss: 14956.125000\n",
      "Train Epoch: 66 [48000/225000 (21%)] Loss: 15432.026367\n",
      "Train Epoch: 66 [49408/225000 (22%)] Loss: 15002.756836\n",
      "Train Epoch: 66 [50816/225000 (23%)] Loss: 15181.364258\n",
      "Train Epoch: 66 [52224/225000 (23%)] Loss: 15368.019531\n",
      "Train Epoch: 66 [53632/225000 (24%)] Loss: 15608.499023\n",
      "Train Epoch: 66 [55040/225000 (24%)] Loss: 14868.520508\n",
      "Train Epoch: 66 [56448/225000 (25%)] Loss: 15250.572266\n",
      "Train Epoch: 66 [57856/225000 (26%)] Loss: 14664.240234\n",
      "Train Epoch: 66 [59264/225000 (26%)] Loss: 15480.177734\n",
      "Train Epoch: 66 [60672/225000 (27%)] Loss: 15410.581055\n",
      "Train Epoch: 66 [62080/225000 (28%)] Loss: 15165.325195\n",
      "Train Epoch: 66 [63488/225000 (28%)] Loss: 15299.830078\n",
      "Train Epoch: 66 [64896/225000 (29%)] Loss: 14746.142578\n",
      "Train Epoch: 66 [66304/225000 (29%)] Loss: 15389.219727\n",
      "Train Epoch: 66 [67712/225000 (30%)] Loss: 15144.795898\n",
      "Train Epoch: 66 [69120/225000 (31%)] Loss: 15065.216797\n",
      "Train Epoch: 66 [70528/225000 (31%)] Loss: 14821.784180\n",
      "Train Epoch: 66 [71936/225000 (32%)] Loss: 14951.192383\n",
      "Train Epoch: 66 [73344/225000 (33%)] Loss: 15128.809570\n",
      "Train Epoch: 66 [74752/225000 (33%)] Loss: 15083.513672\n",
      "Train Epoch: 66 [76160/225000 (34%)] Loss: 15425.641602\n",
      "Train Epoch: 66 [77568/225000 (34%)] Loss: 14959.341797\n",
      "Train Epoch: 66 [78976/225000 (35%)] Loss: 14791.927734\n",
      "Train Epoch: 66 [80384/225000 (36%)] Loss: 15092.393555\n",
      "Train Epoch: 66 [81792/225000 (36%)] Loss: 15246.648438\n",
      "Train Epoch: 66 [83200/225000 (37%)] Loss: 15209.285156\n",
      "Train Epoch: 66 [84608/225000 (38%)] Loss: 15633.368164\n",
      "Train Epoch: 66 [86016/225000 (38%)] Loss: 14788.107422\n",
      "Train Epoch: 66 [87424/225000 (39%)] Loss: 14883.609375\n",
      "Train Epoch: 66 [88832/225000 (39%)] Loss: 15560.537109\n",
      "Train Epoch: 66 [90240/225000 (40%)] Loss: 14984.430664\n",
      "Train Epoch: 66 [91648/225000 (41%)] Loss: 15054.066406\n",
      "Train Epoch: 66 [93056/225000 (41%)] Loss: 15238.357422\n",
      "Train Epoch: 66 [94464/225000 (42%)] Loss: 14741.907227\n",
      "Train Epoch: 66 [95872/225000 (43%)] Loss: 14756.079102\n",
      "Train Epoch: 66 [97280/225000 (43%)] Loss: 15091.833008\n",
      "Train Epoch: 66 [98688/225000 (44%)] Loss: 15260.441406\n",
      "Train Epoch: 66 [100096/225000 (44%)] Loss: 14807.694336\n",
      "Train Epoch: 66 [101504/225000 (45%)] Loss: 15433.273438\n",
      "Train Epoch: 66 [102912/225000 (46%)] Loss: 14992.861328\n",
      "Train Epoch: 66 [104320/225000 (46%)] Loss: 15218.094727\n",
      "Train Epoch: 66 [105728/225000 (47%)] Loss: 15085.519531\n",
      "Train Epoch: 66 [107136/225000 (48%)] Loss: 14676.849609\n",
      "Train Epoch: 66 [108544/225000 (48%)] Loss: 14606.231445\n",
      "Train Epoch: 66 [109952/225000 (49%)] Loss: 15273.961914\n",
      "Train Epoch: 66 [111360/225000 (49%)] Loss: 14858.367188\n",
      "Train Epoch: 66 [112768/225000 (50%)] Loss: 15224.151367\n",
      "Train Epoch: 66 [114176/225000 (51%)] Loss: 14993.521484\n",
      "Train Epoch: 66 [115584/225000 (51%)] Loss: 15000.590820\n",
      "Train Epoch: 66 [116992/225000 (52%)] Loss: 15340.330078\n",
      "Train Epoch: 66 [118400/225000 (53%)] Loss: 15365.993164\n",
      "Train Epoch: 66 [119808/225000 (53%)] Loss: 15005.794922\n",
      "Train Epoch: 66 [121216/225000 (54%)] Loss: 14982.224609\n",
      "Train Epoch: 66 [122624/225000 (54%)] Loss: 16022.653320\n",
      "Train Epoch: 66 [124032/225000 (55%)] Loss: 15358.005859\n",
      "Train Epoch: 66 [125440/225000 (56%)] Loss: 15395.168945\n",
      "Train Epoch: 66 [126848/225000 (56%)] Loss: 14970.507812\n",
      "Train Epoch: 66 [128256/225000 (57%)] Loss: 14849.541992\n",
      "Train Epoch: 66 [129664/225000 (58%)] Loss: 14894.028320\n",
      "Train Epoch: 66 [131072/225000 (58%)] Loss: 14835.048828\n",
      "Train Epoch: 66 [132480/225000 (59%)] Loss: 14829.160156\n",
      "Train Epoch: 66 [133888/225000 (60%)] Loss: 15132.534180\n",
      "Train Epoch: 66 [135296/225000 (60%)] Loss: 14850.368164\n",
      "Train Epoch: 66 [136704/225000 (61%)] Loss: 14614.658203\n",
      "Train Epoch: 66 [138112/225000 (61%)] Loss: 14879.625000\n",
      "Train Epoch: 66 [139520/225000 (62%)] Loss: 15266.536133\n",
      "Train Epoch: 66 [140928/225000 (63%)] Loss: 15180.931641\n",
      "Train Epoch: 66 [142336/225000 (63%)] Loss: 15087.109375\n",
      "Train Epoch: 66 [143744/225000 (64%)] Loss: 14994.156250\n",
      "Train Epoch: 66 [145152/225000 (65%)] Loss: 14511.833984\n",
      "Train Epoch: 66 [146560/225000 (65%)] Loss: 15071.213867\n",
      "Train Epoch: 66 [147968/225000 (66%)] Loss: 15593.127930\n",
      "Train Epoch: 66 [149376/225000 (66%)] Loss: 15344.778320\n",
      "Train Epoch: 66 [150784/225000 (67%)] Loss: 15228.690430\n",
      "Train Epoch: 66 [152192/225000 (68%)] Loss: 15114.422852\n",
      "Train Epoch: 66 [153600/225000 (68%)] Loss: 14944.223633\n",
      "Train Epoch: 66 [155008/225000 (69%)] Loss: 14878.003906\n",
      "Train Epoch: 66 [156416/225000 (70%)] Loss: 14788.124023\n",
      "Train Epoch: 66 [157824/225000 (70%)] Loss: 15187.714844\n",
      "Train Epoch: 66 [159232/225000 (71%)] Loss: 15029.245117\n",
      "Train Epoch: 66 [160640/225000 (71%)] Loss: 15214.425781\n",
      "Train Epoch: 66 [162048/225000 (72%)] Loss: 14860.604492\n",
      "Train Epoch: 66 [163456/225000 (73%)] Loss: 15602.439453\n",
      "Train Epoch: 66 [164864/225000 (73%)] Loss: 14929.698242\n",
      "Train Epoch: 66 [166272/225000 (74%)] Loss: 14577.430664\n",
      "Train Epoch: 66 [167680/225000 (75%)] Loss: 15021.337891\n",
      "Train Epoch: 66 [169088/225000 (75%)] Loss: 14837.263672\n",
      "Train Epoch: 66 [170496/225000 (76%)] Loss: 15395.289062\n",
      "Train Epoch: 66 [171904/225000 (76%)] Loss: 14983.362305\n",
      "Train Epoch: 66 [173312/225000 (77%)] Loss: 14688.847656\n",
      "Train Epoch: 66 [174720/225000 (78%)] Loss: 14687.588867\n",
      "Train Epoch: 66 [176128/225000 (78%)] Loss: 15055.364258\n",
      "Train Epoch: 66 [177536/225000 (79%)] Loss: 14962.901367\n",
      "Train Epoch: 66 [178944/225000 (80%)] Loss: 14994.896484\n",
      "Train Epoch: 66 [180352/225000 (80%)] Loss: 15041.393555\n",
      "Train Epoch: 66 [181760/225000 (81%)] Loss: 15331.600586\n",
      "Train Epoch: 66 [183168/225000 (81%)] Loss: 15118.845703\n",
      "Train Epoch: 66 [184576/225000 (82%)] Loss: 14676.130859\n",
      "Train Epoch: 66 [185984/225000 (83%)] Loss: 14837.178711\n",
      "Train Epoch: 66 [187392/225000 (83%)] Loss: 14707.702148\n",
      "Train Epoch: 66 [188800/225000 (84%)] Loss: 15313.000977\n",
      "Train Epoch: 66 [190208/225000 (85%)] Loss: 14936.058594\n",
      "Train Epoch: 66 [191616/225000 (85%)] Loss: 15080.435547\n",
      "Train Epoch: 66 [193024/225000 (86%)] Loss: 15033.915039\n",
      "Train Epoch: 66 [194432/225000 (86%)] Loss: 14842.918945\n",
      "Train Epoch: 66 [195840/225000 (87%)] Loss: 14749.820312\n",
      "Train Epoch: 66 [197248/225000 (88%)] Loss: 14766.436523\n",
      "Train Epoch: 66 [198656/225000 (88%)] Loss: 14899.909180\n",
      "Train Epoch: 66 [200064/225000 (89%)] Loss: 15243.439453\n",
      "Train Epoch: 66 [201472/225000 (90%)] Loss: 14918.389648\n",
      "Train Epoch: 66 [202880/225000 (90%)] Loss: 15145.936523\n",
      "Train Epoch: 66 [204288/225000 (91%)] Loss: 15262.082031\n",
      "Train Epoch: 66 [205696/225000 (91%)] Loss: 15195.981445\n",
      "Train Epoch: 66 [207104/225000 (92%)] Loss: 15147.738281\n",
      "Train Epoch: 66 [208512/225000 (93%)] Loss: 15344.754883\n",
      "Train Epoch: 66 [209920/225000 (93%)] Loss: 14800.829102\n",
      "Train Epoch: 66 [211328/225000 (94%)] Loss: 15083.054688\n",
      "Train Epoch: 66 [212736/225000 (95%)] Loss: 15061.226562\n",
      "Train Epoch: 66 [214144/225000 (95%)] Loss: 14976.802734\n",
      "Train Epoch: 66 [215552/225000 (96%)] Loss: 15019.148438\n",
      "Train Epoch: 66 [216960/225000 (96%)] Loss: 14910.017578\n",
      "Train Epoch: 66 [218368/225000 (97%)] Loss: 15100.998047\n",
      "Train Epoch: 66 [219776/225000 (98%)] Loss: 15225.739258\n",
      "Train Epoch: 66 [221184/225000 (98%)] Loss: 15078.250000\n",
      "Train Epoch: 66 [222592/225000 (99%)] Loss: 14708.931641\n",
      "Train Epoch: 66 [224000/225000 (100%)] Loss: 15001.028320\n",
      "    epoch          : 66\n",
      "    loss           : 15074.090397579814\n",
      "    val_loss       : 15058.541245411398\n",
      "Train Epoch: 67 [128/225000 (0%)] Loss: 14832.655273\n",
      "Train Epoch: 67 [1536/225000 (1%)] Loss: 14839.823242\n",
      "Train Epoch: 67 [2944/225000 (1%)] Loss: 15200.000000\n",
      "Train Epoch: 67 [4352/225000 (2%)] Loss: 15295.469727\n",
      "Train Epoch: 67 [5760/225000 (3%)] Loss: 15015.683594\n",
      "Train Epoch: 67 [7168/225000 (3%)] Loss: 14630.616211\n",
      "Train Epoch: 67 [8576/225000 (4%)] Loss: 15264.088867\n",
      "Train Epoch: 67 [9984/225000 (4%)] Loss: 15561.705078\n",
      "Train Epoch: 67 [11392/225000 (5%)] Loss: 15489.632812\n",
      "Train Epoch: 67 [12800/225000 (6%)] Loss: 15242.331055\n",
      "Train Epoch: 67 [14208/225000 (6%)] Loss: 15573.959961\n",
      "Train Epoch: 67 [15616/225000 (7%)] Loss: 15023.708984\n",
      "Train Epoch: 67 [17024/225000 (8%)] Loss: 14276.437500\n",
      "Train Epoch: 67 [18432/225000 (8%)] Loss: 15058.083008\n",
      "Train Epoch: 67 [19840/225000 (9%)] Loss: 15385.694336\n",
      "Train Epoch: 67 [21248/225000 (9%)] Loss: 15369.834961\n",
      "Train Epoch: 67 [22656/225000 (10%)] Loss: 15015.269531\n",
      "Train Epoch: 67 [24064/225000 (11%)] Loss: 14942.075195\n",
      "Train Epoch: 67 [25472/225000 (11%)] Loss: 15095.990234\n",
      "Train Epoch: 67 [26880/225000 (12%)] Loss: 15165.118164\n",
      "Train Epoch: 67 [28288/225000 (13%)] Loss: 15150.739258\n",
      "Train Epoch: 67 [29696/225000 (13%)] Loss: 15077.607422\n",
      "Train Epoch: 67 [31104/225000 (14%)] Loss: 15127.073242\n",
      "Train Epoch: 67 [32512/225000 (14%)] Loss: 15227.750000\n",
      "Train Epoch: 67 [33920/225000 (15%)] Loss: 14915.239258\n",
      "Train Epoch: 67 [35328/225000 (16%)] Loss: 15123.043945\n",
      "Train Epoch: 67 [36736/225000 (16%)] Loss: 15083.131836\n",
      "Train Epoch: 67 [38144/225000 (17%)] Loss: 14623.541016\n",
      "Train Epoch: 67 [39552/225000 (18%)] Loss: 15488.101562\n",
      "Train Epoch: 67 [40960/225000 (18%)] Loss: 14883.696289\n",
      "Train Epoch: 67 [42368/225000 (19%)] Loss: 14646.523438\n",
      "Train Epoch: 67 [43776/225000 (19%)] Loss: 15254.920898\n",
      "Train Epoch: 67 [45184/225000 (20%)] Loss: 15178.324219\n",
      "Train Epoch: 67 [46592/225000 (21%)] Loss: 15076.448242\n",
      "Train Epoch: 67 [48000/225000 (21%)] Loss: 14989.017578\n",
      "Train Epoch: 67 [49408/225000 (22%)] Loss: 14998.697266\n",
      "Train Epoch: 67 [50816/225000 (23%)] Loss: 14785.162109\n",
      "Train Epoch: 67 [52224/225000 (23%)] Loss: 15102.458984\n",
      "Train Epoch: 67 [53632/225000 (24%)] Loss: 15216.827148\n",
      "Train Epoch: 67 [55040/225000 (24%)] Loss: 14772.230469\n",
      "Train Epoch: 67 [56448/225000 (25%)] Loss: 15152.984375\n",
      "Train Epoch: 67 [57856/225000 (26%)] Loss: 15087.090820\n",
      "Train Epoch: 67 [59264/225000 (26%)] Loss: 14922.931641\n",
      "Train Epoch: 67 [60672/225000 (27%)] Loss: 14918.593750\n",
      "Train Epoch: 67 [62080/225000 (28%)] Loss: 15161.531250\n",
      "Train Epoch: 67 [63488/225000 (28%)] Loss: 15170.533203\n",
      "Train Epoch: 67 [64896/225000 (29%)] Loss: 14737.970703\n",
      "Train Epoch: 67 [66304/225000 (29%)] Loss: 14975.562500\n",
      "Train Epoch: 67 [67712/225000 (30%)] Loss: 15170.631836\n",
      "Train Epoch: 67 [69120/225000 (31%)] Loss: 14940.404297\n",
      "Train Epoch: 67 [70528/225000 (31%)] Loss: 15007.657227\n",
      "Train Epoch: 67 [71936/225000 (32%)] Loss: 15153.758789\n",
      "Train Epoch: 67 [73344/225000 (33%)] Loss: 14668.191406\n",
      "Train Epoch: 67 [74752/225000 (33%)] Loss: 15400.712891\n",
      "Train Epoch: 67 [76160/225000 (34%)] Loss: 15329.258789\n",
      "Train Epoch: 67 [77568/225000 (34%)] Loss: 15239.132812\n",
      "Train Epoch: 67 [78976/225000 (35%)] Loss: 15384.976562\n",
      "Train Epoch: 67 [80384/225000 (36%)] Loss: 16005.531250\n",
      "Train Epoch: 67 [81792/225000 (36%)] Loss: 14908.179688\n",
      "Train Epoch: 67 [83200/225000 (37%)] Loss: 15064.245117\n",
      "Train Epoch: 67 [84608/225000 (38%)] Loss: 15004.758789\n",
      "Train Epoch: 67 [86016/225000 (38%)] Loss: 14991.239258\n",
      "Train Epoch: 67 [87424/225000 (39%)] Loss: 14803.572266\n",
      "Train Epoch: 67 [88832/225000 (39%)] Loss: 15598.919922\n",
      "Train Epoch: 67 [90240/225000 (40%)] Loss: 15268.907227\n",
      "Train Epoch: 67 [91648/225000 (41%)] Loss: 14884.396484\n",
      "Train Epoch: 67 [93056/225000 (41%)] Loss: 14862.807617\n",
      "Train Epoch: 67 [94464/225000 (42%)] Loss: 14796.293945\n",
      "Train Epoch: 67 [95872/225000 (43%)] Loss: 14970.975586\n",
      "Train Epoch: 67 [97280/225000 (43%)] Loss: 14831.829102\n",
      "Train Epoch: 67 [98688/225000 (44%)] Loss: 15082.664062\n",
      "Train Epoch: 67 [100096/225000 (44%)] Loss: 15333.524414\n",
      "Train Epoch: 67 [101504/225000 (45%)] Loss: 14902.809570\n",
      "Train Epoch: 67 [102912/225000 (46%)] Loss: 15275.560547\n",
      "Train Epoch: 67 [104320/225000 (46%)] Loss: 14834.315430\n",
      "Train Epoch: 67 [105728/225000 (47%)] Loss: 15164.466797\n",
      "Train Epoch: 67 [107136/225000 (48%)] Loss: 15092.696289\n",
      "Train Epoch: 67 [108544/225000 (48%)] Loss: 14778.262695\n",
      "Train Epoch: 67 [109952/225000 (49%)] Loss: 15024.352539\n",
      "Train Epoch: 67 [111360/225000 (49%)] Loss: 15003.093750\n",
      "Train Epoch: 67 [112768/225000 (50%)] Loss: 15212.986328\n",
      "Train Epoch: 67 [114176/225000 (51%)] Loss: 14873.309570\n",
      "Train Epoch: 67 [115584/225000 (51%)] Loss: 14955.430664\n",
      "Train Epoch: 67 [116992/225000 (52%)] Loss: 14816.765625\n",
      "Train Epoch: 67 [118400/225000 (53%)] Loss: 14503.750000\n",
      "Train Epoch: 67 [119808/225000 (53%)] Loss: 15551.560547\n",
      "Train Epoch: 67 [121216/225000 (54%)] Loss: 15247.020508\n",
      "Train Epoch: 67 [122624/225000 (54%)] Loss: 14837.988281\n",
      "Train Epoch: 67 [124032/225000 (55%)] Loss: 15176.380859\n",
      "Train Epoch: 67 [125440/225000 (56%)] Loss: 15023.583984\n",
      "Train Epoch: 67 [126848/225000 (56%)] Loss: 15363.375000\n",
      "Train Epoch: 67 [128256/225000 (57%)] Loss: 15038.625000\n",
      "Train Epoch: 67 [129664/225000 (58%)] Loss: 15399.318359\n",
      "Train Epoch: 67 [131072/225000 (58%)] Loss: 15605.789062\n",
      "Train Epoch: 67 [132480/225000 (59%)] Loss: 15299.300781\n",
      "Train Epoch: 67 [133888/225000 (60%)] Loss: 15471.525391\n",
      "Train Epoch: 67 [135296/225000 (60%)] Loss: 15063.803711\n",
      "Train Epoch: 67 [136704/225000 (61%)] Loss: 14764.651367\n",
      "Train Epoch: 67 [138112/225000 (61%)] Loss: 15073.456055\n",
      "Train Epoch: 67 [139520/225000 (62%)] Loss: 14880.888672\n",
      "Train Epoch: 67 [140928/225000 (63%)] Loss: 15151.136719\n",
      "Train Epoch: 67 [142336/225000 (63%)] Loss: 15053.583008\n",
      "Train Epoch: 67 [143744/225000 (64%)] Loss: 15106.853516\n",
      "Train Epoch: 67 [145152/225000 (65%)] Loss: 15425.761719\n",
      "Train Epoch: 67 [146560/225000 (65%)] Loss: 14900.129883\n",
      "Train Epoch: 67 [147968/225000 (66%)] Loss: 15465.564453\n",
      "Train Epoch: 67 [149376/225000 (66%)] Loss: 14775.981445\n",
      "Train Epoch: 67 [150784/225000 (67%)] Loss: 15468.649414\n",
      "Train Epoch: 67 [152192/225000 (68%)] Loss: 15165.687500\n",
      "Train Epoch: 67 [153600/225000 (68%)] Loss: 14926.325195\n",
      "Train Epoch: 67 [155008/225000 (69%)] Loss: 14378.016602\n",
      "Train Epoch: 67 [156416/225000 (70%)] Loss: 14805.090820\n",
      "Train Epoch: 67 [157824/225000 (70%)] Loss: 14963.549805\n",
      "Train Epoch: 67 [159232/225000 (71%)] Loss: 14872.720703\n",
      "Train Epoch: 67 [160640/225000 (71%)] Loss: 14682.168945\n",
      "Train Epoch: 67 [162048/225000 (72%)] Loss: 15313.517578\n",
      "Train Epoch: 67 [163456/225000 (73%)] Loss: 15127.115234\n",
      "Train Epoch: 67 [164864/225000 (73%)] Loss: 15268.625000\n",
      "Train Epoch: 67 [166272/225000 (74%)] Loss: 15267.319336\n",
      "Train Epoch: 67 [167680/225000 (75%)] Loss: 15296.555664\n",
      "Train Epoch: 67 [169088/225000 (75%)] Loss: 15201.990234\n",
      "Train Epoch: 67 [170496/225000 (76%)] Loss: 14719.299805\n",
      "Train Epoch: 67 [171904/225000 (76%)] Loss: 14655.083984\n",
      "Train Epoch: 67 [173312/225000 (77%)] Loss: 15161.435547\n",
      "Train Epoch: 67 [174720/225000 (78%)] Loss: 15155.404297\n",
      "Train Epoch: 67 [176128/225000 (78%)] Loss: 14565.345703\n",
      "Train Epoch: 67 [177536/225000 (79%)] Loss: 15115.915039\n",
      "Train Epoch: 67 [178944/225000 (80%)] Loss: 15600.488281\n",
      "Train Epoch: 67 [180352/225000 (80%)] Loss: 15284.141602\n",
      "Train Epoch: 67 [181760/225000 (81%)] Loss: 15062.035156\n",
      "Train Epoch: 67 [183168/225000 (81%)] Loss: 14955.889648\n",
      "Train Epoch: 67 [184576/225000 (82%)] Loss: 14600.180664\n",
      "Train Epoch: 67 [185984/225000 (83%)] Loss: 15448.776367\n",
      "Train Epoch: 67 [187392/225000 (83%)] Loss: 15032.019531\n",
      "Train Epoch: 67 [188800/225000 (84%)] Loss: 15304.814453\n",
      "Train Epoch: 67 [190208/225000 (85%)] Loss: 15231.374023\n",
      "Train Epoch: 67 [191616/225000 (85%)] Loss: 15612.893555\n",
      "Train Epoch: 67 [193024/225000 (86%)] Loss: 14815.769531\n",
      "Train Epoch: 67 [194432/225000 (86%)] Loss: 15320.848633\n",
      "Train Epoch: 67 [195840/225000 (87%)] Loss: 15113.766602\n",
      "Train Epoch: 67 [197248/225000 (88%)] Loss: 15160.830078\n",
      "Train Epoch: 67 [198656/225000 (88%)] Loss: 15312.042969\n",
      "Train Epoch: 67 [200064/225000 (89%)] Loss: 15141.618164\n",
      "Train Epoch: 67 [201472/225000 (90%)] Loss: 15098.610352\n",
      "Train Epoch: 67 [202880/225000 (90%)] Loss: 15131.625977\n",
      "Train Epoch: 67 [204288/225000 (91%)] Loss: 15169.637695\n",
      "Train Epoch: 67 [205696/225000 (91%)] Loss: 15037.646484\n",
      "Train Epoch: 67 [207104/225000 (92%)] Loss: 14675.920898\n",
      "Train Epoch: 67 [208512/225000 (93%)] Loss: 15050.307617\n",
      "Train Epoch: 67 [209920/225000 (93%)] Loss: 14936.932617\n",
      "Train Epoch: 67 [211328/225000 (94%)] Loss: 15035.038086\n",
      "Train Epoch: 67 [212736/225000 (95%)] Loss: 14774.160156\n",
      "Train Epoch: 67 [214144/225000 (95%)] Loss: 15546.660156\n",
      "Train Epoch: 67 [215552/225000 (96%)] Loss: 15021.129883\n",
      "Train Epoch: 67 [216960/225000 (96%)] Loss: 15103.777344\n",
      "Train Epoch: 67 [218368/225000 (97%)] Loss: 15170.088867\n",
      "Train Epoch: 67 [219776/225000 (98%)] Loss: 15116.487305\n",
      "Train Epoch: 67 [221184/225000 (98%)] Loss: 15363.154297\n",
      "Train Epoch: 67 [222592/225000 (99%)] Loss: 15312.723633\n",
      "Train Epoch: 67 [224000/225000 (100%)] Loss: 15159.211914\n",
      "    epoch          : 67\n",
      "    loss           : 15073.629775046218\n",
      "    val_loss       : 15064.300454778635\n",
      "Train Epoch: 68 [128/225000 (0%)] Loss: 15107.253906\n",
      "Train Epoch: 68 [1536/225000 (1%)] Loss: 15204.492188\n",
      "Train Epoch: 68 [2944/225000 (1%)] Loss: 15447.225586\n",
      "Train Epoch: 68 [4352/225000 (2%)] Loss: 15426.113281\n",
      "Train Epoch: 68 [5760/225000 (3%)] Loss: 15153.906250\n",
      "Train Epoch: 68 [7168/225000 (3%)] Loss: 15551.751953\n",
      "Train Epoch: 68 [8576/225000 (4%)] Loss: 14565.094727\n",
      "Train Epoch: 68 [9984/225000 (4%)] Loss: 14799.931641\n",
      "Train Epoch: 68 [11392/225000 (5%)] Loss: 15126.338867\n",
      "Train Epoch: 68 [12800/225000 (6%)] Loss: 15249.730469\n",
      "Train Epoch: 68 [14208/225000 (6%)] Loss: 15056.564453\n",
      "Train Epoch: 68 [15616/225000 (7%)] Loss: 14861.524414\n",
      "Train Epoch: 68 [17024/225000 (8%)] Loss: 15163.190430\n",
      "Train Epoch: 68 [18432/225000 (8%)] Loss: 15332.639648\n",
      "Train Epoch: 68 [19840/225000 (9%)] Loss: 14977.733398\n",
      "Train Epoch: 68 [21248/225000 (9%)] Loss: 14756.492188\n",
      "Train Epoch: 68 [22656/225000 (10%)] Loss: 15094.272461\n",
      "Train Epoch: 68 [24064/225000 (11%)] Loss: 15114.792969\n",
      "Train Epoch: 68 [25472/225000 (11%)] Loss: 15205.431641\n",
      "Train Epoch: 68 [26880/225000 (12%)] Loss: 15114.040039\n",
      "Train Epoch: 68 [28288/225000 (13%)] Loss: 15061.824219\n",
      "Train Epoch: 68 [29696/225000 (13%)] Loss: 14979.524414\n",
      "Train Epoch: 68 [31104/225000 (14%)] Loss: 14837.258789\n",
      "Train Epoch: 68 [32512/225000 (14%)] Loss: 15530.654297\n",
      "Train Epoch: 68 [33920/225000 (15%)] Loss: 14844.350586\n",
      "Train Epoch: 68 [35328/225000 (16%)] Loss: 15184.418945\n",
      "Train Epoch: 68 [36736/225000 (16%)] Loss: 15141.679688\n",
      "Train Epoch: 68 [38144/225000 (17%)] Loss: 14893.853516\n",
      "Train Epoch: 68 [39552/225000 (18%)] Loss: 15029.171875\n",
      "Train Epoch: 68 [40960/225000 (18%)] Loss: 14536.711914\n",
      "Train Epoch: 68 [42368/225000 (19%)] Loss: 14998.197266\n",
      "Train Epoch: 68 [43776/225000 (19%)] Loss: 14913.707031\n",
      "Train Epoch: 68 [45184/225000 (20%)] Loss: 15089.621094\n",
      "Train Epoch: 68 [46592/225000 (21%)] Loss: 15404.624023\n",
      "Train Epoch: 68 [48000/225000 (21%)] Loss: 14768.426758\n",
      "Train Epoch: 68 [49408/225000 (22%)] Loss: 14917.651367\n",
      "Train Epoch: 68 [50816/225000 (23%)] Loss: 14949.351562\n",
      "Train Epoch: 68 [52224/225000 (23%)] Loss: 14608.813477\n",
      "Train Epoch: 68 [53632/225000 (24%)] Loss: 15074.841797\n",
      "Train Epoch: 68 [55040/225000 (24%)] Loss: 14981.667969\n",
      "Train Epoch: 68 [56448/225000 (25%)] Loss: 15273.056641\n",
      "Train Epoch: 68 [57856/225000 (26%)] Loss: 15281.288086\n",
      "Train Epoch: 68 [59264/225000 (26%)] Loss: 15293.472656\n",
      "Train Epoch: 68 [60672/225000 (27%)] Loss: 14950.060547\n",
      "Train Epoch: 68 [62080/225000 (28%)] Loss: 15445.336914\n",
      "Train Epoch: 68 [63488/225000 (28%)] Loss: 15213.590820\n",
      "Train Epoch: 68 [64896/225000 (29%)] Loss: 15239.007812\n",
      "Train Epoch: 68 [66304/225000 (29%)] Loss: 14438.638672\n",
      "Train Epoch: 68 [67712/225000 (30%)] Loss: 14985.031250\n",
      "Train Epoch: 68 [69120/225000 (31%)] Loss: 14732.154297\n",
      "Train Epoch: 68 [70528/225000 (31%)] Loss: 15126.149414\n",
      "Train Epoch: 68 [71936/225000 (32%)] Loss: 15442.842773\n",
      "Train Epoch: 68 [73344/225000 (33%)] Loss: 14868.504883\n",
      "Train Epoch: 68 [74752/225000 (33%)] Loss: 15470.524414\n",
      "Train Epoch: 68 [76160/225000 (34%)] Loss: 15211.538086\n",
      "Train Epoch: 68 [77568/225000 (34%)] Loss: 14784.701172\n",
      "Train Epoch: 68 [78976/225000 (35%)] Loss: 15081.863281\n",
      "Train Epoch: 68 [80384/225000 (36%)] Loss: 15350.200195\n",
      "Train Epoch: 68 [81792/225000 (36%)] Loss: 15135.387695\n",
      "Train Epoch: 68 [83200/225000 (37%)] Loss: 15232.363281\n",
      "Train Epoch: 68 [84608/225000 (38%)] Loss: 15400.400391\n",
      "Train Epoch: 68 [86016/225000 (38%)] Loss: 14886.600586\n",
      "Train Epoch: 68 [87424/225000 (39%)] Loss: 15179.883789\n",
      "Train Epoch: 68 [88832/225000 (39%)] Loss: 14930.783203\n",
      "Train Epoch: 68 [90240/225000 (40%)] Loss: 15709.088867\n",
      "Train Epoch: 68 [91648/225000 (41%)] Loss: 14728.625000\n",
      "Train Epoch: 68 [93056/225000 (41%)] Loss: 14965.646484\n",
      "Train Epoch: 68 [94464/225000 (42%)] Loss: 15398.483398\n",
      "Train Epoch: 68 [95872/225000 (43%)] Loss: 15019.544922\n",
      "Train Epoch: 68 [97280/225000 (43%)] Loss: 15063.619141\n",
      "Train Epoch: 68 [98688/225000 (44%)] Loss: 15036.244141\n",
      "Train Epoch: 68 [100096/225000 (44%)] Loss: 14968.378906\n",
      "Train Epoch: 68 [101504/225000 (45%)] Loss: 15014.387695\n",
      "Train Epoch: 68 [102912/225000 (46%)] Loss: 15044.308594\n",
      "Train Epoch: 68 [104320/225000 (46%)] Loss: 15277.713867\n",
      "Train Epoch: 68 [105728/225000 (47%)] Loss: 14852.110352\n",
      "Train Epoch: 68 [107136/225000 (48%)] Loss: 15385.614258\n",
      "Train Epoch: 68 [108544/225000 (48%)] Loss: 14527.481445\n",
      "Train Epoch: 68 [109952/225000 (49%)] Loss: 15134.250977\n",
      "Train Epoch: 68 [111360/225000 (49%)] Loss: 15213.688477\n",
      "Train Epoch: 68 [112768/225000 (50%)] Loss: 15117.563477\n",
      "Train Epoch: 68 [114176/225000 (51%)] Loss: 14844.384766\n",
      "Train Epoch: 68 [115584/225000 (51%)] Loss: 15059.734375\n",
      "Train Epoch: 68 [116992/225000 (52%)] Loss: 16654.144531\n",
      "Train Epoch: 68 [118400/225000 (53%)] Loss: 15086.842773\n",
      "Train Epoch: 68 [119808/225000 (53%)] Loss: 14686.490234\n",
      "Train Epoch: 68 [121216/225000 (54%)] Loss: 15335.612305\n",
      "Train Epoch: 68 [122624/225000 (54%)] Loss: 14879.776367\n",
      "Train Epoch: 68 [124032/225000 (55%)] Loss: 15153.586914\n",
      "Train Epoch: 68 [125440/225000 (56%)] Loss: 14941.011719\n",
      "Train Epoch: 68 [126848/225000 (56%)] Loss: 14979.964844\n",
      "Train Epoch: 68 [128256/225000 (57%)] Loss: 15087.128906\n",
      "Train Epoch: 68 [129664/225000 (58%)] Loss: 14957.049805\n",
      "Train Epoch: 68 [131072/225000 (58%)] Loss: 15012.374023\n",
      "Train Epoch: 68 [132480/225000 (59%)] Loss: 14872.645508\n",
      "Train Epoch: 68 [133888/225000 (60%)] Loss: 15489.157227\n",
      "Train Epoch: 68 [135296/225000 (60%)] Loss: 15018.262695\n",
      "Train Epoch: 68 [136704/225000 (61%)] Loss: 15801.617188\n",
      "Train Epoch: 68 [138112/225000 (61%)] Loss: 15350.593750\n",
      "Train Epoch: 68 [139520/225000 (62%)] Loss: 14952.861328\n",
      "Train Epoch: 68 [140928/225000 (63%)] Loss: 15279.656250\n",
      "Train Epoch: 68 [142336/225000 (63%)] Loss: 14578.042969\n",
      "Train Epoch: 68 [143744/225000 (64%)] Loss: 14745.878906\n",
      "Train Epoch: 68 [145152/225000 (65%)] Loss: 15438.519531\n",
      "Train Epoch: 68 [146560/225000 (65%)] Loss: 15544.366211\n",
      "Train Epoch: 68 [147968/225000 (66%)] Loss: 14806.948242\n",
      "Train Epoch: 68 [149376/225000 (66%)] Loss: 14643.064453\n",
      "Train Epoch: 68 [150784/225000 (67%)] Loss: 15046.219727\n",
      "Train Epoch: 68 [152192/225000 (68%)] Loss: 15156.311523\n",
      "Train Epoch: 68 [153600/225000 (68%)] Loss: 14993.418945\n",
      "Train Epoch: 68 [155008/225000 (69%)] Loss: 15100.256836\n",
      "Train Epoch: 68 [156416/225000 (70%)] Loss: 15095.421875\n",
      "Train Epoch: 68 [157824/225000 (70%)] Loss: 15113.364258\n",
      "Train Epoch: 68 [159232/225000 (71%)] Loss: 15791.903320\n",
      "Train Epoch: 68 [160640/225000 (71%)] Loss: 15206.855469\n",
      "Train Epoch: 68 [162048/225000 (72%)] Loss: 15010.860352\n",
      "Train Epoch: 68 [163456/225000 (73%)] Loss: 14898.244141\n",
      "Train Epoch: 68 [164864/225000 (73%)] Loss: 15252.908203\n",
      "Train Epoch: 68 [166272/225000 (74%)] Loss: 14827.821289\n",
      "Train Epoch: 68 [167680/225000 (75%)] Loss: 15266.570312\n",
      "Train Epoch: 68 [169088/225000 (75%)] Loss: 15128.283203\n",
      "Train Epoch: 68 [170496/225000 (76%)] Loss: 15071.233398\n",
      "Train Epoch: 68 [171904/225000 (76%)] Loss: 15085.573242\n",
      "Train Epoch: 68 [173312/225000 (77%)] Loss: 15288.974609\n",
      "Train Epoch: 68 [174720/225000 (78%)] Loss: 14960.042969\n",
      "Train Epoch: 68 [176128/225000 (78%)] Loss: 14804.564453\n",
      "Train Epoch: 68 [177536/225000 (79%)] Loss: 14912.968750\n",
      "Train Epoch: 68 [178944/225000 (80%)] Loss: 15213.743164\n",
      "Train Epoch: 68 [180352/225000 (80%)] Loss: 14991.090820\n",
      "Train Epoch: 68 [181760/225000 (81%)] Loss: 14935.499023\n",
      "Train Epoch: 68 [183168/225000 (81%)] Loss: 15015.135742\n",
      "Train Epoch: 68 [184576/225000 (82%)] Loss: 14881.980469\n",
      "Train Epoch: 68 [185984/225000 (83%)] Loss: 14790.458008\n",
      "Train Epoch: 68 [187392/225000 (83%)] Loss: 14663.332031\n",
      "Train Epoch: 68 [188800/225000 (84%)] Loss: 14770.654297\n",
      "Train Epoch: 68 [190208/225000 (85%)] Loss: 15318.215820\n",
      "Train Epoch: 68 [191616/225000 (85%)] Loss: 15049.589844\n",
      "Train Epoch: 68 [193024/225000 (86%)] Loss: 14962.333984\n",
      "Train Epoch: 68 [194432/225000 (86%)] Loss: 15050.623047\n",
      "Train Epoch: 68 [195840/225000 (87%)] Loss: 14993.538086\n",
      "Train Epoch: 68 [197248/225000 (88%)] Loss: 15232.911133\n",
      "Train Epoch: 68 [198656/225000 (88%)] Loss: 15272.473633\n",
      "Train Epoch: 68 [200064/225000 (89%)] Loss: 14973.712891\n",
      "Train Epoch: 68 [201472/225000 (90%)] Loss: 15287.060547\n",
      "Train Epoch: 68 [202880/225000 (90%)] Loss: 15235.852539\n",
      "Train Epoch: 68 [204288/225000 (91%)] Loss: 14707.539062\n",
      "Train Epoch: 68 [205696/225000 (91%)] Loss: 15206.348633\n",
      "Train Epoch: 68 [207104/225000 (92%)] Loss: 15184.859375\n",
      "Train Epoch: 68 [208512/225000 (93%)] Loss: 14675.803711\n",
      "Train Epoch: 68 [209920/225000 (93%)] Loss: 14712.866211\n",
      "Train Epoch: 68 [211328/225000 (94%)] Loss: 15111.768555\n",
      "Train Epoch: 68 [212736/225000 (95%)] Loss: 15312.320312\n",
      "Train Epoch: 68 [214144/225000 (95%)] Loss: 14832.841797\n",
      "Train Epoch: 68 [215552/225000 (96%)] Loss: 14976.521484\n",
      "Train Epoch: 68 [216960/225000 (96%)] Loss: 15484.191406\n",
      "Train Epoch: 68 [218368/225000 (97%)] Loss: 14684.148438\n",
      "Train Epoch: 68 [219776/225000 (98%)] Loss: 15248.369141\n",
      "Train Epoch: 68 [221184/225000 (98%)] Loss: 15406.661133\n",
      "Train Epoch: 68 [222592/225000 (99%)] Loss: 14864.046875\n",
      "Train Epoch: 68 [224000/225000 (100%)] Loss: 15268.092773\n",
      "    epoch          : 68\n",
      "    loss           : 15077.401590497013\n",
      "    val_loss       : 15069.578963859349\n",
      "Train Epoch: 69 [128/225000 (0%)] Loss: 15192.726562\n",
      "Train Epoch: 69 [1536/225000 (1%)] Loss: 14916.113281\n",
      "Train Epoch: 69 [2944/225000 (1%)] Loss: 14754.189453\n",
      "Train Epoch: 69 [4352/225000 (2%)] Loss: 14983.366211\n",
      "Train Epoch: 69 [5760/225000 (3%)] Loss: 15185.251953\n",
      "Train Epoch: 69 [7168/225000 (3%)] Loss: 14896.436523\n",
      "Train Epoch: 69 [8576/225000 (4%)] Loss: 15284.196289\n",
      "Train Epoch: 69 [9984/225000 (4%)] Loss: 15285.716797\n",
      "Train Epoch: 69 [11392/225000 (5%)] Loss: 15049.774414\n",
      "Train Epoch: 69 [12800/225000 (6%)] Loss: 14730.462891\n",
      "Train Epoch: 69 [14208/225000 (6%)] Loss: 14936.988281\n",
      "Train Epoch: 69 [15616/225000 (7%)] Loss: 14812.957031\n",
      "Train Epoch: 69 [17024/225000 (8%)] Loss: 14243.105469\n",
      "Train Epoch: 69 [18432/225000 (8%)] Loss: 15230.612305\n",
      "Train Epoch: 69 [19840/225000 (9%)] Loss: 15333.250977\n",
      "Train Epoch: 69 [21248/225000 (9%)] Loss: 15034.395508\n",
      "Train Epoch: 69 [22656/225000 (10%)] Loss: 15066.286133\n",
      "Train Epoch: 69 [24064/225000 (11%)] Loss: 15088.116211\n",
      "Train Epoch: 69 [25472/225000 (11%)] Loss: 15490.046875\n",
      "Train Epoch: 69 [26880/225000 (12%)] Loss: 15214.984375\n",
      "Train Epoch: 69 [28288/225000 (13%)] Loss: 14828.614258\n",
      "Train Epoch: 69 [29696/225000 (13%)] Loss: 15190.646484\n",
      "Train Epoch: 69 [31104/225000 (14%)] Loss: 15189.606445\n",
      "Train Epoch: 69 [32512/225000 (14%)] Loss: 15082.550781\n",
      "Train Epoch: 69 [33920/225000 (15%)] Loss: 15099.336914\n",
      "Train Epoch: 69 [35328/225000 (16%)] Loss: 15124.067383\n",
      "Train Epoch: 69 [36736/225000 (16%)] Loss: 14776.335938\n",
      "Train Epoch: 69 [38144/225000 (17%)] Loss: 14989.964844\n",
      "Train Epoch: 69 [39552/225000 (18%)] Loss: 14731.573242\n",
      "Train Epoch: 69 [40960/225000 (18%)] Loss: 15076.067383\n",
      "Train Epoch: 69 [42368/225000 (19%)] Loss: 15349.594727\n",
      "Train Epoch: 69 [43776/225000 (19%)] Loss: 14879.563477\n",
      "Train Epoch: 69 [45184/225000 (20%)] Loss: 14467.272461\n",
      "Train Epoch: 69 [46592/225000 (21%)] Loss: 15107.317383\n",
      "Train Epoch: 69 [48000/225000 (21%)] Loss: 15194.464844\n",
      "Train Epoch: 69 [49408/225000 (22%)] Loss: 14869.663086\n",
      "Train Epoch: 69 [50816/225000 (23%)] Loss: 15267.713867\n",
      "Train Epoch: 69 [52224/225000 (23%)] Loss: 15522.747070\n",
      "Train Epoch: 69 [53632/225000 (24%)] Loss: 15097.608398\n",
      "Train Epoch: 69 [55040/225000 (24%)] Loss: 14952.196289\n",
      "Train Epoch: 69 [56448/225000 (25%)] Loss: 14853.368164\n",
      "Train Epoch: 69 [57856/225000 (26%)] Loss: 14970.152344\n",
      "Train Epoch: 69 [59264/225000 (26%)] Loss: 15238.908203\n",
      "Train Epoch: 69 [60672/225000 (27%)] Loss: 14845.976562\n",
      "Train Epoch: 69 [62080/225000 (28%)] Loss: 15300.165039\n",
      "Train Epoch: 69 [63488/225000 (28%)] Loss: 14934.459961\n",
      "Train Epoch: 69 [64896/225000 (29%)] Loss: 15087.681641\n",
      "Train Epoch: 69 [66304/225000 (29%)] Loss: 14937.069336\n",
      "Train Epoch: 69 [67712/225000 (30%)] Loss: 15324.529297\n",
      "Train Epoch: 69 [69120/225000 (31%)] Loss: 15186.206055\n",
      "Train Epoch: 69 [70528/225000 (31%)] Loss: 14771.230469\n",
      "Train Epoch: 69 [71936/225000 (32%)] Loss: 14946.040039\n",
      "Train Epoch: 69 [73344/225000 (33%)] Loss: 15381.465820\n",
      "Train Epoch: 69 [74752/225000 (33%)] Loss: 14653.692383\n",
      "Train Epoch: 69 [76160/225000 (34%)] Loss: 14607.773438\n",
      "Train Epoch: 69 [77568/225000 (34%)] Loss: 15229.022461\n",
      "Train Epoch: 69 [78976/225000 (35%)] Loss: 14791.016602\n",
      "Train Epoch: 69 [80384/225000 (36%)] Loss: 15510.656250\n",
      "Train Epoch: 69 [81792/225000 (36%)] Loss: 14763.965820\n",
      "Train Epoch: 69 [83200/225000 (37%)] Loss: 15013.238281\n",
      "Train Epoch: 69 [84608/225000 (38%)] Loss: 15828.501953\n",
      "Train Epoch: 69 [86016/225000 (38%)] Loss: 16237.666992\n",
      "Train Epoch: 69 [87424/225000 (39%)] Loss: 15076.360352\n",
      "Train Epoch: 69 [88832/225000 (39%)] Loss: 14873.094727\n",
      "Train Epoch: 69 [90240/225000 (40%)] Loss: 15102.688477\n",
      "Train Epoch: 69 [91648/225000 (41%)] Loss: 15270.776367\n",
      "Train Epoch: 69 [93056/225000 (41%)] Loss: 15037.817383\n",
      "Train Epoch: 69 [94464/225000 (42%)] Loss: 15249.903320\n",
      "Train Epoch: 69 [95872/225000 (43%)] Loss: 15267.344727\n",
      "Train Epoch: 69 [97280/225000 (43%)] Loss: 14973.833984\n",
      "Train Epoch: 69 [98688/225000 (44%)] Loss: 14681.290039\n",
      "Train Epoch: 69 [100096/225000 (44%)] Loss: 15029.348633\n",
      "Train Epoch: 69 [101504/225000 (45%)] Loss: 15243.131836\n",
      "Train Epoch: 69 [102912/225000 (46%)] Loss: 14806.951172\n",
      "Train Epoch: 69 [104320/225000 (46%)] Loss: 14680.676758\n",
      "Train Epoch: 69 [105728/225000 (47%)] Loss: 15111.469727\n",
      "Train Epoch: 69 [107136/225000 (48%)] Loss: 14823.002930\n",
      "Train Epoch: 69 [108544/225000 (48%)] Loss: 15916.291992\n",
      "Train Epoch: 69 [109952/225000 (49%)] Loss: 15301.229492\n",
      "Train Epoch: 69 [111360/225000 (49%)] Loss: 14980.896484\n",
      "Train Epoch: 69 [112768/225000 (50%)] Loss: 15477.527344\n",
      "Train Epoch: 69 [114176/225000 (51%)] Loss: 15249.542969\n",
      "Train Epoch: 69 [115584/225000 (51%)] Loss: 15139.181641\n",
      "Train Epoch: 69 [116992/225000 (52%)] Loss: 15260.388672\n",
      "Train Epoch: 69 [118400/225000 (53%)] Loss: 15117.154297\n",
      "Train Epoch: 69 [119808/225000 (53%)] Loss: 14830.652344\n",
      "Train Epoch: 69 [121216/225000 (54%)] Loss: 14630.167969\n",
      "Train Epoch: 69 [122624/225000 (54%)] Loss: 15046.733398\n",
      "Train Epoch: 69 [124032/225000 (55%)] Loss: 14766.008789\n",
      "Train Epoch: 69 [125440/225000 (56%)] Loss: 14962.351562\n",
      "Train Epoch: 69 [126848/225000 (56%)] Loss: 14991.187500\n",
      "Train Epoch: 69 [128256/225000 (57%)] Loss: 15430.256836\n",
      "Train Epoch: 69 [129664/225000 (58%)] Loss: 15002.736328\n",
      "Train Epoch: 69 [131072/225000 (58%)] Loss: 14848.425781\n",
      "Train Epoch: 69 [132480/225000 (59%)] Loss: 14721.764648\n",
      "Train Epoch: 69 [133888/225000 (60%)] Loss: 15051.916016\n",
      "Train Epoch: 69 [135296/225000 (60%)] Loss: 15193.004883\n",
      "Train Epoch: 69 [136704/225000 (61%)] Loss: 15309.094727\n",
      "Train Epoch: 69 [138112/225000 (61%)] Loss: 15178.597656\n",
      "Train Epoch: 69 [139520/225000 (62%)] Loss: 15070.299805\n",
      "Train Epoch: 69 [140928/225000 (63%)] Loss: 14776.177734\n",
      "Train Epoch: 69 [142336/225000 (63%)] Loss: 14406.617188\n",
      "Train Epoch: 69 [143744/225000 (64%)] Loss: 14716.225586\n",
      "Train Epoch: 69 [145152/225000 (65%)] Loss: 14721.374023\n",
      "Train Epoch: 69 [146560/225000 (65%)] Loss: 15023.138672\n",
      "Train Epoch: 69 [147968/225000 (66%)] Loss: 15313.281250\n",
      "Train Epoch: 69 [149376/225000 (66%)] Loss: 15454.750977\n",
      "Train Epoch: 69 [150784/225000 (67%)] Loss: 15268.568359\n",
      "Train Epoch: 69 [152192/225000 (68%)] Loss: 15273.776367\n",
      "Train Epoch: 69 [153600/225000 (68%)] Loss: 14932.240234\n",
      "Train Epoch: 69 [155008/225000 (69%)] Loss: 15253.108398\n",
      "Train Epoch: 69 [156416/225000 (70%)] Loss: 14778.853516\n",
      "Train Epoch: 69 [157824/225000 (70%)] Loss: 15484.016602\n",
      "Train Epoch: 69 [159232/225000 (71%)] Loss: 15124.996094\n",
      "Train Epoch: 69 [160640/225000 (71%)] Loss: 15036.853516\n",
      "Train Epoch: 69 [162048/225000 (72%)] Loss: 15147.064453\n",
      "Train Epoch: 69 [163456/225000 (73%)] Loss: 15329.664062\n",
      "Train Epoch: 69 [164864/225000 (73%)] Loss: 14865.025391\n",
      "Train Epoch: 69 [166272/225000 (74%)] Loss: 14868.949219\n",
      "Train Epoch: 69 [167680/225000 (75%)] Loss: 14843.414062\n",
      "Train Epoch: 69 [169088/225000 (75%)] Loss: 14839.340820\n",
      "Train Epoch: 69 [170496/225000 (76%)] Loss: 15392.318359\n",
      "Train Epoch: 69 [171904/225000 (76%)] Loss: 14950.928711\n",
      "Train Epoch: 69 [173312/225000 (77%)] Loss: 14969.167969\n",
      "Train Epoch: 69 [174720/225000 (78%)] Loss: 15098.808594\n",
      "Train Epoch: 69 [176128/225000 (78%)] Loss: 15073.171875\n",
      "Train Epoch: 69 [177536/225000 (79%)] Loss: 15328.173828\n",
      "Train Epoch: 69 [178944/225000 (80%)] Loss: 15061.574219\n",
      "Train Epoch: 69 [180352/225000 (80%)] Loss: 14634.438477\n",
      "Train Epoch: 69 [181760/225000 (81%)] Loss: 14942.942383\n",
      "Train Epoch: 69 [183168/225000 (81%)] Loss: 15633.709961\n",
      "Train Epoch: 69 [184576/225000 (82%)] Loss: 14897.884766\n",
      "Train Epoch: 69 [185984/225000 (83%)] Loss: 14867.938477\n",
      "Train Epoch: 69 [187392/225000 (83%)] Loss: 14955.844727\n",
      "Train Epoch: 69 [188800/225000 (84%)] Loss: 15140.712891\n",
      "Train Epoch: 69 [190208/225000 (85%)] Loss: 15211.231445\n",
      "Train Epoch: 69 [191616/225000 (85%)] Loss: 14954.197266\n",
      "Train Epoch: 69 [193024/225000 (86%)] Loss: 15661.675781\n",
      "Train Epoch: 69 [194432/225000 (86%)] Loss: 14996.256836\n",
      "Train Epoch: 69 [195840/225000 (87%)] Loss: 15184.458984\n",
      "Train Epoch: 69 [197248/225000 (88%)] Loss: 15058.471680\n",
      "Train Epoch: 69 [198656/225000 (88%)] Loss: 15303.633789\n",
      "Train Epoch: 69 [200064/225000 (89%)] Loss: 15079.916992\n",
      "Train Epoch: 69 [201472/225000 (90%)] Loss: 14904.551758\n",
      "Train Epoch: 69 [202880/225000 (90%)] Loss: 15025.454102\n",
      "Train Epoch: 69 [204288/225000 (91%)] Loss: 15282.532227\n",
      "Train Epoch: 69 [205696/225000 (91%)] Loss: 14664.069336\n",
      "Train Epoch: 69 [207104/225000 (92%)] Loss: 15069.844727\n",
      "Train Epoch: 69 [208512/225000 (93%)] Loss: 14606.282227\n",
      "Train Epoch: 69 [209920/225000 (93%)] Loss: 15200.158203\n",
      "Train Epoch: 69 [211328/225000 (94%)] Loss: 14930.226562\n",
      "Train Epoch: 69 [212736/225000 (95%)] Loss: 15087.193359\n",
      "Train Epoch: 69 [214144/225000 (95%)] Loss: 14921.478516\n",
      "Train Epoch: 69 [215552/225000 (96%)] Loss: 15490.989258\n",
      "Train Epoch: 69 [216960/225000 (96%)] Loss: 14884.713867\n",
      "Train Epoch: 69 [218368/225000 (97%)] Loss: 15420.481445\n",
      "Train Epoch: 69 [219776/225000 (98%)] Loss: 14918.962891\n",
      "Train Epoch: 69 [221184/225000 (98%)] Loss: 14865.112305\n",
      "Train Epoch: 69 [222592/225000 (99%)] Loss: 15680.488281\n",
      "Train Epoch: 69 [224000/225000 (100%)] Loss: 15334.436523\n",
      "    epoch          : 69\n",
      "    loss           : 15074.828543844213\n",
      "    val_loss       : 15103.528615684838\n",
      "Train Epoch: 70 [128/225000 (0%)] Loss: 14688.138672\n",
      "Train Epoch: 70 [1536/225000 (1%)] Loss: 15600.947266\n",
      "Train Epoch: 70 [2944/225000 (1%)] Loss: 15177.589844\n",
      "Train Epoch: 70 [4352/225000 (2%)] Loss: 15018.380859\n",
      "Train Epoch: 70 [5760/225000 (3%)] Loss: 14625.182617\n",
      "Train Epoch: 70 [7168/225000 (3%)] Loss: 15077.205078\n",
      "Train Epoch: 70 [8576/225000 (4%)] Loss: 14716.756836\n",
      "Train Epoch: 70 [9984/225000 (4%)] Loss: 15418.621094\n",
      "Train Epoch: 70 [11392/225000 (5%)] Loss: 14949.710938\n",
      "Train Epoch: 70 [12800/225000 (6%)] Loss: 15117.815430\n",
      "Train Epoch: 70 [14208/225000 (6%)] Loss: 15008.659180\n",
      "Train Epoch: 70 [15616/225000 (7%)] Loss: 14610.849609\n",
      "Train Epoch: 70 [17024/225000 (8%)] Loss: 14829.244141\n",
      "Train Epoch: 70 [18432/225000 (8%)] Loss: 15296.023438\n",
      "Train Epoch: 70 [19840/225000 (9%)] Loss: 14965.846680\n",
      "Train Epoch: 70 [21248/225000 (9%)] Loss: 14739.260742\n",
      "Train Epoch: 70 [22656/225000 (10%)] Loss: 14846.718750\n",
      "Train Epoch: 70 [24064/225000 (11%)] Loss: 15242.435547\n",
      "Train Epoch: 70 [25472/225000 (11%)] Loss: 14598.903320\n",
      "Train Epoch: 70 [26880/225000 (12%)] Loss: 15338.437500\n",
      "Train Epoch: 70 [28288/225000 (13%)] Loss: 15490.918945\n",
      "Train Epoch: 70 [29696/225000 (13%)] Loss: 15069.690430\n",
      "Train Epoch: 70 [31104/225000 (14%)] Loss: 15077.249023\n",
      "Train Epoch: 70 [32512/225000 (14%)] Loss: 14819.117188\n",
      "Train Epoch: 70 [33920/225000 (15%)] Loss: 15121.262695\n",
      "Train Epoch: 70 [35328/225000 (16%)] Loss: 14746.964844\n",
      "Train Epoch: 70 [36736/225000 (16%)] Loss: 14997.618164\n",
      "Train Epoch: 70 [38144/225000 (17%)] Loss: 15127.320312\n",
      "Train Epoch: 70 [39552/225000 (18%)] Loss: 15099.104492\n",
      "Train Epoch: 70 [40960/225000 (18%)] Loss: 15068.250977\n",
      "Train Epoch: 70 [42368/225000 (19%)] Loss: 15475.975586\n",
      "Train Epoch: 70 [43776/225000 (19%)] Loss: 15469.567383\n",
      "Train Epoch: 70 [45184/225000 (20%)] Loss: 14921.008789\n",
      "Train Epoch: 70 [46592/225000 (21%)] Loss: 15220.245117\n",
      "Train Epoch: 70 [48000/225000 (21%)] Loss: 15333.220703\n",
      "Train Epoch: 70 [49408/225000 (22%)] Loss: 15132.593750\n",
      "Train Epoch: 70 [50816/225000 (23%)] Loss: 15112.123047\n",
      "Train Epoch: 70 [52224/225000 (23%)] Loss: 15366.519531\n",
      "Train Epoch: 70 [53632/225000 (24%)] Loss: 15007.625000\n",
      "Train Epoch: 70 [55040/225000 (24%)] Loss: 14879.990234\n",
      "Train Epoch: 70 [56448/225000 (25%)] Loss: 15084.397461\n",
      "Train Epoch: 70 [57856/225000 (26%)] Loss: 14881.417969\n",
      "Train Epoch: 70 [59264/225000 (26%)] Loss: 15016.461914\n",
      "Train Epoch: 70 [60672/225000 (27%)] Loss: 15143.331055\n",
      "Train Epoch: 70 [62080/225000 (28%)] Loss: 14814.770508\n",
      "Train Epoch: 70 [63488/225000 (28%)] Loss: 15193.193359\n",
      "Train Epoch: 70 [64896/225000 (29%)] Loss: 14705.281250\n",
      "Train Epoch: 70 [66304/225000 (29%)] Loss: 15018.485352\n",
      "Train Epoch: 70 [67712/225000 (30%)] Loss: 15374.815430\n",
      "Train Epoch: 70 [69120/225000 (31%)] Loss: 14815.941406\n",
      "Train Epoch: 70 [70528/225000 (31%)] Loss: 15298.726562\n",
      "Train Epoch: 70 [71936/225000 (32%)] Loss: 15462.628906\n",
      "Train Epoch: 70 [73344/225000 (33%)] Loss: 15146.236328\n",
      "Train Epoch: 70 [74752/225000 (33%)] Loss: 15206.357422\n",
      "Train Epoch: 70 [76160/225000 (34%)] Loss: 15357.321289\n",
      "Train Epoch: 70 [77568/225000 (34%)] Loss: 14995.980469\n",
      "Train Epoch: 70 [78976/225000 (35%)] Loss: 14867.605469\n",
      "Train Epoch: 70 [80384/225000 (36%)] Loss: 15359.445312\n",
      "Train Epoch: 70 [81792/225000 (36%)] Loss: 14944.957031\n",
      "Train Epoch: 70 [83200/225000 (37%)] Loss: 14417.010742\n",
      "Train Epoch: 70 [84608/225000 (38%)] Loss: 14849.346680\n",
      "Train Epoch: 70 [86016/225000 (38%)] Loss: 15009.071289\n",
      "Train Epoch: 70 [87424/225000 (39%)] Loss: 14705.623047\n",
      "Train Epoch: 70 [88832/225000 (39%)] Loss: 15129.730469\n",
      "Train Epoch: 70 [90240/225000 (40%)] Loss: 15164.003906\n",
      "Train Epoch: 70 [91648/225000 (41%)] Loss: 14855.269531\n",
      "Train Epoch: 70 [93056/225000 (41%)] Loss: 15334.341797\n",
      "Train Epoch: 70 [94464/225000 (42%)] Loss: 15252.915039\n",
      "Train Epoch: 70 [95872/225000 (43%)] Loss: 15402.201172\n",
      "Train Epoch: 70 [97280/225000 (43%)] Loss: 15240.062500\n",
      "Train Epoch: 70 [98688/225000 (44%)] Loss: 15049.048828\n",
      "Train Epoch: 70 [100096/225000 (44%)] Loss: 14845.107422\n",
      "Train Epoch: 70 [101504/225000 (45%)] Loss: 15092.476562\n",
      "Train Epoch: 70 [102912/225000 (46%)] Loss: 14949.990234\n",
      "Train Epoch: 70 [104320/225000 (46%)] Loss: 14844.532227\n",
      "Train Epoch: 70 [105728/225000 (47%)] Loss: 14542.959961\n",
      "Train Epoch: 70 [107136/225000 (48%)] Loss: 14992.010742\n",
      "Train Epoch: 70 [108544/225000 (48%)] Loss: 15094.458984\n",
      "Train Epoch: 70 [109952/225000 (49%)] Loss: 15083.319336\n",
      "Train Epoch: 70 [111360/225000 (49%)] Loss: 15746.682617\n",
      "Train Epoch: 70 [112768/225000 (50%)] Loss: 14983.844727\n",
      "Train Epoch: 70 [114176/225000 (51%)] Loss: 14864.416016\n",
      "Train Epoch: 70 [115584/225000 (51%)] Loss: 15121.540039\n",
      "Train Epoch: 70 [116992/225000 (52%)] Loss: 14817.321289\n",
      "Train Epoch: 70 [118400/225000 (53%)] Loss: 15482.587891\n",
      "Train Epoch: 70 [119808/225000 (53%)] Loss: 15338.553711\n",
      "Train Epoch: 70 [121216/225000 (54%)] Loss: 14911.660156\n",
      "Train Epoch: 70 [122624/225000 (54%)] Loss: 14987.843750\n",
      "Train Epoch: 70 [124032/225000 (55%)] Loss: 15560.232422\n",
      "Train Epoch: 70 [125440/225000 (56%)] Loss: 15727.561523\n",
      "Train Epoch: 70 [126848/225000 (56%)] Loss: 15007.833984\n",
      "Train Epoch: 70 [128256/225000 (57%)] Loss: 15251.675781\n",
      "Train Epoch: 70 [129664/225000 (58%)] Loss: 15496.251953\n",
      "Train Epoch: 70 [131072/225000 (58%)] Loss: 15246.889648\n",
      "Train Epoch: 70 [132480/225000 (59%)] Loss: 15000.878906\n",
      "Train Epoch: 70 [133888/225000 (60%)] Loss: 15457.943359\n",
      "Train Epoch: 70 [135296/225000 (60%)] Loss: 15045.873047\n",
      "Train Epoch: 70 [136704/225000 (61%)] Loss: 15389.880859\n",
      "Train Epoch: 70 [138112/225000 (61%)] Loss: 15068.862305\n",
      "Train Epoch: 70 [139520/225000 (62%)] Loss: 15546.807617\n",
      "Train Epoch: 70 [140928/225000 (63%)] Loss: 14797.690430\n",
      "Train Epoch: 70 [142336/225000 (63%)] Loss: 15217.399414\n",
      "Train Epoch: 70 [143744/225000 (64%)] Loss: 14805.096680\n",
      "Train Epoch: 70 [145152/225000 (65%)] Loss: 15003.415039\n",
      "Train Epoch: 70 [146560/225000 (65%)] Loss: 15100.542969\n",
      "Train Epoch: 70 [147968/225000 (66%)] Loss: 15251.451172\n",
      "Train Epoch: 70 [149376/225000 (66%)] Loss: 14950.722656\n",
      "Train Epoch: 70 [150784/225000 (67%)] Loss: 14809.237305\n",
      "Train Epoch: 70 [152192/225000 (68%)] Loss: 15312.044922\n",
      "Train Epoch: 70 [153600/225000 (68%)] Loss: 15180.234375\n",
      "Train Epoch: 70 [155008/225000 (69%)] Loss: 14908.688477\n",
      "Train Epoch: 70 [156416/225000 (70%)] Loss: 15140.157227\n",
      "Train Epoch: 70 [157824/225000 (70%)] Loss: 14647.958984\n",
      "Train Epoch: 70 [159232/225000 (71%)] Loss: 15198.217773\n",
      "Train Epoch: 70 [160640/225000 (71%)] Loss: 15392.653320\n",
      "Train Epoch: 70 [162048/225000 (72%)] Loss: 14460.194336\n",
      "Train Epoch: 70 [163456/225000 (73%)] Loss: 15573.090820\n",
      "Train Epoch: 70 [164864/225000 (73%)] Loss: 15338.626953\n",
      "Train Epoch: 70 [166272/225000 (74%)] Loss: 14737.656250\n",
      "Train Epoch: 70 [167680/225000 (75%)] Loss: 15351.801758\n",
      "Train Epoch: 70 [169088/225000 (75%)] Loss: 14873.679688\n",
      "Train Epoch: 70 [170496/225000 (76%)] Loss: 14986.517578\n",
      "Train Epoch: 70 [171904/225000 (76%)] Loss: 15516.544922\n",
      "Train Epoch: 70 [173312/225000 (77%)] Loss: 15202.655273\n",
      "Train Epoch: 70 [174720/225000 (78%)] Loss: 14992.550781\n",
      "Train Epoch: 70 [176128/225000 (78%)] Loss: 14626.958984\n",
      "Train Epoch: 70 [177536/225000 (79%)] Loss: 14611.667969\n",
      "Train Epoch: 70 [178944/225000 (80%)] Loss: 15379.521484\n",
      "Train Epoch: 70 [180352/225000 (80%)] Loss: 14735.419922\n",
      "Train Epoch: 70 [181760/225000 (81%)] Loss: 14994.762695\n",
      "Train Epoch: 70 [183168/225000 (81%)] Loss: 14594.482422\n",
      "Train Epoch: 70 [184576/225000 (82%)] Loss: 14822.859375\n",
      "Train Epoch: 70 [185984/225000 (83%)] Loss: 14830.490234\n",
      "Train Epoch: 70 [187392/225000 (83%)] Loss: 15150.916016\n",
      "Train Epoch: 70 [188800/225000 (84%)] Loss: 14814.901367\n",
      "Train Epoch: 70 [190208/225000 (85%)] Loss: 14909.239258\n",
      "Train Epoch: 70 [191616/225000 (85%)] Loss: 15472.323242\n",
      "Train Epoch: 70 [193024/225000 (86%)] Loss: 14673.617188\n",
      "Train Epoch: 70 [194432/225000 (86%)] Loss: 14767.088867\n",
      "Train Epoch: 70 [195840/225000 (87%)] Loss: 14775.870117\n",
      "Train Epoch: 70 [197248/225000 (88%)] Loss: 14816.857422\n",
      "Train Epoch: 70 [198656/225000 (88%)] Loss: 15288.029297\n",
      "Train Epoch: 70 [200064/225000 (89%)] Loss: 14857.962891\n",
      "Train Epoch: 70 [201472/225000 (90%)] Loss: 14695.687500\n",
      "Train Epoch: 70 [202880/225000 (90%)] Loss: 15302.620117\n",
      "Train Epoch: 70 [204288/225000 (91%)] Loss: 14837.797852\n",
      "Train Epoch: 70 [205696/225000 (91%)] Loss: 14869.059570\n",
      "Train Epoch: 70 [207104/225000 (92%)] Loss: 14603.947266\n",
      "Train Epoch: 70 [208512/225000 (93%)] Loss: 15040.544922\n",
      "Train Epoch: 70 [209920/225000 (93%)] Loss: 15022.284180\n",
      "Train Epoch: 70 [211328/225000 (94%)] Loss: 15267.666016\n",
      "Train Epoch: 70 [212736/225000 (95%)] Loss: 14654.762695\n",
      "Train Epoch: 70 [214144/225000 (95%)] Loss: 14842.483398\n",
      "Train Epoch: 70 [215552/225000 (96%)] Loss: 14852.184570\n",
      "Train Epoch: 70 [216960/225000 (96%)] Loss: 15236.644531\n",
      "Train Epoch: 70 [218368/225000 (97%)] Loss: 15077.644531\n",
      "Train Epoch: 70 [219776/225000 (98%)] Loss: 15688.641602\n",
      "Train Epoch: 70 [221184/225000 (98%)] Loss: 14923.356445\n",
      "Train Epoch: 70 [222592/225000 (99%)] Loss: 15469.639648\n",
      "Train Epoch: 70 [224000/225000 (100%)] Loss: 14846.244141\n",
      "    epoch          : 70\n",
      "    loss           : 15074.278027010452\n",
      "    val_loss       : 15057.807004111763\n",
      "Train Epoch: 71 [128/225000 (0%)] Loss: 15210.964844\n",
      "Train Epoch: 71 [1536/225000 (1%)] Loss: 14960.950195\n",
      "Train Epoch: 71 [2944/225000 (1%)] Loss: 14666.871094\n",
      "Train Epoch: 71 [4352/225000 (2%)] Loss: 15103.590820\n",
      "Train Epoch: 71 [5760/225000 (3%)] Loss: 15139.397461\n",
      "Train Epoch: 71 [7168/225000 (3%)] Loss: 14853.468750\n",
      "Train Epoch: 71 [8576/225000 (4%)] Loss: 15335.272461\n",
      "Train Epoch: 71 [9984/225000 (4%)] Loss: 15162.496094\n",
      "Train Epoch: 71 [11392/225000 (5%)] Loss: 15155.127930\n",
      "Train Epoch: 71 [12800/225000 (6%)] Loss: 14491.144531\n",
      "Train Epoch: 71 [14208/225000 (6%)] Loss: 14666.824219\n",
      "Train Epoch: 71 [15616/225000 (7%)] Loss: 14971.510742\n",
      "Train Epoch: 71 [17024/225000 (8%)] Loss: 15412.365234\n",
      "Train Epoch: 71 [18432/225000 (8%)] Loss: 14979.299805\n",
      "Train Epoch: 71 [19840/225000 (9%)] Loss: 15006.037109\n",
      "Train Epoch: 71 [21248/225000 (9%)] Loss: 15362.222656\n",
      "Train Epoch: 71 [22656/225000 (10%)] Loss: 15021.534180\n",
      "Train Epoch: 71 [24064/225000 (11%)] Loss: 15097.795898\n",
      "Train Epoch: 71 [25472/225000 (11%)] Loss: 14908.272461\n",
      "Train Epoch: 71 [26880/225000 (12%)] Loss: 14899.287109\n",
      "Train Epoch: 71 [28288/225000 (13%)] Loss: 15255.638672\n",
      "Train Epoch: 71 [29696/225000 (13%)] Loss: 15302.437500\n",
      "Train Epoch: 71 [31104/225000 (14%)] Loss: 14837.474609\n",
      "Train Epoch: 71 [32512/225000 (14%)] Loss: 15286.884766\n",
      "Train Epoch: 71 [33920/225000 (15%)] Loss: 14896.730469\n",
      "Train Epoch: 71 [35328/225000 (16%)] Loss: 15005.086914\n",
      "Train Epoch: 71 [36736/225000 (16%)] Loss: 15826.826172\n",
      "Train Epoch: 71 [38144/225000 (17%)] Loss: 15298.632812\n",
      "Train Epoch: 71 [39552/225000 (18%)] Loss: 15494.875000\n",
      "Train Epoch: 71 [40960/225000 (18%)] Loss: 15198.004883\n",
      "Train Epoch: 71 [42368/225000 (19%)] Loss: 14954.055664\n",
      "Train Epoch: 71 [43776/225000 (19%)] Loss: 15037.583984\n",
      "Train Epoch: 71 [45184/225000 (20%)] Loss: 14853.060547\n",
      "Train Epoch: 71 [46592/225000 (21%)] Loss: 15139.082031\n",
      "Train Epoch: 71 [48000/225000 (21%)] Loss: 15553.482422\n",
      "Train Epoch: 71 [49408/225000 (22%)] Loss: 14958.933594\n",
      "Train Epoch: 71 [50816/225000 (23%)] Loss: 14855.852539\n",
      "Train Epoch: 71 [52224/225000 (23%)] Loss: 15014.809570\n",
      "Train Epoch: 71 [53632/225000 (24%)] Loss: 14562.697266\n",
      "Train Epoch: 71 [55040/225000 (24%)] Loss: 14892.494141\n",
      "Train Epoch: 71 [56448/225000 (25%)] Loss: 15187.395508\n",
      "Train Epoch: 71 [57856/225000 (26%)] Loss: 14932.708984\n",
      "Train Epoch: 71 [59264/225000 (26%)] Loss: 14818.463867\n",
      "Train Epoch: 71 [60672/225000 (27%)] Loss: 14762.660156\n",
      "Train Epoch: 71 [62080/225000 (28%)] Loss: 14770.840820\n",
      "Train Epoch: 71 [63488/225000 (28%)] Loss: 15537.457031\n",
      "Train Epoch: 71 [64896/225000 (29%)] Loss: 15885.703125\n",
      "Train Epoch: 71 [66304/225000 (29%)] Loss: 15156.921875\n",
      "Train Epoch: 71 [67712/225000 (30%)] Loss: 15603.350586\n",
      "Train Epoch: 71 [69120/225000 (31%)] Loss: 15427.400391\n",
      "Train Epoch: 71 [70528/225000 (31%)] Loss: 14748.806641\n",
      "Train Epoch: 71 [71936/225000 (32%)] Loss: 14920.016602\n",
      "Train Epoch: 71 [73344/225000 (33%)] Loss: 15161.769531\n",
      "Train Epoch: 71 [74752/225000 (33%)] Loss: 15190.921875\n",
      "Train Epoch: 71 [76160/225000 (34%)] Loss: 14953.750000\n",
      "Train Epoch: 71 [77568/225000 (34%)] Loss: 15148.546875\n",
      "Train Epoch: 71 [78976/225000 (35%)] Loss: 15143.826172\n",
      "Train Epoch: 71 [80384/225000 (36%)] Loss: 15304.954102\n",
      "Train Epoch: 71 [81792/225000 (36%)] Loss: 14753.866211\n",
      "Train Epoch: 71 [83200/225000 (37%)] Loss: 14821.902344\n",
      "Train Epoch: 71 [84608/225000 (38%)] Loss: 15242.855469\n",
      "Train Epoch: 71 [86016/225000 (38%)] Loss: 15205.925781\n",
      "Train Epoch: 71 [87424/225000 (39%)] Loss: 14939.474609\n",
      "Train Epoch: 71 [88832/225000 (39%)] Loss: 15507.948242\n",
      "Train Epoch: 71 [90240/225000 (40%)] Loss: 15190.569336\n",
      "Train Epoch: 71 [91648/225000 (41%)] Loss: 14950.939453\n",
      "Train Epoch: 71 [93056/225000 (41%)] Loss: 15188.338867\n",
      "Train Epoch: 71 [94464/225000 (42%)] Loss: 15229.244141\n",
      "Train Epoch: 71 [95872/225000 (43%)] Loss: 14808.273438\n",
      "Train Epoch: 71 [97280/225000 (43%)] Loss: 14957.277344\n",
      "Train Epoch: 71 [98688/225000 (44%)] Loss: 15557.299805\n",
      "Train Epoch: 71 [100096/225000 (44%)] Loss: 15436.007812\n",
      "Train Epoch: 71 [101504/225000 (45%)] Loss: 15049.669922\n",
      "Train Epoch: 71 [102912/225000 (46%)] Loss: 15086.037109\n",
      "Train Epoch: 71 [104320/225000 (46%)] Loss: 15143.032227\n",
      "Train Epoch: 71 [105728/225000 (47%)] Loss: 14979.964844\n",
      "Train Epoch: 71 [107136/225000 (48%)] Loss: 15344.142578\n",
      "Train Epoch: 71 [108544/225000 (48%)] Loss: 14593.325195\n",
      "Train Epoch: 71 [109952/225000 (49%)] Loss: 15022.186523\n",
      "Train Epoch: 71 [111360/225000 (49%)] Loss: 14521.311523\n",
      "Train Epoch: 71 [112768/225000 (50%)] Loss: 15129.541016\n",
      "Train Epoch: 71 [114176/225000 (51%)] Loss: 15169.416016\n",
      "Train Epoch: 71 [115584/225000 (51%)] Loss: 14986.958008\n",
      "Train Epoch: 71 [116992/225000 (52%)] Loss: 14767.642578\n",
      "Train Epoch: 71 [118400/225000 (53%)] Loss: 15138.182617\n",
      "Train Epoch: 71 [119808/225000 (53%)] Loss: 15523.046875\n",
      "Train Epoch: 71 [121216/225000 (54%)] Loss: 15028.952148\n",
      "Train Epoch: 71 [122624/225000 (54%)] Loss: 14859.037109\n",
      "Train Epoch: 71 [124032/225000 (55%)] Loss: 15350.290039\n",
      "Train Epoch: 71 [125440/225000 (56%)] Loss: 15122.368164\n",
      "Train Epoch: 71 [126848/225000 (56%)] Loss: 15076.426758\n",
      "Train Epoch: 71 [128256/225000 (57%)] Loss: 15146.906250\n",
      "Train Epoch: 71 [129664/225000 (58%)] Loss: 14882.018555\n",
      "Train Epoch: 71 [131072/225000 (58%)] Loss: 14789.896484\n",
      "Train Epoch: 71 [132480/225000 (59%)] Loss: 15589.783203\n",
      "Train Epoch: 71 [133888/225000 (60%)] Loss: 15089.048828\n",
      "Train Epoch: 71 [135296/225000 (60%)] Loss: 15172.472656\n",
      "Train Epoch: 71 [136704/225000 (61%)] Loss: 14985.759766\n",
      "Train Epoch: 71 [138112/225000 (61%)] Loss: 14774.616211\n",
      "Train Epoch: 71 [139520/225000 (62%)] Loss: 15257.967773\n",
      "Train Epoch: 71 [140928/225000 (63%)] Loss: 14750.894531\n",
      "Train Epoch: 71 [142336/225000 (63%)] Loss: 15176.503906\n",
      "Train Epoch: 71 [143744/225000 (64%)] Loss: 14875.828125\n",
      "Train Epoch: 71 [145152/225000 (65%)] Loss: 14804.248047\n",
      "Train Epoch: 71 [146560/225000 (65%)] Loss: 15049.929688\n",
      "Train Epoch: 71 [147968/225000 (66%)] Loss: 15366.919922\n",
      "Train Epoch: 71 [149376/225000 (66%)] Loss: 15387.151367\n",
      "Train Epoch: 71 [150784/225000 (67%)] Loss: 14785.291016\n",
      "Train Epoch: 71 [152192/225000 (68%)] Loss: 14928.230469\n",
      "Train Epoch: 71 [153600/225000 (68%)] Loss: 14854.387695\n",
      "Train Epoch: 71 [155008/225000 (69%)] Loss: 15418.870117\n",
      "Train Epoch: 71 [156416/225000 (70%)] Loss: 15313.304688\n",
      "Train Epoch: 71 [157824/225000 (70%)] Loss: 15434.462891\n",
      "Train Epoch: 71 [159232/225000 (71%)] Loss: 14851.681641\n",
      "Train Epoch: 71 [160640/225000 (71%)] Loss: 14832.284180\n",
      "Train Epoch: 71 [162048/225000 (72%)] Loss: 15327.026367\n",
      "Train Epoch: 71 [163456/225000 (73%)] Loss: 15294.305664\n",
      "Train Epoch: 71 [164864/225000 (73%)] Loss: 15379.786133\n",
      "Train Epoch: 71 [166272/225000 (74%)] Loss: 14804.403320\n",
      "Train Epoch: 71 [167680/225000 (75%)] Loss: 15428.172852\n",
      "Train Epoch: 71 [169088/225000 (75%)] Loss: 15403.068359\n",
      "Train Epoch: 71 [170496/225000 (76%)] Loss: 15034.136719\n",
      "Train Epoch: 71 [171904/225000 (76%)] Loss: 15461.856445\n",
      "Train Epoch: 71 [173312/225000 (77%)] Loss: 15555.332031\n",
      "Train Epoch: 71 [174720/225000 (78%)] Loss: 15355.729492\n",
      "Train Epoch: 71 [176128/225000 (78%)] Loss: 14907.728516\n",
      "Train Epoch: 71 [177536/225000 (79%)] Loss: 15304.145508\n",
      "Train Epoch: 71 [178944/225000 (80%)] Loss: 14811.895508\n",
      "Train Epoch: 71 [180352/225000 (80%)] Loss: 15406.657227\n",
      "Train Epoch: 71 [181760/225000 (81%)] Loss: 15316.632812\n",
      "Train Epoch: 71 [183168/225000 (81%)] Loss: 14757.847656\n",
      "Train Epoch: 71 [184576/225000 (82%)] Loss: 15183.259766\n",
      "Train Epoch: 71 [185984/225000 (83%)] Loss: 15397.620117\n",
      "Train Epoch: 71 [187392/225000 (83%)] Loss: 15138.416992\n",
      "Train Epoch: 71 [188800/225000 (84%)] Loss: 14920.515625\n",
      "Train Epoch: 71 [190208/225000 (85%)] Loss: 15437.851562\n",
      "Train Epoch: 71 [191616/225000 (85%)] Loss: 15340.016602\n",
      "Train Epoch: 71 [193024/225000 (86%)] Loss: 14666.440430\n",
      "Train Epoch: 71 [194432/225000 (86%)] Loss: 14641.040039\n",
      "Train Epoch: 71 [195840/225000 (87%)] Loss: 15355.045898\n",
      "Train Epoch: 71 [197248/225000 (88%)] Loss: 15667.522461\n",
      "Train Epoch: 71 [198656/225000 (88%)] Loss: 15554.706055\n",
      "Train Epoch: 71 [200064/225000 (89%)] Loss: 15031.550781\n",
      "Train Epoch: 71 [201472/225000 (90%)] Loss: 14943.553711\n",
      "Train Epoch: 71 [202880/225000 (90%)] Loss: 15003.411133\n",
      "Train Epoch: 71 [204288/225000 (91%)] Loss: 15245.553711\n",
      "Train Epoch: 71 [205696/225000 (91%)] Loss: 14876.837891\n",
      "Train Epoch: 71 [207104/225000 (92%)] Loss: 15023.680664\n",
      "Train Epoch: 71 [208512/225000 (93%)] Loss: 15325.718750\n",
      "Train Epoch: 71 [209920/225000 (93%)] Loss: 15534.552734\n",
      "Train Epoch: 71 [211328/225000 (94%)] Loss: 15480.547852\n",
      "Train Epoch: 71 [212736/225000 (95%)] Loss: 15281.346680\n",
      "Train Epoch: 71 [214144/225000 (95%)] Loss: 14712.331055\n",
      "Train Epoch: 71 [215552/225000 (96%)] Loss: 14845.786133\n",
      "Train Epoch: 71 [216960/225000 (96%)] Loss: 14827.296875\n",
      "Train Epoch: 71 [218368/225000 (97%)] Loss: 14979.225586\n",
      "Train Epoch: 71 [219776/225000 (98%)] Loss: 15167.010742\n",
      "Train Epoch: 71 [221184/225000 (98%)] Loss: 14858.075195\n",
      "Train Epoch: 71 [222592/225000 (99%)] Loss: 15182.843750\n",
      "Train Epoch: 71 [224000/225000 (100%)] Loss: 15088.296875\n",
      "    epoch          : 71\n",
      "    loss           : 15074.695077525064\n",
      "    val_loss       : 15055.754733179145\n",
      "Train Epoch: 72 [128/225000 (0%)] Loss: 14735.048828\n",
      "Train Epoch: 72 [1536/225000 (1%)] Loss: 15628.538086\n",
      "Train Epoch: 72 [2944/225000 (1%)] Loss: 14930.082031\n",
      "Train Epoch: 72 [4352/225000 (2%)] Loss: 14897.750977\n",
      "Train Epoch: 72 [5760/225000 (3%)] Loss: 15001.776367\n",
      "Train Epoch: 72 [7168/225000 (3%)] Loss: 14609.359375\n",
      "Train Epoch: 72 [8576/225000 (4%)] Loss: 15087.515625\n",
      "Train Epoch: 72 [9984/225000 (4%)] Loss: 15543.190430\n",
      "Train Epoch: 72 [11392/225000 (5%)] Loss: 15391.369141\n",
      "Train Epoch: 72 [12800/225000 (6%)] Loss: 15139.041992\n",
      "Train Epoch: 72 [14208/225000 (6%)] Loss: 14912.280273\n",
      "Train Epoch: 72 [15616/225000 (7%)] Loss: 14993.875000\n",
      "Train Epoch: 72 [17024/225000 (8%)] Loss: 15473.221680\n",
      "Train Epoch: 72 [18432/225000 (8%)] Loss: 14950.475586\n",
      "Train Epoch: 72 [19840/225000 (9%)] Loss: 15580.282227\n",
      "Train Epoch: 72 [21248/225000 (9%)] Loss: 15165.820312\n",
      "Train Epoch: 72 [22656/225000 (10%)] Loss: 14778.252930\n",
      "Train Epoch: 72 [24064/225000 (11%)] Loss: 15272.941406\n",
      "Train Epoch: 72 [25472/225000 (11%)] Loss: 15375.281250\n",
      "Train Epoch: 72 [26880/225000 (12%)] Loss: 14897.636719\n",
      "Train Epoch: 72 [28288/225000 (13%)] Loss: 15069.400391\n",
      "Train Epoch: 72 [29696/225000 (13%)] Loss: 14720.875000\n",
      "Train Epoch: 72 [31104/225000 (14%)] Loss: 15195.777344\n",
      "Train Epoch: 72 [32512/225000 (14%)] Loss: 14927.210938\n",
      "Train Epoch: 72 [33920/225000 (15%)] Loss: 14922.882812\n",
      "Train Epoch: 72 [35328/225000 (16%)] Loss: 14889.278320\n",
      "Train Epoch: 72 [36736/225000 (16%)] Loss: 14957.167969\n",
      "Train Epoch: 72 [38144/225000 (17%)] Loss: 14918.729492\n",
      "Train Epoch: 72 [39552/225000 (18%)] Loss: 15228.582031\n",
      "Train Epoch: 72 [40960/225000 (18%)] Loss: 14634.457031\n",
      "Train Epoch: 72 [42368/225000 (19%)] Loss: 15039.380859\n",
      "Train Epoch: 72 [43776/225000 (19%)] Loss: 15044.739258\n",
      "Train Epoch: 72 [45184/225000 (20%)] Loss: 14921.299805\n",
      "Train Epoch: 72 [46592/225000 (21%)] Loss: 15215.252930\n",
      "Train Epoch: 72 [48000/225000 (21%)] Loss: 14953.614258\n",
      "Train Epoch: 72 [49408/225000 (22%)] Loss: 15180.124023\n",
      "Train Epoch: 72 [50816/225000 (23%)] Loss: 15285.404297\n",
      "Train Epoch: 72 [52224/225000 (23%)] Loss: 15096.064453\n",
      "Train Epoch: 72 [53632/225000 (24%)] Loss: 14767.602539\n",
      "Train Epoch: 72 [55040/225000 (24%)] Loss: 14697.470703\n",
      "Train Epoch: 72 [56448/225000 (25%)] Loss: 14735.827148\n",
      "Train Epoch: 72 [57856/225000 (26%)] Loss: 15195.965820\n",
      "Train Epoch: 72 [59264/225000 (26%)] Loss: 15270.889648\n",
      "Train Epoch: 72 [60672/225000 (27%)] Loss: 14973.554688\n",
      "Train Epoch: 72 [62080/225000 (28%)] Loss: 15384.548828\n",
      "Train Epoch: 72 [63488/225000 (28%)] Loss: 15213.502930\n",
      "Train Epoch: 72 [64896/225000 (29%)] Loss: 15423.525391\n",
      "Train Epoch: 72 [66304/225000 (29%)] Loss: 15098.450195\n",
      "Train Epoch: 72 [67712/225000 (30%)] Loss: 15074.611328\n",
      "Train Epoch: 72 [69120/225000 (31%)] Loss: 15251.090820\n",
      "Train Epoch: 72 [70528/225000 (31%)] Loss: 15136.593750\n",
      "Train Epoch: 72 [71936/225000 (32%)] Loss: 14736.062500\n",
      "Train Epoch: 72 [73344/225000 (33%)] Loss: 15242.706055\n",
      "Train Epoch: 72 [74752/225000 (33%)] Loss: 15370.011719\n",
      "Train Epoch: 72 [76160/225000 (34%)] Loss: 14997.743164\n",
      "Train Epoch: 72 [77568/225000 (34%)] Loss: 14767.026367\n",
      "Train Epoch: 72 [78976/225000 (35%)] Loss: 15234.733398\n",
      "Train Epoch: 72 [80384/225000 (36%)] Loss: 15137.622070\n",
      "Train Epoch: 72 [81792/225000 (36%)] Loss: 14799.139648\n",
      "Train Epoch: 72 [83200/225000 (37%)] Loss: 15061.225586\n",
      "Train Epoch: 72 [84608/225000 (38%)] Loss: 15097.063477\n",
      "Train Epoch: 72 [86016/225000 (38%)] Loss: 15114.000000\n",
      "Train Epoch: 72 [87424/225000 (39%)] Loss: 15284.669922\n",
      "Train Epoch: 72 [88832/225000 (39%)] Loss: 15044.203125\n",
      "Train Epoch: 72 [90240/225000 (40%)] Loss: 14854.496094\n",
      "Train Epoch: 72 [91648/225000 (41%)] Loss: 15137.405273\n",
      "Train Epoch: 72 [93056/225000 (41%)] Loss: 15112.562500\n",
      "Train Epoch: 72 [94464/225000 (42%)] Loss: 15011.511719\n",
      "Train Epoch: 72 [95872/225000 (43%)] Loss: 15259.853516\n",
      "Train Epoch: 72 [97280/225000 (43%)] Loss: 14669.583984\n",
      "Train Epoch: 72 [98688/225000 (44%)] Loss: 15111.236328\n",
      "Train Epoch: 72 [100096/225000 (44%)] Loss: 15032.234375\n",
      "Train Epoch: 72 [101504/225000 (45%)] Loss: 15218.576172\n",
      "Train Epoch: 72 [102912/225000 (46%)] Loss: 14553.621094\n",
      "Train Epoch: 72 [104320/225000 (46%)] Loss: 14964.522461\n",
      "Train Epoch: 72 [105728/225000 (47%)] Loss: 14998.451172\n",
      "Train Epoch: 72 [107136/225000 (48%)] Loss: 15164.626953\n",
      "Train Epoch: 72 [108544/225000 (48%)] Loss: 15248.363281\n",
      "Train Epoch: 72 [109952/225000 (49%)] Loss: 15257.063477\n",
      "Train Epoch: 72 [111360/225000 (49%)] Loss: 15194.675781\n",
      "Train Epoch: 72 [112768/225000 (50%)] Loss: 14917.308594\n",
      "Train Epoch: 72 [114176/225000 (51%)] Loss: 14800.136719\n",
      "Train Epoch: 72 [115584/225000 (51%)] Loss: 15630.216797\n",
      "Train Epoch: 72 [116992/225000 (52%)] Loss: 15262.043945\n",
      "Train Epoch: 72 [118400/225000 (53%)] Loss: 15113.154297\n",
      "Train Epoch: 72 [119808/225000 (53%)] Loss: 14759.971680\n",
      "Train Epoch: 72 [121216/225000 (54%)] Loss: 14788.800781\n",
      "Train Epoch: 72 [122624/225000 (54%)] Loss: 15028.805664\n",
      "Train Epoch: 72 [124032/225000 (55%)] Loss: 14816.327148\n",
      "Train Epoch: 72 [125440/225000 (56%)] Loss: 15170.894531\n",
      "Train Epoch: 72 [126848/225000 (56%)] Loss: 15286.461914\n",
      "Train Epoch: 72 [128256/225000 (57%)] Loss: 15239.972656\n",
      "Train Epoch: 72 [129664/225000 (58%)] Loss: 14997.284180\n",
      "Train Epoch: 72 [131072/225000 (58%)] Loss: 15758.728516\n",
      "Train Epoch: 72 [132480/225000 (59%)] Loss: 15000.372070\n",
      "Train Epoch: 72 [133888/225000 (60%)] Loss: 15032.346680\n",
      "Train Epoch: 72 [135296/225000 (60%)] Loss: 15232.121094\n",
      "Train Epoch: 72 [136704/225000 (61%)] Loss: 14768.249023\n",
      "Train Epoch: 72 [138112/225000 (61%)] Loss: 15530.147461\n",
      "Train Epoch: 72 [139520/225000 (62%)] Loss: 15403.838867\n",
      "Train Epoch: 72 [140928/225000 (63%)] Loss: 15229.498047\n",
      "Train Epoch: 72 [142336/225000 (63%)] Loss: 14781.773438\n",
      "Train Epoch: 72 [143744/225000 (64%)] Loss: 15388.320312\n",
      "Train Epoch: 72 [145152/225000 (65%)] Loss: 14514.929688\n",
      "Train Epoch: 72 [146560/225000 (65%)] Loss: 14904.633789\n",
      "Train Epoch: 72 [147968/225000 (66%)] Loss: 15006.083008\n",
      "Train Epoch: 72 [149376/225000 (66%)] Loss: 15210.179688\n",
      "Train Epoch: 72 [150784/225000 (67%)] Loss: 15021.832031\n",
      "Train Epoch: 72 [152192/225000 (68%)] Loss: 15210.713867\n",
      "Train Epoch: 72 [153600/225000 (68%)] Loss: 15059.624023\n",
      "Train Epoch: 72 [155008/225000 (69%)] Loss: 14987.213867\n",
      "Train Epoch: 72 [156416/225000 (70%)] Loss: 15000.527344\n",
      "Train Epoch: 72 [157824/225000 (70%)] Loss: 14747.491211\n",
      "Train Epoch: 72 [159232/225000 (71%)] Loss: 15001.270508\n",
      "Train Epoch: 72 [160640/225000 (71%)] Loss: 15478.174805\n",
      "Train Epoch: 72 [162048/225000 (72%)] Loss: 14711.862305\n",
      "Train Epoch: 72 [163456/225000 (73%)] Loss: 14715.614258\n",
      "Train Epoch: 72 [164864/225000 (73%)] Loss: 14986.592773\n",
      "Train Epoch: 72 [166272/225000 (74%)] Loss: 15729.109375\n",
      "Train Epoch: 72 [167680/225000 (75%)] Loss: 15153.191406\n",
      "Train Epoch: 72 [169088/225000 (75%)] Loss: 14865.440430\n",
      "Train Epoch: 72 [170496/225000 (76%)] Loss: 15029.253906\n",
      "Train Epoch: 72 [171904/225000 (76%)] Loss: 15028.340820\n",
      "Train Epoch: 72 [173312/225000 (77%)] Loss: 15505.947266\n",
      "Train Epoch: 72 [174720/225000 (78%)] Loss: 15118.932617\n",
      "Train Epoch: 72 [176128/225000 (78%)] Loss: 15239.396484\n",
      "Train Epoch: 72 [177536/225000 (79%)] Loss: 15708.992188\n",
      "Train Epoch: 72 [178944/225000 (80%)] Loss: 14668.089844\n",
      "Train Epoch: 72 [180352/225000 (80%)] Loss: 14898.752930\n",
      "Train Epoch: 72 [181760/225000 (81%)] Loss: 15099.750977\n",
      "Train Epoch: 72 [183168/225000 (81%)] Loss: 15499.586914\n",
      "Train Epoch: 72 [184576/225000 (82%)] Loss: 15555.099609\n",
      "Train Epoch: 72 [185984/225000 (83%)] Loss: 15376.317383\n",
      "Train Epoch: 72 [187392/225000 (83%)] Loss: 15073.257812\n",
      "Train Epoch: 72 [188800/225000 (84%)] Loss: 14997.415039\n",
      "Train Epoch: 72 [190208/225000 (85%)] Loss: 14807.450195\n",
      "Train Epoch: 72 [191616/225000 (85%)] Loss: 14973.818359\n",
      "Train Epoch: 72 [193024/225000 (86%)] Loss: 15117.296875\n",
      "Train Epoch: 72 [194432/225000 (86%)] Loss: 14844.467773\n",
      "Train Epoch: 72 [195840/225000 (87%)] Loss: 15132.311523\n",
      "Train Epoch: 72 [197248/225000 (88%)] Loss: 15125.587891\n",
      "Train Epoch: 72 [198656/225000 (88%)] Loss: 15096.474609\n",
      "Train Epoch: 72 [200064/225000 (89%)] Loss: 15160.738281\n",
      "Train Epoch: 72 [201472/225000 (90%)] Loss: 15213.401367\n",
      "Train Epoch: 72 [202880/225000 (90%)] Loss: 15657.581055\n",
      "Train Epoch: 72 [204288/225000 (91%)] Loss: 15256.957031\n",
      "Train Epoch: 72 [205696/225000 (91%)] Loss: 15489.321289\n",
      "Train Epoch: 72 [207104/225000 (92%)] Loss: 15227.575195\n",
      "Train Epoch: 72 [208512/225000 (93%)] Loss: 15046.881836\n",
      "Train Epoch: 72 [209920/225000 (93%)] Loss: 15063.732422\n",
      "Train Epoch: 72 [211328/225000 (94%)] Loss: 15267.567383\n",
      "Train Epoch: 72 [212736/225000 (95%)] Loss: 14984.748047\n",
      "Train Epoch: 72 [214144/225000 (95%)] Loss: 14737.722656\n",
      "Train Epoch: 72 [215552/225000 (96%)] Loss: 14731.715820\n",
      "Train Epoch: 72 [216960/225000 (96%)] Loss: 15526.168945\n",
      "Train Epoch: 72 [218368/225000 (97%)] Loss: 14695.629883\n",
      "Train Epoch: 72 [219776/225000 (98%)] Loss: 15000.570312\n",
      "Train Epoch: 72 [221184/225000 (98%)] Loss: 15034.929688\n",
      "Train Epoch: 72 [222592/225000 (99%)] Loss: 15627.653320\n",
      "Train Epoch: 72 [224000/225000 (100%)] Loss: 15059.937500\n",
      "    epoch          : 72\n",
      "    loss           : 15073.818038853633\n",
      "    val_loss       : 15056.012394637326\n",
      "Train Epoch: 73 [128/225000 (0%)] Loss: 15745.980469\n",
      "Train Epoch: 73 [1536/225000 (1%)] Loss: 15113.217773\n",
      "Train Epoch: 73 [2944/225000 (1%)] Loss: 14625.945312\n",
      "Train Epoch: 73 [4352/225000 (2%)] Loss: 14787.319336\n",
      "Train Epoch: 73 [5760/225000 (3%)] Loss: 14808.787109\n",
      "Train Epoch: 73 [7168/225000 (3%)] Loss: 15251.025391\n",
      "Train Epoch: 73 [8576/225000 (4%)] Loss: 15156.236328\n",
      "Train Epoch: 73 [9984/225000 (4%)] Loss: 15080.406250\n",
      "Train Epoch: 73 [11392/225000 (5%)] Loss: 14950.576172\n",
      "Train Epoch: 73 [12800/225000 (6%)] Loss: 14873.458984\n",
      "Train Epoch: 73 [14208/225000 (6%)] Loss: 14793.296875\n",
      "Train Epoch: 73 [15616/225000 (7%)] Loss: 14598.344727\n",
      "Train Epoch: 73 [17024/225000 (8%)] Loss: 15036.291016\n",
      "Train Epoch: 73 [18432/225000 (8%)] Loss: 15183.696289\n",
      "Train Epoch: 73 [19840/225000 (9%)] Loss: 15458.260742\n",
      "Train Epoch: 73 [21248/225000 (9%)] Loss: 15385.833984\n",
      "Train Epoch: 73 [22656/225000 (10%)] Loss: 15401.865234\n",
      "Train Epoch: 73 [24064/225000 (11%)] Loss: 15174.304688\n",
      "Train Epoch: 73 [25472/225000 (11%)] Loss: 15150.305664\n",
      "Train Epoch: 73 [26880/225000 (12%)] Loss: 14820.448242\n",
      "Train Epoch: 73 [28288/225000 (13%)] Loss: 15156.743164\n",
      "Train Epoch: 73 [29696/225000 (13%)] Loss: 15184.119141\n",
      "Train Epoch: 73 [31104/225000 (14%)] Loss: 15355.152344\n",
      "Train Epoch: 73 [32512/225000 (14%)] Loss: 14466.916016\n",
      "Train Epoch: 73 [33920/225000 (15%)] Loss: 15100.416016\n",
      "Train Epoch: 73 [35328/225000 (16%)] Loss: 15272.337891\n",
      "Train Epoch: 73 [36736/225000 (16%)] Loss: 15086.538086\n",
      "Train Epoch: 73 [38144/225000 (17%)] Loss: 14959.603516\n",
      "Train Epoch: 73 [39552/225000 (18%)] Loss: 15025.473633\n",
      "Train Epoch: 73 [40960/225000 (18%)] Loss: 14945.881836\n",
      "Train Epoch: 73 [42368/225000 (19%)] Loss: 14961.418945\n",
      "Train Epoch: 73 [43776/225000 (19%)] Loss: 15469.298828\n",
      "Train Epoch: 73 [45184/225000 (20%)] Loss: 15434.852539\n",
      "Train Epoch: 73 [46592/225000 (21%)] Loss: 15165.390625\n",
      "Train Epoch: 73 [48000/225000 (21%)] Loss: 15292.532227\n",
      "Train Epoch: 73 [49408/225000 (22%)] Loss: 14966.274414\n",
      "Train Epoch: 73 [50816/225000 (23%)] Loss: 15250.511719\n",
      "Train Epoch: 73 [52224/225000 (23%)] Loss: 14950.295898\n",
      "Train Epoch: 73 [53632/225000 (24%)] Loss: 14612.939453\n",
      "Train Epoch: 73 [55040/225000 (24%)] Loss: 15036.423828\n",
      "Train Epoch: 73 [56448/225000 (25%)] Loss: 14817.087891\n",
      "Train Epoch: 73 [57856/225000 (26%)] Loss: 15146.447266\n",
      "Train Epoch: 73 [59264/225000 (26%)] Loss: 15052.413086\n",
      "Train Epoch: 73 [60672/225000 (27%)] Loss: 14995.301758\n",
      "Train Epoch: 73 [62080/225000 (28%)] Loss: 15036.760742\n",
      "Train Epoch: 73 [63488/225000 (28%)] Loss: 15079.566406\n",
      "Train Epoch: 73 [64896/225000 (29%)] Loss: 15269.385742\n",
      "Train Epoch: 73 [66304/225000 (29%)] Loss: 14895.636719\n",
      "Train Epoch: 73 [67712/225000 (30%)] Loss: 14999.194336\n",
      "Train Epoch: 73 [69120/225000 (31%)] Loss: 15000.030273\n",
      "Train Epoch: 73 [70528/225000 (31%)] Loss: 15077.920898\n",
      "Train Epoch: 73 [71936/225000 (32%)] Loss: 14978.475586\n",
      "Train Epoch: 73 [73344/225000 (33%)] Loss: 15132.175781\n",
      "Train Epoch: 73 [74752/225000 (33%)] Loss: 15173.943359\n",
      "Train Epoch: 73 [76160/225000 (34%)] Loss: 15133.011719\n",
      "Train Epoch: 73 [77568/225000 (34%)] Loss: 15027.724609\n",
      "Train Epoch: 73 [78976/225000 (35%)] Loss: 14714.033203\n",
      "Train Epoch: 73 [80384/225000 (36%)] Loss: 15415.750977\n",
      "Train Epoch: 73 [81792/225000 (36%)] Loss: 14921.981445\n",
      "Train Epoch: 73 [83200/225000 (37%)] Loss: 15131.617188\n",
      "Train Epoch: 73 [84608/225000 (38%)] Loss: 14720.523438\n",
      "Train Epoch: 73 [86016/225000 (38%)] Loss: 15198.167969\n",
      "Train Epoch: 73 [87424/225000 (39%)] Loss: 15448.813477\n",
      "Train Epoch: 73 [88832/225000 (39%)] Loss: 15456.596680\n",
      "Train Epoch: 73 [90240/225000 (40%)] Loss: 15631.198242\n",
      "Train Epoch: 73 [91648/225000 (41%)] Loss: 15141.164062\n",
      "Train Epoch: 73 [93056/225000 (41%)] Loss: 15059.178711\n",
      "Train Epoch: 73 [94464/225000 (42%)] Loss: 15286.384766\n",
      "Train Epoch: 73 [95872/225000 (43%)] Loss: 15776.226562\n",
      "Train Epoch: 73 [97280/225000 (43%)] Loss: 15332.259766\n",
      "Train Epoch: 73 [98688/225000 (44%)] Loss: 15146.510742\n",
      "Train Epoch: 73 [100096/225000 (44%)] Loss: 15043.610352\n",
      "Train Epoch: 73 [101504/225000 (45%)] Loss: 14788.865234\n",
      "Train Epoch: 73 [102912/225000 (46%)] Loss: 15118.631836\n",
      "Train Epoch: 73 [104320/225000 (46%)] Loss: 15008.731445\n",
      "Train Epoch: 73 [105728/225000 (47%)] Loss: 14478.565430\n",
      "Train Epoch: 73 [107136/225000 (48%)] Loss: 15284.163086\n",
      "Train Epoch: 73 [108544/225000 (48%)] Loss: 14958.285156\n",
      "Train Epoch: 73 [109952/225000 (49%)] Loss: 15381.732422\n",
      "Train Epoch: 73 [111360/225000 (49%)] Loss: 15120.125977\n",
      "Train Epoch: 73 [112768/225000 (50%)] Loss: 15074.485352\n",
      "Train Epoch: 73 [114176/225000 (51%)] Loss: 15187.730469\n",
      "Train Epoch: 73 [115584/225000 (51%)] Loss: 14603.167969\n",
      "Train Epoch: 73 [116992/225000 (52%)] Loss: 15323.170898\n",
      "Train Epoch: 73 [118400/225000 (53%)] Loss: 14835.946289\n",
      "Train Epoch: 73 [119808/225000 (53%)] Loss: 15678.826172\n",
      "Train Epoch: 73 [121216/225000 (54%)] Loss: 15520.992188\n",
      "Train Epoch: 73 [122624/225000 (54%)] Loss: 14918.135742\n",
      "Train Epoch: 73 [124032/225000 (55%)] Loss: 14813.991211\n",
      "Train Epoch: 73 [125440/225000 (56%)] Loss: 15624.467773\n",
      "Train Epoch: 73 [126848/225000 (56%)] Loss: 14972.822266\n",
      "Train Epoch: 73 [128256/225000 (57%)] Loss: 15213.406250\n",
      "Train Epoch: 73 [129664/225000 (58%)] Loss: 14688.657227\n",
      "Train Epoch: 73 [131072/225000 (58%)] Loss: 14830.722656\n",
      "Train Epoch: 73 [132480/225000 (59%)] Loss: 15365.421875\n",
      "Train Epoch: 73 [133888/225000 (60%)] Loss: 15172.501953\n",
      "Train Epoch: 73 [135296/225000 (60%)] Loss: 14846.321289\n",
      "Train Epoch: 73 [136704/225000 (61%)] Loss: 15104.386719\n",
      "Train Epoch: 73 [138112/225000 (61%)] Loss: 15106.071289\n",
      "Train Epoch: 73 [139520/225000 (62%)] Loss: 15103.158203\n",
      "Train Epoch: 73 [140928/225000 (63%)] Loss: 15130.865234\n",
      "Train Epoch: 73 [142336/225000 (63%)] Loss: 14808.608398\n",
      "Train Epoch: 73 [143744/225000 (64%)] Loss: 15218.474609\n",
      "Train Epoch: 73 [145152/225000 (65%)] Loss: 15049.210938\n",
      "Train Epoch: 73 [146560/225000 (65%)] Loss: 14937.117188\n",
      "Train Epoch: 73 [147968/225000 (66%)] Loss: 15111.934570\n",
      "Train Epoch: 73 [149376/225000 (66%)] Loss: 15346.436523\n",
      "Train Epoch: 73 [150784/225000 (67%)] Loss: 14959.801758\n",
      "Train Epoch: 73 [152192/225000 (68%)] Loss: 15302.765625\n",
      "Train Epoch: 73 [153600/225000 (68%)] Loss: 15155.044922\n",
      "Train Epoch: 73 [155008/225000 (69%)] Loss: 15039.183594\n",
      "Train Epoch: 73 [156416/225000 (70%)] Loss: 14637.806641\n",
      "Train Epoch: 73 [157824/225000 (70%)] Loss: 15198.739258\n",
      "Train Epoch: 73 [159232/225000 (71%)] Loss: 15015.642578\n",
      "Train Epoch: 73 [160640/225000 (71%)] Loss: 14580.237305\n",
      "Train Epoch: 73 [162048/225000 (72%)] Loss: 15594.468750\n",
      "Train Epoch: 73 [163456/225000 (73%)] Loss: 15180.966797\n",
      "Train Epoch: 73 [164864/225000 (73%)] Loss: 14667.142578\n",
      "Train Epoch: 73 [166272/225000 (74%)] Loss: 14709.127930\n",
      "Train Epoch: 73 [167680/225000 (75%)] Loss: 15161.677734\n",
      "Train Epoch: 73 [169088/225000 (75%)] Loss: 14850.412109\n",
      "Train Epoch: 73 [170496/225000 (76%)] Loss: 14982.330078\n",
      "Train Epoch: 73 [171904/225000 (76%)] Loss: 14788.984375\n",
      "Train Epoch: 73 [173312/225000 (77%)] Loss: 15096.718750\n",
      "Train Epoch: 73 [174720/225000 (78%)] Loss: 15021.641602\n",
      "Train Epoch: 73 [176128/225000 (78%)] Loss: 15077.961914\n",
      "Train Epoch: 73 [177536/225000 (79%)] Loss: 15108.397461\n",
      "Train Epoch: 73 [178944/225000 (80%)] Loss: 15567.928711\n",
      "Train Epoch: 73 [180352/225000 (80%)] Loss: 15271.138672\n",
      "Train Epoch: 73 [181760/225000 (81%)] Loss: 15261.758789\n",
      "Train Epoch: 73 [183168/225000 (81%)] Loss: 15437.984375\n",
      "Train Epoch: 73 [184576/225000 (82%)] Loss: 15376.872070\n",
      "Train Epoch: 73 [185984/225000 (83%)] Loss: 15091.090820\n",
      "Train Epoch: 73 [187392/225000 (83%)] Loss: 15260.227539\n",
      "Train Epoch: 73 [188800/225000 (84%)] Loss: 14917.931641\n",
      "Train Epoch: 73 [190208/225000 (85%)] Loss: 14937.672852\n",
      "Train Epoch: 73 [191616/225000 (85%)] Loss: 14917.131836\n",
      "Train Epoch: 73 [193024/225000 (86%)] Loss: 15169.464844\n",
      "Train Epoch: 73 [194432/225000 (86%)] Loss: 15023.675781\n",
      "Train Epoch: 73 [195840/225000 (87%)] Loss: 15181.169922\n",
      "Train Epoch: 73 [197248/225000 (88%)] Loss: 15207.619141\n",
      "Train Epoch: 73 [198656/225000 (88%)] Loss: 14876.856445\n",
      "Train Epoch: 73 [200064/225000 (89%)] Loss: 14898.377930\n",
      "Train Epoch: 73 [201472/225000 (90%)] Loss: 15156.250000\n",
      "Train Epoch: 73 [202880/225000 (90%)] Loss: 15261.122070\n",
      "Train Epoch: 73 [204288/225000 (91%)] Loss: 15044.151367\n",
      "Train Epoch: 73 [205696/225000 (91%)] Loss: 14992.020508\n",
      "Train Epoch: 73 [207104/225000 (92%)] Loss: 15091.958984\n",
      "Train Epoch: 73 [208512/225000 (93%)] Loss: 14946.613281\n",
      "Train Epoch: 73 [209920/225000 (93%)] Loss: 15215.655273\n",
      "Train Epoch: 73 [211328/225000 (94%)] Loss: 14834.561523\n",
      "Train Epoch: 73 [212736/225000 (95%)] Loss: 15198.654297\n",
      "Train Epoch: 73 [214144/225000 (95%)] Loss: 14701.189453\n",
      "Train Epoch: 73 [215552/225000 (96%)] Loss: 14863.621094\n",
      "Train Epoch: 73 [216960/225000 (96%)] Loss: 14622.717773\n",
      "Train Epoch: 73 [218368/225000 (97%)] Loss: 14860.899414\n",
      "Train Epoch: 73 [219776/225000 (98%)] Loss: 15552.591797\n",
      "Train Epoch: 73 [221184/225000 (98%)] Loss: 14983.425781\n",
      "Train Epoch: 73 [222592/225000 (99%)] Loss: 14619.551758\n",
      "Train Epoch: 73 [224000/225000 (100%)] Loss: 15237.388672\n",
      "    epoch          : 73\n",
      "    loss           : 15074.407632630297\n",
      "    val_loss       : 15055.865863625188\n",
      "Train Epoch: 74 [128/225000 (0%)] Loss: 14883.426758\n",
      "Train Epoch: 74 [1536/225000 (1%)] Loss: 15329.665039\n",
      "Train Epoch: 74 [2944/225000 (1%)] Loss: 14510.233398\n",
      "Train Epoch: 74 [4352/225000 (2%)] Loss: 15212.982422\n",
      "Train Epoch: 74 [5760/225000 (3%)] Loss: 14862.694336\n",
      "Train Epoch: 74 [7168/225000 (3%)] Loss: 15301.399414\n",
      "Train Epoch: 74 [8576/225000 (4%)] Loss: 15022.365234\n",
      "Train Epoch: 74 [9984/225000 (4%)] Loss: 15300.156250\n",
      "Train Epoch: 74 [11392/225000 (5%)] Loss: 14845.927734\n",
      "Train Epoch: 74 [12800/225000 (6%)] Loss: 14825.946289\n",
      "Train Epoch: 74 [14208/225000 (6%)] Loss: 15181.726562\n",
      "Train Epoch: 74 [15616/225000 (7%)] Loss: 15242.591797\n",
      "Train Epoch: 74 [17024/225000 (8%)] Loss: 15154.788086\n",
      "Train Epoch: 74 [18432/225000 (8%)] Loss: 15170.506836\n",
      "Train Epoch: 74 [19840/225000 (9%)] Loss: 15324.308594\n",
      "Train Epoch: 74 [21248/225000 (9%)] Loss: 14837.675781\n",
      "Train Epoch: 74 [22656/225000 (10%)] Loss: 15120.130859\n",
      "Train Epoch: 74 [24064/225000 (11%)] Loss: 14642.257812\n",
      "Train Epoch: 74 [25472/225000 (11%)] Loss: 15018.879883\n",
      "Train Epoch: 74 [26880/225000 (12%)] Loss: 15077.152344\n",
      "Train Epoch: 74 [28288/225000 (13%)] Loss: 15208.798828\n",
      "Train Epoch: 74 [29696/225000 (13%)] Loss: 15182.706055\n",
      "Train Epoch: 74 [31104/225000 (14%)] Loss: 15537.372070\n",
      "Train Epoch: 74 [32512/225000 (14%)] Loss: 14633.596680\n",
      "Train Epoch: 74 [33920/225000 (15%)] Loss: 14691.345703\n",
      "Train Epoch: 74 [35328/225000 (16%)] Loss: 14647.146484\n",
      "Train Epoch: 74 [36736/225000 (16%)] Loss: 15131.449219\n",
      "Train Epoch: 74 [38144/225000 (17%)] Loss: 14692.817383\n",
      "Train Epoch: 74 [39552/225000 (18%)] Loss: 15351.400391\n",
      "Train Epoch: 74 [40960/225000 (18%)] Loss: 14866.565430\n",
      "Train Epoch: 74 [42368/225000 (19%)] Loss: 15768.833008\n",
      "Train Epoch: 74 [43776/225000 (19%)] Loss: 14680.263672\n",
      "Train Epoch: 74 [45184/225000 (20%)] Loss: 14906.059570\n",
      "Train Epoch: 74 [46592/225000 (21%)] Loss: 15204.327148\n",
      "Train Epoch: 74 [48000/225000 (21%)] Loss: 14632.545898\n",
      "Train Epoch: 74 [49408/225000 (22%)] Loss: 15023.396484\n",
      "Train Epoch: 74 [50816/225000 (23%)] Loss: 14990.419922\n",
      "Train Epoch: 74 [52224/225000 (23%)] Loss: 15493.425781\n",
      "Train Epoch: 74 [53632/225000 (24%)] Loss: 15037.015625\n",
      "Train Epoch: 74 [55040/225000 (24%)] Loss: 14980.581055\n",
      "Train Epoch: 74 [56448/225000 (25%)] Loss: 15336.964844\n",
      "Train Epoch: 74 [57856/225000 (26%)] Loss: 15033.021484\n",
      "Train Epoch: 74 [59264/225000 (26%)] Loss: 15548.238281\n",
      "Train Epoch: 74 [60672/225000 (27%)] Loss: 14703.691406\n",
      "Train Epoch: 74 [62080/225000 (28%)] Loss: 15050.891602\n",
      "Train Epoch: 74 [63488/225000 (28%)] Loss: 15464.386719\n",
      "Train Epoch: 74 [64896/225000 (29%)] Loss: 14889.080078\n",
      "Train Epoch: 74 [66304/225000 (29%)] Loss: 15203.927734\n",
      "Train Epoch: 74 [67712/225000 (30%)] Loss: 15313.708984\n",
      "Train Epoch: 74 [69120/225000 (31%)] Loss: 15161.582031\n",
      "Train Epoch: 74 [70528/225000 (31%)] Loss: 15019.239258\n",
      "Train Epoch: 74 [71936/225000 (32%)] Loss: 14505.671875\n",
      "Train Epoch: 74 [73344/225000 (33%)] Loss: 15486.985352\n",
      "Train Epoch: 74 [74752/225000 (33%)] Loss: 15155.706055\n",
      "Train Epoch: 74 [76160/225000 (34%)] Loss: 15116.375977\n",
      "Train Epoch: 74 [77568/225000 (34%)] Loss: 15529.295898\n",
      "Train Epoch: 74 [78976/225000 (35%)] Loss: 15010.404297\n",
      "Train Epoch: 74 [80384/225000 (36%)] Loss: 15233.077148\n",
      "Train Epoch: 74 [81792/225000 (36%)] Loss: 15251.805664\n",
      "Train Epoch: 74 [83200/225000 (37%)] Loss: 15025.829102\n",
      "Train Epoch: 74 [84608/225000 (38%)] Loss: 14877.394531\n",
      "Train Epoch: 74 [86016/225000 (38%)] Loss: 15564.334961\n",
      "Train Epoch: 74 [87424/225000 (39%)] Loss: 14960.102539\n",
      "Train Epoch: 74 [88832/225000 (39%)] Loss: 14878.408203\n",
      "Train Epoch: 74 [90240/225000 (40%)] Loss: 15021.293945\n",
      "Train Epoch: 74 [91648/225000 (41%)] Loss: 15556.850586\n",
      "Train Epoch: 74 [93056/225000 (41%)] Loss: 14871.022461\n",
      "Train Epoch: 74 [94464/225000 (42%)] Loss: 15419.548828\n",
      "Train Epoch: 74 [95872/225000 (43%)] Loss: 15309.505859\n",
      "Train Epoch: 74 [97280/225000 (43%)] Loss: 14831.333984\n",
      "Train Epoch: 74 [98688/225000 (44%)] Loss: 14967.625977\n",
      "Train Epoch: 74 [100096/225000 (44%)] Loss: 15107.110352\n",
      "Train Epoch: 74 [101504/225000 (45%)] Loss: 15028.344727\n",
      "Train Epoch: 74 [102912/225000 (46%)] Loss: 15677.149414\n",
      "Train Epoch: 74 [104320/225000 (46%)] Loss: 14773.528320\n",
      "Train Epoch: 74 [105728/225000 (47%)] Loss: 14807.817383\n",
      "Train Epoch: 74 [107136/225000 (48%)] Loss: 15161.445312\n",
      "Train Epoch: 74 [108544/225000 (48%)] Loss: 14907.719727\n",
      "Train Epoch: 74 [109952/225000 (49%)] Loss: 14644.335938\n",
      "Train Epoch: 74 [111360/225000 (49%)] Loss: 14798.320312\n",
      "Train Epoch: 74 [112768/225000 (50%)] Loss: 15240.010742\n",
      "Train Epoch: 74 [114176/225000 (51%)] Loss: 14942.736328\n",
      "Train Epoch: 74 [115584/225000 (51%)] Loss: 15271.596680\n",
      "Train Epoch: 74 [116992/225000 (52%)] Loss: 14754.343750\n",
      "Train Epoch: 74 [118400/225000 (53%)] Loss: 15111.884766\n",
      "Train Epoch: 74 [119808/225000 (53%)] Loss: 15046.267578\n",
      "Train Epoch: 74 [121216/225000 (54%)] Loss: 14885.214844\n",
      "Train Epoch: 74 [122624/225000 (54%)] Loss: 15218.184570\n",
      "Train Epoch: 74 [124032/225000 (55%)] Loss: 14999.601562\n",
      "Train Epoch: 74 [125440/225000 (56%)] Loss: 14843.380859\n",
      "Train Epoch: 74 [126848/225000 (56%)] Loss: 15130.540039\n",
      "Train Epoch: 74 [128256/225000 (57%)] Loss: 15402.559570\n",
      "Train Epoch: 74 [129664/225000 (58%)] Loss: 15141.923828\n",
      "Train Epoch: 74 [131072/225000 (58%)] Loss: 15355.324219\n",
      "Train Epoch: 74 [132480/225000 (59%)] Loss: 15182.291992\n",
      "Train Epoch: 74 [133888/225000 (60%)] Loss: 15536.035156\n",
      "Train Epoch: 74 [135296/225000 (60%)] Loss: 15011.930664\n",
      "Train Epoch: 74 [136704/225000 (61%)] Loss: 15369.758789\n",
      "Train Epoch: 74 [138112/225000 (61%)] Loss: 15193.011719\n",
      "Train Epoch: 74 [139520/225000 (62%)] Loss: 14900.812500\n",
      "Train Epoch: 74 [140928/225000 (63%)] Loss: 14891.306641\n",
      "Train Epoch: 74 [142336/225000 (63%)] Loss: 14515.753906\n",
      "Train Epoch: 74 [143744/225000 (64%)] Loss: 15154.931641\n",
      "Train Epoch: 74 [145152/225000 (65%)] Loss: 15149.789062\n",
      "Train Epoch: 74 [146560/225000 (65%)] Loss: 14930.892578\n",
      "Train Epoch: 74 [147968/225000 (66%)] Loss: 14741.380859\n",
      "Train Epoch: 74 [149376/225000 (66%)] Loss: 14945.396484\n",
      "Train Epoch: 74 [150784/225000 (67%)] Loss: 14739.606445\n",
      "Train Epoch: 74 [152192/225000 (68%)] Loss: 14975.810547\n",
      "Train Epoch: 74 [153600/225000 (68%)] Loss: 14774.338867\n",
      "Train Epoch: 74 [155008/225000 (69%)] Loss: 14690.235352\n",
      "Train Epoch: 74 [156416/225000 (70%)] Loss: 15336.695312\n",
      "Train Epoch: 74 [157824/225000 (70%)] Loss: 15124.709961\n",
      "Train Epoch: 74 [159232/225000 (71%)] Loss: 14751.771484\n",
      "Train Epoch: 74 [160640/225000 (71%)] Loss: 14941.935547\n",
      "Train Epoch: 74 [162048/225000 (72%)] Loss: 14920.813477\n",
      "Train Epoch: 74 [163456/225000 (73%)] Loss: 15410.933594\n",
      "Train Epoch: 74 [164864/225000 (73%)] Loss: 14934.026367\n",
      "Train Epoch: 74 [166272/225000 (74%)] Loss: 15471.980469\n",
      "Train Epoch: 74 [167680/225000 (75%)] Loss: 15072.195312\n",
      "Train Epoch: 74 [169088/225000 (75%)] Loss: 15635.096680\n",
      "Train Epoch: 74 [170496/225000 (76%)] Loss: 14850.586914\n",
      "Train Epoch: 74 [171904/225000 (76%)] Loss: 14824.780273\n",
      "Train Epoch: 74 [173312/225000 (77%)] Loss: 15079.268555\n",
      "Train Epoch: 74 [174720/225000 (78%)] Loss: 15101.364258\n",
      "Train Epoch: 74 [176128/225000 (78%)] Loss: 14945.108398\n",
      "Train Epoch: 74 [177536/225000 (79%)] Loss: 18137.199219\n",
      "Train Epoch: 74 [178944/225000 (80%)] Loss: 14730.759766\n",
      "Train Epoch: 74 [180352/225000 (80%)] Loss: 15322.125000\n",
      "Train Epoch: 74 [181760/225000 (81%)] Loss: 14905.749023\n",
      "Train Epoch: 74 [183168/225000 (81%)] Loss: 15031.794922\n",
      "Train Epoch: 74 [184576/225000 (82%)] Loss: 15084.401367\n",
      "Train Epoch: 74 [185984/225000 (83%)] Loss: 14793.796875\n",
      "Train Epoch: 74 [187392/225000 (83%)] Loss: 15203.961914\n",
      "Train Epoch: 74 [188800/225000 (84%)] Loss: 15234.707031\n",
      "Train Epoch: 74 [190208/225000 (85%)] Loss: 15452.428711\n",
      "Train Epoch: 74 [191616/225000 (85%)] Loss: 14776.622070\n",
      "Train Epoch: 74 [193024/225000 (86%)] Loss: 14476.839844\n",
      "Train Epoch: 74 [194432/225000 (86%)] Loss: 15677.255859\n",
      "Train Epoch: 74 [195840/225000 (87%)] Loss: 14614.681641\n",
      "Train Epoch: 74 [197248/225000 (88%)] Loss: 15395.176758\n",
      "Train Epoch: 74 [198656/225000 (88%)] Loss: 14760.875000\n",
      "Train Epoch: 74 [200064/225000 (89%)] Loss: 15224.957031\n",
      "Train Epoch: 74 [201472/225000 (90%)] Loss: 14609.622070\n",
      "Train Epoch: 74 [202880/225000 (90%)] Loss: 15072.542969\n",
      "Train Epoch: 74 [204288/225000 (91%)] Loss: 14916.739258\n",
      "Train Epoch: 74 [205696/225000 (91%)] Loss: 15605.057617\n",
      "Train Epoch: 74 [207104/225000 (92%)] Loss: 15139.389648\n",
      "Train Epoch: 74 [208512/225000 (93%)] Loss: 15005.849609\n",
      "Train Epoch: 74 [209920/225000 (93%)] Loss: 14854.529297\n",
      "Train Epoch: 74 [211328/225000 (94%)] Loss: 15006.272461\n",
      "Train Epoch: 74 [212736/225000 (95%)] Loss: 14822.525391\n",
      "Train Epoch: 74 [214144/225000 (95%)] Loss: 15191.530273\n",
      "Train Epoch: 74 [215552/225000 (96%)] Loss: 15713.661133\n",
      "Train Epoch: 74 [216960/225000 (96%)] Loss: 14793.538086\n",
      "Train Epoch: 74 [218368/225000 (97%)] Loss: 14729.013672\n",
      "Train Epoch: 74 [219776/225000 (98%)] Loss: 15133.505859\n",
      "Train Epoch: 74 [221184/225000 (98%)] Loss: 15217.446289\n",
      "Train Epoch: 74 [222592/225000 (99%)] Loss: 14754.950195\n",
      "Train Epoch: 74 [224000/225000 (100%)] Loss: 14752.992188\n",
      "    epoch          : 74\n",
      "    loss           : 15076.331371320393\n",
      "    val_loss       : 15063.875408759835\n",
      "Train Epoch: 75 [128/225000 (0%)] Loss: 15048.349609\n",
      "Train Epoch: 75 [1536/225000 (1%)] Loss: 15050.397461\n",
      "Train Epoch: 75 [2944/225000 (1%)] Loss: 15107.586914\n",
      "Train Epoch: 75 [4352/225000 (2%)] Loss: 15275.529297\n",
      "Train Epoch: 75 [5760/225000 (3%)] Loss: 14879.336914\n",
      "Train Epoch: 75 [7168/225000 (3%)] Loss: 14739.822266\n",
      "Train Epoch: 75 [8576/225000 (4%)] Loss: 14941.325195\n",
      "Train Epoch: 75 [9984/225000 (4%)] Loss: 15268.744141\n",
      "Train Epoch: 75 [11392/225000 (5%)] Loss: 14974.522461\n",
      "Train Epoch: 75 [12800/225000 (6%)] Loss: 15159.273438\n",
      "Train Epoch: 75 [14208/225000 (6%)] Loss: 15059.678711\n",
      "Train Epoch: 75 [15616/225000 (7%)] Loss: 15099.886719\n",
      "Train Epoch: 75 [17024/225000 (8%)] Loss: 14699.447266\n",
      "Train Epoch: 75 [18432/225000 (8%)] Loss: 15189.616211\n",
      "Train Epoch: 75 [19840/225000 (9%)] Loss: 15080.712891\n",
      "Train Epoch: 75 [21248/225000 (9%)] Loss: 14809.764648\n",
      "Train Epoch: 75 [22656/225000 (10%)] Loss: 14954.691406\n",
      "Train Epoch: 75 [24064/225000 (11%)] Loss: 14990.083008\n",
      "Train Epoch: 75 [25472/225000 (11%)] Loss: 14661.644531\n",
      "Train Epoch: 75 [26880/225000 (12%)] Loss: 14777.632812\n",
      "Train Epoch: 75 [28288/225000 (13%)] Loss: 14914.083008\n",
      "Train Epoch: 75 [29696/225000 (13%)] Loss: 15248.856445\n",
      "Train Epoch: 75 [31104/225000 (14%)] Loss: 14829.140625\n",
      "Train Epoch: 75 [32512/225000 (14%)] Loss: 14893.876953\n",
      "Train Epoch: 75 [33920/225000 (15%)] Loss: 14964.935547\n",
      "Train Epoch: 75 [35328/225000 (16%)] Loss: 14966.327148\n",
      "Train Epoch: 75 [36736/225000 (16%)] Loss: 15447.915039\n",
      "Train Epoch: 75 [38144/225000 (17%)] Loss: 15401.655273\n",
      "Train Epoch: 75 [39552/225000 (18%)] Loss: 14931.588867\n",
      "Train Epoch: 75 [40960/225000 (18%)] Loss: 15163.748047\n",
      "Train Epoch: 75 [42368/225000 (19%)] Loss: 15268.077148\n",
      "Train Epoch: 75 [43776/225000 (19%)] Loss: 14998.850586\n",
      "Train Epoch: 75 [45184/225000 (20%)] Loss: 15020.745117\n",
      "Train Epoch: 75 [46592/225000 (21%)] Loss: 14800.640625\n",
      "Train Epoch: 75 [48000/225000 (21%)] Loss: 15110.303711\n",
      "Train Epoch: 75 [49408/225000 (22%)] Loss: 15145.009766\n",
      "Train Epoch: 75 [50816/225000 (23%)] Loss: 15175.288086\n",
      "Train Epoch: 75 [52224/225000 (23%)] Loss: 15034.594727\n",
      "Train Epoch: 75 [53632/225000 (24%)] Loss: 14578.937500\n",
      "Train Epoch: 75 [55040/225000 (24%)] Loss: 15499.745117\n",
      "Train Epoch: 75 [56448/225000 (25%)] Loss: 14909.024414\n",
      "Train Epoch: 75 [57856/225000 (26%)] Loss: 14928.003906\n",
      "Train Epoch: 75 [59264/225000 (26%)] Loss: 15674.553711\n",
      "Train Epoch: 75 [60672/225000 (27%)] Loss: 15483.098633\n",
      "Train Epoch: 75 [62080/225000 (28%)] Loss: 15265.827148\n",
      "Train Epoch: 75 [63488/225000 (28%)] Loss: 14940.331055\n",
      "Train Epoch: 75 [64896/225000 (29%)] Loss: 15206.776367\n",
      "Train Epoch: 75 [66304/225000 (29%)] Loss: 14612.266602\n",
      "Train Epoch: 75 [67712/225000 (30%)] Loss: 15230.820312\n",
      "Train Epoch: 75 [69120/225000 (31%)] Loss: 15364.041016\n",
      "Train Epoch: 75 [70528/225000 (31%)] Loss: 14872.511719\n",
      "Train Epoch: 75 [71936/225000 (32%)] Loss: 15016.926758\n",
      "Train Epoch: 75 [73344/225000 (33%)] Loss: 15328.210938\n",
      "Train Epoch: 75 [74752/225000 (33%)] Loss: 14915.500977\n",
      "Train Epoch: 75 [76160/225000 (34%)] Loss: 14930.593750\n",
      "Train Epoch: 75 [77568/225000 (34%)] Loss: 15168.098633\n",
      "Train Epoch: 75 [78976/225000 (35%)] Loss: 14809.725586\n",
      "Train Epoch: 75 [80384/225000 (36%)] Loss: 15072.953125\n",
      "Train Epoch: 75 [81792/225000 (36%)] Loss: 15099.875977\n",
      "Train Epoch: 75 [83200/225000 (37%)] Loss: 14797.088867\n",
      "Train Epoch: 75 [84608/225000 (38%)] Loss: 14793.221680\n",
      "Train Epoch: 75 [86016/225000 (38%)] Loss: 14927.464844\n",
      "Train Epoch: 75 [87424/225000 (39%)] Loss: 14824.211914\n",
      "Train Epoch: 75 [88832/225000 (39%)] Loss: 14797.401367\n",
      "Train Epoch: 75 [90240/225000 (40%)] Loss: 14925.241211\n",
      "Train Epoch: 75 [91648/225000 (41%)] Loss: 15126.567383\n",
      "Train Epoch: 75 [93056/225000 (41%)] Loss: 15237.109375\n",
      "Train Epoch: 75 [94464/225000 (42%)] Loss: 14684.109375\n",
      "Train Epoch: 75 [95872/225000 (43%)] Loss: 14676.096680\n",
      "Train Epoch: 75 [97280/225000 (43%)] Loss: 14893.384766\n",
      "Train Epoch: 75 [98688/225000 (44%)] Loss: 15071.002930\n",
      "Train Epoch: 75 [100096/225000 (44%)] Loss: 14517.695312\n",
      "Train Epoch: 75 [101504/225000 (45%)] Loss: 14977.431641\n",
      "Train Epoch: 75 [102912/225000 (46%)] Loss: 14517.344727\n",
      "Train Epoch: 75 [104320/225000 (46%)] Loss: 15096.456055\n",
      "Train Epoch: 75 [105728/225000 (47%)] Loss: 15005.751953\n",
      "Train Epoch: 75 [107136/225000 (48%)] Loss: 14883.735352\n",
      "Train Epoch: 75 [108544/225000 (48%)] Loss: 14982.657227\n",
      "Train Epoch: 75 [109952/225000 (49%)] Loss: 15552.268555\n",
      "Train Epoch: 75 [111360/225000 (49%)] Loss: 15367.260742\n",
      "Train Epoch: 75 [112768/225000 (50%)] Loss: 14769.142578\n",
      "Train Epoch: 75 [114176/225000 (51%)] Loss: 15143.466797\n",
      "Train Epoch: 75 [115584/225000 (51%)] Loss: 15337.207031\n",
      "Train Epoch: 75 [116992/225000 (52%)] Loss: 15273.459961\n",
      "Train Epoch: 75 [118400/225000 (53%)] Loss: 14809.987305\n",
      "Train Epoch: 75 [119808/225000 (53%)] Loss: 15068.995117\n",
      "Train Epoch: 75 [121216/225000 (54%)] Loss: 15058.232422\n",
      "Train Epoch: 75 [122624/225000 (54%)] Loss: 14772.940430\n",
      "Train Epoch: 75 [124032/225000 (55%)] Loss: 15473.079102\n",
      "Train Epoch: 75 [125440/225000 (56%)] Loss: 15631.873047\n",
      "Train Epoch: 75 [126848/225000 (56%)] Loss: 15048.589844\n",
      "Train Epoch: 75 [128256/225000 (57%)] Loss: 14945.083008\n",
      "Train Epoch: 75 [129664/225000 (58%)] Loss: 14843.952148\n",
      "Train Epoch: 75 [131072/225000 (58%)] Loss: 15107.600586\n",
      "Train Epoch: 75 [132480/225000 (59%)] Loss: 15324.461914\n",
      "Train Epoch: 75 [133888/225000 (60%)] Loss: 14857.229492\n",
      "Train Epoch: 75 [135296/225000 (60%)] Loss: 14916.410156\n",
      "Train Epoch: 75 [136704/225000 (61%)] Loss: 15273.023438\n",
      "Train Epoch: 75 [138112/225000 (61%)] Loss: 15438.499023\n",
      "Train Epoch: 75 [139520/225000 (62%)] Loss: 15097.173828\n",
      "Train Epoch: 75 [140928/225000 (63%)] Loss: 14817.964844\n",
      "Train Epoch: 75 [142336/225000 (63%)] Loss: 14869.145508\n",
      "Train Epoch: 75 [143744/225000 (64%)] Loss: 14668.187500\n",
      "Train Epoch: 75 [145152/225000 (65%)] Loss: 14765.784180\n",
      "Train Epoch: 75 [146560/225000 (65%)] Loss: 14981.218750\n",
      "Train Epoch: 75 [147968/225000 (66%)] Loss: 14789.799805\n",
      "Train Epoch: 75 [149376/225000 (66%)] Loss: 15185.556641\n",
      "Train Epoch: 75 [150784/225000 (67%)] Loss: 15028.327148\n",
      "Train Epoch: 75 [152192/225000 (68%)] Loss: 14834.557617\n",
      "Train Epoch: 75 [153600/225000 (68%)] Loss: 15314.193359\n",
      "Train Epoch: 75 [155008/225000 (69%)] Loss: 15043.811523\n",
      "Train Epoch: 75 [156416/225000 (70%)] Loss: 14862.400391\n",
      "Train Epoch: 75 [157824/225000 (70%)] Loss: 14918.841797\n",
      "Train Epoch: 75 [159232/225000 (71%)] Loss: 15337.838867\n",
      "Train Epoch: 75 [160640/225000 (71%)] Loss: 15022.442383\n",
      "Train Epoch: 75 [162048/225000 (72%)] Loss: 15190.880859\n",
      "Train Epoch: 75 [163456/225000 (73%)] Loss: 14823.368164\n",
      "Train Epoch: 75 [164864/225000 (73%)] Loss: 14985.376953\n",
      "Train Epoch: 75 [166272/225000 (74%)] Loss: 14821.522461\n",
      "Train Epoch: 75 [167680/225000 (75%)] Loss: 15274.085938\n",
      "Train Epoch: 75 [169088/225000 (75%)] Loss: 15151.699219\n",
      "Train Epoch: 75 [170496/225000 (76%)] Loss: 14926.971680\n",
      "Train Epoch: 75 [171904/225000 (76%)] Loss: 15348.330078\n",
      "Train Epoch: 75 [173312/225000 (77%)] Loss: 15167.089844\n",
      "Train Epoch: 75 [174720/225000 (78%)] Loss: 15025.096680\n",
      "Train Epoch: 75 [176128/225000 (78%)] Loss: 15807.948242\n",
      "Train Epoch: 75 [177536/225000 (79%)] Loss: 14983.546875\n",
      "Train Epoch: 75 [178944/225000 (80%)] Loss: 14986.807617\n",
      "Train Epoch: 75 [180352/225000 (80%)] Loss: 14505.849609\n",
      "Train Epoch: 75 [181760/225000 (81%)] Loss: 14995.580078\n",
      "Train Epoch: 75 [183168/225000 (81%)] Loss: 14717.483398\n",
      "Train Epoch: 75 [184576/225000 (82%)] Loss: 14887.667969\n",
      "Train Epoch: 75 [185984/225000 (83%)] Loss: 14843.936523\n",
      "Train Epoch: 75 [187392/225000 (83%)] Loss: 15722.840820\n",
      "Train Epoch: 75 [188800/225000 (84%)] Loss: 15056.590820\n",
      "Train Epoch: 75 [190208/225000 (85%)] Loss: 15037.394531\n",
      "Train Epoch: 75 [191616/225000 (85%)] Loss: 15180.739258\n",
      "Train Epoch: 75 [193024/225000 (86%)] Loss: 15564.527344\n",
      "Train Epoch: 75 [194432/225000 (86%)] Loss: 14664.115234\n",
      "Train Epoch: 75 [195840/225000 (87%)] Loss: 15253.904297\n",
      "Train Epoch: 75 [197248/225000 (88%)] Loss: 14884.669922\n",
      "Train Epoch: 75 [198656/225000 (88%)] Loss: 14973.243164\n",
      "Train Epoch: 75 [200064/225000 (89%)] Loss: 14948.819336\n",
      "Train Epoch: 75 [201472/225000 (90%)] Loss: 15087.024414\n",
      "Train Epoch: 75 [202880/225000 (90%)] Loss: 15009.463867\n",
      "Train Epoch: 75 [204288/225000 (91%)] Loss: 14440.850586\n",
      "Train Epoch: 75 [205696/225000 (91%)] Loss: 15157.204102\n",
      "Train Epoch: 75 [207104/225000 (92%)] Loss: 15204.693359\n",
      "Train Epoch: 75 [208512/225000 (93%)] Loss: 15279.698242\n",
      "Train Epoch: 75 [209920/225000 (93%)] Loss: 14801.835938\n",
      "Train Epoch: 75 [211328/225000 (94%)] Loss: 15408.168945\n",
      "Train Epoch: 75 [212736/225000 (95%)] Loss: 15077.725586\n",
      "Train Epoch: 75 [214144/225000 (95%)] Loss: 15155.704102\n",
      "Train Epoch: 75 [215552/225000 (96%)] Loss: 15090.254883\n",
      "Train Epoch: 75 [216960/225000 (96%)] Loss: 14891.636719\n",
      "Train Epoch: 75 [218368/225000 (97%)] Loss: 14865.789062\n",
      "Train Epoch: 75 [219776/225000 (98%)] Loss: 14835.099609\n",
      "Train Epoch: 75 [221184/225000 (98%)] Loss: 14955.503906\n",
      "Train Epoch: 75 [222592/225000 (99%)] Loss: 14876.729492\n",
      "Train Epoch: 75 [224000/225000 (100%)] Loss: 14750.353516\n",
      "    epoch          : 75\n",
      "    loss           : 15074.580876373187\n",
      "    val_loss       : 15061.03056023346\n",
      "Train Epoch: 76 [128/225000 (0%)] Loss: 15171.672852\n",
      "Train Epoch: 76 [1536/225000 (1%)] Loss: 15685.430664\n",
      "Train Epoch: 76 [2944/225000 (1%)] Loss: 15318.799805\n",
      "Train Epoch: 76 [4352/225000 (2%)] Loss: 15144.282227\n",
      "Train Epoch: 76 [5760/225000 (3%)] Loss: 15193.213867\n",
      "Train Epoch: 76 [7168/225000 (3%)] Loss: 15003.654297\n",
      "Train Epoch: 76 [8576/225000 (4%)] Loss: 15623.967773\n",
      "Train Epoch: 76 [9984/225000 (4%)] Loss: 14894.764648\n",
      "Train Epoch: 76 [11392/225000 (5%)] Loss: 15236.047852\n",
      "Train Epoch: 76 [12800/225000 (6%)] Loss: 15187.103516\n",
      "Train Epoch: 76 [14208/225000 (6%)] Loss: 14894.041992\n",
      "Train Epoch: 76 [15616/225000 (7%)] Loss: 15273.370117\n",
      "Train Epoch: 76 [17024/225000 (8%)] Loss: 15216.775391\n",
      "Train Epoch: 76 [18432/225000 (8%)] Loss: 14888.064453\n",
      "Train Epoch: 76 [19840/225000 (9%)] Loss: 15247.232422\n",
      "Train Epoch: 76 [21248/225000 (9%)] Loss: 14787.348633\n",
      "Train Epoch: 76 [22656/225000 (10%)] Loss: 14798.452148\n",
      "Train Epoch: 76 [24064/225000 (11%)] Loss: 15185.872070\n",
      "Train Epoch: 76 [25472/225000 (11%)] Loss: 15324.233398\n",
      "Train Epoch: 76 [26880/225000 (12%)] Loss: 14861.853516\n",
      "Train Epoch: 76 [28288/225000 (13%)] Loss: 15075.066406\n",
      "Train Epoch: 76 [29696/225000 (13%)] Loss: 14789.075195\n",
      "Train Epoch: 76 [31104/225000 (14%)] Loss: 14852.799805\n",
      "Train Epoch: 76 [32512/225000 (14%)] Loss: 15099.039062\n",
      "Train Epoch: 76 [33920/225000 (15%)] Loss: 14876.436523\n",
      "Train Epoch: 76 [35328/225000 (16%)] Loss: 15270.698242\n",
      "Train Epoch: 76 [36736/225000 (16%)] Loss: 15117.869141\n",
      "Train Epoch: 76 [38144/225000 (17%)] Loss: 14632.349609\n",
      "Train Epoch: 76 [39552/225000 (18%)] Loss: 15096.164062\n",
      "Train Epoch: 76 [40960/225000 (18%)] Loss: 15058.695312\n",
      "Train Epoch: 76 [42368/225000 (19%)] Loss: 14961.240234\n",
      "Train Epoch: 76 [43776/225000 (19%)] Loss: 15137.833008\n",
      "Train Epoch: 76 [45184/225000 (20%)] Loss: 14778.956055\n",
      "Train Epoch: 76 [46592/225000 (21%)] Loss: 14870.285156\n",
      "Train Epoch: 76 [48000/225000 (21%)] Loss: 14976.358398\n",
      "Train Epoch: 76 [49408/225000 (22%)] Loss: 14873.861328\n",
      "Train Epoch: 76 [50816/225000 (23%)] Loss: 14596.175781\n",
      "Train Epoch: 76 [52224/225000 (23%)] Loss: 14802.655273\n",
      "Train Epoch: 76 [53632/225000 (24%)] Loss: 15522.850586\n",
      "Train Epoch: 76 [55040/225000 (24%)] Loss: 15206.392578\n",
      "Train Epoch: 76 [56448/225000 (25%)] Loss: 14748.848633\n",
      "Train Epoch: 76 [57856/225000 (26%)] Loss: 14745.273438\n",
      "Train Epoch: 76 [59264/225000 (26%)] Loss: 15517.867188\n",
      "Train Epoch: 76 [60672/225000 (27%)] Loss: 15149.379883\n",
      "Train Epoch: 76 [62080/225000 (28%)] Loss: 14849.560547\n",
      "Train Epoch: 76 [63488/225000 (28%)] Loss: 15013.751953\n",
      "Train Epoch: 76 [64896/225000 (29%)] Loss: 15132.222656\n",
      "Train Epoch: 76 [66304/225000 (29%)] Loss: 15061.552734\n",
      "Train Epoch: 76 [67712/225000 (30%)] Loss: 14728.200195\n",
      "Train Epoch: 76 [69120/225000 (31%)] Loss: 14456.170898\n",
      "Train Epoch: 76 [70528/225000 (31%)] Loss: 15197.734375\n",
      "Train Epoch: 76 [71936/225000 (32%)] Loss: 15466.567383\n",
      "Train Epoch: 76 [73344/225000 (33%)] Loss: 14770.799805\n",
      "Train Epoch: 76 [74752/225000 (33%)] Loss: 14983.594727\n",
      "Train Epoch: 76 [76160/225000 (34%)] Loss: 15337.514648\n",
      "Train Epoch: 76 [77568/225000 (34%)] Loss: 15047.868164\n",
      "Train Epoch: 76 [78976/225000 (35%)] Loss: 15104.933594\n",
      "Train Epoch: 76 [80384/225000 (36%)] Loss: 15217.096680\n",
      "Train Epoch: 76 [81792/225000 (36%)] Loss: 14649.859375\n",
      "Train Epoch: 76 [83200/225000 (37%)] Loss: 14962.146484\n",
      "Train Epoch: 76 [84608/225000 (38%)] Loss: 14981.215820\n",
      "Train Epoch: 76 [86016/225000 (38%)] Loss: 15007.116211\n",
      "Train Epoch: 76 [87424/225000 (39%)] Loss: 15331.416992\n",
      "Train Epoch: 76 [88832/225000 (39%)] Loss: 15136.769531\n",
      "Train Epoch: 76 [90240/225000 (40%)] Loss: 15122.390625\n",
      "Train Epoch: 76 [91648/225000 (41%)] Loss: 15271.910156\n",
      "Train Epoch: 76 [93056/225000 (41%)] Loss: 15793.831055\n",
      "Train Epoch: 76 [94464/225000 (42%)] Loss: 16165.419922\n",
      "Train Epoch: 76 [95872/225000 (43%)] Loss: 14963.122070\n",
      "Train Epoch: 76 [97280/225000 (43%)] Loss: 14954.203125\n",
      "Train Epoch: 76 [98688/225000 (44%)] Loss: 15551.278320\n",
      "Train Epoch: 76 [100096/225000 (44%)] Loss: 14839.898438\n",
      "Train Epoch: 76 [101504/225000 (45%)] Loss: 14892.031250\n",
      "Train Epoch: 76 [102912/225000 (46%)] Loss: 15373.545898\n",
      "Train Epoch: 76 [104320/225000 (46%)] Loss: 14876.384766\n",
      "Train Epoch: 76 [105728/225000 (47%)] Loss: 14794.081055\n",
      "Train Epoch: 76 [107136/225000 (48%)] Loss: 15363.816406\n",
      "Train Epoch: 76 [108544/225000 (48%)] Loss: 15178.647461\n",
      "Train Epoch: 76 [109952/225000 (49%)] Loss: 15137.369141\n",
      "Train Epoch: 76 [111360/225000 (49%)] Loss: 15166.878906\n",
      "Train Epoch: 76 [112768/225000 (50%)] Loss: 15122.824219\n",
      "Train Epoch: 76 [114176/225000 (51%)] Loss: 15033.830078\n",
      "Train Epoch: 76 [115584/225000 (51%)] Loss: 15096.195312\n",
      "Train Epoch: 76 [116992/225000 (52%)] Loss: 14814.226562\n",
      "Train Epoch: 76 [118400/225000 (53%)] Loss: 15084.533203\n",
      "Train Epoch: 76 [119808/225000 (53%)] Loss: 15260.761719\n",
      "Train Epoch: 76 [121216/225000 (54%)] Loss: 14947.261719\n",
      "Train Epoch: 76 [122624/225000 (54%)] Loss: 15148.440430\n",
      "Train Epoch: 76 [124032/225000 (55%)] Loss: 15141.450195\n",
      "Train Epoch: 76 [125440/225000 (56%)] Loss: 14922.689453\n",
      "Train Epoch: 76 [126848/225000 (56%)] Loss: 15370.891602\n",
      "Train Epoch: 76 [128256/225000 (57%)] Loss: 15736.825195\n",
      "Train Epoch: 76 [129664/225000 (58%)] Loss: 14911.022461\n",
      "Train Epoch: 76 [131072/225000 (58%)] Loss: 15105.758789\n",
      "Train Epoch: 76 [132480/225000 (59%)] Loss: 15128.810547\n",
      "Train Epoch: 76 [133888/225000 (60%)] Loss: 14976.171875\n",
      "Train Epoch: 76 [135296/225000 (60%)] Loss: 15295.326172\n",
      "Train Epoch: 76 [136704/225000 (61%)] Loss: 15127.987305\n",
      "Train Epoch: 76 [138112/225000 (61%)] Loss: 14923.833984\n",
      "Train Epoch: 76 [139520/225000 (62%)] Loss: 14862.751953\n",
      "Train Epoch: 76 [140928/225000 (63%)] Loss: 15523.495117\n",
      "Train Epoch: 76 [142336/225000 (63%)] Loss: 15317.981445\n",
      "Train Epoch: 76 [143744/225000 (64%)] Loss: 14953.796875\n",
      "Train Epoch: 76 [145152/225000 (65%)] Loss: 15055.586914\n",
      "Train Epoch: 76 [146560/225000 (65%)] Loss: 14741.649414\n",
      "Train Epoch: 76 [147968/225000 (66%)] Loss: 15427.356445\n",
      "Train Epoch: 76 [149376/225000 (66%)] Loss: 14767.031250\n",
      "Train Epoch: 76 [150784/225000 (67%)] Loss: 14903.879883\n",
      "Train Epoch: 76 [152192/225000 (68%)] Loss: 15524.493164\n",
      "Train Epoch: 76 [153600/225000 (68%)] Loss: 15346.594727\n",
      "Train Epoch: 76 [155008/225000 (69%)] Loss: 14950.603516\n",
      "Train Epoch: 76 [156416/225000 (70%)] Loss: 14953.948242\n",
      "Train Epoch: 76 [157824/225000 (70%)] Loss: 15193.030273\n",
      "Train Epoch: 76 [159232/225000 (71%)] Loss: 15127.664062\n",
      "Train Epoch: 76 [160640/225000 (71%)] Loss: 15386.418945\n",
      "Train Epoch: 76 [162048/225000 (72%)] Loss: 15350.432617\n",
      "Train Epoch: 76 [163456/225000 (73%)] Loss: 15262.760742\n",
      "Train Epoch: 76 [164864/225000 (73%)] Loss: 14971.755859\n",
      "Train Epoch: 76 [166272/225000 (74%)] Loss: 14761.501953\n",
      "Train Epoch: 76 [167680/225000 (75%)] Loss: 15192.718750\n",
      "Train Epoch: 76 [169088/225000 (75%)] Loss: 14834.817383\n",
      "Train Epoch: 76 [170496/225000 (76%)] Loss: 14712.474609\n",
      "Train Epoch: 76 [171904/225000 (76%)] Loss: 15088.158203\n",
      "Train Epoch: 76 [173312/225000 (77%)] Loss: 14888.499023\n",
      "Train Epoch: 76 [174720/225000 (78%)] Loss: 14941.446289\n",
      "Train Epoch: 76 [176128/225000 (78%)] Loss: 15338.399414\n",
      "Train Epoch: 76 [177536/225000 (79%)] Loss: 15090.369141\n",
      "Train Epoch: 76 [178944/225000 (80%)] Loss: 15244.166016\n",
      "Train Epoch: 76 [180352/225000 (80%)] Loss: 15239.889648\n",
      "Train Epoch: 76 [181760/225000 (81%)] Loss: 14859.276367\n",
      "Train Epoch: 76 [183168/225000 (81%)] Loss: 15029.601562\n",
      "Train Epoch: 76 [184576/225000 (82%)] Loss: 15248.536133\n",
      "Train Epoch: 76 [185984/225000 (83%)] Loss: 14874.788086\n",
      "Train Epoch: 76 [187392/225000 (83%)] Loss: 15574.808594\n",
      "Train Epoch: 76 [188800/225000 (84%)] Loss: 15624.778320\n",
      "Train Epoch: 76 [190208/225000 (85%)] Loss: 15054.459961\n",
      "Train Epoch: 76 [191616/225000 (85%)] Loss: 14781.016602\n",
      "Train Epoch: 76 [193024/225000 (86%)] Loss: 15242.160156\n",
      "Train Epoch: 76 [194432/225000 (86%)] Loss: 14837.840820\n",
      "Train Epoch: 76 [195840/225000 (87%)] Loss: 14553.246094\n",
      "Train Epoch: 76 [197248/225000 (88%)] Loss: 15070.211914\n",
      "Train Epoch: 76 [198656/225000 (88%)] Loss: 14881.846680\n",
      "Train Epoch: 76 [200064/225000 (89%)] Loss: 15857.626953\n",
      "Train Epoch: 76 [201472/225000 (90%)] Loss: 14736.981445\n",
      "Train Epoch: 76 [202880/225000 (90%)] Loss: 15059.501953\n",
      "Train Epoch: 76 [204288/225000 (91%)] Loss: 15147.940430\n",
      "Train Epoch: 76 [205696/225000 (91%)] Loss: 15109.152344\n",
      "Train Epoch: 76 [207104/225000 (92%)] Loss: 14982.178711\n",
      "Train Epoch: 76 [208512/225000 (93%)] Loss: 14988.068359\n",
      "Train Epoch: 76 [209920/225000 (93%)] Loss: 15056.390625\n",
      "Train Epoch: 76 [211328/225000 (94%)] Loss: 14986.807617\n",
      "Train Epoch: 76 [212736/225000 (95%)] Loss: 15238.921875\n",
      "Train Epoch: 76 [214144/225000 (95%)] Loss: 15078.661133\n",
      "Train Epoch: 76 [215552/225000 (96%)] Loss: 14619.065430\n",
      "Train Epoch: 76 [216960/225000 (96%)] Loss: 15061.522461\n",
      "Train Epoch: 76 [218368/225000 (97%)] Loss: 15603.354492\n",
      "Train Epoch: 76 [219776/225000 (98%)] Loss: 14761.918945\n",
      "Train Epoch: 76 [221184/225000 (98%)] Loss: 14552.482422\n",
      "Train Epoch: 76 [222592/225000 (99%)] Loss: 15034.283203\n",
      "Train Epoch: 76 [224000/225000 (100%)] Loss: 15269.382812\n",
      "    epoch          : 76\n",
      "    loss           : 15074.610598758354\n",
      "    val_loss       : 15057.543448635206\n",
      "Train Epoch: 77 [128/225000 (0%)] Loss: 15195.902344\n",
      "Train Epoch: 77 [1536/225000 (1%)] Loss: 14924.686523\n",
      "Train Epoch: 77 [2944/225000 (1%)] Loss: 15285.485352\n",
      "Train Epoch: 77 [4352/225000 (2%)] Loss: 14894.603516\n",
      "Train Epoch: 77 [5760/225000 (3%)] Loss: 15031.631836\n",
      "Train Epoch: 77 [7168/225000 (3%)] Loss: 15559.450195\n",
      "Train Epoch: 77 [8576/225000 (4%)] Loss: 14827.101562\n",
      "Train Epoch: 77 [9984/225000 (4%)] Loss: 14731.931641\n",
      "Train Epoch: 77 [11392/225000 (5%)] Loss: 14416.541992\n",
      "Train Epoch: 77 [12800/225000 (6%)] Loss: 15485.037109\n",
      "Train Epoch: 77 [14208/225000 (6%)] Loss: 14974.053711\n",
      "Train Epoch: 77 [15616/225000 (7%)] Loss: 14720.478516\n",
      "Train Epoch: 77 [17024/225000 (8%)] Loss: 15144.239258\n",
      "Train Epoch: 77 [18432/225000 (8%)] Loss: 15118.547852\n",
      "Train Epoch: 77 [19840/225000 (9%)] Loss: 15137.185547\n",
      "Train Epoch: 77 [21248/225000 (9%)] Loss: 15301.347656\n",
      "Train Epoch: 77 [22656/225000 (10%)] Loss: 15314.994141\n",
      "Train Epoch: 77 [24064/225000 (11%)] Loss: 15011.121094\n",
      "Train Epoch: 77 [25472/225000 (11%)] Loss: 15317.341797\n",
      "Train Epoch: 77 [26880/225000 (12%)] Loss: 14862.355469\n",
      "Train Epoch: 77 [28288/225000 (13%)] Loss: 15362.599609\n",
      "Train Epoch: 77 [29696/225000 (13%)] Loss: 14897.640625\n",
      "Train Epoch: 77 [31104/225000 (14%)] Loss: 15309.855469\n",
      "Train Epoch: 77 [32512/225000 (14%)] Loss: 14940.749023\n",
      "Train Epoch: 77 [33920/225000 (15%)] Loss: 14993.358398\n",
      "Train Epoch: 77 [35328/225000 (16%)] Loss: 15145.375000\n",
      "Train Epoch: 77 [36736/225000 (16%)] Loss: 14990.997070\n",
      "Train Epoch: 77 [38144/225000 (17%)] Loss: 14926.814453\n",
      "Train Epoch: 77 [39552/225000 (18%)] Loss: 15651.810547\n",
      "Train Epoch: 77 [40960/225000 (18%)] Loss: 14768.382812\n",
      "Train Epoch: 77 [42368/225000 (19%)] Loss: 15188.812500\n",
      "Train Epoch: 77 [43776/225000 (19%)] Loss: 15159.957031\n",
      "Train Epoch: 77 [45184/225000 (20%)] Loss: 14969.396484\n",
      "Train Epoch: 77 [46592/225000 (21%)] Loss: 15110.850586\n",
      "Train Epoch: 77 [48000/225000 (21%)] Loss: 15045.643555\n",
      "Train Epoch: 77 [49408/225000 (22%)] Loss: 15258.449219\n",
      "Train Epoch: 77 [50816/225000 (23%)] Loss: 14899.174805\n",
      "Train Epoch: 77 [52224/225000 (23%)] Loss: 15321.857422\n",
      "Train Epoch: 77 [53632/225000 (24%)] Loss: 15195.693359\n",
      "Train Epoch: 77 [55040/225000 (24%)] Loss: 14846.927734\n",
      "Train Epoch: 77 [56448/225000 (25%)] Loss: 15419.534180\n",
      "Train Epoch: 77 [57856/225000 (26%)] Loss: 15024.003906\n",
      "Train Epoch: 77 [59264/225000 (26%)] Loss: 14995.925781\n",
      "Train Epoch: 77 [60672/225000 (27%)] Loss: 15140.253906\n",
      "Train Epoch: 77 [62080/225000 (28%)] Loss: 14882.251953\n",
      "Train Epoch: 77 [63488/225000 (28%)] Loss: 15081.144531\n",
      "Train Epoch: 77 [64896/225000 (29%)] Loss: 15030.516602\n",
      "Train Epoch: 77 [66304/225000 (29%)] Loss: 15199.169922\n",
      "Train Epoch: 77 [67712/225000 (30%)] Loss: 15196.503906\n",
      "Train Epoch: 77 [69120/225000 (31%)] Loss: 14971.869141\n",
      "Train Epoch: 77 [70528/225000 (31%)] Loss: 15060.091797\n",
      "Train Epoch: 77 [71936/225000 (32%)] Loss: 15091.297852\n",
      "Train Epoch: 77 [73344/225000 (33%)] Loss: 15199.486328\n",
      "Train Epoch: 77 [74752/225000 (33%)] Loss: 15226.589844\n",
      "Train Epoch: 77 [76160/225000 (34%)] Loss: 14808.506836\n",
      "Train Epoch: 77 [77568/225000 (34%)] Loss: 15013.524414\n",
      "Train Epoch: 77 [78976/225000 (35%)] Loss: 14715.989258\n",
      "Train Epoch: 77 [80384/225000 (36%)] Loss: 15118.147461\n",
      "Train Epoch: 77 [81792/225000 (36%)] Loss: 15111.041016\n",
      "Train Epoch: 77 [83200/225000 (37%)] Loss: 15387.889648\n",
      "Train Epoch: 77 [84608/225000 (38%)] Loss: 15004.792969\n",
      "Train Epoch: 77 [86016/225000 (38%)] Loss: 14738.734375\n",
      "Train Epoch: 77 [87424/225000 (39%)] Loss: 14841.057617\n",
      "Train Epoch: 77 [88832/225000 (39%)] Loss: 15209.550781\n",
      "Train Epoch: 77 [90240/225000 (40%)] Loss: 14865.306641\n",
      "Train Epoch: 77 [91648/225000 (41%)] Loss: 15193.183594\n",
      "Train Epoch: 77 [93056/225000 (41%)] Loss: 15349.899414\n",
      "Train Epoch: 77 [94464/225000 (42%)] Loss: 15427.001953\n",
      "Train Epoch: 77 [95872/225000 (43%)] Loss: 14619.041992\n",
      "Train Epoch: 77 [97280/225000 (43%)] Loss: 14751.697266\n",
      "Train Epoch: 77 [98688/225000 (44%)] Loss: 15345.376953\n",
      "Train Epoch: 77 [100096/225000 (44%)] Loss: 14882.152344\n",
      "Train Epoch: 77 [101504/225000 (45%)] Loss: 15232.288086\n",
      "Train Epoch: 77 [102912/225000 (46%)] Loss: 15071.213867\n",
      "Train Epoch: 77 [104320/225000 (46%)] Loss: 14606.340820\n",
      "Train Epoch: 77 [105728/225000 (47%)] Loss: 14848.390625\n",
      "Train Epoch: 77 [107136/225000 (48%)] Loss: 15088.656250\n",
      "Train Epoch: 77 [108544/225000 (48%)] Loss: 15260.073242\n",
      "Train Epoch: 77 [109952/225000 (49%)] Loss: 15395.019531\n",
      "Train Epoch: 77 [111360/225000 (49%)] Loss: 15628.485352\n",
      "Train Epoch: 77 [112768/225000 (50%)] Loss: 15087.237305\n",
      "Train Epoch: 77 [114176/225000 (51%)] Loss: 15104.364258\n",
      "Train Epoch: 77 [115584/225000 (51%)] Loss: 14724.786133\n",
      "Train Epoch: 77 [116992/225000 (52%)] Loss: 15030.197266\n",
      "Train Epoch: 77 [118400/225000 (53%)] Loss: 15057.974609\n",
      "Train Epoch: 77 [119808/225000 (53%)] Loss: 15042.072266\n",
      "Train Epoch: 77 [121216/225000 (54%)] Loss: 15035.540039\n",
      "Train Epoch: 77 [122624/225000 (54%)] Loss: 15190.774414\n",
      "Train Epoch: 77 [124032/225000 (55%)] Loss: 14610.473633\n",
      "Train Epoch: 77 [125440/225000 (56%)] Loss: 15206.385742\n",
      "Train Epoch: 77 [126848/225000 (56%)] Loss: 15099.582031\n",
      "Train Epoch: 77 [128256/225000 (57%)] Loss: 14961.731445\n",
      "Train Epoch: 77 [129664/225000 (58%)] Loss: 15278.236328\n",
      "Train Epoch: 77 [131072/225000 (58%)] Loss: 14980.395508\n",
      "Train Epoch: 77 [132480/225000 (59%)] Loss: 15368.402344\n",
      "Train Epoch: 77 [133888/225000 (60%)] Loss: 15307.188477\n",
      "Train Epoch: 77 [135296/225000 (60%)] Loss: 15091.211914\n",
      "Train Epoch: 77 [136704/225000 (61%)] Loss: 15221.083008\n",
      "Train Epoch: 77 [138112/225000 (61%)] Loss: 14762.030273\n",
      "Train Epoch: 77 [139520/225000 (62%)] Loss: 14785.890625\n",
      "Train Epoch: 77 [140928/225000 (63%)] Loss: 15148.647461\n",
      "Train Epoch: 77 [142336/225000 (63%)] Loss: 14567.361328\n",
      "Train Epoch: 77 [143744/225000 (64%)] Loss: 14873.041016\n",
      "Train Epoch: 77 [145152/225000 (65%)] Loss: 15242.795898\n",
      "Train Epoch: 77 [146560/225000 (65%)] Loss: 14603.621094\n",
      "Train Epoch: 77 [147968/225000 (66%)] Loss: 15011.374023\n",
      "Train Epoch: 77 [149376/225000 (66%)] Loss: 15325.329102\n",
      "Train Epoch: 77 [150784/225000 (67%)] Loss: 14936.095703\n",
      "Train Epoch: 77 [152192/225000 (68%)] Loss: 15533.888672\n",
      "Train Epoch: 77 [153600/225000 (68%)] Loss: 14965.609375\n",
      "Train Epoch: 77 [155008/225000 (69%)] Loss: 14755.820312\n",
      "Train Epoch: 77 [156416/225000 (70%)] Loss: 15375.287109\n",
      "Train Epoch: 77 [157824/225000 (70%)] Loss: 14846.997070\n",
      "Train Epoch: 77 [159232/225000 (71%)] Loss: 14570.924805\n",
      "Train Epoch: 77 [160640/225000 (71%)] Loss: 15256.204102\n",
      "Train Epoch: 77 [162048/225000 (72%)] Loss: 15594.385742\n",
      "Train Epoch: 77 [163456/225000 (73%)] Loss: 15073.010742\n",
      "Train Epoch: 77 [164864/225000 (73%)] Loss: 14773.560547\n",
      "Train Epoch: 77 [166272/225000 (74%)] Loss: 14990.160156\n",
      "Train Epoch: 77 [167680/225000 (75%)] Loss: 14792.083008\n",
      "Train Epoch: 77 [169088/225000 (75%)] Loss: 15065.513672\n",
      "Train Epoch: 77 [170496/225000 (76%)] Loss: 14845.952148\n",
      "Train Epoch: 77 [171904/225000 (76%)] Loss: 14987.957031\n",
      "Train Epoch: 77 [173312/225000 (77%)] Loss: 15260.058594\n",
      "Train Epoch: 77 [174720/225000 (78%)] Loss: 15124.588867\n",
      "Train Epoch: 77 [176128/225000 (78%)] Loss: 15597.694336\n",
      "Train Epoch: 77 [177536/225000 (79%)] Loss: 15389.336914\n",
      "Train Epoch: 77 [178944/225000 (80%)] Loss: 15216.462891\n",
      "Train Epoch: 77 [180352/225000 (80%)] Loss: 15288.181641\n",
      "Train Epoch: 77 [181760/225000 (81%)] Loss: 14555.221680\n",
      "Train Epoch: 77 [183168/225000 (81%)] Loss: 15121.700195\n",
      "Train Epoch: 77 [184576/225000 (82%)] Loss: 14752.294922\n",
      "Train Epoch: 77 [185984/225000 (83%)] Loss: 15415.650391\n",
      "Train Epoch: 77 [187392/225000 (83%)] Loss: 15042.991211\n",
      "Train Epoch: 77 [188800/225000 (84%)] Loss: 15087.875000\n",
      "Train Epoch: 77 [190208/225000 (85%)] Loss: 15139.906250\n",
      "Train Epoch: 77 [191616/225000 (85%)] Loss: 15475.121094\n",
      "Train Epoch: 77 [193024/225000 (86%)] Loss: 14792.076172\n",
      "Train Epoch: 77 [194432/225000 (86%)] Loss: 14847.608398\n",
      "Train Epoch: 77 [195840/225000 (87%)] Loss: 14912.569336\n",
      "Train Epoch: 77 [197248/225000 (88%)] Loss: 15276.117188\n",
      "Train Epoch: 77 [198656/225000 (88%)] Loss: 15228.838867\n",
      "Train Epoch: 77 [200064/225000 (89%)] Loss: 14959.049805\n",
      "Train Epoch: 77 [201472/225000 (90%)] Loss: 15151.861328\n",
      "Train Epoch: 77 [202880/225000 (90%)] Loss: 14488.644531\n",
      "Train Epoch: 77 [204288/225000 (91%)] Loss: 15097.771484\n",
      "Train Epoch: 77 [205696/225000 (91%)] Loss: 14803.999023\n",
      "Train Epoch: 77 [207104/225000 (92%)] Loss: 15138.100586\n",
      "Train Epoch: 77 [208512/225000 (93%)] Loss: 15012.386719\n",
      "Train Epoch: 77 [209920/225000 (93%)] Loss: 15952.608398\n",
      "Train Epoch: 77 [211328/225000 (94%)] Loss: 15414.417969\n",
      "Train Epoch: 77 [212736/225000 (95%)] Loss: 15237.029297\n",
      "Train Epoch: 77 [214144/225000 (95%)] Loss: 15297.478516\n",
      "Train Epoch: 77 [215552/225000 (96%)] Loss: 14975.013672\n",
      "Train Epoch: 77 [216960/225000 (96%)] Loss: 15217.889648\n",
      "Train Epoch: 77 [218368/225000 (97%)] Loss: 14857.023438\n",
      "Train Epoch: 77 [219776/225000 (98%)] Loss: 14777.607422\n",
      "Train Epoch: 77 [221184/225000 (98%)] Loss: 15559.908203\n",
      "Train Epoch: 77 [222592/225000 (99%)] Loss: 14940.380859\n",
      "Train Epoch: 77 [224000/225000 (100%)] Loss: 15453.949219\n",
      "    epoch          : 77\n",
      "    loss           : 15074.143628013011\n",
      "    val_loss       : 15056.186193175461\n",
      "Train Epoch: 78 [128/225000 (0%)] Loss: 15052.497070\n",
      "Train Epoch: 78 [1536/225000 (1%)] Loss: 15450.541016\n",
      "Train Epoch: 78 [2944/225000 (1%)] Loss: 15132.899414\n",
      "Train Epoch: 78 [4352/225000 (2%)] Loss: 15178.460938\n",
      "Train Epoch: 78 [5760/225000 (3%)] Loss: 15037.322266\n",
      "Train Epoch: 78 [7168/225000 (3%)] Loss: 14862.356445\n",
      "Train Epoch: 78 [8576/225000 (4%)] Loss: 14920.230469\n",
      "Train Epoch: 78 [9984/225000 (4%)] Loss: 14748.019531\n",
      "Train Epoch: 78 [11392/225000 (5%)] Loss: 15175.022461\n",
      "Train Epoch: 78 [12800/225000 (6%)] Loss: 14989.927734\n",
      "Train Epoch: 78 [14208/225000 (6%)] Loss: 15092.261719\n",
      "Train Epoch: 78 [15616/225000 (7%)] Loss: 15247.840820\n",
      "Train Epoch: 78 [17024/225000 (8%)] Loss: 14948.270508\n",
      "Train Epoch: 78 [18432/225000 (8%)] Loss: 15056.838867\n",
      "Train Epoch: 78 [19840/225000 (9%)] Loss: 15152.964844\n",
      "Train Epoch: 78 [21248/225000 (9%)] Loss: 15287.132812\n",
      "Train Epoch: 78 [22656/225000 (10%)] Loss: 14929.834961\n",
      "Train Epoch: 78 [24064/225000 (11%)] Loss: 15256.291016\n",
      "Train Epoch: 78 [25472/225000 (11%)] Loss: 15022.927734\n",
      "Train Epoch: 78 [26880/225000 (12%)] Loss: 15007.158203\n",
      "Train Epoch: 78 [28288/225000 (13%)] Loss: 14680.302734\n",
      "Train Epoch: 78 [29696/225000 (13%)] Loss: 15126.755859\n",
      "Train Epoch: 78 [31104/225000 (14%)] Loss: 14872.093750\n",
      "Train Epoch: 78 [32512/225000 (14%)] Loss: 14872.291992\n",
      "Train Epoch: 78 [33920/225000 (15%)] Loss: 15428.721680\n",
      "Train Epoch: 78 [35328/225000 (16%)] Loss: 14685.331055\n",
      "Train Epoch: 78 [36736/225000 (16%)] Loss: 15128.416016\n",
      "Train Epoch: 78 [38144/225000 (17%)] Loss: 14823.699219\n",
      "Train Epoch: 78 [39552/225000 (18%)] Loss: 15565.458984\n",
      "Train Epoch: 78 [40960/225000 (18%)] Loss: 15503.352539\n",
      "Train Epoch: 78 [42368/225000 (19%)] Loss: 15042.996094\n",
      "Train Epoch: 78 [43776/225000 (19%)] Loss: 15185.642578\n",
      "Train Epoch: 78 [45184/225000 (20%)] Loss: 15594.908203\n",
      "Train Epoch: 78 [46592/225000 (21%)] Loss: 15227.527344\n",
      "Train Epoch: 78 [48000/225000 (21%)] Loss: 15060.642578\n",
      "Train Epoch: 78 [49408/225000 (22%)] Loss: 15016.543945\n",
      "Train Epoch: 78 [50816/225000 (23%)] Loss: 15152.746094\n",
      "Train Epoch: 78 [52224/225000 (23%)] Loss: 15106.360352\n",
      "Train Epoch: 78 [53632/225000 (24%)] Loss: 15400.874023\n",
      "Train Epoch: 78 [55040/225000 (24%)] Loss: 15015.116211\n",
      "Train Epoch: 78 [56448/225000 (25%)] Loss: 15232.344727\n",
      "Train Epoch: 78 [57856/225000 (26%)] Loss: 15351.804688\n",
      "Train Epoch: 78 [59264/225000 (26%)] Loss: 15475.007812\n",
      "Train Epoch: 78 [60672/225000 (27%)] Loss: 14912.892578\n",
      "Train Epoch: 78 [62080/225000 (28%)] Loss: 15023.781250\n",
      "Train Epoch: 78 [63488/225000 (28%)] Loss: 14907.215820\n",
      "Train Epoch: 78 [64896/225000 (29%)] Loss: 14877.736328\n",
      "Train Epoch: 78 [66304/225000 (29%)] Loss: 15747.228516\n",
      "Train Epoch: 78 [67712/225000 (30%)] Loss: 15189.116211\n",
      "Train Epoch: 78 [69120/225000 (31%)] Loss: 14656.910156\n",
      "Train Epoch: 78 [70528/225000 (31%)] Loss: 15014.503906\n",
      "Train Epoch: 78 [71936/225000 (32%)] Loss: 15330.069336\n",
      "Train Epoch: 78 [73344/225000 (33%)] Loss: 15239.675781\n",
      "Train Epoch: 78 [74752/225000 (33%)] Loss: 15718.176758\n",
      "Train Epoch: 78 [76160/225000 (34%)] Loss: 14546.430664\n",
      "Train Epoch: 78 [77568/225000 (34%)] Loss: 15464.820312\n",
      "Train Epoch: 78 [78976/225000 (35%)] Loss: 15067.182617\n",
      "Train Epoch: 78 [80384/225000 (36%)] Loss: 15284.453125\n",
      "Train Epoch: 78 [81792/225000 (36%)] Loss: 15085.105469\n",
      "Train Epoch: 78 [83200/225000 (37%)] Loss: 15153.353516\n",
      "Train Epoch: 78 [84608/225000 (38%)] Loss: 14963.549805\n",
      "Train Epoch: 78 [86016/225000 (38%)] Loss: 14790.545898\n",
      "Train Epoch: 78 [87424/225000 (39%)] Loss: 15008.079102\n",
      "Train Epoch: 78 [88832/225000 (39%)] Loss: 14843.664062\n",
      "Train Epoch: 78 [90240/225000 (40%)] Loss: 14480.368164\n",
      "Train Epoch: 78 [91648/225000 (41%)] Loss: 15298.631836\n",
      "Train Epoch: 78 [93056/225000 (41%)] Loss: 14619.270508\n",
      "Train Epoch: 78 [94464/225000 (42%)] Loss: 15079.627930\n",
      "Train Epoch: 78 [95872/225000 (43%)] Loss: 15187.045898\n",
      "Train Epoch: 78 [97280/225000 (43%)] Loss: 15266.178711\n",
      "Train Epoch: 78 [98688/225000 (44%)] Loss: 14852.166992\n",
      "Train Epoch: 78 [100096/225000 (44%)] Loss: 15137.537109\n",
      "Train Epoch: 78 [101504/225000 (45%)] Loss: 15218.757812\n",
      "Train Epoch: 78 [102912/225000 (46%)] Loss: 15370.499023\n",
      "Train Epoch: 78 [104320/225000 (46%)] Loss: 14840.222656\n",
      "Train Epoch: 78 [105728/225000 (47%)] Loss: 14503.222656\n",
      "Train Epoch: 78 [107136/225000 (48%)] Loss: 14985.906250\n",
      "Train Epoch: 78 [108544/225000 (48%)] Loss: 15092.156250\n",
      "Train Epoch: 78 [109952/225000 (49%)] Loss: 14644.928711\n",
      "Train Epoch: 78 [111360/225000 (49%)] Loss: 15133.420898\n",
      "Train Epoch: 78 [112768/225000 (50%)] Loss: 14890.854492\n",
      "Train Epoch: 78 [114176/225000 (51%)] Loss: 14506.107422\n",
      "Train Epoch: 78 [115584/225000 (51%)] Loss: 15291.173828\n",
      "Train Epoch: 78 [116992/225000 (52%)] Loss: 15680.792969\n",
      "Train Epoch: 78 [118400/225000 (53%)] Loss: 14898.341797\n",
      "Train Epoch: 78 [119808/225000 (53%)] Loss: 15188.311523\n",
      "Train Epoch: 78 [121216/225000 (54%)] Loss: 15065.231445\n",
      "Train Epoch: 78 [122624/225000 (54%)] Loss: 14837.895508\n",
      "Train Epoch: 78 [124032/225000 (55%)] Loss: 14936.261719\n",
      "Train Epoch: 78 [125440/225000 (56%)] Loss: 15048.783203\n",
      "Train Epoch: 78 [126848/225000 (56%)] Loss: 14789.853516\n",
      "Train Epoch: 78 [128256/225000 (57%)] Loss: 15191.525391\n",
      "Train Epoch: 78 [129664/225000 (58%)] Loss: 14941.029297\n",
      "Train Epoch: 78 [131072/225000 (58%)] Loss: 15056.275391\n",
      "Train Epoch: 78 [132480/225000 (59%)] Loss: 14867.571289\n",
      "Train Epoch: 78 [133888/225000 (60%)] Loss: 15287.719727\n",
      "Train Epoch: 78 [135296/225000 (60%)] Loss: 14580.346680\n",
      "Train Epoch: 78 [136704/225000 (61%)] Loss: 15550.667969\n",
      "Train Epoch: 78 [138112/225000 (61%)] Loss: 15243.129883\n",
      "Train Epoch: 78 [139520/225000 (62%)] Loss: 14664.634766\n",
      "Train Epoch: 78 [140928/225000 (63%)] Loss: 14989.790039\n",
      "Train Epoch: 78 [142336/225000 (63%)] Loss: 14939.354492\n",
      "Train Epoch: 78 [143744/225000 (64%)] Loss: 15500.674805\n",
      "Train Epoch: 78 [145152/225000 (65%)] Loss: 15280.127930\n",
      "Train Epoch: 78 [146560/225000 (65%)] Loss: 15542.446289\n",
      "Train Epoch: 78 [147968/225000 (66%)] Loss: 15132.924805\n",
      "Train Epoch: 78 [149376/225000 (66%)] Loss: 15229.670898\n",
      "Train Epoch: 78 [150784/225000 (67%)] Loss: 14818.332031\n",
      "Train Epoch: 78 [152192/225000 (68%)] Loss: 15128.784180\n",
      "Train Epoch: 78 [153600/225000 (68%)] Loss: 15438.625000\n",
      "Train Epoch: 78 [155008/225000 (69%)] Loss: 14779.541992\n",
      "Train Epoch: 78 [156416/225000 (70%)] Loss: 14845.014648\n",
      "Train Epoch: 78 [157824/225000 (70%)] Loss: 14959.891602\n",
      "Train Epoch: 78 [159232/225000 (71%)] Loss: 15687.875000\n",
      "Train Epoch: 78 [160640/225000 (71%)] Loss: 15054.657227\n",
      "Train Epoch: 78 [162048/225000 (72%)] Loss: 15136.358398\n",
      "Train Epoch: 78 [163456/225000 (73%)] Loss: 15257.816406\n",
      "Train Epoch: 78 [164864/225000 (73%)] Loss: 15356.144531\n",
      "Train Epoch: 78 [166272/225000 (74%)] Loss: 14972.809570\n",
      "Train Epoch: 78 [167680/225000 (75%)] Loss: 14844.620117\n",
      "Train Epoch: 78 [169088/225000 (75%)] Loss: 15065.619141\n",
      "Train Epoch: 78 [170496/225000 (76%)] Loss: 14797.493164\n",
      "Train Epoch: 78 [171904/225000 (76%)] Loss: 15131.433594\n",
      "Train Epoch: 78 [173312/225000 (77%)] Loss: 14958.167969\n",
      "Train Epoch: 78 [174720/225000 (78%)] Loss: 14928.438477\n",
      "Train Epoch: 78 [176128/225000 (78%)] Loss: 14653.744141\n",
      "Train Epoch: 78 [177536/225000 (79%)] Loss: 14926.190430\n",
      "Train Epoch: 78 [178944/225000 (80%)] Loss: 14852.038086\n",
      "Train Epoch: 78 [180352/225000 (80%)] Loss: 15158.275391\n",
      "Train Epoch: 78 [181760/225000 (81%)] Loss: 15045.854492\n",
      "Train Epoch: 78 [183168/225000 (81%)] Loss: 15558.420898\n",
      "Train Epoch: 78 [184576/225000 (82%)] Loss: 15243.060547\n",
      "Train Epoch: 78 [185984/225000 (83%)] Loss: 15055.859375\n",
      "Train Epoch: 78 [187392/225000 (83%)] Loss: 14985.702148\n",
      "Train Epoch: 78 [188800/225000 (84%)] Loss: 15412.646484\n",
      "Train Epoch: 78 [190208/225000 (85%)] Loss: 14522.699219\n",
      "Train Epoch: 78 [191616/225000 (85%)] Loss: 14756.893555\n",
      "Train Epoch: 78 [193024/225000 (86%)] Loss: 14550.220703\n",
      "Train Epoch: 78 [194432/225000 (86%)] Loss: 14919.228516\n",
      "Train Epoch: 78 [195840/225000 (87%)] Loss: 15297.186523\n",
      "Train Epoch: 78 [197248/225000 (88%)] Loss: 15054.960938\n",
      "Train Epoch: 78 [198656/225000 (88%)] Loss: 14914.433594\n",
      "Train Epoch: 78 [200064/225000 (89%)] Loss: 15005.479492\n",
      "Train Epoch: 78 [201472/225000 (90%)] Loss: 14628.209961\n",
      "Train Epoch: 78 [202880/225000 (90%)] Loss: 14817.904297\n",
      "Train Epoch: 78 [204288/225000 (91%)] Loss: 14607.008789\n",
      "Train Epoch: 78 [205696/225000 (91%)] Loss: 14801.612305\n",
      "Train Epoch: 78 [207104/225000 (92%)] Loss: 15288.382812\n",
      "Train Epoch: 78 [208512/225000 (93%)] Loss: 14830.135742\n",
      "Train Epoch: 78 [209920/225000 (93%)] Loss: 14685.594727\n",
      "Train Epoch: 78 [211328/225000 (94%)] Loss: 15125.372070\n",
      "Train Epoch: 78 [212736/225000 (95%)] Loss: 15128.385742\n",
      "Train Epoch: 78 [214144/225000 (95%)] Loss: 15011.179688\n",
      "Train Epoch: 78 [215552/225000 (96%)] Loss: 15133.981445\n",
      "Train Epoch: 78 [216960/225000 (96%)] Loss: 14989.707031\n",
      "Train Epoch: 78 [218368/225000 (97%)] Loss: 14767.149414\n",
      "Train Epoch: 78 [219776/225000 (98%)] Loss: 15129.208008\n",
      "Train Epoch: 78 [221184/225000 (98%)] Loss: 14916.688477\n",
      "Train Epoch: 78 [222592/225000 (99%)] Loss: 15221.934570\n",
      "Train Epoch: 78 [224000/225000 (100%)] Loss: 15246.004883\n",
      "    epoch          : 78\n",
      "    loss           : 15074.66769377933\n",
      "    val_loss       : 15062.250819905072\n",
      "Train Epoch: 79 [128/225000 (0%)] Loss: 15520.854492\n",
      "Train Epoch: 79 [1536/225000 (1%)] Loss: 14943.916016\n",
      "Train Epoch: 79 [2944/225000 (1%)] Loss: 15229.393555\n",
      "Train Epoch: 79 [4352/225000 (2%)] Loss: 14737.940430\n",
      "Train Epoch: 79 [5760/225000 (3%)] Loss: 14961.542969\n",
      "Train Epoch: 79 [7168/225000 (3%)] Loss: 15206.522461\n",
      "Train Epoch: 79 [8576/225000 (4%)] Loss: 14564.624023\n",
      "Train Epoch: 79 [9984/225000 (4%)] Loss: 14736.647461\n",
      "Train Epoch: 79 [11392/225000 (5%)] Loss: 14832.228516\n",
      "Train Epoch: 79 [12800/225000 (6%)] Loss: 14991.271484\n",
      "Train Epoch: 79 [14208/225000 (6%)] Loss: 15086.534180\n",
      "Train Epoch: 79 [15616/225000 (7%)] Loss: 15308.846680\n",
      "Train Epoch: 79 [17024/225000 (8%)] Loss: 14478.603516\n",
      "Train Epoch: 79 [18432/225000 (8%)] Loss: 14936.143555\n",
      "Train Epoch: 79 [19840/225000 (9%)] Loss: 15394.632812\n",
      "Train Epoch: 79 [21248/225000 (9%)] Loss: 15221.035156\n",
      "Train Epoch: 79 [22656/225000 (10%)] Loss: 15232.029297\n",
      "Train Epoch: 79 [24064/225000 (11%)] Loss: 14808.516602\n",
      "Train Epoch: 79 [25472/225000 (11%)] Loss: 14972.855469\n",
      "Train Epoch: 79 [26880/225000 (12%)] Loss: 14860.624023\n",
      "Train Epoch: 79 [28288/225000 (13%)] Loss: 14695.215820\n",
      "Train Epoch: 79 [29696/225000 (13%)] Loss: 15256.149414\n",
      "Train Epoch: 79 [31104/225000 (14%)] Loss: 15392.849609\n",
      "Train Epoch: 79 [32512/225000 (14%)] Loss: 15289.881836\n",
      "Train Epoch: 79 [33920/225000 (15%)] Loss: 15248.525391\n",
      "Train Epoch: 79 [35328/225000 (16%)] Loss: 14944.518555\n",
      "Train Epoch: 79 [36736/225000 (16%)] Loss: 14842.421875\n",
      "Train Epoch: 79 [38144/225000 (17%)] Loss: 15322.066406\n",
      "Train Epoch: 79 [39552/225000 (18%)] Loss: 14603.749023\n",
      "Train Epoch: 79 [40960/225000 (18%)] Loss: 15402.720703\n",
      "Train Epoch: 79 [42368/225000 (19%)] Loss: 14994.691406\n",
      "Train Epoch: 79 [43776/225000 (19%)] Loss: 14890.062500\n",
      "Train Epoch: 79 [45184/225000 (20%)] Loss: 14944.662109\n",
      "Train Epoch: 79 [46592/225000 (21%)] Loss: 15491.432617\n",
      "Train Epoch: 79 [48000/225000 (21%)] Loss: 14696.614258\n",
      "Train Epoch: 79 [49408/225000 (22%)] Loss: 15053.067383\n",
      "Train Epoch: 79 [50816/225000 (23%)] Loss: 15101.775391\n",
      "Train Epoch: 79 [52224/225000 (23%)] Loss: 15106.653320\n",
      "Train Epoch: 79 [53632/225000 (24%)] Loss: 14820.841797\n",
      "Train Epoch: 79 [55040/225000 (24%)] Loss: 15117.478516\n",
      "Train Epoch: 79 [56448/225000 (25%)] Loss: 14789.125000\n",
      "Train Epoch: 79 [57856/225000 (26%)] Loss: 14958.107422\n",
      "Train Epoch: 79 [59264/225000 (26%)] Loss: 15099.058594\n",
      "Train Epoch: 79 [60672/225000 (27%)] Loss: 15222.430664\n",
      "Train Epoch: 79 [62080/225000 (28%)] Loss: 15308.754883\n",
      "Train Epoch: 79 [63488/225000 (28%)] Loss: 15368.361328\n",
      "Train Epoch: 79 [64896/225000 (29%)] Loss: 14550.850586\n",
      "Train Epoch: 79 [66304/225000 (29%)] Loss: 15093.163086\n",
      "Train Epoch: 79 [67712/225000 (30%)] Loss: 14950.659180\n",
      "Train Epoch: 79 [69120/225000 (31%)] Loss: 14790.924805\n",
      "Train Epoch: 79 [70528/225000 (31%)] Loss: 14992.860352\n",
      "Train Epoch: 79 [71936/225000 (32%)] Loss: 14686.057617\n",
      "Train Epoch: 79 [73344/225000 (33%)] Loss: 14940.311523\n",
      "Train Epoch: 79 [74752/225000 (33%)] Loss: 14668.031250\n",
      "Train Epoch: 79 [76160/225000 (34%)] Loss: 15082.223633\n",
      "Train Epoch: 79 [77568/225000 (34%)] Loss: 14917.537109\n",
      "Train Epoch: 79 [78976/225000 (35%)] Loss: 15249.419922\n",
      "Train Epoch: 79 [80384/225000 (36%)] Loss: 14941.179688\n",
      "Train Epoch: 79 [81792/225000 (36%)] Loss: 14647.723633\n",
      "Train Epoch: 79 [83200/225000 (37%)] Loss: 15191.984375\n",
      "Train Epoch: 79 [84608/225000 (38%)] Loss: 15269.297852\n",
      "Train Epoch: 79 [86016/225000 (38%)] Loss: 15599.175781\n",
      "Train Epoch: 79 [87424/225000 (39%)] Loss: 15124.480469\n",
      "Train Epoch: 79 [88832/225000 (39%)] Loss: 15147.230469\n",
      "Train Epoch: 79 [90240/225000 (40%)] Loss: 15119.877930\n",
      "Train Epoch: 79 [91648/225000 (41%)] Loss: 15379.249023\n",
      "Train Epoch: 79 [93056/225000 (41%)] Loss: 15203.902344\n",
      "Train Epoch: 79 [94464/225000 (42%)] Loss: 15403.206055\n",
      "Train Epoch: 79 [95872/225000 (43%)] Loss: 15096.344727\n",
      "Train Epoch: 79 [97280/225000 (43%)] Loss: 14959.632812\n",
      "Train Epoch: 79 [98688/225000 (44%)] Loss: 15244.720703\n",
      "Train Epoch: 79 [100096/225000 (44%)] Loss: 14792.180664\n",
      "Train Epoch: 79 [101504/225000 (45%)] Loss: 15179.961914\n",
      "Train Epoch: 79 [102912/225000 (46%)] Loss: 14475.796875\n",
      "Train Epoch: 79 [104320/225000 (46%)] Loss: 14704.914062\n",
      "Train Epoch: 79 [105728/225000 (47%)] Loss: 15249.609375\n",
      "Train Epoch: 79 [107136/225000 (48%)] Loss: 14933.144531\n",
      "Train Epoch: 79 [108544/225000 (48%)] Loss: 14688.959961\n",
      "Train Epoch: 79 [109952/225000 (49%)] Loss: 15066.750977\n",
      "Train Epoch: 79 [111360/225000 (49%)] Loss: 15269.634766\n",
      "Train Epoch: 79 [112768/225000 (50%)] Loss: 15174.112305\n",
      "Train Epoch: 79 [114176/225000 (51%)] Loss: 15140.031250\n",
      "Train Epoch: 79 [115584/225000 (51%)] Loss: 15198.155273\n",
      "Train Epoch: 79 [116992/225000 (52%)] Loss: 15091.284180\n",
      "Train Epoch: 79 [118400/225000 (53%)] Loss: 15103.871094\n",
      "Train Epoch: 79 [119808/225000 (53%)] Loss: 15466.979492\n",
      "Train Epoch: 79 [121216/225000 (54%)] Loss: 14802.500977\n",
      "Train Epoch: 79 [122624/225000 (54%)] Loss: 15111.782227\n",
      "Train Epoch: 79 [124032/225000 (55%)] Loss: 15068.243164\n",
      "Train Epoch: 79 [125440/225000 (56%)] Loss: 15456.696289\n",
      "Train Epoch: 79 [126848/225000 (56%)] Loss: 15354.105469\n",
      "Train Epoch: 79 [128256/225000 (57%)] Loss: 15181.035156\n",
      "Train Epoch: 79 [129664/225000 (58%)] Loss: 14815.420898\n",
      "Train Epoch: 79 [131072/225000 (58%)] Loss: 15046.507812\n",
      "Train Epoch: 79 [132480/225000 (59%)] Loss: 15394.688477\n",
      "Train Epoch: 79 [133888/225000 (60%)] Loss: 14693.870117\n",
      "Train Epoch: 79 [135296/225000 (60%)] Loss: 14834.648438\n",
      "Train Epoch: 79 [136704/225000 (61%)] Loss: 15209.375977\n",
      "Train Epoch: 79 [138112/225000 (61%)] Loss: 14854.211914\n",
      "Train Epoch: 79 [139520/225000 (62%)] Loss: 15065.333984\n",
      "Train Epoch: 79 [140928/225000 (63%)] Loss: 15251.119141\n",
      "Train Epoch: 79 [142336/225000 (63%)] Loss: 14723.319336\n",
      "Train Epoch: 79 [143744/225000 (64%)] Loss: 14816.931641\n",
      "Train Epoch: 79 [145152/225000 (65%)] Loss: 15045.249023\n",
      "Train Epoch: 79 [146560/225000 (65%)] Loss: 15513.708008\n",
      "Train Epoch: 79 [147968/225000 (66%)] Loss: 14646.683594\n",
      "Train Epoch: 79 [149376/225000 (66%)] Loss: 15380.440430\n",
      "Train Epoch: 79 [150784/225000 (67%)] Loss: 14843.885742\n",
      "Train Epoch: 79 [152192/225000 (68%)] Loss: 15279.480469\n",
      "Train Epoch: 79 [153600/225000 (68%)] Loss: 15168.593750\n",
      "Train Epoch: 79 [155008/225000 (69%)] Loss: 15222.963867\n",
      "Train Epoch: 79 [156416/225000 (70%)] Loss: 14433.992188\n",
      "Train Epoch: 79 [157824/225000 (70%)] Loss: 15422.578125\n",
      "Train Epoch: 79 [159232/225000 (71%)] Loss: 15126.751953\n",
      "Train Epoch: 79 [160640/225000 (71%)] Loss: 15006.888672\n",
      "Train Epoch: 79 [162048/225000 (72%)] Loss: 15262.486328\n",
      "Train Epoch: 79 [163456/225000 (73%)] Loss: 14548.278320\n",
      "Train Epoch: 79 [164864/225000 (73%)] Loss: 15524.075195\n",
      "Train Epoch: 79 [166272/225000 (74%)] Loss: 15448.005859\n",
      "Train Epoch: 79 [167680/225000 (75%)] Loss: 15289.342773\n",
      "Train Epoch: 79 [169088/225000 (75%)] Loss: 14796.303711\n",
      "Train Epoch: 79 [170496/225000 (76%)] Loss: 15147.319336\n",
      "Train Epoch: 79 [171904/225000 (76%)] Loss: 14732.583008\n",
      "Train Epoch: 79 [173312/225000 (77%)] Loss: 15122.933594\n",
      "Train Epoch: 79 [174720/225000 (78%)] Loss: 15173.470703\n",
      "Train Epoch: 79 [176128/225000 (78%)] Loss: 14853.125000\n",
      "Train Epoch: 79 [177536/225000 (79%)] Loss: 15002.553711\n",
      "Train Epoch: 79 [178944/225000 (80%)] Loss: 15219.280273\n",
      "Train Epoch: 79 [180352/225000 (80%)] Loss: 15634.187500\n",
      "Train Epoch: 79 [181760/225000 (81%)] Loss: 14642.953125\n",
      "Train Epoch: 79 [183168/225000 (81%)] Loss: 14963.309570\n",
      "Train Epoch: 79 [184576/225000 (82%)] Loss: 15188.569336\n",
      "Train Epoch: 79 [185984/225000 (83%)] Loss: 15336.491211\n",
      "Train Epoch: 79 [187392/225000 (83%)] Loss: 15016.784180\n",
      "Train Epoch: 79 [188800/225000 (84%)] Loss: 14875.439453\n",
      "Train Epoch: 79 [190208/225000 (85%)] Loss: 15380.747070\n",
      "Train Epoch: 79 [191616/225000 (85%)] Loss: 14894.236328\n",
      "Train Epoch: 79 [193024/225000 (86%)] Loss: 14526.628906\n",
      "Train Epoch: 79 [194432/225000 (86%)] Loss: 15185.895508\n",
      "Train Epoch: 79 [195840/225000 (87%)] Loss: 15054.782227\n",
      "Train Epoch: 79 [197248/225000 (88%)] Loss: 15423.931641\n",
      "Train Epoch: 79 [198656/225000 (88%)] Loss: 15128.633789\n",
      "Train Epoch: 79 [200064/225000 (89%)] Loss: 15539.562500\n",
      "Train Epoch: 79 [201472/225000 (90%)] Loss: 15171.026367\n",
      "Train Epoch: 79 [202880/225000 (90%)] Loss: 14983.280273\n",
      "Train Epoch: 79 [204288/225000 (91%)] Loss: 15577.156250\n",
      "Train Epoch: 79 [205696/225000 (91%)] Loss: 14968.299805\n",
      "Train Epoch: 79 [207104/225000 (92%)] Loss: 14533.704102\n",
      "Train Epoch: 79 [208512/225000 (93%)] Loss: 14771.166992\n",
      "Train Epoch: 79 [209920/225000 (93%)] Loss: 15193.585938\n",
      "Train Epoch: 79 [211328/225000 (94%)] Loss: 15319.446289\n",
      "Train Epoch: 79 [212736/225000 (95%)] Loss: 15119.990234\n",
      "Train Epoch: 79 [214144/225000 (95%)] Loss: 15693.756836\n",
      "Train Epoch: 79 [215552/225000 (96%)] Loss: 14538.514648\n",
      "Train Epoch: 79 [216960/225000 (96%)] Loss: 15808.181641\n",
      "Train Epoch: 79 [218368/225000 (97%)] Loss: 15168.332031\n",
      "Train Epoch: 79 [219776/225000 (98%)] Loss: 14884.816406\n",
      "Train Epoch: 79 [221184/225000 (98%)] Loss: 15239.990234\n",
      "Train Epoch: 79 [222592/225000 (99%)] Loss: 14963.004883\n",
      "Train Epoch: 79 [224000/225000 (100%)] Loss: 15405.009766\n",
      "    epoch          : 79\n",
      "    loss           : 15074.848833346665\n",
      "    val_loss       : 15069.794959125926\n",
      "Train Epoch: 80 [128/225000 (0%)] Loss: 15435.954102\n",
      "Train Epoch: 80 [1536/225000 (1%)] Loss: 15477.184570\n",
      "Train Epoch: 80 [2944/225000 (1%)] Loss: 15029.207031\n",
      "Train Epoch: 80 [4352/225000 (2%)] Loss: 15335.066406\n",
      "Train Epoch: 80 [5760/225000 (3%)] Loss: 15667.354492\n",
      "Train Epoch: 80 [7168/225000 (3%)] Loss: 15003.083008\n",
      "Train Epoch: 80 [8576/225000 (4%)] Loss: 15303.666992\n",
      "Train Epoch: 80 [9984/225000 (4%)] Loss: 15254.031250\n",
      "Train Epoch: 80 [11392/225000 (5%)] Loss: 14989.907227\n",
      "Train Epoch: 80 [12800/225000 (6%)] Loss: 14750.821289\n",
      "Train Epoch: 80 [14208/225000 (6%)] Loss: 14971.263672\n",
      "Train Epoch: 80 [15616/225000 (7%)] Loss: 15327.717773\n",
      "Train Epoch: 80 [17024/225000 (8%)] Loss: 15129.104492\n",
      "Train Epoch: 80 [18432/225000 (8%)] Loss: 15344.349609\n",
      "Train Epoch: 80 [19840/225000 (9%)] Loss: 15155.989258\n",
      "Train Epoch: 80 [21248/225000 (9%)] Loss: 15713.576172\n",
      "Train Epoch: 80 [22656/225000 (10%)] Loss: 15138.956055\n",
      "Train Epoch: 80 [24064/225000 (11%)] Loss: 15267.634766\n",
      "Train Epoch: 80 [25472/225000 (11%)] Loss: 14821.837891\n",
      "Train Epoch: 80 [26880/225000 (12%)] Loss: 15125.778320\n",
      "Train Epoch: 80 [28288/225000 (13%)] Loss: 15591.307617\n",
      "Train Epoch: 80 [29696/225000 (13%)] Loss: 15040.109375\n",
      "Train Epoch: 80 [31104/225000 (14%)] Loss: 15084.198242\n",
      "Train Epoch: 80 [32512/225000 (14%)] Loss: 15191.090820\n",
      "Train Epoch: 80 [33920/225000 (15%)] Loss: 14403.902344\n",
      "Train Epoch: 80 [35328/225000 (16%)] Loss: 14719.322266\n",
      "Train Epoch: 80 [36736/225000 (16%)] Loss: 15535.351562\n",
      "Train Epoch: 80 [38144/225000 (17%)] Loss: 15217.112305\n",
      "Train Epoch: 80 [39552/225000 (18%)] Loss: 15406.984375\n",
      "Train Epoch: 80 [40960/225000 (18%)] Loss: 15041.670898\n",
      "Train Epoch: 80 [42368/225000 (19%)] Loss: 14972.284180\n",
      "Train Epoch: 80 [43776/225000 (19%)] Loss: 14595.415039\n",
      "Train Epoch: 80 [45184/225000 (20%)] Loss: 14615.540039\n",
      "Train Epoch: 80 [46592/225000 (21%)] Loss: 14844.223633\n",
      "Train Epoch: 80 [48000/225000 (21%)] Loss: 15040.860352\n",
      "Train Epoch: 80 [49408/225000 (22%)] Loss: 15067.720703\n",
      "Train Epoch: 80 [50816/225000 (23%)] Loss: 14681.629883\n",
      "Train Epoch: 80 [52224/225000 (23%)] Loss: 14999.423828\n",
      "Train Epoch: 80 [53632/225000 (24%)] Loss: 15016.275391\n",
      "Train Epoch: 80 [55040/225000 (24%)] Loss: 15082.109375\n",
      "Train Epoch: 80 [56448/225000 (25%)] Loss: 15382.945312\n",
      "Train Epoch: 80 [57856/225000 (26%)] Loss: 15256.508789\n",
      "Train Epoch: 80 [59264/225000 (26%)] Loss: 14712.478516\n",
      "Train Epoch: 80 [60672/225000 (27%)] Loss: 15124.331055\n",
      "Train Epoch: 80 [62080/225000 (28%)] Loss: 14911.812500\n",
      "Train Epoch: 80 [63488/225000 (28%)] Loss: 15852.766602\n",
      "Train Epoch: 80 [64896/225000 (29%)] Loss: 15324.628906\n",
      "Train Epoch: 80 [66304/225000 (29%)] Loss: 15289.119141\n",
      "Train Epoch: 80 [67712/225000 (30%)] Loss: 15120.841797\n",
      "Train Epoch: 80 [69120/225000 (31%)] Loss: 15330.299805\n",
      "Train Epoch: 80 [70528/225000 (31%)] Loss: 15615.386719\n",
      "Train Epoch: 80 [71936/225000 (32%)] Loss: 15140.364258\n",
      "Train Epoch: 80 [73344/225000 (33%)] Loss: 15257.380859\n",
      "Train Epoch: 80 [74752/225000 (33%)] Loss: 15075.499023\n",
      "Train Epoch: 80 [76160/225000 (34%)] Loss: 15042.509766\n",
      "Train Epoch: 80 [77568/225000 (34%)] Loss: 14915.640625\n",
      "Train Epoch: 80 [78976/225000 (35%)] Loss: 15336.671875\n",
      "Train Epoch: 80 [80384/225000 (36%)] Loss: 15579.579102\n",
      "Train Epoch: 80 [81792/225000 (36%)] Loss: 15450.601562\n",
      "Train Epoch: 80 [83200/225000 (37%)] Loss: 15280.297852\n",
      "Train Epoch: 80 [84608/225000 (38%)] Loss: 15717.158203\n",
      "Train Epoch: 80 [86016/225000 (38%)] Loss: 14965.355469\n",
      "Train Epoch: 80 [87424/225000 (39%)] Loss: 14751.326172\n",
      "Train Epoch: 80 [88832/225000 (39%)] Loss: 14807.586914\n",
      "Train Epoch: 80 [90240/225000 (40%)] Loss: 15441.702148\n",
      "Train Epoch: 80 [91648/225000 (41%)] Loss: 15135.904297\n",
      "Train Epoch: 80 [93056/225000 (41%)] Loss: 15143.709961\n",
      "Train Epoch: 80 [94464/225000 (42%)] Loss: 14990.256836\n",
      "Train Epoch: 80 [95872/225000 (43%)] Loss: 14960.497070\n",
      "Train Epoch: 80 [97280/225000 (43%)] Loss: 15212.277344\n",
      "Train Epoch: 80 [98688/225000 (44%)] Loss: 14859.377930\n",
      "Train Epoch: 80 [100096/225000 (44%)] Loss: 15394.566406\n",
      "Train Epoch: 80 [101504/225000 (45%)] Loss: 15395.651367\n",
      "Train Epoch: 80 [102912/225000 (46%)] Loss: 14610.901367\n",
      "Train Epoch: 80 [104320/225000 (46%)] Loss: 15632.106445\n",
      "Train Epoch: 80 [105728/225000 (47%)] Loss: 15086.345703\n",
      "Train Epoch: 80 [107136/225000 (48%)] Loss: 14917.973633\n",
      "Train Epoch: 80 [108544/225000 (48%)] Loss: 15130.634766\n",
      "Train Epoch: 80 [109952/225000 (49%)] Loss: 15706.495117\n",
      "Train Epoch: 80 [111360/225000 (49%)] Loss: 15135.464844\n",
      "Train Epoch: 80 [112768/225000 (50%)] Loss: 14709.476562\n",
      "Train Epoch: 80 [114176/225000 (51%)] Loss: 15069.800781\n",
      "Train Epoch: 80 [115584/225000 (51%)] Loss: 15255.660156\n",
      "Train Epoch: 80 [116992/225000 (52%)] Loss: 14843.489258\n",
      "Train Epoch: 80 [118400/225000 (53%)] Loss: 14796.616211\n",
      "Train Epoch: 80 [119808/225000 (53%)] Loss: 14953.756836\n",
      "Train Epoch: 80 [121216/225000 (54%)] Loss: 15152.134766\n",
      "Train Epoch: 80 [122624/225000 (54%)] Loss: 14842.708984\n",
      "Train Epoch: 80 [124032/225000 (55%)] Loss: 14901.790039\n",
      "Train Epoch: 80 [125440/225000 (56%)] Loss: 14662.948242\n",
      "Train Epoch: 80 [126848/225000 (56%)] Loss: 14764.668945\n",
      "Train Epoch: 80 [128256/225000 (57%)] Loss: 15108.351562\n",
      "Train Epoch: 80 [129664/225000 (58%)] Loss: 15265.654297\n",
      "Train Epoch: 80 [131072/225000 (58%)] Loss: 14757.041992\n",
      "Train Epoch: 80 [132480/225000 (59%)] Loss: 14740.463867\n",
      "Train Epoch: 80 [133888/225000 (60%)] Loss: 14946.351562\n",
      "Train Epoch: 80 [135296/225000 (60%)] Loss: 14623.211914\n",
      "Train Epoch: 80 [136704/225000 (61%)] Loss: 15132.034180\n",
      "Train Epoch: 80 [138112/225000 (61%)] Loss: 14876.070312\n",
      "Train Epoch: 80 [139520/225000 (62%)] Loss: 14888.125000\n",
      "Train Epoch: 80 [140928/225000 (63%)] Loss: 15234.354492\n",
      "Train Epoch: 80 [142336/225000 (63%)] Loss: 15058.418945\n",
      "Train Epoch: 80 [143744/225000 (64%)] Loss: 14956.188477\n",
      "Train Epoch: 80 [145152/225000 (65%)] Loss: 15286.242188\n",
      "Train Epoch: 80 [146560/225000 (65%)] Loss: 15177.124023\n",
      "Train Epoch: 80 [147968/225000 (66%)] Loss: 15237.903320\n",
      "Train Epoch: 80 [149376/225000 (66%)] Loss: 15121.963867\n",
      "Train Epoch: 80 [150784/225000 (67%)] Loss: 15508.081055\n",
      "Train Epoch: 80 [152192/225000 (68%)] Loss: 15546.900391\n",
      "Train Epoch: 80 [153600/225000 (68%)] Loss: 14723.200195\n",
      "Train Epoch: 80 [155008/225000 (69%)] Loss: 14900.862305\n",
      "Train Epoch: 80 [156416/225000 (70%)] Loss: 14962.283203\n",
      "Train Epoch: 80 [157824/225000 (70%)] Loss: 14913.543945\n",
      "Train Epoch: 80 [159232/225000 (71%)] Loss: 15309.458984\n",
      "Train Epoch: 80 [160640/225000 (71%)] Loss: 15464.028320\n",
      "Train Epoch: 80 [162048/225000 (72%)] Loss: 15629.507812\n",
      "Train Epoch: 80 [163456/225000 (73%)] Loss: 15156.167969\n",
      "Train Epoch: 80 [164864/225000 (73%)] Loss: 15062.975586\n",
      "Train Epoch: 80 [166272/225000 (74%)] Loss: 15231.436523\n",
      "Train Epoch: 80 [167680/225000 (75%)] Loss: 15106.952148\n",
      "Train Epoch: 80 [169088/225000 (75%)] Loss: 14862.813477\n",
      "Train Epoch: 80 [170496/225000 (76%)] Loss: 14879.902344\n",
      "Train Epoch: 80 [171904/225000 (76%)] Loss: 15276.691406\n",
      "Train Epoch: 80 [173312/225000 (77%)] Loss: 14720.908203\n",
      "Train Epoch: 80 [174720/225000 (78%)] Loss: 14734.836914\n",
      "Train Epoch: 80 [176128/225000 (78%)] Loss: 14874.290039\n",
      "Train Epoch: 80 [177536/225000 (79%)] Loss: 15123.551758\n",
      "Train Epoch: 80 [178944/225000 (80%)] Loss: 14924.040039\n",
      "Train Epoch: 80 [180352/225000 (80%)] Loss: 14965.900391\n",
      "Train Epoch: 80 [181760/225000 (81%)] Loss: 14938.101562\n",
      "Train Epoch: 80 [183168/225000 (81%)] Loss: 14834.968750\n",
      "Train Epoch: 80 [184576/225000 (82%)] Loss: 15004.766602\n",
      "Train Epoch: 80 [185984/225000 (83%)] Loss: 15007.419922\n",
      "Train Epoch: 80 [187392/225000 (83%)] Loss: 14881.131836\n",
      "Train Epoch: 80 [188800/225000 (84%)] Loss: 14762.475586\n",
      "Train Epoch: 80 [190208/225000 (85%)] Loss: 14722.166992\n",
      "Train Epoch: 80 [191616/225000 (85%)] Loss: 14915.046875\n",
      "Train Epoch: 80 [193024/225000 (86%)] Loss: 15359.849609\n",
      "Train Epoch: 80 [194432/225000 (86%)] Loss: 14788.944336\n",
      "Train Epoch: 80 [195840/225000 (87%)] Loss: 14599.430664\n",
      "Train Epoch: 80 [197248/225000 (88%)] Loss: 15124.201172\n",
      "Train Epoch: 80 [198656/225000 (88%)] Loss: 15556.271484\n",
      "Train Epoch: 80 [200064/225000 (89%)] Loss: 14984.950195\n",
      "Train Epoch: 80 [201472/225000 (90%)] Loss: 14840.447266\n",
      "Train Epoch: 80 [202880/225000 (90%)] Loss: 15559.624023\n",
      "Train Epoch: 80 [204288/225000 (91%)] Loss: 14891.393555\n",
      "Train Epoch: 80 [205696/225000 (91%)] Loss: 15002.317383\n",
      "Train Epoch: 80 [207104/225000 (92%)] Loss: 15342.197266\n",
      "Train Epoch: 80 [208512/225000 (93%)] Loss: 15241.336914\n",
      "Train Epoch: 80 [209920/225000 (93%)] Loss: 15035.143555\n",
      "Train Epoch: 80 [211328/225000 (94%)] Loss: 14745.504883\n",
      "Train Epoch: 80 [212736/225000 (95%)] Loss: 15523.930664\n",
      "Train Epoch: 80 [214144/225000 (95%)] Loss: 15159.963867\n",
      "Train Epoch: 80 [215552/225000 (96%)] Loss: 15660.789062\n",
      "Train Epoch: 80 [216960/225000 (96%)] Loss: 15127.087891\n",
      "Train Epoch: 80 [218368/225000 (97%)] Loss: 15004.902344\n",
      "Train Epoch: 80 [219776/225000 (98%)] Loss: 15064.700195\n",
      "Train Epoch: 80 [221184/225000 (98%)] Loss: 15092.004883\n",
      "Train Epoch: 80 [222592/225000 (99%)] Loss: 15004.682617\n",
      "Train Epoch: 80 [224000/225000 (100%)] Loss: 14779.754883\n",
      "    epoch          : 80\n",
      "    loss           : 15073.391133834613\n",
      "    val_loss       : 15058.380968632899\n",
      "Train Epoch: 81 [128/225000 (0%)] Loss: 14861.014648\n",
      "Train Epoch: 81 [1536/225000 (1%)] Loss: 14996.911133\n",
      "Train Epoch: 81 [2944/225000 (1%)] Loss: 15177.854492\n",
      "Train Epoch: 81 [4352/225000 (2%)] Loss: 15015.420898\n",
      "Train Epoch: 81 [5760/225000 (3%)] Loss: 15050.000977\n",
      "Train Epoch: 81 [7168/225000 (3%)] Loss: 15143.262695\n",
      "Train Epoch: 81 [8576/225000 (4%)] Loss: 15105.748047\n",
      "Train Epoch: 81 [9984/225000 (4%)] Loss: 15403.677734\n",
      "Train Epoch: 81 [11392/225000 (5%)] Loss: 14836.005859\n",
      "Train Epoch: 81 [12800/225000 (6%)] Loss: 15046.210938\n",
      "Train Epoch: 81 [14208/225000 (6%)] Loss: 15061.273438\n",
      "Train Epoch: 81 [15616/225000 (7%)] Loss: 14889.075195\n",
      "Train Epoch: 81 [17024/225000 (8%)] Loss: 15311.388672\n",
      "Train Epoch: 81 [18432/225000 (8%)] Loss: 14995.460938\n",
      "Train Epoch: 81 [19840/225000 (9%)] Loss: 15208.300781\n",
      "Train Epoch: 81 [21248/225000 (9%)] Loss: 14860.975586\n",
      "Train Epoch: 81 [22656/225000 (10%)] Loss: 14931.700195\n",
      "Train Epoch: 81 [24064/225000 (11%)] Loss: 15397.360352\n",
      "Train Epoch: 81 [25472/225000 (11%)] Loss: 15859.652344\n",
      "Train Epoch: 81 [26880/225000 (12%)] Loss: 15391.483398\n",
      "Train Epoch: 81 [28288/225000 (13%)] Loss: 15258.601562\n",
      "Train Epoch: 81 [29696/225000 (13%)] Loss: 15253.607422\n",
      "Train Epoch: 81 [31104/225000 (14%)] Loss: 15044.136719\n",
      "Train Epoch: 81 [32512/225000 (14%)] Loss: 15108.811523\n",
      "Train Epoch: 81 [33920/225000 (15%)] Loss: 15114.912109\n",
      "Train Epoch: 81 [35328/225000 (16%)] Loss: 14947.467773\n",
      "Train Epoch: 81 [36736/225000 (16%)] Loss: 15228.039062\n",
      "Train Epoch: 81 [38144/225000 (17%)] Loss: 14952.301758\n",
      "Train Epoch: 81 [39552/225000 (18%)] Loss: 15169.020508\n",
      "Train Epoch: 81 [40960/225000 (18%)] Loss: 15047.918945\n",
      "Train Epoch: 81 [42368/225000 (19%)] Loss: 14638.324219\n",
      "Train Epoch: 81 [43776/225000 (19%)] Loss: 15410.014648\n",
      "Train Epoch: 81 [45184/225000 (20%)] Loss: 15239.182617\n",
      "Train Epoch: 81 [46592/225000 (21%)] Loss: 15227.448242\n",
      "Train Epoch: 81 [48000/225000 (21%)] Loss: 14905.141602\n",
      "Train Epoch: 81 [49408/225000 (22%)] Loss: 15020.278320\n",
      "Train Epoch: 81 [50816/225000 (23%)] Loss: 14946.836914\n",
      "Train Epoch: 81 [52224/225000 (23%)] Loss: 15109.247070\n",
      "Train Epoch: 81 [53632/225000 (24%)] Loss: 15439.516602\n",
      "Train Epoch: 81 [55040/225000 (24%)] Loss: 15278.355469\n",
      "Train Epoch: 81 [56448/225000 (25%)] Loss: 15152.020508\n",
      "Train Epoch: 81 [57856/225000 (26%)] Loss: 15423.535156\n",
      "Train Epoch: 81 [59264/225000 (26%)] Loss: 14843.084961\n",
      "Train Epoch: 81 [60672/225000 (27%)] Loss: 15320.737305\n",
      "Train Epoch: 81 [62080/225000 (28%)] Loss: 15030.275391\n",
      "Train Epoch: 81 [63488/225000 (28%)] Loss: 14774.093750\n",
      "Train Epoch: 81 [64896/225000 (29%)] Loss: 15580.999023\n",
      "Train Epoch: 81 [66304/225000 (29%)] Loss: 15340.831055\n",
      "Train Epoch: 81 [67712/225000 (30%)] Loss: 15378.200195\n",
      "Train Epoch: 81 [69120/225000 (31%)] Loss: 15084.383789\n",
      "Train Epoch: 81 [70528/225000 (31%)] Loss: 15332.402344\n",
      "Train Epoch: 81 [71936/225000 (32%)] Loss: 15032.169922\n",
      "Train Epoch: 81 [73344/225000 (33%)] Loss: 15132.529297\n",
      "Train Epoch: 81 [74752/225000 (33%)] Loss: 15118.731445\n",
      "Train Epoch: 81 [76160/225000 (34%)] Loss: 15497.905273\n",
      "Train Epoch: 81 [77568/225000 (34%)] Loss: 15429.416992\n",
      "Train Epoch: 81 [78976/225000 (35%)] Loss: 15414.708008\n",
      "Train Epoch: 81 [80384/225000 (36%)] Loss: 14896.139648\n",
      "Train Epoch: 81 [81792/225000 (36%)] Loss: 15075.965820\n",
      "Train Epoch: 81 [83200/225000 (37%)] Loss: 14643.475586\n",
      "Train Epoch: 81 [84608/225000 (38%)] Loss: 14946.254883\n",
      "Train Epoch: 81 [86016/225000 (38%)] Loss: 15610.691406\n",
      "Train Epoch: 81 [87424/225000 (39%)] Loss: 14973.379883\n",
      "Train Epoch: 81 [88832/225000 (39%)] Loss: 14989.010742\n",
      "Train Epoch: 81 [90240/225000 (40%)] Loss: 15061.437500\n",
      "Train Epoch: 81 [91648/225000 (41%)] Loss: 15302.070312\n",
      "Train Epoch: 81 [93056/225000 (41%)] Loss: 15006.133789\n",
      "Train Epoch: 81 [94464/225000 (42%)] Loss: 14811.743164\n",
      "Train Epoch: 81 [95872/225000 (43%)] Loss: 14822.253906\n",
      "Train Epoch: 81 [97280/225000 (43%)] Loss: 14802.821289\n",
      "Train Epoch: 81 [98688/225000 (44%)] Loss: 15096.407227\n",
      "Train Epoch: 81 [100096/225000 (44%)] Loss: 14775.858398\n",
      "Train Epoch: 81 [101504/225000 (45%)] Loss: 14979.316406\n",
      "Train Epoch: 81 [102912/225000 (46%)] Loss: 14929.485352\n",
      "Train Epoch: 81 [104320/225000 (46%)] Loss: 14863.568359\n",
      "Train Epoch: 81 [105728/225000 (47%)] Loss: 15552.616211\n",
      "Train Epoch: 81 [107136/225000 (48%)] Loss: 15322.634766\n",
      "Train Epoch: 81 [108544/225000 (48%)] Loss: 15808.617188\n",
      "Train Epoch: 81 [109952/225000 (49%)] Loss: 15182.387695\n",
      "Train Epoch: 81 [111360/225000 (49%)] Loss: 15324.213867\n",
      "Train Epoch: 81 [112768/225000 (50%)] Loss: 15247.833008\n",
      "Train Epoch: 81 [114176/225000 (51%)] Loss: 15528.246094\n",
      "Train Epoch: 81 [115584/225000 (51%)] Loss: 15009.847656\n",
      "Train Epoch: 81 [116992/225000 (52%)] Loss: 15177.622070\n",
      "Train Epoch: 81 [118400/225000 (53%)] Loss: 15250.777344\n",
      "Train Epoch: 81 [119808/225000 (53%)] Loss: 14704.162109\n",
      "Train Epoch: 81 [121216/225000 (54%)] Loss: 15016.435547\n",
      "Train Epoch: 81 [122624/225000 (54%)] Loss: 15110.891602\n",
      "Train Epoch: 81 [124032/225000 (55%)] Loss: 14823.067383\n",
      "Train Epoch: 81 [125440/225000 (56%)] Loss: 14924.106445\n",
      "Train Epoch: 81 [126848/225000 (56%)] Loss: 14951.900391\n",
      "Train Epoch: 81 [128256/225000 (57%)] Loss: 15232.052734\n",
      "Train Epoch: 81 [129664/225000 (58%)] Loss: 14942.594727\n",
      "Train Epoch: 81 [131072/225000 (58%)] Loss: 15419.253906\n",
      "Train Epoch: 81 [132480/225000 (59%)] Loss: 15826.043945\n",
      "Train Epoch: 81 [133888/225000 (60%)] Loss: 15243.730469\n",
      "Train Epoch: 81 [135296/225000 (60%)] Loss: 14938.070312\n",
      "Train Epoch: 81 [136704/225000 (61%)] Loss: 15188.333984\n",
      "Train Epoch: 81 [138112/225000 (61%)] Loss: 14952.685547\n",
      "Train Epoch: 81 [139520/225000 (62%)] Loss: 14886.355469\n",
      "Train Epoch: 81 [140928/225000 (63%)] Loss: 15189.324219\n",
      "Train Epoch: 81 [142336/225000 (63%)] Loss: 15047.908203\n",
      "Train Epoch: 81 [143744/225000 (64%)] Loss: 15121.467773\n",
      "Train Epoch: 81 [145152/225000 (65%)] Loss: 15005.934570\n",
      "Train Epoch: 81 [146560/225000 (65%)] Loss: 14822.509766\n",
      "Train Epoch: 81 [147968/225000 (66%)] Loss: 15074.700195\n",
      "Train Epoch: 81 [149376/225000 (66%)] Loss: 15184.147461\n",
      "Train Epoch: 81 [150784/225000 (67%)] Loss: 14820.466797\n",
      "Train Epoch: 81 [152192/225000 (68%)] Loss: 15709.440430\n",
      "Train Epoch: 81 [153600/225000 (68%)] Loss: 15550.094727\n",
      "Train Epoch: 81 [155008/225000 (69%)] Loss: 15093.368164\n",
      "Train Epoch: 81 [156416/225000 (70%)] Loss: 15096.710938\n",
      "Train Epoch: 81 [157824/225000 (70%)] Loss: 15044.709961\n",
      "Train Epoch: 81 [159232/225000 (71%)] Loss: 15129.797852\n",
      "Train Epoch: 81 [160640/225000 (71%)] Loss: 15568.927734\n",
      "Train Epoch: 81 [162048/225000 (72%)] Loss: 14856.530273\n",
      "Train Epoch: 81 [163456/225000 (73%)] Loss: 15241.275391\n",
      "Train Epoch: 81 [164864/225000 (73%)] Loss: 14873.433594\n",
      "Train Epoch: 81 [166272/225000 (74%)] Loss: 15690.174805\n",
      "Train Epoch: 81 [167680/225000 (75%)] Loss: 15318.518555\n",
      "Train Epoch: 81 [169088/225000 (75%)] Loss: 15783.288086\n",
      "Train Epoch: 81 [170496/225000 (76%)] Loss: 14476.823242\n",
      "Train Epoch: 81 [171904/225000 (76%)] Loss: 15403.161133\n",
      "Train Epoch: 81 [173312/225000 (77%)] Loss: 15383.527344\n",
      "Train Epoch: 81 [174720/225000 (78%)] Loss: 15444.182617\n",
      "Train Epoch: 81 [176128/225000 (78%)] Loss: 15125.762695\n",
      "Train Epoch: 81 [177536/225000 (79%)] Loss: 14848.224609\n",
      "Train Epoch: 81 [178944/225000 (80%)] Loss: 15002.405273\n",
      "Train Epoch: 81 [180352/225000 (80%)] Loss: 14947.636719\n",
      "Train Epoch: 81 [181760/225000 (81%)] Loss: 15173.614258\n",
      "Train Epoch: 81 [183168/225000 (81%)] Loss: 15042.334961\n",
      "Train Epoch: 81 [184576/225000 (82%)] Loss: 14682.632812\n",
      "Train Epoch: 81 [185984/225000 (83%)] Loss: 15119.991211\n",
      "Train Epoch: 81 [187392/225000 (83%)] Loss: 14698.137695\n",
      "Train Epoch: 81 [188800/225000 (84%)] Loss: 14972.876953\n",
      "Train Epoch: 81 [190208/225000 (85%)] Loss: 14749.925781\n",
      "Train Epoch: 81 [191616/225000 (85%)] Loss: 14935.736328\n",
      "Train Epoch: 81 [193024/225000 (86%)] Loss: 15003.688477\n",
      "Train Epoch: 81 [194432/225000 (86%)] Loss: 15199.473633\n",
      "Train Epoch: 81 [195840/225000 (87%)] Loss: 14886.199219\n",
      "Train Epoch: 81 [197248/225000 (88%)] Loss: 14728.285156\n",
      "Train Epoch: 81 [198656/225000 (88%)] Loss: 15843.155273\n",
      "Train Epoch: 81 [200064/225000 (89%)] Loss: 15248.310547\n",
      "Train Epoch: 81 [201472/225000 (90%)] Loss: 15206.315430\n",
      "Train Epoch: 81 [202880/225000 (90%)] Loss: 15030.872070\n",
      "Train Epoch: 81 [204288/225000 (91%)] Loss: 14935.861328\n",
      "Train Epoch: 81 [205696/225000 (91%)] Loss: 15215.367188\n",
      "Train Epoch: 81 [207104/225000 (92%)] Loss: 15520.470703\n",
      "Train Epoch: 81 [208512/225000 (93%)] Loss: 14978.140625\n",
      "Train Epoch: 81 [209920/225000 (93%)] Loss: 15030.438477\n",
      "Train Epoch: 81 [211328/225000 (94%)] Loss: 14986.274414\n",
      "Train Epoch: 81 [212736/225000 (95%)] Loss: 14970.930664\n",
      "Train Epoch: 81 [214144/225000 (95%)] Loss: 15221.225586\n",
      "Train Epoch: 81 [215552/225000 (96%)] Loss: 15466.305664\n",
      "Train Epoch: 81 [216960/225000 (96%)] Loss: 14838.192383\n",
      "Train Epoch: 81 [218368/225000 (97%)] Loss: 15413.586914\n",
      "Train Epoch: 81 [219776/225000 (98%)] Loss: 15236.723633\n",
      "Train Epoch: 81 [221184/225000 (98%)] Loss: 15084.687500\n",
      "Train Epoch: 81 [222592/225000 (99%)] Loss: 15427.554688\n",
      "Train Epoch: 81 [224000/225000 (100%)] Loss: 15164.883789\n",
      "    epoch          : 81\n",
      "    loss           : 15074.084281565521\n",
      "    val_loss       : 15055.45053610601\n",
      "Train Epoch: 82 [128/225000 (0%)] Loss: 14698.197266\n",
      "Train Epoch: 82 [1536/225000 (1%)] Loss: 15638.437500\n",
      "Train Epoch: 82 [2944/225000 (1%)] Loss: 15272.238281\n",
      "Train Epoch: 82 [4352/225000 (2%)] Loss: 15022.262695\n",
      "Train Epoch: 82 [5760/225000 (3%)] Loss: 15419.113281\n",
      "Train Epoch: 82 [7168/225000 (3%)] Loss: 15036.645508\n",
      "Train Epoch: 82 [8576/225000 (4%)] Loss: 15451.768555\n",
      "Train Epoch: 82 [9984/225000 (4%)] Loss: 15201.414062\n",
      "Train Epoch: 82 [11392/225000 (5%)] Loss: 15292.317383\n",
      "Train Epoch: 82 [12800/225000 (6%)] Loss: 15635.227539\n",
      "Train Epoch: 82 [14208/225000 (6%)] Loss: 15383.017578\n",
      "Train Epoch: 82 [15616/225000 (7%)] Loss: 15018.209961\n",
      "Train Epoch: 82 [17024/225000 (8%)] Loss: 15549.060547\n",
      "Train Epoch: 82 [18432/225000 (8%)] Loss: 15193.401367\n",
      "Train Epoch: 82 [19840/225000 (9%)] Loss: 15072.018555\n",
      "Train Epoch: 82 [21248/225000 (9%)] Loss: 14958.984375\n",
      "Train Epoch: 82 [22656/225000 (10%)] Loss: 14987.335938\n",
      "Train Epoch: 82 [24064/225000 (11%)] Loss: 15149.265625\n",
      "Train Epoch: 82 [25472/225000 (11%)] Loss: 15103.720703\n",
      "Train Epoch: 82 [26880/225000 (12%)] Loss: 15006.644531\n",
      "Train Epoch: 82 [28288/225000 (13%)] Loss: 15493.620117\n",
      "Train Epoch: 82 [29696/225000 (13%)] Loss: 15160.578125\n",
      "Train Epoch: 82 [31104/225000 (14%)] Loss: 14982.727539\n",
      "Train Epoch: 82 [32512/225000 (14%)] Loss: 14971.246094\n",
      "Train Epoch: 82 [33920/225000 (15%)] Loss: 14403.682617\n",
      "Train Epoch: 82 [35328/225000 (16%)] Loss: 15158.592773\n",
      "Train Epoch: 82 [36736/225000 (16%)] Loss: 14940.077148\n",
      "Train Epoch: 82 [38144/225000 (17%)] Loss: 14536.250977\n",
      "Train Epoch: 82 [39552/225000 (18%)] Loss: 15430.212891\n",
      "Train Epoch: 82 [40960/225000 (18%)] Loss: 14886.320312\n",
      "Train Epoch: 82 [42368/225000 (19%)] Loss: 15375.887695\n",
      "Train Epoch: 82 [43776/225000 (19%)] Loss: 14590.972656\n",
      "Train Epoch: 82 [45184/225000 (20%)] Loss: 14912.714844\n",
      "Train Epoch: 82 [46592/225000 (21%)] Loss: 15543.146484\n",
      "Train Epoch: 82 [48000/225000 (21%)] Loss: 15132.453125\n",
      "Train Epoch: 82 [49408/225000 (22%)] Loss: 14800.753906\n",
      "Train Epoch: 82 [50816/225000 (23%)] Loss: 14561.917969\n",
      "Train Epoch: 82 [52224/225000 (23%)] Loss: 15288.778320\n",
      "Train Epoch: 82 [53632/225000 (24%)] Loss: 15224.991211\n",
      "Train Epoch: 82 [55040/225000 (24%)] Loss: 14727.060547\n",
      "Train Epoch: 82 [56448/225000 (25%)] Loss: 15112.133789\n",
      "Train Epoch: 82 [57856/225000 (26%)] Loss: 14412.889648\n",
      "Train Epoch: 82 [59264/225000 (26%)] Loss: 14992.490234\n",
      "Train Epoch: 82 [60672/225000 (27%)] Loss: 15516.563477\n",
      "Train Epoch: 82 [62080/225000 (28%)] Loss: 14753.272461\n",
      "Train Epoch: 82 [63488/225000 (28%)] Loss: 14870.092773\n",
      "Train Epoch: 82 [64896/225000 (29%)] Loss: 14802.429688\n",
      "Train Epoch: 82 [66304/225000 (29%)] Loss: 14817.841797\n",
      "Train Epoch: 82 [67712/225000 (30%)] Loss: 15363.908203\n",
      "Train Epoch: 82 [69120/225000 (31%)] Loss: 15349.972656\n",
      "Train Epoch: 82 [70528/225000 (31%)] Loss: 15132.192383\n",
      "Train Epoch: 82 [71936/225000 (32%)] Loss: 15549.964844\n",
      "Train Epoch: 82 [73344/225000 (33%)] Loss: 15719.597656\n",
      "Train Epoch: 82 [74752/225000 (33%)] Loss: 15360.664062\n",
      "Train Epoch: 82 [76160/225000 (34%)] Loss: 15114.458984\n",
      "Train Epoch: 82 [77568/225000 (34%)] Loss: 14535.517578\n",
      "Train Epoch: 82 [78976/225000 (35%)] Loss: 15291.007812\n",
      "Train Epoch: 82 [80384/225000 (36%)] Loss: 14635.244141\n",
      "Train Epoch: 82 [81792/225000 (36%)] Loss: 15167.597656\n",
      "Train Epoch: 82 [83200/225000 (37%)] Loss: 15012.024414\n",
      "Train Epoch: 82 [84608/225000 (38%)] Loss: 15014.938477\n",
      "Train Epoch: 82 [86016/225000 (38%)] Loss: 15040.851562\n",
      "Train Epoch: 82 [87424/225000 (39%)] Loss: 15065.169922\n",
      "Train Epoch: 82 [88832/225000 (39%)] Loss: 15410.531250\n",
      "Train Epoch: 82 [90240/225000 (40%)] Loss: 15012.023438\n",
      "Train Epoch: 82 [91648/225000 (41%)] Loss: 15554.376953\n",
      "Train Epoch: 82 [93056/225000 (41%)] Loss: 14730.217773\n",
      "Train Epoch: 82 [94464/225000 (42%)] Loss: 15256.308594\n",
      "Train Epoch: 82 [95872/225000 (43%)] Loss: 15309.389648\n",
      "Train Epoch: 82 [97280/225000 (43%)] Loss: 15142.720703\n",
      "Train Epoch: 82 [98688/225000 (44%)] Loss: 15676.964844\n",
      "Train Epoch: 82 [100096/225000 (44%)] Loss: 15209.077148\n",
      "Train Epoch: 82 [101504/225000 (45%)] Loss: 15012.487305\n",
      "Train Epoch: 82 [102912/225000 (46%)] Loss: 15174.957031\n",
      "Train Epoch: 82 [104320/225000 (46%)] Loss: 15431.187500\n",
      "Train Epoch: 82 [105728/225000 (47%)] Loss: 15169.261719\n",
      "Train Epoch: 82 [107136/225000 (48%)] Loss: 14911.114258\n",
      "Train Epoch: 82 [108544/225000 (48%)] Loss: 15543.330078\n",
      "Train Epoch: 82 [109952/225000 (49%)] Loss: 15079.834961\n",
      "Train Epoch: 82 [111360/225000 (49%)] Loss: 15030.104492\n",
      "Train Epoch: 82 [112768/225000 (50%)] Loss: 15262.031250\n",
      "Train Epoch: 82 [114176/225000 (51%)] Loss: 14736.822266\n",
      "Train Epoch: 82 [115584/225000 (51%)] Loss: 14963.232422\n",
      "Train Epoch: 82 [116992/225000 (52%)] Loss: 14998.753906\n",
      "Train Epoch: 82 [118400/225000 (53%)] Loss: 15012.990234\n",
      "Train Epoch: 82 [119808/225000 (53%)] Loss: 15157.996094\n",
      "Train Epoch: 82 [121216/225000 (54%)] Loss: 15209.824219\n",
      "Train Epoch: 82 [122624/225000 (54%)] Loss: 15244.986328\n",
      "Train Epoch: 82 [124032/225000 (55%)] Loss: 14831.982422\n",
      "Train Epoch: 82 [125440/225000 (56%)] Loss: 15033.668945\n",
      "Train Epoch: 82 [126848/225000 (56%)] Loss: 14622.666016\n",
      "Train Epoch: 82 [128256/225000 (57%)] Loss: 15447.688477\n",
      "Train Epoch: 82 [129664/225000 (58%)] Loss: 15118.246094\n",
      "Train Epoch: 82 [131072/225000 (58%)] Loss: 14869.725586\n",
      "Train Epoch: 82 [132480/225000 (59%)] Loss: 15144.972656\n",
      "Train Epoch: 82 [133888/225000 (60%)] Loss: 15114.872070\n",
      "Train Epoch: 82 [135296/225000 (60%)] Loss: 15090.650391\n",
      "Train Epoch: 82 [136704/225000 (61%)] Loss: 15256.381836\n",
      "Train Epoch: 82 [138112/225000 (61%)] Loss: 15130.068359\n",
      "Train Epoch: 82 [139520/225000 (62%)] Loss: 15677.909180\n",
      "Train Epoch: 82 [140928/225000 (63%)] Loss: 14661.136719\n",
      "Train Epoch: 82 [142336/225000 (63%)] Loss: 15204.868164\n",
      "Train Epoch: 82 [143744/225000 (64%)] Loss: 15376.583984\n",
      "Train Epoch: 82 [145152/225000 (65%)] Loss: 14986.098633\n",
      "Train Epoch: 82 [146560/225000 (65%)] Loss: 15191.140625\n",
      "Train Epoch: 82 [147968/225000 (66%)] Loss: 14817.107422\n",
      "Train Epoch: 82 [149376/225000 (66%)] Loss: 14970.052734\n",
      "Train Epoch: 82 [150784/225000 (67%)] Loss: 15509.700195\n",
      "Train Epoch: 82 [152192/225000 (68%)] Loss: 15081.912109\n",
      "Train Epoch: 82 [153600/225000 (68%)] Loss: 14419.048828\n",
      "Train Epoch: 82 [155008/225000 (69%)] Loss: 15025.783203\n",
      "Train Epoch: 82 [156416/225000 (70%)] Loss: 14541.462891\n",
      "Train Epoch: 82 [157824/225000 (70%)] Loss: 14750.055664\n",
      "Train Epoch: 82 [159232/225000 (71%)] Loss: 14996.574219\n",
      "Train Epoch: 82 [160640/225000 (71%)] Loss: 15158.143555\n",
      "Train Epoch: 82 [162048/225000 (72%)] Loss: 15239.793945\n",
      "Train Epoch: 82 [163456/225000 (73%)] Loss: 15024.909180\n",
      "Train Epoch: 82 [164864/225000 (73%)] Loss: 15462.992188\n",
      "Train Epoch: 82 [166272/225000 (74%)] Loss: 15184.236328\n",
      "Train Epoch: 82 [167680/225000 (75%)] Loss: 15310.845703\n",
      "Train Epoch: 82 [169088/225000 (75%)] Loss: 14722.529297\n",
      "Train Epoch: 82 [170496/225000 (76%)] Loss: 14957.425781\n",
      "Train Epoch: 82 [171904/225000 (76%)] Loss: 14696.140625\n",
      "Train Epoch: 82 [173312/225000 (77%)] Loss: 14759.273438\n",
      "Train Epoch: 82 [174720/225000 (78%)] Loss: 14925.590820\n",
      "Train Epoch: 82 [176128/225000 (78%)] Loss: 15340.215820\n",
      "Train Epoch: 82 [177536/225000 (79%)] Loss: 14746.256836\n",
      "Train Epoch: 82 [178944/225000 (80%)] Loss: 14855.714844\n",
      "Train Epoch: 82 [180352/225000 (80%)] Loss: 15106.370117\n",
      "Train Epoch: 82 [181760/225000 (81%)] Loss: 14838.887695\n",
      "Train Epoch: 82 [183168/225000 (81%)] Loss: 15196.091797\n",
      "Train Epoch: 82 [184576/225000 (82%)] Loss: 14857.914062\n",
      "Train Epoch: 82 [185984/225000 (83%)] Loss: 14608.412109\n",
      "Train Epoch: 82 [187392/225000 (83%)] Loss: 14846.522461\n",
      "Train Epoch: 82 [188800/225000 (84%)] Loss: 15276.878906\n",
      "Train Epoch: 82 [190208/225000 (85%)] Loss: 15244.475586\n",
      "Train Epoch: 82 [191616/225000 (85%)] Loss: 14898.506836\n",
      "Train Epoch: 82 [193024/225000 (86%)] Loss: 14946.188477\n",
      "Train Epoch: 82 [194432/225000 (86%)] Loss: 14725.290039\n",
      "Train Epoch: 82 [195840/225000 (87%)] Loss: 15125.718750\n",
      "Train Epoch: 82 [197248/225000 (88%)] Loss: 15309.837891\n",
      "Train Epoch: 82 [198656/225000 (88%)] Loss: 15116.555664\n",
      "Train Epoch: 82 [200064/225000 (89%)] Loss: 15523.389648\n",
      "Train Epoch: 82 [201472/225000 (90%)] Loss: 15282.570312\n",
      "Train Epoch: 82 [202880/225000 (90%)] Loss: 15356.734375\n",
      "Train Epoch: 82 [204288/225000 (91%)] Loss: 15119.215820\n",
      "Train Epoch: 82 [205696/225000 (91%)] Loss: 15507.305664\n",
      "Train Epoch: 82 [207104/225000 (92%)] Loss: 15539.663086\n",
      "Train Epoch: 82 [208512/225000 (93%)] Loss: 15045.761719\n",
      "Train Epoch: 82 [209920/225000 (93%)] Loss: 15121.859375\n",
      "Train Epoch: 82 [211328/225000 (94%)] Loss: 15077.191406\n",
      "Train Epoch: 82 [212736/225000 (95%)] Loss: 15164.800781\n",
      "Train Epoch: 82 [214144/225000 (95%)] Loss: 15510.252930\n",
      "Train Epoch: 82 [215552/225000 (96%)] Loss: 14532.659180\n",
      "Train Epoch: 82 [216960/225000 (96%)] Loss: 15655.373047\n",
      "Train Epoch: 82 [218368/225000 (97%)] Loss: 14960.973633\n",
      "Train Epoch: 82 [219776/225000 (98%)] Loss: 14904.844727\n",
      "Train Epoch: 82 [221184/225000 (98%)] Loss: 14698.434570\n",
      "Train Epoch: 82 [222592/225000 (99%)] Loss: 15587.780273\n",
      "Train Epoch: 82 [224000/225000 (100%)] Loss: 14955.895508\n",
      "    epoch          : 82\n",
      "    loss           : 15075.011653756932\n",
      "    val_loss       : 15058.25858520458\n",
      "Train Epoch: 83 [128/225000 (0%)] Loss: 15519.778320\n",
      "Train Epoch: 83 [1536/225000 (1%)] Loss: 14963.616211\n",
      "Train Epoch: 83 [2944/225000 (1%)] Loss: 14786.403320\n",
      "Train Epoch: 83 [4352/225000 (2%)] Loss: 15471.814453\n",
      "Train Epoch: 83 [5760/225000 (3%)] Loss: 14806.045898\n",
      "Train Epoch: 83 [7168/225000 (3%)] Loss: 15125.108398\n",
      "Train Epoch: 83 [8576/225000 (4%)] Loss: 15081.796875\n",
      "Train Epoch: 83 [9984/225000 (4%)] Loss: 15157.876953\n",
      "Train Epoch: 83 [11392/225000 (5%)] Loss: 15082.444336\n",
      "Train Epoch: 83 [12800/225000 (6%)] Loss: 15008.279297\n",
      "Train Epoch: 83 [14208/225000 (6%)] Loss: 15067.541992\n",
      "Train Epoch: 83 [15616/225000 (7%)] Loss: 15273.176758\n",
      "Train Epoch: 83 [17024/225000 (8%)] Loss: 15305.554688\n",
      "Train Epoch: 83 [18432/225000 (8%)] Loss: 15053.401367\n",
      "Train Epoch: 83 [19840/225000 (9%)] Loss: 14806.801758\n",
      "Train Epoch: 83 [21248/225000 (9%)] Loss: 15438.373047\n",
      "Train Epoch: 83 [22656/225000 (10%)] Loss: 15296.587891\n",
      "Train Epoch: 83 [24064/225000 (11%)] Loss: 15961.122070\n",
      "Train Epoch: 83 [25472/225000 (11%)] Loss: 15164.505859\n",
      "Train Epoch: 83 [26880/225000 (12%)] Loss: 15088.668945\n",
      "Train Epoch: 83 [28288/225000 (13%)] Loss: 15027.810547\n",
      "Train Epoch: 83 [29696/225000 (13%)] Loss: 15077.605469\n",
      "Train Epoch: 83 [31104/225000 (14%)] Loss: 15166.198242\n",
      "Train Epoch: 83 [32512/225000 (14%)] Loss: 15443.341797\n",
      "Train Epoch: 83 [33920/225000 (15%)] Loss: 14978.726562\n",
      "Train Epoch: 83 [35328/225000 (16%)] Loss: 15325.184570\n",
      "Train Epoch: 83 [36736/225000 (16%)] Loss: 15125.474609\n",
      "Train Epoch: 83 [38144/225000 (17%)] Loss: 15058.427734\n",
      "Train Epoch: 83 [39552/225000 (18%)] Loss: 15336.297852\n",
      "Train Epoch: 83 [40960/225000 (18%)] Loss: 14781.886719\n",
      "Train Epoch: 83 [42368/225000 (19%)] Loss: 14958.347656\n",
      "Train Epoch: 83 [43776/225000 (19%)] Loss: 14957.325195\n",
      "Train Epoch: 83 [45184/225000 (20%)] Loss: 14955.250977\n",
      "Train Epoch: 83 [46592/225000 (21%)] Loss: 14979.140625\n",
      "Train Epoch: 83 [48000/225000 (21%)] Loss: 14960.932617\n",
      "Train Epoch: 83 [49408/225000 (22%)] Loss: 15029.585938\n",
      "Train Epoch: 83 [50816/225000 (23%)] Loss: 15161.768555\n",
      "Train Epoch: 83 [52224/225000 (23%)] Loss: 14973.162109\n",
      "Train Epoch: 83 [53632/225000 (24%)] Loss: 15422.367188\n",
      "Train Epoch: 83 [55040/225000 (24%)] Loss: 14776.301758\n",
      "Train Epoch: 83 [56448/225000 (25%)] Loss: 15222.398438\n",
      "Train Epoch: 83 [57856/225000 (26%)] Loss: 14968.503906\n",
      "Train Epoch: 83 [59264/225000 (26%)] Loss: 15016.927734\n",
      "Train Epoch: 83 [60672/225000 (27%)] Loss: 14769.139648\n",
      "Train Epoch: 83 [62080/225000 (28%)] Loss: 15671.101562\n",
      "Train Epoch: 83 [63488/225000 (28%)] Loss: 14888.241211\n",
      "Train Epoch: 83 [64896/225000 (29%)] Loss: 15163.644531\n",
      "Train Epoch: 83 [66304/225000 (29%)] Loss: 15252.887695\n",
      "Train Epoch: 83 [67712/225000 (30%)] Loss: 15203.785156\n",
      "Train Epoch: 83 [69120/225000 (31%)] Loss: 15026.013672\n",
      "Train Epoch: 83 [70528/225000 (31%)] Loss: 15381.227539\n",
      "Train Epoch: 83 [71936/225000 (32%)] Loss: 15143.470703\n",
      "Train Epoch: 83 [73344/225000 (33%)] Loss: 15369.440430\n",
      "Train Epoch: 83 [74752/225000 (33%)] Loss: 14924.504883\n",
      "Train Epoch: 83 [76160/225000 (34%)] Loss: 14880.060547\n",
      "Train Epoch: 83 [77568/225000 (34%)] Loss: 14603.041016\n",
      "Train Epoch: 83 [78976/225000 (35%)] Loss: 15092.141602\n",
      "Train Epoch: 83 [80384/225000 (36%)] Loss: 15537.410156\n",
      "Train Epoch: 83 [81792/225000 (36%)] Loss: 14697.649414\n",
      "Train Epoch: 83 [83200/225000 (37%)] Loss: 15082.650391\n",
      "Train Epoch: 83 [84608/225000 (38%)] Loss: 14938.869141\n",
      "Train Epoch: 83 [86016/225000 (38%)] Loss: 15448.272461\n",
      "Train Epoch: 83 [87424/225000 (39%)] Loss: 15132.140625\n",
      "Train Epoch: 83 [88832/225000 (39%)] Loss: 15095.094727\n",
      "Train Epoch: 83 [90240/225000 (40%)] Loss: 15797.610352\n",
      "Train Epoch: 83 [91648/225000 (41%)] Loss: 14998.139648\n",
      "Train Epoch: 83 [93056/225000 (41%)] Loss: 15056.200195\n",
      "Train Epoch: 83 [94464/225000 (42%)] Loss: 14929.184570\n",
      "Train Epoch: 83 [95872/225000 (43%)] Loss: 15286.422852\n",
      "Train Epoch: 83 [97280/225000 (43%)] Loss: 14941.853516\n",
      "Train Epoch: 83 [98688/225000 (44%)] Loss: 15291.007812\n",
      "Train Epoch: 83 [100096/225000 (44%)] Loss: 15280.085938\n",
      "Train Epoch: 83 [101504/225000 (45%)] Loss: 14818.394531\n",
      "Train Epoch: 83 [102912/225000 (46%)] Loss: 15059.787109\n",
      "Train Epoch: 83 [104320/225000 (46%)] Loss: 15237.835938\n",
      "Train Epoch: 83 [105728/225000 (47%)] Loss: 15029.505859\n",
      "Train Epoch: 83 [107136/225000 (48%)] Loss: 14940.542969\n",
      "Train Epoch: 83 [108544/225000 (48%)] Loss: 14974.598633\n",
      "Train Epoch: 83 [109952/225000 (49%)] Loss: 15097.365234\n",
      "Train Epoch: 83 [111360/225000 (49%)] Loss: 14778.814453\n",
      "Train Epoch: 83 [112768/225000 (50%)] Loss: 15453.474609\n",
      "Train Epoch: 83 [114176/225000 (51%)] Loss: 14994.084961\n",
      "Train Epoch: 83 [115584/225000 (51%)] Loss: 14954.817383\n",
      "Train Epoch: 83 [116992/225000 (52%)] Loss: 15332.583984\n",
      "Train Epoch: 83 [118400/225000 (53%)] Loss: 14926.101562\n",
      "Train Epoch: 83 [119808/225000 (53%)] Loss: 14954.517578\n",
      "Train Epoch: 83 [121216/225000 (54%)] Loss: 15113.391602\n",
      "Train Epoch: 83 [122624/225000 (54%)] Loss: 14869.007812\n",
      "Train Epoch: 83 [124032/225000 (55%)] Loss: 15129.208008\n",
      "Train Epoch: 83 [125440/225000 (56%)] Loss: 15253.617188\n",
      "Train Epoch: 83 [126848/225000 (56%)] Loss: 14925.416016\n",
      "Train Epoch: 83 [128256/225000 (57%)] Loss: 14885.375977\n",
      "Train Epoch: 83 [129664/225000 (58%)] Loss: 15133.471680\n",
      "Train Epoch: 83 [131072/225000 (58%)] Loss: 15073.705078\n",
      "Train Epoch: 83 [132480/225000 (59%)] Loss: 15114.825195\n",
      "Train Epoch: 83 [133888/225000 (60%)] Loss: 15181.264648\n",
      "Train Epoch: 83 [135296/225000 (60%)] Loss: 14704.114258\n",
      "Train Epoch: 83 [136704/225000 (61%)] Loss: 15079.625000\n",
      "Train Epoch: 83 [138112/225000 (61%)] Loss: 15000.286133\n",
      "Train Epoch: 83 [139520/225000 (62%)] Loss: 15316.831055\n",
      "Train Epoch: 83 [140928/225000 (63%)] Loss: 15415.586914\n",
      "Train Epoch: 83 [142336/225000 (63%)] Loss: 15008.253906\n",
      "Train Epoch: 83 [143744/225000 (64%)] Loss: 14706.412109\n",
      "Train Epoch: 83 [145152/225000 (65%)] Loss: 15416.000977\n",
      "Train Epoch: 83 [146560/225000 (65%)] Loss: 14804.624023\n",
      "Train Epoch: 83 [147968/225000 (66%)] Loss: 14759.239258\n",
      "Train Epoch: 83 [149376/225000 (66%)] Loss: 14936.256836\n",
      "Train Epoch: 83 [150784/225000 (67%)] Loss: 14912.171875\n",
      "Train Epoch: 83 [152192/225000 (68%)] Loss: 15361.559570\n",
      "Train Epoch: 83 [153600/225000 (68%)] Loss: 14936.553711\n",
      "Train Epoch: 83 [155008/225000 (69%)] Loss: 15138.137695\n",
      "Train Epoch: 83 [156416/225000 (70%)] Loss: 15127.864258\n",
      "Train Epoch: 83 [157824/225000 (70%)] Loss: 14846.050781\n",
      "Train Epoch: 83 [159232/225000 (71%)] Loss: 15012.424805\n",
      "Train Epoch: 83 [160640/225000 (71%)] Loss: 14950.799805\n",
      "Train Epoch: 83 [162048/225000 (72%)] Loss: 15130.524414\n",
      "Train Epoch: 83 [163456/225000 (73%)] Loss: 14962.693359\n",
      "Train Epoch: 83 [164864/225000 (73%)] Loss: 15192.334961\n",
      "Train Epoch: 83 [166272/225000 (74%)] Loss: 14998.723633\n",
      "Train Epoch: 83 [167680/225000 (75%)] Loss: 14983.386719\n",
      "Train Epoch: 83 [169088/225000 (75%)] Loss: 14566.333008\n",
      "Train Epoch: 83 [170496/225000 (76%)] Loss: 15266.812500\n",
      "Train Epoch: 83 [171904/225000 (76%)] Loss: 14957.099609\n",
      "Train Epoch: 83 [173312/225000 (77%)] Loss: 14723.167969\n",
      "Train Epoch: 83 [174720/225000 (78%)] Loss: 14951.524414\n",
      "Train Epoch: 83 [176128/225000 (78%)] Loss: 14891.411133\n",
      "Train Epoch: 83 [177536/225000 (79%)] Loss: 14848.131836\n",
      "Train Epoch: 83 [178944/225000 (80%)] Loss: 15118.599609\n",
      "Train Epoch: 83 [180352/225000 (80%)] Loss: 15038.461914\n",
      "Train Epoch: 83 [181760/225000 (81%)] Loss: 14919.309570\n",
      "Train Epoch: 83 [183168/225000 (81%)] Loss: 15186.867188\n",
      "Train Epoch: 83 [184576/225000 (82%)] Loss: 15376.050781\n",
      "Train Epoch: 83 [185984/225000 (83%)] Loss: 15246.419922\n",
      "Train Epoch: 83 [187392/225000 (83%)] Loss: 15051.367188\n",
      "Train Epoch: 83 [188800/225000 (84%)] Loss: 15024.452148\n",
      "Train Epoch: 83 [190208/225000 (85%)] Loss: 15089.525391\n",
      "Train Epoch: 83 [191616/225000 (85%)] Loss: 15361.787109\n",
      "Train Epoch: 83 [193024/225000 (86%)] Loss: 15505.436523\n",
      "Train Epoch: 83 [194432/225000 (86%)] Loss: 14945.160156\n",
      "Train Epoch: 83 [195840/225000 (87%)] Loss: 14791.382812\n",
      "Train Epoch: 83 [197248/225000 (88%)] Loss: 14777.310547\n",
      "Train Epoch: 83 [198656/225000 (88%)] Loss: 15031.662109\n",
      "Train Epoch: 83 [200064/225000 (89%)] Loss: 15021.843750\n",
      "Train Epoch: 83 [201472/225000 (90%)] Loss: 15582.286133\n",
      "Train Epoch: 83 [202880/225000 (90%)] Loss: 14495.847656\n",
      "Train Epoch: 83 [204288/225000 (91%)] Loss: 14971.732422\n",
      "Train Epoch: 83 [205696/225000 (91%)] Loss: 15189.436523\n",
      "Train Epoch: 83 [207104/225000 (92%)] Loss: 14878.138672\n",
      "Train Epoch: 83 [208512/225000 (93%)] Loss: 14894.929688\n",
      "Train Epoch: 83 [209920/225000 (93%)] Loss: 14824.105469\n",
      "Train Epoch: 83 [211328/225000 (94%)] Loss: 15255.825195\n",
      "Train Epoch: 83 [212736/225000 (95%)] Loss: 14876.034180\n",
      "Train Epoch: 83 [214144/225000 (95%)] Loss: 14643.975586\n",
      "Train Epoch: 83 [215552/225000 (96%)] Loss: 14825.422852\n",
      "Train Epoch: 83 [216960/225000 (96%)] Loss: 14493.869141\n",
      "Train Epoch: 83 [218368/225000 (97%)] Loss: 15219.993164\n",
      "Train Epoch: 83 [219776/225000 (98%)] Loss: 15567.143555\n",
      "Train Epoch: 83 [221184/225000 (98%)] Loss: 14965.620117\n",
      "Train Epoch: 83 [222592/225000 (99%)] Loss: 15098.165039\n",
      "Train Epoch: 83 [224000/225000 (100%)] Loss: 14681.940430\n",
      "    epoch          : 83\n",
      "    loss           : 15073.599078876032\n",
      "    val_loss       : 15063.686476942836\n",
      "Train Epoch: 84 [128/225000 (0%)] Loss: 14946.734375\n",
      "Train Epoch: 84 [1536/225000 (1%)] Loss: 15005.240234\n",
      "Train Epoch: 84 [2944/225000 (1%)] Loss: 15129.313477\n",
      "Train Epoch: 84 [4352/225000 (2%)] Loss: 14899.305664\n",
      "Train Epoch: 84 [5760/225000 (3%)] Loss: 15527.200195\n",
      "Train Epoch: 84 [7168/225000 (3%)] Loss: 14818.976562\n",
      "Train Epoch: 84 [8576/225000 (4%)] Loss: 15523.255859\n",
      "Train Epoch: 84 [9984/225000 (4%)] Loss: 15568.547852\n",
      "Train Epoch: 84 [11392/225000 (5%)] Loss: 15269.233398\n",
      "Train Epoch: 84 [12800/225000 (6%)] Loss: 15177.007812\n",
      "Train Epoch: 84 [14208/225000 (6%)] Loss: 15404.310547\n",
      "Train Epoch: 84 [15616/225000 (7%)] Loss: 15202.967773\n",
      "Train Epoch: 84 [17024/225000 (8%)] Loss: 15249.076172\n",
      "Train Epoch: 84 [18432/225000 (8%)] Loss: 14917.443359\n",
      "Train Epoch: 84 [19840/225000 (9%)] Loss: 15031.233398\n",
      "Train Epoch: 84 [21248/225000 (9%)] Loss: 15297.381836\n",
      "Train Epoch: 84 [22656/225000 (10%)] Loss: 14814.063477\n",
      "Train Epoch: 84 [24064/225000 (11%)] Loss: 15167.312500\n",
      "Train Epoch: 84 [25472/225000 (11%)] Loss: 14941.336914\n",
      "Train Epoch: 84 [26880/225000 (12%)] Loss: 15204.601562\n",
      "Train Epoch: 84 [28288/225000 (13%)] Loss: 14871.165039\n",
      "Train Epoch: 84 [29696/225000 (13%)] Loss: 14755.701172\n",
      "Train Epoch: 84 [31104/225000 (14%)] Loss: 14846.030273\n",
      "Train Epoch: 84 [32512/225000 (14%)] Loss: 14851.740234\n",
      "Train Epoch: 84 [33920/225000 (15%)] Loss: 14568.357422\n",
      "Train Epoch: 84 [35328/225000 (16%)] Loss: 14753.933594\n",
      "Train Epoch: 84 [36736/225000 (16%)] Loss: 15150.056641\n",
      "Train Epoch: 84 [38144/225000 (17%)] Loss: 14984.102539\n",
      "Train Epoch: 84 [39552/225000 (18%)] Loss: 14990.242188\n",
      "Train Epoch: 84 [40960/225000 (18%)] Loss: 15082.912109\n",
      "Train Epoch: 84 [42368/225000 (19%)] Loss: 14827.375977\n",
      "Train Epoch: 84 [43776/225000 (19%)] Loss: 15335.739258\n",
      "Train Epoch: 84 [45184/225000 (20%)] Loss: 14778.944336\n",
      "Train Epoch: 84 [46592/225000 (21%)] Loss: 15101.761719\n",
      "Train Epoch: 84 [48000/225000 (21%)] Loss: 15209.053711\n",
      "Train Epoch: 84 [49408/225000 (22%)] Loss: 15478.898438\n",
      "Train Epoch: 84 [50816/225000 (23%)] Loss: 14904.944336\n",
      "Train Epoch: 84 [52224/225000 (23%)] Loss: 14520.732422\n",
      "Train Epoch: 84 [53632/225000 (24%)] Loss: 14955.027344\n",
      "Train Epoch: 84 [55040/225000 (24%)] Loss: 15185.217773\n",
      "Train Epoch: 84 [56448/225000 (25%)] Loss: 15378.535156\n",
      "Train Epoch: 84 [57856/225000 (26%)] Loss: 15085.977539\n",
      "Train Epoch: 84 [59264/225000 (26%)] Loss: 15289.374023\n",
      "Train Epoch: 84 [60672/225000 (27%)] Loss: 15119.523438\n",
      "Train Epoch: 84 [62080/225000 (28%)] Loss: 14919.602539\n",
      "Train Epoch: 84 [63488/225000 (28%)] Loss: 15322.844727\n",
      "Train Epoch: 84 [64896/225000 (29%)] Loss: 15643.384766\n",
      "Train Epoch: 84 [66304/225000 (29%)] Loss: 15549.956055\n",
      "Train Epoch: 84 [67712/225000 (30%)] Loss: 15281.253906\n",
      "Train Epoch: 84 [69120/225000 (31%)] Loss: 15144.547852\n",
      "Train Epoch: 84 [70528/225000 (31%)] Loss: 14925.798828\n",
      "Train Epoch: 84 [71936/225000 (32%)] Loss: 14961.836914\n",
      "Train Epoch: 84 [73344/225000 (33%)] Loss: 15371.395508\n",
      "Train Epoch: 84 [74752/225000 (33%)] Loss: 14720.781250\n",
      "Train Epoch: 84 [76160/225000 (34%)] Loss: 15061.650391\n",
      "Train Epoch: 84 [77568/225000 (34%)] Loss: 15094.735352\n",
      "Train Epoch: 84 [78976/225000 (35%)] Loss: 15021.120117\n",
      "Train Epoch: 84 [80384/225000 (36%)] Loss: 14877.710938\n",
      "Train Epoch: 84 [81792/225000 (36%)] Loss: 14909.516602\n",
      "Train Epoch: 84 [83200/225000 (37%)] Loss: 15548.927734\n",
      "Train Epoch: 84 [84608/225000 (38%)] Loss: 15398.122070\n",
      "Train Epoch: 84 [86016/225000 (38%)] Loss: 14999.884766\n",
      "Train Epoch: 84 [87424/225000 (39%)] Loss: 14644.462891\n",
      "Train Epoch: 84 [88832/225000 (39%)] Loss: 15294.541016\n",
      "Train Epoch: 84 [90240/225000 (40%)] Loss: 15083.798828\n",
      "Train Epoch: 84 [91648/225000 (41%)] Loss: 14423.208984\n",
      "Train Epoch: 84 [93056/225000 (41%)] Loss: 14688.980469\n",
      "Train Epoch: 84 [94464/225000 (42%)] Loss: 15252.079102\n",
      "Train Epoch: 84 [95872/225000 (43%)] Loss: 14825.587891\n",
      "Train Epoch: 84 [97280/225000 (43%)] Loss: 15228.631836\n",
      "Train Epoch: 84 [98688/225000 (44%)] Loss: 15014.864258\n",
      "Train Epoch: 84 [100096/225000 (44%)] Loss: 15085.752930\n",
      "Train Epoch: 84 [101504/225000 (45%)] Loss: 14896.992188\n",
      "Train Epoch: 84 [102912/225000 (46%)] Loss: 15427.746094\n",
      "Train Epoch: 84 [104320/225000 (46%)] Loss: 15099.874023\n",
      "Train Epoch: 84 [105728/225000 (47%)] Loss: 15265.533203\n",
      "Train Epoch: 84 [107136/225000 (48%)] Loss: 14853.306641\n",
      "Train Epoch: 84 [108544/225000 (48%)] Loss: 15038.233398\n",
      "Train Epoch: 84 [109952/225000 (49%)] Loss: 15120.649414\n",
      "Train Epoch: 84 [111360/225000 (49%)] Loss: 15777.142578\n",
      "Train Epoch: 84 [112768/225000 (50%)] Loss: 14807.793945\n",
      "Train Epoch: 84 [114176/225000 (51%)] Loss: 14667.460938\n",
      "Train Epoch: 84 [115584/225000 (51%)] Loss: 15063.631836\n",
      "Train Epoch: 84 [116992/225000 (52%)] Loss: 15485.566406\n",
      "Train Epoch: 84 [118400/225000 (53%)] Loss: 14894.571289\n",
      "Train Epoch: 84 [119808/225000 (53%)] Loss: 15262.569336\n",
      "Train Epoch: 84 [121216/225000 (54%)] Loss: 14943.310547\n",
      "Train Epoch: 84 [122624/225000 (54%)] Loss: 15255.038086\n",
      "Train Epoch: 84 [124032/225000 (55%)] Loss: 14754.564453\n",
      "Train Epoch: 84 [125440/225000 (56%)] Loss: 15152.134766\n",
      "Train Epoch: 84 [126848/225000 (56%)] Loss: 14681.470703\n",
      "Train Epoch: 84 [128256/225000 (57%)] Loss: 14948.983398\n",
      "Train Epoch: 84 [129664/225000 (58%)] Loss: 15114.152344\n",
      "Train Epoch: 84 [131072/225000 (58%)] Loss: 15584.583984\n",
      "Train Epoch: 84 [132480/225000 (59%)] Loss: 15061.994141\n",
      "Train Epoch: 84 [133888/225000 (60%)] Loss: 14937.081055\n",
      "Train Epoch: 84 [135296/225000 (60%)] Loss: 15218.242188\n",
      "Train Epoch: 84 [136704/225000 (61%)] Loss: 14642.997070\n",
      "Train Epoch: 84 [138112/225000 (61%)] Loss: 15276.383789\n",
      "Train Epoch: 84 [139520/225000 (62%)] Loss: 15292.132812\n",
      "Train Epoch: 84 [140928/225000 (63%)] Loss: 14824.525391\n",
      "Train Epoch: 84 [142336/225000 (63%)] Loss: 14874.765625\n",
      "Train Epoch: 84 [143744/225000 (64%)] Loss: 15312.871094\n",
      "Train Epoch: 84 [145152/225000 (65%)] Loss: 15326.614258\n",
      "Train Epoch: 84 [146560/225000 (65%)] Loss: 15198.004883\n",
      "Train Epoch: 84 [147968/225000 (66%)] Loss: 14857.698242\n",
      "Train Epoch: 84 [149376/225000 (66%)] Loss: 15109.905273\n",
      "Train Epoch: 84 [150784/225000 (67%)] Loss: 14976.215820\n",
      "Train Epoch: 84 [152192/225000 (68%)] Loss: 15063.367188\n",
      "Train Epoch: 84 [153600/225000 (68%)] Loss: 14971.767578\n",
      "Train Epoch: 84 [155008/225000 (69%)] Loss: 15331.387695\n",
      "Train Epoch: 84 [156416/225000 (70%)] Loss: 14935.477539\n",
      "Train Epoch: 84 [157824/225000 (70%)] Loss: 14702.273438\n",
      "Train Epoch: 84 [159232/225000 (71%)] Loss: 14860.774414\n",
      "Train Epoch: 84 [160640/225000 (71%)] Loss: 15530.489258\n",
      "Train Epoch: 84 [162048/225000 (72%)] Loss: 14930.554688\n",
      "Train Epoch: 84 [163456/225000 (73%)] Loss: 14707.808594\n",
      "Train Epoch: 84 [164864/225000 (73%)] Loss: 15068.411133\n",
      "Train Epoch: 84 [166272/225000 (74%)] Loss: 15294.868164\n",
      "Train Epoch: 84 [167680/225000 (75%)] Loss: 15569.266602\n",
      "Train Epoch: 84 [169088/225000 (75%)] Loss: 14893.889648\n",
      "Train Epoch: 84 [170496/225000 (76%)] Loss: 15080.254883\n",
      "Train Epoch: 84 [171904/225000 (76%)] Loss: 15376.460938\n",
      "Train Epoch: 84 [173312/225000 (77%)] Loss: 14948.563477\n",
      "Train Epoch: 84 [174720/225000 (78%)] Loss: 15520.075195\n",
      "Train Epoch: 84 [176128/225000 (78%)] Loss: 15084.792969\n",
      "Train Epoch: 84 [177536/225000 (79%)] Loss: 15106.183594\n",
      "Train Epoch: 84 [178944/225000 (80%)] Loss: 14913.900391\n",
      "Train Epoch: 84 [180352/225000 (80%)] Loss: 15083.261719\n",
      "Train Epoch: 84 [181760/225000 (81%)] Loss: 15101.065430\n",
      "Train Epoch: 84 [183168/225000 (81%)] Loss: 15053.179688\n",
      "Train Epoch: 84 [184576/225000 (82%)] Loss: 14915.340820\n",
      "Train Epoch: 84 [185984/225000 (83%)] Loss: 15116.700195\n",
      "Train Epoch: 84 [187392/225000 (83%)] Loss: 15084.090820\n",
      "Train Epoch: 84 [188800/225000 (84%)] Loss: 14966.898438\n",
      "Train Epoch: 84 [190208/225000 (85%)] Loss: 15138.473633\n",
      "Train Epoch: 84 [191616/225000 (85%)] Loss: 14728.041016\n",
      "Train Epoch: 84 [193024/225000 (86%)] Loss: 14836.524414\n",
      "Train Epoch: 84 [194432/225000 (86%)] Loss: 15129.368164\n",
      "Train Epoch: 84 [195840/225000 (87%)] Loss: 14944.769531\n",
      "Train Epoch: 84 [197248/225000 (88%)] Loss: 15163.269531\n",
      "Train Epoch: 84 [198656/225000 (88%)] Loss: 15109.916016\n",
      "Train Epoch: 84 [200064/225000 (89%)] Loss: 15289.080078\n",
      "Train Epoch: 84 [201472/225000 (90%)] Loss: 14768.581055\n",
      "Train Epoch: 84 [202880/225000 (90%)] Loss: 14888.143555\n",
      "Train Epoch: 84 [204288/225000 (91%)] Loss: 15133.063477\n",
      "Train Epoch: 84 [205696/225000 (91%)] Loss: 15116.628906\n",
      "Train Epoch: 84 [207104/225000 (92%)] Loss: 15108.011719\n",
      "Train Epoch: 84 [208512/225000 (93%)] Loss: 15473.575195\n",
      "Train Epoch: 84 [209920/225000 (93%)] Loss: 14991.334961\n",
      "Train Epoch: 84 [211328/225000 (94%)] Loss: 15026.419922\n",
      "Train Epoch: 84 [212736/225000 (95%)] Loss: 14775.060547\n",
      "Train Epoch: 84 [214144/225000 (95%)] Loss: 14881.161133\n",
      "Train Epoch: 84 [215552/225000 (96%)] Loss: 14964.424805\n",
      "Train Epoch: 84 [216960/225000 (96%)] Loss: 15061.664062\n",
      "Train Epoch: 84 [218368/225000 (97%)] Loss: 15034.705078\n",
      "Train Epoch: 84 [219776/225000 (98%)] Loss: 14849.426758\n",
      "Train Epoch: 84 [221184/225000 (98%)] Loss: 14707.798828\n",
      "Train Epoch: 84 [222592/225000 (99%)] Loss: 14745.504883\n",
      "Train Epoch: 84 [224000/225000 (100%)] Loss: 15278.499023\n",
      "    epoch          : 84\n",
      "    loss           : 15073.388917404365\n",
      "    val_loss       : 15054.696117308371\n",
      "Train Epoch: 85 [128/225000 (0%)] Loss: 15137.427734\n",
      "Train Epoch: 85 [1536/225000 (1%)] Loss: 14938.622070\n",
      "Train Epoch: 85 [2944/225000 (1%)] Loss: 14817.355469\n",
      "Train Epoch: 85 [4352/225000 (2%)] Loss: 15016.518555\n",
      "Train Epoch: 85 [5760/225000 (3%)] Loss: 15037.791016\n",
      "Train Epoch: 85 [7168/225000 (3%)] Loss: 15238.734375\n",
      "Train Epoch: 85 [8576/225000 (4%)] Loss: 15540.660156\n",
      "Train Epoch: 85 [9984/225000 (4%)] Loss: 15053.094727\n",
      "Train Epoch: 85 [11392/225000 (5%)] Loss: 15121.046875\n",
      "Train Epoch: 85 [12800/225000 (6%)] Loss: 15416.677734\n",
      "Train Epoch: 85 [14208/225000 (6%)] Loss: 14943.464844\n",
      "Train Epoch: 85 [15616/225000 (7%)] Loss: 14827.465820\n",
      "Train Epoch: 85 [17024/225000 (8%)] Loss: 15120.785156\n",
      "Train Epoch: 85 [18432/225000 (8%)] Loss: 15408.294922\n",
      "Train Epoch: 85 [19840/225000 (9%)] Loss: 15224.943359\n",
      "Train Epoch: 85 [21248/225000 (9%)] Loss: 15440.536133\n",
      "Train Epoch: 85 [22656/225000 (10%)] Loss: 15010.619141\n",
      "Train Epoch: 85 [24064/225000 (11%)] Loss: 14982.078125\n",
      "Train Epoch: 85 [25472/225000 (11%)] Loss: 14769.776367\n",
      "Train Epoch: 85 [26880/225000 (12%)] Loss: 15083.878906\n",
      "Train Epoch: 85 [28288/225000 (13%)] Loss: 14849.837891\n",
      "Train Epoch: 85 [29696/225000 (13%)] Loss: 14971.523438\n",
      "Train Epoch: 85 [31104/225000 (14%)] Loss: 14726.776367\n",
      "Train Epoch: 85 [32512/225000 (14%)] Loss: 15442.856445\n",
      "Train Epoch: 85 [33920/225000 (15%)] Loss: 14733.234375\n",
      "Train Epoch: 85 [35328/225000 (16%)] Loss: 15067.966797\n",
      "Train Epoch: 85 [36736/225000 (16%)] Loss: 15186.926758\n",
      "Train Epoch: 85 [38144/225000 (17%)] Loss: 15458.192383\n",
      "Train Epoch: 85 [39552/225000 (18%)] Loss: 14948.939453\n",
      "Train Epoch: 85 [40960/225000 (18%)] Loss: 14559.907227\n",
      "Train Epoch: 85 [42368/225000 (19%)] Loss: 14942.022461\n",
      "Train Epoch: 85 [43776/225000 (19%)] Loss: 15009.960938\n",
      "Train Epoch: 85 [45184/225000 (20%)] Loss: 14773.127930\n",
      "Train Epoch: 85 [46592/225000 (21%)] Loss: 14800.726562\n",
      "Train Epoch: 85 [48000/225000 (21%)] Loss: 15040.520508\n",
      "Train Epoch: 85 [49408/225000 (22%)] Loss: 15277.893555\n",
      "Train Epoch: 85 [50816/225000 (23%)] Loss: 15212.704102\n",
      "Train Epoch: 85 [52224/225000 (23%)] Loss: 15546.657227\n",
      "Train Epoch: 85 [53632/225000 (24%)] Loss: 15606.948242\n",
      "Train Epoch: 85 [55040/225000 (24%)] Loss: 15012.674805\n",
      "Train Epoch: 85 [56448/225000 (25%)] Loss: 15098.468750\n",
      "Train Epoch: 85 [57856/225000 (26%)] Loss: 15163.514648\n",
      "Train Epoch: 85 [59264/225000 (26%)] Loss: 14773.566406\n",
      "Train Epoch: 85 [60672/225000 (27%)] Loss: 15229.371094\n",
      "Train Epoch: 85 [62080/225000 (28%)] Loss: 14951.820312\n",
      "Train Epoch: 85 [63488/225000 (28%)] Loss: 14826.128906\n",
      "Train Epoch: 85 [64896/225000 (29%)] Loss: 14915.078125\n",
      "Train Epoch: 85 [66304/225000 (29%)] Loss: 14661.732422\n",
      "Train Epoch: 85 [67712/225000 (30%)] Loss: 14836.172852\n",
      "Train Epoch: 85 [69120/225000 (31%)] Loss: 14991.134766\n",
      "Train Epoch: 85 [70528/225000 (31%)] Loss: 14797.401367\n",
      "Train Epoch: 85 [71936/225000 (32%)] Loss: 14666.564453\n",
      "Train Epoch: 85 [73344/225000 (33%)] Loss: 15033.745117\n",
      "Train Epoch: 85 [74752/225000 (33%)] Loss: 14586.927734\n",
      "Train Epoch: 85 [76160/225000 (34%)] Loss: 14954.123047\n",
      "Train Epoch: 85 [77568/225000 (34%)] Loss: 15240.017578\n",
      "Train Epoch: 85 [78976/225000 (35%)] Loss: 15054.081055\n",
      "Train Epoch: 85 [80384/225000 (36%)] Loss: 15021.607422\n",
      "Train Epoch: 85 [81792/225000 (36%)] Loss: 14848.408203\n",
      "Train Epoch: 85 [83200/225000 (37%)] Loss: 15050.859375\n",
      "Train Epoch: 85 [84608/225000 (38%)] Loss: 15484.040039\n",
      "Train Epoch: 85 [86016/225000 (38%)] Loss: 14758.269531\n",
      "Train Epoch: 85 [87424/225000 (39%)] Loss: 14569.094727\n",
      "Train Epoch: 85 [88832/225000 (39%)] Loss: 15337.364258\n",
      "Train Epoch: 85 [90240/225000 (40%)] Loss: 15058.686523\n",
      "Train Epoch: 85 [91648/225000 (41%)] Loss: 15182.606445\n",
      "Train Epoch: 85 [93056/225000 (41%)] Loss: 14757.633789\n",
      "Train Epoch: 85 [94464/225000 (42%)] Loss: 15013.482422\n",
      "Train Epoch: 85 [95872/225000 (43%)] Loss: 15195.353516\n",
      "Train Epoch: 85 [97280/225000 (43%)] Loss: 14908.542969\n",
      "Train Epoch: 85 [98688/225000 (44%)] Loss: 15229.734375\n",
      "Train Epoch: 85 [100096/225000 (44%)] Loss: 14957.332031\n",
      "Train Epoch: 85 [101504/225000 (45%)] Loss: 15093.324219\n",
      "Train Epoch: 85 [102912/225000 (46%)] Loss: 14689.584961\n",
      "Train Epoch: 85 [104320/225000 (46%)] Loss: 14983.457031\n",
      "Train Epoch: 85 [105728/225000 (47%)] Loss: 14546.832031\n",
      "Train Epoch: 85 [107136/225000 (48%)] Loss: 14996.478516\n",
      "Train Epoch: 85 [108544/225000 (48%)] Loss: 15178.226562\n",
      "Train Epoch: 85 [109952/225000 (49%)] Loss: 14996.966797\n",
      "Train Epoch: 85 [111360/225000 (49%)] Loss: 14918.350586\n",
      "Train Epoch: 85 [112768/225000 (50%)] Loss: 15227.327148\n",
      "Train Epoch: 85 [114176/225000 (51%)] Loss: 14878.966797\n",
      "Train Epoch: 85 [115584/225000 (51%)] Loss: 14713.284180\n",
      "Train Epoch: 85 [116992/225000 (52%)] Loss: 14886.266602\n",
      "Train Epoch: 85 [118400/225000 (53%)] Loss: 14817.954102\n",
      "Train Epoch: 85 [119808/225000 (53%)] Loss: 14956.581055\n",
      "Train Epoch: 85 [121216/225000 (54%)] Loss: 14775.652344\n",
      "Train Epoch: 85 [122624/225000 (54%)] Loss: 15062.872070\n",
      "Train Epoch: 85 [124032/225000 (55%)] Loss: 14965.595703\n",
      "Train Epoch: 85 [125440/225000 (56%)] Loss: 14903.234375\n",
      "Train Epoch: 85 [126848/225000 (56%)] Loss: 15012.093750\n",
      "Train Epoch: 85 [128256/225000 (57%)] Loss: 15270.777344\n",
      "Train Epoch: 85 [129664/225000 (58%)] Loss: 15498.603516\n",
      "Train Epoch: 85 [131072/225000 (58%)] Loss: 14915.323242\n",
      "Train Epoch: 85 [132480/225000 (59%)] Loss: 15139.835938\n",
      "Train Epoch: 85 [133888/225000 (60%)] Loss: 14746.125000\n",
      "Train Epoch: 85 [135296/225000 (60%)] Loss: 15046.465820\n",
      "Train Epoch: 85 [136704/225000 (61%)] Loss: 14664.496094\n",
      "Train Epoch: 85 [138112/225000 (61%)] Loss: 14907.458008\n",
      "Train Epoch: 85 [139520/225000 (62%)] Loss: 15087.093750\n",
      "Train Epoch: 85 [140928/225000 (63%)] Loss: 15019.812500\n",
      "Train Epoch: 85 [142336/225000 (63%)] Loss: 15339.019531\n",
      "Train Epoch: 85 [143744/225000 (64%)] Loss: 15951.416992\n",
      "Train Epoch: 85 [145152/225000 (65%)] Loss: 15042.887695\n",
      "Train Epoch: 85 [146560/225000 (65%)] Loss: 15198.451172\n",
      "Train Epoch: 85 [147968/225000 (66%)] Loss: 14846.294922\n",
      "Train Epoch: 85 [149376/225000 (66%)] Loss: 14781.736328\n",
      "Train Epoch: 85 [150784/225000 (67%)] Loss: 14643.169922\n",
      "Train Epoch: 85 [152192/225000 (68%)] Loss: 14876.010742\n",
      "Train Epoch: 85 [153600/225000 (68%)] Loss: 14813.406250\n",
      "Train Epoch: 85 [155008/225000 (69%)] Loss: 15173.978516\n",
      "Train Epoch: 85 [156416/225000 (70%)] Loss: 15581.182617\n",
      "Train Epoch: 85 [157824/225000 (70%)] Loss: 14917.355469\n",
      "Train Epoch: 85 [159232/225000 (71%)] Loss: 14933.466797\n",
      "Train Epoch: 85 [160640/225000 (71%)] Loss: 14795.932617\n",
      "Train Epoch: 85 [162048/225000 (72%)] Loss: 15007.370117\n",
      "Train Epoch: 85 [163456/225000 (73%)] Loss: 15194.810547\n",
      "Train Epoch: 85 [164864/225000 (73%)] Loss: 15113.339844\n",
      "Train Epoch: 85 [166272/225000 (74%)] Loss: 14593.881836\n",
      "Train Epoch: 85 [167680/225000 (75%)] Loss: 15113.859375\n",
      "Train Epoch: 85 [169088/225000 (75%)] Loss: 14988.255859\n",
      "Train Epoch: 85 [170496/225000 (76%)] Loss: 15090.992188\n",
      "Train Epoch: 85 [171904/225000 (76%)] Loss: 14754.436523\n",
      "Train Epoch: 85 [173312/225000 (77%)] Loss: 14951.458008\n",
      "Train Epoch: 85 [174720/225000 (78%)] Loss: 15438.395508\n",
      "Train Epoch: 85 [176128/225000 (78%)] Loss: 15441.877930\n",
      "Train Epoch: 85 [177536/225000 (79%)] Loss: 15407.525391\n",
      "Train Epoch: 85 [178944/225000 (80%)] Loss: 14931.214844\n",
      "Train Epoch: 85 [180352/225000 (80%)] Loss: 15031.770508\n",
      "Train Epoch: 85 [181760/225000 (81%)] Loss: 15628.267578\n",
      "Train Epoch: 85 [183168/225000 (81%)] Loss: 15560.300781\n",
      "Train Epoch: 85 [184576/225000 (82%)] Loss: 15314.450195\n",
      "Train Epoch: 85 [185984/225000 (83%)] Loss: 14768.829102\n",
      "Train Epoch: 85 [187392/225000 (83%)] Loss: 15031.603516\n",
      "Train Epoch: 85 [188800/225000 (84%)] Loss: 15138.348633\n",
      "Train Epoch: 85 [190208/225000 (85%)] Loss: 15252.661133\n",
      "Train Epoch: 85 [191616/225000 (85%)] Loss: 15081.367188\n",
      "Train Epoch: 85 [193024/225000 (86%)] Loss: 15215.016602\n",
      "Train Epoch: 85 [194432/225000 (86%)] Loss: 15139.718750\n",
      "Train Epoch: 85 [195840/225000 (87%)] Loss: 15262.235352\n",
      "Train Epoch: 85 [197248/225000 (88%)] Loss: 14717.833008\n",
      "Train Epoch: 85 [198656/225000 (88%)] Loss: 14802.316406\n",
      "Train Epoch: 85 [200064/225000 (89%)] Loss: 15213.440430\n",
      "Train Epoch: 85 [201472/225000 (90%)] Loss: 14884.518555\n",
      "Train Epoch: 85 [202880/225000 (90%)] Loss: 14785.139648\n",
      "Train Epoch: 85 [204288/225000 (91%)] Loss: 15066.108398\n",
      "Train Epoch: 85 [205696/225000 (91%)] Loss: 15181.923828\n",
      "Train Epoch: 85 [207104/225000 (92%)] Loss: 14931.224609\n",
      "Train Epoch: 85 [208512/225000 (93%)] Loss: 14945.791016\n",
      "Train Epoch: 85 [209920/225000 (93%)] Loss: 15096.613281\n",
      "Train Epoch: 85 [211328/225000 (94%)] Loss: 15082.645508\n",
      "Train Epoch: 85 [212736/225000 (95%)] Loss: 14929.587891\n",
      "Train Epoch: 85 [214144/225000 (95%)] Loss: 15089.567383\n",
      "Train Epoch: 85 [215552/225000 (96%)] Loss: 15188.029297\n",
      "Train Epoch: 85 [216960/225000 (96%)] Loss: 15552.507812\n",
      "Train Epoch: 85 [218368/225000 (97%)] Loss: 14730.100586\n",
      "Train Epoch: 85 [219776/225000 (98%)] Loss: 15372.703125\n",
      "Train Epoch: 85 [221184/225000 (98%)] Loss: 15310.413086\n",
      "Train Epoch: 85 [222592/225000 (99%)] Loss: 15253.531250\n",
      "Train Epoch: 85 [224000/225000 (100%)] Loss: 15204.052734\n",
      "    epoch          : 85\n",
      "    loss           : 15080.026673265962\n",
      "    val_loss       : 15056.799375367713\n",
      "Train Epoch: 86 [128/225000 (0%)] Loss: 14858.155273\n",
      "Train Epoch: 86 [1536/225000 (1%)] Loss: 14725.281250\n",
      "Train Epoch: 86 [2944/225000 (1%)] Loss: 14830.049805\n",
      "Train Epoch: 86 [4352/225000 (2%)] Loss: 15383.302734\n",
      "Train Epoch: 86 [5760/225000 (3%)] Loss: 14833.834961\n",
      "Train Epoch: 86 [7168/225000 (3%)] Loss: 15511.778320\n",
      "Train Epoch: 86 [8576/225000 (4%)] Loss: 15207.028320\n",
      "Train Epoch: 86 [9984/225000 (4%)] Loss: 14769.033203\n",
      "Train Epoch: 86 [11392/225000 (5%)] Loss: 14859.615234\n",
      "Train Epoch: 86 [12800/225000 (6%)] Loss: 14795.099609\n",
      "Train Epoch: 86 [14208/225000 (6%)] Loss: 15046.564453\n",
      "Train Epoch: 86 [15616/225000 (7%)] Loss: 14854.945312\n",
      "Train Epoch: 86 [17024/225000 (8%)] Loss: 14785.649414\n",
      "Train Epoch: 86 [18432/225000 (8%)] Loss: 15334.443359\n",
      "Train Epoch: 86 [19840/225000 (9%)] Loss: 15458.399414\n",
      "Train Epoch: 86 [21248/225000 (9%)] Loss: 15082.588867\n",
      "Train Epoch: 86 [22656/225000 (10%)] Loss: 15031.510742\n",
      "Train Epoch: 86 [24064/225000 (11%)] Loss: 15111.306641\n",
      "Train Epoch: 86 [25472/225000 (11%)] Loss: 14745.359375\n",
      "Train Epoch: 86 [26880/225000 (12%)] Loss: 15264.717773\n",
      "Train Epoch: 86 [28288/225000 (13%)] Loss: 15343.319336\n",
      "Train Epoch: 86 [29696/225000 (13%)] Loss: 14730.432617\n",
      "Train Epoch: 86 [31104/225000 (14%)] Loss: 15019.523438\n",
      "Train Epoch: 86 [32512/225000 (14%)] Loss: 14755.828125\n",
      "Train Epoch: 86 [33920/225000 (15%)] Loss: 14886.181641\n",
      "Train Epoch: 86 [35328/225000 (16%)] Loss: 14850.316406\n",
      "Train Epoch: 86 [36736/225000 (16%)] Loss: 15241.343750\n",
      "Train Epoch: 86 [38144/225000 (17%)] Loss: 14873.691406\n",
      "Train Epoch: 86 [39552/225000 (18%)] Loss: 15177.318359\n",
      "Train Epoch: 86 [40960/225000 (18%)] Loss: 15232.311523\n",
      "Train Epoch: 86 [42368/225000 (19%)] Loss: 15719.296875\n",
      "Train Epoch: 86 [43776/225000 (19%)] Loss: 15105.332031\n",
      "Train Epoch: 86 [45184/225000 (20%)] Loss: 15080.929688\n",
      "Train Epoch: 86 [46592/225000 (21%)] Loss: 14631.930664\n",
      "Train Epoch: 86 [48000/225000 (21%)] Loss: 14832.910156\n",
      "Train Epoch: 86 [49408/225000 (22%)] Loss: 14896.991211\n",
      "Train Epoch: 86 [50816/225000 (23%)] Loss: 14897.242188\n",
      "Train Epoch: 86 [52224/225000 (23%)] Loss: 14959.263672\n",
      "Train Epoch: 86 [53632/225000 (24%)] Loss: 15036.236328\n",
      "Train Epoch: 86 [55040/225000 (24%)] Loss: 15003.361328\n",
      "Train Epoch: 86 [56448/225000 (25%)] Loss: 15023.806641\n",
      "Train Epoch: 86 [57856/225000 (26%)] Loss: 14962.611328\n",
      "Train Epoch: 86 [59264/225000 (26%)] Loss: 15026.236328\n",
      "Train Epoch: 86 [60672/225000 (27%)] Loss: 15317.195312\n",
      "Train Epoch: 86 [62080/225000 (28%)] Loss: 15188.958984\n",
      "Train Epoch: 86 [63488/225000 (28%)] Loss: 15274.398438\n",
      "Train Epoch: 86 [64896/225000 (29%)] Loss: 14991.039062\n",
      "Train Epoch: 86 [66304/225000 (29%)] Loss: 14986.341797\n",
      "Train Epoch: 86 [67712/225000 (30%)] Loss: 15571.282227\n",
      "Train Epoch: 86 [69120/225000 (31%)] Loss: 15005.432617\n",
      "Train Epoch: 86 [70528/225000 (31%)] Loss: 15238.459961\n",
      "Train Epoch: 86 [71936/225000 (32%)] Loss: 14849.660156\n",
      "Train Epoch: 86 [73344/225000 (33%)] Loss: 15863.041992\n",
      "Train Epoch: 86 [74752/225000 (33%)] Loss: 15461.590820\n",
      "Train Epoch: 86 [76160/225000 (34%)] Loss: 15194.401367\n",
      "Train Epoch: 86 [77568/225000 (34%)] Loss: 15032.770508\n",
      "Train Epoch: 86 [78976/225000 (35%)] Loss: 15423.835938\n",
      "Train Epoch: 86 [80384/225000 (36%)] Loss: 15522.325195\n",
      "Train Epoch: 86 [81792/225000 (36%)] Loss: 15266.193359\n",
      "Train Epoch: 86 [83200/225000 (37%)] Loss: 15232.710938\n",
      "Train Epoch: 86 [84608/225000 (38%)] Loss: 15103.058594\n",
      "Train Epoch: 86 [86016/225000 (38%)] Loss: 15051.693359\n",
      "Train Epoch: 86 [87424/225000 (39%)] Loss: 14942.872070\n",
      "Train Epoch: 86 [88832/225000 (39%)] Loss: 14934.894531\n",
      "Train Epoch: 86 [90240/225000 (40%)] Loss: 14962.463867\n",
      "Train Epoch: 86 [91648/225000 (41%)] Loss: 15107.253906\n",
      "Train Epoch: 86 [93056/225000 (41%)] Loss: 15121.099609\n",
      "Train Epoch: 86 [94464/225000 (42%)] Loss: 15207.044922\n",
      "Train Epoch: 86 [95872/225000 (43%)] Loss: 14837.869141\n",
      "Train Epoch: 86 [97280/225000 (43%)] Loss: 15082.976562\n",
      "Train Epoch: 86 [98688/225000 (44%)] Loss: 15336.665039\n",
      "Train Epoch: 86 [100096/225000 (44%)] Loss: 15243.213867\n",
      "Train Epoch: 86 [101504/225000 (45%)] Loss: 14733.048828\n",
      "Train Epoch: 86 [102912/225000 (46%)] Loss: 15253.647461\n",
      "Train Epoch: 86 [104320/225000 (46%)] Loss: 15022.584961\n",
      "Train Epoch: 86 [105728/225000 (47%)] Loss: 15079.279297\n",
      "Train Epoch: 86 [107136/225000 (48%)] Loss: 15244.706055\n",
      "Train Epoch: 86 [108544/225000 (48%)] Loss: 14624.220703\n",
      "Train Epoch: 86 [109952/225000 (49%)] Loss: 14807.971680\n",
      "Train Epoch: 86 [111360/225000 (49%)] Loss: 14609.280273\n",
      "Train Epoch: 86 [112768/225000 (50%)] Loss: 14928.191406\n",
      "Train Epoch: 86 [114176/225000 (51%)] Loss: 14948.043945\n",
      "Train Epoch: 86 [115584/225000 (51%)] Loss: 15035.774414\n",
      "Train Epoch: 86 [116992/225000 (52%)] Loss: 14883.782227\n",
      "Train Epoch: 86 [118400/225000 (53%)] Loss: 15272.364258\n",
      "Train Epoch: 86 [119808/225000 (53%)] Loss: 14772.876953\n",
      "Train Epoch: 86 [121216/225000 (54%)] Loss: 15182.735352\n",
      "Train Epoch: 86 [122624/225000 (54%)] Loss: 14908.661133\n",
      "Train Epoch: 86 [124032/225000 (55%)] Loss: 14764.245117\n",
      "Train Epoch: 86 [125440/225000 (56%)] Loss: 15236.916992\n",
      "Train Epoch: 86 [126848/225000 (56%)] Loss: 15007.363281\n",
      "Train Epoch: 86 [128256/225000 (57%)] Loss: 15238.007812\n",
      "Train Epoch: 86 [129664/225000 (58%)] Loss: 15303.171875\n",
      "Train Epoch: 86 [131072/225000 (58%)] Loss: 15212.570312\n",
      "Train Epoch: 86 [132480/225000 (59%)] Loss: 15130.772461\n",
      "Train Epoch: 86 [133888/225000 (60%)] Loss: 14716.178711\n",
      "Train Epoch: 86 [135296/225000 (60%)] Loss: 15365.601562\n",
      "Train Epoch: 86 [136704/225000 (61%)] Loss: 14776.621094\n",
      "Train Epoch: 86 [138112/225000 (61%)] Loss: 15700.557617\n",
      "Train Epoch: 86 [139520/225000 (62%)] Loss: 15300.098633\n",
      "Train Epoch: 86 [140928/225000 (63%)] Loss: 15252.461914\n",
      "Train Epoch: 86 [142336/225000 (63%)] Loss: 15208.066406\n",
      "Train Epoch: 86 [143744/225000 (64%)] Loss: 15496.343750\n",
      "Train Epoch: 86 [145152/225000 (65%)] Loss: 15026.270508\n",
      "Train Epoch: 86 [146560/225000 (65%)] Loss: 15008.616211\n",
      "Train Epoch: 86 [147968/225000 (66%)] Loss: 15185.937500\n",
      "Train Epoch: 86 [149376/225000 (66%)] Loss: 15552.993164\n",
      "Train Epoch: 86 [150784/225000 (67%)] Loss: 14961.761719\n",
      "Train Epoch: 86 [152192/225000 (68%)] Loss: 14995.224609\n",
      "Train Epoch: 86 [153600/225000 (68%)] Loss: 15321.884766\n",
      "Train Epoch: 86 [155008/225000 (69%)] Loss: 14937.245117\n",
      "Train Epoch: 86 [156416/225000 (70%)] Loss: 15279.357422\n",
      "Train Epoch: 86 [157824/225000 (70%)] Loss: 15590.820312\n",
      "Train Epoch: 86 [159232/225000 (71%)] Loss: 15247.181641\n",
      "Train Epoch: 86 [160640/225000 (71%)] Loss: 15152.366211\n",
      "Train Epoch: 86 [162048/225000 (72%)] Loss: 14952.492188\n",
      "Train Epoch: 86 [163456/225000 (73%)] Loss: 14985.110352\n",
      "Train Epoch: 86 [164864/225000 (73%)] Loss: 15172.768555\n",
      "Train Epoch: 86 [166272/225000 (74%)] Loss: 14438.284180\n",
      "Train Epoch: 86 [167680/225000 (75%)] Loss: 14988.898438\n",
      "Train Epoch: 86 [169088/225000 (75%)] Loss: 15188.947266\n",
      "Train Epoch: 86 [170496/225000 (76%)] Loss: 15613.272461\n",
      "Train Epoch: 86 [171904/225000 (76%)] Loss: 14904.753906\n",
      "Train Epoch: 86 [173312/225000 (77%)] Loss: 15366.195312\n",
      "Train Epoch: 86 [174720/225000 (78%)] Loss: 14879.799805\n",
      "Train Epoch: 86 [176128/225000 (78%)] Loss: 14827.489258\n",
      "Train Epoch: 86 [177536/225000 (79%)] Loss: 15241.945312\n",
      "Train Epoch: 86 [178944/225000 (80%)] Loss: 15206.248047\n",
      "Train Epoch: 86 [180352/225000 (80%)] Loss: 15321.028320\n",
      "Train Epoch: 86 [181760/225000 (81%)] Loss: 15277.719727\n",
      "Train Epoch: 86 [183168/225000 (81%)] Loss: 15386.364258\n",
      "Train Epoch: 86 [184576/225000 (82%)] Loss: 15102.335938\n",
      "Train Epoch: 86 [185984/225000 (83%)] Loss: 14922.854492\n",
      "Train Epoch: 86 [187392/225000 (83%)] Loss: 15186.612305\n",
      "Train Epoch: 86 [188800/225000 (84%)] Loss: 14789.399414\n",
      "Train Epoch: 86 [190208/225000 (85%)] Loss: 15211.412109\n",
      "Train Epoch: 86 [191616/225000 (85%)] Loss: 14865.583984\n",
      "Train Epoch: 86 [193024/225000 (86%)] Loss: 15459.345703\n",
      "Train Epoch: 86 [194432/225000 (86%)] Loss: 15126.349609\n",
      "Train Epoch: 86 [195840/225000 (87%)] Loss: 14967.111328\n",
      "Train Epoch: 86 [197248/225000 (88%)] Loss: 15541.111328\n",
      "Train Epoch: 86 [198656/225000 (88%)] Loss: 15188.398438\n",
      "Train Epoch: 86 [200064/225000 (89%)] Loss: 14851.155273\n",
      "Train Epoch: 86 [201472/225000 (90%)] Loss: 15026.556641\n",
      "Train Epoch: 86 [202880/225000 (90%)] Loss: 15295.290039\n",
      "Train Epoch: 86 [204288/225000 (91%)] Loss: 15149.167969\n",
      "Train Epoch: 86 [205696/225000 (91%)] Loss: 14978.716797\n",
      "Train Epoch: 86 [207104/225000 (92%)] Loss: 14813.742188\n",
      "Train Epoch: 86 [208512/225000 (93%)] Loss: 15571.634766\n",
      "Train Epoch: 86 [209920/225000 (93%)] Loss: 14747.228516\n",
      "Train Epoch: 86 [211328/225000 (94%)] Loss: 15434.924805\n",
      "Train Epoch: 86 [212736/225000 (95%)] Loss: 14930.424805\n",
      "Train Epoch: 86 [214144/225000 (95%)] Loss: 14588.383789\n",
      "Train Epoch: 86 [215552/225000 (96%)] Loss: 14903.548828\n",
      "Train Epoch: 86 [216960/225000 (96%)] Loss: 14714.682617\n",
      "Train Epoch: 86 [218368/225000 (97%)] Loss: 15132.195312\n",
      "Train Epoch: 86 [219776/225000 (98%)] Loss: 15086.618164\n",
      "Train Epoch: 86 [221184/225000 (98%)] Loss: 15587.243164\n",
      "Train Epoch: 86 [222592/225000 (99%)] Loss: 14882.309570\n",
      "Train Epoch: 86 [224000/225000 (100%)] Loss: 14676.179688\n",
      "    epoch          : 86\n",
      "    loss           : 15079.9013671875\n",
      "    val_loss       : 15075.702791345668\n",
      "Train Epoch: 87 [128/225000 (0%)] Loss: 14657.232422\n",
      "Train Epoch: 87 [1536/225000 (1%)] Loss: 14968.683594\n",
      "Train Epoch: 87 [2944/225000 (1%)] Loss: 14766.669922\n",
      "Train Epoch: 87 [4352/225000 (2%)] Loss: 14816.545898\n",
      "Train Epoch: 87 [5760/225000 (3%)] Loss: 14808.894531\n",
      "Train Epoch: 87 [7168/225000 (3%)] Loss: 14772.085938\n",
      "Train Epoch: 87 [8576/225000 (4%)] Loss: 14874.143555\n",
      "Train Epoch: 87 [9984/225000 (4%)] Loss: 15011.731445\n",
      "Train Epoch: 87 [11392/225000 (5%)] Loss: 14865.518555\n",
      "Train Epoch: 87 [12800/225000 (6%)] Loss: 15239.046875\n",
      "Train Epoch: 87 [14208/225000 (6%)] Loss: 14781.280273\n",
      "Train Epoch: 87 [15616/225000 (7%)] Loss: 14925.240234\n",
      "Train Epoch: 87 [17024/225000 (8%)] Loss: 15144.420898\n",
      "Train Epoch: 87 [18432/225000 (8%)] Loss: 15413.493164\n",
      "Train Epoch: 87 [19840/225000 (9%)] Loss: 14859.460938\n",
      "Train Epoch: 87 [21248/225000 (9%)] Loss: 15127.621094\n",
      "Train Epoch: 87 [22656/225000 (10%)] Loss: 15001.332031\n",
      "Train Epoch: 87 [24064/225000 (11%)] Loss: 15091.854492\n",
      "Train Epoch: 87 [25472/225000 (11%)] Loss: 14829.762695\n",
      "Train Epoch: 87 [26880/225000 (12%)] Loss: 15172.714844\n",
      "Train Epoch: 87 [28288/225000 (13%)] Loss: 14873.621094\n",
      "Train Epoch: 87 [29696/225000 (13%)] Loss: 14891.453125\n",
      "Train Epoch: 87 [31104/225000 (14%)] Loss: 15455.432617\n",
      "Train Epoch: 87 [32512/225000 (14%)] Loss: 15017.679688\n",
      "Train Epoch: 87 [33920/225000 (15%)] Loss: 15111.348633\n",
      "Train Epoch: 87 [35328/225000 (16%)] Loss: 15101.682617\n",
      "Train Epoch: 87 [36736/225000 (16%)] Loss: 15289.470703\n",
      "Train Epoch: 87 [38144/225000 (17%)] Loss: 15089.575195\n",
      "Train Epoch: 87 [39552/225000 (18%)] Loss: 15037.458008\n",
      "Train Epoch: 87 [40960/225000 (18%)] Loss: 15047.635742\n",
      "Train Epoch: 87 [42368/225000 (19%)] Loss: 15074.729492\n",
      "Train Epoch: 87 [43776/225000 (19%)] Loss: 15035.722656\n",
      "Train Epoch: 87 [45184/225000 (20%)] Loss: 15056.896484\n",
      "Train Epoch: 87 [46592/225000 (21%)] Loss: 14999.343750\n",
      "Train Epoch: 87 [48000/225000 (21%)] Loss: 15861.603516\n",
      "Train Epoch: 87 [49408/225000 (22%)] Loss: 14927.430664\n",
      "Train Epoch: 87 [50816/225000 (23%)] Loss: 14804.061523\n",
      "Train Epoch: 87 [52224/225000 (23%)] Loss: 15334.163086\n",
      "Train Epoch: 87 [53632/225000 (24%)] Loss: 15490.565430\n",
      "Train Epoch: 87 [55040/225000 (24%)] Loss: 14875.030273\n",
      "Train Epoch: 87 [56448/225000 (25%)] Loss: 14984.338867\n",
      "Train Epoch: 87 [57856/225000 (26%)] Loss: 15027.726562\n",
      "Train Epoch: 87 [59264/225000 (26%)] Loss: 14708.964844\n",
      "Train Epoch: 87 [60672/225000 (27%)] Loss: 14787.683594\n",
      "Train Epoch: 87 [62080/225000 (28%)] Loss: 15163.560547\n",
      "Train Epoch: 87 [63488/225000 (28%)] Loss: 15073.933594\n",
      "Train Epoch: 87 [64896/225000 (29%)] Loss: 14984.327148\n",
      "Train Epoch: 87 [66304/225000 (29%)] Loss: 15474.291992\n",
      "Train Epoch: 87 [67712/225000 (30%)] Loss: 15402.857422\n",
      "Train Epoch: 87 [69120/225000 (31%)] Loss: 14735.272461\n",
      "Train Epoch: 87 [70528/225000 (31%)] Loss: 15233.496094\n",
      "Train Epoch: 87 [71936/225000 (32%)] Loss: 15739.470703\n",
      "Train Epoch: 87 [73344/225000 (33%)] Loss: 15258.738281\n",
      "Train Epoch: 87 [74752/225000 (33%)] Loss: 15714.460938\n",
      "Train Epoch: 87 [76160/225000 (34%)] Loss: 15036.780273\n",
      "Train Epoch: 87 [77568/225000 (34%)] Loss: 14906.192383\n",
      "Train Epoch: 87 [78976/225000 (35%)] Loss: 15397.303711\n",
      "Train Epoch: 87 [80384/225000 (36%)] Loss: 15133.402344\n",
      "Train Epoch: 87 [81792/225000 (36%)] Loss: 15048.396484\n",
      "Train Epoch: 87 [83200/225000 (37%)] Loss: 15427.978516\n",
      "Train Epoch: 87 [84608/225000 (38%)] Loss: 15038.709961\n",
      "Train Epoch: 87 [86016/225000 (38%)] Loss: 15139.176758\n",
      "Train Epoch: 87 [87424/225000 (39%)] Loss: 15375.809570\n",
      "Train Epoch: 87 [88832/225000 (39%)] Loss: 15416.909180\n",
      "Train Epoch: 87 [90240/225000 (40%)] Loss: 15230.168945\n",
      "Train Epoch: 87 [91648/225000 (41%)] Loss: 14825.042969\n",
      "Train Epoch: 87 [93056/225000 (41%)] Loss: 15518.901367\n",
      "Train Epoch: 87 [94464/225000 (42%)] Loss: 15868.520508\n",
      "Train Epoch: 87 [95872/225000 (43%)] Loss: 15064.669922\n",
      "Train Epoch: 87 [97280/225000 (43%)] Loss: 14813.690430\n",
      "Train Epoch: 87 [98688/225000 (44%)] Loss: 14896.168945\n",
      "Train Epoch: 87 [100096/225000 (44%)] Loss: 14948.007812\n",
      "Train Epoch: 87 [101504/225000 (45%)] Loss: 14783.734375\n",
      "Train Epoch: 87 [102912/225000 (46%)] Loss: 15092.150391\n",
      "Train Epoch: 87 [104320/225000 (46%)] Loss: 15106.514648\n",
      "Train Epoch: 87 [105728/225000 (47%)] Loss: 15174.180664\n",
      "Train Epoch: 87 [107136/225000 (48%)] Loss: 15412.721680\n",
      "Train Epoch: 87 [108544/225000 (48%)] Loss: 14947.363281\n",
      "Train Epoch: 87 [109952/225000 (49%)] Loss: 15288.172852\n",
      "Train Epoch: 87 [111360/225000 (49%)] Loss: 15480.442383\n",
      "Train Epoch: 87 [112768/225000 (50%)] Loss: 14858.727539\n",
      "Train Epoch: 87 [114176/225000 (51%)] Loss: 14689.990234\n",
      "Train Epoch: 87 [115584/225000 (51%)] Loss: 15153.611328\n",
      "Train Epoch: 87 [116992/225000 (52%)] Loss: 14936.703125\n",
      "Train Epoch: 87 [118400/225000 (53%)] Loss: 15276.484375\n",
      "Train Epoch: 87 [119808/225000 (53%)] Loss: 14821.161133\n",
      "Train Epoch: 87 [121216/225000 (54%)] Loss: 14734.809570\n",
      "Train Epoch: 87 [122624/225000 (54%)] Loss: 14879.307617\n",
      "Train Epoch: 87 [124032/225000 (55%)] Loss: 15049.536133\n",
      "Train Epoch: 87 [125440/225000 (56%)] Loss: 14997.666016\n",
      "Train Epoch: 87 [126848/225000 (56%)] Loss: 15082.874023\n",
      "Train Epoch: 87 [128256/225000 (57%)] Loss: 15059.736328\n",
      "Train Epoch: 87 [129664/225000 (58%)] Loss: 15068.802734\n",
      "Train Epoch: 87 [131072/225000 (58%)] Loss: 14819.213867\n",
      "Train Epoch: 87 [132480/225000 (59%)] Loss: 15073.624023\n",
      "Train Epoch: 87 [133888/225000 (60%)] Loss: 14836.966797\n",
      "Train Epoch: 87 [135296/225000 (60%)] Loss: 15226.333008\n",
      "Train Epoch: 87 [136704/225000 (61%)] Loss: 15320.943359\n",
      "Train Epoch: 87 [138112/225000 (61%)] Loss: 15066.052734\n",
      "Train Epoch: 87 [139520/225000 (62%)] Loss: 15031.698242\n",
      "Train Epoch: 87 [140928/225000 (63%)] Loss: 14951.688477\n",
      "Train Epoch: 87 [142336/225000 (63%)] Loss: 14703.649414\n",
      "Train Epoch: 87 [143744/225000 (64%)] Loss: 14770.595703\n",
      "Train Epoch: 87 [145152/225000 (65%)] Loss: 14662.490234\n",
      "Train Epoch: 87 [146560/225000 (65%)] Loss: 14858.441406\n",
      "Train Epoch: 87 [147968/225000 (66%)] Loss: 15295.234375\n",
      "Train Epoch: 87 [149376/225000 (66%)] Loss: 15249.927734\n",
      "Train Epoch: 87 [150784/225000 (67%)] Loss: 14829.869141\n",
      "Train Epoch: 87 [152192/225000 (68%)] Loss: 15227.645508\n",
      "Train Epoch: 87 [153600/225000 (68%)] Loss: 14922.453125\n",
      "Train Epoch: 87 [155008/225000 (69%)] Loss: 15045.441406\n",
      "Train Epoch: 87 [156416/225000 (70%)] Loss: 15370.708008\n",
      "Train Epoch: 87 [157824/225000 (70%)] Loss: 15414.461914\n",
      "Train Epoch: 87 [159232/225000 (71%)] Loss: 14779.252930\n",
      "Train Epoch: 87 [160640/225000 (71%)] Loss: 15321.760742\n",
      "Train Epoch: 87 [162048/225000 (72%)] Loss: 15698.430664\n",
      "Train Epoch: 87 [163456/225000 (73%)] Loss: 14863.985352\n",
      "Train Epoch: 87 [164864/225000 (73%)] Loss: 14770.637695\n",
      "Train Epoch: 87 [166272/225000 (74%)] Loss: 14952.788086\n",
      "Train Epoch: 87 [167680/225000 (75%)] Loss: 14747.386719\n",
      "Train Epoch: 87 [169088/225000 (75%)] Loss: 14787.555664\n",
      "Train Epoch: 87 [170496/225000 (76%)] Loss: 15000.422852\n",
      "Train Epoch: 87 [171904/225000 (76%)] Loss: 15259.301758\n",
      "Train Epoch: 87 [173312/225000 (77%)] Loss: 15082.156250\n",
      "Train Epoch: 87 [174720/225000 (78%)] Loss: 15621.042969\n",
      "Train Epoch: 87 [176128/225000 (78%)] Loss: 15347.821289\n",
      "Train Epoch: 87 [177536/225000 (79%)] Loss: 15096.236328\n",
      "Train Epoch: 87 [178944/225000 (80%)] Loss: 15007.298828\n",
      "Train Epoch: 87 [180352/225000 (80%)] Loss: 14984.432617\n",
      "Train Epoch: 87 [181760/225000 (81%)] Loss: 14854.736328\n",
      "Train Epoch: 87 [183168/225000 (81%)] Loss: 14868.742188\n",
      "Train Epoch: 87 [184576/225000 (82%)] Loss: 15196.623047\n",
      "Train Epoch: 87 [185984/225000 (83%)] Loss: 14870.905273\n",
      "Train Epoch: 87 [187392/225000 (83%)] Loss: 15404.376953\n",
      "Train Epoch: 87 [188800/225000 (84%)] Loss: 14781.997070\n",
      "Train Epoch: 87 [190208/225000 (85%)] Loss: 15268.162109\n",
      "Train Epoch: 87 [191616/225000 (85%)] Loss: 15094.512695\n",
      "Train Epoch: 87 [193024/225000 (86%)] Loss: 15263.435547\n",
      "Train Epoch: 87 [194432/225000 (86%)] Loss: 14744.650391\n",
      "Train Epoch: 87 [195840/225000 (87%)] Loss: 15521.627930\n",
      "Train Epoch: 87 [197248/225000 (88%)] Loss: 14913.022461\n",
      "Train Epoch: 87 [198656/225000 (88%)] Loss: 14966.177734\n",
      "Train Epoch: 87 [200064/225000 (89%)] Loss: 15091.616211\n",
      "Train Epoch: 87 [201472/225000 (90%)] Loss: 15217.890625\n",
      "Train Epoch: 87 [202880/225000 (90%)] Loss: 15157.039062\n",
      "Train Epoch: 87 [204288/225000 (91%)] Loss: 15037.800781\n",
      "Train Epoch: 87 [205696/225000 (91%)] Loss: 15197.083984\n",
      "Train Epoch: 87 [207104/225000 (92%)] Loss: 15476.458984\n",
      "Train Epoch: 87 [208512/225000 (93%)] Loss: 15498.000977\n",
      "Train Epoch: 87 [209920/225000 (93%)] Loss: 15276.010742\n",
      "Train Epoch: 87 [211328/225000 (94%)] Loss: 15001.225586\n",
      "Train Epoch: 87 [212736/225000 (95%)] Loss: 15252.282227\n",
      "Train Epoch: 87 [214144/225000 (95%)] Loss: 14994.732422\n",
      "Train Epoch: 87 [215552/225000 (96%)] Loss: 14982.336914\n",
      "Train Epoch: 87 [216960/225000 (96%)] Loss: 15046.477539\n",
      "Train Epoch: 87 [218368/225000 (97%)] Loss: 14644.827148\n",
      "Train Epoch: 87 [219776/225000 (98%)] Loss: 14985.532227\n",
      "Train Epoch: 87 [221184/225000 (98%)] Loss: 15050.823242\n",
      "Train Epoch: 87 [222592/225000 (99%)] Loss: 14776.729492\n",
      "Train Epoch: 87 [224000/225000 (100%)] Loss: 14878.593750\n",
      "    epoch          : 87\n",
      "    loss           : 15073.608692295044\n",
      "    val_loss       : 15065.75244524482\n",
      "Train Epoch: 88 [128/225000 (0%)] Loss: 14806.310547\n",
      "Train Epoch: 88 [1536/225000 (1%)] Loss: 15096.731445\n",
      "Train Epoch: 88 [2944/225000 (1%)] Loss: 15249.989258\n",
      "Train Epoch: 88 [4352/225000 (2%)] Loss: 14962.863281\n",
      "Train Epoch: 88 [5760/225000 (3%)] Loss: 14913.567383\n",
      "Train Epoch: 88 [7168/225000 (3%)] Loss: 15494.806641\n",
      "Train Epoch: 88 [8576/225000 (4%)] Loss: 15431.295898\n",
      "Train Epoch: 88 [9984/225000 (4%)] Loss: 15271.075195\n",
      "Train Epoch: 88 [11392/225000 (5%)] Loss: 15308.032227\n",
      "Train Epoch: 88 [12800/225000 (6%)] Loss: 15040.415039\n",
      "Train Epoch: 88 [14208/225000 (6%)] Loss: 14922.074219\n",
      "Train Epoch: 88 [15616/225000 (7%)] Loss: 14832.854492\n",
      "Train Epoch: 88 [17024/225000 (8%)] Loss: 14845.070312\n",
      "Train Epoch: 88 [18432/225000 (8%)] Loss: 14764.799805\n",
      "Train Epoch: 88 [19840/225000 (9%)] Loss: 15022.829102\n",
      "Train Epoch: 88 [21248/225000 (9%)] Loss: 15301.012695\n",
      "Train Epoch: 88 [22656/225000 (10%)] Loss: 14781.593750\n",
      "Train Epoch: 88 [24064/225000 (11%)] Loss: 15709.892578\n",
      "Train Epoch: 88 [25472/225000 (11%)] Loss: 15058.943359\n",
      "Train Epoch: 88 [26880/225000 (12%)] Loss: 15337.268555\n",
      "Train Epoch: 88 [28288/225000 (13%)] Loss: 15145.345703\n",
      "Train Epoch: 88 [29696/225000 (13%)] Loss: 15210.198242\n",
      "Train Epoch: 88 [31104/225000 (14%)] Loss: 15636.369141\n",
      "Train Epoch: 88 [32512/225000 (14%)] Loss: 15626.483398\n",
      "Train Epoch: 88 [33920/225000 (15%)] Loss: 14923.195312\n",
      "Train Epoch: 88 [35328/225000 (16%)] Loss: 15088.626953\n",
      "Train Epoch: 88 [36736/225000 (16%)] Loss: 16089.915039\n",
      "Train Epoch: 88 [38144/225000 (17%)] Loss: 14515.135742\n",
      "Train Epoch: 88 [39552/225000 (18%)] Loss: 15036.171875\n",
      "Train Epoch: 88 [40960/225000 (18%)] Loss: 15536.551758\n",
      "Train Epoch: 88 [42368/225000 (19%)] Loss: 15134.652344\n",
      "Train Epoch: 88 [43776/225000 (19%)] Loss: 15210.235352\n",
      "Train Epoch: 88 [45184/225000 (20%)] Loss: 15261.056641\n",
      "Train Epoch: 88 [46592/225000 (21%)] Loss: 15038.912109\n",
      "Train Epoch: 88 [48000/225000 (21%)] Loss: 15614.681641\n",
      "Train Epoch: 88 [49408/225000 (22%)] Loss: 14919.618164\n",
      "Train Epoch: 88 [50816/225000 (23%)] Loss: 14928.900391\n",
      "Train Epoch: 88 [52224/225000 (23%)] Loss: 15347.443359\n",
      "Train Epoch: 88 [53632/225000 (24%)] Loss: 15297.989258\n",
      "Train Epoch: 88 [55040/225000 (24%)] Loss: 15308.241211\n",
      "Train Epoch: 88 [56448/225000 (25%)] Loss: 15166.563477\n",
      "Train Epoch: 88 [57856/225000 (26%)] Loss: 14897.210938\n",
      "Train Epoch: 88 [59264/225000 (26%)] Loss: 14866.141602\n",
      "Train Epoch: 88 [60672/225000 (27%)] Loss: 15054.744141\n",
      "Train Epoch: 88 [62080/225000 (28%)] Loss: 15290.011719\n",
      "Train Epoch: 88 [63488/225000 (28%)] Loss: 14731.241211\n",
      "Train Epoch: 88 [64896/225000 (29%)] Loss: 14772.358398\n",
      "Train Epoch: 88 [66304/225000 (29%)] Loss: 15222.585938\n",
      "Train Epoch: 88 [67712/225000 (30%)] Loss: 14976.084961\n",
      "Train Epoch: 88 [69120/225000 (31%)] Loss: 15216.503906\n",
      "Train Epoch: 88 [70528/225000 (31%)] Loss: 15010.799805\n",
      "Train Epoch: 88 [71936/225000 (32%)] Loss: 15253.829102\n",
      "Train Epoch: 88 [73344/225000 (33%)] Loss: 15594.369141\n",
      "Train Epoch: 88 [74752/225000 (33%)] Loss: 14935.542969\n",
      "Train Epoch: 88 [76160/225000 (34%)] Loss: 14808.092773\n",
      "Train Epoch: 88 [77568/225000 (34%)] Loss: 14974.327148\n",
      "Train Epoch: 88 [78976/225000 (35%)] Loss: 15396.099609\n",
      "Train Epoch: 88 [80384/225000 (36%)] Loss: 14546.612305\n",
      "Train Epoch: 88 [81792/225000 (36%)] Loss: 15318.687500\n",
      "Train Epoch: 88 [83200/225000 (37%)] Loss: 15174.058594\n",
      "Train Epoch: 88 [84608/225000 (38%)] Loss: 15340.118164\n",
      "Train Epoch: 88 [86016/225000 (38%)] Loss: 15152.386719\n",
      "Train Epoch: 88 [87424/225000 (39%)] Loss: 15644.011719\n",
      "Train Epoch: 88 [88832/225000 (39%)] Loss: 14963.592773\n",
      "Train Epoch: 88 [90240/225000 (40%)] Loss: 14713.463867\n",
      "Train Epoch: 88 [91648/225000 (41%)] Loss: 14914.110352\n",
      "Train Epoch: 88 [93056/225000 (41%)] Loss: 15151.896484\n",
      "Train Epoch: 88 [94464/225000 (42%)] Loss: 15169.721680\n",
      "Train Epoch: 88 [95872/225000 (43%)] Loss: 15147.138672\n",
      "Train Epoch: 88 [97280/225000 (43%)] Loss: 15463.714844\n",
      "Train Epoch: 88 [98688/225000 (44%)] Loss: 15098.755859\n",
      "Train Epoch: 88 [100096/225000 (44%)] Loss: 15288.642578\n",
      "Train Epoch: 88 [101504/225000 (45%)] Loss: 14993.945312\n",
      "Train Epoch: 88 [102912/225000 (46%)] Loss: 15138.837891\n",
      "Train Epoch: 88 [104320/225000 (46%)] Loss: 15170.111328\n",
      "Train Epoch: 88 [105728/225000 (47%)] Loss: 15080.601562\n",
      "Train Epoch: 88 [107136/225000 (48%)] Loss: 15035.270508\n",
      "Train Epoch: 88 [108544/225000 (48%)] Loss: 14962.734375\n",
      "Train Epoch: 88 [109952/225000 (49%)] Loss: 14735.622070\n",
      "Train Epoch: 88 [111360/225000 (49%)] Loss: 15315.539062\n",
      "Train Epoch: 88 [112768/225000 (50%)] Loss: 15207.171875\n",
      "Train Epoch: 88 [114176/225000 (51%)] Loss: 14934.855469\n",
      "Train Epoch: 88 [115584/225000 (51%)] Loss: 15113.474609\n",
      "Train Epoch: 88 [116992/225000 (52%)] Loss: 15446.511719\n",
      "Train Epoch: 88 [118400/225000 (53%)] Loss: 15160.825195\n",
      "Train Epoch: 88 [119808/225000 (53%)] Loss: 15258.936523\n",
      "Train Epoch: 88 [121216/225000 (54%)] Loss: 15227.573242\n",
      "Train Epoch: 88 [122624/225000 (54%)] Loss: 14910.006836\n",
      "Train Epoch: 88 [124032/225000 (55%)] Loss: 15193.844727\n",
      "Train Epoch: 88 [125440/225000 (56%)] Loss: 15019.887695\n",
      "Train Epoch: 88 [126848/225000 (56%)] Loss: 15487.933594\n",
      "Train Epoch: 88 [128256/225000 (57%)] Loss: 14978.137695\n",
      "Train Epoch: 88 [129664/225000 (58%)] Loss: 15385.923828\n",
      "Train Epoch: 88 [131072/225000 (58%)] Loss: 15112.620117\n",
      "Train Epoch: 88 [132480/225000 (59%)] Loss: 14839.904297\n",
      "Train Epoch: 88 [133888/225000 (60%)] Loss: 15165.852539\n",
      "Train Epoch: 88 [135296/225000 (60%)] Loss: 14796.641602\n",
      "Train Epoch: 88 [136704/225000 (61%)] Loss: 15052.880859\n",
      "Train Epoch: 88 [138112/225000 (61%)] Loss: 15174.882812\n",
      "Train Epoch: 88 [139520/225000 (62%)] Loss: 15008.770508\n",
      "Train Epoch: 88 [140928/225000 (63%)] Loss: 14525.250977\n",
      "Train Epoch: 88 [142336/225000 (63%)] Loss: 14766.929688\n",
      "Train Epoch: 88 [143744/225000 (64%)] Loss: 15206.063477\n",
      "Train Epoch: 88 [145152/225000 (65%)] Loss: 14748.707031\n",
      "Train Epoch: 88 [146560/225000 (65%)] Loss: 15537.184570\n",
      "Train Epoch: 88 [147968/225000 (66%)] Loss: 14716.540039\n",
      "Train Epoch: 88 [149376/225000 (66%)] Loss: 15347.918945\n",
      "Train Epoch: 88 [150784/225000 (67%)] Loss: 14740.642578\n",
      "Train Epoch: 88 [152192/225000 (68%)] Loss: 15149.634766\n",
      "Train Epoch: 88 [153600/225000 (68%)] Loss: 14910.094727\n",
      "Train Epoch: 88 [155008/225000 (69%)] Loss: 14829.196289\n",
      "Train Epoch: 88 [156416/225000 (70%)] Loss: 15355.207031\n",
      "Train Epoch: 88 [157824/225000 (70%)] Loss: 15188.369141\n",
      "Train Epoch: 88 [159232/225000 (71%)] Loss: 15082.596680\n",
      "Train Epoch: 88 [160640/225000 (71%)] Loss: 15196.361328\n",
      "Train Epoch: 88 [162048/225000 (72%)] Loss: 15364.077148\n",
      "Train Epoch: 88 [163456/225000 (73%)] Loss: 15320.535156\n",
      "Train Epoch: 88 [164864/225000 (73%)] Loss: 15209.953125\n",
      "Train Epoch: 88 [166272/225000 (74%)] Loss: 15085.976562\n",
      "Train Epoch: 88 [167680/225000 (75%)] Loss: 15232.428711\n",
      "Train Epoch: 88 [169088/225000 (75%)] Loss: 15476.655273\n",
      "Train Epoch: 88 [170496/225000 (76%)] Loss: 14994.500000\n",
      "Train Epoch: 88 [171904/225000 (76%)] Loss: 14759.189453\n",
      "Train Epoch: 88 [173312/225000 (77%)] Loss: 15160.964844\n",
      "Train Epoch: 88 [174720/225000 (78%)] Loss: 15448.853516\n",
      "Train Epoch: 88 [176128/225000 (78%)] Loss: 14754.130859\n",
      "Train Epoch: 88 [177536/225000 (79%)] Loss: 15034.716797\n",
      "Train Epoch: 88 [178944/225000 (80%)] Loss: 14595.755859\n",
      "Train Epoch: 88 [180352/225000 (80%)] Loss: 15870.370117\n",
      "Train Epoch: 88 [181760/225000 (81%)] Loss: 15178.267578\n",
      "Train Epoch: 88 [183168/225000 (81%)] Loss: 14802.402344\n",
      "Train Epoch: 88 [184576/225000 (82%)] Loss: 15017.704102\n",
      "Train Epoch: 88 [185984/225000 (83%)] Loss: 14813.538086\n",
      "Train Epoch: 88 [187392/225000 (83%)] Loss: 14932.921875\n",
      "Train Epoch: 88 [188800/225000 (84%)] Loss: 14996.765625\n",
      "Train Epoch: 88 [190208/225000 (85%)] Loss: 15009.658203\n",
      "Train Epoch: 88 [191616/225000 (85%)] Loss: 15400.209961\n",
      "Train Epoch: 88 [193024/225000 (86%)] Loss: 15301.318359\n",
      "Train Epoch: 88 [194432/225000 (86%)] Loss: 15234.588867\n",
      "Train Epoch: 88 [195840/225000 (87%)] Loss: 15258.867188\n",
      "Train Epoch: 88 [197248/225000 (88%)] Loss: 15111.780273\n",
      "Train Epoch: 88 [198656/225000 (88%)] Loss: 15138.639648\n",
      "Train Epoch: 88 [200064/225000 (89%)] Loss: 14940.327148\n",
      "Train Epoch: 88 [201472/225000 (90%)] Loss: 15207.803711\n",
      "Train Epoch: 88 [202880/225000 (90%)] Loss: 14998.781250\n",
      "Train Epoch: 88 [204288/225000 (91%)] Loss: 15462.081055\n",
      "Train Epoch: 88 [205696/225000 (91%)] Loss: 15317.026367\n",
      "Train Epoch: 88 [207104/225000 (92%)] Loss: 14817.287109\n",
      "Train Epoch: 88 [208512/225000 (93%)] Loss: 14899.697266\n",
      "Train Epoch: 88 [209920/225000 (93%)] Loss: 15444.796875\n",
      "Train Epoch: 88 [211328/225000 (94%)] Loss: 14666.564453\n",
      "Train Epoch: 88 [212736/225000 (95%)] Loss: 15258.312500\n",
      "Train Epoch: 88 [214144/225000 (95%)] Loss: 14773.903320\n",
      "Train Epoch: 88 [215552/225000 (96%)] Loss: 15123.059570\n",
      "Train Epoch: 88 [216960/225000 (96%)] Loss: 15035.537109\n",
      "Train Epoch: 88 [218368/225000 (97%)] Loss: 14741.182617\n",
      "Train Epoch: 88 [219776/225000 (98%)] Loss: 15027.190430\n",
      "Train Epoch: 88 [221184/225000 (98%)] Loss: 15043.875000\n",
      "Train Epoch: 88 [222592/225000 (99%)] Loss: 14652.384766\n",
      "Train Epoch: 88 [224000/225000 (100%)] Loss: 14990.037109\n",
      "    epoch          : 88\n",
      "    loss           : 15074.564906409983\n",
      "    val_loss       : 15071.933984917341\n",
      "Train Epoch: 89 [128/225000 (0%)] Loss: 15122.298828\n",
      "Train Epoch: 89 [1536/225000 (1%)] Loss: 14896.891602\n",
      "Train Epoch: 89 [2944/225000 (1%)] Loss: 15132.162109\n",
      "Train Epoch: 89 [4352/225000 (2%)] Loss: 15270.652344\n",
      "Train Epoch: 89 [5760/225000 (3%)] Loss: 15604.484375\n",
      "Train Epoch: 89 [7168/225000 (3%)] Loss: 14894.905273\n",
      "Train Epoch: 89 [8576/225000 (4%)] Loss: 15189.632812\n",
      "Train Epoch: 89 [9984/225000 (4%)] Loss: 14591.516602\n",
      "Train Epoch: 89 [11392/225000 (5%)] Loss: 14373.837891\n",
      "Train Epoch: 89 [12800/225000 (6%)] Loss: 15487.418945\n",
      "Train Epoch: 89 [14208/225000 (6%)] Loss: 14816.927734\n",
      "Train Epoch: 89 [15616/225000 (7%)] Loss: 15021.801758\n",
      "Train Epoch: 89 [17024/225000 (8%)] Loss: 14487.005859\n",
      "Train Epoch: 89 [18432/225000 (8%)] Loss: 15426.016602\n",
      "Train Epoch: 89 [19840/225000 (9%)] Loss: 15228.817383\n",
      "Train Epoch: 89 [21248/225000 (9%)] Loss: 14967.096680\n",
      "Train Epoch: 89 [22656/225000 (10%)] Loss: 15582.310547\n",
      "Train Epoch: 89 [24064/225000 (11%)] Loss: 14619.164062\n",
      "Train Epoch: 89 [25472/225000 (11%)] Loss: 14758.676758\n",
      "Train Epoch: 89 [26880/225000 (12%)] Loss: 15339.903320\n",
      "Train Epoch: 89 [28288/225000 (13%)] Loss: 15076.699219\n",
      "Train Epoch: 89 [29696/225000 (13%)] Loss: 14666.068359\n",
      "Train Epoch: 89 [31104/225000 (14%)] Loss: 14908.581055\n",
      "Train Epoch: 89 [32512/225000 (14%)] Loss: 14802.923828\n",
      "Train Epoch: 89 [33920/225000 (15%)] Loss: 14942.436523\n",
      "Train Epoch: 89 [35328/225000 (16%)] Loss: 15165.833984\n",
      "Train Epoch: 89 [36736/225000 (16%)] Loss: 15745.661133\n",
      "Train Epoch: 89 [38144/225000 (17%)] Loss: 14516.541992\n",
      "Train Epoch: 89 [39552/225000 (18%)] Loss: 15024.326172\n",
      "Train Epoch: 89 [40960/225000 (18%)] Loss: 14845.839844\n",
      "Train Epoch: 89 [42368/225000 (19%)] Loss: 15123.508789\n",
      "Train Epoch: 89 [43776/225000 (19%)] Loss: 15083.970703\n",
      "Train Epoch: 89 [45184/225000 (20%)] Loss: 14574.881836\n",
      "Train Epoch: 89 [46592/225000 (21%)] Loss: 14709.532227\n",
      "Train Epoch: 89 [48000/225000 (21%)] Loss: 15187.599609\n",
      "Train Epoch: 89 [49408/225000 (22%)] Loss: 15040.868164\n",
      "Train Epoch: 89 [50816/225000 (23%)] Loss: 15202.573242\n",
      "Train Epoch: 89 [52224/225000 (23%)] Loss: 15237.507812\n",
      "Train Epoch: 89 [53632/225000 (24%)] Loss: 14892.034180\n",
      "Train Epoch: 89 [55040/225000 (24%)] Loss: 15139.869141\n",
      "Train Epoch: 89 [56448/225000 (25%)] Loss: 15315.827148\n",
      "Train Epoch: 89 [57856/225000 (26%)] Loss: 15359.089844\n",
      "Train Epoch: 89 [59264/225000 (26%)] Loss: 14540.884766\n",
      "Train Epoch: 89 [60672/225000 (27%)] Loss: 14974.431641\n",
      "Train Epoch: 89 [62080/225000 (28%)] Loss: 15289.983398\n",
      "Train Epoch: 89 [63488/225000 (28%)] Loss: 14892.600586\n",
      "Train Epoch: 89 [64896/225000 (29%)] Loss: 15442.627930\n",
      "Train Epoch: 89 [66304/225000 (29%)] Loss: 14838.983398\n",
      "Train Epoch: 89 [67712/225000 (30%)] Loss: 15221.279297\n",
      "Train Epoch: 89 [69120/225000 (31%)] Loss: 15448.083984\n",
      "Train Epoch: 89 [70528/225000 (31%)] Loss: 15119.071289\n",
      "Train Epoch: 89 [71936/225000 (32%)] Loss: 15174.364258\n",
      "Train Epoch: 89 [73344/225000 (33%)] Loss: 14970.782227\n",
      "Train Epoch: 89 [74752/225000 (33%)] Loss: 15018.896484\n",
      "Train Epoch: 89 [76160/225000 (34%)] Loss: 14608.043945\n",
      "Train Epoch: 89 [77568/225000 (34%)] Loss: 14903.754883\n",
      "Train Epoch: 89 [78976/225000 (35%)] Loss: 15545.891602\n",
      "Train Epoch: 89 [80384/225000 (36%)] Loss: 14941.437500\n",
      "Train Epoch: 89 [81792/225000 (36%)] Loss: 14758.871094\n",
      "Train Epoch: 89 [83200/225000 (37%)] Loss: 15369.295898\n",
      "Train Epoch: 89 [84608/225000 (38%)] Loss: 15107.225586\n",
      "Train Epoch: 89 [86016/225000 (38%)] Loss: 14795.312500\n",
      "Train Epoch: 89 [87424/225000 (39%)] Loss: 14822.919922\n",
      "Train Epoch: 89 [88832/225000 (39%)] Loss: 14609.193359\n",
      "Train Epoch: 89 [90240/225000 (40%)] Loss: 15374.028320\n",
      "Train Epoch: 89 [91648/225000 (41%)] Loss: 14512.465820\n",
      "Train Epoch: 89 [93056/225000 (41%)] Loss: 15007.773438\n",
      "Train Epoch: 89 [94464/225000 (42%)] Loss: 14833.775391\n",
      "Train Epoch: 89 [95872/225000 (43%)] Loss: 15375.188477\n",
      "Train Epoch: 89 [97280/225000 (43%)] Loss: 14845.012695\n",
      "Train Epoch: 89 [98688/225000 (44%)] Loss: 14662.819336\n",
      "Train Epoch: 89 [100096/225000 (44%)] Loss: 15327.438477\n",
      "Train Epoch: 89 [101504/225000 (45%)] Loss: 15208.413086\n",
      "Train Epoch: 89 [102912/225000 (46%)] Loss: 14886.533203\n",
      "Train Epoch: 89 [104320/225000 (46%)] Loss: 15295.404297\n",
      "Train Epoch: 89 [105728/225000 (47%)] Loss: 15032.341797\n",
      "Train Epoch: 89 [107136/225000 (48%)] Loss: 15442.780273\n",
      "Train Epoch: 89 [108544/225000 (48%)] Loss: 15232.678711\n",
      "Train Epoch: 89 [109952/225000 (49%)] Loss: 14888.375000\n",
      "Train Epoch: 89 [111360/225000 (49%)] Loss: 14809.505859\n",
      "Train Epoch: 89 [112768/225000 (50%)] Loss: 14954.695312\n",
      "Train Epoch: 89 [114176/225000 (51%)] Loss: 15318.637695\n",
      "Train Epoch: 89 [115584/225000 (51%)] Loss: 15033.040039\n",
      "Train Epoch: 89 [116992/225000 (52%)] Loss: 15146.457031\n",
      "Train Epoch: 89 [118400/225000 (53%)] Loss: 15049.750000\n",
      "Train Epoch: 89 [119808/225000 (53%)] Loss: 14941.379883\n",
      "Train Epoch: 89 [121216/225000 (54%)] Loss: 15109.375000\n",
      "Train Epoch: 89 [122624/225000 (54%)] Loss: 15218.711914\n",
      "Train Epoch: 89 [124032/225000 (55%)] Loss: 14961.744141\n",
      "Train Epoch: 89 [125440/225000 (56%)] Loss: 14655.262695\n",
      "Train Epoch: 89 [126848/225000 (56%)] Loss: 14956.830078\n",
      "Train Epoch: 89 [128256/225000 (57%)] Loss: 14909.012695\n",
      "Train Epoch: 89 [129664/225000 (58%)] Loss: 15262.829102\n",
      "Train Epoch: 89 [131072/225000 (58%)] Loss: 14779.755859\n",
      "Train Epoch: 89 [132480/225000 (59%)] Loss: 15053.958008\n",
      "Train Epoch: 89 [133888/225000 (60%)] Loss: 15149.431641\n",
      "Train Epoch: 89 [135296/225000 (60%)] Loss: 14960.150391\n",
      "Train Epoch: 89 [136704/225000 (61%)] Loss: 15148.006836\n",
      "Train Epoch: 89 [138112/225000 (61%)] Loss: 15212.340820\n",
      "Train Epoch: 89 [139520/225000 (62%)] Loss: 14586.663086\n",
      "Train Epoch: 89 [140928/225000 (63%)] Loss: 15468.430664\n",
      "Train Epoch: 89 [142336/225000 (63%)] Loss: 15222.842773\n",
      "Train Epoch: 89 [143744/225000 (64%)] Loss: 15100.432617\n",
      "Train Epoch: 89 [145152/225000 (65%)] Loss: 15281.380859\n",
      "Train Epoch: 89 [146560/225000 (65%)] Loss: 15207.372070\n",
      "Train Epoch: 89 [147968/225000 (66%)] Loss: 15297.749023\n",
      "Train Epoch: 89 [149376/225000 (66%)] Loss: 14686.321289\n",
      "Train Epoch: 89 [150784/225000 (67%)] Loss: 15079.746094\n",
      "Train Epoch: 89 [152192/225000 (68%)] Loss: 14332.441406\n",
      "Train Epoch: 89 [153600/225000 (68%)] Loss: 15416.966797\n",
      "Train Epoch: 89 [155008/225000 (69%)] Loss: 15422.215820\n",
      "Train Epoch: 89 [156416/225000 (70%)] Loss: 15641.427734\n",
      "Train Epoch: 89 [157824/225000 (70%)] Loss: 15280.362305\n",
      "Train Epoch: 89 [159232/225000 (71%)] Loss: 14887.200195\n",
      "Train Epoch: 89 [160640/225000 (71%)] Loss: 15055.765625\n",
      "Train Epoch: 89 [162048/225000 (72%)] Loss: 14928.232422\n",
      "Train Epoch: 89 [163456/225000 (73%)] Loss: 14848.240234\n",
      "Train Epoch: 89 [164864/225000 (73%)] Loss: 15167.143555\n",
      "Train Epoch: 89 [166272/225000 (74%)] Loss: 14668.486328\n",
      "Train Epoch: 89 [167680/225000 (75%)] Loss: 14612.889648\n",
      "Train Epoch: 89 [169088/225000 (75%)] Loss: 15681.010742\n",
      "Train Epoch: 89 [170496/225000 (76%)] Loss: 14916.462891\n",
      "Train Epoch: 89 [171904/225000 (76%)] Loss: 15073.846680\n",
      "Train Epoch: 89 [173312/225000 (77%)] Loss: 15074.834961\n",
      "Train Epoch: 89 [174720/225000 (78%)] Loss: 14823.224609\n",
      "Train Epoch: 89 [176128/225000 (78%)] Loss: 15254.675781\n",
      "Train Epoch: 89 [177536/225000 (79%)] Loss: 15227.105469\n",
      "Train Epoch: 89 [178944/225000 (80%)] Loss: 15402.765625\n",
      "Train Epoch: 89 [180352/225000 (80%)] Loss: 15475.776367\n",
      "Train Epoch: 89 [181760/225000 (81%)] Loss: 15208.532227\n",
      "Train Epoch: 89 [183168/225000 (81%)] Loss: 14806.892578\n",
      "Train Epoch: 89 [184576/225000 (82%)] Loss: 14939.310547\n",
      "Train Epoch: 89 [185984/225000 (83%)] Loss: 15007.263672\n",
      "Train Epoch: 89 [187392/225000 (83%)] Loss: 14703.568359\n",
      "Train Epoch: 89 [188800/225000 (84%)] Loss: 15054.939453\n",
      "Train Epoch: 89 [190208/225000 (85%)] Loss: 14675.705078\n",
      "Train Epoch: 89 [191616/225000 (85%)] Loss: 15509.923828\n",
      "Train Epoch: 89 [193024/225000 (86%)] Loss: 14944.319336\n",
      "Train Epoch: 89 [194432/225000 (86%)] Loss: 14913.731445\n",
      "Train Epoch: 89 [195840/225000 (87%)] Loss: 15263.598633\n",
      "Train Epoch: 89 [197248/225000 (88%)] Loss: 14864.209961\n",
      "Train Epoch: 89 [198656/225000 (88%)] Loss: 14528.871094\n",
      "Train Epoch: 89 [200064/225000 (89%)] Loss: 15140.260742\n",
      "Train Epoch: 89 [201472/225000 (90%)] Loss: 14811.771484\n",
      "Train Epoch: 89 [202880/225000 (90%)] Loss: 14949.757812\n",
      "Train Epoch: 89 [204288/225000 (91%)] Loss: 15279.593750\n",
      "Train Epoch: 89 [205696/225000 (91%)] Loss: 15116.964844\n",
      "Train Epoch: 89 [207104/225000 (92%)] Loss: 14854.067383\n",
      "Train Epoch: 89 [208512/225000 (93%)] Loss: 15081.952148\n",
      "Train Epoch: 89 [209920/225000 (93%)] Loss: 14689.334961\n",
      "Train Epoch: 89 [211328/225000 (94%)] Loss: 15354.802734\n",
      "Train Epoch: 89 [212736/225000 (95%)] Loss: 15088.753906\n",
      "Train Epoch: 89 [214144/225000 (95%)] Loss: 15120.977539\n",
      "Train Epoch: 89 [215552/225000 (96%)] Loss: 15082.482422\n",
      "Train Epoch: 89 [216960/225000 (96%)] Loss: 14763.368164\n",
      "Train Epoch: 89 [218368/225000 (97%)] Loss: 15498.382812\n",
      "Train Epoch: 89 [219776/225000 (98%)] Loss: 14816.786133\n",
      "Train Epoch: 89 [221184/225000 (98%)] Loss: 15154.011719\n",
      "Train Epoch: 89 [222592/225000 (99%)] Loss: 14946.099609\n",
      "Train Epoch: 89 [224000/225000 (100%)] Loss: 15246.594727\n",
      "    epoch          : 89\n",
      "    loss           : 15078.209623751245\n",
      "    val_loss       : 15057.531123989243\n",
      "Train Epoch: 90 [128/225000 (0%)] Loss: 15143.123047\n",
      "Train Epoch: 90 [1536/225000 (1%)] Loss: 14870.758789\n",
      "Train Epoch: 90 [2944/225000 (1%)] Loss: 15048.876953\n",
      "Train Epoch: 90 [4352/225000 (2%)] Loss: 14664.116211\n",
      "Train Epoch: 90 [5760/225000 (3%)] Loss: 15232.107422\n",
      "Train Epoch: 90 [7168/225000 (3%)] Loss: 14917.773438\n",
      "Train Epoch: 90 [8576/225000 (4%)] Loss: 14939.343750\n",
      "Train Epoch: 90 [9984/225000 (4%)] Loss: 15308.285156\n",
      "Train Epoch: 90 [11392/225000 (5%)] Loss: 15486.335938\n",
      "Train Epoch: 90 [12800/225000 (6%)] Loss: 15236.360352\n",
      "Train Epoch: 90 [14208/225000 (6%)] Loss: 15174.083984\n",
      "Train Epoch: 90 [15616/225000 (7%)] Loss: 15305.872070\n",
      "Train Epoch: 90 [17024/225000 (8%)] Loss: 14850.590820\n",
      "Train Epoch: 90 [18432/225000 (8%)] Loss: 14812.522461\n",
      "Train Epoch: 90 [19840/225000 (9%)] Loss: 15483.441406\n",
      "Train Epoch: 90 [21248/225000 (9%)] Loss: 15222.408203\n",
      "Train Epoch: 90 [22656/225000 (10%)] Loss: 15211.878906\n",
      "Train Epoch: 90 [24064/225000 (11%)] Loss: 15246.249023\n",
      "Train Epoch: 90 [25472/225000 (11%)] Loss: 14937.477539\n",
      "Train Epoch: 90 [26880/225000 (12%)] Loss: 14900.814453\n",
      "Train Epoch: 90 [28288/225000 (13%)] Loss: 14791.862305\n",
      "Train Epoch: 90 [29696/225000 (13%)] Loss: 15134.598633\n",
      "Train Epoch: 90 [31104/225000 (14%)] Loss: 15011.074219\n",
      "Train Epoch: 90 [32512/225000 (14%)] Loss: 14983.205078\n",
      "Train Epoch: 90 [33920/225000 (15%)] Loss: 15003.571289\n",
      "Train Epoch: 90 [35328/225000 (16%)] Loss: 15249.556641\n",
      "Train Epoch: 90 [36736/225000 (16%)] Loss: 14754.752930\n",
      "Train Epoch: 90 [38144/225000 (17%)] Loss: 14908.448242\n",
      "Train Epoch: 90 [39552/225000 (18%)] Loss: 14818.266602\n",
      "Train Epoch: 90 [40960/225000 (18%)] Loss: 15095.913086\n",
      "Train Epoch: 90 [42368/225000 (19%)] Loss: 15063.618164\n",
      "Train Epoch: 90 [43776/225000 (19%)] Loss: 15524.190430\n",
      "Train Epoch: 90 [45184/225000 (20%)] Loss: 15204.858398\n",
      "Train Epoch: 90 [46592/225000 (21%)] Loss: 15466.559570\n",
      "Train Epoch: 90 [48000/225000 (21%)] Loss: 14820.619141\n",
      "Train Epoch: 90 [49408/225000 (22%)] Loss: 14973.007812\n",
      "Train Epoch: 90 [50816/225000 (23%)] Loss: 14982.723633\n",
      "Train Epoch: 90 [52224/225000 (23%)] Loss: 14911.384766\n",
      "Train Epoch: 90 [53632/225000 (24%)] Loss: 15689.466797\n",
      "Train Epoch: 90 [55040/225000 (24%)] Loss: 15149.868164\n",
      "Train Epoch: 90 [56448/225000 (25%)] Loss: 15043.539062\n",
      "Train Epoch: 90 [57856/225000 (26%)] Loss: 14998.213867\n",
      "Train Epoch: 90 [59264/225000 (26%)] Loss: 15189.345703\n",
      "Train Epoch: 90 [60672/225000 (27%)] Loss: 15182.199219\n",
      "Train Epoch: 90 [62080/225000 (28%)] Loss: 15011.831055\n",
      "Train Epoch: 90 [63488/225000 (28%)] Loss: 15060.462891\n",
      "Train Epoch: 90 [64896/225000 (29%)] Loss: 14712.189453\n",
      "Train Epoch: 90 [66304/225000 (29%)] Loss: 14927.548828\n",
      "Train Epoch: 90 [67712/225000 (30%)] Loss: 14803.458984\n",
      "Train Epoch: 90 [69120/225000 (31%)] Loss: 15242.984375\n",
      "Train Epoch: 90 [70528/225000 (31%)] Loss: 15143.875000\n",
      "Train Epoch: 90 [71936/225000 (32%)] Loss: 14610.968750\n",
      "Train Epoch: 90 [73344/225000 (33%)] Loss: 15222.482422\n",
      "Train Epoch: 90 [74752/225000 (33%)] Loss: 15062.873047\n",
      "Train Epoch: 90 [76160/225000 (34%)] Loss: 15152.684570\n",
      "Train Epoch: 90 [77568/225000 (34%)] Loss: 14693.554688\n",
      "Train Epoch: 90 [78976/225000 (35%)] Loss: 15056.464844\n",
      "Train Epoch: 90 [80384/225000 (36%)] Loss: 15221.926758\n",
      "Train Epoch: 90 [81792/225000 (36%)] Loss: 15371.986328\n",
      "Train Epoch: 90 [83200/225000 (37%)] Loss: 14587.031250\n",
      "Train Epoch: 90 [84608/225000 (38%)] Loss: 15053.752930\n",
      "Train Epoch: 90 [86016/225000 (38%)] Loss: 15504.761719\n",
      "Train Epoch: 90 [87424/225000 (39%)] Loss: 14973.465820\n",
      "Train Epoch: 90 [88832/225000 (39%)] Loss: 15135.399414\n",
      "Train Epoch: 90 [90240/225000 (40%)] Loss: 14920.348633\n",
      "Train Epoch: 90 [91648/225000 (41%)] Loss: 15044.840820\n",
      "Train Epoch: 90 [93056/225000 (41%)] Loss: 14939.432617\n",
      "Train Epoch: 90 [94464/225000 (42%)] Loss: 15016.839844\n",
      "Train Epoch: 90 [95872/225000 (43%)] Loss: 15351.216797\n",
      "Train Epoch: 90 [97280/225000 (43%)] Loss: 15198.299805\n",
      "Train Epoch: 90 [98688/225000 (44%)] Loss: 14960.259766\n",
      "Train Epoch: 90 [100096/225000 (44%)] Loss: 14889.172852\n",
      "Train Epoch: 90 [101504/225000 (45%)] Loss: 14627.296875\n",
      "Train Epoch: 90 [102912/225000 (46%)] Loss: 14924.518555\n",
      "Train Epoch: 90 [104320/225000 (46%)] Loss: 15034.707031\n",
      "Train Epoch: 90 [105728/225000 (47%)] Loss: 15060.161133\n",
      "Train Epoch: 90 [107136/225000 (48%)] Loss: 15087.958008\n",
      "Train Epoch: 90 [108544/225000 (48%)] Loss: 15199.190430\n",
      "Train Epoch: 90 [109952/225000 (49%)] Loss: 15372.070312\n",
      "Train Epoch: 90 [111360/225000 (49%)] Loss: 14778.429688\n",
      "Train Epoch: 90 [112768/225000 (50%)] Loss: 15324.773438\n",
      "Train Epoch: 90 [114176/225000 (51%)] Loss: 14938.402344\n",
      "Train Epoch: 90 [115584/225000 (51%)] Loss: 15130.293945\n",
      "Train Epoch: 90 [116992/225000 (52%)] Loss: 15056.623047\n",
      "Train Epoch: 90 [118400/225000 (53%)] Loss: 14890.858398\n",
      "Train Epoch: 90 [119808/225000 (53%)] Loss: 14443.054688\n",
      "Train Epoch: 90 [121216/225000 (54%)] Loss: 15233.816406\n",
      "Train Epoch: 90 [122624/225000 (54%)] Loss: 15445.400391\n",
      "Train Epoch: 90 [124032/225000 (55%)] Loss: 15079.019531\n",
      "Train Epoch: 90 [125440/225000 (56%)] Loss: 14986.384766\n",
      "Train Epoch: 90 [126848/225000 (56%)] Loss: 14809.942383\n",
      "Train Epoch: 90 [128256/225000 (57%)] Loss: 14967.846680\n",
      "Train Epoch: 90 [129664/225000 (58%)] Loss: 15233.174805\n",
      "Train Epoch: 90 [131072/225000 (58%)] Loss: 15093.094727\n",
      "Train Epoch: 90 [132480/225000 (59%)] Loss: 14980.849609\n",
      "Train Epoch: 90 [133888/225000 (60%)] Loss: 15305.195312\n",
      "Train Epoch: 90 [135296/225000 (60%)] Loss: 15184.616211\n",
      "Train Epoch: 90 [136704/225000 (61%)] Loss: 14930.936523\n",
      "Train Epoch: 90 [138112/225000 (61%)] Loss: 15152.113281\n",
      "Train Epoch: 90 [139520/225000 (62%)] Loss: 15670.466797\n",
      "Train Epoch: 90 [140928/225000 (63%)] Loss: 14867.156250\n",
      "Train Epoch: 90 [142336/225000 (63%)] Loss: 14797.650391\n",
      "Train Epoch: 90 [143744/225000 (64%)] Loss: 15307.481445\n",
      "Train Epoch: 90 [145152/225000 (65%)] Loss: 15074.587891\n",
      "Train Epoch: 90 [146560/225000 (65%)] Loss: 15029.239258\n",
      "Train Epoch: 90 [147968/225000 (66%)] Loss: 15416.602539\n",
      "Train Epoch: 90 [149376/225000 (66%)] Loss: 14515.373047\n",
      "Train Epoch: 90 [150784/225000 (67%)] Loss: 14888.351562\n",
      "Train Epoch: 90 [152192/225000 (68%)] Loss: 14775.482422\n",
      "Train Epoch: 90 [153600/225000 (68%)] Loss: 14923.000977\n",
      "Train Epoch: 90 [155008/225000 (69%)] Loss: 14550.576172\n",
      "Train Epoch: 90 [156416/225000 (70%)] Loss: 14460.276367\n",
      "Train Epoch: 90 [157824/225000 (70%)] Loss: 15084.747070\n",
      "Train Epoch: 90 [159232/225000 (71%)] Loss: 15526.746094\n",
      "Train Epoch: 90 [160640/225000 (71%)] Loss: 15229.791016\n",
      "Train Epoch: 90 [162048/225000 (72%)] Loss: 15102.855469\n",
      "Train Epoch: 90 [163456/225000 (73%)] Loss: 14936.474609\n",
      "Train Epoch: 90 [164864/225000 (73%)] Loss: 15353.251953\n",
      "Train Epoch: 90 [166272/225000 (74%)] Loss: 15052.745117\n",
      "Train Epoch: 90 [167680/225000 (75%)] Loss: 15264.963867\n",
      "Train Epoch: 90 [169088/225000 (75%)] Loss: 15240.231445\n",
      "Train Epoch: 90 [170496/225000 (76%)] Loss: 15592.252930\n",
      "Train Epoch: 90 [171904/225000 (76%)] Loss: 15205.974609\n",
      "Train Epoch: 90 [173312/225000 (77%)] Loss: 15023.728516\n",
      "Train Epoch: 90 [174720/225000 (78%)] Loss: 15070.993164\n",
      "Train Epoch: 90 [176128/225000 (78%)] Loss: 15448.931641\n",
      "Train Epoch: 90 [177536/225000 (79%)] Loss: 15799.775391\n",
      "Train Epoch: 90 [178944/225000 (80%)] Loss: 15225.562500\n",
      "Train Epoch: 90 [180352/225000 (80%)] Loss: 14935.061523\n",
      "Train Epoch: 90 [181760/225000 (81%)] Loss: 14994.041016\n",
      "Train Epoch: 90 [183168/225000 (81%)] Loss: 15164.800781\n",
      "Train Epoch: 90 [184576/225000 (82%)] Loss: 15076.327148\n",
      "Train Epoch: 90 [185984/225000 (83%)] Loss: 15128.719727\n",
      "Train Epoch: 90 [187392/225000 (83%)] Loss: 14896.022461\n",
      "Train Epoch: 90 [188800/225000 (84%)] Loss: 14853.188477\n",
      "Train Epoch: 90 [190208/225000 (85%)] Loss: 14980.206055\n",
      "Train Epoch: 90 [191616/225000 (85%)] Loss: 15831.557617\n",
      "Train Epoch: 90 [193024/225000 (86%)] Loss: 14842.577148\n",
      "Train Epoch: 90 [194432/225000 (86%)] Loss: 14896.956055\n",
      "Train Epoch: 90 [195840/225000 (87%)] Loss: 14624.171875\n",
      "Train Epoch: 90 [197248/225000 (88%)] Loss: 15583.625977\n",
      "Train Epoch: 90 [198656/225000 (88%)] Loss: 14804.535156\n",
      "Train Epoch: 90 [200064/225000 (89%)] Loss: 14897.131836\n",
      "Train Epoch: 90 [201472/225000 (90%)] Loss: 15454.454102\n",
      "Train Epoch: 90 [202880/225000 (90%)] Loss: 15290.389648\n",
      "Train Epoch: 90 [204288/225000 (91%)] Loss: 14661.282227\n",
      "Train Epoch: 90 [205696/225000 (91%)] Loss: 14665.932617\n",
      "Train Epoch: 90 [207104/225000 (92%)] Loss: 15068.649414\n",
      "Train Epoch: 90 [208512/225000 (93%)] Loss: 15678.834961\n",
      "Train Epoch: 90 [209920/225000 (93%)] Loss: 15485.876953\n",
      "Train Epoch: 90 [211328/225000 (94%)] Loss: 14642.524414\n",
      "Train Epoch: 90 [212736/225000 (95%)] Loss: 15420.301758\n",
      "Train Epoch: 90 [214144/225000 (95%)] Loss: 15031.565430\n",
      "Train Epoch: 90 [215552/225000 (96%)] Loss: 15613.622070\n",
      "Train Epoch: 90 [216960/225000 (96%)] Loss: 15017.583008\n",
      "Train Epoch: 90 [218368/225000 (97%)] Loss: 15122.126953\n",
      "Train Epoch: 90 [219776/225000 (98%)] Loss: 14633.045898\n",
      "Train Epoch: 90 [221184/225000 (98%)] Loss: 15031.089844\n",
      "Train Epoch: 90 [222592/225000 (99%)] Loss: 14841.866211\n",
      "Train Epoch: 90 [224000/225000 (100%)] Loss: 14882.152344\n",
      "    epoch          : 90\n",
      "    loss           : 15074.100825356407\n",
      "    val_loss       : 15055.173598362322\n",
      "Train Epoch: 91 [128/225000 (0%)] Loss: 14781.333008\n",
      "Train Epoch: 91 [1536/225000 (1%)] Loss: 14690.180664\n",
      "Train Epoch: 91 [2944/225000 (1%)] Loss: 14749.701172\n",
      "Train Epoch: 91 [4352/225000 (2%)] Loss: 14507.105469\n",
      "Train Epoch: 91 [5760/225000 (3%)] Loss: 14975.833008\n",
      "Train Epoch: 91 [7168/225000 (3%)] Loss: 15386.985352\n",
      "Train Epoch: 91 [8576/225000 (4%)] Loss: 15105.276367\n",
      "Train Epoch: 91 [9984/225000 (4%)] Loss: 15185.614258\n",
      "Train Epoch: 91 [11392/225000 (5%)] Loss: 14758.281250\n",
      "Train Epoch: 91 [12800/225000 (6%)] Loss: 15119.495117\n",
      "Train Epoch: 91 [14208/225000 (6%)] Loss: 15431.847656\n",
      "Train Epoch: 91 [15616/225000 (7%)] Loss: 15111.358398\n",
      "Train Epoch: 91 [17024/225000 (8%)] Loss: 14819.755859\n",
      "Train Epoch: 91 [18432/225000 (8%)] Loss: 15085.991211\n",
      "Train Epoch: 91 [19840/225000 (9%)] Loss: 15735.840820\n",
      "Train Epoch: 91 [21248/225000 (9%)] Loss: 15082.676758\n",
      "Train Epoch: 91 [22656/225000 (10%)] Loss: 14809.055664\n",
      "Train Epoch: 91 [24064/225000 (11%)] Loss: 15061.685547\n",
      "Train Epoch: 91 [25472/225000 (11%)] Loss: 15358.259766\n",
      "Train Epoch: 91 [26880/225000 (12%)] Loss: 15292.479492\n",
      "Train Epoch: 91 [28288/225000 (13%)] Loss: 14944.096680\n",
      "Train Epoch: 91 [29696/225000 (13%)] Loss: 15006.123047\n",
      "Train Epoch: 91 [31104/225000 (14%)] Loss: 14763.666016\n",
      "Train Epoch: 91 [32512/225000 (14%)] Loss: 14856.468750\n",
      "Train Epoch: 91 [33920/225000 (15%)] Loss: 15437.481445\n",
      "Train Epoch: 91 [35328/225000 (16%)] Loss: 14827.698242\n",
      "Train Epoch: 91 [36736/225000 (16%)] Loss: 15557.136719\n",
      "Train Epoch: 91 [38144/225000 (17%)] Loss: 15081.396484\n",
      "Train Epoch: 91 [39552/225000 (18%)] Loss: 15334.317383\n",
      "Train Epoch: 91 [40960/225000 (18%)] Loss: 15386.697266\n",
      "Train Epoch: 91 [42368/225000 (19%)] Loss: 14770.561523\n",
      "Train Epoch: 91 [43776/225000 (19%)] Loss: 15239.608398\n",
      "Train Epoch: 91 [45184/225000 (20%)] Loss: 15222.270508\n",
      "Train Epoch: 91 [46592/225000 (21%)] Loss: 15272.061523\n",
      "Train Epoch: 91 [48000/225000 (21%)] Loss: 14996.775391\n",
      "Train Epoch: 91 [49408/225000 (22%)] Loss: 15068.762695\n",
      "Train Epoch: 91 [50816/225000 (23%)] Loss: 14798.278320\n",
      "Train Epoch: 91 [52224/225000 (23%)] Loss: 14634.084961\n",
      "Train Epoch: 91 [53632/225000 (24%)] Loss: 15043.925781\n",
      "Train Epoch: 91 [55040/225000 (24%)] Loss: 15162.466797\n",
      "Train Epoch: 91 [56448/225000 (25%)] Loss: 15070.023438\n",
      "Train Epoch: 91 [57856/225000 (26%)] Loss: 15266.687500\n",
      "Train Epoch: 91 [59264/225000 (26%)] Loss: 14986.383789\n",
      "Train Epoch: 91 [60672/225000 (27%)] Loss: 14967.676758\n",
      "Train Epoch: 91 [62080/225000 (28%)] Loss: 14870.183594\n",
      "Train Epoch: 91 [63488/225000 (28%)] Loss: 14904.844727\n",
      "Train Epoch: 91 [64896/225000 (29%)] Loss: 14789.080078\n",
      "Train Epoch: 91 [66304/225000 (29%)] Loss: 15278.737305\n",
      "Train Epoch: 91 [67712/225000 (30%)] Loss: 14896.146484\n",
      "Train Epoch: 91 [69120/225000 (31%)] Loss: 15192.657227\n",
      "Train Epoch: 91 [70528/225000 (31%)] Loss: 14677.718750\n",
      "Train Epoch: 91 [71936/225000 (32%)] Loss: 14814.413086\n",
      "Train Epoch: 91 [73344/225000 (33%)] Loss: 14928.384766\n",
      "Train Epoch: 91 [74752/225000 (33%)] Loss: 15076.421875\n",
      "Train Epoch: 91 [76160/225000 (34%)] Loss: 14437.102539\n",
      "Train Epoch: 91 [77568/225000 (34%)] Loss: 15442.937500\n",
      "Train Epoch: 91 [78976/225000 (35%)] Loss: 15011.721680\n",
      "Train Epoch: 91 [80384/225000 (36%)] Loss: 14935.858398\n",
      "Train Epoch: 91 [81792/225000 (36%)] Loss: 14996.184570\n",
      "Train Epoch: 91 [83200/225000 (37%)] Loss: 15089.002930\n",
      "Train Epoch: 91 [84608/225000 (38%)] Loss: 14839.649414\n",
      "Train Epoch: 91 [86016/225000 (38%)] Loss: 15443.028320\n",
      "Train Epoch: 91 [87424/225000 (39%)] Loss: 14749.613281\n",
      "Train Epoch: 91 [88832/225000 (39%)] Loss: 15074.845703\n",
      "Train Epoch: 91 [90240/225000 (40%)] Loss: 14759.570312\n",
      "Train Epoch: 91 [91648/225000 (41%)] Loss: 15316.187500\n",
      "Train Epoch: 91 [93056/225000 (41%)] Loss: 15328.917969\n",
      "Train Epoch: 91 [94464/225000 (42%)] Loss: 14770.447266\n",
      "Train Epoch: 91 [95872/225000 (43%)] Loss: 14981.328125\n",
      "Train Epoch: 91 [97280/225000 (43%)] Loss: 15126.651367\n",
      "Train Epoch: 91 [98688/225000 (44%)] Loss: 14977.581055\n",
      "Train Epoch: 91 [100096/225000 (44%)] Loss: 15377.396484\n",
      "Train Epoch: 91 [101504/225000 (45%)] Loss: 14814.712891\n",
      "Train Epoch: 91 [102912/225000 (46%)] Loss: 15676.517578\n",
      "Train Epoch: 91 [104320/225000 (46%)] Loss: 14827.587891\n",
      "Train Epoch: 91 [105728/225000 (47%)] Loss: 15116.202148\n",
      "Train Epoch: 91 [107136/225000 (48%)] Loss: 14957.643555\n",
      "Train Epoch: 91 [108544/225000 (48%)] Loss: 14415.162109\n",
      "Train Epoch: 91 [109952/225000 (49%)] Loss: 14912.390625\n",
      "Train Epoch: 91 [111360/225000 (49%)] Loss: 15030.726562\n",
      "Train Epoch: 91 [112768/225000 (50%)] Loss: 15059.277344\n",
      "Train Epoch: 91 [114176/225000 (51%)] Loss: 14816.531250\n",
      "Train Epoch: 91 [115584/225000 (51%)] Loss: 14868.966797\n",
      "Train Epoch: 91 [116992/225000 (52%)] Loss: 15112.548828\n",
      "Train Epoch: 91 [118400/225000 (53%)] Loss: 14846.583008\n",
      "Train Epoch: 91 [119808/225000 (53%)] Loss: 15320.832031\n",
      "Train Epoch: 91 [121216/225000 (54%)] Loss: 14857.799805\n",
      "Train Epoch: 91 [122624/225000 (54%)] Loss: 15259.707031\n",
      "Train Epoch: 91 [124032/225000 (55%)] Loss: 15040.682617\n",
      "Train Epoch: 91 [125440/225000 (56%)] Loss: 15389.688477\n",
      "Train Epoch: 91 [126848/225000 (56%)] Loss: 15083.333008\n",
      "Train Epoch: 91 [128256/225000 (57%)] Loss: 15383.845703\n",
      "Train Epoch: 91 [129664/225000 (58%)] Loss: 15284.840820\n",
      "Train Epoch: 91 [131072/225000 (58%)] Loss: 14800.258789\n",
      "Train Epoch: 91 [132480/225000 (59%)] Loss: 14799.008789\n",
      "Train Epoch: 91 [133888/225000 (60%)] Loss: 15135.048828\n",
      "Train Epoch: 91 [135296/225000 (60%)] Loss: 15320.274414\n",
      "Train Epoch: 91 [136704/225000 (61%)] Loss: 14970.621094\n",
      "Train Epoch: 91 [138112/225000 (61%)] Loss: 14897.741211\n",
      "Train Epoch: 91 [139520/225000 (62%)] Loss: 15109.773438\n",
      "Train Epoch: 91 [140928/225000 (63%)] Loss: 15123.812500\n",
      "Train Epoch: 91 [142336/225000 (63%)] Loss: 14455.087891\n",
      "Train Epoch: 91 [143744/225000 (64%)] Loss: 15690.097656\n",
      "Train Epoch: 91 [145152/225000 (65%)] Loss: 15106.530273\n",
      "Train Epoch: 91 [146560/225000 (65%)] Loss: 14859.026367\n",
      "Train Epoch: 91 [147968/225000 (66%)] Loss: 15067.693359\n",
      "Train Epoch: 91 [149376/225000 (66%)] Loss: 15101.675781\n",
      "Train Epoch: 91 [150784/225000 (67%)] Loss: 14772.700195\n",
      "Train Epoch: 91 [152192/225000 (68%)] Loss: 15379.634766\n",
      "Train Epoch: 91 [153600/225000 (68%)] Loss: 15123.564453\n",
      "Train Epoch: 91 [155008/225000 (69%)] Loss: 15239.185547\n",
      "Train Epoch: 91 [156416/225000 (70%)] Loss: 15229.911133\n",
      "Train Epoch: 91 [157824/225000 (70%)] Loss: 14766.897461\n",
      "Train Epoch: 91 [159232/225000 (71%)] Loss: 15195.978516\n",
      "Train Epoch: 91 [160640/225000 (71%)] Loss: 14950.905273\n",
      "Train Epoch: 91 [162048/225000 (72%)] Loss: 14848.596680\n",
      "Train Epoch: 91 [163456/225000 (73%)] Loss: 14719.119141\n",
      "Train Epoch: 91 [164864/225000 (73%)] Loss: 15080.335938\n",
      "Train Epoch: 91 [166272/225000 (74%)] Loss: 14749.485352\n",
      "Train Epoch: 91 [167680/225000 (75%)] Loss: 14649.339844\n",
      "Train Epoch: 91 [169088/225000 (75%)] Loss: 15279.802734\n",
      "Train Epoch: 91 [170496/225000 (76%)] Loss: 15855.822266\n",
      "Train Epoch: 91 [171904/225000 (76%)] Loss: 14987.266602\n",
      "Train Epoch: 91 [173312/225000 (77%)] Loss: 15062.632812\n",
      "Train Epoch: 91 [174720/225000 (78%)] Loss: 15405.430664\n",
      "Train Epoch: 91 [176128/225000 (78%)] Loss: 14752.598633\n",
      "Train Epoch: 91 [177536/225000 (79%)] Loss: 15359.102539\n",
      "Train Epoch: 91 [178944/225000 (80%)] Loss: 15249.610352\n",
      "Train Epoch: 91 [180352/225000 (80%)] Loss: 15164.169922\n",
      "Train Epoch: 91 [181760/225000 (81%)] Loss: 15023.608398\n",
      "Train Epoch: 91 [183168/225000 (81%)] Loss: 14880.879883\n",
      "Train Epoch: 91 [184576/225000 (82%)] Loss: 15112.195312\n",
      "Train Epoch: 91 [185984/225000 (83%)] Loss: 14807.989258\n",
      "Train Epoch: 91 [187392/225000 (83%)] Loss: 15550.195312\n",
      "Train Epoch: 91 [188800/225000 (84%)] Loss: 15168.936523\n",
      "Train Epoch: 91 [190208/225000 (85%)] Loss: 15564.650391\n",
      "Train Epoch: 91 [191616/225000 (85%)] Loss: 14831.973633\n",
      "Train Epoch: 91 [193024/225000 (86%)] Loss: 15132.554688\n",
      "Train Epoch: 91 [194432/225000 (86%)] Loss: 14804.399414\n",
      "Train Epoch: 91 [195840/225000 (87%)] Loss: 15200.883789\n",
      "Train Epoch: 91 [197248/225000 (88%)] Loss: 15133.180664\n",
      "Train Epoch: 91 [198656/225000 (88%)] Loss: 15090.197266\n",
      "Train Epoch: 91 [200064/225000 (89%)] Loss: 14768.001953\n",
      "Train Epoch: 91 [201472/225000 (90%)] Loss: 14881.306641\n",
      "Train Epoch: 91 [202880/225000 (90%)] Loss: 15050.113281\n",
      "Train Epoch: 91 [204288/225000 (91%)] Loss: 14625.835938\n",
      "Train Epoch: 91 [205696/225000 (91%)] Loss: 15206.182617\n",
      "Train Epoch: 91 [207104/225000 (92%)] Loss: 14996.943359\n",
      "Train Epoch: 91 [208512/225000 (93%)] Loss: 15085.118164\n",
      "Train Epoch: 91 [209920/225000 (93%)] Loss: 14815.329102\n",
      "Train Epoch: 91 [211328/225000 (94%)] Loss: 14958.005859\n",
      "Train Epoch: 91 [212736/225000 (95%)] Loss: 14686.935547\n",
      "Train Epoch: 91 [214144/225000 (95%)] Loss: 15435.459961\n",
      "Train Epoch: 91 [215552/225000 (96%)] Loss: 15263.991211\n",
      "Train Epoch: 91 [216960/225000 (96%)] Loss: 14712.491211\n",
      "Train Epoch: 91 [218368/225000 (97%)] Loss: 15310.353516\n",
      "Train Epoch: 91 [219776/225000 (98%)] Loss: 15105.083984\n",
      "Train Epoch: 91 [221184/225000 (98%)] Loss: 15287.969727\n",
      "Train Epoch: 91 [222592/225000 (99%)] Loss: 15003.437500\n",
      "Train Epoch: 91 [224000/225000 (100%)] Loss: 15203.302734\n",
      "    epoch          : 91\n",
      "    loss           : 15073.313042164391\n",
      "    val_loss       : 15059.76083508879\n",
      "Train Epoch: 92 [128/225000 (0%)] Loss: 15450.468750\n",
      "Train Epoch: 92 [1536/225000 (1%)] Loss: 15208.833984\n",
      "Train Epoch: 92 [2944/225000 (1%)] Loss: 15030.081055\n",
      "Train Epoch: 92 [4352/225000 (2%)] Loss: 15194.682617\n",
      "Train Epoch: 92 [5760/225000 (3%)] Loss: 15260.169922\n",
      "Train Epoch: 92 [7168/225000 (3%)] Loss: 15266.512695\n",
      "Train Epoch: 92 [8576/225000 (4%)] Loss: 14622.215820\n",
      "Train Epoch: 92 [9984/225000 (4%)] Loss: 15446.675781\n",
      "Train Epoch: 92 [11392/225000 (5%)] Loss: 15496.861328\n",
      "Train Epoch: 92 [12800/225000 (6%)] Loss: 14934.017578\n",
      "Train Epoch: 92 [14208/225000 (6%)] Loss: 15167.770508\n",
      "Train Epoch: 92 [15616/225000 (7%)] Loss: 15044.146484\n",
      "Train Epoch: 92 [17024/225000 (8%)] Loss: 15200.160156\n",
      "Train Epoch: 92 [18432/225000 (8%)] Loss: 15000.337891\n",
      "Train Epoch: 92 [19840/225000 (9%)] Loss: 15240.068359\n",
      "Train Epoch: 92 [21248/225000 (9%)] Loss: 15727.920898\n",
      "Train Epoch: 92 [22656/225000 (10%)] Loss: 15160.953125\n",
      "Train Epoch: 92 [24064/225000 (11%)] Loss: 15446.081055\n",
      "Train Epoch: 92 [25472/225000 (11%)] Loss: 14963.226562\n",
      "Train Epoch: 92 [26880/225000 (12%)] Loss: 14896.183594\n",
      "Train Epoch: 92 [28288/225000 (13%)] Loss: 15096.494141\n",
      "Train Epoch: 92 [29696/225000 (13%)] Loss: 15186.738281\n",
      "Train Epoch: 92 [31104/225000 (14%)] Loss: 15122.983398\n",
      "Train Epoch: 92 [32512/225000 (14%)] Loss: 15118.013672\n",
      "Train Epoch: 92 [33920/225000 (15%)] Loss: 14825.687500\n",
      "Train Epoch: 92 [35328/225000 (16%)] Loss: 15102.823242\n",
      "Train Epoch: 92 [36736/225000 (16%)] Loss: 15275.391602\n",
      "Train Epoch: 92 [38144/225000 (17%)] Loss: 15163.024414\n",
      "Train Epoch: 92 [39552/225000 (18%)] Loss: 15285.483398\n",
      "Train Epoch: 92 [40960/225000 (18%)] Loss: 15169.156250\n",
      "Train Epoch: 92 [42368/225000 (19%)] Loss: 15631.271484\n",
      "Train Epoch: 92 [43776/225000 (19%)] Loss: 14820.190430\n",
      "Train Epoch: 92 [45184/225000 (20%)] Loss: 15107.535156\n",
      "Train Epoch: 92 [46592/225000 (21%)] Loss: 15388.021484\n",
      "Train Epoch: 92 [48000/225000 (21%)] Loss: 14859.554688\n",
      "Train Epoch: 92 [49408/225000 (22%)] Loss: 15178.437500\n",
      "Train Epoch: 92 [50816/225000 (23%)] Loss: 14813.437500\n",
      "Train Epoch: 92 [52224/225000 (23%)] Loss: 15113.189453\n",
      "Train Epoch: 92 [53632/225000 (24%)] Loss: 14833.786133\n",
      "Train Epoch: 92 [55040/225000 (24%)] Loss: 14777.701172\n",
      "Train Epoch: 92 [56448/225000 (25%)] Loss: 14738.590820\n",
      "Train Epoch: 92 [57856/225000 (26%)] Loss: 14917.648438\n",
      "Train Epoch: 92 [59264/225000 (26%)] Loss: 15367.362305\n",
      "Train Epoch: 92 [60672/225000 (27%)] Loss: 14834.692383\n",
      "Train Epoch: 92 [62080/225000 (28%)] Loss: 15226.340820\n",
      "Train Epoch: 92 [63488/225000 (28%)] Loss: 14937.520508\n",
      "Train Epoch: 92 [64896/225000 (29%)] Loss: 14553.379883\n",
      "Train Epoch: 92 [66304/225000 (29%)] Loss: 14808.209961\n",
      "Train Epoch: 92 [67712/225000 (30%)] Loss: 15518.904297\n",
      "Train Epoch: 92 [69120/225000 (31%)] Loss: 15227.415039\n",
      "Train Epoch: 92 [70528/225000 (31%)] Loss: 14788.477539\n",
      "Train Epoch: 92 [71936/225000 (32%)] Loss: 15242.663086\n",
      "Train Epoch: 92 [73344/225000 (33%)] Loss: 15126.108398\n",
      "Train Epoch: 92 [74752/225000 (33%)] Loss: 14881.077148\n",
      "Train Epoch: 92 [76160/225000 (34%)] Loss: 15209.400391\n",
      "Train Epoch: 92 [77568/225000 (34%)] Loss: 14650.323242\n",
      "Train Epoch: 92 [78976/225000 (35%)] Loss: 15355.280273\n",
      "Train Epoch: 92 [80384/225000 (36%)] Loss: 15102.074219\n",
      "Train Epoch: 92 [81792/225000 (36%)] Loss: 15252.497070\n",
      "Train Epoch: 92 [83200/225000 (37%)] Loss: 14737.277344\n",
      "Train Epoch: 92 [84608/225000 (38%)] Loss: 15394.858398\n",
      "Train Epoch: 92 [86016/225000 (38%)] Loss: 15248.094727\n",
      "Train Epoch: 92 [87424/225000 (39%)] Loss: 15365.476562\n",
      "Train Epoch: 92 [88832/225000 (39%)] Loss: 14724.754883\n",
      "Train Epoch: 92 [90240/225000 (40%)] Loss: 15397.713867\n",
      "Train Epoch: 92 [91648/225000 (41%)] Loss: 14764.958008\n",
      "Train Epoch: 92 [93056/225000 (41%)] Loss: 15082.987305\n",
      "Train Epoch: 92 [94464/225000 (42%)] Loss: 14951.829102\n",
      "Train Epoch: 92 [95872/225000 (43%)] Loss: 14854.932617\n",
      "Train Epoch: 92 [97280/225000 (43%)] Loss: 15229.497070\n",
      "Train Epoch: 92 [98688/225000 (44%)] Loss: 15237.302734\n",
      "Train Epoch: 92 [100096/225000 (44%)] Loss: 14937.175781\n",
      "Train Epoch: 92 [101504/225000 (45%)] Loss: 15266.846680\n",
      "Train Epoch: 92 [102912/225000 (46%)] Loss: 15105.117188\n",
      "Train Epoch: 92 [104320/225000 (46%)] Loss: 15082.559570\n",
      "Train Epoch: 92 [105728/225000 (47%)] Loss: 14834.612305\n",
      "Train Epoch: 92 [107136/225000 (48%)] Loss: 15283.558594\n",
      "Train Epoch: 92 [108544/225000 (48%)] Loss: 14776.065430\n",
      "Train Epoch: 92 [109952/225000 (49%)] Loss: 14894.751953\n",
      "Train Epoch: 92 [111360/225000 (49%)] Loss: 15109.533203\n",
      "Train Epoch: 92 [112768/225000 (50%)] Loss: 14971.444336\n",
      "Train Epoch: 92 [114176/225000 (51%)] Loss: 15000.080078\n",
      "Train Epoch: 92 [115584/225000 (51%)] Loss: 14974.477539\n",
      "Train Epoch: 92 [116992/225000 (52%)] Loss: 15170.401367\n",
      "Train Epoch: 92 [118400/225000 (53%)] Loss: 15046.349609\n",
      "Train Epoch: 92 [119808/225000 (53%)] Loss: 14866.676758\n",
      "Train Epoch: 92 [121216/225000 (54%)] Loss: 15473.083984\n",
      "Train Epoch: 92 [122624/225000 (54%)] Loss: 15445.826172\n",
      "Train Epoch: 92 [124032/225000 (55%)] Loss: 15291.722656\n",
      "Train Epoch: 92 [125440/225000 (56%)] Loss: 14651.196289\n",
      "Train Epoch: 92 [126848/225000 (56%)] Loss: 15238.404297\n",
      "Train Epoch: 92 [128256/225000 (57%)] Loss: 14788.338867\n",
      "Train Epoch: 92 [129664/225000 (58%)] Loss: 15366.548828\n",
      "Train Epoch: 92 [131072/225000 (58%)] Loss: 14907.789062\n",
      "Train Epoch: 92 [132480/225000 (59%)] Loss: 14998.584961\n",
      "Train Epoch: 92 [133888/225000 (60%)] Loss: 14998.158203\n",
      "Train Epoch: 92 [135296/225000 (60%)] Loss: 14707.635742\n",
      "Train Epoch: 92 [136704/225000 (61%)] Loss: 14999.622070\n",
      "Train Epoch: 92 [138112/225000 (61%)] Loss: 15124.841797\n",
      "Train Epoch: 92 [139520/225000 (62%)] Loss: 15221.714844\n",
      "Train Epoch: 92 [140928/225000 (63%)] Loss: 14798.242188\n",
      "Train Epoch: 92 [142336/225000 (63%)] Loss: 15653.193359\n",
      "Train Epoch: 92 [143744/225000 (64%)] Loss: 14760.641602\n",
      "Train Epoch: 92 [145152/225000 (65%)] Loss: 14892.947266\n",
      "Train Epoch: 92 [146560/225000 (65%)] Loss: 14834.294922\n",
      "Train Epoch: 92 [147968/225000 (66%)] Loss: 14793.904297\n",
      "Train Epoch: 92 [149376/225000 (66%)] Loss: 14900.905273\n",
      "Train Epoch: 92 [150784/225000 (67%)] Loss: 15361.777344\n",
      "Train Epoch: 92 [152192/225000 (68%)] Loss: 14718.596680\n",
      "Train Epoch: 92 [153600/225000 (68%)] Loss: 15020.387695\n",
      "Train Epoch: 92 [155008/225000 (69%)] Loss: 15095.799805\n",
      "Train Epoch: 92 [156416/225000 (70%)] Loss: 15073.187500\n",
      "Train Epoch: 92 [157824/225000 (70%)] Loss: 14800.715820\n",
      "Train Epoch: 92 [159232/225000 (71%)] Loss: 14893.518555\n",
      "Train Epoch: 92 [160640/225000 (71%)] Loss: 15319.153320\n",
      "Train Epoch: 92 [162048/225000 (72%)] Loss: 14964.996094\n",
      "Train Epoch: 92 [163456/225000 (73%)] Loss: 15407.473633\n",
      "Train Epoch: 92 [164864/225000 (73%)] Loss: 15106.628906\n",
      "Train Epoch: 92 [166272/225000 (74%)] Loss: 14957.553711\n",
      "Train Epoch: 92 [167680/225000 (75%)] Loss: 15320.535156\n",
      "Train Epoch: 92 [169088/225000 (75%)] Loss: 15222.595703\n",
      "Train Epoch: 92 [170496/225000 (76%)] Loss: 15304.268555\n",
      "Train Epoch: 92 [171904/225000 (76%)] Loss: 15026.263672\n",
      "Train Epoch: 92 [173312/225000 (77%)] Loss: 15343.143555\n",
      "Train Epoch: 92 [174720/225000 (78%)] Loss: 15293.944336\n",
      "Train Epoch: 92 [176128/225000 (78%)] Loss: 15830.810547\n",
      "Train Epoch: 92 [177536/225000 (79%)] Loss: 15237.450195\n",
      "Train Epoch: 92 [178944/225000 (80%)] Loss: 14892.370117\n",
      "Train Epoch: 92 [180352/225000 (80%)] Loss: 14916.166016\n",
      "Train Epoch: 92 [181760/225000 (81%)] Loss: 14992.574219\n",
      "Train Epoch: 92 [183168/225000 (81%)] Loss: 15124.542969\n",
      "Train Epoch: 92 [184576/225000 (82%)] Loss: 14756.472656\n",
      "Train Epoch: 92 [185984/225000 (83%)] Loss: 15210.727539\n",
      "Train Epoch: 92 [187392/225000 (83%)] Loss: 15034.252930\n",
      "Train Epoch: 92 [188800/225000 (84%)] Loss: 15577.735352\n",
      "Train Epoch: 92 [190208/225000 (85%)] Loss: 14993.815430\n",
      "Train Epoch: 92 [191616/225000 (85%)] Loss: 15299.766602\n",
      "Train Epoch: 92 [193024/225000 (86%)] Loss: 14904.227539\n",
      "Train Epoch: 92 [194432/225000 (86%)] Loss: 15116.730469\n",
      "Train Epoch: 92 [195840/225000 (87%)] Loss: 14490.998047\n",
      "Train Epoch: 92 [197248/225000 (88%)] Loss: 14972.750000\n",
      "Train Epoch: 92 [198656/225000 (88%)] Loss: 14818.278320\n",
      "Train Epoch: 92 [200064/225000 (89%)] Loss: 15016.595703\n",
      "Train Epoch: 92 [201472/225000 (90%)] Loss: 14980.661133\n",
      "Train Epoch: 92 [202880/225000 (90%)] Loss: 14992.201172\n",
      "Train Epoch: 92 [204288/225000 (91%)] Loss: 15157.230469\n",
      "Train Epoch: 92 [205696/225000 (91%)] Loss: 14890.852539\n",
      "Train Epoch: 92 [207104/225000 (92%)] Loss: 15112.757812\n",
      "Train Epoch: 92 [208512/225000 (93%)] Loss: 14664.672852\n",
      "Train Epoch: 92 [209920/225000 (93%)] Loss: 14648.569336\n",
      "Train Epoch: 92 [211328/225000 (94%)] Loss: 14854.749023\n",
      "Train Epoch: 92 [212736/225000 (95%)] Loss: 15031.097656\n",
      "Train Epoch: 92 [214144/225000 (95%)] Loss: 14718.174805\n",
      "Train Epoch: 92 [215552/225000 (96%)] Loss: 15378.259766\n",
      "Train Epoch: 92 [216960/225000 (96%)] Loss: 15121.801758\n",
      "Train Epoch: 92 [218368/225000 (97%)] Loss: 14758.147461\n",
      "Train Epoch: 92 [219776/225000 (98%)] Loss: 15242.037109\n",
      "Train Epoch: 92 [221184/225000 (98%)] Loss: 14593.094727\n",
      "Train Epoch: 92 [222592/225000 (99%)] Loss: 15227.083008\n",
      "Train Epoch: 92 [224000/225000 (100%)] Loss: 14389.258789\n",
      "    epoch          : 92\n",
      "    loss           : 15073.20181347323\n",
      "    val_loss       : 15060.146404571984\n",
      "Train Epoch: 93 [128/225000 (0%)] Loss: 14716.450195\n",
      "Train Epoch: 93 [1536/225000 (1%)] Loss: 15203.670898\n",
      "Train Epoch: 93 [2944/225000 (1%)] Loss: 14820.062500\n",
      "Train Epoch: 93 [4352/225000 (2%)] Loss: 14982.649414\n",
      "Train Epoch: 93 [5760/225000 (3%)] Loss: 15279.518555\n",
      "Train Epoch: 93 [7168/225000 (3%)] Loss: 14923.433594\n",
      "Train Epoch: 93 [8576/225000 (4%)] Loss: 15686.341797\n",
      "Train Epoch: 93 [9984/225000 (4%)] Loss: 14936.677734\n",
      "Train Epoch: 93 [11392/225000 (5%)] Loss: 15468.958984\n",
      "Train Epoch: 93 [12800/225000 (6%)] Loss: 14785.919922\n",
      "Train Epoch: 93 [14208/225000 (6%)] Loss: 15024.697266\n",
      "Train Epoch: 93 [15616/225000 (7%)] Loss: 15293.447266\n",
      "Train Epoch: 93 [17024/225000 (8%)] Loss: 15499.903320\n",
      "Train Epoch: 93 [18432/225000 (8%)] Loss: 15218.174805\n",
      "Train Epoch: 93 [19840/225000 (9%)] Loss: 15276.540039\n",
      "Train Epoch: 93 [21248/225000 (9%)] Loss: 15401.902344\n",
      "Train Epoch: 93 [22656/225000 (10%)] Loss: 15279.169922\n",
      "Train Epoch: 93 [24064/225000 (11%)] Loss: 15079.355469\n",
      "Train Epoch: 93 [25472/225000 (11%)] Loss: 15250.096680\n",
      "Train Epoch: 93 [26880/225000 (12%)] Loss: 15171.063477\n",
      "Train Epoch: 93 [28288/225000 (13%)] Loss: 15138.759766\n",
      "Train Epoch: 93 [29696/225000 (13%)] Loss: 15030.795898\n",
      "Train Epoch: 93 [31104/225000 (14%)] Loss: 14912.907227\n",
      "Train Epoch: 93 [32512/225000 (14%)] Loss: 15184.584961\n",
      "Train Epoch: 93 [33920/225000 (15%)] Loss: 15403.974609\n",
      "Train Epoch: 93 [35328/225000 (16%)] Loss: 14730.010742\n",
      "Train Epoch: 93 [36736/225000 (16%)] Loss: 14984.506836\n",
      "Train Epoch: 93 [38144/225000 (17%)] Loss: 15157.969727\n",
      "Train Epoch: 93 [39552/225000 (18%)] Loss: 15063.852539\n",
      "Train Epoch: 93 [40960/225000 (18%)] Loss: 15227.374023\n",
      "Train Epoch: 93 [42368/225000 (19%)] Loss: 15412.474609\n",
      "Train Epoch: 93 [43776/225000 (19%)] Loss: 15491.835938\n",
      "Train Epoch: 93 [45184/225000 (20%)] Loss: 15207.602539\n",
      "Train Epoch: 93 [46592/225000 (21%)] Loss: 15505.343750\n",
      "Train Epoch: 93 [48000/225000 (21%)] Loss: 15079.339844\n",
      "Train Epoch: 93 [49408/225000 (22%)] Loss: 15076.594727\n",
      "Train Epoch: 93 [50816/225000 (23%)] Loss: 14915.856445\n",
      "Train Epoch: 93 [52224/225000 (23%)] Loss: 15234.266602\n",
      "Train Epoch: 93 [53632/225000 (24%)] Loss: 15243.333008\n",
      "Train Epoch: 93 [55040/225000 (24%)] Loss: 15334.541016\n",
      "Train Epoch: 93 [56448/225000 (25%)] Loss: 14920.184570\n",
      "Train Epoch: 93 [57856/225000 (26%)] Loss: 15094.478516\n",
      "Train Epoch: 93 [59264/225000 (26%)] Loss: 15136.206055\n",
      "Train Epoch: 93 [60672/225000 (27%)] Loss: 14810.069336\n",
      "Train Epoch: 93 [62080/225000 (28%)] Loss: 14935.099609\n",
      "Train Epoch: 93 [63488/225000 (28%)] Loss: 15312.317383\n",
      "Train Epoch: 93 [64896/225000 (29%)] Loss: 15284.021484\n",
      "Train Epoch: 93 [66304/225000 (29%)] Loss: 15088.839844\n",
      "Train Epoch: 93 [67712/225000 (30%)] Loss: 15262.833008\n",
      "Train Epoch: 93 [69120/225000 (31%)] Loss: 15238.536133\n",
      "Train Epoch: 93 [70528/225000 (31%)] Loss: 14888.794922\n",
      "Train Epoch: 93 [71936/225000 (32%)] Loss: 14960.112305\n",
      "Train Epoch: 93 [73344/225000 (33%)] Loss: 14821.268555\n",
      "Train Epoch: 93 [74752/225000 (33%)] Loss: 14922.417969\n",
      "Train Epoch: 93 [76160/225000 (34%)] Loss: 14975.438477\n",
      "Train Epoch: 93 [77568/225000 (34%)] Loss: 15413.175781\n",
      "Train Epoch: 93 [78976/225000 (35%)] Loss: 14866.253906\n",
      "Train Epoch: 93 [80384/225000 (36%)] Loss: 15000.274414\n",
      "Train Epoch: 93 [81792/225000 (36%)] Loss: 15276.011719\n",
      "Train Epoch: 93 [83200/225000 (37%)] Loss: 15234.234375\n",
      "Train Epoch: 93 [84608/225000 (38%)] Loss: 15170.675781\n",
      "Train Epoch: 93 [86016/225000 (38%)] Loss: 15305.785156\n",
      "Train Epoch: 93 [87424/225000 (39%)] Loss: 15221.907227\n",
      "Train Epoch: 93 [88832/225000 (39%)] Loss: 14965.831055\n",
      "Train Epoch: 93 [90240/225000 (40%)] Loss: 15497.197266\n",
      "Train Epoch: 93 [91648/225000 (41%)] Loss: 14914.789062\n",
      "Train Epoch: 93 [93056/225000 (41%)] Loss: 14765.430664\n",
      "Train Epoch: 93 [94464/225000 (42%)] Loss: 14967.995117\n",
      "Train Epoch: 93 [95872/225000 (43%)] Loss: 15060.524414\n",
      "Train Epoch: 93 [97280/225000 (43%)] Loss: 15092.198242\n",
      "Train Epoch: 93 [98688/225000 (44%)] Loss: 15091.132812\n",
      "Train Epoch: 93 [100096/225000 (44%)] Loss: 14856.830078\n",
      "Train Epoch: 93 [101504/225000 (45%)] Loss: 15615.894531\n",
      "Train Epoch: 93 [102912/225000 (46%)] Loss: 15029.106445\n",
      "Train Epoch: 93 [104320/225000 (46%)] Loss: 15179.569336\n",
      "Train Epoch: 93 [105728/225000 (47%)] Loss: 14977.524414\n",
      "Train Epoch: 93 [107136/225000 (48%)] Loss: 15600.163086\n",
      "Train Epoch: 93 [108544/225000 (48%)] Loss: 14977.724609\n",
      "Train Epoch: 93 [109952/225000 (49%)] Loss: 15195.674805\n",
      "Train Epoch: 93 [111360/225000 (49%)] Loss: 14877.977539\n",
      "Train Epoch: 93 [112768/225000 (50%)] Loss: 14677.931641\n",
      "Train Epoch: 93 [114176/225000 (51%)] Loss: 15093.242188\n",
      "Train Epoch: 93 [115584/225000 (51%)] Loss: 15069.798828\n",
      "Train Epoch: 93 [116992/225000 (52%)] Loss: 15094.857422\n",
      "Train Epoch: 93 [118400/225000 (53%)] Loss: 15308.824219\n",
      "Train Epoch: 93 [119808/225000 (53%)] Loss: 14820.542969\n",
      "Train Epoch: 93 [121216/225000 (54%)] Loss: 15755.210938\n",
      "Train Epoch: 93 [122624/225000 (54%)] Loss: 15160.126953\n",
      "Train Epoch: 93 [124032/225000 (55%)] Loss: 15409.801758\n",
      "Train Epoch: 93 [125440/225000 (56%)] Loss: 14947.371094\n",
      "Train Epoch: 93 [126848/225000 (56%)] Loss: 15417.670898\n",
      "Train Epoch: 93 [128256/225000 (57%)] Loss: 15113.630859\n",
      "Train Epoch: 93 [129664/225000 (58%)] Loss: 15335.552734\n",
      "Train Epoch: 93 [131072/225000 (58%)] Loss: 14722.967773\n",
      "Train Epoch: 93 [132480/225000 (59%)] Loss: 15083.195312\n",
      "Train Epoch: 93 [133888/225000 (60%)] Loss: 14641.499023\n",
      "Train Epoch: 93 [135296/225000 (60%)] Loss: 15311.427734\n",
      "Train Epoch: 93 [136704/225000 (61%)] Loss: 15191.000000\n",
      "Train Epoch: 93 [138112/225000 (61%)] Loss: 14922.967773\n",
      "Train Epoch: 93 [139520/225000 (62%)] Loss: 15428.029297\n",
      "Train Epoch: 93 [140928/225000 (63%)] Loss: 15576.683594\n",
      "Train Epoch: 93 [142336/225000 (63%)] Loss: 15394.241211\n",
      "Train Epoch: 93 [143744/225000 (64%)] Loss: 15272.542969\n",
      "Train Epoch: 93 [145152/225000 (65%)] Loss: 15185.483398\n",
      "Train Epoch: 93 [146560/225000 (65%)] Loss: 15321.242188\n",
      "Train Epoch: 93 [147968/225000 (66%)] Loss: 15173.261719\n",
      "Train Epoch: 93 [149376/225000 (66%)] Loss: 14831.006836\n",
      "Train Epoch: 93 [150784/225000 (67%)] Loss: 15007.945312\n",
      "Train Epoch: 93 [152192/225000 (68%)] Loss: 15068.717773\n",
      "Train Epoch: 93 [153600/225000 (68%)] Loss: 15095.896484\n",
      "Train Epoch: 93 [155008/225000 (69%)] Loss: 15129.538086\n",
      "Train Epoch: 93 [156416/225000 (70%)] Loss: 15365.523438\n",
      "Train Epoch: 93 [157824/225000 (70%)] Loss: 14788.620117\n",
      "Train Epoch: 93 [159232/225000 (71%)] Loss: 14928.919922\n",
      "Train Epoch: 93 [160640/225000 (71%)] Loss: 15102.582031\n",
      "Train Epoch: 93 [162048/225000 (72%)] Loss: 15374.382812\n",
      "Train Epoch: 93 [163456/225000 (73%)] Loss: 15170.682617\n",
      "Train Epoch: 93 [164864/225000 (73%)] Loss: 15507.329102\n",
      "Train Epoch: 93 [166272/225000 (74%)] Loss: 15119.746094\n",
      "Train Epoch: 93 [167680/225000 (75%)] Loss: 14766.534180\n",
      "Train Epoch: 93 [169088/225000 (75%)] Loss: 14925.598633\n",
      "Train Epoch: 93 [170496/225000 (76%)] Loss: 14907.337891\n",
      "Train Epoch: 93 [171904/225000 (76%)] Loss: 15361.429688\n",
      "Train Epoch: 93 [173312/225000 (77%)] Loss: 15471.395508\n",
      "Train Epoch: 93 [174720/225000 (78%)] Loss: 15135.360352\n",
      "Train Epoch: 93 [176128/225000 (78%)] Loss: 14823.283203\n",
      "Train Epoch: 93 [177536/225000 (79%)] Loss: 15312.263672\n",
      "Train Epoch: 93 [178944/225000 (80%)] Loss: 15423.291992\n",
      "Train Epoch: 93 [180352/225000 (80%)] Loss: 14865.310547\n",
      "Train Epoch: 93 [181760/225000 (81%)] Loss: 14816.603516\n",
      "Train Epoch: 93 [183168/225000 (81%)] Loss: 14756.185547\n",
      "Train Epoch: 93 [184576/225000 (82%)] Loss: 14481.044922\n",
      "Train Epoch: 93 [185984/225000 (83%)] Loss: 14917.054688\n",
      "Train Epoch: 93 [187392/225000 (83%)] Loss: 14945.354492\n",
      "Train Epoch: 93 [188800/225000 (84%)] Loss: 15099.897461\n",
      "Train Epoch: 93 [190208/225000 (85%)] Loss: 14683.598633\n",
      "Train Epoch: 93 [191616/225000 (85%)] Loss: 14681.571289\n",
      "Train Epoch: 93 [193024/225000 (86%)] Loss: 15307.965820\n",
      "Train Epoch: 93 [194432/225000 (86%)] Loss: 14974.172852\n",
      "Train Epoch: 93 [195840/225000 (87%)] Loss: 15005.661133\n",
      "Train Epoch: 93 [197248/225000 (88%)] Loss: 15395.715820\n",
      "Train Epoch: 93 [198656/225000 (88%)] Loss: 14738.248047\n",
      "Train Epoch: 93 [200064/225000 (89%)] Loss: 15044.109375\n",
      "Train Epoch: 93 [201472/225000 (90%)] Loss: 14938.715820\n",
      "Train Epoch: 93 [202880/225000 (90%)] Loss: 14960.687500\n",
      "Train Epoch: 93 [204288/225000 (91%)] Loss: 14913.210938\n",
      "Train Epoch: 93 [205696/225000 (91%)] Loss: 15141.472656\n",
      "Train Epoch: 93 [207104/225000 (92%)] Loss: 15324.237305\n",
      "Train Epoch: 93 [208512/225000 (93%)] Loss: 14696.706055\n",
      "Train Epoch: 93 [209920/225000 (93%)] Loss: 14791.166016\n",
      "Train Epoch: 93 [211328/225000 (94%)] Loss: 14521.774414\n",
      "Train Epoch: 93 [212736/225000 (95%)] Loss: 14732.355469\n",
      "Train Epoch: 93 [214144/225000 (95%)] Loss: 15226.219727\n",
      "Train Epoch: 93 [215552/225000 (96%)] Loss: 15171.373047\n",
      "Train Epoch: 93 [216960/225000 (96%)] Loss: 14633.213867\n",
      "Train Epoch: 93 [218368/225000 (97%)] Loss: 15276.514648\n",
      "Train Epoch: 93 [219776/225000 (98%)] Loss: 14947.139648\n",
      "Train Epoch: 93 [221184/225000 (98%)] Loss: 15023.638672\n",
      "Train Epoch: 93 [222592/225000 (99%)] Loss: 15053.800781\n",
      "Train Epoch: 93 [224000/225000 (100%)] Loss: 14852.403320\n",
      "    epoch          : 93\n",
      "    loss           : 15072.852264647327\n",
      "    val_loss       : 15057.0612984695\n",
      "Train Epoch: 94 [128/225000 (0%)] Loss: 15405.672852\n",
      "Train Epoch: 94 [1536/225000 (1%)] Loss: 14981.113281\n",
      "Train Epoch: 94 [2944/225000 (1%)] Loss: 14879.196289\n",
      "Train Epoch: 94 [4352/225000 (2%)] Loss: 15407.602539\n",
      "Train Epoch: 94 [5760/225000 (3%)] Loss: 14962.951172\n",
      "Train Epoch: 94 [7168/225000 (3%)] Loss: 15058.859375\n",
      "Train Epoch: 94 [8576/225000 (4%)] Loss: 15023.416016\n",
      "Train Epoch: 94 [9984/225000 (4%)] Loss: 15650.484375\n",
      "Train Epoch: 94 [11392/225000 (5%)] Loss: 15431.469727\n",
      "Train Epoch: 94 [12800/225000 (6%)] Loss: 14838.867188\n",
      "Train Epoch: 94 [14208/225000 (6%)] Loss: 14935.047852\n",
      "Train Epoch: 94 [15616/225000 (7%)] Loss: 14996.549805\n",
      "Train Epoch: 94 [17024/225000 (8%)] Loss: 15092.775391\n",
      "Train Epoch: 94 [18432/225000 (8%)] Loss: 15011.940430\n",
      "Train Epoch: 94 [19840/225000 (9%)] Loss: 14880.203125\n",
      "Train Epoch: 94 [21248/225000 (9%)] Loss: 14897.865234\n",
      "Train Epoch: 94 [22656/225000 (10%)] Loss: 15092.436523\n",
      "Train Epoch: 94 [24064/225000 (11%)] Loss: 15524.413086\n",
      "Train Epoch: 94 [25472/225000 (11%)] Loss: 15462.992188\n",
      "Train Epoch: 94 [26880/225000 (12%)] Loss: 15085.627930\n",
      "Train Epoch: 94 [28288/225000 (13%)] Loss: 14971.664062\n",
      "Train Epoch: 94 [29696/225000 (13%)] Loss: 15038.291992\n",
      "Train Epoch: 94 [31104/225000 (14%)] Loss: 15309.327148\n",
      "Train Epoch: 94 [32512/225000 (14%)] Loss: 15216.032227\n",
      "Train Epoch: 94 [33920/225000 (15%)] Loss: 15093.793945\n",
      "Train Epoch: 94 [35328/225000 (16%)] Loss: 14955.578125\n",
      "Train Epoch: 94 [36736/225000 (16%)] Loss: 14713.521484\n",
      "Train Epoch: 94 [38144/225000 (17%)] Loss: 15308.713867\n",
      "Train Epoch: 94 [39552/225000 (18%)] Loss: 14794.551758\n",
      "Train Epoch: 94 [40960/225000 (18%)] Loss: 14955.192383\n",
      "Train Epoch: 94 [42368/225000 (19%)] Loss: 14848.438477\n",
      "Train Epoch: 94 [43776/225000 (19%)] Loss: 14751.215820\n",
      "Train Epoch: 94 [45184/225000 (20%)] Loss: 14924.944336\n",
      "Train Epoch: 94 [46592/225000 (21%)] Loss: 14978.768555\n",
      "Train Epoch: 94 [48000/225000 (21%)] Loss: 15158.341797\n",
      "Train Epoch: 94 [49408/225000 (22%)] Loss: 15104.160156\n",
      "Train Epoch: 94 [50816/225000 (23%)] Loss: 15243.702148\n",
      "Train Epoch: 94 [52224/225000 (23%)] Loss: 15106.495117\n",
      "Train Epoch: 94 [53632/225000 (24%)] Loss: 15507.710938\n",
      "Train Epoch: 94 [55040/225000 (24%)] Loss: 14979.861328\n",
      "Train Epoch: 94 [56448/225000 (25%)] Loss: 14769.333984\n",
      "Train Epoch: 94 [57856/225000 (26%)] Loss: 14878.562500\n",
      "Train Epoch: 94 [59264/225000 (26%)] Loss: 14708.684570\n",
      "Train Epoch: 94 [60672/225000 (27%)] Loss: 14690.322266\n",
      "Train Epoch: 94 [62080/225000 (28%)] Loss: 14894.974609\n",
      "Train Epoch: 94 [63488/225000 (28%)] Loss: 15824.173828\n",
      "Train Epoch: 94 [64896/225000 (29%)] Loss: 14871.917969\n",
      "Train Epoch: 94 [66304/225000 (29%)] Loss: 14940.116211\n",
      "Train Epoch: 94 [67712/225000 (30%)] Loss: 15314.300781\n",
      "Train Epoch: 94 [69120/225000 (31%)] Loss: 15337.961914\n",
      "Train Epoch: 94 [70528/225000 (31%)] Loss: 14841.461914\n",
      "Train Epoch: 94 [71936/225000 (32%)] Loss: 14665.276367\n",
      "Train Epoch: 94 [73344/225000 (33%)] Loss: 14933.685547\n",
      "Train Epoch: 94 [74752/225000 (33%)] Loss: 14862.161133\n",
      "Train Epoch: 94 [76160/225000 (34%)] Loss: 15011.081055\n",
      "Train Epoch: 94 [77568/225000 (34%)] Loss: 14692.804688\n",
      "Train Epoch: 94 [78976/225000 (35%)] Loss: 14973.473633\n",
      "Train Epoch: 94 [80384/225000 (36%)] Loss: 15083.190430\n",
      "Train Epoch: 94 [81792/225000 (36%)] Loss: 14776.464844\n",
      "Train Epoch: 94 [83200/225000 (37%)] Loss: 14971.683594\n",
      "Train Epoch: 94 [84608/225000 (38%)] Loss: 15394.543945\n",
      "Train Epoch: 94 [86016/225000 (38%)] Loss: 15450.786133\n",
      "Train Epoch: 94 [87424/225000 (39%)] Loss: 15242.565430\n",
      "Train Epoch: 94 [88832/225000 (39%)] Loss: 15318.965820\n",
      "Train Epoch: 94 [90240/225000 (40%)] Loss: 15022.886719\n",
      "Train Epoch: 94 [91648/225000 (41%)] Loss: 15286.528320\n",
      "Train Epoch: 94 [93056/225000 (41%)] Loss: 15083.553711\n",
      "Train Epoch: 94 [94464/225000 (42%)] Loss: 15061.534180\n",
      "Train Epoch: 94 [95872/225000 (43%)] Loss: 14675.656250\n",
      "Train Epoch: 94 [97280/225000 (43%)] Loss: 15013.038086\n",
      "Train Epoch: 94 [98688/225000 (44%)] Loss: 15207.738281\n",
      "Train Epoch: 94 [100096/225000 (44%)] Loss: 14931.498047\n",
      "Train Epoch: 94 [101504/225000 (45%)] Loss: 14949.077148\n",
      "Train Epoch: 94 [102912/225000 (46%)] Loss: 14808.457031\n",
      "Train Epoch: 94 [104320/225000 (46%)] Loss: 14561.387695\n",
      "Train Epoch: 94 [105728/225000 (47%)] Loss: 15219.095703\n",
      "Train Epoch: 94 [107136/225000 (48%)] Loss: 15115.499023\n",
      "Train Epoch: 94 [108544/225000 (48%)] Loss: 14762.400391\n",
      "Train Epoch: 94 [109952/225000 (49%)] Loss: 14895.572266\n",
      "Train Epoch: 94 [111360/225000 (49%)] Loss: 14975.605469\n",
      "Train Epoch: 94 [112768/225000 (50%)] Loss: 14888.490234\n",
      "Train Epoch: 94 [114176/225000 (51%)] Loss: 15157.457031\n",
      "Train Epoch: 94 [115584/225000 (51%)] Loss: 15117.276367\n",
      "Train Epoch: 94 [116992/225000 (52%)] Loss: 14722.569336\n",
      "Train Epoch: 94 [118400/225000 (53%)] Loss: 15102.853516\n",
      "Train Epoch: 94 [119808/225000 (53%)] Loss: 14728.971680\n",
      "Train Epoch: 94 [121216/225000 (54%)] Loss: 14556.922852\n",
      "Train Epoch: 94 [122624/225000 (54%)] Loss: 15172.388672\n",
      "Train Epoch: 94 [124032/225000 (55%)] Loss: 15312.399414\n",
      "Train Epoch: 94 [125440/225000 (56%)] Loss: 14579.079102\n",
      "Train Epoch: 94 [126848/225000 (56%)] Loss: 15314.526367\n",
      "Train Epoch: 94 [128256/225000 (57%)] Loss: 15036.684570\n",
      "Train Epoch: 94 [129664/225000 (58%)] Loss: 15194.951172\n",
      "Train Epoch: 94 [131072/225000 (58%)] Loss: 15240.096680\n",
      "Train Epoch: 94 [132480/225000 (59%)] Loss: 15132.696289\n",
      "Train Epoch: 94 [133888/225000 (60%)] Loss: 15483.808594\n",
      "Train Epoch: 94 [135296/225000 (60%)] Loss: 14712.966797\n",
      "Train Epoch: 94 [136704/225000 (61%)] Loss: 15336.228516\n",
      "Train Epoch: 94 [138112/225000 (61%)] Loss: 14924.131836\n",
      "Train Epoch: 94 [139520/225000 (62%)] Loss: 14887.243164\n",
      "Train Epoch: 94 [140928/225000 (63%)] Loss: 15240.767578\n",
      "Train Epoch: 94 [142336/225000 (63%)] Loss: 15398.267578\n",
      "Train Epoch: 94 [143744/225000 (64%)] Loss: 14777.612305\n",
      "Train Epoch: 94 [145152/225000 (65%)] Loss: 15668.502930\n",
      "Train Epoch: 94 [146560/225000 (65%)] Loss: 14725.590820\n",
      "Train Epoch: 94 [147968/225000 (66%)] Loss: 15304.860352\n",
      "Train Epoch: 94 [149376/225000 (66%)] Loss: 14834.377930\n",
      "Train Epoch: 94 [150784/225000 (67%)] Loss: 14865.098633\n",
      "Train Epoch: 94 [152192/225000 (68%)] Loss: 15253.653320\n",
      "Train Epoch: 94 [153600/225000 (68%)] Loss: 14928.374023\n",
      "Train Epoch: 94 [155008/225000 (69%)] Loss: 15166.511719\n",
      "Train Epoch: 94 [156416/225000 (70%)] Loss: 14983.875977\n",
      "Train Epoch: 94 [157824/225000 (70%)] Loss: 14774.046875\n",
      "Train Epoch: 94 [159232/225000 (71%)] Loss: 15298.987305\n",
      "Train Epoch: 94 [160640/225000 (71%)] Loss: 14966.928711\n",
      "Train Epoch: 94 [162048/225000 (72%)] Loss: 15106.221680\n",
      "Train Epoch: 94 [163456/225000 (73%)] Loss: 14952.849609\n",
      "Train Epoch: 94 [164864/225000 (73%)] Loss: 14987.626953\n",
      "Train Epoch: 94 [166272/225000 (74%)] Loss: 14829.866211\n",
      "Train Epoch: 94 [167680/225000 (75%)] Loss: 14954.034180\n",
      "Train Epoch: 94 [169088/225000 (75%)] Loss: 14841.561523\n",
      "Train Epoch: 94 [170496/225000 (76%)] Loss: 15459.848633\n",
      "Train Epoch: 94 [171904/225000 (76%)] Loss: 15018.762695\n",
      "Train Epoch: 94 [173312/225000 (77%)] Loss: 15210.434570\n",
      "Train Epoch: 94 [174720/225000 (78%)] Loss: 14540.876953\n",
      "Train Epoch: 94 [176128/225000 (78%)] Loss: 14764.577148\n",
      "Train Epoch: 94 [177536/225000 (79%)] Loss: 14662.756836\n",
      "Train Epoch: 94 [178944/225000 (80%)] Loss: 15464.023438\n",
      "Train Epoch: 94 [180352/225000 (80%)] Loss: 15188.997070\n",
      "Train Epoch: 94 [181760/225000 (81%)] Loss: 14852.885742\n",
      "Train Epoch: 94 [183168/225000 (81%)] Loss: 14921.538086\n",
      "Train Epoch: 94 [184576/225000 (82%)] Loss: 15266.480469\n",
      "Train Epoch: 94 [185984/225000 (83%)] Loss: 15252.712891\n",
      "Train Epoch: 94 [187392/225000 (83%)] Loss: 14671.136719\n",
      "Train Epoch: 94 [188800/225000 (84%)] Loss: 15022.154297\n",
      "Train Epoch: 94 [190208/225000 (85%)] Loss: 14997.767578\n",
      "Train Epoch: 94 [191616/225000 (85%)] Loss: 15242.176758\n",
      "Train Epoch: 94 [193024/225000 (86%)] Loss: 15135.905273\n",
      "Train Epoch: 94 [194432/225000 (86%)] Loss: 15160.203125\n",
      "Train Epoch: 94 [195840/225000 (87%)] Loss: 15071.163086\n",
      "Train Epoch: 94 [197248/225000 (88%)] Loss: 15177.895508\n",
      "Train Epoch: 94 [198656/225000 (88%)] Loss: 14848.625000\n",
      "Train Epoch: 94 [200064/225000 (89%)] Loss: 15395.708008\n",
      "Train Epoch: 94 [201472/225000 (90%)] Loss: 15475.703125\n",
      "Train Epoch: 94 [202880/225000 (90%)] Loss: 15003.427734\n",
      "Train Epoch: 94 [204288/225000 (91%)] Loss: 14959.474609\n",
      "Train Epoch: 94 [205696/225000 (91%)] Loss: 15247.247070\n",
      "Train Epoch: 94 [207104/225000 (92%)] Loss: 15101.373047\n",
      "Train Epoch: 94 [208512/225000 (93%)] Loss: 15426.523438\n",
      "Train Epoch: 94 [209920/225000 (93%)] Loss: 15097.828125\n",
      "Train Epoch: 94 [211328/225000 (94%)] Loss: 15019.563477\n",
      "Train Epoch: 94 [212736/225000 (95%)] Loss: 15390.367188\n",
      "Train Epoch: 94 [214144/225000 (95%)] Loss: 15011.066406\n",
      "Train Epoch: 94 [215552/225000 (96%)] Loss: 15093.479492\n",
      "Train Epoch: 94 [216960/225000 (96%)] Loss: 14967.513672\n",
      "Train Epoch: 94 [218368/225000 (97%)] Loss: 14810.302734\n",
      "Train Epoch: 94 [219776/225000 (98%)] Loss: 14959.923828\n",
      "Train Epoch: 94 [221184/225000 (98%)] Loss: 15140.596680\n",
      "Train Epoch: 94 [222592/225000 (99%)] Loss: 14906.148438\n",
      "Train Epoch: 94 [224000/225000 (100%)] Loss: 15280.859375\n",
      "    epoch          : 94\n",
      "    loss           : 15073.185741854202\n",
      "    val_loss       : 15055.89636544275\n",
      "Train Epoch: 95 [128/225000 (0%)] Loss: 15605.176758\n",
      "Train Epoch: 95 [1536/225000 (1%)] Loss: 15263.662109\n",
      "Train Epoch: 95 [2944/225000 (1%)] Loss: 15242.205078\n",
      "Train Epoch: 95 [4352/225000 (2%)] Loss: 15222.425781\n",
      "Train Epoch: 95 [5760/225000 (3%)] Loss: 14702.524414\n",
      "Train Epoch: 95 [7168/225000 (3%)] Loss: 14692.965820\n",
      "Train Epoch: 95 [8576/225000 (4%)] Loss: 14814.566406\n",
      "Train Epoch: 95 [9984/225000 (4%)] Loss: 15002.015625\n",
      "Train Epoch: 95 [11392/225000 (5%)] Loss: 15490.750000\n",
      "Train Epoch: 95 [12800/225000 (6%)] Loss: 15496.027344\n",
      "Train Epoch: 95 [14208/225000 (6%)] Loss: 15220.324219\n",
      "Train Epoch: 95 [15616/225000 (7%)] Loss: 15307.162109\n",
      "Train Epoch: 95 [17024/225000 (8%)] Loss: 15131.364258\n",
      "Train Epoch: 95 [18432/225000 (8%)] Loss: 15250.472656\n",
      "Train Epoch: 95 [19840/225000 (9%)] Loss: 14801.516602\n",
      "Train Epoch: 95 [21248/225000 (9%)] Loss: 15323.883789\n",
      "Train Epoch: 95 [22656/225000 (10%)] Loss: 14833.211914\n",
      "Train Epoch: 95 [24064/225000 (11%)] Loss: 14906.833984\n",
      "Train Epoch: 95 [25472/225000 (11%)] Loss: 15042.443359\n",
      "Train Epoch: 95 [26880/225000 (12%)] Loss: 15173.791992\n",
      "Train Epoch: 95 [28288/225000 (13%)] Loss: 15181.784180\n",
      "Train Epoch: 95 [29696/225000 (13%)] Loss: 15060.474609\n",
      "Train Epoch: 95 [31104/225000 (14%)] Loss: 15371.151367\n",
      "Train Epoch: 95 [32512/225000 (14%)] Loss: 15068.316406\n",
      "Train Epoch: 95 [33920/225000 (15%)] Loss: 14647.875977\n",
      "Train Epoch: 95 [35328/225000 (16%)] Loss: 15399.904297\n",
      "Train Epoch: 95 [36736/225000 (16%)] Loss: 15343.311523\n",
      "Train Epoch: 95 [38144/225000 (17%)] Loss: 15501.138672\n",
      "Train Epoch: 95 [39552/225000 (18%)] Loss: 15306.357422\n",
      "Train Epoch: 95 [40960/225000 (18%)] Loss: 15091.084961\n",
      "Train Epoch: 95 [42368/225000 (19%)] Loss: 15573.427734\n",
      "Train Epoch: 95 [43776/225000 (19%)] Loss: 14618.361328\n",
      "Train Epoch: 95 [45184/225000 (20%)] Loss: 14825.298828\n",
      "Train Epoch: 95 [46592/225000 (21%)] Loss: 14915.793945\n",
      "Train Epoch: 95 [48000/225000 (21%)] Loss: 14955.433594\n",
      "Train Epoch: 95 [49408/225000 (22%)] Loss: 15615.378906\n",
      "Train Epoch: 95 [50816/225000 (23%)] Loss: 14693.788086\n",
      "Train Epoch: 95 [52224/225000 (23%)] Loss: 15189.769531\n",
      "Train Epoch: 95 [53632/225000 (24%)] Loss: 14916.767578\n",
      "Train Epoch: 95 [55040/225000 (24%)] Loss: 15166.246094\n",
      "Train Epoch: 95 [56448/225000 (25%)] Loss: 14831.063477\n",
      "Train Epoch: 95 [57856/225000 (26%)] Loss: 14730.150391\n",
      "Train Epoch: 95 [59264/225000 (26%)] Loss: 14750.066406\n",
      "Train Epoch: 95 [60672/225000 (27%)] Loss: 14954.972656\n",
      "Train Epoch: 95 [62080/225000 (28%)] Loss: 14789.052734\n",
      "Train Epoch: 95 [63488/225000 (28%)] Loss: 14938.299805\n",
      "Train Epoch: 95 [64896/225000 (29%)] Loss: 15085.090820\n",
      "Train Epoch: 95 [66304/225000 (29%)] Loss: 14988.848633\n",
      "Train Epoch: 95 [67712/225000 (30%)] Loss: 14893.090820\n",
      "Train Epoch: 95 [69120/225000 (31%)] Loss: 15141.333984\n",
      "Train Epoch: 95 [70528/225000 (31%)] Loss: 15160.985352\n",
      "Train Epoch: 95 [71936/225000 (32%)] Loss: 15500.365234\n",
      "Train Epoch: 95 [73344/225000 (33%)] Loss: 14883.797852\n",
      "Train Epoch: 95 [74752/225000 (33%)] Loss: 14814.000977\n",
      "Train Epoch: 95 [76160/225000 (34%)] Loss: 15309.480469\n",
      "Train Epoch: 95 [77568/225000 (34%)] Loss: 15211.737305\n",
      "Train Epoch: 95 [78976/225000 (35%)] Loss: 15160.211914\n",
      "Train Epoch: 95 [80384/225000 (36%)] Loss: 14421.229492\n",
      "Train Epoch: 95 [81792/225000 (36%)] Loss: 14767.432617\n",
      "Train Epoch: 95 [83200/225000 (37%)] Loss: 14888.228516\n",
      "Train Epoch: 95 [84608/225000 (38%)] Loss: 15090.080078\n",
      "Train Epoch: 95 [86016/225000 (38%)] Loss: 14913.326172\n",
      "Train Epoch: 95 [87424/225000 (39%)] Loss: 15128.654297\n",
      "Train Epoch: 95 [88832/225000 (39%)] Loss: 14808.393555\n",
      "Train Epoch: 95 [90240/225000 (40%)] Loss: 15163.631836\n",
      "Train Epoch: 95 [91648/225000 (41%)] Loss: 15058.105469\n",
      "Train Epoch: 95 [93056/225000 (41%)] Loss: 15438.076172\n",
      "Train Epoch: 95 [94464/225000 (42%)] Loss: 15405.444336\n",
      "Train Epoch: 95 [95872/225000 (43%)] Loss: 15283.222656\n",
      "Train Epoch: 95 [97280/225000 (43%)] Loss: 15031.011719\n",
      "Train Epoch: 95 [98688/225000 (44%)] Loss: 15327.035156\n",
      "Train Epoch: 95 [100096/225000 (44%)] Loss: 15167.147461\n",
      "Train Epoch: 95 [101504/225000 (45%)] Loss: 15094.658203\n",
      "Train Epoch: 95 [102912/225000 (46%)] Loss: 15045.943359\n",
      "Train Epoch: 95 [104320/225000 (46%)] Loss: 14884.371094\n",
      "Train Epoch: 95 [105728/225000 (47%)] Loss: 15194.531250\n",
      "Train Epoch: 95 [107136/225000 (48%)] Loss: 15032.212891\n",
      "Train Epoch: 95 [108544/225000 (48%)] Loss: 15141.907227\n",
      "Train Epoch: 95 [109952/225000 (49%)] Loss: 14918.442383\n",
      "Train Epoch: 95 [111360/225000 (49%)] Loss: 15641.840820\n",
      "Train Epoch: 95 [112768/225000 (50%)] Loss: 14638.498047\n",
      "Train Epoch: 95 [114176/225000 (51%)] Loss: 15296.433594\n",
      "Train Epoch: 95 [115584/225000 (51%)] Loss: 14746.252930\n",
      "Train Epoch: 95 [116992/225000 (52%)] Loss: 14749.591797\n",
      "Train Epoch: 95 [118400/225000 (53%)] Loss: 15589.317383\n",
      "Train Epoch: 95 [119808/225000 (53%)] Loss: 15284.713867\n",
      "Train Epoch: 95 [121216/225000 (54%)] Loss: 15571.660156\n",
      "Train Epoch: 95 [122624/225000 (54%)] Loss: 14956.406250\n",
      "Train Epoch: 95 [124032/225000 (55%)] Loss: 14830.281250\n",
      "Train Epoch: 95 [125440/225000 (56%)] Loss: 15092.946289\n",
      "Train Epoch: 95 [126848/225000 (56%)] Loss: 15112.713867\n",
      "Train Epoch: 95 [128256/225000 (57%)] Loss: 15062.352539\n",
      "Train Epoch: 95 [129664/225000 (58%)] Loss: 15116.463867\n",
      "Train Epoch: 95 [131072/225000 (58%)] Loss: 15346.247070\n",
      "Train Epoch: 95 [132480/225000 (59%)] Loss: 14989.022461\n",
      "Train Epoch: 95 [133888/225000 (60%)] Loss: 14591.486328\n",
      "Train Epoch: 95 [135296/225000 (60%)] Loss: 15083.510742\n",
      "Train Epoch: 95 [136704/225000 (61%)] Loss: 15192.673828\n",
      "Train Epoch: 95 [138112/225000 (61%)] Loss: 14900.500977\n",
      "Train Epoch: 95 [139520/225000 (62%)] Loss: 15216.181641\n",
      "Train Epoch: 95 [140928/225000 (63%)] Loss: 14796.318359\n",
      "Train Epoch: 95 [142336/225000 (63%)] Loss: 15068.551758\n",
      "Train Epoch: 95 [143744/225000 (64%)] Loss: 15035.230469\n",
      "Train Epoch: 95 [145152/225000 (65%)] Loss: 15045.497070\n",
      "Train Epoch: 95 [146560/225000 (65%)] Loss: 15384.699219\n",
      "Train Epoch: 95 [147968/225000 (66%)] Loss: 15114.557617\n",
      "Train Epoch: 95 [149376/225000 (66%)] Loss: 14758.357422\n",
      "Train Epoch: 95 [150784/225000 (67%)] Loss: 14938.052734\n",
      "Train Epoch: 95 [152192/225000 (68%)] Loss: 15148.118164\n",
      "Train Epoch: 95 [153600/225000 (68%)] Loss: 14942.710938\n",
      "Train Epoch: 95 [155008/225000 (69%)] Loss: 14982.253906\n",
      "Train Epoch: 95 [156416/225000 (70%)] Loss: 14940.147461\n",
      "Train Epoch: 95 [157824/225000 (70%)] Loss: 14979.215820\n",
      "Train Epoch: 95 [159232/225000 (71%)] Loss: 14912.372070\n",
      "Train Epoch: 95 [160640/225000 (71%)] Loss: 14936.172852\n",
      "Train Epoch: 95 [162048/225000 (72%)] Loss: 14718.441406\n",
      "Train Epoch: 95 [163456/225000 (73%)] Loss: 14900.951172\n",
      "Train Epoch: 95 [164864/225000 (73%)] Loss: 14747.067383\n",
      "Train Epoch: 95 [166272/225000 (74%)] Loss: 15449.448242\n",
      "Train Epoch: 95 [167680/225000 (75%)] Loss: 15045.508789\n",
      "Train Epoch: 95 [169088/225000 (75%)] Loss: 15611.385742\n",
      "Train Epoch: 95 [170496/225000 (76%)] Loss: 14992.494141\n",
      "Train Epoch: 95 [171904/225000 (76%)] Loss: 14883.975586\n",
      "Train Epoch: 95 [173312/225000 (77%)] Loss: 15498.363281\n",
      "Train Epoch: 95 [174720/225000 (78%)] Loss: 15000.063477\n",
      "Train Epoch: 95 [176128/225000 (78%)] Loss: 14831.850586\n",
      "Train Epoch: 95 [177536/225000 (79%)] Loss: 15101.379883\n",
      "Train Epoch: 95 [178944/225000 (80%)] Loss: 14941.646484\n",
      "Train Epoch: 95 [180352/225000 (80%)] Loss: 15036.506836\n",
      "Train Epoch: 95 [181760/225000 (81%)] Loss: 14526.165039\n",
      "Train Epoch: 95 [183168/225000 (81%)] Loss: 15233.798828\n",
      "Train Epoch: 95 [184576/225000 (82%)] Loss: 15112.496094\n",
      "Train Epoch: 95 [185984/225000 (83%)] Loss: 15031.001953\n",
      "Train Epoch: 95 [187392/225000 (83%)] Loss: 15359.954102\n",
      "Train Epoch: 95 [188800/225000 (84%)] Loss: 15487.060547\n",
      "Train Epoch: 95 [190208/225000 (85%)] Loss: 14937.962891\n",
      "Train Epoch: 95 [191616/225000 (85%)] Loss: 14493.598633\n",
      "Train Epoch: 95 [193024/225000 (86%)] Loss: 15193.316406\n",
      "Train Epoch: 95 [194432/225000 (86%)] Loss: 14947.791992\n",
      "Train Epoch: 95 [195840/225000 (87%)] Loss: 15127.856445\n",
      "Train Epoch: 95 [197248/225000 (88%)] Loss: 15291.331055\n",
      "Train Epoch: 95 [198656/225000 (88%)] Loss: 14646.708008\n",
      "Train Epoch: 95 [200064/225000 (89%)] Loss: 15107.583984\n",
      "Train Epoch: 95 [201472/225000 (90%)] Loss: 15348.229492\n",
      "Train Epoch: 95 [202880/225000 (90%)] Loss: 15209.435547\n",
      "Train Epoch: 95 [204288/225000 (91%)] Loss: 14848.430664\n",
      "Train Epoch: 95 [205696/225000 (91%)] Loss: 14932.425781\n",
      "Train Epoch: 95 [207104/225000 (92%)] Loss: 15264.716797\n",
      "Train Epoch: 95 [208512/225000 (93%)] Loss: 15285.289062\n",
      "Train Epoch: 95 [209920/225000 (93%)] Loss: 14859.826172\n",
      "Train Epoch: 95 [211328/225000 (94%)] Loss: 15309.510742\n",
      "Train Epoch: 95 [212736/225000 (95%)] Loss: 15078.877930\n",
      "Train Epoch: 95 [214144/225000 (95%)] Loss: 14859.680664\n",
      "Train Epoch: 95 [215552/225000 (96%)] Loss: 15034.513672\n",
      "Train Epoch: 95 [216960/225000 (96%)] Loss: 14587.979492\n",
      "Train Epoch: 95 [218368/225000 (97%)] Loss: 14894.477539\n",
      "Train Epoch: 95 [219776/225000 (98%)] Loss: 14928.581055\n",
      "Train Epoch: 95 [221184/225000 (98%)] Loss: 15178.424805\n",
      "Train Epoch: 95 [222592/225000 (99%)] Loss: 15194.438477\n",
      "Train Epoch: 95 [224000/225000 (100%)] Loss: 15418.235352\n",
      "    epoch          : 95\n",
      "    loss           : 15075.197096754124\n",
      "    val_loss       : 15055.542052235834\n",
      "Train Epoch: 96 [128/225000 (0%)] Loss: 14950.945312\n",
      "Train Epoch: 96 [1536/225000 (1%)] Loss: 14892.508789\n",
      "Train Epoch: 96 [2944/225000 (1%)] Loss: 15097.281250\n",
      "Train Epoch: 96 [4352/225000 (2%)] Loss: 15101.829102\n",
      "Train Epoch: 96 [5760/225000 (3%)] Loss: 15108.681641\n",
      "Train Epoch: 96 [7168/225000 (3%)] Loss: 15103.873047\n",
      "Train Epoch: 96 [8576/225000 (4%)] Loss: 15624.199219\n",
      "Train Epoch: 96 [9984/225000 (4%)] Loss: 15077.813477\n",
      "Train Epoch: 96 [11392/225000 (5%)] Loss: 15601.403320\n",
      "Train Epoch: 96 [12800/225000 (6%)] Loss: 15025.195312\n",
      "Train Epoch: 96 [14208/225000 (6%)] Loss: 15110.318359\n",
      "Train Epoch: 96 [15616/225000 (7%)] Loss: 14946.642578\n",
      "Train Epoch: 96 [17024/225000 (8%)] Loss: 14629.864258\n",
      "Train Epoch: 96 [18432/225000 (8%)] Loss: 15289.058594\n",
      "Train Epoch: 96 [19840/225000 (9%)] Loss: 14866.741211\n",
      "Train Epoch: 96 [21248/225000 (9%)] Loss: 15190.517578\n",
      "Train Epoch: 96 [22656/225000 (10%)] Loss: 15339.016602\n",
      "Train Epoch: 96 [24064/225000 (11%)] Loss: 14719.656250\n",
      "Train Epoch: 96 [25472/225000 (11%)] Loss: 15035.923828\n",
      "Train Epoch: 96 [26880/225000 (12%)] Loss: 14976.802734\n",
      "Train Epoch: 96 [28288/225000 (13%)] Loss: 14786.777344\n",
      "Train Epoch: 96 [29696/225000 (13%)] Loss: 14696.888672\n",
      "Train Epoch: 96 [31104/225000 (14%)] Loss: 15004.732422\n",
      "Train Epoch: 96 [32512/225000 (14%)] Loss: 15032.359375\n",
      "Train Epoch: 96 [33920/225000 (15%)] Loss: 14701.811523\n",
      "Train Epoch: 96 [35328/225000 (16%)] Loss: 15202.952148\n",
      "Train Epoch: 96 [36736/225000 (16%)] Loss: 15801.546875\n",
      "Train Epoch: 96 [38144/225000 (17%)] Loss: 15389.515625\n",
      "Train Epoch: 96 [39552/225000 (18%)] Loss: 14784.672852\n",
      "Train Epoch: 96 [40960/225000 (18%)] Loss: 15312.728516\n",
      "Train Epoch: 96 [42368/225000 (19%)] Loss: 15477.392578\n",
      "Train Epoch: 96 [43776/225000 (19%)] Loss: 14667.740234\n",
      "Train Epoch: 96 [45184/225000 (20%)] Loss: 15230.834961\n",
      "Train Epoch: 96 [46592/225000 (21%)] Loss: 15197.557617\n",
      "Train Epoch: 96 [48000/225000 (21%)] Loss: 15398.511719\n",
      "Train Epoch: 96 [49408/225000 (22%)] Loss: 15300.105469\n",
      "Train Epoch: 96 [50816/225000 (23%)] Loss: 14993.807617\n",
      "Train Epoch: 96 [52224/225000 (23%)] Loss: 14791.123047\n",
      "Train Epoch: 96 [53632/225000 (24%)] Loss: 15437.790039\n",
      "Train Epoch: 96 [55040/225000 (24%)] Loss: 15354.500000\n",
      "Train Epoch: 96 [56448/225000 (25%)] Loss: 14659.566406\n",
      "Train Epoch: 96 [57856/225000 (26%)] Loss: 15017.208984\n",
      "Train Epoch: 96 [59264/225000 (26%)] Loss: 15420.245117\n",
      "Train Epoch: 96 [60672/225000 (27%)] Loss: 14970.038086\n",
      "Train Epoch: 96 [62080/225000 (28%)] Loss: 15397.392578\n",
      "Train Epoch: 96 [63488/225000 (28%)] Loss: 15432.658203\n",
      "Train Epoch: 96 [64896/225000 (29%)] Loss: 15515.684570\n",
      "Train Epoch: 96 [66304/225000 (29%)] Loss: 14501.098633\n",
      "Train Epoch: 96 [67712/225000 (30%)] Loss: 15448.186523\n",
      "Train Epoch: 96 [69120/225000 (31%)] Loss: 15116.191406\n",
      "Train Epoch: 96 [70528/225000 (31%)] Loss: 15042.778320\n",
      "Train Epoch: 96 [71936/225000 (32%)] Loss: 14658.417969\n",
      "Train Epoch: 96 [73344/225000 (33%)] Loss: 15667.222656\n",
      "Train Epoch: 96 [74752/225000 (33%)] Loss: 15425.327148\n",
      "Train Epoch: 96 [76160/225000 (34%)] Loss: 15109.330078\n",
      "Train Epoch: 96 [77568/225000 (34%)] Loss: 14943.415039\n",
      "Train Epoch: 96 [78976/225000 (35%)] Loss: 14869.760742\n",
      "Train Epoch: 96 [80384/225000 (36%)] Loss: 15396.979492\n",
      "Train Epoch: 96 [81792/225000 (36%)] Loss: 15465.613281\n",
      "Train Epoch: 96 [83200/225000 (37%)] Loss: 15058.770508\n",
      "Train Epoch: 96 [84608/225000 (38%)] Loss: 15019.256836\n",
      "Train Epoch: 96 [86016/225000 (38%)] Loss: 15027.839844\n",
      "Train Epoch: 96 [87424/225000 (39%)] Loss: 15579.465820\n",
      "Train Epoch: 96 [88832/225000 (39%)] Loss: 15291.508789\n",
      "Train Epoch: 96 [90240/225000 (40%)] Loss: 14588.322266\n",
      "Train Epoch: 96 [91648/225000 (41%)] Loss: 15310.295898\n",
      "Train Epoch: 96 [93056/225000 (41%)] Loss: 15210.340820\n",
      "Train Epoch: 96 [94464/225000 (42%)] Loss: 14992.783203\n",
      "Train Epoch: 96 [95872/225000 (43%)] Loss: 15445.958984\n",
      "Train Epoch: 96 [97280/225000 (43%)] Loss: 15078.646484\n",
      "Train Epoch: 96 [98688/225000 (44%)] Loss: 14744.581055\n",
      "Train Epoch: 96 [100096/225000 (44%)] Loss: 15059.045898\n",
      "Train Epoch: 96 [101504/225000 (45%)] Loss: 15536.592773\n",
      "Train Epoch: 96 [102912/225000 (46%)] Loss: 15603.046875\n",
      "Train Epoch: 96 [104320/225000 (46%)] Loss: 15331.507812\n",
      "Train Epoch: 96 [105728/225000 (47%)] Loss: 14893.222656\n",
      "Train Epoch: 96 [107136/225000 (48%)] Loss: 14956.545898\n",
      "Train Epoch: 96 [108544/225000 (48%)] Loss: 15029.611328\n",
      "Train Epoch: 96 [109952/225000 (49%)] Loss: 15178.511719\n",
      "Train Epoch: 96 [111360/225000 (49%)] Loss: 14998.821289\n",
      "Train Epoch: 96 [112768/225000 (50%)] Loss: 15219.441406\n",
      "Train Epoch: 96 [114176/225000 (51%)] Loss: 14906.926758\n",
      "Train Epoch: 96 [115584/225000 (51%)] Loss: 14784.897461\n",
      "Train Epoch: 96 [116992/225000 (52%)] Loss: 15297.556641\n",
      "Train Epoch: 96 [118400/225000 (53%)] Loss: 14656.890625\n",
      "Train Epoch: 96 [119808/225000 (53%)] Loss: 14972.998047\n",
      "Train Epoch: 96 [121216/225000 (54%)] Loss: 15270.523438\n",
      "Train Epoch: 96 [122624/225000 (54%)] Loss: 14734.147461\n",
      "Train Epoch: 96 [124032/225000 (55%)] Loss: 14691.970703\n",
      "Train Epoch: 96 [125440/225000 (56%)] Loss: 14802.392578\n",
      "Train Epoch: 96 [126848/225000 (56%)] Loss: 15210.881836\n",
      "Train Epoch: 96 [128256/225000 (57%)] Loss: 15262.588867\n",
      "Train Epoch: 96 [129664/225000 (58%)] Loss: 15324.427734\n",
      "Train Epoch: 96 [131072/225000 (58%)] Loss: 14855.054688\n",
      "Train Epoch: 96 [132480/225000 (59%)] Loss: 15009.718750\n",
      "Train Epoch: 96 [133888/225000 (60%)] Loss: 15330.346680\n",
      "Train Epoch: 96 [135296/225000 (60%)] Loss: 15031.708984\n",
      "Train Epoch: 96 [136704/225000 (61%)] Loss: 15370.440430\n",
      "Train Epoch: 96 [138112/225000 (61%)] Loss: 14960.807617\n",
      "Train Epoch: 96 [139520/225000 (62%)] Loss: 15303.571289\n",
      "Train Epoch: 96 [140928/225000 (63%)] Loss: 15746.706055\n",
      "Train Epoch: 96 [142336/225000 (63%)] Loss: 15095.571289\n",
      "Train Epoch: 96 [143744/225000 (64%)] Loss: 14907.210938\n",
      "Train Epoch: 96 [145152/225000 (65%)] Loss: 14657.527344\n",
      "Train Epoch: 96 [146560/225000 (65%)] Loss: 15218.091797\n",
      "Train Epoch: 96 [147968/225000 (66%)] Loss: 15106.260742\n",
      "Train Epoch: 96 [149376/225000 (66%)] Loss: 14941.302734\n",
      "Train Epoch: 96 [150784/225000 (67%)] Loss: 15156.873047\n",
      "Train Epoch: 96 [152192/225000 (68%)] Loss: 15272.239258\n",
      "Train Epoch: 96 [153600/225000 (68%)] Loss: 15801.611328\n",
      "Train Epoch: 96 [155008/225000 (69%)] Loss: 15393.717773\n",
      "Train Epoch: 96 [156416/225000 (70%)] Loss: 15015.160156\n",
      "Train Epoch: 96 [157824/225000 (70%)] Loss: 15135.472656\n",
      "Train Epoch: 96 [159232/225000 (71%)] Loss: 15018.432617\n",
      "Train Epoch: 96 [160640/225000 (71%)] Loss: 15358.219727\n",
      "Train Epoch: 96 [162048/225000 (72%)] Loss: 15064.172852\n",
      "Train Epoch: 96 [163456/225000 (73%)] Loss: 15318.822266\n",
      "Train Epoch: 96 [164864/225000 (73%)] Loss: 15459.828125\n",
      "Train Epoch: 96 [166272/225000 (74%)] Loss: 14880.323242\n",
      "Train Epoch: 96 [167680/225000 (75%)] Loss: 15230.297852\n",
      "Train Epoch: 96 [169088/225000 (75%)] Loss: 15038.340820\n",
      "Train Epoch: 96 [170496/225000 (76%)] Loss: 15333.636719\n",
      "Train Epoch: 96 [171904/225000 (76%)] Loss: 14955.869141\n",
      "Train Epoch: 96 [173312/225000 (77%)] Loss: 14696.542969\n",
      "Train Epoch: 96 [174720/225000 (78%)] Loss: 15505.916992\n",
      "Train Epoch: 96 [176128/225000 (78%)] Loss: 14860.883789\n",
      "Train Epoch: 96 [177536/225000 (79%)] Loss: 15048.199219\n",
      "Train Epoch: 96 [178944/225000 (80%)] Loss: 14797.341797\n",
      "Train Epoch: 96 [180352/225000 (80%)] Loss: 15258.416016\n",
      "Train Epoch: 96 [181760/225000 (81%)] Loss: 14894.340820\n",
      "Train Epoch: 96 [183168/225000 (81%)] Loss: 14788.441406\n",
      "Train Epoch: 96 [184576/225000 (82%)] Loss: 15076.808594\n",
      "Train Epoch: 96 [185984/225000 (83%)] Loss: 14527.090820\n",
      "Train Epoch: 96 [187392/225000 (83%)] Loss: 15381.369141\n",
      "Train Epoch: 96 [188800/225000 (84%)] Loss: 15369.849609\n",
      "Train Epoch: 96 [190208/225000 (85%)] Loss: 15005.544922\n",
      "Train Epoch: 96 [191616/225000 (85%)] Loss: 14757.390625\n",
      "Train Epoch: 96 [193024/225000 (86%)] Loss: 15095.088867\n",
      "Train Epoch: 96 [194432/225000 (86%)] Loss: 15188.790039\n",
      "Train Epoch: 96 [195840/225000 (87%)] Loss: 14782.019531\n",
      "Train Epoch: 96 [197248/225000 (88%)] Loss: 14636.817383\n",
      "Train Epoch: 96 [198656/225000 (88%)] Loss: 15103.576172\n",
      "Train Epoch: 96 [200064/225000 (89%)] Loss: 15307.589844\n",
      "Train Epoch: 96 [201472/225000 (90%)] Loss: 14338.750977\n",
      "Train Epoch: 96 [202880/225000 (90%)] Loss: 14757.403320\n",
      "Train Epoch: 96 [204288/225000 (91%)] Loss: 15446.852539\n",
      "Train Epoch: 96 [205696/225000 (91%)] Loss: 15218.999023\n",
      "Train Epoch: 96 [207104/225000 (92%)] Loss: 14815.708008\n",
      "Train Epoch: 96 [208512/225000 (93%)] Loss: 15651.628906\n",
      "Train Epoch: 96 [209920/225000 (93%)] Loss: 15216.528320\n",
      "Train Epoch: 96 [211328/225000 (94%)] Loss: 14856.248047\n",
      "Train Epoch: 96 [212736/225000 (95%)] Loss: 14975.814453\n",
      "Train Epoch: 96 [214144/225000 (95%)] Loss: 14849.972656\n",
      "Train Epoch: 96 [215552/225000 (96%)] Loss: 15196.941406\n",
      "Train Epoch: 96 [216960/225000 (96%)] Loss: 15367.942383\n",
      "Train Epoch: 96 [218368/225000 (97%)] Loss: 15107.211914\n",
      "Train Epoch: 96 [219776/225000 (98%)] Loss: 15194.327148\n",
      "Train Epoch: 96 [221184/225000 (98%)] Loss: 14931.143555\n",
      "Train Epoch: 96 [222592/225000 (99%)] Loss: 15546.303711\n",
      "Train Epoch: 96 [224000/225000 (100%)] Loss: 15076.877930\n",
      "    epoch          : 96\n",
      "    loss           : 15073.354861037045\n",
      "    val_loss       : 15060.35053003625\n",
      "Train Epoch: 97 [128/225000 (0%)] Loss: 14892.797852\n",
      "Train Epoch: 97 [1536/225000 (1%)] Loss: 15149.011719\n",
      "Train Epoch: 97 [2944/225000 (1%)] Loss: 15580.944336\n",
      "Train Epoch: 97 [4352/225000 (2%)] Loss: 15347.007812\n",
      "Train Epoch: 97 [5760/225000 (3%)] Loss: 15134.946289\n",
      "Train Epoch: 97 [7168/225000 (3%)] Loss: 14865.996094\n",
      "Train Epoch: 97 [8576/225000 (4%)] Loss: 15066.159180\n",
      "Train Epoch: 97 [9984/225000 (4%)] Loss: 14903.857422\n",
      "Train Epoch: 97 [11392/225000 (5%)] Loss: 14923.681641\n",
      "Train Epoch: 97 [12800/225000 (6%)] Loss: 14666.996094\n",
      "Train Epoch: 97 [14208/225000 (6%)] Loss: 15019.039062\n",
      "Train Epoch: 97 [15616/225000 (7%)] Loss: 15328.080078\n",
      "Train Epoch: 97 [17024/225000 (8%)] Loss: 14968.982422\n",
      "Train Epoch: 97 [18432/225000 (8%)] Loss: 15128.826172\n",
      "Train Epoch: 97 [19840/225000 (9%)] Loss: 14983.600586\n",
      "Train Epoch: 97 [21248/225000 (9%)] Loss: 15044.172852\n",
      "Train Epoch: 97 [22656/225000 (10%)] Loss: 15248.286133\n",
      "Train Epoch: 97 [24064/225000 (11%)] Loss: 15091.258789\n",
      "Train Epoch: 97 [25472/225000 (11%)] Loss: 15167.396484\n",
      "Train Epoch: 97 [26880/225000 (12%)] Loss: 15285.663086\n",
      "Train Epoch: 97 [28288/225000 (13%)] Loss: 15346.574219\n",
      "Train Epoch: 97 [29696/225000 (13%)] Loss: 15275.170898\n",
      "Train Epoch: 97 [31104/225000 (14%)] Loss: 15057.151367\n",
      "Train Epoch: 97 [32512/225000 (14%)] Loss: 15096.352539\n",
      "Train Epoch: 97 [33920/225000 (15%)] Loss: 14947.318359\n",
      "Train Epoch: 97 [35328/225000 (16%)] Loss: 14901.765625\n",
      "Train Epoch: 97 [36736/225000 (16%)] Loss: 14916.619141\n",
      "Train Epoch: 97 [38144/225000 (17%)] Loss: 15402.624023\n",
      "Train Epoch: 97 [39552/225000 (18%)] Loss: 15265.736328\n",
      "Train Epoch: 97 [40960/225000 (18%)] Loss: 15471.539062\n",
      "Train Epoch: 97 [42368/225000 (19%)] Loss: 14913.716797\n",
      "Train Epoch: 97 [43776/225000 (19%)] Loss: 14993.369141\n",
      "Train Epoch: 97 [45184/225000 (20%)] Loss: 14855.292969\n",
      "Train Epoch: 97 [46592/225000 (21%)] Loss: 15128.618164\n",
      "Train Epoch: 97 [48000/225000 (21%)] Loss: 15558.886719\n",
      "Train Epoch: 97 [49408/225000 (22%)] Loss: 15061.165039\n",
      "Train Epoch: 97 [50816/225000 (23%)] Loss: 15333.862305\n",
      "Train Epoch: 97 [52224/225000 (23%)] Loss: 15098.724609\n",
      "Train Epoch: 97 [53632/225000 (24%)] Loss: 14940.983398\n",
      "Train Epoch: 97 [55040/225000 (24%)] Loss: 15115.434570\n",
      "Train Epoch: 97 [56448/225000 (25%)] Loss: 14993.312500\n",
      "Train Epoch: 97 [57856/225000 (26%)] Loss: 14728.752930\n",
      "Train Epoch: 97 [59264/225000 (26%)] Loss: 14894.138672\n",
      "Train Epoch: 97 [60672/225000 (27%)] Loss: 14559.249023\n",
      "Train Epoch: 97 [62080/225000 (28%)] Loss: 15049.198242\n",
      "Train Epoch: 97 [63488/225000 (28%)] Loss: 15380.486328\n",
      "Train Epoch: 97 [64896/225000 (29%)] Loss: 14779.056641\n",
      "Train Epoch: 97 [66304/225000 (29%)] Loss: 14935.686523\n",
      "Train Epoch: 97 [67712/225000 (30%)] Loss: 14755.183594\n",
      "Train Epoch: 97 [69120/225000 (31%)] Loss: 15094.416992\n",
      "Train Epoch: 97 [70528/225000 (31%)] Loss: 15010.269531\n",
      "Train Epoch: 97 [71936/225000 (32%)] Loss: 15120.237305\n",
      "Train Epoch: 97 [73344/225000 (33%)] Loss: 15045.136719\n",
      "Train Epoch: 97 [74752/225000 (33%)] Loss: 15010.387695\n",
      "Train Epoch: 97 [76160/225000 (34%)] Loss: 15064.611328\n",
      "Train Epoch: 97 [77568/225000 (34%)] Loss: 15124.525391\n",
      "Train Epoch: 97 [78976/225000 (35%)] Loss: 15733.097656\n",
      "Train Epoch: 97 [80384/225000 (36%)] Loss: 14788.721680\n",
      "Train Epoch: 97 [81792/225000 (36%)] Loss: 15295.228516\n",
      "Train Epoch: 97 [83200/225000 (37%)] Loss: 14710.599609\n",
      "Train Epoch: 97 [84608/225000 (38%)] Loss: 15070.028320\n",
      "Train Epoch: 97 [86016/225000 (38%)] Loss: 15274.339844\n",
      "Train Epoch: 97 [87424/225000 (39%)] Loss: 14514.632812\n",
      "Train Epoch: 97 [88832/225000 (39%)] Loss: 14906.178711\n",
      "Train Epoch: 97 [90240/225000 (40%)] Loss: 14863.784180\n",
      "Train Epoch: 97 [91648/225000 (41%)] Loss: 14993.489258\n",
      "Train Epoch: 97 [93056/225000 (41%)] Loss: 14980.541992\n",
      "Train Epoch: 97 [94464/225000 (42%)] Loss: 15009.281250\n",
      "Train Epoch: 97 [95872/225000 (43%)] Loss: 15049.134766\n",
      "Train Epoch: 97 [97280/225000 (43%)] Loss: 14865.162109\n",
      "Train Epoch: 97 [98688/225000 (44%)] Loss: 14616.141602\n",
      "Train Epoch: 97 [100096/225000 (44%)] Loss: 14912.005859\n",
      "Train Epoch: 97 [101504/225000 (45%)] Loss: 15099.913086\n",
      "Train Epoch: 97 [102912/225000 (46%)] Loss: 15307.880859\n",
      "Train Epoch: 97 [104320/225000 (46%)] Loss: 15237.149414\n",
      "Train Epoch: 97 [105728/225000 (47%)] Loss: 15190.275391\n",
      "Train Epoch: 97 [107136/225000 (48%)] Loss: 15125.172852\n",
      "Train Epoch: 97 [108544/225000 (48%)] Loss: 14809.003906\n",
      "Train Epoch: 97 [109952/225000 (49%)] Loss: 14899.439453\n",
      "Train Epoch: 97 [111360/225000 (49%)] Loss: 15635.207031\n",
      "Train Epoch: 97 [112768/225000 (50%)] Loss: 15200.508789\n",
      "Train Epoch: 97 [114176/225000 (51%)] Loss: 15220.568359\n",
      "Train Epoch: 97 [115584/225000 (51%)] Loss: 15242.184570\n",
      "Train Epoch: 97 [116992/225000 (52%)] Loss: 15797.094727\n",
      "Train Epoch: 97 [118400/225000 (53%)] Loss: 14841.444336\n",
      "Train Epoch: 97 [119808/225000 (53%)] Loss: 15252.509766\n",
      "Train Epoch: 97 [121216/225000 (54%)] Loss: 14852.014648\n",
      "Train Epoch: 97 [122624/225000 (54%)] Loss: 15253.706055\n",
      "Train Epoch: 97 [124032/225000 (55%)] Loss: 15218.653320\n",
      "Train Epoch: 97 [125440/225000 (56%)] Loss: 14634.912109\n",
      "Train Epoch: 97 [126848/225000 (56%)] Loss: 15649.380859\n",
      "Train Epoch: 97 [128256/225000 (57%)] Loss: 15263.920898\n",
      "Train Epoch: 97 [129664/225000 (58%)] Loss: 15205.741211\n",
      "Train Epoch: 97 [131072/225000 (58%)] Loss: 14650.439453\n",
      "Train Epoch: 97 [132480/225000 (59%)] Loss: 15032.086914\n",
      "Train Epoch: 97 [133888/225000 (60%)] Loss: 14469.277344\n",
      "Train Epoch: 97 [135296/225000 (60%)] Loss: 14994.587891\n",
      "Train Epoch: 97 [136704/225000 (61%)] Loss: 14969.597656\n",
      "Train Epoch: 97 [138112/225000 (61%)] Loss: 15120.576172\n",
      "Train Epoch: 97 [139520/225000 (62%)] Loss: 15540.217773\n",
      "Train Epoch: 97 [140928/225000 (63%)] Loss: 15789.818359\n",
      "Train Epoch: 97 [142336/225000 (63%)] Loss: 14979.201172\n",
      "Train Epoch: 97 [143744/225000 (64%)] Loss: 15272.827148\n",
      "Train Epoch: 97 [145152/225000 (65%)] Loss: 15027.498047\n",
      "Train Epoch: 97 [146560/225000 (65%)] Loss: 15127.328125\n",
      "Train Epoch: 97 [147968/225000 (66%)] Loss: 14642.769531\n",
      "Train Epoch: 97 [149376/225000 (66%)] Loss: 15012.850586\n",
      "Train Epoch: 97 [150784/225000 (67%)] Loss: 15138.998047\n",
      "Train Epoch: 97 [152192/225000 (68%)] Loss: 15177.190430\n",
      "Train Epoch: 97 [153600/225000 (68%)] Loss: 15404.621094\n",
      "Train Epoch: 97 [155008/225000 (69%)] Loss: 14909.947266\n",
      "Train Epoch: 97 [156416/225000 (70%)] Loss: 14856.885742\n",
      "Train Epoch: 97 [157824/225000 (70%)] Loss: 14791.628906\n",
      "Train Epoch: 97 [159232/225000 (71%)] Loss: 15408.343750\n",
      "Train Epoch: 97 [160640/225000 (71%)] Loss: 14666.256836\n",
      "Train Epoch: 97 [162048/225000 (72%)] Loss: 15049.709961\n",
      "Train Epoch: 97 [163456/225000 (73%)] Loss: 15123.406250\n",
      "Train Epoch: 97 [164864/225000 (73%)] Loss: 15563.698242\n",
      "Train Epoch: 97 [166272/225000 (74%)] Loss: 14680.293945\n",
      "Train Epoch: 97 [167680/225000 (75%)] Loss: 14928.903320\n",
      "Train Epoch: 97 [169088/225000 (75%)] Loss: 15202.367188\n",
      "Train Epoch: 97 [170496/225000 (76%)] Loss: 14727.421875\n",
      "Train Epoch: 97 [171904/225000 (76%)] Loss: 14898.072266\n",
      "Train Epoch: 97 [173312/225000 (77%)] Loss: 15226.840820\n",
      "Train Epoch: 97 [174720/225000 (78%)] Loss: 15254.160156\n",
      "Train Epoch: 97 [176128/225000 (78%)] Loss: 15095.699219\n",
      "Train Epoch: 97 [177536/225000 (79%)] Loss: 15017.246094\n",
      "Train Epoch: 97 [178944/225000 (80%)] Loss: 15204.116211\n",
      "Train Epoch: 97 [180352/225000 (80%)] Loss: 14817.968750\n",
      "Train Epoch: 97 [181760/225000 (81%)] Loss: 15019.697266\n",
      "Train Epoch: 97 [183168/225000 (81%)] Loss: 15543.589844\n",
      "Train Epoch: 97 [184576/225000 (82%)] Loss: 14762.598633\n",
      "Train Epoch: 97 [185984/225000 (83%)] Loss: 14947.771484\n",
      "Train Epoch: 97 [187392/225000 (83%)] Loss: 15077.575195\n",
      "Train Epoch: 97 [188800/225000 (84%)] Loss: 15223.998047\n",
      "Train Epoch: 97 [190208/225000 (85%)] Loss: 15062.772461\n",
      "Train Epoch: 97 [191616/225000 (85%)] Loss: 14702.985352\n",
      "Train Epoch: 97 [193024/225000 (86%)] Loss: 14902.603516\n",
      "Train Epoch: 97 [194432/225000 (86%)] Loss: 14942.497070\n",
      "Train Epoch: 97 [195840/225000 (87%)] Loss: 14720.228516\n",
      "Train Epoch: 97 [197248/225000 (88%)] Loss: 15042.534180\n",
      "Train Epoch: 97 [198656/225000 (88%)] Loss: 14663.849609\n",
      "Train Epoch: 97 [200064/225000 (89%)] Loss: 14790.776367\n",
      "Train Epoch: 97 [201472/225000 (90%)] Loss: 14653.233398\n",
      "Train Epoch: 97 [202880/225000 (90%)] Loss: 14849.631836\n",
      "Train Epoch: 97 [204288/225000 (91%)] Loss: 15394.905273\n",
      "Train Epoch: 97 [205696/225000 (91%)] Loss: 15016.372070\n",
      "Train Epoch: 97 [207104/225000 (92%)] Loss: 14770.009766\n",
      "Train Epoch: 97 [208512/225000 (93%)] Loss: 15392.441406\n",
      "Train Epoch: 97 [209920/225000 (93%)] Loss: 15633.887695\n",
      "Train Epoch: 97 [211328/225000 (94%)] Loss: 15212.007812\n",
      "Train Epoch: 97 [212736/225000 (95%)] Loss: 14903.137695\n",
      "Train Epoch: 97 [214144/225000 (95%)] Loss: 14872.189453\n",
      "Train Epoch: 97 [215552/225000 (96%)] Loss: 15307.363281\n",
      "Train Epoch: 97 [216960/225000 (96%)] Loss: 15148.122070\n",
      "Train Epoch: 97 [218368/225000 (97%)] Loss: 15073.258789\n",
      "Train Epoch: 97 [219776/225000 (98%)] Loss: 14778.140625\n",
      "Train Epoch: 97 [221184/225000 (98%)] Loss: 15613.667969\n",
      "Train Epoch: 97 [222592/225000 (99%)] Loss: 14883.316406\n",
      "Train Epoch: 97 [224000/225000 (100%)] Loss: 15131.767578\n",
      "    epoch          : 97\n",
      "    loss           : 15073.823773241966\n",
      "    val_loss       : 15056.303543778098\n",
      "Train Epoch: 98 [128/225000 (0%)] Loss: 14853.750977\n",
      "Train Epoch: 98 [1536/225000 (1%)] Loss: 15197.725586\n",
      "Train Epoch: 98 [2944/225000 (1%)] Loss: 15102.572266\n",
      "Train Epoch: 98 [4352/225000 (2%)] Loss: 14735.862305\n",
      "Train Epoch: 98 [5760/225000 (3%)] Loss: 15082.412109\n",
      "Train Epoch: 98 [7168/225000 (3%)] Loss: 15283.124023\n",
      "Train Epoch: 98 [8576/225000 (4%)] Loss: 15112.718750\n",
      "Train Epoch: 98 [9984/225000 (4%)] Loss: 15338.928711\n",
      "Train Epoch: 98 [11392/225000 (5%)] Loss: 15165.646484\n",
      "Train Epoch: 98 [12800/225000 (6%)] Loss: 14896.162109\n",
      "Train Epoch: 98 [14208/225000 (6%)] Loss: 15283.674805\n",
      "Train Epoch: 98 [15616/225000 (7%)] Loss: 15746.667969\n",
      "Train Epoch: 98 [17024/225000 (8%)] Loss: 15123.180664\n",
      "Train Epoch: 98 [18432/225000 (8%)] Loss: 14846.476562\n",
      "Train Epoch: 98 [19840/225000 (9%)] Loss: 15235.883789\n",
      "Train Epoch: 98 [21248/225000 (9%)] Loss: 15221.980469\n",
      "Train Epoch: 98 [22656/225000 (10%)] Loss: 15243.039062\n",
      "Train Epoch: 98 [24064/225000 (11%)] Loss: 15151.023438\n",
      "Train Epoch: 98 [25472/225000 (11%)] Loss: 15150.751953\n",
      "Train Epoch: 98 [26880/225000 (12%)] Loss: 15193.442383\n",
      "Train Epoch: 98 [28288/225000 (13%)] Loss: 14980.895508\n",
      "Train Epoch: 98 [29696/225000 (13%)] Loss: 14335.281250\n",
      "Train Epoch: 98 [31104/225000 (14%)] Loss: 15049.802734\n",
      "Train Epoch: 98 [32512/225000 (14%)] Loss: 14806.833008\n",
      "Train Epoch: 98 [33920/225000 (15%)] Loss: 15315.902344\n",
      "Train Epoch: 98 [35328/225000 (16%)] Loss: 15081.310547\n",
      "Train Epoch: 98 [36736/225000 (16%)] Loss: 14894.163086\n",
      "Train Epoch: 98 [38144/225000 (17%)] Loss: 15219.728516\n",
      "Train Epoch: 98 [39552/225000 (18%)] Loss: 15411.625977\n",
      "Train Epoch: 98 [40960/225000 (18%)] Loss: 14998.082031\n",
      "Train Epoch: 98 [42368/225000 (19%)] Loss: 15003.118164\n",
      "Train Epoch: 98 [43776/225000 (19%)] Loss: 15354.303711\n",
      "Train Epoch: 98 [45184/225000 (20%)] Loss: 15031.585938\n",
      "Train Epoch: 98 [46592/225000 (21%)] Loss: 15178.283203\n",
      "Train Epoch: 98 [48000/225000 (21%)] Loss: 14757.513672\n",
      "Train Epoch: 98 [49408/225000 (22%)] Loss: 15155.743164\n",
      "Train Epoch: 98 [50816/225000 (23%)] Loss: 14836.674805\n",
      "Train Epoch: 98 [52224/225000 (23%)] Loss: 15097.612305\n",
      "Train Epoch: 98 [53632/225000 (24%)] Loss: 14900.880859\n",
      "Train Epoch: 98 [55040/225000 (24%)] Loss: 14708.995117\n",
      "Train Epoch: 98 [56448/225000 (25%)] Loss: 15165.342773\n",
      "Train Epoch: 98 [57856/225000 (26%)] Loss: 15005.496094\n",
      "Train Epoch: 98 [59264/225000 (26%)] Loss: 15147.505859\n",
      "Train Epoch: 98 [60672/225000 (27%)] Loss: 15617.065430\n",
      "Train Epoch: 98 [62080/225000 (28%)] Loss: 14899.120117\n",
      "Train Epoch: 98 [63488/225000 (28%)] Loss: 15490.652344\n",
      "Train Epoch: 98 [64896/225000 (29%)] Loss: 15425.969727\n",
      "Train Epoch: 98 [66304/225000 (29%)] Loss: 14938.363281\n",
      "Train Epoch: 98 [67712/225000 (30%)] Loss: 14672.293945\n",
      "Train Epoch: 98 [69120/225000 (31%)] Loss: 15286.680664\n",
      "Train Epoch: 98 [70528/225000 (31%)] Loss: 14832.345703\n",
      "Train Epoch: 98 [71936/225000 (32%)] Loss: 15139.538086\n",
      "Train Epoch: 98 [73344/225000 (33%)] Loss: 15149.940430\n",
      "Train Epoch: 98 [74752/225000 (33%)] Loss: 15576.399414\n",
      "Train Epoch: 98 [76160/225000 (34%)] Loss: 15446.524414\n",
      "Train Epoch: 98 [77568/225000 (34%)] Loss: 14675.177734\n",
      "Train Epoch: 98 [78976/225000 (35%)] Loss: 14742.637695\n",
      "Train Epoch: 98 [80384/225000 (36%)] Loss: 15055.470703\n",
      "Train Epoch: 98 [81792/225000 (36%)] Loss: 15292.995117\n",
      "Train Epoch: 98 [83200/225000 (37%)] Loss: 15447.173828\n",
      "Train Epoch: 98 [84608/225000 (38%)] Loss: 15007.160156\n",
      "Train Epoch: 98 [86016/225000 (38%)] Loss: 15123.065430\n",
      "Train Epoch: 98 [87424/225000 (39%)] Loss: 15189.879883\n",
      "Train Epoch: 98 [88832/225000 (39%)] Loss: 15466.823242\n",
      "Train Epoch: 98 [90240/225000 (40%)] Loss: 15117.120117\n",
      "Train Epoch: 98 [91648/225000 (41%)] Loss: 14785.330078\n",
      "Train Epoch: 98 [93056/225000 (41%)] Loss: 14813.262695\n",
      "Train Epoch: 98 [94464/225000 (42%)] Loss: 14754.116211\n",
      "Train Epoch: 98 [95872/225000 (43%)] Loss: 15565.920898\n",
      "Train Epoch: 98 [97280/225000 (43%)] Loss: 15177.333008\n",
      "Train Epoch: 98 [98688/225000 (44%)] Loss: 14721.111328\n",
      "Train Epoch: 98 [100096/225000 (44%)] Loss: 14550.338867\n",
      "Train Epoch: 98 [101504/225000 (45%)] Loss: 15215.722656\n",
      "Train Epoch: 98 [102912/225000 (46%)] Loss: 15398.548828\n",
      "Train Epoch: 98 [104320/225000 (46%)] Loss: 14724.617188\n",
      "Train Epoch: 98 [105728/225000 (47%)] Loss: 15041.291016\n",
      "Train Epoch: 98 [107136/225000 (48%)] Loss: 14846.282227\n",
      "Train Epoch: 98 [108544/225000 (48%)] Loss: 14671.397461\n",
      "Train Epoch: 98 [109952/225000 (49%)] Loss: 14806.077148\n",
      "Train Epoch: 98 [111360/225000 (49%)] Loss: 15456.104492\n",
      "Train Epoch: 98 [112768/225000 (50%)] Loss: 15126.188477\n",
      "Train Epoch: 98 [114176/225000 (51%)] Loss: 14884.849609\n",
      "Train Epoch: 98 [115584/225000 (51%)] Loss: 14958.566406\n",
      "Train Epoch: 98 [116992/225000 (52%)] Loss: 14890.744141\n",
      "Train Epoch: 98 [118400/225000 (53%)] Loss: 15058.947266\n",
      "Train Epoch: 98 [119808/225000 (53%)] Loss: 15031.625977\n",
      "Train Epoch: 98 [121216/225000 (54%)] Loss: 14995.967773\n",
      "Train Epoch: 98 [122624/225000 (54%)] Loss: 15181.599609\n",
      "Train Epoch: 98 [124032/225000 (55%)] Loss: 14687.598633\n",
      "Train Epoch: 98 [125440/225000 (56%)] Loss: 14809.359375\n",
      "Train Epoch: 98 [126848/225000 (56%)] Loss: 15145.466797\n",
      "Train Epoch: 98 [128256/225000 (57%)] Loss: 15015.682617\n",
      "Train Epoch: 98 [129664/225000 (58%)] Loss: 15168.175781\n",
      "Train Epoch: 98 [131072/225000 (58%)] Loss: 14582.439453\n",
      "Train Epoch: 98 [132480/225000 (59%)] Loss: 14541.343750\n",
      "Train Epoch: 98 [133888/225000 (60%)] Loss: 15238.114258\n",
      "Train Epoch: 98 [135296/225000 (60%)] Loss: 14890.635742\n",
      "Train Epoch: 98 [136704/225000 (61%)] Loss: 15312.286133\n",
      "Train Epoch: 98 [138112/225000 (61%)] Loss: 14785.187500\n",
      "Train Epoch: 98 [139520/225000 (62%)] Loss: 15035.745117\n",
      "Train Epoch: 98 [140928/225000 (63%)] Loss: 14877.894531\n",
      "Train Epoch: 98 [142336/225000 (63%)] Loss: 14850.738281\n",
      "Train Epoch: 98 [143744/225000 (64%)] Loss: 14839.861328\n",
      "Train Epoch: 98 [145152/225000 (65%)] Loss: 14446.872070\n",
      "Train Epoch: 98 [146560/225000 (65%)] Loss: 15025.440430\n",
      "Train Epoch: 98 [147968/225000 (66%)] Loss: 15121.725586\n",
      "Train Epoch: 98 [149376/225000 (66%)] Loss: 15321.231445\n",
      "Train Epoch: 98 [150784/225000 (67%)] Loss: 15103.151367\n",
      "Train Epoch: 98 [152192/225000 (68%)] Loss: 15121.489258\n",
      "Train Epoch: 98 [153600/225000 (68%)] Loss: 15008.606445\n",
      "Train Epoch: 98 [155008/225000 (69%)] Loss: 15173.156250\n",
      "Train Epoch: 98 [156416/225000 (70%)] Loss: 14666.748047\n",
      "Train Epoch: 98 [157824/225000 (70%)] Loss: 14782.813477\n",
      "Train Epoch: 98 [159232/225000 (71%)] Loss: 14847.261719\n",
      "Train Epoch: 98 [160640/225000 (71%)] Loss: 14869.839844\n",
      "Train Epoch: 98 [162048/225000 (72%)] Loss: 14967.852539\n",
      "Train Epoch: 98 [163456/225000 (73%)] Loss: 15464.209961\n",
      "Train Epoch: 98 [164864/225000 (73%)] Loss: 14792.039062\n",
      "Train Epoch: 98 [166272/225000 (74%)] Loss: 15117.252930\n",
      "Train Epoch: 98 [167680/225000 (75%)] Loss: 15020.477539\n",
      "Train Epoch: 98 [169088/225000 (75%)] Loss: 15225.960938\n",
      "Train Epoch: 98 [170496/225000 (76%)] Loss: 14801.491211\n",
      "Train Epoch: 98 [171904/225000 (76%)] Loss: 15254.379883\n",
      "Train Epoch: 98 [173312/225000 (77%)] Loss: 15314.465820\n",
      "Train Epoch: 98 [174720/225000 (78%)] Loss: 15071.974609\n",
      "Train Epoch: 98 [176128/225000 (78%)] Loss: 14752.396484\n",
      "Train Epoch: 98 [177536/225000 (79%)] Loss: 14829.696289\n",
      "Train Epoch: 98 [178944/225000 (80%)] Loss: 14706.797852\n",
      "Train Epoch: 98 [180352/225000 (80%)] Loss: 15284.095703\n",
      "Train Epoch: 98 [181760/225000 (81%)] Loss: 15108.261719\n",
      "Train Epoch: 98 [183168/225000 (81%)] Loss: 14828.826172\n",
      "Train Epoch: 98 [184576/225000 (82%)] Loss: 14984.688477\n",
      "Train Epoch: 98 [185984/225000 (83%)] Loss: 15191.672852\n",
      "Train Epoch: 98 [187392/225000 (83%)] Loss: 15171.264648\n",
      "Train Epoch: 98 [188800/225000 (84%)] Loss: 15132.668945\n",
      "Train Epoch: 98 [190208/225000 (85%)] Loss: 14888.642578\n",
      "Train Epoch: 98 [191616/225000 (85%)] Loss: 15503.691406\n",
      "Train Epoch: 98 [193024/225000 (86%)] Loss: 15164.172852\n",
      "Train Epoch: 98 [194432/225000 (86%)] Loss: 14736.567383\n",
      "Train Epoch: 98 [195840/225000 (87%)] Loss: 15561.114258\n",
      "Train Epoch: 98 [197248/225000 (88%)] Loss: 15127.190430\n",
      "Train Epoch: 98 [198656/225000 (88%)] Loss: 15469.941406\n",
      "Train Epoch: 98 [200064/225000 (89%)] Loss: 14796.602539\n",
      "Train Epoch: 98 [201472/225000 (90%)] Loss: 14900.310547\n",
      "Train Epoch: 98 [202880/225000 (90%)] Loss: 15372.561523\n",
      "Train Epoch: 98 [204288/225000 (91%)] Loss: 15223.846680\n",
      "Train Epoch: 98 [205696/225000 (91%)] Loss: 14948.376953\n",
      "Train Epoch: 98 [207104/225000 (92%)] Loss: 15304.880859\n",
      "Train Epoch: 98 [208512/225000 (93%)] Loss: 15086.556641\n",
      "Train Epoch: 98 [209920/225000 (93%)] Loss: 14898.458984\n",
      "Train Epoch: 98 [211328/225000 (94%)] Loss: 15511.964844\n",
      "Train Epoch: 98 [212736/225000 (95%)] Loss: 15238.860352\n",
      "Train Epoch: 98 [214144/225000 (95%)] Loss: 15161.310547\n",
      "Train Epoch: 98 [215552/225000 (96%)] Loss: 15067.741211\n",
      "Train Epoch: 98 [216960/225000 (96%)] Loss: 15227.327148\n",
      "Train Epoch: 98 [218368/225000 (97%)] Loss: 14709.934570\n",
      "Train Epoch: 98 [219776/225000 (98%)] Loss: 15264.595703\n",
      "Train Epoch: 98 [221184/225000 (98%)] Loss: 14549.137695\n",
      "Train Epoch: 98 [222592/225000 (99%)] Loss: 15181.091797\n",
      "Train Epoch: 98 [224000/225000 (100%)] Loss: 14808.732422\n",
      "    epoch          : 98\n",
      "    loss           : 15072.916160609535\n",
      "    val_loss       : 15056.870051257769\n",
      "Train Epoch: 99 [128/225000 (0%)] Loss: 14967.090820\n",
      "Train Epoch: 99 [1536/225000 (1%)] Loss: 15167.879883\n",
      "Train Epoch: 99 [2944/225000 (1%)] Loss: 14975.806641\n",
      "Train Epoch: 99 [4352/225000 (2%)] Loss: 15343.035156\n",
      "Train Epoch: 99 [5760/225000 (3%)] Loss: 15233.718750\n",
      "Train Epoch: 99 [7168/225000 (3%)] Loss: 14745.861328\n",
      "Train Epoch: 99 [8576/225000 (4%)] Loss: 14736.266602\n",
      "Train Epoch: 99 [9984/225000 (4%)] Loss: 15008.083008\n",
      "Train Epoch: 99 [11392/225000 (5%)] Loss: 15603.765625\n",
      "Train Epoch: 99 [12800/225000 (6%)] Loss: 14654.741211\n",
      "Train Epoch: 99 [14208/225000 (6%)] Loss: 14949.263672\n",
      "Train Epoch: 99 [15616/225000 (7%)] Loss: 14947.300781\n",
      "Train Epoch: 99 [17024/225000 (8%)] Loss: 14887.458008\n",
      "Train Epoch: 99 [18432/225000 (8%)] Loss: 15291.689453\n",
      "Train Epoch: 99 [19840/225000 (9%)] Loss: 14761.057617\n",
      "Train Epoch: 99 [21248/225000 (9%)] Loss: 15030.741211\n",
      "Train Epoch: 99 [22656/225000 (10%)] Loss: 14887.463867\n",
      "Train Epoch: 99 [24064/225000 (11%)] Loss: 15409.438477\n",
      "Train Epoch: 99 [25472/225000 (11%)] Loss: 14852.966797\n",
      "Train Epoch: 99 [26880/225000 (12%)] Loss: 15478.486328\n",
      "Train Epoch: 99 [28288/225000 (13%)] Loss: 15068.554688\n",
      "Train Epoch: 99 [29696/225000 (13%)] Loss: 15613.682617\n",
      "Train Epoch: 99 [31104/225000 (14%)] Loss: 15082.358398\n",
      "Train Epoch: 99 [32512/225000 (14%)] Loss: 15191.614258\n",
      "Train Epoch: 99 [33920/225000 (15%)] Loss: 15667.414062\n",
      "Train Epoch: 99 [35328/225000 (16%)] Loss: 14796.562500\n",
      "Train Epoch: 99 [36736/225000 (16%)] Loss: 15260.333008\n",
      "Train Epoch: 99 [38144/225000 (17%)] Loss: 15113.467773\n",
      "Train Epoch: 99 [39552/225000 (18%)] Loss: 15255.267578\n",
      "Train Epoch: 99 [40960/225000 (18%)] Loss: 14781.593750\n",
      "Train Epoch: 99 [42368/225000 (19%)] Loss: 14646.779297\n",
      "Train Epoch: 99 [43776/225000 (19%)] Loss: 15111.438477\n",
      "Train Epoch: 99 [45184/225000 (20%)] Loss: 14984.869141\n",
      "Train Epoch: 99 [46592/225000 (21%)] Loss: 15037.408203\n",
      "Train Epoch: 99 [48000/225000 (21%)] Loss: 14582.465820\n",
      "Train Epoch: 99 [49408/225000 (22%)] Loss: 15518.124023\n",
      "Train Epoch: 99 [50816/225000 (23%)] Loss: 15514.381836\n",
      "Train Epoch: 99 [52224/225000 (23%)] Loss: 15461.698242\n",
      "Train Epoch: 99 [53632/225000 (24%)] Loss: 15021.513672\n",
      "Train Epoch: 99 [55040/225000 (24%)] Loss: 15481.744141\n",
      "Train Epoch: 99 [56448/225000 (25%)] Loss: 15103.329102\n",
      "Train Epoch: 99 [57856/225000 (26%)] Loss: 15067.527344\n",
      "Train Epoch: 99 [59264/225000 (26%)] Loss: 14954.976562\n",
      "Train Epoch: 99 [60672/225000 (27%)] Loss: 15317.009766\n",
      "Train Epoch: 99 [62080/225000 (28%)] Loss: 15161.337891\n",
      "Train Epoch: 99 [63488/225000 (28%)] Loss: 15159.461914\n",
      "Train Epoch: 99 [64896/225000 (29%)] Loss: 15065.797852\n",
      "Train Epoch: 99 [66304/225000 (29%)] Loss: 15190.667969\n",
      "Train Epoch: 99 [67712/225000 (30%)] Loss: 14862.367188\n",
      "Train Epoch: 99 [69120/225000 (31%)] Loss: 15013.099609\n",
      "Train Epoch: 99 [70528/225000 (31%)] Loss: 15017.704102\n",
      "Train Epoch: 99 [71936/225000 (32%)] Loss: 15215.828125\n",
      "Train Epoch: 99 [73344/225000 (33%)] Loss: 15174.945312\n",
      "Train Epoch: 99 [74752/225000 (33%)] Loss: 15519.762695\n",
      "Train Epoch: 99 [76160/225000 (34%)] Loss: 15041.719727\n",
      "Train Epoch: 99 [77568/225000 (34%)] Loss: 14896.741211\n",
      "Train Epoch: 99 [78976/225000 (35%)] Loss: 15244.533203\n",
      "Train Epoch: 99 [80384/225000 (36%)] Loss: 15031.282227\n",
      "Train Epoch: 99 [81792/225000 (36%)] Loss: 14875.912109\n",
      "Train Epoch: 99 [83200/225000 (37%)] Loss: 14775.507812\n",
      "Train Epoch: 99 [84608/225000 (38%)] Loss: 15435.403320\n",
      "Train Epoch: 99 [86016/225000 (38%)] Loss: 15339.497070\n",
      "Train Epoch: 99 [87424/225000 (39%)] Loss: 15183.844727\n",
      "Train Epoch: 99 [88832/225000 (39%)] Loss: 14977.111328\n",
      "Train Epoch: 99 [90240/225000 (40%)] Loss: 14912.278320\n",
      "Train Epoch: 99 [91648/225000 (41%)] Loss: 14754.175781\n",
      "Train Epoch: 99 [93056/225000 (41%)] Loss: 15174.581055\n",
      "Train Epoch: 99 [94464/225000 (42%)] Loss: 14570.362305\n",
      "Train Epoch: 99 [95872/225000 (43%)] Loss: 15336.185547\n",
      "Train Epoch: 99 [97280/225000 (43%)] Loss: 15222.695312\n",
      "Train Epoch: 99 [98688/225000 (44%)] Loss: 15610.477539\n",
      "Train Epoch: 99 [100096/225000 (44%)] Loss: 15042.512695\n",
      "Train Epoch: 99 [101504/225000 (45%)] Loss: 15384.829102\n",
      "Train Epoch: 99 [102912/225000 (46%)] Loss: 15151.224609\n",
      "Train Epoch: 99 [104320/225000 (46%)] Loss: 15162.234375\n",
      "Train Epoch: 99 [105728/225000 (47%)] Loss: 14609.310547\n",
      "Train Epoch: 99 [107136/225000 (48%)] Loss: 14803.435547\n",
      "Train Epoch: 99 [108544/225000 (48%)] Loss: 14722.080078\n",
      "Train Epoch: 99 [109952/225000 (49%)] Loss: 14968.151367\n",
      "Train Epoch: 99 [111360/225000 (49%)] Loss: 15228.231445\n",
      "Train Epoch: 99 [112768/225000 (50%)] Loss: 15018.726562\n",
      "Train Epoch: 99 [114176/225000 (51%)] Loss: 15102.606445\n",
      "Train Epoch: 99 [115584/225000 (51%)] Loss: 15113.778320\n",
      "Train Epoch: 99 [116992/225000 (52%)] Loss: 15018.350586\n",
      "Train Epoch: 99 [118400/225000 (53%)] Loss: 15018.979492\n",
      "Train Epoch: 99 [119808/225000 (53%)] Loss: 15475.359375\n",
      "Train Epoch: 99 [121216/225000 (54%)] Loss: 14969.373047\n",
      "Train Epoch: 99 [122624/225000 (54%)] Loss: 14734.570312\n",
      "Train Epoch: 99 [124032/225000 (55%)] Loss: 15016.426758\n",
      "Train Epoch: 99 [125440/225000 (56%)] Loss: 14863.430664\n",
      "Train Epoch: 99 [126848/225000 (56%)] Loss: 14896.633789\n",
      "Train Epoch: 99 [128256/225000 (57%)] Loss: 15116.508789\n",
      "Train Epoch: 99 [129664/225000 (58%)] Loss: 14795.701172\n",
      "Train Epoch: 99 [131072/225000 (58%)] Loss: 15161.584961\n",
      "Train Epoch: 99 [132480/225000 (59%)] Loss: 15255.052734\n",
      "Train Epoch: 99 [133888/225000 (60%)] Loss: 15168.611328\n",
      "Train Epoch: 99 [135296/225000 (60%)] Loss: 14845.353516\n",
      "Train Epoch: 99 [136704/225000 (61%)] Loss: 15174.641602\n",
      "Train Epoch: 99 [138112/225000 (61%)] Loss: 15278.515625\n",
      "Train Epoch: 99 [139520/225000 (62%)] Loss: 14956.390625\n",
      "Train Epoch: 99 [140928/225000 (63%)] Loss: 14897.756836\n",
      "Train Epoch: 99 [142336/225000 (63%)] Loss: 14949.958984\n",
      "Train Epoch: 99 [143744/225000 (64%)] Loss: 14928.031250\n",
      "Train Epoch: 99 [145152/225000 (65%)] Loss: 15161.436523\n",
      "Train Epoch: 99 [146560/225000 (65%)] Loss: 15551.706055\n",
      "Train Epoch: 99 [147968/225000 (66%)] Loss: 14715.518555\n",
      "Train Epoch: 99 [149376/225000 (66%)] Loss: 14959.180664\n",
      "Train Epoch: 99 [150784/225000 (67%)] Loss: 15108.199219\n",
      "Train Epoch: 99 [152192/225000 (68%)] Loss: 15175.536133\n",
      "Train Epoch: 99 [153600/225000 (68%)] Loss: 15108.339844\n",
      "Train Epoch: 99 [155008/225000 (69%)] Loss: 15292.842773\n",
      "Train Epoch: 99 [156416/225000 (70%)] Loss: 15322.093750\n",
      "Train Epoch: 99 [157824/225000 (70%)] Loss: 15024.458008\n",
      "Train Epoch: 99 [159232/225000 (71%)] Loss: 15128.196289\n",
      "Train Epoch: 99 [160640/225000 (71%)] Loss: 14920.620117\n",
      "Train Epoch: 99 [162048/225000 (72%)] Loss: 15048.486328\n",
      "Train Epoch: 99 [163456/225000 (73%)] Loss: 15462.845703\n",
      "Train Epoch: 99 [164864/225000 (73%)] Loss: 14998.718750\n",
      "Train Epoch: 99 [166272/225000 (74%)] Loss: 15236.741211\n",
      "Train Epoch: 99 [167680/225000 (75%)] Loss: 14807.336914\n",
      "Train Epoch: 99 [169088/225000 (75%)] Loss: 14964.074219\n",
      "Train Epoch: 99 [170496/225000 (76%)] Loss: 15691.059570\n",
      "Train Epoch: 99 [171904/225000 (76%)] Loss: 15179.494141\n",
      "Train Epoch: 99 [173312/225000 (77%)] Loss: 15218.433594\n",
      "Train Epoch: 99 [174720/225000 (78%)] Loss: 15026.274414\n",
      "Train Epoch: 99 [176128/225000 (78%)] Loss: 15050.186523\n",
      "Train Epoch: 99 [177536/225000 (79%)] Loss: 14853.211914\n",
      "Train Epoch: 99 [178944/225000 (80%)] Loss: 14826.683594\n",
      "Train Epoch: 99 [180352/225000 (80%)] Loss: 14766.912109\n",
      "Train Epoch: 99 [181760/225000 (81%)] Loss: 15040.541992\n",
      "Train Epoch: 99 [183168/225000 (81%)] Loss: 15231.221680\n",
      "Train Epoch: 99 [184576/225000 (82%)] Loss: 15310.759766\n",
      "Train Epoch: 99 [185984/225000 (83%)] Loss: 15086.305664\n",
      "Train Epoch: 99 [187392/225000 (83%)] Loss: 14623.200195\n",
      "Train Epoch: 99 [188800/225000 (84%)] Loss: 14804.162109\n",
      "Train Epoch: 99 [190208/225000 (85%)] Loss: 14832.572266\n",
      "Train Epoch: 99 [191616/225000 (85%)] Loss: 14415.527344\n",
      "Train Epoch: 99 [193024/225000 (86%)] Loss: 14790.058594\n",
      "Train Epoch: 99 [194432/225000 (86%)] Loss: 15090.445312\n",
      "Train Epoch: 99 [195840/225000 (87%)] Loss: 15082.233398\n",
      "Train Epoch: 99 [197248/225000 (88%)] Loss: 15003.226562\n",
      "Train Epoch: 99 [198656/225000 (88%)] Loss: 14943.075195\n",
      "Train Epoch: 99 [200064/225000 (89%)] Loss: 14984.259766\n",
      "Train Epoch: 99 [201472/225000 (90%)] Loss: 15264.993164\n",
      "Train Epoch: 99 [202880/225000 (90%)] Loss: 15129.362305\n",
      "Train Epoch: 99 [204288/225000 (91%)] Loss: 14707.524414\n",
      "Train Epoch: 99 [205696/225000 (91%)] Loss: 15024.809570\n",
      "Train Epoch: 99 [207104/225000 (92%)] Loss: 15247.596680\n",
      "Train Epoch: 99 [208512/225000 (93%)] Loss: 14835.743164\n",
      "Train Epoch: 99 [209920/225000 (93%)] Loss: 15445.845703\n",
      "Train Epoch: 99 [211328/225000 (94%)] Loss: 14723.930664\n",
      "Train Epoch: 99 [212736/225000 (95%)] Loss: 15156.362305\n",
      "Train Epoch: 99 [214144/225000 (95%)] Loss: 14992.279297\n",
      "Train Epoch: 99 [215552/225000 (96%)] Loss: 15645.199219\n",
      "Train Epoch: 99 [216960/225000 (96%)] Loss: 15152.259766\n",
      "Train Epoch: 99 [218368/225000 (97%)] Loss: 14925.344727\n",
      "Train Epoch: 99 [219776/225000 (98%)] Loss: 15499.038086\n",
      "Train Epoch: 99 [221184/225000 (98%)] Loss: 15064.151367\n",
      "Train Epoch: 99 [222592/225000 (99%)] Loss: 15469.059570\n",
      "Train Epoch: 99 [224000/225000 (100%)] Loss: 15072.483398\n",
      "    epoch          : 99\n",
      "    loss           : 15073.240397690914\n",
      "    val_loss       : 15060.699809478254\n",
      "Train Epoch: 100 [128/225000 (0%)] Loss: 14634.541992\n",
      "Train Epoch: 100 [1536/225000 (1%)] Loss: 14800.045898\n",
      "Train Epoch: 100 [2944/225000 (1%)] Loss: 14818.866211\n",
      "Train Epoch: 100 [4352/225000 (2%)] Loss: 15038.327148\n",
      "Train Epoch: 100 [5760/225000 (3%)] Loss: 15182.782227\n",
      "Train Epoch: 100 [7168/225000 (3%)] Loss: 15111.626953\n",
      "Train Epoch: 100 [8576/225000 (4%)] Loss: 14890.449219\n",
      "Train Epoch: 100 [9984/225000 (4%)] Loss: 14966.247070\n",
      "Train Epoch: 100 [11392/225000 (5%)] Loss: 14742.214844\n",
      "Train Epoch: 100 [12800/225000 (6%)] Loss: 15494.402344\n",
      "Train Epoch: 100 [14208/225000 (6%)] Loss: 14971.657227\n",
      "Train Epoch: 100 [15616/225000 (7%)] Loss: 15532.856445\n",
      "Train Epoch: 100 [17024/225000 (8%)] Loss: 14928.822266\n",
      "Train Epoch: 100 [18432/225000 (8%)] Loss: 15052.652344\n",
      "Train Epoch: 100 [19840/225000 (9%)] Loss: 15481.787109\n",
      "Train Epoch: 100 [21248/225000 (9%)] Loss: 14912.444336\n",
      "Train Epoch: 100 [22656/225000 (10%)] Loss: 15591.029297\n",
      "Train Epoch: 100 [24064/225000 (11%)] Loss: 15612.150391\n",
      "Train Epoch: 100 [25472/225000 (11%)] Loss: 15135.061523\n",
      "Train Epoch: 100 [26880/225000 (12%)] Loss: 15296.083984\n",
      "Train Epoch: 100 [28288/225000 (13%)] Loss: 15370.561523\n",
      "Train Epoch: 100 [29696/225000 (13%)] Loss: 15110.767578\n",
      "Train Epoch: 100 [31104/225000 (14%)] Loss: 15542.515625\n",
      "Train Epoch: 100 [32512/225000 (14%)] Loss: 15033.422852\n",
      "Train Epoch: 100 [33920/225000 (15%)] Loss: 14670.557617\n",
      "Train Epoch: 100 [35328/225000 (16%)] Loss: 14839.485352\n",
      "Train Epoch: 100 [36736/225000 (16%)] Loss: 15259.366211\n",
      "Train Epoch: 100 [38144/225000 (17%)] Loss: 15048.360352\n",
      "Train Epoch: 100 [39552/225000 (18%)] Loss: 14874.917969\n",
      "Train Epoch: 100 [40960/225000 (18%)] Loss: 15097.653320\n",
      "Train Epoch: 100 [42368/225000 (19%)] Loss: 15236.702148\n",
      "Train Epoch: 100 [43776/225000 (19%)] Loss: 15203.849609\n",
      "Train Epoch: 100 [45184/225000 (20%)] Loss: 15022.971680\n",
      "Train Epoch: 100 [46592/225000 (21%)] Loss: 15139.238281\n",
      "Train Epoch: 100 [48000/225000 (21%)] Loss: 15455.061523\n",
      "Train Epoch: 100 [49408/225000 (22%)] Loss: 14864.666016\n",
      "Train Epoch: 100 [50816/225000 (23%)] Loss: 15245.676758\n",
      "Train Epoch: 100 [52224/225000 (23%)] Loss: 15135.799805\n",
      "Train Epoch: 100 [53632/225000 (24%)] Loss: 14685.669922\n",
      "Train Epoch: 100 [55040/225000 (24%)] Loss: 14559.328125\n",
      "Train Epoch: 100 [56448/225000 (25%)] Loss: 14844.816406\n",
      "Train Epoch: 100 [57856/225000 (26%)] Loss: 14815.869141\n",
      "Train Epoch: 100 [59264/225000 (26%)] Loss: 15203.234375\n",
      "Train Epoch: 100 [60672/225000 (27%)] Loss: 14957.981445\n",
      "Train Epoch: 100 [62080/225000 (28%)] Loss: 14673.158203\n",
      "Train Epoch: 100 [63488/225000 (28%)] Loss: 14972.503906\n",
      "Train Epoch: 100 [64896/225000 (29%)] Loss: 14895.241211\n",
      "Train Epoch: 100 [66304/225000 (29%)] Loss: 14820.500000\n",
      "Train Epoch: 100 [67712/225000 (30%)] Loss: 14913.103516\n",
      "Train Epoch: 100 [69120/225000 (31%)] Loss: 14970.534180\n",
      "Train Epoch: 100 [70528/225000 (31%)] Loss: 14933.627930\n",
      "Train Epoch: 100 [71936/225000 (32%)] Loss: 15079.743164\n",
      "Train Epoch: 100 [73344/225000 (33%)] Loss: 15192.541016\n",
      "Train Epoch: 100 [74752/225000 (33%)] Loss: 15299.295898\n",
      "Train Epoch: 100 [76160/225000 (34%)] Loss: 14730.139648\n",
      "Train Epoch: 100 [77568/225000 (34%)] Loss: 15014.307617\n",
      "Train Epoch: 100 [78976/225000 (35%)] Loss: 15104.981445\n",
      "Train Epoch: 100 [80384/225000 (36%)] Loss: 15450.237305\n",
      "Train Epoch: 100 [81792/225000 (36%)] Loss: 14922.363281\n",
      "Train Epoch: 100 [83200/225000 (37%)] Loss: 15613.823242\n",
      "Train Epoch: 100 [84608/225000 (38%)] Loss: 14889.795898\n",
      "Train Epoch: 100 [86016/225000 (38%)] Loss: 15094.283203\n",
      "Train Epoch: 100 [87424/225000 (39%)] Loss: 15090.505859\n",
      "Train Epoch: 100 [88832/225000 (39%)] Loss: 15340.072266\n",
      "Train Epoch: 100 [90240/225000 (40%)] Loss: 15221.567383\n",
      "Train Epoch: 100 [91648/225000 (41%)] Loss: 15567.777344\n",
      "Train Epoch: 100 [93056/225000 (41%)] Loss: 15121.821289\n",
      "Train Epoch: 100 [94464/225000 (42%)] Loss: 14566.837891\n",
      "Train Epoch: 100 [95872/225000 (43%)] Loss: 15323.567383\n",
      "Train Epoch: 100 [97280/225000 (43%)] Loss: 15180.069336\n",
      "Train Epoch: 100 [98688/225000 (44%)] Loss: 14961.214844\n",
      "Train Epoch: 100 [100096/225000 (44%)] Loss: 14888.118164\n",
      "Train Epoch: 100 [101504/225000 (45%)] Loss: 14753.943359\n",
      "Train Epoch: 100 [102912/225000 (46%)] Loss: 14796.351562\n",
      "Train Epoch: 100 [104320/225000 (46%)] Loss: 15302.337891\n",
      "Train Epoch: 100 [105728/225000 (47%)] Loss: 15462.378906\n",
      "Train Epoch: 100 [107136/225000 (48%)] Loss: 15070.719727\n",
      "Train Epoch: 100 [108544/225000 (48%)] Loss: 15132.880859\n",
      "Train Epoch: 100 [109952/225000 (49%)] Loss: 15563.239258\n",
      "Train Epoch: 100 [111360/225000 (49%)] Loss: 15181.754883\n",
      "Train Epoch: 100 [112768/225000 (50%)] Loss: 14690.831055\n",
      "Train Epoch: 100 [114176/225000 (51%)] Loss: 14945.562500\n",
      "Train Epoch: 100 [115584/225000 (51%)] Loss: 15322.951172\n",
      "Train Epoch: 100 [116992/225000 (52%)] Loss: 14744.595703\n",
      "Train Epoch: 100 [118400/225000 (53%)] Loss: 15267.526367\n",
      "Train Epoch: 100 [119808/225000 (53%)] Loss: 15171.977539\n",
      "Train Epoch: 100 [121216/225000 (54%)] Loss: 15005.756836\n",
      "Train Epoch: 100 [122624/225000 (54%)] Loss: 14777.419922\n",
      "Train Epoch: 100 [124032/225000 (55%)] Loss: 15314.717773\n",
      "Train Epoch: 100 [125440/225000 (56%)] Loss: 15220.887695\n",
      "Train Epoch: 100 [126848/225000 (56%)] Loss: 15205.689453\n",
      "Train Epoch: 100 [128256/225000 (57%)] Loss: 15337.771484\n",
      "Train Epoch: 100 [129664/225000 (58%)] Loss: 14849.183594\n",
      "Train Epoch: 100 [131072/225000 (58%)] Loss: 14943.046875\n",
      "Train Epoch: 100 [132480/225000 (59%)] Loss: 15080.055664\n",
      "Train Epoch: 100 [133888/225000 (60%)] Loss: 14925.453125\n",
      "Train Epoch: 100 [135296/225000 (60%)] Loss: 14486.451172\n",
      "Train Epoch: 100 [136704/225000 (61%)] Loss: 14518.953125\n",
      "Train Epoch: 100 [138112/225000 (61%)] Loss: 15002.062500\n",
      "Train Epoch: 100 [139520/225000 (62%)] Loss: 14740.274414\n",
      "Train Epoch: 100 [140928/225000 (63%)] Loss: 14821.746094\n",
      "Train Epoch: 100 [142336/225000 (63%)] Loss: 15132.231445\n",
      "Train Epoch: 100 [143744/225000 (64%)] Loss: 15623.930664\n",
      "Train Epoch: 100 [145152/225000 (65%)] Loss: 14642.925781\n",
      "Train Epoch: 100 [146560/225000 (65%)] Loss: 15600.394531\n",
      "Train Epoch: 100 [147968/225000 (66%)] Loss: 14961.079102\n",
      "Train Epoch: 100 [149376/225000 (66%)] Loss: 14945.882812\n",
      "Train Epoch: 100 [150784/225000 (67%)] Loss: 15311.613281\n",
      "Train Epoch: 100 [152192/225000 (68%)] Loss: 15110.678711\n",
      "Train Epoch: 100 [153600/225000 (68%)] Loss: 14852.759766\n",
      "Train Epoch: 100 [155008/225000 (69%)] Loss: 15021.668945\n",
      "Train Epoch: 100 [156416/225000 (70%)] Loss: 14849.328125\n",
      "Train Epoch: 100 [157824/225000 (70%)] Loss: 15024.258789\n",
      "Train Epoch: 100 [159232/225000 (71%)] Loss: 15138.249023\n",
      "Train Epoch: 100 [160640/225000 (71%)] Loss: 14801.514648\n",
      "Train Epoch: 100 [162048/225000 (72%)] Loss: 14773.231445\n",
      "Train Epoch: 100 [163456/225000 (73%)] Loss: 15276.216797\n",
      "Train Epoch: 100 [164864/225000 (73%)] Loss: 15253.879883\n",
      "Train Epoch: 100 [166272/225000 (74%)] Loss: 15344.133789\n",
      "Train Epoch: 100 [167680/225000 (75%)] Loss: 15215.201172\n",
      "Train Epoch: 100 [169088/225000 (75%)] Loss: 14833.280273\n",
      "Train Epoch: 100 [170496/225000 (76%)] Loss: 15265.615234\n",
      "Train Epoch: 100 [171904/225000 (76%)] Loss: 15228.365234\n",
      "Train Epoch: 100 [173312/225000 (77%)] Loss: 15008.320312\n",
      "Train Epoch: 100 [174720/225000 (78%)] Loss: 14843.376953\n",
      "Train Epoch: 100 [176128/225000 (78%)] Loss: 14799.065430\n",
      "Train Epoch: 100 [177536/225000 (79%)] Loss: 15375.475586\n",
      "Train Epoch: 100 [178944/225000 (80%)] Loss: 15315.649414\n",
      "Train Epoch: 100 [180352/225000 (80%)] Loss: 15091.676758\n",
      "Train Epoch: 100 [181760/225000 (81%)] Loss: 15116.478516\n",
      "Train Epoch: 100 [183168/225000 (81%)] Loss: 15228.118164\n",
      "Train Epoch: 100 [184576/225000 (82%)] Loss: 15457.176758\n",
      "Train Epoch: 100 [185984/225000 (83%)] Loss: 15175.632812\n",
      "Train Epoch: 100 [187392/225000 (83%)] Loss: 14758.356445\n",
      "Train Epoch: 100 [188800/225000 (84%)] Loss: 15669.683594\n",
      "Train Epoch: 100 [190208/225000 (85%)] Loss: 14808.857422\n",
      "Train Epoch: 100 [191616/225000 (85%)] Loss: 14932.726562\n",
      "Train Epoch: 100 [193024/225000 (86%)] Loss: 14931.189453\n",
      "Train Epoch: 100 [194432/225000 (86%)] Loss: 14696.934570\n",
      "Train Epoch: 100 [195840/225000 (87%)] Loss: 14592.312500\n",
      "Train Epoch: 100 [197248/225000 (88%)] Loss: 14373.244141\n",
      "Train Epoch: 100 [198656/225000 (88%)] Loss: 15054.115234\n",
      "Train Epoch: 100 [200064/225000 (89%)] Loss: 14709.538086\n",
      "Train Epoch: 100 [201472/225000 (90%)] Loss: 15142.284180\n",
      "Train Epoch: 100 [202880/225000 (90%)] Loss: 15465.491211\n",
      "Train Epoch: 100 [204288/225000 (91%)] Loss: 14955.029297\n",
      "Train Epoch: 100 [205696/225000 (91%)] Loss: 15481.823242\n",
      "Train Epoch: 100 [207104/225000 (92%)] Loss: 14765.779297\n",
      "Train Epoch: 100 [208512/225000 (93%)] Loss: 15097.933594\n",
      "Train Epoch: 100 [209920/225000 (93%)] Loss: 15123.948242\n",
      "Train Epoch: 100 [211328/225000 (94%)] Loss: 14871.000000\n",
      "Train Epoch: 100 [212736/225000 (95%)] Loss: 15039.940430\n",
      "Train Epoch: 100 [214144/225000 (95%)] Loss: 15029.488281\n",
      "Train Epoch: 100 [215552/225000 (96%)] Loss: 15230.773438\n",
      "Train Epoch: 100 [216960/225000 (96%)] Loss: 15097.214844\n",
      "Train Epoch: 100 [218368/225000 (97%)] Loss: 14972.473633\n",
      "Train Epoch: 100 [219776/225000 (98%)] Loss: 14664.892578\n",
      "Train Epoch: 100 [221184/225000 (98%)] Loss: 14987.679688\n",
      "Train Epoch: 100 [222592/225000 (99%)] Loss: 14672.609375\n",
      "Train Epoch: 100 [224000/225000 (100%)] Loss: 15220.524414\n",
      "    epoch          : 100\n",
      "    loss           : 15072.6959735406\n",
      "    val_loss       : 15054.779345420095\n",
      "Saving checkpoint: saved/models/Molecular_VaeCategory/0723_110905/checkpoint-epoch100.pth ...\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MolecularVaeCategoryModel(\n",
       "  (_category): FreeCategory(\n",
       "    (generator_0): MolecularDecoder(\n",
       "      (pre_recurrence_linear): Sequential(\n",
       "        (0): Linear(in_features=196, out_features=196, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (recurrence): GRU(196, 50, num_layers=3, batch_first=True)\n",
       "      (decoder): Sequential(\n",
       "        (0): Linear(in_features=50, out_features=34, bias=True)\n",
       "        (1): LogSoftmax(dim=-1)\n",
       "      )\n",
       "    )\n",
       "    (generator_0_dagger): ConvMolecularEncoder(\n",
       "      (smiles_conv): Sequential(\n",
       "        (0): Conv1d(120, 9, kernel_size=(9,), stride=(1,))\n",
       "        (1): ReLU()\n",
       "        (2): Conv1d(9, 9, kernel_size=(9,), stride=(1,))\n",
       "        (3): ReLU()\n",
       "        (4): Conv1d(9, 10, kernel_size=(11,), stride=(1,))\n",
       "        (5): ReLU()\n",
       "      )\n",
       "      (smiles_linear): Sequential(\n",
       "        (0): Linear(in_features=80, out_features=196, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (embedding_loc): Linear(in_features=196, out_features=196, bias=True)\n",
       "      (embedding_log_scale): Linear(in_features=196, out_features=196, bias=True)\n",
       "      (embedding_dist): DiagonalGaussian()\n",
       "    )\n",
       "    (generator_1): MolecularDecoder(\n",
       "      (pre_recurrence_linear): Sequential(\n",
       "        (0): Linear(in_features=196, out_features=196, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (recurrence): GRU(196, 50, num_layers=3, batch_first=True)\n",
       "      (decoder): Sequential(\n",
       "        (0): Linear(in_features=50, out_features=34, bias=True)\n",
       "        (1): LogSoftmax(dim=-1)\n",
       "      )\n",
       "    )\n",
       "    (generator_1_dagger): RecurrentMolecularEncoder(\n",
       "      (encoder_linear): Sequential(\n",
       "        (0): Linear(in_features=34, out_features=50, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (recurrence): GRU(50, 196, num_layers=3, batch_first=True)\n",
       "      (postrecurrence_linear): Sequential(\n",
       "        (0): Linear(in_features=196, out_features=196, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (embedding_loc): Linear(in_features=196, out_features=196, bias=True)\n",
       "      (embedding_log_scale): Linear(in_features=196, out_features=196, bias=True)\n",
       "      (embedding_dist): DiagonalGaussian()\n",
       "    )\n",
       "    (generator_2): MolecularDecoder(\n",
       "      (pre_recurrence_linear): Sequential(\n",
       "        (0): Linear(in_features=196, out_features=196, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (recurrence): GRU(196, 488, num_layers=3, batch_first=True)\n",
       "      (decoder): Sequential(\n",
       "        (0): Linear(in_features=488, out_features=34, bias=True)\n",
       "        (1): LogSoftmax(dim=-1)\n",
       "      )\n",
       "    )\n",
       "    (generator_2_dagger): ConvMolecularEncoder(\n",
       "      (smiles_conv): Sequential(\n",
       "        (0): Conv1d(120, 9, kernel_size=(9,), stride=(1,))\n",
       "        (1): ReLU()\n",
       "        (2): Conv1d(9, 9, kernel_size=(9,), stride=(1,))\n",
       "        (3): ReLU()\n",
       "        (4): Conv1d(9, 10, kernel_size=(11,), stride=(1,))\n",
       "        (5): ReLU()\n",
       "      )\n",
       "      (smiles_linear): Sequential(\n",
       "        (0): Linear(in_features=80, out_features=196, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (embedding_loc): Linear(in_features=196, out_features=196, bias=True)\n",
       "      (embedding_log_scale): Linear(in_features=196, out_features=196, bias=True)\n",
       "      (embedding_dist): DiagonalGaussian()\n",
       "    )\n",
       "    (generator_3): MolecularDecoder(\n",
       "      (pre_recurrence_linear): Sequential(\n",
       "        (0): Linear(in_features=196, out_features=196, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (recurrence): GRU(196, 488, num_layers=3, batch_first=True)\n",
       "      (decoder): Sequential(\n",
       "        (0): Linear(in_features=488, out_features=34, bias=True)\n",
       "        (1): LogSoftmax(dim=-1)\n",
       "      )\n",
       "    )\n",
       "    (generator_3_dagger): RecurrentMolecularEncoder(\n",
       "      (encoder_linear): Sequential(\n",
       "        (0): Linear(in_features=34, out_features=488, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (recurrence): GRU(488, 196, num_layers=3, batch_first=True)\n",
       "      (postrecurrence_linear): Sequential(\n",
       "        (0): Linear(in_features=196, out_features=196, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (embedding_loc): Linear(in_features=196, out_features=196, bias=True)\n",
       "      (embedding_log_scale): Linear(in_features=196, out_features=196, bias=True)\n",
       "      (embedding_dist): DiagonalGaussian()\n",
       "    )\n",
       "    (generator_4): MolecularDecoder(\n",
       "      (pre_recurrence_linear): Sequential(\n",
       "        (0): Linear(in_features=196, out_features=196, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (recurrence): GRU(196, 501, num_layers=3, batch_first=True)\n",
       "      (decoder): Sequential(\n",
       "        (0): Linear(in_features=501, out_features=34, bias=True)\n",
       "        (1): LogSoftmax(dim=-1)\n",
       "      )\n",
       "    )\n",
       "    (generator_4_dagger): ConvMolecularEncoder(\n",
       "      (smiles_conv): Sequential(\n",
       "        (0): Conv1d(120, 9, kernel_size=(9,), stride=(1,))\n",
       "        (1): ReLU()\n",
       "        (2): Conv1d(9, 9, kernel_size=(9,), stride=(1,))\n",
       "        (3): ReLU()\n",
       "        (4): Conv1d(9, 10, kernel_size=(11,), stride=(1,))\n",
       "        (5): ReLU()\n",
       "      )\n",
       "      (smiles_linear): Sequential(\n",
       "        (0): Linear(in_features=80, out_features=196, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (embedding_loc): Linear(in_features=196, out_features=196, bias=True)\n",
       "      (embedding_log_scale): Linear(in_features=196, out_features=196, bias=True)\n",
       "      (embedding_dist): DiagonalGaussian()\n",
       "    )\n",
       "    (generator_5): MolecularDecoder(\n",
       "      (pre_recurrence_linear): Sequential(\n",
       "        (0): Linear(in_features=196, out_features=196, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (recurrence): GRU(196, 501, num_layers=3, batch_first=True)\n",
       "      (decoder): Sequential(\n",
       "        (0): Linear(in_features=501, out_features=34, bias=True)\n",
       "        (1): LogSoftmax(dim=-1)\n",
       "      )\n",
       "    )\n",
       "    (generator_5_dagger): RecurrentMolecularEncoder(\n",
       "      (encoder_linear): Sequential(\n",
       "        (0): Linear(in_features=34, out_features=501, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (recurrence): GRU(501, 196, num_layers=3, batch_first=True)\n",
       "      (postrecurrence_linear): Sequential(\n",
       "        (0): Linear(in_features=196, out_features=196, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (embedding_loc): Linear(in_features=196, out_features=196, bias=True)\n",
       "      (embedding_log_scale): Linear(in_features=196, out_features=196, bias=True)\n",
       "      (embedding_dist): DiagonalGaussian()\n",
       "    )\n",
       "    (generator_6): MolecularDecoder(\n",
       "      (pre_recurrence_linear): Sequential(\n",
       "        (0): Linear(in_features=292, out_features=292, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (recurrence): GRU(292, 50, num_layers=3, batch_first=True)\n",
       "      (decoder): Sequential(\n",
       "        (0): Linear(in_features=50, out_features=34, bias=True)\n",
       "        (1): LogSoftmax(dim=-1)\n",
       "      )\n",
       "    )\n",
       "    (generator_6_dagger): ConvMolecularEncoder(\n",
       "      (smiles_conv): Sequential(\n",
       "        (0): Conv1d(120, 9, kernel_size=(9,), stride=(1,))\n",
       "        (1): ReLU()\n",
       "        (2): Conv1d(9, 9, kernel_size=(9,), stride=(1,))\n",
       "        (3): ReLU()\n",
       "        (4): Conv1d(9, 10, kernel_size=(11,), stride=(1,))\n",
       "        (5): ReLU()\n",
       "      )\n",
       "      (smiles_linear): Sequential(\n",
       "        (0): Linear(in_features=80, out_features=292, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (embedding_loc): Linear(in_features=292, out_features=292, bias=True)\n",
       "      (embedding_log_scale): Linear(in_features=292, out_features=292, bias=True)\n",
       "      (embedding_dist): DiagonalGaussian()\n",
       "    )\n",
       "    (generator_7): MolecularDecoder(\n",
       "      (pre_recurrence_linear): Sequential(\n",
       "        (0): Linear(in_features=292, out_features=292, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (recurrence): GRU(292, 50, num_layers=3, batch_first=True)\n",
       "      (decoder): Sequential(\n",
       "        (0): Linear(in_features=50, out_features=34, bias=True)\n",
       "        (1): LogSoftmax(dim=-1)\n",
       "      )\n",
       "    )\n",
       "    (generator_7_dagger): RecurrentMolecularEncoder(\n",
       "      (encoder_linear): Sequential(\n",
       "        (0): Linear(in_features=34, out_features=50, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (recurrence): GRU(50, 292, num_layers=3, batch_first=True)\n",
       "      (postrecurrence_linear): Sequential(\n",
       "        (0): Linear(in_features=292, out_features=292, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (embedding_loc): Linear(in_features=292, out_features=292, bias=True)\n",
       "      (embedding_log_scale): Linear(in_features=292, out_features=292, bias=True)\n",
       "      (embedding_dist): DiagonalGaussian()\n",
       "    )\n",
       "    (generator_8): MolecularDecoder(\n",
       "      (pre_recurrence_linear): Sequential(\n",
       "        (0): Linear(in_features=292, out_features=292, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (recurrence): GRU(292, 488, num_layers=3, batch_first=True)\n",
       "      (decoder): Sequential(\n",
       "        (0): Linear(in_features=488, out_features=34, bias=True)\n",
       "        (1): LogSoftmax(dim=-1)\n",
       "      )\n",
       "    )\n",
       "    (generator_8_dagger): ConvMolecularEncoder(\n",
       "      (smiles_conv): Sequential(\n",
       "        (0): Conv1d(120, 9, kernel_size=(9,), stride=(1,))\n",
       "        (1): ReLU()\n",
       "        (2): Conv1d(9, 9, kernel_size=(9,), stride=(1,))\n",
       "        (3): ReLU()\n",
       "        (4): Conv1d(9, 10, kernel_size=(11,), stride=(1,))\n",
       "        (5): ReLU()\n",
       "      )\n",
       "      (smiles_linear): Sequential(\n",
       "        (0): Linear(in_features=80, out_features=292, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (embedding_loc): Linear(in_features=292, out_features=292, bias=True)\n",
       "      (embedding_log_scale): Linear(in_features=292, out_features=292, bias=True)\n",
       "      (embedding_dist): DiagonalGaussian()\n",
       "    )\n",
       "    (generator_9): MolecularDecoder(\n",
       "      (pre_recurrence_linear): Sequential(\n",
       "        (0): Linear(in_features=292, out_features=292, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (recurrence): GRU(292, 488, num_layers=3, batch_first=True)\n",
       "      (decoder): Sequential(\n",
       "        (0): Linear(in_features=488, out_features=34, bias=True)\n",
       "        (1): LogSoftmax(dim=-1)\n",
       "      )\n",
       "    )\n",
       "    (generator_9_dagger): RecurrentMolecularEncoder(\n",
       "      (encoder_linear): Sequential(\n",
       "        (0): Linear(in_features=34, out_features=488, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (recurrence): GRU(488, 292, num_layers=3, batch_first=True)\n",
       "      (postrecurrence_linear): Sequential(\n",
       "        (0): Linear(in_features=292, out_features=292, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (embedding_loc): Linear(in_features=292, out_features=292, bias=True)\n",
       "      (embedding_log_scale): Linear(in_features=292, out_features=292, bias=True)\n",
       "      (embedding_dist): DiagonalGaussian()\n",
       "    )\n",
       "    (generator_10): MolecularDecoder(\n",
       "      (pre_recurrence_linear): Sequential(\n",
       "        (0): Linear(in_features=292, out_features=292, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (recurrence): GRU(292, 501, num_layers=3, batch_first=True)\n",
       "      (decoder): Sequential(\n",
       "        (0): Linear(in_features=501, out_features=34, bias=True)\n",
       "        (1): LogSoftmax(dim=-1)\n",
       "      )\n",
       "    )\n",
       "    (generator_10_dagger): ConvMolecularEncoder(\n",
       "      (smiles_conv): Sequential(\n",
       "        (0): Conv1d(120, 9, kernel_size=(9,), stride=(1,))\n",
       "        (1): ReLU()\n",
       "        (2): Conv1d(9, 9, kernel_size=(9,), stride=(1,))\n",
       "        (3): ReLU()\n",
       "        (4): Conv1d(9, 10, kernel_size=(11,), stride=(1,))\n",
       "        (5): ReLU()\n",
       "      )\n",
       "      (smiles_linear): Sequential(\n",
       "        (0): Linear(in_features=80, out_features=292, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (embedding_loc): Linear(in_features=292, out_features=292, bias=True)\n",
       "      (embedding_log_scale): Linear(in_features=292, out_features=292, bias=True)\n",
       "      (embedding_dist): DiagonalGaussian()\n",
       "    )\n",
       "    (generator_11): MolecularDecoder(\n",
       "      (pre_recurrence_linear): Sequential(\n",
       "        (0): Linear(in_features=292, out_features=292, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (recurrence): GRU(292, 501, num_layers=3, batch_first=True)\n",
       "      (decoder): Sequential(\n",
       "        (0): Linear(in_features=501, out_features=34, bias=True)\n",
       "        (1): LogSoftmax(dim=-1)\n",
       "      )\n",
       "    )\n",
       "    (generator_11_dagger): RecurrentMolecularEncoder(\n",
       "      (encoder_linear): Sequential(\n",
       "        (0): Linear(in_features=34, out_features=501, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (recurrence): GRU(501, 292, num_layers=3, batch_first=True)\n",
       "      (postrecurrence_linear): Sequential(\n",
       "        (0): Linear(in_features=292, out_features=292, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (embedding_loc): Linear(in_features=292, out_features=292, bias=True)\n",
       "      (embedding_log_scale): Linear(in_features=292, out_features=292, bias=True)\n",
       "      (embedding_dist): DiagonalGaussian()\n",
       "    )\n",
       "    (generator_12): MolecularDecoder(\n",
       "      (pre_recurrence_linear): Sequential(\n",
       "        (0): Linear(in_features=435, out_features=435, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (recurrence): GRU(435, 50, num_layers=3, batch_first=True)\n",
       "      (decoder): Sequential(\n",
       "        (0): Linear(in_features=50, out_features=34, bias=True)\n",
       "        (1): LogSoftmax(dim=-1)\n",
       "      )\n",
       "    )\n",
       "    (generator_12_dagger): ConvMolecularEncoder(\n",
       "      (smiles_conv): Sequential(\n",
       "        (0): Conv1d(120, 9, kernel_size=(9,), stride=(1,))\n",
       "        (1): ReLU()\n",
       "        (2): Conv1d(9, 9, kernel_size=(9,), stride=(1,))\n",
       "        (3): ReLU()\n",
       "        (4): Conv1d(9, 10, kernel_size=(11,), stride=(1,))\n",
       "        (5): ReLU()\n",
       "      )\n",
       "      (smiles_linear): Sequential(\n",
       "        (0): Linear(in_features=80, out_features=435, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (embedding_loc): Linear(in_features=435, out_features=435, bias=True)\n",
       "      (embedding_log_scale): Linear(in_features=435, out_features=435, bias=True)\n",
       "      (embedding_dist): DiagonalGaussian()\n",
       "    )\n",
       "    (generator_13): MolecularDecoder(\n",
       "      (pre_recurrence_linear): Sequential(\n",
       "        (0): Linear(in_features=435, out_features=435, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (recurrence): GRU(435, 50, num_layers=3, batch_first=True)\n",
       "      (decoder): Sequential(\n",
       "        (0): Linear(in_features=50, out_features=34, bias=True)\n",
       "        (1): LogSoftmax(dim=-1)\n",
       "      )\n",
       "    )\n",
       "    (generator_13_dagger): RecurrentMolecularEncoder(\n",
       "      (encoder_linear): Sequential(\n",
       "        (0): Linear(in_features=34, out_features=50, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (recurrence): GRU(50, 435, num_layers=3, batch_first=True)\n",
       "      (postrecurrence_linear): Sequential(\n",
       "        (0): Linear(in_features=435, out_features=435, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (embedding_loc): Linear(in_features=435, out_features=435, bias=True)\n",
       "      (embedding_log_scale): Linear(in_features=435, out_features=435, bias=True)\n",
       "      (embedding_dist): DiagonalGaussian()\n",
       "    )\n",
       "    (generator_14): MolecularDecoder(\n",
       "      (pre_recurrence_linear): Sequential(\n",
       "        (0): Linear(in_features=435, out_features=435, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (recurrence): GRU(435, 488, num_layers=3, batch_first=True)\n",
       "      (decoder): Sequential(\n",
       "        (0): Linear(in_features=488, out_features=34, bias=True)\n",
       "        (1): LogSoftmax(dim=-1)\n",
       "      )\n",
       "    )\n",
       "    (generator_14_dagger): ConvMolecularEncoder(\n",
       "      (smiles_conv): Sequential(\n",
       "        (0): Conv1d(120, 9, kernel_size=(9,), stride=(1,))\n",
       "        (1): ReLU()\n",
       "        (2): Conv1d(9, 9, kernel_size=(9,), stride=(1,))\n",
       "        (3): ReLU()\n",
       "        (4): Conv1d(9, 10, kernel_size=(11,), stride=(1,))\n",
       "        (5): ReLU()\n",
       "      )\n",
       "      (smiles_linear): Sequential(\n",
       "        (0): Linear(in_features=80, out_features=435, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (embedding_loc): Linear(in_features=435, out_features=435, bias=True)\n",
       "      (embedding_log_scale): Linear(in_features=435, out_features=435, bias=True)\n",
       "      (embedding_dist): DiagonalGaussian()\n",
       "    )\n",
       "    (generator_15): MolecularDecoder(\n",
       "      (pre_recurrence_linear): Sequential(\n",
       "        (0): Linear(in_features=435, out_features=435, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (recurrence): GRU(435, 488, num_layers=3, batch_first=True)\n",
       "      (decoder): Sequential(\n",
       "        (0): Linear(in_features=488, out_features=34, bias=True)\n",
       "        (1): LogSoftmax(dim=-1)\n",
       "      )\n",
       "    )\n",
       "    (generator_15_dagger): RecurrentMolecularEncoder(\n",
       "      (encoder_linear): Sequential(\n",
       "        (0): Linear(in_features=34, out_features=488, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (recurrence): GRU(488, 435, num_layers=3, batch_first=True)\n",
       "      (postrecurrence_linear): Sequential(\n",
       "        (0): Linear(in_features=435, out_features=435, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (embedding_loc): Linear(in_features=435, out_features=435, bias=True)\n",
       "      (embedding_log_scale): Linear(in_features=435, out_features=435, bias=True)\n",
       "      (embedding_dist): DiagonalGaussian()\n",
       "    )\n",
       "    (generator_16): MolecularDecoder(\n",
       "      (pre_recurrence_linear): Sequential(\n",
       "        (0): Linear(in_features=435, out_features=435, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (recurrence): GRU(435, 501, num_layers=3, batch_first=True)\n",
       "      (decoder): Sequential(\n",
       "        (0): Linear(in_features=501, out_features=34, bias=True)\n",
       "        (1): LogSoftmax(dim=-1)\n",
       "      )\n",
       "    )\n",
       "    (generator_16_dagger): ConvMolecularEncoder(\n",
       "      (smiles_conv): Sequential(\n",
       "        (0): Conv1d(120, 9, kernel_size=(9,), stride=(1,))\n",
       "        (1): ReLU()\n",
       "        (2): Conv1d(9, 9, kernel_size=(9,), stride=(1,))\n",
       "        (3): ReLU()\n",
       "        (4): Conv1d(9, 10, kernel_size=(11,), stride=(1,))\n",
       "        (5): ReLU()\n",
       "      )\n",
       "      (smiles_linear): Sequential(\n",
       "        (0): Linear(in_features=80, out_features=435, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (embedding_loc): Linear(in_features=435, out_features=435, bias=True)\n",
       "      (embedding_log_scale): Linear(in_features=435, out_features=435, bias=True)\n",
       "      (embedding_dist): DiagonalGaussian()\n",
       "    )\n",
       "    (generator_17): MolecularDecoder(\n",
       "      (pre_recurrence_linear): Sequential(\n",
       "        (0): Linear(in_features=435, out_features=435, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (recurrence): GRU(435, 501, num_layers=3, batch_first=True)\n",
       "      (decoder): Sequential(\n",
       "        (0): Linear(in_features=501, out_features=34, bias=True)\n",
       "        (1): LogSoftmax(dim=-1)\n",
       "      )\n",
       "    )\n",
       "    (generator_17_dagger): RecurrentMolecularEncoder(\n",
       "      (encoder_linear): Sequential(\n",
       "        (0): Linear(in_features=34, out_features=501, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (recurrence): GRU(501, 435, num_layers=3, batch_first=True)\n",
       "      (postrecurrence_linear): Sequential(\n",
       "        (0): Linear(in_features=435, out_features=435, bias=True)\n",
       "        (1): SELU()\n",
       "      )\n",
       "      (embedding_loc): Linear(in_features=435, out_features=435, bias=True)\n",
       "      (embedding_log_scale): Linear(in_features=435, out_features=435, bias=True)\n",
       "      (embedding_dist): DiagonalGaussian()\n",
       "    )\n",
       "    (global_element_0): StandardNormal()\n",
       "    (global_element_1): StandardNormal()\n",
       "    (global_element_2): StandardNormal()\n",
       "    (global_element_3): StandardNormal()\n",
       "  )\n",
       "  (guide_temperatures): Sequential(\n",
       "    (0): Linear(in_features=4080, out_features=256, bias=True)\n",
       "    (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    (2): PReLU(num_parameters=1)\n",
       "    (3): Linear(in_features=256, out_features=2, bias=True)\n",
       "    (4): Softplus(beta=1, threshold=20)\n",
       "  )\n",
       "  (guide_arrow_weights): Sequential(\n",
       "    (0): Linear(in_features=4080, out_features=256, bias=True)\n",
       "    (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    (2): PReLU(num_parameters=1)\n",
       "    (3): Linear(in_features=256, out_features=44, bias=True)\n",
       "    (4): Softplus(beta=1, threshold=20)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_xs, valid_ys = list(valid_data_loader)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "m, recons = model(observations=valid_xs, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6519)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(recons == valid_xs).all(dim=-1).flatten().to(dtype=torch.float).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:categorical_bpl] *",
   "language": "python",
   "name": "conda-env-categorical_bpl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
