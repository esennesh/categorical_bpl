{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import collections\n",
    "import pyro\n",
    "import torch\n",
    "import numpy as np\n",
    "import data_loader.data_loaders as module_data\n",
    "import model.model as module_arch\n",
    "from parse_config import ConfigParser\n",
    "from trainer import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x7f9cc7429550>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seeds for reproducibility\n",
    "SEED = 123\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Args = collections.namedtuple('Args', 'config resume device')\n",
    "config = ConfigParser.from_args(Args(config='mnist_config.json', resume=None, device=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = config.get_logger('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup data_loader instances\n",
    "data_loader = config.init_obj('data_loader', module_data)\n",
    "valid_data_loader = data_loader.split_validation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# build model architecture, then print to console\n",
    "model = config.init_obj('arch', module_arch)\n",
    "model.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = config.init_obj('optimizer', pyro.optim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model, [], optimizer, config=config,\n",
    "                  data_loader=data_loader,\n",
    "                  valid_data_loader=valid_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/54000 (0%)] Loss: 89019.289062\n",
      "Train Epoch: 1 [1408/54000 (3%)] Loss: 51170.773438\n",
      "Train Epoch: 1 [2816/54000 (5%)] Loss: -87983.460938\n",
      "Train Epoch: 1 [4224/54000 (8%)] Loss: -176239.656250\n",
      "Train Epoch: 1 [5632/54000 (10%)] Loss: -231536.984375\n",
      "Train Epoch: 1 [7040/54000 (13%)] Loss: -410080.625000\n",
      "Train Epoch: 1 [8448/54000 (16%)] Loss: -395591.062500\n",
      "Train Epoch: 1 [9856/54000 (18%)] Loss: -397397.125000\n",
      "Train Epoch: 1 [11264/54000 (21%)] Loss: -405101.031250\n",
      "Train Epoch: 1 [12672/54000 (23%)] Loss: -406436.062500\n",
      "Train Epoch: 1 [14080/54000 (26%)] Loss: -424519.187500\n",
      "Train Epoch: 1 [15488/54000 (29%)] Loss: -434581.093750\n",
      "Train Epoch: 1 [16896/54000 (31%)] Loss: -511774.187500\n",
      "Train Epoch: 1 [18304/54000 (34%)] Loss: -441589.812500\n",
      "Train Epoch: 1 [19712/54000 (37%)] Loss: -447008.812500\n",
      "Train Epoch: 1 [21120/54000 (39%)] Loss: -467285.468750\n",
      "Train Epoch: 1 [22528/54000 (42%)] Loss: -515178.343750\n",
      "Train Epoch: 1 [23936/54000 (44%)] Loss: -518738.718750\n",
      "Train Epoch: 1 [25344/54000 (47%)] Loss: -487198.031250\n",
      "Train Epoch: 1 [26752/54000 (50%)] Loss: -550479.250000\n",
      "Train Epoch: 1 [28160/54000 (52%)] Loss: -493224.062500\n",
      "Train Epoch: 1 [29568/54000 (55%)] Loss: -484963.625000\n",
      "Train Epoch: 1 [30976/54000 (57%)] Loss: -497890.625000\n",
      "Train Epoch: 1 [32384/54000 (60%)] Loss: -487141.781250\n",
      "Train Epoch: 1 [33792/54000 (63%)] Loss: -499117.343750\n",
      "Train Epoch: 1 [35200/54000 (65%)] Loss: -519328.937500\n",
      "Train Epoch: 1 [36608/54000 (68%)] Loss: -512562.250000\n",
      "Train Epoch: 1 [38016/54000 (70%)] Loss: -519694.156250\n",
      "Train Epoch: 1 [39424/54000 (73%)] Loss: -499673.406250\n",
      "Train Epoch: 1 [40832/54000 (76%)] Loss: -580332.062500\n",
      "Train Epoch: 1 [42240/54000 (78%)] Loss: -571630.625000\n",
      "Train Epoch: 1 [43648/54000 (81%)] Loss: -565599.187500\n",
      "Train Epoch: 1 [45056/54000 (83%)] Loss: -497985.500000\n",
      "Train Epoch: 1 [46464/54000 (86%)] Loss: -507905.250000\n",
      "Train Epoch: 1 [47872/54000 (89%)] Loss: -598826.875000\n",
      "Train Epoch: 1 [49280/54000 (91%)] Loss: -536383.125000\n",
      "Train Epoch: 1 [50688/54000 (94%)] Loss: -504631.656250\n",
      "Train Epoch: 1 [52096/54000 (96%)] Loss: -532719.062500\n",
      "    epoch          : 1\n",
      "    loss           : -434449.83108038653\n",
      "    val_loss       : -595491.5066692074\n",
      "Train Epoch: 2 [0/54000 (0%)] Loss: -503144.312500\n",
      "Train Epoch: 2 [1408/54000 (3%)] Loss: -560760.000000\n",
      "Train Epoch: 2 [2816/54000 (5%)] Loss: -603550.000000\n",
      "Train Epoch: 2 [4224/54000 (8%)] Loss: -530236.625000\n",
      "Train Epoch: 2 [5632/54000 (10%)] Loss: -500722.968750\n",
      "Train Epoch: 2 [7040/54000 (13%)] Loss: -598691.875000\n",
      "Train Epoch: 2 [8448/54000 (16%)] Loss: -567113.875000\n",
      "Train Epoch: 2 [9856/54000 (18%)] Loss: -612450.437500\n",
      "Train Epoch: 2 [11264/54000 (21%)] Loss: -609262.875000\n",
      "Train Epoch: 2 [12672/54000 (23%)] Loss: -606008.062500\n",
      "Train Epoch: 2 [14080/54000 (26%)] Loss: -539702.500000\n",
      "Train Epoch: 2 [15488/54000 (29%)] Loss: -572227.187500\n",
      "Train Epoch: 2 [16896/54000 (31%)] Loss: -564938.125000\n",
      "Train Epoch: 2 [18304/54000 (34%)] Loss: -532649.812500\n",
      "Train Epoch: 2 [19712/54000 (37%)] Loss: -571299.625000\n",
      "Train Epoch: 2 [21120/54000 (39%)] Loss: -627567.625000\n",
      "Train Epoch: 2 [22528/54000 (42%)] Loss: -638886.375000\n",
      "Train Epoch: 2 [23936/54000 (44%)] Loss: -638436.125000\n",
      "Train Epoch: 2 [25344/54000 (47%)] Loss: -581836.500000\n",
      "Train Epoch: 2 [26752/54000 (50%)] Loss: -632894.250000\n",
      "Train Epoch: 2 [28160/54000 (52%)] Loss: -568158.750000\n",
      "Train Epoch: 2 [29568/54000 (55%)] Loss: -563459.625000\n",
      "Train Epoch: 2 [30976/54000 (57%)] Loss: -574405.375000\n",
      "Train Epoch: 2 [32384/54000 (60%)] Loss: -598376.875000\n",
      "Train Epoch: 2 [33792/54000 (63%)] Loss: -600855.625000\n",
      "Train Epoch: 2 [35200/54000 (65%)] Loss: -601258.875000\n",
      "Train Epoch: 2 [36608/54000 (68%)] Loss: -628072.500000\n",
      "Train Epoch: 2 [38016/54000 (70%)] Loss: -637213.750000\n",
      "Train Epoch: 2 [39424/54000 (73%)] Loss: -651951.500000\n",
      "Train Epoch: 2 [40832/54000 (76%)] Loss: -594272.875000\n",
      "Train Epoch: 2 [42240/54000 (78%)] Loss: -649120.187500\n",
      "Train Epoch: 2 [43648/54000 (81%)] Loss: -668895.125000\n",
      "Train Epoch: 2 [45056/54000 (83%)] Loss: -589948.875000\n",
      "Train Epoch: 2 [46464/54000 (86%)] Loss: -617140.125000\n",
      "Train Epoch: 2 [47872/54000 (89%)] Loss: -593117.687500\n",
      "Train Epoch: 2 [49280/54000 (91%)] Loss: -594894.687500\n",
      "Train Epoch: 2 [50688/54000 (94%)] Loss: -637021.000000\n",
      "Train Epoch: 2 [52096/54000 (96%)] Loss: -589561.562500\n",
      "    epoch          : 2\n",
      "    loss           : -590474.8062200957\n",
      "    val_loss       : -680570.3050685975\n",
      "Train Epoch: 3 [0/54000 (0%)] Loss: -637099.812500\n",
      "Train Epoch: 3 [1408/54000 (3%)] Loss: -651664.125000\n",
      "Train Epoch: 3 [2816/54000 (5%)] Loss: -597456.937500\n",
      "Train Epoch: 3 [4224/54000 (8%)] Loss: -658185.125000\n",
      "Train Epoch: 3 [5632/54000 (10%)] Loss: -644900.375000\n",
      "Train Epoch: 3 [7040/54000 (13%)] Loss: -590159.875000\n",
      "Train Epoch: 3 [8448/54000 (16%)] Loss: -629477.062500\n",
      "Train Epoch: 3 [9856/54000 (18%)] Loss: -668643.750000\n",
      "Train Epoch: 3 [11264/54000 (21%)] Loss: -658755.375000\n",
      "Train Epoch: 3 [12672/54000 (23%)] Loss: -680792.812500\n",
      "Train Epoch: 3 [14080/54000 (26%)] Loss: -637761.750000\n",
      "Train Epoch: 3 [15488/54000 (29%)] Loss: -596928.312500\n",
      "Train Epoch: 3 [16896/54000 (31%)] Loss: -652106.187500\n",
      "Train Epoch: 3 [18304/54000 (34%)] Loss: -608959.625000\n",
      "Train Epoch: 3 [19712/54000 (37%)] Loss: -651493.000000\n",
      "Train Epoch: 3 [21120/54000 (39%)] Loss: -669721.375000\n",
      "Train Epoch: 3 [22528/54000 (42%)] Loss: -644229.312500\n",
      "Train Epoch: 3 [23936/54000 (44%)] Loss: -654416.937500\n",
      "Train Epoch: 3 [25344/54000 (47%)] Loss: -635613.875000\n",
      "Train Epoch: 3 [26752/54000 (50%)] Loss: -682883.687500\n",
      "Train Epoch: 3 [28160/54000 (52%)] Loss: -634838.562500\n",
      "Train Epoch: 3 [29568/54000 (55%)] Loss: -643035.562500\n",
      "Train Epoch: 3 [30976/54000 (57%)] Loss: -654208.000000\n",
      "Train Epoch: 3 [32384/54000 (60%)] Loss: -638317.875000\n",
      "Train Epoch: 3 [33792/54000 (63%)] Loss: -648174.687500\n",
      "Train Epoch: 3 [35200/54000 (65%)] Loss: -624240.312500\n",
      "Train Epoch: 3 [36608/54000 (68%)] Loss: -671074.562500\n",
      "Train Epoch: 3 [38016/54000 (70%)] Loss: -676565.375000\n",
      "Train Epoch: 3 [39424/54000 (73%)] Loss: -655249.687500\n",
      "Train Epoch: 3 [40832/54000 (76%)] Loss: -687925.000000\n",
      "Train Epoch: 3 [42240/54000 (78%)] Loss: -682155.312500\n",
      "Train Epoch: 3 [43648/54000 (81%)] Loss: -726388.000000\n",
      "Train Epoch: 3 [45056/54000 (83%)] Loss: -674517.125000\n",
      "Train Epoch: 3 [46464/54000 (86%)] Loss: -665729.062500\n",
      "Train Epoch: 3 [47872/54000 (89%)] Loss: -668059.000000\n",
      "Train Epoch: 3 [49280/54000 (91%)] Loss: -646686.687500\n",
      "Train Epoch: 3 [50688/54000 (94%)] Loss: -683194.125000\n",
      "Train Epoch: 3 [52096/54000 (96%)] Loss: -647370.000000\n",
      "    epoch          : 3\n",
      "    loss           : -651624.6212619618\n",
      "    val_loss       : -717664.1118521341\n",
      "Train Epoch: 4 [0/54000 (0%)] Loss: -691820.500000\n",
      "Train Epoch: 4 [1408/54000 (3%)] Loss: -672180.812500\n",
      "Train Epoch: 4 [2816/54000 (5%)] Loss: -653671.625000\n",
      "Train Epoch: 4 [4224/54000 (8%)] Loss: -641486.125000\n",
      "Train Epoch: 4 [5632/54000 (10%)] Loss: -738244.375000\n",
      "Train Epoch: 4 [7040/54000 (13%)] Loss: -702044.375000\n",
      "Train Epoch: 4 [8448/54000 (16%)] Loss: -689359.125000\n",
      "Train Epoch: 4 [9856/54000 (18%)] Loss: -667786.937500\n",
      "Train Epoch: 4 [11264/54000 (21%)] Loss: -714256.000000\n",
      "Train Epoch: 4 [12672/54000 (23%)] Loss: -663004.875000\n",
      "Train Epoch: 4 [14080/54000 (26%)] Loss: -723510.750000\n",
      "Train Epoch: 4 [15488/54000 (29%)] Loss: -667100.000000\n",
      "Train Epoch: 4 [16896/54000 (31%)] Loss: -719048.250000\n",
      "Train Epoch: 4 [18304/54000 (34%)] Loss: -676947.062500\n",
      "Train Epoch: 4 [19712/54000 (37%)] Loss: -693859.625000\n",
      "Train Epoch: 4 [21120/54000 (39%)] Loss: -693152.125000\n",
      "Train Epoch: 4 [22528/54000 (42%)] Loss: -713319.500000\n",
      "Train Epoch: 4 [23936/54000 (44%)] Loss: -686839.812500\n",
      "Train Epoch: 4 [25344/54000 (47%)] Loss: -760464.875000\n",
      "Train Epoch: 4 [26752/54000 (50%)] Loss: -685879.312500\n",
      "Train Epoch: 4 [28160/54000 (52%)] Loss: -748644.875000\n",
      "Train Epoch: 4 [29568/54000 (55%)] Loss: -749529.625000\n",
      "Train Epoch: 4 [30976/54000 (57%)] Loss: -689358.937500\n",
      "Train Epoch: 4 [32384/54000 (60%)] Loss: -678423.437500\n",
      "Train Epoch: 4 [33792/54000 (63%)] Loss: -685479.562500\n",
      "Train Epoch: 4 [35200/54000 (65%)] Loss: -684613.125000\n",
      "Train Epoch: 4 [36608/54000 (68%)] Loss: -665149.625000\n",
      "Train Epoch: 4 [38016/54000 (70%)] Loss: -667591.125000\n",
      "Train Epoch: 4 [39424/54000 (73%)] Loss: -681961.375000\n",
      "Train Epoch: 4 [40832/54000 (76%)] Loss: -727194.937500\n",
      "Train Epoch: 4 [42240/54000 (78%)] Loss: -715931.250000\n",
      "Train Epoch: 4 [43648/54000 (81%)] Loss: -666901.250000\n",
      "Train Epoch: 4 [45056/54000 (83%)] Loss: -701982.562500\n",
      "Train Epoch: 4 [46464/54000 (86%)] Loss: -697359.375000\n",
      "Train Epoch: 4 [47872/54000 (89%)] Loss: -687962.312500\n",
      "Train Epoch: 4 [49280/54000 (91%)] Loss: -685245.375000\n",
      "Train Epoch: 4 [50688/54000 (94%)] Loss: -677351.375000\n",
      "Train Epoch: 4 [52096/54000 (96%)] Loss: -661765.250000\n",
      "    epoch          : 4\n",
      "    loss           : -689499.4285287082\n",
      "    val_loss       : -739791.8900533536\n",
      "Train Epoch: 5 [0/54000 (0%)] Loss: -689967.750000\n",
      "Train Epoch: 5 [1408/54000 (3%)] Loss: -767888.812500\n",
      "Train Epoch: 5 [2816/54000 (5%)] Loss: -697334.812500\n",
      "Train Epoch: 5 [4224/54000 (8%)] Loss: -703219.750000\n",
      "Train Epoch: 5 [5632/54000 (10%)] Loss: -778819.375000\n",
      "Train Epoch: 5 [7040/54000 (13%)] Loss: -691242.312500\n",
      "Train Epoch: 5 [8448/54000 (16%)] Loss: -687191.000000\n",
      "Train Epoch: 5 [9856/54000 (18%)] Loss: -744599.875000\n",
      "Train Epoch: 5 [11264/54000 (21%)] Loss: -685037.500000\n",
      "Train Epoch: 5 [12672/54000 (23%)] Loss: -740435.875000\n",
      "Train Epoch: 5 [14080/54000 (26%)] Loss: -737038.250000\n",
      "Train Epoch: 5 [15488/54000 (29%)] Loss: -682926.750000\n",
      "Train Epoch: 5 [16896/54000 (31%)] Loss: -691410.875000\n",
      "Train Epoch: 5 [18304/54000 (34%)] Loss: -742901.375000\n",
      "Train Epoch: 5 [19712/54000 (37%)] Loss: -732906.812500\n",
      "Train Epoch: 5 [21120/54000 (39%)] Loss: -693413.562500\n",
      "Train Epoch: 5 [22528/54000 (42%)] Loss: -705229.062500\n",
      "Train Epoch: 5 [23936/54000 (44%)] Loss: -704107.562500\n",
      "Train Epoch: 5 [25344/54000 (47%)] Loss: -695849.250000\n",
      "Train Epoch: 5 [26752/54000 (50%)] Loss: -731271.750000\n",
      "Train Epoch: 5 [28160/54000 (52%)] Loss: -700770.437500\n",
      "Train Epoch: 5 [29568/54000 (55%)] Loss: -772397.500000\n",
      "Train Epoch: 5 [30976/54000 (57%)] Loss: -724707.750000\n",
      "Train Epoch: 5 [32384/54000 (60%)] Loss: -724913.375000\n",
      "Train Epoch: 5 [33792/54000 (63%)] Loss: -683663.125000\n",
      "Train Epoch: 5 [35200/54000 (65%)] Loss: -735402.500000\n",
      "Train Epoch: 5 [36608/54000 (68%)] Loss: -707498.375000\n",
      "Train Epoch: 5 [38016/54000 (70%)] Loss: -715264.125000\n",
      "Train Epoch: 5 [39424/54000 (73%)] Loss: -690524.500000\n",
      "Train Epoch: 5 [40832/54000 (76%)] Loss: -690846.312500\n",
      "Train Epoch: 5 [42240/54000 (78%)] Loss: -688837.375000\n",
      "Train Epoch: 5 [43648/54000 (81%)] Loss: -737439.625000\n",
      "Train Epoch: 5 [45056/54000 (83%)] Loss: -726392.250000\n",
      "Train Epoch: 5 [46464/54000 (86%)] Loss: -714265.062500\n",
      "Train Epoch: 5 [47872/54000 (89%)] Loss: -719926.375000\n",
      "Train Epoch: 5 [49280/54000 (91%)] Loss: -734156.875000\n",
      "Train Epoch: 5 [50688/54000 (94%)] Loss: -713300.562500\n",
      "Train Epoch: 5 [52096/54000 (96%)] Loss: -703574.937500\n",
      "    epoch          : 5\n",
      "    loss           : -715975.266895933\n",
      "    val_loss       : -756317.6314786585\n",
      "Saving checkpoint: saved/models/Mnist_VaeCategory/0422_221614/checkpoint-epoch5.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 6 [0/54000 (0%)] Loss: -712161.062500\n",
      "Train Epoch: 6 [1408/54000 (3%)] Loss: -696168.375000\n",
      "Train Epoch: 6 [2816/54000 (5%)] Loss: -710993.437500\n",
      "Train Epoch: 6 [4224/54000 (8%)] Loss: -744524.250000\n",
      "Train Epoch: 6 [5632/54000 (10%)] Loss: -717269.625000\n",
      "Train Epoch: 6 [7040/54000 (13%)] Loss: -723358.062500\n",
      "Train Epoch: 6 [8448/54000 (16%)] Loss: -724710.125000\n",
      "Train Epoch: 6 [9856/54000 (18%)] Loss: -731121.187500\n",
      "Train Epoch: 6 [11264/54000 (21%)] Loss: -801114.937500\n",
      "Train Epoch: 6 [12672/54000 (23%)] Loss: -811454.187500\n",
      "Train Epoch: 6 [14080/54000 (26%)] Loss: -724982.125000\n",
      "Train Epoch: 6 [15488/54000 (29%)] Loss: -708584.750000\n",
      "Train Epoch: 6 [16896/54000 (31%)] Loss: -715356.875000\n",
      "Train Epoch: 6 [18304/54000 (34%)] Loss: -718276.687500\n",
      "Train Epoch: 6 [19712/54000 (37%)] Loss: -721239.750000\n",
      "Train Epoch: 6 [21120/54000 (39%)] Loss: -728561.187500\n",
      "Train Epoch: 6 [22528/54000 (42%)] Loss: -714472.500000\n",
      "Train Epoch: 6 [23936/54000 (44%)] Loss: -717281.312500\n",
      "Train Epoch: 6 [25344/54000 (47%)] Loss: -718501.375000\n",
      "Train Epoch: 6 [26752/54000 (50%)] Loss: -812803.437500\n",
      "Train Epoch: 6 [28160/54000 (52%)] Loss: -746514.437500\n",
      "Train Epoch: 6 [29568/54000 (55%)] Loss: -730216.250000\n",
      "Train Epoch: 6 [30976/54000 (57%)] Loss: -751893.437500\n",
      "Train Epoch: 6 [32384/54000 (60%)] Loss: -705330.062500\n",
      "Train Epoch: 6 [33792/54000 (63%)] Loss: -732334.812500\n",
      "Train Epoch: 6 [35200/54000 (65%)] Loss: -703117.875000\n",
      "Train Epoch: 6 [36608/54000 (68%)] Loss: -720760.062500\n",
      "Train Epoch: 6 [38016/54000 (70%)] Loss: -714394.000000\n",
      "Train Epoch: 6 [39424/54000 (73%)] Loss: -721647.187500\n",
      "Train Epoch: 6 [40832/54000 (76%)] Loss: -808284.812500\n",
      "Train Epoch: 6 [42240/54000 (78%)] Loss: -809158.375000\n",
      "Train Epoch: 6 [43648/54000 (81%)] Loss: -817190.062500\n",
      "Train Epoch: 6 [45056/54000 (83%)] Loss: -712488.000000\n",
      "Train Epoch: 6 [46464/54000 (86%)] Loss: -730328.875000\n",
      "Train Epoch: 6 [47872/54000 (89%)] Loss: -733296.500000\n",
      "Train Epoch: 6 [49280/54000 (91%)] Loss: -733672.687500\n",
      "Train Epoch: 6 [50688/54000 (94%)] Loss: -744808.750000\n",
      "Train Epoch: 6 [52096/54000 (96%)] Loss: -714015.000000\n",
      "    epoch          : 6\n",
      "    loss           : -734450.3048744019\n",
      "    val_loss       : -765907.4220655488\n",
      "Train Epoch: 7 [0/54000 (0%)] Loss: -817497.312500\n",
      "Train Epoch: 7 [1408/54000 (3%)] Loss: -747553.125000\n",
      "Train Epoch: 7 [2816/54000 (5%)] Loss: -752106.125000\n",
      "Train Epoch: 7 [4224/54000 (8%)] Loss: -711233.937500\n",
      "Train Epoch: 7 [5632/54000 (10%)] Loss: -715996.250000\n",
      "Train Epoch: 7 [7040/54000 (13%)] Loss: -722499.625000\n",
      "Train Epoch: 7 [8448/54000 (16%)] Loss: -716078.812500\n",
      "Train Epoch: 7 [9856/54000 (18%)] Loss: -727727.312500\n",
      "Train Epoch: 7 [11264/54000 (21%)] Loss: -721599.937500\n",
      "Train Epoch: 7 [12672/54000 (23%)] Loss: -693747.875000\n",
      "Train Epoch: 7 [14080/54000 (26%)] Loss: -768891.687500\n",
      "Train Epoch: 7 [15488/54000 (29%)] Loss: -722390.125000\n",
      "Train Epoch: 7 [16896/54000 (31%)] Loss: -730726.687500\n",
      "Train Epoch: 7 [18304/54000 (34%)] Loss: -843936.437500\n",
      "Train Epoch: 7 [19712/54000 (37%)] Loss: -722174.812500\n",
      "Train Epoch: 7 [21120/54000 (39%)] Loss: -712368.375000\n",
      "Train Epoch: 7 [22528/54000 (42%)] Loss: -741771.187500\n",
      "Train Epoch: 7 [23936/54000 (44%)] Loss: -725628.500000\n",
      "Train Epoch: 7 [25344/54000 (47%)] Loss: -726091.375000\n",
      "Train Epoch: 7 [26752/54000 (50%)] Loss: -760436.625000\n",
      "Train Epoch: 7 [28160/54000 (52%)] Loss: -754121.687500\n",
      "Train Epoch: 7 [29568/54000 (55%)] Loss: -726638.062500\n",
      "Train Epoch: 7 [30976/54000 (57%)] Loss: -725943.437500\n",
      "Train Epoch: 7 [32384/54000 (60%)] Loss: -724558.750000\n",
      "Train Epoch: 7 [33792/54000 (63%)] Loss: -754823.312500\n",
      "Train Epoch: 7 [35200/54000 (65%)] Loss: -782598.437500\n",
      "Train Epoch: 7 [36608/54000 (68%)] Loss: -709600.687500\n",
      "Train Epoch: 7 [38016/54000 (70%)] Loss: -736113.875000\n",
      "Train Epoch: 7 [39424/54000 (73%)] Loss: -745724.375000\n",
      "Train Epoch: 7 [40832/54000 (76%)] Loss: -738556.625000\n",
      "Train Epoch: 7 [42240/54000 (78%)] Loss: -822723.875000\n",
      "Train Epoch: 7 [43648/54000 (81%)] Loss: -723032.625000\n",
      "Train Epoch: 7 [45056/54000 (83%)] Loss: -746946.937500\n",
      "Train Epoch: 7 [46464/54000 (86%)] Loss: -736530.437500\n",
      "Train Epoch: 7 [47872/54000 (89%)] Loss: -745703.187500\n",
      "Train Epoch: 7 [49280/54000 (91%)] Loss: -754768.500000\n",
      "Train Epoch: 7 [50688/54000 (94%)] Loss: -761324.062500\n",
      "Train Epoch: 7 [52096/54000 (96%)] Loss: -742724.562500\n",
      "    epoch          : 7\n",
      "    loss           : -748476.127541866\n",
      "    val_loss       : -770690.6962652439\n",
      "Train Epoch: 8 [0/54000 (0%)] Loss: -734140.000000\n",
      "Train Epoch: 8 [1408/54000 (3%)] Loss: -730145.312500\n",
      "Train Epoch: 8 [2816/54000 (5%)] Loss: -761385.125000\n",
      "Train Epoch: 8 [4224/54000 (8%)] Loss: -774347.187500\n",
      "Train Epoch: 8 [5632/54000 (10%)] Loss: -746233.500000\n",
      "Train Epoch: 8 [7040/54000 (13%)] Loss: -732909.437500\n",
      "Train Epoch: 8 [8448/54000 (16%)] Loss: -741484.375000\n",
      "Train Epoch: 8 [9856/54000 (18%)] Loss: -725545.437500\n",
      "Train Epoch: 8 [11264/54000 (21%)] Loss: -751636.125000\n",
      "Train Epoch: 8 [12672/54000 (23%)] Loss: -738301.125000\n",
      "Train Epoch: 8 [14080/54000 (26%)] Loss: -734250.250000\n",
      "Train Epoch: 8 [15488/54000 (29%)] Loss: -734362.750000\n",
      "Train Epoch: 8 [16896/54000 (31%)] Loss: -756049.937500\n",
      "Train Epoch: 8 [18304/54000 (34%)] Loss: -728393.312500\n",
      "Train Epoch: 8 [19712/54000 (37%)] Loss: -840901.812500\n",
      "Train Epoch: 8 [21120/54000 (39%)] Loss: -733595.062500\n",
      "Train Epoch: 8 [22528/54000 (42%)] Loss: -711188.125000\n",
      "Train Epoch: 8 [23936/54000 (44%)] Loss: -742022.375000\n",
      "Train Epoch: 8 [25344/54000 (47%)] Loss: -728800.000000\n",
      "Train Epoch: 8 [26752/54000 (50%)] Loss: -744765.062500\n",
      "Train Epoch: 8 [28160/54000 (52%)] Loss: -763254.437500\n",
      "Train Epoch: 8 [29568/54000 (55%)] Loss: -762319.812500\n",
      "Train Epoch: 8 [30976/54000 (57%)] Loss: -742176.750000\n",
      "Train Epoch: 8 [32384/54000 (60%)] Loss: -735348.375000\n",
      "Train Epoch: 8 [33792/54000 (63%)] Loss: -760394.375000\n",
      "Train Epoch: 8 [35200/54000 (65%)] Loss: -741426.000000\n",
      "Train Epoch: 8 [36608/54000 (68%)] Loss: -740910.437500\n",
      "Train Epoch: 8 [38016/54000 (70%)] Loss: -722520.875000\n",
      "Train Epoch: 8 [39424/54000 (73%)] Loss: -736219.312500\n",
      "Train Epoch: 8 [40832/54000 (76%)] Loss: -733910.250000\n",
      "Train Epoch: 8 [42240/54000 (78%)] Loss: -726292.000000\n",
      "Train Epoch: 8 [43648/54000 (81%)] Loss: -765521.812500\n",
      "Train Epoch: 8 [45056/54000 (83%)] Loss: -772637.812500\n",
      "Train Epoch: 8 [46464/54000 (86%)] Loss: -770909.375000\n",
      "Train Epoch: 8 [47872/54000 (89%)] Loss: -783702.437500\n",
      "Train Epoch: 8 [49280/54000 (91%)] Loss: -798398.437500\n",
      "Train Epoch: 8 [50688/54000 (94%)] Loss: -739102.000000\n",
      "Train Epoch: 8 [52096/54000 (96%)] Loss: -722370.062500\n",
      "    epoch          : 8\n",
      "    loss           : -758169.1931818182\n",
      "    val_loss       : -776166.7069359756\n",
      "Train Epoch: 9 [0/54000 (0%)] Loss: -728237.687500\n",
      "Train Epoch: 9 [1408/54000 (3%)] Loss: -770192.000000\n",
      "Train Epoch: 9 [2816/54000 (5%)] Loss: -729306.000000\n",
      "Train Epoch: 9 [4224/54000 (8%)] Loss: -757977.125000\n",
      "Train Epoch: 9 [5632/54000 (10%)] Loss: -757144.250000\n",
      "Train Epoch: 9 [7040/54000 (13%)] Loss: -763981.625000\n",
      "Train Epoch: 9 [8448/54000 (16%)] Loss: -796009.250000\n",
      "Train Epoch: 9 [9856/54000 (18%)] Loss: -755861.125000\n",
      "Train Epoch: 9 [11264/54000 (21%)] Loss: -759150.687500\n",
      "Train Epoch: 9 [12672/54000 (23%)] Loss: -736163.000000\n",
      "Train Epoch: 9 [14080/54000 (26%)] Loss: -719643.125000\n",
      "Train Epoch: 9 [15488/54000 (29%)] Loss: -796797.125000\n",
      "Train Epoch: 9 [16896/54000 (31%)] Loss: -750656.250000\n",
      "Train Epoch: 9 [18304/54000 (34%)] Loss: -739906.562500\n",
      "Train Epoch: 9 [19712/54000 (37%)] Loss: -738525.375000\n",
      "Train Epoch: 9 [21120/54000 (39%)] Loss: -724426.625000\n",
      "Train Epoch: 9 [22528/54000 (42%)] Loss: -773625.500000\n",
      "Train Epoch: 9 [23936/54000 (44%)] Loss: -757658.250000\n",
      "Train Epoch: 9 [25344/54000 (47%)] Loss: -762061.125000\n",
      "Train Epoch: 9 [26752/54000 (50%)] Loss: -757479.500000\n",
      "Train Epoch: 9 [28160/54000 (52%)] Loss: -765262.062500\n",
      "Train Epoch: 9 [29568/54000 (55%)] Loss: -772237.437500\n",
      "Train Epoch: 9 [30976/54000 (57%)] Loss: -753967.375000\n",
      "Train Epoch: 9 [32384/54000 (60%)] Loss: -738913.062500\n",
      "Train Epoch: 9 [33792/54000 (63%)] Loss: -737987.437500\n",
      "Train Epoch: 9 [35200/54000 (65%)] Loss: -842696.500000\n",
      "Train Epoch: 9 [36608/54000 (68%)] Loss: -854579.625000\n",
      "Train Epoch: 9 [38016/54000 (70%)] Loss: -792234.250000\n",
      "Train Epoch: 9 [39424/54000 (73%)] Loss: -729916.250000\n",
      "Train Epoch: 9 [40832/54000 (76%)] Loss: -746149.375000\n",
      "Train Epoch: 9 [42240/54000 (78%)] Loss: -751489.625000\n",
      "Train Epoch: 9 [43648/54000 (81%)] Loss: -740939.187500\n",
      "Train Epoch: 9 [45056/54000 (83%)] Loss: -727920.062500\n",
      "Train Epoch: 9 [46464/54000 (86%)] Loss: -750551.375000\n",
      "Train Epoch: 9 [47872/54000 (89%)] Loss: -757269.937500\n",
      "Train Epoch: 9 [49280/54000 (91%)] Loss: -764936.500000\n",
      "Train Epoch: 9 [50688/54000 (94%)] Loss: -737892.000000\n",
      "Train Epoch: 9 [52096/54000 (96%)] Loss: -759895.062500\n",
      "    epoch          : 9\n",
      "    loss           : -765123.7275717703\n",
      "    val_loss       : -781329.9422637195\n",
      "Train Epoch: 10 [0/54000 (0%)] Loss: -739081.500000\n",
      "Train Epoch: 10 [1408/54000 (3%)] Loss: -771794.125000\n",
      "Train Epoch: 10 [2816/54000 (5%)] Loss: -771284.750000\n",
      "Train Epoch: 10 [4224/54000 (8%)] Loss: -744848.000000\n",
      "Train Epoch: 10 [5632/54000 (10%)] Loss: -762426.937500\n",
      "Train Epoch: 10 [7040/54000 (13%)] Loss: -755319.250000\n",
      "Train Epoch: 10 [8448/54000 (16%)] Loss: -743224.500000\n",
      "Train Epoch: 10 [9856/54000 (18%)] Loss: -773418.000000\n",
      "Train Epoch: 10 [11264/54000 (21%)] Loss: -792351.812500\n",
      "Train Epoch: 10 [12672/54000 (23%)] Loss: -738710.437500\n",
      "Train Epoch: 10 [14080/54000 (26%)] Loss: -742536.562500\n",
      "Train Epoch: 10 [15488/54000 (29%)] Loss: -852317.687500\n",
      "Train Epoch: 10 [16896/54000 (31%)] Loss: -780461.562500\n",
      "Train Epoch: 10 [18304/54000 (34%)] Loss: -757484.687500\n",
      "Train Epoch: 10 [19712/54000 (37%)] Loss: -783354.500000\n",
      "Train Epoch: 10 [21120/54000 (39%)] Loss: -838824.625000\n",
      "Train Epoch: 10 [22528/54000 (42%)] Loss: -855674.687500\n",
      "Train Epoch: 10 [23936/54000 (44%)] Loss: -762218.562500\n",
      "Train Epoch: 10 [25344/54000 (47%)] Loss: -731892.125000\n",
      "Train Epoch: 10 [26752/54000 (50%)] Loss: -733687.437500\n",
      "Train Epoch: 10 [28160/54000 (52%)] Loss: -806250.750000\n",
      "Train Epoch: 10 [29568/54000 (55%)] Loss: -752132.937500\n",
      "Train Epoch: 10 [30976/54000 (57%)] Loss: -761563.875000\n",
      "Train Epoch: 10 [32384/54000 (60%)] Loss: -739158.125000\n",
      "Train Epoch: 10 [33792/54000 (63%)] Loss: -749986.937500\n",
      "Train Epoch: 10 [35200/54000 (65%)] Loss: -741553.750000\n",
      "Train Epoch: 10 [36608/54000 (68%)] Loss: -780047.625000\n",
      "Train Epoch: 10 [38016/54000 (70%)] Loss: -767542.375000\n",
      "Train Epoch: 10 [39424/54000 (73%)] Loss: -768409.812500\n",
      "Train Epoch: 10 [40832/54000 (76%)] Loss: -761114.937500\n",
      "Train Epoch: 10 [42240/54000 (78%)] Loss: -805449.000000\n",
      "Train Epoch: 10 [43648/54000 (81%)] Loss: -807028.125000\n",
      "Train Epoch: 10 [45056/54000 (83%)] Loss: -789655.125000\n",
      "Train Epoch: 10 [46464/54000 (86%)] Loss: -807757.625000\n",
      "Train Epoch: 10 [47872/54000 (89%)] Loss: -751449.875000\n",
      "Train Epoch: 10 [49280/54000 (91%)] Loss: -797278.562500\n",
      "Train Epoch: 10 [50688/54000 (94%)] Loss: -736237.312500\n",
      "Train Epoch: 10 [52096/54000 (96%)] Loss: -768475.562500\n",
      "    epoch          : 10\n",
      "    loss           : -770319.3569078947\n",
      "    val_loss       : -781672.59375\n",
      "Saving checkpoint: saved/models/Mnist_VaeCategory/0422_221614/checkpoint-epoch10.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 11 [0/54000 (0%)] Loss: -756508.625000\n",
      "Train Epoch: 11 [1408/54000 (3%)] Loss: -748504.812500\n",
      "Train Epoch: 11 [2816/54000 (5%)] Loss: -749658.187500\n",
      "Train Epoch: 11 [4224/54000 (8%)] Loss: -773098.250000\n",
      "Train Epoch: 11 [5632/54000 (10%)] Loss: -754075.687500\n",
      "Train Epoch: 11 [7040/54000 (13%)] Loss: -858648.750000\n",
      "Train Epoch: 11 [8448/54000 (16%)] Loss: -756369.750000\n",
      "Train Epoch: 11 [9856/54000 (18%)] Loss: -774903.250000\n",
      "Train Epoch: 11 [11264/54000 (21%)] Loss: -850631.062500\n",
      "Train Epoch: 11 [12672/54000 (23%)] Loss: -804291.625000\n",
      "Train Epoch: 11 [14080/54000 (26%)] Loss: -790600.125000\n",
      "Train Epoch: 11 [15488/54000 (29%)] Loss: -749169.937500\n",
      "Train Epoch: 11 [16896/54000 (31%)] Loss: -735966.187500\n",
      "Train Epoch: 11 [18304/54000 (34%)] Loss: -763657.125000\n",
      "Train Epoch: 11 [19712/54000 (37%)] Loss: -772972.062500\n",
      "Train Epoch: 11 [21120/54000 (39%)] Loss: -744684.937500\n",
      "Train Epoch: 11 [22528/54000 (42%)] Loss: -748487.812500\n",
      "Train Epoch: 11 [23936/54000 (44%)] Loss: -785361.062500\n",
      "Train Epoch: 11 [25344/54000 (47%)] Loss: -853193.187500\n",
      "Train Epoch: 11 [26752/54000 (50%)] Loss: -776431.250000\n",
      "Train Epoch: 11 [28160/54000 (52%)] Loss: -773364.812500\n",
      "Train Epoch: 11 [29568/54000 (55%)] Loss: -758153.312500\n",
      "Train Epoch: 11 [30976/54000 (57%)] Loss: -815702.437500\n",
      "Train Epoch: 11 [32384/54000 (60%)] Loss: -738861.187500\n",
      "Train Epoch: 11 [33792/54000 (63%)] Loss: -775124.125000\n",
      "Train Epoch: 11 [35200/54000 (65%)] Loss: -747440.125000\n",
      "Train Epoch: 11 [36608/54000 (68%)] Loss: -850224.250000\n",
      "Train Epoch: 11 [38016/54000 (70%)] Loss: -766999.250000\n",
      "Train Epoch: 11 [39424/54000 (73%)] Loss: -772827.500000\n",
      "Train Epoch: 11 [40832/54000 (76%)] Loss: -744506.875000\n",
      "Train Epoch: 11 [42240/54000 (78%)] Loss: -806588.187500\n",
      "Train Epoch: 11 [43648/54000 (81%)] Loss: -760025.125000\n",
      "Train Epoch: 11 [45056/54000 (83%)] Loss: -777766.437500\n",
      "Train Epoch: 11 [46464/54000 (86%)] Loss: -770891.000000\n",
      "Train Epoch: 11 [47872/54000 (89%)] Loss: -795640.625000\n",
      "Train Epoch: 11 [49280/54000 (91%)] Loss: -813202.875000\n",
      "Train Epoch: 11 [50688/54000 (94%)] Loss: -746384.875000\n",
      "Train Epoch: 11 [52096/54000 (96%)] Loss: -746525.125000\n",
      "    epoch          : 11\n",
      "    loss           : -774905.4249401914\n",
      "    val_loss       : -785397.3147865854\n",
      "Train Epoch: 12 [0/54000 (0%)] Loss: -748421.375000\n",
      "Train Epoch: 12 [1408/54000 (3%)] Loss: -778765.125000\n",
      "Train Epoch: 12 [2816/54000 (5%)] Loss: -776924.625000\n",
      "Train Epoch: 12 [4224/54000 (8%)] Loss: -776764.500000\n",
      "Train Epoch: 12 [5632/54000 (10%)] Loss: -790622.937500\n",
      "Train Epoch: 12 [7040/54000 (13%)] Loss: -777756.812500\n",
      "Train Epoch: 12 [8448/54000 (16%)] Loss: -849849.125000\n",
      "Train Epoch: 12 [9856/54000 (18%)] Loss: -850101.062500\n",
      "Train Epoch: 12 [11264/54000 (21%)] Loss: -769031.250000\n",
      "Train Epoch: 12 [12672/54000 (23%)] Loss: -741689.750000\n",
      "Train Epoch: 12 [14080/54000 (26%)] Loss: -734100.437500\n",
      "Train Epoch: 12 [15488/54000 (29%)] Loss: -806416.625000\n",
      "Train Epoch: 12 [16896/54000 (31%)] Loss: -781722.562500\n",
      "Train Epoch: 12 [18304/54000 (34%)] Loss: -791299.062500\n",
      "Train Epoch: 12 [19712/54000 (37%)] Loss: -753952.750000\n",
      "Train Epoch: 12 [21120/54000 (39%)] Loss: -748232.937500\n",
      "Train Epoch: 12 [22528/54000 (42%)] Loss: -864680.750000\n",
      "Train Epoch: 12 [23936/54000 (44%)] Loss: -848973.312500\n",
      "Train Epoch: 12 [25344/54000 (47%)] Loss: -859849.937500\n",
      "Train Epoch: 12 [26752/54000 (50%)] Loss: -850676.750000\n",
      "Train Epoch: 12 [28160/54000 (52%)] Loss: -768401.000000\n",
      "Train Epoch: 12 [29568/54000 (55%)] Loss: -769076.062500\n",
      "Train Epoch: 12 [30976/54000 (57%)] Loss: -785077.750000\n",
      "Train Epoch: 12 [32384/54000 (60%)] Loss: -782691.250000\n",
      "Train Epoch: 12 [33792/54000 (63%)] Loss: -797706.875000\n",
      "Train Epoch: 12 [35200/54000 (65%)] Loss: -771496.750000\n",
      "Train Epoch: 12 [36608/54000 (68%)] Loss: -805395.437500\n",
      "Train Epoch: 12 [38016/54000 (70%)] Loss: -782111.937500\n",
      "Train Epoch: 12 [39424/54000 (73%)] Loss: -746209.625000\n",
      "Train Epoch: 12 [40832/54000 (76%)] Loss: -777838.000000\n",
      "Train Epoch: 12 [42240/54000 (78%)] Loss: -798477.875000\n",
      "Train Epoch: 12 [43648/54000 (81%)] Loss: -772102.437500\n",
      "Train Epoch: 12 [45056/54000 (83%)] Loss: -777811.312500\n",
      "Train Epoch: 12 [46464/54000 (86%)] Loss: -753238.187500\n",
      "Train Epoch: 12 [47872/54000 (89%)] Loss: -864599.625000\n",
      "Train Epoch: 12 [49280/54000 (91%)] Loss: -796675.250000\n",
      "Train Epoch: 12 [50688/54000 (94%)] Loss: -792919.375000\n",
      "Train Epoch: 12 [52096/54000 (96%)] Loss: -748421.000000\n",
      "    epoch          : 12\n",
      "    loss           : -778681.8821770335\n",
      "    val_loss       : -788771.651105183\n",
      "Train Epoch: 13 [0/54000 (0%)] Loss: -859671.687500\n",
      "Train Epoch: 13 [1408/54000 (3%)] Loss: -758008.562500\n",
      "Train Epoch: 13 [2816/54000 (5%)] Loss: -753162.875000\n",
      "Train Epoch: 13 [4224/54000 (8%)] Loss: -746715.000000\n",
      "Train Epoch: 13 [5632/54000 (10%)] Loss: -785251.375000\n",
      "Train Epoch: 13 [7040/54000 (13%)] Loss: -857309.562500\n",
      "Train Epoch: 13 [8448/54000 (16%)] Loss: -771006.375000\n",
      "Train Epoch: 13 [9856/54000 (18%)] Loss: -750280.625000\n",
      "Train Epoch: 13 [11264/54000 (21%)] Loss: -767661.375000\n",
      "Train Epoch: 13 [12672/54000 (23%)] Loss: -788404.375000\n",
      "Train Epoch: 13 [14080/54000 (26%)] Loss: -794605.625000\n",
      "Train Epoch: 13 [15488/54000 (29%)] Loss: -754158.625000\n",
      "Train Epoch: 13 [16896/54000 (31%)] Loss: -800391.687500\n",
      "Train Epoch: 13 [18304/54000 (34%)] Loss: -755094.812500\n",
      "Train Epoch: 13 [19712/54000 (37%)] Loss: -747912.375000\n",
      "Train Epoch: 13 [21120/54000 (39%)] Loss: -767543.562500\n",
      "Train Epoch: 13 [22528/54000 (42%)] Loss: -778283.562500\n",
      "Train Epoch: 13 [23936/54000 (44%)] Loss: -816624.875000\n",
      "Train Epoch: 13 [25344/54000 (47%)] Loss: -774240.937500\n",
      "Train Epoch: 13 [26752/54000 (50%)] Loss: -745856.500000\n",
      "Train Epoch: 13 [28160/54000 (52%)] Loss: -810893.125000\n",
      "Train Epoch: 13 [29568/54000 (55%)] Loss: -768533.000000\n",
      "Train Epoch: 13 [30976/54000 (57%)] Loss: -762681.000000\n",
      "Train Epoch: 13 [32384/54000 (60%)] Loss: -732879.750000\n",
      "Train Epoch: 13 [33792/54000 (63%)] Loss: -793204.125000\n",
      "Train Epoch: 13 [35200/54000 (65%)] Loss: -792980.000000\n",
      "Train Epoch: 13 [36608/54000 (68%)] Loss: -743284.812500\n",
      "Train Epoch: 13 [38016/54000 (70%)] Loss: -806795.000000\n",
      "Train Epoch: 13 [39424/54000 (73%)] Loss: -772509.062500\n",
      "Train Epoch: 13 [40832/54000 (76%)] Loss: -866382.375000\n",
      "Train Epoch: 13 [42240/54000 (78%)] Loss: -762498.312500\n",
      "Train Epoch: 13 [43648/54000 (81%)] Loss: -767046.062500\n",
      "Train Epoch: 13 [45056/54000 (83%)] Loss: -771399.312500\n",
      "Train Epoch: 13 [46464/54000 (86%)] Loss: -763935.500000\n",
      "Train Epoch: 13 [47872/54000 (89%)] Loss: -803298.812500\n",
      "Train Epoch: 13 [49280/54000 (91%)] Loss: -812363.750000\n",
      "Train Epoch: 13 [50688/54000 (94%)] Loss: -783308.500000\n",
      "Train Epoch: 13 [52096/54000 (96%)] Loss: -755734.750000\n",
      "    epoch          : 13\n",
      "    loss           : -781523.5930023923\n",
      "    val_loss       : -790967.862042683\n",
      "Train Epoch: 14 [0/54000 (0%)] Loss: -751954.625000\n",
      "Train Epoch: 14 [1408/54000 (3%)] Loss: -750131.250000\n",
      "Train Epoch: 14 [2816/54000 (5%)] Loss: -763891.625000\n",
      "Train Epoch: 14 [4224/54000 (8%)] Loss: -772783.875000\n",
      "Train Epoch: 14 [5632/54000 (10%)] Loss: -779985.250000\n",
      "Train Epoch: 14 [7040/54000 (13%)] Loss: -766398.312500\n",
      "Train Epoch: 14 [8448/54000 (16%)] Loss: -782030.750000\n",
      "Train Epoch: 14 [9856/54000 (18%)] Loss: -764763.875000\n",
      "Train Epoch: 14 [11264/54000 (21%)] Loss: -757023.812500\n",
      "Train Epoch: 14 [12672/54000 (23%)] Loss: -748510.062500\n",
      "Train Epoch: 14 [14080/54000 (26%)] Loss: -872497.562500\n",
      "Train Epoch: 14 [15488/54000 (29%)] Loss: -850074.187500\n",
      "Train Epoch: 14 [16896/54000 (31%)] Loss: -817723.125000\n",
      "Train Epoch: 14 [18304/54000 (34%)] Loss: -778421.250000\n",
      "Train Epoch: 14 [19712/54000 (37%)] Loss: -785068.375000\n",
      "Train Epoch: 14 [21120/54000 (39%)] Loss: -748626.500000\n",
      "Train Epoch: 14 [22528/54000 (42%)] Loss: -814321.250000\n",
      "Train Epoch: 14 [23936/54000 (44%)] Loss: -784116.562500\n",
      "Train Epoch: 14 [25344/54000 (47%)] Loss: -747207.062500\n",
      "Train Epoch: 14 [26752/54000 (50%)] Loss: -793352.187500\n",
      "Train Epoch: 14 [28160/54000 (52%)] Loss: -741518.937500\n",
      "Train Epoch: 14 [29568/54000 (55%)] Loss: -766258.000000\n",
      "Train Epoch: 14 [30976/54000 (57%)] Loss: -808876.437500\n",
      "Train Epoch: 14 [32384/54000 (60%)] Loss: -849122.125000\n",
      "Train Epoch: 14 [33792/54000 (63%)] Loss: -852922.937500\n",
      "Train Epoch: 14 [35200/54000 (65%)] Loss: -748343.687500\n",
      "Train Epoch: 14 [36608/54000 (68%)] Loss: -794043.062500\n",
      "Train Epoch: 14 [38016/54000 (70%)] Loss: -753836.312500\n",
      "Train Epoch: 14 [39424/54000 (73%)] Loss: -777710.437500\n",
      "Train Epoch: 14 [40832/54000 (76%)] Loss: -774139.000000\n",
      "Train Epoch: 14 [42240/54000 (78%)] Loss: -804297.187500\n",
      "Train Epoch: 14 [43648/54000 (81%)] Loss: -778608.687500\n",
      "Train Epoch: 14 [45056/54000 (83%)] Loss: -779640.250000\n",
      "Train Epoch: 14 [46464/54000 (86%)] Loss: -784133.125000\n",
      "Train Epoch: 14 [47872/54000 (89%)] Loss: -786030.875000\n",
      "Train Epoch: 14 [49280/54000 (91%)] Loss: -758534.312500\n",
      "Train Epoch: 14 [50688/54000 (94%)] Loss: -785239.437500\n",
      "Train Epoch: 14 [52096/54000 (96%)] Loss: -758117.437500\n",
      "    epoch          : 14\n",
      "    loss           : -783672.6735944976\n",
      "    val_loss       : -792026.3016387195\n",
      "Train Epoch: 15 [0/54000 (0%)] Loss: -750888.812500\n",
      "Train Epoch: 15 [1408/54000 (3%)] Loss: -749475.625000\n",
      "Train Epoch: 15 [2816/54000 (5%)] Loss: -755793.000000\n",
      "Train Epoch: 15 [4224/54000 (8%)] Loss: -776666.062500\n",
      "Train Epoch: 15 [5632/54000 (10%)] Loss: -779628.687500\n",
      "Train Epoch: 15 [7040/54000 (13%)] Loss: -769732.937500\n",
      "Train Epoch: 15 [8448/54000 (16%)] Loss: -806556.812500\n",
      "Train Epoch: 15 [9856/54000 (18%)] Loss: -751985.125000\n",
      "Train Epoch: 15 [11264/54000 (21%)] Loss: -868234.375000\n",
      "Train Epoch: 15 [12672/54000 (23%)] Loss: -785358.062500\n",
      "Train Epoch: 15 [14080/54000 (26%)] Loss: -743906.125000\n",
      "Train Epoch: 15 [15488/54000 (29%)] Loss: -745322.437500\n",
      "Train Epoch: 15 [16896/54000 (31%)] Loss: -816826.625000\n",
      "Train Epoch: 15 [18304/54000 (34%)] Loss: -808169.750000\n",
      "Train Epoch: 15 [19712/54000 (37%)] Loss: -798270.875000\n",
      "Train Epoch: 15 [21120/54000 (39%)] Loss: -777655.437500\n",
      "Train Epoch: 15 [22528/54000 (42%)] Loss: -859335.812500\n",
      "Train Epoch: 15 [23936/54000 (44%)] Loss: -745089.875000\n",
      "Train Epoch: 15 [25344/54000 (47%)] Loss: -803905.937500\n",
      "Train Epoch: 15 [26752/54000 (50%)] Loss: -760080.625000\n",
      "Train Epoch: 15 [28160/54000 (52%)] Loss: -775411.937500\n",
      "Train Epoch: 15 [29568/54000 (55%)] Loss: -856553.625000\n",
      "Train Epoch: 15 [30976/54000 (57%)] Loss: -856616.562500\n",
      "Train Epoch: 15 [32384/54000 (60%)] Loss: -750627.375000\n",
      "Train Epoch: 15 [33792/54000 (63%)] Loss: -748557.312500\n",
      "Train Epoch: 15 [35200/54000 (65%)] Loss: -796696.062500\n",
      "Train Epoch: 15 [36608/54000 (68%)] Loss: -784235.937500\n",
      "Train Epoch: 15 [38016/54000 (70%)] Loss: -802887.125000\n",
      "Train Epoch: 15 [39424/54000 (73%)] Loss: -773945.062500\n",
      "Train Epoch: 15 [40832/54000 (76%)] Loss: -808201.250000\n",
      "Train Epoch: 15 [42240/54000 (78%)] Loss: -847422.562500\n",
      "Train Epoch: 15 [43648/54000 (81%)] Loss: -775564.437500\n",
      "Train Epoch: 15 [45056/54000 (83%)] Loss: -752603.000000\n",
      "Train Epoch: 15 [46464/54000 (86%)] Loss: -863416.250000\n",
      "Train Epoch: 15 [47872/54000 (89%)] Loss: -762580.062500\n",
      "Train Epoch: 15 [49280/54000 (91%)] Loss: -794026.062500\n",
      "Train Epoch: 15 [50688/54000 (94%)] Loss: -753829.062500\n",
      "Train Epoch: 15 [52096/54000 (96%)] Loss: -757596.875000\n",
      "    epoch          : 15\n",
      "    loss           : -784822.9859449761\n",
      "    val_loss       : -791387.9394054879\n",
      "Saving checkpoint: saved/models/Mnist_VaeCategory/0422_221614/checkpoint-epoch15.pth ...\n",
      "Train Epoch: 16 [0/54000 (0%)] Loss: -862353.000000\n",
      "Train Epoch: 16 [1408/54000 (3%)] Loss: -752831.812500\n",
      "Train Epoch: 16 [2816/54000 (5%)] Loss: -747757.937500\n",
      "Train Epoch: 16 [4224/54000 (8%)] Loss: -819266.937500\n",
      "Train Epoch: 16 [5632/54000 (10%)] Loss: -749495.625000\n",
      "Train Epoch: 16 [7040/54000 (13%)] Loss: -765866.375000\n",
      "Train Epoch: 16 [8448/54000 (16%)] Loss: -792189.687500\n",
      "Train Epoch: 16 [9856/54000 (18%)] Loss: -788031.375000\n",
      "Train Epoch: 16 [11264/54000 (21%)] Loss: -801830.125000\n",
      "Train Epoch: 16 [12672/54000 (23%)] Loss: -773068.312500\n",
      "Train Epoch: 16 [14080/54000 (26%)] Loss: -784976.500000\n",
      "Train Epoch: 16 [15488/54000 (29%)] Loss: -750632.875000\n",
      "Train Epoch: 16 [16896/54000 (31%)] Loss: -772949.125000\n",
      "Train Epoch: 16 [18304/54000 (34%)] Loss: -777509.875000\n",
      "Train Epoch: 16 [19712/54000 (37%)] Loss: -749853.625000\n",
      "Train Epoch: 16 [21120/54000 (39%)] Loss: -874543.687500\n",
      "Train Epoch: 16 [22528/54000 (42%)] Loss: -750605.187500\n",
      "Train Epoch: 16 [23936/54000 (44%)] Loss: -794995.875000\n",
      "Train Epoch: 16 [25344/54000 (47%)] Loss: -797199.625000\n",
      "Train Epoch: 16 [26752/54000 (50%)] Loss: -800576.625000\n",
      "Train Epoch: 16 [28160/54000 (52%)] Loss: -802990.875000\n",
      "Train Epoch: 16 [29568/54000 (55%)] Loss: -760422.687500\n",
      "Train Epoch: 16 [30976/54000 (57%)] Loss: -779980.562500\n",
      "Train Epoch: 16 [32384/54000 (60%)] Loss: -757572.750000\n",
      "Train Epoch: 16 [33792/54000 (63%)] Loss: -786748.125000\n",
      "Train Epoch: 16 [35200/54000 (65%)] Loss: -781777.250000\n",
      "Train Epoch: 16 [36608/54000 (68%)] Loss: -860839.562500\n",
      "Train Epoch: 16 [38016/54000 (70%)] Loss: -789140.750000\n",
      "Train Epoch: 16 [39424/54000 (73%)] Loss: -777060.125000\n",
      "Train Epoch: 16 [40832/54000 (76%)] Loss: -773229.625000\n",
      "Train Epoch: 16 [42240/54000 (78%)] Loss: -757413.125000\n",
      "Train Epoch: 16 [43648/54000 (81%)] Loss: -748105.687500\n",
      "Train Epoch: 16 [45056/54000 (83%)] Loss: -766404.937500\n",
      "Train Epoch: 16 [46464/54000 (86%)] Loss: -804781.250000\n",
      "Train Epoch: 16 [47872/54000 (89%)] Loss: -798659.375000\n",
      "Train Epoch: 16 [49280/54000 (91%)] Loss: -794360.500000\n",
      "Train Epoch: 16 [50688/54000 (94%)] Loss: -747921.625000\n",
      "Train Epoch: 16 [52096/54000 (96%)] Loss: -790807.562500\n",
      "    epoch          : 16\n",
      "    loss           : -787537.9524521531\n",
      "    val_loss       : -793982.4822789634\n",
      "Train Epoch: 17 [0/54000 (0%)] Loss: -749620.937500\n",
      "Train Epoch: 17 [1408/54000 (3%)] Loss: -752257.687500\n",
      "Train Epoch: 17 [2816/54000 (5%)] Loss: -759467.000000\n",
      "Train Epoch: 17 [4224/54000 (8%)] Loss: -783020.875000\n",
      "Train Epoch: 17 [5632/54000 (10%)] Loss: -854550.125000\n",
      "Train Epoch: 17 [7040/54000 (13%)] Loss: -824426.062500\n",
      "Train Epoch: 17 [8448/54000 (16%)] Loss: -799182.875000\n",
      "Train Epoch: 17 [9856/54000 (18%)] Loss: -785889.250000\n",
      "Train Epoch: 17 [11264/54000 (21%)] Loss: -774320.562500\n",
      "Train Epoch: 17 [12672/54000 (23%)] Loss: -783276.000000\n",
      "Train Epoch: 17 [14080/54000 (26%)] Loss: -748256.500000\n",
      "Train Epoch: 17 [15488/54000 (29%)] Loss: -753984.875000\n",
      "Train Epoch: 17 [16896/54000 (31%)] Loss: -787367.187500\n",
      "Train Epoch: 17 [18304/54000 (34%)] Loss: -782975.375000\n",
      "Train Epoch: 17 [19712/54000 (37%)] Loss: -782082.562500\n",
      "Train Epoch: 17 [21120/54000 (39%)] Loss: -801700.562500\n",
      "Train Epoch: 17 [22528/54000 (42%)] Loss: -803189.812500\n",
      "Train Epoch: 17 [23936/54000 (44%)] Loss: -860871.125000\n",
      "Train Epoch: 17 [25344/54000 (47%)] Loss: -805450.125000\n",
      "Train Epoch: 17 [26752/54000 (50%)] Loss: -745702.125000\n",
      "Train Epoch: 17 [28160/54000 (52%)] Loss: -823620.562500\n",
      "Train Epoch: 17 [29568/54000 (55%)] Loss: -784811.687500\n",
      "Train Epoch: 17 [30976/54000 (57%)] Loss: -785688.000000\n",
      "Train Epoch: 17 [32384/54000 (60%)] Loss: -755642.375000\n",
      "Train Epoch: 17 [33792/54000 (63%)] Loss: -756608.250000\n",
      "Train Epoch: 17 [35200/54000 (65%)] Loss: -777054.312500\n",
      "Train Epoch: 17 [36608/54000 (68%)] Loss: -789200.125000\n",
      "Train Epoch: 17 [38016/54000 (70%)] Loss: -739620.937500\n",
      "Train Epoch: 17 [39424/54000 (73%)] Loss: -868370.187500\n",
      "Train Epoch: 17 [40832/54000 (76%)] Loss: -785817.312500\n",
      "Train Epoch: 17 [42240/54000 (78%)] Loss: -873975.000000\n",
      "Train Epoch: 17 [43648/54000 (81%)] Loss: -865222.625000\n",
      "Train Epoch: 17 [45056/54000 (83%)] Loss: -874056.750000\n",
      "Train Epoch: 17 [46464/54000 (86%)] Loss: -876958.250000\n",
      "Train Epoch: 17 [47872/54000 (89%)] Loss: -789126.375000\n",
      "Train Epoch: 17 [49280/54000 (91%)] Loss: -809436.687500\n",
      "Train Epoch: 17 [50688/54000 (94%)] Loss: -807971.625000\n",
      "Train Epoch: 17 [52096/54000 (96%)] Loss: -754109.312500\n",
      "    epoch          : 17\n",
      "    loss           : -789249.1966208135\n",
      "    val_loss       : -795156.640625\n",
      "Train Epoch: 18 [0/54000 (0%)] Loss: -760744.500000\n",
      "Train Epoch: 18 [1408/54000 (3%)] Loss: -783935.187500\n",
      "Train Epoch: 18 [2816/54000 (5%)] Loss: -789831.937500\n",
      "Train Epoch: 18 [4224/54000 (8%)] Loss: -866246.250000\n",
      "Train Epoch: 18 [5632/54000 (10%)] Loss: -794332.812500\n",
      "Train Epoch: 18 [7040/54000 (13%)] Loss: -755550.437500\n",
      "Train Epoch: 18 [8448/54000 (16%)] Loss: -746416.875000\n",
      "Train Epoch: 18 [9856/54000 (18%)] Loss: -775196.625000\n",
      "Train Epoch: 18 [11264/54000 (21%)] Loss: -819050.375000\n",
      "Train Epoch: 18 [12672/54000 (23%)] Loss: -764721.875000\n",
      "Train Epoch: 18 [14080/54000 (26%)] Loss: -759581.437500\n",
      "Train Epoch: 18 [15488/54000 (29%)] Loss: -768603.437500\n",
      "Train Epoch: 18 [16896/54000 (31%)] Loss: -746140.000000\n",
      "Train Epoch: 18 [18304/54000 (34%)] Loss: -868938.500000\n",
      "Train Epoch: 18 [19712/54000 (37%)] Loss: -755457.125000\n",
      "Train Epoch: 18 [21120/54000 (39%)] Loss: -791264.375000\n",
      "Train Epoch: 18 [22528/54000 (42%)] Loss: -792564.312500\n",
      "Train Epoch: 18 [23936/54000 (44%)] Loss: -788576.062500\n",
      "Train Epoch: 18 [25344/54000 (47%)] Loss: -754458.625000\n",
      "Train Epoch: 18 [26752/54000 (50%)] Loss: -779855.500000\n",
      "Train Epoch: 18 [28160/54000 (52%)] Loss: -780093.125000\n",
      "Train Epoch: 18 [29568/54000 (55%)] Loss: -782634.250000\n",
      "Train Epoch: 18 [30976/54000 (57%)] Loss: -824650.500000\n",
      "Train Epoch: 18 [32384/54000 (60%)] Loss: -800228.000000\n",
      "Train Epoch: 18 [33792/54000 (63%)] Loss: -795468.000000\n",
      "Train Epoch: 18 [35200/54000 (65%)] Loss: -822777.312500\n",
      "Train Epoch: 18 [36608/54000 (68%)] Loss: -772651.250000\n",
      "Train Epoch: 18 [38016/54000 (70%)] Loss: -813840.875000\n",
      "Train Epoch: 18 [39424/54000 (73%)] Loss: -749875.562500\n",
      "Train Epoch: 18 [40832/54000 (76%)] Loss: -756821.250000\n",
      "Train Epoch: 18 [42240/54000 (78%)] Loss: -857554.625000\n",
      "Train Epoch: 18 [43648/54000 (81%)] Loss: -865138.062500\n",
      "Train Epoch: 18 [45056/54000 (83%)] Loss: -876008.937500\n",
      "Train Epoch: 18 [46464/54000 (86%)] Loss: -794762.125000\n",
      "Train Epoch: 18 [47872/54000 (89%)] Loss: -797567.500000\n",
      "Train Epoch: 18 [49280/54000 (91%)] Loss: -812752.437500\n",
      "Train Epoch: 18 [50688/54000 (94%)] Loss: -763068.875000\n",
      "Train Epoch: 18 [52096/54000 (96%)] Loss: -761397.375000\n",
      "    epoch          : 18\n",
      "    loss           : -790238.6073564594\n",
      "    val_loss       : -795368.4967606707\n",
      "Train Epoch: 19 [0/54000 (0%)] Loss: -756424.312500\n",
      "Train Epoch: 19 [1408/54000 (3%)] Loss: -766909.875000\n",
      "Train Epoch: 19 [2816/54000 (5%)] Loss: -758120.562500\n",
      "Train Epoch: 19 [4224/54000 (8%)] Loss: -761760.875000\n",
      "Train Epoch: 19 [5632/54000 (10%)] Loss: -864025.062500\n",
      "Train Epoch: 19 [7040/54000 (13%)] Loss: -786999.375000\n",
      "Train Epoch: 19 [8448/54000 (16%)] Loss: -808404.687500\n",
      "Train Epoch: 19 [9856/54000 (18%)] Loss: -784723.250000\n",
      "Train Epoch: 19 [11264/54000 (21%)] Loss: -761013.125000\n",
      "Train Epoch: 19 [12672/54000 (23%)] Loss: -792485.125000\n",
      "Train Epoch: 19 [14080/54000 (26%)] Loss: -786967.375000\n",
      "Train Epoch: 19 [15488/54000 (29%)] Loss: -759223.750000\n",
      "Train Epoch: 19 [16896/54000 (31%)] Loss: -788139.125000\n",
      "Train Epoch: 19 [18304/54000 (34%)] Loss: -803441.312500\n",
      "Train Epoch: 19 [19712/54000 (37%)] Loss: -807471.687500\n",
      "Train Epoch: 19 [21120/54000 (39%)] Loss: -876238.250000\n",
      "Train Epoch: 19 [22528/54000 (42%)] Loss: -876917.000000\n",
      "Train Epoch: 19 [23936/54000 (44%)] Loss: -865403.000000\n",
      "Train Epoch: 19 [25344/54000 (47%)] Loss: -834819.437500\n",
      "Train Epoch: 19 [26752/54000 (50%)] Loss: -785176.937500\n",
      "Train Epoch: 19 [28160/54000 (52%)] Loss: -789880.937500\n",
      "Train Epoch: 19 [29568/54000 (55%)] Loss: -791440.687500\n",
      "Train Epoch: 19 [30976/54000 (57%)] Loss: -805162.500000\n",
      "Train Epoch: 19 [32384/54000 (60%)] Loss: -784936.062500\n",
      "Train Epoch: 19 [33792/54000 (63%)] Loss: -819715.125000\n",
      "Train Epoch: 19 [35200/54000 (65%)] Loss: -808681.500000\n",
      "Train Epoch: 19 [36608/54000 (68%)] Loss: -747748.187500\n",
      "Train Epoch: 19 [38016/54000 (70%)] Loss: -772278.812500\n",
      "Train Epoch: 19 [39424/54000 (73%)] Loss: -781525.000000\n",
      "Train Epoch: 19 [40832/54000 (76%)] Loss: -751523.187500\n",
      "Train Epoch: 19 [42240/54000 (78%)] Loss: -772731.812500\n",
      "Train Epoch: 19 [43648/54000 (81%)] Loss: -755997.312500\n",
      "Train Epoch: 19 [45056/54000 (83%)] Loss: -749695.312500\n",
      "Train Epoch: 19 [46464/54000 (86%)] Loss: -800114.937500\n",
      "Train Epoch: 19 [47872/54000 (89%)] Loss: -801908.875000\n",
      "Train Epoch: 19 [49280/54000 (91%)] Loss: -830845.312500\n",
      "Train Epoch: 19 [50688/54000 (94%)] Loss: -808075.750000\n",
      "Train Epoch: 19 [52096/54000 (96%)] Loss: -754748.625000\n",
      "    epoch          : 19\n",
      "    loss           : -791527.821770335\n",
      "    val_loss       : -796635.0342987805\n",
      "Train Epoch: 20 [0/54000 (0%)] Loss: -752944.750000\n",
      "Train Epoch: 20 [1408/54000 (3%)] Loss: -757100.562500\n",
      "Train Epoch: 20 [2816/54000 (5%)] Loss: -747691.750000\n",
      "Train Epoch: 20 [4224/54000 (8%)] Loss: -863554.937500\n",
      "Train Epoch: 20 [5632/54000 (10%)] Loss: -818323.875000\n",
      "Train Epoch: 20 [7040/54000 (13%)] Loss: -758465.375000\n",
      "Train Epoch: 20 [8448/54000 (16%)] Loss: -779308.562500\n",
      "Train Epoch: 20 [9856/54000 (18%)] Loss: -809626.625000\n",
      "Train Epoch: 20 [11264/54000 (21%)] Loss: -788820.250000\n",
      "Train Epoch: 20 [12672/54000 (23%)] Loss: -795143.437500\n",
      "Train Epoch: 20 [14080/54000 (26%)] Loss: -799046.312500\n",
      "Train Epoch: 20 [15488/54000 (29%)] Loss: -798718.187500\n",
      "Train Epoch: 20 [16896/54000 (31%)] Loss: -862357.625000\n",
      "Train Epoch: 20 [18304/54000 (34%)] Loss: -867647.625000\n",
      "Train Epoch: 20 [19712/54000 (37%)] Loss: -776009.187500\n",
      "Train Epoch: 20 [21120/54000 (39%)] Loss: -798570.500000\n",
      "Train Epoch: 20 [22528/54000 (42%)] Loss: -779458.062500\n",
      "Train Epoch: 20 [23936/54000 (44%)] Loss: -782550.000000\n",
      "Train Epoch: 20 [25344/54000 (47%)] Loss: -843347.625000\n",
      "Train Epoch: 20 [26752/54000 (50%)] Loss: -806834.562500\n",
      "Train Epoch: 20 [28160/54000 (52%)] Loss: -864844.375000\n",
      "Train Epoch: 20 [29568/54000 (55%)] Loss: -857470.062500\n",
      "Train Epoch: 20 [30976/54000 (57%)] Loss: -806727.812500\n",
      "Train Epoch: 20 [32384/54000 (60%)] Loss: -805557.875000\n",
      "Train Epoch: 20 [33792/54000 (63%)] Loss: -779671.937500\n",
      "Train Epoch: 20 [35200/54000 (65%)] Loss: -785589.812500\n",
      "Train Epoch: 20 [36608/54000 (68%)] Loss: -824807.000000\n",
      "Train Epoch: 20 [38016/54000 (70%)] Loss: -758205.375000\n",
      "Train Epoch: 20 [39424/54000 (73%)] Loss: -803022.312500\n",
      "Train Epoch: 20 [40832/54000 (76%)] Loss: -778998.000000\n",
      "Train Epoch: 20 [42240/54000 (78%)] Loss: -790741.062500\n",
      "Train Epoch: 20 [43648/54000 (81%)] Loss: -826464.687500\n",
      "Train Epoch: 20 [45056/54000 (83%)] Loss: -782694.500000\n",
      "Train Epoch: 20 [46464/54000 (86%)] Loss: -780293.687500\n",
      "Train Epoch: 20 [47872/54000 (89%)] Loss: -765261.187500\n",
      "Train Epoch: 20 [49280/54000 (91%)] Loss: -762849.500000\n",
      "Train Epoch: 20 [50688/54000 (94%)] Loss: -747981.812500\n",
      "Train Epoch: 20 [52096/54000 (96%)] Loss: -755594.250000\n",
      "    epoch          : 20\n",
      "    loss           : -792712.5423145933\n",
      "    val_loss       : -793637.6274771341\n",
      "Saving checkpoint: saved/models/Mnist_VaeCategory/0422_221614/checkpoint-epoch20.pth ...\n",
      "Train Epoch: 21 [0/54000 (0%)] Loss: -754937.937500\n",
      "Train Epoch: 21 [1408/54000 (3%)] Loss: -780061.625000\n",
      "Train Epoch: 21 [2816/54000 (5%)] Loss: -762568.375000\n",
      "Train Epoch: 21 [4224/54000 (8%)] Loss: -754467.500000\n",
      "Train Epoch: 21 [5632/54000 (10%)] Loss: -782288.562500\n",
      "Train Epoch: 21 [7040/54000 (13%)] Loss: -809952.750000\n",
      "Train Epoch: 21 [8448/54000 (16%)] Loss: -771404.875000\n",
      "Train Epoch: 21 [9856/54000 (18%)] Loss: -831255.500000\n",
      "Train Epoch: 21 [11264/54000 (21%)] Loss: -762765.187500\n",
      "Train Epoch: 21 [12672/54000 (23%)] Loss: -872839.750000\n",
      "Train Epoch: 21 [14080/54000 (26%)] Loss: -816215.750000\n",
      "Train Epoch: 21 [15488/54000 (29%)] Loss: -774251.125000\n",
      "Train Epoch: 21 [16896/54000 (31%)] Loss: -780811.250000\n",
      "Train Epoch: 21 [18304/54000 (34%)] Loss: -799333.500000\n",
      "Train Epoch: 21 [19712/54000 (37%)] Loss: -758388.625000\n",
      "Train Epoch: 21 [21120/54000 (39%)] Loss: -744779.500000\n",
      "Train Epoch: 21 [22528/54000 (42%)] Loss: -790907.750000\n",
      "Train Epoch: 21 [23936/54000 (44%)] Loss: -873258.937500\n",
      "Train Epoch: 21 [25344/54000 (47%)] Loss: -789865.500000\n",
      "Train Epoch: 21 [26752/54000 (50%)] Loss: -772815.750000\n",
      "Train Epoch: 21 [28160/54000 (52%)] Loss: -778542.437500\n",
      "Train Epoch: 21 [29568/54000 (55%)] Loss: -819663.750000\n",
      "Train Epoch: 21 [30976/54000 (57%)] Loss: -747565.875000\n",
      "Train Epoch: 21 [32384/54000 (60%)] Loss: -749481.875000\n",
      "Train Epoch: 21 [33792/54000 (63%)] Loss: -810431.375000\n",
      "Train Epoch: 21 [35200/54000 (65%)] Loss: -815262.375000\n",
      "Train Epoch: 21 [36608/54000 (68%)] Loss: -802681.812500\n",
      "Train Epoch: 21 [38016/54000 (70%)] Loss: -874600.625000\n",
      "Train Epoch: 21 [39424/54000 (73%)] Loss: -875957.812500\n",
      "Train Epoch: 21 [40832/54000 (76%)] Loss: -781028.000000\n",
      "Train Epoch: 21 [42240/54000 (78%)] Loss: -772464.062500\n",
      "Train Epoch: 21 [43648/54000 (81%)] Loss: -764268.500000\n",
      "Train Epoch: 21 [45056/54000 (83%)] Loss: -817961.625000\n",
      "Train Epoch: 21 [46464/54000 (86%)] Loss: -817388.312500\n",
      "Train Epoch: 21 [47872/54000 (89%)] Loss: -792546.875000\n",
      "Train Epoch: 21 [49280/54000 (91%)] Loss: -822556.000000\n",
      "Train Epoch: 21 [50688/54000 (94%)] Loss: -825078.437500\n",
      "Train Epoch: 21 [52096/54000 (96%)] Loss: -750102.187500\n",
      "    epoch          : 21\n",
      "    loss           : -793513.9052033493\n",
      "    val_loss       : -796162.935785061\n",
      "Train Epoch: 22 [0/54000 (0%)] Loss: -812033.062500\n",
      "Train Epoch: 22 [1408/54000 (3%)] Loss: -801132.062500\n",
      "Train Epoch: 22 [2816/54000 (5%)] Loss: -795901.812500\n",
      "Train Epoch: 22 [4224/54000 (8%)] Loss: -786227.812500\n",
      "Train Epoch: 22 [5632/54000 (10%)] Loss: -801914.375000\n",
      "Train Epoch: 22 [7040/54000 (13%)] Loss: -802279.000000\n",
      "Train Epoch: 22 [8448/54000 (16%)] Loss: -813876.562500\n",
      "Train Epoch: 22 [9856/54000 (18%)] Loss: -780408.875000\n",
      "Train Epoch: 22 [11264/54000 (21%)] Loss: -775155.500000\n",
      "Train Epoch: 22 [12672/54000 (23%)] Loss: -823142.312500\n",
      "Train Epoch: 22 [14080/54000 (26%)] Loss: -855115.500000\n",
      "Train Epoch: 22 [15488/54000 (29%)] Loss: -745451.125000\n",
      "Train Epoch: 22 [16896/54000 (31%)] Loss: -781523.687500\n",
      "Train Epoch: 22 [18304/54000 (34%)] Loss: -800223.812500\n",
      "Train Epoch: 22 [19712/54000 (37%)] Loss: -811314.500000\n",
      "Train Epoch: 22 [21120/54000 (39%)] Loss: -759157.812500\n",
      "Train Epoch: 22 [22528/54000 (42%)] Loss: -780488.687500\n",
      "Train Epoch: 22 [23936/54000 (44%)] Loss: -806764.625000\n",
      "Train Epoch: 22 [25344/54000 (47%)] Loss: -810663.187500\n",
      "Train Epoch: 22 [26752/54000 (50%)] Loss: -769149.500000\n",
      "Train Epoch: 22 [28160/54000 (52%)] Loss: -877962.000000\n",
      "Train Epoch: 22 [29568/54000 (55%)] Loss: -800204.437500\n",
      "Train Epoch: 22 [30976/54000 (57%)] Loss: -795919.312500\n",
      "Train Epoch: 22 [32384/54000 (60%)] Loss: -803966.437500\n",
      "Train Epoch: 22 [33792/54000 (63%)] Loss: -800636.312500\n",
      "Train Epoch: 22 [35200/54000 (65%)] Loss: -786758.812500\n",
      "Train Epoch: 22 [36608/54000 (68%)] Loss: -761470.375000\n",
      "Train Epoch: 22 [38016/54000 (70%)] Loss: -779228.437500\n",
      "Train Epoch: 22 [39424/54000 (73%)] Loss: -792652.812500\n",
      "Train Epoch: 22 [40832/54000 (76%)] Loss: -863466.062500\n",
      "Train Epoch: 22 [42240/54000 (78%)] Loss: -760214.500000\n",
      "Train Epoch: 22 [43648/54000 (81%)] Loss: -763328.750000\n",
      "Train Epoch: 22 [45056/54000 (83%)] Loss: -781389.250000\n",
      "Train Epoch: 22 [46464/54000 (86%)] Loss: -784738.125000\n",
      "Train Epoch: 22 [47872/54000 (89%)] Loss: -790658.562500\n",
      "Train Epoch: 22 [49280/54000 (91%)] Loss: -755816.875000\n",
      "Train Epoch: 22 [50688/54000 (94%)] Loss: -756934.562500\n",
      "Train Epoch: 22 [52096/54000 (96%)] Loss: -804479.187500\n",
      "    epoch          : 22\n",
      "    loss           : -794369.3540669857\n",
      "    val_loss       : -798521.0211509146\n",
      "Train Epoch: 23 [0/54000 (0%)] Loss: -786257.875000\n",
      "Train Epoch: 23 [1408/54000 (3%)] Loss: -775210.875000\n",
      "Train Epoch: 23 [2816/54000 (5%)] Loss: -803506.000000\n",
      "Train Epoch: 23 [4224/54000 (8%)] Loss: -773098.875000\n",
      "Train Epoch: 23 [5632/54000 (10%)] Loss: -778023.687500\n",
      "Train Epoch: 23 [7040/54000 (13%)] Loss: -822053.125000\n",
      "Train Epoch: 23 [8448/54000 (16%)] Loss: -777845.125000\n",
      "Train Epoch: 23 [9856/54000 (18%)] Loss: -803152.250000\n",
      "Train Epoch: 23 [11264/54000 (21%)] Loss: -779092.312500\n",
      "Train Epoch: 23 [12672/54000 (23%)] Loss: -784886.812500\n",
      "Train Epoch: 23 [14080/54000 (26%)] Loss: -759885.375000\n",
      "Train Epoch: 23 [15488/54000 (29%)] Loss: -764935.937500\n",
      "Train Epoch: 23 [16896/54000 (31%)] Loss: -764373.062500\n",
      "Train Epoch: 23 [18304/54000 (34%)] Loss: -777708.937500\n",
      "Train Epoch: 23 [19712/54000 (37%)] Loss: -779614.687500\n",
      "Train Epoch: 23 [21120/54000 (39%)] Loss: -805597.500000\n",
      "Train Epoch: 23 [22528/54000 (42%)] Loss: -813443.125000\n",
      "Train Epoch: 23 [23936/54000 (44%)] Loss: -772504.062500\n",
      "Train Epoch: 23 [25344/54000 (47%)] Loss: -771238.000000\n",
      "Train Epoch: 23 [26752/54000 (50%)] Loss: -753434.000000\n",
      "Train Epoch: 23 [28160/54000 (52%)] Loss: -875746.687500\n",
      "Train Epoch: 23 [29568/54000 (55%)] Loss: -811139.812500\n",
      "Train Epoch: 23 [30976/54000 (57%)] Loss: -777138.437500\n",
      "Train Epoch: 23 [32384/54000 (60%)] Loss: -785568.250000\n",
      "Train Epoch: 23 [33792/54000 (63%)] Loss: -754245.750000\n",
      "Train Epoch: 23 [35200/54000 (65%)] Loss: -791009.187500\n",
      "Train Epoch: 23 [36608/54000 (68%)] Loss: -758988.625000\n",
      "Train Epoch: 23 [38016/54000 (70%)] Loss: -785791.562500\n",
      "Train Epoch: 23 [39424/54000 (73%)] Loss: -760113.625000\n",
      "Train Epoch: 23 [40832/54000 (76%)] Loss: -781687.312500\n",
      "Train Epoch: 23 [42240/54000 (78%)] Loss: -785613.937500\n",
      "Train Epoch: 23 [43648/54000 (81%)] Loss: -869695.125000\n",
      "Train Epoch: 23 [45056/54000 (83%)] Loss: -815650.625000\n",
      "Train Epoch: 23 [46464/54000 (86%)] Loss: -791539.187500\n",
      "Train Epoch: 23 [47872/54000 (89%)] Loss: -799324.375000\n",
      "Train Epoch: 23 [49280/54000 (91%)] Loss: -828585.812500\n",
      "Train Epoch: 23 [50688/54000 (94%)] Loss: -760105.937500\n",
      "Train Epoch: 23 [52096/54000 (96%)] Loss: -807971.250000\n",
      "    epoch          : 23\n",
      "    loss           : -795450.149222488\n",
      "    val_loss       : -800018.8184070121\n",
      "Train Epoch: 24 [0/54000 (0%)] Loss: -782136.187500\n",
      "Train Epoch: 24 [1408/54000 (3%)] Loss: -750759.312500\n",
      "Train Epoch: 24 [2816/54000 (5%)] Loss: -773728.687500\n",
      "Train Epoch: 24 [4224/54000 (8%)] Loss: -785408.500000\n",
      "Train Epoch: 24 [5632/54000 (10%)] Loss: -779510.687500\n",
      "Train Epoch: 24 [7040/54000 (13%)] Loss: -813902.062500\n",
      "Train Epoch: 24 [8448/54000 (16%)] Loss: -802185.062500\n",
      "Train Epoch: 24 [9856/54000 (18%)] Loss: -813746.062500\n",
      "Train Epoch: 24 [11264/54000 (21%)] Loss: -801808.375000\n",
      "Train Epoch: 24 [12672/54000 (23%)] Loss: -795321.187500\n",
      "Train Epoch: 24 [14080/54000 (26%)] Loss: -836960.875000\n",
      "Train Epoch: 24 [15488/54000 (29%)] Loss: -811402.937500\n",
      "Train Epoch: 24 [16896/54000 (31%)] Loss: -805910.750000\n",
      "Train Epoch: 24 [18304/54000 (34%)] Loss: -792184.500000\n",
      "Train Epoch: 24 [19712/54000 (37%)] Loss: -767636.812500\n",
      "Train Epoch: 24 [21120/54000 (39%)] Loss: -785637.625000\n",
      "Train Epoch: 24 [22528/54000 (42%)] Loss: -802434.375000\n",
      "Train Epoch: 24 [23936/54000 (44%)] Loss: -755292.312500\n",
      "Train Epoch: 24 [25344/54000 (47%)] Loss: -750117.000000\n",
      "Train Epoch: 24 [26752/54000 (50%)] Loss: -873673.312500\n",
      "Train Epoch: 24 [28160/54000 (52%)] Loss: -802818.187500\n",
      "Train Epoch: 24 [29568/54000 (55%)] Loss: -788640.062500\n",
      "Train Epoch: 24 [30976/54000 (57%)] Loss: -802618.312500\n",
      "Train Epoch: 24 [32384/54000 (60%)] Loss: -795132.250000\n",
      "Train Epoch: 24 [33792/54000 (63%)] Loss: -780094.687500\n",
      "Train Epoch: 24 [35200/54000 (65%)] Loss: -792272.375000\n",
      "Train Epoch: 24 [36608/54000 (68%)] Loss: -779291.062500\n",
      "Train Epoch: 24 [38016/54000 (70%)] Loss: -810961.000000\n",
      "Train Epoch: 24 [39424/54000 (73%)] Loss: -808874.500000\n",
      "Train Epoch: 24 [40832/54000 (76%)] Loss: -769061.812500\n",
      "Train Epoch: 24 [42240/54000 (78%)] Loss: -762337.312500\n",
      "Train Epoch: 24 [43648/54000 (81%)] Loss: -748911.250000\n",
      "Train Epoch: 24 [45056/54000 (83%)] Loss: -864376.125000\n",
      "Train Epoch: 24 [46464/54000 (86%)] Loss: -833438.937500\n",
      "Train Epoch: 24 [47872/54000 (89%)] Loss: -804940.062500\n",
      "Train Epoch: 24 [49280/54000 (91%)] Loss: -795880.000000\n",
      "Train Epoch: 24 [50688/54000 (94%)] Loss: -813793.500000\n",
      "Train Epoch: 24 [52096/54000 (96%)] Loss: -755337.437500\n",
      "    epoch          : 24\n",
      "    loss           : -796223.280950957\n",
      "    val_loss       : -800521.6520579269\n",
      "Train Epoch: 25 [0/54000 (0%)] Loss: -784326.125000\n",
      "Train Epoch: 25 [1408/54000 (3%)] Loss: -766616.062500\n",
      "Train Epoch: 25 [2816/54000 (5%)] Loss: -801663.500000\n",
      "Train Epoch: 25 [4224/54000 (8%)] Loss: -789523.750000\n",
      "Train Epoch: 25 [5632/54000 (10%)] Loss: -787332.187500\n",
      "Train Epoch: 25 [7040/54000 (13%)] Loss: -783977.312500\n",
      "Train Epoch: 25 [8448/54000 (16%)] Loss: -774815.375000\n",
      "Train Epoch: 25 [9856/54000 (18%)] Loss: -783214.812500\n",
      "Train Epoch: 25 [11264/54000 (21%)] Loss: -786261.687500\n",
      "Train Epoch: 25 [12672/54000 (23%)] Loss: -759112.062500\n",
      "Train Epoch: 25 [14080/54000 (26%)] Loss: -802336.750000\n",
      "Train Epoch: 25 [15488/54000 (29%)] Loss: -758000.125000\n",
      "Train Epoch: 25 [16896/54000 (31%)] Loss: -832506.625000\n",
      "Train Epoch: 25 [18304/54000 (34%)] Loss: -868764.625000\n",
      "Train Epoch: 25 [19712/54000 (37%)] Loss: -803428.687500\n",
      "Train Epoch: 25 [21120/54000 (39%)] Loss: -747803.750000\n",
      "Train Epoch: 25 [22528/54000 (42%)] Loss: -777637.000000\n",
      "Train Epoch: 25 [23936/54000 (44%)] Loss: -750462.187500\n",
      "Train Epoch: 25 [25344/54000 (47%)] Loss: -781950.250000\n",
      "Train Epoch: 25 [26752/54000 (50%)] Loss: -783116.500000\n",
      "Train Epoch: 25 [28160/54000 (52%)] Loss: -755702.312500\n",
      "Train Epoch: 25 [29568/54000 (55%)] Loss: -837369.562500\n",
      "Train Epoch: 25 [30976/54000 (57%)] Loss: -825349.250000\n",
      "Train Epoch: 25 [32384/54000 (60%)] Loss: -795745.875000\n",
      "Train Epoch: 25 [33792/54000 (63%)] Loss: -804178.500000\n",
      "Train Epoch: 25 [35200/54000 (65%)] Loss: -816370.375000\n",
      "Train Epoch: 25 [36608/54000 (68%)] Loss: -787364.625000\n",
      "Train Epoch: 25 [38016/54000 (70%)] Loss: -809603.562500\n",
      "Train Epoch: 25 [39424/54000 (73%)] Loss: -741197.437500\n",
      "Train Epoch: 25 [40832/54000 (76%)] Loss: -875540.750000\n",
      "Train Epoch: 25 [42240/54000 (78%)] Loss: -755959.875000\n",
      "Train Epoch: 25 [43648/54000 (81%)] Loss: -821647.062500\n",
      "Train Epoch: 25 [45056/54000 (83%)] Loss: -811339.812500\n",
      "Train Epoch: 25 [46464/54000 (86%)] Loss: -840253.250000\n",
      "Train Epoch: 25 [47872/54000 (89%)] Loss: -806960.562500\n",
      "Train Epoch: 25 [49280/54000 (91%)] Loss: -783320.000000\n",
      "Train Epoch: 25 [50688/54000 (94%)] Loss: -757951.437500\n",
      "Train Epoch: 25 [52096/54000 (96%)] Loss: -761860.687500\n",
      "    epoch          : 25\n",
      "    loss           : -796163.0465011962\n",
      "    val_loss       : -800376.362042683\n",
      "Saving checkpoint: saved/models/Mnist_VaeCategory/0422_221614/checkpoint-epoch25.pth ...\n",
      "Train Epoch: 26 [0/54000 (0%)] Loss: -754435.562500\n",
      "Train Epoch: 26 [1408/54000 (3%)] Loss: -810708.812500\n",
      "Train Epoch: 26 [2816/54000 (5%)] Loss: -766731.125000\n",
      "Train Epoch: 26 [4224/54000 (8%)] Loss: -791701.500000\n",
      "Train Epoch: 26 [5632/54000 (10%)] Loss: -785185.000000\n",
      "Train Epoch: 26 [7040/54000 (13%)] Loss: -782937.000000\n",
      "Train Epoch: 26 [8448/54000 (16%)] Loss: -781540.750000\n",
      "Train Epoch: 26 [9856/54000 (18%)] Loss: -867681.937500\n",
      "Train Epoch: 26 [11264/54000 (21%)] Loss: -798353.375000\n",
      "Train Epoch: 26 [12672/54000 (23%)] Loss: -801478.312500\n",
      "Train Epoch: 26 [14080/54000 (26%)] Loss: -790416.187500\n",
      "Train Epoch: 26 [15488/54000 (29%)] Loss: -803892.500000\n",
      "Train Epoch: 26 [16896/54000 (31%)] Loss: -796030.625000\n",
      "Train Epoch: 26 [18304/54000 (34%)] Loss: -753301.750000\n",
      "Train Epoch: 26 [19712/54000 (37%)] Loss: -807716.562500\n",
      "Train Epoch: 26 [21120/54000 (39%)] Loss: -790137.437500\n",
      "Train Epoch: 26 [22528/54000 (42%)] Loss: -818521.687500\n",
      "Train Epoch: 26 [23936/54000 (44%)] Loss: -764103.250000\n",
      "Train Epoch: 26 [25344/54000 (47%)] Loss: -782994.187500\n",
      "Train Epoch: 26 [26752/54000 (50%)] Loss: -804929.937500\n",
      "Train Epoch: 26 [28160/54000 (52%)] Loss: -807268.187500\n",
      "Train Epoch: 26 [29568/54000 (55%)] Loss: -861397.750000\n",
      "Train Epoch: 26 [30976/54000 (57%)] Loss: -757276.437500\n",
      "Train Epoch: 26 [32384/54000 (60%)] Loss: -791625.250000\n",
      "Train Epoch: 26 [33792/54000 (63%)] Loss: -774216.875000\n",
      "Train Epoch: 26 [35200/54000 (65%)] Loss: -821040.062500\n",
      "Train Epoch: 26 [36608/54000 (68%)] Loss: -751265.125000\n",
      "Train Epoch: 26 [38016/54000 (70%)] Loss: -781980.250000\n",
      "Train Epoch: 26 [39424/54000 (73%)] Loss: -803313.937500\n",
      "Train Epoch: 26 [40832/54000 (76%)] Loss: -773321.375000\n",
      "Train Epoch: 26 [42240/54000 (78%)] Loss: -809069.500000\n",
      "Train Epoch: 26 [43648/54000 (81%)] Loss: -753476.062500\n",
      "Train Epoch: 26 [45056/54000 (83%)] Loss: -866138.437500\n",
      "Train Epoch: 26 [46464/54000 (86%)] Loss: -789712.562500\n",
      "Train Epoch: 26 [47872/54000 (89%)] Loss: -789666.000000\n",
      "Train Epoch: 26 [49280/54000 (91%)] Loss: -829262.375000\n",
      "Train Epoch: 26 [50688/54000 (94%)] Loss: -759952.562500\n",
      "Train Epoch: 26 [52096/54000 (96%)] Loss: -765563.312500\n",
      "    epoch          : 26\n",
      "    loss           : -797259.3986244019\n",
      "    val_loss       : -799429.2052210366\n",
      "Train Epoch: 27 [0/54000 (0%)] Loss: -786508.500000\n",
      "Train Epoch: 27 [1408/54000 (3%)] Loss: -763964.437500\n",
      "Train Epoch: 27 [2816/54000 (5%)] Loss: -811227.562500\n",
      "Train Epoch: 27 [4224/54000 (8%)] Loss: -869917.312500\n",
      "Train Epoch: 27 [5632/54000 (10%)] Loss: -794976.437500\n",
      "Train Epoch: 27 [7040/54000 (13%)] Loss: -784366.875000\n",
      "Train Epoch: 27 [8448/54000 (16%)] Loss: -813263.250000\n",
      "Train Epoch: 27 [9856/54000 (18%)] Loss: -882734.625000\n",
      "Train Epoch: 27 [11264/54000 (21%)] Loss: -778055.375000\n",
      "Train Epoch: 27 [12672/54000 (23%)] Loss: -829812.687500\n",
      "Train Epoch: 27 [14080/54000 (26%)] Loss: -776405.500000\n",
      "Train Epoch: 27 [15488/54000 (29%)] Loss: -801081.375000\n",
      "Train Epoch: 27 [16896/54000 (31%)] Loss: -813286.625000\n",
      "Train Epoch: 27 [18304/54000 (34%)] Loss: -768540.875000\n",
      "Train Epoch: 27 [19712/54000 (37%)] Loss: -809174.250000\n",
      "Train Epoch: 27 [21120/54000 (39%)] Loss: -804204.500000\n",
      "Train Epoch: 27 [22528/54000 (42%)] Loss: -782277.500000\n",
      "Train Epoch: 27 [23936/54000 (44%)] Loss: -781078.437500\n",
      "Train Epoch: 27 [25344/54000 (47%)] Loss: -808799.125000\n",
      "Train Epoch: 27 [26752/54000 (50%)] Loss: -872051.750000\n",
      "Train Epoch: 27 [28160/54000 (52%)] Loss: -750450.937500\n",
      "Train Epoch: 27 [29568/54000 (55%)] Loss: -795176.000000\n",
      "Train Epoch: 27 [30976/54000 (57%)] Loss: -805010.375000\n",
      "Train Epoch: 27 [32384/54000 (60%)] Loss: -819795.875000\n",
      "Train Epoch: 27 [33792/54000 (63%)] Loss: -813030.375000\n",
      "Train Epoch: 27 [35200/54000 (65%)] Loss: -755462.312500\n",
      "Train Epoch: 27 [36608/54000 (68%)] Loss: -797644.687500\n",
      "Train Epoch: 27 [38016/54000 (70%)] Loss: -760726.812500\n",
      "Train Epoch: 27 [39424/54000 (73%)] Loss: -782565.312500\n",
      "Train Epoch: 27 [40832/54000 (76%)] Loss: -878198.875000\n",
      "Train Epoch: 27 [42240/54000 (78%)] Loss: -775520.000000\n",
      "Train Epoch: 27 [43648/54000 (81%)] Loss: -770876.375000\n",
      "Train Epoch: 27 [45056/54000 (83%)] Loss: -796958.437500\n",
      "Train Epoch: 27 [46464/54000 (86%)] Loss: -790114.750000\n",
      "Train Epoch: 27 [47872/54000 (89%)] Loss: -829305.125000\n",
      "Train Epoch: 27 [49280/54000 (91%)] Loss: -763515.375000\n",
      "Train Epoch: 27 [50688/54000 (94%)] Loss: -807698.562500\n",
      "Train Epoch: 27 [52096/54000 (96%)] Loss: -754379.000000\n",
      "    epoch          : 27\n",
      "    loss           : -798040.925388756\n",
      "    val_loss       : -801502.0030487805\n",
      "Train Epoch: 28 [0/54000 (0%)] Loss: -757240.625000\n",
      "Train Epoch: 28 [1408/54000 (3%)] Loss: -815516.687500\n",
      "Train Epoch: 28 [2816/54000 (5%)] Loss: -815461.625000\n",
      "Train Epoch: 28 [4224/54000 (8%)] Loss: -876643.625000\n",
      "Train Epoch: 28 [5632/54000 (10%)] Loss: -796400.000000\n",
      "Train Epoch: 28 [7040/54000 (13%)] Loss: -757532.500000\n",
      "Train Epoch: 28 [8448/54000 (16%)] Loss: -794711.000000\n",
      "Train Epoch: 28 [9856/54000 (18%)] Loss: -831950.250000\n",
      "Train Epoch: 28 [11264/54000 (21%)] Loss: -781690.437500\n",
      "Train Epoch: 28 [12672/54000 (23%)] Loss: -774434.250000\n",
      "Train Epoch: 28 [14080/54000 (26%)] Loss: -759187.875000\n",
      "Train Epoch: 28 [15488/54000 (29%)] Loss: -806099.312500\n",
      "Train Epoch: 28 [16896/54000 (31%)] Loss: -755206.937500\n",
      "Train Epoch: 28 [18304/54000 (34%)] Loss: -788640.500000\n",
      "Train Epoch: 28 [19712/54000 (37%)] Loss: -801901.187500\n",
      "Train Epoch: 28 [21120/54000 (39%)] Loss: -839000.375000\n",
      "Train Epoch: 28 [22528/54000 (42%)] Loss: -872379.250000\n",
      "Train Epoch: 28 [23936/54000 (44%)] Loss: -753347.250000\n",
      "Train Epoch: 28 [25344/54000 (47%)] Loss: -806434.062500\n",
      "Train Epoch: 28 [26752/54000 (50%)] Loss: -813696.125000\n",
      "Train Epoch: 28 [28160/54000 (52%)] Loss: -828285.250000\n",
      "Train Epoch: 28 [29568/54000 (55%)] Loss: -812704.125000\n",
      "Train Epoch: 28 [30976/54000 (57%)] Loss: -827575.375000\n",
      "Train Epoch: 28 [32384/54000 (60%)] Loss: -783514.562500\n",
      "Train Epoch: 28 [33792/54000 (63%)] Loss: -795100.187500\n",
      "Train Epoch: 28 [35200/54000 (65%)] Loss: -811280.125000\n",
      "Train Epoch: 28 [36608/54000 (68%)] Loss: -758483.687500\n",
      "Train Epoch: 28 [38016/54000 (70%)] Loss: -798144.312500\n",
      "Train Epoch: 28 [39424/54000 (73%)] Loss: -816229.250000\n",
      "Train Epoch: 28 [40832/54000 (76%)] Loss: -778674.062500\n",
      "Train Epoch: 28 [42240/54000 (78%)] Loss: -814299.375000\n",
      "Train Epoch: 28 [43648/54000 (81%)] Loss: -786343.500000\n",
      "Train Epoch: 28 [45056/54000 (83%)] Loss: -791673.062500\n",
      "Train Epoch: 28 [46464/54000 (86%)] Loss: -791242.687500\n",
      "Train Epoch: 28 [47872/54000 (89%)] Loss: -827602.187500\n",
      "Train Epoch: 28 [49280/54000 (91%)] Loss: -779714.500000\n",
      "Train Epoch: 28 [50688/54000 (94%)] Loss: -790410.250000\n",
      "Train Epoch: 28 [52096/54000 (96%)] Loss: -814907.500000\n",
      "    epoch          : 28\n",
      "    loss           : -798465.2854366029\n",
      "    val_loss       : -802580.1821646341\n",
      "Train Epoch: 29 [0/54000 (0%)] Loss: -757772.875000\n",
      "Train Epoch: 29 [1408/54000 (3%)] Loss: -818687.812500\n",
      "Train Epoch: 29 [2816/54000 (5%)] Loss: -810988.375000\n",
      "Train Epoch: 29 [4224/54000 (8%)] Loss: -789384.250000\n",
      "Train Epoch: 29 [5632/54000 (10%)] Loss: -764319.625000\n",
      "Train Epoch: 29 [7040/54000 (13%)] Loss: -839020.812500\n",
      "Train Epoch: 29 [8448/54000 (16%)] Loss: -813276.125000\n",
      "Train Epoch: 29 [9856/54000 (18%)] Loss: -775918.875000\n",
      "Train Epoch: 29 [11264/54000 (21%)] Loss: -806706.812500\n",
      "Train Epoch: 29 [12672/54000 (23%)] Loss: -806985.312500\n",
      "Train Epoch: 29 [14080/54000 (26%)] Loss: -809239.000000\n",
      "Train Epoch: 29 [15488/54000 (29%)] Loss: -810948.562500\n",
      "Train Epoch: 29 [16896/54000 (31%)] Loss: -758458.062500\n",
      "Train Epoch: 29 [18304/54000 (34%)] Loss: -755353.500000\n",
      "Train Epoch: 29 [19712/54000 (37%)] Loss: -885393.812500\n",
      "Train Epoch: 29 [21120/54000 (39%)] Loss: -785586.375000\n",
      "Train Epoch: 29 [22528/54000 (42%)] Loss: -817120.437500\n",
      "Train Epoch: 29 [23936/54000 (44%)] Loss: -805008.375000\n",
      "Train Epoch: 29 [25344/54000 (47%)] Loss: -775476.125000\n",
      "Train Epoch: 29 [26752/54000 (50%)] Loss: -815938.187500\n",
      "Train Epoch: 29 [28160/54000 (52%)] Loss: -828224.812500\n",
      "Train Epoch: 29 [29568/54000 (55%)] Loss: -782693.437500\n",
      "Train Epoch: 29 [30976/54000 (57%)] Loss: -789290.875000\n",
      "Train Epoch: 29 [32384/54000 (60%)] Loss: -779156.187500\n",
      "Train Epoch: 29 [33792/54000 (63%)] Loss: -886026.500000\n",
      "Train Epoch: 29 [35200/54000 (65%)] Loss: -765714.812500\n",
      "Train Epoch: 29 [36608/54000 (68%)] Loss: -873431.000000\n",
      "Train Epoch: 29 [38016/54000 (70%)] Loss: -800890.937500\n",
      "Train Epoch: 29 [39424/54000 (73%)] Loss: -816566.250000\n",
      "Train Epoch: 29 [40832/54000 (76%)] Loss: -789741.375000\n",
      "Train Epoch: 29 [42240/54000 (78%)] Loss: -798963.000000\n",
      "Train Epoch: 29 [43648/54000 (81%)] Loss: -760208.750000\n",
      "Train Epoch: 29 [45056/54000 (83%)] Loss: -761902.625000\n",
      "Train Epoch: 29 [46464/54000 (86%)] Loss: -785152.250000\n",
      "Train Epoch: 29 [47872/54000 (89%)] Loss: -819402.812500\n",
      "Train Epoch: 29 [49280/54000 (91%)] Loss: -815605.187500\n",
      "Train Epoch: 29 [50688/54000 (94%)] Loss: -819151.250000\n",
      "Train Epoch: 29 [52096/54000 (96%)] Loss: -757950.812500\n",
      "    epoch          : 29\n",
      "    loss           : -798897.3899521531\n",
      "    val_loss       : -801392.5167682926\n",
      "Train Epoch: 30 [0/54000 (0%)] Loss: -811516.437500\n",
      "Train Epoch: 30 [1408/54000 (3%)] Loss: -808805.125000\n",
      "Train Epoch: 30 [2816/54000 (5%)] Loss: -824564.562500\n",
      "Train Epoch: 30 [4224/54000 (8%)] Loss: -804936.062500\n",
      "Train Epoch: 30 [5632/54000 (10%)] Loss: -779819.125000\n",
      "Train Epoch: 30 [7040/54000 (13%)] Loss: -808954.125000\n",
      "Train Epoch: 30 [8448/54000 (16%)] Loss: -796343.750000\n",
      "Train Epoch: 30 [9856/54000 (18%)] Loss: -786965.312500\n",
      "Train Epoch: 30 [11264/54000 (21%)] Loss: -888893.750000\n",
      "Train Epoch: 30 [12672/54000 (23%)] Loss: -827414.562500\n",
      "Train Epoch: 30 [14080/54000 (26%)] Loss: -795679.500000\n",
      "Train Epoch: 30 [15488/54000 (29%)] Loss: -796286.437500\n",
      "Train Epoch: 30 [16896/54000 (31%)] Loss: -815932.937500\n",
      "Train Epoch: 30 [18304/54000 (34%)] Loss: -758454.062500\n",
      "Train Epoch: 30 [19712/54000 (37%)] Loss: -813836.937500\n",
      "Train Epoch: 30 [21120/54000 (39%)] Loss: -780039.125000\n",
      "Train Epoch: 30 [22528/54000 (42%)] Loss: -889810.312500\n",
      "Train Epoch: 30 [23936/54000 (44%)] Loss: -754870.187500\n",
      "Train Epoch: 30 [25344/54000 (47%)] Loss: -745385.812500\n",
      "Train Epoch: 30 [26752/54000 (50%)] Loss: -809284.562500\n",
      "Train Epoch: 30 [28160/54000 (52%)] Loss: -808551.812500\n",
      "Train Epoch: 30 [29568/54000 (55%)] Loss: -814956.125000\n",
      "Train Epoch: 30 [30976/54000 (57%)] Loss: -819488.500000\n",
      "Train Epoch: 30 [32384/54000 (60%)] Loss: -813609.875000\n",
      "Train Epoch: 30 [33792/54000 (63%)] Loss: -807187.500000\n",
      "Train Epoch: 30 [35200/54000 (65%)] Loss: -796958.375000\n",
      "Train Epoch: 30 [36608/54000 (68%)] Loss: -797281.062500\n",
      "Train Epoch: 30 [38016/54000 (70%)] Loss: -789614.250000\n",
      "Train Epoch: 30 [39424/54000 (73%)] Loss: -778507.250000\n",
      "Train Epoch: 30 [40832/54000 (76%)] Loss: -783573.187500\n",
      "Train Epoch: 30 [42240/54000 (78%)] Loss: -760945.375000\n",
      "Train Epoch: 30 [43648/54000 (81%)] Loss: -782603.562500\n",
      "Train Epoch: 30 [45056/54000 (83%)] Loss: -819876.750000\n",
      "Train Epoch: 30 [46464/54000 (86%)] Loss: -823541.625000\n",
      "Train Epoch: 30 [47872/54000 (89%)] Loss: -833178.125000\n",
      "Train Epoch: 30 [49280/54000 (91%)] Loss: -803711.000000\n",
      "Train Epoch: 30 [50688/54000 (94%)] Loss: -808881.750000\n",
      "Train Epoch: 30 [52096/54000 (96%)] Loss: -771551.750000\n",
      "    epoch          : 30\n",
      "    loss           : -799489.3531698565\n",
      "    val_loss       : -800152.8016387195\n",
      "Saving checkpoint: saved/models/Mnist_VaeCategory/0422_221614/checkpoint-epoch30.pth ...\n",
      "Train Epoch: 31 [0/54000 (0%)] Loss: -815398.312500\n",
      "Train Epoch: 31 [1408/54000 (3%)] Loss: -768223.937500\n",
      "Train Epoch: 31 [2816/54000 (5%)] Loss: -766550.875000\n",
      "Train Epoch: 31 [4224/54000 (8%)] Loss: -803363.625000\n",
      "Train Epoch: 31 [5632/54000 (10%)] Loss: -810681.687500\n",
      "Train Epoch: 31 [7040/54000 (13%)] Loss: -861871.125000\n",
      "Train Epoch: 31 [8448/54000 (16%)] Loss: -801901.000000\n",
      "Train Epoch: 31 [9856/54000 (18%)] Loss: -797081.500000\n",
      "Train Epoch: 31 [11264/54000 (21%)] Loss: -754100.750000\n",
      "Train Epoch: 31 [12672/54000 (23%)] Loss: -765042.500000\n",
      "Train Epoch: 31 [14080/54000 (26%)] Loss: -812804.625000\n",
      "Train Epoch: 31 [15488/54000 (29%)] Loss: -799965.375000\n",
      "Train Epoch: 31 [16896/54000 (31%)] Loss: -756353.000000\n",
      "Train Epoch: 31 [18304/54000 (34%)] Loss: -791974.812500\n",
      "Train Epoch: 31 [19712/54000 (37%)] Loss: -791500.125000\n",
      "Train Epoch: 31 [21120/54000 (39%)] Loss: -770626.125000\n",
      "Train Epoch: 31 [22528/54000 (42%)] Loss: -783477.812500\n",
      "Train Epoch: 31 [23936/54000 (44%)] Loss: -801268.125000\n",
      "Train Epoch: 31 [25344/54000 (47%)] Loss: -897637.750000\n",
      "Train Epoch: 31 [26752/54000 (50%)] Loss: -879659.312500\n",
      "Train Epoch: 31 [28160/54000 (52%)] Loss: -876511.250000\n",
      "Train Epoch: 31 [29568/54000 (55%)] Loss: -814221.312500\n",
      "Train Epoch: 31 [30976/54000 (57%)] Loss: -767432.500000\n",
      "Train Epoch: 31 [32384/54000 (60%)] Loss: -826908.625000\n",
      "Train Epoch: 31 [33792/54000 (63%)] Loss: -791111.750000\n",
      "Train Epoch: 31 [35200/54000 (65%)] Loss: -790358.000000\n",
      "Train Epoch: 31 [36608/54000 (68%)] Loss: -770653.375000\n",
      "Train Epoch: 31 [38016/54000 (70%)] Loss: -803304.687500\n",
      "Train Epoch: 31 [39424/54000 (73%)] Loss: -861077.187500\n",
      "Train Epoch: 31 [40832/54000 (76%)] Loss: -804656.312500\n",
      "Train Epoch: 31 [42240/54000 (78%)] Loss: -880899.625000\n",
      "Train Epoch: 31 [43648/54000 (81%)] Loss: -767765.187500\n",
      "Train Epoch: 31 [45056/54000 (83%)] Loss: -758206.375000\n",
      "Train Epoch: 31 [46464/54000 (86%)] Loss: -770677.187500\n",
      "Train Epoch: 31 [47872/54000 (89%)] Loss: -783267.375000\n",
      "Train Epoch: 31 [49280/54000 (91%)] Loss: -813145.750000\n",
      "Train Epoch: 31 [50688/54000 (94%)] Loss: -815597.937500\n",
      "Train Epoch: 31 [52096/54000 (96%)] Loss: -832770.375000\n",
      "    epoch          : 31\n",
      "    loss           : -799512.6121411483\n",
      "    val_loss       : -802491.2848704269\n",
      "Train Epoch: 32 [0/54000 (0%)] Loss: -868978.250000\n",
      "Train Epoch: 32 [1408/54000 (3%)] Loss: -784689.875000\n",
      "Train Epoch: 32 [2816/54000 (5%)] Loss: -794507.875000\n",
      "Train Epoch: 32 [4224/54000 (8%)] Loss: -791677.312500\n",
      "Train Epoch: 32 [5632/54000 (10%)] Loss: -812705.875000\n",
      "Train Epoch: 32 [7040/54000 (13%)] Loss: -808073.875000\n",
      "Train Epoch: 32 [8448/54000 (16%)] Loss: -767128.375000\n",
      "Train Epoch: 32 [9856/54000 (18%)] Loss: -804167.125000\n",
      "Train Epoch: 32 [11264/54000 (21%)] Loss: -781441.875000\n",
      "Train Epoch: 32 [12672/54000 (23%)] Loss: -798080.750000\n",
      "Train Epoch: 32 [14080/54000 (26%)] Loss: -839033.375000\n",
      "Train Epoch: 32 [15488/54000 (29%)] Loss: -845952.875000\n",
      "Train Epoch: 32 [16896/54000 (31%)] Loss: -773836.187500\n",
      "Train Epoch: 32 [18304/54000 (34%)] Loss: -783726.000000\n",
      "Train Epoch: 32 [19712/54000 (37%)] Loss: -798779.250000\n",
      "Train Epoch: 32 [21120/54000 (39%)] Loss: -804043.625000\n",
      "Train Epoch: 32 [22528/54000 (42%)] Loss: -784655.062500\n",
      "Train Epoch: 32 [23936/54000 (44%)] Loss: -771335.250000\n",
      "Train Epoch: 32 [25344/54000 (47%)] Loss: -793691.937500\n",
      "Train Epoch: 32 [26752/54000 (50%)] Loss: -783988.875000\n",
      "Train Epoch: 32 [28160/54000 (52%)] Loss: -786435.875000\n",
      "Train Epoch: 32 [29568/54000 (55%)] Loss: -785555.000000\n",
      "Train Epoch: 32 [30976/54000 (57%)] Loss: -779552.750000\n",
      "Train Epoch: 32 [32384/54000 (60%)] Loss: -797479.250000\n",
      "Train Epoch: 32 [33792/54000 (63%)] Loss: -809182.937500\n",
      "Train Epoch: 32 [35200/54000 (65%)] Loss: -812982.125000\n",
      "Train Epoch: 32 [36608/54000 (68%)] Loss: -880187.312500\n",
      "Train Epoch: 32 [38016/54000 (70%)] Loss: -771602.437500\n",
      "Train Epoch: 32 [39424/54000 (73%)] Loss: -762723.625000\n",
      "Train Epoch: 32 [40832/54000 (76%)] Loss: -787274.812500\n",
      "Train Epoch: 32 [42240/54000 (78%)] Loss: -808107.000000\n",
      "Train Epoch: 32 [43648/54000 (81%)] Loss: -815555.687500\n",
      "Train Epoch: 32 [45056/54000 (83%)] Loss: -796430.375000\n",
      "Train Epoch: 32 [46464/54000 (86%)] Loss: -813207.437500\n",
      "Train Epoch: 32 [47872/54000 (89%)] Loss: -782714.500000\n",
      "Train Epoch: 32 [49280/54000 (91%)] Loss: -828714.250000\n",
      "Train Epoch: 32 [50688/54000 (94%)] Loss: -761260.625000\n",
      "Train Epoch: 32 [52096/54000 (96%)] Loss: -832115.250000\n",
      "    epoch          : 32\n",
      "    loss           : -799753.3207236842\n",
      "    val_loss       : -802711.4424542683\n",
      "Train Epoch: 33 [0/54000 (0%)] Loss: -761780.187500\n",
      "Train Epoch: 33 [1408/54000 (3%)] Loss: -791266.687500\n",
      "Train Epoch: 33 [2816/54000 (5%)] Loss: -800660.000000\n",
      "Train Epoch: 33 [4224/54000 (8%)] Loss: -796511.062500\n",
      "Train Epoch: 33 [5632/54000 (10%)] Loss: -791861.937500\n",
      "Train Epoch: 33 [7040/54000 (13%)] Loss: -808837.500000\n",
      "Train Epoch: 33 [8448/54000 (16%)] Loss: -814588.937500\n",
      "Train Epoch: 33 [9856/54000 (18%)] Loss: -777049.625000\n",
      "Train Epoch: 33 [11264/54000 (21%)] Loss: -821694.312500\n",
      "Train Epoch: 33 [12672/54000 (23%)] Loss: -883209.562500\n",
      "Train Epoch: 33 [14080/54000 (26%)] Loss: -824324.375000\n",
      "Train Epoch: 33 [15488/54000 (29%)] Loss: -756522.562500\n",
      "Train Epoch: 33 [16896/54000 (31%)] Loss: -765120.812500\n",
      "Train Epoch: 33 [18304/54000 (34%)] Loss: -797248.937500\n",
      "Train Epoch: 33 [19712/54000 (37%)] Loss: -789666.000000\n",
      "Train Epoch: 33 [21120/54000 (39%)] Loss: -752871.937500\n",
      "Train Epoch: 33 [22528/54000 (42%)] Loss: -784075.937500\n",
      "Train Epoch: 33 [23936/54000 (44%)] Loss: -815120.375000\n",
      "Train Epoch: 33 [25344/54000 (47%)] Loss: -815640.562500\n",
      "Train Epoch: 33 [26752/54000 (50%)] Loss: -823642.625000\n",
      "Train Epoch: 33 [28160/54000 (52%)] Loss: -756748.000000\n",
      "Train Epoch: 33 [29568/54000 (55%)] Loss: -789190.812500\n",
      "Train Epoch: 33 [30976/54000 (57%)] Loss: -830212.125000\n",
      "Train Epoch: 33 [32384/54000 (60%)] Loss: -831900.187500\n",
      "Train Epoch: 33 [33792/54000 (63%)] Loss: -830596.000000\n",
      "Train Epoch: 33 [35200/54000 (65%)] Loss: -785617.625000\n",
      "Train Epoch: 33 [36608/54000 (68%)] Loss: -777450.500000\n",
      "Train Epoch: 33 [38016/54000 (70%)] Loss: -790825.250000\n",
      "Train Epoch: 33 [39424/54000 (73%)] Loss: -783558.875000\n",
      "Train Epoch: 33 [40832/54000 (76%)] Loss: -794664.125000\n",
      "Train Epoch: 33 [42240/54000 (78%)] Loss: -769792.937500\n",
      "Train Epoch: 33 [43648/54000 (81%)] Loss: -787354.437500\n",
      "Train Epoch: 33 [45056/54000 (83%)] Loss: -875118.937500\n",
      "Train Epoch: 33 [46464/54000 (86%)] Loss: -787651.500000\n",
      "Train Epoch: 33 [47872/54000 (89%)] Loss: -786350.937500\n",
      "Train Epoch: 33 [49280/54000 (91%)] Loss: -829649.625000\n",
      "Train Epoch: 33 [50688/54000 (94%)] Loss: -761488.375000\n",
      "Train Epoch: 33 [52096/54000 (96%)] Loss: -763712.937500\n",
      "    epoch          : 33\n",
      "    loss           : -800447.4197069379\n",
      "    val_loss       : -802058.7219893293\n",
      "Train Epoch: 34 [0/54000 (0%)] Loss: -767917.500000\n",
      "Train Epoch: 34 [1408/54000 (3%)] Loss: -823308.687500\n",
      "Train Epoch: 34 [2816/54000 (5%)] Loss: -811075.000000\n",
      "Train Epoch: 34 [4224/54000 (8%)] Loss: -789829.437500\n",
      "Train Epoch: 34 [5632/54000 (10%)] Loss: -794791.187500\n",
      "Train Epoch: 34 [7040/54000 (13%)] Loss: -756084.000000\n",
      "Train Epoch: 34 [8448/54000 (16%)] Loss: -880379.375000\n",
      "Train Epoch: 34 [9856/54000 (18%)] Loss: -883602.437500\n",
      "Train Epoch: 34 [11264/54000 (21%)] Loss: -805157.500000\n",
      "Train Epoch: 34 [12672/54000 (23%)] Loss: -752122.375000\n",
      "Train Epoch: 34 [14080/54000 (26%)] Loss: -792873.562500\n",
      "Train Epoch: 34 [15488/54000 (29%)] Loss: -796593.250000\n",
      "Train Epoch: 34 [16896/54000 (31%)] Loss: -805461.750000\n",
      "Train Epoch: 34 [18304/54000 (34%)] Loss: -786492.875000\n",
      "Train Epoch: 34 [19712/54000 (37%)] Loss: -786334.875000\n",
      "Train Epoch: 34 [21120/54000 (39%)] Loss: -792770.937500\n",
      "Train Epoch: 34 [22528/54000 (42%)] Loss: -818026.187500\n",
      "Train Epoch: 34 [23936/54000 (44%)] Loss: -785824.250000\n",
      "Train Epoch: 34 [25344/54000 (47%)] Loss: -801260.000000\n",
      "Train Epoch: 34 [26752/54000 (50%)] Loss: -873523.875000\n",
      "Train Epoch: 34 [28160/54000 (52%)] Loss: -787602.750000\n",
      "Train Epoch: 34 [29568/54000 (55%)] Loss: -760471.375000\n",
      "Train Epoch: 34 [30976/54000 (57%)] Loss: -825524.562500\n",
      "Train Epoch: 34 [32384/54000 (60%)] Loss: -827573.312500\n",
      "Train Epoch: 34 [33792/54000 (63%)] Loss: -804313.687500\n",
      "Train Epoch: 34 [35200/54000 (65%)] Loss: -817688.937500\n",
      "Train Epoch: 34 [36608/54000 (68%)] Loss: -755463.750000\n",
      "Train Epoch: 34 [38016/54000 (70%)] Loss: -822566.750000\n",
      "Train Epoch: 34 [39424/54000 (73%)] Loss: -752498.687500\n",
      "Train Epoch: 34 [40832/54000 (76%)] Loss: -846300.812500\n",
      "Train Epoch: 34 [42240/54000 (78%)] Loss: -767351.312500\n",
      "Train Epoch: 34 [43648/54000 (81%)] Loss: -871272.125000\n",
      "Train Epoch: 34 [45056/54000 (83%)] Loss: -830102.812500\n",
      "Train Epoch: 34 [46464/54000 (86%)] Loss: -788386.375000\n",
      "Train Epoch: 34 [47872/54000 (89%)] Loss: -818900.187500\n",
      "Train Epoch: 34 [49280/54000 (91%)] Loss: -804777.500000\n",
      "Train Epoch: 34 [50688/54000 (94%)] Loss: -756848.375000\n",
      "Train Epoch: 34 [52096/54000 (96%)] Loss: -768168.875000\n",
      "    epoch          : 34\n",
      "    loss           : -800781.2203947369\n",
      "    val_loss       : -803975.7831554879\n",
      "Train Epoch: 35 [0/54000 (0%)] Loss: -762368.500000\n",
      "Train Epoch: 35 [1408/54000 (3%)] Loss: -880797.125000\n",
      "Train Epoch: 35 [2816/54000 (5%)] Loss: -803580.062500\n",
      "Train Epoch: 35 [4224/54000 (8%)] Loss: -789469.375000\n",
      "Train Epoch: 35 [5632/54000 (10%)] Loss: -790819.625000\n",
      "Train Epoch: 35 [7040/54000 (13%)] Loss: -790421.437500\n",
      "Train Epoch: 35 [8448/54000 (16%)] Loss: -802622.437500\n",
      "Train Epoch: 35 [9856/54000 (18%)] Loss: -760606.187500\n",
      "Train Epoch: 35 [11264/54000 (21%)] Loss: -820968.000000\n",
      "Train Epoch: 35 [12672/54000 (23%)] Loss: -836914.437500\n",
      "Train Epoch: 35 [14080/54000 (26%)] Loss: -822260.500000\n",
      "Train Epoch: 35 [15488/54000 (29%)] Loss: -753983.937500\n",
      "Train Epoch: 35 [16896/54000 (31%)] Loss: -760161.750000\n",
      "Train Epoch: 35 [18304/54000 (34%)] Loss: -791685.875000\n",
      "Train Epoch: 35 [19712/54000 (37%)] Loss: -800369.125000\n",
      "Train Epoch: 35 [21120/54000 (39%)] Loss: -794121.125000\n",
      "Train Epoch: 35 [22528/54000 (42%)] Loss: -882304.750000\n",
      "Train Epoch: 35 [23936/54000 (44%)] Loss: -867895.375000\n",
      "Train Epoch: 35 [25344/54000 (47%)] Loss: -766032.250000\n",
      "Train Epoch: 35 [26752/54000 (50%)] Loss: -796760.000000\n",
      "Train Epoch: 35 [28160/54000 (52%)] Loss: -756591.875000\n",
      "Train Epoch: 35 [29568/54000 (55%)] Loss: -791981.687500\n",
      "Train Epoch: 35 [30976/54000 (57%)] Loss: -757733.812500\n",
      "Train Epoch: 35 [32384/54000 (60%)] Loss: -813903.437500\n",
      "Train Epoch: 35 [33792/54000 (63%)] Loss: -764238.875000\n",
      "Train Epoch: 35 [35200/54000 (65%)] Loss: -824134.312500\n",
      "Train Epoch: 35 [36608/54000 (68%)] Loss: -787170.062500\n",
      "Train Epoch: 35 [38016/54000 (70%)] Loss: -763884.937500\n",
      "Train Epoch: 35 [39424/54000 (73%)] Loss: -789643.812500\n",
      "Train Epoch: 35 [40832/54000 (76%)] Loss: -791683.750000\n",
      "Train Epoch: 35 [42240/54000 (78%)] Loss: -789882.375000\n",
      "Train Epoch: 35 [43648/54000 (81%)] Loss: -760221.187500\n",
      "Train Epoch: 35 [45056/54000 (83%)] Loss: -876646.937500\n",
      "Train Epoch: 35 [46464/54000 (86%)] Loss: -806705.812500\n",
      "Train Epoch: 35 [47872/54000 (89%)] Loss: -790673.937500\n",
      "Train Epoch: 35 [49280/54000 (91%)] Loss: -759175.750000\n",
      "Train Epoch: 35 [50688/54000 (94%)] Loss: -847146.687500\n",
      "Train Epoch: 35 [52096/54000 (96%)] Loss: -768848.125000\n",
      "    epoch          : 35\n",
      "    loss           : -801080.2996411483\n",
      "    val_loss       : -804364.1476753049\n",
      "Saving checkpoint: saved/models/Mnist_VaeCategory/0422_221614/checkpoint-epoch35.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 36 [0/54000 (0%)] Loss: -800937.750000\n",
      "Train Epoch: 36 [1408/54000 (3%)] Loss: -762707.000000\n",
      "Train Epoch: 36 [2816/54000 (5%)] Loss: -775336.312500\n",
      "Train Epoch: 36 [4224/54000 (8%)] Loss: -806743.875000\n",
      "Train Epoch: 36 [5632/54000 (10%)] Loss: -801456.125000\n",
      "Train Epoch: 36 [7040/54000 (13%)] Loss: -828971.875000\n",
      "Train Epoch: 36 [8448/54000 (16%)] Loss: -816081.750000\n",
      "Train Epoch: 36 [9856/54000 (18%)] Loss: -788913.187500\n",
      "Train Epoch: 36 [11264/54000 (21%)] Loss: -868454.625000\n",
      "Train Epoch: 36 [12672/54000 (23%)] Loss: -793478.625000\n",
      "Train Epoch: 36 [14080/54000 (26%)] Loss: -815416.625000\n",
      "Train Epoch: 36 [15488/54000 (29%)] Loss: -776247.750000\n",
      "Train Epoch: 36 [16896/54000 (31%)] Loss: -760414.250000\n",
      "Train Epoch: 36 [18304/54000 (34%)] Loss: -816967.125000\n",
      "Train Epoch: 36 [19712/54000 (37%)] Loss: -793659.250000\n",
      "Train Epoch: 36 [21120/54000 (39%)] Loss: -826773.750000\n",
      "Train Epoch: 36 [22528/54000 (42%)] Loss: -796435.250000\n",
      "Train Epoch: 36 [23936/54000 (44%)] Loss: -809382.375000\n",
      "Train Epoch: 36 [25344/54000 (47%)] Loss: -766011.000000\n",
      "Train Epoch: 36 [26752/54000 (50%)] Loss: -806095.000000\n",
      "Train Epoch: 36 [28160/54000 (52%)] Loss: -754627.000000\n",
      "Train Epoch: 36 [29568/54000 (55%)] Loss: -881109.562500\n",
      "Train Epoch: 36 [30976/54000 (57%)] Loss: -807403.000000\n",
      "Train Epoch: 36 [32384/54000 (60%)] Loss: -792977.937500\n",
      "Train Epoch: 36 [33792/54000 (63%)] Loss: -752550.437500\n",
      "Train Epoch: 36 [35200/54000 (65%)] Loss: -833243.875000\n",
      "Train Epoch: 36 [36608/54000 (68%)] Loss: -809738.625000\n",
      "Train Epoch: 36 [38016/54000 (70%)] Loss: -766718.625000\n",
      "Train Epoch: 36 [39424/54000 (73%)] Loss: -764482.500000\n",
      "Train Epoch: 36 [40832/54000 (76%)] Loss: -800868.687500\n",
      "Train Epoch: 36 [42240/54000 (78%)] Loss: -801945.312500\n",
      "Train Epoch: 36 [43648/54000 (81%)] Loss: -749382.500000\n",
      "Train Epoch: 36 [45056/54000 (83%)] Loss: -762183.187500\n",
      "Train Epoch: 36 [46464/54000 (86%)] Loss: -785136.375000\n",
      "Train Epoch: 36 [47872/54000 (89%)] Loss: -795882.062500\n",
      "Train Epoch: 36 [49280/54000 (91%)] Loss: -833591.812500\n",
      "Train Epoch: 36 [50688/54000 (94%)] Loss: -810561.812500\n",
      "Train Epoch: 36 [52096/54000 (96%)] Loss: -758802.625000\n",
      "    epoch          : 36\n",
      "    loss           : -801847.1798744019\n",
      "    val_loss       : -804456.4868521341\n",
      "Train Epoch: 37 [0/54000 (0%)] Loss: -763352.875000\n",
      "Train Epoch: 37 [1408/54000 (3%)] Loss: -808612.687500\n",
      "Train Epoch: 37 [2816/54000 (5%)] Loss: -774857.500000\n",
      "Train Epoch: 37 [4224/54000 (8%)] Loss: -790026.562500\n",
      "Train Epoch: 37 [5632/54000 (10%)] Loss: -821028.500000\n",
      "Train Epoch: 37 [7040/54000 (13%)] Loss: -831332.125000\n",
      "Train Epoch: 37 [8448/54000 (16%)] Loss: -885288.875000\n",
      "Train Epoch: 37 [9856/54000 (18%)] Loss: -794955.250000\n",
      "Train Epoch: 37 [11264/54000 (21%)] Loss: -879166.125000\n",
      "Train Epoch: 37 [12672/54000 (23%)] Loss: -818507.750000\n",
      "Train Epoch: 37 [14080/54000 (26%)] Loss: -807578.187500\n",
      "Train Epoch: 37 [15488/54000 (29%)] Loss: -798800.750000\n",
      "Train Epoch: 37 [16896/54000 (31%)] Loss: -792771.875000\n",
      "Train Epoch: 37 [18304/54000 (34%)] Loss: -784546.875000\n",
      "Train Epoch: 37 [19712/54000 (37%)] Loss: -772282.500000\n",
      "Train Epoch: 37 [21120/54000 (39%)] Loss: -763834.937500\n",
      "Train Epoch: 37 [22528/54000 (42%)] Loss: -801049.375000\n",
      "Train Epoch: 37 [23936/54000 (44%)] Loss: -799492.375000\n",
      "Train Epoch: 37 [25344/54000 (47%)] Loss: -804401.875000\n",
      "Train Epoch: 37 [26752/54000 (50%)] Loss: -842267.125000\n",
      "Train Epoch: 37 [28160/54000 (52%)] Loss: -803704.875000\n",
      "Train Epoch: 37 [29568/54000 (55%)] Loss: -817135.187500\n",
      "Train Epoch: 37 [30976/54000 (57%)] Loss: -762711.937500\n",
      "Train Epoch: 37 [32384/54000 (60%)] Loss: -783365.437500\n",
      "Train Epoch: 37 [33792/54000 (63%)] Loss: -769295.500000\n",
      "Train Epoch: 37 [35200/54000 (65%)] Loss: -759841.625000\n",
      "Train Epoch: 37 [36608/54000 (68%)] Loss: -816887.750000\n",
      "Train Epoch: 37 [38016/54000 (70%)] Loss: -809495.375000\n",
      "Train Epoch: 37 [39424/54000 (73%)] Loss: -778072.312500\n",
      "Train Epoch: 37 [40832/54000 (76%)] Loss: -780950.125000\n",
      "Train Epoch: 37 [42240/54000 (78%)] Loss: -887749.812500\n",
      "Train Epoch: 37 [43648/54000 (81%)] Loss: -793306.312500\n",
      "Train Epoch: 37 [45056/54000 (83%)] Loss: -801368.437500\n",
      "Train Epoch: 37 [46464/54000 (86%)] Loss: -792696.625000\n",
      "Train Epoch: 37 [47872/54000 (89%)] Loss: -815102.062500\n",
      "Train Epoch: 37 [49280/54000 (91%)] Loss: -836665.875000\n",
      "Train Epoch: 37 [50688/54000 (94%)] Loss: -842712.187500\n",
      "Train Epoch: 37 [52096/54000 (96%)] Loss: -801775.687500\n",
      "    epoch          : 37\n",
      "    loss           : -802209.8962320574\n",
      "    val_loss       : -804396.2425685975\n",
      "Train Epoch: 38 [0/54000 (0%)] Loss: -760230.812500\n",
      "Train Epoch: 38 [1408/54000 (3%)] Loss: -766234.562500\n",
      "Train Epoch: 38 [2816/54000 (5%)] Loss: -823408.437500\n",
      "Train Epoch: 38 [4224/54000 (8%)] Loss: -770203.812500\n",
      "Train Epoch: 38 [5632/54000 (10%)] Loss: -793026.625000\n",
      "Train Epoch: 38 [7040/54000 (13%)] Loss: -796496.562500\n",
      "Train Epoch: 38 [8448/54000 (16%)] Loss: -836814.875000\n",
      "Train Epoch: 38 [9856/54000 (18%)] Loss: -844257.937500\n",
      "Train Epoch: 38 [11264/54000 (21%)] Loss: -818245.125000\n",
      "Train Epoch: 38 [12672/54000 (23%)] Loss: -835333.437500\n",
      "Train Epoch: 38 [14080/54000 (26%)] Loss: -790690.250000\n",
      "Train Epoch: 38 [15488/54000 (29%)] Loss: -769301.687500\n",
      "Train Epoch: 38 [16896/54000 (31%)] Loss: -752848.250000\n",
      "Train Epoch: 38 [18304/54000 (34%)] Loss: -876691.125000\n",
      "Train Epoch: 38 [19712/54000 (37%)] Loss: -813876.875000\n",
      "Train Epoch: 38 [21120/54000 (39%)] Loss: -817089.500000\n",
      "Train Epoch: 38 [22528/54000 (42%)] Loss: -825875.562500\n",
      "Train Epoch: 38 [23936/54000 (44%)] Loss: -792064.937500\n",
      "Train Epoch: 38 [25344/54000 (47%)] Loss: -812352.750000\n",
      "Train Epoch: 38 [26752/54000 (50%)] Loss: -823378.500000\n",
      "Train Epoch: 38 [28160/54000 (52%)] Loss: -760804.000000\n",
      "Train Epoch: 38 [29568/54000 (55%)] Loss: -781014.250000\n",
      "Train Epoch: 38 [30976/54000 (57%)] Loss: -792724.375000\n",
      "Train Epoch: 38 [32384/54000 (60%)] Loss: -775732.562500\n",
      "Train Epoch: 38 [33792/54000 (63%)] Loss: -797222.125000\n",
      "Train Epoch: 38 [35200/54000 (65%)] Loss: -797443.062500\n",
      "Train Epoch: 38 [36608/54000 (68%)] Loss: -786587.687500\n",
      "Train Epoch: 38 [38016/54000 (70%)] Loss: -796841.000000\n",
      "Train Epoch: 38 [39424/54000 (73%)] Loss: -800035.937500\n",
      "Train Epoch: 38 [40832/54000 (76%)] Loss: -761563.312500\n",
      "Train Epoch: 38 [42240/54000 (78%)] Loss: -887750.750000\n",
      "Train Epoch: 38 [43648/54000 (81%)] Loss: -772313.375000\n",
      "Train Epoch: 38 [45056/54000 (83%)] Loss: -761089.125000\n",
      "Train Epoch: 38 [46464/54000 (86%)] Loss: -834582.000000\n",
      "Train Epoch: 38 [47872/54000 (89%)] Loss: -758199.750000\n",
      "Train Epoch: 38 [49280/54000 (91%)] Loss: -781474.625000\n",
      "Train Epoch: 38 [50688/54000 (94%)] Loss: -768993.750000\n",
      "Train Epoch: 38 [52096/54000 (96%)] Loss: -822357.812500\n",
      "    epoch          : 38\n",
      "    loss           : -802496.0711722488\n",
      "    val_loss       : -803781.7147484756\n",
      "Train Epoch: 39 [0/54000 (0%)] Loss: -766083.875000\n",
      "Train Epoch: 39 [1408/54000 (3%)] Loss: -758332.375000\n",
      "Train Epoch: 39 [2816/54000 (5%)] Loss: -763743.000000\n",
      "Train Epoch: 39 [4224/54000 (8%)] Loss: -830923.000000\n",
      "Train Epoch: 39 [5632/54000 (10%)] Loss: -808131.625000\n",
      "Train Epoch: 39 [7040/54000 (13%)] Loss: -783992.125000\n",
      "Train Epoch: 39 [8448/54000 (16%)] Loss: -805897.750000\n",
      "Train Epoch: 39 [9856/54000 (18%)] Loss: -809070.000000\n",
      "Train Epoch: 39 [11264/54000 (21%)] Loss: -793921.125000\n",
      "Train Epoch: 39 [12672/54000 (23%)] Loss: -799259.187500\n",
      "Train Epoch: 39 [14080/54000 (26%)] Loss: -793300.500000\n",
      "Train Epoch: 39 [15488/54000 (29%)] Loss: -775220.750000\n",
      "Train Epoch: 39 [16896/54000 (31%)] Loss: -829098.062500\n",
      "Train Epoch: 39 [18304/54000 (34%)] Loss: -794396.250000\n",
      "Train Epoch: 39 [19712/54000 (37%)] Loss: -776656.000000\n",
      "Train Epoch: 39 [21120/54000 (39%)] Loss: -787651.437500\n",
      "Train Epoch: 39 [22528/54000 (42%)] Loss: -807303.312500\n",
      "Train Epoch: 39 [23936/54000 (44%)] Loss: -773590.125000\n",
      "Train Epoch: 39 [25344/54000 (47%)] Loss: -764726.312500\n",
      "Train Epoch: 39 [26752/54000 (50%)] Loss: -764342.000000\n",
      "Train Epoch: 39 [28160/54000 (52%)] Loss: -811717.000000\n",
      "Train Epoch: 39 [29568/54000 (55%)] Loss: -819388.812500\n",
      "Train Epoch: 39 [30976/54000 (57%)] Loss: -754265.500000\n",
      "Train Epoch: 39 [32384/54000 (60%)] Loss: -806291.375000\n",
      "Train Epoch: 39 [33792/54000 (63%)] Loss: -802226.562500\n",
      "Train Epoch: 39 [35200/54000 (65%)] Loss: -803543.812500\n",
      "Train Epoch: 39 [36608/54000 (68%)] Loss: -754158.062500\n",
      "Train Epoch: 39 [38016/54000 (70%)] Loss: -811991.750000\n",
      "Train Epoch: 39 [39424/54000 (73%)] Loss: -812179.312500\n",
      "Train Epoch: 39 [40832/54000 (76%)] Loss: -805583.937500\n",
      "Train Epoch: 39 [42240/54000 (78%)] Loss: -814827.812500\n",
      "Train Epoch: 39 [43648/54000 (81%)] Loss: -752634.687500\n",
      "Train Epoch: 39 [45056/54000 (83%)] Loss: -781165.750000\n",
      "Train Epoch: 39 [46464/54000 (86%)] Loss: -840409.000000\n",
      "Train Epoch: 39 [47872/54000 (89%)] Loss: -840419.000000\n",
      "Train Epoch: 39 [49280/54000 (91%)] Loss: -812437.000000\n",
      "Train Epoch: 39 [50688/54000 (94%)] Loss: -839030.687500\n",
      "Train Epoch: 39 [52096/54000 (96%)] Loss: -825631.375000\n",
      "    epoch          : 39\n",
      "    loss           : -802459.5148026316\n",
      "    val_loss       : -805173.4384527439\n",
      "Train Epoch: 40 [0/54000 (0%)] Loss: -812732.625000\n",
      "Train Epoch: 40 [1408/54000 (3%)] Loss: -815731.687500\n",
      "Train Epoch: 40 [2816/54000 (5%)] Loss: -799920.187500\n",
      "Train Epoch: 40 [4224/54000 (8%)] Loss: -766381.375000\n",
      "Train Epoch: 40 [5632/54000 (10%)] Loss: -792743.937500\n",
      "Train Epoch: 40 [7040/54000 (13%)] Loss: -891171.125000\n",
      "Train Epoch: 40 [8448/54000 (16%)] Loss: -805534.625000\n",
      "Train Epoch: 40 [9856/54000 (18%)] Loss: -812483.375000\n",
      "Train Epoch: 40 [11264/54000 (21%)] Loss: -785855.750000\n",
      "Train Epoch: 40 [12672/54000 (23%)] Loss: -797200.062500\n",
      "Train Epoch: 40 [14080/54000 (26%)] Loss: -756476.250000\n",
      "Train Epoch: 40 [15488/54000 (29%)] Loss: -799702.875000\n",
      "Train Epoch: 40 [16896/54000 (31%)] Loss: -786463.000000\n",
      "Train Epoch: 40 [18304/54000 (34%)] Loss: -790810.875000\n",
      "Train Epoch: 40 [19712/54000 (37%)] Loss: -821584.312500\n",
      "Train Epoch: 40 [21120/54000 (39%)] Loss: -822143.312500\n",
      "Train Epoch: 40 [22528/54000 (42%)] Loss: -819886.750000\n",
      "Train Epoch: 40 [23936/54000 (44%)] Loss: -878618.937500\n",
      "Train Epoch: 40 [25344/54000 (47%)] Loss: -862014.875000\n",
      "Train Epoch: 40 [26752/54000 (50%)] Loss: -768899.000000\n",
      "Train Epoch: 40 [28160/54000 (52%)] Loss: -756286.250000\n",
      "Train Epoch: 40 [29568/54000 (55%)] Loss: -823015.750000\n",
      "Train Epoch: 40 [30976/54000 (57%)] Loss: -782395.187500\n",
      "Train Epoch: 40 [32384/54000 (60%)] Loss: -773433.312500\n",
      "Train Epoch: 40 [33792/54000 (63%)] Loss: -797479.625000\n",
      "Train Epoch: 40 [35200/54000 (65%)] Loss: -838583.125000\n",
      "Train Epoch: 40 [36608/54000 (68%)] Loss: -806190.937500\n",
      "Train Epoch: 40 [38016/54000 (70%)] Loss: -837760.000000\n",
      "Train Epoch: 40 [39424/54000 (73%)] Loss: -811802.562500\n",
      "Train Epoch: 40 [40832/54000 (76%)] Loss: -834454.500000\n",
      "Train Epoch: 40 [42240/54000 (78%)] Loss: -805115.000000\n",
      "Train Epoch: 40 [43648/54000 (81%)] Loss: -827390.375000\n",
      "Train Epoch: 40 [45056/54000 (83%)] Loss: -830277.937500\n",
      "Train Epoch: 40 [46464/54000 (86%)] Loss: -794367.875000\n",
      "Train Epoch: 40 [47872/54000 (89%)] Loss: -809509.937500\n",
      "Train Epoch: 40 [49280/54000 (91%)] Loss: -793083.750000\n",
      "Train Epoch: 40 [50688/54000 (94%)] Loss: -785035.250000\n",
      "Train Epoch: 40 [52096/54000 (96%)] Loss: -797973.312500\n",
      "    epoch          : 40\n",
      "    loss           : -802738.2488038278\n",
      "    val_loss       : -804135.8355564025\n",
      "Saving checkpoint: saved/models/Mnist_VaeCategory/0422_221614/checkpoint-epoch40.pth ...\n",
      "Train Epoch: 41 [0/54000 (0%)] Loss: -768044.000000\n",
      "Train Epoch: 41 [1408/54000 (3%)] Loss: -769452.812500\n",
      "Train Epoch: 41 [2816/54000 (5%)] Loss: -777949.687500\n",
      "Train Epoch: 41 [4224/54000 (8%)] Loss: -808782.562500\n",
      "Train Epoch: 41 [5632/54000 (10%)] Loss: -891321.437500\n",
      "Train Epoch: 41 [7040/54000 (13%)] Loss: -788253.750000\n",
      "Train Epoch: 41 [8448/54000 (16%)] Loss: -789275.437500\n",
      "Train Epoch: 41 [9856/54000 (18%)] Loss: -792185.562500\n",
      "Train Epoch: 41 [11264/54000 (21%)] Loss: -760028.750000\n",
      "Train Epoch: 41 [12672/54000 (23%)] Loss: -815052.937500\n",
      "Train Epoch: 41 [14080/54000 (26%)] Loss: -810415.562500\n",
      "Train Epoch: 41 [15488/54000 (29%)] Loss: -819098.500000\n",
      "Train Epoch: 41 [16896/54000 (31%)] Loss: -755047.250000\n",
      "Train Epoch: 41 [18304/54000 (34%)] Loss: -778081.500000\n",
      "Train Epoch: 41 [19712/54000 (37%)] Loss: -796105.125000\n",
      "Train Epoch: 41 [21120/54000 (39%)] Loss: -794720.500000\n",
      "Train Epoch: 41 [22528/54000 (42%)] Loss: -820359.625000\n",
      "Train Epoch: 41 [23936/54000 (44%)] Loss: -822464.875000\n",
      "Train Epoch: 41 [25344/54000 (47%)] Loss: -785034.562500\n",
      "Train Epoch: 41 [26752/54000 (50%)] Loss: -837788.062500\n",
      "Train Epoch: 41 [28160/54000 (52%)] Loss: -795083.500000\n",
      "Train Epoch: 41 [29568/54000 (55%)] Loss: -768930.437500\n",
      "Train Epoch: 41 [30976/54000 (57%)] Loss: -878451.062500\n",
      "Train Epoch: 41 [32384/54000 (60%)] Loss: -760904.312500\n",
      "Train Epoch: 41 [33792/54000 (63%)] Loss: -881749.187500\n",
      "Train Epoch: 41 [35200/54000 (65%)] Loss: -817414.562500\n",
      "Train Epoch: 41 [36608/54000 (68%)] Loss: -767425.562500\n",
      "Train Epoch: 41 [38016/54000 (70%)] Loss: -773096.187500\n",
      "Train Epoch: 41 [39424/54000 (73%)] Loss: -784697.625000\n",
      "Train Epoch: 41 [40832/54000 (76%)] Loss: -794343.125000\n",
      "Train Epoch: 41 [42240/54000 (78%)] Loss: -791169.500000\n",
      "Train Epoch: 41 [43648/54000 (81%)] Loss: -784083.687500\n",
      "Train Epoch: 41 [45056/54000 (83%)] Loss: -822323.375000\n",
      "Train Epoch: 41 [46464/54000 (86%)] Loss: -796254.375000\n",
      "Train Epoch: 41 [47872/54000 (89%)] Loss: -811721.250000\n",
      "Train Epoch: 41 [49280/54000 (91%)] Loss: -799487.562500\n",
      "Train Epoch: 41 [50688/54000 (94%)] Loss: -826778.937500\n",
      "Train Epoch: 41 [52096/54000 (96%)] Loss: -769810.812500\n",
      "    epoch          : 41\n",
      "    loss           : -803224.795604067\n",
      "    val_loss       : -803460.1280487805\n",
      "Train Epoch: 42 [0/54000 (0%)] Loss: -750704.625000\n",
      "Train Epoch: 42 [1408/54000 (3%)] Loss: -766159.500000\n",
      "Train Epoch: 42 [2816/54000 (5%)] Loss: -789657.875000\n",
      "Train Epoch: 42 [4224/54000 (8%)] Loss: -839967.875000\n",
      "Train Epoch: 42 [5632/54000 (10%)] Loss: -815071.875000\n",
      "Train Epoch: 42 [7040/54000 (13%)] Loss: -822763.750000\n",
      "Train Epoch: 42 [8448/54000 (16%)] Loss: -893646.687500\n",
      "Train Epoch: 42 [9856/54000 (18%)] Loss: -757864.437500\n",
      "Train Epoch: 42 [11264/54000 (21%)] Loss: -809246.500000\n",
      "Train Epoch: 42 [12672/54000 (23%)] Loss: -785160.625000\n",
      "Train Epoch: 42 [14080/54000 (26%)] Loss: -768669.000000\n",
      "Train Epoch: 42 [15488/54000 (29%)] Loss: -834645.625000\n",
      "Train Epoch: 42 [16896/54000 (31%)] Loss: -759209.625000\n",
      "Train Epoch: 42 [18304/54000 (34%)] Loss: -837682.375000\n",
      "Train Epoch: 42 [19712/54000 (37%)] Loss: -885298.437500\n",
      "Train Epoch: 42 [21120/54000 (39%)] Loss: -885120.000000\n",
      "Train Epoch: 42 [22528/54000 (42%)] Loss: -843467.875000\n",
      "Train Epoch: 42 [23936/54000 (44%)] Loss: -813832.687500\n",
      "Train Epoch: 42 [25344/54000 (47%)] Loss: -763169.500000\n",
      "Train Epoch: 42 [26752/54000 (50%)] Loss: -802102.000000\n",
      "Train Epoch: 42 [28160/54000 (52%)] Loss: -789637.937500\n",
      "Train Epoch: 42 [29568/54000 (55%)] Loss: -753355.312500\n",
      "Train Epoch: 42 [30976/54000 (57%)] Loss: -814732.000000\n",
      "Train Epoch: 42 [32384/54000 (60%)] Loss: -774717.375000\n",
      "Train Epoch: 42 [33792/54000 (63%)] Loss: -818155.250000\n",
      "Train Epoch: 42 [35200/54000 (65%)] Loss: -802928.312500\n",
      "Train Epoch: 42 [36608/54000 (68%)] Loss: -814407.250000\n",
      "Train Epoch: 42 [38016/54000 (70%)] Loss: -800042.562500\n",
      "Train Epoch: 42 [39424/54000 (73%)] Loss: -815540.812500\n",
      "Train Epoch: 42 [40832/54000 (76%)] Loss: -757629.562500\n",
      "Train Epoch: 42 [42240/54000 (78%)] Loss: -787551.062500\n",
      "Train Epoch: 42 [43648/54000 (81%)] Loss: -760100.375000\n",
      "Train Epoch: 42 [45056/54000 (83%)] Loss: -814760.375000\n",
      "Train Epoch: 42 [46464/54000 (86%)] Loss: -780856.375000\n",
      "Train Epoch: 42 [47872/54000 (89%)] Loss: -827185.125000\n",
      "Train Epoch: 42 [49280/54000 (91%)] Loss: -757943.500000\n",
      "Train Epoch: 42 [50688/54000 (94%)] Loss: -807931.125000\n",
      "Train Epoch: 42 [52096/54000 (96%)] Loss: -798239.187500\n",
      "    epoch          : 42\n",
      "    loss           : -803216.843450957\n",
      "    val_loss       : -804842.8365091464\n",
      "Train Epoch: 43 [0/54000 (0%)] Loss: -769278.312500\n",
      "Train Epoch: 43 [1408/54000 (3%)] Loss: -758177.937500\n",
      "Train Epoch: 43 [2816/54000 (5%)] Loss: -793359.250000\n",
      "Train Epoch: 43 [4224/54000 (8%)] Loss: -813760.687500\n",
      "Train Epoch: 43 [5632/54000 (10%)] Loss: -819283.000000\n",
      "Train Epoch: 43 [7040/54000 (13%)] Loss: -796253.312500\n",
      "Train Epoch: 43 [8448/54000 (16%)] Loss: -882268.875000\n",
      "Train Epoch: 43 [9856/54000 (18%)] Loss: -815840.437500\n",
      "Train Epoch: 43 [11264/54000 (21%)] Loss: -760762.187500\n",
      "Train Epoch: 43 [12672/54000 (23%)] Loss: -831474.312500\n",
      "Train Epoch: 43 [14080/54000 (26%)] Loss: -787907.125000\n",
      "Train Epoch: 43 [15488/54000 (29%)] Loss: -761633.375000\n",
      "Train Epoch: 43 [16896/54000 (31%)] Loss: -807827.437500\n",
      "Train Epoch: 43 [18304/54000 (34%)] Loss: -818955.875000\n",
      "Train Epoch: 43 [19712/54000 (37%)] Loss: -810605.250000\n",
      "Train Epoch: 43 [21120/54000 (39%)] Loss: -815886.625000\n",
      "Train Epoch: 43 [22528/54000 (42%)] Loss: -827256.062500\n",
      "Train Epoch: 43 [23936/54000 (44%)] Loss: -786045.500000\n",
      "Train Epoch: 43 [25344/54000 (47%)] Loss: -756283.625000\n",
      "Train Epoch: 43 [26752/54000 (50%)] Loss: -874140.250000\n",
      "Train Epoch: 43 [28160/54000 (52%)] Loss: -871113.625000\n",
      "Train Epoch: 43 [29568/54000 (55%)] Loss: -786892.375000\n",
      "Train Epoch: 43 [30976/54000 (57%)] Loss: -780370.875000\n",
      "Train Epoch: 43 [32384/54000 (60%)] Loss: -759282.000000\n",
      "Train Epoch: 43 [33792/54000 (63%)] Loss: -791524.125000\n",
      "Train Epoch: 43 [35200/54000 (65%)] Loss: -791649.625000\n",
      "Train Epoch: 43 [36608/54000 (68%)] Loss: -766983.750000\n",
      "Train Epoch: 43 [38016/54000 (70%)] Loss: -808609.062500\n",
      "Train Epoch: 43 [39424/54000 (73%)] Loss: -760127.187500\n",
      "Train Epoch: 43 [40832/54000 (76%)] Loss: -814416.500000\n",
      "Train Epoch: 43 [42240/54000 (78%)] Loss: -794001.437500\n",
      "Train Epoch: 43 [43648/54000 (81%)] Loss: -789948.812500\n",
      "Train Epoch: 43 [45056/54000 (83%)] Loss: -757037.500000\n",
      "Train Epoch: 43 [46464/54000 (86%)] Loss: -800114.375000\n",
      "Train Epoch: 43 [47872/54000 (89%)] Loss: -814945.437500\n",
      "Train Epoch: 43 [49280/54000 (91%)] Loss: -842494.375000\n",
      "Train Epoch: 43 [50688/54000 (94%)] Loss: -844659.687500\n",
      "Train Epoch: 43 [52096/54000 (96%)] Loss: -831814.562500\n",
      "    epoch          : 43\n",
      "    loss           : -803432.2619617225\n",
      "    val_loss       : -805352.1631097561\n",
      "Train Epoch: 44 [0/54000 (0%)] Loss: -814037.000000\n",
      "Train Epoch: 44 [1408/54000 (3%)] Loss: -843055.250000\n",
      "Train Epoch: 44 [2816/54000 (5%)] Loss: -774305.312500\n",
      "Train Epoch: 44 [4224/54000 (8%)] Loss: -881866.500000\n",
      "Train Epoch: 44 [5632/54000 (10%)] Loss: -761071.937500\n",
      "Train Epoch: 44 [7040/54000 (13%)] Loss: -800563.312500\n",
      "Train Epoch: 44 [8448/54000 (16%)] Loss: -806504.937500\n",
      "Train Epoch: 44 [9856/54000 (18%)] Loss: -811926.125000\n",
      "Train Epoch: 44 [11264/54000 (21%)] Loss: -787674.437500\n",
      "Train Epoch: 44 [12672/54000 (23%)] Loss: -816315.625000\n",
      "Train Epoch: 44 [14080/54000 (26%)] Loss: -792566.625000\n",
      "Train Epoch: 44 [15488/54000 (29%)] Loss: -795984.375000\n",
      "Train Epoch: 44 [16896/54000 (31%)] Loss: -786762.750000\n",
      "Train Epoch: 44 [18304/54000 (34%)] Loss: -833132.500000\n",
      "Train Epoch: 44 [19712/54000 (37%)] Loss: -757207.500000\n",
      "Train Epoch: 44 [21120/54000 (39%)] Loss: -811005.562500\n",
      "Train Epoch: 44 [22528/54000 (42%)] Loss: -769190.000000\n",
      "Train Epoch: 44 [23936/54000 (44%)] Loss: -783060.750000\n",
      "Train Epoch: 44 [25344/54000 (47%)] Loss: -797481.500000\n",
      "Train Epoch: 44 [26752/54000 (50%)] Loss: -792266.062500\n",
      "Train Epoch: 44 [28160/54000 (52%)] Loss: -836756.250000\n",
      "Train Epoch: 44 [29568/54000 (55%)] Loss: -840881.687500\n",
      "Train Epoch: 44 [30976/54000 (57%)] Loss: -777676.062500\n",
      "Train Epoch: 44 [32384/54000 (60%)] Loss: -795874.812500\n",
      "Train Epoch: 44 [33792/54000 (63%)] Loss: -777396.750000\n",
      "Train Epoch: 44 [35200/54000 (65%)] Loss: -796286.500000\n",
      "Train Epoch: 44 [36608/54000 (68%)] Loss: -795758.312500\n",
      "Train Epoch: 44 [38016/54000 (70%)] Loss: -807224.812500\n",
      "Train Epoch: 44 [39424/54000 (73%)] Loss: -885109.375000\n",
      "Train Epoch: 44 [40832/54000 (76%)] Loss: -770160.062500\n",
      "Train Epoch: 44 [42240/54000 (78%)] Loss: -743409.125000\n",
      "Train Epoch: 44 [43648/54000 (81%)] Loss: -836696.250000\n",
      "Train Epoch: 44 [45056/54000 (83%)] Loss: -786258.937500\n",
      "Train Epoch: 44 [46464/54000 (86%)] Loss: -833328.562500\n",
      "Train Epoch: 44 [47872/54000 (89%)] Loss: -837230.250000\n",
      "Train Epoch: 44 [49280/54000 (91%)] Loss: -827455.062500\n",
      "Train Epoch: 44 [50688/54000 (94%)] Loss: -833746.687500\n",
      "Train Epoch: 44 [52096/54000 (96%)] Loss: -789812.250000\n",
      "    epoch          : 44\n",
      "    loss           : -803661.411034689\n",
      "    val_loss       : -805231.1537728659\n",
      "Train Epoch: 45 [0/54000 (0%)] Loss: -758746.812500\n",
      "Train Epoch: 45 [1408/54000 (3%)] Loss: -772749.312500\n",
      "Train Epoch: 45 [2816/54000 (5%)] Loss: -806378.437500\n",
      "Train Epoch: 45 [4224/54000 (8%)] Loss: -866215.687500\n",
      "Train Epoch: 45 [5632/54000 (10%)] Loss: -805195.687500\n",
      "Train Epoch: 45 [7040/54000 (13%)] Loss: -820016.750000\n",
      "Train Epoch: 45 [8448/54000 (16%)] Loss: -804898.437500\n",
      "Train Epoch: 45 [9856/54000 (18%)] Loss: -788862.875000\n",
      "Train Epoch: 45 [11264/54000 (21%)] Loss: -797569.312500\n",
      "Train Epoch: 45 [12672/54000 (23%)] Loss: -795981.875000\n",
      "Train Epoch: 45 [14080/54000 (26%)] Loss: -782149.625000\n",
      "Train Epoch: 45 [15488/54000 (29%)] Loss: -792602.625000\n",
      "Train Epoch: 45 [16896/54000 (31%)] Loss: -810616.187500\n",
      "Train Epoch: 45 [18304/54000 (34%)] Loss: -825898.187500\n",
      "Train Epoch: 45 [19712/54000 (37%)] Loss: -775715.000000\n",
      "Train Epoch: 45 [21120/54000 (39%)] Loss: -781996.250000\n",
      "Train Epoch: 45 [22528/54000 (42%)] Loss: -755722.750000\n",
      "Train Epoch: 45 [23936/54000 (44%)] Loss: -816774.062500\n",
      "Train Epoch: 45 [25344/54000 (47%)] Loss: -787487.312500\n",
      "Train Epoch: 45 [26752/54000 (50%)] Loss: -877958.687500\n",
      "Train Epoch: 45 [28160/54000 (52%)] Loss: -786674.750000\n",
      "Train Epoch: 45 [29568/54000 (55%)] Loss: -886969.375000\n",
      "Train Epoch: 45 [30976/54000 (57%)] Loss: -819769.625000\n",
      "Train Epoch: 45 [32384/54000 (60%)] Loss: -781795.875000\n",
      "Train Epoch: 45 [33792/54000 (63%)] Loss: -759369.937500\n",
      "Train Epoch: 45 [35200/54000 (65%)] Loss: -801360.500000\n",
      "Train Epoch: 45 [36608/54000 (68%)] Loss: -816880.750000\n",
      "Train Epoch: 45 [38016/54000 (70%)] Loss: -885466.875000\n",
      "Train Epoch: 45 [39424/54000 (73%)] Loss: -762722.500000\n",
      "Train Epoch: 45 [40832/54000 (76%)] Loss: -871568.000000\n",
      "Train Epoch: 45 [42240/54000 (78%)] Loss: -880328.125000\n",
      "Train Epoch: 45 [43648/54000 (81%)] Loss: -812853.312500\n",
      "Train Epoch: 45 [45056/54000 (83%)] Loss: -816972.125000\n",
      "Train Epoch: 45 [46464/54000 (86%)] Loss: -796842.375000\n",
      "Train Epoch: 45 [47872/54000 (89%)] Loss: -788360.437500\n",
      "Train Epoch: 45 [49280/54000 (91%)] Loss: -839141.500000\n",
      "Train Epoch: 45 [50688/54000 (94%)] Loss: -751993.812500\n",
      "Train Epoch: 45 [52096/54000 (96%)] Loss: -769031.437500\n",
      "    epoch          : 45\n",
      "    loss           : -803424.6281399522\n",
      "    val_loss       : -804974.8738567074\n",
      "Saving checkpoint: saved/models/Mnist_VaeCategory/0422_221614/checkpoint-epoch45.pth ...\n",
      "Train Epoch: 46 [0/54000 (0%)] Loss: -768360.250000\n",
      "Train Epoch: 46 [1408/54000 (3%)] Loss: -821062.062500\n",
      "Train Epoch: 46 [2816/54000 (5%)] Loss: -769426.500000\n",
      "Train Epoch: 46 [4224/54000 (8%)] Loss: -768015.187500\n",
      "Train Epoch: 46 [5632/54000 (10%)] Loss: -805412.312500\n",
      "Train Epoch: 46 [7040/54000 (13%)] Loss: -876811.625000\n",
      "Train Epoch: 46 [8448/54000 (16%)] Loss: -819817.562500\n",
      "Train Epoch: 46 [9856/54000 (18%)] Loss: -876989.750000\n",
      "Train Epoch: 46 [11264/54000 (21%)] Loss: -833911.437500\n",
      "Train Epoch: 46 [12672/54000 (23%)] Loss: -886835.125000\n",
      "Train Epoch: 46 [14080/54000 (26%)] Loss: -824285.250000\n",
      "Train Epoch: 46 [15488/54000 (29%)] Loss: -789371.937500\n",
      "Train Epoch: 46 [16896/54000 (31%)] Loss: -799596.750000\n",
      "Train Epoch: 46 [18304/54000 (34%)] Loss: -789752.062500\n",
      "Train Epoch: 46 [19712/54000 (37%)] Loss: -780975.250000\n",
      "Train Epoch: 46 [21120/54000 (39%)] Loss: -772279.687500\n",
      "Train Epoch: 46 [22528/54000 (42%)] Loss: -793560.500000\n",
      "Train Epoch: 46 [23936/54000 (44%)] Loss: -837204.250000\n",
      "Train Epoch: 46 [25344/54000 (47%)] Loss: -829169.750000\n",
      "Train Epoch: 46 [26752/54000 (50%)] Loss: -808146.125000\n",
      "Train Epoch: 46 [28160/54000 (52%)] Loss: -756464.500000\n",
      "Train Epoch: 46 [29568/54000 (55%)] Loss: -875326.187500\n",
      "Train Epoch: 46 [30976/54000 (57%)] Loss: -842983.125000\n",
      "Train Epoch: 46 [32384/54000 (60%)] Loss: -830025.375000\n",
      "Train Epoch: 46 [33792/54000 (63%)] Loss: -788926.875000\n",
      "Train Epoch: 46 [35200/54000 (65%)] Loss: -795430.125000\n",
      "Train Epoch: 46 [36608/54000 (68%)] Loss: -786998.375000\n",
      "Train Epoch: 46 [38016/54000 (70%)] Loss: -825746.250000\n",
      "Train Epoch: 46 [39424/54000 (73%)] Loss: -767664.875000\n",
      "Train Epoch: 46 [40832/54000 (76%)] Loss: -893326.062500\n",
      "Train Epoch: 46 [42240/54000 (78%)] Loss: -822067.125000\n",
      "Train Epoch: 46 [43648/54000 (81%)] Loss: -796778.125000\n",
      "Train Epoch: 46 [45056/54000 (83%)] Loss: -801099.000000\n",
      "Train Epoch: 46 [46464/54000 (86%)] Loss: -788942.687500\n",
      "Train Epoch: 46 [47872/54000 (89%)] Loss: -789943.750000\n",
      "Train Epoch: 46 [49280/54000 (91%)] Loss: -829197.312500\n",
      "Train Epoch: 46 [50688/54000 (94%)] Loss: -755903.750000\n",
      "Train Epoch: 46 [52096/54000 (96%)] Loss: -807508.500000\n",
      "    epoch          : 46\n",
      "    loss           : -803694.3044258374\n",
      "    val_loss       : -805060.6413871951\n",
      "Train Epoch: 47 [0/54000 (0%)] Loss: -778852.937500\n",
      "Train Epoch: 47 [1408/54000 (3%)] Loss: -754910.125000\n",
      "Train Epoch: 47 [2816/54000 (5%)] Loss: -824752.562500\n",
      "Train Epoch: 47 [4224/54000 (8%)] Loss: -788771.437500\n",
      "Train Epoch: 47 [5632/54000 (10%)] Loss: -808105.375000\n",
      "Train Epoch: 47 [7040/54000 (13%)] Loss: -829819.187500\n",
      "Train Epoch: 47 [8448/54000 (16%)] Loss: -758341.750000\n",
      "Train Epoch: 47 [9856/54000 (18%)] Loss: -766003.375000\n",
      "Train Epoch: 47 [11264/54000 (21%)] Loss: -896129.125000\n",
      "Train Epoch: 47 [12672/54000 (23%)] Loss: -828177.000000\n",
      "Train Epoch: 47 [14080/54000 (26%)] Loss: -763967.250000\n",
      "Train Epoch: 47 [15488/54000 (29%)] Loss: -789553.375000\n",
      "Train Epoch: 47 [16896/54000 (31%)] Loss: -835348.625000\n",
      "Train Epoch: 47 [18304/54000 (34%)] Loss: -787749.187500\n",
      "Train Epoch: 47 [19712/54000 (37%)] Loss: -871436.312500\n",
      "Train Epoch: 47 [21120/54000 (39%)] Loss: -802018.125000\n",
      "Train Epoch: 47 [22528/54000 (42%)] Loss: -820208.812500\n",
      "Train Epoch: 47 [23936/54000 (44%)] Loss: -873021.000000\n",
      "Train Epoch: 47 [25344/54000 (47%)] Loss: -790994.937500\n",
      "Train Epoch: 47 [26752/54000 (50%)] Loss: -795162.187500\n",
      "Train Epoch: 47 [28160/54000 (52%)] Loss: -804900.875000\n",
      "Train Epoch: 47 [29568/54000 (55%)] Loss: -755094.875000\n",
      "Train Epoch: 47 [30976/54000 (57%)] Loss: -760125.000000\n",
      "Train Epoch: 47 [32384/54000 (60%)] Loss: -811146.375000\n",
      "Train Epoch: 47 [33792/54000 (63%)] Loss: -889662.750000\n",
      "Train Epoch: 47 [35200/54000 (65%)] Loss: -789310.937500\n",
      "Train Epoch: 47 [36608/54000 (68%)] Loss: -887601.937500\n",
      "Train Epoch: 47 [38016/54000 (70%)] Loss: -874375.625000\n",
      "Train Epoch: 47 [39424/54000 (73%)] Loss: -761742.750000\n",
      "Train Epoch: 47 [40832/54000 (76%)] Loss: -778785.500000\n",
      "Train Epoch: 47 [42240/54000 (78%)] Loss: -789944.000000\n",
      "Train Epoch: 47 [43648/54000 (81%)] Loss: -886328.625000\n",
      "Train Epoch: 47 [45056/54000 (83%)] Loss: -881159.937500\n",
      "Train Epoch: 47 [46464/54000 (86%)] Loss: -821785.875000\n",
      "Train Epoch: 47 [47872/54000 (89%)] Loss: -810383.125000\n",
      "Train Epoch: 47 [49280/54000 (91%)] Loss: -834391.562500\n",
      "Train Epoch: 47 [50688/54000 (94%)] Loss: -772215.250000\n",
      "Train Epoch: 47 [52096/54000 (96%)] Loss: -765206.000000\n",
      "    epoch          : 47\n",
      "    loss           : -803752.6294856459\n",
      "    val_loss       : -804524.9773246951\n",
      "Train Epoch: 48 [0/54000 (0%)] Loss: -792688.437500\n",
      "Train Epoch: 48 [1408/54000 (3%)] Loss: -883951.500000\n",
      "Train Epoch: 48 [2816/54000 (5%)] Loss: -753873.062500\n",
      "Train Epoch: 48 [4224/54000 (8%)] Loss: -837309.500000\n",
      "Train Epoch: 48 [5632/54000 (10%)] Loss: -795844.250000\n",
      "Train Epoch: 48 [7040/54000 (13%)] Loss: -805832.000000\n",
      "Train Epoch: 48 [8448/54000 (16%)] Loss: -793633.250000\n",
      "Train Epoch: 48 [9856/54000 (18%)] Loss: -792859.000000\n",
      "Train Epoch: 48 [11264/54000 (21%)] Loss: -787496.062500\n",
      "Train Epoch: 48 [12672/54000 (23%)] Loss: -752107.687500\n",
      "Train Epoch: 48 [14080/54000 (26%)] Loss: -767698.562500\n",
      "Train Epoch: 48 [15488/54000 (29%)] Loss: -809851.875000\n",
      "Train Epoch: 48 [16896/54000 (31%)] Loss: -812947.687500\n",
      "Train Epoch: 48 [18304/54000 (34%)] Loss: -805215.812500\n",
      "Train Epoch: 48 [19712/54000 (37%)] Loss: -814720.187500\n",
      "Train Epoch: 48 [21120/54000 (39%)] Loss: -780077.562500\n",
      "Train Epoch: 48 [22528/54000 (42%)] Loss: -777915.125000\n",
      "Train Epoch: 48 [23936/54000 (44%)] Loss: -759739.750000\n",
      "Train Epoch: 48 [25344/54000 (47%)] Loss: -811499.750000\n",
      "Train Epoch: 48 [26752/54000 (50%)] Loss: -883033.625000\n",
      "Train Epoch: 48 [28160/54000 (52%)] Loss: -826599.125000\n",
      "Train Epoch: 48 [29568/54000 (55%)] Loss: -790065.250000\n",
      "Train Epoch: 48 [30976/54000 (57%)] Loss: -798738.750000\n",
      "Train Epoch: 48 [32384/54000 (60%)] Loss: -776919.500000\n",
      "Train Epoch: 48 [33792/54000 (63%)] Loss: -805747.812500\n",
      "Train Epoch: 48 [35200/54000 (65%)] Loss: -774392.750000\n",
      "Train Epoch: 48 [36608/54000 (68%)] Loss: -792888.437500\n",
      "Train Epoch: 48 [38016/54000 (70%)] Loss: -786655.500000\n",
      "Train Epoch: 48 [39424/54000 (73%)] Loss: -814474.375000\n",
      "Train Epoch: 48 [40832/54000 (76%)] Loss: -822557.812500\n",
      "Train Epoch: 48 [42240/54000 (78%)] Loss: -792002.437500\n",
      "Train Epoch: 48 [43648/54000 (81%)] Loss: -881470.750000\n",
      "Train Epoch: 48 [45056/54000 (83%)] Loss: -885912.625000\n",
      "Train Epoch: 48 [46464/54000 (86%)] Loss: -800165.750000\n",
      "Train Epoch: 48 [47872/54000 (89%)] Loss: -836932.125000\n",
      "Train Epoch: 48 [49280/54000 (91%)] Loss: -860698.000000\n",
      "Train Epoch: 48 [50688/54000 (94%)] Loss: -833741.750000\n",
      "Train Epoch: 48 [52096/54000 (96%)] Loss: -770640.375000\n",
      "    epoch          : 48\n",
      "    loss           : -804304.0868720096\n",
      "    val_loss       : -805767.887957317\n",
      "Train Epoch: 49 [0/54000 (0%)] Loss: -819290.250000\n",
      "Train Epoch: 49 [1408/54000 (3%)] Loss: -781305.562500\n",
      "Train Epoch: 49 [2816/54000 (5%)] Loss: -839755.125000\n",
      "Train Epoch: 49 [4224/54000 (8%)] Loss: -807762.812500\n",
      "Train Epoch: 49 [5632/54000 (10%)] Loss: -892064.750000\n",
      "Train Epoch: 49 [7040/54000 (13%)] Loss: -813461.250000\n",
      "Train Epoch: 49 [8448/54000 (16%)] Loss: -790347.625000\n",
      "Train Epoch: 49 [9856/54000 (18%)] Loss: -778588.125000\n",
      "Train Epoch: 49 [11264/54000 (21%)] Loss: -821741.000000\n",
      "Train Epoch: 49 [12672/54000 (23%)] Loss: -801801.125000\n",
      "Train Epoch: 49 [14080/54000 (26%)] Loss: -824122.312500\n",
      "Train Epoch: 49 [15488/54000 (29%)] Loss: -770346.625000\n",
      "Train Epoch: 49 [16896/54000 (31%)] Loss: -762163.812500\n",
      "Train Epoch: 49 [18304/54000 (34%)] Loss: -878068.937500\n",
      "Train Epoch: 49 [19712/54000 (37%)] Loss: -794305.875000\n",
      "Train Epoch: 49 [21120/54000 (39%)] Loss: -807323.500000\n",
      "Train Epoch: 49 [22528/54000 (42%)] Loss: -842326.750000\n",
      "Train Epoch: 49 [23936/54000 (44%)] Loss: -785620.750000\n",
      "Train Epoch: 49 [25344/54000 (47%)] Loss: -807149.875000\n",
      "Train Epoch: 49 [26752/54000 (50%)] Loss: -770470.000000\n",
      "Train Epoch: 49 [28160/54000 (52%)] Loss: -811523.125000\n",
      "Train Epoch: 49 [29568/54000 (55%)] Loss: -811824.812500\n",
      "Train Epoch: 49 [30976/54000 (57%)] Loss: -789304.000000\n",
      "Train Epoch: 49 [32384/54000 (60%)] Loss: -765256.812500\n",
      "Train Epoch: 49 [33792/54000 (63%)] Loss: -820751.812500\n",
      "Train Epoch: 49 [35200/54000 (65%)] Loss: -810489.875000\n",
      "Train Epoch: 49 [36608/54000 (68%)] Loss: -828718.250000\n",
      "Train Epoch: 49 [38016/54000 (70%)] Loss: -781345.875000\n",
      "Train Epoch: 49 [39424/54000 (73%)] Loss: -821417.437500\n",
      "Train Epoch: 49 [40832/54000 (76%)] Loss: -827764.875000\n",
      "Train Epoch: 49 [42240/54000 (78%)] Loss: -846275.875000\n",
      "Train Epoch: 49 [43648/54000 (81%)] Loss: -755410.125000\n",
      "Train Epoch: 49 [45056/54000 (83%)] Loss: -799102.125000\n",
      "Train Epoch: 49 [46464/54000 (86%)] Loss: -787144.000000\n",
      "Train Epoch: 49 [47872/54000 (89%)] Loss: -837557.500000\n",
      "Train Epoch: 49 [49280/54000 (91%)] Loss: -804286.750000\n",
      "Train Epoch: 49 [50688/54000 (94%)] Loss: -750774.062500\n",
      "Train Epoch: 49 [52096/54000 (96%)] Loss: -767147.000000\n",
      "    epoch          : 49\n",
      "    loss           : -804522.3584031101\n",
      "    val_loss       : -805727.7776295731\n",
      "Train Epoch: 50 [0/54000 (0%)] Loss: -796183.125000\n",
      "Train Epoch: 50 [1408/54000 (3%)] Loss: -766934.562500\n",
      "Train Epoch: 50 [2816/54000 (5%)] Loss: -810963.437500\n",
      "Train Epoch: 50 [4224/54000 (8%)] Loss: -804327.125000\n",
      "Train Epoch: 50 [5632/54000 (10%)] Loss: -812125.687500\n",
      "Train Epoch: 50 [7040/54000 (13%)] Loss: -798014.250000\n",
      "Train Epoch: 50 [8448/54000 (16%)] Loss: -795762.187500\n",
      "Train Epoch: 50 [9856/54000 (18%)] Loss: -792343.250000\n",
      "Train Epoch: 50 [11264/54000 (21%)] Loss: -812936.625000\n",
      "Train Epoch: 50 [12672/54000 (23%)] Loss: -793478.250000\n",
      "Train Epoch: 50 [14080/54000 (26%)] Loss: -792680.937500\n",
      "Train Epoch: 50 [15488/54000 (29%)] Loss: -767602.500000\n",
      "Train Epoch: 50 [16896/54000 (31%)] Loss: -784069.875000\n",
      "Train Epoch: 50 [18304/54000 (34%)] Loss: -758171.687500\n",
      "Train Epoch: 50 [19712/54000 (37%)] Loss: -827865.250000\n",
      "Train Epoch: 50 [21120/54000 (39%)] Loss: -838091.937500\n",
      "Train Epoch: 50 [22528/54000 (42%)] Loss: -775635.750000\n",
      "Train Epoch: 50 [23936/54000 (44%)] Loss: -761304.062500\n",
      "Train Epoch: 50 [25344/54000 (47%)] Loss: -788084.625000\n",
      "Train Epoch: 50 [26752/54000 (50%)] Loss: -810864.062500\n",
      "Train Epoch: 50 [28160/54000 (52%)] Loss: -762354.562500\n",
      "Train Epoch: 50 [29568/54000 (55%)] Loss: -761070.375000\n",
      "Train Epoch: 50 [30976/54000 (57%)] Loss: -796232.562500\n",
      "Train Epoch: 50 [32384/54000 (60%)] Loss: -836971.875000\n",
      "Train Epoch: 50 [33792/54000 (63%)] Loss: -818376.437500\n",
      "Train Epoch: 50 [35200/54000 (65%)] Loss: -789693.000000\n",
      "Train Epoch: 50 [36608/54000 (68%)] Loss: -766639.375000\n",
      "Train Epoch: 50 [38016/54000 (70%)] Loss: -794189.687500\n",
      "Train Epoch: 50 [39424/54000 (73%)] Loss: -801168.875000\n",
      "Train Epoch: 50 [40832/54000 (76%)] Loss: -781193.625000\n",
      "Train Epoch: 50 [42240/54000 (78%)] Loss: -806755.562500\n",
      "Train Epoch: 50 [43648/54000 (81%)] Loss: -785348.437500\n",
      "Train Epoch: 50 [45056/54000 (83%)] Loss: -759822.375000\n",
      "Train Epoch: 50 [46464/54000 (86%)] Loss: -796121.437500\n",
      "Train Epoch: 50 [47872/54000 (89%)] Loss: -836381.437500\n",
      "Train Epoch: 50 [49280/54000 (91%)] Loss: -847116.375000\n",
      "Train Epoch: 50 [50688/54000 (94%)] Loss: -754625.062500\n",
      "Train Epoch: 50 [52096/54000 (96%)] Loss: -826293.937500\n",
      "    epoch          : 50\n",
      "    loss           : -804510.8267045454\n",
      "    val_loss       : -806278.6312881098\n",
      "Saving checkpoint: saved/models/Mnist_VaeCategory/0422_221614/checkpoint-epoch50.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 51 [0/54000 (0%)] Loss: -836167.875000\n",
      "Train Epoch: 51 [1408/54000 (3%)] Loss: -794095.625000\n",
      "Train Epoch: 51 [2816/54000 (5%)] Loss: -825820.062500\n",
      "Train Epoch: 51 [4224/54000 (8%)] Loss: -815617.500000\n",
      "Train Epoch: 51 [5632/54000 (10%)] Loss: -765506.000000\n",
      "Train Epoch: 51 [7040/54000 (13%)] Loss: -792979.312500\n",
      "Train Epoch: 51 [8448/54000 (16%)] Loss: -877207.562500\n",
      "Train Epoch: 51 [9856/54000 (18%)] Loss: -843360.062500\n",
      "Train Epoch: 51 [11264/54000 (21%)] Loss: -831868.125000\n",
      "Train Epoch: 51 [12672/54000 (23%)] Loss: -894652.937500\n",
      "Train Epoch: 51 [14080/54000 (26%)] Loss: -865200.375000\n",
      "Train Epoch: 51 [15488/54000 (29%)] Loss: -768481.750000\n",
      "Train Epoch: 51 [16896/54000 (31%)] Loss: -794092.437500\n",
      "Train Epoch: 51 [18304/54000 (34%)] Loss: -793319.062500\n",
      "Train Epoch: 51 [19712/54000 (37%)] Loss: -797782.500000\n",
      "Train Epoch: 51 [21120/54000 (39%)] Loss: -873590.687500\n",
      "Train Epoch: 51 [22528/54000 (42%)] Loss: -805916.750000\n",
      "Train Epoch: 51 [23936/54000 (44%)] Loss: -772234.625000\n",
      "Train Epoch: 51 [25344/54000 (47%)] Loss: -808999.562500\n",
      "Train Epoch: 51 [26752/54000 (50%)] Loss: -823573.375000\n",
      "Train Epoch: 51 [28160/54000 (52%)] Loss: -791023.187500\n",
      "Train Epoch: 51 [29568/54000 (55%)] Loss: -797435.125000\n",
      "Train Epoch: 51 [30976/54000 (57%)] Loss: -790374.125000\n",
      "Train Epoch: 51 [32384/54000 (60%)] Loss: -842231.937500\n",
      "Train Epoch: 51 [33792/54000 (63%)] Loss: -763701.437500\n",
      "Train Epoch: 51 [35200/54000 (65%)] Loss: -813411.000000\n",
      "Train Epoch: 51 [36608/54000 (68%)] Loss: -790740.937500\n",
      "Train Epoch: 51 [38016/54000 (70%)] Loss: -802805.250000\n",
      "Train Epoch: 51 [39424/54000 (73%)] Loss: -823471.750000\n",
      "Train Epoch: 51 [40832/54000 (76%)] Loss: -773983.125000\n",
      "Train Epoch: 51 [42240/54000 (78%)] Loss: -819770.812500\n",
      "Train Epoch: 51 [43648/54000 (81%)] Loss: -881337.375000\n",
      "Train Epoch: 51 [45056/54000 (83%)] Loss: -790253.500000\n",
      "Train Epoch: 51 [46464/54000 (86%)] Loss: -787262.437500\n",
      "Train Epoch: 51 [47872/54000 (89%)] Loss: -791619.062500\n",
      "Train Epoch: 51 [49280/54000 (91%)] Loss: -811789.437500\n",
      "Train Epoch: 51 [50688/54000 (94%)] Loss: -754642.437500\n",
      "Train Epoch: 51 [52096/54000 (96%)] Loss: -772403.500000\n",
      "    epoch          : 51\n",
      "    loss           : -805047.2072368421\n",
      "    val_loss       : -805812.3111661585\n",
      "Train Epoch: 52 [0/54000 (0%)] Loss: -811779.437500\n",
      "Train Epoch: 52 [1408/54000 (3%)] Loss: -772097.750000\n",
      "Train Epoch: 52 [2816/54000 (5%)] Loss: -780429.125000\n",
      "Train Epoch: 52 [4224/54000 (8%)] Loss: -790042.875000\n",
      "Train Epoch: 52 [5632/54000 (10%)] Loss: -848002.125000\n",
      "Train Epoch: 52 [7040/54000 (13%)] Loss: -792542.375000\n",
      "Train Epoch: 52 [8448/54000 (16%)] Loss: -788686.375000\n",
      "Train Epoch: 52 [9856/54000 (18%)] Loss: -809954.000000\n",
      "Train Epoch: 52 [11264/54000 (21%)] Loss: -768827.750000\n",
      "Train Epoch: 52 [12672/54000 (23%)] Loss: -886954.062500\n",
      "Train Epoch: 52 [14080/54000 (26%)] Loss: -786688.125000\n",
      "Train Epoch: 52 [15488/54000 (29%)] Loss: -790179.937500\n",
      "Train Epoch: 52 [16896/54000 (31%)] Loss: -778458.875000\n",
      "Train Epoch: 52 [18304/54000 (34%)] Loss: -768014.625000\n",
      "Train Epoch: 52 [19712/54000 (37%)] Loss: -763676.187500\n",
      "Train Epoch: 52 [21120/54000 (39%)] Loss: -793981.375000\n",
      "Train Epoch: 52 [22528/54000 (42%)] Loss: -778051.125000\n",
      "Train Epoch: 52 [23936/54000 (44%)] Loss: -785362.937500\n",
      "Train Epoch: 52 [25344/54000 (47%)] Loss: -814742.562500\n",
      "Train Epoch: 52 [26752/54000 (50%)] Loss: -758747.687500\n",
      "Train Epoch: 52 [28160/54000 (52%)] Loss: -821920.937500\n",
      "Train Epoch: 52 [29568/54000 (55%)] Loss: -758715.500000\n",
      "Train Epoch: 52 [30976/54000 (57%)] Loss: -779040.250000\n",
      "Train Epoch: 52 [32384/54000 (60%)] Loss: -758268.750000\n",
      "Train Epoch: 52 [33792/54000 (63%)] Loss: -886137.187500\n",
      "Train Epoch: 52 [35200/54000 (65%)] Loss: -789082.375000\n",
      "Train Epoch: 52 [36608/54000 (68%)] Loss: -826868.250000\n",
      "Train Epoch: 52 [38016/54000 (70%)] Loss: -811631.750000\n",
      "Train Epoch: 52 [39424/54000 (73%)] Loss: -808295.437500\n",
      "Train Epoch: 52 [40832/54000 (76%)] Loss: -881019.500000\n",
      "Train Epoch: 52 [42240/54000 (78%)] Loss: -792884.062500\n",
      "Train Epoch: 52 [43648/54000 (81%)] Loss: -792810.375000\n",
      "Train Epoch: 52 [45056/54000 (83%)] Loss: -807273.500000\n",
      "Train Epoch: 52 [46464/54000 (86%)] Loss: -824541.187500\n",
      "Train Epoch: 52 [47872/54000 (89%)] Loss: -825947.250000\n",
      "Train Epoch: 52 [49280/54000 (91%)] Loss: -825422.125000\n",
      "Train Epoch: 52 [50688/54000 (94%)] Loss: -840847.437500\n",
      "Train Epoch: 52 [52096/54000 (96%)] Loss: -826597.562500\n",
      "    epoch          : 52\n",
      "    loss           : -804962.4863935406\n",
      "    val_loss       : -806720.5994664634\n",
      "Train Epoch: 53 [0/54000 (0%)] Loss: -761329.562500\n",
      "Train Epoch: 53 [1408/54000 (3%)] Loss: -831070.000000\n",
      "Train Epoch: 53 [2816/54000 (5%)] Loss: -831978.125000\n",
      "Train Epoch: 53 [4224/54000 (8%)] Loss: -820843.625000\n",
      "Train Epoch: 53 [5632/54000 (10%)] Loss: -898281.187500\n",
      "Train Epoch: 53 [7040/54000 (13%)] Loss: -794263.375000\n",
      "Train Epoch: 53 [8448/54000 (16%)] Loss: -825562.312500\n",
      "Train Epoch: 53 [9856/54000 (18%)] Loss: -825353.625000\n",
      "Train Epoch: 53 [11264/54000 (21%)] Loss: -844465.125000\n",
      "Train Epoch: 53 [12672/54000 (23%)] Loss: -839124.000000\n",
      "Train Epoch: 53 [14080/54000 (26%)] Loss: -820458.000000\n",
      "Train Epoch: 53 [15488/54000 (29%)] Loss: -766582.812500\n",
      "Train Epoch: 53 [16896/54000 (31%)] Loss: -747781.250000\n",
      "Train Epoch: 53 [18304/54000 (34%)] Loss: -877378.125000\n",
      "Train Epoch: 53 [19712/54000 (37%)] Loss: -754321.375000\n",
      "Train Epoch: 53 [21120/54000 (39%)] Loss: -824044.875000\n",
      "Train Epoch: 53 [22528/54000 (42%)] Loss: -780215.187500\n",
      "Train Epoch: 53 [23936/54000 (44%)] Loss: -826720.125000\n",
      "Train Epoch: 53 [25344/54000 (47%)] Loss: -795106.437500\n",
      "Train Epoch: 53 [26752/54000 (50%)] Loss: -800841.500000\n",
      "Train Epoch: 53 [28160/54000 (52%)] Loss: -842238.750000\n",
      "Train Epoch: 53 [29568/54000 (55%)] Loss: -814005.625000\n",
      "Train Epoch: 53 [30976/54000 (57%)] Loss: -755418.750000\n",
      "Train Epoch: 53 [32384/54000 (60%)] Loss: -795349.625000\n",
      "Train Epoch: 53 [33792/54000 (63%)] Loss: -778980.375000\n",
      "Train Epoch: 53 [35200/54000 (65%)] Loss: -802790.812500\n",
      "Train Epoch: 53 [36608/54000 (68%)] Loss: -814850.500000\n",
      "Train Epoch: 53 [38016/54000 (70%)] Loss: -801373.312500\n",
      "Train Epoch: 53 [39424/54000 (73%)] Loss: -869191.937500\n",
      "Train Epoch: 53 [40832/54000 (76%)] Loss: -885277.875000\n",
      "Train Epoch: 53 [42240/54000 (78%)] Loss: -873348.500000\n",
      "Train Epoch: 53 [43648/54000 (81%)] Loss: -758124.000000\n",
      "Train Epoch: 53 [45056/54000 (83%)] Loss: -791070.375000\n",
      "Train Epoch: 53 [46464/54000 (86%)] Loss: -826664.000000\n",
      "Train Epoch: 53 [47872/54000 (89%)] Loss: -819268.812500\n",
      "Train Epoch: 53 [49280/54000 (91%)] Loss: -760195.000000\n",
      "Train Epoch: 53 [50688/54000 (94%)] Loss: -759227.687500\n",
      "Train Epoch: 53 [52096/54000 (96%)] Loss: -794033.062500\n",
      "    epoch          : 53\n",
      "    loss           : -805159.5639952153\n",
      "    val_loss       : -805308.8490853659\n",
      "Train Epoch: 54 [0/54000 (0%)] Loss: -886182.875000\n",
      "Train Epoch: 54 [1408/54000 (3%)] Loss: -883785.187500\n",
      "Train Epoch: 54 [2816/54000 (5%)] Loss: -810785.437500\n",
      "Train Epoch: 54 [4224/54000 (8%)] Loss: -801021.125000\n",
      "Train Epoch: 54 [5632/54000 (10%)] Loss: -865258.125000\n",
      "Train Epoch: 54 [7040/54000 (13%)] Loss: -800854.062500\n",
      "Train Epoch: 54 [8448/54000 (16%)] Loss: -825366.125000\n",
      "Train Epoch: 54 [9856/54000 (18%)] Loss: -786201.000000\n",
      "Train Epoch: 54 [11264/54000 (21%)] Loss: -844567.062500\n",
      "Train Epoch: 54 [12672/54000 (23%)] Loss: -842630.125000\n",
      "Train Epoch: 54 [14080/54000 (26%)] Loss: -759858.875000\n",
      "Train Epoch: 54 [15488/54000 (29%)] Loss: -772888.812500\n",
      "Train Epoch: 54 [16896/54000 (31%)] Loss: -823116.750000\n",
      "Train Epoch: 54 [18304/54000 (34%)] Loss: -811762.312500\n",
      "Train Epoch: 54 [19712/54000 (37%)] Loss: -810633.062500\n",
      "Train Epoch: 54 [21120/54000 (39%)] Loss: -790057.187500\n",
      "Train Epoch: 54 [22528/54000 (42%)] Loss: -777239.562500\n",
      "Train Epoch: 54 [23936/54000 (44%)] Loss: -797236.625000\n",
      "Train Epoch: 54 [25344/54000 (47%)] Loss: -828104.000000\n",
      "Train Epoch: 54 [26752/54000 (50%)] Loss: -798679.187500\n",
      "Train Epoch: 54 [28160/54000 (52%)] Loss: -765318.625000\n",
      "Train Epoch: 54 [29568/54000 (55%)] Loss: -796208.187500\n",
      "Train Epoch: 54 [30976/54000 (57%)] Loss: -780871.000000\n",
      "Train Epoch: 54 [32384/54000 (60%)] Loss: -806050.250000\n",
      "Train Epoch: 54 [33792/54000 (63%)] Loss: -818051.500000\n",
      "Train Epoch: 54 [35200/54000 (65%)] Loss: -886076.125000\n",
      "Train Epoch: 54 [36608/54000 (68%)] Loss: -828970.375000\n",
      "Train Epoch: 54 [38016/54000 (70%)] Loss: -793076.312500\n",
      "Train Epoch: 54 [39424/54000 (73%)] Loss: -823571.500000\n",
      "Train Epoch: 54 [40832/54000 (76%)] Loss: -796989.250000\n",
      "Train Epoch: 54 [42240/54000 (78%)] Loss: -767095.437500\n",
      "Train Epoch: 54 [43648/54000 (81%)] Loss: -762203.875000\n",
      "Train Epoch: 54 [45056/54000 (83%)] Loss: -797801.625000\n",
      "Train Epoch: 54 [46464/54000 (86%)] Loss: -836741.937500\n",
      "Train Epoch: 54 [47872/54000 (89%)] Loss: -834004.625000\n",
      "Train Epoch: 54 [49280/54000 (91%)] Loss: -789850.875000\n",
      "Train Epoch: 54 [50688/54000 (94%)] Loss: -838620.000000\n",
      "Train Epoch: 54 [52096/54000 (96%)] Loss: -776445.000000\n",
      "    epoch          : 54\n",
      "    loss           : -805435.9232954546\n",
      "    val_loss       : -806540.448742378\n",
      "Train Epoch: 55 [0/54000 (0%)] Loss: -759538.062500\n",
      "Train Epoch: 55 [1408/54000 (3%)] Loss: -761955.125000\n",
      "Train Epoch: 55 [2816/54000 (5%)] Loss: -828369.250000\n",
      "Train Epoch: 55 [4224/54000 (8%)] Loss: -802322.500000\n",
      "Train Epoch: 55 [5632/54000 (10%)] Loss: -785727.000000\n",
      "Train Epoch: 55 [7040/54000 (13%)] Loss: -879095.750000\n",
      "Train Epoch: 55 [8448/54000 (16%)] Loss: -791024.875000\n",
      "Train Epoch: 55 [9856/54000 (18%)] Loss: -886507.750000\n",
      "Train Epoch: 55 [11264/54000 (21%)] Loss: -800744.625000\n",
      "Train Epoch: 55 [12672/54000 (23%)] Loss: -836376.375000\n",
      "Train Epoch: 55 [14080/54000 (26%)] Loss: -838770.125000\n",
      "Train Epoch: 55 [15488/54000 (29%)] Loss: -805292.187500\n",
      "Train Epoch: 55 [16896/54000 (31%)] Loss: -768869.937500\n",
      "Train Epoch: 55 [18304/54000 (34%)] Loss: -772082.000000\n",
      "Train Epoch: 55 [19712/54000 (37%)] Loss: -827996.250000\n",
      "Train Epoch: 55 [21120/54000 (39%)] Loss: -880786.375000\n",
      "Train Epoch: 55 [22528/54000 (42%)] Loss: -886272.375000\n",
      "Train Epoch: 55 [23936/54000 (44%)] Loss: -774791.125000\n",
      "Train Epoch: 55 [25344/54000 (47%)] Loss: -765577.125000\n",
      "Train Epoch: 55 [26752/54000 (50%)] Loss: -847507.500000\n",
      "Train Epoch: 55 [28160/54000 (52%)] Loss: -775281.312500\n",
      "Train Epoch: 55 [29568/54000 (55%)] Loss: -801393.062500\n",
      "Train Epoch: 55 [30976/54000 (57%)] Loss: -832562.375000\n",
      "Train Epoch: 55 [32384/54000 (60%)] Loss: -792114.437500\n",
      "Train Epoch: 55 [33792/54000 (63%)] Loss: -830871.625000\n",
      "Train Epoch: 55 [35200/54000 (65%)] Loss: -763562.437500\n",
      "Train Epoch: 55 [36608/54000 (68%)] Loss: -763799.500000\n",
      "Train Epoch: 55 [38016/54000 (70%)] Loss: -818529.875000\n",
      "Train Epoch: 55 [39424/54000 (73%)] Loss: -774379.625000\n",
      "Train Epoch: 55 [40832/54000 (76%)] Loss: -838892.000000\n",
      "Train Epoch: 55 [42240/54000 (78%)] Loss: -831094.375000\n",
      "Train Epoch: 55 [43648/54000 (81%)] Loss: -806122.250000\n",
      "Train Epoch: 55 [45056/54000 (83%)] Loss: -884656.812500\n",
      "Train Epoch: 55 [46464/54000 (86%)] Loss: -808142.875000\n",
      "Train Epoch: 55 [47872/54000 (89%)] Loss: -788488.937500\n",
      "Train Epoch: 55 [49280/54000 (91%)] Loss: -791248.562500\n",
      "Train Epoch: 55 [50688/54000 (94%)] Loss: -813590.875000\n",
      "Train Epoch: 55 [52096/54000 (96%)] Loss: -766844.000000\n",
      "    epoch          : 55\n",
      "    loss           : -805554.8119019138\n",
      "    val_loss       : -807361.8666158536\n",
      "Saving checkpoint: saved/models/Mnist_VaeCategory/0422_221614/checkpoint-epoch55.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 56 [0/54000 (0%)] Loss: -756940.500000\n",
      "Train Epoch: 56 [1408/54000 (3%)] Loss: -827779.437500\n",
      "Train Epoch: 56 [2816/54000 (5%)] Loss: -783896.875000\n",
      "Train Epoch: 56 [4224/54000 (8%)] Loss: -811474.250000\n",
      "Train Epoch: 56 [5632/54000 (10%)] Loss: -793517.812500\n",
      "Train Epoch: 56 [7040/54000 (13%)] Loss: -797331.500000\n",
      "Train Epoch: 56 [8448/54000 (16%)] Loss: -877117.437500\n",
      "Train Epoch: 56 [9856/54000 (18%)] Loss: -889330.750000\n",
      "Train Epoch: 56 [11264/54000 (21%)] Loss: -821928.187500\n",
      "Train Epoch: 56 [12672/54000 (23%)] Loss: -766876.812500\n",
      "Train Epoch: 56 [14080/54000 (26%)] Loss: -821400.687500\n",
      "Train Epoch: 56 [15488/54000 (29%)] Loss: -802384.625000\n",
      "Train Epoch: 56 [16896/54000 (31%)] Loss: -753873.687500\n",
      "Train Epoch: 56 [18304/54000 (34%)] Loss: -787314.187500\n",
      "Train Epoch: 56 [19712/54000 (37%)] Loss: -782502.750000\n",
      "Train Epoch: 56 [21120/54000 (39%)] Loss: -820548.875000\n",
      "Train Epoch: 56 [22528/54000 (42%)] Loss: -809562.750000\n",
      "Train Epoch: 56 [23936/54000 (44%)] Loss: -824453.375000\n",
      "Train Epoch: 56 [25344/54000 (47%)] Loss: -816743.062500\n",
      "Train Epoch: 56 [26752/54000 (50%)] Loss: -818597.750000\n",
      "Train Epoch: 56 [28160/54000 (52%)] Loss: -758080.500000\n",
      "Train Epoch: 56 [29568/54000 (55%)] Loss: -795277.500000\n",
      "Train Epoch: 56 [30976/54000 (57%)] Loss: -799119.250000\n",
      "Train Epoch: 56 [32384/54000 (60%)] Loss: -808998.312500\n",
      "Train Epoch: 56 [33792/54000 (63%)] Loss: -777248.375000\n",
      "Train Epoch: 56 [35200/54000 (65%)] Loss: -762793.437500\n",
      "Train Epoch: 56 [36608/54000 (68%)] Loss: -817791.312500\n",
      "Train Epoch: 56 [38016/54000 (70%)] Loss: -820340.937500\n",
      "Train Epoch: 56 [39424/54000 (73%)] Loss: -815407.875000\n",
      "Train Epoch: 56 [40832/54000 (76%)] Loss: -768505.750000\n",
      "Train Epoch: 56 [42240/54000 (78%)] Loss: -755246.625000\n",
      "Train Epoch: 56 [43648/54000 (81%)] Loss: -793830.375000\n",
      "Train Epoch: 56 [45056/54000 (83%)] Loss: -784334.875000\n",
      "Train Epoch: 56 [46464/54000 (86%)] Loss: -761531.812500\n",
      "Train Epoch: 56 [47872/54000 (89%)] Loss: -830531.375000\n",
      "Train Epoch: 56 [49280/54000 (91%)] Loss: -773605.312500\n",
      "Train Epoch: 56 [50688/54000 (94%)] Loss: -759379.750000\n",
      "Train Epoch: 56 [52096/54000 (96%)] Loss: -780109.562500\n",
      "    epoch          : 56\n",
      "    loss           : -805855.141895933\n",
      "    val_loss       : -806535.1274771341\n",
      "Train Epoch: 57 [0/54000 (0%)] Loss: -765095.875000\n",
      "Train Epoch: 57 [1408/54000 (3%)] Loss: -759250.187500\n",
      "Train Epoch: 57 [2816/54000 (5%)] Loss: -819716.125000\n",
      "Train Epoch: 57 [4224/54000 (8%)] Loss: -787634.562500\n",
      "Train Epoch: 57 [5632/54000 (10%)] Loss: -818214.187500\n",
      "Train Epoch: 57 [7040/54000 (13%)] Loss: -819280.187500\n",
      "Train Epoch: 57 [8448/54000 (16%)] Loss: -787492.687500\n",
      "Train Epoch: 57 [9856/54000 (18%)] Loss: -778112.125000\n",
      "Train Epoch: 57 [11264/54000 (21%)] Loss: -842302.562500\n",
      "Train Epoch: 57 [12672/54000 (23%)] Loss: -834494.937500\n",
      "Train Epoch: 57 [14080/54000 (26%)] Loss: -853147.812500\n",
      "Train Epoch: 57 [15488/54000 (29%)] Loss: -823751.250000\n",
      "Train Epoch: 57 [16896/54000 (31%)] Loss: -818794.937500\n",
      "Train Epoch: 57 [18304/54000 (34%)] Loss: -786331.750000\n",
      "Train Epoch: 57 [19712/54000 (37%)] Loss: -793157.312500\n",
      "Train Epoch: 57 [21120/54000 (39%)] Loss: -888195.812500\n",
      "Train Epoch: 57 [22528/54000 (42%)] Loss: -884437.625000\n",
      "Train Epoch: 57 [23936/54000 (44%)] Loss: -783441.312500\n",
      "Train Epoch: 57 [25344/54000 (47%)] Loss: -760640.125000\n",
      "Train Epoch: 57 [26752/54000 (50%)] Loss: -787168.375000\n",
      "Train Epoch: 57 [28160/54000 (52%)] Loss: -783321.875000\n",
      "Train Epoch: 57 [29568/54000 (55%)] Loss: -759514.000000\n",
      "Train Epoch: 57 [30976/54000 (57%)] Loss: -781572.562500\n",
      "Train Epoch: 57 [32384/54000 (60%)] Loss: -789787.187500\n",
      "Train Epoch: 57 [33792/54000 (63%)] Loss: -851406.125000\n",
      "Train Epoch: 57 [35200/54000 (65%)] Loss: -818420.875000\n",
      "Train Epoch: 57 [36608/54000 (68%)] Loss: -835907.562500\n",
      "Train Epoch: 57 [38016/54000 (70%)] Loss: -874654.562500\n",
      "Train Epoch: 57 [39424/54000 (73%)] Loss: -822119.312500\n",
      "Train Epoch: 57 [40832/54000 (76%)] Loss: -739748.562500\n",
      "Train Epoch: 57 [42240/54000 (78%)] Loss: -769417.250000\n",
      "Train Epoch: 57 [43648/54000 (81%)] Loss: -786455.625000\n",
      "Train Epoch: 57 [45056/54000 (83%)] Loss: -790288.375000\n",
      "Train Epoch: 57 [46464/54000 (86%)] Loss: -823077.937500\n",
      "Train Epoch: 57 [47872/54000 (89%)] Loss: -816689.312500\n",
      "Train Epoch: 57 [49280/54000 (91%)] Loss: -845867.437500\n",
      "Train Epoch: 57 [50688/54000 (94%)] Loss: -757389.125000\n",
      "Train Epoch: 57 [52096/54000 (96%)] Loss: -766673.937500\n",
      "    epoch          : 57\n",
      "    loss           : -805575.8244617225\n",
      "    val_loss       : -807464.0828887195\n",
      "Train Epoch: 58 [0/54000 (0%)] Loss: -758376.375000\n",
      "Train Epoch: 58 [1408/54000 (3%)] Loss: -800363.375000\n",
      "Train Epoch: 58 [2816/54000 (5%)] Loss: -791230.125000\n",
      "Train Epoch: 58 [4224/54000 (8%)] Loss: -798311.937500\n",
      "Train Epoch: 58 [5632/54000 (10%)] Loss: -863691.437500\n",
      "Train Epoch: 58 [7040/54000 (13%)] Loss: -791092.500000\n",
      "Train Epoch: 58 [8448/54000 (16%)] Loss: -807256.250000\n",
      "Train Epoch: 58 [9856/54000 (18%)] Loss: -795634.250000\n",
      "Train Epoch: 58 [11264/54000 (21%)] Loss: -819086.812500\n",
      "Train Epoch: 58 [12672/54000 (23%)] Loss: -761830.125000\n",
      "Train Epoch: 58 [14080/54000 (26%)] Loss: -765817.687500\n",
      "Train Epoch: 58 [15488/54000 (29%)] Loss: -837368.250000\n",
      "Train Epoch: 58 [16896/54000 (31%)] Loss: -814075.437500\n",
      "Train Epoch: 58 [18304/54000 (34%)] Loss: -817108.375000\n",
      "Train Epoch: 58 [19712/54000 (37%)] Loss: -763548.062500\n",
      "Train Epoch: 58 [21120/54000 (39%)] Loss: -799272.625000\n",
      "Train Epoch: 58 [22528/54000 (42%)] Loss: -801763.937500\n",
      "Train Epoch: 58 [23936/54000 (44%)] Loss: -787411.687500\n",
      "Train Epoch: 58 [25344/54000 (47%)] Loss: -792059.875000\n",
      "Train Epoch: 58 [26752/54000 (50%)] Loss: -815165.562500\n",
      "Train Epoch: 58 [28160/54000 (52%)] Loss: -794179.937500\n",
      "Train Epoch: 58 [29568/54000 (55%)] Loss: -814691.125000\n",
      "Train Epoch: 58 [30976/54000 (57%)] Loss: -821414.875000\n",
      "Train Epoch: 58 [32384/54000 (60%)] Loss: -827631.062500\n",
      "Train Epoch: 58 [33792/54000 (63%)] Loss: -816332.625000\n",
      "Train Epoch: 58 [35200/54000 (65%)] Loss: -804343.250000\n",
      "Train Epoch: 58 [36608/54000 (68%)] Loss: -817629.875000\n",
      "Train Epoch: 58 [38016/54000 (70%)] Loss: -813997.375000\n",
      "Train Epoch: 58 [39424/54000 (73%)] Loss: -757067.312500\n",
      "Train Epoch: 58 [40832/54000 (76%)] Loss: -820072.812500\n",
      "Train Epoch: 58 [42240/54000 (78%)] Loss: -817157.750000\n",
      "Train Epoch: 58 [43648/54000 (81%)] Loss: -789765.312500\n",
      "Train Epoch: 58 [45056/54000 (83%)] Loss: -770002.500000\n",
      "Train Epoch: 58 [46464/54000 (86%)] Loss: -763327.625000\n",
      "Train Epoch: 58 [47872/54000 (89%)] Loss: -814478.000000\n",
      "Train Epoch: 58 [49280/54000 (91%)] Loss: -818515.375000\n",
      "Train Epoch: 58 [50688/54000 (94%)] Loss: -837771.312500\n",
      "Train Epoch: 58 [52096/54000 (96%)] Loss: -762368.187500\n",
      "    epoch          : 58\n",
      "    loss           : -806107.2984449761\n",
      "    val_loss       : -806515.7915396341\n",
      "Train Epoch: 59 [0/54000 (0%)] Loss: -759238.250000\n",
      "Train Epoch: 59 [1408/54000 (3%)] Loss: -761723.375000\n",
      "Train Epoch: 59 [2816/54000 (5%)] Loss: -891887.625000\n",
      "Train Epoch: 59 [4224/54000 (8%)] Loss: -813576.875000\n",
      "Train Epoch: 59 [5632/54000 (10%)] Loss: -806875.875000\n",
      "Train Epoch: 59 [7040/54000 (13%)] Loss: -796673.562500\n",
      "Train Epoch: 59 [8448/54000 (16%)] Loss: -784631.500000\n",
      "Train Epoch: 59 [9856/54000 (18%)] Loss: -794335.875000\n",
      "Train Epoch: 59 [11264/54000 (21%)] Loss: -798466.500000\n",
      "Train Epoch: 59 [12672/54000 (23%)] Loss: -800153.812500\n",
      "Train Epoch: 59 [14080/54000 (26%)] Loss: -836603.875000\n",
      "Train Epoch: 59 [15488/54000 (29%)] Loss: -844910.000000\n",
      "Train Epoch: 59 [16896/54000 (31%)] Loss: -823102.000000\n",
      "Train Epoch: 59 [18304/54000 (34%)] Loss: -895686.750000\n",
      "Train Epoch: 59 [19712/54000 (37%)] Loss: -790637.125000\n",
      "Train Epoch: 59 [21120/54000 (39%)] Loss: -799099.812500\n",
      "Train Epoch: 59 [22528/54000 (42%)] Loss: -761060.250000\n",
      "Train Epoch: 59 [23936/54000 (44%)] Loss: -801837.000000\n",
      "Train Epoch: 59 [25344/54000 (47%)] Loss: -807785.875000\n",
      "Train Epoch: 59 [26752/54000 (50%)] Loss: -836232.250000\n",
      "Train Epoch: 59 [28160/54000 (52%)] Loss: -763521.187500\n",
      "Train Epoch: 59 [29568/54000 (55%)] Loss: -788604.937500\n",
      "Train Epoch: 59 [30976/54000 (57%)] Loss: -793062.375000\n",
      "Train Epoch: 59 [32384/54000 (60%)] Loss: -776477.062500\n",
      "Train Epoch: 59 [33792/54000 (63%)] Loss: -780688.250000\n",
      "Train Epoch: 59 [35200/54000 (65%)] Loss: -809950.000000\n",
      "Train Epoch: 59 [36608/54000 (68%)] Loss: -799496.750000\n",
      "Train Epoch: 59 [38016/54000 (70%)] Loss: -785619.625000\n",
      "Train Epoch: 59 [39424/54000 (73%)] Loss: -794305.500000\n",
      "Train Epoch: 59 [40832/54000 (76%)] Loss: -814705.125000\n",
      "Train Epoch: 59 [42240/54000 (78%)] Loss: -784079.687500\n",
      "Train Epoch: 59 [43648/54000 (81%)] Loss: -786614.750000\n",
      "Train Epoch: 59 [45056/54000 (83%)] Loss: -799562.000000\n",
      "Train Epoch: 59 [46464/54000 (86%)] Loss: -808520.687500\n",
      "Train Epoch: 59 [47872/54000 (89%)] Loss: -845364.437500\n",
      "Train Epoch: 59 [49280/54000 (91%)] Loss: -774000.375000\n",
      "Train Epoch: 59 [50688/54000 (94%)] Loss: -804416.312500\n",
      "Train Epoch: 59 [52096/54000 (96%)] Loss: -759452.375000\n",
      "    epoch          : 59\n",
      "    loss           : -805669.4294258374\n",
      "    val_loss       : -806372.862804878\n",
      "Train Epoch: 60 [0/54000 (0%)] Loss: -789451.000000\n",
      "Train Epoch: 60 [1408/54000 (3%)] Loss: -786784.500000\n",
      "Train Epoch: 60 [2816/54000 (5%)] Loss: -766259.750000\n",
      "Train Epoch: 60 [4224/54000 (8%)] Loss: -797914.750000\n",
      "Train Epoch: 60 [5632/54000 (10%)] Loss: -826549.312500\n",
      "Train Epoch: 60 [7040/54000 (13%)] Loss: -790610.437500\n",
      "Train Epoch: 60 [8448/54000 (16%)] Loss: -838827.500000\n",
      "Train Epoch: 60 [9856/54000 (18%)] Loss: -807307.500000\n",
      "Train Epoch: 60 [11264/54000 (21%)] Loss: -819217.625000\n",
      "Train Epoch: 60 [12672/54000 (23%)] Loss: -795441.000000\n",
      "Train Epoch: 60 [14080/54000 (26%)] Loss: -756912.000000\n",
      "Train Epoch: 60 [15488/54000 (29%)] Loss: -769755.750000\n",
      "Train Epoch: 60 [16896/54000 (31%)] Loss: -827540.687500\n",
      "Train Epoch: 60 [18304/54000 (34%)] Loss: -886593.562500\n",
      "Train Epoch: 60 [19712/54000 (37%)] Loss: -885489.625000\n",
      "Train Epoch: 60 [21120/54000 (39%)] Loss: -765279.187500\n",
      "Train Epoch: 60 [22528/54000 (42%)] Loss: -789910.937500\n",
      "Train Epoch: 60 [23936/54000 (44%)] Loss: -812945.687500\n",
      "Train Epoch: 60 [25344/54000 (47%)] Loss: -818123.625000\n",
      "Train Epoch: 60 [26752/54000 (50%)] Loss: -818650.875000\n",
      "Train Epoch: 60 [28160/54000 (52%)] Loss: -799230.625000\n",
      "Train Epoch: 60 [29568/54000 (55%)] Loss: -842392.125000\n",
      "Train Epoch: 60 [30976/54000 (57%)] Loss: -779618.687500\n",
      "Train Epoch: 60 [32384/54000 (60%)] Loss: -772259.375000\n",
      "Train Epoch: 60 [33792/54000 (63%)] Loss: -787548.625000\n",
      "Train Epoch: 60 [35200/54000 (65%)] Loss: -755217.250000\n",
      "Train Epoch: 60 [36608/54000 (68%)] Loss: -812521.437500\n",
      "Train Epoch: 60 [38016/54000 (70%)] Loss: -821224.500000\n",
      "Train Epoch: 60 [39424/54000 (73%)] Loss: -762421.062500\n",
      "Train Epoch: 60 [40832/54000 (76%)] Loss: -773187.312500\n",
      "Train Epoch: 60 [42240/54000 (78%)] Loss: -752923.000000\n",
      "Train Epoch: 60 [43648/54000 (81%)] Loss: -793767.750000\n",
      "Train Epoch: 60 [45056/54000 (83%)] Loss: -831773.062500\n",
      "Train Epoch: 60 [46464/54000 (86%)] Loss: -817626.562500\n",
      "Train Epoch: 60 [47872/54000 (89%)] Loss: -799590.437500\n",
      "Train Epoch: 60 [49280/54000 (91%)] Loss: -765536.125000\n",
      "Train Epoch: 60 [50688/54000 (94%)] Loss: -792806.875000\n",
      "Train Epoch: 60 [52096/54000 (96%)] Loss: -767427.687500\n",
      "    epoch          : 60\n",
      "    loss           : -805848.374700957\n",
      "    val_loss       : -808240.9979039634\n",
      "Saving checkpoint: saved/models/Mnist_VaeCategory/0422_221614/checkpoint-epoch60.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 61 [0/54000 (0%)] Loss: -766704.062500\n",
      "Train Epoch: 61 [1408/54000 (3%)] Loss: -814387.062500\n",
      "Train Epoch: 61 [2816/54000 (5%)] Loss: -822384.875000\n",
      "Train Epoch: 61 [4224/54000 (8%)] Loss: -786300.687500\n",
      "Train Epoch: 61 [5632/54000 (10%)] Loss: -875474.125000\n",
      "Train Epoch: 61 [7040/54000 (13%)] Loss: -848184.625000\n",
      "Train Epoch: 61 [8448/54000 (16%)] Loss: -803905.687500\n",
      "Train Epoch: 61 [9856/54000 (18%)] Loss: -787769.687500\n",
      "Train Epoch: 61 [11264/54000 (21%)] Loss: -794551.562500\n",
      "Train Epoch: 61 [12672/54000 (23%)] Loss: -829741.062500\n",
      "Train Epoch: 61 [14080/54000 (26%)] Loss: -801531.875000\n",
      "Train Epoch: 61 [15488/54000 (29%)] Loss: -766329.437500\n",
      "Train Epoch: 61 [16896/54000 (31%)] Loss: -781918.062500\n",
      "Train Epoch: 61 [18304/54000 (34%)] Loss: -765108.250000\n",
      "Train Epoch: 61 [19712/54000 (37%)] Loss: -818471.625000\n",
      "Train Epoch: 61 [21120/54000 (39%)] Loss: -792568.000000\n",
      "Train Epoch: 61 [22528/54000 (42%)] Loss: -872069.875000\n",
      "Train Epoch: 61 [23936/54000 (44%)] Loss: -884325.312500\n",
      "Train Epoch: 61 [25344/54000 (47%)] Loss: -837499.500000\n",
      "Train Epoch: 61 [26752/54000 (50%)] Loss: -812339.625000\n",
      "Train Epoch: 61 [28160/54000 (52%)] Loss: -842756.562500\n",
      "Train Epoch: 61 [29568/54000 (55%)] Loss: -797197.375000\n",
      "Train Epoch: 61 [30976/54000 (57%)] Loss: -805140.687500\n",
      "Train Epoch: 61 [32384/54000 (60%)] Loss: -818113.625000\n",
      "Train Epoch: 61 [33792/54000 (63%)] Loss: -777516.500000\n",
      "Train Epoch: 61 [35200/54000 (65%)] Loss: -795328.687500\n",
      "Train Epoch: 61 [36608/54000 (68%)] Loss: -758959.875000\n",
      "Train Epoch: 61 [38016/54000 (70%)] Loss: -797914.937500\n",
      "Train Epoch: 61 [39424/54000 (73%)] Loss: -760831.125000\n",
      "Train Epoch: 61 [40832/54000 (76%)] Loss: -788852.625000\n",
      "Train Epoch: 61 [42240/54000 (78%)] Loss: -887387.375000\n",
      "Train Epoch: 61 [43648/54000 (81%)] Loss: -760150.812500\n",
      "Train Epoch: 61 [45056/54000 (83%)] Loss: -775092.250000\n",
      "Train Epoch: 61 [46464/54000 (86%)] Loss: -804199.250000\n",
      "Train Epoch: 61 [47872/54000 (89%)] Loss: -821364.125000\n",
      "Train Epoch: 61 [49280/54000 (91%)] Loss: -823752.000000\n",
      "Train Epoch: 61 [50688/54000 (94%)] Loss: -756828.375000\n",
      "Train Epoch: 61 [52096/54000 (96%)] Loss: -761877.875000\n",
      "    epoch          : 61\n",
      "    loss           : -806024.1339712918\n",
      "    val_loss       : -806407.5632621951\n",
      "Train Epoch: 62 [0/54000 (0%)] Loss: -887327.937500\n",
      "Train Epoch: 62 [1408/54000 (3%)] Loss: -882479.125000\n",
      "Train Epoch: 62 [2816/54000 (5%)] Loss: -786876.000000\n",
      "Train Epoch: 62 [4224/54000 (8%)] Loss: -789851.125000\n",
      "Train Epoch: 62 [5632/54000 (10%)] Loss: -827869.937500\n",
      "Train Epoch: 62 [7040/54000 (13%)] Loss: -805714.000000\n",
      "Train Epoch: 62 [8448/54000 (16%)] Loss: -794510.312500\n",
      "Train Epoch: 62 [9856/54000 (18%)] Loss: -758331.750000\n",
      "Train Epoch: 62 [11264/54000 (21%)] Loss: -804858.375000\n",
      "Train Epoch: 62 [12672/54000 (23%)] Loss: -798543.250000\n",
      "Train Epoch: 62 [14080/54000 (26%)] Loss: -795592.625000\n",
      "Train Epoch: 62 [15488/54000 (29%)] Loss: -754755.750000\n",
      "Train Epoch: 62 [16896/54000 (31%)] Loss: -766336.250000\n",
      "Train Epoch: 62 [18304/54000 (34%)] Loss: -811451.125000\n",
      "Train Epoch: 62 [19712/54000 (37%)] Loss: -822371.000000\n",
      "Train Epoch: 62 [21120/54000 (39%)] Loss: -795585.187500\n",
      "Train Epoch: 62 [22528/54000 (42%)] Loss: -793070.687500\n",
      "Train Epoch: 62 [23936/54000 (44%)] Loss: -786463.562500\n",
      "Train Epoch: 62 [25344/54000 (47%)] Loss: -794934.437500\n",
      "Train Epoch: 62 [26752/54000 (50%)] Loss: -756902.875000\n",
      "Train Epoch: 62 [28160/54000 (52%)] Loss: -813659.125000\n",
      "Train Epoch: 62 [29568/54000 (55%)] Loss: -764140.187500\n",
      "Train Epoch: 62 [30976/54000 (57%)] Loss: -790647.187500\n",
      "Train Epoch: 62 [32384/54000 (60%)] Loss: -760125.625000\n",
      "Train Epoch: 62 [33792/54000 (63%)] Loss: -835977.125000\n",
      "Train Epoch: 62 [35200/54000 (65%)] Loss: -823125.687500\n",
      "Train Epoch: 62 [36608/54000 (68%)] Loss: -879790.062500\n",
      "Train Epoch: 62 [38016/54000 (70%)] Loss: -824670.375000\n",
      "Train Epoch: 62 [39424/54000 (73%)] Loss: -829494.750000\n",
      "Train Epoch: 62 [40832/54000 (76%)] Loss: -791145.125000\n",
      "Train Epoch: 62 [42240/54000 (78%)] Loss: -891656.750000\n",
      "Train Epoch: 62 [43648/54000 (81%)] Loss: -813450.375000\n",
      "Train Epoch: 62 [45056/54000 (83%)] Loss: -764714.437500\n",
      "Train Epoch: 62 [46464/54000 (86%)] Loss: -778867.750000\n",
      "Train Epoch: 62 [47872/54000 (89%)] Loss: -761982.312500\n",
      "Train Epoch: 62 [49280/54000 (91%)] Loss: -765549.687500\n",
      "Train Epoch: 62 [50688/54000 (94%)] Loss: -780124.375000\n",
      "Train Epoch: 62 [52096/54000 (96%)] Loss: -837672.500000\n",
      "    epoch          : 62\n",
      "    loss           : -806011.4696471292\n",
      "    val_loss       : -806487.6038490854\n",
      "Train Epoch: 63 [0/54000 (0%)] Loss: -753451.750000\n",
      "Train Epoch: 63 [1408/54000 (3%)] Loss: -811357.250000\n",
      "Train Epoch: 63 [2816/54000 (5%)] Loss: -774446.375000\n",
      "Train Epoch: 63 [4224/54000 (8%)] Loss: -848250.125000\n",
      "Train Epoch: 63 [5632/54000 (10%)] Loss: -832896.562500\n",
      "Train Epoch: 63 [7040/54000 (13%)] Loss: -794721.187500\n",
      "Train Epoch: 63 [8448/54000 (16%)] Loss: -888126.375000\n",
      "Train Epoch: 63 [9856/54000 (18%)] Loss: -888831.625000\n",
      "Train Epoch: 63 [11264/54000 (21%)] Loss: -794315.250000\n",
      "Train Epoch: 63 [12672/54000 (23%)] Loss: -760981.000000\n",
      "Train Epoch: 63 [14080/54000 (26%)] Loss: -799618.937500\n",
      "Train Epoch: 63 [15488/54000 (29%)] Loss: -822597.000000\n",
      "Train Epoch: 63 [16896/54000 (31%)] Loss: -810712.250000\n",
      "Train Epoch: 63 [18304/54000 (34%)] Loss: -761684.250000\n",
      "Train Epoch: 63 [19712/54000 (37%)] Loss: -830817.812500\n",
      "Train Epoch: 63 [21120/54000 (39%)] Loss: -833180.125000\n",
      "Train Epoch: 63 [22528/54000 (42%)] Loss: -829994.875000\n",
      "Train Epoch: 63 [23936/54000 (44%)] Loss: -789987.875000\n",
      "Train Epoch: 63 [25344/54000 (47%)] Loss: -763522.375000\n",
      "Train Epoch: 63 [26752/54000 (50%)] Loss: -892999.250000\n",
      "Train Epoch: 63 [28160/54000 (52%)] Loss: -774785.500000\n",
      "Train Epoch: 63 [29568/54000 (55%)] Loss: -812290.000000\n",
      "Train Epoch: 63 [30976/54000 (57%)] Loss: -792136.125000\n",
      "Train Epoch: 63 [32384/54000 (60%)] Loss: -812074.000000\n",
      "Train Epoch: 63 [33792/54000 (63%)] Loss: -820238.750000\n",
      "Train Epoch: 63 [35200/54000 (65%)] Loss: -773876.875000\n",
      "Train Epoch: 63 [36608/54000 (68%)] Loss: -819167.187500\n",
      "Train Epoch: 63 [38016/54000 (70%)] Loss: -763171.812500\n",
      "Train Epoch: 63 [39424/54000 (73%)] Loss: -793724.750000\n",
      "Train Epoch: 63 [40832/54000 (76%)] Loss: -894625.812500\n",
      "Train Epoch: 63 [42240/54000 (78%)] Loss: -817819.625000\n",
      "Train Epoch: 63 [43648/54000 (81%)] Loss: -804335.062500\n",
      "Train Epoch: 63 [45056/54000 (83%)] Loss: -797054.625000\n",
      "Train Epoch: 63 [46464/54000 (86%)] Loss: -781195.500000\n",
      "Train Epoch: 63 [47872/54000 (89%)] Loss: -830687.125000\n",
      "Train Epoch: 63 [49280/54000 (91%)] Loss: -806641.375000\n",
      "Train Epoch: 63 [50688/54000 (94%)] Loss: -762723.500000\n",
      "Train Epoch: 63 [52096/54000 (96%)] Loss: -830786.750000\n",
      "    epoch          : 63\n",
      "    loss           : -805781.6607356459\n",
      "    val_loss       : -807185.8772865854\n",
      "Train Epoch: 64 [0/54000 (0%)] Loss: -766961.437500\n",
      "Train Epoch: 64 [1408/54000 (3%)] Loss: -735824.750000\n",
      "Train Epoch: 64 [2816/54000 (5%)] Loss: -830243.250000\n",
      "Train Epoch: 64 [4224/54000 (8%)] Loss: -787669.000000\n",
      "Train Epoch: 64 [5632/54000 (10%)] Loss: -801273.875000\n",
      "Train Epoch: 64 [7040/54000 (13%)] Loss: -816443.437500\n",
      "Train Epoch: 64 [8448/54000 (16%)] Loss: -821614.062500\n",
      "Train Epoch: 64 [9856/54000 (18%)] Loss: -831366.062500\n",
      "Train Epoch: 64 [11264/54000 (21%)] Loss: -763863.687500\n",
      "Train Epoch: 64 [12672/54000 (23%)] Loss: -767767.750000\n",
      "Train Epoch: 64 [14080/54000 (26%)] Loss: -838381.750000\n",
      "Train Epoch: 64 [15488/54000 (29%)] Loss: -814076.250000\n",
      "Train Epoch: 64 [16896/54000 (31%)] Loss: -799839.125000\n",
      "Train Epoch: 64 [18304/54000 (34%)] Loss: -765225.750000\n",
      "Train Epoch: 64 [19712/54000 (37%)] Loss: -763920.375000\n",
      "Train Epoch: 64 [21120/54000 (39%)] Loss: -794230.687500\n",
      "Train Epoch: 64 [22528/54000 (42%)] Loss: -799710.875000\n",
      "Train Epoch: 64 [23936/54000 (44%)] Loss: -815492.750000\n",
      "Train Epoch: 64 [25344/54000 (47%)] Loss: -756558.750000\n",
      "Train Epoch: 64 [26752/54000 (50%)] Loss: -820874.250000\n",
      "Train Epoch: 64 [28160/54000 (52%)] Loss: -813000.687500\n",
      "Train Epoch: 64 [29568/54000 (55%)] Loss: -890988.312500\n",
      "Train Epoch: 64 [30976/54000 (57%)] Loss: -761827.187500\n",
      "Train Epoch: 64 [32384/54000 (60%)] Loss: -836393.125000\n",
      "Train Epoch: 64 [33792/54000 (63%)] Loss: -766779.625000\n",
      "Train Epoch: 64 [35200/54000 (65%)] Loss: -759683.250000\n",
      "Train Epoch: 64 [36608/54000 (68%)] Loss: -810636.875000\n",
      "Train Epoch: 64 [38016/54000 (70%)] Loss: -820456.000000\n",
      "Train Epoch: 64 [39424/54000 (73%)] Loss: -814429.062500\n",
      "Train Epoch: 64 [40832/54000 (76%)] Loss: -822566.625000\n",
      "Train Epoch: 64 [42240/54000 (78%)] Loss: -769683.875000\n",
      "Train Epoch: 64 [43648/54000 (81%)] Loss: -784531.625000\n",
      "Train Epoch: 64 [45056/54000 (83%)] Loss: -785076.000000\n",
      "Train Epoch: 64 [46464/54000 (86%)] Loss: -795070.125000\n",
      "Train Epoch: 64 [47872/54000 (89%)] Loss: -836587.375000\n",
      "Train Epoch: 64 [49280/54000 (91%)] Loss: -840714.750000\n",
      "Train Epoch: 64 [50688/54000 (94%)] Loss: -771980.875000\n",
      "Train Epoch: 64 [52096/54000 (96%)] Loss: -772196.125000\n",
      "    epoch          : 64\n",
      "    loss           : -806473.6267942584\n",
      "    val_loss       : -807488.5367759146\n",
      "Train Epoch: 65 [0/54000 (0%)] Loss: -832328.750000\n",
      "Train Epoch: 65 [1408/54000 (3%)] Loss: -782890.562500\n",
      "Train Epoch: 65 [2816/54000 (5%)] Loss: -769160.625000\n",
      "Train Epoch: 65 [4224/54000 (8%)] Loss: -824518.250000\n",
      "Train Epoch: 65 [5632/54000 (10%)] Loss: -786301.062500\n",
      "Train Epoch: 65 [7040/54000 (13%)] Loss: -812962.125000\n",
      "Train Epoch: 65 [8448/54000 (16%)] Loss: -831225.375000\n",
      "Train Epoch: 65 [9856/54000 (18%)] Loss: -772359.437500\n",
      "Train Epoch: 65 [11264/54000 (21%)] Loss: -758340.750000\n",
      "Train Epoch: 65 [12672/54000 (23%)] Loss: -826315.375000\n",
      "Train Epoch: 65 [14080/54000 (26%)] Loss: -798709.562500\n",
      "Train Epoch: 65 [15488/54000 (29%)] Loss: -873063.812500\n",
      "Train Epoch: 65 [16896/54000 (31%)] Loss: -807419.750000\n",
      "Train Epoch: 65 [18304/54000 (34%)] Loss: -772597.187500\n",
      "Train Epoch: 65 [19712/54000 (37%)] Loss: -809470.500000\n",
      "Train Epoch: 65 [21120/54000 (39%)] Loss: -833762.375000\n",
      "Train Epoch: 65 [22528/54000 (42%)] Loss: -846052.875000\n",
      "Train Epoch: 65 [23936/54000 (44%)] Loss: -816737.000000\n",
      "Train Epoch: 65 [25344/54000 (47%)] Loss: -837441.750000\n",
      "Train Epoch: 65 [26752/54000 (50%)] Loss: -822279.437500\n",
      "Train Epoch: 65 [28160/54000 (52%)] Loss: -830243.875000\n",
      "Train Epoch: 65 [29568/54000 (55%)] Loss: -876935.937500\n",
      "Train Epoch: 65 [30976/54000 (57%)] Loss: -802991.500000\n",
      "Train Epoch: 65 [32384/54000 (60%)] Loss: -788268.875000\n",
      "Train Epoch: 65 [33792/54000 (63%)] Loss: -833727.187500\n",
      "Train Epoch: 65 [35200/54000 (65%)] Loss: -795410.187500\n",
      "Train Epoch: 65 [36608/54000 (68%)] Loss: -817037.250000\n",
      "Train Epoch: 65 [38016/54000 (70%)] Loss: -790577.375000\n",
      "Train Epoch: 65 [39424/54000 (73%)] Loss: -764260.062500\n",
      "Train Epoch: 65 [40832/54000 (76%)] Loss: -787894.437500\n",
      "Train Epoch: 65 [42240/54000 (78%)] Loss: -833761.187500\n",
      "Train Epoch: 65 [43648/54000 (81%)] Loss: -815908.500000\n",
      "Train Epoch: 65 [45056/54000 (83%)] Loss: -837806.062500\n",
      "Train Epoch: 65 [46464/54000 (86%)] Loss: -838805.375000\n",
      "Train Epoch: 65 [47872/54000 (89%)] Loss: -818619.375000\n",
      "Train Epoch: 65 [49280/54000 (91%)] Loss: -794083.312500\n",
      "Train Epoch: 65 [50688/54000 (94%)] Loss: -762527.000000\n",
      "Train Epoch: 65 [52096/54000 (96%)] Loss: -763097.187500\n",
      "    epoch          : 65\n",
      "    loss           : -806642.4889354067\n",
      "    val_loss       : -806252.5613567074\n",
      "Saving checkpoint: saved/models/Mnist_VaeCategory/0422_221614/checkpoint-epoch65.pth ...\n",
      "Train Epoch: 66 [0/54000 (0%)] Loss: -758376.812500\n",
      "Train Epoch: 66 [1408/54000 (3%)] Loss: -807423.500000\n",
      "Train Epoch: 66 [2816/54000 (5%)] Loss: -884519.937500\n",
      "Train Epoch: 66 [4224/54000 (8%)] Loss: -796325.437500\n",
      "Train Epoch: 66 [5632/54000 (10%)] Loss: -840991.250000\n",
      "Train Epoch: 66 [7040/54000 (13%)] Loss: -841194.062500\n",
      "Train Epoch: 66 [8448/54000 (16%)] Loss: -785301.500000\n",
      "Train Epoch: 66 [9856/54000 (18%)] Loss: -802621.062500\n",
      "Train Epoch: 66 [11264/54000 (21%)] Loss: -789339.312500\n",
      "Train Epoch: 66 [12672/54000 (23%)] Loss: -804958.750000\n",
      "Train Epoch: 66 [14080/54000 (26%)] Loss: -808442.437500\n",
      "Train Epoch: 66 [15488/54000 (29%)] Loss: -762784.000000\n",
      "Train Epoch: 66 [16896/54000 (31%)] Loss: -801023.687500\n",
      "Train Epoch: 66 [18304/54000 (34%)] Loss: -800339.500000\n",
      "Train Epoch: 66 [19712/54000 (37%)] Loss: -887984.125000\n",
      "Train Epoch: 66 [21120/54000 (39%)] Loss: -790014.375000\n",
      "Train Epoch: 66 [22528/54000 (42%)] Loss: -824057.750000\n",
      "Train Epoch: 66 [23936/54000 (44%)] Loss: -791689.000000\n",
      "Train Epoch: 66 [25344/54000 (47%)] Loss: -799262.437500\n",
      "Train Epoch: 66 [26752/54000 (50%)] Loss: -890671.875000\n",
      "Train Epoch: 66 [28160/54000 (52%)] Loss: -883154.812500\n",
      "Train Epoch: 66 [29568/54000 (55%)] Loss: -807425.187500\n",
      "Train Epoch: 66 [30976/54000 (57%)] Loss: -771439.687500\n",
      "Train Epoch: 66 [32384/54000 (60%)] Loss: -779306.000000\n",
      "Train Epoch: 66 [33792/54000 (63%)] Loss: -761191.562500\n",
      "Train Epoch: 66 [35200/54000 (65%)] Loss: -789574.250000\n",
      "Train Epoch: 66 [36608/54000 (68%)] Loss: -808745.875000\n",
      "Train Epoch: 66 [38016/54000 (70%)] Loss: -791255.187500\n",
      "Train Epoch: 66 [39424/54000 (73%)] Loss: -822513.125000\n",
      "Train Epoch: 66 [40832/54000 (76%)] Loss: -820342.687500\n",
      "Train Epoch: 66 [42240/54000 (78%)] Loss: -792040.625000\n",
      "Train Epoch: 66 [43648/54000 (81%)] Loss: -796448.750000\n",
      "Train Epoch: 66 [45056/54000 (83%)] Loss: -786479.250000\n",
      "Train Epoch: 66 [46464/54000 (86%)] Loss: -789699.312500\n",
      "Train Epoch: 66 [47872/54000 (89%)] Loss: -793166.750000\n",
      "Train Epoch: 66 [49280/54000 (91%)] Loss: -796329.562500\n",
      "Train Epoch: 66 [50688/54000 (94%)] Loss: -775829.937500\n",
      "Train Epoch: 66 [52096/54000 (96%)] Loss: -843122.875000\n",
      "    epoch          : 66\n",
      "    loss           : -806914.5517344498\n",
      "    val_loss       : -807134.0592606707\n",
      "Train Epoch: 67 [0/54000 (0%)] Loss: -756374.250000\n",
      "Train Epoch: 67 [1408/54000 (3%)] Loss: -819911.437500\n",
      "Train Epoch: 67 [2816/54000 (5%)] Loss: -797779.312500\n",
      "Train Epoch: 67 [4224/54000 (8%)] Loss: -797107.000000\n",
      "Train Epoch: 67 [5632/54000 (10%)] Loss: -786165.250000\n",
      "Train Epoch: 67 [7040/54000 (13%)] Loss: -754278.250000\n",
      "Train Epoch: 67 [8448/54000 (16%)] Loss: -825733.625000\n",
      "Train Epoch: 67 [9856/54000 (18%)] Loss: -849136.062500\n",
      "Train Epoch: 67 [11264/54000 (21%)] Loss: -890000.125000\n",
      "Train Epoch: 67 [12672/54000 (23%)] Loss: -807705.312500\n",
      "Train Epoch: 67 [14080/54000 (26%)] Loss: -824276.875000\n",
      "Train Epoch: 67 [15488/54000 (29%)] Loss: -764347.875000\n",
      "Train Epoch: 67 [16896/54000 (31%)] Loss: -761418.000000\n",
      "Train Epoch: 67 [18304/54000 (34%)] Loss: -827666.250000\n",
      "Train Epoch: 67 [19712/54000 (37%)] Loss: -784626.562500\n",
      "Train Epoch: 67 [21120/54000 (39%)] Loss: -793675.875000\n",
      "Train Epoch: 67 [22528/54000 (42%)] Loss: -832426.250000\n",
      "Train Epoch: 67 [23936/54000 (44%)] Loss: -890400.937500\n",
      "Train Epoch: 67 [25344/54000 (47%)] Loss: -891414.875000\n",
      "Train Epoch: 67 [26752/54000 (50%)] Loss: -762958.375000\n",
      "Train Epoch: 67 [28160/54000 (52%)] Loss: -826086.812500\n",
      "Train Epoch: 67 [29568/54000 (55%)] Loss: -835386.250000\n",
      "Train Epoch: 67 [30976/54000 (57%)] Loss: -832694.875000\n",
      "Train Epoch: 67 [32384/54000 (60%)] Loss: -834648.000000\n",
      "Train Epoch: 67 [33792/54000 (63%)] Loss: -836745.625000\n",
      "Train Epoch: 67 [35200/54000 (65%)] Loss: -851625.875000\n",
      "Train Epoch: 67 [36608/54000 (68%)] Loss: -775893.250000\n",
      "Train Epoch: 67 [38016/54000 (70%)] Loss: -769298.875000\n",
      "Train Epoch: 67 [39424/54000 (73%)] Loss: -877613.562500\n",
      "Train Epoch: 67 [40832/54000 (76%)] Loss: -870681.562500\n",
      "Train Epoch: 67 [42240/54000 (78%)] Loss: -824728.562500\n",
      "Train Epoch: 67 [43648/54000 (81%)] Loss: -791123.187500\n",
      "Train Epoch: 67 [45056/54000 (83%)] Loss: -801058.562500\n",
      "Train Epoch: 67 [46464/54000 (86%)] Loss: -799317.125000\n",
      "Train Epoch: 67 [47872/54000 (89%)] Loss: -842689.187500\n",
      "Train Epoch: 67 [49280/54000 (91%)] Loss: -839643.500000\n",
      "Train Epoch: 67 [50688/54000 (94%)] Loss: -812581.125000\n",
      "Train Epoch: 67 [52096/54000 (96%)] Loss: -769932.875000\n",
      "    epoch          : 67\n",
      "    loss           : -806794.9570873206\n",
      "    val_loss       : -806798.5196265244\n",
      "Train Epoch: 68 [0/54000 (0%)] Loss: -761111.562500\n",
      "Train Epoch: 68 [1408/54000 (3%)] Loss: -802367.500000\n",
      "Train Epoch: 68 [2816/54000 (5%)] Loss: -797797.750000\n",
      "Train Epoch: 68 [4224/54000 (8%)] Loss: -807187.250000\n",
      "Train Epoch: 68 [5632/54000 (10%)] Loss: -790061.625000\n",
      "Train Epoch: 68 [7040/54000 (13%)] Loss: -791423.125000\n",
      "Train Epoch: 68 [8448/54000 (16%)] Loss: -787870.875000\n",
      "Train Epoch: 68 [9856/54000 (18%)] Loss: -788916.562500\n",
      "Train Epoch: 68 [11264/54000 (21%)] Loss: -816663.187500\n",
      "Train Epoch: 68 [12672/54000 (23%)] Loss: -832399.000000\n",
      "Train Epoch: 68 [14080/54000 (26%)] Loss: -766667.250000\n",
      "Train Epoch: 68 [15488/54000 (29%)] Loss: -814701.812500\n",
      "Train Epoch: 68 [16896/54000 (31%)] Loss: -760316.062500\n",
      "Train Epoch: 68 [18304/54000 (34%)] Loss: -808668.125000\n",
      "Train Epoch: 68 [19712/54000 (37%)] Loss: -812026.000000\n",
      "Train Epoch: 68 [21120/54000 (39%)] Loss: -826624.187500\n",
      "Train Epoch: 68 [22528/54000 (42%)] Loss: -787494.687500\n",
      "Train Epoch: 68 [23936/54000 (44%)] Loss: -800603.875000\n",
      "Train Epoch: 68 [25344/54000 (47%)] Loss: -768505.375000\n",
      "Train Epoch: 68 [26752/54000 (50%)] Loss: -790734.875000\n",
      "Train Epoch: 68 [28160/54000 (52%)] Loss: -790081.875000\n",
      "Train Epoch: 68 [29568/54000 (55%)] Loss: -759272.625000\n",
      "Train Epoch: 68 [30976/54000 (57%)] Loss: -788256.687500\n",
      "Train Epoch: 68 [32384/54000 (60%)] Loss: -795284.375000\n",
      "Train Epoch: 68 [33792/54000 (63%)] Loss: -764655.250000\n",
      "Train Epoch: 68 [35200/54000 (65%)] Loss: -817315.875000\n",
      "Train Epoch: 68 [36608/54000 (68%)] Loss: -830777.000000\n",
      "Train Epoch: 68 [38016/54000 (70%)] Loss: -762264.062500\n",
      "Train Epoch: 68 [39424/54000 (73%)] Loss: -802438.937500\n",
      "Train Epoch: 68 [40832/54000 (76%)] Loss: -892961.937500\n",
      "Train Epoch: 68 [42240/54000 (78%)] Loss: -837329.875000\n",
      "Train Epoch: 68 [43648/54000 (81%)] Loss: -807267.125000\n",
      "Train Epoch: 68 [45056/54000 (83%)] Loss: -796836.250000\n",
      "Train Epoch: 68 [46464/54000 (86%)] Loss: -790570.687500\n",
      "Train Epoch: 68 [47872/54000 (89%)] Loss: -853481.187500\n",
      "Train Epoch: 68 [49280/54000 (91%)] Loss: -818410.437500\n",
      "Train Epoch: 68 [50688/54000 (94%)] Loss: -823350.375000\n",
      "Train Epoch: 68 [52096/54000 (96%)] Loss: -762789.062500\n",
      "    epoch          : 68\n",
      "    loss           : -806905.9240430621\n",
      "    val_loss       : -807388.142339939\n",
      "Train Epoch: 69 [0/54000 (0%)] Loss: -814931.687500\n",
      "Train Epoch: 69 [1408/54000 (3%)] Loss: -866647.750000\n",
      "Train Epoch: 69 [2816/54000 (5%)] Loss: -809404.062500\n",
      "Train Epoch: 69 [4224/54000 (8%)] Loss: -778630.875000\n",
      "Train Epoch: 69 [5632/54000 (10%)] Loss: -788745.375000\n",
      "Train Epoch: 69 [7040/54000 (13%)] Loss: -801304.062500\n",
      "Train Epoch: 69 [8448/54000 (16%)] Loss: -877538.875000\n",
      "Train Epoch: 69 [9856/54000 (18%)] Loss: -792675.625000\n",
      "Train Epoch: 69 [11264/54000 (21%)] Loss: -796065.250000\n",
      "Train Epoch: 69 [12672/54000 (23%)] Loss: -794365.000000\n",
      "Train Epoch: 69 [14080/54000 (26%)] Loss: -818817.625000\n",
      "Train Epoch: 69 [15488/54000 (29%)] Loss: -772926.875000\n",
      "Train Epoch: 69 [16896/54000 (31%)] Loss: -770035.187500\n",
      "Train Epoch: 69 [18304/54000 (34%)] Loss: -817648.500000\n",
      "Train Epoch: 69 [19712/54000 (37%)] Loss: -805041.687500\n",
      "Train Epoch: 69 [21120/54000 (39%)] Loss: -753905.375000\n",
      "Train Epoch: 69 [22528/54000 (42%)] Loss: -784956.250000\n",
      "Train Epoch: 69 [23936/54000 (44%)] Loss: -802385.687500\n",
      "Train Epoch: 69 [25344/54000 (47%)] Loss: -821009.687500\n",
      "Train Epoch: 69 [26752/54000 (50%)] Loss: -753072.000000\n",
      "Train Epoch: 69 [28160/54000 (52%)] Loss: -804570.125000\n",
      "Train Epoch: 69 [29568/54000 (55%)] Loss: -819374.375000\n",
      "Train Epoch: 69 [30976/54000 (57%)] Loss: -799492.875000\n",
      "Train Epoch: 69 [32384/54000 (60%)] Loss: -790425.687500\n",
      "Train Epoch: 69 [33792/54000 (63%)] Loss: -804240.937500\n",
      "Train Epoch: 69 [35200/54000 (65%)] Loss: -796386.687500\n",
      "Train Epoch: 69 [36608/54000 (68%)] Loss: -777814.937500\n",
      "Train Epoch: 69 [38016/54000 (70%)] Loss: -822084.000000\n",
      "Train Epoch: 69 [39424/54000 (73%)] Loss: -801651.187500\n",
      "Train Epoch: 69 [40832/54000 (76%)] Loss: -802948.437500\n",
      "Train Epoch: 69 [42240/54000 (78%)] Loss: -894232.875000\n",
      "Train Epoch: 69 [43648/54000 (81%)] Loss: -790054.375000\n",
      "Train Epoch: 69 [45056/54000 (83%)] Loss: -837335.562500\n",
      "Train Epoch: 69 [46464/54000 (86%)] Loss: -754734.875000\n",
      "Train Epoch: 69 [47872/54000 (89%)] Loss: -818174.437500\n",
      "Train Epoch: 69 [49280/54000 (91%)] Loss: -842798.250000\n",
      "Train Epoch: 69 [50688/54000 (94%)] Loss: -763440.812500\n",
      "Train Epoch: 69 [52096/54000 (96%)] Loss: -825235.812500\n",
      "    epoch          : 69\n",
      "    loss           : -806724.0255681818\n",
      "    val_loss       : -806540.388910061\n",
      "Train Epoch: 70 [0/54000 (0%)] Loss: -758681.625000\n",
      "Train Epoch: 70 [1408/54000 (3%)] Loss: -756920.875000\n",
      "Train Epoch: 70 [2816/54000 (5%)] Loss: -766102.562500\n",
      "Train Epoch: 70 [4224/54000 (8%)] Loss: -818779.000000\n",
      "Train Epoch: 70 [5632/54000 (10%)] Loss: -849515.062500\n",
      "Train Epoch: 70 [7040/54000 (13%)] Loss: -789564.562500\n",
      "Train Epoch: 70 [8448/54000 (16%)] Loss: -763804.000000\n",
      "Train Epoch: 70 [9856/54000 (18%)] Loss: -819772.562500\n",
      "Train Epoch: 70 [11264/54000 (21%)] Loss: -810884.750000\n",
      "Train Epoch: 70 [12672/54000 (23%)] Loss: -776549.312500\n",
      "Train Epoch: 70 [14080/54000 (26%)] Loss: -786068.000000\n",
      "Train Epoch: 70 [15488/54000 (29%)] Loss: -810023.437500\n",
      "Train Epoch: 70 [16896/54000 (31%)] Loss: -799068.125000\n",
      "Train Epoch: 70 [18304/54000 (34%)] Loss: -759866.375000\n",
      "Train Epoch: 70 [19712/54000 (37%)] Loss: -793451.187500\n",
      "Train Epoch: 70 [21120/54000 (39%)] Loss: -827084.625000\n",
      "Train Epoch: 70 [22528/54000 (42%)] Loss: -782067.187500\n",
      "Train Epoch: 70 [23936/54000 (44%)] Loss: -882167.750000\n",
      "Train Epoch: 70 [25344/54000 (47%)] Loss: -902380.437500\n",
      "Train Epoch: 70 [26752/54000 (50%)] Loss: -832116.625000\n",
      "Train Epoch: 70 [28160/54000 (52%)] Loss: -839702.437500\n",
      "Train Epoch: 70 [29568/54000 (55%)] Loss: -819300.125000\n",
      "Train Epoch: 70 [30976/54000 (57%)] Loss: -757667.812500\n",
      "Train Epoch: 70 [32384/54000 (60%)] Loss: -833599.750000\n",
      "Train Epoch: 70 [33792/54000 (63%)] Loss: -803531.812500\n",
      "Train Epoch: 70 [35200/54000 (65%)] Loss: -784551.812500\n",
      "Train Epoch: 70 [36608/54000 (68%)] Loss: -754511.000000\n",
      "Train Epoch: 70 [38016/54000 (70%)] Loss: -786431.562500\n",
      "Train Epoch: 70 [39424/54000 (73%)] Loss: -814829.750000\n",
      "Train Epoch: 70 [40832/54000 (76%)] Loss: -808279.062500\n",
      "Train Epoch: 70 [42240/54000 (78%)] Loss: -888191.625000\n",
      "Train Epoch: 70 [43648/54000 (81%)] Loss: -792622.000000\n",
      "Train Epoch: 70 [45056/54000 (83%)] Loss: -803654.125000\n",
      "Train Epoch: 70 [46464/54000 (86%)] Loss: -789266.625000\n",
      "Train Epoch: 70 [47872/54000 (89%)] Loss: -838334.937500\n",
      "Train Epoch: 70 [49280/54000 (91%)] Loss: -760751.250000\n",
      "Train Epoch: 70 [50688/54000 (94%)] Loss: -815080.437500\n",
      "Train Epoch: 70 [52096/54000 (96%)] Loss: -847697.125000\n",
      "    epoch          : 70\n",
      "    loss           : -806565.8818779904\n",
      "    val_loss       : -807923.8418445121\n",
      "Saving checkpoint: saved/models/Mnist_VaeCategory/0422_221614/checkpoint-epoch70.pth ...\n",
      "Train Epoch: 71 [0/54000 (0%)] Loss: -736027.937500\n",
      "Train Epoch: 71 [1408/54000 (3%)] Loss: -757353.625000\n",
      "Train Epoch: 71 [2816/54000 (5%)] Loss: -776459.875000\n",
      "Train Epoch: 71 [4224/54000 (8%)] Loss: -820683.625000\n",
      "Train Epoch: 71 [5632/54000 (10%)] Loss: -812120.062500\n",
      "Train Epoch: 71 [7040/54000 (13%)] Loss: -791843.812500\n",
      "Train Epoch: 71 [8448/54000 (16%)] Loss: -834485.187500\n",
      "Train Epoch: 71 [9856/54000 (18%)] Loss: -757577.937500\n",
      "Train Epoch: 71 [11264/54000 (21%)] Loss: -844697.562500\n",
      "Train Epoch: 71 [12672/54000 (23%)] Loss: -787066.000000\n",
      "Train Epoch: 71 [14080/54000 (26%)] Loss: -795739.500000\n",
      "Train Epoch: 71 [15488/54000 (29%)] Loss: -822452.937500\n",
      "Train Epoch: 71 [16896/54000 (31%)] Loss: -890577.625000\n",
      "Train Epoch: 71 [18304/54000 (34%)] Loss: -829432.500000\n",
      "Train Epoch: 71 [19712/54000 (37%)] Loss: -824477.750000\n",
      "Train Epoch: 71 [21120/54000 (39%)] Loss: -880598.812500\n",
      "Train Epoch: 71 [22528/54000 (42%)] Loss: -759754.062500\n",
      "Train Epoch: 71 [23936/54000 (44%)] Loss: -806919.625000\n",
      "Train Epoch: 71 [25344/54000 (47%)] Loss: -797376.812500\n",
      "Train Epoch: 71 [26752/54000 (50%)] Loss: -803620.125000\n",
      "Train Epoch: 71 [28160/54000 (52%)] Loss: -812015.750000\n",
      "Train Epoch: 71 [29568/54000 (55%)] Loss: -762326.750000\n",
      "Train Epoch: 71 [30976/54000 (57%)] Loss: -754547.250000\n",
      "Train Epoch: 71 [32384/54000 (60%)] Loss: -830255.875000\n",
      "Train Epoch: 71 [33792/54000 (63%)] Loss: -809289.375000\n",
      "Train Epoch: 71 [35200/54000 (65%)] Loss: -759039.750000\n",
      "Train Epoch: 71 [36608/54000 (68%)] Loss: -870535.437500\n",
      "Train Epoch: 71 [38016/54000 (70%)] Loss: -807001.062500\n",
      "Train Epoch: 71 [39424/54000 (73%)] Loss: -794870.062500\n",
      "Train Epoch: 71 [40832/54000 (76%)] Loss: -888826.000000\n",
      "Train Epoch: 71 [42240/54000 (78%)] Loss: -794858.875000\n",
      "Train Epoch: 71 [43648/54000 (81%)] Loss: -781365.062500\n",
      "Train Epoch: 71 [45056/54000 (83%)] Loss: -771358.500000\n",
      "Train Epoch: 71 [46464/54000 (86%)] Loss: -800836.312500\n",
      "Train Epoch: 71 [47872/54000 (89%)] Loss: -835909.625000\n",
      "Train Epoch: 71 [49280/54000 (91%)] Loss: -811924.500000\n",
      "Train Epoch: 71 [50688/54000 (94%)] Loss: -790242.375000\n",
      "Train Epoch: 71 [52096/54000 (96%)] Loss: -795556.687500\n",
      "    epoch          : 71\n",
      "    loss           : -806921.632027512\n",
      "    val_loss       : -807606.5493521341\n",
      "Train Epoch: 72 [0/54000 (0%)] Loss: -755267.187500\n",
      "Train Epoch: 72 [1408/54000 (3%)] Loss: -795007.437500\n",
      "Train Epoch: 72 [2816/54000 (5%)] Loss: -801427.125000\n",
      "Train Epoch: 72 [4224/54000 (8%)] Loss: -873952.437500\n",
      "Train Epoch: 72 [5632/54000 (10%)] Loss: -807492.750000\n",
      "Train Epoch: 72 [7040/54000 (13%)] Loss: -808813.750000\n",
      "Train Epoch: 72 [8448/54000 (16%)] Loss: -845319.937500\n",
      "Train Epoch: 72 [9856/54000 (18%)] Loss: -794344.312500\n",
      "Train Epoch: 72 [11264/54000 (21%)] Loss: -795534.625000\n",
      "Train Epoch: 72 [12672/54000 (23%)] Loss: -794385.437500\n",
      "Train Epoch: 72 [14080/54000 (26%)] Loss: -778652.937500\n",
      "Train Epoch: 72 [15488/54000 (29%)] Loss: -774132.687500\n",
      "Train Epoch: 72 [16896/54000 (31%)] Loss: -805840.312500\n",
      "Train Epoch: 72 [18304/54000 (34%)] Loss: -811029.687500\n",
      "Train Epoch: 72 [19712/54000 (37%)] Loss: -827939.250000\n",
      "Train Epoch: 72 [21120/54000 (39%)] Loss: -793497.437500\n",
      "Train Epoch: 72 [22528/54000 (42%)] Loss: -799068.250000\n",
      "Train Epoch: 72 [23936/54000 (44%)] Loss: -877293.375000\n",
      "Train Epoch: 72 [25344/54000 (47%)] Loss: -828244.750000\n",
      "Train Epoch: 72 [26752/54000 (50%)] Loss: -843209.562500\n",
      "Train Epoch: 72 [28160/54000 (52%)] Loss: -852752.937500\n",
      "Train Epoch: 72 [29568/54000 (55%)] Loss: -814999.250000\n",
      "Train Epoch: 72 [30976/54000 (57%)] Loss: -794653.187500\n",
      "Train Epoch: 72 [32384/54000 (60%)] Loss: -779683.562500\n",
      "Train Epoch: 72 [33792/54000 (63%)] Loss: -763119.187500\n",
      "Train Epoch: 72 [35200/54000 (65%)] Loss: -830309.812500\n",
      "Train Epoch: 72 [36608/54000 (68%)] Loss: -825500.437500\n",
      "Train Epoch: 72 [38016/54000 (70%)] Loss: -791561.125000\n",
      "Train Epoch: 72 [39424/54000 (73%)] Loss: -797956.375000\n",
      "Train Epoch: 72 [40832/54000 (76%)] Loss: -763033.750000\n",
      "Train Epoch: 72 [42240/54000 (78%)] Loss: -789833.000000\n",
      "Train Epoch: 72 [43648/54000 (81%)] Loss: -787373.125000\n",
      "Train Epoch: 72 [45056/54000 (83%)] Loss: -793010.250000\n",
      "Train Epoch: 72 [46464/54000 (86%)] Loss: -794853.062500\n",
      "Train Epoch: 72 [47872/54000 (89%)] Loss: -847766.250000\n",
      "Train Epoch: 72 [49280/54000 (91%)] Loss: -835222.000000\n",
      "Train Epoch: 72 [50688/54000 (94%)] Loss: -760973.250000\n",
      "Train Epoch: 72 [52096/54000 (96%)] Loss: -777323.250000\n",
      "    epoch          : 72\n",
      "    loss           : -807081.0085227273\n",
      "    val_loss       : -807374.618902439\n",
      "Train Epoch: 73 [0/54000 (0%)] Loss: -796453.625000\n",
      "Train Epoch: 73 [1408/54000 (3%)] Loss: -768957.562500\n",
      "Train Epoch: 73 [2816/54000 (5%)] Loss: -792221.250000\n",
      "Train Epoch: 73 [4224/54000 (8%)] Loss: -775998.375000\n",
      "Train Epoch: 73 [5632/54000 (10%)] Loss: -796432.625000\n",
      "Train Epoch: 73 [7040/54000 (13%)] Loss: -803956.875000\n",
      "Train Epoch: 73 [8448/54000 (16%)] Loss: -763444.375000\n",
      "Train Epoch: 73 [9856/54000 (18%)] Loss: -809250.125000\n",
      "Train Epoch: 73 [11264/54000 (21%)] Loss: -790571.687500\n",
      "Train Epoch: 73 [12672/54000 (23%)] Loss: -843776.875000\n",
      "Train Epoch: 73 [14080/54000 (26%)] Loss: -888080.250000\n",
      "Train Epoch: 73 [15488/54000 (29%)] Loss: -758270.312500\n",
      "Train Epoch: 73 [16896/54000 (31%)] Loss: -789262.500000\n",
      "Train Epoch: 73 [18304/54000 (34%)] Loss: -823575.437500\n",
      "Train Epoch: 73 [19712/54000 (37%)] Loss: -793861.687500\n",
      "Train Epoch: 73 [21120/54000 (39%)] Loss: -790516.687500\n",
      "Train Epoch: 73 [22528/54000 (42%)] Loss: -887311.250000\n",
      "Train Epoch: 73 [23936/54000 (44%)] Loss: -827201.000000\n",
      "Train Epoch: 73 [25344/54000 (47%)] Loss: -826632.312500\n",
      "Train Epoch: 73 [26752/54000 (50%)] Loss: -794405.312500\n",
      "Train Epoch: 73 [28160/54000 (52%)] Loss: -781692.312500\n",
      "Train Epoch: 73 [29568/54000 (55%)] Loss: -801616.937500\n",
      "Train Epoch: 73 [30976/54000 (57%)] Loss: -785460.000000\n",
      "Train Epoch: 73 [32384/54000 (60%)] Loss: -832275.812500\n",
      "Train Epoch: 73 [33792/54000 (63%)] Loss: -814033.000000\n",
      "Train Epoch: 73 [35200/54000 (65%)] Loss: -814851.437500\n",
      "Train Epoch: 73 [36608/54000 (68%)] Loss: -762730.000000\n",
      "Train Epoch: 73 [38016/54000 (70%)] Loss: -775577.562500\n",
      "Train Epoch: 73 [39424/54000 (73%)] Loss: -898102.500000\n",
      "Train Epoch: 73 [40832/54000 (76%)] Loss: -812063.125000\n",
      "Train Epoch: 73 [42240/54000 (78%)] Loss: -795075.250000\n",
      "Train Epoch: 73 [43648/54000 (81%)] Loss: -759480.625000\n",
      "Train Epoch: 73 [45056/54000 (83%)] Loss: -806886.250000\n",
      "Train Epoch: 73 [46464/54000 (86%)] Loss: -816356.375000\n",
      "Train Epoch: 73 [47872/54000 (89%)] Loss: -816832.125000\n",
      "Train Epoch: 73 [49280/54000 (91%)] Loss: -757005.875000\n",
      "Train Epoch: 73 [50688/54000 (94%)] Loss: -772995.375000\n",
      "Train Epoch: 73 [52096/54000 (96%)] Loss: -784706.062500\n",
      "    epoch          : 73\n",
      "    loss           : -807291.7872308613\n",
      "    val_loss       : -807828.9906631098\n",
      "Train Epoch: 74 [0/54000 (0%)] Loss: -766360.187500\n",
      "Train Epoch: 74 [1408/54000 (3%)] Loss: -764275.687500\n",
      "Train Epoch: 74 [2816/54000 (5%)] Loss: -793479.562500\n",
      "Train Epoch: 74 [4224/54000 (8%)] Loss: -819635.625000\n",
      "Train Epoch: 74 [5632/54000 (10%)] Loss: -811696.625000\n",
      "Train Epoch: 74 [7040/54000 (13%)] Loss: -811183.562500\n",
      "Train Epoch: 74 [8448/54000 (16%)] Loss: -882672.750000\n",
      "Train Epoch: 74 [9856/54000 (18%)] Loss: -881553.250000\n",
      "Train Epoch: 74 [11264/54000 (21%)] Loss: -770747.125000\n",
      "Train Epoch: 74 [12672/54000 (23%)] Loss: -803570.062500\n",
      "Train Epoch: 74 [14080/54000 (26%)] Loss: -809379.625000\n",
      "Train Epoch: 74 [15488/54000 (29%)] Loss: -812900.375000\n",
      "Train Epoch: 74 [16896/54000 (31%)] Loss: -815953.562500\n",
      "Train Epoch: 74 [18304/54000 (34%)] Loss: -820675.000000\n",
      "Train Epoch: 74 [19712/54000 (37%)] Loss: -819948.625000\n",
      "Train Epoch: 74 [21120/54000 (39%)] Loss: -792641.000000\n",
      "Train Epoch: 74 [22528/54000 (42%)] Loss: -887496.625000\n",
      "Train Epoch: 74 [23936/54000 (44%)] Loss: -792157.375000\n",
      "Train Epoch: 74 [25344/54000 (47%)] Loss: -793483.125000\n",
      "Train Epoch: 74 [26752/54000 (50%)] Loss: -775020.062500\n",
      "Train Epoch: 74 [28160/54000 (52%)] Loss: -762152.125000\n",
      "Train Epoch: 74 [29568/54000 (55%)] Loss: -832116.625000\n",
      "Train Epoch: 74 [30976/54000 (57%)] Loss: -760464.000000\n",
      "Train Epoch: 74 [32384/54000 (60%)] Loss: -801663.875000\n",
      "Train Epoch: 74 [33792/54000 (63%)] Loss: -770355.500000\n",
      "Train Epoch: 74 [35200/54000 (65%)] Loss: -827415.125000\n",
      "Train Epoch: 74 [36608/54000 (68%)] Loss: -762688.812500\n",
      "Train Epoch: 74 [38016/54000 (70%)] Loss: -798540.375000\n",
      "Train Epoch: 74 [39424/54000 (73%)] Loss: -825818.000000\n",
      "Train Epoch: 74 [40832/54000 (76%)] Loss: -880143.562500\n",
      "Train Epoch: 74 [42240/54000 (78%)] Loss: -794186.750000\n",
      "Train Epoch: 74 [43648/54000 (81%)] Loss: -807588.562500\n",
      "Train Epoch: 74 [45056/54000 (83%)] Loss: -811930.687500\n",
      "Train Epoch: 74 [46464/54000 (86%)] Loss: -792925.500000\n",
      "Train Epoch: 74 [47872/54000 (89%)] Loss: -836906.562500\n",
      "Train Epoch: 74 [49280/54000 (91%)] Loss: -832006.937500\n",
      "Train Epoch: 74 [50688/54000 (94%)] Loss: -837082.750000\n",
      "Train Epoch: 74 [52096/54000 (96%)] Loss: -824412.562500\n",
      "    epoch          : 74\n",
      "    loss           : -807447.5617523923\n",
      "    val_loss       : -807803.381097561\n",
      "Train Epoch: 75 [0/54000 (0%)] Loss: -751105.812500\n",
      "Train Epoch: 75 [1408/54000 (3%)] Loss: -777149.437500\n",
      "Train Epoch: 75 [2816/54000 (5%)] Loss: -797652.500000\n",
      "Train Epoch: 75 [4224/54000 (8%)] Loss: -806963.250000\n",
      "Train Epoch: 75 [5632/54000 (10%)] Loss: -805704.750000\n",
      "Train Epoch: 75 [7040/54000 (13%)] Loss: -822063.687500\n",
      "Train Epoch: 75 [8448/54000 (16%)] Loss: -796430.250000\n",
      "Train Epoch: 75 [9856/54000 (18%)] Loss: -851987.125000\n",
      "Train Epoch: 75 [11264/54000 (21%)] Loss: -804581.750000\n",
      "Train Epoch: 75 [12672/54000 (23%)] Loss: -805310.250000\n",
      "Train Epoch: 75 [14080/54000 (26%)] Loss: -795986.375000\n",
      "Train Epoch: 75 [15488/54000 (29%)] Loss: -758323.125000\n",
      "Train Epoch: 75 [16896/54000 (31%)] Loss: -767771.812500\n",
      "Train Epoch: 75 [18304/54000 (34%)] Loss: -767748.562500\n",
      "Train Epoch: 75 [19712/54000 (37%)] Loss: -808300.937500\n",
      "Train Epoch: 75 [21120/54000 (39%)] Loss: -760399.562500\n",
      "Train Epoch: 75 [22528/54000 (42%)] Loss: -869114.875000\n",
      "Train Epoch: 75 [23936/54000 (44%)] Loss: -890276.875000\n",
      "Train Epoch: 75 [25344/54000 (47%)] Loss: -844216.062500\n",
      "Train Epoch: 75 [26752/54000 (50%)] Loss: -795241.562500\n",
      "Train Epoch: 75 [28160/54000 (52%)] Loss: -819158.250000\n",
      "Train Epoch: 75 [29568/54000 (55%)] Loss: -830835.375000\n",
      "Train Epoch: 75 [30976/54000 (57%)] Loss: -814954.312500\n",
      "Train Epoch: 75 [32384/54000 (60%)] Loss: -769134.625000\n",
      "Train Epoch: 75 [33792/54000 (63%)] Loss: -763532.000000\n",
      "Train Epoch: 75 [35200/54000 (65%)] Loss: -827136.875000\n",
      "Train Epoch: 75 [36608/54000 (68%)] Loss: -767158.750000\n",
      "Train Epoch: 75 [38016/54000 (70%)] Loss: -782873.750000\n",
      "Train Epoch: 75 [39424/54000 (73%)] Loss: -816092.000000\n",
      "Train Epoch: 75 [40832/54000 (76%)] Loss: -772392.812500\n",
      "Train Epoch: 75 [42240/54000 (78%)] Loss: -880454.625000\n",
      "Train Epoch: 75 [43648/54000 (81%)] Loss: -759653.062500\n",
      "Train Epoch: 75 [45056/54000 (83%)] Loss: -846213.375000\n",
      "Train Epoch: 75 [46464/54000 (86%)] Loss: -805827.250000\n",
      "Train Epoch: 75 [47872/54000 (89%)] Loss: -845164.250000\n",
      "Train Epoch: 75 [49280/54000 (91%)] Loss: -793697.500000\n",
      "Train Epoch: 75 [50688/54000 (94%)] Loss: -770020.562500\n",
      "Train Epoch: 75 [52096/54000 (96%)] Loss: -772166.000000\n",
      "    epoch          : 75\n",
      "    loss           : -807171.1296351674\n",
      "    val_loss       : -807381.4533155488\n",
      "Saving checkpoint: saved/models/Mnist_VaeCategory/0422_221614/checkpoint-epoch75.pth ...\n",
      "Train Epoch: 76 [0/54000 (0%)] Loss: -825722.312500\n",
      "Train Epoch: 76 [1408/54000 (3%)] Loss: -761962.875000\n",
      "Train Epoch: 76 [2816/54000 (5%)] Loss: -801379.625000\n",
      "Train Epoch: 76 [4224/54000 (8%)] Loss: -781180.937500\n",
      "Train Epoch: 76 [5632/54000 (10%)] Loss: -782201.125000\n",
      "Train Epoch: 76 [7040/54000 (13%)] Loss: -791353.500000\n",
      "Train Epoch: 76 [8448/54000 (16%)] Loss: -829302.187500\n",
      "Train Epoch: 76 [9856/54000 (18%)] Loss: -794943.375000\n",
      "Train Epoch: 76 [11264/54000 (21%)] Loss: -840885.625000\n",
      "Train Epoch: 76 [12672/54000 (23%)] Loss: -802169.562500\n",
      "Train Epoch: 76 [14080/54000 (26%)] Loss: -810228.125000\n",
      "Train Epoch: 76 [15488/54000 (29%)] Loss: -758620.875000\n",
      "Train Epoch: 76 [16896/54000 (31%)] Loss: -791325.312500\n",
      "Train Epoch: 76 [18304/54000 (34%)] Loss: -828602.125000\n",
      "Train Epoch: 76 [19712/54000 (37%)] Loss: -787151.312500\n",
      "Train Epoch: 76 [21120/54000 (39%)] Loss: -795126.875000\n",
      "Train Epoch: 76 [22528/54000 (42%)] Loss: -794928.812500\n",
      "Train Epoch: 76 [23936/54000 (44%)] Loss: -814736.937500\n",
      "Train Epoch: 76 [25344/54000 (47%)] Loss: -804716.937500\n",
      "Train Epoch: 76 [26752/54000 (50%)] Loss: -766159.562500\n",
      "Train Epoch: 76 [28160/54000 (52%)] Loss: -758900.437500\n",
      "Train Epoch: 76 [29568/54000 (55%)] Loss: -833698.562500\n",
      "Train Epoch: 76 [30976/54000 (57%)] Loss: -800032.125000\n",
      "Train Epoch: 76 [32384/54000 (60%)] Loss: -821547.875000\n",
      "Train Epoch: 76 [33792/54000 (63%)] Loss: -814492.062500\n",
      "Train Epoch: 76 [35200/54000 (65%)] Loss: -826206.125000\n",
      "Train Epoch: 76 [36608/54000 (68%)] Loss: -823010.062500\n",
      "Train Epoch: 76 [38016/54000 (70%)] Loss: -794345.375000\n",
      "Train Epoch: 76 [39424/54000 (73%)] Loss: -805320.687500\n",
      "Train Epoch: 76 [40832/54000 (76%)] Loss: -772265.125000\n",
      "Train Epoch: 76 [42240/54000 (78%)] Loss: -793467.625000\n",
      "Train Epoch: 76 [43648/54000 (81%)] Loss: -793227.812500\n",
      "Train Epoch: 76 [45056/54000 (83%)] Loss: -809104.250000\n",
      "Train Epoch: 76 [46464/54000 (86%)] Loss: -767353.250000\n",
      "Train Epoch: 76 [47872/54000 (89%)] Loss: -824393.750000\n",
      "Train Epoch: 76 [49280/54000 (91%)] Loss: -846562.875000\n",
      "Train Epoch: 76 [50688/54000 (94%)] Loss: -759668.625000\n",
      "Train Epoch: 76 [52096/54000 (96%)] Loss: -777749.750000\n",
      "    epoch          : 76\n",
      "    loss           : -807327.5921052631\n",
      "    val_loss       : -807016.6177591464\n",
      "Train Epoch: 77 [0/54000 (0%)] Loss: -833588.562500\n",
      "Train Epoch: 77 [1408/54000 (3%)] Loss: -807559.875000\n",
      "Train Epoch: 77 [2816/54000 (5%)] Loss: -812780.000000\n",
      "Train Epoch: 77 [4224/54000 (8%)] Loss: -805233.875000\n",
      "Train Epoch: 77 [5632/54000 (10%)] Loss: -798774.875000\n",
      "Train Epoch: 77 [7040/54000 (13%)] Loss: -794459.250000\n",
      "Train Epoch: 77 [8448/54000 (16%)] Loss: -815375.875000\n",
      "Train Epoch: 77 [9856/54000 (18%)] Loss: -781102.375000\n",
      "Train Epoch: 77 [11264/54000 (21%)] Loss: -823111.250000\n",
      "Train Epoch: 77 [12672/54000 (23%)] Loss: -794966.250000\n",
      "Train Epoch: 77 [14080/54000 (26%)] Loss: -801657.500000\n",
      "Train Epoch: 77 [15488/54000 (29%)] Loss: -763393.750000\n",
      "Train Epoch: 77 [16896/54000 (31%)] Loss: -786517.812500\n",
      "Train Epoch: 77 [18304/54000 (34%)] Loss: -794931.375000\n",
      "Train Epoch: 77 [19712/54000 (37%)] Loss: -792468.750000\n",
      "Train Epoch: 77 [21120/54000 (39%)] Loss: -744985.000000\n",
      "Train Epoch: 77 [22528/54000 (42%)] Loss: -889795.687500\n",
      "Train Epoch: 77 [23936/54000 (44%)] Loss: -787652.125000\n",
      "Train Epoch: 77 [25344/54000 (47%)] Loss: -889151.062500\n",
      "Train Epoch: 77 [26752/54000 (50%)] Loss: -885547.875000\n",
      "Train Epoch: 77 [28160/54000 (52%)] Loss: -825724.062500\n",
      "Train Epoch: 77 [29568/54000 (55%)] Loss: -757412.125000\n",
      "Train Epoch: 77 [30976/54000 (57%)] Loss: -810632.500000\n",
      "Train Epoch: 77 [32384/54000 (60%)] Loss: -811163.437500\n",
      "Train Epoch: 77 [33792/54000 (63%)] Loss: -775510.500000\n",
      "Train Epoch: 77 [35200/54000 (65%)] Loss: -764788.375000\n",
      "Train Epoch: 77 [36608/54000 (68%)] Loss: -895667.250000\n",
      "Train Epoch: 77 [38016/54000 (70%)] Loss: -887047.250000\n",
      "Train Epoch: 77 [39424/54000 (73%)] Loss: -886476.750000\n",
      "Train Epoch: 77 [40832/54000 (76%)] Loss: -833605.000000\n",
      "Train Epoch: 77 [42240/54000 (78%)] Loss: -785392.750000\n",
      "Train Epoch: 77 [43648/54000 (81%)] Loss: -765037.562500\n",
      "Train Epoch: 77 [45056/54000 (83%)] Loss: -836385.437500\n",
      "Train Epoch: 77 [46464/54000 (86%)] Loss: -839956.625000\n",
      "Train Epoch: 77 [47872/54000 (89%)] Loss: -787242.375000\n",
      "Train Epoch: 77 [49280/54000 (91%)] Loss: -814878.687500\n",
      "Train Epoch: 77 [50688/54000 (94%)] Loss: -755254.312500\n",
      "Train Epoch: 77 [52096/54000 (96%)] Loss: -768805.187500\n",
      "    epoch          : 77\n",
      "    loss           : -807557.6004784689\n",
      "    val_loss       : -808535.526105183\n",
      "Train Epoch: 78 [0/54000 (0%)] Loss: -775422.250000\n",
      "Train Epoch: 78 [1408/54000 (3%)] Loss: -823532.562500\n",
      "Train Epoch: 78 [2816/54000 (5%)] Loss: -819439.062500\n",
      "Train Epoch: 78 [4224/54000 (8%)] Loss: -786472.437500\n",
      "Train Epoch: 78 [5632/54000 (10%)] Loss: -841494.812500\n",
      "Train Epoch: 78 [7040/54000 (13%)] Loss: -801134.250000\n",
      "Train Epoch: 78 [8448/54000 (16%)] Loss: -773846.625000\n",
      "Train Epoch: 78 [9856/54000 (18%)] Loss: -762385.000000\n",
      "Train Epoch: 78 [11264/54000 (21%)] Loss: -791509.125000\n",
      "Train Epoch: 78 [12672/54000 (23%)] Loss: -837557.312500\n",
      "Train Epoch: 78 [14080/54000 (26%)] Loss: -795337.125000\n",
      "Train Epoch: 78 [15488/54000 (29%)] Loss: -786983.375000\n",
      "Train Epoch: 78 [16896/54000 (31%)] Loss: -753275.250000\n",
      "Train Epoch: 78 [18304/54000 (34%)] Loss: -889392.375000\n",
      "Train Epoch: 78 [19712/54000 (37%)] Loss: -824900.187500\n",
      "Train Epoch: 78 [21120/54000 (39%)] Loss: -784799.500000\n",
      "Train Epoch: 78 [22528/54000 (42%)] Loss: -787953.312500\n",
      "Train Epoch: 78 [23936/54000 (44%)] Loss: -869638.750000\n",
      "Train Epoch: 78 [25344/54000 (47%)] Loss: -784708.312500\n",
      "Train Epoch: 78 [26752/54000 (50%)] Loss: -782321.750000\n",
      "Train Epoch: 78 [28160/54000 (52%)] Loss: -843067.625000\n",
      "Train Epoch: 78 [29568/54000 (55%)] Loss: -761475.750000\n",
      "Train Epoch: 78 [30976/54000 (57%)] Loss: -782477.000000\n",
      "Train Epoch: 78 [32384/54000 (60%)] Loss: -814549.687500\n",
      "Train Epoch: 78 [33792/54000 (63%)] Loss: -818265.375000\n",
      "Train Epoch: 78 [35200/54000 (65%)] Loss: -785034.000000\n",
      "Train Epoch: 78 [36608/54000 (68%)] Loss: -786458.875000\n",
      "Train Epoch: 78 [38016/54000 (70%)] Loss: -815067.375000\n",
      "Train Epoch: 78 [39424/54000 (73%)] Loss: -775520.500000\n",
      "Train Epoch: 78 [40832/54000 (76%)] Loss: -762465.500000\n",
      "Train Epoch: 78 [42240/54000 (78%)] Loss: -798418.562500\n",
      "Train Epoch: 78 [43648/54000 (81%)] Loss: -760747.500000\n",
      "Train Epoch: 78 [45056/54000 (83%)] Loss: -797186.375000\n",
      "Train Epoch: 78 [46464/54000 (86%)] Loss: -790998.312500\n",
      "Train Epoch: 78 [47872/54000 (89%)] Loss: -801500.250000\n",
      "Train Epoch: 78 [49280/54000 (91%)] Loss: -806759.062500\n",
      "Train Epoch: 78 [50688/54000 (94%)] Loss: -773145.375000\n",
      "Train Epoch: 78 [52096/54000 (96%)] Loss: -849046.375000\n",
      "    epoch          : 78\n",
      "    loss           : -807393.8933911483\n",
      "    val_loss       : -806587.7852515244\n",
      "Train Epoch: 79 [0/54000 (0%)] Loss: -769235.875000\n",
      "Train Epoch: 79 [1408/54000 (3%)] Loss: -770345.375000\n",
      "Train Epoch: 79 [2816/54000 (5%)] Loss: -791323.937500\n",
      "Train Epoch: 79 [4224/54000 (8%)] Loss: -801910.437500\n",
      "Train Epoch: 79 [5632/54000 (10%)] Loss: -813014.125000\n",
      "Train Epoch: 79 [7040/54000 (13%)] Loss: -762175.437500\n",
      "Train Epoch: 79 [8448/54000 (16%)] Loss: -807087.250000\n",
      "Train Epoch: 79 [9856/54000 (18%)] Loss: -875425.625000\n",
      "Train Epoch: 79 [11264/54000 (21%)] Loss: -768183.375000\n",
      "Train Epoch: 79 [12672/54000 (23%)] Loss: -798188.250000\n",
      "Train Epoch: 79 [14080/54000 (26%)] Loss: -765914.250000\n",
      "Train Epoch: 79 [15488/54000 (29%)] Loss: -764711.125000\n",
      "Train Epoch: 79 [16896/54000 (31%)] Loss: -820281.125000\n",
      "Train Epoch: 79 [18304/54000 (34%)] Loss: -772297.937500\n",
      "Train Epoch: 79 [19712/54000 (37%)] Loss: -820909.625000\n",
      "Train Epoch: 79 [21120/54000 (39%)] Loss: -803456.250000\n",
      "Train Epoch: 79 [22528/54000 (42%)] Loss: -794387.625000\n",
      "Train Epoch: 79 [23936/54000 (44%)] Loss: -824272.312500\n",
      "Train Epoch: 79 [25344/54000 (47%)] Loss: -790703.437500\n",
      "Train Epoch: 79 [26752/54000 (50%)] Loss: -787879.000000\n",
      "Train Epoch: 79 [28160/54000 (52%)] Loss: -755363.437500\n",
      "Train Epoch: 79 [29568/54000 (55%)] Loss: -775311.687500\n",
      "Train Epoch: 79 [30976/54000 (57%)] Loss: -785866.937500\n",
      "Train Epoch: 79 [32384/54000 (60%)] Loss: -795253.625000\n",
      "Train Epoch: 79 [33792/54000 (63%)] Loss: -860901.187500\n",
      "Train Epoch: 79 [35200/54000 (65%)] Loss: -837196.312500\n",
      "Train Epoch: 79 [36608/54000 (68%)] Loss: -820394.750000\n",
      "Train Epoch: 79 [38016/54000 (70%)] Loss: -823513.375000\n",
      "Train Epoch: 79 [39424/54000 (73%)] Loss: -772677.562500\n",
      "Train Epoch: 79 [40832/54000 (76%)] Loss: -752377.812500\n",
      "Train Epoch: 79 [42240/54000 (78%)] Loss: -886438.000000\n",
      "Train Epoch: 79 [43648/54000 (81%)] Loss: -796091.000000\n",
      "Train Epoch: 79 [45056/54000 (83%)] Loss: -828935.000000\n",
      "Train Epoch: 79 [46464/54000 (86%)] Loss: -820968.062500\n",
      "Train Epoch: 79 [47872/54000 (89%)] Loss: -823004.812500\n",
      "Train Epoch: 79 [49280/54000 (91%)] Loss: -792170.625000\n",
      "Train Epoch: 79 [50688/54000 (94%)] Loss: -814661.250000\n",
      "Train Epoch: 79 [52096/54000 (96%)] Loss: -768943.125000\n",
      "    epoch          : 79\n",
      "    loss           : -807757.5154007177\n",
      "    val_loss       : -807412.3323170731\n",
      "Train Epoch: 80 [0/54000 (0%)] Loss: -765757.125000\n",
      "Train Epoch: 80 [1408/54000 (3%)] Loss: -814119.187500\n",
      "Train Epoch: 80 [2816/54000 (5%)] Loss: -773225.375000\n",
      "Train Epoch: 80 [4224/54000 (8%)] Loss: -793354.750000\n",
      "Train Epoch: 80 [5632/54000 (10%)] Loss: -785485.750000\n",
      "Train Epoch: 80 [7040/54000 (13%)] Loss: -790236.125000\n",
      "Train Epoch: 80 [8448/54000 (16%)] Loss: -766519.875000\n",
      "Train Epoch: 80 [9856/54000 (18%)] Loss: -799551.312500\n",
      "Train Epoch: 80 [11264/54000 (21%)] Loss: -834801.500000\n",
      "Train Epoch: 80 [12672/54000 (23%)] Loss: -818406.937500\n",
      "Train Epoch: 80 [14080/54000 (26%)] Loss: -827210.437500\n",
      "Train Epoch: 80 [15488/54000 (29%)] Loss: -815797.000000\n",
      "Train Epoch: 80 [16896/54000 (31%)] Loss: -830398.312500\n",
      "Train Epoch: 80 [18304/54000 (34%)] Loss: -815853.187500\n",
      "Train Epoch: 80 [19712/54000 (37%)] Loss: -815947.125000\n",
      "Train Epoch: 80 [21120/54000 (39%)] Loss: -788107.687500\n",
      "Train Epoch: 80 [22528/54000 (42%)] Loss: -782032.562500\n",
      "Train Epoch: 80 [23936/54000 (44%)] Loss: -796508.250000\n",
      "Train Epoch: 80 [25344/54000 (47%)] Loss: -817075.750000\n",
      "Train Epoch: 80 [26752/54000 (50%)] Loss: -846778.625000\n",
      "Train Epoch: 80 [28160/54000 (52%)] Loss: -759516.250000\n",
      "Train Epoch: 80 [29568/54000 (55%)] Loss: -810510.250000\n",
      "Train Epoch: 80 [30976/54000 (57%)] Loss: -814200.375000\n",
      "Train Epoch: 80 [32384/54000 (60%)] Loss: -756225.750000\n",
      "Train Epoch: 80 [33792/54000 (63%)] Loss: -756740.250000\n",
      "Train Epoch: 80 [35200/54000 (65%)] Loss: -822517.625000\n",
      "Train Epoch: 80 [36608/54000 (68%)] Loss: -888357.812500\n",
      "Train Epoch: 80 [38016/54000 (70%)] Loss: -808541.625000\n",
      "Train Epoch: 80 [39424/54000 (73%)] Loss: -803517.437500\n",
      "Train Epoch: 80 [40832/54000 (76%)] Loss: -799061.187500\n",
      "Train Epoch: 80 [42240/54000 (78%)] Loss: -844766.000000\n",
      "Train Epoch: 80 [43648/54000 (81%)] Loss: -789053.687500\n",
      "Train Epoch: 80 [45056/54000 (83%)] Loss: -841072.125000\n",
      "Train Epoch: 80 [46464/54000 (86%)] Loss: -792843.500000\n",
      "Train Epoch: 80 [47872/54000 (89%)] Loss: -807810.375000\n",
      "Train Epoch: 80 [49280/54000 (91%)] Loss: -822898.812500\n",
      "Train Epoch: 80 [50688/54000 (94%)] Loss: -823317.812500\n",
      "Train Epoch: 80 [52096/54000 (96%)] Loss: -827699.000000\n",
      "    epoch          : 80\n",
      "    loss           : -807666.0947966507\n",
      "    val_loss       : -807707.8506097561\n",
      "Saving checkpoint: saved/models/Mnist_VaeCategory/0422_221614/checkpoint-epoch80.pth ...\n",
      "Train Epoch: 81 [0/54000 (0%)] Loss: -766938.562500\n",
      "Train Epoch: 81 [1408/54000 (3%)] Loss: -828490.750000\n",
      "Train Epoch: 81 [2816/54000 (5%)] Loss: -811108.625000\n",
      "Train Epoch: 81 [4224/54000 (8%)] Loss: -783219.812500\n",
      "Train Epoch: 81 [5632/54000 (10%)] Loss: -790078.187500\n",
      "Train Epoch: 81 [7040/54000 (13%)] Loss: -816020.500000\n",
      "Train Epoch: 81 [8448/54000 (16%)] Loss: -836695.750000\n",
      "Train Epoch: 81 [9856/54000 (18%)] Loss: -839947.437500\n",
      "Train Epoch: 81 [11264/54000 (21%)] Loss: -788162.000000\n",
      "Train Epoch: 81 [12672/54000 (23%)] Loss: -895781.562500\n",
      "Train Epoch: 81 [14080/54000 (26%)] Loss: -772371.000000\n",
      "Train Epoch: 81 [15488/54000 (29%)] Loss: -895079.562500\n",
      "Train Epoch: 81 [16896/54000 (31%)] Loss: -815172.000000\n",
      "Train Epoch: 81 [18304/54000 (34%)] Loss: -810721.187500\n",
      "Train Epoch: 81 [19712/54000 (37%)] Loss: -795612.562500\n",
      "Train Epoch: 81 [21120/54000 (39%)] Loss: -856394.312500\n",
      "Train Epoch: 81 [22528/54000 (42%)] Loss: -795379.937500\n",
      "Train Epoch: 81 [23936/54000 (44%)] Loss: -769712.250000\n",
      "Train Epoch: 81 [25344/54000 (47%)] Loss: -795384.750000\n",
      "Train Epoch: 81 [26752/54000 (50%)] Loss: -816050.000000\n",
      "Train Epoch: 81 [28160/54000 (52%)] Loss: -762881.125000\n",
      "Train Epoch: 81 [29568/54000 (55%)] Loss: -807384.250000\n",
      "Train Epoch: 81 [30976/54000 (57%)] Loss: -789935.625000\n",
      "Train Epoch: 81 [32384/54000 (60%)] Loss: -826766.062500\n",
      "Train Epoch: 81 [33792/54000 (63%)] Loss: -789561.312500\n",
      "Train Epoch: 81 [35200/54000 (65%)] Loss: -795398.250000\n",
      "Train Epoch: 81 [36608/54000 (68%)] Loss: -822186.250000\n",
      "Train Epoch: 81 [38016/54000 (70%)] Loss: -802186.437500\n",
      "Train Epoch: 81 [39424/54000 (73%)] Loss: -769517.562500\n",
      "Train Epoch: 81 [40832/54000 (76%)] Loss: -756697.375000\n",
      "Train Epoch: 81 [42240/54000 (78%)] Loss: -787442.312500\n",
      "Train Epoch: 81 [43648/54000 (81%)] Loss: -800356.625000\n",
      "Train Epoch: 81 [45056/54000 (83%)] Loss: -797240.625000\n",
      "Train Epoch: 81 [46464/54000 (86%)] Loss: -799665.562500\n",
      "Train Epoch: 81 [47872/54000 (89%)] Loss: -789734.625000\n",
      "Train Epoch: 81 [49280/54000 (91%)] Loss: -794307.375000\n",
      "Train Epoch: 81 [50688/54000 (94%)] Loss: -818933.562500\n",
      "Train Epoch: 81 [52096/54000 (96%)] Loss: -817695.187500\n",
      "    epoch          : 81\n",
      "    loss           : -808019.75\n",
      "    val_loss       : -808494.191882622\n",
      "Train Epoch: 82 [0/54000 (0%)] Loss: -895140.500000\n",
      "Train Epoch: 82 [1408/54000 (3%)] Loss: -830433.250000\n",
      "Train Epoch: 82 [2816/54000 (5%)] Loss: -783041.125000\n",
      "Train Epoch: 82 [4224/54000 (8%)] Loss: -801705.562500\n",
      "Train Epoch: 82 [5632/54000 (10%)] Loss: -792109.500000\n",
      "Train Epoch: 82 [7040/54000 (13%)] Loss: -815955.687500\n",
      "Train Epoch: 82 [8448/54000 (16%)] Loss: -824899.375000\n",
      "Train Epoch: 82 [9856/54000 (18%)] Loss: -806033.750000\n",
      "Train Epoch: 82 [11264/54000 (21%)] Loss: -811726.250000\n",
      "Train Epoch: 82 [12672/54000 (23%)] Loss: -813066.812500\n",
      "Train Epoch: 82 [14080/54000 (26%)] Loss: -806048.000000\n",
      "Train Epoch: 82 [15488/54000 (29%)] Loss: -786929.562500\n",
      "Train Epoch: 82 [16896/54000 (31%)] Loss: -899172.750000\n",
      "Train Epoch: 82 [18304/54000 (34%)] Loss: -788241.062500\n",
      "Train Epoch: 82 [19712/54000 (37%)] Loss: -884041.437500\n",
      "Train Epoch: 82 [21120/54000 (39%)] Loss: -758325.625000\n",
      "Train Epoch: 82 [22528/54000 (42%)] Loss: -823499.562500\n",
      "Train Epoch: 82 [23936/54000 (44%)] Loss: -803362.875000\n",
      "Train Epoch: 82 [25344/54000 (47%)] Loss: -775441.000000\n",
      "Train Epoch: 82 [26752/54000 (50%)] Loss: -792346.750000\n",
      "Train Epoch: 82 [28160/54000 (52%)] Loss: -787022.875000\n",
      "Train Epoch: 82 [29568/54000 (55%)] Loss: -794328.250000\n",
      "Train Epoch: 82 [30976/54000 (57%)] Loss: -819078.000000\n",
      "Train Epoch: 82 [32384/54000 (60%)] Loss: -767046.812500\n",
      "Train Epoch: 82 [33792/54000 (63%)] Loss: -774858.125000\n",
      "Train Epoch: 82 [35200/54000 (65%)] Loss: -805857.312500\n",
      "Train Epoch: 82 [36608/54000 (68%)] Loss: -895685.312500\n",
      "Train Epoch: 82 [38016/54000 (70%)] Loss: -876575.062500\n",
      "Train Epoch: 82 [39424/54000 (73%)] Loss: -820781.375000\n",
      "Train Epoch: 82 [40832/54000 (76%)] Loss: -811393.875000\n",
      "Train Epoch: 82 [42240/54000 (78%)] Loss: -774285.437500\n",
      "Train Epoch: 82 [43648/54000 (81%)] Loss: -766124.937500\n",
      "Train Epoch: 82 [45056/54000 (83%)] Loss: -805121.812500\n",
      "Train Epoch: 82 [46464/54000 (86%)] Loss: -791514.687500\n",
      "Train Epoch: 82 [47872/54000 (89%)] Loss: -797043.250000\n",
      "Train Epoch: 82 [49280/54000 (91%)] Loss: -811805.500000\n",
      "Train Epoch: 82 [50688/54000 (94%)] Loss: -793895.625000\n",
      "Train Epoch: 82 [52096/54000 (96%)] Loss: -846711.500000\n",
      "    epoch          : 82\n",
      "    loss           : -808187.5930023923\n",
      "    val_loss       : -807493.7850609756\n",
      "Train Epoch: 83 [0/54000 (0%)] Loss: -757360.687500\n",
      "Train Epoch: 83 [1408/54000 (3%)] Loss: -761409.062500\n",
      "Train Epoch: 83 [2816/54000 (5%)] Loss: -757855.687500\n",
      "Train Epoch: 83 [4224/54000 (8%)] Loss: -772054.250000\n",
      "Train Epoch: 83 [5632/54000 (10%)] Loss: -778928.500000\n",
      "Train Epoch: 83 [7040/54000 (13%)] Loss: -784385.187500\n",
      "Train Epoch: 83 [8448/54000 (16%)] Loss: -759518.875000\n",
      "Train Epoch: 83 [9856/54000 (18%)] Loss: -766658.500000\n",
      "Train Epoch: 83 [11264/54000 (21%)] Loss: -794296.125000\n",
      "Train Epoch: 83 [12672/54000 (23%)] Loss: -792092.937500\n",
      "Train Epoch: 83 [14080/54000 (26%)] Loss: -773521.000000\n",
      "Train Epoch: 83 [15488/54000 (29%)] Loss: -754490.312500\n",
      "Train Epoch: 83 [16896/54000 (31%)] Loss: -811557.625000\n",
      "Train Epoch: 83 [18304/54000 (34%)] Loss: -895729.250000\n",
      "Train Epoch: 83 [19712/54000 (37%)] Loss: -770012.812500\n",
      "Train Epoch: 83 [21120/54000 (39%)] Loss: -761675.937500\n",
      "Train Epoch: 83 [22528/54000 (42%)] Loss: -799323.375000\n",
      "Train Epoch: 83 [23936/54000 (44%)] Loss: -868015.937500\n",
      "Train Epoch: 83 [25344/54000 (47%)] Loss: -795468.125000\n",
      "Train Epoch: 83 [26752/54000 (50%)] Loss: -816107.812500\n",
      "Train Epoch: 83 [28160/54000 (52%)] Loss: -761239.500000\n",
      "Train Epoch: 83 [29568/54000 (55%)] Loss: -799261.187500\n",
      "Train Epoch: 83 [30976/54000 (57%)] Loss: -809098.562500\n",
      "Train Epoch: 83 [32384/54000 (60%)] Loss: -766416.375000\n",
      "Train Epoch: 83 [33792/54000 (63%)] Loss: -758350.062500\n",
      "Train Epoch: 83 [35200/54000 (65%)] Loss: -833489.625000\n",
      "Train Epoch: 83 [36608/54000 (68%)] Loss: -889500.750000\n",
      "Train Epoch: 83 [38016/54000 (70%)] Loss: -839756.750000\n",
      "Train Epoch: 83 [39424/54000 (73%)] Loss: -762352.312500\n",
      "Train Epoch: 83 [40832/54000 (76%)] Loss: -877096.750000\n",
      "Train Epoch: 83 [42240/54000 (78%)] Loss: -839065.375000\n",
      "Train Epoch: 83 [43648/54000 (81%)] Loss: -889619.812500\n",
      "Train Epoch: 83 [45056/54000 (83%)] Loss: -759069.937500\n",
      "Train Epoch: 83 [46464/54000 (86%)] Loss: -815136.062500\n",
      "Train Epoch: 83 [47872/54000 (89%)] Loss: -819296.375000\n",
      "Train Epoch: 83 [49280/54000 (91%)] Loss: -787007.625000\n",
      "Train Epoch: 83 [50688/54000 (94%)] Loss: -789971.375000\n",
      "Train Epoch: 83 [52096/54000 (96%)] Loss: -771321.750000\n",
      "    epoch          : 83\n",
      "    loss           : -807762.0909090909\n",
      "    val_loss       : -807000.3117378049\n",
      "Train Epoch: 84 [0/54000 (0%)] Loss: -766753.312500\n",
      "Train Epoch: 84 [1408/54000 (3%)] Loss: -763687.250000\n",
      "Train Epoch: 84 [2816/54000 (5%)] Loss: -837473.562500\n",
      "Train Epoch: 84 [4224/54000 (8%)] Loss: -790055.875000\n",
      "Train Epoch: 84 [5632/54000 (10%)] Loss: -806529.500000\n",
      "Train Epoch: 84 [7040/54000 (13%)] Loss: -817411.875000\n",
      "Train Epoch: 84 [8448/54000 (16%)] Loss: -818700.937500\n",
      "Train Epoch: 84 [9856/54000 (18%)] Loss: -815576.062500\n",
      "Train Epoch: 84 [11264/54000 (21%)] Loss: -796584.000000\n",
      "Train Epoch: 84 [12672/54000 (23%)] Loss: -777828.812500\n",
      "Train Epoch: 84 [14080/54000 (26%)] Loss: -847573.625000\n",
      "Train Epoch: 84 [15488/54000 (29%)] Loss: -840313.687500\n",
      "Train Epoch: 84 [16896/54000 (31%)] Loss: -759391.500000\n",
      "Train Epoch: 84 [18304/54000 (34%)] Loss: -759867.875000\n",
      "Train Epoch: 84 [19712/54000 (37%)] Loss: -891970.812500\n",
      "Train Epoch: 84 [21120/54000 (39%)] Loss: -763258.687500\n",
      "Train Epoch: 84 [22528/54000 (42%)] Loss: -824110.187500\n",
      "Train Epoch: 84 [23936/54000 (44%)] Loss: -888248.250000\n",
      "Train Epoch: 84 [25344/54000 (47%)] Loss: -802851.875000\n",
      "Train Epoch: 84 [26752/54000 (50%)] Loss: -788159.562500\n",
      "Train Epoch: 84 [28160/54000 (52%)] Loss: -835915.500000\n",
      "Train Epoch: 84 [29568/54000 (55%)] Loss: -785835.687500\n",
      "Train Epoch: 84 [30976/54000 (57%)] Loss: -803138.000000\n",
      "Train Epoch: 84 [32384/54000 (60%)] Loss: -770594.312500\n",
      "Train Epoch: 84 [33792/54000 (63%)] Loss: -797266.250000\n",
      "Train Epoch: 84 [35200/54000 (65%)] Loss: -823921.062500\n",
      "Train Epoch: 84 [36608/54000 (68%)] Loss: -826986.062500\n",
      "Train Epoch: 84 [38016/54000 (70%)] Loss: -813413.125000\n",
      "Train Epoch: 84 [39424/54000 (73%)] Loss: -817853.250000\n",
      "Train Epoch: 84 [40832/54000 (76%)] Loss: -770577.375000\n",
      "Train Epoch: 84 [42240/54000 (78%)] Loss: -872860.750000\n",
      "Train Epoch: 84 [43648/54000 (81%)] Loss: -806417.062500\n",
      "Train Epoch: 84 [45056/54000 (83%)] Loss: -883880.750000\n",
      "Train Epoch: 84 [46464/54000 (86%)] Loss: -793293.687500\n",
      "Train Epoch: 84 [47872/54000 (89%)] Loss: -791366.187500\n",
      "Train Epoch: 84 [49280/54000 (91%)] Loss: -817061.500000\n",
      "Train Epoch: 84 [50688/54000 (94%)] Loss: -825785.125000\n",
      "Train Epoch: 84 [52096/54000 (96%)] Loss: -817728.312500\n",
      "    epoch          : 84\n",
      "    loss           : -807933.684958134\n",
      "    val_loss       : -807713.441882622\n",
      "Train Epoch: 85 [0/54000 (0%)] Loss: -807756.125000\n",
      "Train Epoch: 85 [1408/54000 (3%)] Loss: -821415.125000\n",
      "Train Epoch: 85 [2816/54000 (5%)] Loss: -773752.375000\n",
      "Train Epoch: 85 [4224/54000 (8%)] Loss: -800384.062500\n",
      "Train Epoch: 85 [5632/54000 (10%)] Loss: -820262.375000\n",
      "Train Epoch: 85 [7040/54000 (13%)] Loss: -815548.750000\n",
      "Train Epoch: 85 [8448/54000 (16%)] Loss: -827623.000000\n",
      "Train Epoch: 85 [9856/54000 (18%)] Loss: -802346.812500\n",
      "Train Epoch: 85 [11264/54000 (21%)] Loss: -804461.125000\n",
      "Train Epoch: 85 [12672/54000 (23%)] Loss: -800275.750000\n",
      "Train Epoch: 85 [14080/54000 (26%)] Loss: -839813.125000\n",
      "Train Epoch: 85 [15488/54000 (29%)] Loss: -788367.875000\n",
      "Train Epoch: 85 [16896/54000 (31%)] Loss: -770438.500000\n",
      "Train Epoch: 85 [18304/54000 (34%)] Loss: -826283.500000\n",
      "Train Epoch: 85 [19712/54000 (37%)] Loss: -825585.875000\n",
      "Train Epoch: 85 [21120/54000 (39%)] Loss: -789599.437500\n",
      "Train Epoch: 85 [22528/54000 (42%)] Loss: -813804.562500\n",
      "Train Epoch: 85 [23936/54000 (44%)] Loss: -817767.125000\n",
      "Train Epoch: 85 [25344/54000 (47%)] Loss: -827147.937500\n",
      "Train Epoch: 85 [26752/54000 (50%)] Loss: -816732.937500\n",
      "Train Epoch: 85 [28160/54000 (52%)] Loss: -826977.437500\n",
      "Train Epoch: 85 [29568/54000 (55%)] Loss: -865758.000000\n",
      "Train Epoch: 85 [30976/54000 (57%)] Loss: -769658.687500\n",
      "Train Epoch: 85 [32384/54000 (60%)] Loss: -803497.500000\n",
      "Train Epoch: 85 [33792/54000 (63%)] Loss: -789244.125000\n",
      "Train Epoch: 85 [35200/54000 (65%)] Loss: -822346.750000\n",
      "Train Epoch: 85 [36608/54000 (68%)] Loss: -825207.375000\n",
      "Train Epoch: 85 [38016/54000 (70%)] Loss: -826718.562500\n",
      "Train Epoch: 85 [39424/54000 (73%)] Loss: -832571.000000\n",
      "Train Epoch: 85 [40832/54000 (76%)] Loss: -763591.937500\n",
      "Train Epoch: 85 [42240/54000 (78%)] Loss: -787304.875000\n",
      "Train Epoch: 85 [43648/54000 (81%)] Loss: -765194.625000\n",
      "Train Epoch: 85 [45056/54000 (83%)] Loss: -800089.687500\n",
      "Train Epoch: 85 [46464/54000 (86%)] Loss: -816892.312500\n",
      "Train Epoch: 85 [47872/54000 (89%)] Loss: -821371.250000\n",
      "Train Epoch: 85 [49280/54000 (91%)] Loss: -802148.750000\n",
      "Train Epoch: 85 [50688/54000 (94%)] Loss: -754831.187500\n",
      "Train Epoch: 85 [52096/54000 (96%)] Loss: -777329.937500\n",
      "    epoch          : 85\n",
      "    loss           : -807820.9052033493\n",
      "    val_loss       : -808084.2399009146\n",
      "Saving checkpoint: saved/models/Mnist_VaeCategory/0422_221614/checkpoint-epoch85.pth ...\n",
      "Train Epoch: 86 [0/54000 (0%)] Loss: -828800.250000\n",
      "Train Epoch: 86 [1408/54000 (3%)] Loss: -770576.437500\n",
      "Train Epoch: 86 [2816/54000 (5%)] Loss: -891279.125000\n",
      "Train Epoch: 86 [4224/54000 (8%)] Loss: -883076.250000\n",
      "Train Epoch: 86 [5632/54000 (10%)] Loss: -790119.312500\n",
      "Train Epoch: 86 [7040/54000 (13%)] Loss: -836776.125000\n",
      "Train Epoch: 86 [8448/54000 (16%)] Loss: -794764.375000\n",
      "Train Epoch: 86 [9856/54000 (18%)] Loss: -803580.250000\n",
      "Train Epoch: 86 [11264/54000 (21%)] Loss: -824035.562500\n",
      "Train Epoch: 86 [12672/54000 (23%)] Loss: -835577.500000\n",
      "Train Epoch: 86 [14080/54000 (26%)] Loss: -815490.500000\n",
      "Train Epoch: 86 [15488/54000 (29%)] Loss: -776603.250000\n",
      "Train Epoch: 86 [16896/54000 (31%)] Loss: -844766.625000\n",
      "Train Epoch: 86 [18304/54000 (34%)] Loss: -876111.500000\n",
      "Train Epoch: 86 [19712/54000 (37%)] Loss: -893430.750000\n",
      "Train Epoch: 86 [21120/54000 (39%)] Loss: -820878.937500\n",
      "Train Epoch: 86 [22528/54000 (42%)] Loss: -794272.625000\n",
      "Train Epoch: 86 [23936/54000 (44%)] Loss: -788495.375000\n",
      "Train Epoch: 86 [25344/54000 (47%)] Loss: -803741.750000\n",
      "Train Epoch: 86 [26752/54000 (50%)] Loss: -789015.687500\n",
      "Train Epoch: 86 [28160/54000 (52%)] Loss: -883143.625000\n",
      "Train Epoch: 86 [29568/54000 (55%)] Loss: -822242.250000\n",
      "Train Epoch: 86 [30976/54000 (57%)] Loss: -757955.500000\n",
      "Train Epoch: 86 [32384/54000 (60%)] Loss: -810493.562500\n",
      "Train Epoch: 86 [33792/54000 (63%)] Loss: -778005.750000\n",
      "Train Epoch: 86 [35200/54000 (65%)] Loss: -840429.437500\n",
      "Train Epoch: 86 [36608/54000 (68%)] Loss: -817781.625000\n",
      "Train Epoch: 86 [38016/54000 (70%)] Loss: -762441.750000\n",
      "Train Epoch: 86 [39424/54000 (73%)] Loss: -894149.875000\n",
      "Train Epoch: 86 [40832/54000 (76%)] Loss: -783897.687500\n",
      "Train Epoch: 86 [42240/54000 (78%)] Loss: -780743.250000\n",
      "Train Epoch: 86 [43648/54000 (81%)] Loss: -752039.437500\n",
      "Train Epoch: 86 [45056/54000 (83%)] Loss: -832091.875000\n",
      "Train Epoch: 86 [46464/54000 (86%)] Loss: -817956.687500\n",
      "Train Epoch: 86 [47872/54000 (89%)] Loss: -817813.500000\n",
      "Train Epoch: 86 [49280/54000 (91%)] Loss: -831316.875000\n",
      "Train Epoch: 86 [50688/54000 (94%)] Loss: -838606.250000\n",
      "Train Epoch: 86 [52096/54000 (96%)] Loss: -756221.750000\n",
      "    epoch          : 86\n",
      "    loss           : -808283.5249700957\n",
      "    val_loss       : -808012.3136432926\n",
      "Train Epoch: 87 [0/54000 (0%)] Loss: -763464.000000\n",
      "Train Epoch: 87 [1408/54000 (3%)] Loss: -793972.937500\n",
      "Train Epoch: 87 [2816/54000 (5%)] Loss: -763771.437500\n",
      "Train Epoch: 87 [4224/54000 (8%)] Loss: -799629.187500\n",
      "Train Epoch: 87 [5632/54000 (10%)] Loss: -883153.875000\n",
      "Train Epoch: 87 [7040/54000 (13%)] Loss: -762543.187500\n",
      "Train Epoch: 87 [8448/54000 (16%)] Loss: -809728.000000\n",
      "Train Epoch: 87 [9856/54000 (18%)] Loss: -843407.437500\n",
      "Train Epoch: 87 [11264/54000 (21%)] Loss: -847129.437500\n",
      "Train Epoch: 87 [12672/54000 (23%)] Loss: -764326.000000\n",
      "Train Epoch: 87 [14080/54000 (26%)] Loss: -825526.375000\n",
      "Train Epoch: 87 [15488/54000 (29%)] Loss: -824174.937500\n",
      "Train Epoch: 87 [16896/54000 (31%)] Loss: -793049.500000\n",
      "Train Epoch: 87 [18304/54000 (34%)] Loss: -795637.687500\n",
      "Train Epoch: 87 [19712/54000 (37%)] Loss: -845050.937500\n",
      "Train Epoch: 87 [21120/54000 (39%)] Loss: -793380.562500\n",
      "Train Epoch: 87 [22528/54000 (42%)] Loss: -856233.750000\n",
      "Train Epoch: 87 [23936/54000 (44%)] Loss: -829478.062500\n",
      "Train Epoch: 87 [25344/54000 (47%)] Loss: -780489.875000\n",
      "Train Epoch: 87 [26752/54000 (50%)] Loss: -791000.937500\n",
      "Train Epoch: 87 [28160/54000 (52%)] Loss: -768125.562500\n",
      "Train Epoch: 87 [29568/54000 (55%)] Loss: -814533.437500\n",
      "Train Epoch: 87 [30976/54000 (57%)] Loss: -792711.625000\n",
      "Train Epoch: 87 [32384/54000 (60%)] Loss: -764494.000000\n",
      "Train Epoch: 87 [33792/54000 (63%)] Loss: -769779.062500\n",
      "Train Epoch: 87 [35200/54000 (65%)] Loss: -777089.250000\n",
      "Train Epoch: 87 [36608/54000 (68%)] Loss: -788034.125000\n",
      "Train Epoch: 87 [38016/54000 (70%)] Loss: -769254.437500\n",
      "Train Epoch: 87 [39424/54000 (73%)] Loss: -838515.312500\n",
      "Train Epoch: 87 [40832/54000 (76%)] Loss: -804767.000000\n",
      "Train Epoch: 87 [42240/54000 (78%)] Loss: -773656.812500\n",
      "Train Epoch: 87 [43648/54000 (81%)] Loss: -781877.250000\n",
      "Train Epoch: 87 [45056/54000 (83%)] Loss: -817755.375000\n",
      "Train Epoch: 87 [46464/54000 (86%)] Loss: -792601.062500\n",
      "Train Epoch: 87 [47872/54000 (89%)] Loss: -831954.500000\n",
      "Train Epoch: 87 [49280/54000 (91%)] Loss: -837699.187500\n",
      "Train Epoch: 87 [50688/54000 (94%)] Loss: -827753.062500\n",
      "Train Epoch: 87 [52096/54000 (96%)] Loss: -812799.937500\n",
      "    epoch          : 87\n",
      "    loss           : -808033.2265251196\n",
      "    val_loss       : -807434.329839939\n",
      "Train Epoch: 88 [0/54000 (0%)] Loss: -758937.125000\n",
      "Train Epoch: 88 [1408/54000 (3%)] Loss: -762540.375000\n",
      "Train Epoch: 88 [2816/54000 (5%)] Loss: -777149.375000\n",
      "Train Epoch: 88 [4224/54000 (8%)] Loss: -903865.125000\n",
      "Train Epoch: 88 [5632/54000 (10%)] Loss: -879856.812500\n",
      "Train Epoch: 88 [7040/54000 (13%)] Loss: -876256.687500\n",
      "Train Epoch: 88 [8448/54000 (16%)] Loss: -837891.000000\n",
      "Train Epoch: 88 [9856/54000 (18%)] Loss: -838181.625000\n",
      "Train Epoch: 88 [11264/54000 (21%)] Loss: -848715.000000\n",
      "Train Epoch: 88 [12672/54000 (23%)] Loss: -882512.000000\n",
      "Train Epoch: 88 [14080/54000 (26%)] Loss: -772870.812500\n",
      "Train Epoch: 88 [15488/54000 (29%)] Loss: -795205.187500\n",
      "Train Epoch: 88 [16896/54000 (31%)] Loss: -820705.500000\n",
      "Train Epoch: 88 [18304/54000 (34%)] Loss: -762664.875000\n",
      "Train Epoch: 88 [19712/54000 (37%)] Loss: -822647.625000\n",
      "Train Epoch: 88 [21120/54000 (39%)] Loss: -883784.625000\n",
      "Train Epoch: 88 [22528/54000 (42%)] Loss: -772312.375000\n",
      "Train Epoch: 88 [23936/54000 (44%)] Loss: -810771.625000\n",
      "Train Epoch: 88 [25344/54000 (47%)] Loss: -802211.500000\n",
      "Train Epoch: 88 [26752/54000 (50%)] Loss: -786312.562500\n",
      "Train Epoch: 88 [28160/54000 (52%)] Loss: -803116.437500\n",
      "Train Epoch: 88 [29568/54000 (55%)] Loss: -897544.812500\n",
      "Train Epoch: 88 [30976/54000 (57%)] Loss: -885211.812500\n",
      "Train Epoch: 88 [32384/54000 (60%)] Loss: -814897.250000\n",
      "Train Epoch: 88 [33792/54000 (63%)] Loss: -888286.687500\n",
      "Train Epoch: 88 [35200/54000 (65%)] Loss: -771264.312500\n",
      "Train Epoch: 88 [36608/54000 (68%)] Loss: -821591.000000\n",
      "Train Epoch: 88 [38016/54000 (70%)] Loss: -813858.062500\n",
      "Train Epoch: 88 [39424/54000 (73%)] Loss: -757841.875000\n",
      "Train Epoch: 88 [40832/54000 (76%)] Loss: -786312.812500\n",
      "Train Epoch: 88 [42240/54000 (78%)] Loss: -787164.375000\n",
      "Train Epoch: 88 [43648/54000 (81%)] Loss: -784578.125000\n",
      "Train Epoch: 88 [45056/54000 (83%)] Loss: -829210.750000\n",
      "Train Epoch: 88 [46464/54000 (86%)] Loss: -821564.687500\n",
      "Train Epoch: 88 [47872/54000 (89%)] Loss: -811287.750000\n",
      "Train Epoch: 88 [49280/54000 (91%)] Loss: -816281.187500\n",
      "Train Epoch: 88 [50688/54000 (94%)] Loss: -776936.125000\n",
      "Train Epoch: 88 [52096/54000 (96%)] Loss: -825316.562500\n",
      "    epoch          : 88\n",
      "    loss           : -808310.2556818182\n",
      "    val_loss       : -808417.2884908536\n",
      "Train Epoch: 89 [0/54000 (0%)] Loss: -769042.062500\n",
      "Train Epoch: 89 [1408/54000 (3%)] Loss: -763110.875000\n",
      "Train Epoch: 89 [2816/54000 (5%)] Loss: -764171.250000\n",
      "Train Epoch: 89 [4224/54000 (8%)] Loss: -787336.125000\n",
      "Train Epoch: 89 [5632/54000 (10%)] Loss: -842597.937500\n",
      "Train Epoch: 89 [7040/54000 (13%)] Loss: -798902.812500\n",
      "Train Epoch: 89 [8448/54000 (16%)] Loss: -814890.500000\n",
      "Train Epoch: 89 [9856/54000 (18%)] Loss: -820275.625000\n",
      "Train Epoch: 89 [11264/54000 (21%)] Loss: -888926.625000\n",
      "Train Epoch: 89 [12672/54000 (23%)] Loss: -879602.125000\n",
      "Train Epoch: 89 [14080/54000 (26%)] Loss: -770188.250000\n",
      "Train Epoch: 89 [15488/54000 (29%)] Loss: -820213.250000\n",
      "Train Epoch: 89 [16896/54000 (31%)] Loss: -793013.750000\n",
      "Train Epoch: 89 [18304/54000 (34%)] Loss: -804794.437500\n",
      "Train Epoch: 89 [19712/54000 (37%)] Loss: -829154.937500\n",
      "Train Epoch: 89 [21120/54000 (39%)] Loss: -884492.875000\n",
      "Train Epoch: 89 [22528/54000 (42%)] Loss: -886395.250000\n",
      "Train Epoch: 89 [23936/54000 (44%)] Loss: -768841.000000\n",
      "Train Epoch: 89 [25344/54000 (47%)] Loss: -846378.375000\n",
      "Train Epoch: 89 [26752/54000 (50%)] Loss: -831235.125000\n",
      "Train Epoch: 89 [28160/54000 (52%)] Loss: -800416.312500\n",
      "Train Epoch: 89 [29568/54000 (55%)] Loss: -800224.750000\n",
      "Train Epoch: 89 [30976/54000 (57%)] Loss: -775667.875000\n",
      "Train Epoch: 89 [32384/54000 (60%)] Loss: -793647.062500\n",
      "Train Epoch: 89 [33792/54000 (63%)] Loss: -793725.562500\n",
      "Train Epoch: 89 [35200/54000 (65%)] Loss: -825512.125000\n",
      "Train Epoch: 89 [36608/54000 (68%)] Loss: -775469.375000\n",
      "Train Epoch: 89 [38016/54000 (70%)] Loss: -824590.562500\n",
      "Train Epoch: 89 [39424/54000 (73%)] Loss: -766366.375000\n",
      "Train Epoch: 89 [40832/54000 (76%)] Loss: -893462.375000\n",
      "Train Epoch: 89 [42240/54000 (78%)] Loss: -800455.312500\n",
      "Train Epoch: 89 [43648/54000 (81%)] Loss: -789686.875000\n",
      "Train Epoch: 89 [45056/54000 (83%)] Loss: -806242.250000\n",
      "Train Epoch: 89 [46464/54000 (86%)] Loss: -794909.062500\n",
      "Train Epoch: 89 [47872/54000 (89%)] Loss: -838654.375000\n",
      "Train Epoch: 89 [49280/54000 (91%)] Loss: -840301.687500\n",
      "Train Epoch: 89 [50688/54000 (94%)] Loss: -764292.000000\n",
      "Train Epoch: 89 [52096/54000 (96%)] Loss: -823079.062500\n",
      "    epoch          : 89\n",
      "    loss           : -808288.8125\n",
      "    val_loss       : -808713.5562118902\n",
      "Train Epoch: 90 [0/54000 (0%)] Loss: -823229.687500\n",
      "Train Epoch: 90 [1408/54000 (3%)] Loss: -819187.250000\n",
      "Train Epoch: 90 [2816/54000 (5%)] Loss: -897419.875000\n",
      "Train Epoch: 90 [4224/54000 (8%)] Loss: -819612.812500\n",
      "Train Epoch: 90 [5632/54000 (10%)] Loss: -774357.625000\n",
      "Train Epoch: 90 [7040/54000 (13%)] Loss: -763655.062500\n",
      "Train Epoch: 90 [8448/54000 (16%)] Loss: -815310.750000\n",
      "Train Epoch: 90 [9856/54000 (18%)] Loss: -813133.875000\n",
      "Train Epoch: 90 [11264/54000 (21%)] Loss: -831277.437500\n",
      "Train Epoch: 90 [12672/54000 (23%)] Loss: -763538.562500\n",
      "Train Epoch: 90 [14080/54000 (26%)] Loss: -825735.062500\n",
      "Train Epoch: 90 [15488/54000 (29%)] Loss: -845147.937500\n",
      "Train Epoch: 90 [16896/54000 (31%)] Loss: -837180.812500\n",
      "Train Epoch: 90 [18304/54000 (34%)] Loss: -797764.812500\n",
      "Train Epoch: 90 [19712/54000 (37%)] Loss: -804595.562500\n",
      "Train Epoch: 90 [21120/54000 (39%)] Loss: -795078.187500\n",
      "Train Epoch: 90 [22528/54000 (42%)] Loss: -761005.875000\n",
      "Train Epoch: 90 [23936/54000 (44%)] Loss: -891824.625000\n",
      "Train Epoch: 90 [25344/54000 (47%)] Loss: -775140.687500\n",
      "Train Epoch: 90 [26752/54000 (50%)] Loss: -817772.375000\n",
      "Train Epoch: 90 [28160/54000 (52%)] Loss: -883888.437500\n",
      "Train Epoch: 90 [29568/54000 (55%)] Loss: -759027.375000\n",
      "Train Epoch: 90 [30976/54000 (57%)] Loss: -840025.250000\n",
      "Train Epoch: 90 [32384/54000 (60%)] Loss: -779069.375000\n",
      "Train Epoch: 90 [33792/54000 (63%)] Loss: -838591.312500\n",
      "Train Epoch: 90 [35200/54000 (65%)] Loss: -791068.062500\n",
      "Train Epoch: 90 [36608/54000 (68%)] Loss: -874867.125000\n",
      "Train Epoch: 90 [38016/54000 (70%)] Loss: -763040.500000\n",
      "Train Epoch: 90 [39424/54000 (73%)] Loss: -813212.375000\n",
      "Train Epoch: 90 [40832/54000 (76%)] Loss: -800563.625000\n",
      "Train Epoch: 90 [42240/54000 (78%)] Loss: -820086.000000\n",
      "Train Epoch: 90 [43648/54000 (81%)] Loss: -767367.375000\n",
      "Train Epoch: 90 [45056/54000 (83%)] Loss: -826313.812500\n",
      "Train Epoch: 90 [46464/54000 (86%)] Loss: -818887.000000\n",
      "Train Epoch: 90 [47872/54000 (89%)] Loss: -846970.250000\n",
      "Train Epoch: 90 [49280/54000 (91%)] Loss: -802977.187500\n",
      "Train Epoch: 90 [50688/54000 (94%)] Loss: -759390.875000\n",
      "Train Epoch: 90 [52096/54000 (96%)] Loss: -808504.750000\n",
      "    epoch          : 90\n",
      "    loss           : -808558.9274820574\n",
      "    val_loss       : -808694.5362042683\n",
      "Saving checkpoint: saved/models/Mnist_VaeCategory/0422_221614/checkpoint-epoch90.pth ...\n",
      "Train Epoch: 91 [0/54000 (0%)] Loss: -817222.125000\n",
      "Train Epoch: 91 [1408/54000 (3%)] Loss: -773412.875000\n",
      "Train Epoch: 91 [2816/54000 (5%)] Loss: -752837.312500\n",
      "Train Epoch: 91 [4224/54000 (8%)] Loss: -805930.562500\n",
      "Train Epoch: 91 [5632/54000 (10%)] Loss: -817188.687500\n",
      "Train Epoch: 91 [7040/54000 (13%)] Loss: -801575.812500\n",
      "Train Epoch: 91 [8448/54000 (16%)] Loss: -820293.125000\n",
      "Train Epoch: 91 [9856/54000 (18%)] Loss: -831916.625000\n",
      "Train Epoch: 91 [11264/54000 (21%)] Loss: -835450.437500\n",
      "Train Epoch: 91 [12672/54000 (23%)] Loss: -836875.500000\n",
      "Train Epoch: 91 [14080/54000 (26%)] Loss: -797134.062500\n",
      "Train Epoch: 91 [15488/54000 (29%)] Loss: -761419.500000\n",
      "Train Epoch: 91 [16896/54000 (31%)] Loss: -817212.625000\n",
      "Train Epoch: 91 [18304/54000 (34%)] Loss: -790446.625000\n",
      "Train Epoch: 91 [19712/54000 (37%)] Loss: -798631.375000\n",
      "Train Epoch: 91 [21120/54000 (39%)] Loss: -791046.875000\n",
      "Train Epoch: 91 [22528/54000 (42%)] Loss: -795158.000000\n",
      "Train Epoch: 91 [23936/54000 (44%)] Loss: -832678.750000\n",
      "Train Epoch: 91 [25344/54000 (47%)] Loss: -788899.875000\n",
      "Train Epoch: 91 [26752/54000 (50%)] Loss: -853353.312500\n",
      "Train Epoch: 91 [28160/54000 (52%)] Loss: -891842.937500\n",
      "Train Epoch: 91 [29568/54000 (55%)] Loss: -838811.812500\n",
      "Train Epoch: 91 [30976/54000 (57%)] Loss: -815185.062500\n",
      "Train Epoch: 91 [32384/54000 (60%)] Loss: -763258.250000\n",
      "Train Epoch: 91 [33792/54000 (63%)] Loss: -765889.875000\n",
      "Train Epoch: 91 [35200/54000 (65%)] Loss: -789195.500000\n",
      "Train Epoch: 91 [36608/54000 (68%)] Loss: -811506.312500\n",
      "Train Epoch: 91 [38016/54000 (70%)] Loss: -754410.875000\n",
      "Train Epoch: 91 [39424/54000 (73%)] Loss: -826731.875000\n",
      "Train Epoch: 91 [40832/54000 (76%)] Loss: -814859.687500\n",
      "Train Epoch: 91 [42240/54000 (78%)] Loss: -799942.500000\n",
      "Train Epoch: 91 [43648/54000 (81%)] Loss: -823965.875000\n",
      "Train Epoch: 91 [45056/54000 (83%)] Loss: -793713.937500\n",
      "Train Epoch: 91 [46464/54000 (86%)] Loss: -853828.187500\n",
      "Train Epoch: 91 [47872/54000 (89%)] Loss: -839989.250000\n",
      "Train Epoch: 91 [49280/54000 (91%)] Loss: -825453.250000\n",
      "Train Epoch: 91 [50688/54000 (94%)] Loss: -826783.125000\n",
      "Train Epoch: 91 [52096/54000 (96%)] Loss: -828550.187500\n",
      "    epoch          : 91\n",
      "    loss           : -808022.1602870814\n",
      "    val_loss       : -808214.5994664634\n",
      "Train Epoch: 92 [0/54000 (0%)] Loss: -842440.875000\n",
      "Train Epoch: 92 [1408/54000 (3%)] Loss: -824211.750000\n",
      "Train Epoch: 92 [2816/54000 (5%)] Loss: -806854.937500\n",
      "Train Epoch: 92 [4224/54000 (8%)] Loss: -821314.312500\n",
      "Train Epoch: 92 [5632/54000 (10%)] Loss: -850510.875000\n",
      "Train Epoch: 92 [7040/54000 (13%)] Loss: -835627.750000\n",
      "Train Epoch: 92 [8448/54000 (16%)] Loss: -826043.812500\n",
      "Train Epoch: 92 [9856/54000 (18%)] Loss: -764732.687500\n",
      "Train Epoch: 92 [11264/54000 (21%)] Loss: -897963.000000\n",
      "Train Epoch: 92 [12672/54000 (23%)] Loss: -796090.437500\n",
      "Train Epoch: 92 [14080/54000 (26%)] Loss: -776426.687500\n",
      "Train Epoch: 92 [15488/54000 (29%)] Loss: -785728.500000\n",
      "Train Epoch: 92 [16896/54000 (31%)] Loss: -776575.375000\n",
      "Train Epoch: 92 [18304/54000 (34%)] Loss: -831182.750000\n",
      "Train Epoch: 92 [19712/54000 (37%)] Loss: -846008.625000\n",
      "Train Epoch: 92 [21120/54000 (39%)] Loss: -827766.312500\n",
      "Train Epoch: 92 [22528/54000 (42%)] Loss: -838851.812500\n",
      "Train Epoch: 92 [23936/54000 (44%)] Loss: -790388.437500\n",
      "Train Epoch: 92 [25344/54000 (47%)] Loss: -797821.062500\n",
      "Train Epoch: 92 [26752/54000 (50%)] Loss: -821360.625000\n",
      "Train Epoch: 92 [28160/54000 (52%)] Loss: -884628.437500\n",
      "Train Epoch: 92 [29568/54000 (55%)] Loss: -822668.875000\n",
      "Train Epoch: 92 [30976/54000 (57%)] Loss: -805378.875000\n",
      "Train Epoch: 92 [32384/54000 (60%)] Loss: -791987.562500\n",
      "Train Epoch: 92 [33792/54000 (63%)] Loss: -815882.375000\n",
      "Train Epoch: 92 [35200/54000 (65%)] Loss: -818502.875000\n",
      "Train Epoch: 92 [36608/54000 (68%)] Loss: -822975.250000\n",
      "Train Epoch: 92 [38016/54000 (70%)] Loss: -790931.000000\n",
      "Train Epoch: 92 [39424/54000 (73%)] Loss: -795380.375000\n",
      "Train Epoch: 92 [40832/54000 (76%)] Loss: -799622.062500\n",
      "Train Epoch: 92 [42240/54000 (78%)] Loss: -879710.375000\n",
      "Train Epoch: 92 [43648/54000 (81%)] Loss: -897516.750000\n",
      "Train Epoch: 92 [45056/54000 (83%)] Loss: -759238.812500\n",
      "Train Epoch: 92 [46464/54000 (86%)] Loss: -817077.125000\n",
      "Train Epoch: 92 [47872/54000 (89%)] Loss: -822470.000000\n",
      "Train Epoch: 92 [49280/54000 (91%)] Loss: -838571.562500\n",
      "Train Epoch: 92 [50688/54000 (94%)] Loss: -841482.375000\n",
      "Train Epoch: 92 [52096/54000 (96%)] Loss: -824367.250000\n",
      "    epoch          : 92\n",
      "    loss           : -808486.5156997608\n",
      "    val_loss       : -807344.6724466464\n",
      "Train Epoch: 93 [0/54000 (0%)] Loss: -776986.500000\n",
      "Train Epoch: 93 [1408/54000 (3%)] Loss: -791117.125000\n",
      "Train Epoch: 93 [2816/54000 (5%)] Loss: -781728.812500\n",
      "Train Epoch: 93 [4224/54000 (8%)] Loss: -868303.937500\n",
      "Train Epoch: 93 [5632/54000 (10%)] Loss: -794371.500000\n",
      "Train Epoch: 93 [7040/54000 (13%)] Loss: -808994.937500\n",
      "Train Epoch: 93 [8448/54000 (16%)] Loss: -820488.125000\n",
      "Train Epoch: 93 [9856/54000 (18%)] Loss: -836463.437500\n",
      "Train Epoch: 93 [11264/54000 (21%)] Loss: -839393.000000\n",
      "Train Epoch: 93 [12672/54000 (23%)] Loss: -836659.875000\n",
      "Train Epoch: 93 [14080/54000 (26%)] Loss: -798064.125000\n",
      "Train Epoch: 93 [15488/54000 (29%)] Loss: -817523.000000\n",
      "Train Epoch: 93 [16896/54000 (31%)] Loss: -758352.125000\n",
      "Train Epoch: 93 [18304/54000 (34%)] Loss: -892288.937500\n",
      "Train Epoch: 93 [19712/54000 (37%)] Loss: -801189.500000\n",
      "Train Epoch: 93 [21120/54000 (39%)] Loss: -770625.000000\n",
      "Train Epoch: 93 [22528/54000 (42%)] Loss: -804661.812500\n",
      "Train Epoch: 93 [23936/54000 (44%)] Loss: -820170.625000\n",
      "Train Epoch: 93 [25344/54000 (47%)] Loss: -786561.125000\n",
      "Train Epoch: 93 [26752/54000 (50%)] Loss: -820151.500000\n",
      "Train Epoch: 93 [28160/54000 (52%)] Loss: -813937.500000\n",
      "Train Epoch: 93 [29568/54000 (55%)] Loss: -799713.125000\n",
      "Train Epoch: 93 [30976/54000 (57%)] Loss: -842005.625000\n",
      "Train Epoch: 93 [32384/54000 (60%)] Loss: -770282.250000\n",
      "Train Epoch: 93 [33792/54000 (63%)] Loss: -903185.125000\n",
      "Train Epoch: 93 [35200/54000 (65%)] Loss: -759963.437500\n",
      "Train Epoch: 93 [36608/54000 (68%)] Loss: -830922.875000\n",
      "Train Epoch: 93 [38016/54000 (70%)] Loss: -823253.875000\n",
      "Train Epoch: 93 [39424/54000 (73%)] Loss: -788986.750000\n",
      "Train Epoch: 93 [40832/54000 (76%)] Loss: -785636.187500\n",
      "Train Epoch: 93 [42240/54000 (78%)] Loss: -790069.000000\n",
      "Train Epoch: 93 [43648/54000 (81%)] Loss: -765825.625000\n",
      "Train Epoch: 93 [45056/54000 (83%)] Loss: -754419.937500\n",
      "Train Epoch: 93 [46464/54000 (86%)] Loss: -796307.500000\n",
      "Train Epoch: 93 [47872/54000 (89%)] Loss: -836248.375000\n",
      "Train Epoch: 93 [49280/54000 (91%)] Loss: -836551.125000\n",
      "Train Epoch: 93 [50688/54000 (94%)] Loss: -826356.562500\n",
      "Train Epoch: 93 [52096/54000 (96%)] Loss: -817900.000000\n",
      "    epoch          : 93\n",
      "    loss           : -808609.5125598086\n",
      "    val_loss       : -807585.7902057926\n",
      "Train Epoch: 94 [0/54000 (0%)] Loss: -761802.937500\n",
      "Train Epoch: 94 [1408/54000 (3%)] Loss: -795155.625000\n",
      "Train Epoch: 94 [2816/54000 (5%)] Loss: -812306.875000\n",
      "Train Epoch: 94 [4224/54000 (8%)] Loss: -822625.000000\n",
      "Train Epoch: 94 [5632/54000 (10%)] Loss: -768910.000000\n",
      "Train Epoch: 94 [7040/54000 (13%)] Loss: -831895.000000\n",
      "Train Epoch: 94 [8448/54000 (16%)] Loss: -805952.250000\n",
      "Train Epoch: 94 [9856/54000 (18%)] Loss: -838819.312500\n",
      "Train Epoch: 94 [11264/54000 (21%)] Loss: -827072.125000\n",
      "Train Epoch: 94 [12672/54000 (23%)] Loss: -790065.750000\n",
      "Train Epoch: 94 [14080/54000 (26%)] Loss: -869333.500000\n",
      "Train Epoch: 94 [15488/54000 (29%)] Loss: -791951.687500\n",
      "Train Epoch: 94 [16896/54000 (31%)] Loss: -813359.625000\n",
      "Train Epoch: 94 [18304/54000 (34%)] Loss: -798897.375000\n",
      "Train Epoch: 94 [19712/54000 (37%)] Loss: -774469.125000\n",
      "Train Epoch: 94 [21120/54000 (39%)] Loss: -800926.437500\n",
      "Train Epoch: 94 [22528/54000 (42%)] Loss: -817315.687500\n",
      "Train Epoch: 94 [23936/54000 (44%)] Loss: -802719.937500\n",
      "Train Epoch: 94 [25344/54000 (47%)] Loss: -767303.000000\n",
      "Train Epoch: 94 [26752/54000 (50%)] Loss: -824867.250000\n",
      "Train Epoch: 94 [28160/54000 (52%)] Loss: -834662.437500\n",
      "Train Epoch: 94 [29568/54000 (55%)] Loss: -792546.750000\n",
      "Train Epoch: 94 [30976/54000 (57%)] Loss: -809588.312500\n",
      "Train Epoch: 94 [32384/54000 (60%)] Loss: -876383.875000\n",
      "Train Epoch: 94 [33792/54000 (63%)] Loss: -822956.062500\n",
      "Train Epoch: 94 [35200/54000 (65%)] Loss: -849759.312500\n",
      "Train Epoch: 94 [36608/54000 (68%)] Loss: -765783.687500\n",
      "Train Epoch: 94 [38016/54000 (70%)] Loss: -846925.125000\n",
      "Train Epoch: 94 [39424/54000 (73%)] Loss: -812028.812500\n",
      "Train Epoch: 94 [40832/54000 (76%)] Loss: -759870.125000\n",
      "Train Epoch: 94 [42240/54000 (78%)] Loss: -804932.500000\n",
      "Train Epoch: 94 [43648/54000 (81%)] Loss: -786624.937500\n",
      "Train Epoch: 94 [45056/54000 (83%)] Loss: -880345.437500\n",
      "Train Epoch: 94 [46464/54000 (86%)] Loss: -786344.375000\n",
      "Train Epoch: 94 [47872/54000 (89%)] Loss: -755400.562500\n",
      "Train Epoch: 94 [49280/54000 (91%)] Loss: -791578.937500\n",
      "Train Epoch: 94 [50688/54000 (94%)] Loss: -784301.000000\n",
      "Train Epoch: 94 [52096/54000 (96%)] Loss: -774384.875000\n",
      "    epoch          : 94\n",
      "    loss           : -808538.7757177034\n",
      "    val_loss       : -808183.3639481707\n",
      "Train Epoch: 95 [0/54000 (0%)] Loss: -773739.000000\n",
      "Train Epoch: 95 [1408/54000 (3%)] Loss: -760100.312500\n",
      "Train Epoch: 95 [2816/54000 (5%)] Loss: -885003.187500\n",
      "Train Epoch: 95 [4224/54000 (8%)] Loss: -828022.687500\n",
      "Train Epoch: 95 [5632/54000 (10%)] Loss: -805996.312500\n",
      "Train Epoch: 95 [7040/54000 (13%)] Loss: -798777.125000\n",
      "Train Epoch: 95 [8448/54000 (16%)] Loss: -804686.937500\n",
      "Train Epoch: 95 [9856/54000 (18%)] Loss: -764840.250000\n",
      "Train Epoch: 95 [11264/54000 (21%)] Loss: -772521.500000\n",
      "Train Epoch: 95 [12672/54000 (23%)] Loss: -762850.875000\n",
      "Train Epoch: 95 [14080/54000 (26%)] Loss: -800872.125000\n",
      "Train Epoch: 95 [15488/54000 (29%)] Loss: -805174.312500\n",
      "Train Epoch: 95 [16896/54000 (31%)] Loss: -878611.625000\n",
      "Train Epoch: 95 [18304/54000 (34%)] Loss: -806453.562500\n",
      "Train Epoch: 95 [19712/54000 (37%)] Loss: -774503.375000\n",
      "Train Epoch: 95 [21120/54000 (39%)] Loss: -766346.375000\n",
      "Train Epoch: 95 [22528/54000 (42%)] Loss: -806608.000000\n",
      "Train Epoch: 95 [23936/54000 (44%)] Loss: -804007.187500\n",
      "Train Epoch: 95 [25344/54000 (47%)] Loss: -790688.812500\n",
      "Train Epoch: 95 [26752/54000 (50%)] Loss: -810875.187500\n",
      "Train Epoch: 95 [28160/54000 (52%)] Loss: -823375.875000\n",
      "Train Epoch: 95 [29568/54000 (55%)] Loss: -818685.250000\n",
      "Train Epoch: 95 [30976/54000 (57%)] Loss: -842701.250000\n",
      "Train Epoch: 95 [32384/54000 (60%)] Loss: -765214.250000\n",
      "Train Epoch: 95 [33792/54000 (63%)] Loss: -823906.125000\n",
      "Train Epoch: 95 [35200/54000 (65%)] Loss: -812805.875000\n",
      "Train Epoch: 95 [36608/54000 (68%)] Loss: -819302.937500\n",
      "Train Epoch: 95 [38016/54000 (70%)] Loss: -771949.875000\n",
      "Train Epoch: 95 [39424/54000 (73%)] Loss: -893017.187500\n",
      "Train Epoch: 95 [40832/54000 (76%)] Loss: -764210.875000\n",
      "Train Epoch: 95 [42240/54000 (78%)] Loss: -795327.000000\n",
      "Train Epoch: 95 [43648/54000 (81%)] Loss: -816814.125000\n",
      "Train Epoch: 95 [45056/54000 (83%)] Loss: -840757.375000\n",
      "Train Epoch: 95 [46464/54000 (86%)] Loss: -762032.875000\n",
      "Train Epoch: 95 [47872/54000 (89%)] Loss: -852340.500000\n",
      "Train Epoch: 95 [49280/54000 (91%)] Loss: -807973.687500\n",
      "Train Epoch: 95 [50688/54000 (94%)] Loss: -779144.937500\n",
      "Train Epoch: 95 [52096/54000 (96%)] Loss: -765791.875000\n",
      "    epoch          : 95\n",
      "    loss           : -808697.6273923445\n",
      "    val_loss       : -809070.0038109756\n",
      "Saving checkpoint: saved/models/Mnist_VaeCategory/0422_221614/checkpoint-epoch95.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 96 [0/54000 (0%)] Loss: -766867.312500\n",
      "Train Epoch: 96 [1408/54000 (3%)] Loss: -801085.875000\n",
      "Train Epoch: 96 [2816/54000 (5%)] Loss: -810602.500000\n",
      "Train Epoch: 96 [4224/54000 (8%)] Loss: -828673.625000\n",
      "Train Epoch: 96 [5632/54000 (10%)] Loss: -811502.000000\n",
      "Train Epoch: 96 [7040/54000 (13%)] Loss: -796488.687500\n",
      "Train Epoch: 96 [8448/54000 (16%)] Loss: -812781.750000\n",
      "Train Epoch: 96 [9856/54000 (18%)] Loss: -837424.437500\n",
      "Train Epoch: 96 [11264/54000 (21%)] Loss: -799478.750000\n",
      "Train Epoch: 96 [12672/54000 (23%)] Loss: -813019.937500\n",
      "Train Epoch: 96 [14080/54000 (26%)] Loss: -793146.562500\n",
      "Train Epoch: 96 [15488/54000 (29%)] Loss: -765509.125000\n",
      "Train Epoch: 96 [16896/54000 (31%)] Loss: -760374.687500\n",
      "Train Epoch: 96 [18304/54000 (34%)] Loss: -896161.062500\n",
      "Train Epoch: 96 [19712/54000 (37%)] Loss: -797033.312500\n",
      "Train Epoch: 96 [21120/54000 (39%)] Loss: -809756.125000\n",
      "Train Epoch: 96 [22528/54000 (42%)] Loss: -825181.875000\n",
      "Train Epoch: 96 [23936/54000 (44%)] Loss: -902068.437500\n",
      "Train Epoch: 96 [25344/54000 (47%)] Loss: -821960.375000\n",
      "Train Epoch: 96 [26752/54000 (50%)] Loss: -791440.687500\n",
      "Train Epoch: 96 [28160/54000 (52%)] Loss: -796807.375000\n",
      "Train Epoch: 96 [29568/54000 (55%)] Loss: -789906.125000\n",
      "Train Epoch: 96 [30976/54000 (57%)] Loss: -767672.812500\n",
      "Train Epoch: 96 [32384/54000 (60%)] Loss: -772246.000000\n",
      "Train Epoch: 96 [33792/54000 (63%)] Loss: -830944.125000\n",
      "Train Epoch: 96 [35200/54000 (65%)] Loss: -832865.437500\n",
      "Train Epoch: 96 [36608/54000 (68%)] Loss: -792729.062500\n",
      "Train Epoch: 96 [38016/54000 (70%)] Loss: -798606.812500\n",
      "Train Epoch: 96 [39424/54000 (73%)] Loss: -862748.625000\n",
      "Train Epoch: 96 [40832/54000 (76%)] Loss: -887531.500000\n",
      "Train Epoch: 96 [42240/54000 (78%)] Loss: -768577.937500\n",
      "Train Epoch: 96 [43648/54000 (81%)] Loss: -763342.500000\n",
      "Train Epoch: 96 [45056/54000 (83%)] Loss: -801704.187500\n",
      "Train Epoch: 96 [46464/54000 (86%)] Loss: -800340.750000\n",
      "Train Epoch: 96 [47872/54000 (89%)] Loss: -780245.250000\n",
      "Train Epoch: 96 [49280/54000 (91%)] Loss: -771043.062500\n",
      "Train Epoch: 96 [50688/54000 (94%)] Loss: -773014.375000\n",
      "Train Epoch: 96 [52096/54000 (96%)] Loss: -753829.875000\n",
      "    epoch          : 96\n",
      "    loss           : -808806.6380083732\n",
      "    val_loss       : -808763.0996570121\n",
      "Train Epoch: 97 [0/54000 (0%)] Loss: -813686.187500\n",
      "Train Epoch: 97 [1408/54000 (3%)] Loss: -821366.875000\n",
      "Train Epoch: 97 [2816/54000 (5%)] Loss: -766764.812500\n",
      "Train Epoch: 97 [4224/54000 (8%)] Loss: -834159.000000\n",
      "Train Epoch: 97 [5632/54000 (10%)] Loss: -774210.750000\n",
      "Train Epoch: 97 [7040/54000 (13%)] Loss: -798586.062500\n",
      "Train Epoch: 97 [8448/54000 (16%)] Loss: -795627.750000\n",
      "Train Epoch: 97 [9856/54000 (18%)] Loss: -794996.000000\n",
      "Train Epoch: 97 [11264/54000 (21%)] Loss: -789400.875000\n",
      "Train Epoch: 97 [12672/54000 (23%)] Loss: -849244.375000\n",
      "Train Epoch: 97 [14080/54000 (26%)] Loss: -762935.687500\n",
      "Train Epoch: 97 [15488/54000 (29%)] Loss: -760296.375000\n",
      "Train Epoch: 97 [16896/54000 (31%)] Loss: -828171.812500\n",
      "Train Epoch: 97 [18304/54000 (34%)] Loss: -817731.375000\n",
      "Train Epoch: 97 [19712/54000 (37%)] Loss: -786581.250000\n",
      "Train Epoch: 97 [21120/54000 (39%)] Loss: -760649.625000\n",
      "Train Epoch: 97 [22528/54000 (42%)] Loss: -846723.062500\n",
      "Train Epoch: 97 [23936/54000 (44%)] Loss: -759802.750000\n",
      "Train Epoch: 97 [25344/54000 (47%)] Loss: -809375.687500\n",
      "Train Epoch: 97 [26752/54000 (50%)] Loss: -798896.062500\n",
      "Train Epoch: 97 [28160/54000 (52%)] Loss: -800069.500000\n",
      "Train Epoch: 97 [29568/54000 (55%)] Loss: -825875.500000\n",
      "Train Epoch: 97 [30976/54000 (57%)] Loss: -843704.687500\n",
      "Train Epoch: 97 [32384/54000 (60%)] Loss: -769741.625000\n",
      "Train Epoch: 97 [33792/54000 (63%)] Loss: -767826.187500\n",
      "Train Epoch: 97 [35200/54000 (65%)] Loss: -819075.875000\n",
      "Train Epoch: 97 [36608/54000 (68%)] Loss: -809804.750000\n",
      "Train Epoch: 97 [38016/54000 (70%)] Loss: -869096.937500\n",
      "Train Epoch: 97 [39424/54000 (73%)] Loss: -764331.000000\n",
      "Train Epoch: 97 [40832/54000 (76%)] Loss: -801224.562500\n",
      "Train Epoch: 97 [42240/54000 (78%)] Loss: -775250.000000\n",
      "Train Epoch: 97 [43648/54000 (81%)] Loss: -802959.000000\n",
      "Train Epoch: 97 [45056/54000 (83%)] Loss: -769887.500000\n",
      "Train Epoch: 97 [46464/54000 (86%)] Loss: -816578.062500\n",
      "Train Epoch: 97 [47872/54000 (89%)] Loss: -788968.250000\n",
      "Train Epoch: 97 [49280/54000 (91%)] Loss: -803960.000000\n",
      "Train Epoch: 97 [50688/54000 (94%)] Loss: -851612.125000\n",
      "Train Epoch: 97 [52096/54000 (96%)] Loss: -763915.375000\n",
      "    epoch          : 97\n",
      "    loss           : -808864.5133074162\n",
      "    val_loss       : -808226.9405487805\n",
      "Train Epoch: 98 [0/54000 (0%)] Loss: -762357.000000\n",
      "Train Epoch: 98 [1408/54000 (3%)] Loss: -775342.875000\n",
      "Train Epoch: 98 [2816/54000 (5%)] Loss: -769602.312500\n",
      "Train Epoch: 98 [4224/54000 (8%)] Loss: -803983.750000\n",
      "Train Epoch: 98 [5632/54000 (10%)] Loss: -831456.187500\n",
      "Train Epoch: 98 [7040/54000 (13%)] Loss: -767181.000000\n",
      "Train Epoch: 98 [8448/54000 (16%)] Loss: -794661.937500\n",
      "Train Epoch: 98 [9856/54000 (18%)] Loss: -818751.375000\n",
      "Train Epoch: 98 [11264/54000 (21%)] Loss: -792624.375000\n",
      "Train Epoch: 98 [12672/54000 (23%)] Loss: -767984.000000\n",
      "Train Epoch: 98 [14080/54000 (26%)] Loss: -890207.000000\n",
      "Train Epoch: 98 [15488/54000 (29%)] Loss: -823989.437500\n",
      "Train Epoch: 98 [16896/54000 (31%)] Loss: -765299.125000\n",
      "Train Epoch: 98 [18304/54000 (34%)] Loss: -757353.312500\n",
      "Train Epoch: 98 [19712/54000 (37%)] Loss: -827786.250000\n",
      "Train Epoch: 98 [21120/54000 (39%)] Loss: -811305.687500\n",
      "Train Epoch: 98 [22528/54000 (42%)] Loss: -797725.125000\n",
      "Train Epoch: 98 [23936/54000 (44%)] Loss: -824210.750000\n",
      "Train Epoch: 98 [25344/54000 (47%)] Loss: -803472.312500\n",
      "Train Epoch: 98 [26752/54000 (50%)] Loss: -759615.875000\n",
      "Train Epoch: 98 [28160/54000 (52%)] Loss: -825177.937500\n",
      "Train Epoch: 98 [29568/54000 (55%)] Loss: -893395.812500\n",
      "Train Epoch: 98 [30976/54000 (57%)] Loss: -758928.125000\n",
      "Train Epoch: 98 [32384/54000 (60%)] Loss: -798359.875000\n",
      "Train Epoch: 98 [33792/54000 (63%)] Loss: -771306.062500\n",
      "Train Epoch: 98 [35200/54000 (65%)] Loss: -822690.625000\n",
      "Train Epoch: 98 [36608/54000 (68%)] Loss: -756535.625000\n",
      "Train Epoch: 98 [38016/54000 (70%)] Loss: -800656.500000\n",
      "Train Epoch: 98 [39424/54000 (73%)] Loss: -778627.625000\n",
      "Train Epoch: 98 [40832/54000 (76%)] Loss: -835839.000000\n",
      "Train Epoch: 98 [42240/54000 (78%)] Loss: -827219.250000\n",
      "Train Epoch: 98 [43648/54000 (81%)] Loss: -811311.000000\n",
      "Train Epoch: 98 [45056/54000 (83%)] Loss: -803920.750000\n",
      "Train Epoch: 98 [46464/54000 (86%)] Loss: -824328.625000\n",
      "Train Epoch: 98 [47872/54000 (89%)] Loss: -843282.375000\n",
      "Train Epoch: 98 [49280/54000 (91%)] Loss: -836137.625000\n",
      "Train Epoch: 98 [50688/54000 (94%)] Loss: -828383.000000\n",
      "Train Epoch: 98 [52096/54000 (96%)] Loss: -763063.125000\n",
      "    epoch          : 98\n",
      "    loss           : -808654.3655801435\n",
      "    val_loss       : -807985.1520579269\n",
      "Train Epoch: 99 [0/54000 (0%)] Loss: -757440.937500\n",
      "Train Epoch: 99 [1408/54000 (3%)] Loss: -848823.375000\n",
      "Train Epoch: 99 [2816/54000 (5%)] Loss: -850735.312500\n",
      "Train Epoch: 99 [4224/54000 (8%)] Loss: -790168.125000\n",
      "Train Epoch: 99 [5632/54000 (10%)] Loss: -848145.625000\n",
      "Train Epoch: 99 [7040/54000 (13%)] Loss: -788036.187500\n",
      "Train Epoch: 99 [8448/54000 (16%)] Loss: -759915.250000\n",
      "Train Epoch: 99 [9856/54000 (18%)] Loss: -877808.250000\n",
      "Train Epoch: 99 [11264/54000 (21%)] Loss: -806111.187500\n",
      "Train Epoch: 99 [12672/54000 (23%)] Loss: -805414.625000\n",
      "Train Epoch: 99 [14080/54000 (26%)] Loss: -777154.312500\n",
      "Train Epoch: 99 [15488/54000 (29%)] Loss: -831813.750000\n",
      "Train Epoch: 99 [16896/54000 (31%)] Loss: -797657.250000\n",
      "Train Epoch: 99 [18304/54000 (34%)] Loss: -797560.562500\n",
      "Train Epoch: 99 [19712/54000 (37%)] Loss: -756700.562500\n",
      "Train Epoch: 99 [21120/54000 (39%)] Loss: -798618.562500\n",
      "Train Epoch: 99 [22528/54000 (42%)] Loss: -765173.125000\n",
      "Train Epoch: 99 [23936/54000 (44%)] Loss: -815986.500000\n",
      "Train Epoch: 99 [25344/54000 (47%)] Loss: -886753.625000\n",
      "Train Epoch: 99 [26752/54000 (50%)] Loss: -796163.750000\n",
      "Train Epoch: 99 [28160/54000 (52%)] Loss: -763480.500000\n",
      "Train Epoch: 99 [29568/54000 (55%)] Loss: -880185.375000\n",
      "Train Epoch: 99 [30976/54000 (57%)] Loss: -758262.375000\n",
      "Train Epoch: 99 [32384/54000 (60%)] Loss: -771921.875000\n",
      "Train Epoch: 99 [33792/54000 (63%)] Loss: -824325.000000\n",
      "Train Epoch: 99 [35200/54000 (65%)] Loss: -823668.875000\n",
      "Train Epoch: 99 [36608/54000 (68%)] Loss: -815679.062500\n",
      "Train Epoch: 99 [38016/54000 (70%)] Loss: -840680.937500\n",
      "Train Epoch: 99 [39424/54000 (73%)] Loss: -849079.000000\n",
      "Train Epoch: 99 [40832/54000 (76%)] Loss: -806214.312500\n",
      "Train Epoch: 99 [42240/54000 (78%)] Loss: -799357.250000\n",
      "Train Epoch: 99 [43648/54000 (81%)] Loss: -894767.312500\n",
      "Train Epoch: 99 [45056/54000 (83%)] Loss: -761379.687500\n",
      "Train Epoch: 99 [46464/54000 (86%)] Loss: -765663.062500\n",
      "Train Epoch: 99 [47872/54000 (89%)] Loss: -803011.000000\n",
      "Train Epoch: 99 [49280/54000 (91%)] Loss: -789359.250000\n",
      "Train Epoch: 99 [50688/54000 (94%)] Loss: -845449.812500\n",
      "Train Epoch: 99 [52096/54000 (96%)] Loss: -826662.937500\n",
      "    epoch          : 99\n",
      "    loss           : -808913.1641746411\n",
      "    val_loss       : -808519.864519817\n",
      "Train Epoch: 100 [0/54000 (0%)] Loss: -810435.625000\n",
      "Train Epoch: 100 [1408/54000 (3%)] Loss: -834998.500000\n",
      "Train Epoch: 100 [2816/54000 (5%)] Loss: -838960.750000\n",
      "Train Epoch: 100 [4224/54000 (8%)] Loss: -798508.250000\n",
      "Train Epoch: 100 [5632/54000 (10%)] Loss: -831597.750000\n",
      "Train Epoch: 100 [7040/54000 (13%)] Loss: -757778.875000\n",
      "Train Epoch: 100 [8448/54000 (16%)] Loss: -816841.125000\n",
      "Train Epoch: 100 [9856/54000 (18%)] Loss: -844267.187500\n",
      "Train Epoch: 100 [11264/54000 (21%)] Loss: -837377.562500\n",
      "Train Epoch: 100 [12672/54000 (23%)] Loss: -802223.812500\n",
      "Train Epoch: 100 [14080/54000 (26%)] Loss: -887261.187500\n",
      "Train Epoch: 100 [15488/54000 (29%)] Loss: -787734.187500\n",
      "Train Epoch: 100 [16896/54000 (31%)] Loss: -804581.875000\n",
      "Train Epoch: 100 [18304/54000 (34%)] Loss: -764353.250000\n",
      "Train Epoch: 100 [19712/54000 (37%)] Loss: -833386.875000\n",
      "Train Epoch: 100 [21120/54000 (39%)] Loss: -832479.500000\n",
      "Train Epoch: 100 [22528/54000 (42%)] Loss: -775072.000000\n",
      "Train Epoch: 100 [23936/54000 (44%)] Loss: -761320.625000\n",
      "Train Epoch: 100 [25344/54000 (47%)] Loss: -907838.437500\n",
      "Train Epoch: 100 [26752/54000 (50%)] Loss: -811380.500000\n",
      "Train Epoch: 100 [28160/54000 (52%)] Loss: -797104.062500\n",
      "Train Epoch: 100 [29568/54000 (55%)] Loss: -839236.750000\n",
      "Train Epoch: 100 [30976/54000 (57%)] Loss: -820476.687500\n",
      "Train Epoch: 100 [32384/54000 (60%)] Loss: -835251.500000\n",
      "Train Epoch: 100 [33792/54000 (63%)] Loss: -836983.812500\n",
      "Train Epoch: 100 [35200/54000 (65%)] Loss: -798242.750000\n",
      "Train Epoch: 100 [36608/54000 (68%)] Loss: -781090.562500\n",
      "Train Epoch: 100 [38016/54000 (70%)] Loss: -762474.500000\n",
      "Train Epoch: 100 [39424/54000 (73%)] Loss: -818904.500000\n",
      "Train Epoch: 100 [40832/54000 (76%)] Loss: -774464.562500\n",
      "Train Epoch: 100 [42240/54000 (78%)] Loss: -901703.250000\n",
      "Train Epoch: 100 [43648/54000 (81%)] Loss: -758768.125000\n",
      "Train Epoch: 100 [45056/54000 (83%)] Loss: -793504.000000\n",
      "Train Epoch: 100 [46464/54000 (86%)] Loss: -795823.250000\n",
      "Train Epoch: 100 [47872/54000 (89%)] Loss: -812264.937500\n",
      "Train Epoch: 100 [49280/54000 (91%)] Loss: -848954.937500\n",
      "Train Epoch: 100 [50688/54000 (94%)] Loss: -844449.187500\n",
      "Train Epoch: 100 [52096/54000 (96%)] Loss: -847830.375000\n",
      "    epoch          : 100\n",
      "    loss           : -808918.9789174641\n",
      "    val_loss       : -809156.5926067074\n",
      "Saving checkpoint: saved/models/Mnist_VaeCategory/0422_221614/checkpoint-epoch100.pth ...\n",
      "Saving current best: model_best.pth ...\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:RoutingCategories] *",
   "language": "python",
   "name": "conda-env-RoutingCategories-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
