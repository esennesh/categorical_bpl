{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/eli/AnacondaProjects/categorical_bpl\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import collections\n",
    "import pyro\n",
    "import torch\n",
    "import numpy as np\n",
    "import data_loader.data_loaders as module_data\n",
    "import model.model as module_arch\n",
    "from parse_config import ConfigParser\n",
    "from trainer import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyro.enable_validation(True)\n",
    "# torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seeds for reproducibility\n",
    "SEED = 123\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Args = collections.namedtuple('Args', 'config resume device')\n",
    "config = ConfigParser.from_args(Args(config='omniglot_config.json', resume=None, device=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = config.get_logger('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# setup data_loader instances\n",
    "data_loader = config.init_obj('data_loader', module_data)\n",
    "valid_data_loader = data_loader.split_validation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model architecture, then print to console\n",
    "model = config.init_obj('arch', module_arch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = pyro.optim.ReduceLROnPlateau({\n",
    "    'optimizer': torch.optim.Adam,\n",
    "    'optim_args': {\n",
    "        \"lr\": 1e-3,\n",
    "        \"weight_decay\": 0,\n",
    "        \"amsgrad\": True\n",
    "    },\n",
    "    \"patience\": 50,\n",
    "    \"cooldown\": 25,\n",
    "    \"factor\": 0.1,\n",
    "    \"verbose\": True,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model, [], optimizer, config=config,\n",
    "                  data_loader=data_loader,\n",
    "                  valid_data_loader=valid_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [512/17352 (3%)] Loss: 1837.849731\n",
      "Train Epoch: 1 [10068/17352 (58%)] Loss: 1002.983061\n",
      "Train Epoch: 1 [16939/17352 (98%)] Loss: 920.359949\n",
      "    epoch          : 1\n",
      "    loss           : 1128.937376800312\n",
      "    val_loss       : 959.5928768573973\n",
      "Train Epoch: 2 [512/17352 (3%)] Loss: 917.569336\n",
      "Train Epoch: 2 [10382/17352 (60%)] Loss: 851.478768\n",
      "Train Epoch: 2 [17263/17352 (99%)] Loss: 868.716208\n",
      "    epoch          : 2\n",
      "    loss           : 884.728523550055\n",
      "    val_loss       : 857.3083547773776\n",
      "Train Epoch: 3 [512/17352 (3%)] Loss: 836.403992\n",
      "Train Epoch: 3 [10694/17352 (62%)] Loss: 807.249934\n",
      "Train Epoch: 3 [17153/17352 (99%)] Loss: 788.372303\n",
      "    epoch          : 3\n",
      "    loss           : 807.0321296675924\n",
      "    val_loss       : 779.1332181159446\n",
      "Train Epoch: 4 [512/17352 (3%)] Loss: 761.650696\n",
      "Train Epoch: 4 [10007/17352 (58%)] Loss: 774.819032\n",
      "Train Epoch: 4 [17049/17352 (98%)] Loss: 753.679521\n",
      "    epoch          : 4\n",
      "    loss           : 759.7294062491158\n",
      "    val_loss       : 737.9816687429767\n",
      "Train Epoch: 5 [512/17352 (3%)] Loss: 740.320557\n",
      "Train Epoch: 5 [10769/17352 (62%)] Loss: 711.117188\n",
      "Train Epoch: 5 [17126/17352 (99%)] Loss: 688.558266\n",
      "    epoch          : 5\n",
      "    loss           : 716.5114738402492\n",
      "    val_loss       : 709.3153061423675\n",
      "Train Epoch: 6 [512/17352 (3%)] Loss: 701.597717\n",
      "Train Epoch: 6 [10226/17352 (59%)] Loss: 697.001163\n",
      "Train Epoch: 6 [16887/17352 (97%)] Loss: 672.469727\n",
      "    epoch          : 6\n",
      "    loss           : 689.5768003937434\n",
      "    val_loss       : 682.0122633115749\n",
      "Train Epoch: 7 [512/17352 (3%)] Loss: 683.468140\n",
      "Train Epoch: 7 [10715/17352 (62%)] Loss: 668.534274\n",
      "Train Epoch: 7 [17044/17352 (98%)] Loss: 657.508635\n",
      "    epoch          : 7\n",
      "    loss           : 664.7214878717696\n",
      "    val_loss       : 654.637355117229\n",
      "Train Epoch: 8 [512/17352 (3%)] Loss: 653.197632\n",
      "Train Epoch: 8 [10595/17352 (61%)] Loss: 643.884487\n",
      "Train Epoch: 8 [17263/17352 (99%)] Loss: 641.568780\n",
      "    epoch          : 8\n",
      "    loss           : 642.6397472346753\n",
      "    val_loss       : 641.9689953227435\n",
      "Train Epoch: 9 [512/17352 (3%)] Loss: 636.838501\n",
      "Train Epoch: 9 [10243/17352 (59%)] Loss: 618.531964\n",
      "Train Epoch: 9 [16887/17352 (97%)] Loss: 628.989122\n",
      "    epoch          : 9\n",
      "    loss           : 625.851182165396\n",
      "    val_loss       : 620.8054707492211\n",
      "Train Epoch: 10 [512/17352 (3%)] Loss: 617.142639\n",
      "Train Epoch: 10 [10504/17352 (61%)] Loss: 602.715502\n",
      "Train Epoch: 10 [16883/17352 (97%)] Loss: 614.669422\n",
      "    epoch          : 10\n",
      "    loss           : 608.0107299782466\n",
      "    val_loss       : 606.3689252320412\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch10.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 11 [512/17352 (3%)] Loss: 599.829529\n",
      "Train Epoch: 11 [9856/17352 (57%)] Loss: 594.353802\n",
      "Train Epoch: 11 [17049/17352 (98%)] Loss: 572.737340\n",
      "    epoch          : 11\n",
      "    loss           : 589.1560466204464\n",
      "    val_loss       : 583.7088970461809\n",
      "Train Epoch: 12 [512/17352 (3%)] Loss: 580.293640\n",
      "Train Epoch: 12 [9838/17352 (57%)] Loss: 573.072865\n",
      "Train Epoch: 12 [17064/17352 (98%)] Loss: 562.325140\n",
      "    epoch          : 12\n",
      "    loss           : 571.6043698249614\n",
      "    val_loss       : 566.6876774446403\n",
      "Train Epoch: 13 [512/17352 (3%)] Loss: 559.567139\n",
      "Train Epoch: 13 [10313/17352 (59%)] Loss: 546.554727\n",
      "Train Epoch: 13 [17253/17352 (99%)] Loss: 552.574826\n",
      "    epoch          : 13\n",
      "    loss           : 554.3377147772807\n",
      "    val_loss       : 555.0469169518943\n",
      "Train Epoch: 14 [512/17352 (3%)] Loss: 549.563477\n",
      "Train Epoch: 14 [10999/17352 (63%)] Loss: 535.186003\n",
      "Train Epoch: 14 [16992/17352 (98%)] Loss: 528.709084\n",
      "    epoch          : 14\n",
      "    loss           : 538.8581249125451\n",
      "    val_loss       : 530.7253524807043\n",
      "Train Epoch: 15 [512/17352 (3%)] Loss: 525.337341\n",
      "Train Epoch: 15 [10563/17352 (61%)] Loss: 522.818273\n",
      "Train Epoch: 15 [17016/17352 (98%)] Loss: 508.197311\n",
      "    epoch          : 15\n",
      "    loss           : 520.3709502088925\n",
      "    val_loss       : 517.5462648535655\n",
      "Train Epoch: 16 [512/17352 (3%)] Loss: 513.294739\n",
      "Train Epoch: 16 [10191/17352 (59%)] Loss: 506.723445\n",
      "Train Epoch: 16 [17090/17352 (98%)] Loss: 505.016189\n",
      "    epoch          : 16\n",
      "    loss           : 504.19589999796744\n",
      "    val_loss       : 508.92461532983236\n",
      "Train Epoch: 17 [512/17352 (3%)] Loss: 504.327637\n",
      "Train Epoch: 17 [10427/17352 (60%)] Loss: 482.554975\n",
      "Train Epoch: 17 [16957/17352 (98%)] Loss: 506.731183\n",
      "    epoch          : 17\n",
      "    loss           : 489.6380070283914\n",
      "    val_loss       : 492.2791098442374\n",
      "Train Epoch: 18 [512/17352 (3%)] Loss: 488.386719\n",
      "Train Epoch: 18 [10135/17352 (58%)] Loss: 484.020896\n",
      "Train Epoch: 18 [17335/17352 (100%)] Loss: 476.627063\n",
      "    epoch          : 18\n",
      "    loss           : 471.4904063409093\n",
      "    val_loss       : 466.20004058342937\n",
      "Train Epoch: 19 [512/17352 (3%)] Loss: 460.060852\n",
      "Train Epoch: 19 [10251/17352 (59%)] Loss: 452.875186\n",
      "Train Epoch: 19 [16922/17352 (98%)] Loss: 460.295567\n",
      "    epoch          : 19\n",
      "    loss           : 454.0515869941177\n",
      "    val_loss       : 447.7314153842009\n",
      "Train Epoch: 20 [512/17352 (3%)] Loss: 442.800049\n",
      "Train Epoch: 20 [10151/17352 (59%)] Loss: 437.093987\n",
      "Train Epoch: 20 [16872/17352 (97%)] Loss: 423.770622\n",
      "    epoch          : 20\n",
      "    loss           : 438.47925117463313\n",
      "    val_loss       : 430.7719636325541\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch20.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 21 [512/17352 (3%)] Loss: 426.314911\n",
      "Train Epoch: 21 [10491/17352 (60%)] Loss: 409.750841\n",
      "Train Epoch: 21 [17126/17352 (99%)] Loss: 410.142721\n",
      "    epoch          : 21\n",
      "    loss           : 426.58914603014415\n",
      "    val_loss       : 420.39875114944203\n",
      "Train Epoch: 22 [512/17352 (3%)] Loss: 410.913849\n",
      "Train Epoch: 22 [9965/17352 (57%)] Loss: 393.257812\n",
      "Train Epoch: 22 [16878/17352 (97%)] Loss: 408.709593\n",
      "    epoch          : 22\n",
      "    loss           : 407.36848035717156\n",
      "    val_loss       : 405.10382430485095\n",
      "Train Epoch: 23 [512/17352 (3%)] Loss: 396.571533\n",
      "Train Epoch: 23 [10405/17352 (60%)] Loss: 403.819079\n",
      "Train Epoch: 23 [17133/17352 (99%)] Loss: 377.995094\n",
      "    epoch          : 23\n",
      "    loss           : 389.2372945759221\n",
      "    val_loss       : 387.44475073719383\n",
      "Train Epoch: 24 [512/17352 (3%)] Loss: 381.338165\n",
      "Train Epoch: 24 [9762/17352 (56%)] Loss: 382.154585\n",
      "Train Epoch: 24 [17106/17352 (99%)] Loss: 377.844080\n",
      "    epoch          : 24\n",
      "    loss           : 380.8273288564869\n",
      "    val_loss       : 406.3630321887546\n",
      "Train Epoch: 25 [512/17352 (3%)] Loss: 400.065552\n",
      "Train Epoch: 25 [9896/17352 (57%)] Loss: 378.316388\n",
      "Train Epoch: 25 [16922/17352 (98%)] Loss: 343.311992\n",
      "    epoch          : 25\n",
      "    loss           : 363.95509331022754\n",
      "    val_loss       : 355.8962355011723\n",
      "Train Epoch: 26 [512/17352 (3%)] Loss: 345.056610\n",
      "Train Epoch: 26 [10526/17352 (61%)] Loss: 343.282599\n",
      "Train Epoch: 26 [17101/17352 (99%)] Loss: 355.384158\n",
      "    epoch          : 26\n",
      "    loss           : 343.66605908494745\n",
      "    val_loss       : 337.713581572514\n",
      "Train Epoch: 27 [512/17352 (3%)] Loss: 333.509216\n",
      "Train Epoch: 27 [9710/17352 (56%)] Loss: 349.529935\n",
      "Train Epoch: 27 [17108/17352 (99%)] Loss: 336.174305\n",
      "    epoch          : 27\n",
      "    loss           : 329.5829780943058\n",
      "    val_loss       : 346.6930301029746\n",
      "Train Epoch: 28 [512/17352 (3%)] Loss: 320.180725\n",
      "Train Epoch: 28 [9917/17352 (57%)] Loss: 321.668284\n",
      "Train Epoch: 28 [16958/17352 (98%)] Loss: 290.115334\n",
      "    epoch          : 28\n",
      "    loss           : 317.07005146038875\n",
      "    val_loss       : 312.2574017812623\n",
      "Train Epoch: 29 [512/17352 (3%)] Loss: 308.458862\n",
      "Train Epoch: 29 [10190/17352 (59%)] Loss: 290.788325\n",
      "Train Epoch: 29 [16992/17352 (98%)] Loss: 289.745998\n",
      "    epoch          : 29\n",
      "    loss           : 304.3027975186782\n",
      "    val_loss       : 296.9427296891421\n",
      "Train Epoch: 30 [512/17352 (3%)] Loss: 295.205872\n",
      "Train Epoch: 30 [10295/17352 (59%)] Loss: 320.591129\n",
      "Train Epoch: 30 [16992/17352 (98%)] Loss: 281.789141\n",
      "    epoch          : 30\n",
      "    loss           : 288.3175314653603\n",
      "    val_loss       : 281.3408348705554\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch30.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 31 [512/17352 (3%)] Loss: 277.335083\n",
      "Train Epoch: 31 [10667/17352 (61%)] Loss: 267.114258\n",
      "Train Epoch: 31 [17044/17352 (98%)] Loss: 268.815301\n",
      "    epoch          : 31\n",
      "    loss           : 272.7483872989219\n",
      "    val_loss       : 268.3909285057964\n",
      "Train Epoch: 32 [512/17352 (3%)] Loss: 267.143890\n",
      "Train Epoch: 32 [10581/17352 (61%)] Loss: 274.967122\n",
      "Train Epoch: 32 [16958/17352 (98%)] Loss: 239.440829\n",
      "    epoch          : 32\n",
      "    loss           : 265.5526177382516\n",
      "    val_loss       : 263.88218773006395\n",
      "Train Epoch: 33 [512/17352 (3%)] Loss: 254.554672\n",
      "Train Epoch: 33 [10075/17352 (58%)] Loss: 218.317114\n",
      "Train Epoch: 33 [17126/17352 (99%)] Loss: 248.289410\n",
      "    epoch          : 33\n",
      "    loss           : 250.47797359932642\n",
      "    val_loss       : 245.83079207267573\n",
      "Train Epoch: 34 [512/17352 (3%)] Loss: 241.616425\n",
      "Train Epoch: 34 [10108/17352 (58%)] Loss: 225.263299\n",
      "Train Epoch: 34 [16883/17352 (97%)] Loss: 244.267492\n",
      "    epoch          : 34\n",
      "    loss           : 235.88187483523032\n",
      "    val_loss       : 230.40153884043374\n",
      "Train Epoch: 35 [512/17352 (3%)] Loss: 220.694244\n",
      "Train Epoch: 35 [10108/17352 (58%)] Loss: 194.726101\n",
      "Train Epoch: 35 [17108/17352 (99%)] Loss: 227.785410\n",
      "    epoch          : 35\n",
      "    loss           : 223.21298510920914\n",
      "    val_loss       : 224.93626568068274\n",
      "Train Epoch: 36 [512/17352 (3%)] Loss: 217.823303\n",
      "Train Epoch: 36 [10298/17352 (59%)] Loss: 208.715599\n",
      "Train Epoch: 36 [16957/17352 (98%)] Loss: 186.633577\n",
      "    epoch          : 36\n",
      "    loss           : 210.49941179215145\n",
      "    val_loss       : 207.54336336517164\n",
      "Train Epoch: 37 [512/17352 (3%)] Loss: 196.878357\n",
      "Train Epoch: 37 [10429/17352 (60%)] Loss: 184.971843\n",
      "Train Epoch: 37 [17143/17352 (99%)] Loss: 167.110501\n",
      "    epoch          : 37\n",
      "    loss           : 198.78088857832083\n",
      "    val_loss       : 199.7561307918998\n",
      "Train Epoch: 38 [512/17352 (3%)] Loss: 197.588776\n",
      "Train Epoch: 38 [10365/17352 (60%)] Loss: 214.583243\n",
      "Train Epoch: 38 [17133/17352 (99%)] Loss: 173.995404\n",
      "    epoch          : 38\n",
      "    loss           : 185.98657940280293\n",
      "    val_loss       : 181.36129361693796\n",
      "Train Epoch: 39 [512/17352 (3%)] Loss: 171.839661\n",
      "Train Epoch: 39 [10420/17352 (60%)] Loss: 176.512653\n",
      "Train Epoch: 39 [16922/17352 (98%)] Loss: 198.765910\n",
      "    epoch          : 39\n",
      "    loss           : 177.62676946314446\n",
      "    val_loss       : 194.65906233083\n",
      "Train Epoch: 40 [512/17352 (3%)] Loss: 184.234161\n",
      "Train Epoch: 40 [10017/17352 (58%)] Loss: 168.111735\n",
      "Train Epoch: 40 [16992/17352 (98%)] Loss: 176.422678\n",
      "    epoch          : 40\n",
      "    loss           : 170.33203886637898\n",
      "    val_loss       : 169.18086612278165\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch40.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 41 [512/17352 (3%)] Loss: 160.638275\n",
      "Train Epoch: 41 [10705/17352 (62%)] Loss: 135.760344\n",
      "Train Epoch: 41 [16988/17352 (98%)] Loss: 167.519704\n",
      "    epoch          : 41\n",
      "    loss           : 157.04188853452425\n",
      "    val_loss       : 158.2636951188758\n",
      "Train Epoch: 42 [512/17352 (3%)] Loss: 150.798080\n",
      "Train Epoch: 42 [10394/17352 (60%)] Loss: 158.753494\n",
      "Train Epoch: 42 [17049/17352 (98%)] Loss: 159.446513\n",
      "    epoch          : 42\n",
      "    loss           : 148.95002393183725\n",
      "    val_loss       : 147.02947254474634\n",
      "Train Epoch: 43 [512/17352 (3%)] Loss: 135.300354\n",
      "Train Epoch: 43 [10404/17352 (60%)] Loss: 166.995664\n",
      "Train Epoch: 43 [17153/17352 (99%)] Loss: 125.586302\n",
      "    epoch          : 43\n",
      "    loss           : 140.5638931707762\n",
      "    val_loss       : 144.65012085842872\n",
      "Train Epoch: 44 [512/17352 (3%)] Loss: 136.313873\n",
      "Train Epoch: 44 [10269/17352 (59%)] Loss: 154.374914\n",
      "Train Epoch: 44 [17335/17352 (100%)] Loss: 129.627361\n",
      "    epoch          : 44\n",
      "    loss           : 132.2407353003384\n",
      "    val_loss       : 157.42058215099067\n",
      "Train Epoch: 45 [512/17352 (3%)] Loss: 141.674423\n",
      "Train Epoch: 45 [9592/17352 (55%)] Loss: 173.421802\n",
      "Train Epoch: 45 [17049/17352 (98%)] Loss: 122.190248\n",
      "    epoch          : 45\n",
      "    loss           : 128.0156464364004\n",
      "    val_loss       : 121.2036306249494\n",
      "Train Epoch: 46 [512/17352 (3%)] Loss: 109.540924\n",
      "Train Epoch: 46 [10913/17352 (63%)] Loss: 98.625651\n",
      "Train Epoch: 46 [17277/17352 (100%)] Loss: 84.638672\n",
      "    epoch          : 46\n",
      "    loss           : 108.27856162484271\n",
      "    val_loss       : 118.35527817939328\n",
      "Train Epoch: 47 [512/17352 (3%)] Loss: 114.399689\n",
      "Train Epoch: 47 [10264/17352 (59%)] Loss: 78.802793\n",
      "Train Epoch: 47 [17143/17352 (99%)] Loss: 99.020325\n",
      "    epoch          : 47\n",
      "    loss           : 103.61789530801595\n",
      "    val_loss       : 105.72395759398786\n",
      "Train Epoch: 48 [512/17352 (3%)] Loss: 87.896141\n",
      "Train Epoch: 48 [10189/17352 (59%)] Loss: 69.853211\n",
      "Train Epoch: 48 [17253/17352 (99%)] Loss: 110.087688\n",
      "    epoch          : 48\n",
      "    loss           : 91.9500039972696\n",
      "    val_loss       : 97.10303632265192\n",
      "Train Epoch: 49 [512/17352 (3%)] Loss: 83.104446\n",
      "Train Epoch: 49 [10375/17352 (60%)] Loss: 81.877148\n",
      "Train Epoch: 49 [17153/17352 (99%)] Loss: 97.961024\n",
      "    epoch          : 49\n",
      "    loss           : 90.29287070087797\n",
      "    val_loss       : 107.83076413283207\n",
      "Train Epoch: 50 [512/17352 (3%)] Loss: 97.335831\n",
      "Train Epoch: 50 [10743/17352 (62%)] Loss: 29.056491\n",
      "Train Epoch: 50 [17049/17352 (98%)] Loss: 83.567996\n",
      "    epoch          : 50\n",
      "    loss           : 77.31622416422759\n",
      "    val_loss       : 76.02572935076788\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch50.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 51 [512/17352 (3%)] Loss: 64.637566\n",
      "Train Epoch: 51 [10471/17352 (60%)] Loss: 68.594812\n",
      "Train Epoch: 51 [17263/17352 (99%)] Loss: 61.985523\n",
      "    epoch          : 51\n",
      "    loss           : 69.94847879499902\n",
      "    val_loss       : 85.29110182232975\n",
      "Train Epoch: 52 [512/17352 (3%)] Loss: 76.612999\n",
      "Train Epoch: 52 [10466/17352 (60%)] Loss: 67.628280\n",
      "Train Epoch: 52 [16922/17352 (98%)] Loss: 46.545487\n",
      "    epoch          : 52\n",
      "    loss           : 68.34041089118392\n",
      "    val_loss       : 62.39442864790012\n",
      "Train Epoch: 53 [512/17352 (3%)] Loss: 50.973392\n",
      "Train Epoch: 53 [10416/17352 (60%)] Loss: 32.905095\n",
      "Train Epoch: 53 [17133/17352 (99%)] Loss: 39.254571\n",
      "    epoch          : 53\n",
      "    loss           : 55.76280592610019\n",
      "    val_loss       : 66.79769980943482\n",
      "Train Epoch: 54 [512/17352 (3%)] Loss: 57.415112\n",
      "Train Epoch: 54 [9728/17352 (56%)] Loss: 76.516428\n",
      "Train Epoch: 54 [17016/17352 (98%)] Loss: 49.891597\n",
      "    epoch          : 54\n",
      "    loss           : 56.191957450115616\n",
      "    val_loss       : 61.37654931557038\n",
      "Train Epoch: 55 [512/17352 (3%)] Loss: 43.270260\n",
      "Train Epoch: 55 [10093/17352 (58%)] Loss: 22.612922\n",
      "Train Epoch: 55 [17016/17352 (98%)] Loss: 58.943187\n",
      "    epoch          : 55\n",
      "    loss           : 47.32508294461556\n",
      "    val_loss       : 43.87038642498279\n",
      "Train Epoch: 56 [512/17352 (3%)] Loss: 37.641396\n",
      "Train Epoch: 56 [10215/17352 (59%)] Loss: 37.085891\n",
      "Train Epoch: 56 [17064/17352 (98%)] Loss: 21.410688\n",
      "    epoch          : 56\n",
      "    loss           : 36.21644523721865\n",
      "    val_loss       : 43.68685402480318\n",
      "Train Epoch: 57 [512/17352 (3%)] Loss: 24.679138\n",
      "Train Epoch: 57 [9851/17352 (57%)] Loss: 13.940789\n",
      "Train Epoch: 57 [17126/17352 (99%)] Loss: 18.843585\n",
      "    epoch          : 57\n",
      "    loss           : 33.243627906519244\n",
      "    val_loss       : 35.183651462331106\n",
      "Train Epoch: 58 [512/17352 (3%)] Loss: 19.220428\n",
      "Train Epoch: 58 [10257/17352 (59%)] Loss: -2.983215\n",
      "Train Epoch: 58 [17126/17352 (99%)] Loss: 54.080631\n",
      "    epoch          : 58\n",
      "    loss           : 25.101510157725283\n",
      "    val_loss       : 27.662050167548536\n",
      "Train Epoch: 59 [512/17352 (3%)] Loss: 14.854317\n",
      "Train Epoch: 59 [10426/17352 (60%)] Loss: -7.880484\n",
      "Train Epoch: 59 [16887/17352 (97%)] Loss: -19.374697\n",
      "    epoch          : 59\n",
      "    loss           : 21.67201970343595\n",
      "    val_loss       : 22.187842109395316\n",
      "Train Epoch: 60 [512/17352 (3%)] Loss: 11.605073\n",
      "Train Epoch: 60 [10639/17352 (61%)] Loss: 74.424707\n",
      "Train Epoch: 60 [17106/17352 (99%)] Loss: -33.561351\n",
      "    epoch          : 60\n",
      "    loss           : 20.00138898909921\n",
      "    val_loss       : 44.970178709890384\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch60.pth ...\n",
      "Train Epoch: 61 [512/17352 (3%)] Loss: 25.271900\n",
      "Train Epoch: 61 [9778/17352 (56%)] Loss: -22.776469\n",
      "Train Epoch: 61 [16923/17352 (98%)] Loss: 38.993215\n",
      "    epoch          : 61\n",
      "    loss           : 24.917102774810257\n",
      "    val_loss       : 19.399420335956354\n",
      "Train Epoch: 62 [512/17352 (3%)] Loss: 3.304841\n",
      "Train Epoch: 62 [10783/17352 (62%)] Loss: 81.730544\n",
      "Train Epoch: 62 [16923/17352 (98%)] Loss: 136.751431\n",
      "    epoch          : 62\n",
      "    loss           : 10.492332752077006\n",
      "    val_loss       : 57.68295877568119\n",
      "Train Epoch: 63 [512/17352 (3%)] Loss: 36.453297\n",
      "Train Epoch: 63 [10198/17352 (59%)] Loss: -21.681385\n",
      "Train Epoch: 63 [16957/17352 (98%)] Loss: 72.662013\n",
      "    epoch          : 63\n",
      "    loss           : 16.6120328793312\n",
      "    val_loss       : 8.296526011842868\n",
      "Train Epoch: 64 [512/17352 (3%)] Loss: -6.096947\n",
      "Train Epoch: 64 [10478/17352 (60%)] Loss: -41.939391\n",
      "Train Epoch: 64 [16992/17352 (98%)] Loss: -14.461686\n",
      "    epoch          : 64\n",
      "    loss           : -3.1716628830907383\n",
      "    val_loss       : 2.120961021918637\n",
      "Train Epoch: 65 [512/17352 (3%)] Loss: -17.715500\n",
      "Train Epoch: 65 [10656/17352 (61%)] Loss: 6.598893\n",
      "Train Epoch: 65 [16882/17352 (97%)] Loss: 15.200703\n",
      "    epoch          : 65\n",
      "    loss           : -0.320448549599096\n",
      "    val_loss       : 48.857437690385204\n",
      "Train Epoch: 66 [512/17352 (3%)] Loss: 35.760384\n",
      "Train Epoch: 66 [10770/17352 (62%)] Loss: 37.513094\n",
      "Train Epoch: 66 [17106/17352 (99%)] Loss: -35.826727\n",
      "    epoch          : 66\n",
      "    loss           : 4.814005013061793\n",
      "    val_loss       : 35.59957935242813\n",
      "Train Epoch: 67 [512/17352 (3%)] Loss: 18.206306\n",
      "Train Epoch: 67 [10488/17352 (60%)] Loss: 70.237347\n",
      "Train Epoch: 67 [17263/17352 (99%)] Loss: -17.237170\n",
      "    epoch          : 67\n",
      "    loss           : -0.8737573983587368\n",
      "    val_loss       : 1.7655464137870411\n",
      "Train Epoch: 68 [512/17352 (3%)] Loss: -16.012802\n",
      "Train Epoch: 68 [10649/17352 (61%)] Loss: 50.644834\n",
      "Train Epoch: 68 [16922/17352 (98%)] Loss: -18.830514\n",
      "    epoch          : 68\n",
      "    loss           : -16.484623598103145\n",
      "    val_loss       : -12.61592282166721\n",
      "Train Epoch: 69 [512/17352 (3%)] Loss: -22.914711\n",
      "Train Epoch: 69 [10359/17352 (60%)] Loss: -97.806573\n",
      "Train Epoch: 69 [17049/17352 (98%)] Loss: -104.249134\n",
      "    epoch          : 69\n",
      "    loss           : -24.769596226439095\n",
      "    val_loss       : -22.042760757416634\n",
      "Train Epoch: 70 [512/17352 (3%)] Loss: -43.065498\n",
      "Train Epoch: 70 [10134/17352 (58%)] Loss: -58.372127\n",
      "Train Epoch: 70 [17126/17352 (99%)] Loss: -18.302555\n",
      "    epoch          : 70\n",
      "    loss           : -24.27001419559719\n",
      "    val_loss       : -6.6667435424056425\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch70.pth ...\n",
      "Train Epoch: 71 [512/17352 (3%)] Loss: -23.538517\n",
      "Train Epoch: 71 [10138/17352 (58%)] Loss: -32.663338\n",
      "Train Epoch: 71 [16934/17352 (98%)] Loss: -10.387838\n",
      "    epoch          : 71\n",
      "    loss           : -23.34496641479663\n",
      "    val_loss       : -25.10197901632351\n",
      "Train Epoch: 72 [512/17352 (3%)] Loss: -45.627823\n",
      "Train Epoch: 72 [10304/17352 (59%)] Loss: -70.689110\n",
      "Train Epoch: 72 [17335/17352 (100%)] Loss: 46.025496\n",
      "    epoch          : 72\n",
      "    loss           : -34.0231422141375\n",
      "    val_loss       : -29.682697722526832\n",
      "Train Epoch: 73 [512/17352 (3%)] Loss: -44.431515\n",
      "Train Epoch: 73 [10020/17352 (58%)] Loss: -37.894157\n",
      "Train Epoch: 73 [17090/17352 (98%)] Loss: -0.218911\n",
      "    epoch          : 73\n",
      "    loss           : -38.91159943407541\n",
      "    val_loss       : -29.03867614289848\n",
      "Train Epoch: 74 [512/17352 (3%)] Loss: 42.052910\n",
      "Train Epoch: 74 [10640/17352 (61%)] Loss: -10.903821\n",
      "Train Epoch: 74 [17016/17352 (98%)] Loss: -48.079518\n",
      "    epoch          : 74\n",
      "    loss           : -39.540878221858755\n",
      "    val_loss       : -35.309172639789615\n",
      "Train Epoch: 75 [512/17352 (3%)] Loss: -54.118351\n",
      "Train Epoch: 75 [10363/17352 (60%)] Loss: -53.769763\n",
      "Train Epoch: 75 [17253/17352 (99%)] Loss: -145.757746\n",
      "    epoch          : 75\n",
      "    loss           : -48.011735092712804\n",
      "    val_loss       : -42.57720266695717\n",
      "Train Epoch: 76 [512/17352 (3%)] Loss: -63.821617\n",
      "Train Epoch: 76 [9968/17352 (57%)] Loss: -19.605577\n",
      "Train Epoch: 76 [16887/17352 (97%)] Loss: -16.654278\n",
      "    epoch          : 76\n",
      "    loss           : -55.96988383228248\n",
      "    val_loss       : -52.16389400341326\n",
      "Train Epoch: 77 [512/17352 (3%)] Loss: -74.093018\n",
      "Train Epoch: 77 [10567/17352 (61%)] Loss: -33.479334\n",
      "Train Epoch: 77 [16883/17352 (97%)] Loss: -83.158794\n",
      "    epoch          : 77\n",
      "    loss           : -59.51218363763096\n",
      "    val_loss       : -49.58597982297459\n",
      "Train Epoch: 78 [512/17352 (3%)] Loss: -71.844910\n",
      "Train Epoch: 78 [11032/17352 (64%)] Loss: -57.023996\n",
      "Train Epoch: 78 [17090/17352 (98%)] Loss: 11.799617\n",
      "    epoch          : 78\n",
      "    loss           : -46.02826125407209\n",
      "    val_loss       : -31.44902463524599\n",
      "Train Epoch: 79 [512/17352 (3%)] Loss: -50.586491\n",
      "Train Epoch: 79 [10526/17352 (61%)] Loss: 47.184932\n",
      "Train Epoch: 79 [17064/17352 (98%)] Loss: -74.282081\n",
      "    epoch          : 79\n",
      "    loss           : -30.416289389696395\n",
      "    val_loss       : -32.531642981982735\n",
      "Train Epoch: 80 [512/17352 (3%)] Loss: 48.900696\n",
      "Train Epoch: 80 [10405/17352 (60%)] Loss: -60.890793\n",
      "Train Epoch: 80 [17044/17352 (98%)] Loss: -19.026822\n",
      "    epoch          : 80\n",
      "    loss           : -31.786754727242812\n",
      "    val_loss       : -44.213564582757954\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch80.pth ...\n",
      "Train Epoch: 81 [512/17352 (3%)] Loss: -71.408264\n",
      "Train Epoch: 81 [10585/17352 (61%)] Loss: -51.162348\n",
      "Train Epoch: 81 [17143/17352 (99%)] Loss: -70.717432\n",
      "    epoch          : 81\n",
      "    loss           : -62.30570019781987\n",
      "    val_loss       : -39.90200345462719\n",
      "Train Epoch: 82 [512/17352 (3%)] Loss: -60.680702\n",
      "Train Epoch: 82 [10051/17352 (58%)] Loss: -72.752507\n",
      "Train Epoch: 82 [16988/17352 (98%)] Loss: -39.034017\n",
      "    epoch          : 82\n",
      "    loss           : -72.32029394527625\n",
      "    val_loss       : -69.55476498931586\n",
      "Train Epoch: 83 [512/17352 (3%)] Loss: -96.399300\n",
      "Train Epoch: 83 [10043/17352 (58%)] Loss: -115.965236\n",
      "Train Epoch: 83 [16988/17352 (98%)] Loss: -50.608046\n",
      "    epoch          : 83\n",
      "    loss           : -77.85104759343905\n",
      "    val_loss       : -68.37337482314493\n",
      "Train Epoch: 84 [512/17352 (3%)] Loss: -92.922249\n",
      "Train Epoch: 84 [10188/17352 (59%)] Loss: -57.568836\n",
      "Train Epoch: 84 [17277/17352 (100%)] Loss: -32.857188\n",
      "    epoch          : 84\n",
      "    loss           : -76.35661685060474\n",
      "    val_loss       : -51.01522777358916\n",
      "Train Epoch: 85 [512/17352 (3%)] Loss: -74.830055\n",
      "Train Epoch: 85 [10404/17352 (60%)] Loss: -82.270679\n",
      "Train Epoch: 85 [16958/17352 (98%)] Loss: 31.026089\n",
      "    epoch          : 85\n",
      "    loss           : -56.51064340208788\n",
      "    val_loss       : -65.07156192376456\n",
      "Train Epoch: 86 [512/17352 (3%)] Loss: -90.940216\n",
      "Train Epoch: 86 [10360/17352 (60%)] Loss: -97.242698\n",
      "Train Epoch: 86 [16934/17352 (98%)] Loss: -53.307271\n",
      "    epoch          : 86\n",
      "    loss           : -63.162817553775774\n",
      "    val_loss       : -70.30765740394493\n",
      "Train Epoch: 87 [512/17352 (3%)] Loss: -96.945656\n",
      "Train Epoch: 87 [10322/17352 (59%)] Loss: 5.745953\n",
      "Train Epoch: 87 [17335/17352 (100%)] Loss: -102.503478\n",
      "    epoch          : 87\n",
      "    loss           : -77.20769085810105\n",
      "    val_loss       : 60.809386555370125\n",
      "Train Epoch: 88 [512/17352 (3%)] Loss: 40.174843\n",
      "Train Epoch: 88 [9941/17352 (57%)] Loss: -63.091303\n",
      "Train Epoch: 88 [17253/17352 (99%)] Loss: -122.928216\n",
      "    epoch          : 88\n",
      "    loss           : -75.31162463997214\n",
      "    val_loss       : -84.69416689175027\n",
      "Train Epoch: 89 [512/17352 (3%)] Loss: -119.039810\n",
      "Train Epoch: 89 [10528/17352 (61%)] Loss: -136.489043\n",
      "Train Epoch: 89 [17253/17352 (99%)] Loss: -129.434193\n",
      "    epoch          : 89\n",
      "    loss           : -100.33432366021388\n",
      "    val_loss       : -93.20944221109333\n",
      "Train Epoch: 90 [512/17352 (3%)] Loss: -129.197098\n",
      "Train Epoch: 90 [10057/17352 (58%)] Loss: -65.319912\n",
      "Train Epoch: 90 [16988/17352 (98%)] Loss: -193.710729\n",
      "    epoch          : 90\n",
      "    loss           : -110.8037625278738\n",
      "    val_loss       : -104.47557701461764\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch90.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 91 [512/17352 (3%)] Loss: -25.760622\n",
      "Train Epoch: 91 [10525/17352 (61%)] Loss: -15.010807\n",
      "Train Epoch: 91 [17133/17352 (99%)] Loss: -61.849819\n",
      "    epoch          : 91\n",
      "    loss           : -113.99868558828591\n",
      "    val_loss       : -109.3753211121993\n",
      "Train Epoch: 92 [512/17352 (3%)] Loss: -16.662006\n",
      "Train Epoch: 92 [10194/17352 (59%)] Loss: -184.918774\n",
      "Train Epoch: 92 [16988/17352 (98%)] Loss: -128.542346\n",
      "    epoch          : 92\n",
      "    loss           : -120.71285789750026\n",
      "    val_loss       : -115.98188627313708\n",
      "Train Epoch: 93 [512/17352 (3%)] Loss: -149.977509\n",
      "Train Epoch: 93 [10707/17352 (62%)] Loss: -78.036768\n",
      "Train Epoch: 93 [17277/17352 (100%)] Loss: -135.486127\n",
      "    epoch          : 93\n",
      "    loss           : -125.37896236396526\n",
      "    val_loss       : -108.22260086495676\n",
      "Train Epoch: 94 [512/17352 (3%)] Loss: -145.150024\n",
      "Train Epoch: 94 [10263/17352 (59%)] Loss: -97.217316\n",
      "Train Epoch: 94 [17277/17352 (100%)] Loss: -103.587926\n",
      "    epoch          : 94\n",
      "    loss           : -122.22095077298388\n",
      "    val_loss       : -108.9376074304694\n",
      "Train Epoch: 95 [512/17352 (3%)] Loss: -142.667816\n",
      "Train Epoch: 95 [10042/17352 (58%)] Loss: -122.137607\n",
      "Train Epoch: 95 [16923/17352 (98%)] Loss: -102.305527\n",
      "    epoch          : 95\n",
      "    loss           : -132.3691923256898\n",
      "    val_loss       : -123.06316192861925\n",
      "Train Epoch: 96 [512/17352 (3%)] Loss: -106.591415\n",
      "Train Epoch: 96 [10819/17352 (62%)] Loss: -60.032432\n",
      "Train Epoch: 96 [17126/17352 (99%)] Loss: -197.571443\n",
      "    epoch          : 96\n",
      "    loss           : -122.55723559366567\n",
      "    val_loss       : -117.93614613327031\n",
      "Train Epoch: 97 [512/17352 (3%)] Loss: -164.671722\n",
      "Train Epoch: 97 [9868/17352 (57%)] Loss: -106.599737\n",
      "Train Epoch: 97 [16957/17352 (98%)] Loss: -189.060040\n",
      "    epoch          : 97\n",
      "    loss           : -137.23565178324688\n",
      "    val_loss       : -131.47464506147452\n",
      "Train Epoch: 98 [512/17352 (3%)] Loss: -175.611542\n",
      "Train Epoch: 98 [10510/17352 (61%)] Loss: -47.383080\n",
      "Train Epoch: 98 [16939/17352 (98%)] Loss: -98.766458\n",
      "    epoch          : 98\n",
      "    loss           : -104.78739552503309\n",
      "    val_loss       : -74.1804222487743\n",
      "Train Epoch: 99 [512/17352 (3%)] Loss: -113.085007\n",
      "Train Epoch: 99 [10488/17352 (60%)] Loss: -184.174701\n",
      "Train Epoch: 99 [17090/17352 (98%)] Loss: -80.487039\n",
      "    epoch          : 99\n",
      "    loss           : -111.89926051014531\n",
      "    val_loss       : -78.9558893878858\n",
      "Train Epoch: 100 [512/17352 (3%)] Loss: -118.670090\n",
      "Train Epoch: 100 [10541/17352 (61%)] Loss: -106.352713\n",
      "Train Epoch: 100 [16878/17352 (97%)] Loss: -9.817647\n",
      "    epoch          : 100\n",
      "    loss           : -123.26168893023574\n",
      "    val_loss       : -26.4857116765738\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch100.pth ...\n",
      "Train Epoch: 101 [512/17352 (3%)] Loss: -23.979801\n",
      "Train Epoch: 101 [10051/17352 (58%)] Loss: -44.116591\n",
      "Train Epoch: 101 [17108/17352 (99%)] Loss: -177.479064\n",
      "    epoch          : 101\n",
      "    loss           : -112.55598074349929\n",
      "    val_loss       : -125.60715050653258\n",
      "Train Epoch: 102 [512/17352 (3%)] Loss: -162.541138\n",
      "Train Epoch: 102 [10645/17352 (61%)] Loss: -58.967881\n",
      "Train Epoch: 102 [17335/17352 (100%)] Loss: -241.209746\n",
      "    epoch          : 102\n",
      "    loss           : -148.2504580379659\n",
      "    val_loss       : -129.50675922049967\n",
      "Train Epoch: 103 [512/17352 (3%)] Loss: -183.347351\n",
      "Train Epoch: 103 [10548/17352 (61%)] Loss: -78.846305\n",
      "Train Epoch: 103 [17124/17352 (99%)] Loss: -148.741061\n",
      "    epoch          : 103\n",
      "    loss           : -153.5960884224383\n",
      "    val_loss       : -140.52902364869175\n",
      "Train Epoch: 104 [512/17352 (3%)] Loss: -182.061371\n",
      "Train Epoch: 104 [10545/17352 (61%)] Loss: -230.176230\n",
      "Train Epoch: 104 [17016/17352 (98%)] Loss: -147.447828\n",
      "    epoch          : 104\n",
      "    loss           : -162.19744754328295\n",
      "    val_loss       : -159.6684055907822\n",
      "Train Epoch: 105 [512/17352 (3%)] Loss: -200.759109\n",
      "Train Epoch: 105 [10745/17352 (62%)] Loss: -228.002729\n",
      "Train Epoch: 105 [16878/17352 (97%)] Loss: -159.873755\n",
      "    epoch          : 105\n",
      "    loss           : -167.20167151291773\n",
      "    val_loss       : -157.9424595484261\n",
      "Train Epoch: 106 [512/17352 (3%)] Loss: -207.345474\n",
      "Train Epoch: 106 [10049/17352 (58%)] Loss: -274.156288\n",
      "Train Epoch: 106 [17101/17352 (99%)] Loss: -159.257685\n",
      "    epoch          : 106\n",
      "    loss           : -183.24404566763656\n",
      "    val_loss       : -163.83768249700202\n",
      "Train Epoch: 107 [512/17352 (3%)] Loss: -203.422760\n",
      "Train Epoch: 107 [10503/17352 (61%)] Loss: -47.489189\n",
      "Train Epoch: 107 [16988/17352 (98%)] Loss: -156.896566\n",
      "    epoch          : 107\n",
      "    loss           : -193.0255426085816\n",
      "    val_loss       : -181.44291703322605\n",
      "Train Epoch: 108 [512/17352 (3%)] Loss: -232.015381\n",
      "Train Epoch: 108 [9692/17352 (56%)] Loss: -221.130145\n",
      "Train Epoch: 108 [16883/17352 (97%)] Loss: -271.662816\n",
      "    epoch          : 108\n",
      "    loss           : -195.1407384773914\n",
      "    val_loss       : -184.13410437059414\n",
      "Train Epoch: 109 [512/17352 (3%)] Loss: -201.954712\n",
      "Train Epoch: 109 [10711/17352 (62%)] Loss: -99.980714\n",
      "Train Epoch: 109 [16934/17352 (98%)] Loss: -129.969278\n",
      "    epoch          : 109\n",
      "    loss           : -201.50894313073627\n",
      "    val_loss       : -181.26756523563833\n",
      "Train Epoch: 110 [512/17352 (3%)] Loss: -230.497070\n",
      "Train Epoch: 110 [9894/17352 (57%)] Loss: -138.336727\n",
      "Train Epoch: 110 [16878/17352 (97%)] Loss: -78.278307\n",
      "    epoch          : 110\n",
      "    loss           : -181.82155280572834\n",
      "    val_loss       : -43.75202112097638\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch110.pth ...\n",
      "Train Epoch: 111 [512/17352 (3%)] Loss: -105.954315\n",
      "Train Epoch: 111 [10649/17352 (61%)] Loss: -121.910017\n",
      "Train Epoch: 111 [17064/17352 (98%)] Loss: -25.773332\n",
      "    epoch          : 111\n",
      "    loss           : -160.70609280903528\n",
      "    val_loss       : -172.76046125011084\n",
      "Train Epoch: 112 [512/17352 (3%)] Loss: -220.307770\n",
      "Train Epoch: 112 [10345/17352 (60%)] Loss: -155.705031\n",
      "Train Epoch: 112 [16887/17352 (97%)] Loss: -221.160923\n",
      "    epoch          : 112\n",
      "    loss           : -199.3288518213356\n",
      "    val_loss       : -199.17087915334002\n",
      "Train Epoch: 113 [512/17352 (3%)] Loss: -244.816803\n",
      "Train Epoch: 113 [10609/17352 (61%)] Loss: -175.705694\n",
      "Train Epoch: 113 [17106/17352 (99%)] Loss: -341.767657\n",
      "    epoch          : 113\n",
      "    loss           : -220.29439683930065\n",
      "    val_loss       : -203.21724619492377\n",
      "Train Epoch: 114 [512/17352 (3%)] Loss: -247.049927\n",
      "Train Epoch: 114 [9745/17352 (56%)] Loss: -272.800400\n",
      "Train Epoch: 114 [17044/17352 (98%)] Loss: -28.931862\n",
      "    epoch          : 114\n",
      "    loss           : -203.21751276477272\n",
      "    val_loss       : -90.65721597364264\n",
      "Train Epoch: 115 [512/17352 (3%)] Loss: -189.000198\n",
      "Train Epoch: 115 [10369/17352 (60%)] Loss: -109.416829\n",
      "Train Epoch: 115 [16958/17352 (98%)] Loss: -218.452378\n",
      "    epoch          : 115\n",
      "    loss           : -181.6943895278832\n",
      "    val_loss       : -190.99645037490055\n",
      "Train Epoch: 116 [512/17352 (3%)] Loss: -239.904449\n",
      "Train Epoch: 116 [10351/17352 (60%)] Loss: -69.760853\n",
      "Train Epoch: 116 [17106/17352 (99%)] Loss: -252.243882\n",
      "    epoch          : 116\n",
      "    loss           : -234.0738887919995\n",
      "    val_loss       : -230.48245489285728\n",
      "Train Epoch: 117 [512/17352 (3%)] Loss: -278.539307\n",
      "Train Epoch: 117 [10312/17352 (59%)] Loss: -270.379720\n",
      "Train Epoch: 117 [17153/17352 (99%)] Loss: -302.107496\n",
      "    epoch          : 117\n",
      "    loss           : -243.7417090084126\n",
      "    val_loss       : -223.44824745747712\n",
      "Train Epoch: 118 [512/17352 (3%)] Loss: -289.168365\n",
      "Train Epoch: 118 [9978/17352 (58%)] Loss: -306.817240\n",
      "Train Epoch: 118 [17124/17352 (99%)] Loss: -331.194448\n",
      "    epoch          : 118\n",
      "    loss           : -258.16135072309027\n",
      "    val_loss       : -215.46254942685596\n",
      "Train Epoch: 119 [512/17352 (3%)] Loss: -281.772827\n",
      "Train Epoch: 119 [10442/17352 (60%)] Loss: -181.733740\n",
      "Train Epoch: 119 [17090/17352 (98%)] Loss: -236.558680\n",
      "    epoch          : 119\n",
      "    loss           : -218.67936705517633\n",
      "    val_loss       : -133.17627464529252\n",
      "Train Epoch: 120 [512/17352 (3%)] Loss: -180.594696\n",
      "Train Epoch: 120 [9988/17352 (58%)] Loss: -264.750356\n",
      "Train Epoch: 120 [17064/17352 (98%)] Loss: -172.609084\n",
      "    epoch          : 120\n",
      "    loss           : -210.5001620962334\n",
      "    val_loss       : -176.23106330544366\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch120.pth ...\n",
      "Train Epoch: 121 [512/17352 (3%)] Loss: -259.603760\n",
      "Train Epoch: 121 [9931/17352 (57%)] Loss: -278.075418\n",
      "Train Epoch: 121 [16887/17352 (97%)] Loss: -280.362370\n",
      "    epoch          : 121\n",
      "    loss           : -226.89995008091338\n",
      "    val_loss       : -232.6684118200228\n",
      "Train Epoch: 122 [512/17352 (3%)] Loss: -281.725464\n",
      "Train Epoch: 122 [10309/17352 (59%)] Loss: -290.365183\n",
      "Train Epoch: 122 [17049/17352 (98%)] Loss: -261.036241\n",
      "    epoch          : 122\n",
      "    loss           : -267.148001391471\n",
      "    val_loss       : -249.13165087568262\n",
      "Train Epoch: 123 [512/17352 (3%)] Loss: -309.561371\n",
      "Train Epoch: 123 [10345/17352 (60%)] Loss: -245.905273\n",
      "Train Epoch: 123 [16934/17352 (98%)] Loss: -401.683569\n",
      "    epoch          : 123\n",
      "    loss           : -285.01053129987326\n",
      "    val_loss       : -274.3402294381537\n",
      "Train Epoch: 124 [512/17352 (3%)] Loss: -325.904999\n",
      "Train Epoch: 124 [10580/17352 (61%)] Loss: -359.307081\n",
      "Train Epoch: 124 [17133/17352 (99%)] Loss: -224.664431\n",
      "    epoch          : 124\n",
      "    loss           : -290.5530565779409\n",
      "    val_loss       : -263.45746188893884\n",
      "Train Epoch: 125 [512/17352 (3%)] Loss: -322.908661\n",
      "Train Epoch: 125 [10641/17352 (61%)] Loss: -257.540712\n",
      "Train Epoch: 125 [16883/17352 (97%)] Loss: -348.554578\n",
      "    epoch          : 125\n",
      "    loss           : -305.01286256804354\n",
      "    val_loss       : -287.6605844877692\n",
      "Train Epoch: 126 [512/17352 (3%)] Loss: -352.906372\n",
      "Train Epoch: 126 [10212/17352 (59%)] Loss: -382.121511\n",
      "Train Epoch: 126 [16934/17352 (98%)] Loss: -301.606417\n",
      "    epoch          : 126\n",
      "    loss           : -310.9050259088945\n",
      "    val_loss       : -284.62753793206593\n",
      "Train Epoch: 127 [512/17352 (3%)] Loss: -342.566498\n",
      "Train Epoch: 127 [10629/17352 (61%)] Loss: -374.837302\n",
      "Train Epoch: 127 [16958/17352 (98%)] Loss: -246.252410\n",
      "    epoch          : 127\n",
      "    loss           : -312.6278926680403\n",
      "    val_loss       : -292.9637179897915\n",
      "Train Epoch: 128 [512/17352 (3%)] Loss: -351.134491\n",
      "Train Epoch: 128 [10401/17352 (60%)] Loss: -350.016061\n",
      "Train Epoch: 128 [16957/17352 (98%)] Loss: -344.540853\n",
      "    epoch          : 128\n",
      "    loss           : -313.1126707719453\n",
      "    val_loss       : -287.9615579726101\n",
      "Train Epoch: 129 [512/17352 (3%)] Loss: -359.312592\n",
      "Train Epoch: 129 [9867/17352 (57%)] Loss: -203.601939\n",
      "Train Epoch: 129 [17277/17352 (100%)] Loss: -247.466856\n",
      "    epoch          : 129\n",
      "    loss           : -321.33929966011726\n",
      "    val_loss       : -287.9491044708989\n",
      "Train Epoch: 130 [512/17352 (3%)] Loss: -328.235657\n",
      "Train Epoch: 130 [10519/17352 (61%)] Loss: -204.113926\n",
      "Train Epoch: 130 [16957/17352 (98%)] Loss: -374.717640\n",
      "    epoch          : 130\n",
      "    loss           : -309.19192776381334\n",
      "    val_loss       : -286.9502644306617\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch130.pth ...\n",
      "Train Epoch: 131 [512/17352 (3%)] Loss: -330.261292\n",
      "Train Epoch: 131 [10218/17352 (59%)] Loss: -408.876999\n",
      "Train Epoch: 131 [17126/17352 (99%)] Loss: 151.569513\n",
      "    epoch          : 131\n",
      "    loss           : -246.53301943992446\n",
      "    val_loss       : -7.531596128981284\n",
      "Train Epoch: 132 [512/17352 (3%)] Loss: -93.308632\n",
      "Train Epoch: 132 [10511/17352 (61%)] Loss: -257.811942\n",
      "Train Epoch: 132 [16923/17352 (98%)] Loss: -345.583906\n",
      "    epoch          : 132\n",
      "    loss           : -222.28907830719433\n",
      "    val_loss       : -255.9730737098903\n",
      "Train Epoch: 133 [512/17352 (3%)] Loss: -323.641296\n",
      "Train Epoch: 133 [10281/17352 (59%)] Loss: -293.940805\n",
      "Train Epoch: 133 [17090/17352 (98%)] Loss: -370.984844\n",
      "    epoch          : 133\n",
      "    loss           : -305.46438247358276\n",
      "    val_loss       : -293.8077530938348\n",
      "Train Epoch: 134 [512/17352 (3%)] Loss: -342.646942\n",
      "Train Epoch: 134 [10198/17352 (59%)] Loss: -345.809053\n",
      "Train Epoch: 134 [17106/17352 (99%)] Loss: -213.771966\n",
      "    epoch          : 134\n",
      "    loss           : -327.2843442772369\n",
      "    val_loss       : -299.5656436759358\n",
      "Train Epoch: 135 [512/17352 (3%)] Loss: -373.704224\n",
      "Train Epoch: 135 [10224/17352 (59%)] Loss: -330.209956\n",
      "Train Epoch: 135 [17106/17352 (99%)] Loss: -424.981916\n",
      "    epoch          : 135\n",
      "    loss           : -337.17916280674325\n",
      "    val_loss       : -299.5373342107747\n",
      "Train Epoch: 136 [512/17352 (3%)] Loss: -345.897217\n",
      "Train Epoch: 136 [10262/17352 (59%)] Loss: -204.130712\n",
      "Train Epoch: 136 [16882/17352 (97%)] Loss: -355.532617\n",
      "    epoch          : 136\n",
      "    loss           : -336.827689154989\n",
      "    val_loss       : -312.5114869758954\n",
      "Train Epoch: 137 [512/17352 (3%)] Loss: -367.799683\n",
      "Train Epoch: 137 [10186/17352 (59%)] Loss: -370.342537\n",
      "Train Epoch: 137 [16958/17352 (98%)] Loss: -407.836815\n",
      "    epoch          : 137\n",
      "    loss           : -344.88912099928996\n",
      "    val_loss       : -310.9514018181898\n",
      "Train Epoch: 138 [512/17352 (3%)] Loss: -382.794128\n",
      "Train Epoch: 138 [10462/17352 (60%)] Loss: -378.564475\n",
      "Train Epoch: 138 [17126/17352 (99%)] Loss: -392.502085\n",
      "    epoch          : 138\n",
      "    loss           : -341.9087901037001\n",
      "    val_loss       : -308.9522353231985\n",
      "Train Epoch: 139 [512/17352 (3%)] Loss: -383.633026\n",
      "Train Epoch: 139 [9945/17352 (57%)] Loss: -402.859726\n",
      "Train Epoch: 139 [17090/17352 (98%)] Loss: -435.701297\n",
      "    epoch          : 139\n",
      "    loss           : -359.83816172467226\n",
      "    val_loss       : -304.73946336891987\n",
      "Train Epoch: 140 [512/17352 (3%)] Loss: -379.471313\n",
      "Train Epoch: 140 [10506/17352 (61%)] Loss: -399.864629\n",
      "Train Epoch: 140 [17124/17352 (99%)] Loss: -454.571940\n",
      "    epoch          : 140\n",
      "    loss           : -351.66891853288706\n",
      "    val_loss       : -329.8272640876468\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch140.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 141 [512/17352 (3%)] Loss: -386.671967\n",
      "Train Epoch: 141 [9931/17352 (57%)] Loss: -442.382113\n",
      "Train Epoch: 141 [16878/17352 (97%)] Loss: -444.060106\n",
      "    epoch          : 141\n",
      "    loss           : -351.9662960921849\n",
      "    val_loss       : -324.8405163040621\n",
      "Train Epoch: 142 [512/17352 (3%)] Loss: -410.830383\n",
      "Train Epoch: 142 [10641/17352 (61%)] Loss: -257.470096\n",
      "Train Epoch: 142 [16923/17352 (98%)] Loss: -476.348381\n",
      "    epoch          : 142\n",
      "    loss           : -373.5961404339717\n",
      "    val_loss       : -343.7421138218227\n",
      "Train Epoch: 143 [512/17352 (3%)] Loss: -397.130341\n",
      "Train Epoch: 143 [10549/17352 (61%)] Loss: -416.569718\n",
      "Train Epoch: 143 [17253/17352 (99%)] Loss: -321.570140\n",
      "    epoch          : 143\n",
      "    loss           : -358.48028446464923\n",
      "    val_loss       : -310.41697154669\n",
      "Train Epoch: 144 [512/17352 (3%)] Loss: -388.151123\n",
      "Train Epoch: 144 [10288/17352 (59%)] Loss: -395.787374\n",
      "Train Epoch: 144 [16934/17352 (98%)] Loss: -459.829588\n",
      "    epoch          : 144\n",
      "    loss           : -372.2716723091958\n",
      "    val_loss       : -347.0914417397525\n",
      "Train Epoch: 145 [512/17352 (3%)] Loss: -369.973572\n",
      "Train Epoch: 145 [10253/17352 (59%)] Loss: -362.471842\n",
      "Train Epoch: 145 [17153/17352 (99%)] Loss: -465.668659\n",
      "    epoch          : 145\n",
      "    loss           : -355.8476640859498\n",
      "    val_loss       : -327.9277952590502\n",
      "Train Epoch: 146 [512/17352 (3%)] Loss: -217.095459\n",
      "Train Epoch: 146 [10403/17352 (60%)] Loss: -375.605959\n",
      "Train Epoch: 146 [16988/17352 (98%)] Loss: -440.211032\n",
      "    epoch          : 146\n",
      "    loss           : -343.3550336922205\n",
      "    val_loss       : -329.53000707956846\n",
      "Train Epoch: 147 [512/17352 (3%)] Loss: -419.200989\n",
      "Train Epoch: 147 [10194/17352 (59%)] Loss: -147.672510\n",
      "Train Epoch: 147 [17133/17352 (99%)] Loss: -429.365148\n",
      "    epoch          : 147\n",
      "    loss           : -353.8189845453746\n",
      "    val_loss       : -308.1051700738983\n",
      "Train Epoch: 148 [512/17352 (3%)] Loss: -252.252945\n",
      "Train Epoch: 148 [10370/17352 (60%)] Loss: -472.891602\n",
      "Train Epoch: 148 [16923/17352 (98%)] Loss: -437.178239\n",
      "    epoch          : 148\n",
      "    loss           : -366.08568934566574\n",
      "    val_loss       : -344.022997093275\n",
      "Train Epoch: 149 [512/17352 (3%)] Loss: -414.483643\n",
      "Train Epoch: 149 [9731/17352 (56%)] Loss: -260.875103\n",
      "Train Epoch: 149 [16887/17352 (97%)] Loss: -416.679573\n",
      "    epoch          : 149\n",
      "    loss           : -382.62775553799776\n",
      "    val_loss       : -348.7609888479979\n",
      "Train Epoch: 150 [512/17352 (3%)] Loss: -442.885590\n",
      "Train Epoch: 150 [10430/17352 (60%)] Loss: -348.758917\n",
      "Train Epoch: 150 [16872/17352 (97%)] Loss: -439.257420\n",
      "    epoch          : 150\n",
      "    loss           : -365.1997457404139\n",
      "    val_loss       : -358.2337908688823\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch150.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 151 [512/17352 (3%)] Loss: -432.640076\n",
      "Train Epoch: 151 [10140/17352 (58%)] Loss: -460.814122\n",
      "Train Epoch: 151 [16988/17352 (98%)] Loss: -379.770218\n",
      "    epoch          : 151\n",
      "    loss           : -341.6475525735111\n",
      "    val_loss       : -218.94638812186412\n",
      "Train Epoch: 152 [512/17352 (3%)] Loss: -151.779068\n",
      "Train Epoch: 152 [10944/17352 (63%)] Loss: -449.065871\n",
      "Train Epoch: 152 [17126/17352 (99%)] Loss: -352.981698\n",
      "    epoch          : 152\n",
      "    loss           : -343.5671310295979\n",
      "    val_loss       : -337.7054208357385\n",
      "Train Epoch: 153 [512/17352 (3%)] Loss: -402.199036\n",
      "Train Epoch: 153 [10534/17352 (61%)] Loss: -437.353682\n",
      "Train Epoch: 153 [16992/17352 (98%)] Loss: -228.030136\n",
      "    epoch          : 153\n",
      "    loss           : -389.98431684014736\n",
      "    val_loss       : -298.24355420730006\n",
      "Train Epoch: 154 [512/17352 (3%)] Loss: -329.405579\n",
      "Train Epoch: 154 [10942/17352 (63%)] Loss: -200.189294\n",
      "Train Epoch: 154 [17263/17352 (99%)] Loss: -237.461943\n",
      "    epoch          : 154\n",
      "    loss           : -375.9211063001716\n",
      "    val_loss       : -271.24295388284827\n",
      "Train Epoch: 155 [512/17352 (3%)] Loss: -182.690979\n",
      "Train Epoch: 155 [10890/17352 (63%)] Loss: -448.364714\n",
      "Train Epoch: 155 [17044/17352 (98%)] Loss: -379.026224\n",
      "    epoch          : 155\n",
      "    loss           : -405.61215314932997\n",
      "    val_loss       : -361.5987069733223\n",
      "Train Epoch: 156 [512/17352 (3%)] Loss: -443.578735\n",
      "Train Epoch: 156 [10405/17352 (60%)] Loss: -467.204020\n",
      "Train Epoch: 156 [17044/17352 (98%)] Loss: -432.369081\n",
      "    epoch          : 156\n",
      "    loss           : -408.90912561865616\n",
      "    val_loss       : -370.6434228920861\n",
      "Train Epoch: 157 [512/17352 (3%)] Loss: -450.831909\n",
      "Train Epoch: 157 [10224/17352 (59%)] Loss: -473.730645\n",
      "Train Epoch: 157 [17263/17352 (99%)] Loss: -407.331444\n",
      "    epoch          : 157\n",
      "    loss           : -415.2904037106903\n",
      "    val_loss       : -384.6063791361308\n",
      "Train Epoch: 158 [512/17352 (3%)] Loss: -460.874878\n",
      "Train Epoch: 158 [10198/17352 (59%)] Loss: -507.686748\n",
      "Train Epoch: 158 [16934/17352 (98%)] Loss: -380.937586\n",
      "    epoch          : 158\n",
      "    loss           : -417.2496119707968\n",
      "    val_loss       : -348.6210767488127\n",
      "Train Epoch: 159 [512/17352 (3%)] Loss: -432.288239\n",
      "Train Epoch: 159 [10389/17352 (60%)] Loss: -497.030140\n",
      "Train Epoch: 159 [17090/17352 (98%)] Loss: -315.110956\n",
      "    epoch          : 159\n",
      "    loss           : -415.36310893670856\n",
      "    val_loss       : -364.9195611079841\n",
      "Train Epoch: 160 [512/17352 (3%)] Loss: -430.314026\n",
      "Train Epoch: 160 [10713/17352 (62%)] Loss: -463.529505\n",
      "Train Epoch: 160 [17335/17352 (100%)] Loss: -450.916646\n",
      "    epoch          : 160\n",
      "    loss           : -414.37273406026577\n",
      "    val_loss       : -243.60772712856752\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch160.pth ...\n",
      "Train Epoch: 161 [512/17352 (3%)] Loss: -313.618195\n",
      "Train Epoch: 161 [10233/17352 (59%)] Loss: -236.956322\n",
      "Train Epoch: 161 [17106/17352 (99%)] Loss: 10.664721\n",
      "    epoch          : 161\n",
      "    loss           : -284.82203956742507\n",
      "    val_loss       : 387.0355205708107\n",
      "Train Epoch: 162 [512/17352 (3%)] Loss: 146.987518\n",
      "Train Epoch: 162 [9927/17352 (57%)] Loss: -319.986805\n",
      "Train Epoch: 162 [16878/17352 (97%)] Loss: -454.517297\n",
      "    epoch          : 162\n",
      "    loss           : -301.37945557498506\n",
      "    val_loss       : -361.32633354630246\n",
      "Train Epoch: 163 [512/17352 (3%)] Loss: -438.965027\n",
      "Train Epoch: 163 [10028/17352 (58%)] Loss: -468.756094\n",
      "Train Epoch: 163 [17106/17352 (99%)] Loss: -385.273734\n",
      "    epoch          : 163\n",
      "    loss           : -411.50690891692614\n",
      "    val_loss       : -391.78454692789836\n",
      "Train Epoch: 164 [512/17352 (3%)] Loss: -440.415253\n",
      "Train Epoch: 164 [10314/17352 (59%)] Loss: -506.375316\n",
      "Train Epoch: 164 [16958/17352 (98%)] Loss: -507.756858\n",
      "    epoch          : 164\n",
      "    loss           : -446.3908342912601\n",
      "    val_loss       : -395.69061342760557\n",
      "Train Epoch: 165 [512/17352 (3%)] Loss: -485.212952\n",
      "Train Epoch: 165 [10989/17352 (63%)] Loss: -328.916095\n",
      "Train Epoch: 165 [17253/17352 (99%)] Loss: -479.698679\n",
      "    epoch          : 165\n",
      "    loss           : -447.5182361872604\n",
      "    val_loss       : -395.0311301732035\n",
      "Train Epoch: 166 [512/17352 (3%)] Loss: -489.467163\n",
      "Train Epoch: 166 [10688/17352 (62%)] Loss: -323.686761\n",
      "Train Epoch: 166 [16992/17352 (98%)] Loss: -309.655577\n",
      "    epoch          : 166\n",
      "    loss           : -455.6490243914309\n",
      "    val_loss       : -414.69252162092994\n",
      "Train Epoch: 167 [512/17352 (3%)] Loss: -491.423889\n",
      "Train Epoch: 167 [10185/17352 (59%)] Loss: -384.614600\n",
      "Train Epoch: 167 [17108/17352 (99%)] Loss: -522.230308\n",
      "    epoch          : 167\n",
      "    loss           : -467.8466558009142\n",
      "    val_loss       : -428.28043695603037\n",
      "Train Epoch: 168 [512/17352 (3%)] Loss: -504.737946\n",
      "Train Epoch: 168 [10009/17352 (58%)] Loss: -404.337987\n",
      "Train Epoch: 168 [16887/17352 (97%)] Loss: -538.489873\n",
      "    epoch          : 168\n",
      "    loss           : -458.88643948555426\n",
      "    val_loss       : -412.5922776660767\n",
      "Train Epoch: 169 [512/17352 (3%)] Loss: -488.468231\n",
      "Train Epoch: 169 [10294/17352 (59%)] Loss: -514.094064\n",
      "Train Epoch: 169 [17277/17352 (100%)] Loss: -477.227078\n",
      "    epoch          : 169\n",
      "    loss           : -468.3537238462112\n",
      "    val_loss       : -421.03153034808645\n",
      "Train Epoch: 170 [512/17352 (3%)] Loss: -497.482727\n",
      "Train Epoch: 170 [9905/17352 (57%)] Loss: -400.803504\n",
      "Train Epoch: 170 [16883/17352 (97%)] Loss: -429.056983\n",
      "    epoch          : 170\n",
      "    loss           : -469.0103064417453\n",
      "    val_loss       : -428.3771432504195\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch170.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 171 [512/17352 (3%)] Loss: -496.296204\n",
      "Train Epoch: 171 [10647/17352 (61%)] Loss: -437.487263\n",
      "Train Epoch: 171 [17335/17352 (100%)] Loss: -460.369553\n",
      "    epoch          : 171\n",
      "    loss           : -428.89238975300157\n",
      "    val_loss       : -331.5064965569527\n",
      "Train Epoch: 172 [512/17352 (3%)] Loss: -363.844666\n",
      "Train Epoch: 172 [10221/17352 (59%)] Loss: -478.284638\n",
      "Train Epoch: 172 [17090/17352 (98%)] Loss: -458.056526\n",
      "    epoch          : 172\n",
      "    loss           : -422.6788301850585\n",
      "    val_loss       : -397.2843005352503\n",
      "Train Epoch: 173 [512/17352 (3%)] Loss: -493.891937\n",
      "Train Epoch: 173 [10704/17352 (62%)] Loss: -421.687350\n",
      "Train Epoch: 173 [16939/17352 (98%)] Loss: -329.916142\n",
      "    epoch          : 173\n",
      "    loss           : -465.5186807760027\n",
      "    val_loss       : -420.1939051322139\n",
      "Train Epoch: 174 [512/17352 (3%)] Loss: -495.625916\n",
      "Train Epoch: 174 [10370/17352 (60%)] Loss: -429.746512\n",
      "Train Epoch: 174 [17044/17352 (98%)] Loss: -315.827214\n",
      "    epoch          : 174\n",
      "    loss           : -484.4679744350395\n",
      "    val_loss       : -437.87888336857964\n",
      "Train Epoch: 175 [512/17352 (3%)] Loss: -521.170776\n",
      "Train Epoch: 175 [10177/17352 (59%)] Loss: -476.345161\n",
      "Train Epoch: 175 [17016/17352 (98%)] Loss: 238.425052\n",
      "    epoch          : 175\n",
      "    loss           : -429.62863538618365\n",
      "    val_loss       : -82.31908761515858\n",
      "Train Epoch: 176 [512/17352 (3%)] Loss: -165.234558\n",
      "Train Epoch: 176 [10501/17352 (61%)] Loss: -393.869792\n",
      "Train Epoch: 176 [17044/17352 (98%)] Loss: -405.074392\n",
      "    epoch          : 176\n",
      "    loss           : -397.6807250827735\n",
      "    val_loss       : -397.04627366488904\n",
      "Train Epoch: 177 [512/17352 (3%)] Loss: -479.049103\n",
      "Train Epoch: 177 [10324/17352 (59%)] Loss: -434.635828\n",
      "Train Epoch: 177 [16878/17352 (97%)] Loss: -184.624480\n",
      "    epoch          : 177\n",
      "    loss           : -449.6476696779357\n",
      "    val_loss       : -304.96481901024237\n",
      "Train Epoch: 178 [512/17352 (3%)] Loss: -403.764130\n",
      "Train Epoch: 178 [9552/17352 (55%)] Loss: -494.388627\n",
      "Train Epoch: 178 [17044/17352 (98%)] Loss: -502.250219\n",
      "    epoch          : 178\n",
      "    loss           : -438.13233946453835\n",
      "    val_loss       : -410.382226079228\n",
      "Train Epoch: 179 [512/17352 (3%)] Loss: -483.691681\n",
      "Train Epoch: 179 [9716/17352 (56%)] Loss: -390.766831\n",
      "Train Epoch: 179 [16923/17352 (98%)] Loss: -344.545363\n",
      "    epoch          : 179\n",
      "    loss           : -466.6932458536424\n",
      "    val_loss       : -442.6479641977004\n",
      "Train Epoch: 180 [512/17352 (3%)] Loss: -539.981201\n",
      "Train Epoch: 180 [10323/17352 (59%)] Loss: -464.193316\n",
      "Train Epoch: 180 [16878/17352 (97%)] Loss: -418.060826\n",
      "    epoch          : 180\n",
      "    loss           : -501.75530323401387\n",
      "    val_loss       : -446.8953102934896\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch180.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 181 [512/17352 (3%)] Loss: -530.100647\n",
      "Train Epoch: 181 [10979/17352 (63%)] Loss: -394.533338\n",
      "Train Epoch: 181 [17101/17352 (99%)] Loss: -532.018218\n",
      "    epoch          : 181\n",
      "    loss           : -504.6071602593574\n",
      "    val_loss       : -444.4225600545969\n",
      "Train Epoch: 182 [512/17352 (3%)] Loss: -520.603882\n",
      "Train Epoch: 182 [10574/17352 (61%)] Loss: -430.540128\n",
      "Train Epoch: 182 [17064/17352 (98%)] Loss: -542.198207\n",
      "    epoch          : 182\n",
      "    loss           : -506.12500564685945\n",
      "    val_loss       : -445.6455068908849\n",
      "Train Epoch: 183 [512/17352 (3%)] Loss: -541.439392\n",
      "Train Epoch: 183 [10037/17352 (58%)] Loss: -444.614167\n",
      "Train Epoch: 183 [17016/17352 (98%)] Loss: -510.318294\n",
      "    epoch          : 183\n",
      "    loss           : -479.04294382830705\n",
      "    val_loss       : -391.07205691419784\n",
      "Train Epoch: 184 [512/17352 (3%)] Loss: -512.726196\n",
      "Train Epoch: 184 [10887/17352 (63%)] Loss: -547.732660\n",
      "Train Epoch: 184 [16922/17352 (98%)] Loss: -587.384723\n",
      "    epoch          : 184\n",
      "    loss           : -461.0946934186957\n",
      "    val_loss       : -426.3391014795867\n",
      "Train Epoch: 185 [512/17352 (3%)] Loss: -538.127686\n",
      "Train Epoch: 185 [10610/17352 (61%)] Loss: -584.981120\n",
      "Train Epoch: 185 [17049/17352 (98%)] Loss: -549.183765\n",
      "    epoch          : 185\n",
      "    loss           : -469.2570872865909\n",
      "    val_loss       : -390.85187807184207\n",
      "Train Epoch: 186 [512/17352 (3%)] Loss: -500.385437\n",
      "Train Epoch: 186 [10702/17352 (62%)] Loss: -295.457056\n",
      "Train Epoch: 186 [17335/17352 (100%)] Loss: -561.962687\n",
      "    epoch          : 186\n",
      "    loss           : -479.01481543173026\n",
      "    val_loss       : -312.7147788286468\n",
      "Train Epoch: 187 [512/17352 (3%)] Loss: -213.740982\n",
      "Train Epoch: 187 [10159/17352 (59%)] Loss: -422.943291\n",
      "Train Epoch: 187 [17090/17352 (98%)] Loss: -416.901899\n",
      "    epoch          : 187\n",
      "    loss           : -465.5633917165794\n",
      "    val_loss       : -436.54740574086713\n",
      "Train Epoch: 188 [512/17352 (3%)] Loss: -544.028137\n",
      "Train Epoch: 188 [10272/17352 (59%)] Loss: -518.270135\n",
      "Train Epoch: 188 [17263/17352 (99%)] Loss: -401.513120\n",
      "    epoch          : 188\n",
      "    loss           : -455.42884727914674\n",
      "    val_loss       : -356.57179802678155\n",
      "Train Epoch: 189 [512/17352 (3%)] Loss: -463.515839\n",
      "Train Epoch: 189 [9805/17352 (57%)] Loss: -353.022071\n",
      "Train Epoch: 189 [17090/17352 (98%)] Loss: -513.552436\n",
      "    epoch          : 189\n",
      "    loss           : -453.4571448751331\n",
      "    val_loss       : -333.88702087293115\n",
      "Train Epoch: 190 [512/17352 (3%)] Loss: -348.591156\n",
      "Train Epoch: 190 [10576/17352 (61%)] Loss: -394.128475\n",
      "Train Epoch: 190 [17143/17352 (99%)] Loss: -409.811983\n",
      "    epoch          : 190\n",
      "    loss           : -418.9207438517114\n",
      "    val_loss       : -397.2094092090133\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch190.pth ...\n",
      "Train Epoch: 191 [512/17352 (3%)] Loss: -494.469513\n",
      "Train Epoch: 191 [10501/17352 (61%)] Loss: -381.322595\n",
      "Train Epoch: 191 [16934/17352 (98%)] Loss: -580.166719\n",
      "    epoch          : 191\n",
      "    loss           : -474.6515600773509\n",
      "    val_loss       : -461.7814612725224\n",
      "Train Epoch: 192 [512/17352 (3%)] Loss: -562.970398\n",
      "Train Epoch: 192 [10085/17352 (58%)] Loss: -569.393500\n",
      "Train Epoch: 192 [17101/17352 (99%)] Loss: -420.659757\n",
      "    epoch          : 192\n",
      "    loss           : -502.7736133665585\n",
      "    val_loss       : -461.7524091564601\n",
      "Train Epoch: 193 [512/17352 (3%)] Loss: -554.466248\n",
      "Train Epoch: 193 [9797/17352 (56%)] Loss: -371.822883\n",
      "Train Epoch: 193 [17016/17352 (98%)] Loss: -491.648438\n",
      "    epoch          : 193\n",
      "    loss           : -518.7438134269585\n",
      "    val_loss       : -469.31086419655117\n",
      "Train Epoch: 194 [512/17352 (3%)] Loss: -586.174377\n",
      "Train Epoch: 194 [10640/17352 (61%)] Loss: -502.540471\n",
      "Train Epoch: 194 [16958/17352 (98%)] Loss: -539.005025\n",
      "    epoch          : 194\n",
      "    loss           : -540.8234841050595\n",
      "    val_loss       : -463.28437217894344\n",
      "Train Epoch: 195 [512/17352 (3%)] Loss: -548.639526\n",
      "Train Epoch: 195 [10833/17352 (62%)] Loss: -465.062283\n",
      "Train Epoch: 195 [17064/17352 (98%)] Loss: -456.842084\n",
      "    epoch          : 195\n",
      "    loss           : -521.1368473368215\n",
      "    val_loss       : -438.537917342986\n",
      "Train Epoch: 196 [512/17352 (3%)] Loss: -477.930908\n",
      "Train Epoch: 196 [10700/17352 (62%)] Loss: -573.239927\n",
      "Train Epoch: 196 [16883/17352 (97%)] Loss: -427.904600\n",
      "    epoch          : 196\n",
      "    loss           : -511.4278562230453\n",
      "    val_loss       : -470.34151981556704\n",
      "Train Epoch: 197 [512/17352 (3%)] Loss: -403.461365\n",
      "Train Epoch: 197 [10695/17352 (62%)] Loss: -618.695035\n",
      "Train Epoch: 197 [17044/17352 (98%)] Loss: -421.618122\n",
      "    epoch          : 197\n",
      "    loss           : -530.408724436047\n",
      "    val_loss       : -440.9491632151761\n",
      "Train Epoch: 198 [512/17352 (3%)] Loss: -370.484314\n",
      "Train Epoch: 198 [10544/17352 (61%)] Loss: -358.187573\n",
      "Train Epoch: 198 [17106/17352 (99%)] Loss: -564.961512\n",
      "    epoch          : 198\n",
      "    loss           : -495.2113863205715\n",
      "    val_loss       : -416.3882202604329\n",
      "Train Epoch: 199 [512/17352 (3%)] Loss: -517.216431\n",
      "Train Epoch: 199 [10566/17352 (61%)] Loss: -596.499130\n",
      "Train Epoch: 199 [17153/17352 (99%)] Loss: -392.448415\n",
      "    epoch          : 199\n",
      "    loss           : -503.84567161484046\n",
      "    val_loss       : -432.9044011717617\n",
      "Train Epoch: 200 [512/17352 (3%)] Loss: -534.148682\n",
      "Train Epoch: 200 [10698/17352 (62%)] Loss: -324.532259\n",
      "Train Epoch: 200 [17143/17352 (99%)] Loss: -589.013021\n",
      "    epoch          : 200\n",
      "    loss           : -503.1061097496923\n",
      "    val_loss       : -453.90892751775596\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch200.pth ...\n",
      "Train Epoch: 201 [512/17352 (3%)] Loss: -544.674438\n",
      "Train Epoch: 201 [9953/17352 (57%)] Loss: -525.617903\n",
      "Train Epoch: 201 [16958/17352 (98%)] Loss: -529.672038\n",
      "    epoch          : 201\n",
      "    loss           : -491.37174564861346\n",
      "    val_loss       : -439.4739904205219\n",
      "Train Epoch: 202 [512/17352 (3%)] Loss: -572.293823\n",
      "Train Epoch: 202 [10182/17352 (59%)] Loss: -200.189872\n",
      "Train Epoch: 202 [16988/17352 (98%)] Loss: -474.450498\n",
      "    epoch          : 202\n",
      "    loss           : -474.3601853196964\n",
      "    val_loss       : -434.85703219287745\n",
      "Train Epoch: 203 [512/17352 (3%)] Loss: -556.307556\n",
      "Train Epoch: 203 [10119/17352 (58%)] Loss: -412.772690\n",
      "Train Epoch: 203 [16988/17352 (98%)] Loss: -573.753104\n",
      "    epoch          : 203\n",
      "    loss           : -516.3892273599887\n",
      "    val_loss       : -467.5953724084646\n",
      "Train Epoch: 204 [512/17352 (3%)] Loss: -585.197815\n",
      "Train Epoch: 204 [10041/17352 (58%)] Loss: -486.613496\n",
      "Train Epoch: 204 [17049/17352 (98%)] Loss: -569.225651\n",
      "    epoch          : 204\n",
      "    loss           : -528.1884798406379\n",
      "    val_loss       : -458.76154773689905\n",
      "Train Epoch: 205 [512/17352 (3%)] Loss: -512.209045\n",
      "Train Epoch: 205 [10342/17352 (60%)] Loss: -605.815676\n",
      "Train Epoch: 205 [16922/17352 (98%)] Loss: -572.454622\n",
      "    epoch          : 205\n",
      "    loss           : -532.6356119933315\n",
      "    val_loss       : -469.17933735391705\n",
      "Train Epoch: 206 [512/17352 (3%)] Loss: -593.855835\n",
      "Train Epoch: 206 [10225/17352 (59%)] Loss: 90.719698\n",
      "Train Epoch: 206 [16958/17352 (98%)] Loss: -440.394590\n",
      "    epoch          : 206\n",
      "    loss           : -447.00433306123256\n",
      "    val_loss       : -311.5722970571124\n",
      "Train Epoch: 207 [512/17352 (3%)] Loss: -461.736328\n",
      "Train Epoch: 207 [10012/17352 (58%)] Loss: -314.987252\n",
      "Train Epoch: 207 [17133/17352 (99%)] Loss: -572.117354\n",
      "    epoch          : 207\n",
      "    loss           : -367.21329508240234\n",
      "    val_loss       : -364.90953531794423\n",
      "Train Epoch: 208 [512/17352 (3%)] Loss: -494.424805\n",
      "Train Epoch: 208 [10414/17352 (60%)] Loss: -411.431897\n",
      "Train Epoch: 208 [16878/17352 (97%)] Loss: -429.707992\n",
      "    epoch          : 208\n",
      "    loss           : -471.97196892751015\n",
      "    val_loss       : -460.18198997530607\n",
      "Train Epoch: 209 [512/17352 (3%)] Loss: -507.462524\n",
      "Train Epoch: 209 [10310/17352 (59%)] Loss: -460.841077\n",
      "Train Epoch: 209 [17277/17352 (100%)] Loss: -462.384201\n",
      "    epoch          : 209\n",
      "    loss           : -507.186254085318\n",
      "    val_loss       : -271.32276469420884\n",
      "Train Epoch: 210 [512/17352 (3%)] Loss: -346.051819\n",
      "Train Epoch: 210 [10299/17352 (59%)] Loss: -608.673526\n",
      "Train Epoch: 210 [16922/17352 (98%)] Loss: -441.913284\n",
      "    epoch          : 210\n",
      "    loss           : -464.5181393110781\n",
      "    val_loss       : -453.9197823729465\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch210.pth ...\n",
      "Train Epoch: 211 [512/17352 (3%)] Loss: -563.393311\n",
      "Train Epoch: 211 [10545/17352 (61%)] Loss: -597.983740\n",
      "Train Epoch: 211 [17153/17352 (99%)] Loss: -606.891179\n",
      "    epoch          : 211\n",
      "    loss           : -514.799181810466\n",
      "    val_loss       : -397.0430074595139\n",
      "Train Epoch: 212 [512/17352 (3%)] Loss: -528.572876\n",
      "Train Epoch: 212 [10227/17352 (59%)] Loss: -587.481093\n",
      "Train Epoch: 212 [16958/17352 (98%)] Loss: -604.343333\n",
      "    epoch          : 212\n",
      "    loss           : -540.617776232739\n",
      "    val_loss       : -492.2604716251497\n",
      "Train Epoch: 213 [512/17352 (3%)] Loss: -604.185547\n",
      "Train Epoch: 213 [10207/17352 (59%)] Loss: -514.020354\n",
      "Train Epoch: 213 [17016/17352 (98%)] Loss: -536.949678\n",
      "    epoch          : 213\n",
      "    loss           : -576.5968757976224\n",
      "    val_loss       : -500.31104687715765\n",
      "Train Epoch: 214 [512/17352 (3%)] Loss: -613.923828\n",
      "Train Epoch: 214 [10357/17352 (60%)] Loss: -695.502387\n",
      "Train Epoch: 214 [17106/17352 (99%)] Loss: -441.045380\n",
      "    epoch          : 214\n",
      "    loss           : -578.8117753801772\n",
      "    val_loss       : -486.39129701389663\n",
      "Train Epoch: 215 [512/17352 (3%)] Loss: -596.989136\n",
      "Train Epoch: 215 [10332/17352 (60%)] Loss: -604.471723\n",
      "Train Epoch: 215 [17153/17352 (99%)] Loss: -631.261771\n",
      "    epoch          : 215\n",
      "    loss           : -561.9757195119726\n",
      "    val_loss       : -341.8032666024238\n",
      "Train Epoch: 216 [512/17352 (3%)] Loss: -423.097412\n",
      "Train Epoch: 216 [10384/17352 (60%)] Loss: -459.912691\n",
      "Train Epoch: 216 [17064/17352 (98%)] Loss: -196.877766\n",
      "    epoch          : 216\n",
      "    loss           : -350.8195473506398\n",
      "    val_loss       : -271.2753312089381\n",
      "Train Epoch: 217 [512/17352 (3%)] Loss: -295.312988\n",
      "Train Epoch: 217 [10585/17352 (61%)] Loss: -270.724143\n",
      "Train Epoch: 217 [16934/17352 (98%)] Loss: -453.526255\n",
      "    epoch          : 217\n",
      "    loss           : -444.99849785262205\n",
      "    val_loss       : -404.2729060611893\n",
      "Train Epoch: 218 [512/17352 (3%)] Loss: -461.516174\n",
      "Train Epoch: 218 [10658/17352 (61%)] Loss: -645.564619\n",
      "Train Epoch: 218 [17335/17352 (100%)] Loss: -596.667416\n",
      "    epoch          : 218\n",
      "    loss           : -534.7607224508494\n",
      "    val_loss       : -452.5869345319998\n",
      "Train Epoch: 219 [512/17352 (3%)] Loss: -575.781738\n",
      "Train Epoch: 219 [10355/17352 (60%)] Loss: -645.968814\n",
      "Train Epoch: 219 [16957/17352 (98%)] Loss: -608.497511\n",
      "    epoch          : 219\n",
      "    loss           : -544.9229011178693\n",
      "    val_loss       : -472.4083648889302\n",
      "Train Epoch: 220 [512/17352 (3%)] Loss: -439.059082\n",
      "Train Epoch: 220 [10353/17352 (60%)] Loss: -496.969722\n",
      "Train Epoch: 220 [16958/17352 (98%)] Loss: -433.668922\n",
      "    epoch          : 220\n",
      "    loss           : -565.6582484490284\n",
      "    val_loss       : -509.7534245035884\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch220.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 221 [512/17352 (3%)] Loss: -605.363037\n",
      "Train Epoch: 221 [10454/17352 (60%)] Loss: -582.050009\n",
      "Train Epoch: 221 [17277/17352 (100%)] Loss: -630.810383\n",
      "    epoch          : 221\n",
      "    loss           : -584.3758861865665\n",
      "    val_loss       : -492.73567505866066\n",
      "Train Epoch: 222 [512/17352 (3%)] Loss: -624.527954\n",
      "Train Epoch: 222 [10246/17352 (59%)] Loss: -600.860204\n",
      "Train Epoch: 222 [17106/17352 (99%)] Loss: -484.970535\n",
      "    epoch          : 222\n",
      "    loss           : -585.167410731535\n",
      "    val_loss       : -506.95927387971165\n",
      "Train Epoch: 223 [512/17352 (3%)] Loss: -622.194580\n",
      "Train Epoch: 223 [9996/17352 (58%)] Loss: -537.839139\n",
      "Train Epoch: 223 [17044/17352 (98%)] Loss: -557.316917\n",
      "    epoch          : 223\n",
      "    loss           : -589.0161330459407\n",
      "    val_loss       : -525.0101587343889\n",
      "Train Epoch: 224 [512/17352 (3%)] Loss: -636.937073\n",
      "Train Epoch: 224 [10772/17352 (62%)] Loss: -709.751899\n",
      "Train Epoch: 224 [17153/17352 (99%)] Loss: -625.007882\n",
      "    epoch          : 224\n",
      "    loss           : -598.5344338871887\n",
      "    val_loss       : -515.6658781159055\n",
      "Train Epoch: 225 [512/17352 (3%)] Loss: -642.372498\n",
      "Train Epoch: 225 [10393/17352 (60%)] Loss: -690.146943\n",
      "Train Epoch: 225 [16958/17352 (98%)] Loss: -621.077434\n",
      "    epoch          : 225\n",
      "    loss           : -580.5919234362693\n",
      "    val_loss       : -481.1826182000078\n",
      "Train Epoch: 226 [512/17352 (3%)] Loss: -604.869141\n",
      "Train Epoch: 226 [10062/17352 (58%)] Loss: -538.569992\n",
      "Train Epoch: 226 [17126/17352 (99%)] Loss: -479.435752\n",
      "    epoch          : 226\n",
      "    loss           : -587.2979124660101\n",
      "    val_loss       : -489.5516032287556\n",
      "Train Epoch: 227 [512/17352 (3%)] Loss: -558.143127\n",
      "Train Epoch: 227 [9957/17352 (57%)] Loss: -629.352398\n",
      "Train Epoch: 227 [16934/17352 (98%)] Loss: -540.016509\n",
      "    epoch          : 227\n",
      "    loss           : -593.3269862037529\n",
      "    val_loss       : -520.5803402709341\n",
      "Train Epoch: 228 [512/17352 (3%)] Loss: -653.437439\n",
      "Train Epoch: 228 [9632/17352 (56%)] Loss: -671.876667\n",
      "Train Epoch: 228 [16957/17352 (98%)] Loss: -508.831109\n",
      "    epoch          : 228\n",
      "    loss           : -567.735703711607\n",
      "    val_loss       : -500.52656115544477\n",
      "Train Epoch: 229 [512/17352 (3%)] Loss: -629.223755\n",
      "Train Epoch: 229 [10441/17352 (60%)] Loss: -498.171875\n",
      "Train Epoch: 229 [17101/17352 (99%)] Loss: -492.333504\n",
      "    epoch          : 229\n",
      "    loss           : -503.57750922486315\n",
      "    val_loss       : -266.91699740885065\n",
      "Train Epoch: 230 [512/17352 (3%)] Loss: -388.327484\n",
      "Train Epoch: 230 [10330/17352 (60%)] Loss: -563.765117\n",
      "Train Epoch: 230 [17133/17352 (99%)] Loss: -565.588778\n",
      "    epoch          : 230\n",
      "    loss           : -480.8952096489364\n",
      "    val_loss       : -411.35079215285765\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch230.pth ...\n",
      "Train Epoch: 231 [512/17352 (3%)] Loss: -503.251892\n",
      "Train Epoch: 231 [11012/17352 (63%)] Loss: -656.088252\n",
      "Train Epoch: 231 [17277/17352 (100%)] Loss: -642.404231\n",
      "    epoch          : 231\n",
      "    loss           : -565.4389405844119\n",
      "    val_loss       : -481.0581625331631\n",
      "Train Epoch: 232 [512/17352 (3%)] Loss: -587.722168\n",
      "Train Epoch: 232 [10073/17352 (58%)] Loss: -463.712916\n",
      "Train Epoch: 232 [17253/17352 (99%)] Loss: -551.601866\n",
      "    epoch          : 232\n",
      "    loss           : -586.9668613029269\n",
      "    val_loss       : -509.42323181866703\n",
      "Train Epoch: 233 [512/17352 (3%)] Loss: -654.150757\n",
      "Train Epoch: 233 [10884/17352 (63%)] Loss: -708.004987\n",
      "Train Epoch: 233 [16934/17352 (98%)] Loss: -689.202656\n",
      "    epoch          : 233\n",
      "    loss           : -612.9678158526494\n",
      "    val_loss       : -528.9354300125627\n",
      "Train Epoch: 234 [512/17352 (3%)] Loss: -636.536926\n",
      "Train Epoch: 234 [10350/17352 (60%)] Loss: -618.181140\n",
      "Train Epoch: 234 [17126/17352 (99%)] Loss: -579.077741\n",
      "    epoch          : 234\n",
      "    loss           : -614.7287353185235\n",
      "    val_loss       : -526.176609082581\n",
      "Train Epoch: 235 [512/17352 (3%)] Loss: -652.829834\n",
      "Train Epoch: 235 [9620/17352 (55%)] Loss: -705.236090\n",
      "Train Epoch: 235 [17090/17352 (98%)] Loss: -498.468094\n",
      "    epoch          : 235\n",
      "    loss           : -619.2793556292564\n",
      "    val_loss       : -527.0256001122556\n",
      "Train Epoch: 236 [512/17352 (3%)] Loss: -643.085083\n",
      "Train Epoch: 236 [10607/17352 (61%)] Loss: -446.904435\n",
      "Train Epoch: 236 [17133/17352 (99%)] Loss: 855.730769\n",
      "    epoch          : 236\n",
      "    loss           : -546.1920746002473\n",
      "    val_loss       : -129.88379507479576\n",
      "Train Epoch: 237 [512/17352 (3%)] Loss: -312.207886\n",
      "Train Epoch: 237 [10445/17352 (60%)] Loss: -541.550656\n",
      "Train Epoch: 237 [16939/17352 (98%)] Loss: -659.096545\n",
      "    epoch          : 237\n",
      "    loss           : -456.7467424493615\n",
      "    val_loss       : -460.1552492044703\n",
      "Train Epoch: 238 [512/17352 (3%)] Loss: -609.708191\n",
      "Train Epoch: 238 [10325/17352 (60%)] Loss: -574.450120\n",
      "Train Epoch: 238 [16992/17352 (98%)] Loss: -532.716060\n",
      "    epoch          : 238\n",
      "    loss           : -543.6652324745311\n",
      "    val_loss       : -491.52100377634684\n",
      "Train Epoch: 239 [512/17352 (3%)] Loss: -619.387756\n",
      "Train Epoch: 239 [9697/17352 (56%)] Loss: -616.685417\n",
      "Train Epoch: 239 [17049/17352 (98%)] Loss: -393.196621\n",
      "    epoch          : 239\n",
      "    loss           : -579.0212862043672\n",
      "    val_loss       : -513.0535643439162\n",
      "Train Epoch: 240 [512/17352 (3%)] Loss: -647.942078\n",
      "Train Epoch: 240 [10009/17352 (58%)] Loss: -586.767685\n",
      "Train Epoch: 240 [16957/17352 (98%)] Loss: -587.565994\n",
      "    epoch          : 240\n",
      "    loss           : -615.2543929052384\n",
      "    val_loss       : -535.8407695571624\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch240.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 241 [512/17352 (3%)] Loss: -619.060120\n",
      "Train Epoch: 241 [9869/17352 (57%)] Loss: -690.458356\n",
      "Train Epoch: 241 [17090/17352 (98%)] Loss: -714.491356\n",
      "    epoch          : 241\n",
      "    loss           : -598.0588901085135\n",
      "    val_loss       : -530.3553797172939\n",
      "Train Epoch: 242 [512/17352 (3%)] Loss: -662.245850\n",
      "Train Epoch: 242 [10960/17352 (63%)] Loss: -689.882558\n",
      "Train Epoch: 242 [17133/17352 (99%)] Loss: -572.572069\n",
      "    epoch          : 242\n",
      "    loss           : -616.5307780418458\n",
      "    val_loss       : -534.0606489920102\n",
      "Train Epoch: 243 [512/17352 (3%)] Loss: -669.021484\n",
      "Train Epoch: 243 [10249/17352 (59%)] Loss: -515.315899\n",
      "Train Epoch: 243 [16992/17352 (98%)] Loss: -701.528118\n",
      "    epoch          : 243\n",
      "    loss           : -608.3439713020739\n",
      "    val_loss       : -459.17137131942866\n",
      "Train Epoch: 244 [512/17352 (3%)] Loss: -544.319458\n",
      "Train Epoch: 244 [10338/17352 (60%)] Loss: -611.726264\n",
      "Train Epoch: 244 [17101/17352 (99%)] Loss: -342.413838\n",
      "    epoch          : 244\n",
      "    loss           : -558.7295944408555\n",
      "    val_loss       : -434.48869713096224\n",
      "Train Epoch: 245 [512/17352 (3%)] Loss: -581.622375\n",
      "Train Epoch: 245 [10744/17352 (62%)] Loss: -552.745964\n",
      "Train Epoch: 245 [17335/17352 (100%)] Loss: -627.164971\n",
      "    epoch          : 245\n",
      "    loss           : -561.1716317800838\n",
      "    val_loss       : -478.8000408394212\n",
      "Train Epoch: 246 [512/17352 (3%)] Loss: -626.848083\n",
      "Train Epoch: 246 [10540/17352 (61%)] Loss: -627.029507\n",
      "Train Epoch: 246 [16883/17352 (97%)] Loss: -600.058525\n",
      "    epoch          : 246\n",
      "    loss           : -600.3950845520387\n",
      "    val_loss       : -529.5431258306422\n",
      "Train Epoch: 247 [512/17352 (3%)] Loss: -668.987671\n",
      "Train Epoch: 247 [10537/17352 (61%)] Loss: -758.684570\n",
      "Train Epoch: 247 [17049/17352 (98%)] Loss: -668.618321\n",
      "    epoch          : 247\n",
      "    loss           : -627.1123229712654\n",
      "    val_loss       : -547.3675157920263\n",
      "Train Epoch: 248 [512/17352 (3%)] Loss: -679.216187\n",
      "Train Epoch: 248 [10440/17352 (60%)] Loss: -629.447974\n",
      "Train Epoch: 248 [17106/17352 (99%)] Loss: -751.393500\n",
      "    epoch          : 248\n",
      "    loss           : -637.3601820759076\n",
      "    val_loss       : -554.2021577588105\n",
      "Train Epoch: 249 [512/17352 (3%)] Loss: -686.128601\n",
      "Train Epoch: 249 [10397/17352 (60%)] Loss: -501.076195\n",
      "Train Epoch: 249 [16878/17352 (97%)] Loss: -708.291768\n",
      "    epoch          : 249\n",
      "    loss           : -619.4602254979087\n",
      "    val_loss       : -499.63109612862115\n",
      "Train Epoch: 250 [512/17352 (3%)] Loss: -606.803345\n",
      "Train Epoch: 250 [10278/17352 (59%)] Loss: -632.259344\n",
      "Train Epoch: 250 [16922/17352 (98%)] Loss: -721.301324\n",
      "    epoch          : 250\n",
      "    loss           : -607.3324080996674\n",
      "    val_loss       : -522.6680548043151\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch250.pth ...\n",
      "Train Epoch: 251 [512/17352 (3%)] Loss: -636.967896\n",
      "Train Epoch: 251 [10298/17352 (59%)] Loss: -663.034296\n",
      "Train Epoch: 251 [16882/17352 (97%)] Loss: -691.249733\n",
      "    epoch          : 251\n",
      "    loss           : -600.3676329684794\n",
      "    val_loss       : -528.8120329835724\n",
      "Train Epoch: 252 [512/17352 (3%)] Loss: -670.000916\n",
      "Train Epoch: 252 [10009/17352 (58%)] Loss: -544.073874\n",
      "Train Epoch: 252 [17108/17352 (99%)] Loss: -650.346291\n",
      "    epoch          : 252\n",
      "    loss           : -603.2555354117759\n",
      "    val_loss       : -496.6966379821334\n",
      "Train Epoch: 253 [512/17352 (3%)] Loss: -631.714661\n",
      "Train Epoch: 253 [10763/17352 (62%)] Loss: -470.509690\n",
      "Train Epoch: 253 [16883/17352 (97%)] Loss: -428.100306\n",
      "    epoch          : 253\n",
      "    loss           : -572.7155560625373\n",
      "    val_loss       : -411.2823108941443\n",
      "Train Epoch: 254 [512/17352 (3%)] Loss: -560.491455\n",
      "Train Epoch: 254 [10249/17352 (59%)] Loss: -659.138073\n",
      "Train Epoch: 254 [17090/17352 (98%)] Loss: -600.424544\n",
      "    epoch          : 254\n",
      "    loss           : -546.8337420291123\n",
      "    val_loss       : -476.8880151094392\n",
      "Train Epoch: 255 [512/17352 (3%)] Loss: -652.281433\n",
      "Train Epoch: 255 [10343/17352 (60%)] Loss: -658.891260\n",
      "Train Epoch: 255 [16878/17352 (97%)] Loss: -442.065799\n",
      "    epoch          : 255\n",
      "    loss           : -575.6139491568921\n",
      "    val_loss       : -413.97040631025925\n",
      "Train Epoch: 256 [512/17352 (3%)] Loss: -599.083008\n",
      "Train Epoch: 256 [10577/17352 (61%)] Loss: -499.640328\n",
      "Train Epoch: 256 [16934/17352 (98%)] Loss: -660.129189\n",
      "    epoch          : 256\n",
      "    loss           : -570.7012932822101\n",
      "    val_loss       : -514.2300174111724\n",
      "Train Epoch: 257 [512/17352 (3%)] Loss: -623.494080\n",
      "Train Epoch: 257 [10169/17352 (59%)] Loss: -650.010156\n",
      "Train Epoch: 257 [16958/17352 (98%)] Loss: -524.672548\n",
      "    epoch          : 257\n",
      "    loss           : -614.8945827494605\n",
      "    val_loss       : -524.4202694705721\n",
      "Train Epoch: 258 [512/17352 (3%)] Loss: -656.813171\n",
      "Train Epoch: 258 [10399/17352 (60%)] Loss: -689.240072\n",
      "Train Epoch: 258 [17090/17352 (98%)] Loss: -666.485374\n",
      "    epoch          : 258\n",
      "    loss           : -612.5954762043915\n",
      "    val_loss       : -472.8215955249864\n",
      "Train Epoch: 259 [512/17352 (3%)] Loss: -596.260498\n",
      "Train Epoch: 259 [10687/17352 (62%)] Loss: -648.736740\n",
      "Train Epoch: 259 [16957/17352 (98%)] Loss: -546.659133\n",
      "    epoch          : 259\n",
      "    loss           : -562.6143990836246\n",
      "    val_loss       : -481.83743429119255\n",
      "Train Epoch: 260 [512/17352 (3%)] Loss: -651.549683\n",
      "Train Epoch: 260 [10919/17352 (63%)] Loss: -707.489362\n",
      "Train Epoch: 260 [17124/17352 (99%)] Loss: -664.426922\n",
      "    epoch          : 260\n",
      "    loss           : -596.694701133298\n",
      "    val_loss       : -473.85891814365016\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch260.pth ...\n",
      "Train Epoch: 261 [512/17352 (3%)] Loss: -622.209839\n",
      "Train Epoch: 261 [10612/17352 (61%)] Loss: -699.194084\n",
      "Train Epoch: 261 [16878/17352 (97%)] Loss: -623.552044\n",
      "    epoch          : 261\n",
      "    loss           : -593.3927305195392\n",
      "    val_loss       : -527.6902027836979\n",
      "Train Epoch: 262 [512/17352 (3%)] Loss: -674.199097\n",
      "Train Epoch: 262 [10202/17352 (59%)] Loss: -497.460054\n",
      "Train Epoch: 262 [17153/17352 (99%)] Loss: -653.349172\n",
      "    epoch          : 262\n",
      "    loss           : -546.3537752812451\n",
      "    val_loss       : 81.90172938701956\n",
      "Train Epoch: 263 [512/17352 (3%)] Loss: -56.810795\n",
      "Train Epoch: 263 [10179/17352 (59%)] Loss: -434.637761\n",
      "Train Epoch: 263 [17126/17352 (99%)] Loss: -625.925869\n",
      "    epoch          : 263\n",
      "    loss           : -386.63413599516826\n",
      "    val_loss       : -429.3132111198507\n",
      "Train Epoch: 264 [512/17352 (3%)] Loss: -540.385071\n",
      "Train Epoch: 264 [10362/17352 (60%)] Loss: -537.473288\n",
      "Train Epoch: 264 [16988/17352 (98%)] Loss: -667.282172\n",
      "    epoch          : 264\n",
      "    loss           : -558.3947039436359\n",
      "    val_loss       : -498.79272306768416\n",
      "Train Epoch: 265 [512/17352 (3%)] Loss: -431.974518\n",
      "Train Epoch: 265 [10312/17352 (59%)] Loss: -429.237141\n",
      "Train Epoch: 265 [16882/17352 (97%)] Loss: -625.715955\n",
      "    epoch          : 265\n",
      "    loss           : -590.1881558542884\n",
      "    val_loss       : -498.83837095612023\n",
      "Train Epoch: 266 [512/17352 (3%)] Loss: -616.550537\n",
      "Train Epoch: 266 [10663/17352 (61%)] Loss: -583.954055\n",
      "Train Epoch: 266 [17277/17352 (100%)] Loss: -661.749529\n",
      "    epoch          : 266\n",
      "    loss           : -628.9752389797427\n",
      "    val_loss       : -527.7684487303861\n",
      "Train Epoch: 267 [512/17352 (3%)] Loss: -666.327026\n",
      "Train Epoch: 267 [10243/17352 (59%)] Loss: -582.245546\n",
      "Train Epoch: 267 [17133/17352 (99%)] Loss: -530.792106\n",
      "    epoch          : 267\n",
      "    loss           : -640.2280340764468\n",
      "    val_loss       : -556.9050950518808\n",
      "Train Epoch: 268 [512/17352 (3%)] Loss: -687.209778\n",
      "Train Epoch: 268 [10176/17352 (59%)] Loss: -607.052632\n",
      "Train Epoch: 268 [16934/17352 (98%)] Loss: -411.114085\n",
      "    epoch          : 268\n",
      "    loss           : -611.6319002687694\n",
      "    val_loss       : -538.5691521093037\n",
      "Train Epoch: 269 [512/17352 (3%)] Loss: -682.953735\n",
      "Train Epoch: 269 [9294/17352 (54%)] Loss: -76.136446\n",
      "Train Epoch: 269 [16922/17352 (98%)] Loss: -537.671503\n",
      "    epoch          : 269\n",
      "    loss           : -429.01695711776074\n",
      "    val_loss       : -434.6751332103346\n",
      "Train Epoch: 270 [512/17352 (3%)] Loss: -621.872314\n",
      "Train Epoch: 270 [10868/17352 (63%)] Loss: -688.052039\n",
      "Train Epoch: 270 [16992/17352 (98%)] Loss: -640.410590\n",
      "    epoch          : 270\n",
      "    loss           : -586.3948047797194\n",
      "    val_loss       : -520.1911128536135\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch270.pth ...\n",
      "Train Epoch: 271 [512/17352 (3%)] Loss: -663.517944\n",
      "Train Epoch: 271 [10589/17352 (61%)] Loss: -702.756992\n",
      "Train Epoch: 271 [16958/17352 (98%)] Loss: -712.941297\n",
      "    epoch          : 271\n",
      "    loss           : -643.7122627702511\n",
      "    val_loss       : -551.82391002194\n",
      "Train Epoch: 272 [512/17352 (3%)] Loss: -678.943909\n",
      "Train Epoch: 272 [10288/17352 (59%)] Loss: -551.671839\n",
      "Train Epoch: 272 [17016/17352 (98%)] Loss: -716.152326\n",
      "    epoch          : 272\n",
      "    loss           : -651.6861671062608\n",
      "    val_loss       : -560.7620371504254\n",
      "Train Epoch: 273 [512/17352 (3%)] Loss: -716.888184\n",
      "Train Epoch: 273 [10739/17352 (62%)] Loss: -657.051944\n",
      "Train Epoch: 273 [16939/17352 (98%)] Loss: -607.086706\n",
      "    epoch          : 273\n",
      "    loss           : -668.6610834100903\n",
      "    val_loss       : -574.5074809605052\n",
      "Train Epoch: 274 [512/17352 (3%)] Loss: -716.365112\n",
      "Train Epoch: 274 [10510/17352 (61%)] Loss: -756.291978\n",
      "Train Epoch: 274 [16923/17352 (98%)] Loss: -696.364284\n",
      "    epoch          : 274\n",
      "    loss           : -666.3445098928223\n",
      "    val_loss       : -572.5027758921946\n",
      "Train Epoch: 275 [512/17352 (3%)] Loss: -718.680115\n",
      "Train Epoch: 275 [10421/17352 (60%)] Loss: -471.407780\n",
      "Train Epoch: 275 [16878/17352 (97%)] Loss: -753.494157\n",
      "    epoch          : 275\n",
      "    loss           : -657.6450765943974\n",
      "    val_loss       : -546.1074904568263\n",
      "Train Epoch: 276 [512/17352 (3%)] Loss: -705.312622\n",
      "Train Epoch: 276 [9836/17352 (57%)] Loss: -684.723248\n",
      "Train Epoch: 276 [17126/17352 (99%)] Loss: -653.149468\n",
      "    epoch          : 276\n",
      "    loss           : -666.5392343903669\n",
      "    val_loss       : -564.3303176196536\n",
      "Train Epoch: 277 [512/17352 (3%)] Loss: -699.698425\n",
      "Train Epoch: 277 [10587/17352 (61%)] Loss: -722.876031\n",
      "Train Epoch: 277 [17263/17352 (99%)] Loss: -708.953675\n",
      "    epoch          : 277\n",
      "    loss           : -676.292997473567\n",
      "    val_loss       : -566.9152856535276\n",
      "Train Epoch: 278 [512/17352 (3%)] Loss: -714.628296\n",
      "Train Epoch: 278 [10205/17352 (59%)] Loss: -593.724150\n",
      "Train Epoch: 278 [16992/17352 (98%)] Loss: -736.796233\n",
      "    epoch          : 278\n",
      "    loss           : -680.801341515423\n",
      "    val_loss       : -580.7099349568708\n",
      "Train Epoch: 279 [512/17352 (3%)] Loss: -732.869141\n",
      "Train Epoch: 279 [10248/17352 (59%)] Loss: -707.736103\n",
      "Train Epoch: 279 [17049/17352 (98%)] Loss: -726.407891\n",
      "    epoch          : 279\n",
      "    loss           : -679.3004345285958\n",
      "    val_loss       : -566.4711332935345\n",
      "Train Epoch: 280 [512/17352 (3%)] Loss: -708.451294\n",
      "Train Epoch: 280 [10075/17352 (58%)] Loss: -657.859444\n",
      "Train Epoch: 280 [17126/17352 (99%)] Loss: -683.000911\n",
      "    epoch          : 280\n",
      "    loss           : -674.5023825241674\n",
      "    val_loss       : -529.6241127896966\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch280.pth ...\n",
      "Train Epoch: 281 [512/17352 (3%)] Loss: -688.564270\n",
      "Train Epoch: 281 [10449/17352 (60%)] Loss: -800.626302\n",
      "Train Epoch: 281 [16939/17352 (98%)] Loss: -733.036331\n",
      "    epoch          : 281\n",
      "    loss           : -648.8198077656023\n",
      "    val_loss       : -517.9826246326686\n",
      "Train Epoch: 282 [512/17352 (3%)] Loss: -686.587708\n",
      "Train Epoch: 282 [10846/17352 (63%)] Loss: -656.069597\n",
      "Train Epoch: 282 [16939/17352 (98%)] Loss: -437.907233\n",
      "    epoch          : 282\n",
      "    loss           : -596.8536179601368\n",
      "    val_loss       : -474.56987542892585\n",
      "Train Epoch: 283 [512/17352 (3%)] Loss: -587.659485\n",
      "Train Epoch: 283 [10629/17352 (61%)] Loss: -556.863332\n",
      "Train Epoch: 283 [16958/17352 (98%)] Loss: -653.601562\n",
      "    epoch          : 283\n",
      "    loss           : -606.7887160631242\n",
      "    val_loss       : -545.1063380548544\n",
      "Train Epoch: 284 [512/17352 (3%)] Loss: -526.928772\n",
      "Train Epoch: 284 [10382/17352 (60%)] Loss: -651.479524\n",
      "Train Epoch: 284 [17090/17352 (98%)] Loss: -543.595703\n",
      "    epoch          : 284\n",
      "    loss           : -617.8128917966708\n",
      "    val_loss       : -525.1840670296756\n",
      "Train Epoch: 285 [512/17352 (3%)] Loss: -672.326965\n",
      "Train Epoch: 285 [10523/17352 (61%)] Loss: -693.274527\n",
      "Train Epoch: 285 [17106/17352 (99%)] Loss: -198.757457\n",
      "    epoch          : 285\n",
      "    loss           : -274.74869312382555\n",
      "    val_loss       : 38.88405766773481\n",
      "Train Epoch: 286 [512/17352 (3%)] Loss: -154.012833\n",
      "Train Epoch: 286 [10005/17352 (58%)] Loss: -286.870047\n",
      "Train Epoch: 286 [16882/17352 (97%)] Loss: -612.556901\n",
      "    epoch          : 286\n",
      "    loss           : -366.1724718045259\n",
      "    val_loss       : -450.11972555554894\n",
      "Train Epoch: 287 [512/17352 (3%)] Loss: -586.888611\n",
      "Train Epoch: 287 [10365/17352 (60%)] Loss: -515.260104\n",
      "Train Epoch: 287 [16923/17352 (98%)] Loss: -676.937766\n",
      "    epoch          : 287\n",
      "    loss           : -580.7043686664226\n",
      "    val_loss       : -503.24256176927815\n",
      "Train Epoch: 288 [512/17352 (3%)] Loss: -648.934265\n",
      "Train Epoch: 288 [10838/17352 (62%)] Loss: -611.982057\n",
      "Train Epoch: 288 [17263/17352 (99%)] Loss: -611.639476\n",
      "    epoch          : 288\n",
      "    loss           : -638.9753023707786\n",
      "    val_loss       : -529.3827587251329\n",
      "Train Epoch: 289 [512/17352 (3%)] Loss: -685.865295\n",
      "Train Epoch: 289 [10226/17352 (59%)] Loss: -688.346101\n",
      "Train Epoch: 289 [16934/17352 (98%)] Loss: -668.845869\n",
      "    epoch          : 289\n",
      "    loss           : -609.0038379977143\n",
      "    val_loss       : -499.9278364864726\n",
      "Train Epoch: 290 [512/17352 (3%)] Loss: -626.889709\n",
      "Train Epoch: 290 [9682/17352 (56%)] Loss: -672.918418\n",
      "Train Epoch: 290 [17090/17352 (98%)] Loss: -680.433268\n",
      "    epoch          : 290\n",
      "    loss           : -622.9093409367559\n",
      "    val_loss       : -540.0451328288057\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch290.pth ...\n",
      "Train Epoch: 291 [512/17352 (3%)] Loss: -697.995422\n",
      "Train Epoch: 291 [10458/17352 (60%)] Loss: -531.523394\n",
      "Train Epoch: 291 [17124/17352 (99%)] Loss: -599.753033\n",
      "    epoch          : 291\n",
      "    loss           : -635.6215433956236\n",
      "    val_loss       : -528.203632453287\n",
      "Train Epoch: 292 [512/17352 (3%)] Loss: -703.289856\n",
      "Train Epoch: 292 [10123/17352 (58%)] Loss: -531.719059\n",
      "Train Epoch: 292 [16883/17352 (97%)] Loss: -735.768671\n",
      "    epoch          : 292\n",
      "    loss           : -650.3309541009157\n",
      "    val_loss       : -557.1087678444494\n",
      "Train Epoch: 293 [512/17352 (3%)] Loss: -715.258667\n",
      "Train Epoch: 293 [10673/17352 (62%)] Loss: -723.386344\n",
      "Train Epoch: 293 [16922/17352 (98%)] Loss: -755.057753\n",
      "    epoch          : 293\n",
      "    loss           : -665.0124971010903\n",
      "    val_loss       : -571.7363807865217\n",
      "Train Epoch: 294 [512/17352 (3%)] Loss: -737.836853\n",
      "Train Epoch: 294 [10691/17352 (62%)] Loss: -761.843036\n",
      "Train Epoch: 294 [16922/17352 (98%)] Loss: -770.563105\n",
      "    epoch          : 294\n",
      "    loss           : -677.1943058238597\n",
      "    val_loss       : -578.8139354240739\n",
      "Train Epoch: 295 [512/17352 (3%)] Loss: -722.241211\n",
      "Train Epoch: 295 [10184/17352 (59%)] Loss: -698.816458\n",
      "Train Epoch: 295 [17263/17352 (99%)] Loss: -734.232122\n",
      "    epoch          : 295\n",
      "    loss           : -680.056549392297\n",
      "    val_loss       : -569.7014567791524\n",
      "Train Epoch: 296 [512/17352 (3%)] Loss: -553.644287\n",
      "Train Epoch: 296 [10372/17352 (60%)] Loss: -722.962214\n",
      "Train Epoch: 296 [16992/17352 (98%)] Loss: -723.220964\n",
      "    epoch          : 296\n",
      "    loss           : -673.8080989023441\n",
      "    val_loss       : -580.3413269671985\n",
      "Train Epoch: 297 [512/17352 (3%)] Loss: -735.571533\n",
      "Train Epoch: 297 [10614/17352 (61%)] Loss: -653.058544\n",
      "Train Epoch: 297 [16958/17352 (98%)] Loss: -817.914822\n",
      "    epoch          : 297\n",
      "    loss           : -689.7725552838654\n",
      "    val_loss       : -590.7825876508952\n",
      "Train Epoch: 298 [512/17352 (3%)] Loss: -732.685303\n",
      "Train Epoch: 298 [10428/17352 (60%)] Loss: -765.018908\n",
      "Train Epoch: 298 [17277/17352 (100%)] Loss: -780.496609\n",
      "    epoch          : 298\n",
      "    loss           : -686.6548287222377\n",
      "    val_loss       : -569.7480689123507\n",
      "Train Epoch: 299 [512/17352 (3%)] Loss: -735.681030\n",
      "Train Epoch: 299 [9810/17352 (57%)] Loss: -792.780869\n",
      "Train Epoch: 299 [16883/17352 (97%)] Loss: -663.632812\n",
      "    epoch          : 299\n",
      "    loss           : -691.8570184395354\n",
      "    val_loss       : -583.4622804780512\n",
      "Train Epoch: 300 [512/17352 (3%)] Loss: -753.661133\n",
      "Train Epoch: 300 [10448/17352 (60%)] Loss: -643.131076\n",
      "Train Epoch: 300 [16988/17352 (98%)] Loss: -609.759131\n",
      "    epoch          : 300\n",
      "    loss           : -696.3556252648098\n",
      "    val_loss       : -575.4064481508412\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch300.pth ...\n",
      "Train Epoch: 301 [512/17352 (3%)] Loss: -755.816162\n",
      "Train Epoch: 301 [10860/17352 (63%)] Loss: -784.770080\n",
      "Train Epoch: 301 [16872/17352 (97%)] Loss: -677.480813\n",
      "    epoch          : 301\n",
      "    loss           : -703.3686251085963\n",
      "    val_loss       : -591.9393144692375\n",
      "Train Epoch: 302 [512/17352 (3%)] Loss: -730.234253\n",
      "Train Epoch: 302 [10094/17352 (58%)] Loss: -637.954733\n",
      "Train Epoch: 302 [17124/17352 (99%)] Loss: -760.937936\n",
      "    epoch          : 302\n",
      "    loss           : -701.2480149472088\n",
      "    val_loss       : -570.2550104210225\n",
      "Train Epoch: 303 [512/17352 (3%)] Loss: -738.786438\n",
      "Train Epoch: 303 [10644/17352 (61%)] Loss: -792.702359\n",
      "Train Epoch: 303 [17126/17352 (99%)] Loss: -674.074176\n",
      "    epoch          : 303\n",
      "    loss           : -682.7765758529423\n",
      "    val_loss       : -544.628792795737\n",
      "Train Epoch: 304 [512/17352 (3%)] Loss: -661.129517\n",
      "Train Epoch: 304 [10773/17352 (62%)] Loss: -519.256093\n",
      "Train Epoch: 304 [16887/17352 (97%)] Loss: -671.307953\n",
      "    epoch          : 304\n",
      "    loss           : -665.7494590168724\n",
      "    val_loss       : -572.5978719193531\n",
      "Train Epoch: 305 [512/17352 (3%)] Loss: -754.504395\n",
      "Train Epoch: 305 [10652/17352 (61%)] Loss: -545.116702\n",
      "Train Epoch: 305 [16957/17352 (98%)] Loss: -752.250781\n",
      "    epoch          : 305\n",
      "    loss           : -695.4362981248858\n",
      "    val_loss       : -600.2132441389983\n",
      "Train Epoch: 306 [512/17352 (3%)] Loss: -548.687073\n",
      "Train Epoch: 306 [10658/17352 (61%)] Loss: -835.189670\n",
      "Train Epoch: 306 [17133/17352 (99%)] Loss: -793.479041\n",
      "    epoch          : 306\n",
      "    loss           : -704.7885121117564\n",
      "    val_loss       : -581.8996030023752\n",
      "Train Epoch: 307 [512/17352 (3%)] Loss: -742.030029\n",
      "Train Epoch: 307 [9669/17352 (56%)] Loss: -690.026398\n",
      "Train Epoch: 307 [17049/17352 (98%)] Loss: -794.280720\n",
      "    epoch          : 307\n",
      "    loss           : -697.9456845537734\n",
      "    val_loss       : -580.121799520726\n",
      "Train Epoch: 308 [512/17352 (3%)] Loss: -736.029724\n",
      "Train Epoch: 308 [10365/17352 (60%)] Loss: -780.420734\n",
      "Train Epoch: 308 [17143/17352 (99%)] Loss: -739.592951\n",
      "    epoch          : 308\n",
      "    loss           : -703.6419774479518\n",
      "    val_loss       : -511.1086440736437\n",
      "Train Epoch: 309 [512/17352 (3%)] Loss: -664.232788\n",
      "Train Epoch: 309 [10198/17352 (59%)] Loss: -545.756962\n",
      "Train Epoch: 309 [16922/17352 (98%)] Loss: -804.872830\n",
      "    epoch          : 309\n",
      "    loss           : -638.0680504352634\n",
      "    val_loss       : -527.5420994553156\n",
      "Train Epoch: 310 [512/17352 (3%)] Loss: -720.306030\n",
      "Train Epoch: 310 [9957/17352 (57%)] Loss: -725.997504\n",
      "Train Epoch: 310 [17335/17352 (100%)] Loss: -501.473327\n",
      "    epoch          : 310\n",
      "    loss           : -601.4438753704404\n",
      "    val_loss       : -66.71966775269927\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch310.pth ...\n",
      "Train Epoch: 311 [512/17352 (3%)] Loss: -162.581345\n",
      "Train Epoch: 311 [10072/17352 (58%)] Loss: -555.923783\n",
      "Train Epoch: 311 [17108/17352 (99%)] Loss: -667.627414\n",
      "    epoch          : 311\n",
      "    loss           : -386.1726628868988\n",
      "    val_loss       : -368.13568266140203\n",
      "Train Epoch: 312 [512/17352 (3%)] Loss: -569.190186\n",
      "Train Epoch: 312 [10390/17352 (60%)] Loss: -550.941139\n",
      "Train Epoch: 312 [17124/17352 (99%)] Loss: -510.288753\n",
      "    epoch          : 312\n",
      "    loss           : -592.6295580931593\n",
      "    val_loss       : -488.05952306097726\n",
      "Train Epoch: 313 [512/17352 (3%)] Loss: -658.030029\n",
      "Train Epoch: 313 [9989/17352 (58%)] Loss: -782.380907\n",
      "Train Epoch: 313 [16887/17352 (97%)] Loss: -590.876321\n",
      "    epoch          : 313\n",
      "    loss           : -667.3645884501259\n",
      "    val_loss       : -562.5733971668947\n",
      "Train Epoch: 314 [512/17352 (3%)] Loss: -718.202393\n",
      "Train Epoch: 314 [9648/17352 (56%)] Loss: -765.330108\n",
      "Train Epoch: 314 [17143/17352 (99%)] Loss: -664.708056\n",
      "    epoch          : 314\n",
      "    loss           : -695.9216197257673\n",
      "    val_loss       : -602.9125885447442\n",
      "Train Epoch: 315 [512/17352 (3%)] Loss: -747.612549\n",
      "Train Epoch: 315 [10731/17352 (62%)] Loss: -575.557715\n",
      "Train Epoch: 315 [17101/17352 (99%)] Loss: -616.352413\n",
      "    epoch          : 315\n",
      "    loss           : -712.7950970474058\n",
      "    val_loss       : -589.0509571132769\n",
      "Train Epoch: 316 [512/17352 (3%)] Loss: -752.788940\n",
      "Train Epoch: 316 [10315/17352 (59%)] Loss: -638.748655\n",
      "Train Epoch: 316 [16988/17352 (98%)] Loss: -762.543677\n",
      "    epoch          : 316\n",
      "    loss           : -711.1346052957905\n",
      "    val_loss       : -596.5422474401341\n",
      "Train Epoch: 317 [512/17352 (3%)] Loss: -745.145142\n",
      "Train Epoch: 317 [10252/17352 (59%)] Loss: -598.530786\n",
      "Train Epoch: 317 [16883/17352 (97%)] Loss: -666.263832\n",
      "    epoch          : 317\n",
      "    loss           : -711.2959859001046\n",
      "    val_loss       : -605.0885450891519\n",
      "Train Epoch: 318 [512/17352 (3%)] Loss: -749.714722\n",
      "Train Epoch: 318 [10198/17352 (59%)] Loss: -649.300013\n",
      "Train Epoch: 318 [17263/17352 (99%)] Loss: -801.915645\n",
      "    epoch          : 318\n",
      "    loss           : -711.9476014000622\n",
      "    val_loss       : -584.4884611072556\n",
      "Train Epoch: 319 [512/17352 (3%)] Loss: -758.295776\n",
      "Train Epoch: 319 [10938/17352 (63%)] Loss: -680.664481\n",
      "Train Epoch: 319 [17253/17352 (99%)] Loss: -551.610721\n",
      "    epoch          : 319\n",
      "    loss           : -711.8428454283718\n",
      "    val_loss       : -594.3189313868141\n",
      "Train Epoch: 320 [512/17352 (3%)] Loss: -761.776489\n",
      "Train Epoch: 320 [10384/17352 (60%)] Loss: -763.025025\n",
      "Train Epoch: 320 [17335/17352 (100%)] Loss: -623.633371\n",
      "    epoch          : 320\n",
      "    loss           : -721.5398196881741\n",
      "    val_loss       : -604.212575905024\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch320.pth ...\n",
      "Train Epoch: 321 [512/17352 (3%)] Loss: -753.351257\n",
      "Train Epoch: 321 [10303/17352 (59%)] Loss: -813.209888\n",
      "Train Epoch: 321 [16957/17352 (98%)] Loss: -766.695247\n",
      "    epoch          : 321\n",
      "    loss           : -727.234497529721\n",
      "    val_loss       : -600.9404252944639\n",
      "Train Epoch: 322 [512/17352 (3%)] Loss: -782.594116\n",
      "Train Epoch: 322 [10409/17352 (60%)] Loss: -811.816704\n",
      "Train Epoch: 322 [16883/17352 (97%)] Loss: -613.661422\n",
      "    epoch          : 322\n",
      "    loss           : -731.4945678695184\n",
      "    val_loss       : -602.3810636128426\n",
      "Train Epoch: 323 [512/17352 (3%)] Loss: -770.633850\n",
      "Train Epoch: 323 [10569/17352 (61%)] Loss: -771.571765\n",
      "Train Epoch: 323 [17101/17352 (99%)] Loss: -750.078268\n",
      "    epoch          : 323\n",
      "    loss           : -716.3404169751691\n",
      "    val_loss       : -596.3168417067401\n",
      "Train Epoch: 324 [512/17352 (3%)] Loss: -731.700623\n",
      "Train Epoch: 324 [10214/17352 (59%)] Loss: -679.206639\n",
      "Train Epoch: 324 [17277/17352 (100%)] Loss: -662.614025\n",
      "    epoch          : 324\n",
      "    loss           : -718.1262361585\n",
      "    val_loss       : -594.5657201703496\n",
      "Train Epoch: 325 [512/17352 (3%)] Loss: -762.012634\n",
      "Train Epoch: 325 [10995/17352 (63%)] Loss: -653.277257\n",
      "Train Epoch: 325 [16988/17352 (98%)] Loss: -749.396940\n",
      "    epoch          : 325\n",
      "    loss           : -715.6070087480193\n",
      "    val_loss       : -594.8961282810208\n",
      "Train Epoch: 326 [512/17352 (3%)] Loss: -762.564209\n",
      "Train Epoch: 326 [10077/17352 (58%)] Loss: -605.393874\n",
      "Train Epoch: 326 [17253/17352 (99%)] Loss: -559.473086\n",
      "    epoch          : 326\n",
      "    loss           : -718.8907069680743\n",
      "    val_loss       : -584.3156327997461\n",
      "Train Epoch: 327 [512/17352 (3%)] Loss: -735.559509\n",
      "Train Epoch: 327 [10143/17352 (58%)] Loss: -631.420139\n",
      "Train Epoch: 327 [17106/17352 (99%)] Loss: -792.146922\n",
      "    epoch          : 327\n",
      "    loss           : -705.8112519970812\n",
      "    val_loss       : -581.3725320548052\n",
      "Train Epoch: 328 [512/17352 (3%)] Loss: -706.575378\n",
      "Train Epoch: 328 [10962/17352 (63%)] Loss: -812.837633\n",
      "Train Epoch: 328 [16887/17352 (97%)] Loss: -812.407120\n",
      "    epoch          : 328\n",
      "    loss           : -727.0198274190965\n",
      "    val_loss       : -603.9808627361062\n",
      "Train Epoch: 329 [512/17352 (3%)] Loss: -779.423218\n",
      "Train Epoch: 329 [10195/17352 (59%)] Loss: -743.119076\n",
      "Train Epoch: 329 [16934/17352 (98%)] Loss: -534.477016\n",
      "    epoch          : 329\n",
      "    loss           : -707.8446547017669\n",
      "    val_loss       : -565.0416159942737\n",
      "Train Epoch: 330 [512/17352 (3%)] Loss: -741.027100\n",
      "Train Epoch: 330 [10149/17352 (58%)] Loss: -634.332717\n",
      "Train Epoch: 330 [16957/17352 (98%)] Loss: -632.317115\n",
      "    epoch          : 330\n",
      "    loss           : -709.433343283981\n",
      "    val_loss       : -566.8972869408874\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch330.pth ...\n",
      "Train Epoch: 331 [512/17352 (3%)] Loss: -750.541504\n",
      "Train Epoch: 331 [9778/17352 (56%)] Loss: -712.887311\n",
      "Train Epoch: 331 [17124/17352 (99%)] Loss: -715.191495\n",
      "    epoch          : 331\n",
      "    loss           : -679.4293264504087\n",
      "    val_loss       : -533.1455328588171\n",
      "Train Epoch: 332 [512/17352 (3%)] Loss: -715.370483\n",
      "Train Epoch: 332 [10091/17352 (58%)] Loss: -522.051238\n",
      "Train Epoch: 332 [16923/17352 (98%)] Loss: -548.398181\n",
      "    epoch          : 332\n",
      "    loss           : -633.2192939130349\n",
      "    val_loss       : -565.4683539421342\n",
      "Train Epoch: 333 [512/17352 (3%)] Loss: -704.935059\n",
      "Train Epoch: 333 [10653/17352 (61%)] Loss: -705.515232\n",
      "Train Epoch: 333 [17101/17352 (99%)] Loss: -675.662403\n",
      "    epoch          : 333\n",
      "    loss           : -653.2774815044035\n",
      "    val_loss       : -515.9324408413418\n",
      "Train Epoch: 334 [512/17352 (3%)] Loss: -671.556519\n",
      "Train Epoch: 334 [10699/17352 (62%)] Loss: -700.698576\n",
      "Train Epoch: 334 [17277/17352 (100%)] Loss: -553.878146\n",
      "    epoch          : 334\n",
      "    loss           : -675.4815041579557\n",
      "    val_loss       : -469.76903363050064\n",
      "Train Epoch: 335 [512/17352 (3%)] Loss: -629.050476\n",
      "Train Epoch: 335 [9721/17352 (56%)] Loss: -507.889748\n",
      "Train Epoch: 335 [17133/17352 (99%)] Loss: -570.168723\n",
      "    epoch          : 335\n",
      "    loss           : -585.3761419251834\n",
      "    val_loss       : -222.61298785739464\n",
      "Train Epoch: 336 [512/17352 (3%)] Loss: -462.492004\n",
      "Train Epoch: 336 [9939/17352 (57%)] Loss: -657.541884\n",
      "Train Epoch: 336 [17016/17352 (98%)] Loss: -527.229232\n",
      "    epoch          : 336\n",
      "    loss           : -431.2806861420092\n",
      "    val_loss       : -390.37056328768796\n",
      "Train Epoch: 337 [512/17352 (3%)] Loss: -593.582886\n",
      "Train Epoch: 337 [10316/17352 (59%)] Loss: -596.285797\n",
      "Train Epoch: 337 [17126/17352 (99%)] Loss: -716.506663\n",
      "    epoch          : 337\n",
      "    loss           : -616.6586890717563\n",
      "    val_loss       : -479.40345595338096\n",
      "Train Epoch: 338 [512/17352 (3%)] Loss: -667.660095\n",
      "Train Epoch: 338 [9991/17352 (58%)] Loss: -626.269339\n",
      "Train Epoch: 338 [16934/17352 (98%)] Loss: -581.526843\n",
      "    epoch          : 338\n",
      "    loss           : -676.9958961469962\n",
      "    val_loss       : -587.5751661081762\n",
      "Train Epoch: 339 [512/17352 (3%)] Loss: -745.723572\n",
      "Train Epoch: 339 [10301/17352 (59%)] Loss: -741.375781\n",
      "Train Epoch: 339 [17106/17352 (99%)] Loss: -789.149508\n",
      "    epoch          : 339\n",
      "    loss           : -716.5839199223948\n",
      "    val_loss       : -606.162907733119\n",
      "Train Epoch: 340 [512/17352 (3%)] Loss: -745.411011\n",
      "Train Epoch: 340 [10073/17352 (58%)] Loss: -554.971540\n",
      "Train Epoch: 340 [16988/17352 (98%)] Loss: -785.635918\n",
      "    epoch          : 340\n",
      "    loss           : -706.8022484127072\n",
      "    val_loss       : -599.4763868998225\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch340.pth ...\n",
      "Train Epoch: 341 [512/17352 (3%)] Loss: -775.412842\n",
      "Train Epoch: 341 [10180/17352 (59%)] Loss: -767.352815\n",
      "Train Epoch: 341 [16934/17352 (98%)] Loss: -757.794912\n",
      "    epoch          : 341\n",
      "    loss           : -733.0813291380373\n",
      "    val_loss       : -613.8180848375748\n",
      "Train Epoch: 342 [512/17352 (3%)] Loss: -588.051758\n",
      "Train Epoch: 342 [10643/17352 (61%)] Loss: -797.840981\n",
      "Train Epoch: 342 [16887/17352 (97%)] Loss: -798.824438\n",
      "    epoch          : 342\n",
      "    loss           : -737.9382388090183\n",
      "    val_loss       : -609.5845121590246\n",
      "Train Epoch: 343 [512/17352 (3%)] Loss: -779.898560\n",
      "Train Epoch: 343 [10681/17352 (62%)] Loss: -786.701199\n",
      "Train Epoch: 343 [16872/17352 (97%)] Loss: -650.864676\n",
      "    epoch          : 343\n",
      "    loss           : -738.6365894583809\n",
      "    val_loss       : -586.9076182548529\n",
      "Train Epoch: 344 [512/17352 (3%)] Loss: -779.234009\n",
      "Train Epoch: 344 [10574/17352 (61%)] Loss: -625.115869\n",
      "Train Epoch: 344 [16939/17352 (98%)] Loss: -581.209468\n",
      "    epoch          : 344\n",
      "    loss           : -731.952275143727\n",
      "    val_loss       : -608.6535343942437\n",
      "Train Epoch: 345 [512/17352 (3%)] Loss: -786.489746\n",
      "Train Epoch: 345 [10303/17352 (59%)] Loss: -750.284705\n",
      "Train Epoch: 345 [16957/17352 (98%)] Loss: -558.075957\n",
      "    epoch          : 345\n",
      "    loss           : -727.4344560606489\n",
      "    val_loss       : -575.6189774386742\n",
      "Train Epoch: 346 [512/17352 (3%)] Loss: -748.127380\n",
      "Train Epoch: 346 [10267/17352 (59%)] Loss: -718.382675\n",
      "Train Epoch: 346 [17277/17352 (100%)] Loss: -770.134542\n",
      "    epoch          : 346\n",
      "    loss           : -728.3404564993673\n",
      "    val_loss       : -592.5172161833638\n",
      "Train Epoch: 347 [512/17352 (3%)] Loss: -768.229553\n",
      "Train Epoch: 347 [10490/17352 (60%)] Loss: -776.974851\n",
      "Train Epoch: 347 [16934/17352 (98%)] Loss: -697.293992\n",
      "    epoch          : 347\n",
      "    loss           : -726.9467870327499\n",
      "    val_loss       : -609.0899682901891\n",
      "Train Epoch: 348 [512/17352 (3%)] Loss: -774.446045\n",
      "Train Epoch: 348 [9968/17352 (57%)] Loss: -753.120760\n",
      "Train Epoch: 348 [17253/17352 (99%)] Loss: -630.857526\n",
      "    epoch          : 348\n",
      "    loss           : -707.5052590514467\n",
      "    val_loss       : -591.5827333471667\n",
      "Train Epoch: 349 [512/17352 (3%)] Loss: -776.547485\n",
      "Train Epoch: 349 [10774/17352 (62%)] Loss: -787.755864\n",
      "Train Epoch: 349 [16934/17352 (98%)] Loss: -364.602941\n",
      "    epoch          : 349\n",
      "    loss           : -599.3515293092016\n",
      "    val_loss       : -558.4566803515354\n",
      "Train Epoch: 350 [512/17352 (3%)] Loss: -713.547852\n",
      "Train Epoch: 350 [10737/17352 (62%)] Loss: -433.841315\n",
      "Train Epoch: 350 [17153/17352 (99%)] Loss: -324.295444\n",
      "    epoch          : 350\n",
      "    loss           : -319.1863531660974\n",
      "    val_loss       : -340.2431001579714\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch350.pth ...\n",
      "Train Epoch: 351 [512/17352 (3%)] Loss: -494.831329\n",
      "Train Epoch: 351 [9867/17352 (57%)] Loss: -463.897659\n",
      "Train Epoch: 351 [16939/17352 (98%)] Loss: -813.793511\n",
      "    epoch          : 351\n",
      "    loss           : -539.775481268339\n",
      "    val_loss       : -533.2353480022904\n",
      "Train Epoch: 352 [512/17352 (3%)] Loss: -718.006348\n",
      "Train Epoch: 352 [10376/17352 (60%)] Loss: -766.270789\n",
      "Train Epoch: 352 [17263/17352 (99%)] Loss: -715.366010\n",
      "    epoch          : 352\n",
      "    loss           : -674.4294533555945\n",
      "    val_loss       : -546.9666384503236\n",
      "Train Epoch: 353 [512/17352 (3%)] Loss: -710.118225\n",
      "Train Epoch: 353 [10182/17352 (59%)] Loss: -790.782240\n",
      "Train Epoch: 353 [17064/17352 (98%)] Loss: -772.515044\n",
      "    epoch          : 353\n",
      "    loss           : -687.6916601726252\n",
      "    val_loss       : -567.7842527919947\n",
      "Train Epoch: 354 [512/17352 (3%)] Loss: -733.071716\n",
      "Train Epoch: 354 [10646/17352 (61%)] Loss: -774.664812\n",
      "Train Epoch: 354 [16882/17352 (97%)] Loss: -734.357486\n",
      "    epoch          : 354\n",
      "    loss           : -723.3577290295722\n",
      "    val_loss       : -620.3345214264847\n",
      "Train Epoch: 355 [512/17352 (3%)] Loss: -796.833557\n",
      "Train Epoch: 355 [10339/17352 (60%)] Loss: -788.054509\n",
      "Train Epoch: 355 [16957/17352 (98%)] Loss: -745.916035\n",
      "    epoch          : 355\n",
      "    loss           : -742.2022006557133\n",
      "    val_loss       : -607.0762476790965\n",
      "Train Epoch: 356 [512/17352 (3%)] Loss: -785.037415\n",
      "Train Epoch: 356 [10764/17352 (62%)] Loss: -665.552506\n",
      "Train Epoch: 356 [16883/17352 (97%)] Loss: -739.340436\n",
      "    epoch          : 356\n",
      "    loss           : -751.0315301188876\n",
      "    val_loss       : -610.5575598206252\n",
      "Train Epoch: 357 [512/17352 (3%)] Loss: -786.205505\n",
      "Train Epoch: 357 [10306/17352 (59%)] Loss: -841.269057\n",
      "Train Epoch: 357 [17277/17352 (100%)] Loss: -777.779523\n",
      "    epoch          : 357\n",
      "    loss           : -734.1147688793649\n",
      "    val_loss       : -603.8634015420888\n",
      "Train Epoch: 358 [512/17352 (3%)] Loss: -799.345703\n",
      "Train Epoch: 358 [10461/17352 (60%)] Loss: -847.300307\n",
      "Train Epoch: 358 [17124/17352 (99%)] Loss: -727.209031\n",
      "    epoch          : 358\n",
      "    loss           : -739.9885064336708\n",
      "    val_loss       : -585.3895650482174\n",
      "Train Epoch: 359 [512/17352 (3%)] Loss: -789.333374\n",
      "Train Epoch: 359 [9930/17352 (57%)] Loss: -693.276600\n",
      "Train Epoch: 359 [17124/17352 (99%)] Loss: -801.610231\n",
      "    epoch          : 359\n",
      "    loss           : -742.801719527479\n",
      "    val_loss       : -595.4620879945401\n",
      "Train Epoch: 360 [512/17352 (3%)] Loss: -787.848755\n",
      "Train Epoch: 360 [10301/17352 (59%)] Loss: -719.023998\n",
      "Train Epoch: 360 [16922/17352 (98%)] Loss: -858.766344\n",
      "    epoch          : 360\n",
      "    loss           : -725.4351788387152\n",
      "    val_loss       : -617.1394143527459\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch360.pth ...\n",
      "Train Epoch: 361 [512/17352 (3%)] Loss: -813.673706\n",
      "Train Epoch: 361 [10200/17352 (59%)] Loss: -623.785207\n",
      "Train Epoch: 361 [17153/17352 (99%)] Loss: -777.659382\n",
      "    epoch          : 361\n",
      "    loss           : -702.2080111545944\n",
      "    val_loss       : -425.67188093458344\n",
      "Train Epoch: 362 [512/17352 (3%)] Loss: -642.927429\n",
      "Train Epoch: 362 [10421/17352 (60%)] Loss: -668.626717\n",
      "Train Epoch: 362 [17064/17352 (98%)] Loss: -642.055319\n",
      "    epoch          : 362\n",
      "    loss           : -605.5728388520081\n",
      "    val_loss       : -186.86586236257267\n",
      "Train Epoch: 363 [512/17352 (3%)] Loss: -267.754059\n",
      "Train Epoch: 363 [10073/17352 (58%)] Loss: -286.320399\n",
      "Train Epoch: 363 [16958/17352 (98%)] Loss: -689.828915\n",
      "    epoch          : 363\n",
      "    loss           : -418.0266542880295\n",
      "    val_loss       : -467.81906682926734\n",
      "Train Epoch: 364 [512/17352 (3%)] Loss: -655.301697\n",
      "Train Epoch: 364 [10868/17352 (63%)] Loss: -742.947311\n",
      "Train Epoch: 364 [17049/17352 (98%)] Loss: -610.614293\n",
      "    epoch          : 364\n",
      "    loss           : -597.2313231301717\n",
      "    val_loss       : -538.1151208072977\n",
      "Train Epoch: 365 [512/17352 (3%)] Loss: -744.785461\n",
      "Train Epoch: 365 [10254/17352 (59%)] Loss: -754.821846\n",
      "Train Epoch: 365 [16887/17352 (97%)] Loss: -807.600080\n",
      "    epoch          : 365\n",
      "    loss           : -704.9050856941835\n",
      "    val_loss       : -586.1913529839953\n",
      "Train Epoch: 366 [512/17352 (3%)] Loss: -775.964233\n",
      "Train Epoch: 366 [10414/17352 (60%)] Loss: -781.065862\n",
      "Train Epoch: 366 [17335/17352 (100%)] Loss: -804.457865\n",
      "    epoch          : 366\n",
      "    loss           : -744.250622711722\n",
      "    val_loss       : -597.7511247687381\n",
      "Train Epoch: 367 [512/17352 (3%)] Loss: -760.317810\n",
      "Train Epoch: 367 [9813/17352 (57%)] Loss: -814.219740\n",
      "Train Epoch: 367 [16887/17352 (97%)] Loss: -841.080357\n",
      "    epoch          : 367\n",
      "    loss           : -749.5207358263838\n",
      "    val_loss       : -619.4013831744542\n",
      "Train Epoch: 368 [512/17352 (3%)] Loss: -610.278625\n",
      "Train Epoch: 368 [10278/17352 (59%)] Loss: -610.925806\n",
      "Train Epoch: 368 [16934/17352 (98%)] Loss: -627.957087\n",
      "    epoch          : 368\n",
      "    loss           : -751.5361371864851\n",
      "    val_loss       : -605.0532979612068\n",
      "Train Epoch: 369 [512/17352 (3%)] Loss: -735.933350\n",
      "Train Epoch: 369 [9963/17352 (57%)] Loss: -769.510914\n",
      "Train Epoch: 369 [17124/17352 (99%)] Loss: -812.523737\n",
      "    epoch          : 369\n",
      "    loss           : -713.8332278234027\n",
      "    val_loss       : -586.8422992466129\n",
      "Train Epoch: 370 [512/17352 (3%)] Loss: -740.393555\n",
      "Train Epoch: 370 [10309/17352 (59%)] Loss: -643.478651\n",
      "Train Epoch: 370 [16878/17352 (97%)] Loss: -731.678883\n",
      "    epoch          : 370\n",
      "    loss           : -746.5840942432491\n",
      "    val_loss       : -628.185085110969\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch370.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 371 [512/17352 (3%)] Loss: -806.920227\n",
      "Train Epoch: 371 [10575/17352 (61%)] Loss: -713.246658\n",
      "Train Epoch: 371 [17106/17352 (99%)] Loss: -734.396345\n",
      "    epoch          : 371\n",
      "    loss           : -762.3733482325556\n",
      "    val_loss       : -632.5255497268728\n",
      "Train Epoch: 372 [512/17352 (3%)] Loss: -812.942505\n",
      "Train Epoch: 372 [10475/17352 (60%)] Loss: -688.650487\n",
      "Train Epoch: 372 [17263/17352 (99%)] Loss: -690.361589\n",
      "    epoch          : 372\n",
      "    loss           : -762.2043269915072\n",
      "    val_loss       : -620.8338643816664\n",
      "Train Epoch: 373 [512/17352 (3%)] Loss: -803.221802\n",
      "Train Epoch: 373 [10679/17352 (62%)] Loss: -789.434830\n",
      "Train Epoch: 373 [17108/17352 (99%)] Loss: -688.697817\n",
      "    epoch          : 373\n",
      "    loss           : -746.3186548080674\n",
      "    val_loss       : -591.3895723554821\n",
      "Train Epoch: 374 [512/17352 (3%)] Loss: -764.506714\n",
      "Train Epoch: 374 [10540/17352 (61%)] Loss: -707.655924\n",
      "Train Epoch: 374 [16922/17352 (98%)] Loss: -801.360517\n",
      "    epoch          : 374\n",
      "    loss           : -761.0762310508338\n",
      "    val_loss       : -623.9432481511574\n",
      "Train Epoch: 375 [512/17352 (3%)] Loss: -620.862122\n",
      "Train Epoch: 375 [10252/17352 (59%)] Loss: -820.362791\n",
      "Train Epoch: 375 [17106/17352 (99%)] Loss: -748.837489\n",
      "    epoch          : 375\n",
      "    loss           : -768.7002725865822\n",
      "    val_loss       : -612.6799681922997\n",
      "Train Epoch: 376 [512/17352 (3%)] Loss: -797.615479\n",
      "Train Epoch: 376 [10174/17352 (59%)] Loss: -798.368151\n",
      "Train Epoch: 376 [16923/17352 (98%)] Loss: -792.750000\n",
      "    epoch          : 376\n",
      "    loss           : -760.474090783403\n",
      "    val_loss       : -629.6096540369558\n",
      "Train Epoch: 377 [512/17352 (3%)] Loss: -807.923096\n",
      "Train Epoch: 377 [10362/17352 (60%)] Loss: -794.192510\n",
      "Train Epoch: 377 [17106/17352 (99%)] Loss: -816.434699\n",
      "    epoch          : 377\n",
      "    loss           : -758.2729234967463\n",
      "    val_loss       : -602.317087598054\n",
      "Train Epoch: 378 [512/17352 (3%)] Loss: -787.808838\n",
      "Train Epoch: 378 [10470/17352 (60%)] Loss: -827.712405\n",
      "Train Epoch: 378 [16887/17352 (97%)] Loss: -685.909446\n",
      "    epoch          : 378\n",
      "    loss           : -758.1684034143422\n",
      "    val_loss       : -617.1160727054062\n",
      "Train Epoch: 379 [512/17352 (3%)] Loss: -805.886353\n",
      "Train Epoch: 379 [10356/17352 (60%)] Loss: -792.105013\n",
      "Train Epoch: 379 [16992/17352 (98%)] Loss: -794.104588\n",
      "    epoch          : 379\n",
      "    loss           : -754.5271287295966\n",
      "    val_loss       : -586.391131766792\n",
      "Train Epoch: 380 [512/17352 (3%)] Loss: -771.263367\n",
      "Train Epoch: 380 [10416/17352 (60%)] Loss: -827.559177\n",
      "Train Epoch: 380 [17153/17352 (99%)] Loss: -714.394345\n",
      "    epoch          : 380\n",
      "    loss           : -757.8678874682837\n",
      "    val_loss       : -618.3469069927479\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch380.pth ...\n",
      "Train Epoch: 381 [512/17352 (3%)] Loss: -807.633667\n",
      "Train Epoch: 381 [10191/17352 (59%)] Loss: -810.562061\n",
      "Train Epoch: 381 [17153/17352 (99%)] Loss: -648.515999\n",
      "    epoch          : 381\n",
      "    loss           : -762.9659560447878\n",
      "    val_loss       : -619.7264742408257\n",
      "Train Epoch: 382 [512/17352 (3%)] Loss: -805.437378\n",
      "Train Epoch: 382 [10388/17352 (60%)] Loss: -811.985365\n",
      "Train Epoch: 382 [16923/17352 (98%)] Loss: -600.929507\n",
      "    epoch          : 382\n",
      "    loss           : -776.8821225172707\n",
      "    val_loss       : -630.4727795236815\n",
      "Train Epoch: 383 [512/17352 (3%)] Loss: -820.638184\n",
      "Train Epoch: 383 [10454/17352 (60%)] Loss: -846.665406\n",
      "Train Epoch: 383 [17101/17352 (99%)] Loss: -808.327183\n",
      "    epoch          : 383\n",
      "    loss           : -760.824497640303\n",
      "    val_loss       : -612.5575673867763\n",
      "Train Epoch: 384 [512/17352 (3%)] Loss: -817.251221\n",
      "Train Epoch: 384 [9570/17352 (55%)] Loss: -780.313675\n",
      "Train Epoch: 384 [16883/17352 (97%)] Loss: -732.490017\n",
      "    epoch          : 384\n",
      "    loss           : -780.1678845075791\n",
      "    val_loss       : -628.1717892451221\n",
      "Train Epoch: 385 [512/17352 (3%)] Loss: -824.356567\n",
      "Train Epoch: 385 [10760/17352 (62%)] Loss: -832.238421\n",
      "Train Epoch: 385 [17124/17352 (99%)] Loss: -662.283071\n",
      "    epoch          : 385\n",
      "    loss           : -773.1787825035531\n",
      "    val_loss       : -630.1891792378918\n",
      "Train Epoch: 386 [512/17352 (3%)] Loss: -820.995544\n",
      "Train Epoch: 386 [10192/17352 (59%)] Loss: -807.990625\n",
      "Train Epoch: 386 [17101/17352 (99%)] Loss: -731.309073\n",
      "    epoch          : 386\n",
      "    loss           : -760.3706534511338\n",
      "    val_loss       : -517.7917130387848\n",
      "Train Epoch: 387 [512/17352 (3%)] Loss: -766.382935\n",
      "Train Epoch: 387 [10179/17352 (59%)] Loss: -786.083379\n",
      "Train Epoch: 387 [16992/17352 (98%)] Loss: -760.404753\n",
      "    epoch          : 387\n",
      "    loss           : -758.624905873348\n",
      "    val_loss       : -592.1999737469062\n",
      "Train Epoch: 388 [512/17352 (3%)] Loss: -799.695190\n",
      "Train Epoch: 388 [10018/17352 (58%)] Loss: -725.509161\n",
      "Train Epoch: 388 [17143/17352 (99%)] Loss: -780.479665\n",
      "    epoch          : 388\n",
      "    loss           : -768.0318553238883\n",
      "    val_loss       : -611.1833753165646\n",
      "Train Epoch: 389 [512/17352 (3%)] Loss: -829.901855\n",
      "Train Epoch: 389 [10237/17352 (59%)] Loss: -699.067877\n",
      "Train Epoch: 389 [17133/17352 (99%)] Loss: -721.737122\n",
      "    epoch          : 389\n",
      "    loss           : -772.2948417596123\n",
      "    val_loss       : -611.2854588344866\n",
      "Train Epoch: 390 [512/17352 (3%)] Loss: -810.813232\n",
      "Train Epoch: 390 [10252/17352 (59%)] Loss: -834.659312\n",
      "Train Epoch: 390 [17124/17352 (99%)] Loss: -712.119031\n",
      "    epoch          : 390\n",
      "    loss           : -728.8413384654077\n",
      "    val_loss       : -383.78691564084437\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch390.pth ...\n",
      "Train Epoch: 391 [512/17352 (3%)] Loss: -629.742310\n",
      "Train Epoch: 391 [10573/17352 (61%)] Loss: -681.200707\n",
      "Train Epoch: 391 [16923/17352 (98%)] Loss: -766.975911\n",
      "    epoch          : 391\n",
      "    loss           : -691.6205719847392\n",
      "    val_loss       : -557.0110836983582\n",
      "Train Epoch: 392 [512/17352 (3%)] Loss: -768.788269\n",
      "Train Epoch: 392 [10099/17352 (58%)] Loss: -724.164583\n",
      "Train Epoch: 392 [17106/17352 (99%)] Loss: -498.040707\n",
      "    epoch          : 392\n",
      "    loss           : -700.0778186229684\n",
      "    val_loss       : -483.29605076436076\n",
      "Train Epoch: 393 [512/17352 (3%)] Loss: -697.528320\n",
      "Train Epoch: 393 [10150/17352 (58%)] Loss: -521.916753\n",
      "Train Epoch: 393 [16939/17352 (98%)] Loss: -801.171114\n",
      "    epoch          : 393\n",
      "    loss           : -694.3715219061223\n",
      "    val_loss       : -578.1730590259849\n",
      "Train Epoch: 394 [512/17352 (3%)] Loss: -789.116760\n",
      "Train Epoch: 394 [10520/17352 (61%)] Loss: -635.549991\n",
      "Train Epoch: 394 [17133/17352 (99%)] Loss: -636.068519\n",
      "    epoch          : 394\n",
      "    loss           : -731.855321276126\n",
      "    val_loss       : -588.8431011372567\n",
      "Train Epoch: 395 [512/17352 (3%)] Loss: -782.081970\n",
      "Train Epoch: 395 [10270/17352 (59%)] Loss: -668.122608\n",
      "Train Epoch: 395 [16988/17352 (98%)] Loss: -629.460612\n",
      "    epoch          : 395\n",
      "    loss           : -699.3572736009838\n",
      "    val_loss       : -555.0659200690077\n",
      "Train Epoch: 396 [512/17352 (3%)] Loss: -563.555420\n",
      "Train Epoch: 396 [10540/17352 (61%)] Loss: -779.555253\n",
      "Train Epoch: 396 [17126/17352 (99%)] Loss: -781.132097\n",
      "    epoch          : 396\n",
      "    loss           : -729.2812985309937\n",
      "    val_loss       : -543.378846058346\n",
      "Train Epoch: 397 [512/17352 (3%)] Loss: -741.095581\n",
      "Train Epoch: 397 [10353/17352 (60%)] Loss: -774.344622\n",
      "Train Epoch: 397 [17124/17352 (99%)] Loss: -775.204852\n",
      "    epoch          : 397\n",
      "    loss           : -732.0991330553181\n",
      "    val_loss       : -590.491119823648\n",
      "Train Epoch: 398 [512/17352 (3%)] Loss: -790.771912\n",
      "Train Epoch: 398 [10701/17352 (62%)] Loss: -761.115390\n",
      "Train Epoch: 398 [17106/17352 (99%)] Loss: -641.897786\n",
      "    epoch          : 398\n",
      "    loss           : -715.122377104824\n",
      "    val_loss       : -544.9543798975461\n",
      "Train Epoch: 399 [512/17352 (3%)] Loss: -778.172913\n",
      "Train Epoch: 399 [10295/17352 (59%)] Loss: -833.241223\n",
      "Train Epoch: 399 [17049/17352 (98%)] Loss: -775.692629\n",
      "    epoch          : 399\n",
      "    loss           : -719.6995790401841\n",
      "    val_loss       : -594.6186266545453\n",
      "Train Epoch: 400 [512/17352 (3%)] Loss: -777.739136\n",
      "Train Epoch: 400 [9528/17352 (55%)] Loss: -701.144740\n",
      "Train Epoch: 400 [16923/17352 (98%)] Loss: -603.485330\n",
      "    epoch          : 400\n",
      "    loss           : -685.2202164773073\n",
      "    val_loss       : -531.0113787611011\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch400.pth ...\n",
      "Train Epoch: 401 [512/17352 (3%)] Loss: -713.778809\n",
      "Train Epoch: 401 [9657/17352 (56%)] Loss: -888.383021\n",
      "Train Epoch: 401 [16882/17352 (97%)] Loss: -811.057431\n",
      "    epoch          : 401\n",
      "    loss           : -742.0779635849576\n",
      "    val_loss       : -624.6325118136793\n",
      "Train Epoch: 402 [512/17352 (3%)] Loss: -822.244080\n",
      "Train Epoch: 402 [10550/17352 (61%)] Loss: -754.443576\n",
      "Train Epoch: 402 [16958/17352 (98%)] Loss: -830.749867\n",
      "    epoch          : 402\n",
      "    loss           : -780.9728990889472\n",
      "    val_loss       : -581.8950933636411\n",
      "Train Epoch: 403 [512/17352 (3%)] Loss: -790.492920\n",
      "Train Epoch: 403 [10295/17352 (59%)] Loss: -487.412733\n",
      "Train Epoch: 403 [16887/17352 (97%)] Loss: -715.575822\n",
      "    epoch          : 403\n",
      "    loss           : -632.1157541790477\n",
      "    val_loss       : -393.60557572934204\n",
      "Train Epoch: 404 [512/17352 (3%)] Loss: -413.697296\n",
      "Train Epoch: 404 [10120/17352 (58%)] Loss: -731.603212\n",
      "Train Epoch: 404 [17253/17352 (99%)] Loss: -773.743655\n",
      "    epoch          : 404\n",
      "    loss           : -571.5311252993331\n",
      "    val_loss       : -382.5977747097783\n",
      "Train Epoch: 405 [512/17352 (3%)] Loss: -657.400635\n",
      "Train Epoch: 405 [10434/17352 (60%)] Loss: -823.917484\n",
      "Train Epoch: 405 [17106/17352 (99%)] Loss: -649.157785\n",
      "    epoch          : 405\n",
      "    loss           : -701.3485816343957\n",
      "    val_loss       : -573.6370388254375\n",
      "Train Epoch: 406 [512/17352 (3%)] Loss: -786.817688\n",
      "Train Epoch: 406 [10634/17352 (61%)] Loss: -619.233902\n",
      "Train Epoch: 406 [17124/17352 (99%)] Loss: -752.436811\n",
      "    epoch          : 406\n",
      "    loss           : -754.6982598114555\n",
      "    val_loss       : -596.4952376626246\n",
      "Train Epoch: 407 [512/17352 (3%)] Loss: -750.425903\n",
      "Train Epoch: 407 [10770/17352 (62%)] Loss: -593.342204\n",
      "Train Epoch: 407 [16992/17352 (98%)] Loss: -579.309987\n",
      "    epoch          : 407\n",
      "    loss           : -751.8299439448015\n",
      "    val_loss       : -589.2316667156955\n",
      "Train Epoch: 408 [512/17352 (3%)] Loss: -748.537170\n",
      "Train Epoch: 408 [9633/17352 (56%)] Loss: -834.034235\n",
      "Train Epoch: 408 [17101/17352 (99%)] Loss: -883.683498\n",
      "    epoch          : 408\n",
      "    loss           : -749.180042294072\n",
      "    val_loss       : -610.4713498850647\n",
      "Train Epoch: 409 [512/17352 (3%)] Loss: -785.344727\n",
      "Train Epoch: 409 [10748/17352 (62%)] Loss: -592.026210\n",
      "Train Epoch: 409 [16988/17352 (98%)] Loss: -599.627258\n",
      "    epoch          : 409\n",
      "    loss           : -746.2822141748276\n",
      "    val_loss       : -583.0348213890504\n",
      "Train Epoch: 410 [512/17352 (3%)] Loss: -738.481873\n",
      "Train Epoch: 410 [10555/17352 (61%)] Loss: -715.790520\n",
      "Train Epoch: 410 [17108/17352 (99%)] Loss: -828.168445\n",
      "    epoch          : 410\n",
      "    loss           : -741.5034980518326\n",
      "    val_loss       : -567.4616693265765\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch410.pth ...\n",
      "Train Epoch: 411 [512/17352 (3%)] Loss: -752.323792\n",
      "Train Epoch: 411 [10279/17352 (59%)] Loss: -689.891406\n",
      "Train Epoch: 411 [17064/17352 (98%)] Loss: -849.484715\n",
      "    epoch          : 411\n",
      "    loss           : -754.0769817065909\n",
      "    val_loss       : -603.4757347328651\n",
      "Train Epoch: 412 [512/17352 (3%)] Loss: -803.496582\n",
      "Train Epoch: 412 [9608/17352 (55%)] Loss: -824.804782\n",
      "Train Epoch: 412 [17277/17352 (100%)] Loss: -840.336483\n",
      "    epoch          : 412\n",
      "    loss           : -767.582016090044\n",
      "    val_loss       : -600.2482456451845\n",
      "Train Epoch: 413 [512/17352 (3%)] Loss: -797.900635\n",
      "Train Epoch: 413 [10542/17352 (61%)] Loss: -786.175086\n",
      "Train Epoch: 413 [16883/17352 (97%)] Loss: -705.057117\n",
      "    epoch          : 413\n",
      "    loss           : -726.8092725380064\n",
      "    val_loss       : -618.0600089746642\n",
      "Train Epoch: 414 [512/17352 (3%)] Loss: -779.798828\n",
      "Train Epoch: 414 [10877/17352 (63%)] Loss: -718.976749\n",
      "Train Epoch: 414 [17253/17352 (99%)] Loss: -884.930513\n",
      "    epoch          : 414\n",
      "    loss           : -754.5294353809375\n",
      "    val_loss       : -605.8385300642548\n",
      "Train Epoch: 415 [512/17352 (3%)] Loss: -797.394104\n",
      "Train Epoch: 415 [10482/17352 (60%)] Loss: -790.196257\n",
      "Train Epoch: 415 [17106/17352 (99%)] Loss: -628.442658\n",
      "    epoch          : 415\n",
      "    loss           : -790.724900440238\n",
      "    val_loss       : -649.7591963469027\n",
      "Train Epoch: 416 [512/17352 (3%)] Loss: -843.514282\n",
      "Train Epoch: 416 [10705/17352 (62%)] Loss: -880.594464\n",
      "Train Epoch: 416 [16988/17352 (98%)] Loss: -740.213976\n",
      "    epoch          : 416\n",
      "    loss           : -794.5118277760909\n",
      "    val_loss       : -646.0858252116295\n",
      "Train Epoch: 417 [512/17352 (3%)] Loss: -845.807983\n",
      "Train Epoch: 417 [9928/17352 (57%)] Loss: -824.294677\n",
      "Train Epoch: 417 [16958/17352 (98%)] Loss: -789.337431\n",
      "    epoch          : 417\n",
      "    loss           : -794.9447920678456\n",
      "    val_loss       : -632.7663843023171\n",
      "Train Epoch: 418 [512/17352 (3%)] Loss: -849.105042\n",
      "Train Epoch: 418 [9976/17352 (57%)] Loss: -697.384208\n",
      "Train Epoch: 418 [16958/17352 (98%)] Loss: -711.986455\n",
      "    epoch          : 418\n",
      "    loss           : -788.736902695966\n",
      "    val_loss       : -636.3138801739234\n",
      "Train Epoch: 419 [512/17352 (3%)] Loss: -836.901611\n",
      "Train Epoch: 419 [10131/17352 (58%)] Loss: -730.968750\n",
      "Train Epoch: 419 [16958/17352 (98%)] Loss: -754.717708\n",
      "    epoch          : 419\n",
      "    loss           : -716.5118889421892\n",
      "    val_loss       : -613.4790250396206\n",
      "Train Epoch: 420 [512/17352 (3%)] Loss: -813.637573\n",
      "Train Epoch: 420 [10367/17352 (60%)] Loss: -599.228562\n",
      "Train Epoch: 420 [16872/17352 (97%)] Loss: -751.894413\n",
      "    epoch          : 420\n",
      "    loss           : -635.4961590613627\n",
      "    val_loss       : -536.2644872903994\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch420.pth ...\n",
      "Train Epoch: 421 [512/17352 (3%)] Loss: -759.400452\n",
      "Train Epoch: 421 [10382/17352 (60%)] Loss: -532.476332\n",
      "Train Epoch: 421 [17253/17352 (99%)] Loss: -762.400575\n",
      "    epoch          : 421\n",
      "    loss           : -561.7734416025769\n",
      "    val_loss       : -438.3573713907093\n",
      "Train Epoch: 422 [512/17352 (3%)] Loss: -608.962280\n",
      "Train Epoch: 422 [10434/17352 (60%)] Loss: -573.839900\n",
      "Train Epoch: 422 [17133/17352 (99%)] Loss: -773.872840\n",
      "    epoch          : 422\n",
      "    loss           : -690.7767395880551\n",
      "    val_loss       : -545.566614506744\n",
      "Train Epoch: 423 [512/17352 (3%)] Loss: -756.842651\n",
      "Train Epoch: 423 [10341/17352 (60%)] Loss: -822.278090\n",
      "Train Epoch: 423 [17253/17352 (99%)] Loss: -550.998377\n",
      "    epoch          : 423\n",
      "    loss           : -694.547252347752\n",
      "    val_loss       : -489.27062723757126\n",
      "Train Epoch: 424 [512/17352 (3%)] Loss: -650.784851\n",
      "Train Epoch: 424 [10666/17352 (61%)] Loss: -774.176039\n",
      "Train Epoch: 424 [17090/17352 (98%)] Loss: -742.352151\n",
      "    epoch          : 424\n",
      "    loss           : -696.8811391935684\n",
      "    val_loss       : -590.184910555569\n",
      "Train Epoch: 425 [512/17352 (3%)] Loss: -728.348999\n",
      "Train Epoch: 425 [10248/17352 (59%)] Loss: -819.591322\n",
      "Train Epoch: 425 [16923/17352 (98%)] Loss: -861.250791\n",
      "    epoch          : 425\n",
      "    loss           : -753.0414252625487\n",
      "    val_loss       : -608.290880749319\n",
      "Train Epoch: 426 [512/17352 (3%)] Loss: -805.156799\n",
      "Train Epoch: 426 [9813/17352 (57%)] Loss: -643.096895\n",
      "Train Epoch: 426 [16922/17352 (98%)] Loss: -831.726656\n",
      "    epoch          : 426\n",
      "    loss           : -767.9324492701322\n",
      "    val_loss       : -643.0129851932688\n",
      "Train Epoch: 427 [512/17352 (3%)] Loss: -614.727478\n",
      "Train Epoch: 427 [10544/17352 (61%)] Loss: -934.029188\n",
      "Train Epoch: 427 [16887/17352 (97%)] Loss: -750.419405\n",
      "    epoch          : 427\n",
      "    loss           : -789.9590918883546\n",
      "    val_loss       : -647.4175736013301\n",
      "Train Epoch: 428 [512/17352 (3%)] Loss: -848.192261\n",
      "Train Epoch: 428 [10506/17352 (61%)] Loss: -888.793044\n",
      "Train Epoch: 428 [17016/17352 (98%)] Loss: -251.586800\n",
      "    epoch          : 428\n",
      "    loss           : -746.860870442437\n",
      "    val_loss       : -339.7618797459017\n",
      "Train Epoch: 429 [512/17352 (3%)] Loss: -574.617432\n",
      "Train Epoch: 429 [10833/17352 (62%)] Loss: -825.893257\n",
      "Train Epoch: 429 [17101/17352 (99%)] Loss: -830.448568\n",
      "    epoch          : 429\n",
      "    loss           : -734.6593922037755\n",
      "    val_loss       : -648.9011468507451\n",
      "Train Epoch: 430 [512/17352 (3%)] Loss: -834.967041\n",
      "Train Epoch: 430 [10399/17352 (60%)] Loss: -716.388342\n",
      "Train Epoch: 430 [16988/17352 (98%)] Loss: -847.535112\n",
      "    epoch          : 430\n",
      "    loss           : -799.6079462847504\n",
      "    val_loss       : -619.8152311488647\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch430.pth ...\n",
      "Train Epoch: 431 [512/17352 (3%)] Loss: -839.566833\n",
      "Train Epoch: 431 [9896/17352 (57%)] Loss: -816.884919\n",
      "Train Epoch: 431 [16923/17352 (98%)] Loss: -744.591822\n",
      "    epoch          : 431\n",
      "    loss           : -782.1656399510762\n",
      "    val_loss       : -622.2314706682498\n",
      "Train Epoch: 432 [512/17352 (3%)] Loss: -847.538208\n",
      "Train Epoch: 432 [10269/17352 (59%)] Loss: -779.905702\n",
      "Train Epoch: 432 [16882/17352 (97%)] Loss: -696.464614\n",
      "    epoch          : 432\n",
      "    loss           : -785.2970895084461\n",
      "    val_loss       : -625.064558297226\n",
      "Train Epoch: 433 [512/17352 (3%)] Loss: -764.756836\n",
      "Train Epoch: 433 [10667/17352 (61%)] Loss: -875.554328\n",
      "Train Epoch: 433 [17126/17352 (99%)] Loss: -516.807560\n",
      "    epoch          : 433\n",
      "    loss           : -750.2116157626306\n",
      "    val_loss       : -591.7073008112736\n",
      "Train Epoch: 434 [512/17352 (3%)] Loss: -785.229858\n",
      "Train Epoch: 434 [10305/17352 (59%)] Loss: -627.205128\n",
      "Train Epoch: 434 [16887/17352 (97%)] Loss: -877.665587\n",
      "    epoch          : 434\n",
      "    loss           : -778.3082283214641\n",
      "    val_loss       : -654.095003246013\n",
      "Train Epoch: 435 [512/17352 (3%)] Loss: -853.121582\n",
      "Train Epoch: 435 [10103/17352 (58%)] Loss: -769.461397\n",
      "Train Epoch: 435 [17133/17352 (99%)] Loss: -837.432344\n",
      "    epoch          : 435\n",
      "    loss           : -776.0071455650303\n",
      "    val_loss       : -595.9469082088475\n",
      "Train Epoch: 436 [512/17352 (3%)] Loss: -796.295959\n",
      "Train Epoch: 436 [10198/17352 (59%)] Loss: -850.261327\n",
      "Train Epoch: 436 [16939/17352 (98%)] Loss: -868.949187\n",
      "    epoch          : 436\n",
      "    loss           : -758.4378162126794\n",
      "    val_loss       : -585.618059868438\n",
      "Train Epoch: 437 [512/17352 (3%)] Loss: -785.109497\n",
      "Train Epoch: 437 [10579/17352 (61%)] Loss: -770.266016\n",
      "Train Epoch: 437 [16887/17352 (97%)] Loss: -824.386955\n",
      "    epoch          : 437\n",
      "    loss           : -742.306716321117\n",
      "    val_loss       : -606.872841960922\n",
      "Train Epoch: 438 [512/17352 (3%)] Loss: -844.842590\n",
      "Train Epoch: 438 [9583/17352 (55%)] Loss: -683.865924\n",
      "Train Epoch: 438 [16923/17352 (98%)] Loss: -753.256138\n",
      "    epoch          : 438\n",
      "    loss           : -759.7877250067471\n",
      "    val_loss       : -615.1657267854833\n",
      "Train Epoch: 439 [512/17352 (3%)] Loss: -812.674927\n",
      "Train Epoch: 439 [10350/17352 (60%)] Loss: -877.041622\n",
      "Train Epoch: 439 [16878/17352 (97%)] Loss: -715.378906\n",
      "    epoch          : 439\n",
      "    loss           : -727.8484739930913\n",
      "    val_loss       : -616.7114303981313\n",
      "Train Epoch: 440 [512/17352 (3%)] Loss: -818.299194\n",
      "Train Epoch: 440 [10263/17352 (59%)] Loss: -644.119100\n",
      "Train Epoch: 440 [17049/17352 (98%)] Loss: -525.356566\n",
      "    epoch          : 440\n",
      "    loss           : -572.388850247743\n",
      "    val_loss       : -473.70563604460904\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch440.pth ...\n",
      "Train Epoch: 441 [512/17352 (3%)] Loss: -675.778137\n",
      "Train Epoch: 441 [9624/17352 (55%)] Loss: -522.811715\n",
      "Train Epoch: 441 [16878/17352 (97%)] Loss: -562.287658\n",
      "    epoch          : 441\n",
      "    loss           : -618.8708577987746\n",
      "    val_loss       : -318.9628337506887\n",
      "Train Epoch: 442 [512/17352 (3%)] Loss: -522.667053\n",
      "Train Epoch: 442 [10313/17352 (59%)] Loss: -634.723542\n",
      "Train Epoch: 442 [16872/17352 (97%)] Loss: -561.221237\n",
      "    epoch          : 442\n",
      "    loss           : -668.4650087264728\n",
      "    val_loss       : -575.6775512702505\n",
      "Train Epoch: 443 [512/17352 (3%)] Loss: -763.636353\n",
      "Train Epoch: 443 [10382/17352 (60%)] Loss: -757.113496\n",
      "Train Epoch: 443 [17153/17352 (99%)] Loss: -716.620069\n",
      "    epoch          : 443\n",
      "    loss           : -758.588724725724\n",
      "    val_loss       : -621.9366243273179\n",
      "Train Epoch: 444 [512/17352 (3%)] Loss: -791.333069\n",
      "Train Epoch: 444 [9707/17352 (56%)] Loss: -892.537919\n",
      "Train Epoch: 444 [17124/17352 (99%)] Loss: -824.810655\n",
      "    epoch          : 444\n",
      "    loss           : -756.6570170813657\n",
      "    val_loss       : -538.476895573945\n",
      "Train Epoch: 445 [512/17352 (3%)] Loss: -789.497070\n",
      "Train Epoch: 445 [10235/17352 (59%)] Loss: -688.692708\n",
      "Train Epoch: 445 [17016/17352 (98%)] Loss: -815.850546\n",
      "    epoch          : 445\n",
      "    loss           : -726.6070668367422\n",
      "    val_loss       : -565.6807635995001\n",
      "Train Epoch: 446 [512/17352 (3%)] Loss: -767.242737\n",
      "Train Epoch: 446 [10077/17352 (58%)] Loss: -835.992947\n",
      "Train Epoch: 446 [17108/17352 (99%)] Loss: -724.522384\n",
      "    epoch          : 446\n",
      "    loss           : -707.3920181252772\n",
      "    val_loss       : -372.2429089226592\n",
      "Train Epoch: 447 [512/17352 (3%)] Loss: -605.337158\n",
      "Train Epoch: 447 [10463/17352 (60%)] Loss: -764.643513\n",
      "Train Epoch: 447 [16878/17352 (97%)] Loss: -753.657292\n",
      "    epoch          : 447\n",
      "    loss           : -684.8849265799244\n",
      "    val_loss       : -599.8581741155631\n",
      "Train Epoch: 448 [512/17352 (3%)] Loss: -819.317017\n",
      "Train Epoch: 448 [10785/17352 (62%)] Loss: -727.472442\n",
      "Train Epoch: 448 [17263/17352 (99%)] Loss: -596.806922\n",
      "    epoch          : 448\n",
      "    loss           : -789.1586281246765\n",
      "    val_loss       : -622.079225615817\n",
      "Train Epoch: 449 [512/17352 (3%)] Loss: -820.857605\n",
      "Train Epoch: 449 [10690/17352 (62%)] Loss: -837.193850\n",
      "Train Epoch: 449 [17064/17352 (98%)] Loss: -857.470104\n",
      "    epoch          : 449\n",
      "    loss           : -793.0005061914796\n",
      "    val_loss       : -631.2668147562969\n",
      "Train Epoch: 450 [512/17352 (3%)] Loss: -836.715637\n",
      "Train Epoch: 450 [10025/17352 (58%)] Loss: -779.992653\n",
      "Train Epoch: 450 [16878/17352 (97%)] Loss: -661.218234\n",
      "    epoch          : 450\n",
      "    loss           : -795.1602138681956\n",
      "    val_loss       : -647.624673883117\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch450.pth ...\n",
      "Train Epoch: 451 [512/17352 (3%)] Loss: -845.300415\n",
      "Train Epoch: 451 [10094/17352 (58%)] Loss: -885.693908\n",
      "Train Epoch: 451 [17108/17352 (99%)] Loss: -870.075759\n",
      "    epoch          : 451\n",
      "    loss           : -801.6287504640832\n",
      "    val_loss       : -635.5525353766714\n",
      "Train Epoch: 452 [512/17352 (3%)] Loss: -813.740845\n",
      "Train Epoch: 452 [10892/17352 (63%)] Loss: -741.271295\n",
      "Train Epoch: 452 [17049/17352 (98%)] Loss: -735.342482\n",
      "    epoch          : 452\n",
      "    loss           : -786.819209427548\n",
      "    val_loss       : -623.8997332549751\n",
      "Train Epoch: 453 [512/17352 (3%)] Loss: -830.725342\n",
      "Train Epoch: 453 [10742/17352 (62%)] Loss: -751.336322\n",
      "Train Epoch: 453 [17253/17352 (99%)] Loss: -794.160371\n",
      "    epoch          : 453\n",
      "    loss           : -795.3686345748299\n",
      "    val_loss       : -629.6172281310846\n",
      "Train Epoch: 454 [512/17352 (3%)] Loss: -851.031494\n",
      "Train Epoch: 454 [10861/17352 (63%)] Loss: -720.055070\n",
      "Train Epoch: 454 [16878/17352 (97%)] Loss: -805.660313\n",
      "    epoch          : 454\n",
      "    loss           : -761.7309276424313\n",
      "    val_loss       : -603.7411874740136\n",
      "Train Epoch: 455 [512/17352 (3%)] Loss: -809.338745\n",
      "Train Epoch: 455 [10434/17352 (60%)] Loss: -852.242468\n",
      "Train Epoch: 455 [17044/17352 (98%)] Loss: -812.801610\n",
      "    epoch          : 455\n",
      "    loss           : -788.5868800209695\n",
      "    val_loss       : -635.9579958704961\n",
      "Train Epoch: 456 [512/17352 (3%)] Loss: -855.695496\n",
      "Train Epoch: 456 [10592/17352 (61%)] Loss: -885.607533\n",
      "Train Epoch: 456 [17090/17352 (98%)] Loss: -862.535804\n",
      "    epoch          : 456\n",
      "    loss           : -802.0510627776073\n",
      "    val_loss       : -634.2364521748856\n",
      "Train Epoch: 457 [512/17352 (3%)] Loss: -827.669678\n",
      "Train Epoch: 457 [9727/17352 (56%)] Loss: -906.479654\n",
      "Train Epoch: 457 [16958/17352 (98%)] Loss: -874.033919\n",
      "    epoch          : 457\n",
      "    loss           : -809.9288684024027\n",
      "    val_loss       : -658.7397127715675\n",
      "Train Epoch: 458 [512/17352 (3%)] Loss: -845.121094\n",
      "Train Epoch: 458 [9870/17352 (57%)] Loss: -910.157187\n",
      "Train Epoch: 458 [16939/17352 (98%)] Loss: -848.585349\n",
      "    epoch          : 458\n",
      "    loss           : -818.6403798878243\n",
      "    val_loss       : -656.1471842474922\n",
      "Train Epoch: 459 [512/17352 (3%)] Loss: -877.402222\n",
      "Train Epoch: 459 [10089/17352 (58%)] Loss: -697.079022\n",
      "Train Epoch: 459 [16922/17352 (98%)] Loss: -745.220411\n",
      "    epoch          : 459\n",
      "    loss           : -591.9976132636453\n",
      "    val_loss       : -520.8252878711722\n",
      "Train Epoch: 460 [512/17352 (3%)] Loss: -374.779724\n",
      "Train Epoch: 460 [10515/17352 (61%)] Loss: -288.811727\n",
      "Train Epoch: 460 [16957/17352 (98%)] Loss: -523.794339\n",
      "    epoch          : 460\n",
      "    loss           : -511.44792987384614\n",
      "    val_loss       : -518.9874689527514\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch460.pth ...\n",
      "Train Epoch: 461 [512/17352 (3%)] Loss: -716.195007\n",
      "Train Epoch: 461 [9856/17352 (57%)] Loss: -623.564607\n",
      "Train Epoch: 461 [17277/17352 (100%)] Loss: -655.137643\n",
      "    epoch          : 461\n",
      "    loss           : -480.0992935408913\n",
      "    val_loss       : 878.1416701154276\n",
      "Train Epoch: 462 [512/17352 (3%)] Loss: 1134.236206\n",
      "Train Epoch: 462 [10489/17352 (60%)] Loss: -413.853222\n",
      "Train Epoch: 462 [16958/17352 (98%)] Loss: -529.611872\n",
      "    epoch          : 462\n",
      "    loss           : -287.0021091258254\n",
      "    val_loss       : -354.58311159696933\n",
      "Train Epoch: 463 [512/17352 (3%)] Loss: -511.003479\n",
      "Train Epoch: 463 [9940/17352 (57%)] Loss: -603.243099\n",
      "Train Epoch: 463 [16922/17352 (98%)] Loss: -628.249744\n",
      "    epoch          : 463\n",
      "    loss           : -691.2585648186043\n",
      "    val_loss       : -609.4821027627144\n",
      "Train Epoch: 464 [512/17352 (3%)] Loss: -826.989990\n",
      "Train Epoch: 464 [10387/17352 (60%)] Loss: -815.681969\n",
      "Train Epoch: 464 [16958/17352 (98%)] Loss: -881.258595\n",
      "    epoch          : 464\n",
      "    loss           : -773.615930668643\n",
      "    val_loss       : -650.290508726515\n",
      "Train Epoch: 465 [512/17352 (3%)] Loss: -842.653625\n",
      "Train Epoch: 465 [10361/17352 (60%)] Loss: -732.425781\n",
      "Train Epoch: 465 [16878/17352 (97%)] Loss: -766.884389\n",
      "    epoch          : 465\n",
      "    loss           : -798.7073649676786\n",
      "    val_loss       : -656.8920129007125\n",
      "Train Epoch: 466 [512/17352 (3%)] Loss: -858.356323\n",
      "Train Epoch: 466 [10477/17352 (60%)] Loss: -871.765839\n",
      "Train Epoch: 466 [17143/17352 (99%)] Loss: -852.621452\n",
      "    epoch          : 466\n",
      "    loss           : -811.899669713456\n",
      "    val_loss       : -657.3860916663399\n",
      "Train Epoch: 467 [512/17352 (3%)] Loss: -846.201477\n",
      "Train Epoch: 467 [10270/17352 (59%)] Loss: -814.153320\n",
      "Train Epoch: 467 [16957/17352 (98%)] Loss: -814.586975\n",
      "    epoch          : 467\n",
      "    loss           : -808.4455981818982\n",
      "    val_loss       : -651.4698592646424\n",
      "Train Epoch: 468 [512/17352 (3%)] Loss: -864.667603\n",
      "Train Epoch: 468 [10269/17352 (59%)] Loss: -738.653303\n",
      "Train Epoch: 468 [17153/17352 (99%)] Loss: -898.321181\n",
      "    epoch          : 468\n",
      "    loss           : -802.6171728611216\n",
      "    val_loss       : -639.7618984809244\n",
      "Train Epoch: 469 [512/17352 (3%)] Loss: -821.908813\n",
      "Train Epoch: 469 [9988/17352 (58%)] Loss: -857.060890\n",
      "Train Epoch: 469 [17277/17352 (100%)] Loss: -676.750258\n",
      "    epoch          : 469\n",
      "    loss           : -795.4242840593942\n",
      "    val_loss       : -627.8710633440888\n",
      "Train Epoch: 470 [512/17352 (3%)] Loss: -832.509766\n",
      "Train Epoch: 470 [10545/17352 (61%)] Loss: -763.665436\n",
      "Train Epoch: 470 [16922/17352 (98%)] Loss: -878.470944\n",
      "    epoch          : 470\n",
      "    loss           : -789.9707337134598\n",
      "    val_loss       : -658.2186723175676\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch470.pth ...\n",
      "Train Epoch: 471 [512/17352 (3%)] Loss: -859.568054\n",
      "Train Epoch: 471 [10687/17352 (62%)] Loss: -867.109180\n",
      "Train Epoch: 471 [16958/17352 (98%)] Loss: -848.450913\n",
      "    epoch          : 471\n",
      "    loss           : -822.1639638252627\n",
      "    val_loss       : -648.1066664514865\n",
      "Train Epoch: 472 [512/17352 (3%)] Loss: -867.449463\n",
      "Train Epoch: 472 [10466/17352 (60%)] Loss: -761.885438\n",
      "Train Epoch: 472 [17143/17352 (99%)] Loss: -771.392206\n",
      "    epoch          : 472\n",
      "    loss           : -825.1265642537962\n",
      "    val_loss       : -652.9938455712427\n",
      "Train Epoch: 473 [512/17352 (3%)] Loss: -856.104675\n",
      "Train Epoch: 473 [10527/17352 (61%)] Loss: -830.702888\n",
      "Train Epoch: 473 [17101/17352 (99%)] Loss: -883.564271\n",
      "    epoch          : 473\n",
      "    loss           : -831.6860232263142\n",
      "    val_loss       : -662.0024346830943\n",
      "Train Epoch: 474 [512/17352 (3%)] Loss: -880.320068\n",
      "Train Epoch: 474 [10261/17352 (59%)] Loss: -743.298351\n",
      "Train Epoch: 474 [16883/17352 (97%)] Loss: -746.271459\n",
      "    epoch          : 474\n",
      "    loss           : -792.2636249268043\n",
      "    val_loss       : -652.5107381105014\n",
      "Train Epoch: 475 [512/17352 (3%)] Loss: -839.408203\n",
      "Train Epoch: 475 [10276/17352 (59%)] Loss: -857.196687\n",
      "Train Epoch: 475 [16882/17352 (97%)] Loss: -798.818404\n",
      "    epoch          : 475\n",
      "    loss           : -807.2791774840517\n",
      "    val_loss       : -642.7647068966345\n",
      "Train Epoch: 476 [512/17352 (3%)] Loss: -846.774475\n",
      "Train Epoch: 476 [10042/17352 (58%)] Loss: -868.896468\n",
      "Train Epoch: 476 [16887/17352 (97%)] Loss: -885.726170\n",
      "    epoch          : 476\n",
      "    loss           : -819.0533389163284\n",
      "    val_loss       : -657.9485603910293\n",
      "Train Epoch: 477 [512/17352 (3%)] Loss: -862.193665\n",
      "Train Epoch: 477 [10243/17352 (59%)] Loss: -863.452261\n",
      "Train Epoch: 477 [16887/17352 (97%)] Loss: -798.608910\n",
      "    epoch          : 477\n",
      "    loss           : -822.5557277858882\n",
      "    val_loss       : -655.9050309594974\n",
      "Train Epoch: 478 [512/17352 (3%)] Loss: -862.064148\n",
      "Train Epoch: 478 [10479/17352 (60%)] Loss: -758.870781\n",
      "Train Epoch: 478 [16882/17352 (97%)] Loss: -919.071361\n",
      "    epoch          : 478\n",
      "    loss           : -835.7974284241799\n",
      "    val_loss       : -671.054125248582\n",
      "Train Epoch: 479 [512/17352 (3%)] Loss: -881.293091\n",
      "Train Epoch: 479 [10499/17352 (61%)] Loss: -786.593924\n",
      "Train Epoch: 479 [17335/17352 (100%)] Loss: -638.912567\n",
      "    epoch          : 479\n",
      "    loss           : -834.6331343442231\n",
      "    val_loss       : -651.2397563309607\n",
      "Train Epoch: 480 [512/17352 (3%)] Loss: -680.010803\n",
      "Train Epoch: 480 [10380/17352 (60%)] Loss: -836.061904\n",
      "Train Epoch: 480 [16923/17352 (98%)] Loss: -926.094150\n",
      "    epoch          : 480\n",
      "    loss           : -827.2235289724155\n",
      "    val_loss       : -641.4596871714868\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch480.pth ...\n",
      "Train Epoch: 481 [512/17352 (3%)] Loss: -873.285034\n",
      "Train Epoch: 481 [10872/17352 (63%)] Loss: -925.238528\n",
      "Train Epoch: 481 [17126/17352 (99%)] Loss: -941.364672\n",
      "    epoch          : 481\n",
      "    loss           : -838.5389126836961\n",
      "    val_loss       : -661.3906651878093\n",
      "Train Epoch: 482 [512/17352 (3%)] Loss: -894.865662\n",
      "Train Epoch: 482 [9996/17352 (58%)] Loss: -775.214662\n",
      "Train Epoch: 482 [17253/17352 (99%)] Loss: -759.104911\n",
      "    epoch          : 482\n",
      "    loss           : -841.493781555627\n",
      "    val_loss       : -637.3807343281018\n",
      "Train Epoch: 483 [512/17352 (3%)] Loss: -857.322144\n",
      "Train Epoch: 483 [10600/17352 (61%)] Loss: -643.901952\n",
      "Train Epoch: 483 [17090/17352 (98%)] Loss: -929.280784\n",
      "    epoch          : 483\n",
      "    loss           : -813.9404809926641\n",
      "    val_loss       : -632.36434016499\n",
      "Train Epoch: 484 [512/17352 (3%)] Loss: -867.932068\n",
      "Train Epoch: 484 [10220/17352 (59%)] Loss: -662.491029\n",
      "Train Epoch: 484 [17143/17352 (99%)] Loss: -944.065864\n",
      "    epoch          : 484\n",
      "    loss           : -820.0560439768881\n",
      "    val_loss       : -639.9518930201085\n",
      "Train Epoch: 485 [512/17352 (3%)] Loss: -842.616516\n",
      "Train Epoch: 485 [10514/17352 (61%)] Loss: -753.928522\n",
      "Train Epoch: 485 [17106/17352 (99%)] Loss: -925.463226\n",
      "    epoch          : 485\n",
      "    loss           : -802.335427697035\n",
      "    val_loss       : -559.1265791219312\n",
      "Train Epoch: 486 [512/17352 (3%)] Loss: -760.734863\n",
      "Train Epoch: 486 [10432/17352 (60%)] Loss: -606.510778\n",
      "Train Epoch: 486 [16878/17352 (97%)] Loss: -775.704670\n",
      "    epoch          : 486\n",
      "    loss           : -778.726971810591\n",
      "    val_loss       : -632.0896121131144\n",
      "Train Epoch: 487 [512/17352 (3%)] Loss: -874.424927\n",
      "Train Epoch: 487 [10327/17352 (60%)] Loss: -695.812706\n",
      "Train Epoch: 487 [17335/17352 (100%)] Loss: -857.139918\n",
      "    epoch          : 487\n",
      "    loss           : -818.0191272519281\n",
      "    val_loss       : -646.2274834520189\n",
      "Train Epoch: 488 [512/17352 (3%)] Loss: -858.887085\n",
      "Train Epoch: 488 [10827/17352 (62%)] Loss: -915.753402\n",
      "Train Epoch: 488 [17108/17352 (99%)] Loss: -691.080201\n",
      "    epoch          : 488\n",
      "    loss           : -828.056774160482\n",
      "    val_loss       : -621.2686028957706\n",
      "Train Epoch: 489 [512/17352 (3%)] Loss: -831.716736\n",
      "Train Epoch: 489 [11230/17352 (65%)] Loss: -608.554704\n",
      "Train Epoch: 489 [16934/17352 (98%)] Loss: -935.240315\n",
      "    epoch          : 489\n",
      "    loss           : -807.6740995033151\n",
      "    val_loss       : -628.9372213729871\n",
      "Train Epoch: 490 [512/17352 (3%)] Loss: -843.736145\n",
      "Train Epoch: 490 [10855/17352 (63%)] Loss: -869.779433\n",
      "Train Epoch: 490 [17049/17352 (98%)] Loss: -853.974747\n",
      "    epoch          : 490\n",
      "    loss           : -826.6579290558908\n",
      "    val_loss       : -659.7521308593017\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch490.pth ...\n",
      "Train Epoch: 491 [512/17352 (3%)] Loss: -677.952087\n",
      "Train Epoch: 491 [10659/17352 (61%)] Loss: -888.888343\n",
      "Train Epoch: 491 [17016/17352 (98%)] Loss: -846.346146\n",
      "    epoch          : 491\n",
      "    loss           : -821.0274040743759\n",
      "    val_loss       : -620.0216153485954\n",
      "Train Epoch: 492 [512/17352 (3%)] Loss: -889.357483\n",
      "Train Epoch: 492 [10386/17352 (60%)] Loss: -733.810369\n",
      "Train Epoch: 492 [17253/17352 (99%)] Loss: -840.133573\n",
      "    epoch          : 492\n",
      "    loss           : -813.8478163579854\n",
      "    val_loss       : -639.5009644290292\n",
      "Train Epoch: 493 [512/17352 (3%)] Loss: -866.022217\n",
      "Train Epoch: 493 [10009/17352 (58%)] Loss: -769.965760\n",
      "Train Epoch: 493 [16887/17352 (97%)] Loss: -924.296875\n",
      "    epoch          : 493\n",
      "    loss           : -825.8963617252032\n",
      "    val_loss       : -648.7065551354061\n",
      "Train Epoch: 494 [512/17352 (3%)] Loss: -892.295654\n",
      "Train Epoch: 494 [10549/17352 (61%)] Loss: -777.566851\n",
      "Train Epoch: 494 [16988/17352 (98%)] Loss: -614.761567\n",
      "    epoch          : 494\n",
      "    loss           : -828.7622052820055\n",
      "    val_loss       : -642.1535444400631\n",
      "Train Epoch: 495 [512/17352 (3%)] Loss: -863.783203\n",
      "Train Epoch: 495 [10950/17352 (63%)] Loss: -904.759610\n",
      "Train Epoch: 495 [17016/17352 (98%)] Loss: -660.717031\n",
      "    epoch          : 495\n",
      "    loss           : -814.2161451070991\n",
      "    val_loss       : -637.6695924908886\n",
      "Train Epoch: 496 [512/17352 (3%)] Loss: -853.564819\n",
      "Train Epoch: 496 [10201/17352 (59%)] Loss: -884.860364\n",
      "Train Epoch: 496 [17108/17352 (99%)] Loss: -781.373233\n",
      "    epoch          : 496\n",
      "    loss           : -822.1765439160415\n",
      "    val_loss       : -597.024716490472\n",
      "Train Epoch: 497 [512/17352 (3%)] Loss: -809.320435\n",
      "Train Epoch: 497 [10186/17352 (59%)] Loss: -814.558019\n",
      "Train Epoch: 497 [16934/17352 (98%)] Loss: -879.927540\n",
      "    epoch          : 497\n",
      "    loss           : -821.7565786446136\n",
      "    val_loss       : -648.7484166771917\n",
      "Train Epoch: 498 [512/17352 (3%)] Loss: -874.924133\n",
      "Train Epoch: 498 [10522/17352 (61%)] Loss: -810.035103\n",
      "Train Epoch: 498 [16957/17352 (98%)] Loss: -772.376319\n",
      "    epoch          : 498\n",
      "    loss           : -834.0934570839011\n",
      "    val_loss       : -633.5867708378998\n",
      "Train Epoch: 499 [512/17352 (3%)] Loss: -851.747437\n",
      "Train Epoch: 499 [10176/17352 (59%)] Loss: -908.261047\n",
      "Train Epoch: 499 [17106/17352 (99%)] Loss: -801.850070\n",
      "    epoch          : 499\n",
      "    loss           : -771.2146403906812\n",
      "    val_loss       : -556.6725381951741\n",
      "Train Epoch: 500 [512/17352 (3%)] Loss: -735.473267\n",
      "Train Epoch: 500 [10221/17352 (59%)] Loss: -719.385771\n",
      "Train Epoch: 500 [17253/17352 (99%)] Loss: -521.845431\n",
      "    epoch          : 500\n",
      "    loss           : -693.6552046569909\n",
      "    val_loss       : -409.16695561877424\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch500.pth ...\n",
      "Train Epoch: 501 [512/17352 (3%)] Loss: -649.745239\n",
      "Train Epoch: 501 [10210/17352 (59%)] Loss: -642.543202\n",
      "Train Epoch: 501 [16878/17352 (97%)] Loss: -753.734768\n",
      "    epoch          : 501\n",
      "    loss           : -693.2414894113144\n",
      "    val_loss       : -599.545183312576\n",
      "Train Epoch: 502 [512/17352 (3%)] Loss: -817.361206\n",
      "Train Epoch: 502 [10059/17352 (58%)] Loss: -916.430773\n",
      "Train Epoch: 502 [16988/17352 (98%)] Loss: -869.279584\n",
      "    epoch          : 502\n",
      "    loss           : -753.9738450951453\n",
      "    val_loss       : -565.0310650988769\n",
      "Train Epoch: 503 [512/17352 (3%)] Loss: -822.879883\n",
      "Train Epoch: 503 [10756/17352 (62%)] Loss: -788.438711\n",
      "Train Epoch: 503 [17106/17352 (99%)] Loss: -638.288631\n",
      "    epoch          : 503\n",
      "    loss           : -606.9315777092386\n",
      "    val_loss       : -303.4352842133259\n",
      "Train Epoch: 504 [512/17352 (3%)] Loss: -508.937744\n",
      "Train Epoch: 504 [9973/17352 (57%)] Loss: -531.881392\n",
      "Train Epoch: 504 [16939/17352 (98%)] Loss: -699.572680\n",
      "    epoch          : 504\n",
      "    loss           : -673.1744671272036\n",
      "    val_loss       : -598.4348071189964\n",
      "Train Epoch: 505 [512/17352 (3%)] Loss: -725.002197\n",
      "Train Epoch: 505 [10272/17352 (59%)] Loss: -826.068289\n",
      "Train Epoch: 505 [17253/17352 (99%)] Loss: -890.489372\n",
      "    epoch          : 505\n",
      "    loss           : -781.8231320529632\n",
      "    val_loss       : -641.0559107992831\n",
      "Train Epoch: 506 [512/17352 (3%)] Loss: -846.714539\n",
      "Train Epoch: 506 [10563/17352 (61%)] Loss: -886.948287\n",
      "Train Epoch: 506 [17253/17352 (99%)] Loss: -865.386003\n",
      "    epoch          : 506\n",
      "    loss           : -827.2063313558676\n",
      "    val_loss       : -653.0558061435866\n",
      "Train Epoch: 507 [512/17352 (3%)] Loss: -881.546875\n",
      "Train Epoch: 507 [10402/17352 (60%)] Loss: -631.443548\n",
      "Train Epoch: 507 [17143/17352 (99%)] Loss: -841.745347\n",
      "    epoch          : 507\n",
      "    loss           : -840.2687255071878\n",
      "    val_loss       : -653.0790760639703\n",
      "Train Epoch: 508 [512/17352 (3%)] Loss: -882.004700\n",
      "Train Epoch: 508 [10002/17352 (58%)] Loss: -858.803190\n",
      "Train Epoch: 508 [16922/17352 (98%)] Loss: -732.376856\n",
      "    epoch          : 508\n",
      "    loss           : -832.4873833171071\n",
      "    val_loss       : -675.3115730786928\n",
      "Train Epoch: 509 [512/17352 (3%)] Loss: -900.529846\n",
      "Train Epoch: 509 [10026/17352 (58%)] Loss: -950.784235\n",
      "Train Epoch: 509 [17133/17352 (99%)] Loss: -781.964414\n",
      "    epoch          : 509\n",
      "    loss           : -846.6443604374697\n",
      "    val_loss       : -650.7578329732478\n",
      "Train Epoch: 510 [512/17352 (3%)] Loss: -880.044983\n",
      "Train Epoch: 510 [10623/17352 (61%)] Loss: -793.656944\n",
      "Train Epoch: 510 [17263/17352 (99%)] Loss: -747.993811\n",
      "    epoch          : 510\n",
      "    loss           : -823.4697258646789\n",
      "    val_loss       : -610.5891249485794\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch510.pth ...\n",
      "Train Epoch: 511 [512/17352 (3%)] Loss: -815.480469\n",
      "Train Epoch: 511 [11042/17352 (64%)] Loss: -795.650608\n",
      "Train Epoch: 511 [17133/17352 (99%)] Loss: -936.995069\n",
      "    epoch          : 511\n",
      "    loss           : -826.2137388097192\n",
      "    val_loss       : -635.5902461163383\n",
      "Train Epoch: 512 [512/17352 (3%)] Loss: -845.627319\n",
      "Train Epoch: 512 [10258/17352 (59%)] Loss: -801.000000\n",
      "Train Epoch: 512 [16872/17352 (97%)] Loss: -915.689241\n",
      "    epoch          : 512\n",
      "    loss           : -832.3730935227968\n",
      "    val_loss       : -640.5723596985403\n",
      "Train Epoch: 513 [512/17352 (3%)] Loss: -888.785889\n",
      "Train Epoch: 513 [10583/17352 (61%)] Loss: -822.347656\n",
      "Train Epoch: 513 [17253/17352 (99%)] Loss: -770.825135\n",
      "    epoch          : 513\n",
      "    loss           : -832.8255617885378\n",
      "    val_loss       : -630.8367988019517\n",
      "Train Epoch: 514 [512/17352 (3%)] Loss: -640.892761\n",
      "Train Epoch: 514 [10177/17352 (59%)] Loss: -745.292395\n",
      "Train Epoch: 514 [17277/17352 (100%)] Loss: -862.570520\n",
      "    epoch          : 514\n",
      "    loss           : -828.3313080166714\n",
      "    val_loss       : -654.8248945283865\n",
      "Train Epoch: 515 [512/17352 (3%)] Loss: -711.711487\n",
      "Train Epoch: 515 [10389/17352 (60%)] Loss: -912.800573\n",
      "Train Epoch: 515 [16923/17352 (98%)] Loss: -938.736026\n",
      "    epoch          : 515\n",
      "    loss           : -851.4358983627858\n",
      "    val_loss       : -667.7962307785521\n",
      "Train Epoch: 516 [512/17352 (3%)] Loss: -911.495239\n",
      "Train Epoch: 516 [10243/17352 (59%)] Loss: -778.135069\n",
      "Train Epoch: 516 [16957/17352 (98%)] Loss: -848.514940\n",
      "    epoch          : 516\n",
      "    loss           : -853.2072935357284\n",
      "    val_loss       : -681.2481862633946\n",
      "Train Epoch: 517 [512/17352 (3%)] Loss: -891.521179\n",
      "Train Epoch: 517 [9901/17352 (57%)] Loss: -811.953929\n",
      "Train Epoch: 517 [16922/17352 (98%)] Loss: -909.508349\n",
      "    epoch          : 517\n",
      "    loss           : -856.0500698078852\n",
      "    val_loss       : -677.2068253422182\n",
      "Train Epoch: 518 [512/17352 (3%)] Loss: -912.515259\n",
      "Train Epoch: 518 [10855/17352 (63%)] Loss: -901.099477\n",
      "Train Epoch: 518 [17124/17352 (99%)] Loss: -815.514583\n",
      "    epoch          : 518\n",
      "    loss           : -858.9978366927681\n",
      "    val_loss       : -669.557515303784\n",
      "Train Epoch: 519 [512/17352 (3%)] Loss: -884.358032\n",
      "Train Epoch: 519 [9980/17352 (58%)] Loss: -873.973816\n",
      "Train Epoch: 519 [16988/17352 (98%)] Loss: -871.582631\n",
      "    epoch          : 519\n",
      "    loss           : -838.985523640255\n",
      "    val_loss       : -617.9928602457411\n",
      "Train Epoch: 520 [512/17352 (3%)] Loss: -850.626709\n",
      "Train Epoch: 520 [10392/17352 (60%)] Loss: -696.648923\n",
      "Train Epoch: 520 [16958/17352 (98%)] Loss: -788.404668\n",
      "    epoch          : 520\n",
      "    loss           : -832.2458634583886\n",
      "    val_loss       : -621.6145954915653\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch520.pth ...\n",
      "Train Epoch: 521 [512/17352 (3%)] Loss: -841.136902\n",
      "Train Epoch: 521 [10435/17352 (60%)] Loss: -768.191051\n",
      "Train Epoch: 521 [16958/17352 (98%)] Loss: -757.521229\n",
      "    epoch          : 521\n",
      "    loss           : -838.1867353484398\n",
      "    val_loss       : -651.495148164543\n",
      "Train Epoch: 522 [512/17352 (3%)] Loss: -860.786377\n",
      "Train Epoch: 522 [10853/17352 (63%)] Loss: -775.935014\n",
      "Train Epoch: 522 [17143/17352 (99%)] Loss: -842.613261\n",
      "    epoch          : 522\n",
      "    loss           : -824.6061725856384\n",
      "    val_loss       : -623.4405760133075\n",
      "Train Epoch: 523 [512/17352 (3%)] Loss: -859.598877\n",
      "Train Epoch: 523 [10506/17352 (61%)] Loss: -694.527512\n",
      "Train Epoch: 523 [17153/17352 (99%)] Loss: -792.653639\n",
      "    epoch          : 523\n",
      "    loss           : -806.1568022184914\n",
      "    val_loss       : -540.4010771805932\n",
      "Train Epoch: 524 [512/17352 (3%)] Loss: -755.775146\n",
      "Train Epoch: 524 [10655/17352 (61%)] Loss: -718.594968\n",
      "Train Epoch: 524 [17153/17352 (99%)] Loss: -612.983029\n",
      "    epoch          : 524\n",
      "    loss           : -778.5252275030656\n",
      "    val_loss       : -574.5995414517914\n",
      "Train Epoch: 525 [512/17352 (3%)] Loss: -755.965698\n",
      "Train Epoch: 525 [10470/17352 (60%)] Loss: -645.672996\n",
      "Train Epoch: 525 [17044/17352 (98%)] Loss: -885.095816\n",
      "    epoch          : 525\n",
      "    loss           : -787.3998028634741\n",
      "    val_loss       : -606.585530199289\n",
      "Train Epoch: 526 [512/17352 (3%)] Loss: -868.091553\n",
      "Train Epoch: 526 [10308/17352 (59%)] Loss: -892.235692\n",
      "Train Epoch: 526 [17277/17352 (100%)] Loss: -882.142252\n",
      "    epoch          : 526\n",
      "    loss           : -794.9868230797039\n",
      "    val_loss       : -570.2263350863549\n",
      "Train Epoch: 527 [512/17352 (3%)] Loss: -820.398560\n",
      "Train Epoch: 527 [10569/17352 (61%)] Loss: -856.495811\n",
      "Train Epoch: 527 [17108/17352 (99%)] Loss: -751.005840\n",
      "    epoch          : 527\n",
      "    loss           : -787.7102138523067\n",
      "    val_loss       : -509.25740574941165\n",
      "Train Epoch: 528 [512/17352 (3%)] Loss: -736.425903\n",
      "Train Epoch: 528 [10087/17352 (58%)] Loss: -587.519118\n",
      "Train Epoch: 528 [16882/17352 (97%)] Loss: 4335.111587\n",
      "    epoch          : 528\n",
      "    loss           : 113.80382926094096\n",
      "    val_loss       : 1408.5950086019852\n",
      "Train Epoch: 529 [512/17352 (3%)] Loss: 1740.463013\n",
      "Train Epoch: 529 [9931/17352 (57%)] Loss: 189.659013\n",
      "Train Epoch: 529 [17335/17352 (100%)] Loss: -609.876904\n",
      "    epoch          : 529\n",
      "    loss           : 116.52258093963681\n",
      "    val_loss       : -246.13629111579792\n",
      "Train Epoch: 530 [512/17352 (3%)] Loss: -33.708637\n",
      "Train Epoch: 530 [11004/17352 (63%)] Loss: -318.260820\n",
      "Train Epoch: 530 [17044/17352 (98%)] Loss: -694.722969\n",
      "    epoch          : 530\n",
      "    loss           : -630.540114025224\n",
      "    val_loss       : -599.0601497725391\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch530.pth ...\n",
      "Train Epoch: 531 [512/17352 (3%)] Loss: -796.670349\n",
      "Train Epoch: 531 [10378/17352 (60%)] Loss: -854.205491\n",
      "Train Epoch: 531 [17049/17352 (98%)] Loss: -907.457753\n",
      "    epoch          : 531\n",
      "    loss           : -783.2461087980171\n",
      "    val_loss       : -656.3154598279539\n",
      "Train Epoch: 532 [512/17352 (3%)] Loss: -849.214844\n",
      "Train Epoch: 532 [10247/17352 (59%)] Loss: -960.330078\n",
      "Train Epoch: 532 [17124/17352 (99%)] Loss: -736.118509\n",
      "    epoch          : 532\n",
      "    loss           : -815.5682656603364\n",
      "    val_loss       : -646.1953357154867\n",
      "Train Epoch: 533 [512/17352 (3%)] Loss: -854.877930\n",
      "Train Epoch: 533 [10395/17352 (60%)] Loss: -598.963387\n",
      "Train Epoch: 533 [16882/17352 (97%)] Loss: -803.250868\n",
      "    epoch          : 533\n",
      "    loss           : -817.5882004649663\n",
      "    val_loss       : -653.9443186372665\n",
      "Train Epoch: 534 [512/17352 (3%)] Loss: -876.218994\n",
      "Train Epoch: 534 [10442/17352 (60%)] Loss: -759.092853\n",
      "Train Epoch: 534 [16992/17352 (98%)] Loss: -944.305463\n",
      "    epoch          : 534\n",
      "    loss           : -825.8438750590486\n",
      "    val_loss       : -667.7752369309962\n",
      "Train Epoch: 535 [512/17352 (3%)] Loss: -883.139893\n",
      "Train Epoch: 535 [10301/17352 (59%)] Loss: -830.508429\n",
      "Train Epoch: 535 [16992/17352 (98%)] Loss: -934.423699\n",
      "    epoch          : 535\n",
      "    loss           : -844.6521224920508\n",
      "    val_loss       : -691.2772763852018\n",
      "Train Epoch: 536 [512/17352 (3%)] Loss: -888.503845\n",
      "Train Epoch: 536 [10702/17352 (62%)] Loss: -896.899776\n",
      "Train Epoch: 536 [16923/17352 (98%)] Loss: -976.720812\n",
      "    epoch          : 536\n",
      "    loss           : -851.5338458953994\n",
      "    val_loss       : -676.6423034526953\n",
      "Train Epoch: 537 [512/17352 (3%)] Loss: -687.101318\n",
      "Train Epoch: 537 [10406/17352 (60%)] Loss: -952.630372\n",
      "Train Epoch: 537 [17101/17352 (99%)] Loss: -874.971420\n",
      "    epoch          : 537\n",
      "    loss           : -846.075286020484\n",
      "    val_loss       : -674.2428097780985\n",
      "Train Epoch: 538 [512/17352 (3%)] Loss: -883.525146\n",
      "Train Epoch: 538 [9975/17352 (57%)] Loss: -907.221675\n",
      "Train Epoch: 538 [17143/17352 (99%)] Loss: -821.895368\n",
      "    epoch          : 538\n",
      "    loss           : -851.8773236604386\n",
      "    val_loss       : -665.7052974818758\n",
      "Train Epoch: 539 [512/17352 (3%)] Loss: -903.920532\n",
      "Train Epoch: 539 [10248/17352 (59%)] Loss: -790.196243\n",
      "Train Epoch: 539 [17126/17352 (99%)] Loss: -928.088308\n",
      "    epoch          : 539\n",
      "    loss           : -851.7219955990288\n",
      "    val_loss       : -662.6980998172704\n",
      "Train Epoch: 540 [512/17352 (3%)] Loss: -879.783203\n",
      "Train Epoch: 540 [10352/17352 (60%)] Loss: -949.073806\n",
      "Train Epoch: 540 [17253/17352 (99%)] Loss: -862.232057\n",
      "    epoch          : 540\n",
      "    loss           : -865.1657918116151\n",
      "    val_loss       : -681.7215799708855\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch540.pth ...\n",
      "Train Epoch: 541 [512/17352 (3%)] Loss: -905.860962\n",
      "Train Epoch: 541 [10224/17352 (59%)] Loss: -930.911605\n",
      "Train Epoch: 541 [16887/17352 (97%)] Loss: -741.689717\n",
      "    epoch          : 541\n",
      "    loss           : -864.7573001375902\n",
      "    val_loss       : -689.2345548085248\n",
      "Train Epoch: 542 [512/17352 (3%)] Loss: -913.652649\n",
      "Train Epoch: 542 [10631/17352 (61%)] Loss: -903.073892\n",
      "Train Epoch: 542 [16958/17352 (98%)] Loss: -813.142535\n",
      "    epoch          : 542\n",
      "    loss           : -866.9976018321926\n",
      "    val_loss       : -689.9340397746688\n",
      "Train Epoch: 543 [512/17352 (3%)] Loss: -908.166077\n",
      "Train Epoch: 543 [10464/17352 (60%)] Loss: -820.233030\n",
      "Train Epoch: 543 [17126/17352 (99%)] Loss: -969.136426\n",
      "    epoch          : 543\n",
      "    loss           : -868.0144289651537\n",
      "    val_loss       : -674.7300822153974\n",
      "Train Epoch: 544 [512/17352 (3%)] Loss: -908.986816\n",
      "Train Epoch: 544 [10928/17352 (63%)] Loss: -972.607900\n",
      "Train Epoch: 544 [17090/17352 (98%)] Loss: -817.189892\n",
      "    epoch          : 544\n",
      "    loss           : -861.2704599498082\n",
      "    val_loss       : -667.6129140854925\n",
      "Train Epoch: 545 [512/17352 (3%)] Loss: -895.245789\n",
      "Train Epoch: 545 [10015/17352 (58%)] Loss: -880.479798\n",
      "Train Epoch: 545 [16992/17352 (98%)] Loss: -917.409612\n",
      "    epoch          : 545\n",
      "    loss           : -865.631213315556\n",
      "    val_loss       : -674.0701622367222\n",
      "Train Epoch: 546 [512/17352 (3%)] Loss: -904.886902\n",
      "Train Epoch: 546 [10673/17352 (62%)] Loss: -959.192405\n",
      "Train Epoch: 546 [17124/17352 (99%)] Loss: -884.614145\n",
      "    epoch          : 546\n",
      "    loss           : -868.3072054359276\n",
      "    val_loss       : -663.0557290180526\n",
      "Train Epoch: 547 [512/17352 (3%)] Loss: -890.514954\n",
      "Train Epoch: 547 [9694/17352 (56%)] Loss: -914.740668\n",
      "Train Epoch: 547 [16922/17352 (98%)] Loss: -784.702364\n",
      "    epoch          : 547\n",
      "    loss           : -848.266712638324\n",
      "    val_loss       : -669.3970852109054\n",
      "Train Epoch: 548 [512/17352 (3%)] Loss: -904.369385\n",
      "Train Epoch: 548 [10327/17352 (60%)] Loss: -911.533118\n",
      "Train Epoch: 548 [17106/17352 (99%)] Loss: -816.194712\n",
      "    epoch          : 548\n",
      "    loss           : -860.5153613206433\n",
      "    val_loss       : -674.1739261322991\n",
      "Train Epoch: 549 [512/17352 (3%)] Loss: -904.458740\n",
      "Train Epoch: 549 [9870/17352 (57%)] Loss: -844.810030\n",
      "Train Epoch: 549 [16988/17352 (98%)] Loss: -944.270622\n",
      "    epoch          : 549\n",
      "    loss           : -867.2791731244765\n",
      "    val_loss       : -673.4869598979333\n",
      "Train Epoch: 550 [512/17352 (3%)] Loss: -901.956421\n",
      "Train Epoch: 550 [10503/17352 (61%)] Loss: -715.758251\n",
      "Train Epoch: 550 [16878/17352 (97%)] Loss: -848.662603\n",
      "    epoch          : 550\n",
      "    loss           : -861.9149127334322\n",
      "    val_loss       : -680.499335287211\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch550.pth ...\n",
      "Train Epoch: 551 [512/17352 (3%)] Loss: -898.718689\n",
      "Train Epoch: 551 [10463/17352 (60%)] Loss: -871.175206\n",
      "Train Epoch: 551 [17049/17352 (98%)] Loss: -653.621707\n",
      "    epoch          : 551\n",
      "    loss           : -819.5575775336038\n",
      "    val_loss       : -631.4258969581696\n",
      "Train Epoch: 552 [512/17352 (3%)] Loss: -882.790649\n",
      "Train Epoch: 552 [10516/17352 (61%)] Loss: -987.027127\n",
      "Train Epoch: 552 [17049/17352 (98%)] Loss: -896.565397\n",
      "    epoch          : 552\n",
      "    loss           : -835.2415897299809\n",
      "    val_loss       : -669.7877337184672\n",
      "Train Epoch: 553 [512/17352 (3%)] Loss: -717.322510\n",
      "Train Epoch: 553 [9938/17352 (57%)] Loss: -792.109578\n",
      "Train Epoch: 553 [16923/17352 (98%)] Loss: -900.910604\n",
      "    epoch          : 553\n",
      "    loss           : -851.6381296737551\n",
      "    val_loss       : -677.9852325589957\n",
      "Train Epoch: 554 [512/17352 (3%)] Loss: -906.497070\n",
      "Train Epoch: 554 [10408/17352 (60%)] Loss: -802.125434\n",
      "Train Epoch: 554 [17126/17352 (99%)] Loss: -835.868490\n",
      "    epoch          : 554\n",
      "    loss           : -856.2300342555071\n",
      "    val_loss       : -640.9048779770209\n",
      "Train Epoch: 555 [512/17352 (3%)] Loss: -873.170410\n",
      "Train Epoch: 555 [10237/17352 (59%)] Loss: -925.595479\n",
      "Train Epoch: 555 [17064/17352 (98%)] Loss: -685.113324\n",
      "    epoch          : 555\n",
      "    loss           : -829.945558374602\n",
      "    val_loss       : -594.4978014244751\n",
      "Train Epoch: 556 [512/17352 (3%)] Loss: -864.600708\n",
      "Train Epoch: 556 [10232/17352 (59%)] Loss: -839.305082\n",
      "Train Epoch: 556 [17126/17352 (99%)] Loss: -758.664895\n",
      "    epoch          : 556\n",
      "    loss           : -751.6322881700883\n",
      "    val_loss       : -519.27085940328\n",
      "Train Epoch: 557 [512/17352 (3%)] Loss: -795.072998\n",
      "Train Epoch: 557 [10259/17352 (59%)] Loss: -683.920294\n",
      "Train Epoch: 557 [17133/17352 (99%)] Loss: -903.373734\n",
      "    epoch          : 557\n",
      "    loss           : -732.257320891286\n",
      "    val_loss       : -623.4104317672804\n",
      "Train Epoch: 558 [512/17352 (3%)] Loss: -893.084961\n",
      "Train Epoch: 558 [10218/17352 (59%)] Loss: -834.409113\n",
      "Train Epoch: 558 [17124/17352 (99%)] Loss: -886.773619\n",
      "    epoch          : 558\n",
      "    loss           : -807.9238212968505\n",
      "    val_loss       : -633.0835922291313\n",
      "Train Epoch: 559 [512/17352 (3%)] Loss: -895.214722\n",
      "Train Epoch: 559 [10149/17352 (58%)] Loss: -815.298412\n",
      "Train Epoch: 559 [17064/17352 (98%)] Loss: -816.657969\n",
      "    epoch          : 559\n",
      "    loss           : -845.2918311652709\n",
      "    val_loss       : -647.0520190094978\n",
      "Train Epoch: 560 [512/17352 (3%)] Loss: -900.122681\n",
      "Train Epoch: 560 [10184/17352 (59%)] Loss: -879.004182\n",
      "Train Epoch: 560 [16878/17352 (97%)] Loss: -828.414234\n",
      "    epoch          : 560\n",
      "    loss           : -863.7077098778872\n",
      "    val_loss       : -634.6998287283942\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch560.pth ...\n",
      "Train Epoch: 561 [512/17352 (3%)] Loss: -906.215698\n",
      "Train Epoch: 561 [10564/17352 (61%)] Loss: -791.319095\n",
      "Train Epoch: 561 [16992/17352 (98%)] Loss: -912.369119\n",
      "    epoch          : 561\n",
      "    loss           : -852.5763143018276\n",
      "    val_loss       : -675.2986036243943\n",
      "Train Epoch: 562 [512/17352 (3%)] Loss: -904.766479\n",
      "Train Epoch: 562 [10238/17352 (59%)] Loss: -940.124130\n",
      "Train Epoch: 562 [17277/17352 (100%)] Loss: -981.965495\n",
      "    epoch          : 562\n",
      "    loss           : -854.1947360292866\n",
      "    val_loss       : -637.9006222023029\n",
      "Train Epoch: 563 [512/17352 (3%)] Loss: -894.984497\n",
      "Train Epoch: 563 [10405/17352 (60%)] Loss: -806.030016\n",
      "Train Epoch: 563 [16957/17352 (98%)] Loss: -911.072965\n",
      "    epoch          : 563\n",
      "    loss           : -853.5017806141514\n",
      "    val_loss       : -640.3922862478947\n",
      "Train Epoch: 564 [512/17352 (3%)] Loss: -894.446960\n",
      "Train Epoch: 564 [10394/17352 (60%)] Loss: -893.499843\n",
      "Train Epoch: 564 [17143/17352 (99%)] Loss: -795.469846\n",
      "    epoch          : 564\n",
      "    loss           : -853.5777945215583\n",
      "    val_loss       : -617.1941465714158\n",
      "Train Epoch: 565 [512/17352 (3%)] Loss: -884.343140\n",
      "Train Epoch: 565 [10439/17352 (60%)] Loss: -894.918535\n",
      "Train Epoch: 565 [17263/17352 (99%)] Loss: -677.419643\n",
      "    epoch          : 565\n",
      "    loss           : -834.4390539451879\n",
      "    val_loss       : -637.2672365846204\n",
      "Train Epoch: 566 [512/17352 (3%)] Loss: -906.804810\n",
      "Train Epoch: 566 [10241/17352 (59%)] Loss: -792.893229\n",
      "Train Epoch: 566 [17126/17352 (99%)] Loss: -754.061466\n",
      "    epoch          : 566\n",
      "    loss           : -852.2682573528481\n",
      "    val_loss       : -630.3023427761477\n",
      "Train Epoch: 567 [512/17352 (3%)] Loss: -889.559814\n",
      "Train Epoch: 567 [9997/17352 (58%)] Loss: -905.452373\n",
      "Train Epoch: 567 [16883/17352 (97%)] Loss: -787.866166\n",
      "    epoch          : 567\n",
      "    loss           : -792.8230492372479\n",
      "    val_loss       : -487.3302483496642\n",
      "Train Epoch: 568 [512/17352 (3%)] Loss: -460.850494\n",
      "Train Epoch: 568 [10234/17352 (59%)] Loss: -877.493671\n",
      "Train Epoch: 568 [17124/17352 (99%)] Loss: -717.724731\n",
      "    epoch          : 568\n",
      "    loss           : -790.6918530972374\n",
      "    val_loss       : -616.4659206914508\n",
      "Train Epoch: 569 [512/17352 (3%)] Loss: -887.156616\n",
      "Train Epoch: 569 [10943/17352 (63%)] Loss: -924.049209\n",
      "Train Epoch: 569 [17044/17352 (98%)] Loss: -920.632558\n",
      "    epoch          : 569\n",
      "    loss           : -835.8478048326632\n",
      "    val_loss       : -653.7545393958042\n",
      "Train Epoch: 570 [512/17352 (3%)] Loss: -905.718140\n",
      "Train Epoch: 570 [9969/17352 (57%)] Loss: -770.019633\n",
      "Train Epoch: 570 [17090/17352 (98%)] Loss: -915.464878\n",
      "    epoch          : 570\n",
      "    loss           : -868.1457329574351\n",
      "    val_loss       : -676.0487490675614\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch570.pth ...\n",
      "Train Epoch: 571 [512/17352 (3%)] Loss: -904.271973\n",
      "Train Epoch: 571 [10132/17352 (58%)] Loss: -918.457083\n",
      "Train Epoch: 571 [16922/17352 (98%)] Loss: -972.357010\n",
      "    epoch          : 571\n",
      "    loss           : -879.9305823269585\n",
      "    val_loss       : -673.508969869674\n",
      "Train Epoch: 572 [512/17352 (3%)] Loss: -925.213013\n",
      "Train Epoch: 572 [10185/17352 (59%)] Loss: -791.286937\n",
      "Train Epoch: 572 [17016/17352 (98%)] Loss: -772.558442\n",
      "    epoch          : 572\n",
      "    loss           : -870.5648057375474\n",
      "    val_loss       : -657.8702129345052\n",
      "Train Epoch: 573 [512/17352 (3%)] Loss: -895.341797\n",
      "Train Epoch: 573 [9935/17352 (57%)] Loss: -703.203434\n",
      "Train Epoch: 573 [16878/17352 (97%)] Loss: -900.400208\n",
      "    epoch          : 573\n",
      "    loss           : -869.5346797938363\n",
      "    val_loss       : -673.3562628947286\n",
      "Train Epoch: 574 [512/17352 (3%)] Loss: -933.771606\n",
      "Train Epoch: 574 [10603/17352 (61%)] Loss: -771.845833\n",
      "Train Epoch: 574 [16957/17352 (98%)] Loss: -910.259570\n",
      "    epoch          : 574\n",
      "    loss           : -851.5244497931202\n",
      "    val_loss       : -644.0227234451432\n",
      "Train Epoch: 575 [512/17352 (3%)] Loss: -918.748291\n",
      "Train Epoch: 575 [10621/17352 (61%)] Loss: -988.398608\n",
      "Train Epoch: 575 [17090/17352 (98%)] Loss: -954.406177\n",
      "    epoch          : 575\n",
      "    loss           : -870.0581067893821\n",
      "    val_loss       : -655.613898276378\n",
      "Train Epoch: 576 [512/17352 (3%)] Loss: -916.503723\n",
      "Train Epoch: 576 [10032/17352 (58%)] Loss: -677.151344\n",
      "Train Epoch: 576 [16883/17352 (97%)] Loss: -830.388448\n",
      "    epoch          : 576\n",
      "    loss           : -855.5097854306631\n",
      "    val_loss       : -629.3221146449188\n",
      "Train Epoch: 577 [512/17352 (3%)] Loss: -867.036194\n",
      "Train Epoch: 577 [10583/17352 (61%)] Loss: -675.020933\n",
      "Train Epoch: 577 [17016/17352 (98%)] Loss: -860.424157\n",
      "    epoch          : 577\n",
      "    loss           : -830.6273034290455\n",
      "    val_loss       : -639.959299046034\n",
      "Train Epoch: 578 [512/17352 (3%)] Loss: -907.922852\n",
      "Train Epoch: 578 [10271/17352 (59%)] Loss: -806.534547\n",
      "Train Epoch: 578 [17335/17352 (100%)] Loss: -685.140212\n",
      "    epoch          : 578\n",
      "    loss           : -872.036838988369\n",
      "    val_loss       : -639.2108687999992\n",
      "Train Epoch: 579 [512/17352 (3%)] Loss: -910.435364\n",
      "Train Epoch: 579 [10116/17352 (58%)] Loss: -918.821838\n",
      "Train Epoch: 579 [17253/17352 (99%)] Loss: -767.246841\n",
      "    epoch          : 579\n",
      "    loss           : -860.1556405515128\n",
      "    val_loss       : -594.3095716525222\n",
      "Train Epoch: 580 [512/17352 (3%)] Loss: -867.605774\n",
      "Train Epoch: 580 [10814/17352 (62%)] Loss: -695.029839\n",
      "Train Epoch: 580 [16878/17352 (97%)] Loss: -806.398438\n",
      "    epoch          : 580\n",
      "    loss           : -867.8860599724447\n",
      "    val_loss       : -681.1458622942804\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch580.pth ...\n",
      "Train Epoch: 581 [512/17352 (3%)] Loss: -934.415527\n",
      "Train Epoch: 581 [9632/17352 (56%)] Loss: -819.390274\n",
      "Train Epoch: 581 [16957/17352 (98%)] Loss: -730.014044\n",
      "    epoch          : 581\n",
      "    loss           : -823.1731353292954\n",
      "    val_loss       : -613.0030805883553\n",
      "Train Epoch: 582 [512/17352 (3%)] Loss: -854.549011\n",
      "Train Epoch: 582 [10532/17352 (61%)] Loss: -975.215421\n",
      "Train Epoch: 582 [17133/17352 (99%)] Loss: -676.985282\n",
      "    epoch          : 582\n",
      "    loss           : -842.0483761904366\n",
      "    val_loss       : -629.9894731610715\n",
      "Train Epoch: 583 [512/17352 (3%)] Loss: -930.044250\n",
      "Train Epoch: 583 [10427/17352 (60%)] Loss: -892.800958\n",
      "Train Epoch: 583 [17335/17352 (100%)] Loss: -689.564593\n",
      "    epoch          : 583\n",
      "    loss           : -850.0409365757663\n",
      "    val_loss       : -631.4457040524372\n",
      "Train Epoch: 584 [512/17352 (3%)] Loss: -852.346680\n",
      "Train Epoch: 584 [10355/17352 (60%)] Loss: -874.817951\n",
      "Train Epoch: 584 [16939/17352 (98%)] Loss: -859.523230\n",
      "    epoch          : 584\n",
      "    loss           : -848.4496195147942\n",
      "    val_loss       : -666.6163697427536\n",
      "Train Epoch: 585 [512/17352 (3%)] Loss: -932.541199\n",
      "Train Epoch: 585 [10487/17352 (60%)] Loss: -918.403077\n",
      "Train Epoch: 585 [16883/17352 (97%)] Loss: -699.252183\n",
      "    epoch          : 585\n",
      "    loss           : -794.7339077520062\n",
      "    val_loss       : -595.5461040958131\n",
      "Train Epoch: 586 [512/17352 (3%)] Loss: -849.415161\n",
      "Train Epoch: 586 [10245/17352 (59%)] Loss: -912.614291\n",
      "Train Epoch: 586 [16872/17352 (97%)] Loss: -599.397284\n",
      "    epoch          : 586\n",
      "    loss           : -766.7493294369511\n",
      "    val_loss       : -401.3997099359748\n",
      "Train Epoch: 587 [512/17352 (3%)] Loss: -494.481567\n",
      "Train Epoch: 587 [9889/17352 (57%)] Loss: -610.040799\n",
      "Train Epoch: 587 [16992/17352 (98%)] Loss: 215.768115\n",
      "    epoch          : 587\n",
      "    loss           : -349.5554516889588\n",
      "    val_loss       : 564.3082739633575\n",
      "Train Epoch: 588 [512/17352 (3%)] Loss: 336.571411\n",
      "Train Epoch: 588 [10572/17352 (61%)] Loss: -717.935247\n",
      "Train Epoch: 588 [17106/17352 (99%)] Loss: -729.856503\n",
      "    epoch          : 588\n",
      "    loss           : -554.9695044268336\n",
      "    val_loss       : -382.91154093624107\n",
      "Train Epoch: 589 [512/17352 (3%)] Loss: -373.822571\n",
      "Train Epoch: 589 [10641/17352 (61%)] Loss: -547.807056\n",
      "Train Epoch: 589 [17090/17352 (98%)] Loss: -702.228484\n",
      "    epoch          : 589\n",
      "    loss           : -725.230208275081\n",
      "    val_loss       : -619.5597416740678\n",
      "Train Epoch: 590 [512/17352 (3%)] Loss: -879.415955\n",
      "Train Epoch: 590 [10582/17352 (61%)] Loss: -815.944454\n",
      "Train Epoch: 590 [16939/17352 (98%)] Loss: -960.789029\n",
      "    epoch          : 590\n",
      "    loss           : -840.0462221875032\n",
      "    val_loss       : -675.5317788609362\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch590.pth ...\n",
      "Train Epoch: 591 [512/17352 (3%)] Loss: -912.973755\n",
      "Train Epoch: 591 [10688/17352 (62%)] Loss: -926.457483\n",
      "Train Epoch: 591 [17016/17352 (98%)] Loss: -755.065388\n",
      "    epoch          : 591\n",
      "    loss           : -867.6534476466918\n",
      "    val_loss       : -681.7793221076313\n",
      "Train Epoch: 592 [512/17352 (3%)] Loss: -904.784912\n",
      "Train Epoch: 592 [10204/17352 (59%)] Loss: -848.762184\n",
      "Train Epoch: 592 [17090/17352 (98%)] Loss: -758.983974\n",
      "    epoch          : 592\n",
      "    loss           : -883.6435541440973\n",
      "    val_loss       : -679.2379852882931\n",
      "Train Epoch: 593 [512/17352 (3%)] Loss: -908.846741\n",
      "Train Epoch: 593 [10383/17352 (60%)] Loss: -820.755783\n",
      "Train Epoch: 593 [16882/17352 (97%)] Loss: -723.627321\n",
      "    epoch          : 593\n",
      "    loss           : -877.3689587049304\n",
      "    val_loss       : -689.1614514654613\n",
      "Train Epoch: 594 [512/17352 (3%)] Loss: -912.277527\n",
      "Train Epoch: 594 [10370/17352 (60%)] Loss: -854.984169\n",
      "Train Epoch: 594 [17106/17352 (99%)] Loss: -956.322292\n",
      "    epoch          : 594\n",
      "    loss           : -885.6025144357194\n",
      "    val_loss       : -672.8927600364462\n",
      "Train Epoch: 595 [512/17352 (3%)] Loss: -924.903809\n",
      "Train Epoch: 595 [10223/17352 (59%)] Loss: -984.811167\n",
      "Train Epoch: 595 [16957/17352 (98%)] Loss: -814.644810\n",
      "    epoch          : 595\n",
      "    loss           : -879.2848845252311\n",
      "    val_loss       : -682.8663396516306\n",
      "Train Epoch: 596 [512/17352 (3%)] Loss: -716.984558\n",
      "Train Epoch: 596 [10760/17352 (62%)] Loss: -965.397074\n",
      "Train Epoch: 596 [17143/17352 (99%)] Loss: -1007.232422\n",
      "    epoch          : 596\n",
      "    loss           : -878.4100725955954\n",
      "    val_loss       : -656.6970424316816\n",
      "Train Epoch: 597 [512/17352 (3%)] Loss: -911.234619\n",
      "Train Epoch: 597 [10111/17352 (58%)] Loss: -911.367070\n",
      "Train Epoch: 597 [16934/17352 (98%)] Loss: -907.942708\n",
      "    epoch          : 597\n",
      "    loss           : -879.5628439843251\n",
      "    val_loss       : -685.511712675745\n",
      "Train Epoch: 598 [512/17352 (3%)] Loss: -938.464172\n",
      "Train Epoch: 598 [10551/17352 (61%)] Loss: -972.450833\n",
      "Train Epoch: 598 [17253/17352 (99%)] Loss: -947.752041\n",
      "    epoch          : 598\n",
      "    loss           : -899.4137318241815\n",
      "    val_loss       : -697.0843947768553\n",
      "Train Epoch: 599 [512/17352 (3%)] Loss: -926.447021\n",
      "Train Epoch: 599 [9817/17352 (57%)] Loss: -833.506148\n",
      "Train Epoch: 599 [16923/17352 (98%)] Loss: -765.033158\n",
      "    epoch          : 599\n",
      "    loss           : -889.9611652631604\n",
      "    val_loss       : -680.8219247772137\n",
      "Train Epoch: 600 [512/17352 (3%)] Loss: -932.159180\n",
      "Train Epoch: 600 [10654/17352 (61%)] Loss: -738.547786\n",
      "Train Epoch: 600 [16988/17352 (98%)] Loss: -898.616924\n",
      "    epoch          : 600\n",
      "    loss           : -842.1245640129431\n",
      "    val_loss       : -632.0353201273914\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch600.pth ...\n",
      "Train Epoch: 601 [512/17352 (3%)] Loss: -894.047485\n",
      "Train Epoch: 601 [10607/17352 (61%)] Loss: -690.292285\n",
      "Train Epoch: 601 [16992/17352 (98%)] Loss: -959.086370\n",
      "    epoch          : 601\n",
      "    loss           : -843.4100481516522\n",
      "    val_loss       : -663.9661335443246\n",
      "Train Epoch: 602 [512/17352 (3%)] Loss: -900.674316\n",
      "Train Epoch: 602 [10499/17352 (61%)] Loss: -926.202191\n",
      "Train Epoch: 602 [16878/17352 (97%)] Loss: -963.620808\n",
      "    epoch          : 602\n",
      "    loss           : -875.0748481439972\n",
      "    val_loss       : -686.9468404902755\n",
      "Train Epoch: 603 [512/17352 (3%)] Loss: -929.365723\n",
      "Train Epoch: 603 [10634/17352 (61%)] Loss: -746.311334\n",
      "Train Epoch: 603 [16992/17352 (98%)] Loss: -801.900792\n",
      "    epoch          : 603\n",
      "    loss           : -858.9487123583285\n",
      "    val_loss       : -637.8522337168055\n",
      "Train Epoch: 604 [512/17352 (3%)] Loss: -917.749329\n",
      "Train Epoch: 604 [10624/17352 (61%)] Loss: -827.840164\n",
      "Train Epoch: 604 [17049/17352 (98%)] Loss: -959.566386\n",
      "    epoch          : 604\n",
      "    loss           : -859.3683046176711\n",
      "    val_loss       : -666.477843215442\n",
      "Train Epoch: 605 [512/17352 (3%)] Loss: -925.879456\n",
      "Train Epoch: 605 [10965/17352 (63%)] Loss: -930.905229\n",
      "Train Epoch: 605 [17049/17352 (98%)] Loss: -996.974947\n",
      "    epoch          : 605\n",
      "    loss           : -891.3086770949953\n",
      "    val_loss       : -673.047338777911\n",
      "Train Epoch: 606 [512/17352 (3%)] Loss: -937.111572\n",
      "Train Epoch: 606 [10858/17352 (63%)] Loss: -951.903137\n",
      "Train Epoch: 606 [16872/17352 (97%)] Loss: -860.457403\n",
      "    epoch          : 606\n",
      "    loss           : -896.9460178703986\n",
      "    val_loss       : -675.1461045094425\n",
      "Train Epoch: 607 [512/17352 (3%)] Loss: -912.401978\n",
      "Train Epoch: 607 [10536/17352 (61%)] Loss: -921.577529\n",
      "Train Epoch: 607 [17101/17352 (99%)] Loss: -929.239388\n",
      "    epoch          : 607\n",
      "    loss           : -886.9831759217135\n",
      "    val_loss       : -666.5066338965278\n",
      "Train Epoch: 608 [512/17352 (3%)] Loss: -925.594177\n",
      "Train Epoch: 608 [10339/17352 (60%)] Loss: -963.996221\n",
      "Train Epoch: 608 [16923/17352 (98%)] Loss: -827.480317\n",
      "    epoch          : 608\n",
      "    loss           : -878.1093676213496\n",
      "    val_loss       : -665.8830248351453\n",
      "Train Epoch: 609 [512/17352 (3%)] Loss: -921.600281\n",
      "Train Epoch: 609 [10419/17352 (60%)] Loss: -1002.352973\n",
      "Train Epoch: 609 [16939/17352 (98%)] Loss: -929.969141\n",
      "    epoch          : 609\n",
      "    loss           : -861.8497146675829\n",
      "    val_loss       : -677.9414650848088\n",
      "Train Epoch: 610 [512/17352 (3%)] Loss: -930.282349\n",
      "Train Epoch: 610 [10248/17352 (59%)] Loss: -787.364480\n",
      "Train Epoch: 610 [17263/17352 (99%)] Loss: -827.192808\n",
      "    epoch          : 610\n",
      "    loss           : -894.2741510268442\n",
      "    val_loss       : -631.3283280522114\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch610.pth ...\n",
      "Train Epoch: 611 [512/17352 (3%)] Loss: -716.345764\n",
      "Train Epoch: 611 [10696/17352 (62%)] Loss: -832.984145\n",
      "Train Epoch: 611 [17064/17352 (98%)] Loss: -907.284479\n",
      "    epoch          : 611\n",
      "    loss           : -862.9915851412236\n",
      "    val_loss       : -645.8391943702776\n",
      "Train Epoch: 612 [512/17352 (3%)] Loss: -892.142578\n",
      "Train Epoch: 612 [9416/17352 (54%)] Loss: -835.642768\n",
      "Train Epoch: 612 [17090/17352 (98%)] Loss: -967.881849\n",
      "    epoch          : 612\n",
      "    loss           : -870.3646358761506\n",
      "    val_loss       : -656.3581085259248\n",
      "Train Epoch: 613 [512/17352 (3%)] Loss: -909.066284\n",
      "Train Epoch: 613 [10198/17352 (59%)] Loss: -906.148714\n",
      "Train Epoch: 613 [16988/17352 (98%)] Loss: -1021.134440\n",
      "    epoch          : 613\n",
      "    loss           : -879.5277641566596\n",
      "    val_loss       : -673.1024904051015\n",
      "Train Epoch: 614 [512/17352 (3%)] Loss: -945.834900\n",
      "Train Epoch: 614 [10414/17352 (60%)] Loss: -873.710800\n",
      "Train Epoch: 614 [17253/17352 (99%)] Loss: -793.826555\n",
      "    epoch          : 614\n",
      "    loss           : -901.2073970782577\n",
      "    val_loss       : -587.6583132538228\n",
      "Train Epoch: 615 [512/17352 (3%)] Loss: -839.699463\n",
      "Train Epoch: 615 [10590/17352 (61%)] Loss: -838.546636\n",
      "Train Epoch: 615 [17108/17352 (99%)] Loss: -753.986990\n",
      "    epoch          : 615\n",
      "    loss           : -795.682401107365\n",
      "    val_loss       : -597.0539770532433\n",
      "Train Epoch: 616 [512/17352 (3%)] Loss: -902.560852\n",
      "Train Epoch: 616 [10307/17352 (59%)] Loss: -861.517992\n",
      "Train Epoch: 616 [17133/17352 (99%)] Loss: -854.147802\n",
      "    epoch          : 616\n",
      "    loss           : -774.7686524307466\n",
      "    val_loss       : -544.6143061432532\n",
      "Train Epoch: 617 [512/17352 (3%)] Loss: -830.006042\n",
      "Train Epoch: 617 [11051/17352 (64%)] Loss: -917.015546\n",
      "Train Epoch: 617 [17335/17352 (100%)] Loss: -764.487141\n",
      "    epoch          : 617\n",
      "    loss           : -783.8486649106873\n",
      "    val_loss       : -478.07104367296796\n",
      "Train Epoch: 618 [512/17352 (3%)] Loss: -551.037720\n",
      "Train Epoch: 618 [10658/17352 (61%)] Loss: -744.974684\n",
      "Train Epoch: 618 [16887/17352 (97%)] Loss: -908.598497\n",
      "    epoch          : 618\n",
      "    loss           : -800.2683255756485\n",
      "    val_loss       : -630.9388338268379\n",
      "Train Epoch: 619 [512/17352 (3%)] Loss: -902.311768\n",
      "Train Epoch: 619 [10742/17352 (62%)] Loss: -890.505116\n",
      "Train Epoch: 619 [17143/17352 (99%)] Loss: -859.380308\n",
      "    epoch          : 619\n",
      "    loss           : -838.9193959370743\n",
      "    val_loss       : -654.2150531802001\n",
      "Train Epoch: 620 [512/17352 (3%)] Loss: -898.739258\n",
      "Train Epoch: 620 [10491/17352 (60%)] Loss: -703.429127\n",
      "Train Epoch: 620 [17106/17352 (99%)] Loss: -959.991489\n",
      "    epoch          : 620\n",
      "    loss           : -859.9205146715593\n",
      "    val_loss       : -672.8253103714061\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch620.pth ...\n",
      "Train Epoch: 621 [512/17352 (3%)] Loss: -916.602600\n",
      "Train Epoch: 621 [9536/17352 (55%)] Loss: -820.075371\n",
      "Train Epoch: 621 [16883/17352 (97%)] Loss: -836.239931\n",
      "    epoch          : 621\n",
      "    loss           : -885.8747510228884\n",
      "    val_loss       : -674.2137213776772\n",
      "Train Epoch: 622 [512/17352 (3%)] Loss: -843.223938\n",
      "Train Epoch: 622 [10807/17352 (62%)] Loss: -996.435764\n",
      "Train Epoch: 622 [17277/17352 (100%)] Loss: -999.632869\n",
      "    epoch          : 622\n",
      "    loss           : -879.6236416704696\n",
      "    val_loss       : -664.6732883221378\n",
      "Train Epoch: 623 [512/17352 (3%)] Loss: -903.905334\n",
      "Train Epoch: 623 [9949/17352 (57%)] Loss: -1001.556858\n",
      "Train Epoch: 623 [17277/17352 (100%)] Loss: -721.211423\n",
      "    epoch          : 623\n",
      "    loss           : -890.5965518152536\n",
      "    val_loss       : -672.1229976494226\n",
      "Train Epoch: 624 [512/17352 (3%)] Loss: -926.170288\n",
      "Train Epoch: 624 [10389/17352 (60%)] Loss: -988.746519\n",
      "Train Epoch: 624 [16923/17352 (98%)] Loss: -993.102793\n",
      "    epoch          : 624\n",
      "    loss           : -899.1345637699234\n",
      "    val_loss       : -691.866793309073\n",
      "Train Epoch: 625 [512/17352 (3%)] Loss: -952.257568\n",
      "Train Epoch: 625 [10087/17352 (58%)] Loss: -967.702490\n",
      "Train Epoch: 625 [16878/17352 (97%)] Loss: -1006.827331\n",
      "    epoch          : 625\n",
      "    loss           : -897.8554757340576\n",
      "    val_loss       : -686.5027307091896\n",
      "Train Epoch: 626 [512/17352 (3%)] Loss: -945.736694\n",
      "Train Epoch: 626 [10573/17352 (61%)] Loss: -919.959327\n",
      "Train Epoch: 626 [16988/17352 (98%)] Loss: -805.004590\n",
      "    epoch          : 626\n",
      "    loss           : -897.4329024425625\n",
      "    val_loss       : -685.9749649674303\n",
      "Train Epoch: 627 [512/17352 (3%)] Loss: -748.775879\n",
      "Train Epoch: 627 [10704/17352 (62%)] Loss: -1032.586108\n",
      "Train Epoch: 627 [16887/17352 (97%)] Loss: -869.985491\n",
      "    epoch          : 627\n",
      "    loss           : -910.5256608782341\n",
      "    val_loss       : -671.4277980642499\n",
      "Train Epoch: 628 [512/17352 (3%)] Loss: -973.344543\n",
      "Train Epoch: 628 [10894/17352 (63%)] Loss: -937.333659\n",
      "Train Epoch: 628 [17143/17352 (99%)] Loss: -922.176689\n",
      "    epoch          : 628\n",
      "    loss           : -913.0285989564202\n",
      "    val_loss       : -656.7471855021445\n",
      "Train Epoch: 629 [512/17352 (3%)] Loss: -936.038330\n",
      "Train Epoch: 629 [10121/17352 (58%)] Loss: -953.306536\n",
      "Train Epoch: 629 [17153/17352 (99%)] Loss: -958.032440\n",
      "    epoch          : 629\n",
      "    loss           : -874.2347797026333\n",
      "    val_loss       : -591.3244879115143\n",
      "Train Epoch: 630 [512/17352 (3%)] Loss: -872.336487\n",
      "Train Epoch: 630 [10203/17352 (59%)] Loss: -675.335035\n",
      "Train Epoch: 630 [17253/17352 (99%)] Loss: -906.231039\n",
      "    epoch          : 630\n",
      "    loss           : -837.3891257905759\n",
      "    val_loss       : -530.6095375359643\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch630.pth ...\n",
      "Train Epoch: 631 [512/17352 (3%)] Loss: -783.799683\n",
      "Train Epoch: 631 [10722/17352 (62%)] Loss: -978.469835\n",
      "Train Epoch: 631 [16922/17352 (98%)] Loss: -901.764241\n",
      "    epoch          : 631\n",
      "    loss           : -800.148990500805\n",
      "    val_loss       : -607.0673053340047\n",
      "Train Epoch: 632 [512/17352 (3%)] Loss: -886.897888\n",
      "Train Epoch: 632 [10061/17352 (58%)] Loss: -878.277820\n",
      "Train Epoch: 632 [16923/17352 (98%)] Loss: -797.793385\n",
      "    epoch          : 632\n",
      "    loss           : -759.9907430977901\n",
      "    val_loss       : -522.7872989944133\n",
      "Train Epoch: 633 [512/17352 (3%)] Loss: -770.826599\n",
      "Train Epoch: 633 [10378/17352 (60%)] Loss: -886.191579\n",
      "Train Epoch: 633 [17044/17352 (98%)] Loss: -852.336979\n",
      "    epoch          : 633\n",
      "    loss           : -831.8493752987941\n",
      "    val_loss       : -637.289013885054\n",
      "Train Epoch: 634 [512/17352 (3%)] Loss: -900.528687\n",
      "Train Epoch: 634 [10420/17352 (60%)] Loss: -940.239165\n",
      "Train Epoch: 634 [17049/17352 (98%)] Loss: -921.877532\n",
      "    epoch          : 634\n",
      "    loss           : -871.9410307364751\n",
      "    val_loss       : -544.5620593355885\n",
      "Train Epoch: 635 [512/17352 (3%)] Loss: -781.951721\n",
      "Train Epoch: 635 [10468/17352 (60%)] Loss: -970.402926\n",
      "Train Epoch: 635 [17263/17352 (99%)] Loss: -685.814101\n",
      "    epoch          : 635\n",
      "    loss           : -830.5288506017662\n",
      "    val_loss       : -497.4502390414565\n",
      "Train Epoch: 636 [512/17352 (3%)] Loss: -788.247925\n",
      "Train Epoch: 636 [10588/17352 (61%)] Loss: -956.209688\n",
      "Train Epoch: 636 [17153/17352 (99%)] Loss: -763.459010\n",
      "    epoch          : 636\n",
      "    loss           : -833.102654390463\n",
      "    val_loss       : -594.2363699237113\n",
      "Train Epoch: 637 [512/17352 (3%)] Loss: -850.444824\n",
      "Train Epoch: 637 [10180/17352 (59%)] Loss: -848.636676\n",
      "Train Epoch: 637 [16872/17352 (97%)] Loss: -963.447500\n",
      "    epoch          : 637\n",
      "    loss           : -886.862774527263\n",
      "    val_loss       : -684.785273949418\n",
      "Train Epoch: 638 [512/17352 (3%)] Loss: -949.720337\n",
      "Train Epoch: 638 [9855/17352 (57%)] Loss: -906.316982\n",
      "Train Epoch: 638 [17335/17352 (100%)] Loss: -1024.548880\n",
      "    epoch          : 638\n",
      "    loss           : -897.3517730218692\n",
      "    val_loss       : -678.2036324023949\n",
      "Train Epoch: 639 [512/17352 (3%)] Loss: -949.702332\n",
      "Train Epoch: 639 [10892/17352 (63%)] Loss: -767.690191\n",
      "Train Epoch: 639 [17044/17352 (98%)] Loss: -972.159479\n",
      "    epoch          : 639\n",
      "    loss           : -916.2979436632451\n",
      "    val_loss       : -687.4311387320549\n",
      "Train Epoch: 640 [512/17352 (3%)] Loss: -936.445190\n",
      "Train Epoch: 640 [10166/17352 (59%)] Loss: -1054.726780\n",
      "Train Epoch: 640 [16882/17352 (97%)] Loss: -810.190451\n",
      "    epoch          : 640\n",
      "    loss           : -913.9571836682941\n",
      "    val_loss       : -683.3869684454365\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch640.pth ...\n",
      "Train Epoch: 641 [512/17352 (3%)] Loss: -962.212158\n",
      "Train Epoch: 641 [9878/17352 (57%)] Loss: -1042.708984\n",
      "Train Epoch: 641 [17153/17352 (99%)] Loss: -1010.975332\n",
      "    epoch          : 641\n",
      "    loss           : -912.7425323324395\n",
      "    val_loss       : -698.1293399371822\n",
      "Train Epoch: 642 [512/17352 (3%)] Loss: -966.959473\n",
      "Train Epoch: 642 [10815/17352 (62%)] Loss: -903.317479\n",
      "Train Epoch: 642 [16934/17352 (98%)] Loss: -1015.538979\n",
      "    epoch          : 642\n",
      "    loss           : -916.7309889474293\n",
      "    val_loss       : -678.9207403298075\n",
      "Train Epoch: 643 [512/17352 (3%)] Loss: -956.618591\n",
      "Train Epoch: 643 [10431/17352 (60%)] Loss: -934.755025\n",
      "Train Epoch: 643 [16988/17352 (98%)] Loss: -772.472339\n",
      "    epoch          : 643\n",
      "    loss           : -900.6209004076244\n",
      "    val_loss       : -618.4468404305819\n",
      "Train Epoch: 644 [512/17352 (3%)] Loss: -908.716858\n",
      "Train Epoch: 644 [10068/17352 (58%)] Loss: -854.729550\n",
      "Train Epoch: 644 [16992/17352 (98%)] Loss: -713.894086\n",
      "    epoch          : 644\n",
      "    loss           : -877.0771009851835\n",
      "    val_loss       : -655.2809381529318\n",
      "Train Epoch: 645 [512/17352 (3%)] Loss: -763.896301\n",
      "Train Epoch: 645 [10400/17352 (60%)] Loss: -995.473814\n",
      "Train Epoch: 645 [17277/17352 (100%)] Loss: -967.060788\n",
      "    epoch          : 645\n",
      "    loss           : -902.3953071985877\n",
      "    val_loss       : -644.5282969296026\n",
      "Train Epoch: 646 [512/17352 (3%)] Loss: -913.963318\n",
      "Train Epoch: 646 [11039/17352 (64%)] Loss: -880.505838\n",
      "Train Epoch: 646 [17106/17352 (99%)] Loss: -770.493202\n",
      "    epoch          : 646\n",
      "    loss           : -903.5369334476718\n",
      "    val_loss       : -685.241480659563\n",
      "Train Epoch: 647 [512/17352 (3%)] Loss: -952.169922\n",
      "Train Epoch: 647 [10059/17352 (58%)] Loss: -793.824499\n",
      "Train Epoch: 647 [16887/17352 (97%)] Loss: -828.726656\n",
      "    epoch          : 647\n",
      "    loss           : -845.3804159595469\n",
      "    val_loss       : -615.3853849195858\n",
      "Train Epoch: 648 [512/17352 (3%)] Loss: -905.985168\n",
      "Train Epoch: 648 [9989/17352 (58%)] Loss: -583.089826\n",
      "Train Epoch: 648 [16883/17352 (97%)] Loss: 237.706087\n",
      "    epoch          : 648\n",
      "    loss           : -147.99645601971338\n",
      "    val_loss       : 130.07591303877012\n",
      "Train Epoch: 649 [512/17352 (3%)] Loss: -173.677124\n",
      "Train Epoch: 649 [10049/17352 (58%)] Loss: -450.584978\n",
      "Train Epoch: 649 [17153/17352 (99%)] Loss: -752.699227\n",
      "    epoch          : 649\n",
      "    loss           : -457.7182070186106\n",
      "    val_loss       : 301.54269933912457\n",
      "Train Epoch: 650 [512/17352 (3%)] Loss: -21.666424\n",
      "Train Epoch: 650 [10017/17352 (58%)] Loss: -932.821289\n",
      "Train Epoch: 650 [17143/17352 (99%)] Loss: -864.175833\n",
      "    epoch          : 650\n",
      "    loss           : -685.799699396333\n",
      "    val_loss       : -572.7031328051909\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch650.pth ...\n",
      "Train Epoch: 651 [512/17352 (3%)] Loss: -569.962830\n",
      "Train Epoch: 651 [10641/17352 (61%)] Loss: -874.485896\n",
      "Train Epoch: 651 [16922/17352 (98%)] Loss: -999.282839\n",
      "    epoch          : 651\n",
      "    loss           : -827.7032587225207\n",
      "    val_loss       : -684.3256123667004\n",
      "Train Epoch: 652 [512/17352 (3%)] Loss: -916.633850\n",
      "Train Epoch: 652 [10074/17352 (58%)] Loss: -936.850966\n",
      "Train Epoch: 652 [16934/17352 (98%)] Loss: -969.653553\n",
      "    epoch          : 652\n",
      "    loss           : -888.7979675745257\n",
      "    val_loss       : -687.6360120094699\n",
      "Train Epoch: 653 [512/17352 (3%)] Loss: -947.205811\n",
      "Train Epoch: 653 [10026/17352 (58%)] Loss: -995.735247\n",
      "Train Epoch: 653 [16883/17352 (97%)] Loss: -824.192421\n",
      "    epoch          : 653\n",
      "    loss           : -908.175216343964\n",
      "    val_loss       : -697.0021885958696\n",
      "Train Epoch: 654 [512/17352 (3%)] Loss: -959.593628\n",
      "Train Epoch: 654 [9870/17352 (57%)] Loss: -789.095134\n",
      "Train Epoch: 654 [16922/17352 (98%)] Loss: -967.694656\n",
      "    epoch          : 654\n",
      "    loss           : -915.1924954290173\n",
      "    val_loss       : -696.9734674981408\n",
      "Train Epoch: 655 [512/17352 (3%)] Loss: -965.351196\n",
      "Train Epoch: 655 [10798/17352 (62%)] Loss: -1024.984408\n",
      "Train Epoch: 655 [16992/17352 (98%)] Loss: -972.725237\n",
      "    epoch          : 655\n",
      "    loss           : -915.5378601468664\n",
      "    val_loss       : -700.1363989941398\n",
      "Train Epoch: 656 [512/17352 (3%)] Loss: -937.301514\n",
      "Train Epoch: 656 [9700/17352 (56%)] Loss: -948.510301\n",
      "Train Epoch: 656 [17277/17352 (100%)] Loss: -1054.190972\n",
      "    epoch          : 656\n",
      "    loss           : -919.4960042632418\n",
      "    val_loss       : -696.9498622062085\n",
      "Train Epoch: 657 [512/17352 (3%)] Loss: -959.150208\n",
      "Train Epoch: 657 [10745/17352 (62%)] Loss: -1010.874468\n",
      "Train Epoch: 657 [17277/17352 (100%)] Loss: -918.387092\n",
      "    epoch          : 657\n",
      "    loss           : -913.6758006018678\n",
      "    val_loss       : -682.9308039660746\n",
      "Train Epoch: 658 [512/17352 (3%)] Loss: -938.459717\n",
      "Train Epoch: 658 [10136/17352 (58%)] Loss: -860.450174\n",
      "Train Epoch: 658 [16923/17352 (98%)] Loss: -866.884889\n",
      "    epoch          : 658\n",
      "    loss           : -920.1070742752762\n",
      "    val_loss       : -699.8373446885774\n",
      "Train Epoch: 659 [512/17352 (3%)] Loss: -968.093872\n",
      "Train Epoch: 659 [10464/17352 (60%)] Loss: -1001.444004\n",
      "Train Epoch: 659 [16882/17352 (97%)] Loss: -992.827708\n",
      "    epoch          : 659\n",
      "    loss           : -926.517932266043\n",
      "    val_loss       : -710.5957611820972\n",
      "Train Epoch: 660 [512/17352 (3%)] Loss: -966.405640\n",
      "Train Epoch: 660 [10297/17352 (59%)] Loss: -764.032527\n",
      "Train Epoch: 660 [16922/17352 (98%)] Loss: -844.570887\n",
      "    epoch          : 660\n",
      "    loss           : -923.1771921928092\n",
      "    val_loss       : -684.8791422237032\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch660.pth ...\n",
      "Train Epoch: 661 [512/17352 (3%)] Loss: -955.210205\n",
      "Train Epoch: 661 [10503/17352 (61%)] Loss: -928.776460\n",
      "Train Epoch: 661 [16922/17352 (98%)] Loss: -853.427220\n",
      "    epoch          : 661\n",
      "    loss           : -901.8131994706399\n",
      "    val_loss       : -680.3186150125272\n",
      "Train Epoch: 662 [512/17352 (3%)] Loss: -930.305542\n",
      "Train Epoch: 662 [10113/17352 (58%)] Loss: -937.229088\n",
      "Train Epoch: 662 [17133/17352 (99%)] Loss: -718.256654\n",
      "    epoch          : 662\n",
      "    loss           : -907.4544684721319\n",
      "    val_loss       : -665.958694323613\n",
      "Train Epoch: 663 [512/17352 (3%)] Loss: -958.359497\n",
      "Train Epoch: 663 [9934/17352 (57%)] Loss: -974.204968\n",
      "Train Epoch: 663 [17090/17352 (98%)] Loss: -771.981116\n",
      "    epoch          : 663\n",
      "    loss           : -917.0363463657792\n",
      "    val_loss       : -681.2252572575974\n",
      "Train Epoch: 664 [512/17352 (3%)] Loss: -971.192139\n",
      "Train Epoch: 664 [10230/17352 (59%)] Loss: -870.040984\n",
      "Train Epoch: 664 [16882/17352 (97%)] Loss: -960.697683\n",
      "    epoch          : 664\n",
      "    loss           : -926.0575541286943\n",
      "    val_loss       : -695.3749668149543\n",
      "Train Epoch: 665 [512/17352 (3%)] Loss: -960.489929\n",
      "Train Epoch: 665 [10179/17352 (59%)] Loss: -868.897743\n",
      "Train Epoch: 665 [16934/17352 (98%)] Loss: -1007.013325\n",
      "    epoch          : 665\n",
      "    loss           : -923.7707526254643\n",
      "    val_loss       : -684.7106700470616\n",
      "Train Epoch: 666 [512/17352 (3%)] Loss: -960.326538\n",
      "Train Epoch: 666 [10047/17352 (58%)] Loss: -924.172105\n",
      "Train Epoch: 666 [17090/17352 (98%)] Loss: -996.098837\n",
      "    epoch          : 666\n",
      "    loss           : -928.3333375005468\n",
      "    val_loss       : -693.4166199386123\n",
      "Train Epoch: 667 [512/17352 (3%)] Loss: -970.423767\n",
      "Train Epoch: 667 [9807/17352 (57%)] Loss: -1029.306911\n",
      "Train Epoch: 667 [16883/17352 (97%)] Loss: -817.771343\n",
      "    epoch          : 667\n",
      "    loss           : -927.0262395669731\n",
      "    val_loss       : -702.1918426173393\n",
      "Train Epoch: 668 [512/17352 (3%)] Loss: -972.076721\n",
      "Train Epoch: 668 [10418/17352 (60%)] Loss: -1025.418318\n",
      "Train Epoch: 668 [17016/17352 (98%)] Loss: -782.122525\n",
      "    epoch          : 668\n",
      "    loss           : -920.7106318121798\n",
      "    val_loss       : -670.913511477897\n",
      "Train Epoch: 669 [512/17352 (3%)] Loss: -965.607056\n",
      "Train Epoch: 669 [10617/17352 (61%)] Loss: -899.539835\n",
      "Train Epoch: 669 [16872/17352 (97%)] Loss: -837.826302\n",
      "    epoch          : 669\n",
      "    loss           : -925.1252462691408\n",
      "    val_loss       : -674.2229122429977\n",
      "Train Epoch: 670 [512/17352 (3%)] Loss: -952.545715\n",
      "Train Epoch: 670 [10823/17352 (62%)] Loss: -884.423084\n",
      "Train Epoch: 670 [17263/17352 (99%)] Loss: -852.518802\n",
      "    epoch          : 670\n",
      "    loss           : -891.6292906624006\n",
      "    val_loss       : -603.2116803996239\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch670.pth ...\n",
      "Train Epoch: 671 [512/17352 (3%)] Loss: -875.331604\n",
      "Train Epoch: 671 [10665/17352 (61%)] Loss: -970.566854\n",
      "Train Epoch: 671 [17126/17352 (99%)] Loss: -996.465208\n",
      "    epoch          : 671\n",
      "    loss           : -902.0088095179561\n",
      "    val_loss       : -678.5020840786389\n",
      "Train Epoch: 672 [512/17352 (3%)] Loss: -965.063354\n",
      "Train Epoch: 672 [10488/17352 (60%)] Loss: -1061.818468\n",
      "Train Epoch: 672 [16882/17352 (97%)] Loss: -872.571994\n",
      "    epoch          : 672\n",
      "    loss           : -921.076411308545\n",
      "    val_loss       : -685.8484948194474\n",
      "Train Epoch: 673 [512/17352 (3%)] Loss: -963.090332\n",
      "Train Epoch: 673 [10014/17352 (58%)] Loss: -890.221740\n",
      "Train Epoch: 673 [16872/17352 (97%)] Loss: -955.145716\n",
      "    epoch          : 673\n",
      "    loss           : -922.1955738579401\n",
      "    val_loss       : -670.3530337619449\n",
      "Train Epoch: 674 [512/17352 (3%)] Loss: -948.480103\n",
      "Train Epoch: 674 [10889/17352 (63%)] Loss: -995.300603\n",
      "Train Epoch: 674 [17016/17352 (98%)] Loss: -950.923516\n",
      "    epoch          : 674\n",
      "    loss           : -909.8379117426111\n",
      "    val_loss       : -649.8781947110158\n",
      "Train Epoch: 675 [512/17352 (3%)] Loss: -942.729187\n",
      "Train Epoch: 675 [10471/17352 (60%)] Loss: -957.292878\n",
      "Train Epoch: 675 [16958/17352 (98%)] Loss: -958.011850\n",
      "    epoch          : 675\n",
      "    loss           : -896.123740930073\n",
      "    val_loss       : -631.1247921931886\n",
      "Train Epoch: 676 [512/17352 (3%)] Loss: -928.970154\n",
      "Train Epoch: 676 [10987/17352 (63%)] Loss: -722.975030\n",
      "Train Epoch: 676 [16923/17352 (98%)] Loss: -930.035511\n",
      "    epoch          : 676\n",
      "    loss           : -893.2734421013025\n",
      "    val_loss       : -678.6621685966713\n",
      "Train Epoch: 677 [512/17352 (3%)] Loss: -945.030273\n",
      "Train Epoch: 677 [10041/17352 (58%)] Loss: -959.548373\n",
      "Train Epoch: 677 [16887/17352 (97%)] Loss: -820.531250\n",
      "    epoch          : 677\n",
      "    loss           : -912.196064889861\n",
      "    val_loss       : -677.7927974314549\n",
      "Train Epoch: 678 [512/17352 (3%)] Loss: -977.849304\n",
      "Train Epoch: 678 [10465/17352 (60%)] Loss: -881.218270\n",
      "Train Epoch: 678 [17335/17352 (100%)] Loss: -969.294728\n",
      "    epoch          : 678\n",
      "    loss           : -922.3417344348361\n",
      "    val_loss       : -669.079130650832\n",
      "Train Epoch: 679 [512/17352 (3%)] Loss: -951.197205\n",
      "Train Epoch: 679 [10417/17352 (60%)] Loss: -1003.045471\n",
      "Train Epoch: 679 [17044/17352 (98%)] Loss: -909.884272\n",
      "    epoch          : 679\n",
      "    loss           : -926.3476614276304\n",
      "    val_loss       : -702.9596287452554\n",
      "Train Epoch: 680 [512/17352 (3%)] Loss: -981.811157\n",
      "Train Epoch: 680 [9976/17352 (57%)] Loss: -843.433289\n",
      "Train Epoch: 680 [16922/17352 (98%)] Loss: -827.543051\n",
      "    epoch          : 680\n",
      "    loss           : -926.3837222563752\n",
      "    val_loss       : -693.7158935638969\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch680.pth ...\n",
      "Train Epoch: 681 [512/17352 (3%)] Loss: -982.661804\n",
      "Train Epoch: 681 [10466/17352 (60%)] Loss: -982.824700\n",
      "Train Epoch: 681 [17277/17352 (100%)] Loss: -1038.281250\n",
      "    epoch          : 681\n",
      "    loss           : -935.7508657218851\n",
      "    val_loss       : -663.9047422682294\n",
      "Train Epoch: 682 [512/17352 (3%)] Loss: -770.283203\n",
      "Train Epoch: 682 [9999/17352 (58%)] Loss: -853.153378\n",
      "Train Epoch: 682 [17044/17352 (98%)] Loss: -1038.733409\n",
      "    epoch          : 682\n",
      "    loss           : -925.6531886689332\n",
      "    val_loss       : -688.5623827266791\n",
      "Train Epoch: 683 [512/17352 (3%)] Loss: -966.332764\n",
      "Train Epoch: 683 [9967/17352 (57%)] Loss: -874.561603\n",
      "Train Epoch: 683 [16887/17352 (97%)] Loss: -999.961265\n",
      "    epoch          : 683\n",
      "    loss           : -935.5410235934309\n",
      "    val_loss       : -679.5715962564145\n",
      "Train Epoch: 684 [512/17352 (3%)] Loss: -951.271973\n",
      "Train Epoch: 684 [10297/17352 (59%)] Loss: -830.611607\n",
      "Train Epoch: 684 [17153/17352 (99%)] Loss: -984.854333\n",
      "    epoch          : 684\n",
      "    loss           : -929.822142062746\n",
      "    val_loss       : -675.5047994878253\n",
      "Train Epoch: 685 [512/17352 (3%)] Loss: -970.810303\n",
      "Train Epoch: 685 [10534/17352 (61%)] Loss: -969.484296\n",
      "Train Epoch: 685 [17143/17352 (99%)] Loss: -1021.810104\n",
      "    epoch          : 685\n",
      "    loss           : -931.6433671995313\n",
      "    val_loss       : -660.6528367503167\n",
      "Train Epoch: 686 [512/17352 (3%)] Loss: -969.021545\n",
      "Train Epoch: 686 [10063/17352 (58%)] Loss: -663.742809\n",
      "Train Epoch: 686 [16958/17352 (98%)] Loss: -798.395767\n",
      "    epoch          : 686\n",
      "    loss           : -883.6787876816321\n",
      "    val_loss       : -601.8132209856914\n",
      "Train Epoch: 687 [512/17352 (3%)] Loss: -919.940063\n",
      "Train Epoch: 687 [10038/17352 (58%)] Loss: -937.330009\n",
      "Train Epoch: 687 [16872/17352 (97%)] Loss: -935.202099\n",
      "    epoch          : 687\n",
      "    loss           : -904.3253057023818\n",
      "    val_loss       : -650.4792688998273\n",
      "Train Epoch: 688 [512/17352 (3%)] Loss: -944.607239\n",
      "Train Epoch: 688 [10718/17352 (62%)] Loss: -866.584224\n",
      "Train Epoch: 688 [16872/17352 (97%)] Loss: -958.934867\n",
      "    epoch          : 688\n",
      "    loss           : -885.9062564699404\n",
      "    val_loss       : -657.4237011067368\n",
      "Train Epoch: 689 [512/17352 (3%)] Loss: -900.717041\n",
      "Train Epoch: 689 [10378/17352 (60%)] Loss: -829.425141\n",
      "Train Epoch: 689 [16992/17352 (98%)] Loss: -939.451250\n",
      "    epoch          : 689\n",
      "    loss           : -886.6896065844722\n",
      "    val_loss       : -642.5872195806649\n",
      "Train Epoch: 690 [512/17352 (3%)] Loss: -936.693420\n",
      "Train Epoch: 690 [10292/17352 (59%)] Loss: -833.172492\n",
      "Train Epoch: 690 [16923/17352 (98%)] Loss: -999.129464\n",
      "    epoch          : 690\n",
      "    loss           : -882.8680537702246\n",
      "    val_loss       : -657.2524616496721\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch690.pth ...\n",
      "Train Epoch: 691 [512/17352 (3%)] Loss: -932.725403\n",
      "Train Epoch: 691 [10674/17352 (62%)] Loss: -1009.376995\n",
      "Train Epoch: 691 [17016/17352 (98%)] Loss: -845.738582\n",
      "    epoch          : 691\n",
      "    loss           : -898.6360829761097\n",
      "    val_loss       : -641.6967486890874\n",
      "Train Epoch: 692 [512/17352 (3%)] Loss: -900.413574\n",
      "Train Epoch: 692 [10172/17352 (59%)] Loss: -949.666067\n",
      "Train Epoch: 692 [17090/17352 (98%)] Loss: -938.223147\n",
      "    epoch          : 692\n",
      "    loss           : -905.8317772929323\n",
      "    val_loss       : -647.9344180560137\n",
      "Train Epoch: 693 [512/17352 (3%)] Loss: -950.122314\n",
      "Train Epoch: 693 [10879/17352 (63%)] Loss: -978.181250\n",
      "Train Epoch: 693 [17143/17352 (99%)] Loss: -614.315660\n",
      "    epoch          : 693\n",
      "    loss           : -819.7239972852469\n",
      "    val_loss       : -560.6474572861234\n",
      "Train Epoch: 694 [512/17352 (3%)] Loss: -845.303284\n",
      "Train Epoch: 694 [10285/17352 (59%)] Loss: -848.160136\n",
      "Train Epoch: 694 [16922/17352 (98%)] Loss: -331.717694\n",
      "    epoch          : 694\n",
      "    loss           : -727.5884594631946\n",
      "    val_loss       : -274.63355513293874\n",
      "Train Epoch: 695 [512/17352 (3%)] Loss: -600.800964\n",
      "Train Epoch: 695 [10727/17352 (62%)] Loss: -520.442060\n",
      "Train Epoch: 695 [17335/17352 (100%)] Loss: -555.884879\n",
      "    epoch          : 695\n",
      "    loss           : -714.3938406529595\n",
      "    val_loss       : -228.77361399181038\n",
      "Train Epoch: 696 [512/17352 (3%)] Loss: -584.002075\n",
      "Train Epoch: 696 [10210/17352 (59%)] Loss: -374.050840\n",
      "Train Epoch: 696 [17090/17352 (98%)] Loss: -807.437832\n",
      "    epoch          : 696\n",
      "    loss           : -649.5908274373893\n",
      "    val_loss       : -468.5839836863999\n",
      "Train Epoch: 697 [512/17352 (3%)] Loss: -725.473938\n",
      "Train Epoch: 697 [10911/17352 (63%)] Loss: -738.771040\n",
      "Train Epoch: 697 [17108/17352 (99%)] Loss: -906.285245\n",
      "    epoch          : 697\n",
      "    loss           : -841.186228593745\n",
      "    val_loss       : -666.0601694679682\n",
      "Train Epoch: 698 [512/17352 (3%)] Loss: -965.463379\n",
      "Train Epoch: 698 [10197/17352 (59%)] Loss: -744.816163\n",
      "Train Epoch: 698 [17106/17352 (99%)] Loss: -898.440076\n",
      "    epoch          : 698\n",
      "    loss           : -892.191585007304\n",
      "    val_loss       : -637.2507048716091\n",
      "Train Epoch: 699 [512/17352 (3%)] Loss: -933.358887\n",
      "Train Epoch: 699 [10620/17352 (61%)] Loss: -1004.434583\n",
      "Train Epoch: 699 [17253/17352 (99%)] Loss: -737.857955\n",
      "    epoch          : 699\n",
      "    loss           : -895.759725798712\n",
      "    val_loss       : -665.433125446046\n",
      "Train Epoch: 700 [512/17352 (3%)] Loss: -933.573120\n",
      "Train Epoch: 700 [9996/17352 (58%)] Loss: -920.482694\n",
      "Train Epoch: 700 [17106/17352 (99%)] Loss: -841.199611\n",
      "    epoch          : 700\n",
      "    loss           : -909.0808289406216\n",
      "    val_loss       : -681.1655327552577\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch700.pth ...\n",
      "Train Epoch: 701 [512/17352 (3%)] Loss: -977.811523\n",
      "Train Epoch: 701 [9864/17352 (57%)] Loss: -984.223244\n",
      "Train Epoch: 701 [17153/17352 (99%)] Loss: -793.673090\n",
      "    epoch          : 701\n",
      "    loss           : -922.2816229760109\n",
      "    val_loss       : -685.6944281825105\n",
      "Train Epoch: 702 [512/17352 (3%)] Loss: -979.898315\n",
      "Train Epoch: 702 [10451/17352 (60%)] Loss: -1009.770807\n",
      "Train Epoch: 702 [16958/17352 (98%)] Loss: -1026.798308\n",
      "    epoch          : 702\n",
      "    loss           : -910.1232616343395\n",
      "    val_loss       : -654.9484087087815\n",
      "Train Epoch: 703 [512/17352 (3%)] Loss: -941.297302\n",
      "Train Epoch: 703 [10289/17352 (59%)] Loss: -920.615695\n",
      "Train Epoch: 703 [16887/17352 (97%)] Loss: -731.699371\n",
      "    epoch          : 703\n",
      "    loss           : -863.514051147957\n",
      "    val_loss       : -653.3135840832814\n",
      "Train Epoch: 704 [512/17352 (3%)] Loss: -942.583069\n",
      "Train Epoch: 704 [10723/17352 (62%)] Loss: -1022.717484\n",
      "Train Epoch: 704 [17049/17352 (98%)] Loss: -1010.664096\n",
      "    epoch          : 704\n",
      "    loss           : -900.5259434964736\n",
      "    val_loss       : -671.6535127223985\n",
      "Train Epoch: 705 [512/17352 (3%)] Loss: -960.592407\n",
      "Train Epoch: 705 [9759/17352 (56%)] Loss: -939.503936\n",
      "Train Epoch: 705 [16988/17352 (98%)] Loss: -934.572061\n",
      "    epoch          : 705\n",
      "    loss           : -886.1524169414629\n",
      "    val_loss       : -635.004831582587\n",
      "Train Epoch: 706 [512/17352 (3%)] Loss: -747.529663\n",
      "Train Epoch: 706 [10203/17352 (59%)] Loss: -1011.314519\n",
      "Train Epoch: 706 [17106/17352 (99%)] Loss: -983.703753\n",
      "    epoch          : 706\n",
      "    loss           : -915.8804683740739\n",
      "    val_loss       : -656.3025720974689\n",
      "Train Epoch: 707 [512/17352 (3%)] Loss: -940.717712\n",
      "Train Epoch: 707 [10377/17352 (60%)] Loss: -762.222669\n",
      "Train Epoch: 707 [17016/17352 (98%)] Loss: -729.174566\n",
      "    epoch          : 707\n",
      "    loss           : -903.5562344016669\n",
      "    val_loss       : -670.2217399916506\n",
      "Train Epoch: 708 [512/17352 (3%)] Loss: -965.324463\n",
      "Train Epoch: 708 [10289/17352 (59%)] Loss: -951.039730\n",
      "Train Epoch: 708 [17335/17352 (100%)] Loss: -954.441210\n",
      "    epoch          : 708\n",
      "    loss           : -902.6157087935762\n",
      "    val_loss       : -649.047201162895\n",
      "Train Epoch: 709 [512/17352 (3%)] Loss: -928.981934\n",
      "Train Epoch: 709 [10303/17352 (59%)] Loss: -455.796501\n",
      "Train Epoch: 709 [16882/17352 (97%)] Loss: -789.136489\n",
      "    epoch          : 709\n",
      "    loss           : -887.9934832773749\n",
      "    val_loss       : -663.4785457486125\n",
      "Train Epoch: 710 [512/17352 (3%)] Loss: -969.567261\n",
      "Train Epoch: 710 [10322/17352 (59%)] Loss: -975.968034\n",
      "Train Epoch: 710 [16878/17352 (97%)] Loss: -1001.469540\n",
      "    epoch          : 710\n",
      "    loss           : -923.518829405408\n",
      "    val_loss       : -683.3511068462892\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch710.pth ...\n",
      "Train Epoch: 711 [512/17352 (3%)] Loss: -953.427734\n",
      "Train Epoch: 711 [10966/17352 (63%)] Loss: -1050.778518\n",
      "Train Epoch: 711 [17253/17352 (99%)] Loss: -833.828125\n",
      "    epoch          : 711\n",
      "    loss           : -899.3761445123572\n",
      "    val_loss       : -499.4335865908242\n",
      "Train Epoch: 712 [512/17352 (3%)] Loss: -770.571228\n",
      "Train Epoch: 712 [10604/17352 (61%)] Loss: -1020.219618\n",
      "Train Epoch: 712 [16958/17352 (98%)] Loss: -213.936216\n",
      "    epoch          : 712\n",
      "    loss           : -763.043161542254\n",
      "    val_loss       : -145.05495797984645\n",
      "Train Epoch: 713 [512/17352 (3%)] Loss: -180.483368\n",
      "Train Epoch: 713 [10709/17352 (62%)] Loss: -638.289887\n",
      "Train Epoch: 713 [16883/17352 (97%)] Loss: -897.991071\n",
      "    epoch          : 713\n",
      "    loss           : -720.7938676565019\n",
      "    val_loss       : -567.5105790655424\n",
      "Train Epoch: 714 [512/17352 (3%)] Loss: -676.488953\n",
      "Train Epoch: 714 [9834/17352 (57%)] Loss: -802.842552\n",
      "Train Epoch: 714 [16922/17352 (98%)] Loss: -853.285432\n",
      "    epoch          : 714\n",
      "    loss           : -824.4758931659295\n",
      "    val_loss       : -660.1744051634371\n",
      "Train Epoch: 715 [512/17352 (3%)] Loss: -747.122925\n",
      "Train Epoch: 715 [10010/17352 (58%)] Loss: -893.680294\n",
      "Train Epoch: 715 [16923/17352 (98%)] Loss: -928.286636\n",
      "    epoch          : 715\n",
      "    loss           : -875.070192567773\n",
      "    val_loss       : -641.4609740863908\n",
      "Train Epoch: 716 [512/17352 (3%)] Loss: -910.399780\n",
      "Train Epoch: 716 [10162/17352 (59%)] Loss: -746.775336\n",
      "Train Epoch: 716 [16923/17352 (98%)] Loss: -946.396435\n",
      "    epoch          : 716\n",
      "    loss           : -895.1676694461934\n",
      "    val_loss       : -695.2351671086376\n",
      "Train Epoch: 717 [512/17352 (3%)] Loss: -948.174683\n",
      "Train Epoch: 717 [10361/17352 (60%)] Loss: -815.894787\n",
      "Train Epoch: 717 [17044/17352 (98%)] Loss: -948.780355\n",
      "    epoch          : 717\n",
      "    loss           : -914.0945852554194\n",
      "    val_loss       : -686.473847059828\n",
      "Train Epoch: 718 [512/17352 (3%)] Loss: -966.650513\n",
      "Train Epoch: 718 [9768/17352 (56%)] Loss: -893.364857\n",
      "Train Epoch: 718 [17108/17352 (99%)] Loss: -1027.372049\n",
      "    epoch          : 718\n",
      "    loss           : -911.4457819073209\n",
      "    val_loss       : -672.0482151381142\n",
      "Train Epoch: 719 [512/17352 (3%)] Loss: -946.753052\n",
      "Train Epoch: 719 [10219/17352 (59%)] Loss: -936.665562\n",
      "Train Epoch: 719 [17153/17352 (99%)] Loss: -1009.737500\n",
      "    epoch          : 719\n",
      "    loss           : -890.31254472345\n",
      "    val_loss       : -605.3983355664709\n",
      "Train Epoch: 720 [512/17352 (3%)] Loss: -673.733704\n",
      "Train Epoch: 720 [10886/17352 (63%)] Loss: -1014.965418\n",
      "Train Epoch: 720 [17090/17352 (98%)] Loss: -826.246559\n",
      "    epoch          : 720\n",
      "    loss           : -878.9930170580899\n",
      "    val_loss       : -612.6605729613303\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch720.pth ...\n",
      "Train Epoch: 721 [512/17352 (3%)] Loss: -847.662659\n",
      "Train Epoch: 721 [10546/17352 (61%)] Loss: -862.506261\n",
      "Train Epoch: 721 [16922/17352 (98%)] Loss: -775.355578\n",
      "    epoch          : 721\n",
      "    loss           : -922.9636545744773\n",
      "    val_loss       : -697.5773801719421\n",
      "Train Epoch: 722 [512/17352 (3%)] Loss: -971.046082\n",
      "Train Epoch: 722 [10496/17352 (60%)] Loss: -885.947222\n",
      "Train Epoch: 722 [16988/17352 (98%)] Loss: -783.019961\n",
      "    epoch          : 722\n",
      "    loss           : -934.5423320096273\n",
      "    val_loss       : -679.2273558961788\n",
      "Train Epoch: 723 [512/17352 (3%)] Loss: -959.194580\n",
      "Train Epoch: 723 [10557/17352 (61%)] Loss: -807.608553\n",
      "Train Epoch: 723 [17108/17352 (99%)] Loss: -903.357980\n",
      "    epoch          : 723\n",
      "    loss           : -937.7595052270799\n",
      "    val_loss       : -679.5817286747812\n",
      "Train Epoch: 724 [512/17352 (3%)] Loss: -956.365234\n",
      "Train Epoch: 724 [10917/17352 (63%)] Loss: -899.952288\n",
      "Train Epoch: 724 [16939/17352 (98%)] Loss: -958.978015\n",
      "    epoch          : 724\n",
      "    loss           : -936.1981060511607\n",
      "    val_loss       : -676.3295963020646\n",
      "Train Epoch: 725 [512/17352 (3%)] Loss: -984.969177\n",
      "Train Epoch: 725 [10140/17352 (58%)] Loss: -800.527170\n",
      "Train Epoch: 725 [16883/17352 (97%)] Loss: -552.684715\n",
      "    epoch          : 725\n",
      "    loss           : -851.3135311892576\n",
      "    val_loss       : -579.3476205971765\n",
      "Train Epoch: 726 [512/17352 (3%)] Loss: -552.829834\n",
      "Train Epoch: 726 [10304/17352 (59%)] Loss: -756.628132\n",
      "Train Epoch: 726 [16988/17352 (98%)] Loss: -867.324278\n",
      "    epoch          : 726\n",
      "    loss           : -844.370610512135\n",
      "    val_loss       : -635.7190906698526\n",
      "Train Epoch: 727 [512/17352 (3%)] Loss: -952.555420\n",
      "Train Epoch: 727 [10374/17352 (60%)] Loss: -957.203989\n",
      "Train Epoch: 727 [16992/17352 (98%)] Loss: -868.634593\n",
      "    epoch          : 727\n",
      "    loss           : -877.7789968041144\n",
      "    val_loss       : -657.2617051778656\n",
      "Train Epoch: 728 [512/17352 (3%)] Loss: -940.151428\n",
      "Train Epoch: 728 [9927/17352 (57%)] Loss: -926.882277\n",
      "Train Epoch: 728 [16887/17352 (97%)] Loss: -768.171651\n",
      "    epoch          : 728\n",
      "    loss           : -876.0955506580062\n",
      "    val_loss       : -658.589049014565\n",
      "Train Epoch: 729 [512/17352 (3%)] Loss: -936.323914\n",
      "Train Epoch: 729 [9875/17352 (57%)] Loss: -854.571634\n",
      "Train Epoch: 729 [17253/17352 (99%)] Loss: -792.635314\n",
      "    epoch          : 729\n",
      "    loss           : -920.1344711514154\n",
      "    val_loss       : -690.8419960497982\n",
      "Train Epoch: 730 [512/17352 (3%)] Loss: -955.820068\n",
      "Train Epoch: 730 [10410/17352 (60%)] Loss: -968.254909\n",
      "Train Epoch: 730 [16923/17352 (98%)] Loss: -917.184348\n",
      "    epoch          : 730\n",
      "    loss           : -943.420457600622\n",
      "    val_loss       : -695.3463799489784\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch730.pth ...\n",
      "Train Epoch: 731 [512/17352 (3%)] Loss: -983.368530\n",
      "Train Epoch: 731 [10465/17352 (60%)] Loss: -970.586330\n",
      "Train Epoch: 731 [17277/17352 (100%)] Loss: -1000.479747\n",
      "    epoch          : 731\n",
      "    loss           : -903.3946829601239\n",
      "    val_loss       : -649.8965274468038\n",
      "Train Epoch: 732 [512/17352 (3%)] Loss: -933.689636\n",
      "Train Epoch: 732 [10484/17352 (60%)] Loss: -1017.979933\n",
      "Train Epoch: 732 [17049/17352 (98%)] Loss: -940.670455\n",
      "    epoch          : 732\n",
      "    loss           : -923.9819918733021\n",
      "    val_loss       : -678.1215021978288\n",
      "Train Epoch: 733 [512/17352 (3%)] Loss: -952.448120\n",
      "Train Epoch: 733 [10613/17352 (61%)] Loss: -1008.311771\n",
      "Train Epoch: 733 [17143/17352 (99%)] Loss: -841.838925\n",
      "    epoch          : 733\n",
      "    loss           : -898.2099979833276\n",
      "    val_loss       : -503.644184459666\n",
      "Train Epoch: 734 [512/17352 (3%)] Loss: -827.797546\n",
      "Train Epoch: 734 [10590/17352 (61%)] Loss: -846.966493\n",
      "Train Epoch: 734 [17124/17352 (99%)] Loss: -891.957491\n",
      "    epoch          : 734\n",
      "    loss           : -842.4698755705206\n",
      "    val_loss       : -572.4839454977067\n",
      "Train Epoch: 735 [512/17352 (3%)] Loss: -912.851440\n",
      "Train Epoch: 735 [10872/17352 (63%)] Loss: -806.958531\n",
      "Train Epoch: 735 [17153/17352 (99%)] Loss: -996.447340\n",
      "    epoch          : 735\n",
      "    loss           : -872.245432315072\n",
      "    val_loss       : -596.316934650333\n",
      "Train Epoch: 736 [512/17352 (3%)] Loss: -877.460815\n",
      "Train Epoch: 736 [10380/17352 (60%)] Loss: -1026.945067\n",
      "Train Epoch: 736 [16872/17352 (97%)] Loss: -753.921532\n",
      "    epoch          : 736\n",
      "    loss           : -908.614934984891\n",
      "    val_loss       : -622.596703161317\n",
      "Train Epoch: 737 [512/17352 (3%)] Loss: -905.848389\n",
      "Train Epoch: 737 [10253/17352 (59%)] Loss: -1029.564619\n",
      "Train Epoch: 737 [17153/17352 (99%)] Loss: -1019.241297\n",
      "    epoch          : 737\n",
      "    loss           : -901.1988064181226\n",
      "    val_loss       : -647.5724024744994\n",
      "Train Epoch: 738 [512/17352 (3%)] Loss: -926.964905\n",
      "Train Epoch: 738 [9875/17352 (57%)] Loss: -989.884721\n",
      "Train Epoch: 738 [16988/17352 (98%)] Loss: -626.446419\n",
      "    epoch          : 738\n",
      "    loss           : -902.8946565875735\n",
      "    val_loss       : -291.5846834967724\n",
      "Train Epoch: 739 [512/17352 (3%)] Loss: -533.811279\n",
      "Train Epoch: 739 [10652/17352 (61%)] Loss: -721.626015\n",
      "Train Epoch: 739 [17064/17352 (98%)] Loss: -774.966059\n",
      "    epoch          : 739\n",
      "    loss           : -860.6863269987717\n",
      "    val_loss       : -662.7130492377213\n",
      "Train Epoch: 740 [512/17352 (3%)] Loss: -951.214417\n",
      "Train Epoch: 740 [10446/17352 (60%)] Loss: -1063.399197\n",
      "Train Epoch: 740 [16934/17352 (98%)] Loss: -910.252990\n",
      "    epoch          : 740\n",
      "    loss           : -926.4878765740162\n",
      "    val_loss       : -708.2132142971152\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch740.pth ...\n",
      "Train Epoch: 741 [512/17352 (3%)] Loss: -1001.057861\n",
      "Train Epoch: 741 [10571/17352 (61%)] Loss: -1035.761263\n",
      "Train Epoch: 741 [17064/17352 (98%)] Loss: -965.549022\n",
      "    epoch          : 741\n",
      "    loss           : -942.9164984004143\n",
      "    val_loss       : -653.000714628111\n",
      "Train Epoch: 742 [512/17352 (3%)] Loss: -971.139221\n",
      "Train Epoch: 742 [10352/17352 (60%)] Loss: -1010.162832\n",
      "Train Epoch: 742 [16939/17352 (98%)] Loss: -876.381197\n",
      "    epoch          : 742\n",
      "    loss           : -916.5405449135961\n",
      "    val_loss       : -684.4428544008072\n",
      "Train Epoch: 743 [512/17352 (3%)] Loss: -979.938843\n",
      "Train Epoch: 743 [10640/17352 (61%)] Loss: -789.766447\n",
      "Train Epoch: 743 [17263/17352 (99%)] Loss: -871.242188\n",
      "    epoch          : 743\n",
      "    loss           : -937.6201820975874\n",
      "    val_loss       : -683.9854014996578\n",
      "Train Epoch: 744 [512/17352 (3%)] Loss: -811.966736\n",
      "Train Epoch: 744 [10105/17352 (58%)] Loss: -877.306870\n",
      "Train Epoch: 744 [16922/17352 (98%)] Loss: -877.331938\n",
      "    epoch          : 744\n",
      "    loss           : -940.4932647711968\n",
      "    val_loss       : -664.0606291720666\n",
      "Train Epoch: 745 [512/17352 (3%)] Loss: -972.129517\n",
      "Train Epoch: 745 [10709/17352 (62%)] Loss: -1014.019681\n",
      "Train Epoch: 745 [17108/17352 (99%)] Loss: -871.959314\n",
      "    epoch          : 745\n",
      "    loss           : -925.7946802807503\n",
      "    val_loss       : -655.4282695021574\n",
      "Train Epoch: 746 [512/17352 (3%)] Loss: -976.180054\n",
      "Train Epoch: 746 [10281/17352 (59%)] Loss: -854.623813\n",
      "Train Epoch: 746 [17049/17352 (98%)] Loss: -974.982449\n",
      "    epoch          : 746\n",
      "    loss           : -938.808839179343\n",
      "    val_loss       : -689.1609532450186\n",
      "Train Epoch: 747 [512/17352 (3%)] Loss: -991.218872\n",
      "Train Epoch: 747 [10034/17352 (58%)] Loss: -836.027496\n",
      "Train Epoch: 747 [16988/17352 (98%)] Loss: -1070.831290\n",
      "    epoch          : 747\n",
      "    loss           : -950.4291891745759\n",
      "    val_loss       : -687.4102279250181\n",
      "Train Epoch: 748 [512/17352 (3%)] Loss: -1010.003052\n",
      "Train Epoch: 748 [10803/17352 (62%)] Loss: -1029.827927\n",
      "Train Epoch: 748 [16992/17352 (98%)] Loss: -934.649983\n",
      "    epoch          : 748\n",
      "    loss           : -934.8774569660294\n",
      "    val_loss       : -648.278305982633\n",
      "Train Epoch: 749 [512/17352 (3%)] Loss: -930.750854\n",
      "Train Epoch: 749 [10234/17352 (59%)] Loss: -920.829230\n",
      "Train Epoch: 749 [17143/17352 (99%)] Loss: -1000.786168\n",
      "    epoch          : 749\n",
      "    loss           : -924.1312224696811\n",
      "    val_loss       : -618.6167410450342\n",
      "Train Epoch: 750 [512/17352 (3%)] Loss: -963.902344\n",
      "Train Epoch: 750 [10315/17352 (59%)] Loss: -969.593037\n",
      "Train Epoch: 750 [16883/17352 (97%)] Loss: -620.764046\n",
      "    epoch          : 750\n",
      "    loss           : -861.9265455946563\n",
      "    val_loss       : -642.9600286605206\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch750.pth ...\n",
      "Train Epoch: 751 [512/17352 (3%)] Loss: -942.418823\n",
      "Train Epoch: 751 [10235/17352 (59%)] Loss: -946.487301\n",
      "Train Epoch: 751 [16878/17352 (97%)] Loss: -699.606061\n",
      "    epoch          : 751\n",
      "    loss           : -881.0313552227614\n",
      "    val_loss       : -660.5807997278738\n",
      "Train Epoch: 752 [512/17352 (3%)] Loss: -959.801575\n",
      "Train Epoch: 752 [10259/17352 (59%)] Loss: -959.311047\n",
      "Train Epoch: 752 [17124/17352 (99%)] Loss: -952.048750\n",
      "    epoch          : 752\n",
      "    loss           : -893.4260816421329\n",
      "    val_loss       : -562.8449583460348\n",
      "Train Epoch: 753 [512/17352 (3%)] Loss: -855.590515\n",
      "Train Epoch: 753 [10045/17352 (58%)] Loss: -827.713740\n",
      "Train Epoch: 753 [17064/17352 (98%)] Loss: -725.148438\n",
      "    epoch          : 753\n",
      "    loss           : -827.6114867839383\n",
      "    val_loss       : -508.41155763813083\n",
      "Train Epoch: 754 [512/17352 (3%)] Loss: -854.836975\n",
      "Train Epoch: 754 [10683/17352 (62%)] Loss: -1017.145291\n",
      "Train Epoch: 754 [17335/17352 (100%)] Loss: -696.573041\n",
      "    epoch          : 754\n",
      "    loss           : -869.0773457935487\n",
      "    val_loss       : -597.2554828085279\n",
      "Train Epoch: 755 [512/17352 (3%)] Loss: -852.727783\n",
      "Train Epoch: 755 [10691/17352 (62%)] Loss: -616.266906\n",
      "Train Epoch: 755 [17335/17352 (100%)] Loss: -759.158623\n",
      "    epoch          : 755\n",
      "    loss           : -846.9453718206048\n",
      "    val_loss       : -558.9428031664921\n",
      "Train Epoch: 756 [512/17352 (3%)] Loss: -859.149048\n",
      "Train Epoch: 756 [10451/17352 (60%)] Loss: -1002.438961\n",
      "Train Epoch: 756 [17124/17352 (99%)] Loss: -1031.601562\n",
      "    epoch          : 756\n",
      "    loss           : -870.1939599809715\n",
      "    val_loss       : -671.9382269728418\n",
      "Train Epoch: 757 [512/17352 (3%)] Loss: -969.520813\n",
      "Train Epoch: 757 [10494/17352 (60%)] Loss: -980.222859\n",
      "Train Epoch: 757 [17124/17352 (99%)] Loss: -950.523542\n",
      "    epoch          : 757\n",
      "    loss           : -906.1912394855984\n",
      "    val_loss       : -684.0072486164747\n",
      "Train Epoch: 758 [512/17352 (3%)] Loss: -988.674194\n",
      "Train Epoch: 758 [10054/17352 (58%)] Loss: -1019.169575\n",
      "Train Epoch: 758 [17064/17352 (98%)] Loss: -1017.805104\n",
      "    epoch          : 758\n",
      "    loss           : -931.3977455618649\n",
      "    val_loss       : -669.4357795202017\n",
      "Train Epoch: 759 [512/17352 (3%)] Loss: -969.107422\n",
      "Train Epoch: 759 [11018/17352 (63%)] Loss: -997.214517\n",
      "Train Epoch: 759 [16992/17352 (98%)] Loss: -791.924092\n",
      "    epoch          : 759\n",
      "    loss           : -938.1898274511361\n",
      "    val_loss       : -692.1808284377845\n",
      "Train Epoch: 760 [512/17352 (3%)] Loss: -974.410889\n",
      "Train Epoch: 760 [10333/17352 (60%)] Loss: -977.644141\n",
      "Train Epoch: 760 [16957/17352 (98%)] Loss: -897.197618\n",
      "    epoch          : 760\n",
      "    loss           : -947.7972199497169\n",
      "    val_loss       : -705.401301990204\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch760.pth ...\n",
      "Train Epoch: 761 [512/17352 (3%)] Loss: -992.690918\n",
      "Train Epoch: 761 [10523/17352 (61%)] Loss: -1086.840603\n",
      "Train Epoch: 761 [16883/17352 (97%)] Loss: -930.066291\n",
      "    epoch          : 761\n",
      "    loss           : -938.9452142557053\n",
      "    val_loss       : -689.6180257978336\n",
      "Train Epoch: 762 [512/17352 (3%)] Loss: -969.533386\n",
      "Train Epoch: 762 [10451/17352 (60%)] Loss: -828.992014\n",
      "Train Epoch: 762 [16957/17352 (98%)] Loss: -968.085828\n",
      "    epoch          : 762\n",
      "    loss           : -906.4810723888934\n",
      "    val_loss       : -653.7948029044628\n",
      "Train Epoch: 763 [512/17352 (3%)] Loss: -918.426697\n",
      "Train Epoch: 763 [10619/17352 (61%)] Loss: -867.709039\n",
      "Train Epoch: 763 [16882/17352 (97%)] Loss: -1020.180854\n",
      "    epoch          : 763\n",
      "    loss           : -913.1602162053157\n",
      "    val_loss       : -675.576237974555\n",
      "Train Epoch: 764 [512/17352 (3%)] Loss: -798.489685\n",
      "Train Epoch: 764 [9939/17352 (57%)] Loss: -1083.037760\n",
      "Train Epoch: 764 [16957/17352 (98%)] Loss: -898.593494\n",
      "    epoch          : 764\n",
      "    loss           : -944.9946884848324\n",
      "    val_loss       : -682.1185785624035\n",
      "Train Epoch: 765 [512/17352 (3%)] Loss: -995.858459\n",
      "Train Epoch: 765 [9954/17352 (57%)] Loss: -919.418888\n",
      "Train Epoch: 765 [16939/17352 (98%)] Loss: -865.791233\n",
      "    epoch          : 765\n",
      "    loss           : -940.6705879020692\n",
      "    val_loss       : -693.4382918312319\n",
      "Train Epoch: 766 [512/17352 (3%)] Loss: -952.542358\n",
      "Train Epoch: 766 [10584/17352 (61%)] Loss: -814.383448\n",
      "Train Epoch: 766 [17090/17352 (98%)] Loss: -928.708079\n",
      "    epoch          : 766\n",
      "    loss           : -863.8029768544288\n",
      "    val_loss       : -634.5165702426877\n",
      "Train Epoch: 767 [512/17352 (3%)] Loss: -889.772705\n",
      "Train Epoch: 767 [10438/17352 (60%)] Loss: -927.553722\n",
      "Train Epoch: 767 [17277/17352 (100%)] Loss: -841.101461\n",
      "    epoch          : 767\n",
      "    loss           : -898.3871693147951\n",
      "    val_loss       : -639.2924238560684\n",
      "Train Epoch: 768 [512/17352 (3%)] Loss: -916.004517\n",
      "Train Epoch: 768 [10452/17352 (60%)] Loss: -1011.237104\n",
      "Train Epoch: 768 [16882/17352 (97%)] Loss: -730.084049\n",
      "    epoch          : 768\n",
      "    loss           : -914.7146737846139\n",
      "    val_loss       : -540.0029936645832\n",
      "Train Epoch: 769 [512/17352 (3%)] Loss: -808.132629\n",
      "Train Epoch: 769 [9955/17352 (57%)] Loss: -710.750622\n",
      "Train Epoch: 769 [17101/17352 (99%)] Loss: 1076.540313\n",
      "    epoch          : 769\n",
      "    loss           : -159.5884117762526\n",
      "    val_loss       : 1212.4920558761878\n",
      "Train Epoch: 770 [512/17352 (3%)] Loss: 767.617371\n",
      "Train Epoch: 770 [9885/17352 (57%)] Loss: -108.049881\n",
      "Train Epoch: 770 [17106/17352 (99%)] Loss: -281.858939\n",
      "    epoch          : 770\n",
      "    loss           : 265.1696016432132\n",
      "    val_loss       : 455.96755898044086\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch770.pth ...\n",
      "Train Epoch: 771 [512/17352 (3%)] Loss: 212.153870\n",
      "Train Epoch: 771 [10791/17352 (62%)] Loss: -638.200557\n",
      "Train Epoch: 771 [16922/17352 (98%)] Loss: -830.295558\n",
      "    epoch          : 771\n",
      "    loss           : -458.54048946495436\n",
      "    val_loss       : -507.5558524709123\n",
      "Train Epoch: 772 [512/17352 (3%)] Loss: -753.496948\n",
      "Train Epoch: 772 [10726/17352 (62%)] Loss: -796.480382\n",
      "Train Epoch: 772 [17124/17352 (99%)] Loss: -603.752355\n",
      "    epoch          : 772\n",
      "    loss           : -774.1411900770512\n",
      "    val_loss       : -564.4044657408031\n",
      "Train Epoch: 773 [512/17352 (3%)] Loss: -835.892883\n",
      "Train Epoch: 773 [10474/17352 (60%)] Loss: -942.152315\n",
      "Train Epoch: 773 [17106/17352 (99%)] Loss: -860.577166\n",
      "    epoch          : 773\n",
      "    loss           : -849.7038145956689\n",
      "    val_loss       : -685.2667056951392\n",
      "Train Epoch: 774 [512/17352 (3%)] Loss: -947.405762\n",
      "Train Epoch: 774 [10527/17352 (61%)] Loss: -897.692023\n",
      "Train Epoch: 774 [17253/17352 (99%)] Loss: -965.686192\n",
      "    epoch          : 774\n",
      "    loss           : -912.0100645110703\n",
      "    val_loss       : -722.0921514357175\n",
      "Train Epoch: 775 [512/17352 (3%)] Loss: -964.951721\n",
      "Train Epoch: 775 [10617/17352 (61%)] Loss: -866.010944\n",
      "Train Epoch: 775 [17124/17352 (99%)] Loss: -1017.759256\n",
      "    epoch          : 775\n",
      "    loss           : -924.3430739918061\n",
      "    val_loss       : -715.7379855033832\n",
      "Train Epoch: 776 [512/17352 (3%)] Loss: -971.889160\n",
      "Train Epoch: 776 [10894/17352 (63%)] Loss: -1044.638242\n",
      "Train Epoch: 776 [17277/17352 (100%)] Loss: -941.771149\n",
      "    epoch          : 776\n",
      "    loss           : -925.7315730762682\n",
      "    val_loss       : -689.0905752793827\n",
      "Train Epoch: 777 [512/17352 (3%)] Loss: -958.915649\n",
      "Train Epoch: 777 [10002/17352 (58%)] Loss: -1016.994029\n",
      "Train Epoch: 777 [16934/17352 (98%)] Loss: -980.450557\n",
      "    epoch          : 777\n",
      "    loss           : -926.2115269012137\n",
      "    val_loss       : -712.0320767229985\n",
      "Train Epoch: 778 [512/17352 (3%)] Loss: -981.571045\n",
      "Train Epoch: 778 [10747/17352 (62%)] Loss: -865.178865\n",
      "Train Epoch: 778 [16957/17352 (98%)] Loss: -979.393944\n",
      "    epoch          : 778\n",
      "    loss           : -939.4314948230655\n",
      "    val_loss       : -723.8437951975734\n",
      "Train Epoch: 779 [512/17352 (3%)] Loss: -992.185486\n",
      "Train Epoch: 779 [9871/17352 (57%)] Loss: -903.932117\n",
      "Train Epoch: 779 [17153/17352 (99%)] Loss: -1057.960621\n",
      "    epoch          : 779\n",
      "    loss           : -948.8731975699418\n",
      "    val_loss       : -720.0064046478957\n",
      "Train Epoch: 780 [512/17352 (3%)] Loss: -984.648438\n",
      "Train Epoch: 780 [9889/17352 (57%)] Loss: -1063.202331\n",
      "Train Epoch: 780 [16988/17352 (98%)] Loss: -1079.489149\n",
      "    epoch          : 780\n",
      "    loss           : -951.9517099905405\n",
      "    val_loss       : -710.0187791647554\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch780.pth ...\n",
      "Train Epoch: 781 [512/17352 (3%)] Loss: -980.363281\n",
      "Train Epoch: 781 [10369/17352 (60%)] Loss: -1006.988458\n",
      "Train Epoch: 781 [17016/17352 (98%)] Loss: -1039.488766\n",
      "    epoch          : 781\n",
      "    loss           : -952.5385299424123\n",
      "    val_loss       : -723.0674585463004\n",
      "Train Epoch: 782 [512/17352 (3%)] Loss: -994.440613\n",
      "Train Epoch: 782 [10599/17352 (61%)] Loss: -1093.329861\n",
      "Train Epoch: 782 [17049/17352 (98%)] Loss: -978.197838\n",
      "    epoch          : 782\n",
      "    loss           : -959.4869179313507\n",
      "    val_loss       : -712.2846455996674\n",
      "Train Epoch: 783 [512/17352 (3%)] Loss: -1003.224060\n",
      "Train Epoch: 783 [10581/17352 (61%)] Loss: -979.178720\n",
      "Train Epoch: 783 [16883/17352 (97%)] Loss: -891.639931\n",
      "    epoch          : 783\n",
      "    loss           : -961.5127762449472\n",
      "    val_loss       : -725.8190674075933\n",
      "Train Epoch: 784 [512/17352 (3%)] Loss: -833.608826\n",
      "Train Epoch: 784 [10111/17352 (58%)] Loss: -886.971441\n",
      "Train Epoch: 784 [16992/17352 (98%)] Loss: -1053.621677\n",
      "    epoch          : 784\n",
      "    loss           : -962.9558248301103\n",
      "    val_loss       : -714.2377721581394\n",
      "Train Epoch: 785 [512/17352 (3%)] Loss: -994.583313\n",
      "Train Epoch: 785 [9887/17352 (57%)] Loss: -977.572663\n",
      "Train Epoch: 785 [16923/17352 (98%)] Loss: -850.433581\n",
      "    epoch          : 785\n",
      "    loss           : -954.8914861784808\n",
      "    val_loss       : -718.0804606208111\n",
      "Train Epoch: 786 [512/17352 (3%)] Loss: -1001.568726\n",
      "Train Epoch: 786 [9897/17352 (57%)] Loss: -845.709468\n",
      "Train Epoch: 786 [17108/17352 (99%)] Loss: -881.639821\n",
      "    epoch          : 786\n",
      "    loss           : -960.4581214368632\n",
      "    val_loss       : -707.6212458119629\n",
      "Train Epoch: 787 [512/17352 (3%)] Loss: -1004.431152\n",
      "Train Epoch: 787 [9965/17352 (57%)] Loss: -1064.589685\n",
      "Train Epoch: 787 [16883/17352 (97%)] Loss: -1009.881185\n",
      "    epoch          : 787\n",
      "    loss           : -964.6327922496797\n",
      "    val_loss       : -719.6310449807271\n",
      "Train Epoch: 788 [512/17352 (3%)] Loss: -1011.051819\n",
      "Train Epoch: 788 [10394/17352 (60%)] Loss: -918.472830\n",
      "Train Epoch: 788 [17143/17352 (99%)] Loss: -1022.051088\n",
      "    epoch          : 788\n",
      "    loss           : -959.4289830123622\n",
      "    val_loss       : -697.8895625661355\n",
      "Train Epoch: 789 [512/17352 (3%)] Loss: -994.644958\n",
      "Train Epoch: 789 [10847/17352 (63%)] Loss: -1001.175539\n",
      "Train Epoch: 789 [17106/17352 (99%)] Loss: -835.054997\n",
      "    epoch          : 789\n",
      "    loss           : -960.8412309958544\n",
      "    val_loss       : -723.4836290425152\n",
      "Train Epoch: 790 [512/17352 (3%)] Loss: -997.442383\n",
      "Train Epoch: 790 [10321/17352 (59%)] Loss: -961.975361\n",
      "Train Epoch: 790 [17044/17352 (98%)] Loss: -1074.900187\n",
      "    epoch          : 790\n",
      "    loss           : -965.8850941002128\n",
      "    val_loss       : -690.7113014922035\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch790.pth ...\n",
      "Train Epoch: 791 [512/17352 (3%)] Loss: -998.822998\n",
      "Train Epoch: 791 [10347/17352 (60%)] Loss: -1082.054025\n",
      "Train Epoch: 791 [17101/17352 (99%)] Loss: -964.729739\n",
      "    epoch          : 791\n",
      "    loss           : -964.4584473522757\n",
      "    val_loss       : -690.5949623982629\n",
      "Train Epoch: 792 [512/17352 (3%)] Loss: -990.673340\n",
      "Train Epoch: 792 [10410/17352 (60%)] Loss: -908.721168\n",
      "Train Epoch: 792 [17253/17352 (99%)] Loss: -939.144574\n",
      "    epoch          : 792\n",
      "    loss           : -963.3023579178431\n",
      "    val_loss       : -684.1968386422942\n",
      "Train Epoch: 793 [512/17352 (3%)] Loss: -1016.683655\n",
      "Train Epoch: 793 [10721/17352 (62%)] Loss: -911.811012\n",
      "Train Epoch: 793 [16934/17352 (98%)] Loss: -1017.365820\n",
      "    epoch          : 793\n",
      "    loss           : -968.2983592453759\n",
      "    val_loss       : -700.7262670940677\n",
      "Train Epoch: 794 [512/17352 (3%)] Loss: -1017.809082\n",
      "Train Epoch: 794 [10314/17352 (59%)] Loss: -1026.422577\n",
      "Train Epoch: 794 [16887/17352 (97%)] Loss: -899.448255\n",
      "    epoch          : 794\n",
      "    loss           : -971.361962710603\n",
      "    val_loss       : -701.1672751190333\n",
      "Train Epoch: 795 [512/17352 (3%)] Loss: -1022.170837\n",
      "Train Epoch: 795 [9883/17352 (57%)] Loss: -1029.177976\n",
      "Train Epoch: 795 [17106/17352 (99%)] Loss: -890.129769\n",
      "    epoch          : 795\n",
      "    loss           : -972.4324335871116\n",
      "    val_loss       : -702.314703655829\n",
      "Train Epoch: 796 [512/17352 (3%)] Loss: -999.963501\n",
      "Train Epoch: 796 [9896/17352 (57%)] Loss: -1026.952968\n",
      "Train Epoch: 796 [17106/17352 (99%)] Loss: -947.407452\n",
      "    epoch          : 796\n",
      "    loss           : -971.203801184533\n",
      "    val_loss       : -714.4569158371947\n",
      "Train Epoch: 797 [512/17352 (3%)] Loss: -1006.703552\n",
      "Train Epoch: 797 [10358/17352 (60%)] Loss: -851.689150\n",
      "Train Epoch: 797 [16934/17352 (98%)] Loss: -937.715872\n",
      "    epoch          : 797\n",
      "    loss           : -973.3887143902465\n",
      "    val_loss       : -709.8321873730632\n",
      "Train Epoch: 798 [512/17352 (3%)] Loss: -1018.414795\n",
      "Train Epoch: 798 [10360/17352 (60%)] Loss: -938.402001\n",
      "Train Epoch: 798 [17277/17352 (100%)] Loss: -959.424517\n",
      "    epoch          : 798\n",
      "    loss           : -969.9639573873957\n",
      "    val_loss       : -670.3864579606604\n",
      "Train Epoch: 799 [512/17352 (3%)] Loss: -981.143982\n",
      "Train Epoch: 799 [10268/17352 (59%)] Loss: -1004.011236\n",
      "Train Epoch: 799 [17064/17352 (98%)] Loss: -979.001736\n",
      "    epoch          : 799\n",
      "    loss           : -955.6094281723922\n",
      "    val_loss       : -674.6660649717021\n",
      "Train Epoch: 800 [512/17352 (3%)] Loss: -993.144897\n",
      "Train Epoch: 800 [10416/17352 (60%)] Loss: -855.329155\n",
      "Train Epoch: 800 [17090/17352 (98%)] Loss: -892.788555\n",
      "    epoch          : 800\n",
      "    loss           : -945.9717653021199\n",
      "    val_loss       : -653.3884215771536\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch800.pth ...\n",
      "Train Epoch: 801 [512/17352 (3%)] Loss: -937.728760\n",
      "Train Epoch: 801 [10029/17352 (58%)] Loss: -951.432192\n",
      "Train Epoch: 801 [17016/17352 (98%)] Loss: -1052.272786\n",
      "    epoch          : 801\n",
      "    loss           : -935.784887208681\n",
      "    val_loss       : -678.0812437250416\n",
      "Train Epoch: 802 [512/17352 (3%)] Loss: -976.895020\n",
      "Train Epoch: 802 [10557/17352 (61%)] Loss: -981.219823\n",
      "Train Epoch: 802 [16923/17352 (98%)] Loss: -1058.604896\n",
      "    epoch          : 802\n",
      "    loss           : -928.1372406861619\n",
      "    val_loss       : -648.3363827825003\n",
      "Train Epoch: 803 [512/17352 (3%)] Loss: -901.027100\n",
      "Train Epoch: 803 [10409/17352 (60%)] Loss: -1018.302917\n",
      "Train Epoch: 803 [17126/17352 (99%)] Loss: -872.564805\n",
      "    epoch          : 803\n",
      "    loss           : -949.6149242760374\n",
      "    val_loss       : -688.3437138030098\n",
      "Train Epoch: 804 [512/17352 (3%)] Loss: -1011.156738\n",
      "Train Epoch: 804 [10745/17352 (62%)] Loss: -1058.749733\n",
      "Train Epoch: 804 [17143/17352 (99%)] Loss: -914.627434\n",
      "    epoch          : 804\n",
      "    loss           : -935.320808486901\n",
      "    val_loss       : -669.8267652226477\n",
      "Train Epoch: 805 [512/17352 (3%)] Loss: -996.101013\n",
      "Train Epoch: 805 [10515/17352 (61%)] Loss: -1008.838568\n",
      "Train Epoch: 805 [16957/17352 (98%)] Loss: -935.672149\n",
      "    epoch          : 805\n",
      "    loss           : -938.3724638283442\n",
      "    val_loss       : -695.7158559066287\n",
      "Train Epoch: 806 [512/17352 (3%)] Loss: -998.216614\n",
      "Train Epoch: 806 [10264/17352 (59%)] Loss: -1047.656317\n",
      "Train Epoch: 806 [16992/17352 (98%)] Loss: -1009.223698\n",
      "    epoch          : 806\n",
      "    loss           : -949.4925087880976\n",
      "    val_loss       : -649.2595771060206\n",
      "Train Epoch: 807 [512/17352 (3%)] Loss: -972.243896\n",
      "Train Epoch: 807 [10391/17352 (60%)] Loss: -1004.595658\n",
      "Train Epoch: 807 [17277/17352 (100%)] Loss: -828.059715\n",
      "    epoch          : 807\n",
      "    loss           : -967.2258710835814\n",
      "    val_loss       : -700.0504404501489\n",
      "Train Epoch: 808 [512/17352 (3%)] Loss: -1021.950317\n",
      "Train Epoch: 808 [10126/17352 (58%)] Loss: -1076.850864\n",
      "Train Epoch: 808 [16939/17352 (98%)] Loss: -1010.878255\n",
      "    epoch          : 808\n",
      "    loss           : -978.2610018392454\n",
      "    val_loss       : -704.2902561517719\n",
      "Train Epoch: 809 [512/17352 (3%)] Loss: -1023.162659\n",
      "Train Epoch: 809 [10158/17352 (59%)] Loss: -877.458843\n",
      "Train Epoch: 809 [16992/17352 (98%)] Loss: -993.568860\n",
      "    epoch          : 809\n",
      "    loss           : -969.8044735286688\n",
      "    val_loss       : -708.4495716213889\n",
      "Train Epoch: 810 [512/17352 (3%)] Loss: -1020.731567\n",
      "Train Epoch: 810 [10334/17352 (60%)] Loss: -975.139734\n",
      "Train Epoch: 810 [16988/17352 (98%)] Loss: -764.885167\n",
      "    epoch          : 810\n",
      "    loss           : -962.9422931233121\n",
      "    val_loss       : -666.2678886453497\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch810.pth ...\n",
      "Train Epoch: 811 [512/17352 (3%)] Loss: -994.163269\n",
      "Train Epoch: 811 [10589/17352 (61%)] Loss: -880.529525\n",
      "Train Epoch: 811 [16988/17352 (98%)] Loss: -1092.688477\n",
      "    epoch          : 811\n",
      "    loss           : -948.7410732172292\n",
      "    val_loss       : -645.1835267979475\n",
      "Train Epoch: 812 [512/17352 (3%)] Loss: -994.362793\n",
      "Train Epoch: 812 [10591/17352 (61%)] Loss: -1082.691184\n",
      "Train Epoch: 812 [16939/17352 (98%)] Loss: -897.564732\n",
      "    epoch          : 812\n",
      "    loss           : -968.8752808420229\n",
      "    val_loss       : -699.7362550220568\n",
      "Train Epoch: 813 [512/17352 (3%)] Loss: -1027.479248\n",
      "Train Epoch: 813 [10103/17352 (58%)] Loss: -1029.013508\n",
      "Train Epoch: 813 [16878/17352 (97%)] Loss: -998.426563\n",
      "    epoch          : 813\n",
      "    loss           : -968.4341354012723\n",
      "    val_loss       : -682.1039751652152\n",
      "Train Epoch: 814 [512/17352 (3%)] Loss: -1008.048340\n",
      "Train Epoch: 814 [10783/17352 (62%)] Loss: -1053.340498\n",
      "Train Epoch: 814 [17016/17352 (98%)] Loss: -879.558114\n",
      "    epoch          : 814\n",
      "    loss           : -964.8531587030286\n",
      "    val_loss       : -703.0377134929162\n",
      "Train Epoch: 815 [512/17352 (3%)] Loss: -1017.986694\n",
      "Train Epoch: 815 [10573/17352 (61%)] Loss: -839.318983\n",
      "Train Epoch: 815 [16872/17352 (97%)] Loss: -840.360336\n",
      "    epoch          : 815\n",
      "    loss           : -932.2710444288238\n",
      "    val_loss       : -656.2807393615792\n",
      "Train Epoch: 816 [512/17352 (3%)] Loss: -989.917725\n",
      "Train Epoch: 816 [10074/17352 (58%)] Loss: -857.819627\n",
      "Train Epoch: 816 [16988/17352 (98%)] Loss: -942.767555\n",
      "    epoch          : 816\n",
      "    loss           : -944.7115398886604\n",
      "    val_loss       : -672.4013211194186\n",
      "Train Epoch: 817 [512/17352 (3%)] Loss: -1006.311279\n",
      "Train Epoch: 817 [10248/17352 (59%)] Loss: -942.885338\n",
      "Train Epoch: 817 [17044/17352 (98%)] Loss: -878.947362\n",
      "    epoch          : 817\n",
      "    loss           : -926.7304221578831\n",
      "    val_loss       : -643.015699029716\n",
      "Train Epoch: 818 [512/17352 (3%)] Loss: -958.606201\n",
      "Train Epoch: 818 [10993/17352 (63%)] Loss: -1018.123334\n",
      "Train Epoch: 818 [17277/17352 (100%)] Loss: -1023.971941\n",
      "    epoch          : 818\n",
      "    loss           : -923.042510424945\n",
      "    val_loss       : -596.6344947661805\n",
      "Train Epoch: 819 [512/17352 (3%)] Loss: -933.396484\n",
      "Train Epoch: 819 [10471/17352 (60%)] Loss: -845.581583\n",
      "Train Epoch: 819 [16958/17352 (98%)] Loss: -830.017818\n",
      "    epoch          : 819\n",
      "    loss           : -907.3588939036223\n",
      "    val_loss       : -653.1475322658919\n",
      "Train Epoch: 820 [512/17352 (3%)] Loss: -968.812378\n",
      "Train Epoch: 820 [10020/17352 (58%)] Loss: -894.987807\n",
      "Train Epoch: 820 [16922/17352 (98%)] Loss: -891.499572\n",
      "    epoch          : 820\n",
      "    loss           : -915.282952978903\n",
      "    val_loss       : -646.3601682569937\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch820.pth ...\n",
      "Train Epoch: 821 [512/17352 (3%)] Loss: -943.562561\n",
      "Train Epoch: 821 [10744/17352 (62%)] Loss: -978.857955\n",
      "Train Epoch: 821 [16992/17352 (98%)] Loss: -942.178934\n",
      "    epoch          : 821\n",
      "    loss           : -965.244701389639\n",
      "    val_loss       : -668.8732098112323\n",
      "Train Epoch: 822 [512/17352 (3%)] Loss: -1020.733765\n",
      "Train Epoch: 822 [9774/17352 (56%)] Loss: -1011.177999\n",
      "Train Epoch: 822 [17126/17352 (99%)] Loss: -1038.918825\n",
      "    epoch          : 822\n",
      "    loss           : -972.9716115367312\n",
      "    val_loss       : -703.7524732364824\n",
      "Train Epoch: 823 [512/17352 (3%)] Loss: -1027.715576\n",
      "Train Epoch: 823 [10009/17352 (58%)] Loss: -923.831839\n",
      "Train Epoch: 823 [17124/17352 (99%)] Loss: -1092.860245\n",
      "    epoch          : 823\n",
      "    loss           : -974.7628936681875\n",
      "    val_loss       : -672.2348262993096\n",
      "Train Epoch: 824 [512/17352 (3%)] Loss: -994.775635\n",
      "Train Epoch: 824 [10251/17352 (59%)] Loss: -874.986917\n",
      "Train Epoch: 824 [16958/17352 (98%)] Loss: -1062.211509\n",
      "    epoch          : 824\n",
      "    loss           : -924.015294854758\n",
      "    val_loss       : -659.9266895278407\n",
      "Train Epoch: 825 [512/17352 (3%)] Loss: -957.705322\n",
      "Train Epoch: 825 [10605/17352 (61%)] Loss: -1100.440864\n",
      "Train Epoch: 825 [17253/17352 (99%)] Loss: -867.965116\n",
      "    epoch          : 825\n",
      "    loss           : -939.4456645165103\n",
      "    val_loss       : -591.2142206535075\n",
      "Train Epoch: 826 [512/17352 (3%)] Loss: -763.521545\n",
      "Train Epoch: 826 [9832/17352 (57%)] Loss: -841.177511\n",
      "Train Epoch: 826 [17335/17352 (100%)] Loss: -956.035514\n",
      "    epoch          : 826\n",
      "    loss           : -807.0540617751597\n",
      "    val_loss       : -372.80722764860155\n",
      "Train Epoch: 827 [512/17352 (3%)] Loss: -425.875305\n",
      "Train Epoch: 827 [9834/17352 (57%)] Loss: -914.524564\n",
      "Train Epoch: 827 [17049/17352 (98%)] Loss: -770.620518\n",
      "    epoch          : 827\n",
      "    loss           : -767.5908750073771\n",
      "    val_loss       : -530.5261484976548\n",
      "Train Epoch: 828 [512/17352 (3%)] Loss: -745.149414\n",
      "Train Epoch: 828 [10278/17352 (59%)] Loss: -852.742660\n",
      "Train Epoch: 828 [17106/17352 (99%)] Loss: -955.504122\n",
      "    epoch          : 828\n",
      "    loss           : -845.6208399759583\n",
      "    val_loss       : -612.7039842555992\n",
      "Train Epoch: 829 [512/17352 (3%)] Loss: -903.862183\n",
      "Train Epoch: 829 [10158/17352 (59%)] Loss: -1008.284235\n",
      "Train Epoch: 829 [17153/17352 (99%)] Loss: -1077.944163\n",
      "    epoch          : 829\n",
      "    loss           : -940.539069759546\n",
      "    val_loss       : -675.9987410070113\n",
      "Train Epoch: 830 [512/17352 (3%)] Loss: -997.285889\n",
      "Train Epoch: 830 [10573/17352 (61%)] Loss: -912.465164\n",
      "Train Epoch: 830 [17106/17352 (99%)] Loss: -833.038905\n",
      "    epoch          : 830\n",
      "    loss           : -936.4163626549117\n",
      "    val_loss       : -660.8138959845357\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch830.pth ...\n",
      "Train Epoch: 831 [512/17352 (3%)] Loss: -955.630920\n",
      "Train Epoch: 831 [10551/17352 (61%)] Loss: -970.718314\n",
      "Train Epoch: 831 [17101/17352 (99%)] Loss: -937.585104\n",
      "    epoch          : 831\n",
      "    loss           : -926.9577287519066\n",
      "    val_loss       : -685.2769616872665\n",
      "Train Epoch: 832 [512/17352 (3%)] Loss: -1021.344666\n",
      "Train Epoch: 832 [10141/17352 (58%)] Loss: -1026.191609\n",
      "Train Epoch: 832 [17263/17352 (99%)] Loss: -796.212702\n",
      "    epoch          : 832\n",
      "    loss           : -963.3883164678259\n",
      "    val_loss       : -685.9638595905112\n",
      "Train Epoch: 833 [512/17352 (3%)] Loss: -825.589417\n",
      "Train Epoch: 833 [10169/17352 (59%)] Loss: -1000.526562\n",
      "Train Epoch: 833 [16923/17352 (98%)] Loss: -950.679688\n",
      "    epoch          : 833\n",
      "    loss           : -975.9357901452896\n",
      "    val_loss       : -706.5582890606311\n",
      "Train Epoch: 834 [512/17352 (3%)] Loss: -1023.193237\n",
      "Train Epoch: 834 [9939/17352 (57%)] Loss: -1034.804081\n",
      "Train Epoch: 834 [17016/17352 (98%)] Loss: -923.836458\n",
      "    epoch          : 834\n",
      "    loss           : -963.8486607105118\n",
      "    val_loss       : -676.4939691234301\n",
      "Train Epoch: 835 [512/17352 (3%)] Loss: -986.718262\n",
      "Train Epoch: 835 [10242/17352 (59%)] Loss: -765.878813\n",
      "Train Epoch: 835 [16883/17352 (97%)] Loss: -919.212259\n",
      "    epoch          : 835\n",
      "    loss           : -944.8372632689853\n",
      "    val_loss       : -688.3445122360074\n",
      "Train Epoch: 836 [512/17352 (3%)] Loss: -1036.769531\n",
      "Train Epoch: 836 [10230/17352 (59%)] Loss: -932.597208\n",
      "Train Epoch: 836 [17106/17352 (99%)] Loss: -1036.347925\n",
      "    epoch          : 836\n",
      "    loss           : -974.4887972569331\n",
      "    val_loss       : -695.7223224065976\n",
      "Train Epoch: 837 [512/17352 (3%)] Loss: -1004.179199\n",
      "Train Epoch: 837 [10503/17352 (61%)] Loss: -1075.379664\n",
      "Train Epoch: 837 [17253/17352 (99%)] Loss: -1040.918023\n",
      "    epoch          : 837\n",
      "    loss           : -973.1279182248661\n",
      "    val_loss       : -691.9366873382716\n",
      "Train Epoch: 838 [512/17352 (3%)] Loss: -1032.159302\n",
      "Train Epoch: 838 [9999/17352 (58%)] Loss: -979.002734\n",
      "Train Epoch: 838 [17263/17352 (99%)] Loss: -1081.546975\n",
      "    epoch          : 838\n",
      "    loss           : -967.5295963667568\n",
      "    val_loss       : -657.3024705054136\n",
      "Train Epoch: 839 [512/17352 (3%)] Loss: -989.350830\n",
      "Train Epoch: 839 [10150/17352 (58%)] Loss: -828.157281\n",
      "Train Epoch: 839 [16882/17352 (97%)] Loss: -815.385618\n",
      "    epoch          : 839\n",
      "    loss           : -972.8342700881747\n",
      "    val_loss       : -692.5427424004664\n",
      "Train Epoch: 840 [512/17352 (3%)] Loss: -1021.746338\n",
      "Train Epoch: 840 [10524/17352 (61%)] Loss: -654.810108\n",
      "Train Epoch: 840 [17090/17352 (98%)] Loss: -1035.608433\n",
      "    epoch          : 840\n",
      "    loss           : -945.5742908128798\n",
      "    val_loss       : -676.360837326097\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch840.pth ...\n",
      "Train Epoch: 841 [512/17352 (3%)] Loss: -1014.206970\n",
      "Train Epoch: 841 [9997/17352 (58%)] Loss: -986.416746\n",
      "Train Epoch: 841 [17108/17352 (99%)] Loss: -1047.152433\n",
      "    epoch          : 841\n",
      "    loss           : -972.9016537433628\n",
      "    val_loss       : -714.8346377903832\n",
      "Train Epoch: 842 [512/17352 (3%)] Loss: -1022.893494\n",
      "Train Epoch: 842 [10370/17352 (60%)] Loss: -885.732966\n",
      "Train Epoch: 842 [17064/17352 (98%)] Loss: -967.105855\n",
      "    epoch          : 842\n",
      "    loss           : -971.3572259914956\n",
      "    val_loss       : -642.3067350976503\n",
      "Train Epoch: 843 [512/17352 (3%)] Loss: -998.757690\n",
      "Train Epoch: 843 [10451/17352 (60%)] Loss: -1078.592691\n",
      "Train Epoch: 843 [16988/17352 (98%)] Loss: -1030.125785\n",
      "    epoch          : 843\n",
      "    loss           : -962.6665592039095\n",
      "    val_loss       : -699.6146353705974\n",
      "Train Epoch: 844 [512/17352 (3%)] Loss: -1033.148315\n",
      "Train Epoch: 844 [10105/17352 (58%)] Loss: -808.931071\n",
      "Train Epoch: 844 [16883/17352 (97%)] Loss: -862.623033\n",
      "    epoch          : 844\n",
      "    loss           : -971.9281641600053\n",
      "    val_loss       : -696.7458608820688\n",
      "Train Epoch: 845 [512/17352 (3%)] Loss: -1025.931885\n",
      "Train Epoch: 845 [10492/17352 (60%)] Loss: -958.330710\n",
      "Train Epoch: 845 [17016/17352 (98%)] Loss: -1001.148359\n",
      "    epoch          : 845\n",
      "    loss           : -976.8494252365291\n",
      "    val_loss       : -694.462284773826\n",
      "Train Epoch: 846 [512/17352 (3%)] Loss: -826.671753\n",
      "Train Epoch: 846 [10543/17352 (61%)] Loss: -1095.523628\n",
      "Train Epoch: 846 [16934/17352 (98%)] Loss: -1031.626662\n",
      "    epoch          : 846\n",
      "    loss           : -974.4159490920882\n",
      "    val_loss       : -675.2303020336931\n",
      "Train Epoch: 847 [512/17352 (3%)] Loss: -1009.562683\n",
      "Train Epoch: 847 [10699/17352 (62%)] Loss: -1094.451801\n",
      "Train Epoch: 847 [16988/17352 (98%)] Loss: -872.658945\n",
      "    epoch          : 847\n",
      "    loss           : -980.8165658355927\n",
      "    val_loss       : -703.0768903890256\n",
      "Train Epoch: 848 [512/17352 (3%)] Loss: -1031.859009\n",
      "Train Epoch: 848 [10723/17352 (62%)] Loss: -1105.689232\n",
      "Train Epoch: 848 [17049/17352 (98%)] Loss: -991.771035\n",
      "    epoch          : 848\n",
      "    loss           : -980.7807665751376\n",
      "    val_loss       : -505.5371678630882\n",
      "Train Epoch: 849 [512/17352 (3%)] Loss: -861.086426\n",
      "Train Epoch: 849 [10090/17352 (58%)] Loss: -643.744237\n",
      "Train Epoch: 849 [17016/17352 (98%)] Loss: -626.340124\n",
      "    epoch          : 849\n",
      "    loss           : -779.1059029253767\n",
      "    val_loss       : -543.3052259722019\n",
      "Train Epoch: 850 [512/17352 (3%)] Loss: -871.881287\n",
      "Train Epoch: 850 [9980/17352 (58%)] Loss: -754.912555\n",
      "Train Epoch: 850 [16878/17352 (97%)] Loss: -1043.447866\n",
      "    epoch          : 850\n",
      "    loss           : -835.0684698321564\n",
      "    val_loss       : -618.3262788098466\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch850.pth ...\n",
      "Train Epoch: 851 [512/17352 (3%)] Loss: -955.520508\n",
      "Train Epoch: 851 [10057/17352 (58%)] Loss: -822.547643\n",
      "Train Epoch: 851 [16878/17352 (97%)] Loss: -1020.433772\n",
      "    epoch          : 851\n",
      "    loss           : -926.320192293815\n",
      "    val_loss       : -659.2428702672717\n",
      "Train Epoch: 852 [512/17352 (3%)] Loss: -966.172058\n",
      "Train Epoch: 852 [9985/17352 (58%)] Loss: -1001.413764\n",
      "Train Epoch: 852 [16882/17352 (97%)] Loss: -1010.840295\n",
      "    epoch          : 852\n",
      "    loss           : -961.3185387585836\n",
      "    val_loss       : -670.0315479392204\n",
      "Train Epoch: 853 [512/17352 (3%)] Loss: -1002.639526\n",
      "Train Epoch: 853 [9784/17352 (56%)] Loss: -440.636684\n",
      "Train Epoch: 853 [16923/17352 (98%)] Loss: -998.510443\n",
      "    epoch          : 853\n",
      "    loss           : -891.9674374724252\n",
      "    val_loss       : -697.1076392209663\n",
      "Train Epoch: 854 [512/17352 (3%)] Loss: -1012.256104\n",
      "Train Epoch: 854 [10221/17352 (59%)] Loss: -1078.932703\n",
      "Train Epoch: 854 [17143/17352 (99%)] Loss: -928.041337\n",
      "    epoch          : 854\n",
      "    loss           : -964.5993528824457\n",
      "    val_loss       : -667.2359924683566\n",
      "Train Epoch: 855 [512/17352 (3%)] Loss: -1002.412109\n",
      "Train Epoch: 855 [9896/17352 (57%)] Loss: -1025.204649\n",
      "Train Epoch: 855 [17253/17352 (99%)] Loss: -1038.370796\n",
      "    epoch          : 855\n",
      "    loss           : -962.1212563956286\n",
      "    val_loss       : -636.4086747066028\n",
      "Train Epoch: 856 [512/17352 (3%)] Loss: -967.301941\n",
      "Train Epoch: 856 [10273/17352 (59%)] Loss: -1035.994665\n",
      "Train Epoch: 856 [16923/17352 (98%)] Loss: -1035.122432\n",
      "    epoch          : 856\n",
      "    loss           : -945.5446318986949\n",
      "    val_loss       : -690.4465147155603\n",
      "Train Epoch: 857 [512/17352 (3%)] Loss: -979.160767\n",
      "Train Epoch: 857 [10400/17352 (60%)] Loss: -851.002177\n",
      "Train Epoch: 857 [17124/17352 (99%)] Loss: -805.849432\n",
      "    epoch          : 857\n",
      "    loss           : -961.9601948714817\n",
      "    val_loss       : -674.9172601704863\n",
      "Train Epoch: 858 [512/17352 (3%)] Loss: -992.433594\n",
      "Train Epoch: 858 [10674/17352 (62%)] Loss: -870.336684\n",
      "Train Epoch: 858 [16887/17352 (97%)] Loss: -899.641148\n",
      "    epoch          : 858\n",
      "    loss           : -975.3546035490532\n",
      "    val_loss       : -685.692352557176\n",
      "Train Epoch: 859 [512/17352 (3%)] Loss: -1031.390625\n",
      "Train Epoch: 859 [10036/17352 (58%)] Loss: -944.302269\n",
      "Train Epoch: 859 [16957/17352 (98%)] Loss: -1074.286458\n",
      "    epoch          : 859\n",
      "    loss           : -980.2253038178375\n",
      "    val_loss       : -692.7686104389796\n",
      "Train Epoch: 860 [512/17352 (3%)] Loss: -1020.212219\n",
      "Train Epoch: 860 [9927/17352 (57%)] Loss: -877.875449\n",
      "Train Epoch: 860 [17049/17352 (98%)] Loss: -1078.893829\n",
      "    epoch          : 860\n",
      "    loss           : -970.2988620775667\n",
      "    val_loss       : -686.118848145205\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch860.pth ...\n",
      "Train Epoch: 861 [512/17352 (3%)] Loss: -1016.196899\n",
      "Train Epoch: 861 [10041/17352 (58%)] Loss: -990.928346\n",
      "Train Epoch: 861 [16883/17352 (97%)] Loss: -1133.090278\n",
      "    epoch          : 861\n",
      "    loss           : -971.5687319640701\n",
      "    val_loss       : -706.5504097917742\n",
      "Train Epoch: 862 [512/17352 (3%)] Loss: -1043.120728\n",
      "Train Epoch: 862 [10475/17352 (60%)] Loss: -961.079413\n",
      "Train Epoch: 862 [17277/17352 (100%)] Loss: -820.778965\n",
      "    epoch          : 862\n",
      "    loss           : -981.2890343884982\n",
      "    val_loss       : -639.4172217950885\n",
      "Train Epoch: 863 [512/17352 (3%)] Loss: -954.115784\n",
      "Train Epoch: 863 [10189/17352 (59%)] Loss: -1070.087168\n",
      "Train Epoch: 863 [17253/17352 (99%)] Loss: -854.041885\n",
      "    epoch          : 863\n",
      "    loss           : -964.2320748061347\n",
      "    val_loss       : -628.6794014829795\n",
      "Train Epoch: 864 [512/17352 (3%)] Loss: -965.674683\n",
      "Train Epoch: 864 [10609/17352 (61%)] Loss: -1010.380393\n",
      "Train Epoch: 864 [16872/17352 (97%)] Loss: -810.807118\n",
      "    epoch          : 864\n",
      "    loss           : -871.3623119115424\n",
      "    val_loss       : -624.423268406864\n",
      "Train Epoch: 865 [512/17352 (3%)] Loss: -921.578369\n",
      "Train Epoch: 865 [10712/17352 (62%)] Loss: -975.557312\n",
      "Train Epoch: 865 [16934/17352 (98%)] Loss: -936.773695\n",
      "    epoch          : 865\n",
      "    loss           : -874.7069042536203\n",
      "    val_loss       : -669.8750623564174\n",
      "Train Epoch: 866 [512/17352 (3%)] Loss: -1013.294800\n",
      "Train Epoch: 866 [9609/17352 (55%)] Loss: -1009.352007\n",
      "Train Epoch: 866 [16957/17352 (98%)] Loss: -1023.238941\n",
      "    epoch          : 866\n",
      "    loss           : -945.2632419486125\n",
      "    val_loss       : -685.7931642779522\n",
      "Train Epoch: 867 [512/17352 (3%)] Loss: -1014.147949\n",
      "Train Epoch: 867 [11057/17352 (64%)] Loss: -845.250739\n",
      "Train Epoch: 867 [16883/17352 (97%)] Loss: -885.718750\n",
      "    epoch          : 867\n",
      "    loss           : -989.6821899237208\n",
      "    val_loss       : -702.6456195665378\n",
      "Train Epoch: 868 [512/17352 (3%)] Loss: -1038.478394\n",
      "Train Epoch: 868 [10580/17352 (61%)] Loss: -850.749053\n",
      "Train Epoch: 868 [16939/17352 (98%)] Loss: -919.650850\n",
      "    epoch          : 868\n",
      "    loss           : -969.6959208219054\n",
      "    val_loss       : -708.4021735383847\n",
      "Train Epoch: 869 [512/17352 (3%)] Loss: -1035.388550\n",
      "Train Epoch: 869 [10029/17352 (58%)] Loss: -902.036702\n",
      "Train Epoch: 869 [17133/17352 (99%)] Loss: -959.248132\n",
      "    epoch          : 869\n",
      "    loss           : -929.3002729530762\n",
      "    val_loss       : -608.4322377197443\n",
      "Train Epoch: 870 [512/17352 (3%)] Loss: -946.662720\n",
      "Train Epoch: 870 [10274/17352 (59%)] Loss: -983.717886\n",
      "Train Epoch: 870 [16939/17352 (98%)] Loss: -1095.037047\n",
      "    epoch          : 870\n",
      "    loss           : -921.8252813986222\n",
      "    val_loss       : -639.0576317137989\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch870.pth ...\n",
      "Train Epoch: 871 [512/17352 (3%)] Loss: -989.283691\n",
      "Train Epoch: 871 [10399/17352 (60%)] Loss: -966.919020\n",
      "Train Epoch: 871 [16923/17352 (98%)] Loss: -838.785156\n",
      "    epoch          : 871\n",
      "    loss           : -910.0316695520283\n",
      "    val_loss       : -661.1875505462808\n",
      "Train Epoch: 872 [512/17352 (3%)] Loss: -980.422791\n",
      "Train Epoch: 872 [10666/17352 (61%)] Loss: -974.263413\n",
      "Train Epoch: 872 [17124/17352 (99%)] Loss: -1013.702072\n",
      "    epoch          : 872\n",
      "    loss           : -921.6684869453284\n",
      "    val_loss       : -669.9994939501511\n",
      "Train Epoch: 873 [512/17352 (3%)] Loss: -996.709290\n",
      "Train Epoch: 873 [10742/17352 (62%)] Loss: -1092.608511\n",
      "Train Epoch: 873 [17153/17352 (99%)] Loss: -1067.353006\n",
      "    epoch          : 873\n",
      "    loss           : -983.3923782757586\n",
      "    val_loss       : -683.639053687348\n",
      "Train Epoch: 874 [512/17352 (3%)] Loss: -1024.996582\n",
      "Train Epoch: 874 [9844/17352 (57%)] Loss: -952.742740\n",
      "Train Epoch: 874 [16887/17352 (97%)] Loss: -1057.017484\n",
      "    epoch          : 874\n",
      "    loss           : -962.5491512082223\n",
      "    val_loss       : -696.2849444080865\n",
      "Train Epoch: 875 [512/17352 (3%)] Loss: -1027.078613\n",
      "Train Epoch: 875 [10367/17352 (60%)] Loss: -798.338130\n",
      "Train Epoch: 875 [16923/17352 (98%)] Loss: 2230.880967\n",
      "    epoch          : 875\n",
      "    loss           : -121.60538885129436\n",
      "    val_loss       : 968.974817318287\n",
      "Train Epoch: 876 [512/17352 (3%)] Loss: 607.591431\n",
      "Train Epoch: 876 [10528/17352 (61%)] Loss: 1717.085809\n",
      "Train Epoch: 876 [17090/17352 (98%)] Loss: -446.772922\n",
      "    epoch          : 876\n",
      "    loss           : 602.7546246051189\n",
      "    val_loss       : 105.55842041023534\n",
      "Train Epoch: 877 [512/17352 (3%)] Loss: -384.892822\n",
      "Train Epoch: 877 [10348/17352 (60%)] Loss: -517.441919\n",
      "Train Epoch: 877 [17277/17352 (100%)] Loss: -744.737671\n",
      "    epoch          : 877\n",
      "    loss           : -535.0076562150508\n",
      "    val_loss       : -551.5805833197436\n",
      "Train Epoch: 878 [512/17352 (3%)] Loss: -818.826294\n",
      "Train Epoch: 878 [10316/17352 (59%)] Loss: -945.699709\n",
      "Train Epoch: 878 [17153/17352 (99%)] Loss: -815.368456\n",
      "    epoch          : 878\n",
      "    loss           : -852.4572213415242\n",
      "    val_loss       : -680.4208641915343\n",
      "Train Epoch: 879 [512/17352 (3%)] Loss: -958.529907\n",
      "Train Epoch: 879 [9867/17352 (57%)] Loss: -861.455357\n",
      "Train Epoch: 879 [17090/17352 (98%)] Loss: -846.797996\n",
      "    epoch          : 879\n",
      "    loss           : -919.3472738039333\n",
      "    val_loss       : -713.2226846582195\n",
      "Train Epoch: 880 [512/17352 (3%)] Loss: -989.156616\n",
      "Train Epoch: 880 [10114/17352 (58%)] Loss: -845.436453\n",
      "Train Epoch: 880 [17106/17352 (99%)] Loss: -977.556297\n",
      "    epoch          : 880\n",
      "    loss           : -915.6705322144529\n",
      "    val_loss       : -678.1057421741298\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch880.pth ...\n",
      "Train Epoch: 881 [512/17352 (3%)] Loss: -770.587036\n",
      "Train Epoch: 881 [10470/17352 (60%)] Loss: -877.000406\n",
      "Train Epoch: 881 [17143/17352 (99%)] Loss: -800.951681\n",
      "    epoch          : 881\n",
      "    loss           : -945.4336158217311\n",
      "    val_loss       : -719.4534566892578\n",
      "Train Epoch: 882 [512/17352 (3%)] Loss: -761.850586\n",
      "Train Epoch: 882 [10288/17352 (59%)] Loss: -1017.226345\n",
      "Train Epoch: 882 [16923/17352 (98%)] Loss: -999.211687\n",
      "    epoch          : 882\n",
      "    loss           : -957.5558192400559\n",
      "    val_loss       : -712.3605230895444\n",
      "Train Epoch: 883 [512/17352 (3%)] Loss: -1012.838013\n",
      "Train Epoch: 883 [10397/17352 (60%)] Loss: -859.576872\n",
      "Train Epoch: 883 [16872/17352 (97%)] Loss: -926.120692\n",
      "    epoch          : 883\n",
      "    loss           : -963.2695677958667\n",
      "    val_loss       : -723.9313524696192\n",
      "Train Epoch: 884 [512/17352 (3%)] Loss: -1021.672668\n",
      "Train Epoch: 884 [10364/17352 (60%)] Loss: -1015.205793\n",
      "Train Epoch: 884 [16878/17352 (97%)] Loss: -817.938738\n",
      "    epoch          : 884\n",
      "    loss           : -940.9839192609168\n",
      "    val_loss       : -680.0279257338532\n",
      "Train Epoch: 885 [512/17352 (3%)] Loss: -975.736633\n",
      "Train Epoch: 885 [10358/17352 (60%)] Loss: -998.204053\n",
      "Train Epoch: 885 [16882/17352 (97%)] Loss: -906.660074\n",
      "    epoch          : 885\n",
      "    loss           : -960.5555583939473\n",
      "    val_loss       : -720.0966373264755\n",
      "Train Epoch: 886 [512/17352 (3%)] Loss: -1003.648621\n",
      "Train Epoch: 886 [10080/17352 (58%)] Loss: -919.887807\n",
      "Train Epoch: 886 [17044/17352 (98%)] Loss: -978.091089\n",
      "    epoch          : 886\n",
      "    loss           : -973.5198659943983\n",
      "    val_loss       : -732.4215897658436\n",
      "Train Epoch: 887 [512/17352 (3%)] Loss: -1008.665710\n",
      "Train Epoch: 887 [11010/17352 (63%)] Loss: -825.152823\n",
      "Train Epoch: 887 [17143/17352 (99%)] Loss: -954.764763\n",
      "    epoch          : 887\n",
      "    loss           : -972.9227955896807\n",
      "    val_loss       : -728.5193883489818\n",
      "Train Epoch: 888 [512/17352 (3%)] Loss: -1019.612122\n",
      "Train Epoch: 888 [10698/17352 (62%)] Loss: -1021.398828\n",
      "Train Epoch: 888 [17090/17352 (98%)] Loss: -824.661022\n",
      "    epoch          : 888\n",
      "    loss           : -981.9290715226807\n",
      "    val_loss       : -736.3782737761696\n",
      "Train Epoch: 889 [512/17352 (3%)] Loss: -1031.589600\n",
      "Train Epoch: 889 [10050/17352 (58%)] Loss: -1033.392551\n",
      "Train Epoch: 889 [16992/17352 (98%)] Loss: -1079.797074\n",
      "    epoch          : 889\n",
      "    loss           : -984.9942781563061\n",
      "    val_loss       : -723.1760833462615\n",
      "Train Epoch: 890 [512/17352 (3%)] Loss: -1022.414429\n",
      "Train Epoch: 890 [10250/17352 (59%)] Loss: -1013.714695\n",
      "Train Epoch: 890 [16923/17352 (98%)] Loss: -1033.138259\n",
      "    epoch          : 890\n",
      "    loss           : -985.3941576522335\n",
      "    val_loss       : -734.7819273875995\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch890.pth ...\n",
      "Train Epoch: 891 [512/17352 (3%)] Loss: -1036.593018\n",
      "Train Epoch: 891 [10472/17352 (60%)] Loss: -927.216772\n",
      "Train Epoch: 891 [17090/17352 (98%)] Loss: -926.308338\n",
      "    epoch          : 891\n",
      "    loss           : -989.4379280419541\n",
      "    val_loss       : -731.5432821270504\n",
      "Train Epoch: 892 [512/17352 (3%)] Loss: -1048.067505\n",
      "Train Epoch: 892 [10446/17352 (60%)] Loss: -1031.248330\n",
      "Train Epoch: 892 [17108/17352 (99%)] Loss: -1072.613440\n",
      "    epoch          : 892\n",
      "    loss           : -992.363532829835\n",
      "    val_loss       : -720.506830999221\n",
      "Train Epoch: 893 [512/17352 (3%)] Loss: -1036.399292\n",
      "Train Epoch: 893 [10643/17352 (61%)] Loss: -1092.282774\n",
      "Train Epoch: 893 [17064/17352 (98%)] Loss: -1053.313021\n",
      "    epoch          : 893\n",
      "    loss           : -995.2520654172592\n",
      "    val_loss       : -716.791142353689\n",
      "Train Epoch: 894 [512/17352 (3%)] Loss: -1041.593384\n",
      "Train Epoch: 894 [10224/17352 (59%)] Loss: -933.009233\n",
      "Train Epoch: 894 [17335/17352 (100%)] Loss: -1032.845658\n",
      "    epoch          : 894\n",
      "    loss           : -993.7616909527562\n",
      "    val_loss       : -695.0692175030931\n",
      "Train Epoch: 895 [512/17352 (3%)] Loss: -1026.608643\n",
      "Train Epoch: 895 [10095/17352 (58%)] Loss: -878.675839\n",
      "Train Epoch: 895 [16922/17352 (98%)] Loss: -1079.067200\n",
      "    epoch          : 895\n",
      "    loss           : -989.0081417737431\n",
      "    val_loss       : -724.181761257159\n",
      "Train Epoch: 896 [512/17352 (3%)] Loss: -1023.609985\n",
      "Train Epoch: 896 [10039/17352 (58%)] Loss: -1087.123487\n",
      "Train Epoch: 896 [17263/17352 (99%)] Loss: -1033.617903\n",
      "    epoch          : 896\n",
      "    loss           : -994.3572452014596\n",
      "    val_loss       : -720.8295785224533\n",
      "Train Epoch: 897 [512/17352 (3%)] Loss: -1033.664551\n",
      "Train Epoch: 897 [9933/17352 (57%)] Loss: -1086.969101\n",
      "Train Epoch: 897 [17253/17352 (99%)] Loss: -1075.771415\n",
      "    epoch          : 897\n",
      "    loss           : -995.8645113358442\n",
      "    val_loss       : -709.0932317476278\n",
      "Train Epoch: 898 [512/17352 (3%)] Loss: -1026.552612\n",
      "Train Epoch: 898 [10351/17352 (60%)] Loss: -1092.522141\n",
      "Train Epoch: 898 [16883/17352 (97%)] Loss: -1069.647747\n",
      "    epoch          : 898\n",
      "    loss           : -995.8348219227895\n",
      "    val_loss       : -714.9642011543627\n",
      "Train Epoch: 899 [512/17352 (3%)] Loss: -1039.032227\n",
      "Train Epoch: 899 [10291/17352 (59%)] Loss: -899.452142\n",
      "Train Epoch: 899 [17106/17352 (99%)] Loss: -1115.287760\n",
      "    epoch          : 899\n",
      "    loss           : -998.5734376102163\n",
      "    val_loss       : -693.0822520346156\n",
      "Train Epoch: 900 [512/17352 (3%)] Loss: -1021.243652\n",
      "Train Epoch: 900 [10641/17352 (61%)] Loss: -843.831250\n",
      "Train Epoch: 900 [17126/17352 (99%)] Loss: -944.255059\n",
      "    epoch          : 900\n",
      "    loss           : -992.1438497282821\n",
      "    val_loss       : -689.24555309628\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch900.pth ...\n",
      "Train Epoch: 901 [512/17352 (3%)] Loss: -1014.799683\n",
      "Train Epoch: 901 [9983/17352 (58%)] Loss: -1000.548314\n",
      "Train Epoch: 901 [17106/17352 (99%)] Loss: -842.352796\n",
      "    epoch          : 901\n",
      "    loss           : -995.6743323300341\n",
      "    val_loss       : -715.7204553931823\n",
      "Train Epoch: 902 [512/17352 (3%)] Loss: -1054.420044\n",
      "Train Epoch: 902 [9582/17352 (55%)] Loss: -945.720927\n",
      "Train Epoch: 902 [17106/17352 (99%)] Loss: -950.375347\n",
      "    epoch          : 902\n",
      "    loss           : -1007.5647999268613\n",
      "    val_loss       : -726.2143668774883\n",
      "Train Epoch: 903 [512/17352 (3%)] Loss: -1055.835327\n",
      "Train Epoch: 903 [10575/17352 (61%)] Loss: -1082.534026\n",
      "Train Epoch: 903 [16883/17352 (97%)] Loss: -1093.115744\n",
      "    epoch          : 903\n",
      "    loss           : -1003.0781760720034\n",
      "    val_loss       : -716.7900506554387\n",
      "Train Epoch: 904 [512/17352 (3%)] Loss: -1036.712402\n",
      "Train Epoch: 904 [10257/17352 (59%)] Loss: -1065.500833\n",
      "Train Epoch: 904 [17049/17352 (98%)] Loss: -1054.449950\n",
      "    epoch          : 904\n",
      "    loss           : -1001.3260545731008\n",
      "    val_loss       : -691.1537544719766\n",
      "Train Epoch: 905 [512/17352 (3%)] Loss: -1034.403076\n",
      "Train Epoch: 905 [10494/17352 (60%)] Loss: -1099.189024\n",
      "Train Epoch: 905 [17124/17352 (99%)] Loss: -904.137675\n",
      "    epoch          : 905\n",
      "    loss           : -1003.2578046354223\n",
      "    val_loss       : -696.7055107586349\n",
      "Train Epoch: 906 [512/17352 (3%)] Loss: -1036.922852\n",
      "Train Epoch: 906 [9941/17352 (57%)] Loss: -854.314924\n",
      "Train Epoch: 906 [16988/17352 (98%)] Loss: -923.440747\n",
      "    epoch          : 906\n",
      "    loss           : -975.985470456663\n",
      "    val_loss       : -680.1511414843812\n",
      "Train Epoch: 907 [512/17352 (3%)] Loss: -1012.964600\n",
      "Train Epoch: 907 [10504/17352 (61%)] Loss: -925.955543\n",
      "Train Epoch: 907 [17049/17352 (98%)] Loss: -981.072522\n",
      "    epoch          : 907\n",
      "    loss           : -963.5907883514692\n",
      "    val_loss       : -685.9436450006481\n",
      "Train Epoch: 908 [512/17352 (3%)] Loss: -1024.530762\n",
      "Train Epoch: 908 [10821/17352 (62%)] Loss: -951.013363\n",
      "Train Epoch: 908 [17153/17352 (99%)] Loss: -818.340726\n",
      "    epoch          : 908\n",
      "    loss           : -981.0144031821568\n",
      "    val_loss       : -685.1790472657322\n",
      "Train Epoch: 909 [512/17352 (3%)] Loss: -1041.686890\n",
      "Train Epoch: 909 [10136/17352 (58%)] Loss: -849.666567\n",
      "Train Epoch: 909 [17016/17352 (98%)] Loss: -940.941726\n",
      "    epoch          : 909\n",
      "    loss           : -1000.2994729506822\n",
      "    val_loss       : -701.5685582126355\n",
      "Train Epoch: 910 [512/17352 (3%)] Loss: -1052.939697\n",
      "Train Epoch: 910 [10393/17352 (60%)] Loss: -1035.221104\n",
      "Train Epoch: 910 [17335/17352 (100%)] Loss: -1142.803385\n",
      "    epoch          : 910\n",
      "    loss           : -992.2496433199404\n",
      "    val_loss       : -671.1460627437292\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch910.pth ...\n",
      "Train Epoch: 911 [512/17352 (3%)] Loss: -1017.273682\n",
      "Train Epoch: 911 [10377/17352 (60%)] Loss: -1121.742188\n",
      "Train Epoch: 911 [16957/17352 (98%)] Loss: -1048.921348\n",
      "    epoch          : 911\n",
      "    loss           : -978.2369047647621\n",
      "    val_loss       : -634.208375985661\n",
      "Train Epoch: 912 [512/17352 (3%)] Loss: -1034.059204\n",
      "Train Epoch: 912 [10895/17352 (63%)] Loss: -945.728618\n",
      "Train Epoch: 912 [16883/17352 (97%)] Loss: -891.838179\n",
      "    epoch          : 912\n",
      "    loss           : -917.4309085428466\n",
      "    val_loss       : -641.8164339676168\n",
      "Train Epoch: 913 [512/17352 (3%)] Loss: -1017.088379\n",
      "Train Epoch: 913 [10361/17352 (60%)] Loss: -840.911633\n",
      "Train Epoch: 913 [16923/17352 (98%)] Loss: -946.812414\n",
      "    epoch          : 913\n",
      "    loss           : -973.2605016439177\n",
      "    val_loss       : -697.0152699993628\n",
      "Train Epoch: 914 [512/17352 (3%)] Loss: -1022.731445\n",
      "Train Epoch: 914 [10344/17352 (60%)] Loss: -1024.914457\n",
      "Train Epoch: 914 [16883/17352 (97%)] Loss: -962.493122\n",
      "    epoch          : 914\n",
      "    loss           : -986.8074671428501\n",
      "    val_loss       : -692.8293525924668\n",
      "Train Epoch: 915 [512/17352 (3%)] Loss: -1039.474121\n",
      "Train Epoch: 915 [10405/17352 (60%)] Loss: -1083.497606\n",
      "Train Epoch: 915 [16883/17352 (97%)] Loss: -1140.278212\n",
      "    epoch          : 915\n",
      "    loss           : -997.877968184879\n",
      "    val_loss       : -724.1764245971841\n",
      "Train Epoch: 916 [512/17352 (3%)] Loss: -856.657715\n",
      "Train Epoch: 916 [10032/17352 (58%)] Loss: -1076.145878\n",
      "Train Epoch: 916 [16992/17352 (98%)] Loss: -1085.108027\n",
      "    epoch          : 916\n",
      "    loss           : -995.6566124796118\n",
      "    val_loss       : -681.6814870969977\n",
      "Train Epoch: 917 [512/17352 (3%)] Loss: -1041.217773\n",
      "Train Epoch: 917 [10535/17352 (61%)] Loss: -1008.048138\n",
      "Train Epoch: 917 [17106/17352 (99%)] Loss: -1053.570348\n",
      "    epoch          : 917\n",
      "    loss           : -990.0127452508439\n",
      "    val_loss       : -658.2011720155481\n",
      "Train Epoch: 918 [512/17352 (3%)] Loss: -1017.910095\n",
      "Train Epoch: 918 [10453/17352 (60%)] Loss: -1132.078125\n",
      "Train Epoch: 918 [17106/17352 (99%)] Loss: -1021.467188\n",
      "    epoch          : 918\n",
      "    loss           : -957.321629114166\n",
      "    val_loss       : -298.3006724421051\n",
      "Train Epoch: 919 [512/17352 (3%)] Loss: -713.122620\n",
      "Train Epoch: 919 [10104/17352 (58%)] Loss: -1047.610245\n",
      "Train Epoch: 919 [16957/17352 (98%)] Loss: -659.123355\n",
      "    epoch          : 919\n",
      "    loss           : -760.3148905235241\n",
      "    val_loss       : -621.58809332036\n",
      "Train Epoch: 920 [512/17352 (3%)] Loss: -955.120850\n",
      "Train Epoch: 920 [9787/17352 (56%)] Loss: -905.177035\n",
      "Train Epoch: 920 [16939/17352 (98%)] Loss: -1073.246123\n",
      "    epoch          : 920\n",
      "    loss           : -935.6530740538111\n",
      "    val_loss       : -677.7823307645111\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch920.pth ...\n",
      "Train Epoch: 921 [512/17352 (3%)] Loss: -1019.647644\n",
      "Train Epoch: 921 [10342/17352 (60%)] Loss: -1004.922636\n",
      "Train Epoch: 921 [16872/17352 (97%)] Loss: -1009.551582\n",
      "    epoch          : 921\n",
      "    loss           : -970.5125767587234\n",
      "    val_loss       : -624.8260969739362\n",
      "Train Epoch: 922 [512/17352 (3%)] Loss: -994.769531\n",
      "Train Epoch: 922 [9974/17352 (57%)] Loss: -918.372832\n",
      "Train Epoch: 922 [16887/17352 (97%)] Loss: -880.800930\n",
      "    epoch          : 922\n",
      "    loss           : -954.889394922226\n",
      "    val_loss       : -566.6872463210532\n",
      "Train Epoch: 923 [512/17352 (3%)] Loss: -888.300293\n",
      "Train Epoch: 923 [10076/17352 (58%)] Loss: -972.158684\n",
      "Train Epoch: 923 [16988/17352 (98%)] Loss: -944.375533\n",
      "    epoch          : 923\n",
      "    loss           : -870.8573528034661\n",
      "    val_loss       : -627.3471709595761\n",
      "Train Epoch: 924 [512/17352 (3%)] Loss: -1006.901428\n",
      "Train Epoch: 924 [10453/17352 (60%)] Loss: -875.189174\n",
      "Train Epoch: 924 [16957/17352 (98%)] Loss: -1011.009115\n",
      "    epoch          : 924\n",
      "    loss           : -879.5835380385606\n",
      "    val_loss       : -539.8508751807902\n",
      "Train Epoch: 925 [512/17352 (3%)] Loss: -701.709167\n",
      "Train Epoch: 925 [10256/17352 (59%)] Loss: -756.529069\n",
      "Train Epoch: 925 [17016/17352 (98%)] Loss: -846.041157\n",
      "    epoch          : 925\n",
      "    loss           : -896.3126301800137\n",
      "    val_loss       : -658.75356614455\n",
      "Train Epoch: 926 [512/17352 (3%)] Loss: -832.666016\n",
      "Train Epoch: 926 [10561/17352 (61%)] Loss: -1076.518990\n",
      "Train Epoch: 926 [16988/17352 (98%)] Loss: -1014.328750\n",
      "    epoch          : 926\n",
      "    loss           : -933.1469907277922\n",
      "    val_loss       : -623.5762520463417\n",
      "Train Epoch: 927 [512/17352 (3%)] Loss: -765.708252\n",
      "Train Epoch: 927 [10385/17352 (60%)] Loss: -812.638978\n",
      "Train Epoch: 927 [17016/17352 (98%)] Loss: -905.984243\n",
      "    epoch          : 927\n",
      "    loss           : -957.3761323787976\n",
      "    val_loss       : -685.9233879026096\n",
      "Train Epoch: 928 [512/17352 (3%)] Loss: -1032.356201\n",
      "Train Epoch: 928 [10255/17352 (59%)] Loss: -943.070807\n",
      "Train Epoch: 928 [17277/17352 (100%)] Loss: -843.806570\n",
      "    epoch          : 928\n",
      "    loss           : -1000.7440752895661\n",
      "    val_loss       : -695.3428092583983\n",
      "Train Epoch: 929 [512/17352 (3%)] Loss: -876.126587\n",
      "Train Epoch: 929 [10237/17352 (59%)] Loss: -975.058612\n",
      "Train Epoch: 929 [16992/17352 (98%)] Loss: -978.561813\n",
      "    epoch          : 929\n",
      "    loss           : -1006.5463520108257\n",
      "    val_loss       : -705.5418770007634\n",
      "Train Epoch: 930 [512/17352 (3%)] Loss: -864.331848\n",
      "Train Epoch: 930 [10054/17352 (58%)] Loss: -1091.718275\n",
      "Train Epoch: 930 [16992/17352 (98%)] Loss: -953.996044\n",
      "    epoch          : 930\n",
      "    loss           : -1005.6754185841661\n",
      "    val_loss       : -723.630947191728\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch930.pth ...\n",
      "Train Epoch: 931 [512/17352 (3%)] Loss: -1062.031616\n",
      "Train Epoch: 931 [10367/17352 (60%)] Loss: -1001.752068\n",
      "Train Epoch: 931 [17090/17352 (98%)] Loss: -1077.819480\n",
      "    epoch          : 931\n",
      "    loss           : -1010.8209109139357\n",
      "    val_loss       : -707.4951102027475\n",
      "Train Epoch: 932 [512/17352 (3%)] Loss: -1056.662720\n",
      "Train Epoch: 932 [9742/17352 (56%)] Loss: -1150.477431\n",
      "Train Epoch: 932 [16872/17352 (97%)] Loss: -1035.440265\n",
      "    epoch          : 932\n",
      "    loss           : -1012.9304047835022\n",
      "    val_loss       : -714.9729713966477\n",
      "Train Epoch: 933 [512/17352 (3%)] Loss: -1064.739014\n",
      "Train Epoch: 933 [10508/17352 (61%)] Loss: -837.724462\n",
      "Train Epoch: 933 [16878/17352 (97%)] Loss: -1098.095000\n",
      "    epoch          : 933\n",
      "    loss           : -1015.5469761631845\n",
      "    val_loss       : -711.6003449055793\n",
      "Train Epoch: 934 [512/17352 (3%)] Loss: -1051.358521\n",
      "Train Epoch: 934 [10269/17352 (59%)] Loss: -1128.828625\n",
      "Train Epoch: 934 [16939/17352 (98%)] Loss: -944.266741\n",
      "    epoch          : 934\n",
      "    loss           : -1013.5267458412536\n",
      "    val_loss       : -702.5036397039619\n",
      "Train Epoch: 935 [512/17352 (3%)] Loss: -1051.159912\n",
      "Train Epoch: 935 [9626/17352 (55%)] Loss: -1151.661892\n",
      "Train Epoch: 935 [17153/17352 (99%)] Loss: -991.552284\n",
      "    epoch          : 935\n",
      "    loss           : -1018.8212521472254\n",
      "    val_loss       : -694.3954992784933\n",
      "Train Epoch: 936 [512/17352 (3%)] Loss: -1059.027954\n",
      "Train Epoch: 936 [10193/17352 (59%)] Loss: -1005.726905\n",
      "Train Epoch: 936 [17106/17352 (99%)] Loss: -1111.337016\n",
      "    epoch          : 936\n",
      "    loss           : -1010.992624093613\n",
      "    val_loss       : -686.0708427774287\n",
      "Train Epoch: 937 [512/17352 (3%)] Loss: -1073.395020\n",
      "Train Epoch: 937 [10549/17352 (61%)] Loss: -1043.477099\n",
      "Train Epoch: 937 [17124/17352 (99%)] Loss: -839.667389\n",
      "    epoch          : 937\n",
      "    loss           : -997.4489228719871\n",
      "    val_loss       : -692.5730326530164\n",
      "Train Epoch: 938 [512/17352 (3%)] Loss: -1015.164307\n",
      "Train Epoch: 938 [9512/17352 (55%)] Loss: -1010.923455\n",
      "Train Epoch: 938 [17049/17352 (98%)] Loss: -691.878956\n",
      "    epoch          : 938\n",
      "    loss           : -950.005751151235\n",
      "    val_loss       : -582.7468581147883\n",
      "Train Epoch: 939 [512/17352 (3%)] Loss: -891.925659\n",
      "Train Epoch: 939 [10850/17352 (63%)] Loss: -1018.487476\n",
      "Train Epoch: 939 [16887/17352 (97%)] Loss: -896.446987\n",
      "    epoch          : 939\n",
      "    loss           : -917.4349185992181\n",
      "    val_loss       : -647.5227380204702\n",
      "Train Epoch: 940 [512/17352 (3%)] Loss: -980.951782\n",
      "Train Epoch: 940 [10433/17352 (60%)] Loss: -877.736979\n",
      "Train Epoch: 940 [17064/17352 (98%)] Loss: -848.353291\n",
      "    epoch          : 940\n",
      "    loss           : -858.0511395035011\n",
      "    val_loss       : -581.9231149835505\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch940.pth ...\n",
      "Train Epoch: 941 [512/17352 (3%)] Loss: -645.206604\n",
      "Train Epoch: 941 [10671/17352 (61%)] Loss: -856.165885\n",
      "Train Epoch: 941 [16957/17352 (98%)] Loss: -907.508575\n",
      "    epoch          : 941\n",
      "    loss           : -897.5108972340446\n",
      "    val_loss       : -630.2806180646903\n",
      "Train Epoch: 942 [512/17352 (3%)] Loss: -966.424744\n",
      "Train Epoch: 942 [10274/17352 (59%)] Loss: -837.315705\n",
      "Train Epoch: 942 [17253/17352 (99%)] Loss: -917.451689\n",
      "    epoch          : 942\n",
      "    loss           : -958.2713245694515\n",
      "    val_loss       : -516.8091621323584\n",
      "Train Epoch: 943 [512/17352 (3%)] Loss: -874.927002\n",
      "Train Epoch: 943 [10279/17352 (59%)] Loss: -741.286729\n",
      "Train Epoch: 943 [16882/17352 (97%)] Loss: -897.389931\n",
      "    epoch          : 943\n",
      "    loss           : -911.3810248676765\n",
      "    val_loss       : -678.9060576886196\n",
      "Train Epoch: 944 [512/17352 (3%)] Loss: -825.245605\n",
      "Train Epoch: 944 [10294/17352 (59%)] Loss: -1040.296159\n",
      "Train Epoch: 944 [16992/17352 (98%)] Loss: -1045.281727\n",
      "    epoch          : 944\n",
      "    loss           : -954.4047930115623\n",
      "    val_loss       : -666.6675394663823\n",
      "Train Epoch: 945 [512/17352 (3%)] Loss: -999.220215\n",
      "Train Epoch: 945 [10448/17352 (60%)] Loss: -787.016141\n",
      "Train Epoch: 945 [17108/17352 (99%)] Loss: -1080.989583\n",
      "    epoch          : 945\n",
      "    loss           : -966.8158282722146\n",
      "    val_loss       : -670.1594730847017\n",
      "Train Epoch: 946 [512/17352 (3%)] Loss: -1021.075745\n",
      "Train Epoch: 946 [10622/17352 (61%)] Loss: -953.254185\n",
      "Train Epoch: 946 [17277/17352 (100%)] Loss: -834.264706\n",
      "    epoch          : 946\n",
      "    loss           : -988.1166014275587\n",
      "    val_loss       : -653.6200654686957\n",
      "Train Epoch: 947 [512/17352 (3%)] Loss: -987.033142\n",
      "Train Epoch: 947 [9996/17352 (58%)] Loss: -1005.371005\n",
      "Train Epoch: 947 [17143/17352 (99%)] Loss: -1003.849023\n",
      "    epoch          : 947\n",
      "    loss           : -986.5423984947282\n",
      "    val_loss       : -554.9065960253627\n",
      "Train Epoch: 948 [512/17352 (3%)] Loss: -928.857178\n",
      "Train Epoch: 948 [10385/17352 (60%)] Loss: -1090.234177\n",
      "Train Epoch: 948 [16988/17352 (98%)] Loss: -615.698191\n",
      "    epoch          : 948\n",
      "    loss           : -939.0244012804694\n",
      "    val_loss       : -559.2888642355961\n",
      "Train Epoch: 949 [512/17352 (3%)] Loss: -938.599243\n",
      "Train Epoch: 949 [10165/17352 (59%)] Loss: -917.421939\n",
      "Train Epoch: 949 [17253/17352 (99%)] Loss: -528.207899\n",
      "    epoch          : 949\n",
      "    loss           : -610.6159422270273\n",
      "    val_loss       : 7.210311596189605\n",
      "Train Epoch: 950 [512/17352 (3%)] Loss: -312.197845\n",
      "Train Epoch: 950 [10128/17352 (58%)] Loss: -890.933648\n",
      "Train Epoch: 950 [16992/17352 (98%)] Loss: -1058.390858\n",
      "    epoch          : 950\n",
      "    loss           : -807.6244869847372\n",
      "    val_loss       : -640.4679391531172\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch950.pth ...\n",
      "Train Epoch: 951 [512/17352 (3%)] Loss: -979.890503\n",
      "Train Epoch: 951 [9870/17352 (57%)] Loss: -855.737417\n",
      "Train Epoch: 951 [17153/17352 (99%)] Loss: -1095.823298\n",
      "    epoch          : 951\n",
      "    loss           : -977.9401346967262\n",
      "    val_loss       : -664.4730494920786\n",
      "Train Epoch: 952 [512/17352 (3%)] Loss: -1011.440186\n",
      "Train Epoch: 952 [10043/17352 (58%)] Loss: -982.495423\n",
      "Train Epoch: 952 [16883/17352 (97%)] Loss: -943.490666\n",
      "    epoch          : 952\n",
      "    loss           : -994.8417687690478\n",
      "    val_loss       : -702.0672411357165\n",
      "Train Epoch: 953 [512/17352 (3%)] Loss: -1059.807129\n",
      "Train Epoch: 953 [10613/17352 (61%)] Loss: -884.727723\n",
      "Train Epoch: 953 [16922/17352 (98%)] Loss: -1112.425133\n",
      "    epoch          : 953\n",
      "    loss           : -1013.2276544284971\n",
      "    val_loss       : -710.8022086758859\n",
      "Train Epoch: 954 [512/17352 (3%)] Loss: -1054.425537\n",
      "Train Epoch: 954 [9850/17352 (57%)] Loss: -1069.735303\n",
      "Train Epoch: 954 [17335/17352 (100%)] Loss: -1032.191998\n",
      "    epoch          : 954\n",
      "    loss           : -1011.2911961196622\n",
      "    val_loss       : -696.6882907596382\n",
      "Train Epoch: 955 [512/17352 (3%)] Loss: -1052.760620\n",
      "Train Epoch: 955 [10213/17352 (59%)] Loss: -1055.302189\n",
      "Train Epoch: 955 [17143/17352 (99%)] Loss: -954.280035\n",
      "    epoch          : 955\n",
      "    loss           : -1003.311329244679\n",
      "    val_loss       : -685.2999871100484\n",
      "Train Epoch: 956 [512/17352 (3%)] Loss: -1044.107178\n",
      "Train Epoch: 956 [10601/17352 (61%)] Loss: -889.554127\n",
      "Train Epoch: 956 [17335/17352 (100%)] Loss: -1082.418702\n",
      "    epoch          : 956\n",
      "    loss           : -999.5193691858655\n",
      "    val_loss       : -671.3327578706602\n",
      "Train Epoch: 957 [512/17352 (3%)] Loss: -1016.762085\n",
      "Train Epoch: 957 [10458/17352 (60%)] Loss: -961.271456\n",
      "Train Epoch: 957 [16872/17352 (97%)] Loss: -1128.872957\n",
      "    epoch          : 957\n",
      "    loss           : -1002.554103175709\n",
      "    val_loss       : -679.5817884743549\n",
      "Train Epoch: 958 [512/17352 (3%)] Loss: -1049.100586\n",
      "Train Epoch: 958 [10169/17352 (59%)] Loss: -833.806250\n",
      "Train Epoch: 958 [17044/17352 (98%)] Loss: -937.874327\n",
      "    epoch          : 958\n",
      "    loss           : -994.316777830296\n",
      "    val_loss       : -704.4322709664845\n",
      "Train Epoch: 959 [512/17352 (3%)] Loss: -1025.716431\n",
      "Train Epoch: 959 [10116/17352 (58%)] Loss: -1095.105521\n",
      "Train Epoch: 959 [16883/17352 (97%)] Loss: -1067.276172\n",
      "    epoch          : 959\n",
      "    loss           : -1014.234112854287\n",
      "    val_loss       : -704.8817090883599\n",
      "Train Epoch: 960 [512/17352 (3%)] Loss: -1048.609741\n",
      "Train Epoch: 960 [10525/17352 (61%)] Loss: -945.083070\n",
      "Train Epoch: 960 [17277/17352 (100%)] Loss: -1126.011501\n",
      "    epoch          : 960\n",
      "    loss           : -1012.562162317577\n",
      "    val_loss       : -687.0672461497194\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch960.pth ...\n",
      "Train Epoch: 961 [512/17352 (3%)] Loss: -1051.308472\n",
      "Train Epoch: 961 [10265/17352 (59%)] Loss: -1039.196948\n",
      "Train Epoch: 961 [16958/17352 (98%)] Loss: -1061.990790\n",
      "    epoch          : 961\n",
      "    loss           : -990.6539393711465\n",
      "    val_loss       : -681.9541807267117\n",
      "Train Epoch: 962 [512/17352 (3%)] Loss: -1024.102051\n",
      "Train Epoch: 962 [10172/17352 (59%)] Loss: -1012.124544\n",
      "Train Epoch: 962 [17124/17352 (99%)] Loss: -863.902171\n",
      "    epoch          : 962\n",
      "    loss           : -986.7972652108394\n",
      "    val_loss       : -663.8847103428462\n",
      "Train Epoch: 963 [512/17352 (3%)] Loss: -970.038330\n",
      "Train Epoch: 963 [10030/17352 (58%)] Loss: -846.812698\n",
      "Train Epoch: 963 [17133/17352 (99%)] Loss: -740.077970\n",
      "    epoch          : 963\n",
      "    loss           : -977.2189600178863\n",
      "    val_loss       : -667.5484673354478\n",
      "Train Epoch: 964 [512/17352 (3%)] Loss: -1025.643555\n",
      "Train Epoch: 964 [10621/17352 (61%)] Loss: -1045.135131\n",
      "Train Epoch: 964 [17126/17352 (99%)] Loss: -1044.369460\n",
      "    epoch          : 964\n",
      "    loss           : -985.3519671465648\n",
      "    val_loss       : -680.5849805260132\n",
      "Train Epoch: 965 [512/17352 (3%)] Loss: -1019.069458\n",
      "Train Epoch: 965 [10094/17352 (58%)] Loss: -940.057528\n",
      "Train Epoch: 965 [16882/17352 (97%)] Loss: -959.149148\n",
      "    epoch          : 965\n",
      "    loss           : -1018.8481131281604\n",
      "    val_loss       : -705.9954702655417\n",
      "Train Epoch: 966 [512/17352 (3%)] Loss: -1062.348389\n",
      "Train Epoch: 966 [10343/17352 (60%)] Loss: -945.475738\n",
      "Train Epoch: 966 [17090/17352 (98%)] Loss: -951.829948\n",
      "    epoch          : 966\n",
      "    loss           : -1016.5293450968298\n",
      "    val_loss       : -702.0572820495453\n",
      "Train Epoch: 967 [512/17352 (3%)] Loss: -1064.528320\n",
      "Train Epoch: 967 [10596/17352 (61%)] Loss: -1051.768229\n",
      "Train Epoch: 967 [16923/17352 (98%)] Loss: -1080.865770\n",
      "    epoch          : 967\n",
      "    loss           : -1020.7904624771999\n",
      "    val_loss       : -703.8039026596405\n",
      "Train Epoch: 968 [512/17352 (3%)] Loss: -1057.078369\n",
      "Train Epoch: 968 [10583/17352 (61%)] Loss: -899.059883\n",
      "Train Epoch: 968 [17106/17352 (99%)] Loss: -1055.622235\n",
      "    epoch          : 968\n",
      "    loss           : -1027.9583841050285\n",
      "    val_loss       : -696.330816543425\n",
      "Train Epoch: 969 [512/17352 (3%)] Loss: -1076.238159\n",
      "Train Epoch: 969 [10478/17352 (60%)] Loss: -1106.922113\n",
      "Train Epoch: 969 [17090/17352 (98%)] Loss: -1018.493336\n",
      "    epoch          : 969\n",
      "    loss           : -1027.4808290897424\n",
      "    val_loss       : -714.1973526139449\n",
      "Train Epoch: 970 [512/17352 (3%)] Loss: -1060.510376\n",
      "Train Epoch: 970 [10190/17352 (59%)] Loss: -1044.530072\n",
      "Train Epoch: 970 [16923/17352 (98%)] Loss: -937.333433\n",
      "    epoch          : 970\n",
      "    loss           : -1009.7179898089504\n",
      "    val_loss       : -686.997094415735\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch970.pth ...\n",
      "Train Epoch: 971 [512/17352 (3%)] Loss: -1059.733643\n",
      "Train Epoch: 971 [10180/17352 (59%)] Loss: -1068.298958\n",
      "Train Epoch: 971 [17108/17352 (99%)] Loss: -1075.529346\n",
      "    epoch          : 971\n",
      "    loss           : -1000.7274912285034\n",
      "    val_loss       : -676.3782563065968\n",
      "Train Epoch: 972 [512/17352 (3%)] Loss: -1048.040771\n",
      "Train Epoch: 972 [10903/17352 (63%)] Loss: -933.615885\n",
      "Train Epoch: 972 [17016/17352 (98%)] Loss: -757.889728\n",
      "    epoch          : 972\n",
      "    loss           : -1007.4761896069265\n",
      "    val_loss       : -653.5414556821453\n",
      "Train Epoch: 973 [512/17352 (3%)] Loss: -1029.563477\n",
      "Train Epoch: 973 [10747/17352 (62%)] Loss: -1119.205357\n",
      "Train Epoch: 973 [16939/17352 (98%)] Loss: -881.603733\n",
      "    epoch          : 973\n",
      "    loss           : -979.6761955488007\n",
      "    val_loss       : -668.179914069483\n",
      "Train Epoch: 974 [512/17352 (3%)] Loss: -1054.214111\n",
      "Train Epoch: 974 [10667/17352 (61%)] Loss: -934.322748\n",
      "Train Epoch: 974 [16939/17352 (98%)] Loss: -1064.888984\n",
      "    epoch          : 974\n",
      "    loss           : -1003.5266254690501\n",
      "    val_loss       : -702.9665645114355\n",
      "Train Epoch: 975 [512/17352 (3%)] Loss: -1054.818726\n",
      "Train Epoch: 975 [10363/17352 (60%)] Loss: -1092.691875\n",
      "Train Epoch: 975 [17143/17352 (99%)] Loss: -954.592601\n",
      "    epoch          : 975\n",
      "    loss           : -1002.781414430198\n",
      "    val_loss       : -651.4122178401014\n",
      "Train Epoch: 976 [512/17352 (3%)] Loss: -1026.299561\n",
      "Train Epoch: 976 [9830/17352 (57%)] Loss: -1006.229090\n",
      "Train Epoch: 976 [16883/17352 (97%)] Loss: -937.644278\n",
      "    epoch          : 976\n",
      "    loss           : -1012.5598594512809\n",
      "    val_loss       : -700.6874786688898\n",
      "Train Epoch: 977 [512/17352 (3%)] Loss: -1078.094238\n",
      "Train Epoch: 977 [9687/17352 (56%)] Loss: -1077.059896\n",
      "Train Epoch: 977 [16882/17352 (97%)] Loss: -916.646205\n",
      "    epoch          : 977\n",
      "    loss           : -988.4482128219108\n",
      "    val_loss       : -687.9300824133384\n",
      "Train Epoch: 978 [512/17352 (3%)] Loss: -1062.220215\n",
      "Train Epoch: 978 [10064/17352 (58%)] Loss: -1053.435144\n",
      "Train Epoch: 978 [16939/17352 (98%)] Loss: -837.191794\n",
      "    epoch          : 978\n",
      "    loss           : -974.2368994382311\n",
      "    val_loss       : -613.5470298846415\n",
      "Train Epoch: 979 [512/17352 (3%)] Loss: -1030.923340\n",
      "Train Epoch: 979 [9939/17352 (57%)] Loss: -918.081692\n",
      "Train Epoch: 979 [16887/17352 (97%)] Loss: -906.751492\n",
      "    epoch          : 979\n",
      "    loss           : -774.69488730423\n",
      "    val_loss       : -581.4200267202964\n",
      "Train Epoch: 980 [512/17352 (3%)] Loss: -961.151855\n",
      "Train Epoch: 980 [10565/17352 (61%)] Loss: -803.643023\n",
      "Train Epoch: 980 [17049/17352 (98%)] Loss: -676.018127\n",
      "    epoch          : 980\n",
      "    loss           : -701.9377904358117\n",
      "    val_loss       : -520.4141328877542\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch980.pth ...\n",
      "Train Epoch: 981 [512/17352 (3%)] Loss: -870.390381\n",
      "Train Epoch: 981 [10340/17352 (60%)] Loss: -483.874252\n",
      "Train Epoch: 981 [16872/17352 (97%)] Loss: -681.712298\n",
      "    epoch          : 981\n",
      "    loss           : -757.4674414771492\n",
      "    val_loss       : -477.1398808561169\n",
      "Train Epoch: 982 [512/17352 (3%)] Loss: -880.543457\n",
      "Train Epoch: 982 [10339/17352 (60%)] Loss: -701.472414\n",
      "Train Epoch: 982 [17153/17352 (99%)] Loss: -711.563950\n",
      "    epoch          : 982\n",
      "    loss           : -713.3526885774662\n",
      "    val_loss       : -534.3833804810716\n",
      "Train Epoch: 983 [512/17352 (3%)] Loss: -872.998413\n",
      "Train Epoch: 983 [10577/17352 (61%)] Loss: -612.755301\n",
      "Train Epoch: 983 [17133/17352 (99%)] Loss: -928.617585\n",
      "    epoch          : 983\n",
      "    loss           : -708.991380281044\n",
      "    val_loss       : 761.2446896967958\n",
      "Train Epoch: 984 [512/17352 (3%)] Loss: 426.482727\n",
      "Train Epoch: 984 [11077/17352 (64%)] Loss: -560.626533\n",
      "Train Epoch: 984 [17277/17352 (100%)] Loss: -807.545205\n",
      "    epoch          : 984\n",
      "    loss           : -547.4417157892038\n",
      "    val_loss       : -487.8400027722904\n",
      "Train Epoch: 985 [512/17352 (3%)] Loss: -561.552856\n",
      "Train Epoch: 985 [10313/17352 (59%)] Loss: -910.185202\n",
      "Train Epoch: 985 [17126/17352 (99%)] Loss: -991.331812\n",
      "    epoch          : 985\n",
      "    loss           : -836.6538916322708\n",
      "    val_loss       : -515.5415452825363\n",
      "Train Epoch: 986 [512/17352 (3%)] Loss: -812.448242\n",
      "Train Epoch: 986 [10198/17352 (59%)] Loss: -943.400597\n",
      "Train Epoch: 986 [16939/17352 (98%)] Loss: -882.076631\n",
      "    epoch          : 986\n",
      "    loss           : -887.3774350757461\n",
      "    val_loss       : -636.1713576509031\n",
      "Train Epoch: 987 [512/17352 (3%)] Loss: -970.595642\n",
      "Train Epoch: 987 [10396/17352 (60%)] Loss: -894.400298\n",
      "Train Epoch: 987 [16887/17352 (97%)] Loss: -1004.062625\n",
      "    epoch          : 987\n",
      "    loss           : -941.6962448938401\n",
      "    val_loss       : -681.6416442473515\n",
      "Train Epoch: 988 [512/17352 (3%)] Loss: -1014.202393\n",
      "Train Epoch: 988 [10474/17352 (60%)] Loss: -872.636757\n",
      "Train Epoch: 988 [17124/17352 (99%)] Loss: -1042.191424\n",
      "    epoch          : 988\n",
      "    loss           : -969.764933829256\n",
      "    val_loss       : -660.5413317819194\n",
      "Train Epoch: 989 [512/17352 (3%)] Loss: -990.820312\n",
      "Train Epoch: 989 [10709/17352 (62%)] Loss: -1006.601042\n",
      "Train Epoch: 989 [17090/17352 (98%)] Loss: -897.730519\n",
      "    epoch          : 989\n",
      "    loss           : -967.7525417860417\n",
      "    val_loss       : -694.341345981821\n",
      "Train Epoch: 990 [512/17352 (3%)] Loss: -1032.247559\n",
      "Train Epoch: 990 [10410/17352 (60%)] Loss: -1039.578125\n",
      "Train Epoch: 990 [17101/17352 (99%)] Loss: -948.860759\n",
      "    epoch          : 990\n",
      "    loss           : -991.8313127413008\n",
      "    val_loss       : -695.5501846698554\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch990.pth ...\n",
      "Train Epoch: 991 [512/17352 (3%)] Loss: -1038.842773\n",
      "Train Epoch: 991 [10074/17352 (58%)] Loss: -864.162978\n",
      "Train Epoch: 991 [17049/17352 (98%)] Loss: -1111.895389\n",
      "    epoch          : 991\n",
      "    loss           : -1005.8043490344289\n",
      "    val_loss       : -713.9260230278487\n",
      "Train Epoch: 992 [512/17352 (3%)] Loss: -1074.571533\n",
      "Train Epoch: 992 [10582/17352 (61%)] Loss: -929.167539\n",
      "Train Epoch: 992 [17133/17352 (99%)] Loss: -976.417215\n",
      "    epoch          : 992\n",
      "    loss           : -1005.3545143091926\n",
      "    val_loss       : -687.1778201169093\n",
      "Train Epoch: 993 [512/17352 (3%)] Loss: -1037.112793\n",
      "Train Epoch: 993 [10393/17352 (60%)] Loss: -921.430711\n",
      "Train Epoch: 993 [16887/17352 (97%)] Loss: -1028.876284\n",
      "    epoch          : 993\n",
      "    loss           : -992.0927372081578\n",
      "    val_loss       : -713.3325311316399\n",
      "Train Epoch: 994 [512/17352 (3%)] Loss: -1040.511841\n",
      "Train Epoch: 994 [10153/17352 (59%)] Loss: -1061.619792\n",
      "Train Epoch: 994 [17126/17352 (99%)] Loss: -922.677471\n",
      "    epoch          : 994\n",
      "    loss           : -954.2841736171303\n",
      "    val_loss       : -695.2129551118397\n",
      "Train Epoch: 995 [512/17352 (3%)] Loss: -1047.443726\n",
      "Train Epoch: 995 [10281/17352 (59%)] Loss: -1065.678510\n",
      "Train Epoch: 995 [16934/17352 (98%)] Loss: -1073.515274\n",
      "    epoch          : 995\n",
      "    loss           : -1008.3011617092598\n",
      "    val_loss       : -723.5120679401725\n",
      "Train Epoch: 996 [512/17352 (3%)] Loss: -1060.649658\n",
      "Train Epoch: 996 [10140/17352 (58%)] Loss: -1035.057708\n",
      "Train Epoch: 996 [17044/17352 (98%)] Loss: -1073.910961\n",
      "    epoch          : 996\n",
      "    loss           : -1007.7051838451853\n",
      "    val_loss       : -691.7232049798403\n",
      "Train Epoch: 997 [512/17352 (3%)] Loss: -1047.532837\n",
      "Train Epoch: 997 [10256/17352 (59%)] Loss: -1074.649644\n",
      "Train Epoch: 997 [16923/17352 (98%)] Loss: -1028.962251\n",
      "    epoch          : 997\n",
      "    loss           : -990.3142534540974\n",
      "    val_loss       : -681.8949352300938\n",
      "Train Epoch: 998 [512/17352 (3%)] Loss: -1013.302368\n",
      "Train Epoch: 998 [10353/17352 (60%)] Loss: -1030.949392\n",
      "Train Epoch: 998 [16923/17352 (98%)] Loss: -1143.544113\n",
      "    epoch          : 998\n",
      "    loss           : -1014.6475318471024\n",
      "    val_loss       : -714.0403329812235\n",
      "Train Epoch: 999 [512/17352 (3%)] Loss: -1060.886719\n",
      "Train Epoch: 999 [9852/17352 (57%)] Loss: -866.975454\n",
      "Train Epoch: 999 [17108/17352 (99%)] Loss: -973.970069\n",
      "    epoch          : 999\n",
      "    loss           : -1023.272982951867\n",
      "    val_loss       : -727.1634875320225\n",
      "Train Epoch: 1000 [512/17352 (3%)] Loss: -1067.485840\n",
      "Train Epoch: 1000 [10145/17352 (58%)] Loss: -1073.978835\n",
      "Train Epoch: 1000 [17153/17352 (99%)] Loss: -1090.742224\n",
      "    epoch          : 1000\n",
      "    loss           : -1025.293594843089\n",
      "    val_loss       : -725.6673658167394\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch1000.pth ...\n",
      "Train Epoch: 1001 [512/17352 (3%)] Loss: -1069.056641\n",
      "Train Epoch: 1001 [9983/17352 (58%)] Loss: -900.758887\n",
      "Train Epoch: 1001 [16958/17352 (98%)] Loss: -1139.831423\n",
      "    epoch          : 1001\n",
      "    loss           : -1030.2865953419357\n",
      "    val_loss       : -702.1050151767116\n",
      "Train Epoch: 1002 [512/17352 (3%)] Loss: -1061.282715\n",
      "Train Epoch: 1002 [10339/17352 (60%)] Loss: -1059.068232\n",
      "Train Epoch: 1002 [17101/17352 (99%)] Loss: -1167.248047\n",
      "    epoch          : 1002\n",
      "    loss           : -1029.8870117596484\n",
      "    val_loss       : -718.2257676923309\n",
      "Train Epoch: 1003 [512/17352 (3%)] Loss: -1080.928101\n",
      "Train Epoch: 1003 [10006/17352 (58%)] Loss: -1108.522547\n",
      "Train Epoch: 1003 [16882/17352 (97%)] Loss: -998.221461\n",
      "    epoch          : 1003\n",
      "    loss           : -1019.7209346292576\n",
      "    val_loss       : -687.432192588074\n",
      "Train Epoch: 1004 [512/17352 (3%)] Loss: -1060.686279\n",
      "Train Epoch: 1004 [10568/17352 (61%)] Loss: -661.963797\n",
      "Train Epoch: 1004 [16872/17352 (97%)] Loss: -989.707376\n",
      "    epoch          : 1004\n",
      "    loss           : -935.6568402238199\n",
      "    val_loss       : -657.8015894319938\n",
      "Train Epoch: 1005 [512/17352 (3%)] Loss: -1044.472900\n",
      "Train Epoch: 1005 [10612/17352 (61%)] Loss: -918.000449\n",
      "Train Epoch: 1005 [17126/17352 (99%)] Loss: -942.613397\n",
      "    epoch          : 1005\n",
      "    loss           : -946.6565539129118\n",
      "    val_loss       : -649.4276238938342\n",
      "Train Epoch: 1006 [512/17352 (3%)] Loss: -1002.978760\n",
      "Train Epoch: 1006 [10599/17352 (61%)] Loss: -1102.406171\n",
      "Train Epoch: 1006 [17253/17352 (99%)] Loss: -958.962246\n",
      "    epoch          : 1006\n",
      "    loss           : -1003.6977402933012\n",
      "    val_loss       : -692.2112531375959\n",
      "Train Epoch: 1007 [512/17352 (3%)] Loss: -1048.820068\n",
      "Train Epoch: 1007 [10348/17352 (60%)] Loss: -903.082995\n",
      "Train Epoch: 1007 [16992/17352 (98%)] Loss: -985.523280\n",
      "    epoch          : 1007\n",
      "    loss           : -1015.930281447315\n",
      "    val_loss       : -692.2383673253785\n",
      "Train Epoch: 1008 [512/17352 (3%)] Loss: -1060.363281\n",
      "Train Epoch: 1008 [9974/17352 (57%)] Loss: -1113.242089\n",
      "Train Epoch: 1008 [16934/17352 (98%)] Loss: -931.870739\n",
      "    epoch          : 1008\n",
      "    loss           : -1012.7257472261383\n",
      "    val_loss       : -719.002597263772\n",
      "Train Epoch: 1009 [512/17352 (3%)] Loss: -1051.516357\n",
      "Train Epoch: 1009 [10282/17352 (59%)] Loss: -1127.485026\n",
      "Train Epoch: 1009 [16878/17352 (97%)] Loss: -953.296875\n",
      "    epoch          : 1009\n",
      "    loss           : -1003.3003923219698\n",
      "    val_loss       : -678.0121394931888\n",
      "Train Epoch: 1010 [512/17352 (3%)] Loss: -1036.931885\n",
      "Train Epoch: 1010 [10385/17352 (60%)] Loss: -1117.847079\n",
      "Train Epoch: 1010 [16883/17352 (97%)] Loss: -1072.954914\n",
      "    epoch          : 1010\n",
      "    loss           : -1004.4465268810657\n",
      "    val_loss       : -676.1214370314331\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch1010.pth ...\n",
      "Train Epoch: 1011 [512/17352 (3%)] Loss: -1073.234375\n",
      "Train Epoch: 1011 [10197/17352 (59%)] Loss: -965.333333\n",
      "Train Epoch: 1011 [17277/17352 (100%)] Loss: -1117.476064\n",
      "    epoch          : 1011\n",
      "    loss           : -1021.8958952256419\n",
      "    val_loss       : -641.8323846388577\n",
      "Train Epoch: 1012 [512/17352 (3%)] Loss: -989.570312\n",
      "Train Epoch: 1012 [10469/17352 (60%)] Loss: -1060.759375\n",
      "Train Epoch: 1012 [16878/17352 (97%)] Loss: -1062.576808\n",
      "    epoch          : 1012\n",
      "    loss           : -1007.6747459295802\n",
      "    val_loss       : -664.9627355906761\n",
      "Train Epoch: 1013 [512/17352 (3%)] Loss: -1037.686035\n",
      "Train Epoch: 1013 [10439/17352 (60%)] Loss: -1022.227323\n",
      "Train Epoch: 1013 [17335/17352 (100%)] Loss: -864.246753\n",
      "    epoch          : 1013\n",
      "    loss           : -993.2145316654485\n",
      "    val_loss       : -669.0611904953129\n",
      "Train Epoch: 1014 [512/17352 (3%)] Loss: -1020.121277\n",
      "Train Epoch: 1014 [10684/17352 (62%)] Loss: -1027.713894\n",
      "Train Epoch: 1014 [17108/17352 (99%)] Loss: -1014.950534\n",
      "    epoch          : 1014\n",
      "    loss           : -988.4158252120768\n",
      "    val_loss       : -659.1860328719534\n",
      "Train Epoch: 1015 [512/17352 (3%)] Loss: -1043.357056\n",
      "Train Epoch: 1015 [10392/17352 (60%)] Loss: -1036.102858\n",
      "Train Epoch: 1015 [17064/17352 (98%)] Loss: 1374.831967\n",
      "    epoch          : 1015\n",
      "    loss           : -314.48673842811564\n",
      "    val_loss       : 298.4490290751236\n",
      "Train Epoch: 1016 [512/17352 (3%)] Loss: -126.795425\n",
      "Train Epoch: 1016 [10229/17352 (59%)] Loss: 109.283267\n",
      "Train Epoch: 1016 [17101/17352 (99%)] Loss: -571.635064\n",
      "    epoch          : 1016\n",
      "    loss           : 97.14168641504986\n",
      "    val_loss       : -95.26173956345417\n",
      "Train Epoch: 1017 [512/17352 (3%)] Loss: -345.550720\n",
      "Train Epoch: 1017 [10256/17352 (59%)] Loss: -720.257595\n",
      "Train Epoch: 1017 [17064/17352 (98%)] Loss: -901.013079\n",
      "    epoch          : 1017\n",
      "    loss           : -693.1233904146029\n",
      "    val_loss       : -568.01221006076\n",
      "Train Epoch: 1018 [512/17352 (3%)] Loss: -899.533752\n",
      "Train Epoch: 1018 [10097/17352 (58%)] Loss: -775.811553\n",
      "Train Epoch: 1018 [16939/17352 (98%)] Loss: -782.105175\n",
      "    epoch          : 1018\n",
      "    loss           : -906.4464460897899\n",
      "    val_loss       : -676.0472424813903\n",
      "Train Epoch: 1019 [512/17352 (3%)] Loss: -1011.602234\n",
      "Train Epoch: 1019 [9947/17352 (57%)] Loss: -953.957168\n",
      "Train Epoch: 1019 [17108/17352 (99%)] Loss: -849.505099\n",
      "    epoch          : 1019\n",
      "    loss           : -981.9228754397146\n",
      "    val_loss       : -660.3360537689725\n",
      "Train Epoch: 1020 [512/17352 (3%)] Loss: -985.081238\n",
      "Train Epoch: 1020 [10628/17352 (61%)] Loss: -1091.122274\n",
      "Train Epoch: 1020 [17064/17352 (98%)] Loss: -1057.619934\n",
      "    epoch          : 1020\n",
      "    loss           : -999.479766419434\n",
      "    val_loss       : -711.7520712679884\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch1020.pth ...\n",
      "Train Epoch: 1021 [512/17352 (3%)] Loss: -1044.850220\n",
      "Train Epoch: 1021 [10757/17352 (62%)] Loss: -1079.714971\n",
      "Train Epoch: 1021 [17101/17352 (99%)] Loss: -1086.268829\n",
      "    epoch          : 1021\n",
      "    loss           : -1014.4462013436176\n",
      "    val_loss       : -724.6057252460728\n",
      "Train Epoch: 1022 [512/17352 (3%)] Loss: -1061.725952\n",
      "Train Epoch: 1022 [9928/17352 (57%)] Loss: -956.260054\n",
      "Train Epoch: 1022 [16878/17352 (97%)] Loss: -997.609512\n",
      "    epoch          : 1022\n",
      "    loss           : -1022.3159288527337\n",
      "    val_loss       : -716.7762355578049\n",
      "Train Epoch: 1023 [512/17352 (3%)] Loss: -1044.665527\n",
      "Train Epoch: 1023 [10022/17352 (58%)] Loss: -1070.063114\n",
      "Train Epoch: 1023 [17106/17352 (99%)] Loss: -1039.267630\n",
      "    epoch          : 1023\n",
      "    loss           : -1018.3482106608329\n",
      "    val_loss       : -739.5353370756969\n",
      "Train Epoch: 1024 [512/17352 (3%)] Loss: -1057.183838\n",
      "Train Epoch: 1024 [10649/17352 (61%)] Loss: -927.454471\n",
      "Train Epoch: 1024 [16883/17352 (97%)] Loss: -987.325827\n",
      "    epoch          : 1024\n",
      "    loss           : -1025.097711704787\n",
      "    val_loss       : -712.17239015477\n",
      "Train Epoch: 1025 [512/17352 (3%)] Loss: -1065.056641\n",
      "Train Epoch: 1025 [10490/17352 (60%)] Loss: -1120.880718\n",
      "Train Epoch: 1025 [16992/17352 (98%)] Loss: -1099.809515\n",
      "    epoch          : 1025\n",
      "    loss           : -1028.4319747928541\n",
      "    val_loss       : -735.8250272419142\n",
      "Train Epoch: 1026 [512/17352 (3%)] Loss: -1068.419556\n",
      "Train Epoch: 1026 [10583/17352 (61%)] Loss: -1160.129883\n",
      "Train Epoch: 1026 [16988/17352 (98%)] Loss: -906.676209\n",
      "    epoch          : 1026\n",
      "    loss           : -1031.7364132614525\n",
      "    val_loss       : -731.5530043482579\n",
      "Train Epoch: 1027 [512/17352 (3%)] Loss: -1076.168213\n",
      "Train Epoch: 1027 [10128/17352 (58%)] Loss: -1021.642407\n",
      "Train Epoch: 1027 [16957/17352 (98%)] Loss: -919.799971\n",
      "    epoch          : 1027\n",
      "    loss           : -1034.3464436642832\n",
      "    val_loss       : -718.1949169389328\n",
      "Train Epoch: 1028 [512/17352 (3%)] Loss: -1056.304810\n",
      "Train Epoch: 1028 [10554/17352 (61%)] Loss: -1072.568308\n",
      "Train Epoch: 1028 [16883/17352 (97%)] Loss: -1124.612234\n",
      "    epoch          : 1028\n",
      "    loss           : -1034.8330676733476\n",
      "    val_loss       : -722.2340298587235\n",
      "Train Epoch: 1029 [512/17352 (3%)] Loss: -910.047546\n",
      "Train Epoch: 1029 [10191/17352 (59%)] Loss: -1079.498568\n",
      "Train Epoch: 1029 [16922/17352 (98%)] Loss: -871.246493\n",
      "    epoch          : 1029\n",
      "    loss           : -1035.69865066072\n",
      "    val_loss       : -716.0274090110061\n",
      "Train Epoch: 1030 [512/17352 (3%)] Loss: -1070.153442\n",
      "Train Epoch: 1030 [10255/17352 (59%)] Loss: -879.209880\n",
      "Train Epoch: 1030 [17124/17352 (99%)] Loss: -992.989758\n",
      "    epoch          : 1030\n",
      "    loss           : -1031.0912223951764\n",
      "    val_loss       : -712.6275964121585\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch1030.pth ...\n",
      "Train Epoch: 1031 [512/17352 (3%)] Loss: -1088.320801\n",
      "Train Epoch: 1031 [10204/17352 (59%)] Loss: -991.288969\n",
      "Train Epoch: 1031 [16939/17352 (98%)] Loss: -974.038555\n",
      "    epoch          : 1031\n",
      "    loss           : -1036.6588931530546\n",
      "    val_loss       : -719.7376637179318\n",
      "Train Epoch: 1032 [512/17352 (3%)] Loss: -898.815674\n",
      "Train Epoch: 1032 [10884/17352 (63%)] Loss: -866.729704\n",
      "Train Epoch: 1032 [17090/17352 (98%)] Loss: -1109.209391\n",
      "    epoch          : 1032\n",
      "    loss           : -1038.2197792416441\n",
      "    val_loss       : -724.080806772783\n",
      "Train Epoch: 1033 [512/17352 (3%)] Loss: -1068.849609\n",
      "Train Epoch: 1033 [10123/17352 (58%)] Loss: -1086.341994\n",
      "Train Epoch: 1033 [17016/17352 (98%)] Loss: -1154.341684\n",
      "    epoch          : 1033\n",
      "    loss           : -1037.4627349498455\n",
      "    val_loss       : -706.7314273619274\n",
      "Train Epoch: 1034 [512/17352 (3%)] Loss: -1081.857666\n",
      "Train Epoch: 1034 [10180/17352 (59%)] Loss: -1174.266819\n",
      "Train Epoch: 1034 [17124/17352 (99%)] Loss: -1118.202927\n",
      "    epoch          : 1034\n",
      "    loss           : -1034.9455678525771\n",
      "    val_loss       : -692.1485315090763\n",
      "Train Epoch: 1035 [512/17352 (3%)] Loss: -1071.705444\n",
      "Train Epoch: 1035 [10333/17352 (60%)] Loss: -1010.379688\n",
      "Train Epoch: 1035 [16988/17352 (98%)] Loss: -988.888787\n",
      "    epoch          : 1035\n",
      "    loss           : -1018.6550247442887\n",
      "    val_loss       : -653.770701661304\n",
      "Train Epoch: 1036 [512/17352 (3%)] Loss: -1039.467285\n",
      "Train Epoch: 1036 [10737/17352 (62%)] Loss: -1048.818103\n",
      "Train Epoch: 1036 [16939/17352 (98%)] Loss: -999.473684\n",
      "    epoch          : 1036\n",
      "    loss           : -1024.8873959184593\n",
      "    val_loss       : -704.689608884112\n",
      "Train Epoch: 1037 [512/17352 (3%)] Loss: -1089.783447\n",
      "Train Epoch: 1037 [10450/17352 (60%)] Loss: -994.226562\n",
      "Train Epoch: 1037 [17106/17352 (99%)] Loss: -1066.890885\n",
      "    epoch          : 1037\n",
      "    loss           : -1040.6001401462574\n",
      "    val_loss       : -710.1159003901699\n",
      "Train Epoch: 1038 [512/17352 (3%)] Loss: -1096.385986\n",
      "Train Epoch: 1038 [10067/17352 (58%)] Loss: -1071.552214\n",
      "Train Epoch: 1038 [16887/17352 (97%)] Loss: -1018.928194\n",
      "    epoch          : 1038\n",
      "    loss           : -1042.6772043572112\n",
      "    val_loss       : -715.3127179569789\n",
      "Train Epoch: 1039 [512/17352 (3%)] Loss: -878.765564\n",
      "Train Epoch: 1039 [10468/17352 (60%)] Loss: -1150.254540\n",
      "Train Epoch: 1039 [16957/17352 (98%)] Loss: -1024.099931\n",
      "    epoch          : 1039\n",
      "    loss           : -1041.0025184243057\n",
      "    val_loss       : -710.4389709022205\n",
      "Train Epoch: 1040 [512/17352 (3%)] Loss: -1082.870117\n",
      "Train Epoch: 1040 [10157/17352 (59%)] Loss: -1080.847859\n",
      "Train Epoch: 1040 [16878/17352 (97%)] Loss: -1038.963699\n",
      "    epoch          : 1040\n",
      "    loss           : -1036.183134309046\n",
      "    val_loss       : -693.0646806408001\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch1040.pth ...\n",
      "Train Epoch: 1041 [512/17352 (3%)] Loss: -1098.226807\n",
      "Train Epoch: 1041 [10305/17352 (59%)] Loss: -907.997318\n",
      "Train Epoch: 1041 [16883/17352 (97%)] Loss: -1032.873025\n",
      "    epoch          : 1041\n",
      "    loss           : -1038.3621922544373\n",
      "    val_loss       : -706.0970971636707\n",
      "Train Epoch: 1042 [512/17352 (3%)] Loss: -1099.922363\n",
      "Train Epoch: 1042 [9766/17352 (56%)] Loss: -1112.509256\n",
      "Train Epoch: 1042 [17124/17352 (99%)] Loss: -911.506395\n",
      "    epoch          : 1042\n",
      "    loss           : -1034.815756106085\n",
      "    val_loss       : -706.7325383609653\n",
      "Train Epoch: 1043 [512/17352 (3%)] Loss: -1080.167480\n",
      "Train Epoch: 1043 [10287/17352 (59%)] Loss: -1006.522752\n",
      "Train Epoch: 1043 [16958/17352 (98%)] Loss: -1078.790204\n",
      "    epoch          : 1043\n",
      "    loss           : -1036.1705112045784\n",
      "    val_loss       : -711.0618439338248\n",
      "Train Epoch: 1044 [512/17352 (3%)] Loss: -1076.666382\n",
      "Train Epoch: 1044 [10285/17352 (59%)] Loss: -970.427347\n",
      "Train Epoch: 1044 [17049/17352 (98%)] Loss: -805.434543\n",
      "    epoch          : 1044\n",
      "    loss           : -1015.2749320175362\n",
      "    val_loss       : -621.6615939081555\n",
      "Train Epoch: 1045 [512/17352 (3%)] Loss: -1036.312988\n",
      "Train Epoch: 1045 [9888/17352 (57%)] Loss: -1011.175110\n",
      "Train Epoch: 1045 [17126/17352 (99%)] Loss: -957.117700\n",
      "    epoch          : 1045\n",
      "    loss           : -1014.8773120991863\n",
      "    val_loss       : -681.3621606563352\n",
      "Train Epoch: 1046 [512/17352 (3%)] Loss: -1064.099854\n",
      "Train Epoch: 1046 [10410/17352 (60%)] Loss: -974.294109\n",
      "Train Epoch: 1046 [17124/17352 (99%)] Loss: -964.803064\n",
      "    epoch          : 1046\n",
      "    loss           : -1032.2167145684457\n",
      "    val_loss       : -684.1314873533632\n",
      "Train Epoch: 1047 [512/17352 (3%)] Loss: -893.119446\n",
      "Train Epoch: 1047 [10226/17352 (59%)] Loss: -979.097787\n",
      "Train Epoch: 1047 [17106/17352 (99%)] Loss: -1111.249792\n",
      "    epoch          : 1047\n",
      "    loss           : -1030.9984928048016\n",
      "    val_loss       : -661.0211792775492\n",
      "Train Epoch: 1048 [512/17352 (3%)] Loss: -1071.563843\n",
      "Train Epoch: 1048 [9894/17352 (57%)] Loss: -1022.440025\n",
      "Train Epoch: 1048 [16882/17352 (97%)] Loss: -1102.906563\n",
      "    epoch          : 1048\n",
      "    loss           : -1007.1754592683928\n",
      "    val_loss       : -632.7214050512046\n",
      "Train Epoch: 1049 [512/17352 (3%)] Loss: -991.220276\n",
      "Train Epoch: 1049 [10423/17352 (60%)] Loss: -908.272877\n",
      "Train Epoch: 1049 [16872/17352 (97%)] Loss: -993.357407\n",
      "    epoch          : 1049\n",
      "    loss           : -988.543123907986\n",
      "    val_loss       : -613.1349634302686\n",
      "Train Epoch: 1050 [512/17352 (3%)] Loss: -987.281738\n",
      "Train Epoch: 1050 [10161/17352 (59%)] Loss: -822.001856\n",
      "Train Epoch: 1050 [16878/17352 (97%)] Loss: -885.792714\n",
      "    epoch          : 1050\n",
      "    loss           : -919.2478112196725\n",
      "    val_loss       : -574.4867498279029\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch1050.pth ...\n",
      "Train Epoch: 1051 [512/17352 (3%)] Loss: -915.540710\n",
      "Train Epoch: 1051 [9905/17352 (57%)] Loss: -869.508365\n",
      "Train Epoch: 1051 [17133/17352 (99%)] Loss: -885.561970\n",
      "    epoch          : 1051\n",
      "    loss           : -928.8625736177856\n",
      "    val_loss       : -321.28361857386136\n",
      "Train Epoch: 1052 [512/17352 (3%)] Loss: -745.845032\n",
      "Train Epoch: 1052 [10262/17352 (59%)] Loss: -1135.792751\n",
      "Train Epoch: 1052 [17335/17352 (100%)] Loss: -1114.458689\n",
      "    epoch          : 1052\n",
      "    loss           : -924.9605794719088\n",
      "    val_loss       : -651.2089842366\n",
      "Train Epoch: 1053 [512/17352 (3%)] Loss: -1035.328369\n",
      "Train Epoch: 1053 [10314/17352 (59%)] Loss: -1153.938260\n",
      "Train Epoch: 1053 [17133/17352 (99%)] Loss: -1013.084736\n",
      "    epoch          : 1053\n",
      "    loss           : -1019.7319975096726\n",
      "    val_loss       : -673.6034709826334\n",
      "Train Epoch: 1054 [512/17352 (3%)] Loss: -1071.532959\n",
      "Train Epoch: 1054 [10243/17352 (59%)] Loss: -964.382626\n",
      "Train Epoch: 1054 [17049/17352 (98%)] Loss: -1022.837674\n",
      "    epoch          : 1054\n",
      "    loss           : -1022.3663290066252\n",
      "    val_loss       : -686.189376887937\n",
      "Train Epoch: 1055 [512/17352 (3%)] Loss: -1069.412354\n",
      "Train Epoch: 1055 [9997/17352 (58%)] Loss: -1120.567952\n",
      "Train Epoch: 1055 [16992/17352 (98%)] Loss: -1032.092122\n",
      "    epoch          : 1055\n",
      "    loss           : -990.1463699616922\n",
      "    val_loss       : -612.5868528167563\n",
      "Train Epoch: 1056 [512/17352 (3%)] Loss: -987.662415\n",
      "Train Epoch: 1056 [10699/17352 (62%)] Loss: -649.010484\n",
      "Train Epoch: 1056 [17126/17352 (99%)] Loss: -1039.453390\n",
      "    epoch          : 1056\n",
      "    loss           : -942.5581157168656\n",
      "    val_loss       : -630.0596615787724\n",
      "Train Epoch: 1057 [512/17352 (3%)] Loss: -991.997437\n",
      "Train Epoch: 1057 [10548/17352 (61%)] Loss: -1038.849167\n",
      "Train Epoch: 1057 [17133/17352 (99%)] Loss: -994.741924\n",
      "    epoch          : 1057\n",
      "    loss           : -937.0056059787736\n",
      "    val_loss       : -618.6929407264242\n",
      "Train Epoch: 1058 [512/17352 (3%)] Loss: -1009.059692\n",
      "Train Epoch: 1058 [10427/17352 (60%)] Loss: -1071.005711\n",
      "Train Epoch: 1058 [17335/17352 (100%)] Loss: -1118.893614\n",
      "    epoch          : 1058\n",
      "    loss           : -986.8187868242672\n",
      "    val_loss       : -669.6636754778931\n",
      "Train Epoch: 1059 [512/17352 (3%)] Loss: -1057.458496\n",
      "Train Epoch: 1059 [10036/17352 (58%)] Loss: -1102.298750\n",
      "Train Epoch: 1059 [16992/17352 (98%)] Loss: -1076.470890\n",
      "    epoch          : 1059\n",
      "    loss           : -1006.8950277245332\n",
      "    val_loss       : -629.7140972252394\n",
      "Train Epoch: 1060 [512/17352 (3%)] Loss: -1030.187012\n",
      "Train Epoch: 1060 [10880/17352 (63%)] Loss: -997.042331\n",
      "Train Epoch: 1060 [17335/17352 (100%)] Loss: -794.444204\n",
      "    epoch          : 1060\n",
      "    loss           : -935.8968893110796\n",
      "    val_loss       : -635.091934115779\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch1060.pth ...\n",
      "Train Epoch: 1061 [512/17352 (3%)] Loss: -997.936646\n",
      "Train Epoch: 1061 [10555/17352 (61%)] Loss: -1018.282109\n",
      "Train Epoch: 1061 [16878/17352 (97%)] Loss: -962.102070\n",
      "    epoch          : 1061\n",
      "    loss           : -998.1547015362279\n",
      "    val_loss       : -698.435393524949\n",
      "Train Epoch: 1062 [512/17352 (3%)] Loss: -1052.680420\n",
      "Train Epoch: 1062 [10140/17352 (58%)] Loss: -915.049534\n",
      "Train Epoch: 1062 [17124/17352 (99%)] Loss: -977.538194\n",
      "    epoch          : 1062\n",
      "    loss           : -1022.3838545381582\n",
      "    val_loss       : -687.6176809286073\n",
      "Train Epoch: 1063 [512/17352 (3%)] Loss: -1066.616333\n",
      "Train Epoch: 1063 [9924/17352 (57%)] Loss: -966.667279\n",
      "Train Epoch: 1063 [17044/17352 (98%)] Loss: -1022.116693\n",
      "    epoch          : 1063\n",
      "    loss           : -1025.1891340564382\n",
      "    val_loss       : -668.0655612764243\n",
      "Train Epoch: 1064 [512/17352 (3%)] Loss: -866.824890\n",
      "Train Epoch: 1064 [10128/17352 (58%)] Loss: -1153.561301\n",
      "Train Epoch: 1064 [16988/17352 (98%)] Loss: -880.395965\n",
      "    epoch          : 1064\n",
      "    loss           : -1013.3245640822986\n",
      "    val_loss       : -586.2250360408548\n",
      "Train Epoch: 1065 [512/17352 (3%)] Loss: -963.875366\n",
      "Train Epoch: 1065 [10306/17352 (59%)] Loss: -1015.154362\n",
      "Train Epoch: 1065 [16922/17352 (98%)] Loss: -938.204951\n",
      "    epoch          : 1065\n",
      "    loss           : -964.3104972277563\n",
      "    val_loss       : -680.8250734807752\n",
      "Train Epoch: 1066 [512/17352 (3%)] Loss: -1065.883545\n",
      "Train Epoch: 1066 [9780/17352 (56%)] Loss: -871.246184\n",
      "Train Epoch: 1066 [16992/17352 (98%)] Loss: -1014.120265\n",
      "    epoch          : 1066\n",
      "    loss           : -1011.9565259183271\n",
      "    val_loss       : -691.5368995476342\n",
      "Train Epoch: 1067 [512/17352 (3%)] Loss: -1082.336914\n",
      "Train Epoch: 1067 [10324/17352 (59%)] Loss: -1153.944007\n",
      "Train Epoch: 1067 [17106/17352 (99%)] Loss: -972.004226\n",
      "    epoch          : 1067\n",
      "    loss           : -1029.9836840060293\n",
      "    val_loss       : -658.6320095770385\n",
      "Train Epoch: 1068 [512/17352 (3%)] Loss: -1071.552002\n",
      "Train Epoch: 1068 [10075/17352 (58%)] Loss: -1084.366875\n",
      "Train Epoch: 1068 [17126/17352 (99%)] Loss: -1108.684593\n",
      "    epoch          : 1068\n",
      "    loss           : -1035.0578039470524\n",
      "    val_loss       : -674.371689228677\n",
      "Train Epoch: 1069 [512/17352 (3%)] Loss: -1071.984375\n",
      "Train Epoch: 1069 [10184/17352 (59%)] Loss: -916.624709\n",
      "Train Epoch: 1069 [16934/17352 (98%)] Loss: -992.054516\n",
      "    epoch          : 1069\n",
      "    loss           : -1029.7206876381467\n",
      "    val_loss       : -714.3695657513363\n",
      "Train Epoch: 1070 [512/17352 (3%)] Loss: -1088.085205\n",
      "Train Epoch: 1070 [10262/17352 (59%)] Loss: -1103.326890\n",
      "Train Epoch: 1070 [16939/17352 (98%)] Loss: -952.621753\n",
      "    epoch          : 1070\n",
      "    loss           : -1036.7387778080456\n",
      "    val_loss       : -699.9944296775079\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch1070.pth ...\n",
      "Train Epoch: 1071 [512/17352 (3%)] Loss: -1097.716553\n",
      "Train Epoch: 1071 [10020/17352 (58%)] Loss: -971.212022\n",
      "Train Epoch: 1071 [17253/17352 (99%)] Loss: -1008.880003\n",
      "    epoch          : 1071\n",
      "    loss           : -1036.6084657584727\n",
      "    val_loss       : -677.9905105520508\n",
      "Train Epoch: 1072 [512/17352 (3%)] Loss: -1084.930664\n",
      "Train Epoch: 1072 [10281/17352 (59%)] Loss: -1052.418359\n",
      "Train Epoch: 1072 [16878/17352 (97%)] Loss: -984.212155\n",
      "    epoch          : 1072\n",
      "    loss           : -1035.561910990484\n",
      "    val_loss       : -700.9691725613786\n",
      "Train Epoch: 1073 [512/17352 (3%)] Loss: -1085.417725\n",
      "Train Epoch: 1073 [10210/17352 (59%)] Loss: -972.937692\n",
      "Train Epoch: 1073 [17101/17352 (99%)] Loss: -867.542182\n",
      "    epoch          : 1073\n",
      "    loss           : -1040.1162067662074\n",
      "    val_loss       : -685.3259516915011\n",
      "Train Epoch: 1074 [512/17352 (3%)] Loss: -1050.174561\n",
      "Train Epoch: 1074 [10426/17352 (60%)] Loss: -803.032738\n",
      "Train Epoch: 1074 [17108/17352 (99%)] Loss: -889.465417\n",
      "    epoch          : 1074\n",
      "    loss           : -841.6133647173721\n",
      "    val_loss       : -556.0625391511014\n",
      "Train Epoch: 1075 [512/17352 (3%)] Loss: -868.769226\n",
      "Train Epoch: 1075 [10347/17352 (60%)] Loss: -1036.448736\n",
      "Train Epoch: 1075 [16992/17352 (98%)] Loss: -705.867972\n",
      "    epoch          : 1075\n",
      "    loss           : -924.1736671691881\n",
      "    val_loss       : -516.1437856522655\n",
      "Train Epoch: 1076 [512/17352 (3%)] Loss: -890.826721\n",
      "Train Epoch: 1076 [10270/17352 (59%)] Loss: -600.604036\n",
      "Train Epoch: 1076 [16939/17352 (98%)] Loss: -904.029342\n",
      "    epoch          : 1076\n",
      "    loss           : -829.3459899647307\n",
      "    val_loss       : -568.498459467659\n",
      "Train Epoch: 1077 [512/17352 (3%)] Loss: -961.485840\n",
      "Train Epoch: 1077 [10291/17352 (59%)] Loss: -1081.069559\n",
      "Train Epoch: 1077 [17126/17352 (99%)] Loss: -508.020733\n",
      "    epoch          : 1077\n",
      "    loss           : -897.0304542795442\n",
      "    val_loss       : -56.05856868092362\n",
      "Train Epoch: 1078 [512/17352 (3%)] Loss: -592.536255\n",
      "Train Epoch: 1078 [10225/17352 (59%)] Loss: -757.399184\n",
      "Train Epoch: 1078 [16992/17352 (98%)] Loss: -927.610918\n",
      "    epoch          : 1078\n",
      "    loss           : -721.294628023431\n",
      "    val_loss       : -343.16286907607883\n",
      "Train Epoch: 1079 [512/17352 (3%)] Loss: -682.362610\n",
      "Train Epoch: 1079 [10025/17352 (58%)] Loss: -366.453536\n",
      "Train Epoch: 1079 [17064/17352 (98%)] Loss: -610.797112\n",
      "    epoch          : 1079\n",
      "    loss           : -763.3304373656044\n",
      "    val_loss       : -548.9949393620572\n",
      "Train Epoch: 1080 [512/17352 (3%)] Loss: -899.544189\n",
      "Train Epoch: 1080 [10391/17352 (60%)] Loss: -898.937201\n",
      "Train Epoch: 1080 [17263/17352 (99%)] Loss: -801.642533\n",
      "    epoch          : 1080\n",
      "    loss           : -948.8047570424204\n",
      "    val_loss       : -480.4220135667456\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch1080.pth ...\n",
      "Train Epoch: 1081 [512/17352 (3%)] Loss: -860.852600\n",
      "Train Epoch: 1081 [10378/17352 (60%)] Loss: -853.415520\n",
      "Train Epoch: 1081 [16882/17352 (97%)] Loss: -1037.009836\n",
      "    epoch          : 1081\n",
      "    loss           : -980.2371663070427\n",
      "    val_loss       : -671.4176751570753\n",
      "Train Epoch: 1082 [512/17352 (3%)] Loss: -1055.721069\n",
      "Train Epoch: 1082 [10042/17352 (58%)] Loss: -1034.209762\n",
      "Train Epoch: 1082 [16882/17352 (97%)] Loss: -1048.197638\n",
      "    epoch          : 1082\n",
      "    loss           : -1016.6741610094821\n",
      "    val_loss       : -699.3983467933797\n",
      "Train Epoch: 1083 [512/17352 (3%)] Loss: -873.945496\n",
      "Train Epoch: 1083 [10329/17352 (60%)] Loss: -1116.304370\n",
      "Train Epoch: 1083 [16872/17352 (97%)] Loss: -1102.730162\n",
      "    epoch          : 1083\n",
      "    loss           : -1022.9343973008823\n",
      "    val_loss       : -694.1771086469037\n",
      "Train Epoch: 1084 [512/17352 (3%)] Loss: -1065.780762\n",
      "Train Epoch: 1084 [10620/17352 (61%)] Loss: -885.754813\n",
      "Train Epoch: 1084 [16923/17352 (98%)] Loss: -921.379352\n",
      "    epoch          : 1084\n",
      "    loss           : -1007.3961768691629\n",
      "    val_loss       : -658.0190054967406\n",
      "Train Epoch: 1085 [512/17352 (3%)] Loss: -829.004395\n",
      "Train Epoch: 1085 [9869/17352 (57%)] Loss: -1081.225722\n",
      "Train Epoch: 1085 [16883/17352 (97%)] Loss: -1130.184197\n",
      "    epoch          : 1085\n",
      "    loss           : -1020.8799134221932\n",
      "    val_loss       : -694.552399682644\n",
      "Train Epoch: 1086 [512/17352 (3%)] Loss: -1091.772217\n",
      "Train Epoch: 1086 [10178/17352 (59%)] Loss: -1096.633515\n",
      "Train Epoch: 1086 [16887/17352 (97%)] Loss: -1126.470812\n",
      "    epoch          : 1086\n",
      "    loss           : -1038.680916874759\n",
      "    val_loss       : -724.4092311725593\n",
      "Train Epoch: 1087 [512/17352 (3%)] Loss: -1103.909668\n",
      "Train Epoch: 1087 [10208/17352 (59%)] Loss: -1190.904622\n",
      "Train Epoch: 1087 [16878/17352 (97%)] Loss: -972.748277\n",
      "    epoch          : 1087\n",
      "    loss           : -1040.1443523216328\n",
      "    val_loss       : -678.9321829120302\n",
      "Train Epoch: 1088 [512/17352 (3%)] Loss: -1081.817627\n",
      "Train Epoch: 1088 [10474/17352 (60%)] Loss: -1133.383257\n",
      "Train Epoch: 1088 [16872/17352 (97%)] Loss: -1015.877757\n",
      "    epoch          : 1088\n",
      "    loss           : -1046.4347056515828\n",
      "    val_loss       : -712.4865323134762\n",
      "Train Epoch: 1089 [512/17352 (3%)] Loss: -1100.124268\n",
      "Train Epoch: 1089 [10433/17352 (60%)] Loss: -1165.995611\n",
      "Train Epoch: 1089 [16958/17352 (98%)] Loss: -1144.753085\n",
      "    epoch          : 1089\n",
      "    loss           : -1044.0879287502707\n",
      "    val_loss       : -695.5955465670656\n",
      "Train Epoch: 1090 [512/17352 (3%)] Loss: -1064.537231\n",
      "Train Epoch: 1090 [10618/17352 (61%)] Loss: -995.991164\n",
      "Train Epoch: 1090 [16934/17352 (98%)] Loss: -852.655108\n",
      "    epoch          : 1090\n",
      "    loss           : -1030.1550758852702\n",
      "    val_loss       : -641.465198919589\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch1090.pth ...\n",
      "Train Epoch: 1091 [512/17352 (3%)] Loss: -1070.214966\n",
      "Train Epoch: 1091 [10057/17352 (58%)] Loss: -1074.743359\n",
      "Train Epoch: 1091 [17064/17352 (98%)] Loss: -1115.450000\n",
      "    epoch          : 1091\n",
      "    loss           : -1038.4904986019083\n",
      "    val_loss       : -705.624783305329\n",
      "Train Epoch: 1092 [512/17352 (3%)] Loss: -1081.289917\n",
      "Train Epoch: 1092 [10005/17352 (58%)] Loss: -1062.876693\n",
      "Train Epoch: 1092 [16992/17352 (98%)] Loss: -1130.275133\n",
      "    epoch          : 1092\n",
      "    loss           : -1020.7558230565293\n",
      "    val_loss       : -674.3177876520514\n",
      "Train Epoch: 1093 [512/17352 (3%)] Loss: -1077.563477\n",
      "Train Epoch: 1093 [10350/17352 (60%)] Loss: -1099.792671\n",
      "Train Epoch: 1093 [17101/17352 (99%)] Loss: -1050.702604\n",
      "    epoch          : 1093\n",
      "    loss           : -1034.0233154278442\n",
      "    val_loss       : -685.8628526511893\n",
      "Train Epoch: 1094 [512/17352 (3%)] Loss: -1079.721313\n",
      "Train Epoch: 1094 [9667/17352 (56%)] Loss: -957.764419\n",
      "Train Epoch: 1094 [17143/17352 (99%)] Loss: -1071.137195\n",
      "    epoch          : 1094\n",
      "    loss           : -989.7785575799695\n",
      "    val_loss       : -491.47325542645467\n",
      "Train Epoch: 1095 [512/17352 (3%)] Loss: -949.381165\n",
      "Train Epoch: 1095 [10351/17352 (60%)] Loss: -877.281901\n",
      "Train Epoch: 1095 [16957/17352 (98%)] Loss: -756.636812\n",
      "    epoch          : 1095\n",
      "    loss           : -946.7152132968926\n",
      "    val_loss       : -597.4537221158218\n",
      "Train Epoch: 1096 [512/17352 (3%)] Loss: -943.119324\n",
      "Train Epoch: 1096 [10558/17352 (61%)] Loss: -1024.682812\n",
      "Train Epoch: 1096 [17124/17352 (99%)] Loss: -999.343883\n",
      "    epoch          : 1096\n",
      "    loss           : -962.1341212917916\n",
      "    val_loss       : -524.0609462759011\n",
      "Train Epoch: 1097 [512/17352 (3%)] Loss: -913.549561\n",
      "Train Epoch: 1097 [9850/17352 (57%)] Loss: -993.742088\n",
      "Train Epoch: 1097 [17108/17352 (99%)] Loss: -1056.635073\n",
      "    epoch          : 1097\n",
      "    loss           : -932.6726050790837\n",
      "    val_loss       : -601.9169272836513\n",
      "Train Epoch: 1098 [512/17352 (3%)] Loss: -1010.976196\n",
      "Train Epoch: 1098 [10190/17352 (59%)] Loss: -1011.880208\n",
      "Train Epoch: 1098 [16878/17352 (97%)] Loss: -998.880757\n",
      "    epoch          : 1098\n",
      "    loss           : -955.7872712244465\n",
      "    val_loss       : -675.6356175410182\n",
      "Train Epoch: 1099 [512/17352 (3%)] Loss: -1066.611206\n",
      "Train Epoch: 1099 [10301/17352 (59%)] Loss: -1117.152205\n",
      "Train Epoch: 1099 [17124/17352 (99%)] Loss: -1141.134195\n",
      "    epoch          : 1099\n",
      "    loss           : -1016.4615501671506\n",
      "    val_loss       : -677.5091303469792\n",
      "Train Epoch: 1100 [512/17352 (3%)] Loss: -1084.776489\n",
      "Train Epoch: 1100 [10491/17352 (60%)] Loss: -1099.436447\n",
      "Train Epoch: 1100 [17106/17352 (99%)] Loss: -1047.891250\n",
      "    epoch          : 1100\n",
      "    loss           : -1023.9139986840269\n",
      "    val_loss       : -661.874931239089\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch1100.pth ...\n",
      "Train Epoch: 1101 [512/17352 (3%)] Loss: -1067.268799\n",
      "Train Epoch: 1101 [10438/17352 (60%)] Loss: -1077.509810\n",
      "Train Epoch: 1101 [17016/17352 (98%)] Loss: -1160.018121\n",
      "    epoch          : 1101\n",
      "    loss           : -1007.7440437529027\n",
      "    val_loss       : -690.2354341287257\n",
      "Train Epoch: 1102 [512/17352 (3%)] Loss: -1050.773804\n",
      "Train Epoch: 1102 [9758/17352 (56%)] Loss: -1028.377292\n",
      "Train Epoch: 1102 [16957/17352 (98%)] Loss: -1058.759440\n",
      "    epoch          : 1102\n",
      "    loss           : -1017.3285224758519\n",
      "    val_loss       : -638.0520919824158\n",
      "Train Epoch: 1103 [512/17352 (3%)] Loss: -1027.561279\n",
      "Train Epoch: 1103 [10770/17352 (62%)] Loss: -1110.585759\n",
      "Train Epoch: 1103 [16958/17352 (98%)] Loss: -1125.653223\n",
      "    epoch          : 1103\n",
      "    loss           : -1013.639790951858\n",
      "    val_loss       : -675.9004053647623\n",
      "Train Epoch: 1104 [512/17352 (3%)] Loss: -1068.913086\n",
      "Train Epoch: 1104 [10408/17352 (60%)] Loss: -826.199206\n",
      "Train Epoch: 1104 [16922/17352 (98%)] Loss: -881.484339\n",
      "    epoch          : 1104\n",
      "    loss           : -999.9385530991825\n",
      "    val_loss       : -654.0701843352691\n",
      "Train Epoch: 1105 [512/17352 (3%)] Loss: -1049.422363\n",
      "Train Epoch: 1105 [10533/17352 (61%)] Loss: -1095.806771\n",
      "Train Epoch: 1105 [16934/17352 (98%)] Loss: -1102.270277\n",
      "    epoch          : 1105\n",
      "    loss           : -1014.6625538759941\n",
      "    val_loss       : -712.7021092675011\n",
      "Train Epoch: 1106 [512/17352 (3%)] Loss: -1083.038574\n",
      "Train Epoch: 1106 [10661/17352 (61%)] Loss: -1010.501860\n",
      "Train Epoch: 1106 [17277/17352 (100%)] Loss: -1087.523712\n",
      "    epoch          : 1106\n",
      "    loss           : -1027.618752399132\n",
      "    val_loss       : -667.699721693911\n",
      "Train Epoch: 1107 [512/17352 (3%)] Loss: -1047.885498\n",
      "Train Epoch: 1107 [10754/17352 (62%)] Loss: -1161.560235\n",
      "Train Epoch: 1107 [16923/17352 (98%)] Loss: -1100.795733\n",
      "    epoch          : 1107\n",
      "    loss           : -1038.513019417615\n",
      "    val_loss       : -694.39001011798\n",
      "Train Epoch: 1108 [512/17352 (3%)] Loss: -1066.965576\n",
      "Train Epoch: 1108 [10161/17352 (59%)] Loss: -959.837358\n",
      "Train Epoch: 1108 [17049/17352 (98%)] Loss: -1074.616016\n",
      "    epoch          : 1108\n",
      "    loss           : -1050.8459940671846\n",
      "    val_loss       : -702.6197740996673\n",
      "Train Epoch: 1109 [512/17352 (3%)] Loss: -892.635132\n",
      "Train Epoch: 1109 [10254/17352 (59%)] Loss: -996.793056\n",
      "Train Epoch: 1109 [16988/17352 (98%)] Loss: -963.490572\n",
      "    epoch          : 1109\n",
      "    loss           : -1051.3875685490714\n",
      "    val_loss       : -697.609064650445\n",
      "Train Epoch: 1110 [512/17352 (3%)] Loss: -1076.442993\n",
      "Train Epoch: 1110 [9931/17352 (57%)] Loss: -1020.809637\n",
      "Train Epoch: 1110 [17049/17352 (98%)] Loss: -1086.121094\n",
      "    epoch          : 1110\n",
      "    loss           : -1036.6398566533112\n",
      "    val_loss       : -685.4104661580437\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch1110.pth ...\n",
      "Train Epoch: 1111 [512/17352 (3%)] Loss: -1090.018555\n",
      "Train Epoch: 1111 [10881/17352 (63%)] Loss: -1102.993954\n",
      "Train Epoch: 1111 [17064/17352 (98%)] Loss: -1172.120203\n",
      "    epoch          : 1111\n",
      "    loss           : -1058.3272714646737\n",
      "    val_loss       : -712.7943622329955\n",
      "Train Epoch: 1112 [512/17352 (3%)] Loss: -1108.653564\n",
      "Train Epoch: 1112 [10263/17352 (59%)] Loss: -1047.359375\n",
      "Train Epoch: 1112 [16922/17352 (98%)] Loss: -1137.642529\n",
      "    epoch          : 1112\n",
      "    loss           : -1049.2584368313144\n",
      "    val_loss       : -719.342877663863\n",
      "Train Epoch: 1113 [512/17352 (3%)] Loss: -1089.191895\n",
      "Train Epoch: 1113 [10500/17352 (61%)] Loss: -979.268989\n",
      "Train Epoch: 1113 [17101/17352 (99%)] Loss: -1020.250553\n",
      "    epoch          : 1113\n",
      "    loss           : -1033.5032354551738\n",
      "    val_loss       : -684.8664615752266\n",
      "Train Epoch: 1114 [512/17352 (3%)] Loss: -1087.555176\n",
      "Train Epoch: 1114 [10576/17352 (61%)] Loss: -1094.689617\n",
      "Train Epoch: 1114 [16939/17352 (98%)] Loss: -1137.899390\n",
      "    epoch          : 1114\n",
      "    loss           : -1038.666886199088\n",
      "    val_loss       : -691.7678491856661\n",
      "Train Epoch: 1115 [512/17352 (3%)] Loss: -1103.118896\n",
      "Train Epoch: 1115 [9878/17352 (57%)] Loss: -1041.751717\n",
      "Train Epoch: 1115 [17126/17352 (99%)] Loss: -955.527025\n",
      "    epoch          : 1115\n",
      "    loss           : -1051.2311144654147\n",
      "    val_loss       : -711.174592737555\n",
      "Train Epoch: 1116 [512/17352 (3%)] Loss: -1088.479858\n",
      "Train Epoch: 1116 [10051/17352 (58%)] Loss: -934.848804\n",
      "Train Epoch: 1116 [16939/17352 (98%)] Loss: -1125.698773\n",
      "    epoch          : 1116\n",
      "    loss           : -1060.7335348230324\n",
      "    val_loss       : -712.5753976583455\n",
      "Train Epoch: 1117 [512/17352 (3%)] Loss: -1106.108154\n",
      "Train Epoch: 1117 [10701/17352 (62%)] Loss: -1188.771055\n",
      "Train Epoch: 1117 [17044/17352 (98%)] Loss: -1164.888544\n",
      "    epoch          : 1117\n",
      "    loss           : -1061.395533438136\n",
      "    val_loss       : -700.9945021420721\n",
      "Train Epoch: 1118 [512/17352 (3%)] Loss: -1108.794922\n",
      "Train Epoch: 1118 [10132/17352 (58%)] Loss: -1105.011205\n",
      "Train Epoch: 1118 [17253/17352 (99%)] Loss: -1164.518992\n",
      "    epoch          : 1118\n",
      "    loss           : -1055.189794467601\n",
      "    val_loss       : -676.3189476039395\n",
      "Train Epoch: 1119 [512/17352 (3%)] Loss: -1070.953125\n",
      "Train Epoch: 1119 [10589/17352 (61%)] Loss: -1166.219734\n",
      "Train Epoch: 1119 [16923/17352 (98%)] Loss: -882.525731\n",
      "    epoch          : 1119\n",
      "    loss           : -1009.6316372053124\n",
      "    val_loss       : -497.9655204665292\n",
      "Train Epoch: 1120 [512/17352 (3%)] Loss: -928.922913\n",
      "Train Epoch: 1120 [9966/17352 (57%)] Loss: -892.223958\n",
      "Train Epoch: 1120 [16958/17352 (98%)] Loss: -857.687324\n",
      "    epoch          : 1120\n",
      "    loss           : -853.4675989522842\n",
      "    val_loss       : -558.921645350094\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch1120.pth ...\n",
      "Train Epoch: 1121 [512/17352 (3%)] Loss: -927.398743\n",
      "Train Epoch: 1121 [10743/17352 (62%)] Loss: -1068.861992\n",
      "Train Epoch: 1121 [16934/17352 (98%)] Loss: -1023.370603\n",
      "    epoch          : 1121\n",
      "    loss           : -960.8367079729577\n",
      "    val_loss       : -641.9252972619207\n",
      "Train Epoch: 1122 [512/17352 (3%)] Loss: -1052.968994\n",
      "Train Epoch: 1122 [10133/17352 (58%)] Loss: -845.363967\n",
      "Train Epoch: 1122 [17044/17352 (98%)] Loss: -913.007465\n",
      "    epoch          : 1122\n",
      "    loss           : -927.0429856084958\n",
      "    val_loss       : -628.5558496591156\n",
      "Train Epoch: 1123 [512/17352 (3%)] Loss: -1034.530518\n",
      "Train Epoch: 1123 [10474/17352 (60%)] Loss: -1110.293354\n",
      "Train Epoch: 1123 [16934/17352 (98%)] Loss: -1039.922425\n",
      "    epoch          : 1123\n",
      "    loss           : -997.9807606391947\n",
      "    val_loss       : -673.9727103166117\n",
      "Train Epoch: 1124 [512/17352 (3%)] Loss: -1068.547363\n",
      "Train Epoch: 1124 [10200/17352 (59%)] Loss: -1023.337597\n",
      "Train Epoch: 1124 [17277/17352 (100%)] Loss: -1110.659232\n",
      "    epoch          : 1124\n",
      "    loss           : -1034.4552797588308\n",
      "    val_loss       : -597.4528675845744\n",
      "Train Epoch: 1125 [512/17352 (3%)] Loss: -988.847473\n",
      "Train Epoch: 1125 [9975/17352 (57%)] Loss: -962.976178\n",
      "Train Epoch: 1125 [17153/17352 (99%)] Loss: -1116.930126\n",
      "    epoch          : 1125\n",
      "    loss           : -1021.6644809788297\n",
      "    val_loss       : -666.1906170659363\n",
      "Train Epoch: 1126 [512/17352 (3%)] Loss: -1074.504028\n",
      "Train Epoch: 1126 [9758/17352 (56%)] Loss: -961.292016\n",
      "Train Epoch: 1126 [17126/17352 (99%)] Loss: -932.095857\n",
      "    epoch          : 1126\n",
      "    loss           : -966.6172397590618\n",
      "    val_loss       : -609.3468232120938\n",
      "Train Epoch: 1127 [512/17352 (3%)] Loss: -1018.028503\n",
      "Train Epoch: 1127 [10401/17352 (60%)] Loss: -879.684441\n",
      "Train Epoch: 1127 [16934/17352 (98%)] Loss: -1075.739146\n",
      "    epoch          : 1127\n",
      "    loss           : -1009.8612744291637\n",
      "    val_loss       : -670.3508453501785\n",
      "Train Epoch: 1128 [512/17352 (3%)] Loss: -1051.584229\n",
      "Train Epoch: 1128 [10467/17352 (60%)] Loss: -1164.594083\n",
      "Train Epoch: 1128 [17253/17352 (99%)] Loss: -894.630712\n",
      "    epoch          : 1128\n",
      "    loss           : -1017.1794415650555\n",
      "    val_loss       : -668.4441164632041\n",
      "Train Epoch: 1129 [512/17352 (3%)] Loss: -1059.205200\n",
      "Train Epoch: 1129 [9818/17352 (57%)] Loss: -1080.347745\n",
      "Train Epoch: 1129 [16872/17352 (97%)] Loss: -883.934946\n",
      "    epoch          : 1129\n",
      "    loss           : -1050.1097620235057\n",
      "    val_loss       : -689.8763410956194\n",
      "Train Epoch: 1130 [512/17352 (3%)] Loss: -920.902588\n",
      "Train Epoch: 1130 [10923/17352 (63%)] Loss: -927.950830\n",
      "Train Epoch: 1130 [16883/17352 (97%)] Loss: -1045.542352\n",
      "    epoch          : 1130\n",
      "    loss           : -1059.2305821087152\n",
      "    val_loss       : -679.683980570604\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch1130.pth ...\n",
      "Train Epoch: 1131 [512/17352 (3%)] Loss: -1097.181396\n",
      "Train Epoch: 1131 [10044/17352 (58%)] Loss: -1109.154846\n",
      "Train Epoch: 1131 [17153/17352 (99%)] Loss: -961.329733\n",
      "    epoch          : 1131\n",
      "    loss           : -1052.0958030544305\n",
      "    val_loss       : -673.7825819022701\n",
      "Train Epoch: 1132 [512/17352 (3%)] Loss: -1090.562500\n",
      "Train Epoch: 1132 [10035/17352 (58%)] Loss: -1087.927932\n",
      "Train Epoch: 1132 [17335/17352 (100%)] Loss: -924.216584\n",
      "    epoch          : 1132\n",
      "    loss           : -1047.212685974526\n",
      "    val_loss       : -695.4734837897731\n",
      "Train Epoch: 1133 [512/17352 (3%)] Loss: -1102.603027\n",
      "Train Epoch: 1133 [10144/17352 (58%)] Loss: -1156.741139\n",
      "Train Epoch: 1133 [17124/17352 (99%)] Loss: -1182.097331\n",
      "    epoch          : 1133\n",
      "    loss           : -1057.2926499828907\n",
      "    val_loss       : -695.1108038982045\n",
      "Train Epoch: 1134 [512/17352 (3%)] Loss: -1100.941650\n",
      "Train Epoch: 1134 [10524/17352 (61%)] Loss: -967.235390\n",
      "Train Epoch: 1134 [17124/17352 (99%)] Loss: -874.542904\n",
      "    epoch          : 1134\n",
      "    loss           : -1049.5780287063685\n",
      "    val_loss       : -665.6695383561637\n",
      "Train Epoch: 1135 [512/17352 (3%)] Loss: -1072.804565\n",
      "Train Epoch: 1135 [10660/17352 (61%)] Loss: -1145.921796\n",
      "Train Epoch: 1135 [17153/17352 (99%)] Loss: -745.511247\n",
      "    epoch          : 1135\n",
      "    loss           : -1015.3968331156899\n",
      "    val_loss       : -451.03680347232796\n",
      "Train Epoch: 1136 [512/17352 (3%)] Loss: -848.357971\n",
      "Train Epoch: 1136 [10770/17352 (62%)] Loss: -691.076181\n",
      "Train Epoch: 1136 [17253/17352 (99%)] Loss: -1074.182991\n",
      "    epoch          : 1136\n",
      "    loss           : -911.4325504583624\n",
      "    val_loss       : -519.845786014356\n",
      "Train Epoch: 1137 [512/17352 (3%)] Loss: -921.931580\n",
      "Train Epoch: 1137 [9937/17352 (57%)] Loss: -1074.439687\n",
      "Train Epoch: 1137 [16887/17352 (97%)] Loss: -1067.865289\n",
      "    epoch          : 1137\n",
      "    loss           : -952.7915807966216\n",
      "    val_loss       : -676.1381486068877\n",
      "Train Epoch: 1138 [512/17352 (3%)] Loss: -1072.774658\n",
      "Train Epoch: 1138 [10858/17352 (63%)] Loss: -1123.735522\n",
      "Train Epoch: 1138 [17277/17352 (100%)] Loss: -733.161407\n",
      "    epoch          : 1138\n",
      "    loss           : -1007.0200796169471\n",
      "    val_loss       : -664.4776742227086\n",
      "Train Epoch: 1139 [512/17352 (3%)] Loss: -1065.728760\n",
      "Train Epoch: 1139 [10611/17352 (61%)] Loss: -970.151910\n",
      "Train Epoch: 1139 [16934/17352 (98%)] Loss: -953.285028\n",
      "    epoch          : 1139\n",
      "    loss           : -1010.3666578951772\n",
      "    val_loss       : -668.6431402719122\n",
      "Train Epoch: 1140 [512/17352 (3%)] Loss: -1049.983154\n",
      "Train Epoch: 1140 [9797/17352 (56%)] Loss: -1123.937917\n",
      "Train Epoch: 1140 [16934/17352 (98%)] Loss: -970.738265\n",
      "    epoch          : 1140\n",
      "    loss           : -1036.617094170774\n",
      "    val_loss       : -637.1114589285828\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch1140.pth ...\n",
      "Train Epoch: 1141 [512/17352 (3%)] Loss: -1045.456055\n",
      "Train Epoch: 1141 [10781/17352 (62%)] Loss: -1100.199203\n",
      "Train Epoch: 1141 [16939/17352 (98%)] Loss: -1141.096044\n",
      "    epoch          : 1141\n",
      "    loss           : -1044.7393482186976\n",
      "    val_loss       : -689.7429508408625\n",
      "Train Epoch: 1142 [512/17352 (3%)] Loss: -1098.069580\n",
      "Train Epoch: 1142 [10496/17352 (60%)] Loss: -1006.862961\n",
      "Train Epoch: 1142 [16882/17352 (97%)] Loss: -873.366550\n",
      "    epoch          : 1142\n",
      "    loss           : -1037.0757449400146\n",
      "    val_loss       : -659.0811607606298\n",
      "Train Epoch: 1143 [512/17352 (3%)] Loss: -1084.980591\n",
      "Train Epoch: 1143 [10248/17352 (59%)] Loss: -1059.819068\n",
      "Train Epoch: 1143 [17064/17352 (98%)] Loss: -882.458836\n",
      "    epoch          : 1143\n",
      "    loss           : -934.2511847280581\n",
      "    val_loss       : -582.107154399805\n",
      "Train Epoch: 1144 [512/17352 (3%)] Loss: -994.410522\n",
      "Train Epoch: 1144 [10222/17352 (59%)] Loss: -980.514323\n",
      "Train Epoch: 1144 [17335/17352 (100%)] Loss: -842.114031\n",
      "    epoch          : 1144\n",
      "    loss           : -895.979285943981\n",
      "    val_loss       : -551.8408746215106\n",
      "Train Epoch: 1145 [512/17352 (3%)] Loss: -964.778809\n",
      "Train Epoch: 1145 [10103/17352 (58%)] Loss: -901.657128\n",
      "Train Epoch: 1145 [16934/17352 (98%)] Loss: -792.177083\n",
      "    epoch          : 1145\n",
      "    loss           : -804.5789455588342\n",
      "    val_loss       : -330.2719837448329\n",
      "Train Epoch: 1146 [512/17352 (3%)] Loss: -645.809570\n",
      "Train Epoch: 1146 [10288/17352 (59%)] Loss: -970.290837\n",
      "Train Epoch: 1146 [17106/17352 (99%)] Loss: -898.241291\n",
      "    epoch          : 1146\n",
      "    loss           : -766.2425105691087\n",
      "    val_loss       : -501.9634007258699\n",
      "Train Epoch: 1147 [512/17352 (3%)] Loss: -673.794861\n",
      "Train Epoch: 1147 [10470/17352 (60%)] Loss: -917.885691\n",
      "Train Epoch: 1147 [17064/17352 (98%)] Loss: -728.051163\n",
      "    epoch          : 1147\n",
      "    loss           : -730.5859221481809\n",
      "    val_loss       : 2000.5864868896235\n",
      "Train Epoch: 1148 [512/17352 (3%)] Loss: 1749.534546\n",
      "Train Epoch: 1148 [10201/17352 (59%)] Loss: -502.016697\n",
      "Train Epoch: 1148 [17101/17352 (99%)] Loss: 2803.909341\n",
      "    epoch          : 1148\n",
      "    loss           : 29.76494400546844\n",
      "    val_loss       : 335.04172592064987\n",
      "Train Epoch: 1149 [512/17352 (3%)] Loss: -61.807320\n",
      "Train Epoch: 1149 [9802/17352 (56%)] Loss: -355.059839\n",
      "Train Epoch: 1149 [16872/17352 (97%)] Loss: -350.827037\n",
      "    epoch          : 1149\n",
      "    loss           : -327.47518933399\n",
      "    val_loss       : -55.63773820373571\n",
      "Train Epoch: 1150 [512/17352 (3%)] Loss: -445.792480\n",
      "Train Epoch: 1150 [10442/17352 (60%)] Loss: -716.106061\n",
      "Train Epoch: 1150 [17090/17352 (98%)] Loss: -1056.429721\n",
      "    epoch          : 1150\n",
      "    loss           : -837.0168643489948\n",
      "    val_loss       : -636.685409221707\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch1150.pth ...\n",
      "Train Epoch: 1151 [512/17352 (3%)] Loss: -995.834839\n",
      "Train Epoch: 1151 [10677/17352 (62%)] Loss: -1152.812609\n",
      "Train Epoch: 1151 [17126/17352 (99%)] Loss: -1054.495213\n",
      "    epoch          : 1151\n",
      "    loss           : -976.7507413093674\n",
      "    val_loss       : -693.8715572962635\n",
      "Train Epoch: 1152 [512/17352 (3%)] Loss: -1047.858521\n",
      "Train Epoch: 1152 [10145/17352 (58%)] Loss: -1070.198307\n",
      "Train Epoch: 1152 [16922/17352 (98%)] Loss: -1161.761199\n",
      "    epoch          : 1152\n",
      "    loss           : -1030.4173015978079\n",
      "    val_loss       : -707.0589443569849\n",
      "Train Epoch: 1153 [512/17352 (3%)] Loss: -1089.080078\n",
      "Train Epoch: 1153 [10646/17352 (61%)] Loss: -1014.464457\n",
      "Train Epoch: 1153 [17126/17352 (99%)] Loss: -1134.266356\n",
      "    epoch          : 1153\n",
      "    loss           : -1043.2076067824694\n",
      "    val_loss       : -721.3015652850484\n",
      "Train Epoch: 1154 [512/17352 (3%)] Loss: -1087.847168\n",
      "Train Epoch: 1154 [10171/17352 (59%)] Loss: -1111.959972\n",
      "Train Epoch: 1154 [17277/17352 (100%)] Loss: -1035.523695\n",
      "    epoch          : 1154\n",
      "    loss           : -1045.502385048208\n",
      "    val_loss       : -697.2559273350148\n",
      "Train Epoch: 1155 [512/17352 (3%)] Loss: -1083.239014\n",
      "Train Epoch: 1155 [9718/17352 (56%)] Loss: -1093.378362\n",
      "Train Epoch: 1155 [17153/17352 (99%)] Loss: -1047.709635\n",
      "    epoch          : 1155\n",
      "    loss           : -1041.438520193396\n",
      "    val_loss       : -553.3692150522339\n",
      "Train Epoch: 1156 [512/17352 (3%)] Loss: -921.919556\n",
      "Train Epoch: 1156 [10869/17352 (63%)] Loss: -991.297012\n",
      "Train Epoch: 1156 [16923/17352 (98%)] Loss: -964.651215\n",
      "    epoch          : 1156\n",
      "    loss           : -1014.8081517139298\n",
      "    val_loss       : -713.0123142885978\n",
      "Train Epoch: 1157 [512/17352 (3%)] Loss: -927.451477\n",
      "Train Epoch: 1157 [9696/17352 (56%)] Loss: -965.556968\n",
      "Train Epoch: 1157 [16957/17352 (98%)] Loss: -807.804570\n",
      "    epoch          : 1157\n",
      "    loss           : -1019.158478356087\n",
      "    val_loss       : -573.7321882602097\n",
      "Train Epoch: 1158 [512/17352 (3%)] Loss: -947.577026\n",
      "Train Epoch: 1158 [10288/17352 (59%)] Loss: -994.871112\n",
      "Train Epoch: 1158 [17064/17352 (98%)] Loss: -854.154704\n",
      "    epoch          : 1158\n",
      "    loss           : -1027.6543763792452\n",
      "    val_loss       : -636.7087568770509\n",
      "Train Epoch: 1159 [512/17352 (3%)] Loss: -1004.328979\n",
      "Train Epoch: 1159 [9977/17352 (57%)] Loss: -1132.586382\n",
      "Train Epoch: 1159 [17253/17352 (99%)] Loss: -1001.151884\n",
      "    epoch          : 1159\n",
      "    loss           : -1038.2865697119541\n",
      "    val_loss       : -691.7301307852201\n",
      "Train Epoch: 1160 [512/17352 (3%)] Loss: -1066.371948\n",
      "Train Epoch: 1160 [10373/17352 (60%)] Loss: -944.214307\n",
      "Train Epoch: 1160 [16988/17352 (98%)] Loss: -1149.867686\n",
      "    epoch          : 1160\n",
      "    loss           : -1050.815569151098\n",
      "    val_loss       : -702.3722065394726\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch1160.pth ...\n",
      "Train Epoch: 1161 [512/17352 (3%)] Loss: -1105.952637\n",
      "Train Epoch: 1161 [10651/17352 (61%)] Loss: -1157.697917\n",
      "Train Epoch: 1161 [16939/17352 (98%)] Loss: -1100.813207\n",
      "    epoch          : 1161\n",
      "    loss           : -1053.0678955471294\n",
      "    val_loss       : -703.9715000952351\n",
      "Train Epoch: 1162 [512/17352 (3%)] Loss: -1090.588379\n",
      "Train Epoch: 1162 [10932/17352 (63%)] Loss: -1154.454255\n",
      "Train Epoch: 1162 [16992/17352 (98%)] Loss: -1067.683628\n",
      "    epoch          : 1162\n",
      "    loss           : -1049.682858390144\n",
      "    val_loss       : -665.1657449622096\n",
      "Train Epoch: 1163 [512/17352 (3%)] Loss: -1060.791992\n",
      "Train Epoch: 1163 [10639/17352 (61%)] Loss: -1104.187500\n",
      "Train Epoch: 1163 [17126/17352 (99%)] Loss: -1032.073403\n",
      "    epoch          : 1163\n",
      "    loss           : -1048.2937465086313\n",
      "    val_loss       : -728.1882836556554\n",
      "Train Epoch: 1164 [512/17352 (3%)] Loss: -1104.350342\n",
      "Train Epoch: 1164 [10498/17352 (61%)] Loss: -1162.474848\n",
      "Train Epoch: 1164 [17263/17352 (99%)] Loss: -1125.555938\n",
      "    epoch          : 1164\n",
      "    loss           : -1058.6281303583798\n",
      "    val_loss       : -713.5916479575063\n",
      "Train Epoch: 1165 [512/17352 (3%)] Loss: -1076.488037\n",
      "Train Epoch: 1165 [10066/17352 (58%)] Loss: -1049.434924\n",
      "Train Epoch: 1165 [17153/17352 (99%)] Loss: -1180.177772\n",
      "    epoch          : 1165\n",
      "    loss           : -1059.0533069809953\n",
      "    val_loss       : -672.7350427994633\n",
      "Train Epoch: 1166 [512/17352 (3%)] Loss: -1081.746094\n",
      "Train Epoch: 1166 [9898/17352 (57%)] Loss: -1132.045527\n",
      "Train Epoch: 1166 [16922/17352 (98%)] Loss: -1074.739629\n",
      "    epoch          : 1166\n",
      "    loss           : -1039.9854524466914\n",
      "    val_loss       : -720.2948237134456\n",
      "Train Epoch: 1167 [512/17352 (3%)] Loss: -1096.124512\n",
      "Train Epoch: 1167 [10248/17352 (59%)] Loss: -1135.538110\n",
      "Train Epoch: 1167 [17049/17352 (98%)] Loss: -1105.183362\n",
      "    epoch          : 1167\n",
      "    loss           : -1054.9640676052773\n",
      "    val_loss       : -729.0036124731686\n",
      "Train Epoch: 1168 [512/17352 (3%)] Loss: -1101.253174\n",
      "Train Epoch: 1168 [10695/17352 (62%)] Loss: -1004.209288\n",
      "Train Epoch: 1168 [17133/17352 (99%)] Loss: -1163.302512\n",
      "    epoch          : 1168\n",
      "    loss           : -1059.8168340563439\n",
      "    val_loss       : -682.3748318607782\n",
      "Train Epoch: 1169 [512/17352 (3%)] Loss: -1092.191406\n",
      "Train Epoch: 1169 [10396/17352 (60%)] Loss: -1107.901643\n",
      "Train Epoch: 1169 [17044/17352 (98%)] Loss: -991.888054\n",
      "    epoch          : 1169\n",
      "    loss           : -1055.6838745321809\n",
      "    val_loss       : -716.2115711888207\n",
      "Train Epoch: 1170 [512/17352 (3%)] Loss: -1103.577026\n",
      "Train Epoch: 1170 [10226/17352 (59%)] Loss: -1113.930104\n",
      "Train Epoch: 1170 [16958/17352 (98%)] Loss: -1123.033616\n",
      "    epoch          : 1170\n",
      "    loss           : -1068.155195671681\n",
      "    val_loss       : -715.4891849004078\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch1170.pth ...\n",
      "Train Epoch: 1171 [512/17352 (3%)] Loss: -1111.292114\n",
      "Train Epoch: 1171 [10321/17352 (59%)] Loss: -944.690182\n",
      "Train Epoch: 1171 [17124/17352 (99%)] Loss: -1134.596439\n",
      "    epoch          : 1171\n",
      "    loss           : -1069.8482483045307\n",
      "    val_loss       : -713.2446202952201\n",
      "Train Epoch: 1172 [512/17352 (3%)] Loss: -1116.295776\n",
      "Train Epoch: 1172 [10581/17352 (61%)] Loss: -1051.145261\n",
      "Train Epoch: 1172 [16887/17352 (97%)] Loss: -1109.175921\n",
      "    epoch          : 1172\n",
      "    loss           : -1068.8270965395823\n",
      "    val_loss       : -717.7842698394118\n",
      "Train Epoch: 1173 [512/17352 (3%)] Loss: -1103.911011\n",
      "Train Epoch: 1173 [10183/17352 (59%)] Loss: -1166.396267\n",
      "Train Epoch: 1173 [17124/17352 (99%)] Loss: -985.534836\n",
      "    epoch          : 1173\n",
      "    loss           : -1063.9580127247627\n",
      "    val_loss       : -696.9408740132354\n",
      "Train Epoch: 1174 [512/17352 (3%)] Loss: -1094.149170\n",
      "Train Epoch: 1174 [10533/17352 (61%)] Loss: -1168.065981\n",
      "Train Epoch: 1174 [17106/17352 (99%)] Loss: -1086.674380\n",
      "    epoch          : 1174\n",
      "    loss           : -1063.83630469986\n",
      "    val_loss       : -706.9288408799798\n",
      "Train Epoch: 1175 [512/17352 (3%)] Loss: -1093.881592\n",
      "Train Epoch: 1175 [9907/17352 (57%)] Loss: -1101.204409\n",
      "Train Epoch: 1175 [17049/17352 (98%)] Loss: -1088.821745\n",
      "    epoch          : 1175\n",
      "    loss           : -1052.1111606801992\n",
      "    val_loss       : -648.4074289798577\n",
      "Train Epoch: 1176 [512/17352 (3%)] Loss: -1086.969482\n",
      "Train Epoch: 1176 [9609/17352 (55%)] Loss: -1136.677611\n",
      "Train Epoch: 1176 [16878/17352 (97%)] Loss: -1145.507846\n",
      "    epoch          : 1176\n",
      "    loss           : -1030.2451368940085\n",
      "    val_loss       : -682.3155489618717\n",
      "Train Epoch: 1177 [512/17352 (3%)] Loss: -1100.385498\n",
      "Train Epoch: 1177 [10181/17352 (59%)] Loss: -1161.979611\n",
      "Train Epoch: 1177 [17277/17352 (100%)] Loss: -1108.845833\n",
      "    epoch          : 1177\n",
      "    loss           : -1062.0987153557896\n",
      "    val_loss       : -686.5936719328186\n",
      "Train Epoch: 1178 [512/17352 (3%)] Loss: -1103.143799\n",
      "Train Epoch: 1178 [10656/17352 (61%)] Loss: -930.145185\n",
      "Train Epoch: 1178 [16883/17352 (97%)] Loss: -1141.945431\n",
      "    epoch          : 1178\n",
      "    loss           : -1070.2694527290448\n",
      "    val_loss       : -706.6955007600511\n",
      "Train Epoch: 1179 [512/17352 (3%)] Loss: -1116.381348\n",
      "Train Epoch: 1179 [10815/17352 (62%)] Loss: -1156.468591\n",
      "Train Epoch: 1179 [17263/17352 (99%)] Loss: -1184.226090\n",
      "    epoch          : 1179\n",
      "    loss           : -1066.5061500318911\n",
      "    val_loss       : -677.6348932388362\n",
      "Train Epoch: 1180 [512/17352 (3%)] Loss: -1073.795654\n",
      "Train Epoch: 1180 [10083/17352 (58%)] Loss: -868.574670\n",
      "Train Epoch: 1180 [16992/17352 (98%)] Loss: -1037.371843\n",
      "    epoch          : 1180\n",
      "    loss           : -1034.1587596028426\n",
      "    val_loss       : -660.6462912295883\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch1180.pth ...\n",
      "Train Epoch: 1181 [512/17352 (3%)] Loss: -1067.552124\n",
      "Train Epoch: 1181 [10127/17352 (58%)] Loss: -1122.728956\n",
      "Train Epoch: 1181 [17133/17352 (99%)] Loss: -1003.770910\n",
      "    epoch          : 1181\n",
      "    loss           : -1037.0264799122276\n",
      "    val_loss       : -673.5047778370052\n",
      "Train Epoch: 1182 [512/17352 (3%)] Loss: -1053.742432\n",
      "Train Epoch: 1182 [10433/17352 (60%)] Loss: -1132.445751\n",
      "Train Epoch: 1182 [16939/17352 (98%)] Loss: -904.809745\n",
      "    epoch          : 1182\n",
      "    loss           : -1044.9129199346703\n",
      "    val_loss       : -681.8162341031547\n",
      "Train Epoch: 1183 [512/17352 (3%)] Loss: -1054.923096\n",
      "Train Epoch: 1183 [10740/17352 (62%)] Loss: -1004.000299\n",
      "Train Epoch: 1183 [16934/17352 (98%)] Loss: -915.742574\n",
      "    epoch          : 1183\n",
      "    loss           : -1063.294528314094\n",
      "    val_loss       : -688.3903211126769\n",
      "Train Epoch: 1184 [512/17352 (3%)] Loss: -1104.444214\n",
      "Train Epoch: 1184 [10831/17352 (62%)] Loss: -951.665355\n",
      "Train Epoch: 1184 [17016/17352 (98%)] Loss: -1129.441692\n",
      "    epoch          : 1184\n",
      "    loss           : -1049.1156144315155\n",
      "    val_loss       : -701.5134906022653\n",
      "Train Epoch: 1185 [512/17352 (3%)] Loss: -1104.672119\n",
      "Train Epoch: 1185 [10635/17352 (61%)] Loss: -1032.404507\n",
      "Train Epoch: 1185 [17124/17352 (99%)] Loss: -1043.825994\n",
      "    epoch          : 1185\n",
      "    loss           : -1036.4374299377557\n",
      "    val_loss       : -629.93532565624\n",
      "Train Epoch: 1186 [512/17352 (3%)] Loss: -1031.240479\n",
      "Train Epoch: 1186 [10511/17352 (61%)] Loss: -905.802931\n",
      "Train Epoch: 1186 [16958/17352 (98%)] Loss: -1162.470016\n",
      "    epoch          : 1186\n",
      "    loss           : -992.9094593973819\n",
      "    val_loss       : -647.3956801832883\n",
      "Train Epoch: 1187 [512/17352 (3%)] Loss: -1034.307251\n",
      "Train Epoch: 1187 [10229/17352 (59%)] Loss: -976.687431\n",
      "Train Epoch: 1187 [16883/17352 (97%)] Loss: -910.546514\n",
      "    epoch          : 1187\n",
      "    loss           : -1009.6959732020753\n",
      "    val_loss       : -680.036473347306\n",
      "Train Epoch: 1188 [512/17352 (3%)] Loss: -1084.451172\n",
      "Train Epoch: 1188 [10448/17352 (60%)] Loss: -897.172623\n",
      "Train Epoch: 1188 [16872/17352 (97%)] Loss: -861.115104\n",
      "    epoch          : 1188\n",
      "    loss           : -1013.3605406971211\n",
      "    val_loss       : -668.0787946362198\n",
      "Train Epoch: 1189 [512/17352 (3%)] Loss: -1111.087280\n",
      "Train Epoch: 1189 [10471/17352 (60%)] Loss: -1173.384534\n",
      "Train Epoch: 1189 [17124/17352 (99%)] Loss: -997.005831\n",
      "    epoch          : 1189\n",
      "    loss           : -1048.3654058970624\n",
      "    val_loss       : -705.4625347526177\n",
      "Train Epoch: 1190 [512/17352 (3%)] Loss: -1101.515503\n",
      "Train Epoch: 1190 [10028/17352 (58%)] Loss: -998.187308\n",
      "Train Epoch: 1190 [17106/17352 (99%)] Loss: -1127.460323\n",
      "    epoch          : 1190\n",
      "    loss           : -1069.3352719569032\n",
      "    val_loss       : -692.5098371631146\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch1190.pth ...\n",
      "Train Epoch: 1191 [512/17352 (3%)] Loss: -1112.416504\n",
      "Train Epoch: 1191 [10561/17352 (61%)] Loss: -1168.540523\n",
      "Train Epoch: 1191 [17133/17352 (99%)] Loss: -1140.548541\n",
      "    epoch          : 1191\n",
      "    loss           : -1069.9985892992577\n",
      "    val_loss       : -707.4151974641488\n",
      "Train Epoch: 1192 [512/17352 (3%)] Loss: -1122.207520\n",
      "Train Epoch: 1192 [10411/17352 (60%)] Loss: -1162.679116\n",
      "Train Epoch: 1192 [17124/17352 (99%)] Loss: -1126.660097\n",
      "    epoch          : 1192\n",
      "    loss           : -1068.3020564685864\n",
      "    val_loss       : -683.2547031684519\n",
      "Train Epoch: 1193 [512/17352 (3%)] Loss: -1114.118042\n",
      "Train Epoch: 1193 [10948/17352 (63%)] Loss: -1012.858259\n",
      "Train Epoch: 1193 [17108/17352 (99%)] Loss: -946.227564\n",
      "    epoch          : 1193\n",
      "    loss           : -1065.3476631363671\n",
      "    val_loss       : -671.8751778465497\n",
      "Train Epoch: 1194 [512/17352 (3%)] Loss: -1106.324707\n",
      "Train Epoch: 1194 [10278/17352 (59%)] Loss: -1019.069522\n",
      "Train Epoch: 1194 [17049/17352 (98%)] Loss: -1022.180344\n",
      "    epoch          : 1194\n",
      "    loss           : -958.4538174956531\n",
      "    val_loss       : -649.7600280525957\n",
      "Train Epoch: 1195 [512/17352 (3%)] Loss: -1056.063232\n",
      "Train Epoch: 1195 [10201/17352 (59%)] Loss: -948.583479\n",
      "Train Epoch: 1195 [16939/17352 (98%)] Loss: -1051.542865\n",
      "    epoch          : 1195\n",
      "    loss           : -997.9836552616417\n",
      "    val_loss       : -669.6904790071178\n",
      "Train Epoch: 1196 [512/17352 (3%)] Loss: -1080.722168\n",
      "Train Epoch: 1196 [9892/17352 (57%)] Loss: -1094.275632\n",
      "Train Epoch: 1196 [17106/17352 (99%)] Loss: -1065.745760\n",
      "    epoch          : 1196\n",
      "    loss           : -1033.6099917075487\n",
      "    val_loss       : -588.1441290484503\n",
      "Train Epoch: 1197 [512/17352 (3%)] Loss: -1021.875793\n",
      "Train Epoch: 1197 [10315/17352 (59%)] Loss: -885.647727\n",
      "Train Epoch: 1197 [16872/17352 (97%)] Loss: -914.559924\n",
      "    epoch          : 1197\n",
      "    loss           : -980.7458103622972\n",
      "    val_loss       : -632.495230062164\n",
      "Train Epoch: 1198 [512/17352 (3%)] Loss: -1025.656982\n",
      "Train Epoch: 1198 [10474/17352 (60%)] Loss: -986.402344\n",
      "Train Epoch: 1198 [17064/17352 (98%)] Loss: -1092.787580\n",
      "    epoch          : 1198\n",
      "    loss           : -1011.555291283525\n",
      "    val_loss       : -667.7683262663068\n",
      "Train Epoch: 1199 [512/17352 (3%)] Loss: -1062.110107\n",
      "Train Epoch: 1199 [10072/17352 (58%)] Loss: -1183.050906\n",
      "Train Epoch: 1199 [16887/17352 (97%)] Loss: -1116.262640\n",
      "    epoch          : 1199\n",
      "    loss           : -1046.4641820067156\n",
      "    val_loss       : -693.9508844661501\n",
      "Train Epoch: 1200 [512/17352 (3%)] Loss: -1119.985596\n",
      "Train Epoch: 1200 [10604/17352 (61%)] Loss: -1184.776150\n",
      "Train Epoch: 1200 [17133/17352 (99%)] Loss: -1017.894874\n",
      "    epoch          : 1200\n",
      "    loss           : -1048.8988257387794\n",
      "    val_loss       : -695.231751777014\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0408_153205/checkpoint-epoch1200.pth ...\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:categorical_bpl] *",
   "language": "python",
   "name": "conda-env-categorical_bpl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
