{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/eli/AnacondaProjects/categorical_bpl\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import collections\n",
    "import pyro\n",
    "import torch\n",
    "import numpy as np\n",
    "import data_loader.data_loaders as module_data\n",
    "import model.model as module_arch\n",
    "from parse_config import ConfigParser\n",
    "from trainer import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyro.enable_validation(True)\n",
    "# torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seeds for reproducibility\n",
    "SEED = 123\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Args = collections.namedtuple('Args', 'config resume device')\n",
    "config = ConfigParser.from_args(Args(config='omniglot_config.json', resume=None, device=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = config.get_logger('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# setup data_loader instances\n",
    "data_loader = config.init_obj('data_loader', module_data)\n",
    "valid_data_loader = data_loader.split_validation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model architecture, then print to console\n",
    "model = config.init_obj('arch', module_arch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = pyro.optim.ReduceLROnPlateau({\n",
    "    'optimizer': torch.optim.Adam,\n",
    "    'optim_args': {\n",
    "        \"lr\": 1e-3,\n",
    "        \"weight_decay\": 0,\n",
    "        \"amsgrad\": True\n",
    "    },\n",
    "    \"patience\": 50,\n",
    "    \"cooldown\": 25,\n",
    "    \"factor\": 0.1,\n",
    "    \"verbose\": True,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model, [], optimizer, config=config,\n",
    "                  data_loader=data_loader,\n",
    "                  valid_data_loader=valid_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [512/17352 (3%)] Loss: 1636.887085\n",
      "Train Epoch: 1 [10068/17352 (58%)] Loss: 1105.734652\n",
      "Train Epoch: 1 [16939/17352 (98%)] Loss: 1060.569738\n",
      "    epoch          : 1\n",
      "    loss           : 1165.7473470171526\n",
      "    val_loss       : 978.0334024437907\n",
      "    val_log_likelihood: -814.1265894858747\n",
      "    val_log_marginal: -901.4884017435036\n",
      "Train Epoch: 2 [512/17352 (3%)] Loss: 917.626526\n",
      "Train Epoch: 2 [10382/17352 (60%)] Loss: 923.299791\n",
      "Train Epoch: 2 [17263/17352 (99%)] Loss: 866.137485\n",
      "    epoch          : 2\n",
      "    loss           : 898.6408611245594\n",
      "    val_loss       : 849.7538761234869\n",
      "    val_log_likelihood: -758.6250816441523\n",
      "    val_log_marginal: -804.039053847109\n",
      "Train Epoch: 3 [512/17352 (3%)] Loss: 831.301086\n",
      "Train Epoch: 3 [10694/17352 (62%)] Loss: 816.986968\n",
      "Train Epoch: 3 [17153/17352 (99%)] Loss: 815.920765\n",
      "    epoch          : 3\n",
      "    loss           : 805.6701572278056\n",
      "    val_loss       : 784.910458512592\n",
      "    val_log_likelihood: -724.0326737709643\n",
      "    val_log_marginal: -756.548933803163\n",
      "Train Epoch: 4 [512/17352 (3%)] Loss: 752.472778\n",
      "Train Epoch: 4 [10007/17352 (58%)] Loss: 804.770172\n",
      "Train Epoch: 4 [17049/17352 (98%)] Loss: 771.883777\n",
      "    epoch          : 4\n",
      "    loss           : 762.7208026349234\n",
      "    val_loss       : 759.0122431423385\n",
      "    val_log_likelihood: -699.2034186089438\n",
      "    val_log_marginal: -733.8071289118859\n",
      "Train Epoch: 5 [512/17352 (3%)] Loss: 744.904541\n",
      "Train Epoch: 5 [10769/17352 (62%)] Loss: 718.110528\n",
      "Train Epoch: 5 [17126/17352 (99%)] Loss: 695.777910\n",
      "    epoch          : 5\n",
      "    loss           : 718.6791629102149\n",
      "    val_loss       : 711.2448168740051\n",
      "    val_log_likelihood: -675.0743421924842\n",
      "    val_log_marginal: -698.8975526123169\n",
      "Train Epoch: 6 [512/17352 (3%)] Loss: 702.100830\n",
      "Train Epoch: 6 [10226/17352 (59%)] Loss: 682.632533\n",
      "Train Epoch: 6 [16887/17352 (97%)] Loss: 677.423177\n",
      "    epoch          : 6\n",
      "    loss           : 690.7015770850122\n",
      "    val_loss       : 686.0688484035297\n",
      "    val_log_likelihood: -655.8201569698872\n",
      "    val_log_marginal: -679.1653097176932\n",
      "Train Epoch: 7 [512/17352 (3%)] Loss: 676.428406\n",
      "Train Epoch: 7 [10715/17352 (62%)] Loss: 673.954637\n",
      "Train Epoch: 7 [17044/17352 (98%)] Loss: 654.194627\n",
      "    epoch          : 7\n",
      "    loss           : 663.4411027161067\n",
      "    val_loss       : 657.4942849649043\n",
      "    val_log_likelihood: -636.1911931147293\n",
      "    val_log_marginal: -651.989419593888\n",
      "Train Epoch: 8 [512/17352 (3%)] Loss: 648.531738\n",
      "Train Epoch: 8 [10595/17352 (61%)] Loss: 644.524926\n",
      "Train Epoch: 8 [17263/17352 (99%)] Loss: 641.184584\n",
      "    epoch          : 8\n",
      "    loss           : 642.9800163762254\n",
      "    val_loss       : 644.6194216429965\n",
      "    val_log_likelihood: -618.7475163921854\n",
      "    val_log_marginal: -640.7975265157942\n",
      "Train Epoch: 9 [512/17352 (3%)] Loss: 638.400146\n",
      "Train Epoch: 9 [10243/17352 (59%)] Loss: 620.372184\n",
      "Train Epoch: 9 [16887/17352 (97%)] Loss: 650.038212\n",
      "    epoch          : 9\n",
      "    loss           : 627.551216766692\n",
      "    val_loss       : 633.7117902948391\n",
      "    val_log_likelihood: -604.6192196243189\n",
      "    val_log_marginal: -630.3139884921688\n",
      "Train Epoch: 10 [512/17352 (3%)] Loss: 628.205078\n",
      "Train Epoch: 10 [10504/17352 (61%)] Loss: 604.602967\n",
      "Train Epoch: 10 [16883/17352 (97%)] Loss: 615.655847\n",
      "    epoch          : 10\n",
      "    loss           : 611.709739396646\n",
      "    val_loss       : 606.0926503008299\n",
      "    val_log_likelihood: -587.9959844183064\n",
      "    val_log_marginal: -603.0581759315918\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0506_152815/checkpoint-epoch10.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 11 [512/17352 (3%)] Loss: 602.586670\n",
      "Train Epoch: 11 [9856/17352 (57%)] Loss: 592.880828\n",
      "Train Epoch: 11 [17049/17352 (98%)] Loss: 576.955890\n",
      "    epoch          : 11\n",
      "    loss           : 589.7835087047987\n",
      "    val_loss       : 626.8631222660104\n",
      "    val_log_likelihood: -567.4753692688286\n",
      "    val_log_marginal: -590.5984089443427\n",
      "Train Epoch: 12 [512/17352 (3%)] Loss: 583.495544\n",
      "Train Epoch: 12 [9838/17352 (57%)] Loss: 574.309375\n",
      "Train Epoch: 12 [17064/17352 (98%)] Loss: 567.776598\n",
      "    epoch          : 12\n",
      "    loss           : 573.0288587683134\n",
      "    val_loss       : 566.5516119947241\n",
      "    val_log_likelihood: -550.705336247699\n",
      "    val_log_marginal: -564.2506463755059\n",
      "Train Epoch: 13 [512/17352 (3%)] Loss: 560.393677\n",
      "Train Epoch: 13 [10313/17352 (59%)] Loss: 548.597002\n",
      "Train Epoch: 13 [17253/17352 (99%)] Loss: 552.760956\n",
      "    epoch          : 13\n",
      "    loss           : 555.962832241088\n",
      "    val_loss       : 558.1994399542925\n",
      "    val_log_likelihood: -535.3747800703904\n",
      "    val_log_marginal: -553.7891892441021\n",
      "Train Epoch: 14 [512/17352 (3%)] Loss: 550.001221\n",
      "Train Epoch: 14 [10999/17352 (63%)] Loss: 536.514486\n",
      "Train Epoch: 14 [16992/17352 (98%)] Loss: 532.528270\n",
      "    epoch          : 14\n",
      "    loss           : 540.149595456608\n",
      "    val_loss       : 537.6042820821556\n",
      "    val_log_likelihood: -518.6710656418232\n",
      "    val_log_marginal: -533.7526560687099\n",
      "Train Epoch: 15 [512/17352 (3%)] Loss: 528.861084\n",
      "Train Epoch: 15 [10563/17352 (61%)] Loss: 526.432552\n",
      "Train Epoch: 15 [17016/17352 (98%)] Loss: 507.965698\n",
      "    epoch          : 15\n",
      "    loss           : 522.6138211564528\n",
      "    val_loss       : 520.3763091188267\n",
      "    val_log_likelihood: -502.5742778410701\n",
      "    val_log_marginal: -517.5511755582559\n",
      "Train Epoch: 16 [512/17352 (3%)] Loss: 512.226013\n",
      "Train Epoch: 16 [10191/17352 (59%)] Loss: 506.888139\n",
      "Train Epoch: 16 [17090/17352 (98%)] Loss: 522.054253\n",
      "    epoch          : 16\n",
      "    loss           : 506.9206331986489\n",
      "    val_loss       : 535.3930602772926\n",
      "    val_log_likelihood: -485.4102118585561\n",
      "    val_log_marginal: -532.6931850825339\n",
      "Train Epoch: 17 [512/17352 (3%)] Loss: 528.519165\n",
      "Train Epoch: 17 [10427/17352 (60%)] Loss: 495.281882\n",
      "Train Epoch: 17 [16957/17352 (98%)] Loss: 504.260114\n",
      "    epoch          : 17\n",
      "    loss           : 495.1795948362156\n",
      "    val_loss       : 488.3689479454053\n",
      "    val_log_likelihood: -468.81699056242763\n",
      "    val_log_marginal: -485.76338964179837\n",
      "Train Epoch: 18 [512/17352 (3%)] Loss: 482.776123\n",
      "Train Epoch: 18 [10135/17352 (58%)] Loss: 485.103394\n",
      "Train Epoch: 18 [17335/17352 (100%)] Loss: 480.263614\n",
      "    epoch          : 18\n",
      "    loss           : 471.86268352075246\n",
      "    val_loss       : 467.6034713214066\n",
      "    val_log_likelihood: -451.7822723492435\n",
      "    val_log_marginal: -464.7164275242033\n",
      "Train Epoch: 19 [512/17352 (3%)] Loss: 462.143372\n",
      "Train Epoch: 19 [10251/17352 (59%)] Loss: 452.820033\n",
      "Train Epoch: 19 [16922/17352 (98%)] Loss: 463.737216\n",
      "    epoch          : 19\n",
      "    loss           : 455.0652603899905\n",
      "    val_loss       : 449.2723877616906\n",
      "    val_log_likelihood: -436.3720639430277\n",
      "    val_log_marginal: -446.4753741192346\n",
      "Train Epoch: 20 [512/17352 (3%)] Loss: 444.497498\n",
      "Train Epoch: 20 [10151/17352 (59%)] Loss: 438.018308\n",
      "Train Epoch: 20 [16872/17352 (97%)] Loss: 424.947057\n",
      "    epoch          : 20\n",
      "    loss           : 440.45312894725066\n",
      "    val_loss       : 433.76201343426186\n",
      "    val_log_likelihood: -419.26511987643516\n",
      "    val_log_marginal: -430.9783381093572\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0506_152815/checkpoint-epoch20.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 21 [512/17352 (3%)] Loss: 429.402893\n",
      "Train Epoch: 21 [10491/17352 (60%)] Loss: 410.527235\n",
      "Train Epoch: 21 [17126/17352 (99%)] Loss: 408.632749\n",
      "    epoch          : 21\n",
      "    loss           : 423.46709837094687\n",
      "    val_loss       : 419.12257106331583\n",
      "    val_log_likelihood: -401.03639964693775\n",
      "    val_log_marginal: -415.84596707022007\n",
      "Train Epoch: 22 [512/17352 (3%)] Loss: 414.728271\n",
      "Train Epoch: 22 [9965/17352 (57%)] Loss: 395.037299\n",
      "Train Epoch: 22 [16878/17352 (97%)] Loss: 409.245069\n",
      "    epoch          : 22\n",
      "    loss           : 407.80488755798933\n",
      "    val_loss       : 401.47754953669994\n",
      "    val_log_likelihood: -386.1044617192875\n",
      "    val_log_marginal: -399.0403899782868\n",
      "Train Epoch: 23 [512/17352 (3%)] Loss: 394.620544\n",
      "Train Epoch: 23 [10405/17352 (60%)] Loss: 405.183612\n",
      "Train Epoch: 23 [17133/17352 (99%)] Loss: 378.710574\n",
      "    epoch          : 23\n",
      "    loss           : 390.22485097802524\n",
      "    val_loss       : 387.52400865098394\n",
      "    val_log_likelihood: -370.780647621571\n",
      "    val_log_marginal: -384.8480783942209\n",
      "Train Epoch: 24 [512/17352 (3%)] Loss: 380.800781\n",
      "Train Epoch: 24 [9762/17352 (56%)] Loss: 385.445761\n",
      "Train Epoch: 24 [17106/17352 (99%)] Loss: 366.858782\n",
      "    epoch          : 24\n",
      "    loss           : 376.8452530473055\n",
      "    val_loss       : 390.4223431460398\n",
      "    val_log_likelihood: -355.7172299022861\n",
      "    val_log_marginal: -386.1881511835048\n",
      "Train Epoch: 25 [512/17352 (3%)] Loss: 385.767761\n",
      "Train Epoch: 25 [9896/17352 (57%)] Loss: 377.677669\n",
      "Train Epoch: 25 [16922/17352 (98%)] Loss: 346.187564\n",
      "    epoch          : 25\n",
      "    loss           : 365.0087671228686\n",
      "    val_loss       : 358.25941770179145\n",
      "    val_log_likelihood: -339.48906299463863\n",
      "    val_log_marginal: -353.67619322848833\n",
      "Train Epoch: 26 [512/17352 (3%)] Loss: 346.967804\n",
      "Train Epoch: 26 [10526/17352 (61%)] Loss: 347.921735\n",
      "Train Epoch: 26 [17101/17352 (99%)] Loss: 357.286820\n",
      "    epoch          : 26\n",
      "    loss           : 344.7057201688635\n",
      "    val_loss       : 339.22328293771005\n",
      "    val_log_likelihood: -322.27492790443813\n",
      "    val_log_marginal: -335.92371141518237\n",
      "Train Epoch: 27 [512/17352 (3%)] Loss: 334.221191\n",
      "Train Epoch: 27 [9710/17352 (56%)] Loss: 345.138794\n",
      "Train Epoch: 27 [17108/17352 (99%)] Loss: 336.899559\n",
      "    epoch          : 27\n",
      "    loss           : 330.1213508653581\n",
      "    val_loss       : 326.29246484554017\n",
      "    val_log_likelihood: -308.37112461616897\n",
      "    val_log_marginal: -323.1504782786698\n",
      "Train Epoch: 28 [512/17352 (3%)] Loss: 322.423798\n",
      "Train Epoch: 28 [9917/17352 (57%)] Loss: 322.151890\n",
      "Train Epoch: 28 [16958/17352 (98%)] Loss: 297.733240\n",
      "    epoch          : 28\n",
      "    loss           : 317.9229277737651\n",
      "    val_loss       : 317.5427314492858\n",
      "    val_log_likelihood: -294.3312526859397\n",
      "    val_log_marginal: -314.4823625743428\n",
      "Train Epoch: 29 [512/17352 (3%)] Loss: 312.216095\n",
      "Train Epoch: 29 [10190/17352 (59%)] Loss: 307.449493\n",
      "Train Epoch: 29 [16992/17352 (98%)] Loss: 288.732597\n",
      "    epoch          : 29\n",
      "    loss           : 309.15819143265196\n",
      "    val_loss       : 300.913092169151\n",
      "    val_log_likelihood: -280.06201534394984\n",
      "    val_log_marginal: -297.35155579085176\n",
      "Train Epoch: 30 [512/17352 (3%)] Loss: 298.087219\n",
      "Train Epoch: 30 [10295/17352 (59%)] Loss: 320.040155\n",
      "Train Epoch: 30 [16992/17352 (98%)] Loss: 282.127427\n",
      "    epoch          : 30\n",
      "    loss           : 292.0587947253331\n",
      "    val_loss       : 284.646171059268\n",
      "    val_log_likelihood: -265.9161182843216\n",
      "    val_log_marginal: -279.4317554370456\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0506_152815/checkpoint-epoch30.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 31 [512/17352 (3%)] Loss: 281.422180\n",
      "Train Epoch: 31 [10667/17352 (61%)] Loss: 268.450618\n",
      "Train Epoch: 31 [17044/17352 (98%)] Loss: 270.458852\n",
      "    epoch          : 31\n",
      "    loss           : 274.55116904451387\n",
      "    val_loss       : 273.46386953458443\n",
      "    val_log_likelihood: -249.67384748592937\n",
      "    val_log_marginal: -268.5739135186562\n",
      "Train Epoch: 32 [512/17352 (3%)] Loss: 266.693298\n",
      "Train Epoch: 32 [10581/17352 (61%)] Loss: 272.695415\n",
      "Train Epoch: 32 [16958/17352 (98%)] Loss: 239.943515\n",
      "    epoch          : 32\n",
      "    loss           : 266.87343764018163\n",
      "    val_loss       : 268.4397020327302\n",
      "    val_log_likelihood: -239.05952920492828\n",
      "    val_log_marginal: -265.4083178528497\n",
      "Train Epoch: 33 [512/17352 (3%)] Loss: 257.748779\n",
      "Train Epoch: 33 [10075/17352 (58%)] Loss: 216.309568\n",
      "Train Epoch: 33 [17126/17352 (99%)] Loss: 254.420747\n",
      "    epoch          : 33\n",
      "    loss           : 251.4221292808826\n",
      "    val_loss       : 251.07407323031092\n",
      "    val_log_likelihood: -224.4330167632998\n",
      "    val_log_marginal: -246.7979089718023\n",
      "Train Epoch: 34 [512/17352 (3%)] Loss: 243.168701\n",
      "Train Epoch: 34 [10108/17352 (58%)] Loss: 224.954661\n",
      "Train Epoch: 34 [16883/17352 (97%)] Loss: 242.999452\n",
      "    epoch          : 34\n",
      "    loss           : 237.9956413014587\n",
      "    val_loss       : 236.76933218425734\n",
      "    val_log_likelihood: -210.8332609366569\n",
      "    val_log_marginal: -231.57157993453964\n",
      "Train Epoch: 35 [512/17352 (3%)] Loss: 226.258682\n",
      "Train Epoch: 35 [10108/17352 (58%)] Loss: 196.942925\n",
      "Train Epoch: 35 [17108/17352 (99%)] Loss: 225.508548\n",
      "    epoch          : 35\n",
      "    loss           : 225.01492750411435\n",
      "    val_loss       : 230.1272951348795\n",
      "    val_log_likelihood: -200.3937369634662\n",
      "    val_log_marginal: -223.70938366444798\n",
      "Train Epoch: 36 [512/17352 (3%)] Loss: 223.495529\n",
      "Train Epoch: 36 [10298/17352 (59%)] Loss: 204.849258\n",
      "Train Epoch: 36 [16957/17352 (98%)] Loss: 190.873637\n",
      "    epoch          : 36\n",
      "    loss           : 213.11121461544724\n",
      "    val_loss       : 211.87618469365134\n",
      "    val_log_likelihood: -184.46702147481932\n",
      "    val_log_marginal: -206.1221839452459\n",
      "Train Epoch: 37 [512/17352 (3%)] Loss: 198.565979\n",
      "Train Epoch: 37 [10429/17352 (60%)] Loss: 186.946086\n",
      "Train Epoch: 37 [17143/17352 (99%)] Loss: 169.991306\n",
      "    epoch          : 37\n",
      "    loss           : 202.32975103056992\n",
      "    val_loss       : 209.69469894118103\n",
      "    val_log_likelihood: -174.75762773086518\n",
      "    val_log_marginal: -203.93107430036645\n",
      "Train Epoch: 38 [512/17352 (3%)] Loss: 199.648712\n",
      "Train Epoch: 38 [10365/17352 (60%)] Loss: 215.692708\n",
      "Train Epoch: 38 [17133/17352 (99%)] Loss: 188.665938\n",
      "    epoch          : 38\n",
      "    loss           : 192.6986509466374\n",
      "    val_loss       : 188.60958398045074\n",
      "    val_log_likelihood: -160.0692327936274\n",
      "    val_log_marginal: -183.30729783911224\n",
      "Train Epoch: 39 [512/17352 (3%)] Loss: 178.398361\n",
      "Train Epoch: 39 [10420/17352 (60%)] Loss: 183.235822\n",
      "Train Epoch: 39 [16922/17352 (98%)] Loss: 177.491991\n",
      "    epoch          : 39\n",
      "    loss           : 182.09460959548443\n",
      "    val_loss       : 181.29113691970943\n",
      "    val_log_likelihood: -150.87170745054914\n",
      "    val_log_marginal: -175.18059978651422\n",
      "Train Epoch: 40 [512/17352 (3%)] Loss: 171.254639\n",
      "Train Epoch: 40 [10017/17352 (58%)] Loss: 171.032406\n",
      "Train Epoch: 40 [16992/17352 (98%)] Loss: 182.353828\n",
      "    epoch          : 40\n",
      "    loss           : 171.5250742241213\n",
      "    val_loss       : 174.93679712348563\n",
      "    val_log_likelihood: -137.8889571549296\n",
      "    val_log_marginal: -168.44690013774954\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0506_152815/checkpoint-epoch40.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 41 [512/17352 (3%)] Loss: 165.411499\n",
      "Train Epoch: 41 [10705/17352 (62%)] Loss: 144.986392\n",
      "Train Epoch: 41 [16988/17352 (98%)] Loss: 184.213797\n",
      "    epoch          : 41\n",
      "    loss           : 159.94320059565018\n",
      "    val_loss       : 169.04955674359073\n",
      "    val_log_likelihood: -128.11455627366163\n",
      "    val_log_marginal: -162.23330855568292\n",
      "Train Epoch: 42 [512/17352 (3%)] Loss: 155.166077\n",
      "Train Epoch: 42 [10394/17352 (60%)] Loss: 161.360493\n",
      "Train Epoch: 42 [17049/17352 (98%)] Loss: 166.699139\n",
      "    epoch          : 42\n",
      "    loss           : 148.99388577874794\n",
      "    val_loss       : 146.97840768859493\n",
      "    val_log_likelihood: -116.53395075499289\n",
      "    val_log_marginal: -142.41722738585804\n",
      "Train Epoch: 43 [512/17352 (3%)] Loss: 137.017044\n",
      "Train Epoch: 43 [10404/17352 (60%)] Loss: 170.473124\n",
      "Train Epoch: 43 [17153/17352 (99%)] Loss: 131.368229\n",
      "    epoch          : 43\n",
      "    loss           : 139.56585588221307\n",
      "    val_loss       : 143.6210391504548\n",
      "    val_log_likelihood: -101.30031955109284\n",
      "    val_log_marginal: -135.82799558237988\n",
      "Train Epoch: 44 [512/17352 (3%)] Loss: 133.300735\n",
      "Train Epoch: 44 [10269/17352 (59%)] Loss: 157.467242\n",
      "Train Epoch: 44 [17335/17352 (100%)] Loss: 127.200528\n",
      "    epoch          : 44\n",
      "    loss           : 136.81570120903675\n",
      "    val_loss       : 235.18349303160963\n",
      "    val_log_likelihood: -105.41534893653143\n",
      "    val_log_marginal: -221.68706616595202\n",
      "Train Epoch: 45 [512/17352 (3%)] Loss: 224.302475\n",
      "Train Epoch: 45 [9592/17352 (55%)] Loss: 157.595753\n",
      "Train Epoch: 45 [17049/17352 (98%)] Loss: 119.901177\n",
      "    epoch          : 45\n",
      "    loss           : 135.54224602889985\n",
      "    val_loss       : 123.94838803919535\n",
      "    val_log_likelihood: -94.12809210835539\n",
      "    val_log_marginal: -118.9109359575099\n",
      "Train Epoch: 46 [512/17352 (3%)] Loss: 112.823761\n",
      "Train Epoch: 46 [10913/17352 (63%)] Loss: 101.533553\n",
      "Train Epoch: 46 [17277/17352 (100%)] Loss: 84.840354\n",
      "    epoch          : 46\n",
      "    loss           : 110.33903598548726\n",
      "    val_loss       : 112.69666605496285\n",
      "    val_log_likelihood: -72.94972954227094\n",
      "    val_log_marginal: -106.59573639625835\n",
      "Train Epoch: 47 [512/17352 (3%)] Loss: 102.826248\n",
      "Train Epoch: 47 [10264/17352 (59%)] Loss: 80.230153\n",
      "Train Epoch: 47 [17143/17352 (99%)] Loss: 106.548871\n",
      "    epoch          : 47\n",
      "    loss           : 104.83768847881605\n",
      "    val_loss       : 112.29726714513438\n",
      "    val_log_likelihood: -75.74558574690163\n",
      "    val_log_marginal: -105.99924061705626\n",
      "Train Epoch: 48 [512/17352 (3%)] Loss: 92.722466\n",
      "Train Epoch: 48 [10189/17352 (59%)] Loss: 93.063364\n",
      "Train Epoch: 48 [17253/17352 (99%)] Loss: 108.291954\n",
      "    epoch          : 48\n",
      "    loss           : 97.26768045845384\n",
      "    val_loss       : 101.74733825008204\n",
      "    val_log_likelihood: -55.53316738281056\n",
      "    val_log_marginal: -94.68103732164657\n",
      "Train Epoch: 49 [512/17352 (3%)] Loss: 93.497772\n",
      "Train Epoch: 49 [10375/17352 (60%)] Loss: 81.011828\n",
      "Train Epoch: 49 [17153/17352 (99%)] Loss: 89.297248\n",
      "    epoch          : 49\n",
      "    loss           : 85.20197258101376\n",
      "    val_loss       : 97.24786390884988\n",
      "    val_log_likelihood: -55.02439864658943\n",
      "    val_log_marginal: -91.30002068726719\n",
      "Train Epoch: 50 [512/17352 (3%)] Loss: 80.874084\n",
      "Train Epoch: 50 [10743/17352 (62%)] Loss: 35.263811\n",
      "Train Epoch: 50 [17049/17352 (98%)] Loss: 88.597559\n",
      "    epoch          : 50\n",
      "    loss           : 79.61598755050113\n",
      "    val_loss       : 80.34356189274145\n",
      "    val_log_likelihood: -39.28501346352227\n",
      "    val_log_marginal: -72.60594727493645\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0506_152815/checkpoint-epoch50.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 51 [512/17352 (3%)] Loss: 64.608063\n",
      "Train Epoch: 51 [10471/17352 (60%)] Loss: 73.065553\n",
      "Train Epoch: 51 [17263/17352 (99%)] Loss: 41.712194\n",
      "    epoch          : 51\n",
      "    loss           : 71.11619987282018\n",
      "    val_loss       : 75.82768508575263\n",
      "    val_log_likelihood: -34.88920446202646\n",
      "    val_log_marginal: -70.02700109656399\n",
      "Train Epoch: 52 [512/17352 (3%)] Loss: 73.473854\n",
      "Train Epoch: 52 [10466/17352 (60%)] Loss: 51.972544\n",
      "Train Epoch: 52 [16922/17352 (98%)] Loss: 52.750104\n",
      "    epoch          : 52\n",
      "    loss           : 73.19183024500897\n",
      "    val_loss       : 65.57483536731205\n",
      "    val_log_likelihood: -28.706337343801984\n",
      "    val_log_marginal: -57.323538980882205\n",
      "Train Epoch: 53 [512/17352 (3%)] Loss: 59.908966\n",
      "Train Epoch: 53 [10416/17352 (60%)] Loss: 30.144435\n",
      "Train Epoch: 53 [17133/17352 (99%)] Loss: 27.349102\n",
      "    epoch          : 53\n",
      "    loss           : 60.579937399951554\n",
      "    val_loss       : 64.41021542135907\n",
      "    val_log_likelihood: -15.035170206977378\n",
      "    val_log_marginal: -55.325433954273734\n",
      "Train Epoch: 54 [512/17352 (3%)] Loss: 44.440704\n",
      "Train Epoch: 54 [9728/17352 (56%)] Loss: 98.331621\n",
      "Train Epoch: 54 [17016/17352 (98%)] Loss: 90.006934\n",
      "    epoch          : 54\n",
      "    loss           : 89.97039659198136\n",
      "    val_loss       : 176.65629132617173\n",
      "    val_log_likelihood: -35.90261428316803\n",
      "    val_log_marginal: -153.67260745525786\n",
      "Train Epoch: 55 [512/17352 (3%)] Loss: 160.974182\n",
      "Train Epoch: 55 [10093/17352 (58%)] Loss: 49.739481\n",
      "Train Epoch: 55 [17016/17352 (98%)] Loss: 73.088083\n",
      "    epoch          : 55\n",
      "    loss           : 76.63958965532254\n",
      "    val_loss       : 56.66064531028392\n",
      "    val_log_likelihood: -12.212956244045072\n",
      "    val_log_marginal: -48.49839486228486\n",
      "Train Epoch: 56 [512/17352 (3%)] Loss: 48.176228\n",
      "Train Epoch: 56 [10215/17352 (59%)] Loss: 52.568842\n",
      "Train Epoch: 56 [17064/17352 (98%)] Loss: 39.757739\n",
      "    epoch          : 56\n",
      "    loss           : 46.31855304338955\n",
      "    val_loss       : 51.30478951357473\n",
      "    val_log_likelihood: 3.46607183517763\n",
      "    val_log_marginal: -41.63517722199524\n",
      "Train Epoch: 57 [512/17352 (3%)] Loss: 22.760689\n",
      "Train Epoch: 57 [9851/17352 (57%)] Loss: 7.256946\n",
      "Train Epoch: 57 [17126/17352 (99%)] Loss: 30.555943\n",
      "    epoch          : 57\n",
      "    loss           : 37.94622189351878\n",
      "    val_loss       : 42.38446861206916\n",
      "    val_log_likelihood: 13.144371579488888\n",
      "    val_log_marginal: -34.75418107063938\n",
      "Train Epoch: 58 [512/17352 (3%)] Loss: 24.980511\n",
      "Train Epoch: 58 [10257/17352 (59%)] Loss: -6.594293\n",
      "Train Epoch: 58 [17126/17352 (99%)] Loss: 56.624122\n",
      "    epoch          : 58\n",
      "    loss           : 27.759164605631252\n",
      "    val_loss       : 29.528142458126148\n",
      "    val_log_likelihood: 23.34673777777862\n",
      "    val_log_marginal: -22.487129330114143\n",
      "Train Epoch: 59 [512/17352 (3%)] Loss: 14.443617\n",
      "Train Epoch: 59 [10426/17352 (60%)] Loss: -6.139532\n",
      "Train Epoch: 59 [16887/17352 (97%)] Loss: -11.720212\n",
      "    epoch          : 59\n",
      "    loss           : 22.620727377032384\n",
      "    val_loss       : 27.073616816786785\n",
      "    val_log_likelihood: 29.37100888997525\n",
      "    val_log_marginal: -17.565527989276973\n",
      "Train Epoch: 60 [512/17352 (3%)] Loss: 16.070013\n",
      "Train Epoch: 60 [10639/17352 (61%)] Loss: 77.705695\n",
      "Train Epoch: 60 [17106/17352 (99%)] Loss: -45.407518\n",
      "    epoch          : 60\n",
      "    loss           : 19.25716636890273\n",
      "    val_loss       : 41.18972674655829\n",
      "    val_log_likelihood: 32.297847352223236\n",
      "    val_log_marginal: -32.52588322089681\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0506_152815/checkpoint-epoch60.pth ...\n",
      "Train Epoch: 61 [512/17352 (3%)] Loss: 25.418091\n",
      "Train Epoch: 61 [9778/17352 (56%)] Loss: -13.238414\n",
      "Train Epoch: 61 [16923/17352 (98%)] Loss: 40.365995\n",
      "    epoch          : 61\n",
      "    loss           : 26.436904172518734\n",
      "    val_loss       : 22.60232645860032\n",
      "    val_log_likelihood: 37.89315127156832\n",
      "    val_log_marginal: -14.98476420648518\n",
      "Train Epoch: 62 [512/17352 (3%)] Loss: 14.157747\n",
      "Train Epoch: 62 [10783/17352 (62%)] Loss: 82.345632\n",
      "Train Epoch: 62 [16923/17352 (98%)] Loss: 85.049208\n",
      "    epoch          : 62\n",
      "    loss           : 11.593256793095502\n",
      "    val_loss       : 25.13299299520067\n",
      "    val_log_likelihood: 45.72468727109177\n",
      "    val_log_marginal: -18.78383287058001\n",
      "Train Epoch: 63 [512/17352 (3%)] Loss: 11.496511\n",
      "Train Epoch: 63 [10198/17352 (59%)] Loss: -28.612211\n",
      "Train Epoch: 63 [16957/17352 (98%)] Loss: 82.393968\n",
      "    epoch          : 63\n",
      "    loss           : 12.222422539248496\n",
      "    val_loss       : 12.49193103561197\n",
      "    val_log_likelihood: 48.58939971539416\n",
      "    val_log_marginal: -7.641671964232399\n",
      "Train Epoch: 64 [512/17352 (3%)] Loss: -4.127224\n",
      "Train Epoch: 64 [10478/17352 (60%)] Loss: -30.991780\n",
      "Train Epoch: 64 [16992/17352 (98%)] Loss: -8.549165\n",
      "    epoch          : 64\n",
      "    loss           : 0.30407102712854656\n",
      "    val_loss       : 5.189799755152097\n",
      "    val_log_likelihood: 57.827417349091824\n",
      "    val_log_marginal: 2.422287933983053\n",
      "Train Epoch: 65 [512/17352 (3%)] Loss: -14.038622\n",
      "Train Epoch: 65 [10656/17352 (61%)] Loss: 23.225224\n",
      "Train Epoch: 65 [16882/17352 (97%)] Loss: -50.609623\n",
      "    epoch          : 65\n",
      "    loss           : -5.231436861757374\n",
      "    val_loss       : -1.3742719700222072\n",
      "    val_log_likelihood: 68.5595959478845\n",
      "    val_log_marginal: 9.83340745508829\n",
      "Train Epoch: 66 [512/17352 (3%)] Loss: -22.785069\n",
      "Train Epoch: 66 [10770/17352 (62%)] Loss: 28.908490\n",
      "Train Epoch: 66 [17106/17352 (99%)] Loss: -24.558001\n",
      "    epoch          : 66\n",
      "    loss           : 2.2727464142508373\n",
      "    val_loss       : 68.62543303459984\n",
      "    val_log_likelihood: 73.86885387655494\n",
      "    val_log_marginal: -54.0833354281308\n",
      "Train Epoch: 67 [512/17352 (3%)] Loss: 41.546150\n",
      "Train Epoch: 67 [10488/17352 (60%)] Loss: 80.656642\n",
      "Train Epoch: 67 [17263/17352 (99%)] Loss: -19.691726\n",
      "    epoch          : 67\n",
      "    loss           : 4.735639327087756\n",
      "    val_loss       : 9.425941643544093\n",
      "    val_log_likelihood: 79.67341501648556\n",
      "    val_log_marginal: -1.634048253719545\n",
      "Train Epoch: 68 [512/17352 (3%)] Loss: -11.044640\n",
      "Train Epoch: 68 [10649/17352 (61%)] Loss: 56.982660\n",
      "Train Epoch: 68 [16922/17352 (98%)] Loss: -2.199486\n",
      "    epoch          : 68\n",
      "    loss           : -4.411444072277327\n",
      "    val_loss       : 6.596227225233389\n",
      "    val_log_likelihood: 82.1061953179763\n",
      "    val_log_marginal: 2.398401525043075\n",
      "Train Epoch: 69 [512/17352 (3%)] Loss: -2.434433\n",
      "Train Epoch: 69 [10359/17352 (60%)] Loss: -92.728834\n",
      "Train Epoch: 69 [17049/17352 (98%)] Loss: -102.480685\n",
      "    epoch          : 69\n",
      "    loss           : -17.7026268710417\n",
      "    val_loss       : -14.807426140493982\n",
      "    val_log_likelihood: 86.04831917446805\n",
      "    val_log_marginal: 19.754312520053677\n",
      "Train Epoch: 70 [512/17352 (3%)] Loss: -29.969679\n",
      "Train Epoch: 70 [10134/17352 (58%)] Loss: -60.569101\n",
      "Train Epoch: 70 [17126/17352 (99%)] Loss: 4.103825\n",
      "    epoch          : 70\n",
      "    loss           : -21.653510241488107\n",
      "    val_loss       : 17.407342421582918\n",
      "    val_log_likelihood: 94.14188496146095\n",
      "    val_log_marginal: -8.583383740525525\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0506_152815/checkpoint-epoch70.pth ...\n",
      "Train Epoch: 71 [512/17352 (3%)] Loss: 10.136673\n",
      "Train Epoch: 71 [10138/17352 (58%)] Loss: -44.431836\n",
      "Train Epoch: 71 [16934/17352 (98%)] Loss: -27.174178\n",
      "    epoch          : 71\n",
      "    loss           : -26.770088126850155\n",
      "    val_loss       : -26.28285781391036\n",
      "    val_log_likelihood: 101.43451540894662\n",
      "    val_log_marginal: 35.49413283712879\n",
      "Train Epoch: 72 [512/17352 (3%)] Loss: -49.589867\n",
      "Train Epoch: 72 [10304/17352 (59%)] Loss: -66.897171\n",
      "Train Epoch: 72 [17335/17352 (100%)] Loss: 48.973190\n",
      "    epoch          : 72\n",
      "    loss           : -36.30956346999743\n",
      "    val_loss       : -24.530163852239788\n",
      "    val_log_likelihood: 119.08683401530851\n",
      "    val_log_marginal: 32.69263465663024\n",
      "Train Epoch: 73 [512/17352 (3%)] Loss: -48.837708\n",
      "Train Epoch: 73 [10020/17352 (58%)] Loss: -38.703763\n",
      "Train Epoch: 73 [17090/17352 (98%)] Loss: -5.463097\n",
      "    epoch          : 73\n",
      "    loss           : -29.210246808454382\n",
      "    val_loss       : -12.585361787206134\n",
      "    val_log_likelihood: 113.66979363705849\n",
      "    val_log_marginal: 27.309167634172002\n",
      "Train Epoch: 74 [512/17352 (3%)] Loss: 44.172943\n",
      "Train Epoch: 74 [10640/17352 (61%)] Loss: 35.497976\n",
      "Train Epoch: 74 [17016/17352 (98%)] Loss: -31.334336\n",
      "    epoch          : 74\n",
      "    loss           : -23.291357853014134\n",
      "    val_loss       : -20.784711858646972\n",
      "    val_log_likelihood: 115.51710547584976\n",
      "    val_log_marginal: 35.650223068358734\n",
      "Train Epoch: 75 [512/17352 (3%)] Loss: -56.940304\n",
      "Train Epoch: 75 [10363/17352 (60%)] Loss: -54.199544\n",
      "Train Epoch: 75 [17253/17352 (99%)] Loss: -140.311451\n",
      "    epoch          : 75\n",
      "    loss           : -43.58385261668029\n",
      "    val_loss       : -35.89836451371467\n",
      "    val_log_likelihood: 132.9045757543942\n",
      "    val_log_marginal: 46.222871587671015\n",
      "Train Epoch: 76 [512/17352 (3%)] Loss: -66.230972\n",
      "Train Epoch: 76 [9968/17352 (57%)] Loss: -0.392226\n",
      "Train Epoch: 76 [16887/17352 (97%)] Loss: -13.420716\n",
      "    epoch          : 76\n",
      "    loss           : -48.203817224686766\n",
      "    val_loss       : -42.9929612478414\n",
      "    val_log_likelihood: 137.90460642157845\n",
      "    val_log_marginal: 52.816256738473456\n",
      "Train Epoch: 77 [512/17352 (3%)] Loss: -72.528717\n",
      "Train Epoch: 77 [10567/17352 (61%)] Loss: -24.237363\n",
      "Train Epoch: 77 [16883/17352 (97%)] Loss: -79.323692\n",
      "    epoch          : 77\n",
      "    loss           : -58.237605267424925\n",
      "    val_loss       : -51.31143944400943\n",
      "    val_log_likelihood: 152.50881705925553\n",
      "    val_log_marginal: 60.65261416578553\n",
      "Train Epoch: 78 [512/17352 (3%)] Loss: -76.075485\n",
      "Train Epoch: 78 [11032/17352 (64%)] Loss: -64.331876\n",
      "Train Epoch: 78 [17090/17352 (98%)] Loss: -4.187324\n",
      "    epoch          : 78\n",
      "    loss           : -49.55008954486124\n",
      "    val_loss       : -45.95172922855921\n",
      "    val_log_likelihood: 147.4546534160085\n",
      "    val_log_marginal: 55.70976447884493\n",
      "Train Epoch: 79 [512/17352 (3%)] Loss: -60.323555\n",
      "Train Epoch: 79 [10526/17352 (61%)] Loss: -0.875304\n",
      "Train Epoch: 79 [17064/17352 (98%)] Loss: -93.005287\n",
      "    epoch          : 79\n",
      "    loss           : -51.805215426598714\n",
      "    val_loss       : -53.102761572752236\n",
      "    val_log_likelihood: 153.81565954072173\n",
      "    val_log_marginal: 63.81351862534391\n",
      "Train Epoch: 80 [512/17352 (3%)] Loss: 14.575920\n",
      "Train Epoch: 80 [10405/17352 (60%)] Loss: -102.269225\n",
      "Train Epoch: 80 [17044/17352 (98%)] Loss: -59.070861\n",
      "    epoch          : 80\n",
      "    loss           : -57.085951742144665\n",
      "    val_loss       : -58.24400726483852\n",
      "    val_log_likelihood: 158.96243286452867\n",
      "    val_log_marginal: 69.99786927641874\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0506_152815/checkpoint-epoch80.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 81 [512/17352 (3%)] Loss: -76.906174\n",
      "Train Epoch: 81 [10585/17352 (61%)] Loss: -56.862758\n",
      "Train Epoch: 81 [17143/17352 (99%)] Loss: -87.100366\n",
      "    epoch          : 81\n",
      "    loss           : -70.77059820915018\n",
      "    val_loss       : -57.5794149434152\n",
      "    val_log_likelihood: 170.5042230426682\n",
      "    val_log_marginal: 69.0676336563019\n",
      "Train Epoch: 82 [512/17352 (3%)] Loss: -89.621841\n",
      "Train Epoch: 82 [10051/17352 (58%)] Loss: -83.650155\n",
      "Train Epoch: 82 [16988/17352 (98%)] Loss: -39.366746\n",
      "    epoch          : 82\n",
      "    loss           : -62.1815057068094\n",
      "    val_loss       : -60.029491574783165\n",
      "    val_log_likelihood: 173.82044725757342\n",
      "    val_log_marginal: 72.52698393136734\n",
      "Train Epoch: 83 [512/17352 (3%)] Loss: -87.659180\n",
      "Train Epoch: 83 [10043/17352 (58%)] Loss: -100.513888\n",
      "Train Epoch: 83 [16988/17352 (98%)] Loss: -2.921986\n",
      "    epoch          : 83\n",
      "    loss           : -57.23011333265327\n",
      "    val_loss       : -35.695371367008924\n",
      "    val_log_likelihood: 175.7803044237414\n",
      "    val_log_marginal: 49.934877500949256\n",
      "Train Epoch: 84 [512/17352 (3%)] Loss: -72.684875\n",
      "Train Epoch: 84 [10188/17352 (59%)] Loss: -36.480457\n",
      "Train Epoch: 84 [17277/17352 (100%)] Loss: -27.435474\n",
      "    epoch          : 84\n",
      "    loss           : -55.99592881376334\n",
      "    val_loss       : -18.384250949869706\n",
      "    val_log_likelihood: 177.43814420897687\n",
      "    val_log_marginal: 34.599721800118694\n",
      "Train Epoch: 85 [512/17352 (3%)] Loss: -45.383175\n",
      "Train Epoch: 85 [10404/17352 (60%)] Loss: -82.795280\n",
      "Train Epoch: 85 [16958/17352 (98%)] Loss: -36.736295\n",
      "    epoch          : 85\n",
      "    loss           : -72.15622808067377\n",
      "    val_loss       : -65.64209759300282\n",
      "    val_log_likelihood: 185.07922313848243\n",
      "    val_log_marginal: 80.79651984640716\n",
      "Train Epoch: 86 [512/17352 (3%)] Loss: -85.489548\n",
      "Train Epoch: 86 [10360/17352 (60%)] Loss: -104.679216\n",
      "Train Epoch: 86 [16934/17352 (98%)] Loss: -55.382070\n",
      "    epoch          : 86\n",
      "    loss           : -77.39372876806254\n",
      "    val_loss       : -71.08063931099359\n",
      "    val_log_likelihood: 193.8709344361646\n",
      "    val_log_marginal: 83.26412320216028\n",
      "Train Epoch: 87 [512/17352 (3%)] Loss: -106.543678\n",
      "Train Epoch: 87 [10322/17352 (59%)] Loss: 11.817540\n",
      "Train Epoch: 87 [17335/17352 (100%)] Loss: -117.846460\n",
      "    epoch          : 87\n",
      "    loss           : -91.51106705145489\n",
      "    val_loss       : -66.37371665676592\n",
      "    val_log_likelihood: 208.2826959833436\n",
      "    val_log_marginal: 78.76610970885412\n",
      "Train Epoch: 88 [512/17352 (3%)] Loss: -99.244049\n",
      "Train Epoch: 88 [9941/17352 (57%)] Loss: -65.132894\n",
      "Train Epoch: 88 [17253/17352 (99%)] Loss: -64.057858\n",
      "    epoch          : 88\n",
      "    loss           : -82.20836654395951\n",
      "    val_loss       : -51.86441494426342\n",
      "    val_log_likelihood: 204.91404460689796\n",
      "    val_log_marginal: 67.74557900513592\n",
      "Train Epoch: 89 [512/17352 (3%)] Loss: -74.683441\n",
      "Train Epoch: 89 [10528/17352 (61%)] Loss: -115.509416\n",
      "Train Epoch: 89 [17253/17352 (99%)] Loss: -105.035130\n",
      "    epoch          : 89\n",
      "    loss           : -76.81716573550993\n",
      "    val_loss       : -74.01909132425479\n",
      "    val_log_likelihood: 206.93914435883335\n",
      "    val_log_marginal: 87.98692804863158\n",
      "Train Epoch: 90 [512/17352 (3%)] Loss: -101.213211\n",
      "Train Epoch: 90 [10057/17352 (58%)] Loss: -52.066279\n",
      "Train Epoch: 90 [16988/17352 (98%)] Loss: -187.173142\n",
      "    epoch          : 90\n",
      "    loss           : -98.09918720199539\n",
      "    val_loss       : -91.01470314637598\n",
      "    val_log_likelihood: 231.98964184290492\n",
      "    val_log_marginal: 101.6011387687831\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0506_152815/checkpoint-epoch90.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 91 [512/17352 (3%)] Loss: -17.690420\n",
      "Train Epoch: 91 [10525/17352 (61%)] Loss: 17.509974\n",
      "Train Epoch: 91 [17133/17352 (99%)] Loss: -51.438255\n",
      "    epoch          : 91\n",
      "    loss           : -102.26727625858545\n",
      "    val_loss       : -90.915235757668\n",
      "    val_log_likelihood: 244.13356784517592\n",
      "    val_log_marginal: 103.74896631141038\n",
      "Train Epoch: 92 [512/17352 (3%)] Loss: -5.609714\n",
      "Train Epoch: 92 [10194/17352 (59%)] Loss: -171.728367\n",
      "Train Epoch: 92 [16988/17352 (98%)] Loss: -104.223893\n",
      "    epoch          : 92\n",
      "    loss           : -106.22086487375469\n",
      "    val_loss       : -101.29078280708463\n",
      "    val_log_likelihood: 245.104769068771\n",
      "    val_log_marginal: 109.6550217974822\n",
      "Train Epoch: 93 [512/17352 (3%)] Loss: -122.418007\n",
      "Train Epoch: 93 [10707/17352 (62%)] Loss: -80.700348\n",
      "Train Epoch: 93 [17277/17352 (100%)] Loss: -121.908892\n",
      "    epoch          : 93\n",
      "    loss           : -112.46818515198127\n",
      "    val_loss       : -93.36706828118565\n",
      "    val_log_likelihood: 248.09148535713092\n",
      "    val_log_marginal: 104.52761355549009\n",
      "Train Epoch: 94 [512/17352 (3%)] Loss: -136.171387\n",
      "Train Epoch: 94 [10263/17352 (59%)] Loss: -97.810951\n",
      "Train Epoch: 94 [17277/17352 (100%)] Loss: -93.502087\n",
      "    epoch          : 94\n",
      "    loss           : -113.44967789079631\n",
      "    val_loss       : -101.1968283063236\n",
      "    val_log_likelihood: 262.26465668465653\n",
      "    val_log_marginal: 111.40862802594148\n",
      "Train Epoch: 95 [512/17352 (3%)] Loss: -134.214020\n",
      "Train Epoch: 95 [10042/17352 (58%)] Loss: -108.429115\n",
      "Train Epoch: 95 [16923/17352 (98%)] Loss: 16.669389\n",
      "    epoch          : 95\n",
      "    loss           : -104.86833802099792\n",
      "    val_loss       : -57.465162942718074\n",
      "    val_log_likelihood: 255.02853018120388\n",
      "    val_log_marginal: 74.48128880926039\n",
      "Train Epoch: 96 [512/17352 (3%)] Loss: -88.522278\n",
      "Train Epoch: 96 [10819/17352 (62%)] Loss: -47.572541\n",
      "Train Epoch: 96 [17126/17352 (99%)] Loss: -179.392287\n",
      "    epoch          : 96\n",
      "    loss           : -101.67168358039338\n",
      "    val_loss       : -98.00288141955261\n",
      "    val_log_likelihood: 253.08426945519102\n",
      "    val_log_marginal: 113.96025698888745\n",
      "Train Epoch: 97 [512/17352 (3%)] Loss: -143.483215\n",
      "Train Epoch: 97 [9868/17352 (57%)] Loss: -98.149251\n",
      "Train Epoch: 97 [16957/17352 (98%)] Loss: -180.116397\n",
      "    epoch          : 97\n",
      "    loss           : -115.99578450499129\n",
      "    val_loss       : -114.41101585690352\n",
      "    val_log_likelihood: 262.71951737554144\n",
      "    val_log_marginal: 125.38820925392842\n",
      "Train Epoch: 98 [512/17352 (3%)] Loss: -144.403488\n",
      "Train Epoch: 98 [10510/17352 (61%)] Loss: -81.870616\n",
      "Train Epoch: 98 [16939/17352 (98%)] Loss: -107.554143\n",
      "    epoch          : 98\n",
      "    loss           : -85.7476101869603\n",
      "    val_loss       : -97.80796479276498\n",
      "    val_log_likelihood: 265.3830233462074\n",
      "    val_log_marginal: 109.12560644367727\n",
      "Train Epoch: 99 [512/17352 (3%)] Loss: -122.763062\n",
      "Train Epoch: 99 [10488/17352 (60%)] Loss: -157.014053\n",
      "Train Epoch: 99 [17090/17352 (98%)] Loss: -14.314499\n",
      "    epoch          : 99\n",
      "    loss           : -50.86787013199028\n",
      "    val_loss       : -27.188700414494818\n",
      "    val_log_likelihood: 229.49585054917736\n",
      "    val_log_marginal: 48.23634954442225\n",
      "Train Epoch: 100 [512/17352 (3%)] Loss: -66.328461\n",
      "Train Epoch: 100 [10541/17352 (61%)] Loss: -69.544911\n",
      "Train Epoch: 100 [16878/17352 (97%)] Loss: -116.181882\n",
      "    epoch          : 100\n",
      "    loss           : -89.21285953990954\n",
      "    val_loss       : -99.21361126994492\n",
      "    val_log_likelihood: 272.49036357096395\n",
      "    val_log_marginal: 113.47168627348425\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0506_152815/checkpoint-epoch100.pth ...\n",
      "Train Epoch: 101 [512/17352 (3%)] Loss: -124.098503\n",
      "Train Epoch: 101 [10051/17352 (58%)] Loss: -71.119952\n",
      "Train Epoch: 101 [17108/17352 (99%)] Loss: -173.784597\n",
      "    epoch          : 101\n",
      "    loss           : -122.31223148946462\n",
      "    val_loss       : -113.18714006338875\n",
      "    val_log_likelihood: 288.7834812136166\n",
      "    val_log_marginal: 127.04808400645942\n",
      "Train Epoch: 102 [512/17352 (3%)] Loss: -156.004883\n",
      "Train Epoch: 102 [10645/17352 (61%)] Loss: -94.005466\n",
      "Train Epoch: 102 [17335/17352 (100%)] Loss: -233.381167\n",
      "    epoch          : 102\n",
      "    loss           : -146.67063002078095\n",
      "    val_loss       : -130.7641494479541\n",
      "    val_log_likelihood: 297.2903022242511\n",
      "    val_log_marginal: 144.16215256912196\n",
      "Train Epoch: 103 [512/17352 (3%)] Loss: -170.005051\n",
      "Train Epoch: 103 [10548/17352 (61%)] Loss: -130.141385\n",
      "Train Epoch: 103 [17124/17352 (99%)] Loss: -160.612487\n",
      "    epoch          : 103\n",
      "    loss           : -148.18725172442996\n",
      "    val_loss       : -123.44193160393469\n",
      "    val_log_likelihood: 300.7332126757633\n",
      "    val_log_marginal: 141.32405442504913\n",
      "Train Epoch: 104 [512/17352 (3%)] Loss: -181.195007\n",
      "Train Epoch: 104 [10545/17352 (61%)] Loss: -204.972274\n",
      "Train Epoch: 104 [17016/17352 (98%)] Loss: -110.232580\n",
      "    epoch          : 104\n",
      "    loss           : -137.15879369137429\n",
      "    val_loss       : -134.15129851790707\n",
      "    val_log_likelihood: 304.12877525638913\n",
      "    val_log_marginal: 146.81050054919297\n",
      "Train Epoch: 105 [512/17352 (3%)] Loss: -153.226410\n",
      "Train Epoch: 105 [10745/17352 (62%)] Loss: -214.312757\n",
      "Train Epoch: 105 [16878/17352 (97%)] Loss: -156.203919\n",
      "    epoch          : 105\n",
      "    loss           : -149.617850041499\n",
      "    val_loss       : -135.09518850137619\n",
      "    val_log_likelihood: 308.1115670487733\n",
      "    val_log_marginal: 151.57170692047433\n",
      "Train Epoch: 106 [512/17352 (3%)] Loss: -179.677887\n",
      "Train Epoch: 106 [10049/17352 (58%)] Loss: -245.585692\n",
      "Train Epoch: 106 [17101/17352 (99%)] Loss: -117.294945\n",
      "    epoch          : 106\n",
      "    loss           : -154.8976780807601\n",
      "    val_loss       : -128.30096790802486\n",
      "    val_log_likelihood: 322.0562411475809\n",
      "    val_log_marginal: 144.7878691337523\n",
      "Train Epoch: 107 [512/17352 (3%)] Loss: -160.567383\n",
      "Train Epoch: 107 [10503/17352 (61%)] Loss: -49.825227\n",
      "Train Epoch: 107 [16988/17352 (98%)] Loss: -126.364432\n",
      "    epoch          : 107\n",
      "    loss           : -164.9238695220325\n",
      "    val_loss       : -159.39012738962145\n",
      "    val_log_likelihood: 332.8795571372873\n",
      "    val_log_marginal: 172.04210359082046\n",
      "Train Epoch: 108 [512/17352 (3%)] Loss: -201.160019\n",
      "Train Epoch: 108 [9692/17352 (56%)] Loss: -221.818089\n",
      "Train Epoch: 108 [16883/17352 (97%)] Loss: -250.553600\n",
      "    epoch          : 108\n",
      "    loss           : -181.23572101735834\n",
      "    val_loss       : -167.58464578104923\n",
      "    val_log_likelihood: 345.4870290790479\n",
      "    val_log_marginal: 181.28517382846388\n",
      "Train Epoch: 109 [512/17352 (3%)] Loss: -214.820099\n",
      "Train Epoch: 109 [10711/17352 (62%)] Loss: -101.179842\n",
      "Train Epoch: 109 [16934/17352 (98%)] Loss: -113.048842\n",
      "    epoch          : 109\n",
      "    loss           : -185.53173814004876\n",
      "    val_loss       : -163.86298106630085\n",
      "    val_log_likelihood: 351.3908514679496\n",
      "    val_log_marginal: 176.12290849771253\n",
      "Train Epoch: 110 [512/17352 (3%)] Loss: -204.481400\n",
      "Train Epoch: 110 [9894/17352 (57%)] Loss: -156.730567\n",
      "Train Epoch: 110 [16878/17352 (97%)] Loss: 16.237601\n",
      "    epoch          : 110\n",
      "    loss           : -160.9735348656592\n",
      "    val_loss       : 68.88623293797436\n",
      "    val_log_likelihood: 328.9855619365754\n",
      "    val_log_marginal: -37.40244507236504\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0506_152815/checkpoint-epoch110.pth ...\n",
      "Train Epoch: 111 [512/17352 (3%)] Loss: -38.664528\n",
      "Train Epoch: 111 [10649/17352 (61%)] Loss: -103.564593\n",
      "Train Epoch: 111 [17064/17352 (98%)] Loss: 26.513926\n",
      "    epoch          : 111\n",
      "    loss           : -94.38025714983183\n",
      "    val_loss       : -111.53385243387581\n",
      "    val_log_likelihood: 333.7537958445393\n",
      "    val_log_marginal: 133.38123849186775\n",
      "Train Epoch: 112 [512/17352 (3%)] Loss: -140.159515\n",
      "Train Epoch: 112 [10345/17352 (60%)] Loss: -132.870832\n",
      "Train Epoch: 112 [16887/17352 (97%)] Loss: -200.977865\n",
      "    epoch          : 112\n",
      "    loss           : -163.15322242268104\n",
      "    val_loss       : -168.05718930599312\n",
      "    val_log_likelihood: 350.3011859212668\n",
      "    val_log_marginal: 184.9644173202594\n",
      "Train Epoch: 113 [512/17352 (3%)] Loss: -210.731430\n",
      "Train Epoch: 113 [10609/17352 (61%)] Loss: -143.282901\n",
      "Train Epoch: 113 [17106/17352 (99%)] Loss: -264.107326\n",
      "    epoch          : 113\n",
      "    loss           : -178.7581871476813\n",
      "    val_loss       : -96.16821703172405\n",
      "    val_log_likelihood: 363.97719504473173\n",
      "    val_log_marginal: 112.56434656094812\n",
      "Train Epoch: 114 [512/17352 (3%)] Loss: -179.967865\n",
      "Train Epoch: 114 [9745/17352 (56%)] Loss: -142.961691\n",
      "Train Epoch: 114 [17044/17352 (98%)] Loss: -101.704718\n",
      "    epoch          : 114\n",
      "    loss           : -131.62640352025713\n",
      "    val_loss       : -146.9364343865766\n",
      "    val_log_likelihood: 335.58830270937074\n",
      "    val_log_marginal: 161.0885425283671\n",
      "Train Epoch: 115 [512/17352 (3%)] Loss: -155.439133\n",
      "Train Epoch: 115 [10369/17352 (60%)] Loss: -149.113001\n",
      "Train Epoch: 115 [16958/17352 (98%)] Loss: -186.017337\n",
      "    epoch          : 115\n",
      "    loss           : -177.01092715629443\n",
      "    val_loss       : -110.51253980965441\n",
      "    val_log_likelihood: 368.62384974342183\n",
      "    val_log_marginal: 186.9673610097147\n",
      "Train Epoch: 116 [512/17352 (3%)] Loss: -185.148193\n",
      "Train Epoch: 116 [10351/17352 (60%)] Loss: -29.250979\n",
      "Train Epoch: 116 [17106/17352 (99%)] Loss: -206.115885\n",
      "    epoch          : 116\n",
      "    loss           : -166.63909472399354\n",
      "    val_loss       : -171.97002385213395\n",
      "    val_log_likelihood: 374.4116017202533\n",
      "    val_log_marginal: 195.18359149967583\n",
      "Train Epoch: 117 [512/17352 (3%)] Loss: -231.818024\n",
      "Train Epoch: 117 [10312/17352 (59%)] Loss: -215.713704\n",
      "Train Epoch: 117 [17153/17352 (99%)] Loss: -283.502927\n",
      "    epoch          : 117\n",
      "    loss           : -205.63924288699772\n",
      "    val_loss       : -197.00678983328902\n",
      "    val_log_likelihood: 391.1946734398981\n",
      "    val_log_marginal: 211.67993917467203\n",
      "Train Epoch: 118 [512/17352 (3%)] Loss: -251.718781\n",
      "Train Epoch: 118 [9978/17352 (58%)] Loss: -267.366002\n",
      "Train Epoch: 118 [17124/17352 (99%)] Loss: -303.337733\n",
      "    epoch          : 118\n",
      "    loss           : -226.9548295986815\n",
      "    val_loss       : -209.0652379991273\n",
      "    val_log_likelihood: 402.71864695741635\n",
      "    val_log_marginal: 222.8103441756938\n",
      "Train Epoch: 119 [512/17352 (3%)] Loss: -269.832062\n",
      "Train Epoch: 119 [10442/17352 (60%)] Loss: -168.288763\n",
      "Train Epoch: 119 [17090/17352 (98%)] Loss: -234.086715\n",
      "    epoch          : 119\n",
      "    loss           : -221.88484428926017\n",
      "    val_loss       : -206.7210718940381\n",
      "    val_log_likelihood: 403.01522829394526\n",
      "    val_log_marginal: 220.4166488956852\n",
      "Train Epoch: 120 [512/17352 (3%)] Loss: -248.814072\n",
      "Train Epoch: 120 [9988/17352 (58%)] Loss: -223.741871\n",
      "Train Epoch: 120 [17064/17352 (98%)] Loss: -189.321678\n",
      "    epoch          : 120\n",
      "    loss           : -215.18229503262447\n",
      "    val_loss       : -194.7160668101877\n",
      "    val_log_likelihood: 414.4284118136642\n",
      "    val_log_marginal: 212.4658021613334\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0506_152815/checkpoint-epoch120.pth ...\n",
      "Train Epoch: 121 [512/17352 (3%)] Loss: -226.352783\n",
      "Train Epoch: 121 [9931/17352 (57%)] Loss: -207.710411\n",
      "Train Epoch: 121 [16887/17352 (97%)] Loss: -234.356510\n",
      "    epoch          : 121\n",
      "    loss           : -205.30742580083867\n",
      "    val_loss       : -204.36717990269236\n",
      "    val_log_likelihood: 412.89514170274225\n",
      "    val_log_marginal: 226.45307935318513\n",
      "Train Epoch: 122 [512/17352 (3%)] Loss: -260.360687\n",
      "Train Epoch: 122 [10309/17352 (59%)] Loss: -278.356506\n",
      "Train Epoch: 122 [17049/17352 (98%)] Loss: -227.171816\n",
      "    epoch          : 122\n",
      "    loss           : -235.5164523112417\n",
      "    val_loss       : -221.6052987803855\n",
      "    val_log_likelihood: 426.6794725267216\n",
      "    val_log_marginal: 235.26566010929446\n",
      "Train Epoch: 123 [512/17352 (3%)] Loss: -274.192780\n",
      "Train Epoch: 123 [10345/17352 (60%)] Loss: -203.078730\n",
      "Train Epoch: 123 [16934/17352 (98%)] Loss: -367.691298\n",
      "    epoch          : 123\n",
      "    loss           : -248.68590490765695\n",
      "    val_loss       : -242.63551988433014\n",
      "    val_log_likelihood: 440.17364013046665\n",
      "    val_log_marginal: 256.3684595402654\n",
      "Train Epoch: 124 [512/17352 (3%)] Loss: -290.676605\n",
      "Train Epoch: 124 [10580/17352 (61%)] Loss: -328.961636\n",
      "Train Epoch: 124 [17133/17352 (99%)] Loss: -198.604926\n",
      "    epoch          : 124\n",
      "    loss           : -259.4309102573084\n",
      "    val_loss       : -215.5216030043332\n",
      "    val_log_likelihood: 440.6665931093527\n",
      "    val_log_marginal: 237.79245013130998\n",
      "Train Epoch: 125 [512/17352 (3%)] Loss: -283.222382\n",
      "Train Epoch: 125 [10641/17352 (61%)] Loss: -217.061762\n",
      "Train Epoch: 125 [16883/17352 (97%)] Loss: -259.536592\n",
      "    epoch          : 125\n",
      "    loss           : -251.6743377407165\n",
      "    val_loss       : -173.77167634608927\n",
      "    val_log_likelihood: 446.2778831707815\n",
      "    val_log_marginal: 188.39594484381405\n",
      "Train Epoch: 126 [512/17352 (3%)] Loss: -235.653885\n",
      "Train Epoch: 126 [10212/17352 (59%)] Loss: -335.363132\n",
      "Train Epoch: 126 [16934/17352 (98%)] Loss: -246.882382\n",
      "    epoch          : 126\n",
      "    loss           : -250.64719544109812\n",
      "    val_loss       : -234.53925227913473\n",
      "    val_log_likelihood: 449.9705745037714\n",
      "    val_log_marginal: 254.85823696263645\n",
      "Train Epoch: 127 [512/17352 (3%)] Loss: -303.791382\n",
      "Train Epoch: 127 [10629/17352 (61%)] Loss: -331.120293\n",
      "Train Epoch: 127 [16958/17352 (98%)] Loss: -198.332298\n",
      "    epoch          : 127\n",
      "    loss           : -265.44068156460935\n",
      "    val_loss       : -257.80064975653823\n",
      "    val_log_likelihood: 462.01436754409843\n",
      "    val_log_marginal: 273.80615921101287\n",
      "Train Epoch: 128 [512/17352 (3%)] Loss: -302.005615\n",
      "Train Epoch: 128 [10401/17352 (60%)] Loss: -295.238917\n",
      "Train Epoch: 128 [16957/17352 (98%)] Loss: -327.839681\n",
      "    epoch          : 128\n",
      "    loss           : -274.66803918627954\n",
      "    val_loss       : -255.58327952101246\n",
      "    val_log_likelihood: 476.32981494093593\n",
      "    val_log_marginal: 277.11234947759203\n",
      "Train Epoch: 129 [512/17352 (3%)] Loss: -302.153625\n",
      "Train Epoch: 129 [9867/17352 (57%)] Loss: -230.054893\n",
      "Train Epoch: 129 [17277/17352 (100%)] Loss: -239.291193\n",
      "    epoch          : 129\n",
      "    loss           : -286.17714335562044\n",
      "    val_loss       : -267.9558702981356\n",
      "    val_log_likelihood: 480.54360643464776\n",
      "    val_log_marginal: 281.2272897710599\n",
      "Train Epoch: 130 [512/17352 (3%)] Loss: -309.744171\n",
      "Train Epoch: 130 [10519/17352 (61%)] Loss: -207.046939\n",
      "Train Epoch: 130 [16957/17352 (98%)] Loss: -354.333399\n",
      "    epoch          : 130\n",
      "    loss           : -297.90238117510796\n",
      "    val_loss       : -279.0643683232296\n",
      "    val_log_likelihood: 492.5038794664925\n",
      "    val_log_marginal: 290.21697379892146\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0506_152815/checkpoint-epoch130.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 131 [512/17352 (3%)] Loss: -321.258057\n",
      "Train Epoch: 131 [10218/17352 (59%)] Loss: -413.849214\n",
      "Train Epoch: 131 [17126/17352 (99%)] Loss: -210.606166\n",
      "    epoch          : 131\n",
      "    loss           : -291.02637222211075\n",
      "    val_loss       : -256.38250182610875\n",
      "    val_log_likelihood: 486.82000818284604\n",
      "    val_log_marginal: 275.99206413868126\n",
      "Train Epoch: 132 [512/17352 (3%)] Loss: -319.614777\n",
      "Train Epoch: 132 [10511/17352 (61%)] Loss: -275.579241\n",
      "Train Epoch: 132 [16923/17352 (98%)] Loss: -337.679714\n",
      "    epoch          : 132\n",
      "    loss           : -280.82861348279346\n",
      "    val_loss       : -270.69410343435504\n",
      "    val_log_likelihood: 492.30297214579656\n",
      "    val_log_marginal: 288.52463258770877\n",
      "Train Epoch: 133 [512/17352 (3%)] Loss: -336.757141\n",
      "Train Epoch: 133 [10281/17352 (59%)] Loss: -227.784255\n",
      "Train Epoch: 133 [17090/17352 (98%)] Loss: -292.923073\n",
      "    epoch          : 133\n",
      "    loss           : -258.7103346868987\n",
      "    val_loss       : -232.558379131239\n",
      "    val_log_likelihood: 486.68571423079237\n",
      "    val_log_marginal: 264.79178168200485\n",
      "Train Epoch: 134 [512/17352 (3%)] Loss: -304.809692\n",
      "Train Epoch: 134 [10198/17352 (59%)] Loss: -318.394991\n",
      "Train Epoch: 134 [17106/17352 (99%)] Loss: -248.465782\n",
      "    epoch          : 134\n",
      "    loss           : -293.9408038240732\n",
      "    val_loss       : -271.5829068962574\n",
      "    val_log_likelihood: 502.8152270471391\n",
      "    val_log_marginal: 295.4167817579892\n",
      "Train Epoch: 135 [512/17352 (3%)] Loss: -340.225372\n",
      "Train Epoch: 135 [10224/17352 (59%)] Loss: -354.949435\n",
      "Train Epoch: 135 [17106/17352 (99%)] Loss: -379.684246\n",
      "    epoch          : 135\n",
      "    loss           : -292.19267569191834\n",
      "    val_loss       : -280.820462181658\n",
      "    val_log_likelihood: 504.04732028410353\n",
      "    val_log_marginal: 298.4672762926509\n",
      "Train Epoch: 136 [512/17352 (3%)] Loss: -353.348633\n",
      "Train Epoch: 136 [10262/17352 (59%)] Loss: -91.322463\n",
      "Train Epoch: 136 [16882/17352 (97%)] Loss: -270.285400\n",
      "    epoch          : 136\n",
      "    loss           : -271.5719502291888\n",
      "    val_loss       : -231.85428557521138\n",
      "    val_log_likelihood: 464.16858027796354\n",
      "    val_log_marginal: 247.23369892672497\n",
      "Train Epoch: 137 [512/17352 (3%)] Loss: -304.561768\n",
      "Train Epoch: 137 [10186/17352 (59%)] Loss: -313.895905\n",
      "Train Epoch: 137 [16958/17352 (98%)] Loss: -380.698473\n",
      "    epoch          : 137\n",
      "    loss           : -282.79832430563727\n",
      "    val_loss       : -279.4151333129884\n",
      "    val_log_likelihood: 506.86131107768233\n",
      "    val_log_marginal: 294.0776095399479\n",
      "Train Epoch: 138 [512/17352 (3%)] Loss: -327.247131\n",
      "Train Epoch: 138 [10462/17352 (60%)] Loss: -384.868021\n",
      "Train Epoch: 138 [17126/17352 (99%)] Loss: -362.564554\n",
      "    epoch          : 138\n",
      "    loss           : -318.30358677113094\n",
      "    val_loss       : -285.2844848510607\n",
      "    val_log_likelihood: 525.8796220340413\n",
      "    val_log_marginal: 302.0839267745277\n",
      "Train Epoch: 139 [512/17352 (3%)] Loss: -343.499298\n",
      "Train Epoch: 139 [9945/17352 (57%)] Loss: -351.717631\n",
      "Train Epoch: 139 [17090/17352 (98%)] Loss: -408.728989\n",
      "    epoch          : 139\n",
      "    loss           : -325.09309587487826\n",
      "    val_loss       : -262.76261738849485\n",
      "    val_log_likelihood: 499.3790115179071\n",
      "    val_log_marginal: 275.69315896237225\n",
      "Train Epoch: 140 [512/17352 (3%)] Loss: -333.387451\n",
      "Train Epoch: 140 [10506/17352 (61%)] Loss: -369.756637\n",
      "Train Epoch: 140 [17124/17352 (99%)] Loss: -443.414008\n",
      "    epoch          : 140\n",
      "    loss           : -322.32807453418786\n",
      "    val_loss       : -298.0677207152952\n",
      "    val_log_likelihood: 538.2152201675078\n",
      "    val_log_marginal: 324.7194925186958\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0506_152815/checkpoint-epoch140.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 141 [512/17352 (3%)] Loss: -339.233887\n",
      "Train Epoch: 141 [9931/17352 (57%)] Loss: -424.521754\n",
      "Train Epoch: 141 [16878/17352 (97%)] Loss: -421.338763\n",
      "    epoch          : 141\n",
      "    loss           : -340.26708785559595\n",
      "    val_loss       : -313.3049626828341\n",
      "    val_log_likelihood: 538.8433036202109\n",
      "    val_log_marginal: 332.044829099479\n",
      "Train Epoch: 142 [512/17352 (3%)] Loss: -395.000580\n",
      "Train Epoch: 142 [10641/17352 (61%)] Loss: -227.683463\n",
      "Train Epoch: 142 [16923/17352 (98%)] Loss: -472.994170\n",
      "    epoch          : 142\n",
      "    loss           : -354.56123772311645\n",
      "    val_loss       : -333.29580044128903\n",
      "    val_log_likelihood: 560.2888924810103\n",
      "    val_log_marginal: 348.5950485341479\n",
      "Train Epoch: 143 [512/17352 (3%)] Loss: -399.798615\n",
      "Train Epoch: 143 [10549/17352 (61%)] Loss: -331.040332\n",
      "Train Epoch: 143 [17253/17352 (99%)] Loss: -291.884019\n",
      "    epoch          : 143\n",
      "    loss           : -334.7630949838139\n",
      "    val_loss       : -308.7161185037668\n",
      "    val_log_likelihood: 556.3672157731986\n",
      "    val_log_marginal: 326.25411058057233\n",
      "Train Epoch: 144 [512/17352 (3%)] Loss: -376.520386\n",
      "Train Epoch: 144 [10288/17352 (59%)] Loss: -381.395729\n",
      "Train Epoch: 144 [16934/17352 (98%)] Loss: -448.582380\n",
      "    epoch          : 144\n",
      "    loss           : -356.4163309929148\n",
      "    val_loss       : -337.5717457299622\n",
      "    val_log_likelihood: 568.4835320685588\n",
      "    val_log_marginal: 357.60248288901363\n",
      "Train Epoch: 145 [512/17352 (3%)] Loss: -402.366425\n",
      "Train Epoch: 145 [10253/17352 (59%)] Loss: -448.584283\n",
      "Train Epoch: 145 [17153/17352 (99%)] Loss: -469.431787\n",
      "    epoch          : 145\n",
      "    loss           : -368.4211811548545\n",
      "    val_loss       : -340.9809448821911\n",
      "    val_log_likelihood: 582.8328931578609\n",
      "    val_log_marginal: 361.330633676312\n",
      "Train Epoch: 146 [512/17352 (3%)] Loss: -259.524933\n",
      "Train Epoch: 146 [10403/17352 (60%)] Loss: -419.895567\n",
      "Train Epoch: 146 [16988/17352 (98%)] Loss: -461.595906\n",
      "    epoch          : 146\n",
      "    loss           : -362.6582127624048\n",
      "    val_loss       : -317.76395050245713\n",
      "    val_log_likelihood: 572.9819431839746\n",
      "    val_log_marginal: 348.6263853668721\n",
      "Train Epoch: 147 [512/17352 (3%)] Loss: -377.194153\n",
      "Train Epoch: 147 [10194/17352 (59%)] Loss: -258.666025\n",
      "Train Epoch: 147 [17133/17352 (99%)] Loss: -408.421944\n",
      "    epoch          : 147\n",
      "    loss           : -365.51452151937417\n",
      "    val_loss       : -321.5320152768227\n",
      "    val_log_likelihood: 570.9524263971753\n",
      "    val_log_marginal: 343.3463783233834\n",
      "Train Epoch: 148 [512/17352 (3%)] Loss: -175.861145\n",
      "Train Epoch: 148 [10370/17352 (60%)] Loss: -460.413845\n",
      "Train Epoch: 148 [16923/17352 (98%)] Loss: -447.262377\n",
      "    epoch          : 148\n",
      "    loss           : -366.85544925012744\n",
      "    val_loss       : -338.2034129417615\n",
      "    val_log_likelihood: 570.1692735612232\n",
      "    val_log_marginal: 355.86634620951605\n",
      "Train Epoch: 149 [512/17352 (3%)] Loss: -409.406769\n",
      "Train Epoch: 149 [9731/17352 (56%)] Loss: -316.745717\n",
      "Train Epoch: 149 [16887/17352 (97%)] Loss: -405.854722\n",
      "    epoch          : 149\n",
      "    loss           : -374.5407032610581\n",
      "    val_loss       : -343.6861980652567\n",
      "    val_log_likelihood: 579.3052480717612\n",
      "    val_log_marginal: 364.21609493633406\n",
      "Train Epoch: 150 [512/17352 (3%)] Loss: -410.245911\n",
      "Train Epoch: 150 [10430/17352 (60%)] Loss: -384.888652\n",
      "Train Epoch: 150 [16872/17352 (97%)] Loss: -396.590325\n",
      "    epoch          : 150\n",
      "    loss           : -384.30553589269033\n",
      "    val_loss       : -352.33501488500565\n",
      "    val_log_likelihood: 593.4593374067472\n",
      "    val_log_marginal: 367.9111297457759\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0506_152815/checkpoint-epoch150.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 151 [512/17352 (3%)] Loss: -428.269745\n",
      "Train Epoch: 151 [10140/17352 (58%)] Loss: -432.937421\n",
      "Train Epoch: 151 [16988/17352 (98%)] Loss: -384.001570\n",
      "    epoch          : 151\n",
      "    loss           : -362.180176947811\n",
      "    val_loss       : -310.1894757736425\n",
      "    val_log_likelihood: 580.1378534692013\n",
      "    val_log_marginal: 327.3490185518582\n",
      "Train Epoch: 152 [512/17352 (3%)] Loss: -226.303238\n",
      "Train Epoch: 152 [10944/17352 (63%)] Loss: -440.804093\n",
      "Train Epoch: 152 [17126/17352 (99%)] Loss: -396.523344\n",
      "    epoch          : 152\n",
      "    loss           : -356.5276632863186\n",
      "    val_loss       : -314.5001229558948\n",
      "    val_log_likelihood: 594.2776846745926\n",
      "    val_log_marginal: 335.8022878276244\n",
      "Train Epoch: 153 [512/17352 (3%)] Loss: -404.470337\n",
      "Train Epoch: 153 [10534/17352 (61%)] Loss: -401.916025\n",
      "Train Epoch: 153 [16992/17352 (98%)] Loss: 1695.902001\n",
      "    epoch          : 153\n",
      "    loss           : -265.89529642459047\n",
      "    val_loss       : 342.5599495017356\n",
      "    val_log_likelihood: 469.40744328524346\n",
      "    val_log_marginal: -288.81604633350884\n",
      "Train Epoch: 154 [512/17352 (3%)] Loss: 418.402802\n",
      "Train Epoch: 154 [10942/17352 (63%)] Loss: -69.861889\n",
      "Train Epoch: 154 [17263/17352 (99%)] Loss: 134.394067\n",
      "    epoch          : 154\n",
      "    loss           : -81.24988822739488\n",
      "    val_loss       : -200.00927399279578\n",
      "    val_log_likelihood: 504.0520300469345\n",
      "    val_log_marginal: 234.88498237734993\n",
      "Train Epoch: 155 [512/17352 (3%)] Loss: -84.136002\n",
      "Train Epoch: 155 [10890/17352 (63%)] Loss: -361.141732\n",
      "Train Epoch: 155 [17044/17352 (98%)] Loss: -338.598317\n",
      "    epoch          : 155\n",
      "    loss           : -315.69997376874085\n",
      "    val_loss       : -308.1735437587822\n",
      "    val_log_likelihood: 565.5364337433409\n",
      "    val_log_marginal: 329.233133438797\n",
      "Train Epoch: 156 [512/17352 (3%)] Loss: -398.436310\n",
      "Train Epoch: 156 [10405/17352 (60%)] Loss: -454.350131\n",
      "Train Epoch: 156 [17044/17352 (98%)] Loss: -399.972656\n",
      "    epoch          : 156\n",
      "    loss           : -376.1874964753383\n",
      "    val_loss       : -351.0456037069962\n",
      "    val_log_likelihood: 601.3290151966536\n",
      "    val_log_marginal: 373.2873230121487\n",
      "Train Epoch: 157 [512/17352 (3%)] Loss: -443.649109\n",
      "Train Epoch: 157 [10224/17352 (59%)] Loss: -459.731234\n",
      "Train Epoch: 157 [17263/17352 (99%)] Loss: -445.376590\n",
      "    epoch          : 157\n",
      "    loss           : -401.8031865961624\n",
      "    val_loss       : -368.56458065369895\n",
      "    val_log_likelihood: 613.6519879597215\n",
      "    val_log_marginal: 389.903716686823\n",
      "Train Epoch: 158 [512/17352 (3%)] Loss: -446.672485\n",
      "Train Epoch: 158 [10198/17352 (59%)] Loss: -486.651028\n",
      "Train Epoch: 158 [16934/17352 (98%)] Loss: -386.772579\n",
      "    epoch          : 158\n",
      "    loss           : -406.6008392974717\n",
      "    val_loss       : -366.46962773174016\n",
      "    val_log_likelihood: 624.4336359031214\n",
      "    val_log_marginal: 385.40767587682626\n",
      "Train Epoch: 159 [512/17352 (3%)] Loss: -435.779846\n",
      "Train Epoch: 159 [10389/17352 (60%)] Loss: -483.248929\n",
      "Train Epoch: 159 [17090/17352 (98%)] Loss: -375.387323\n",
      "    epoch          : 159\n",
      "    loss           : -412.61381647276556\n",
      "    val_loss       : -384.7521532827332\n",
      "    val_log_likelihood: 628.7333557738677\n",
      "    val_log_marginal: 404.4918692192989\n",
      "Train Epoch: 160 [512/17352 (3%)] Loss: -463.248840\n",
      "Train Epoch: 160 [10713/17352 (62%)] Loss: -498.130116\n",
      "Train Epoch: 160 [17335/17352 (100%)] Loss: -465.790650\n",
      "    epoch          : 160\n",
      "    loss           : -425.06013013661004\n",
      "    val_loss       : -363.4930652364134\n",
      "    val_log_likelihood: 635.3239216478446\n",
      "    val_log_marginal: 378.8863877083454\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0506_152815/checkpoint-epoch160.pth ...\n",
      "Train Epoch: 161 [512/17352 (3%)] Loss: -427.429993\n",
      "Train Epoch: 161 [10233/17352 (59%)] Loss: -264.796101\n",
      "Train Epoch: 161 [17106/17352 (99%)] Loss: -467.031214\n",
      "    epoch          : 161\n",
      "    loss           : -418.6378560589207\n",
      "    val_loss       : -380.27219668372504\n",
      "    val_log_likelihood: 640.4100127593872\n",
      "    val_log_marginal: 401.9126004195366\n",
      "Train Epoch: 162 [512/17352 (3%)] Loss: -474.900635\n",
      "Train Epoch: 162 [9927/17352 (57%)] Loss: -334.570574\n",
      "Train Epoch: 162 [16878/17352 (97%)] Loss: -482.968859\n",
      "    epoch          : 162\n",
      "    loss           : -431.1972914008818\n",
      "    val_loss       : -392.7222408263897\n",
      "    val_log_likelihood: 649.2893430906223\n",
      "    val_log_marginal: 416.38973744690423\n",
      "Train Epoch: 163 [512/17352 (3%)] Loss: -483.990631\n",
      "Train Epoch: 163 [10028/17352 (58%)] Loss: -501.845104\n",
      "Train Epoch: 163 [17106/17352 (99%)] Loss: -380.944258\n",
      "    epoch          : 163\n",
      "    loss           : -436.58191195184025\n",
      "    val_loss       : -371.34704910552335\n",
      "    val_log_likelihood: 656.890760410378\n",
      "    val_log_marginal: 391.9409069330902\n",
      "Train Epoch: 164 [512/17352 (3%)] Loss: -466.054016\n",
      "Train Epoch: 164 [10314/17352 (59%)] Loss: -424.151187\n",
      "Train Epoch: 164 [16958/17352 (98%)] Loss: 305.903924\n",
      "    epoch          : 164\n",
      "    loss           : -286.6324643287211\n",
      "    val_loss       : 137.96938857771627\n",
      "    val_log_likelihood: 564.4824477327217\n",
      "    val_log_marginal: -84.01456385135745\n",
      "Train Epoch: 165 [512/17352 (3%)] Loss: 139.313812\n",
      "Train Epoch: 165 [10989/17352 (63%)] Loss: -81.905981\n",
      "Train Epoch: 165 [17253/17352 (99%)] Loss: -443.314342\n",
      "    epoch          : 165\n",
      "    loss           : -265.49543167795207\n",
      "    val_loss       : -283.6030835685022\n",
      "    val_log_likelihood: 600.5594977478515\n",
      "    val_log_marginal: 326.0388927586152\n",
      "Train Epoch: 166 [512/17352 (3%)] Loss: -377.833588\n",
      "Train Epoch: 166 [10688/17352 (62%)] Loss: -235.456233\n",
      "Train Epoch: 166 [16992/17352 (98%)] Loss: -155.318387\n",
      "    epoch          : 166\n",
      "    loss           : -348.0608131936164\n",
      "    val_loss       : -259.39350501266443\n",
      "    val_log_likelihood: 587.1619956674207\n",
      "    val_log_marginal: 343.37092420648867\n",
      "Train Epoch: 167 [512/17352 (3%)] Loss: -399.356415\n",
      "Train Epoch: 167 [10185/17352 (59%)] Loss: -313.578734\n",
      "Train Epoch: 167 [17108/17352 (99%)] Loss: -461.107663\n",
      "    epoch          : 167\n",
      "    loss           : -389.6612560664135\n",
      "    val_loss       : -368.9035763907822\n",
      "    val_log_likelihood: 643.4599035500552\n",
      "    val_log_marginal: 402.83471646721887\n",
      "Train Epoch: 168 [512/17352 (3%)] Loss: -468.281982\n",
      "Train Epoch: 168 [10009/17352 (58%)] Loss: -353.650038\n",
      "Train Epoch: 168 [16887/17352 (97%)] Loss: -516.188805\n",
      "    epoch          : 168\n",
      "    loss           : -428.05215853194727\n",
      "    val_loss       : -382.4131654137747\n",
      "    val_log_likelihood: 643.387229850632\n",
      "    val_log_marginal: 405.20551638364793\n",
      "Train Epoch: 169 [512/17352 (3%)] Loss: -478.866821\n",
      "Train Epoch: 169 [10294/17352 (59%)] Loss: -467.661628\n",
      "Train Epoch: 169 [17277/17352 (100%)] Loss: -425.322030\n",
      "    epoch          : 169\n",
      "    loss           : -443.28855611999967\n",
      "    val_loss       : -402.688601250924\n",
      "    val_log_likelihood: 666.8931426586125\n",
      "    val_log_marginal: 421.10906220906224\n",
      "Train Epoch: 170 [512/17352 (3%)] Loss: -482.816437\n",
      "Train Epoch: 170 [9905/17352 (57%)] Loss: -451.046283\n",
      "Train Epoch: 170 [16883/17352 (97%)] Loss: -415.366502\n",
      "    epoch          : 170\n",
      "    loss           : -450.4847165794205\n",
      "    val_loss       : -410.988011151455\n",
      "    val_log_likelihood: 671.4091274551199\n",
      "    val_log_marginal: 434.2351227350335\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0506_152815/checkpoint-epoch170.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 171 [512/17352 (3%)] Loss: -490.247223\n",
      "Train Epoch: 171 [10647/17352 (61%)] Loss: -526.622231\n",
      "Train Epoch: 171 [17335/17352 (100%)] Loss: -488.095711\n",
      "    epoch          : 171\n",
      "    loss           : -452.4290848825702\n",
      "    val_loss       : -404.2666791207099\n",
      "    val_log_likelihood: 674.5741504693174\n",
      "    val_log_marginal: 428.188004436806\n",
      "Train Epoch: 172 [512/17352 (3%)] Loss: -481.125732\n",
      "Train Epoch: 172 [10221/17352 (59%)] Loss: -501.547808\n",
      "Train Epoch: 172 [17090/17352 (98%)] Loss: -453.392262\n",
      "    epoch          : 172\n",
      "    loss           : -459.51642239675226\n",
      "    val_loss       : -414.8690853089362\n",
      "    val_log_likelihood: 677.4462201579178\n",
      "    val_log_marginal: 428.92149448542847\n",
      "Train Epoch: 173 [512/17352 (3%)] Loss: -508.336182\n",
      "Train Epoch: 173 [10704/17352 (62%)] Loss: -441.903185\n",
      "Train Epoch: 173 [16939/17352 (98%)] Loss: -398.159700\n",
      "    epoch          : 173\n",
      "    loss           : -467.07007019773124\n",
      "    val_loss       : -412.5226859043194\n",
      "    val_log_likelihood: 690.803470279628\n",
      "    val_log_marginal: 434.5960598458001\n",
      "Train Epoch: 174 [512/17352 (3%)] Loss: -489.517975\n",
      "Train Epoch: 174 [10370/17352 (60%)] Loss: -400.823754\n",
      "Train Epoch: 174 [17044/17352 (98%)] Loss: -360.893320\n",
      "    epoch          : 174\n",
      "    loss           : -464.2721392418217\n",
      "    val_loss       : -409.60484175490564\n",
      "    val_log_likelihood: 692.299956272091\n",
      "    val_log_marginal: 431.0469101823193\n",
      "Train Epoch: 175 [512/17352 (3%)] Loss: -491.058258\n",
      "Train Epoch: 175 [10177/17352 (59%)] Loss: -551.391059\n",
      "Train Epoch: 175 [17016/17352 (98%)] Loss: -366.768914\n",
      "    epoch          : 175\n",
      "    loss           : -462.2124204690432\n",
      "    val_loss       : -417.41270123851814\n",
      "    val_log_likelihood: 691.0100061399514\n",
      "    val_log_marginal: 440.63780322923355\n",
      "Train Epoch: 176 [512/17352 (3%)] Loss: -505.818176\n",
      "Train Epoch: 176 [10501/17352 (61%)] Loss: -421.735746\n",
      "Train Epoch: 176 [17044/17352 (98%)] Loss: -382.172352\n",
      "    epoch          : 176\n",
      "    loss           : -436.030508160712\n",
      "    val_loss       : -376.25943354337255\n",
      "    val_log_likelihood: 671.2514603772215\n",
      "    val_log_marginal: 412.79518547729066\n",
      "Train Epoch: 177 [512/17352 (3%)] Loss: -374.996887\n",
      "Train Epoch: 177 [10324/17352 (59%)] Loss: -389.312226\n",
      "Train Epoch: 177 [16878/17352 (97%)] Loss: -329.668324\n",
      "    epoch          : 177\n",
      "    loss           : -426.26452581886997\n",
      "    val_loss       : -380.62282723903553\n",
      "    val_log_likelihood: 690.2464880368553\n",
      "    val_log_marginal: 410.8829219254383\n",
      "Train Epoch: 178 [512/17352 (3%)] Loss: -463.990540\n",
      "Train Epoch: 178 [9552/17352 (55%)] Loss: -449.056792\n",
      "Train Epoch: 178 [17044/17352 (98%)] Loss: -505.500527\n",
      "    epoch          : 178\n",
      "    loss           : -439.8362194472605\n",
      "    val_loss       : -412.2590441397265\n",
      "    val_log_likelihood: 698.6669094992334\n",
      "    val_log_marginal: 439.68515799954685\n",
      "Train Epoch: 179 [512/17352 (3%)] Loss: -505.760803\n",
      "Train Epoch: 179 [9716/17352 (56%)] Loss: -377.931066\n",
      "Train Epoch: 179 [16923/17352 (98%)] Loss: -307.728091\n",
      "    epoch          : 179\n",
      "    loss           : -461.47651973703296\n",
      "    val_loss       : -419.2124569084483\n",
      "    val_log_likelihood: 696.1715482530548\n",
      "    val_log_marginal: 442.92617327079995\n",
      "Train Epoch: 180 [512/17352 (3%)] Loss: -520.962402\n",
      "Train Epoch: 180 [10323/17352 (59%)] Loss: -445.247396\n",
      "Train Epoch: 180 [16878/17352 (97%)] Loss: -407.668015\n",
      "    epoch          : 180\n",
      "    loss           : -461.96174297357777\n",
      "    val_loss       : -410.66135898107115\n",
      "    val_log_likelihood: 697.3509577830612\n",
      "    val_log_marginal: 437.7003602530553\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0506_152815/checkpoint-epoch180.pth ...\n",
      "Train Epoch: 181 [512/17352 (3%)] Loss: -493.227356\n",
      "Train Epoch: 181 [10979/17352 (63%)] Loss: -400.842332\n",
      "Train Epoch: 181 [17101/17352 (99%)] Loss: -512.893874\n",
      "    epoch          : 181\n",
      "    loss           : -476.9594441731187\n",
      "    val_loss       : -430.9324497290751\n",
      "    val_log_likelihood: 711.3729607000361\n",
      "    val_log_marginal: 453.08165459834845\n",
      "Train Epoch: 182 [512/17352 (3%)] Loss: -437.723572\n",
      "Train Epoch: 182 [10574/17352 (61%)] Loss: -379.805651\n",
      "Train Epoch: 182 [17064/17352 (98%)] Loss: -510.843563\n",
      "    epoch          : 182\n",
      "    loss           : -466.3045157871365\n",
      "    val_loss       : -409.39757206432836\n",
      "    val_log_likelihood: 698.7060847684329\n",
      "    val_log_marginal: 434.420145780918\n",
      "Train Epoch: 183 [512/17352 (3%)] Loss: -530.316528\n",
      "Train Epoch: 183 [10037/17352 (58%)] Loss: -455.422344\n",
      "Train Epoch: 183 [17016/17352 (98%)] Loss: -481.496712\n",
      "    epoch          : 183\n",
      "    loss           : -456.7585401965328\n",
      "    val_loss       : -404.3007570736215\n",
      "    val_log_likelihood: 685.9124380815236\n",
      "    val_log_marginal: 426.4924858594719\n",
      "Train Epoch: 184 [512/17352 (3%)] Loss: -506.483276\n",
      "Train Epoch: 184 [10887/17352 (63%)] Loss: -536.860963\n",
      "Train Epoch: 184 [16922/17352 (98%)] Loss: -532.315451\n",
      "    epoch          : 184\n",
      "    loss           : -426.6064528394137\n",
      "    val_loss       : -367.3942528846083\n",
      "    val_log_likelihood: 708.6904643220123\n",
      "    val_log_marginal: 390.7965795383821\n",
      "Train Epoch: 185 [512/17352 (3%)] Loss: -481.227051\n",
      "Train Epoch: 185 [10610/17352 (61%)] Loss: -542.885417\n",
      "Train Epoch: 185 [17049/17352 (98%)] Loss: -517.809014\n",
      "    epoch          : 185\n",
      "    loss           : -396.83314160113\n",
      "    val_loss       : -407.82437061505897\n",
      "    val_log_likelihood: 706.3726370240955\n",
      "    val_log_marginal: 429.5641780076914\n",
      "Train Epoch: 186 [512/17352 (3%)] Loss: -519.041931\n",
      "Train Epoch: 186 [10702/17352 (62%)] Loss: -316.748589\n",
      "Train Epoch: 186 [17335/17352 (100%)] Loss: -560.999267\n",
      "    epoch          : 186\n",
      "    loss           : -467.8746339706772\n",
      "    val_loss       : -376.350478886471\n",
      "    val_log_likelihood: 703.5981175580916\n",
      "    val_log_marginal: 402.3066225973038\n",
      "Train Epoch: 187 [512/17352 (3%)] Loss: -267.844055\n",
      "Train Epoch: 187 [10159/17352 (59%)] Loss: -451.050576\n",
      "Train Epoch: 187 [17090/17352 (98%)] Loss: -452.588674\n",
      "    epoch          : 187\n",
      "    loss           : -473.31956927426654\n",
      "    val_loss       : -385.9355695875141\n",
      "    val_log_likelihood: 715.73646473887\n",
      "    val_log_marginal: 409.27829191695275\n",
      "Train Epoch: 188 [512/17352 (3%)] Loss: -498.077148\n",
      "Train Epoch: 188 [10272/17352 (59%)] Loss: -528.505748\n",
      "Train Epoch: 188 [17263/17352 (99%)] Loss: -360.719442\n",
      "    epoch          : 188\n",
      "    loss           : -443.49257312811943\n",
      "    val_loss       : -370.73263239570025\n",
      "    val_log_likelihood: 710.9833232981271\n",
      "    val_log_marginal: 395.5953988093605\n",
      "Train Epoch: 189 [512/17352 (3%)] Loss: -489.978333\n",
      "Train Epoch: 189 [9805/17352 (57%)] Loss: -338.511010\n",
      "Train Epoch: 189 [17090/17352 (98%)] Loss: -587.096625\n",
      "    epoch          : 189\n",
      "    loss           : -476.63568274964933\n",
      "    val_loss       : -420.80348076409666\n",
      "    val_log_likelihood: 731.006763360528\n",
      "    val_log_marginal: 444.547640998036\n",
      "Train Epoch: 190 [512/17352 (3%)] Loss: -507.878143\n",
      "Train Epoch: 190 [10576/17352 (61%)] Loss: -398.595272\n",
      "Train Epoch: 190 [17143/17352 (99%)] Loss: -445.957347\n",
      "    epoch          : 190\n",
      "    loss           : -497.2859224790221\n",
      "    val_loss       : -426.7813311268625\n",
      "    val_log_likelihood: 690.039219408283\n",
      "    val_log_marginal: 439.2133666634647\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0506_152815/checkpoint-epoch190.pth ...\n",
      "Train Epoch: 191 [512/17352 (3%)] Loss: -520.647888\n",
      "Train Epoch: 191 [10501/17352 (61%)] Loss: -380.153561\n",
      "Train Epoch: 191 [16934/17352 (98%)] Loss: -581.660573\n",
      "    epoch          : 191\n",
      "    loss           : -491.1575358462633\n",
      "    val_loss       : -448.54808496910573\n",
      "    val_log_likelihood: 740.564394146219\n",
      "    val_log_marginal: 470.944437475522\n",
      "Train Epoch: 192 [512/17352 (3%)] Loss: -557.943542\n",
      "Train Epoch: 192 [10085/17352 (58%)] Loss: -582.476834\n",
      "Train Epoch: 192 [17101/17352 (99%)] Loss: -422.196473\n",
      "    epoch          : 192\n",
      "    loss           : -501.03551591340147\n",
      "    val_loss       : -442.1347991809432\n",
      "    val_log_likelihood: 729.3829816755198\n",
      "    val_log_marginal: 465.68577747880715\n",
      "Train Epoch: 193 [512/17352 (3%)] Loss: -541.746216\n",
      "Train Epoch: 193 [9797/17352 (56%)] Loss: -311.497547\n",
      "Train Epoch: 193 [17016/17352 (98%)] Loss: -459.749696\n",
      "    epoch          : 193\n",
      "    loss           : -489.4237832338684\n",
      "    val_loss       : -441.6679996799522\n",
      "    val_log_likelihood: 739.8837300131829\n",
      "    val_log_marginal: 470.2205495329632\n",
      "Train Epoch: 194 [512/17352 (3%)] Loss: -543.088806\n",
      "Train Epoch: 194 [10640/17352 (61%)] Loss: -399.346376\n",
      "Train Epoch: 194 [16958/17352 (98%)] Loss: -560.046875\n",
      "    epoch          : 194\n",
      "    loss           : -507.7862875218023\n",
      "    val_loss       : -447.5983980470484\n",
      "    val_log_likelihood: 745.926997639404\n",
      "    val_log_marginal: 471.9753735976584\n",
      "Train Epoch: 195 [512/17352 (3%)] Loss: -538.122620\n",
      "Train Epoch: 195 [10833/17352 (62%)] Loss: -442.323785\n",
      "Train Epoch: 195 [17064/17352 (98%)] Loss: -482.379940\n",
      "    epoch          : 195\n",
      "    loss           : -522.7198378690832\n",
      "    val_loss       : -450.6434960613966\n",
      "    val_log_likelihood: 752.787022441236\n",
      "    val_log_marginal: 472.0300751788536\n",
      "Train Epoch: 196 [512/17352 (3%)] Loss: -560.990784\n",
      "Train Epoch: 196 [10700/17352 (62%)] Loss: -547.148556\n",
      "Train Epoch: 196 [16883/17352 (97%)] Loss: -397.024675\n",
      "    epoch          : 196\n",
      "    loss           : -515.3889067524975\n",
      "    val_loss       : -467.91221611660967\n",
      "    val_log_likelihood: 763.0558774923014\n",
      "    val_log_marginal: 490.57163976955445\n",
      "Train Epoch: 197 [512/17352 (3%)] Loss: -370.423523\n",
      "Train Epoch: 197 [10695/17352 (62%)] Loss: -563.661762\n",
      "Train Epoch: 197 [17044/17352 (98%)] Loss: -390.098273\n",
      "    epoch          : 197\n",
      "    loss           : -496.97658249187594\n",
      "    val_loss       : -442.37092264714573\n",
      "    val_log_likelihood: 739.7516092159921\n",
      "    val_log_marginal: 470.1557847616352\n",
      "Train Epoch: 198 [512/17352 (3%)] Loss: -514.689453\n",
      "Train Epoch: 198 [10544/17352 (61%)] Loss: -425.731425\n",
      "Train Epoch: 198 [17106/17352 (99%)] Loss: -547.368164\n",
      "    epoch          : 198\n",
      "    loss           : -482.5432042324181\n",
      "    val_loss       : -402.8777165851113\n",
      "    val_log_likelihood: 728.4595676831112\n",
      "    val_log_marginal: 433.07378302634334\n",
      "Train Epoch: 199 [512/17352 (3%)] Loss: -515.955750\n",
      "Train Epoch: 199 [10566/17352 (61%)] Loss: -569.614873\n",
      "Train Epoch: 199 [17153/17352 (99%)] Loss: -418.726899\n",
      "    epoch          : 199\n",
      "    loss           : -491.6435919703631\n",
      "    val_loss       : -411.98279379831297\n",
      "    val_log_likelihood: 742.8512607732041\n",
      "    val_log_marginal: 453.8165993483934\n",
      "Train Epoch: 200 [512/17352 (3%)] Loss: -506.359222\n",
      "Train Epoch: 200 [10698/17352 (62%)] Loss: -291.412530\n",
      "Train Epoch: 200 [17143/17352 (99%)] Loss: -600.694233\n",
      "    epoch          : 200\n",
      "    loss           : -490.62767653988175\n",
      "    val_loss       : -435.67679386921344\n",
      "    val_log_likelihood: 764.8589566536165\n",
      "    val_log_marginal: 463.0017314137185\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0506_152815/checkpoint-epoch200.pth ...\n",
      "Train Epoch: 201 [512/17352 (3%)] Loss: -543.071716\n",
      "Train Epoch: 201 [9953/17352 (57%)] Loss: -541.702191\n",
      "Train Epoch: 201 [16958/17352 (98%)] Loss: -544.723307\n",
      "    epoch          : 201\n",
      "    loss           : -515.2205872932667\n",
      "    val_loss       : -438.03378543330825\n",
      "    val_log_likelihood: 762.4379892641587\n",
      "    val_log_marginal: 463.22268235360065\n",
      "Train Epoch: 202 [512/17352 (3%)] Loss: -549.211609\n",
      "Train Epoch: 202 [10182/17352 (59%)] Loss: -393.725015\n",
      "Train Epoch: 202 [16988/17352 (98%)] Loss: -560.238247\n",
      "    epoch          : 202\n",
      "    loss           : -520.7309078426614\n",
      "    val_loss       : -473.6869692266299\n",
      "    val_log_likelihood: 772.9066844962267\n",
      "    val_log_marginal: 494.94982286153567\n",
      "Train Epoch: 203 [512/17352 (3%)] Loss: -583.073059\n",
      "Train Epoch: 203 [10119/17352 (58%)] Loss: -340.004177\n",
      "Train Epoch: 203 [16988/17352 (98%)] Loss: -558.693208\n",
      "    epoch          : 203\n",
      "    loss           : -528.3754943753739\n",
      "    val_loss       : -469.4615958675503\n",
      "    val_log_likelihood: 770.9811444764719\n",
      "    val_log_marginal: 487.6977416976095\n",
      "Train Epoch: 204 [512/17352 (3%)] Loss: -578.438477\n",
      "Train Epoch: 204 [10041/17352 (58%)] Loss: -473.452532\n",
      "Train Epoch: 204 [17049/17352 (98%)] Loss: -572.107682\n",
      "    epoch          : 204\n",
      "    loss           : -537.6413916587788\n",
      "    val_loss       : -478.9625750624392\n",
      "    val_log_likelihood: 775.946073121901\n",
      "    val_log_marginal: 497.1268214112477\n",
      "Train Epoch: 205 [512/17352 (3%)] Loss: -592.037476\n",
      "Train Epoch: 205 [10342/17352 (60%)] Loss: -635.059959\n",
      "Train Epoch: 205 [16922/17352 (98%)] Loss: -587.991276\n",
      "    epoch          : 205\n",
      "    loss           : -550.3371934641523\n",
      "    val_loss       : -483.8538278506579\n",
      "    val_log_likelihood: 790.1151404136609\n",
      "    val_log_marginal: 504.5131863124319\n",
      "Train Epoch: 206 [512/17352 (3%)] Loss: -589.351318\n",
      "Train Epoch: 206 [10225/17352 (59%)] Loss: -254.267481\n",
      "Train Epoch: 206 [16958/17352 (98%)] Loss: -640.536647\n",
      "    epoch          : 206\n",
      "    loss           : -525.6127080061202\n",
      "    val_loss       : -465.32504670301626\n",
      "    val_log_likelihood: 782.8811505551636\n",
      "    val_log_marginal: 486.880499008038\n",
      "Train Epoch: 207 [512/17352 (3%)] Loss: -585.927124\n",
      "Train Epoch: 207 [10012/17352 (58%)] Loss: -443.022764\n",
      "Train Epoch: 207 [17133/17352 (99%)] Loss: -628.633045\n",
      "    epoch          : 207\n",
      "    loss           : -517.6942763639204\n",
      "    val_loss       : -416.1365665578722\n",
      "    val_log_likelihood: 762.0294250448674\n",
      "    val_log_marginal: 431.6796994882485\n",
      "Train Epoch: 208 [512/17352 (3%)] Loss: -550.109436\n",
      "Train Epoch: 208 [10414/17352 (60%)] Loss: -414.488515\n",
      "Train Epoch: 208 [16878/17352 (97%)] Loss: -195.351338\n",
      "    epoch          : 208\n",
      "    loss           : -334.59854615583623\n",
      "    val_loss       : -178.3025327307303\n",
      "    val_log_likelihood: 719.8006208114704\n",
      "    val_log_marginal: 303.85314852835876\n",
      "Train Epoch: 209 [512/17352 (3%)] Loss: -346.507141\n",
      "Train Epoch: 209 [10310/17352 (59%)] Loss: -316.600535\n",
      "Train Epoch: 209 [17277/17352 (100%)] Loss: -390.451649\n",
      "    epoch          : 209\n",
      "    loss           : -400.02976877247823\n",
      "    val_loss       : -345.518710622362\n",
      "    val_log_likelihood: 728.4435572322014\n",
      "    val_log_marginal: 405.1156378336467\n",
      "Train Epoch: 210 [512/17352 (3%)] Loss: -443.433105\n",
      "Train Epoch: 210 [10299/17352 (59%)] Loss: -601.143801\n",
      "Train Epoch: 210 [16922/17352 (98%)] Loss: -563.823581\n",
      "    epoch          : 210\n",
      "    loss           : -463.8846140777292\n",
      "    val_loss       : -448.9472525898424\n",
      "    val_log_likelihood: 765.9326983030815\n",
      "    val_log_marginal: 485.7966145872823\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0506_152815/checkpoint-epoch210.pth ...\n",
      "Train Epoch: 211 [512/17352 (3%)] Loss: -550.383789\n",
      "Train Epoch: 211 [10545/17352 (61%)] Loss: -607.705901\n",
      "Train Epoch: 211 [17153/17352 (99%)] Loss: -606.682634\n",
      "    epoch          : 211\n",
      "    loss           : -521.8527809030392\n",
      "    val_loss       : -413.3120539147421\n",
      "    val_log_likelihood: 763.7614571495327\n",
      "    val_log_marginal: 449.138801691009\n",
      "Train Epoch: 212 [512/17352 (3%)] Loss: -565.654663\n",
      "Train Epoch: 212 [10227/17352 (59%)] Loss: -571.300121\n",
      "Train Epoch: 212 [16958/17352 (98%)] Loss: -591.923854\n",
      "    epoch          : 212\n",
      "    loss           : -521.2754782185906\n",
      "    val_loss       : -460.7601200575138\n",
      "    val_log_likelihood: 772.1608241844395\n",
      "    val_log_marginal: 490.8135997216515\n",
      "Train Epoch: 213 [512/17352 (3%)] Loss: -580.331787\n",
      "Train Epoch: 213 [10207/17352 (59%)] Loss: -431.248184\n",
      "Train Epoch: 213 [17016/17352 (98%)] Loss: -472.865148\n",
      "    epoch          : 213\n",
      "    loss           : -530.3811459418312\n",
      "    val_loss       : -443.4214938561981\n",
      "    val_log_likelihood: 775.7449542436291\n",
      "    val_log_marginal: 480.86873801174295\n",
      "Train Epoch: 214 [512/17352 (3%)] Loss: -584.428223\n",
      "Train Epoch: 214 [10357/17352 (60%)] Loss: -665.159614\n",
      "Train Epoch: 214 [17106/17352 (99%)] Loss: -350.447839\n",
      "    epoch          : 214\n",
      "    loss           : -524.0149989833357\n",
      "    val_loss       : -441.64174586125654\n",
      "    val_log_likelihood: 777.2173727943997\n",
      "    val_log_marginal: 469.4605270160596\n",
      "Train Epoch: 215 [512/17352 (3%)] Loss: -563.967651\n",
      "Train Epoch: 215 [10332/17352 (60%)] Loss: -591.793764\n",
      "Train Epoch: 215 [17153/17352 (99%)] Loss: -578.541563\n",
      "    epoch          : 215\n",
      "    loss           : -486.54414222489766\n",
      "    val_loss       : -192.41565349213639\n",
      "    val_log_likelihood: 763.9977729244013\n",
      "    val_log_marginal: 230.30131149872648\n",
      "Train Epoch: 216 [512/17352 (3%)] Loss: -159.182190\n",
      "Train Epoch: 216 [10384/17352 (60%)] Loss: -503.224773\n",
      "Train Epoch: 216 [17064/17352 (98%)] Loss: -207.356515\n",
      "    epoch          : 216\n",
      "    loss           : -344.84138522637375\n",
      "    val_loss       : -324.12977937523783\n",
      "    val_log_likelihood: 749.7908058893496\n",
      "    val_log_marginal: 370.48608267538305\n",
      "Train Epoch: 217 [512/17352 (3%)] Loss: -363.748077\n",
      "Train Epoch: 217 [10585/17352 (61%)] Loss: -314.056653\n",
      "Train Epoch: 217 [16934/17352 (98%)] Loss: -491.270492\n",
      "    epoch          : 217\n",
      "    loss           : -494.6672721450427\n",
      "    val_loss       : -456.23757369046524\n",
      "    val_log_likelihood: 778.065922032659\n",
      "    val_log_marginal: 484.1952245224796\n",
      "Train Epoch: 218 [512/17352 (3%)] Loss: -563.905273\n",
      "Train Epoch: 218 [10658/17352 (61%)] Loss: -643.675469\n",
      "Train Epoch: 218 [17335/17352 (100%)] Loss: -597.596925\n",
      "    epoch          : 218\n",
      "    loss           : -524.3575226958307\n",
      "    val_loss       : -430.43077697386695\n",
      "    val_log_likelihood: 778.2756738769755\n",
      "    val_log_marginal: 463.8902539875325\n",
      "Train Epoch: 219 [512/17352 (3%)] Loss: -567.064331\n",
      "Train Epoch: 219 [10355/17352 (60%)] Loss: -629.591781\n",
      "Train Epoch: 219 [16957/17352 (98%)] Loss: -604.965017\n",
      "    epoch          : 219\n",
      "    loss           : -545.8105860016891\n",
      "    val_loss       : -479.4692624607796\n",
      "    val_log_likelihood: 787.880241198363\n",
      "    val_log_marginal: 504.7941668501048\n",
      "Train Epoch: 220 [512/17352 (3%)] Loss: -423.920593\n",
      "Train Epoch: 220 [10353/17352 (60%)] Loss: -524.925239\n",
      "Train Epoch: 220 [16958/17352 (98%)] Loss: -388.744954\n",
      "    epoch          : 220\n",
      "    loss           : -563.2903528040171\n",
      "    val_loss       : -492.35266524372787\n",
      "    val_log_likelihood: 806.8328629299118\n",
      "    val_log_marginal: 516.5744808797109\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0506_152815/checkpoint-epoch220.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 221 [512/17352 (3%)] Loss: -587.276123\n",
      "Train Epoch: 221 [10454/17352 (60%)] Loss: -549.553228\n",
      "Train Epoch: 221 [17277/17352 (100%)] Loss: -622.671688\n",
      "    epoch          : 221\n",
      "    loss           : -566.6729042579288\n",
      "    val_loss       : -454.4672732389264\n",
      "    val_log_likelihood: 791.650614337339\n",
      "    val_log_marginal: 485.16855963056287\n",
      "Train Epoch: 222 [512/17352 (3%)] Loss: -584.821716\n",
      "Train Epoch: 222 [10246/17352 (59%)] Loss: -575.264717\n",
      "Train Epoch: 222 [17106/17352 (99%)] Loss: -490.999454\n",
      "    epoch          : 222\n",
      "    loss           : -569.0154091128351\n",
      "    val_loss       : -497.93636090219593\n",
      "    val_log_likelihood: 811.4290387423605\n",
      "    val_log_marginal: 523.8672555029523\n",
      "Train Epoch: 223 [512/17352 (3%)] Loss: -616.694275\n",
      "Train Epoch: 223 [9996/17352 (58%)] Loss: -504.722912\n",
      "Train Epoch: 223 [17044/17352 (98%)] Loss: -499.859968\n",
      "    epoch          : 223\n",
      "    loss           : -550.6217309569587\n",
      "    val_loss       : -475.43247269624027\n",
      "    val_log_likelihood: 799.6938403053081\n",
      "    val_log_marginal: 507.84805811136596\n",
      "Train Epoch: 224 [512/17352 (3%)] Loss: -596.466187\n",
      "Train Epoch: 224 [10772/17352 (62%)] Loss: -687.639323\n",
      "Train Epoch: 224 [17153/17352 (99%)] Loss: -577.356402\n",
      "    epoch          : 224\n",
      "    loss           : -553.5552549009349\n",
      "    val_loss       : -476.47898553084934\n",
      "    val_log_likelihood: 803.2697292554058\n",
      "    val_log_marginal: 497.89077858102047\n",
      "Train Epoch: 225 [512/17352 (3%)] Loss: -603.543579\n",
      "Train Epoch: 225 [10393/17352 (60%)] Loss: -642.020732\n",
      "Train Epoch: 225 [16958/17352 (98%)] Loss: -548.454473\n",
      "    epoch          : 225\n",
      "    loss           : -526.9895938318778\n",
      "    val_loss       : -418.8454282240611\n",
      "    val_log_likelihood: 726.3619259946917\n",
      "    val_log_marginal: 435.7445844771141\n",
      "Train Epoch: 226 [512/17352 (3%)] Loss: -533.530090\n",
      "Train Epoch: 226 [10062/17352 (58%)] Loss: -510.955783\n",
      "Train Epoch: 226 [17126/17352 (99%)] Loss: -420.173077\n",
      "    epoch          : 226\n",
      "    loss           : -510.06552766410545\n",
      "    val_loss       : -429.45439007470287\n",
      "    val_log_likelihood: 795.494151747153\n",
      "    val_log_marginal: 477.1508646846496\n",
      "Train Epoch: 227 [512/17352 (3%)] Loss: -547.994263\n",
      "Train Epoch: 227 [9957/17352 (57%)] Loss: -597.920749\n",
      "Train Epoch: 227 [16934/17352 (98%)] Loss: -499.976702\n",
      "    epoch          : 227\n",
      "    loss           : -535.9566954103215\n",
      "    val_loss       : -471.0736880340677\n",
      "    val_log_likelihood: 805.7239004168617\n",
      "    val_log_marginal: 513.6694971277718\n",
      "Train Epoch: 228 [512/17352 (3%)] Loss: -623.137207\n",
      "Train Epoch: 228 [9632/17352 (56%)] Loss: -580.658646\n",
      "Train Epoch: 228 [16957/17352 (98%)] Loss: -472.090452\n",
      "    epoch          : 228\n",
      "    loss           : -495.0574129350979\n",
      "    val_loss       : -415.9620014167443\n",
      "    val_log_likelihood: 756.9844825914665\n",
      "    val_log_marginal: 446.8236758290938\n",
      "Train Epoch: 229 [512/17352 (3%)] Loss: -494.282349\n",
      "Train Epoch: 229 [10441/17352 (60%)] Loss: -525.048281\n",
      "Train Epoch: 229 [17101/17352 (99%)] Loss: -453.174212\n",
      "    epoch          : 229\n",
      "    loss           : -437.0404151287756\n",
      "    val_loss       : -215.73136206397442\n",
      "    val_log_likelihood: 777.0020498988434\n",
      "    val_log_marginal: 263.46624581869315\n",
      "Train Epoch: 230 [512/17352 (3%)] Loss: -375.413696\n",
      "Train Epoch: 230 [10330/17352 (60%)] Loss: -396.929624\n",
      "Train Epoch: 230 [17133/17352 (99%)] Loss: -517.886127\n",
      "    epoch          : 230\n",
      "    loss           : -400.65139582938656\n",
      "    val_loss       : -360.962351557719\n",
      "    val_log_likelihood: 776.8314723163214\n",
      "    val_log_marginal: 419.8175572504251\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0506_152815/checkpoint-epoch230.pth ...\n",
      "Train Epoch: 231 [512/17352 (3%)] Loss: -524.597900\n",
      "Train Epoch: 231 [11012/17352 (63%)] Loss: -622.689478\n",
      "Train Epoch: 231 [17277/17352 (100%)] Loss: -627.116968\n",
      "    epoch          : 231\n",
      "    loss           : -505.53733406566266\n",
      "    val_loss       : -419.85694966293386\n",
      "    val_log_likelihood: 771.9498348065521\n",
      "    val_log_marginal: 447.7465386303784\n",
      "Train Epoch: 232 [512/17352 (3%)] Loss: -539.230103\n",
      "Train Epoch: 232 [10073/17352 (58%)] Loss: -442.319044\n",
      "Train Epoch: 232 [17253/17352 (99%)] Loss: -487.860677\n",
      "    epoch          : 232\n",
      "    loss           : -547.3824332569435\n",
      "    val_loss       : -487.65844761043735\n",
      "    val_log_likelihood: 814.5497827205709\n",
      "    val_log_marginal: 516.6631884554264\n",
      "Train Epoch: 233 [512/17352 (3%)] Loss: -612.878662\n",
      "Train Epoch: 233 [10884/17352 (63%)] Loss: -678.075532\n",
      "Train Epoch: 233 [16934/17352 (98%)] Loss: -666.040000\n",
      "    epoch          : 233\n",
      "    loss           : -581.3103895092098\n",
      "    val_loss       : -509.94462329120154\n",
      "    val_log_likelihood: 822.4607335019439\n",
      "    val_log_marginal: 531.1850065926341\n",
      "Train Epoch: 234 [512/17352 (3%)] Loss: -556.643311\n",
      "Train Epoch: 234 [10350/17352 (60%)] Loss: -614.902167\n",
      "Train Epoch: 234 [17126/17352 (99%)] Loss: -556.686860\n",
      "    epoch          : 234\n",
      "    loss           : -576.1100632740659\n",
      "    val_loss       : -493.00132405635236\n",
      "    val_log_likelihood: 827.873202522613\n",
      "    val_log_marginal: 530.5907645330898\n",
      "Train Epoch: 235 [512/17352 (3%)] Loss: -606.462280\n",
      "Train Epoch: 235 [9620/17352 (55%)] Loss: -650.037093\n",
      "Train Epoch: 235 [17090/17352 (98%)] Loss: -384.792177\n",
      "    epoch          : 235\n",
      "    loss           : -573.4085488868585\n",
      "    val_loss       : -456.66186319128667\n",
      "    val_log_likelihood: 832.039965841756\n",
      "    val_log_marginal: 486.764801526734\n",
      "Train Epoch: 236 [512/17352 (3%)] Loss: -579.334290\n",
      "Train Epoch: 236 [10607/17352 (61%)] Loss: -316.693649\n",
      "Train Epoch: 236 [17133/17352 (99%)] Loss: 1266.036229\n",
      "    epoch          : 236\n",
      "    loss           : -355.1984276510055\n",
      "    val_loss       : -97.19231135606778\n",
      "    val_log_likelihood: 747.1097507570659\n",
      "    val_log_marginal: 124.45310840891663\n",
      "Train Epoch: 237 [512/17352 (3%)] Loss: -216.450287\n",
      "Train Epoch: 237 [10445/17352 (60%)] Loss: -488.821561\n",
      "Train Epoch: 237 [16939/17352 (98%)] Loss: -610.185467\n",
      "    epoch          : 237\n",
      "    loss           : -382.8285131622543\n",
      "    val_loss       : -443.9818065517148\n",
      "    val_log_likelihood: 785.7375905527988\n",
      "    val_log_marginal: 478.19991343154913\n",
      "Train Epoch: 238 [512/17352 (3%)] Loss: -562.520874\n",
      "Train Epoch: 238 [10325/17352 (60%)] Loss: -496.974545\n",
      "Train Epoch: 238 [16992/17352 (98%)] Loss: -514.762423\n",
      "    epoch          : 238\n",
      "    loss           : -533.4496157328585\n",
      "    val_loss       : -479.8794496091028\n",
      "    val_log_likelihood: 801.9753173538851\n",
      "    val_log_marginal: 507.4367382791393\n",
      "Train Epoch: 239 [512/17352 (3%)] Loss: -624.490479\n",
      "Train Epoch: 239 [9697/17352 (56%)] Loss: -616.678229\n",
      "Train Epoch: 239 [17049/17352 (98%)] Loss: -434.506654\n",
      "    epoch          : 239\n",
      "    loss           : -570.7769965292217\n",
      "    val_loss       : -510.1216903532306\n",
      "    val_log_likelihood: 816.8566538097999\n",
      "    val_log_marginal: 530.0138482089077\n",
      "Train Epoch: 240 [512/17352 (3%)] Loss: -618.456299\n",
      "Train Epoch: 240 [10009/17352 (58%)] Loss: -593.106027\n",
      "Train Epoch: 240 [16957/17352 (98%)] Loss: -521.599717\n",
      "    epoch          : 240\n",
      "    loss           : -590.211820472178\n",
      "    val_loss       : -516.5506333585861\n",
      "    val_log_likelihood: 838.5833350626245\n",
      "    val_log_marginal: 542.285318690725\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0506_152815/checkpoint-epoch240.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 241 [512/17352 (3%)] Loss: -647.667114\n",
      "Train Epoch: 241 [9869/17352 (57%)] Loss: -679.331157\n",
      "Train Epoch: 241 [17090/17352 (98%)] Loss: -681.791223\n",
      "    epoch          : 241\n",
      "    loss           : -592.4243767236818\n",
      "    val_loss       : -519.128425609333\n",
      "    val_log_likelihood: 839.9138908181192\n",
      "    val_log_marginal: 544.8355542683358\n",
      "Train Epoch: 242 [512/17352 (3%)] Loss: -647.000183\n",
      "Train Epoch: 242 [10960/17352 (63%)] Loss: -654.095712\n",
      "Train Epoch: 242 [17133/17352 (99%)] Loss: -557.979553\n",
      "    epoch          : 242\n",
      "    loss           : -604.473796186741\n",
      "    val_loss       : -529.2285559990135\n",
      "    val_log_likelihood: 845.556804255832\n",
      "    val_log_marginal: 552.953515683136\n",
      "Train Epoch: 243 [512/17352 (3%)] Loss: -655.604431\n",
      "Train Epoch: 243 [10249/17352 (59%)] Loss: -495.339286\n",
      "Train Epoch: 243 [16992/17352 (98%)] Loss: -702.725680\n",
      "    epoch          : 243\n",
      "    loss           : -607.7067580982042\n",
      "    val_loss       : -527.374643301773\n",
      "    val_log_likelihood: 845.481528479221\n",
      "    val_log_marginal: 549.8714166245514\n",
      "Train Epoch: 244 [512/17352 (3%)] Loss: -661.164917\n",
      "Train Epoch: 244 [10338/17352 (60%)] Loss: -655.849475\n",
      "Train Epoch: 244 [17101/17352 (99%)] Loss: -469.532857\n",
      "    epoch          : 244\n",
      "    loss           : -603.2160253717578\n",
      "    val_loss       : -515.3201502033227\n",
      "    val_log_likelihood: 844.4123169622701\n",
      "    val_log_marginal: 538.2284117768138\n",
      "Train Epoch: 245 [512/17352 (3%)] Loss: -643.934448\n",
      "Train Epoch: 245 [10744/17352 (62%)] Loss: -550.758854\n",
      "Train Epoch: 245 [17335/17352 (100%)] Loss: -653.429360\n",
      "    epoch          : 245\n",
      "    loss           : -598.5864335592684\n",
      "    val_loss       : -520.5572292374993\n",
      "    val_log_likelihood: 848.6020904081646\n",
      "    val_log_marginal: 545.3230514961692\n",
      "Train Epoch: 246 [512/17352 (3%)] Loss: -663.016846\n",
      "Train Epoch: 246 [10540/17352 (61%)] Loss: -659.409114\n",
      "Train Epoch: 246 [16883/17352 (97%)] Loss: -567.650596\n",
      "    epoch          : 246\n",
      "    loss           : -613.3129251549236\n",
      "    val_loss       : -532.1783950269962\n",
      "    val_log_likelihood: 852.3349072300629\n",
      "    val_log_marginal: 551.2822597449696\n",
      "Train Epoch: 247 [512/17352 (3%)] Loss: -663.755798\n",
      "Train Epoch: 247 [10537/17352 (61%)] Loss: -724.656304\n",
      "Train Epoch: 247 [17049/17352 (98%)] Loss: -651.273378\n",
      "    epoch          : 247\n",
      "    loss           : -612.3998872229984\n",
      "    val_loss       : -537.7885133536661\n",
      "    val_log_likelihood: 857.7438684849824\n",
      "    val_log_marginal: 555.8030653663682\n",
      "Train Epoch: 248 [512/17352 (3%)] Loss: -666.459351\n",
      "Train Epoch: 248 [10440/17352 (60%)] Loss: -619.900798\n",
      "Train Epoch: 248 [17106/17352 (99%)] Loss: -737.654460\n",
      "    epoch          : 248\n",
      "    loss           : -620.6698181172534\n",
      "    val_loss       : -534.7326121732165\n",
      "    val_log_likelihood: 865.814539767143\n",
      "    val_log_marginal: 560.9170329036713\n",
      "Train Epoch: 249 [512/17352 (3%)] Loss: -663.205994\n",
      "Train Epoch: 249 [10397/17352 (60%)] Loss: -507.312281\n",
      "Train Epoch: 249 [16878/17352 (97%)] Loss: -718.144068\n",
      "    epoch          : 249\n",
      "    loss           : -617.5217551418341\n",
      "    val_loss       : -527.028380167661\n",
      "    val_log_likelihood: 862.8540232945575\n",
      "    val_log_marginal: 551.2202068498268\n",
      "Train Epoch: 250 [512/17352 (3%)] Loss: -671.405273\n",
      "Train Epoch: 250 [10278/17352 (59%)] Loss: -673.453675\n",
      "Train Epoch: 250 [16922/17352 (98%)] Loss: -753.894368\n",
      "    epoch          : 250\n",
      "    loss           : -623.4835107925638\n",
      "    val_loss       : -541.346593435014\n",
      "    val_log_likelihood: 868.1010227921599\n",
      "    val_log_marginal: 563.1175878450143\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0506_152815/checkpoint-epoch250.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 251 [512/17352 (3%)] Loss: -659.000000\n",
      "Train Epoch: 251 [10298/17352 (59%)] Loss: -696.772864\n",
      "Train Epoch: 251 [16882/17352 (97%)] Loss: -713.324494\n",
      "    epoch          : 251\n",
      "    loss           : -612.959211931051\n",
      "    val_loss       : -528.9691289574396\n",
      "    val_log_likelihood: 871.4731383973086\n",
      "    val_log_marginal: 555.9707253695209\n",
      "Train Epoch: 252 [512/17352 (3%)] Loss: -677.979187\n",
      "Train Epoch: 252 [10009/17352 (58%)] Loss: -551.186581\n",
      "Train Epoch: 252 [17108/17352 (99%)] Loss: -715.259146\n",
      "    epoch          : 252\n",
      "    loss           : -619.580143283817\n",
      "    val_loss       : -526.1947165702776\n",
      "    val_log_likelihood: 869.5899097714171\n",
      "    val_log_marginal: 554.5023081474643\n",
      "Train Epoch: 253 [512/17352 (3%)] Loss: -672.287720\n",
      "Train Epoch: 253 [10763/17352 (62%)] Loss: -521.561638\n",
      "Train Epoch: 253 [16883/17352 (97%)] Loss: -447.175517\n",
      "    epoch          : 253\n",
      "    loss           : -596.0552841415466\n",
      "    val_loss       : -508.01383354502593\n",
      "    val_log_likelihood: 849.3063064567044\n",
      "    val_log_marginal: 537.2986799505496\n",
      "Train Epoch: 254 [512/17352 (3%)] Loss: -652.024048\n",
      "Train Epoch: 254 [10249/17352 (59%)] Loss: -676.920417\n",
      "Train Epoch: 254 [17090/17352 (98%)] Loss: -631.071159\n",
      "    epoch          : 254\n",
      "    loss           : -594.259067570869\n",
      "    val_loss       : -518.0798962206452\n",
      "    val_log_likelihood: 863.5944206982898\n",
      "    val_log_marginal: 545.9403958357617\n",
      "Train Epoch: 255 [512/17352 (3%)] Loss: -652.610657\n",
      "Train Epoch: 255 [10343/17352 (60%)] Loss: -714.155996\n",
      "Train Epoch: 255 [16878/17352 (97%)] Loss: -517.093967\n",
      "    epoch          : 255\n",
      "    loss           : -613.1593923690208\n",
      "    val_loss       : -514.9097425894731\n",
      "    val_log_likelihood: 864.6008713407412\n",
      "    val_log_marginal: 544.0644997390644\n",
      "Train Epoch: 256 [512/17352 (3%)] Loss: -671.851624\n",
      "Train Epoch: 256 [10577/17352 (61%)] Loss: -563.723892\n",
      "Train Epoch: 256 [16934/17352 (98%)] Loss: -708.745612\n",
      "    epoch          : 256\n",
      "    loss           : -619.7284515155408\n",
      "    val_loss       : -540.6078753773279\n",
      "    val_log_likelihood: 876.7237329187952\n",
      "    val_log_marginal: 567.2299693185133\n",
      "Train Epoch: 257 [512/17352 (3%)] Loss: -640.937012\n",
      "Train Epoch: 257 [10169/17352 (59%)] Loss: -657.682682\n",
      "Train Epoch: 257 [16958/17352 (98%)] Loss: -542.555772\n",
      "    epoch          : 257\n",
      "    loss           : -628.3304968314413\n",
      "    val_loss       : -539.4272388760596\n",
      "    val_log_likelihood: 877.8762400302663\n",
      "    val_log_marginal: 563.7787548550431\n",
      "Train Epoch: 258 [512/17352 (3%)] Loss: -668.227905\n",
      "Train Epoch: 258 [10399/17352 (60%)] Loss: -696.257596\n",
      "Train Epoch: 258 [17090/17352 (98%)] Loss: -661.023687\n",
      "    epoch          : 258\n",
      "    loss           : -605.017648624231\n",
      "    val_loss       : -466.27258404881326\n",
      "    val_log_likelihood: 870.5420686453156\n",
      "    val_log_marginal: 488.5916483542816\n",
      "Train Epoch: 259 [512/17352 (3%)] Loss: -609.752563\n",
      "Train Epoch: 259 [10687/17352 (62%)] Loss: -706.267924\n",
      "Train Epoch: 259 [16957/17352 (98%)] Loss: -538.994280\n",
      "    epoch          : 259\n",
      "    loss           : -569.2925058413146\n",
      "    val_loss       : -418.0396385866925\n",
      "    val_log_likelihood: 858.3776057644455\n",
      "    val_log_marginal: 451.64574358037106\n",
      "Train Epoch: 260 [512/17352 (3%)] Loss: -568.997925\n",
      "Train Epoch: 260 [10919/17352 (63%)] Loss: -648.594282\n",
      "Train Epoch: 260 [17124/17352 (99%)] Loss: -669.011499\n",
      "    epoch          : 260\n",
      "    loss           : -540.601376453931\n",
      "    val_loss       : -483.668264714044\n",
      "    val_log_likelihood: 840.3282313852063\n",
      "    val_log_marginal: 507.837255660732\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0506_152815/checkpoint-epoch260.pth ...\n",
      "Train Epoch: 261 [512/17352 (3%)] Loss: -578.277466\n",
      "Train Epoch: 261 [10612/17352 (61%)] Loss: -695.461903\n",
      "Train Epoch: 261 [16878/17352 (97%)] Loss: -603.391809\n",
      "    epoch          : 261\n",
      "    loss           : -601.1339590560076\n",
      "    val_loss       : -528.5059343799729\n",
      "    val_log_likelihood: 866.4383970856551\n",
      "    val_log_marginal: 551.9753525684794\n",
      "Train Epoch: 262 [512/17352 (3%)] Loss: -671.158997\n",
      "Train Epoch: 262 [10202/17352 (59%)] Loss: -422.820638\n",
      "Train Epoch: 262 [17153/17352 (99%)] Loss: -675.241652\n",
      "    epoch          : 262\n",
      "    loss           : -594.25473826486\n",
      "    val_loss       : -493.55809089509154\n",
      "    val_log_likelihood: 869.7444304413305\n",
      "    val_log_marginal: 522.0458035210902\n",
      "Train Epoch: 263 [512/17352 (3%)] Loss: -627.907898\n",
      "Train Epoch: 263 [10179/17352 (59%)] Loss: -658.131599\n",
      "Train Epoch: 263 [17126/17352 (99%)] Loss: -694.673894\n",
      "    epoch          : 263\n",
      "    loss           : -609.3930781956515\n",
      "    val_loss       : -408.84776248561997\n",
      "    val_log_likelihood: 861.9826261364865\n",
      "    val_log_marginal: 439.3511672317437\n",
      "Train Epoch: 264 [512/17352 (3%)] Loss: -575.197388\n",
      "Train Epoch: 264 [10362/17352 (60%)] Loss: -583.936523\n",
      "Train Epoch: 264 [16988/17352 (98%)] Loss: -661.439343\n",
      "    epoch          : 264\n",
      "    loss           : -578.6455857978901\n",
      "    val_loss       : -467.7583431529763\n",
      "    val_log_likelihood: 862.4895783963517\n",
      "    val_log_marginal: 495.8073447620301\n",
      "Train Epoch: 265 [512/17352 (3%)] Loss: -429.388397\n",
      "Train Epoch: 265 [10312/17352 (59%)] Loss: -124.297866\n",
      "Train Epoch: 265 [16882/17352 (97%)] Loss: -451.596005\n",
      "    epoch          : 265\n",
      "    loss           : -393.3341671863494\n",
      "    val_loss       : -380.9352498411124\n",
      "    val_log_likelihood: 808.634375918816\n",
      "    val_log_marginal: 427.99791408291946\n",
      "Train Epoch: 266 [512/17352 (3%)] Loss: -544.046692\n",
      "Train Epoch: 266 [10663/17352 (61%)] Loss: -460.552920\n",
      "Train Epoch: 266 [17277/17352 (100%)] Loss: -650.582051\n",
      "    epoch          : 266\n",
      "    loss           : -555.6673732558152\n",
      "    val_loss       : -486.4997119729746\n",
      "    val_log_likelihood: 845.2154055190027\n",
      "    val_log_marginal: 517.3428323347944\n",
      "Train Epoch: 267 [512/17352 (3%)] Loss: -634.226685\n",
      "Train Epoch: 267 [10243/17352 (59%)] Loss: -539.271347\n",
      "Train Epoch: 267 [17133/17352 (99%)] Loss: -498.056666\n",
      "    epoch          : 267\n",
      "    loss           : -614.3555736832232\n",
      "    val_loss       : -517.0546536129605\n",
      "    val_log_likelihood: 870.1880597030097\n",
      "    val_log_marginal: 559.9235599287146\n",
      "Train Epoch: 268 [512/17352 (3%)] Loss: -673.028442\n",
      "Train Epoch: 268 [10176/17352 (59%)] Loss: -591.659745\n",
      "Train Epoch: 268 [16934/17352 (98%)] Loss: -609.172679\n",
      "    epoch          : 268\n",
      "    loss           : -627.1665341863194\n",
      "    val_loss       : -538.1855898324354\n",
      "    val_log_likelihood: 877.6548301972649\n",
      "    val_log_marginal: 566.4669185861381\n",
      "Train Epoch: 269 [512/17352 (3%)] Loss: -685.206604\n",
      "Train Epoch: 269 [9294/17352 (54%)] Loss: -630.257238\n",
      "Train Epoch: 269 [16922/17352 (98%)] Loss: -563.557943\n",
      "    epoch          : 269\n",
      "    loss           : -641.6219647429873\n",
      "    val_loss       : -539.5754296616678\n",
      "    val_log_likelihood: 879.2804145290087\n",
      "    val_log_marginal: 568.3787797420179\n",
      "Train Epoch: 270 [512/17352 (3%)] Loss: -684.415283\n",
      "Train Epoch: 270 [10868/17352 (63%)] Loss: -734.112340\n",
      "Train Epoch: 270 [16992/17352 (98%)] Loss: -663.313920\n",
      "    epoch          : 270\n",
      "    loss           : -639.2457990560191\n",
      "    val_loss       : -530.7497584807304\n",
      "    val_log_likelihood: 880.6969021334146\n",
      "    val_log_marginal: 555.2682289205644\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0506_152815/checkpoint-epoch270.pth ...\n",
      "Train Epoch: 271 [512/17352 (3%)] Loss: -684.228333\n",
      "Train Epoch: 271 [10589/17352 (61%)] Loss: -673.372432\n",
      "Train Epoch: 271 [16958/17352 (98%)] Loss: -626.716891\n",
      "    epoch          : 271\n",
      "    loss           : -630.8870446490961\n",
      "    val_loss       : -537.3653301711914\n",
      "    val_log_likelihood: 881.766855392878\n",
      "    val_log_marginal: 563.687322261434\n",
      "Train Epoch: 272 [512/17352 (3%)] Loss: -655.631287\n",
      "Train Epoch: 272 [10288/17352 (59%)] Loss: -526.850488\n",
      "Train Epoch: 272 [17016/17352 (98%)] Loss: -634.354809\n",
      "    epoch          : 272\n",
      "    loss           : -627.1767670670014\n",
      "    val_loss       : -528.780099444724\n",
      "    val_log_likelihood: 891.907154875762\n",
      "    val_log_marginal: 561.716608719801\n",
      "Train Epoch: 273 [512/17352 (3%)] Loss: -584.533752\n",
      "Train Epoch: 273 [10739/17352 (62%)] Loss: -552.682757\n",
      "Train Epoch: 273 [16939/17352 (98%)] Loss: -490.346696\n",
      "    epoch          : 273\n",
      "    loss           : -602.8222809926635\n",
      "    val_loss       : -509.7623709200821\n",
      "    val_log_likelihood: 864.3701588600048\n",
      "    val_log_marginal: 542.349150122144\n",
      "Train Epoch: 274 [512/17352 (3%)] Loss: -643.398865\n",
      "Train Epoch: 274 [10510/17352 (61%)] Loss: -623.258329\n",
      "Train Epoch: 274 [16923/17352 (98%)] Loss: -568.802994\n",
      "    epoch          : 274\n",
      "    loss           : -510.64908507860997\n",
      "    val_loss       : -325.53197213211683\n",
      "    val_log_likelihood: 846.1105885266527\n",
      "    val_log_marginal: 501.8713181561364\n",
      "Train Epoch: 275 [512/17352 (3%)] Loss: -334.853516\n",
      "Train Epoch: 275 [10421/17352 (60%)] Loss: -425.359193\n",
      "Train Epoch: 275 [16878/17352 (97%)] Loss: -667.247777\n",
      "    epoch          : 275\n",
      "    loss           : -531.4639344384444\n",
      "    val_loss       : -498.65659641717446\n",
      "    val_log_likelihood: 859.1787515372938\n",
      "    val_log_marginal: 532.8120599105923\n",
      "Train Epoch: 276 [512/17352 (3%)] Loss: -625.208008\n",
      "Train Epoch: 276 [9836/17352 (57%)] Loss: -652.787011\n",
      "Train Epoch: 276 [17126/17352 (99%)] Loss: -639.698489\n",
      "    epoch          : 276\n",
      "    loss           : -614.996284764781\n",
      "    val_loss       : -535.8081619641978\n",
      "    val_log_likelihood: 885.9641381452282\n",
      "    val_log_marginal: 568.8954297720039\n",
      "Train Epoch: 277 [512/17352 (3%)] Loss: -667.792786\n",
      "Train Epoch: 277 [10587/17352 (61%)] Loss: -715.384597\n",
      "Train Epoch: 277 [17263/17352 (99%)] Loss: -657.568546\n",
      "    epoch          : 277\n",
      "    loss           : -636.1065304475187\n",
      "    val_loss       : -506.815618584022\n",
      "    val_log_likelihood: 872.2550479209359\n",
      "    val_log_marginal: 533.8567220827489\n",
      "Train Epoch: 278 [512/17352 (3%)] Loss: -645.396729\n",
      "Train Epoch: 278 [10205/17352 (59%)] Loss: -535.477654\n",
      "Train Epoch: 278 [16992/17352 (98%)] Loss: -692.618721\n",
      "    epoch          : 278\n",
      "    loss           : -634.8309823797964\n",
      "    val_loss       : -541.5695665016983\n",
      "    val_log_likelihood: 893.9291699530098\n",
      "    val_log_marginal: 571.8605058734196\n",
      "Train Epoch: 279 [512/17352 (3%)] Loss: -681.581848\n",
      "Train Epoch: 279 [10248/17352 (59%)] Loss: -663.227254\n",
      "Train Epoch: 279 [17049/17352 (98%)] Loss: -711.158890\n",
      "    epoch          : 279\n",
      "    loss           : -650.56272615819\n",
      "    val_loss       : -539.764356741788\n",
      "    val_log_likelihood: 902.5702670322946\n",
      "    val_log_marginal: 566.8207527045922\n",
      "Train Epoch: 280 [512/17352 (3%)] Loss: -677.627136\n",
      "Train Epoch: 280 [10075/17352 (58%)] Loss: -603.272067\n",
      "Train Epoch: 280 [17126/17352 (99%)] Loss: -647.007812\n",
      "    epoch          : 280\n",
      "    loss           : -641.0133165639138\n",
      "    val_loss       : -507.8169096871229\n",
      "    val_log_likelihood: 902.4999174261792\n",
      "    val_log_marginal: 534.6950305045139\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0506_152815/checkpoint-epoch280.pth ...\n",
      "Train Epoch: 281 [512/17352 (3%)] Loss: -651.812378\n",
      "Train Epoch: 281 [10449/17352 (60%)] Loss: -772.347765\n",
      "Train Epoch: 281 [16939/17352 (98%)] Loss: -731.364901\n",
      "    epoch          : 281\n",
      "    loss           : -605.0291664993831\n",
      "    val_loss       : -503.9355764166957\n",
      "    val_log_likelihood: 897.4724561115094\n",
      "    val_log_marginal: 550.6040547399218\n",
      "Train Epoch: 282 [512/17352 (3%)] Loss: -627.279602\n",
      "Train Epoch: 282 [10846/17352 (63%)] Loss: -668.711529\n",
      "Train Epoch: 282 [16939/17352 (98%)] Loss: -452.610577\n",
      "    epoch          : 282\n",
      "    loss           : -578.1300581532925\n",
      "    val_loss       : -486.42344170826095\n",
      "    val_log_likelihood: 891.502517636307\n",
      "    val_log_marginal: 530.4847916166507\n",
      "Train Epoch: 283 [512/17352 (3%)] Loss: -653.567505\n",
      "Train Epoch: 283 [10629/17352 (61%)] Loss: -549.955053\n",
      "Train Epoch: 283 [16958/17352 (98%)] Loss: -702.212448\n",
      "    epoch          : 283\n",
      "    loss           : -594.318336799387\n",
      "    val_loss       : -541.7497142226495\n",
      "    val_log_likelihood: 896.2928829083739\n",
      "    val_log_marginal: 569.5353062484947\n",
      "Train Epoch: 284 [512/17352 (3%)] Loss: -486.434814\n",
      "Train Epoch: 284 [10382/17352 (60%)] Loss: -639.489741\n",
      "Train Epoch: 284 [17090/17352 (98%)] Loss: -560.868222\n",
      "    epoch          : 284\n",
      "    loss           : -636.6351629318406\n",
      "    val_loss       : -509.4773121022472\n",
      "    val_log_likelihood: 868.1004390141152\n",
      "    val_log_marginal: 541.2935299802446\n",
      "Train Epoch: 285 [512/17352 (3%)] Loss: -620.362488\n",
      "Train Epoch: 285 [10523/17352 (61%)] Loss: -712.799490\n",
      "Train Epoch: 285 [17106/17352 (99%)] Loss: -510.808081\n",
      "    epoch          : 285\n",
      "    loss           : -597.7653167673274\n",
      "    val_loss       : -441.2077068625555\n",
      "    val_log_likelihood: 860.7499255225526\n",
      "    val_log_marginal: 477.02546124353586\n",
      "Train Epoch: 286 [512/17352 (3%)] Loss: -578.713135\n",
      "Train Epoch: 286 [10005/17352 (58%)] Loss: -430.065565\n",
      "Train Epoch: 286 [16882/17352 (97%)] Loss: -638.713477\n",
      "    epoch          : 286\n",
      "    loss           : -595.2863025263495\n",
      "    val_loss       : -509.09297206648654\n",
      "    val_log_likelihood: 893.1240417484549\n",
      "    val_log_marginal: 546.6032170697862\n",
      "Train Epoch: 287 [512/17352 (3%)] Loss: -666.517944\n",
      "Train Epoch: 287 [10365/17352 (60%)] Loss: -686.974687\n",
      "Train Epoch: 287 [16923/17352 (98%)] Loss: -718.661104\n",
      "    epoch          : 287\n",
      "    loss           : -654.0377723049926\n",
      "    val_loss       : -526.4617653367769\n",
      "    val_log_likelihood: 907.2553448642149\n",
      "    val_log_marginal: 552.1135551285905\n",
      "Train Epoch: 288 [512/17352 (3%)] Loss: -686.500427\n",
      "Train Epoch: 288 [10838/17352 (62%)] Loss: -659.579198\n",
      "Train Epoch: 288 [17263/17352 (99%)] Loss: -641.240005\n",
      "    epoch          : 288\n",
      "    loss           : -659.371673545577\n",
      "    val_loss       : -517.3888831836274\n",
      "    val_log_likelihood: 890.0850479146694\n",
      "    val_log_marginal: 550.5832750843817\n",
      "Train Epoch: 289 [512/17352 (3%)] Loss: -684.679871\n",
      "Train Epoch: 289 [10226/17352 (59%)] Loss: -686.172082\n",
      "Train Epoch: 289 [16934/17352 (98%)] Loss: -761.287757\n",
      "    epoch          : 289\n",
      "    loss           : -659.5474608442445\n",
      "    val_loss       : -563.9920541797677\n",
      "    val_log_likelihood: 917.4631805087807\n",
      "    val_log_marginal: 597.6967054751508\n",
      "Train Epoch: 290 [512/17352 (3%)] Loss: -679.692566\n",
      "Train Epoch: 290 [9682/17352 (56%)] Loss: -702.257743\n",
      "Train Epoch: 290 [17090/17352 (98%)] Loss: -686.813932\n",
      "    epoch          : 290\n",
      "    loss           : -662.0151965247059\n",
      "    val_loss       : -551.2970358403725\n",
      "    val_log_likelihood: 920.6511538349657\n",
      "    val_log_marginal: 579.8335273133354\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0506_152815/checkpoint-epoch290.pth ...\n",
      "Train Epoch: 291 [512/17352 (3%)] Loss: -706.368225\n",
      "Train Epoch: 291 [10458/17352 (60%)] Loss: -610.817448\n",
      "Train Epoch: 291 [17124/17352 (99%)] Loss: -605.409019\n",
      "    epoch          : 291\n",
      "    loss           : -670.3187988945734\n",
      "    val_loss       : -552.0245688620989\n",
      "    val_log_likelihood: 926.8582992601191\n",
      "    val_log_marginal: 580.4102414362208\n",
      "Train Epoch: 292 [512/17352 (3%)] Loss: -713.101440\n",
      "Train Epoch: 292 [10123/17352 (58%)] Loss: -527.936469\n",
      "Train Epoch: 292 [16883/17352 (97%)] Loss: -730.008386\n",
      "    epoch          : 292\n",
      "    loss           : -662.3429868754497\n",
      "    val_loss       : -519.3869768930906\n",
      "    val_log_likelihood: 920.6842213731331\n",
      "    val_log_marginal: 543.4674467370311\n",
      "Train Epoch: 293 [512/17352 (3%)] Loss: -647.982056\n",
      "Train Epoch: 293 [10673/17352 (62%)] Loss: -541.166524\n",
      "Train Epoch: 293 [16922/17352 (98%)] Loss: -678.348576\n",
      "    epoch          : 293\n",
      "    loss           : -596.2291328506262\n",
      "    val_loss       : -493.9983051640449\n",
      "    val_log_likelihood: 910.9546220236855\n",
      "    val_log_marginal: 518.9102830624932\n",
      "Train Epoch: 294 [512/17352 (3%)] Loss: -647.593506\n",
      "Train Epoch: 294 [10691/17352 (62%)] Loss: -726.402364\n",
      "Train Epoch: 294 [16922/17352 (98%)] Loss: -750.663211\n",
      "    epoch          : 294\n",
      "    loss           : -629.7560241394027\n",
      "    val_loss       : -519.9176551922144\n",
      "    val_log_likelihood: 922.1373544416683\n",
      "    val_log_marginal: 554.0609421454718\n",
      "Train Epoch: 295 [512/17352 (3%)] Loss: -690.283020\n",
      "Train Epoch: 295 [10184/17352 (59%)] Loss: -690.769844\n",
      "Train Epoch: 295 [17263/17352 (99%)] Loss: -721.398692\n",
      "    epoch          : 295\n",
      "    loss           : -642.2952559544502\n",
      "    val_loss       : -539.0823148607641\n",
      "    val_log_likelihood: 916.7793974155663\n",
      "    val_log_marginal: 569.741321688761\n",
      "Train Epoch: 296 [512/17352 (3%)] Loss: -508.142059\n",
      "Train Epoch: 296 [10372/17352 (60%)] Loss: -728.970057\n",
      "Train Epoch: 296 [16992/17352 (98%)] Loss: -639.807812\n",
      "    epoch          : 296\n",
      "    loss           : -650.9045971261188\n",
      "    val_loss       : -482.7477515038438\n",
      "    val_log_likelihood: 919.3164242929879\n",
      "    val_log_marginal: 515.6409426054659\n",
      "Train Epoch: 297 [512/17352 (3%)] Loss: -651.867798\n",
      "Train Epoch: 297 [10614/17352 (61%)] Loss: -570.069818\n",
      "Train Epoch: 297 [16958/17352 (98%)] Loss: -756.065321\n",
      "    epoch          : 297\n",
      "    loss           : -614.89920806768\n",
      "    val_loss       : -494.90671135420024\n",
      "    val_log_likelihood: 916.4329519167026\n",
      "    val_log_marginal: 520.111461144032\n",
      "Train Epoch: 298 [512/17352 (3%)] Loss: -649.279785\n",
      "Train Epoch: 298 [10428/17352 (60%)] Loss: -668.900870\n",
      "Train Epoch: 298 [17277/17352 (100%)] Loss: -671.153391\n",
      "    epoch          : 298\n",
      "    loss           : -583.9907779814927\n",
      "    val_loss       : -477.3130152764303\n",
      "    val_log_likelihood: 888.30654335086\n",
      "    val_log_marginal: 518.90574310069\n",
      "Train Epoch: 299 [512/17352 (3%)] Loss: -550.711487\n",
      "Train Epoch: 299 [9810/17352 (57%)] Loss: -751.245173\n",
      "Train Epoch: 299 [16883/17352 (97%)] Loss: -559.004317\n",
      "    epoch          : 299\n",
      "    loss           : -619.0508636793858\n",
      "    val_loss       : -504.61281747004546\n",
      "    val_log_likelihood: 869.8907717514888\n",
      "    val_log_marginal: 525.4705667573028\n",
      "Train Epoch: 300 [512/17352 (3%)] Loss: -680.668579\n",
      "Train Epoch: 300 [10448/17352 (60%)] Loss: -532.925781\n",
      "Train Epoch: 300 [16988/17352 (98%)] Loss: -556.496347\n",
      "    epoch          : 300\n",
      "    loss           : -638.1422193503045\n",
      "    val_loss       : -537.6027230596535\n",
      "    val_log_likelihood: 921.4508285207496\n",
      "    val_log_marginal: 574.8637089317449\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0506_152815/checkpoint-epoch300.pth ...\n",
      "Train Epoch: 301 [512/17352 (3%)] Loss: -716.834778\n",
      "Train Epoch: 301 [10860/17352 (63%)] Loss: -752.223537\n",
      "Train Epoch: 301 [16872/17352 (97%)] Loss: -621.185489\n",
      "    epoch          : 301\n",
      "    loss           : -653.4345461813608\n",
      "    val_loss       : -551.1863163840414\n",
      "    val_log_likelihood: 915.0498255760559\n",
      "    val_log_marginal: 574.4650139814634\n",
      "Train Epoch: 302 [512/17352 (3%)] Loss: -713.517212\n",
      "Train Epoch: 302 [10094/17352 (58%)] Loss: -627.597771\n",
      "Train Epoch: 302 [17124/17352 (99%)] Loss: -727.598692\n",
      "    epoch          : 302\n",
      "    loss           : -673.6991252252094\n",
      "    val_loss       : -549.5300568241912\n",
      "    val_log_likelihood: 921.611447340506\n",
      "    val_log_marginal: 570.9105392607282\n",
      "Train Epoch: 303 [512/17352 (3%)] Loss: -714.052917\n",
      "Train Epoch: 303 [10644/17352 (61%)] Loss: -748.027052\n",
      "Train Epoch: 303 [17126/17352 (99%)] Loss: -614.390968\n",
      "    epoch          : 303\n",
      "    loss           : -629.9942804735039\n",
      "    val_loss       : -494.48197647463115\n",
      "    val_log_likelihood: 876.8137969268968\n",
      "    val_log_marginal: 535.6935045482871\n",
      "Train Epoch: 304 [512/17352 (3%)] Loss: -653.109619\n",
      "Train Epoch: 304 [10773/17352 (62%)] Loss: -423.882962\n",
      "Train Epoch: 304 [16887/17352 (97%)] Loss: -604.075051\n",
      "    epoch          : 304\n",
      "    loss           : -645.6282357545821\n",
      "    val_loss       : -545.5631206839325\n",
      "    val_log_likelihood: 923.3978016542991\n",
      "    val_log_marginal: 572.1096958453708\n",
      "Train Epoch: 305 [512/17352 (3%)] Loss: -717.317261\n",
      "Train Epoch: 305 [10652/17352 (61%)] Loss: -519.108702\n",
      "Train Epoch: 305 [16957/17352 (98%)] Loss: -685.473333\n",
      "    epoch          : 305\n",
      "    loss           : -663.4636531060827\n",
      "    val_loss       : -560.1704964474286\n",
      "    val_log_likelihood: 940.6598087805272\n",
      "    val_log_marginal: 599.5449939425043\n",
      "Train Epoch: 306 [512/17352 (3%)] Loss: -512.964844\n",
      "Train Epoch: 306 [10658/17352 (61%)] Loss: -813.212457\n",
      "Train Epoch: 306 [17133/17352 (99%)] Loss: -758.942645\n",
      "    epoch          : 306\n",
      "    loss           : -660.130318417778\n",
      "    val_loss       : -555.9038234568515\n",
      "    val_log_likelihood: 925.2235051367036\n",
      "    val_log_marginal: 578.1226956811286\n",
      "Train Epoch: 307 [512/17352 (3%)] Loss: -691.437134\n",
      "Train Epoch: 307 [9669/17352 (56%)] Loss: -719.782106\n",
      "Train Epoch: 307 [17049/17352 (98%)] Loss: -782.890587\n",
      "    epoch          : 307\n",
      "    loss           : -665.3448175977104\n",
      "    val_loss       : -553.2377243572371\n",
      "    val_log_likelihood: 915.9531218371255\n",
      "    val_log_marginal: 582.3708562295092\n",
      "Train Epoch: 308 [512/17352 (3%)] Loss: -713.575439\n",
      "Train Epoch: 308 [10365/17352 (60%)] Loss: -722.301659\n",
      "Train Epoch: 308 [17143/17352 (99%)] Loss: -702.792587\n",
      "    epoch          : 308\n",
      "    loss           : -664.5583087822922\n",
      "    val_loss       : -535.9745107036299\n",
      "    val_log_likelihood: 922.0891057118104\n",
      "    val_log_marginal: 560.2514686440542\n",
      "Train Epoch: 309 [512/17352 (3%)] Loss: -681.015625\n",
      "Train Epoch: 309 [10198/17352 (59%)] Loss: -748.880696\n",
      "Train Epoch: 309 [16922/17352 (98%)] Loss: -823.777886\n",
      "    epoch          : 309\n",
      "    loss           : -676.0785574042758\n",
      "    val_loss       : -563.8233556314283\n",
      "    val_log_likelihood: 937.240378776809\n",
      "    val_log_marginal: 590.1974420366978\n",
      "Train Epoch: 310 [512/17352 (3%)] Loss: -750.831848\n",
      "Train Epoch: 310 [9957/17352 (57%)] Loss: -807.530707\n",
      "Train Epoch: 310 [17335/17352 (100%)] Loss: -648.299558\n",
      "    epoch          : 310\n",
      "    loss           : -672.6288330172894\n",
      "    val_loss       : -402.3275218653548\n",
      "    val_log_likelihood: 912.8551537131043\n",
      "    val_log_marginal: 434.3237284792812\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0506_152815/checkpoint-epoch310.pth ...\n",
      "Train Epoch: 311 [512/17352 (3%)] Loss: -564.186951\n",
      "Train Epoch: 311 [10072/17352 (58%)] Loss: -608.118559\n",
      "Train Epoch: 311 [17108/17352 (99%)] Loss: -424.243934\n",
      "    epoch          : 311\n",
      "    loss           : -477.99014927817433\n",
      "    val_loss       : -250.6502805262623\n",
      "    val_log_likelihood: 824.4953365593864\n",
      "    val_log_marginal: 277.33319611392693\n",
      "Train Epoch: 312 [512/17352 (3%)] Loss: -292.917755\n",
      "Train Epoch: 312 [10390/17352 (60%)] Loss: -475.247717\n",
      "Train Epoch: 312 [17124/17352 (99%)] Loss: -325.574628\n",
      "    epoch          : 312\n",
      "    loss           : -313.05617979281095\n",
      "    val_loss       : 36.90028931304101\n",
      "    val_log_likelihood: 794.0961055915598\n",
      "    val_log_marginal: 29.89743768051387\n",
      "Train Epoch: 313 [512/17352 (3%)] Loss: -226.485687\n",
      "Train Epoch: 313 [9989/17352 (58%)] Loss: -575.396278\n",
      "Train Epoch: 313 [16887/17352 (97%)] Loss: -358.342515\n",
      "    epoch          : 313\n",
      "    loss           : -450.07057970152465\n",
      "    val_loss       : -393.6052539579573\n",
      "    val_log_likelihood: 824.2546623241228\n",
      "    val_log_marginal: 479.54334607412443\n",
      "Train Epoch: 314 [512/17352 (3%)] Loss: -505.314789\n",
      "Train Epoch: 314 [9648/17352 (56%)] Loss: -627.633526\n",
      "Train Epoch: 314 [17143/17352 (99%)] Loss: -601.175717\n",
      "    epoch          : 314\n",
      "    loss           : -565.5408814867835\n",
      "    val_loss       : -518.123352629114\n",
      "    val_log_likelihood: 884.9282543464411\n",
      "    val_log_marginal: 559.5946006367893\n",
      "Train Epoch: 315 [512/17352 (3%)] Loss: -646.319519\n",
      "Train Epoch: 315 [10731/17352 (62%)] Loss: -503.301959\n",
      "Train Epoch: 315 [17101/17352 (99%)] Loss: -562.703692\n",
      "    epoch          : 315\n",
      "    loss           : -641.7345551748683\n",
      "    val_loss       : -539.7014801950987\n",
      "    val_log_likelihood: 910.727304961622\n",
      "    val_log_marginal: 585.5488753464588\n",
      "Train Epoch: 316 [512/17352 (3%)] Loss: -703.757324\n",
      "Train Epoch: 316 [10315/17352 (59%)] Loss: -634.556250\n",
      "Train Epoch: 316 [16988/17352 (98%)] Loss: -736.418605\n",
      "    epoch          : 316\n",
      "    loss           : -679.8797725047087\n",
      "    val_loss       : -589.2631370423602\n",
      "    val_log_likelihood: 925.4815334293168\n",
      "    val_log_marginal: 613.7422622324318\n",
      "Train Epoch: 317 [512/17352 (3%)] Loss: -726.257080\n",
      "Train Epoch: 317 [10252/17352 (59%)] Loss: -529.919761\n",
      "Train Epoch: 317 [16883/17352 (97%)] Loss: -651.120453\n",
      "    epoch          : 317\n",
      "    loss           : -688.9368716909967\n",
      "    val_loss       : -587.3794873968059\n",
      "    val_log_likelihood: 939.7031783287713\n",
      "    val_log_marginal: 612.4730100401194\n",
      "Train Epoch: 318 [512/17352 (3%)] Loss: -726.554871\n",
      "Train Epoch: 318 [10198/17352 (59%)] Loss: -632.865330\n",
      "Train Epoch: 318 [17263/17352 (99%)] Loss: -786.237673\n",
      "    epoch          : 318\n",
      "    loss           : -695.0289653517546\n",
      "    val_loss       : -571.9281367512805\n",
      "    val_log_likelihood: 934.3993432747471\n",
      "    val_log_marginal: 599.8211441741195\n",
      "Train Epoch: 319 [512/17352 (3%)] Loss: -725.770996\n",
      "Train Epoch: 319 [10938/17352 (63%)] Loss: -672.674526\n",
      "Train Epoch: 319 [17253/17352 (99%)] Loss: -543.471292\n",
      "    epoch          : 319\n",
      "    loss           : -681.158716191457\n",
      "    val_loss       : -560.9897658577253\n",
      "    val_log_likelihood: 931.2194147847638\n",
      "    val_log_marginal: 598.7423773001103\n",
      "Train Epoch: 320 [512/17352 (3%)] Loss: -703.152283\n",
      "Train Epoch: 320 [10384/17352 (60%)] Loss: -701.943414\n",
      "Train Epoch: 320 [17335/17352 (100%)] Loss: -606.155185\n",
      "    epoch          : 320\n",
      "    loss           : -670.0819044942004\n",
      "    val_loss       : -552.6532349707867\n",
      "    val_log_likelihood: 921.7373086816822\n",
      "    val_log_marginal: 586.9813628289938\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0506_152815/checkpoint-epoch320.pth ...\n",
      "Train Epoch: 321 [512/17352 (3%)] Loss: -711.066406\n",
      "Train Epoch: 321 [10303/17352 (59%)] Loss: -789.636594\n",
      "Train Epoch: 321 [16957/17352 (98%)] Loss: -732.638151\n",
      "    epoch          : 321\n",
      "    loss           : -696.4831821939395\n",
      "    val_loss       : -595.4141583014363\n",
      "    val_log_likelihood: 948.7368659331443\n",
      "    val_log_marginal: 613.7623568444952\n",
      "Train Epoch: 322 [512/17352 (3%)] Loss: -758.266541\n",
      "Train Epoch: 322 [10409/17352 (60%)] Loss: -780.571938\n",
      "Train Epoch: 322 [16883/17352 (97%)] Loss: -608.086393\n",
      "    epoch          : 322\n",
      "    loss           : -709.4470857151839\n",
      "    val_loss       : -587.2558688673573\n",
      "    val_log_likelihood: 947.2243600779478\n",
      "    val_log_marginal: 611.4381361634277\n",
      "Train Epoch: 323 [512/17352 (3%)] Loss: -739.922729\n",
      "Train Epoch: 323 [10569/17352 (61%)] Loss: -754.149576\n",
      "Train Epoch: 323 [17101/17352 (99%)] Loss: -772.802226\n",
      "    epoch          : 323\n",
      "    loss           : -711.4538902837876\n",
      "    val_loss       : -595.6573965535738\n",
      "    val_log_likelihood: 959.1806023990235\n",
      "    val_log_marginal: 624.0965640379185\n",
      "Train Epoch: 324 [512/17352 (3%)] Loss: -736.851685\n",
      "Train Epoch: 324 [10214/17352 (59%)] Loss: -668.074985\n",
      "Train Epoch: 324 [17277/17352 (100%)] Loss: -639.477772\n",
      "    epoch          : 324\n",
      "    loss           : -702.6611030460175\n",
      "    val_loss       : -580.4568202601397\n",
      "    val_log_likelihood: 958.6860807193099\n",
      "    val_log_marginal: 604.6977097629593\n",
      "Train Epoch: 325 [512/17352 (3%)] Loss: -745.367249\n",
      "Train Epoch: 325 [10995/17352 (63%)] Loss: -649.322960\n",
      "Train Epoch: 325 [16988/17352 (98%)] Loss: -734.371615\n",
      "    epoch          : 325\n",
      "    loss           : -711.9015079252637\n",
      "    val_loss       : -592.7721163122067\n",
      "    val_log_likelihood: 963.5454592928506\n",
      "    val_log_marginal: 618.6413045726746\n",
      "Train Epoch: 326 [512/17352 (3%)] Loss: -754.052979\n",
      "Train Epoch: 326 [10077/17352 (58%)] Loss: -597.653981\n",
      "Train Epoch: 326 [17253/17352 (99%)] Loss: -520.773886\n",
      "    epoch          : 326\n",
      "    loss           : -711.4572400139645\n",
      "    val_loss       : -598.8432861912811\n",
      "    val_log_likelihood: 962.8986699520223\n",
      "    val_log_marginal: 620.6045643558851\n",
      "Train Epoch: 327 [512/17352 (3%)] Loss: -746.321777\n",
      "Train Epoch: 327 [10143/17352 (58%)] Loss: -667.649306\n",
      "Train Epoch: 327 [17106/17352 (99%)] Loss: -810.743137\n",
      "    epoch          : 327\n",
      "    loss           : -713.2719639119193\n",
      "    val_loss       : -592.6446949344833\n",
      "    val_log_likelihood: 960.7394472645893\n",
      "    val_log_marginal: 618.7230293835503\n",
      "Train Epoch: 328 [512/17352 (3%)] Loss: -760.886963\n",
      "Train Epoch: 328 [10962/17352 (63%)] Loss: -802.551795\n",
      "Train Epoch: 328 [16887/17352 (97%)] Loss: -787.650158\n",
      "    epoch          : 328\n",
      "    loss           : -711.936989187949\n",
      "    val_loss       : -588.2692776879663\n",
      "    val_log_likelihood: 964.8187843652564\n",
      "    val_log_marginal: 612.1976836852833\n",
      "Train Epoch: 329 [512/17352 (3%)] Loss: -759.951294\n",
      "Train Epoch: 329 [10195/17352 (59%)] Loss: -742.997396\n",
      "Train Epoch: 329 [16934/17352 (98%)] Loss: -533.453999\n",
      "    epoch          : 329\n",
      "    loss           : -710.305240216831\n",
      "    val_loss       : -581.1329586735254\n",
      "    val_log_likelihood: 961.1871789691235\n",
      "    val_log_marginal: 606.4334422101067\n",
      "Train Epoch: 330 [512/17352 (3%)] Loss: -755.756226\n",
      "Train Epoch: 330 [10149/17352 (58%)] Loss: -594.531798\n",
      "Train Epoch: 330 [16957/17352 (98%)] Loss: -621.122495\n",
      "    epoch          : 330\n",
      "    loss           : -654.8547063190113\n",
      "    val_loss       : -540.8561981199539\n",
      "    val_log_likelihood: 942.3440181200455\n",
      "    val_log_marginal: 578.7959633862093\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0506_152815/checkpoint-epoch330.pth ...\n",
      "Train Epoch: 331 [512/17352 (3%)] Loss: -724.946716\n",
      "Train Epoch: 331 [9778/17352 (56%)] Loss: -711.948390\n",
      "Train Epoch: 331 [17124/17352 (99%)] Loss: -702.586615\n",
      "    epoch          : 331\n",
      "    loss           : -660.7254754337486\n",
      "    val_loss       : -501.3189744388736\n",
      "    val_log_likelihood: 941.6121060701504\n",
      "    val_log_marginal: 525.7054230003563\n",
      "Train Epoch: 332 [512/17352 (3%)] Loss: -705.317871\n",
      "Train Epoch: 332 [10091/17352 (58%)] Loss: -572.818689\n",
      "Train Epoch: 332 [16923/17352 (98%)] Loss: -573.649526\n",
      "    epoch          : 332\n",
      "    loss           : -628.3507273609257\n",
      "    val_loss       : -525.9241549902082\n",
      "    val_log_likelihood: 947.8054959489116\n",
      "    val_log_marginal: 581.128787578324\n",
      "Train Epoch: 333 [512/17352 (3%)] Loss: -725.724609\n",
      "Train Epoch: 333 [10653/17352 (61%)] Loss: -690.839589\n",
      "Train Epoch: 333 [17101/17352 (99%)] Loss: -651.613800\n",
      "    epoch          : 333\n",
      "    loss           : -646.2992054135623\n",
      "    val_loss       : -439.74381757679276\n",
      "    val_log_likelihood: 921.3655915998065\n",
      "    val_log_marginal: 478.0666505685045\n",
      "Train Epoch: 334 [512/17352 (3%)] Loss: -646.345154\n",
      "Train Epoch: 334 [10699/17352 (62%)] Loss: -792.618038\n",
      "Train Epoch: 334 [17277/17352 (100%)] Loss: -509.437913\n",
      "    epoch          : 334\n",
      "    loss           : -643.2352839163946\n",
      "    val_loss       : -317.86553312741677\n",
      "    val_log_likelihood: 925.0539139950032\n",
      "    val_log_marginal: 367.8117724092391\n",
      "Train Epoch: 335 [512/17352 (3%)] Loss: -550.923035\n",
      "Train Epoch: 335 [9721/17352 (56%)] Loss: -300.126418\n",
      "Train Epoch: 335 [17133/17352 (99%)] Loss: -435.936575\n",
      "    epoch          : 335\n",
      "    loss           : -466.0002445444302\n",
      "    val_loss       : -122.38627486002878\n",
      "    val_log_likelihood: 866.4523829356579\n",
      "    val_log_marginal: 174.76523677044383\n",
      "Train Epoch: 336 [512/17352 (3%)] Loss: -385.333649\n",
      "Train Epoch: 336 [9939/17352 (57%)] Loss: -571.747396\n",
      "Train Epoch: 336 [17016/17352 (98%)] Loss: -580.422852\n",
      "    epoch          : 336\n",
      "    loss           : -357.54569336241894\n",
      "    val_loss       : -254.5327816109807\n",
      "    val_log_likelihood: 870.6317744547533\n",
      "    val_log_marginal: 306.84823838255494\n",
      "Train Epoch: 337 [512/17352 (3%)] Loss: -381.573639\n",
      "Train Epoch: 337 [10316/17352 (59%)] Loss: -450.382845\n",
      "Train Epoch: 337 [17126/17352 (99%)] Loss: -711.914579\n",
      "    epoch          : 337\n",
      "    loss           : -548.8015346986227\n",
      "    val_loss       : -492.9542418795823\n",
      "    val_log_likelihood: 909.6328217632238\n",
      "    val_log_marginal: 534.2395435511082\n",
      "Train Epoch: 338 [512/17352 (3%)] Loss: -661.351929\n",
      "Train Epoch: 338 [9991/17352 (58%)] Loss: -479.655193\n",
      "Train Epoch: 338 [16934/17352 (98%)] Loss: -562.018939\n",
      "    epoch          : 338\n",
      "    loss           : -630.1085311539151\n",
      "    val_loss       : -549.8513585676097\n",
      "    val_log_likelihood: 919.1582859694752\n",
      "    val_log_marginal: 587.5394028338397\n",
      "Train Epoch: 339 [512/17352 (3%)] Loss: -710.108154\n",
      "Train Epoch: 339 [10301/17352 (59%)] Loss: -725.066992\n",
      "Train Epoch: 339 [17106/17352 (99%)] Loss: -765.380790\n",
      "    epoch          : 339\n",
      "    loss           : -686.468730660043\n",
      "    val_loss       : -573.6899323233832\n",
      "    val_log_likelihood: 944.0717010932992\n",
      "    val_log_marginal: 610.4223964317858\n",
      "Train Epoch: 340 [512/17352 (3%)] Loss: -702.736572\n",
      "Train Epoch: 340 [10073/17352 (58%)] Loss: -524.217330\n",
      "Train Epoch: 340 [16988/17352 (98%)] Loss: -760.259335\n",
      "    epoch          : 340\n",
      "    loss           : -676.5530150657175\n",
      "    val_loss       : -583.3831904992873\n",
      "    val_log_likelihood: 947.7748431668973\n",
      "    val_log_marginal: 617.3585777095021\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0506_152815/checkpoint-epoch340.pth ...\n",
      "Train Epoch: 341 [512/17352 (3%)] Loss: -749.839844\n",
      "Train Epoch: 341 [10180/17352 (59%)] Loss: -705.018189\n",
      "Train Epoch: 341 [16934/17352 (98%)] Loss: -744.010050\n",
      "    epoch          : 341\n",
      "    loss           : -700.8370002901244\n",
      "    val_loss       : -589.1085730453615\n",
      "    val_log_likelihood: 957.0991733130188\n",
      "    val_log_marginal: 617.8227684171073\n",
      "Train Epoch: 342 [512/17352 (3%)] Loss: -557.591614\n",
      "Train Epoch: 342 [10643/17352 (61%)] Loss: -790.687816\n",
      "Train Epoch: 342 [16887/17352 (97%)] Loss: -769.769487\n",
      "    epoch          : 342\n",
      "    loss           : -699.4488223366491\n",
      "    val_loss       : -573.1118470149097\n",
      "    val_log_likelihood: 954.6466309672353\n",
      "    val_log_marginal: 612.0316449479495\n",
      "Train Epoch: 343 [512/17352 (3%)] Loss: -716.481506\n",
      "Train Epoch: 343 [10681/17352 (62%)] Loss: -762.931864\n",
      "Train Epoch: 343 [16872/17352 (97%)] Loss: -587.763207\n",
      "    epoch          : 343\n",
      "    loss           : -697.3607763633311\n",
      "    val_loss       : -523.3023785064629\n",
      "    val_log_likelihood: 950.5710226006934\n",
      "    val_log_marginal: 550.7764694047954\n",
      "Train Epoch: 344 [512/17352 (3%)] Loss: -680.734619\n",
      "Train Epoch: 344 [10574/17352 (61%)] Loss: -621.997920\n",
      "Train Epoch: 344 [16939/17352 (98%)] Loss: -512.326681\n",
      "    epoch          : 344\n",
      "    loss           : -683.1361102855614\n",
      "    val_loss       : -584.5076416003839\n",
      "    val_log_likelihood: 956.7574594491514\n",
      "    val_log_marginal: 606.6151266821009\n",
      "Train Epoch: 345 [512/17352 (3%)] Loss: -745.574097\n",
      "Train Epoch: 345 [10303/17352 (59%)] Loss: -736.225503\n",
      "Train Epoch: 345 [16957/17352 (98%)] Loss: -503.876121\n",
      "    epoch          : 345\n",
      "    loss           : -711.3543147751623\n",
      "    val_loss       : -584.2897825313844\n",
      "    val_log_likelihood: 967.5888465570089\n",
      "    val_log_marginal: 610.3261085574222\n",
      "Train Epoch: 346 [512/17352 (3%)] Loss: -752.729736\n",
      "Train Epoch: 346 [10267/17352 (59%)] Loss: -686.433868\n",
      "Train Epoch: 346 [17277/17352 (100%)] Loss: -757.992366\n",
      "    epoch          : 346\n",
      "    loss           : -719.6182936170376\n",
      "    val_loss       : -594.9959221446215\n",
      "    val_log_likelihood: 970.6183496178672\n",
      "    val_log_marginal: 623.8603681913726\n",
      "Train Epoch: 347 [512/17352 (3%)] Loss: -756.665405\n",
      "Train Epoch: 347 [10490/17352 (60%)] Loss: -778.825573\n",
      "Train Epoch: 347 [16934/17352 (98%)] Loss: -666.672061\n",
      "    epoch          : 347\n",
      "    loss           : -724.7803213916271\n",
      "    val_loss       : -596.5885777909424\n",
      "    val_log_likelihood: 974.699903467223\n",
      "    val_log_marginal: 627.1203790524438\n",
      "Train Epoch: 348 [512/17352 (3%)] Loss: -780.283508\n",
      "Train Epoch: 348 [9968/17352 (57%)] Loss: -753.511464\n",
      "Train Epoch: 348 [17253/17352 (99%)] Loss: -752.005725\n",
      "    epoch          : 348\n",
      "    loss           : -724.1988639780735\n",
      "    val_loss       : -602.473084442687\n",
      "    val_log_likelihood: 973.842749406728\n",
      "    val_log_marginal: 625.9638305762998\n",
      "Train Epoch: 349 [512/17352 (3%)] Loss: -758.871582\n",
      "Train Epoch: 349 [10774/17352 (62%)] Loss: -824.850613\n",
      "Train Epoch: 349 [16934/17352 (98%)] Loss: -682.007927\n",
      "    epoch          : 349\n",
      "    loss           : -725.6173204081759\n",
      "    val_loss       : -606.1707422001325\n",
      "    val_log_likelihood: 977.1197026223693\n",
      "    val_log_marginal: 633.7384867101963\n",
      "Train Epoch: 350 [512/17352 (3%)] Loss: -778.269043\n",
      "Train Epoch: 350 [10737/17352 (62%)] Loss: -672.735694\n",
      "Train Epoch: 350 [17153/17352 (99%)] Loss: -755.682848\n",
      "    epoch          : 350\n",
      "    loss           : -727.5640798620886\n",
      "    val_loss       : -600.7037627794027\n",
      "    val_log_likelihood: 982.4435003423883\n",
      "    val_log_marginal: 633.2424500377932\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0506_152815/checkpoint-epoch350.pth ...\n",
      "Train Epoch: 351 [512/17352 (3%)] Loss: -758.522644\n",
      "Train Epoch: 351 [9867/17352 (57%)] Loss: -765.735122\n",
      "Train Epoch: 351 [16939/17352 (98%)] Loss: -849.874023\n",
      "    epoch          : 351\n",
      "    loss           : -723.1748589501989\n",
      "    val_loss       : -592.1153209697202\n",
      "    val_log_likelihood: 975.1382454876523\n",
      "    val_log_marginal: 615.2185839800172\n",
      "Train Epoch: 352 [512/17352 (3%)] Loss: -774.547607\n",
      "Train Epoch: 352 [10376/17352 (60%)] Loss: -816.952759\n",
      "Train Epoch: 352 [17263/17352 (99%)] Loss: -781.117937\n",
      "    epoch          : 352\n",
      "    loss           : -725.3964714859035\n",
      "    val_loss       : -590.6378991236379\n",
      "    val_log_likelihood: 975.8578602326037\n",
      "    val_log_marginal: 610.6923888074465\n",
      "Train Epoch: 353 [512/17352 (3%)] Loss: -767.814575\n",
      "Train Epoch: 353 [10182/17352 (59%)] Loss: -807.898021\n",
      "Train Epoch: 353 [17064/17352 (98%)] Loss: -798.294186\n",
      "    epoch          : 353\n",
      "    loss           : -734.0659733419003\n",
      "    val_loss       : -608.0946922196044\n",
      "    val_log_likelihood: 991.1790136481623\n",
      "    val_log_marginal: 633.5484389646181\n",
      "Train Epoch: 354 [512/17352 (3%)] Loss: -770.230896\n",
      "Train Epoch: 354 [10646/17352 (61%)] Loss: -747.463470\n",
      "Train Epoch: 354 [16882/17352 (97%)] Loss: -731.407967\n",
      "    epoch          : 354\n",
      "    loss           : -731.2514362665676\n",
      "    val_loss       : -610.0599741668982\n",
      "    val_log_likelihood: 983.7240736130336\n",
      "    val_log_marginal: 631.1394294356048\n",
      "Train Epoch: 355 [512/17352 (3%)] Loss: -782.449341\n",
      "Train Epoch: 355 [10339/17352 (60%)] Loss: -751.505129\n",
      "Train Epoch: 355 [16957/17352 (98%)] Loss: -748.339015\n",
      "    epoch          : 355\n",
      "    loss           : -735.4269890501145\n",
      "    val_loss       : -605.0400301448184\n",
      "    val_log_likelihood: 985.0057443084877\n",
      "    val_log_marginal: 627.1803313828021\n",
      "Train Epoch: 356 [512/17352 (3%)] Loss: -781.716187\n",
      "Train Epoch: 356 [10764/17352 (62%)] Loss: -647.027800\n",
      "Train Epoch: 356 [16883/17352 (97%)] Loss: -718.137705\n",
      "    epoch          : 356\n",
      "    loss           : -740.3657083063852\n",
      "    val_loss       : -607.5838107487818\n",
      "    val_log_likelihood: 985.6105981489023\n",
      "    val_log_marginal: 630.4204272144798\n",
      "Train Epoch: 357 [512/17352 (3%)] Loss: -795.588074\n",
      "Train Epoch: 357 [10306/17352 (59%)] Loss: -818.835821\n",
      "Train Epoch: 357 [17277/17352 (100%)] Loss: -703.089039\n",
      "    epoch          : 357\n",
      "    loss           : -728.297613605918\n",
      "    val_loss       : -596.4478335321664\n",
      "    val_log_likelihood: 989.6610875050211\n",
      "    val_log_marginal: 624.3273431110812\n",
      "Train Epoch: 358 [512/17352 (3%)] Loss: -784.643188\n",
      "Train Epoch: 358 [10461/17352 (60%)] Loss: -847.715885\n",
      "Train Epoch: 358 [17124/17352 (99%)] Loss: -721.596680\n",
      "    epoch          : 358\n",
      "    loss           : -732.1518606167328\n",
      "    val_loss       : -563.6778720517989\n",
      "    val_log_likelihood: 974.797987405139\n",
      "    val_log_marginal: 597.2173408188709\n",
      "Train Epoch: 359 [512/17352 (3%)] Loss: -752.621826\n",
      "Train Epoch: 359 [9930/17352 (57%)] Loss: -675.144299\n",
      "Train Epoch: 359 [17124/17352 (99%)] Loss: -732.176084\n",
      "    epoch          : 359\n",
      "    loss           : -721.7196022281469\n",
      "    val_loss       : -555.2042399592003\n",
      "    val_log_likelihood: 968.4072868612415\n",
      "    val_log_marginal: 587.8071076844928\n",
      "Train Epoch: 360 [512/17352 (3%)] Loss: -765.047852\n",
      "Train Epoch: 360 [10301/17352 (59%)] Loss: -672.042614\n",
      "Train Epoch: 360 [16922/17352 (98%)] Loss: -788.271186\n",
      "    epoch          : 360\n",
      "    loss           : -670.8392875559393\n",
      "    val_loss       : -539.3809169490547\n",
      "    val_log_likelihood: 974.461259863912\n",
      "    val_log_marginal: 590.9877981944627\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0506_152815/checkpoint-epoch360.pth ...\n",
      "Train Epoch: 361 [512/17352 (3%)] Loss: -766.331909\n",
      "Train Epoch: 361 [10200/17352 (59%)] Loss: -181.422737\n",
      "Train Epoch: 361 [17153/17352 (99%)] Loss: -627.861407\n",
      "    epoch          : 361\n",
      "    loss           : -422.8209117568258\n",
      "    val_loss       : -28.835360052547045\n",
      "    val_log_likelihood: 820.0622835971527\n",
      "    val_log_marginal: 76.42750436781222\n",
      "Train Epoch: 362 [512/17352 (3%)] Loss: -324.992188\n",
      "Train Epoch: 362 [10421/17352 (60%)] Loss: -541.195913\n",
      "Train Epoch: 362 [17064/17352 (98%)] Loss: -613.511364\n",
      "    epoch          : 362\n",
      "    loss           : -421.53119527079514\n",
      "    val_loss       : 62.151876795717065\n",
      "    val_log_likelihood: 864.4287140378665\n",
      "    val_log_marginal: -26.3459417074391\n",
      "Train Epoch: 363 [512/17352 (3%)] Loss: 37.066219\n",
      "Train Epoch: 363 [10073/17352 (58%)] Loss: -348.276769\n",
      "Train Epoch: 363 [16958/17352 (98%)] Loss: -660.397604\n",
      "    epoch          : 363\n",
      "    loss           : -421.69475469857974\n",
      "    val_loss       : -481.86701260562984\n",
      "    val_log_likelihood: 907.3512854464869\n",
      "    val_log_marginal: 512.4737998252527\n",
      "Train Epoch: 364 [512/17352 (3%)] Loss: -644.560913\n",
      "Train Epoch: 364 [10868/17352 (63%)] Loss: -726.600581\n",
      "Train Epoch: 364 [17049/17352 (98%)] Loss: -702.617281\n",
      "    epoch          : 364\n",
      "    loss           : -636.9792177080719\n",
      "    val_loss       : -528.1939322990628\n",
      "    val_log_likelihood: 919.2410271183951\n",
      "    val_log_marginal: 563.7581402371746\n",
      "Train Epoch: 365 [512/17352 (3%)] Loss: -699.962646\n",
      "Train Epoch: 365 [10254/17352 (59%)] Loss: -636.516196\n",
      "Train Epoch: 365 [16887/17352 (97%)] Loss: -803.899120\n",
      "    epoch          : 365\n",
      "    loss           : -665.1778187588062\n",
      "    val_loss       : -566.215767687681\n",
      "    val_log_likelihood: 950.8085321231971\n",
      "    val_log_marginal: 604.2252968432206\n",
      "Train Epoch: 366 [512/17352 (3%)] Loss: -763.179688\n",
      "Train Epoch: 366 [10414/17352 (60%)] Loss: -774.185881\n",
      "Train Epoch: 366 [17335/17352 (100%)] Loss: -796.193206\n",
      "    epoch          : 366\n",
      "    loss           : -725.9538616569488\n",
      "    val_loss       : -598.7421916401312\n",
      "    val_log_likelihood: 970.9829596011059\n",
      "    val_log_marginal: 621.9781877658763\n",
      "Train Epoch: 367 [512/17352 (3%)] Loss: -766.960449\n",
      "Train Epoch: 367 [9813/17352 (57%)] Loss: -780.196510\n",
      "Train Epoch: 367 [16887/17352 (97%)] Loss: -825.477545\n",
      "    epoch          : 367\n",
      "    loss           : -735.565161964114\n",
      "    val_loss       : -609.169231888778\n",
      "    val_log_likelihood: 985.1206138089557\n",
      "    val_log_marginal: 639.5830379708028\n",
      "Train Epoch: 368 [512/17352 (3%)] Loss: -587.777100\n",
      "Train Epoch: 368 [10278/17352 (59%)] Loss: -586.564382\n",
      "Train Epoch: 368 [16934/17352 (98%)] Loss: -626.809136\n",
      "    epoch          : 368\n",
      "    loss           : -736.1328697746965\n",
      "    val_loss       : -606.6837933021933\n",
      "    val_log_likelihood: 971.6128700901422\n",
      "    val_log_marginal: 630.8443647667377\n",
      "Train Epoch: 369 [512/17352 (3%)] Loss: -773.054932\n",
      "Train Epoch: 369 [9963/17352 (57%)] Loss: -767.314528\n",
      "Train Epoch: 369 [17124/17352 (99%)] Loss: -829.132912\n",
      "    epoch          : 369\n",
      "    loss           : -729.0291503795944\n",
      "    val_loss       : -592.6902180202709\n",
      "    val_log_likelihood: 977.7467555956512\n",
      "    val_log_marginal: 630.0362885775564\n",
      "Train Epoch: 370 [512/17352 (3%)] Loss: -740.898438\n",
      "Train Epoch: 370 [10309/17352 (59%)] Loss: -613.976434\n",
      "Train Epoch: 370 [16878/17352 (97%)] Loss: -704.994141\n",
      "    epoch          : 370\n",
      "    loss           : -728.3698229909279\n",
      "    val_loss       : -582.1167043821104\n",
      "    val_log_likelihood: 990.9081330765713\n",
      "    val_log_marginal: 631.6505010401727\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0506_152815/checkpoint-epoch370.pth ...\n",
      "Train Epoch: 371 [512/17352 (3%)] Loss: -749.055847\n",
      "Train Epoch: 371 [10575/17352 (61%)] Loss: -637.702344\n",
      "Train Epoch: 371 [17106/17352 (99%)] Loss: -697.061570\n",
      "    epoch          : 371\n",
      "    loss           : -719.469670627953\n",
      "    val_loss       : -606.3871057322879\n",
      "    val_log_likelihood: 988.7982103432512\n",
      "    val_log_marginal: 627.080304913818\n",
      "Train Epoch: 372 [512/17352 (3%)] Loss: -776.488159\n",
      "Train Epoch: 372 [10475/17352 (60%)] Loss: -701.229380\n",
      "Train Epoch: 372 [17263/17352 (99%)] Loss: -664.796137\n",
      "    epoch          : 372\n",
      "    loss           : -737.3123609380258\n",
      "    val_loss       : -607.2783010202156\n",
      "    val_log_likelihood: 985.8373926762495\n",
      "    val_log_marginal: 629.2305710258438\n",
      "Train Epoch: 373 [512/17352 (3%)] Loss: -780.130981\n",
      "Train Epoch: 373 [10679/17352 (62%)] Loss: -776.706030\n",
      "Train Epoch: 373 [17108/17352 (99%)] Loss: -678.558911\n",
      "    epoch          : 373\n",
      "    loss           : -729.3092725165427\n",
      "    val_loss       : -599.2860476933314\n",
      "    val_log_likelihood: 996.8425364092329\n",
      "    val_log_marginal: 635.1526640783404\n",
      "Train Epoch: 374 [512/17352 (3%)] Loss: -747.402466\n",
      "Train Epoch: 374 [10540/17352 (61%)] Loss: -693.534970\n",
      "Train Epoch: 374 [16922/17352 (98%)] Loss: -791.243507\n",
      "    epoch          : 374\n",
      "    loss           : -750.0190557140222\n",
      "    val_loss       : -618.995094062499\n",
      "    val_log_likelihood: 1006.091817648288\n",
      "    val_log_marginal: 649.3232269522879\n",
      "Train Epoch: 375 [512/17352 (3%)] Loss: -591.697571\n",
      "Train Epoch: 375 [10252/17352 (59%)] Loss: -824.024709\n",
      "Train Epoch: 375 [17106/17352 (99%)] Loss: -732.100528\n",
      "    epoch          : 375\n",
      "    loss           : -751.0610446074145\n",
      "    val_loss       : -603.2705664474797\n",
      "    val_log_likelihood: 987.6187506046149\n",
      "    val_log_marginal: 624.8003960183723\n",
      "Train Epoch: 376 [512/17352 (3%)] Loss: -777.664795\n",
      "Train Epoch: 376 [10174/17352 (59%)] Loss: -797.880066\n",
      "Train Epoch: 376 [16923/17352 (98%)] Loss: -771.703598\n",
      "    epoch          : 376\n",
      "    loss           : -751.029947656231\n",
      "    val_loss       : -624.4979710011554\n",
      "    val_log_likelihood: 1003.9729959449567\n",
      "    val_log_marginal: 646.9402634154252\n",
      "Train Epoch: 377 [512/17352 (3%)] Loss: -797.288086\n",
      "Train Epoch: 377 [10362/17352 (60%)] Loss: -796.937261\n",
      "Train Epoch: 377 [17106/17352 (99%)] Loss: -803.825199\n",
      "    epoch          : 377\n",
      "    loss           : -756.1905871522868\n",
      "    val_loss       : -614.0874569256948\n",
      "    val_log_likelihood: 1004.4190864369764\n",
      "    val_log_marginal: 634.888904506557\n",
      "Train Epoch: 378 [512/17352 (3%)] Loss: -791.422729\n",
      "Train Epoch: 378 [10470/17352 (60%)] Loss: -836.777760\n",
      "Train Epoch: 378 [16887/17352 (97%)] Loss: -662.179282\n",
      "    epoch          : 378\n",
      "    loss           : -757.5521869080158\n",
      "    val_loss       : -591.6525642239608\n",
      "    val_log_likelihood: 1010.2424787647308\n",
      "    val_log_marginal: 622.1395128202832\n",
      "Train Epoch: 379 [512/17352 (3%)] Loss: -749.525513\n",
      "Train Epoch: 379 [10356/17352 (60%)] Loss: -831.714150\n",
      "Train Epoch: 379 [16992/17352 (98%)] Loss: -851.415226\n",
      "    epoch          : 379\n",
      "    loss           : -739.6242423852926\n",
      "    val_loss       : -608.0255006532385\n",
      "    val_log_likelihood: 1006.7543424874589\n",
      "    val_log_marginal: 635.2772052211874\n",
      "Train Epoch: 380 [512/17352 (3%)] Loss: -780.704285\n",
      "Train Epoch: 380 [10416/17352 (60%)] Loss: -838.476108\n",
      "Train Epoch: 380 [17153/17352 (99%)] Loss: -715.635789\n",
      "    epoch          : 380\n",
      "    loss           : -757.9442338523899\n",
      "    val_loss       : -612.3545446941822\n",
      "    val_log_likelihood: 1003.7506980431809\n",
      "    val_log_marginal: 635.7717998511896\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0506_152815/checkpoint-epoch380.pth ...\n",
      "Train Epoch: 381 [512/17352 (3%)] Loss: -798.886597\n",
      "Train Epoch: 381 [10191/17352 (59%)] Loss: -809.268873\n",
      "Train Epoch: 381 [17153/17352 (99%)] Loss: -622.551622\n",
      "    epoch          : 381\n",
      "    loss           : -756.808030232114\n",
      "    val_loss       : -621.0689929531758\n",
      "    val_log_likelihood: 1012.3062002959654\n",
      "    val_log_marginal: 642.6582104060593\n",
      "Train Epoch: 382 [512/17352 (3%)] Loss: -799.039917\n",
      "Train Epoch: 382 [10388/17352 (60%)] Loss: -803.225990\n",
      "Train Epoch: 382 [16923/17352 (98%)] Loss: -594.996545\n",
      "    epoch          : 382\n",
      "    loss           : -759.2020023035058\n",
      "    val_loss       : -620.3881126577547\n",
      "    val_log_likelihood: 1005.9240905654649\n",
      "    val_log_marginal: 639.5231782986988\n",
      "Train Epoch: 383 [512/17352 (3%)] Loss: -792.739502\n",
      "Train Epoch: 383 [10454/17352 (60%)] Loss: -857.886577\n",
      "Train Epoch: 383 [17101/17352 (99%)] Loss: -781.027246\n",
      "    epoch          : 383\n",
      "    loss           : -752.8689318003243\n",
      "    val_loss       : -613.7701009418732\n",
      "    val_log_likelihood: 1012.0915388278871\n",
      "    val_log_marginal: 638.4251955000534\n",
      "Train Epoch: 384 [512/17352 (3%)] Loss: -796.082520\n",
      "Train Epoch: 384 [9570/17352 (55%)] Loss: -798.290445\n",
      "Train Epoch: 384 [16883/17352 (97%)] Loss: -714.107378\n",
      "    epoch          : 384\n",
      "    loss           : -771.174923528639\n",
      "    val_loss       : -624.9366153096129\n",
      "    val_log_likelihood: 1022.4084623104844\n",
      "    val_log_marginal: 652.4508127303313\n",
      "Train Epoch: 385 [512/17352 (3%)] Loss: -825.574402\n",
      "Train Epoch: 385 [10760/17352 (62%)] Loss: -831.212463\n",
      "Train Epoch: 385 [17124/17352 (99%)] Loss: -653.252040\n",
      "    epoch          : 385\n",
      "    loss           : -775.4545733396473\n",
      "    val_loss       : -629.9972395685506\n",
      "    val_log_likelihood: 1023.0988244496058\n",
      "    val_log_marginal: 653.2030472313102\n",
      "Train Epoch: 386 [512/17352 (3%)] Loss: -812.976990\n",
      "Train Epoch: 386 [10192/17352 (59%)] Loss: -786.444477\n",
      "Train Epoch: 386 [17101/17352 (99%)] Loss: -727.436952\n",
      "    epoch          : 386\n",
      "    loss           : -747.5264071749668\n",
      "    val_loss       : -524.6479083293332\n",
      "    val_log_likelihood: 993.7554662046686\n",
      "    val_log_marginal: 551.0815474945186\n",
      "Train Epoch: 387 [512/17352 (3%)] Loss: -760.737915\n",
      "Train Epoch: 387 [10179/17352 (59%)] Loss: -725.934735\n",
      "Train Epoch: 387 [16992/17352 (98%)] Loss: -765.097005\n",
      "    epoch          : 387\n",
      "    loss           : -734.0374254040413\n",
      "    val_loss       : -599.5536309347084\n",
      "    val_log_likelihood: 1013.0954042762527\n",
      "    val_log_marginal: 626.6055161776633\n",
      "Train Epoch: 388 [512/17352 (3%)] Loss: -792.468079\n",
      "Train Epoch: 388 [10018/17352 (58%)] Loss: -734.711961\n",
      "Train Epoch: 388 [17143/17352 (99%)] Loss: -754.144761\n",
      "    epoch          : 388\n",
      "    loss           : -763.0811304211788\n",
      "    val_loss       : -604.5050880291831\n",
      "    val_log_likelihood: 1017.0831802032978\n",
      "    val_log_marginal: 631.0558700293446\n",
      "Train Epoch: 389 [512/17352 (3%)] Loss: -812.096680\n",
      "Train Epoch: 389 [10237/17352 (59%)] Loss: -700.446530\n",
      "Train Epoch: 389 [17133/17352 (99%)] Loss: -702.797905\n",
      "    epoch          : 389\n",
      "    loss           : -752.2060804163309\n",
      "    val_loss       : -598.5721829776369\n",
      "    val_log_likelihood: 1016.4260677056413\n",
      "    val_log_marginal: 620.3954629960776\n",
      "Train Epoch: 390 [512/17352 (3%)] Loss: -791.935852\n",
      "Train Epoch: 390 [10252/17352 (59%)] Loss: -775.063364\n",
      "Train Epoch: 390 [17124/17352 (99%)] Loss: -427.358234\n",
      "    epoch          : 390\n",
      "    loss           : -653.1083664175756\n",
      "    val_loss       : -377.6511937183622\n",
      "    val_log_likelihood: 973.0418773673542\n",
      "    val_log_marginal: 418.41868087231546\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0506_152815/checkpoint-epoch390.pth ...\n",
      "Train Epoch: 391 [512/17352 (3%)] Loss: -625.402832\n",
      "Train Epoch: 391 [10573/17352 (61%)] Loss: -650.150065\n",
      "Train Epoch: 391 [16923/17352 (98%)] Loss: -677.442969\n",
      "    epoch          : 391\n",
      "    loss           : -562.933073833923\n",
      "    val_loss       : -558.5818452669062\n",
      "    val_log_likelihood: 985.3169480481436\n",
      "    val_log_marginal: 594.4766998186217\n",
      "Train Epoch: 392 [512/17352 (3%)] Loss: -740.080505\n",
      "Train Epoch: 392 [10099/17352 (58%)] Loss: -606.331966\n",
      "Train Epoch: 392 [17106/17352 (99%)] Loss: -278.707760\n",
      "    epoch          : 392\n",
      "    loss           : -586.0007657695379\n",
      "    val_loss       : -430.08669695876034\n",
      "    val_log_likelihood: 946.4052939746986\n",
      "    val_log_marginal: 499.77790225844353\n",
      "Train Epoch: 393 [512/17352 (3%)] Loss: -592.181030\n",
      "Train Epoch: 393 [10150/17352 (58%)] Loss: -533.786979\n",
      "Train Epoch: 393 [16939/17352 (98%)] Loss: -764.487970\n",
      "    epoch          : 393\n",
      "    loss           : -651.3812287998076\n",
      "    val_loss       : -575.0446563912287\n",
      "    val_log_likelihood: 983.100603229125\n",
      "    val_log_marginal: 603.5035239146189\n",
      "Train Epoch: 394 [512/17352 (3%)] Loss: -761.453979\n",
      "Train Epoch: 394 [10520/17352 (61%)] Loss: -638.571243\n",
      "Train Epoch: 394 [17133/17352 (99%)] Loss: -622.581903\n",
      "    epoch          : 394\n",
      "    loss           : -726.7402434204439\n",
      "    val_loss       : -573.7464380555735\n",
      "    val_log_likelihood: 984.5655957881371\n",
      "    val_log_marginal: 599.1704448147277\n",
      "Train Epoch: 395 [512/17352 (3%)] Loss: -748.580383\n",
      "Train Epoch: 395 [10270/17352 (59%)] Loss: -686.822219\n",
      "Train Epoch: 395 [16988/17352 (98%)] Loss: -734.683547\n",
      "    epoch          : 395\n",
      "    loss           : -742.8422222045207\n",
      "    val_loss       : -617.5848282240487\n",
      "    val_log_likelihood: 1010.3365334569014\n",
      "    val_log_marginal: 639.9455542463528\n",
      "Train Epoch: 396 [512/17352 (3%)] Loss: -599.043091\n",
      "Train Epoch: 396 [10540/17352 (61%)] Loss: -839.043351\n",
      "Train Epoch: 396 [17126/17352 (99%)] Loss: -824.819223\n",
      "    epoch          : 396\n",
      "    loss           : -765.4826580705034\n",
      "    val_loss       : -606.167460936391\n",
      "    val_log_likelihood: 1017.5181762438418\n",
      "    val_log_marginal: 629.1439785884937\n",
      "Train Epoch: 397 [512/17352 (3%)] Loss: -787.708923\n",
      "Train Epoch: 397 [10353/17352 (60%)] Loss: -822.517224\n",
      "Train Epoch: 397 [17124/17352 (99%)] Loss: -803.885364\n",
      "    epoch          : 397\n",
      "    loss           : -761.031726322132\n",
      "    val_loss       : -576.9168106012013\n",
      "    val_log_likelihood: 1006.5218700388133\n",
      "    val_log_marginal: 610.4511342660888\n",
      "Train Epoch: 398 [512/17352 (3%)] Loss: -782.039062\n",
      "Train Epoch: 398 [10701/17352 (62%)] Loss: -747.043072\n",
      "Train Epoch: 398 [17106/17352 (99%)] Loss: -688.562314\n",
      "    epoch          : 398\n",
      "    loss           : -705.373851240843\n",
      "    val_loss       : -546.081521436224\n",
      "    val_log_likelihood: 984.0933631223099\n",
      "    val_log_marginal: 575.1065799655556\n",
      "Train Epoch: 399 [512/17352 (3%)] Loss: -751.863098\n",
      "Train Epoch: 399 [10295/17352 (59%)] Loss: -802.809774\n",
      "Train Epoch: 399 [17049/17352 (98%)] Loss: -728.641877\n",
      "    epoch          : 399\n",
      "    loss           : -717.5685877373782\n",
      "    val_loss       : -590.7149721236137\n",
      "    val_log_likelihood: 995.4467574715543\n",
      "    val_log_marginal: 621.4174512429023\n",
      "Train Epoch: 400 [512/17352 (3%)] Loss: -767.605103\n",
      "Train Epoch: 400 [9528/17352 (55%)] Loss: -433.858898\n",
      "Train Epoch: 400 [16923/17352 (98%)] Loss: -658.383116\n",
      "    epoch          : 400\n",
      "    loss           : -704.9570647414204\n",
      "    val_loss       : -576.1871453966338\n",
      "    val_log_likelihood: 1003.0734954515476\n",
      "    val_log_marginal: 612.8859936584628\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0506_152815/checkpoint-epoch400.pth ...\n",
      "Train Epoch: 401 [512/17352 (3%)] Loss: -771.756042\n",
      "Train Epoch: 401 [9657/17352 (56%)] Loss: -869.149364\n",
      "Train Epoch: 401 [16882/17352 (97%)] Loss: -789.877207\n",
      "    epoch          : 401\n",
      "    loss           : -747.8231501768355\n",
      "    val_loss       : -604.9509225766499\n",
      "    val_log_likelihood: 1016.9166289998287\n",
      "    val_log_marginal: 632.2979683332455\n",
      "Train Epoch: 402 [512/17352 (3%)] Loss: -813.123108\n",
      "Train Epoch: 402 [10550/17352 (61%)] Loss: -728.258247\n",
      "Train Epoch: 402 [16958/17352 (98%)] Loss: -860.807703\n",
      "    epoch          : 402\n",
      "    loss           : -765.7767423952668\n",
      "    val_loss       : -603.2523847027545\n",
      "    val_log_likelihood: 1020.3541692936908\n",
      "    val_log_marginal: 626.0301058329188\n",
      "Train Epoch: 403 [512/17352 (3%)] Loss: -804.256897\n",
      "Train Epoch: 403 [10295/17352 (59%)] Loss: -589.696423\n",
      "Train Epoch: 403 [16887/17352 (97%)] Loss: -807.038471\n",
      "    epoch          : 403\n",
      "    loss           : -728.809268447478\n",
      "    val_loss       : -587.0841268533821\n",
      "    val_log_likelihood: 1018.9864257759386\n",
      "    val_log_marginal: 604.9080131214427\n",
      "Train Epoch: 404 [512/17352 (3%)] Loss: -775.099243\n",
      "Train Epoch: 404 [10120/17352 (58%)] Loss: -841.780251\n",
      "Train Epoch: 404 [17253/17352 (99%)] Loss: -835.508883\n",
      "    epoch          : 404\n",
      "    loss           : -748.9410553623757\n",
      "    val_loss       : -581.0114108726902\n",
      "    val_log_likelihood: 1004.2111578753629\n",
      "    val_log_marginal: 610.589136471393\n",
      "Train Epoch: 405 [512/17352 (3%)] Loss: -794.588989\n",
      "Train Epoch: 405 [10434/17352 (60%)] Loss: -858.981646\n",
      "Train Epoch: 405 [17106/17352 (99%)] Loss: -673.042225\n",
      "    epoch          : 405\n",
      "    loss           : -762.879362692866\n",
      "    val_loss       : -582.5693690832819\n",
      "    val_log_likelihood: 1002.2349208234807\n",
      "    val_log_marginal: 607.1108891787167\n",
      "Train Epoch: 406 [512/17352 (3%)] Loss: -799.707825\n",
      "Train Epoch: 406 [10634/17352 (61%)] Loss: -582.211393\n",
      "Train Epoch: 406 [17124/17352 (99%)] Loss: -709.305377\n",
      "    epoch          : 406\n",
      "    loss           : -728.4786795784679\n",
      "    val_loss       : -568.6006997287926\n",
      "    val_log_likelihood: 987.222431076969\n",
      "    val_log_marginal: 605.6417770167384\n",
      "Train Epoch: 407 [512/17352 (3%)] Loss: -760.450806\n",
      "Train Epoch: 407 [10770/17352 (62%)] Loss: -576.648992\n",
      "Train Epoch: 407 [16992/17352 (98%)] Loss: -598.610504\n",
      "    epoch          : 407\n",
      "    loss           : -748.5263773288474\n",
      "    val_loss       : -595.589003700071\n",
      "    val_log_likelihood: 1009.4305392144408\n",
      "    val_log_marginal: 620.1966715233991\n",
      "Train Epoch: 408 [512/17352 (3%)] Loss: -783.022461\n",
      "Train Epoch: 408 [9633/17352 (56%)] Loss: -829.137992\n",
      "Train Epoch: 408 [17101/17352 (99%)] Loss: -875.415523\n",
      "    epoch          : 408\n",
      "    loss           : -765.2738277971633\n",
      "    val_loss       : -581.8506046443918\n",
      "    val_log_likelihood: 1013.5813234464222\n",
      "    val_log_marginal: 622.5310394623431\n",
      "Train Epoch: 409 [512/17352 (3%)] Loss: -784.383423\n",
      "Train Epoch: 409 [10748/17352 (62%)] Loss: -565.659946\n",
      "Train Epoch: 409 [16988/17352 (98%)] Loss: -643.658872\n",
      "    epoch          : 409\n",
      "    loss           : -746.8718099954615\n",
      "    val_loss       : -615.3716321252458\n",
      "    val_log_likelihood: 1026.923654368146\n",
      "    val_log_marginal: 644.5723982478587\n",
      "Train Epoch: 410 [512/17352 (3%)] Loss: -808.862732\n",
      "Train Epoch: 410 [10555/17352 (61%)] Loss: -711.327975\n",
      "Train Epoch: 410 [17108/17352 (99%)] Loss: -865.014355\n",
      "    epoch          : 410\n",
      "    loss           : -764.5195657520052\n",
      "    val_loss       : -606.992549974189\n",
      "    val_log_likelihood: 1021.0460635861037\n",
      "    val_log_marginal: 630.8689981724501\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0506_152815/checkpoint-epoch410.pth ...\n",
      "Train Epoch: 411 [512/17352 (3%)] Loss: -778.450073\n",
      "Train Epoch: 411 [10279/17352 (59%)] Loss: -675.547960\n",
      "Train Epoch: 411 [17064/17352 (98%)] Loss: -844.935533\n",
      "    epoch          : 411\n",
      "    loss           : -761.518502777072\n",
      "    val_loss       : -600.8595119158676\n",
      "    val_log_likelihood: 1026.0691948726585\n",
      "    val_log_marginal: 630.5367993971934\n",
      "Train Epoch: 412 [512/17352 (3%)] Loss: -791.682495\n",
      "Train Epoch: 412 [9608/17352 (55%)] Loss: -862.975484\n",
      "Train Epoch: 412 [17277/17352 (100%)] Loss: -850.584448\n",
      "    epoch          : 412\n",
      "    loss           : -772.7016127516347\n",
      "    val_loss       : -596.9380366878689\n",
      "    val_log_likelihood: 1025.212862587608\n",
      "    val_log_marginal: 622.9922341880414\n",
      "Train Epoch: 413 [512/17352 (3%)] Loss: -809.096069\n",
      "Train Epoch: 413 [10542/17352 (61%)] Loss: -834.654395\n",
      "Train Epoch: 413 [16883/17352 (97%)] Loss: -684.430323\n",
      "    epoch          : 413\n",
      "    loss           : -760.2819310780769\n",
      "    val_loss       : -616.6117056805518\n",
      "    val_log_likelihood: 1027.010065086931\n",
      "    val_log_marginal: 638.1578704858662\n",
      "Train Epoch: 414 [512/17352 (3%)] Loss: -804.157837\n",
      "Train Epoch: 414 [10877/17352 (63%)] Loss: -745.187919\n",
      "Train Epoch: 414 [17253/17352 (99%)] Loss: -862.217289\n",
      "    epoch          : 414\n",
      "    loss           : -766.4449730412407\n",
      "    val_loss       : -608.3949135025036\n",
      "    val_log_likelihood: 1021.3675747517676\n",
      "    val_log_marginal: 632.8878097805512\n",
      "Train Epoch: 415 [512/17352 (3%)] Loss: -782.396545\n",
      "Train Epoch: 415 [10482/17352 (60%)] Loss: -767.221240\n",
      "Train Epoch: 415 [17106/17352 (99%)] Loss: -652.177108\n",
      "    epoch          : 415\n",
      "    loss           : -786.1664022224367\n",
      "    val_loss       : -632.929669135054\n",
      "    val_log_likelihood: 1041.4315501982194\n",
      "    val_log_marginal: 663.9557115847452\n",
      "Train Epoch: 416 [512/17352 (3%)] Loss: -841.075073\n",
      "Train Epoch: 416 [10705/17352 (62%)] Loss: -876.964705\n",
      "Train Epoch: 416 [16988/17352 (98%)] Loss: -736.304167\n",
      "    epoch          : 416\n",
      "    loss           : -792.870398597648\n",
      "    val_loss       : -625.3617767185212\n",
      "    val_log_likelihood: 1040.5001554851328\n",
      "    val_log_marginal: 657.2049955088474\n",
      "Train Epoch: 417 [512/17352 (3%)] Loss: -839.086182\n",
      "Train Epoch: 417 [9928/17352 (57%)] Loss: -805.642195\n",
      "Train Epoch: 417 [16958/17352 (98%)] Loss: -770.456342\n",
      "    epoch          : 417\n",
      "    loss           : -780.925139263967\n",
      "    val_loss       : -600.2372621278064\n",
      "    val_log_likelihood: 1028.0928507962967\n",
      "    val_log_marginal: 640.5717239805508\n",
      "Train Epoch: 418 [512/17352 (3%)] Loss: -833.069275\n",
      "Train Epoch: 418 [9976/17352 (57%)] Loss: -702.243536\n",
      "Train Epoch: 418 [16958/17352 (98%)] Loss: -705.912744\n",
      "    epoch          : 418\n",
      "    loss           : -766.8311328672405\n",
      "    val_loss       : -612.6799593025561\n",
      "    val_log_likelihood: 1037.8082218350157\n",
      "    val_log_marginal: 651.0601609655296\n",
      "Train Epoch: 419 [512/17352 (3%)] Loss: -836.538879\n",
      "Train Epoch: 419 [10131/17352 (58%)] Loss: -725.720982\n",
      "Train Epoch: 419 [16958/17352 (98%)] Loss: -773.105013\n",
      "    epoch          : 419\n",
      "    loss           : -747.6744966939846\n",
      "    val_loss       : -584.3621765254044\n",
      "    val_log_likelihood: 1016.6180789952115\n",
      "    val_log_marginal: 613.3762694304652\n",
      "Train Epoch: 420 [512/17352 (3%)] Loss: -787.339233\n",
      "Train Epoch: 420 [10367/17352 (60%)] Loss: -579.681183\n",
      "Train Epoch: 420 [16872/17352 (97%)] Loss: -793.147254\n",
      "    epoch          : 420\n",
      "    loss           : -731.5678570659635\n",
      "    val_loss       : -610.3843283250587\n",
      "    val_log_likelihood: 1040.4259107487528\n",
      "    val_log_marginal: 646.262571972133\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0506_152815/checkpoint-epoch420.pth ...\n",
      "Train Epoch: 421 [512/17352 (3%)] Loss: -820.154358\n",
      "Train Epoch: 421 [10382/17352 (60%)] Loss: -683.574631\n",
      "Train Epoch: 421 [17253/17352 (99%)] Loss: -872.022170\n",
      "    epoch          : 421\n",
      "    loss           : -757.1116443183168\n",
      "    val_loss       : -541.9758298806086\n",
      "    val_log_likelihood: 1019.9584088274893\n",
      "    val_log_marginal: 562.8724019806937\n",
      "Train Epoch: 422 [512/17352 (3%)] Loss: -728.448242\n",
      "Train Epoch: 422 [10434/17352 (60%)] Loss: -672.399821\n",
      "Train Epoch: 422 [17133/17352 (99%)] Loss: -844.405170\n",
      "    epoch          : 422\n",
      "    loss           : -739.0787475550544\n",
      "    val_loss       : -538.7417995055052\n",
      "    val_log_likelihood: 1013.4493413238141\n",
      "    val_log_marginal: 573.4953138655495\n",
      "Train Epoch: 423 [512/17352 (3%)] Loss: -734.560181\n",
      "Train Epoch: 423 [10341/17352 (60%)] Loss: -820.819874\n",
      "Train Epoch: 423 [17253/17352 (99%)] Loss: -508.503754\n",
      "    epoch          : 423\n",
      "    loss           : -686.1570067984562\n",
      "    val_loss       : -214.52058646717876\n",
      "    val_log_likelihood: 978.0722616418578\n",
      "    val_log_marginal: 284.10125198430944\n",
      "Train Epoch: 424 [512/17352 (3%)] Loss: -459.824768\n",
      "Train Epoch: 424 [10666/17352 (61%)] Loss: -778.462087\n",
      "Train Epoch: 424 [17090/17352 (98%)] Loss: -665.932632\n",
      "    epoch          : 424\n",
      "    loss           : -637.7616327528694\n",
      "    val_loss       : -556.0077368357913\n",
      "    val_log_likelihood: 1015.6818799471423\n",
      "    val_log_marginal: 596.9456821253425\n",
      "Train Epoch: 425 [512/17352 (3%)] Loss: -764.299255\n",
      "Train Epoch: 425 [10248/17352 (59%)] Loss: -736.704432\n",
      "Train Epoch: 425 [16923/17352 (98%)] Loss: -765.056329\n",
      "    epoch          : 425\n",
      "    loss           : -725.7752381061412\n",
      "    val_loss       : -450.39869075987644\n",
      "    val_log_likelihood: 1004.787216811605\n",
      "    val_log_marginal: 475.25132577162907\n",
      "Train Epoch: 426 [512/17352 (3%)] Loss: -633.505981\n",
      "Train Epoch: 426 [9813/17352 (57%)] Loss: -371.389255\n",
      "Train Epoch: 426 [16922/17352 (98%)] Loss: -568.749751\n",
      "    epoch          : 426\n",
      "    loss           : -307.1572152023189\n",
      "    val_loss       : -62.041318736475894\n",
      "    val_log_likelihood: 901.0836829183678\n",
      "    val_log_marginal: 159.10606759971898\n",
      "Train Epoch: 427 [512/17352 (3%)] Loss: -23.140968\n",
      "Train Epoch: 427 [10544/17352 (61%)] Loss: -708.960938\n",
      "Train Epoch: 427 [16887/17352 (97%)] Loss: -297.381721\n",
      "    epoch          : 427\n",
      "    loss           : -209.7554810938025\n",
      "    val_loss       : -430.32677818858684\n",
      "    val_log_likelihood: 932.7675193171324\n",
      "    val_log_marginal: 471.6046751964703\n",
      "Train Epoch: 428 [512/17352 (3%)] Loss: -627.441711\n",
      "Train Epoch: 428 [10506/17352 (61%)] Loss: -678.596882\n",
      "Train Epoch: 428 [17016/17352 (98%)] Loss: -550.806818\n",
      "    epoch          : 428\n",
      "    loss           : -572.944518704276\n",
      "    val_loss       : -560.1512168797083\n",
      "    val_log_likelihood: 980.4898440064927\n",
      "    val_log_marginal: 602.2847880933294\n",
      "Train Epoch: 429 [512/17352 (3%)] Loss: -759.515015\n",
      "Train Epoch: 429 [10833/17352 (62%)] Loss: -837.225213\n",
      "Train Epoch: 429 [17101/17352 (99%)] Loss: -737.410417\n",
      "    epoch          : 429\n",
      "    loss           : -719.9730748594673\n",
      "    val_loss       : -606.6377531184833\n",
      "    val_log_likelihood: 1008.3462507778049\n",
      "    val_log_marginal: 632.7517152693622\n",
      "Train Epoch: 430 [512/17352 (3%)] Loss: -780.768616\n",
      "Train Epoch: 430 [10399/17352 (60%)] Loss: -607.551644\n",
      "Train Epoch: 430 [16988/17352 (98%)] Loss: -789.462079\n",
      "    epoch          : 430\n",
      "    loss           : -747.7560614139562\n",
      "    val_loss       : -603.6229731154725\n",
      "    val_log_likelihood: 993.7415926406853\n",
      "    val_log_marginal: 639.5497866395043\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0506_152815/checkpoint-epoch430.pth ...\n",
      "Train Epoch: 431 [512/17352 (3%)] Loss: -811.908752\n",
      "Train Epoch: 431 [9896/17352 (57%)] Loss: -638.638387\n",
      "Train Epoch: 431 [16923/17352 (98%)] Loss: -700.340554\n",
      "    epoch          : 431\n",
      "    loss           : -727.8558657048209\n",
      "    val_loss       : -605.7195044463338\n",
      "    val_log_likelihood: 1000.6503965834946\n",
      "    val_log_marginal: 644.0019758834621\n",
      "Train Epoch: 432 [512/17352 (3%)] Loss: -805.711914\n",
      "Train Epoch: 432 [10269/17352 (59%)] Loss: -744.007812\n",
      "Train Epoch: 432 [16882/17352 (97%)] Loss: -721.296415\n",
      "    epoch          : 432\n",
      "    loss           : -761.8200671252633\n",
      "    val_loss       : -636.0403120372625\n",
      "    val_log_likelihood: 1021.1961474531814\n",
      "    val_log_marginal: 659.5113237001161\n",
      "Train Epoch: 433 [512/17352 (3%)] Loss: -806.390076\n",
      "Train Epoch: 433 [10667/17352 (61%)] Loss: -868.186441\n",
      "Train Epoch: 433 [17126/17352 (99%)] Loss: -621.724059\n",
      "    epoch          : 433\n",
      "    loss           : -771.5482908844536\n",
      "    val_loss       : -632.0358076065515\n",
      "    val_log_likelihood: 1025.3233786056874\n",
      "    val_log_marginal: 662.0151186901783\n",
      "Train Epoch: 434 [512/17352 (3%)] Loss: -811.819702\n",
      "Train Epoch: 434 [10305/17352 (59%)] Loss: -655.212048\n",
      "Train Epoch: 434 [16887/17352 (97%)] Loss: -880.950711\n",
      "    epoch          : 434\n",
      "    loss           : -769.402424175658\n",
      "    val_loss       : -639.5398790316829\n",
      "    val_log_likelihood: 1027.4020969805774\n",
      "    val_log_marginal: 669.7334521648893\n",
      "Train Epoch: 435 [512/17352 (3%)] Loss: -832.728455\n",
      "Train Epoch: 435 [10103/17352 (58%)] Loss: -717.593118\n",
      "Train Epoch: 435 [17133/17352 (99%)] Loss: -833.511354\n",
      "    epoch          : 435\n",
      "    loss           : -748.4963148755883\n",
      "    val_loss       : -603.391192986957\n",
      "    val_log_likelihood: 1007.7110557634458\n",
      "    val_log_marginal: 631.2551831766707\n",
      "Train Epoch: 436 [512/17352 (3%)] Loss: -808.260620\n",
      "Train Epoch: 436 [10198/17352 (59%)] Loss: -871.257263\n",
      "Train Epoch: 436 [16939/17352 (98%)] Loss: -887.597624\n",
      "    epoch          : 436\n",
      "    loss           : -775.0924893934093\n",
      "    val_loss       : -629.0682964771132\n",
      "    val_log_likelihood: 1025.4428473219457\n",
      "    val_log_marginal: 661.2983360759487\n",
      "Train Epoch: 437 [512/17352 (3%)] Loss: -818.835327\n",
      "Train Epoch: 437 [10579/17352 (61%)] Loss: -838.563151\n",
      "Train Epoch: 437 [16887/17352 (97%)] Loss: -896.106538\n",
      "    epoch          : 437\n",
      "    loss           : -794.375742927082\n",
      "    val_loss       : -651.1599515970279\n",
      "    val_log_likelihood: 1044.0132498800365\n",
      "    val_log_marginal: 673.8740833512113\n",
      "Train Epoch: 438 [512/17352 (3%)] Loss: -851.927856\n",
      "Train Epoch: 438 [9583/17352 (55%)] Loss: -711.120290\n",
      "Train Epoch: 438 [16923/17352 (98%)] Loss: -704.765904\n",
      "    epoch          : 438\n",
      "    loss           : -795.7501985179067\n",
      "    val_loss       : -630.9965979607663\n",
      "    val_log_likelihood: 1036.0483470574184\n",
      "    val_log_marginal: 667.0400432990771\n",
      "Train Epoch: 439 [512/17352 (3%)] Loss: -845.976501\n",
      "Train Epoch: 439 [10350/17352 (60%)] Loss: -892.399468\n",
      "Train Epoch: 439 [16878/17352 (97%)] Loss: -738.381250\n",
      "    epoch          : 439\n",
      "    loss           : -795.4377586884192\n",
      "    val_loss       : -638.2070788673262\n",
      "    val_log_likelihood: 1045.9924751908686\n",
      "    val_log_marginal: 670.595861483632\n",
      "Train Epoch: 440 [512/17352 (3%)] Loss: -849.935303\n",
      "Train Epoch: 440 [10263/17352 (59%)] Loss: -666.431818\n",
      "Train Epoch: 440 [17049/17352 (98%)] Loss: -857.877809\n",
      "    epoch          : 440\n",
      "    loss           : -802.637433659742\n",
      "    val_loss       : -640.4015669776091\n",
      "    val_log_likelihood: 1040.6272708671731\n",
      "    val_log_marginal: 667.5889886562469\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0506_152815/checkpoint-epoch440.pth ...\n",
      "Train Epoch: 441 [512/17352 (3%)] Loss: -848.305359\n",
      "Train Epoch: 441 [9624/17352 (55%)] Loss: -704.375897\n",
      "Train Epoch: 441 [16878/17352 (97%)] Loss: -788.223958\n",
      "    epoch          : 441\n",
      "    loss           : -799.1489953266513\n",
      "    val_loss       : -658.9531833764993\n",
      "    val_log_likelihood: 1054.6305782907455\n",
      "    val_log_marginal: 676.3612471338973\n",
      "Train Epoch: 442 [512/17352 (3%)] Loss: -845.909424\n",
      "Train Epoch: 442 [10313/17352 (59%)] Loss: -864.396979\n",
      "Train Epoch: 442 [16872/17352 (97%)] Loss: -662.594220\n",
      "    epoch          : 442\n",
      "    loss           : -796.0101182531688\n",
      "    val_loss       : -631.3917058609845\n",
      "    val_log_likelihood: 1041.967109842082\n",
      "    val_log_marginal: 659.3808093581619\n",
      "Train Epoch: 443 [512/17352 (3%)] Loss: -855.129395\n",
      "Train Epoch: 443 [10382/17352 (60%)] Loss: -753.408139\n",
      "Train Epoch: 443 [17153/17352 (99%)] Loss: -703.950435\n",
      "    epoch          : 443\n",
      "    loss           : -736.723504498417\n",
      "    val_loss       : -536.3202171600442\n",
      "    val_log_likelihood: 1018.0449894135726\n",
      "    val_log_marginal: 634.4684199041843\n",
      "Train Epoch: 444 [512/17352 (3%)] Loss: -699.972534\n",
      "Train Epoch: 444 [9707/17352 (56%)] Loss: -855.226054\n",
      "Train Epoch: 444 [17124/17352 (99%)] Loss: -893.681424\n",
      "    epoch          : 444\n",
      "    loss           : -731.3947508940028\n",
      "    val_loss       : -569.9879724055401\n",
      "    val_log_likelihood: 1012.0631710532161\n",
      "    val_log_marginal: 601.8358612685839\n",
      "Train Epoch: 445 [512/17352 (3%)] Loss: -752.874878\n",
      "Train Epoch: 445 [10235/17352 (59%)] Loss: -593.729509\n",
      "Train Epoch: 445 [17016/17352 (98%)] Loss: -835.052401\n",
      "    epoch          : 445\n",
      "    loss           : -711.1412380396196\n",
      "    val_loss       : -576.8482683267854\n",
      "    val_log_likelihood: 1012.9933126849741\n",
      "    val_log_marginal: 618.0719665776614\n",
      "Train Epoch: 446 [512/17352 (3%)] Loss: -762.376587\n",
      "Train Epoch: 446 [10077/17352 (58%)] Loss: -862.439724\n",
      "Train Epoch: 446 [17108/17352 (99%)] Loss: -788.692065\n",
      "    epoch          : 446\n",
      "    loss           : -724.6360998151487\n",
      "    val_loss       : -469.91315719618365\n",
      "    val_log_likelihood: 1020.6694823141984\n",
      "    val_log_marginal: 509.84251276614975\n",
      "Train Epoch: 447 [512/17352 (3%)] Loss: -692.062622\n",
      "Train Epoch: 447 [10463/17352 (60%)] Loss: -837.258861\n",
      "Train Epoch: 447 [16878/17352 (97%)] Loss: -811.125391\n",
      "    epoch          : 447\n",
      "    loss           : -729.7236888841944\n",
      "    val_loss       : -603.7523094318328\n",
      "    val_log_likelihood: 1031.5533691919343\n",
      "    val_log_marginal: 629.299931345086\n",
      "Train Epoch: 448 [512/17352 (3%)] Loss: -799.168518\n",
      "Train Epoch: 448 [10785/17352 (62%)] Loss: -707.302611\n",
      "Train Epoch: 448 [17263/17352 (99%)] Loss: -573.864785\n",
      "    epoch          : 448\n",
      "    loss           : -784.2339795453263\n",
      "    val_loss       : -638.5055755844983\n",
      "    val_log_likelihood: 1039.1688040065567\n",
      "    val_log_marginal: 660.8633930373838\n",
      "Train Epoch: 449 [512/17352 (3%)] Loss: -845.784546\n",
      "Train Epoch: 449 [10690/17352 (62%)] Loss: -792.477597\n",
      "Train Epoch: 449 [17064/17352 (98%)] Loss: -835.074062\n",
      "    epoch          : 449\n",
      "    loss           : -778.516863001858\n",
      "    val_loss       : -605.7139617363323\n",
      "    val_log_likelihood: 1029.1193434093323\n",
      "    val_log_marginal: 641.1409944015902\n",
      "Train Epoch: 450 [512/17352 (3%)] Loss: -805.197021\n",
      "Train Epoch: 450 [10025/17352 (58%)] Loss: -738.669643\n",
      "Train Epoch: 450 [16878/17352 (97%)] Loss: -560.943791\n",
      "    epoch          : 450\n",
      "    loss           : -765.6217631791192\n",
      "    val_loss       : -629.6181876401205\n",
      "    val_log_likelihood: 1030.8519283917035\n",
      "    val_log_marginal: 657.5787160917276\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0506_152815/checkpoint-epoch450.pth ...\n",
      "Train Epoch: 451 [512/17352 (3%)] Loss: -825.257812\n",
      "Train Epoch: 451 [10094/17352 (58%)] Loss: -883.836903\n",
      "Train Epoch: 451 [17108/17352 (99%)] Loss: -847.895481\n",
      "    epoch          : 451\n",
      "    loss           : -795.7326138888315\n",
      "    val_loss       : -631.5029210531532\n",
      "    val_log_likelihood: 1046.2141915026784\n",
      "    val_log_marginal: 668.7660077253905\n",
      "Train Epoch: 452 [512/17352 (3%)] Loss: -842.863464\n",
      "Train Epoch: 452 [10892/17352 (63%)] Loss: -723.210443\n",
      "Train Epoch: 452 [17049/17352 (98%)] Loss: -709.199980\n",
      "    epoch          : 452\n",
      "    loss           : -791.0120909954527\n",
      "    val_loss       : -624.7887842693058\n",
      "    val_log_likelihood: 1045.021986776038\n",
      "    val_log_marginal: 652.2064706948452\n",
      "Train Epoch: 453 [512/17352 (3%)] Loss: -839.242432\n",
      "Train Epoch: 453 [10742/17352 (62%)] Loss: -736.981878\n",
      "Train Epoch: 453 [17253/17352 (99%)] Loss: -797.887191\n",
      "    epoch          : 453\n",
      "    loss           : -800.8129584044146\n",
      "    val_loss       : -626.7950434596471\n",
      "    val_log_likelihood: 1056.5832130490394\n",
      "    val_log_marginal: 647.9251111082918\n",
      "Train Epoch: 454 [512/17352 (3%)] Loss: -830.872559\n",
      "Train Epoch: 454 [10861/17352 (63%)] Loss: -678.395251\n",
      "Train Epoch: 454 [16878/17352 (97%)] Loss: -859.160417\n",
      "    epoch          : 454\n",
      "    loss           : -804.4206944787967\n",
      "    val_loss       : -649.3432394311926\n",
      "    val_log_likelihood: 1056.7918557527755\n",
      "    val_log_marginal: 670.4789785583216\n",
      "Train Epoch: 455 [512/17352 (3%)] Loss: -865.140564\n",
      "Train Epoch: 455 [10434/17352 (60%)] Loss: -870.570344\n",
      "Train Epoch: 455 [17044/17352 (98%)] Loss: -814.187500\n",
      "    epoch          : 455\n",
      "    loss           : -812.5661663386944\n",
      "    val_loss       : -640.7649120182341\n",
      "    val_log_likelihood: 1050.4398036206992\n",
      "    val_log_marginal: 661.34750158985\n",
      "Train Epoch: 456 [512/17352 (3%)] Loss: -852.076843\n",
      "Train Epoch: 456 [10592/17352 (61%)] Loss: -902.622523\n",
      "Train Epoch: 456 [17090/17352 (98%)] Loss: -859.807082\n",
      "    epoch          : 456\n",
      "    loss           : -806.5166623435646\n",
      "    val_loss       : -633.9513589818755\n",
      "    val_log_likelihood: 1053.629851504937\n",
      "    val_log_marginal: 662.5309776208032\n",
      "Train Epoch: 457 [512/17352 (3%)] Loss: -847.634277\n",
      "Train Epoch: 457 [9727/17352 (56%)] Loss: -906.483378\n",
      "Train Epoch: 457 [16958/17352 (98%)] Loss: -855.400911\n",
      "    epoch          : 457\n",
      "    loss           : -806.2788790817536\n",
      "    val_loss       : -630.4931310484798\n",
      "    val_log_likelihood: 1057.5313471812713\n",
      "    val_log_marginal: 662.9195226516825\n",
      "Train Epoch: 458 [512/17352 (3%)] Loss: -854.468994\n",
      "Train Epoch: 458 [9870/17352 (57%)] Loss: -859.579479\n",
      "Train Epoch: 458 [16939/17352 (98%)] Loss: -849.570195\n",
      "    epoch          : 458\n",
      "    loss           : -811.3004102079236\n",
      "    val_loss       : -641.2279406769802\n",
      "    val_log_likelihood: 1060.2663995821194\n",
      "    val_log_marginal: 664.7334647656056\n",
      "Train Epoch: 459 [512/17352 (3%)] Loss: -866.078308\n",
      "Train Epoch: 459 [10089/17352 (58%)] Loss: -725.946657\n",
      "Train Epoch: 459 [16922/17352 (98%)] Loss: 1313.062658\n",
      "    epoch          : 459\n",
      "    loss           : 365.17966019325837\n",
      "    val_loss       : 327.35190440891984\n",
      "    val_log_likelihood: 698.8198946204317\n",
      "    val_log_marginal: -229.55008050433693\n",
      "Train Epoch: 460 [512/17352 (3%)] Loss: 561.424316\n",
      "Train Epoch: 460 [10515/17352 (61%)] Loss: -386.019875\n",
      "Train Epoch: 460 [16957/17352 (98%)] Loss: -550.400493\n",
      "    epoch          : 460\n",
      "    loss           : -337.10002592227397\n",
      "    val_loss       : -466.4657182396733\n",
      "    val_log_likelihood: 914.0500586153387\n",
      "    val_log_marginal: 504.418005816663\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0506_152815/checkpoint-epoch460.pth ...\n",
      "Train Epoch: 461 [512/17352 (3%)] Loss: -689.852051\n",
      "Train Epoch: 461 [9856/17352 (57%)] Loss: -768.664326\n",
      "Train Epoch: 461 [17277/17352 (100%)] Loss: -786.273378\n",
      "    epoch          : 461\n",
      "    loss           : -689.0043908582734\n",
      "    val_loss       : -567.690547132637\n",
      "    val_log_likelihood: 992.4976606633268\n",
      "    val_log_marginal: 602.1361559005579\n",
      "Train Epoch: 462 [512/17352 (3%)] Loss: -764.404846\n",
      "Train Epoch: 462 [10489/17352 (60%)] Loss: -814.023438\n",
      "Train Epoch: 462 [16958/17352 (98%)] Loss: -860.013469\n",
      "    epoch          : 462\n",
      "    loss           : -751.690303134152\n",
      "    val_loss       : -615.4463064486337\n",
      "    val_log_likelihood: 1014.183719892278\n",
      "    val_log_marginal: 638.9798423989971\n",
      "Train Epoch: 463 [512/17352 (3%)] Loss: -800.616211\n",
      "Train Epoch: 463 [9940/17352 (57%)] Loss: -722.797569\n",
      "Train Epoch: 463 [16922/17352 (98%)] Loss: -706.172323\n",
      "    epoch          : 463\n",
      "    loss           : -777.3829898606172\n",
      "    val_loss       : -645.9477987004304\n",
      "    val_log_likelihood: 1030.3749053402817\n",
      "    val_log_marginal: 674.9805907547573\n",
      "Train Epoch: 464 [512/17352 (3%)] Loss: -820.074341\n",
      "Train Epoch: 464 [10387/17352 (60%)] Loss: -823.623548\n",
      "Train Epoch: 464 [16958/17352 (98%)] Loss: -881.692764\n",
      "    epoch          : 464\n",
      "    loss           : -778.2536350747478\n",
      "    val_loss       : -635.420868970287\n",
      "    val_log_likelihood: 1025.0024886772126\n",
      "    val_log_marginal: 666.3433162570134\n",
      "Train Epoch: 465 [512/17352 (3%)] Loss: -820.021973\n",
      "Train Epoch: 465 [10361/17352 (60%)] Loss: -659.663737\n",
      "Train Epoch: 465 [16878/17352 (97%)] Loss: -777.565036\n",
      "    epoch          : 465\n",
      "    loss           : -778.5285333693411\n",
      "    val_loss       : -639.8149579952393\n",
      "    val_log_likelihood: 1038.1491380753237\n",
      "    val_log_marginal: 656.3022004104305\n",
      "Train Epoch: 466 [512/17352 (3%)] Loss: -831.995178\n",
      "Train Epoch: 466 [10477/17352 (60%)] Loss: -834.589541\n",
      "Train Epoch: 466 [17143/17352 (99%)] Loss: -850.364729\n",
      "    epoch          : 466\n",
      "    loss           : -789.022001499604\n",
      "    val_loss       : -646.4832756311885\n",
      "    val_log_likelihood: 1043.818935166882\n",
      "    val_log_marginal: 670.2079528865348\n",
      "Train Epoch: 467 [512/17352 (3%)] Loss: -841.295105\n",
      "Train Epoch: 467 [10270/17352 (59%)] Loss: -794.552964\n",
      "Train Epoch: 467 [16957/17352 (98%)] Loss: -807.986242\n",
      "    epoch          : 467\n",
      "    loss           : -802.1279193295301\n",
      "    val_loss       : -653.7580123405608\n",
      "    val_log_likelihood: 1045.1128392947878\n",
      "    val_log_marginal: 675.9888209223235\n",
      "Train Epoch: 468 [512/17352 (3%)] Loss: -857.954346\n",
      "Train Epoch: 468 [10269/17352 (59%)] Loss: -769.797423\n",
      "Train Epoch: 468 [17153/17352 (99%)] Loss: -921.744575\n",
      "    epoch          : 468\n",
      "    loss           : -803.3869374990525\n",
      "    val_loss       : -646.094380353759\n",
      "    val_log_likelihood: 1046.5668605495273\n",
      "    val_log_marginal: 663.4604363559895\n",
      "Train Epoch: 469 [512/17352 (3%)] Loss: -849.234558\n",
      "Train Epoch: 469 [9988/17352 (58%)] Loss: -856.287273\n",
      "Train Epoch: 469 [17277/17352 (100%)] Loss: -806.137105\n",
      "    epoch          : 469\n",
      "    loss           : -810.4237838324912\n",
      "    val_loss       : -663.4541025020621\n",
      "    val_log_likelihood: 1058.6494607664938\n",
      "    val_log_marginal: 683.8982822992839\n",
      "Train Epoch: 470 [512/17352 (3%)] Loss: -831.874207\n",
      "Train Epoch: 470 [10545/17352 (61%)] Loss: -795.798420\n",
      "Train Epoch: 470 [16922/17352 (98%)] Loss: -894.078191\n",
      "    epoch          : 470\n",
      "    loss           : -809.7854536043556\n",
      "    val_loss       : -655.1317879956417\n",
      "    val_log_likelihood: 1058.983752785006\n",
      "    val_log_marginal: 678.8832831974123\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0506_152815/checkpoint-epoch470.pth ...\n",
      "Train Epoch: 471 [512/17352 (3%)] Loss: -854.596802\n",
      "Train Epoch: 471 [10687/17352 (62%)] Loss: -853.160612\n",
      "Train Epoch: 471 [16958/17352 (98%)] Loss: -851.803097\n",
      "    epoch          : 471\n",
      "    loss           : -818.21757151571\n",
      "    val_loss       : -655.3136287268119\n",
      "    val_log_likelihood: 1060.0941486650916\n",
      "    val_log_marginal: 677.2442423999056\n",
      "Train Epoch: 472 [512/17352 (3%)] Loss: -866.821289\n",
      "Train Epoch: 472 [10466/17352 (60%)] Loss: -761.188525\n",
      "Train Epoch: 472 [17143/17352 (99%)] Loss: -758.907738\n",
      "    epoch          : 472\n",
      "    loss           : -818.1586511544381\n",
      "    val_loss       : -641.5712512367248\n",
      "    val_log_likelihood: 1062.6273914784197\n",
      "    val_log_marginal: 671.1738079043741\n",
      "Train Epoch: 473 [512/17352 (3%)] Loss: -837.264221\n",
      "Train Epoch: 473 [10527/17352 (61%)] Loss: -811.944129\n",
      "Train Epoch: 473 [17101/17352 (99%)] Loss: -871.872813\n",
      "    epoch          : 473\n",
      "    loss           : -807.7762810709376\n",
      "    val_loss       : -640.7488773335502\n",
      "    val_log_likelihood: 1058.6062816787778\n",
      "    val_log_marginal: 663.9115828884615\n",
      "Train Epoch: 474 [512/17352 (3%)] Loss: -868.697205\n",
      "Train Epoch: 474 [10261/17352 (59%)] Loss: -764.965799\n",
      "Train Epoch: 474 [16883/17352 (97%)] Loss: -730.769683\n",
      "    epoch          : 474\n",
      "    loss           : -808.1570771610527\n",
      "    val_loss       : -648.9659727174223\n",
      "    val_log_likelihood: 1057.5993627830512\n",
      "    val_log_marginal: 679.4248039645198\n",
      "Train Epoch: 475 [512/17352 (3%)] Loss: -851.927368\n",
      "Train Epoch: 475 [10276/17352 (59%)] Loss: -847.413160\n",
      "Train Epoch: 475 [16882/17352 (97%)] Loss: -836.738490\n",
      "    epoch          : 475\n",
      "    loss           : -816.3900670193309\n",
      "    val_loss       : -656.2913871293061\n",
      "    val_log_likelihood: 1060.7754083050872\n",
      "    val_log_marginal: 670.2006264505337\n",
      "Train Epoch: 476 [512/17352 (3%)] Loss: -869.745972\n",
      "Train Epoch: 476 [10042/17352 (58%)] Loss: -918.198361\n",
      "Train Epoch: 476 [16887/17352 (97%)] Loss: -852.953910\n",
      "    epoch          : 476\n",
      "    loss           : -824.1265433557945\n",
      "    val_loss       : -657.0916574539399\n",
      "    val_log_likelihood: 1070.9551258543218\n",
      "    val_log_marginal: 682.8469384505592\n",
      "Train Epoch: 477 [512/17352 (3%)] Loss: -851.093567\n",
      "Train Epoch: 477 [10243/17352 (59%)] Loss: -850.481784\n",
      "Train Epoch: 477 [16887/17352 (97%)] Loss: -796.005580\n",
      "    epoch          : 477\n",
      "    loss           : -819.8569513174856\n",
      "    val_loss       : -656.7885448755875\n",
      "    val_log_likelihood: 1072.127716019069\n",
      "    val_log_marginal: 681.8713791655377\n",
      "Train Epoch: 478 [512/17352 (3%)] Loss: -832.802368\n",
      "Train Epoch: 478 [10479/17352 (60%)] Loss: -751.225211\n",
      "Train Epoch: 478 [16882/17352 (97%)] Loss: -905.171994\n",
      "    epoch          : 478\n",
      "    loss           : -825.2737946347778\n",
      "    val_loss       : -665.5680282083565\n",
      "    val_log_likelihood: 1077.7079583996158\n",
      "    val_log_marginal: 687.2348533769934\n",
      "Train Epoch: 479 [512/17352 (3%)] Loss: -873.864746\n",
      "Train Epoch: 479 [10499/17352 (61%)] Loss: -786.273958\n",
      "Train Epoch: 479 [17335/17352 (100%)] Loss: -685.432258\n",
      "    epoch          : 479\n",
      "    loss           : -832.282837048008\n",
      "    val_loss       : -652.2330341508721\n",
      "    val_log_likelihood: 1075.5255918364758\n",
      "    val_log_marginal: 676.3183911350072\n",
      "Train Epoch: 480 [512/17352 (3%)] Loss: -711.911133\n",
      "Train Epoch: 480 [10380/17352 (60%)] Loss: -852.745825\n",
      "Train Epoch: 480 [16923/17352 (98%)] Loss: -926.943697\n",
      "    epoch          : 480\n",
      "    loss           : -831.0651651072504\n",
      "    val_loss       : -650.053217829296\n",
      "    val_log_likelihood: 1075.6304852266658\n",
      "    val_log_marginal: 676.5668089438166\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0506_152815/checkpoint-epoch480.pth ...\n",
      "Train Epoch: 481 [512/17352 (3%)] Loss: -855.217468\n",
      "Train Epoch: 481 [10872/17352 (63%)] Loss: -911.189715\n",
      "Train Epoch: 481 [17126/17352 (99%)] Loss: -935.470416\n",
      "    epoch          : 481\n",
      "    loss           : -832.8150756978446\n",
      "    val_loss       : -659.9174722435581\n",
      "    val_log_likelihood: 1068.5677763801557\n",
      "    val_log_marginal: 675.4290817971912\n",
      "Train Epoch: 482 [512/17352 (3%)] Loss: -867.516418\n",
      "Train Epoch: 482 [9996/17352 (58%)] Loss: -783.304061\n",
      "Train Epoch: 482 [17253/17352 (99%)] Loss: -754.294034\n",
      "    epoch          : 482\n",
      "    loss           : -835.9606818899362\n",
      "    val_loss       : -640.5547258155963\n",
      "    val_log_likelihood: 1067.2967755044078\n",
      "    val_log_marginal: 664.080910446739\n",
      "Train Epoch: 483 [512/17352 (3%)] Loss: -855.318970\n",
      "Train Epoch: 483 [10600/17352 (61%)] Loss: -714.959645\n",
      "Train Epoch: 483 [17090/17352 (98%)] Loss: -925.166311\n",
      "    epoch          : 483\n",
      "    loss           : -820.9200624594479\n",
      "    val_loss       : -641.9069971109283\n",
      "    val_log_likelihood: 1067.7364863748433\n",
      "    val_log_marginal: 662.5835855264166\n",
      "Train Epoch: 484 [512/17352 (3%)] Loss: -861.984070\n",
      "Train Epoch: 484 [10220/17352 (59%)] Loss: -677.573415\n",
      "Train Epoch: 484 [17143/17352 (99%)] Loss: -959.437717\n",
      "    epoch          : 484\n",
      "    loss           : -828.5391990720507\n",
      "    val_loss       : -648.5996391072835\n",
      "    val_log_likelihood: 1072.043624289668\n",
      "    val_log_marginal: 672.0577616618219\n",
      "Train Epoch: 485 [512/17352 (3%)] Loss: -846.876221\n",
      "Train Epoch: 485 [10514/17352 (61%)] Loss: -803.816886\n",
      "Train Epoch: 485 [17106/17352 (99%)] Loss: -926.239028\n",
      "    epoch          : 485\n",
      "    loss           : -824.6603408099032\n",
      "    val_loss       : -609.4332779312888\n",
      "    val_log_likelihood: 1048.6900094908779\n",
      "    val_log_marginal: 634.3208298362271\n",
      "Train Epoch: 486 [512/17352 (3%)] Loss: -820.039734\n",
      "Train Epoch: 486 [10432/17352 (60%)] Loss: -674.955807\n",
      "Train Epoch: 486 [16878/17352 (97%)] Loss: -827.928056\n",
      "    epoch          : 486\n",
      "    loss           : -815.2846472027086\n",
      "    val_loss       : -630.8252626175015\n",
      "    val_log_likelihood: 1077.7792565281593\n",
      "    val_log_marginal: 675.0633979401691\n",
      "Train Epoch: 487 [512/17352 (3%)] Loss: -884.148682\n",
      "Train Epoch: 487 [10327/17352 (60%)] Loss: -692.055229\n",
      "Train Epoch: 487 [17335/17352 (100%)] Loss: -868.404837\n",
      "    epoch          : 487\n",
      "    loss           : -814.6954167500635\n",
      "    val_loss       : -641.1499002242509\n",
      "    val_log_likelihood: 1078.6871744979196\n",
      "    val_log_marginal: 663.9854229357576\n",
      "Train Epoch: 488 [512/17352 (3%)] Loss: -870.060913\n",
      "Train Epoch: 488 [10827/17352 (62%)] Loss: -902.967563\n",
      "Train Epoch: 488 [17108/17352 (99%)] Loss: -709.572698\n",
      "    epoch          : 488\n",
      "    loss           : -833.1960558012992\n",
      "    val_loss       : -622.1287700696905\n",
      "    val_log_likelihood: 1077.5658686168233\n",
      "    val_log_marginal: 646.2317003803224\n",
      "Train Epoch: 489 [512/17352 (3%)] Loss: -829.549194\n",
      "Train Epoch: 489 [11230/17352 (65%)] Loss: -669.525672\n",
      "Train Epoch: 489 [16934/17352 (98%)] Loss: -934.922745\n",
      "    epoch          : 489\n",
      "    loss           : -821.7716700155228\n",
      "    val_loss       : -638.0631087133654\n",
      "    val_log_likelihood: 1075.2785305976292\n",
      "    val_log_marginal: 666.4996909638431\n",
      "Train Epoch: 490 [512/17352 (3%)] Loss: -864.316040\n",
      "Train Epoch: 490 [10855/17352 (63%)] Loss: -880.500145\n",
      "Train Epoch: 490 [17049/17352 (98%)] Loss: -845.930713\n",
      "    epoch          : 490\n",
      "    loss           : -824.1563758563123\n",
      "    val_loss       : -647.76895465174\n",
      "    val_log_likelihood: 1080.1231691671207\n",
      "    val_log_marginal: 671.6588519498775\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0506_152815/checkpoint-epoch490.pth ...\n",
      "Train Epoch: 491 [512/17352 (3%)] Loss: -705.125000\n",
      "Train Epoch: 491 [10659/17352 (61%)] Loss: -892.173718\n",
      "Train Epoch: 491 [17016/17352 (98%)] Loss: -883.061250\n",
      "    epoch          : 491\n",
      "    loss           : -823.2873734367672\n",
      "    val_loss       : -628.5199240026654\n",
      "    val_log_likelihood: 1067.3568658497725\n",
      "    val_log_marginal: 654.5765841197216\n",
      "Train Epoch: 492 [512/17352 (3%)] Loss: -837.852417\n",
      "Train Epoch: 492 [10386/17352 (60%)] Loss: -735.763900\n",
      "Train Epoch: 492 [17253/17352 (99%)] Loss: -844.566925\n",
      "    epoch          : 492\n",
      "    loss           : -818.4313225456916\n",
      "    val_loss       : -630.5230752538243\n",
      "    val_log_likelihood: 1072.097681795017\n",
      "    val_log_marginal: 671.6059285913409\n",
      "Train Epoch: 493 [512/17352 (3%)] Loss: -868.018066\n",
      "Train Epoch: 493 [10009/17352 (58%)] Loss: -745.111543\n",
      "Train Epoch: 493 [16887/17352 (97%)] Loss: -891.014923\n",
      "    epoch          : 493\n",
      "    loss           : -797.5548629672991\n",
      "    val_loss       : -628.3048776869261\n",
      "    val_log_likelihood: 1079.3219720506072\n",
      "    val_log_marginal: 673.9698715035537\n",
      "Train Epoch: 494 [512/17352 (3%)] Loss: -862.015259\n",
      "Train Epoch: 494 [10549/17352 (61%)] Loss: -770.632648\n",
      "Train Epoch: 494 [16988/17352 (98%)] Loss: -680.263494\n",
      "    epoch          : 494\n",
      "    loss           : -804.4392047916401\n",
      "    val_loss       : -622.4045996426407\n",
      "    val_log_likelihood: 1071.3229007028676\n",
      "    val_log_marginal: 655.9338743520985\n",
      "Train Epoch: 495 [512/17352 (3%)] Loss: -841.554199\n",
      "Train Epoch: 495 [10950/17352 (63%)] Loss: -916.241979\n",
      "Train Epoch: 495 [17016/17352 (98%)] Loss: -604.785100\n",
      "    epoch          : 495\n",
      "    loss           : -803.1757425443487\n",
      "    val_loss       : -590.098842302647\n",
      "    val_log_likelihood: 1059.8749869142982\n",
      "    val_log_marginal: 607.8200230247714\n",
      "Train Epoch: 496 [512/17352 (3%)] Loss: -830.049255\n",
      "Train Epoch: 496 [10201/17352 (59%)] Loss: -899.388370\n",
      "Train Epoch: 496 [17108/17352 (99%)] Loss: -773.071243\n",
      "    epoch          : 496\n",
      "    loss           : -813.2546866831095\n",
      "    val_loss       : -617.2939027757645\n",
      "    val_log_likelihood: 1061.1519912239578\n",
      "    val_log_marginal: 641.7136496936081\n",
      "Train Epoch: 497 [512/17352 (3%)] Loss: -819.010925\n",
      "Train Epoch: 497 [10186/17352 (59%)] Loss: -819.314166\n",
      "Train Epoch: 497 [16934/17352 (98%)] Loss: -849.609500\n",
      "    epoch          : 497\n",
      "    loss           : -806.7758267809961\n",
      "    val_loss       : -633.8263475684179\n",
      "    val_log_likelihood: 1067.282646738237\n",
      "    val_log_marginal: 660.9833980142596\n",
      "Train Epoch: 498 [512/17352 (3%)] Loss: -854.896606\n",
      "Train Epoch: 498 [10522/17352 (61%)] Loss: -873.447703\n",
      "Train Epoch: 498 [16957/17352 (98%)] Loss: -766.443697\n",
      "    epoch          : 498\n",
      "    loss           : -820.2306183160225\n",
      "    val_loss       : -623.2243086133785\n",
      "    val_log_likelihood: 1079.2351684178461\n",
      "    val_log_marginal: 659.3415268611765\n",
      "Train Epoch: 499 [512/17352 (3%)] Loss: -866.510132\n",
      "Train Epoch: 499 [10176/17352 (59%)] Loss: -897.992736\n",
      "Train Epoch: 499 [17106/17352 (99%)] Loss: -867.731127\n",
      "    epoch          : 499\n",
      "    loss           : -789.92740441347\n",
      "    val_loss       : -614.6170954579804\n",
      "    val_log_likelihood: 1071.720724049144\n",
      "    val_log_marginal: 635.0032421839969\n",
      "Train Epoch: 500 [512/17352 (3%)] Loss: -785.235168\n",
      "Train Epoch: 500 [10221/17352 (59%)] Loss: -834.815492\n",
      "Train Epoch: 500 [17253/17352 (99%)] Loss: -745.710311\n",
      "    epoch          : 500\n",
      "    loss           : -795.6493427050264\n",
      "    val_loss       : -530.6597715893079\n",
      "    val_log_likelihood: 1043.978415157606\n",
      "    val_log_marginal: 562.7672068372314\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0506_152815/checkpoint-epoch500.pth ...\n",
      "Train Epoch: 501 [512/17352 (3%)] Loss: -731.430054\n",
      "Train Epoch: 501 [10210/17352 (59%)] Loss: -793.764691\n",
      "Train Epoch: 501 [16878/17352 (97%)] Loss: -782.495367\n",
      "    epoch          : 501\n",
      "    loss           : -784.2384754292295\n",
      "    val_loss       : -638.4619944224821\n",
      "    val_log_likelihood: 1076.593364279588\n",
      "    val_log_marginal: 662.8979539045176\n",
      "Train Epoch: 502 [512/17352 (3%)] Loss: -859.846069\n",
      "Train Epoch: 502 [10059/17352 (58%)] Loss: -915.578342\n",
      "Train Epoch: 502 [16988/17352 (98%)] Loss: -914.913646\n",
      "    epoch          : 502\n",
      "    loss           : -793.9619903212807\n",
      "    val_loss       : -638.7524976661591\n",
      "    val_log_likelihood: 1074.0536129444222\n",
      "    val_log_marginal: 668.7097841321065\n",
      "Train Epoch: 503 [512/17352 (3%)] Loss: -861.673340\n",
      "Train Epoch: 503 [10756/17352 (62%)] Loss: -953.588605\n",
      "Train Epoch: 503 [17106/17352 (99%)] Loss: -873.968829\n",
      "    epoch          : 503\n",
      "    loss           : -810.269072340233\n",
      "    val_loss       : -577.7519248550748\n",
      "    val_log_likelihood: 1042.7143243782548\n",
      "    val_log_marginal: 608.6435504185778\n",
      "Train Epoch: 504 [512/17352 (3%)] Loss: -755.566528\n",
      "Train Epoch: 504 [9973/17352 (57%)] Loss: -706.947667\n",
      "Train Epoch: 504 [16939/17352 (98%)] Loss: -810.099195\n",
      "    epoch          : 504\n",
      "    loss           : -784.8858383853019\n",
      "    val_loss       : -622.1983792286079\n",
      "    val_log_likelihood: 1062.5593772239333\n",
      "    val_log_marginal: 650.455478215012\n",
      "Train Epoch: 505 [512/17352 (3%)] Loss: -797.591858\n",
      "Train Epoch: 505 [10272/17352 (59%)] Loss: -659.166086\n",
      "Train Epoch: 505 [17253/17352 (99%)] Loss: -798.835819\n",
      "    epoch          : 505\n",
      "    loss           : -723.5823420379699\n",
      "    val_loss       : -474.87704804413806\n",
      "    val_log_likelihood: 1000.8126228440445\n",
      "    val_log_marginal: 575.4969534637323\n",
      "Train Epoch: 506 [512/17352 (3%)] Loss: -466.981842\n",
      "Train Epoch: 506 [10563/17352 (61%)] Loss: -748.007852\n",
      "Train Epoch: 506 [17253/17352 (99%)] Loss: -673.231445\n",
      "    epoch          : 506\n",
      "    loss           : -618.1342208098903\n",
      "    val_loss       : -468.4819899381595\n",
      "    val_log_likelihood: 969.3058199664846\n",
      "    val_log_marginal: 532.1158117345622\n",
      "Train Epoch: 507 [512/17352 (3%)] Loss: -745.965576\n",
      "Train Epoch: 507 [10402/17352 (60%)] Loss: -419.436391\n",
      "Train Epoch: 507 [17143/17352 (99%)] Loss: -732.702321\n",
      "    epoch          : 507\n",
      "    loss           : -718.0371587894831\n",
      "    val_loss       : -551.5841604971918\n",
      "    val_log_likelihood: 1029.3643979350943\n",
      "    val_log_marginal: 591.612161803308\n",
      "Train Epoch: 508 [512/17352 (3%)] Loss: -804.020020\n",
      "Train Epoch: 508 [10002/17352 (58%)] Loss: -813.108464\n",
      "Train Epoch: 508 [16922/17352 (98%)] Loss: -667.262067\n",
      "    epoch          : 508\n",
      "    loss           : -770.4173129140146\n",
      "    val_loss       : -638.0068173101755\n",
      "    val_log_likelihood: 1067.208555553619\n",
      "    val_log_marginal: 674.6329333673439\n",
      "Train Epoch: 509 [512/17352 (3%)] Loss: -854.722717\n",
      "Train Epoch: 509 [10026/17352 (58%)] Loss: -918.954268\n",
      "Train Epoch: 509 [17133/17352 (99%)] Loss: -721.336648\n",
      "    epoch          : 509\n",
      "    loss           : -800.4890517389354\n",
      "    val_loss       : -599.9068627667748\n",
      "    val_log_likelihood: 1052.21393930597\n",
      "    val_log_marginal: 630.288560304112\n",
      "Train Epoch: 510 [512/17352 (3%)] Loss: -843.576965\n",
      "Train Epoch: 510 [10623/17352 (61%)] Loss: -679.577083\n",
      "Train Epoch: 510 [17263/17352 (99%)] Loss: -713.332031\n",
      "    epoch          : 510\n",
      "    loss           : -776.550853213286\n",
      "    val_loss       : -584.9735385842996\n",
      "    val_log_likelihood: 1071.4407795184252\n",
      "    val_log_marginal: 612.2633635145443\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0506_152815/checkpoint-epoch510.pth ...\n",
      "Train Epoch: 511 [512/17352 (3%)] Loss: -787.344788\n",
      "Train Epoch: 511 [11042/17352 (64%)] Loss: -791.124306\n",
      "Train Epoch: 511 [17133/17352 (99%)] Loss: -914.879598\n",
      "    epoch          : 511\n",
      "    loss           : -807.4431995135467\n",
      "    val_loss       : -641.3834844002816\n",
      "    val_log_likelihood: 1071.7444065405398\n",
      "    val_log_marginal: 662.3485596356975\n",
      "Train Epoch: 512 [512/17352 (3%)] Loss: -870.585571\n",
      "Train Epoch: 512 [10258/17352 (59%)] Loss: -790.382626\n",
      "Train Epoch: 512 [16872/17352 (97%)] Loss: -911.871598\n",
      "    epoch          : 512\n",
      "    loss           : -825.7511633688192\n",
      "    val_loss       : -647.260102890191\n",
      "    val_log_likelihood: 1079.7186830822588\n",
      "    val_log_marginal: 676.8827088117844\n",
      "Train Epoch: 513 [512/17352 (3%)] Loss: -861.684265\n",
      "Train Epoch: 513 [10583/17352 (61%)] Loss: -813.393503\n",
      "Train Epoch: 513 [17253/17352 (99%)] Loss: -767.782745\n",
      "    epoch          : 513\n",
      "    loss           : -828.9273967027754\n",
      "    val_loss       : -647.7069076275201\n",
      "    val_log_likelihood: 1086.950620616271\n",
      "    val_log_marginal: 676.4519881476186\n",
      "Train Epoch: 514 [512/17352 (3%)] Loss: -680.939758\n",
      "Train Epoch: 514 [10177/17352 (59%)] Loss: -717.871795\n",
      "Train Epoch: 514 [17277/17352 (100%)] Loss: -877.831236\n",
      "    epoch          : 514\n",
      "    loss           : -839.0595163826683\n",
      "    val_loss       : -654.0875565368999\n",
      "    val_log_likelihood: 1089.5958696062644\n",
      "    val_log_marginal: 682.7189340951288\n",
      "Train Epoch: 515 [512/17352 (3%)] Loss: -701.467834\n",
      "Train Epoch: 515 [10389/17352 (60%)] Loss: -894.343392\n",
      "Train Epoch: 515 [16923/17352 (98%)] Loss: -958.748984\n",
      "    epoch          : 515\n",
      "    loss           : -842.548514305\n",
      "    val_loss       : -661.755075968501\n",
      "    val_log_likelihood: 1089.5911098345568\n",
      "    val_log_marginal: 685.9723603346325\n",
      "Train Epoch: 516 [512/17352 (3%)] Loss: -891.491577\n",
      "Train Epoch: 516 [10243/17352 (59%)] Loss: -789.543403\n",
      "Train Epoch: 516 [16957/17352 (98%)] Loss: -835.168037\n",
      "    epoch          : 516\n",
      "    loss           : -850.8114687486232\n",
      "    val_loss       : -672.9287052573222\n",
      "    val_log_likelihood: 1088.2346126340822\n",
      "    val_log_marginal: 688.834025525966\n",
      "Train Epoch: 517 [512/17352 (3%)] Loss: -892.394043\n",
      "Train Epoch: 517 [9901/17352 (57%)] Loss: -821.524242\n",
      "Train Epoch: 517 [16922/17352 (98%)] Loss: -920.197400\n",
      "    epoch          : 517\n",
      "    loss           : -854.3266585021104\n",
      "    val_loss       : -664.3543962208979\n",
      "    val_log_likelihood: 1093.5237890661397\n",
      "    val_log_marginal: 689.9715096819916\n",
      "Train Epoch: 518 [512/17352 (3%)] Loss: -903.292725\n",
      "Train Epoch: 518 [10855/17352 (63%)] Loss: -922.201569\n",
      "Train Epoch: 518 [17124/17352 (99%)] Loss: -802.969618\n",
      "    epoch          : 518\n",
      "    loss           : -854.6355039628772\n",
      "    val_loss       : -663.4170511892221\n",
      "    val_log_likelihood: 1102.6228463750135\n",
      "    val_log_marginal: 691.2879751849675\n",
      "Train Epoch: 519 [512/17352 (3%)] Loss: -883.599487\n",
      "Train Epoch: 519 [9980/17352 (58%)] Loss: -907.042380\n",
      "Train Epoch: 519 [16988/17352 (98%)] Loss: -912.290988\n",
      "    epoch          : 519\n",
      "    loss           : -851.4689717010814\n",
      "    val_loss       : -663.1281193903387\n",
      "    val_log_likelihood: 1096.0831473216217\n",
      "    val_log_marginal: 687.8881830379725\n",
      "Train Epoch: 520 [512/17352 (3%)] Loss: -900.804321\n",
      "Train Epoch: 520 [10392/17352 (60%)] Loss: -661.775419\n",
      "Train Epoch: 520 [16958/17352 (98%)] Loss: -795.044436\n",
      "    epoch          : 520\n",
      "    loss           : -852.7008176374333\n",
      "    val_loss       : -637.5758998834782\n",
      "    val_log_likelihood: 1076.448284746801\n",
      "    val_log_marginal: 661.4906023001901\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0506_152815/checkpoint-epoch520.pth ...\n",
      "Train Epoch: 521 [512/17352 (3%)] Loss: -856.500732\n",
      "Train Epoch: 521 [10435/17352 (60%)] Loss: -763.102628\n",
      "Train Epoch: 521 [16958/17352 (98%)] Loss: -791.782371\n",
      "    epoch          : 521\n",
      "    loss           : -846.6051229799338\n",
      "    val_loss       : -657.1630364358939\n",
      "    val_log_likelihood: 1093.337537113371\n",
      "    val_log_marginal: 686.4539264106083\n",
      "Train Epoch: 522 [512/17352 (3%)] Loss: -912.105835\n",
      "Train Epoch: 522 [10853/17352 (63%)] Loss: -733.053216\n",
      "Train Epoch: 522 [17143/17352 (99%)] Loss: -930.562024\n",
      "    epoch          : 522\n",
      "    loss           : -849.3488061030406\n",
      "    val_loss       : -671.7392645151567\n",
      "    val_log_likelihood: 1105.7832419194488\n",
      "    val_log_marginal: 694.4568021330876\n",
      "Train Epoch: 523 [512/17352 (3%)] Loss: -908.072266\n",
      "Train Epoch: 523 [10506/17352 (61%)] Loss: -709.616627\n",
      "Train Epoch: 523 [17153/17352 (99%)] Loss: -907.004509\n",
      "    epoch          : 523\n",
      "    loss           : -827.3081165177226\n",
      "    val_loss       : -608.0464797072366\n",
      "    val_log_likelihood: 1080.0070559452415\n",
      "    val_log_marginal: 631.6869114171635\n",
      "Train Epoch: 524 [512/17352 (3%)] Loss: -866.645874\n",
      "Train Epoch: 524 [10655/17352 (61%)] Loss: -719.814174\n",
      "Train Epoch: 524 [17153/17352 (99%)] Loss: -638.082013\n",
      "    epoch          : 524\n",
      "    loss           : -803.8672263550875\n",
      "    val_loss       : -610.6552009555752\n",
      "    val_log_likelihood: 1089.0808560747164\n",
      "    val_log_marginal: 637.7756901858194\n",
      "Train Epoch: 525 [512/17352 (3%)] Loss: -846.554810\n",
      "Train Epoch: 525 [10470/17352 (60%)] Loss: -759.044831\n",
      "Train Epoch: 525 [17044/17352 (98%)] Loss: -944.388193\n",
      "    epoch          : 525\n",
      "    loss           : -824.843750031101\n",
      "    val_loss       : -642.6341543543883\n",
      "    val_log_likelihood: 1096.2244541178625\n",
      "    val_log_marginal: 667.9343471386194\n",
      "Train Epoch: 526 [512/17352 (3%)] Loss: -865.701660\n",
      "Train Epoch: 526 [10308/17352 (59%)] Loss: -893.308813\n",
      "Train Epoch: 526 [17277/17352 (100%)] Loss: -960.530569\n",
      "    epoch          : 526\n",
      "    loss           : -825.3360069739305\n",
      "    val_loss       : -577.0658624402495\n",
      "    val_log_likelihood: 1086.9960356193103\n",
      "    val_log_marginal: 603.3844769301824\n",
      "Train Epoch: 527 [512/17352 (3%)] Loss: -812.926941\n",
      "Train Epoch: 527 [10569/17352 (61%)] Loss: -927.448072\n",
      "Train Epoch: 527 [17108/17352 (99%)] Loss: -819.409801\n",
      "    epoch          : 527\n",
      "    loss           : -821.2048031291123\n",
      "    val_loss       : -572.2994886085351\n",
      "    val_log_likelihood: 1069.690859529759\n",
      "    val_log_marginal: 596.2752899609383\n",
      "Train Epoch: 528 [512/17352 (3%)] Loss: -793.165344\n",
      "Train Epoch: 528 [10087/17352 (58%)] Loss: -695.082190\n",
      "Train Epoch: 528 [16882/17352 (97%)] Loss: 1197.186216\n",
      "    epoch          : 528\n",
      "    loss           : -431.0981689628657\n",
      "    val_loss       : 339.67722740522885\n",
      "    val_log_likelihood: 934.6027030786246\n",
      "    val_log_marginal: -287.0157812345104\n",
      "Train Epoch: 529 [512/17352 (3%)] Loss: 673.644226\n",
      "Train Epoch: 529 [9931/17352 (57%)] Loss: -667.801004\n",
      "Train Epoch: 529 [17335/17352 (100%)] Loss: -616.641815\n",
      "    epoch          : 529\n",
      "    loss           : -511.43674281234803\n",
      "    val_loss       : -314.19809619811366\n",
      "    val_log_likelihood: 863.6912868905044\n",
      "    val_log_marginal: 362.1568702050935\n",
      "Train Epoch: 530 [512/17352 (3%)] Loss: -216.386734\n",
      "Train Epoch: 530 [11004/17352 (63%)] Loss: -393.602184\n",
      "Train Epoch: 530 [17044/17352 (98%)] Loss: -656.631461\n",
      "    epoch          : 530\n",
      "    loss           : -637.1631411251274\n",
      "    val_loss       : -505.08476796458586\n",
      "    val_log_likelihood: 1025.7629748566385\n",
      "    val_log_marginal: 560.012292770166\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0506_152815/checkpoint-epoch530.pth ...\n",
      "Train Epoch: 531 [512/17352 (3%)] Loss: -772.442810\n",
      "Train Epoch: 531 [10378/17352 (60%)] Loss: -830.128050\n",
      "Train Epoch: 531 [17049/17352 (98%)] Loss: -900.677532\n",
      "    epoch          : 531\n",
      "    loss           : -746.6185345808157\n",
      "    val_loss       : -600.8311936913274\n",
      "    val_log_likelihood: 1060.32908824444\n",
      "    val_log_marginal: 658.3322933507717\n",
      "Train Epoch: 532 [512/17352 (3%)] Loss: -832.497375\n",
      "Train Epoch: 532 [10247/17352 (59%)] Loss: -885.442383\n",
      "Train Epoch: 532 [17124/17352 (99%)] Loss: -588.830365\n",
      "    epoch          : 532\n",
      "    loss           : -755.409688760159\n",
      "    val_loss       : -528.7230430478327\n",
      "    val_log_likelihood: 1024.8699467612319\n",
      "    val_log_marginal: 578.9117780006452\n",
      "Train Epoch: 533 [512/17352 (3%)] Loss: -648.264709\n",
      "Train Epoch: 533 [10395/17352 (60%)] Loss: -529.972463\n",
      "Train Epoch: 533 [16882/17352 (97%)] Loss: -820.285117\n",
      "    epoch          : 533\n",
      "    loss           : -778.8202058479553\n",
      "    val_loss       : -626.7327856352172\n",
      "    val_log_likelihood: 1055.0446762084168\n",
      "    val_log_marginal: 648.4028715679632\n",
      "Train Epoch: 534 [512/17352 (3%)] Loss: -861.772888\n",
      "Train Epoch: 534 [10442/17352 (60%)] Loss: -774.933687\n",
      "Train Epoch: 534 [16992/17352 (98%)] Loss: -956.645278\n",
      "    epoch          : 534\n",
      "    loss           : -818.9805494438768\n",
      "    val_loss       : -653.6374138772934\n",
      "    val_log_likelihood: 1078.6797726498935\n",
      "    val_log_marginal: 677.4854375622326\n",
      "Train Epoch: 535 [512/17352 (3%)] Loss: -859.167419\n",
      "Train Epoch: 535 [10301/17352 (59%)] Loss: -820.670504\n",
      "Train Epoch: 535 [16992/17352 (98%)] Loss: -855.279426\n",
      "    epoch          : 535\n",
      "    loss           : -824.4653044360783\n",
      "    val_loss       : -524.3822774884912\n",
      "    val_log_likelihood: 1091.5871119377548\n",
      "    val_log_marginal: 549.0160744362976\n",
      "Train Epoch: 536 [512/17352 (3%)] Loss: -754.113037\n",
      "Train Epoch: 536 [10702/17352 (62%)] Loss: -890.527079\n",
      "Train Epoch: 536 [16923/17352 (98%)] Loss: -959.960829\n",
      "    epoch          : 536\n",
      "    loss           : -805.7820740987153\n",
      "    val_loss       : -636.9995848902811\n",
      "    val_log_likelihood: 1087.5238498489782\n",
      "    val_log_marginal: 665.9114673866151\n",
      "Train Epoch: 537 [512/17352 (3%)] Loss: -698.001038\n",
      "Train Epoch: 537 [10406/17352 (60%)] Loss: -860.558263\n",
      "Train Epoch: 537 [17101/17352 (99%)] Loss: -866.890546\n",
      "    epoch          : 537\n",
      "    loss           : -818.4485345217496\n",
      "    val_loss       : -653.6144458689755\n",
      "    val_log_likelihood: 1083.4276967672376\n",
      "    val_log_marginal: 682.6989585934558\n",
      "Train Epoch: 538 [512/17352 (3%)] Loss: -858.056580\n",
      "Train Epoch: 538 [9975/17352 (57%)] Loss: -914.443136\n",
      "Train Epoch: 538 [17143/17352 (99%)] Loss: -806.823382\n",
      "    epoch          : 538\n",
      "    loss           : -841.3284632255188\n",
      "    val_loss       : -637.5475084094744\n",
      "    val_log_likelihood: 1083.9404456306397\n",
      "    val_log_marginal: 671.4945534293254\n",
      "Train Epoch: 539 [512/17352 (3%)] Loss: -902.098206\n",
      "Train Epoch: 539 [10248/17352 (59%)] Loss: -747.437872\n",
      "Train Epoch: 539 [17126/17352 (99%)] Loss: -923.905811\n",
      "    epoch          : 539\n",
      "    loss           : -844.9323026823384\n",
      "    val_loss       : -649.5604104458805\n",
      "    val_log_likelihood: 1084.9726342840418\n",
      "    val_log_marginal: 672.4231250160035\n",
      "Train Epoch: 540 [512/17352 (3%)] Loss: -886.062073\n",
      "Train Epoch: 540 [10352/17352 (60%)] Loss: -944.072154\n",
      "Train Epoch: 540 [17253/17352 (99%)] Loss: -826.898352\n",
      "    epoch          : 540\n",
      "    loss           : -844.7248881264774\n",
      "    val_loss       : -651.9471332472526\n",
      "    val_log_likelihood: 1093.1771077638468\n",
      "    val_log_marginal: 684.0990562551985\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0506_152815/checkpoint-epoch540.pth ...\n",
      "Train Epoch: 541 [512/17352 (3%)] Loss: -891.677856\n",
      "Train Epoch: 541 [10224/17352 (59%)] Loss: -914.000351\n",
      "Train Epoch: 541 [16887/17352 (97%)] Loss: -674.861077\n",
      "    epoch          : 541\n",
      "    loss           : -838.1289179845869\n",
      "    val_loss       : -665.993426637413\n",
      "    val_log_likelihood: 1098.929056726097\n",
      "    val_log_marginal: 694.1998787087837\n",
      "Train Epoch: 542 [512/17352 (3%)] Loss: -913.561951\n",
      "Train Epoch: 542 [10631/17352 (61%)] Loss: -908.510458\n",
      "Train Epoch: 542 [16958/17352 (98%)] Loss: -794.958681\n",
      "    epoch          : 542\n",
      "    loss           : -858.8473154418183\n",
      "    val_loss       : -675.3308677263016\n",
      "    val_log_likelihood: 1109.2832989232506\n",
      "    val_log_marginal: 706.3128255936824\n",
      "Train Epoch: 543 [512/17352 (3%)] Loss: -902.053833\n",
      "Train Epoch: 543 [10464/17352 (60%)] Loss: -805.497246\n",
      "Train Epoch: 543 [17126/17352 (99%)] Loss: -963.728511\n",
      "    epoch          : 543\n",
      "    loss           : -855.9660545270126\n",
      "    val_loss       : -667.0551570252857\n",
      "    val_log_likelihood: 1102.9348986048199\n",
      "    val_log_marginal: 688.0572362172977\n",
      "Train Epoch: 544 [512/17352 (3%)] Loss: -898.819092\n",
      "Train Epoch: 544 [10928/17352 (63%)] Loss: -956.622730\n",
      "Train Epoch: 544 [17090/17352 (98%)] Loss: -813.485721\n",
      "    epoch          : 544\n",
      "    loss           : -861.3357597841414\n",
      "    val_loss       : -659.0110804120175\n",
      "    val_log_likelihood: 1090.666000296007\n",
      "    val_log_marginal: 683.4916956796084\n",
      "Train Epoch: 545 [512/17352 (3%)] Loss: -898.270935\n",
      "Train Epoch: 545 [10015/17352 (58%)] Loss: -844.284407\n",
      "Train Epoch: 545 [16992/17352 (98%)] Loss: -905.686504\n",
      "    epoch          : 545\n",
      "    loss           : -858.4512472981716\n",
      "    val_loss       : -657.4304508209173\n",
      "    val_log_likelihood: 1103.7413180247445\n",
      "    val_log_marginal: 681.3577882675916\n",
      "Train Epoch: 546 [512/17352 (3%)] Loss: -907.576965\n",
      "Train Epoch: 546 [10673/17352 (62%)] Loss: -951.389320\n",
      "Train Epoch: 546 [17124/17352 (99%)] Loss: -895.539132\n",
      "    epoch          : 546\n",
      "    loss           : -859.0822197509209\n",
      "    val_loss       : -630.3861706851626\n",
      "    val_log_likelihood: 1097.2820331860337\n",
      "    val_log_marginal: 655.3117088106633\n",
      "Train Epoch: 547 [512/17352 (3%)] Loss: -884.212708\n",
      "Train Epoch: 547 [9694/17352 (56%)] Loss: -976.607964\n",
      "Train Epoch: 547 [16922/17352 (98%)] Loss: -777.204038\n",
      "    epoch          : 547\n",
      "    loss           : -843.5977902033658\n",
      "    val_loss       : -666.0488359668684\n",
      "    val_log_likelihood: 1100.459813314599\n",
      "    val_log_marginal: 682.6697883327736\n",
      "Train Epoch: 548 [512/17352 (3%)] Loss: -886.918823\n",
      "Train Epoch: 548 [10327/17352 (60%)] Loss: -912.809076\n",
      "Train Epoch: 548 [17106/17352 (99%)] Loss: -731.935440\n",
      "    epoch          : 548\n",
      "    loss           : -842.3955520371633\n",
      "    val_loss       : -598.7275904506829\n",
      "    val_log_likelihood: 1094.9261526480689\n",
      "    val_log_marginal: 624.133790944666\n",
      "Train Epoch: 549 [512/17352 (3%)] Loss: -860.937866\n",
      "Train Epoch: 549 [9870/17352 (57%)] Loss: -841.773782\n",
      "Train Epoch: 549 [16988/17352 (98%)] Loss: -896.196859\n",
      "    epoch          : 549\n",
      "    loss           : -835.4506430154013\n",
      "    val_loss       : -633.1763608194651\n",
      "    val_log_likelihood: 1107.8602312435032\n",
      "    val_log_marginal: 654.915743543977\n",
      "Train Epoch: 550 [512/17352 (3%)] Loss: -840.434875\n",
      "Train Epoch: 550 [10503/17352 (61%)] Loss: -721.672906\n",
      "Train Epoch: 550 [16878/17352 (97%)] Loss: -811.516741\n",
      "    epoch          : 550\n",
      "    loss           : -832.5330021561208\n",
      "    val_loss       : -609.4111466247296\n",
      "    val_log_likelihood: 1106.4683505076218\n",
      "    val_log_marginal: 632.8930737155825\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0506_152815/checkpoint-epoch550.pth ...\n",
      "Train Epoch: 551 [512/17352 (3%)] Loss: -850.550964\n",
      "Train Epoch: 551 [10463/17352 (60%)] Loss: -902.330187\n",
      "Train Epoch: 551 [17049/17352 (98%)] Loss: -611.859140\n",
      "    epoch          : 551\n",
      "    loss           : -819.1177919834397\n",
      "    val_loss       : -635.1781852167433\n",
      "    val_log_likelihood: 1099.256841970017\n",
      "    val_log_marginal: 668.3272083077195\n",
      "Train Epoch: 552 [512/17352 (3%)] Loss: -856.965820\n",
      "Train Epoch: 552 [10516/17352 (61%)] Loss: -983.070964\n",
      "Train Epoch: 552 [17049/17352 (98%)] Loss: -891.772121\n",
      "    epoch          : 552\n",
      "    loss           : -818.7180018036531\n",
      "    val_loss       : -652.9065819512467\n",
      "    val_log_likelihood: 1100.2677669039178\n",
      "    val_log_marginal: 673.5312252718553\n",
      "Train Epoch: 553 [512/17352 (3%)] Loss: -714.862976\n",
      "Train Epoch: 553 [9938/17352 (57%)] Loss: -717.363636\n",
      "Train Epoch: 553 [16923/17352 (98%)] Loss: -874.084268\n",
      "    epoch          : 553\n",
      "    loss           : -829.3430757658879\n",
      "    val_loss       : -659.0109126705219\n",
      "    val_log_likelihood: 1109.6967999209855\n",
      "    val_log_marginal: 680.474378784367\n",
      "Train Epoch: 554 [512/17352 (3%)] Loss: -842.958679\n",
      "Train Epoch: 554 [10408/17352 (60%)] Loss: -734.627257\n",
      "Train Epoch: 554 [17126/17352 (99%)] Loss: -756.884347\n",
      "    epoch          : 554\n",
      "    loss           : -761.2732090860371\n",
      "    val_loss       : -472.01928741903384\n",
      "    val_log_likelihood: 1035.6621216664628\n",
      "    val_log_marginal: 544.560928062199\n",
      "Train Epoch: 555 [512/17352 (3%)] Loss: -614.767700\n",
      "Train Epoch: 555 [10237/17352 (59%)] Loss: -559.322141\n",
      "Train Epoch: 555 [17064/17352 (98%)] Loss: 298.182885\n",
      "    epoch          : 555\n",
      "    loss           : -388.32908573080203\n",
      "    val_loss       : -105.75053098707137\n",
      "    val_log_likelihood: 921.7099751541084\n",
      "    val_log_marginal: 167.73722172410717\n",
      "Train Epoch: 556 [512/17352 (3%)] Loss: -394.694519\n",
      "Train Epoch: 556 [10232/17352 (59%)] Loss: -572.926807\n",
      "Train Epoch: 556 [17126/17352 (99%)] Loss: -510.179495\n",
      "    epoch          : 556\n",
      "    loss           : -358.8705832399843\n",
      "    val_loss       : -433.5169114393399\n",
      "    val_log_likelihood: 988.0024392133415\n",
      "    val_log_marginal: 510.3061518475146\n",
      "Train Epoch: 557 [512/17352 (3%)] Loss: -750.307983\n",
      "Train Epoch: 557 [10259/17352 (59%)] Loss: -597.722424\n",
      "Train Epoch: 557 [17133/17352 (99%)] Loss: -846.305063\n",
      "    epoch          : 557\n",
      "    loss           : -706.6987213285339\n",
      "    val_loss       : -562.8740107831516\n",
      "    val_log_likelihood: 1049.280749350564\n",
      "    val_log_marginal: 605.2149786156157\n",
      "Train Epoch: 558 [512/17352 (3%)] Loss: -797.314880\n",
      "Train Epoch: 558 [10218/17352 (59%)] Loss: -789.175334\n",
      "Train Epoch: 558 [17124/17352 (99%)] Loss: -876.141860\n",
      "    epoch          : 558\n",
      "    loss           : -781.7451351685398\n",
      "    val_loss       : -640.4891583982601\n",
      "    val_log_likelihood: 1072.1288949581535\n",
      "    val_log_marginal: 663.656587409888\n",
      "Train Epoch: 559 [512/17352 (3%)] Loss: -876.820312\n",
      "Train Epoch: 559 [10149/17352 (58%)] Loss: -770.689741\n",
      "Train Epoch: 559 [17064/17352 (98%)] Loss: -800.110496\n",
      "    epoch          : 559\n",
      "    loss           : -827.5333375464652\n",
      "    val_loss       : -660.1841801540202\n",
      "    val_log_likelihood: 1091.5564015878474\n",
      "    val_log_marginal: 689.2972643332976\n",
      "Train Epoch: 560 [512/17352 (3%)] Loss: -884.099365\n",
      "Train Epoch: 560 [10184/17352 (59%)] Loss: -859.726010\n",
      "Train Epoch: 560 [16878/17352 (97%)] Loss: -813.065333\n",
      "    epoch          : 560\n",
      "    loss           : -845.7405723063142\n",
      "    val_loss       : -654.4721991824478\n",
      "    val_log_likelihood: 1095.729090044795\n",
      "    val_log_marginal: 675.9192291748037\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0506_152815/checkpoint-epoch560.pth ...\n",
      "Train Epoch: 561 [512/17352 (3%)] Loss: -892.376465\n",
      "Train Epoch: 561 [10564/17352 (61%)] Loss: -803.687855\n",
      "Train Epoch: 561 [16992/17352 (98%)] Loss: -907.870260\n",
      "    epoch          : 561\n",
      "    loss           : -842.8350174682079\n",
      "    val_loss       : -681.3450882761219\n",
      "    val_log_likelihood: 1101.626802779954\n",
      "    val_log_marginal: 704.8111038392472\n",
      "Train Epoch: 562 [512/17352 (3%)] Loss: -884.301270\n",
      "Train Epoch: 562 [10238/17352 (59%)] Loss: -920.108544\n",
      "Train Epoch: 562 [17277/17352 (100%)] Loss: -988.398003\n",
      "    epoch          : 562\n",
      "    loss           : -854.3434055730318\n",
      "    val_loss       : -671.971125330421\n",
      "    val_log_likelihood: 1094.3257881403852\n",
      "    val_log_marginal: 695.4115343312598\n",
      "Train Epoch: 563 [512/17352 (3%)] Loss: -885.567749\n",
      "Train Epoch: 563 [10405/17352 (60%)] Loss: -833.870546\n",
      "Train Epoch: 563 [16957/17352 (98%)] Loss: -839.826017\n",
      "    epoch          : 563\n",
      "    loss           : -854.4177310344922\n",
      "    val_loss       : -636.2980655851377\n",
      "    val_log_likelihood: 1098.3362529783346\n",
      "    val_log_marginal: 662.3010009621514\n",
      "Train Epoch: 564 [512/17352 (3%)] Loss: -878.752686\n",
      "Train Epoch: 564 [10394/17352 (60%)] Loss: -883.421954\n",
      "Train Epoch: 564 [17143/17352 (99%)] Loss: -826.748150\n",
      "    epoch          : 564\n",
      "    loss           : -843.6613513448154\n",
      "    val_loss       : -606.1431529783405\n",
      "    val_log_likelihood: 1088.868047207865\n",
      "    val_log_marginal: 634.6158525969496\n",
      "Train Epoch: 565 [512/17352 (3%)] Loss: -851.474976\n",
      "Train Epoch: 565 [10439/17352 (60%)] Loss: -871.957657\n",
      "Train Epoch: 565 [17263/17352 (99%)] Loss: -746.926948\n",
      "    epoch          : 565\n",
      "    loss           : -767.459639744473\n",
      "    val_loss       : -624.0643023962003\n",
      "    val_log_likelihood: 1087.355197929358\n",
      "    val_log_marginal: 650.7693352947718\n",
      "Train Epoch: 566 [512/17352 (3%)] Loss: -840.983093\n",
      "Train Epoch: 566 [10241/17352 (59%)] Loss: -633.333637\n",
      "Train Epoch: 566 [17126/17352 (99%)] Loss: -637.120692\n",
      "    epoch          : 566\n",
      "    loss           : -765.7508372409974\n",
      "    val_loss       : -363.50371531037064\n",
      "    val_log_likelihood: 946.0876573922743\n",
      "    val_log_marginal: 504.7424773296016\n",
      "Train Epoch: 567 [512/17352 (3%)] Loss: -483.096497\n",
      "Train Epoch: 567 [9997/17352 (58%)] Loss: -802.957199\n",
      "Train Epoch: 567 [16883/17352 (97%)] Loss: -635.592168\n",
      "    epoch          : 567\n",
      "    loss           : -676.693647093404\n",
      "    val_loss       : -577.5166159687845\n",
      "    val_log_likelihood: 1053.8348228831262\n",
      "    val_log_marginal: 617.8113613385033\n",
      "Train Epoch: 568 [512/17352 (3%)] Loss: -568.974792\n",
      "Train Epoch: 568 [10234/17352 (59%)] Loss: -923.987896\n",
      "Train Epoch: 568 [17124/17352 (99%)] Loss: -766.270335\n",
      "    epoch          : 568\n",
      "    loss           : -824.1192539162913\n",
      "    val_loss       : -639.9766653876633\n",
      "    val_log_likelihood: 1079.8729301150595\n",
      "    val_log_marginal: 665.7252466019683\n",
      "Train Epoch: 569 [512/17352 (3%)] Loss: -883.237061\n",
      "Train Epoch: 569 [10943/17352 (63%)] Loss: -939.795570\n",
      "Train Epoch: 569 [17044/17352 (98%)] Loss: -916.456541\n",
      "    epoch          : 569\n",
      "    loss           : -844.0938807496689\n",
      "    val_loss       : -645.7097707320487\n",
      "    val_log_likelihood: 1084.992171248982\n",
      "    val_log_marginal: 676.237753010594\n",
      "Train Epoch: 570 [512/17352 (3%)] Loss: -892.328125\n",
      "Train Epoch: 570 [9969/17352 (57%)] Loss: -751.283584\n",
      "Train Epoch: 570 [17090/17352 (98%)] Loss: -898.409914\n",
      "    epoch          : 570\n",
      "    loss           : -859.8053466045202\n",
      "    val_loss       : -679.0906752589857\n",
      "    val_log_likelihood: 1102.420227443949\n",
      "    val_log_marginal: 704.8936418245313\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0506_152815/checkpoint-epoch570.pth ...\n",
      "Train Epoch: 571 [512/17352 (3%)] Loss: -898.443359\n",
      "Train Epoch: 571 [10132/17352 (58%)] Loss: -902.651250\n",
      "Train Epoch: 571 [16922/17352 (98%)] Loss: -943.356943\n",
      "    epoch          : 571\n",
      "    loss           : -868.8170437926921\n",
      "    val_loss       : -667.2186778253774\n",
      "    val_log_likelihood: 1109.04464092194\n",
      "    val_log_marginal: 700.5513847127429\n",
      "Train Epoch: 572 [512/17352 (3%)] Loss: -906.378784\n",
      "Train Epoch: 572 [10185/17352 (59%)] Loss: -666.319968\n",
      "Train Epoch: 572 [17016/17352 (98%)] Loss: -771.379211\n",
      "    epoch          : 572\n",
      "    loss           : -834.6757403263997\n",
      "    val_loss       : -655.8370243095517\n",
      "    val_log_likelihood: 1100.1886794944926\n",
      "    val_log_marginal: 683.0108652014914\n",
      "Train Epoch: 573 [512/17352 (3%)] Loss: -880.415955\n",
      "Train Epoch: 573 [9935/17352 (57%)] Loss: -748.990099\n",
      "Train Epoch: 573 [16878/17352 (97%)] Loss: -931.019688\n",
      "    epoch          : 573\n",
      "    loss           : -863.0539918607986\n",
      "    val_loss       : -676.1213438890063\n",
      "    val_log_likelihood: 1106.1086266396408\n",
      "    val_log_marginal: 699.3104840975101\n",
      "Train Epoch: 574 [512/17352 (3%)] Loss: -902.543152\n",
      "Train Epoch: 574 [10603/17352 (61%)] Loss: -810.005903\n",
      "Train Epoch: 574 [16957/17352 (98%)] Loss: -923.183854\n",
      "    epoch          : 574\n",
      "    loss           : -867.0704438778574\n",
      "    val_loss       : -673.4109511827029\n",
      "    val_log_likelihood: 1114.7259782122856\n",
      "    val_log_marginal: 700.0410042931978\n",
      "Train Epoch: 575 [512/17352 (3%)] Loss: -897.096741\n",
      "Train Epoch: 575 [10621/17352 (61%)] Loss: -969.476241\n",
      "Train Epoch: 575 [17090/17352 (98%)] Loss: -940.539826\n",
      "    epoch          : 575\n",
      "    loss           : -870.8173926421049\n",
      "    val_loss       : -672.0100912164991\n",
      "    val_log_likelihood: 1112.295809921802\n",
      "    val_log_marginal: 700.2711154434546\n",
      "Train Epoch: 576 [512/17352 (3%)] Loss: -918.583496\n",
      "Train Epoch: 576 [10032/17352 (58%)] Loss: -647.351546\n",
      "Train Epoch: 576 [16883/17352 (97%)] Loss: -821.691598\n",
      "    epoch          : 576\n",
      "    loss           : -866.2187856799552\n",
      "    val_loss       : -680.0954680371995\n",
      "    val_log_likelihood: 1122.3868533407267\n",
      "    val_log_marginal: 711.4657861287378\n",
      "Train Epoch: 577 [512/17352 (3%)] Loss: -925.667603\n",
      "Train Epoch: 577 [10583/17352 (61%)] Loss: -731.464264\n",
      "Train Epoch: 577 [17016/17352 (98%)] Loss: -939.742451\n",
      "    epoch          : 577\n",
      "    loss           : -873.1662362916942\n",
      "    val_loss       : -673.5985122886449\n",
      "    val_log_likelihood: 1121.0780252276604\n",
      "    val_log_marginal: 703.051871002898\n",
      "Train Epoch: 578 [512/17352 (3%)] Loss: -925.157043\n",
      "Train Epoch: 578 [10271/17352 (59%)] Loss: -803.344765\n",
      "Train Epoch: 578 [17335/17352 (100%)] Loss: -746.805745\n",
      "    epoch          : 578\n",
      "    loss           : -881.2558889251952\n",
      "    val_loss       : -659.8504111980636\n",
      "    val_log_likelihood: 1111.2575678415567\n",
      "    val_log_marginal: 685.1630374563981\n",
      "Train Epoch: 579 [512/17352 (3%)] Loss: -911.824402\n",
      "Train Epoch: 579 [10116/17352 (58%)] Loss: -916.531499\n",
      "Train Epoch: 579 [17253/17352 (99%)] Loss: -848.919807\n",
      "    epoch          : 579\n",
      "    loss           : -869.7213381938503\n",
      "    val_loss       : -648.877832042641\n",
      "    val_log_likelihood: 1110.7125368592465\n",
      "    val_log_marginal: 682.3064305698549\n",
      "Train Epoch: 580 [512/17352 (3%)] Loss: -897.748413\n",
      "Train Epoch: 580 [10814/17352 (62%)] Loss: -737.147110\n",
      "Train Epoch: 580 [16878/17352 (97%)] Loss: -824.688012\n",
      "    epoch          : 580\n",
      "    loss           : -874.7709210572825\n",
      "    val_loss       : -700.2671094672983\n",
      "    val_log_likelihood: 1127.1864475488292\n",
      "    val_log_marginal: 717.5523026219608\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0506_152815/checkpoint-epoch580.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 581 [512/17352 (3%)] Loss: -907.070374\n",
      "Train Epoch: 581 [9632/17352 (56%)] Loss: -951.666345\n",
      "Train Epoch: 581 [16957/17352 (98%)] Loss: -820.538690\n",
      "    epoch          : 581\n",
      "    loss           : -883.9356416069655\n",
      "    val_loss       : -679.2314116869679\n",
      "    val_log_likelihood: 1124.8656938791505\n",
      "    val_log_marginal: 705.5925004585998\n",
      "Train Epoch: 582 [512/17352 (3%)] Loss: -938.822021\n",
      "Train Epoch: 582 [10532/17352 (61%)] Loss: -972.166314\n",
      "Train Epoch: 582 [17133/17352 (99%)] Loss: -715.220430\n",
      "    epoch          : 582\n",
      "    loss           : -885.1577920723437\n",
      "    val_loss       : -669.06575044416\n",
      "    val_log_likelihood: 1120.7044809983458\n",
      "    val_log_marginal: 695.092639899083\n",
      "Train Epoch: 583 [512/17352 (3%)] Loss: -944.857178\n",
      "Train Epoch: 583 [10427/17352 (60%)] Loss: -916.073964\n",
      "Train Epoch: 583 [17335/17352 (100%)] Loss: -739.107356\n",
      "    epoch          : 583\n",
      "    loss           : -885.9041352146132\n",
      "    val_loss       : -666.4982812283088\n",
      "    val_log_likelihood: 1119.9817240425384\n",
      "    val_log_marginal: 696.7134150075663\n",
      "Train Epoch: 584 [512/17352 (3%)] Loss: -872.264893\n",
      "Train Epoch: 584 [10355/17352 (60%)] Loss: -917.579797\n",
      "Train Epoch: 584 [16939/17352 (98%)] Loss: -889.660398\n",
      "    epoch          : 584\n",
      "    loss           : -865.2811680119485\n",
      "    val_loss       : -677.1470457812078\n",
      "    val_log_likelihood: 1121.7075866757305\n",
      "    val_log_marginal: 704.3507167067391\n",
      "Train Epoch: 585 [512/17352 (3%)] Loss: -930.834473\n",
      "Train Epoch: 585 [10487/17352 (60%)] Loss: -893.636263\n",
      "Train Epoch: 585 [16883/17352 (97%)] Loss: -834.841682\n",
      "    epoch          : 585\n",
      "    loss           : -831.1455090647638\n",
      "    val_loss       : -622.2699345944781\n",
      "    val_log_likelihood: 1091.056806843914\n",
      "    val_log_marginal: 648.2945314968415\n",
      "Train Epoch: 586 [512/17352 (3%)] Loss: -885.656128\n",
      "Train Epoch: 586 [10245/17352 (59%)] Loss: -939.088834\n",
      "Train Epoch: 586 [16872/17352 (97%)] Loss: -766.230683\n",
      "    epoch          : 586\n",
      "    loss           : -826.4089960053715\n",
      "    val_loss       : -603.5606007854843\n",
      "    val_log_likelihood: 1103.608769171768\n",
      "    val_log_marginal: 629.322468450313\n",
      "Train Epoch: 587 [512/17352 (3%)] Loss: -675.560791\n",
      "Train Epoch: 587 [9889/17352 (57%)] Loss: -866.022964\n",
      "Train Epoch: 587 [16992/17352 (98%)] Loss: -823.583705\n",
      "    epoch          : 587\n",
      "    loss           : -816.2467327724061\n",
      "    val_loss       : -629.3997342288272\n",
      "    val_log_likelihood: 1105.3409732753157\n",
      "    val_log_marginal: 662.0351652512979\n",
      "Train Epoch: 588 [512/17352 (3%)] Loss: -878.230957\n",
      "Train Epoch: 588 [10572/17352 (61%)] Loss: -871.630305\n",
      "Train Epoch: 588 [17106/17352 (99%)] Loss: -834.793543\n",
      "    epoch          : 588\n",
      "    loss           : -815.586608674766\n",
      "    val_loss       : -592.0302391612138\n",
      "    val_log_likelihood: 1084.6808468663621\n",
      "    val_log_marginal: 619.1731527492092\n",
      "Train Epoch: 589 [512/17352 (3%)] Loss: -594.447937\n",
      "Train Epoch: 589 [10641/17352 (61%)] Loss: -667.567540\n",
      "Train Epoch: 589 [17090/17352 (98%)] Loss: -627.522285\n",
      "    epoch          : 589\n",
      "    loss           : -816.5485774697954\n",
      "    val_loss       : -641.5072289965439\n",
      "    val_log_likelihood: 1112.8094959223104\n",
      "    val_log_marginal: 673.5392201971601\n",
      "Train Epoch: 590 [512/17352 (3%)] Loss: -889.621582\n",
      "Train Epoch: 590 [10582/17352 (61%)] Loss: -831.729396\n",
      "Train Epoch: 590 [16939/17352 (98%)] Loss: -956.301596\n",
      "    epoch          : 590\n",
      "    loss           : -860.0722918346654\n",
      "    val_loss       : -665.118627775267\n",
      "    val_log_likelihood: 1120.1308404078843\n",
      "    val_log_marginal: 689.7512355957161\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0506_152815/checkpoint-epoch590.pth ...\n",
      "Train Epoch: 591 [512/17352 (3%)] Loss: -934.393555\n",
      "Train Epoch: 591 [10688/17352 (62%)] Loss: -934.568850\n",
      "Train Epoch: 591 [17016/17352 (98%)] Loss: -703.257065\n",
      "    epoch          : 591\n",
      "    loss           : -876.1747992871965\n",
      "    val_loss       : -654.7794909312604\n",
      "    val_log_likelihood: 1108.572313723472\n",
      "    val_log_marginal: 687.0140951055253\n",
      "Train Epoch: 592 [512/17352 (3%)] Loss: -934.431763\n",
      "Train Epoch: 592 [10204/17352 (59%)] Loss: -725.253348\n",
      "Train Epoch: 592 [17090/17352 (98%)] Loss: -675.706002\n",
      "    epoch          : 592\n",
      "    loss           : -838.8262314873557\n",
      "    val_loss       : -599.7809999631256\n",
      "    val_log_likelihood: 1111.2821777463841\n",
      "    val_log_marginal: 635.460028087787\n",
      "Train Epoch: 593 [512/17352 (3%)] Loss: -807.692871\n",
      "Train Epoch: 593 [10383/17352 (60%)] Loss: -687.787338\n",
      "Train Epoch: 593 [16882/17352 (97%)] Loss: -676.332508\n",
      "    epoch          : 593\n",
      "    loss           : -839.8136770713096\n",
      "    val_loss       : -664.5594486505335\n",
      "    val_log_likelihood: 1123.155992018798\n",
      "    val_log_marginal: 698.7496406650106\n",
      "Train Epoch: 594 [512/17352 (3%)] Loss: -935.332214\n",
      "Train Epoch: 594 [10370/17352 (60%)] Loss: -818.336965\n",
      "Train Epoch: 594 [17106/17352 (99%)] Loss: -966.059375\n",
      "    epoch          : 594\n",
      "    loss           : -874.4003539626053\n",
      "    val_loss       : -656.6320045692069\n",
      "    val_log_likelihood: 1115.462720989617\n",
      "    val_log_marginal: 680.8831822776555\n",
      "Train Epoch: 595 [512/17352 (3%)] Loss: -882.461121\n",
      "Train Epoch: 595 [10223/17352 (59%)] Loss: -991.896522\n",
      "Train Epoch: 595 [16957/17352 (98%)] Loss: -773.534366\n",
      "    epoch          : 595\n",
      "    loss           : -863.9789943858417\n",
      "    val_loss       : -638.5309897040612\n",
      "    val_log_likelihood: 1104.4674856732465\n",
      "    val_log_marginal: 661.685877826437\n",
      "Train Epoch: 596 [512/17352 (3%)] Loss: -658.600037\n",
      "Train Epoch: 596 [10760/17352 (62%)] Loss: -933.062832\n",
      "Train Epoch: 596 [17143/17352 (99%)] Loss: -1010.967882\n",
      "    epoch          : 596\n",
      "    loss           : -857.6027432747122\n",
      "    val_loss       : -642.3637116157969\n",
      "    val_log_likelihood: 1108.5375497742912\n",
      "    val_log_marginal: 666.8717158805217\n",
      "Train Epoch: 597 [512/17352 (3%)] Loss: -900.350464\n",
      "Train Epoch: 597 [10111/17352 (58%)] Loss: -902.301036\n",
      "Train Epoch: 597 [16934/17352 (98%)] Loss: -897.456706\n",
      "    epoch          : 597\n",
      "    loss           : -850.8617134294093\n",
      "    val_loss       : -661.3814552649112\n",
      "    val_log_likelihood: 1114.1175371048798\n",
      "    val_log_marginal: 689.9187565112094\n",
      "Train Epoch: 598 [512/17352 (3%)] Loss: -929.597717\n",
      "Train Epoch: 598 [10551/17352 (61%)] Loss: -962.207292\n",
      "Train Epoch: 598 [17253/17352 (99%)] Loss: -930.268609\n",
      "    epoch          : 598\n",
      "    loss           : -879.0483103256091\n",
      "    val_loss       : -662.5789569211732\n",
      "    val_log_likelihood: 1132.648754377144\n",
      "    val_log_marginal: 695.5538377725197\n",
      "Train Epoch: 599 [512/17352 (3%)] Loss: -914.436401\n",
      "Train Epoch: 599 [9817/17352 (57%)] Loss: -774.653432\n",
      "Train Epoch: 599 [16923/17352 (98%)] Loss: -762.506343\n",
      "    epoch          : 599\n",
      "    loss           : -881.3924773636849\n",
      "    val_loss       : -677.4855582807678\n",
      "    val_log_likelihood: 1130.0574491453287\n",
      "    val_log_marginal: 698.3027134457294\n",
      "Train Epoch: 600 [512/17352 (3%)] Loss: -926.197876\n",
      "Train Epoch: 600 [10654/17352 (61%)] Loss: -753.982882\n",
      "Train Epoch: 600 [16988/17352 (98%)] Loss: -967.924333\n",
      "    epoch          : 600\n",
      "    loss           : -879.4820596985377\n",
      "    val_loss       : -689.167179588861\n",
      "    val_log_likelihood: 1139.0034499206079\n",
      "    val_log_marginal: 708.2191932479\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0506_152815/checkpoint-epoch600.pth ...\n",
      "Train Epoch: 601 [512/17352 (3%)] Loss: -920.790405\n",
      "Train Epoch: 601 [10607/17352 (61%)] Loss: -778.952145\n",
      "Train Epoch: 601 [16992/17352 (98%)] Loss: -984.252261\n",
      "    epoch          : 601\n",
      "    loss           : -888.1356616299148\n",
      "    val_loss       : -675.75926814341\n",
      "    val_log_likelihood: 1132.7986637220288\n",
      "    val_log_marginal: 696.6609635057963\n",
      "Train Epoch: 602 [512/17352 (3%)] Loss: -926.772705\n",
      "Train Epoch: 602 [10499/17352 (61%)] Loss: -915.519734\n",
      "Train Epoch: 602 [16878/17352 (97%)] Loss: -990.195503\n",
      "    epoch          : 602\n",
      "    loss           : -872.2355017430782\n",
      "    val_loss       : -668.6888711129632\n",
      "    val_log_likelihood: 1131.3737879228836\n",
      "    val_log_marginal: 694.5875071394934\n",
      "Train Epoch: 603 [512/17352 (3%)] Loss: -925.671265\n",
      "Train Epoch: 603 [10634/17352 (61%)] Loss: -709.576923\n",
      "Train Epoch: 603 [16992/17352 (98%)] Loss: -784.300613\n",
      "    epoch          : 603\n",
      "    loss           : -828.8131359293435\n",
      "    val_loss       : -571.2330188401996\n",
      "    val_log_likelihood: 1098.1981067094782\n",
      "    val_log_marginal: 632.4112305031284\n",
      "Train Epoch: 604 [512/17352 (3%)] Loss: -880.146729\n",
      "Train Epoch: 604 [10624/17352 (61%)] Loss: -802.062116\n",
      "Train Epoch: 604 [17049/17352 (98%)] Loss: -938.943290\n",
      "    epoch          : 604\n",
      "    loss           : -808.4962956664771\n",
      "    val_loss       : -637.0576995313012\n",
      "    val_log_likelihood: 1119.7507029032868\n",
      "    val_log_marginal: 665.1605576357543\n",
      "Train Epoch: 605 [512/17352 (3%)] Loss: -915.039490\n",
      "Train Epoch: 605 [10965/17352 (63%)] Loss: -898.669127\n",
      "Train Epoch: 605 [17049/17352 (98%)] Loss: -994.123134\n",
      "    epoch          : 605\n",
      "    loss           : -873.7434993259675\n",
      "    val_loss       : -648.1190800623965\n",
      "    val_log_likelihood: 1121.1178109848117\n",
      "    val_log_marginal: 681.3902708940567\n",
      "Train Epoch: 606 [512/17352 (3%)] Loss: -917.337280\n",
      "Train Epoch: 606 [10858/17352 (63%)] Loss: -945.363110\n",
      "Train Epoch: 606 [16872/17352 (97%)] Loss: -840.166853\n",
      "    epoch          : 606\n",
      "    loss           : -883.4991564904849\n",
      "    val_loss       : -651.2453345045005\n",
      "    val_log_likelihood: 1116.0171474228068\n",
      "    val_log_marginal: 675.9241226851628\n",
      "Train Epoch: 607 [512/17352 (3%)] Loss: -935.601196\n",
      "Train Epoch: 607 [10536/17352 (61%)] Loss: -910.758946\n",
      "Train Epoch: 607 [17101/17352 (99%)] Loss: -925.568750\n",
      "    epoch          : 607\n",
      "    loss           : -871.8552135089275\n",
      "    val_loss       : -601.4182210116547\n",
      "    val_log_likelihood: 1112.2167399474076\n",
      "    val_log_marginal: 620.8057791339066\n",
      "Train Epoch: 608 [512/17352 (3%)] Loss: -861.524841\n",
      "Train Epoch: 608 [10339/17352 (60%)] Loss: -894.464608\n",
      "Train Epoch: 608 [16923/17352 (98%)] Loss: -676.115463\n",
      "    epoch          : 608\n",
      "    loss           : -645.7854633890722\n",
      "    val_loss       : -373.89534777978054\n",
      "    val_log_likelihood: 1067.6132864527472\n",
      "    val_log_marginal: 397.35678742046\n",
      "Train Epoch: 609 [512/17352 (3%)] Loss: -626.763489\n",
      "Train Epoch: 609 [10419/17352 (60%)] Loss: -755.700087\n",
      "Train Epoch: 609 [16939/17352 (98%)] Loss: -700.583398\n",
      "    epoch          : 609\n",
      "    loss           : -473.9473092324256\n",
      "    val_loss       : -523.7377788506052\n",
      "    val_log_likelihood: 1043.9836224245162\n",
      "    val_log_marginal: 566.8277720469376\n",
      "Train Epoch: 610 [512/17352 (3%)] Loss: -704.452637\n",
      "Train Epoch: 610 [10248/17352 (59%)] Loss: -549.608395\n",
      "Train Epoch: 610 [17263/17352 (99%)] Loss: -716.934809\n",
      "    epoch          : 610\n",
      "    loss           : -783.6553615236392\n",
      "    val_loss       : -592.9748789488999\n",
      "    val_log_likelihood: 1081.4729152136645\n",
      "    val_log_marginal: 620.1229241541765\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0506_152815/checkpoint-epoch610.pth ...\n",
      "Train Epoch: 611 [512/17352 (3%)] Loss: -593.919067\n",
      "Train Epoch: 611 [10696/17352 (62%)] Loss: -814.692268\n",
      "Train Epoch: 611 [17064/17352 (98%)] Loss: -924.631250\n",
      "    epoch          : 611\n",
      "    loss           : -778.1716400355543\n",
      "    val_loss       : -614.1541093730619\n",
      "    val_log_likelihood: 1081.6437758880907\n",
      "    val_log_marginal: 642.5187387252289\n",
      "Train Epoch: 612 [512/17352 (3%)] Loss: -872.574158\n",
      "Train Epoch: 612 [9416/17352 (54%)] Loss: -833.971792\n",
      "Train Epoch: 612 [17090/17352 (98%)] Loss: -927.156321\n",
      "    epoch          : 612\n",
      "    loss           : -836.5905220243044\n",
      "    val_loss       : -622.8434111795711\n",
      "    val_log_likelihood: 1093.3379666238477\n",
      "    val_log_marginal: 651.5803405498335\n",
      "Train Epoch: 613 [512/17352 (3%)] Loss: -878.008118\n",
      "Train Epoch: 613 [10198/17352 (59%)] Loss: -523.808455\n",
      "Train Epoch: 613 [16988/17352 (98%)] Loss: -919.167535\n",
      "    epoch          : 613\n",
      "    loss           : -753.9990360231468\n",
      "    val_loss       : -534.2038892593272\n",
      "    val_log_likelihood: 1074.576878653051\n",
      "    val_log_marginal: 564.7160630346145\n",
      "Train Epoch: 614 [512/17352 (3%)] Loss: -791.081543\n",
      "Train Epoch: 614 [10414/17352 (60%)] Loss: -805.735540\n",
      "Train Epoch: 614 [17253/17352 (99%)] Loss: -790.442285\n",
      "    epoch          : 614\n",
      "    loss           : -828.6976672763533\n",
      "    val_loss       : -634.4885026005361\n",
      "    val_log_likelihood: 1096.180017770816\n",
      "    val_log_marginal: 661.6891944119276\n",
      "Train Epoch: 615 [512/17352 (3%)] Loss: -896.957153\n",
      "Train Epoch: 615 [10590/17352 (61%)] Loss: -926.338323\n",
      "Train Epoch: 615 [17108/17352 (99%)] Loss: -840.270418\n",
      "    epoch          : 615\n",
      "    loss           : -855.6672392237562\n",
      "    val_loss       : -646.2841841228326\n",
      "    val_log_likelihood: 1104.0704069090564\n",
      "    val_log_marginal: 683.989615862174\n",
      "Train Epoch: 616 [512/17352 (3%)] Loss: -899.571045\n",
      "Train Epoch: 616 [10307/17352 (59%)] Loss: -911.799795\n",
      "Train Epoch: 616 [17133/17352 (99%)] Loss: -967.728277\n",
      "    epoch          : 616\n",
      "    loss           : -845.8272503431814\n",
      "    val_loss       : -653.1618869763389\n",
      "    val_log_likelihood: 1117.524905545923\n",
      "    val_log_marginal: 686.6645161228089\n",
      "Train Epoch: 617 [512/17352 (3%)] Loss: -920.967773\n",
      "Train Epoch: 617 [11051/17352 (64%)] Loss: -964.483423\n",
      "Train Epoch: 617 [17335/17352 (100%)] Loss: -852.665296\n",
      "    epoch          : 617\n",
      "    loss           : -870.1224131754886\n",
      "    val_loss       : -640.2229265647871\n",
      "    val_log_likelihood: 1122.0105169329508\n",
      "    val_log_marginal: 655.6100079020955\n",
      "Train Epoch: 618 [512/17352 (3%)] Loss: -706.710571\n",
      "Train Epoch: 618 [10658/17352 (61%)] Loss: -790.074631\n",
      "Train Epoch: 618 [16887/17352 (97%)] Loss: -959.214082\n",
      "    epoch          : 618\n",
      "    loss           : -868.4460914706522\n",
      "    val_loss       : -671.1978813509189\n",
      "    val_log_likelihood: 1127.5316849712012\n",
      "    val_log_marginal: 705.0258858864979\n",
      "Train Epoch: 619 [512/17352 (3%)] Loss: -935.731812\n",
      "Train Epoch: 619 [10742/17352 (62%)] Loss: -870.406596\n",
      "Train Epoch: 619 [17143/17352 (99%)] Loss: -908.398974\n",
      "    epoch          : 619\n",
      "    loss           : -875.7421342285945\n",
      "    val_loss       : -662.0897154411523\n",
      "    val_log_likelihood: 1124.0366130514774\n",
      "    val_log_marginal: 683.2876715159492\n",
      "Train Epoch: 620 [512/17352 (3%)] Loss: -909.639404\n",
      "Train Epoch: 620 [10491/17352 (60%)] Loss: -749.271232\n",
      "Train Epoch: 620 [17106/17352 (99%)] Loss: -990.367553\n",
      "    epoch          : 620\n",
      "    loss           : -888.0451746480314\n",
      "    val_loss       : -685.148763894271\n",
      "    val_log_likelihood: 1135.719482851733\n",
      "    val_log_marginal: 708.2467412165979\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0506_152815/checkpoint-epoch620.pth ...\n",
      "Train Epoch: 621 [512/17352 (3%)] Loss: -940.075623\n",
      "Train Epoch: 621 [9536/17352 (55%)] Loss: -857.773694\n",
      "Train Epoch: 621 [16883/17352 (97%)] Loss: -846.653125\n",
      "    epoch          : 621\n",
      "    loss           : -901.6685124914518\n",
      "    val_loss       : -693.3027719411047\n",
      "    val_log_likelihood: 1138.0225590578636\n",
      "    val_log_marginal: 715.9602939044215\n",
      "Train Epoch: 622 [512/17352 (3%)] Loss: -953.657959\n",
      "Train Epoch: 622 [10807/17352 (62%)] Loss: -1039.402995\n",
      "Train Epoch: 622 [17277/17352 (100%)] Loss: -1010.652769\n",
      "    epoch          : 622\n",
      "    loss           : -904.3628084838894\n",
      "    val_loss       : -691.330179752163\n",
      "    val_log_likelihood: 1139.9462383249472\n",
      "    val_log_marginal: 709.7783553110601\n",
      "Train Epoch: 623 [512/17352 (3%)] Loss: -960.143311\n",
      "Train Epoch: 623 [9949/17352 (57%)] Loss: -1006.236871\n",
      "Train Epoch: 623 [17277/17352 (100%)] Loss: -740.781250\n",
      "    epoch          : 623\n",
      "    loss           : -900.8301410930646\n",
      "    val_loss       : -661.7861164433267\n",
      "    val_log_likelihood: 1131.2607491480424\n",
      "    val_log_marginal: 688.3476168222168\n",
      "Train Epoch: 624 [512/17352 (3%)] Loss: -914.109070\n",
      "Train Epoch: 624 [10389/17352 (60%)] Loss: -984.642801\n",
      "Train Epoch: 624 [16923/17352 (98%)] Loss: -980.779654\n",
      "    epoch          : 624\n",
      "    loss           : -888.0322754127568\n",
      "    val_loss       : -689.6835325151501\n",
      "    val_log_likelihood: 1143.6886611842342\n",
      "    val_log_marginal: 707.6944402380187\n",
      "Train Epoch: 625 [512/17352 (3%)] Loss: -957.950195\n",
      "Train Epoch: 625 [10087/17352 (58%)] Loss: -958.426713\n",
      "Train Epoch: 625 [16878/17352 (97%)] Loss: -987.073547\n",
      "    epoch          : 625\n",
      "    loss           : -886.0052157396867\n",
      "    val_loss       : -673.0115796957556\n",
      "    val_log_likelihood: 1138.9581673992222\n",
      "    val_log_marginal: 697.9155414784195\n",
      "Train Epoch: 626 [512/17352 (3%)] Loss: -939.302979\n",
      "Train Epoch: 626 [10573/17352 (61%)] Loss: -853.599594\n",
      "Train Epoch: 626 [16988/17352 (98%)] Loss: -757.230611\n",
      "    epoch          : 626\n",
      "    loss           : -868.148915835735\n",
      "    val_loss       : -656.7887084383586\n",
      "    val_log_likelihood: 1129.4769718933583\n",
      "    val_log_marginal: 682.9926284731188\n",
      "Train Epoch: 627 [512/17352 (3%)] Loss: -722.348755\n",
      "Train Epoch: 627 [10704/17352 (62%)] Loss: -1008.676074\n",
      "Train Epoch: 627 [16887/17352 (97%)] Loss: -868.197452\n",
      "    epoch          : 627\n",
      "    loss           : -895.4198267731424\n",
      "    val_loss       : -670.1881073234068\n",
      "    val_log_likelihood: 1134.5306817023527\n",
      "    val_log_marginal: 695.4801380164209\n",
      "Train Epoch: 628 [512/17352 (3%)] Loss: -958.269409\n",
      "Train Epoch: 628 [10894/17352 (63%)] Loss: -951.125260\n",
      "Train Epoch: 628 [17143/17352 (99%)] Loss: -920.327099\n",
      "    epoch          : 628\n",
      "    loss           : -902.2327518176817\n",
      "    val_loss       : -659.4165894585045\n",
      "    val_log_likelihood: 1140.156443812717\n",
      "    val_log_marginal: 688.5187134690565\n",
      "Train Epoch: 629 [512/17352 (3%)] Loss: -954.597534\n",
      "Train Epoch: 629 [10121/17352 (58%)] Loss: -951.365697\n",
      "Train Epoch: 629 [17153/17352 (99%)] Loss: -965.458122\n",
      "    epoch          : 629\n",
      "    loss           : -893.8420180931481\n",
      "    val_loss       : -644.792127097699\n",
      "    val_log_likelihood: 1137.5619443389976\n",
      "    val_log_marginal: 670.6725038104966\n",
      "Train Epoch: 630 [512/17352 (3%)] Loss: -912.257812\n",
      "Train Epoch: 630 [10203/17352 (59%)] Loss: -934.006225\n",
      "Train Epoch: 630 [17253/17352 (99%)] Loss: -943.940397\n",
      "    epoch          : 630\n",
      "    loss           : -891.5131423435811\n",
      "    val_loss       : -592.0443617634515\n",
      "    val_log_likelihood: 1091.9203828342977\n",
      "    val_log_marginal: 615.383036859464\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0506_152815/checkpoint-epoch630.pth ...\n",
      "Train Epoch: 631 [512/17352 (3%)] Loss: -835.820312\n",
      "Train Epoch: 631 [10722/17352 (62%)] Loss: -1017.145833\n",
      "Train Epoch: 631 [16922/17352 (98%)] Loss: -931.283782\n",
      "    epoch          : 631\n",
      "    loss           : -850.9215995086873\n",
      "    val_loss       : -629.8027904646926\n",
      "    val_log_likelihood: 1117.8757899895095\n",
      "    val_log_marginal: 671.1959603601252\n",
      "Train Epoch: 632 [512/17352 (3%)] Loss: -914.562012\n",
      "Train Epoch: 632 [10061/17352 (58%)] Loss: -907.809832\n",
      "Train Epoch: 632 [16923/17352 (98%)] Loss: -753.956932\n",
      "    epoch          : 632\n",
      "    loss           : -814.0297414199134\n",
      "    val_loss       : -482.55173998541204\n",
      "    val_log_likelihood: 1108.9730878653017\n",
      "    val_log_marginal: 518.6511871548784\n",
      "Train Epoch: 633 [512/17352 (3%)] Loss: -715.561096\n",
      "Train Epoch: 633 [10378/17352 (60%)] Loss: -896.254010\n",
      "Train Epoch: 633 [17044/17352 (98%)] Loss: -812.543424\n",
      "    epoch          : 633\n",
      "    loss           : -804.1591009099174\n",
      "    val_loss       : -587.7252270084108\n",
      "    val_log_likelihood: 1113.7366689384141\n",
      "    val_log_marginal: 631.4318216859147\n",
      "Train Epoch: 634 [512/17352 (3%)] Loss: -876.750854\n",
      "Train Epoch: 634 [10420/17352 (60%)] Loss: -917.707679\n",
      "Train Epoch: 634 [17049/17352 (98%)] Loss: -895.017990\n",
      "    epoch          : 634\n",
      "    loss           : -840.9830423623134\n",
      "    val_loss       : -528.2426210454034\n",
      "    val_log_likelihood: 1107.0622459162628\n",
      "    val_log_marginal: 542.7003231208228\n",
      "Train Epoch: 635 [512/17352 (3%)] Loss: -772.982178\n",
      "Train Epoch: 635 [10468/17352 (60%)] Loss: -934.638564\n",
      "Train Epoch: 635 [17263/17352 (99%)] Loss: -526.458696\n",
      "    epoch          : 635\n",
      "    loss           : -793.2578276520317\n",
      "    val_loss       : -413.2879557428266\n",
      "    val_log_likelihood: 998.813904102134\n",
      "    val_log_marginal: 426.10279069279295\n",
      "Train Epoch: 636 [512/17352 (3%)] Loss: -704.932129\n",
      "Train Epoch: 636 [10588/17352 (61%)] Loss: -940.022321\n",
      "Train Epoch: 636 [17153/17352 (99%)] Loss: -618.843750\n",
      "    epoch          : 636\n",
      "    loss           : -778.9982426419207\n",
      "    val_loss       : -469.75813173114216\n",
      "    val_log_likelihood: 996.3599306463005\n",
      "    val_log_marginal: 524.8979095632375\n",
      "Train Epoch: 637 [512/17352 (3%)] Loss: -757.507385\n",
      "Train Epoch: 637 [10180/17352 (59%)] Loss: -719.108989\n",
      "Train Epoch: 637 [16872/17352 (97%)] Loss: -939.866875\n",
      "    epoch          : 637\n",
      "    loss           : -814.5312613491122\n",
      "    val_loss       : -617.9250707173076\n",
      "    val_log_likelihood: 1080.0905729763315\n",
      "    val_log_marginal: 647.8504755234063\n",
      "Train Epoch: 638 [512/17352 (3%)] Loss: -877.976562\n",
      "Train Epoch: 638 [9855/17352 (57%)] Loss: -903.620020\n",
      "Train Epoch: 638 [17335/17352 (100%)] Loss: -985.328844\n",
      "    epoch          : 638\n",
      "    loss           : -857.8541138233983\n",
      "    val_loss       : -645.1787952467085\n",
      "    val_log_likelihood: 1120.8437141760526\n",
      "    val_log_marginal: 674.0132313771988\n",
      "Train Epoch: 639 [512/17352 (3%)] Loss: -909.169434\n",
      "Train Epoch: 639 [10892/17352 (63%)] Loss: -727.177258\n",
      "Train Epoch: 639 [17044/17352 (98%)] Loss: -950.517187\n",
      "    epoch          : 639\n",
      "    loss           : -888.8912296753819\n",
      "    val_loss       : -642.9277206169127\n",
      "    val_log_likelihood: 1113.0287332572016\n",
      "    val_log_marginal: 675.3450530406041\n",
      "Train Epoch: 640 [512/17352 (3%)] Loss: -901.452454\n",
      "Train Epoch: 640 [10166/17352 (59%)] Loss: -1040.409071\n",
      "Train Epoch: 640 [16882/17352 (97%)] Loss: -791.322049\n",
      "    epoch          : 640\n",
      "    loss           : -892.8883643082914\n",
      "    val_loss       : -666.1073134650688\n",
      "    val_log_likelihood: 1135.4297669946432\n",
      "    val_log_marginal: 698.8551482382645\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0506_152815/checkpoint-epoch640.pth ...\n",
      "Train Epoch: 641 [512/17352 (3%)] Loss: -955.292297\n",
      "Train Epoch: 641 [9878/17352 (57%)] Loss: -1019.782661\n",
      "Train Epoch: 641 [17153/17352 (99%)] Loss: -1001.806981\n",
      "    epoch          : 641\n",
      "    loss           : -899.4216607522561\n",
      "    val_loss       : -666.3504885958716\n",
      "    val_log_likelihood: 1142.2805378391167\n",
      "    val_log_marginal: 696.6009817182515\n",
      "Train Epoch: 642 [512/17352 (3%)] Loss: -932.890747\n",
      "Train Epoch: 642 [10815/17352 (62%)] Loss: -894.396291\n",
      "Train Epoch: 642 [16934/17352 (98%)] Loss: -999.988406\n",
      "    epoch          : 642\n",
      "    loss           : -901.3860538035067\n",
      "    val_loss       : -685.1279152923896\n",
      "    val_log_likelihood: 1145.7064652138693\n",
      "    val_log_marginal: 710.1990551792062\n",
      "Train Epoch: 643 [512/17352 (3%)] Loss: -943.247681\n",
      "Train Epoch: 643 [10431/17352 (60%)] Loss: -911.667714\n",
      "Train Epoch: 643 [16988/17352 (98%)] Loss: -824.331938\n",
      "    epoch          : 643\n",
      "    loss           : -895.7732435702155\n",
      "    val_loss       : -679.4054679247322\n",
      "    val_log_likelihood: 1139.6815218013858\n",
      "    val_log_marginal: 701.2604330003854\n",
      "Train Epoch: 644 [512/17352 (3%)] Loss: -951.183960\n",
      "Train Epoch: 644 [10068/17352 (58%)] Loss: -896.067153\n",
      "Train Epoch: 644 [16992/17352 (98%)] Loss: -766.140121\n",
      "    epoch          : 644\n",
      "    loss           : -904.6706174010243\n",
      "    val_loss       : -684.7561040772562\n",
      "    val_log_likelihood: 1145.7215962577955\n",
      "    val_log_marginal: 709.1354649329004\n",
      "Train Epoch: 645 [512/17352 (3%)] Loss: -752.516846\n",
      "Train Epoch: 645 [10400/17352 (60%)] Loss: -1005.170642\n",
      "Train Epoch: 645 [17277/17352 (100%)] Loss: -950.899044\n",
      "    epoch          : 645\n",
      "    loss           : -910.4159179021003\n",
      "    val_loss       : -672.187303620965\n",
      "    val_log_likelihood: 1141.821024004175\n",
      "    val_log_marginal: 694.7196625109239\n",
      "Train Epoch: 646 [512/17352 (3%)] Loss: -943.741394\n",
      "Train Epoch: 646 [11039/17352 (64%)] Loss: -886.578211\n",
      "Train Epoch: 646 [17106/17352 (99%)] Loss: -812.156351\n",
      "    epoch          : 646\n",
      "    loss           : -907.0822979075181\n",
      "    val_loss       : -687.7526418674763\n",
      "    val_log_likelihood: 1152.3995099214103\n",
      "    val_log_marginal: 710.0624773914566\n",
      "Train Epoch: 647 [512/17352 (3%)] Loss: -943.703735\n",
      "Train Epoch: 647 [10059/17352 (58%)] Loss: -793.419304\n",
      "Train Epoch: 647 [16887/17352 (97%)] Loss: -836.409133\n",
      "    epoch          : 647\n",
      "    loss           : -865.4625949566088\n",
      "    val_loss       : -669.1507257653693\n",
      "    val_log_likelihood: 1152.5044005116197\n",
      "    val_log_marginal: 690.4763724761494\n",
      "Train Epoch: 648 [512/17352 (3%)] Loss: -938.694031\n",
      "Train Epoch: 648 [9989/17352 (58%)] Loss: -479.040739\n",
      "Train Epoch: 648 [16883/17352 (97%)] Loss: -668.553486\n",
      "    epoch          : 648\n",
      "    loss           : -393.8222796444521\n",
      "    val_loss       : -346.07814098351804\n",
      "    val_log_likelihood: 1043.5370494449896\n",
      "    val_log_marginal: 394.8503185446742\n",
      "Train Epoch: 649 [512/17352 (3%)] Loss: -684.773987\n",
      "Train Epoch: 649 [10049/17352 (58%)] Loss: -679.669819\n",
      "Train Epoch: 649 [17153/17352 (99%)] Loss: -981.155917\n",
      "    epoch          : 649\n",
      "    loss           : -733.2936706469396\n",
      "    val_loss       : -510.4564714545006\n",
      "    val_log_likelihood: 1061.8337631063841\n",
      "    val_log_marginal: 541.0598939896092\n",
      "Train Epoch: 650 [512/17352 (3%)] Loss: -792.757629\n",
      "Train Epoch: 650 [10017/17352 (58%)] Loss: -959.137912\n",
      "Train Epoch: 650 [17143/17352 (99%)] Loss: -943.844271\n",
      "    epoch          : 650\n",
      "    loss           : -833.7334093293182\n",
      "    val_loss       : -616.0541701094608\n",
      "    val_log_likelihood: 1119.8839133475954\n",
      "    val_log_marginal: 645.6130530814875\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0506_152815/checkpoint-epoch650.pth ...\n",
      "Train Epoch: 651 [512/17352 (3%)] Loss: -657.951904\n",
      "Train Epoch: 651 [10641/17352 (61%)] Loss: -922.693238\n",
      "Train Epoch: 651 [16922/17352 (98%)] Loss: -1006.723744\n",
      "    epoch          : 651\n",
      "    loss           : -881.6961273291822\n",
      "    val_loss       : -692.5314419908511\n",
      "    val_log_likelihood: 1144.2017416245656\n",
      "    val_log_marginal: 717.3427943447884\n",
      "Train Epoch: 652 [512/17352 (3%)] Loss: -941.250671\n",
      "Train Epoch: 652 [10074/17352 (58%)] Loss: -939.655833\n",
      "Train Epoch: 652 [16934/17352 (98%)] Loss: -983.591133\n",
      "    epoch          : 652\n",
      "    loss           : -901.9870365254271\n",
      "    val_loss       : -676.5512635544459\n",
      "    val_log_likelihood: 1138.0872171865851\n",
      "    val_log_marginal: 695.992059575577\n",
      "Train Epoch: 653 [512/17352 (3%)] Loss: -952.145447\n",
      "Train Epoch: 653 [10026/17352 (58%)] Loss: -986.516101\n",
      "Train Epoch: 653 [16883/17352 (97%)] Loss: -861.940848\n",
      "    epoch          : 653\n",
      "    loss           : -916.0647949798375\n",
      "    val_loss       : -701.0298328396184\n",
      "    val_log_likelihood: 1151.9848224543398\n",
      "    val_log_marginal: 722.2014105171421\n",
      "Train Epoch: 654 [512/17352 (3%)] Loss: -964.147583\n",
      "Train Epoch: 654 [9870/17352 (57%)] Loss: -788.664627\n",
      "Train Epoch: 654 [16922/17352 (98%)] Loss: -960.338383\n",
      "    epoch          : 654\n",
      "    loss           : -916.7505285097493\n",
      "    val_loss       : -689.2669912185113\n",
      "    val_log_likelihood: 1146.1744860436427\n",
      "    val_log_marginal: 710.7255921527618\n",
      "Train Epoch: 655 [512/17352 (3%)] Loss: -965.205444\n",
      "Train Epoch: 655 [10798/17352 (62%)] Loss: -1017.346215\n",
      "Train Epoch: 655 [16992/17352 (98%)] Loss: -996.904272\n",
      "    epoch          : 655\n",
      "    loss           : -905.7398341334547\n",
      "    val_loss       : -686.1115954262582\n",
      "    val_log_likelihood: 1149.2669247376434\n",
      "    val_log_marginal: 707.2553883489239\n",
      "Train Epoch: 656 [512/17352 (3%)] Loss: -941.490845\n",
      "Train Epoch: 656 [9700/17352 (56%)] Loss: -943.692893\n",
      "Train Epoch: 656 [17277/17352 (100%)] Loss: -1052.501302\n",
      "    epoch          : 656\n",
      "    loss           : -914.5183771403794\n",
      "    val_loss       : -680.7747827525932\n",
      "    val_log_likelihood: 1145.5912194211262\n",
      "    val_log_marginal: 708.1016677148655\n",
      "Train Epoch: 657 [512/17352 (3%)] Loss: -962.308960\n",
      "Train Epoch: 657 [10745/17352 (62%)] Loss: -1007.513231\n",
      "Train Epoch: 657 [17277/17352 (100%)] Loss: -847.909077\n",
      "    epoch          : 657\n",
      "    loss           : -903.2817091411215\n",
      "    val_loss       : -670.3933378045809\n",
      "    val_log_likelihood: 1144.3108316418786\n",
      "    val_log_marginal: 686.5332861779564\n",
      "Train Epoch: 658 [512/17352 (3%)] Loss: -948.051941\n",
      "Train Epoch: 658 [10136/17352 (58%)] Loss: -847.314931\n",
      "Train Epoch: 658 [16923/17352 (98%)] Loss: -810.890955\n",
      "    epoch          : 658\n",
      "    loss           : -899.0709433854644\n",
      "    val_loss       : -663.8946069800284\n",
      "    val_log_likelihood: 1146.6140960731152\n",
      "    val_log_marginal: 684.9026313217745\n",
      "Train Epoch: 659 [512/17352 (3%)] Loss: -925.108643\n",
      "Train Epoch: 659 [10464/17352 (60%)] Loss: -964.318131\n",
      "Train Epoch: 659 [16882/17352 (97%)] Loss: -976.741875\n",
      "    epoch          : 659\n",
      "    loss           : -905.8063695726836\n",
      "    val_loss       : -690.1942635450032\n",
      "    val_log_likelihood: 1153.4930479978204\n",
      "    val_log_marginal: 716.7293493453748\n",
      "Train Epoch: 660 [512/17352 (3%)] Loss: -939.210388\n",
      "Train Epoch: 660 [10297/17352 (59%)] Loss: -760.413239\n",
      "Train Epoch: 660 [16922/17352 (98%)] Loss: -831.897633\n",
      "    epoch          : 660\n",
      "    loss           : -915.9091389360041\n",
      "    val_loss       : -687.6348025636026\n",
      "    val_log_likelihood: 1151.5038761423734\n",
      "    val_log_marginal: 710.4386373680405\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0506_152815/checkpoint-epoch660.pth ...\n",
      "Train Epoch: 661 [512/17352 (3%)] Loss: -974.320190\n",
      "Train Epoch: 661 [10503/17352 (61%)] Loss: -959.855842\n",
      "Train Epoch: 661 [16922/17352 (98%)] Loss: -866.195038\n",
      "    epoch          : 661\n",
      "    loss           : -911.8712650915634\n",
      "    val_loss       : -662.0388912560445\n",
      "    val_log_likelihood: 1146.7067418613651\n",
      "    val_log_marginal: 683.6121589806417\n",
      "Train Epoch: 662 [512/17352 (3%)] Loss: -964.201294\n",
      "Train Epoch: 662 [10113/17352 (58%)] Loss: -929.748027\n",
      "Train Epoch: 662 [17133/17352 (99%)] Loss: -705.141896\n",
      "    epoch          : 662\n",
      "    loss           : -904.3766397529155\n",
      "    val_loss       : -630.5419068391701\n",
      "    val_log_likelihood: 1130.875737406866\n",
      "    val_log_marginal: 663.7069855350175\n",
      "Train Epoch: 663 [512/17352 (3%)] Loss: -930.248413\n",
      "Train Epoch: 663 [9934/17352 (57%)] Loss: -939.558813\n",
      "Train Epoch: 663 [17090/17352 (98%)] Loss: -674.858938\n",
      "    epoch          : 663\n",
      "    loss           : -857.5968075570348\n",
      "    val_loss       : -580.4083293826419\n",
      "    val_log_likelihood: 1106.7994864711247\n",
      "    val_log_marginal: 626.659795693462\n",
      "Train Epoch: 664 [512/17352 (3%)] Loss: -886.604126\n",
      "Train Epoch: 664 [10230/17352 (59%)] Loss: -828.290856\n",
      "Train Epoch: 664 [16882/17352 (97%)] Loss: -924.485077\n",
      "    epoch          : 664\n",
      "    loss           : -859.442136034937\n",
      "    val_loss       : -639.4462300860592\n",
      "    val_log_likelihood: 1134.0090614088226\n",
      "    val_log_marginal: 669.3396184382979\n",
      "Train Epoch: 665 [512/17352 (3%)] Loss: -942.400635\n",
      "Train Epoch: 665 [10179/17352 (59%)] Loss: -820.159983\n",
      "Train Epoch: 665 [16934/17352 (98%)] Loss: -972.891577\n",
      "    epoch          : 665\n",
      "    loss           : -877.779544620609\n",
      "    val_loss       : -638.8310011345046\n",
      "    val_log_likelihood: 1131.8073716728825\n",
      "    val_log_marginal: 668.8147867498973\n",
      "Train Epoch: 666 [512/17352 (3%)] Loss: -927.966187\n",
      "Train Epoch: 666 [10047/17352 (58%)] Loss: -927.864890\n",
      "Train Epoch: 666 [17090/17352 (98%)] Loss: -973.090262\n",
      "    epoch          : 666\n",
      "    loss           : -881.0112276184659\n",
      "    val_loss       : -650.7204791436383\n",
      "    val_log_likelihood: 1147.220526999582\n",
      "    val_log_marginal: 678.815280650126\n",
      "Train Epoch: 667 [512/17352 (3%)] Loss: -900.369507\n",
      "Train Epoch: 667 [9807/17352 (57%)] Loss: -996.418318\n",
      "Train Epoch: 667 [16883/17352 (97%)] Loss: -752.056381\n",
      "    epoch          : 667\n",
      "    loss           : -881.7092675982113\n",
      "    val_loss       : -669.9396376223898\n",
      "    val_log_likelihood: 1154.4059245764824\n",
      "    val_log_marginal: 693.3699505078893\n",
      "Train Epoch: 668 [512/17352 (3%)] Loss: -937.880859\n",
      "Train Epoch: 668 [10418/17352 (60%)] Loss: -1003.648819\n",
      "Train Epoch: 668 [17016/17352 (98%)] Loss: -728.856384\n",
      "    epoch          : 668\n",
      "    loss           : -869.7319853554894\n",
      "    val_loss       : -629.106565519369\n",
      "    val_log_likelihood: 1129.8618783968188\n",
      "    val_log_marginal: 652.9566520662162\n",
      "Train Epoch: 669 [512/17352 (3%)] Loss: -914.749268\n",
      "Train Epoch: 669 [10617/17352 (61%)] Loss: -878.910371\n",
      "Train Epoch: 669 [16872/17352 (97%)] Loss: -805.619271\n",
      "    epoch          : 669\n",
      "    loss           : -889.556292033848\n",
      "    val_loss       : -636.5790103016944\n",
      "    val_log_likelihood: 1147.8572404239517\n",
      "    val_log_marginal: 659.3739999593148\n",
      "Train Epoch: 670 [512/17352 (3%)] Loss: -929.644165\n",
      "Train Epoch: 670 [10823/17352 (62%)] Loss: -875.956287\n",
      "Train Epoch: 670 [17263/17352 (99%)] Loss: -833.522064\n",
      "    epoch          : 670\n",
      "    loss           : -865.3264227995763\n",
      "    val_loss       : -548.4500211385854\n",
      "    val_log_likelihood: 1140.4498223140815\n",
      "    val_log_marginal: 585.0864913188972\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0506_152815/checkpoint-epoch670.pth ...\n",
      "Train Epoch: 671 [512/17352 (3%)] Loss: -851.612305\n",
      "Train Epoch: 671 [10665/17352 (61%)] Loss: -924.446326\n",
      "Train Epoch: 671 [17126/17352 (99%)] Loss: -986.374583\n",
      "    epoch          : 671\n",
      "    loss           : -885.7126105509894\n",
      "    val_loss       : -664.677493040614\n",
      "    val_log_likelihood: 1148.877897364477\n",
      "    val_log_marginal: 690.5975129770626\n",
      "Train Epoch: 672 [512/17352 (3%)] Loss: -958.015381\n",
      "Train Epoch: 672 [10488/17352 (60%)] Loss: -1039.728299\n",
      "Train Epoch: 672 [16882/17352 (97%)] Loss: -808.926226\n",
      "    epoch          : 672\n",
      "    loss           : -889.3777087334219\n",
      "    val_loss       : -644.5837164719924\n",
      "    val_log_likelihood: 1152.817545614948\n",
      "    val_log_marginal: 671.2087239627942\n",
      "Train Epoch: 673 [512/17352 (3%)] Loss: -946.728027\n",
      "Train Epoch: 673 [10014/17352 (58%)] Loss: -855.819378\n",
      "Train Epoch: 673 [16872/17352 (97%)] Loss: -918.250702\n",
      "    epoch          : 673\n",
      "    loss           : -894.0422880063003\n",
      "    val_loss       : -624.0003852741906\n",
      "    val_log_likelihood: 1155.1974967331869\n",
      "    val_log_marginal: 651.6432548933658\n",
      "Train Epoch: 674 [512/17352 (3%)] Loss: -905.577148\n",
      "Train Epoch: 674 [10889/17352 (63%)] Loss: -993.034264\n",
      "Train Epoch: 674 [17016/17352 (98%)] Loss: -934.945277\n",
      "    epoch          : 674\n",
      "    loss           : -895.5694525701934\n",
      "    val_loss       : -659.4584322313381\n",
      "    val_log_likelihood: 1147.3393876913258\n",
      "    val_log_marginal: 684.2464315514583\n",
      "Train Epoch: 675 [512/17352 (3%)] Loss: -950.190369\n",
      "Train Epoch: 675 [10471/17352 (60%)] Loss: -972.750363\n",
      "Train Epoch: 675 [16958/17352 (98%)] Loss: -988.576808\n",
      "    epoch          : 675\n",
      "    loss           : -905.2322490319735\n",
      "    val_loss       : -681.5758394687431\n",
      "    val_log_likelihood: 1152.1667908091797\n",
      "    val_log_marginal: 703.5358044064549\n",
      "Train Epoch: 676 [512/17352 (3%)] Loss: -956.648926\n",
      "Train Epoch: 676 [10987/17352 (63%)] Loss: -764.572219\n",
      "Train Epoch: 676 [16923/17352 (98%)] Loss: -931.028093\n",
      "    epoch          : 676\n",
      "    loss           : -921.5344443918983\n",
      "    val_loss       : -678.7846957369527\n",
      "    val_log_likelihood: 1160.5676786322456\n",
      "    val_log_marginal: 706.7168191621022\n",
      "Train Epoch: 677 [512/17352 (3%)] Loss: -969.799500\n",
      "Train Epoch: 677 [10041/17352 (58%)] Loss: -955.840468\n",
      "Train Epoch: 677 [16887/17352 (97%)] Loss: -806.131702\n",
      "    epoch          : 677\n",
      "    loss           : -921.8326649234523\n",
      "    val_loss       : -682.4863970709212\n",
      "    val_log_likelihood: 1163.1407412876854\n",
      "    val_log_marginal: 706.6699636516805\n",
      "Train Epoch: 678 [512/17352 (3%)] Loss: -966.605896\n",
      "Train Epoch: 678 [10465/17352 (60%)] Loss: -900.815652\n",
      "Train Epoch: 678 [17335/17352 (100%)] Loss: -989.762106\n",
      "    epoch          : 678\n",
      "    loss           : -922.036843195448\n",
      "    val_loss       : -660.7846419547922\n",
      "    val_log_likelihood: 1153.9004481934792\n",
      "    val_log_marginal: 685.178365822163\n",
      "Train Epoch: 679 [512/17352 (3%)] Loss: -939.361755\n",
      "Train Epoch: 679 [10417/17352 (60%)] Loss: -1000.547402\n",
      "Train Epoch: 679 [17044/17352 (98%)] Loss: -901.949004\n",
      "    epoch          : 679\n",
      "    loss           : -925.4906441234884\n",
      "    val_loss       : -697.1036666172631\n",
      "    val_log_likelihood: 1171.3190117794666\n",
      "    val_log_marginal: 719.6933541132461\n",
      "Train Epoch: 680 [512/17352 (3%)] Loss: -960.042603\n",
      "Train Epoch: 680 [9976/17352 (57%)] Loss: -835.802658\n",
      "Train Epoch: 680 [16922/17352 (98%)] Loss: -792.882867\n",
      "    epoch          : 680\n",
      "    loss           : -924.4437593722969\n",
      "    val_loss       : -691.2509311947771\n",
      "    val_log_likelihood: 1164.5821213788638\n",
      "    val_log_marginal: 709.5924141833095\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0506_152815/checkpoint-epoch680.pth ...\n",
      "Train Epoch: 681 [512/17352 (3%)] Loss: -961.999268\n",
      "Train Epoch: 681 [10466/17352 (60%)] Loss: -990.560502\n",
      "Train Epoch: 681 [17277/17352 (100%)] Loss: -1018.452553\n",
      "    epoch          : 681\n",
      "    loss           : -926.90187161816\n",
      "    val_loss       : -634.513077803201\n",
      "    val_log_likelihood: 1134.7753731724674\n",
      "    val_log_marginal: 660.7031728657213\n",
      "Train Epoch: 682 [512/17352 (3%)] Loss: -711.408569\n",
      "Train Epoch: 682 [9999/17352 (58%)] Loss: -876.057100\n",
      "Train Epoch: 682 [17044/17352 (98%)] Loss: -997.813366\n",
      "    epoch          : 682\n",
      "    loss           : -906.9740723771537\n",
      "    val_loss       : -646.6237985440264\n",
      "    val_log_likelihood: 1154.9640746044606\n",
      "    val_log_marginal: 672.9808183644217\n",
      "Train Epoch: 683 [512/17352 (3%)] Loss: -927.971008\n",
      "Train Epoch: 683 [9967/17352 (57%)] Loss: -850.452100\n",
      "Train Epoch: 683 [16887/17352 (97%)] Loss: -996.263154\n",
      "    epoch          : 683\n",
      "    loss           : -916.7024236446745\n",
      "    val_loss       : -670.1355748853639\n",
      "    val_log_likelihood: 1154.0565010513278\n",
      "    val_log_marginal: 692.8432923254627\n",
      "Train Epoch: 684 [512/17352 (3%)] Loss: -967.422852\n",
      "Train Epoch: 684 [10297/17352 (59%)] Loss: -850.626319\n",
      "Train Epoch: 684 [17153/17352 (99%)] Loss: -974.984811\n",
      "    epoch          : 684\n",
      "    loss           : -918.5765595871515\n",
      "    val_loss       : -642.7460799357211\n",
      "    val_log_likelihood: 1154.221544775241\n",
      "    val_log_marginal: 689.3749073149379\n",
      "Train Epoch: 685 [512/17352 (3%)] Loss: -918.226440\n",
      "Train Epoch: 685 [10534/17352 (61%)] Loss: -955.418342\n",
      "Train Epoch: 685 [17143/17352 (99%)] Loss: -984.332917\n",
      "    epoch          : 685\n",
      "    loss           : -906.6883464070012\n",
      "    val_loss       : -629.5247544979342\n",
      "    val_log_likelihood: 1141.8413047375245\n",
      "    val_log_marginal: 654.2948826544213\n",
      "Train Epoch: 686 [512/17352 (3%)] Loss: -924.559753\n",
      "Train Epoch: 686 [10063/17352 (58%)] Loss: -603.406720\n",
      "Train Epoch: 686 [16958/17352 (98%)] Loss: -757.213805\n",
      "    epoch          : 686\n",
      "    loss           : -834.9259273944401\n",
      "    val_loss       : -570.8587394629108\n",
      "    val_log_likelihood: 1111.156258589217\n",
      "    val_log_marginal: 596.469876321959\n",
      "Train Epoch: 687 [512/17352 (3%)] Loss: -886.921204\n",
      "Train Epoch: 687 [10038/17352 (58%)] Loss: -911.482098\n",
      "Train Epoch: 687 [16872/17352 (97%)] Loss: -802.702494\n",
      "    epoch          : 687\n",
      "    loss           : -814.4593455359972\n",
      "    val_loss       : -472.32915866834753\n",
      "    val_log_likelihood: 1095.3695800980322\n",
      "    val_log_marginal: 508.718833907433\n",
      "Train Epoch: 688 [512/17352 (3%)] Loss: -805.288147\n",
      "Train Epoch: 688 [10718/17352 (62%)] Loss: -767.159471\n",
      "Train Epoch: 688 [16872/17352 (97%)] Loss: -855.311359\n",
      "    epoch          : 688\n",
      "    loss           : -741.0642809118366\n",
      "    val_loss       : -567.8259825346031\n",
      "    val_log_likelihood: 1105.6399893833286\n",
      "    val_log_marginal: 595.0205064139222\n",
      "Train Epoch: 689 [512/17352 (3%)] Loss: -891.831299\n",
      "Train Epoch: 689 [10378/17352 (60%)] Loss: -739.519980\n",
      "Train Epoch: 689 [16992/17352 (98%)] Loss: -865.806406\n",
      "    epoch          : 689\n",
      "    loss           : -809.8976693211002\n",
      "    val_loss       : -603.5083896400957\n",
      "    val_log_likelihood: 1122.5110181733553\n",
      "    val_log_marginal: 633.9709353341261\n",
      "Train Epoch: 690 [512/17352 (3%)] Loss: -897.686401\n",
      "Train Epoch: 690 [10292/17352 (59%)] Loss: -768.953194\n",
      "Train Epoch: 690 [16923/17352 (98%)] Loss: -912.604797\n",
      "    epoch          : 690\n",
      "    loss           : -818.9703814445544\n",
      "    val_loss       : -568.7203066144777\n",
      "    val_log_likelihood: 1116.5414971785224\n",
      "    val_log_marginal: 597.1160772816625\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0506_152815/checkpoint-epoch690.pth ...\n",
      "Train Epoch: 691 [512/17352 (3%)] Loss: -842.991028\n",
      "Train Epoch: 691 [10674/17352 (62%)] Loss: -919.243019\n",
      "Train Epoch: 691 [17016/17352 (98%)] Loss: -753.069797\n",
      "    epoch          : 691\n",
      "    loss           : -826.6177622818954\n",
      "    val_loss       : -581.6543160010278\n",
      "    val_log_likelihood: 1115.9641133146768\n",
      "    val_log_marginal: 644.1154534883616\n",
      "Train Epoch: 692 [512/17352 (3%)] Loss: -840.077026\n",
      "Train Epoch: 692 [10172/17352 (59%)] Loss: -850.915860\n",
      "Train Epoch: 692 [17090/17352 (98%)] Loss: -397.129161\n",
      "    epoch          : 692\n",
      "    loss           : -767.260766529412\n",
      "    val_loss       : -329.2021716651111\n",
      "    val_log_likelihood: 996.0993311207274\n",
      "    val_log_marginal: 389.48488978162004\n",
      "Train Epoch: 693 [512/17352 (3%)] Loss: -646.907959\n",
      "Train Epoch: 693 [10879/17352 (63%)] Loss: -858.232447\n",
      "Train Epoch: 693 [17143/17352 (99%)] Loss: 1960.357971\n",
      "    epoch          : 693\n",
      "    loss           : 127.47335152400335\n",
      "    val_loss       : 1630.8820180442106\n",
      "    val_log_likelihood: -195.96841035560615\n",
      "    val_log_marginal: -1568.8555867924533\n",
      "Train Epoch: 694 [512/17352 (3%)] Loss: 907.556946\n",
      "Train Epoch: 694 [10285/17352 (59%)] Loss: -413.997621\n",
      "Train Epoch: 694 [16922/17352 (98%)] Loss: 435.581804\n",
      "    epoch          : 694\n",
      "    loss           : -61.960877945989225\n",
      "    val_loss       : 216.43603608896834\n",
      "    val_log_likelihood: 990.6621108497984\n",
      "    val_log_marginal: -97.81100247391446\n",
      "Train Epoch: 695 [512/17352 (3%)] Loss: -61.595325\n",
      "Train Epoch: 695 [10727/17352 (62%)] Loss: -648.768466\n",
      "Train Epoch: 695 [17335/17352 (100%)] Loss: -503.394590\n",
      "    epoch          : 695\n",
      "    loss           : -635.8596761014105\n",
      "    val_loss       : -293.2207182309303\n",
      "    val_log_likelihood: 1084.6306642553648\n",
      "    val_log_marginal: 328.15810215236723\n",
      "Train Epoch: 696 [512/17352 (3%)] Loss: -509.269745\n",
      "Train Epoch: 696 [10210/17352 (59%)] Loss: -839.517352\n",
      "Train Epoch: 696 [17090/17352 (98%)] Loss: -636.233843\n",
      "    epoch          : 696\n",
      "    loss           : -726.3915981157749\n",
      "    val_loss       : -580.4053543173192\n",
      "    val_log_likelihood: 1102.9908524222624\n",
      "    val_log_marginal: 604.5734613061485\n",
      "Train Epoch: 697 [512/17352 (3%)] Loss: -798.318726\n",
      "Train Epoch: 697 [10911/17352 (63%)] Loss: -740.919761\n",
      "Train Epoch: 697 [17108/17352 (99%)] Loss: -940.251142\n",
      "    epoch          : 697\n",
      "    loss           : -854.1679263830838\n",
      "    val_loss       : -680.9267857683556\n",
      "    val_log_likelihood: 1125.5756410053998\n",
      "    val_log_marginal: 701.1858409547375\n",
      "Train Epoch: 698 [512/17352 (3%)] Loss: -923.202515\n",
      "Train Epoch: 698 [10197/17352 (59%)] Loss: -709.864160\n",
      "Train Epoch: 698 [17106/17352 (99%)] Loss: -882.055804\n",
      "    epoch          : 698\n",
      "    loss           : -891.048918231612\n",
      "    val_loss       : -685.7842152921655\n",
      "    val_log_likelihood: 1124.50587728444\n",
      "    val_log_marginal: 703.8741852335595\n",
      "Train Epoch: 699 [512/17352 (3%)] Loss: -937.424011\n",
      "Train Epoch: 699 [10620/17352 (61%)] Loss: -972.875208\n",
      "Train Epoch: 699 [17253/17352 (99%)] Loss: -759.787679\n",
      "    epoch          : 699\n",
      "    loss           : -903.2979240473642\n",
      "    val_loss       : -704.2790137571831\n",
      "    val_log_likelihood: 1137.5661502613493\n",
      "    val_log_marginal: 721.7068161128868\n",
      "Train Epoch: 700 [512/17352 (3%)] Loss: -949.751953\n",
      "Train Epoch: 700 [9996/17352 (58%)] Loss: -961.854333\n",
      "Train Epoch: 700 [17106/17352 (99%)] Loss: -849.786558\n",
      "    epoch          : 700\n",
      "    loss           : -911.2517509611006\n",
      "    val_loss       : -688.3236645146865\n",
      "    val_log_likelihood: 1135.786108703877\n",
      "    val_log_marginal: 711.8661723241381\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0506_152815/checkpoint-epoch700.pth ...\n",
      "Train Epoch: 701 [512/17352 (3%)] Loss: -931.054382\n",
      "Train Epoch: 701 [9864/17352 (57%)] Loss: -944.042519\n",
      "Train Epoch: 701 [17153/17352 (99%)] Loss: -860.376215\n",
      "    epoch          : 701\n",
      "    loss           : -914.0709264136106\n",
      "    val_loss       : -694.133147346607\n",
      "    val_log_likelihood: 1141.7898902703896\n",
      "    val_log_marginal: 721.8199917398488\n",
      "Train Epoch: 702 [512/17352 (3%)] Loss: -953.739136\n",
      "Train Epoch: 702 [10451/17352 (60%)] Loss: -1001.131329\n",
      "Train Epoch: 702 [16958/17352 (98%)] Loss: -1020.602745\n",
      "    epoch          : 702\n",
      "    loss           : -914.0371894820074\n",
      "    val_loss       : -687.5408547641873\n",
      "    val_log_likelihood: 1136.7402033919175\n",
      "    val_log_marginal: 708.878508969067\n",
      "Train Epoch: 703 [512/17352 (3%)] Loss: -956.816467\n",
      "Train Epoch: 703 [10289/17352 (59%)] Loss: -1002.806180\n",
      "Train Epoch: 703 [16887/17352 (97%)] Loss: -832.030844\n",
      "    epoch          : 703\n",
      "    loss           : -919.1222373849806\n",
      "    val_loss       : -706.0838498989153\n",
      "    val_log_likelihood: 1149.2484688267864\n",
      "    val_log_marginal: 725.4731436915828\n",
      "Train Epoch: 704 [512/17352 (3%)] Loss: -956.498413\n",
      "Train Epoch: 704 [10723/17352 (62%)] Loss: -1028.013326\n",
      "Train Epoch: 704 [17049/17352 (98%)] Loss: -1012.034109\n",
      "    epoch          : 704\n",
      "    loss           : -925.1694914914415\n",
      "    val_loss       : -721.4013429549562\n",
      "    val_log_likelihood: 1160.7280499770486\n",
      "    val_log_marginal: 739.7466175068568\n",
      "Train Epoch: 705 [512/17352 (3%)] Loss: -971.705994\n",
      "Train Epoch: 705 [9759/17352 (56%)] Loss: -935.027672\n",
      "Train Epoch: 705 [16988/17352 (98%)] Loss: -974.243721\n",
      "    epoch          : 705\n",
      "    loss           : -918.5227093608644\n",
      "    val_loss       : -704.6383703980978\n",
      "    val_log_likelihood: 1154.8334904126161\n",
      "    val_log_marginal: 724.9520801033689\n",
      "Train Epoch: 706 [512/17352 (3%)] Loss: -796.073486\n",
      "Train Epoch: 706 [10203/17352 (59%)] Loss: -1004.739993\n",
      "Train Epoch: 706 [17106/17352 (99%)] Loss: -987.077497\n",
      "    epoch          : 706\n",
      "    loss           : -921.0099411094662\n",
      "    val_loss       : -708.3203244654702\n",
      "    val_log_likelihood: 1154.9238804295405\n",
      "    val_log_marginal: 729.5943138356921\n",
      "Train Epoch: 707 [512/17352 (3%)] Loss: -962.766602\n",
      "Train Epoch: 707 [10377/17352 (60%)] Loss: -803.353084\n",
      "Train Epoch: 707 [17016/17352 (98%)] Loss: -723.968900\n",
      "    epoch          : 707\n",
      "    loss           : -920.5343331349446\n",
      "    val_loss       : -701.0184028403349\n",
      "    val_log_likelihood: 1150.8515041484877\n",
      "    val_log_marginal: 715.4953936588169\n",
      "Train Epoch: 708 [512/17352 (3%)] Loss: -980.486511\n",
      "Train Epoch: 708 [10289/17352 (59%)] Loss: -966.010835\n",
      "Train Epoch: 708 [17335/17352 (100%)] Loss: -963.984589\n",
      "    epoch          : 708\n",
      "    loss           : -914.0901013305727\n",
      "    val_loss       : -686.2984524772457\n",
      "    val_log_likelihood: 1147.1701603124334\n",
      "    val_log_marginal: 713.688662620522\n",
      "Train Epoch: 709 [512/17352 (3%)] Loss: -941.777283\n",
      "Train Epoch: 709 [10303/17352 (59%)] Loss: -794.526690\n",
      "Train Epoch: 709 [16882/17352 (97%)] Loss: -874.919750\n",
      "    epoch          : 709\n",
      "    loss           : -928.1972985604233\n",
      "    val_loss       : -699.3614108693138\n",
      "    val_log_likelihood: 1154.2469415239163\n",
      "    val_log_marginal: 721.1213094627005\n",
      "Train Epoch: 710 [512/17352 (3%)] Loss: -978.993347\n",
      "Train Epoch: 710 [10322/17352 (59%)] Loss: -959.855859\n",
      "Train Epoch: 710 [16878/17352 (97%)] Loss: -997.683989\n",
      "    epoch          : 710\n",
      "    loss           : -928.5813810938772\n",
      "    val_loss       : -696.7592894657533\n",
      "    val_log_likelihood: 1158.9591961619012\n",
      "    val_log_marginal: 721.254409416897\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0506_152815/checkpoint-epoch710.pth ...\n",
      "Train Epoch: 711 [512/17352 (3%)] Loss: -963.745483\n",
      "Train Epoch: 711 [10966/17352 (63%)] Loss: -1038.119003\n",
      "Train Epoch: 711 [17253/17352 (99%)] Loss: -812.792392\n",
      "    epoch          : 711\n",
      "    loss           : -881.5885720822913\n",
      "    val_loss       : -320.4997472869352\n",
      "    val_log_likelihood: 1135.5925226695467\n",
      "    val_log_marginal: 341.6570048210281\n",
      "Train Epoch: 712 [512/17352 (3%)] Loss: -569.383484\n",
      "Train Epoch: 712 [10604/17352 (61%)] Loss: -1016.061306\n",
      "Train Epoch: 712 [16958/17352 (98%)] Loss: 2528.533105\n",
      "    epoch          : 712\n",
      "    loss           : -276.02044576961\n",
      "    val_loss       : 1014.9670345338815\n",
      "    val_log_likelihood: 738.9676698479107\n",
      "    val_log_marginal: -899.9815080047823\n",
      "Train Epoch: 713 [512/17352 (3%)] Loss: 1246.921143\n",
      "Train Epoch: 713 [10709/17352 (62%)] Loss: -417.766667\n",
      "Train Epoch: 713 [16883/17352 (97%)] Loss: -894.982597\n",
      "    epoch          : 713\n",
      "    loss           : -292.35347971999323\n",
      "    val_loss       : -547.3735966568365\n",
      "    val_log_likelihood: 1064.3649228725924\n",
      "    val_log_marginal: 595.1909783152805\n",
      "Train Epoch: 714 [512/17352 (3%)] Loss: -510.616974\n",
      "Train Epoch: 714 [9834/17352 (57%)] Loss: -868.102083\n",
      "Train Epoch: 714 [16922/17352 (98%)] Loss: -787.751263\n",
      "    epoch          : 714\n",
      "    loss           : -743.1253180832756\n",
      "    val_loss       : -555.1875048452177\n",
      "    val_log_likelihood: 1012.0080807177898\n",
      "    val_log_marginal: 593.6238491804265\n",
      "Train Epoch: 715 [512/17352 (3%)] Loss: -447.092621\n",
      "Train Epoch: 715 [10010/17352 (58%)] Loss: -850.890268\n",
      "Train Epoch: 715 [16923/17352 (98%)] Loss: -948.456649\n",
      "    epoch          : 715\n",
      "    loss           : -791.2429040120534\n",
      "    val_loss       : -644.9636593795188\n",
      "    val_log_likelihood: 1114.8710432140035\n",
      "    val_log_marginal: 687.7623345509818\n",
      "Train Epoch: 716 [512/17352 (3%)] Loss: -822.908081\n",
      "Train Epoch: 716 [10162/17352 (59%)] Loss: -695.118347\n",
      "Train Epoch: 716 [16923/17352 (98%)] Loss: -928.242698\n",
      "    epoch          : 716\n",
      "    loss           : -862.0441420116472\n",
      "    val_loss       : -681.0710007092687\n",
      "    val_log_likelihood: 1145.4530036604901\n",
      "    val_log_marginal: 719.4035100502928\n",
      "Train Epoch: 717 [512/17352 (3%)] Loss: -886.908386\n",
      "Train Epoch: 717 [10361/17352 (60%)] Loss: -806.376281\n",
      "Train Epoch: 717 [17044/17352 (98%)] Loss: -952.614146\n",
      "    epoch          : 717\n",
      "    loss           : -890.4056524140289\n",
      "    val_loss       : -678.1801017402787\n",
      "    val_log_likelihood: 1135.4077073905823\n",
      "    val_log_marginal: 701.1992216355097\n",
      "Train Epoch: 718 [512/17352 (3%)] Loss: -900.647095\n",
      "Train Epoch: 718 [9768/17352 (56%)] Loss: -857.519463\n",
      "Train Epoch: 718 [17108/17352 (99%)] Loss: -1023.486834\n",
      "    epoch          : 718\n",
      "    loss           : -907.1861869450122\n",
      "    val_loss       : -709.933620161502\n",
      "    val_log_likelihood: 1159.2374901086828\n",
      "    val_log_marginal: 741.3253949013746\n",
      "Train Epoch: 719 [512/17352 (3%)] Loss: -953.055969\n",
      "Train Epoch: 719 [10219/17352 (59%)] Loss: -876.083491\n",
      "Train Epoch: 719 [17153/17352 (99%)] Loss: -988.783245\n",
      "    epoch          : 719\n",
      "    loss           : -891.6214358178355\n",
      "    val_loss       : -688.7134666540618\n",
      "    val_log_likelihood: 1150.1832554610874\n",
      "    val_log_marginal: 719.4931934089457\n",
      "Train Epoch: 720 [512/17352 (3%)] Loss: -735.766846\n",
      "Train Epoch: 720 [10886/17352 (63%)] Loss: -1014.217884\n",
      "Train Epoch: 720 [17090/17352 (98%)] Loss: -846.033482\n",
      "    epoch          : 720\n",
      "    loss           : -913.3108761381013\n",
      "    val_loss       : -717.9884994796264\n",
      "    val_log_likelihood: 1160.4536226085108\n",
      "    val_log_marginal: 738.4257176594599\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0506_152815/checkpoint-epoch720.pth ...\n",
      "Train Epoch: 721 [512/17352 (3%)] Loss: -950.727783\n",
      "Train Epoch: 721 [10546/17352 (61%)] Loss: -872.923713\n",
      "Train Epoch: 721 [16922/17352 (98%)] Loss: -768.109677\n",
      "    epoch          : 721\n",
      "    loss           : -923.3913061908725\n",
      "    val_loss       : -702.2959905461628\n",
      "    val_log_likelihood: 1156.6690239232441\n",
      "    val_log_marginal: 724.1797981156694\n",
      "Train Epoch: 722 [512/17352 (3%)] Loss: -964.267944\n",
      "Train Epoch: 722 [10496/17352 (60%)] Loss: -882.846354\n",
      "Train Epoch: 722 [16988/17352 (98%)] Loss: -768.310108\n",
      "    epoch          : 722\n",
      "    loss           : -922.2348179753344\n",
      "    val_loss       : -692.0481604010525\n",
      "    val_log_likelihood: 1155.1357685606865\n",
      "    val_log_marginal: 718.2893703603715\n",
      "Train Epoch: 723 [512/17352 (3%)] Loss: -947.128784\n",
      "Train Epoch: 723 [10557/17352 (61%)] Loss: -744.847563\n",
      "Train Epoch: 723 [17108/17352 (99%)] Loss: -873.228702\n",
      "    epoch          : 723\n",
      "    loss           : -926.6329999961083\n",
      "    val_loss       : -710.4673541040903\n",
      "    val_log_likelihood: 1160.6900857122182\n",
      "    val_log_marginal: 735.0470477467015\n",
      "Train Epoch: 724 [512/17352 (3%)] Loss: -973.453430\n",
      "Train Epoch: 724 [10917/17352 (63%)] Loss: -874.092541\n",
      "Train Epoch: 724 [16939/17352 (98%)] Loss: -962.139133\n",
      "    epoch          : 724\n",
      "    loss           : -933.5380031825015\n",
      "    val_loss       : -693.5679419206796\n",
      "    val_log_likelihood: 1155.111422552604\n",
      "    val_log_marginal: 715.233373688779\n",
      "Train Epoch: 725 [512/17352 (3%)] Loss: -971.562378\n",
      "Train Epoch: 725 [10140/17352 (58%)] Loss: -870.421007\n",
      "Train Epoch: 725 [16883/17352 (97%)] Loss: -795.322814\n",
      "    epoch          : 725\n",
      "    loss           : -929.6910877664259\n",
      "    val_loss       : -700.2213321007616\n",
      "    val_log_likelihood: 1154.5473898304012\n",
      "    val_log_marginal: 726.2638429153154\n",
      "Train Epoch: 726 [512/17352 (3%)] Loss: -799.067017\n",
      "Train Epoch: 726 [10304/17352 (59%)] Loss: -812.867497\n",
      "Train Epoch: 726 [16988/17352 (98%)] Loss: -945.709092\n",
      "    epoch          : 726\n",
      "    loss           : -928.169274498416\n",
      "    val_loss       : -688.9738569402059\n",
      "    val_log_likelihood: 1159.1009074045228\n",
      "    val_log_marginal: 718.1446088871618\n",
      "Train Epoch: 727 [512/17352 (3%)] Loss: -969.812805\n",
      "Train Epoch: 727 [10374/17352 (60%)] Loss: -985.707679\n",
      "Train Epoch: 727 [16992/17352 (98%)] Loss: -940.406595\n",
      "    epoch          : 727\n",
      "    loss           : -930.281870587089\n",
      "    val_loss       : -695.3032062650766\n",
      "    val_log_likelihood: 1158.0927503479447\n",
      "    val_log_marginal: 714.6443833517276\n",
      "Train Epoch: 728 [512/17352 (3%)] Loss: -954.130432\n",
      "Train Epoch: 728 [9927/17352 (57%)] Loss: -956.586972\n",
      "Train Epoch: 728 [16887/17352 (97%)] Loss: -767.586274\n",
      "    epoch          : 728\n",
      "    loss           : -917.3709339758789\n",
      "    val_loss       : -676.2911431485943\n",
      "    val_log_likelihood: 1159.5416053066585\n",
      "    val_log_marginal: 707.1448884373971\n",
      "Train Epoch: 729 [512/17352 (3%)] Loss: -960.387573\n",
      "Train Epoch: 729 [9875/17352 (57%)] Loss: -878.122875\n",
      "Train Epoch: 729 [17253/17352 (99%)] Loss: -785.648205\n",
      "    epoch          : 729\n",
      "    loss           : -930.8726436600778\n",
      "    val_loss       : -702.5341499933631\n",
      "    val_log_likelihood: 1168.2058428617827\n",
      "    val_log_marginal: 727.1423527857818\n",
      "Train Epoch: 730 [512/17352 (3%)] Loss: -958.323608\n",
      "Train Epoch: 730 [10410/17352 (60%)] Loss: -959.924640\n",
      "Train Epoch: 730 [16923/17352 (98%)] Loss: -933.380620\n",
      "    epoch          : 730\n",
      "    loss           : -938.020568623807\n",
      "    val_loss       : -702.5138994392787\n",
      "    val_log_likelihood: 1167.8975785085652\n",
      "    val_log_marginal: 722.2721272248557\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0506_152815/checkpoint-epoch730.pth ...\n",
      "Train Epoch: 731 [512/17352 (3%)] Loss: -977.484436\n",
      "Train Epoch: 731 [10465/17352 (60%)] Loss: -972.820063\n",
      "Train Epoch: 731 [17277/17352 (100%)] Loss: -1022.995728\n",
      "    epoch          : 731\n",
      "    loss           : -930.6391214398691\n",
      "    val_loss       : -703.4714473349679\n",
      "    val_log_likelihood: 1173.5172138458759\n",
      "    val_log_marginal: 724.5980721597663\n",
      "Train Epoch: 732 [512/17352 (3%)] Loss: -969.447998\n",
      "Train Epoch: 732 [10484/17352 (60%)] Loss: -1015.097954\n",
      "Train Epoch: 732 [17049/17352 (98%)] Loss: -938.027541\n",
      "    epoch          : 732\n",
      "    loss           : -943.3053176651872\n",
      "    val_loss       : -703.2127994523263\n",
      "    val_log_likelihood: 1171.8634275664367\n",
      "    val_log_marginal: 723.2587408588888\n",
      "Train Epoch: 733 [512/17352 (3%)] Loss: -984.954651\n",
      "Train Epoch: 733 [10613/17352 (61%)] Loss: -1021.948125\n",
      "Train Epoch: 733 [17143/17352 (99%)] Loss: -936.174345\n",
      "    epoch          : 733\n",
      "    loss           : -941.4620376495367\n",
      "    val_loss       : -694.2694523859002\n",
      "    val_log_likelihood: 1164.8941459914429\n",
      "    val_log_marginal: 717.0747051200581\n",
      "Train Epoch: 734 [512/17352 (3%)] Loss: -978.929077\n",
      "Train Epoch: 734 [10590/17352 (61%)] Loss: -885.104340\n",
      "Train Epoch: 734 [17124/17352 (99%)] Loss: -962.442210\n",
      "    epoch          : 734\n",
      "    loss           : -939.9176538399615\n",
      "    val_loss       : -687.8831948550712\n",
      "    val_log_likelihood: 1168.3778591106552\n",
      "    val_log_marginal: 711.2863645454588\n",
      "Train Epoch: 735 [512/17352 (3%)] Loss: -991.756958\n",
      "Train Epoch: 735 [10872/17352 (63%)] Loss: -826.872429\n",
      "Train Epoch: 735 [17153/17352 (99%)] Loss: -1026.079255\n",
      "    epoch          : 735\n",
      "    loss           : -931.272766926559\n",
      "    val_loss       : -705.0299502126304\n",
      "    val_log_likelihood: 1172.2509066800803\n",
      "    val_log_marginal: 724.6629912433917\n",
      "Train Epoch: 736 [512/17352 (3%)] Loss: -971.163757\n",
      "Train Epoch: 736 [10380/17352 (60%)] Loss: -1041.970339\n",
      "Train Epoch: 736 [16872/17352 (97%)] Loss: -916.083607\n",
      "    epoch          : 736\n",
      "    loss           : -939.8478468855607\n",
      "    val_loss       : -705.4598001402213\n",
      "    val_log_likelihood: 1175.7385536733623\n",
      "    val_log_marginal: 727.6528931834157\n",
      "Train Epoch: 737 [512/17352 (3%)] Loss: -972.436340\n",
      "Train Epoch: 737 [10253/17352 (59%)] Loss: -1051.569915\n",
      "Train Epoch: 737 [17153/17352 (99%)] Loss: -1039.768038\n",
      "    epoch          : 737\n",
      "    loss           : -938.2862015901406\n",
      "    val_loss       : -673.5107301651744\n",
      "    val_log_likelihood: 1168.1380035662553\n",
      "    val_log_marginal: 700.1015146885892\n",
      "Train Epoch: 738 [512/17352 (3%)] Loss: -982.329834\n",
      "Train Epoch: 738 [9875/17352 (57%)] Loss: -972.299499\n",
      "Train Epoch: 738 [16988/17352 (98%)] Loss: -977.526237\n",
      "    epoch          : 738\n",
      "    loss           : -939.4892601310659\n",
      "    val_loss       : -689.2860324075638\n",
      "    val_log_likelihood: 1175.5989771723537\n",
      "    val_log_marginal: 718.4698395027106\n",
      "Train Epoch: 739 [512/17352 (3%)] Loss: -988.522034\n",
      "Train Epoch: 739 [10652/17352 (61%)] Loss: -886.006798\n",
      "Train Epoch: 739 [17064/17352 (98%)] Loss: -737.247682\n",
      "    epoch          : 739\n",
      "    loss           : -931.8551852028659\n",
      "    val_loss       : -664.2187045291608\n",
      "    val_log_likelihood: 1169.5367693753046\n",
      "    val_log_marginal: 704.1057980475366\n",
      "Train Epoch: 740 [512/17352 (3%)] Loss: -965.753479\n",
      "Train Epoch: 740 [10446/17352 (60%)] Loss: -1078.246962\n",
      "Train Epoch: 740 [16934/17352 (98%)] Loss: -902.958059\n",
      "    epoch          : 740\n",
      "    loss           : -932.6155118033049\n",
      "    val_loss       : -700.581339823771\n",
      "    val_log_likelihood: 1183.291048481345\n",
      "    val_log_marginal: 729.0759299561087\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0506_152815/checkpoint-epoch740.pth ...\n",
      "Train Epoch: 741 [512/17352 (3%)] Loss: -1004.561218\n",
      "Train Epoch: 741 [10571/17352 (61%)] Loss: -1021.285374\n",
      "Train Epoch: 741 [17064/17352 (98%)] Loss: -952.834864\n",
      "    epoch          : 741\n",
      "    loss           : -925.1440091947054\n",
      "    val_loss       : -674.2567430827924\n",
      "    val_log_likelihood: 1152.6460973977128\n",
      "    val_log_marginal: 695.9357363320266\n",
      "Train Epoch: 742 [512/17352 (3%)] Loss: -976.925903\n",
      "Train Epoch: 742 [10352/17352 (60%)] Loss: -1002.481250\n",
      "Train Epoch: 742 [16939/17352 (98%)] Loss: -884.148141\n",
      "    epoch          : 742\n",
      "    loss           : -925.9888511628718\n",
      "    val_loss       : -675.1127659196213\n",
      "    val_log_likelihood: 1174.6686543502883\n",
      "    val_log_marginal: 711.9969088024461\n",
      "Train Epoch: 743 [512/17352 (3%)] Loss: -953.600586\n",
      "Train Epoch: 743 [10640/17352 (61%)] Loss: -711.446621\n",
      "Train Epoch: 743 [17263/17352 (99%)] Loss: -878.558222\n",
      "    epoch          : 743\n",
      "    loss           : -930.3846744835813\n",
      "    val_loss       : -681.818228059125\n",
      "    val_log_likelihood: 1163.593047128926\n",
      "    val_log_marginal: 701.433661741746\n",
      "Train Epoch: 744 [512/17352 (3%)] Loss: -775.659729\n",
      "Train Epoch: 744 [10105/17352 (58%)] Loss: -888.846450\n",
      "Train Epoch: 744 [16922/17352 (98%)] Loss: -893.187035\n",
      "    epoch          : 744\n",
      "    loss           : -943.9296168324564\n",
      "    val_loss       : -659.0771202472555\n",
      "    val_log_likelihood: 1158.405106889169\n",
      "    val_log_marginal: 692.7771352221641\n",
      "Train Epoch: 745 [512/17352 (3%)] Loss: -1003.511719\n",
      "Train Epoch: 745 [10709/17352 (62%)] Loss: -1005.009707\n",
      "Train Epoch: 745 [17108/17352 (99%)] Loss: -848.758269\n",
      "    epoch          : 745\n",
      "    loss           : -928.8965760018933\n",
      "    val_loss       : -672.6484656604929\n",
      "    val_log_likelihood: 1170.5349743958413\n",
      "    val_log_marginal: 697.506074673695\n",
      "Train Epoch: 746 [512/17352 (3%)] Loss: -951.725403\n",
      "Train Epoch: 746 [10281/17352 (59%)] Loss: -704.674578\n",
      "Train Epoch: 746 [17049/17352 (98%)] Loss: -703.817423\n",
      "    epoch          : 746\n",
      "    loss           : -850.691752762319\n",
      "    val_loss       : -575.9896120733474\n",
      "    val_log_likelihood: 1119.0606269215864\n",
      "    val_log_marginal: 653.9933799618191\n",
      "Train Epoch: 747 [512/17352 (3%)] Loss: -891.176270\n",
      "Train Epoch: 747 [10034/17352 (58%)] Loss: -779.660765\n",
      "Train Epoch: 747 [16988/17352 (98%)] Loss: -987.838153\n",
      "    epoch          : 747\n",
      "    loss           : -881.0866351545483\n",
      "    val_loss       : -627.3631862496992\n",
      "    val_log_likelihood: 1141.6812875054993\n",
      "    val_log_marginal: 665.6315786232979\n",
      "Train Epoch: 748 [512/17352 (3%)] Loss: -936.251404\n",
      "Train Epoch: 748 [10803/17352 (62%)] Loss: -998.536076\n",
      "Train Epoch: 748 [16992/17352 (98%)] Loss: -832.418698\n",
      "    epoch          : 748\n",
      "    loss           : -856.473520680095\n",
      "    val_loss       : -577.9976190015499\n",
      "    val_log_likelihood: 1089.2533405909705\n",
      "    val_log_marginal: 631.8843406279465\n",
      "Train Epoch: 749 [512/17352 (3%)] Loss: -869.866394\n",
      "Train Epoch: 749 [10234/17352 (59%)] Loss: -642.370462\n",
      "Train Epoch: 749 [17143/17352 (99%)] Loss: -851.600722\n",
      "    epoch          : 749\n",
      "    loss           : -713.7174500977983\n",
      "    val_loss       : -529.448549523448\n",
      "    val_log_likelihood: 1074.535776947887\n",
      "    val_log_marginal: 579.692136345639\n",
      "Train Epoch: 750 [512/17352 (3%)] Loss: -852.241089\n",
      "Train Epoch: 750 [10315/17352 (59%)] Loss: -922.903539\n",
      "Train Epoch: 750 [16883/17352 (97%)] Loss: -635.221505\n",
      "    epoch          : 750\n",
      "    loss           : -819.4340731620649\n",
      "    val_loss       : -655.0135032510593\n",
      "    val_log_likelihood: 1152.0736474796497\n",
      "    val_log_marginal: 696.0745343065582\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0506_152815/checkpoint-epoch750.pth ...\n",
      "Train Epoch: 751 [512/17352 (3%)] Loss: -947.829956\n",
      "Train Epoch: 751 [10235/17352 (59%)] Loss: -743.877926\n",
      "Train Epoch: 751 [16878/17352 (97%)] Loss: -728.614583\n",
      "    epoch          : 751\n",
      "    loss           : -796.9797579499636\n",
      "    val_loss       : -644.9516138916965\n",
      "    val_log_likelihood: 1155.7327041940403\n",
      "    val_log_marginal: 673.4174073823659\n",
      "Train Epoch: 752 [512/17352 (3%)] Loss: -941.997559\n",
      "Train Epoch: 752 [10259/17352 (59%)] Loss: -964.139462\n",
      "Train Epoch: 752 [17124/17352 (99%)] Loss: -978.612917\n",
      "    epoch          : 752\n",
      "    loss           : -892.5620731827948\n",
      "    val_loss       : -658.5216986370549\n",
      "    val_log_likelihood: 1152.2167573262711\n",
      "    val_log_marginal: 698.9087073812241\n",
      "Train Epoch: 753 [512/17352 (3%)] Loss: -958.565430\n",
      "Train Epoch: 753 [10045/17352 (58%)] Loss: -941.820372\n",
      "Train Epoch: 753 [17064/17352 (98%)] Loss: -825.255924\n",
      "    epoch          : 753\n",
      "    loss           : -898.9557382538798\n",
      "    val_loss       : -642.2223357685001\n",
      "    val_log_likelihood: 1142.8564877903243\n",
      "    val_log_marginal: 679.1389096909305\n",
      "Train Epoch: 754 [512/17352 (3%)] Loss: -921.872925\n",
      "Train Epoch: 754 [10683/17352 (62%)] Loss: -1046.286675\n",
      "Train Epoch: 754 [17335/17352 (100%)] Loss: -705.930472\n",
      "    epoch          : 754\n",
      "    loss           : -876.5184231786484\n",
      "    val_loss       : -625.7666655451444\n",
      "    val_log_likelihood: 1140.3176554102793\n",
      "    val_log_marginal: 678.1439648276016\n",
      "Train Epoch: 755 [512/17352 (3%)] Loss: -920.671875\n",
      "Train Epoch: 755 [10691/17352 (62%)] Loss: -837.449155\n",
      "Train Epoch: 755 [17335/17352 (100%)] Loss: -839.280986\n",
      "    epoch          : 755\n",
      "    loss           : -912.9406334870833\n",
      "    val_loss       : -674.484551534762\n",
      "    val_log_likelihood: 1165.9932466244059\n",
      "    val_log_marginal: 702.7242445505179\n",
      "Train Epoch: 756 [512/17352 (3%)] Loss: -948.183899\n",
      "Train Epoch: 756 [10451/17352 (60%)] Loss: -1009.378176\n",
      "Train Epoch: 756 [17124/17352 (99%)] Loss: -1075.866645\n",
      "    epoch          : 756\n",
      "    loss           : -934.7597015026358\n",
      "    val_loss       : -691.5803889402623\n",
      "    val_log_likelihood: 1176.557372990695\n",
      "    val_log_marginal: 711.0613239682692\n",
      "Train Epoch: 757 [512/17352 (3%)] Loss: -969.679749\n",
      "Train Epoch: 757 [10494/17352 (60%)] Loss: -1001.459599\n",
      "Train Epoch: 757 [17124/17352 (99%)] Loss: -999.897812\n",
      "    epoch          : 757\n",
      "    loss           : -944.0750881310013\n",
      "    val_loss       : -713.5418823215612\n",
      "    val_log_likelihood: 1184.6865953435326\n",
      "    val_log_marginal: 737.6389512198683\n",
      "Train Epoch: 758 [512/17352 (3%)] Loss: -996.762634\n",
      "Train Epoch: 758 [10054/17352 (58%)] Loss: -1024.164102\n",
      "Train Epoch: 758 [17064/17352 (98%)] Loss: -997.366354\n",
      "    epoch          : 758\n",
      "    loss           : -945.8638411633616\n",
      "    val_loss       : -693.7108900443909\n",
      "    val_log_likelihood: 1177.3675914385785\n",
      "    val_log_marginal: 716.7174266658918\n",
      "Train Epoch: 759 [512/17352 (3%)] Loss: -992.248596\n",
      "Train Epoch: 759 [11018/17352 (63%)] Loss: -1002.533616\n",
      "Train Epoch: 759 [16992/17352 (98%)] Loss: -818.683168\n",
      "    epoch          : 759\n",
      "    loss           : -945.8695483376225\n",
      "    val_loss       : -706.4496805949684\n",
      "    val_log_likelihood: 1188.865265642163\n",
      "    val_log_marginal: 728.6038770927958\n",
      "Train Epoch: 760 [512/17352 (3%)] Loss: -1003.968445\n",
      "Train Epoch: 760 [10333/17352 (60%)] Loss: -976.028255\n",
      "Train Epoch: 760 [16957/17352 (98%)] Loss: -855.897285\n",
      "    epoch          : 760\n",
      "    loss           : -951.4312518068472\n",
      "    val_loss       : -714.6993567173004\n",
      "    val_log_likelihood: 1186.9598091512114\n",
      "    val_log_marginal: 737.2934989425177\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0506_152815/checkpoint-epoch760.pth ...\n",
      "Train Epoch: 761 [512/17352 (3%)] Loss: -989.560547\n",
      "Train Epoch: 761 [10523/17352 (61%)] Loss: -1081.244792\n",
      "Train Epoch: 761 [16883/17352 (97%)] Loss: -954.861673\n",
      "    epoch          : 761\n",
      "    loss           : -951.5610138689065\n",
      "    val_loss       : -707.3429190936786\n",
      "    val_log_likelihood: 1185.1824485851619\n",
      "    val_log_marginal: 727.7599714653226\n",
      "Train Epoch: 762 [512/17352 (3%)] Loss: -1010.681030\n",
      "Train Epoch: 762 [10451/17352 (60%)] Loss: -887.108247\n",
      "Train Epoch: 762 [16957/17352 (98%)] Loss: -1019.094840\n",
      "    epoch          : 762\n",
      "    loss           : -953.9630553712361\n",
      "    val_loss       : -692.8581748875127\n",
      "    val_log_likelihood: 1182.0024015440497\n",
      "    val_log_marginal: 718.7616931516015\n",
      "Train Epoch: 763 [512/17352 (3%)] Loss: -992.732544\n",
      "Train Epoch: 763 [10619/17352 (61%)] Loss: -999.775959\n",
      "Train Epoch: 763 [16882/17352 (97%)] Loss: -1040.223576\n",
      "    epoch          : 763\n",
      "    loss           : -954.4620865303147\n",
      "    val_loss       : -691.5285867536439\n",
      "    val_log_likelihood: 1185.3699629329176\n",
      "    val_log_marginal: 717.4510775649421\n",
      "Train Epoch: 764 [512/17352 (3%)] Loss: -798.103699\n",
      "Train Epoch: 764 [9939/17352 (57%)] Loss: -1092.646267\n",
      "Train Epoch: 764 [16957/17352 (98%)] Loss: -871.203893\n",
      "    epoch          : 764\n",
      "    loss           : -956.9259786523944\n",
      "    val_loss       : -682.7130033342113\n",
      "    val_log_likelihood: 1179.6649165098036\n",
      "    val_log_marginal: 711.9864791531156\n",
      "Train Epoch: 765 [512/17352 (3%)] Loss: -988.500671\n",
      "Train Epoch: 765 [9954/17352 (57%)] Loss: -920.996553\n",
      "Train Epoch: 765 [16939/17352 (98%)] Loss: -882.807292\n",
      "    epoch          : 765\n",
      "    loss           : -948.3306965030532\n",
      "    val_loss       : -694.799327629012\n",
      "    val_log_likelihood: 1186.9823578192077\n",
      "    val_log_marginal: 726.8894642447178\n",
      "Train Epoch: 766 [512/17352 (3%)] Loss: -996.711060\n",
      "Train Epoch: 766 [10584/17352 (61%)] Loss: -882.632850\n",
      "Train Epoch: 766 [17090/17352 (98%)] Loss: -1052.210747\n",
      "    epoch          : 766\n",
      "    loss           : -945.3948778677593\n",
      "    val_loss       : -690.9976487947429\n",
      "    val_log_likelihood: 1186.364031813446\n",
      "    val_log_marginal: 716.9406656069438\n",
      "Train Epoch: 767 [512/17352 (3%)] Loss: -992.254639\n",
      "Train Epoch: 767 [10438/17352 (60%)] Loss: -1034.526071\n",
      "Train Epoch: 767 [17277/17352 (100%)] Loss: -891.872362\n",
      "    epoch          : 767\n",
      "    loss           : -956.5021183365719\n",
      "    val_loss       : -677.0888416618611\n",
      "    val_log_likelihood: 1186.3318390526965\n",
      "    val_log_marginal: 708.0559865401057\n",
      "Train Epoch: 768 [512/17352 (3%)] Loss: -986.324890\n",
      "Train Epoch: 768 [10452/17352 (60%)] Loss: -1038.649525\n",
      "Train Epoch: 768 [16882/17352 (97%)] Loss: -906.120278\n",
      "    epoch          : 768\n",
      "    loss           : -954.8028525881668\n",
      "    val_loss       : -663.7409098194112\n",
      "    val_log_likelihood: 1187.9832531607412\n",
      "    val_log_marginal: 688.042548072556\n",
      "Train Epoch: 769 [512/17352 (3%)] Loss: -960.299133\n",
      "Train Epoch: 769 [9955/17352 (57%)] Loss: -991.264035\n",
      "Train Epoch: 769 [17101/17352 (99%)] Loss: -1000.878542\n",
      "    epoch          : 769\n",
      "    loss           : -932.5517007578222\n",
      "    val_loss       : -651.1905749484645\n",
      "    val_log_likelihood: 1180.896758523149\n",
      "    val_log_marginal: 676.4331914087077\n",
      "Train Epoch: 770 [512/17352 (3%)] Loss: -974.414856\n",
      "Train Epoch: 770 [9885/17352 (57%)] Loss: -969.118329\n",
      "Train Epoch: 770 [17106/17352 (99%)] Loss: -981.781001\n",
      "    epoch          : 770\n",
      "    loss           : -877.5210892025146\n",
      "    val_loss       : -573.6605955514062\n",
      "    val_log_likelihood: 1172.549659216445\n",
      "    val_log_marginal: 604.7398234161662\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0506_152815/checkpoint-epoch770.pth ...\n",
      "Train Epoch: 771 [512/17352 (3%)] Loss: -875.866577\n",
      "Train Epoch: 771 [10791/17352 (62%)] Loss: -915.673944\n",
      "Train Epoch: 771 [16922/17352 (98%)] Loss: -808.774403\n",
      "    epoch          : 771\n",
      "    loss           : -865.9129323857543\n",
      "    val_loss       : -633.3874506028036\n",
      "    val_log_likelihood: 1168.3590737038814\n",
      "    val_log_marginal: 677.3166905384298\n",
      "Train Epoch: 772 [512/17352 (3%)] Loss: -964.979736\n",
      "Train Epoch: 772 [10726/17352 (62%)] Loss: -853.942448\n",
      "Train Epoch: 772 [17124/17352 (99%)] Loss: 137.155044\n",
      "    epoch          : 772\n",
      "    loss           : -610.112163492385\n",
      "    val_loss       : -158.98526641780435\n",
      "    val_log_likelihood: 963.3937533258348\n",
      "    val_log_marginal: 223.4066336256017\n",
      "Train Epoch: 773 [512/17352 (3%)] Loss: -541.094238\n",
      "Train Epoch: 773 [10474/17352 (60%)] Loss: -780.405872\n",
      "Train Epoch: 773 [17106/17352 (99%)] Loss: -742.167215\n",
      "    epoch          : 773\n",
      "    loss           : -656.7616966717135\n",
      "    val_loss       : -581.5264011231262\n",
      "    val_log_likelihood: 1119.6335293018105\n",
      "    val_log_marginal: 611.3736757183943\n",
      "Train Epoch: 774 [512/17352 (3%)] Loss: -919.764526\n",
      "Train Epoch: 774 [10527/17352 (61%)] Loss: -809.681195\n",
      "Train Epoch: 774 [17253/17352 (99%)] Loss: -959.920640\n",
      "    epoch          : 774\n",
      "    loss           : -848.3858923654291\n",
      "    val_loss       : -643.1736085798121\n",
      "    val_log_likelihood: 1162.96336798792\n",
      "    val_log_marginal: 688.7465790940533\n",
      "Train Epoch: 775 [512/17352 (3%)] Loss: -876.033264\n",
      "Train Epoch: 775 [10617/17352 (61%)] Loss: -843.369066\n",
      "Train Epoch: 775 [17124/17352 (99%)] Loss: -1032.637184\n",
      "    epoch          : 775\n",
      "    loss           : -903.3678955498093\n",
      "    val_loss       : -615.2016379691752\n",
      "    val_log_likelihood: 1174.200267028776\n",
      "    val_log_marginal: 641.2537810423061\n",
      "Train Epoch: 776 [512/17352 (3%)] Loss: -896.229614\n",
      "Train Epoch: 776 [10894/17352 (63%)] Loss: -1049.458838\n",
      "Train Epoch: 776 [17277/17352 (100%)] Loss: -954.181581\n",
      "    epoch          : 776\n",
      "    loss           : -927.8612106718626\n",
      "    val_loss       : -679.0425650931809\n",
      "    val_log_likelihood: 1169.4346119336244\n",
      "    val_log_marginal: 698.1267904147904\n",
      "Train Epoch: 777 [512/17352 (3%)] Loss: -969.409973\n",
      "Train Epoch: 777 [10002/17352 (58%)] Loss: -1037.227071\n",
      "Train Epoch: 777 [16934/17352 (98%)] Loss: -982.751427\n",
      "    epoch          : 777\n",
      "    loss           : -932.5536945714922\n",
      "    val_loss       : -691.0676937836046\n",
      "    val_log_likelihood: 1179.0638006449697\n",
      "    val_log_marginal: 713.0273324569124\n",
      "Train Epoch: 778 [512/17352 (3%)] Loss: -981.160645\n",
      "Train Epoch: 778 [10747/17352 (62%)] Loss: -893.758155\n",
      "Train Epoch: 778 [16957/17352 (98%)] Loss: -953.376383\n",
      "    epoch          : 778\n",
      "    loss           : -954.6439709889266\n",
      "    val_loss       : -695.4404062159889\n",
      "    val_log_likelihood: 1186.399716597133\n",
      "    val_log_marginal: 721.0483959580846\n",
      "Train Epoch: 779 [512/17352 (3%)] Loss: -995.639404\n",
      "Train Epoch: 779 [9871/17352 (57%)] Loss: -886.607057\n",
      "Train Epoch: 779 [17153/17352 (99%)] Loss: -1078.439899\n",
      "    epoch          : 779\n",
      "    loss           : -954.246087360206\n",
      "    val_loss       : -695.047842928147\n",
      "    val_log_likelihood: 1182.2747847581006\n",
      "    val_log_marginal: 717.9205563691398\n",
      "Train Epoch: 780 [512/17352 (3%)] Loss: -1014.259216\n",
      "Train Epoch: 780 [9889/17352 (57%)] Loss: -1069.059171\n",
      "Train Epoch: 780 [16988/17352 (98%)] Loss: -1098.010525\n",
      "    epoch          : 780\n",
      "    loss           : -957.1737012751412\n",
      "    val_loss       : -696.981270817334\n",
      "    val_log_likelihood: 1180.8244900074794\n",
      "    val_log_marginal: 719.59473884009\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0506_152815/checkpoint-epoch780.pth ...\n",
      "Train Epoch: 781 [512/17352 (3%)] Loss: -999.793091\n",
      "Train Epoch: 781 [10369/17352 (60%)] Loss: -993.557946\n",
      "Train Epoch: 781 [17016/17352 (98%)] Loss: -1051.344383\n",
      "    epoch          : 781\n",
      "    loss           : -956.8168485895262\n",
      "    val_loss       : -692.5306580173062\n",
      "    val_log_likelihood: 1187.6137347082063\n",
      "    val_log_marginal: 717.9805162700441\n",
      "Train Epoch: 782 [512/17352 (3%)] Loss: -1011.904724\n",
      "Train Epoch: 782 [10599/17352 (61%)] Loss: -1101.659071\n",
      "Train Epoch: 782 [17049/17352 (98%)] Loss: -998.815814\n",
      "    epoch          : 782\n",
      "    loss           : -966.4279216375539\n",
      "    val_loss       : -693.5092097087039\n",
      "    val_log_likelihood: 1184.0396087837735\n",
      "    val_log_marginal: 712.5413739850936\n",
      "Train Epoch: 783 [512/17352 (3%)] Loss: -1004.599426\n",
      "Train Epoch: 783 [10581/17352 (61%)] Loss: -984.849972\n",
      "Train Epoch: 783 [16883/17352 (97%)] Loss: -914.041146\n",
      "    epoch          : 783\n",
      "    loss           : -965.3054508734334\n",
      "    val_loss       : -703.4172932314683\n",
      "    val_log_likelihood: 1192.6532600352152\n",
      "    val_log_marginal: 728.0203987176702\n",
      "Train Epoch: 784 [512/17352 (3%)] Loss: -825.225037\n",
      "Train Epoch: 784 [10111/17352 (58%)] Loss: -855.309360\n",
      "Train Epoch: 784 [16992/17352 (98%)] Loss: -1051.941614\n",
      "    epoch          : 784\n",
      "    loss           : -943.2998400770083\n",
      "    val_loss       : -688.0198985798057\n",
      "    val_log_likelihood: 1184.3265642534175\n",
      "    val_log_marginal: 714.0782808956824\n",
      "Train Epoch: 785 [512/17352 (3%)] Loss: -996.330811\n",
      "Train Epoch: 785 [9887/17352 (57%)] Loss: -966.796045\n",
      "Train Epoch: 785 [16923/17352 (98%)] Loss: -792.742265\n",
      "    epoch          : 785\n",
      "    loss           : -938.2886223331606\n",
      "    val_loss       : -665.759783555272\n",
      "    val_log_likelihood: 1178.567632835278\n",
      "    val_log_marginal: 705.7661417672256\n",
      "Train Epoch: 786 [512/17352 (3%)] Loss: -939.695435\n",
      "Train Epoch: 786 [9897/17352 (57%)] Loss: -789.570906\n",
      "Train Epoch: 786 [17108/17352 (99%)] Loss: -883.012523\n",
      "    epoch          : 786\n",
      "    loss           : -946.2687116548369\n",
      "    val_loss       : -677.4856710825641\n",
      "    val_log_likelihood: 1178.6864695161305\n",
      "    val_log_marginal: 702.2763504312063\n",
      "Train Epoch: 787 [512/17352 (3%)] Loss: -995.064697\n",
      "Train Epoch: 787 [9965/17352 (57%)] Loss: -1061.774517\n",
      "Train Epoch: 787 [16883/17352 (97%)] Loss: -998.677344\n",
      "    epoch          : 787\n",
      "    loss           : -958.7623202366558\n",
      "    val_loss       : -703.0544340920769\n",
      "    val_log_likelihood: 1193.4026239184923\n",
      "    val_log_marginal: 724.7616213971772\n",
      "Train Epoch: 788 [512/17352 (3%)] Loss: -1028.272217\n",
      "Train Epoch: 788 [10394/17352 (60%)] Loss: -906.701823\n",
      "Train Epoch: 788 [17143/17352 (99%)] Loss: -1009.860604\n",
      "    epoch          : 788\n",
      "    loss           : -961.2577951487805\n",
      "    val_loss       : -673.9261679736439\n",
      "    val_log_likelihood: 1183.84378633063\n",
      "    val_log_marginal: 700.387651056466\n",
      "Train Epoch: 789 [512/17352 (3%)] Loss: -996.065735\n",
      "Train Epoch: 789 [10847/17352 (63%)] Loss: -990.491980\n",
      "Train Epoch: 789 [17106/17352 (99%)] Loss: -832.179050\n",
      "    epoch          : 789\n",
      "    loss           : -952.2175762244026\n",
      "    val_loss       : -677.5501215192693\n",
      "    val_log_likelihood: 1199.0577934929743\n",
      "    val_log_marginal: 706.1280334954387\n",
      "Train Epoch: 790 [512/17352 (3%)] Loss: -980.711243\n",
      "Train Epoch: 790 [10321/17352 (59%)] Loss: -932.127232\n",
      "Train Epoch: 790 [17044/17352 (98%)] Loss: -1055.236940\n",
      "    epoch          : 790\n",
      "    loss           : -954.6314048151237\n",
      "    val_loss       : -624.8072223505052\n",
      "    val_log_likelihood: 1180.8626254096575\n",
      "    val_log_marginal: 647.6232164114182\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0506_152815/checkpoint-epoch790.pth ...\n",
      "Train Epoch: 791 [512/17352 (3%)] Loss: -954.986206\n",
      "Train Epoch: 791 [10347/17352 (60%)] Loss: -1079.351392\n",
      "Train Epoch: 791 [17101/17352 (99%)] Loss: -897.357400\n",
      "    epoch          : 791\n",
      "    loss           : -927.2946782727279\n",
      "    val_loss       : -636.6127449931707\n",
      "    val_log_likelihood: 1178.6705512014514\n",
      "    val_log_marginal: 663.0476585486588\n",
      "Train Epoch: 792 [512/17352 (3%)] Loss: -990.026733\n",
      "Train Epoch: 792 [10410/17352 (60%)] Loss: -876.439081\n",
      "Train Epoch: 792 [17253/17352 (99%)] Loss: -913.434924\n",
      "    epoch          : 792\n",
      "    loss           : -934.6737297898305\n",
      "    val_loss       : -644.3418049389704\n",
      "    val_log_likelihood: 1178.572298302085\n",
      "    val_log_marginal: 671.5551220949689\n",
      "Train Epoch: 793 [512/17352 (3%)] Loss: -922.582947\n",
      "Train Epoch: 793 [10721/17352 (62%)] Loss: -890.353795\n",
      "Train Epoch: 793 [16934/17352 (98%)] Loss: -982.329036\n",
      "    epoch          : 793\n",
      "    loss           : -945.4463147480553\n",
      "    val_loss       : -662.8758459115442\n",
      "    val_log_likelihood: 1182.1985976043575\n",
      "    val_log_marginal: 690.6937715894957\n",
      "Train Epoch: 794 [512/17352 (3%)] Loss: -993.627380\n",
      "Train Epoch: 794 [10314/17352 (59%)] Loss: -1021.043188\n",
      "Train Epoch: 794 [16887/17352 (97%)] Loss: -852.889509\n",
      "    epoch          : 794\n",
      "    loss           : -967.172786756583\n",
      "    val_loss       : -689.8765912636908\n",
      "    val_log_likelihood: 1194.4063853681764\n",
      "    val_log_marginal: 712.8080562554918\n",
      "Train Epoch: 795 [512/17352 (3%)] Loss: -1026.751221\n",
      "Train Epoch: 795 [9883/17352 (57%)] Loss: -1020.949328\n",
      "Train Epoch: 795 [17106/17352 (99%)] Loss: -864.520495\n",
      "    epoch          : 795\n",
      "    loss           : -964.8403792922198\n",
      "    val_loss       : -674.9335279508912\n",
      "    val_log_likelihood: 1185.4646340745219\n",
      "    val_log_marginal: 705.1536962530478\n",
      "Train Epoch: 796 [512/17352 (3%)] Loss: -989.446899\n",
      "Train Epoch: 796 [9896/17352 (57%)] Loss: -997.500785\n",
      "Train Epoch: 796 [17106/17352 (99%)] Loss: -950.477163\n",
      "    epoch          : 796\n",
      "    loss           : -960.5688930674097\n",
      "    val_loss       : -672.9359022362387\n",
      "    val_log_likelihood: 1196.183271815038\n",
      "    val_log_marginal: 701.692370080759\n",
      "Train Epoch: 797 [512/17352 (3%)] Loss: -981.538452\n",
      "Train Epoch: 797 [10358/17352 (60%)] Loss: -840.629693\n",
      "Train Epoch: 797 [16934/17352 (98%)] Loss: -929.079770\n",
      "    epoch          : 797\n",
      "    loss           : -961.6044494688273\n",
      "    val_loss       : -687.899567960863\n",
      "    val_log_likelihood: 1202.7098467065541\n",
      "    val_log_marginal: 715.9617049105475\n",
      "Train Epoch: 798 [512/17352 (3%)] Loss: -1007.836792\n",
      "Train Epoch: 798 [10360/17352 (60%)] Loss: -921.233827\n",
      "Train Epoch: 798 [17277/17352 (100%)] Loss: -914.813477\n",
      "    epoch          : 798\n",
      "    loss           : -965.8619367320757\n",
      "    val_loss       : -660.6257228714301\n",
      "    val_log_likelihood: 1196.4307769519628\n",
      "    val_log_marginal: 691.7324744708122\n",
      "Train Epoch: 799 [512/17352 (3%)] Loss: -993.845886\n",
      "Train Epoch: 799 [10268/17352 (59%)] Loss: -987.458216\n",
      "Train Epoch: 799 [17064/17352 (98%)] Loss: -961.151989\n",
      "    epoch          : 799\n",
      "    loss           : -944.5440631210663\n",
      "    val_loss       : -665.0328097183583\n",
      "    val_log_likelihood: 1185.5567975735512\n",
      "    val_log_marginal: 685.4692333657564\n",
      "Train Epoch: 800 [512/17352 (3%)] Loss: -1001.754150\n",
      "Train Epoch: 800 [10416/17352 (60%)] Loss: -913.521291\n",
      "Train Epoch: 800 [17090/17352 (98%)] Loss: -687.006037\n",
      "    epoch          : 800\n",
      "    loss           : -937.5402321014196\n",
      "    val_loss       : -622.557377567379\n",
      "    val_log_likelihood: 1182.371079068654\n",
      "    val_log_marginal: 647.1972551666599\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0506_152815/checkpoint-epoch800.pth ...\n",
      "Train Epoch: 801 [512/17352 (3%)] Loss: -911.290527\n",
      "Train Epoch: 801 [10029/17352 (58%)] Loss: -875.165255\n",
      "Train Epoch: 801 [17016/17352 (98%)] Loss: -1057.383898\n",
      "    epoch          : 801\n",
      "    loss           : -907.4027164070216\n",
      "    val_loss       : -639.2411617734693\n",
      "    val_log_likelihood: 1185.2263429117909\n",
      "    val_log_marginal: 670.7953967015325\n",
      "Train Epoch: 802 [512/17352 (3%)] Loss: -956.448120\n",
      "Train Epoch: 802 [10557/17352 (61%)] Loss: -960.086534\n",
      "Train Epoch: 802 [16923/17352 (98%)] Loss: -1034.551667\n",
      "    epoch          : 802\n",
      "    loss           : -905.3205213051199\n",
      "    val_loss       : -631.087956350096\n",
      "    val_log_likelihood: 1161.5078613047235\n",
      "    val_log_marginal: 661.5843936881386\n",
      "Train Epoch: 803 [512/17352 (3%)] Loss: -963.623779\n",
      "Train Epoch: 803 [10409/17352 (60%)] Loss: -1001.143021\n",
      "Train Epoch: 803 [17126/17352 (99%)] Loss: -829.253842\n",
      "    epoch          : 803\n",
      "    loss           : -926.5969124827307\n",
      "    val_loss       : -661.0593394765419\n",
      "    val_log_likelihood: 1180.621433125932\n",
      "    val_log_marginal: 693.2859316690323\n",
      "Train Epoch: 804 [512/17352 (3%)] Loss: -1009.455811\n",
      "Train Epoch: 804 [10745/17352 (62%)] Loss: -1064.082223\n",
      "Train Epoch: 804 [17143/17352 (99%)] Loss: -785.917714\n",
      "    epoch          : 804\n",
      "    loss           : -897.4816995481228\n",
      "    val_loss       : -609.3688593180381\n",
      "    val_log_likelihood: 1192.2565620322555\n",
      "    val_log_marginal: 636.1638663603078\n",
      "Train Epoch: 805 [512/17352 (3%)] Loss: -952.764221\n",
      "Train Epoch: 805 [10515/17352 (61%)] Loss: -969.738301\n",
      "Train Epoch: 805 [16957/17352 (98%)] Loss: -907.987253\n",
      "    epoch          : 805\n",
      "    loss           : -914.6492729120375\n",
      "    val_loss       : -659.4990541168414\n",
      "    val_log_likelihood: 1193.1499447063584\n",
      "    val_log_marginal: 700.1113330679106\n",
      "Train Epoch: 806 [512/17352 (3%)] Loss: -975.711914\n",
      "Train Epoch: 806 [10264/17352 (59%)] Loss: -926.976812\n",
      "Train Epoch: 806 [16992/17352 (98%)] Loss: -977.341341\n",
      "    epoch          : 806\n",
      "    loss           : -896.7440140384557\n",
      "    val_loss       : -605.3313662751157\n",
      "    val_log_likelihood: 1162.7201031953123\n",
      "    val_log_marginal: 645.8888871759967\n",
      "Train Epoch: 807 [512/17352 (3%)] Loss: -890.088257\n",
      "Train Epoch: 807 [10391/17352 (60%)] Loss: -930.231393\n",
      "Train Epoch: 807 [17277/17352 (100%)] Loss: -802.060437\n",
      "    epoch          : 807\n",
      "    loss           : -916.753407340766\n",
      "    val_loss       : -623.6756801284461\n",
      "    val_log_likelihood: 1159.8047239991158\n",
      "    val_log_marginal: 655.1644354605236\n",
      "Train Epoch: 808 [512/17352 (3%)] Loss: -911.414551\n",
      "Train Epoch: 808 [10126/17352 (58%)] Loss: -1047.134337\n",
      "Train Epoch: 808 [16939/17352 (98%)] Loss: -996.544596\n",
      "    epoch          : 808\n",
      "    loss           : -946.1660028110929\n",
      "    val_loss       : -657.7694246735372\n",
      "    val_log_likelihood: 1192.0059211187202\n",
      "    val_log_marginal: 683.5486919267885\n",
      "Train Epoch: 809 [512/17352 (3%)] Loss: -975.460205\n",
      "Train Epoch: 809 [10158/17352 (59%)] Loss: -834.063884\n",
      "Train Epoch: 809 [16992/17352 (98%)] Loss: -995.300173\n",
      "    epoch          : 809\n",
      "    loss           : -887.5754054578761\n",
      "    val_loss       : -644.415380481378\n",
      "    val_log_likelihood: 1179.4125226173999\n",
      "    val_log_marginal: 666.0472197008742\n",
      "Train Epoch: 810 [512/17352 (3%)] Loss: -970.837646\n",
      "Train Epoch: 810 [10334/17352 (60%)] Loss: -722.571683\n",
      "Train Epoch: 810 [16988/17352 (98%)] Loss: 9.736918\n",
      "    epoch          : 810\n",
      "    loss           : -711.2810898766502\n",
      "    val_loss       : -425.415783011886\n",
      "    val_log_likelihood: 1097.4072096529512\n",
      "    val_log_marginal: 456.09852358178773\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0506_152815/checkpoint-epoch810.pth ...\n",
      "Train Epoch: 811 [512/17352 (3%)] Loss: -696.398987\n",
      "Train Epoch: 811 [10589/17352 (61%)] Loss: -693.760248\n",
      "Train Epoch: 811 [16988/17352 (98%)] Loss: -145.348958\n",
      "    epoch          : 811\n",
      "    loss           : -661.1996416191005\n",
      "    val_loss       : -328.3220356385578\n",
      "    val_log_likelihood: 1085.1677648407115\n",
      "    val_log_marginal: 384.03262314241164\n",
      "Train Epoch: 812 [512/17352 (3%)] Loss: -596.030884\n",
      "Train Epoch: 812 [10591/17352 (61%)] Loss: -941.970147\n",
      "Train Epoch: 812 [16939/17352 (98%)] Loss: -757.459821\n",
      "    epoch          : 812\n",
      "    loss           : -740.4817486290885\n",
      "    val_loss       : -601.1517395095068\n",
      "    val_log_likelihood: 1150.7701080048926\n",
      "    val_log_marginal: 645.3883808802515\n",
      "Train Epoch: 813 [512/17352 (3%)] Loss: -925.972900\n",
      "Train Epoch: 813 [10103/17352 (58%)] Loss: -822.146414\n",
      "Train Epoch: 813 [16878/17352 (97%)] Loss: -873.649740\n",
      "    epoch          : 813\n",
      "    loss           : -827.6720127393969\n",
      "    val_loss       : -607.1097616850396\n",
      "    val_log_likelihood: 1155.4489917785204\n",
      "    val_log_marginal: 640.6768080022977\n",
      "Train Epoch: 814 [512/17352 (3%)] Loss: -914.122437\n",
      "Train Epoch: 814 [10783/17352 (62%)] Loss: -980.759994\n",
      "Train Epoch: 814 [17016/17352 (98%)] Loss: -867.180578\n",
      "    epoch          : 814\n",
      "    loss           : -887.039706964522\n",
      "    val_loss       : -553.1285305294222\n",
      "    val_log_likelihood: 1160.1394692527024\n",
      "    val_log_marginal: 576.7606256194207\n",
      "Train Epoch: 815 [512/17352 (3%)] Loss: -783.811523\n",
      "Train Epoch: 815 [10573/17352 (61%)] Loss: -801.267191\n",
      "Train Epoch: 815 [16872/17352 (97%)] Loss: -683.948899\n",
      "    epoch          : 815\n",
      "    loss           : -892.4523752005614\n",
      "    val_loss       : -689.5123529788045\n",
      "    val_log_likelihood: 1185.202792256543\n",
      "    val_log_marginal: 715.8559111015272\n",
      "Train Epoch: 816 [512/17352 (3%)] Loss: -965.671997\n",
      "Train Epoch: 816 [10074/17352 (58%)] Loss: -949.692434\n",
      "Train Epoch: 816 [16988/17352 (98%)] Loss: -996.813434\n",
      "    epoch          : 816\n",
      "    loss           : -946.9501287584989\n",
      "    val_loss       : -692.3408611251847\n",
      "    val_log_likelihood: 1189.7822300733308\n",
      "    val_log_marginal: 720.9169282828381\n",
      "Train Epoch: 817 [512/17352 (3%)] Loss: -1007.411255\n",
      "Train Epoch: 817 [10248/17352 (59%)] Loss: -1004.715830\n",
      "Train Epoch: 817 [17044/17352 (98%)] Loss: -880.044570\n",
      "    epoch          : 817\n",
      "    loss           : -958.7836560924325\n",
      "    val_loss       : -670.9656252262959\n",
      "    val_log_likelihood: 1174.6835201408978\n",
      "    val_log_marginal: 704.3673393579273\n",
      "Train Epoch: 818 [512/17352 (3%)] Loss: -1000.579834\n",
      "Train Epoch: 818 [10993/17352 (63%)] Loss: -1049.380552\n",
      "Train Epoch: 818 [17277/17352 (100%)] Loss: -1038.319614\n",
      "    epoch          : 818\n",
      "    loss           : -958.4487900681481\n",
      "    val_loss       : -668.4235880954876\n",
      "    val_log_likelihood: 1173.3308845385166\n",
      "    val_log_marginal: 690.3057236718881\n",
      "Train Epoch: 819 [512/17352 (3%)] Loss: -968.612183\n",
      "Train Epoch: 819 [10471/17352 (60%)] Loss: -904.949603\n",
      "Train Epoch: 819 [16958/17352 (98%)] Loss: -902.445655\n",
      "    epoch          : 819\n",
      "    loss           : -955.4042785323692\n",
      "    val_loss       : -689.7911690942335\n",
      "    val_log_likelihood: 1187.8513445367928\n",
      "    val_log_marginal: 713.5244749486117\n",
      "Train Epoch: 820 [512/17352 (3%)] Loss: -1002.203491\n",
      "Train Epoch: 820 [10020/17352 (58%)] Loss: -992.296375\n",
      "Train Epoch: 820 [16922/17352 (98%)] Loss: -957.847959\n",
      "    epoch          : 820\n",
      "    loss           : -948.3450746906695\n",
      "    val_loss       : -687.6194363348518\n",
      "    val_log_likelihood: 1201.3418960023998\n",
      "    val_log_marginal: 710.4715927503354\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0506_152815/checkpoint-epoch820.pth ...\n",
      "Train Epoch: 821 [512/17352 (3%)] Loss: -1001.374634\n",
      "Train Epoch: 821 [10744/17352 (62%)] Loss: -980.726010\n",
      "Train Epoch: 821 [16992/17352 (98%)] Loss: -931.574150\n",
      "    epoch          : 821\n",
      "    loss           : -971.2267041389711\n",
      "    val_loss       : -671.7464848945195\n",
      "    val_log_likelihood: 1180.391119438885\n",
      "    val_log_marginal: 697.624277973245\n",
      "Train Epoch: 822 [512/17352 (3%)] Loss: -1009.747559\n",
      "Train Epoch: 822 [9774/17352 (56%)] Loss: -1015.351916\n",
      "Train Epoch: 822 [17126/17352 (99%)] Loss: -1033.649465\n",
      "    epoch          : 822\n",
      "    loss           : -973.8966916817205\n",
      "    val_loss       : -705.7578439506676\n",
      "    val_log_likelihood: 1199.736715234776\n",
      "    val_log_marginal: 729.6402665557672\n",
      "Train Epoch: 823 [512/17352 (3%)] Loss: -1024.104980\n",
      "Train Epoch: 823 [10009/17352 (58%)] Loss: -913.491099\n",
      "Train Epoch: 823 [17124/17352 (99%)] Loss: -1087.544189\n",
      "    epoch          : 823\n",
      "    loss           : -975.565532293746\n",
      "    val_loss       : -671.2951081922697\n",
      "    val_log_likelihood: 1201.334599933119\n",
      "    val_log_marginal: 696.5490013246108\n",
      "Train Epoch: 824 [512/17352 (3%)] Loss: -983.698853\n",
      "Train Epoch: 824 [10251/17352 (59%)] Loss: -834.524970\n",
      "Train Epoch: 824 [16958/17352 (98%)] Loss: -1035.750889\n",
      "    epoch          : 824\n",
      "    loss           : -893.2803119884212\n",
      "    val_loss       : -624.1159525905925\n",
      "    val_log_likelihood: 1174.9651070698758\n",
      "    val_log_marginal: 652.659793379177\n",
      "Train Epoch: 825 [512/17352 (3%)] Loss: -941.254578\n",
      "Train Epoch: 825 [10605/17352 (61%)] Loss: -1086.244249\n",
      "Train Epoch: 825 [17253/17352 (99%)] Loss: -981.756904\n",
      "    epoch          : 825\n",
      "    loss           : -925.8614505917458\n",
      "    val_loss       : -648.8525995510141\n",
      "    val_log_likelihood: 1184.1261762208671\n",
      "    val_log_marginal: 681.6324987646906\n",
      "Train Epoch: 826 [512/17352 (3%)] Loss: -808.930054\n",
      "Train Epoch: 826 [9832/17352 (57%)] Loss: -987.263271\n",
      "Train Epoch: 826 [17335/17352 (100%)] Loss: -1068.686967\n",
      "    epoch          : 826\n",
      "    loss           : -962.3276975152054\n",
      "    val_loss       : -651.2215423526418\n",
      "    val_log_likelihood: 1185.1914291334915\n",
      "    val_log_marginal: 674.469704269856\n",
      "Train Epoch: 827 [512/17352 (3%)] Loss: -772.131836\n",
      "Train Epoch: 827 [9834/17352 (57%)] Loss: -1036.595203\n",
      "Train Epoch: 827 [17049/17352 (98%)] Loss: -1003.234313\n",
      "    epoch          : 827\n",
      "    loss           : -959.309866520552\n",
      "    val_loss       : -684.2657384628642\n",
      "    val_log_likelihood: 1187.315030002202\n",
      "    val_log_marginal: 702.7012375269774\n",
      "Train Epoch: 828 [512/17352 (3%)] Loss: -1013.763672\n",
      "Train Epoch: 828 [10278/17352 (59%)] Loss: -1039.779142\n",
      "Train Epoch: 828 [17106/17352 (99%)] Loss: -1042.926928\n",
      "    epoch          : 828\n",
      "    loss           : -972.8448911446753\n",
      "    val_loss       : -670.5552345631003\n",
      "    val_log_likelihood: 1200.0170505302992\n",
      "    val_log_marginal: 693.9516305116183\n",
      "Train Epoch: 829 [512/17352 (3%)] Loss: -994.528503\n",
      "Train Epoch: 829 [10158/17352 (59%)] Loss: -1044.552230\n",
      "Train Epoch: 829 [17153/17352 (99%)] Loss: -1090.967551\n",
      "    epoch          : 829\n",
      "    loss           : -978.1184328443661\n",
      "    val_loss       : -679.7879166505687\n",
      "    val_log_likelihood: 1197.51539242931\n",
      "    val_log_marginal: 708.2411726169336\n",
      "Train Epoch: 830 [512/17352 (3%)] Loss: -1013.255981\n",
      "Train Epoch: 830 [10573/17352 (61%)] Loss: -934.929431\n",
      "Train Epoch: 830 [17106/17352 (99%)] Loss: -971.496765\n",
      "    epoch          : 830\n",
      "    loss           : -974.3318254863811\n",
      "    val_loss       : -693.1094606968401\n",
      "    val_log_likelihood: 1207.1000697587249\n",
      "    val_log_marginal: 716.1975156226775\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0506_152815/checkpoint-epoch830.pth ...\n",
      "Train Epoch: 831 [512/17352 (3%)] Loss: -1013.315308\n",
      "Train Epoch: 831 [10551/17352 (61%)] Loss: -1040.153198\n",
      "Train Epoch: 831 [17101/17352 (99%)] Loss: -1035.017500\n",
      "    epoch          : 831\n",
      "    loss           : -974.2449491488021\n",
      "    val_loss       : -690.0529033566253\n",
      "    val_log_likelihood: 1202.0859919576321\n",
      "    val_log_marginal: 714.1220272886453\n",
      "Train Epoch: 832 [512/17352 (3%)] Loss: -1034.596069\n",
      "Train Epoch: 832 [10141/17352 (58%)] Loss: -1036.830179\n",
      "Train Epoch: 832 [17263/17352 (99%)] Loss: -747.511761\n",
      "    epoch          : 832\n",
      "    loss           : -951.4173665790743\n",
      "    val_loss       : -539.5814199305856\n",
      "    val_log_likelihood: 1186.7322619590366\n",
      "    val_log_marginal: 574.5385740424006\n",
      "Train Epoch: 833 [512/17352 (3%)] Loss: -711.375122\n",
      "Train Epoch: 833 [10169/17352 (59%)] Loss: -912.056510\n",
      "Train Epoch: 833 [16923/17352 (98%)] Loss: -900.046875\n",
      "    epoch          : 833\n",
      "    loss           : -907.2590401753307\n",
      "    val_loss       : -676.5120123202971\n",
      "    val_log_likelihood: 1188.8601712093468\n",
      "    val_log_marginal: 692.2275648258274\n",
      "Train Epoch: 834 [512/17352 (3%)] Loss: -994.857849\n",
      "Train Epoch: 834 [9939/17352 (57%)] Loss: -1003.128139\n",
      "Train Epoch: 834 [17016/17352 (98%)] Loss: -888.525521\n",
      "    epoch          : 834\n",
      "    loss           : -897.4402017044606\n",
      "    val_loss       : -623.2631807745818\n",
      "    val_log_likelihood: 1181.5093250631928\n",
      "    val_log_marginal: 653.7714185551724\n",
      "Train Epoch: 835 [512/17352 (3%)] Loss: -947.571777\n",
      "Train Epoch: 835 [10242/17352 (59%)] Loss: -539.777998\n",
      "Train Epoch: 835 [16883/17352 (97%)] Loss: -877.158892\n",
      "    epoch          : 835\n",
      "    loss           : -893.5091256477605\n",
      "    val_loss       : -646.7262683890444\n",
      "    val_log_likelihood: 1180.40893196367\n",
      "    val_log_marginal: 672.2290723588079\n",
      "Train Epoch: 836 [512/17352 (3%)] Loss: -989.074341\n",
      "Train Epoch: 836 [10230/17352 (59%)] Loss: -869.042777\n",
      "Train Epoch: 836 [17106/17352 (99%)] Loss: -1026.138120\n",
      "    epoch          : 836\n",
      "    loss           : -927.735654627885\n",
      "    val_loss       : -672.4399461795676\n",
      "    val_log_likelihood: 1193.0690776344252\n",
      "    val_log_marginal: 702.033164800594\n",
      "Train Epoch: 837 [512/17352 (3%)] Loss: -997.571899\n",
      "Train Epoch: 837 [10503/17352 (61%)] Loss: -1044.126866\n",
      "Train Epoch: 837 [17253/17352 (99%)] Loss: -1014.322602\n",
      "    epoch          : 837\n",
      "    loss           : -951.8672032986993\n",
      "    val_loss       : -648.0156682109302\n",
      "    val_log_likelihood: 1204.4826616988744\n",
      "    val_log_marginal: 672.7023026196983\n",
      "Train Epoch: 838 [512/17352 (3%)] Loss: -983.965454\n",
      "Train Epoch: 838 [9999/17352 (58%)] Loss: -951.680078\n",
      "Train Epoch: 838 [17263/17352 (99%)] Loss: -1005.889859\n",
      "    epoch          : 838\n",
      "    loss           : -930.7554748368055\n",
      "    val_loss       : -402.3201812330381\n",
      "    val_log_likelihood: 1160.1605341252166\n",
      "    val_log_marginal: 427.0647416151167\n",
      "Train Epoch: 839 [512/17352 (3%)] Loss: -774.818176\n",
      "Train Epoch: 839 [10150/17352 (58%)] Loss: -800.378507\n",
      "Train Epoch: 839 [16882/17352 (97%)] Loss: -681.985417\n",
      "    epoch          : 839\n",
      "    loss           : -900.3202053042733\n",
      "    val_loss       : -631.5292379338588\n",
      "    val_log_likelihood: 1164.1897719009319\n",
      "    val_log_marginal: 654.7502273584937\n",
      "Train Epoch: 840 [512/17352 (3%)] Loss: -986.510559\n",
      "Train Epoch: 840 [10524/17352 (61%)] Loss: -798.569602\n",
      "Train Epoch: 840 [17090/17352 (98%)] Loss: -1011.442368\n",
      "    epoch          : 840\n",
      "    loss           : -939.03409525752\n",
      "    val_loss       : -655.5874264014145\n",
      "    val_log_likelihood: 1184.1923727663007\n",
      "    val_log_marginal: 681.485495559943\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0506_152815/checkpoint-epoch840.pth ...\n",
      "Train Epoch: 841 [512/17352 (3%)] Loss: -1003.177246\n",
      "Train Epoch: 841 [9997/17352 (58%)] Loss: -975.808002\n",
      "Train Epoch: 841 [17108/17352 (99%)] Loss: -1025.736760\n",
      "    epoch          : 841\n",
      "    loss           : -968.710206386075\n",
      "    val_loss       : -705.8208223027626\n",
      "    val_log_likelihood: 1213.1065721535626\n",
      "    val_log_marginal: 732.991843362535\n",
      "Train Epoch: 842 [512/17352 (3%)] Loss: -1029.962524\n",
      "Train Epoch: 842 [10370/17352 (60%)] Loss: -902.105661\n",
      "Train Epoch: 842 [17064/17352 (98%)] Loss: -937.519488\n",
      "    epoch          : 842\n",
      "    loss           : -969.0637649153017\n",
      "    val_loss       : -667.8322643681985\n",
      "    val_log_likelihood: 1187.797922172801\n",
      "    val_log_marginal: 689.4374662474581\n",
      "Train Epoch: 843 [512/17352 (3%)] Loss: -1016.618042\n",
      "Train Epoch: 843 [10451/17352 (60%)] Loss: -1023.475182\n",
      "Train Epoch: 843 [16988/17352 (98%)] Loss: -1021.436073\n",
      "    epoch          : 843\n",
      "    loss           : -953.9227016513663\n",
      "    val_loss       : -690.5144386426191\n",
      "    val_log_likelihood: 1201.2520094475494\n",
      "    val_log_marginal: 715.6200840035668\n",
      "Train Epoch: 844 [512/17352 (3%)] Loss: -1020.838623\n",
      "Train Epoch: 844 [10105/17352 (58%)] Loss: -771.937500\n",
      "Train Epoch: 844 [16883/17352 (97%)] Loss: -870.864510\n",
      "    epoch          : 844\n",
      "    loss           : -955.8832415120793\n",
      "    val_loss       : -668.0705032666356\n",
      "    val_log_likelihood: 1195.3750425480212\n",
      "    val_log_marginal: 688.5472257748478\n",
      "Train Epoch: 845 [512/17352 (3%)] Loss: -990.665588\n",
      "Train Epoch: 845 [10492/17352 (60%)] Loss: -947.133157\n",
      "Train Epoch: 845 [17016/17352 (98%)] Loss: -1012.479798\n",
      "    epoch          : 845\n",
      "    loss           : -960.8937576504953\n",
      "    val_loss       : -685.621549521801\n",
      "    val_log_likelihood: 1203.7760241791264\n",
      "    val_log_marginal: 710.5494869119649\n",
      "Train Epoch: 846 [512/17352 (3%)] Loss: -783.733154\n",
      "Train Epoch: 846 [10543/17352 (61%)] Loss: -1046.756733\n",
      "Train Epoch: 846 [16934/17352 (98%)] Loss: -773.712633\n",
      "    epoch          : 846\n",
      "    loss           : -947.5136971307967\n",
      "    val_loss       : -444.52360038422796\n",
      "    val_log_likelihood: 1183.521767610799\n",
      "    val_log_marginal: 462.0027658167013\n",
      "Train Epoch: 847 [512/17352 (3%)] Loss: -774.246155\n",
      "Train Epoch: 847 [10699/17352 (62%)] Loss: -1095.314467\n",
      "Train Epoch: 847 [16988/17352 (98%)] Loss: -752.365967\n",
      "    epoch          : 847\n",
      "    loss           : -889.8608061896205\n",
      "    val_loss       : -587.9754523902853\n",
      "    val_log_likelihood: 1175.7696516627007\n",
      "    val_log_marginal: 608.8175978975175\n",
      "Train Epoch: 848 [512/17352 (3%)] Loss: -952.785400\n",
      "Train Epoch: 848 [10723/17352 (62%)] Loss: -1015.358875\n",
      "Train Epoch: 848 [17049/17352 (98%)] Loss: -995.857597\n",
      "    epoch          : 848\n",
      "    loss           : -925.0240977976006\n",
      "    val_loss       : -525.0652586561812\n",
      "    val_log_likelihood: 1185.2688619779585\n",
      "    val_log_marginal: 565.0197524870986\n",
      "Train Epoch: 849 [512/17352 (3%)] Loss: -837.715210\n",
      "Train Epoch: 849 [10090/17352 (58%)] Loss: -587.414255\n",
      "Train Epoch: 849 [17016/17352 (98%)] Loss: -557.939145\n",
      "    epoch          : 849\n",
      "    loss           : -681.4542188305035\n",
      "    val_loss       : -455.0200816963037\n",
      "    val_log_likelihood: 1075.5597809083986\n",
      "    val_log_marginal: 484.30038924244917\n",
      "Train Epoch: 850 [512/17352 (3%)] Loss: -765.912659\n",
      "Train Epoch: 850 [9980/17352 (58%)] Loss: -716.255071\n",
      "Train Epoch: 850 [16878/17352 (97%)] Loss: -1028.036849\n",
      "    epoch          : 850\n",
      "    loss           : -764.4389079331204\n",
      "    val_loss       : -602.8894299356169\n",
      "    val_log_likelihood: 1151.0955877884392\n",
      "    val_log_marginal: 645.40468215279\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0506_152815/checkpoint-epoch850.pth ...\n",
      "Train Epoch: 851 [512/17352 (3%)] Loss: -940.029175\n",
      "Train Epoch: 851 [10057/17352 (58%)] Loss: -884.870133\n",
      "Train Epoch: 851 [16878/17352 (97%)] Loss: -1036.664657\n",
      "    epoch          : 851\n",
      "    loss           : -926.4006855657396\n",
      "    val_loss       : -673.6099480654395\n",
      "    val_log_likelihood: 1196.8485893518337\n",
      "    val_log_marginal: 700.6475053513208\n",
      "Train Epoch: 852 [512/17352 (3%)] Loss: -992.773560\n",
      "Train Epoch: 852 [9985/17352 (58%)] Loss: -953.652672\n",
      "Train Epoch: 852 [16882/17352 (97%)] Loss: -992.292635\n",
      "    epoch          : 852\n",
      "    loss           : -952.1937138103409\n",
      "    val_loss       : -668.3553810354293\n",
      "    val_log_likelihood: 1187.1022087349675\n",
      "    val_log_marginal: 687.4127241932555\n",
      "Train Epoch: 853 [512/17352 (3%)] Loss: -1013.113403\n",
      "Train Epoch: 853 [9784/17352 (56%)] Loss: -637.736726\n",
      "Train Epoch: 853 [16923/17352 (98%)] Loss: -982.566112\n",
      "    epoch          : 853\n",
      "    loss           : -916.8496071737541\n",
      "    val_loss       : -685.5601548278114\n",
      "    val_log_likelihood: 1202.952897741603\n",
      "    val_log_marginal: 715.7704254238713\n",
      "Train Epoch: 854 [512/17352 (3%)] Loss: -1010.994446\n",
      "Train Epoch: 854 [10221/17352 (59%)] Loss: -1055.053038\n",
      "Train Epoch: 854 [17143/17352 (99%)] Loss: -888.125923\n",
      "    epoch          : 854\n",
      "    loss           : -949.7853197535923\n",
      "    val_loss       : -662.8847287472687\n",
      "    val_log_likelihood: 1195.5639717216982\n",
      "    val_log_marginal: 688.8447396400312\n",
      "Train Epoch: 855 [512/17352 (3%)] Loss: -972.242249\n",
      "Train Epoch: 855 [9896/17352 (57%)] Loss: -1030.803227\n",
      "Train Epoch: 855 [17253/17352 (99%)] Loss: -1049.520463\n",
      "    epoch          : 855\n",
      "    loss           : -959.6741382520235\n",
      "    val_loss       : -661.9993667605462\n",
      "    val_log_likelihood: 1201.1577598810104\n",
      "    val_log_marginal: 689.0315405782461\n",
      "Train Epoch: 856 [512/17352 (3%)] Loss: -981.580811\n",
      "Train Epoch: 856 [10273/17352 (59%)] Loss: -1056.104675\n",
      "Train Epoch: 856 [16923/17352 (98%)] Loss: -1027.457763\n",
      "    epoch          : 856\n",
      "    loss           : -955.5067097438535\n",
      "    val_loss       : -686.4232480459292\n",
      "    val_log_likelihood: 1195.2413837491104\n",
      "    val_log_marginal: 704.7045703575689\n",
      "Train Epoch: 857 [512/17352 (3%)] Loss: -985.058411\n",
      "Train Epoch: 857 [10400/17352 (60%)] Loss: -813.352075\n",
      "Train Epoch: 857 [17124/17352 (99%)] Loss: -786.004785\n",
      "    epoch          : 857\n",
      "    loss           : -950.7069826557234\n",
      "    val_loss       : -651.5061237929584\n",
      "    val_log_likelihood: 1187.524936537251\n",
      "    val_log_marginal: 668.9955049474322\n",
      "Train Epoch: 858 [512/17352 (3%)] Loss: -935.956177\n",
      "Train Epoch: 858 [10674/17352 (62%)] Loss: -867.150932\n",
      "Train Epoch: 858 [16887/17352 (97%)] Loss: -910.931818\n",
      "    epoch          : 858\n",
      "    loss           : -964.9709388072632\n",
      "    val_loss       : -689.6578426061926\n",
      "    val_log_likelihood: 1202.2691268580281\n",
      "    val_log_marginal: 709.8051749645538\n",
      "Train Epoch: 859 [512/17352 (3%)] Loss: -1022.406799\n",
      "Train Epoch: 859 [10036/17352 (58%)] Loss: -938.695033\n",
      "Train Epoch: 859 [16957/17352 (98%)] Loss: -1067.422256\n",
      "    epoch          : 859\n",
      "    loss           : -952.7554010999729\n",
      "    val_loss       : -596.1449947777381\n",
      "    val_log_likelihood: 1148.9376502878433\n",
      "    val_log_marginal: 662.3730559529679\n",
      "Train Epoch: 860 [512/17352 (3%)] Loss: -935.744873\n",
      "Train Epoch: 860 [9927/17352 (57%)] Loss: -795.621785\n",
      "Train Epoch: 860 [17049/17352 (98%)] Loss: -1034.950791\n",
      "    epoch          : 860\n",
      "    loss           : -897.2220303869544\n",
      "    val_loss       : -635.8379474935809\n",
      "    val_log_likelihood: 1182.0731075950948\n",
      "    val_log_marginal: 667.4078439395373\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0506_152815/checkpoint-epoch860.pth ...\n",
      "Train Epoch: 861 [512/17352 (3%)] Loss: -962.474731\n",
      "Train Epoch: 861 [10041/17352 (58%)] Loss: -936.816761\n",
      "Train Epoch: 861 [16883/17352 (97%)] Loss: -987.271267\n",
      "    epoch          : 861\n",
      "    loss           : -861.0990807003141\n",
      "    val_loss       : -620.9746675088104\n",
      "    val_log_likelihood: 1183.6620940406403\n",
      "    val_log_marginal: 665.4727256176762\n",
      "Train Epoch: 862 [512/17352 (3%)] Loss: -912.012939\n",
      "Train Epoch: 862 [10475/17352 (60%)] Loss: -953.492359\n",
      "Train Epoch: 862 [17277/17352 (100%)] Loss: -787.253495\n",
      "    epoch          : 862\n",
      "    loss           : -936.9274103008788\n",
      "    val_loss       : -631.9706795006101\n",
      "    val_log_likelihood: 1170.0398064576634\n",
      "    val_log_marginal: 659.0347825456196\n",
      "Train Epoch: 863 [512/17352 (3%)] Loss: -957.850220\n",
      "Train Epoch: 863 [10189/17352 (59%)] Loss: -1079.229388\n",
      "Train Epoch: 863 [17253/17352 (99%)] Loss: -839.686772\n",
      "    epoch          : 863\n",
      "    loss           : -964.1312483315548\n",
      "    val_loss       : -672.3441549861567\n",
      "    val_log_likelihood: 1201.6839802469306\n",
      "    val_log_marginal: 703.859947066233\n",
      "Train Epoch: 864 [512/17352 (3%)] Loss: -989.759399\n",
      "Train Epoch: 864 [10609/17352 (61%)] Loss: -1065.156250\n",
      "Train Epoch: 864 [16872/17352 (97%)] Loss: -937.083333\n",
      "    epoch          : 864\n",
      "    loss           : -966.7729606314948\n",
      "    val_loss       : -699.808998407869\n",
      "    val_log_likelihood: 1208.939850990047\n",
      "    val_log_marginal: 721.1791682419534\n",
      "Train Epoch: 865 [512/17352 (3%)] Loss: -1014.394897\n",
      "Train Epoch: 865 [10712/17352 (62%)] Loss: -1027.683087\n",
      "Train Epoch: 865 [16934/17352 (98%)] Loss: -979.251717\n",
      "    epoch          : 865\n",
      "    loss           : -975.4963227793234\n",
      "    val_loss       : -715.1675703799153\n",
      "    val_log_likelihood: 1221.4165763259962\n",
      "    val_log_marginal: 740.9223387730899\n",
      "Train Epoch: 866 [512/17352 (3%)] Loss: -1015.783325\n",
      "Train Epoch: 866 [9609/17352 (55%)] Loss: -1070.271850\n",
      "Train Epoch: 866 [16957/17352 (98%)] Loss: -997.977026\n",
      "    epoch          : 866\n",
      "    loss           : -968.624150620259\n",
      "    val_loss       : -698.1130547224373\n",
      "    val_log_likelihood: 1213.9374801053405\n",
      "    val_log_marginal: 722.0220491075198\n",
      "Train Epoch: 867 [512/17352 (3%)] Loss: -1004.276733\n",
      "Train Epoch: 867 [11057/17352 (64%)] Loss: -850.578024\n",
      "Train Epoch: 867 [16883/17352 (97%)] Loss: -842.993090\n",
      "    epoch          : 867\n",
      "    loss           : -976.4603787782927\n",
      "    val_loss       : -690.539057209358\n",
      "    val_log_likelihood: 1215.4208741319972\n",
      "    val_log_marginal: 716.2885050688056\n",
      "Train Epoch: 868 [512/17352 (3%)] Loss: -1022.793396\n",
      "Train Epoch: 868 [10580/17352 (61%)] Loss: -860.994100\n",
      "Train Epoch: 868 [16939/17352 (98%)] Loss: -944.604320\n",
      "    epoch          : 868\n",
      "    loss           : -970.6542053367597\n",
      "    val_loss       : -715.0466622876945\n",
      "    val_log_likelihood: 1218.2462343800494\n",
      "    val_log_marginal: 734.4221789379446\n",
      "Train Epoch: 869 [512/17352 (3%)] Loss: -1025.750977\n",
      "Train Epoch: 869 [10029/17352 (58%)] Loss: -1042.516622\n",
      "Train Epoch: 869 [17133/17352 (99%)] Loss: -1023.226220\n",
      "    epoch          : 869\n",
      "    loss           : -977.1169028056178\n",
      "    val_loss       : -657.609571540176\n",
      "    val_log_likelihood: 1188.1215086888908\n",
      "    val_log_marginal: 678.2529768084112\n",
      "Train Epoch: 870 [512/17352 (3%)] Loss: -989.664978\n",
      "Train Epoch: 870 [10274/17352 (59%)] Loss: -1080.489295\n",
      "Train Epoch: 870 [16939/17352 (98%)] Loss: -1102.161580\n",
      "    epoch          : 870\n",
      "    loss           : -971.2636552354339\n",
      "    val_loss       : -657.532765817603\n",
      "    val_log_likelihood: 1187.546027139278\n",
      "    val_log_marginal: 688.3668358882812\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0506_152815/checkpoint-epoch870.pth ...\n",
      "Train Epoch: 871 [512/17352 (3%)] Loss: -1018.778931\n",
      "Train Epoch: 871 [10399/17352 (60%)] Loss: -1051.004838\n",
      "Train Epoch: 871 [16923/17352 (98%)] Loss: -856.234119\n",
      "    epoch          : 871\n",
      "    loss           : -952.8099561828805\n",
      "    val_loss       : -656.2025442952377\n",
      "    val_log_likelihood: 1191.2582831730583\n",
      "    val_log_marginal: 686.8458893509162\n",
      "Train Epoch: 872 [512/17352 (3%)] Loss: -985.610107\n",
      "Train Epoch: 872 [10666/17352 (61%)] Loss: -968.829267\n",
      "Train Epoch: 872 [17124/17352 (99%)] Loss: -1021.329705\n",
      "    epoch          : 872\n",
      "    loss           : -929.0369150265591\n",
      "    val_loss       : -655.4192379575197\n",
      "    val_log_likelihood: 1195.980349398973\n",
      "    val_log_marginal: 683.6135350297645\n",
      "Train Epoch: 873 [512/17352 (3%)] Loss: -930.161133\n",
      "Train Epoch: 873 [10742/17352 (62%)] Loss: -1069.591689\n",
      "Train Epoch: 873 [17153/17352 (99%)] Loss: -1037.214715\n",
      "    epoch          : 873\n",
      "    loss           : -955.6293479126077\n",
      "    val_loss       : -649.0230913584473\n",
      "    val_log_likelihood: 1190.3412288504694\n",
      "    val_log_marginal: 674.5893674463042\n",
      "Train Epoch: 874 [512/17352 (3%)] Loss: -999.886108\n",
      "Train Epoch: 874 [9844/17352 (57%)] Loss: -897.506392\n",
      "Train Epoch: 874 [16887/17352 (97%)] Loss: -1041.342326\n",
      "    epoch          : 874\n",
      "    loss           : -933.8212042695446\n",
      "    val_loss       : -677.3357259669177\n",
      "    val_log_likelihood: 1202.2126030679397\n",
      "    val_log_marginal: 699.923149358623\n",
      "Train Epoch: 875 [512/17352 (3%)] Loss: -1005.186096\n",
      "Train Epoch: 875 [10367/17352 (60%)] Loss: -876.481497\n",
      "Train Epoch: 875 [16923/17352 (98%)] Loss: -484.432985\n",
      "    epoch          : 875\n",
      "    loss           : -752.6329351525527\n",
      "    val_loss       : -278.942772665417\n",
      "    val_log_likelihood: 1147.8717929090144\n",
      "    val_log_marginal: 304.1791492179098\n",
      "Train Epoch: 876 [512/17352 (3%)] Loss: -581.477417\n",
      "Train Epoch: 876 [10528/17352 (61%)] Loss: -406.079027\n",
      "Train Epoch: 876 [17090/17352 (98%)] Loss: -928.115006\n",
      "    epoch          : 876\n",
      "    loss           : -619.8678265642474\n",
      "    val_loss       : -444.5434570590331\n",
      "    val_log_likelihood: 1116.164839557115\n",
      "    val_log_marginal: 506.63078578938774\n",
      "Train Epoch: 877 [512/17352 (3%)] Loss: -798.176147\n",
      "Train Epoch: 877 [10348/17352 (60%)] Loss: -786.573130\n",
      "Train Epoch: 877 [17277/17352 (100%)] Loss: -854.385746\n",
      "    epoch          : 877\n",
      "    loss           : -866.3088011363268\n",
      "    val_loss       : -656.6322368680839\n",
      "    val_log_likelihood: 1189.2153263358196\n",
      "    val_log_marginal: 686.8002297140204\n",
      "Train Epoch: 878 [512/17352 (3%)] Loss: -962.193359\n",
      "Train Epoch: 878 [10316/17352 (59%)] Loss: -1047.113881\n",
      "Train Epoch: 878 [17153/17352 (99%)] Loss: -841.061485\n",
      "    epoch          : 878\n",
      "    loss           : -962.3532058710949\n",
      "    val_loss       : -667.4828653293695\n",
      "    val_log_likelihood: 1193.8637033255102\n",
      "    val_log_marginal: 690.0181435342621\n",
      "Train Epoch: 879 [512/17352 (3%)] Loss: -995.539795\n",
      "Train Epoch: 879 [9867/17352 (57%)] Loss: -913.562221\n",
      "Train Epoch: 879 [17090/17352 (98%)] Loss: -910.139728\n",
      "    epoch          : 879\n",
      "    loss           : -973.8254401022018\n",
      "    val_loss       : -687.6702811956083\n",
      "    val_log_likelihood: 1211.05233521889\n",
      "    val_log_marginal: 712.5530220918105\n",
      "Train Epoch: 880 [512/17352 (3%)] Loss: -1008.763184\n",
      "Train Epoch: 880 [10114/17352 (58%)] Loss: -929.478544\n",
      "Train Epoch: 880 [17106/17352 (99%)] Loss: -1012.792399\n",
      "    epoch          : 880\n",
      "    loss           : -963.8008968067569\n",
      "    val_loss       : -667.2164354212537\n",
      "    val_log_likelihood: 1192.4705609517973\n",
      "    val_log_marginal: 690.8502930879298\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0506_152815/checkpoint-epoch880.pth ...\n",
      "Train Epoch: 881 [512/17352 (3%)] Loss: -826.936157\n",
      "Train Epoch: 881 [10470/17352 (60%)] Loss: -925.506696\n",
      "Train Epoch: 881 [17143/17352 (99%)] Loss: -843.047288\n",
      "    epoch          : 881\n",
      "    loss           : -982.1511161785759\n",
      "    val_loss       : -693.135805653493\n",
      "    val_log_likelihood: 1206.1472936768482\n",
      "    val_log_marginal: 718.4666364015759\n",
      "Train Epoch: 882 [512/17352 (3%)] Loss: -818.176086\n",
      "Train Epoch: 882 [10288/17352 (59%)] Loss: -1039.766808\n",
      "Train Epoch: 882 [16923/17352 (98%)] Loss: -1030.189926\n",
      "    epoch          : 882\n",
      "    loss           : -984.8661602200749\n",
      "    val_loss       : -677.5953069355267\n",
      "    val_log_likelihood: 1201.1873450386122\n",
      "    val_log_marginal: 702.5667025067575\n",
      "Train Epoch: 883 [512/17352 (3%)] Loss: -1015.282349\n",
      "Train Epoch: 883 [10397/17352 (60%)] Loss: -916.567181\n",
      "Train Epoch: 883 [16872/17352 (97%)] Loss: -950.888672\n",
      "    epoch          : 883\n",
      "    loss           : -989.8966384435647\n",
      "    val_loss       : -701.3659718322873\n",
      "    val_log_likelihood: 1210.1295023126956\n",
      "    val_log_marginal: 720.2340663900682\n",
      "Train Epoch: 884 [512/17352 (3%)] Loss: -1060.033081\n",
      "Train Epoch: 884 [10364/17352 (60%)] Loss: -1084.123476\n",
      "Train Epoch: 884 [16878/17352 (97%)] Loss: -869.880026\n",
      "    epoch          : 884\n",
      "    loss           : -993.7428240428363\n",
      "    val_loss       : -693.350031919003\n",
      "    val_log_likelihood: 1212.6404648459375\n",
      "    val_log_marginal: 722.3001159870767\n",
      "Train Epoch: 885 [512/17352 (3%)] Loss: -1050.647461\n",
      "Train Epoch: 885 [10358/17352 (60%)] Loss: -1032.591681\n",
      "Train Epoch: 885 [16882/17352 (97%)] Loss: -933.125461\n",
      "    epoch          : 885\n",
      "    loss           : -985.8679236704448\n",
      "    val_loss       : -699.621337992598\n",
      "    val_log_likelihood: 1210.397235649787\n",
      "    val_log_marginal: 718.0923581446848\n",
      "Train Epoch: 886 [512/17352 (3%)] Loss: -1012.371338\n",
      "Train Epoch: 886 [10080/17352 (58%)] Loss: -924.685707\n",
      "Train Epoch: 886 [17044/17352 (98%)] Loss: -943.865900\n",
      "    epoch          : 886\n",
      "    loss           : -981.3572740030621\n",
      "    val_loss       : -686.2304476289171\n",
      "    val_log_likelihood: 1211.4862249696077\n",
      "    val_log_marginal: 712.117774281231\n",
      "Train Epoch: 887 [512/17352 (3%)] Loss: -1001.640137\n",
      "Train Epoch: 887 [11010/17352 (63%)] Loss: -831.553293\n",
      "Train Epoch: 887 [17143/17352 (99%)] Loss: -986.429917\n",
      "    epoch          : 887\n",
      "    loss           : -982.091065224516\n",
      "    val_loss       : -662.273143832044\n",
      "    val_log_likelihood: 1201.3514138412625\n",
      "    val_log_marginal: 688.216731048426\n",
      "Train Epoch: 888 [512/17352 (3%)] Loss: -984.996948\n",
      "Train Epoch: 888 [10698/17352 (62%)] Loss: -1022.211589\n",
      "Train Epoch: 888 [17090/17352 (98%)] Loss: -828.826478\n",
      "    epoch          : 888\n",
      "    loss           : -989.5687478717442\n",
      "    val_loss       : -699.226932862612\n",
      "    val_log_likelihood: 1220.1293240826963\n",
      "    val_log_marginal: 721.7703783166129\n",
      "Train Epoch: 889 [512/17352 (3%)] Loss: -1040.165283\n",
      "Train Epoch: 889 [10050/17352 (58%)] Loss: -1022.210830\n",
      "Train Epoch: 889 [16992/17352 (98%)] Loss: -1058.438763\n",
      "    epoch          : 889\n",
      "    loss           : -968.3998920478331\n",
      "    val_loss       : -664.8030435390567\n",
      "    val_log_likelihood: 1204.7041157032195\n",
      "    val_log_marginal: 699.5028436435731\n",
      "Train Epoch: 890 [512/17352 (3%)] Loss: -1022.596558\n",
      "Train Epoch: 890 [10250/17352 (59%)] Loss: -1012.906369\n",
      "Train Epoch: 890 [16923/17352 (98%)] Loss: -1030.238546\n",
      "    epoch          : 890\n",
      "    loss           : -976.6752839296474\n",
      "    val_loss       : -671.4490458461738\n",
      "    val_log_likelihood: 1194.600110862901\n",
      "    val_log_marginal: 688.3508353220748\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0506_152815/checkpoint-epoch890.pth ...\n",
      "Train Epoch: 891 [512/17352 (3%)] Loss: -947.377258\n",
      "Train Epoch: 891 [10472/17352 (60%)] Loss: -915.736485\n",
      "Train Epoch: 891 [17090/17352 (98%)] Loss: -901.373719\n",
      "    epoch          : 891\n",
      "    loss           : -965.4061360248784\n",
      "    val_loss       : -670.0553064772226\n",
      "    val_log_likelihood: 1204.496335949731\n",
      "    val_log_marginal: 691.010924598781\n",
      "Train Epoch: 892 [512/17352 (3%)] Loss: -1022.868530\n",
      "Train Epoch: 892 [10446/17352 (60%)] Loss: -1028.935115\n",
      "Train Epoch: 892 [17108/17352 (99%)] Loss: -970.941565\n",
      "    epoch          : 892\n",
      "    loss           : -975.2884200525668\n",
      "    val_loss       : -675.2152423388867\n",
      "    val_log_likelihood: 1204.8259990683516\n",
      "    val_log_marginal: 705.9155898495399\n",
      "Train Epoch: 893 [512/17352 (3%)] Loss: -1013.880249\n",
      "Train Epoch: 893 [10643/17352 (61%)] Loss: -1066.066057\n",
      "Train Epoch: 893 [17064/17352 (98%)] Loss: -991.640208\n",
      "    epoch          : 893\n",
      "    loss           : -944.0418483548434\n",
      "    val_loss       : -616.7389636018595\n",
      "    val_log_likelihood: 1195.2226269295265\n",
      "    val_log_marginal: 653.3288530618005\n",
      "Train Epoch: 894 [512/17352 (3%)] Loss: -968.858521\n",
      "Train Epoch: 894 [10224/17352 (59%)] Loss: -878.988231\n",
      "Train Epoch: 894 [17335/17352 (100%)] Loss: -998.658755\n",
      "    epoch          : 894\n",
      "    loss           : -950.2049683461547\n",
      "    val_loss       : -615.6288399494955\n",
      "    val_log_likelihood: 1181.5683486623434\n",
      "    val_log_marginal: 643.7436567146282\n",
      "Train Epoch: 895 [512/17352 (3%)] Loss: -981.590332\n",
      "Train Epoch: 895 [10095/17352 (58%)] Loss: -830.789694\n",
      "Train Epoch: 895 [16922/17352 (98%)] Loss: -1040.294588\n",
      "    epoch          : 895\n",
      "    loss           : -976.9265146968249\n",
      "    val_loss       : -689.0062938651897\n",
      "    val_log_likelihood: 1221.5058529570208\n",
      "    val_log_marginal: 716.0327699796615\n",
      "Train Epoch: 896 [512/17352 (3%)] Loss: -1010.972229\n",
      "Train Epoch: 896 [10039/17352 (58%)] Loss: -1124.246065\n",
      "Train Epoch: 896 [17263/17352 (99%)] Loss: -1048.840513\n",
      "    epoch          : 896\n",
      "    loss           : -990.614473312682\n",
      "    val_loss       : -682.9115523810499\n",
      "    val_log_likelihood: 1205.7484593960812\n",
      "    val_log_marginal: 700.4037650010221\n",
      "Train Epoch: 897 [512/17352 (3%)] Loss: -1038.927002\n",
      "Train Epoch: 897 [9933/17352 (57%)] Loss: -1036.309515\n",
      "Train Epoch: 897 [17253/17352 (99%)] Loss: -1041.999048\n",
      "    epoch          : 897\n",
      "    loss           : -983.8080101231928\n",
      "    val_loss       : -656.3564432276052\n",
      "    val_log_likelihood: 1200.0307212475818\n",
      "    val_log_marginal: 689.8391268314153\n",
      "Train Epoch: 898 [512/17352 (3%)] Loss: -1002.499023\n",
      "Train Epoch: 898 [10351/17352 (60%)] Loss: -1056.317819\n",
      "Train Epoch: 898 [16883/17352 (97%)] Loss: -985.371875\n",
      "    epoch          : 898\n",
      "    loss           : -955.9908009527775\n",
      "    val_loss       : -628.9068494844093\n",
      "    val_log_likelihood: 1211.9594675783153\n",
      "    val_log_marginal: 652.0017356331776\n",
      "Train Epoch: 899 [512/17352 (3%)] Loss: -984.085510\n",
      "Train Epoch: 899 [10291/17352 (59%)] Loss: -865.222684\n",
      "Train Epoch: 899 [17106/17352 (99%)] Loss: -1095.689019\n",
      "    epoch          : 899\n",
      "    loss           : -923.3874199765538\n",
      "    val_loss       : -568.6976319975435\n",
      "    val_log_likelihood: 1202.388539569181\n",
      "    val_log_marginal: 596.5168037051399\n",
      "Train Epoch: 900 [512/17352 (3%)] Loss: -889.268860\n",
      "Train Epoch: 900 [10641/17352 (61%)] Loss: -669.721573\n",
      "Train Epoch: 900 [17126/17352 (99%)] Loss: -817.926678\n",
      "    epoch          : 900\n",
      "    loss           : -835.8669369845194\n",
      "    val_loss       : -591.9254529397463\n",
      "    val_log_likelihood: 1160.2000003824348\n",
      "    val_log_marginal: 618.8641402886533\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseCategory/0506_152815/checkpoint-epoch900.pth ...\n",
      "Train Epoch: 901 [512/17352 (3%)] Loss: -964.272583\n",
      "Train Epoch: 901 [9983/17352 (58%)] Loss: -947.164337\n",
      "Train Epoch: 901 [17106/17352 (99%)] Loss: -35.031526\n",
      "    epoch          : 901\n",
      "    loss           : -756.9185951761291\n",
      "    val_loss       : -501.0142764179681\n",
      "    val_log_likelihood: 1151.6179925929625\n",
      "    val_log_marginal: 525.9427902804861\n",
      "Train Epoch: 902 [512/17352 (3%)] Loss: -851.790894\n",
      "Train Epoch: 902 [9582/17352 (55%)] Loss: -758.899846\n",
      "Train Epoch: 902 [17106/17352 (99%)] Loss: -891.795920\n",
      "    epoch          : 902\n",
      "    loss           : -830.6608558037037\n",
      "    val_loss       : -569.9395174506938\n",
      "    val_log_likelihood: 1179.5186671095662\n",
      "    val_log_marginal: 623.2825782729484\n",
      "Train Epoch: 903 [512/17352 (3%)] Loss: -880.265503\n",
      "Train Epoch: 903 [10575/17352 (61%)] Loss: -1010.643480\n",
      "Train Epoch: 903 [16883/17352 (97%)] Loss: -1046.798655\n",
      "    epoch          : 903\n",
      "    loss           : -899.4146944318786\n",
      "    val_loss       : -568.7363277619506\n",
      "    val_log_likelihood: 1134.8859892340138\n",
      "    val_log_marginal: 612.7269254251995\n",
      "Train Epoch: 904 [512/17352 (3%)] Loss: -878.348755\n",
      "Train Epoch: 904 [10257/17352 (59%)] Loss: -999.899167\n",
      "Train Epoch: 904 [17049/17352 (98%)] Loss: -956.837774\n",
      "    epoch          : 904\n",
      "    loss           : -935.0318205339114\n",
      "    val_loss       : -622.9168938354549\n",
      "    val_log_likelihood: 1157.64164217324\n",
      "    val_log_marginal: 652.0020896571357\n",
      "Train Epoch: 905 [512/17352 (3%)] Loss: -911.893250\n",
      "Train Epoch: 905 [10494/17352 (60%)] Loss: -1082.560086\n",
      "Train Epoch: 905 [17124/17352 (99%)] Loss: -853.060388\n",
      "    epoch          : 905\n",
      "    loss           : -952.1367367025612\n",
      "    val_loss       : -673.394666615014\n",
      "    val_log_likelihood: 1202.677102088693\n",
      "    val_log_marginal: 701.4176605276539\n",
      "Validation performance didn't improve for 200 epochs. Training stops.\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:categorical_bpl] *",
   "language": "python",
   "name": "conda-env-categorical_bpl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
