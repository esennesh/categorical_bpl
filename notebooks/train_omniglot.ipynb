{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/eli/AnacondaProjects/categorical_bpl\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import collections\n",
    "import pyro\n",
    "import torch\n",
    "import numpy as np\n",
    "import data_loader.data_loaders as module_data\n",
    "import model.model as module_arch\n",
    "from parse_config import ConfigParser\n",
    "from trainer import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyro.enable_validation(True)\n",
    "# torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seeds for reproducibility\n",
    "SEED = 123\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Args = collections.namedtuple('Args', 'config resume device')\n",
    "config = ConfigParser.from_args(Args(config='omniglot_config.json', resume=None, device=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = config.get_logger('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# setup data_loader instances\n",
    "data_loader = config.init_obj('data_loader', module_data)\n",
    "valid_data_loader = data_loader.split_validation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model architecture, then print to console\n",
    "model = config.init_obj('arch', module_arch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = pyro.optim.ReduceLROnPlateau({\n",
    "    'optimizer': torch.optim.Adam,\n",
    "    'optim_args': {\n",
    "        \"lr\": 1e-3,\n",
    "        \"weight_decay\": 0,\n",
    "        \"amsgrad\": True\n",
    "    },\n",
    "    \"patience\": 50,\n",
    "    \"cooldown\": 25,\n",
    "    \"factor\": 0.1,\n",
    "    \"verbose\": True,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model, [], optimizer, config=config,\n",
    "                  data_loader=data_loader,\n",
    "                  valid_data_loader=valid_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [512/17352 (3%)] Loss: 1720.123779\n",
      "Train Epoch: 1 [10068/17352 (58%)] Loss: 1030.029176\n",
      "Train Epoch: 1 [16939/17352 (98%)] Loss: 960.463695\n",
      "    epoch          : 1\n",
      "    loss           : 1128.211787410873\n",
      "    val_loss       : 963.4035663430403\n",
      "    val_log_likelihood: -816.5397205792078\n",
      "    val_log_marginal: -891.8715215323707\n",
      "Train Epoch: 2 [512/17352 (3%)] Loss: 922.535034\n",
      "Train Epoch: 2 [10115/17352 (58%)] Loss: 907.503522\n",
      "Train Epoch: 2 [16922/17352 (98%)] Loss: 794.054781\n",
      "    epoch          : 2\n",
      "    loss           : 885.2580632952804\n",
      "    val_loss       : 835.1150634178467\n",
      "    val_log_likelihood: -755.645683018167\n",
      "    val_log_marginal: -791.8339170902328\n",
      "Train Epoch: 3 [512/17352 (3%)] Loss: 845.113281\n",
      "Train Epoch: 3 [10212/17352 (59%)] Loss: 801.234208\n",
      "Train Epoch: 3 [17253/17352 (99%)] Loss: 801.719823\n",
      "    epoch          : 3\n",
      "    loss           : 818.3471692881949\n",
      "    val_loss       : 793.1421925688531\n",
      "    val_log_likelihood: -721.1952875358423\n",
      "    val_log_marginal: -753.9465894426373\n",
      "Train Epoch: 4 [512/17352 (3%)] Loss: 810.702087\n",
      "Train Epoch: 4 [10332/17352 (60%)] Loss: 744.537647\n",
      "Train Epoch: 4 [17016/17352 (98%)] Loss: 734.056105\n",
      "    epoch          : 4\n",
      "    loss           : 761.0114795008445\n",
      "    val_loss       : 749.1510149979448\n",
      "    val_log_likelihood: -698.705156854949\n",
      "    val_log_marginal: -721.7410872868821\n",
      "Train Epoch: 5 [512/17352 (3%)] Loss: 747.481812\n",
      "Train Epoch: 5 [10081/17352 (58%)] Loss: 718.918663\n",
      "Train Epoch: 5 [16923/17352 (98%)] Loss: 697.446094\n",
      "    epoch          : 5\n",
      "    loss           : 732.9557279312717\n",
      "    val_loss       : 707.5426101676695\n",
      "    val_log_likelihood: -674.1239116503912\n",
      "    val_log_marginal: -691.4725673062792\n",
      "Train Epoch: 6 [512/17352 (3%)] Loss: 741.605835\n",
      "Train Epoch: 6 [10346/17352 (60%)] Loss: 688.568987\n",
      "Train Epoch: 6 [17064/17352 (98%)] Loss: 685.359300\n",
      "    epoch          : 6\n",
      "    loss           : 691.3104942219375\n",
      "    val_loss       : 677.0598699747892\n",
      "    val_log_likelihood: -653.2581891248611\n",
      "    val_log_marginal: -668.6162811336602\n",
      "Train Epoch: 7 [512/17352 (3%)] Loss: 672.108398\n",
      "Train Epoch: 7 [10580/17352 (61%)] Loss: 665.747340\n",
      "Train Epoch: 7 [16887/17352 (97%)] Loss: 654.138802\n",
      "    epoch          : 7\n",
      "    loss           : 666.2486874739161\n",
      "    val_loss       : 653.5991205001025\n",
      "    val_log_likelihood: -634.6845069798721\n",
      "    val_log_marginal: -648.472633452747\n",
      "Train Epoch: 8 [512/17352 (3%)] Loss: 651.392639\n",
      "Train Epoch: 8 [9874/17352 (57%)] Loss: 643.370877\n",
      "Train Epoch: 8 [17016/17352 (98%)] Loss: 634.581226\n",
      "    epoch          : 8\n",
      "    loss           : 643.3550342099215\n",
      "    val_loss       : 632.1283974392201\n",
      "    val_log_likelihood: -616.8670395857869\n",
      "    val_log_marginal: -628.7278923473943\n",
      "Train Epoch: 9 [512/17352 (3%)] Loss: 631.659302\n",
      "Train Epoch: 9 [10123/17352 (58%)] Loss: 623.231017\n",
      "Train Epoch: 9 [16988/17352 (98%)] Loss: 627.947798\n",
      "    epoch          : 9\n",
      "    loss           : 625.0429327404137\n",
      "    val_loss       : 615.4475864327849\n",
      "    val_log_likelihood: -600.7139476024086\n",
      "    val_log_marginal: -612.7587631004933\n",
      "Train Epoch: 10 [512/17352 (3%)] Loss: 616.882202\n",
      "Train Epoch: 10 [10141/17352 (58%)] Loss: 599.124111\n",
      "Train Epoch: 10 [16934/17352 (98%)] Loss: 597.433693\n",
      "    epoch          : 10\n",
      "    loss           : 607.977420101918\n",
      "    val_loss       : 603.267910399814\n",
      "    val_log_likelihood: -585.4374927102434\n",
      "    val_log_marginal: -601.1956731841242\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch10.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 11 [512/17352 (3%)] Loss: 603.168091\n",
      "Train Epoch: 11 [10317/17352 (59%)] Loss: 583.272739\n",
      "Train Epoch: 11 [16992/17352 (98%)] Loss: 574.254978\n",
      "    epoch          : 11\n",
      "    loss           : 589.0974431641763\n",
      "    val_loss       : 581.3886398104786\n",
      "    val_log_likelihood: -566.583299305255\n",
      "    val_log_marginal: -579.0167430560958\n",
      "Train Epoch: 12 [512/17352 (3%)] Loss: 578.892761\n",
      "Train Epoch: 12 [10175/17352 (59%)] Loss: 570.117724\n",
      "Train Epoch: 12 [17124/17352 (99%)] Loss: 566.659731\n",
      "    epoch          : 12\n",
      "    loss           : 572.8927587992839\n",
      "    val_loss       : 573.982089575207\n",
      "    val_log_likelihood: -550.4820875897639\n",
      "    val_log_marginal: -572.6289542285633\n",
      "Train Epoch: 13 [512/17352 (3%)] Loss: 573.654297\n",
      "Train Epoch: 13 [10572/17352 (61%)] Loss: 547.546875\n",
      "Train Epoch: 13 [17106/17352 (99%)] Loss: 536.396810\n",
      "    epoch          : 13\n",
      "    loss           : 554.4689907284516\n",
      "    val_loss       : 551.0172522360938\n",
      "    val_log_likelihood: -533.4796383225456\n",
      "    val_log_marginal: -548.4082583175242\n",
      "Train Epoch: 14 [512/17352 (3%)] Loss: 547.939941\n",
      "Train Epoch: 14 [10588/17352 (61%)] Loss: 530.456606\n",
      "Train Epoch: 14 [17133/17352 (99%)] Loss: 548.978161\n",
      "    epoch          : 14\n",
      "    loss           : 538.9535839824831\n",
      "    val_loss       : 537.019073283659\n",
      "    val_log_likelihood: -516.7741584025483\n",
      "    val_log_marginal: -535.0627008389336\n",
      "Train Epoch: 15 [512/17352 (3%)] Loss: 536.706421\n",
      "Train Epoch: 15 [10120/17352 (58%)] Loss: 518.291966\n",
      "Train Epoch: 15 [16934/17352 (98%)] Loss: 511.917433\n",
      "    epoch          : 15\n",
      "    loss           : 523.9027228234685\n",
      "    val_loss       : 512.3336689683199\n",
      "    val_log_likelihood: -500.50715275804316\n",
      "    val_log_marginal: -510.18889984807805\n",
      "Train Epoch: 16 [512/17352 (3%)] Loss: 511.310669\n",
      "Train Epoch: 16 [10620/17352 (61%)] Loss: 493.446684\n",
      "Train Epoch: 16 [17263/17352 (99%)] Loss: 506.871094\n",
      "    epoch          : 16\n",
      "    loss           : 503.72079755058945\n",
      "    val_loss       : 507.62902460439363\n",
      "    val_log_likelihood: -484.1630051709862\n",
      "    val_log_marginal: -505.76343113612006\n",
      "Train Epoch: 17 [512/17352 (3%)] Loss: 506.028870\n",
      "Train Epoch: 17 [10651/17352 (61%)] Loss: 487.597298\n",
      "Train Epoch: 17 [16988/17352 (98%)] Loss: 481.611719\n",
      "    epoch          : 17\n",
      "    loss           : 488.8027196267245\n",
      "    val_loss       : 476.9663162973069\n",
      "    val_log_likelihood: -465.92419194825163\n",
      "    val_log_marginal: -474.7614983898956\n",
      "Train Epoch: 18 [512/17352 (3%)] Loss: 476.385834\n",
      "Train Epoch: 18 [10212/17352 (59%)] Loss: 475.858319\n",
      "Train Epoch: 18 [16887/17352 (97%)] Loss: 477.357828\n",
      "    epoch          : 18\n",
      "    loss           : 470.70419601657414\n",
      "    val_loss       : 461.71407301733643\n",
      "    val_log_likelihood: -449.29504413897723\n",
      "    val_log_marginal: -459.3057140888656\n",
      "Train Epoch: 19 [512/17352 (3%)] Loss: 459.076355\n",
      "Train Epoch: 19 [10518/17352 (61%)] Loss: 451.508626\n",
      "Train Epoch: 19 [16988/17352 (98%)] Loss: 448.008368\n",
      "    epoch          : 19\n",
      "    loss           : 459.04863428789866\n",
      "    val_loss       : 459.79530034493035\n",
      "    val_log_likelihood: -435.99197665377034\n",
      "    val_log_marginal: -456.75078824152666\n",
      "Train Epoch: 20 [512/17352 (3%)] Loss: 457.932922\n",
      "Train Epoch: 20 [10261/17352 (59%)] Loss: 438.358061\n",
      "Train Epoch: 20 [16872/17352 (97%)] Loss: 422.083460\n",
      "    epoch          : 20\n",
      "    loss           : 442.56646585493723\n",
      "    val_loss       : 431.65259470076705\n",
      "    val_log_likelihood: -417.9941589299116\n",
      "    val_log_marginal: -428.8240609276917\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch20.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 21 [512/17352 (3%)] Loss: 428.889740\n",
      "Train Epoch: 21 [10324/17352 (59%)] Loss: 401.125500\n",
      "Train Epoch: 21 [17126/17352 (99%)] Loss: 410.264237\n",
      "    epoch          : 21\n",
      "    loss           : 422.84273326309483\n",
      "    val_loss       : 417.1244938117507\n",
      "    val_log_likelihood: -400.6859591944734\n",
      "    val_log_marginal: -414.6912104378997\n",
      "Train Epoch: 22 [512/17352 (3%)] Loss: 413.521790\n",
      "Train Epoch: 22 [10471/17352 (60%)] Loss: 396.983629\n",
      "Train Epoch: 22 [16939/17352 (98%)] Loss: 402.845502\n",
      "    epoch          : 22\n",
      "    loss           : 406.18496227375726\n",
      "    val_loss       : 397.0103968976626\n",
      "    val_log_likelihood: -383.6400254832432\n",
      "    val_log_marginal: -394.61159434109203\n",
      "Train Epoch: 23 [512/17352 (3%)] Loss: 394.403534\n",
      "Train Epoch: 23 [9688/17352 (56%)] Loss: 392.369242\n",
      "Train Epoch: 23 [17253/17352 (99%)] Loss: 383.452111\n",
      "    epoch          : 23\n",
      "    loss           : 392.2231062736543\n",
      "    val_loss       : 394.76362834141423\n",
      "    val_log_likelihood: -369.4580866903874\n",
      "    val_log_marginal: -391.98837455770007\n",
      "Train Epoch: 24 [512/17352 (3%)] Loss: 394.209717\n",
      "Train Epoch: 24 [10325/17352 (60%)] Loss: 371.570036\n",
      "Train Epoch: 24 [17044/17352 (98%)] Loss: 359.932305\n",
      "    epoch          : 24\n",
      "    loss           : 378.1751029597601\n",
      "    val_loss       : 372.05447385256053\n",
      "    val_log_likelihood: -353.08171858742634\n",
      "    val_log_marginal: -368.92879811467475\n",
      "Train Epoch: 25 [512/17352 (3%)] Loss: 370.545654\n",
      "Train Epoch: 25 [10211/17352 (59%)] Loss: 388.958669\n",
      "Train Epoch: 25 [17044/17352 (98%)] Loss: 343.497257\n",
      "    epoch          : 25\n",
      "    loss           : 361.01256323702694\n",
      "    val_loss       : 355.1700749224654\n",
      "    val_log_likelihood: -337.6926795757374\n",
      "    val_log_marginal: -352.29598498159385\n",
      "Train Epoch: 26 [512/17352 (3%)] Loss: 353.192322\n",
      "Train Epoch: 26 [10675/17352 (62%)] Loss: 334.016768\n",
      "Train Epoch: 26 [17335/17352 (100%)] Loss: 333.725738\n",
      "    epoch          : 26\n",
      "    loss           : 345.4400782455412\n",
      "    val_loss       : 337.34850580307955\n",
      "    val_log_likelihood: -319.87774986979707\n",
      "    val_log_marginal: -334.6623367432323\n",
      "Train Epoch: 27 [512/17352 (3%)] Loss: 333.223206\n",
      "Train Epoch: 27 [10981/17352 (63%)] Loss: 325.596712\n",
      "Train Epoch: 27 [16958/17352 (98%)] Loss: 343.203873\n",
      "    epoch          : 27\n",
      "    loss           : 330.8542448805296\n",
      "    val_loss       : 325.979554569256\n",
      "    val_log_likelihood: -307.386583726052\n",
      "    val_log_marginal: -322.9677627456946\n",
      "Train Epoch: 28 [512/17352 (3%)] Loss: 325.215942\n",
      "Train Epoch: 28 [10026/17352 (58%)] Loss: 304.849482\n",
      "Train Epoch: 28 [17101/17352 (99%)] Loss: 327.490954\n",
      "    epoch          : 28\n",
      "    loss           : 316.89707655236634\n",
      "    val_loss       : 308.83131177336253\n",
      "    val_log_likelihood: -292.6382280006622\n",
      "    val_log_marginal: -305.46356011696497\n",
      "Train Epoch: 29 [512/17352 (3%)] Loss: 326.880585\n",
      "Train Epoch: 29 [10416/17352 (60%)] Loss: 279.731046\n",
      "Train Epoch: 29 [17106/17352 (99%)] Loss: 304.698880\n",
      "    epoch          : 29\n",
      "    loss           : 306.9921631064333\n",
      "    val_loss       : 327.9010390804305\n",
      "    val_log_likelihood: -279.49605496542705\n",
      "    val_log_marginal: -323.82964157882606\n",
      "Train Epoch: 30 [512/17352 (3%)] Loss: 319.885468\n",
      "Train Epoch: 30 [10200/17352 (59%)] Loss: 300.862500\n",
      "Train Epoch: 30 [16887/17352 (97%)] Loss: 302.918268\n",
      "    epoch          : 30\n",
      "    loss           : 299.68001947814906\n",
      "    val_loss       : 287.34970238174793\n",
      "    val_log_likelihood: -265.15568426191277\n",
      "    val_log_marginal: -283.97990489042104\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch30.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 31 [512/17352 (3%)] Loss: 286.310120\n",
      "Train Epoch: 31 [10333/17352 (60%)] Loss: 283.811297\n",
      "Train Epoch: 31 [16957/17352 (98%)] Loss: 276.752961\n",
      "    epoch          : 31\n",
      "    loss           : 280.77101204643947\n",
      "    val_loss       : 270.51807410926614\n",
      "    val_log_likelihood: -249.00254131625917\n",
      "    val_log_marginal: -265.61664206661766\n",
      "Train Epoch: 32 [512/17352 (3%)] Loss: 269.323151\n",
      "Train Epoch: 32 [10244/17352 (59%)] Loss: 278.387551\n",
      "Train Epoch: 32 [17277/17352 (100%)] Loss: 253.376163\n",
      "    epoch          : 32\n",
      "    loss           : 264.4081768582705\n",
      "    val_loss       : 263.5707093005939\n",
      "    val_log_likelihood: -236.32340699427476\n",
      "    val_log_marginal: -259.0882422818262\n",
      "Train Epoch: 33 [512/17352 (3%)] Loss: 260.608429\n",
      "Train Epoch: 33 [10195/17352 (59%)] Loss: 281.116163\n",
      "Train Epoch: 33 [16882/17352 (97%)] Loss: 240.100598\n",
      "    epoch          : 33\n",
      "    loss           : 250.36785352473268\n",
      "    val_loss       : 240.72031801773716\n",
      "    val_log_likelihood: -219.89124399769094\n",
      "    val_log_marginal: -237.08021789874002\n",
      "Train Epoch: 34 [512/17352 (3%)] Loss: 237.745331\n",
      "Train Epoch: 34 [10817/17352 (62%)] Loss: 218.514522\n",
      "Train Epoch: 34 [17263/17352 (99%)] Loss: 232.059717\n",
      "    epoch          : 34\n",
      "    loss           : 236.8705050922207\n",
      "    val_loss       : 238.21662012673963\n",
      "    val_log_likelihood: -209.46091714440917\n",
      "    val_log_marginal: -232.66880704173934\n",
      "Train Epoch: 35 [512/17352 (3%)] Loss: 236.732880\n",
      "Train Epoch: 35 [10672/17352 (62%)] Loss: 229.047913\n",
      "Train Epoch: 35 [17263/17352 (99%)] Loss: 214.779024\n",
      "    epoch          : 35\n",
      "    loss           : 223.53883847612778\n",
      "    val_loss       : 224.7822453900142\n",
      "    val_log_likelihood: -194.78716599296516\n",
      "    val_log_marginal: -221.3039744946793\n",
      "Train Epoch: 36 [512/17352 (3%)] Loss: 224.091370\n",
      "Train Epoch: 36 [10487/17352 (60%)] Loss: 219.391449\n",
      "Train Epoch: 36 [17049/17352 (98%)] Loss: 179.892290\n",
      "    epoch          : 36\n",
      "    loss           : 214.89094101256183\n",
      "    val_loss       : 205.9617526652224\n",
      "    val_log_likelihood: -179.9582283269005\n",
      "    val_log_marginal: -201.5361875524504\n",
      "Train Epoch: 37 [512/17352 (3%)] Loss: 202.624115\n",
      "Train Epoch: 37 [9880/17352 (57%)] Loss: 179.413168\n",
      "Train Epoch: 37 [17124/17352 (99%)] Loss: 193.682757\n",
      "    epoch          : 37\n",
      "    loss           : 200.1053462667594\n",
      "    val_loss       : 196.17384434246105\n",
      "    val_log_likelihood: -166.41386420581844\n",
      "    val_log_marginal: -190.87009563832555\n",
      "Train Epoch: 38 [512/17352 (3%)] Loss: 192.942657\n",
      "Train Epoch: 38 [10672/17352 (62%)] Loss: 170.099600\n",
      "Train Epoch: 38 [17263/17352 (99%)] Loss: 184.086722\n",
      "    epoch          : 38\n",
      "    loss           : 187.94657146995553\n",
      "    val_loss       : 186.4862615325973\n",
      "    val_log_likelihood: -156.49607531576527\n",
      "    val_log_marginal: -181.55763578282716\n",
      "Train Epoch: 39 [512/17352 (3%)] Loss: 188.900024\n",
      "Train Epoch: 39 [9861/17352 (57%)] Loss: 213.186959\n",
      "Train Epoch: 39 [16988/17352 (98%)] Loss: 184.372610\n",
      "    epoch          : 39\n",
      "    loss           : 180.95201103065375\n",
      "    val_loss       : 175.4716081200511\n",
      "    val_log_likelihood: -145.79948866808417\n",
      "    val_log_marginal: -169.21670663293224\n",
      "Train Epoch: 40 [512/17352 (3%)] Loss: 176.644257\n",
      "Train Epoch: 40 [10287/17352 (59%)] Loss: 133.266344\n",
      "Train Epoch: 40 [17106/17352 (99%)] Loss: 160.129696\n",
      "    epoch          : 40\n",
      "    loss           : 170.30111258477572\n",
      "    val_loss       : 180.5781629715381\n",
      "    val_log_likelihood: -132.68096637446243\n",
      "    val_log_marginal: -176.58237660305008\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch40.pth ...\n",
      "Train Epoch: 41 [512/17352 (3%)] Loss: 173.908478\n",
      "Train Epoch: 41 [10174/17352 (59%)] Loss: 156.367166\n",
      "Train Epoch: 41 [16934/17352 (98%)] Loss: 130.402476\n",
      "    epoch          : 41\n",
      "    loss           : 171.9276223318907\n",
      "    val_loss       : 161.40661978678617\n",
      "    val_log_likelihood: -126.50856574154807\n",
      "    val_log_marginal: -156.25386766721996\n",
      "Train Epoch: 42 [512/17352 (3%)] Loss: 159.475891\n",
      "Train Epoch: 42 [10540/17352 (61%)] Loss: 164.438247\n",
      "Train Epoch: 42 [17253/17352 (99%)] Loss: 145.234669\n",
      "    epoch          : 42\n",
      "    loss           : 149.64208705807843\n",
      "    val_loss       : 148.91311439908563\n",
      "    val_log_likelihood: -111.88588340764298\n",
      "    val_log_marginal: -143.63407035300747\n",
      "Train Epoch: 43 [512/17352 (3%)] Loss: 149.331787\n",
      "Train Epoch: 43 [10695/17352 (62%)] Loss: 154.415039\n",
      "Train Epoch: 43 [16883/17352 (97%)] Loss: 121.157885\n",
      "    epoch          : 43\n",
      "    loss           : 139.51633222379994\n",
      "    val_loss       : 135.14078180424556\n",
      "    val_log_likelihood: -100.12092871974858\n",
      "    val_log_marginal: -129.36803055569234\n",
      "Train Epoch: 44 [512/17352 (3%)] Loss: 169.217346\n",
      "Train Epoch: 44 [10121/17352 (58%)] Loss: 95.108751\n",
      "Train Epoch: 44 [17124/17352 (99%)] Loss: 137.527170\n",
      "    epoch          : 44\n",
      "    loss           : 129.96378465859084\n",
      "    val_loss       : 125.06418876531193\n",
      "    val_log_likelihood: -92.49274677356338\n",
      "    val_log_marginal: -120.53718846130788\n",
      "Train Epoch: 45 [512/17352 (3%)] Loss: 124.525452\n",
      "Train Epoch: 45 [10216/17352 (59%)] Loss: 78.462725\n",
      "Train Epoch: 45 [16872/17352 (97%)] Loss: 78.085314\n",
      "    epoch          : 45\n",
      "    loss           : 118.39123760570834\n",
      "    val_loss       : 109.70186830238772\n",
      "    val_log_likelihood: -77.409466285602\n",
      "    val_log_marginal: -104.06938304412706\n",
      "Train Epoch: 46 [512/17352 (3%)] Loss: 106.296616\n",
      "Train Epoch: 46 [10000/17352 (58%)] Loss: 68.427287\n",
      "Train Epoch: 46 [17049/17352 (98%)] Loss: 113.981521\n",
      "    epoch          : 46\n",
      "    loss           : 109.83182539464609\n",
      "    val_loss       : 109.42623712798866\n",
      "    val_log_likelihood: -69.61165621391152\n",
      "    val_log_marginal: -102.69491852879001\n",
      "Train Epoch: 47 [512/17352 (3%)] Loss: 105.243851\n",
      "Train Epoch: 47 [10347/17352 (60%)] Loss: 59.454271\n",
      "Train Epoch: 47 [16939/17352 (98%)] Loss: 138.819173\n",
      "    epoch          : 47\n",
      "    loss           : 121.0655264402777\n",
      "    val_loss       : 120.10746994098265\n",
      "    val_log_likelihood: -65.61164024539929\n",
      "    val_log_marginal: -109.82698870163681\n",
      "Train Epoch: 48 [512/17352 (3%)] Loss: 109.765610\n",
      "Train Epoch: 48 [10119/17352 (58%)] Loss: 78.279887\n",
      "Train Epoch: 48 [16992/17352 (98%)] Loss: 94.161979\n",
      "    epoch          : 48\n",
      "    loss           : 102.98582353074717\n",
      "    val_loss       : 90.4226146863352\n",
      "    val_log_likelihood: -49.78408164993903\n",
      "    val_log_marginal: -83.56808432880129\n",
      "Train Epoch: 49 [512/17352 (3%)] Loss: 84.519646\n",
      "Train Epoch: 49 [9982/17352 (58%)] Loss: 98.585273\n",
      "Train Epoch: 49 [16887/17352 (97%)] Loss: 103.826102\n",
      "    epoch          : 49\n",
      "    loss           : 85.18163777383603\n",
      "    val_loss       : 87.55245874678916\n",
      "    val_log_likelihood: -40.49161417276299\n",
      "    val_log_marginal: -80.9825936043412\n",
      "Train Epoch: 50 [512/17352 (3%)] Loss: 134.964828\n",
      "Train Epoch: 50 [10149/17352 (58%)] Loss: 95.748645\n",
      "Train Epoch: 50 [16878/17352 (97%)] Loss: 131.367136\n",
      "    epoch          : 50\n",
      "    loss           : 77.47663901085592\n",
      "    val_loss       : 81.54520137143531\n",
      "    val_log_likelihood: -35.14830981131127\n",
      "    val_log_marginal: -77.09024203161674\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch50.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 51 [512/17352 (3%)] Loss: 76.809738\n",
      "Train Epoch: 51 [10465/17352 (60%)] Loss: 129.186509\n",
      "Train Epoch: 51 [16923/17352 (98%)] Loss: 79.839806\n",
      "    epoch          : 51\n",
      "    loss           : 72.35481398576417\n",
      "    val_loss       : 65.22851289631319\n",
      "    val_log_likelihood: -23.404892799082287\n",
      "    val_log_marginal: -59.17115496566686\n",
      "Train Epoch: 52 [512/17352 (3%)] Loss: 62.286880\n",
      "Train Epoch: 52 [9936/17352 (57%)] Loss: 36.619295\n",
      "Train Epoch: 52 [17090/17352 (98%)] Loss: 60.532080\n",
      "    epoch          : 52\n",
      "    loss           : 63.22856582020561\n",
      "    val_loss       : 75.57410825975107\n",
      "    val_log_likelihood: -16.349199567271793\n",
      "    val_log_marginal: -70.60823706473687\n",
      "Train Epoch: 53 [512/17352 (3%)] Loss: 62.361965\n",
      "Train Epoch: 53 [10019/17352 (58%)] Loss: 59.538743\n",
      "Train Epoch: 53 [17133/17352 (99%)] Loss: 60.709094\n",
      "    epoch          : 53\n",
      "    loss           : 64.05410263041703\n",
      "    val_loss       : 65.19969328362026\n",
      "    val_log_likelihood: -12.053706935135594\n",
      "    val_log_marginal: -58.04336217108407\n",
      "Train Epoch: 54 [512/17352 (3%)] Loss: 51.862625\n",
      "Train Epoch: 54 [11089/17352 (64%)] Loss: 37.857170\n",
      "Train Epoch: 54 [17044/17352 (98%)] Loss: 25.041951\n",
      "    epoch          : 54\n",
      "    loss           : 48.873674846945505\n",
      "    val_loss       : 44.43223268355946\n",
      "    val_log_likelihood: 5.3843309048682695\n",
      "    val_log_marginal: -38.07043197018651\n",
      "Train Epoch: 55 [512/17352 (3%)] Loss: 35.609795\n",
      "Train Epoch: 55 [10312/17352 (59%)] Loss: 55.865647\n",
      "Train Epoch: 55 [16887/17352 (97%)] Loss: 46.546648\n",
      "    epoch          : 55\n",
      "    loss           : 40.414078653906465\n",
      "    val_loss       : 38.53626070664327\n",
      "    val_log_likelihood: 12.051619688837775\n",
      "    val_log_marginal: -32.018542379904126\n",
      "Train Epoch: 56 [512/17352 (3%)] Loss: 38.595943\n",
      "Train Epoch: 56 [10567/17352 (61%)] Loss: 59.850445\n",
      "Train Epoch: 56 [16939/17352 (98%)] Loss: 77.760845\n",
      "    epoch          : 56\n",
      "    loss           : 42.42420413556763\n",
      "    val_loss       : 38.61809504026871\n",
      "    val_log_likelihood: 17.86548835561\n",
      "    val_log_marginal: -27.499983596706787\n",
      "Train Epoch: 57 [512/17352 (3%)] Loss: 27.361063\n",
      "Train Epoch: 57 [10703/17352 (62%)] Loss: -3.374441\n",
      "Train Epoch: 57 [17106/17352 (99%)] Loss: 26.799305\n",
      "    epoch          : 57\n",
      "    loss           : 37.56897581732688\n",
      "    val_loss       : 37.56417005875118\n",
      "    val_log_likelihood: 24.622751702098412\n",
      "    val_log_marginal: -30.148688003910443\n",
      "Train Epoch: 58 [512/17352 (3%)] Loss: 106.982033\n",
      "Train Epoch: 58 [10140/17352 (58%)] Loss: 16.058961\n",
      "Train Epoch: 58 [17153/17352 (99%)] Loss: 56.909413\n",
      "    epoch          : 58\n",
      "    loss           : 45.2889170735808\n",
      "    val_loss       : 38.162734253689784\n",
      "    val_log_likelihood: 27.31290519245524\n",
      "    val_log_marginal: -29.78173936002433\n",
      "Train Epoch: 59 [512/17352 (3%)] Loss: 32.814690\n",
      "Train Epoch: 59 [11063/17352 (64%)] Loss: 13.828548\n",
      "Train Epoch: 59 [17277/17352 (100%)] Loss: 44.806080\n",
      "    epoch          : 59\n",
      "    loss           : 23.33461559622581\n",
      "    val_loss       : 28.13869958986355\n",
      "    val_log_likelihood: 39.72488451736017\n",
      "    val_log_marginal: -21.30191307355866\n",
      "Train Epoch: 60 [512/17352 (3%)] Loss: 20.143991\n",
      "Train Epoch: 60 [9945/17352 (57%)] Loss: 17.389642\n",
      "Train Epoch: 60 [17064/17352 (98%)] Loss: 76.867479\n",
      "    epoch          : 60\n",
      "    loss           : 22.93512692250723\n",
      "    val_loss       : 17.587956133498572\n",
      "    val_log_likelihood: 47.84289880823953\n",
      "    val_log_marginal: -7.747667200904511\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch60.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 61 [512/17352 (3%)] Loss: 5.185987\n",
      "Train Epoch: 61 [9440/17352 (54%)] Loss: -21.063454\n",
      "Train Epoch: 61 [16922/17352 (98%)] Loss: -12.422178\n",
      "    epoch          : 61\n",
      "    loss           : 16.402564868662584\n",
      "    val_loss       : 6.545739883821139\n",
      "    val_log_likelihood: 60.80693901542459\n",
      "    val_log_marginal: 3.5306281167518425\n",
      "Train Epoch: 62 [512/17352 (3%)] Loss: -3.383267\n",
      "Train Epoch: 62 [10514/17352 (61%)] Loss: 24.203681\n",
      "Train Epoch: 62 [16923/17352 (98%)] Loss: -29.906909\n",
      "    epoch          : 62\n",
      "    loss           : 4.4142383121766375\n",
      "    val_loss       : 1.796822501446575\n",
      "    val_log_likelihood: 63.07386520281137\n",
      "    val_log_marginal: 5.622792060962151\n",
      "Train Epoch: 63 [512/17352 (3%)] Loss: -15.230894\n",
      "Train Epoch: 63 [10743/17352 (62%)] Loss: -19.943608\n",
      "Train Epoch: 63 [17253/17352 (99%)] Loss: 34.556139\n",
      "    epoch          : 63\n",
      "    loss           : -3.159344552457178\n",
      "    val_loss       : -2.389222649926435\n",
      "    val_log_likelihood: 76.8442105453849\n",
      "    val_log_marginal: 9.690108309624977\n",
      "Train Epoch: 64 [512/17352 (3%)] Loss: -16.401833\n",
      "Train Epoch: 64 [9830/17352 (57%)] Loss: -19.463813\n",
      "Train Epoch: 64 [16958/17352 (98%)] Loss: -38.171680\n",
      "    epoch          : 64\n",
      "    loss           : -6.7183604914674495\n",
      "    val_loss       : -11.21319570140049\n",
      "    val_log_likelihood: 80.64268893663893\n",
      "    val_log_marginal: 18.3038094285348\n",
      "Train Epoch: 65 [512/17352 (3%)] Loss: -17.523121\n",
      "Train Epoch: 65 [10381/17352 (60%)] Loss: 6.139902\n",
      "Train Epoch: 65 [16939/17352 (98%)] Loss: -91.599530\n",
      "    epoch          : 65\n",
      "    loss           : -12.072901826009202\n",
      "    val_loss       : -7.226726092207036\n",
      "    val_log_likelihood: 85.05320244549569\n",
      "    val_log_marginal: 14.16242817740965\n",
      "Train Epoch: 66 [512/17352 (3%)] Loss: -14.902818\n",
      "Train Epoch: 66 [10117/17352 (58%)] Loss: 37.935114\n",
      "Train Epoch: 66 [16939/17352 (98%)] Loss: -9.757588\n",
      "    epoch          : 66\n",
      "    loss           : -9.390364305797942\n",
      "    val_loss       : -19.81421380101076\n",
      "    val_log_likelihood: 95.7554248334939\n",
      "    val_log_marginal: 26.24936821465112\n",
      "Train Epoch: 67 [512/17352 (3%)] Loss: -27.574419\n",
      "Train Epoch: 67 [10274/17352 (59%)] Loss: -23.141353\n",
      "Train Epoch: 67 [16988/17352 (98%)] Loss: -2.842972\n",
      "    epoch          : 67\n",
      "    loss           : -10.833051209109193\n",
      "    val_loss       : 16.459408678055134\n",
      "    val_log_likelihood: 97.58858817600199\n",
      "    val_log_marginal: -5.714759977443454\n",
      "Train Epoch: 68 [512/17352 (3%)] Loss: -0.279732\n",
      "Train Epoch: 68 [10079/17352 (58%)] Loss: -44.893229\n",
      "Train Epoch: 68 [16882/17352 (97%)] Loss: 27.597180\n",
      "    epoch          : 68\n",
      "    loss           : -11.512098868297143\n",
      "    val_loss       : -15.48372627612461\n",
      "    val_log_likelihood: 100.20593651842107\n",
      "    val_log_marginal: 25.718683002376828\n",
      "Train Epoch: 69 [512/17352 (3%)] Loss: -31.717680\n",
      "Train Epoch: 69 [10075/17352 (58%)] Loss: 15.152445\n",
      "Train Epoch: 69 [16872/17352 (97%)] Loss: 92.439584\n",
      "    epoch          : 69\n",
      "    loss           : -12.119994676197335\n",
      "    val_loss       : -6.012598859791473\n",
      "    val_log_likelihood: 109.24647507660029\n",
      "    val_log_marginal: 29.757742483477905\n",
      "Train Epoch: 70 [512/17352 (3%)] Loss: -25.411150\n",
      "Train Epoch: 70 [10466/17352 (60%)] Loss: -113.548541\n",
      "Train Epoch: 70 [17106/17352 (99%)] Loss: -57.192304\n",
      "    epoch          : 70\n",
      "    loss           : -13.94195269818207\n",
      "    val_loss       : -13.42714816104576\n",
      "    val_log_likelihood: 107.82602379681848\n",
      "    val_log_marginal: 22.243199305227275\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch70.pth ...\n",
      "Train Epoch: 71 [512/17352 (3%)] Loss: -30.439850\n",
      "Train Epoch: 71 [10181/17352 (59%)] Loss: -67.763190\n",
      "Train Epoch: 71 [16878/17352 (97%)] Loss: -37.981197\n",
      "    epoch          : 71\n",
      "    loss           : -29.79801506428602\n",
      "    val_loss       : -34.58490472872138\n",
      "    val_log_likelihood: 128.05115533180643\n",
      "    val_log_marginal: 42.89329391018312\n",
      "Train Epoch: 72 [512/17352 (3%)] Loss: -30.943672\n",
      "Train Epoch: 72 [10145/17352 (58%)] Loss: -16.688839\n",
      "Train Epoch: 72 [16934/17352 (98%)] Loss: -7.025996\n",
      "    epoch          : 72\n",
      "    loss           : -32.67392637043829\n",
      "    val_loss       : -37.29785351784402\n",
      "    val_log_likelihood: 134.54456429378544\n",
      "    val_log_marginal: 47.43319525965437\n",
      "Train Epoch: 73 [512/17352 (3%)] Loss: -61.311317\n",
      "Train Epoch: 73 [10451/17352 (60%)] Loss: 46.902566\n",
      "Train Epoch: 73 [16958/17352 (98%)] Loss: -82.287134\n",
      "    epoch          : 73\n",
      "    loss           : -33.519392831065176\n",
      "    val_loss       : -39.99953727359009\n",
      "    val_log_likelihood: 132.29384773929613\n",
      "    val_log_marginal: 50.332064336996915\n",
      "Train Epoch: 74 [512/17352 (3%)] Loss: -45.234009\n",
      "Train Epoch: 74 [10930/17352 (63%)] Loss: -0.303677\n",
      "Train Epoch: 74 [17133/17352 (99%)] Loss: -83.046146\n",
      "    epoch          : 74\n",
      "    loss           : -41.608407883443014\n",
      "    val_loss       : -45.96632176422013\n",
      "    val_log_likelihood: 143.63635738442127\n",
      "    val_log_marginal: 56.972879453033514\n",
      "Train Epoch: 75 [512/17352 (3%)] Loss: -57.396473\n",
      "Train Epoch: 75 [9816/17352 (57%)] Loss: -48.011797\n",
      "Train Epoch: 75 [16883/17352 (97%)] Loss: -71.137047\n",
      "    epoch          : 75\n",
      "    loss           : -50.69615768862342\n",
      "    val_loss       : -47.60073237196785\n",
      "    val_log_likelihood: 154.50172035818377\n",
      "    val_log_marginal: 60.84519395799933\n",
      "Train Epoch: 76 [512/17352 (3%)] Loss: -73.115700\n",
      "Train Epoch: 76 [10247/17352 (59%)] Loss: -53.233048\n",
      "Train Epoch: 76 [16883/17352 (97%)] Loss: -104.660196\n",
      "    epoch          : 76\n",
      "    loss           : -52.66066269876377\n",
      "    val_loss       : -53.71566483525862\n",
      "    val_log_likelihood: 165.13343151357702\n",
      "    val_log_marginal: 63.346716402826544\n",
      "Train Epoch: 77 [512/17352 (3%)] Loss: -70.882080\n",
      "Train Epoch: 77 [10153/17352 (59%)] Loss: -89.875133\n",
      "Train Epoch: 77 [17090/17352 (98%)] Loss: -19.229140\n",
      "    epoch          : 77\n",
      "    loss           : -46.163946962131504\n",
      "    val_loss       : -47.457321140961874\n",
      "    val_log_likelihood: 167.18576221382062\n",
      "    val_log_marginal: 58.87692085583032\n",
      "Train Epoch: 78 [512/17352 (3%)] Loss: -50.381775\n",
      "Train Epoch: 78 [10561/17352 (61%)] Loss: -78.721144\n",
      "Train Epoch: 78 [16992/17352 (98%)] Loss: -92.906011\n",
      "    epoch          : 78\n",
      "    loss           : -49.37251710303255\n",
      "    val_loss       : -59.69247080292765\n",
      "    val_log_likelihood: 172.77063550637766\n",
      "    val_log_marginal: 70.48864639422544\n",
      "Train Epoch: 79 [512/17352 (3%)] Loss: -72.089523\n",
      "Train Epoch: 79 [10190/17352 (59%)] Loss: -21.116081\n",
      "Train Epoch: 79 [16883/17352 (97%)] Loss: -49.219321\n",
      "    epoch          : 79\n",
      "    loss           : -47.37636476742998\n",
      "    val_loss       : -66.04959538589334\n",
      "    val_log_likelihood: 171.60496248249075\n",
      "    val_log_marginal: 77.49022683560044\n",
      "Train Epoch: 80 [512/17352 (3%)] Loss: -79.975739\n",
      "Train Epoch: 80 [10517/17352 (61%)] Loss: -75.878447\n",
      "Train Epoch: 80 [16923/17352 (98%)] Loss: -141.590704\n",
      "    epoch          : 80\n",
      "    loss           : -52.1665975341099\n",
      "    val_loss       : -66.83016866151345\n",
      "    val_log_likelihood: 180.9634622299492\n",
      "    val_log_marginal: 77.84473653460049\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch80.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 81 [512/17352 (3%)] Loss: -87.767441\n",
      "Train Epoch: 81 [10111/17352 (58%)] Loss: -29.790045\n",
      "Train Epoch: 81 [16958/17352 (98%)] Loss: -104.974678\n",
      "    epoch          : 81\n",
      "    loss           : -66.48949886071355\n",
      "    val_loss       : -73.97248857283351\n",
      "    val_log_likelihood: 194.2308863401518\n",
      "    val_log_marginal: 84.26010750120541\n",
      "Train Epoch: 82 [512/17352 (3%)] Loss: -80.732155\n",
      "Train Epoch: 82 [10363/17352 (60%)] Loss: -82.155929\n",
      "Train Epoch: 82 [17044/17352 (98%)] Loss: -165.475346\n",
      "    epoch          : 82\n",
      "    loss           : -76.8748854111818\n",
      "    val_loss       : -76.56008379364323\n",
      "    val_log_likelihood: 199.34343944243403\n",
      "    val_log_marginal: 89.86934433368687\n",
      "Train Epoch: 83 [512/17352 (3%)] Loss: -98.830818\n",
      "Train Epoch: 83 [10172/17352 (59%)] Loss: -79.960782\n",
      "Train Epoch: 83 [16923/17352 (98%)] Loss: -117.021786\n",
      "    epoch          : 83\n",
      "    loss           : -80.36747549614894\n",
      "    val_loss       : -85.7830861858106\n",
      "    val_log_likelihood: 216.04484631513512\n",
      "    val_log_marginal: 100.81114815451306\n",
      "Train Epoch: 84 [512/17352 (3%)] Loss: -102.497963\n",
      "Train Epoch: 84 [10616/17352 (61%)] Loss: 0.736093\n",
      "Train Epoch: 84 [17126/17352 (99%)] Loss: -50.729291\n",
      "    epoch          : 84\n",
      "    loss           : -88.49940763803791\n",
      "    val_loss       : -89.30525492598196\n",
      "    val_log_likelihood: 218.50931763825875\n",
      "    val_log_marginal: 100.41884777830067\n",
      "Train Epoch: 85 [512/17352 (3%)] Loss: -102.304527\n",
      "Train Epoch: 85 [10542/17352 (61%)] Loss: -105.280403\n",
      "Train Epoch: 85 [17064/17352 (98%)] Loss: -31.575619\n",
      "    epoch          : 85\n",
      "    loss           : -93.66630560016564\n",
      "    val_loss       : -89.69763944863624\n",
      "    val_log_likelihood: 212.92218915854673\n",
      "    val_log_marginal: 96.54089625852333\n",
      "Train Epoch: 86 [512/17352 (3%)] Loss: -107.548431\n",
      "Train Epoch: 86 [10631/17352 (61%)] Loss: -82.979678\n",
      "Train Epoch: 86 [17277/17352 (100%)] Loss: -69.268924\n",
      "    epoch          : 86\n",
      "    loss           : -95.8729422869064\n",
      "    val_loss       : -94.19602645695785\n",
      "    val_log_likelihood: 232.519136912835\n",
      "    val_log_marginal: 105.92698396708782\n",
      "Train Epoch: 87 [512/17352 (3%)] Loss: -103.709076\n",
      "Train Epoch: 87 [10705/17352 (62%)] Loss: -93.389466\n",
      "Train Epoch: 87 [16887/17352 (97%)] Loss: -26.645617\n",
      "    epoch          : 87\n",
      "    loss           : -97.61255308955177\n",
      "    val_loss       : -96.45285637906021\n",
      "    val_log_likelihood: 236.64380569555823\n",
      "    val_log_marginal: 107.55202344017106\n",
      "Train Epoch: 88 [512/17352 (3%)] Loss: -118.152313\n",
      "Train Epoch: 88 [10430/17352 (60%)] Loss: -186.181670\n",
      "Train Epoch: 88 [17049/17352 (98%)] Loss: -119.434738\n",
      "    epoch          : 88\n",
      "    loss           : -76.47154953449963\n",
      "    val_loss       : -72.11903946591963\n",
      "    val_log_likelihood: 217.57642492084193\n",
      "    val_log_marginal: 87.06067354928177\n",
      "Train Epoch: 89 [512/17352 (3%)] Loss: -94.142906\n",
      "Train Epoch: 89 [10539/17352 (61%)] Loss: -29.788639\n",
      "Train Epoch: 89 [16939/17352 (98%)] Loss: 50.205406\n",
      "    epoch          : 89\n",
      "    loss           : -9.86968463478488\n",
      "    val_loss       : 18.846765694868115\n",
      "    val_log_likelihood: 169.59463781729977\n",
      "    val_log_marginal: 9.941304952827787\n",
      "Train Epoch: 90 [512/17352 (3%)] Loss: -16.430920\n",
      "Train Epoch: 90 [10213/17352 (59%)] Loss: 32.659319\n",
      "Train Epoch: 90 [16988/17352 (98%)] Loss: -117.885258\n",
      "    epoch          : 90\n",
      "    loss           : -31.13579200623966\n",
      "    val_loss       : -75.01342766912478\n",
      "    val_log_likelihood: 204.4932631107708\n",
      "    val_log_marginal: 87.6348884947946\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch90.pth ...\n",
      "Train Epoch: 91 [512/17352 (3%)] Loss: -90.104546\n",
      "Train Epoch: 91 [10131/17352 (58%)] Loss: -129.143569\n",
      "Train Epoch: 91 [17253/17352 (99%)] Loss: -76.574599\n",
      "    epoch          : 91\n",
      "    loss           : -95.63460783444016\n",
      "    val_loss       : -100.99355227551571\n",
      "    val_log_likelihood: 242.55529507797414\n",
      "    val_log_marginal: 115.47112510465313\n",
      "Train Epoch: 92 [512/17352 (3%)] Loss: -124.011559\n",
      "Train Epoch: 92 [10631/17352 (61%)] Loss: -88.954267\n",
      "Train Epoch: 92 [17277/17352 (100%)] Loss: -177.849356\n",
      "    epoch          : 92\n",
      "    loss           : -110.05018210889031\n",
      "    val_loss       : -114.37975487209224\n",
      "    val_log_likelihood: 256.0983202229509\n",
      "    val_log_marginal: 124.65134866739562\n",
      "Train Epoch: 93 [512/17352 (3%)] Loss: -150.612885\n",
      "Train Epoch: 93 [10031/17352 (58%)] Loss: -158.872237\n",
      "Train Epoch: 93 [16882/17352 (97%)] Loss: -122.364609\n",
      "    epoch          : 93\n",
      "    loss           : -116.64508129915531\n",
      "    val_loss       : -123.83303270953053\n",
      "    val_log_likelihood: 264.40656858215016\n",
      "    val_log_marginal: 132.4943726710191\n",
      "Train Epoch: 94 [512/17352 (3%)] Loss: -133.494446\n",
      "Train Epoch: 94 [10228/17352 (59%)] Loss: -126.156678\n",
      "Train Epoch: 94 [16988/17352 (98%)] Loss: -159.098641\n",
      "    epoch          : 94\n",
      "    loss           : -123.63447044598226\n",
      "    val_loss       : -127.56366736202185\n",
      "    val_log_likelihood: 275.2420693804376\n",
      "    val_log_marginal: 139.53084090801772\n",
      "Train Epoch: 95 [512/17352 (3%)] Loss: -154.616394\n",
      "Train Epoch: 95 [10425/17352 (60%)] Loss: -54.177696\n",
      "Train Epoch: 95 [17335/17352 (100%)] Loss: -70.800318\n",
      "    epoch          : 95\n",
      "    loss           : -125.24789628206292\n",
      "    val_loss       : -109.82729524634524\n",
      "    val_log_likelihood: 285.56391489413784\n",
      "    val_log_marginal: 123.8677322071866\n",
      "Train Epoch: 96 [512/17352 (3%)] Loss: -18.023270\n",
      "Train Epoch: 96 [10319/17352 (59%)] Loss: -125.871747\n",
      "Train Epoch: 96 [17064/17352 (98%)] Loss: -138.800120\n",
      "    epoch          : 96\n",
      "    loss           : -125.26600696928274\n",
      "    val_loss       : -131.6670520455075\n",
      "    val_log_likelihood: 287.5941567944125\n",
      "    val_log_marginal: 147.54752552611026\n",
      "Train Epoch: 97 [512/17352 (3%)] Loss: -158.764023\n",
      "Train Epoch: 97 [10195/17352 (59%)] Loss: -212.861776\n",
      "Train Epoch: 97 [16922/17352 (98%)] Loss: -182.821678\n",
      "    epoch          : 97\n",
      "    loss           : -137.8059034111852\n",
      "    val_loss       : -145.91992492672952\n",
      "    val_log_likelihood: 305.63003501684705\n",
      "    val_log_marginal: 157.66637763906155\n",
      "Train Epoch: 98 [512/17352 (3%)] Loss: -160.719055\n",
      "Train Epoch: 98 [10788/17352 (62%)] Loss: -102.314089\n",
      "Train Epoch: 98 [16958/17352 (98%)] Loss: -129.627308\n",
      "    epoch          : 98\n",
      "    loss           : -144.7562689881958\n",
      "    val_loss       : -146.39124306051053\n",
      "    val_log_likelihood: 310.6406996154929\n",
      "    val_log_marginal: 159.5951030638972\n",
      "Train Epoch: 99 [512/17352 (3%)] Loss: -155.780426\n",
      "Train Epoch: 99 [10612/17352 (61%)] Loss: -141.470736\n",
      "Train Epoch: 99 [16988/17352 (98%)] Loss: -183.883987\n",
      "    epoch          : 99\n",
      "    loss           : -139.57133956984356\n",
      "    val_loss       : -141.99137625004076\n",
      "    val_log_likelihood: 311.09105211586905\n",
      "    val_log_marginal: 160.35111896633586\n",
      "Train Epoch: 100 [512/17352 (3%)] Loss: -161.131683\n",
      "Train Epoch: 100 [10165/17352 (59%)] Loss: -109.633389\n",
      "Train Epoch: 100 [17263/17352 (99%)] Loss: -152.470387\n",
      "    epoch          : 100\n",
      "    loss           : -150.29332996296293\n",
      "    val_loss       : -148.6896135487557\n",
      "    val_log_likelihood: 325.6593097362548\n",
      "    val_log_marginal: 160.69239099382742\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch100.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 101 [512/17352 (3%)] Loss: -176.239197\n",
      "Train Epoch: 101 [10282/17352 (59%)] Loss: -127.433958\n",
      "Train Epoch: 101 [17253/17352 (99%)] Loss: -202.956285\n",
      "    epoch          : 101\n",
      "    loss           : -154.82289585489093\n",
      "    val_loss       : -144.22156500192486\n",
      "    val_log_likelihood: 325.3025780832389\n",
      "    val_log_marginal: 161.84932966637308\n",
      "Train Epoch: 102 [512/17352 (3%)] Loss: -156.956116\n",
      "Train Epoch: 102 [10784/17352 (62%)] Loss: -213.900198\n",
      "Train Epoch: 102 [17335/17352 (100%)] Loss: -140.757304\n",
      "    epoch          : 102\n",
      "    loss           : -146.82536928080233\n",
      "    val_loss       : -152.24210651982565\n",
      "    val_log_likelihood: 325.66210724661994\n",
      "    val_log_marginal: 165.06356474789018\n",
      "Train Epoch: 103 [512/17352 (3%)] Loss: -178.986984\n",
      "Train Epoch: 103 [10137/17352 (58%)] Loss: -169.489544\n",
      "Train Epoch: 103 [16992/17352 (98%)] Loss: 16.693127\n",
      "    epoch          : 103\n",
      "    loss           : -157.22736885632366\n",
      "    val_loss       : -159.91447516611706\n",
      "    val_log_likelihood: 333.6340468180872\n",
      "    val_log_marginal: 178.4658856881152\n",
      "Train Epoch: 104 [512/17352 (3%)] Loss: -182.938202\n",
      "Train Epoch: 104 [10521/17352 (61%)] Loss: -188.896891\n",
      "Train Epoch: 104 [17277/17352 (100%)] Loss: -290.611807\n",
      "    epoch          : 104\n",
      "    loss           : -171.7883328969152\n",
      "    val_loss       : -172.3329041261122\n",
      "    val_log_likelihood: 346.215834616147\n",
      "    val_log_marginal: 190.40390463804601\n",
      "Train Epoch: 105 [512/17352 (3%)] Loss: -173.613968\n",
      "Train Epoch: 105 [10046/17352 (58%)] Loss: -106.994508\n",
      "Train Epoch: 105 [17143/17352 (99%)] Loss: -222.327435\n",
      "    epoch          : 105\n",
      "    loss           : -172.45771413640213\n",
      "    val_loss       : -169.1675759396699\n",
      "    val_log_likelihood: 359.2993193699155\n",
      "    val_log_marginal: 184.8923563187256\n",
      "Train Epoch: 106 [512/17352 (3%)] Loss: -202.255249\n",
      "Train Epoch: 106 [10224/17352 (59%)] Loss: -187.866880\n",
      "Train Epoch: 106 [17106/17352 (99%)] Loss: -263.168647\n",
      "    epoch          : 106\n",
      "    loss           : -174.1341030619393\n",
      "    val_loss       : -173.98767945388624\n",
      "    val_log_likelihood: 363.09540419169304\n",
      "    val_log_marginal: 194.2648720150897\n",
      "Train Epoch: 107 [512/17352 (3%)] Loss: -173.730957\n",
      "Train Epoch: 107 [10764/17352 (62%)] Loss: -97.293698\n",
      "Train Epoch: 107 [16922/17352 (98%)] Loss: -196.068102\n",
      "    epoch          : 107\n",
      "    loss           : -174.25176328456004\n",
      "    val_loss       : -179.11336864770968\n",
      "    val_log_likelihood: 355.8393682676698\n",
      "    val_log_marginal: 195.17305665321965\n",
      "Train Epoch: 108 [512/17352 (3%)] Loss: -220.910187\n",
      "Train Epoch: 108 [10536/17352 (61%)] Loss: -220.508285\n",
      "Train Epoch: 108 [17016/17352 (98%)] Loss: -214.237551\n",
      "    epoch          : 108\n",
      "    loss           : -180.11137187277455\n",
      "    val_loss       : -168.0388619831772\n",
      "    val_log_likelihood: 371.57033645532084\n",
      "    val_log_marginal: 196.99414773348153\n",
      "Train Epoch: 109 [512/17352 (3%)] Loss: -190.656448\n",
      "Train Epoch: 109 [10425/17352 (60%)] Loss: -208.262467\n",
      "Train Epoch: 109 [16957/17352 (98%)] Loss: -137.846776\n",
      "    epoch          : 109\n",
      "    loss           : -170.08904968914996\n",
      "    val_loss       : -180.56058677331757\n",
      "    val_log_likelihood: 361.30385125438164\n",
      "    val_log_marginal: 196.73292456433825\n",
      "Train Epoch: 110 [512/17352 (3%)] Loss: -199.531281\n",
      "Train Epoch: 110 [10482/17352 (60%)] Loss: -238.925305\n",
      "Train Epoch: 110 [16934/17352 (98%)] Loss: -248.606341\n",
      "    epoch          : 110\n",
      "    loss           : -180.82235151555426\n",
      "    val_loss       : -198.24572520544714\n",
      "    val_log_likelihood: 385.10721120094604\n",
      "    val_log_marginal: 214.3433000208968\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch110.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 111 [512/17352 (3%)] Loss: -87.592468\n",
      "Train Epoch: 111 [10530/17352 (61%)] Loss: -166.662214\n",
      "Train Epoch: 111 [17049/17352 (98%)] Loss: -266.260206\n",
      "    epoch          : 111\n",
      "    loss           : -205.44884652082138\n",
      "    val_loss       : -202.75904457601743\n",
      "    val_log_likelihood: 400.5893116058754\n",
      "    val_log_marginal: 216.80770476455683\n",
      "Train Epoch: 112 [512/17352 (3%)] Loss: -54.062317\n",
      "Train Epoch: 112 [10306/17352 (59%)] Loss: -109.327871\n",
      "Train Epoch: 112 [17090/17352 (98%)] Loss: 79.925379\n",
      "    epoch          : 112\n",
      "    loss           : -124.36863451614767\n",
      "    val_loss       : -86.16134654586546\n",
      "    val_log_likelihood: 353.481400508831\n",
      "    val_log_marginal: 118.68485478635931\n",
      "Train Epoch: 113 [512/17352 (3%)] Loss: -133.001007\n",
      "Train Epoch: 113 [10006/17352 (58%)] Loss: 24.188506\n",
      "Train Epoch: 113 [16992/17352 (98%)] Loss: -141.447374\n",
      "    epoch          : 113\n",
      "    loss           : -84.8055232396341\n",
      "    val_loss       : -140.29087571847086\n",
      "    val_log_likelihood: 351.3661239682461\n",
      "    val_log_marginal: 161.8566732451033\n",
      "Train Epoch: 114 [512/17352 (3%)] Loss: -172.059372\n",
      "Train Epoch: 114 [10618/17352 (61%)] Loss: -220.444090\n",
      "Train Epoch: 114 [17108/17352 (99%)] Loss: -156.928861\n",
      "    epoch          : 114\n",
      "    loss           : -140.59929676928886\n",
      "    val_loss       : -172.5555666548828\n",
      "    val_log_likelihood: 367.2840336055443\n",
      "    val_log_marginal: 193.61243162019542\n",
      "Train Epoch: 115 [512/17352 (3%)] Loss: -184.696060\n",
      "Train Epoch: 115 [10575/17352 (61%)] Loss: -131.453237\n",
      "Train Epoch: 115 [17101/17352 (99%)] Loss: -193.015141\n",
      "    epoch          : 115\n",
      "    loss           : -191.23157598514175\n",
      "    val_loss       : -192.2886973303183\n",
      "    val_log_likelihood: 385.16186991284894\n",
      "    val_log_marginal: 216.8897055490408\n",
      "Train Epoch: 116 [512/17352 (3%)] Loss: -230.413605\n",
      "Train Epoch: 116 [10667/17352 (61%)] Loss: -297.769560\n",
      "Train Epoch: 116 [17049/17352 (98%)] Loss: -200.117667\n",
      "    epoch          : 116\n",
      "    loss           : -218.98463644259562\n",
      "    val_loss       : -229.13265442296978\n",
      "    val_log_likelihood: 411.63316717735546\n",
      "    val_log_marginal: 243.65452168245224\n",
      "Train Epoch: 117 [512/17352 (3%)] Loss: -255.742477\n",
      "Train Epoch: 117 [10185/17352 (59%)] Loss: -264.871664\n",
      "Train Epoch: 117 [17101/17352 (99%)] Loss: -167.390608\n",
      "    epoch          : 117\n",
      "    loss           : -227.60707932060012\n",
      "    val_loss       : -230.64405567496902\n",
      "    val_log_likelihood: 417.6553361370194\n",
      "    val_log_marginal: 247.40895551704213\n",
      "Train Epoch: 118 [512/17352 (3%)] Loss: -238.486298\n",
      "Train Epoch: 118 [10538/17352 (61%)] Loss: -175.365842\n",
      "Train Epoch: 118 [16958/17352 (98%)] Loss: -297.784968\n",
      "    epoch          : 118\n",
      "    loss           : -238.44490815934822\n",
      "    val_loss       : -236.73966548180184\n",
      "    val_log_likelihood: 435.2449385389625\n",
      "    val_log_marginal: 249.94536237464723\n",
      "Train Epoch: 119 [512/17352 (3%)] Loss: -247.931976\n",
      "Train Epoch: 119 [10383/17352 (60%)] Loss: -175.735883\n",
      "Train Epoch: 119 [17049/17352 (98%)] Loss: -216.452037\n",
      "    epoch          : 119\n",
      "    loss           : -245.0435475143428\n",
      "    val_loss       : -252.46428537428784\n",
      "    val_log_likelihood: 443.87385282498485\n",
      "    val_log_marginal: 267.6566086623527\n",
      "Train Epoch: 120 [512/17352 (3%)] Loss: -277.380859\n",
      "Train Epoch: 120 [10681/17352 (62%)] Loss: -332.810306\n",
      "Train Epoch: 120 [17016/17352 (98%)] Loss: -325.638730\n",
      "    epoch          : 120\n",
      "    loss           : -256.89297732047504\n",
      "    val_loss       : -262.4430882384789\n",
      "    val_log_likelihood: 458.8472381215858\n",
      "    val_log_marginal: 275.9854318056396\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch120.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 121 [512/17352 (3%)] Loss: -292.737061\n",
      "Train Epoch: 121 [10679/17352 (62%)] Loss: -379.972814\n",
      "Train Epoch: 121 [16882/17352 (97%)] Loss: -343.860270\n",
      "    epoch          : 121\n",
      "    loss           : -270.4564760121395\n",
      "    val_loss       : -270.09451344172305\n",
      "    val_log_likelihood: 467.8431074381216\n",
      "    val_log_marginal: 283.7579920511891\n",
      "Train Epoch: 122 [512/17352 (3%)] Loss: -292.835693\n",
      "Train Epoch: 122 [10507/17352 (61%)] Loss: -276.395347\n",
      "Train Epoch: 122 [17263/17352 (99%)] Loss: -360.815943\n",
      "    epoch          : 122\n",
      "    loss           : -268.1896502669091\n",
      "    val_loss       : -255.5489743743476\n",
      "    val_log_likelihood: 466.6344634375605\n",
      "    val_log_marginal: 269.82761879946264\n",
      "Train Epoch: 123 [512/17352 (3%)] Loss: -281.526093\n",
      "Train Epoch: 123 [9953/17352 (57%)] Loss: -267.828733\n",
      "Train Epoch: 123 [16872/17352 (97%)] Loss: -337.844149\n",
      "    epoch          : 123\n",
      "    loss           : -258.07312229299265\n",
      "    val_loss       : -268.1705079683904\n",
      "    val_log_likelihood: 473.63418824568384\n",
      "    val_log_marginal: 286.57069966454475\n",
      "Train Epoch: 124 [512/17352 (3%)] Loss: -302.964966\n",
      "Train Epoch: 124 [10660/17352 (61%)] Loss: -287.529948\n",
      "Train Epoch: 124 [16872/17352 (97%)] Loss: -322.988995\n",
      "    epoch          : 124\n",
      "    loss           : -261.6903459919051\n",
      "    val_loss       : -266.25166502693736\n",
      "    val_log_likelihood: 481.7743112587952\n",
      "    val_log_marginal: 284.67667165196\n",
      "Train Epoch: 125 [512/17352 (3%)] Loss: -296.956787\n",
      "Train Epoch: 125 [10134/17352 (58%)] Loss: -214.628703\n",
      "Train Epoch: 125 [17016/17352 (98%)] Loss: -364.259956\n",
      "    epoch          : 125\n",
      "    loss           : -270.0439140826949\n",
      "    val_loss       : -265.1942160112115\n",
      "    val_log_likelihood: 481.12258554192704\n",
      "    val_log_marginal: 288.4047061161142\n",
      "Train Epoch: 126 [512/17352 (3%)] Loss: -295.162811\n",
      "Train Epoch: 126 [9793/17352 (56%)] Loss: -205.108169\n",
      "Train Epoch: 126 [16992/17352 (98%)] Loss: -233.531343\n",
      "    epoch          : 126\n",
      "    loss           : -269.9499058806656\n",
      "    val_loss       : -275.15437173742356\n",
      "    val_log_likelihood: 483.5619354650768\n",
      "    val_log_marginal: 292.84074865277745\n",
      "Train Epoch: 127 [512/17352 (3%)] Loss: -304.013367\n",
      "Train Epoch: 127 [10822/17352 (62%)] Loss: -152.598937\n",
      "Train Epoch: 127 [17090/17352 (98%)] Loss: -198.926325\n",
      "    epoch          : 127\n",
      "    loss           : -272.38648519076435\n",
      "    val_loss       : -118.35230283629356\n",
      "    val_log_likelihood: 487.0816685841643\n",
      "    val_log_marginal: 137.88702356713466\n",
      "Train Epoch: 128 [512/17352 (3%)] Loss: -143.829376\n",
      "Train Epoch: 128 [10087/17352 (58%)] Loss: -260.956354\n",
      "Train Epoch: 128 [17106/17352 (99%)] Loss: -181.381082\n",
      "    epoch          : 128\n",
      "    loss           : -193.7982161061875\n",
      "    val_loss       : -224.0991778370232\n",
      "    val_log_likelihood: 454.71042183236653\n",
      "    val_log_marginal: 248.37833283043082\n",
      "Train Epoch: 129 [512/17352 (3%)] Loss: -254.504608\n",
      "Train Epoch: 129 [10515/17352 (61%)] Loss: -346.831923\n",
      "Train Epoch: 129 [16922/17352 (98%)] Loss: -213.951332\n",
      "    epoch          : 129\n",
      "    loss           : -229.80247897489778\n",
      "    val_loss       : -259.7782618158799\n",
      "    val_log_likelihood: 481.7020765193304\n",
      "    val_log_marginal: 285.2993750511938\n",
      "Train Epoch: 130 [512/17352 (3%)] Loss: -281.316528\n",
      "Train Epoch: 130 [10515/17352 (61%)] Loss: -316.906599\n",
      "Train Epoch: 130 [17108/17352 (99%)] Loss: -317.055102\n",
      "    epoch          : 130\n",
      "    loss           : -263.4472459253114\n",
      "    val_loss       : -283.4227164658429\n",
      "    val_log_likelihood: 501.85336419272664\n",
      "    val_log_marginal: 307.13326876325465\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch130.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 131 [512/17352 (3%)] Loss: -270.275360\n",
      "Train Epoch: 131 [10209/17352 (59%)] Loss: -206.386009\n",
      "Train Epoch: 131 [17253/17352 (99%)] Loss: -363.071585\n",
      "    epoch          : 131\n",
      "    loss           : -289.3404035088556\n",
      "    val_loss       : -296.9922695460731\n",
      "    val_log_likelihood: 515.9416846593406\n",
      "    val_log_marginal: 319.3793873606012\n",
      "Train Epoch: 132 [512/17352 (3%)] Loss: -324.108154\n",
      "Train Epoch: 132 [10334/17352 (60%)] Loss: -340.242816\n",
      "Train Epoch: 132 [17124/17352 (99%)] Loss: -353.614180\n",
      "    epoch          : 132\n",
      "    loss           : -302.07728202083143\n",
      "    val_loss       : -308.21573809523454\n",
      "    val_log_likelihood: 522.9263568928093\n",
      "    val_log_marginal: 325.5292129361341\n",
      "Train Epoch: 133 [512/17352 (3%)] Loss: -330.556152\n",
      "Train Epoch: 133 [9702/17352 (56%)] Loss: -418.669271\n",
      "Train Epoch: 133 [17016/17352 (98%)] Loss: -391.951293\n",
      "    epoch          : 133\n",
      "    loss           : -307.90247743536486\n",
      "    val_loss       : -297.67288950563557\n",
      "    val_log_likelihood: 523.8557999386969\n",
      "    val_log_marginal: 320.8024368896815\n",
      "Train Epoch: 134 [512/17352 (3%)] Loss: -334.914429\n",
      "Train Epoch: 134 [10346/17352 (60%)] Loss: -177.098417\n",
      "Train Epoch: 134 [16882/17352 (97%)] Loss: -310.730114\n",
      "    epoch          : 134\n",
      "    loss           : -286.779202364885\n",
      "    val_loss       : -306.42148973769775\n",
      "    val_log_likelihood: 530.1906940494667\n",
      "    val_log_marginal: 328.30570513856156\n",
      "Train Epoch: 135 [512/17352 (3%)] Loss: -332.970123\n",
      "Train Epoch: 135 [10687/17352 (62%)] Loss: -417.553571\n",
      "Train Epoch: 135 [17016/17352 (98%)] Loss: -123.709081\n",
      "    epoch          : 135\n",
      "    loss           : -305.1228830792331\n",
      "    val_loss       : -275.4788865032125\n",
      "    val_log_likelihood: 537.944057764456\n",
      "    val_log_marginal: 294.75481160944264\n",
      "Train Epoch: 136 [512/17352 (3%)] Loss: -287.627930\n",
      "Train Epoch: 136 [10259/17352 (59%)] Loss: -242.107594\n",
      "Train Epoch: 136 [17126/17352 (99%)] Loss: -305.368365\n",
      "    epoch          : 136\n",
      "    loss           : -274.2767752624026\n",
      "    val_loss       : -262.19988471922267\n",
      "    val_log_likelihood: 511.7718967810092\n",
      "    val_log_marginal: 288.521253054989\n",
      "Train Epoch: 137 [512/17352 (3%)] Loss: -285.725525\n",
      "Train Epoch: 137 [10687/17352 (62%)] Loss: -387.625033\n",
      "Train Epoch: 137 [17101/17352 (99%)] Loss: -280.600114\n",
      "    epoch          : 137\n",
      "    loss           : -268.8564550732289\n",
      "    val_loss       : -149.3415009070583\n",
      "    val_log_likelihood: 513.079205346193\n",
      "    val_log_marginal: 171.95641930242914\n",
      "Train Epoch: 138 [512/17352 (3%)] Loss: -103.092133\n",
      "Train Epoch: 138 [10500/17352 (61%)] Loss: -278.785941\n",
      "Train Epoch: 138 [17277/17352 (100%)] Loss: -219.328317\n",
      "    epoch          : 138\n",
      "    loss           : -173.61194156804063\n",
      "    val_loss       : -241.86348054026968\n",
      "    val_log_likelihood: 491.78285233112814\n",
      "    val_log_marginal: 262.02292256712576\n",
      "Train Epoch: 139 [512/17352 (3%)] Loss: -261.294891\n",
      "Train Epoch: 139 [10438/17352 (60%)] Loss: -331.937949\n",
      "Train Epoch: 139 [17263/17352 (99%)] Loss: -390.076463\n",
      "    epoch          : 139\n",
      "    loss           : -277.8455167419758\n",
      "    val_loss       : -303.0815411106293\n",
      "    val_log_likelihood: 532.433679903468\n",
      "    val_log_marginal: 326.2310041938554\n",
      "Train Epoch: 140 [512/17352 (3%)] Loss: -152.595078\n",
      "Train Epoch: 140 [9673/17352 (56%)] Loss: -401.728214\n",
      "Train Epoch: 140 [17016/17352 (98%)] Loss: -300.868450\n",
      "    epoch          : 140\n",
      "    loss           : -325.8565727989042\n",
      "    val_loss       : -326.616437445655\n",
      "    val_log_likelihood: 542.2717046045534\n",
      "    val_log_marginal: 348.68016009199937\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch140.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 141 [512/17352 (3%)] Loss: -377.813995\n",
      "Train Epoch: 141 [9999/17352 (58%)] Loss: -357.768099\n",
      "Train Epoch: 141 [17277/17352 (100%)] Loss: -229.459098\n",
      "    epoch          : 141\n",
      "    loss           : -322.1799321463175\n",
      "    val_loss       : -301.8522339582332\n",
      "    val_log_likelihood: 542.6177342407412\n",
      "    val_log_marginal: 336.9757023682543\n",
      "Train Epoch: 142 [512/17352 (3%)] Loss: -349.746216\n",
      "Train Epoch: 142 [10119/17352 (58%)] Loss: -281.368682\n",
      "Train Epoch: 142 [16992/17352 (98%)] Loss: -279.575976\n",
      "    epoch          : 142\n",
      "    loss           : -305.9467156391952\n",
      "    val_loss       : -325.0274000789201\n",
      "    val_log_likelihood: 552.6529021755478\n",
      "    val_log_marginal: 351.3234440444365\n",
      "Train Epoch: 143 [512/17352 (3%)] Loss: -331.496033\n",
      "Train Epoch: 143 [10386/17352 (60%)] Loss: -282.166447\n",
      "Train Epoch: 143 [17124/17352 (99%)] Loss: -324.762071\n",
      "    epoch          : 143\n",
      "    loss           : -345.12090124986094\n",
      "    val_loss       : -351.6451363571982\n",
      "    val_log_likelihood: 570.604284116746\n",
      "    val_log_marginal: 370.4429458936884\n",
      "Train Epoch: 144 [512/17352 (3%)] Loss: -382.286804\n",
      "Train Epoch: 144 [10276/17352 (59%)] Loss: -425.403678\n",
      "Train Epoch: 144 [16887/17352 (97%)] Loss: -432.911076\n",
      "    epoch          : 144\n",
      "    loss           : -354.75082798375695\n",
      "    val_loss       : -358.4843652876945\n",
      "    val_log_likelihood: 582.9812972397303\n",
      "    val_log_marginal: 381.20665421604764\n",
      "Train Epoch: 145 [512/17352 (3%)] Loss: -219.828690\n",
      "Train Epoch: 145 [10801/17352 (62%)] Loss: -410.678244\n",
      "Train Epoch: 145 [17263/17352 (99%)] Loss: -221.737721\n",
      "    epoch          : 145\n",
      "    loss           : -359.2033259531614\n",
      "    val_loss       : -362.9867322459719\n",
      "    val_log_likelihood: 586.6266934668754\n",
      "    val_log_marginal: 378.45785259334076\n",
      "Train Epoch: 146 [512/17352 (3%)] Loss: -394.168823\n",
      "Train Epoch: 146 [10108/17352 (58%)] Loss: -427.973628\n",
      "Train Epoch: 146 [16923/17352 (98%)] Loss: -447.391930\n",
      "    epoch          : 146\n",
      "    loss           : -362.6647479534782\n",
      "    val_loss       : -364.1156955420987\n",
      "    val_log_likelihood: 592.7707359397009\n",
      "    val_log_marginal: 384.8549298134332\n",
      "Train Epoch: 147 [512/17352 (3%)] Loss: -397.791443\n",
      "Train Epoch: 147 [10505/17352 (61%)] Loss: -450.899525\n",
      "Train Epoch: 147 [17153/17352 (99%)] Loss: -286.593022\n",
      "    epoch          : 147\n",
      "    loss           : -371.3494013297809\n",
      "    val_loss       : -362.8966488937533\n",
      "    val_log_likelihood: 596.3424223865699\n",
      "    val_log_marginal: 389.3172834292862\n",
      "Train Epoch: 148 [512/17352 (3%)] Loss: -379.481628\n",
      "Train Epoch: 148 [10416/17352 (60%)] Loss: -288.213086\n",
      "Train Epoch: 148 [17049/17352 (98%)] Loss: -433.443021\n",
      "    epoch          : 148\n",
      "    loss           : -365.56912279333443\n",
      "    val_loss       : -368.48612900438053\n",
      "    val_log_likelihood: 596.2541538527155\n",
      "    val_log_marginal: 385.7464941792581\n",
      "Train Epoch: 149 [512/17352 (3%)] Loss: -411.126892\n",
      "Train Epoch: 149 [10384/17352 (60%)] Loss: -388.929885\n",
      "Train Epoch: 149 [17133/17352 (99%)] Loss: -367.531858\n",
      "    epoch          : 149\n",
      "    loss           : -375.9636571609749\n",
      "    val_loss       : -377.5771086252385\n",
      "    val_log_likelihood: 609.3725171498543\n",
      "    val_log_marginal: 391.40248778734315\n",
      "Train Epoch: 150 [512/17352 (3%)] Loss: -401.159851\n",
      "Train Epoch: 150 [10642/17352 (61%)] Loss: -304.202136\n",
      "Train Epoch: 150 [17106/17352 (99%)] Loss: -365.170731\n",
      "    epoch          : 150\n",
      "    loss           : -373.2580264179276\n",
      "    val_loss       : -364.60185059691565\n",
      "    val_log_likelihood: 609.7202350565778\n",
      "    val_log_marginal: 384.34762924424484\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch150.pth ...\n",
      "Train Epoch: 151 [512/17352 (3%)] Loss: -412.811371\n",
      "Train Epoch: 151 [10929/17352 (63%)] Loss: -346.877558\n",
      "Train Epoch: 151 [17277/17352 (100%)] Loss: -477.457248\n",
      "    epoch          : 151\n",
      "    loss           : -377.9050950120357\n",
      "    val_loss       : -389.71505418938517\n",
      "    val_log_likelihood: 619.9480006712469\n",
      "    val_log_marginal: 403.3800608635036\n",
      "Train Epoch: 152 [512/17352 (3%)] Loss: -408.095551\n",
      "Train Epoch: 152 [10671/17352 (61%)] Loss: -464.755671\n",
      "Train Epoch: 152 [17253/17352 (99%)] Loss: -402.986678\n",
      "    epoch          : 152\n",
      "    loss           : -386.3524024991041\n",
      "    val_loss       : -374.24883977569664\n",
      "    val_log_likelihood: 622.2090378026445\n",
      "    val_log_marginal: 393.01862398756674\n",
      "Train Epoch: 153 [512/17352 (3%)] Loss: -411.217285\n",
      "Train Epoch: 153 [10023/17352 (58%)] Loss: -325.299089\n",
      "Train Epoch: 153 [17263/17352 (99%)] Loss: -205.916734\n",
      "    epoch          : 153\n",
      "    loss           : -384.8424386333174\n",
      "    val_loss       : -369.0680965047157\n",
      "    val_log_likelihood: 602.6354439541\n",
      "    val_log_marginal: 386.43653967531185\n",
      "Train Epoch: 154 [512/17352 (3%)] Loss: -409.515472\n",
      "Train Epoch: 154 [10299/17352 (59%)] Loss: -311.359804\n",
      "Train Epoch: 154 [17126/17352 (99%)] Loss: -391.041317\n",
      "    epoch          : 154\n",
      "    loss           : -376.02722621896044\n",
      "    val_loss       : -387.34624169534754\n",
      "    val_log_likelihood: 624.1516018786529\n",
      "    val_log_marginal: 402.4279931623564\n",
      "Train Epoch: 155 [512/17352 (3%)] Loss: -434.725464\n",
      "Train Epoch: 155 [10902/17352 (63%)] Loss: -420.896973\n",
      "Train Epoch: 155 [17124/17352 (99%)] Loss: -374.441093\n",
      "    epoch          : 155\n",
      "    loss           : -383.68480544441917\n",
      "    val_loss       : -375.63698881190953\n",
      "    val_log_likelihood: 641.5563935980082\n",
      "    val_log_marginal: 393.722206851513\n",
      "Train Epoch: 156 [512/17352 (3%)] Loss: -421.687531\n",
      "Train Epoch: 156 [10334/17352 (60%)] Loss: -265.669379\n",
      "Train Epoch: 156 [17124/17352 (99%)] Loss: -390.120835\n",
      "    epoch          : 156\n",
      "    loss           : -337.59483154787256\n",
      "    val_loss       : -249.63146241366402\n",
      "    val_log_likelihood: 608.2165482818929\n",
      "    val_log_marginal: 275.5515882969687\n",
      "Train Epoch: 157 [512/17352 (3%)] Loss: -287.993347\n",
      "Train Epoch: 157 [10104/17352 (58%)] Loss: -181.253711\n",
      "Train Epoch: 157 [17101/17352 (99%)] Loss: -314.968610\n",
      "    epoch          : 157\n",
      "    loss           : -290.7753764922281\n",
      "    val_loss       : -242.03349473817653\n",
      "    val_log_likelihood: 610.1829046066908\n",
      "    val_log_marginal: 266.6939167524671\n",
      "Train Epoch: 158 [512/17352 (3%)] Loss: -285.007141\n",
      "Train Epoch: 158 [10243/17352 (59%)] Loss: -388.035612\n",
      "Train Epoch: 158 [17263/17352 (99%)] Loss: -269.888537\n",
      "    epoch          : 158\n",
      "    loss           : -319.0810731151902\n",
      "    val_loss       : -360.3101580168631\n",
      "    val_log_likelihood: 608.9295299505112\n",
      "    val_log_marginal: 378.98524440440474\n",
      "Train Epoch: 159 [512/17352 (3%)] Loss: -396.075073\n",
      "Train Epoch: 159 [10458/17352 (60%)] Loss: -438.871005\n",
      "Train Epoch: 159 [17263/17352 (99%)] Loss: -300.199009\n",
      "    epoch          : 159\n",
      "    loss           : -380.363277163364\n",
      "    val_loss       : -341.3083246219766\n",
      "    val_log_likelihood: 638.3441674859116\n",
      "    val_log_marginal: 358.4567234216002\n",
      "Train Epoch: 160 [512/17352 (3%)] Loss: -379.766876\n",
      "Train Epoch: 160 [10128/17352 (58%)] Loss: -366.969178\n",
      "Train Epoch: 160 [17108/17352 (99%)] Loss: -238.724316\n",
      "    epoch          : 160\n",
      "    loss           : -331.5183675319758\n",
      "    val_loss       : -144.11787182881736\n",
      "    val_log_likelihood: 619.9058692210701\n",
      "    val_log_marginal: 190.28506811595716\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch160.pth ...\n",
      "Train Epoch: 161 [512/17352 (3%)] Loss: -185.470688\n",
      "Train Epoch: 161 [10637/17352 (61%)] Loss: -333.264440\n",
      "Train Epoch: 161 [16883/17352 (97%)] Loss: -431.280884\n",
      "    epoch          : 161\n",
      "    loss           : -347.33199358530277\n",
      "    val_loss       : -385.1089864537789\n",
      "    val_log_likelihood: 643.1680247810098\n",
      "    val_log_marginal: 419.59275167323335\n",
      "Train Epoch: 162 [512/17352 (3%)] Loss: -410.418335\n",
      "Train Epoch: 162 [10638/17352 (61%)] Loss: -484.888830\n",
      "Train Epoch: 162 [17049/17352 (98%)] Loss: -407.326547\n",
      "    epoch          : 162\n",
      "    loss           : -404.1274823263903\n",
      "    val_loss       : -405.00952379248486\n",
      "    val_log_likelihood: 655.3540676863786\n",
      "    val_log_marginal: 433.0827367236988\n",
      "Train Epoch: 163 [512/17352 (3%)] Loss: -445.699951\n",
      "Train Epoch: 163 [10521/17352 (61%)] Loss: -448.213265\n",
      "Train Epoch: 163 [16988/17352 (98%)] Loss: -517.084888\n",
      "    epoch          : 163\n",
      "    loss           : -424.6814027822539\n",
      "    val_loss       : -427.22226839181315\n",
      "    val_log_likelihood: 675.4048385600632\n",
      "    val_log_marginal: 440.1287549770157\n",
      "Train Epoch: 164 [512/17352 (3%)] Loss: -471.596527\n",
      "Train Epoch: 164 [10177/17352 (59%)] Loss: -479.224169\n",
      "Train Epoch: 164 [17090/17352 (98%)] Loss: -382.617653\n",
      "    epoch          : 164\n",
      "    loss           : -424.16631433312267\n",
      "    val_loss       : -420.1590929314429\n",
      "    val_log_likelihood: 672.3990079816978\n",
      "    val_log_marginal: 438.13255280971504\n",
      "Train Epoch: 165 [512/17352 (3%)] Loss: -449.628082\n",
      "Train Epoch: 165 [10679/17352 (62%)] Loss: -486.571043\n",
      "Train Epoch: 165 [17253/17352 (99%)] Loss: -377.164800\n",
      "    epoch          : 165\n",
      "    loss           : -430.10065459307066\n",
      "    val_loss       : -432.65018267209865\n",
      "    val_log_likelihood: 684.366764411375\n",
      "    val_log_marginal: 446.3763877383593\n",
      "Train Epoch: 166 [512/17352 (3%)] Loss: -465.543701\n",
      "Train Epoch: 166 [10069/17352 (58%)] Loss: -487.596927\n",
      "Train Epoch: 166 [17049/17352 (98%)] Loss: -543.345349\n",
      "    epoch          : 166\n",
      "    loss           : -439.10935610869836\n",
      "    val_loss       : -446.1459605029033\n",
      "    val_log_likelihood: 690.0853933231854\n",
      "    val_log_marginal: 460.76657107426234\n",
      "Train Epoch: 167 [512/17352 (3%)] Loss: -481.489380\n",
      "Train Epoch: 167 [10965/17352 (63%)] Loss: -337.410613\n",
      "Train Epoch: 167 [17106/17352 (99%)] Loss: -502.690005\n",
      "    epoch          : 167\n",
      "    loss           : -437.229625871661\n",
      "    val_loss       : -428.179967429208\n",
      "    val_log_likelihood: 685.3555345843789\n",
      "    val_log_marginal: 450.83834752185993\n",
      "Train Epoch: 168 [512/17352 (3%)] Loss: -471.115326\n",
      "Train Epoch: 168 [10813/17352 (62%)] Loss: -514.093816\n",
      "Train Epoch: 168 [17143/17352 (99%)] Loss: -381.706310\n",
      "    epoch          : 168\n",
      "    loss           : -426.16081102381816\n",
      "    val_loss       : -407.383323618512\n",
      "    val_log_likelihood: 678.7848725062582\n",
      "    val_log_marginal: 432.8409241957975\n",
      "Train Epoch: 169 [512/17352 (3%)] Loss: -399.258453\n",
      "Train Epoch: 169 [10006/17352 (58%)] Loss: -319.848121\n",
      "Train Epoch: 169 [17049/17352 (98%)] Loss: -263.288240\n",
      "    epoch          : 169\n",
      "    loss           : -427.59461629126156\n",
      "    val_loss       : -441.3377019084902\n",
      "    val_log_likelihood: 696.7130548185775\n",
      "    val_log_marginal: 460.09540012469193\n",
      "Train Epoch: 170 [512/17352 (3%)] Loss: -400.052094\n",
      "Train Epoch: 170 [10406/17352 (60%)] Loss: -373.005441\n",
      "Train Epoch: 170 [16988/17352 (98%)] Loss: -461.500395\n",
      "    epoch          : 170\n",
      "    loss           : -417.3883262050885\n",
      "    val_loss       : -426.91830141192844\n",
      "    val_log_likelihood: 688.0016254688869\n",
      "    val_log_marginal: 444.86078137828224\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch170.pth ...\n",
      "Train Epoch: 171 [512/17352 (3%)] Loss: -471.698700\n",
      "Train Epoch: 171 [10610/17352 (61%)] Loss: -445.734804\n",
      "Train Epoch: 171 [17044/17352 (98%)] Loss: -405.803995\n",
      "    epoch          : 171\n",
      "    loss           : -436.9162151428945\n",
      "    val_loss       : -445.1118081212274\n",
      "    val_log_likelihood: 702.8468913809928\n",
      "    val_log_marginal: 470.0847067550574\n",
      "Train Epoch: 172 [512/17352 (3%)] Loss: -487.282257\n",
      "Train Epoch: 172 [11038/17352 (64%)] Loss: -554.055704\n",
      "Train Epoch: 172 [17335/17352 (100%)] Loss: -501.019121\n",
      "    epoch          : 172\n",
      "    loss           : -450.70542787851423\n",
      "    val_loss       : -439.6130662683414\n",
      "    val_log_likelihood: 708.3067685146627\n",
      "    val_log_marginal: 466.74130264541725\n",
      "Train Epoch: 173 [512/17352 (3%)] Loss: -437.544189\n",
      "Train Epoch: 173 [10027/17352 (58%)] Loss: -529.074536\n",
      "Train Epoch: 173 [16957/17352 (98%)] Loss: -342.945576\n",
      "    epoch          : 173\n",
      "    loss           : -424.4762636614048\n",
      "    val_loss       : -434.76768628194367\n",
      "    val_log_likelihood: 699.4294851462985\n",
      "    val_log_marginal: 466.2864168181635\n",
      "Train Epoch: 174 [512/17352 (3%)] Loss: -481.296631\n",
      "Train Epoch: 174 [10184/17352 (59%)] Loss: -408.613331\n",
      "Train Epoch: 174 [16883/17352 (97%)] Loss: -374.232570\n",
      "    epoch          : 174\n",
      "    loss           : -440.1274455256777\n",
      "    val_loss       : -459.66092215284436\n",
      "    val_log_likelihood: 716.6807169865126\n",
      "    val_log_marginal: 482.17995297416064\n",
      "Train Epoch: 175 [512/17352 (3%)] Loss: -491.765015\n",
      "Train Epoch: 175 [10255/17352 (59%)] Loss: -496.029193\n",
      "Train Epoch: 175 [16887/17352 (97%)] Loss: -519.553498\n",
      "    epoch          : 175\n",
      "    loss           : -434.2746331523933\n",
      "    val_loss       : -438.96534391630445\n",
      "    val_log_likelihood: 694.7552898914662\n",
      "    val_log_marginal: 462.9468705785242\n",
      "Train Epoch: 176 [512/17352 (3%)] Loss: -319.369446\n",
      "Train Epoch: 176 [10456/17352 (60%)] Loss: -372.613758\n",
      "Train Epoch: 176 [17064/17352 (98%)] Loss: -520.327294\n",
      "    epoch          : 176\n",
      "    loss           : -433.0615322050613\n",
      "    val_loss       : -418.6050351396083\n",
      "    val_log_likelihood: 702.9674185941166\n",
      "    val_log_marginal: 454.60758876762213\n",
      "Train Epoch: 177 [512/17352 (3%)] Loss: -496.902527\n",
      "Train Epoch: 177 [10667/17352 (61%)] Loss: -549.570041\n",
      "Train Epoch: 177 [17049/17352 (98%)] Loss: -479.603011\n",
      "    epoch          : 177\n",
      "    loss           : -440.93509430028666\n",
      "    val_loss       : -443.7040722369331\n",
      "    val_log_likelihood: 712.9735227546879\n",
      "    val_log_marginal: 465.59259065134114\n",
      "Train Epoch: 178 [512/17352 (3%)] Loss: -472.167450\n",
      "Train Epoch: 178 [10155/17352 (59%)] Loss: -375.134570\n",
      "Train Epoch: 178 [16958/17352 (98%)] Loss: 9.853407\n",
      "    epoch          : 178\n",
      "    loss           : -350.8081168007324\n",
      "    val_loss       : -214.04939780303772\n",
      "    val_log_likelihood: 677.3915998935672\n",
      "    val_log_marginal: 242.4526706155283\n",
      "Train Epoch: 179 [512/17352 (3%)] Loss: -88.374313\n",
      "Train Epoch: 179 [10387/17352 (60%)] Loss: -277.943127\n",
      "Train Epoch: 179 [17101/17352 (99%)] Loss: -428.236094\n",
      "    epoch          : 179\n",
      "    loss           : -341.47856830181905\n",
      "    val_loss       : -386.5635957948457\n",
      "    val_log_likelihood: 684.6287493255595\n",
      "    val_log_marginal: 429.34961978119236\n",
      "Train Epoch: 180 [512/17352 (3%)] Loss: -442.667603\n",
      "Train Epoch: 180 [10530/17352 (61%)] Loss: -536.517785\n",
      "Train Epoch: 180 [17108/17352 (99%)] Loss: -572.101725\n",
      "    epoch          : 180\n",
      "    loss           : -433.79622036482846\n",
      "    val_loss       : -467.09501801373005\n",
      "    val_log_likelihood: 720.1322837530986\n",
      "    val_log_marginal: 487.47214374776235\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch180.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 181 [512/17352 (3%)] Loss: -484.748535\n",
      "Train Epoch: 181 [10395/17352 (60%)] Loss: -527.877413\n",
      "Train Epoch: 181 [16883/17352 (97%)] Loss: -576.329427\n",
      "    epoch          : 181\n",
      "    loss           : -456.2719149455166\n",
      "    val_loss       : -464.0725400528059\n",
      "    val_log_likelihood: 725.5885116446832\n",
      "    val_log_marginal: 487.1936940576976\n",
      "Train Epoch: 182 [512/17352 (3%)] Loss: -506.531433\n",
      "Train Epoch: 182 [10239/17352 (59%)] Loss: -540.475831\n",
      "Train Epoch: 182 [17277/17352 (100%)] Loss: -534.448891\n",
      "    epoch          : 182\n",
      "    loss           : -468.48835099650546\n",
      "    val_loss       : -475.3874219851532\n",
      "    val_log_likelihood: 735.4363558332541\n",
      "    val_log_marginal: 492.6198458307475\n",
      "Train Epoch: 183 [512/17352 (3%)] Loss: -489.858002\n",
      "Train Epoch: 183 [10450/17352 (60%)] Loss: -481.353494\n",
      "Train Epoch: 183 [17101/17352 (99%)] Loss: -341.166978\n",
      "    epoch          : 183\n",
      "    loss           : -476.0279122298224\n",
      "    val_loss       : -483.4641665585566\n",
      "    val_log_likelihood: 742.9978269897251\n",
      "    val_log_marginal: 497.2286029123045\n",
      "Train Epoch: 184 [512/17352 (3%)] Loss: -517.858582\n",
      "Train Epoch: 184 [10725/17352 (62%)] Loss: -575.894123\n",
      "Train Epoch: 184 [16887/17352 (97%)] Loss: -505.563521\n",
      "    epoch          : 184\n",
      "    loss           : -464.01532287943706\n",
      "    val_loss       : -466.48552955710653\n",
      "    val_log_likelihood: 747.9982725037905\n",
      "    val_log_marginal: 482.7792416338169\n",
      "Train Epoch: 185 [512/17352 (3%)] Loss: -505.842773\n",
      "Train Epoch: 185 [9815/17352 (57%)] Loss: -396.653866\n",
      "Train Epoch: 185 [17044/17352 (98%)] Loss: -474.233001\n",
      "    epoch          : 185\n",
      "    loss           : -444.2011639099314\n",
      "    val_loss       : -471.9418793148804\n",
      "    val_log_likelihood: 746.0070223904657\n",
      "    val_log_marginal: 491.04166107055534\n",
      "Train Epoch: 186 [512/17352 (3%)] Loss: -512.236877\n",
      "Train Epoch: 186 [10261/17352 (59%)] Loss: -404.463302\n",
      "Train Epoch: 186 [17016/17352 (98%)] Loss: -614.055501\n",
      "    epoch          : 186\n",
      "    loss           : -485.7692943926068\n",
      "    val_loss       : -503.2864912512599\n",
      "    val_log_likelihood: 762.7379687365203\n",
      "    val_log_marginal: 519.2985659705352\n",
      "Train Epoch: 187 [512/17352 (3%)] Loss: -542.066223\n",
      "Train Epoch: 187 [9853/17352 (57%)] Loss: -450.026460\n",
      "Train Epoch: 187 [17133/17352 (99%)] Loss: -550.169150\n",
      "    epoch          : 187\n",
      "    loss           : -501.2337686831642\n",
      "    val_loss       : -508.4291684864101\n",
      "    val_log_likelihood: 768.9791823480623\n",
      "    val_log_marginal: 523.4554521281455\n",
      "Train Epoch: 188 [512/17352 (3%)] Loss: -554.403687\n",
      "Train Epoch: 188 [10436/17352 (60%)] Loss: -526.373202\n",
      "Train Epoch: 188 [17101/17352 (99%)] Loss: -492.306029\n",
      "    epoch          : 188\n",
      "    loss           : -503.0111696213001\n",
      "    val_loss       : -493.3005630754979\n",
      "    val_log_likelihood: 767.3367348426699\n",
      "    val_log_marginal: 510.18287219298674\n",
      "Train Epoch: 189 [512/17352 (3%)] Loss: -539.622192\n",
      "Train Epoch: 189 [10537/17352 (61%)] Loss: -573.324822\n",
      "Train Epoch: 189 [17108/17352 (99%)] Loss: -548.640186\n",
      "    epoch          : 189\n",
      "    loss           : -493.00972701329783\n",
      "    val_loss       : -495.208692535971\n",
      "    val_log_likelihood: 765.8050672725637\n",
      "    val_log_marginal: 513.612188803627\n",
      "Train Epoch: 190 [512/17352 (3%)] Loss: -521.652405\n",
      "Train Epoch: 190 [9488/17352 (55%)] Loss: -484.026827\n",
      "Train Epoch: 190 [16887/17352 (97%)] Loss: -569.583539\n",
      "    epoch          : 190\n",
      "    loss           : -504.31620870674647\n",
      "    val_loss       : -508.20758031674706\n",
      "    val_log_likelihood: 779.0016019340371\n",
      "    val_log_marginal: 526.2585521681862\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch190.pth ...\n",
      "Train Epoch: 191 [512/17352 (3%)] Loss: -546.588867\n",
      "Train Epoch: 191 [10701/17352 (62%)] Loss: -601.094415\n",
      "Train Epoch: 191 [16922/17352 (98%)] Loss: -469.562431\n",
      "    epoch          : 191\n",
      "    loss           : -499.2826175832429\n",
      "    val_loss       : -511.30362920223587\n",
      "    val_log_likelihood: 784.6911708586005\n",
      "    val_log_marginal: 528.4799466530004\n",
      "Train Epoch: 192 [512/17352 (3%)] Loss: -555.801025\n",
      "Train Epoch: 192 [10328/17352 (60%)] Loss: -423.704983\n",
      "Train Epoch: 192 [17335/17352 (100%)] Loss: -596.774844\n",
      "    epoch          : 192\n",
      "    loss           : -503.9860350771211\n",
      "    val_loss       : -494.774531559478\n",
      "    val_log_likelihood: 780.4052495058803\n",
      "    val_log_marginal: 513.054942536322\n",
      "Train Epoch: 193 [512/17352 (3%)] Loss: -538.648926\n",
      "Train Epoch: 193 [10248/17352 (59%)] Loss: -487.066564\n",
      "Train Epoch: 193 [16992/17352 (98%)] Loss: -517.295947\n",
      "    epoch          : 193\n",
      "    loss           : -477.25477561824954\n",
      "    val_loss       : -480.19766376935286\n",
      "    val_log_likelihood: 770.2393431250072\n",
      "    val_log_marginal: 511.1910979995413\n",
      "Train Epoch: 194 [512/17352 (3%)] Loss: -509.896057\n",
      "Train Epoch: 194 [10366/17352 (60%)] Loss: -360.142773\n",
      "Train Epoch: 194 [17253/17352 (99%)] Loss: -384.145304\n",
      "    epoch          : 194\n",
      "    loss           : -375.2529844596074\n",
      "    val_loss       : -401.0382143608232\n",
      "    val_log_likelihood: 729.1664639872482\n",
      "    val_log_marginal: 426.11619192949036\n",
      "Train Epoch: 195 [512/17352 (3%)] Loss: -417.735626\n",
      "Train Epoch: 195 [10707/17352 (62%)] Loss: -520.417416\n",
      "Train Epoch: 195 [17277/17352 (100%)] Loss: -397.123008\n",
      "    epoch          : 195\n",
      "    loss           : -451.85423690064124\n",
      "    val_loss       : -404.85834346239\n",
      "    val_log_likelihood: 701.78991221518\n",
      "    val_log_marginal: 443.4628466598889\n",
      "Train Epoch: 196 [512/17352 (3%)] Loss: -445.808624\n",
      "Train Epoch: 196 [9831/17352 (57%)] Loss: -401.653460\n",
      "Train Epoch: 196 [16887/17352 (97%)] Loss: -571.146655\n",
      "    epoch          : 196\n",
      "    loss           : -445.83440315258196\n",
      "    val_loss       : -470.4443748975989\n",
      "    val_log_likelihood: 768.4163596976799\n",
      "    val_log_marginal: 504.7793407578098\n",
      "Train Epoch: 197 [512/17352 (3%)] Loss: -530.051880\n",
      "Train Epoch: 197 [10660/17352 (61%)] Loss: -456.405295\n",
      "Train Epoch: 197 [17049/17352 (98%)] Loss: -473.284176\n",
      "    epoch          : 197\n",
      "    loss           : -474.21677529254305\n",
      "    val_loss       : -493.24501598276265\n",
      "    val_log_likelihood: 773.3564938373233\n",
      "    val_log_marginal: 518.5076721759938\n",
      "Train Epoch: 198 [512/17352 (3%)] Loss: -537.969360\n",
      "Train Epoch: 198 [10073/17352 (58%)] Loss: -546.714399\n",
      "Train Epoch: 198 [16883/17352 (97%)] Loss: -450.548206\n",
      "    epoch          : 198\n",
      "    loss           : -489.9014660378526\n",
      "    val_loss       : -501.82580935144506\n",
      "    val_log_likelihood: 793.4325656273056\n",
      "    val_log_marginal: 521.6983542538038\n",
      "Train Epoch: 199 [512/17352 (3%)] Loss: -546.032471\n",
      "Train Epoch: 199 [10326/17352 (60%)] Loss: -543.422307\n",
      "Train Epoch: 199 [17049/17352 (98%)] Loss: -451.954140\n",
      "    epoch          : 199\n",
      "    loss           : -510.91634577119396\n",
      "    val_loss       : -511.0361792589714\n",
      "    val_log_likelihood: 796.3435171051036\n",
      "    val_log_marginal: 532.5664022372728\n",
      "Train Epoch: 200 [512/17352 (3%)] Loss: -535.270264\n",
      "Train Epoch: 200 [10533/17352 (61%)] Loss: -543.787159\n",
      "Train Epoch: 200 [17143/17352 (99%)] Loss: -604.744628\n",
      "    epoch          : 200\n",
      "    loss           : -505.17647806173534\n",
      "    val_loss       : -501.33556763919836\n",
      "    val_log_likelihood: 791.570374866992\n",
      "    val_log_marginal: 524.6754581768735\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch200.pth ...\n",
      "Train Epoch: 201 [512/17352 (3%)] Loss: -531.372559\n",
      "Train Epoch: 201 [9318/17352 (54%)] Loss: -551.073548\n",
      "Train Epoch: 201 [17263/17352 (99%)] Loss: -382.258604\n",
      "    epoch          : 201\n",
      "    loss           : -512.593053877973\n",
      "    val_loss       : -510.4228564244241\n",
      "    val_log_likelihood: 798.2898930245651\n",
      "    val_log_marginal: 536.8182395334419\n",
      "Train Epoch: 202 [512/17352 (3%)] Loss: -551.243835\n",
      "Train Epoch: 202 [10657/17352 (61%)] Loss: -406.766746\n",
      "Train Epoch: 202 [17253/17352 (99%)] Loss: -333.344456\n",
      "    epoch          : 202\n",
      "    loss           : -483.3781693530745\n",
      "    val_loss       : -491.2932024649136\n",
      "    val_log_likelihood: 793.3631664380538\n",
      "    val_log_marginal: 529.4966632356475\n",
      "Train Epoch: 203 [512/17352 (3%)] Loss: -501.769226\n",
      "Train Epoch: 203 [10392/17352 (60%)] Loss: -480.901570\n",
      "Train Epoch: 203 [17044/17352 (98%)] Loss: -425.630339\n",
      "    epoch          : 203\n",
      "    loss           : -449.1211319288731\n",
      "    val_loss       : -432.0300601029348\n",
      "    val_log_likelihood: 752.6862664246349\n",
      "    val_log_marginal: 458.71874012305454\n",
      "Train Epoch: 204 [512/17352 (3%)] Loss: -462.718475\n",
      "Train Epoch: 204 [10597/17352 (61%)] Loss: -574.022340\n",
      "Train Epoch: 204 [17263/17352 (99%)] Loss: -537.642088\n",
      "    epoch          : 204\n",
      "    loss           : -478.2545620376869\n",
      "    val_loss       : -455.8744549924318\n",
      "    val_log_likelihood: 783.4253871667945\n",
      "    val_log_marginal: 501.5262048943635\n",
      "Train Epoch: 205 [512/17352 (3%)] Loss: -481.749512\n",
      "Train Epoch: 205 [10467/17352 (60%)] Loss: -586.214419\n",
      "Train Epoch: 205 [16878/17352 (97%)] Loss: -544.705596\n",
      "    epoch          : 205\n",
      "    loss           : -491.57211854601843\n",
      "    val_loss       : -510.763187075207\n",
      "    val_log_likelihood: 798.3025457641112\n",
      "    val_log_marginal: 532.9826799466553\n",
      "Train Epoch: 206 [512/17352 (3%)] Loss: -539.762878\n",
      "Train Epoch: 206 [9926/17352 (57%)] Loss: -548.904222\n",
      "Train Epoch: 206 [16958/17352 (98%)] Loss: -505.756988\n",
      "    epoch          : 206\n",
      "    loss           : -457.5318431717041\n",
      "    val_loss       : -475.9943055670681\n",
      "    val_log_likelihood: 789.4695557779007\n",
      "    val_log_marginal: 499.3259446715883\n",
      "Train Epoch: 207 [512/17352 (3%)] Loss: -503.039307\n",
      "Train Epoch: 207 [9670/17352 (56%)] Loss: 241.521875\n",
      "Train Epoch: 207 [16934/17352 (98%)] Loss: 517.862470\n",
      "    epoch          : 207\n",
      "    loss           : 134.10568499861773\n",
      "    val_loss       : -53.70018512040217\n",
      "    val_log_likelihood: 500.4146665187594\n",
      "    val_log_marginal: 111.02428103475741\n",
      "Train Epoch: 208 [512/17352 (3%)] Loss: -31.044035\n",
      "Train Epoch: 208 [10498/17352 (61%)] Loss: -215.946205\n",
      "Train Epoch: 208 [17126/17352 (99%)] Loss: -382.940858\n",
      "    epoch          : 208\n",
      "    loss           : -227.36917366782623\n",
      "    val_loss       : -350.2976270103606\n",
      "    val_log_likelihood: 703.6043955839335\n",
      "    val_log_marginal: 391.95674612234825\n",
      "Train Epoch: 209 [512/17352 (3%)] Loss: -398.290222\n",
      "Train Epoch: 209 [10401/17352 (60%)] Loss: -499.033034\n",
      "Train Epoch: 209 [16958/17352 (98%)] Loss: -608.353733\n",
      "    epoch          : 209\n",
      "    loss           : -453.5494259719473\n",
      "    val_loss       : -489.76930182771196\n",
      "    val_log_likelihood: 756.5655533123652\n",
      "    val_log_marginal: 512.6678791119075\n",
      "Train Epoch: 210 [512/17352 (3%)] Loss: -533.455566\n",
      "Train Epoch: 210 [10435/17352 (60%)] Loss: -549.008529\n",
      "Train Epoch: 210 [17153/17352 (99%)] Loss: -403.226846\n",
      "    epoch          : 210\n",
      "    loss           : -499.70437617899495\n",
      "    val_loss       : -512.4462746841349\n",
      "    val_log_likelihood: 785.607492229854\n",
      "    val_log_marginal: 535.8665963511155\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch210.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 211 [512/17352 (3%)] Loss: -575.805664\n",
      "Train Epoch: 211 [10628/17352 (61%)] Loss: -477.358964\n",
      "Train Epoch: 211 [16923/17352 (98%)] Loss: -558.906510\n",
      "    epoch          : 211\n",
      "    loss           : -523.546980724026\n",
      "    val_loss       : -527.4545170615245\n",
      "    val_log_likelihood: 799.155104701761\n",
      "    val_log_marginal: 551.2473953806312\n",
      "Train Epoch: 212 [512/17352 (3%)] Loss: -368.860291\n",
      "Train Epoch: 212 [10098/17352 (58%)] Loss: -596.628643\n",
      "Train Epoch: 212 [17253/17352 (99%)] Loss: -444.236455\n",
      "    epoch          : 212\n",
      "    loss           : -529.3408593786233\n",
      "    val_loss       : -533.0048009937215\n",
      "    val_log_likelihood: 807.2371462622568\n",
      "    val_log_marginal: 552.8474306177358\n",
      "Train Epoch: 213 [512/17352 (3%)] Loss: -394.322571\n",
      "Train Epoch: 213 [10349/17352 (60%)] Loss: -597.155365\n",
      "Train Epoch: 213 [17253/17352 (99%)] Loss: -407.600964\n",
      "    epoch          : 213\n",
      "    loss           : -542.4275577028889\n",
      "    val_loss       : -544.4215758530679\n",
      "    val_log_likelihood: 818.1221677915955\n",
      "    val_log_marginal: 560.6037502389987\n",
      "Train Epoch: 214 [512/17352 (3%)] Loss: -583.482056\n",
      "Train Epoch: 214 [10544/17352 (61%)] Loss: -617.090156\n",
      "Train Epoch: 214 [17263/17352 (99%)] Loss: -503.266009\n",
      "    epoch          : 214\n",
      "    loss           : -540.3126519449114\n",
      "    val_loss       : -547.6308186266939\n",
      "    val_log_likelihood: 820.7045372682986\n",
      "    val_log_marginal: 564.0264419967\n",
      "Train Epoch: 215 [512/17352 (3%)] Loss: -599.714600\n",
      "Train Epoch: 215 [10605/17352 (61%)] Loss: -637.771122\n",
      "Train Epoch: 215 [16957/17352 (98%)] Loss: -661.867079\n",
      "    epoch          : 215\n",
      "    loss           : -549.191053659838\n",
      "    val_loss       : -553.898163177293\n",
      "    val_log_likelihood: 823.0306855660543\n",
      "    val_log_marginal: 570.5929397056133\n",
      "Train Epoch: 216 [512/17352 (3%)] Loss: -600.924805\n",
      "Train Epoch: 216 [9880/17352 (57%)] Loss: -580.625856\n",
      "Train Epoch: 216 [17153/17352 (99%)] Loss: -471.648009\n",
      "    epoch          : 216\n",
      "    loss           : -550.000754584689\n",
      "    val_loss       : -551.7953100718192\n",
      "    val_log_likelihood: 829.3483335410644\n",
      "    val_log_marginal: 570.5703494614685\n",
      "Train Epoch: 217 [512/17352 (3%)] Loss: -585.304077\n",
      "Train Epoch: 217 [10022/17352 (58%)] Loss: -592.441016\n",
      "Train Epoch: 217 [16958/17352 (98%)] Loss: -556.367227\n",
      "    epoch          : 217\n",
      "    loss           : -554.7611332018852\n",
      "    val_loss       : -555.3009660118777\n",
      "    val_log_likelihood: 831.6880724486136\n",
      "    val_log_marginal: 574.2246393861353\n",
      "Train Epoch: 218 [512/17352 (3%)] Loss: -590.859558\n",
      "Train Epoch: 218 [10031/17352 (58%)] Loss: -597.205312\n",
      "Train Epoch: 218 [17044/17352 (98%)] Loss: -655.827558\n",
      "    epoch          : 218\n",
      "    loss           : -558.9704769166369\n",
      "    val_loss       : -563.9763493025825\n",
      "    val_log_likelihood: 838.8532236356591\n",
      "    val_log_marginal: 580.8868784476406\n",
      "Train Epoch: 219 [512/17352 (3%)] Loss: -606.064819\n",
      "Train Epoch: 219 [10364/17352 (60%)] Loss: -499.440712\n",
      "Train Epoch: 219 [17335/17352 (100%)] Loss: -553.805270\n",
      "    epoch          : 219\n",
      "    loss           : -565.4569000312756\n",
      "    val_loss       : -552.3028663035511\n",
      "    val_log_likelihood: 844.1788315932776\n",
      "    val_log_marginal: 572.2520288911423\n",
      "Train Epoch: 220 [512/17352 (3%)] Loss: -587.263000\n",
      "Train Epoch: 220 [9904/17352 (57%)] Loss: -488.127841\n",
      "Train Epoch: 220 [17106/17352 (99%)] Loss: -500.470102\n",
      "    epoch          : 220\n",
      "    loss           : -563.9906394405273\n",
      "    val_loss       : -544.6324856541235\n",
      "    val_log_likelihood: 844.4391697768284\n",
      "    val_log_marginal: 578.5171239108672\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch220.pth ...\n",
      "Train Epoch: 221 [512/17352 (3%)] Loss: -596.587524\n",
      "Train Epoch: 221 [10444/17352 (60%)] Loss: -479.625761\n",
      "Train Epoch: 221 [17090/17352 (98%)] Loss: -634.049374\n",
      "    epoch          : 221\n",
      "    loss           : -527.2043030033863\n",
      "    val_loss       : -535.5731643850216\n",
      "    val_log_likelihood: 839.29119957335\n",
      "    val_log_marginal: 564.229285313968\n",
      "Train Epoch: 222 [512/17352 (3%)] Loss: -580.904846\n",
      "Train Epoch: 222 [10842/17352 (62%)] Loss: -635.241831\n",
      "Train Epoch: 222 [17253/17352 (99%)] Loss: -622.427004\n",
      "    epoch          : 222\n",
      "    loss           : -558.6426872315756\n",
      "    val_loss       : -557.804211949376\n",
      "    val_log_likelihood: 844.2498237736697\n",
      "    val_log_marginal: 574.6045287913722\n",
      "Train Epoch: 223 [512/17352 (3%)] Loss: -593.242615\n",
      "Train Epoch: 223 [10155/17352 (59%)] Loss: -472.950701\n",
      "Train Epoch: 223 [17277/17352 (100%)] Loss: -613.643164\n",
      "    epoch          : 223\n",
      "    loss           : -562.64644664861\n",
      "    val_loss       : -562.2313276402881\n",
      "    val_log_likelihood: 851.8612857863513\n",
      "    val_log_marginal: 581.6666821640933\n",
      "Train Epoch: 224 [512/17352 (3%)] Loss: -616.780396\n",
      "Train Epoch: 224 [9975/17352 (57%)] Loss: -488.849782\n",
      "Train Epoch: 224 [16992/17352 (98%)] Loss: -534.676884\n",
      "    epoch          : 224\n",
      "    loss           : -569.8778503526245\n",
      "    val_loss       : -572.5819987997272\n",
      "    val_log_likelihood: 857.8380884457423\n",
      "    val_log_marginal: 589.8610627776012\n",
      "Train Epoch: 225 [512/17352 (3%)] Loss: -595.207397\n",
      "Train Epoch: 225 [10227/17352 (59%)] Loss: -590.662749\n",
      "Train Epoch: 225 [16872/17352 (97%)] Loss: -667.125254\n",
      "    epoch          : 225\n",
      "    loss           : -570.7725659077984\n",
      "    val_loss       : -576.7128825202806\n",
      "    val_log_likelihood: 859.2805605957495\n",
      "    val_log_marginal: 596.7883618721037\n",
      "Train Epoch: 226 [512/17352 (3%)] Loss: -610.006714\n",
      "Train Epoch: 226 [9968/17352 (57%)] Loss: -617.108779\n",
      "Train Epoch: 226 [16939/17352 (98%)] Loss: -523.467773\n",
      "    epoch          : 226\n",
      "    loss           : -572.0845437203296\n",
      "    val_loss       : -580.5876030812894\n",
      "    val_log_likelihood: 866.8269668117892\n",
      "    val_log_marginal: 595.5410595976119\n",
      "Train Epoch: 227 [512/17352 (3%)] Loss: -629.128540\n",
      "Train Epoch: 227 [10471/17352 (60%)] Loss: -435.794146\n",
      "Train Epoch: 227 [17153/17352 (99%)] Loss: -632.396350\n",
      "    epoch          : 227\n",
      "    loss           : -576.867434418235\n",
      "    val_loss       : -558.2673475579232\n",
      "    val_log_likelihood: 857.1776987533858\n",
      "    val_log_marginal: 574.4888534906682\n",
      "Train Epoch: 228 [512/17352 (3%)] Loss: -606.553101\n",
      "Train Epoch: 228 [9730/17352 (56%)] Loss: -637.438854\n",
      "Train Epoch: 228 [17016/17352 (98%)] Loss: -526.300987\n",
      "    epoch          : 228\n",
      "    loss           : -576.4400672788751\n",
      "    val_loss       : -583.4206443182857\n",
      "    val_log_likelihood: 875.8908934822241\n",
      "    val_log_marginal: 602.9692695317646\n",
      "Train Epoch: 229 [512/17352 (3%)] Loss: -615.522095\n",
      "Train Epoch: 229 [10782/17352 (62%)] Loss: -631.776264\n",
      "Train Epoch: 229 [16988/17352 (98%)] Loss: -645.677930\n",
      "    epoch          : 229\n",
      "    loss           : -582.1848269164284\n",
      "    val_loss       : -585.4450173701268\n",
      "    val_log_likelihood: 876.9605392695041\n",
      "    val_log_marginal: 605.5395803379058\n",
      "Train Epoch: 230 [512/17352 (3%)] Loss: -623.179260\n",
      "Train Epoch: 230 [10160/17352 (59%)] Loss: -470.098849\n",
      "Train Epoch: 230 [16939/17352 (98%)] Loss: -660.451777\n",
      "    epoch          : 230\n",
      "    loss           : -586.8213274846481\n",
      "    val_loss       : -593.2093417039332\n",
      "    val_log_likelihood: 885.0073615994618\n",
      "    val_log_marginal: 611.8008138437727\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch230.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 231 [512/17352 (3%)] Loss: -637.302612\n",
      "Train Epoch: 231 [10669/17352 (61%)] Loss: -633.624154\n",
      "Train Epoch: 231 [16992/17352 (98%)] Loss: -527.817941\n",
      "    epoch          : 231\n",
      "    loss           : -591.8694411206302\n",
      "    val_loss       : -589.4163602732792\n",
      "    val_log_likelihood: 886.7668603552452\n",
      "    val_log_marginal: 612.648811908583\n",
      "Train Epoch: 232 [512/17352 (3%)] Loss: -638.708191\n",
      "Train Epoch: 232 [10536/17352 (61%)] Loss: -534.380170\n",
      "Train Epoch: 232 [16958/17352 (98%)] Loss: -660.811929\n",
      "    epoch          : 232\n",
      "    loss           : -585.8596545524632\n",
      "    val_loss       : -577.3624674148275\n",
      "    val_log_likelihood: 883.2400328822804\n",
      "    val_log_marginal: 603.9700892564008\n",
      "Train Epoch: 233 [512/17352 (3%)] Loss: -629.886902\n",
      "Train Epoch: 233 [9581/17352 (55%)] Loss: -553.662654\n",
      "Train Epoch: 233 [16887/17352 (97%)] Loss: -379.258597\n",
      "    epoch          : 233\n",
      "    loss           : -590.3289265968369\n",
      "    val_loss       : -594.9671949739322\n",
      "    val_log_likelihood: 882.9199150863867\n",
      "    val_log_marginal: 609.9625575322613\n",
      "Train Epoch: 234 [512/17352 (3%)] Loss: -648.962341\n",
      "Train Epoch: 234 [10194/17352 (59%)] Loss: -479.601836\n",
      "Train Epoch: 234 [16934/17352 (98%)] Loss: -525.218843\n",
      "    epoch          : 234\n",
      "    loss           : -587.1826304077731\n",
      "    val_loss       : -593.5937649855707\n",
      "    val_log_likelihood: 893.1129287381793\n",
      "    val_log_marginal: 610.1372797662125\n",
      "Train Epoch: 235 [512/17352 (3%)] Loss: -610.033630\n",
      "Train Epoch: 235 [10185/17352 (59%)] Loss: -598.939603\n",
      "Train Epoch: 235 [17335/17352 (100%)] Loss: -663.395530\n",
      "    epoch          : 235\n",
      "    loss           : -579.0371858558432\n",
      "    val_loss       : -550.7220397520784\n",
      "    val_log_likelihood: 879.8645337691516\n",
      "    val_log_marginal: 588.2234401829743\n",
      "Train Epoch: 236 [512/17352 (3%)] Loss: -615.189697\n",
      "Train Epoch: 236 [10305/17352 (59%)] Loss: -613.846240\n",
      "Train Epoch: 236 [17277/17352 (100%)] Loss: -394.283119\n",
      "    epoch          : 236\n",
      "    loss           : -571.2201412920462\n",
      "    val_loss       : -452.600134243705\n",
      "    val_log_likelihood: 875.7798409352703\n",
      "    val_log_marginal: 473.3981688309129\n",
      "Train Epoch: 237 [512/17352 (3%)] Loss: -435.371399\n",
      "Train Epoch: 237 [10284/17352 (59%)] Loss: -389.604244\n",
      "Train Epoch: 237 [16922/17352 (98%)] Loss: -422.237032\n",
      "    epoch          : 237\n",
      "    loss           : -448.78987550180324\n",
      "    val_loss       : -466.27973591435506\n",
      "    val_log_likelihood: 845.9214426604783\n",
      "    val_log_marginal: 505.13429775573013\n",
      "Train Epoch: 238 [512/17352 (3%)] Loss: -521.539062\n",
      "Train Epoch: 238 [10169/17352 (59%)] Loss: -435.769010\n",
      "Train Epoch: 238 [16878/17352 (97%)] Loss: -589.461534\n",
      "    epoch          : 238\n",
      "    loss           : -424.394875244706\n",
      "    val_loss       : -452.8792745188559\n",
      "    val_log_likelihood: 788.2612453504431\n",
      "    val_log_marginal: 477.98032023312504\n",
      "Train Epoch: 239 [512/17352 (3%)] Loss: -468.905853\n",
      "Train Epoch: 239 [10415/17352 (60%)] Loss: -622.343069\n",
      "Train Epoch: 239 [17049/17352 (98%)] Loss: -701.280111\n",
      "    epoch          : 239\n",
      "    loss           : -528.0398919596817\n",
      "    val_loss       : -549.4120506513202\n",
      "    val_log_likelihood: 858.206850909103\n",
      "    val_log_marginal: 582.0237276733849\n",
      "Train Epoch: 240 [512/17352 (3%)] Loss: -544.157410\n",
      "Train Epoch: 240 [10145/17352 (58%)] Loss: -605.609059\n",
      "Train Epoch: 240 [17044/17352 (98%)] Loss: -500.560787\n",
      "    epoch          : 240\n",
      "    loss           : -572.7081816123608\n",
      "    val_loss       : -588.9581599570118\n",
      "    val_log_likelihood: 883.7995680187406\n",
      "    val_log_marginal: 609.2699643108974\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch240.pth ...\n",
      "Train Epoch: 241 [512/17352 (3%)] Loss: -623.773315\n",
      "Train Epoch: 241 [10553/17352 (61%)] Loss: -689.706649\n",
      "Train Epoch: 241 [16883/17352 (97%)] Loss: -473.732020\n",
      "    epoch          : 241\n",
      "    loss           : -590.4831572402421\n",
      "    val_loss       : -604.2986488759545\n",
      "    val_log_likelihood: 899.2762581960928\n",
      "    val_log_marginal: 625.3976108291063\n",
      "Train Epoch: 242 [512/17352 (3%)] Loss: -638.075684\n",
      "Train Epoch: 242 [10871/17352 (63%)] Loss: -640.378255\n",
      "Train Epoch: 242 [17108/17352 (99%)] Loss: -444.193967\n",
      "    epoch          : 242\n",
      "    loss           : -596.9568878462624\n",
      "    val_loss       : -611.2552887448504\n",
      "    val_log_likelihood: 904.2650777002926\n",
      "    val_log_marginal: 625.1672813566475\n",
      "Train Epoch: 243 [512/17352 (3%)] Loss: -650.228638\n",
      "Train Epoch: 243 [10619/17352 (61%)] Loss: -460.775672\n",
      "Train Epoch: 243 [17263/17352 (99%)] Loss: -693.172468\n",
      "    epoch          : 243\n",
      "    loss           : -615.4781574063417\n",
      "    val_loss       : -604.5665978193892\n",
      "    val_log_likelihood: 909.7322406185834\n",
      "    val_log_marginal: 621.8468454826635\n",
      "Train Epoch: 244 [512/17352 (3%)] Loss: -644.620178\n",
      "Train Epoch: 244 [10297/17352 (59%)] Loss: -537.666903\n",
      "Train Epoch: 244 [17108/17352 (99%)] Loss: -580.556315\n",
      "    epoch          : 244\n",
      "    loss           : -612.7143992783393\n",
      "    val_loss       : -601.5673612750162\n",
      "    val_log_likelihood: 911.2074178470061\n",
      "    val_log_marginal: 619.0658151286098\n",
      "Train Epoch: 245 [512/17352 (3%)] Loss: -626.580444\n",
      "Train Epoch: 245 [10244/17352 (59%)] Loss: -583.887580\n",
      "Train Epoch: 245 [16923/17352 (98%)] Loss: -640.909461\n",
      "    epoch          : 245\n",
      "    loss           : -618.6931461355483\n",
      "    val_loss       : -614.3395573472861\n",
      "    val_log_likelihood: 915.2392285021388\n",
      "    val_log_marginal: 625.6816466259869\n",
      "Train Epoch: 246 [512/17352 (3%)] Loss: -643.386658\n",
      "Train Epoch: 246 [10503/17352 (61%)] Loss: -680.837088\n",
      "Train Epoch: 246 [16887/17352 (97%)] Loss: -443.033210\n",
      "    epoch          : 246\n",
      "    loss           : -608.0942675375234\n",
      "    val_loss       : -585.9820489578451\n",
      "    val_log_likelihood: 901.1145843521296\n",
      "    val_log_marginal: 602.4575954756792\n",
      "Train Epoch: 247 [512/17352 (3%)] Loss: -621.587646\n",
      "Train Epoch: 247 [10260/17352 (59%)] Loss: -563.902186\n",
      "Train Epoch: 247 [17124/17352 (99%)] Loss: -700.613098\n",
      "    epoch          : 247\n",
      "    loss           : -581.2746969513861\n",
      "    val_loss       : -583.4924683109837\n",
      "    val_log_likelihood: 907.2082429079596\n",
      "    val_log_marginal: 602.3567689559407\n",
      "Train Epoch: 248 [512/17352 (3%)] Loss: -638.701416\n",
      "Train Epoch: 248 [10851/17352 (63%)] Loss: -446.184136\n",
      "Train Epoch: 248 [16882/17352 (97%)] Loss: -629.645585\n",
      "    epoch          : 248\n",
      "    loss           : -598.7958011170325\n",
      "    val_loss       : -609.3573965049771\n",
      "    val_log_likelihood: 922.970035163903\n",
      "    val_log_marginal: 624.8034121902612\n",
      "Train Epoch: 249 [512/17352 (3%)] Loss: -644.254456\n",
      "Train Epoch: 249 [10880/17352 (63%)] Loss: -678.960351\n",
      "Train Epoch: 249 [17064/17352 (98%)] Loss: -482.992169\n",
      "    epoch          : 249\n",
      "    loss           : -508.0872906209035\n",
      "    val_loss       : -550.9854023481213\n",
      "    val_log_likelihood: 896.0219681534757\n",
      "    val_log_marginal: 573.2418445782608\n",
      "Train Epoch: 250 [512/17352 (3%)] Loss: -591.743042\n",
      "Train Epoch: 250 [10635/17352 (61%)] Loss: -518.875330\n",
      "Train Epoch: 250 [16887/17352 (97%)] Loss: -651.957571\n",
      "    epoch          : 250\n",
      "    loss           : -555.5864465926771\n",
      "    val_loss       : -588.2426762010014\n",
      "    val_log_likelihood: 905.2626510338625\n",
      "    val_log_marginal: 603.0310277721295\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch250.pth ...\n",
      "Train Epoch: 251 [512/17352 (3%)] Loss: -642.133667\n",
      "Train Epoch: 251 [10340/17352 (60%)] Loss: -540.922061\n",
      "Train Epoch: 251 [17143/17352 (99%)] Loss: -391.521980\n",
      "    epoch          : 251\n",
      "    loss           : -585.1827324000008\n",
      "    val_loss       : -597.7789893282361\n",
      "    val_log_likelihood: 917.9029806693713\n",
      "    val_log_marginal: 620.6678200143947\n",
      "Train Epoch: 252 [512/17352 (3%)] Loss: -637.171509\n",
      "Train Epoch: 252 [10419/17352 (60%)] Loss: -496.399740\n",
      "Train Epoch: 252 [16939/17352 (98%)] Loss: -536.542208\n",
      "    epoch          : 252\n",
      "    loss           : -589.1910925266884\n",
      "    val_loss       : -625.382011202105\n",
      "    val_log_likelihood: 920.6190059778262\n",
      "    val_log_marginal: 639.7395680854736\n",
      "Train Epoch: 253 [512/17352 (3%)] Loss: -663.028259\n",
      "Train Epoch: 253 [10516/17352 (61%)] Loss: -690.009782\n",
      "Train Epoch: 253 [17126/17352 (99%)] Loss: -750.955512\n",
      "    epoch          : 253\n",
      "    loss           : -619.0948680227249\n",
      "    val_loss       : -610.1268068187843\n",
      "    val_log_likelihood: 917.3144074176209\n",
      "    val_log_marginal: 636.5125155788338\n",
      "Train Epoch: 254 [512/17352 (3%)] Loss: -638.554932\n",
      "Train Epoch: 254 [10729/17352 (62%)] Loss: -645.406383\n",
      "Train Epoch: 254 [17143/17352 (99%)] Loss: -442.366674\n",
      "    epoch          : 254\n",
      "    loss           : -543.0173929233739\n",
      "    val_loss       : -534.5643808931546\n",
      "    val_log_likelihood: 870.1478054335103\n",
      "    val_log_marginal: 567.9570413953675\n",
      "Train Epoch: 255 [512/17352 (3%)] Loss: -579.622437\n",
      "Train Epoch: 255 [10219/17352 (59%)] Loss: -336.520047\n",
      "Train Epoch: 255 [16887/17352 (97%)] Loss: -171.184454\n",
      "    epoch          : 255\n",
      "    loss           : -206.0104461646195\n",
      "    val_loss       : -174.81240820610006\n",
      "    val_log_likelihood: 760.8050828606677\n",
      "    val_log_marginal: 207.63108489801962\n",
      "Train Epoch: 256 [512/17352 (3%)] Loss: -282.716370\n",
      "Train Epoch: 256 [10787/17352 (62%)] Loss: -386.621638\n",
      "Train Epoch: 256 [17124/17352 (99%)] Loss: -552.750156\n",
      "    epoch          : 256\n",
      "    loss           : -262.77998239886244\n",
      "    val_loss       : -418.31714575280296\n",
      "    val_log_likelihood: 791.0889601227133\n",
      "    val_log_marginal: 459.30390021732944\n",
      "Train Epoch: 257 [512/17352 (3%)] Loss: -485.583099\n",
      "Train Epoch: 257 [10128/17352 (58%)] Loss: -601.107987\n",
      "Train Epoch: 257 [16872/17352 (97%)] Loss: -507.458410\n",
      "    epoch          : 257\n",
      "    loss           : -499.30519772697903\n",
      "    val_loss       : -561.2141008121932\n",
      "    val_log_likelihood: 868.3426340292187\n",
      "    val_log_marginal: 586.8177824271447\n",
      "Train Epoch: 258 [512/17352 (3%)] Loss: -346.506958\n",
      "Train Epoch: 258 [10582/17352 (61%)] Loss: -636.351146\n",
      "Train Epoch: 258 [17126/17352 (99%)] Loss: -729.137099\n",
      "    epoch          : 258\n",
      "    loss           : -578.6562365614426\n",
      "    val_loss       : -596.8940352247412\n",
      "    val_log_likelihood: 893.416886928796\n",
      "    val_log_marginal: 617.2271451268263\n",
      "Train Epoch: 259 [512/17352 (3%)] Loss: -642.765381\n",
      "Train Epoch: 259 [9983/17352 (58%)] Loss: -694.355024\n",
      "Train Epoch: 259 [16957/17352 (98%)] Loss: -678.211259\n",
      "    epoch          : 259\n",
      "    loss           : -602.9959654852681\n",
      "    val_loss       : -613.0182339545279\n",
      "    val_log_likelihood: 913.7403388625877\n",
      "    val_log_marginal: 634.0081719193406\n",
      "Train Epoch: 260 [512/17352 (3%)] Loss: -665.089050\n",
      "Train Epoch: 260 [10170/17352 (59%)] Loss: -717.859867\n",
      "Train Epoch: 260 [17153/17352 (99%)] Loss: -532.299513\n",
      "    epoch          : 260\n",
      "    loss           : -612.6768302253842\n",
      "    val_loss       : -594.767270630315\n",
      "    val_log_likelihood: 920.4372198199934\n",
      "    val_log_marginal: 611.7285310504928\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch260.pth ...\n",
      "Train Epoch: 261 [512/17352 (3%)] Loss: -651.356018\n",
      "Train Epoch: 261 [10247/17352 (59%)] Loss: -580.964670\n",
      "Train Epoch: 261 [17126/17352 (99%)] Loss: -693.589134\n",
      "    epoch          : 261\n",
      "    loss           : -615.8255450621095\n",
      "    val_loss       : -609.095855752327\n",
      "    val_log_likelihood: 924.3216127260181\n",
      "    val_log_marginal: 627.4305992653744\n",
      "Train Epoch: 262 [512/17352 (3%)] Loss: -655.804993\n",
      "Train Epoch: 262 [10077/17352 (58%)] Loss: -563.399078\n",
      "Train Epoch: 262 [16958/17352 (98%)] Loss: -614.819635\n",
      "    epoch          : 262\n",
      "    loss           : -598.5887340370679\n",
      "    val_loss       : -621.9983367800177\n",
      "    val_log_likelihood: 928.1951183672084\n",
      "    val_log_marginal: 640.0060638298734\n",
      "Train Epoch: 263 [512/17352 (3%)] Loss: -666.274475\n",
      "Train Epoch: 263 [10015/17352 (58%)] Loss: -662.419519\n",
      "Train Epoch: 263 [17049/17352 (98%)] Loss: -652.169840\n",
      "    epoch          : 263\n",
      "    loss           : -611.9247514208342\n",
      "    val_loss       : -634.3573840345823\n",
      "    val_log_likelihood: 932.9741202649097\n",
      "    val_log_marginal: 648.1478019987338\n",
      "Train Epoch: 264 [512/17352 (3%)] Loss: -494.194702\n",
      "Train Epoch: 264 [10167/17352 (59%)] Loss: -721.127223\n",
      "Train Epoch: 264 [16922/17352 (98%)] Loss: -675.797240\n",
      "    epoch          : 264\n",
      "    loss           : -628.1659232833294\n",
      "    val_loss       : -634.3870638825198\n",
      "    val_log_likelihood: 936.5333158213213\n",
      "    val_log_marginal: 652.4199977128322\n",
      "Train Epoch: 265 [512/17352 (3%)] Loss: -463.493530\n",
      "Train Epoch: 265 [10563/17352 (61%)] Loss: -542.022423\n",
      "Train Epoch: 265 [17126/17352 (99%)] Loss: -728.736910\n",
      "    epoch          : 265\n",
      "    loss           : -617.572998018021\n",
      "    val_loss       : -609.6228361186012\n",
      "    val_log_likelihood: 938.9039697343251\n",
      "    val_log_marginal: 633.168948702931\n",
      "Train Epoch: 266 [512/17352 (3%)] Loss: -604.000183\n",
      "Train Epoch: 266 [10739/17352 (62%)] Loss: -708.654987\n",
      "Train Epoch: 266 [17263/17352 (99%)] Loss: -599.848575\n",
      "    epoch          : 266\n",
      "    loss           : -608.0694721443969\n",
      "    val_loss       : -594.6339532882296\n",
      "    val_log_likelihood: 927.9644622553291\n",
      "    val_log_marginal: 612.8831412853951\n",
      "Train Epoch: 267 [512/17352 (3%)] Loss: -642.193359\n",
      "Train Epoch: 267 [10091/17352 (58%)] Loss: -706.194741\n",
      "Train Epoch: 267 [17064/17352 (98%)] Loss: -700.087816\n",
      "    epoch          : 267\n",
      "    loss           : -610.3768506417607\n",
      "    val_loss       : -627.2775628896059\n",
      "    val_log_likelihood: 942.377730315351\n",
      "    val_log_marginal: 654.924072394347\n",
      "Train Epoch: 268 [512/17352 (3%)] Loss: -658.115906\n",
      "Train Epoch: 268 [9987/17352 (58%)] Loss: -702.002500\n",
      "Train Epoch: 268 [16923/17352 (98%)] Loss: -708.617544\n",
      "    epoch          : 268\n",
      "    loss           : -619.4362794292884\n",
      "    val_loss       : -605.8235818045308\n",
      "    val_log_likelihood: 940.5870705192308\n",
      "    val_log_marginal: 649.9441715250152\n",
      "Train Epoch: 269 [512/17352 (3%)] Loss: -675.152039\n",
      "Train Epoch: 269 [9963/17352 (57%)] Loss: -728.544542\n",
      "Train Epoch: 269 [17263/17352 (99%)] Loss: -612.777070\n",
      "    epoch          : 269\n",
      "    loss           : -608.8094376894952\n",
      "    val_loss       : -605.7023393955263\n",
      "    val_log_likelihood: 925.5652958529929\n",
      "    val_log_marginal: 627.9353041252201\n",
      "Train Epoch: 270 [512/17352 (3%)] Loss: -630.527161\n",
      "Train Epoch: 270 [10564/17352 (61%)] Loss: -538.054719\n",
      "Train Epoch: 270 [17016/17352 (98%)] Loss: -567.135931\n",
      "    epoch          : 270\n",
      "    loss           : -584.2475674128872\n",
      "    val_loss       : -575.2741863831983\n",
      "    val_log_likelihood: 917.2616139405089\n",
      "    val_log_marginal: 628.0617892774609\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch270.pth ...\n",
      "Train Epoch: 271 [512/17352 (3%)] Loss: -599.298157\n",
      "Train Epoch: 271 [10253/17352 (59%)] Loss: -652.931925\n",
      "Train Epoch: 271 [16958/17352 (98%)] Loss: -721.233976\n",
      "    epoch          : 271\n",
      "    loss           : -620.3738940679997\n",
      "    val_loss       : -635.1830207072896\n",
      "    val_log_likelihood: 947.6947396953102\n",
      "    val_log_marginal: 649.4009196354355\n",
      "Train Epoch: 272 [512/17352 (3%)] Loss: -679.861511\n",
      "Train Epoch: 272 [10432/17352 (60%)] Loss: -563.810515\n",
      "Train Epoch: 272 [17133/17352 (99%)] Loss: -703.124867\n",
      "    epoch          : 272\n",
      "    loss           : -605.8372755071539\n",
      "    val_loss       : -603.3292580358271\n",
      "    val_log_likelihood: 939.0584154365897\n",
      "    val_log_marginal: 626.1024333459918\n",
      "Train Epoch: 273 [512/17352 (3%)] Loss: -660.046143\n",
      "Train Epoch: 273 [10081/17352 (58%)] Loss: -680.215678\n",
      "Train Epoch: 273 [16883/17352 (97%)] Loss: -599.796875\n",
      "    epoch          : 273\n",
      "    loss           : -614.3777549162855\n",
      "    val_loss       : -508.250037372917\n",
      "    val_log_likelihood: 948.4322371043972\n",
      "    val_log_marginal: 522.8826773870096\n",
      "Train Epoch: 274 [512/17352 (3%)] Loss: -528.055420\n",
      "Train Epoch: 274 [10406/17352 (60%)] Loss: -560.708103\n",
      "Train Epoch: 274 [16922/17352 (98%)] Loss: -457.163585\n",
      "    epoch          : 274\n",
      "    loss           : -553.3428968355772\n",
      "    val_loss       : -545.7240844241226\n",
      "    val_log_likelihood: 936.3545400625835\n",
      "    val_log_marginal: 567.9754342635538\n",
      "Train Epoch: 275 [512/17352 (3%)] Loss: -536.806274\n",
      "Train Epoch: 275 [10856/17352 (63%)] Loss: -693.244481\n",
      "Train Epoch: 275 [17143/17352 (99%)] Loss: -456.308220\n",
      "    epoch          : 275\n",
      "    loss           : -596.9250369262738\n",
      "    val_loss       : -628.3742671203319\n",
      "    val_log_likelihood: 948.0770264089725\n",
      "    val_log_marginal: 647.9011563582716\n",
      "Train Epoch: 276 [512/17352 (3%)] Loss: -672.918274\n",
      "Train Epoch: 276 [10399/17352 (60%)] Loss: -537.046745\n",
      "Train Epoch: 276 [17090/17352 (98%)] Loss: -568.113592\n",
      "    epoch          : 276\n",
      "    loss           : -600.3403098008345\n",
      "    val_loss       : -619.854226371441\n",
      "    val_log_likelihood: 941.3983058594837\n",
      "    val_log_marginal: 639.0996224688547\n",
      "Train Epoch: 277 [512/17352 (3%)] Loss: -667.331665\n",
      "Train Epoch: 277 [10260/17352 (59%)] Loss: -494.306821\n",
      "Train Epoch: 277 [17106/17352 (99%)] Loss: -492.289913\n",
      "    epoch          : 277\n",
      "    loss           : -601.5045030001903\n",
      "    val_loss       : -585.9543653194133\n",
      "    val_log_likelihood: 936.8184555078122\n",
      "    val_log_marginal: 635.2190538493641\n",
      "Train Epoch: 278 [512/17352 (3%)] Loss: -618.153687\n",
      "Train Epoch: 278 [10387/17352 (60%)] Loss: -629.965887\n",
      "Train Epoch: 278 [17101/17352 (99%)] Loss: -690.625999\n",
      "    epoch          : 278\n",
      "    loss           : -618.4896651559623\n",
      "    val_loss       : -624.2077577476662\n",
      "    val_log_likelihood: 947.0013429806484\n",
      "    val_log_marginal: 648.9101112025389\n",
      "Train Epoch: 279 [512/17352 (3%)] Loss: -674.064636\n",
      "Train Epoch: 279 [10328/17352 (60%)] Loss: -696.390154\n",
      "Train Epoch: 279 [16939/17352 (98%)] Loss: -549.122009\n",
      "    epoch          : 279\n",
      "    loss           : -647.3222701173778\n",
      "    val_loss       : -660.1487583654978\n",
      "    val_log_likelihood: 969.1688322297304\n",
      "    val_log_marginal: 677.8976904359286\n",
      "Train Epoch: 280 [512/17352 (3%)] Loss: -688.218872\n",
      "Train Epoch: 280 [10053/17352 (58%)] Loss: -707.225208\n",
      "Train Epoch: 280 [17016/17352 (98%)] Loss: -733.095654\n",
      "    epoch          : 280\n",
      "    loss           : -659.4055371790646\n",
      "    val_loss       : -670.2923836187782\n",
      "    val_log_likelihood: 978.232693618493\n",
      "    val_log_marginal: 686.6368986567398\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch280.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 281 [512/17352 (3%)] Loss: -720.010437\n",
      "Train Epoch: 281 [9554/17352 (55%)] Loss: -718.048125\n",
      "Train Epoch: 281 [17263/17352 (99%)] Loss: -728.759731\n",
      "    epoch          : 281\n",
      "    loss           : -661.9761590392662\n",
      "    val_loss       : -635.6240690530601\n",
      "    val_log_likelihood: 963.9807574786352\n",
      "    val_log_marginal: 661.148718686624\n",
      "Train Epoch: 282 [512/17352 (3%)] Loss: -667.510254\n",
      "Train Epoch: 282 [10274/17352 (59%)] Loss: -570.171479\n",
      "Train Epoch: 282 [16883/17352 (97%)] Loss: -719.368899\n",
      "    epoch          : 282\n",
      "    loss           : -647.7206853742807\n",
      "    val_loss       : -651.6486263726293\n",
      "    val_log_likelihood: 973.0117374803073\n",
      "    val_log_marginal: 670.4468829783724\n",
      "Train Epoch: 283 [512/17352 (3%)] Loss: -702.258850\n",
      "Train Epoch: 283 [9981/17352 (58%)] Loss: -705.240506\n",
      "Train Epoch: 283 [16883/17352 (97%)] Loss: -479.611094\n",
      "    epoch          : 283\n",
      "    loss           : -634.3154323895405\n",
      "    val_loss       : -656.442326092087\n",
      "    val_log_likelihood: 968.8720459890304\n",
      "    val_log_marginal: 672.6360012221429\n",
      "Train Epoch: 284 [512/17352 (3%)] Loss: -689.641968\n",
      "Train Epoch: 284 [10343/17352 (60%)] Loss: -705.460683\n",
      "Train Epoch: 284 [17108/17352 (99%)] Loss: -620.822300\n",
      "    epoch          : 284\n",
      "    loss           : -662.974405229079\n",
      "    val_loss       : -665.0901137945893\n",
      "    val_log_likelihood: 978.2909691483898\n",
      "    val_log_marginal: 679.2995502716014\n",
      "Train Epoch: 285 [512/17352 (3%)] Loss: -696.209229\n",
      "Train Epoch: 285 [10559/17352 (61%)] Loss: -756.712367\n",
      "Train Epoch: 285 [17143/17352 (99%)] Loss: -696.530109\n",
      "    epoch          : 285\n",
      "    loss           : -661.6670481442463\n",
      "    val_loss       : -639.6769490206043\n",
      "    val_log_likelihood: 967.1141652315488\n",
      "    val_log_marginal: 656.0545020317306\n",
      "Train Epoch: 286 [512/17352 (3%)] Loss: -664.049133\n",
      "Train Epoch: 286 [10506/17352 (61%)] Loss: -708.359518\n",
      "Train Epoch: 286 [17049/17352 (98%)] Loss: -696.701042\n",
      "    epoch          : 286\n",
      "    loss           : -652.7392207838749\n",
      "    val_loss       : -655.3881662021047\n",
      "    val_log_likelihood: 983.7866689110925\n",
      "    val_log_marginal: 670.9872806034151\n",
      "Train Epoch: 287 [512/17352 (3%)] Loss: -693.058655\n",
      "Train Epoch: 287 [9799/17352 (56%)] Loss: -658.905904\n",
      "Train Epoch: 287 [17064/17352 (98%)] Loss: -764.707889\n",
      "    epoch          : 287\n",
      "    loss           : -659.537728273351\n",
      "    val_loss       : -668.4321041811587\n",
      "    val_log_likelihood: 986.4518887262969\n",
      "    val_log_marginal: 682.3201101570427\n",
      "Train Epoch: 288 [512/17352 (3%)] Loss: -701.769287\n",
      "Train Epoch: 288 [10052/17352 (58%)] Loss: -592.729200\n",
      "Train Epoch: 288 [16882/17352 (97%)] Loss: -688.456823\n",
      "    epoch          : 288\n",
      "    loss           : -640.2001876625114\n",
      "    val_loss       : -578.1201154272297\n",
      "    val_log_likelihood: 982.8293998763577\n",
      "    val_log_marginal: 598.3794293373716\n",
      "Train Epoch: 289 [512/17352 (3%)] Loss: -630.608398\n",
      "Train Epoch: 289 [10270/17352 (59%)] Loss: -741.859756\n",
      "Train Epoch: 289 [16922/17352 (98%)] Loss: -696.015365\n",
      "    epoch          : 289\n",
      "    loss           : -610.866240435566\n",
      "    val_loss       : -657.4086559772265\n",
      "    val_log_likelihood: 976.8378382006484\n",
      "    val_log_marginal: 675.4117420110921\n",
      "Train Epoch: 290 [512/17352 (3%)] Loss: -707.839111\n",
      "Train Epoch: 290 [10479/17352 (60%)] Loss: -782.016873\n",
      "Train Epoch: 290 [17090/17352 (98%)] Loss: -701.403761\n",
      "    epoch          : 290\n",
      "    loss           : -661.4894411535608\n",
      "    val_loss       : -629.4728127523271\n",
      "    val_log_likelihood: 985.0172172364954\n",
      "    val_log_marginal: 649.2345055013153\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch290.pth ...\n",
      "Train Epoch: 291 [512/17352 (3%)] Loss: -674.125610\n",
      "Train Epoch: 291 [10177/17352 (59%)] Loss: -706.016258\n",
      "Train Epoch: 291 [16878/17352 (97%)] Loss: -610.294139\n",
      "    epoch          : 291\n",
      "    loss           : -534.5764494034013\n",
      "    val_loss       : -485.1157077618431\n",
      "    val_log_likelihood: 949.5283855711945\n",
      "    val_log_marginal: 551.7538388628288\n",
      "Train Epoch: 292 [512/17352 (3%)] Loss: -576.360840\n",
      "Train Epoch: 292 [10510/17352 (61%)] Loss: -470.805380\n",
      "Train Epoch: 292 [16882/17352 (97%)] Loss: -525.818275\n",
      "    epoch          : 292\n",
      "    loss           : -503.312698889921\n",
      "    val_loss       : -478.0605198537076\n",
      "    val_log_likelihood: 908.3460442607\n",
      "    val_log_marginal: 512.965119694104\n",
      "Train Epoch: 293 [512/17352 (3%)] Loss: -341.023315\n",
      "Train Epoch: 293 [10433/17352 (60%)] Loss: -613.081090\n",
      "Train Epoch: 293 [17126/17352 (99%)] Loss: -358.959846\n",
      "    epoch          : 293\n",
      "    loss           : -522.9410589987369\n",
      "    val_loss       : -485.00319849773695\n",
      "    val_log_likelihood: 880.875463902339\n",
      "    val_log_marginal: 566.2236703307464\n",
      "Train Epoch: 294 [512/17352 (3%)] Loss: -473.542419\n",
      "Train Epoch: 294 [10209/17352 (59%)] Loss: -503.991153\n",
      "Train Epoch: 294 [17106/17352 (99%)] Loss: -657.623177\n",
      "    epoch          : 294\n",
      "    loss           : -516.042137710808\n",
      "    val_loss       : -550.7381176309751\n",
      "    val_log_likelihood: 917.9159269319192\n",
      "    val_log_marginal: 609.443336173019\n",
      "Train Epoch: 295 [512/17352 (3%)] Loss: -652.534546\n",
      "Train Epoch: 295 [10677/17352 (62%)] Loss: -540.184291\n",
      "Train Epoch: 295 [16988/17352 (98%)] Loss: -636.179843\n",
      "    epoch          : 295\n",
      "    loss           : -593.9336291623252\n",
      "    val_loss       : -640.397363640529\n",
      "    val_log_likelihood: 961.189292945485\n",
      "    val_log_marginal: 668.944618875848\n",
      "Train Epoch: 296 [512/17352 (3%)] Loss: -679.738281\n",
      "Train Epoch: 296 [9977/17352 (57%)] Loss: -725.424041\n",
      "Train Epoch: 296 [16934/17352 (98%)] Loss: -719.311504\n",
      "    epoch          : 296\n",
      "    loss           : -653.0002871397304\n",
      "    val_loss       : -660.7589338919536\n",
      "    val_log_likelihood: 981.3882196326838\n",
      "    val_log_marginal: 683.0565313913983\n",
      "Train Epoch: 297 [512/17352 (3%)] Loss: -700.142944\n",
      "Train Epoch: 297 [10398/17352 (60%)] Loss: -629.361424\n",
      "Train Epoch: 297 [17044/17352 (98%)] Loss: -757.952411\n",
      "    epoch          : 297\n",
      "    loss           : -661.3371090568912\n",
      "    val_loss       : -670.9679048563007\n",
      "    val_log_likelihood: 988.7228266200362\n",
      "    val_log_marginal: 692.0158527001577\n",
      "Train Epoch: 298 [512/17352 (3%)] Loss: -724.653809\n",
      "Train Epoch: 298 [10021/17352 (58%)] Loss: -625.488514\n",
      "Train Epoch: 298 [17090/17352 (98%)] Loss: -698.200843\n",
      "    epoch          : 298\n",
      "    loss           : -672.9952319828453\n",
      "    val_loss       : -667.5115869821702\n",
      "    val_log_likelihood: 991.9350504791958\n",
      "    val_log_marginal: 688.6920367583317\n",
      "Train Epoch: 299 [512/17352 (3%)] Loss: -695.794861\n",
      "Train Epoch: 299 [10178/17352 (59%)] Loss: -731.665862\n",
      "Train Epoch: 299 [16878/17352 (97%)] Loss: -769.983070\n",
      "    epoch          : 299\n",
      "    loss           : -672.1175211529652\n",
      "    val_loss       : -677.5285282015695\n",
      "    val_log_likelihood: 1001.7961052817058\n",
      "    val_log_marginal: 700.5250856203076\n",
      "Train Epoch: 300 [512/17352 (3%)] Loss: -704.269226\n",
      "Train Epoch: 300 [10499/17352 (61%)] Loss: -708.904452\n",
      "Train Epoch: 300 [16992/17352 (98%)] Loss: -679.089953\n",
      "    epoch          : 300\n",
      "    loss           : -670.9674545315951\n",
      "    val_loss       : -680.3660731830746\n",
      "    val_log_likelihood: 1002.3669658991239\n",
      "    val_log_marginal: 695.9258952741573\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch300.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 301 [512/17352 (3%)] Loss: -706.175171\n",
      "Train Epoch: 301 [9979/17352 (58%)] Loss: -721.569004\n",
      "Train Epoch: 301 [16939/17352 (98%)] Loss: -642.575718\n",
      "    epoch          : 301\n",
      "    loss           : -657.2974227658302\n",
      "    val_loss       : -657.4069530435255\n",
      "    val_log_likelihood: 982.3961834628001\n",
      "    val_log_marginal: 673.5975311845225\n",
      "Train Epoch: 302 [512/17352 (3%)] Loss: -703.876221\n",
      "Train Epoch: 302 [10349/17352 (60%)] Loss: -720.514244\n",
      "Train Epoch: 302 [17153/17352 (99%)] Loss: -550.278517\n",
      "    epoch          : 302\n",
      "    loss           : -657.9102514490351\n",
      "    val_loss       : -645.2267858966959\n",
      "    val_log_likelihood: 986.9350906655284\n",
      "    val_log_marginal: 673.2044664148829\n",
      "Train Epoch: 303 [512/17352 (3%)] Loss: -689.358521\n",
      "Train Epoch: 303 [10771/17352 (62%)] Loss: -800.850315\n",
      "Train Epoch: 303 [16882/17352 (97%)] Loss: -556.940544\n",
      "    epoch          : 303\n",
      "    loss           : -662.4753799663382\n",
      "    val_loss       : -676.2117843849795\n",
      "    val_log_likelihood: 989.6427206033787\n",
      "    val_log_marginal: 689.4410782836227\n",
      "Train Epoch: 304 [512/17352 (3%)] Loss: -698.830322\n",
      "Train Epoch: 304 [10355/17352 (60%)] Loss: -768.335805\n",
      "Train Epoch: 304 [17108/17352 (99%)] Loss: -533.867606\n",
      "    epoch          : 304\n",
      "    loss           : -658.9147811001567\n",
      "    val_loss       : -664.5274813591245\n",
      "    val_log_likelihood: 998.4950214537037\n",
      "    val_log_marginal: 686.3425514520169\n",
      "Train Epoch: 305 [512/17352 (3%)] Loss: -717.242554\n",
      "Train Epoch: 305 [10219/17352 (59%)] Loss: -630.238337\n",
      "Train Epoch: 305 [16872/17352 (97%)] Loss: -738.696584\n",
      "    epoch          : 305\n",
      "    loss           : -682.3563558749978\n",
      "    val_loss       : -686.9775366711234\n",
      "    val_log_likelihood: 1006.695500496807\n",
      "    val_log_marginal: 700.6803875454092\n",
      "Train Epoch: 306 [512/17352 (3%)] Loss: -724.109924\n",
      "Train Epoch: 306 [9758/17352 (56%)] Loss: -699.891746\n",
      "Train Epoch: 306 [16958/17352 (98%)] Loss: -570.980301\n",
      "    epoch          : 306\n",
      "    loss           : -675.3572865765592\n",
      "    val_loss       : -686.03801102521\n",
      "    val_log_likelihood: 1006.8215937047432\n",
      "    val_log_marginal: 699.7201852925485\n",
      "Train Epoch: 307 [512/17352 (3%)] Loss: -730.659668\n",
      "Train Epoch: 307 [9957/17352 (57%)] Loss: -516.559285\n",
      "Train Epoch: 307 [16882/17352 (97%)] Loss: -797.330357\n",
      "    epoch          : 307\n",
      "    loss           : -680.3136050936426\n",
      "    val_loss       : -686.5577007952443\n",
      "    val_log_likelihood: 1013.9839497259516\n",
      "    val_log_marginal: 708.2170392993229\n",
      "Train Epoch: 308 [512/17352 (3%)] Loss: -729.560608\n",
      "Train Epoch: 308 [10762/17352 (62%)] Loss: -542.775739\n",
      "Train Epoch: 308 [17049/17352 (98%)] Loss: -677.062083\n",
      "    epoch          : 308\n",
      "    loss           : -681.1682805384975\n",
      "    val_loss       : -667.925878450134\n",
      "    val_log_likelihood: 1011.8619270261706\n",
      "    val_log_marginal: 697.595196816751\n",
      "Train Epoch: 309 [512/17352 (3%)] Loss: -682.790894\n",
      "Train Epoch: 309 [10150/17352 (58%)] Loss: -90.548221\n",
      "Train Epoch: 309 [17263/17352 (99%)] Loss: -595.254318\n",
      "    epoch          : 309\n",
      "    loss           : -534.6180582041089\n",
      "    val_loss       : -402.43536748108613\n",
      "    val_log_likelihood: 839.3465886713852\n",
      "    val_log_marginal: 452.56727467727836\n",
      "Train Epoch: 310 [512/17352 (3%)] Loss: -423.907288\n",
      "Train Epoch: 310 [9948/17352 (57%)] Loss: -742.713832\n",
      "Train Epoch: 310 [17133/17352 (99%)] Loss: -643.234375\n",
      "    epoch          : 310\n",
      "    loss           : -605.6083418678747\n",
      "    val_loss       : -639.7146496005245\n",
      "    val_log_likelihood: 973.823878637\n",
      "    val_log_marginal: 661.4792101123904\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch310.pth ...\n",
      "Train Epoch: 311 [512/17352 (3%)] Loss: -677.578369\n",
      "Train Epoch: 311 [10192/17352 (59%)] Loss: -754.300386\n",
      "Train Epoch: 311 [17335/17352 (100%)] Loss: -599.843948\n",
      "    epoch          : 311\n",
      "    loss           : -667.5063017404927\n",
      "    val_loss       : -663.5664232780653\n",
      "    val_log_likelihood: 996.9114373159119\n",
      "    val_log_marginal: 688.0209529805189\n",
      "Train Epoch: 312 [512/17352 (3%)] Loss: -703.842773\n",
      "Train Epoch: 312 [9982/17352 (58%)] Loss: -717.533532\n",
      "Train Epoch: 312 [17090/17352 (98%)] Loss: -758.536881\n",
      "    epoch          : 312\n",
      "    loss           : -685.6101579476062\n",
      "    val_loss       : -692.322901686947\n",
      "    val_log_likelihood: 1016.9609332074788\n",
      "    val_log_marginal: 709.4676259663522\n",
      "Train Epoch: 313 [512/17352 (3%)] Loss: -728.685425\n",
      "Train Epoch: 313 [10494/17352 (60%)] Loss: -748.402052\n",
      "Train Epoch: 313 [17335/17352 (100%)] Loss: -759.889923\n",
      "    epoch          : 313\n",
      "    loss           : -678.6216403913179\n",
      "    val_loss       : -661.1929544266052\n",
      "    val_log_likelihood: 1010.6101265278282\n",
      "    val_log_marginal: 691.8837215225038\n",
      "Train Epoch: 314 [512/17352 (3%)] Loss: -707.476318\n",
      "Train Epoch: 314 [10217/17352 (59%)] Loss: -372.410586\n",
      "Train Epoch: 314 [17101/17352 (99%)] Loss: -740.960688\n",
      "    epoch          : 314\n",
      "    loss           : -661.3406742587991\n",
      "    val_loss       : -679.2062274819017\n",
      "    val_log_likelihood: 1011.7732887857007\n",
      "    val_log_marginal: 692.9941321315894\n",
      "Train Epoch: 315 [512/17352 (3%)] Loss: -712.237305\n",
      "Train Epoch: 315 [10181/17352 (59%)] Loss: -560.130538\n",
      "Train Epoch: 315 [17106/17352 (99%)] Loss: -470.500822\n",
      "    epoch          : 315\n",
      "    loss           : -620.8668511543531\n",
      "    val_loss       : -632.5254523955424\n",
      "    val_log_likelihood: 990.4826931339667\n",
      "    val_log_marginal: 648.1880059261231\n",
      "Train Epoch: 316 [512/17352 (3%)] Loss: -664.396729\n",
      "Train Epoch: 316 [10537/17352 (61%)] Loss: -560.823682\n",
      "Train Epoch: 316 [17101/17352 (99%)] Loss: -685.041985\n",
      "    epoch          : 316\n",
      "    loss           : -644.2544948282218\n",
      "    val_loss       : -674.1817429698862\n",
      "    val_log_likelihood: 1010.9883083336197\n",
      "    val_log_marginal: 689.6435236095625\n",
      "Train Epoch: 317 [512/17352 (3%)] Loss: -664.182129\n",
      "Train Epoch: 317 [10473/17352 (60%)] Loss: -597.311767\n",
      "Train Epoch: 317 [17335/17352 (100%)] Loss: -708.340885\n",
      "    epoch          : 317\n",
      "    loss           : -624.3715410481922\n",
      "    val_loss       : -653.2681880932333\n",
      "    val_log_likelihood: 1007.7562416405991\n",
      "    val_log_marginal: 669.7793287342307\n",
      "Train Epoch: 318 [512/17352 (3%)] Loss: -693.198303\n",
      "Train Epoch: 318 [10167/17352 (59%)] Loss: -696.394334\n",
      "Train Epoch: 318 [17106/17352 (99%)] Loss: -773.305918\n",
      "    epoch          : 318\n",
      "    loss           : -671.940262551787\n",
      "    val_loss       : -682.9464979698612\n",
      "    val_log_likelihood: 1021.4861831239571\n",
      "    val_log_marginal: 697.5783945882216\n",
      "Train Epoch: 319 [512/17352 (3%)] Loss: -528.823242\n",
      "Train Epoch: 319 [10190/17352 (59%)] Loss: -467.984776\n",
      "Train Epoch: 319 [17090/17352 (98%)] Loss: -621.837967\n",
      "    epoch          : 319\n",
      "    loss           : -682.819898619295\n",
      "    val_loss       : -697.3041487223119\n",
      "    val_log_likelihood: 1025.10112626512\n",
      "    val_log_marginal: 714.0954702231236\n",
      "Train Epoch: 320 [512/17352 (3%)] Loss: -729.089111\n",
      "Train Epoch: 320 [10696/17352 (62%)] Loss: -722.727083\n",
      "Train Epoch: 320 [17016/17352 (98%)] Loss: -234.263292\n",
      "    epoch          : 320\n",
      "    loss           : -441.9735346749104\n",
      "    val_loss       : 105.96656725969963\n",
      "    val_log_likelihood: 855.8422202222783\n",
      "    val_log_marginal: 16.185497589120494\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch320.pth ...\n",
      "Train Epoch: 321 [512/17352 (3%)] Loss: 44.480129\n",
      "Train Epoch: 321 [10485/17352 (60%)] Loss: -629.503027\n",
      "Train Epoch: 321 [17143/17352 (99%)] Loss: -514.080019\n",
      "    epoch          : 321\n",
      "    loss           : -348.8398944610126\n",
      "    val_loss       : -524.7919650529799\n",
      "    val_log_likelihood: 902.9501656410563\n",
      "    val_log_marginal: 576.5357849448752\n",
      "Train Epoch: 322 [512/17352 (3%)] Loss: -568.509033\n",
      "Train Epoch: 322 [10592/17352 (61%)] Loss: -700.615654\n",
      "Train Epoch: 322 [17108/17352 (99%)] Loss: -575.504000\n",
      "    epoch          : 322\n",
      "    loss           : -615.9728343422914\n",
      "    val_loss       : -656.8552600337398\n",
      "    val_log_likelihood: 985.5393739775143\n",
      "    val_log_marginal: 679.6401377838687\n",
      "Train Epoch: 323 [512/17352 (3%)] Loss: -703.600403\n",
      "Train Epoch: 323 [10049/17352 (58%)] Loss: -662.000862\n",
      "Train Epoch: 323 [16992/17352 (98%)] Loss: -711.935459\n",
      "    epoch          : 323\n",
      "    loss           : -665.3797893723338\n",
      "    val_loss       : -675.2642669740951\n",
      "    val_log_likelihood: 999.0139483655398\n",
      "    val_log_marginal: 692.8202897653975\n",
      "Train Epoch: 324 [512/17352 (3%)] Loss: -708.783020\n",
      "Train Epoch: 324 [9890/17352 (57%)] Loss: -634.977914\n",
      "Train Epoch: 324 [17108/17352 (99%)] Loss: -775.621589\n",
      "    epoch          : 324\n",
      "    loss           : -685.7617022102477\n",
      "    val_loss       : -683.0114897157895\n",
      "    val_log_likelihood: 1014.0213655153005\n",
      "    val_log_marginal: 706.6877449762563\n",
      "Train Epoch: 325 [512/17352 (3%)] Loss: -732.893616\n",
      "Train Epoch: 325 [10605/17352 (61%)] Loss: -513.021875\n",
      "Train Epoch: 325 [17101/17352 (99%)] Loss: -664.789831\n",
      "    epoch          : 325\n",
      "    loss           : -689.8558689308927\n",
      "    val_loss       : -695.3494743919034\n",
      "    val_log_likelihood: 1021.2101288827965\n",
      "    val_log_marginal: 712.6470571666003\n",
      "Train Epoch: 326 [512/17352 (3%)] Loss: -739.317505\n",
      "Train Epoch: 326 [10115/17352 (58%)] Loss: -707.899069\n",
      "Train Epoch: 326 [17108/17352 (99%)] Loss: -479.167838\n",
      "    epoch          : 326\n",
      "    loss           : -689.6354863633665\n",
      "    val_loss       : -687.4733144910431\n",
      "    val_log_likelihood: 1017.7849350789918\n",
      "    val_log_marginal: 699.2200759641711\n",
      "Train Epoch: 327 [512/17352 (3%)] Loss: -721.979675\n",
      "Train Epoch: 327 [10604/17352 (61%)] Loss: -753.028052\n",
      "Train Epoch: 327 [16988/17352 (98%)] Loss: -722.204091\n",
      "    epoch          : 327\n",
      "    loss           : -686.7889163872727\n",
      "    val_loss       : -696.795201738439\n",
      "    val_log_likelihood: 1026.2440310503796\n",
      "    val_log_marginal: 713.6799049517505\n",
      "Train Epoch: 328 [512/17352 (3%)] Loss: -719.926575\n",
      "Train Epoch: 328 [10111/17352 (58%)] Loss: -753.180142\n",
      "Train Epoch: 328 [16988/17352 (98%)] Loss: -579.563119\n",
      "    epoch          : 328\n",
      "    loss           : -693.196071857071\n",
      "    val_loss       : -706.1753484401008\n",
      "    val_log_likelihood: 1033.1817330098859\n",
      "    val_log_marginal: 724.1393416371004\n",
      "Train Epoch: 329 [512/17352 (3%)] Loss: -742.982056\n",
      "Train Epoch: 329 [10647/17352 (61%)] Loss: -656.965867\n",
      "Train Epoch: 329 [16872/17352 (97%)] Loss: -547.284946\n",
      "    epoch          : 329\n",
      "    loss           : -698.3496309420754\n",
      "    val_loss       : -697.7441200310957\n",
      "    val_log_likelihood: 1038.9631747652224\n",
      "    val_log_marginal: 719.9122773225852\n",
      "Train Epoch: 330 [512/17352 (3%)] Loss: -738.932800\n",
      "Train Epoch: 330 [9934/17352 (57%)] Loss: -515.179772\n",
      "Train Epoch: 330 [17124/17352 (99%)] Loss: -738.485937\n",
      "    epoch          : 330\n",
      "    loss           : -698.1200169196312\n",
      "    val_loss       : -695.855816690761\n",
      "    val_log_likelihood: 1028.4228639492367\n",
      "    val_log_marginal: 713.3503446492298\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch330.pth ...\n",
      "Train Epoch: 331 [512/17352 (3%)] Loss: -742.115845\n",
      "Train Epoch: 331 [9895/17352 (57%)] Loss: -673.386376\n",
      "Train Epoch: 331 [17106/17352 (99%)] Loss: -737.890983\n",
      "    epoch          : 331\n",
      "    loss           : -700.4776048229036\n",
      "    val_loss       : -706.4213840897468\n",
      "    val_log_likelihood: 1035.678349412828\n",
      "    val_log_marginal: 726.3648239740105\n",
      "Train Epoch: 332 [512/17352 (3%)] Loss: -755.018677\n",
      "Train Epoch: 332 [9763/17352 (56%)] Loss: -799.481390\n",
      "Train Epoch: 332 [16958/17352 (98%)] Loss: -595.953810\n",
      "    epoch          : 332\n",
      "    loss           : -698.0626894771094\n",
      "    val_loss       : -671.4228420160599\n",
      "    val_log_likelihood: 990.9764109959408\n",
      "    val_log_marginal: 686.8663611328623\n",
      "Train Epoch: 333 [512/17352 (3%)] Loss: -717.454163\n",
      "Train Epoch: 333 [10953/17352 (63%)] Loss: -714.472231\n",
      "Train Epoch: 333 [17108/17352 (99%)] Loss: -649.066311\n",
      "    epoch          : 333\n",
      "    loss           : -555.2122219872161\n",
      "    val_loss       : -568.9288178450979\n",
      "    val_log_likelihood: 920.5233813874559\n",
      "    val_log_marginal: 596.6201472910436\n",
      "Train Epoch: 334 [512/17352 (3%)] Loss: -622.901672\n",
      "Train Epoch: 334 [9901/17352 (57%)] Loss: -321.715692\n",
      "Train Epoch: 334 [16878/17352 (97%)] Loss: -522.714962\n",
      "    epoch          : 334\n",
      "    loss           : -589.5598996717936\n",
      "    val_loss       : -654.4197405460671\n",
      "    val_log_likelihood: 994.6770810762083\n",
      "    val_log_marginal: 689.2672928995197\n",
      "Train Epoch: 335 [512/17352 (3%)] Loss: -739.644653\n",
      "Train Epoch: 335 [10101/17352 (58%)] Loss: -747.477261\n",
      "Train Epoch: 335 [16882/17352 (97%)] Loss: -600.905922\n",
      "    epoch          : 335\n",
      "    loss           : -672.1551745392909\n",
      "    val_loss       : -692.8369691040974\n",
      "    val_log_likelihood: 1020.1908337483842\n",
      "    val_log_marginal: 713.1827747621027\n",
      "Train Epoch: 336 [512/17352 (3%)] Loss: -738.150024\n",
      "Train Epoch: 336 [10261/17352 (59%)] Loss: -641.916193\n",
      "Train Epoch: 336 [17044/17352 (98%)] Loss: -569.713078\n",
      "    epoch          : 336\n",
      "    loss           : -686.2054607678793\n",
      "    val_loss       : -665.2415029592003\n",
      "    val_log_likelihood: 1025.829468709039\n",
      "    val_log_marginal: 712.8778001053671\n",
      "Train Epoch: 337 [512/17352 (3%)] Loss: -730.099854\n",
      "Train Epoch: 337 [10632/17352 (61%)] Loss: -500.949119\n",
      "Train Epoch: 337 [16958/17352 (98%)] Loss: -746.205523\n",
      "    epoch          : 337\n",
      "    loss           : -679.9934302510985\n",
      "    val_loss       : -687.1977806645936\n",
      "    val_log_likelihood: 1025.0943364143975\n",
      "    val_log_marginal: 710.6255763744749\n",
      "Train Epoch: 338 [512/17352 (3%)] Loss: -744.879028\n",
      "Train Epoch: 338 [9978/17352 (58%)] Loss: -732.490294\n",
      "Train Epoch: 338 [17049/17352 (98%)] Loss: -667.867941\n",
      "    epoch          : 338\n",
      "    loss           : -695.7756492792158\n",
      "    val_loss       : -691.7159814826758\n",
      "    val_log_likelihood: 1031.9757183491995\n",
      "    val_log_marginal: 716.0339621758686\n",
      "Train Epoch: 339 [512/17352 (3%)] Loss: -747.146606\n",
      "Train Epoch: 339 [10017/17352 (58%)] Loss: -730.243153\n",
      "Train Epoch: 339 [16883/17352 (97%)] Loss: -395.468279\n",
      "    epoch          : 339\n",
      "    loss           : -645.6315145500564\n",
      "    val_loss       : -561.5791472854722\n",
      "    val_log_likelihood: 1021.9549375075612\n",
      "    val_log_marginal: 580.4766071460317\n",
      "Train Epoch: 340 [512/17352 (3%)] Loss: -612.894409\n",
      "Train Epoch: 340 [10253/17352 (59%)] Loss: -684.965990\n",
      "Train Epoch: 340 [16957/17352 (98%)] Loss: -552.110303\n",
      "    epoch          : 340\n",
      "    loss           : -621.9183526798646\n",
      "    val_loss       : -695.0106821866873\n",
      "    val_log_likelihood: 1015.2623289781036\n",
      "    val_log_marginal: 711.2712151457588\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch340.pth ...\n",
      "Train Epoch: 341 [512/17352 (3%)] Loss: -748.944519\n",
      "Train Epoch: 341 [10034/17352 (58%)] Loss: -650.730390\n",
      "Train Epoch: 341 [16923/17352 (98%)] Loss: -679.043451\n",
      "    epoch          : 341\n",
      "    loss           : -651.2679082639603\n",
      "    val_loss       : -691.5956253962456\n",
      "    val_log_likelihood: 1021.3077164455755\n",
      "    val_log_marginal: 711.0076892027164\n",
      "Train Epoch: 342 [512/17352 (3%)] Loss: -736.830505\n",
      "Train Epoch: 342 [9852/17352 (57%)] Loss: -718.059450\n",
      "Train Epoch: 342 [17108/17352 (99%)] Loss: -660.822060\n",
      "    epoch          : 342\n",
      "    loss           : -695.2899138262418\n",
      "    val_loss       : -698.6670112131967\n",
      "    val_log_likelihood: 1036.4944699924995\n",
      "    val_log_marginal: 717.7490218489374\n",
      "Train Epoch: 343 [512/17352 (3%)] Loss: -735.361206\n",
      "Train Epoch: 343 [10342/17352 (60%)] Loss: -634.388896\n",
      "Train Epoch: 343 [17263/17352 (99%)] Loss: -778.200573\n",
      "    epoch          : 343\n",
      "    loss           : -705.468155285951\n",
      "    val_loss       : -699.4180285484206\n",
      "    val_log_likelihood: 1043.7216209983983\n",
      "    val_log_marginal: 713.1164895360781\n",
      "Train Epoch: 344 [512/17352 (3%)] Loss: -725.148193\n",
      "Train Epoch: 344 [10893/17352 (63%)] Loss: -660.996642\n",
      "Train Epoch: 344 [17253/17352 (99%)] Loss: -740.919946\n",
      "    epoch          : 344\n",
      "    loss           : -693.1272646253503\n",
      "    val_loss       : -665.529879838918\n",
      "    val_log_likelihood: 1042.2406298836868\n",
      "    val_log_marginal: 682.0522370888381\n",
      "Train Epoch: 345 [512/17352 (3%)] Loss: -704.314087\n",
      "Train Epoch: 345 [10379/17352 (60%)] Loss: -779.285252\n",
      "Train Epoch: 345 [17016/17352 (98%)] Loss: -796.702179\n",
      "    epoch          : 345\n",
      "    loss           : -689.9739783103134\n",
      "    val_loss       : -700.3971009669332\n",
      "    val_log_likelihood: 1047.2315087247246\n",
      "    val_log_marginal: 729.7185677809474\n",
      "Train Epoch: 346 [512/17352 (3%)] Loss: -758.643188\n",
      "Train Epoch: 346 [10277/17352 (59%)] Loss: -637.209809\n",
      "Train Epoch: 346 [17277/17352 (100%)] Loss: -823.817454\n",
      "    epoch          : 346\n",
      "    loss           : -694.2248192238109\n",
      "    val_loss       : -709.8161473201823\n",
      "    val_log_likelihood: 1042.5147853014046\n",
      "    val_log_marginal: 728.9366448564994\n",
      "Train Epoch: 347 [512/17352 (3%)] Loss: -756.342102\n",
      "Train Epoch: 347 [10093/17352 (58%)] Loss: -653.601134\n",
      "Train Epoch: 347 [17335/17352 (100%)] Loss: -782.060502\n",
      "    epoch          : 347\n",
      "    loss           : -710.5161014260228\n",
      "    val_loss       : -716.333586683912\n",
      "    val_log_likelihood: 1050.7807896923882\n",
      "    val_log_marginal: 729.8152532690696\n",
      "Train Epoch: 348 [512/17352 (3%)] Loss: -755.166992\n",
      "Train Epoch: 348 [10282/17352 (59%)] Loss: -789.313897\n",
      "Train Epoch: 348 [17335/17352 (100%)] Loss: -769.178062\n",
      "    epoch          : 348\n",
      "    loss           : -711.0200024480981\n",
      "    val_loss       : -674.4186069903251\n",
      "    val_log_likelihood: 1044.3313911505682\n",
      "    val_log_marginal: 695.1617071163058\n",
      "Train Epoch: 349 [512/17352 (3%)] Loss: -675.256714\n",
      "Train Epoch: 349 [10164/17352 (59%)] Loss: -790.828324\n",
      "Train Epoch: 349 [17016/17352 (98%)] Loss: -714.110286\n",
      "    epoch          : 349\n",
      "    loss           : -684.9994747105872\n",
      "    val_loss       : -720.9147076813258\n",
      "    val_log_likelihood: 1051.8216776729457\n",
      "    val_log_marginal: 733.1024119951851\n",
      "Train Epoch: 350 [512/17352 (3%)] Loss: -569.324036\n",
      "Train Epoch: 350 [9949/17352 (57%)] Loss: -738.052060\n",
      "Train Epoch: 350 [16882/17352 (97%)] Loss: -825.936365\n",
      "    epoch          : 350\n",
      "    loss           : -698.6294850707569\n",
      "    val_loss       : -709.8557158400176\n",
      "    val_log_likelihood: 1052.108897256129\n",
      "    val_log_marginal: 724.9952370411075\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch350.pth ...\n",
      "Train Epoch: 351 [512/17352 (3%)] Loss: -756.334595\n",
      "Train Epoch: 351 [10447/17352 (60%)] Loss: -745.314232\n",
      "Train Epoch: 351 [16939/17352 (98%)] Loss: -565.453850\n",
      "    epoch          : 351\n",
      "    loss           : -655.0834711131913\n",
      "    val_loss       : -664.5339871682593\n",
      "    val_log_likelihood: 1048.0757045401335\n",
      "    val_log_marginal: 687.6703618814652\n",
      "Train Epoch: 352 [512/17352 (3%)] Loss: -514.339355\n",
      "Train Epoch: 352 [9961/17352 (57%)] Loss: -750.903529\n",
      "Train Epoch: 352 [17126/17352 (99%)] Loss: -598.407366\n",
      "    epoch          : 352\n",
      "    loss           : -684.151702598218\n",
      "    val_loss       : -647.305620190766\n",
      "    val_log_likelihood: 1046.0524745106597\n",
      "    val_log_marginal: 667.3484477220358\n",
      "Train Epoch: 353 [512/17352 (3%)] Loss: -651.736145\n",
      "Train Epoch: 353 [10226/17352 (59%)] Loss: -588.416240\n",
      "Train Epoch: 353 [17253/17352 (99%)] Loss: -811.834286\n",
      "    epoch          : 353\n",
      "    loss           : -695.5108016757692\n",
      "    val_loss       : -710.2840747467638\n",
      "    val_log_likelihood: 1059.7444959973611\n",
      "    val_log_marginal: 726.1632555902756\n",
      "Train Epoch: 354 [512/17352 (3%)] Loss: -751.204956\n",
      "Train Epoch: 354 [10939/17352 (63%)] Loss: -747.039841\n",
      "Train Epoch: 354 [17108/17352 (99%)] Loss: -644.634592\n",
      "    epoch          : 354\n",
      "    loss           : -715.4324181741463\n",
      "    val_loss       : -731.3166539795287\n",
      "    val_log_likelihood: 1068.3792924953952\n",
      "    val_log_marginal: 746.5735140328609\n",
      "Train Epoch: 355 [512/17352 (3%)] Loss: -771.782715\n",
      "Train Epoch: 355 [10669/17352 (61%)] Loss: -713.625000\n",
      "Train Epoch: 355 [16958/17352 (98%)] Loss: -748.323983\n",
      "    epoch          : 355\n",
      "    loss           : -729.1219765002215\n",
      "    val_loss       : -727.5084835875388\n",
      "    val_log_likelihood: 1071.9228949794199\n",
      "    val_log_marginal: 743.8688817576665\n",
      "Train Epoch: 356 [512/17352 (3%)] Loss: -770.525513\n",
      "Train Epoch: 356 [9758/17352 (56%)] Loss: -835.518166\n",
      "Train Epoch: 356 [16887/17352 (97%)] Loss: -741.492874\n",
      "    epoch          : 356\n",
      "    loss           : -733.593485927199\n",
      "    val_loss       : -744.6881811352375\n",
      "    val_log_likelihood: 1071.099409492023\n",
      "    val_log_marginal: 756.3631070772911\n",
      "Train Epoch: 357 [512/17352 (3%)] Loss: -780.828918\n",
      "Train Epoch: 357 [9921/17352 (57%)] Loss: -835.243493\n",
      "Train Epoch: 357 [16922/17352 (98%)] Loss: -514.688663\n",
      "    epoch          : 357\n",
      "    loss           : -688.8749500938729\n",
      "    val_loss       : -655.0869554692943\n",
      "    val_log_likelihood: 1068.645674293891\n",
      "    val_log_marginal: 669.8202776036185\n",
      "Train Epoch: 358 [512/17352 (3%)] Loss: -687.984314\n",
      "Train Epoch: 358 [10472/17352 (60%)] Loss: -712.407663\n",
      "Train Epoch: 358 [17016/17352 (98%)] Loss: -677.960076\n",
      "    epoch          : 358\n",
      "    loss           : -663.3517677365281\n",
      "    val_loss       : -704.9999928474903\n",
      "    val_log_likelihood: 1049.4003608294195\n",
      "    val_log_marginal: 724.5643292534138\n",
      "Train Epoch: 359 [512/17352 (3%)] Loss: -755.249512\n",
      "Train Epoch: 359 [10724/17352 (62%)] Loss: -814.200521\n",
      "Train Epoch: 359 [16958/17352 (98%)] Loss: -573.332915\n",
      "    epoch          : 359\n",
      "    loss           : -677.9074788212785\n",
      "    val_loss       : -622.1937767376565\n",
      "    val_log_likelihood: 1046.6176725387982\n",
      "    val_log_marginal: 634.18474802169\n",
      "Train Epoch: 360 [512/17352 (3%)] Loss: -677.197754\n",
      "Train Epoch: 360 [10574/17352 (61%)] Loss: -764.072652\n",
      "Train Epoch: 360 [16922/17352 (98%)] Loss: -802.820218\n",
      "    epoch          : 360\n",
      "    loss           : -650.7471622514896\n",
      "    val_loss       : -675.1765923169554\n",
      "    val_log_likelihood: 1036.2817219089823\n",
      "    val_log_marginal: 704.9204947849819\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch360.pth ...\n",
      "Train Epoch: 361 [512/17352 (3%)] Loss: -738.100586\n",
      "Train Epoch: 361 [10309/17352 (59%)] Loss: -606.829928\n",
      "Train Epoch: 361 [17101/17352 (99%)] Loss: -412.506003\n",
      "    epoch          : 361\n",
      "    loss           : -643.2903074841416\n",
      "    val_loss       : -598.8275113600188\n",
      "    val_log_likelihood: 1024.5707317109068\n",
      "    val_log_marginal: 617.7462978433837\n",
      "Train Epoch: 362 [512/17352 (3%)] Loss: -613.316162\n",
      "Train Epoch: 362 [9957/17352 (57%)] Loss: -565.592988\n",
      "Train Epoch: 362 [16922/17352 (98%)] Loss: -661.577357\n",
      "    epoch          : 362\n",
      "    loss           : -587.7442551231879\n",
      "    val_loss       : -695.5144600252654\n",
      "    val_log_likelihood: 1031.8275701578457\n",
      "    val_log_marginal: 712.5607651901502\n",
      "Train Epoch: 363 [512/17352 (3%)] Loss: -712.403442\n",
      "Train Epoch: 363 [9970/17352 (57%)] Loss: -638.983681\n",
      "Train Epoch: 363 [17253/17352 (99%)] Loss: -719.557778\n",
      "    epoch          : 363\n",
      "    loss           : -697.0108636783772\n",
      "    val_loss       : -724.5061346727625\n",
      "    val_log_likelihood: 1064.3692751240642\n",
      "    val_log_marginal: 746.549708973058\n",
      "Train Epoch: 364 [512/17352 (3%)] Loss: -708.815491\n",
      "Train Epoch: 364 [10182/17352 (59%)] Loss: -756.038440\n",
      "Train Epoch: 364 [17124/17352 (99%)] Loss: -776.639844\n",
      "    epoch          : 364\n",
      "    loss           : -716.1022325117997\n",
      "    val_loss       : -718.0499729478819\n",
      "    val_log_likelihood: 1064.8379672497945\n",
      "    val_log_marginal: 737.2573693203028\n",
      "Train Epoch: 365 [512/17352 (3%)] Loss: -745.312622\n",
      "Train Epoch: 365 [10249/17352 (59%)] Loss: -793.426106\n",
      "Train Epoch: 365 [16872/17352 (97%)] Loss: -571.438978\n",
      "    epoch          : 365\n",
      "    loss           : -734.7437268383143\n",
      "    val_loss       : -728.8966490586955\n",
      "    val_log_likelihood: 1081.8920034605155\n",
      "    val_log_marginal: 744.9412566935079\n",
      "Train Epoch: 366 [512/17352 (3%)] Loss: -774.116638\n",
      "Train Epoch: 366 [9960/17352 (57%)] Loss: -688.897185\n",
      "Train Epoch: 366 [16934/17352 (98%)] Loss: -803.535417\n",
      "    epoch          : 366\n",
      "    loss           : -706.8468757501408\n",
      "    val_loss       : -727.5843995216899\n",
      "    val_log_likelihood: 1065.9068679815507\n",
      "    val_log_marginal: 739.0559651435897\n",
      "Train Epoch: 367 [512/17352 (3%)] Loss: -768.410950\n",
      "Train Epoch: 367 [10733/17352 (62%)] Loss: -542.852991\n",
      "Train Epoch: 367 [17106/17352 (99%)] Loss: -631.614068\n",
      "    epoch          : 367\n",
      "    loss           : -734.0257883596714\n",
      "    val_loss       : -745.692483480021\n",
      "    val_log_likelihood: 1082.6970974521018\n",
      "    val_log_marginal: 761.7760968310575\n",
      "Train Epoch: 368 [512/17352 (3%)] Loss: -786.325623\n",
      "Train Epoch: 368 [10388/17352 (60%)] Loss: -698.938717\n",
      "Train Epoch: 368 [17064/17352 (98%)] Loss: -661.248106\n",
      "    epoch          : 368\n",
      "    loss           : -752.8714432360239\n",
      "    val_loss       : -760.3051516125643\n",
      "    val_log_likelihood: 1092.2372799349353\n",
      "    val_log_marginal: 773.9289247524471\n",
      "Train Epoch: 369 [512/17352 (3%)] Loss: -806.470764\n",
      "Train Epoch: 369 [10619/17352 (61%)] Loss: -820.273587\n",
      "Train Epoch: 369 [17049/17352 (98%)] Loss: -757.679438\n",
      "    epoch          : 369\n",
      "    loss           : -743.5405923151272\n",
      "    val_loss       : -747.0943774207966\n",
      "    val_log_likelihood: 1088.0525191313295\n",
      "    val_log_marginal: 761.6422523927718\n",
      "Train Epoch: 370 [512/17352 (3%)] Loss: -758.500244\n",
      "Train Epoch: 370 [9830/17352 (57%)] Loss: -777.025253\n",
      "Train Epoch: 370 [17126/17352 (99%)] Loss: -817.198972\n",
      "    epoch          : 370\n",
      "    loss           : -719.7315671695775\n",
      "    val_loss       : -663.1865601027092\n",
      "    val_log_likelihood: 1084.4979010412806\n",
      "    val_log_marginal: 678.8139713776229\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch370.pth ...\n",
      "Train Epoch: 371 [512/17352 (3%)] Loss: -695.285156\n",
      "Train Epoch: 371 [9993/17352 (58%)] Loss: -775.863014\n",
      "Train Epoch: 371 [17044/17352 (98%)] Loss: -780.999642\n",
      "    epoch          : 371\n",
      "    loss           : -685.0196846206322\n",
      "    val_loss       : -741.6891319290904\n",
      "    val_log_likelihood: 1079.6979489146956\n",
      "    val_log_marginal: 754.5684707882191\n",
      "Train Epoch: 372 [512/17352 (3%)] Loss: -584.925964\n",
      "Train Epoch: 372 [10880/17352 (63%)] Loss: -673.180903\n",
      "Train Epoch: 372 [17101/17352 (99%)] Loss: -787.561192\n",
      "    epoch          : 372\n",
      "    loss           : -720.2736047810181\n",
      "    val_loss       : -725.4098623257086\n",
      "    val_log_likelihood: 1075.2141585061258\n",
      "    val_log_marginal: 745.6520182929991\n",
      "Train Epoch: 373 [512/17352 (3%)] Loss: -765.187012\n",
      "Train Epoch: 373 [9659/17352 (56%)] Loss: -821.354865\n",
      "Train Epoch: 373 [17253/17352 (99%)] Loss: -595.218787\n",
      "    epoch          : 373\n",
      "    loss           : -738.1787546999758\n",
      "    val_loss       : -737.8749797320962\n",
      "    val_log_likelihood: 1077.3962088141302\n",
      "    val_log_marginal: 753.0632298641816\n",
      "Train Epoch: 374 [512/17352 (3%)] Loss: -786.145386\n",
      "Train Epoch: 374 [10325/17352 (60%)] Loss: -741.292951\n",
      "Train Epoch: 374 [17335/17352 (100%)] Loss: -641.310978\n",
      "    epoch          : 374\n",
      "    loss           : -735.9236320388081\n",
      "    val_loss       : -726.158248542675\n",
      "    val_log_likelihood: 1080.4658865205122\n",
      "    val_log_marginal: 747.136105681653\n",
      "Train Epoch: 375 [512/17352 (3%)] Loss: -728.989868\n",
      "Train Epoch: 375 [10340/17352 (60%)] Loss: -820.990472\n",
      "Train Epoch: 375 [16939/17352 (98%)] Loss: -795.494331\n",
      "    epoch          : 375\n",
      "    loss           : -739.0749273913639\n",
      "    val_loss       : -752.7719043588278\n",
      "    val_log_likelihood: 1097.86176441505\n",
      "    val_log_marginal: 766.992028822138\n",
      "Train Epoch: 376 [512/17352 (3%)] Loss: -787.612305\n",
      "Train Epoch: 376 [10324/17352 (59%)] Loss: -849.259156\n",
      "Train Epoch: 376 [17153/17352 (99%)] Loss: -764.260302\n",
      "    epoch          : 376\n",
      "    loss           : -754.6246358050055\n",
      "    val_loss       : -747.265885782985\n",
      "    val_log_likelihood: 1099.474622344651\n",
      "    val_log_marginal: 763.3352320395355\n",
      "Train Epoch: 377 [512/17352 (3%)] Loss: -763.548889\n",
      "Train Epoch: 377 [10505/17352 (61%)] Loss: -797.762762\n",
      "Train Epoch: 377 [16883/17352 (97%)] Loss: -720.746607\n",
      "    epoch          : 377\n",
      "    loss           : -739.8946921094631\n",
      "    val_loss       : -672.6416629558802\n",
      "    val_log_likelihood: 1091.6824506827443\n",
      "    val_log_marginal: 695.3359200570059\n",
      "Train Epoch: 378 [512/17352 (3%)] Loss: -725.151672\n",
      "Train Epoch: 378 [9850/17352 (57%)] Loss: -616.612774\n",
      "Train Epoch: 378 [16887/17352 (97%)] Loss: -658.977907\n",
      "    epoch          : 378\n",
      "    loss           : -578.4033142430969\n",
      "    val_loss       : -656.6938448774723\n",
      "    val_log_likelihood: 1035.3056166975048\n",
      "    val_log_marginal: 699.9176103383793\n",
      "Train Epoch: 379 [512/17352 (3%)] Loss: -515.166870\n",
      "Train Epoch: 379 [11237/17352 (65%)] Loss: -825.679056\n",
      "Train Epoch: 379 [17143/17352 (99%)] Loss: -832.735485\n",
      "    epoch          : 379\n",
      "    loss           : -711.2268328362328\n",
      "    val_loss       : -707.6600442771156\n",
      "    val_log_likelihood: 1063.6244437761682\n",
      "    val_log_marginal: 730.9350280794429\n",
      "Train Epoch: 380 [512/17352 (3%)] Loss: -752.550903\n",
      "Train Epoch: 380 [10125/17352 (58%)] Loss: -821.717563\n",
      "Train Epoch: 380 [17133/17352 (99%)] Loss: -877.755751\n",
      "    epoch          : 380\n",
      "    loss           : -732.4012337676257\n",
      "    val_loss       : -745.8101540442933\n",
      "    val_log_likelihood: 1089.8475372153137\n",
      "    val_log_marginal: 763.2302102033136\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch380.pth ...\n",
      "Train Epoch: 381 [512/17352 (3%)] Loss: -792.258545\n",
      "Train Epoch: 381 [10529/17352 (61%)] Loss: -878.762912\n",
      "Train Epoch: 381 [17263/17352 (99%)] Loss: -766.016615\n",
      "    epoch          : 381\n",
      "    loss           : -730.5908320009869\n",
      "    val_loss       : -694.4927852288488\n",
      "    val_log_likelihood: 1070.963275164631\n",
      "    val_log_marginal: 721.5190066421259\n",
      "Train Epoch: 382 [512/17352 (3%)] Loss: -724.617004\n",
      "Train Epoch: 382 [10737/17352 (62%)] Loss: -688.752373\n",
      "Train Epoch: 382 [17153/17352 (99%)] Loss: -784.974167\n",
      "    epoch          : 382\n",
      "    loss           : -735.1430789735386\n",
      "    val_loss       : -737.872486838581\n",
      "    val_log_likelihood: 1089.5356239383739\n",
      "    val_log_marginal: 757.0515167342622\n",
      "Train Epoch: 383 [512/17352 (3%)] Loss: -787.133484\n",
      "Train Epoch: 383 [10905/17352 (63%)] Loss: -493.908804\n",
      "Train Epoch: 383 [17064/17352 (98%)] Loss: -834.966133\n",
      "    epoch          : 383\n",
      "    loss           : -740.0045169718178\n",
      "    val_loss       : -730.5657718895951\n",
      "    val_log_likelihood: 1085.5032510255455\n",
      "    val_log_marginal: 751.6225391371408\n",
      "Train Epoch: 384 [512/17352 (3%)] Loss: -731.825806\n",
      "Train Epoch: 384 [11121/17352 (64%)] Loss: -582.978965\n",
      "Train Epoch: 384 [16939/17352 (98%)] Loss: -785.365219\n",
      "    epoch          : 384\n",
      "    loss           : -752.6720450896431\n",
      "    val_loss       : -757.4933875329589\n",
      "    val_log_likelihood: 1100.3011537469365\n",
      "    val_log_marginal: 773.4354485268191\n",
      "Train Epoch: 385 [512/17352 (3%)] Loss: -750.914062\n",
      "Train Epoch: 385 [10096/17352 (58%)] Loss: -658.110496\n",
      "Train Epoch: 385 [16934/17352 (98%)] Loss: -859.518841\n",
      "    epoch          : 385\n",
      "    loss           : -730.2144907165812\n",
      "    val_loss       : -730.0303290148553\n",
      "    val_log_likelihood: 1088.2501565211483\n",
      "    val_log_marginal: 744.6289734739311\n",
      "Train Epoch: 386 [512/17352 (3%)] Loss: -744.469849\n",
      "Train Epoch: 386 [10129/17352 (58%)] Loss: -820.613438\n",
      "Train Epoch: 386 [16883/17352 (97%)] Loss: -630.751666\n",
      "    epoch          : 386\n",
      "    loss           : -689.7389845640871\n",
      "    val_loss       : -690.6852803546017\n",
      "    val_log_likelihood: 1066.9561858000438\n",
      "    val_log_marginal: 707.3543362340316\n",
      "Train Epoch: 387 [512/17352 (3%)] Loss: -748.966003\n",
      "Train Epoch: 387 [10524/17352 (61%)] Loss: -689.178793\n",
      "Train Epoch: 387 [17016/17352 (98%)] Loss: -613.715755\n",
      "    epoch          : 387\n",
      "    loss           : -588.967661742972\n",
      "    val_loss       : -87.33599377306378\n",
      "    val_log_likelihood: 1032.6542085608392\n",
      "    val_log_marginal: 135.10442525534918\n",
      "Train Epoch: 388 [512/17352 (3%)] Loss: -22.578302\n",
      "Train Epoch: 388 [10345/17352 (60%)] Loss: -13.433354\n",
      "Train Epoch: 388 [16878/17352 (97%)] Loss: -574.650149\n",
      "    epoch          : 388\n",
      "    loss           : -465.7775812790118\n",
      "    val_loss       : -626.629806074538\n",
      "    val_log_likelihood: 1025.9309108454702\n",
      "    val_log_marginal: 668.389971740604\n",
      "Train Epoch: 389 [512/17352 (3%)] Loss: -671.418640\n",
      "Train Epoch: 389 [9777/17352 (56%)] Loss: -576.877904\n",
      "Train Epoch: 389 [16958/17352 (98%)] Loss: -646.235496\n",
      "    epoch          : 389\n",
      "    loss           : -616.6538546181481\n",
      "    val_loss       : -630.7319729373103\n",
      "    val_log_likelihood: 1035.283844989385\n",
      "    val_log_marginal: 664.3458447367532\n",
      "Train Epoch: 390 [512/17352 (3%)] Loss: -659.045166\n",
      "Train Epoch: 390 [10470/17352 (60%)] Loss: -835.712168\n",
      "Train Epoch: 390 [16957/17352 (98%)] Loss: -625.386068\n",
      "    epoch          : 390\n",
      "    loss           : -702.8386269701019\n",
      "    val_loss       : -727.1562680918828\n",
      "    val_log_likelihood: 1071.4123686981804\n",
      "    val_log_marginal: 753.1485041914464\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch390.pth ...\n",
      "Train Epoch: 391 [512/17352 (3%)] Loss: -795.196289\n",
      "Train Epoch: 391 [10248/17352 (59%)] Loss: -571.580108\n",
      "Train Epoch: 391 [16922/17352 (98%)] Loss: -725.667519\n",
      "    epoch          : 391\n",
      "    loss           : -731.3403965256848\n",
      "    val_loss       : -742.9958791637756\n",
      "    val_log_likelihood: 1093.8659657081187\n",
      "    val_log_marginal: 766.652688701374\n",
      "Train Epoch: 392 [512/17352 (3%)] Loss: -789.560608\n",
      "Train Epoch: 392 [9769/17352 (56%)] Loss: -668.490205\n",
      "Train Epoch: 392 [16992/17352 (98%)] Loss: -624.017206\n",
      "    epoch          : 392\n",
      "    loss           : -679.023812726026\n",
      "    val_loss       : -711.49556775495\n",
      "    val_log_likelihood: 1067.6428126737499\n",
      "    val_log_marginal: 738.2943365251149\n",
      "Train Epoch: 393 [512/17352 (3%)] Loss: -729.790405\n",
      "Train Epoch: 393 [10319/17352 (59%)] Loss: -487.851176\n",
      "Train Epoch: 393 [16878/17352 (97%)] Loss: -753.269531\n",
      "    epoch          : 393\n",
      "    loss           : -701.139684518559\n",
      "    val_loss       : -716.2605556658048\n",
      "    val_log_likelihood: 1071.1823413024788\n",
      "    val_log_marginal: 740.8246082818558\n",
      "Train Epoch: 394 [512/17352 (3%)] Loss: -741.792847\n",
      "Train Epoch: 394 [10521/17352 (61%)] Loss: -776.930983\n",
      "Train Epoch: 394 [17253/17352 (99%)] Loss: -774.200705\n",
      "    epoch          : 394\n",
      "    loss           : -725.6316458794092\n",
      "    val_loss       : -708.2591348581988\n",
      "    val_log_likelihood: 1073.8601527416295\n",
      "    val_log_marginal: 742.7976814005334\n",
      "Train Epoch: 395 [512/17352 (3%)] Loss: -762.506897\n",
      "Train Epoch: 395 [10257/17352 (59%)] Loss: -670.996337\n",
      "Train Epoch: 395 [17016/17352 (98%)] Loss: -777.792310\n",
      "    epoch          : 395\n",
      "    loss           : -739.9357001656565\n",
      "    val_loss       : -756.0174996540499\n",
      "    val_log_likelihood: 1099.294873171638\n",
      "    val_log_marginal: 772.802297816929\n",
      "Train Epoch: 396 [512/17352 (3%)] Loss: -794.268555\n",
      "Train Epoch: 396 [10465/17352 (60%)] Loss: -697.474631\n",
      "Train Epoch: 396 [17253/17352 (99%)] Loss: -544.834375\n",
      "    epoch          : 396\n",
      "    loss           : -676.5670873888754\n",
      "    val_loss       : -667.455059005849\n",
      "    val_log_likelihood: 1081.2647410642169\n",
      "    val_log_marginal: 684.1297097831233\n",
      "Train Epoch: 397 [512/17352 (3%)] Loss: -718.548950\n",
      "Train Epoch: 397 [10113/17352 (58%)] Loss: -662.692367\n",
      "Train Epoch: 397 [16957/17352 (98%)] Loss: -813.198294\n",
      "    epoch          : 397\n",
      "    loss           : -676.3807300645277\n",
      "    val_loss       : -699.8957435792443\n",
      "    val_log_likelihood: 1076.0230153425002\n",
      "    val_log_marginal: 720.668815683865\n",
      "Train Epoch: 398 [512/17352 (3%)] Loss: -709.662476\n",
      "Train Epoch: 398 [9775/17352 (56%)] Loss: -853.763148\n",
      "Train Epoch: 398 [16922/17352 (98%)] Loss: -776.385547\n",
      "    epoch          : 398\n",
      "    loss           : -735.2766613993929\n",
      "    val_loss       : -758.3114294564211\n",
      "    val_log_likelihood: 1102.708138776962\n",
      "    val_log_marginal: 775.1656824774393\n",
      "Train Epoch: 399 [512/17352 (3%)] Loss: -796.522156\n",
      "Train Epoch: 399 [9944/17352 (57%)] Loss: -609.448281\n",
      "Train Epoch: 399 [17263/17352 (99%)] Loss: -688.785249\n",
      "    epoch          : 399\n",
      "    loss           : -755.7658206267363\n",
      "    val_loss       : -747.1173370500655\n",
      "    val_log_likelihood: 1095.830179331948\n",
      "    val_log_marginal: 766.7291695671333\n",
      "Train Epoch: 400 [512/17352 (3%)] Loss: -782.644775\n",
      "Train Epoch: 400 [10349/17352 (60%)] Loss: -783.873242\n",
      "Train Epoch: 400 [16988/17352 (98%)] Loss: -853.198018\n",
      "    epoch          : 400\n",
      "    loss           : -757.6851181689715\n",
      "    val_loss       : -752.5612482080412\n",
      "    val_log_likelihood: 1108.073657614594\n",
      "    val_log_marginal: 767.8049216392044\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch400.pth ...\n",
      "Train Epoch: 401 [512/17352 (3%)] Loss: -781.553040\n",
      "Train Epoch: 401 [10407/17352 (60%)] Loss: -643.913806\n",
      "Train Epoch: 401 [16923/17352 (98%)] Loss: -697.904576\n",
      "    epoch          : 401\n",
      "    loss           : -760.9800698731059\n",
      "    val_loss       : -770.4748638774894\n",
      "    val_log_likelihood: 1117.7247158477503\n",
      "    val_log_marginal: 785.1046243303912\n",
      "Train Epoch: 402 [512/17352 (3%)] Loss: -778.505310\n",
      "Train Epoch: 402 [10453/17352 (60%)] Loss: -849.899289\n",
      "Train Epoch: 402 [16988/17352 (98%)] Loss: -667.214962\n",
      "    epoch          : 402\n",
      "    loss           : -756.1220073761408\n",
      "    val_loss       : -768.5009648970611\n",
      "    val_log_likelihood: 1110.792801281316\n",
      "    val_log_marginal: 786.8031091827717\n",
      "Train Epoch: 403 [512/17352 (3%)] Loss: -788.514771\n",
      "Train Epoch: 403 [10433/17352 (60%)] Loss: -723.323568\n",
      "Train Epoch: 403 [16887/17352 (97%)] Loss: -850.259271\n",
      "    epoch          : 403\n",
      "    loss           : -767.9160841458518\n",
      "    val_loss       : -767.6537354723733\n",
      "    val_log_likelihood: 1114.099093002197\n",
      "    val_log_marginal: 782.998326910146\n",
      "Train Epoch: 404 [512/17352 (3%)] Loss: -815.477051\n",
      "Train Epoch: 404 [10284/17352 (59%)] Loss: -761.426013\n",
      "Train Epoch: 404 [16882/17352 (97%)] Loss: -859.426345\n",
      "    epoch          : 404\n",
      "    loss           : -768.4471905700506\n",
      "    val_loss       : -772.2478814234313\n",
      "    val_log_likelihood: 1118.604266300908\n",
      "    val_log_marginal: 792.0265787830468\n",
      "Train Epoch: 405 [512/17352 (3%)] Loss: -784.685181\n",
      "Train Epoch: 405 [10932/17352 (63%)] Loss: -608.103024\n",
      "Train Epoch: 405 [16939/17352 (98%)] Loss: -843.303299\n",
      "    epoch          : 405\n",
      "    loss           : -773.1384274421661\n",
      "    val_loss       : -781.1093786512163\n",
      "    val_log_likelihood: 1127.4310140484752\n",
      "    val_log_marginal: 799.4874054889548\n",
      "Train Epoch: 406 [512/17352 (3%)] Loss: -825.139160\n",
      "Train Epoch: 406 [10219/17352 (59%)] Loss: -852.214844\n",
      "Train Epoch: 406 [16957/17352 (98%)] Loss: -765.384272\n",
      "    epoch          : 406\n",
      "    loss           : -778.471599689665\n",
      "    val_loss       : -784.9034302962451\n",
      "    val_log_likelihood: 1129.8924135630207\n",
      "    val_log_marginal: 798.0534556134544\n",
      "Train Epoch: 407 [512/17352 (3%)] Loss: -820.699951\n",
      "Train Epoch: 407 [10482/17352 (60%)] Loss: -748.999402\n",
      "Train Epoch: 407 [16988/17352 (98%)] Loss: -690.312703\n",
      "    epoch          : 407\n",
      "    loss           : -780.4787844248154\n",
      "    val_loss       : -777.7543590784708\n",
      "    val_log_likelihood: 1128.9943987252839\n",
      "    val_log_marginal: 793.2941128300554\n",
      "Train Epoch: 408 [512/17352 (3%)] Loss: -811.230164\n",
      "Train Epoch: 408 [10537/17352 (61%)] Loss: -820.489044\n",
      "Train Epoch: 408 [17108/17352 (99%)] Loss: -887.054177\n",
      "    epoch          : 408\n",
      "    loss           : -768.7141710015675\n",
      "    val_loss       : -765.9609276893651\n",
      "    val_log_likelihood: 1130.0414469660943\n",
      "    val_log_marginal: 783.6649628258481\n",
      "Train Epoch: 409 [512/17352 (3%)] Loss: -807.058350\n",
      "Train Epoch: 409 [10226/17352 (59%)] Loss: -794.233091\n",
      "Train Epoch: 409 [17101/17352 (99%)] Loss: -875.892252\n",
      "    epoch          : 409\n",
      "    loss           : -768.3136828366098\n",
      "    val_loss       : -686.7204127117136\n",
      "    val_log_likelihood: 1126.4725748370845\n",
      "    val_log_marginal: 700.3008177236967\n",
      "Train Epoch: 410 [512/17352 (3%)] Loss: -738.051086\n",
      "Train Epoch: 410 [10326/17352 (60%)] Loss: -635.821243\n",
      "Train Epoch: 410 [17335/17352 (100%)] Loss: -690.999585\n",
      "    epoch          : 410\n",
      "    loss           : -607.4956525061549\n",
      "    val_loss       : -317.6384376614802\n",
      "    val_log_likelihood: 1038.196123152038\n",
      "    val_log_marginal: 337.53072998730875\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch410.pth ...\n",
      "Train Epoch: 411 [512/17352 (3%)] Loss: -289.807129\n",
      "Train Epoch: 411 [10050/17352 (58%)] Loss: -709.679618\n",
      "Train Epoch: 411 [16992/17352 (98%)] Loss: -629.821721\n",
      "    epoch          : 411\n",
      "    loss           : -516.3899781056856\n",
      "    val_loss       : -686.2630249253666\n",
      "    val_log_likelihood: 1060.7070702372587\n",
      "    val_log_marginal: 708.9216341691188\n",
      "Train Epoch: 412 [512/17352 (3%)] Loss: -665.789612\n",
      "Train Epoch: 412 [10339/17352 (60%)] Loss: -730.340397\n",
      "Train Epoch: 412 [16923/17352 (98%)] Loss: -741.344823\n",
      "    epoch          : 412\n",
      "    loss           : -693.6842291501947\n",
      "    val_loss       : -733.267624702854\n",
      "    val_log_likelihood: 1097.9216445294442\n",
      "    val_log_marginal: 755.7437155539337\n",
      "Train Epoch: 413 [512/17352 (3%)] Loss: -743.940063\n",
      "Train Epoch: 413 [9988/17352 (58%)] Loss: -616.683464\n",
      "Train Epoch: 413 [16887/17352 (97%)] Loss: -741.829928\n",
      "    epoch          : 413\n",
      "    loss           : -720.0212176391659\n",
      "    val_loss       : -760.4284032824384\n",
      "    val_log_likelihood: 1108.316578117397\n",
      "    val_log_marginal: 778.6280804565798\n",
      "Train Epoch: 414 [512/17352 (3%)] Loss: -796.390808\n",
      "Train Epoch: 414 [10700/17352 (62%)] Loss: -830.040609\n",
      "Train Epoch: 414 [16988/17352 (98%)] Loss: -477.561678\n",
      "    epoch          : 414\n",
      "    loss           : -755.483825900889\n",
      "    val_loss       : -723.5522747594869\n",
      "    val_log_likelihood: 1112.0393912432396\n",
      "    val_log_marginal: 739.3858664433263\n",
      "Train Epoch: 415 [512/17352 (3%)] Loss: -745.719238\n",
      "Train Epoch: 415 [10836/17352 (62%)] Loss: -568.417839\n",
      "Train Epoch: 415 [17253/17352 (99%)] Loss: -686.429757\n",
      "    epoch          : 415\n",
      "    loss           : -691.1877652097683\n",
      "    val_loss       : -716.7238667929431\n",
      "    val_log_likelihood: 1091.6494950374656\n",
      "    val_log_marginal: 758.793825375106\n",
      "Train Epoch: 416 [512/17352 (3%)] Loss: -756.685425\n",
      "Train Epoch: 416 [10250/17352 (59%)] Loss: -844.757940\n",
      "Train Epoch: 416 [17101/17352 (99%)] Loss: -607.878360\n",
      "    epoch          : 416\n",
      "    loss           : -726.5742403693762\n",
      "    val_loss       : -709.2601656776958\n",
      "    val_log_likelihood: 1082.2910233185823\n",
      "    val_log_marginal: 737.2855895720589\n",
      "Train Epoch: 417 [512/17352 (3%)] Loss: -731.687805\n",
      "Train Epoch: 417 [10568/17352 (61%)] Loss: -776.549552\n",
      "Train Epoch: 417 [16922/17352 (98%)] Loss: -850.745269\n",
      "    epoch          : 417\n",
      "    loss           : -744.3430941373712\n",
      "    val_loss       : -776.9140370571727\n",
      "    val_log_likelihood: 1120.2377050566176\n",
      "    val_log_marginal: 796.9751408288895\n",
      "Train Epoch: 418 [512/17352 (3%)] Loss: -827.845642\n",
      "Train Epoch: 418 [10411/17352 (60%)] Loss: -847.850254\n",
      "Train Epoch: 418 [17108/17352 (99%)] Loss: -511.283571\n",
      "    epoch          : 418\n",
      "    loss           : -748.8243025888793\n",
      "    val_loss       : -712.986458012694\n",
      "    val_log_likelihood: 1073.4254584003643\n",
      "    val_log_marginal: 739.743598544598\n",
      "Train Epoch: 419 [512/17352 (3%)] Loss: -779.190063\n",
      "Train Epoch: 419 [10205/17352 (59%)] Loss: -695.822381\n",
      "Train Epoch: 419 [16922/17352 (98%)] Loss: -841.163364\n",
      "    epoch          : 419\n",
      "    loss           : -713.2313975743511\n",
      "    val_loss       : -747.7581332110574\n",
      "    val_log_likelihood: 1096.5228862000238\n",
      "    val_log_marginal: 771.9723812100249\n",
      "Train Epoch: 420 [512/17352 (3%)] Loss: -789.670349\n",
      "Train Epoch: 420 [10450/17352 (60%)] Loss: -783.598958\n",
      "Train Epoch: 420 [17016/17352 (98%)] Loss: -875.603435\n",
      "    epoch          : 420\n",
      "    loss           : -749.4575897736687\n",
      "    val_loss       : -776.6554837206454\n",
      "    val_log_likelihood: 1120.4588736611374\n",
      "    val_log_marginal: 796.6513704871388\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch420.pth ...\n",
      "Train Epoch: 421 [512/17352 (3%)] Loss: -826.798706\n",
      "Train Epoch: 421 [10061/17352 (58%)] Loss: -795.425347\n",
      "Train Epoch: 421 [16934/17352 (98%)] Loss: -840.479365\n",
      "    epoch          : 421\n",
      "    loss           : -776.4287235649685\n",
      "    val_loss       : -785.6024751328848\n",
      "    val_log_likelihood: 1131.1656824000922\n",
      "    val_log_marginal: 798.8778682503074\n",
      "Train Epoch: 422 [512/17352 (3%)] Loss: -812.137451\n",
      "Train Epoch: 422 [10156/17352 (59%)] Loss: -702.154231\n",
      "Train Epoch: 422 [17277/17352 (100%)] Loss: -615.004772\n",
      "    epoch          : 422\n",
      "    loss           : -780.4337159845425\n",
      "    val_loss       : -767.6072526822908\n",
      "    val_log_likelihood: 1133.6952346147255\n",
      "    val_log_marginal: 785.0438407361937\n",
      "Train Epoch: 423 [512/17352 (3%)] Loss: -810.336426\n",
      "Train Epoch: 423 [10492/17352 (60%)] Loss: -865.800286\n",
      "Train Epoch: 423 [17101/17352 (99%)] Loss: -829.577128\n",
      "    epoch          : 423\n",
      "    loss           : -778.1857346546738\n",
      "    val_loss       : -711.3285801341685\n",
      "    val_log_likelihood: 1133.0765667971114\n",
      "    val_log_marginal: 730.793038163687\n",
      "Train Epoch: 424 [512/17352 (3%)] Loss: -745.406555\n",
      "Train Epoch: 424 [10502/17352 (61%)] Loss: -696.880530\n",
      "Train Epoch: 424 [17335/17352 (100%)] Loss: -861.784688\n",
      "    epoch          : 424\n",
      "    loss           : -755.1631443248489\n",
      "    val_loss       : -677.7931839962758\n",
      "    val_log_likelihood: 1119.4089910508803\n",
      "    val_log_marginal: 697.5341997170354\n",
      "Train Epoch: 425 [512/17352 (3%)] Loss: -753.381592\n",
      "Train Epoch: 425 [10091/17352 (58%)] Loss: -776.614629\n",
      "Train Epoch: 425 [16934/17352 (98%)] Loss: -666.955357\n",
      "    epoch          : 425\n",
      "    loss           : -722.218032417513\n",
      "    val_loss       : -637.2931993133319\n",
      "    val_log_likelihood: 1100.0741755355255\n",
      "    val_log_marginal: 657.763161811253\n",
      "Train Epoch: 426 [512/17352 (3%)] Loss: -678.472717\n",
      "Train Epoch: 426 [10413/17352 (60%)] Loss: -735.812002\n",
      "Train Epoch: 426 [17335/17352 (100%)] Loss: -587.224583\n",
      "    epoch          : 426\n",
      "    loss           : -594.9089144970704\n",
      "    val_loss       : 2205.57781892223\n",
      "    val_log_likelihood: 965.2964032209504\n",
      "    val_log_marginal: -2192.7741951860644\n",
      "Train Epoch: 427 [512/17352 (3%)] Loss: 2153.359131\n",
      "Train Epoch: 427 [9733/17352 (56%)] Loss: -38.780886\n",
      "Train Epoch: 427 [16992/17352 (98%)] Loss: -274.755647\n",
      "    epoch          : 427\n",
      "    loss           : -109.28490858508542\n",
      "    val_loss       : -436.7966332479834\n",
      "    val_log_likelihood: 967.9598775820014\n",
      "    val_log_marginal: 472.5354265825537\n",
      "Train Epoch: 428 [512/17352 (3%)] Loss: -489.138306\n",
      "Train Epoch: 428 [10136/17352 (58%)] Loss: -609.616441\n",
      "Train Epoch: 428 [17064/17352 (98%)] Loss: 182.187878\n",
      "    epoch          : 428\n",
      "    loss           : -449.68662375439175\n",
      "    val_loss       : -463.9519445506453\n",
      "    val_log_likelihood: 999.259951644402\n",
      "    val_log_marginal: 499.2284022869662\n",
      "Train Epoch: 429 [512/17352 (3%)] Loss: -441.242828\n",
      "Train Epoch: 429 [9922/17352 (57%)] Loss: -398.766386\n",
      "Train Epoch: 429 [17143/17352 (99%)] Loss: -630.647600\n",
      "    epoch          : 429\n",
      "    loss           : -532.3364487240424\n",
      "    val_loss       : -685.973739112431\n",
      "    val_log_likelihood: 1039.209757691816\n",
      "    val_log_marginal: 705.5739291815435\n",
      "Train Epoch: 430 [512/17352 (3%)] Loss: -730.032043\n",
      "Train Epoch: 430 [10761/17352 (62%)] Loss: -762.259065\n",
      "Train Epoch: 430 [16887/17352 (97%)] Loss: -697.020364\n",
      "    epoch          : 430\n",
      "    loss           : -736.1092424164681\n",
      "    val_loss       : -765.0708074845787\n",
      "    val_log_likelihood: 1096.1699494250572\n",
      "    val_log_marginal: 782.4526668988999\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch430.pth ...\n",
      "Train Epoch: 431 [512/17352 (3%)] Loss: -808.643127\n",
      "Train Epoch: 431 [10774/17352 (62%)] Loss: -564.524708\n",
      "Train Epoch: 431 [17101/17352 (99%)] Loss: -767.256313\n",
      "    epoch          : 431\n",
      "    loss           : -762.8729954103768\n",
      "    val_loss       : -774.1569518444564\n",
      "    val_log_likelihood: 1110.0695312482555\n",
      "    val_log_marginal: 791.6460165097913\n",
      "Train Epoch: 432 [512/17352 (3%)] Loss: -805.214966\n",
      "Train Epoch: 432 [10277/17352 (59%)] Loss: -888.842773\n",
      "Train Epoch: 432 [16872/17352 (97%)] Loss: -739.850790\n",
      "    epoch          : 432\n",
      "    loss           : -759.2763345706865\n",
      "    val_loss       : -774.5322189437337\n",
      "    val_log_likelihood: 1109.6196013504448\n",
      "    val_log_marginal: 787.205250713895\n",
      "Train Epoch: 433 [512/17352 (3%)] Loss: -818.846497\n",
      "Train Epoch: 433 [10729/17352 (62%)] Loss: -827.634400\n",
      "Train Epoch: 433 [17044/17352 (98%)] Loss: -910.559245\n",
      "    epoch          : 433\n",
      "    loss           : -772.6809944292969\n",
      "    val_loss       : -787.8439727056483\n",
      "    val_log_likelihood: 1122.3909624796463\n",
      "    val_log_marginal: 801.0692699179468\n",
      "Train Epoch: 434 [512/17352 (3%)] Loss: -830.261230\n",
      "Train Epoch: 434 [10482/17352 (60%)] Loss: -812.003551\n",
      "Train Epoch: 434 [16883/17352 (97%)] Loss: -815.421990\n",
      "    epoch          : 434\n",
      "    loss           : -789.0672327909318\n",
      "    val_loss       : -797.8850749851658\n",
      "    val_log_likelihood: 1134.4867239783614\n",
      "    val_log_marginal: 811.972333453856\n",
      "Train Epoch: 435 [512/17352 (3%)] Loss: -846.216125\n",
      "Train Epoch: 435 [10302/17352 (59%)] Loss: -849.724058\n",
      "Train Epoch: 435 [17143/17352 (99%)] Loss: -806.657276\n",
      "    epoch          : 435\n",
      "    loss           : -792.8831464520953\n",
      "    val_loss       : -793.4795034650318\n",
      "    val_log_likelihood: 1132.5660172490273\n",
      "    val_log_marginal: 803.2874278975472\n",
      "Train Epoch: 436 [512/17352 (3%)] Loss: -827.473999\n",
      "Train Epoch: 436 [10515/17352 (61%)] Loss: -582.648656\n",
      "Train Epoch: 436 [17106/17352 (99%)] Loss: -842.937811\n",
      "    epoch          : 436\n",
      "    loss           : -783.3162552783994\n",
      "    val_loss       : -789.1391775497041\n",
      "    val_log_likelihood: 1128.7278305939403\n",
      "    val_log_marginal: 800.8198678202034\n",
      "Train Epoch: 437 [512/17352 (3%)] Loss: -837.618774\n",
      "Train Epoch: 437 [10337/17352 (60%)] Loss: -831.990943\n",
      "Train Epoch: 437 [17090/17352 (98%)] Loss: -679.095245\n",
      "    epoch          : 437\n",
      "    loss           : -789.346767059375\n",
      "    val_loss       : -800.5496598704052\n",
      "    val_log_likelihood: 1138.4998610819237\n",
      "    val_log_marginal: 813.4021190217054\n",
      "Train Epoch: 438 [512/17352 (3%)] Loss: -842.525146\n",
      "Train Epoch: 438 [10173/17352 (59%)] Loss: -652.817900\n",
      "Train Epoch: 438 [16958/17352 (98%)] Loss: -886.144531\n",
      "    epoch          : 438\n",
      "    loss           : -751.5657427081089\n",
      "    val_loss       : -751.8117867733843\n",
      "    val_log_likelihood: 1108.9316016995842\n",
      "    val_log_marginal: 769.6750110751058\n",
      "Train Epoch: 439 [512/17352 (3%)] Loss: -796.045593\n",
      "Train Epoch: 439 [10698/17352 (62%)] Loss: -661.589816\n",
      "Train Epoch: 439 [17124/17352 (99%)] Loss: -846.949051\n",
      "    epoch          : 439\n",
      "    loss           : -765.7308673485003\n",
      "    val_loss       : -753.6853543772211\n",
      "    val_log_likelihood: 1125.5883501401418\n",
      "    val_log_marginal: 786.6628467546147\n",
      "Train Epoch: 440 [512/17352 (3%)] Loss: -772.703918\n",
      "Train Epoch: 440 [10007/17352 (58%)] Loss: -783.518545\n",
      "Train Epoch: 440 [17049/17352 (98%)] Loss: -845.068430\n",
      "    epoch          : 440\n",
      "    loss           : -768.7086711866428\n",
      "    val_loss       : -773.3332287766509\n",
      "    val_log_likelihood: 1124.0055326214738\n",
      "    val_log_marginal: 792.2302869510146\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch440.pth ...\n",
      "Train Epoch: 441 [512/17352 (3%)] Loss: -817.808777\n",
      "Train Epoch: 441 [10516/17352 (61%)] Loss: -821.459140\n",
      "Train Epoch: 441 [17335/17352 (100%)] Loss: -629.117075\n",
      "    epoch          : 441\n",
      "    loss           : -792.6571162386005\n",
      "    val_loss       : -803.1795913350907\n",
      "    val_log_likelihood: 1144.5600316069726\n",
      "    val_log_marginal: 817.5124039707255\n",
      "Train Epoch: 442 [512/17352 (3%)] Loss: -848.252869\n",
      "Train Epoch: 442 [9763/17352 (56%)] Loss: -749.159539\n",
      "Train Epoch: 442 [17335/17352 (100%)] Loss: -889.659494\n",
      "    epoch          : 442\n",
      "    loss           : -804.3518189273019\n",
      "    val_loss       : -806.3854198701113\n",
      "    val_log_likelihood: 1147.6417365293144\n",
      "    val_log_marginal: 820.1526223515652\n",
      "Train Epoch: 443 [512/17352 (3%)] Loss: -855.631653\n",
      "Train Epoch: 443 [10047/17352 (58%)] Loss: -843.822732\n",
      "Train Epoch: 443 [16939/17352 (98%)] Loss: -841.860286\n",
      "    epoch          : 443\n",
      "    loss           : -806.681061786\n",
      "    val_loss       : -808.5243168488474\n",
      "    val_log_likelihood: 1154.9927506714625\n",
      "    val_log_marginal: 822.730952826242\n",
      "Train Epoch: 444 [512/17352 (3%)] Loss: -859.145874\n",
      "Train Epoch: 444 [10146/17352 (58%)] Loss: -832.083857\n",
      "Train Epoch: 444 [16922/17352 (98%)] Loss: -641.045497\n",
      "    epoch          : 444\n",
      "    loss           : -809.3521178606507\n",
      "    val_loss       : -814.0998975443252\n",
      "    val_log_likelihood: 1160.097277746918\n",
      "    val_log_marginal: 825.6731106790447\n",
      "Train Epoch: 445 [512/17352 (3%)] Loss: -857.365662\n",
      "Train Epoch: 445 [10563/17352 (61%)] Loss: -753.829474\n",
      "Train Epoch: 445 [17108/17352 (99%)] Loss: -853.828268\n",
      "    epoch          : 445\n",
      "    loss           : -810.8181905299741\n",
      "    val_loss       : -813.6900566433874\n",
      "    val_log_likelihood: 1162.149350651526\n",
      "    val_log_marginal: 826.3273242316883\n",
      "Train Epoch: 446 [512/17352 (3%)] Loss: -853.282959\n",
      "Train Epoch: 446 [10339/17352 (60%)] Loss: -900.654255\n",
      "Train Epoch: 446 [17253/17352 (99%)] Loss: -895.474680\n",
      "    epoch          : 446\n",
      "    loss           : -815.0317603500314\n",
      "    val_loss       : -817.2218313806042\n",
      "    val_log_likelihood: 1165.7627233995993\n",
      "    val_log_marginal: 829.1304435403314\n",
      "Train Epoch: 447 [512/17352 (3%)] Loss: -862.649780\n",
      "Train Epoch: 447 [10332/17352 (60%)] Loss: -852.530273\n",
      "Train Epoch: 447 [17263/17352 (99%)] Loss: -881.583437\n",
      "    epoch          : 447\n",
      "    loss           : -820.8189917111579\n",
      "    val_loss       : -817.8688513618863\n",
      "    val_log_likelihood: 1169.947587004299\n",
      "    val_log_marginal: 828.6617104147609\n",
      "Train Epoch: 448 [512/17352 (3%)] Loss: -861.502625\n",
      "Train Epoch: 448 [10259/17352 (59%)] Loss: -737.420108\n",
      "Train Epoch: 448 [17143/17352 (99%)] Loss: -642.479528\n",
      "    epoch          : 448\n",
      "    loss           : -805.2853747747643\n",
      "    val_loss       : -795.2777115899497\n",
      "    val_log_likelihood: 1159.6314096858075\n",
      "    val_log_marginal: 814.6428092245673\n",
      "Train Epoch: 449 [512/17352 (3%)] Loss: -816.561584\n",
      "Train Epoch: 449 [9988/17352 (58%)] Loss: -880.400133\n",
      "Train Epoch: 449 [17044/17352 (98%)] Loss: -634.572849\n",
      "    epoch          : 449\n",
      "    loss           : -783.5593238479928\n",
      "    val_loss       : -796.3801135908724\n",
      "    val_log_likelihood: 1154.503984065153\n",
      "    val_log_marginal: 812.6099712218751\n",
      "Train Epoch: 450 [512/17352 (3%)] Loss: -842.382690\n",
      "Train Epoch: 450 [10643/17352 (61%)] Loss: -768.761440\n",
      "Train Epoch: 450 [17335/17352 (100%)] Loss: -699.019905\n",
      "    epoch          : 450\n",
      "    loss           : -809.8984788368155\n",
      "    val_loss       : -801.0519371108192\n",
      "    val_log_likelihood: 1160.0746313577306\n",
      "    val_log_marginal: 818.5371487971743\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch450.pth ...\n",
      "Train Epoch: 451 [512/17352 (3%)] Loss: -848.714111\n",
      "Train Epoch: 451 [10553/17352 (61%)] Loss: -930.720920\n",
      "Train Epoch: 451 [16872/17352 (97%)] Loss: -733.427713\n",
      "    epoch          : 451\n",
      "    loss           : -790.3127906365505\n",
      "    val_loss       : -797.0714237708858\n",
      "    val_log_likelihood: 1163.258294798349\n",
      "    val_log_marginal: 819.6854716065369\n",
      "Train Epoch: 452 [512/17352 (3%)] Loss: -812.673889\n",
      "Train Epoch: 452 [10760/17352 (62%)] Loss: -742.213871\n",
      "Train Epoch: 452 [17064/17352 (98%)] Loss: -839.002434\n",
      "    epoch          : 452\n",
      "    loss           : -780.3636065650757\n",
      "    val_loss       : -803.1387756705141\n",
      "    val_log_likelihood: 1156.8509448822492\n",
      "    val_log_marginal: 816.0970384297223\n",
      "Train Epoch: 453 [512/17352 (3%)] Loss: -849.308105\n",
      "Train Epoch: 453 [10072/17352 (58%)] Loss: -704.920150\n",
      "Train Epoch: 453 [16922/17352 (98%)] Loss: -914.967231\n",
      "    epoch          : 453\n",
      "    loss           : -802.115199353814\n",
      "    val_loss       : -818.793680388933\n",
      "    val_log_likelihood: 1168.0906922327545\n",
      "    val_log_marginal: 831.7196126815386\n",
      "Train Epoch: 454 [512/17352 (3%)] Loss: -877.744263\n",
      "Train Epoch: 454 [10475/17352 (60%)] Loss: -749.422179\n",
      "Train Epoch: 454 [17126/17352 (99%)] Loss: -690.596947\n",
      "    epoch          : 454\n",
      "    loss           : -814.8366552097383\n",
      "    val_loss       : -820.790461519145\n",
      "    val_log_likelihood: 1176.3100226699585\n",
      "    val_log_marginal: 834.6215456889158\n",
      "Train Epoch: 455 [512/17352 (3%)] Loss: -845.413940\n",
      "Train Epoch: 455 [10834/17352 (62%)] Loss: -842.214062\n",
      "Train Epoch: 455 [16883/17352 (97%)] Loss: -775.245614\n",
      "    epoch          : 455\n",
      "    loss           : -819.9088913511092\n",
      "    val_loss       : -829.9800954957386\n",
      "    val_log_likelihood: 1181.9527326343741\n",
      "    val_log_marginal: 841.4892723635143\n",
      "Train Epoch: 456 [512/17352 (3%)] Loss: -859.911194\n",
      "Train Epoch: 456 [10127/17352 (58%)] Loss: -837.252558\n",
      "Train Epoch: 456 [17101/17352 (99%)] Loss: -708.038833\n",
      "    epoch          : 456\n",
      "    loss           : -806.1511114429571\n",
      "    val_loss       : -802.2717804185879\n",
      "    val_log_likelihood: 1166.710196177606\n",
      "    val_log_marginal: 821.5983499910969\n",
      "Train Epoch: 457 [512/17352 (3%)] Loss: -862.205444\n",
      "Train Epoch: 457 [10761/17352 (62%)] Loss: -647.322219\n",
      "Train Epoch: 457 [17335/17352 (100%)] Loss: -896.018646\n",
      "    epoch          : 457\n",
      "    loss           : -808.7759458267986\n",
      "    val_loss       : -811.008986096075\n",
      "    val_log_likelihood: 1173.7691141898342\n",
      "    val_log_marginal: 825.817308385305\n",
      "Train Epoch: 458 [512/17352 (3%)] Loss: -847.821899\n",
      "Train Epoch: 458 [10499/17352 (61%)] Loss: -642.044761\n",
      "Train Epoch: 458 [17133/17352 (99%)] Loss: -913.255272\n",
      "    epoch          : 458\n",
      "    loss           : -809.6106886915845\n",
      "    val_loss       : -801.7146730674834\n",
      "    val_log_likelihood: 1177.3828860155845\n",
      "    val_log_marginal: 820.8461706573056\n",
      "Train Epoch: 459 [512/17352 (3%)] Loss: -851.160400\n",
      "Train Epoch: 459 [9916/17352 (57%)] Loss: -633.506183\n",
      "Train Epoch: 459 [16958/17352 (98%)] Loss: -744.078906\n",
      "    epoch          : 459\n",
      "    loss           : -797.398547812747\n",
      "    val_loss       : -804.7167585878364\n",
      "    val_log_likelihood: 1170.5557522564172\n",
      "    val_log_marginal: 823.0700337757564\n",
      "Train Epoch: 460 [512/17352 (3%)] Loss: -843.599182\n",
      "Train Epoch: 460 [10368/17352 (60%)] Loss: -855.405151\n",
      "Train Epoch: 460 [17277/17352 (100%)] Loss: -751.627093\n",
      "    epoch          : 460\n",
      "    loss           : -802.4009251952546\n",
      "    val_loss       : -796.4340865296108\n",
      "    val_log_likelihood: 1166.6068097143677\n",
      "    val_log_marginal: 813.7147268707947\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch460.pth ...\n",
      "Train Epoch: 461 [512/17352 (3%)] Loss: -842.756226\n",
      "Train Epoch: 461 [10360/17352 (60%)] Loss: -911.299696\n",
      "Train Epoch: 461 [17049/17352 (98%)] Loss: -533.366552\n",
      "    epoch          : 461\n",
      "    loss           : -767.6193241271167\n",
      "    val_loss       : -699.9695349658326\n",
      "    val_log_likelihood: 1138.7445572942124\n",
      "    val_log_marginal: 710.9647773315829\n",
      "Train Epoch: 462 [512/17352 (3%)] Loss: -761.033813\n",
      "Train Epoch: 462 [10854/17352 (63%)] Loss: -831.379688\n",
      "Train Epoch: 462 [17108/17352 (99%)] Loss: -847.747892\n",
      "    epoch          : 462\n",
      "    loss           : -758.636971384757\n",
      "    val_loss       : -787.7652386470351\n",
      "    val_log_likelihood: 1150.6059645541106\n",
      "    val_log_marginal: 804.883132326436\n",
      "Train Epoch: 463 [512/17352 (3%)] Loss: -835.723938\n",
      "Train Epoch: 463 [10491/17352 (60%)] Loss: -755.664578\n",
      "Train Epoch: 463 [17016/17352 (98%)] Loss: -876.848947\n",
      "    epoch          : 463\n",
      "    loss           : -776.0315091777871\n",
      "    val_loss       : -771.6588177553496\n",
      "    val_log_likelihood: 1161.4800735272077\n",
      "    val_log_marginal: 786.5316095613105\n",
      "Train Epoch: 464 [512/17352 (3%)] Loss: -809.178284\n",
      "Train Epoch: 464 [10222/17352 (59%)] Loss: -781.879940\n",
      "Train Epoch: 464 [17044/17352 (98%)] Loss: -621.733911\n",
      "    epoch          : 464\n",
      "    loss           : -800.3461480579056\n",
      "    val_loss       : -809.647529598098\n",
      "    val_log_likelihood: 1172.4585382046675\n",
      "    val_log_marginal: 818.7182301426417\n",
      "Train Epoch: 465 [512/17352 (3%)] Loss: -847.914917\n",
      "Train Epoch: 465 [10446/17352 (60%)] Loss: -837.800954\n",
      "Train Epoch: 465 [17335/17352 (100%)] Loss: -850.459485\n",
      "    epoch          : 465\n",
      "    loss           : -818.9209148611342\n",
      "    val_loss       : -812.2585483675256\n",
      "    val_log_likelihood: 1180.9498497161273\n",
      "    val_log_marginal: 826.1831014655367\n",
      "Train Epoch: 466 [512/17352 (3%)] Loss: -853.174316\n",
      "Train Epoch: 466 [10503/17352 (61%)] Loss: -899.579589\n",
      "Train Epoch: 466 [16988/17352 (98%)] Loss: -920.221474\n",
      "    epoch          : 466\n",
      "    loss           : -805.6246491036776\n",
      "    val_loss       : -779.7876966214292\n",
      "    val_log_likelihood: 1169.2381810060056\n",
      "    val_log_marginal: 797.3780753118242\n",
      "Train Epoch: 467 [512/17352 (3%)] Loss: -813.442993\n",
      "Train Epoch: 467 [10313/17352 (59%)] Loss: -861.385488\n",
      "Train Epoch: 467 [17049/17352 (98%)] Loss: -899.025520\n",
      "    epoch          : 467\n",
      "    loss           : -792.2307898893379\n",
      "    val_loss       : -808.3915057431684\n",
      "    val_log_likelihood: 1179.2111201680343\n",
      "    val_log_marginal: 826.7031676583296\n",
      "Train Epoch: 468 [512/17352 (3%)] Loss: -846.345459\n",
      "Train Epoch: 468 [10470/17352 (60%)] Loss: -857.471738\n",
      "Train Epoch: 468 [17064/17352 (98%)] Loss: -856.825145\n",
      "    epoch          : 468\n",
      "    loss           : -809.4584281701359\n",
      "    val_loss       : -773.429904931235\n",
      "    val_log_likelihood: 1184.3242686002807\n",
      "    val_log_marginal: 792.2289132640492\n",
      "Train Epoch: 469 [512/17352 (3%)] Loss: -820.853394\n",
      "Train Epoch: 469 [10292/17352 (59%)] Loss: -658.785887\n",
      "Train Epoch: 469 [17106/17352 (99%)] Loss: -858.912891\n",
      "    epoch          : 469\n",
      "    loss           : -791.3906764709185\n",
      "    val_loss       : -800.0641603650855\n",
      "    val_log_likelihood: 1183.7570425821752\n",
      "    val_log_marginal: 815.6284820150531\n",
      "Train Epoch: 470 [512/17352 (3%)] Loss: -840.535156\n",
      "Train Epoch: 470 [10314/17352 (59%)] Loss: -835.388966\n",
      "Train Epoch: 470 [17049/17352 (98%)] Loss: -812.542792\n",
      "    epoch          : 470\n",
      "    loss           : -798.9662501437945\n",
      "    val_loss       : -776.3010993212765\n",
      "    val_log_likelihood: 1163.1453852571183\n",
      "    val_log_marginal: 801.2075244309852\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch470.pth ...\n",
      "Train Epoch: 471 [512/17352 (3%)] Loss: -818.824280\n",
      "Train Epoch: 471 [9979/17352 (58%)] Loss: -610.298669\n",
      "Train Epoch: 471 [16939/17352 (98%)] Loss: -879.418908\n",
      "    epoch          : 471\n",
      "    loss           : -784.6426865393462\n",
      "    val_loss       : -756.1500179273528\n",
      "    val_log_likelihood: 1170.4925591713304\n",
      "    val_log_marginal: 772.9741644029858\n",
      "Train Epoch: 472 [512/17352 (3%)] Loss: -802.191345\n",
      "Train Epoch: 472 [10231/17352 (59%)] Loss: -658.273176\n",
      "Train Epoch: 472 [17064/17352 (98%)] Loss: -866.228025\n",
      "    epoch          : 472\n",
      "    loss           : -802.8790266675993\n",
      "    val_loss       : -802.5133124874059\n",
      "    val_log_likelihood: 1173.3328844257674\n",
      "    val_log_marginal: 814.7695198119566\n",
      "Train Epoch: 473 [512/17352 (3%)] Loss: -855.471313\n",
      "Train Epoch: 473 [10301/17352 (59%)] Loss: -690.657745\n",
      "Train Epoch: 473 [17016/17352 (98%)] Loss: -898.870411\n",
      "    epoch          : 473\n",
      "    loss           : -789.8822437063739\n",
      "    val_loss       : -811.3141907472176\n",
      "    val_log_likelihood: 1176.422546845345\n",
      "    val_log_marginal: 828.1690755862785\n",
      "Train Epoch: 474 [512/17352 (3%)] Loss: -870.269470\n",
      "Train Epoch: 474 [10049/17352 (58%)] Loss: -774.985464\n",
      "Train Epoch: 474 [17016/17352 (98%)] Loss: -868.037101\n",
      "    epoch          : 474\n",
      "    loss           : -800.0248095227383\n",
      "    val_loss       : -808.9415221289004\n",
      "    val_log_likelihood: 1185.0695388601437\n",
      "    val_log_marginal: 822.8688698591892\n",
      "Train Epoch: 475 [512/17352 (3%)] Loss: -851.739502\n",
      "Train Epoch: 475 [10411/17352 (60%)] Loss: -872.523350\n",
      "Train Epoch: 475 [16957/17352 (98%)] Loss: -626.266260\n",
      "    epoch          : 475\n",
      "    loss           : -802.4142059410007\n",
      "    val_loss       : -779.7885628338114\n",
      "    val_log_likelihood: 1188.424027116289\n",
      "    val_log_marginal: 792.899206539304\n",
      "Train Epoch: 476 [512/17352 (3%)] Loss: -842.065918\n",
      "Train Epoch: 476 [10559/17352 (61%)] Loss: -621.143196\n",
      "Train Epoch: 476 [17108/17352 (99%)] Loss: -769.854271\n",
      "    epoch          : 476\n",
      "    loss           : -665.091063451192\n",
      "    val_loss       : -564.6042611353416\n",
      "    val_log_likelihood: 1112.2751118616484\n",
      "    val_log_marginal: 585.2390726455859\n",
      "Train Epoch: 477 [512/17352 (3%)] Loss: -569.921448\n",
      "Train Epoch: 477 [9786/17352 (56%)] Loss: -624.101677\n",
      "Train Epoch: 477 [16878/17352 (97%)] Loss: -558.187345\n",
      "    epoch          : 477\n",
      "    loss           : -676.6981806183354\n",
      "    val_loss       : -786.6521811196269\n",
      "    val_log_likelihood: 1157.5380855666317\n",
      "    val_log_marginal: 809.3640401724854\n",
      "Train Epoch: 478 [512/17352 (3%)] Loss: -843.632080\n",
      "Train Epoch: 478 [10343/17352 (60%)] Loss: -672.218149\n",
      "Train Epoch: 478 [16934/17352 (98%)] Loss: -882.045464\n",
      "    epoch          : 478\n",
      "    loss           : -758.9258018952839\n",
      "    val_loss       : -793.13101238773\n",
      "    val_log_likelihood: 1151.582745208101\n",
      "    val_log_marginal: 809.0308715433661\n",
      "Train Epoch: 479 [512/17352 (3%)] Loss: -834.423889\n",
      "Train Epoch: 479 [10693/17352 (62%)] Loss: -879.024419\n",
      "Train Epoch: 479 [16939/17352 (98%)] Loss: -881.311787\n",
      "    epoch          : 479\n",
      "    loss           : -802.3949183415161\n",
      "    val_loss       : -822.1180663330929\n",
      "    val_log_likelihood: 1183.8116720990665\n",
      "    val_log_marginal: 843.8579759217348\n",
      "Train Epoch: 480 [512/17352 (3%)] Loss: -863.793884\n",
      "Train Epoch: 480 [10618/17352 (61%)] Loss: -849.475312\n",
      "Train Epoch: 480 [17126/17352 (99%)] Loss: -798.081731\n",
      "    epoch          : 480\n",
      "    loss           : -811.875176445125\n",
      "    val_loss       : -821.7056478886701\n",
      "    val_log_likelihood: 1188.6593339439974\n",
      "    val_log_marginal: 836.2323533361701\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch480.pth ...\n",
      "Train Epoch: 481 [512/17352 (3%)] Loss: -877.613281\n",
      "Train Epoch: 481 [10277/17352 (59%)] Loss: -794.451960\n",
      "Train Epoch: 481 [16923/17352 (98%)] Loss: -935.606689\n",
      "    epoch          : 481\n",
      "    loss           : -828.4596880863253\n",
      "    val_loss       : -809.9321239155636\n",
      "    val_log_likelihood: 1181.121746525556\n",
      "    val_log_marginal: 827.4262923446964\n",
      "Train Epoch: 482 [512/17352 (3%)] Loss: -798.134338\n",
      "Train Epoch: 482 [9342/17352 (54%)] Loss: -879.844672\n",
      "Train Epoch: 482 [16922/17352 (98%)] Loss: -714.102171\n",
      "    epoch          : 482\n",
      "    loss           : -791.0790237596618\n",
      "    val_loss       : -809.2620765854174\n",
      "    val_log_likelihood: 1179.8901172961089\n",
      "    val_log_marginal: 826.2384777466827\n",
      "Train Epoch: 483 [512/17352 (3%)] Loss: -856.483826\n",
      "Train Epoch: 483 [10399/17352 (60%)] Loss: -742.257031\n",
      "Train Epoch: 483 [16957/17352 (98%)] Loss: -796.748414\n",
      "    epoch          : 483\n",
      "    loss           : -714.535596138955\n",
      "    val_loss       : -729.2265703606898\n",
      "    val_log_likelihood: 1154.857276294981\n",
      "    val_log_marginal: 751.0244366389273\n",
      "Train Epoch: 484 [512/17352 (3%)] Loss: -736.668762\n",
      "Train Epoch: 484 [10552/17352 (61%)] Loss: -865.266070\n",
      "Train Epoch: 484 [16934/17352 (98%)] Loss: -519.654445\n",
      "    epoch          : 484\n",
      "    loss           : -705.4993179608609\n",
      "    val_loss       : -681.4786870911297\n",
      "    val_log_likelihood: 1146.4068966258528\n",
      "    val_log_marginal: 691.379520970479\n",
      "Train Epoch: 485 [512/17352 (3%)] Loss: -741.767822\n",
      "Train Epoch: 485 [10633/17352 (61%)] Loss: -724.150670\n",
      "Train Epoch: 485 [16922/17352 (98%)] Loss: -789.243017\n",
      "    epoch          : 485\n",
      "    loss           : -741.4304081263537\n",
      "    val_loss       : -820.6735438334796\n",
      "    val_log_likelihood: 1177.3361781464675\n",
      "    val_log_marginal: 831.9283845541847\n",
      "Train Epoch: 486 [512/17352 (3%)] Loss: -854.933472\n",
      "Train Epoch: 486 [10359/17352 (60%)] Loss: -871.636094\n",
      "Train Epoch: 486 [17090/17352 (98%)] Loss: -862.044767\n",
      "    epoch          : 486\n",
      "    loss           : -773.7245800735813\n",
      "    val_loss       : -769.7631025900481\n",
      "    val_log_likelihood: 1171.0374598252672\n",
      "    val_log_marginal: 786.3148992214167\n",
      "Train Epoch: 487 [512/17352 (3%)] Loss: -831.536926\n",
      "Train Epoch: 487 [9753/17352 (56%)] Loss: -742.171922\n",
      "Train Epoch: 487 [17044/17352 (98%)] Loss: -656.887966\n",
      "    epoch          : 487\n",
      "    loss           : -793.5292149754731\n",
      "    val_loss       : -800.2457897715152\n",
      "    val_log_likelihood: 1179.7775574108514\n",
      "    val_log_marginal: 813.7678995982691\n",
      "Train Epoch: 488 [512/17352 (3%)] Loss: -837.663513\n",
      "Train Epoch: 488 [10192/17352 (59%)] Loss: -717.924461\n",
      "Train Epoch: 488 [17124/17352 (99%)] Loss: -860.224609\n",
      "    epoch          : 488\n",
      "    loss           : -822.0974635332379\n",
      "    val_loss       : -835.5233086581881\n",
      "    val_log_likelihood: 1192.044733920082\n",
      "    val_log_marginal: 847.4555171753555\n",
      "Train Epoch: 489 [512/17352 (3%)] Loss: -865.450500\n",
      "Train Epoch: 489 [10660/17352 (61%)] Loss: -720.137583\n",
      "Train Epoch: 489 [17090/17352 (98%)] Loss: -926.952292\n",
      "    epoch          : 489\n",
      "    loss           : -841.6288386223414\n",
      "    val_loss       : -833.3752466800046\n",
      "    val_log_likelihood: 1202.5498279575197\n",
      "    val_log_marginal: 846.596058483702\n",
      "Train Epoch: 490 [512/17352 (3%)] Loss: -881.344727\n",
      "Train Epoch: 490 [10551/17352 (61%)] Loss: -880.942383\n",
      "Train Epoch: 490 [17126/17352 (99%)] Loss: -802.983863\n",
      "    epoch          : 490\n",
      "    loss           : -845.3493843403763\n",
      "    val_loss       : -845.9387614213316\n",
      "    val_log_likelihood: 1208.2780385498786\n",
      "    val_log_marginal: 858.9217282475664\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch490.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 491 [512/17352 (3%)] Loss: -886.070557\n",
      "Train Epoch: 491 [10788/17352 (62%)] Loss: -711.751186\n",
      "Train Epoch: 491 [17143/17352 (99%)] Loss: -753.483247\n",
      "    epoch          : 491\n",
      "    loss           : -849.2089735144615\n",
      "    val_loss       : -829.5310428735421\n",
      "    val_log_likelihood: 1213.7730050438993\n",
      "    val_log_marginal: 843.1840125245187\n",
      "Train Epoch: 492 [512/17352 (3%)] Loss: -692.552246\n",
      "Train Epoch: 492 [9610/17352 (55%)] Loss: -821.348300\n",
      "Train Epoch: 492 [16882/17352 (97%)] Loss: -882.210174\n",
      "    epoch          : 492\n",
      "    loss           : -826.7852437413873\n",
      "    val_loss       : -803.209866369771\n",
      "    val_log_likelihood: 1200.4967233414902\n",
      "    val_log_marginal: 836.7211412325195\n",
      "Train Epoch: 493 [512/17352 (3%)] Loss: -868.819336\n",
      "Train Epoch: 493 [9968/17352 (57%)] Loss: -912.662475\n",
      "Train Epoch: 493 [17253/17352 (99%)] Loss: -706.710785\n",
      "    epoch          : 493\n",
      "    loss           : -816.8422639304082\n",
      "    val_loss       : -809.7771789510759\n",
      "    val_log_likelihood: 1192.8932947851424\n",
      "    val_log_marginal: 826.3634171197967\n",
      "Train Epoch: 494 [512/17352 (3%)] Loss: -869.482422\n",
      "Train Epoch: 494 [10614/17352 (61%)] Loss: -912.240160\n",
      "Train Epoch: 494 [16988/17352 (98%)] Loss: -749.623505\n",
      "    epoch          : 494\n",
      "    loss           : -810.4343301267762\n",
      "    val_loss       : -817.8750027993237\n",
      "    val_log_likelihood: 1196.6102882705106\n",
      "    val_log_marginal: 847.0065988031322\n",
      "Train Epoch: 495 [512/17352 (3%)] Loss: -810.578674\n",
      "Train Epoch: 495 [10427/17352 (60%)] Loss: -868.013662\n",
      "Train Epoch: 495 [16872/17352 (97%)] Loss: -740.440755\n",
      "    epoch          : 495\n",
      "    loss           : -820.2466598591492\n",
      "    val_loss       : -814.936982705137\n",
      "    val_log_likelihood: 1194.3731102196732\n",
      "    val_log_marginal: 836.7403025003571\n",
      "Train Epoch: 496 [512/17352 (3%)] Loss: -843.677673\n",
      "Train Epoch: 496 [10127/17352 (58%)] Loss: -836.897884\n",
      "Train Epoch: 496 [17253/17352 (99%)] Loss: -833.190239\n",
      "    epoch          : 496\n",
      "    loss           : -815.8056320901234\n",
      "    val_loss       : -774.5257022323896\n",
      "    val_log_likelihood: 1192.3878666811406\n",
      "    val_log_marginal: 790.8807438719538\n",
      "Train Epoch: 497 [512/17352 (3%)] Loss: -797.744019\n",
      "Train Epoch: 497 [10295/17352 (59%)] Loss: -639.207314\n",
      "Train Epoch: 497 [17253/17352 (99%)] Loss: -857.038151\n",
      "    epoch          : 497\n",
      "    loss           : -767.6444712577024\n",
      "    val_loss       : -597.2480339719777\n",
      "    val_log_likelihood: 1170.2138457530602\n",
      "    val_log_marginal: 614.1534832777558\n",
      "Train Epoch: 498 [512/17352 (3%)] Loss: -629.161499\n",
      "Train Epoch: 498 [10454/17352 (60%)] Loss: -812.549089\n",
      "Train Epoch: 498 [16923/17352 (98%)] Loss: -854.042808\n",
      "    epoch          : 498\n",
      "    loss           : -734.9279390634123\n",
      "    val_loss       : -793.7547807773618\n",
      "    val_log_likelihood: 1175.7787177877756\n",
      "    val_log_marginal: 813.649560392226\n",
      "Train Epoch: 499 [512/17352 (3%)] Loss: -842.005981\n",
      "Train Epoch: 499 [10682/17352 (62%)] Loss: -752.422230\n",
      "Train Epoch: 499 [17049/17352 (98%)] Loss: -929.012860\n",
      "    epoch          : 499\n",
      "    loss           : -820.0001509889843\n",
      "    val_loss       : -827.2176476769911\n",
      "    val_log_likelihood: 1195.626670811845\n",
      "    val_log_marginal: 840.8172060719336\n",
      "Train Epoch: 500 [512/17352 (3%)] Loss: -868.706177\n",
      "Train Epoch: 500 [10796/17352 (62%)] Loss: -740.084853\n",
      "Train Epoch: 500 [16958/17352 (98%)] Loss: -865.787749\n",
      "    epoch          : 500\n",
      "    loss           : -814.0760550555071\n",
      "    val_loss       : -825.8704946889414\n",
      "    val_log_likelihood: 1192.8111744219582\n",
      "    val_log_marginal: 846.3704974369623\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch500.pth ...\n",
      "Train Epoch: 501 [512/17352 (3%)] Loss: -874.927734\n",
      "Train Epoch: 501 [10322/17352 (59%)] Loss: -914.091354\n",
      "Train Epoch: 501 [16882/17352 (97%)] Loss: -930.903753\n",
      "    epoch          : 501\n",
      "    loss           : -822.2227202141461\n",
      "    val_loss       : -833.4269360967068\n",
      "    val_log_likelihood: 1199.1223572516883\n",
      "    val_log_marginal: 844.4284124513073\n",
      "Train Epoch: 502 [512/17352 (3%)] Loss: -861.424622\n",
      "Train Epoch: 502 [10304/17352 (59%)] Loss: -625.609973\n",
      "Train Epoch: 502 [17124/17352 (99%)] Loss: -795.901113\n",
      "    epoch          : 502\n",
      "    loss           : -812.1272404876416\n",
      "    val_loss       : -818.6523676219257\n",
      "    val_log_likelihood: 1198.153363855093\n",
      "    val_log_marginal: 836.0476241815846\n",
      "Train Epoch: 503 [512/17352 (3%)] Loss: -871.272217\n",
      "Train Epoch: 503 [10447/17352 (60%)] Loss: -899.411780\n",
      "Train Epoch: 503 [17335/17352 (100%)] Loss: -876.182271\n",
      "    epoch          : 503\n",
      "    loss           : -797.8724460374966\n",
      "    val_loss       : -725.9409829717512\n",
      "    val_log_likelihood: 1183.35524904833\n",
      "    val_log_marginal: 739.2566769044715\n",
      "Train Epoch: 504 [512/17352 (3%)] Loss: -781.741333\n",
      "Train Epoch: 504 [10154/17352 (59%)] Loss: -913.389648\n",
      "Train Epoch: 504 [16872/17352 (97%)] Loss: -682.344775\n",
      "    epoch          : 504\n",
      "    loss           : -719.2756539149907\n",
      "    val_loss       : -706.371057537632\n",
      "    val_log_likelihood: 1156.3173022560948\n",
      "    val_log_marginal: 726.4609619797022\n",
      "Train Epoch: 505 [512/17352 (3%)] Loss: -735.439880\n",
      "Train Epoch: 505 [9754/17352 (56%)] Loss: -657.462740\n",
      "Train Epoch: 505 [16992/17352 (98%)] Loss: -591.880064\n",
      "    epoch          : 505\n",
      "    loss           : -686.1346178302085\n",
      "    val_loss       : -705.4654795501584\n",
      "    val_log_likelihood: 1140.7977902937625\n",
      "    val_log_marginal: 736.5944139426242\n",
      "Train Epoch: 506 [512/17352 (3%)] Loss: -758.511414\n",
      "Train Epoch: 506 [10072/17352 (58%)] Loss: -742.320944\n",
      "Train Epoch: 506 [17263/17352 (99%)] Loss: -718.977179\n",
      "    epoch          : 506\n",
      "    loss           : -733.8710107978739\n",
      "    val_loss       : -763.2813177170411\n",
      "    val_log_likelihood: 1160.9908901801925\n",
      "    val_log_marginal: 789.3015918188524\n",
      "Train Epoch: 507 [512/17352 (3%)] Loss: -828.073792\n",
      "Train Epoch: 507 [10046/17352 (58%)] Loss: -776.622934\n",
      "Train Epoch: 507 [16988/17352 (98%)] Loss: -894.402215\n",
      "    epoch          : 507\n",
      "    loss           : -764.8769653998306\n",
      "    val_loss       : -799.6093611664555\n",
      "    val_log_likelihood: 1172.408340659866\n",
      "    val_log_marginal: 817.4315778163573\n",
      "Train Epoch: 508 [512/17352 (3%)] Loss: -859.601501\n",
      "Train Epoch: 508 [10726/17352 (62%)] Loss: -856.131863\n",
      "Train Epoch: 508 [16934/17352 (98%)] Loss: -726.119828\n",
      "    epoch          : 508\n",
      "    loss           : -806.3104630716718\n",
      "    val_loss       : -838.3752836336098\n",
      "    val_log_likelihood: 1199.2568352938165\n",
      "    val_log_marginal: 854.448676489922\n",
      "Train Epoch: 509 [512/17352 (3%)] Loss: -679.621216\n",
      "Train Epoch: 509 [10024/17352 (58%)] Loss: -862.323178\n",
      "Train Epoch: 509 [17049/17352 (98%)] Loss: -895.243501\n",
      "    epoch          : 509\n",
      "    loss           : -838.8565286088782\n",
      "    val_loss       : -839.7785952426857\n",
      "    val_log_likelihood: 1205.5724534157057\n",
      "    val_log_marginal: 854.4382961759014\n",
      "Train Epoch: 510 [512/17352 (3%)] Loss: -691.903076\n",
      "Train Epoch: 510 [10308/17352 (59%)] Loss: -877.978274\n",
      "Train Epoch: 510 [17126/17352 (99%)] Loss: -727.450827\n",
      "    epoch          : 510\n",
      "    loss           : -796.2875528967924\n",
      "    val_loss       : -739.2956704911024\n",
      "    val_log_likelihood: 1164.0313191884911\n",
      "    val_log_marginal: 791.7541812499815\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch510.pth ...\n",
      "Train Epoch: 511 [512/17352 (3%)] Loss: -806.634155\n",
      "Train Epoch: 511 [10187/17352 (59%)] Loss: -786.555508\n",
      "Train Epoch: 511 [16957/17352 (98%)] Loss: -805.793997\n",
      "    epoch          : 511\n",
      "    loss           : -791.1145064154888\n",
      "    val_loss       : -825.9691000592717\n",
      "    val_log_likelihood: 1198.5909444419653\n",
      "    val_log_marginal: 855.1768216880675\n",
      "Train Epoch: 512 [512/17352 (3%)] Loss: -864.809204\n",
      "Train Epoch: 512 [10185/17352 (59%)] Loss: -910.818895\n",
      "Train Epoch: 512 [16939/17352 (98%)] Loss: -883.158176\n",
      "    epoch          : 512\n",
      "    loss           : -831.2843196243168\n",
      "    val_loss       : -842.5759454673085\n",
      "    val_log_likelihood: 1205.32946996539\n",
      "    val_log_marginal: 864.0807692423084\n",
      "Train Epoch: 513 [512/17352 (3%)] Loss: -899.706787\n",
      "Train Epoch: 513 [10282/17352 (59%)] Loss: -715.830858\n",
      "Train Epoch: 513 [17124/17352 (99%)] Loss: -773.836654\n",
      "    epoch          : 513\n",
      "    loss           : -812.128668452653\n",
      "    val_loss       : -780.4147337957693\n",
      "    val_log_likelihood: 1178.815841364207\n",
      "    val_log_marginal: 812.2770216334459\n",
      "Train Epoch: 514 [512/17352 (3%)] Loss: -821.456665\n",
      "Train Epoch: 514 [10303/17352 (59%)] Loss: -894.076146\n",
      "Train Epoch: 514 [17049/17352 (98%)] Loss: -684.302830\n",
      "    epoch          : 514\n",
      "    loss           : -790.1318213077401\n",
      "    val_loss       : -769.585928785109\n",
      "    val_log_likelihood: 1170.9457999734261\n",
      "    val_log_marginal: 813.7809588786686\n",
      "Train Epoch: 515 [512/17352 (3%)] Loss: -808.790222\n",
      "Train Epoch: 515 [10461/17352 (60%)] Loss: -853.282663\n",
      "Train Epoch: 515 [16957/17352 (98%)] Loss: -755.347917\n",
      "    epoch          : 515\n",
      "    loss           : -782.9880124980854\n",
      "    val_loss       : -836.5246356849256\n",
      "    val_log_likelihood: 1192.147865204105\n",
      "    val_log_marginal: 853.1717784644785\n",
      "Train Epoch: 516 [512/17352 (3%)] Loss: -880.364014\n",
      "Train Epoch: 516 [10348/17352 (60%)] Loss: -776.147972\n",
      "Train Epoch: 516 [17335/17352 (100%)] Loss: -739.879079\n",
      "    epoch          : 516\n",
      "    loss           : -838.1632791300972\n",
      "    val_loss       : -833.2614594996033\n",
      "    val_log_likelihood: 1195.035392922724\n",
      "    val_log_marginal: 845.8872821662455\n",
      "Train Epoch: 517 [512/17352 (3%)] Loss: -884.512573\n",
      "Train Epoch: 517 [10137/17352 (58%)] Loss: -956.535823\n",
      "Train Epoch: 517 [17108/17352 (99%)] Loss: -932.764241\n",
      "    epoch          : 517\n",
      "    loss           : -850.8351010001992\n",
      "    val_loss       : -853.0042282379574\n",
      "    val_log_likelihood: 1221.2395920891793\n",
      "    val_log_marginal: 867.0097480202292\n",
      "Train Epoch: 518 [512/17352 (3%)] Loss: -890.232666\n",
      "Train Epoch: 518 [10603/17352 (61%)] Loss: -990.003581\n",
      "Train Epoch: 518 [16939/17352 (98%)] Loss: -799.682505\n",
      "    epoch          : 518\n",
      "    loss           : -844.9832736630447\n",
      "    val_loss       : -848.5291125408501\n",
      "    val_log_likelihood: 1220.4451979952196\n",
      "    val_log_marginal: 862.7950458169996\n",
      "Train Epoch: 519 [512/17352 (3%)] Loss: -893.387512\n",
      "Train Epoch: 519 [10317/17352 (59%)] Loss: -740.908508\n",
      "Train Epoch: 519 [16883/17352 (97%)] Loss: -793.980748\n",
      "    epoch          : 519\n",
      "    loss           : -844.761099861391\n",
      "    val_loss       : -837.9908131029803\n",
      "    val_log_likelihood: 1216.8620710571442\n",
      "    val_log_marginal: 852.5159943341855\n",
      "Train Epoch: 520 [512/17352 (3%)] Loss: -847.060303\n",
      "Train Epoch: 520 [10453/17352 (60%)] Loss: -699.885781\n",
      "Train Epoch: 520 [16887/17352 (97%)] Loss: -708.876346\n",
      "    epoch          : 520\n",
      "    loss           : -836.359287527895\n",
      "    val_loss       : -797.0220573196464\n",
      "    val_log_likelihood: 1221.3442192402485\n",
      "    val_log_marginal: 818.6740161252264\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch520.pth ...\n",
      "Train Epoch: 521 [512/17352 (3%)] Loss: -814.538391\n",
      "Train Epoch: 521 [10944/17352 (63%)] Loss: -888.770515\n",
      "Train Epoch: 521 [17064/17352 (98%)] Loss: -380.209111\n",
      "    epoch          : 521\n",
      "    loss           : -825.9472516491345\n",
      "    val_loss       : -731.1698434389145\n",
      "    val_log_likelihood: 1211.2849826665256\n",
      "    val_log_marginal: 746.2463618534726\n",
      "Train Epoch: 522 [512/17352 (3%)] Loss: -776.323120\n",
      "Train Epoch: 522 [10551/17352 (61%)] Loss: -708.758247\n",
      "Train Epoch: 522 [17335/17352 (100%)] Loss: -931.144522\n",
      "    epoch          : 522\n",
      "    loss           : -787.6773178272588\n",
      "    val_loss       : -430.4677674615791\n",
      "    val_log_likelihood: 1183.9752955441745\n",
      "    val_log_marginal: 450.2337407150234\n",
      "Train Epoch: 523 [512/17352 (3%)] Loss: -459.732605\n",
      "Train Epoch: 523 [10436/17352 (60%)] Loss: -707.092796\n",
      "Train Epoch: 523 [17153/17352 (99%)] Loss: 312.004079\n",
      "    epoch          : 523\n",
      "    loss           : -299.76006604595597\n",
      "    val_loss       : -54.74825246559731\n",
      "    val_log_likelihood: 922.7636221396574\n",
      "    val_log_marginal: 107.55475204921171\n",
      "Train Epoch: 524 [512/17352 (3%)] Loss: -70.233749\n",
      "Train Epoch: 524 [10505/17352 (61%)] Loss: -480.730080\n",
      "Train Epoch: 524 [17143/17352 (99%)] Loss: -798.945975\n",
      "    epoch          : 524\n",
      "    loss           : -415.719837123095\n",
      "    val_loss       : -575.8451925185957\n",
      "    val_log_likelihood: 1084.961569893939\n",
      "    val_log_marginal: 601.4454411658969\n",
      "Train Epoch: 525 [512/17352 (3%)] Loss: -638.661499\n",
      "Train Epoch: 525 [10342/17352 (60%)] Loss: -836.640546\n",
      "Train Epoch: 525 [17044/17352 (98%)] Loss: -630.628278\n",
      "    epoch          : 525\n",
      "    loss           : -710.88526638054\n",
      "    val_loss       : -749.8344291385968\n",
      "    val_log_likelihood: 1158.8624218834673\n",
      "    val_log_marginal: 785.8038299345454\n",
      "Train Epoch: 526 [512/17352 (3%)] Loss: -813.545105\n",
      "Train Epoch: 526 [9596/17352 (55%)] Loss: -860.956109\n",
      "Train Epoch: 526 [17335/17352 (100%)] Loss: -867.798328\n",
      "    epoch          : 526\n",
      "    loss           : -805.4270275773598\n",
      "    val_loss       : -806.9970827022242\n",
      "    val_log_likelihood: 1179.703306301845\n",
      "    val_log_marginal: 828.6072340304996\n",
      "Train Epoch: 527 [512/17352 (3%)] Loss: -845.888489\n",
      "Train Epoch: 527 [10687/17352 (62%)] Loss: -892.993258\n",
      "Train Epoch: 527 [16957/17352 (98%)] Loss: -912.579003\n",
      "    epoch          : 527\n",
      "    loss           : -807.8353330036701\n",
      "    val_loss       : -828.2460417376917\n",
      "    val_log_likelihood: 1194.5872987128357\n",
      "    val_log_marginal: 846.6801605853648\n",
      "Train Epoch: 528 [512/17352 (3%)] Loss: -855.953857\n",
      "Train Epoch: 528 [10272/17352 (59%)] Loss: -685.110646\n",
      "Train Epoch: 528 [17064/17352 (98%)] Loss: -872.266808\n",
      "    epoch          : 528\n",
      "    loss           : -833.1589982557381\n",
      "    val_loss       : -827.5194729728004\n",
      "    val_log_likelihood: 1203.111988939483\n",
      "    val_log_marginal: 842.7328072429467\n",
      "Train Epoch: 529 [512/17352 (3%)] Loss: -881.712036\n",
      "Train Epoch: 529 [10052/17352 (58%)] Loss: -795.394792\n",
      "Train Epoch: 529 [17016/17352 (98%)] Loss: -931.283982\n",
      "    epoch          : 529\n",
      "    loss           : -837.5707757145518\n",
      "    val_loss       : -840.4126014915806\n",
      "    val_log_likelihood: 1211.4015546915743\n",
      "    val_log_marginal: 864.1129252944996\n",
      "Train Epoch: 530 [512/17352 (3%)] Loss: -891.401062\n",
      "Train Epoch: 530 [9967/17352 (57%)] Loss: -880.546875\n",
      "Train Epoch: 530 [17124/17352 (99%)] Loss: -679.540054\n",
      "    epoch          : 530\n",
      "    loss           : -848.2491125101022\n",
      "    val_loss       : -860.3517378405737\n",
      "    val_log_likelihood: 1211.1344753189608\n",
      "    val_log_marginal: 868.7886297175374\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch530.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 531 [512/17352 (3%)] Loss: -907.155212\n",
      "Train Epoch: 531 [10429/17352 (60%)] Loss: -972.646593\n",
      "Train Epoch: 531 [17101/17352 (99%)] Loss: -803.249360\n",
      "    epoch          : 531\n",
      "    loss           : -850.9508745673932\n",
      "    val_loss       : -855.6064758387802\n",
      "    val_log_likelihood: 1219.4877267182108\n",
      "    val_log_marginal: 872.396128047456\n",
      "Train Epoch: 532 [512/17352 (3%)] Loss: -903.114685\n",
      "Train Epoch: 532 [10671/17352 (61%)] Loss: -714.202433\n",
      "Train Epoch: 532 [17263/17352 (99%)] Loss: -816.740063\n",
      "    epoch          : 532\n",
      "    loss           : -854.980544973456\n",
      "    val_loss       : -831.2396989114696\n",
      "    val_log_likelihood: 1204.228997992127\n",
      "    val_log_marginal: 844.1441333880296\n",
      "Train Epoch: 533 [512/17352 (3%)] Loss: -882.754089\n",
      "Train Epoch: 533 [10117/17352 (58%)] Loss: -902.498750\n",
      "Train Epoch: 533 [16882/17352 (97%)] Loss: -913.630523\n",
      "    epoch          : 533\n",
      "    loss           : -853.7802555941561\n",
      "    val_loss       : -864.9018522512634\n",
      "    val_log_likelihood: 1224.649327994248\n",
      "    val_log_marginal: 877.1365561509257\n",
      "Train Epoch: 534 [512/17352 (3%)] Loss: -902.160645\n",
      "Train Epoch: 534 [10518/17352 (61%)] Loss: -959.291286\n",
      "Train Epoch: 534 [16988/17352 (98%)] Loss: -782.392718\n",
      "    epoch          : 534\n",
      "    loss           : -864.213406813576\n",
      "    val_loss       : -869.2988475663007\n",
      "    val_log_likelihood: 1228.59893422437\n",
      "    val_log_marginal: 880.9929269901279\n",
      "Train Epoch: 535 [512/17352 (3%)] Loss: -909.343201\n",
      "Train Epoch: 535 [10123/17352 (58%)] Loss: -884.580194\n",
      "Train Epoch: 535 [16883/17352 (97%)] Loss: -833.925027\n",
      "    epoch          : 535\n",
      "    loss           : -856.5008943112201\n",
      "    val_loss       : -860.3685575803968\n",
      "    val_log_likelihood: 1229.4876339015686\n",
      "    val_log_marginal: 878.9402544131952\n",
      "Train Epoch: 536 [512/17352 (3%)] Loss: -910.368042\n",
      "Train Epoch: 536 [10547/17352 (61%)] Loss: -873.214804\n",
      "Train Epoch: 536 [17143/17352 (99%)] Loss: -900.392053\n",
      "    epoch          : 536\n",
      "    loss           : -843.8835047282067\n",
      "    val_loss       : -828.2045066514644\n",
      "    val_log_likelihood: 1225.2204804230341\n",
      "    val_log_marginal: 843.830750015777\n",
      "Train Epoch: 537 [512/17352 (3%)] Loss: -871.741211\n",
      "Train Epoch: 537 [10125/17352 (58%)] Loss: -755.517014\n",
      "Train Epoch: 537 [16939/17352 (98%)] Loss: -464.622191\n",
      "    epoch          : 537\n",
      "    loss           : -789.4096865216989\n",
      "    val_loss       : -747.5995700497987\n",
      "    val_log_likelihood: 1211.061823517294\n",
      "    val_log_marginal: 758.8665586407734\n",
      "Train Epoch: 538 [512/17352 (3%)] Loss: -767.611938\n",
      "Train Epoch: 538 [10468/17352 (60%)] Loss: -492.381696\n",
      "Train Epoch: 538 [17090/17352 (98%)] Loss: -640.778449\n",
      "    epoch          : 538\n",
      "    loss           : -623.5313477088333\n",
      "    val_loss       : -783.7339992164259\n",
      "    val_log_likelihood: 1168.5265409022654\n",
      "    val_log_marginal: 810.635872113364\n",
      "Train Epoch: 539 [512/17352 (3%)] Loss: -597.327759\n",
      "Train Epoch: 539 [10088/17352 (58%)] Loss: -818.330256\n",
      "Train Epoch: 539 [17263/17352 (99%)] Loss: -648.272526\n",
      "    epoch          : 539\n",
      "    loss           : -790.027801609699\n",
      "    val_loss       : -796.9468157329886\n",
      "    val_log_likelihood: 1204.0084658255641\n",
      "    val_log_marginal: 814.4320569870046\n",
      "Train Epoch: 540 [512/17352 (3%)] Loss: -833.248413\n",
      "Train Epoch: 540 [10353/17352 (60%)] Loss: -796.896094\n",
      "Train Epoch: 540 [16922/17352 (98%)] Loss: -847.399491\n",
      "    epoch          : 540\n",
      "    loss           : -798.4420260908354\n",
      "    val_loss       : -844.6291363980105\n",
      "    val_log_likelihood: 1200.9705641007938\n",
      "    val_log_marginal: 859.1051803953762\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch540.pth ...\n",
      "Train Epoch: 541 [512/17352 (3%)] Loss: -688.687622\n",
      "Train Epoch: 541 [10474/17352 (60%)] Loss: -983.151042\n",
      "Train Epoch: 541 [16883/17352 (97%)] Loss: -895.642708\n",
      "    epoch          : 541\n",
      "    loss           : -838.5550410692739\n",
      "    val_loss       : -855.7283842888752\n",
      "    val_log_likelihood: 1221.9838221667883\n",
      "    val_log_marginal: 874.812015967051\n",
      "Train Epoch: 542 [512/17352 (3%)] Loss: -887.847534\n",
      "Train Epoch: 542 [10394/17352 (60%)] Loss: -755.533725\n",
      "Train Epoch: 542 [17101/17352 (99%)] Loss: -807.070927\n",
      "    epoch          : 542\n",
      "    loss           : -839.6042738432676\n",
      "    val_loss       : -789.5867157355788\n",
      "    val_log_likelihood: 1218.6312471677754\n",
      "    val_log_marginal: 802.0232069112118\n",
      "Train Epoch: 543 [512/17352 (3%)] Loss: -814.883301\n",
      "Train Epoch: 543 [10087/17352 (58%)] Loss: -613.659555\n",
      "Train Epoch: 543 [17016/17352 (98%)] Loss: -707.718635\n",
      "    epoch          : 543\n",
      "    loss           : -806.9641996890879\n",
      "    val_loss       : -836.5246363475662\n",
      "    val_log_likelihood: 1210.4038725586015\n",
      "    val_log_marginal: 848.3628250007208\n",
      "Train Epoch: 544 [512/17352 (3%)] Loss: -880.233459\n",
      "Train Epoch: 544 [10371/17352 (60%)] Loss: -696.635840\n",
      "Train Epoch: 544 [17106/17352 (99%)] Loss: -926.768459\n",
      "    epoch          : 544\n",
      "    loss           : -848.6891295990458\n",
      "    val_loss       : -866.7228052473777\n",
      "    val_log_likelihood: 1235.2376716693357\n",
      "    val_log_marginal: 883.2793883233783\n",
      "Train Epoch: 545 [512/17352 (3%)] Loss: -916.798279\n",
      "Train Epoch: 545 [10175/17352 (59%)] Loss: -939.720857\n",
      "Train Epoch: 545 [16923/17352 (98%)] Loss: -862.892772\n",
      "    epoch          : 545\n",
      "    loss           : -865.1554970520978\n",
      "    val_loss       : -853.8704227186624\n",
      "    val_log_likelihood: 1231.4819572682763\n",
      "    val_log_marginal: 875.4053147239881\n",
      "Train Epoch: 546 [512/17352 (3%)] Loss: -883.637268\n",
      "Train Epoch: 546 [10346/17352 (60%)] Loss: -783.424158\n",
      "Train Epoch: 546 [17126/17352 (99%)] Loss: -697.512709\n",
      "    epoch          : 546\n",
      "    loss           : -849.884677184137\n",
      "    val_loss       : -846.469196480046\n",
      "    val_log_likelihood: 1225.9619165753463\n",
      "    val_log_marginal: 866.2515104355791\n",
      "Train Epoch: 547 [512/17352 (3%)] Loss: -901.902100\n",
      "Train Epoch: 547 [10374/17352 (60%)] Loss: -968.014225\n",
      "Train Epoch: 547 [16934/17352 (98%)] Loss: -780.827608\n",
      "    epoch          : 547\n",
      "    loss           : -855.6439306193198\n",
      "    val_loss       : -848.3879736666196\n",
      "    val_log_likelihood: 1225.9472763292981\n",
      "    val_log_marginal: 868.1432941132232\n",
      "Train Epoch: 548 [512/17352 (3%)] Loss: -863.589600\n",
      "Train Epoch: 548 [9884/17352 (57%)] Loss: -922.431875\n",
      "Train Epoch: 548 [16957/17352 (98%)] Loss: -868.371726\n",
      "    epoch          : 548\n",
      "    loss           : -849.6836629144331\n",
      "    val_loss       : -846.5660495187444\n",
      "    val_log_likelihood: 1224.0177205088385\n",
      "    val_log_marginal: 867.2302576202189\n",
      "Train Epoch: 549 [512/17352 (3%)] Loss: -818.692078\n",
      "Train Epoch: 549 [10031/17352 (58%)] Loss: -849.569444\n",
      "Train Epoch: 549 [17049/17352 (98%)] Loss: -759.180361\n",
      "    epoch          : 549\n",
      "    loss           : -835.6096682857752\n",
      "    val_loss       : -850.6059618482337\n",
      "    val_log_likelihood: 1227.0067145183887\n",
      "    val_log_marginal: 862.8500407552375\n",
      "Train Epoch: 550 [512/17352 (3%)] Loss: -897.002625\n",
      "Train Epoch: 550 [10273/17352 (59%)] Loss: -824.226305\n",
      "Train Epoch: 550 [16992/17352 (98%)] Loss: -945.239082\n",
      "    epoch          : 550\n",
      "    loss           : -849.4523708120886\n",
      "    val_loss       : -858.2387639167653\n",
      "    val_log_likelihood: 1237.9412368888202\n",
      "    val_log_marginal: 882.2788963326788\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch550.pth ...\n",
      "Train Epoch: 551 [512/17352 (3%)] Loss: -915.100037\n",
      "Train Epoch: 551 [10494/17352 (60%)] Loss: -936.657878\n",
      "Train Epoch: 551 [17124/17352 (99%)] Loss: -937.300633\n",
      "    epoch          : 551\n",
      "    loss           : -844.7279482763302\n",
      "    val_loss       : -847.9736520496688\n",
      "    val_log_likelihood: 1231.8280822434467\n",
      "    val_log_marginal: 867.7067554595229\n",
      "Train Epoch: 552 [512/17352 (3%)] Loss: -890.079529\n",
      "Train Epoch: 552 [10295/17352 (59%)] Loss: -894.665201\n",
      "Train Epoch: 552 [16887/17352 (97%)] Loss: -588.008672\n",
      "    epoch          : 552\n",
      "    loss           : -842.8867128185645\n",
      "    val_loss       : -762.3744125866255\n",
      "    val_log_likelihood: 1233.62281647926\n",
      "    val_log_marginal: 785.8439740491585\n",
      "Train Epoch: 553 [512/17352 (3%)] Loss: -628.244080\n",
      "Train Epoch: 553 [10206/17352 (59%)] Loss: -947.186567\n",
      "Train Epoch: 553 [17277/17352 (100%)] Loss: -751.203963\n",
      "    epoch          : 553\n",
      "    loss           : -851.1318600076262\n",
      "    val_loss       : -871.9213381508594\n",
      "    val_log_likelihood: 1241.8258701598777\n",
      "    val_log_marginal: 888.3842814852933\n",
      "Train Epoch: 554 [512/17352 (3%)] Loss: -900.084229\n",
      "Train Epoch: 554 [10064/17352 (58%)] Loss: -742.153775\n",
      "Train Epoch: 554 [17108/17352 (99%)] Loss: -938.611992\n",
      "    epoch          : 554\n",
      "    loss           : -840.470145255909\n",
      "    val_loss       : -709.5105528007562\n",
      "    val_log_likelihood: 1226.2102683740927\n",
      "    val_log_marginal: 728.8381761739229\n",
      "Train Epoch: 555 [512/17352 (3%)] Loss: -768.656250\n",
      "Train Epoch: 555 [10086/17352 (58%)] Loss: -695.971583\n",
      "Train Epoch: 555 [16934/17352 (98%)] Loss: -869.693629\n",
      "    epoch          : 555\n",
      "    loss           : -781.3804741868245\n",
      "    val_loss       : -739.9694269288497\n",
      "    val_log_likelihood: 1211.0598580641397\n",
      "    val_log_marginal: 757.808070299646\n",
      "Train Epoch: 556 [512/17352 (3%)] Loss: -749.892700\n",
      "Train Epoch: 556 [10477/17352 (60%)] Loss: -767.905035\n",
      "Train Epoch: 556 [17126/17352 (99%)] Loss: -819.755354\n",
      "    epoch          : 556\n",
      "    loss           : -798.1572299034297\n",
      "    val_loss       : -714.52406741752\n",
      "    val_log_likelihood: 1194.574968684814\n",
      "    val_log_marginal: 731.4762600456723\n",
      "Train Epoch: 557 [512/17352 (3%)] Loss: -774.284851\n",
      "Train Epoch: 557 [10575/17352 (61%)] Loss: -697.694639\n",
      "Train Epoch: 557 [17143/17352 (99%)] Loss: -827.329624\n",
      "    epoch          : 557\n",
      "    loss           : -825.1118465132002\n",
      "    val_loss       : -834.3319795859267\n",
      "    val_log_likelihood: 1224.3984187438475\n",
      "    val_log_marginal: 851.8468821308983\n",
      "Train Epoch: 558 [512/17352 (3%)] Loss: -875.793640\n",
      "Train Epoch: 558 [10646/17352 (61%)] Loss: -765.131119\n",
      "Train Epoch: 558 [16882/17352 (97%)] Loss: -805.997024\n",
      "    epoch          : 558\n",
      "    loss           : -857.145744927858\n",
      "    val_loss       : -873.9179035926351\n",
      "    val_log_likelihood: 1245.2638096935123\n",
      "    val_log_marginal: 886.5459948818066\n",
      "Train Epoch: 559 [512/17352 (3%)] Loss: -910.868408\n",
      "Train Epoch: 559 [9578/17352 (55%)] Loss: -770.315257\n",
      "Train Epoch: 559 [17277/17352 (100%)] Loss: -786.952753\n",
      "    epoch          : 559\n",
      "    loss           : -834.3098984227634\n",
      "    val_loss       : -742.9074155406645\n",
      "    val_log_likelihood: 1158.6877158138188\n",
      "    val_log_marginal: 778.5763896000684\n",
      "Train Epoch: 560 [512/17352 (3%)] Loss: -756.399353\n",
      "Train Epoch: 560 [10006/17352 (58%)] Loss: -762.276195\n",
      "Train Epoch: 560 [16923/17352 (98%)] Loss: -678.450726\n",
      "    epoch          : 560\n",
      "    loss           : -812.6771618513117\n",
      "    val_loss       : -762.2649766142647\n",
      "    val_log_likelihood: 1190.018817762175\n",
      "    val_log_marginal: 813.3314690453901\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch560.pth ...\n",
      "Train Epoch: 561 [512/17352 (3%)] Loss: -744.672485\n",
      "Train Epoch: 561 [10402/17352 (60%)] Loss: -832.761273\n",
      "Train Epoch: 561 [17143/17352 (99%)] Loss: -878.483212\n",
      "    epoch          : 561\n",
      "    loss           : -765.3927184207861\n",
      "    val_loss       : -778.8201088495915\n",
      "    val_log_likelihood: 1166.418306715068\n",
      "    val_log_marginal: 801.9925766495929\n",
      "Train Epoch: 562 [512/17352 (3%)] Loss: -601.886475\n",
      "Train Epoch: 562 [10624/17352 (61%)] Loss: -892.993857\n",
      "Train Epoch: 562 [17106/17352 (99%)] Loss: -760.689825\n",
      "    epoch          : 562\n",
      "    loss           : -823.8618549680497\n",
      "    val_loss       : -843.1530855014931\n",
      "    val_log_likelihood: 1218.0161762821863\n",
      "    val_log_marginal: 863.7584899307844\n",
      "Train Epoch: 563 [512/17352 (3%)] Loss: -885.344849\n",
      "Train Epoch: 563 [10662/17352 (61%)] Loss: -839.355312\n",
      "Train Epoch: 563 [17016/17352 (98%)] Loss: -798.807155\n",
      "    epoch          : 563\n",
      "    loss           : -810.2709513726836\n",
      "    val_loss       : -858.6042727643119\n",
      "    val_log_likelihood: 1226.9237492010982\n",
      "    val_log_marginal: 875.6298366617301\n",
      "Train Epoch: 564 [512/17352 (3%)] Loss: -915.708984\n",
      "Train Epoch: 564 [10614/17352 (61%)] Loss: -723.466315\n",
      "Train Epoch: 564 [16958/17352 (98%)] Loss: -847.193187\n",
      "    epoch          : 564\n",
      "    loss           : -843.8566487184751\n",
      "    val_loss       : -858.2057768129722\n",
      "    val_log_likelihood: 1233.681910272545\n",
      "    val_log_marginal: 873.1205661732189\n",
      "Train Epoch: 565 [512/17352 (3%)] Loss: -904.670349\n",
      "Train Epoch: 565 [10500/17352 (61%)] Loss: -787.529668\n",
      "Train Epoch: 565 [17064/17352 (98%)] Loss: -675.205239\n",
      "    epoch          : 565\n",
      "    loss           : -843.2381360869679\n",
      "    val_loss       : -840.8857947766829\n",
      "    val_log_likelihood: 1232.2850449695898\n",
      "    val_log_marginal: 861.9392220285424\n",
      "Train Epoch: 566 [512/17352 (3%)] Loss: -885.461487\n",
      "Train Epoch: 566 [10421/17352 (60%)] Loss: -753.493346\n",
      "Train Epoch: 566 [16958/17352 (98%)] Loss: -774.969041\n",
      "    epoch          : 566\n",
      "    loss           : -861.4214827574458\n",
      "    val_loss       : -875.1838541097234\n",
      "    val_log_likelihood: 1246.3383370309293\n",
      "    val_log_marginal: 888.0672785946552\n",
      "Train Epoch: 567 [512/17352 (3%)] Loss: -912.875916\n",
      "Train Epoch: 567 [10791/17352 (62%)] Loss: -969.019937\n",
      "Train Epoch: 567 [16887/17352 (97%)] Loss: -730.952821\n",
      "    epoch          : 567\n",
      "    loss           : -865.8816594579115\n",
      "    val_loss       : -870.817732050894\n",
      "    val_log_likelihood: 1252.4946147341889\n",
      "    val_log_marginal: 885.7755713923849\n",
      "Train Epoch: 568 [512/17352 (3%)] Loss: -910.998596\n",
      "Train Epoch: 568 [10318/17352 (59%)] Loss: -958.040333\n",
      "Train Epoch: 568 [17253/17352 (99%)] Loss: -764.069271\n",
      "    epoch          : 568\n",
      "    loss           : -869.051449872221\n",
      "    val_loss       : -827.9614055736549\n",
      "    val_log_likelihood: 1232.1830858040344\n",
      "    val_log_marginal: 852.9171493929206\n",
      "Train Epoch: 569 [512/17352 (3%)] Loss: -879.547424\n",
      "Train Epoch: 569 [10106/17352 (58%)] Loss: -1013.328451\n",
      "Train Epoch: 569 [17124/17352 (99%)] Loss: -966.951759\n",
      "    epoch          : 569\n",
      "    loss           : -851.6712619086502\n",
      "    val_loss       : -860.3304177690067\n",
      "    val_log_likelihood: 1245.3583638438392\n",
      "    val_log_marginal: 881.0316045458478\n",
      "Train Epoch: 570 [512/17352 (3%)] Loss: -874.016296\n",
      "Train Epoch: 570 [10687/17352 (62%)] Loss: -910.607487\n",
      "Train Epoch: 570 [17277/17352 (100%)] Loss: -910.504318\n",
      "    epoch          : 570\n",
      "    loss           : -875.0278125722083\n",
      "    val_loss       : -871.9095013827011\n",
      "    val_log_likelihood: 1250.041147573252\n",
      "    val_log_marginal: 883.5003193358629\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch570.pth ...\n",
      "Train Epoch: 571 [512/17352 (3%)] Loss: -908.755615\n",
      "Train Epoch: 571 [10516/17352 (61%)] Loss: -766.774959\n",
      "Train Epoch: 571 [16887/17352 (97%)] Loss: -760.976219\n",
      "    epoch          : 571\n",
      "    loss           : -851.9995670505547\n",
      "    val_loss       : -860.6866400465261\n",
      "    val_log_likelihood: 1248.124090594123\n",
      "    val_log_marginal: 882.2966713009104\n",
      "Train Epoch: 572 [512/17352 (3%)] Loss: -915.885132\n",
      "Train Epoch: 572 [10458/17352 (60%)] Loss: -824.262460\n",
      "Train Epoch: 572 [17253/17352 (99%)] Loss: -847.257900\n",
      "    epoch          : 572\n",
      "    loss           : -840.7948764969584\n",
      "    val_loss       : -767.4154310259154\n",
      "    val_log_likelihood: 1181.3892435025175\n",
      "    val_log_marginal: 782.3303160611447\n",
      "Train Epoch: 573 [512/17352 (3%)] Loss: -816.182129\n",
      "Train Epoch: 573 [10240/17352 (59%)] Loss: -907.285950\n",
      "Train Epoch: 573 [16934/17352 (98%)] Loss: -606.638911\n",
      "    epoch          : 573\n",
      "    loss           : -837.5900093670073\n",
      "    val_loss       : -871.8566145955366\n",
      "    val_log_likelihood: 1239.7689267825826\n",
      "    val_log_marginal: 887.9603480350384\n",
      "Train Epoch: 574 [512/17352 (3%)] Loss: -894.202271\n",
      "Train Epoch: 574 [10033/17352 (58%)] Loss: -870.940814\n",
      "Train Epoch: 574 [16872/17352 (97%)] Loss: -949.242804\n",
      "    epoch          : 574\n",
      "    loss           : -862.326207032776\n",
      "    val_loss       : -867.136097219079\n",
      "    val_log_likelihood: 1241.3679206189126\n",
      "    val_log_marginal: 882.6134324669532\n",
      "Train Epoch: 575 [512/17352 (3%)] Loss: -906.969177\n",
      "Train Epoch: 575 [9755/17352 (56%)] Loss: -859.932100\n",
      "Train Epoch: 575 [17124/17352 (99%)] Loss: -867.883843\n",
      "    epoch          : 575\n",
      "    loss           : -852.9913242409316\n",
      "    val_loss       : -836.6397455763056\n",
      "    val_log_likelihood: 1219.8459846733415\n",
      "    val_log_marginal: 857.9300313541701\n",
      "Train Epoch: 576 [512/17352 (3%)] Loss: -888.093872\n",
      "Train Epoch: 576 [10156/17352 (59%)] Loss: -772.495231\n",
      "Train Epoch: 576 [17253/17352 (99%)] Loss: -973.063834\n",
      "    epoch          : 576\n",
      "    loss           : -857.5760406609244\n",
      "    val_loss       : -863.7861388972353\n",
      "    val_log_likelihood: 1251.2927230706812\n",
      "    val_log_marginal: 886.8959021277192\n",
      "Train Epoch: 577 [512/17352 (3%)] Loss: -907.385986\n",
      "Train Epoch: 577 [10219/17352 (59%)] Loss: -828.666337\n",
      "Train Epoch: 577 [17124/17352 (99%)] Loss: -935.332918\n",
      "    epoch          : 577\n",
      "    loss           : -873.6527120444541\n",
      "    val_loss       : -882.9707987306246\n",
      "    val_log_likelihood: 1255.2442885510497\n",
      "    val_log_marginal: 900.8512038021081\n",
      "Train Epoch: 578 [512/17352 (3%)] Loss: -917.661987\n",
      "Train Epoch: 578 [10122/17352 (58%)] Loss: -857.705181\n",
      "Train Epoch: 578 [16872/17352 (97%)] Loss: -716.278427\n",
      "    epoch          : 578\n",
      "    loss           : -868.9318507558321\n",
      "    val_loss       : -886.8411335773187\n",
      "    val_log_likelihood: 1260.217970299435\n",
      "    val_log_marginal: 902.725345394224\n",
      "Train Epoch: 579 [512/17352 (3%)] Loss: -918.535645\n",
      "Train Epoch: 579 [10614/17352 (61%)] Loss: -1000.710578\n",
      "Train Epoch: 579 [16872/17352 (97%)] Loss: -880.302026\n",
      "    epoch          : 579\n",
      "    loss           : -888.1448240360984\n",
      "    val_loss       : -892.0937225791515\n",
      "    val_log_likelihood: 1267.9423845768301\n",
      "    val_log_marginal: 905.188754724781\n",
      "Train Epoch: 580 [512/17352 (3%)] Loss: -891.539551\n",
      "Train Epoch: 580 [10596/17352 (61%)] Loss: -899.216536\n",
      "Train Epoch: 580 [17126/17352 (99%)] Loss: -721.788170\n",
      "    epoch          : 580\n",
      "    loss           : -867.7885895038668\n",
      "    val_loss       : -870.0906694290389\n",
      "    val_log_likelihood: 1257.7579833997952\n",
      "    val_log_marginal: 885.232485779505\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch580.pth ...\n",
      "Train Epoch: 581 [512/17352 (3%)] Loss: -909.993835\n",
      "Train Epoch: 581 [10072/17352 (58%)] Loss: -953.669583\n",
      "Train Epoch: 581 [16958/17352 (98%)] Loss: -952.904080\n",
      "    epoch          : 581\n",
      "    loss           : -860.559300254957\n",
      "    val_loss       : -863.4363152104278\n",
      "    val_log_likelihood: 1248.095603305284\n",
      "    val_log_marginal: 880.0894159323595\n",
      "Train Epoch: 582 [512/17352 (3%)] Loss: -887.040283\n",
      "Train Epoch: 582 [10627/17352 (61%)] Loss: -854.055804\n",
      "Train Epoch: 582 [17143/17352 (99%)] Loss: -619.064612\n",
      "    epoch          : 582\n",
      "    loss           : -862.6380799997103\n",
      "    val_loss       : -717.0775778233466\n",
      "    val_log_likelihood: 1249.197254054666\n",
      "    val_log_marginal: 728.9796584097878\n",
      "Train Epoch: 583 [512/17352 (3%)] Loss: -765.753845\n",
      "Train Epoch: 583 [10076/17352 (58%)] Loss: -974.946964\n",
      "Train Epoch: 583 [16878/17352 (97%)] Loss: -929.472081\n",
      "    epoch          : 583\n",
      "    loss           : -808.1337375722369\n",
      "    val_loss       : -820.7770340869165\n",
      "    val_log_likelihood: 1226.145210553108\n",
      "    val_log_marginal: 862.9037092599908\n",
      "Train Epoch: 584 [512/17352 (3%)] Loss: -902.987488\n",
      "Train Epoch: 584 [10028/17352 (58%)] Loss: -790.163316\n",
      "Train Epoch: 584 [17108/17352 (99%)] Loss: -894.850521\n",
      "    epoch          : 584\n",
      "    loss           : -833.2043114143663\n",
      "    val_loss       : -842.4748648875127\n",
      "    val_log_likelihood: 1247.2848529644052\n",
      "    val_log_marginal: 869.8923403488442\n",
      "Train Epoch: 585 [512/17352 (3%)] Loss: -674.297791\n",
      "Train Epoch: 585 [11099/17352 (64%)] Loss: -958.965359\n",
      "Train Epoch: 585 [16887/17352 (97%)] Loss: -755.558333\n",
      "    epoch          : 585\n",
      "    loss           : -861.5561027367477\n",
      "    val_loss       : -878.2634975202118\n",
      "    val_log_likelihood: 1259.7136052443534\n",
      "    val_log_marginal: 896.8401060622285\n",
      "Train Epoch: 586 [512/17352 (3%)] Loss: -926.570068\n",
      "Train Epoch: 586 [9679/17352 (56%)] Loss: -809.856301\n",
      "Train Epoch: 586 [16939/17352 (98%)] Loss: -904.428852\n",
      "    epoch          : 586\n",
      "    loss           : -875.4681256622767\n",
      "    val_loss       : -881.1969162268341\n",
      "    val_log_likelihood: 1259.197180999561\n",
      "    val_log_marginal: 896.8540013807185\n",
      "Train Epoch: 587 [512/17352 (3%)] Loss: -890.321167\n",
      "Train Epoch: 587 [10078/17352 (58%)] Loss: -709.049328\n",
      "Train Epoch: 587 [16934/17352 (98%)] Loss: -963.181882\n",
      "    epoch          : 587\n",
      "    loss           : -880.7288176934417\n",
      "    val_loss       : -888.7820515336024\n",
      "    val_log_likelihood: 1266.226322836311\n",
      "    val_log_marginal: 904.98031036428\n",
      "Train Epoch: 588 [512/17352 (3%)] Loss: -924.991943\n",
      "Train Epoch: 588 [10071/17352 (58%)] Loss: -858.994256\n",
      "Train Epoch: 588 [16872/17352 (97%)] Loss: -997.832063\n",
      "    epoch          : 588\n",
      "    loss           : -889.5502554644683\n",
      "    val_loss       : -902.9197828256918\n",
      "    val_log_likelihood: 1276.4305192863844\n",
      "    val_log_marginal: 916.2258312002431\n",
      "Train Epoch: 589 [512/17352 (3%)] Loss: -940.594788\n",
      "Train Epoch: 589 [9940/17352 (57%)] Loss: -771.778257\n",
      "Train Epoch: 589 [16992/17352 (98%)] Loss: -989.293699\n",
      "    epoch          : 589\n",
      "    loss           : -881.6859400614645\n",
      "    val_loss       : -888.7541542826152\n",
      "    val_log_likelihood: 1261.21791231329\n",
      "    val_log_marginal: 902.7509880784339\n",
      "Train Epoch: 590 [512/17352 (3%)] Loss: -937.693848\n",
      "Train Epoch: 590 [10407/17352 (60%)] Loss: -976.049334\n",
      "Train Epoch: 590 [17263/17352 (99%)] Loss: -887.365663\n",
      "    epoch          : 590\n",
      "    loss           : -838.3222256880873\n",
      "    val_loss       : -612.5254087176628\n",
      "    val_log_likelihood: 1248.699891022351\n",
      "    val_log_marginal: 630.4872730973383\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch590.pth ...\n",
      "Train Epoch: 591 [512/17352 (3%)] Loss: -668.195679\n",
      "Train Epoch: 591 [10305/17352 (59%)] Loss: -925.653437\n",
      "Train Epoch: 591 [17133/17352 (99%)] Loss: -810.419598\n",
      "    epoch          : 591\n",
      "    loss           : -745.4108695372762\n",
      "    val_loss       : -552.7538847835789\n",
      "    val_log_likelihood: 1236.3735482744194\n",
      "    val_log_marginal: 575.8841498771598\n",
      "Train Epoch: 592 [512/17352 (3%)] Loss: -537.794067\n",
      "Train Epoch: 592 [10374/17352 (60%)] Loss: -605.358958\n",
      "Train Epoch: 592 [17263/17352 (99%)] Loss: -593.624239\n",
      "    epoch          : 592\n",
      "    loss           : -466.40435976870214\n",
      "    val_loss       : -458.3320337093035\n",
      "    val_log_likelihood: 1129.7287464371132\n",
      "    val_log_marginal: 493.65089248566665\n",
      "Train Epoch: 593 [512/17352 (3%)] Loss: -491.558167\n",
      "Train Epoch: 593 [10183/17352 (59%)] Loss: -789.520000\n",
      "Train Epoch: 593 [16958/17352 (98%)] Loss: -815.580469\n",
      "    epoch          : 593\n",
      "    loss           : -715.9280806231596\n",
      "    val_loss       : -783.5360347755926\n",
      "    val_log_likelihood: 1207.5735080431602\n",
      "    val_log_marginal: 810.9892824587732\n",
      "Train Epoch: 594 [512/17352 (3%)] Loss: -824.113770\n",
      "Train Epoch: 594 [10421/17352 (60%)] Loss: -882.598485\n",
      "Train Epoch: 594 [17277/17352 (100%)] Loss: -915.275398\n",
      "    epoch          : 594\n",
      "    loss           : -815.9325389549728\n",
      "    val_loss       : -847.2191529565563\n",
      "    val_log_likelihood: 1227.4261048446826\n",
      "    val_log_marginal: 864.1120061180222\n",
      "Train Epoch: 595 [512/17352 (3%)] Loss: -895.103760\n",
      "Train Epoch: 595 [9979/17352 (58%)] Loss: -887.095634\n",
      "Train Epoch: 595 [17124/17352 (99%)] Loss: -871.895278\n",
      "    epoch          : 595\n",
      "    loss           : -856.3204379862323\n",
      "    val_loss       : -802.6275379257601\n",
      "    val_log_likelihood: 1238.24518035012\n",
      "    val_log_marginal: 826.4779617006028\n",
      "Train Epoch: 596 [512/17352 (3%)] Loss: -818.023132\n",
      "Train Epoch: 596 [10506/17352 (61%)] Loss: -860.675781\n",
      "Train Epoch: 596 [17101/17352 (99%)] Loss: -644.260649\n",
      "    epoch          : 596\n",
      "    loss           : -762.9499267544625\n",
      "    val_loss       : -729.5575409317788\n",
      "    val_log_likelihood: 1179.0924238378946\n",
      "    val_log_marginal: 793.6638125307845\n",
      "Train Epoch: 597 [512/17352 (3%)] Loss: -742.055542\n",
      "Train Epoch: 597 [9826/17352 (57%)] Loss: -773.263955\n",
      "Train Epoch: 597 [17049/17352 (98%)] Loss: -958.090820\n",
      "    epoch          : 597\n",
      "    loss           : -785.7525663402073\n",
      "    val_loss       : -822.1753113063912\n",
      "    val_log_likelihood: 1197.8933371309092\n",
      "    val_log_marginal: 850.7027831466953\n",
      "Train Epoch: 598 [512/17352 (3%)] Loss: -864.439453\n",
      "Train Epoch: 598 [10268/17352 (59%)] Loss: -805.289844\n",
      "Train Epoch: 598 [17044/17352 (98%)] Loss: -940.146044\n",
      "    epoch          : 598\n",
      "    loss           : -854.5775611670914\n",
      "    val_loss       : -873.3834432014227\n",
      "    val_log_likelihood: 1245.426226915661\n",
      "    val_log_marginal: 891.5492755682236\n",
      "Train Epoch: 599 [512/17352 (3%)] Loss: -923.746582\n",
      "Train Epoch: 599 [10611/17352 (61%)] Loss: -962.006323\n",
      "Train Epoch: 599 [17263/17352 (99%)] Loss: -983.039646\n",
      "    epoch          : 599\n",
      "    loss           : -888.3503707931203\n",
      "    val_loss       : -890.0265695897939\n",
      "    val_log_likelihood: 1255.0986314276447\n",
      "    val_log_marginal: 908.4499171756329\n",
      "Train Epoch: 600 [512/17352 (3%)] Loss: -934.886902\n",
      "Train Epoch: 600 [10205/17352 (59%)] Loss: -950.367006\n",
      "Train Epoch: 600 [17153/17352 (99%)] Loss: -1011.564921\n",
      "    epoch          : 600\n",
      "    loss           : -895.9774695081171\n",
      "    val_loss       : -895.1658327274987\n",
      "    val_log_likelihood: 1272.8691648595168\n",
      "    val_log_marginal: 908.9439284812111\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch600.pth ...\n",
      "Train Epoch: 601 [512/17352 (3%)] Loss: -741.836060\n",
      "Train Epoch: 601 [10586/17352 (61%)] Loss: -946.942383\n",
      "Train Epoch: 601 [16957/17352 (98%)] Loss: -1010.306522\n",
      "    epoch          : 601\n",
      "    loss           : -897.9870264829815\n",
      "    val_loss       : -904.2653210463441\n",
      "    val_log_likelihood: 1276.8420241408787\n",
      "    val_log_marginal: 920.3563877714339\n",
      "Train Epoch: 602 [512/17352 (3%)] Loss: -941.944946\n",
      "Train Epoch: 602 [10489/17352 (60%)] Loss: -954.503750\n",
      "Train Epoch: 602 [16958/17352 (98%)] Loss: -922.749843\n",
      "    epoch          : 602\n",
      "    loss           : -897.3311177915913\n",
      "    val_loss       : -897.1133042105151\n",
      "    val_log_likelihood: 1269.7848780158265\n",
      "    val_log_marginal: 910.5596869084322\n",
      "Train Epoch: 603 [512/17352 (3%)] Loss: -936.014526\n",
      "Train Epoch: 603 [10420/17352 (60%)] Loss: -898.683594\n",
      "Train Epoch: 603 [17090/17352 (98%)] Loss: -964.373730\n",
      "    epoch          : 603\n",
      "    loss           : -884.307229051257\n",
      "    val_loss       : -875.1091969272031\n",
      "    val_log_likelihood: 1273.4743368727102\n",
      "    val_log_marginal: 889.558883998619\n",
      "Train Epoch: 604 [512/17352 (3%)] Loss: -885.816040\n",
      "Train Epoch: 604 [10930/17352 (63%)] Loss: -832.763054\n",
      "Train Epoch: 604 [16934/17352 (98%)] Loss: -516.651887\n",
      "    epoch          : 604\n",
      "    loss           : -833.6331663702654\n",
      "    val_loss       : -764.6321065047176\n",
      "    val_log_likelihood: 1257.17260560256\n",
      "    val_log_marginal: 778.7252070071725\n",
      "Train Epoch: 605 [512/17352 (3%)] Loss: -791.499023\n",
      "Train Epoch: 605 [10738/17352 (62%)] Loss: -727.926238\n",
      "Train Epoch: 605 [17126/17352 (99%)] Loss: -652.360123\n",
      "    epoch          : 605\n",
      "    loss           : -803.4055327915461\n",
      "    val_loss       : -853.7668690555155\n",
      "    val_log_likelihood: 1245.7074119672468\n",
      "    val_log_marginal: 869.0099438512606\n",
      "Train Epoch: 606 [512/17352 (3%)] Loss: -902.616394\n",
      "Train Epoch: 606 [10598/17352 (61%)] Loss: -894.735221\n",
      "Train Epoch: 606 [17133/17352 (99%)] Loss: -813.700508\n",
      "    epoch          : 606\n",
      "    loss           : -864.6323984195305\n",
      "    val_loss       : -877.197606275104\n",
      "    val_log_likelihood: 1261.835440642446\n",
      "    val_log_marginal: 893.6335133656539\n",
      "Train Epoch: 607 [512/17352 (3%)] Loss: -918.116638\n",
      "Train Epoch: 607 [10612/17352 (61%)] Loss: -924.256421\n",
      "Train Epoch: 607 [17153/17352 (99%)] Loss: -741.262336\n",
      "    epoch          : 607\n",
      "    loss           : -890.6039863895134\n",
      "    val_loss       : -876.3059401629987\n",
      "    val_log_likelihood: 1257.182328139415\n",
      "    val_log_marginal: 889.3653134912622\n",
      "Train Epoch: 608 [512/17352 (3%)] Loss: -909.937256\n",
      "Train Epoch: 608 [10238/17352 (59%)] Loss: -885.504894\n",
      "Train Epoch: 608 [17090/17352 (98%)] Loss: -833.560061\n",
      "    epoch          : 608\n",
      "    loss           : -898.3572761075196\n",
      "    val_loss       : -890.7720636008729\n",
      "    val_log_likelihood: 1279.021174016752\n",
      "    val_log_marginal: 902.3110687821957\n",
      "Train Epoch: 609 [512/17352 (3%)] Loss: -742.050903\n",
      "Train Epoch: 609 [10485/17352 (60%)] Loss: -748.872513\n",
      "Train Epoch: 609 [16872/17352 (97%)] Loss: -973.966042\n",
      "    epoch          : 609\n",
      "    loss           : -896.7697164511851\n",
      "    val_loss       : -906.5694764030891\n",
      "    val_log_likelihood: 1281.6238758159143\n",
      "    val_log_marginal: 923.3092153014036\n",
      "Train Epoch: 610 [512/17352 (3%)] Loss: -960.081055\n",
      "Train Epoch: 610 [10075/17352 (58%)] Loss: -979.111754\n",
      "Train Epoch: 610 [17064/17352 (98%)] Loss: -939.126743\n",
      "    epoch          : 610\n",
      "    loss           : -902.5347289745899\n",
      "    val_loss       : -910.9093392884602\n",
      "    val_log_likelihood: 1285.8437017949734\n",
      "    val_log_marginal: 923.5543442131308\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch610.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 611 [512/17352 (3%)] Loss: -954.022705\n",
      "Train Epoch: 611 [10683/17352 (62%)] Loss: -835.851765\n",
      "Train Epoch: 611 [16988/17352 (98%)] Loss: -792.455308\n",
      "    epoch          : 611\n",
      "    loss           : -895.7678400891382\n",
      "    val_loss       : -886.5962164413568\n",
      "    val_log_likelihood: 1270.8322912108579\n",
      "    val_log_marginal: 898.1928217084285\n",
      "Train Epoch: 612 [512/17352 (3%)] Loss: -928.881897\n",
      "Train Epoch: 612 [10119/17352 (58%)] Loss: -876.048295\n",
      "Train Epoch: 612 [16923/17352 (98%)] Loss: -985.759792\n",
      "    epoch          : 612\n",
      "    loss           : -892.373834010596\n",
      "    val_loss       : -900.4581115401816\n",
      "    val_log_likelihood: 1279.9039049572355\n",
      "    val_log_marginal: 917.3098922932722\n",
      "Train Epoch: 613 [512/17352 (3%)] Loss: -931.770142\n",
      "Train Epoch: 613 [10764/17352 (62%)] Loss: -949.526480\n",
      "Train Epoch: 613 [16922/17352 (98%)] Loss: -935.812064\n",
      "    epoch          : 613\n",
      "    loss           : -886.7990953160862\n",
      "    val_loss       : -886.4857609620465\n",
      "    val_log_likelihood: 1269.8659927387976\n",
      "    val_log_marginal: 903.8780879232888\n",
      "Train Epoch: 614 [512/17352 (3%)] Loss: -962.945679\n",
      "Train Epoch: 614 [9889/17352 (57%)] Loss: -785.485347\n",
      "Train Epoch: 614 [17106/17352 (99%)] Loss: -839.341406\n",
      "    epoch          : 614\n",
      "    loss           : -860.7655334203814\n",
      "    val_loss       : -780.3559923872004\n",
      "    val_log_likelihood: 1269.3109987015978\n",
      "    val_log_marginal: 805.1581523633897\n",
      "Train Epoch: 615 [512/17352 (3%)] Loss: -838.857544\n",
      "Train Epoch: 615 [10559/17352 (61%)] Loss: -975.240668\n",
      "Train Epoch: 615 [17108/17352 (99%)] Loss: -956.212881\n",
      "    epoch          : 615\n",
      "    loss           : -853.3239358964977\n",
      "    val_loss       : -650.9994358054237\n",
      "    val_log_likelihood: 1249.2618995985179\n",
      "    val_log_marginal: 663.4120950525786\n",
      "Train Epoch: 616 [512/17352 (3%)] Loss: -646.512512\n",
      "Train Epoch: 616 [10221/17352 (59%)] Loss: -555.070491\n",
      "Train Epoch: 616 [17016/17352 (98%)] Loss: -641.351562\n",
      "    epoch          : 616\n",
      "    loss           : -580.2197458160122\n",
      "    val_loss       : -644.1673012147094\n",
      "    val_log_likelihood: 1156.5742550390912\n",
      "    val_log_marginal: 691.4695626249442\n",
      "Train Epoch: 617 [512/17352 (3%)] Loss: -726.294983\n",
      "Train Epoch: 617 [9938/17352 (57%)] Loss: -498.214203\n",
      "Train Epoch: 617 [16957/17352 (98%)] Loss: -892.379688\n",
      "    epoch          : 617\n",
      "    loss           : -675.2661881442483\n",
      "    val_loss       : -745.1749657265449\n",
      "    val_log_likelihood: 1151.7429192657694\n",
      "    val_log_marginal: 777.0829887706496\n",
      "Train Epoch: 618 [512/17352 (3%)] Loss: -825.791382\n",
      "Train Epoch: 618 [10603/17352 (61%)] Loss: -656.574836\n",
      "Train Epoch: 618 [17124/17352 (99%)] Loss: -846.724339\n",
      "    epoch          : 618\n",
      "    loss           : -731.7690965006623\n",
      "    val_loss       : -774.4620328139529\n",
      "    val_log_likelihood: 1184.2031486551468\n",
      "    val_log_marginal: 820.6688239379129\n",
      "Train Epoch: 619 [512/17352 (3%)] Loss: -854.001038\n",
      "Train Epoch: 619 [10521/17352 (61%)] Loss: -837.599419\n",
      "Train Epoch: 619 [17090/17352 (98%)] Loss: -979.984262\n",
      "    epoch          : 619\n",
      "    loss           : -838.0091617791833\n",
      "    val_loss       : -870.0246644261977\n",
      "    val_log_likelihood: 1246.1816136442167\n",
      "    val_log_marginal: 892.4053231469057\n",
      "Train Epoch: 620 [512/17352 (3%)] Loss: -919.898560\n",
      "Train Epoch: 620 [10685/17352 (62%)] Loss: -825.678106\n",
      "Train Epoch: 620 [17101/17352 (99%)] Loss: -902.711840\n",
      "    epoch          : 620\n",
      "    loss           : -873.7882563408799\n",
      "    val_loss       : -889.854649437526\n",
      "    val_log_likelihood: 1264.6251234864353\n",
      "    val_log_marginal: 910.011775940548\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch620.pth ...\n",
      "Train Epoch: 621 [512/17352 (3%)] Loss: -921.182983\n",
      "Train Epoch: 621 [10319/17352 (59%)] Loss: -784.772436\n",
      "Train Epoch: 621 [17016/17352 (98%)] Loss: -832.346560\n",
      "    epoch          : 621\n",
      "    loss           : -884.1679183844236\n",
      "    val_loss       : -886.4676333368718\n",
      "    val_log_likelihood: 1273.0683262564794\n",
      "    val_log_marginal: 911.2189169816025\n",
      "Train Epoch: 622 [512/17352 (3%)] Loss: -942.997437\n",
      "Train Epoch: 622 [9931/17352 (57%)] Loss: -696.679973\n",
      "Train Epoch: 622 [16992/17352 (98%)] Loss: -853.753687\n",
      "    epoch          : 622\n",
      "    loss           : -843.691586170072\n",
      "    val_loss       : -738.8576483943402\n",
      "    val_log_likelihood: 1248.2335544278444\n",
      "    val_log_marginal: 745.7734885920053\n",
      "Train Epoch: 623 [512/17352 (3%)] Loss: -756.894409\n",
      "Train Epoch: 623 [10267/17352 (59%)] Loss: -657.380040\n",
      "Train Epoch: 623 [16988/17352 (98%)] Loss: -611.510696\n",
      "    epoch          : 623\n",
      "    loss           : -825.9348930211738\n",
      "    val_loss       : -847.6569141836743\n",
      "    val_log_likelihood: 1259.784182932787\n",
      "    val_log_marginal: 860.1141445881561\n",
      "Train Epoch: 624 [512/17352 (3%)] Loss: -888.689819\n",
      "Train Epoch: 624 [10494/17352 (60%)] Loss: -794.359309\n",
      "Train Epoch: 624 [17090/17352 (98%)] Loss: -749.728220\n",
      "    epoch          : 624\n",
      "    loss           : -861.6207055126825\n",
      "    val_loss       : -873.6712540050488\n",
      "    val_log_likelihood: 1268.847146482705\n",
      "    val_log_marginal: 891.0178908724795\n",
      "Train Epoch: 625 [512/17352 (3%)] Loss: -724.240356\n",
      "Train Epoch: 625 [10821/17352 (62%)] Loss: -1010.421049\n",
      "Train Epoch: 625 [17133/17352 (99%)] Loss: -846.083640\n",
      "    epoch          : 625\n",
      "    loss           : -886.1800443679624\n",
      "    val_loss       : -890.7137232881779\n",
      "    val_log_likelihood: 1265.6605069608524\n",
      "    val_log_marginal: 906.6406012029257\n",
      "Train Epoch: 626 [512/17352 (3%)] Loss: -928.776611\n",
      "Train Epoch: 626 [9985/17352 (58%)] Loss: -938.223841\n",
      "Train Epoch: 626 [17124/17352 (99%)] Loss: -791.402389\n",
      "    epoch          : 626\n",
      "    loss           : -882.986542147513\n",
      "    val_loss       : -894.485566306521\n",
      "    val_log_likelihood: 1277.9149667679171\n",
      "    val_log_marginal: 908.09881730362\n",
      "Train Epoch: 627 [512/17352 (3%)] Loss: -936.254639\n",
      "Train Epoch: 627 [10292/17352 (59%)] Loss: -880.632950\n",
      "Train Epoch: 627 [16988/17352 (98%)] Loss: -1001.886955\n",
      "    epoch          : 627\n",
      "    loss           : -894.2369134961024\n",
      "    val_loss       : -906.5344329301491\n",
      "    val_log_likelihood: 1286.7740962961095\n",
      "    val_log_marginal: 921.5544927549587\n",
      "Train Epoch: 628 [512/17352 (3%)] Loss: -921.806702\n",
      "Train Epoch: 628 [10209/17352 (59%)] Loss: -980.815226\n",
      "Train Epoch: 628 [16923/17352 (98%)] Loss: -957.908616\n",
      "    epoch          : 628\n",
      "    loss           : -891.0637558738863\n",
      "    val_loss       : -912.6275496963425\n",
      "    val_log_likelihood: 1288.1551422354378\n",
      "    val_log_marginal: 926.6684450680223\n",
      "Train Epoch: 629 [512/17352 (3%)] Loss: -961.400269\n",
      "Train Epoch: 629 [10503/17352 (61%)] Loss: -1009.737170\n",
      "Train Epoch: 629 [16883/17352 (97%)] Loss: -756.095699\n",
      "    epoch          : 629\n",
      "    loss           : -909.0038107122365\n",
      "    val_loss       : -915.267831736948\n",
      "    val_log_likelihood: 1295.617330548889\n",
      "    val_log_marginal: 934.5501029073895\n",
      "Train Epoch: 630 [512/17352 (3%)] Loss: -944.815796\n",
      "Train Epoch: 630 [10150/17352 (58%)] Loss: -707.028965\n",
      "Train Epoch: 630 [17106/17352 (99%)] Loss: -1006.589029\n",
      "    epoch          : 630\n",
      "    loss           : -901.455023046903\n",
      "    val_loss       : -902.5948682043845\n",
      "    val_log_likelihood: 1286.4154322771813\n",
      "    val_log_marginal: 919.8436397774636\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch630.pth ...\n",
      "Train Epoch: 631 [512/17352 (3%)] Loss: -940.247742\n",
      "Train Epoch: 631 [10699/17352 (62%)] Loss: -974.220336\n",
      "Train Epoch: 631 [17124/17352 (99%)] Loss: -872.153665\n",
      "    epoch          : 631\n",
      "    loss           : -901.675393116244\n",
      "    val_loss       : -884.0729370105364\n",
      "    val_log_likelihood: 1271.1340203432974\n",
      "    val_log_marginal: 899.4083439185415\n",
      "Train Epoch: 632 [512/17352 (3%)] Loss: -940.864319\n",
      "Train Epoch: 632 [10619/17352 (61%)] Loss: -769.237030\n",
      "Train Epoch: 632 [17277/17352 (100%)] Loss: -1020.379010\n",
      "    epoch          : 632\n",
      "    loss           : -903.4468050757876\n",
      "    val_loss       : -902.1493519539883\n",
      "    val_log_likelihood: 1291.0458698468171\n",
      "    val_log_marginal: 914.4966279042776\n",
      "Train Epoch: 633 [512/17352 (3%)] Loss: -940.005737\n",
      "Train Epoch: 633 [10042/17352 (58%)] Loss: -924.358245\n",
      "Train Epoch: 633 [16883/17352 (97%)] Loss: -610.172312\n",
      "    epoch          : 633\n",
      "    loss           : -882.507087180456\n",
      "    val_loss       : -810.0315045663953\n",
      "    val_log_likelihood: 1284.8620010493644\n",
      "    val_log_marginal: 819.9763545517127\n",
      "Train Epoch: 634 [512/17352 (3%)] Loss: -850.003418\n",
      "Train Epoch: 634 [9746/17352 (56%)] Loss: -827.713333\n",
      "Train Epoch: 634 [17016/17352 (98%)] Loss: -613.044227\n",
      "    epoch          : 634\n",
      "    loss           : -782.7432278165082\n",
      "    val_loss       : -584.2767876742528\n",
      "    val_log_likelihood: 1262.2476952955224\n",
      "    val_log_marginal: 613.6464062537501\n",
      "Train Epoch: 635 [512/17352 (3%)] Loss: -646.625366\n",
      "Train Epoch: 635 [10141/17352 (58%)] Loss: -701.572387\n",
      "Train Epoch: 635 [17335/17352 (100%)] Loss: -633.736694\n",
      "    epoch          : 635\n",
      "    loss           : -712.7297465071706\n",
      "    val_loss       : -664.2949629133615\n",
      "    val_log_likelihood: 1190.8173253778752\n",
      "    val_log_marginal: 694.5239538158635\n",
      "Train Epoch: 636 [512/17352 (3%)] Loss: -711.986145\n",
      "Train Epoch: 636 [9780/17352 (56%)] Loss: -707.150568\n",
      "Train Epoch: 636 [16992/17352 (98%)] Loss: -434.639881\n",
      "    epoch          : 636\n",
      "    loss           : -605.09064528211\n",
      "    val_loss       : -760.2893535264936\n",
      "    val_log_likelihood: 1197.0186116822376\n",
      "    val_log_marginal: 774.6047719960892\n",
      "Train Epoch: 637 [512/17352 (3%)] Loss: -776.220703\n",
      "Train Epoch: 637 [10043/17352 (58%)] Loss: -606.051126\n",
      "Train Epoch: 637 [16878/17352 (97%)] Loss: -861.404472\n",
      "    epoch          : 637\n",
      "    loss           : -579.8391235934866\n",
      "    val_loss       : -762.8011134815938\n",
      "    val_log_likelihood: 1191.976111129054\n",
      "    val_log_marginal: 792.8131636961363\n",
      "Train Epoch: 638 [512/17352 (3%)] Loss: -760.409546\n",
      "Train Epoch: 638 [11099/17352 (64%)] Loss: -578.578629\n",
      "Train Epoch: 638 [17277/17352 (100%)] Loss: -852.058525\n",
      "    epoch          : 638\n",
      "    loss           : -780.2072765290332\n",
      "    val_loss       : -865.8760020753608\n",
      "    val_log_likelihood: 1235.0903475794687\n",
      "    val_log_marginal: 879.245373257018\n",
      "Train Epoch: 639 [512/17352 (3%)] Loss: -915.022217\n",
      "Train Epoch: 639 [10320/17352 (59%)] Loss: -707.601747\n",
      "Train Epoch: 639 [16958/17352 (98%)] Loss: -831.298456\n",
      "    epoch          : 639\n",
      "    loss           : -880.0017787235945\n",
      "    val_loss       : -900.8590498215311\n",
      "    val_log_likelihood: 1275.1823862940241\n",
      "    val_log_marginal: 916.8747478767744\n",
      "Train Epoch: 640 [512/17352 (3%)] Loss: -927.923401\n",
      "Train Epoch: 640 [9801/17352 (56%)] Loss: -838.666574\n",
      "Train Epoch: 640 [16922/17352 (98%)] Loss: -940.169176\n",
      "    epoch          : 640\n",
      "    loss           : -894.1737755694536\n",
      "    val_loss       : -891.3937125623344\n",
      "    val_log_likelihood: 1267.9898365865597\n",
      "    val_log_marginal: 912.3673814028488\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch640.pth ...\n",
      "Train Epoch: 641 [512/17352 (3%)] Loss: -927.581726\n",
      "Train Epoch: 641 [10585/17352 (61%)] Loss: -844.846504\n",
      "Train Epoch: 641 [17016/17352 (98%)] Loss: -768.746572\n",
      "    epoch          : 641\n",
      "    loss           : -876.7440906475651\n",
      "    val_loss       : -858.2432834533082\n",
      "    val_log_likelihood: 1261.470897831779\n",
      "    val_log_marginal: 898.6462620802614\n",
      "Train Epoch: 642 [512/17352 (3%)] Loss: -895.515259\n",
      "Train Epoch: 642 [10335/17352 (60%)] Loss: -884.844511\n",
      "Train Epoch: 642 [16923/17352 (98%)] Loss: -825.334405\n",
      "    epoch          : 642\n",
      "    loss           : -890.5357780536085\n",
      "    val_loss       : -903.6195411313303\n",
      "    val_log_likelihood: 1276.9258663224184\n",
      "    val_log_marginal: 921.3050916804189\n",
      "Train Epoch: 643 [512/17352 (3%)] Loss: -762.362183\n",
      "Train Epoch: 643 [10239/17352 (59%)] Loss: -725.863243\n",
      "Train Epoch: 643 [17016/17352 (98%)] Loss: -803.853868\n",
      "    epoch          : 643\n",
      "    loss           : -887.3576902247283\n",
      "    val_loss       : -889.5534885935874\n",
      "    val_log_likelihood: 1271.0328219644264\n",
      "    val_log_marginal: 905.1172456671178\n",
      "Train Epoch: 644 [512/17352 (3%)] Loss: -921.860962\n",
      "Train Epoch: 644 [10434/17352 (60%)] Loss: -954.784766\n",
      "Train Epoch: 644 [17133/17352 (99%)] Loss: -948.953691\n",
      "    epoch          : 644\n",
      "    loss           : -889.2673016160729\n",
      "    val_loss       : -850.722977182889\n",
      "    val_log_likelihood: 1276.494206066832\n",
      "    val_log_marginal: 895.8553466808784\n",
      "Train Epoch: 645 [512/17352 (3%)] Loss: -926.011353\n",
      "Train Epoch: 645 [11029/17352 (64%)] Loss: -953.033982\n",
      "Train Epoch: 645 [16923/17352 (98%)] Loss: -898.766662\n",
      "    epoch          : 645\n",
      "    loss           : -877.0838950565791\n",
      "    val_loss       : -906.4903537709183\n",
      "    val_log_likelihood: 1280.4597415696473\n",
      "    val_log_marginal: 922.373749950374\n",
      "Train Epoch: 646 [512/17352 (3%)] Loss: -925.126099\n",
      "Train Epoch: 646 [10136/17352 (58%)] Loss: -826.279221\n",
      "Train Epoch: 646 [17108/17352 (99%)] Loss: -1008.176829\n",
      "    epoch          : 646\n",
      "    loss           : -898.2419896773254\n",
      "    val_loss       : -910.676151001329\n",
      "    val_log_likelihood: 1288.5199086392258\n",
      "    val_log_marginal: 926.8828181571586\n",
      "Train Epoch: 647 [512/17352 (3%)] Loss: -940.771851\n",
      "Train Epoch: 647 [10596/17352 (61%)] Loss: -824.389205\n",
      "Train Epoch: 647 [16922/17352 (98%)] Loss: -788.654231\n",
      "    epoch          : 647\n",
      "    loss           : -917.1384513161304\n",
      "    val_loss       : -928.4101692845511\n",
      "    val_log_likelihood: 1301.6749860876541\n",
      "    val_log_marginal: 941.3015555721237\n",
      "Train Epoch: 648 [512/17352 (3%)] Loss: -964.230530\n",
      "Train Epoch: 648 [10315/17352 (59%)] Loss: -966.427544\n",
      "Train Epoch: 648 [17108/17352 (99%)] Loss: -980.508562\n",
      "    epoch          : 648\n",
      "    loss           : -924.1500679063331\n",
      "    val_loss       : -928.1895564629104\n",
      "    val_log_likelihood: 1303.3453846310676\n",
      "    val_log_marginal: 940.315679042563\n",
      "Train Epoch: 649 [512/17352 (3%)] Loss: -959.474487\n",
      "Train Epoch: 649 [10075/17352 (58%)] Loss: -1020.504987\n",
      "Train Epoch: 649 [16883/17352 (97%)] Loss: -875.092127\n",
      "    epoch          : 649\n",
      "    loss           : -932.7020173081676\n",
      "    val_loss       : -929.3834919317333\n",
      "    val_log_likelihood: 1308.9845066279775\n",
      "    val_log_marginal: 942.937497290764\n",
      "Train Epoch: 650 [512/17352 (3%)] Loss: -962.561523\n",
      "Train Epoch: 650 [10479/17352 (60%)] Loss: -763.596666\n",
      "Train Epoch: 650 [16958/17352 (98%)] Loss: -1046.203559\n",
      "    epoch          : 650\n",
      "    loss           : -920.2619823390248\n",
      "    val_loss       : -911.8260434594563\n",
      "    val_log_likelihood: 1300.9288265707428\n",
      "    val_log_marginal: 929.1427090756381\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch650.pth ...\n",
      "Train Epoch: 651 [512/17352 (3%)] Loss: -934.513123\n",
      "Train Epoch: 651 [10523/17352 (61%)] Loss: -728.092100\n",
      "Train Epoch: 651 [17124/17352 (99%)] Loss: -885.963725\n",
      "    epoch          : 651\n",
      "    loss           : -869.3010917706266\n",
      "    val_loss       : -736.3830008035104\n",
      "    val_log_likelihood: 1216.8686581548081\n",
      "    val_log_marginal: 787.9387880302683\n",
      "Train Epoch: 652 [512/17352 (3%)] Loss: -835.617920\n",
      "Train Epoch: 652 [10712/17352 (62%)] Loss: -793.332422\n",
      "Train Epoch: 652 [17277/17352 (100%)] Loss: -937.168509\n",
      "    epoch          : 652\n",
      "    loss           : -735.8772567809162\n",
      "    val_loss       : -645.866305212141\n",
      "    val_log_likelihood: 1188.8109832439625\n",
      "    val_log_marginal: 672.1619090280236\n",
      "Train Epoch: 653 [512/17352 (3%)] Loss: -691.428223\n",
      "Train Epoch: 653 [10006/17352 (58%)] Loss: -880.266854\n",
      "Train Epoch: 653 [16934/17352 (98%)] Loss: -980.827406\n",
      "    epoch          : 653\n",
      "    loss           : -802.1726465546167\n",
      "    val_loss       : -863.2738163107356\n",
      "    val_log_likelihood: 1253.3110070984612\n",
      "    val_log_marginal: 881.871983719225\n",
      "Train Epoch: 654 [512/17352 (3%)] Loss: -912.535217\n",
      "Train Epoch: 654 [10614/17352 (61%)] Loss: -835.716574\n",
      "Train Epoch: 654 [17133/17352 (99%)] Loss: -820.362064\n",
      "    epoch          : 654\n",
      "    loss           : -890.5402688696187\n",
      "    val_loss       : -895.2433433451268\n",
      "    val_log_likelihood: 1277.0622996873483\n",
      "    val_log_marginal: 910.9276940153285\n",
      "Train Epoch: 655 [512/17352 (3%)] Loss: -922.777710\n",
      "Train Epoch: 655 [9910/17352 (57%)] Loss: -616.574350\n",
      "Train Epoch: 655 [16922/17352 (98%)] Loss: -766.793183\n",
      "    epoch          : 655\n",
      "    loss           : -847.6603819308785\n",
      "    val_loss       : -842.8786129822171\n",
      "    val_log_likelihood: 1243.5876509059685\n",
      "    val_log_marginal: 875.9795745407847\n",
      "Train Epoch: 656 [512/17352 (3%)] Loss: -901.299683\n",
      "Train Epoch: 656 [10173/17352 (59%)] Loss: -686.762092\n",
      "Train Epoch: 656 [17153/17352 (99%)] Loss: -883.956380\n",
      "    epoch          : 656\n",
      "    loss           : -812.6210540517742\n",
      "    val_loss       : -862.6981306814577\n",
      "    val_log_likelihood: 1255.737225955124\n",
      "    val_log_marginal: 897.0870390576245\n",
      "Train Epoch: 657 [512/17352 (3%)] Loss: -905.776001\n",
      "Train Epoch: 657 [10058/17352 (58%)] Loss: -819.733386\n",
      "Train Epoch: 657 [16883/17352 (97%)] Loss: -945.894708\n",
      "    epoch          : 657\n",
      "    loss           : -846.4637386842155\n",
      "    val_loss       : -861.7322070874659\n",
      "    val_log_likelihood: 1267.3205072218668\n",
      "    val_log_marginal: 912.8389664991386\n",
      "Train Epoch: 658 [512/17352 (3%)] Loss: -954.320190\n",
      "Train Epoch: 658 [10584/17352 (61%)] Loss: -770.586892\n",
      "Train Epoch: 658 [17108/17352 (99%)] Loss: -915.834438\n",
      "    epoch          : 658\n",
      "    loss           : -888.5775969622889\n",
      "    val_loss       : -897.1388587059123\n",
      "    val_log_likelihood: 1280.7535553143932\n",
      "    val_log_marginal: 914.3307047031747\n",
      "Train Epoch: 659 [512/17352 (3%)] Loss: -936.682983\n",
      "Train Epoch: 659 [10582/17352 (61%)] Loss: -947.259661\n",
      "Train Epoch: 659 [17049/17352 (98%)] Loss: -980.047517\n",
      "    epoch          : 659\n",
      "    loss           : -908.177356379789\n",
      "    val_loss       : -922.8608822644416\n",
      "    val_log_likelihood: 1297.693361073675\n",
      "    val_log_marginal: 940.1877087515818\n",
      "Train Epoch: 660 [512/17352 (3%)] Loss: -978.654785\n",
      "Train Epoch: 660 [10281/17352 (59%)] Loss: -846.807885\n",
      "Train Epoch: 660 [16958/17352 (98%)] Loss: -956.832601\n",
      "    epoch          : 660\n",
      "    loss           : -920.1333858513318\n",
      "    val_loss       : -932.8665202276759\n",
      "    val_log_likelihood: 1303.9501626293336\n",
      "    val_log_marginal: 944.5233843096498\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch660.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 661 [512/17352 (3%)] Loss: -970.769714\n",
      "Train Epoch: 661 [9927/17352 (57%)] Loss: -986.948999\n",
      "Train Epoch: 661 [16883/17352 (97%)] Loss: -783.396040\n",
      "    epoch          : 661\n",
      "    loss           : -924.909685399999\n",
      "    val_loss       : -923.3165155540242\n",
      "    val_log_likelihood: 1304.9179869742811\n",
      "    val_log_marginal: 938.6813541397734\n",
      "Train Epoch: 662 [512/17352 (3%)] Loss: -965.720825\n",
      "Train Epoch: 662 [9726/17352 (56%)] Loss: -954.804065\n",
      "Train Epoch: 662 [16923/17352 (98%)] Loss: -1000.975417\n",
      "    epoch          : 662\n",
      "    loss           : -911.0117310730429\n",
      "    val_loss       : -924.7105672884499\n",
      "    val_log_likelihood: 1302.739809562904\n",
      "    val_log_marginal: 939.5160739577886\n",
      "Train Epoch: 663 [512/17352 (3%)] Loss: -964.719910\n",
      "Train Epoch: 663 [9762/17352 (56%)] Loss: -893.297081\n",
      "Train Epoch: 663 [16958/17352 (98%)] Loss: -809.502550\n",
      "    epoch          : 663\n",
      "    loss           : -914.5127669423425\n",
      "    val_loss       : -926.1644263395991\n",
      "    val_log_likelihood: 1306.16919316646\n",
      "    val_log_marginal: 941.851902916139\n",
      "Train Epoch: 664 [512/17352 (3%)] Loss: -974.125183\n",
      "Train Epoch: 664 [10340/17352 (60%)] Loss: -851.876665\n",
      "Train Epoch: 664 [16923/17352 (98%)] Loss: -863.055460\n",
      "    epoch          : 664\n",
      "    loss           : -920.9411540157674\n",
      "    val_loss       : -930.4937866028624\n",
      "    val_log_likelihood: 1311.9289803632437\n",
      "    val_log_marginal: 944.8659775547646\n",
      "Train Epoch: 665 [512/17352 (3%)] Loss: -933.424133\n",
      "Train Epoch: 665 [9924/17352 (57%)] Loss: -1038.021050\n",
      "Train Epoch: 665 [16883/17352 (97%)] Loss: -991.719062\n",
      "    epoch          : 665\n",
      "    loss           : -911.9429549017611\n",
      "    val_loss       : -922.4751177192985\n",
      "    val_log_likelihood: 1308.0306315024716\n",
      "    val_log_marginal: 937.068907086144\n",
      "Train Epoch: 666 [512/17352 (3%)] Loss: -968.316040\n",
      "Train Epoch: 666 [10435/17352 (60%)] Loss: -831.054501\n",
      "Train Epoch: 666 [17263/17352 (99%)] Loss: -974.005335\n",
      "    epoch          : 666\n",
      "    loss           : -905.2413382154082\n",
      "    val_loss       : -830.1745272062566\n",
      "    val_log_likelihood: 1289.830906948171\n",
      "    val_log_marginal: 846.6891874527894\n",
      "Train Epoch: 667 [512/17352 (3%)] Loss: -876.574768\n",
      "Train Epoch: 667 [10442/17352 (60%)] Loss: -842.432278\n",
      "Train Epoch: 667 [17277/17352 (100%)] Loss: -940.968284\n",
      "    epoch          : 667\n",
      "    loss           : -829.1958816425646\n",
      "    val_loss       : -645.3172472251496\n",
      "    val_log_likelihood: 1262.8208803645082\n",
      "    val_log_marginal: 662.2584707795038\n",
      "Train Epoch: 668 [512/17352 (3%)] Loss: -710.830566\n",
      "Train Epoch: 668 [10500/17352 (61%)] Loss: -694.076480\n",
      "Train Epoch: 668 [17277/17352 (100%)] Loss: -938.974763\n",
      "    epoch          : 668\n",
      "    loss           : -818.8602849715804\n",
      "    val_loss       : -825.787775234571\n",
      "    val_log_likelihood: 1265.9969600217933\n",
      "    val_log_marginal: 847.9515672031603\n",
      "Train Epoch: 669 [512/17352 (3%)] Loss: -866.882996\n",
      "Train Epoch: 669 [9953/17352 (57%)] Loss: -791.315061\n",
      "Train Epoch: 669 [17016/17352 (98%)] Loss: -673.166976\n",
      "    epoch          : 669\n",
      "    loss           : -639.7076818708074\n",
      "    val_loss       : -346.6302419496281\n",
      "    val_log_likelihood: 1226.5020201956786\n",
      "    val_log_marginal: 370.3727238736842\n",
      "Train Epoch: 670 [512/17352 (3%)] Loss: -178.985779\n",
      "Train Epoch: 670 [10563/17352 (61%)] Loss: -591.192196\n",
      "Train Epoch: 670 [17090/17352 (98%)] Loss: -819.021256\n",
      "    epoch          : 670\n",
      "    loss           : -416.12334188650266\n",
      "    val_loss       : -690.4443662524292\n",
      "    val_log_likelihood: 1170.4960581756138\n",
      "    val_log_marginal: 715.6901615818912\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch670.pth ...\n",
      "Train Epoch: 671 [512/17352 (3%)] Loss: -760.543335\n",
      "Train Epoch: 671 [10110/17352 (58%)] Loss: -873.651270\n",
      "Train Epoch: 671 [17253/17352 (99%)] Loss: -813.587612\n",
      "    epoch          : 671\n",
      "    loss           : -809.3183609305318\n",
      "    val_loss       : -833.0533349142646\n",
      "    val_log_likelihood: 1249.3162441079992\n",
      "    val_log_marginal: 851.2185335107496\n",
      "Train Epoch: 672 [512/17352 (3%)] Loss: -875.579285\n",
      "Train Epoch: 672 [10242/17352 (59%)] Loss: -970.263404\n",
      "Train Epoch: 672 [16883/17352 (97%)] Loss: -869.948465\n",
      "    epoch          : 672\n",
      "    loss           : -885.7644597346341\n",
      "    val_loss       : -915.5132464864865\n",
      "    val_log_likelihood: 1287.722906053723\n",
      "    val_log_marginal: 927.9203938968592\n",
      "Train Epoch: 673 [512/17352 (3%)] Loss: -954.853760\n",
      "Train Epoch: 673 [10334/17352 (60%)] Loss: -951.254424\n",
      "Train Epoch: 673 [17253/17352 (99%)] Loss: -905.332483\n",
      "    epoch          : 673\n",
      "    loss           : -893.9508053694916\n",
      "    val_loss       : -862.1797452824491\n",
      "    val_log_likelihood: 1280.3544506740711\n",
      "    val_log_marginal: 881.8882066909756\n",
      "Train Epoch: 674 [512/17352 (3%)] Loss: -903.403870\n",
      "Train Epoch: 674 [10447/17352 (60%)] Loss: -708.462395\n",
      "Train Epoch: 674 [17044/17352 (98%)] Loss: -796.090495\n",
      "    epoch          : 674\n",
      "    loss           : -822.8918559043572\n",
      "    val_loss       : -857.5302244884423\n",
      "    val_log_likelihood: 1272.1024467883785\n",
      "    val_log_marginal: 874.4926066077285\n",
      "Train Epoch: 675 [512/17352 (3%)] Loss: -889.935852\n",
      "Train Epoch: 675 [10188/17352 (59%)] Loss: -823.949312\n",
      "Train Epoch: 675 [17101/17352 (99%)] Loss: -807.716619\n",
      "    epoch          : 675\n",
      "    loss           : -888.4244706837818\n",
      "    val_loss       : -903.7931212653895\n",
      "    val_log_likelihood: 1285.6613995371276\n",
      "    val_log_marginal: 920.0020976276493\n",
      "Train Epoch: 676 [512/17352 (3%)] Loss: -927.864319\n",
      "Train Epoch: 676 [10591/17352 (61%)] Loss: -871.866675\n",
      "Train Epoch: 676 [17106/17352 (99%)] Loss: -884.710286\n",
      "    epoch          : 676\n",
      "    loss           : -904.6260320828769\n",
      "    val_loss       : -926.290623244108\n",
      "    val_log_likelihood: 1300.2862380545337\n",
      "    val_log_marginal: 939.6383855968255\n",
      "Train Epoch: 677 [512/17352 (3%)] Loss: -969.362671\n",
      "Train Epoch: 677 [10476/17352 (60%)] Loss: -910.288891\n",
      "Train Epoch: 677 [17126/17352 (99%)] Loss: -930.175251\n",
      "    epoch          : 677\n",
      "    loss           : -927.1378818701256\n",
      "    val_loss       : -920.7760963288837\n",
      "    val_log_likelihood: 1309.9547795724277\n",
      "    val_log_marginal: 931.4145438188468\n",
      "Train Epoch: 678 [512/17352 (3%)] Loss: -960.653931\n",
      "Train Epoch: 678 [9766/17352 (56%)] Loss: -990.309515\n",
      "Train Epoch: 678 [16883/17352 (97%)] Loss: -989.228399\n",
      "    epoch          : 678\n",
      "    loss           : -917.7093622573299\n",
      "    val_loss       : -937.3662572118083\n",
      "    val_log_likelihood: 1312.3898116559496\n",
      "    val_log_marginal: 952.0999880035168\n",
      "Train Epoch: 679 [512/17352 (3%)] Loss: -975.020386\n",
      "Train Epoch: 679 [9695/17352 (56%)] Loss: -942.395991\n",
      "Train Epoch: 679 [16883/17352 (97%)] Loss: -1068.085938\n",
      "    epoch          : 679\n",
      "    loss           : -935.3945493729015\n",
      "    val_loss       : -940.5518790854952\n",
      "    val_log_likelihood: 1319.0557590862759\n",
      "    val_log_marginal: 955.3289269144647\n",
      "Train Epoch: 680 [512/17352 (3%)] Loss: -985.405151\n",
      "Train Epoch: 680 [10459/17352 (60%)] Loss: -962.402724\n",
      "Train Epoch: 680 [17016/17352 (98%)] Loss: -871.852321\n",
      "    epoch          : 680\n",
      "    loss           : -938.080856773518\n",
      "    val_loss       : -931.0562550006952\n",
      "    val_log_likelihood: 1317.478458733211\n",
      "    val_log_marginal: 943.0558445404873\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch680.pth ...\n",
      "Train Epoch: 681 [512/17352 (3%)] Loss: -971.413818\n",
      "Train Epoch: 681 [10335/17352 (60%)] Loss: -931.470896\n",
      "Train Epoch: 681 [16872/17352 (97%)] Loss: -784.917608\n",
      "    epoch          : 681\n",
      "    loss           : -936.3005341453872\n",
      "    val_loss       : -925.3217619001418\n",
      "    val_log_likelihood: 1321.6598886483803\n",
      "    val_log_marginal: 944.8571292755287\n",
      "Train Epoch: 682 [512/17352 (3%)] Loss: -981.026245\n",
      "Train Epoch: 682 [10335/17352 (60%)] Loss: -967.691648\n",
      "Train Epoch: 682 [17124/17352 (99%)] Loss: -1039.672669\n",
      "    epoch          : 682\n",
      "    loss           : -929.1120922437101\n",
      "    val_loss       : -927.0894969136846\n",
      "    val_log_likelihood: 1321.343469828569\n",
      "    val_log_marginal: 943.3784725839171\n",
      "Train Epoch: 683 [512/17352 (3%)] Loss: -967.373291\n",
      "Train Epoch: 683 [10753/17352 (62%)] Loss: -1013.717884\n",
      "Train Epoch: 683 [17335/17352 (100%)] Loss: -1039.539800\n",
      "    epoch          : 683\n",
      "    loss           : -917.6880835324667\n",
      "    val_loss       : -823.4989847350188\n",
      "    val_log_likelihood: 1292.4112180890206\n",
      "    val_log_marginal: 837.4138107191038\n",
      "Train Epoch: 684 [512/17352 (3%)] Loss: -851.120972\n",
      "Train Epoch: 684 [10000/17352 (58%)] Loss: -770.021814\n",
      "Train Epoch: 684 [17263/17352 (99%)] Loss: -756.797110\n",
      "    epoch          : 684\n",
      "    loss           : -891.8791634895955\n",
      "    val_loss       : -885.4043654524176\n",
      "    val_log_likelihood: 1308.1751904154023\n",
      "    val_log_marginal: 904.0876622841046\n",
      "Train Epoch: 685 [512/17352 (3%)] Loss: -932.268555\n",
      "Train Epoch: 685 [11043/17352 (64%)] Loss: -983.983265\n",
      "Train Epoch: 685 [17133/17352 (99%)] Loss: -787.855149\n",
      "    epoch          : 685\n",
      "    loss           : -890.8017934092177\n",
      "    val_loss       : -890.7316865090102\n",
      "    val_log_likelihood: 1295.7063443976\n",
      "    val_log_marginal: 900.5191367427917\n",
      "Train Epoch: 686 [512/17352 (3%)] Loss: -742.645081\n",
      "Train Epoch: 686 [10761/17352 (62%)] Loss: -1016.756197\n",
      "Train Epoch: 686 [17133/17352 (99%)] Loss: -989.460184\n",
      "    epoch          : 686\n",
      "    loss           : -894.0540472361927\n",
      "    val_loss       : -859.6722283478099\n",
      "    val_log_likelihood: 1275.840091516875\n",
      "    val_log_marginal: 889.0768125820044\n",
      "Train Epoch: 687 [512/17352 (3%)] Loss: -934.904846\n",
      "Train Epoch: 687 [9984/17352 (58%)] Loss: -1002.735882\n",
      "Train Epoch: 687 [16887/17352 (97%)] Loss: -897.171181\n",
      "    epoch          : 687\n",
      "    loss           : -903.942085166727\n",
      "    val_loss       : -925.2055092237878\n",
      "    val_log_likelihood: 1315.131161445779\n",
      "    val_log_marginal: 942.2287058979023\n",
      "Train Epoch: 688 [512/17352 (3%)] Loss: -969.636169\n",
      "Train Epoch: 688 [10563/17352 (61%)] Loss: -1013.769656\n",
      "Train Epoch: 688 [17101/17352 (99%)] Loss: -914.436899\n",
      "    epoch          : 688\n",
      "    loss           : -915.3679548349548\n",
      "    val_loss       : -904.4172506783635\n",
      "    val_log_likelihood: 1318.7254494083675\n",
      "    val_log_marginal: 918.8502572847422\n",
      "Train Epoch: 689 [512/17352 (3%)] Loss: -958.442993\n",
      "Train Epoch: 689 [10179/17352 (59%)] Loss: -825.536305\n",
      "Train Epoch: 689 [16882/17352 (97%)] Loss: -1057.963759\n",
      "    epoch          : 689\n",
      "    loss           : -920.0100817640722\n",
      "    val_loss       : -915.9944514163616\n",
      "    val_log_likelihood: 1311.7884600459493\n",
      "    val_log_marginal: 927.9672842430397\n",
      "Train Epoch: 690 [512/17352 (3%)] Loss: -969.044617\n",
      "Train Epoch: 690 [10501/17352 (61%)] Loss: -844.659412\n",
      "Train Epoch: 690 [17124/17352 (99%)] Loss: -820.379008\n",
      "    epoch          : 690\n",
      "    loss           : -907.1465945773897\n",
      "    val_loss       : -931.5400634366766\n",
      "    val_log_likelihood: 1319.9820493111558\n",
      "    val_log_marginal: 944.9655174538848\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch690.pth ...\n",
      "Train Epoch: 691 [512/17352 (3%)] Loss: -968.116150\n",
      "Train Epoch: 691 [10400/17352 (60%)] Loss: -917.987058\n",
      "Train Epoch: 691 [17101/17352 (99%)] Loss: -771.141192\n",
      "    epoch          : 691\n",
      "    loss           : -920.0597692550579\n",
      "    val_loss       : -868.6461590666421\n",
      "    val_log_likelihood: 1323.7398841087083\n",
      "    val_log_marginal: 880.3717895248984\n",
      "Train Epoch: 692 [512/17352 (3%)] Loss: -923.332458\n",
      "Train Epoch: 692 [10557/17352 (61%)] Loss: -742.750806\n",
      "Train Epoch: 692 [17090/17352 (98%)] Loss: -946.243947\n",
      "    epoch          : 692\n",
      "    loss           : -897.5414391290476\n",
      "    val_loss       : -725.732156839894\n",
      "    val_log_likelihood: 1302.5970827314218\n",
      "    val_log_marginal: 746.1907914065858\n",
      "Train Epoch: 693 [512/17352 (3%)] Loss: -739.661133\n",
      "Train Epoch: 693 [10356/17352 (60%)] Loss: -725.634928\n",
      "Train Epoch: 693 [17108/17352 (99%)] Loss: -673.584812\n",
      "    epoch          : 693\n",
      "    loss           : -805.9107412297416\n",
      "    val_loss       : -881.9457374856894\n",
      "    val_log_likelihood: 1290.0357374872\n",
      "    val_log_marginal: 897.2645326462113\n",
      "Train Epoch: 694 [512/17352 (3%)] Loss: -908.018127\n",
      "Train Epoch: 694 [9853/17352 (57%)] Loss: -1016.092665\n",
      "Train Epoch: 694 [16922/17352 (98%)] Loss: -836.399142\n",
      "    epoch          : 694\n",
      "    loss           : -881.4427542405614\n",
      "    val_loss       : -915.5052691567215\n",
      "    val_log_likelihood: 1304.3427089533832\n",
      "    val_log_marginal: 933.0332368579824\n",
      "Train Epoch: 695 [512/17352 (3%)] Loss: -953.603760\n",
      "Train Epoch: 695 [10667/17352 (61%)] Loss: -758.056720\n",
      "Train Epoch: 695 [17106/17352 (99%)] Loss: -818.689022\n",
      "    epoch          : 695\n",
      "    loss           : -923.5326200613483\n",
      "    val_loss       : -936.3261969108186\n",
      "    val_log_likelihood: 1328.394750514333\n",
      "    val_log_marginal: 948.8408021212083\n",
      "Train Epoch: 696 [512/17352 (3%)] Loss: -974.921326\n",
      "Train Epoch: 696 [9668/17352 (56%)] Loss: -1069.312283\n",
      "Train Epoch: 696 [17126/17352 (99%)] Loss: -994.846365\n",
      "    epoch          : 696\n",
      "    loss           : -935.3757104918135\n",
      "    val_loss       : -939.6027890947677\n",
      "    val_log_likelihood: 1330.4320598729398\n",
      "    val_log_marginal: 953.7096710231332\n",
      "Train Epoch: 697 [512/17352 (3%)] Loss: -980.688049\n",
      "Train Epoch: 697 [10725/17352 (62%)] Loss: -984.546484\n",
      "Train Epoch: 697 [17016/17352 (98%)] Loss: -1007.714399\n",
      "    epoch          : 697\n",
      "    loss           : -935.7230050455656\n",
      "    val_loss       : -933.4794865032164\n",
      "    val_log_likelihood: 1333.3494725299884\n",
      "    val_log_marginal: 948.9841049008124\n",
      "Train Epoch: 698 [512/17352 (3%)] Loss: -975.199097\n",
      "Train Epoch: 698 [10248/17352 (59%)] Loss: -943.415375\n",
      "Train Epoch: 698 [16923/17352 (98%)] Loss: -958.302214\n",
      "    epoch          : 698\n",
      "    loss           : -925.6557993491693\n",
      "    val_loss       : -918.0252574251676\n",
      "    val_log_likelihood: 1330.0163638933648\n",
      "    val_log_marginal: 935.9267468554726\n",
      "Train Epoch: 699 [512/17352 (3%)] Loss: -958.175781\n",
      "Train Epoch: 699 [9725/17352 (56%)] Loss: -942.673854\n",
      "Train Epoch: 699 [16957/17352 (98%)] Loss: -833.691372\n",
      "    epoch          : 699\n",
      "    loss           : -870.9365601614054\n",
      "    val_loss       : -908.0307126207744\n",
      "    val_log_likelihood: 1319.4624685406611\n",
      "    val_log_marginal: 938.4616632369413\n",
      "Train Epoch: 700 [512/17352 (3%)] Loss: -981.450806\n",
      "Train Epoch: 700 [10267/17352 (59%)] Loss: -936.441510\n",
      "Train Epoch: 700 [17101/17352 (99%)] Loss: -831.119606\n",
      "    epoch          : 700\n",
      "    loss           : -872.1814925479852\n",
      "    val_loss       : -903.3759033501439\n",
      "    val_log_likelihood: 1310.7002402198661\n",
      "    val_log_marginal: 918.5159601380939\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch700.pth ...\n",
      "Train Epoch: 701 [512/17352 (3%)] Loss: -937.269714\n",
      "Train Epoch: 701 [9873/17352 (57%)] Loss: -754.053728\n",
      "Train Epoch: 701 [17090/17352 (98%)] Loss: -1016.450203\n",
      "    epoch          : 701\n",
      "    loss           : -888.5255689587757\n",
      "    val_loss       : -925.7002174699454\n",
      "    val_log_likelihood: 1312.6604424296136\n",
      "    val_log_marginal: 937.1133285779302\n",
      "Train Epoch: 702 [512/17352 (3%)] Loss: -967.337524\n",
      "Train Epoch: 702 [9604/17352 (55%)] Loss: -771.905459\n",
      "Train Epoch: 702 [16957/17352 (98%)] Loss: -1018.139792\n",
      "    epoch          : 702\n",
      "    loss           : -912.7639725642072\n",
      "    val_loss       : -916.9237924397778\n",
      "    val_log_likelihood: 1312.380921991328\n",
      "    val_log_marginal: 939.8432214822456\n",
      "Train Epoch: 703 [512/17352 (3%)] Loss: -981.713440\n",
      "Train Epoch: 703 [10675/17352 (62%)] Loss: -842.228969\n",
      "Train Epoch: 703 [17335/17352 (100%)] Loss: -1020.439320\n",
      "    epoch          : 703\n",
      "    loss           : -910.7669055676306\n",
      "    val_loss       : -930.0178125910643\n",
      "    val_log_likelihood: 1323.5007581053642\n",
      "    val_log_marginal: 948.7958418529885\n",
      "Train Epoch: 704 [512/17352 (3%)] Loss: -980.793884\n",
      "Train Epoch: 704 [10358/17352 (60%)] Loss: -1056.738064\n",
      "Train Epoch: 704 [16882/17352 (97%)] Loss: -1005.693645\n",
      "    epoch          : 704\n",
      "    loss           : -934.8166102077536\n",
      "    val_loss       : -941.2763818450895\n",
      "    val_log_likelihood: 1327.7469629095522\n",
      "    val_log_marginal: 953.9002677087144\n",
      "Train Epoch: 705 [512/17352 (3%)] Loss: -971.492798\n",
      "Train Epoch: 705 [9910/17352 (57%)] Loss: -968.842367\n",
      "Train Epoch: 705 [17044/17352 (98%)] Loss: -787.543959\n",
      "    epoch          : 705\n",
      "    loss           : -917.6567876090836\n",
      "    val_loss       : -939.4199680764493\n",
      "    val_log_likelihood: 1335.713834077751\n",
      "    val_log_marginal: 956.8307313596944\n",
      "Train Epoch: 706 [512/17352 (3%)] Loss: -984.240051\n",
      "Train Epoch: 706 [10501/17352 (61%)] Loss: -795.960082\n",
      "Train Epoch: 706 [16939/17352 (98%)] Loss: -804.380982\n",
      "    epoch          : 706\n",
      "    loss           : -919.9476859626246\n",
      "    val_loss       : -950.9733975991891\n",
      "    val_log_likelihood: 1341.8101352165434\n",
      "    val_log_marginal: 964.3878864748636\n",
      "Train Epoch: 707 [512/17352 (3%)] Loss: -987.834534\n",
      "Train Epoch: 707 [10453/17352 (60%)] Loss: -790.254298\n",
      "Train Epoch: 707 [17090/17352 (98%)] Loss: -980.592253\n",
      "    epoch          : 707\n",
      "    loss           : -930.3625599580455\n",
      "    val_loss       : -914.4594004286033\n",
      "    val_log_likelihood: 1320.5122205417126\n",
      "    val_log_marginal: 934.6468340163175\n",
      "Train Epoch: 708 [512/17352 (3%)] Loss: -975.219482\n",
      "Train Epoch: 708 [10041/17352 (58%)] Loss: -906.276199\n",
      "Train Epoch: 708 [17108/17352 (99%)] Loss: -811.924653\n",
      "    epoch          : 708\n",
      "    loss           : -904.9046783244817\n",
      "    val_loss       : -849.6395645780244\n",
      "    val_log_likelihood: 1301.1559269099705\n",
      "    val_log_marginal: 864.1512465743222\n",
      "Train Epoch: 709 [512/17352 (3%)] Loss: -918.880920\n",
      "Train Epoch: 709 [10648/17352 (61%)] Loss: -737.178454\n",
      "Train Epoch: 709 [16872/17352 (97%)] Loss: -828.363108\n",
      "    epoch          : 709\n",
      "    loss           : -870.365669040137\n",
      "    val_loss       : -907.7177351039228\n",
      "    val_log_likelihood: 1303.3508668089112\n",
      "    val_log_marginal: 926.5261168225707\n",
      "Train Epoch: 710 [512/17352 (3%)] Loss: -979.093384\n",
      "Train Epoch: 710 [10530/17352 (61%)] Loss: -1023.346149\n",
      "Train Epoch: 710 [16882/17352 (97%)] Loss: -989.088023\n",
      "    epoch          : 710\n",
      "    loss           : -923.7697980148643\n",
      "    val_loss       : -944.2775092362904\n",
      "    val_log_likelihood: 1327.5537118247303\n",
      "    val_log_marginal: 958.6223507247855\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch710.pth ...\n",
      "Train Epoch: 711 [512/17352 (3%)] Loss: -975.845215\n",
      "Train Epoch: 711 [10629/17352 (61%)] Loss: -1013.461108\n",
      "Train Epoch: 711 [17263/17352 (99%)] Loss: -786.272217\n",
      "    epoch          : 711\n",
      "    loss           : -906.6226608254485\n",
      "    val_loss       : -841.4991483255621\n",
      "    val_log_likelihood: 1291.9810521110487\n",
      "    val_log_marginal: 855.4562985922728\n",
      "Train Epoch: 712 [512/17352 (3%)] Loss: -884.771484\n",
      "Train Epoch: 712 [10075/17352 (58%)] Loss: -1002.678168\n",
      "Train Epoch: 712 [16878/17352 (97%)] Loss: -813.116721\n",
      "    epoch          : 712\n",
      "    loss           : -830.6760363509004\n",
      "    val_loss       : -802.2412037884387\n",
      "    val_log_likelihood: 1301.430244556039\n",
      "    val_log_marginal: 820.243577431617\n",
      "Train Epoch: 713 [512/17352 (3%)] Loss: -831.250854\n",
      "Train Epoch: 713 [10658/17352 (61%)] Loss: -966.250484\n",
      "Train Epoch: 713 [17133/17352 (99%)] Loss: -1017.440972\n",
      "    epoch          : 713\n",
      "    loss           : -863.921433348258\n",
      "    val_loss       : -867.8434718186494\n",
      "    val_log_likelihood: 1293.034644672507\n",
      "    val_log_marginal: 882.7058701051582\n",
      "Train Epoch: 714 [512/17352 (3%)] Loss: -900.337891\n",
      "Train Epoch: 714 [10467/17352 (60%)] Loss: -896.768880\n",
      "Train Epoch: 714 [16934/17352 (98%)] Loss: -991.184245\n",
      "    epoch          : 714\n",
      "    loss           : -883.2174336127383\n",
      "    val_loss       : -904.8799795124445\n",
      "    val_log_likelihood: 1304.0338144507318\n",
      "    val_log_marginal: 933.515610909549\n",
      "Train Epoch: 715 [512/17352 (3%)] Loss: -938.277771\n",
      "Train Epoch: 715 [9978/17352 (58%)] Loss: -846.047588\n",
      "Train Epoch: 715 [16922/17352 (98%)] Loss: -889.472963\n",
      "    epoch          : 715\n",
      "    loss           : -856.4807086524695\n",
      "    val_loss       : -882.7322522322329\n",
      "    val_log_likelihood: 1288.7635291602803\n",
      "    val_log_marginal: 913.2103747674837\n",
      "Train Epoch: 716 [512/17352 (3%)] Loss: -953.613831\n",
      "Train Epoch: 716 [10634/17352 (61%)] Loss: -694.452487\n",
      "Train Epoch: 716 [16939/17352 (98%)] Loss: -780.077975\n",
      "    epoch          : 716\n",
      "    loss           : -886.541349412885\n",
      "    val_loss       : -934.5048171299878\n",
      "    val_log_likelihood: 1312.5420525010775\n",
      "    val_log_marginal: 951.1378176062935\n",
      "Train Epoch: 717 [512/17352 (3%)] Loss: -961.468689\n",
      "Train Epoch: 717 [10274/17352 (59%)] Loss: -970.326875\n",
      "Train Epoch: 717 [16957/17352 (98%)] Loss: -1024.812100\n",
      "    epoch          : 717\n",
      "    loss           : -921.7655790753366\n",
      "    val_loss       : -909.2730697337994\n",
      "    val_log_likelihood: 1307.9027010960185\n",
      "    val_log_marginal: 921.6859235598014\n",
      "Train Epoch: 718 [512/17352 (3%)] Loss: -957.043396\n",
      "Train Epoch: 718 [10380/17352 (60%)] Loss: -870.864833\n",
      "Train Epoch: 718 [17153/17352 (99%)] Loss: -888.500781\n",
      "    epoch          : 718\n",
      "    loss           : -935.8163604588677\n",
      "    val_loss       : -945.597282390387\n",
      "    val_log_likelihood: 1329.977301163426\n",
      "    val_log_marginal: 960.6958601977389\n",
      "Train Epoch: 719 [512/17352 (3%)] Loss: -988.952026\n",
      "Train Epoch: 719 [10469/17352 (60%)] Loss: -836.496094\n",
      "Train Epoch: 719 [17263/17352 (99%)] Loss: -1072.521111\n",
      "    epoch          : 719\n",
      "    loss           : -938.9861533897954\n",
      "    val_loss       : -925.9743498939619\n",
      "    val_log_likelihood: 1323.368519631996\n",
      "    val_log_marginal: 938.4552932712822\n",
      "Train Epoch: 720 [512/17352 (3%)] Loss: -967.218201\n",
      "Train Epoch: 720 [10071/17352 (58%)] Loss: -985.522546\n",
      "Train Epoch: 720 [17253/17352 (99%)] Loss: -831.384543\n",
      "    epoch          : 720\n",
      "    loss           : -945.4355146346907\n",
      "    val_loss       : -947.1249089861129\n",
      "    val_log_likelihood: 1340.7037000777852\n",
      "    val_log_marginal: 965.1342929058948\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch720.pth ...\n",
      "Train Epoch: 721 [512/17352 (3%)] Loss: -993.458069\n",
      "Train Epoch: 721 [10441/17352 (60%)] Loss: -1053.643356\n",
      "Train Epoch: 721 [17049/17352 (98%)] Loss: -1063.732096\n",
      "    epoch          : 721\n",
      "    loss           : -948.3533892019769\n",
      "    val_loss       : -953.9169556944571\n",
      "    val_log_likelihood: 1345.1183123315213\n",
      "    val_log_marginal: 966.7175194561727\n",
      "Train Epoch: 722 [512/17352 (3%)] Loss: -998.739685\n",
      "Train Epoch: 722 [10519/17352 (61%)] Loss: -929.549205\n",
      "Train Epoch: 722 [16934/17352 (98%)] Loss: -1028.834098\n",
      "    epoch          : 722\n",
      "    loss           : -939.4684939273847\n",
      "    val_loss       : -947.132796562187\n",
      "    val_log_likelihood: 1337.264754008525\n",
      "    val_log_marginal: 959.7153315821953\n",
      "Train Epoch: 723 [512/17352 (3%)] Loss: -977.976807\n",
      "Train Epoch: 723 [10623/17352 (61%)] Loss: -894.504836\n",
      "Train Epoch: 723 [16882/17352 (97%)] Loss: -831.588883\n",
      "    epoch          : 723\n",
      "    loss           : -939.0926239570164\n",
      "    val_loss       : -913.0288489555553\n",
      "    val_log_likelihood: 1331.3441757934195\n",
      "    val_log_marginal: 937.0404383658783\n",
      "Train Epoch: 724 [512/17352 (3%)] Loss: -957.172668\n",
      "Train Epoch: 724 [10228/17352 (59%)] Loss: -983.986045\n",
      "Train Epoch: 724 [16882/17352 (97%)] Loss: -1006.684335\n",
      "    epoch          : 724\n",
      "    loss           : -935.5841185257142\n",
      "    val_loss       : -926.461141998897\n",
      "    val_log_likelihood: 1341.822933515368\n",
      "    val_log_marginal: 940.5275710715272\n",
      "Train Epoch: 725 [512/17352 (3%)] Loss: -971.855713\n",
      "Train Epoch: 725 [10219/17352 (59%)] Loss: -779.127957\n",
      "Train Epoch: 725 [16957/17352 (98%)] Loss: -973.561216\n",
      "    epoch          : 725\n",
      "    loss           : -911.2379205413474\n",
      "    val_loss       : -939.6801988115031\n",
      "    val_log_likelihood: 1338.1408540644852\n",
      "    val_log_marginal: 955.5573051843082\n",
      "Train Epoch: 726 [512/17352 (3%)] Loss: -972.246460\n",
      "Train Epoch: 726 [9930/17352 (57%)] Loss: -990.211042\n",
      "Train Epoch: 726 [17090/17352 (98%)] Loss: -832.897925\n",
      "    epoch          : 726\n",
      "    loss           : -927.810398323665\n",
      "    val_loss       : -923.8821736766627\n",
      "    val_log_likelihood: 1330.0958527183438\n",
      "    val_log_marginal: 939.7792891167759\n",
      "Train Epoch: 727 [512/17352 (3%)] Loss: -957.611572\n",
      "Train Epoch: 727 [10684/17352 (62%)] Loss: -899.869076\n",
      "Train Epoch: 727 [17106/17352 (99%)] Loss: -958.352475\n",
      "    epoch          : 727\n",
      "    loss           : -923.5895099444916\n",
      "    val_loss       : -904.7460818011864\n",
      "    val_log_likelihood: 1342.9734887215814\n",
      "    val_log_marginal: 921.9760455376611\n",
      "Train Epoch: 728 [512/17352 (3%)] Loss: -942.418213\n",
      "Train Epoch: 728 [10015/17352 (58%)] Loss: -910.802152\n",
      "Train Epoch: 728 [17016/17352 (98%)] Loss: -938.306032\n",
      "    epoch          : 728\n",
      "    loss           : -891.6535833704171\n",
      "    val_loss       : -898.1589844105082\n",
      "    val_log_likelihood: 1320.5925568763853\n",
      "    val_log_marginal: 925.2043866048144\n",
      "Train Epoch: 729 [512/17352 (3%)] Loss: -927.405640\n",
      "Train Epoch: 729 [10668/17352 (61%)] Loss: -833.293959\n",
      "Train Epoch: 729 [17108/17352 (99%)] Loss: -956.284059\n",
      "    epoch          : 729\n",
      "    loss           : -893.2250158809074\n",
      "    val_loss       : -893.6528331688246\n",
      "    val_log_likelihood: 1320.2154518713946\n",
      "    val_log_marginal: 922.3802839089427\n",
      "Train Epoch: 730 [512/17352 (3%)] Loss: -947.015503\n",
      "Train Epoch: 730 [10103/17352 (58%)] Loss: -1038.165708\n",
      "Train Epoch: 730 [17016/17352 (98%)] Loss: -894.695962\n",
      "    epoch          : 730\n",
      "    loss           : -854.5419281090318\n",
      "    val_loss       : -849.4234129977428\n",
      "    val_log_likelihood: 1295.190998229863\n",
      "    val_log_marginal: 895.491873394659\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch730.pth ...\n",
      "Train Epoch: 731 [512/17352 (3%)] Loss: -844.852356\n",
      "Train Epoch: 731 [10257/17352 (59%)] Loss: -974.215320\n",
      "Train Epoch: 731 [17335/17352 (100%)] Loss: -1037.155342\n",
      "    epoch          : 731\n",
      "    loss           : -894.4348328388834\n",
      "    val_loss       : -902.3692244138906\n",
      "    val_log_likelihood: 1302.9560882613684\n",
      "    val_log_marginal: 918.952410768483\n",
      "Train Epoch: 732 [512/17352 (3%)] Loss: -941.729248\n",
      "Train Epoch: 732 [9967/17352 (57%)] Loss: -772.935215\n",
      "Train Epoch: 732 [16883/17352 (97%)] Loss: -1024.389478\n",
      "    epoch          : 732\n",
      "    loss           : -918.1352211827216\n",
      "    val_loss       : -924.9987035748729\n",
      "    val_log_likelihood: 1333.7027284400353\n",
      "    val_log_marginal: 941.2921357195637\n",
      "Train Epoch: 733 [512/17352 (3%)] Loss: -943.059937\n",
      "Train Epoch: 733 [11193/17352 (65%)] Loss: -809.087553\n",
      "Train Epoch: 733 [17126/17352 (99%)] Loss: -757.658777\n",
      "    epoch          : 733\n",
      "    loss           : -905.5965032020548\n",
      "    val_loss       : -909.4509801272178\n",
      "    val_log_likelihood: 1317.4890433088553\n",
      "    val_log_marginal: 923.5616903890805\n",
      "Train Epoch: 734 [512/17352 (3%)] Loss: -925.107727\n",
      "Train Epoch: 734 [9908/17352 (57%)] Loss: -828.089775\n",
      "Train Epoch: 734 [16957/17352 (98%)] Loss: -748.959722\n",
      "    epoch          : 734\n",
      "    loss           : -845.439503483333\n",
      "    val_loss       : -800.2976736291769\n",
      "    val_log_likelihood: 1305.939355143353\n",
      "    val_log_marginal: 819.9260677534869\n",
      "Train Epoch: 735 [512/17352 (3%)] Loss: -819.272339\n",
      "Train Epoch: 735 [10469/17352 (60%)] Loss: -705.612314\n",
      "Train Epoch: 735 [17153/17352 (99%)] Loss: -654.859119\n",
      "    epoch          : 735\n",
      "    loss           : -871.8485955706107\n",
      "    val_loss       : -669.6980871988537\n",
      "    val_log_likelihood: 1305.6425816895867\n",
      "    val_log_marginal: 684.6199880639343\n",
      "Train Epoch: 736 [512/17352 (3%)] Loss: -717.237854\n",
      "Train Epoch: 736 [10519/17352 (61%)] Loss: -781.007196\n",
      "Train Epoch: 736 [17153/17352 (99%)] Loss: -879.899740\n",
      "    epoch          : 736\n",
      "    loss           : -812.4300060479213\n",
      "    val_loss       : -772.2997086989465\n",
      "    val_log_likelihood: 1293.785145551716\n",
      "    val_log_marginal: 799.2239633696599\n",
      "Train Epoch: 737 [512/17352 (3%)] Loss: -821.172363\n",
      "Train Epoch: 737 [10959/17352 (63%)] Loss: -990.364161\n",
      "Train Epoch: 737 [17064/17352 (98%)] Loss: -945.522384\n",
      "    epoch          : 737\n",
      "    loss           : -856.0400809561285\n",
      "    val_loss       : -886.1295511029064\n",
      "    val_log_likelihood: 1320.206273897078\n",
      "    val_log_marginal: 904.7439785023655\n",
      "Train Epoch: 738 [512/17352 (3%)] Loss: -932.992859\n",
      "Train Epoch: 738 [10177/17352 (59%)] Loss: -860.724895\n",
      "Train Epoch: 738 [17090/17352 (98%)] Loss: -752.497110\n",
      "    epoch          : 738\n",
      "    loss           : -910.7772447767856\n",
      "    val_loss       : -862.9178238201356\n",
      "    val_log_likelihood: 1311.500833802166\n",
      "    val_log_marginal: 888.3375755487544\n",
      "Train Epoch: 739 [512/17352 (3%)] Loss: -895.066223\n",
      "Train Epoch: 739 [9965/17352 (57%)] Loss: -1018.607832\n",
      "Train Epoch: 739 [16922/17352 (98%)] Loss: -1069.855686\n",
      "    epoch          : 739\n",
      "    loss           : -921.474716894759\n",
      "    val_loss       : -947.1311575843375\n",
      "    val_log_likelihood: 1335.5611076947182\n",
      "    val_log_marginal: 959.9610759675998\n",
      "Train Epoch: 740 [512/17352 (3%)] Loss: -984.611816\n",
      "Train Epoch: 740 [9598/17352 (55%)] Loss: -956.470306\n",
      "Train Epoch: 740 [17277/17352 (100%)] Loss: -1007.688812\n",
      "    epoch          : 740\n",
      "    loss           : -927.0204922443905\n",
      "    val_loss       : -917.3383740872995\n",
      "    val_log_likelihood: 1335.739885600678\n",
      "    val_log_marginal: 933.0708549477248\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch740.pth ...\n",
      "Train Epoch: 741 [512/17352 (3%)] Loss: -962.923828\n",
      "Train Epoch: 741 [10208/17352 (59%)] Loss: -997.254213\n",
      "Train Epoch: 741 [16992/17352 (98%)] Loss: -818.783989\n",
      "    epoch          : 741\n",
      "    loss           : -857.9327660756987\n",
      "    val_loss       : -747.729042827425\n",
      "    val_log_likelihood: 1321.0636785804993\n",
      "    val_log_marginal: 764.8974519320113\n",
      "Train Epoch: 742 [512/17352 (3%)] Loss: -820.235413\n",
      "Train Epoch: 742 [10343/17352 (60%)] Loss: -937.370468\n",
      "Train Epoch: 742 [17108/17352 (99%)] Loss: -1030.655184\n",
      "    epoch          : 742\n",
      "    loss           : -876.0288539613055\n",
      "    val_loss       : -875.2111022167967\n",
      "    val_log_likelihood: 1321.7041707381647\n",
      "    val_log_marginal: 899.9281045235253\n",
      "Train Epoch: 743 [512/17352 (3%)] Loss: -887.764221\n",
      "Train Epoch: 743 [10417/17352 (60%)] Loss: -710.661334\n",
      "Train Epoch: 743 [17153/17352 (99%)] Loss: -552.010210\n",
      "    epoch          : 743\n",
      "    loss           : -707.2089808605764\n",
      "    val_loss       : 9.392332188034056\n",
      "    val_log_likelihood: 1237.9374262904184\n",
      "    val_log_marginal: 15.951270534773906\n",
      "Train Epoch: 744 [512/17352 (3%)] Loss: -82.538300\n",
      "Train Epoch: 744 [10061/17352 (58%)] Loss: -789.077197\n",
      "Train Epoch: 744 [16923/17352 (98%)] Loss: -605.182358\n",
      "    epoch          : 744\n",
      "    loss           : -391.1598548355927\n",
      "    val_loss       : -649.0128838212006\n",
      "    val_log_likelihood: 1207.660453696352\n",
      "    val_log_marginal: 686.9698241079119\n",
      "Train Epoch: 745 [512/17352 (3%)] Loss: -620.352722\n",
      "Train Epoch: 745 [10388/17352 (60%)] Loss: -696.633909\n",
      "Train Epoch: 745 [17064/17352 (98%)] Loss: -864.067416\n",
      "    epoch          : 745\n",
      "    loss           : -721.6025086714181\n",
      "    val_loss       : -790.1441251001512\n",
      "    val_log_likelihood: 1267.3506716141837\n",
      "    val_log_marginal: 835.769606992959\n",
      "Train Epoch: 746 [512/17352 (3%)] Loss: -851.672729\n",
      "Train Epoch: 746 [9850/17352 (57%)] Loss: -925.347345\n",
      "Train Epoch: 746 [16922/17352 (98%)] Loss: -951.371575\n",
      "    epoch          : 746\n",
      "    loss           : -832.80379608801\n",
      "    val_loss       : -885.0294234166937\n",
      "    val_log_likelihood: 1295.3919143684482\n",
      "    val_log_marginal: 901.8642122035844\n",
      "Train Epoch: 747 [512/17352 (3%)] Loss: -939.094666\n",
      "Train Epoch: 747 [10165/17352 (59%)] Loss: -893.688368\n",
      "Train Epoch: 747 [17263/17352 (99%)] Loss: -1006.465665\n",
      "    epoch          : 747\n",
      "    loss           : -912.9366669682289\n",
      "    val_loss       : -932.3786248602704\n",
      "    val_log_likelihood: 1320.3506184458972\n",
      "    val_log_marginal: 948.5902429959722\n",
      "Train Epoch: 748 [512/17352 (3%)] Loss: -984.345520\n",
      "Train Epoch: 748 [9984/17352 (58%)] Loss: -904.904756\n",
      "Train Epoch: 748 [16883/17352 (97%)] Loss: -1073.347231\n",
      "    epoch          : 748\n",
      "    loss           : -944.2485457062076\n",
      "    val_loss       : -961.7558636029268\n",
      "    val_log_likelihood: 1339.57751408791\n",
      "    val_log_marginal: 975.5626482590367\n",
      "Train Epoch: 749 [512/17352 (3%)] Loss: -991.835266\n",
      "Train Epoch: 749 [10316/17352 (59%)] Loss: -937.652412\n",
      "Train Epoch: 749 [17064/17352 (98%)] Loss: -949.286487\n",
      "    epoch          : 749\n",
      "    loss           : -962.2889047289214\n",
      "    val_loss       : -965.1118305942764\n",
      "    val_log_likelihood: 1346.5330870809323\n",
      "    val_log_marginal: 976.5041211665421\n",
      "Train Epoch: 750 [512/17352 (3%)] Loss: -1007.839355\n",
      "Train Epoch: 750 [10149/17352 (58%)] Loss: -894.940138\n",
      "Train Epoch: 750 [17335/17352 (100%)] Loss: -1094.434787\n",
      "    epoch          : 750\n",
      "    loss           : -962.3299219282933\n",
      "    val_loss       : -963.0581550697244\n",
      "    val_log_likelihood: 1351.2184333467605\n",
      "    val_log_marginal: 975.0613543034989\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch750.pth ...\n",
      "Train Epoch: 751 [512/17352 (3%)] Loss: -1002.940796\n",
      "Train Epoch: 751 [10047/17352 (58%)] Loss: -991.030108\n",
      "Train Epoch: 751 [17108/17352 (99%)] Loss: -837.217719\n",
      "    epoch          : 751\n",
      "    loss           : -962.3474087133676\n",
      "    val_loss       : -956.1135461266493\n",
      "    val_log_likelihood: 1352.9197509044996\n",
      "    val_log_marginal: 969.120679776373\n",
      "Train Epoch: 752 [512/17352 (3%)] Loss: -1005.357666\n",
      "Train Epoch: 752 [10573/17352 (61%)] Loss: -1087.168403\n",
      "Train Epoch: 752 [16958/17352 (98%)] Loss: -856.054167\n",
      "    epoch          : 752\n",
      "    loss           : -958.1265376727584\n",
      "    val_loss       : -958.2102061175071\n",
      "    val_log_likelihood: 1355.8520246596293\n",
      "    val_log_marginal: 974.2213135334936\n",
      "Train Epoch: 753 [512/17352 (3%)] Loss: -1020.410461\n",
      "Train Epoch: 753 [10791/17352 (62%)] Loss: -892.157639\n",
      "Train Epoch: 753 [17153/17352 (99%)] Loss: -1049.374604\n",
      "    epoch          : 753\n",
      "    loss           : -952.9477663178554\n",
      "    val_loss       : -959.1300781297241\n",
      "    val_log_likelihood: 1350.1823268157973\n",
      "    val_log_marginal: 971.5490805149335\n",
      "Train Epoch: 754 [512/17352 (3%)] Loss: -978.619873\n",
      "Train Epoch: 754 [10652/17352 (61%)] Loss: -903.820574\n",
      "Train Epoch: 754 [16872/17352 (97%)] Loss: -1047.129668\n",
      "    epoch          : 754\n",
      "    loss           : -957.8498657939264\n",
      "    val_loss       : -966.1099889318103\n",
      "    val_log_likelihood: 1356.0102537037549\n",
      "    val_log_marginal: 980.0628300054341\n",
      "Train Epoch: 755 [512/17352 (3%)] Loss: -1006.377930\n",
      "Train Epoch: 755 [10320/17352 (59%)] Loss: -860.810643\n",
      "Train Epoch: 755 [16878/17352 (97%)] Loss: -1015.600598\n",
      "    epoch          : 755\n",
      "    loss           : -959.9734930335367\n",
      "    val_loss       : -959.9641554203805\n",
      "    val_log_likelihood: 1355.3515135845855\n",
      "    val_log_marginal: 976.4533802636505\n",
      "Train Epoch: 756 [512/17352 (3%)] Loss: -1010.302490\n",
      "Train Epoch: 756 [10112/17352 (58%)] Loss: -792.798267\n",
      "Train Epoch: 756 [17044/17352 (98%)] Loss: -994.104036\n",
      "    epoch          : 756\n",
      "    loss           : -946.7179610884874\n",
      "    val_loss       : -962.424159727841\n",
      "    val_log_likelihood: 1357.6792531337694\n",
      "    val_log_marginal: 973.9190369574198\n",
      "Train Epoch: 757 [512/17352 (3%)] Loss: -1012.202271\n",
      "Train Epoch: 757 [10547/17352 (61%)] Loss: -768.322667\n",
      "Train Epoch: 757 [16939/17352 (98%)] Loss: -995.932038\n",
      "    epoch          : 757\n",
      "    loss           : -941.420246473822\n",
      "    val_loss       : -950.5851668791034\n",
      "    val_log_likelihood: 1358.1272272702247\n",
      "    val_log_marginal: 965.4670810364421\n",
      "Train Epoch: 758 [512/17352 (3%)] Loss: -986.965271\n",
      "Train Epoch: 758 [9873/17352 (57%)] Loss: -986.063913\n",
      "Train Epoch: 758 [16878/17352 (97%)] Loss: -852.041927\n",
      "    epoch          : 758\n",
      "    loss           : -945.1776942016194\n",
      "    val_loss       : -937.1851036845909\n",
      "    val_log_likelihood: 1354.104367306793\n",
      "    val_log_marginal: 951.5387500802142\n",
      "Train Epoch: 759 [512/17352 (3%)] Loss: -808.138062\n",
      "Train Epoch: 759 [10140/17352 (58%)] Loss: -1030.468333\n",
      "Train Epoch: 759 [17263/17352 (99%)] Loss: -1056.755978\n",
      "    epoch          : 759\n",
      "    loss           : -943.9345311349105\n",
      "    val_loss       : -943.733440848096\n",
      "    val_log_likelihood: 1346.0125121615806\n",
      "    val_log_marginal: 957.810622934182\n",
      "Train Epoch: 760 [512/17352 (3%)] Loss: -988.712036\n",
      "Train Epoch: 760 [10313/17352 (59%)] Loss: -1001.154507\n",
      "Train Epoch: 760 [17016/17352 (98%)] Loss: -967.391016\n",
      "    epoch          : 760\n",
      "    loss           : -956.7321139483307\n",
      "    val_loss       : -937.6663203892939\n",
      "    val_log_likelihood: 1361.2128980875248\n",
      "    val_log_marginal: 950.4507537850149\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch760.pth ...\n",
      "Train Epoch: 761 [512/17352 (3%)] Loss: -976.291809\n",
      "Train Epoch: 761 [9684/17352 (56%)] Loss: -953.472911\n",
      "Train Epoch: 761 [16887/17352 (97%)] Loss: -861.566919\n",
      "    epoch          : 761\n",
      "    loss           : -924.3859865628393\n",
      "    val_loss       : -884.7723721673506\n",
      "    val_log_likelihood: 1303.2042548147742\n",
      "    val_log_marginal: 906.9755000599665\n",
      "Train Epoch: 762 [512/17352 (3%)] Loss: -942.181519\n",
      "Train Epoch: 762 [10801/17352 (62%)] Loss: -1028.173272\n",
      "Train Epoch: 762 [17090/17352 (98%)] Loss: -954.550263\n",
      "    epoch          : 762\n",
      "    loss           : -920.8492747049855\n",
      "    val_loss       : -914.6485913386763\n",
      "    val_log_likelihood: 1321.4854673731554\n",
      "    val_log_marginal: 937.2230528673472\n",
      "Train Epoch: 763 [512/17352 (3%)] Loss: -940.899231\n",
      "Train Epoch: 763 [11064/17352 (64%)] Loss: -1053.515458\n",
      "Train Epoch: 763 [17049/17352 (98%)] Loss: -964.489660\n",
      "    epoch          : 763\n",
      "    loss           : -939.3355091502373\n",
      "    val_loss       : -927.6340779857802\n",
      "    val_log_likelihood: 1328.4976382027278\n",
      "    val_log_marginal: 940.3416817777295\n",
      "Train Epoch: 764 [512/17352 (3%)] Loss: -984.841064\n",
      "Train Epoch: 764 [10148/17352 (58%)] Loss: -1025.635918\n",
      "Train Epoch: 764 [16922/17352 (98%)] Loss: -1036.444062\n",
      "    epoch          : 764\n",
      "    loss           : -948.3305319661596\n",
      "    val_loss       : -967.3590922737521\n",
      "    val_log_likelihood: 1358.3653113737762\n",
      "    val_log_marginal: 983.4286796708847\n",
      "Train Epoch: 765 [512/17352 (3%)] Loss: -1023.325806\n",
      "Train Epoch: 765 [10308/17352 (59%)] Loss: -1054.065665\n",
      "Train Epoch: 765 [17108/17352 (99%)] Loss: -982.074806\n",
      "    epoch          : 765\n",
      "    loss           : -958.4701974188275\n",
      "    val_loss       : -961.253704930603\n",
      "    val_log_likelihood: 1365.4078850546327\n",
      "    val_log_marginal: 980.425916118466\n",
      "Train Epoch: 766 [512/17352 (3%)] Loss: -1009.228088\n",
      "Train Epoch: 766 [10309/17352 (59%)] Loss: -910.485590\n",
      "Train Epoch: 766 [17016/17352 (98%)] Loss: -881.767699\n",
      "    epoch          : 766\n",
      "    loss           : -940.4310221779153\n",
      "    val_loss       : -886.7352536968983\n",
      "    val_log_likelihood: 1336.1801004040788\n",
      "    val_log_marginal: 950.9121458616692\n",
      "Train Epoch: 767 [512/17352 (3%)] Loss: -872.705688\n",
      "Train Epoch: 767 [9896/17352 (57%)] Loss: -690.839414\n",
      "Train Epoch: 767 [16887/17352 (97%)] Loss: -822.010759\n",
      "    epoch          : 767\n",
      "    loss           : -851.175867344843\n",
      "    val_loss       : -895.9575637055881\n",
      "    val_log_likelihood: 1310.4920905194322\n",
      "    val_log_marginal: 926.6779517215723\n",
      "Train Epoch: 768 [512/17352 (3%)] Loss: -950.525269\n",
      "Train Epoch: 768 [10405/17352 (60%)] Loss: -1052.606337\n",
      "Train Epoch: 768 [16988/17352 (98%)] Loss: -853.272482\n",
      "    epoch          : 768\n",
      "    loss           : -891.2602780461126\n",
      "    val_loss       : -928.8058486336737\n",
      "    val_log_likelihood: 1330.6557382926133\n",
      "    val_log_marginal: 947.9679868858632\n",
      "Train Epoch: 769 [512/17352 (3%)] Loss: -973.020508\n",
      "Train Epoch: 769 [9797/17352 (56%)] Loss: -878.401654\n",
      "Train Epoch: 769 [16923/17352 (98%)] Loss: -874.957536\n",
      "    epoch          : 769\n",
      "    loss           : -939.7506629662008\n",
      "    val_loss       : -971.4966891426272\n",
      "    val_log_likelihood: 1352.753872562304\n",
      "    val_log_marginal: 981.4166195472156\n",
      "Train Epoch: 770 [512/17352 (3%)] Loss: -1010.932251\n",
      "Train Epoch: 770 [10218/17352 (59%)] Loss: -1078.900499\n",
      "Train Epoch: 770 [16934/17352 (98%)] Loss: -1021.032278\n",
      "    epoch          : 770\n",
      "    loss           : -956.4137788685564\n",
      "    val_loss       : -955.1453231289648\n",
      "    val_log_likelihood: 1361.0660614257506\n",
      "    val_log_marginal: 968.5834800058382\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch770.pth ...\n",
      "Train Epoch: 771 [512/17352 (3%)] Loss: -978.027466\n",
      "Train Epoch: 771 [10096/17352 (58%)] Loss: -988.977240\n",
      "Train Epoch: 771 [17016/17352 (98%)] Loss: -898.035989\n",
      "    epoch          : 771\n",
      "    loss           : -948.7148438935114\n",
      "    val_loss       : -962.3135689763435\n",
      "    val_log_likelihood: 1362.4592170537742\n",
      "    val_log_marginal: 979.8576358987797\n",
      "Train Epoch: 772 [512/17352 (3%)] Loss: -1017.617920\n",
      "Train Epoch: 772 [10473/17352 (60%)] Loss: -762.835526\n",
      "Train Epoch: 772 [17133/17352 (99%)] Loss: -908.677548\n",
      "    epoch          : 772\n",
      "    loss           : -950.5901898739867\n",
      "    val_loss       : -945.6290124148109\n",
      "    val_log_likelihood: 1346.7476713659723\n",
      "    val_log_marginal: 957.6076949178545\n",
      "Train Epoch: 773 [512/17352 (3%)] Loss: -990.529175\n",
      "Train Epoch: 773 [10736/17352 (62%)] Loss: -1051.545570\n",
      "Train Epoch: 773 [17253/17352 (99%)] Loss: -835.755105\n",
      "    epoch          : 773\n",
      "    loss           : -953.9016665240089\n",
      "    val_loss       : -939.9925627688474\n",
      "    val_log_likelihood: 1351.545845802266\n",
      "    val_log_marginal: 954.1886474081276\n",
      "Train Epoch: 774 [512/17352 (3%)] Loss: -978.159668\n",
      "Train Epoch: 774 [10389/17352 (60%)] Loss: -1051.917925\n",
      "Train Epoch: 774 [16988/17352 (98%)] Loss: -916.603548\n",
      "    epoch          : 774\n",
      "    loss           : -963.3800725976383\n",
      "    val_loss       : -965.3306380288146\n",
      "    val_log_likelihood: 1363.7741843130807\n",
      "    val_log_marginal: 977.6406900380196\n",
      "Train Epoch: 775 [512/17352 (3%)] Loss: -994.966248\n",
      "Train Epoch: 775 [10113/17352 (58%)] Loss: -1010.149069\n",
      "Train Epoch: 775 [16872/17352 (97%)] Loss: -751.853441\n",
      "    epoch          : 775\n",
      "    loss           : -920.8675098593878\n",
      "    val_loss       : -855.8747082974113\n",
      "    val_log_likelihood: 1329.7161201372035\n",
      "    val_log_marginal: 869.3467258452608\n",
      "Train Epoch: 776 [512/17352 (3%)] Loss: -904.024475\n",
      "Train Epoch: 776 [10299/17352 (59%)] Loss: -593.463449\n",
      "Train Epoch: 776 [17124/17352 (99%)] Loss: -745.569553\n",
      "    epoch          : 776\n",
      "    loss           : -629.1545632653335\n",
      "    val_loss       : 238.68472871591715\n",
      "    val_log_likelihood: 1203.1433772605044\n",
      "    val_log_marginal: -215.21948960566885\n",
      "Train Epoch: 777 [512/17352 (3%)] Loss: 176.899689\n",
      "Train Epoch: 777 [10008/17352 (58%)] Loss: -449.996985\n",
      "Train Epoch: 777 [16988/17352 (98%)] Loss: -871.698351\n",
      "    epoch          : 777\n",
      "    loss           : -506.67599710259054\n",
      "    val_loss       : -768.8499186400926\n",
      "    val_log_likelihood: 1222.5514359277952\n",
      "    val_log_marginal: 810.1729644761824\n",
      "Train Epoch: 778 [512/17352 (3%)] Loss: -757.139404\n",
      "Train Epoch: 778 [10544/17352 (61%)] Loss: -907.111801\n",
      "Train Epoch: 778 [17143/17352 (99%)] Loss: -656.025538\n",
      "    epoch          : 778\n",
      "    loss           : -835.6648598464507\n",
      "    val_loss       : -801.8544264054382\n",
      "    val_log_likelihood: 1249.4897995487097\n",
      "    val_log_marginal: 827.6535897385637\n",
      "Train Epoch: 779 [512/17352 (3%)] Loss: -683.615479\n",
      "Train Epoch: 779 [10246/17352 (59%)] Loss: -918.596220\n",
      "Train Epoch: 779 [17064/17352 (98%)] Loss: -929.782604\n",
      "    epoch          : 779\n",
      "    loss           : -860.4706047412132\n",
      "    val_loss       : -908.4767470175199\n",
      "    val_log_likelihood: 1298.2415942482864\n",
      "    val_log_marginal: 926.7651695919609\n",
      "Train Epoch: 780 [512/17352 (3%)] Loss: -948.596924\n",
      "Train Epoch: 780 [9886/17352 (57%)] Loss: -902.566852\n",
      "Train Epoch: 780 [16882/17352 (97%)] Loss: -990.992933\n",
      "    epoch          : 780\n",
      "    loss           : -923.3155164070655\n",
      "    val_loss       : -943.8205405853923\n",
      "    val_log_likelihood: 1335.5146371811136\n",
      "    val_log_marginal: 964.4670584364297\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch780.pth ...\n",
      "Train Epoch: 781 [512/17352 (3%)] Loss: -988.004028\n",
      "Train Epoch: 781 [10496/17352 (60%)] Loss: -1013.425000\n",
      "Train Epoch: 781 [16887/17352 (97%)] Loss: -1045.433160\n",
      "    epoch          : 781\n",
      "    loss           : -937.2976085792353\n",
      "    val_loss       : -947.1136920873804\n",
      "    val_log_likelihood: 1345.3131511181655\n",
      "    val_log_marginal: 967.0389133656298\n",
      "Train Epoch: 782 [512/17352 (3%)] Loss: -989.788818\n",
      "Train Epoch: 782 [10137/17352 (58%)] Loss: -1049.167671\n",
      "Train Epoch: 782 [16887/17352 (97%)] Loss: -1011.060508\n",
      "    epoch          : 782\n",
      "    loss           : -949.9038331980772\n",
      "    val_loss       : -945.5321017865521\n",
      "    val_log_likelihood: 1340.180811224722\n",
      "    val_log_marginal: 959.0674121691021\n",
      "Train Epoch: 783 [512/17352 (3%)] Loss: -997.315979\n",
      "Train Epoch: 783 [10280/17352 (59%)] Loss: -1008.780197\n",
      "Train Epoch: 783 [17143/17352 (99%)] Loss: -774.998387\n",
      "    epoch          : 783\n",
      "    loss           : -959.1477900686906\n",
      "    val_loss       : -969.1385915589809\n",
      "    val_log_likelihood: 1360.9116378719973\n",
      "    val_log_marginal: 982.2993581263132\n",
      "Train Epoch: 784 [512/17352 (3%)] Loss: -1012.400146\n",
      "Train Epoch: 784 [10562/17352 (61%)] Loss: -1057.508710\n",
      "Train Epoch: 784 [17143/17352 (99%)] Loss: -900.553199\n",
      "    epoch          : 784\n",
      "    loss           : -958.0864612780755\n",
      "    val_loss       : -959.594985514882\n",
      "    val_log_likelihood: 1355.5708628396194\n",
      "    val_log_marginal: 977.4971169449819\n",
      "Train Epoch: 785 [512/17352 (3%)] Loss: -1005.348755\n",
      "Train Epoch: 785 [10505/17352 (61%)] Loss: -919.116825\n",
      "Train Epoch: 785 [16988/17352 (98%)] Loss: -1067.326347\n",
      "    epoch          : 785\n",
      "    loss           : -967.1843898331932\n",
      "    val_loss       : -972.7457368363766\n",
      "    val_log_likelihood: 1365.9764013607441\n",
      "    val_log_marginal: 987.5566749146828\n",
      "Train Epoch: 786 [512/17352 (3%)] Loss: -993.234192\n",
      "Train Epoch: 786 [9958/17352 (57%)] Loss: -1017.926606\n",
      "Train Epoch: 786 [16957/17352 (98%)] Loss: -1041.952180\n",
      "    epoch          : 786\n",
      "    loss           : -974.7004921763922\n",
      "    val_loss       : -982.4090132139476\n",
      "    val_log_likelihood: 1372.1096438579182\n",
      "    val_log_marginal: 995.8939008547588\n",
      "Train Epoch: 787 [512/17352 (3%)] Loss: -1029.207031\n",
      "Train Epoch: 787 [10350/17352 (60%)] Loss: -791.042809\n",
      "Train Epoch: 787 [16934/17352 (98%)] Loss: -893.666590\n",
      "    epoch          : 787\n",
      "    loss           : -962.081162623331\n",
      "    val_loss       : -950.875314905805\n",
      "    val_log_likelihood: 1350.1670699548602\n",
      "    val_log_marginal: 968.2075936047728\n",
      "Train Epoch: 788 [512/17352 (3%)] Loss: -987.555176\n",
      "Train Epoch: 788 [10037/17352 (58%)] Loss: -827.108653\n",
      "Train Epoch: 788 [16887/17352 (97%)] Loss: -797.318929\n",
      "    epoch          : 788\n",
      "    loss           : -954.1177268003013\n",
      "    val_loss       : -964.387396936209\n",
      "    val_log_likelihood: 1360.3280165550134\n",
      "    val_log_marginal: 983.9747686544624\n",
      "Train Epoch: 789 [512/17352 (3%)] Loss: -1019.081970\n",
      "Train Epoch: 789 [10208/17352 (59%)] Loss: -821.287644\n",
      "Train Epoch: 789 [17064/17352 (98%)] Loss: -890.521772\n",
      "    epoch          : 789\n",
      "    loss           : -927.165346697352\n",
      "    val_loss       : -872.4260033933675\n",
      "    val_log_likelihood: 1334.181342044858\n",
      "    val_log_marginal: 928.3445569349726\n",
      "Train Epoch: 790 [512/17352 (3%)] Loss: -904.523621\n",
      "Train Epoch: 790 [10409/17352 (60%)] Loss: -1018.704752\n",
      "Train Epoch: 790 [17124/17352 (99%)] Loss: -827.179975\n",
      "    epoch          : 790\n",
      "    loss           : -907.4101584402855\n",
      "    val_loss       : -912.0892187142497\n",
      "    val_log_likelihood: 1331.7607326327839\n",
      "    val_log_marginal: 943.1235861205349\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch790.pth ...\n",
      "Train Epoch: 791 [512/17352 (3%)] Loss: -981.530579\n",
      "Train Epoch: 791 [10429/17352 (60%)] Loss: -982.630946\n",
      "Train Epoch: 791 [17064/17352 (98%)] Loss: -1018.274564\n",
      "    epoch          : 791\n",
      "    loss           : -943.0884482481173\n",
      "    val_loss       : -951.2323050903865\n",
      "    val_log_likelihood: 1350.6234030303926\n",
      "    val_log_marginal: 972.2250352487514\n",
      "Train Epoch: 792 [512/17352 (3%)] Loss: -981.988281\n",
      "Train Epoch: 792 [10640/17352 (61%)] Loss: -773.962769\n",
      "Train Epoch: 792 [16883/17352 (97%)] Loss: -1080.591688\n",
      "    epoch          : 792\n",
      "    loss           : -930.7014590304959\n",
      "    val_loss       : -967.7630199437838\n",
      "    val_log_likelihood: 1360.048861087899\n",
      "    val_log_marginal: 982.058858478508\n",
      "Train Epoch: 793 [512/17352 (3%)] Loss: -1016.348267\n",
      "Train Epoch: 793 [10460/17352 (60%)] Loss: -829.066471\n",
      "Train Epoch: 793 [16878/17352 (97%)] Loss: -579.871112\n",
      "    epoch          : 793\n",
      "    loss           : -894.3026844432868\n",
      "    val_loss       : -841.1474361794815\n",
      "    val_log_likelihood: 1342.1616168351836\n",
      "    val_log_marginal: 857.1585486086665\n",
      "Train Epoch: 794 [512/17352 (3%)] Loss: -904.926636\n",
      "Train Epoch: 794 [9971/17352 (57%)] Loss: -960.546835\n",
      "Train Epoch: 794 [17263/17352 (99%)] Loss: -999.165714\n",
      "    epoch          : 794\n",
      "    loss           : -834.2180315549201\n",
      "    val_loss       : -900.2275021894395\n",
      "    val_log_likelihood: 1323.9957484588915\n",
      "    val_log_marginal: 928.4525762425179\n",
      "Train Epoch: 795 [512/17352 (3%)] Loss: -937.498779\n",
      "Train Epoch: 795 [9937/17352 (57%)] Loss: -943.318687\n",
      "Train Epoch: 795 [16957/17352 (98%)] Loss: -725.733122\n",
      "    epoch          : 795\n",
      "    loss           : -860.4482379130274\n",
      "    val_loss       : -826.4143851162105\n",
      "    val_log_likelihood: 1332.4494423314763\n",
      "    val_log_marginal: 839.0181568832711\n",
      "Train Epoch: 796 [512/17352 (3%)] Loss: -883.449890\n",
      "Train Epoch: 796 [10240/17352 (59%)] Loss: -805.400551\n",
      "Train Epoch: 796 [16922/17352 (98%)] Loss: -827.726905\n",
      "    epoch          : 796\n",
      "    loss           : -856.1800199672855\n",
      "    val_loss       : -867.8955296657123\n",
      "    val_log_likelihood: 1273.2182969841306\n",
      "    val_log_marginal: 885.1939172023347\n",
      "Train Epoch: 797 [512/17352 (3%)] Loss: -929.605896\n",
      "Train Epoch: 797 [10382/17352 (60%)] Loss: -1012.308036\n",
      "Train Epoch: 797 [17263/17352 (99%)] Loss: -850.223631\n",
      "    epoch          : 797\n",
      "    loss           : -907.0929155439619\n",
      "    val_loss       : -938.8123101438497\n",
      "    val_log_likelihood: 1341.0663706479088\n",
      "    val_log_marginal: 949.7867535106302\n",
      "Train Epoch: 798 [512/17352 (3%)] Loss: -983.072083\n",
      "Train Epoch: 798 [9889/17352 (57%)] Loss: -1031.648921\n",
      "Train Epoch: 798 [17101/17352 (99%)] Loss: -1037.496361\n",
      "    epoch          : 798\n",
      "    loss           : -946.2962632145283\n",
      "    val_loss       : -967.8346507902985\n",
      "    val_log_likelihood: 1355.804965097007\n",
      "    val_log_marginal: 979.7004127950131\n",
      "Train Epoch: 799 [512/17352 (3%)] Loss: -997.751343\n",
      "Train Epoch: 799 [10312/17352 (59%)] Loss: -1008.136621\n",
      "Train Epoch: 799 [17044/17352 (98%)] Loss: -1064.860047\n",
      "    epoch          : 799\n",
      "    loss           : -969.6110483398512\n",
      "    val_loss       : -976.1589926512486\n",
      "    val_log_likelihood: 1363.3574256692298\n",
      "    val_log_marginal: 986.7846206396955\n",
      "Train Epoch: 800 [512/17352 (3%)] Loss: -1007.240845\n",
      "Train Epoch: 800 [9967/17352 (57%)] Loss: -1017.001492\n",
      "Train Epoch: 800 [16872/17352 (97%)] Loss: -932.427431\n",
      "    epoch          : 800\n",
      "    loss           : -973.0040381933634\n",
      "    val_loss       : -976.6906175321077\n",
      "    val_log_likelihood: 1369.4399703693691\n",
      "    val_log_marginal: 985.7080369062867\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch800.pth ...\n",
      "Train Epoch: 801 [512/17352 (3%)] Loss: -1007.976929\n",
      "Train Epoch: 801 [10313/17352 (59%)] Loss: -1064.058263\n",
      "Train Epoch: 801 [16988/17352 (98%)] Loss: -646.403539\n",
      "    epoch          : 801\n",
      "    loss           : -929.4650256558331\n",
      "    val_loss       : -789.531670301131\n",
      "    val_log_likelihood: 1351.43437505993\n",
      "    val_log_marginal: 797.7769106704015\n",
      "Train Epoch: 802 [512/17352 (3%)] Loss: -881.139709\n",
      "Train Epoch: 802 [10542/17352 (61%)] Loss: -1046.593316\n",
      "Train Epoch: 802 [17335/17352 (100%)] Loss: -711.627766\n",
      "    epoch          : 802\n",
      "    loss           : -882.9826589305907\n",
      "    val_loss       : -942.2794006237131\n",
      "    val_log_likelihood: 1351.7470461169034\n",
      "    val_log_marginal: 961.3120346391123\n",
      "Train Epoch: 803 [512/17352 (3%)] Loss: -990.501953\n",
      "Train Epoch: 803 [10501/17352 (61%)] Loss: -869.279777\n",
      "Train Epoch: 803 [17106/17352 (99%)] Loss: -895.104496\n",
      "    epoch          : 803\n",
      "    loss           : -940.5915202890448\n",
      "    val_loss       : -941.6270151800965\n",
      "    val_log_likelihood: 1355.1926758395955\n",
      "    val_log_marginal: 952.5898590132157\n",
      "Train Epoch: 804 [512/17352 (3%)] Loss: -968.218018\n",
      "Train Epoch: 804 [10791/17352 (62%)] Loss: -867.611632\n",
      "Train Epoch: 804 [17253/17352 (99%)] Loss: -1031.646708\n",
      "    epoch          : 804\n",
      "    loss           : -962.954149410269\n",
      "    val_loss       : -975.400379456819\n",
      "    val_log_likelihood: 1368.1080337364635\n",
      "    val_log_marginal: 986.8721949336314\n",
      "Train Epoch: 805 [512/17352 (3%)] Loss: -1008.141113\n",
      "Train Epoch: 805 [10020/17352 (58%)] Loss: -918.632066\n",
      "Train Epoch: 805 [16872/17352 (97%)] Loss: -901.795466\n",
      "    epoch          : 805\n",
      "    loss           : -976.7202313696205\n",
      "    val_loss       : -978.293890201573\n",
      "    val_log_likelihood: 1376.4043244175007\n",
      "    val_log_marginal: 990.0830245956403\n",
      "Train Epoch: 806 [512/17352 (3%)] Loss: -1017.280029\n",
      "Train Epoch: 806 [10221/17352 (59%)] Loss: -859.117471\n",
      "Train Epoch: 806 [17126/17352 (99%)] Loss: -858.776078\n",
      "    epoch          : 806\n",
      "    loss           : -966.7890155118204\n",
      "    val_loss       : -947.2577564039793\n",
      "    val_log_likelihood: 1355.0718841023447\n",
      "    val_log_marginal: 958.3921084783917\n",
      "Train Epoch: 807 [512/17352 (3%)] Loss: -981.339600\n",
      "Train Epoch: 807 [9749/17352 (56%)] Loss: -1103.781467\n",
      "Train Epoch: 807 [16882/17352 (97%)] Loss: -1021.314856\n",
      "    epoch          : 807\n",
      "    loss           : -967.6645243425922\n",
      "    val_loss       : -986.2405284522553\n",
      "    val_log_likelihood: 1378.1007290496057\n",
      "    val_log_marginal: 997.9741682936635\n",
      "Train Epoch: 808 [512/17352 (3%)] Loss: -1010.502747\n",
      "Train Epoch: 808 [10617/17352 (61%)] Loss: -908.790150\n",
      "Train Epoch: 808 [16883/17352 (97%)] Loss: -981.030060\n",
      "    epoch          : 808\n",
      "    loss           : -953.2765247677977\n",
      "    val_loss       : -921.2760499362242\n",
      "    val_log_likelihood: 1366.6276676617583\n",
      "    val_log_marginal: 933.4705459091682\n",
      "Train Epoch: 809 [512/17352 (3%)] Loss: -957.817749\n",
      "Train Epoch: 809 [10640/17352 (61%)] Loss: -933.342101\n",
      "Train Epoch: 809 [17253/17352 (99%)] Loss: -973.746124\n",
      "    epoch          : 809\n",
      "    loss           : -951.203327772562\n",
      "    val_loss       : -898.4107419037712\n",
      "    val_log_likelihood: 1337.5020862346826\n",
      "    val_log_marginal: 919.6123847796783\n",
      "Train Epoch: 810 [512/17352 (3%)] Loss: -920.683228\n",
      "Train Epoch: 810 [10847/17352 (63%)] Loss: -585.772581\n",
      "Train Epoch: 810 [17090/17352 (98%)] Loss: -814.168289\n",
      "    epoch          : 810\n",
      "    loss           : -847.8387759724468\n",
      "    val_loss       : -655.4265680444088\n",
      "    val_log_likelihood: 1331.2708112897174\n",
      "    val_log_marginal: 685.8147353424456\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch810.pth ...\n",
      "Train Epoch: 811 [512/17352 (3%)] Loss: -722.576965\n",
      "Train Epoch: 811 [9996/17352 (58%)] Loss: -858.134785\n",
      "Train Epoch: 811 [16923/17352 (98%)] Loss: -535.800015\n",
      "    epoch          : 811\n",
      "    loss           : -866.0720254488435\n",
      "    val_loss       : -853.4368921930445\n",
      "    val_log_likelihood: 1332.2196853051341\n",
      "    val_log_marginal: 871.9062778708862\n",
      "Train Epoch: 812 [512/17352 (3%)] Loss: -900.449463\n",
      "Train Epoch: 812 [10465/17352 (60%)] Loss: -749.105712\n",
      "Train Epoch: 812 [16872/17352 (97%)] Loss: -695.254423\n",
      "    epoch          : 812\n",
      "    loss           : -855.6647352888034\n",
      "    val_loss       : -935.8444059016401\n",
      "    val_log_likelihood: 1354.852282662229\n",
      "    val_log_marginal: 950.5069401149606\n",
      "Train Epoch: 813 [512/17352 (3%)] Loss: -978.802002\n",
      "Train Epoch: 813 [9963/17352 (57%)] Loss: -886.060387\n",
      "Train Epoch: 813 [17106/17352 (99%)] Loss: -941.256487\n",
      "    epoch          : 813\n",
      "    loss           : -805.372580578915\n",
      "    val_loss       : -877.7381681274386\n",
      "    val_log_likelihood: 1300.5346848564575\n",
      "    val_log_marginal: 893.8978277348731\n",
      "Train Epoch: 814 [512/17352 (3%)] Loss: -685.868225\n",
      "Train Epoch: 814 [10400/17352 (60%)] Loss: -866.407812\n",
      "Train Epoch: 814 [16957/17352 (98%)] Loss: -898.463405\n",
      "    epoch          : 814\n",
      "    loss           : -912.2118896087486\n",
      "    val_loss       : -937.0488734633884\n",
      "    val_log_likelihood: 1350.2832231979546\n",
      "    val_log_marginal: 946.5211779454265\n",
      "Train Epoch: 815 [512/17352 (3%)] Loss: -978.430298\n",
      "Train Epoch: 815 [10383/17352 (60%)] Loss: -1005.679781\n",
      "Train Epoch: 815 [17143/17352 (99%)] Loss: -1025.648854\n",
      "    epoch          : 815\n",
      "    loss           : -925.5159912669318\n",
      "    val_loss       : -862.264247100362\n",
      "    val_log_likelihood: 1334.0971937883662\n",
      "    val_log_marginal: 879.1181560743659\n",
      "Train Epoch: 816 [512/17352 (3%)] Loss: -917.683960\n",
      "Train Epoch: 816 [10125/17352 (58%)] Loss: -1024.065168\n",
      "Train Epoch: 816 [17263/17352 (99%)] Loss: -960.479167\n",
      "    epoch          : 816\n",
      "    loss           : -929.7667695815451\n",
      "    val_loss       : -943.150933649178\n",
      "    val_log_likelihood: 1353.9460705892013\n",
      "    val_log_marginal: 955.7001529107577\n",
      "Train Epoch: 817 [512/17352 (3%)] Loss: -1005.142273\n",
      "Train Epoch: 817 [10196/17352 (59%)] Loss: -1010.028387\n",
      "Train Epoch: 817 [17253/17352 (99%)] Loss: -917.183780\n",
      "    epoch          : 817\n",
      "    loss           : -961.9004584336014\n",
      "    val_loss       : -920.3793169340106\n",
      "    val_log_likelihood: 1372.1597078148181\n",
      "    val_log_marginal: 935.8542963803659\n",
      "Train Epoch: 818 [512/17352 (3%)] Loss: -985.178467\n",
      "Train Epoch: 818 [10752/17352 (62%)] Loss: -833.917122\n",
      "Train Epoch: 818 [17126/17352 (99%)] Loss: -664.191016\n",
      "    epoch          : 818\n",
      "    loss           : -793.2302279282206\n",
      "    val_loss       : -631.8778839018485\n",
      "    val_log_likelihood: 1265.127796494858\n",
      "    val_log_marginal: 661.7088092401\n",
      "Train Epoch: 819 [512/17352 (3%)] Loss: -289.932281\n",
      "Train Epoch: 819 [10816/17352 (62%)] Loss: -932.737800\n",
      "Train Epoch: 819 [17101/17352 (99%)] Loss: -839.038806\n",
      "    epoch          : 819\n",
      "    loss           : -824.2089139737619\n",
      "    val_loss       : -880.4578710648193\n",
      "    val_log_likelihood: 1318.4383380658771\n",
      "    val_log_marginal: 893.892037319984\n",
      "Train Epoch: 820 [512/17352 (3%)] Loss: -856.075073\n",
      "Train Epoch: 820 [9980/17352 (58%)] Loss: -824.492001\n",
      "Train Epoch: 820 [17049/17352 (98%)] Loss: -979.234589\n",
      "    epoch          : 820\n",
      "    loss           : -922.776628731296\n",
      "    val_loss       : -945.7218844740984\n",
      "    val_log_likelihood: 1358.8702324006379\n",
      "    val_log_marginal: 958.4431464591208\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch820.pth ...\n",
      "Train Epoch: 821 [512/17352 (3%)] Loss: -983.344971\n",
      "Train Epoch: 821 [9997/17352 (58%)] Loss: -1026.515208\n",
      "Train Epoch: 821 [17124/17352 (99%)] Loss: -986.531960\n",
      "    epoch          : 821\n",
      "    loss           : -968.1754585185396\n",
      "    val_loss       : -973.1732992784374\n",
      "    val_log_likelihood: 1368.8870081953337\n",
      "    val_log_marginal: 987.5898149701788\n",
      "Train Epoch: 822 [512/17352 (3%)] Loss: -1008.853394\n",
      "Train Epoch: 822 [10477/17352 (60%)] Loss: -1074.836486\n",
      "Train Epoch: 822 [16887/17352 (97%)] Loss: -933.073611\n",
      "    epoch          : 822\n",
      "    loss           : -974.9009105288976\n",
      "    val_loss       : -986.8261146771038\n",
      "    val_log_likelihood: 1379.8415751270977\n",
      "    val_log_marginal: 998.6434812407554\n",
      "Train Epoch: 823 [512/17352 (3%)] Loss: -1027.857544\n",
      "Train Epoch: 823 [10780/17352 (62%)] Loss: -1083.079558\n",
      "Train Epoch: 823 [17108/17352 (99%)] Loss: -1075.171361\n",
      "    epoch          : 823\n",
      "    loss           : -975.4872248202455\n",
      "    val_loss       : -976.5085744327946\n",
      "    val_log_likelihood: 1381.6039139479592\n",
      "    val_log_marginal: 989.7314816989383\n",
      "Train Epoch: 824 [512/17352 (3%)] Loss: -1018.457764\n",
      "Train Epoch: 824 [10380/17352 (60%)] Loss: -746.656183\n",
      "Train Epoch: 824 [16939/17352 (98%)] Loss: -901.392681\n",
      "    epoch          : 824\n",
      "    loss           : -963.7051446618336\n",
      "    val_loss       : -963.7554213882536\n",
      "    val_log_likelihood: 1384.4559113943064\n",
      "    val_log_marginal: 977.2232629690108\n",
      "Train Epoch: 825 [512/17352 (3%)] Loss: -1004.068726\n",
      "Train Epoch: 825 [10078/17352 (58%)] Loss: -680.585654\n",
      "Train Epoch: 825 [17126/17352 (99%)] Loss: -933.073059\n",
      "    epoch          : 825\n",
      "    loss           : -881.1630470291727\n",
      "    val_loss       : -880.6004612493053\n",
      "    val_log_likelihood: 1310.9758236956031\n",
      "    val_log_marginal: 903.5292097296143\n",
      "Train Epoch: 826 [512/17352 (3%)] Loss: -922.138550\n",
      "Train Epoch: 826 [10029/17352 (58%)] Loss: -850.837103\n",
      "Train Epoch: 826 [17253/17352 (99%)] Loss: -845.520833\n",
      "    epoch          : 826\n",
      "    loss           : -896.5208791088515\n",
      "    val_loss       : -843.6005809363237\n",
      "    val_log_likelihood: 1304.1112449677823\n",
      "    val_log_marginal: 867.0168093254974\n",
      "Train Epoch: 827 [512/17352 (3%)] Loss: -867.945862\n",
      "Train Epoch: 827 [10049/17352 (58%)] Loss: -941.101799\n",
      "Train Epoch: 827 [17143/17352 (99%)] Loss: -994.851599\n",
      "    epoch          : 827\n",
      "    loss           : -905.6239803120834\n",
      "    val_loss       : -926.0894693833931\n",
      "    val_log_likelihood: 1361.5510116472772\n",
      "    val_log_marginal: 953.1956381999188\n",
      "Train Epoch: 828 [512/17352 (3%)] Loss: -977.102661\n",
      "Train Epoch: 828 [9880/17352 (57%)] Loss: -763.167520\n",
      "Train Epoch: 828 [17263/17352 (99%)] Loss: 229.433637\n",
      "    epoch          : 828\n",
      "    loss           : -855.1120314145003\n",
      "    val_loss       : -549.0393880833667\n",
      "    val_log_likelihood: 1306.6575463257925\n",
      "    val_log_marginal: 569.792347364477\n",
      "Train Epoch: 829 [512/17352 (3%)] Loss: -585.084412\n",
      "Train Epoch: 829 [10166/17352 (59%)] Loss: -734.280097\n",
      "Train Epoch: 829 [17044/17352 (98%)] Loss: -1018.734256\n",
      "    epoch          : 829\n",
      "    loss           : -887.7955419264638\n",
      "    val_loss       : -954.9093161563569\n",
      "    val_log_likelihood: 1350.0166833168632\n",
      "    val_log_marginal: 974.7155762869704\n",
      "Train Epoch: 830 [512/17352 (3%)] Loss: -983.794006\n",
      "Train Epoch: 830 [10017/17352 (58%)] Loss: -997.516559\n",
      "Train Epoch: 830 [16922/17352 (98%)] Loss: -1003.033283\n",
      "    epoch          : 830\n",
      "    loss           : -941.0283970495932\n",
      "    val_loss       : -942.012137686678\n",
      "    val_log_likelihood: 1370.317888212909\n",
      "    val_log_marginal: 962.3610474573575\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch830.pth ...\n",
      "Train Epoch: 831 [512/17352 (3%)] Loss: -964.732605\n",
      "Train Epoch: 831 [9669/17352 (56%)] Loss: -997.750000\n",
      "Train Epoch: 831 [17277/17352 (100%)] Loss: -766.994431\n",
      "    epoch          : 831\n",
      "    loss           : -941.3825742249481\n",
      "    val_loss       : -940.8445367087971\n",
      "    val_log_likelihood: 1368.914323298842\n",
      "    val_log_marginal: 962.0261302904263\n",
      "Train Epoch: 832 [512/17352 (3%)] Loss: -975.113159\n",
      "Train Epoch: 832 [10160/17352 (59%)] Loss: -1001.428038\n",
      "Train Epoch: 832 [16923/17352 (98%)] Loss: -922.974095\n",
      "    epoch          : 832\n",
      "    loss           : -952.3948328096513\n",
      "    val_loss       : -919.0406470776019\n",
      "    val_log_likelihood: 1341.307656757879\n",
      "    val_log_marginal: 951.2132778676311\n",
      "Train Epoch: 833 [512/17352 (3%)] Loss: -965.792419\n",
      "Train Epoch: 833 [10235/17352 (59%)] Loss: -820.075672\n",
      "Train Epoch: 833 [16872/17352 (97%)] Loss: -1020.039616\n",
      "    epoch          : 833\n",
      "    loss           : -968.4556306713275\n",
      "    val_loss       : -985.8368111206428\n",
      "    val_log_likelihood: 1381.8277374432625\n",
      "    val_log_marginal: 1001.9740341256742\n",
      "Train Epoch: 834 [512/17352 (3%)] Loss: -1025.376465\n",
      "Train Epoch: 834 [10619/17352 (61%)] Loss: -875.944274\n",
      "Train Epoch: 834 [17108/17352 (99%)] Loss: -1087.806903\n",
      "    epoch          : 834\n",
      "    loss           : -983.8430812820438\n",
      "    val_loss       : -988.7987449470085\n",
      "    val_log_likelihood: 1387.364440576352\n",
      "    val_log_marginal: 1002.5813359476916\n",
      "Train Epoch: 835 [512/17352 (3%)] Loss: -1035.994995\n",
      "Train Epoch: 835 [10142/17352 (58%)] Loss: -1018.146433\n",
      "Train Epoch: 835 [16988/17352 (98%)] Loss: -1036.878710\n",
      "    epoch          : 835\n",
      "    loss           : -989.0064469327816\n",
      "    val_loss       : -996.6337082977174\n",
      "    val_log_likelihood: 1392.7196844051978\n",
      "    val_log_marginal: 1009.0821372504721\n",
      "Train Epoch: 836 [512/17352 (3%)] Loss: -817.023682\n",
      "Train Epoch: 836 [10338/17352 (60%)] Loss: -1038.991174\n",
      "Train Epoch: 836 [16939/17352 (98%)] Loss: -1045.115698\n",
      "    epoch          : 836\n",
      "    loss           : -986.0981444777611\n",
      "    val_loss       : -988.6032096657765\n",
      "    val_log_likelihood: 1395.0890512225185\n",
      "    val_log_marginal: 1003.6734764752272\n",
      "Train Epoch: 837 [512/17352 (3%)] Loss: -815.260986\n",
      "Train Epoch: 837 [10634/17352 (61%)] Loss: -1030.513607\n",
      "Train Epoch: 837 [17064/17352 (98%)] Loss: -1078.640259\n",
      "    epoch          : 837\n",
      "    loss           : -979.2845737240738\n",
      "    val_loss       : -987.354513223848\n",
      "    val_log_likelihood: 1388.7545586230212\n",
      "    val_log_marginal: 1000.1438782826003\n",
      "Train Epoch: 838 [512/17352 (3%)] Loss: -1024.517456\n",
      "Train Epoch: 838 [10089/17352 (58%)] Loss: -1127.231337\n",
      "Train Epoch: 838 [17049/17352 (98%)] Loss: -1071.651424\n",
      "    epoch          : 838\n",
      "    loss           : -987.500918858565\n",
      "    val_loss       : -993.8871912047742\n",
      "    val_log_likelihood: 1396.7227926616576\n",
      "    val_log_marginal: 1007.1282548822115\n",
      "Train Epoch: 839 [512/17352 (3%)] Loss: -1035.378906\n",
      "Train Epoch: 839 [10711/17352 (62%)] Loss: -885.983601\n",
      "Train Epoch: 839 [16872/17352 (97%)] Loss: -1105.923956\n",
      "    epoch          : 839\n",
      "    loss           : -994.3253090795833\n",
      "    val_loss       : -996.1190159865864\n",
      "    val_log_likelihood: 1396.2409663374904\n",
      "    val_log_marginal: 1007.085768515694\n",
      "Train Epoch: 840 [512/17352 (3%)] Loss: -1042.674072\n",
      "Train Epoch: 840 [10265/17352 (59%)] Loss: -774.371545\n",
      "Train Epoch: 840 [17108/17352 (99%)] Loss: -994.242602\n",
      "    epoch          : 840\n",
      "    loss           : -972.9225505388065\n",
      "    val_loss       : -973.7437889333601\n",
      "    val_log_likelihood: 1383.5914401318928\n",
      "    val_log_marginal: 993.5266333363317\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch840.pth ...\n",
      "Train Epoch: 841 [512/17352 (3%)] Loss: -1022.354492\n",
      "Train Epoch: 841 [10464/17352 (60%)] Loss: -913.703389\n",
      "Train Epoch: 841 [16988/17352 (98%)] Loss: -808.059734\n",
      "    epoch          : 841\n",
      "    loss           : -959.4072735510683\n",
      "    val_loss       : -856.7705750765393\n",
      "    val_log_likelihood: 1300.3793311685397\n",
      "    val_log_marginal: 875.8250355251879\n",
      "Train Epoch: 842 [512/17352 (3%)] Loss: -771.858276\n",
      "Train Epoch: 842 [10342/17352 (60%)] Loss: -1022.331171\n",
      "Train Epoch: 842 [17090/17352 (98%)] Loss: -845.213752\n",
      "    epoch          : 842\n",
      "    loss           : -925.4707349117069\n",
      "    val_loss       : -889.3337749576134\n",
      "    val_log_likelihood: 1323.18540733282\n",
      "    val_log_marginal: 907.3697393385237\n",
      "Train Epoch: 843 [512/17352 (3%)] Loss: -930.789734\n",
      "Train Epoch: 843 [10810/17352 (62%)] Loss: -880.280134\n",
      "Train Epoch: 843 [17049/17352 (98%)] Loss: -852.713020\n",
      "    epoch          : 843\n",
      "    loss           : -858.2878294231264\n",
      "    val_loss       : -770.323186956422\n",
      "    val_log_likelihood: 1216.3950262854312\n",
      "    val_log_marginal: 805.1354475943801\n",
      "Train Epoch: 844 [512/17352 (3%)] Loss: -757.217957\n",
      "Train Epoch: 844 [10570/17352 (61%)] Loss: -995.299684\n",
      "Train Epoch: 844 [17064/17352 (98%)] Loss: -836.051486\n",
      "    epoch          : 844\n",
      "    loss           : -885.5151329718024\n",
      "    val_loss       : -939.9310690476099\n",
      "    val_log_likelihood: 1330.4092027173726\n",
      "    val_log_marginal: 958.2759867118382\n",
      "Train Epoch: 845 [512/17352 (3%)] Loss: -964.022461\n",
      "Train Epoch: 845 [9464/17352 (55%)] Loss: -986.081703\n",
      "Train Epoch: 845 [16922/17352 (98%)] Loss: -959.681147\n",
      "    epoch          : 845\n",
      "    loss           : -953.1017164641377\n",
      "    val_loss       : -993.301703083802\n",
      "    val_log_likelihood: 1376.60572264569\n",
      "    val_log_marginal: 1001.4963805712399\n",
      "Train Epoch: 846 [512/17352 (3%)] Loss: -1015.145996\n",
      "Train Epoch: 846 [10713/17352 (62%)] Loss: -867.959983\n",
      "Train Epoch: 846 [16992/17352 (98%)] Loss: -798.365057\n",
      "    epoch          : 846\n",
      "    loss           : -978.7721200384852\n",
      "    val_loss       : -975.4309816087131\n",
      "    val_log_likelihood: 1384.7909469931285\n",
      "    val_log_marginal: 986.2576068246179\n",
      "Train Epoch: 847 [512/17352 (3%)] Loss: -1017.197632\n",
      "Train Epoch: 847 [10213/17352 (59%)] Loss: -1033.670132\n",
      "Train Epoch: 847 [16939/17352 (98%)] Loss: -1029.907267\n",
      "    epoch          : 847\n",
      "    loss           : -976.1372016148176\n",
      "    val_loss       : -981.4882515172282\n",
      "    val_log_likelihood: 1390.0598103674968\n",
      "    val_log_marginal: 997.6575992607362\n",
      "Train Epoch: 848 [512/17352 (3%)] Loss: -1015.866394\n",
      "Train Epoch: 848 [10312/17352 (59%)] Loss: -1090.281117\n",
      "Train Epoch: 848 [16939/17352 (98%)] Loss: -864.329473\n",
      "    epoch          : 848\n",
      "    loss           : -989.6882518566676\n",
      "    val_loss       : -989.1642464441519\n",
      "    val_log_likelihood: 1395.799780126457\n",
      "    val_log_marginal: 1007.4367934163473\n",
      "Train Epoch: 849 [512/17352 (3%)] Loss: -1037.637451\n",
      "Train Epoch: 849 [10466/17352 (60%)] Loss: -1137.000326\n",
      "Train Epoch: 849 [16988/17352 (98%)] Loss: -1089.635163\n",
      "    epoch          : 849\n",
      "    loss           : -991.7362279626071\n",
      "    val_loss       : -1002.5827944207442\n",
      "    val_log_likelihood: 1398.5621499868514\n",
      "    val_log_marginal: 1016.4217224661062\n",
      "Train Epoch: 850 [512/17352 (3%)] Loss: -1037.475464\n",
      "Train Epoch: 850 [10081/17352 (58%)] Loss: -989.487926\n",
      "Train Epoch: 850 [17124/17352 (99%)] Loss: -852.613487\n",
      "    epoch          : 850\n",
      "    loss           : -984.5680057946939\n",
      "    val_loss       : -966.0904133472533\n",
      "    val_log_likelihood: 1384.2878526896427\n",
      "    val_log_marginal: 989.7637629107934\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch850.pth ...\n",
      "Train Epoch: 851 [512/17352 (3%)] Loss: -992.335327\n",
      "Train Epoch: 851 [9622/17352 (55%)] Loss: -938.422355\n",
      "Train Epoch: 851 [17108/17352 (99%)] Loss: -1082.083782\n",
      "    epoch          : 851\n",
      "    loss           : -981.5129752611781\n",
      "    val_loss       : -990.2127414995562\n",
      "    val_log_likelihood: 1396.5076384307565\n",
      "    val_log_marginal: 1005.0358046338953\n",
      "Train Epoch: 852 [512/17352 (3%)] Loss: -1017.432312\n",
      "Train Epoch: 852 [10672/17352 (62%)] Loss: -1070.621584\n",
      "Train Epoch: 852 [16872/17352 (97%)] Loss: -955.447917\n",
      "    epoch          : 852\n",
      "    loss           : -999.9074046865425\n",
      "    val_loss       : -1010.1727747589265\n",
      "    val_log_likelihood: 1409.6887407709403\n",
      "    val_log_marginal: 1021.5793127415515\n",
      "Train Epoch: 853 [512/17352 (3%)] Loss: -1049.534058\n",
      "Train Epoch: 853 [10439/17352 (60%)] Loss: -1049.205814\n",
      "Train Epoch: 853 [17108/17352 (99%)] Loss: -1076.391418\n",
      "    epoch          : 853\n",
      "    loss           : -1001.5507589134362\n",
      "    val_loss       : -1001.0356468003969\n",
      "    val_log_likelihood: 1405.5064957171046\n",
      "    val_log_marginal: 1012.49188199341\n",
      "Train Epoch: 854 [512/17352 (3%)] Loss: -1035.995728\n",
      "Train Epoch: 854 [10178/17352 (59%)] Loss: -1057.392188\n",
      "Train Epoch: 854 [17124/17352 (99%)] Loss: -1021.895833\n",
      "    epoch          : 854\n",
      "    loss           : -997.2194428032683\n",
      "    val_loss       : -996.440601388338\n",
      "    val_log_likelihood: 1409.4208695772336\n",
      "    val_log_marginal: 1011.7709963752933\n",
      "Train Epoch: 855 [512/17352 (3%)] Loss: -1039.520264\n",
      "Train Epoch: 855 [10021/17352 (58%)] Loss: -975.710252\n",
      "Train Epoch: 855 [16872/17352 (97%)] Loss: -1041.338910\n",
      "    epoch          : 855\n",
      "    loss           : -1000.3572181442886\n",
      "    val_loss       : -1007.911082452203\n",
      "    val_log_likelihood: 1411.4245881234533\n",
      "    val_log_marginal: 1021.6185452089582\n",
      "Train Epoch: 856 [512/17352 (3%)] Loss: -1058.074951\n",
      "Train Epoch: 856 [10681/17352 (62%)] Loss: -936.489242\n",
      "Train Epoch: 856 [17153/17352 (99%)] Loss: -1018.957171\n",
      "    epoch          : 856\n",
      "    loss           : -991.9303210307739\n",
      "    val_loss       : -1001.8599102686453\n",
      "    val_log_likelihood: 1407.1291497658133\n",
      "    val_log_marginal: 1013.5673196400664\n",
      "Train Epoch: 857 [512/17352 (3%)] Loss: -1040.768799\n",
      "Train Epoch: 857 [10314/17352 (59%)] Loss: -1056.300509\n",
      "Train Epoch: 857 [16882/17352 (97%)] Loss: -913.905930\n",
      "    epoch          : 857\n",
      "    loss           : -975.7261895371782\n",
      "    val_loss       : -973.2201389322796\n",
      "    val_log_likelihood: 1385.5890137650151\n",
      "    val_log_marginal: 991.5674131603204\n",
      "Train Epoch: 858 [512/17352 (3%)] Loss: -993.124634\n",
      "Train Epoch: 858 [10656/17352 (61%)] Loss: -1097.083838\n",
      "Train Epoch: 858 [17133/17352 (99%)] Loss: -976.188125\n",
      "    epoch          : 858\n",
      "    loss           : -962.046611576707\n",
      "    val_loss       : -886.746960740674\n",
      "    val_log_likelihood: 1358.499183856607\n",
      "    val_log_marginal: 907.364444717486\n",
      "Train Epoch: 859 [512/17352 (3%)] Loss: -920.535156\n",
      "Train Epoch: 859 [10042/17352 (58%)] Loss: -876.853924\n",
      "Train Epoch: 859 [17133/17352 (99%)] Loss: -759.072786\n",
      "    epoch          : 859\n",
      "    loss           : -845.0268377801177\n",
      "    val_loss       : -107.10945267375719\n",
      "    val_log_likelihood: 1305.881699375302\n",
      "    val_log_marginal: 133.48005713068736\n",
      "Train Epoch: 860 [512/17352 (3%)] Loss: -194.115814\n",
      "Train Epoch: 860 [10220/17352 (59%)] Loss: -671.256975\n",
      "Train Epoch: 860 [17106/17352 (99%)] Loss: -903.820551\n",
      "    epoch          : 860\n",
      "    loss           : -672.0391435113996\n",
      "    val_loss       : -88.44654948753619\n",
      "    val_log_likelihood: 1256.7228890070248\n",
      "    val_log_marginal: 122.12548628466922\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch860.pth ...\n",
      "Train Epoch: 861 [512/17352 (3%)] Loss: -110.087555\n",
      "Train Epoch: 861 [10531/17352 (61%)] Loss: -831.349237\n",
      "Train Epoch: 861 [17124/17352 (99%)] Loss: -833.913651\n",
      "    epoch          : 861\n",
      "    loss           : -740.9514251501006\n",
      "    val_loss       : -879.8077885228383\n",
      "    val_log_likelihood: 1320.0857572948216\n",
      "    val_log_marginal: 913.8311377862863\n",
      "Train Epoch: 862 [512/17352 (3%)] Loss: -952.414307\n",
      "Train Epoch: 862 [10015/17352 (58%)] Loss: -969.483040\n",
      "Train Epoch: 862 [16958/17352 (98%)] Loss: -937.099475\n",
      "    epoch          : 862\n",
      "    loss           : -918.9721730080051\n",
      "    val_loss       : -937.1666398191744\n",
      "    val_log_likelihood: 1358.202486467651\n",
      "    val_log_marginal: 954.8748251234844\n",
      "Train Epoch: 863 [512/17352 (3%)] Loss: -973.427246\n",
      "Train Epoch: 863 [10517/17352 (61%)] Loss: -762.544355\n",
      "Train Epoch: 863 [17277/17352 (100%)] Loss: -921.814851\n",
      "    epoch          : 863\n",
      "    loss           : -932.3448309726384\n",
      "    val_loss       : -874.7073298671667\n",
      "    val_log_likelihood: 1360.664716699548\n",
      "    val_log_marginal: 930.7098666565145\n",
      "Train Epoch: 864 [512/17352 (3%)] Loss: -933.876038\n",
      "Train Epoch: 864 [10740/17352 (62%)] Loss: -1016.843036\n",
      "Train Epoch: 864 [16939/17352 (98%)] Loss: -736.451410\n",
      "    epoch          : 864\n",
      "    loss           : -885.1941357848751\n",
      "    val_loss       : -788.9629274722378\n",
      "    val_log_likelihood: 1349.7013920850952\n",
      "    val_log_marginal: 821.099269128861\n",
      "Train Epoch: 865 [512/17352 (3%)] Loss: -685.054993\n",
      "Train Epoch: 865 [10089/17352 (58%)] Loss: -940.742855\n",
      "Train Epoch: 865 [17335/17352 (100%)] Loss: -1038.987500\n",
      "    epoch          : 865\n",
      "    loss           : -861.675038697314\n",
      "    val_loss       : -846.9052132802641\n",
      "    val_log_likelihood: 1296.2288359740721\n",
      "    val_log_marginal: 867.3431988051555\n",
      "Train Epoch: 866 [512/17352 (3%)] Loss: -884.924194\n",
      "Train Epoch: 866 [10324/17352 (59%)] Loss: -897.005393\n",
      "Train Epoch: 866 [17101/17352 (99%)] Loss: -940.960422\n",
      "    epoch          : 866\n",
      "    loss           : -902.3386157953634\n",
      "    val_loss       : -931.8894172934265\n",
      "    val_log_likelihood: 1354.5584246342387\n",
      "    val_log_marginal: 959.6163586623276\n",
      "Train Epoch: 867 [512/17352 (3%)] Loss: -950.713257\n",
      "Train Epoch: 867 [9770/17352 (56%)] Loss: -889.545504\n",
      "Train Epoch: 867 [17277/17352 (100%)] Loss: -829.196751\n",
      "    epoch          : 867\n",
      "    loss           : -940.3640007249356\n",
      "    val_loss       : -930.8521189235718\n",
      "    val_log_likelihood: 1346.5595872422714\n",
      "    val_log_marginal: 945.7723510729868\n",
      "Train Epoch: 868 [512/17352 (3%)] Loss: -958.367432\n",
      "Train Epoch: 868 [10619/17352 (61%)] Loss: -1049.485723\n",
      "Train Epoch: 868 [16872/17352 (97%)] Loss: -1041.369919\n",
      "    epoch          : 868\n",
      "    loss           : -959.4002962065812\n",
      "    val_loss       : -940.8456063706486\n",
      "    val_log_likelihood: 1373.5598479094897\n",
      "    val_log_marginal: 955.4004366272803\n",
      "Train Epoch: 869 [512/17352 (3%)] Loss: -969.709351\n",
      "Train Epoch: 869 [10635/17352 (61%)] Loss: -1103.097873\n",
      "Train Epoch: 869 [16887/17352 (97%)] Loss: -1065.157708\n",
      "    epoch          : 869\n",
      "    loss           : -983.2749077329757\n",
      "    val_loss       : -984.41765640429\n",
      "    val_log_likelihood: 1384.3394347505935\n",
      "    val_log_marginal: 998.9210004408128\n",
      "Train Epoch: 870 [512/17352 (3%)] Loss: -1002.781799\n",
      "Train Epoch: 870 [9927/17352 (57%)] Loss: -1008.618082\n",
      "Train Epoch: 870 [17106/17352 (99%)] Loss: -1063.212355\n",
      "    epoch          : 870\n",
      "    loss           : -981.456825535541\n",
      "    val_loss       : -996.7409122320505\n",
      "    val_log_likelihood: 1388.5138950478702\n",
      "    val_log_marginal: 1008.3543345086756\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch870.pth ...\n",
      "Train Epoch: 871 [512/17352 (3%)] Loss: -1030.042358\n",
      "Train Epoch: 871 [10498/17352 (61%)] Loss: -1083.666445\n",
      "Train Epoch: 871 [17106/17352 (99%)] Loss: -1016.274187\n",
      "    epoch          : 871\n",
      "    loss           : -986.2367898924912\n",
      "    val_loss       : -974.5783020019825\n",
      "    val_log_likelihood: 1384.2104722388963\n",
      "    val_log_marginal: 987.0658021122827\n",
      "Train Epoch: 872 [512/17352 (3%)] Loss: -1016.336365\n",
      "Train Epoch: 872 [10608/17352 (61%)] Loss: -928.815191\n",
      "Train Epoch: 872 [17044/17352 (98%)] Loss: -1040.676822\n",
      "    epoch          : 872\n",
      "    loss           : -992.6704446985123\n",
      "    val_loss       : -1007.3097427695183\n",
      "    val_log_likelihood: 1401.3045570320232\n",
      "    val_log_marginal: 1020.2638942891507\n",
      "Train Epoch: 873 [512/17352 (3%)] Loss: -1049.336670\n",
      "Train Epoch: 873 [10529/17352 (61%)] Loss: -1122.262182\n",
      "Train Epoch: 873 [16934/17352 (98%)] Loss: -1066.352740\n",
      "    epoch          : 873\n",
      "    loss           : -1006.4516895146512\n",
      "    val_loss       : -1014.3296205911405\n",
      "    val_log_likelihood: 1407.0736059636881\n",
      "    val_log_marginal: 1025.3410428872705\n",
      "Train Epoch: 874 [512/17352 (3%)] Loss: -1039.147705\n",
      "Train Epoch: 874 [11050/17352 (64%)] Loss: -1099.920909\n",
      "Train Epoch: 874 [17133/17352 (99%)] Loss: -1105.014894\n",
      "    epoch          : 874\n",
      "    loss           : -1002.6252939177319\n",
      "    val_loss       : -1013.4391223947094\n",
      "    val_log_likelihood: 1404.7949557741067\n",
      "    val_log_marginal: 1022.6035716129278\n",
      "Train Epoch: 875 [512/17352 (3%)] Loss: -1049.295410\n",
      "Train Epoch: 875 [10211/17352 (59%)] Loss: -1071.472083\n",
      "Train Epoch: 875 [17106/17352 (99%)] Loss: -933.904272\n",
      "    epoch          : 875\n",
      "    loss           : -985.3852160599869\n",
      "    val_loss       : -973.0705300372446\n",
      "    val_log_likelihood: 1395.0962037223785\n",
      "    val_log_marginal: 997.2810243175976\n",
      "Train Epoch: 876 [512/17352 (3%)] Loss: -1022.877686\n",
      "Train Epoch: 876 [10230/17352 (59%)] Loss: -1051.151744\n",
      "Train Epoch: 876 [17143/17352 (99%)] Loss: -1093.464050\n",
      "    epoch          : 876\n",
      "    loss           : -974.6322482208672\n",
      "    val_loss       : -1000.4846382647378\n",
      "    val_log_likelihood: 1403.8716588089146\n",
      "    val_log_marginal: 1016.7296171413267\n",
      "Train Epoch: 877 [512/17352 (3%)] Loss: -1045.954590\n",
      "Train Epoch: 877 [10260/17352 (59%)] Loss: -892.583952\n",
      "Train Epoch: 877 [17090/17352 (98%)] Loss: -1023.350738\n",
      "    epoch          : 877\n",
      "    loss           : -979.366406442139\n",
      "    val_loss       : -926.2159025149886\n",
      "    val_log_likelihood: 1392.4344701674186\n",
      "    val_log_marginal: 950.2627081817215\n",
      "Train Epoch: 878 [512/17352 (3%)] Loss: -983.170715\n",
      "Train Epoch: 878 [10567/17352 (61%)] Loss: -1062.436301\n",
      "Train Epoch: 878 [16988/17352 (98%)] Loss: -1064.848985\n",
      "    epoch          : 878\n",
      "    loss           : -948.993213306423\n",
      "    val_loss       : -906.8087236343871\n",
      "    val_log_likelihood: 1348.3737064072461\n",
      "    val_log_marginal: 936.8616053321526\n",
      "Train Epoch: 879 [512/17352 (3%)] Loss: -708.181641\n",
      "Train Epoch: 879 [9883/17352 (57%)] Loss: -742.712395\n",
      "Train Epoch: 879 [17101/17352 (99%)] Loss: -917.941732\n",
      "    epoch          : 879\n",
      "    loss           : -910.0115905556557\n",
      "    val_loss       : -917.5158215425071\n",
      "    val_log_likelihood: 1358.2609988568315\n",
      "    val_log_marginal: 936.7955398597034\n",
      "Train Epoch: 880 [512/17352 (3%)] Loss: -965.004761\n",
      "Train Epoch: 880 [10516/17352 (61%)] Loss: -920.267203\n",
      "Train Epoch: 880 [17101/17352 (99%)] Loss: -876.361607\n",
      "    epoch          : 880\n",
      "    loss           : -965.4042198279659\n",
      "    val_loss       : -976.172715532204\n",
      "    val_log_likelihood: 1388.3786829023063\n",
      "    val_log_marginal: 991.437580818134\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch880.pth ...\n",
      "Train Epoch: 881 [512/17352 (3%)] Loss: -1000.635925\n",
      "Train Epoch: 881 [10021/17352 (58%)] Loss: -839.392327\n",
      "Train Epoch: 881 [17143/17352 (99%)] Loss: -1045.069840\n",
      "    epoch          : 881\n",
      "    loss           : -979.5852355296238\n",
      "    val_loss       : -964.5911031769739\n",
      "    val_log_likelihood: 1383.6904692811665\n",
      "    val_log_marginal: 979.702939190468\n",
      "Train Epoch: 882 [512/17352 (3%)] Loss: -970.399963\n",
      "Train Epoch: 882 [10265/17352 (59%)] Loss: -925.261206\n",
      "Train Epoch: 882 [16872/17352 (97%)] Loss: -1025.523753\n",
      "    epoch          : 882\n",
      "    loss           : -992.8900136991668\n",
      "    val_loss       : -1006.7788988153624\n",
      "    val_log_likelihood: 1409.6555939073608\n",
      "    val_log_marginal: 1023.4723455497782\n",
      "Train Epoch: 883 [512/17352 (3%)] Loss: -1032.452148\n",
      "Train Epoch: 883 [10601/17352 (61%)] Loss: -1059.514241\n",
      "Train Epoch: 883 [16922/17352 (98%)] Loss: -1031.976384\n",
      "    epoch          : 883\n",
      "    loss           : -999.1879435238145\n",
      "    val_loss       : -1008.0752136653556\n",
      "    val_log_likelihood: 1407.9771527733199\n",
      "    val_log_marginal: 1021.0078737473499\n",
      "Train Epoch: 884 [512/17352 (3%)] Loss: -1045.116699\n",
      "Train Epoch: 884 [10131/17352 (58%)] Loss: -988.882401\n",
      "Train Epoch: 884 [16878/17352 (97%)] Loss: -1015.405934\n",
      "    epoch          : 884\n",
      "    loss           : -1002.7282199360338\n",
      "    val_loss       : -1011.7647330065867\n",
      "    val_log_likelihood: 1414.8095782206722\n",
      "    val_log_marginal: 1025.5352458826096\n",
      "Train Epoch: 885 [512/17352 (3%)] Loss: -1060.909668\n",
      "Train Epoch: 885 [10302/17352 (59%)] Loss: -837.265780\n",
      "Train Epoch: 885 [16882/17352 (97%)] Loss: -831.468622\n",
      "    epoch          : 885\n",
      "    loss           : -931.0453396958889\n",
      "    val_loss       : -925.0622523904228\n",
      "    val_log_likelihood: 1352.049878981078\n",
      "    val_log_marginal: 953.2077970835521\n",
      "Train Epoch: 886 [512/17352 (3%)] Loss: -962.722046\n",
      "Train Epoch: 886 [10337/17352 (60%)] Loss: -894.640152\n",
      "Train Epoch: 886 [17126/17352 (99%)] Loss: -899.031826\n",
      "    epoch          : 886\n",
      "    loss           : -938.6867930741153\n",
      "    val_loss       : -853.3408155034672\n",
      "    val_log_likelihood: 1270.0433719981086\n",
      "    val_log_marginal: 863.9028377352417\n",
      "Train Epoch: 887 [512/17352 (3%)] Loss: -848.555298\n",
      "Train Epoch: 887 [10187/17352 (59%)] Loss: -992.611311\n",
      "Train Epoch: 887 [16872/17352 (97%)] Loss: -1058.459022\n",
      "    epoch          : 887\n",
      "    loss           : -950.1146558310342\n",
      "    val_loss       : -965.269547452349\n",
      "    val_log_likelihood: 1380.849783657923\n",
      "    val_log_marginal: 995.0570478637927\n",
      "Train Epoch: 888 [512/17352 (3%)] Loss: -1023.075195\n",
      "Train Epoch: 888 [10917/17352 (63%)] Loss: -1037.974699\n",
      "Train Epoch: 888 [17133/17352 (99%)] Loss: -893.951327\n",
      "    epoch          : 888\n",
      "    loss           : -868.2841653871204\n",
      "    val_loss       : -575.0867399912743\n",
      "    val_log_likelihood: 1215.7916592846066\n",
      "    val_log_marginal: 596.4597996301699\n",
      "Train Epoch: 889 [512/17352 (3%)] Loss: -662.041809\n",
      "Train Epoch: 889 [10562/17352 (61%)] Loss: -64.400383\n",
      "Train Epoch: 889 [17143/17352 (99%)] Loss: -117.814063\n",
      "    epoch          : 889\n",
      "    loss           : -547.7695865207157\n",
      "    val_loss       : -560.5006481983207\n",
      "    val_log_likelihood: 1258.450086297974\n",
      "    val_log_marginal: 621.7388578982612\n",
      "Train Epoch: 890 [512/17352 (3%)] Loss: -655.100342\n",
      "Train Epoch: 890 [10008/17352 (58%)] Loss: -713.018620\n",
      "Train Epoch: 890 [16958/17352 (98%)] Loss: -747.097712\n",
      "    epoch          : 890\n",
      "    loss           : -812.7491695807298\n",
      "    val_loss       : -870.8251989040117\n",
      "    val_log_likelihood: 1341.2625728349046\n",
      "    val_log_marginal: 896.0047042835997\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch890.pth ...\n",
      "Train Epoch: 891 [512/17352 (3%)] Loss: -824.640137\n",
      "Train Epoch: 891 [10185/17352 (59%)] Loss: -864.262615\n",
      "Train Epoch: 891 [17106/17352 (99%)] Loss: -957.122511\n",
      "    epoch          : 891\n",
      "    loss           : -915.2980101982952\n",
      "    val_loss       : -911.6067400349245\n",
      "    val_log_likelihood: 1350.693695837503\n",
      "    val_log_marginal: 927.7656274659178\n",
      "Train Epoch: 892 [512/17352 (3%)] Loss: -950.016479\n",
      "Train Epoch: 892 [9574/17352 (55%)] Loss: -1071.198552\n",
      "Train Epoch: 892 [16988/17352 (98%)] Loss: -1010.207365\n",
      "    epoch          : 892\n",
      "    loss           : -950.5899750179038\n",
      "    val_loss       : -983.4170644082369\n",
      "    val_log_likelihood: 1380.8938676610057\n",
      "    val_log_marginal: 995.5703197780077\n",
      "Train Epoch: 893 [512/17352 (3%)] Loss: -1008.526428\n",
      "Train Epoch: 893 [10279/17352 (59%)] Loss: -1051.738750\n",
      "Train Epoch: 893 [16922/17352 (98%)] Loss: -811.508199\n",
      "    epoch          : 893\n",
      "    loss           : -955.6325804028055\n",
      "    val_loss       : -984.1250992727217\n",
      "    val_log_likelihood: 1388.7787744885823\n",
      "    val_log_marginal: 1002.2499345163109\n",
      "Train Epoch: 894 [512/17352 (3%)] Loss: -1034.165649\n",
      "Train Epoch: 894 [10426/17352 (60%)] Loss: -1061.792813\n",
      "Train Epoch: 894 [16883/17352 (97%)] Loss: -996.499626\n",
      "    epoch          : 894\n",
      "    loss           : -994.0331151692332\n",
      "    val_loss       : -996.1021499328772\n",
      "    val_log_likelihood: 1398.9447019499096\n",
      "    val_log_marginal: 1008.7212760240461\n",
      "Train Epoch: 895 [512/17352 (3%)] Loss: -1040.539185\n",
      "Train Epoch: 895 [10104/17352 (58%)] Loss: -999.774357\n",
      "Train Epoch: 895 [17133/17352 (99%)] Loss: -1050.314896\n",
      "    epoch          : 895\n",
      "    loss           : -989.7065458248272\n",
      "    val_loss       : -977.8019792277806\n",
      "    val_log_likelihood: 1393.4948518924998\n",
      "    val_log_marginal: 999.0576269880966\n",
      "Train Epoch: 896 [512/17352 (3%)] Loss: -1034.198975\n",
      "Train Epoch: 896 [10225/17352 (59%)] Loss: -868.564062\n",
      "Train Epoch: 896 [17126/17352 (99%)] Loss: -1090.620006\n",
      "    epoch          : 896\n",
      "    loss           : -967.3779191449961\n",
      "    val_loss       : -974.2017932133094\n",
      "    val_log_likelihood: 1393.6184163923012\n",
      "    val_log_marginal: 987.0160745751891\n",
      "Train Epoch: 897 [512/17352 (3%)] Loss: -834.075867\n",
      "Train Epoch: 897 [10554/17352 (61%)] Loss: -869.195367\n",
      "Train Epoch: 897 [17133/17352 (99%)] Loss: -961.169524\n",
      "    epoch          : 897\n",
      "    loss           : -968.6984194559841\n",
      "    val_loss       : -982.7393206382516\n",
      "    val_log_likelihood: 1387.1777646873213\n",
      "    val_log_marginal: 994.9847956076494\n",
      "Train Epoch: 898 [512/17352 (3%)] Loss: -1015.273926\n",
      "Train Epoch: 898 [10671/17352 (61%)] Loss: -1028.650166\n",
      "Train Epoch: 898 [17263/17352 (99%)] Loss: -1097.699094\n",
      "    epoch          : 898\n",
      "    loss           : -984.9651515696468\n",
      "    val_loss       : -949.0032495992431\n",
      "    val_log_likelihood: 1386.8933591551595\n",
      "    val_log_marginal: 970.0089007225413\n",
      "Train Epoch: 899 [512/17352 (3%)] Loss: -999.843933\n",
      "Train Epoch: 899 [10777/17352 (62%)] Loss: -855.675175\n",
      "Train Epoch: 899 [17016/17352 (98%)] Loss: -1058.005552\n",
      "    epoch          : 899\n",
      "    loss           : -980.1571198552564\n",
      "    val_loss       : -990.5991441908246\n",
      "    val_log_likelihood: 1383.3042498174332\n",
      "    val_log_marginal: 999.241892671877\n",
      "Train Epoch: 900 [512/17352 (3%)] Loss: -1041.155762\n",
      "Train Epoch: 900 [10463/17352 (60%)] Loss: -841.426585\n",
      "Train Epoch: 900 [17090/17352 (98%)] Loss: -1109.890191\n",
      "    epoch          : 900\n",
      "    loss           : -975.5032938774086\n",
      "    val_loss       : -967.2077703821109\n",
      "    val_log_likelihood: 1390.7657336256714\n",
      "    val_log_marginal: 995.0849625265558\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch900.pth ...\n",
      "Train Epoch: 901 [512/17352 (3%)] Loss: -1020.851807\n",
      "Train Epoch: 901 [10312/17352 (59%)] Loss: -853.215610\n",
      "Train Epoch: 901 [17124/17352 (99%)] Loss: -1098.992247\n",
      "    epoch          : 901\n",
      "    loss           : -985.6510052042638\n",
      "    val_loss       : -1009.8195226819585\n",
      "    val_log_likelihood: 1410.078363635656\n",
      "    val_log_marginal: 1019.2385603226446\n",
      "Train Epoch: 902 [512/17352 (3%)] Loss: -1048.427979\n",
      "Train Epoch: 902 [10245/17352 (59%)] Loss: -1120.004843\n",
      "Train Epoch: 902 [17335/17352 (100%)] Loss: -879.364146\n",
      "    epoch          : 902\n",
      "    loss           : -999.2647006528102\n",
      "    val_loss       : -955.7167477299962\n",
      "    val_log_likelihood: 1400.4825828517032\n",
      "    val_log_marginal: 968.7426304785823\n",
      "Train Epoch: 903 [512/17352 (3%)] Loss: -994.741211\n",
      "Train Epoch: 903 [11283/17352 (65%)] Loss: -1085.274051\n",
      "Train Epoch: 903 [16939/17352 (98%)] Loss: -1069.167513\n",
      "    epoch          : 903\n",
      "    loss           : -989.1669607633055\n",
      "    val_loss       : -1008.0128661823137\n",
      "    val_log_likelihood: 1413.0294649999885\n",
      "    val_log_marginal: 1021.6021992304012\n",
      "Train Epoch: 904 [512/17352 (3%)] Loss: -1047.746582\n",
      "Train Epoch: 904 [10317/17352 (59%)] Loss: -1044.741862\n",
      "Train Epoch: 904 [17090/17352 (98%)] Loss: -973.697368\n",
      "    epoch          : 904\n",
      "    loss           : -952.4400718247122\n",
      "    val_loss       : -952.5489151134537\n",
      "    val_log_likelihood: 1401.7327673003535\n",
      "    val_log_marginal: 963.4143431325397\n",
      "Train Epoch: 905 [512/17352 (3%)] Loss: -1000.508667\n",
      "Train Epoch: 905 [10682/17352 (62%)] Loss: -1010.851632\n",
      "Train Epoch: 905 [16939/17352 (98%)] Loss: -1034.694404\n",
      "    epoch          : 905\n",
      "    loss           : -978.8224367186385\n",
      "    val_loss       : -994.6302889522267\n",
      "    val_log_likelihood: 1411.1727549708623\n",
      "    val_log_marginal: 1008.4055895879516\n",
      "Train Epoch: 906 [512/17352 (3%)] Loss: -1035.640991\n",
      "Train Epoch: 906 [9903/17352 (57%)] Loss: -1033.709447\n",
      "Train Epoch: 906 [17044/17352 (98%)] Loss: -1040.264983\n",
      "    epoch          : 906\n",
      "    loss           : -992.0492231063016\n",
      "    val_loss       : -987.6438067858346\n",
      "    val_log_likelihood: 1405.205774437118\n",
      "    val_log_marginal: 1008.7025405666309\n",
      "Train Epoch: 907 [512/17352 (3%)] Loss: -1021.529419\n",
      "Train Epoch: 907 [10865/17352 (63%)] Loss: -1094.519699\n",
      "Train Epoch: 907 [17263/17352 (99%)] Loss: -1070.520522\n",
      "    epoch          : 907\n",
      "    loss           : -985.1016016996282\n",
      "    val_loss       : -953.4180960616544\n",
      "    val_log_likelihood: 1391.95686315496\n",
      "    val_log_marginal: 980.1635291067279\n",
      "Train Epoch: 908 [512/17352 (3%)] Loss: -978.141113\n",
      "Train Epoch: 908 [10178/17352 (59%)] Loss: -845.164991\n",
      "Train Epoch: 908 [17064/17352 (98%)] Loss: -762.324731\n",
      "    epoch          : 908\n",
      "    loss           : -956.1759849436334\n",
      "    val_loss       : -969.9390594785885\n",
      "    val_log_likelihood: 1398.9117039806072\n",
      "    val_log_marginal: 983.5991428550573\n",
      "Train Epoch: 909 [512/17352 (3%)] Loss: -1000.972717\n",
      "Train Epoch: 909 [10573/17352 (61%)] Loss: -813.452975\n",
      "Train Epoch: 909 [17153/17352 (99%)] Loss: -919.510045\n",
      "    epoch          : 909\n",
      "    loss           : -957.7343452597617\n",
      "    val_loss       : -950.4332930193799\n",
      "    val_log_likelihood: 1381.2154662682087\n",
      "    val_log_marginal: 965.8540567427234\n",
      "Train Epoch: 910 [512/17352 (3%)] Loss: -978.100891\n",
      "Train Epoch: 910 [10575/17352 (61%)] Loss: -934.568316\n",
      "Train Epoch: 910 [17016/17352 (98%)] Loss: -930.916877\n",
      "    epoch          : 910\n",
      "    loss           : -968.2639996211275\n",
      "    val_loss       : -989.9216555224218\n",
      "    val_log_likelihood: 1403.0539758280456\n",
      "    val_log_marginal: 1003.5244573554045\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch910.pth ...\n",
      "Train Epoch: 911 [512/17352 (3%)] Loss: -1038.137451\n",
      "Train Epoch: 911 [10792/17352 (62%)] Loss: -1074.631129\n",
      "Train Epoch: 911 [16958/17352 (98%)] Loss: -1038.636236\n",
      "    epoch          : 911\n",
      "    loss           : -956.938391513196\n",
      "    val_loss       : -968.3104598160762\n",
      "    val_log_likelihood: 1395.7595252860172\n",
      "    val_log_marginal: 1007.0394579399763\n",
      "Train Epoch: 912 [512/17352 (3%)] Loss: -977.600952\n",
      "Train Epoch: 912 [10030/17352 (58%)] Loss: -893.038657\n",
      "Train Epoch: 912 [16872/17352 (97%)] Loss: -1060.240107\n",
      "    epoch          : 912\n",
      "    loss           : -978.9424897061792\n",
      "    val_loss       : -1006.1362243542934\n",
      "    val_log_likelihood: 1412.513170506976\n",
      "    val_log_marginal: 1024.5743423669178\n",
      "Train Epoch: 913 [512/17352 (3%)] Loss: -1054.898315\n",
      "Train Epoch: 913 [9734/17352 (56%)] Loss: -1069.647473\n",
      "Train Epoch: 913 [17253/17352 (99%)] Loss: -926.639813\n",
      "    epoch          : 913\n",
      "    loss           : -989.5469412471627\n",
      "    val_loss       : -953.928050984718\n",
      "    val_log_likelihood: 1381.3587842739457\n",
      "    val_log_marginal: 969.055109533656\n",
      "Train Epoch: 914 [512/17352 (3%)] Loss: -974.563599\n",
      "Train Epoch: 914 [11079/17352 (64%)] Loss: -1050.284310\n",
      "Train Epoch: 914 [17133/17352 (99%)] Loss: -1010.719934\n",
      "    epoch          : 914\n",
      "    loss           : -989.1943094972122\n",
      "    val_loss       : -999.9497037654002\n",
      "    val_log_likelihood: 1408.5754621888461\n",
      "    val_log_marginal: 1014.5256525041242\n",
      "Train Epoch: 915 [512/17352 (3%)] Loss: -1025.850586\n",
      "Train Epoch: 915 [10391/17352 (60%)] Loss: -1098.375238\n",
      "Train Epoch: 915 [17153/17352 (99%)] Loss: -1077.603173\n",
      "    epoch          : 915\n",
      "    loss           : -1000.9549114466911\n",
      "    val_loss       : -1001.1039148918081\n",
      "    val_log_likelihood: 1415.7515431338777\n",
      "    val_log_marginal: 1020.462625647393\n",
      "Train Epoch: 916 [512/17352 (3%)] Loss: -1052.206665\n",
      "Train Epoch: 916 [10515/17352 (61%)] Loss: -928.105925\n",
      "Train Epoch: 916 [16923/17352 (98%)] Loss: -1053.906800\n",
      "    epoch          : 916\n",
      "    loss           : -997.2613275039539\n",
      "    val_loss       : -1015.2203180437087\n",
      "    val_log_likelihood: 1424.171506667959\n",
      "    val_log_marginal: 1030.7886803810957\n",
      "Train Epoch: 917 [512/17352 (3%)] Loss: -1045.745605\n",
      "Train Epoch: 917 [10195/17352 (59%)] Loss: -909.016437\n",
      "Train Epoch: 917 [17049/17352 (98%)] Loss: -1093.441377\n",
      "    epoch          : 917\n",
      "    loss           : -1002.6860964005843\n",
      "    val_loss       : -1004.3604839135799\n",
      "    val_log_likelihood: 1420.529724957827\n",
      "    val_log_marginal: 1023.7590652267018\n",
      "Train Epoch: 918 [512/17352 (3%)] Loss: -1063.484375\n",
      "Train Epoch: 918 [10687/17352 (62%)] Loss: -949.106027\n",
      "Train Epoch: 918 [16939/17352 (98%)] Loss: -942.670139\n",
      "    epoch          : 918\n",
      "    loss           : -1011.1310427313291\n",
      "    val_loss       : -1008.6493642068709\n",
      "    val_log_likelihood: 1425.517070471904\n",
      "    val_log_marginal: 1024.7033858516056\n",
      "Train Epoch: 919 [512/17352 (3%)] Loss: -1036.967529\n",
      "Train Epoch: 919 [10067/17352 (58%)] Loss: -845.731160\n",
      "Train Epoch: 919 [16992/17352 (98%)] Loss: -1088.868218\n",
      "    epoch          : 919\n",
      "    loss           : -1003.2072131283461\n",
      "    val_loss       : -1000.8582823147427\n",
      "    val_log_likelihood: 1419.954047484163\n",
      "    val_log_marginal: 1016.8673652763598\n",
      "Train Epoch: 920 [512/17352 (3%)] Loss: -1031.986816\n",
      "Train Epoch: 920 [10761/17352 (62%)] Loss: -1090.230964\n",
      "Train Epoch: 920 [16992/17352 (98%)] Loss: -945.838499\n",
      "    epoch          : 920\n",
      "    loss           : -1001.4382068753944\n",
      "    val_loss       : -1002.9797127265745\n",
      "    val_log_likelihood: 1424.9177331522012\n",
      "    val_log_marginal: 1023.7918657166842\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch920.pth ...\n",
      "Train Epoch: 921 [512/17352 (3%)] Loss: -1055.878296\n",
      "Train Epoch: 921 [10659/17352 (61%)] Loss: -1056.209270\n",
      "Train Epoch: 921 [17049/17352 (98%)] Loss: -920.937601\n",
      "    epoch          : 921\n",
      "    loss           : -966.7597161072154\n",
      "    val_loss       : -959.627388153367\n",
      "    val_log_likelihood: 1404.0754154044773\n",
      "    val_log_marginal: 971.3095228977747\n",
      "Train Epoch: 922 [512/17352 (3%)] Loss: -992.431702\n",
      "Train Epoch: 922 [10354/17352 (60%)] Loss: -795.078073\n",
      "Train Epoch: 922 [17133/17352 (99%)] Loss: -846.813763\n",
      "    epoch          : 922\n",
      "    loss           : -944.8728640325884\n",
      "    val_loss       : -946.2950982677781\n",
      "    val_log_likelihood: 1389.3792944358715\n",
      "    val_log_marginal: 970.0311720622112\n",
      "Train Epoch: 923 [512/17352 (3%)] Loss: -1003.242554\n",
      "Train Epoch: 923 [10632/17352 (61%)] Loss: -988.641484\n",
      "Train Epoch: 923 [17277/17352 (100%)] Loss: -815.221019\n",
      "    epoch          : 923\n",
      "    loss           : -938.6470247498313\n",
      "    val_loss       : -929.3284129918081\n",
      "    val_log_likelihood: 1375.6123880048765\n",
      "    val_log_marginal: 955.3976081501297\n",
      "Train Epoch: 924 [512/17352 (3%)] Loss: -974.841064\n",
      "Train Epoch: 924 [9989/17352 (58%)] Loss: -898.563368\n",
      "Train Epoch: 924 [17044/17352 (98%)] Loss: -424.052058\n",
      "    epoch          : 924\n",
      "    loss           : -944.1072698083653\n",
      "    val_loss       : -734.5524814018811\n",
      "    val_log_likelihood: 1384.4089206294134\n",
      "    val_log_marginal: 754.1095192232569\n",
      "Train Epoch: 925 [512/17352 (3%)] Loss: -741.631165\n",
      "Train Epoch: 925 [10267/17352 (59%)] Loss: -853.091882\n",
      "Train Epoch: 925 [17108/17352 (99%)] Loss: -956.558114\n",
      "    epoch          : 925\n",
      "    loss           : -919.6184778618315\n",
      "    val_loss       : -967.4392835028813\n",
      "    val_log_likelihood: 1400.8396609763229\n",
      "    val_log_marginal: 984.5258101475968\n",
      "Train Epoch: 926 [512/17352 (3%)] Loss: -1020.776978\n",
      "Train Epoch: 926 [10297/17352 (59%)] Loss: -962.139388\n",
      "Train Epoch: 926 [16878/17352 (97%)] Loss: -817.898241\n",
      "    epoch          : 926\n",
      "    loss           : -913.4014300829027\n",
      "    val_loss       : -833.7544230929389\n",
      "    val_log_likelihood: 1389.666425697689\n",
      "    val_log_marginal: 870.7047616587055\n",
      "Train Epoch: 927 [512/17352 (3%)] Loss: -907.295166\n",
      "Train Epoch: 927 [10559/17352 (61%)] Loss: -716.026609\n",
      "Train Epoch: 927 [16883/17352 (97%)] Loss: 580.796224\n",
      "    epoch          : 927\n",
      "    loss           : -611.9216995573064\n",
      "    val_loss       : 256.9081771586396\n",
      "    val_log_likelihood: 1293.543794465054\n",
      "    val_log_marginal: -223.68007192603616\n",
      "Train Epoch: 928 [512/17352 (3%)] Loss: 104.143417\n",
      "Train Epoch: 928 [10224/17352 (59%)] Loss: -908.564165\n",
      "Train Epoch: 928 [16887/17352 (97%)] Loss: 352.563920\n",
      "    epoch          : 928\n",
      "    loss           : -414.21959077528334\n",
      "    val_loss       : -194.130446771643\n",
      "    val_log_likelihood: 1245.0594722229089\n",
      "    val_log_marginal: 220.66460010795126\n",
      "Train Epoch: 929 [512/17352 (3%)] Loss: -273.558167\n",
      "Train Epoch: 929 [10605/17352 (61%)] Loss: -539.271582\n",
      "Train Epoch: 929 [17064/17352 (98%)] Loss: -708.145169\n",
      "    epoch          : 929\n",
      "    loss           : -520.9643543744644\n",
      "    val_loss       : -758.9629565611475\n",
      "    val_log_likelihood: 1278.5228329439494\n",
      "    val_log_marginal: 791.4858546169602\n",
      "Train Epoch: 930 [512/17352 (3%)] Loss: -822.016602\n",
      "Train Epoch: 930 [10465/17352 (60%)] Loss: -973.035372\n",
      "Train Epoch: 930 [17044/17352 (98%)] Loss: -884.661949\n",
      "    epoch          : 930\n",
      "    loss           : -860.5443300847838\n",
      "    val_loss       : -935.6553158072338\n",
      "    val_log_likelihood: 1356.9518171297077\n",
      "    val_log_marginal: 959.2898520684203\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch930.pth ...\n",
      "Train Epoch: 931 [512/17352 (3%)] Loss: -962.511108\n",
      "Train Epoch: 931 [10391/17352 (60%)] Loss: -1031.392195\n",
      "Train Epoch: 931 [17016/17352 (98%)] Loss: -1005.238870\n",
      "    epoch          : 931\n",
      "    loss           : -962.1014400822985\n",
      "    val_loss       : -991.5552720271804\n",
      "    val_log_likelihood: 1395.3532146297991\n",
      "    val_log_marginal: 999.8062762642115\n",
      "Train Epoch: 932 [512/17352 (3%)] Loss: -1008.678345\n",
      "Train Epoch: 932 [10125/17352 (58%)] Loss: -1081.427187\n",
      "Train Epoch: 932 [17049/17352 (98%)] Loss: -1097.680304\n",
      "    epoch          : 932\n",
      "    loss           : -994.1795118235868\n",
      "    val_loss       : -1013.2478005124292\n",
      "    val_log_likelihood: 1409.4624382998995\n",
      "    val_log_marginal: 1025.5095124829884\n",
      "Train Epoch: 933 [512/17352 (3%)] Loss: -1052.217041\n",
      "Train Epoch: 933 [10583/17352 (61%)] Loss: -1106.957646\n",
      "Train Epoch: 933 [17106/17352 (99%)] Loss: -1055.946458\n",
      "    epoch          : 933\n",
      "    loss           : -1011.5498540386418\n",
      "    val_loss       : -1003.358843321045\n",
      "    val_log_likelihood: 1414.826258200569\n",
      "    val_log_marginal: 1021.6221826463209\n",
      "Train Epoch: 934 [512/17352 (3%)] Loss: -1050.036255\n",
      "Train Epoch: 934 [9949/17352 (57%)] Loss: -1065.104687\n",
      "Train Epoch: 934 [16992/17352 (98%)] Loss: -994.816648\n",
      "    epoch          : 934\n",
      "    loss           : -992.1938630721743\n",
      "    val_loss       : -1006.1247252677086\n",
      "    val_log_likelihood: 1406.8868388358371\n",
      "    val_log_marginal: 1019.448250838466\n",
      "Train Epoch: 935 [512/17352 (3%)] Loss: -1030.326172\n",
      "Train Epoch: 935 [10347/17352 (60%)] Loss: -1081.028074\n",
      "Train Epoch: 935 [16992/17352 (98%)] Loss: -867.439108\n",
      "    epoch          : 935\n",
      "    loss           : -976.5069474492678\n",
      "    val_loss       : -977.5806548719731\n",
      "    val_log_likelihood: 1389.5931172686414\n",
      "    val_log_marginal: 994.051284141556\n",
      "Train Epoch: 936 [512/17352 (3%)] Loss: -1021.546509\n",
      "Train Epoch: 936 [10056/17352 (58%)] Loss: -898.831684\n",
      "Train Epoch: 936 [17064/17352 (98%)] Loss: -1066.939399\n",
      "    epoch          : 936\n",
      "    loss           : -957.893393048736\n",
      "    val_loss       : -987.198365370167\n",
      "    val_log_likelihood: 1389.346213599702\n",
      "    val_log_marginal: 1001.699308680012\n",
      "Train Epoch: 937 [512/17352 (3%)] Loss: -1018.353516\n",
      "Train Epoch: 937 [10472/17352 (60%)] Loss: -844.924969\n",
      "Train Epoch: 937 [16988/17352 (98%)] Loss: -1060.083731\n",
      "    epoch          : 937\n",
      "    loss           : -998.9874777292663\n",
      "    val_loss       : -1017.0428159045515\n",
      "    val_log_likelihood: 1412.1266149227954\n",
      "    val_log_marginal: 1030.9464330164988\n",
      "Train Epoch: 938 [512/17352 (3%)] Loss: -1056.054688\n",
      "Train Epoch: 938 [10610/17352 (61%)] Loss: -795.056444\n",
      "Train Epoch: 938 [17124/17352 (99%)] Loss: -1098.330187\n",
      "    epoch          : 938\n",
      "    loss           : -1005.1965801681081\n",
      "    val_loss       : -991.747859948443\n",
      "    val_log_likelihood: 1399.4805705297515\n",
      "    val_log_marginal: 1003.713508645139\n",
      "Train Epoch: 939 [512/17352 (3%)] Loss: -1033.656982\n",
      "Train Epoch: 939 [9670/17352 (56%)] Loss: -1076.821875\n",
      "Train Epoch: 939 [16882/17352 (97%)] Loss: -936.109450\n",
      "    epoch          : 939\n",
      "    loss           : -1004.4945325581203\n",
      "    val_loss       : -1015.459428217615\n",
      "    val_log_likelihood: 1416.1360563181283\n",
      "    val_log_marginal: 1030.8978583684207\n",
      "Train Epoch: 940 [512/17352 (3%)] Loss: -1045.993896\n",
      "Train Epoch: 940 [10490/17352 (60%)] Loss: -1025.743086\n",
      "Train Epoch: 940 [16939/17352 (98%)] Loss: -1114.779388\n",
      "    epoch          : 940\n",
      "    loss           : -1010.6886483601779\n",
      "    val_loss       : -1017.749951525659\n",
      "    val_log_likelihood: 1417.9133357860699\n",
      "    val_log_marginal: 1030.6058721228644\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch940.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 941 [512/17352 (3%)] Loss: -1069.846680\n",
      "Train Epoch: 941 [10442/17352 (60%)] Loss: -870.450269\n",
      "Train Epoch: 941 [17126/17352 (99%)] Loss: -1072.807271\n",
      "    epoch          : 941\n",
      "    loss           : -1018.815062151299\n",
      "    val_loss       : -1011.4438482160556\n",
      "    val_log_likelihood: 1417.8209510506053\n",
      "    val_log_marginal: 1027.468670003807\n",
      "Train Epoch: 942 [512/17352 (3%)] Loss: -1051.869141\n",
      "Train Epoch: 942 [10076/17352 (58%)] Loss: -1099.252732\n",
      "Train Epoch: 942 [17143/17352 (99%)] Loss: -855.689758\n",
      "    epoch          : 942\n",
      "    loss           : -976.7092551163531\n",
      "    val_loss       : -917.6784651349028\n",
      "    val_log_likelihood: 1393.8636046422203\n",
      "    val_log_marginal: 949.0127659053977\n",
      "Train Epoch: 943 [512/17352 (3%)] Loss: -977.942871\n",
      "Train Epoch: 943 [10637/17352 (61%)] Loss: -833.790635\n",
      "Train Epoch: 943 [17253/17352 (99%)] Loss: -917.118272\n",
      "    epoch          : 943\n",
      "    loss           : -969.9877762300571\n",
      "    val_loss       : -809.592763439683\n",
      "    val_log_likelihood: 1399.979181129466\n",
      "    val_log_marginal: 834.3481770018321\n",
      "Train Epoch: 944 [512/17352 (3%)] Loss: -776.282776\n",
      "Train Epoch: 944 [10272/17352 (59%)] Loss: -1046.130589\n",
      "Train Epoch: 944 [17044/17352 (98%)] Loss: -951.220993\n",
      "    epoch          : 944\n",
      "    loss           : -952.2470423349895\n",
      "    val_loss       : -998.6313330541955\n",
      "    val_log_likelihood: 1404.4012725522218\n",
      "    val_log_marginal: 1013.8045487466038\n",
      "Train Epoch: 945 [512/17352 (3%)] Loss: -1038.410889\n",
      "Train Epoch: 945 [10301/17352 (59%)] Loss: -931.892034\n",
      "Train Epoch: 945 [17253/17352 (99%)] Loss: -936.290072\n",
      "    epoch          : 945\n",
      "    loss           : -1000.5669553020358\n",
      "    val_loss       : -1007.781162793683\n",
      "    val_log_likelihood: 1420.3074625984232\n",
      "    val_log_marginal: 1020.3692315443308\n",
      "Train Epoch: 946 [512/17352 (3%)] Loss: -1042.768066\n",
      "Train Epoch: 946 [10686/17352 (62%)] Loss: -860.184584\n",
      "Train Epoch: 946 [17253/17352 (99%)] Loss: -948.541050\n",
      "    epoch          : 946\n",
      "    loss           : -1006.8378779394392\n",
      "    val_loss       : -1009.2155629717782\n",
      "    val_log_likelihood: 1419.4037151323712\n",
      "    val_log_marginal: 1030.5162097122327\n",
      "Train Epoch: 947 [512/17352 (3%)] Loss: -1054.893188\n",
      "Train Epoch: 947 [10168/17352 (59%)] Loss: -956.576197\n",
      "Train Epoch: 947 [16883/17352 (97%)] Loss: -1153.213433\n",
      "    epoch          : 947\n",
      "    loss           : -1006.9028769130833\n",
      "    val_loss       : -994.7401193138759\n",
      "    val_log_likelihood: 1425.5446662155607\n",
      "    val_log_marginal: 1009.242218148606\n",
      "Train Epoch: 948 [512/17352 (3%)] Loss: -1037.923218\n",
      "Train Epoch: 948 [10550/17352 (61%)] Loss: -983.885143\n",
      "Train Epoch: 948 [16957/17352 (98%)] Loss: -1115.692364\n",
      "    epoch          : 948\n",
      "    loss           : -1014.3423012292252\n",
      "    val_loss       : -1021.6380731766425\n",
      "    val_log_likelihood: 1434.6100544237158\n",
      "    val_log_marginal: 1036.6663759138842\n",
      "Train Epoch: 949 [512/17352 (3%)] Loss: -1071.359131\n",
      "Train Epoch: 949 [10477/17352 (60%)] Loss: -985.314174\n",
      "Train Epoch: 949 [17126/17352 (99%)] Loss: -1083.823338\n",
      "    epoch          : 949\n",
      "    loss           : -1007.1915685150313\n",
      "    val_loss       : -965.0373009128242\n",
      "    val_log_likelihood: 1411.683489151436\n",
      "    val_log_marginal: 977.1747039510432\n",
      "Train Epoch: 950 [512/17352 (3%)] Loss: -994.450867\n",
      "Train Epoch: 950 [10025/17352 (58%)] Loss: -604.731235\n",
      "Train Epoch: 950 [16887/17352 (97%)] Loss: -409.370898\n",
      "    epoch          : 950\n",
      "    loss           : -617.7032290266102\n",
      "    val_loss       : -499.454329113699\n",
      "    val_log_likelihood: 1214.4299845293071\n",
      "    val_log_marginal: 516.5893492897267\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch950.pth ...\n",
      "Train Epoch: 951 [512/17352 (3%)] Loss: -522.489624\n",
      "Train Epoch: 951 [10443/17352 (60%)] Loss: -753.389063\n",
      "Train Epoch: 951 [17108/17352 (99%)] Loss: -871.239873\n",
      "    epoch          : 951\n",
      "    loss           : -669.8410498382683\n",
      "    val_loss       : -699.2851399574753\n",
      "    val_log_likelihood: 1223.6787183290169\n",
      "    val_log_marginal: 776.8307600598921\n",
      "Train Epoch: 952 [512/17352 (3%)] Loss: -735.514587\n",
      "Train Epoch: 952 [10456/17352 (60%)] Loss: -549.440087\n",
      "Train Epoch: 952 [16988/17352 (98%)] Loss: -885.779822\n",
      "    epoch          : 952\n",
      "    loss           : -732.5360715776661\n",
      "    val_loss       : -892.5157084230669\n",
      "    val_log_likelihood: 1294.5572937879704\n",
      "    val_log_marginal: 910.7067550338248\n",
      "Train Epoch: 953 [512/17352 (3%)] Loss: -926.933594\n",
      "Train Epoch: 953 [10341/17352 (60%)] Loss: -1014.476879\n",
      "Train Epoch: 953 [16957/17352 (98%)] Loss: -1024.848666\n",
      "    epoch          : 953\n",
      "    loss           : -891.6875001630526\n",
      "    val_loss       : -949.0125763349856\n",
      "    val_log_likelihood: 1353.0596140183109\n",
      "    val_log_marginal: 972.058225391581\n",
      "Train Epoch: 954 [512/17352 (3%)] Loss: -813.707581\n",
      "Train Epoch: 954 [9984/17352 (58%)] Loss: -1051.288227\n",
      "Train Epoch: 954 [17124/17352 (99%)] Loss: -1079.847627\n",
      "    epoch          : 954\n",
      "    loss           : -980.1182865217354\n",
      "    val_loss       : -1001.8738680293242\n",
      "    val_log_likelihood: 1398.0784333623383\n",
      "    val_log_marginal: 1016.3537679380619\n",
      "Train Epoch: 955 [512/17352 (3%)] Loss: -1045.965698\n",
      "Train Epoch: 955 [10655/17352 (61%)] Loss: -1098.395189\n",
      "Train Epoch: 955 [17016/17352 (98%)] Loss: -1022.062739\n",
      "    epoch          : 955\n",
      "    loss           : -1006.3487151168072\n",
      "    val_loss       : -1011.277158008166\n",
      "    val_log_likelihood: 1407.8996349088598\n",
      "    val_log_marginal: 1024.200845900588\n",
      "Train Epoch: 956 [512/17352 (3%)] Loss: -1049.086548\n",
      "Train Epoch: 956 [10034/17352 (58%)] Loss: -929.743010\n",
      "Train Epoch: 956 [17133/17352 (99%)] Loss: -805.597566\n",
      "    epoch          : 956\n",
      "    loss           : -962.6522733925502\n",
      "    val_loss       : -797.0754105969019\n",
      "    val_log_likelihood: 1401.8484587372573\n",
      "    val_log_marginal: 808.3327188620264\n",
      "Train Epoch: 957 [512/17352 (3%)] Loss: -805.170837\n",
      "Train Epoch: 957 [10236/17352 (59%)] Loss: -796.090830\n",
      "Train Epoch: 957 [17335/17352 (100%)] Loss: -1087.487807\n",
      "    epoch          : 957\n",
      "    loss           : -884.6133306458706\n",
      "    val_loss       : -762.9574654334517\n",
      "    val_log_likelihood: 1374.9080064339475\n",
      "    val_log_marginal: 779.9885853108027\n",
      "Train Epoch: 958 [512/17352 (3%)] Loss: -776.422363\n",
      "Train Epoch: 958 [10099/17352 (58%)] Loss: -903.197707\n",
      "Train Epoch: 958 [16878/17352 (97%)] Loss: -998.473841\n",
      "    epoch          : 958\n",
      "    loss           : -891.681475714362\n",
      "    val_loss       : -938.7865985574733\n",
      "    val_log_likelihood: 1365.1899253557172\n",
      "    val_log_marginal: 956.8345610084717\n",
      "Train Epoch: 959 [512/17352 (3%)] Loss: -972.417236\n",
      "Train Epoch: 959 [10639/17352 (61%)] Loss: -842.387449\n",
      "Train Epoch: 959 [16939/17352 (98%)] Loss: -504.490104\n",
      "    epoch          : 959\n",
      "    loss           : -578.8401402660639\n",
      "    val_loss       : -590.595934866832\n",
      "    val_log_likelihood: 1183.7441222069535\n",
      "    val_log_marginal: 640.895410260975\n",
      "Train Epoch: 960 [512/17352 (3%)] Loss: -631.130066\n",
      "Train Epoch: 960 [10564/17352 (61%)] Loss: -767.576120\n",
      "Train Epoch: 960 [16923/17352 (98%)] Loss: -889.672292\n",
      "    epoch          : 960\n",
      "    loss           : -620.533772447219\n",
      "    val_loss       : -878.6984003540861\n",
      "    val_log_likelihood: 1311.3449915256879\n",
      "    val_log_marginal: 904.9461918238429\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch960.pth ...\n",
      "Train Epoch: 961 [512/17352 (3%)] Loss: -850.830750\n",
      "Train Epoch: 961 [9995/17352 (58%)] Loss: -825.288857\n",
      "Train Epoch: 961 [17101/17352 (99%)] Loss: -672.898715\n",
      "    epoch          : 961\n",
      "    loss           : -759.7202549754187\n",
      "    val_loss       : -893.5371058973236\n",
      "    val_log_likelihood: 1330.12862335524\n",
      "    val_log_marginal: 923.8667050965552\n",
      "Train Epoch: 962 [512/17352 (3%)] Loss: -949.393921\n",
      "Train Epoch: 962 [10452/17352 (60%)] Loss: -1008.273084\n",
      "Train Epoch: 962 [17044/17352 (98%)] Loss: -1019.944895\n",
      "    epoch          : 962\n",
      "    loss           : -903.046792090242\n",
      "    val_loss       : -708.8775542284266\n",
      "    val_log_likelihood: 1364.5360590653897\n",
      "    val_log_marginal: 723.9600497027204\n",
      "Train Epoch: 963 [512/17352 (3%)] Loss: -727.857849\n",
      "Train Epoch: 963 [10084/17352 (58%)] Loss: -831.517034\n",
      "Train Epoch: 963 [16882/17352 (97%)] Loss: -922.697983\n",
      "    epoch          : 963\n",
      "    loss           : -905.1654498646534\n",
      "    val_loss       : -934.8739937672143\n",
      "    val_log_likelihood: 1374.5080309467382\n",
      "    val_log_marginal: 950.3401467607539\n",
      "Train Epoch: 964 [512/17352 (3%)] Loss: -1000.574890\n",
      "Train Epoch: 964 [10516/17352 (61%)] Loss: -1106.320748\n",
      "Train Epoch: 964 [17253/17352 (99%)] Loss: -968.414688\n",
      "    epoch          : 964\n",
      "    loss           : -934.5611069703886\n",
      "    val_loss       : -697.9003224640933\n",
      "    val_log_likelihood: 1354.7879492054496\n",
      "    val_log_marginal: 710.1106004098293\n",
      "Train Epoch: 965 [512/17352 (3%)] Loss: -714.232239\n",
      "Train Epoch: 965 [10258/17352 (59%)] Loss: -823.369623\n",
      "Train Epoch: 965 [16992/17352 (98%)] Loss: -1032.393387\n",
      "    epoch          : 965\n",
      "    loss           : -896.9373358212046\n",
      "    val_loss       : -928.3146586880381\n",
      "    val_log_likelihood: 1372.7834180797734\n",
      "    val_log_marginal: 944.0650158250053\n",
      "Train Epoch: 966 [512/17352 (3%)] Loss: -973.685364\n",
      "Train Epoch: 966 [10310/17352 (59%)] Loss: -789.082378\n",
      "Train Epoch: 966 [17049/17352 (98%)] Loss: -746.927885\n",
      "    epoch          : 966\n",
      "    loss           : -900.8533760264376\n",
      "    val_loss       : -965.9528478709005\n",
      "    val_log_likelihood: 1381.9048707209322\n",
      "    val_log_marginal: 982.99675771398\n",
      "Train Epoch: 967 [512/17352 (3%)] Loss: -1012.055786\n",
      "Train Epoch: 967 [10407/17352 (60%)] Loss: -917.582163\n",
      "Train Epoch: 967 [17153/17352 (99%)] Loss: -716.074390\n",
      "    epoch          : 967\n",
      "    loss           : -765.0011042762874\n",
      "    val_loss       : -211.55014985138286\n",
      "    val_log_likelihood: 1332.5974043274314\n",
      "    val_log_marginal: 235.01415284967342\n",
      "Train Epoch: 968 [512/17352 (3%)] Loss: -327.551483\n",
      "Train Epoch: 968 [10224/17352 (59%)] Loss: -651.523181\n",
      "Train Epoch: 968 [17090/17352 (98%)] Loss: -670.041271\n",
      "    epoch          : 968\n",
      "    loss           : -748.5988857134947\n",
      "    val_loss       : -839.4525159106532\n",
      "    val_log_likelihood: 1347.23332039068\n",
      "    val_log_marginal: 853.6319517245543\n",
      "Train Epoch: 969 [512/17352 (3%)] Loss: -882.050842\n",
      "Train Epoch: 969 [10728/17352 (62%)] Loss: -1050.256395\n",
      "Train Epoch: 969 [16887/17352 (97%)] Loss: -1028.304433\n",
      "    epoch          : 969\n",
      "    loss           : -930.6853390168031\n",
      "    val_loss       : -981.1090032903634\n",
      "    val_log_likelihood: 1381.0625072396908\n",
      "    val_log_marginal: 999.8792905139026\n",
      "Train Epoch: 970 [512/17352 (3%)] Loss: -1012.763977\n",
      "Train Epoch: 970 [10098/17352 (58%)] Loss: -920.249391\n",
      "Train Epoch: 970 [17126/17352 (99%)] Loss: -1120.726888\n",
      "    epoch          : 970\n",
      "    loss           : -988.4862007776835\n",
      "    val_loss       : -1005.1667252224232\n",
      "    val_log_likelihood: 1396.4483245184128\n",
      "    val_log_marginal: 1017.432351553385\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch970.pth ...\n",
      "Train Epoch: 971 [512/17352 (3%)] Loss: -1040.785522\n",
      "Train Epoch: 971 [10745/17352 (62%)] Loss: -1099.419681\n",
      "Train Epoch: 971 [17101/17352 (99%)] Loss: -1095.023734\n",
      "    epoch          : 971\n",
      "    loss           : -1000.9896244102368\n",
      "    val_loss       : -1011.9331779690604\n",
      "    val_log_likelihood: 1409.3707684360854\n",
      "    val_log_marginal: 1025.3296423783204\n",
      "Train Epoch: 972 [512/17352 (3%)] Loss: -1050.046631\n",
      "Train Epoch: 972 [9980/17352 (58%)] Loss: -975.621280\n",
      "Train Epoch: 972 [16958/17352 (98%)] Loss: -1083.891218\n",
      "    epoch          : 972\n",
      "    loss           : -1009.7295474954593\n",
      "    val_loss       : -1005.8688344286959\n",
      "    val_log_likelihood: 1416.0113884755087\n",
      "    val_log_marginal: 1019.307868270161\n",
      "Train Epoch: 973 [512/17352 (3%)] Loss: -1054.381592\n",
      "Train Epoch: 973 [10399/17352 (60%)] Loss: -962.386161\n",
      "Train Epoch: 973 [16934/17352 (98%)] Loss: -901.347392\n",
      "    epoch          : 973\n",
      "    loss           : -1018.6630043755238\n",
      "    val_loss       : -1022.83273057345\n",
      "    val_log_likelihood: 1417.0850193877448\n",
      "    val_log_marginal: 1032.8783615854911\n",
      "Train Epoch: 974 [512/17352 (3%)] Loss: -1061.919067\n",
      "Train Epoch: 974 [10141/17352 (58%)] Loss: -971.891021\n",
      "Train Epoch: 974 [16882/17352 (97%)] Loss: -1074.592023\n",
      "    epoch          : 974\n",
      "    loss           : -1022.2576388902461\n",
      "    val_loss       : -1028.8872799335236\n",
      "    val_log_likelihood: 1422.169435230025\n",
      "    val_log_marginal: 1039.0888578426895\n",
      "Train Epoch: 975 [512/17352 (3%)] Loss: -1073.007690\n",
      "Train Epoch: 975 [10425/17352 (60%)] Loss: -971.858724\n",
      "Train Epoch: 975 [17064/17352 (98%)] Loss: -1013.319883\n",
      "    epoch          : 975\n",
      "    loss           : -1022.9041594689917\n",
      "    val_loss       : -1018.8432148700207\n",
      "    val_log_likelihood: 1422.8654082868193\n",
      "    val_log_marginal: 1032.2288905507128\n",
      "Train Epoch: 976 [512/17352 (3%)] Loss: -1054.280396\n",
      "Train Epoch: 976 [10171/17352 (59%)] Loss: -879.004298\n",
      "Train Epoch: 976 [17106/17352 (99%)] Loss: -1089.646945\n",
      "    epoch          : 976\n",
      "    loss           : -1015.6469223782975\n",
      "    val_loss       : -1015.5560269752729\n",
      "    val_log_likelihood: 1422.5459641898449\n",
      "    val_log_marginal: 1029.464171583317\n",
      "Train Epoch: 977 [512/17352 (3%)] Loss: -1047.116455\n",
      "Train Epoch: 977 [10548/17352 (61%)] Loss: -981.919347\n",
      "Train Epoch: 977 [17124/17352 (99%)] Loss: -1075.689779\n",
      "    epoch          : 977\n",
      "    loss           : -1024.2379337249577\n",
      "    val_loss       : -1026.326526943454\n",
      "    val_log_likelihood: 1429.3890025280004\n",
      "    val_log_marginal: 1038.5226275068726\n",
      "Train Epoch: 978 [512/17352 (3%)] Loss: -1060.621216\n",
      "Train Epoch: 978 [10663/17352 (61%)] Loss: -1123.046809\n",
      "Train Epoch: 978 [16883/17352 (97%)] Loss: -986.911938\n",
      "    epoch          : 978\n",
      "    loss           : -1031.1624500017213\n",
      "    val_loss       : -1035.2295139313167\n",
      "    val_log_likelihood: 1437.5506217686052\n",
      "    val_log_marginal: 1045.719904060783\n",
      "Train Epoch: 979 [512/17352 (3%)] Loss: -1063.809570\n",
      "Train Epoch: 979 [10121/17352 (58%)] Loss: -1080.510835\n",
      "Train Epoch: 979 [17253/17352 (99%)] Loss: -1105.778074\n",
      "    epoch          : 979\n",
      "    loss           : -1023.4651703842335\n",
      "    val_loss       : -1015.0004554801769\n",
      "    val_log_likelihood: 1429.942347778777\n",
      "    val_log_marginal: 1022.2978253601011\n",
      "Train Epoch: 980 [512/17352 (3%)] Loss: -1048.054565\n",
      "Train Epoch: 980 [10803/17352 (62%)] Loss: -1061.505889\n",
      "Train Epoch: 980 [17263/17352 (99%)] Loss: -1071.004731\n",
      "    epoch          : 980\n",
      "    loss           : -1026.1567389076895\n",
      "    val_loss       : -1030.903960587571\n",
      "    val_log_likelihood: 1437.045101278428\n",
      "    val_log_marginal: 1041.4051305104408\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch980.pth ...\n",
      "Train Epoch: 981 [512/17352 (3%)] Loss: -1076.656250\n",
      "Train Epoch: 981 [10923/17352 (63%)] Loss: -1073.821088\n",
      "Train Epoch: 981 [16957/17352 (98%)] Loss: -943.624290\n",
      "    epoch          : 981\n",
      "    loss           : -1028.6806095118422\n",
      "    val_loss       : -1035.6574192691817\n",
      "    val_log_likelihood: 1441.2349528111688\n",
      "    val_log_marginal: 1047.8386833407376\n",
      "Train Epoch: 982 [512/17352 (3%)] Loss: -1083.569336\n",
      "Train Epoch: 982 [10212/17352 (59%)] Loss: -917.115603\n",
      "Train Epoch: 982 [17049/17352 (98%)] Loss: -980.262103\n",
      "    epoch          : 982\n",
      "    loss           : -1033.458304675513\n",
      "    val_loss       : -1035.3778357143317\n",
      "    val_log_likelihood: 1441.821331773822\n",
      "    val_log_marginal: 1045.8458846022324\n",
      "Train Epoch: 983 [512/17352 (3%)] Loss: -1074.121338\n",
      "Train Epoch: 983 [10506/17352 (61%)] Loss: -1156.669813\n",
      "Train Epoch: 983 [16922/17352 (98%)] Loss: -1123.920986\n",
      "    epoch          : 983\n",
      "    loss           : -1022.6746105558664\n",
      "    val_loss       : -1021.6567373022932\n",
      "    val_log_likelihood: 1438.6378178727198\n",
      "    val_log_marginal: 1037.4204352449492\n",
      "Train Epoch: 984 [512/17352 (3%)] Loss: -1074.553223\n",
      "Train Epoch: 984 [10891/17352 (63%)] Loss: -939.540599\n",
      "Train Epoch: 984 [17143/17352 (99%)] Loss: -1024.196280\n",
      "    epoch          : 984\n",
      "    loss           : -1013.9246289054686\n",
      "    val_loss       : -997.1342169755186\n",
      "    val_log_likelihood: 1434.9323547859512\n",
      "    val_log_marginal: 1031.7259693290289\n",
      "Train Epoch: 985 [512/17352 (3%)] Loss: -1040.601562\n",
      "Train Epoch: 985 [10713/17352 (62%)] Loss: -818.308202\n",
      "Train Epoch: 985 [17090/17352 (98%)] Loss: -1018.208416\n",
      "    epoch          : 985\n",
      "    loss           : -965.4818611254382\n",
      "    val_loss       : -972.8559695819474\n",
      "    val_log_likelihood: 1406.0087266613516\n",
      "    val_log_marginal: 1006.4144288143918\n",
      "Train Epoch: 986 [512/17352 (3%)] Loss: -976.196289\n",
      "Train Epoch: 986 [10592/17352 (61%)] Loss: -964.632812\n",
      "Train Epoch: 986 [16934/17352 (98%)] Loss: -1037.768845\n",
      "    epoch          : 986\n",
      "    loss           : -964.710248928384\n",
      "    val_loss       : -989.9269597280186\n",
      "    val_log_likelihood: 1416.17557836077\n",
      "    val_log_marginal: 1024.520424304455\n",
      "Train Epoch: 987 [512/17352 (3%)] Loss: -1057.234253\n",
      "Train Epoch: 987 [9693/17352 (56%)] Loss: -1072.998506\n",
      "Train Epoch: 987 [17016/17352 (98%)] Loss: -1036.862417\n",
      "    epoch          : 987\n",
      "    loss           : -1006.7099023791781\n",
      "    val_loss       : -1029.7930351883451\n",
      "    val_log_likelihood: 1437.0307455765617\n",
      "    val_log_marginal: 1044.6625266843735\n",
      "Train Epoch: 988 [512/17352 (3%)] Loss: -1080.588135\n",
      "Train Epoch: 988 [10667/17352 (61%)] Loss: -901.835484\n",
      "Train Epoch: 988 [17277/17352 (100%)] Loss: -931.649525\n",
      "    epoch          : 988\n",
      "    loss           : -1021.2624925988906\n",
      "    val_loss       : -1009.1177799401913\n",
      "    val_log_likelihood: 1425.3329150893396\n",
      "    val_log_marginal: 1021.554138258332\n",
      "Train Epoch: 989 [512/17352 (3%)] Loss: -1049.490234\n",
      "Train Epoch: 989 [10079/17352 (58%)] Loss: -1033.547566\n",
      "Train Epoch: 989 [17335/17352 (100%)] Loss: -1066.299702\n",
      "    epoch          : 989\n",
      "    loss           : -1015.1602715328942\n",
      "    val_loss       : -994.8857395340174\n",
      "    val_log_likelihood: 1423.9038526922511\n",
      "    val_log_marginal: 1006.6739749953935\n",
      "Train Epoch: 990 [512/17352 (3%)] Loss: -1036.348999\n",
      "Train Epoch: 990 [9734/17352 (56%)] Loss: -1096.999238\n",
      "Train Epoch: 990 [16882/17352 (97%)] Loss: -917.294945\n",
      "    epoch          : 990\n",
      "    loss           : -1012.9107663538662\n",
      "    val_loss       : -1031.3874177358357\n",
      "    val_log_likelihood: 1438.196856810131\n",
      "    val_log_marginal: 1042.2991119385877\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch990.pth ...\n",
      "Train Epoch: 991 [512/17352 (3%)] Loss: -1068.903809\n",
      "Train Epoch: 991 [10537/17352 (61%)] Loss: -814.298858\n",
      "Train Epoch: 991 [17090/17352 (98%)] Loss: -1084.986180\n",
      "    epoch          : 991\n",
      "    loss           : -1020.3195420201112\n",
      "    val_loss       : -1020.3576554092874\n",
      "    val_log_likelihood: 1438.38474527656\n",
      "    val_log_marginal: 1037.5193628035565\n",
      "Train Epoch: 992 [512/17352 (3%)] Loss: -1004.868835\n",
      "Train Epoch: 992 [10318/17352 (59%)] Loss: -1133.511199\n",
      "Train Epoch: 992 [16988/17352 (98%)] Loss: -908.197069\n",
      "    epoch          : 992\n",
      "    loss           : -1024.8958771750592\n",
      "    val_loss       : -1032.810576433423\n",
      "    val_log_likelihood: 1446.3766703878612\n",
      "    val_log_marginal: 1047.6981387946987\n",
      "Train Epoch: 993 [512/17352 (3%)] Loss: -1078.057861\n",
      "Train Epoch: 993 [10575/17352 (61%)] Loss: -988.781622\n",
      "Train Epoch: 993 [17064/17352 (98%)] Loss: -1052.981264\n",
      "    epoch          : 993\n",
      "    loss           : -1035.398266139134\n",
      "    val_loss       : -1040.6434072220777\n",
      "    val_log_likelihood: 1449.4977153851416\n",
      "    val_log_marginal: 1051.3596863817384\n",
      "Train Epoch: 994 [512/17352 (3%)] Loss: -1073.110229\n",
      "Train Epoch: 994 [10128/17352 (58%)] Loss: -1048.290100\n",
      "Train Epoch: 994 [16988/17352 (98%)] Loss: -1126.165902\n",
      "    epoch          : 994\n",
      "    loss           : -1031.4931480581147\n",
      "    val_loss       : -1032.0866702408878\n",
      "    val_log_likelihood: 1448.80186516397\n",
      "    val_log_marginal: 1046.3152600489725\n",
      "Train Epoch: 995 [512/17352 (3%)] Loss: -1082.067871\n",
      "Train Epoch: 995 [10270/17352 (59%)] Loss: -971.995902\n",
      "Train Epoch: 995 [17049/17352 (98%)] Loss: -946.103893\n",
      "    epoch          : 995\n",
      "    loss           : -1022.488857351266\n",
      "    val_loss       : -1032.0722975990896\n",
      "    val_log_likelihood: 1441.4931997909412\n",
      "    val_log_marginal: 1042.8934616673405\n",
      "Train Epoch: 996 [512/17352 (3%)] Loss: -1060.103271\n",
      "Train Epoch: 996 [10148/17352 (58%)] Loss: -1158.173177\n",
      "Train Epoch: 996 [17263/17352 (99%)] Loss: -1090.294282\n",
      "    epoch          : 996\n",
      "    loss           : -998.0957957184805\n",
      "    val_loss       : -979.8025123920279\n",
      "    val_log_likelihood: 1421.4471870079192\n",
      "    val_log_marginal: 1009.170829924993\n",
      "Train Epoch: 997 [512/17352 (3%)] Loss: -1008.603699\n",
      "Train Epoch: 997 [10422/17352 (60%)] Loss: -1010.643764\n",
      "Train Epoch: 997 [17126/17352 (99%)] Loss: -1014.411773\n",
      "    epoch          : 997\n",
      "    loss           : -939.3569857088704\n",
      "    val_loss       : -964.9267063445918\n",
      "    val_log_likelihood: 1398.7521385859097\n",
      "    val_log_marginal: 995.4220863131187\n",
      "Train Epoch: 998 [512/17352 (3%)] Loss: -1022.496948\n",
      "Train Epoch: 998 [10632/17352 (61%)] Loss: -786.197715\n",
      "Train Epoch: 998 [16934/17352 (98%)] Loss: -1065.802591\n",
      "    epoch          : 998\n",
      "    loss           : -972.2858657450637\n",
      "    val_loss       : -995.2965585790703\n",
      "    val_log_likelihood: 1425.2655364546467\n",
      "    val_log_marginal: 1018.799290384208\n",
      "Train Epoch: 999 [512/17352 (3%)] Loss: -1057.536499\n",
      "Train Epoch: 999 [9929/17352 (57%)] Loss: -1048.833857\n",
      "Train Epoch: 999 [17049/17352 (98%)] Loss: -865.167456\n",
      "    epoch          : 999\n",
      "    loss           : -989.890075081223\n",
      "    val_loss       : -1001.2751928052677\n",
      "    val_log_likelihood: 1428.1722106839898\n",
      "    val_log_marginal: 1019.7944581821649\n",
      "Train Epoch: 1000 [512/17352 (3%)] Loss: -1039.083252\n",
      "Train Epoch: 1000 [10225/17352 (59%)] Loss: -1147.068359\n",
      "Train Epoch: 1000 [17124/17352 (99%)] Loss: -860.977721\n",
      "    epoch          : 1000\n",
      "    loss           : -998.1200533808272\n",
      "    val_loss       : -995.8632789921312\n",
      "    val_log_likelihood: 1430.9305838760922\n",
      "    val_log_marginal: 1017.013703509176\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch1000.pth ...\n",
      "Train Epoch: 1001 [512/17352 (3%)] Loss: -1033.352295\n",
      "Train Epoch: 1001 [9975/17352 (57%)] Loss: -927.096292\n",
      "Train Epoch: 1001 [17106/17352 (99%)] Loss: -1059.863795\n",
      "    epoch          : 1001\n",
      "    loss           : -1021.4894411358674\n",
      "    val_loss       : -1010.6270458405978\n",
      "    val_log_likelihood: 1438.4562097743787\n",
      "    val_log_marginal: 1030.3317329939143\n",
      "Train Epoch: 1002 [512/17352 (3%)] Loss: -1005.107300\n",
      "Train Epoch: 1002 [10497/17352 (60%)] Loss: -841.069154\n",
      "Train Epoch: 1002 [17335/17352 (100%)] Loss: -1097.153718\n",
      "    epoch          : 1002\n",
      "    loss           : -989.1289759253071\n",
      "    val_loss       : -932.9290242291161\n",
      "    val_log_likelihood: 1423.4092971190132\n",
      "    val_log_marginal: 945.8509864120318\n",
      "Train Epoch: 1003 [512/17352 (3%)] Loss: -952.674683\n",
      "Train Epoch: 1003 [10366/17352 (60%)] Loss: -944.861951\n",
      "Train Epoch: 1003 [17143/17352 (99%)] Loss: -1001.658242\n",
      "    epoch          : 1003\n",
      "    loss           : -957.3484393971358\n",
      "    val_loss       : -994.9615940299462\n",
      "    val_log_likelihood: 1425.4135069624554\n",
      "    val_log_marginal: 1012.6398974283193\n",
      "Train Epoch: 1004 [512/17352 (3%)] Loss: -1028.902222\n",
      "Train Epoch: 1004 [10210/17352 (59%)] Loss: -1044.364298\n",
      "Train Epoch: 1004 [17143/17352 (99%)] Loss: -1002.730990\n",
      "    epoch          : 1004\n",
      "    loss           : -955.1390596596365\n",
      "    val_loss       : -492.11636606365306\n",
      "    val_log_likelihood: 1318.2523909198296\n",
      "    val_log_marginal: 506.891322625292\n",
      "Train Epoch: 1005 [512/17352 (3%)] Loss: -605.871765\n",
      "Train Epoch: 1005 [10292/17352 (59%)] Loss: -892.803789\n",
      "Train Epoch: 1005 [16887/17352 (97%)] Loss: -757.853913\n",
      "    epoch          : 1005\n",
      "    loss           : -722.7962387102742\n",
      "    val_loss       : -814.1616532531052\n",
      "    val_log_likelihood: 1358.6041798675747\n",
      "    val_log_marginal: 847.2593432258848\n",
      "Train Epoch: 1006 [512/17352 (3%)] Loss: -914.523926\n",
      "Train Epoch: 1006 [10066/17352 (58%)] Loss: -504.058974\n",
      "Train Epoch: 1006 [17064/17352 (98%)] Loss: -492.859151\n",
      "    epoch          : 1006\n",
      "    loss           : -192.27378443004937\n",
      "    val_loss       : 109.0101851180183\n",
      "    val_log_likelihood: 1157.8291796474496\n",
      "    val_log_marginal: -36.47347281646553\n",
      "Train Epoch: 1007 [512/17352 (3%)] Loss: 170.663544\n",
      "Train Epoch: 1007 [10304/17352 (59%)] Loss: -380.044089\n",
      "Train Epoch: 1007 [17064/17352 (98%)] Loss: -1010.167511\n",
      "    epoch          : 1007\n",
      "    loss           : -599.7327293401396\n",
      "    val_loss       : -830.1363052786583\n",
      "    val_log_likelihood: 1293.9433912694312\n",
      "    val_log_marginal: 862.6068125347317\n",
      "Train Epoch: 1008 [512/17352 (3%)] Loss: -888.855896\n",
      "Train Epoch: 1008 [10538/17352 (61%)] Loss: -766.258681\n",
      "Train Epoch: 1008 [17090/17352 (98%)] Loss: -954.643497\n",
      "    epoch          : 1008\n",
      "    loss           : -907.9954505542264\n",
      "    val_loss       : -797.618818214946\n",
      "    val_log_likelihood: 1377.023475651653\n",
      "    val_log_marginal: 822.6063716809783\n",
      "Train Epoch: 1009 [512/17352 (3%)] Loss: -842.378967\n",
      "Train Epoch: 1009 [10160/17352 (59%)] Loss: -993.024038\n",
      "Train Epoch: 1009 [16882/17352 (97%)] Loss: -948.704564\n",
      "    epoch          : 1009\n",
      "    loss           : -960.1120688146193\n",
      "    val_loss       : -1011.7791570287695\n",
      "    val_log_likelihood: 1407.400952651948\n",
      "    val_log_marginal: 1027.939472202763\n",
      "Train Epoch: 1010 [512/17352 (3%)] Loss: -1044.514160\n",
      "Train Epoch: 1010 [10144/17352 (58%)] Loss: -1094.007917\n",
      "Train Epoch: 1010 [17335/17352 (100%)] Loss: -941.274046\n",
      "    epoch          : 1010\n",
      "    loss           : -1012.2593566184728\n",
      "    val_loss       : -1009.0157290752708\n",
      "    val_log_likelihood: 1413.306783518149\n",
      "    val_log_marginal: 1022.5159030667586\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch1010.pth ...\n",
      "Train Epoch: 1011 [512/17352 (3%)] Loss: -1043.360840\n",
      "Train Epoch: 1011 [10063/17352 (58%)] Loss: -899.207237\n",
      "Train Epoch: 1011 [17101/17352 (99%)] Loss: -1104.913711\n",
      "    epoch          : 1011\n",
      "    loss           : -1014.1383948251836\n",
      "    val_loss       : -1012.6476371159721\n",
      "    val_log_likelihood: 1422.435828241021\n",
      "    val_log_marginal: 1028.6967824286187\n",
      "Train Epoch: 1012 [512/17352 (3%)] Loss: -1048.896851\n",
      "Train Epoch: 1012 [10120/17352 (58%)] Loss: -986.531699\n",
      "Train Epoch: 1012 [16958/17352 (98%)] Loss: -1070.228516\n",
      "    epoch          : 1012\n",
      "    loss           : -1015.3724620418539\n",
      "    val_loss       : -1019.4582242960556\n",
      "    val_log_likelihood: 1426.151753574009\n",
      "    val_log_marginal: 1035.772522844902\n",
      "Train Epoch: 1013 [512/17352 (3%)] Loss: -1063.511353\n",
      "Train Epoch: 1013 [10453/17352 (60%)] Loss: -1081.467082\n",
      "Train Epoch: 1013 [17090/17352 (98%)] Loss: -1118.527719\n",
      "    epoch          : 1013\n",
      "    loss           : -1020.7178007926499\n",
      "    val_loss       : -1013.045005667759\n",
      "    val_log_likelihood: 1433.612798681828\n",
      "    val_log_marginal: 1024.8832634786027\n",
      "Train Epoch: 1014 [512/17352 (3%)] Loss: -1056.926270\n",
      "Train Epoch: 1014 [10577/17352 (61%)] Loss: -1115.319699\n",
      "Train Epoch: 1014 [16922/17352 (98%)] Loss: -893.805487\n",
      "    epoch          : 1014\n",
      "    loss           : -1025.7616792571125\n",
      "    val_loss       : -1028.157198266457\n",
      "    val_log_likelihood: 1436.5632351426993\n",
      "    val_log_marginal: 1039.2324106759713\n",
      "Train Epoch: 1015 [512/17352 (3%)] Loss: -1074.015747\n",
      "Train Epoch: 1015 [10309/17352 (59%)] Loss: -1063.238084\n",
      "Train Epoch: 1015 [16988/17352 (98%)] Loss: -958.793142\n",
      "    epoch          : 1015\n",
      "    loss           : -1018.2748313152817\n",
      "    val_loss       : -1031.4976849555078\n",
      "    val_log_likelihood: 1437.4666364798773\n",
      "    val_log_marginal: 1044.6844849271758\n",
      "Train Epoch: 1016 [512/17352 (3%)] Loss: -1076.161865\n",
      "Train Epoch: 1016 [10358/17352 (60%)] Loss: -973.636719\n",
      "Train Epoch: 1016 [17126/17352 (99%)] Loss: -1096.391768\n",
      "    epoch          : 1016\n",
      "    loss           : -1023.6151231658845\n",
      "    val_loss       : -1031.0122304300264\n",
      "    val_log_likelihood: 1437.7643959419738\n",
      "    val_log_marginal: 1044.3384531574823\n",
      "Train Epoch: 1017 [512/17352 (3%)] Loss: -1080.886719\n",
      "Train Epoch: 1017 [10801/17352 (62%)] Loss: -1111.530298\n",
      "Train Epoch: 1017 [17153/17352 (99%)] Loss: -1169.888129\n",
      "    epoch          : 1017\n",
      "    loss           : -1034.8174741825635\n",
      "    val_loss       : -1034.7735739875066\n",
      "    val_log_likelihood: 1446.4985498650137\n",
      "    val_log_marginal: 1046.207055338376\n",
      "Train Epoch: 1018 [512/17352 (3%)] Loss: -1080.230591\n",
      "Train Epoch: 1018 [10645/17352 (61%)] Loss: -1135.593817\n",
      "Train Epoch: 1018 [17277/17352 (100%)] Loss: -949.787184\n",
      "    epoch          : 1018\n",
      "    loss           : -1034.246349540185\n",
      "    val_loss       : -1009.5318510696663\n",
      "    val_log_likelihood: 1441.9212628024864\n",
      "    val_log_marginal: 1023.485769891824\n",
      "Train Epoch: 1019 [512/17352 (3%)] Loss: -1051.352539\n",
      "Train Epoch: 1019 [9980/17352 (58%)] Loss: -961.379859\n",
      "Train Epoch: 1019 [16883/17352 (97%)] Loss: -1117.229695\n",
      "    epoch          : 1019\n",
      "    loss           : -1030.0257316315979\n",
      "    val_loss       : -1039.9440899821307\n",
      "    val_log_likelihood: 1449.632973493742\n",
      "    val_log_marginal: 1052.656446568243\n",
      "Train Epoch: 1020 [512/17352 (3%)] Loss: -1085.345947\n",
      "Train Epoch: 1020 [10749/17352 (62%)] Loss: -1115.527284\n",
      "Train Epoch: 1020 [17263/17352 (99%)] Loss: -887.463575\n",
      "    epoch          : 1020\n",
      "    loss           : -1033.055958444354\n",
      "    val_loss       : -1019.395632538121\n",
      "    val_log_likelihood: 1443.0371368340188\n",
      "    val_log_marginal: 1034.5597869159842\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch1020.pth ...\n",
      "Train Epoch: 1021 [512/17352 (3%)] Loss: -1057.455200\n",
      "Train Epoch: 1021 [10284/17352 (59%)] Loss: -999.811952\n",
      "Train Epoch: 1021 [17108/17352 (99%)] Loss: -742.867882\n",
      "    epoch          : 1021\n",
      "    loss           : -1014.586303486498\n",
      "    val_loss       : -915.4391572614828\n",
      "    val_log_likelihood: 1440.0577245464876\n",
      "    val_log_marginal: 926.7122750015146\n",
      "Train Epoch: 1022 [512/17352 (3%)] Loss: -932.909180\n",
      "Train Epoch: 1022 [10408/17352 (60%)] Loss: -840.014015\n",
      "Train Epoch: 1022 [17253/17352 (99%)] Loss: -678.730452\n",
      "    epoch          : 1022\n",
      "    loss           : -953.1203670871412\n",
      "    val_loss       : -270.39511751095216\n",
      "    val_log_likelihood: 1373.4912573010338\n",
      "    val_log_marginal: 288.57996113752165\n",
      "Train Epoch: 1023 [512/17352 (3%)] Loss: -347.798340\n",
      "Train Epoch: 1023 [10414/17352 (60%)] Loss: -874.906336\n",
      "Train Epoch: 1023 [17044/17352 (98%)] Loss: -941.666035\n",
      "    epoch          : 1023\n",
      "    loss           : -730.0846087624849\n",
      "    val_loss       : -932.0789951982887\n",
      "    val_log_likelihood: 1373.3329128038906\n",
      "    val_log_marginal: 973.6956946995036\n",
      "Train Epoch: 1024 [512/17352 (3%)] Loss: -1007.722107\n",
      "Train Epoch: 1024 [10306/17352 (59%)] Loss: -974.303977\n",
      "Train Epoch: 1024 [17064/17352 (98%)] Loss: -663.477855\n",
      "    epoch          : 1024\n",
      "    loss           : -950.8058120888546\n",
      "    val_loss       : -767.906622029674\n",
      "    val_log_likelihood: 1400.6467713388242\n",
      "    val_log_marginal: 799.7610788737628\n",
      "Train Epoch: 1025 [512/17352 (3%)] Loss: -849.934509\n",
      "Train Epoch: 1025 [10713/17352 (62%)] Loss: -1073.113073\n",
      "Train Epoch: 1025 [17126/17352 (99%)] Loss: -951.346094\n",
      "    epoch          : 1025\n",
      "    loss           : -916.281501262952\n",
      "    val_loss       : -984.4258651772271\n",
      "    val_log_likelihood: 1399.7020642608295\n",
      "    val_log_marginal: 1007.5356570553105\n",
      "Train Epoch: 1026 [512/17352 (3%)] Loss: -835.666870\n",
      "Train Epoch: 1026 [10761/17352 (62%)] Loss: -1013.260274\n",
      "Train Epoch: 1026 [16988/17352 (98%)] Loss: -922.194097\n",
      "    epoch          : 1026\n",
      "    loss           : -978.412312415865\n",
      "    val_loss       : -994.799458416661\n",
      "    val_log_likelihood: 1409.9407113656362\n",
      "    val_log_marginal: 1015.8974692178917\n",
      "Train Epoch: 1027 [512/17352 (3%)] Loss: -1030.817627\n",
      "Train Epoch: 1027 [10755/17352 (62%)] Loss: -903.374290\n",
      "Train Epoch: 1027 [17101/17352 (99%)] Loss: -981.402778\n",
      "    epoch          : 1027\n",
      "    loss           : -1013.3019843597203\n",
      "    val_loss       : -1019.5784187081566\n",
      "    val_log_likelihood: 1434.499521057439\n",
      "    val_log_marginal: 1036.9180801275572\n",
      "Train Epoch: 1028 [512/17352 (3%)] Loss: -1066.853882\n",
      "Train Epoch: 1028 [10459/17352 (60%)] Loss: -1070.918556\n",
      "Train Epoch: 1028 [16882/17352 (97%)] Loss: -962.848815\n",
      "    epoch          : 1028\n",
      "    loss           : -1026.1465041108727\n",
      "    val_loss       : -1007.6806518333436\n",
      "    val_log_likelihood: 1435.3767011116827\n",
      "    val_log_marginal: 1022.6353363611258\n",
      "Train Epoch: 1029 [512/17352 (3%)] Loss: -843.106934\n",
      "Train Epoch: 1029 [10590/17352 (61%)] Loss: -1058.260872\n",
      "Train Epoch: 1029 [16988/17352 (98%)] Loss: -880.471304\n",
      "    epoch          : 1029\n",
      "    loss           : -1011.7295233410983\n",
      "    val_loss       : -1011.7584514355487\n",
      "    val_log_likelihood: 1429.3274139354946\n",
      "    val_log_marginal: 1030.7241749750895\n",
      "Train Epoch: 1030 [512/17352 (3%)] Loss: -1044.560791\n",
      "Train Epoch: 1030 [9947/17352 (57%)] Loss: -1051.548995\n",
      "Train Epoch: 1030 [16883/17352 (97%)] Loss: -977.849035\n",
      "    epoch          : 1030\n",
      "    loss           : -1026.6545265744492\n",
      "    val_loss       : -1040.6181298509152\n",
      "    val_log_likelihood: 1445.305928962235\n",
      "    val_log_marginal: 1052.700325920781\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch1030.pth ...\n",
      "Train Epoch: 1031 [512/17352 (3%)] Loss: -1086.037720\n",
      "Train Epoch: 1031 [10020/17352 (58%)] Loss: -1143.568142\n",
      "Train Epoch: 1031 [17044/17352 (98%)] Loss: -1113.578314\n",
      "    epoch          : 1031\n",
      "    loss           : -1027.154363509583\n",
      "    val_loss       : -1021.4216086085929\n",
      "    val_log_likelihood: 1443.5107630500431\n",
      "    val_log_marginal: 1035.168473941103\n",
      "Train Epoch: 1032 [512/17352 (3%)] Loss: -1064.110352\n",
      "Train Epoch: 1032 [9979/17352 (58%)] Loss: -1047.595565\n",
      "Train Epoch: 1032 [17263/17352 (99%)] Loss: -1088.738646\n",
      "    epoch          : 1032\n",
      "    loss           : -1030.2041695501352\n",
      "    val_loss       : -986.4403733922085\n",
      "    val_log_likelihood: 1444.3634566465232\n",
      "    val_log_marginal: 1001.1228887615794\n",
      "Train Epoch: 1033 [512/17352 (3%)] Loss: -1012.443970\n",
      "Train Epoch: 1033 [10493/17352 (60%)] Loss: -1033.079267\n",
      "Train Epoch: 1033 [16883/17352 (97%)] Loss: -853.295380\n",
      "    epoch          : 1033\n",
      "    loss           : -1014.0523276383682\n",
      "    val_loss       : -1035.644070144455\n",
      "    val_log_likelihood: 1452.226080757232\n",
      "    val_log_marginal: 1052.8959832187365\n",
      "Train Epoch: 1034 [512/17352 (3%)] Loss: -1074.152832\n",
      "Train Epoch: 1034 [10601/17352 (61%)] Loss: -945.009121\n",
      "Train Epoch: 1034 [16887/17352 (97%)] Loss: -963.981045\n",
      "    epoch          : 1034\n",
      "    loss           : -1029.3842948378594\n",
      "    val_loss       : -1040.4329949057026\n",
      "    val_log_likelihood: 1455.9980964072624\n",
      "    val_log_marginal: 1056.1506024266857\n",
      "Train Epoch: 1035 [512/17352 (3%)] Loss: -1080.518311\n",
      "Train Epoch: 1035 [10203/17352 (59%)] Loss: -1079.958416\n",
      "Train Epoch: 1035 [17153/17352 (99%)] Loss: -1143.077331\n",
      "    epoch          : 1035\n",
      "    loss           : -1033.451486829748\n",
      "    val_loss       : -975.8917559985013\n",
      "    val_log_likelihood: 1445.1016835475439\n",
      "    val_log_marginal: 991.3046793400054\n",
      "Train Epoch: 1036 [512/17352 (3%)] Loss: -1009.635132\n",
      "Train Epoch: 1036 [10461/17352 (60%)] Loss: -957.937425\n",
      "Train Epoch: 1036 [16872/17352 (97%)] Loss: -1031.488829\n",
      "    epoch          : 1036\n",
      "    loss           : -1024.3202957261312\n",
      "    val_loss       : -1049.915413151064\n",
      "    val_log_likelihood: 1460.5865728371475\n",
      "    val_log_marginal: 1061.9204234726794\n",
      "Train Epoch: 1037 [512/17352 (3%)] Loss: -1057.087769\n",
      "Train Epoch: 1037 [10570/17352 (61%)] Loss: -1068.781541\n",
      "Train Epoch: 1037 [16992/17352 (98%)] Loss: -1138.895080\n",
      "    epoch          : 1037\n",
      "    loss           : -1040.2028704129546\n",
      "    val_loss       : -1044.8985183760567\n",
      "    val_log_likelihood: 1460.3600464212923\n",
      "    val_log_marginal: 1061.5913487428113\n",
      "Train Epoch: 1038 [512/17352 (3%)] Loss: -1092.874146\n",
      "Train Epoch: 1038 [10353/17352 (60%)] Loss: -1134.047231\n",
      "Train Epoch: 1038 [17133/17352 (99%)] Loss: -969.921619\n",
      "    epoch          : 1038\n",
      "    loss           : -1037.0341834782446\n",
      "    val_loss       : -1045.1951847500802\n",
      "    val_log_likelihood: 1462.5534009631592\n",
      "    val_log_marginal: 1059.881607404419\n",
      "Train Epoch: 1039 [512/17352 (3%)] Loss: -1081.394531\n",
      "Train Epoch: 1039 [10076/17352 (58%)] Loss: -965.302760\n",
      "Train Epoch: 1039 [17064/17352 (98%)] Loss: -1038.788603\n",
      "    epoch          : 1039\n",
      "    loss           : -1043.2335892801984\n",
      "    val_loss       : -1041.077721134475\n",
      "    val_log_likelihood: 1463.5995485278067\n",
      "    val_log_marginal: 1059.2104457694036\n",
      "Train Epoch: 1040 [512/17352 (3%)] Loss: -1072.819580\n",
      "Train Epoch: 1040 [9975/17352 (57%)] Loss: -1041.929924\n",
      "Train Epoch: 1040 [17126/17352 (99%)] Loss: -996.046150\n",
      "    epoch          : 1040\n",
      "    loss           : -1041.0461572380864\n",
      "    val_loss       : -1042.8261604116417\n",
      "    val_log_likelihood: 1469.1310586747986\n",
      "    val_log_marginal: 1057.1832389790902\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch1040.pth ...\n",
      "Train Epoch: 1041 [512/17352 (3%)] Loss: -1088.894775\n",
      "Train Epoch: 1041 [10440/17352 (60%)] Loss: -1155.154726\n",
      "Train Epoch: 1041 [17335/17352 (100%)] Loss: -967.199795\n",
      "    epoch          : 1041\n",
      "    loss           : -1043.1143463940157\n",
      "    val_loss       : -992.9406843575745\n",
      "    val_log_likelihood: 1443.964479066268\n",
      "    val_log_marginal: 1007.7775729100404\n",
      "Train Epoch: 1042 [512/17352 (3%)] Loss: -1048.158936\n",
      "Train Epoch: 1042 [10445/17352 (60%)] Loss: -1029.816713\n",
      "Train Epoch: 1042 [17153/17352 (99%)] Loss: -732.221740\n",
      "    epoch          : 1042\n",
      "    loss           : -932.8507864441264\n",
      "    val_loss       : -875.5620781118507\n",
      "    val_log_likelihood: 1381.7589177351908\n",
      "    val_log_marginal: 917.8673569969308\n",
      "Train Epoch: 1043 [512/17352 (3%)] Loss: -667.100403\n",
      "Train Epoch: 1043 [10716/17352 (62%)] Loss: -1007.891689\n",
      "Train Epoch: 1043 [17016/17352 (98%)] Loss: -865.244318\n",
      "    epoch          : 1043\n",
      "    loss           : -892.7031768404999\n",
      "    val_loss       : -974.7777293550752\n",
      "    val_log_likelihood: 1400.324832094821\n",
      "    val_log_marginal: 1006.5662384004987\n",
      "Train Epoch: 1044 [512/17352 (3%)] Loss: -1012.497070\n",
      "Train Epoch: 1044 [10350/17352 (60%)] Loss: -1078.525833\n",
      "Train Epoch: 1044 [16883/17352 (97%)] Loss: -986.522802\n",
      "    epoch          : 1044\n",
      "    loss           : -931.5139741465297\n",
      "    val_loss       : -962.4578811140138\n",
      "    val_log_likelihood: 1392.032439947054\n",
      "    val_log_marginal: 979.053139677984\n",
      "Train Epoch: 1045 [512/17352 (3%)] Loss: -1007.808472\n",
      "Train Epoch: 1045 [9764/17352 (56%)] Loss: -957.010200\n",
      "Train Epoch: 1045 [17253/17352 (99%)] Loss: -829.687066\n",
      "    epoch          : 1045\n",
      "    loss           : -876.1623996632426\n",
      "    val_loss       : -694.8115431061548\n",
      "    val_log_likelihood: 1358.318409049826\n",
      "    val_log_marginal: 715.2651302212078\n",
      "Train Epoch: 1046 [512/17352 (3%)] Loss: -677.266785\n",
      "Train Epoch: 1046 [9397/17352 (54%)] Loss: -871.027481\n",
      "Train Epoch: 1046 [17133/17352 (99%)] Loss: -935.697554\n",
      "    epoch          : 1046\n",
      "    loss           : -922.9988458674804\n",
      "    val_loss       : -988.4526979633608\n",
      "    val_log_likelihood: 1417.2863214956626\n",
      "    val_log_marginal: 1009.9005395629196\n",
      "Train Epoch: 1047 [512/17352 (3%)] Loss: -1049.002441\n",
      "Train Epoch: 1047 [10653/17352 (61%)] Loss: -1007.428056\n",
      "Train Epoch: 1047 [16872/17352 (97%)] Loss: -1079.991458\n",
      "    epoch          : 1047\n",
      "    loss           : -1020.8148487152961\n",
      "    val_loss       : -1023.7425898343237\n",
      "    val_log_likelihood: 1430.5720225023283\n",
      "    val_log_marginal: 1038.2893586977498\n",
      "Train Epoch: 1048 [512/17352 (3%)] Loss: -1076.631226\n",
      "Train Epoch: 1048 [10000/17352 (58%)] Loss: -1049.029591\n",
      "Train Epoch: 1048 [16939/17352 (98%)] Loss: -1017.634628\n",
      "    epoch          : 1048\n",
      "    loss           : -1026.6136920406818\n",
      "    val_loss       : -1048.0967420241748\n",
      "    val_log_likelihood: 1453.322901681027\n",
      "    val_log_marginal: 1063.44466102805\n",
      "Train Epoch: 1049 [512/17352 (3%)] Loss: -1090.808594\n",
      "Train Epoch: 1049 [10442/17352 (60%)] Loss: -1071.454806\n",
      "Train Epoch: 1049 [17153/17352 (99%)] Loss: -1062.327494\n",
      "    epoch          : 1049\n",
      "    loss           : -1035.047300429595\n",
      "    val_loss       : -1018.5340376996808\n",
      "    val_log_likelihood: 1441.3139818239083\n",
      "    val_log_marginal: 1038.070253518106\n",
      "Train Epoch: 1050 [512/17352 (3%)] Loss: -1065.102783\n",
      "Train Epoch: 1050 [10367/17352 (60%)] Loss: -1107.847020\n",
      "Train Epoch: 1050 [17253/17352 (99%)] Loss: -1140.978324\n",
      "    epoch          : 1050\n",
      "    loss           : -1041.7025191989785\n",
      "    val_loss       : -1053.5445946554482\n",
      "    val_log_likelihood: 1462.5137800199702\n",
      "    val_log_marginal: 1065.987392122236\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch1050.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 1051 [512/17352 (3%)] Loss: -1099.099854\n",
      "Train Epoch: 1051 [9973/17352 (57%)] Loss: -1100.311753\n",
      "Train Epoch: 1051 [17253/17352 (99%)] Loss: -1086.581906\n",
      "    epoch          : 1051\n",
      "    loss           : -1052.0199940489392\n",
      "    val_loss       : -1051.3646281264985\n",
      "    val_log_likelihood: 1466.1491807697835\n",
      "    val_log_marginal: 1065.5130284723678\n",
      "Train Epoch: 1052 [512/17352 (3%)] Loss: -1089.018799\n",
      "Train Epoch: 1052 [10572/17352 (61%)] Loss: -1078.694656\n",
      "Train Epoch: 1052 [16872/17352 (97%)] Loss: -1089.893122\n",
      "    epoch          : 1052\n",
      "    loss           : -1051.1731192855095\n",
      "    val_loss       : -1057.358570087641\n",
      "    val_log_likelihood: 1472.7510644491097\n",
      "    val_log_marginal: 1068.7231840590969\n",
      "Train Epoch: 1053 [512/17352 (3%)] Loss: -1094.492432\n",
      "Train Epoch: 1053 [10489/17352 (60%)] Loss: -906.104270\n",
      "Train Epoch: 1053 [16878/17352 (97%)] Loss: -829.469624\n",
      "    epoch          : 1053\n",
      "    loss           : -1011.0896032936806\n",
      "    val_loss       : -1039.6045928158314\n",
      "    val_log_likelihood: 1462.707682015279\n",
      "    val_log_marginal: 1054.1436291602856\n",
      "Train Epoch: 1054 [512/17352 (3%)] Loss: -1082.978882\n",
      "Train Epoch: 1054 [10652/17352 (61%)] Loss: -1048.051680\n",
      "Train Epoch: 1054 [16934/17352 (98%)] Loss: -843.562500\n",
      "    epoch          : 1054\n",
      "    loss           : -966.0861415896733\n",
      "    val_loss       : -1015.3396421401158\n",
      "    val_log_likelihood: 1436.3164847487908\n",
      "    val_log_marginal: 1030.0601489428993\n",
      "Train Epoch: 1055 [512/17352 (3%)] Loss: -1041.206665\n",
      "Train Epoch: 1055 [10308/17352 (59%)] Loss: -953.125593\n",
      "Train Epoch: 1055 [17263/17352 (99%)] Loss: -973.504650\n",
      "    epoch          : 1055\n",
      "    loss           : -1007.5719704517146\n",
      "    val_loss       : -828.7652383351996\n",
      "    val_log_likelihood: 1432.2172538779923\n",
      "    val_log_marginal: 843.4996959280572\n",
      "Train Epoch: 1056 [512/17352 (3%)] Loss: -837.405090\n",
      "Train Epoch: 1056 [9974/17352 (57%)] Loss: -559.649774\n",
      "Train Epoch: 1056 [17335/17352 (100%)] Loss: -950.688694\n",
      "    epoch          : 1056\n",
      "    loss           : -795.5165656725324\n",
      "    val_loss       : 104.88098369043871\n",
      "    val_log_likelihood: 1293.9551645758893\n",
      "    val_log_marginal: -73.48732358355436\n",
      "Train Epoch: 1057 [512/17352 (3%)] Loss: -77.059158\n",
      "Train Epoch: 1057 [10263/17352 (59%)] Loss: -744.992794\n",
      "Train Epoch: 1057 [17263/17352 (99%)] Loss: -1030.454373\n",
      "    epoch          : 1057\n",
      "    loss           : -757.1685861854854\n",
      "    val_loss       : -897.5362053118083\n",
      "    val_log_likelihood: 1373.001698349994\n",
      "    val_log_marginal: 930.2902517603782\n",
      "Train Epoch: 1058 [512/17352 (3%)] Loss: -950.211670\n",
      "Train Epoch: 1058 [10436/17352 (60%)] Loss: -989.881671\n",
      "Train Epoch: 1058 [16883/17352 (97%)] Loss: -735.742570\n",
      "    epoch          : 1058\n",
      "    loss           : -922.8441108993853\n",
      "    val_loss       : -804.9799900181274\n",
      "    val_log_likelihood: 1410.3238146032652\n",
      "    val_log_marginal: 822.0604188922632\n",
      "Train Epoch: 1059 [512/17352 (3%)] Loss: -833.843750\n",
      "Train Epoch: 1059 [10550/17352 (61%)] Loss: -1078.135470\n",
      "Train Epoch: 1059 [17064/17352 (98%)] Loss: -1020.704529\n",
      "    epoch          : 1059\n",
      "    loss           : -967.3653410320259\n",
      "    val_loss       : -977.5086867084357\n",
      "    val_log_likelihood: 1435.149670677489\n",
      "    val_log_marginal: 995.7156864797397\n",
      "Train Epoch: 1060 [512/17352 (3%)] Loss: -1005.201721\n",
      "Train Epoch: 1060 [10130/17352 (58%)] Loss: -881.441564\n",
      "Train Epoch: 1060 [17049/17352 (98%)] Loss: -880.109216\n",
      "    epoch          : 1060\n",
      "    loss           : -939.1869591817446\n",
      "    val_loss       : -508.80244298034876\n",
      "    val_log_likelihood: 1405.8088389110223\n",
      "    val_log_marginal: 517.860636194207\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch1060.pth ...\n",
      "Train Epoch: 1061 [512/17352 (3%)] Loss: -546.562256\n",
      "Train Epoch: 1061 [10281/17352 (59%)] Loss: -667.282191\n",
      "Train Epoch: 1061 [17143/17352 (99%)] Loss: -1108.642420\n",
      "    epoch          : 1061\n",
      "    loss           : -907.1315443842706\n",
      "    val_loss       : -975.8065403263716\n",
      "    val_log_likelihood: 1419.2369171086307\n",
      "    val_log_marginal: 992.5642212391341\n",
      "Train Epoch: 1062 [512/17352 (3%)] Loss: -1031.777222\n",
      "Train Epoch: 1062 [10330/17352 (60%)] Loss: -1019.069839\n",
      "Train Epoch: 1062 [16922/17352 (98%)] Loss: -1042.842256\n",
      "    epoch          : 1062\n",
      "    loss           : -971.0747513621908\n",
      "    val_loss       : -1009.1343863171053\n",
      "    val_log_likelihood: 1434.001283600371\n",
      "    val_log_marginal: 1034.7668083349904\n",
      "Train Epoch: 1063 [512/17352 (3%)] Loss: -1045.478516\n",
      "Train Epoch: 1063 [10453/17352 (60%)] Loss: -1028.898201\n",
      "Train Epoch: 1063 [17143/17352 (99%)] Loss: -868.669109\n",
      "    epoch          : 1063\n",
      "    loss           : -1009.1129755511193\n",
      "    val_loss       : -985.2768542062056\n",
      "    val_log_likelihood: 1425.3215670714894\n",
      "    val_log_marginal: 997.2543268125785\n",
      "Train Epoch: 1064 [512/17352 (3%)] Loss: -994.851685\n",
      "Train Epoch: 1064 [10677/17352 (62%)] Loss: -855.697990\n",
      "Train Epoch: 1064 [17016/17352 (98%)] Loss: -1011.088068\n",
      "    epoch          : 1064\n",
      "    loss           : -996.7211775260818\n",
      "    val_loss       : -1027.2441186837027\n",
      "    val_log_likelihood: 1442.7773946810266\n",
      "    val_log_marginal: 1042.8624405560417\n",
      "Train Epoch: 1065 [512/17352 (3%)] Loss: -1071.971802\n",
      "Train Epoch: 1065 [10642/17352 (61%)] Loss: -1099.467005\n",
      "Train Epoch: 1065 [17143/17352 (99%)] Loss: -1068.801765\n",
      "    epoch          : 1065\n",
      "    loss           : -1012.1784685826942\n",
      "    val_loss       : -1031.726145906799\n",
      "    val_log_likelihood: 1447.9757252051133\n",
      "    val_log_marginal: 1045.5348654434017\n",
      "Train Epoch: 1066 [512/17352 (3%)] Loss: -1073.840698\n",
      "Train Epoch: 1066 [10682/17352 (62%)] Loss: -1103.774867\n",
      "Train Epoch: 1066 [17153/17352 (99%)] Loss: -1024.174321\n",
      "    epoch          : 1066\n",
      "    loss           : -1021.4856261598616\n",
      "    val_loss       : -1013.8690459734236\n",
      "    val_log_likelihood: 1450.3362100674585\n",
      "    val_log_marginal: 1030.2198592569716\n",
      "Train Epoch: 1067 [512/17352 (3%)] Loss: -1052.834961\n",
      "Train Epoch: 1067 [10007/17352 (58%)] Loss: -1060.413945\n",
      "Train Epoch: 1067 [16939/17352 (98%)] Loss: -943.636801\n",
      "    epoch          : 1067\n",
      "    loss           : -1015.8776851397872\n",
      "    val_loss       : -949.2738622685508\n",
      "    val_log_likelihood: 1404.3636494212442\n",
      "    val_log_marginal: 961.7636166875549\n",
      "Train Epoch: 1068 [512/17352 (3%)] Loss: -972.383301\n",
      "Train Epoch: 1068 [10723/17352 (62%)] Loss: -1096.496543\n",
      "Train Epoch: 1068 [17101/17352 (99%)] Loss: -956.441269\n",
      "    epoch          : 1068\n",
      "    loss           : -998.2946950886301\n",
      "    val_loss       : -983.0304998926734\n",
      "    val_log_likelihood: 1422.6167846060089\n",
      "    val_log_marginal: 1008.907368470438\n",
      "Train Epoch: 1069 [512/17352 (3%)] Loss: -1026.892456\n",
      "Train Epoch: 1069 [9632/17352 (56%)] Loss: -1013.285053\n",
      "Train Epoch: 1069 [17044/17352 (98%)] Loss: -992.922712\n",
      "    epoch          : 1069\n",
      "    loss           : -996.9990887515903\n",
      "    val_loss       : -853.1990442097846\n",
      "    val_log_likelihood: 1340.5103630171502\n",
      "    val_log_marginal: 874.0110375227654\n",
      "Train Epoch: 1070 [512/17352 (3%)] Loss: -863.506226\n",
      "Train Epoch: 1070 [10663/17352 (61%)] Loss: -1003.992605\n",
      "Train Epoch: 1070 [17064/17352 (98%)] Loss: -1004.719554\n",
      "    epoch          : 1070\n",
      "    loss           : -958.6971539622594\n",
      "    val_loss       : -1000.0937888397486\n",
      "    val_log_likelihood: 1412.2307615199284\n",
      "    val_log_marginal: 1023.4448343844512\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch1070.pth ...\n",
      "Train Epoch: 1071 [512/17352 (3%)] Loss: -1037.011353\n",
      "Train Epoch: 1071 [9867/17352 (57%)] Loss: -763.279861\n",
      "Train Epoch: 1071 [16934/17352 (98%)] Loss: -870.077110\n",
      "    epoch          : 1071\n",
      "    loss           : -946.5535290104845\n",
      "    val_loss       : -973.1682777861391\n",
      "    val_log_likelihood: 1384.676050574638\n",
      "    val_log_marginal: 999.163185586342\n",
      "Train Epoch: 1072 [512/17352 (3%)] Loss: -982.244507\n",
      "Train Epoch: 1072 [10702/17352 (62%)] Loss: -1069.376428\n",
      "Train Epoch: 1072 [17049/17352 (98%)] Loss: -1078.114726\n",
      "    epoch          : 1072\n",
      "    loss           : -999.0217420919749\n",
      "    val_loss       : -1035.2225617566287\n",
      "    val_log_likelihood: 1430.9987312379824\n",
      "    val_log_marginal: 1047.90444125761\n",
      "Train Epoch: 1073 [512/17352 (3%)] Loss: -1013.224121\n",
      "Train Epoch: 1073 [10091/17352 (58%)] Loss: -848.017718\n",
      "Train Epoch: 1073 [16887/17352 (97%)] Loss: -1113.619066\n",
      "    epoch          : 1073\n",
      "    loss           : -1013.7207582573468\n",
      "    val_loss       : -1037.20416753576\n",
      "    val_log_likelihood: 1444.552191511249\n",
      "    val_log_marginal: 1052.9687948365008\n",
      "Train Epoch: 1074 [512/17352 (3%)] Loss: -1072.687988\n",
      "Train Epoch: 1074 [10259/17352 (59%)] Loss: -1113.132022\n",
      "Train Epoch: 1074 [17277/17352 (100%)] Loss: -1051.125138\n",
      "    epoch          : 1074\n",
      "    loss           : -1037.7480740361261\n",
      "    val_loss       : -1033.0413353117958\n",
      "    val_log_likelihood: 1445.0482763755774\n",
      "    val_log_marginal: 1046.710825285953\n",
      "Train Epoch: 1075 [512/17352 (3%)] Loss: -1080.142334\n",
      "Train Epoch: 1075 [10098/17352 (58%)] Loss: -1088.051272\n",
      "Train Epoch: 1075 [16992/17352 (98%)] Loss: -1065.255669\n",
      "    epoch          : 1075\n",
      "    loss           : -1035.1387276931598\n",
      "    val_loss       : -1034.0217261721925\n",
      "    val_log_likelihood: 1451.6791471075899\n",
      "    val_log_marginal: 1052.7004318026118\n",
      "Train Epoch: 1076 [512/17352 (3%)] Loss: -1088.942139\n",
      "Train Epoch: 1076 [10881/17352 (63%)] Loss: -894.749328\n",
      "Train Epoch: 1076 [17253/17352 (99%)] Loss: -993.279531\n",
      "    epoch          : 1076\n",
      "    loss           : -1045.548970652302\n",
      "    val_loss       : -1038.5015278152046\n",
      "    val_log_likelihood: 1457.840259670664\n",
      "    val_log_marginal: 1057.7759741733385\n",
      "Train Epoch: 1077 [512/17352 (3%)] Loss: -1094.881836\n",
      "Train Epoch: 1077 [10085/17352 (58%)] Loss: -994.370581\n",
      "Train Epoch: 1077 [17049/17352 (98%)] Loss: -945.133960\n",
      "    epoch          : 1077\n",
      "    loss           : -1048.7015646374966\n",
      "    val_loss       : -1056.7970627062853\n",
      "    val_log_likelihood: 1465.2624497040806\n",
      "    val_log_marginal: 1067.3339055809604\n",
      "Train Epoch: 1078 [512/17352 (3%)] Loss: -1089.583252\n",
      "Train Epoch: 1078 [10769/17352 (62%)] Loss: -1152.635794\n",
      "Train Epoch: 1078 [16988/17352 (98%)] Loss: -1159.877043\n",
      "    epoch          : 1078\n",
      "    loss           : -1042.1547177015893\n",
      "    val_loss       : -1044.9522138095404\n",
      "    val_log_likelihood: 1469.9738756949496\n",
      "    val_log_marginal: 1055.6346724696423\n",
      "Train Epoch: 1079 [512/17352 (3%)] Loss: -1087.880859\n",
      "Train Epoch: 1079 [10266/17352 (59%)] Loss: -846.676882\n",
      "Train Epoch: 1079 [16992/17352 (98%)] Loss: -1149.061957\n",
      "    epoch          : 1079\n",
      "    loss           : -1036.5981471286907\n",
      "    val_loss       : -1046.035995377428\n",
      "    val_log_likelihood: 1465.8284740018594\n",
      "    val_log_marginal: 1059.1597633628783\n",
      "Train Epoch: 1080 [512/17352 (3%)] Loss: -1090.219360\n",
      "Train Epoch: 1080 [9820/17352 (57%)] Loss: -914.565487\n",
      "Train Epoch: 1080 [17153/17352 (99%)] Loss: -1129.880589\n",
      "    epoch          : 1080\n",
      "    loss           : -1033.186450399677\n",
      "    val_loss       : -1029.2652636048456\n",
      "    val_log_likelihood: 1471.7168301956697\n",
      "    val_log_marginal: 1042.0212809091106\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch1080.pth ...\n",
      "Train Epoch: 1081 [512/17352 (3%)] Loss: -1059.963745\n",
      "Train Epoch: 1081 [10404/17352 (60%)] Loss: -973.585156\n",
      "Train Epoch: 1081 [16934/17352 (98%)] Loss: -1047.326398\n",
      "    epoch          : 1081\n",
      "    loss           : -1004.5528612101472\n",
      "    val_loss       : -952.8548257961368\n",
      "    val_log_likelihood: 1448.694476545373\n",
      "    val_log_marginal: 965.8804501406125\n",
      "Train Epoch: 1082 [512/17352 (3%)] Loss: -1001.838745\n",
      "Train Epoch: 1082 [10385/17352 (60%)] Loss: -1043.216643\n",
      "Train Epoch: 1082 [17277/17352 (100%)] Loss: -1052.453981\n",
      "    epoch          : 1082\n",
      "    loss           : -1000.9275766985022\n",
      "    val_loss       : -1023.2030230246519\n",
      "    val_log_likelihood: 1436.486346571487\n",
      "    val_log_marginal: 1032.5755026009972\n",
      "Train Epoch: 1083 [512/17352 (3%)] Loss: -1046.376709\n",
      "Train Epoch: 1083 [10479/17352 (60%)] Loss: -972.363188\n",
      "Train Epoch: 1083 [17106/17352 (99%)] Loss: -980.187035\n",
      "    epoch          : 1083\n",
      "    loss           : -1033.0679524477425\n",
      "    val_loss       : -1005.9829408915275\n",
      "    val_log_likelihood: 1461.5710297195872\n",
      "    val_log_marginal: 1018.729120976824\n",
      "Train Epoch: 1084 [512/17352 (3%)] Loss: -1058.280518\n",
      "Train Epoch: 1084 [9908/17352 (57%)] Loss: -995.292926\n",
      "Train Epoch: 1084 [16923/17352 (98%)] Loss: -881.196322\n",
      "    epoch          : 1084\n",
      "    loss           : -1024.5887418766015\n",
      "    val_loss       : -1054.4962211944728\n",
      "    val_log_likelihood: 1468.7478049945883\n",
      "    val_log_marginal: 1071.2347753096599\n",
      "Train Epoch: 1085 [512/17352 (3%)] Loss: -1106.566772\n",
      "Train Epoch: 1085 [9909/17352 (57%)] Loss: -1061.372972\n",
      "Train Epoch: 1085 [16934/17352 (98%)] Loss: -1134.969131\n",
      "    epoch          : 1085\n",
      "    loss           : -1049.814331285144\n",
      "    val_loss       : -1046.1805863290322\n",
      "    val_log_likelihood: 1470.8778713499073\n",
      "    val_log_marginal: 1062.759664485261\n",
      "Train Epoch: 1086 [512/17352 (3%)] Loss: -1086.486328\n",
      "Train Epoch: 1086 [10246/17352 (59%)] Loss: -877.418586\n",
      "Train Epoch: 1086 [17108/17352 (99%)] Loss: -1117.072238\n",
      "    epoch          : 1086\n",
      "    loss           : -1028.8904207865799\n",
      "    val_loss       : -1025.0107064082474\n",
      "    val_log_likelihood: 1446.416307616212\n",
      "    val_log_marginal: 1035.3183158337508\n",
      "Train Epoch: 1087 [512/17352 (3%)] Loss: -1069.399902\n",
      "Train Epoch: 1087 [10985/17352 (63%)] Loss: -931.189583\n",
      "Train Epoch: 1087 [17133/17352 (99%)] Loss: -1075.328581\n",
      "    epoch          : 1087\n",
      "    loss           : -1031.1807053890825\n",
      "    val_loss       : -999.5063916390552\n",
      "    val_log_likelihood: 1454.5979540549881\n",
      "    val_log_marginal: 1019.6744834280444\n",
      "Train Epoch: 1088 [512/17352 (3%)] Loss: -1057.489014\n",
      "Train Epoch: 1088 [10019/17352 (58%)] Loss: -852.204032\n",
      "Train Epoch: 1088 [16878/17352 (97%)] Loss: -1082.532320\n",
      "    epoch          : 1088\n",
      "    loss           : -1027.6754484731819\n",
      "    val_loss       : -1047.39275010381\n",
      "    val_log_likelihood: 1470.7089531839058\n",
      "    val_log_marginal: 1068.2989923458495\n",
      "Train Epoch: 1089 [512/17352 (3%)] Loss: -1084.189819\n",
      "Train Epoch: 1089 [10899/17352 (63%)] Loss: -926.349796\n",
      "Train Epoch: 1089 [16872/17352 (97%)] Loss: -1168.003472\n",
      "    epoch          : 1089\n",
      "    loss           : -1045.5189425343506\n",
      "    val_loss       : -1055.3057406539237\n",
      "    val_log_likelihood: 1474.8414776842515\n",
      "    val_log_marginal: 1068.4502335739223\n",
      "Train Epoch: 1090 [512/17352 (3%)] Loss: -1094.530273\n",
      "Train Epoch: 1090 [10555/17352 (61%)] Loss: -923.108871\n",
      "Train Epoch: 1090 [16882/17352 (97%)] Loss: -996.580423\n",
      "    epoch          : 1090\n",
      "    loss           : -1050.2903688888814\n",
      "    val_loss       : -1054.222016758191\n",
      "    val_log_likelihood: 1476.3683408448487\n",
      "    val_log_marginal: 1068.5752105752551\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch1090.pth ...\n",
      "Train Epoch: 1091 [512/17352 (3%)] Loss: -1100.148193\n",
      "Train Epoch: 1091 [10360/17352 (60%)] Loss: -912.061189\n",
      "Train Epoch: 1091 [17090/17352 (98%)] Loss: -1155.451093\n",
      "    epoch          : 1091\n",
      "    loss           : -1045.1840804931965\n",
      "    val_loss       : -1037.7974146440145\n",
      "    val_log_likelihood: 1479.351162730868\n",
      "    val_log_marginal: 1055.8719605001338\n",
      "Train Epoch: 1092 [512/17352 (3%)] Loss: -1081.255127\n",
      "Train Epoch: 1092 [10245/17352 (59%)] Loss: -913.935850\n",
      "Train Epoch: 1092 [17016/17352 (98%)] Loss: -1082.450063\n",
      "    epoch          : 1092\n",
      "    loss           : -1047.5583960860033\n",
      "    val_loss       : -1043.5471181303378\n",
      "    val_log_likelihood: 1476.801086416316\n",
      "    val_log_marginal: 1060.560839134922\n",
      "Train Epoch: 1093 [512/17352 (3%)] Loss: -1083.676270\n",
      "Train Epoch: 1093 [10021/17352 (58%)] Loss: -1142.102079\n",
      "Train Epoch: 1093 [16923/17352 (98%)] Loss: -1138.608544\n",
      "    epoch          : 1093\n",
      "    loss           : -1046.4480113931697\n",
      "    val_loss       : -1042.566682689969\n",
      "    val_log_likelihood: 1477.3841297696117\n",
      "    val_log_marginal: 1067.604376085621\n",
      "Train Epoch: 1094 [512/17352 (3%)] Loss: -910.243042\n",
      "Train Epoch: 1094 [9580/17352 (55%)] Loss: -945.842597\n",
      "Train Epoch: 1094 [17101/17352 (99%)] Loss: -1099.205729\n",
      "    epoch          : 1094\n",
      "    loss           : -1052.436781211576\n",
      "    val_loss       : -1042.307702371607\n",
      "    val_log_likelihood: 1473.9627076834968\n",
      "    val_log_marginal: 1054.6610881930083\n",
      "Train Epoch: 1095 [512/17352 (3%)] Loss: -1094.121460\n",
      "Train Epoch: 1095 [10294/17352 (59%)] Loss: -823.489429\n",
      "Train Epoch: 1095 [17124/17352 (99%)] Loss: -1084.970478\n",
      "    epoch          : 1095\n",
      "    loss           : -1041.736060574258\n",
      "    val_loss       : -994.4585166330972\n",
      "    val_log_likelihood: 1454.3722720095636\n",
      "    val_log_marginal: 1035.3195089116407\n",
      "Train Epoch: 1096 [512/17352 (3%)] Loss: -1036.635132\n",
      "Train Epoch: 1096 [11152/17352 (64%)] Loss: -856.841956\n",
      "Train Epoch: 1096 [17090/17352 (98%)] Loss: -914.859201\n",
      "    epoch          : 1096\n",
      "    loss           : -1015.3877707883177\n",
      "    val_loss       : -1022.434142034207\n",
      "    val_log_likelihood: 1461.9477089581026\n",
      "    val_log_marginal: 1045.206520276268\n",
      "Train Epoch: 1097 [512/17352 (3%)] Loss: -845.294006\n",
      "Train Epoch: 1097 [9965/17352 (57%)] Loss: -998.048242\n",
      "Train Epoch: 1097 [16882/17352 (97%)] Loss: -1120.677690\n",
      "    epoch          : 1097\n",
      "    loss           : -1028.000696719181\n",
      "    val_loss       : -1051.1088802864017\n",
      "    val_log_likelihood: 1474.4450733387396\n",
      "    val_log_marginal: 1060.678421482772\n",
      "Train Epoch: 1098 [512/17352 (3%)] Loss: -1079.336914\n",
      "Train Epoch: 1098 [10428/17352 (60%)] Loss: -1013.768229\n",
      "Train Epoch: 1098 [17153/17352 (99%)] Loss: -1021.342798\n",
      "    epoch          : 1098\n",
      "    loss           : -1031.6687378510762\n",
      "    val_loss       : -996.5406317540458\n",
      "    val_log_likelihood: 1471.293809187907\n",
      "    val_log_marginal: 1015.3774345017612\n",
      "Train Epoch: 1099 [512/17352 (3%)] Loss: -1046.140137\n",
      "Train Epoch: 1099 [10822/17352 (62%)] Loss: -935.502914\n",
      "Train Epoch: 1099 [17124/17352 (99%)] Loss: -1144.856117\n",
      "    epoch          : 1099\n",
      "    loss           : -1027.1137400801301\n",
      "    val_loss       : -965.1832190605398\n",
      "    val_log_likelihood: 1430.659554131944\n",
      "    val_log_marginal: 985.9271054830776\n",
      "Train Epoch: 1100 [512/17352 (3%)] Loss: -1036.413696\n",
      "Train Epoch: 1100 [10019/17352 (58%)] Loss: -974.693703\n",
      "Train Epoch: 1100 [17108/17352 (99%)] Loss: -1068.751533\n",
      "    epoch          : 1100\n",
      "    loss           : -950.2431814485437\n",
      "    val_loss       : -881.9976143600653\n",
      "    val_log_likelihood: 1373.4261207407746\n",
      "    val_log_marginal: 899.293740994852\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch1100.pth ...\n",
      "Train Epoch: 1101 [512/17352 (3%)] Loss: -921.494995\n",
      "Train Epoch: 1101 [10333/17352 (60%)] Loss: -816.134907\n",
      "Train Epoch: 1101 [16958/17352 (98%)] Loss: -1062.185502\n",
      "    epoch          : 1101\n",
      "    loss           : -955.2776793237048\n",
      "    val_loss       : -1016.2622290961448\n",
      "    val_log_likelihood: 1446.4852954875898\n",
      "    val_log_marginal: 1044.3034210955223\n",
      "Train Epoch: 1102 [512/17352 (3%)] Loss: -1046.820068\n",
      "Train Epoch: 1102 [10650/17352 (61%)] Loss: -1021.162088\n",
      "Train Epoch: 1102 [16939/17352 (98%)] Loss: -853.938109\n",
      "    epoch          : 1102\n",
      "    loss           : -992.2514850771462\n",
      "    val_loss       : -1009.6337063908278\n",
      "    val_log_likelihood: 1454.6293964393196\n",
      "    val_log_marginal: 1036.4837773188324\n",
      "Train Epoch: 1103 [512/17352 (3%)] Loss: -1029.223511\n",
      "Train Epoch: 1103 [9835/17352 (57%)] Loss: -854.382284\n",
      "Train Epoch: 1103 [16988/17352 (98%)] Loss: -951.075932\n",
      "    epoch          : 1103\n",
      "    loss           : -953.5634174233854\n",
      "    val_loss       : -1018.3027929565246\n",
      "    val_log_likelihood: 1434.5634748169211\n",
      "    val_log_marginal: 1034.0731887984796\n",
      "Train Epoch: 1104 [512/17352 (3%)] Loss: -1074.197754\n",
      "Train Epoch: 1104 [10164/17352 (59%)] Loss: -1086.370648\n",
      "Train Epoch: 1104 [16883/17352 (97%)] Loss: -995.276649\n",
      "    epoch          : 1104\n",
      "    loss           : -1036.1628615504178\n",
      "    val_loss       : -1048.870153994136\n",
      "    val_log_likelihood: 1464.5541542746796\n",
      "    val_log_marginal: 1061.4306591894886\n",
      "Train Epoch: 1105 [512/17352 (3%)] Loss: -1079.353394\n",
      "Train Epoch: 1105 [10792/17352 (62%)] Loss: -922.819784\n",
      "Train Epoch: 1105 [17049/17352 (98%)] Loss: -1105.151755\n",
      "    epoch          : 1105\n",
      "    loss           : -1027.1298567096765\n",
      "    val_loss       : -1039.5180112360617\n",
      "    val_log_likelihood: 1467.3890626326145\n",
      "    val_log_marginal: 1055.954809410877\n",
      "Train Epoch: 1106 [512/17352 (3%)] Loss: -1088.342529\n",
      "Train Epoch: 1106 [9960/17352 (57%)] Loss: -1174.796913\n",
      "Train Epoch: 1106 [16882/17352 (97%)] Loss: -884.207527\n",
      "    epoch          : 1106\n",
      "    loss           : -1038.874291743633\n",
      "    val_loss       : -1064.9218798421687\n",
      "    val_log_likelihood: 1474.0456050753767\n",
      "    val_log_marginal: 1076.8212724219786\n",
      "Train Epoch: 1107 [512/17352 (3%)] Loss: -1108.605103\n",
      "Train Epoch: 1107 [10772/17352 (62%)] Loss: -892.043683\n",
      "Train Epoch: 1107 [16939/17352 (98%)] Loss: -995.267868\n",
      "    epoch          : 1107\n",
      "    loss           : -1053.6065330361273\n",
      "    val_loss       : -1062.746838463009\n",
      "    val_log_likelihood: 1487.4227460414818\n",
      "    val_log_marginal: 1076.834532268973\n",
      "Train Epoch: 1108 [512/17352 (3%)] Loss: -1110.219971\n",
      "Train Epoch: 1108 [10124/17352 (58%)] Loss: -891.160885\n",
      "Train Epoch: 1108 [16883/17352 (97%)] Loss: -1097.679251\n",
      "    epoch          : 1108\n",
      "    loss           : -1050.3335442019907\n",
      "    val_loss       : -1034.6079042904382\n",
      "    val_log_likelihood: 1470.1233281188647\n",
      "    val_log_marginal: 1047.31876834534\n",
      "Train Epoch: 1109 [512/17352 (3%)] Loss: -1083.264893\n",
      "Train Epoch: 1109 [10436/17352 (60%)] Loss: -1126.690565\n",
      "Train Epoch: 1109 [16882/17352 (97%)] Loss: -1000.490543\n",
      "    epoch          : 1109\n",
      "    loss           : -1037.2494520489665\n",
      "    val_loss       : -1046.5016500143956\n",
      "    val_log_likelihood: 1477.7914899087095\n",
      "    val_log_marginal: 1062.7483901298208\n",
      "Train Epoch: 1110 [512/17352 (3%)] Loss: -1108.640015\n",
      "Train Epoch: 1110 [10081/17352 (58%)] Loss: -1085.598590\n",
      "Train Epoch: 1110 [17277/17352 (100%)] Loss: -1150.014757\n",
      "    epoch          : 1110\n",
      "    loss           : -1042.123862861972\n",
      "    val_loss       : -952.4987708117187\n",
      "    val_log_likelihood: 1468.0555898922084\n",
      "    val_log_marginal: 964.9798271418005\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch1110.pth ...\n",
      "Train Epoch: 1111 [512/17352 (3%)] Loss: -995.615967\n",
      "Train Epoch: 1111 [9979/17352 (58%)] Loss: -706.914748\n",
      "Train Epoch: 1111 [16992/17352 (98%)] Loss: -957.432571\n",
      "    epoch          : 1111\n",
      "    loss           : -945.0295937869096\n",
      "    val_loss       : -1018.8284535083469\n",
      "    val_log_likelihood: 1464.383865628203\n",
      "    val_log_marginal: 1044.2179312994165\n",
      "Train Epoch: 1112 [512/17352 (3%)] Loss: -1017.606201\n",
      "Train Epoch: 1112 [10586/17352 (61%)] Loss: -822.225387\n",
      "Train Epoch: 1112 [16887/17352 (97%)] Loss: -507.857422\n",
      "    epoch          : 1112\n",
      "    loss           : -874.9436963281697\n",
      "    val_loss       : -762.7062588438118\n",
      "    val_log_likelihood: 1395.8249496022215\n",
      "    val_log_marginal: 832.7641289657032\n",
      "Train Epoch: 1113 [512/17352 (3%)] Loss: -880.871887\n",
      "Train Epoch: 1113 [10243/17352 (59%)] Loss: -894.146291\n",
      "Train Epoch: 1113 [17263/17352 (99%)] Loss: -822.009849\n",
      "    epoch          : 1113\n",
      "    loss           : -905.0793236500234\n",
      "    val_loss       : -922.6439180773067\n",
      "    val_log_likelihood: 1409.5033829458669\n",
      "    val_log_marginal: 962.1076353087911\n",
      "Train Epoch: 1114 [512/17352 (3%)] Loss: -944.072876\n",
      "Train Epoch: 1114 [10148/17352 (58%)] Loss: -1050.328516\n",
      "Train Epoch: 1114 [17044/17352 (98%)] Loss: -860.469187\n",
      "    epoch          : 1114\n",
      "    loss           : -998.7561398535844\n",
      "    val_loss       : -901.5785876899054\n",
      "    val_log_likelihood: 1443.2053473538297\n",
      "    val_log_marginal: 918.0858110399677\n",
      "Train Epoch: 1115 [512/17352 (3%)] Loss: -935.690430\n",
      "Train Epoch: 1115 [10657/17352 (61%)] Loss: -1032.431329\n",
      "Train Epoch: 1115 [17277/17352 (100%)] Loss: -1017.919509\n",
      "    epoch          : 1115\n",
      "    loss           : -956.3216263537741\n",
      "    val_loss       : -701.2323544137253\n",
      "    val_log_likelihood: 1405.8049471047568\n",
      "    val_log_marginal: 722.785175218082\n",
      "Train Epoch: 1116 [512/17352 (3%)] Loss: -772.102173\n",
      "Train Epoch: 1116 [10872/17352 (63%)] Loss: -691.454618\n",
      "Train Epoch: 1116 [17124/17352 (99%)] Loss: -58.218869\n",
      "    epoch          : 1116\n",
      "    loss           : -384.61414164684356\n",
      "    val_loss       : -342.1375872785447\n",
      "    val_log_likelihood: 1216.1535975992279\n",
      "    val_log_marginal: 392.764560394964\n",
      "Train Epoch: 1117 [512/17352 (3%)] Loss: -47.298355\n",
      "Train Epoch: 1117 [10232/17352 (59%)] Loss: -374.583034\n",
      "Train Epoch: 1117 [17108/17352 (99%)] Loss: -825.617839\n",
      "    epoch          : 1117\n",
      "    loss           : -556.3728593602851\n",
      "    val_loss       : -210.93304214284913\n",
      "    val_log_likelihood: 1312.8052053957936\n",
      "    val_log_marginal: 241.21056704364503\n",
      "Train Epoch: 1118 [512/17352 (3%)] Loss: 132.230576\n",
      "Train Epoch: 1118 [10413/17352 (60%)] Loss: -660.799267\n",
      "Train Epoch: 1118 [17108/17352 (99%)] Loss: -1026.040625\n",
      "    epoch          : 1118\n",
      "    loss           : -603.9311717883571\n",
      "    val_loss       : 1133.7318378181435\n",
      "    val_log_likelihood: 1301.4780987421743\n",
      "    val_log_marginal: -1094.1499603582245\n",
      "Train Epoch: 1119 [512/17352 (3%)] Loss: 1324.273926\n",
      "Train Epoch: 1119 [10265/17352 (59%)] Loss: -322.238272\n",
      "Train Epoch: 1119 [17064/17352 (98%)] Loss: 492.915728\n",
      "    epoch          : 1119\n",
      "    loss           : -190.53842219912883\n",
      "    val_loss       : 9.325765525296964\n",
      "    val_log_likelihood: 1261.6391809398358\n",
      "    val_log_marginal: 46.74072707079566\n",
      "Train Epoch: 1120 [512/17352 (3%)] Loss: -6.382483\n",
      "Train Epoch: 1120 [11034/17352 (64%)] Loss: -913.392554\n",
      "Train Epoch: 1120 [17108/17352 (99%)] Loss: -793.276042\n",
      "    epoch          : 1120\n",
      "    loss           : -554.6241935758642\n",
      "    val_loss       : -881.918325611308\n",
      "    val_log_likelihood: 1300.5211300364138\n",
      "    val_log_marginal: 915.0318594103547\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch1120.pth ...\n",
      "Train Epoch: 1121 [512/17352 (3%)] Loss: -948.046021\n",
      "Train Epoch: 1121 [10308/17352 (59%)] Loss: -1029.025087\n",
      "Train Epoch: 1121 [17126/17352 (99%)] Loss: -1061.370312\n",
      "    epoch          : 1121\n",
      "    loss           : -932.0950805793007\n",
      "    val_loss       : -991.210669596083\n",
      "    val_log_likelihood: 1396.800678192393\n",
      "    val_log_marginal: 1010.7939464233266\n",
      "Train Epoch: 1122 [512/17352 (3%)] Loss: -1047.716797\n",
      "Train Epoch: 1122 [10216/17352 (59%)] Loss: -897.303321\n",
      "Train Epoch: 1122 [17064/17352 (98%)] Loss: -1126.344016\n",
      "    epoch          : 1122\n",
      "    loss           : -1015.1231345744866\n",
      "    val_loss       : -1023.91999742089\n",
      "    val_log_likelihood: 1424.2059181730747\n",
      "    val_log_marginal: 1039.7447496966183\n",
      "Train Epoch: 1123 [512/17352 (3%)] Loss: -1068.251953\n",
      "Train Epoch: 1123 [10422/17352 (60%)] Loss: -1059.079044\n",
      "Train Epoch: 1123 [17263/17352 (99%)] Loss: -1150.586259\n",
      "    epoch          : 1123\n",
      "    loss           : -1033.2437211594568\n",
      "    val_loss       : -1046.190721602805\n",
      "    val_log_likelihood: 1438.0084689350003\n",
      "    val_log_marginal: 1055.7318385887288\n",
      "Train Epoch: 1124 [512/17352 (3%)] Loss: -1067.074707\n",
      "Train Epoch: 1124 [10279/17352 (59%)] Loss: -1078.562109\n",
      "Train Epoch: 1124 [17064/17352 (98%)] Loss: -1104.443023\n",
      "    epoch          : 1124\n",
      "    loss           : -1040.1315236924142\n",
      "    val_loss       : -1050.720044879619\n",
      "    val_log_likelihood: 1448.4145375826247\n",
      "    val_log_marginal: 1062.2227320023799\n",
      "Train Epoch: 1125 [512/17352 (3%)] Loss: -1086.159302\n",
      "Train Epoch: 1125 [10341/17352 (60%)] Loss: -1114.875145\n",
      "Train Epoch: 1125 [17108/17352 (99%)] Loss: -895.382796\n",
      "    epoch          : 1125\n",
      "    loss           : -1046.3361901135822\n",
      "    val_loss       : -1051.0484968008773\n",
      "    val_log_likelihood: 1451.8771433176266\n",
      "    val_log_marginal: 1065.690343487007\n",
      "Train Epoch: 1126 [512/17352 (3%)] Loss: -1087.459473\n",
      "Train Epoch: 1126 [10360/17352 (60%)] Loss: -1076.365390\n",
      "Train Epoch: 1126 [17277/17352 (100%)] Loss: -1099.366536\n",
      "    epoch          : 1126\n",
      "    loss           : -1053.5728924878294\n",
      "    val_loss       : -1050.7930943118813\n",
      "    val_log_likelihood: 1454.0852088056076\n",
      "    val_log_marginal: 1063.23238609507\n",
      "Train Epoch: 1127 [512/17352 (3%)] Loss: -1102.991089\n",
      "Train Epoch: 1127 [10316/17352 (59%)] Loss: -1107.231478\n",
      "Train Epoch: 1127 [16988/17352 (98%)] Loss: -989.826400\n",
      "    epoch          : 1127\n",
      "    loss           : -1050.3856358934208\n",
      "    val_loss       : -1057.9999753304096\n",
      "    val_log_likelihood: 1458.2715974859989\n",
      "    val_log_marginal: 1066.0564997772476\n",
      "Train Epoch: 1128 [512/17352 (3%)] Loss: -1098.131226\n",
      "Train Epoch: 1128 [10161/17352 (59%)] Loss: -1126.066851\n",
      "Train Epoch: 1128 [17044/17352 (98%)] Loss: -1115.276381\n",
      "    epoch          : 1128\n",
      "    loss           : -1055.0572430934824\n",
      "    val_loss       : -1062.297774366578\n",
      "    val_log_likelihood: 1465.3986042292302\n",
      "    val_log_marginal: 1073.902681055905\n",
      "Train Epoch: 1129 [512/17352 (3%)] Loss: -1102.510254\n",
      "Train Epoch: 1129 [9753/17352 (56%)] Loss: -1043.489995\n",
      "Train Epoch: 1129 [17126/17352 (99%)] Loss: -1049.487294\n",
      "    epoch          : 1129\n",
      "    loss           : -1054.542850002707\n",
      "    val_loss       : -1063.0240104931054\n",
      "    val_log_likelihood: 1466.8174599794384\n",
      "    val_log_marginal: 1075.094347524315\n",
      "Train Epoch: 1130 [512/17352 (3%)] Loss: -1096.437256\n",
      "Train Epoch: 1130 [10059/17352 (58%)] Loss: -1083.047268\n",
      "Train Epoch: 1130 [17143/17352 (99%)] Loss: -1129.053165\n",
      "    epoch          : 1130\n",
      "    loss           : -1060.2402525748444\n",
      "    val_loss       : -1062.1621770072022\n",
      "    val_log_likelihood: 1471.4419763808096\n",
      "    val_log_marginal: 1070.8841310451342\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch1130.pth ...\n",
      "Train Epoch: 1131 [512/17352 (3%)] Loss: -1098.322998\n",
      "Train Epoch: 1131 [10769/17352 (62%)] Loss: -1155.232851\n",
      "Train Epoch: 1131 [16922/17352 (98%)] Loss: -1039.895360\n",
      "    epoch          : 1131\n",
      "    loss           : -1055.4317527893838\n",
      "    val_loss       : -1051.351124086979\n",
      "    val_log_likelihood: 1460.6517321446952\n",
      "    val_log_marginal: 1065.0706692898034\n",
      "Train Epoch: 1132 [512/17352 (3%)] Loss: -1062.050293\n",
      "Train Epoch: 1132 [10416/17352 (60%)] Loss: -1173.273438\n",
      "Train Epoch: 1132 [17106/17352 (99%)] Loss: -1025.177045\n",
      "    epoch          : 1132\n",
      "    loss           : -1045.2504588499924\n",
      "    val_loss       : -1049.3074722301517\n",
      "    val_log_likelihood: 1463.9707903500428\n",
      "    val_log_marginal: 1062.1370289007887\n",
      "Train Epoch: 1133 [512/17352 (3%)] Loss: -1088.854492\n",
      "Train Epoch: 1133 [10699/17352 (62%)] Loss: -981.338373\n",
      "Train Epoch: 1133 [16939/17352 (98%)] Loss: -1150.379573\n",
      "    epoch          : 1133\n",
      "    loss           : -1056.2305953605846\n",
      "    val_loss       : -1063.4138024665754\n",
      "    val_log_likelihood: 1475.294431143219\n",
      "    val_log_marginal: 1077.075959268855\n",
      "Train Epoch: 1134 [512/17352 (3%)] Loss: -921.898682\n",
      "Train Epoch: 1134 [10409/17352 (60%)] Loss: -1022.951265\n",
      "Train Epoch: 1134 [16922/17352 (98%)] Loss: -923.500000\n",
      "    epoch          : 1134\n",
      "    loss           : -1065.1985377444394\n",
      "    val_loss       : -1069.465137593217\n",
      "    val_log_likelihood: 1481.2927608064385\n",
      "    val_log_marginal: 1082.4416514997736\n",
      "Train Epoch: 1135 [512/17352 (3%)] Loss: -1102.809814\n",
      "Train Epoch: 1135 [9876/17352 (57%)] Loss: -1051.750206\n",
      "Train Epoch: 1135 [17090/17352 (98%)] Loss: -1097.037818\n",
      "    epoch          : 1135\n",
      "    loss           : -1062.5618820022823\n",
      "    val_loss       : -1065.2844309622699\n",
      "    val_log_likelihood: 1479.8771796928356\n",
      "    val_log_marginal: 1077.404060573524\n",
      "Train Epoch: 1136 [512/17352 (3%)] Loss: -1100.746826\n",
      "Train Epoch: 1136 [10048/17352 (58%)] Loss: -1183.704752\n",
      "Train Epoch: 1136 [17143/17352 (99%)] Loss: -1155.187234\n",
      "    epoch          : 1136\n",
      "    loss           : -1059.946772405667\n",
      "    val_loss       : -1071.0115623368008\n",
      "    val_log_likelihood: 1482.7536015045666\n",
      "    val_log_marginal: 1082.076851159859\n",
      "Train Epoch: 1137 [512/17352 (3%)] Loss: -1113.086792\n",
      "Train Epoch: 1137 [10131/17352 (58%)] Loss: -1049.931319\n",
      "Train Epoch: 1137 [17335/17352 (100%)] Loss: -1047.668860\n",
      "    epoch          : 1137\n",
      "    loss           : -1069.1156748669484\n",
      "    val_loss       : -1066.4651637967124\n",
      "    val_log_likelihood: 1482.6582130448548\n",
      "    val_log_marginal: 1076.7181954698642\n",
      "Train Epoch: 1138 [512/17352 (3%)] Loss: -1105.339844\n",
      "Train Epoch: 1138 [11007/17352 (63%)] Loss: -941.482467\n",
      "Train Epoch: 1138 [17108/17352 (99%)] Loss: -927.181183\n",
      "    epoch          : 1138\n",
      "    loss           : -1074.1926632178217\n",
      "    val_loss       : -1068.4499024547906\n",
      "    val_log_likelihood: 1484.1559815278408\n",
      "    val_log_marginal: 1078.0272913281472\n",
      "Train Epoch: 1139 [512/17352 (3%)] Loss: -1108.192993\n",
      "Train Epoch: 1139 [10705/17352 (62%)] Loss: -1056.176527\n",
      "Train Epoch: 1139 [16988/17352 (98%)] Loss: -1005.417132\n",
      "    epoch          : 1139\n",
      "    loss           : -1059.6114700740065\n",
      "    val_loss       : -1067.850697870417\n",
      "    val_log_likelihood: 1487.1668550125817\n",
      "    val_log_marginal: 1083.6959817591037\n",
      "Train Epoch: 1140 [512/17352 (3%)] Loss: -1121.284912\n",
      "Train Epoch: 1140 [10530/17352 (61%)] Loss: -1041.740127\n",
      "Train Epoch: 1140 [16957/17352 (98%)] Loss: -1112.916759\n",
      "    epoch          : 1140\n",
      "    loss           : -1069.980296681992\n",
      "    val_loss       : -1076.312474172441\n",
      "    val_log_likelihood: 1493.3785278080006\n",
      "    val_log_marginal: 1088.882776139156\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch1140.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 1141 [512/17352 (3%)] Loss: -1106.311890\n",
      "Train Epoch: 1141 [10317/17352 (59%)] Loss: -932.526680\n",
      "Train Epoch: 1141 [16923/17352 (98%)] Loss: -1132.055378\n",
      "    epoch          : 1141\n",
      "    loss           : -1066.8590006479715\n",
      "    val_loss       : -1056.703902888365\n",
      "    val_log_likelihood: 1483.2510167860626\n",
      "    val_log_marginal: 1068.1911152415657\n",
      "Train Epoch: 1142 [512/17352 (3%)] Loss: -1092.555664\n",
      "Train Epoch: 1142 [10162/17352 (59%)] Loss: -1013.560733\n",
      "Train Epoch: 1142 [17126/17352 (99%)] Loss: -1133.052500\n",
      "    epoch          : 1142\n",
      "    loss           : -1065.4725873332118\n",
      "    val_loss       : -1065.6188237687759\n",
      "    val_log_likelihood: 1490.5651310037201\n",
      "    val_log_marginal: 1079.8717953408525\n",
      "Train Epoch: 1143 [512/17352 (3%)] Loss: -1103.729614\n",
      "Train Epoch: 1143 [10276/17352 (59%)] Loss: -1119.228586\n",
      "Train Epoch: 1143 [16878/17352 (97%)] Loss: -1089.376563\n",
      "    epoch          : 1143\n",
      "    loss           : -1052.180798546136\n",
      "    val_loss       : -1059.3298049655139\n",
      "    val_log_likelihood: 1490.4175296162477\n",
      "    val_log_marginal: 1073.8848892849992\n",
      "Train Epoch: 1144 [512/17352 (3%)] Loss: -1101.320068\n",
      "Train Epoch: 1144 [10005/17352 (58%)] Loss: -1106.568106\n",
      "Train Epoch: 1144 [17253/17352 (99%)] Loss: -843.872989\n",
      "    epoch          : 1144\n",
      "    loss           : -1056.5476397163166\n",
      "    val_loss       : -1068.460688517651\n",
      "    val_log_likelihood: 1490.5907426729186\n",
      "    val_log_marginal: 1080.0859060675482\n",
      "Train Epoch: 1145 [512/17352 (3%)] Loss: -1099.038940\n",
      "Train Epoch: 1145 [10346/17352 (60%)] Loss: -866.605611\n",
      "Train Epoch: 1145 [16882/17352 (97%)] Loss: -1084.795770\n",
      "    epoch          : 1145\n",
      "    loss           : -1046.8690782459933\n",
      "    val_loss       : -1075.8245118675923\n",
      "    val_log_likelihood: 1493.7931689377656\n",
      "    val_log_marginal: 1086.9263439099525\n",
      "Train Epoch: 1146 [512/17352 (3%)] Loss: -1117.869141\n",
      "Train Epoch: 1146 [10158/17352 (59%)] Loss: -1038.793313\n",
      "Train Epoch: 1146 [17126/17352 (99%)] Loss: -1164.438516\n",
      "    epoch          : 1146\n",
      "    loss           : -1041.863023250304\n",
      "    val_loss       : -904.1443428938793\n",
      "    val_log_likelihood: 1465.4244177397948\n",
      "    val_log_marginal: 919.905065911989\n",
      "Train Epoch: 1147 [512/17352 (3%)] Loss: -782.997925\n",
      "Train Epoch: 1147 [10393/17352 (60%)] Loss: -925.210227\n",
      "Train Epoch: 1147 [17016/17352 (98%)] Loss: -961.223264\n",
      "    epoch          : 1147\n",
      "    loss           : -989.1038304666549\n",
      "    val_loss       : -1031.7089505937295\n",
      "    val_log_likelihood: 1481.1169242262536\n",
      "    val_log_marginal: 1043.683549621474\n",
      "Train Epoch: 1148 [512/17352 (3%)] Loss: -1067.986572\n",
      "Train Epoch: 1148 [10492/17352 (60%)] Loss: -1101.674260\n",
      "Train Epoch: 1148 [17263/17352 (99%)] Loss: -995.896599\n",
      "    epoch          : 1148\n",
      "    loss           : -1055.7917803410317\n",
      "    val_loss       : -1046.9995401002875\n",
      "    val_log_likelihood: 1476.5432290962701\n",
      "    val_log_marginal: 1058.343295951375\n",
      "Train Epoch: 1149 [512/17352 (3%)] Loss: -913.391968\n",
      "Train Epoch: 1149 [10581/17352 (61%)] Loss: -1168.205091\n",
      "Train Epoch: 1149 [16922/17352 (98%)] Loss: -1072.947331\n",
      "    epoch          : 1149\n",
      "    loss           : -1063.0705603009942\n",
      "    val_loss       : -1068.8504148681561\n",
      "    val_log_likelihood: 1495.205743461718\n",
      "    val_log_marginal: 1082.7690587904995\n",
      "Train Epoch: 1150 [512/17352 (3%)] Loss: -1109.768677\n",
      "Train Epoch: 1150 [10065/17352 (58%)] Loss: -1104.223461\n",
      "Train Epoch: 1150 [16958/17352 (98%)] Loss: -909.918280\n",
      "    epoch          : 1150\n",
      "    loss           : -1070.782974197105\n",
      "    val_loss       : -1081.774152071888\n",
      "    val_log_likelihood: 1504.0564886605805\n",
      "    val_log_marginal: 1093.0033029563833\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch1150.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 1151 [512/17352 (3%)] Loss: -1135.799194\n",
      "Train Epoch: 1151 [9859/17352 (57%)] Loss: -1111.219141\n",
      "Train Epoch: 1151 [16958/17352 (98%)] Loss: -1007.834156\n",
      "    epoch          : 1151\n",
      "    loss           : -1072.8868802203017\n",
      "    val_loss       : -1067.644004883444\n",
      "    val_log_likelihood: 1502.8054721749384\n",
      "    val_log_marginal: 1088.6922299769558\n",
      "Train Epoch: 1152 [512/17352 (3%)] Loss: -1118.929688\n",
      "Train Epoch: 1152 [10062/17352 (58%)] Loss: -1194.516276\n",
      "Train Epoch: 1152 [16872/17352 (97%)] Loss: -1136.762406\n",
      "    epoch          : 1152\n",
      "    loss           : -1073.4912236449236\n",
      "    val_loss       : -1082.532813812574\n",
      "    val_log_likelihood: 1506.1241222796332\n",
      "    val_log_marginal: 1096.3520818802933\n",
      "Train Epoch: 1153 [512/17352 (3%)] Loss: -1125.331177\n",
      "Train Epoch: 1153 [10847/17352 (63%)] Loss: -933.988038\n",
      "Train Epoch: 1153 [17277/17352 (100%)] Loss: -992.807267\n",
      "    epoch          : 1153\n",
      "    loss           : -1070.5446361101672\n",
      "    val_loss       : -1029.8861693789945\n",
      "    val_log_likelihood: 1472.7912885327362\n",
      "    val_log_marginal: 1045.6324788562238\n",
      "Train Epoch: 1154 [512/17352 (3%)] Loss: -1080.239014\n",
      "Train Epoch: 1154 [9829/17352 (57%)] Loss: -1064.262013\n",
      "Train Epoch: 1154 [17101/17352 (99%)] Loss: -1076.451535\n",
      "    epoch          : 1154\n",
      "    loss           : -1036.6632433738498\n",
      "    val_loss       : -1043.951560903939\n",
      "    val_log_likelihood: 1481.449929366725\n",
      "    val_log_marginal: 1069.3785686542908\n",
      "Train Epoch: 1155 [512/17352 (3%)] Loss: -1089.886719\n",
      "Train Epoch: 1155 [10171/17352 (59%)] Loss: -995.872190\n",
      "Train Epoch: 1155 [16922/17352 (98%)] Loss: -992.147677\n",
      "    epoch          : 1155\n",
      "    loss           : -988.5665118262931\n",
      "    val_loss       : -1028.8814665282073\n",
      "    val_log_likelihood: 1463.6531746299872\n",
      "    val_log_marginal: 1058.4161622323682\n",
      "Train Epoch: 1156 [512/17352 (3%)] Loss: -1092.485840\n",
      "Train Epoch: 1156 [10289/17352 (59%)] Loss: -825.388575\n",
      "Train Epoch: 1156 [17143/17352 (99%)] Loss: -1073.298903\n",
      "    epoch          : 1156\n",
      "    loss           : -1033.6423525577832\n",
      "    val_loss       : -1060.4987551475785\n",
      "    val_log_likelihood: 1489.074417213368\n",
      "    val_log_marginal: 1079.7607264800424\n",
      "Train Epoch: 1157 [512/17352 (3%)] Loss: -1120.954834\n",
      "Train Epoch: 1157 [10417/17352 (60%)] Loss: -1150.857597\n",
      "Train Epoch: 1157 [17263/17352 (99%)] Loss: -1177.241071\n",
      "    epoch          : 1157\n",
      "    loss           : -1060.5784183733097\n",
      "    val_loss       : -1068.2667595341195\n",
      "    val_log_likelihood: 1500.8058933627437\n",
      "    val_log_marginal: 1080.6907092768568\n",
      "Train Epoch: 1158 [512/17352 (3%)] Loss: -1111.398315\n",
      "Train Epoch: 1158 [10277/17352 (59%)] Loss: -1032.237909\n",
      "Train Epoch: 1158 [16939/17352 (98%)] Loss: -979.618935\n",
      "    epoch          : 1158\n",
      "    loss           : -1045.174602492895\n",
      "    val_loss       : -1011.6166462299855\n",
      "    val_log_likelihood: 1463.185047774067\n",
      "    val_log_marginal: 1035.781366574349\n",
      "Train Epoch: 1159 [512/17352 (3%)] Loss: -983.248230\n",
      "Train Epoch: 1159 [10087/17352 (58%)] Loss: -880.611160\n",
      "Train Epoch: 1159 [17277/17352 (100%)] Loss: -1041.842548\n",
      "    epoch          : 1159\n",
      "    loss           : -1023.9411516611952\n",
      "    val_loss       : -965.3525997811942\n",
      "    val_log_likelihood: 1447.1071445289758\n",
      "    val_log_marginal: 985.8511480621804\n",
      "Train Epoch: 1160 [512/17352 (3%)] Loss: -991.537720\n",
      "Train Epoch: 1160 [10256/17352 (59%)] Loss: -1058.111198\n",
      "Train Epoch: 1160 [17124/17352 (99%)] Loss: -1105.292642\n",
      "    epoch          : 1160\n",
      "    loss           : -1008.4991467244412\n",
      "    val_loss       : -1047.9180626610464\n",
      "    val_log_likelihood: 1469.3128214655178\n",
      "    val_log_marginal: 1061.408311986312\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch1160.pth ...\n",
      "Train Epoch: 1161 [512/17352 (3%)] Loss: -1088.632690\n",
      "Train Epoch: 1161 [10484/17352 (60%)] Loss: -897.361319\n",
      "Train Epoch: 1161 [16958/17352 (98%)] Loss: -1140.826196\n",
      "    epoch          : 1161\n",
      "    loss           : -1044.2772590767825\n",
      "    val_loss       : -1046.8599528298018\n",
      "    val_log_likelihood: 1488.5304354327375\n",
      "    val_log_marginal: 1074.4359022925403\n",
      "Train Epoch: 1162 [512/17352 (3%)] Loss: -1084.353271\n",
      "Train Epoch: 1162 [10549/17352 (61%)] Loss: -1087.117128\n",
      "Train Epoch: 1162 [17143/17352 (99%)] Loss: -1148.412729\n",
      "    epoch          : 1162\n",
      "    loss           : -1054.0473782650713\n",
      "    val_loss       : -993.9282650139346\n",
      "    val_log_likelihood: 1447.528286232277\n",
      "    val_log_marginal: 1011.158886471828\n",
      "Train Epoch: 1163 [512/17352 (3%)] Loss: -1016.657959\n",
      "Train Epoch: 1163 [10225/17352 (59%)] Loss: -1080.450143\n",
      "Train Epoch: 1163 [17126/17352 (99%)] Loss: -961.083465\n",
      "    epoch          : 1163\n",
      "    loss           : -1022.5241328129712\n",
      "    val_loss       : -1052.4787854959638\n",
      "    val_log_likelihood: 1477.528501994498\n",
      "    val_log_marginal: 1065.3124247349654\n",
      "Train Epoch: 1164 [512/17352 (3%)] Loss: -1095.124756\n",
      "Train Epoch: 1164 [10728/17352 (62%)] Loss: -1124.506323\n",
      "Train Epoch: 1164 [17263/17352 (99%)] Loss: -1094.264983\n",
      "    epoch          : 1164\n",
      "    loss           : -1047.0506526914883\n",
      "    val_loss       : -1016.6404777228466\n",
      "    val_log_likelihood: 1470.8601679651215\n",
      "    val_log_marginal: 1035.4151929774275\n",
      "Train Epoch: 1165 [512/17352 (3%)] Loss: -1071.325317\n",
      "Train Epoch: 1165 [10396/17352 (60%)] Loss: -954.781250\n",
      "Train Epoch: 1165 [16883/17352 (97%)] Loss: -750.506145\n",
      "    epoch          : 1165\n",
      "    loss           : -937.3335889376127\n",
      "    val_loss       : -971.1792642058928\n",
      "    val_log_likelihood: 1448.6344771586755\n",
      "    val_log_marginal: 1017.3499016426947\n",
      "Train Epoch: 1166 [512/17352 (3%)] Loss: -1049.413574\n",
      "Train Epoch: 1166 [10344/17352 (60%)] Loss: -970.141256\n",
      "Train Epoch: 1166 [16923/17352 (98%)] Loss: -830.178603\n",
      "    epoch          : 1166\n",
      "    loss           : -895.8631990643497\n",
      "    val_loss       : -983.5668432863176\n",
      "    val_log_likelihood: 1428.2387654680067\n",
      "    val_log_marginal: 1022.9607091688514\n",
      "Train Epoch: 1167 [512/17352 (3%)] Loss: -939.321289\n",
      "Train Epoch: 1167 [10150/17352 (58%)] Loss: -1093.250702\n",
      "Train Epoch: 1167 [17016/17352 (98%)] Loss: -994.101992\n",
      "    epoch          : 1167\n",
      "    loss           : -979.0700505821063\n",
      "    val_loss       : -978.258198492896\n",
      "    val_log_likelihood: 1448.9596475225098\n",
      "    val_log_marginal: 996.503000376268\n",
      "Train Epoch: 1168 [512/17352 (3%)] Loss: -980.124146\n",
      "Train Epoch: 1168 [10081/17352 (58%)] Loss: -1034.870793\n",
      "Train Epoch: 1168 [17253/17352 (99%)] Loss: -1095.811628\n",
      "    epoch          : 1168\n",
      "    loss           : -1042.75809969181\n",
      "    val_loss       : -996.5329622803876\n",
      "    val_log_likelihood: 1473.8571887846938\n",
      "    val_log_marginal: 1011.8217455507959\n",
      "Train Epoch: 1169 [512/17352 (3%)] Loss: -1031.673584\n",
      "Train Epoch: 1169 [10727/17352 (62%)] Loss: -1152.324051\n",
      "Train Epoch: 1169 [16882/17352 (97%)] Loss: -1122.433576\n",
      "    epoch          : 1169\n",
      "    loss           : -1025.7139831226891\n",
      "    val_loss       : -1060.9308911289515\n",
      "    val_log_likelihood: 1484.1109368315153\n",
      "    val_log_marginal: 1075.9094238455423\n",
      "Train Epoch: 1170 [512/17352 (3%)] Loss: -1106.823364\n",
      "Train Epoch: 1170 [10099/17352 (58%)] Loss: -928.448639\n",
      "Train Epoch: 1170 [17016/17352 (98%)] Loss: -930.976795\n",
      "    epoch          : 1170\n",
      "    loss           : -1051.1779784181556\n",
      "    val_loss       : -1069.5883994163246\n",
      "    val_log_likelihood: 1489.9824852557424\n",
      "    val_log_marginal: 1086.9083530640569\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch1170.pth ...\n",
      "Train Epoch: 1171 [512/17352 (3%)] Loss: -1118.195068\n",
      "Train Epoch: 1171 [10414/17352 (60%)] Loss: -926.494018\n",
      "Train Epoch: 1171 [17124/17352 (99%)] Loss: -854.955511\n",
      "    epoch          : 1171\n",
      "    loss           : -1021.7349091727458\n",
      "    val_loss       : -1025.5328858764221\n",
      "    val_log_likelihood: 1472.22397575425\n",
      "    val_log_marginal: 1039.2009984360282\n",
      "Train Epoch: 1172 [512/17352 (3%)] Loss: -1028.099609\n",
      "Train Epoch: 1172 [10225/17352 (59%)] Loss: -954.811988\n",
      "Train Epoch: 1172 [16957/17352 (98%)] Loss: -1119.014594\n",
      "    epoch          : 1172\n",
      "    loss           : -1020.5455563395744\n",
      "    val_loss       : -1053.4392034412667\n",
      "    val_log_likelihood: 1484.428620569022\n",
      "    val_log_marginal: 1074.8593705912344\n",
      "Train Epoch: 1173 [512/17352 (3%)] Loss: -1109.540161\n",
      "Train Epoch: 1173 [10315/17352 (59%)] Loss: -1128.157041\n",
      "Train Epoch: 1173 [17101/17352 (99%)] Loss: -1096.365100\n",
      "    epoch          : 1173\n",
      "    loss           : -1036.099796436717\n",
      "    val_loss       : -1041.910703558525\n",
      "    val_log_likelihood: 1471.390537764209\n",
      "    val_log_marginal: 1057.2357706766757\n",
      "Train Epoch: 1174 [512/17352 (3%)] Loss: -1072.283325\n",
      "Train Epoch: 1174 [10778/17352 (62%)] Loss: -1095.512109\n",
      "Train Epoch: 1174 [17101/17352 (99%)] Loss: -1171.668953\n",
      "    epoch          : 1174\n",
      "    loss           : -1057.1197005995587\n",
      "    val_loss       : -1049.9794224339034\n",
      "    val_log_likelihood: 1486.5424500090205\n",
      "    val_log_marginal: 1061.5630600890886\n",
      "Train Epoch: 1175 [512/17352 (3%)] Loss: -1096.368042\n",
      "Train Epoch: 1175 [10573/17352 (61%)] Loss: -1195.623915\n",
      "Train Epoch: 1175 [17049/17352 (98%)] Loss: -1136.466206\n",
      "    epoch          : 1175\n",
      "    loss           : -1061.366769138645\n",
      "    val_loss       : -1072.598481300054\n",
      "    val_log_likelihood: 1493.605145945941\n",
      "    val_log_marginal: 1082.7437034485959\n",
      "Train Epoch: 1176 [512/17352 (3%)] Loss: -1117.084717\n",
      "Train Epoch: 1176 [10010/17352 (58%)] Loss: -1130.149842\n",
      "Train Epoch: 1176 [16872/17352 (97%)] Loss: -1019.573872\n",
      "    epoch          : 1176\n",
      "    loss           : -1065.6457136005813\n",
      "    val_loss       : -1081.0345932611951\n",
      "    val_log_likelihood: 1504.0573830084818\n",
      "    val_log_marginal: 1094.6598525168488\n",
      "Train Epoch: 1177 [512/17352 (3%)] Loss: -1117.452148\n",
      "Train Epoch: 1177 [10277/17352 (59%)] Loss: -1041.417497\n",
      "Train Epoch: 1177 [17335/17352 (100%)] Loss: -973.944056\n",
      "    epoch          : 1177\n",
      "    loss           : -1073.347012054356\n",
      "    val_loss       : -1054.4585204361251\n",
      "    val_log_likelihood: 1488.9707057961252\n",
      "    val_log_marginal: 1068.8637981795855\n",
      "Train Epoch: 1178 [512/17352 (3%)] Loss: -1088.532593\n",
      "Train Epoch: 1178 [10556/17352 (61%)] Loss: -1164.253723\n",
      "Train Epoch: 1178 [17153/17352 (99%)] Loss: -1107.883591\n",
      "    epoch          : 1178\n",
      "    loss           : -1068.2715960687326\n",
      "    val_loss       : -1057.8544112069787\n",
      "    val_log_likelihood: 1482.6160382419882\n",
      "    val_log_marginal: 1066.3926306039548\n",
      "Train Epoch: 1179 [512/17352 (3%)] Loss: -1098.292969\n",
      "Train Epoch: 1179 [10564/17352 (61%)] Loss: -916.070574\n",
      "Train Epoch: 1179 [17126/17352 (99%)] Loss: -1017.279536\n",
      "    epoch          : 1179\n",
      "    loss           : -1070.4367180557153\n",
      "    val_loss       : -1066.4082509777334\n",
      "    val_log_likelihood: 1499.1303834465477\n",
      "    val_log_marginal: 1085.9654023953176\n",
      "Train Epoch: 1180 [512/17352 (3%)] Loss: -1112.430176\n",
      "Train Epoch: 1180 [10661/17352 (61%)] Loss: -1023.377637\n",
      "Train Epoch: 1180 [16872/17352 (97%)] Loss: -1142.322244\n",
      "    epoch          : 1180\n",
      "    loss           : -1056.3487276299834\n",
      "    val_loss       : -1070.0320872023099\n",
      "    val_log_likelihood: 1501.3115410015216\n",
      "    val_log_marginal: 1091.8325230871226\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch1180.pth ...\n",
      "Train Epoch: 1181 [512/17352 (3%)] Loss: -913.299133\n",
      "Train Epoch: 1181 [10427/17352 (60%)] Loss: -1213.126953\n",
      "Train Epoch: 1181 [17143/17352 (99%)] Loss: -1116.248692\n",
      "    epoch          : 1181\n",
      "    loss           : -1063.4941405738155\n",
      "    val_loss       : -1052.803455538126\n",
      "    val_log_likelihood: 1501.275937367635\n",
      "    val_log_marginal: 1081.0990742604959\n",
      "Train Epoch: 1182 [512/17352 (3%)] Loss: -1058.415283\n",
      "Train Epoch: 1182 [10102/17352 (58%)] Loss: -1152.490521\n",
      "Train Epoch: 1182 [16923/17352 (98%)] Loss: -1129.652398\n",
      "    epoch          : 1182\n",
      "    loss           : -1059.8641800630594\n",
      "    val_loss       : -1081.9801321422053\n",
      "    val_log_likelihood: 1507.7514416230158\n",
      "    val_log_marginal: 1096.6834034093795\n",
      "Train Epoch: 1183 [512/17352 (3%)] Loss: -927.214050\n",
      "Train Epoch: 1183 [10073/17352 (58%)] Loss: -871.736468\n",
      "Train Epoch: 1183 [17101/17352 (99%)] Loss: -1208.309245\n",
      "    epoch          : 1183\n",
      "    loss           : -1078.339326796451\n",
      "    val_loss       : -1086.0543124162657\n",
      "    val_log_likelihood: 1510.0233099876514\n",
      "    val_log_marginal: 1097.2299856958596\n",
      "Train Epoch: 1184 [512/17352 (3%)] Loss: -1113.860107\n",
      "Train Epoch: 1184 [10442/17352 (60%)] Loss: -1191.974014\n",
      "Train Epoch: 1184 [16988/17352 (98%)] Loss: -890.144271\n",
      "    epoch          : 1184\n",
      "    loss           : -1063.8215089765242\n",
      "    val_loss       : -1002.7134408858906\n",
      "    val_log_likelihood: 1496.5569149638752\n",
      "    val_log_marginal: 1012.9178753969338\n",
      "Train Epoch: 1185 [512/17352 (3%)] Loss: -1039.544556\n",
      "Train Epoch: 1185 [10150/17352 (58%)] Loss: -869.649249\n",
      "Train Epoch: 1185 [17108/17352 (99%)] Loss: -681.122267\n",
      "    epoch          : 1185\n",
      "    loss           : -990.975250615983\n",
      "    val_loss       : -968.6994822669295\n",
      "    val_log_likelihood: 1442.0482096792564\n",
      "    val_log_marginal: 1008.6228416364336\n",
      "Train Epoch: 1186 [512/17352 (3%)] Loss: -544.538330\n",
      "Train Epoch: 1186 [10424/17352 (60%)] Loss: -966.761342\n",
      "Train Epoch: 1186 [17044/17352 (98%)] Loss: -933.157141\n",
      "    epoch          : 1186\n",
      "    loss           : -877.7506784686693\n",
      "    val_loss       : -903.8205819070325\n",
      "    val_log_likelihood: 1405.7189721439413\n",
      "    val_log_marginal: 943.1790712681645\n",
      "Train Epoch: 1187 [512/17352 (3%)] Loss: -944.835571\n",
      "Train Epoch: 1187 [10463/17352 (60%)] Loss: -901.929852\n",
      "Train Epoch: 1187 [17090/17352 (98%)] Loss: -857.382161\n",
      "    epoch          : 1187\n",
      "    loss           : -915.6736342547118\n",
      "    val_loss       : -664.2122817643461\n",
      "    val_log_likelihood: 1399.1448774176658\n",
      "    val_log_marginal: 692.9238274913804\n",
      "Train Epoch: 1188 [512/17352 (3%)] Loss: -684.395020\n",
      "Train Epoch: 1188 [10641/17352 (61%)] Loss: -1133.006130\n",
      "Train Epoch: 1188 [16957/17352 (98%)] Loss: -1051.045080\n",
      "    epoch          : 1188\n",
      "    loss           : -923.1204366816079\n",
      "    val_loss       : -943.8958254020804\n",
      "    val_log_likelihood: 1437.4760927423808\n",
      "    val_log_marginal: 967.4823138826888\n",
      "Train Epoch: 1189 [512/17352 (3%)] Loss: -976.236633\n",
      "Train Epoch: 1189 [10299/17352 (59%)] Loss: -1046.241570\n",
      "Train Epoch: 1189 [17133/17352 (99%)] Loss: -864.652280\n",
      "    epoch          : 1189\n",
      "    loss           : -955.6005279255131\n",
      "    val_loss       : -975.0315920628746\n",
      "    val_log_likelihood: 1426.7899808695893\n",
      "    val_log_marginal: 1002.6888275769536\n",
      "Train Epoch: 1190 [512/17352 (3%)] Loss: -1038.767822\n",
      "Train Epoch: 1190 [11121/17352 (64%)] Loss: -1042.375665\n",
      "Train Epoch: 1190 [17143/17352 (99%)] Loss: -1059.035732\n",
      "    epoch          : 1190\n",
      "    loss           : -968.2122996917019\n",
      "    val_loss       : -961.3941345800094\n",
      "    val_log_likelihood: 1419.1194242429447\n",
      "    val_log_marginal: 982.9691140356233\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch1190.pth ...\n",
      "Train Epoch: 1191 [512/17352 (3%)] Loss: -1019.077209\n",
      "Train Epoch: 1191 [10057/17352 (58%)] Loss: -934.847785\n",
      "Train Epoch: 1191 [16882/17352 (97%)] Loss: -1072.821918\n",
      "    epoch          : 1191\n",
      "    loss           : -986.1612510700659\n",
      "    val_loss       : -1003.6736008580775\n",
      "    val_log_likelihood: 1455.6702294740874\n",
      "    val_log_marginal: 1059.7991231020274\n",
      "Train Epoch: 1192 [512/17352 (3%)] Loss: -986.452820\n",
      "Train Epoch: 1192 [10693/17352 (62%)] Loss: -1095.340334\n",
      "Train Epoch: 1192 [16934/17352 (98%)] Loss: -1175.808717\n",
      "    epoch          : 1192\n",
      "    loss           : -1002.238619543254\n",
      "    val_loss       : -1033.2644395029824\n",
      "    val_log_likelihood: 1464.0877105339764\n",
      "    val_log_marginal: 1066.1546817279502\n",
      "Train Epoch: 1193 [512/17352 (3%)] Loss: -1088.125610\n",
      "Train Epoch: 1193 [9734/17352 (56%)] Loss: -1089.135885\n",
      "Train Epoch: 1193 [16988/17352 (98%)] Loss: -1079.645543\n",
      "    epoch          : 1193\n",
      "    loss           : -1035.3371661604965\n",
      "    val_loss       : -1031.7481991371608\n",
      "    val_log_likelihood: 1479.0611242723776\n",
      "    val_log_marginal: 1057.7861662045686\n",
      "Train Epoch: 1194 [512/17352 (3%)] Loss: -1091.642334\n",
      "Train Epoch: 1194 [10445/17352 (60%)] Loss: -932.817890\n",
      "Train Epoch: 1194 [17044/17352 (98%)] Loss: -1135.324614\n",
      "    epoch          : 1194\n",
      "    loss           : -1054.5404259769412\n",
      "    val_loss       : -1074.082189849469\n",
      "    val_log_likelihood: 1486.9188702842996\n",
      "    val_log_marginal: 1087.5233282320742\n",
      "Train Epoch: 1195 [512/17352 (3%)] Loss: -1109.037842\n",
      "Train Epoch: 1195 [10297/17352 (59%)] Loss: -1093.340625\n",
      "Train Epoch: 1195 [17335/17352 (100%)] Loss: -1132.334708\n",
      "    epoch          : 1195\n",
      "    loss           : -1075.5515461519205\n",
      "    val_loss       : -1061.4813449010405\n",
      "    val_log_likelihood: 1497.129341593223\n",
      "    val_log_marginal: 1073.10900299413\n",
      "Train Epoch: 1196 [512/17352 (3%)] Loss: -1091.355713\n",
      "Train Epoch: 1196 [10473/17352 (60%)] Loss: -928.185753\n",
      "Train Epoch: 1196 [17153/17352 (99%)] Loss: -929.822646\n",
      "    epoch          : 1196\n",
      "    loss           : -1056.503460296166\n",
      "    val_loss       : -1071.0028327115149\n",
      "    val_log_likelihood: 1499.0124424986645\n",
      "    val_log_marginal: 1082.1308889979975\n",
      "Train Epoch: 1197 [512/17352 (3%)] Loss: -1092.337280\n",
      "Train Epoch: 1197 [10110/17352 (58%)] Loss: -935.446226\n",
      "Train Epoch: 1197 [16882/17352 (97%)] Loss: -729.116979\n",
      "    epoch          : 1197\n",
      "    loss           : -823.3262918963006\n",
      "    val_loss       : -840.1985627178558\n",
      "    val_log_likelihood: 1418.683234970689\n",
      "    val_log_marginal: 864.651866766026\n",
      "Train Epoch: 1198 [512/17352 (3%)] Loss: -855.034668\n",
      "Train Epoch: 1198 [10108/17352 (58%)] Loss: -716.949738\n",
      "Train Epoch: 1198 [17101/17352 (99%)] Loss: -827.660954\n",
      "    epoch          : 1198\n",
      "    loss           : -871.6701010625403\n",
      "    val_loss       : -933.9674543621311\n",
      "    val_log_likelihood: 1424.4699980327005\n",
      "    val_log_marginal: 956.2981840583994\n",
      "Train Epoch: 1199 [512/17352 (3%)] Loss: -971.676941\n",
      "Train Epoch: 1199 [10517/17352 (61%)] Loss: -1149.855478\n",
      "Train Epoch: 1199 [17153/17352 (99%)] Loss: -1077.681507\n",
      "    epoch          : 1199\n",
      "    loss           : -1028.4956201686762\n",
      "    val_loss       : -1057.6888470837323\n",
      "    val_log_likelihood: 1477.9848164922732\n",
      "    val_log_marginal: 1071.4969498914165\n",
      "Train Epoch: 1200 [512/17352 (3%)] Loss: -1105.639404\n",
      "Train Epoch: 1200 [10490/17352 (60%)] Loss: -1072.794728\n",
      "Train Epoch: 1200 [17143/17352 (99%)] Loss: -1003.317573\n",
      "    epoch          : 1200\n",
      "    loss           : -1067.4267434840453\n",
      "    val_loss       : -1066.6014396934388\n",
      "    val_log_likelihood: 1498.195714232628\n",
      "    val_log_marginal: 1078.142889451984\n",
      "Saving checkpoint: saved/models/Omniglot_GlimpseOperad/0214_181759/checkpoint-epoch1200.pth ...\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:categorical_bpl] *",
   "language": "python",
   "name": "conda-env-categorical_bpl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
